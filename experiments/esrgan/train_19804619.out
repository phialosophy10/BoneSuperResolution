
------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 19804619: <esrgan> in cluster <dcc> Exited

Job <esrgan> was submitted from host <n-62-11-19> by user <soeba> in cluster <dcc> at Tue Dec 19 11:45:36 2023
Job was executed on host(s) <4*n-62-20-11>, in queue <gpuv100>, as user <soeba> in cluster <dcc> at Tue Dec 19 11:47:09 2023
</zhome/19/0/64415> was used as the home directory.
</work3/soeba/HALOS/batch_jobs> was used as the working directory.
Started at Tue Dec 19 11:47:09 2023
Terminated at Tue Dec 19 11:52:42 2023
Results reported at Tue Dec 19 11:52:42 2023

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh
#BSUB -q gpuv100
#BSUB -J esrgan
#BSUB -n 4
#BSUB -gpu "num=1:mode=exclusive_process"
#BSUB -W 12:00
#BSUB -R "span[hosts=1]"
#BSUB -R "rusage[mem=8GB]"
#BSUB -R "select[gpu32gb]"
#BSUB -o /work3/soeba/HALOS/experiments/esrgan/train_%J.out
#BSUB -e /work3/soeba/HALOS/experiments/esrgan/train_%J.err

cd ..

source init.sh

# args: 
# n_epochs (int)
# batch_size (int)
# learning rate (float)
# loss-coefficient, adversarial (float)
# loss-coefficient, pixel (float)
# loss-coefficient, content (float)
# number of warmup-batches with only pixel-wise loss (int)
# femur to test on (str)
# femur(s) to train on (str)
# femurs: {"001","002","013","015","021","026","074","075","083","086","138","164","172"}

python -u esrgan_bones_v3-5.py 1 4 1e-4 1e-3 1 6e-3 0 "001" "002" "026" "083"

------------------------------------------------------------

TERM_MEMLIMIT: job killed after reaching LSF memory usage limit.
Exited with exit code 137.

Resource usage summary:

    CPU time :                                   39.00 sec.
    Max Memory :                                 32768 MB
    Average Memory :                             7508.80 MB
    Total Requested Memory :                     32768.00 MB
    Delta Memory :                               0.00 MB
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                27
    Run time :                                   332 sec.
    Turnaround time :                            426 sec.

The output (if any) is above this job summary.



PS:

Read file </work3/soeba/HALOS/experiments/esrgan/train_19804619.err> for stderr output of this job.


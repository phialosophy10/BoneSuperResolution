Training Epoch 1

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 19821755: <esrgan> in cluster <dcc> Exited

Job <esrgan> was submitted from host <n-62-11-19> by user <soeba> in cluster <dcc> at Thu Dec 21 09:58:10 2023
Job was executed on host(s) <8*n-62-18-12>, in queue <gpua100>, as user <soeba> in cluster <dcc> at Thu Dec 21 11:46:05 2023
</zhome/19/0/64415> was used as the home directory.
</work3/soeba/HALOS/batch_jobs> was used as the working directory.
Started at Thu Dec 21 11:46:05 2023
Terminated at Thu Dec 21 12:06:38 2023
Results reported at Thu Dec 21 12:06:38 2023

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh
#BSUB -q gpua100
#BSUB -J esrgan
#BSUB -n 8
#BSUB -gpu "num=1:mode=exclusive_process"
#BSUB -W 12:00
#BSUB -R "span[hosts=1]"
#BSUB -R "rusage[mem=16GB]"
#BSUB -R "select[gpu80gb]"
#BSUB -o /work3/soeba/HALOS/experiments/esrgan/train_%J.out
#BSUB -e /work3/soeba/HALOS/experiments/esrgan/train_%J.err

cd ..

source init.sh

# args: 
# n_epochs (int)
# batch_size (int)
# learning rate (float)
# loss-coefficient, adversarial (float)
# loss-coefficient, pixel (float)
# loss-coefficient, content (float)
# number of warmup-batches with only pixel-wise loss (int)
# femur to test on (str)
# femur(s) to train on (str)
# femurs: {"001","002","013","015","021","026","074","075","083","086","138","164","172"}

python -u esrgan_bones_v3-5.py 1 4 1e-4 1e-3 1 6e-3 0 "001" "002" "026" "083"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   282.41 sec.
    Max Memory :                                 102299 MB
    Average Memory :                             52815.76 MB
    Total Requested Memory :                     131072.00 MB
    Delta Memory :                               28773.00 MB
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                27
    Run time :                                   1232 sec.
    Turnaround time :                            7708 sec.

The output (if any) is above this job summary.



PS:

Read file </work3/soeba/HALOS/experiments/esrgan/train_19821755.err> for stderr output of this job.


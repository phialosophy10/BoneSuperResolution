/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 0.5553927421569824, disc_loss = 0.7012757062911987
Trained batch 1 in epoch 0, gen_loss = 0.5309128761291504, disc_loss = 0.6517634391784668
Trained batch 2 in epoch 0, gen_loss = 0.5179326037565867, disc_loss = 0.7615674336751302
Trained batch 3 in epoch 0, gen_loss = 0.5040541142225266, disc_loss = 0.6851985305547714
Trained batch 4 in epoch 0, gen_loss = 0.487139892578125, disc_loss = 0.6180076837539673
Trained batch 5 in epoch 0, gen_loss = 0.4768606821695964, disc_loss = 0.5668071508407593
Trained batch 6 in epoch 0, gen_loss = 0.4606124929019383, disc_loss = 0.5226693323680333
Trained batch 7 in epoch 0, gen_loss = 0.45063516497612, disc_loss = 0.4892972707748413
Trained batch 8 in epoch 0, gen_loss = 0.4432071910964118, disc_loss = 0.4609036048253377
Trained batch 9 in epoch 0, gen_loss = 0.437869992852211, disc_loss = 0.43520740866661073
Trained batch 10 in epoch 0, gen_loss = 0.4262544431469657, disc_loss = 0.40962364727800543
Trained batch 11 in epoch 0, gen_loss = 0.4178793554504712, disc_loss = 0.3884357127050559
Trained batch 12 in epoch 0, gen_loss = 0.4119797028028048, disc_loss = 0.36893528126753294
Trained batch 13 in epoch 0, gen_loss = 0.40383417691503254, disc_loss = 0.3517200169818742
Trained batch 14 in epoch 0, gen_loss = 0.39775424003601073, disc_loss = 0.33719147940476735
Trained batch 15 in epoch 0, gen_loss = 0.3895496018230915, disc_loss = 0.3231832687743008
Trained batch 16 in epoch 0, gen_loss = 0.3838874943116132, disc_loss = 0.3102584143771845
Trained batch 17 in epoch 0, gen_loss = 0.37734342614809674, disc_loss = 0.3000764999952581
Trained batch 18 in epoch 0, gen_loss = 0.371532214315314, disc_loss = 0.28998261729353353
Trained batch 19 in epoch 0, gen_loss = 0.36567461788654326, disc_loss = 0.28096180558204653
Trained batch 20 in epoch 0, gen_loss = 0.3599490580104646, disc_loss = 0.2707473841451463
Trained batch 21 in epoch 0, gen_loss = 0.35513249852440576, disc_loss = 0.2612671706486832
Trained batch 22 in epoch 0, gen_loss = 0.34951823561087897, disc_loss = 0.2528350667461105
Trained batch 23 in epoch 0, gen_loss = 0.3449624106287956, disc_loss = 0.2448794568578402
Trained batch 24 in epoch 0, gen_loss = 0.3400714325904846, disc_loss = 0.23753052100539207
Trained batch 25 in epoch 0, gen_loss = 0.3363670397263307, disc_loss = 0.23075777650452578
Trained batch 26 in epoch 0, gen_loss = 0.3326200037090867, disc_loss = 0.2245520674796016
Trained batch 27 in epoch 0, gen_loss = 0.32765615412167143, disc_loss = 0.21857049223035574
Trained batch 28 in epoch 0, gen_loss = 0.3235596253954131, disc_loss = 0.21250650967503415
Trained batch 29 in epoch 0, gen_loss = 0.3201399405797323, disc_loss = 0.2067580512414376
Trained batch 30 in epoch 0, gen_loss = 0.3165503288469007, disc_loss = 0.2013873052933524
Trained batch 31 in epoch 0, gen_loss = 0.31349348463118076, disc_loss = 0.1964531681733206
Trained batch 32 in epoch 0, gen_loss = 0.31013782638492005, disc_loss = 0.1915008383944179
Trained batch 33 in epoch 0, gen_loss = 0.30733665298013124, disc_loss = 0.18734293924096754
Trained batch 34 in epoch 0, gen_loss = 0.30469894877501896, disc_loss = 0.18301280896578517
Trained batch 35 in epoch 0, gen_loss = 0.3018285358945529, disc_loss = 0.17895398951239055
Trained batch 36 in epoch 0, gen_loss = 0.3001340273264292, disc_loss = 0.17517311850915085
Trained batch 37 in epoch 0, gen_loss = 0.2976183714835267, disc_loss = 0.17149964053379863
Trained batch 38 in epoch 0, gen_loss = 0.29487417065180266, disc_loss = 0.1683283895254135
Trained batch 39 in epoch 0, gen_loss = 0.2927811622619629, disc_loss = 0.16538339331746102
Trained batch 40 in epoch 0, gen_loss = 0.2899725796972833, disc_loss = 0.1627826065551944
Trained batch 41 in epoch 0, gen_loss = 0.28754796513489317, disc_loss = 0.16142121099290394
Trained batch 42 in epoch 0, gen_loss = 0.2855256799348565, disc_loss = 0.16061138690904128
Trained batch 43 in epoch 0, gen_loss = 0.28352318467064336, disc_loss = 0.15877351114018398
Trained batch 44 in epoch 0, gen_loss = 0.28110784855153825, disc_loss = 0.15654553125301998
Trained batch 45 in epoch 0, gen_loss = 0.27894596075234207, disc_loss = 0.1540788695540117
Trained batch 46 in epoch 0, gen_loss = 0.2770931679517665, disc_loss = 0.15156820479859698
Trained batch 47 in epoch 0, gen_loss = 0.27525686752051115, disc_loss = 0.14902769471518695
Trained batch 48 in epoch 0, gen_loss = 0.27369122085522635, disc_loss = 0.146600891816981
Trained batch 49 in epoch 0, gen_loss = 0.2717698732018471, disc_loss = 0.14412333238869907
Trained batch 50 in epoch 0, gen_loss = 0.26982293555549547, disc_loss = 0.1416917950207112
Trained batch 51 in epoch 0, gen_loss = 0.2673929210465688, disc_loss = 0.1393249728358709
Trained batch 52 in epoch 0, gen_loss = 0.2656384793654928, disc_loss = 0.1373317765317998
Trained batch 53 in epoch 0, gen_loss = 0.26363437788354027, disc_loss = 0.13531720465808003
Trained batch 54 in epoch 0, gen_loss = 0.2623773474584926, disc_loss = 0.13343724269758572
Trained batch 55 in epoch 0, gen_loss = 0.2608787537153278, disc_loss = 0.13144203119112977
Trained batch 56 in epoch 0, gen_loss = 0.25938097557477785, disc_loss = 0.1295045672736147
Trained batch 57 in epoch 0, gen_loss = 0.25737194794005364, disc_loss = 0.1277065538191076
Trained batch 58 in epoch 0, gen_loss = 0.25523249501899137, disc_loss = 0.12589068410886547
Trained batch 59 in epoch 0, gen_loss = 0.25354527632395424, disc_loss = 0.12411064899836978
Trained batch 60 in epoch 0, gen_loss = 0.25187304054127363, disc_loss = 0.12238913215696812
Trained batch 61 in epoch 0, gen_loss = 0.25029218461244335, disc_loss = 0.12069251259127932
Trained batch 62 in epoch 0, gen_loss = 0.24895090148562476, disc_loss = 0.11905215893472944
Trained batch 63 in epoch 0, gen_loss = 0.24727763491682708, disc_loss = 0.11742305369989481
Trained batch 64 in epoch 0, gen_loss = 0.2457862335901994, disc_loss = 0.11587305210817318
Trained batch 65 in epoch 0, gen_loss = 0.24401562999595294, disc_loss = 0.11445033238410499
Trained batch 66 in epoch 0, gen_loss = 0.24192027892194576, disc_loss = 0.1129849697532716
Trained batch 67 in epoch 0, gen_loss = 0.24003828174489386, disc_loss = 0.11157274995382656
Trained batch 68 in epoch 0, gen_loss = 0.2385564566306446, disc_loss = 0.11018890618900026
Trained batch 69 in epoch 0, gen_loss = 0.2367860942014626, disc_loss = 0.10880766960659198
Trained batch 70 in epoch 0, gen_loss = 0.23538048366005992, disc_loss = 0.10752296253619059
Trained batch 71 in epoch 0, gen_loss = 0.233985955413017, disc_loss = 0.10630582161765131
Trained batch 72 in epoch 0, gen_loss = 0.23244982335257203, disc_loss = 0.1051410119215103
Trained batch 73 in epoch 0, gen_loss = 0.23123451050471616, disc_loss = 0.10394969607728559
Trained batch 74 in epoch 0, gen_loss = 0.23022027005751927, disc_loss = 0.10283908476432164
Trained batch 75 in epoch 0, gen_loss = 0.22852813315234685, disc_loss = 0.10173343175924138
Trained batch 76 in epoch 0, gen_loss = 0.22730216712920698, disc_loss = 0.10063221537834638
Trained batch 77 in epoch 0, gen_loss = 0.22627172600000334, disc_loss = 0.0995311646316296
Trained batch 78 in epoch 0, gen_loss = 0.22513344167154045, disc_loss = 0.09845193527355979
Trained batch 79 in epoch 0, gen_loss = 0.22427183352410793, disc_loss = 0.09740662655094638
Trained batch 80 in epoch 0, gen_loss = 0.22270551691820592, disc_loss = 0.0963986973726639
Trained batch 81 in epoch 0, gen_loss = 0.22143088453790036, disc_loss = 0.09545162044147529
Trained batch 82 in epoch 0, gen_loss = 0.22014703996569276, disc_loss = 0.09451462271208146
Trained batch 83 in epoch 0, gen_loss = 0.21903521860284464, disc_loss = 0.09358711311194513
Trained batch 84 in epoch 0, gen_loss = 0.21762263748575658, disc_loss = 0.09266766823609085
Trained batch 85 in epoch 0, gen_loss = 0.21616668306117834, disc_loss = 0.09178649191203159
Trained batch 86 in epoch 0, gen_loss = 0.215162236800139, disc_loss = 0.09085840553088093
Trained batch 87 in epoch 0, gen_loss = 0.21392128125510432, disc_loss = 0.08996797085274011
Trained batch 88 in epoch 0, gen_loss = 0.21273034225019177, disc_loss = 0.08912267127817267
Trained batch 89 in epoch 0, gen_loss = 0.21155711942248875, disc_loss = 0.08834681376400921
Trained batch 90 in epoch 0, gen_loss = 0.21069905292856825, disc_loss = 0.08754152938682627
Trained batch 91 in epoch 0, gen_loss = 0.20928199095246586, disc_loss = 0.08676541603737227
Trained batch 92 in epoch 0, gen_loss = 0.2082657901349888, disc_loss = 0.08604292923043813
Trained batch 93 in epoch 0, gen_loss = 0.20693142862713082, disc_loss = 0.08528894495139731
Trained batch 94 in epoch 0, gen_loss = 0.2053797614417578, disc_loss = 0.08454515498719717
Trained batch 95 in epoch 0, gen_loss = 0.2045783766079694, disc_loss = 0.08396442354811977
Trained batch 96 in epoch 0, gen_loss = 0.20377334330192545, disc_loss = 0.08348032759176087
Trained batch 97 in epoch 0, gen_loss = 0.20242048343833613, disc_loss = 0.08280093874782324
Trained batch 98 in epoch 0, gen_loss = 0.2013320088236019, disc_loss = 0.08208167740153242
Trained batch 99 in epoch 0, gen_loss = 0.2001161801069975, disc_loss = 0.08139347376301885
Trained batch 100 in epoch 0, gen_loss = 0.19918260472540808, disc_loss = 0.08075830434439796
Trained batch 101 in epoch 0, gen_loss = 0.19811204243816583, disc_loss = 0.0800881123845922
Trained batch 102 in epoch 0, gen_loss = 0.19742407447215424, disc_loss = 0.07943914496131892
Trained batch 103 in epoch 0, gen_loss = 0.19642702203530532, disc_loss = 0.07877459217650959
Trained batch 104 in epoch 0, gen_loss = 0.19528829604387282, disc_loss = 0.07814254984259605
Trained batch 105 in epoch 0, gen_loss = 0.19420599164265506, disc_loss = 0.07751617682570557
Trained batch 106 in epoch 0, gen_loss = 0.19370556058727692, disc_loss = 0.07688713876234594
Trained batch 107 in epoch 0, gen_loss = 0.19227958246375676, disc_loss = 0.07629899340854199
Trained batch 108 in epoch 0, gen_loss = 0.19144188219664293, disc_loss = 0.07574486238625619
Trained batch 109 in epoch 0, gen_loss = 0.19045580893077635, disc_loss = 0.07514250397004864
Trained batch 110 in epoch 0, gen_loss = 0.18918565717769098, disc_loss = 0.07454041497328796
Trained batch 111 in epoch 0, gen_loss = 0.18828004029845552, disc_loss = 0.07396979927684047
Trained batch 112 in epoch 0, gen_loss = 0.1873244588815533, disc_loss = 0.07339225947626132
Trained batch 113 in epoch 0, gen_loss = 0.18587440253937976, disc_loss = 0.07281990168746888
Trained batch 114 in epoch 0, gen_loss = 0.18499354916098326, disc_loss = 0.07229346996578186
Trained batch 115 in epoch 0, gen_loss = 0.18428299821720556, disc_loss = 0.07174436589060672
Trained batch 116 in epoch 0, gen_loss = 0.18343081288676485, disc_loss = 0.07120017763068023
Trained batch 117 in epoch 0, gen_loss = 0.18245825116222691, disc_loss = 0.07069330110009443
Trained batch 118 in epoch 0, gen_loss = 0.18199492435307563, disc_loss = 0.07019238407966219
Trained batch 119 in epoch 0, gen_loss = 0.1811213073786348, disc_loss = 0.06970790097645173
Trained batch 120 in epoch 0, gen_loss = 0.17989608471489643, disc_loss = 0.06923183911934125
Trained batch 121 in epoch 0, gen_loss = 0.1792076251271074, disc_loss = 0.0687848256259668
Trained batch 122 in epoch 0, gen_loss = 0.17844979293886723, disc_loss = 0.06830624583351418
Trained batch 123 in epoch 0, gen_loss = 0.17761646606208337, disc_loss = 0.06780880885649353
Trained batch 124 in epoch 0, gen_loss = 0.17690881304442882, disc_loss = 0.0673189453445375
Trained batch 125 in epoch 0, gen_loss = 0.1762897689043293, disc_loss = 0.06685194823639615
Trained batch 126 in epoch 0, gen_loss = 0.1754165942832006, disc_loss = 0.06637863984595485
Trained batch 127 in epoch 0, gen_loss = 0.17475038724660408, disc_loss = 0.06592008939696825
Trained batch 128 in epoch 0, gen_loss = 0.1740096672762965, disc_loss = 0.06546968137556615
Trained batch 129 in epoch 0, gen_loss = 0.17335118563989035, disc_loss = 0.06502832008454089
Trained batch 130 in epoch 0, gen_loss = 0.17233754809633012, disc_loss = 0.06460612591085885
Trained batch 131 in epoch 0, gen_loss = 0.171619433810878, disc_loss = 0.06417900585978659
Trained batch 132 in epoch 0, gen_loss = 0.17079343093573152, disc_loss = 0.0637478361823561
Trained batch 133 in epoch 0, gen_loss = 0.1701059181437786, disc_loss = 0.0633380686787805
Trained batch 134 in epoch 0, gen_loss = 0.16952926705556887, disc_loss = 0.0629369074030331
Trained batch 135 in epoch 0, gen_loss = 0.1685439635424272, disc_loss = 0.06252791832529885
Trained batch 136 in epoch 0, gen_loss = 0.16777674447282823, disc_loss = 0.062135544802694426
Trained batch 137 in epoch 0, gen_loss = 0.16675848574580057, disc_loss = 0.06176755299278791
Trained batch 138 in epoch 0, gen_loss = 0.16594213672089492, disc_loss = 0.06138921782320781
Trained batch 139 in epoch 0, gen_loss = 0.16539198124249066, disc_loss = 0.06103201708091157
Trained batch 140 in epoch 0, gen_loss = 0.16458597357867036, disc_loss = 0.06067897728148927
Trained batch 141 in epoch 0, gen_loss = 0.16380589467171633, disc_loss = 0.060316686439787
Trained batch 142 in epoch 0, gen_loss = 0.16279632669801897, disc_loss = 0.05996949076522272
Trained batch 143 in epoch 0, gen_loss = 0.16190658231628025, disc_loss = 0.05962377740070224
Trained batch 144 in epoch 0, gen_loss = 0.1611018880302536, disc_loss = 0.05926784884569974
Trained batch 145 in epoch 0, gen_loss = 0.1606401030152832, disc_loss = 0.05892388562174284
Trained batch 146 in epoch 0, gen_loss = 0.15975903592953067, disc_loss = 0.05858645530506259
Trained batch 147 in epoch 0, gen_loss = 0.15911978896002513, disc_loss = 0.058247575467150356
Trained batch 148 in epoch 0, gen_loss = 0.15838635477843702, disc_loss = 0.057906492494496725
Trained batch 149 in epoch 0, gen_loss = 0.1574208435602486, disc_loss = 0.05756971857200066
Trained batch 150 in epoch 0, gen_loss = 0.15683167967451922, disc_loss = 0.05724707228557163
Trained batch 151 in epoch 0, gen_loss = 0.15619341910841236, disc_loss = 0.05692129735957439
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 0.029275773093104362, disc_loss = 0.008058817125856876
Trained batch 1 in epoch 1, gen_loss = 0.06476711761206388, disc_loss = 0.010163720231503248
Trained batch 2 in epoch 1, gen_loss = 0.05696903603772322, disc_loss = 0.009965365131696066
Trained batch 3 in epoch 1, gen_loss = 0.05513527384027839, disc_loss = 0.00942359957844019
Trained batch 4 in epoch 1, gen_loss = 0.06141802482306957, disc_loss = 0.008918534964323044
Trained batch 5 in epoch 1, gen_loss = 0.053857261004547276, disc_loss = 0.008668588319172462
Trained batch 6 in epoch 1, gen_loss = 0.049216807686856816, disc_loss = 0.008332203075821911
Trained batch 7 in epoch 1, gen_loss = 0.048003399511799216, disc_loss = 0.00846972392173484
Trained batch 8 in epoch 1, gen_loss = 0.04854287517567476, disc_loss = 0.008546788400659958
Trained batch 9 in epoch 1, gen_loss = 0.04857006799429655, disc_loss = 0.008452824410051107
Trained batch 10 in epoch 1, gen_loss = 0.04909994029863314, disc_loss = 0.008394046093929897
Trained batch 11 in epoch 1, gen_loss = 0.04988591761017839, disc_loss = 0.00837948297460874
Trained batch 12 in epoch 1, gen_loss = 0.04794071156245012, disc_loss = 0.008455278280262764
Trained batch 13 in epoch 1, gen_loss = 0.04426520547297384, disc_loss = 0.008339446836284228
Trained batch 14 in epoch 1, gen_loss = 0.045643683926512794, disc_loss = 0.008167055062949657
Trained batch 15 in epoch 1, gen_loss = 0.04416434155427851, disc_loss = 0.008033878781134263
Trained batch 16 in epoch 1, gen_loss = 0.040357272113289905, disc_loss = 0.007926662069033174
Trained batch 17 in epoch 1, gen_loss = 0.03846257953490648, disc_loss = 0.007813354022800922
Trained batch 18 in epoch 1, gen_loss = 0.03625173651074108, disc_loss = 0.007877497443635213
Trained batch 19 in epoch 1, gen_loss = 0.03610356207937002, disc_loss = 0.00845462824217975
Trained batch 20 in epoch 1, gen_loss = 0.036459959156456445, disc_loss = 0.010059263158057417
Trained batch 21 in epoch 1, gen_loss = 0.03665669110010971, disc_loss = 0.011202548164874315
Trained batch 22 in epoch 1, gen_loss = 0.035044478171545525, disc_loss = 0.011433462288392626
Trained batch 23 in epoch 1, gen_loss = 0.03372077395518621, disc_loss = 0.011341143399477005
Trained batch 24 in epoch 1, gen_loss = 0.033815187513828275, disc_loss = 0.011613290011882781
Trained batch 25 in epoch 1, gen_loss = 0.034514471888542175, disc_loss = 0.011626880544309433
Trained batch 26 in epoch 1, gen_loss = 0.03352495219075569, disc_loss = 0.01144643452156473
Trained batch 27 in epoch 1, gen_loss = 0.03227526118280366, disc_loss = 0.011223871759804232
Trained batch 28 in epoch 1, gen_loss = 0.03192663972330247, disc_loss = 0.01112242479776514
Trained batch 29 in epoch 1, gen_loss = 0.030429991295871636, disc_loss = 0.011122579996784529
Trained batch 30 in epoch 1, gen_loss = 0.03157313500771359, disc_loss = 0.011193543191879027
Trained batch 31 in epoch 1, gen_loss = 0.0301694022709853, disc_loss = 0.011252464464632794
Trained batch 32 in epoch 1, gen_loss = 0.030791017389150733, disc_loss = 0.011286891347756891
Trained batch 33 in epoch 1, gen_loss = 0.02955657957970877, disc_loss = 0.011214651961756103
Trained batch 34 in epoch 1, gen_loss = 0.02929142172714429, disc_loss = 0.0110383877530694
Trained batch 35 in epoch 1, gen_loss = 0.029182189111856535, disc_loss = 0.010891993892275624
Trained batch 36 in epoch 1, gen_loss = 0.029044746566010086, disc_loss = 0.010817034446911232
Trained batch 37 in epoch 1, gen_loss = 0.02762911705863907, disc_loss = 0.010671816398634723
Trained batch 38 in epoch 1, gen_loss = 0.026920796636671022, disc_loss = 0.01050597871056734
Trained batch 39 in epoch 1, gen_loss = 0.025915399544953744, disc_loss = 0.010397969465702771
Trained batch 40 in epoch 1, gen_loss = 0.026906329845044128, disc_loss = 0.010330685119076474
Trained batch 41 in epoch 1, gen_loss = 0.02752152305015443, disc_loss = 0.010253678153579434
Trained batch 42 in epoch 1, gen_loss = 0.027129605349315637, disc_loss = 0.010203800781435051
Trained batch 43 in epoch 1, gen_loss = 0.026666415349061688, disc_loss = 0.010102100744420155
Trained batch 44 in epoch 1, gen_loss = 0.02618239505596244, disc_loss = 0.010025564467327462
Trained batch 45 in epoch 1, gen_loss = 0.025151420710274222, disc_loss = 0.00993573144280716
Trained batch 46 in epoch 1, gen_loss = 0.023694366535360036, disc_loss = 0.009802451907122072
Trained batch 47 in epoch 1, gen_loss = 0.023440531204367215, disc_loss = 0.00969940811531463
Trained batch 48 in epoch 1, gen_loss = 0.023507166332346598, disc_loss = 0.009610057575628161
Trained batch 49 in epoch 1, gen_loss = 0.023938924876665622, disc_loss = 0.009562991498969496
Trained batch 50 in epoch 1, gen_loss = 0.023893471863549863, disc_loss = 0.009473216331874331
Trained batch 51 in epoch 1, gen_loss = 0.023821113292333742, disc_loss = 0.009403023013594346
Trained batch 52 in epoch 1, gen_loss = 0.02342903423972667, disc_loss = 0.009330076292895203
Trained batch 53 in epoch 1, gen_loss = 0.023733920449347825, disc_loss = 0.009260365942113654
Trained batch 54 in epoch 1, gen_loss = 0.02226237681497051, disc_loss = 0.009251876814629544
Trained batch 55 in epoch 1, gen_loss = 0.021994965331121615, disc_loss = 0.009173489886701905
Trained batch 56 in epoch 1, gen_loss = 0.021309350777899357, disc_loss = 0.009121522826158949
Trained batch 57 in epoch 1, gen_loss = 0.02111757381005881, disc_loss = 0.009102935738187155
Trained batch 58 in epoch 1, gen_loss = 0.019978081662799723, disc_loss = 0.009045862683521236
Trained batch 59 in epoch 1, gen_loss = 0.019357499369008716, disc_loss = 0.008987247614034763
Trained batch 60 in epoch 1, gen_loss = 0.018787929984168318, disc_loss = 0.008914929459665398
Trained batch 61 in epoch 1, gen_loss = 0.01892354884385426, disc_loss = 0.008856972089908537
Trained batch 62 in epoch 1, gen_loss = 0.018618566592327364, disc_loss = 0.008788947566663699
Trained batch 63 in epoch 1, gen_loss = 0.018444426112488088, disc_loss = 0.008733965620194795
Trained batch 64 in epoch 1, gen_loss = 0.018207660745771976, disc_loss = 0.008675312455027149
Trained batch 65 in epoch 1, gen_loss = 0.0183837702483164, disc_loss = 0.008606872454313843
Trained batch 66 in epoch 1, gen_loss = 0.018169163516319455, disc_loss = 0.008571216186730941
Trained batch 67 in epoch 1, gen_loss = 0.01731233997128022, disc_loss = 0.008512889969792655
Trained batch 68 in epoch 1, gen_loss = 0.01652933681324335, disc_loss = 0.008454978300690435
Trained batch 69 in epoch 1, gen_loss = 0.016021807437177165, disc_loss = 0.008410247059405915
Trained batch 70 in epoch 1, gen_loss = 0.01598918037746149, disc_loss = 0.008352261223554822
Trained batch 71 in epoch 1, gen_loss = 0.015438140045230538, disc_loss = 0.008293587756472535
Trained batch 72 in epoch 1, gen_loss = 0.014993220477071478, disc_loss = 0.008239966348349436
Trained batch 73 in epoch 1, gen_loss = 0.014163476954843497, disc_loss = 0.00820461571581561
Trained batch 74 in epoch 1, gen_loss = 0.013525233130852334, disc_loss = 0.00818491973914206
Trained batch 75 in epoch 1, gen_loss = 0.013093845782703428, disc_loss = 0.008139463953404246
Trained batch 76 in epoch 1, gen_loss = 0.012237384732667455, disc_loss = 0.00809456316403464
Trained batch 77 in epoch 1, gen_loss = 0.012060901605571836, disc_loss = 0.008079971864413565
Trained batch 78 in epoch 1, gen_loss = 0.011485009420545183, disc_loss = 0.008052760443379041
Trained batch 79 in epoch 1, gen_loss = 0.011374879065505184, disc_loss = 0.008024625413236208
Trained batch 80 in epoch 1, gen_loss = 0.0114946507658625, disc_loss = 0.007972408571843932
Trained batch 81 in epoch 1, gen_loss = 0.010772962459862733, disc_loss = 0.007919466915176955
Trained batch 82 in epoch 1, gen_loss = 0.010309923189389196, disc_loss = 0.007872209230617407
Trained batch 83 in epoch 1, gen_loss = 0.00985868753738963, disc_loss = 0.007826915822945358
Trained batch 84 in epoch 1, gen_loss = 0.009602077049433265, disc_loss = 0.0077934384044698055
Trained batch 85 in epoch 1, gen_loss = 0.009356743349043913, disc_loss = 0.007800004956702334
Trained batch 86 in epoch 1, gen_loss = 0.008828962260771544, disc_loss = 0.007767523138452022
Trained batch 87 in epoch 1, gen_loss = 0.008458842413817407, disc_loss = 0.0077487940619572655
Trained batch 88 in epoch 1, gen_loss = 0.0080728122529814, disc_loss = 0.007729127257539148
Trained batch 89 in epoch 1, gen_loss = 0.007433069100458548, disc_loss = 0.0076795520157449775
Trained batch 90 in epoch 1, gen_loss = 0.006927746641255139, disc_loss = 0.0076395017350768
Trained batch 91 in epoch 1, gen_loss = 0.006666035225837573, disc_loss = 0.007595437588980017
Trained batch 92 in epoch 1, gen_loss = 0.00615071448874005, disc_loss = 0.007539775608087419
Trained batch 93 in epoch 1, gen_loss = 0.005627929090799606, disc_loss = 0.007495443215296465
Trained batch 94 in epoch 1, gen_loss = 0.005546795754703213, disc_loss = 0.007452393504545877
Trained batch 95 in epoch 1, gen_loss = 0.00520771084262132, disc_loss = 0.007409266729761536
Trained batch 96 in epoch 1, gen_loss = 0.004621887888202464, disc_loss = 0.007359925667112021
Trained batch 97 in epoch 1, gen_loss = 0.004887741801709052, disc_loss = 0.007497750916423238
Trained batch 98 in epoch 1, gen_loss = 0.004469290659301925, disc_loss = 0.01054616973293249
Trained batch 99 in epoch 1, gen_loss = 0.004626313318926805, disc_loss = 0.01430619620718062
Trained batch 100 in epoch 1, gen_loss = 0.00449433081023539, disc_loss = 0.020037516149332617
Trained batch 101 in epoch 1, gen_loss = 0.004540863767795813, disc_loss = 0.02542533792153585
Trained batch 102 in epoch 1, gen_loss = 0.004179264890283166, disc_loss = 0.039619268370267836
Trained batch 103 in epoch 1, gen_loss = 0.003945856544493591, disc_loss = 0.04664322698954493
Trained batch 104 in epoch 1, gen_loss = 0.0033649620657342895, disc_loss = 0.04969726113513822
Trained batch 105 in epoch 1, gen_loss = 0.0028521108348449386, disc_loss = 0.051884912876939436
Trained batch 106 in epoch 1, gen_loss = 0.0025558858234783137, disc_loss = 0.05350010049155104
Trained batch 107 in epoch 1, gen_loss = 0.001981889873415336, disc_loss = 0.05469200395358106
Trained batch 108 in epoch 1, gen_loss = 0.0017881312531102627, disc_loss = 0.05553687884207439
Trained batch 109 in epoch 1, gen_loss = 0.0011845029648901056, disc_loss = 0.05623899922621521
Trained batch 110 in epoch 1, gen_loss = 0.0008619203924092027, disc_loss = 0.05690414311683124
Trained batch 111 in epoch 1, gen_loss = 0.0007394091155146855, disc_loss = 0.057317575647695254
Trained batch 112 in epoch 1, gen_loss = 0.0005115248291398514, disc_loss = 0.05743971250258979
Trained batch 113 in epoch 1, gen_loss = 0.00019987059157469239, disc_loss = 0.0574501219957152
Trained batch 114 in epoch 1, gen_loss = 5.4884290128266794e-05, disc_loss = 0.057381307665744556
Trained batch 115 in epoch 1, gen_loss = -0.00016690924614349884, disc_loss = 0.05721249901047298
Trained batch 116 in epoch 1, gen_loss = -0.0004888124609063889, disc_loss = 0.05700309384359509
Trained batch 117 in epoch 1, gen_loss = -0.0004555748850896758, disc_loss = 0.056735578916524934
Trained batch 118 in epoch 1, gen_loss = -0.000976369265075647, disc_loss = 0.056498182162705086
Trained batch 119 in epoch 1, gen_loss = -0.0014746419880073821, disc_loss = 0.05624397067197909
Trained batch 120 in epoch 1, gen_loss = -0.0018068318752002671, disc_loss = 0.05603451376457599
Trained batch 121 in epoch 1, gen_loss = -0.0022840083786973752, disc_loss = 0.05586884490626513
Trained batch 122 in epoch 1, gen_loss = -0.002832213351230462, disc_loss = 0.05562049186054042
Trained batch 123 in epoch 1, gen_loss = -0.0033592984722777292, disc_loss = 0.05529845946828925
Trained batch 124 in epoch 1, gen_loss = -0.0038446323078424028, disc_loss = 0.05496028994768858
Trained batch 125 in epoch 1, gen_loss = -0.004354446515514884, disc_loss = 0.0546303870348585
Trained batch 126 in epoch 1, gen_loss = -0.004567401185587781, disc_loss = 0.05430593065858826
Trained batch 127 in epoch 1, gen_loss = -0.0050384294398391205, disc_loss = 0.05395423427398782
Trained batch 128 in epoch 1, gen_loss = -0.005367694446817069, disc_loss = 0.05361954619487127
Trained batch 129 in epoch 1, gen_loss = -0.005480524592058618, disc_loss = 0.053268789514326134
Trained batch 130 in epoch 1, gen_loss = -0.00571359356562432, disc_loss = 0.052927455047273454
Trained batch 131 in epoch 1, gen_loss = -0.005974104609298124, disc_loss = 0.05259983426411495
Trained batch 132 in epoch 1, gen_loss = -0.0062925288814603434, disc_loss = 0.052285576561339815
Trained batch 133 in epoch 1, gen_loss = -0.0068594599653786295, disc_loss = 0.051973553374409676
Trained batch 134 in epoch 1, gen_loss = -0.007356166655777256, disc_loss = 0.0516524283974259
Trained batch 135 in epoch 1, gen_loss = -0.007595074837986297, disc_loss = 0.05132408165509867
Trained batch 136 in epoch 1, gen_loss = -0.008030255001242279, disc_loss = 0.0509978074573633
Trained batch 137 in epoch 1, gen_loss = -0.008524069247753858, disc_loss = 0.050664085624874504
Trained batch 138 in epoch 1, gen_loss = -0.008581661447413668, disc_loss = 0.05036592447339631
Trained batch 139 in epoch 1, gen_loss = -0.008710910016364842, disc_loss = 0.050047138379886745
Trained batch 140 in epoch 1, gen_loss = -0.008779613679988295, disc_loss = 0.04972983015278447
Trained batch 141 in epoch 1, gen_loss = -0.008987257226632645, disc_loss = 0.049419698620241294
Trained batch 142 in epoch 1, gen_loss = -0.009224916615230349, disc_loss = 0.049129356682248465
Trained batch 143 in epoch 1, gen_loss = -0.009276896775661372, disc_loss = 0.0488427492738184
Trained batch 144 in epoch 1, gen_loss = -0.009581045583879665, disc_loss = 0.04856669474393129
Trained batch 145 in epoch 1, gen_loss = -0.009794165963039133, disc_loss = 0.0482818176874202
Trained batch 146 in epoch 1, gen_loss = -0.009874463698148853, disc_loss = 0.0479967114388892
Trained batch 147 in epoch 1, gen_loss = -0.01036306416108653, disc_loss = 0.04771254045221753
Trained batch 148 in epoch 1, gen_loss = -0.010752868540797583, disc_loss = 0.047433389416402016
Trained batch 149 in epoch 1, gen_loss = -0.01101080433374894, disc_loss = 0.04715847198230525
Trained batch 150 in epoch 1, gen_loss = -0.011357522423755376, disc_loss = 0.0468931574750667
Trained batch 151 in epoch 1, gen_loss = -0.011636170125774769, disc_loss = 0.046631708716679564
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = -0.04107816517353058, disc_loss = 0.005646790377795696
Trained batch 1 in epoch 2, gen_loss = -0.05143622308969498, disc_loss = 0.005362235009670258
Trained batch 2 in epoch 2, gen_loss = -0.06748169908920924, disc_loss = 0.0053457704683144884
Trained batch 3 in epoch 2, gen_loss = -0.07650176249444485, disc_loss = 0.005013143760152161
Trained batch 4 in epoch 2, gen_loss = -0.08084753602743149, disc_loss = 0.004994799196720123
Trained batch 5 in epoch 2, gen_loss = -0.08093603576223056, disc_loss = 0.005119654660423596
Trained batch 6 in epoch 2, gen_loss = -0.08000246116093226, disc_loss = 0.005066560115665197
Trained batch 7 in epoch 2, gen_loss = -0.0791097404435277, disc_loss = 0.005252309027127922
Trained batch 8 in epoch 2, gen_loss = -0.07788840019040638, disc_loss = 0.005410012530369891
Trained batch 9 in epoch 2, gen_loss = -0.08153399899601936, disc_loss = 0.005326489312574267
Trained batch 10 in epoch 2, gen_loss = -0.08179412917657332, disc_loss = 0.005327933933585882
Trained batch 11 in epoch 2, gen_loss = -0.08093051984906197, disc_loss = 0.0054081321383516
Trained batch 12 in epoch 2, gen_loss = -0.07950778305530548, disc_loss = 0.005456479445386391
Trained batch 13 in epoch 2, gen_loss = -0.07776646156396184, disc_loss = 0.005376104697851198
Trained batch 14 in epoch 2, gen_loss = -0.07798770715792974, disc_loss = 0.0053104160043100515
Trained batch 15 in epoch 2, gen_loss = -0.07833825005218387, disc_loss = 0.00523300762870349
Trained batch 16 in epoch 2, gen_loss = -0.07864683603539187, disc_loss = 0.005184125620871782
Trained batch 17 in epoch 2, gen_loss = -0.07900865914093123, disc_loss = 0.0050617957798143225
Trained batch 18 in epoch 2, gen_loss = -0.07930239682134829, disc_loss = 0.004982144351264364
Trained batch 19 in epoch 2, gen_loss = -0.07891456335783005, disc_loss = 0.004938346636481583
Trained batch 20 in epoch 2, gen_loss = -0.08028537992920194, disc_loss = 0.004873048314558608
Trained batch 21 in epoch 2, gen_loss = -0.07902926579117775, disc_loss = 0.004805414598773827
Trained batch 22 in epoch 2, gen_loss = -0.07756305745114452, disc_loss = 0.004735611622100291
Trained batch 23 in epoch 2, gen_loss = -0.07775523482511441, disc_loss = 0.00468512096752723
Trained batch 24 in epoch 2, gen_loss = -0.07685363382101058, disc_loss = 0.004636996248736977
Trained batch 25 in epoch 2, gen_loss = -0.0764872615153973, disc_loss = 0.004575842060148716
Trained batch 26 in epoch 2, gen_loss = -0.07712014461005176, disc_loss = 0.004520709126221913
Trained batch 27 in epoch 2, gen_loss = -0.07744779224906649, disc_loss = 0.004518981324508786
Trained batch 28 in epoch 2, gen_loss = -0.07669942877415953, disc_loss = 0.004524090102520482
Trained batch 29 in epoch 2, gen_loss = -0.07733488157391548, disc_loss = 0.004492814644860724
Trained batch 30 in epoch 2, gen_loss = -0.0783119446808292, disc_loss = 0.004463839247041653
Trained batch 31 in epoch 2, gen_loss = -0.07698853802867234, disc_loss = 0.004470325984584633
Trained batch 32 in epoch 2, gen_loss = -0.07827102708997148, disc_loss = 0.004444479977599148
Trained batch 33 in epoch 2, gen_loss = -0.07793855908162453, disc_loss = 0.004393190891920205
Trained batch 34 in epoch 2, gen_loss = -0.07822698929480144, disc_loss = 0.004362342633040888
Trained batch 35 in epoch 2, gen_loss = -0.07862875714070267, disc_loss = 0.004339125932246033
Trained batch 36 in epoch 2, gen_loss = -0.0789592580215351, disc_loss = 0.004306844196508865
Trained batch 37 in epoch 2, gen_loss = -0.07900784458768995, disc_loss = 0.004273187779625387
Trained batch 38 in epoch 2, gen_loss = -0.0797897919248312, disc_loss = 0.0042878572697727345
Trained batch 39 in epoch 2, gen_loss = -0.07959790099412203, disc_loss = 0.004304691689321771
Trained batch 40 in epoch 2, gen_loss = -0.0788630699602569, disc_loss = 0.004271805064934419
Trained batch 41 in epoch 2, gen_loss = -0.07963209333164352, disc_loss = 0.004226915948536424
Trained batch 42 in epoch 2, gen_loss = -0.08001156012679256, disc_loss = 0.004206142550724191
Trained batch 43 in epoch 2, gen_loss = -0.07998500696637413, disc_loss = 0.004206913152963601
Trained batch 44 in epoch 2, gen_loss = -0.08003988977935579, disc_loss = 0.0042112587123281425
Trained batch 45 in epoch 2, gen_loss = -0.08060132388187491, disc_loss = 0.004198640068669034
Trained batch 46 in epoch 2, gen_loss = -0.08074537078116803, disc_loss = 0.004186136256705256
Trained batch 47 in epoch 2, gen_loss = -0.08027506837000449, disc_loss = 0.004156600785790943
Trained batch 48 in epoch 2, gen_loss = -0.08013335630601766, disc_loss = 0.004117650521577013
Trained batch 49 in epoch 2, gen_loss = -0.08033491030335427, disc_loss = 0.004084486863575876
Trained batch 50 in epoch 2, gen_loss = -0.08072993699826446, disc_loss = 0.0040680953511493465
Trained batch 51 in epoch 2, gen_loss = -0.0817771225881118, disc_loss = 0.004063388180489151
Trained batch 52 in epoch 2, gen_loss = -0.08184699531433717, disc_loss = 0.004051209761286681
Trained batch 53 in epoch 2, gen_loss = -0.08197526468171014, disc_loss = 0.004023702970395486
Trained batch 54 in epoch 2, gen_loss = -0.08188449916514483, disc_loss = 0.003992830039086667
Trained batch 55 in epoch 2, gen_loss = -0.08141255511769227, disc_loss = 0.003967405222023704
Trained batch 56 in epoch 2, gen_loss = -0.08163119617261384, disc_loss = 0.003938508162830482
Trained batch 57 in epoch 2, gen_loss = -0.0817207424291249, disc_loss = 0.003948280411162253
Trained batch 58 in epoch 2, gen_loss = -0.08181209331851895, disc_loss = 0.003973098329694594
Trained batch 59 in epoch 2, gen_loss = -0.08196898524959882, disc_loss = 0.003977730699504415
Trained batch 60 in epoch 2, gen_loss = -0.08099737357287133, disc_loss = 0.004136400404157209
Trained batch 61 in epoch 2, gen_loss = -0.08182104181257947, disc_loss = 0.004238816203489419
Trained batch 62 in epoch 2, gen_loss = -0.08287593281813084, disc_loss = 0.004322134446175326
Trained batch 63 in epoch 2, gen_loss = -0.08245252675260417, disc_loss = 0.004349262831965461
Trained batch 64 in epoch 2, gen_loss = -0.08308854925517853, disc_loss = 0.004349339466828566
Trained batch 65 in epoch 2, gen_loss = -0.08315327162431045, disc_loss = 0.004345332230017943
Trained batch 66 in epoch 2, gen_loss = -0.08361491180066742, disc_loss = 0.0043291492985366884
Trained batch 67 in epoch 2, gen_loss = -0.08344662022393416, disc_loss = 0.0043189423980520055
Trained batch 68 in epoch 2, gen_loss = -0.0832557014959014, disc_loss = 0.004287864864412425
Trained batch 69 in epoch 2, gen_loss = -0.08350437664027725, disc_loss = 0.00426423699328942
Trained batch 70 in epoch 2, gen_loss = -0.08339715998252513, disc_loss = 0.0042367782181417435
Trained batch 71 in epoch 2, gen_loss = -0.08358946253752543, disc_loss = 0.004214350244082097
Trained batch 72 in epoch 2, gen_loss = -0.08389401392475383, disc_loss = 0.004192480527196233
Trained batch 73 in epoch 2, gen_loss = -0.08452564797590713, disc_loss = 0.004187113564536982
Trained batch 74 in epoch 2, gen_loss = -0.08445949661235015, disc_loss = 0.00419594413600862
Trained batch 75 in epoch 2, gen_loss = -0.08492615365570313, disc_loss = 0.004203903896268457
Trained batch 76 in epoch 2, gen_loss = -0.08472502577517714, disc_loss = 0.004193731798342876
Trained batch 77 in epoch 2, gen_loss = -0.08488163387832734, disc_loss = 0.004185324889989808
Trained batch 78 in epoch 2, gen_loss = -0.08553194770990294, disc_loss = 0.004182675874002183
Trained batch 79 in epoch 2, gen_loss = -0.0855777453398332, disc_loss = 0.004170998724293895
Trained batch 80 in epoch 2, gen_loss = -0.08581301999956738, disc_loss = 0.0041582837246680335
Trained batch 81 in epoch 2, gen_loss = -0.08560850623449902, disc_loss = 0.004148111857541996
Trained batch 82 in epoch 2, gen_loss = -0.08555511831788414, disc_loss = 0.004156796814290336
Trained batch 83 in epoch 2, gen_loss = -0.08560696392807932, disc_loss = 0.0041672608210882615
Trained batch 84 in epoch 2, gen_loss = -0.08624949935166275, disc_loss = 0.004159704373930307
Trained batch 85 in epoch 2, gen_loss = -0.08670052667256704, disc_loss = 0.004134482273637036
Trained batch 86 in epoch 2, gen_loss = -0.08682961794066019, disc_loss = 0.004109187558796471
Trained batch 87 in epoch 2, gen_loss = -0.08743807739070193, disc_loss = 0.004085600993924097
Trained batch 88 in epoch 2, gen_loss = -0.08748959488329593, disc_loss = 0.004066629477860301
Trained batch 89 in epoch 2, gen_loss = -0.08793738316744566, disc_loss = 0.004045439688747542
Trained batch 90 in epoch 2, gen_loss = -0.0880516231837836, disc_loss = 0.004030672200075299
Trained batch 91 in epoch 2, gen_loss = -0.0885928417151065, disc_loss = 0.004009788401637469
Trained batch 92 in epoch 2, gen_loss = -0.08879145465150315, disc_loss = 0.003989626619694454
Trained batch 93 in epoch 2, gen_loss = -0.08871165573834738, disc_loss = 0.003995626338787297
Trained batch 94 in epoch 2, gen_loss = -0.08910643809327953, disc_loss = 0.003988764181390013
Trained batch 95 in epoch 2, gen_loss = -0.08915585688858603, disc_loss = 0.003986063829264215
Trained batch 96 in epoch 2, gen_loss = -0.08965746203879106, disc_loss = 0.003983621388318536
Trained batch 97 in epoch 2, gen_loss = -0.08987828250974417, disc_loss = 0.003970452618775699
Trained batch 98 in epoch 2, gen_loss = -0.09009670223476308, disc_loss = 0.0039637282036828125
Trained batch 99 in epoch 2, gen_loss = -0.08971884986385703, disc_loss = 0.003950344497570768
Trained batch 100 in epoch 2, gen_loss = -0.08994947379399644, disc_loss = 0.003932466733933306
Trained batch 101 in epoch 2, gen_loss = -0.08993829974868134, disc_loss = 0.0039179001183833415
Trained batch 102 in epoch 2, gen_loss = -0.09007801417514537, disc_loss = 0.0038979613341987855
Trained batch 103 in epoch 2, gen_loss = -0.09025513092414118, disc_loss = 0.0038795831843834515
Trained batch 104 in epoch 2, gen_loss = -0.0904612332405079, disc_loss = 0.0038559463928409276
Trained batch 105 in epoch 2, gen_loss = -0.09076441457178795, disc_loss = 0.0038363861879948877
Trained batch 106 in epoch 2, gen_loss = -0.0913525749972769, disc_loss = 0.003818871378332864
Trained batch 107 in epoch 2, gen_loss = -0.09158070238859013, disc_loss = 0.003801638354262751
Trained batch 108 in epoch 2, gen_loss = -0.09170137870407433, disc_loss = 0.0037837353964344763
Trained batch 109 in epoch 2, gen_loss = -0.0915341842411594, disc_loss = 0.003771817475684326
Trained batch 110 in epoch 2, gen_loss = -0.0920532379836381, disc_loss = 0.003754853450290456
Trained batch 111 in epoch 2, gen_loss = -0.09240196437375355, disc_loss = 0.003745767428232024
Trained batch 112 in epoch 2, gen_loss = -0.0924343198241122, disc_loss = 0.0037424597194813916
Trained batch 113 in epoch 2, gen_loss = -0.0931295596161171, disc_loss = 0.0037371437422718786
Trained batch 114 in epoch 2, gen_loss = -0.09349122674244902, disc_loss = 0.003721946715782194
Trained batch 115 in epoch 2, gen_loss = -0.09355276416794493, disc_loss = 0.0037106420726370835
Trained batch 116 in epoch 2, gen_loss = -0.09350439630703539, disc_loss = 0.003703409974049363
Trained batch 117 in epoch 2, gen_loss = -0.09343201747574544, disc_loss = 0.0036897649603769562
Trained batch 118 in epoch 2, gen_loss = -0.09366902194040663, disc_loss = 0.0036793432497818556
Trained batch 119 in epoch 2, gen_loss = -0.09407673215804001, disc_loss = 0.003674270935395422
Trained batch 120 in epoch 2, gen_loss = -0.09434166906232183, disc_loss = 0.0036656497775630886
Trained batch 121 in epoch 2, gen_loss = -0.0950488322185444, disc_loss = 0.0036548028888990034
Trained batch 122 in epoch 2, gen_loss = -0.0955783236408379, disc_loss = 0.0036432234413270666
Trained batch 123 in epoch 2, gen_loss = -0.09600598039105535, disc_loss = 0.0036383966639292457
Trained batch 124 in epoch 2, gen_loss = -0.09638306306302548, disc_loss = 0.003626765719614923
Trained batch 125 in epoch 2, gen_loss = -0.09644248926391204, disc_loss = 0.0036160763831705684
Trained batch 126 in epoch 2, gen_loss = -0.09696524618120175, disc_loss = 0.003601463673834315
Trained batch 127 in epoch 2, gen_loss = -0.09749968662799802, disc_loss = 0.003586670483855414
Trained batch 128 in epoch 2, gen_loss = -0.09780639628049477, disc_loss = 0.00357994322968257
Trained batch 129 in epoch 2, gen_loss = -0.09816535973491577, disc_loss = 0.003567101007613998
Trained batch 130 in epoch 2, gen_loss = -0.09844732396873354, disc_loss = 0.0035519180810505537
Trained batch 131 in epoch 2, gen_loss = -0.09875081997421203, disc_loss = 0.0035410774298449696
Trained batch 132 in epoch 2, gen_loss = -0.09906969940695996, disc_loss = 0.0035275075719446727
Trained batch 133 in epoch 2, gen_loss = -0.09949254932632642, disc_loss = 0.0035188006482142677
Trained batch 134 in epoch 2, gen_loss = -0.09974510701442206, disc_loss = 0.0035113463428354374
Trained batch 135 in epoch 2, gen_loss = -0.09994913230869262, disc_loss = 0.0034996038893415756
Trained batch 136 in epoch 2, gen_loss = -0.1003440984925867, disc_loss = 0.003489345904392102
Trained batch 137 in epoch 2, gen_loss = -0.10059460132396307, disc_loss = 0.003478637252819549
Trained batch 138 in epoch 2, gen_loss = -0.10070599281905795, disc_loss = 0.0034644985931637368
Trained batch 139 in epoch 2, gen_loss = -0.10091918428827609, disc_loss = 0.003458695754774713
Trained batch 140 in epoch 2, gen_loss = -0.10084388409047684, disc_loss = 0.003454090242194844
Trained batch 141 in epoch 2, gen_loss = -0.10112367506125863, disc_loss = 0.0034446614740324586
Trained batch 142 in epoch 2, gen_loss = -0.10107346305011453, disc_loss = 0.0034368304052175237
Trained batch 143 in epoch 2, gen_loss = -0.10117957025714633, disc_loss = 0.003423601979092281
Trained batch 144 in epoch 2, gen_loss = -0.10144069080465827, disc_loss = 0.003411244425183997
Trained batch 145 in epoch 2, gen_loss = -0.10191222738270482, disc_loss = 0.0033983430380244064
Trained batch 146 in epoch 2, gen_loss = -0.10202975230304157, disc_loss = 0.0033872584633364462
Trained batch 147 in epoch 2, gen_loss = -0.10234802159656947, disc_loss = 0.0033786910848780157
Trained batch 148 in epoch 2, gen_loss = -0.10277420236110288, disc_loss = 0.0033686573753108416
Trained batch 149 in epoch 2, gen_loss = -0.10312569085508586, disc_loss = 0.0033552839164622127
Trained batch 150 in epoch 2, gen_loss = -0.103349420642912, disc_loss = 0.0033414709491235827
Trained batch 151 in epoch 2, gen_loss = -0.10332206674655409, disc_loss = 0.003332308002618926
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = -0.1313086748123169, disc_loss = 0.002180636627599597
Trained batch 1 in epoch 3, gen_loss = -0.13164856284856796, disc_loss = 0.0020170968491584063
Trained batch 2 in epoch 3, gen_loss = -0.12728449950615564, disc_loss = 0.0018457685364410281
Trained batch 3 in epoch 3, gen_loss = -0.13542590104043484, disc_loss = 0.0017377035692334175
Trained batch 4 in epoch 3, gen_loss = -0.13579959124326707, disc_loss = 0.0017790741287171841
Trained batch 5 in epoch 3, gen_loss = -0.1460979071756204, disc_loss = 0.0019289834890514612
Trained batch 6 in epoch 3, gen_loss = -0.1441110298037529, disc_loss = 0.0023544618992933203
Trained batch 7 in epoch 3, gen_loss = -0.13744816184043884, disc_loss = 0.0024519890430383384
Trained batch 8 in epoch 3, gen_loss = -0.13874544368849862, disc_loss = 0.0023233470015434753
Trained batch 9 in epoch 3, gen_loss = -0.13740059435367585, disc_loss = 0.0022656234912574293
Trained batch 10 in epoch 3, gen_loss = -0.14090427620844406, disc_loss = 0.0022231199439953675
Trained batch 11 in epoch 3, gen_loss = -0.140208816776673, disc_loss = 0.0022032219955387213
Trained batch 12 in epoch 3, gen_loss = -0.14193938901791206, disc_loss = 0.0022085557441012217
Trained batch 13 in epoch 3, gen_loss = -0.14197541773319244, disc_loss = 0.002172616509986775
Trained batch 14 in epoch 3, gen_loss = -0.14461856782436372, disc_loss = 0.0021269794708738726
Trained batch 15 in epoch 3, gen_loss = -0.14346020761877298, disc_loss = 0.0020797941979253665
Trained batch 16 in epoch 3, gen_loss = -0.14441238431369557, disc_loss = 0.0020273884840528757
Trained batch 17 in epoch 3, gen_loss = -0.14520086265272564, disc_loss = 0.0019831054766351977
Trained batch 18 in epoch 3, gen_loss = -0.14686052971764615, disc_loss = 0.0020032745026248066
Trained batch 19 in epoch 3, gen_loss = -0.14673205837607384, disc_loss = 0.0020547110587358476
Trained batch 20 in epoch 3, gen_loss = -0.1476558737811588, disc_loss = 0.0020612036321489583
Trained batch 21 in epoch 3, gen_loss = -0.14793889156796716, disc_loss = 0.002043243984437802
Trained batch 22 in epoch 3, gen_loss = -0.1480152911466101, disc_loss = 0.002030267734485476
Trained batch 23 in epoch 3, gen_loss = -0.14982670918107033, disc_loss = 0.002043255565998455
Trained batch 24 in epoch 3, gen_loss = -0.15045231461524963, disc_loss = 0.0020443749241530894
Trained batch 25 in epoch 3, gen_loss = -0.15140249465520567, disc_loss = 0.00201857361333588
Trained batch 26 in epoch 3, gen_loss = -0.15054434096371686, disc_loss = 0.0020093913276300387
Trained batch 27 in epoch 3, gen_loss = -0.15017027141792433, disc_loss = 0.0019865629812037306
Trained batch 28 in epoch 3, gen_loss = -0.1499658160168549, disc_loss = 0.0019999328069388866
Trained batch 29 in epoch 3, gen_loss = -0.15090918491284053, disc_loss = 0.0020088423819591603
Trained batch 30 in epoch 3, gen_loss = -0.1509699239846199, disc_loss = 0.002021509673326246
Trained batch 31 in epoch 3, gen_loss = -0.15225784527137876, disc_loss = 0.002006660470215138
Trained batch 32 in epoch 3, gen_loss = -0.1515430568745642, disc_loss = 0.0019941916019006662
Trained batch 33 in epoch 3, gen_loss = -0.1519782915711403, disc_loss = 0.0020033460048794307
Trained batch 34 in epoch 3, gen_loss = -0.15214354949338096, disc_loss = 0.0019947389739432505
Trained batch 35 in epoch 3, gen_loss = -0.1520003481871552, disc_loss = 0.002033013151958585
Trained batch 36 in epoch 3, gen_loss = -0.15337579153679512, disc_loss = 0.0020239585318376084
Trained batch 37 in epoch 3, gen_loss = -0.15334378888732508, disc_loss = 0.0020471818279474974
Trained batch 38 in epoch 3, gen_loss = -0.15470595696033576, disc_loss = 0.0020721708901990685
Trained batch 39 in epoch 3, gen_loss = -0.15458658933639527, disc_loss = 0.002089270617580041
Trained batch 40 in epoch 3, gen_loss = -0.15496451244121645, disc_loss = 0.00208392299189255
Trained batch 41 in epoch 3, gen_loss = -0.1543508101077307, disc_loss = 0.002076543296598608
Trained batch 42 in epoch 3, gen_loss = -0.15374652937401173, disc_loss = 0.0020639642011807406
Trained batch 43 in epoch 3, gen_loss = -0.15335724705999548, disc_loss = 0.002051980441055176
Trained batch 44 in epoch 3, gen_loss = -0.15365219877825842, disc_loss = 0.002047401180283891
Trained batch 45 in epoch 3, gen_loss = -0.15505751287159714, disc_loss = 0.002042108999929674
Trained batch 46 in epoch 3, gen_loss = -0.1549548570145952, disc_loss = 0.0020416772855009805
Trained batch 47 in epoch 3, gen_loss = -0.1554004012917479, disc_loss = 0.002024835159924502
Trained batch 48 in epoch 3, gen_loss = -0.1550411998617406, disc_loss = 0.002015097812768452
Trained batch 49 in epoch 3, gen_loss = -0.15463597863912582, disc_loss = 0.002014156086370349
Trained batch 50 in epoch 3, gen_loss = -0.1553841160208571, disc_loss = 0.0020046243170166716
Trained batch 51 in epoch 3, gen_loss = -0.15528101101517677, disc_loss = 0.002016126693118937
Trained batch 52 in epoch 3, gen_loss = -0.1557898040650026, disc_loss = 0.0020355768018525166
Trained batch 53 in epoch 3, gen_loss = -0.15628471059931648, disc_loss = 0.00204802386428195
Trained batch 54 in epoch 3, gen_loss = -0.15687535405158998, disc_loss = 0.0020433422389694238
Trained batch 55 in epoch 3, gen_loss = -0.15665112169725554, disc_loss = 0.0020333208272599484
Trained batch 56 in epoch 3, gen_loss = -0.15754729849204682, disc_loss = 0.0020231310535516393
Trained batch 57 in epoch 3, gen_loss = -0.1581653318014638, disc_loss = 0.0020127984964096084
Trained batch 58 in epoch 3, gen_loss = -0.1583744269811501, disc_loss = 0.002007049899074738
Trained batch 59 in epoch 3, gen_loss = -0.1590437687933445, disc_loss = 0.0020096143047946195
Trained batch 60 in epoch 3, gen_loss = -0.15935341696270178, disc_loss = 0.0020129358640215435
Trained batch 61 in epoch 3, gen_loss = -0.15952083420368932, disc_loss = 0.002000626289255677
Trained batch 62 in epoch 3, gen_loss = -0.15929057342665537, disc_loss = 0.0020032251135460913
Trained batch 63 in epoch 3, gen_loss = -0.15919220657087862, disc_loss = 0.002052302865195088
Trained batch 64 in epoch 3, gen_loss = -0.15940802807991322, disc_loss = 0.0021297420446689313
Trained batch 65 in epoch 3, gen_loss = -0.15964730467760202, disc_loss = 0.0021664685724924007
Trained batch 66 in epoch 3, gen_loss = -0.15937663481306674, disc_loss = 0.0021673744864094614
Trained batch 67 in epoch 3, gen_loss = -0.15997356768040097, disc_loss = 0.002155940472970114
Trained batch 68 in epoch 3, gen_loss = -0.15978035935457202, disc_loss = 0.0021485542234006352
Trained batch 69 in epoch 3, gen_loss = -0.15926889117274964, disc_loss = 0.002151044972041356
Trained batch 70 in epoch 3, gen_loss = -0.15903721812745214, disc_loss = 0.0021444057019322483
Trained batch 71 in epoch 3, gen_loss = -0.15942423356076083, disc_loss = 0.002158570415405039
Trained batch 72 in epoch 3, gen_loss = -0.1598987681408451, disc_loss = 0.0021793217229184834
Trained batch 73 in epoch 3, gen_loss = -0.1593159971809065, disc_loss = 0.0022001878053226785
Trained batch 74 in epoch 3, gen_loss = -0.15984435011943182, disc_loss = 0.0022227637205893794
Trained batch 75 in epoch 3, gen_loss = -0.1598140441469456, disc_loss = 0.002222322333469301
Trained batch 76 in epoch 3, gen_loss = -0.1592444908115771, disc_loss = 0.0022143498985338714
Trained batch 77 in epoch 3, gen_loss = -0.1600098406466154, disc_loss = 0.0022242350387386978
Trained batch 78 in epoch 3, gen_loss = -0.16005891212556936, disc_loss = 0.002253323317434686
Trained batch 79 in epoch 3, gen_loss = -0.1601395790465176, disc_loss = 0.00226671092241304
Trained batch 80 in epoch 3, gen_loss = -0.15995223019961957, disc_loss = 0.0022689686487371353
Trained batch 81 in epoch 3, gen_loss = -0.1598988912272744, disc_loss = 0.002261440428655322
Trained batch 82 in epoch 3, gen_loss = -0.16014335340405084, disc_loss = 0.0022474280895149134
Trained batch 83 in epoch 3, gen_loss = -0.16045988803463324, disc_loss = 0.0022387070958280846
Trained batch 84 in epoch 3, gen_loss = -0.16070542782545089, disc_loss = 0.00223148708943935
Trained batch 85 in epoch 3, gen_loss = -0.1608757334219855, disc_loss = 0.002220715880718862
Trained batch 86 in epoch 3, gen_loss = -0.16069297843623434, disc_loss = 0.0022239525475935347
Trained batch 87 in epoch 3, gen_loss = -0.16116368914531035, disc_loss = 0.002223618003137579
Trained batch 88 in epoch 3, gen_loss = -0.1617140360595135, disc_loss = 0.00221374934261895
Trained batch 89 in epoch 3, gen_loss = -0.16148812017507022, disc_loss = 0.0022153135997036266
Trained batch 90 in epoch 3, gen_loss = -0.16187076655390498, disc_loss = 0.002227073224455855
Trained batch 91 in epoch 3, gen_loss = -0.16222578716342864, disc_loss = 0.0022281226461611527
Trained batch 92 in epoch 3, gen_loss = -0.16213696433972286, disc_loss = 0.002219124100050859
Trained batch 93 in epoch 3, gen_loss = -0.1620548629855856, disc_loss = 0.002206772180680344
Trained batch 94 in epoch 3, gen_loss = -0.16190960430785228, disc_loss = 0.002201879499970298
Trained batch 95 in epoch 3, gen_loss = -0.16207938835335275, disc_loss = 0.0021937785350019112
Trained batch 96 in epoch 3, gen_loss = -0.16262362981887207, disc_loss = 0.0021885576149083905
Trained batch 97 in epoch 3, gen_loss = -0.16257668704706796, disc_loss = 0.0021856073373263435
Trained batch 98 in epoch 3, gen_loss = -0.16314360537011213, disc_loss = 0.002174402986925961
Trained batch 99 in epoch 3, gen_loss = -0.16376968808472156, disc_loss = 0.002163261378882453
Trained batch 100 in epoch 3, gen_loss = -0.1640076820950697, disc_loss = 0.0021520237885599976
Trained batch 101 in epoch 3, gen_loss = -0.16452766684632675, disc_loss = 0.0021414983761953374
Trained batch 102 in epoch 3, gen_loss = -0.16465156684512072, disc_loss = 0.002131683668302535
Trained batch 103 in epoch 3, gen_loss = -0.16463648520696622, disc_loss = 0.002123211273171294
Trained batch 104 in epoch 3, gen_loss = -0.16530239163410096, disc_loss = 0.0021122010895938035
Trained batch 105 in epoch 3, gen_loss = -0.1654347672636779, disc_loss = 0.0021070104234034793
Trained batch 106 in epoch 3, gen_loss = -0.1658874851103141, disc_loss = 0.0021117941555828202
Trained batch 107 in epoch 3, gen_loss = -0.1661247697279409, disc_loss = 0.0021198737867288635
Trained batch 108 in epoch 3, gen_loss = -0.16658486938531245, disc_loss = 0.002120779507362002
Trained batch 109 in epoch 3, gen_loss = -0.1665058632465926, disc_loss = 0.0021245639056856323
Trained batch 110 in epoch 3, gen_loss = -0.16668974205448822, disc_loss = 0.0021207939643572244
Trained batch 111 in epoch 3, gen_loss = -0.16665080169747984, disc_loss = 0.002116485346570179
Trained batch 112 in epoch 3, gen_loss = -0.16680049639096303, disc_loss = 0.002109253102711575
Trained batch 113 in epoch 3, gen_loss = -0.1671107804173963, disc_loss = 0.002104096265260555
Trained batch 114 in epoch 3, gen_loss = -0.1672680626096933, disc_loss = 0.0020997687399832775
Trained batch 115 in epoch 3, gen_loss = -0.16735400098921924, disc_loss = 0.002100325702862204
Trained batch 116 in epoch 3, gen_loss = -0.16721234776270696, disc_loss = 0.0021049878793832264
Trained batch 117 in epoch 3, gen_loss = -0.16755488912685443, disc_loss = 0.0021072475676685255
Trained batch 118 in epoch 3, gen_loss = -0.16749267336450704, disc_loss = 0.00210088407063168
Trained batch 119 in epoch 3, gen_loss = -0.1680138853068153, disc_loss = 0.00209423285802283
Trained batch 120 in epoch 3, gen_loss = -0.16842504233614472, disc_loss = 0.002096768640355045
Trained batch 121 in epoch 3, gen_loss = -0.16853671380486646, disc_loss = 0.0021021278583650766
Trained batch 122 in epoch 3, gen_loss = -0.1683974902683157, disc_loss = 0.0021287793794275843
Trained batch 123 in epoch 3, gen_loss = -0.16816632035038165, disc_loss = 0.0021482807524960427
Trained batch 124 in epoch 3, gen_loss = -0.16804702991247178, disc_loss = 0.0021527883955277504
Trained batch 125 in epoch 3, gen_loss = -0.16837232057300824, disc_loss = 0.00214695673119942
Trained batch 126 in epoch 3, gen_loss = -0.16874453759803545, disc_loss = 0.00214241202196517
Trained batch 127 in epoch 3, gen_loss = -0.16899498255224898, disc_loss = 0.0021356034899326914
Trained batch 128 in epoch 3, gen_loss = -0.16909079698398133, disc_loss = 0.0021337208833523786
Trained batch 129 in epoch 3, gen_loss = -0.1695828708891685, disc_loss = 0.002134533488424495
Trained batch 130 in epoch 3, gen_loss = -0.16997551286721047, disc_loss = 0.0021500579860836326
Trained batch 131 in epoch 3, gen_loss = -0.16970949783695466, disc_loss = 0.002173469504641341
Trained batch 132 in epoch 3, gen_loss = -0.16994672033347583, disc_loss = 0.0021804488807587526
Trained batch 133 in epoch 3, gen_loss = -0.17011153770249282, disc_loss = 0.002177494612379945
Trained batch 134 in epoch 3, gen_loss = -0.17004082727211492, disc_loss = 0.002173277129056967
Trained batch 135 in epoch 3, gen_loss = -0.17038252933279557, disc_loss = 0.002167099445239942
Trained batch 136 in epoch 3, gen_loss = -0.17052135899336668, disc_loss = 0.0021611224850605713
Trained batch 137 in epoch 3, gen_loss = -0.17077934445030446, disc_loss = 0.002159527029278621
Trained batch 138 in epoch 3, gen_loss = -0.17112646991614816, disc_loss = 0.0021659958384857387
Trained batch 139 in epoch 3, gen_loss = -0.17167644537985324, disc_loss = 0.002177881612858203
Trained batch 140 in epoch 3, gen_loss = -0.17210689741880336, disc_loss = 0.0021835919193005362
Trained batch 141 in epoch 3, gen_loss = -0.17233299553184442, disc_loss = 0.0021800800078240236
Trained batch 142 in epoch 3, gen_loss = -0.1724546627252252, disc_loss = 0.0021796006969032953
Trained batch 143 in epoch 3, gen_loss = -0.17247380890573064, disc_loss = 0.0021765787334718173
Trained batch 144 in epoch 3, gen_loss = -0.17249695119158975, disc_loss = 0.0021716418447261998
Trained batch 145 in epoch 3, gen_loss = -0.17269365627267588, disc_loss = 0.0021714754318914132
Trained batch 146 in epoch 3, gen_loss = -0.1729910983418932, disc_loss = 0.0021740706874292066
Trained batch 147 in epoch 3, gen_loss = -0.1731937081125137, disc_loss = 0.0021770768008364766
Trained batch 148 in epoch 3, gen_loss = -0.1733908495747003, disc_loss = 0.0021731905282112527
Trained batch 149 in epoch 3, gen_loss = -0.17356275364756585, disc_loss = 0.0021667683237077046
Trained batch 150 in epoch 3, gen_loss = -0.17379078757486596, disc_loss = 0.0021628125085779125
Trained batch 151 in epoch 3, gen_loss = -0.1741338535457065, disc_loss = 0.0021571420484657496
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = -0.2174586057662964, disc_loss = 0.0014479283709079027
Trained batch 1 in epoch 4, gen_loss = -0.21460512280464172, disc_loss = 0.0016095199971459806
Trained batch 2 in epoch 4, gen_loss = -0.22273575266202292, disc_loss = 0.0017010328204681475
Trained batch 3 in epoch 4, gen_loss = -0.2220534235239029, disc_loss = 0.0015528029471170157
Trained batch 4 in epoch 4, gen_loss = -0.22394345402717591, disc_loss = 0.00149671898689121
Trained batch 5 in epoch 4, gen_loss = -0.2188952366511027, disc_loss = 0.0016124430306566258
Trained batch 6 in epoch 4, gen_loss = -0.21533686774117605, disc_loss = 0.0016522957843595318
Trained batch 7 in epoch 4, gen_loss = -0.21115590445697308, disc_loss = 0.0017132006032625213
Trained batch 8 in epoch 4, gen_loss = -0.21206527120537227, disc_loss = 0.001803252134575612
Trained batch 9 in epoch 4, gen_loss = -0.21218914836645125, disc_loss = 0.0018811415997333826
Trained batch 10 in epoch 4, gen_loss = -0.21107513389804147, disc_loss = 0.0019330700795928185
Trained batch 11 in epoch 4, gen_loss = -0.21001416320602098, disc_loss = 0.0020227640925440937
Trained batch 12 in epoch 4, gen_loss = -0.21126658412126395, disc_loss = 0.002180592721113219
Trained batch 13 in epoch 4, gen_loss = -0.2116173952817917, disc_loss = 0.002291099925059825
Trained batch 14 in epoch 4, gen_loss = -0.2106711784998576, disc_loss = 0.002244870737195015
Trained batch 15 in epoch 4, gen_loss = -0.20727963745594025, disc_loss = 0.0021989928500261158
Trained batch 16 in epoch 4, gen_loss = -0.20491121095769546, disc_loss = 0.002173825824523673
Trained batch 17 in epoch 4, gen_loss = -0.20592791338761648, disc_loss = 0.00217837604901029
Trained batch 18 in epoch 4, gen_loss = -0.20688137333644063, disc_loss = 0.002184773966866104
Trained batch 19 in epoch 4, gen_loss = -0.2088657386600971, disc_loss = 0.002163823146838695
Trained batch 20 in epoch 4, gen_loss = -0.20768476596900395, disc_loss = 0.0021434194031393246
Trained batch 21 in epoch 4, gen_loss = -0.2063961388035254, disc_loss = 0.00225336154372516
Trained batch 22 in epoch 4, gen_loss = -0.20721174323040506, disc_loss = 0.00239909115328413
Trained batch 23 in epoch 4, gen_loss = -0.2067194121579329, disc_loss = 0.0025030386459548026
Trained batch 24 in epoch 4, gen_loss = -0.2080177855491638, disc_loss = 0.002474220050498843
Trained batch 25 in epoch 4, gen_loss = -0.2101383633338488, disc_loss = 0.002429779175704775
Trained batch 26 in epoch 4, gen_loss = -0.20964014419802912, disc_loss = 0.0023898179168571477
Trained batch 27 in epoch 4, gen_loss = -0.2112110640321459, disc_loss = 0.002347965055378154
Trained batch 28 in epoch 4, gen_loss = -0.21137851271136054, disc_loss = 0.0022986557310575553
Trained batch 29 in epoch 4, gen_loss = -0.21137657910585403, disc_loss = 0.0022538531261185805
Trained batch 30 in epoch 4, gen_loss = -0.21142779579085688, disc_loss = 0.002225711295801786
Trained batch 31 in epoch 4, gen_loss = -0.21308984095230699, disc_loss = 0.0022155423685035203
Trained batch 32 in epoch 4, gen_loss = -0.21234985869942288, disc_loss = 0.0022066583553554883
Trained batch 33 in epoch 4, gen_loss = -0.21327041790765874, disc_loss = 0.0022152178982437097
Trained batch 34 in epoch 4, gen_loss = -0.21408855489322118, disc_loss = 0.0022071889867740016
Trained batch 35 in epoch 4, gen_loss = -0.21396073698997498, disc_loss = 0.0021973236127653057
Trained batch 36 in epoch 4, gen_loss = -0.21538337823506948, disc_loss = 0.002171874763695775
Trained batch 37 in epoch 4, gen_loss = -0.21604432047981964, disc_loss = 0.0021550646266213767
Trained batch 38 in epoch 4, gen_loss = -0.2152299456871473, disc_loss = 0.0021525152499238267
Trained batch 39 in epoch 4, gen_loss = -0.21384056694805623, disc_loss = 0.0021521748945815488
Trained batch 40 in epoch 4, gen_loss = -0.21403657554126368, disc_loss = 0.002144773286290285
Trained batch 41 in epoch 4, gen_loss = -0.21499005137454896, disc_loss = 0.002127526993198054
Trained batch 42 in epoch 4, gen_loss = -0.21616879625375882, disc_loss = 0.0021048594471933537
Trained batch 43 in epoch 4, gen_loss = -0.2165214219553904, disc_loss = 0.0020982883632479406
Trained batch 44 in epoch 4, gen_loss = -0.21630966564019521, disc_loss = 0.0020894897817116645
Trained batch 45 in epoch 4, gen_loss = -0.21697191667297613, disc_loss = 0.002067018998786807
Trained batch 46 in epoch 4, gen_loss = -0.216337447787853, disc_loss = 0.002045800527954038
Trained batch 47 in epoch 4, gen_loss = -0.21697418919454017, disc_loss = 0.0020288864810330174
Trained batch 48 in epoch 4, gen_loss = -0.21786626960550035, disc_loss = 0.0020070911256824526
Trained batch 49 in epoch 4, gen_loss = -0.21800813257694243, disc_loss = 0.001987426809500903
Trained batch 50 in epoch 4, gen_loss = -0.217751799845228, disc_loss = 0.001980806776212857
Trained batch 51 in epoch 4, gen_loss = -0.21838976729374665, disc_loss = 0.0019846720500096967
Trained batch 52 in epoch 4, gen_loss = -0.2189432554087549, disc_loss = 0.001982136822815211
Trained batch 53 in epoch 4, gen_loss = -0.21935633404387367, disc_loss = 0.0019664217554101787
Trained batch 54 in epoch 4, gen_loss = -0.22009552961046044, disc_loss = 0.001949773318218914
Trained batch 55 in epoch 4, gen_loss = -0.21972062891083105, disc_loss = 0.0019408450129308871
Trained batch 56 in epoch 4, gen_loss = -0.220661045427908, disc_loss = 0.001925215268050108
Trained batch 57 in epoch 4, gen_loss = -0.22132437573424701, disc_loss = 0.0019311610697608057
Trained batch 58 in epoch 4, gen_loss = -0.22074486391019013, disc_loss = 0.0019483807441478564
Trained batch 59 in epoch 4, gen_loss = -0.22108937328060468, disc_loss = 0.0019476811517961322
Trained batch 60 in epoch 4, gen_loss = -0.22089718502075945, disc_loss = 0.0019431711311955922
Trained batch 61 in epoch 4, gen_loss = -0.22111765775949724, disc_loss = 0.0019483931903396883
Trained batch 62 in epoch 4, gen_loss = -0.2205168933622421, disc_loss = 0.001962369703318155
Trained batch 63 in epoch 4, gen_loss = -0.22103630448691547, disc_loss = 0.001969848988665035
Trained batch 64 in epoch 4, gen_loss = -0.22123412375266735, disc_loss = 0.001961419330193446
Trained batch 65 in epoch 4, gen_loss = -0.22212891529003778, disc_loss = 0.0019427563264881346
Trained batch 66 in epoch 4, gen_loss = -0.22141848104213602, disc_loss = 0.0019357738627204255
Trained batch 67 in epoch 4, gen_loss = -0.22084018982508602, disc_loss = 0.0019370870740043327
Trained batch 68 in epoch 4, gen_loss = -0.2208662646404211, disc_loss = 0.001924239147953905
Trained batch 69 in epoch 4, gen_loss = -0.22124188201768058, disc_loss = 0.001917042228991964
Trained batch 70 in epoch 4, gen_loss = -0.2211981321304617, disc_loss = 0.0019234769508688593
Trained batch 71 in epoch 4, gen_loss = -0.22099088587694699, disc_loss = 0.001922281024033307
Trained batch 72 in epoch 4, gen_loss = -0.22135394260491412, disc_loss = 0.0019151506090715324
Trained batch 73 in epoch 4, gen_loss = -0.22177263470114889, disc_loss = 0.0019036362362975204
Trained batch 74 in epoch 4, gen_loss = -0.22235547761122385, disc_loss = 0.0018916900952657065
Trained batch 75 in epoch 4, gen_loss = -0.2228134405848227, disc_loss = 0.0018836595608215582
Trained batch 76 in epoch 4, gen_loss = -0.22366938285239332, disc_loss = 0.0018727335105226798
Trained batch 77 in epoch 4, gen_loss = -0.22365171252152857, disc_loss = 0.0018637416920123191
Trained batch 78 in epoch 4, gen_loss = -0.2240115057064008, disc_loss = 0.0018577464366968297
Trained batch 79 in epoch 4, gen_loss = -0.2245485633611679, disc_loss = 0.0018522233498515562
Trained batch 80 in epoch 4, gen_loss = -0.22451464077572764, disc_loss = 0.001846024742131524
Trained batch 81 in epoch 4, gen_loss = -0.22487479121219822, disc_loss = 0.0018357465245261242
Trained batch 82 in epoch 4, gen_loss = -0.2249278124556484, disc_loss = 0.0018309043560468827
Trained batch 83 in epoch 4, gen_loss = -0.22581636550880613, disc_loss = 0.0018390174054296775
Trained batch 84 in epoch 4, gen_loss = -0.225989089643254, disc_loss = 0.0018501656527137931
Trained batch 85 in epoch 4, gen_loss = -0.22624738860962001, disc_loss = 0.0018491469388611096
Trained batch 86 in epoch 4, gen_loss = -0.2263321465459363, disc_loss = 0.0018458187596165929
Trained batch 87 in epoch 4, gen_loss = -0.2260311758992347, disc_loss = 0.0018444005836499855
Trained batch 88 in epoch 4, gen_loss = -0.2253873621144991, disc_loss = 0.001843120401798423
Trained batch 89 in epoch 4, gen_loss = -0.22534790982802708, disc_loss = 0.0018465084398889707
Trained batch 90 in epoch 4, gen_loss = -0.22548972577839108, disc_loss = 0.001850882822719331
Trained batch 91 in epoch 4, gen_loss = -0.2255616171852402, disc_loss = 0.0018514385611406
Trained batch 92 in epoch 4, gen_loss = -0.22525023340537983, disc_loss = 0.001856707368216287
Trained batch 93 in epoch 4, gen_loss = -0.22546177341582926, disc_loss = 0.0018697731962249158
Trained batch 94 in epoch 4, gen_loss = -0.226021114776009, disc_loss = 0.0018808160724706556
Trained batch 95 in epoch 4, gen_loss = -0.22620003034050265, disc_loss = 0.0018771534002250216
Trained batch 96 in epoch 4, gen_loss = -0.22666024193935788, disc_loss = 0.0018738265300515232
Trained batch 97 in epoch 4, gen_loss = -0.22589912113486504, disc_loss = 0.0018704799906711798
Trained batch 98 in epoch 4, gen_loss = -0.22605714186875506, disc_loss = 0.0018607513083032136
Trained batch 99 in epoch 4, gen_loss = -0.22605276122689247, disc_loss = 0.0018539670400787144
Trained batch 100 in epoch 4, gen_loss = -0.22625692601841274, disc_loss = 0.00184505650805918
Trained batch 101 in epoch 4, gen_loss = -0.2265478227944935, disc_loss = 0.0018340986548448163
Trained batch 102 in epoch 4, gen_loss = -0.2264470473944562, disc_loss = 0.0018265621490252105
Trained batch 103 in epoch 4, gen_loss = -0.22651067476433057, disc_loss = 0.001819610878905783
Trained batch 104 in epoch 4, gen_loss = -0.22673677702744802, disc_loss = 0.0018172811240046507
Trained batch 105 in epoch 4, gen_loss = -0.2271202896844666, disc_loss = 0.0018126054036536447
Trained batch 106 in epoch 4, gen_loss = -0.2275606860345769, disc_loss = 0.00180399040615395
Trained batch 107 in epoch 4, gen_loss = -0.22798072643302106, disc_loss = 0.0018011392185818059
Trained batch 108 in epoch 4, gen_loss = -0.22808749645674994, disc_loss = 0.0018013028247461339
Trained batch 109 in epoch 4, gen_loss = -0.2282387282360684, disc_loss = 0.0018003755730619147
Trained batch 110 in epoch 4, gen_loss = -0.22855010373635334, disc_loss = 0.001795683524399358
Trained batch 111 in epoch 4, gen_loss = -0.2285356731819255, disc_loss = 0.0017988391487701197
Trained batch 112 in epoch 4, gen_loss = -0.2284179833610501, disc_loss = 0.0018025501533329026
Trained batch 113 in epoch 4, gen_loss = -0.22847692171732584, disc_loss = 0.0018048625579308065
Trained batch 114 in epoch 4, gen_loss = -0.22889259276182755, disc_loss = 0.0018019447513127132
Trained batch 115 in epoch 4, gen_loss = -0.2293711543597024, disc_loss = 0.0018012254977606815
Trained batch 116 in epoch 4, gen_loss = -0.22927943381488833, disc_loss = 0.0018031414380320944
Trained batch 117 in epoch 4, gen_loss = -0.22892789163831936, disc_loss = 0.001809993185106886
Trained batch 118 in epoch 4, gen_loss = -0.22965280974612517, disc_loss = 0.0018381615812076302
Trained batch 119 in epoch 4, gen_loss = -0.22999382068713506, disc_loss = 0.0018759161917841992
Trained batch 120 in epoch 4, gen_loss = -0.23038811673802778, disc_loss = 0.0019031979537122567
Trained batch 121 in epoch 4, gen_loss = -0.2308792352187829, disc_loss = 0.0019038017389753864
Trained batch 122 in epoch 4, gen_loss = -0.23154808205317676, disc_loss = 0.0018982063478229915
Trained batch 123 in epoch 4, gen_loss = -0.23163605745761626, disc_loss = 0.0018930008654640387
Trained batch 124 in epoch 4, gen_loss = -0.2315920853614807, disc_loss = 0.0018891949360258877
Trained batch 125 in epoch 4, gen_loss = -0.23181769488349793, disc_loss = 0.0018807557621224236
Trained batch 126 in epoch 4, gen_loss = -0.23166217226681746, disc_loss = 0.0018741773944678092
Trained batch 127 in epoch 4, gen_loss = -0.23184061446227133, disc_loss = 0.0018698607350415841
Trained batch 128 in epoch 4, gen_loss = -0.23199148210444193, disc_loss = 0.0018641294206694751
Trained batch 129 in epoch 4, gen_loss = -0.23242065287553348, disc_loss = 0.0018589342921936454
Trained batch 130 in epoch 4, gen_loss = -0.2327675264300281, disc_loss = 0.001853871132151174
Trained batch 131 in epoch 4, gen_loss = -0.2329437199867133, disc_loss = 0.0018477880675522047
Trained batch 132 in epoch 4, gen_loss = -0.23305357970241317, disc_loss = 0.0018411960633982786
Trained batch 133 in epoch 4, gen_loss = -0.23342374890153086, disc_loss = 0.0018331105877304756
Trained batch 134 in epoch 4, gen_loss = -0.2335547247418651, disc_loss = 0.001825887580074508
Trained batch 135 in epoch 4, gen_loss = -0.23409094124594154, disc_loss = 0.0018196825211121263
Trained batch 136 in epoch 4, gen_loss = -0.23388498727857632, disc_loss = 0.0018149060991687878
Trained batch 137 in epoch 4, gen_loss = -0.23398560415143552, disc_loss = 0.0018113695192184516
Trained batch 138 in epoch 4, gen_loss = -0.23356414891833024, disc_loss = 0.0018234417766245525
Trained batch 139 in epoch 4, gen_loss = -0.2338736517088754, disc_loss = 0.00184293450646302
Trained batch 140 in epoch 4, gen_loss = -0.2342028355767541, disc_loss = 0.0018483423904502594
Trained batch 141 in epoch 4, gen_loss = -0.23386094204976526, disc_loss = 0.0018462253751685765
Trained batch 142 in epoch 4, gen_loss = -0.2340026752098457, disc_loss = 0.0018440370738564932
Trained batch 143 in epoch 4, gen_loss = -0.23431934933695528, disc_loss = 0.0018371581467767505
Trained batch 144 in epoch 4, gen_loss = -0.2344025058992978, disc_loss = 0.0018328959094199898
Trained batch 145 in epoch 4, gen_loss = -0.23431245033463385, disc_loss = 0.001837372879118161
Trained batch 146 in epoch 4, gen_loss = -0.23427152684351213, disc_loss = 0.0018407370990972181
Trained batch 147 in epoch 4, gen_loss = -0.2344713667155923, disc_loss = 0.0018358290501448602
Trained batch 148 in epoch 4, gen_loss = -0.23428924501742293, disc_loss = 0.0018302502275457067
Trained batch 149 in epoch 4, gen_loss = -0.23440412372350694, disc_loss = 0.0018253450029684852
Trained batch 150 in epoch 4, gen_loss = -0.2347423837871741, disc_loss = 0.0018250494497667824
Trained batch 151 in epoch 4, gen_loss = -0.23481979132875017, disc_loss = 0.0018179644030169584
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = -0.22376488149166107, disc_loss = 0.001548691769130528
Trained batch 1 in epoch 5, gen_loss = -0.25526272505521774, disc_loss = 0.0015260048094205558
Trained batch 2 in epoch 5, gen_loss = -0.2691694150368373, disc_loss = 0.0016074183319384854
Trained batch 3 in epoch 5, gen_loss = -0.26996614411473274, disc_loss = 0.0017851608281489462
Trained batch 4 in epoch 5, gen_loss = -0.26589275598526, disc_loss = 0.001902864477597177
Trained batch 5 in epoch 5, gen_loss = -0.26266857981681824, disc_loss = 0.0018861605203710496
Trained batch 6 in epoch 5, gen_loss = -0.2599786307130541, disc_loss = 0.0017968965860615884
Trained batch 7 in epoch 5, gen_loss = -0.2674798481166363, disc_loss = 0.0017187721678055823
Trained batch 8 in epoch 5, gen_loss = -0.26500334011183846, disc_loss = 0.0016547381593328384
Trained batch 9 in epoch 5, gen_loss = -0.26361019909381866, disc_loss = 0.0016001556534320116
Trained batch 10 in epoch 5, gen_loss = -0.262531426819888, disc_loss = 0.001523649155966599
Trained batch 11 in epoch 5, gen_loss = -0.263629508515199, disc_loss = 0.0015150026738410816
Trained batch 12 in epoch 5, gen_loss = -0.26272172882006717, disc_loss = 0.0015111143763463658
Trained batch 13 in epoch 5, gen_loss = -0.26282472695623127, disc_loss = 0.0014669062760991178
Trained batch 14 in epoch 5, gen_loss = -0.2625060260295868, disc_loss = 0.0014370919787324965
Trained batch 15 in epoch 5, gen_loss = -0.2610216401517391, disc_loss = 0.0014709389906784054
Trained batch 16 in epoch 5, gen_loss = -0.2627771619488211, disc_loss = 0.0015207961276995346
Trained batch 17 in epoch 5, gen_loss = -0.2605403835574786, disc_loss = 0.001535993816408639
Trained batch 18 in epoch 5, gen_loss = -0.2634810091633546, disc_loss = 0.0015032463890843485
Trained batch 19 in epoch 5, gen_loss = -0.26303965523838996, disc_loss = 0.0014730926515767351
Trained batch 20 in epoch 5, gen_loss = -0.26377016660713015, disc_loss = 0.0014487511084769807
Trained batch 21 in epoch 5, gen_loss = -0.2655296657573093, disc_loss = 0.0014230417489836161
Trained batch 22 in epoch 5, gen_loss = -0.2663544772759728, disc_loss = 0.001419202713093356
Trained batch 23 in epoch 5, gen_loss = -0.2658692418287198, disc_loss = 0.0014225334792475526
Trained batch 24 in epoch 5, gen_loss = -0.2671653562784195, disc_loss = 0.0014083360834047198
Trained batch 25 in epoch 5, gen_loss = -0.26904982844224345, disc_loss = 0.001411112397013662
Trained batch 26 in epoch 5, gen_loss = -0.2705821610159344, disc_loss = 0.0014214259098042493
Trained batch 27 in epoch 5, gen_loss = -0.26850665946091923, disc_loss = 0.0014399819026168967
Trained batch 28 in epoch 5, gen_loss = -0.26906164298797475, disc_loss = 0.001426169761167518
Trained batch 29 in epoch 5, gen_loss = -0.26928935597340264, disc_loss = 0.0014167001470923423
Trained batch 30 in epoch 5, gen_loss = -0.26868143148960605, disc_loss = 0.0014156458538866813
Trained batch 31 in epoch 5, gen_loss = -0.26956558180972934, disc_loss = 0.001403911770466948
Trained batch 32 in epoch 5, gen_loss = -0.2699632414362647, disc_loss = 0.0013888983451055758
Trained batch 33 in epoch 5, gen_loss = -0.26957768420962724, disc_loss = 0.0013745103257379548
Trained batch 34 in epoch 5, gen_loss = -0.26845900842121667, disc_loss = 0.0013671620582629527
Trained batch 35 in epoch 5, gen_loss = -0.268777084019449, disc_loss = 0.0013572019524872303
Trained batch 36 in epoch 5, gen_loss = -0.26978261728544495, disc_loss = 0.0013543291181023862
Trained batch 37 in epoch 5, gen_loss = -0.2683893614693692, disc_loss = 0.0013445651305741386
Trained batch 38 in epoch 5, gen_loss = -0.26743786113384443, disc_loss = 0.001325428776908666
Trained batch 39 in epoch 5, gen_loss = -0.26661847792565824, disc_loss = 0.0013168382618459872
Trained batch 40 in epoch 5, gen_loss = -0.26703688684033183, disc_loss = 0.0013122411839459546
Trained batch 41 in epoch 5, gen_loss = -0.2669271063946542, disc_loss = 0.0013010864869491862
Trained batch 42 in epoch 5, gen_loss = -0.26756483489690824, disc_loss = 0.0012851433441324464
Trained batch 43 in epoch 5, gen_loss = -0.26776707951318135, disc_loss = 0.0012829537723022936
Trained batch 44 in epoch 5, gen_loss = -0.2689556688070297, disc_loss = 0.001306918908893648
Trained batch 45 in epoch 5, gen_loss = -0.2703902776474538, disc_loss = 0.0013214956966491984
Trained batch 46 in epoch 5, gen_loss = -0.27006359334955826, disc_loss = 0.001318424718424757
Trained batch 47 in epoch 5, gen_loss = -0.2702727320914467, disc_loss = 0.0013046400005502317
Trained batch 48 in epoch 5, gen_loss = -0.27127976472280463, disc_loss = 0.0012970958095119924
Trained batch 49 in epoch 5, gen_loss = -0.2719766536355019, disc_loss = 0.001291886419057846
Trained batch 50 in epoch 5, gen_loss = -0.27236659182052986, disc_loss = 0.0012906698930058994
Trained batch 51 in epoch 5, gen_loss = -0.2728721467921367, disc_loss = 0.0012850736652930768
Trained batch 52 in epoch 5, gen_loss = -0.2718130094262789, disc_loss = 0.0012839948385075298
Trained batch 53 in epoch 5, gen_loss = -0.27298730749774863, disc_loss = 0.0012997677786862132
Trained batch 54 in epoch 5, gen_loss = -0.272508184205402, disc_loss = 0.0013157363113185223
Trained batch 55 in epoch 5, gen_loss = -0.2732425675328289, disc_loss = 0.0013126428530085832
Trained batch 56 in epoch 5, gen_loss = -0.2732470189793068, disc_loss = 0.001302248986209171
Trained batch 57 in epoch 5, gen_loss = -0.27367641314350327, disc_loss = 0.0012945086627010383
Trained batch 58 in epoch 5, gen_loss = -0.27420673355207603, disc_loss = 0.0012883307546440322
Trained batch 59 in epoch 5, gen_loss = -0.27519829496741294, disc_loss = 0.0012887382220166425
Trained batch 60 in epoch 5, gen_loss = -0.275145665299697, disc_loss = 0.0012916195336118584
Trained batch 61 in epoch 5, gen_loss = -0.27526635965031965, disc_loss = 0.00129589174062975
Trained batch 62 in epoch 5, gen_loss = -0.27532006137900883, disc_loss = 0.0013085581170069792
Trained batch 63 in epoch 5, gen_loss = -0.2755213084165007, disc_loss = 0.001300572959735291
Trained batch 64 in epoch 5, gen_loss = -0.2755810721562459, disc_loss = 0.0012949397518801002
Trained batch 65 in epoch 5, gen_loss = -0.2755005632837613, disc_loss = 0.0012886888262900438
Trained batch 66 in epoch 5, gen_loss = -0.2759000696797869, disc_loss = 0.0012838997349921446
Trained batch 67 in epoch 5, gen_loss = -0.2761959514635451, disc_loss = 0.0012786315055564046
Trained batch 68 in epoch 5, gen_loss = -0.2763274219157039, disc_loss = 0.001273648565351639
Trained batch 69 in epoch 5, gen_loss = -0.275849164383752, disc_loss = 0.0012738484240669226
Trained batch 70 in epoch 5, gen_loss = -0.2762622438685995, disc_loss = 0.0012673170512384722
Trained batch 71 in epoch 5, gen_loss = -0.27638232294056153, disc_loss = 0.0012646581114192184
Trained batch 72 in epoch 5, gen_loss = -0.2766210755256757, disc_loss = 0.0012701543044834718
Trained batch 73 in epoch 5, gen_loss = -0.2771818694230673, disc_loss = 0.0012758724262459658
Trained batch 74 in epoch 5, gen_loss = -0.277668578227361, disc_loss = 0.0012770147093882163
Trained batch 75 in epoch 5, gen_loss = -0.2784339848317598, disc_loss = 0.0012765854924892712
Trained batch 76 in epoch 5, gen_loss = -0.27860271079199656, disc_loss = 0.0012722823726521297
Trained batch 77 in epoch 5, gen_loss = -0.2789949881724822, disc_loss = 0.0012627025672162955
Trained batch 78 in epoch 5, gen_loss = -0.2793541852431961, disc_loss = 0.0012605397938455962
Trained batch 79 in epoch 5, gen_loss = -0.27955480515956876, disc_loss = 0.0012683136737905443
Trained batch 80 in epoch 5, gen_loss = -0.2799762546280284, disc_loss = 0.0012926196932424735
Trained batch 81 in epoch 5, gen_loss = -0.28080872319093564, disc_loss = 0.001311077208190066
Trained batch 82 in epoch 5, gen_loss = -0.28035474864833326, disc_loss = 0.0013100233725664846
Trained batch 83 in epoch 5, gen_loss = -0.2803592046811467, disc_loss = 0.0013064107389211478
Trained batch 84 in epoch 5, gen_loss = -0.28082721513860365, disc_loss = 0.0013063492924522827
Trained batch 85 in epoch 5, gen_loss = -0.28103272339632346, disc_loss = 0.0013152507612979863
Trained batch 86 in epoch 5, gen_loss = -0.28107319241282586, disc_loss = 0.0013298279399737373
Trained batch 87 in epoch 5, gen_loss = -0.2812962518496947, disc_loss = 0.0013460376477186483
Trained batch 88 in epoch 5, gen_loss = -0.28140196806929085, disc_loss = 0.0013618797097836486
Trained batch 89 in epoch 5, gen_loss = -0.28172732293605807, disc_loss = 0.0013724793175545831
Trained batch 90 in epoch 5, gen_loss = -0.281428656407765, disc_loss = 0.0013752885733393358
Trained batch 91 in epoch 5, gen_loss = -0.2814014440645342, disc_loss = 0.0013711512045752581
Trained batch 92 in epoch 5, gen_loss = -0.281326630743601, disc_loss = 0.0013674433638531996
Trained batch 93 in epoch 5, gen_loss = -0.28090573847293854, disc_loss = 0.0013703153855068252
Trained batch 94 in epoch 5, gen_loss = -0.28079656707613093, disc_loss = 0.001381440916539807
Trained batch 95 in epoch 5, gen_loss = -0.28112630794445675, disc_loss = 0.001403659562735508
Trained batch 96 in epoch 5, gen_loss = -0.2810959600910698, disc_loss = 0.0014217535523486505
Trained batch 97 in epoch 5, gen_loss = -0.2811728648993434, disc_loss = 0.001425891197571645
Trained batch 98 in epoch 5, gen_loss = -0.28182767647685425, disc_loss = 0.001422539809624655
Trained batch 99 in epoch 5, gen_loss = -0.2822325477004051, disc_loss = 0.0014167111169081181
Trained batch 100 in epoch 5, gen_loss = -0.2823193161794455, disc_loss = 0.0014166914348462873
Trained batch 101 in epoch 5, gen_loss = -0.2828374601462308, disc_loss = 0.0014165037313896213
Trained batch 102 in epoch 5, gen_loss = -0.282972104630424, disc_loss = 0.0014151155799446466
Trained batch 103 in epoch 5, gen_loss = -0.2828214790385503, disc_loss = 0.0014140188107446122
Trained batch 104 in epoch 5, gen_loss = -0.2827250883692787, disc_loss = 0.001408896616305269
Trained batch 105 in epoch 5, gen_loss = -0.28223501314532085, disc_loss = 0.00140505025321442
Trained batch 106 in epoch 5, gen_loss = -0.2823300915900792, disc_loss = 0.0014015567101642629
Trained batch 107 in epoch 5, gen_loss = -0.28263378474447465, disc_loss = 0.0014026158648819008
Trained batch 108 in epoch 5, gen_loss = -0.28270001996547806, disc_loss = 0.001398266065617972
Trained batch 109 in epoch 5, gen_loss = -0.282714813134887, disc_loss = 0.001397923038298772
Trained batch 110 in epoch 5, gen_loss = -0.2825976451774975, disc_loss = 0.001395799182900773
Trained batch 111 in epoch 5, gen_loss = -0.28295573725232054, disc_loss = 0.0014031162603974476
Trained batch 112 in epoch 5, gen_loss = -0.28297271612471186, disc_loss = 0.0014213223795332345
Trained batch 113 in epoch 5, gen_loss = -0.2832610029400441, disc_loss = 0.0014391487041537307
Trained batch 114 in epoch 5, gen_loss = -0.2835077423116435, disc_loss = 0.001457583591463449
Trained batch 115 in epoch 5, gen_loss = -0.28341733124749413, disc_loss = 0.0014655832411994323
Trained batch 116 in epoch 5, gen_loss = -0.2839458513463664, disc_loss = 0.001464025592073225
Trained batch 117 in epoch 5, gen_loss = -0.2837911634627035, disc_loss = 0.0014668547605574762
Trained batch 118 in epoch 5, gen_loss = -0.2843578390213622, disc_loss = 0.0014648256674721963
Trained batch 119 in epoch 5, gen_loss = -0.28432547276218734, disc_loss = 0.0014667459579262262
Trained batch 120 in epoch 5, gen_loss = -0.28419097519117936, disc_loss = 0.0014655544472596616
Trained batch 121 in epoch 5, gen_loss = -0.284186986870453, disc_loss = 0.001459819329120066
Trained batch 122 in epoch 5, gen_loss = -0.2842849519679217, disc_loss = 0.0014539228650983574
Trained batch 123 in epoch 5, gen_loss = -0.28423962694021965, disc_loss = 0.0014539764825096954
Trained batch 124 in epoch 5, gen_loss = -0.28406283068656923, disc_loss = 0.0014656762103550135
Trained batch 125 in epoch 5, gen_loss = -0.2840730008624849, disc_loss = 0.0014922292639745311
Trained batch 126 in epoch 5, gen_loss = -0.2842658190276679, disc_loss = 0.0015271133958640706
Trained batch 127 in epoch 5, gen_loss = -0.2844306130427867, disc_loss = 0.0015572398983749736
Trained batch 128 in epoch 5, gen_loss = -0.28462318463843, disc_loss = 0.001575342425986287
Trained batch 129 in epoch 5, gen_loss = -0.2848808079957962, disc_loss = 0.0015759714597012274
Trained batch 130 in epoch 5, gen_loss = -0.28520925672909686, disc_loss = 0.001573813083414557
Trained batch 131 in epoch 5, gen_loss = -0.28502866129080456, disc_loss = 0.0015679673176209415
Trained batch 132 in epoch 5, gen_loss = -0.28472620226386797, disc_loss = 0.001567591739296773
Trained batch 133 in epoch 5, gen_loss = -0.2848535389152925, disc_loss = 0.0015626716138204253
Trained batch 134 in epoch 5, gen_loss = -0.2851506325933668, disc_loss = 0.0015576220130444401
Trained batch 135 in epoch 5, gen_loss = -0.28551684451453824, disc_loss = 0.001557952973919729
Trained batch 136 in epoch 5, gen_loss = -0.28580571874214783, disc_loss = 0.0015605220492133857
Trained batch 137 in epoch 5, gen_loss = -0.28602779732234235, disc_loss = 0.0015614839946425966
Trained batch 138 in epoch 5, gen_loss = -0.28618752699104144, disc_loss = 0.0015576742786290996
Trained batch 139 in epoch 5, gen_loss = -0.28681909761258534, disc_loss = 0.0015520210527548834
Trained batch 140 in epoch 5, gen_loss = -0.28728079246291033, disc_loss = 0.0015451612177219058
Trained batch 141 in epoch 5, gen_loss = -0.28755923245154635, disc_loss = 0.0015393999654432417
Trained batch 142 in epoch 5, gen_loss = -0.28767325098697955, disc_loss = 0.0015335372902316178
Trained batch 143 in epoch 5, gen_loss = -0.28776245771182907, disc_loss = 0.00152752905341913
Trained batch 144 in epoch 5, gen_loss = -0.28821859380294534, disc_loss = 0.0015213465414427479
Trained batch 145 in epoch 5, gen_loss = -0.28865796143878, disc_loss = 0.0015163089464456864
Trained batch 146 in epoch 5, gen_loss = -0.2885831160610225, disc_loss = 0.0015129624188047687
Trained batch 147 in epoch 5, gen_loss = -0.28893267907000875, disc_loss = 0.0015114413958193886
Trained batch 148 in epoch 5, gen_loss = -0.28887171473279094, disc_loss = 0.0015106458941962094
Trained batch 149 in epoch 5, gen_loss = -0.2891607244809469, disc_loss = 0.0015110403764992952
Trained batch 150 in epoch 5, gen_loss = -0.28923268823434184, disc_loss = 0.001514232779131425
Trained batch 151 in epoch 5, gen_loss = -0.28915270359108325, disc_loss = 0.0015144778360416623
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = -0.33995407819747925, disc_loss = 0.0010426435619592667
Trained batch 1 in epoch 6, gen_loss = -0.3541743755340576, disc_loss = 0.0009389466722495854
Trained batch 2 in epoch 6, gen_loss = -0.3511260648568471, disc_loss = 0.0010044676018878818
Trained batch 3 in epoch 6, gen_loss = -0.33917615562677383, disc_loss = 0.0009754900966072455
Trained batch 4 in epoch 6, gen_loss = -0.3370476305484772, disc_loss = 0.000917158683296293
Trained batch 5 in epoch 6, gen_loss = -0.3404598881800969, disc_loss = 0.0008661107470591863
Trained batch 6 in epoch 6, gen_loss = -0.3363006966454642, disc_loss = 0.0008448655384459666
Trained batch 7 in epoch 6, gen_loss = -0.3354220986366272, disc_loss = 0.0008075458681560121
Trained batch 8 in epoch 6, gen_loss = -0.3324766920672523, disc_loss = 0.0008794357935484084
Trained batch 9 in epoch 6, gen_loss = -0.32656440138816833, disc_loss = 0.0010152599250432103
Trained batch 10 in epoch 6, gen_loss = -0.32500300624153833, disc_loss = 0.0011682923914949324
Trained batch 11 in epoch 6, gen_loss = -0.3208458125591278, disc_loss = 0.001353187481678712
Trained batch 12 in epoch 6, gen_loss = -0.32066748233941883, disc_loss = 0.0014931387402332174
Trained batch 13 in epoch 6, gen_loss = -0.3216731207711356, disc_loss = 0.001548170523684738
Trained batch 14 in epoch 6, gen_loss = -0.3198529124259949, disc_loss = 0.0016097989825842281
Trained batch 15 in epoch 6, gen_loss = -0.3162802420556545, disc_loss = 0.0016596041641605552
Trained batch 16 in epoch 6, gen_loss = -0.3174788829158334, disc_loss = 0.0016426145996186225
Trained batch 17 in epoch 6, gen_loss = -0.31535007059574127, disc_loss = 0.0016138079388636267
Trained batch 18 in epoch 6, gen_loss = -0.3157896007362165, disc_loss = 0.0016933088405302872
Trained batch 19 in epoch 6, gen_loss = -0.31477181166410445, disc_loss = 0.0018682053283555432
Trained batch 20 in epoch 6, gen_loss = -0.3153603332383292, disc_loss = 0.0020304597842152276
Trained batch 21 in epoch 6, gen_loss = -0.31541077115318994, disc_loss = 0.0020645383337978274
Trained batch 22 in epoch 6, gen_loss = -0.3139043994571852, disc_loss = 0.0020232857989511735
Trained batch 23 in epoch 6, gen_loss = -0.31325801089406013, disc_loss = 0.0019733556206726157
Trained batch 24 in epoch 6, gen_loss = -0.31493568181991577, disc_loss = 0.001924544763751328
Trained batch 25 in epoch 6, gen_loss = -0.31459660484240604, disc_loss = 0.00188429149476668
Trained batch 26 in epoch 6, gen_loss = -0.31309371082871046, disc_loss = 0.0018541776463044462
Trained batch 27 in epoch 6, gen_loss = -0.31450310136590687, disc_loss = 0.0018130370257754944
Trained batch 28 in epoch 6, gen_loss = -0.3144205356466359, disc_loss = 0.0017825607250540935
Trained batch 29 in epoch 6, gen_loss = -0.3156804144382477, disc_loss = 0.001784636681744208
Trained batch 30 in epoch 6, gen_loss = -0.315295236725961, disc_loss = 0.0018254196714429605
Trained batch 31 in epoch 6, gen_loss = -0.31496753823012114, disc_loss = 0.0018399713480903301
Trained batch 32 in epoch 6, gen_loss = -0.31475661288608203, disc_loss = 0.0018159837751282435
Trained batch 33 in epoch 6, gen_loss = -0.3171239153427236, disc_loss = 0.0017890320399173482
Trained batch 34 in epoch 6, gen_loss = -0.31858344503811425, disc_loss = 0.0017632529172780258
Trained batch 35 in epoch 6, gen_loss = -0.32036452492078143, disc_loss = 0.001730537897350991
Trained batch 36 in epoch 6, gen_loss = -0.31968782399151774, disc_loss = 0.0017308776937047573
Trained batch 37 in epoch 6, gen_loss = -0.32077432149334956, disc_loss = 0.0017259692310625198
Trained batch 38 in epoch 6, gen_loss = -0.3212703986045642, disc_loss = 0.0017011746695527856
Trained batch 39 in epoch 6, gen_loss = -0.32197691425681113, disc_loss = 0.0016861398893524893
Trained batch 40 in epoch 6, gen_loss = -0.3233823085703501, disc_loss = 0.0016715025526426006
Trained batch 41 in epoch 6, gen_loss = -0.3234730618340628, disc_loss = 0.0016601514584007895
Trained batch 42 in epoch 6, gen_loss = -0.32320157594459004, disc_loss = 0.0016948574853432906
Trained batch 43 in epoch 6, gen_loss = -0.3232534805482084, disc_loss = 0.001758624192337844
Trained batch 44 in epoch 6, gen_loss = -0.32315506206618416, disc_loss = 0.0018335623110437558
Trained batch 45 in epoch 6, gen_loss = -0.32424831908682117, disc_loss = 0.0018594093258877326
Trained batch 46 in epoch 6, gen_loss = -0.3243667058488156, disc_loss = 0.001836924195695827
Trained batch 47 in epoch 6, gen_loss = -0.32466613439222175, disc_loss = 0.0018381707838367827
Trained batch 48 in epoch 6, gen_loss = -0.32449209872557194, disc_loss = 0.0018585126013114896
Trained batch 49 in epoch 6, gen_loss = -0.32522214829921725, disc_loss = 0.0018673832819331437
Trained batch 50 in epoch 6, gen_loss = -0.3253467515403149, disc_loss = 0.0018464764842635714
Trained batch 51 in epoch 6, gen_loss = -0.3260244411917833, disc_loss = 0.0018262580247560085
Trained batch 52 in epoch 6, gen_loss = -0.326733132578292, disc_loss = 0.001806082149071373
Trained batch 53 in epoch 6, gen_loss = -0.3260018295711941, disc_loss = 0.0017901349616564672
Trained batch 54 in epoch 6, gen_loss = -0.3264559501951391, disc_loss = 0.0017703124480745332
Trained batch 55 in epoch 6, gen_loss = -0.3269561305642128, disc_loss = 0.001766881214280147
Trained batch 56 in epoch 6, gen_loss = -0.3265063563982646, disc_loss = 0.0017778918038841272
Trained batch 57 in epoch 6, gen_loss = -0.32747222277624854, disc_loss = 0.0017715893045533448
Trained batch 58 in epoch 6, gen_loss = -0.32751658255771054, disc_loss = 0.001759049201471005
Trained batch 59 in epoch 6, gen_loss = -0.32789483219385146, disc_loss = 0.0017558177438331767
Trained batch 60 in epoch 6, gen_loss = -0.3288465103165048, disc_loss = 0.00174201603074268
Trained batch 61 in epoch 6, gen_loss = -0.32971262643414156, disc_loss = 0.001720941179589699
Trained batch 62 in epoch 6, gen_loss = -0.3293688377690694, disc_loss = 0.0017075228573207462
Trained batch 63 in epoch 6, gen_loss = -0.329684526193887, disc_loss = 0.0017030126409736113
Trained batch 64 in epoch 6, gen_loss = -0.3290514913889078, disc_loss = 0.001701562145115951
Trained batch 65 in epoch 6, gen_loss = -0.32996376581264264, disc_loss = 0.0017033541552143906
Trained batch 66 in epoch 6, gen_loss = -0.32956000628756055, disc_loss = 0.001700719310241793
Trained batch 67 in epoch 6, gen_loss = -0.32984912526958127, disc_loss = 0.0016881707834887922
Trained batch 68 in epoch 6, gen_loss = -0.33012126969254535, disc_loss = 0.0016742930283594499
Trained batch 69 in epoch 6, gen_loss = -0.3302382958786828, disc_loss = 0.001668373411355008
Trained batch 70 in epoch 6, gen_loss = -0.32995923010396283, disc_loss = 0.0016570969388006963
Trained batch 71 in epoch 6, gen_loss = -0.3305259260038535, disc_loss = 0.0016433945315333807
Trained batch 72 in epoch 6, gen_loss = -0.33048319775764257, disc_loss = 0.0016297982146083185
Trained batch 73 in epoch 6, gen_loss = -0.33112428921300013, disc_loss = 0.0016200306756119873
Trained batch 74 in epoch 6, gen_loss = -0.33087358792622884, disc_loss = 0.0016116474972416956
Trained batch 75 in epoch 6, gen_loss = -0.3306622387547242, disc_loss = 0.0016010266906385752
Trained batch 76 in epoch 6, gen_loss = -0.3304320163541026, disc_loss = 0.0015903719974524498
Trained batch 77 in epoch 6, gen_loss = -0.33095568800583863, disc_loss = 0.0015767392850158592
Trained batch 78 in epoch 6, gen_loss = -0.3312118770200995, disc_loss = 0.0015650713540719752
Trained batch 79 in epoch 6, gen_loss = -0.3309851262718439, disc_loss = 0.0015625900028680916
Trained batch 80 in epoch 6, gen_loss = -0.3310113151868184, disc_loss = 0.0015576358109908063
Trained batch 81 in epoch 6, gen_loss = -0.3314035596644006, disc_loss = 0.0015560968079115832
Trained batch 82 in epoch 6, gen_loss = -0.3316569805863392, disc_loss = 0.0015572266287103027
Trained batch 83 in epoch 6, gen_loss = -0.33254567959478926, disc_loss = 0.0015519709524510073
Trained batch 84 in epoch 6, gen_loss = -0.33251231137443993, disc_loss = 0.0015408797751126043
Trained batch 85 in epoch 6, gen_loss = -0.3325816749833351, disc_loss = 0.0015312235790229034
Trained batch 86 in epoch 6, gen_loss = -0.33309896033385705, disc_loss = 0.0015281630424386554
Trained batch 87 in epoch 6, gen_loss = -0.333306378938935, disc_loss = 0.0015334276388536885
Trained batch 88 in epoch 6, gen_loss = -0.3325971338186371, disc_loss = 0.0015392316946121498
Trained batch 89 in epoch 6, gen_loss = -0.33291483322779336, disc_loss = 0.001533447658099855
Trained batch 90 in epoch 6, gen_loss = -0.3331790199646583, disc_loss = 0.0015271438802541284
Trained batch 91 in epoch 6, gen_loss = -0.3332461293624795, disc_loss = 0.0015198545259646262
Trained batch 92 in epoch 6, gen_loss = -0.3330626702436837, disc_loss = 0.0015120784606864697
Trained batch 93 in epoch 6, gen_loss = -0.3327735703676305, disc_loss = 0.0015073210295745508
Trained batch 94 in epoch 6, gen_loss = -0.33253261635178016, disc_loss = 0.0015078608645126223
Trained batch 95 in epoch 6, gen_loss = -0.3322665626183152, disc_loss = 0.0015154087462481887
Trained batch 96 in epoch 6, gen_loss = -0.3322003769505884, disc_loss = 0.00151954408850252
Trained batch 97 in epoch 6, gen_loss = -0.3325465136036581, disc_loss = 0.0015139673012118712
Trained batch 98 in epoch 6, gen_loss = -0.33223599075066923, disc_loss = 0.0015068849709797463
Trained batch 99 in epoch 6, gen_loss = -0.33230848670005797, disc_loss = 0.0014994221343658865
Trained batch 100 in epoch 6, gen_loss = -0.33236633639524477, disc_loss = 0.001494601812665489
Trained batch 101 in epoch 6, gen_loss = -0.3326275261009441, disc_loss = 0.001488868000474302
Trained batch 102 in epoch 6, gen_loss = -0.3328806153200205, disc_loss = 0.0014912225402104985
Trained batch 103 in epoch 6, gen_loss = -0.3325352081312583, disc_loss = 0.001498265890964271
Trained batch 104 in epoch 6, gen_loss = -0.3331102501778376, disc_loss = 0.0014955382234239508
Trained batch 105 in epoch 6, gen_loss = -0.3329896485468127, disc_loss = 0.001487791744710983
Trained batch 106 in epoch 6, gen_loss = -0.3332788768772767, disc_loss = 0.001483576277610367
Trained batch 107 in epoch 6, gen_loss = -0.3331553240617116, disc_loss = 0.001478271040401456
Trained batch 108 in epoch 6, gen_loss = -0.3331424711494271, disc_loss = 0.001473723747340296
Trained batch 109 in epoch 6, gen_loss = -0.3330281282013113, disc_loss = 0.0014694649281657556
Trained batch 110 in epoch 6, gen_loss = -0.333453899836755, disc_loss = 0.0014662428817770502
Trained batch 111 in epoch 6, gen_loss = -0.33333147902573856, disc_loss = 0.0014627209696170343
Trained batch 112 in epoch 6, gen_loss = -0.33392308243608054, disc_loss = 0.0014560868061122905
Trained batch 113 in epoch 6, gen_loss = -0.33419988735726003, disc_loss = 0.0014495545285427127
Trained batch 114 in epoch 6, gen_loss = -0.3345356013463891, disc_loss = 0.0014465080887970069
Trained batch 115 in epoch 6, gen_loss = -0.3348148662982316, disc_loss = 0.0014434534582662686
Trained batch 116 in epoch 6, gen_loss = -0.33520874075400525, disc_loss = 0.001438447663313749
Trained batch 117 in epoch 6, gen_loss = -0.33552401803307613, disc_loss = 0.0014324980152581456
Trained batch 118 in epoch 6, gen_loss = -0.3356239147046033, disc_loss = 0.001429220862068361
Trained batch 119 in epoch 6, gen_loss = -0.33555776278177896, disc_loss = 0.0014292404821996266
Trained batch 120 in epoch 6, gen_loss = -0.3358041685967406, disc_loss = 0.001429563611437959
Trained batch 121 in epoch 6, gen_loss = -0.335981369262836, disc_loss = 0.0014273777688074796
Trained batch 122 in epoch 6, gen_loss = -0.33585494441714714, disc_loss = 0.0014265589340309787
Trained batch 123 in epoch 6, gen_loss = -0.3357876070564793, disc_loss = 0.0014291948098088464
Trained batch 124 in epoch 6, gen_loss = -0.33603082919120786, disc_loss = 0.001435281442478299
Trained batch 125 in epoch 6, gen_loss = -0.33625837900335825, disc_loss = 0.0014435612496786884
Trained batch 126 in epoch 6, gen_loss = -0.3360349878551453, disc_loss = 0.0014550983374131711
Trained batch 127 in epoch 6, gen_loss = -0.3363754362799227, disc_loss = 0.0014638767224823823
Trained batch 128 in epoch 6, gen_loss = -0.3366356524386147, disc_loss = 0.0014624153823382402
Trained batch 129 in epoch 6, gen_loss = -0.3367390217689367, disc_loss = 0.0014567648006889682
Trained batch 130 in epoch 6, gen_loss = -0.33712640632199875, disc_loss = 0.0014496343721322829
Trained batch 131 in epoch 6, gen_loss = -0.33747662739320233, disc_loss = 0.0014462543393054864
Trained batch 132 in epoch 6, gen_loss = -0.33778267314559535, disc_loss = 0.0014500551882438025
Trained batch 133 in epoch 6, gen_loss = -0.3383979463755195, disc_loss = 0.001456378222835848
Trained batch 134 in epoch 6, gen_loss = -0.33840411526185493, disc_loss = 0.0014615883002988995
Trained batch 135 in epoch 6, gen_loss = -0.3382849358022213, disc_loss = 0.0014654003303696621
Trained batch 136 in epoch 6, gen_loss = -0.33832868542114314, disc_loss = 0.0014623809256590903
Trained batch 137 in epoch 6, gen_loss = -0.33843648368897644, disc_loss = 0.0014653510942994415
Trained batch 138 in epoch 6, gen_loss = -0.338773275665242, disc_loss = 0.0014674858095479473
Trained batch 139 in epoch 6, gen_loss = -0.3387543616550309, disc_loss = 0.0014711383360138696
Trained batch 140 in epoch 6, gen_loss = -0.33918726254016796, disc_loss = 0.0014738484706022903
Trained batch 141 in epoch 6, gen_loss = -0.33920369307759785, disc_loss = 0.0014744354366869206
Trained batch 142 in epoch 6, gen_loss = -0.3394724707920235, disc_loss = 0.001471649403960633
Trained batch 143 in epoch 6, gen_loss = -0.3399608464290698, disc_loss = 0.0014696614618717125
Trained batch 144 in epoch 6, gen_loss = -0.3398085012518126, disc_loss = 0.001466433955597338
Trained batch 145 in epoch 6, gen_loss = -0.3396687170822326, disc_loss = 0.0014622138294053252
Trained batch 146 in epoch 6, gen_loss = -0.33964673292880154, disc_loss = 0.0014576812882172768
Trained batch 147 in epoch 6, gen_loss = -0.33980744090434667, disc_loss = 0.001453859543953267
Trained batch 148 in epoch 6, gen_loss = -0.33958111693395066, disc_loss = 0.0014516429506061012
Trained batch 149 in epoch 6, gen_loss = -0.3396584834655126, disc_loss = 0.001447088118099297
Trained batch 150 in epoch 6, gen_loss = -0.34002866314736424, disc_loss = 0.0014412164081362947
Trained batch 151 in epoch 6, gen_loss = -0.34018286709722717, disc_loss = 0.0014352633056420785
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = -0.3421980142593384, disc_loss = 0.0012275931658223271
Trained batch 1 in epoch 7, gen_loss = -0.3500869572162628, disc_loss = 0.001409031916409731
Trained batch 2 in epoch 7, gen_loss = -0.3453300893306732, disc_loss = 0.0014726221561431885
Trained batch 3 in epoch 7, gen_loss = -0.3499245345592499, disc_loss = 0.0014002438983879983
Trained batch 4 in epoch 7, gen_loss = -0.35929720401763915, disc_loss = 0.0012517502182163298
Trained batch 5 in epoch 7, gen_loss = -0.36156806846459705, disc_loss = 0.0011218828003620729
Trained batch 6 in epoch 7, gen_loss = -0.35610929131507874, disc_loss = 0.001084738165705598
Trained batch 7 in epoch 7, gen_loss = -0.35667117312550545, disc_loss = 0.0010624436945363414
Trained batch 8 in epoch 7, gen_loss = -0.3640843994087643, disc_loss = 0.001032497129118484
Trained batch 9 in epoch 7, gen_loss = -0.3651039093732834, disc_loss = 0.0010002239578170702
Trained batch 10 in epoch 7, gen_loss = -0.363201688636433, disc_loss = 0.0009873810261276296
Trained batch 11 in epoch 7, gen_loss = -0.36363687614599866, disc_loss = 0.0009477129569859244
Trained batch 12 in epoch 7, gen_loss = -0.363956460585961, disc_loss = 0.0009276746803572258
Trained batch 13 in epoch 7, gen_loss = -0.3666954019239971, disc_loss = 0.0009333453469610374
Trained batch 14 in epoch 7, gen_loss = -0.3676342209180196, disc_loss = 0.0009945016257309665
Trained batch 15 in epoch 7, gen_loss = -0.3683293256908655, disc_loss = 0.0011085263886343455
Trained batch 16 in epoch 7, gen_loss = -0.36801522444276247, disc_loss = 0.0012483619177467464
Trained batch 17 in epoch 7, gen_loss = -0.3706212076875899, disc_loss = 0.0014060136729515055
Trained batch 18 in epoch 7, gen_loss = -0.3685341116629149, disc_loss = 0.001606363403353546
Trained batch 19 in epoch 7, gen_loss = -0.36763910204172134, disc_loss = 0.0017894214412081054
Trained batch 20 in epoch 7, gen_loss = -0.36684967080752057, disc_loss = 0.001917525076784105
Trained batch 21 in epoch 7, gen_loss = -0.3685691559856588, disc_loss = 0.001931171561326747
Trained batch 22 in epoch 7, gen_loss = -0.3689958181070245, disc_loss = 0.0018807476368712505
Trained batch 23 in epoch 7, gen_loss = -0.3709607223669688, disc_loss = 0.001834328595577972
Trained batch 24 in epoch 7, gen_loss = -0.3715312373638153, disc_loss = 0.0017954509367700665
Trained batch 25 in epoch 7, gen_loss = -0.3727211654186249, disc_loss = 0.0017543260529726888
Trained batch 26 in epoch 7, gen_loss = -0.3740469680892097, disc_loss = 0.0017275354723635785
Trained batch 27 in epoch 7, gen_loss = -0.3743031546473503, disc_loss = 0.0017083975222444028
Trained batch 28 in epoch 7, gen_loss = -0.3744343241740917, disc_loss = 0.0017048890495688879
Trained batch 29 in epoch 7, gen_loss = -0.37605224053064984, disc_loss = 0.0016965121156924093
Trained batch 30 in epoch 7, gen_loss = -0.37539065172595365, disc_loss = 0.0016817904590073253
Trained batch 31 in epoch 7, gen_loss = -0.3758061993867159, disc_loss = 0.0016708665616533835
Trained batch 32 in epoch 7, gen_loss = -0.37728801730907324, disc_loss = 0.00165828687198827
Trained batch 33 in epoch 7, gen_loss = -0.3782963428427191, disc_loss = 0.0016315308723064577
Trained batch 34 in epoch 7, gen_loss = -0.37648267831121174, disc_loss = 0.001602941150278119
Trained batch 35 in epoch 7, gen_loss = -0.3776441721452607, disc_loss = 0.0015716825752557877
Trained batch 36 in epoch 7, gen_loss = -0.3775684962401519, disc_loss = 0.0015420500775862082
Trained batch 37 in epoch 7, gen_loss = -0.3785026120512109, disc_loss = 0.0015228100030646218
Trained batch 38 in epoch 7, gen_loss = -0.3790297477673262, disc_loss = 0.0015185675024090765
Trained batch 39 in epoch 7, gen_loss = -0.37835297733545303, disc_loss = 0.0015194164450804237
Trained batch 40 in epoch 7, gen_loss = -0.3790862385819598, disc_loss = 0.0015005796413766447
Trained batch 41 in epoch 7, gen_loss = -0.37896804156757535, disc_loss = 0.0014786534240036936
Trained batch 42 in epoch 7, gen_loss = -0.3799830661263577, disc_loss = 0.001466098208343177
Trained batch 43 in epoch 7, gen_loss = -0.3810060213912617, disc_loss = 0.0014712696052315137
Trained batch 44 in epoch 7, gen_loss = -0.3811002744568719, disc_loss = 0.0014896748943202612
Trained batch 45 in epoch 7, gen_loss = -0.38003128054349317, disc_loss = 0.0015106527330910626
Trained batch 46 in epoch 7, gen_loss = -0.37962238078421734, disc_loss = 0.0015125772959126674
Trained batch 47 in epoch 7, gen_loss = -0.3794582212964694, disc_loss = 0.0015104214101787268
Trained batch 48 in epoch 7, gen_loss = -0.3790966649444736, disc_loss = 0.0015212501136690605
Trained batch 49 in epoch 7, gen_loss = -0.3795206433534622, disc_loss = 0.0015455740730976686
Trained batch 50 in epoch 7, gen_loss = -0.37861616412798565, disc_loss = 0.001563345255015199
Trained batch 51 in epoch 7, gen_loss = -0.3784411669923709, disc_loss = 0.001569781136193062
Trained batch 52 in epoch 7, gen_loss = -0.37820935924098176, disc_loss = 0.0015661131325924664
Trained batch 53 in epoch 7, gen_loss = -0.3782356442124755, disc_loss = 0.001557960515061428
Trained batch 54 in epoch 7, gen_loss = -0.3785493975335901, disc_loss = 0.0015606124731923708
Trained batch 55 in epoch 7, gen_loss = -0.37830961868166924, disc_loss = 0.0015874083302540904
Trained batch 56 in epoch 7, gen_loss = -0.37839682008090775, disc_loss = 0.0015992174683784118
Trained batch 57 in epoch 7, gen_loss = -0.3786170528880481, disc_loss = 0.0015920036615892153
Trained batch 58 in epoch 7, gen_loss = -0.3788917069717989, disc_loss = 0.001584133999007833
Trained batch 59 in epoch 7, gen_loss = -0.378294009466966, disc_loss = 0.0015876778726427196
Trained batch 60 in epoch 7, gen_loss = -0.3784540964931738, disc_loss = 0.0015866960504771683
Trained batch 61 in epoch 7, gen_loss = -0.37806226649592, disc_loss = 0.001577698503106442
Trained batch 62 in epoch 7, gen_loss = -0.37830063700675964, disc_loss = 0.001570800662554416
Trained batch 63 in epoch 7, gen_loss = -0.3787921774201095, disc_loss = 0.0015639158914382278
Trained batch 64 in epoch 7, gen_loss = -0.37775082817444433, disc_loss = 0.0015601683976666
Trained batch 65 in epoch 7, gen_loss = -0.37703390193708014, disc_loss = 0.0015695065424855177
Trained batch 66 in epoch 7, gen_loss = -0.3772910335170689, disc_loss = 0.0015845605612683819
Trained batch 67 in epoch 7, gen_loss = -0.37809015722835765, disc_loss = 0.0015969511240494765
Trained batch 68 in epoch 7, gen_loss = -0.37803454114043195, disc_loss = 0.001595507181448646
Trained batch 69 in epoch 7, gen_loss = -0.3776683232613972, disc_loss = 0.0015861047593976503
Trained batch 70 in epoch 7, gen_loss = -0.3771773106615308, disc_loss = 0.001575278983579319
Trained batch 71 in epoch 7, gen_loss = -0.37733742429150474, disc_loss = 0.0015637642180889896
Trained batch 72 in epoch 7, gen_loss = -0.3778523855829892, disc_loss = 0.0015484040753743675
Trained batch 73 in epoch 7, gen_loss = -0.37821475476832, disc_loss = 0.001535152127208012
Trained batch 74 in epoch 7, gen_loss = -0.37856808066368103, disc_loss = 0.001524014015449211
Trained batch 75 in epoch 7, gen_loss = -0.37885286972710963, disc_loss = 0.0015105645614216644
Trained batch 76 in epoch 7, gen_loss = -0.3783340372822501, disc_loss = 0.0014966683762371782
Trained batch 77 in epoch 7, gen_loss = -0.3788977838479556, disc_loss = 0.0014846579403801558
Trained batch 78 in epoch 7, gen_loss = -0.378162188620507, disc_loss = 0.0014746049481673944
Trained batch 79 in epoch 7, gen_loss = -0.378411515429616, disc_loss = 0.0014629199151386274
Trained batch 80 in epoch 7, gen_loss = -0.3779882946868002, disc_loss = 0.0014521458281784743
Trained batch 81 in epoch 7, gen_loss = -0.37779834175982124, disc_loss = 0.0014409765806304654
Trained batch 82 in epoch 7, gen_loss = -0.37706453649394484, disc_loss = 0.0014369265749315586
Trained batch 83 in epoch 7, gen_loss = -0.376704946515106, disc_loss = 0.0014494172747141593
Trained batch 84 in epoch 7, gen_loss = -0.37679210094844595, disc_loss = 0.0014707597482757752
Trained batch 85 in epoch 7, gen_loss = -0.37700330621974415, disc_loss = 0.0014896182641847232
Trained batch 86 in epoch 7, gen_loss = -0.3780853481128298, disc_loss = 0.0014931031401756209
Trained batch 87 in epoch 7, gen_loss = -0.3777942874214866, disc_loss = 0.0014850346425108992
Trained batch 88 in epoch 7, gen_loss = -0.3777654743596409, disc_loss = 0.001479358139272591
Trained batch 89 in epoch 7, gen_loss = -0.378560076157252, disc_loss = 0.0014699872004308014
Trained batch 90 in epoch 7, gen_loss = -0.37815000133200005, disc_loss = 0.0014628604502841872
Trained batch 91 in epoch 7, gen_loss = -0.3781698281350343, disc_loss = 0.0014645344006408857
Trained batch 92 in epoch 7, gen_loss = -0.378516706087256, disc_loss = 0.0014643810544868992
Trained batch 93 in epoch 7, gen_loss = -0.37920569073646626, disc_loss = 0.0014735397333502174
Trained batch 94 in epoch 7, gen_loss = -0.37958944314404536, disc_loss = 0.001483879244800559
Trained batch 95 in epoch 7, gen_loss = -0.3792476896196604, disc_loss = 0.0014908777875461965
Trained batch 96 in epoch 7, gen_loss = -0.379969040757602, disc_loss = 0.0014852081343277176
Trained batch 97 in epoch 7, gen_loss = -0.38035132477478106, disc_loss = 0.0014759426617553001
Trained batch 98 in epoch 7, gen_loss = -0.38063519801756346, disc_loss = 0.0014736381441124273
Trained batch 99 in epoch 7, gen_loss = -0.3803866681456566, disc_loss = 0.0014715880292351358
Trained batch 100 in epoch 7, gen_loss = -0.38026838343922453, disc_loss = 0.0014657366264145821
Trained batch 101 in epoch 7, gen_loss = -0.3807755670711106, disc_loss = 0.0014608774055137903
Trained batch 102 in epoch 7, gen_loss = -0.38076890411886194, disc_loss = 0.0014575471345999829
Trained batch 103 in epoch 7, gen_loss = -0.3802609337637058, disc_loss = 0.0014549745613364324
Trained batch 104 in epoch 7, gen_loss = -0.38061833126204353, disc_loss = 0.0014489960044600247
Trained batch 105 in epoch 7, gen_loss = -0.3809334706023054, disc_loss = 0.0014425821754453212
Trained batch 106 in epoch 7, gen_loss = -0.38086446423396886, disc_loss = 0.0014354792909335484
Trained batch 107 in epoch 7, gen_loss = -0.3806097021809331, disc_loss = 0.001429994286876603
Trained batch 108 in epoch 7, gen_loss = -0.3806770837635075, disc_loss = 0.0014237217498844952
Trained batch 109 in epoch 7, gen_loss = -0.3810670931230892, disc_loss = 0.0014176685180493885
Trained batch 110 in epoch 7, gen_loss = -0.38125491571855974, disc_loss = 0.0014114519966627798
Trained batch 111 in epoch 7, gen_loss = -0.38120680089507786, disc_loss = 0.0014066053162033704
Trained batch 112 in epoch 7, gen_loss = -0.3818404505738115, disc_loss = 0.001400186949403363
Trained batch 113 in epoch 7, gen_loss = -0.38184427378470437, disc_loss = 0.0013940732080076838
Trained batch 114 in epoch 7, gen_loss = -0.38184850941533627, disc_loss = 0.0013903204258025178
Trained batch 115 in epoch 7, gen_loss = -0.38230487755660353, disc_loss = 0.0013931708775183733
Trained batch 116 in epoch 7, gen_loss = -0.3818284326638931, disc_loss = 0.0014051264099693166
Trained batch 117 in epoch 7, gen_loss = -0.3820796707424067, disc_loss = 0.0014353337432790579
Trained batch 118 in epoch 7, gen_loss = -0.38213634566098703, disc_loss = 0.001469533795348032
Trained batch 119 in epoch 7, gen_loss = -0.3824494188030561, disc_loss = 0.0014819689121698806
Trained batch 120 in epoch 7, gen_loss = -0.38263727712237144, disc_loss = 0.0014776466094430782
Trained batch 121 in epoch 7, gen_loss = -0.3829873504697299, disc_loss = 0.0014699040089073577
Trained batch 122 in epoch 7, gen_loss = -0.3833707631603489, disc_loss = 0.0014611377730507525
Trained batch 123 in epoch 7, gen_loss = -0.3833718273428179, disc_loss = 0.0014532323879276163
Trained batch 124 in epoch 7, gen_loss = -0.38393518710136415, disc_loss = 0.0014461587478872388
Trained batch 125 in epoch 7, gen_loss = -0.3846395692181966, disc_loss = 0.0014382079774920371
Trained batch 126 in epoch 7, gen_loss = -0.3851341361135948, disc_loss = 0.0014309382811372028
Trained batch 127 in epoch 7, gen_loss = -0.38508298248052597, disc_loss = 0.0014254707598411187
Trained batch 128 in epoch 7, gen_loss = -0.38513293654419656, disc_loss = 0.0014206309339876266
Trained batch 129 in epoch 7, gen_loss = -0.38511356184115775, disc_loss = 0.0014157474896189972
Trained batch 130 in epoch 7, gen_loss = -0.38511062555640707, disc_loss = 0.001410424718206734
Trained batch 131 in epoch 7, gen_loss = -0.38537755856911343, disc_loss = 0.001404662037120116
Trained batch 132 in epoch 7, gen_loss = -0.3857459363184477, disc_loss = 0.0013986710954415507
Trained batch 133 in epoch 7, gen_loss = -0.38572626149476463, disc_loss = 0.001391444763137417
Trained batch 134 in epoch 7, gen_loss = -0.38571806108510054, disc_loss = 0.00138824236691343
Trained batch 135 in epoch 7, gen_loss = -0.3859914764761925, disc_loss = 0.0013916933843146956
Trained batch 136 in epoch 7, gen_loss = -0.3861506215847322, disc_loss = 0.0014009542663812801
Trained batch 137 in epoch 7, gen_loss = -0.3863739487917527, disc_loss = 0.0014022699741990832
Trained batch 138 in epoch 7, gen_loss = -0.38660927813687773, disc_loss = 0.0014005039124280589
Trained batch 139 in epoch 7, gen_loss = -0.3867284338389124, disc_loss = 0.0013939417223030302
Trained batch 140 in epoch 7, gen_loss = -0.3868070320880159, disc_loss = 0.001389422484282206
Trained batch 141 in epoch 7, gen_loss = -0.38739453759831444, disc_loss = 0.0013902262179098998
Trained batch 142 in epoch 7, gen_loss = -0.3872354749616209, disc_loss = 0.0013940645814498795
Trained batch 143 in epoch 7, gen_loss = -0.3871046989742253, disc_loss = 0.0013946626946158682
Trained batch 144 in epoch 7, gen_loss = -0.38678972371693315, disc_loss = 0.001399218418498941
Trained batch 145 in epoch 7, gen_loss = -0.3873285426668925, disc_loss = 0.0014087886265271713
Trained batch 146 in epoch 7, gen_loss = -0.3871227815037682, disc_loss = 0.0014146450139997135
Trained batch 147 in epoch 7, gen_loss = -0.38717938697821386, disc_loss = 0.0014099349947001257
Trained batch 148 in epoch 7, gen_loss = -0.3879353610061159, disc_loss = 0.0014061553608047956
Trained batch 149 in epoch 7, gen_loss = -0.3882174962759018, disc_loss = 0.0014025452579759683
Trained batch 150 in epoch 7, gen_loss = -0.3879264137208067, disc_loss = 0.0013988520643621412
Trained batch 151 in epoch 7, gen_loss = -0.38832392445520353, disc_loss = 0.0013934172516440555
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = -0.42807793617248535, disc_loss = 0.0009714241605252028
Trained batch 1 in epoch 8, gen_loss = -0.41985778510570526, disc_loss = 0.0010322942398488522
Trained batch 2 in epoch 8, gen_loss = -0.41769807537396747, disc_loss = 0.0010015832182640831
Trained batch 3 in epoch 8, gen_loss = -0.4280390962958336, disc_loss = 0.0010582595714367926
Trained batch 4 in epoch 8, gen_loss = -0.43649659752845765, disc_loss = 0.00106844836845994
Trained batch 5 in epoch 8, gen_loss = -0.42706318696339923, disc_loss = 0.0012254551596318681
Trained batch 6 in epoch 8, gen_loss = -0.43079569935798645, disc_loss = 0.0013792609928974084
Trained batch 7 in epoch 8, gen_loss = -0.4335709400475025, disc_loss = 0.0014115134545136243
Trained batch 8 in epoch 8, gen_loss = -0.4297536578443315, disc_loss = 0.0013823470411201317
Trained batch 9 in epoch 8, gen_loss = -0.42560736536979676, disc_loss = 0.001300608174642548
Trained batch 10 in epoch 8, gen_loss = -0.425140917301178, disc_loss = 0.0012800083231096241
Trained batch 11 in epoch 8, gen_loss = -0.42863650619983673, disc_loss = 0.0012529157053601618
Trained batch 12 in epoch 8, gen_loss = -0.4233388717357929, disc_loss = 0.0012441028330403452
Trained batch 13 in epoch 8, gen_loss = -0.4228574207850865, disc_loss = 0.0012183231467913305
Trained batch 14 in epoch 8, gen_loss = -0.4234440227349599, disc_loss = 0.0011825508011194567
Trained batch 15 in epoch 8, gen_loss = -0.42500307224690914, disc_loss = 0.0011627027233771514
Trained batch 16 in epoch 8, gen_loss = -0.422428218757405, disc_loss = 0.0011240495300358709
Trained batch 17 in epoch 8, gen_loss = -0.4244692855411106, disc_loss = 0.001088950010145911
Trained batch 18 in epoch 8, gen_loss = -0.4234994257751264, disc_loss = 0.001057736333582158
Trained batch 19 in epoch 8, gen_loss = -0.4220173329114914, disc_loss = 0.0010330060351407156
Trained batch 20 in epoch 8, gen_loss = -0.4176188622202192, disc_loss = 0.0010388973806541237
Trained batch 21 in epoch 8, gen_loss = -0.41591246019710193, disc_loss = 0.0010999628125732256
Trained batch 22 in epoch 8, gen_loss = -0.4130037439906079, disc_loss = 0.0012616863266726875
Trained batch 23 in epoch 8, gen_loss = -0.41205645228425664, disc_loss = 0.0014980678946206656
Trained batch 24 in epoch 8, gen_loss = -0.4134435272216797, disc_loss = 0.001704557731281966
Trained batch 25 in epoch 8, gen_loss = -0.41345519056686986, disc_loss = 0.0017677343051988059
Trained batch 26 in epoch 8, gen_loss = -0.41517753512771044, disc_loss = 0.001773316186801013
Trained batch 27 in epoch 8, gen_loss = -0.4162239858082363, disc_loss = 0.0017697291852008285
Trained batch 28 in epoch 8, gen_loss = -0.41636889453591974, disc_loss = 0.0017600615673441567
Trained batch 29 in epoch 8, gen_loss = -0.41751977801322937, disc_loss = 0.0017390476326302935
Trained batch 30 in epoch 8, gen_loss = -0.4193723605525109, disc_loss = 0.0017169004422612488
Trained batch 31 in epoch 8, gen_loss = -0.41831101663410664, disc_loss = 0.0017237179108633427
Trained batch 32 in epoch 8, gen_loss = -0.41900629437331, disc_loss = 0.0017372317114760253
Trained batch 33 in epoch 8, gen_loss = -0.41902831021477194, disc_loss = 0.0017374494260259193
Trained batch 34 in epoch 8, gen_loss = -0.42032040442739216, disc_loss = 0.0017236242486563112
Trained batch 35 in epoch 8, gen_loss = -0.41984929227166706, disc_loss = 0.0016987118142424151
Trained batch 36 in epoch 8, gen_loss = -0.4208997721607621, disc_loss = 0.0016697960373995876
Trained batch 37 in epoch 8, gen_loss = -0.4215047681017926, disc_loss = 0.0016443255712817375
Trained batch 38 in epoch 8, gen_loss = -0.42197215251433545, disc_loss = 0.0016141005818588803
Trained batch 39 in epoch 8, gen_loss = -0.4222652480006218, disc_loss = 0.0015890178619883955
Trained batch 40 in epoch 8, gen_loss = -0.4212226257091615, disc_loss = 0.0015895651261572067
Trained batch 41 in epoch 8, gen_loss = -0.4208286731016068, disc_loss = 0.001586970177456914
Trained batch 42 in epoch 8, gen_loss = -0.42041712583497515, disc_loss = 0.0015871038167672448
Trained batch 43 in epoch 8, gen_loss = -0.42013188112865796, disc_loss = 0.001569470444916409
Trained batch 44 in epoch 8, gen_loss = -0.4209395746390025, disc_loss = 0.0015449320082552731
Trained batch 45 in epoch 8, gen_loss = -0.42225525884524634, disc_loss = 0.00152384055748015
Trained batch 46 in epoch 8, gen_loss = -0.42163847545359995, disc_loss = 0.0015057769128458296
Trained batch 47 in epoch 8, gen_loss = -0.4214665250231822, disc_loss = 0.0014931959061262508
Trained batch 48 in epoch 8, gen_loss = -0.42140971945256606, disc_loss = 0.0014798670914499279
Trained batch 49 in epoch 8, gen_loss = -0.4219029307365417, disc_loss = 0.0014698263222817332
Trained batch 50 in epoch 8, gen_loss = -0.42175930738449097, disc_loss = 0.0014644584986016008
Trained batch 51 in epoch 8, gen_loss = -0.42249833276638615, disc_loss = 0.0014789599820058076
Trained batch 52 in epoch 8, gen_loss = -0.42332151251019173, disc_loss = 0.0014976255193721714
Trained batch 53 in epoch 8, gen_loss = -0.4227902348394747, disc_loss = 0.001502212321308131
Trained batch 54 in epoch 8, gen_loss = -0.42282570383765483, disc_loss = 0.0014946782633408226
Trained batch 55 in epoch 8, gen_loss = -0.42276429597820553, disc_loss = 0.0014802682323664027
Trained batch 56 in epoch 8, gen_loss = -0.4224591260416466, disc_loss = 0.0014835634777371428
Trained batch 57 in epoch 8, gen_loss = -0.42239582178921536, disc_loss = 0.0015270648863375314
Trained batch 58 in epoch 8, gen_loss = -0.42262354493141174, disc_loss = 0.0016014141758698653
Trained batch 59 in epoch 8, gen_loss = -0.42235319316387177, disc_loss = 0.0016544946362652506
Trained batch 60 in epoch 8, gen_loss = -0.4222709218986699, disc_loss = 0.0016752906290615802
Trained batch 61 in epoch 8, gen_loss = -0.4224862403446628, disc_loss = 0.0016782530104636304
Trained batch 62 in epoch 8, gen_loss = -0.4224038180850801, disc_loss = 0.00167349375329823
Trained batch 63 in epoch 8, gen_loss = -0.42275788728147745, disc_loss = 0.0016705110583643545
Trained batch 64 in epoch 8, gen_loss = -0.42245124119978683, disc_loss = 0.0016747604742144736
Trained batch 65 in epoch 8, gen_loss = -0.4230315229206374, disc_loss = 0.001670897972706536
Trained batch 66 in epoch 8, gen_loss = -0.4225513178910782, disc_loss = 0.00165552383118462
Trained batch 67 in epoch 8, gen_loss = -0.4220109380343381, disc_loss = 0.0016414640233372612
Trained batch 68 in epoch 8, gen_loss = -0.4219678286193074, disc_loss = 0.0016278714250327776
Trained batch 69 in epoch 8, gen_loss = -0.4218228650944574, disc_loss = 0.001612287270004994
Trained batch 70 in epoch 8, gen_loss = -0.4213937130612387, disc_loss = 0.0016181087834616257
Trained batch 71 in epoch 8, gen_loss = -0.4215749208297994, disc_loss = 0.0016428011642549084
Trained batch 72 in epoch 8, gen_loss = -0.42158089884339944, disc_loss = 0.0016695986149437114
Trained batch 73 in epoch 8, gen_loss = -0.42107323134267655, disc_loss = 0.0016820644826087093
Trained batch 74 in epoch 8, gen_loss = -0.42076759815216064, disc_loss = 0.001677522040748348
Trained batch 75 in epoch 8, gen_loss = -0.4203164020651265, disc_loss = 0.0016622776479619603
Trained batch 76 in epoch 8, gen_loss = -0.419657923184432, disc_loss = 0.001645904611161148
Trained batch 77 in epoch 8, gen_loss = -0.4198066897881337, disc_loss = 0.0016298242542409124
Trained batch 78 in epoch 8, gen_loss = -0.4202863581572907, disc_loss = 0.0016149224590398135
Trained batch 79 in epoch 8, gen_loss = -0.4203926231712103, disc_loss = 0.0016050231428380358
Trained batch 80 in epoch 8, gen_loss = -0.4209733252172117, disc_loss = 0.0016001339625986869
Trained batch 81 in epoch 8, gen_loss = -0.42137156499595174, disc_loss = 0.0016073755548682018
Trained batch 82 in epoch 8, gen_loss = -0.4215172371232366, disc_loss = 0.001614340542077861
Trained batch 83 in epoch 8, gen_loss = -0.4215625169731322, disc_loss = 0.0016097187101314333
Trained batch 84 in epoch 8, gen_loss = -0.42146831820992864, disc_loss = 0.0016002041188424782
Trained batch 85 in epoch 8, gen_loss = -0.42204116666039754, disc_loss = 0.0015969360284480202
Trained batch 86 in epoch 8, gen_loss = -0.42203194862124566, disc_loss = 0.0015929042526932925
Trained batch 87 in epoch 8, gen_loss = -0.4219265434552323, disc_loss = 0.0015848565562919248
Trained batch 88 in epoch 8, gen_loss = -0.4226503623335549, disc_loss = 0.0015750549000483843
Trained batch 89 in epoch 8, gen_loss = -0.4224804315302107, disc_loss = 0.0015629377089984094
Trained batch 90 in epoch 8, gen_loss = -0.4229659968680078, disc_loss = 0.001554283675172233
Trained batch 91 in epoch 8, gen_loss = -0.4233851403645847, disc_loss = 0.0015476432634623843
Trained batch 92 in epoch 8, gen_loss = -0.42245157463576205, disc_loss = 0.0015428908615528296
Trained batch 93 in epoch 8, gen_loss = -0.42277489412338176, disc_loss = 0.0015329169174482888
Trained batch 94 in epoch 8, gen_loss = -0.4228558709746913, disc_loss = 0.0015280398984415162
Trained batch 95 in epoch 8, gen_loss = -0.4228878968084852, disc_loss = 0.0015308054137979827
Trained batch 96 in epoch 8, gen_loss = -0.423004155306472, disc_loss = 0.0015376505574581127
Trained batch 97 in epoch 8, gen_loss = -0.42327238893022345, disc_loss = 0.0015372744947315517
Trained batch 98 in epoch 8, gen_loss = -0.4233845321819036, disc_loss = 0.001530949041339089
Trained batch 99 in epoch 8, gen_loss = -0.4237408298254013, disc_loss = 0.0015215549126151018
Trained batch 100 in epoch 8, gen_loss = -0.4238163344930894, disc_loss = 0.001511784666621283
Trained batch 101 in epoch 8, gen_loss = -0.42386260687136185, disc_loss = 0.0015079847707609444
Trained batch 102 in epoch 8, gen_loss = -0.4242041203582171, disc_loss = 0.0015075975637408245
Trained batch 103 in epoch 8, gen_loss = -0.42464358646136063, disc_loss = 0.0015052308162222079
Trained batch 104 in epoch 8, gen_loss = -0.4249440108026777, disc_loss = 0.0014984759920653665
Trained batch 105 in epoch 8, gen_loss = -0.42516781136674703, disc_loss = 0.0014913644889294926
Trained batch 106 in epoch 8, gen_loss = -0.4259204274026033, disc_loss = 0.001491892698523371
Trained batch 107 in epoch 8, gen_loss = -0.42575686149023195, disc_loss = 0.001503809358163616
Trained batch 108 in epoch 8, gen_loss = -0.42615194140224283, disc_loss = 0.0015160541908298577
Trained batch 109 in epoch 8, gen_loss = -0.42662378305738624, disc_loss = 0.0015192744774553417
Trained batch 110 in epoch 8, gen_loss = -0.4271666117616602, disc_loss = 0.0015122129297123065
Trained batch 111 in epoch 8, gen_loss = -0.4274161740073136, disc_loss = 0.0015019137837433455
Trained batch 112 in epoch 8, gen_loss = -0.42711604274479686, disc_loss = 0.0014948166852231772
Trained batch 113 in epoch 8, gen_loss = -0.4270967848991093, disc_loss = 0.0014911939225592569
Trained batch 114 in epoch 8, gen_loss = -0.4271748537602632, disc_loss = 0.0014926622292715246
Trained batch 115 in epoch 8, gen_loss = -0.4274451324138148, disc_loss = 0.0014941502881340746
Trained batch 116 in epoch 8, gen_loss = -0.4277836214273404, disc_loss = 0.001489127613007067
Trained batch 117 in epoch 8, gen_loss = -0.4279859437275741, disc_loss = 0.001481199670598795
Trained batch 118 in epoch 8, gen_loss = -0.42845290723968954, disc_loss = 0.0014785352513241041
Trained batch 119 in epoch 8, gen_loss = -0.4284532899657885, disc_loss = 0.0014834560288970048
Trained batch 120 in epoch 8, gen_loss = -0.4290357003034639, disc_loss = 0.0014910253509494268
Trained batch 121 in epoch 8, gen_loss = -0.42923115682406504, disc_loss = 0.0014991912023225402
Trained batch 122 in epoch 8, gen_loss = -0.4296786819047075, disc_loss = 0.0015047282118698566
Trained batch 123 in epoch 8, gen_loss = -0.42982066975485894, disc_loss = 0.0015074362323033593
Trained batch 124 in epoch 8, gen_loss = -0.42980234742164614, disc_loss = 0.001502072119154036
Trained batch 125 in epoch 8, gen_loss = -0.43040510326150866, disc_loss = 0.0014943345921069739
Trained batch 126 in epoch 8, gen_loss = -0.4309031674711723, disc_loss = 0.0014860231720835088
Trained batch 127 in epoch 8, gen_loss = -0.4310871565248817, disc_loss = 0.0014812133094892488
Trained batch 128 in epoch 8, gen_loss = -0.4311172798160435, disc_loss = 0.001476192374013422
Trained batch 129 in epoch 8, gen_loss = -0.43127997861458706, disc_loss = 0.00147140908610219
Trained batch 130 in epoch 8, gen_loss = -0.4320514377291876, disc_loss = 0.0014687869902202532
Trained batch 131 in epoch 8, gen_loss = -0.43213202488241775, disc_loss = 0.0014678357507694852
Trained batch 132 in epoch 8, gen_loss = -0.43262464659554617, disc_loss = 0.0014639302363437146
Trained batch 133 in epoch 8, gen_loss = -0.4324557300823838, disc_loss = 0.0014655796460001104
Trained batch 134 in epoch 8, gen_loss = -0.43235238702208906, disc_loss = 0.0014647091419815465
Trained batch 135 in epoch 8, gen_loss = -0.43208711112246795, disc_loss = 0.0014601497660966262
Trained batch 136 in epoch 8, gen_loss = -0.43224236086337237, disc_loss = 0.0014555265788791063
Trained batch 137 in epoch 8, gen_loss = -0.4324728168439174, disc_loss = 0.0014554629063544173
Trained batch 138 in epoch 8, gen_loss = -0.43288655246762064, disc_loss = 0.001452993758176889
Trained batch 139 in epoch 8, gen_loss = -0.4330314955541066, disc_loss = 0.0014483212173217908
Trained batch 140 in epoch 8, gen_loss = -0.43303002575610544, disc_loss = 0.0014411833658252995
Trained batch 141 in epoch 8, gen_loss = -0.43306371401733074, disc_loss = 0.0014354642017409994
Trained batch 142 in epoch 8, gen_loss = -0.4335582402202633, disc_loss = 0.0014305570776658979
Trained batch 143 in epoch 8, gen_loss = -0.4338903021481302, disc_loss = 0.0014239913359940853
Trained batch 144 in epoch 8, gen_loss = -0.4339922952240911, disc_loss = 0.0014169328161595582
Trained batch 145 in epoch 8, gen_loss = -0.4342448460320904, disc_loss = 0.0014098707324592397
Trained batch 146 in epoch 8, gen_loss = -0.43461696854254017, disc_loss = 0.001403306794612586
Trained batch 147 in epoch 8, gen_loss = -0.4351881780737155, disc_loss = 0.001397731969592388
Trained batch 148 in epoch 8, gen_loss = -0.4356405452993892, disc_loss = 0.0013909792527947076
Trained batch 149 in epoch 8, gen_loss = -0.435794428785642, disc_loss = 0.001384421115120252
Trained batch 150 in epoch 8, gen_loss = -0.43601050183473045, disc_loss = 0.0013796767383345112
Trained batch 151 in epoch 8, gen_loss = -0.43615296071297244, disc_loss = 0.0013761927241974167
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = -0.4489886462688446, disc_loss = 0.0009964408818632364
Trained batch 1 in epoch 9, gen_loss = -0.45690634846687317, disc_loss = 0.0010610171593725681
Trained batch 2 in epoch 9, gen_loss = -0.45705511172612506, disc_loss = 0.0010362188719833891
Trained batch 3 in epoch 9, gen_loss = -0.4565696492791176, disc_loss = 0.0009946932113962248
Trained batch 4 in epoch 9, gen_loss = -0.4678847372531891, disc_loss = 0.0009734804392792284
Trained batch 5 in epoch 9, gen_loss = -0.46495143075784046, disc_loss = 0.0010586807135647784
Trained batch 6 in epoch 9, gen_loss = -0.4687671533652714, disc_loss = 0.0011136617228787924
Trained batch 7 in epoch 9, gen_loss = -0.4628854990005493, disc_loss = 0.001110523873649072
Trained batch 8 in epoch 9, gen_loss = -0.4589849048190647, disc_loss = 0.0010994910456550617
Trained batch 9 in epoch 9, gen_loss = -0.4588415950536728, disc_loss = 0.0010680095350835473
Trained batch 10 in epoch 9, gen_loss = -0.4649977548555894, disc_loss = 0.0010192404151894152
Trained batch 11 in epoch 9, gen_loss = -0.4661652197440465, disc_loss = 0.0009831082861637697
Trained batch 12 in epoch 9, gen_loss = -0.46258742534197295, disc_loss = 0.0009431800214000619
Trained batch 13 in epoch 9, gen_loss = -0.4620470085314342, disc_loss = 0.000915264045553548
Trained batch 14 in epoch 9, gen_loss = -0.46092836062113446, disc_loss = 0.0008972515429680546
Trained batch 15 in epoch 9, gen_loss = -0.46236141584813595, disc_loss = 0.0008964272965386044
Trained batch 16 in epoch 9, gen_loss = -0.4597950034281787, disc_loss = 0.0008847460951930022
Trained batch 17 in epoch 9, gen_loss = -0.46171582572989994, disc_loss = 0.0008805172789531449
Trained batch 18 in epoch 9, gen_loss = -0.4644413166924527, disc_loss = 0.0008741520026600675
Trained batch 19 in epoch 9, gen_loss = -0.46566700637340547, disc_loss = 0.0008807456062640995
Trained batch 20 in epoch 9, gen_loss = -0.4672064383824666, disc_loss = 0.0008914032119459339
Trained batch 21 in epoch 9, gen_loss = -0.4690881317312067, disc_loss = 0.000891126171071929
Trained batch 22 in epoch 9, gen_loss = -0.4717472091965053, disc_loss = 0.000872925103581308
Trained batch 23 in epoch 9, gen_loss = -0.4731011316180229, disc_loss = 0.0008842338696316195
Trained batch 24 in epoch 9, gen_loss = -0.4723290181159973, disc_loss = 0.0008762371260672807
Trained batch 25 in epoch 9, gen_loss = -0.4692197052332071, disc_loss = 0.0008695947740656825
Trained batch 26 in epoch 9, gen_loss = -0.46986619631449383, disc_loss = 0.0008576385573380523
Trained batch 27 in epoch 9, gen_loss = -0.46965596292700085, disc_loss = 0.0008660868250964475
Trained batch 28 in epoch 9, gen_loss = -0.47085815873639336, disc_loss = 0.0008641649760177423
Trained batch 29 in epoch 9, gen_loss = -0.47034016450246174, disc_loss = 0.0008592190647808214
Trained batch 30 in epoch 9, gen_loss = -0.4720009373080346, disc_loss = 0.0008512365992271131
Trained batch 31 in epoch 9, gen_loss = -0.47155945748090744, disc_loss = 0.0008388744836338446
Trained batch 32 in epoch 9, gen_loss = -0.47008906530611444, disc_loss = 0.000829478903059763
Trained batch 33 in epoch 9, gen_loss = -0.470413022181567, disc_loss = 0.00082075316030943
Trained batch 34 in epoch 9, gen_loss = -0.4688848521028246, disc_loss = 0.0008092583905506347
Trained batch 35 in epoch 9, gen_loss = -0.47014732079373467, disc_loss = 0.0008039633410387776
Trained batch 36 in epoch 9, gen_loss = -0.46953545551042297, disc_loss = 0.0008211127510671882
Trained batch 37 in epoch 9, gen_loss = -0.46863849068942826, disc_loss = 0.0008776461549323836
Trained batch 38 in epoch 9, gen_loss = -0.4689262906710307, disc_loss = 0.0009604854977880724
Trained batch 39 in epoch 9, gen_loss = -0.4688055828213692, disc_loss = 0.0010087464135722258
Trained batch 40 in epoch 9, gen_loss = -0.4693328432920503, disc_loss = 0.0010128011770841733
Trained batch 41 in epoch 9, gen_loss = -0.46978790561358136, disc_loss = 0.0010036725254308077
Trained batch 42 in epoch 9, gen_loss = -0.46993816869203436, disc_loss = 0.0009963619834093681
Trained batch 43 in epoch 9, gen_loss = -0.468694887377999, disc_loss = 0.0009932239508171651
Trained batch 44 in epoch 9, gen_loss = -0.46789933840433756, disc_loss = 0.0009812085397748484
Trained batch 45 in epoch 9, gen_loss = -0.467487883956536, disc_loss = 0.0009699488759708955
Trained batch 46 in epoch 9, gen_loss = -0.46830556050260014, disc_loss = 0.0009661500609697813
Trained batch 47 in epoch 9, gen_loss = -0.46817619167268276, disc_loss = 0.0009668183580894644
Trained batch 48 in epoch 9, gen_loss = -0.46702806377897454, disc_loss = 0.0009653118572064809
Trained batch 49 in epoch 9, gen_loss = -0.4671273446083069, disc_loss = 0.0009623626270331442
Trained batch 50 in epoch 9, gen_loss = -0.46739538627512317, disc_loss = 0.0009617205576825084
Trained batch 51 in epoch 9, gen_loss = -0.46801207730403316, disc_loss = 0.0009668446235501996
Trained batch 52 in epoch 9, gen_loss = -0.46873694433356233, disc_loss = 0.0009671857817766239
Trained batch 53 in epoch 9, gen_loss = -0.46866615723680566, disc_loss = 0.0009581021941913706
Trained batch 54 in epoch 9, gen_loss = -0.468911244652488, disc_loss = 0.0009501480164048685
Trained batch 55 in epoch 9, gen_loss = -0.4694279943193708, disc_loss = 0.0009407700381416362
Trained batch 56 in epoch 9, gen_loss = -0.46866047120930854, disc_loss = 0.0009319348610006273
Trained batch 57 in epoch 9, gen_loss = -0.46873740029746086, disc_loss = 0.000927701743986008
Trained batch 58 in epoch 9, gen_loss = -0.4691626712427301, disc_loss = 0.0009190028980255948
Trained batch 59 in epoch 9, gen_loss = -0.46881729960441587, disc_loss = 0.0009306258332799188
Trained batch 60 in epoch 9, gen_loss = -0.469673825092003, disc_loss = 0.0009366993980337179
Trained batch 61 in epoch 9, gen_loss = -0.46936935570932203, disc_loss = 0.0009441108113312493
Trained batch 62 in epoch 9, gen_loss = -0.47023898268502856, disc_loss = 0.0009377286164274824
Trained batch 63 in epoch 9, gen_loss = -0.47004796750843525, disc_loss = 0.0009336680809610698
Trained batch 64 in epoch 9, gen_loss = -0.4689446311730605, disc_loss = 0.0009574796104481301
Trained batch 65 in epoch 9, gen_loss = -0.4686763236920039, disc_loss = 0.0009953078640109832
Trained batch 66 in epoch 9, gen_loss = -0.4684134441525189, disc_loss = 0.001027479350354884
Trained batch 67 in epoch 9, gen_loss = -0.4698059957693605, disc_loss = 0.0010346774219857145
Trained batch 68 in epoch 9, gen_loss = -0.4702794176080953, disc_loss = 0.001035334437366818
Trained batch 69 in epoch 9, gen_loss = -0.46970566383429935, disc_loss = 0.0010438790008525497
Trained batch 70 in epoch 9, gen_loss = -0.47028806134009027, disc_loss = 0.001048742073283098
Trained batch 71 in epoch 9, gen_loss = -0.47057465091347694, disc_loss = 0.0010612998072853468
Trained batch 72 in epoch 9, gen_loss = -0.4706125226739335, disc_loss = 0.0010755995957480668
Trained batch 73 in epoch 9, gen_loss = -0.4709557323036967, disc_loss = 0.0010770252127848515
Trained batch 74 in epoch 9, gen_loss = -0.4712052094936371, disc_loss = 0.0010737661020054172
Trained batch 75 in epoch 9, gen_loss = -0.47117732347626434, disc_loss = 0.001067969678077038
Trained batch 76 in epoch 9, gen_loss = -0.4712407306417242, disc_loss = 0.0010634225429573955
Trained batch 77 in epoch 9, gen_loss = -0.47163523122286183, disc_loss = 0.0010582830242735024
Trained batch 78 in epoch 9, gen_loss = -0.47109066346023654, disc_loss = 0.0010539351095286305
Trained batch 79 in epoch 9, gen_loss = -0.471408386901021, disc_loss = 0.0010519674291572302
Trained batch 80 in epoch 9, gen_loss = -0.4713164748233042, disc_loss = 0.0010520884214561248
Trained batch 81 in epoch 9, gen_loss = -0.4717882184720621, disc_loss = 0.0010540935721265424
Trained batch 82 in epoch 9, gen_loss = -0.47258605906762274, disc_loss = 0.0010473207659677166
Trained batch 83 in epoch 9, gen_loss = -0.4728919193148613, disc_loss = 0.0010433115707460924
Trained batch 84 in epoch 9, gen_loss = -0.47303504207554986, disc_loss = 0.0010454589552382992
Trained batch 85 in epoch 9, gen_loss = -0.47281261620133425, disc_loss = 0.0010551932064117864
Trained batch 86 in epoch 9, gen_loss = -0.4732498297061043, disc_loss = 0.001078149999275097
Trained batch 87 in epoch 9, gen_loss = -0.4736358357424086, disc_loss = 0.001107733548203462
Trained batch 88 in epoch 9, gen_loss = -0.473758105146751, disc_loss = 0.001135473696480955
Trained batch 89 in epoch 9, gen_loss = -0.47448837127950455, disc_loss = 0.0011540668728735504
Trained batch 90 in epoch 9, gen_loss = -0.4754423744730897, disc_loss = 0.0011609520127991684
Trained batch 91 in epoch 9, gen_loss = -0.47564709478098416, disc_loss = 0.001160185805296667
Trained batch 92 in epoch 9, gen_loss = -0.47607846189570685, disc_loss = 0.0011566821157166193
Trained batch 93 in epoch 9, gen_loss = -0.47638450689772344, disc_loss = 0.0011511740316215784
Trained batch 94 in epoch 9, gen_loss = -0.4766537606716156, disc_loss = 0.001145207313636906
Trained batch 95 in epoch 9, gen_loss = -0.47694954307128984, disc_loss = 0.0011396810214137076
Trained batch 96 in epoch 9, gen_loss = -0.47682034877157703, disc_loss = 0.0011373480122426006
Trained batch 97 in epoch 9, gen_loss = -0.4771028966928015, disc_loss = 0.001137398687317226
Trained batch 98 in epoch 9, gen_loss = -0.4770677020453443, disc_loss = 0.0011418611402129472
Trained batch 99 in epoch 9, gen_loss = -0.4772171413898468, disc_loss = 0.0011440533088170923
Trained batch 100 in epoch 9, gen_loss = -0.4768308634215062, disc_loss = 0.0011445424144299202
Trained batch 101 in epoch 9, gen_loss = -0.4773390366166246, disc_loss = 0.0011430289416560246
Trained batch 102 in epoch 9, gen_loss = -0.4769706598763327, disc_loss = 0.0011406419242085727
Trained batch 103 in epoch 9, gen_loss = -0.4766610889480664, disc_loss = 0.001136350400394384
Trained batch 104 in epoch 9, gen_loss = -0.47674058051336377, disc_loss = 0.0011331991688902712
Trained batch 105 in epoch 9, gen_loss = -0.4767692592346443, disc_loss = 0.0011273455745123221
Trained batch 106 in epoch 9, gen_loss = -0.4762450464975054, disc_loss = 0.0011239368253644277
Trained batch 107 in epoch 9, gen_loss = -0.47596736942176465, disc_loss = 0.0011176785135628758
Trained batch 108 in epoch 9, gen_loss = -0.47583494902750767, disc_loss = 0.001125916805803998
Trained batch 109 in epoch 9, gen_loss = -0.47612287971106443, disc_loss = 0.0011399266598428684
Trained batch 110 in epoch 9, gen_loss = -0.47655709665100854, disc_loss = 0.0011556237479273296
Trained batch 111 in epoch 9, gen_loss = -0.47678538917430807, disc_loss = 0.0011639276981441071
Trained batch 112 in epoch 9, gen_loss = -0.47776090755926826, disc_loss = 0.0011691866605851667
Trained batch 113 in epoch 9, gen_loss = -0.4776322561920735, disc_loss = 0.0011752219046078
Trained batch 114 in epoch 9, gen_loss = -0.4775647917519445, disc_loss = 0.0011750881775262076
Trained batch 115 in epoch 9, gen_loss = -0.47749946883012506, disc_loss = 0.0011718036034365248
Trained batch 116 in epoch 9, gen_loss = -0.4772548889502501, disc_loss = 0.0011668799553985875
Trained batch 117 in epoch 9, gen_loss = -0.4777224169949354, disc_loss = 0.00116075702742634
Trained batch 118 in epoch 9, gen_loss = -0.47782980919886037, disc_loss = 0.0011555670074308525
Trained batch 119 in epoch 9, gen_loss = -0.4780913618703683, disc_loss = 0.0011498147119709755
Trained batch 120 in epoch 9, gen_loss = -0.4783664195498159, disc_loss = 0.0011443270328031344
Trained batch 121 in epoch 9, gen_loss = -0.4780404687416358, disc_loss = 0.0011404651249606224
Trained batch 122 in epoch 9, gen_loss = -0.4785930909276978, disc_loss = 0.0011349138929186828
Trained batch 123 in epoch 9, gen_loss = -0.4790989970487933, disc_loss = 0.0011316373802988128
Trained batch 124 in epoch 9, gen_loss = -0.4792531917095184, disc_loss = 0.0011321934701409191
Trained batch 125 in epoch 9, gen_loss = -0.4797696989207041, disc_loss = 0.0011314495394120939
Trained batch 126 in epoch 9, gen_loss = -0.47942552486742573, disc_loss = 0.0011290518352010206
Trained batch 127 in epoch 9, gen_loss = -0.47953706071712077, disc_loss = 0.0011247716945490538
Trained batch 128 in epoch 9, gen_loss = -0.47956194410952485, disc_loss = 0.001119134065743839
Trained batch 129 in epoch 9, gen_loss = -0.47990092841478493, disc_loss = 0.001114271508413367
Trained batch 130 in epoch 9, gen_loss = -0.4805445750706068, disc_loss = 0.0011091657528984325
Trained batch 131 in epoch 9, gen_loss = -0.48078057824662235, disc_loss = 0.0011056877558461786
Trained batch 132 in epoch 9, gen_loss = -0.4808793292009741, disc_loss = 0.0011080117185890703
Trained batch 133 in epoch 9, gen_loss = -0.4807398225834121, disc_loss = 0.001108409286304655
Trained batch 134 in epoch 9, gen_loss = -0.4812620304248951, disc_loss = 0.001106854687936397
Trained batch 135 in epoch 9, gen_loss = -0.4811305199914119, disc_loss = 0.001105521074778688
Trained batch 136 in epoch 9, gen_loss = -0.4817536901818575, disc_loss = 0.001103198830247347
Trained batch 137 in epoch 9, gen_loss = -0.4819133033355077, disc_loss = 0.0011015277707264286
Trained batch 138 in epoch 9, gen_loss = -0.4818694703012919, disc_loss = 0.0010965939185317445
Trained batch 139 in epoch 9, gen_loss = -0.4825230598449707, disc_loss = 0.0010943715616511846
Trained batch 140 in epoch 9, gen_loss = -0.48286482459264446, disc_loss = 0.0010951187002145625
Trained batch 141 in epoch 9, gen_loss = -0.4826075002341203, disc_loss = 0.001093779244783177
Trained batch 142 in epoch 9, gen_loss = -0.48292035864783334, disc_loss = 0.0010896511776844965
Trained batch 143 in epoch 9, gen_loss = -0.48322514403197503, disc_loss = 0.0010857737634069053
Trained batch 144 in epoch 9, gen_loss = -0.48320273119827795, disc_loss = 0.0010817390511310178
Trained batch 145 in epoch 9, gen_loss = -0.4834250991475092, disc_loss = 0.00107981866661759
Trained batch 146 in epoch 9, gen_loss = -0.48355832918971575, disc_loss = 0.0010782498420852864
Trained batch 147 in epoch 9, gen_loss = -0.4835743569844478, disc_loss = 0.0010753834053380037
Trained batch 148 in epoch 9, gen_loss = -0.4834363496543577, disc_loss = 0.0010736443462934745
Trained batch 149 in epoch 9, gen_loss = -0.4832547652721405, disc_loss = 0.0010715940833324568
Trained batch 150 in epoch 9, gen_loss = -0.48337980887747756, disc_loss = 0.0010689890622361778
Trained batch 151 in epoch 9, gen_loss = -0.4837302620473661, disc_loss = 0.0010645143727168417
Testing Epoch 9
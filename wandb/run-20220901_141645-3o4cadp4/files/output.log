wandb: WARNING Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 0.5731017589569092, disc_loss = 0.7669799327850342
Trained batch 1 in epoch 0, gen_loss = 0.584461897611618, disc_loss = 0.8232703506946564
Trained batch 2 in epoch 0, gen_loss = 0.5561984678109487, disc_loss = 0.6927520533402761
Trained batch 3 in epoch 0, gen_loss = 0.5185876414179802, disc_loss = 0.6057639494538307
Trained batch 4 in epoch 0, gen_loss = 0.49325422644615174, disc_loss = 0.5381218254566192
Trained batch 5 in epoch 0, gen_loss = 0.472263182202975, disc_loss = 0.48956390966971713
Trained batch 6 in epoch 0, gen_loss = 0.4743476467473166, disc_loss = 0.44748924672603607
Trained batch 7 in epoch 0, gen_loss = 0.47585783153772354, disc_loss = 0.41138929314911366
Trained batch 8 in epoch 0, gen_loss = 0.4745909306738112, disc_loss = 0.3804767926534017
Trained batch 9 in epoch 0, gen_loss = 0.47273009121417997, disc_loss = 0.35612141489982607
Trained batch 10 in epoch 0, gen_loss = 0.47430361130020837, disc_loss = 0.33630278977480804
Trained batch 11 in epoch 0, gen_loss = 0.47621677070856094, disc_loss = 0.32005008558432263
Trained batch 12 in epoch 0, gen_loss = 0.47195594356610227, disc_loss = 0.3048488778563646
Trained batch 13 in epoch 0, gen_loss = 0.47473747602530886, disc_loss = 0.2951986518289362
Trained batch 14 in epoch 0, gen_loss = 0.48032256166140236, disc_loss = 0.286138146619002
Trained batch 15 in epoch 0, gen_loss = 0.47808939032256603, disc_loss = 0.2801498263143003
Trained batch 16 in epoch 0, gen_loss = 0.4757264028577244, disc_loss = 0.2824523462092175
Trained batch 17 in epoch 0, gen_loss = 0.47746363116635215, disc_loss = 0.2762462774084674
Trained batch 18 in epoch 0, gen_loss = 0.4814422114899284, disc_loss = 0.2736081202563487
Trained batch 19 in epoch 0, gen_loss = 0.48177827149629593, disc_loss = 0.27249447293579576
Trained batch 20 in epoch 0, gen_loss = 0.48128452045576914, disc_loss = 0.26702804402226493
Trained batch 21 in epoch 0, gen_loss = 0.4818908680569042, disc_loss = 0.26230243695053185
Trained batch 22 in epoch 0, gen_loss = 0.48140877874001214, disc_loss = 0.2581166064609652
Trained batch 23 in epoch 0, gen_loss = 0.48091931516925496, disc_loss = 0.25449609849601984
Trained batch 24 in epoch 0, gen_loss = 0.4819225680828094, disc_loss = 0.2529203334450722
Trained batch 25 in epoch 0, gen_loss = 0.4806492683979181, disc_loss = 0.25470513936418754
Trained batch 26 in epoch 0, gen_loss = 0.48351676265398663, disc_loss = 0.2570568083061112
Trained batch 27 in epoch 0, gen_loss = 0.4832566540156092, disc_loss = 0.25361078046262264
Trained batch 28 in epoch 0, gen_loss = 0.4828386615062582, disc_loss = 0.25267117264969596
Trained batch 29 in epoch 0, gen_loss = 0.48275836606820427, disc_loss = 0.25653631165623664
Trained batch 30 in epoch 0, gen_loss = 0.4824408706157438, disc_loss = 0.2540615265888552
Trained batch 31 in epoch 0, gen_loss = 0.4817822203040123, disc_loss = 0.251024923985824
Trained batch 32 in epoch 0, gen_loss = 0.4787102702892188, disc_loss = 0.24851799801443564
Trained batch 33 in epoch 0, gen_loss = 0.47661037567783804, disc_loss = 0.24581433810731945
Trained batch 34 in epoch 0, gen_loss = 0.47683539305414474, disc_loss = 0.24199183817420686
Trained batch 35 in epoch 0, gen_loss = 0.478104878630903, disc_loss = 0.238088338325421
Trained batch 36 in epoch 0, gen_loss = 0.4782454854733235, disc_loss = 0.23563994386711637
Trained batch 37 in epoch 0, gen_loss = 0.48081274095334503, disc_loss = 0.23194160763370364
Trained batch 38 in epoch 0, gen_loss = 0.48023236714876616, disc_loss = 0.23057614935514253
Trained batch 39 in epoch 0, gen_loss = 0.4784164600074291, disc_loss = 0.2339739168062806
Trained batch 40 in epoch 0, gen_loss = 0.4801234595659303, disc_loss = 0.23080147639280413
Trained batch 41 in epoch 0, gen_loss = 0.48212090063662755, disc_loss = 0.2284160346857139
Trained batch 42 in epoch 0, gen_loss = 0.48418443216833956, disc_loss = 0.2249960020877594
Trained batch 43 in epoch 0, gen_loss = 0.48378374495289544, disc_loss = 0.22164632634005763
Trained batch 44 in epoch 0, gen_loss = 0.4845547689331902, disc_loss = 0.21827018592092726
Trained batch 45 in epoch 0, gen_loss = 0.48503775959429535, disc_loss = 0.21510050283825916
Trained batch 46 in epoch 0, gen_loss = 0.48602678420695855, disc_loss = 0.2124954790193984
Trained batch 47 in epoch 0, gen_loss = 0.4862386838843425, disc_loss = 0.2107521554765602
Trained batch 48 in epoch 0, gen_loss = 0.48765381075897996, disc_loss = 0.2102309828814195
Trained batch 49 in epoch 0, gen_loss = 0.4869891887903213, disc_loss = 0.21175001248717307
Trained batch 50 in epoch 0, gen_loss = 0.4883570361371134, disc_loss = 0.2095892994719393
Trained batch 51 in epoch 0, gen_loss = 0.4889347879932477, disc_loss = 0.20687843658603156
Trained batch 52 in epoch 0, gen_loss = 0.48929832172843646, disc_loss = 0.2048210954328753
Trained batch 53 in epoch 0, gen_loss = 0.49077097409301335, disc_loss = 0.20361254998931178
Trained batch 54 in epoch 0, gen_loss = 0.4890219498764385, disc_loss = 0.20228453928774054
Trained batch 55 in epoch 0, gen_loss = 0.48829905316233635, disc_loss = 0.20032211792256152
Trained batch 56 in epoch 0, gen_loss = 0.4883462133114798, disc_loss = 0.19893937335725417
Trained batch 57 in epoch 0, gen_loss = 0.4899341695267579, disc_loss = 0.19699831820767502
Trained batch 58 in epoch 0, gen_loss = 0.4902162930722964, disc_loss = 0.19562879785642787
Trained batch 59 in epoch 0, gen_loss = 0.4906827971339226, disc_loss = 0.19698693032066028
Trained batch 60 in epoch 0, gen_loss = 0.49182954235155074, disc_loss = 0.20536604548086884
Trained batch 61 in epoch 0, gen_loss = 0.4920857063224239, disc_loss = 0.20515095730943064
Trained batch 62 in epoch 0, gen_loss = 0.49210176581428167, disc_loss = 0.20518922285428123
Trained batch 63 in epoch 0, gen_loss = 0.4921573488973081, disc_loss = 0.2050871925894171
Trained batch 64 in epoch 0, gen_loss = 0.4920248636832604, disc_loss = 0.20398127184464382
Trained batch 65 in epoch 0, gen_loss = 0.49093586838606634, disc_loss = 0.2031712859417453
Trained batch 66 in epoch 0, gen_loss = 0.48928556202062917, disc_loss = 0.20232858920275276
Trained batch 67 in epoch 0, gen_loss = 0.48859160086687875, disc_loss = 0.20382493493311546
Trained batch 68 in epoch 0, gen_loss = 0.489210932151131, disc_loss = 0.2063178391992182
Trained batch 69 in epoch 0, gen_loss = 0.48919506541320257, disc_loss = 0.20625537101711547
Trained batch 70 in epoch 0, gen_loss = 0.4893670757891427, disc_loss = 0.20616296101623857
Trained batch 71 in epoch 0, gen_loss = 0.4889769707289007, disc_loss = 0.2050040134539207
Trained batch 72 in epoch 0, gen_loss = 0.4877700870984221, disc_loss = 0.2037345671082196
Trained batch 73 in epoch 0, gen_loss = 0.4872394751858067, disc_loss = 0.20305805935247526
Trained batch 74 in epoch 0, gen_loss = 0.4865313430627187, disc_loss = 0.20244132856527963
Trained batch 75 in epoch 0, gen_loss = 0.48645171327026265, disc_loss = 0.2017101314114897
Trained batch 76 in epoch 0, gen_loss = 0.485656277699904, disc_loss = 0.2007883723293032
Trained batch 77 in epoch 0, gen_loss = 0.48574850077812487, disc_loss = 0.20040913308278108
Trained batch 78 in epoch 0, gen_loss = 0.48606776323499556, disc_loss = 0.20166406789912453
Trained batch 79 in epoch 0, gen_loss = 0.48534707017242906, disc_loss = 0.20328424088656902
Trained batch 80 in epoch 0, gen_loss = 0.4850173471150575, disc_loss = 0.2041917829601853
Trained batch 81 in epoch 0, gen_loss = 0.4850847146859983, disc_loss = 0.20527371291707203
Trained batch 82 in epoch 0, gen_loss = 0.4848288495138467, disc_loss = 0.2062597766698125
Trained batch 83 in epoch 0, gen_loss = 0.48469127466281253, disc_loss = 0.20652070535080774
Trained batch 84 in epoch 0, gen_loss = 0.48380212222828584, disc_loss = 0.20694528046776267
Trained batch 85 in epoch 0, gen_loss = 0.4833919787129691, disc_loss = 0.20723770298930103
Trained batch 86 in epoch 0, gen_loss = 0.4833571311386152, disc_loss = 0.20734818502404223
Trained batch 87 in epoch 0, gen_loss = 0.4828522601588206, disc_loss = 0.20706398971378803
Trained batch 88 in epoch 0, gen_loss = 0.483113490128785, disc_loss = 0.20652719762887847
Trained batch 89 in epoch 0, gen_loss = 0.48320980899863775, disc_loss = 0.20637022372749117
Trained batch 90 in epoch 0, gen_loss = 0.48258883776245537, disc_loss = 0.20637529367928978
Trained batch 91 in epoch 0, gen_loss = 0.4831840774935225, disc_loss = 0.2069787376600763
Trained batch 92 in epoch 0, gen_loss = 0.4834745587200247, disc_loss = 0.2070646204294697
Trained batch 93 in epoch 0, gen_loss = 0.4835700164449976, disc_loss = 0.20754693559509643
Trained batch 94 in epoch 0, gen_loss = 0.4836035104174363, disc_loss = 0.20945885542191958
Trained batch 95 in epoch 0, gen_loss = 0.48340953203539055, disc_loss = 0.21033115545287728
Trained batch 96 in epoch 0, gen_loss = 0.48320397703917983, disc_loss = 0.21070634965429602
Trained batch 97 in epoch 0, gen_loss = 0.4823709282339836, disc_loss = 0.21084113814392869
Trained batch 98 in epoch 0, gen_loss = 0.48185085588031346, disc_loss = 0.2109823582148311
Trained batch 99 in epoch 0, gen_loss = 0.4815506660938263, disc_loss = 0.21060710310935973
Trained batch 100 in epoch 0, gen_loss = 0.48115276464141243, disc_loss = 0.21013776353090116
Trained batch 101 in epoch 0, gen_loss = 0.481018044200598, disc_loss = 0.20972857463593578
Trained batch 102 in epoch 0, gen_loss = 0.48086042398387946, disc_loss = 0.2094546967339747
Trained batch 103 in epoch 0, gen_loss = 0.47956203354092747, disc_loss = 0.20951168038524115
Trained batch 104 in epoch 0, gen_loss = 0.47911811073621113, disc_loss = 0.21042911410331727
Trained batch 105 in epoch 0, gen_loss = 0.4796488585899461, disc_loss = 0.21340047610255908
Trained batch 106 in epoch 0, gen_loss = 0.47906213274625975, disc_loss = 0.21453406236996161
Trained batch 107 in epoch 0, gen_loss = 0.4780607463585006, disc_loss = 0.21558384238569825
Trained batch 108 in epoch 0, gen_loss = 0.47742770024395864, disc_loss = 0.21604176699568373
Trained batch 109 in epoch 0, gen_loss = 0.47689981921152635, disc_loss = 0.21634359657764435
Trained batch 110 in epoch 0, gen_loss = 0.47668009003003436, disc_loss = 0.21636251125249778
Trained batch 111 in epoch 0, gen_loss = 0.47570293503148214, disc_loss = 0.21609858183988503
Trained batch 112 in epoch 0, gen_loss = 0.4757962706869682, disc_loss = 0.21565304999857876
Trained batch 113 in epoch 0, gen_loss = 0.47556060029749286, disc_loss = 0.21518656284662716
Trained batch 114 in epoch 0, gen_loss = 0.4751671669275864, disc_loss = 0.21452817048715508
Trained batch 115 in epoch 0, gen_loss = 0.47456197183707666, disc_loss = 0.21392325594507414
Trained batch 116 in epoch 0, gen_loss = 0.47459424331656885, disc_loss = 0.21368107861942714
Trained batch 117 in epoch 0, gen_loss = 0.4747483126692853, disc_loss = 0.2138208634519981
Trained batch 118 in epoch 0, gen_loss = 0.474189198317648, disc_loss = 0.21379307363213612
Trained batch 119 in epoch 0, gen_loss = 0.4732874679068724, disc_loss = 0.21472216099500657
Trained batch 120 in epoch 0, gen_loss = 0.47328233201641684, disc_loss = 0.21589591852889572
Trained batch 121 in epoch 0, gen_loss = 0.4735610243238387, disc_loss = 0.21663958078525106
Trained batch 122 in epoch 0, gen_loss = 0.4733666733997624, disc_loss = 0.21663800875345865
Trained batch 123 in epoch 0, gen_loss = 0.47246687378614177, disc_loss = 0.21649452166691904
Trained batch 124 in epoch 0, gen_loss = 0.47232114481925963, disc_loss = 0.21626989805698396
Trained batch 125 in epoch 0, gen_loss = 0.4716879782222566, disc_loss = 0.2161404551967742
Trained batch 126 in epoch 0, gen_loss = 0.4710401920821723, disc_loss = 0.21573272464782234
Trained batch 127 in epoch 0, gen_loss = 0.47036160971038043, disc_loss = 0.21555251721292734
Trained batch 128 in epoch 0, gen_loss = 0.4695178616878598, disc_loss = 0.21531558394894118
Trained batch 129 in epoch 0, gen_loss = 0.4687496338899319, disc_loss = 0.2149176993049108
Trained batch 130 in epoch 0, gen_loss = 0.46787657059785975, disc_loss = 0.21483963545952134
Trained batch 131 in epoch 0, gen_loss = 0.4677709133336038, disc_loss = 0.21461867416898409
Trained batch 132 in epoch 0, gen_loss = 0.4671280733624795, disc_loss = 0.21466422069789773
Trained batch 133 in epoch 0, gen_loss = 0.4672984810017828, disc_loss = 0.21426871752561027
Trained batch 134 in epoch 0, gen_loss = 0.46708370160173485, disc_loss = 0.21445164702556752
Trained batch 135 in epoch 0, gen_loss = 0.4673456735908985, disc_loss = 0.21445532230769887
Trained batch 136 in epoch 0, gen_loss = 0.46742907231741576, disc_loss = 0.21465236796949902
Trained batch 137 in epoch 0, gen_loss = 0.46716403183729754, disc_loss = 0.21494434061257736
Trained batch 138 in epoch 0, gen_loss = 0.4670285814100032, disc_loss = 0.21565139593837931
Trained batch 139 in epoch 0, gen_loss = 0.4671751175607954, disc_loss = 0.21580177300742695
Trained batch 140 in epoch 0, gen_loss = 0.4665965196934152, disc_loss = 0.2157402733961741
Trained batch 141 in epoch 0, gen_loss = 0.46632438751173694, disc_loss = 0.21579359387847738
Trained batch 142 in epoch 0, gen_loss = 0.4657783852173732, disc_loss = 0.21632614690107066
Trained batch 143 in epoch 0, gen_loss = 0.46560805353025597, disc_loss = 0.21654931124713686
Trained batch 144 in epoch 0, gen_loss = 0.4652507317477259, disc_loss = 0.21679872562145364
Trained batch 145 in epoch 0, gen_loss = 0.4649876443898841, disc_loss = 0.21720124107517608
Trained batch 146 in epoch 0, gen_loss = 0.4646374479848511, disc_loss = 0.2173561957620439
Trained batch 147 in epoch 0, gen_loss = 0.46458782920160807, disc_loss = 0.2174755400298415
Trained batch 148 in epoch 0, gen_loss = 0.4643314998821924, disc_loss = 0.2175839874368386
Trained batch 149 in epoch 0, gen_loss = 0.4650743148724238, disc_loss = 0.21752173751592635
Trained batch 150 in epoch 0, gen_loss = 0.46523569968362516, disc_loss = 0.21755684922073062
Trained batch 151 in epoch 0, gen_loss = 0.46468841755076457, disc_loss = 0.21742807289487437
Trained batch 152 in epoch 0, gen_loss = 0.4648900930008857, disc_loss = 0.21730650377039815
Trained batch 153 in epoch 0, gen_loss = 0.4643647428843882, disc_loss = 0.21765595277795544
Trained batch 154 in epoch 0, gen_loss = 0.4639553912224308, disc_loss = 0.21791792290825998
Trained batch 155 in epoch 0, gen_loss = 0.4638825167830174, disc_loss = 0.21788594957727653
Trained batch 156 in epoch 0, gen_loss = 0.46362493657002785, disc_loss = 0.2179221682677603
Trained batch 157 in epoch 0, gen_loss = 0.4634476520969898, disc_loss = 0.21840408453835716
Trained batch 158 in epoch 0, gen_loss = 0.4633757232120202, disc_loss = 0.21859426018576952
Trained batch 159 in epoch 0, gen_loss = 0.4632772672921419, disc_loss = 0.21861494816839694
Trained batch 160 in epoch 0, gen_loss = 0.4627370267921353, disc_loss = 0.21852329678787208
Trained batch 161 in epoch 0, gen_loss = 0.462409406532476, disc_loss = 0.21858839828658988
Trained batch 162 in epoch 0, gen_loss = 0.4621987876716567, disc_loss = 0.21863161493664138
Trained batch 163 in epoch 0, gen_loss = 0.4620604486000247, disc_loss = 0.2185298873157036
Trained batch 164 in epoch 0, gen_loss = 0.4618546697226438, disc_loss = 0.21839048564434052
Trained batch 165 in epoch 0, gen_loss = 0.4613975622208722, disc_loss = 0.2183192809482655
Trained batch 166 in epoch 0, gen_loss = 0.46087209353903813, disc_loss = 0.2182272450474208
Trained batch 167 in epoch 0, gen_loss = 0.46072994190312566, disc_loss = 0.21802935731552897
Trained batch 168 in epoch 0, gen_loss = 0.4603201694037082, disc_loss = 0.21795936263877258
Trained batch 169 in epoch 0, gen_loss = 0.45996876253801233, disc_loss = 0.21805157845511156
Trained batch 170 in epoch 0, gen_loss = 0.45974535900249813, disc_loss = 0.2183237292787485
Trained batch 171 in epoch 0, gen_loss = 0.4593081074052079, disc_loss = 0.2182204083128031
Trained batch 172 in epoch 0, gen_loss = 0.4592277374915305, disc_loss = 0.2188699925049192
Trained batch 173 in epoch 0, gen_loss = 0.4599184063316762, disc_loss = 0.21965670457174039
Trained batch 174 in epoch 0, gen_loss = 0.45966988733836583, disc_loss = 0.2196607609306063
Trained batch 175 in epoch 0, gen_loss = 0.45959965529089625, disc_loss = 0.21977251971309836
Trained batch 176 in epoch 0, gen_loss = 0.45941007861309807, disc_loss = 0.21950948280466479
Trained batch 177 in epoch 0, gen_loss = 0.4594707038630261, disc_loss = 0.21920523633447925
Trained batch 178 in epoch 0, gen_loss = 0.45923620961897865, disc_loss = 0.21901299267507798
Trained batch 179 in epoch 0, gen_loss = 0.4591119964917501, disc_loss = 0.21876454510622553
Trained batch 180 in epoch 0, gen_loss = 0.45883984015791457, disc_loss = 0.2186803672030486
Trained batch 181 in epoch 0, gen_loss = 0.45872432468356666, disc_loss = 0.21862091959177793
Trained batch 182 in epoch 0, gen_loss = 0.4586508430418421, disc_loss = 0.21840928779925153
Trained batch 183 in epoch 0, gen_loss = 0.45891866185095, disc_loss = 0.21832747951797818
Trained batch 184 in epoch 0, gen_loss = 0.4585573397778176, disc_loss = 0.21855470650904887
Trained batch 185 in epoch 0, gen_loss = 0.4586943644349293, disc_loss = 0.21857645651025157
Trained batch 186 in epoch 0, gen_loss = 0.45872870215120165, disc_loss = 0.21838018282212038
Trained batch 187 in epoch 0, gen_loss = 0.4585824770496247, disc_loss = 0.21816391553333464
Trained batch 188 in epoch 0, gen_loss = 0.4585807421220043, disc_loss = 0.21807561783248156
Trained batch 189 in epoch 0, gen_loss = 0.4583054881346853, disc_loss = 0.2181542024800652
Trained batch 190 in epoch 0, gen_loss = 0.45823214316243277, disc_loss = 0.21874197568568884
Trained batch 191 in epoch 0, gen_loss = 0.4585664017746846, disc_loss = 0.21943320240825415
Trained batch 192 in epoch 0, gen_loss = 0.4583205670272748, disc_loss = 0.2193712854632442
Trained batch 193 in epoch 0, gen_loss = 0.45791731913065176, disc_loss = 0.2196024885189902
Trained batch 194 in epoch 0, gen_loss = 0.4576763298266973, disc_loss = 0.21992157605978158
Trained batch 195 in epoch 0, gen_loss = 0.45733657737775724, disc_loss = 0.219940969074259
Trained batch 196 in epoch 0, gen_loss = 0.45733271924977376, disc_loss = 0.2199028542804234
Trained batch 197 in epoch 0, gen_loss = 0.45706821180353263, disc_loss = 0.21986817124516073
Trained batch 198 in epoch 0, gen_loss = 0.4568425918643798, disc_loss = 0.21978381560675464
Trained batch 199 in epoch 0, gen_loss = 0.45646490052342414, disc_loss = 0.21955475583672523
Trained batch 200 in epoch 0, gen_loss = 0.4559798802605909, disc_loss = 0.21943088839599742
Trained batch 201 in epoch 0, gen_loss = 0.4557120670186411, disc_loss = 0.21947052698619296
Trained batch 202 in epoch 0, gen_loss = 0.4557717053467417, disc_loss = 0.21921324884069376
Trained batch 203 in epoch 0, gen_loss = 0.4556834493197647, disc_loss = 0.21918931355079016
Trained batch 204 in epoch 0, gen_loss = 0.45552228790957755, disc_loss = 0.21917508666108293
Trained batch 205 in epoch 0, gen_loss = 0.45540843585741175, disc_loss = 0.21903476292647203
Trained batch 206 in epoch 0, gen_loss = 0.4551264188715801, disc_loss = 0.21903712608388082
Trained batch 207 in epoch 0, gen_loss = 0.4550358340717279, disc_loss = 0.21940854822213834
Trained batch 208 in epoch 0, gen_loss = 0.45467942511065723, disc_loss = 0.219051056216208
Trained batch 209 in epoch 0, gen_loss = 0.45495112722828274, disc_loss = 0.2189974640806516
Trained batch 210 in epoch 0, gen_loss = 0.4549567943783168, disc_loss = 0.21864721023640926
Trained batch 211 in epoch 0, gen_loss = 0.454719234187648, disc_loss = 0.21824071725022118
Trained batch 212 in epoch 0, gen_loss = 0.454599228263461, disc_loss = 0.21798024770799376
Trained batch 213 in epoch 0, gen_loss = 0.45439301612221195, disc_loss = 0.217669797486791
Trained batch 214 in epoch 0, gen_loss = 0.45423320490260455, disc_loss = 0.21743413591107658
Trained batch 215 in epoch 0, gen_loss = 0.45443121274864234, disc_loss = 0.2173760942424889
Trained batch 216 in epoch 0, gen_loss = 0.454045260419494, disc_loss = 0.21785416203435115
Trained batch 217 in epoch 0, gen_loss = 0.4541649536802134, disc_loss = 0.21897712411410217
Trained batch 218 in epoch 0, gen_loss = 0.4540601035231325, disc_loss = 0.2191372847856452
Trained batch 219 in epoch 0, gen_loss = 0.4538029948418791, disc_loss = 0.21916778107935733
Trained batch 220 in epoch 0, gen_loss = 0.45350005750742434, disc_loss = 0.21919998344522795
Trained batch 221 in epoch 0, gen_loss = 0.45344321362607115, disc_loss = 0.21913064761204762
Trained batch 222 in epoch 0, gen_loss = 0.4533811162138199, disc_loss = 0.21908519814634536
Trained batch 223 in epoch 0, gen_loss = 0.4531939100208027, disc_loss = 0.21891857623787864
Trained batch 224 in epoch 0, gen_loss = 0.45291684601042004, disc_loss = 0.21887991189956665
Trained batch 225 in epoch 0, gen_loss = 0.4528282763419953, disc_loss = 0.21881025132879747
Trained batch 226 in epoch 0, gen_loss = 0.45299543683224314, disc_loss = 0.21860741039467277
Trained batch 227 in epoch 0, gen_loss = 0.4529828941612913, disc_loss = 0.2184595161754834
Trained batch 228 in epoch 0, gen_loss = 0.4531794856729466, disc_loss = 0.21820717640058443
Trained batch 229 in epoch 0, gen_loss = 0.4528898500877878, disc_loss = 0.21802297895369321
Trained batch 230 in epoch 0, gen_loss = 0.45260031747095514, disc_loss = 0.21779610210166864
Trained batch 231 in epoch 0, gen_loss = 0.4525698463207689, disc_loss = 0.21765352066220908
Trained batch 232 in epoch 0, gen_loss = 0.4523034639368753, disc_loss = 0.21752016809109453
Trained batch 233 in epoch 0, gen_loss = 0.4522469260244288, disc_loss = 0.21740877265349412
Trained batch 234 in epoch 0, gen_loss = 0.45215988564998544, disc_loss = 0.2174220455453751
Trained batch 235 in epoch 0, gen_loss = 0.45238493761773835, disc_loss = 0.2174394955321894
Trained batch 236 in epoch 0, gen_loss = 0.4525473712617335, disc_loss = 0.2175415380846096
Trained batch 237 in epoch 0, gen_loss = 0.45248906877862305, disc_loss = 0.2173410993413765
Trained batch 238 in epoch 0, gen_loss = 0.4525023338435584, disc_loss = 0.21716929018248074
Trained batch 239 in epoch 0, gen_loss = 0.45252366612354916, disc_loss = 0.2170484367137154
Trained batch 240 in epoch 0, gen_loss = 0.4523135698187895, disc_loss = 0.2169249285924484
Trained batch 241 in epoch 0, gen_loss = 0.45218099037970394, disc_loss = 0.21682958255622012
Trained batch 242 in epoch 0, gen_loss = 0.45172459684281685, disc_loss = 0.21665186229556677
Trained batch 243 in epoch 0, gen_loss = 0.4513446372307715, disc_loss = 0.21659915063713417
Trained batch 244 in epoch 0, gen_loss = 0.4511621971519626, disc_loss = 0.21641960855649442
Trained batch 245 in epoch 0, gen_loss = 0.4512396211304316, disc_loss = 0.21630159377809463
Trained batch 246 in epoch 0, gen_loss = 0.45080914779713277, disc_loss = 0.21609431517268965
Trained batch 247 in epoch 0, gen_loss = 0.45076062962893515, disc_loss = 0.2160621861055974
Trained batch 248 in epoch 0, gen_loss = 0.450750607922374, disc_loss = 0.215780459194777
Trained batch 249 in epoch 0, gen_loss = 0.4507993814945221, disc_loss = 0.21565014809370042
Trained batch 250 in epoch 0, gen_loss = 0.4507121937683379, disc_loss = 0.2155308148181771
Trained batch 251 in epoch 0, gen_loss = 0.45087806904126726, disc_loss = 0.2155740268173672
Trained batch 252 in epoch 0, gen_loss = 0.4506358094366172, disc_loss = 0.2155191851227651
Trained batch 253 in epoch 0, gen_loss = 0.4506567870303402, disc_loss = 0.21535263627063572
Trained batch 254 in epoch 0, gen_loss = 0.4506535050915737, disc_loss = 0.2152967747519998
Trained batch 255 in epoch 0, gen_loss = 0.4506065803579986, disc_loss = 0.2158386834198609
Trained batch 256 in epoch 0, gen_loss = 0.4506683067820879, disc_loss = 0.21598704652099757
Trained batch 257 in epoch 0, gen_loss = 0.4505329226800638, disc_loss = 0.2158003399769465
Trained batch 258 in epoch 0, gen_loss = 0.4503727979871757, disc_loss = 0.2158572941903442
Trained batch 259 in epoch 0, gen_loss = 0.4503873060529049, disc_loss = 0.21574215029294674
Trained batch 260 in epoch 0, gen_loss = 0.4502110352232995, disc_loss = 0.21574999386323365
Trained batch 261 in epoch 0, gen_loss = 0.45005199756786113, disc_loss = 0.2159473836876964
Trained batch 262 in epoch 0, gen_loss = 0.44978861867701597, disc_loss = 0.21598049794313118
Trained batch 263 in epoch 0, gen_loss = 0.44992206719788636, disc_loss = 0.21577289079626402
Trained batch 264 in epoch 0, gen_loss = 0.44969637247751343, disc_loss = 0.21566055169645346
Trained batch 265 in epoch 0, gen_loss = 0.44937607108202193, disc_loss = 0.21551884285041265
Trained batch 266 in epoch 0, gen_loss = 0.4491890568411752, disc_loss = 0.21538420786125384
Trained batch 267 in epoch 0, gen_loss = 0.4490931641254852, disc_loss = 0.21521087424523794
Trained batch 268 in epoch 0, gen_loss = 0.4487872012928959, disc_loss = 0.21504746349770784
Trained batch 269 in epoch 0, gen_loss = 0.44880435135629443, disc_loss = 0.21475478421758723
Trained batch 270 in epoch 0, gen_loss = 0.44881311993757295, disc_loss = 0.21440994805515473
Trained batch 271 in epoch 0, gen_loss = 0.44865769060219035, disc_loss = 0.21428950875997543
Trained batch 272 in epoch 0, gen_loss = 0.44852116529321495, disc_loss = 0.2141329717614275
Trained batch 273 in epoch 0, gen_loss = 0.4483838384821467, disc_loss = 0.2140999399941333
Trained batch 274 in epoch 0, gen_loss = 0.44843249613588504, disc_loss = 0.2140373130278154
Trained batch 275 in epoch 0, gen_loss = 0.44846350116574246, disc_loss = 0.21385132586178573
Trained batch 276 in epoch 0, gen_loss = 0.4484376256431483, disc_loss = 0.21373957196512808
Trained batch 277 in epoch 0, gen_loss = 0.4483805893779659, disc_loss = 0.21430801921825615
Trained batch 278 in epoch 0, gen_loss = 0.44816269049935015, disc_loss = 0.21546908481360336
Trained batch 279 in epoch 0, gen_loss = 0.4483355308217662, disc_loss = 0.21547605549650534
Trained batch 280 in epoch 0, gen_loss = 0.44797380008731447, disc_loss = 0.2156010261103776
Trained batch 281 in epoch 0, gen_loss = 0.4477544596009221, disc_loss = 0.21551848752490171
Trained batch 282 in epoch 0, gen_loss = 0.4478004259903102, disc_loss = 0.21533791594496884
Trained batch 283 in epoch 0, gen_loss = 0.447797561510348, disc_loss = 0.21515972791633137
Trained batch 284 in epoch 0, gen_loss = 0.44758987531327366, disc_loss = 0.21489465252349252
Trained batch 285 in epoch 0, gen_loss = 0.44760914219842923, disc_loss = 0.2146127738214873
Trained batch 286 in epoch 0, gen_loss = 0.4474672878660807, disc_loss = 0.21429064615470608
Trained batch 287 in epoch 0, gen_loss = 0.447356594622963, disc_loss = 0.21409271409114203
Trained batch 288 in epoch 0, gen_loss = 0.44724955711397746, disc_loss = 0.213764270232623
Trained batch 289 in epoch 0, gen_loss = 0.4471000113363924, disc_loss = 0.21343941996837484
Trained batch 290 in epoch 0, gen_loss = 0.4469569810886973, disc_loss = 0.2132327453684561
Trained batch 291 in epoch 0, gen_loss = 0.44693296096504553, disc_loss = 0.21300927013771176
Trained batch 292 in epoch 0, gen_loss = 0.4468693395523488, disc_loss = 0.2127249754024447
Trained batch 293 in epoch 0, gen_loss = 0.446638906894087, disc_loss = 0.21239007687588937
Trained batch 294 in epoch 0, gen_loss = 0.4469105920549166, disc_loss = 0.21195712155204707
Trained batch 295 in epoch 0, gen_loss = 0.44682254350265943, disc_loss = 0.21168524837373076
Trained batch 296 in epoch 0, gen_loss = 0.44695942961808405, disc_loss = 0.21137819148173637
Trained batch 297 in epoch 0, gen_loss = 0.4467787367585521, disc_loss = 0.2109178589694452
Trained batch 298 in epoch 0, gen_loss = 0.4467661342891961, disc_loss = 0.2107383524095733
Trained batch 299 in epoch 0, gen_loss = 0.4468193777402242, disc_loss = 0.21119154542684554
Trained batch 300 in epoch 0, gen_loss = 0.44657392210738606, disc_loss = 0.2114370569240215
Trained batch 301 in epoch 0, gen_loss = 0.44633038716995166, disc_loss = 0.21142299996306566
Trained batch 302 in epoch 0, gen_loss = 0.44619359464535224, disc_loss = 0.2111820562346147
Trained batch 303 in epoch 0, gen_loss = 0.44580614704050514, disc_loss = 0.2110352900467421
Trained batch 304 in epoch 0, gen_loss = 0.4456452133225613, disc_loss = 0.21091283188491572
Trained batch 305 in epoch 0, gen_loss = 0.44569354859832067, disc_loss = 0.21075119545646742
Trained batch 306 in epoch 0, gen_loss = 0.44574747906833984, disc_loss = 0.21058839627508233
Trained batch 307 in epoch 0, gen_loss = 0.4460551037223308, disc_loss = 0.21028872230997334
Trained batch 308 in epoch 0, gen_loss = 0.44597144275421463, disc_loss = 0.21001612657867974
Trained batch 309 in epoch 0, gen_loss = 0.4458568378802269, disc_loss = 0.20978686872028535
Trained batch 310 in epoch 0, gen_loss = 0.4458858077549091, disc_loss = 0.209572772887742
Trained batch 311 in epoch 0, gen_loss = 0.4458283473474857, disc_loss = 0.20945649594068527
Trained batch 312 in epoch 0, gen_loss = 0.44548332243681715, disc_loss = 0.2095510267411558
Trained batch 313 in epoch 0, gen_loss = 0.4456083725212486, disc_loss = 0.2097579851082176
Trained batch 314 in epoch 0, gen_loss = 0.4453333656939249, disc_loss = 0.20997941049318464
Trained batch 315 in epoch 0, gen_loss = 0.4450813104646115, disc_loss = 0.21018087599850907
Trained batch 316 in epoch 0, gen_loss = 0.4449831959953067, disc_loss = 0.21022422061733642
Trained batch 317 in epoch 0, gen_loss = 0.44481682964840774, disc_loss = 0.21033918398356288
Trained batch 318 in epoch 0, gen_loss = 0.4448988529208312, disc_loss = 0.2104208673989885
Trained batch 319 in epoch 0, gen_loss = 0.444789351336658, disc_loss = 0.21046849982813
Trained batch 320 in epoch 0, gen_loss = 0.4448625558633299, disc_loss = 0.2105214924920014
Trained batch 321 in epoch 0, gen_loss = 0.4448331324210078, disc_loss = 0.21045992657634782
Trained batch 322 in epoch 0, gen_loss = 0.4445609257501714, disc_loss = 0.21028405653987506
Trained batch 323 in epoch 0, gen_loss = 0.44451450105802515, disc_loss = 0.2101455991282875
Trained batch 324 in epoch 0, gen_loss = 0.44443494613354023, disc_loss = 0.20989732650610116
Trained batch 325 in epoch 0, gen_loss = 0.4441540149823288, disc_loss = 0.20975844498060964
Trained batch 326 in epoch 0, gen_loss = 0.4443214532979038, disc_loss = 0.2094497921725661
Trained batch 327 in epoch 0, gen_loss = 0.44429845281127023, disc_loss = 0.2092922445750091
Trained batch 328 in epoch 0, gen_loss = 0.44422023301791275, disc_loss = 0.2091666477701222
Trained batch 329 in epoch 0, gen_loss = 0.4443686726418408, disc_loss = 0.20888827978210014
Trained batch 330 in epoch 0, gen_loss = 0.4443089287626779, disc_loss = 0.20873523174906064
Trained batch 331 in epoch 0, gen_loss = 0.44421643090535357, disc_loss = 0.20846368971628598
Trained batch 332 in epoch 0, gen_loss = 0.4441279903188482, disc_loss = 0.20833172273259978
Trained batch 333 in epoch 0, gen_loss = 0.44424495100975037, disc_loss = 0.20867903938818122
Trained batch 334 in epoch 0, gen_loss = 0.44389945161876393, disc_loss = 0.20867374092340468
Trained batch 335 in epoch 0, gen_loss = 0.44375852841351715, disc_loss = 0.2086951432616583
Trained batch 336 in epoch 0, gen_loss = 0.443844896218897, disc_loss = 0.2090620536257676
Trained batch 337 in epoch 0, gen_loss = 0.443815161578754, disc_loss = 0.20915093226633832
Trained batch 338 in epoch 0, gen_loss = 0.44362707238281723, disc_loss = 0.20900579489174143
Trained batch 339 in epoch 0, gen_loss = 0.4435939247117323, disc_loss = 0.20892645885400912
Trained batch 340 in epoch 0, gen_loss = 0.44347297253846424, disc_loss = 0.20890576431740765
Trained batch 341 in epoch 0, gen_loss = 0.44327407665768565, disc_loss = 0.20879075172961803
Trained batch 342 in epoch 0, gen_loss = 0.4429538731324777, disc_loss = 0.20876480562954533
Trained batch 343 in epoch 0, gen_loss = 0.44294866087824797, disc_loss = 0.20854889885197544
Trained batch 344 in epoch 0, gen_loss = 0.44309136573819147, disc_loss = 0.2084242837800496
Trained batch 345 in epoch 0, gen_loss = 0.4431663543158184, disc_loss = 0.2082531954124139
Trained batch 346 in epoch 0, gen_loss = 0.4429617447708801, disc_loss = 0.20788976249502442
Trained batch 347 in epoch 0, gen_loss = 0.44296331874940587, disc_loss = 0.20800127487244277
Trained batch 348 in epoch 0, gen_loss = 0.44318381814355495, disc_loss = 0.2081430322546672
Trained batch 349 in epoch 0, gen_loss = 0.44310924334185464, disc_loss = 0.2080119675397873
Trained batch 350 in epoch 0, gen_loss = 0.442858940261042, disc_loss = 0.20788047074252725
Trained batch 351 in epoch 0, gen_loss = 0.4427541070194407, disc_loss = 0.20771964313462377
Trained batch 352 in epoch 0, gen_loss = 0.4426315177770242, disc_loss = 0.2074853726385673
Trained batch 353 in epoch 0, gen_loss = 0.44260326894999896, disc_loss = 0.20729923648180934
Trained batch 354 in epoch 0, gen_loss = 0.44263916133155284, disc_loss = 0.20723556834207454
Trained batch 355 in epoch 0, gen_loss = 0.4427104742172059, disc_loss = 0.20710838050319907
Trained batch 356 in epoch 0, gen_loss = 0.4428279012525115, disc_loss = 0.20709200691776114
Trained batch 357 in epoch 0, gen_loss = 0.4427964727305833, disc_loss = 0.20713367970795604
Trained batch 358 in epoch 0, gen_loss = 0.44288509469842513, disc_loss = 0.2073926112528963
Trained batch 359 in epoch 0, gen_loss = 0.44284755885601046, disc_loss = 0.20721446126699447
Trained batch 360 in epoch 0, gen_loss = 0.4425867933810913, disc_loss = 0.20716245914099948
Trained batch 361 in epoch 0, gen_loss = 0.4426523105380285, disc_loss = 0.20701833217512836
Trained batch 362 in epoch 0, gen_loss = 0.4425959066582777, disc_loss = 0.2070119696625665
Trained batch 363 in epoch 0, gen_loss = 0.442570146377925, disc_loss = 0.20683074627931303
Trained batch 364 in epoch 0, gen_loss = 0.44253608535413874, disc_loss = 0.20673627249182086
Trained batch 365 in epoch 0, gen_loss = 0.44235955683585726, disc_loss = 0.20672528527147782
Trained batch 366 in epoch 0, gen_loss = 0.442126985954004, disc_loss = 0.2073863129200013
Trained batch 367 in epoch 0, gen_loss = 0.44219623473675357, disc_loss = 0.20800147019326687
Trained batch 368 in epoch 0, gen_loss = 0.44223631938621605, disc_loss = 0.2078755241099412
Trained batch 369 in epoch 0, gen_loss = 0.4421549174431208, disc_loss = 0.2079215906761788
Trained batch 370 in epoch 0, gen_loss = 0.44213982308007316, disc_loss = 0.20781154376316585
Trained batch 371 in epoch 0, gen_loss = 0.44210997592377405, disc_loss = 0.20774068246765803
Trained batch 372 in epoch 0, gen_loss = 0.44191661293321255, disc_loss = 0.20759067718369073
Trained batch 373 in epoch 0, gen_loss = 0.441708841027423, disc_loss = 0.20740001114772602
Trained batch 374 in epoch 0, gen_loss = 0.4417408598264058, disc_loss = 0.20736629784107208
Trained batch 375 in epoch 0, gen_loss = 0.44184314816239034, disc_loss = 0.20720038412416236
Trained batch 376 in epoch 0, gen_loss = 0.4418112904386748, disc_loss = 0.20697935476938673
Trained batch 377 in epoch 0, gen_loss = 0.44184249213763643, disc_loss = 0.2066710195331662
Trained batch 378 in epoch 0, gen_loss = 0.44164150041137334, disc_loss = 0.20655159630608746
Trained batch 379 in epoch 0, gen_loss = 0.4415640547087318, disc_loss = 0.20644932834333496
Trained batch 380 in epoch 0, gen_loss = 0.4415441538718116, disc_loss = 0.2063874888412283
Trained batch 381 in epoch 0, gen_loss = 0.44148790095177, disc_loss = 0.206253081150548
Trained batch 382 in epoch 0, gen_loss = 0.44134144216542454, disc_loss = 0.20602361889016224
Trained batch 383 in epoch 0, gen_loss = 0.4414133889755855, disc_loss = 0.20576041867025197
Trained batch 384 in epoch 0, gen_loss = 0.44148386562025393, disc_loss = 0.20600020351347986
Trained batch 385 in epoch 0, gen_loss = 0.4415637773553325, disc_loss = 0.20584284799858696
Trained batch 386 in epoch 0, gen_loss = 0.4415935977176794, disc_loss = 0.2057507818213421
Trained batch 387 in epoch 0, gen_loss = 0.4415921308484274, disc_loss = 0.20557664123546218
Trained batch 388 in epoch 0, gen_loss = 0.44141991999584484, disc_loss = 0.20541090102612514
Trained batch 389 in epoch 0, gen_loss = 0.44134594400723776, disc_loss = 0.205186338780018
Trained batch 390 in epoch 0, gen_loss = 0.4413054047338188, disc_loss = 0.20498042189709062
Trained batch 391 in epoch 0, gen_loss = 0.441276021453799, disc_loss = 0.20473349584760714
Trained batch 392 in epoch 0, gen_loss = 0.44138706079269485, disc_loss = 0.20444111220785072
Trained batch 393 in epoch 0, gen_loss = 0.4414212050928077, disc_loss = 0.20418935554659912
Trained batch 394 in epoch 0, gen_loss = 0.44152599490141564, disc_loss = 0.2039987499766712
Trained batch 395 in epoch 0, gen_loss = 0.441611784275132, disc_loss = 0.20394100205540056
Trained batch 396 in epoch 0, gen_loss = 0.44169614777456906, disc_loss = 0.2039649869580413
Trained batch 397 in epoch 0, gen_loss = 0.4414626422838949, disc_loss = 0.2038353731172468
Trained batch 398 in epoch 0, gen_loss = 0.4415060011366555, disc_loss = 0.20351599113908328
Trained batch 399 in epoch 0, gen_loss = 0.4416131801903248, disc_loss = 0.20331720473244785
Trained batch 400 in epoch 0, gen_loss = 0.44144434480001205, disc_loss = 0.20307715094074644
Trained batch 401 in epoch 0, gen_loss = 0.44154759307405844, disc_loss = 0.20306267580063783
Trained batch 402 in epoch 0, gen_loss = 0.44137876819144406, disc_loss = 0.20310258038952098
Trained batch 403 in epoch 0, gen_loss = 0.44146711578463566, disc_loss = 0.2030502526587484
Trained batch 404 in epoch 0, gen_loss = 0.44131620710278735, disc_loss = 0.202902574064555
Trained batch 405 in epoch 0, gen_loss = 0.4411673347644618, disc_loss = 0.2028536738396572
Trained batch 406 in epoch 0, gen_loss = 0.4410298278495779, disc_loss = 0.20271388221651096
Trained batch 407 in epoch 0, gen_loss = 0.441076081757452, disc_loss = 0.20250805732154964
Trained batch 408 in epoch 0, gen_loss = 0.4411255489205964, disc_loss = 0.20233932062801346
Trained batch 409 in epoch 0, gen_loss = 0.44097105867979003, disc_loss = 0.20221198733623436
Trained batch 410 in epoch 0, gen_loss = 0.44062398044152273, disc_loss = 0.20226538828472151
Trained batch 411 in epoch 0, gen_loss = 0.44063661138988236, disc_loss = 0.2020153729697165
Trained batch 412 in epoch 0, gen_loss = 0.4406254261226977, disc_loss = 0.20219913891744382
Trained batch 413 in epoch 0, gen_loss = 0.44038602076290884, disc_loss = 0.20204232692502547
Trained batch 414 in epoch 0, gen_loss = 0.4405793849244175, disc_loss = 0.20169893237481634
Trained batch 415 in epoch 0, gen_loss = 0.4405517172641479, disc_loss = 0.20154859465905106
Trained batch 416 in epoch 0, gen_loss = 0.440728172838545, disc_loss = 0.20144376873398284
Trained batch 417 in epoch 0, gen_loss = 0.44094083483139296, disc_loss = 0.2010888745518107
Trained batch 418 in epoch 0, gen_loss = 0.4408993425830167, disc_loss = 0.20077530484922176
Trained batch 419 in epoch 0, gen_loss = 0.44091109803744727, disc_loss = 0.20051611276964346
Trained batch 420 in epoch 0, gen_loss = 0.440801703165376, disc_loss = 0.20031664148857928
Trained batch 421 in epoch 0, gen_loss = 0.4408223567556996, disc_loss = 0.20009971369428659
Trained batch 422 in epoch 0, gen_loss = 0.4407391815884457, disc_loss = 0.19996511849880783
Trained batch 423 in epoch 0, gen_loss = 0.4404543191897419, disc_loss = 0.1998172748728462
Trained batch 424 in epoch 0, gen_loss = 0.4402747817600475, disc_loss = 0.19987437975757263
Trained batch 425 in epoch 0, gen_loss = 0.44043743512440175, disc_loss = 0.2001958219902896
Trained batch 426 in epoch 0, gen_loss = 0.44040917128813073, disc_loss = 0.2001277165579014
Trained batch 427 in epoch 0, gen_loss = 0.4403025404872181, disc_loss = 0.2000657506461177
Trained batch 428 in epoch 0, gen_loss = 0.44033992373859965, disc_loss = 0.19999339851813439
Trained batch 429 in epoch 0, gen_loss = 0.44019546377104385, disc_loss = 0.2001740762833939
Trained batch 430 in epoch 0, gen_loss = 0.44006745852616436, disc_loss = 0.20042565895413025
Trained batch 431 in epoch 0, gen_loss = 0.4399603450739825, disc_loss = 0.20043570346509418
Trained batch 432 in epoch 0, gen_loss = 0.43993124076730933, disc_loss = 0.20042721791231605
Trained batch 433 in epoch 0, gen_loss = 0.43996870400993504, disc_loss = 0.20008811965790763
Trained batch 434 in epoch 0, gen_loss = 0.4398500754230324, disc_loss = 0.19999680313570747
Trained batch 435 in epoch 0, gen_loss = 0.43995371645470277, disc_loss = 0.19976478651029253
Trained batch 436 in epoch 0, gen_loss = 0.43977363001836517, disc_loss = 0.19956753769510124
Trained batch 437 in epoch 0, gen_loss = 0.43979071972032663, disc_loss = 0.19948224685916074
Trained batch 438 in epoch 0, gen_loss = 0.43960498595835135, disc_loss = 0.19949220110723803
Trained batch 439 in epoch 0, gen_loss = 0.4395463474094868, disc_loss = 0.19969452809203755
Trained batch 440 in epoch 0, gen_loss = 0.43948337442480245, disc_loss = 0.1995173952882252
Trained batch 441 in epoch 0, gen_loss = 0.43930112755945905, disc_loss = 0.19938738239566664
Trained batch 442 in epoch 0, gen_loss = 0.4395598648767708, disc_loss = 0.19947799687057263
Trained batch 443 in epoch 0, gen_loss = 0.4395475619145342, disc_loss = 0.19942885358725582
Trained batch 444 in epoch 0, gen_loss = 0.4394513323735655, disc_loss = 0.19930818753965784
Trained batch 445 in epoch 0, gen_loss = 0.4393733534711359, disc_loss = 0.19935904941083069
Trained batch 446 in epoch 0, gen_loss = 0.43922359684703066, disc_loss = 0.19919104500771637
Trained batch 447 in epoch 0, gen_loss = 0.4391775957441756, disc_loss = 0.1991380047651806
Trained batch 448 in epoch 0, gen_loss = 0.4392435216160288, disc_loss = 0.1989905183392272
Trained batch 449 in epoch 0, gen_loss = 0.439162528845999, disc_loss = 0.19887183325158225
Trained batch 450 in epoch 0, gen_loss = 0.43913437165072117, disc_loss = 0.19872300987629563
Trained batch 451 in epoch 0, gen_loss = 0.4390154575879595, disc_loss = 0.19850170271124987
Trained batch 452 in epoch 0, gen_loss = 0.43898170081195453, disc_loss = 0.19847534091991043
Trained batch 453 in epoch 0, gen_loss = 0.4388106087230901, disc_loss = 0.19833734324653243
Trained batch 454 in epoch 0, gen_loss = 0.4386717242198986, disc_loss = 0.19809329609622012
Trained batch 455 in epoch 0, gen_loss = 0.4387026071025614, disc_loss = 0.1979157227140508
Trained batch 456 in epoch 0, gen_loss = 0.4387827220839536, disc_loss = 0.19767204919907405
Trained batch 457 in epoch 0, gen_loss = 0.43871253201794935, disc_loss = 0.19769729096361122
Trained batch 458 in epoch 0, gen_loss = 0.438595850418336, disc_loss = 0.19772950436489775
Trained batch 459 in epoch 0, gen_loss = 0.43844026968530986, disc_loss = 0.19766721237936746
Trained batch 460 in epoch 0, gen_loss = 0.4382734894106031, disc_loss = 0.19752417196097447
Trained batch 461 in epoch 0, gen_loss = 0.43821804238346235, disc_loss = 0.1974191591304876
Trained batch 462 in epoch 0, gen_loss = 0.43835358826954474, disc_loss = 0.19727771867621793
Trained batch 463 in epoch 0, gen_loss = 0.4382833806990549, disc_loss = 0.1970565812501671
Trained batch 464 in epoch 0, gen_loss = 0.4381593892010309, disc_loss = 0.19690163242881015
Trained batch 465 in epoch 0, gen_loss = 0.4380614027189083, disc_loss = 0.1968345461261375
Trained batch 466 in epoch 0, gen_loss = 0.4381355256544191, disc_loss = 0.19678865323676797
Trained batch 467 in epoch 0, gen_loss = 0.4380744979677037, disc_loss = 0.19669029669056082
Trained batch 468 in epoch 0, gen_loss = 0.4379416629195467, disc_loss = 0.19657731880701934
Trained batch 469 in epoch 0, gen_loss = 0.43810872892115976, disc_loss = 0.19653142454459313
Trained batch 470 in epoch 0, gen_loss = 0.43803369935657316, disc_loss = 0.19644722068828635
Trained batch 471 in epoch 0, gen_loss = 0.43790831195853525, disc_loss = 0.19628175444332724
Trained batch 472 in epoch 0, gen_loss = 0.4378824666236974, disc_loss = 0.19606835551040117
Trained batch 473 in epoch 0, gen_loss = 0.43782683804568356, disc_loss = 0.1959254388316271
Trained batch 474 in epoch 0, gen_loss = 0.4379082874247902, disc_loss = 0.1959918815211246
Trained batch 475 in epoch 0, gen_loss = 0.4379665910446343, disc_loss = 0.19635017178639644
Trained batch 476 in epoch 0, gen_loss = 0.43810117482139377, disc_loss = 0.19643661267352555
Trained batch 477 in epoch 0, gen_loss = 0.43806756596435564, disc_loss = 0.19623134121548183
Trained batch 478 in epoch 0, gen_loss = 0.43791662109918533, disc_loss = 0.19613908497239455
Trained batch 479 in epoch 0, gen_loss = 0.43797424690177045, disc_loss = 0.19598483126610516
Trained batch 480 in epoch 0, gen_loss = 0.4380892432776905, disc_loss = 0.1958524702492474
Trained batch 481 in epoch 0, gen_loss = 0.4380988986289353, disc_loss = 0.19576545050406358
Trained batch 482 in epoch 0, gen_loss = 0.43828494362455966, disc_loss = 0.19548499020391122
Trained batch 483 in epoch 0, gen_loss = 0.4384383924367014, disc_loss = 0.19549871898787327
Trained batch 484 in epoch 0, gen_loss = 0.4384039146998494, disc_loss = 0.19555905671002938
Trained batch 485 in epoch 0, gen_loss = 0.43828514420691833, disc_loss = 0.19548763363112392
Trained batch 486 in epoch 0, gen_loss = 0.4382009620049651, disc_loss = 0.1953569015208823
Trained batch 487 in epoch 0, gen_loss = 0.438121960299914, disc_loss = 0.19516137798820607
Trained batch 488 in epoch 0, gen_loss = 0.43807061312145007, disc_loss = 0.19498916345901773
Trained batch 489 in epoch 0, gen_loss = 0.43816034982399066, disc_loss = 0.1947710792096902
Trained batch 490 in epoch 0, gen_loss = 0.4379117455477627, disc_loss = 0.19475448350829894
Trained batch 491 in epoch 0, gen_loss = 0.43804736804913696, disc_loss = 0.19489458519056801
Trained batch 492 in epoch 0, gen_loss = 0.43793919350022475, disc_loss = 0.19488836060944967
Trained batch 493 in epoch 0, gen_loss = 0.43791645536055934, disc_loss = 0.19471378901196637
Trained batch 494 in epoch 0, gen_loss = 0.43787403925500734, disc_loss = 0.19460177604447712
Trained batch 495 in epoch 0, gen_loss = 0.4378147478545866, disc_loss = 0.19446309694209166
Trained batch 496 in epoch 0, gen_loss = 0.43784651735898716, disc_loss = 0.1943467988199751
Trained batch 497 in epoch 0, gen_loss = 0.4378749284758625, disc_loss = 0.19425780822085328
Trained batch 498 in epoch 0, gen_loss = 0.4378416683965312, disc_loss = 0.1940812227168757
Trained batch 499 in epoch 0, gen_loss = 0.4378691209554672, disc_loss = 0.19397410225123168
Trained batch 500 in epoch 0, gen_loss = 0.43777282301061404, disc_loss = 0.19396260415692768
Trained batch 501 in epoch 0, gen_loss = 0.4376969471633197, disc_loss = 0.19397862447774505
Trained batch 502 in epoch 0, gen_loss = 0.43776606589141, disc_loss = 0.1937793791812528
Trained batch 503 in epoch 0, gen_loss = 0.437729038593788, disc_loss = 0.1937328604168244
Trained batch 504 in epoch 0, gen_loss = 0.4376336123683665, disc_loss = 0.1941799446424045
Trained batch 505 in epoch 0, gen_loss = 0.43782682970107306, disc_loss = 0.19427717161243377
Trained batch 506 in epoch 0, gen_loss = 0.4378738291635081, disc_loss = 0.19412138528343018
Trained batch 507 in epoch 0, gen_loss = 0.43786733433252245, disc_loss = 0.19392284348343067
Trained batch 508 in epoch 0, gen_loss = 0.4380027438076634, disc_loss = 0.19371861107427854
Trained batch 509 in epoch 0, gen_loss = 0.4381838205398298, disc_loss = 0.19368080347045963
Trained batch 510 in epoch 0, gen_loss = 0.4382215074013824, disc_loss = 0.1936446557991542
Trained batch 511 in epoch 0, gen_loss = 0.4381579051259905, disc_loss = 0.19345428799715592
Trained batch 512 in epoch 0, gen_loss = 0.438189817450897, disc_loss = 0.1931946638746452
Trained batch 513 in epoch 0, gen_loss = 0.4382932612288323, disc_loss = 0.19297810606948365
Trained batch 514 in epoch 0, gen_loss = 0.43816680728810503, disc_loss = 0.19281837547433028
Trained batch 515 in epoch 0, gen_loss = 0.43815850408733353, disc_loss = 0.1927142861234241
Trained batch 516 in epoch 0, gen_loss = 0.4381892072969986, disc_loss = 0.19262866837979517
Trained batch 517 in epoch 0, gen_loss = 0.43813466479189145, disc_loss = 0.192376113155116
Trained batch 518 in epoch 0, gen_loss = 0.43799480302026045, disc_loss = 0.19232136142477824
Trained batch 519 in epoch 0, gen_loss = 0.43820714314396564, disc_loss = 0.19229837557874047
Trained batch 520 in epoch 0, gen_loss = 0.43815806536665347, disc_loss = 0.19240067924253085
Trained batch 521 in epoch 0, gen_loss = 0.43831143799412753, disc_loss = 0.19268401851342326
Trained batch 522 in epoch 0, gen_loss = 0.4382317702697294, disc_loss = 0.1924749916458563
Trained batch 523 in epoch 0, gen_loss = 0.4380887561399518, disc_loss = 0.19249729564029525
Trained batch 524 in epoch 0, gen_loss = 0.43808640116737, disc_loss = 0.1924151629706224
Trained batch 525 in epoch 0, gen_loss = 0.43793593653028, disc_loss = 0.1924048909145503
Trained batch 526 in epoch 0, gen_loss = 0.437856805109661, disc_loss = 0.19259718975911105
Trained batch 527 in epoch 0, gen_loss = 0.4377919915837772, disc_loss = 0.19268746794709427
Trained batch 528 in epoch 0, gen_loss = 0.4376456020347112, disc_loss = 0.19259329240888864
Trained batch 529 in epoch 0, gen_loss = 0.43757404195812516, disc_loss = 0.19246637238505876
Trained batch 530 in epoch 0, gen_loss = 0.43774146161510447, disc_loss = 0.19239747318704026
Trained batch 531 in epoch 0, gen_loss = 0.43763924961475503, disc_loss = 0.19225697533780695
Trained batch 532 in epoch 0, gen_loss = 0.4376092927764549, disc_loss = 0.19272427980073398
Trained batch 533 in epoch 0, gen_loss = 0.43766055939795817, disc_loss = 0.1926335399475102
Trained batch 534 in epoch 0, gen_loss = 0.43757253099824783, disc_loss = 0.19249278609858494
Trained batch 535 in epoch 0, gen_loss = 0.43755351468475895, disc_loss = 0.19235956066274154
Trained batch 536 in epoch 0, gen_loss = 0.4374470736838364, disc_loss = 0.1923327211020046
Trained batch 537 in epoch 0, gen_loss = 0.4373217667124085, disc_loss = 0.19228610305676452
Trained batch 538 in epoch 0, gen_loss = 0.4372288281709675, disc_loss = 0.19213465673776417
Trained batch 539 in epoch 0, gen_loss = 0.43725127936513336, disc_loss = 0.19211199983816457
Trained batch 540 in epoch 0, gen_loss = 0.43732826673389585, disc_loss = 0.19199039694093953
Trained batch 541 in epoch 0, gen_loss = 0.4373079428923526, disc_loss = 0.19194374942114212
Trained batch 542 in epoch 0, gen_loss = 0.43751135885605713, disc_loss = 0.19206770559563602
Trained batch 543 in epoch 0, gen_loss = 0.43738547433167696, disc_loss = 0.19204039766918868
Trained batch 544 in epoch 0, gen_loss = 0.43714706607914844, disc_loss = 0.19217874357869866
Trained batch 545 in epoch 0, gen_loss = 0.43717101527439367, disc_loss = 0.19197227645515305
Trained batch 546 in epoch 0, gen_loss = 0.43719456406136536, disc_loss = 0.1918419219308296
Trained batch 547 in epoch 0, gen_loss = 0.43718693372759504, disc_loss = 0.19171149510020105
Trained batch 548 in epoch 0, gen_loss = 0.43700743242691126, disc_loss = 0.1916566205114289
Trained batch 549 in epoch 0, gen_loss = 0.43695417593825947, disc_loss = 0.1917266720059243
Trained batch 550 in epoch 0, gen_loss = 0.4370116468674475, disc_loss = 0.1915306261860632
Trained batch 551 in epoch 0, gen_loss = 0.43721770619352657, disc_loss = 0.19157790185451723
Trained batch 552 in epoch 0, gen_loss = 0.43712296176560317, disc_loss = 0.19136187107475713
Trained batch 553 in epoch 0, gen_loss = 0.43701807729604014, disc_loss = 0.1914183895443213
Trained batch 554 in epoch 0, gen_loss = 0.4370187474263681, disc_loss = 0.191252561376707
Trained batch 555 in epoch 0, gen_loss = 0.43714365700809216, disc_loss = 0.19171974188212654
Trained batch 556 in epoch 0, gen_loss = 0.4369890172990905, disc_loss = 0.19158312360650762
Trained batch 557 in epoch 0, gen_loss = 0.43693139748547666, disc_loss = 0.19178447499203638
Trained batch 558 in epoch 0, gen_loss = 0.4368721413057904, disc_loss = 0.19180908322680829
Trained batch 559 in epoch 0, gen_loss = 0.436825145142419, disc_loss = 0.19173552631400526
Trained batch 560 in epoch 0, gen_loss = 0.43681920302530447, disc_loss = 0.19170467189634335
Trained batch 561 in epoch 0, gen_loss = 0.43669747245693546, disc_loss = 0.19160926297598674
Trained batch 562 in epoch 0, gen_loss = 0.4367402954486928, disc_loss = 0.19147897799553923
Trained batch 563 in epoch 0, gen_loss = 0.4366337476258582, disc_loss = 0.19135359267155963
Trained batch 564 in epoch 0, gen_loss = 0.4365205186658201, disc_loss = 0.19124056851837487
Trained batch 565 in epoch 0, gen_loss = 0.4364582945727628, disc_loss = 0.19109228546253995
Trained batch 566 in epoch 0, gen_loss = 0.43649419443106946, disc_loss = 0.19104241760450907
Trained batch 567 in epoch 0, gen_loss = 0.43642436051872413, disc_loss = 0.19095448507520724
Trained batch 568 in epoch 0, gen_loss = 0.43638127555118084, disc_loss = 0.19091753253749258
Trained batch 569 in epoch 0, gen_loss = 0.4363502280231108, disc_loss = 0.1907956311119753
Trained batch 570 in epoch 0, gen_loss = 0.4363784119878258, disc_loss = 0.19062517206926688
Trained batch 571 in epoch 0, gen_loss = 0.43634359350988083, disc_loss = 0.19045584947782587
Trained batch 572 in epoch 0, gen_loss = 0.4363242105871803, disc_loss = 0.19051851471967307
Trained batch 573 in epoch 0, gen_loss = 0.4361266284558, disc_loss = 0.1904678011332551
Trained batch 574 in epoch 0, gen_loss = 0.43616863323294597, disc_loss = 0.19029101876460988
Trained batch 575 in epoch 0, gen_loss = 0.4362389145212041, disc_loss = 0.19011976830531946
Trained batch 576 in epoch 0, gen_loss = 0.4362052887729797, disc_loss = 0.18996744861816617
Trained batch 577 in epoch 0, gen_loss = 0.4362295009582513, disc_loss = 0.1897890373071894
Trained batch 578 in epoch 0, gen_loss = 0.43632069322729355, disc_loss = 0.18969352205568646
Trained batch 579 in epoch 0, gen_loss = 0.4362003115744426, disc_loss = 0.18955989708032073
Trained batch 580 in epoch 0, gen_loss = 0.4360368327716952, disc_loss = 0.18945948978991803
Trained batch 581 in epoch 0, gen_loss = 0.4360584523464806, disc_loss = 0.1893969236255409
Trained batch 582 in epoch 0, gen_loss = 0.436074390930745, disc_loss = 0.1892391553861097
Trained batch 583 in epoch 0, gen_loss = 0.436133165014525, disc_loss = 0.18913532945978112
Trained batch 584 in epoch 0, gen_loss = 0.4362592514254089, disc_loss = 0.18906486538103504
Trained batch 585 in epoch 0, gen_loss = 0.43618939206665286, disc_loss = 0.18896662194040245
Trained batch 586 in epoch 0, gen_loss = 0.4361471406848914, disc_loss = 0.18896465675565818
Trained batch 587 in epoch 0, gen_loss = 0.4362691217133788, disc_loss = 0.18893153673405347
Trained batch 588 in epoch 0, gen_loss = 0.43629763314598485, disc_loss = 0.18881486239250123
Trained batch 589 in epoch 0, gen_loss = 0.4362941899542081, disc_loss = 0.18868059503956366
Trained batch 590 in epoch 0, gen_loss = 0.43637004943466834, disc_loss = 0.1884752528429939
Trained batch 591 in epoch 0, gen_loss = 0.43632321120113937, disc_loss = 0.18836317199433372
Trained batch 592 in epoch 0, gen_loss = 0.436391182532801, disc_loss = 0.1883148755595515
Trained batch 593 in epoch 0, gen_loss = 0.4363812086257068, disc_loss = 0.1882073071907566
Trained batch 594 in epoch 0, gen_loss = 0.43636351378024124, disc_loss = 0.1881160997730844
Trained batch 595 in epoch 0, gen_loss = 0.43633822951740864, disc_loss = 0.18804209613735043
Trained batch 596 in epoch 0, gen_loss = 0.43622334893025344, disc_loss = 0.1879132201261756
Trained batch 597 in epoch 0, gen_loss = 0.4361664801836014, disc_loss = 0.18777526551888737
Trained batch 598 in epoch 0, gen_loss = 0.43614346938260606, disc_loss = 0.18772580143132672
Testing Epoch 0
------------------------------------------------------------
WARNING    : Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
SOURCE     : matplotlib.image.set_data
TIME STAMP : 2022-09-01 14:20:11,729
------------------------------------------------------------
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 0.32479408383369446, disc_loss = 0.30400046706199646
Trained batch 1 in epoch 1, gen_loss = 0.3958060145378113, disc_loss = 0.26636742800474167
Trained batch 2 in epoch 1, gen_loss = 0.39676279822985333, disc_loss = 0.22837280730406442
Trained batch 3 in epoch 1, gen_loss = 0.3919260799884796, disc_loss = 0.20210909843444824
Trained batch 4 in epoch 1, gen_loss = 0.4067208647727966, disc_loss = 0.1949574679136276
Trained batch 5 in epoch 1, gen_loss = 0.41697055598100025, disc_loss = 0.1853538528084755
Trained batch 6 in epoch 1, gen_loss = 0.4217516652175358, disc_loss = 0.18005255503313883
Trained batch 7 in epoch 1, gen_loss = 0.4137890301644802, disc_loss = 0.17563919350504875
Trained batch 8 in epoch 1, gen_loss = 0.4133932027551863, disc_loss = 0.16763742764790854
Trained batch 9 in epoch 1, gen_loss = 0.4153332501649857, disc_loss = 0.16306227594614028
Trained batch 10 in epoch 1, gen_loss = 0.41532974351536145, disc_loss = 0.15590701726349918
Trained batch 11 in epoch 1, gen_loss = 0.4224953353404999, disc_loss = 0.15132872201502323
Trained batch 12 in epoch 1, gen_loss = 0.42503257668935335, disc_loss = 0.1470086287993651
Trained batch 13 in epoch 1, gen_loss = 0.4311447803463255, disc_loss = 0.1429895529789584
Trained batch 14 in epoch 1, gen_loss = 0.4326058228810628, disc_loss = 0.1399269958337148
Trained batch 15 in epoch 1, gen_loss = 0.4294528551399708, disc_loss = 0.14322537649422884
Trained batch 16 in epoch 1, gen_loss = 0.42323922059115243, disc_loss = 0.16157324436832876
Trained batch 17 in epoch 1, gen_loss = 0.4203978528579076, disc_loss = 0.16262401226494047
Trained batch 18 in epoch 1, gen_loss = 0.4224637182135331, disc_loss = 0.16117405499282636
Trained batch 19 in epoch 1, gen_loss = 0.4210914418101311, disc_loss = 0.1606213428080082
Trained batch 20 in epoch 1, gen_loss = 0.4172598648638952, disc_loss = 0.16105490710054124
Trained batch 21 in epoch 1, gen_loss = 0.4194501760331067, disc_loss = 0.15806948427449574
Trained batch 22 in epoch 1, gen_loss = 0.41610918744750647, disc_loss = 0.15574470259573148
Trained batch 23 in epoch 1, gen_loss = 0.4175865488747756, disc_loss = 0.15473702643066645
Trained batch 24 in epoch 1, gen_loss = 0.4204716360569, disc_loss = 0.1552228781580925
Trained batch 25 in epoch 1, gen_loss = 0.41704539266916424, disc_loss = 0.1543869419166675
Trained batch 26 in epoch 1, gen_loss = 0.4181953767935435, disc_loss = 0.15375040333580087
Trained batch 27 in epoch 1, gen_loss = 0.42208853896175114, disc_loss = 0.1524804774671793
Trained batch 28 in epoch 1, gen_loss = 0.4239958380830699, disc_loss = 0.1497267466680757
Trained batch 29 in epoch 1, gen_loss = 0.4265734295050303, disc_loss = 0.14564975419392187
Trained batch 30 in epoch 1, gen_loss = 0.4253962876335267, disc_loss = 0.14421000517904758
Trained batch 31 in epoch 1, gen_loss = 0.42704932019114494, disc_loss = 0.14146610343595967
Trained batch 32 in epoch 1, gen_loss = 0.426178646810127, disc_loss = 0.1403143315039801
Trained batch 33 in epoch 1, gen_loss = 0.4270233073655297, disc_loss = 0.13877206684692817
Trained batch 34 in epoch 1, gen_loss = 0.42584864241736275, disc_loss = 0.1383517332907234
Trained batch 35 in epoch 1, gen_loss = 0.42768442465199363, disc_loss = 0.13785373724790084
Trained batch 36 in epoch 1, gen_loss = 0.42792155935957626, disc_loss = 0.13518461338370233
Trained batch 37 in epoch 1, gen_loss = 0.42862715532905177, disc_loss = 0.13278822635153406
Trained batch 38 in epoch 1, gen_loss = 0.43110823784119046, disc_loss = 0.13078207756655338
Trained batch 39 in epoch 1, gen_loss = 0.43034534752368925, disc_loss = 0.12886771508492528
Trained batch 40 in epoch 1, gen_loss = 0.43016082557236274, disc_loss = 0.12753332447169757
Trained batch 41 in epoch 1, gen_loss = 0.42936728256089346, disc_loss = 0.1252426759206823
Trained batch 42 in epoch 1, gen_loss = 0.4275663162386695, disc_loss = 0.12415374750488026
Trained batch 43 in epoch 1, gen_loss = 0.4304034398360686, disc_loss = 0.12217058838260444
Trained batch 44 in epoch 1, gen_loss = 0.4323924859364828, disc_loss = 0.12149225295417838
Trained batch 45 in epoch 1, gen_loss = 0.4317180015470671, disc_loss = 0.12039707929057919
Trained batch 46 in epoch 1, gen_loss = 0.4335548605056519, disc_loss = 0.11923944177304177
Trained batch 47 in epoch 1, gen_loss = 0.4349785850693782, disc_loss = 0.12087610662759592
Trained batch 48 in epoch 1, gen_loss = 0.4351490681268731, disc_loss = 0.12596972609813117
Trained batch 49 in epoch 1, gen_loss = 0.43652567207813264, disc_loss = 0.12576413471251727
Trained batch 50 in epoch 1, gen_loss = 0.436019382056068, disc_loss = 0.125808106516214
Trained batch 51 in epoch 1, gen_loss = 0.43472151400951237, disc_loss = 0.1262533454439388
Trained batch 52 in epoch 1, gen_loss = 0.4350839082924825, disc_loss = 0.12668735762390326
Trained batch 53 in epoch 1, gen_loss = 0.43588536977767944, disc_loss = 0.12654668730856092
Trained batch 54 in epoch 1, gen_loss = 0.4359952666542747, disc_loss = 0.12557191784408958
Trained batch 55 in epoch 1, gen_loss = 0.436219435185194, disc_loss = 0.12450266113903906
Trained batch 56 in epoch 1, gen_loss = 0.4356837622952043, disc_loss = 0.12389308047529898
Trained batch 57 in epoch 1, gen_loss = 0.4356005047929698, disc_loss = 0.12358753835975096
Trained batch 58 in epoch 1, gen_loss = 0.4341273191621748, disc_loss = 0.12324654781338522
Trained batch 59 in epoch 1, gen_loss = 0.43304366419712703, disc_loss = 0.12350458580379685
Trained batch 60 in epoch 1, gen_loss = 0.43428081713738986, disc_loss = 0.12867827765399314
Trained batch 61 in epoch 1, gen_loss = 0.4339179858084648, disc_loss = 0.12907845818347508
Trained batch 62 in epoch 1, gen_loss = 0.43364334910634966, disc_loss = 0.12905043697664662
Trained batch 63 in epoch 1, gen_loss = 0.43411303497850895, disc_loss = 0.12880861133453436
Trained batch 64 in epoch 1, gen_loss = 0.43415049818845897, disc_loss = 0.12788458973742448
Trained batch 65 in epoch 1, gen_loss = 0.43413786364324164, disc_loss = 0.127445646900345
Trained batch 66 in epoch 1, gen_loss = 0.43331798911094666, disc_loss = 0.12694936437504506
Trained batch 67 in epoch 1, gen_loss = 0.43375300659852867, disc_loss = 0.12603373915943153
Trained batch 68 in epoch 1, gen_loss = 0.4335562789785689, disc_loss = 0.1263684468694787
Trained batch 69 in epoch 1, gen_loss = 0.4331462472677231, disc_loss = 0.12614881696977787
Trained batch 70 in epoch 1, gen_loss = 0.43290856018872326, disc_loss = 0.12613926179916926
Trained batch 71 in epoch 1, gen_loss = 0.43338554725050926, disc_loss = 0.12621465327942538
Trained batch 72 in epoch 1, gen_loss = 0.4339623851318882, disc_loss = 0.12728008385492515
Trained batch 73 in epoch 1, gen_loss = 0.4328507777001407, disc_loss = 0.12669354448145306
Trained batch 74 in epoch 1, gen_loss = 0.43258358558019, disc_loss = 0.12794781955579917
Trained batch 75 in epoch 1, gen_loss = 0.4320262713651908, disc_loss = 0.127876009718564
Trained batch 76 in epoch 1, gen_loss = 0.43267581524787013, disc_loss = 0.13175030935604076
Trained batch 77 in epoch 1, gen_loss = 0.43305220359410995, disc_loss = 0.13122143933119682
Trained batch 78 in epoch 1, gen_loss = 0.4326605940166908, disc_loss = 0.13154489549372014
Trained batch 79 in epoch 1, gen_loss = 0.4331223614513874, disc_loss = 0.13144050159025938
Trained batch 80 in epoch 1, gen_loss = 0.4335013782536542, disc_loss = 0.13117755924202043
Trained batch 81 in epoch 1, gen_loss = 0.433568042225954, disc_loss = 0.1308835994951972
Trained batch 82 in epoch 1, gen_loss = 0.43379621512918587, disc_loss = 0.1300997767507671
Trained batch 83 in epoch 1, gen_loss = 0.4335642723100526, disc_loss = 0.12948415031479227
Trained batch 84 in epoch 1, gen_loss = 0.43325489163398745, disc_loss = 0.13007822766461793
Trained batch 85 in epoch 1, gen_loss = 0.43358202625152675, disc_loss = 0.12992034118276002
Trained batch 86 in epoch 1, gen_loss = 0.4339435066299877, disc_loss = 0.12864047318868255
Trained batch 87 in epoch 1, gen_loss = 0.43464940549297765, disc_loss = 0.1275642686523497
Trained batch 88 in epoch 1, gen_loss = 0.43475996945681195, disc_loss = 0.12653615329875034
Trained batch 89 in epoch 1, gen_loss = 0.43554921448230743, disc_loss = 0.12546873076094522
Trained batch 90 in epoch 1, gen_loss = 0.4360797277518681, disc_loss = 0.12434871752674763
Trained batch 91 in epoch 1, gen_loss = 0.4362086365404336, disc_loss = 0.1237462505131312
Trained batch 92 in epoch 1, gen_loss = 0.4359422284428791, disc_loss = 0.12275984626944347
Trained batch 93 in epoch 1, gen_loss = 0.4353537654623072, disc_loss = 0.12318505758934832
Trained batch 94 in epoch 1, gen_loss = 0.43684206699070177, disc_loss = 0.1263375388948541
Trained batch 95 in epoch 1, gen_loss = 0.4364279583096504, disc_loss = 0.12690556918581328
Trained batch 96 in epoch 1, gen_loss = 0.4364541268225798, disc_loss = 0.1265328191604811
Trained batch 97 in epoch 1, gen_loss = 0.43633097288559897, disc_loss = 0.12585258757581516
Trained batch 98 in epoch 1, gen_loss = 0.436416084417189, disc_loss = 0.12535968686294074
Trained batch 99 in epoch 1, gen_loss = 0.43621032923460007, disc_loss = 0.12454411204904318
Trained batch 100 in epoch 1, gen_loss = 0.4366982405138488, disc_loss = 0.1238874184834485
Trained batch 101 in epoch 1, gen_loss = 0.4369397037753872, disc_loss = 0.12379805718128588
Trained batch 102 in epoch 1, gen_loss = 0.4364774664050167, disc_loss = 0.12306891671083506
Trained batch 103 in epoch 1, gen_loss = 0.4365166695072101, disc_loss = 0.12248791123812015
Trained batch 104 in epoch 1, gen_loss = 0.43754292726516725, disc_loss = 0.12207241370564416
Trained batch 105 in epoch 1, gen_loss = 0.43800272413019864, disc_loss = 0.12171369327126809
Trained batch 106 in epoch 1, gen_loss = 0.4381506069798336, disc_loss = 0.12087007089753017
Trained batch 107 in epoch 1, gen_loss = 0.4378968808386061, disc_loss = 0.12029985159083649
Trained batch 108 in epoch 1, gen_loss = 0.438090471226141, disc_loss = 0.12087885160511787
Trained batch 109 in epoch 1, gen_loss = 0.43822207152843473, disc_loss = 0.12067656618627635
Trained batch 110 in epoch 1, gen_loss = 0.438026565420735, disc_loss = 0.12047958380735672
Trained batch 111 in epoch 1, gen_loss = 0.43803012690373827, disc_loss = 0.12010353451062526
Trained batch 112 in epoch 1, gen_loss = 0.43773143296748135, disc_loss = 0.11941038665518297
Trained batch 113 in epoch 1, gen_loss = 0.43783043638656016, disc_loss = 0.11906204483749573
Trained batch 114 in epoch 1, gen_loss = 0.4380924978981847, disc_loss = 0.11820279220524041
Trained batch 115 in epoch 1, gen_loss = 0.4381781472214337, disc_loss = 0.11803468358542385
Trained batch 116 in epoch 1, gen_loss = 0.43810432385175657, disc_loss = 0.11922425047582032
Trained batch 117 in epoch 1, gen_loss = 0.4375680068791923, disc_loss = 0.1190568948385574
Trained batch 118 in epoch 1, gen_loss = 0.437282861280842, disc_loss = 0.11895645225123197
Trained batch 119 in epoch 1, gen_loss = 0.4374252234896024, disc_loss = 0.11855150886500875
Trained batch 120 in epoch 1, gen_loss = 0.4369568398668746, disc_loss = 0.11806393805737338
Trained batch 121 in epoch 1, gen_loss = 0.4368970350163882, disc_loss = 0.11761458208937137
Trained batch 122 in epoch 1, gen_loss = 0.43713936548892074, disc_loss = 0.11760506067213004
Trained batch 123 in epoch 1, gen_loss = 0.4370277959012216, disc_loss = 0.11724392171468466
Trained batch 124 in epoch 1, gen_loss = 0.4373918027877808, disc_loss = 0.11678822478652
Trained batch 125 in epoch 1, gen_loss = 0.4377366067871215, disc_loss = 0.1168030814696399
Trained batch 126 in epoch 1, gen_loss = 0.43710043275450156, disc_loss = 0.11666274196871622
Trained batch 127 in epoch 1, gen_loss = 0.4374387238640338, disc_loss = 0.11699370291898958
Trained batch 128 in epoch 1, gen_loss = 0.43777185840200084, disc_loss = 0.12006137626924256
Trained batch 129 in epoch 1, gen_loss = 0.43808237681022055, disc_loss = 0.11992873443433871
Trained batch 130 in epoch 1, gen_loss = 0.437794029712677, disc_loss = 0.11955966467734512
Trained batch 131 in epoch 1, gen_loss = 0.43796817642269714, disc_loss = 0.11924537189417717
Trained batch 132 in epoch 1, gen_loss = 0.43746406063997656, disc_loss = 0.11874398334245932
Trained batch 133 in epoch 1, gen_loss = 0.4376084088389553, disc_loss = 0.11809458149902856
Trained batch 134 in epoch 1, gen_loss = 0.4379232777489556, disc_loss = 0.11770161081243444
Trained batch 135 in epoch 1, gen_loss = 0.43785493404549714, disc_loss = 0.11726745768614552
Trained batch 136 in epoch 1, gen_loss = 0.43811360306113306, disc_loss = 0.11700508001185682
Trained batch 137 in epoch 1, gen_loss = 0.4378613449525142, disc_loss = 0.11666168798894985
Trained batch 138 in epoch 1, gen_loss = 0.4375564893372625, disc_loss = 0.11605969138389868
Trained batch 139 in epoch 1, gen_loss = 0.4376201008047376, disc_loss = 0.11547350375247853
Trained batch 140 in epoch 1, gen_loss = 0.43780253457684887, disc_loss = 0.11476134786263426
Trained batch 141 in epoch 1, gen_loss = 0.4374087526344917, disc_loss = 0.11415474127295991
Trained batch 142 in epoch 1, gen_loss = 0.4378776227260803, disc_loss = 0.11350770745348264
Trained batch 143 in epoch 1, gen_loss = 0.4380920926729838, disc_loss = 0.11279148615560391
Trained batch 144 in epoch 1, gen_loss = 0.438935387956685, disc_loss = 0.11217224303119142
Trained batch 145 in epoch 1, gen_loss = 0.43928812076784163, disc_loss = 0.11147362854306216
Trained batch 146 in epoch 1, gen_loss = 0.43960954319863094, disc_loss = 0.11077543211860114
Trained batch 147 in epoch 1, gen_loss = 0.4399947288471299, disc_loss = 0.11011682931535147
Trained batch 148 in epoch 1, gen_loss = 0.4404211446342852, disc_loss = 0.10956185898624811
Trained batch 149 in epoch 1, gen_loss = 0.44111643731594086, disc_loss = 0.10908545372386773
Trained batch 150 in epoch 1, gen_loss = 0.4411928933977291, disc_loss = 0.10848628549485018
Trained batch 151 in epoch 1, gen_loss = 0.44158715519465896, disc_loss = 0.10789263383240293
Trained batch 152 in epoch 1, gen_loss = 0.44176029613594603, disc_loss = 0.10749735313108544
Trained batch 153 in epoch 1, gen_loss = 0.4422065545986225, disc_loss = 0.10713450172795104
Trained batch 154 in epoch 1, gen_loss = 0.4427091983056837, disc_loss = 0.10650922802667465
Trained batch 155 in epoch 1, gen_loss = 0.44272404450636643, disc_loss = 0.10632216450400077
Trained batch 156 in epoch 1, gen_loss = 0.4431147818352766, disc_loss = 0.10629093416841925
Trained batch 157 in epoch 1, gen_loss = 0.44312707645983634, disc_loss = 0.10582671123497848
Trained batch 158 in epoch 1, gen_loss = 0.443663903377341, disc_loss = 0.10546784510589996
Trained batch 159 in epoch 1, gen_loss = 0.44352590255439284, disc_loss = 0.10498257017461583
Trained batch 160 in epoch 1, gen_loss = 0.44350589154669956, disc_loss = 0.10547135445225683
Trained batch 161 in epoch 1, gen_loss = 0.4428021236334318, disc_loss = 0.10599373445420722
Trained batch 162 in epoch 1, gen_loss = 0.4435383156399054, disc_loss = 0.10564824869067757
Trained batch 163 in epoch 1, gen_loss = 0.44366421605028755, disc_loss = 0.1053664782993132
Trained batch 164 in epoch 1, gen_loss = 0.44361282099377025, disc_loss = 0.10506803590917226
Trained batch 165 in epoch 1, gen_loss = 0.4436984850340579, disc_loss = 0.10464416052697294
Trained batch 166 in epoch 1, gen_loss = 0.44379646924441446, disc_loss = 0.10418988619289712
Trained batch 167 in epoch 1, gen_loss = 0.4445362224110535, disc_loss = 0.10438570954526465
Trained batch 168 in epoch 1, gen_loss = 0.44425096984445694, disc_loss = 0.10411738743178943
Trained batch 169 in epoch 1, gen_loss = 0.44413042489220117, disc_loss = 0.10406004508190295
Trained batch 170 in epoch 1, gen_loss = 0.4443525034084655, disc_loss = 0.10388992868407428
Trained batch 171 in epoch 1, gen_loss = 0.4442454921298249, disc_loss = 0.10361173972054276
Trained batch 172 in epoch 1, gen_loss = 0.44392637021279746, disc_loss = 0.10353030107183263
Trained batch 173 in epoch 1, gen_loss = 0.44422001657129706, disc_loss = 0.1033066769569427
Trained batch 174 in epoch 1, gen_loss = 0.44398615309170314, disc_loss = 0.10310397818684577
Trained batch 175 in epoch 1, gen_loss = 0.4441342538392002, disc_loss = 0.10270753945223987
Trained batch 176 in epoch 1, gen_loss = 0.44370297691916344, disc_loss = 0.10270032368726649
Trained batch 177 in epoch 1, gen_loss = 0.44337209674079764, disc_loss = 0.103161999662773
Trained batch 178 in epoch 1, gen_loss = 0.4437873614899939, disc_loss = 0.10386085166861225
Trained batch 179 in epoch 1, gen_loss = 0.44393274039030073, disc_loss = 0.1035583775697483
Trained batch 180 in epoch 1, gen_loss = 0.444034765603134, disc_loss = 0.10307407772261135
Trained batch 181 in epoch 1, gen_loss = 0.44430558203340886, disc_loss = 0.1026697122686348
Trained batch 182 in epoch 1, gen_loss = 0.44434937036754, disc_loss = 0.10223634831118779
Trained batch 183 in epoch 1, gen_loss = 0.44443806196036545, disc_loss = 0.10203088460611584
Trained batch 184 in epoch 1, gen_loss = 0.4444465795078793, disc_loss = 0.10155693239255531
Trained batch 185 in epoch 1, gen_loss = 0.4450633817462511, disc_loss = 0.10124602334033098
Trained batch 186 in epoch 1, gen_loss = 0.44532286929574244, disc_loss = 0.10078291091470316
Trained batch 187 in epoch 1, gen_loss = 0.445253183232977, disc_loss = 0.10036313444118392
Trained batch 188 in epoch 1, gen_loss = 0.44528918039231075, disc_loss = 0.09998331893550813
Trained batch 189 in epoch 1, gen_loss = 0.44545078183475295, disc_loss = 0.0995352307873729
Trained batch 190 in epoch 1, gen_loss = 0.44580612101479977, disc_loss = 0.09911356627921628
Trained batch 191 in epoch 1, gen_loss = 0.44633047717312974, disc_loss = 0.09864726653904654
Trained batch 192 in epoch 1, gen_loss = 0.4463322395796603, disc_loss = 0.09831226351695048
Trained batch 193 in epoch 1, gen_loss = 0.4466629115883837, disc_loss = 0.09793215352542621
Trained batch 194 in epoch 1, gen_loss = 0.44737311341823677, disc_loss = 0.09759272382809565
Trained batch 195 in epoch 1, gen_loss = 0.44770092638779657, disc_loss = 0.09728583315273329
Trained batch 196 in epoch 1, gen_loss = 0.4481074566465949, disc_loss = 0.0969207254214789
Trained batch 197 in epoch 1, gen_loss = 0.44835064838630984, disc_loss = 0.09647447951232092
Trained batch 198 in epoch 1, gen_loss = 0.4487149814265457, disc_loss = 0.09608033429082465
Trained batch 199 in epoch 1, gen_loss = 0.448466976583004, disc_loss = 0.09568420527968556
Trained batch 200 in epoch 1, gen_loss = 0.4484669563189075, disc_loss = 0.09552938130160618
Trained batch 201 in epoch 1, gen_loss = 0.4493437937580713, disc_loss = 0.09547859071154553
Trained batch 202 in epoch 1, gen_loss = 0.4495419666097669, disc_loss = 0.09509417437145422
Trained batch 203 in epoch 1, gen_loss = 0.449509801233516, disc_loss = 0.09501488138373722
Trained batch 204 in epoch 1, gen_loss = 0.4497224170987199, disc_loss = 0.09509678523442368
Trained batch 205 in epoch 1, gen_loss = 0.44939350040213577, disc_loss = 0.09501986195179589
Trained batch 206 in epoch 1, gen_loss = 0.4495546859531587, disc_loss = 0.09463076452738133
Trained batch 207 in epoch 1, gen_loss = 0.4497788087106668, disc_loss = 0.09425538535623883
Trained batch 208 in epoch 1, gen_loss = 0.45008240248027603, disc_loss = 0.0939237526105494
Trained batch 209 in epoch 1, gen_loss = 0.45020082621347335, disc_loss = 0.09354257682959238
Trained batch 210 in epoch 1, gen_loss = 0.4502718630842688, disc_loss = 0.09315501375485795
Trained batch 211 in epoch 1, gen_loss = 0.45005613270233263, disc_loss = 0.09287307887197525
Trained batch 212 in epoch 1, gen_loss = 0.4497497432948278, disc_loss = 0.09265496591849366
Trained batch 213 in epoch 1, gen_loss = 0.44944910370857916, disc_loss = 0.09245242230228592
Trained batch 214 in epoch 1, gen_loss = 0.4496729748193608, disc_loss = 0.09234654909909465
Trained batch 215 in epoch 1, gen_loss = 0.45008632430323847, disc_loss = 0.09218923229706923
Trained batch 216 in epoch 1, gen_loss = 0.44969224668867575, disc_loss = 0.09192806138541154
Trained batch 217 in epoch 1, gen_loss = 0.4498347223078439, disc_loss = 0.09161734120886124
Trained batch 218 in epoch 1, gen_loss = 0.45039948086216025, disc_loss = 0.09146084120607675
Trained batch 219 in epoch 1, gen_loss = 0.4506036025556651, disc_loss = 0.09117569988170131
Trained batch 220 in epoch 1, gen_loss = 0.4506726972927335, disc_loss = 0.09154860598216365
Trained batch 221 in epoch 1, gen_loss = 0.4504015937044814, disc_loss = 0.09340480960452476
Trained batch 222 in epoch 1, gen_loss = 0.4506601955858581, disc_loss = 0.09350872875479438
Trained batch 223 in epoch 1, gen_loss = 0.4504234985049282, disc_loss = 0.0936606502468099
Trained batch 224 in epoch 1, gen_loss = 0.45073803530799017, disc_loss = 0.09415138768239154
Trained batch 225 in epoch 1, gen_loss = 0.45055392740574557, disc_loss = 0.09458439454716523
Trained batch 226 in epoch 1, gen_loss = 0.45040090296762103, disc_loss = 0.0946041037111096
Trained batch 227 in epoch 1, gen_loss = 0.4501913554574314, disc_loss = 0.0944014184805973
Trained batch 228 in epoch 1, gen_loss = 0.45013622568684375, disc_loss = 0.09420860588436694
Trained batch 229 in epoch 1, gen_loss = 0.4504824030658473, disc_loss = 0.0939540921062555
Trained batch 230 in epoch 1, gen_loss = 0.45027837286263833, disc_loss = 0.09369584405593155
Trained batch 231 in epoch 1, gen_loss = 0.45003846030810785, disc_loss = 0.09344562548132421
Trained batch 232 in epoch 1, gen_loss = 0.4500537249919171, disc_loss = 0.09317237654772823
Trained batch 233 in epoch 1, gen_loss = 0.4499266679979797, disc_loss = 0.09292415083330284
Trained batch 234 in epoch 1, gen_loss = 0.44984584983358994, disc_loss = 0.09261922821640334
Trained batch 235 in epoch 1, gen_loss = 0.45001496412491393, disc_loss = 0.09240843034822936
Trained batch 236 in epoch 1, gen_loss = 0.4502471885349177, disc_loss = 0.09236379588250747
Trained batch 237 in epoch 1, gen_loss = 0.4508818284052761, disc_loss = 0.09279586447935019
Trained batch 238 in epoch 1, gen_loss = 0.4506365068288029, disc_loss = 0.09324957004448235
Trained batch 239 in epoch 1, gen_loss = 0.45109497383236885, disc_loss = 0.09315264204439397
Trained batch 240 in epoch 1, gen_loss = 0.45137782487631833, disc_loss = 0.09313521791960565
Trained batch 241 in epoch 1, gen_loss = 0.4512458149312942, disc_loss = 0.09297923363114069
Trained batch 242 in epoch 1, gen_loss = 0.451215309615979, disc_loss = 0.09278845202576354
Trained batch 243 in epoch 1, gen_loss = 0.451382546395552, disc_loss = 0.09250826235539968
Trained batch 244 in epoch 1, gen_loss = 0.4515615339181861, disc_loss = 0.09235289163355316
Trained batch 245 in epoch 1, gen_loss = 0.45144045498312974, disc_loss = 0.09228825568774246
Trained batch 246 in epoch 1, gen_loss = 0.45182481347790615, disc_loss = 0.09211394573497748
Trained batch 247 in epoch 1, gen_loss = 0.45183614449154946, disc_loss = 0.09190249660487977
Trained batch 248 in epoch 1, gen_loss = 0.4521354937170404, disc_loss = 0.09160587698385778
Trained batch 249 in epoch 1, gen_loss = 0.4522459342479706, disc_loss = 0.09134386173263193
Trained batch 250 in epoch 1, gen_loss = 0.4521302694818413, disc_loss = 0.09116791879231355
Trained batch 251 in epoch 1, gen_loss = 0.45235224446607014, disc_loss = 0.09087922643973595
Trained batch 252 in epoch 1, gen_loss = 0.45216969491936, disc_loss = 0.09129028830294435
Trained batch 253 in epoch 1, gen_loss = 0.45176323333124474, disc_loss = 0.09202132627411973
Trained batch 254 in epoch 1, gen_loss = 0.4519132331305859, disc_loss = 0.09181582345901167
Trained batch 255 in epoch 1, gen_loss = 0.45158547698520124, disc_loss = 0.09165762469274341
Trained batch 256 in epoch 1, gen_loss = 0.45134579138069303, disc_loss = 0.09147531886726386
Trained batch 257 in epoch 1, gen_loss = 0.4510901507943176, disc_loss = 0.09125380760578569
Trained batch 258 in epoch 1, gen_loss = 0.4512302165556138, disc_loss = 0.09117079335966051
Trained batch 259 in epoch 1, gen_loss = 0.45159352731246216, disc_loss = 0.09092752991888958
Trained batch 260 in epoch 1, gen_loss = 0.4515861610799914, disc_loss = 0.09064100030095984
Trained batch 261 in epoch 1, gen_loss = 0.4516532944358942, disc_loss = 0.09034322058952605
Trained batch 262 in epoch 1, gen_loss = 0.4515023705170635, disc_loss = 0.09011805234229044
Trained batch 263 in epoch 1, gen_loss = 0.4516304887153886, disc_loss = 0.08985684422253998
Trained batch 264 in epoch 1, gen_loss = 0.45162452144442866, disc_loss = 0.08958733496168313
Trained batch 265 in epoch 1, gen_loss = 0.45163173883929286, disc_loss = 0.08928986489282627
Trained batch 266 in epoch 1, gen_loss = 0.45176896028750846, disc_loss = 0.08901497574823068
Trained batch 267 in epoch 1, gen_loss = 0.4517732754127303, disc_loss = 0.08872467664473538
Trained batch 268 in epoch 1, gen_loss = 0.4520210450909838, disc_loss = 0.08843436355609101
Trained batch 269 in epoch 1, gen_loss = 0.45218432512548234, disc_loss = 0.08816670785416607
Trained batch 270 in epoch 1, gen_loss = 0.4522941696467875, disc_loss = 0.08787160987082553
Trained batch 271 in epoch 1, gen_loss = 0.4523395079681102, disc_loss = 0.0875867980032447
Trained batch 272 in epoch 1, gen_loss = 0.45277139151489343, disc_loss = 0.08735447019788918
Trained batch 273 in epoch 1, gen_loss = 0.45279062653545044, disc_loss = 0.08713391246138154
Trained batch 274 in epoch 1, gen_loss = 0.4525977758927779, disc_loss = 0.08707885143093087
Trained batch 275 in epoch 1, gen_loss = 0.45260069206141046, disc_loss = 0.08708173319683883
Trained batch 276 in epoch 1, gen_loss = 0.4526773859017162, disc_loss = 0.0869473023205619
Trained batch 277 in epoch 1, gen_loss = 0.4525622924883589, disc_loss = 0.08678115838334607
Trained batch 278 in epoch 1, gen_loss = 0.45251666602268015, disc_loss = 0.08658775666855463
Trained batch 279 in epoch 1, gen_loss = 0.4525254773242133, disc_loss = 0.08649147063427205
Trained batch 280 in epoch 1, gen_loss = 0.45267970992577033, disc_loss = 0.08641128097180265
Trained batch 281 in epoch 1, gen_loss = 0.4527333873383542, disc_loss = 0.08636431832936534
Trained batch 282 in epoch 1, gen_loss = 0.45280017469460043, disc_loss = 0.08618016985603756
Trained batch 283 in epoch 1, gen_loss = 0.4530369668779239, disc_loss = 0.08613407824017948
Trained batch 284 in epoch 1, gen_loss = 0.45270808495973286, disc_loss = 0.08665628639425625
Trained batch 285 in epoch 1, gen_loss = 0.45291462707352803, disc_loss = 0.08693220697903445
Trained batch 286 in epoch 1, gen_loss = 0.4528817382839083, disc_loss = 0.08690528563493116
Trained batch 287 in epoch 1, gen_loss = 0.4528489285666082, disc_loss = 0.08672108403859763
Trained batch 288 in epoch 1, gen_loss = 0.4530422430756183, disc_loss = 0.08678878215705545
Trained batch 289 in epoch 1, gen_loss = 0.4530879664010015, disc_loss = 0.08668351092151012
Trained batch 290 in epoch 1, gen_loss = 0.4529849669777651, disc_loss = 0.08648118280399193
Trained batch 291 in epoch 1, gen_loss = 0.4530411939302536, disc_loss = 0.08633997860007396
Trained batch 292 in epoch 1, gen_loss = 0.4530604127730933, disc_loss = 0.08608796583240655
Trained batch 293 in epoch 1, gen_loss = 0.4532006427544315, disc_loss = 0.08593192109584707
Trained batch 294 in epoch 1, gen_loss = 0.45341650833517816, disc_loss = 0.08599994410839626
Trained batch 295 in epoch 1, gen_loss = 0.4533604967433053, disc_loss = 0.08623567254697853
Trained batch 296 in epoch 1, gen_loss = 0.45332942245785235, disc_loss = 0.0862093559914717
Trained batch 297 in epoch 1, gen_loss = 0.4533178698296515, disc_loss = 0.08606969701101216
Trained batch 298 in epoch 1, gen_loss = 0.4533722804342225, disc_loss = 0.08583353986857727
Trained batch 299 in epoch 1, gen_loss = 0.4536139010389646, disc_loss = 0.08580601144582033
Trained batch 300 in epoch 1, gen_loss = 0.45352343705009385, disc_loss = 0.08629477597104751
Trained batch 301 in epoch 1, gen_loss = 0.4538327522625197, disc_loss = 0.08627252841972752
Trained batch 302 in epoch 1, gen_loss = 0.45390037744745565, disc_loss = 0.08612092932311222
Trained batch 303 in epoch 1, gen_loss = 0.45377747812553454, disc_loss = 0.08598300235002841
Trained batch 304 in epoch 1, gen_loss = 0.45376598229173754, disc_loss = 0.08585260239292364
Trained batch 305 in epoch 1, gen_loss = 0.45399480551676036, disc_loss = 0.08579611853739015
Trained batch 306 in epoch 1, gen_loss = 0.4537319488556455, disc_loss = 0.08554446183945923
Trained batch 307 in epoch 1, gen_loss = 0.4537644304044835, disc_loss = 0.0856735882071125
Trained batch 308 in epoch 1, gen_loss = 0.453968777336349, disc_loss = 0.08556233087259203
Trained batch 309 in epoch 1, gen_loss = 0.45405664530492595, disc_loss = 0.08537943265851466
Trained batch 310 in epoch 1, gen_loss = 0.4541091635296199, disc_loss = 0.08515699150286303
Trained batch 311 in epoch 1, gen_loss = 0.45408278254744333, disc_loss = 0.08498636968672657
Trained batch 312 in epoch 1, gen_loss = 0.4541832337173791, disc_loss = 0.08475893388945645
Trained batch 313 in epoch 1, gen_loss = 0.4543784609076324, disc_loss = 0.08454253768346681
Trained batch 314 in epoch 1, gen_loss = 0.4546305201356373, disc_loss = 0.0843020087403674
Trained batch 315 in epoch 1, gen_loss = 0.45445002785211874, disc_loss = 0.0840940907084725
Trained batch 316 in epoch 1, gen_loss = 0.45452551520209206, disc_loss = 0.08389166232245483
Trained batch 317 in epoch 1, gen_loss = 0.45420613510053864, disc_loss = 0.0836974266395207
Trained batch 318 in epoch 1, gen_loss = 0.4541429171928418, disc_loss = 0.08351616625350004
Trained batch 319 in epoch 1, gen_loss = 0.4542163363657892, disc_loss = 0.0833012864459306
Trained batch 320 in epoch 1, gen_loss = 0.4544658281164377, disc_loss = 0.08308073966488289
Trained batch 321 in epoch 1, gen_loss = 0.45444415990980513, disc_loss = 0.08289518383742304
Trained batch 322 in epoch 1, gen_loss = 0.45463855818329213, disc_loss = 0.0826733379304732
Trained batch 323 in epoch 1, gen_loss = 0.4545919845501582, disc_loss = 0.0824619653335784
Trained batch 324 in epoch 1, gen_loss = 0.4543267709475297, disc_loss = 0.08222982817257826
Trained batch 325 in epoch 1, gen_loss = 0.4545099599046941, disc_loss = 0.08219253669772869
Trained batch 326 in epoch 1, gen_loss = 0.4547599482062395, disc_loss = 0.08198605442778506
Trained batch 327 in epoch 1, gen_loss = 0.45488640784126955, disc_loss = 0.08178754054611867
Trained batch 328 in epoch 1, gen_loss = 0.45466110979894736, disc_loss = 0.08158051076495176
Trained batch 329 in epoch 1, gen_loss = 0.454662457560048, disc_loss = 0.08136322281012932
Trained batch 330 in epoch 1, gen_loss = 0.45456214766848124, disc_loss = 0.08118110339739712
Trained batch 331 in epoch 1, gen_loss = 0.45468973260687057, disc_loss = 0.08096385155299521
Trained batch 332 in epoch 1, gen_loss = 0.4549549607722251, disc_loss = 0.0807534058357368
Trained batch 333 in epoch 1, gen_loss = 0.4550876398821791, disc_loss = 0.08055555092973891
Trained batch 334 in epoch 1, gen_loss = 0.45513947677256456, disc_loss = 0.08036833397432494
Trained batch 335 in epoch 1, gen_loss = 0.45519741748770076, disc_loss = 0.08015209224928792
Trained batch 336 in epoch 1, gen_loss = 0.4552198812940354, disc_loss = 0.07994764548303554
Trained batch 337 in epoch 1, gen_loss = 0.45517744291463547, disc_loss = 0.0797351919081525
Trained batch 338 in epoch 1, gen_loss = 0.4551669355690655, disc_loss = 0.07952158877510676
Trained batch 339 in epoch 1, gen_loss = 0.45523872156353556, disc_loss = 0.07936815123402459
Trained batch 340 in epoch 1, gen_loss = 0.4554119617883061, disc_loss = 0.07922379694103408
Trained batch 341 in epoch 1, gen_loss = 0.4553662874022422, disc_loss = 0.07904079595406414
Trained batch 342 in epoch 1, gen_loss = 0.45554050629410037, disc_loss = 0.07884904077282018
Trained batch 343 in epoch 1, gen_loss = 0.45570196479905484, disc_loss = 0.0786595163260435
Trained batch 344 in epoch 1, gen_loss = 0.45589247795118804, disc_loss = 0.07847777246565059
Trained batch 345 in epoch 1, gen_loss = 0.45589373566511737, disc_loss = 0.07834769164163598
Trained batch 346 in epoch 1, gen_loss = 0.45598223487650624, disc_loss = 0.07816982599946883
Trained batch 347 in epoch 1, gen_loss = 0.45607468383065586, disc_loss = 0.0779818353516146
Trained batch 348 in epoch 1, gen_loss = 0.456188147508654, disc_loss = 0.07781636532139898
Trained batch 349 in epoch 1, gen_loss = 0.45624839535781314, disc_loss = 0.07763620679133705
Trained batch 350 in epoch 1, gen_loss = 0.45652399672741906, disc_loss = 0.07744884896131916
Trained batch 351 in epoch 1, gen_loss = 0.45647686728360976, disc_loss = 0.07727314066671004
Trained batch 352 in epoch 1, gen_loss = 0.45642317320739917, disc_loss = 0.07713428091669386
Trained batch 353 in epoch 1, gen_loss = 0.45647918773909746, disc_loss = 0.07700727845799957
Trained batch 354 in epoch 1, gen_loss = 0.4568860404927966, disc_loss = 0.07687154016129567
Trained batch 355 in epoch 1, gen_loss = 0.45706611402918784, disc_loss = 0.07668427102728172
Trained batch 356 in epoch 1, gen_loss = 0.45696477621209386, disc_loss = 0.0764976093514251
Trained batch 357 in epoch 1, gen_loss = 0.4569688827298873, disc_loss = 0.07632127183609169
Trained batch 358 in epoch 1, gen_loss = 0.4571860432624817, disc_loss = 0.07618502234848097
Trained batch 359 in epoch 1, gen_loss = 0.4571821010775036, disc_loss = 0.07608929642786583
Trained batch 360 in epoch 1, gen_loss = 0.4572922276988254, disc_loss = 0.07595236015369357
Trained batch 361 in epoch 1, gen_loss = 0.4574002421033975, disc_loss = 0.07577796269321392
Trained batch 362 in epoch 1, gen_loss = 0.4574070995668406, disc_loss = 0.07561009859065872
Trained batch 363 in epoch 1, gen_loss = 0.45734810247853563, disc_loss = 0.07544221097071256
Trained batch 364 in epoch 1, gen_loss = 0.45730946178305637, disc_loss = 0.07525117876237794
Trained batch 365 in epoch 1, gen_loss = 0.4572999552299416, disc_loss = 0.0750776759827194
Trained batch 366 in epoch 1, gen_loss = 0.4572798025055867, disc_loss = 0.0748956689093394
Trained batch 367 in epoch 1, gen_loss = 0.4571416753789653, disc_loss = 0.07473264464288545
Trained batch 368 in epoch 1, gen_loss = 0.4570774922202919, disc_loss = 0.07487968724665199
Trained batch 369 in epoch 1, gen_loss = 0.4573280044504114, disc_loss = 0.07487298495614449
Trained batch 370 in epoch 1, gen_loss = 0.4575875007881309, disc_loss = 0.07479021814463514
Trained batch 371 in epoch 1, gen_loss = 0.4574484446196146, disc_loss = 0.07483444793239957
Trained batch 372 in epoch 1, gen_loss = 0.4573542407786239, disc_loss = 0.07467115574314112
Trained batch 373 in epoch 1, gen_loss = 0.45733415976883895, disc_loss = 0.0745048229333591
Trained batch 374 in epoch 1, gen_loss = 0.4573339455127716, disc_loss = 0.07436670866360268
Trained batch 375 in epoch 1, gen_loss = 0.4573887181567385, disc_loss = 0.07422705300082948
Trained batch 376 in epoch 1, gen_loss = 0.45718405061754686, disc_loss = 0.07405493194756126
Trained batch 377 in epoch 1, gen_loss = 0.45713535558294366, disc_loss = 0.07393477939650732
Trained batch 378 in epoch 1, gen_loss = 0.45702904140414535, disc_loss = 0.07380146219943083
Trained batch 379 in epoch 1, gen_loss = 0.4569326524671755, disc_loss = 0.07367743618149114
Trained batch 380 in epoch 1, gen_loss = 0.4570741789547477, disc_loss = 0.07354914092182566
Trained batch 381 in epoch 1, gen_loss = 0.4569478929042816, disc_loss = 0.07341083968838394
Trained batch 382 in epoch 1, gen_loss = 0.4568799396407822, disc_loss = 0.07325266244974445
Trained batch 383 in epoch 1, gen_loss = 0.45682968975355226, disc_loss = 0.0731139540997295
Trained batch 384 in epoch 1, gen_loss = 0.45673852369382784, disc_loss = 0.07335505889752855
Trained batch 385 in epoch 1, gen_loss = 0.45699576763291433, disc_loss = 0.07401701408182633
Trained batch 386 in epoch 1, gen_loss = 0.4566047593604687, disc_loss = 0.07415357530261427
Trained batch 387 in epoch 1, gen_loss = 0.45679303696475076, disc_loss = 0.0741451968482129
Trained batch 388 in epoch 1, gen_loss = 0.45665430785144817, disc_loss = 0.07414332558676255
Trained batch 389 in epoch 1, gen_loss = 0.4565294744876715, disc_loss = 0.07417079389620668
Trained batch 390 in epoch 1, gen_loss = 0.4564660751758634, disc_loss = 0.07429629083856217
Trained batch 391 in epoch 1, gen_loss = 0.45667847177507925, disc_loss = 0.07428338009702536
Trained batch 392 in epoch 1, gen_loss = 0.45665344732408303, disc_loss = 0.07419028000209395
Trained batch 393 in epoch 1, gen_loss = 0.4564510257867387, disc_loss = 0.07421818946436198
Trained batch 394 in epoch 1, gen_loss = 0.456232019391241, disc_loss = 0.07470754373441392
Trained batch 395 in epoch 1, gen_loss = 0.45622911770837477, disc_loss = 0.0748888255647299
Trained batch 396 in epoch 1, gen_loss = 0.4559966809203102, disc_loss = 0.07487522211789109
Trained batch 397 in epoch 1, gen_loss = 0.45619980354404926, disc_loss = 0.07477952130653676
Trained batch 398 in epoch 1, gen_loss = 0.4562082282433235, disc_loss = 0.07466804840949767
Trained batch 399 in epoch 1, gen_loss = 0.4562806063145399, disc_loss = 0.07454438003478572
Trained batch 400 in epoch 1, gen_loss = 0.4563984278580197, disc_loss = 0.07440861756042426
Trained batch 401 in epoch 1, gen_loss = 0.4564528023425619, disc_loss = 0.07428067208809862
Trained batch 402 in epoch 1, gen_loss = 0.45664287574829593, disc_loss = 0.07421291750571495
Trained batch 403 in epoch 1, gen_loss = 0.4566492700193188, disc_loss = 0.07404883028616631
Trained batch 404 in epoch 1, gen_loss = 0.4565604856720677, disc_loss = 0.07398789934124107
Trained batch 405 in epoch 1, gen_loss = 0.45651370492474785, disc_loss = 0.0739709486693988
Trained batch 406 in epoch 1, gen_loss = 0.45647658572442995, disc_loss = 0.07384576436351865
Trained batch 407 in epoch 1, gen_loss = 0.45650849798146415, disc_loss = 0.07370739606638238
Trained batch 408 in epoch 1, gen_loss = 0.456409664856484, disc_loss = 0.07355737936862888
Trained batch 409 in epoch 1, gen_loss = 0.4564012664847258, disc_loss = 0.07342080982947131
Trained batch 410 in epoch 1, gen_loss = 0.45634538283313275, disc_loss = 0.07327404395289665
Trained batch 411 in epoch 1, gen_loss = 0.4562864227636347, disc_loss = 0.07313593532618823
Trained batch 412 in epoch 1, gen_loss = 0.4562508347681013, disc_loss = 0.07300964844374766
Trained batch 413 in epoch 1, gen_loss = 0.45640723666419153, disc_loss = 0.07288172469892795
Trained batch 414 in epoch 1, gen_loss = 0.4565204567937966, disc_loss = 0.07275083451026894
Trained batch 415 in epoch 1, gen_loss = 0.45664306522275394, disc_loss = 0.07261431749122074
Trained batch 416 in epoch 1, gen_loss = 0.4566391115423015, disc_loss = 0.07247817503819934
Trained batch 417 in epoch 1, gen_loss = 0.4564006335712506, disc_loss = 0.0723559829945627
Trained batch 418 in epoch 1, gen_loss = 0.45651889700878207, disc_loss = 0.07220229686311222
Trained batch 419 in epoch 1, gen_loss = 0.456610998014609, disc_loss = 0.07205313145005632
Trained batch 420 in epoch 1, gen_loss = 0.45664183643254985, disc_loss = 0.07190117562928562
Trained batch 421 in epoch 1, gen_loss = 0.4567594483000407, disc_loss = 0.07175225558827557
Trained batch 422 in epoch 1, gen_loss = 0.456685840801708, disc_loss = 0.07160714568336875
Trained batch 423 in epoch 1, gen_loss = 0.45664476624356126, disc_loss = 0.07151823449783239
Trained batch 424 in epoch 1, gen_loss = 0.45676575218929966, disc_loss = 0.07151570913765361
Trained batch 425 in epoch 1, gen_loss = 0.4568140054812454, disc_loss = 0.07146892606766081
Trained batch 426 in epoch 1, gen_loss = 0.45685731520139083, disc_loss = 0.07138116409308527
Trained batch 427 in epoch 1, gen_loss = 0.45715299743079696, disc_loss = 0.07152539786934922
Trained batch 428 in epoch 1, gen_loss = 0.4572327313445387, disc_loss = 0.0715992091492791
Trained batch 429 in epoch 1, gen_loss = 0.4573055480801782, disc_loss = 0.07149527943801395
Trained batch 430 in epoch 1, gen_loss = 0.4573292513043034, disc_loss = 0.07138206527769358
Trained batch 431 in epoch 1, gen_loss = 0.4573670379403565, disc_loss = 0.07132401483573227
Trained batch 432 in epoch 1, gen_loss = 0.4571562071457746, disc_loss = 0.0712022899346766
Trained batch 433 in epoch 1, gen_loss = 0.45697555165686365, disc_loss = 0.07121216328299608
Trained batch 434 in epoch 1, gen_loss = 0.45685248827112135, disc_loss = 0.07147206445920398
Trained batch 435 in epoch 1, gen_loss = 0.4568504466923005, disc_loss = 0.07141608589568064
Trained batch 436 in epoch 1, gen_loss = 0.45680409021999524, disc_loss = 0.07133252891654349
Trained batch 437 in epoch 1, gen_loss = 0.45690962787904693, disc_loss = 0.07140847561098465
Trained batch 438 in epoch 1, gen_loss = 0.45664459609496566, disc_loss = 0.07143855794356258
Trained batch 439 in epoch 1, gen_loss = 0.45678826780481774, disc_loss = 0.07135618188714778
Trained batch 440 in epoch 1, gen_loss = 0.45672709168760683, disc_loss = 0.07128889291270588
Trained batch 441 in epoch 1, gen_loss = 0.4569029851197118, disc_loss = 0.0712637826821417
Trained batch 442 in epoch 1, gen_loss = 0.45700466928848027, disc_loss = 0.07119206002961768
Trained batch 443 in epoch 1, gen_loss = 0.4570258894750664, disc_loss = 0.07108985120220832
Trained batch 444 in epoch 1, gen_loss = 0.4568517438481363, disc_loss = 0.0709629539818911
Trained batch 445 in epoch 1, gen_loss = 0.4567422350960462, disc_loss = 0.0708831131266171
Trained batch 446 in epoch 1, gen_loss = 0.45694317166970616, disc_loss = 0.07092961414365027
Trained batch 447 in epoch 1, gen_loss = 0.45697461195024, disc_loss = 0.07088357246331205
Trained batch 448 in epoch 1, gen_loss = 0.4569722513579048, disc_loss = 0.07081845173309402
Trained batch 449 in epoch 1, gen_loss = 0.4570981127685971, disc_loss = 0.07076737832278013
Trained batch 450 in epoch 1, gen_loss = 0.45719541427565785, disc_loss = 0.07063267327547734
Trained batch 451 in epoch 1, gen_loss = 0.45728396261687826, disc_loss = 0.07050843956567084
Trained batch 452 in epoch 1, gen_loss = 0.4571527268318151, disc_loss = 0.0704571350393344
Trained batch 453 in epoch 1, gen_loss = 0.4573525796246424, disc_loss = 0.07044711516398756
Trained batch 454 in epoch 1, gen_loss = 0.4573858257178422, disc_loss = 0.07030960889430819
Trained batch 455 in epoch 1, gen_loss = 0.45730099304203403, disc_loss = 0.0701953761683973
Trained batch 456 in epoch 1, gen_loss = 0.45716063055480854, disc_loss = 0.07017339369653025
Trained batch 457 in epoch 1, gen_loss = 0.4571932040187469, disc_loss = 0.0706105187807769
Trained batch 458 in epoch 1, gen_loss = 0.4570138115508884, disc_loss = 0.07091770652064766
Trained batch 459 in epoch 1, gen_loss = 0.4571349155643712, disc_loss = 0.07088721621093219
Trained batch 460 in epoch 1, gen_loss = 0.4573128237641556, disc_loss = 0.07098334282434621
Trained batch 461 in epoch 1, gen_loss = 0.4573444020954561, disc_loss = 0.0709306844590772
Trained batch 462 in epoch 1, gen_loss = 0.4572792196119321, disc_loss = 0.0708099064391034
Trained batch 463 in epoch 1, gen_loss = 0.4574028854740077, disc_loss = 0.07077544276273393
Trained batch 464 in epoch 1, gen_loss = 0.457511116355978, disc_loss = 0.07073392194084903
Trained batch 465 in epoch 1, gen_loss = 0.4575948517593703, disc_loss = 0.07070240292642185
Trained batch 466 in epoch 1, gen_loss = 0.4575620526547606, disc_loss = 0.07062356054934432
Trained batch 467 in epoch 1, gen_loss = 0.4577700475979055, disc_loss = 0.07049847997995651
Trained batch 468 in epoch 1, gen_loss = 0.45790519598704665, disc_loss = 0.0703964622171004
Trained batch 469 in epoch 1, gen_loss = 0.45805701873403915, disc_loss = 0.07026779493515162
Trained batch 470 in epoch 1, gen_loss = 0.45810729638532977, disc_loss = 0.07015152157317935
Trained batch 471 in epoch 1, gen_loss = 0.4581472587661218, disc_loss = 0.07003412129341673
Trained batch 472 in epoch 1, gen_loss = 0.4581681110012103, disc_loss = 0.06990753106150706
Trained batch 473 in epoch 1, gen_loss = 0.4582677838797308, disc_loss = 0.06980669983163602
Trained batch 474 in epoch 1, gen_loss = 0.45807298842229344, disc_loss = 0.06968654712760135
Trained batch 475 in epoch 1, gen_loss = 0.4580262225089955, disc_loss = 0.06956774347164363
Trained batch 476 in epoch 1, gen_loss = 0.4579961996533336, disc_loss = 0.0694503108336272
Trained batch 477 in epoch 1, gen_loss = 0.45795972632813153, disc_loss = 0.06939102940175636
Trained batch 478 in epoch 1, gen_loss = 0.4580909397631946, disc_loss = 0.06934311666520067
Trained batch 479 in epoch 1, gen_loss = 0.4581576881930232, disc_loss = 0.06922782879555597
Trained batch 480 in epoch 1, gen_loss = 0.45800457216350055, disc_loss = 0.06915945479580493
Trained batch 481 in epoch 1, gen_loss = 0.45803503246970195, disc_loss = 0.06909321770613
Trained batch 482 in epoch 1, gen_loss = 0.45815079102358214, disc_loss = 0.06898509683646648
Trained batch 483 in epoch 1, gen_loss = 0.45812351576799204, disc_loss = 0.06890883441814337
Trained batch 484 in epoch 1, gen_loss = 0.4580502352149216, disc_loss = 0.06884571257402602
Trained batch 485 in epoch 1, gen_loss = 0.457923830168728, disc_loss = 0.06880992639871168
Trained batch 486 in epoch 1, gen_loss = 0.457884825903777, disc_loss = 0.06877136093925769
Trained batch 487 in epoch 1, gen_loss = 0.45781377519740435, disc_loss = 0.06875697729849546
Trained batch 488 in epoch 1, gen_loss = 0.45793685883832125, disc_loss = 0.06866654253551444
Trained batch 489 in epoch 1, gen_loss = 0.4577488545860563, disc_loss = 0.06886028671371085
Trained batch 490 in epoch 1, gen_loss = 0.45788926717705736, disc_loss = 0.06913219249281888
Trained batch 491 in epoch 1, gen_loss = 0.4579164548739185, disc_loss = 0.06908298769541751
Trained batch 492 in epoch 1, gen_loss = 0.45783074239446475, disc_loss = 0.06906425763624315
Trained batch 493 in epoch 1, gen_loss = 0.4579333371599676, disc_loss = 0.06902422487871487
Trained batch 494 in epoch 1, gen_loss = 0.457644172991165, disc_loss = 0.06901921013163195
Trained batch 495 in epoch 1, gen_loss = 0.4575938939327194, disc_loss = 0.06892919561810672
Trained batch 496 in epoch 1, gen_loss = 0.4577159213588031, disc_loss = 0.06884925392357037
Trained batch 497 in epoch 1, gen_loss = 0.45769003542312175, disc_loss = 0.06878095033791769
Trained batch 498 in epoch 1, gen_loss = 0.4576859637228903, disc_loss = 0.0687363924335442
Trained batch 499 in epoch 1, gen_loss = 0.45763696885108945, disc_loss = 0.06863878843188286
Trained batch 500 in epoch 1, gen_loss = 0.4576687078751966, disc_loss = 0.068540113950204
Trained batch 501 in epoch 1, gen_loss = 0.4575842871252759, disc_loss = 0.06844782467886984
Trained batch 502 in epoch 1, gen_loss = 0.45762815976711674, disc_loss = 0.06834096360070331
Trained batch 503 in epoch 1, gen_loss = 0.45768430793569204, disc_loss = 0.06841945189184376
Trained batch 504 in epoch 1, gen_loss = 0.45758086413440135, disc_loss = 0.06868363036820203
Trained batch 505 in epoch 1, gen_loss = 0.4576631769714619, disc_loss = 0.06859067537391139
Trained batch 506 in epoch 1, gen_loss = 0.4577756683384408, disc_loss = 0.06852617879679217
Trained batch 507 in epoch 1, gen_loss = 0.45788718554682617, disc_loss = 0.06845651296385395
Trained batch 508 in epoch 1, gen_loss = 0.4578811471260835, disc_loss = 0.06834120536131569
Trained batch 509 in epoch 1, gen_loss = 0.4577883241223354, disc_loss = 0.06822356620949566
Trained batch 510 in epoch 1, gen_loss = 0.4577136613034922, disc_loss = 0.0681751190635527
Trained batch 511 in epoch 1, gen_loss = 0.4577646162942983, disc_loss = 0.06809067998801765
Trained batch 512 in epoch 1, gen_loss = 0.4577248667532008, disc_loss = 0.06799649974952142
Trained batch 513 in epoch 1, gen_loss = 0.45776646424824163, disc_loss = 0.06791226967176285
Trained batch 514 in epoch 1, gen_loss = 0.4577166763902868, disc_loss = 0.06783897734418945
Trained batch 515 in epoch 1, gen_loss = 0.45775758659885835, disc_loss = 0.06774972214782249
Trained batch 516 in epoch 1, gen_loss = 0.457614756299172, disc_loss = 0.0676558192412241
Trained batch 517 in epoch 1, gen_loss = 0.4574676242344168, disc_loss = 0.06758916906070353
Trained batch 518 in epoch 1, gen_loss = 0.45756860045798714, disc_loss = 0.06758914478948638
Trained batch 519 in epoch 1, gen_loss = 0.45756915423732536, disc_loss = 0.06750478792326668
Trained batch 520 in epoch 1, gen_loss = 0.4574909508228302, disc_loss = 0.067439717994985
Trained batch 521 in epoch 1, gen_loss = 0.45760807172320356, disc_loss = 0.0673782671016723
Trained batch 522 in epoch 1, gen_loss = 0.4576510182416234, disc_loss = 0.06727948497596195
Trained batch 523 in epoch 1, gen_loss = 0.4576760656164803, disc_loss = 0.0671624596051175
Trained batch 524 in epoch 1, gen_loss = 0.45771763341767446, disc_loss = 0.06707013230149944
Trained batch 525 in epoch 1, gen_loss = 0.45771175696595995, disc_loss = 0.06697085423009053
Trained batch 526 in epoch 1, gen_loss = 0.45765287277820665, disc_loss = 0.06693509758045399
Trained batch 527 in epoch 1, gen_loss = 0.45772927440702915, disc_loss = 0.06686193750779652
Trained batch 528 in epoch 1, gen_loss = 0.45762842087980027, disc_loss = 0.06684589472692636
Trained batch 529 in epoch 1, gen_loss = 0.4576660767478763, disc_loss = 0.06677560843615178
Trained batch 530 in epoch 1, gen_loss = 0.45776820805786694, disc_loss = 0.06670345253839023
Trained batch 531 in epoch 1, gen_loss = 0.45787320218812255, disc_loss = 0.06659970133253758
Trained batch 532 in epoch 1, gen_loss = 0.45789700645890513, disc_loss = 0.06650509813618732
Trained batch 533 in epoch 1, gen_loss = 0.4579365173082673, disc_loss = 0.0663994322208276
Trained batch 534 in epoch 1, gen_loss = 0.45793613702337316, disc_loss = 0.06630694855474563
Trained batch 535 in epoch 1, gen_loss = 0.457867538862264, disc_loss = 0.06622048335431366
Trained batch 536 in epoch 1, gen_loss = 0.45803145445480914, disc_loss = 0.06615592085008876
Trained batch 537 in epoch 1, gen_loss = 0.4581978177049346, disc_loss = 0.06605508489115337
Trained batch 538 in epoch 1, gen_loss = 0.4581556853204136, disc_loss = 0.06596182504883087
Trained batch 539 in epoch 1, gen_loss = 0.45823535157574546, disc_loss = 0.06586146856985849
Trained batch 540 in epoch 1, gen_loss = 0.4583814244393721, disc_loss = 0.0657616774706504
Trained batch 541 in epoch 1, gen_loss = 0.4584457786870619, disc_loss = 0.0656507152529619
Trained batch 542 in epoch 1, gen_loss = 0.4584393724113099, disc_loss = 0.06559257924601326
Trained batch 543 in epoch 1, gen_loss = 0.45845790612785253, disc_loss = 0.06549411542929352
Trained batch 544 in epoch 1, gen_loss = 0.45858432382618614, disc_loss = 0.06541937010601984
Trained batch 545 in epoch 1, gen_loss = 0.45854100590442126, disc_loss = 0.06533426112468071
Trained batch 546 in epoch 1, gen_loss = 0.45872858951253037, disc_loss = 0.06525918815397339
Trained batch 547 in epoch 1, gen_loss = 0.45876092061291646, disc_loss = 0.06517367826920872
Trained batch 548 in epoch 1, gen_loss = 0.45881185206993463, disc_loss = 0.06513548379031117
Trained batch 549 in epoch 1, gen_loss = 0.45877629962834443, disc_loss = 0.06507645914415744
Trained batch 550 in epoch 1, gen_loss = 0.4588519134668603, disc_loss = 0.06498160082829978
Trained batch 551 in epoch 1, gen_loss = 0.4587957521603591, disc_loss = 0.06491277128056475
Trained batch 552 in epoch 1, gen_loss = 0.4589904024523378, disc_loss = 0.06482270095669151
Trained batch 553 in epoch 1, gen_loss = 0.4588914986444294, disc_loss = 0.06472002133636295
Trained batch 554 in epoch 1, gen_loss = 0.4588601884004232, disc_loss = 0.0646166997651259
Trained batch 555 in epoch 1, gen_loss = 0.45890984898634096, disc_loss = 0.06451777051531261
Trained batch 556 in epoch 1, gen_loss = 0.45894897176718585, disc_loss = 0.0644182600983865
Trained batch 557 in epoch 1, gen_loss = 0.458895618503239, disc_loss = 0.06431869054246547
Trained batch 558 in epoch 1, gen_loss = 0.45887014712331975, disc_loss = 0.0642170979189878
Trained batch 559 in epoch 1, gen_loss = 0.45896925213081496, disc_loss = 0.06412942207950567
Trained batch 560 in epoch 1, gen_loss = 0.45891418776835136, disc_loss = 0.06408571389482196
Trained batch 561 in epoch 1, gen_loss = 0.45896797995762467, disc_loss = 0.06402006202122176
Trained batch 562 in epoch 1, gen_loss = 0.45910499929111337, disc_loss = 0.06392173520678102
Trained batch 563 in epoch 1, gen_loss = 0.45927324177736933, disc_loss = 0.06384069028356713
Trained batch 564 in epoch 1, gen_loss = 0.4593747706012388, disc_loss = 0.06376833716259066
Trained batch 565 in epoch 1, gen_loss = 0.45939415235190845, disc_loss = 0.06368269638714542
Trained batch 566 in epoch 1, gen_loss = 0.459413304110263, disc_loss = 0.06358350555509382
Trained batch 567 in epoch 1, gen_loss = 0.4593665120782147, disc_loss = 0.06350582149732385
Trained batch 568 in epoch 1, gen_loss = 0.45941436327404633, disc_loss = 0.06344279795819616
Trained batch 569 in epoch 1, gen_loss = 0.4594038079182307, disc_loss = 0.06334607810468267
Trained batch 570 in epoch 1, gen_loss = 0.4594610327179503, disc_loss = 0.06326643431529846
Trained batch 571 in epoch 1, gen_loss = 0.4595115911085289, disc_loss = 0.06317872134968638
Trained batch 572 in epoch 1, gen_loss = 0.4594219577146034, disc_loss = 0.06308241560079976
Trained batch 573 in epoch 1, gen_loss = 0.4593789716111658, disc_loss = 0.06300579891166933
Trained batch 574 in epoch 1, gen_loss = 0.4594156777340433, disc_loss = 0.06293055125552675
Trained batch 575 in epoch 1, gen_loss = 0.45925621781498194, disc_loss = 0.06299546318930677
Trained batch 576 in epoch 1, gen_loss = 0.45926729500603636, disc_loss = 0.06330572618123151
Trained batch 577 in epoch 1, gen_loss = 0.4592784024955492, disc_loss = 0.06328786389457519
Trained batch 578 in epoch 1, gen_loss = 0.4593103420446162, disc_loss = 0.06324156720532242
Trained batch 579 in epoch 1, gen_loss = 0.4594242903179136, disc_loss = 0.06324057678595699
Trained batch 580 in epoch 1, gen_loss = 0.4592074267630323, disc_loss = 0.06353295071887273
Trained batch 581 in epoch 1, gen_loss = 0.45937537604181217, disc_loss = 0.06401405928342818
Trained batch 582 in epoch 1, gen_loss = 0.4592275437523529, disc_loss = 0.06433128141901914
Trained batch 583 in epoch 1, gen_loss = 0.4592115295770234, disc_loss = 0.06450603638890468
Trained batch 584 in epoch 1, gen_loss = 0.45900830845547536, disc_loss = 0.06468830051967221
Trained batch 585 in epoch 1, gen_loss = 0.45890256630275844, disc_loss = 0.06480212338624758
Trained batch 586 in epoch 1, gen_loss = 0.4587524959744546, disc_loss = 0.06512396854350068
Trained batch 587 in epoch 1, gen_loss = 0.4586110726302984, disc_loss = 0.06517398503742047
Trained batch 588 in epoch 1, gen_loss = 0.45847953307001216, disc_loss = 0.06515315390098682
Trained batch 589 in epoch 1, gen_loss = 0.45850327388714934, disc_loss = 0.06536707991765717
Trained batch 590 in epoch 1, gen_loss = 0.45825086239025675, disc_loss = 0.06559798093717514
Trained batch 591 in epoch 1, gen_loss = 0.4581890360427064, disc_loss = 0.06562321430474923
Trained batch 592 in epoch 1, gen_loss = 0.4581716436559796, disc_loss = 0.06560602015226727
Trained batch 593 in epoch 1, gen_loss = 0.4579836523994452, disc_loss = 0.0655859585863974
Trained batch 594 in epoch 1, gen_loss = 0.4579492941623976, disc_loss = 0.06554305855216098
Trained batch 595 in epoch 1, gen_loss = 0.4578673657054869, disc_loss = 0.06552134420497706
Trained batch 596 in epoch 1, gen_loss = 0.457905498930757, disc_loss = 0.06547197706410833
Trained batch 597 in epoch 1, gen_loss = 0.4578218670393711, disc_loss = 0.06538591753180609
Trained batch 598 in epoch 1, gen_loss = 0.45812806840333, disc_loss = 0.06535189350031453
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 0.4918617010116577, disc_loss = 0.027520742267370224
Trained batch 1 in epoch 2, gen_loss = 0.4755031019449234, disc_loss = 0.026654227636754513
Trained batch 2 in epoch 2, gen_loss = 0.46150729060173035, disc_loss = 0.022927877803643543
Trained batch 3 in epoch 2, gen_loss = 0.461879163980484, disc_loss = 0.023352526128292084
Trained batch 4 in epoch 2, gen_loss = 0.4610811710357666, disc_loss = 0.03106299489736557
Trained batch 5 in epoch 2, gen_loss = 0.4496707171201706, disc_loss = 0.03309458618362745
Trained batch 6 in epoch 2, gen_loss = 0.4371523644242968, disc_loss = 0.03439603692718914
Trained batch 7 in epoch 2, gen_loss = 0.42835071310400963, disc_loss = 0.038229362573474646
Trained batch 8 in epoch 2, gen_loss = 0.4327053858174218, disc_loss = 0.03532306974132856
Trained batch 9 in epoch 2, gen_loss = 0.43337099254131317, disc_loss = 0.03390178233385086
Trained batch 10 in epoch 2, gen_loss = 0.43745323473756964, disc_loss = 0.03180437043986537
Trained batch 11 in epoch 2, gen_loss = 0.44223419080177945, disc_loss = 0.030738717410713434
Trained batch 12 in epoch 2, gen_loss = 0.445479867550043, disc_loss = 0.029518310482112262
Trained batch 13 in epoch 2, gen_loss = 0.4475311828511102, disc_loss = 0.028304655304444686
Trained batch 14 in epoch 2, gen_loss = 0.4526304304599762, disc_loss = 0.027137897287805874
Trained batch 15 in epoch 2, gen_loss = 0.4563604649156332, disc_loss = 0.025887190276989713
Trained batch 16 in epoch 2, gen_loss = 0.4569967897499309, disc_loss = 0.024712170118137318
Trained batch 17 in epoch 2, gen_loss = 0.4557989256249534, disc_loss = 0.025597551035591297
Trained batch 18 in epoch 2, gen_loss = 0.4556799923118792, disc_loss = 0.02545698695374947
Trained batch 19 in epoch 2, gen_loss = 0.45426400005817413, disc_loss = 0.024887034832499922
Trained batch 20 in epoch 2, gen_loss = 0.4568289433206831, disc_loss = 0.024721465982674135
Trained batch 21 in epoch 2, gen_loss = 0.4576787027445706, disc_loss = 0.02497157537039708
Trained batch 22 in epoch 2, gen_loss = 0.46173838947130286, disc_loss = 0.03273886261993776
Trained batch 23 in epoch 2, gen_loss = 0.4590499761203925, disc_loss = 0.03851433298162495
Trained batch 24 in epoch 2, gen_loss = 0.4594926273822784, disc_loss = 0.03786077147349715
Trained batch 25 in epoch 2, gen_loss = 0.4590002034719174, disc_loss = 0.037913601899233
Trained batch 26 in epoch 2, gen_loss = 0.45908339156044853, disc_loss = 0.037348514819448744
Trained batch 27 in epoch 2, gen_loss = 0.45783989131450653, disc_loss = 0.03726830551334258
Trained batch 28 in epoch 2, gen_loss = 0.45672635477164697, disc_loss = 0.03834578939231819
Trained batch 29 in epoch 2, gen_loss = 0.4593351612488429, disc_loss = 0.037684473938619095
Trained batch 30 in epoch 2, gen_loss = 0.46126986222882427, disc_loss = 0.037321938427105066
Trained batch 31 in epoch 2, gen_loss = 0.45899952203035355, disc_loss = 0.03723656460351776
Trained batch 32 in epoch 2, gen_loss = 0.4596392042709119, disc_loss = 0.0376567761978191
Trained batch 33 in epoch 2, gen_loss = 0.4578947118099998, disc_loss = 0.03708743362906663
Trained batch 34 in epoch 2, gen_loss = 0.4590103030204773, disc_loss = 0.03627888516389898
Trained batch 35 in epoch 2, gen_loss = 0.458130757841799, disc_loss = 0.03546962326961673
Trained batch 36 in epoch 2, gen_loss = 0.45961898968026443, disc_loss = 0.03512941571455952
Trained batch 37 in epoch 2, gen_loss = 0.4592105895280838, disc_loss = 0.034689542433050904
Trained batch 38 in epoch 2, gen_loss = 0.4607719924205389, disc_loss = 0.03429714732397443
Trained batch 39 in epoch 2, gen_loss = 0.45993407890200616, disc_loss = 0.03369432754116133
Trained batch 40 in epoch 2, gen_loss = 0.4604338865454604, disc_loss = 0.033213505873502025
Trained batch 41 in epoch 2, gen_loss = 0.4601833380403973, disc_loss = 0.03275782126002014
Trained batch 42 in epoch 2, gen_loss = 0.4606390914251638, disc_loss = 0.03219518018886447
Trained batch 43 in epoch 2, gen_loss = 0.46006842770359735, disc_loss = 0.03167127903593196
Trained batch 44 in epoch 2, gen_loss = 0.45922361082500884, disc_loss = 0.03111724067065451
Trained batch 45 in epoch 2, gen_loss = 0.4586112512194592, disc_loss = 0.030759644188472757
Trained batch 46 in epoch 2, gen_loss = 0.4579574148705665, disc_loss = 0.030387609364821554
Trained batch 47 in epoch 2, gen_loss = 0.4582448365787665, disc_loss = 0.029943486714425187
Trained batch 48 in epoch 2, gen_loss = 0.46092694997787476, disc_loss = 0.02959593731377806
Trained batch 49 in epoch 2, gen_loss = 0.46108654260635373, disc_loss = 0.02930003471672535
Trained batch 50 in epoch 2, gen_loss = 0.4609565986137764, disc_loss = 0.029138798515001934
Trained batch 51 in epoch 2, gen_loss = 0.4604584202170372, disc_loss = 0.029139845202175472
Trained batch 52 in epoch 2, gen_loss = 0.4614245706009415, disc_loss = 0.029103030257348745
Trained batch 53 in epoch 2, gen_loss = 0.46044497191905975, disc_loss = 0.028890496395804263
Trained batch 54 in epoch 2, gen_loss = 0.46054179234938186, disc_loss = 0.02850783011791381
Trained batch 55 in epoch 2, gen_loss = 0.46208215185574125, disc_loss = 0.028180622246249447
Trained batch 56 in epoch 2, gen_loss = 0.46122291997859355, disc_loss = 0.02784586938000039
Trained batch 57 in epoch 2, gen_loss = 0.4629759392861662, disc_loss = 0.02767202031702317
Trained batch 58 in epoch 2, gen_loss = 0.46279136710247754, disc_loss = 0.027426813255553528
Trained batch 59 in epoch 2, gen_loss = 0.46224654614925387, disc_loss = 0.027307391554738086
Trained batch 60 in epoch 2, gen_loss = 0.46270254596334986, disc_loss = 0.027070666296926678
Trained batch 61 in epoch 2, gen_loss = 0.4629969673772012, disc_loss = 0.02712676708676642
Trained batch 62 in epoch 2, gen_loss = 0.4628988830816178, disc_loss = 0.027005060753297238
Trained batch 63 in epoch 2, gen_loss = 0.4621449811384082, disc_loss = 0.026863842402235605
Trained batch 64 in epoch 2, gen_loss = 0.46313931391789365, disc_loss = 0.02696291616616341
Trained batch 65 in epoch 2, gen_loss = 0.4632390182126652, disc_loss = 0.02682326825787172
Trained batch 66 in epoch 2, gen_loss = 0.4630426355262301, disc_loss = 0.026560858684355645
Trained batch 67 in epoch 2, gen_loss = 0.46370851379983563, disc_loss = 0.026635170763577607
Trained batch 68 in epoch 2, gen_loss = 0.4648408820663673, disc_loss = 0.026657310179502205
Trained batch 69 in epoch 2, gen_loss = 0.4643748747450965, disc_loss = 0.0265351260746164
Trained batch 70 in epoch 2, gen_loss = 0.46437469964296046, disc_loss = 0.02624367847776329
Trained batch 71 in epoch 2, gen_loss = 0.4639223983718289, disc_loss = 0.02609698912904908
Trained batch 72 in epoch 2, gen_loss = 0.4644660863974323, disc_loss = 0.025891524739563465
Trained batch 73 in epoch 2, gen_loss = 0.4649012793560286, disc_loss = 0.02663277750331405
Trained batch 74 in epoch 2, gen_loss = 0.4652990714708964, disc_loss = 0.027926181219518186
Trained batch 75 in epoch 2, gen_loss = 0.4651179960683772, disc_loss = 0.027860008388463604
Trained batch 76 in epoch 2, gen_loss = 0.465601319229448, disc_loss = 0.028184842910956253
Trained batch 77 in epoch 2, gen_loss = 0.4659089212998366, disc_loss = 0.028477528216078494
Trained batch 78 in epoch 2, gen_loss = 0.4655692566044723, disc_loss = 0.028248671289014666
Trained batch 79 in epoch 2, gen_loss = 0.46599053740501406, disc_loss = 0.028071610000915827
Trained batch 80 in epoch 2, gen_loss = 0.4648429471769451, disc_loss = 0.028082167729735374
Trained batch 81 in epoch 2, gen_loss = 0.46481947164709975, disc_loss = 0.02815345922348703
Trained batch 82 in epoch 2, gen_loss = 0.4640774730458317, disc_loss = 0.02805255674364337
Trained batch 83 in epoch 2, gen_loss = 0.4641082120083627, disc_loss = 0.028024704705569007
Trained batch 84 in epoch 2, gen_loss = 0.46424849909894605, disc_loss = 0.02794504286173512
Trained batch 85 in epoch 2, gen_loss = 0.46406265608100006, disc_loss = 0.027837652778036372
Trained batch 86 in epoch 2, gen_loss = 0.4641654381806823, disc_loss = 0.027603760522244305
Trained batch 87 in epoch 2, gen_loss = 0.4640962996266105, disc_loss = 0.027424070444381374
Trained batch 88 in epoch 2, gen_loss = 0.46374379115158254, disc_loss = 0.027201895790404818
Trained batch 89 in epoch 2, gen_loss = 0.4638520171244939, disc_loss = 0.026994016425063213
Trained batch 90 in epoch 2, gen_loss = 0.4649792395450257, disc_loss = 0.026800865870337566
Trained batch 91 in epoch 2, gen_loss = 0.4651439397231392, disc_loss = 0.026731020416659507
Trained batch 92 in epoch 2, gen_loss = 0.465611937866416, disc_loss = 0.026871660073357884
Trained batch 93 in epoch 2, gen_loss = 0.46531251643566374, disc_loss = 0.02667951826600635
Trained batch 94 in epoch 2, gen_loss = 0.46473614008803116, disc_loss = 0.026494455563002513
Trained batch 95 in epoch 2, gen_loss = 0.46513169662406045, disc_loss = 0.026391075254650787
Trained batch 96 in epoch 2, gen_loss = 0.46504519495767416, disc_loss = 0.026255307632700068
Trained batch 97 in epoch 2, gen_loss = 0.4647458466340084, disc_loss = 0.026184745313485667
Trained batch 98 in epoch 2, gen_loss = 0.46489532577871073, disc_loss = 0.026291588067331097
Trained batch 99 in epoch 2, gen_loss = 0.46532924443483353, disc_loss = 0.026186130000278352
Trained batch 100 in epoch 2, gen_loss = 0.4651929145992392, disc_loss = 0.02617972321107541
Trained batch 101 in epoch 2, gen_loss = 0.46525561751103867, disc_loss = 0.02651009408245776
Trained batch 102 in epoch 2, gen_loss = 0.46542729365015495, disc_loss = 0.02654961110499588
Trained batch 103 in epoch 2, gen_loss = 0.46503401146485257, disc_loss = 0.02645755456223224
Trained batch 104 in epoch 2, gen_loss = 0.46558231796537125, disc_loss = 0.026583194315788292
Trained batch 105 in epoch 2, gen_loss = 0.465013270108205, disc_loss = 0.026638151207973935
Trained batch 106 in epoch 2, gen_loss = 0.4648284622441942, disc_loss = 0.02651977809755323
Trained batch 107 in epoch 2, gen_loss = 0.4653993006105776, disc_loss = 0.026405075349396578
Trained batch 108 in epoch 2, gen_loss = 0.4649585460850952, disc_loss = 0.02636576102995271
Trained batch 109 in epoch 2, gen_loss = 0.4654223081740466, disc_loss = 0.026761239978738808
Trained batch 110 in epoch 2, gen_loss = 0.464595806759757, disc_loss = 0.027686839243648825
Trained batch 111 in epoch 2, gen_loss = 0.46457082724996973, disc_loss = 0.030771451411835318
Trained batch 112 in epoch 2, gen_loss = 0.46354392039037384, disc_loss = 0.03294300407467954
Trained batch 113 in epoch 2, gen_loss = 0.4628671731865197, disc_loss = 0.033444089790512076
Trained batch 114 in epoch 2, gen_loss = 0.4627007326354151, disc_loss = 0.033703307491605695
Trained batch 115 in epoch 2, gen_loss = 0.46303727118105725, disc_loss = 0.034006195728956114
Trained batch 116 in epoch 2, gen_loss = 0.4632403720647861, disc_loss = 0.03415530153478567
Trained batch 117 in epoch 2, gen_loss = 0.46280953742690006, disc_loss = 0.0346066657280139
Trained batch 118 in epoch 2, gen_loss = 0.4623603733146892, disc_loss = 0.034814008965524806
Trained batch 119 in epoch 2, gen_loss = 0.46279602323969204, disc_loss = 0.03485319022244463
Trained batch 120 in epoch 2, gen_loss = 0.46226182629254237, disc_loss = 0.03559451264691008
Trained batch 121 in epoch 2, gen_loss = 0.4623887350813287, disc_loss = 0.03550206629376187
Trained batch 122 in epoch 2, gen_loss = 0.46253639241544214, disc_loss = 0.0357818199866792
Trained batch 123 in epoch 2, gen_loss = 0.4619910488686254, disc_loss = 0.03581090016861356
Trained batch 124 in epoch 2, gen_loss = 0.4621179358959198, disc_loss = 0.03558772160857916
Trained batch 125 in epoch 2, gen_loss = 0.461543345971713, disc_loss = 0.035464547744523435
Trained batch 126 in epoch 2, gen_loss = 0.4614073643534202, disc_loss = 0.03530407241567617
Trained batch 127 in epoch 2, gen_loss = 0.4611430508084595, disc_loss = 0.03511136969609652
Trained batch 128 in epoch 2, gen_loss = 0.4610133841056232, disc_loss = 0.03506154933756636
Trained batch 129 in epoch 2, gen_loss = 0.46141907343497646, disc_loss = 0.03488455476382604
Trained batch 130 in epoch 2, gen_loss = 0.4615508793419554, disc_loss = 0.03466761405117639
Trained batch 131 in epoch 2, gen_loss = 0.46178223531354556, disc_loss = 0.0344757351417546
Trained batch 132 in epoch 2, gen_loss = 0.46201071972237495, disc_loss = 0.03435800572563159
Trained batch 133 in epoch 2, gen_loss = 0.46198639273643494, disc_loss = 0.034137345968620544
Trained batch 134 in epoch 2, gen_loss = 0.4613977597819434, disc_loss = 0.03399705147301709
Trained batch 135 in epoch 2, gen_loss = 0.4616797814036117, disc_loss = 0.03379721929291811
Trained batch 136 in epoch 2, gen_loss = 0.46146325277586053, disc_loss = 0.03358962598943362
Trained batch 137 in epoch 2, gen_loss = 0.46104874904604926, disc_loss = 0.03355629123963308
Trained batch 138 in epoch 2, gen_loss = 0.4600052531245801, disc_loss = 0.03419449601134808
Trained batch 139 in epoch 2, gen_loss = 0.4603082390768187, disc_loss = 0.03499662958617721
Trained batch 140 in epoch 2, gen_loss = 0.46053807088669313, disc_loss = 0.03491058829405629
Trained batch 141 in epoch 2, gen_loss = 0.45991154476790364, disc_loss = 0.034738148811837316
Trained batch 142 in epoch 2, gen_loss = 0.45935947036409713, disc_loss = 0.034774443330047845
Trained batch 143 in epoch 2, gen_loss = 0.45875259882046115, disc_loss = 0.0348282673706611
Trained batch 144 in epoch 2, gen_loss = 0.45875152596111957, disc_loss = 0.03477168792280658
Trained batch 145 in epoch 2, gen_loss = 0.4585619040139734, disc_loss = 0.034636012597443304
Trained batch 146 in epoch 2, gen_loss = 0.45877353735521537, disc_loss = 0.03449001055540276
Trained batch 147 in epoch 2, gen_loss = 0.45937561324319326, disc_loss = 0.034303175250848604
Trained batch 148 in epoch 2, gen_loss = 0.45957569067910214, disc_loss = 0.03419203996570818
Trained batch 149 in epoch 2, gen_loss = 0.45976469417413074, disc_loss = 0.03405257422787448
Trained batch 150 in epoch 2, gen_loss = 0.45955023406357165, disc_loss = 0.033868202409207425
Trained batch 151 in epoch 2, gen_loss = 0.45959826754896266, disc_loss = 0.03368337720779604
Trained batch 152 in epoch 2, gen_loss = 0.45958786657433104, disc_loss = 0.03357944469533715
Trained batch 153 in epoch 2, gen_loss = 0.4594700868640627, disc_loss = 0.03345650623177553
Trained batch 154 in epoch 2, gen_loss = 0.45945211418213383, disc_loss = 0.03330311310747939
Trained batch 155 in epoch 2, gen_loss = 0.45960664882873875, disc_loss = 0.033262358960480645
Trained batch 156 in epoch 2, gen_loss = 0.45941069703193227, disc_loss = 0.03315175999145789
Trained batch 157 in epoch 2, gen_loss = 0.4591576590945449, disc_loss = 0.03303422384506351
Trained batch 158 in epoch 2, gen_loss = 0.4591249694239418, disc_loss = 0.03287386361790715
Trained batch 159 in epoch 2, gen_loss = 0.4588896367698908, disc_loss = 0.03277337296749465
Trained batch 160 in epoch 2, gen_loss = 0.45832326934204337, disc_loss = 0.03261011034562628
Trained batch 161 in epoch 2, gen_loss = 0.45807849312270127, disc_loss = 0.03265900326674275
Trained batch 162 in epoch 2, gen_loss = 0.45883359371518795, disc_loss = 0.033189517551564546
Trained batch 163 in epoch 2, gen_loss = 0.4584824599143935, disc_loss = 0.03363581075298986
Trained batch 164 in epoch 2, gen_loss = 0.45882902326005875, disc_loss = 0.03378812089054422
Trained batch 165 in epoch 2, gen_loss = 0.4585585775504629, disc_loss = 0.03405058725894126
Trained batch 166 in epoch 2, gen_loss = 0.45862889628924297, disc_loss = 0.03462706658777273
Trained batch 167 in epoch 2, gen_loss = 0.45859856264931814, disc_loss = 0.03495215749578728
Trained batch 168 in epoch 2, gen_loss = 0.458811507246198, disc_loss = 0.03498172145832837
Trained batch 169 in epoch 2, gen_loss = 0.45866426036638375, disc_loss = 0.034984272354118086
Trained batch 170 in epoch 2, gen_loss = 0.4586858217827758, disc_loss = 0.03486171836708808
Trained batch 171 in epoch 2, gen_loss = 0.45913944705281146, disc_loss = 0.03471245933703125
Trained batch 172 in epoch 2, gen_loss = 0.45929922619996044, disc_loss = 0.03467199202853045
Trained batch 173 in epoch 2, gen_loss = 0.45900442082991544, disc_loss = 0.03466387496372664
Trained batch 174 in epoch 2, gen_loss = 0.45969572799546377, disc_loss = 0.03453721440530249
Trained batch 175 in epoch 2, gen_loss = 0.4595790959217332, disc_loss = 0.03445197632589208
Trained batch 176 in epoch 2, gen_loss = 0.459669193979037, disc_loss = 0.034296343842321365
Trained batch 177 in epoch 2, gen_loss = 0.4595572233534931, disc_loss = 0.03415221963967249
Trained batch 178 in epoch 2, gen_loss = 0.4594833830881385, disc_loss = 0.0341048244537796
Trained batch 179 in epoch 2, gen_loss = 0.4598972453011407, disc_loss = 0.03429133226939787
Trained batch 180 in epoch 2, gen_loss = 0.45995295097156125, disc_loss = 0.03436587962131556
Trained batch 181 in epoch 2, gen_loss = 0.4598542713856959, disc_loss = 0.03427243843971455
Trained batch 182 in epoch 2, gen_loss = 0.460339219843755, disc_loss = 0.03414988848813326
Trained batch 183 in epoch 2, gen_loss = 0.46039914469356125, disc_loss = 0.03400639091547498
Trained batch 184 in epoch 2, gen_loss = 0.46071765519477226, disc_loss = 0.03399121642767175
Trained batch 185 in epoch 2, gen_loss = 0.4603350867507278, disc_loss = 0.03393582098676713
Trained batch 186 in epoch 2, gen_loss = 0.46054140338923205, disc_loss = 0.03383498943913828
Trained batch 187 in epoch 2, gen_loss = 0.4608181047629803, disc_loss = 0.03371938935510735
Trained batch 188 in epoch 2, gen_loss = 0.4608573834732096, disc_loss = 0.033634208095944904
Trained batch 189 in epoch 2, gen_loss = 0.46118119766837673, disc_loss = 0.03350270058420536
Trained batch 190 in epoch 2, gen_loss = 0.460913686072015, disc_loss = 0.033395904367448305
Trained batch 191 in epoch 2, gen_loss = 0.4614113244848947, disc_loss = 0.0333636016609186
Trained batch 192 in epoch 2, gen_loss = 0.4613807104103306, disc_loss = 0.033240079529911586
Trained batch 193 in epoch 2, gen_loss = 0.46110014801787347, disc_loss = 0.03332755374530157
Trained batch 194 in epoch 2, gen_loss = 0.4609574337800344, disc_loss = 0.03359233039455154
Trained batch 195 in epoch 2, gen_loss = 0.46058725109513926, disc_loss = 0.033675640039811175
Trained batch 196 in epoch 2, gen_loss = 0.4607893466041778, disc_loss = 0.03360501075220214
Trained batch 197 in epoch 2, gen_loss = 0.4610372298594677, disc_loss = 0.033598502662804244
Trained batch 198 in epoch 2, gen_loss = 0.4606133744345238, disc_loss = 0.03350890852539009
Trained batch 199 in epoch 2, gen_loss = 0.4604541300237179, disc_loss = 0.03339928500121459
Trained batch 200 in epoch 2, gen_loss = 0.4606710341735859, disc_loss = 0.033310755566040524
Trained batch 201 in epoch 2, gen_loss = 0.4605657781409745, disc_loss = 0.03319120539656591
Trained batch 202 in epoch 2, gen_loss = 0.46067880732672556, disc_loss = 0.033094976480426315
Trained batch 203 in epoch 2, gen_loss = 0.46079088206969054, disc_loss = 0.03297718709069943
Trained batch 204 in epoch 2, gen_loss = 0.46070081228163184, disc_loss = 0.032877079576889914
Trained batch 205 in epoch 2, gen_loss = 0.4609588781028118, disc_loss = 0.032758042675180774
Trained batch 206 in epoch 2, gen_loss = 0.46103005535936586, disc_loss = 0.03264527951686638
Trained batch 207 in epoch 2, gen_loss = 0.46113407611846924, disc_loss = 0.032515185950055286
Trained batch 208 in epoch 2, gen_loss = 0.4611886979290173, disc_loss = 0.032450530876329785
Trained batch 209 in epoch 2, gen_loss = 0.4615397217727843, disc_loss = 0.03233202767247955
Trained batch 210 in epoch 2, gen_loss = 0.46153831001706597, disc_loss = 0.03221281810765159
Trained batch 211 in epoch 2, gen_loss = 0.46175420087463454, disc_loss = 0.03208453229514285
Trained batch 212 in epoch 2, gen_loss = 0.46177191927399436, disc_loss = 0.03196391522088591
Trained batch 213 in epoch 2, gen_loss = 0.46200837334182776, disc_loss = 0.0318778086492844
Trained batch 214 in epoch 2, gen_loss = 0.4622125424617945, disc_loss = 0.03190011889132303
Trained batch 215 in epoch 2, gen_loss = 0.462008501506514, disc_loss = 0.031802731719195704
Trained batch 216 in epoch 2, gen_loss = 0.46227811517253997, disc_loss = 0.03174680044599873
Trained batch 217 in epoch 2, gen_loss = 0.46176564105606954, disc_loss = 0.03167647150464766
Trained batch 218 in epoch 2, gen_loss = 0.4617719565896683, disc_loss = 0.03160011090686945
Trained batch 219 in epoch 2, gen_loss = 0.46179682964628394, disc_loss = 0.03148337688127702
Trained batch 220 in epoch 2, gen_loss = 0.46173597865514626, disc_loss = 0.031456884738411836
Trained batch 221 in epoch 2, gen_loss = 0.461470346998524, disc_loss = 0.03145420470753232
Trained batch 222 in epoch 2, gen_loss = 0.46128427421030976, disc_loss = 0.03138285998104667
Trained batch 223 in epoch 2, gen_loss = 0.4615204084132399, disc_loss = 0.03150314575759694
Trained batch 224 in epoch 2, gen_loss = 0.46179867267608643, disc_loss = 0.031518438930312795
Trained batch 225 in epoch 2, gen_loss = 0.46164015502528805, disc_loss = 0.031700201637515454
Trained batch 226 in epoch 2, gen_loss = 0.46173226754570845, disc_loss = 0.03193493388461909
Trained batch 227 in epoch 2, gen_loss = 0.4619967762315482, disc_loss = 0.032013713145269115
Trained batch 228 in epoch 2, gen_loss = 0.46195665066939773, disc_loss = 0.03214763056926071
Trained batch 229 in epoch 2, gen_loss = 0.4622068957142208, disc_loss = 0.032246910966932774
Trained batch 230 in epoch 2, gen_loss = 0.46212864980037077, disc_loss = 0.032329271196738465
Trained batch 231 in epoch 2, gen_loss = 0.462439493115606, disc_loss = 0.032391850989119245
Trained batch 232 in epoch 2, gen_loss = 0.46268724192877186, disc_loss = 0.03233090228533028
Trained batch 233 in epoch 2, gen_loss = 0.4626322014209552, disc_loss = 0.032226385206429876
Trained batch 234 in epoch 2, gen_loss = 0.46269254976130547, disc_loss = 0.03212318475100588
Trained batch 235 in epoch 2, gen_loss = 0.4627396367111449, disc_loss = 0.03201660327810668
Trained batch 236 in epoch 2, gen_loss = 0.4626004636790682, disc_loss = 0.031900190239387095
Trained batch 237 in epoch 2, gen_loss = 0.4623776758167924, disc_loss = 0.03181086623250749
Trained batch 238 in epoch 2, gen_loss = 0.46262573111007405, disc_loss = 0.03171266914855798
Trained batch 239 in epoch 2, gen_loss = 0.4626543038835128, disc_loss = 0.0316589270272137
Trained batch 240 in epoch 2, gen_loss = 0.4627875043890783, disc_loss = 0.03155667702493517
Trained batch 241 in epoch 2, gen_loss = 0.4629404039914943, disc_loss = 0.031514136211115346
Trained batch 242 in epoch 2, gen_loss = 0.46293084905961907, disc_loss = 0.03148216770869898
Trained batch 243 in epoch 2, gen_loss = 0.46314730312003466, disc_loss = 0.03142232370570485
Trained batch 244 in epoch 2, gen_loss = 0.46331040153698044, disc_loss = 0.03133066343903846
Trained batch 245 in epoch 2, gen_loss = 0.4632357417083368, disc_loss = 0.03126272323117327
Trained batch 246 in epoch 2, gen_loss = 0.462916506808779, disc_loss = 0.031223136269928592
Trained batch 247 in epoch 2, gen_loss = 0.46309217125658064, disc_loss = 0.03126566774669975
Trained batch 248 in epoch 2, gen_loss = 0.4629244302889429, disc_loss = 0.03120453648426267
Trained batch 249 in epoch 2, gen_loss = 0.46300943183898924, disc_loss = 0.031190478207543493
Trained batch 250 in epoch 2, gen_loss = 0.46314523455156276, disc_loss = 0.031303313343722626
Trained batch 251 in epoch 2, gen_loss = 0.4630304312422162, disc_loss = 0.03141164790195901
Trained batch 252 in epoch 2, gen_loss = 0.4631881760985484, disc_loss = 0.031495859222523424
Trained batch 253 in epoch 2, gen_loss = 0.46311619572752105, disc_loss = 0.03144801087039486
Trained batch 254 in epoch 2, gen_loss = 0.4631695105749018, disc_loss = 0.031370556714268874
Trained batch 255 in epoch 2, gen_loss = 0.46310142742004246, disc_loss = 0.0312743258291448
Trained batch 256 in epoch 2, gen_loss = 0.4632896434240304, disc_loss = 0.031217353581541474
Trained batch 257 in epoch 2, gen_loss = 0.46314197824906933, disc_loss = 0.031131579847501
Trained batch 258 in epoch 2, gen_loss = 0.46305825742515355, disc_loss = 0.031065138574675244
Trained batch 259 in epoch 2, gen_loss = 0.46334326611115384, disc_loss = 0.03098925915904916
Trained batch 260 in epoch 2, gen_loss = 0.46339957558789013, disc_loss = 0.03090296954744392
Trained batch 261 in epoch 2, gen_loss = 0.46325201296624335, disc_loss = 0.030824839311673215
Trained batch 262 in epoch 2, gen_loss = 0.4633162656211128, disc_loss = 0.03072964143319615
Trained batch 263 in epoch 2, gen_loss = 0.4634122360836376, disc_loss = 0.030651200340468098
Trained batch 264 in epoch 2, gen_loss = 0.46348348023756497, disc_loss = 0.030558152479242602
Trained batch 265 in epoch 2, gen_loss = 0.4632815646945982, disc_loss = 0.030476751194608614
Trained batch 266 in epoch 2, gen_loss = 0.4636598008402278, disc_loss = 0.030406295370715163
Trained batch 267 in epoch 2, gen_loss = 0.4635555290464145, disc_loss = 0.03041932727349227
Trained batch 268 in epoch 2, gen_loss = 0.46358584914508805, disc_loss = 0.030576319731494973
Trained batch 269 in epoch 2, gen_loss = 0.46386342136948194, disc_loss = 0.030522779371865368
Trained batch 270 in epoch 2, gen_loss = 0.46374034826605964, disc_loss = 0.03044839991717101
Trained batch 271 in epoch 2, gen_loss = 0.46328216703499064, disc_loss = 0.030420801335233536
Trained batch 272 in epoch 2, gen_loss = 0.463532336465605, disc_loss = 0.030342375436599876
Trained batch 273 in epoch 2, gen_loss = 0.4636330090082475, disc_loss = 0.0303011130827078
Trained batch 274 in epoch 2, gen_loss = 0.46353148839690467, disc_loss = 0.03023779474198818
Trained batch 275 in epoch 2, gen_loss = 0.46371418421251187, disc_loss = 0.03020085695375135
Trained batch 276 in epoch 2, gen_loss = 0.46387060164114197, disc_loss = 0.030190566104134068
Trained batch 277 in epoch 2, gen_loss = 0.46392603143513633, disc_loss = 0.03012655232530489
Trained batch 278 in epoch 2, gen_loss = 0.46393201470802337, disc_loss = 0.03006015949979371
Trained batch 279 in epoch 2, gen_loss = 0.4641320220061711, disc_loss = 0.030045932208720063
Trained batch 280 in epoch 2, gen_loss = 0.4640269235996165, disc_loss = 0.03001173237318776
Trained batch 281 in epoch 2, gen_loss = 0.46379655039479545, disc_loss = 0.02995512072089399
Trained batch 282 in epoch 2, gen_loss = 0.4637537276365732, disc_loss = 0.0299496361393442
Trained batch 283 in epoch 2, gen_loss = 0.4639570954400049, disc_loss = 0.03001680296294811
Trained batch 284 in epoch 2, gen_loss = 0.4637064586605942, disc_loss = 0.029950640703502455
Trained batch 285 in epoch 2, gen_loss = 0.46382805006904204, disc_loss = 0.029962328920414397
Trained batch 286 in epoch 2, gen_loss = 0.4637433598888876, disc_loss = 0.0299233138587209
Trained batch 287 in epoch 2, gen_loss = 0.4637304261947672, disc_loss = 0.0298536613311929
Trained batch 288 in epoch 2, gen_loss = 0.46375641278329605, disc_loss = 0.02979693661692027
Trained batch 289 in epoch 2, gen_loss = 0.463569129952069, disc_loss = 0.029752010357534064
Trained batch 290 in epoch 2, gen_loss = 0.46369364949845776, disc_loss = 0.029883908594340803
Trained batch 291 in epoch 2, gen_loss = 0.46368648183264144, disc_loss = 0.029849582128481916
Trained batch 292 in epoch 2, gen_loss = 0.4634501956428684, disc_loss = 0.029981776099308764
Trained batch 293 in epoch 2, gen_loss = 0.46388745591754005, disc_loss = 0.031096700496566133
Trained batch 294 in epoch 2, gen_loss = 0.4638391823081647, disc_loss = 0.031605521797881286
Trained batch 295 in epoch 2, gen_loss = 0.46353897754404993, disc_loss = 0.03178452193812543
Trained batch 296 in epoch 2, gen_loss = 0.4635291701615459, disc_loss = 0.03205484853624695
Trained batch 297 in epoch 2, gen_loss = 0.46333486641813443, disc_loss = 0.03246111367147841
Trained batch 298 in epoch 2, gen_loss = 0.46315629137399605, disc_loss = 0.03295450808984978
Trained batch 299 in epoch 2, gen_loss = 0.4629658424854279, disc_loss = 0.033349773529917
Trained batch 300 in epoch 2, gen_loss = 0.4626767366035436, disc_loss = 0.03347462588345688
Trained batch 301 in epoch 2, gen_loss = 0.4628434891732323, disc_loss = 0.03358458226164248
Trained batch 302 in epoch 2, gen_loss = 0.4628419301690835, disc_loss = 0.033764591624978746
Trained batch 303 in epoch 2, gen_loss = 0.4628831620671247, disc_loss = 0.03377947318490202
Trained batch 304 in epoch 2, gen_loss = 0.4626653756274552, disc_loss = 0.033736057445162636
Trained batch 305 in epoch 2, gen_loss = 0.46270495117489807, disc_loss = 0.03367192112518097
Trained batch 306 in epoch 2, gen_loss = 0.46282785499911355, disc_loss = 0.03359968536791273
Trained batch 307 in epoch 2, gen_loss = 0.4628553566607562, disc_loss = 0.03351389166336603
Trained batch 308 in epoch 2, gen_loss = 0.46276625634011326, disc_loss = 0.03342799094134887
Trained batch 309 in epoch 2, gen_loss = 0.4628682863327765, disc_loss = 0.033335881222099545
Trained batch 310 in epoch 2, gen_loss = 0.4626700986428276, disc_loss = 0.03330470910715089
Trained batch 311 in epoch 2, gen_loss = 0.46252673386763304, disc_loss = 0.03324728632698026
Trained batch 312 in epoch 2, gen_loss = 0.4629234498301253, disc_loss = 0.03320294560733647
Trained batch 313 in epoch 2, gen_loss = 0.46269861585015704, disc_loss = 0.033163125387980205
Trained batch 314 in epoch 2, gen_loss = 0.4625304132226914, disc_loss = 0.033137855109655195
Trained batch 315 in epoch 2, gen_loss = 0.4625857849664326, disc_loss = 0.03306830894714811
Trained batch 316 in epoch 2, gen_loss = 0.462553424414024, disc_loss = 0.03301084277364029
Trained batch 317 in epoch 2, gen_loss = 0.46235601407177046, disc_loss = 0.03299015088727311
Trained batch 318 in epoch 2, gen_loss = 0.4624210520410986, disc_loss = 0.032951542420085043
Trained batch 319 in epoch 2, gen_loss = 0.4624604486860335, disc_loss = 0.03287231538561173
Trained batch 320 in epoch 2, gen_loss = 0.46258040798416017, disc_loss = 0.032797919139498116
Trained batch 321 in epoch 2, gen_loss = 0.4626340175637547, disc_loss = 0.03274879200812082
Trained batch 322 in epoch 2, gen_loss = 0.4628400451996747, disc_loss = 0.032666617848740274
Trained batch 323 in epoch 2, gen_loss = 0.46280358639764196, disc_loss = 0.03261609574388943
Trained batch 324 in epoch 2, gen_loss = 0.46287436035963203, disc_loss = 0.032544272444569144
Trained batch 325 in epoch 2, gen_loss = 0.46275188641314124, disc_loss = 0.03247248508790337
Trained batch 326 in epoch 2, gen_loss = 0.46281122933469415, disc_loss = 0.03239643358446043
Trained batch 327 in epoch 2, gen_loss = 0.46260887547964, disc_loss = 0.032343804404684685
Trained batch 328 in epoch 2, gen_loss = 0.462663851610433, disc_loss = 0.03229190472592699
Trained batch 329 in epoch 2, gen_loss = 0.46276185205488496, disc_loss = 0.032229337158302465
Trained batch 330 in epoch 2, gen_loss = 0.46293082572182137, disc_loss = 0.03217320410349038
Trained batch 331 in epoch 2, gen_loss = 0.4627667546990406, disc_loss = 0.032096130105790245
Trained batch 332 in epoch 2, gen_loss = 0.46275418853616573, disc_loss = 0.03201614931930561
Trained batch 333 in epoch 2, gen_loss = 0.4628188104151252, disc_loss = 0.03194350472645845
Trained batch 334 in epoch 2, gen_loss = 0.4627811794850364, disc_loss = 0.03188012682123861
Trained batch 335 in epoch 2, gen_loss = 0.4626405073241109, disc_loss = 0.03182165290040541
Trained batch 336 in epoch 2, gen_loss = 0.46267629014632117, disc_loss = 0.0317423684641343
Trained batch 337 in epoch 2, gen_loss = 0.46276299531995896, disc_loss = 0.03171824445237113
Trained batch 338 in epoch 2, gen_loss = 0.4625041657141176, disc_loss = 0.031670787282408956
Trained batch 339 in epoch 2, gen_loss = 0.4624966840533649, disc_loss = 0.03163242550594184
Trained batch 340 in epoch 2, gen_loss = 0.4625124831703052, disc_loss = 0.031569120437289176
Trained batch 341 in epoch 2, gen_loss = 0.46262774673121715, disc_loss = 0.031510321427496116
Trained batch 342 in epoch 2, gen_loss = 0.4627727775810064, disc_loss = 0.031449042601407705
Trained batch 343 in epoch 2, gen_loss = 0.4627878705776015, disc_loss = 0.031455395595701194
Trained batch 344 in epoch 2, gen_loss = 0.4628388625988062, disc_loss = 0.03138815262152449
Trained batch 345 in epoch 2, gen_loss = 0.46295028339231636, disc_loss = 0.03133464380533494
Trained batch 346 in epoch 2, gen_loss = 0.46317842714381147, disc_loss = 0.03127680611944293
Trained batch 347 in epoch 2, gen_loss = 0.46333369732588187, disc_loss = 0.03128017490895615
Trained batch 348 in epoch 2, gen_loss = 0.463436963650422, disc_loss = 0.03120792549194229
Trained batch 349 in epoch 2, gen_loss = 0.463415475998606, disc_loss = 0.031169739667592303
Trained batch 350 in epoch 2, gen_loss = 0.4635521751693171, disc_loss = 0.03109502211409459
Trained batch 351 in epoch 2, gen_loss = 0.46365951297974045, disc_loss = 0.031076590399607085
Trained batch 352 in epoch 2, gen_loss = 0.4637777693041999, disc_loss = 0.031053953528372577
Trained batch 353 in epoch 2, gen_loss = 0.4637732105908421, disc_loss = 0.030993574031886493
Trained batch 354 in epoch 2, gen_loss = 0.4638645337501042, disc_loss = 0.03097970285387316
Trained batch 355 in epoch 2, gen_loss = 0.46365743264388504, disc_loss = 0.031095516073957
Trained batch 356 in epoch 2, gen_loss = 0.4637570177473608, disc_loss = 0.03123955371338321
Trained batch 357 in epoch 2, gen_loss = 0.4635235380027547, disc_loss = 0.031178443743353032
Trained batch 358 in epoch 2, gen_loss = 0.46360714804163217, disc_loss = 0.031148136423480462
Trained batch 359 in epoch 2, gen_loss = 0.4635994942651855, disc_loss = 0.031133476074319332
Trained batch 360 in epoch 2, gen_loss = 0.4635480919703222, disc_loss = 0.03112048230977559
Trained batch 361 in epoch 2, gen_loss = 0.46379397192054034, disc_loss = 0.031067827874691693
Trained batch 362 in epoch 2, gen_loss = 0.4637892428508475, disc_loss = 0.031044123929055516
Trained batch 363 in epoch 2, gen_loss = 0.4639618368921699, disc_loss = 0.031091038765805355
Trained batch 364 in epoch 2, gen_loss = 0.46402988646128407, disc_loss = 0.031066075823435638
Trained batch 365 in epoch 2, gen_loss = 0.46407515616690526, disc_loss = 0.03101418007933662
Trained batch 366 in epoch 2, gen_loss = 0.46393132786335023, disc_loss = 0.03096963198632205
Trained batch 367 in epoch 2, gen_loss = 0.4640903888351243, disc_loss = 0.03090784394146834
Trained batch 368 in epoch 2, gen_loss = 0.464162084468335, disc_loss = 0.03094196288409797
Trained batch 369 in epoch 2, gen_loss = 0.46416812305514876, disc_loss = 0.030913354951032514
Trained batch 370 in epoch 2, gen_loss = 0.46441436898354893, disc_loss = 0.03088124482101708
Trained batch 371 in epoch 2, gen_loss = 0.4644989183032385, disc_loss = 0.03086807574921598
Trained batch 372 in epoch 2, gen_loss = 0.46461086178912553, disc_loss = 0.030850299562879366
Trained batch 373 in epoch 2, gen_loss = 0.46446306955686867, disc_loss = 0.030786880969323895
Trained batch 374 in epoch 2, gen_loss = 0.4642760072549184, disc_loss = 0.030781433423360188
Trained batch 375 in epoch 2, gen_loss = 0.4644131206293055, disc_loss = 0.03118470655952362
Trained batch 376 in epoch 2, gen_loss = 0.46410332339511945, disc_loss = 0.031852175805233515
Trained batch 377 in epoch 2, gen_loss = 0.46420728923782467, disc_loss = 0.032467997539295725
Trained batch 378 in epoch 2, gen_loss = 0.4640739626179899, disc_loss = 0.03272930849196099
Trained batch 379 in epoch 2, gen_loss = 0.46384310173360926, disc_loss = 0.032882178339519
Trained batch 380 in epoch 2, gen_loss = 0.46373948259303577, disc_loss = 0.033100302177151354
Trained batch 381 in epoch 2, gen_loss = 0.4636186925372528, disc_loss = 0.033458320648258266
Trained batch 382 in epoch 2, gen_loss = 0.46349839776676566, disc_loss = 0.03409399041619064
Trained batch 383 in epoch 2, gen_loss = 0.46329020623428124, disc_loss = 0.03431012495032822
Trained batch 384 in epoch 2, gen_loss = 0.46333517424471965, disc_loss = 0.03447267198330396
Trained batch 385 in epoch 2, gen_loss = 0.46357887180358015, disc_loss = 0.03456099734791202
Trained batch 386 in epoch 2, gen_loss = 0.4634515924971233, disc_loss = 0.0346787420585174
Trained batch 387 in epoch 2, gen_loss = 0.4634672990932907, disc_loss = 0.0347605548875848
Trained batch 388 in epoch 2, gen_loss = 0.46328301593699617, disc_loss = 0.034784824824425124
Trained batch 389 in epoch 2, gen_loss = 0.4631831367810567, disc_loss = 0.03488140134857251
Trained batch 390 in epoch 2, gen_loss = 0.46320537769276166, disc_loss = 0.03483766833763293
Trained batch 391 in epoch 2, gen_loss = 0.46310219845297385, disc_loss = 0.034894638628299744
Trained batch 392 in epoch 2, gen_loss = 0.46316102920597746, disc_loss = 0.03490425924043012
Trained batch 393 in epoch 2, gen_loss = 0.46336571327623377, disc_loss = 0.034844947621925984
Trained batch 394 in epoch 2, gen_loss = 0.46328967251355135, disc_loss = 0.03482949302967968
Trained batch 395 in epoch 2, gen_loss = 0.4634145066292599, disc_loss = 0.03500811478377066
Trained batch 396 in epoch 2, gen_loss = 0.46327864936076724, disc_loss = 0.035390269632922765
Trained batch 397 in epoch 2, gen_loss = 0.46330904121974004, disc_loss = 0.03554502164420845
Trained batch 398 in epoch 2, gen_loss = 0.4633578872471525, disc_loss = 0.03553026669278255
Trained batch 399 in epoch 2, gen_loss = 0.4631775663793087, disc_loss = 0.03578256328823045
Trained batch 400 in epoch 2, gen_loss = 0.4634744119168517, disc_loss = 0.03607168902603542
Trained batch 401 in epoch 2, gen_loss = 0.4633057080394593, disc_loss = 0.03605330213950715
Trained batch 402 in epoch 2, gen_loss = 0.4634681832110024, disc_loss = 0.036044558082654075
Trained batch 403 in epoch 2, gen_loss = 0.46341540937376496, disc_loss = 0.03613902569637809
Trained batch 404 in epoch 2, gen_loss = 0.4634075503290435, disc_loss = 0.03627862095326921
Trained batch 405 in epoch 2, gen_loss = 0.4634503602541139, disc_loss = 0.03622412871743731
Trained batch 406 in epoch 2, gen_loss = 0.4634968408495554, disc_loss = 0.03643107854736012
Trained batch 407 in epoch 2, gen_loss = 0.4632945937999323, disc_loss = 0.036732942498216
Trained batch 408 in epoch 2, gen_loss = 0.4632767733997121, disc_loss = 0.03672487599533825
Trained batch 409 in epoch 2, gen_loss = 0.4632741868495941, disc_loss = 0.03678156266715832
Trained batch 410 in epoch 2, gen_loss = 0.46343357197559665, disc_loss = 0.03685013930156936
Trained batch 411 in epoch 2, gen_loss = 0.46338796145418315, disc_loss = 0.03686124210480998
Trained batch 412 in epoch 2, gen_loss = 0.46347582138190835, disc_loss = 0.03679780541641805
Trained batch 413 in epoch 2, gen_loss = 0.4634569880467106, disc_loss = 0.03675364411395529
Trained batch 414 in epoch 2, gen_loss = 0.4633356421108705, disc_loss = 0.036684759360659555
Trained batch 415 in epoch 2, gen_loss = 0.46336849298901284, disc_loss = 0.03662486072146119
Trained batch 416 in epoch 2, gen_loss = 0.46341861302046466, disc_loss = 0.0365518201946569
Trained batch 417 in epoch 2, gen_loss = 0.46349524859891555, disc_loss = 0.036595337177542125
Trained batch 418 in epoch 2, gen_loss = 0.46351269186254335, disc_loss = 0.03659829276398287
Trained batch 419 in epoch 2, gen_loss = 0.463600550308114, disc_loss = 0.03654351810303827
Trained batch 420 in epoch 2, gen_loss = 0.4634633823839899, disc_loss = 0.036587960179673945
Trained batch 421 in epoch 2, gen_loss = 0.4638063868781402, disc_loss = 0.03674504460360837
Trained batch 422 in epoch 2, gen_loss = 0.4638856924171989, disc_loss = 0.036712840369002055
Trained batch 423 in epoch 2, gen_loss = 0.4639903447538052, disc_loss = 0.036711075767119114
Trained batch 424 in epoch 2, gen_loss = 0.4639962192843942, disc_loss = 0.03665492029093644
Trained batch 425 in epoch 2, gen_loss = 0.46392715844749843, disc_loss = 0.036610036911311705
Trained batch 426 in epoch 2, gen_loss = 0.4637626939272155, disc_loss = 0.036633390590845145
Trained batch 427 in epoch 2, gen_loss = 0.4637626938034441, disc_loss = 0.03661186123815165
Trained batch 428 in epoch 2, gen_loss = 0.46368449558189145, disc_loss = 0.036559504137693585
Trained batch 429 in epoch 2, gen_loss = 0.4637126704981161, disc_loss = 0.03649882523906092
Trained batch 430 in epoch 2, gen_loss = 0.4635638975626908, disc_loss = 0.036432508435402834
Trained batch 431 in epoch 2, gen_loss = 0.4634155771108689, disc_loss = 0.03637717836924518
Trained batch 432 in epoch 2, gen_loss = 0.46349553416287376, disc_loss = 0.03638334557904451
Trained batch 433 in epoch 2, gen_loss = 0.46320505865982603, disc_loss = 0.036390142011014134
Trained batch 434 in epoch 2, gen_loss = 0.46301342886069724, disc_loss = 0.03641722067205728
Trained batch 435 in epoch 2, gen_loss = 0.46310111914479407, disc_loss = 0.03636376343778582
Trained batch 436 in epoch 2, gen_loss = 0.4628788561515459, disc_loss = 0.03630623824732459
Trained batch 437 in epoch 2, gen_loss = 0.4630572108645417, disc_loss = 0.03625915073428184
Trained batch 438 in epoch 2, gen_loss = 0.46304077330917326, disc_loss = 0.0362128168153566
Trained batch 439 in epoch 2, gen_loss = 0.46310239285230637, disc_loss = 0.03615240892607041
Trained batch 440 in epoch 2, gen_loss = 0.46296065964666355, disc_loss = 0.0361068554649176
Trained batch 441 in epoch 2, gen_loss = 0.4628454890456135, disc_loss = 0.03605894687505464
Trained batch 442 in epoch 2, gen_loss = 0.46290310591661094, disc_loss = 0.03599657658403466
Trained batch 443 in epoch 2, gen_loss = 0.46286521523116947, disc_loss = 0.03594425431796693
Trained batch 444 in epoch 2, gen_loss = 0.4628833958272184, disc_loss = 0.03589296207627219
Trained batch 445 in epoch 2, gen_loss = 0.46281766343544417, disc_loss = 0.03588916701076744
Trained batch 446 in epoch 2, gen_loss = 0.4629169713197405, disc_loss = 0.03601482826216309
Trained batch 447 in epoch 2, gen_loss = 0.4628920248443527, disc_loss = 0.03598648435477766
Trained batch 448 in epoch 2, gen_loss = 0.46287948258204553, disc_loss = 0.03592952540795628
Trained batch 449 in epoch 2, gen_loss = 0.46274449798795914, disc_loss = 0.036078166787823045
Trained batch 450 in epoch 2, gen_loss = 0.46278971129669055, disc_loss = 0.036372770681283424
Trained batch 451 in epoch 2, gen_loss = 0.46267442279948595, disc_loss = 0.03661001383829697
Trained batch 452 in epoch 2, gen_loss = 0.46262726477176674, disc_loss = 0.0366030347350549
Trained batch 453 in epoch 2, gen_loss = 0.4627318396048399, disc_loss = 0.036649331458667826
Trained batch 454 in epoch 2, gen_loss = 0.462705842937742, disc_loss = 0.03660983256995678
Trained batch 455 in epoch 2, gen_loss = 0.4625972304166409, disc_loss = 0.036555391572938675
Trained batch 456 in epoch 2, gen_loss = 0.46265019851388245, disc_loss = 0.03649234464004864
Trained batch 457 in epoch 2, gen_loss = 0.46262143884163237, disc_loss = 0.036424101303904985
Trained batch 458 in epoch 2, gen_loss = 0.46252901251539424, disc_loss = 0.03647403322639094
Trained batch 459 in epoch 2, gen_loss = 0.4625706241182659, disc_loss = 0.036469989263898
Trained batch 460 in epoch 2, gen_loss = 0.4625490285827902, disc_loss = 0.03641652223530858
Trained batch 461 in epoch 2, gen_loss = 0.462173744649082, disc_loss = 0.036506176283139555
Trained batch 462 in epoch 2, gen_loss = 0.4621562464062133, disc_loss = 0.03656904321952399
Trained batch 463 in epoch 2, gen_loss = 0.4620870362710336, disc_loss = 0.03671218494780298
Trained batch 464 in epoch 2, gen_loss = 0.46204631142718816, disc_loss = 0.037009811319250574
Trained batch 465 in epoch 2, gen_loss = 0.4622482174583771, disc_loss = 0.03709907193224509
Trained batch 466 in epoch 2, gen_loss = 0.4623472391282721, disc_loss = 0.03707654933530909
Trained batch 467 in epoch 2, gen_loss = 0.46230617178301525, disc_loss = 0.0371666147839278
Trained batch 468 in epoch 2, gen_loss = 0.4624979431186912, disc_loss = 0.037250632604858135
Trained batch 469 in epoch 2, gen_loss = 0.46261194183471355, disc_loss = 0.037208357982416736
Trained batch 470 in epoch 2, gen_loss = 0.46251367579852953, disc_loss = 0.03716198577409147
Trained batch 471 in epoch 2, gen_loss = 0.462573073614957, disc_loss = 0.03709858835485401
Trained batch 472 in epoch 2, gen_loss = 0.4626104197214824, disc_loss = 0.03703568616181013
Trained batch 473 in epoch 2, gen_loss = 0.46267748614655263, disc_loss = 0.03698319125672967
Trained batch 474 in epoch 2, gen_loss = 0.4625572252900977, disc_loss = 0.03691414274079235
Trained batch 475 in epoch 2, gen_loss = 0.46249087862357374, disc_loss = 0.036864237807018044
Trained batch 476 in epoch 2, gen_loss = 0.46235727351666495, disc_loss = 0.03680700186905558
Trained batch 477 in epoch 2, gen_loss = 0.46225720201326714, disc_loss = 0.03674593771258408
Trained batch 478 in epoch 2, gen_loss = 0.46218308520217527, disc_loss = 0.03669861416742672
Trained batch 479 in epoch 2, gen_loss = 0.462120606439809, disc_loss = 0.03664261787780561
Trained batch 480 in epoch 2, gen_loss = 0.46200370943471947, disc_loss = 0.036579901007877315
Trained batch 481 in epoch 2, gen_loss = 0.4620544691550781, disc_loss = 0.0365205043888191
Trained batch 482 in epoch 2, gen_loss = 0.4621296927919052, disc_loss = 0.03646732072729625
Trained batch 483 in epoch 2, gen_loss = 0.4620789190338663, disc_loss = 0.03643391962155453
Trained batch 484 in epoch 2, gen_loss = 0.46219393266844994, disc_loss = 0.03641303599879299
Trained batch 485 in epoch 2, gen_loss = 0.46209275753164486, disc_loss = 0.036382809223860134
Trained batch 486 in epoch 2, gen_loss = 0.46200603705656845, disc_loss = 0.03636670962083144
Trained batch 487 in epoch 2, gen_loss = 0.46187731128979903, disc_loss = 0.03645723434088782
Trained batch 488 in epoch 2, gen_loss = 0.4618366685503587, disc_loss = 0.03665820439488975
Trained batch 489 in epoch 2, gen_loss = 0.4618329347396383, disc_loss = 0.03669508796337308
Trained batch 490 in epoch 2, gen_loss = 0.46170108448220853, disc_loss = 0.03680209999490537
Trained batch 491 in epoch 2, gen_loss = 0.46193206800920206, disc_loss = 0.036966712755431244
Trained batch 492 in epoch 2, gen_loss = 0.46175551402399556, disc_loss = 0.03700470782695508
Trained batch 493 in epoch 2, gen_loss = 0.46164614493065037, disc_loss = 0.03721706847083352
Trained batch 494 in epoch 2, gen_loss = 0.4617597828007708, disc_loss = 0.03736508674167021
Trained batch 495 in epoch 2, gen_loss = 0.4616627942530378, disc_loss = 0.03733922995536799
Trained batch 496 in epoch 2, gen_loss = 0.461675459950023, disc_loss = 0.037295608460843205
Trained batch 497 in epoch 2, gen_loss = 0.4616559056871866, disc_loss = 0.03725862470137546
Trained batch 498 in epoch 2, gen_loss = 0.4615668503937119, disc_loss = 0.03726895729113437
Trained batch 499 in epoch 2, gen_loss = 0.4614231375455856, disc_loss = 0.03725720147788525
Trained batch 500 in epoch 2, gen_loss = 0.4613640320277262, disc_loss = 0.03722576846084195
Trained batch 501 in epoch 2, gen_loss = 0.4613413649251262, disc_loss = 0.03718993131932153
Trained batch 502 in epoch 2, gen_loss = 0.4612908485395534, disc_loss = 0.037146657036902536
Trained batch 503 in epoch 2, gen_loss = 0.46121467241928693, disc_loss = 0.037097203476901444
Trained batch 504 in epoch 2, gen_loss = 0.461227280668693, disc_loss = 0.037044428449382286
Trained batch 505 in epoch 2, gen_loss = 0.46118192722203705, disc_loss = 0.03698183532450863
Trained batch 506 in epoch 2, gen_loss = 0.4610888656427169, disc_loss = 0.03692065168601962
Trained batch 507 in epoch 2, gen_loss = 0.46097547074002543, disc_loss = 0.03685764023139486
Trained batch 508 in epoch 2, gen_loss = 0.46096118921615287, disc_loss = 0.03679516790837255
Trained batch 509 in epoch 2, gen_loss = 0.46086574366279676, disc_loss = 0.036734756868442194
Trained batch 510 in epoch 2, gen_loss = 0.4607963844288119, disc_loss = 0.03668176849443765
Trained batch 511 in epoch 2, gen_loss = 0.46080825140234083, disc_loss = 0.036628938573812775
Trained batch 512 in epoch 2, gen_loss = 0.46087420614142166, disc_loss = 0.03658611354005993
Trained batch 513 in epoch 2, gen_loss = 0.46105701311089187, disc_loss = 0.03653605843727488
Trained batch 514 in epoch 2, gen_loss = 0.4610929940510722, disc_loss = 0.036479452398867865
Trained batch 515 in epoch 2, gen_loss = 0.46112874929988107, disc_loss = 0.03642561314663626
Trained batch 516 in epoch 2, gen_loss = 0.46102653717625763, disc_loss = 0.036374097608923336
Trained batch 517 in epoch 2, gen_loss = 0.4609470774768402, disc_loss = 0.03632903538291921
Trained batch 518 in epoch 2, gen_loss = 0.4608590401895703, disc_loss = 0.03628350113678243
Trained batch 519 in epoch 2, gen_loss = 0.46085853536541643, disc_loss = 0.036251928576698095
Trained batch 520 in epoch 2, gen_loss = 0.46094823324062545, disc_loss = 0.036206503949287185
Trained batch 521 in epoch 2, gen_loss = 0.4610313937010893, disc_loss = 0.036157702243890456
Trained batch 522 in epoch 2, gen_loss = 0.46106949220651877, disc_loss = 0.036118997501326904
Trained batch 523 in epoch 2, gen_loss = 0.4610404343777941, disc_loss = 0.03606239815939303
Trained batch 524 in epoch 2, gen_loss = 0.46105650583902996, disc_loss = 0.036007426331440606
Trained batch 525 in epoch 2, gen_loss = 0.46101473889423417, disc_loss = 0.0359519101358851
Trained batch 526 in epoch 2, gen_loss = 0.46107150735846053, disc_loss = 0.03589496577681666
Trained batch 527 in epoch 2, gen_loss = 0.46105040175219375, disc_loss = 0.03584826685343587
Trained batch 528 in epoch 2, gen_loss = 0.4610729496397909, disc_loss = 0.03579007928560722
Trained batch 529 in epoch 2, gen_loss = 0.46109324558725895, disc_loss = 0.035747753055590505
Trained batch 530 in epoch 2, gen_loss = 0.4611933799337757, disc_loss = 0.03571766023497797
Trained batch 531 in epoch 2, gen_loss = 0.46119676911293117, disc_loss = 0.03565800463241574
Trained batch 532 in epoch 2, gen_loss = 0.4611780413655358, disc_loss = 0.035618008453377974
Trained batch 533 in epoch 2, gen_loss = 0.4612248260876659, disc_loss = 0.03556961033228185
Trained batch 534 in epoch 2, gen_loss = 0.4611654898830663, disc_loss = 0.035544619897258614
Trained batch 535 in epoch 2, gen_loss = 0.46127240048415624, disc_loss = 0.03556013744630253
Trained batch 536 in epoch 2, gen_loss = 0.46127840038562395, disc_loss = 0.03552000618971593
Trained batch 537 in epoch 2, gen_loss = 0.46123409769792095, disc_loss = 0.035479862253323585
Trained batch 538 in epoch 2, gen_loss = 0.46118223445977263, disc_loss = 0.03542702608086957
Trained batch 539 in epoch 2, gen_loss = 0.4612753988416107, disc_loss = 0.03538308646184979
Trained batch 540 in epoch 2, gen_loss = 0.4613599830105653, disc_loss = 0.035332428504903965
Trained batch 541 in epoch 2, gen_loss = 0.46133990140418724, disc_loss = 0.03527947035068268
Trained batch 542 in epoch 2, gen_loss = 0.4614099910685151, disc_loss = 0.0352212417918784
Trained batch 543 in epoch 2, gen_loss = 0.4615091288133579, disc_loss = 0.03517061429053737
Trained batch 544 in epoch 2, gen_loss = 0.46146249393804356, disc_loss = 0.035112582874236575
Trained batch 545 in epoch 2, gen_loss = 0.4615094195573758, disc_loss = 0.03508754564029584
Trained batch 546 in epoch 2, gen_loss = 0.46148544615321885, disc_loss = 0.03504273503375201
Trained batch 547 in epoch 2, gen_loss = 0.4614221799003817, disc_loss = 0.03498935800497794
Trained batch 548 in epoch 2, gen_loss = 0.4614322022662137, disc_loss = 0.03494030849682422
Trained batch 549 in epoch 2, gen_loss = 0.4614353745092045, disc_loss = 0.03489687987264584
Trained batch 550 in epoch 2, gen_loss = 0.4614836970063606, disc_loss = 0.03489687177394863
Trained batch 551 in epoch 2, gen_loss = 0.46141950019459793, disc_loss = 0.03484065447675833
Trained batch 552 in epoch 2, gen_loss = 0.46141644940453885, disc_loss = 0.034788941763674884
Trained batch 553 in epoch 2, gen_loss = 0.46134180911826744, disc_loss = 0.03475405391438491
Trained batch 554 in epoch 2, gen_loss = 0.4613706955501625, disc_loss = 0.03471145071382928
Trained batch 555 in epoch 2, gen_loss = 0.4614570944322099, disc_loss = 0.03466212447764513
Trained batch 556 in epoch 2, gen_loss = 0.461525846373029, disc_loss = 0.03461135479644998
Trained batch 557 in epoch 2, gen_loss = 0.4614678404450844, disc_loss = 0.03456147088991365
Trained batch 558 in epoch 2, gen_loss = 0.46142797851818407, disc_loss = 0.03450772310157302
Trained batch 559 in epoch 2, gen_loss = 0.4613916532269546, disc_loss = 0.03447140722959635
Trained batch 560 in epoch 2, gen_loss = 0.4615485936987634, disc_loss = 0.03442931569632933
Trained batch 561 in epoch 2, gen_loss = 0.46136635335102627, disc_loss = 0.03438682365935508
Trained batch 562 in epoch 2, gen_loss = 0.461386858570004, disc_loss = 0.03433999972671045
Trained batch 563 in epoch 2, gen_loss = 0.4613221752199721, disc_loss = 0.03429485343731874
Trained batch 564 in epoch 2, gen_loss = 0.46135513128432554, disc_loss = 0.03426693113957557
Trained batch 565 in epoch 2, gen_loss = 0.46134926573547796, disc_loss = 0.034219013480551855
Trained batch 566 in epoch 2, gen_loss = 0.46136170252500597, disc_loss = 0.03416682772274331
Trained batch 567 in epoch 2, gen_loss = 0.4613597145907476, disc_loss = 0.03411863385052027
Trained batch 568 in epoch 2, gen_loss = 0.4613770402064432, disc_loss = 0.03407648515311415
Trained batch 569 in epoch 2, gen_loss = 0.46141436596711477, disc_loss = 0.034028893735733604
Trained batch 570 in epoch 2, gen_loss = 0.46143189672830853, disc_loss = 0.03397654029524407
Trained batch 571 in epoch 2, gen_loss = 0.4615149809555574, disc_loss = 0.033924073932962685
Trained batch 572 in epoch 2, gen_loss = 0.4615402946193389, disc_loss = 0.03387222083222063
Trained batch 573 in epoch 2, gen_loss = 0.4615373607815766, disc_loss = 0.033828741768196564
Trained batch 574 in epoch 2, gen_loss = 0.46161517252092776, disc_loss = 0.03380085457075873
Trained batch 575 in epoch 2, gen_loss = 0.4615160484487812, disc_loss = 0.03379467735188276
Trained batch 576 in epoch 2, gen_loss = 0.4614825867490917, disc_loss = 0.0337424917470186
Trained batch 577 in epoch 2, gen_loss = 0.4614830008324455, disc_loss = 0.03370941143400748
Trained batch 578 in epoch 2, gen_loss = 0.46138313072950726, disc_loss = 0.033662035778592725
Trained batch 579 in epoch 2, gen_loss = 0.46126880948913507, disc_loss = 0.03361232858673059
Trained batch 580 in epoch 2, gen_loss = 0.46127214314810383, disc_loss = 0.033578597735725794
Trained batch 581 in epoch 2, gen_loss = 0.4612431335695011, disc_loss = 0.03353020423724031
Trained batch 582 in epoch 2, gen_loss = 0.46117085545590564, disc_loss = 0.03348001685691598
Trained batch 583 in epoch 2, gen_loss = 0.46121373966540374, disc_loss = 0.03343649596583468
Trained batch 584 in epoch 2, gen_loss = 0.46108010732210597, disc_loss = 0.03342493263264306
Trained batch 585 in epoch 2, gen_loss = 0.461193794479956, disc_loss = 0.033441093838106166
Trained batch 586 in epoch 2, gen_loss = 0.4612262133743735, disc_loss = 0.033397146642249353
Trained batch 587 in epoch 2, gen_loss = 0.46110453831703485, disc_loss = 0.03337137933011122
Trained batch 588 in epoch 2, gen_loss = 0.46108489555697285, disc_loss = 0.03334163070865077
Trained batch 589 in epoch 2, gen_loss = 0.46118826386281997, disc_loss = 0.033310251809672405
Trained batch 590 in epoch 2, gen_loss = 0.46116092074946097, disc_loss = 0.03326106523778195
Trained batch 591 in epoch 2, gen_loss = 0.4611331178630526, disc_loss = 0.03322088989355236
Trained batch 592 in epoch 2, gen_loss = 0.4610363243000101, disc_loss = 0.03317551557909113
Trained batch 593 in epoch 2, gen_loss = 0.4610704221207686, disc_loss = 0.03312706367719467
Trained batch 594 in epoch 2, gen_loss = 0.4610794865784525, disc_loss = 0.03307750692919773
Trained batch 595 in epoch 2, gen_loss = 0.4610932614379281, disc_loss = 0.03304581061449377
Trained batch 596 in epoch 2, gen_loss = 0.46095405761121305, disc_loss = 0.03302152622553522
Trained batch 597 in epoch 2, gen_loss = 0.4609585708898047, disc_loss = 0.03298703023391374
Trained batch 598 in epoch 2, gen_loss = 0.460873277885886, disc_loss = 0.03298300371438464
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 0.4248879551887512, disc_loss = 0.007230173330754042
Trained batch 1 in epoch 3, gen_loss = 0.44978347420692444, disc_loss = 0.010324276285246015
Trained batch 2 in epoch 3, gen_loss = 0.46149009466171265, disc_loss = 0.01171114838992556
Trained batch 3 in epoch 3, gen_loss = 0.4775235801935196, disc_loss = 0.010424372623674572
Trained batch 4 in epoch 3, gen_loss = 0.482206666469574, disc_loss = 0.010211579408496619
Trained batch 5 in epoch 3, gen_loss = 0.4858441849549611, disc_loss = 0.009923328723137578
Trained batch 6 in epoch 3, gen_loss = 0.48652674896376474, disc_loss = 0.010094433557242155
Trained batch 7 in epoch 3, gen_loss = 0.4817684628069401, disc_loss = 0.009986116259824485
Trained batch 8 in epoch 3, gen_loss = 0.47501378258069354, disc_loss = 0.010475039016455412
Trained batch 9 in epoch 3, gen_loss = 0.4693005532026291, disc_loss = 0.010539702931419015
Trained batch 10 in epoch 3, gen_loss = 0.46857061982154846, disc_loss = 0.00989998045208102
Trained batch 11 in epoch 3, gen_loss = 0.4668862521648407, disc_loss = 0.009729766422727456
Trained batch 12 in epoch 3, gen_loss = 0.4637867624943073, disc_loss = 0.009479978318827657
Trained batch 13 in epoch 3, gen_loss = 0.46244106761046816, disc_loss = 0.010125837006073977
Trained batch 14 in epoch 3, gen_loss = 0.46274367372194924, disc_loss = 0.011977916567896802
Trained batch 15 in epoch 3, gen_loss = 0.4642103333026171, disc_loss = 0.012393307624734007
Trained batch 16 in epoch 3, gen_loss = 0.4609970818547642, disc_loss = 0.012281272546662128
Trained batch 17 in epoch 3, gen_loss = 0.46456777552763623, disc_loss = 0.012847939907159243
Trained batch 18 in epoch 3, gen_loss = 0.4586078085397419, disc_loss = 0.015821279063330668
Trained batch 19 in epoch 3, gen_loss = 0.4610554277896881, disc_loss = 0.026442139770369976
Trained batch 20 in epoch 3, gen_loss = 0.4600757814589001, disc_loss = 0.035621936288884
Trained batch 21 in epoch 3, gen_loss = 0.46426314928314905, disc_loss = 0.04094261082354933
Trained batch 22 in epoch 3, gen_loss = 0.4657359084357386, disc_loss = 0.043213088379201035
Trained batch 23 in epoch 3, gen_loss = 0.46457262709736824, disc_loss = 0.04789898869542716
Trained batch 24 in epoch 3, gen_loss = 0.46619017243385313, disc_loss = 0.05597363307140767
Trained batch 25 in epoch 3, gen_loss = 0.4666174088533108, disc_loss = 0.05733688532983741
Trained batch 26 in epoch 3, gen_loss = 0.46544581099792764, disc_loss = 0.058967337693536175
Trained batch 27 in epoch 3, gen_loss = 0.46258399529116495, disc_loss = 0.060070295011558174
Trained batch 28 in epoch 3, gen_loss = 0.4634116291999817, disc_loss = 0.06078684085112964
Trained batch 29 in epoch 3, gen_loss = 0.46115656395753224, disc_loss = 0.060758168863443034
Trained batch 30 in epoch 3, gen_loss = 0.461587853008701, disc_loss = 0.060590458245226936
Trained batch 31 in epoch 3, gen_loss = 0.45971647556871176, disc_loss = 0.06142445909063099
Trained batch 32 in epoch 3, gen_loss = 0.4604014718171322, disc_loss = 0.06292037032967941
Trained batch 33 in epoch 3, gen_loss = 0.4580526790198158, disc_loss = 0.06403580942766413
Trained batch 34 in epoch 3, gen_loss = 0.4596718583788191, disc_loss = 0.06402795356698335
Trained batch 35 in epoch 3, gen_loss = 0.45868116203281617, disc_loss = 0.06324583788066068
Trained batch 36 in epoch 3, gen_loss = 0.45637330735051956, disc_loss = 0.06401010400716316
Trained batch 37 in epoch 3, gen_loss = 0.4595330569304918, disc_loss = 0.06338376551253819
Trained batch 38 in epoch 3, gen_loss = 0.45871303096795696, disc_loss = 0.062405019849300004
Trained batch 39 in epoch 3, gen_loss = 0.45859072357416153, disc_loss = 0.06193400420597754
Trained batch 40 in epoch 3, gen_loss = 0.45801766471164984, disc_loss = 0.06117010929212883
Trained batch 41 in epoch 3, gen_loss = 0.45852693773451303, disc_loss = 0.06262858632752406
Trained batch 42 in epoch 3, gen_loss = 0.4553329785202825, disc_loss = 0.06543295149864672
Trained batch 43 in epoch 3, gen_loss = 0.4564646922729232, disc_loss = 0.06765523988393728
Trained batch 44 in epoch 3, gen_loss = 0.4541153841548496, disc_loss = 0.06684278203691874
Trained batch 45 in epoch 3, gen_loss = 0.4545199197271596, disc_loss = 0.06600723654011507
Trained batch 46 in epoch 3, gen_loss = 0.45503176400002016, disc_loss = 0.06482693160131098
Trained batch 47 in epoch 3, gen_loss = 0.4554892300317685, disc_loss = 0.06380029897263739
Trained batch 48 in epoch 3, gen_loss = 0.45503248548021125, disc_loss = 0.0626649520673542
Trained batch 49 in epoch 3, gen_loss = 0.4561596697568893, disc_loss = 0.06186033086385578
Trained batch 50 in epoch 3, gen_loss = 0.4574587596397774, disc_loss = 0.06138628569212468
Trained batch 51 in epoch 3, gen_loss = 0.4578430876135826, disc_loss = 0.06159965473209293
Trained batch 52 in epoch 3, gen_loss = 0.45891443457243575, disc_loss = 0.06212750704133145
Trained batch 53 in epoch 3, gen_loss = 0.4573903779188792, disc_loss = 0.06151468332218765
Trained batch 54 in epoch 3, gen_loss = 0.4578495979309082, disc_loss = 0.06065376114354215
Trained batch 55 in epoch 3, gen_loss = 0.4589483290910721, disc_loss = 0.06011850767286627
Trained batch 56 in epoch 3, gen_loss = 0.459612088245258, disc_loss = 0.05953251967092224
Trained batch 57 in epoch 3, gen_loss = 0.45975747498972663, disc_loss = 0.05911887325908475
Trained batch 58 in epoch 3, gen_loss = 0.4593709166777336, disc_loss = 0.05899554729003901
Trained batch 59 in epoch 3, gen_loss = 0.4605095461010933, disc_loss = 0.06341982519176478
Trained batch 60 in epoch 3, gen_loss = 0.45982709429303154, disc_loss = 0.06609115991970432
Trained batch 61 in epoch 3, gen_loss = 0.46046362865355706, disc_loss = 0.06590434949048946
Trained batch 62 in epoch 3, gen_loss = 0.4602660224551246, disc_loss = 0.06536107857356824
Trained batch 63 in epoch 3, gen_loss = 0.4589218529872596, disc_loss = 0.06549123143122415
Trained batch 64 in epoch 3, gen_loss = 0.45786295991677506, disc_loss = 0.06508217457896814
Trained batch 65 in epoch 3, gen_loss = 0.4580975504535617, disc_loss = 0.06497651624676744
Trained batch 66 in epoch 3, gen_loss = 0.45730551676963693, disc_loss = 0.06581338821326507
Trained batch 67 in epoch 3, gen_loss = 0.4570789065431146, disc_loss = 0.0684383728863288
Trained batch 68 in epoch 3, gen_loss = 0.4565565836602363, disc_loss = 0.07069704717740524
Trained batch 69 in epoch 3, gen_loss = 0.4567148745059967, disc_loss = 0.07227264944397445
Trained batch 70 in epoch 3, gen_loss = 0.4559266819080836, disc_loss = 0.07219591624969222
Trained batch 71 in epoch 3, gen_loss = 0.455738655394978, disc_loss = 0.07161506496615605
Trained batch 72 in epoch 3, gen_loss = 0.4562057885405135, disc_loss = 0.07131665866911309
Trained batch 73 in epoch 3, gen_loss = 0.45593463689894287, disc_loss = 0.07096877516360602
Trained batch 74 in epoch 3, gen_loss = 0.45728986541430156, disc_loss = 0.07040788956917822
Trained batch 75 in epoch 3, gen_loss = 0.45614458738188995, disc_loss = 0.07082390803292296
Trained batch 76 in epoch 3, gen_loss = 0.4585443204873568, disc_loss = 0.07132231684510487
Trained batch 77 in epoch 3, gen_loss = 0.4575511224758931, disc_loss = 0.07058764904295692
Trained batch 78 in epoch 3, gen_loss = 0.45697450600092926, disc_loss = 0.07023094378447137
Trained batch 79 in epoch 3, gen_loss = 0.45714803636074064, disc_loss = 0.06996186958567704
Trained batch 80 in epoch 3, gen_loss = 0.4557373692959915, disc_loss = 0.06990876928098316
Trained batch 81 in epoch 3, gen_loss = 0.45566065464077926, disc_loss = 0.06948056967826788
Trained batch 82 in epoch 3, gen_loss = 0.4547430036297764, disc_loss = 0.0687547896410821
Trained batch 83 in epoch 3, gen_loss = 0.4538189857488587, disc_loss = 0.06862290029225517
Trained batch 84 in epoch 3, gen_loss = 0.45405507368199965, disc_loss = 0.07020125357050667
Trained batch 85 in epoch 3, gen_loss = 0.4539733050867569, disc_loss = 0.07153582229376446
Trained batch 86 in epoch 3, gen_loss = 0.45432927690703295, disc_loss = 0.07175837871190374
Trained batch 87 in epoch 3, gen_loss = 0.45456531745466316, disc_loss = 0.07119190035419623
Trained batch 88 in epoch 3, gen_loss = 0.4547543673033125, disc_loss = 0.07072903685470562
Trained batch 89 in epoch 3, gen_loss = 0.45449723104635875, disc_loss = 0.07006712351770451
Trained batch 90 in epoch 3, gen_loss = 0.45527461826146304, disc_loss = 0.0694536942205709
Trained batch 91 in epoch 3, gen_loss = 0.45406651561674866, disc_loss = 0.06880511627684388
Trained batch 92 in epoch 3, gen_loss = 0.45484758705221195, disc_loss = 0.0681233449403437
Trained batch 93 in epoch 3, gen_loss = 0.4539476534787645, disc_loss = 0.06776372954358366
Trained batch 94 in epoch 3, gen_loss = 0.4532640416371195, disc_loss = 0.06737015828441241
Trained batch 95 in epoch 3, gen_loss = 0.4521564564978083, disc_loss = 0.06681490876508178
Trained batch 96 in epoch 3, gen_loss = 0.45265181439439045, disc_loss = 0.06621381657476508
Trained batch 97 in epoch 3, gen_loss = 0.453702267639491, disc_loss = 0.0657622890371107
Trained batch 98 in epoch 3, gen_loss = 0.4535237565787152, disc_loss = 0.06519565196717252
Trained batch 99 in epoch 3, gen_loss = 0.4536760872602463, disc_loss = 0.06488364904886111
Trained batch 100 in epoch 3, gen_loss = 0.45412229753956934, disc_loss = 0.06434485782629414
Trained batch 101 in epoch 3, gen_loss = 0.4541918798988941, disc_loss = 0.06409140864122367
Trained batch 102 in epoch 3, gen_loss = 0.453128457069397, disc_loss = 0.06374767639457239
Trained batch 103 in epoch 3, gen_loss = 0.45317750710707444, disc_loss = 0.06322163372757271
Trained batch 104 in epoch 3, gen_loss = 0.4531073453880492, disc_loss = 0.06282638269476593
Trained batch 105 in epoch 3, gen_loss = 0.4534063426391134, disc_loss = 0.06230801104717308
Trained batch 106 in epoch 3, gen_loss = 0.45350316835341054, disc_loss = 0.061780750740615425
Trained batch 107 in epoch 3, gen_loss = 0.453609986713639, disc_loss = 0.06129729569053139
Trained batch 108 in epoch 3, gen_loss = 0.4541673974706492, disc_loss = 0.06080065115884698
Trained batch 109 in epoch 3, gen_loss = 0.45506066381931304, disc_loss = 0.06046752879099751
Trained batch 110 in epoch 3, gen_loss = 0.4550417363643646, disc_loss = 0.06006692590082886
Trained batch 111 in epoch 3, gen_loss = 0.4552999460803611, disc_loss = 0.05960681567376014
Trained batch 112 in epoch 3, gen_loss = 0.4554300062951788, disc_loss = 0.05914250712025812
Trained batch 113 in epoch 3, gen_loss = 0.45610347259462924, disc_loss = 0.05875091621725771
Trained batch 114 in epoch 3, gen_loss = 0.4567023119200831, disc_loss = 0.05851658603135982
Trained batch 115 in epoch 3, gen_loss = 0.4566841035567481, disc_loss = 0.058092165684150855
Trained batch 116 in epoch 3, gen_loss = 0.45725349457854897, disc_loss = 0.057671792464903913
Trained batch 117 in epoch 3, gen_loss = 0.4573001662048243, disc_loss = 0.05727901380169758
Trained batch 118 in epoch 3, gen_loss = 0.4581134492108802, disc_loss = 0.05697525421963582
Trained batch 119 in epoch 3, gen_loss = 0.458556525160869, disc_loss = 0.056594899849733336
Trained batch 120 in epoch 3, gen_loss = 0.4583583750015448, disc_loss = 0.05626317710338607
Trained batch 121 in epoch 3, gen_loss = 0.4588227218291799, disc_loss = 0.05585363861669588
Trained batch 122 in epoch 3, gen_loss = 0.458835909763972, disc_loss = 0.05560763113813975
Trained batch 123 in epoch 3, gen_loss = 0.4589924617640434, disc_loss = 0.05538056349389315
Trained batch 124 in epoch 3, gen_loss = 0.45921155548095705, disc_loss = 0.0550282560903579
Trained batch 125 in epoch 3, gen_loss = 0.45918715709731694, disc_loss = 0.0546409714771139
Trained batch 126 in epoch 3, gen_loss = 0.4587592034358678, disc_loss = 0.05424838952214171
Trained batch 127 in epoch 3, gen_loss = 0.4593216634821147, disc_loss = 0.05392517935797514
Trained batch 128 in epoch 3, gen_loss = 0.45919758289359336, disc_loss = 0.05401581433933777
Trained batch 129 in epoch 3, gen_loss = 0.4592708599108916, disc_loss = 0.05371702326139292
Trained batch 130 in epoch 3, gen_loss = 0.45926634182456794, disc_loss = 0.05360879352181183
Trained batch 131 in epoch 3, gen_loss = 0.4592712675080155, disc_loss = 0.053343301594864126
Trained batch 132 in epoch 3, gen_loss = 0.4588947840651175, disc_loss = 0.05303950067014342
Trained batch 133 in epoch 3, gen_loss = 0.45844184951995737, disc_loss = 0.05270672685279052
Trained batch 134 in epoch 3, gen_loss = 0.4581217015231097, disc_loss = 0.052433240370548986
Trained batch 135 in epoch 3, gen_loss = 0.45877689824384804, disc_loss = 0.05216321988572257
Trained batch 136 in epoch 3, gen_loss = 0.45908719518758956, disc_loss = 0.051888575517388916
Trained batch 137 in epoch 3, gen_loss = 0.4590347117703894, disc_loss = 0.05159204940318359
Trained batch 138 in epoch 3, gen_loss = 0.4586844242734017, disc_loss = 0.05126596956929232
Trained batch 139 in epoch 3, gen_loss = 0.45846632016556604, disc_loss = 0.05097270978980565
Trained batch 140 in epoch 3, gen_loss = 0.4583050722771503, disc_loss = 0.05069986535797675
Trained batch 141 in epoch 3, gen_loss = 0.4575829673820818, disc_loss = 0.05052609700204568
Trained batch 142 in epoch 3, gen_loss = 0.45779321785573357, disc_loss = 0.05030143667839572
Trained batch 143 in epoch 3, gen_loss = 0.45802365615963936, disc_loss = 0.04998679328289452
Trained batch 144 in epoch 3, gen_loss = 0.45793406634495176, disc_loss = 0.049709018729305984
Trained batch 145 in epoch 3, gen_loss = 0.4576782173898122, disc_loss = 0.04942369868513197
Trained batch 146 in epoch 3, gen_loss = 0.45770323905004123, disc_loss = 0.04932206452722807
Trained batch 147 in epoch 3, gen_loss = 0.4574500751253721, disc_loss = 0.04963161241785447
Trained batch 148 in epoch 3, gen_loss = 0.4574286015641769, disc_loss = 0.04959755970146382
Trained batch 149 in epoch 3, gen_loss = 0.4574055528640747, disc_loss = 0.04932481979796042
Trained batch 150 in epoch 3, gen_loss = 0.4570970217518459, disc_loss = 0.04907985483542923
Trained batch 151 in epoch 3, gen_loss = 0.45687278183667285, disc_loss = 0.04882064471358286
Trained batch 152 in epoch 3, gen_loss = 0.4565163182666878, disc_loss = 0.04855268530614577
Trained batch 153 in epoch 3, gen_loss = 0.45718020684533306, disc_loss = 0.048383251260421783
Trained batch 154 in epoch 3, gen_loss = 0.4570855413713763, disc_loss = 0.048162280448201686
Trained batch 155 in epoch 3, gen_loss = 0.45732313279922193, disc_loss = 0.047944798353665434
Trained batch 156 in epoch 3, gen_loss = 0.4572222280274531, disc_loss = 0.04795957988300094
Trained batch 157 in epoch 3, gen_loss = 0.4567171069262903, disc_loss = 0.04857788584342439
Trained batch 158 in epoch 3, gen_loss = 0.4567682883649502, disc_loss = 0.05029003631833168
Trained batch 159 in epoch 3, gen_loss = 0.45644950661808253, disc_loss = 0.051944808666303285
Trained batch 160 in epoch 3, gen_loss = 0.4564435913325837, disc_loss = 0.05243405366970099
Trained batch 161 in epoch 3, gen_loss = 0.4564041397821756, disc_loss = 0.053384111439636735
Trained batch 162 in epoch 3, gen_loss = 0.45561445508997866, disc_loss = 0.05533868477085571
Trained batch 163 in epoch 3, gen_loss = 0.45550600766408733, disc_loss = 0.05650790654003575
Trained batch 164 in epoch 3, gen_loss = 0.4557407010685314, disc_loss = 0.05671202152487681
Trained batch 165 in epoch 3, gen_loss = 0.45522999781441975, disc_loss = 0.05693344036201352
Trained batch 166 in epoch 3, gen_loss = 0.45510330831933166, disc_loss = 0.05697480130042814
Trained batch 167 in epoch 3, gen_loss = 0.45528090230765794, disc_loss = 0.05719957527721168
Trained batch 168 in epoch 3, gen_loss = 0.4549254498185491, disc_loss = 0.05934706639316616
Trained batch 169 in epoch 3, gen_loss = 0.4549213561941596, disc_loss = 0.05958017409258686
Trained batch 170 in epoch 3, gen_loss = 0.4548941498611406, disc_loss = 0.05945928630484432
Trained batch 171 in epoch 3, gen_loss = 0.455085578352906, disc_loss = 0.05933204410613926
Trained batch 172 in epoch 3, gen_loss = 0.4548954329738727, disc_loss = 0.05931142022472542
Trained batch 173 in epoch 3, gen_loss = 0.45488124674764174, disc_loss = 0.05954939836031361
Trained batch 174 in epoch 3, gen_loss = 0.4547085624081748, disc_loss = 0.059612077712746604
Trained batch 175 in epoch 3, gen_loss = 0.4549243577163328, disc_loss = 0.059358034831926816
Trained batch 176 in epoch 3, gen_loss = 0.45504180910223624, disc_loss = 0.05957549334619468
Trained batch 177 in epoch 3, gen_loss = 0.4547517287932085, disc_loss = 0.060174943815152884
Trained batch 178 in epoch 3, gen_loss = 0.45463781333502445, disc_loss = 0.06010006707260521
Trained batch 179 in epoch 3, gen_loss = 0.4545469358563423, disc_loss = 0.05996760425752857
Trained batch 180 in epoch 3, gen_loss = 0.45425663583845066, disc_loss = 0.05986226839785212
Trained batch 181 in epoch 3, gen_loss = 0.4543433027280556, disc_loss = 0.05966704700955773
Trained batch 182 in epoch 3, gen_loss = 0.45439647211403145, disc_loss = 0.06004244481885165
Trained batch 183 in epoch 3, gen_loss = 0.4542334585086159, disc_loss = 0.0612998128775001
Trained batch 184 in epoch 3, gen_loss = 0.45439888867172035, disc_loss = 0.06193161375090681
Trained batch 185 in epoch 3, gen_loss = 0.45416434974439684, disc_loss = 0.06192622247517549
Trained batch 186 in epoch 3, gen_loss = 0.45378379531722657, disc_loss = 0.06172196173487619
Trained batch 187 in epoch 3, gen_loss = 0.4538596283565176, disc_loss = 0.06162759900325909
Trained batch 188 in epoch 3, gen_loss = 0.45347826711084477, disc_loss = 0.061507063694840304
Trained batch 189 in epoch 3, gen_loss = 0.453187557584361, disc_loss = 0.06132266275266087
Trained batch 190 in epoch 3, gen_loss = 0.4531377510250551, disc_loss = 0.06103627424058139
Trained batch 191 in epoch 3, gen_loss = 0.4527946423428754, disc_loss = 0.060792740932811284
Trained batch 192 in epoch 3, gen_loss = 0.45288545927853163, disc_loss = 0.0606155425172608
Trained batch 193 in epoch 3, gen_loss = 0.45295543062318233, disc_loss = 0.06034369643215935
Trained batch 194 in epoch 3, gen_loss = 0.45302059619854657, disc_loss = 0.0600914779990816
Trained batch 195 in epoch 3, gen_loss = 0.4529414009682986, disc_loss = 0.05984377809586384
Trained batch 196 in epoch 3, gen_loss = 0.4529068748357937, disc_loss = 0.05956983176617869
Trained batch 197 in epoch 3, gen_loss = 0.452575148506598, disc_loss = 0.05930066771800583
Trained batch 198 in epoch 3, gen_loss = 0.45303441636526404, disc_loss = 0.05904951109316893
Trained batch 199 in epoch 3, gen_loss = 0.45288043186068533, disc_loss = 0.05881760878372006
Trained batch 200 in epoch 3, gen_loss = 0.45309740364255, disc_loss = 0.05865079941881348
Trained batch 201 in epoch 3, gen_loss = 0.45295520451399357, disc_loss = 0.05844201430526221
Trained batch 202 in epoch 3, gen_loss = 0.4529381880325637, disc_loss = 0.05817560374557862
Trained batch 203 in epoch 3, gen_loss = 0.4529936975416015, disc_loss = 0.05796038673610846
Trained batch 204 in epoch 3, gen_loss = 0.45273211482094555, disc_loss = 0.057763238261431094
Trained batch 205 in epoch 3, gen_loss = 0.4527814655917362, disc_loss = 0.05751262577951352
Trained batch 206 in epoch 3, gen_loss = 0.4530118765750369, disc_loss = 0.05725505253961445
Trained batch 207 in epoch 3, gen_loss = 0.4532966853047793, disc_loss = 0.057026419104659
Trained batch 208 in epoch 3, gen_loss = 0.45315126154981733, disc_loss = 0.05680931551698328
Trained batch 209 in epoch 3, gen_loss = 0.4530335683198202, disc_loss = 0.05662685487796331
Trained batch 210 in epoch 3, gen_loss = 0.45311286537003176, disc_loss = 0.05639772190959568
Trained batch 211 in epoch 3, gen_loss = 0.4531563766441255, disc_loss = 0.056161109389921755
Trained batch 212 in epoch 3, gen_loss = 0.4532139967305, disc_loss = 0.05593798893827403
Trained batch 213 in epoch 3, gen_loss = 0.45311144774205214, disc_loss = 0.0557059297701518
Trained batch 214 in epoch 3, gen_loss = 0.4532400332217993, disc_loss = 0.055475061875226536
Trained batch 215 in epoch 3, gen_loss = 0.4534622087246842, disc_loss = 0.05526888706285886
Trained batch 216 in epoch 3, gen_loss = 0.4533471320905993, disc_loss = 0.05507642293267364
Trained batch 217 in epoch 3, gen_loss = 0.45313135705409796, disc_loss = 0.0550488513294146
Trained batch 218 in epoch 3, gen_loss = 0.45359982761073875, disc_loss = 0.055173007234480216
Trained batch 219 in epoch 3, gen_loss = 0.4537288111719218, disc_loss = 0.05498778733149679
Trained batch 220 in epoch 3, gen_loss = 0.4532953649085032, disc_loss = 0.055193989536602775
Trained batch 221 in epoch 3, gen_loss = 0.4537964796160792, disc_loss = 0.05533444731567592
Trained batch 222 in epoch 3, gen_loss = 0.4537579598982773, disc_loss = 0.055163600105132424
Trained batch 223 in epoch 3, gen_loss = 0.4536986510668482, disc_loss = 0.05513770419617815
Trained batch 224 in epoch 3, gen_loss = 0.45419769419564143, disc_loss = 0.05519641366580294
Trained batch 225 in epoch 3, gen_loss = 0.4538328517063529, disc_loss = 0.05503705233248956
Trained batch 226 in epoch 3, gen_loss = 0.4537600668779029, disc_loss = 0.05528200349138664
Trained batch 227 in epoch 3, gen_loss = 0.454140997377404, disc_loss = 0.05590498807182405
Trained batch 228 in epoch 3, gen_loss = 0.4540219534692806, disc_loss = 0.05578826442991249
Trained batch 229 in epoch 3, gen_loss = 0.4538694149774054, disc_loss = 0.05586332300090757
Trained batch 230 in epoch 3, gen_loss = 0.45389072887309184, disc_loss = 0.056457772757253284
Trained batch 231 in epoch 3, gen_loss = 0.4532839860124835, disc_loss = 0.056861888588173315
Trained batch 232 in epoch 3, gen_loss = 0.4530712513197133, disc_loss = 0.05684881484987366
Trained batch 233 in epoch 3, gen_loss = 0.45308572499670535, disc_loss = 0.056757365475790814
Trained batch 234 in epoch 3, gen_loss = 0.45299151844166696, disc_loss = 0.0566648988043295
Trained batch 235 in epoch 3, gen_loss = 0.4529557223037138, disc_loss = 0.05682990321459375
Trained batch 236 in epoch 3, gen_loss = 0.4532475793411963, disc_loss = 0.056926327890162415
Trained batch 237 in epoch 3, gen_loss = 0.45304329342701855, disc_loss = 0.056973065432560234
Trained batch 238 in epoch 3, gen_loss = 0.45316632809000534, disc_loss = 0.056881659094314384
Trained batch 239 in epoch 3, gen_loss = 0.45289138009150826, disc_loss = 0.05676229751649468
Trained batch 240 in epoch 3, gen_loss = 0.452391856315225, disc_loss = 0.05711569306556584
Trained batch 241 in epoch 3, gen_loss = 0.4527293898103651, disc_loss = 0.05827109281970419
Trained batch 242 in epoch 3, gen_loss = 0.45277052112077, disc_loss = 0.05823749928052993
Trained batch 243 in epoch 3, gen_loss = 0.4526452654209293, disc_loss = 0.05833469073528607
Trained batch 244 in epoch 3, gen_loss = 0.45243975678268744, disc_loss = 0.05816415260469883
Trained batch 245 in epoch 3, gen_loss = 0.4524566607504356, disc_loss = 0.05797105634535807
Trained batch 246 in epoch 3, gen_loss = 0.4524355237541894, disc_loss = 0.0578035803253457
Trained batch 247 in epoch 3, gen_loss = 0.4521872637973678, disc_loss = 0.05777946134725015
Trained batch 248 in epoch 3, gen_loss = 0.4519316688120126, disc_loss = 0.057649935276834784
Trained batch 249 in epoch 3, gen_loss = 0.45202856421470644, disc_loss = 0.05750289325322956
Trained batch 250 in epoch 3, gen_loss = 0.452165513162119, disc_loss = 0.05734184967535752
Trained batch 251 in epoch 3, gen_loss = 0.45224179161919487, disc_loss = 0.057238648940313844
Trained batch 252 in epoch 3, gen_loss = 0.45238975196959, disc_loss = 0.057582718595354396
Trained batch 253 in epoch 3, gen_loss = 0.452491485697078, disc_loss = 0.05851075535651121
Trained batch 254 in epoch 3, gen_loss = 0.4527056163432551, disc_loss = 0.05836485453296964
Trained batch 255 in epoch 3, gen_loss = 0.4525977977318689, disc_loss = 0.058309409882895125
Trained batch 256 in epoch 3, gen_loss = 0.4526513322086186, disc_loss = 0.05812955838954258
Trained batch 257 in epoch 3, gen_loss = 0.45291866777941236, disc_loss = 0.057985777713091276
Trained batch 258 in epoch 3, gen_loss = 0.45282872487219145, disc_loss = 0.0579366764353955
Trained batch 259 in epoch 3, gen_loss = 0.45308722441013044, disc_loss = 0.05780428162901304
Trained batch 260 in epoch 3, gen_loss = 0.4527633705130025, disc_loss = 0.058130757068729895
Trained batch 261 in epoch 3, gen_loss = 0.452244539638512, disc_loss = 0.05861130887766916
Trained batch 262 in epoch 3, gen_loss = 0.45243462194961287, disc_loss = 0.058743607457337664
Trained batch 263 in epoch 3, gen_loss = 0.45231042474959837, disc_loss = 0.058570870924141316
Trained batch 264 in epoch 3, gen_loss = 0.45228457282174306, disc_loss = 0.05842257662816852
Trained batch 265 in epoch 3, gen_loss = 0.45210112474466624, disc_loss = 0.05829497252300354
Trained batch 266 in epoch 3, gen_loss = 0.4520368022418647, disc_loss = 0.05822857252273304
Trained batch 267 in epoch 3, gen_loss = 0.45190250606679205, disc_loss = 0.058245969775529
Trained batch 268 in epoch 3, gen_loss = 0.4521435745143536, disc_loss = 0.058131693241785395
Trained batch 269 in epoch 3, gen_loss = 0.452084325088395, disc_loss = 0.057961749515703154
Trained batch 270 in epoch 3, gen_loss = 0.45187399671086526, disc_loss = 0.057943952282739464
Trained batch 271 in epoch 3, gen_loss = 0.4520490832407685, disc_loss = 0.05805340118497364
Trained batch 272 in epoch 3, gen_loss = 0.45214534056929007, disc_loss = 0.05790803565357167
Trained batch 273 in epoch 3, gen_loss = 0.45221229104230004, disc_loss = 0.05774935312402591
Trained batch 274 in epoch 3, gen_loss = 0.4519161477955905, disc_loss = 0.05763479087078436
Trained batch 275 in epoch 3, gen_loss = 0.4519844978399899, disc_loss = 0.057448339020070766
Trained batch 276 in epoch 3, gen_loss = 0.45203886920794684, disc_loss = 0.05729531256283637
Trained batch 277 in epoch 3, gen_loss = 0.45186118417077786, disc_loss = 0.05714054946643602
Trained batch 278 in epoch 3, gen_loss = 0.45199681482007426, disc_loss = 0.05702555627148184
Trained batch 279 in epoch 3, gen_loss = 0.4517614698835782, disc_loss = 0.05698131699630592
Trained batch 280 in epoch 3, gen_loss = 0.45204795000816156, disc_loss = 0.056813067314960726
Trained batch 281 in epoch 3, gen_loss = 0.4523032713443675, disc_loss = 0.05680635772853535
Trained batch 282 in epoch 3, gen_loss = 0.45227909667331845, disc_loss = 0.056857088935321244
Trained batch 283 in epoch 3, gen_loss = 0.45250956074032983, disc_loss = 0.05670761759638865
Trained batch 284 in epoch 3, gen_loss = 0.4525855931273678, disc_loss = 0.056538740603514666
Trained batch 285 in epoch 3, gen_loss = 0.45273350981565624, disc_loss = 0.056376075423387746
Trained batch 286 in epoch 3, gen_loss = 0.4524119483884619, disc_loss = 0.056254175851017704
Trained batch 287 in epoch 3, gen_loss = 0.45235206331643796, disc_loss = 0.05610763703185108
Trained batch 288 in epoch 3, gen_loss = 0.45222333640788254, disc_loss = 0.05594872157282767
Trained batch 289 in epoch 3, gen_loss = 0.45211618347414606, disc_loss = 0.05577909469138831
Trained batch 290 in epoch 3, gen_loss = 0.4520228799061267, disc_loss = 0.05563111440918674
Trained batch 291 in epoch 3, gen_loss = 0.45234402187474787, disc_loss = 0.055477942259542085
Trained batch 292 in epoch 3, gen_loss = 0.45240894082056377, disc_loss = 0.055315216411216624
Trained batch 293 in epoch 3, gen_loss = 0.4524578376083958, disc_loss = 0.05514288429712535
Trained batch 294 in epoch 3, gen_loss = 0.45265040367336595, disc_loss = 0.05500339065615277
Trained batch 295 in epoch 3, gen_loss = 0.4524573633396948, disc_loss = 0.05491403186287907
Trained batch 296 in epoch 3, gen_loss = 0.4523800714850827, disc_loss = 0.05478269730926639
Trained batch 297 in epoch 3, gen_loss = 0.452219458334398, disc_loss = 0.05471590341259444
Trained batch 298 in epoch 3, gen_loss = 0.4524043257220533, disc_loss = 0.054862885968759656
Trained batch 299 in epoch 3, gen_loss = 0.45212137907743455, disc_loss = 0.054813072208780796
Trained batch 300 in epoch 3, gen_loss = 0.45218252511911616, disc_loss = 0.054712345395886965
Trained batch 301 in epoch 3, gen_loss = 0.4523518674618361, disc_loss = 0.05455889584826589
Trained batch 302 in epoch 3, gen_loss = 0.45222768817010883, disc_loss = 0.05441409098553063
Trained batch 303 in epoch 3, gen_loss = 0.4521800313929194, disc_loss = 0.05424764016290857
Trained batch 304 in epoch 3, gen_loss = 0.4521160809720149, disc_loss = 0.0540927591787071
Trained batch 305 in epoch 3, gen_loss = 0.4523170504694671, disc_loss = 0.05397744174647979
Trained batch 306 in epoch 3, gen_loss = 0.45223082092375244, disc_loss = 0.053818308209078174
Trained batch 307 in epoch 3, gen_loss = 0.45232383993925984, disc_loss = 0.05366026826713887
Trained batch 308 in epoch 3, gen_loss = 0.4524703723134346, disc_loss = 0.05349770189160451
Trained batch 309 in epoch 3, gen_loss = 0.452649440207789, disc_loss = 0.05334283449281488
Trained batch 310 in epoch 3, gen_loss = 0.45253562726008545, disc_loss = 0.053199984399014875
Trained batch 311 in epoch 3, gen_loss = 0.45251595333982736, disc_loss = 0.05304226443061056
Trained batch 312 in epoch 3, gen_loss = 0.45250538991282163, disc_loss = 0.05289466685567872
Trained batch 313 in epoch 3, gen_loss = 0.4525333966609019, disc_loss = 0.052746982271427136
Trained batch 314 in epoch 3, gen_loss = 0.4524270080384754, disc_loss = 0.05259227024110418
Trained batch 315 in epoch 3, gen_loss = 0.45253494372473485, disc_loss = 0.05246839027695617
Trained batch 316 in epoch 3, gen_loss = 0.4527052891931323, disc_loss = 0.05232517396346651
Trained batch 317 in epoch 3, gen_loss = 0.4528397168940718, disc_loss = 0.05226733439247586
Trained batch 318 in epoch 3, gen_loss = 0.4527651693753688, disc_loss = 0.05226193529372702
Trained batch 319 in epoch 3, gen_loss = 0.453335446305573, disc_loss = 0.052411197938636175
Trained batch 320 in epoch 3, gen_loss = 0.45329426187221133, disc_loss = 0.052331279537486744
Trained batch 321 in epoch 3, gen_loss = 0.45325513480242735, disc_loss = 0.052222545713515985
Trained batch 322 in epoch 3, gen_loss = 0.4532155608614163, disc_loss = 0.052127360315105356
Trained batch 323 in epoch 3, gen_loss = 0.45306079503562713, disc_loss = 0.05205679681212469
Trained batch 324 in epoch 3, gen_loss = 0.45296791892785293, disc_loss = 0.05192027080732469
Trained batch 325 in epoch 3, gen_loss = 0.45289556535840764, disc_loss = 0.05184166845537014
Trained batch 326 in epoch 3, gen_loss = 0.4527727312633386, disc_loss = 0.05176326884483685
Trained batch 327 in epoch 3, gen_loss = 0.4529342525979368, disc_loss = 0.051632376003686746
Trained batch 328 in epoch 3, gen_loss = 0.4531642214867844, disc_loss = 0.051543802262841526
Trained batch 329 in epoch 3, gen_loss = 0.45310649926012214, disc_loss = 0.051401635238929
Trained batch 330 in epoch 3, gen_loss = 0.4531563229611273, disc_loss = 0.051364208525890805
Trained batch 331 in epoch 3, gen_loss = 0.4532825498875365, disc_loss = 0.05146315965607919
Trained batch 332 in epoch 3, gen_loss = 0.4530519792088517, disc_loss = 0.05181354662618815
Trained batch 333 in epoch 3, gen_loss = 0.453313705003904, disc_loss = 0.052355546818650185
Trained batch 334 in epoch 3, gen_loss = 0.4531110374785181, disc_loss = 0.05225808098008717
Trained batch 335 in epoch 3, gen_loss = 0.45296345393927323, disc_loss = 0.05252082488663118
Trained batch 336 in epoch 3, gen_loss = 0.4529046156286132, disc_loss = 0.05241058864603123
Trained batch 337 in epoch 3, gen_loss = 0.4528392058681454, disc_loss = 0.05234831756121374
Trained batch 338 in epoch 3, gen_loss = 0.45270283287253704, disc_loss = 0.052314725887871026
Trained batch 339 in epoch 3, gen_loss = 0.4526886718238101, disc_loss = 0.052211859498364745
Trained batch 340 in epoch 3, gen_loss = 0.4529689185954958, disc_loss = 0.05250400801249329
Trained batch 341 in epoch 3, gen_loss = 0.4530486979505472, disc_loss = 0.0529758276912106
Trained batch 342 in epoch 3, gen_loss = 0.45330979221068735, disc_loss = 0.05301980752940493
Trained batch 343 in epoch 3, gen_loss = 0.45336508820223254, disc_loss = 0.05293291819560731
Trained batch 344 in epoch 3, gen_loss = 0.4533293286095495, disc_loss = 0.05284545539770329
Trained batch 345 in epoch 3, gen_loss = 0.4534335923677235, disc_loss = 0.0527896953180077
Trained batch 346 in epoch 3, gen_loss = 0.4532560655466074, disc_loss = 0.052678913518824005
Trained batch 347 in epoch 3, gen_loss = 0.4532915233880624, disc_loss = 0.05256184196867712
Trained batch 348 in epoch 3, gen_loss = 0.4534268164019872, disc_loss = 0.05245247473313145
Trained batch 349 in epoch 3, gen_loss = 0.4535250079631805, disc_loss = 0.05235143354096051
Trained batch 350 in epoch 3, gen_loss = 0.45345742800976135, disc_loss = 0.05231465572462102
Trained batch 351 in epoch 3, gen_loss = 0.4533391977575692, disc_loss = 0.052272407646920656
Trained batch 352 in epoch 3, gen_loss = 0.4533317958666988, disc_loss = 0.05218167064999027
Trained batch 353 in epoch 3, gen_loss = 0.4533555452938134, disc_loss = 0.052067399134801566
Trained batch 354 in epoch 3, gen_loss = 0.4533731438744236, disc_loss = 0.05196288259188369
Trained batch 355 in epoch 3, gen_loss = 0.4536216906952054, disc_loss = 0.051866828502558714
Trained batch 356 in epoch 3, gen_loss = 0.45371212662101124, disc_loss = 0.0518325744712
Trained batch 357 in epoch 3, gen_loss = 0.4537764299848226, disc_loss = 0.05197087126620135
Trained batch 358 in epoch 3, gen_loss = 0.4536669768164749, disc_loss = 0.052046332525836514
Trained batch 359 in epoch 3, gen_loss = 0.4538166149622864, disc_loss = 0.05209282753251803
Trained batch 360 in epoch 3, gen_loss = 0.4536853408714411, disc_loss = 0.05198749596152424
Trained batch 361 in epoch 3, gen_loss = 0.45360020856830957, disc_loss = 0.051960316190151346
Trained batch 362 in epoch 3, gen_loss = 0.45357439767559043, disc_loss = 0.05188509733313515
Trained batch 363 in epoch 3, gen_loss = 0.4535895890586979, disc_loss = 0.051762293527225174
Trained batch 364 in epoch 3, gen_loss = 0.45367640395687053, disc_loss = 0.05170010667587694
Trained batch 365 in epoch 3, gen_loss = 0.45363539913312984, disc_loss = 0.05175040491737039
Trained batch 366 in epoch 3, gen_loss = 0.4536796835852579, disc_loss = 0.052498917899168114
Trained batch 367 in epoch 3, gen_loss = 0.4534822189775498, disc_loss = 0.052741627132332804
Trained batch 368 in epoch 3, gen_loss = 0.45362248839078556, disc_loss = 0.052939720112996975
Trained batch 369 in epoch 3, gen_loss = 0.4535189035776499, disc_loss = 0.05282928108904712
Trained batch 370 in epoch 3, gen_loss = 0.45333541845375636, disc_loss = 0.05271321454718006
Trained batch 371 in epoch 3, gen_loss = 0.4531709202515182, disc_loss = 0.05279394705787361
Trained batch 372 in epoch 3, gen_loss = 0.4531520820814547, disc_loss = 0.05270282039231553
Trained batch 373 in epoch 3, gen_loss = 0.45335798132865823, disc_loss = 0.05275912064857243
Trained batch 374 in epoch 3, gen_loss = 0.4530165119171143, disc_loss = 0.05281601409055293
Trained batch 375 in epoch 3, gen_loss = 0.45304067686517185, disc_loss = 0.052710513177481384
Trained batch 376 in epoch 3, gen_loss = 0.45292993771302603, disc_loss = 0.05262961728678675
Trained batch 377 in epoch 3, gen_loss = 0.4529512071262592, disc_loss = 0.05261700633831973
Trained batch 378 in epoch 3, gen_loss = 0.452881964262683, disc_loss = 0.0527276505260313
Trained batch 379 in epoch 3, gen_loss = 0.45305624941461964, disc_loss = 0.05324776988219176
Trained batch 380 in epoch 3, gen_loss = 0.45282197741698715, disc_loss = 0.0537778005349814
Trained batch 381 in epoch 3, gen_loss = 0.45261229964763083, disc_loss = 0.053793177047027615
Trained batch 382 in epoch 3, gen_loss = 0.4525427914008148, disc_loss = 0.05375952160717827
Trained batch 383 in epoch 3, gen_loss = 0.45268962245124084, disc_loss = 0.05369076415020876
Trained batch 384 in epoch 3, gen_loss = 0.4525451646222697, disc_loss = 0.053644207206421664
Trained batch 385 in epoch 3, gen_loss = 0.45249525862963086, disc_loss = 0.053614224128092164
Trained batch 386 in epoch 3, gen_loss = 0.45242675699928936, disc_loss = 0.05372970538678307
Trained batch 387 in epoch 3, gen_loss = 0.4526016890388174, disc_loss = 0.05445162580317347
Trained batch 388 in epoch 3, gen_loss = 0.45261225073686906, disc_loss = 0.05446192557961802
Trained batch 389 in epoch 3, gen_loss = 0.4525722884979004, disc_loss = 0.05436958458023862
Trained batch 390 in epoch 3, gen_loss = 0.4526013769304661, disc_loss = 0.054254874314927044
Trained batch 391 in epoch 3, gen_loss = 0.4524789488285172, disc_loss = 0.05418969218426726
Trained batch 392 in epoch 3, gen_loss = 0.45246510696775133, disc_loss = 0.05416905513073557
Trained batch 393 in epoch 3, gen_loss = 0.45247247157060555, disc_loss = 0.054236987869841456
Trained batch 394 in epoch 3, gen_loss = 0.45262393430818487, disc_loss = 0.054200438635801026
Trained batch 395 in epoch 3, gen_loss = 0.4526707992860765, disc_loss = 0.05410486644997045
Trained batch 396 in epoch 3, gen_loss = 0.4526708824208161, disc_loss = 0.0541015133180747
Trained batch 397 in epoch 3, gen_loss = 0.452760416508919, disc_loss = 0.05435827001870783
Trained batch 398 in epoch 3, gen_loss = 0.4527509233407807, disc_loss = 0.05503496058917789
Trained batch 399 in epoch 3, gen_loss = 0.4529935686290264, disc_loss = 0.055186934824450876
Trained batch 400 in epoch 3, gen_loss = 0.45286246234936606, disc_loss = 0.05515288071941463
Trained batch 401 in epoch 3, gen_loss = 0.4527288325390412, disc_loss = 0.055052921624821775
Trained batch 402 in epoch 3, gen_loss = 0.4525766926574944, disc_loss = 0.05507561489049965
Trained batch 403 in epoch 3, gen_loss = 0.45263923011203805, disc_loss = 0.05510331200156822
Trained batch 404 in epoch 3, gen_loss = 0.4527294353938397, disc_loss = 0.05499951641167296
Trained batch 405 in epoch 3, gen_loss = 0.4525780713029683, disc_loss = 0.054912189369805596
Trained batch 406 in epoch 3, gen_loss = 0.4523709254563587, disc_loss = 0.054841270294447755
Trained batch 407 in epoch 3, gen_loss = 0.45269692155952546, disc_loss = 0.05487876284500018
Trained batch 408 in epoch 3, gen_loss = 0.45270298016974864, disc_loss = 0.0548878777402164
Trained batch 409 in epoch 3, gen_loss = 0.4527125688587747, disc_loss = 0.054777844701666474
Trained batch 410 in epoch 3, gen_loss = 0.4526297022971504, disc_loss = 0.05465915982969504
Trained batch 411 in epoch 3, gen_loss = 0.45265056178407764, disc_loss = 0.05459176915645762
Trained batch 412 in epoch 3, gen_loss = 0.4527356977468541, disc_loss = 0.05452008404967445
Trained batch 413 in epoch 3, gen_loss = 0.45274211430319267, disc_loss = 0.05440748530239821
Trained batch 414 in epoch 3, gen_loss = 0.45285073834729483, disc_loss = 0.054292063510987955
Trained batch 415 in epoch 3, gen_loss = 0.45280765727735484, disc_loss = 0.054297819748731296
Trained batch 416 in epoch 3, gen_loss = 0.45316034412498385, disc_loss = 0.05503952347481404
Trained batch 417 in epoch 3, gen_loss = 0.45288929813786555, disc_loss = 0.05536070820467734
Trained batch 418 in epoch 3, gen_loss = 0.45280884842884, disc_loss = 0.05533246667266586
Trained batch 419 in epoch 3, gen_loss = 0.4527563133410045, disc_loss = 0.05529508387304044
Trained batch 420 in epoch 3, gen_loss = 0.45286383778918665, disc_loss = 0.055214250143374055
Trained batch 421 in epoch 3, gen_loss = 0.452751332408444, disc_loss = 0.055231655066749034
Trained batch 422 in epoch 3, gen_loss = 0.4527139844060226, disc_loss = 0.055696545240863385
Trained batch 423 in epoch 3, gen_loss = 0.452598354093871, disc_loss = 0.0563856796685492
Trained batch 424 in epoch 3, gen_loss = 0.45223857094259823, disc_loss = 0.0567234745857251
Trained batch 425 in epoch 3, gen_loss = 0.4520625866634745, disc_loss = 0.05701631504086944
Trained batch 426 in epoch 3, gen_loss = 0.4518645975293823, disc_loss = 0.057211171518858586
Trained batch 427 in epoch 3, gen_loss = 0.4518781440141045, disc_loss = 0.05727270562974214
Trained batch 428 in epoch 3, gen_loss = 0.4518044135231516, disc_loss = 0.057295743651180106
Trained batch 429 in epoch 3, gen_loss = 0.4517639887194301, disc_loss = 0.05730156025816795
Trained batch 430 in epoch 3, gen_loss = 0.45176320037266493, disc_loss = 0.05725099992281444
Trained batch 431 in epoch 3, gen_loss = 0.45180384656069456, disc_loss = 0.05714322371932212
Trained batch 432 in epoch 3, gen_loss = 0.4517420528254388, disc_loss = 0.05706394215729561
Trained batch 433 in epoch 3, gen_loss = 0.4518069111257105, disc_loss = 0.05708316582832314
Trained batch 434 in epoch 3, gen_loss = 0.45152905713552716, disc_loss = 0.05744835634758674
Trained batch 435 in epoch 3, gen_loss = 0.4516859876179914, disc_loss = 0.05761529221316936
Trained batch 436 in epoch 3, gen_loss = 0.4516665569295599, disc_loss = 0.057546430100629306
Trained batch 437 in epoch 3, gen_loss = 0.4515014226169891, disc_loss = 0.05751160953829669
Trained batch 438 in epoch 3, gen_loss = 0.45139496378040533, disc_loss = 0.05748935608704551
Trained batch 439 in epoch 3, gen_loss = 0.45120532627810134, disc_loss = 0.05745640996240333
Trained batch 440 in epoch 3, gen_loss = 0.4510875820032323, disc_loss = 0.057360526235022344
Trained batch 441 in epoch 3, gen_loss = 0.45110128415386064, disc_loss = 0.05736007855107325
Trained batch 442 in epoch 3, gen_loss = 0.4513312682475785, disc_loss = 0.05758179065090253
Trained batch 443 in epoch 3, gen_loss = 0.45106937924215385, disc_loss = 0.057525535224756515
Trained batch 444 in epoch 3, gen_loss = 0.45096359299809746, disc_loss = 0.057525285828879544
Trained batch 445 in epoch 3, gen_loss = 0.45107192375734784, disc_loss = 0.05752289392244104
Trained batch 446 in epoch 3, gen_loss = 0.4510351988159837, disc_loss = 0.05744888342373173
Trained batch 447 in epoch 3, gen_loss = 0.4510487360613687, disc_loss = 0.057506464194635294
Trained batch 448 in epoch 3, gen_loss = 0.4510983196823528, disc_loss = 0.05807944120609
Trained batch 449 in epoch 3, gen_loss = 0.450920692814721, disc_loss = 0.058694489769534106
Trained batch 450 in epoch 3, gen_loss = 0.45092843377140834, disc_loss = 0.05869326121566152
Trained batch 451 in epoch 3, gen_loss = 0.45094281909740075, disc_loss = 0.05875008421964465
Trained batch 452 in epoch 3, gen_loss = 0.4508957327991132, disc_loss = 0.0587182746347961
Trained batch 453 in epoch 3, gen_loss = 0.4508699902747696, disc_loss = 0.05876431711549391
Trained batch 454 in epoch 3, gen_loss = 0.45099151848436714, disc_loss = 0.05896740214090671
Trained batch 455 in epoch 3, gen_loss = 0.4508963025322086, disc_loss = 0.059016614128619006
Trained batch 456 in epoch 3, gen_loss = 0.4508958929738018, disc_loss = 0.0589617906801639
Trained batch 457 in epoch 3, gen_loss = 0.4509070095276728, disc_loss = 0.05903068088619323
Trained batch 458 in epoch 3, gen_loss = 0.4509271696242372, disc_loss = 0.05917839713806534
Trained batch 459 in epoch 3, gen_loss = 0.451034649429114, disc_loss = 0.05921664770601479
Trained batch 460 in epoch 3, gen_loss = 0.45107299988026733, disc_loss = 0.05919710401023401
Trained batch 461 in epoch 3, gen_loss = 0.4510503724152908, disc_loss = 0.05931021984075942
Trained batch 462 in epoch 3, gen_loss = 0.45125275251674857, disc_loss = 0.05944089248492815
Trained batch 463 in epoch 3, gen_loss = 0.4510117333767743, disc_loss = 0.05949611134640471
Trained batch 464 in epoch 3, gen_loss = 0.4509737648630655, disc_loss = 0.059426451087378526
Trained batch 465 in epoch 3, gen_loss = 0.4509067319237623, disc_loss = 0.05936981288090652
Trained batch 466 in epoch 3, gen_loss = 0.4510548453004253, disc_loss = 0.05933600482012383
Trained batch 467 in epoch 3, gen_loss = 0.45095502024787104, disc_loss = 0.05925747003698817
Trained batch 468 in epoch 3, gen_loss = 0.4508188574680133, disc_loss = 0.059210276590096256
Trained batch 469 in epoch 3, gen_loss = 0.45076498985290525, disc_loss = 0.059207791483842157
Trained batch 470 in epoch 3, gen_loss = 0.45085351039396476, disc_loss = 0.059103292165395276
Trained batch 471 in epoch 3, gen_loss = 0.45093815887378436, disc_loss = 0.05902809032852667
Trained batch 472 in epoch 3, gen_loss = 0.4510554256701318, disc_loss = 0.05895330392594113
Trained batch 473 in epoch 3, gen_loss = 0.4511349009436394, disc_loss = 0.058869019696461466
Trained batch 474 in epoch 3, gen_loss = 0.45124082483743366, disc_loss = 0.05879665002569948
Trained batch 475 in epoch 3, gen_loss = 0.451369921888123, disc_loss = 0.05878915567637789
Trained batch 476 in epoch 3, gen_loss = 0.45122937024014553, disc_loss = 0.0587701856952348
Trained batch 477 in epoch 3, gen_loss = 0.45139267953369905, disc_loss = 0.058676849321508975
Trained batch 478 in epoch 3, gen_loss = 0.45140791642392103, disc_loss = 0.058594071836597705
Trained batch 479 in epoch 3, gen_loss = 0.451236094844838, disc_loss = 0.058509065610026785
Trained batch 480 in epoch 3, gen_loss = 0.4512008815198331, disc_loss = 0.05848894780550129
Trained batch 481 in epoch 3, gen_loss = 0.45126149787942405, disc_loss = 0.0586600372238332
Trained batch 482 in epoch 3, gen_loss = 0.4513112557107124, disc_loss = 0.05879010612918276
Trained batch 483 in epoch 3, gen_loss = 0.45123617788237974, disc_loss = 0.05881267331477085
Trained batch 484 in epoch 3, gen_loss = 0.45130112699626646, disc_loss = 0.058764767519572804
Trained batch 485 in epoch 3, gen_loss = 0.45107905345934407, disc_loss = 0.0588039665328676
Trained batch 486 in epoch 3, gen_loss = 0.45126696344029, disc_loss = 0.05956635389666339
Trained batch 487 in epoch 3, gen_loss = 0.4511576070160162, disc_loss = 0.06002897527555508
Trained batch 488 in epoch 3, gen_loss = 0.45115585341775344, disc_loss = 0.060229732576426276
Trained batch 489 in epoch 3, gen_loss = 0.451111179407762, disc_loss = 0.06029800720541377
Trained batch 490 in epoch 3, gen_loss = 0.45103374457407874, disc_loss = 0.06038161556429918
Trained batch 491 in epoch 3, gen_loss = 0.45099447449532953, disc_loss = 0.06031836095650309
Trained batch 492 in epoch 3, gen_loss = 0.45093840312280714, disc_loss = 0.060244746528410976
Trained batch 493 in epoch 3, gen_loss = 0.45083259576969303, disc_loss = 0.060187959945044264
Trained batch 494 in epoch 3, gen_loss = 0.45067630434277084, disc_loss = 0.06018282958456889
Trained batch 495 in epoch 3, gen_loss = 0.4506314925008243, disc_loss = 0.06041760977701239
Trained batch 496 in epoch 3, gen_loss = 0.4504741076492448, disc_loss = 0.06096244302776903
Trained batch 497 in epoch 3, gen_loss = 0.45047488270035707, disc_loss = 0.06114616117068009
Trained batch 498 in epoch 3, gen_loss = 0.45059222735479504, disc_loss = 0.06145348154215557
Trained batch 499 in epoch 3, gen_loss = 0.4504638557434082, disc_loss = 0.06179677281482145
Trained batch 500 in epoch 3, gen_loss = 0.4503939528308229, disc_loss = 0.06193317598551735
Trained batch 501 in epoch 3, gen_loss = 0.45039831090020943, disc_loss = 0.061988985996630296
Trained batch 502 in epoch 3, gen_loss = 0.45031747944786343, disc_loss = 0.061966451991693844
Trained batch 503 in epoch 3, gen_loss = 0.4503629898268079, disc_loss = 0.06191331428237304
Trained batch 504 in epoch 3, gen_loss = 0.45025136417681627, disc_loss = 0.06183680400648846
Trained batch 505 in epoch 3, gen_loss = 0.4503645941085024, disc_loss = 0.06178838141187069
Trained batch 506 in epoch 3, gen_loss = 0.4503044197427686, disc_loss = 0.061737123611833186
Trained batch 507 in epoch 3, gen_loss = 0.45023460134746524, disc_loss = 0.061679116354459586
Trained batch 508 in epoch 3, gen_loss = 0.4502174155182829, disc_loss = 0.06171234658999782
Trained batch 509 in epoch 3, gen_loss = 0.4501844688957813, disc_loss = 0.06209751532604808
Trained batch 510 in epoch 3, gen_loss = 0.450194275717446, disc_loss = 0.06266429619325978
Trained batch 511 in epoch 3, gen_loss = 0.45017340034246445, disc_loss = 0.06261404741917431
Trained batch 512 in epoch 3, gen_loss = 0.4499621598111723, disc_loss = 0.06273816143921404
Trained batch 513 in epoch 3, gen_loss = 0.4498963314851434, disc_loss = 0.06276790459924794
Trained batch 514 in epoch 3, gen_loss = 0.4499106013659135, disc_loss = 0.06278011861022163
Trained batch 515 in epoch 3, gen_loss = 0.4498694120913513, disc_loss = 0.06296237083034618
Trained batch 516 in epoch 3, gen_loss = 0.44996918412195647, disc_loss = 0.0630244995017916
Trained batch 517 in epoch 3, gen_loss = 0.44998509192328656, disc_loss = 0.06300179159734398
Trained batch 518 in epoch 3, gen_loss = 0.4501537146021635, disc_loss = 0.06295303906303308
Trained batch 519 in epoch 3, gen_loss = 0.45010709086289774, disc_loss = 0.0630083103659742
Trained batch 520 in epoch 3, gen_loss = 0.45015154266998086, disc_loss = 0.06343348339269735
Trained batch 521 in epoch 3, gen_loss = 0.4501027819982434, disc_loss = 0.06338170154325279
Trained batch 522 in epoch 3, gen_loss = 0.44997479371997184, disc_loss = 0.06357150304711728
Trained batch 523 in epoch 3, gen_loss = 0.44999425562510964, disc_loss = 0.06390566754871126
Trained batch 524 in epoch 3, gen_loss = 0.4497136128516424, disc_loss = 0.06384795167572087
Trained batch 525 in epoch 3, gen_loss = 0.4495725494033937, disc_loss = 0.06385892745728884
Trained batch 526 in epoch 3, gen_loss = 0.4495288928726819, disc_loss = 0.06382325879718748
Trained batch 527 in epoch 3, gen_loss = 0.4496030057357116, disc_loss = 0.06389815365907976
Trained batch 528 in epoch 3, gen_loss = 0.44948411477986716, disc_loss = 0.0639593295452831
Trained batch 529 in epoch 3, gen_loss = 0.4495402419342185, disc_loss = 0.06398887918198938
Trained batch 530 in epoch 3, gen_loss = 0.44952872603177574, disc_loss = 0.06388610918837793
Trained batch 531 in epoch 3, gen_loss = 0.4495573460047406, disc_loss = 0.06381404566835906
Trained batch 532 in epoch 3, gen_loss = 0.4496214241628128, disc_loss = 0.06380644846335402
Trained batch 533 in epoch 3, gen_loss = 0.44951327279042663, disc_loss = 0.0637665469969417
Trained batch 534 in epoch 3, gen_loss = 0.44949825740306176, disc_loss = 0.06369271632762644
Trained batch 535 in epoch 3, gen_loss = 0.44953530587589563, disc_loss = 0.06376925592420192
Trained batch 536 in epoch 3, gen_loss = 0.4494282917381443, disc_loss = 0.06433362227229807
Trained batch 537 in epoch 3, gen_loss = 0.4495313286116575, disc_loss = 0.06453820775638656
Trained batch 538 in epoch 3, gen_loss = 0.4495749275073934, disc_loss = 0.06446829179331232
Trained batch 539 in epoch 3, gen_loss = 0.44961317948721075, disc_loss = 0.06450904000300431
Trained batch 540 in epoch 3, gen_loss = 0.44965992975367197, disc_loss = 0.0645460541460787
Trained batch 541 in epoch 3, gen_loss = 0.44965880762826915, disc_loss = 0.06453166553893254
Trained batch 542 in epoch 3, gen_loss = 0.4495949228714404, disc_loss = 0.06456656812631884
Trained batch 543 in epoch 3, gen_loss = 0.44965409706620607, disc_loss = 0.06460582991841125
Trained batch 544 in epoch 3, gen_loss = 0.44969672691931417, disc_loss = 0.06455952633437145
Trained batch 545 in epoch 3, gen_loss = 0.4497161827462933, disc_loss = 0.06449419920777923
Trained batch 546 in epoch 3, gen_loss = 0.44964148847886803, disc_loss = 0.06443202444113845
Trained batch 547 in epoch 3, gen_loss = 0.44957054526048856, disc_loss = 0.06438881811731746
Trained batch 548 in epoch 3, gen_loss = 0.4495341865742793, disc_loss = 0.06432365937852293
Trained batch 549 in epoch 3, gen_loss = 0.4492572828314521, disc_loss = 0.06429505469065837
Trained batch 550 in epoch 3, gen_loss = 0.4492245167764259, disc_loss = 0.06452099629001735
Trained batch 551 in epoch 3, gen_loss = 0.44934935322490294, disc_loss = 0.06485609190860776
Trained batch 552 in epoch 3, gen_loss = 0.4492916866301628, disc_loss = 0.06477749878481691
Trained batch 553 in epoch 3, gen_loss = 0.4491788731477751, disc_loss = 0.06484231282830817
Trained batch 554 in epoch 3, gen_loss = 0.44925365501695924, disc_loss = 0.06481728075147682
Trained batch 555 in epoch 3, gen_loss = 0.44921506748353834, disc_loss = 0.06476292718267203
Trained batch 556 in epoch 3, gen_loss = 0.4492602258439124, disc_loss = 0.0647605551298895
Trained batch 557 in epoch 3, gen_loss = 0.4492739944261462, disc_loss = 0.06469569162267017
Trained batch 558 in epoch 3, gen_loss = 0.44916553648725177, disc_loss = 0.064670027894666
Trained batch 559 in epoch 3, gen_loss = 0.4490874770496573, disc_loss = 0.06465105951189928
Trained batch 560 in epoch 3, gen_loss = 0.44888549007196477, disc_loss = 0.0647248527538961
Trained batch 561 in epoch 3, gen_loss = 0.44901892155727036, disc_loss = 0.06510997651719896
Trained batch 562 in epoch 3, gen_loss = 0.44889572368633684, disc_loss = 0.06504599133309566
Trained batch 563 in epoch 3, gen_loss = 0.4487065764289376, disc_loss = 0.06513266740919996
Trained batch 564 in epoch 3, gen_loss = 0.4485532031122562, disc_loss = 0.0650661385424468
Trained batch 565 in epoch 3, gen_loss = 0.44865221064208677, disc_loss = 0.06501182978898748
Trained batch 566 in epoch 3, gen_loss = 0.4485761987889675, disc_loss = 0.06493989279620166
Trained batch 567 in epoch 3, gen_loss = 0.448535413651819, disc_loss = 0.06487672277816414
Trained batch 568 in epoch 3, gen_loss = 0.4484597181079677, disc_loss = 0.06482345342058328
Trained batch 569 in epoch 3, gen_loss = 0.44841526135017995, disc_loss = 0.06494328977924102
Trained batch 570 in epoch 3, gen_loss = 0.4484275937497929, disc_loss = 0.06515769104248209
Trained batch 571 in epoch 3, gen_loss = 0.4482651496683801, disc_loss = 0.06545059622218181
Trained batch 572 in epoch 3, gen_loss = 0.4483122518757459, disc_loss = 0.06539448980936036
Trained batch 573 in epoch 3, gen_loss = 0.44829421223040655, disc_loss = 0.06546003010265126
Trained batch 574 in epoch 3, gen_loss = 0.44821158486863844, disc_loss = 0.065559835365528
Trained batch 575 in epoch 3, gen_loss = 0.44820820566059816, disc_loss = 0.06555964732696237
Trained batch 576 in epoch 3, gen_loss = 0.4480909029057369, disc_loss = 0.06551015385720343
Trained batch 577 in epoch 3, gen_loss = 0.44812207088957196, disc_loss = 0.06542256230506144
Trained batch 578 in epoch 3, gen_loss = 0.4482099742263504, disc_loss = 0.06539233738841209
Trained batch 579 in epoch 3, gen_loss = 0.44819727709581114, disc_loss = 0.06539217767683018
Trained batch 580 in epoch 3, gen_loss = 0.44822994387498616, disc_loss = 0.06546401489877082
Trained batch 581 in epoch 3, gen_loss = 0.44815316371286856, disc_loss = 0.06594784173408773
Trained batch 582 in epoch 3, gen_loss = 0.44818607207841366, disc_loss = 0.06592892014140368
Trained batch 583 in epoch 3, gen_loss = 0.44826685249397197, disc_loss = 0.06590592892711332
Trained batch 584 in epoch 3, gen_loss = 0.4482239305973053, disc_loss = 0.06587395958689989
Trained batch 585 in epoch 3, gen_loss = 0.4482022558971477, disc_loss = 0.06583265352115328
Trained batch 586 in epoch 3, gen_loss = 0.44830072266279736, disc_loss = 0.0658393986677843
Trained batch 587 in epoch 3, gen_loss = 0.448425745528166, disc_loss = 0.06583494603987086
Trained batch 588 in epoch 3, gen_loss = 0.4483434504786655, disc_loss = 0.06580250659295009
Trained batch 589 in epoch 3, gen_loss = 0.44837119326753133, disc_loss = 0.06572318541762119
Trained batch 590 in epoch 3, gen_loss = 0.44826190019823775, disc_loss = 0.06598826841917677
Trained batch 591 in epoch 3, gen_loss = 0.448329458617278, disc_loss = 0.0661197030107409
Trained batch 592 in epoch 3, gen_loss = 0.4483022287261828, disc_loss = 0.06607383750905212
Trained batch 593 in epoch 3, gen_loss = 0.4483046537196195, disc_loss = 0.0663174365702797
Trained batch 594 in epoch 3, gen_loss = 0.4482397753150523, disc_loss = 0.06641368570408838
Trained batch 595 in epoch 3, gen_loss = 0.4482039611711598, disc_loss = 0.0663179374708569
Trained batch 596 in epoch 3, gen_loss = 0.4482130578514719, disc_loss = 0.06634715054975121
Trained batch 597 in epoch 3, gen_loss = 0.44815317723264664, disc_loss = 0.06648097763166616
Trained batch 598 in epoch 3, gen_loss = 0.4483180212258098, disc_loss = 0.06655456521548331
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 0.4143161177635193, disc_loss = 0.23396818339824677
Trained batch 1 in epoch 4, gen_loss = 0.4513748586177826, disc_loss = 0.1831078752875328
Trained batch 2 in epoch 4, gen_loss = 0.4531803826491038, disc_loss = 0.16313956926266351
Trained batch 3 in epoch 4, gen_loss = 0.42583418637514114, disc_loss = 0.16029766388237476
Trained batch 4 in epoch 4, gen_loss = 0.4437116324901581, disc_loss = 0.1350847713649273
Trained batch 5 in epoch 4, gen_loss = 0.4493805269400279, disc_loss = 0.12124564312398434
Trained batch 6 in epoch 4, gen_loss = 0.44494048186710905, disc_loss = 0.118706683495215
Trained batch 7 in epoch 4, gen_loss = 0.44712669402360916, disc_loss = 0.10651177424006164
Trained batch 8 in epoch 4, gen_loss = 0.4521215193801456, disc_loss = 0.09961992274555895
Trained batch 9 in epoch 4, gen_loss = 0.44535567462444303, disc_loss = 0.09462551940232515
Trained batch 10 in epoch 4, gen_loss = 0.4505927860736847, disc_loss = 0.08684578766538338
Trained batch 11 in epoch 4, gen_loss = 0.4541533887386322, disc_loss = 0.08488905949828525
Trained batch 12 in epoch 4, gen_loss = 0.45094770880845875, disc_loss = 0.08209223866176146
Trained batch 13 in epoch 4, gen_loss = 0.45049389558179037, disc_loss = 0.07876177444787962
Trained batch 14 in epoch 4, gen_loss = 0.45335187315940856, disc_loss = 0.07832124326378107
Trained batch 15 in epoch 4, gen_loss = 0.45147084444761276, disc_loss = 0.08240858366480097
Trained batch 16 in epoch 4, gen_loss = 0.4555467893095577, disc_loss = 0.10146467557505649
Trained batch 17 in epoch 4, gen_loss = 0.45520935621526504, disc_loss = 0.09838055027648807
Trained batch 18 in epoch 4, gen_loss = 0.45305904432346944, disc_loss = 0.1044253122159525
Trained batch 19 in epoch 4, gen_loss = 0.4533467724919319, disc_loss = 0.10911575960926712
Trained batch 20 in epoch 4, gen_loss = 0.45510809194473995, disc_loss = 0.10605842331867843
Trained batch 21 in epoch 4, gen_loss = 0.45038671656088397, disc_loss = 0.10492867870594967
Trained batch 22 in epoch 4, gen_loss = 0.4489362252795178, disc_loss = 0.10250772612736277
Trained batch 23 in epoch 4, gen_loss = 0.45237404728929204, disc_loss = 0.1005632319720462
Trained batch 24 in epoch 4, gen_loss = 0.45033366918563844, disc_loss = 0.10007354360073804
Trained batch 25 in epoch 4, gen_loss = 0.4492424118977327, disc_loss = 0.09801390319346236
Trained batch 26 in epoch 4, gen_loss = 0.451458152797487, disc_loss = 0.09919127611512388
Trained batch 27 in epoch 4, gen_loss = 0.44878540294510977, disc_loss = 0.09865442833064922
Trained batch 28 in epoch 4, gen_loss = 0.4469769175710349, disc_loss = 0.09810386993119428
Trained batch 29 in epoch 4, gen_loss = 0.4490068684021632, disc_loss = 0.10477216575915614
Trained batch 30 in epoch 4, gen_loss = 0.44782489634329276, disc_loss = 0.10261526568642547
Trained batch 31 in epoch 4, gen_loss = 0.44488171953707933, disc_loss = 0.10285059534362517
Trained batch 32 in epoch 4, gen_loss = 0.4448137274294188, disc_loss = 0.1028575837104158
Trained batch 33 in epoch 4, gen_loss = 0.4433027225382188, disc_loss = 0.1010523214662338
Trained batch 34 in epoch 4, gen_loss = 0.4421099662780762, disc_loss = 0.09958758245089225
Trained batch 35 in epoch 4, gen_loss = 0.44137997842497295, disc_loss = 0.09832898690365255
Trained batch 36 in epoch 4, gen_loss = 0.44032421949747447, disc_loss = 0.09782811835710262
Trained batch 37 in epoch 4, gen_loss = 0.4416164410741706, disc_loss = 0.09583144264883901
Trained batch 38 in epoch 4, gen_loss = 0.441716411174872, disc_loss = 0.09389790216795145
Trained batch 39 in epoch 4, gen_loss = 0.4426641009747982, disc_loss = 0.0922497890656814
Trained batch 40 in epoch 4, gen_loss = 0.44112210375506705, disc_loss = 0.09138686062268368
Trained batch 41 in epoch 4, gen_loss = 0.4405236967972347, disc_loss = 0.09569677867971006
Trained batch 42 in epoch 4, gen_loss = 0.44150412706441655, disc_loss = 0.09899175875322071
Trained batch 43 in epoch 4, gen_loss = 0.4404422694986517, disc_loss = 0.09841806219298053
Trained batch 44 in epoch 4, gen_loss = 0.4398812294006348, disc_loss = 0.09812914015104374
Trained batch 45 in epoch 4, gen_loss = 0.4407373537187991, disc_loss = 0.097943099114396
Trained batch 46 in epoch 4, gen_loss = 0.44169577068470894, disc_loss = 0.09719126289115941
Trained batch 47 in epoch 4, gen_loss = 0.44101412656406563, disc_loss = 0.09682564482015248
Trained batch 48 in epoch 4, gen_loss = 0.44100768651281086, disc_loss = 0.10000610516919774
Trained batch 49 in epoch 4, gen_loss = 0.43872919261455534, disc_loss = 0.10025492308661342
Trained batch 50 in epoch 4, gen_loss = 0.4388323180815753, disc_loss = 0.09954678221587457
Trained batch 51 in epoch 4, gen_loss = 0.43869393605452317, disc_loss = 0.0985766254329624
Trained batch 52 in epoch 4, gen_loss = 0.4375566081056055, disc_loss = 0.09762016499309607
Trained batch 53 in epoch 4, gen_loss = 0.43758666184213424, disc_loss = 0.09651297260144795
Trained batch 54 in epoch 4, gen_loss = 0.43913736560127953, disc_loss = 0.0977460453286767
Trained batch 55 in epoch 4, gen_loss = 0.43865732848644257, disc_loss = 0.09751853744299817
Trained batch 56 in epoch 4, gen_loss = 0.439035214353026, disc_loss = 0.09598766984581425
Trained batch 57 in epoch 4, gen_loss = 0.43889172066902293, disc_loss = 0.09448096523832145
Trained batch 58 in epoch 4, gen_loss = 0.43877599603038725, disc_loss = 0.09326078678023512
Trained batch 59 in epoch 4, gen_loss = 0.4379653826355934, disc_loss = 0.09238511415508886
Trained batch 60 in epoch 4, gen_loss = 0.43822975676567827, disc_loss = 0.09274209002185552
Trained batch 61 in epoch 4, gen_loss = 0.4380374493137483, disc_loss = 0.0950173013843596
Trained batch 62 in epoch 4, gen_loss = 0.4388867399049184, disc_loss = 0.09667307580451644
Trained batch 63 in epoch 4, gen_loss = 0.4385071527212858, disc_loss = 0.09547513617144432
Trained batch 64 in epoch 4, gen_loss = 0.4389923998942742, disc_loss = 0.09444822954157224
Trained batch 65 in epoch 4, gen_loss = 0.43883368869622547, disc_loss = 0.0932609689083289
Trained batch 66 in epoch 4, gen_loss = 0.43970325678142147, disc_loss = 0.09259674493779442
Trained batch 67 in epoch 4, gen_loss = 0.43923241951886344, disc_loss = 0.09180840177406721
Trained batch 68 in epoch 4, gen_loss = 0.43835767758065375, disc_loss = 0.09125258024458004
Trained batch 69 in epoch 4, gen_loss = 0.4387197766985212, disc_loss = 0.0908968289648848
Trained batch 70 in epoch 4, gen_loss = 0.4389666881359799, disc_loss = 0.08984267487334953
Trained batch 71 in epoch 4, gen_loss = 0.43952545606427723, disc_loss = 0.08892515965271741
Trained batch 72 in epoch 4, gen_loss = 0.43897892351019874, disc_loss = 0.08898687772197675
Trained batch 73 in epoch 4, gen_loss = 0.4396983719355351, disc_loss = 0.09020410620330556
Trained batch 74 in epoch 4, gen_loss = 0.4390903294086456, disc_loss = 0.09036302716781695
Trained batch 75 in epoch 4, gen_loss = 0.4401149581137456, disc_loss = 0.08929605359260581
Trained batch 76 in epoch 4, gen_loss = 0.4402659423165507, disc_loss = 0.0892860113292352
Trained batch 77 in epoch 4, gen_loss = 0.43997095945553905, disc_loss = 0.09018758071873051
Trained batch 78 in epoch 4, gen_loss = 0.4406328887879094, disc_loss = 0.08960523426862835
Trained batch 79 in epoch 4, gen_loss = 0.44120720624923704, disc_loss = 0.08896107355831191
Trained batch 80 in epoch 4, gen_loss = 0.441381769415773, disc_loss = 0.08893124794840444
Trained batch 81 in epoch 4, gen_loss = 0.44267859836904017, disc_loss = 0.0882429087920705
Trained batch 82 in epoch 4, gen_loss = 0.44303780219641076, disc_loss = 0.08737116824296942
Trained batch 83 in epoch 4, gen_loss = 0.44310344010591507, disc_loss = 0.08648023180042703
Trained batch 84 in epoch 4, gen_loss = 0.44211694878690383, disc_loss = 0.08582743564072777
Trained batch 85 in epoch 4, gen_loss = 0.4418216222940489, disc_loss = 0.0854080195517041
Trained batch 86 in epoch 4, gen_loss = 0.4416969959763275, disc_loss = 0.08509930655702777
Trained batch 87 in epoch 4, gen_loss = 0.441758049482649, disc_loss = 0.08433682490563528
Trained batch 88 in epoch 4, gen_loss = 0.44188509998696573, disc_loss = 0.08350051638115658
Trained batch 89 in epoch 4, gen_loss = 0.44129494031270344, disc_loss = 0.08328034140997463
Trained batch 90 in epoch 4, gen_loss = 0.4406536339403509, disc_loss = 0.08425299618597869
Trained batch 91 in epoch 4, gen_loss = 0.44098204179950384, disc_loss = 0.08415064110380152
Trained batch 92 in epoch 4, gen_loss = 0.4406961035984819, disc_loss = 0.08355149666788758
Trained batch 93 in epoch 4, gen_loss = 0.4414821945606394, disc_loss = 0.08307031058567635
Trained batch 94 in epoch 4, gen_loss = 0.44112372837568586, disc_loss = 0.08243560355744864
Trained batch 95 in epoch 4, gen_loss = 0.44174398481845856, disc_loss = 0.08178035594755784
Trained batch 96 in epoch 4, gen_loss = 0.44195585920638647, disc_loss = 0.08106661904795268
Trained batch 97 in epoch 4, gen_loss = 0.44121004610645526, disc_loss = 0.08095093453493045
Trained batch 98 in epoch 4, gen_loss = 0.44117583861254683, disc_loss = 0.0805972885490969
Trained batch 99 in epoch 4, gen_loss = 0.441557534635067, disc_loss = 0.0801278338395059
Trained batch 100 in epoch 4, gen_loss = 0.4417576300035609, disc_loss = 0.08018424994505868
Trained batch 101 in epoch 4, gen_loss = 0.4425024857708052, disc_loss = 0.08115799350700542
Trained batch 102 in epoch 4, gen_loss = 0.44278328337715667, disc_loss = 0.08103107051580276
Trained batch 103 in epoch 4, gen_loss = 0.4431896140942207, disc_loss = 0.08065984586182122
Trained batch 104 in epoch 4, gen_loss = 0.44344247721490404, disc_loss = 0.08013967495589029
Trained batch 105 in epoch 4, gen_loss = 0.4436881606871227, disc_loss = 0.079733466905243
Trained batch 106 in epoch 4, gen_loss = 0.44305268041441376, disc_loss = 0.08013508420124232
Trained batch 107 in epoch 4, gen_loss = 0.44345136566294563, disc_loss = 0.08038089817596807
Trained batch 108 in epoch 4, gen_loss = 0.44335573173444204, disc_loss = 0.07984825750009729
Trained batch 109 in epoch 4, gen_loss = 0.44298137426376344, disc_loss = 0.07964698110114445
Trained batch 110 in epoch 4, gen_loss = 0.4432255993555258, disc_loss = 0.0792126370979859
Trained batch 111 in epoch 4, gen_loss = 0.4432228880801371, disc_loss = 0.07861763208971492
Trained batch 112 in epoch 4, gen_loss = 0.44316439000906144, disc_loss = 0.07816798661926151
Trained batch 113 in epoch 4, gen_loss = 0.44309476854508384, disc_loss = 0.07778279584620082
Trained batch 114 in epoch 4, gen_loss = 0.4433355530966883, disc_loss = 0.07790212135600007
Trained batch 115 in epoch 4, gen_loss = 0.4434254179740774, disc_loss = 0.07785922735287197
Trained batch 116 in epoch 4, gen_loss = 0.4436538311151358, disc_loss = 0.07737373541562985
Trained batch 117 in epoch 4, gen_loss = 0.443335804393736, disc_loss = 0.0770202491874412
Trained batch 118 in epoch 4, gen_loss = 0.443790498901816, disc_loss = 0.07667441378120615
Trained batch 119 in epoch 4, gen_loss = 0.4443559393286705, disc_loss = 0.07613135642992953
Trained batch 120 in epoch 4, gen_loss = 0.44471243171652486, disc_loss = 0.07604926970810437
Trained batch 121 in epoch 4, gen_loss = 0.4445148706436157, disc_loss = 0.07595514272507585
Trained batch 122 in epoch 4, gen_loss = 0.44428643705399057, disc_loss = 0.07576232795732293
Trained batch 123 in epoch 4, gen_loss = 0.44383616505130646, disc_loss = 0.07540292044981353
Trained batch 124 in epoch 4, gen_loss = 0.4441725528240204, disc_loss = 0.0753980375379324
Trained batch 125 in epoch 4, gen_loss = 0.4437011421199829, disc_loss = 0.07660460778112922
Trained batch 126 in epoch 4, gen_loss = 0.44434780375225336, disc_loss = 0.0770919839081567
Trained batch 127 in epoch 4, gen_loss = 0.4438934284262359, disc_loss = 0.07673815464659128
Trained batch 128 in epoch 4, gen_loss = 0.44387468695640564, disc_loss = 0.07639213525798431
Trained batch 129 in epoch 4, gen_loss = 0.44378002813229195, disc_loss = 0.07592057347154388
Trained batch 130 in epoch 4, gen_loss = 0.44362650823047145, disc_loss = 0.0755025864372613
Trained batch 131 in epoch 4, gen_loss = 0.4436616353464849, disc_loss = 0.07524648734199052
Trained batch 132 in epoch 4, gen_loss = 0.4437350563536909, disc_loss = 0.07518531703495217
Trained batch 133 in epoch 4, gen_loss = 0.44378018179046574, disc_loss = 0.07492632548839076
Trained batch 134 in epoch 4, gen_loss = 0.4438446501890818, disc_loss = 0.07488200451350874
Trained batch 135 in epoch 4, gen_loss = 0.4439532469738932, disc_loss = 0.07578914773458724
Trained batch 136 in epoch 4, gen_loss = 0.44362602181678273, disc_loss = 0.07617734369216826
Trained batch 137 in epoch 4, gen_loss = 0.44358054494512256, disc_loss = 0.07594896207118164
Trained batch 138 in epoch 4, gen_loss = 0.44400475779883297, disc_loss = 0.07547791920629122
Trained batch 139 in epoch 4, gen_loss = 0.4439632177352905, disc_loss = 0.07533184675100658
Trained batch 140 in epoch 4, gen_loss = 0.4440307946915322, disc_loss = 0.07506560007810381
Trained batch 141 in epoch 4, gen_loss = 0.4442239699649139, disc_loss = 0.0749753601783493
Trained batch 142 in epoch 4, gen_loss = 0.4443059178082259, disc_loss = 0.07479026371131202
Trained batch 143 in epoch 4, gen_loss = 0.4435942005366087, disc_loss = 0.07491377192006136
Trained batch 144 in epoch 4, gen_loss = 0.4443025323851355, disc_loss = 0.07511223163455724
Trained batch 145 in epoch 4, gen_loss = 0.4438552544133304, disc_loss = 0.07478162017969849
Trained batch 146 in epoch 4, gen_loss = 0.44435187322752817, disc_loss = 0.07443772863951467
Trained batch 147 in epoch 4, gen_loss = 0.4448078075373495, disc_loss = 0.07413895248838172
Trained batch 148 in epoch 4, gen_loss = 0.445124856377608, disc_loss = 0.07395806265432363
Trained batch 149 in epoch 4, gen_loss = 0.44504565954208375, disc_loss = 0.07382020351166527
Trained batch 150 in epoch 4, gen_loss = 0.44534750489999125, disc_loss = 0.0734392021603833
Trained batch 151 in epoch 4, gen_loss = 0.44581414680731923, disc_loss = 0.07382135867067662
Trained batch 152 in epoch 4, gen_loss = 0.44570350900195005, disc_loss = 0.07511833942574418
Trained batch 153 in epoch 4, gen_loss = 0.4456902374694874, disc_loss = 0.07484282039759027
Trained batch 154 in epoch 4, gen_loss = 0.44603081249421644, disc_loss = 0.07494794144144942
Trained batch 155 in epoch 4, gen_loss = 0.44566509758050626, disc_loss = 0.07507493852589948
Trained batch 156 in epoch 4, gen_loss = 0.445780907277089, disc_loss = 0.07485104382488948
Trained batch 157 in epoch 4, gen_loss = 0.44573724835733824, disc_loss = 0.07474625569803617
Trained batch 158 in epoch 4, gen_loss = 0.44546142332958727, disc_loss = 0.07487719798308311
Trained batch 159 in epoch 4, gen_loss = 0.4448946245014668, disc_loss = 0.07506370271439664
Trained batch 160 in epoch 4, gen_loss = 0.44512584861020865, disc_loss = 0.07497135482103744
Trained batch 161 in epoch 4, gen_loss = 0.44510886017923, disc_loss = 0.07521473084587926
Trained batch 162 in epoch 4, gen_loss = 0.44471744105128425, disc_loss = 0.07628959757304447
Trained batch 163 in epoch 4, gen_loss = 0.4453300969993196, disc_loss = 0.07751125253441675
Trained batch 164 in epoch 4, gen_loss = 0.44487302736802536, disc_loss = 0.0774789691140706
Trained batch 165 in epoch 4, gen_loss = 0.444731113960944, disc_loss = 0.07713531091786831
Trained batch 166 in epoch 4, gen_loss = 0.4444802551569339, disc_loss = 0.07699432723157242
Trained batch 167 in epoch 4, gen_loss = 0.4441777150191012, disc_loss = 0.07793410392367237
Trained batch 168 in epoch 4, gen_loss = 0.4443980056858627, disc_loss = 0.07864659270216551
Trained batch 169 in epoch 4, gen_loss = 0.44457684772856093, disc_loss = 0.07889212829553906
Trained batch 170 in epoch 4, gen_loss = 0.44407614385872557, disc_loss = 0.07882883198755353
Trained batch 171 in epoch 4, gen_loss = 0.4442427149692247, disc_loss = 0.07858042128189185
Trained batch 172 in epoch 4, gen_loss = 0.4436943574103317, disc_loss = 0.07849556487053633
Trained batch 173 in epoch 4, gen_loss = 0.4439427241169173, disc_loss = 0.07823587882857042
Trained batch 174 in epoch 4, gen_loss = 0.44377535820007324, disc_loss = 0.07785472817718983
Trained batch 175 in epoch 4, gen_loss = 0.44357161867347633, disc_loss = 0.07762561678166756
Trained batch 176 in epoch 4, gen_loss = 0.4431188771616941, disc_loss = 0.07845992050896593
Trained batch 177 in epoch 4, gen_loss = 0.44381052640716684, disc_loss = 0.07956380571835162
Trained batch 178 in epoch 4, gen_loss = 0.44369322377876197, disc_loss = 0.07948592429012892
Trained batch 179 in epoch 4, gen_loss = 0.44366804477241306, disc_loss = 0.07914136889287167
Trained batch 180 in epoch 4, gen_loss = 0.44379569746512737, disc_loss = 0.07891216391481418
Trained batch 181 in epoch 4, gen_loss = 0.4436695544601797, disc_loss = 0.07912801176432398
Trained batch 182 in epoch 4, gen_loss = 0.4431235104636416, disc_loss = 0.08053488161190937
Trained batch 183 in epoch 4, gen_loss = 0.44341677783623984, disc_loss = 0.08040723914240042
Trained batch 184 in epoch 4, gen_loss = 0.4437658003858618, disc_loss = 0.08159547380700305
Trained batch 185 in epoch 4, gen_loss = 0.443576804252081, disc_loss = 0.08189503332820311
Trained batch 186 in epoch 4, gen_loss = 0.44334523116841035, disc_loss = 0.08194675919086856
Trained batch 187 in epoch 4, gen_loss = 0.44343386986788286, disc_loss = 0.08199086076916849
Trained batch 188 in epoch 4, gen_loss = 0.4434520542306244, disc_loss = 0.08193367645735779
Trained batch 189 in epoch 4, gen_loss = 0.4431883923317257, disc_loss = 0.08193734398994007
Trained batch 190 in epoch 4, gen_loss = 0.4426826060754466, disc_loss = 0.08225898968338655
Trained batch 191 in epoch 4, gen_loss = 0.4421941804078718, disc_loss = 0.08278610837684634
Trained batch 192 in epoch 4, gen_loss = 0.4418547659957965, disc_loss = 0.0829203492561307
Trained batch 193 in epoch 4, gen_loss = 0.4420298534570281, disc_loss = 0.0827085730744545
Trained batch 194 in epoch 4, gen_loss = 0.4420124312241872, disc_loss = 0.08252703462464688
Trained batch 195 in epoch 4, gen_loss = 0.4416829297433094, disc_loss = 0.08233600450983765
Trained batch 196 in epoch 4, gen_loss = 0.44188894656709005, disc_loss = 0.08226635725932376
Trained batch 197 in epoch 4, gen_loss = 0.44202737419894245, disc_loss = 0.08217997573353726
Trained batch 198 in epoch 4, gen_loss = 0.44187112219968633, disc_loss = 0.08216436112758203
Trained batch 199 in epoch 4, gen_loss = 0.4412904144823551, disc_loss = 0.08269829372875392
Trained batch 200 in epoch 4, gen_loss = 0.4413515934303625, disc_loss = 0.08272366024627911
Trained batch 201 in epoch 4, gen_loss = 0.4414972859148932, disc_loss = 0.0824166971839743
Trained batch 202 in epoch 4, gen_loss = 0.4412985154854253, disc_loss = 0.08220051881384674
Trained batch 203 in epoch 4, gen_loss = 0.4412647997047387, disc_loss = 0.08187406739293068
Trained batch 204 in epoch 4, gen_loss = 0.44153365681811074, disc_loss = 0.08177847552408532
Trained batch 205 in epoch 4, gen_loss = 0.44140488603740063, disc_loss = 0.08170007783196216
Trained batch 206 in epoch 4, gen_loss = 0.4417362947394882, disc_loss = 0.08155622647328366
Trained batch 207 in epoch 4, gen_loss = 0.4418327119201422, disc_loss = 0.08134794601490004
Trained batch 208 in epoch 4, gen_loss = 0.4419144590220383, disc_loss = 0.0815130348214835
Trained batch 209 in epoch 4, gen_loss = 0.4423328602597827, disc_loss = 0.08143514367263942
Trained batch 210 in epoch 4, gen_loss = 0.44207969209029213, disc_loss = 0.08114021301481396
Trained batch 211 in epoch 4, gen_loss = 0.4420979565606927, disc_loss = 0.08094838836212766
Trained batch 212 in epoch 4, gen_loss = 0.4421337579897312, disc_loss = 0.08075937168768874
Trained batch 213 in epoch 4, gen_loss = 0.4420669268224841, disc_loss = 0.08069470213186518
Trained batch 214 in epoch 4, gen_loss = 0.44159831169039704, disc_loss = 0.08077212421353473
Trained batch 215 in epoch 4, gen_loss = 0.441512754118001, disc_loss = 0.08046229674342882
Trained batch 216 in epoch 4, gen_loss = 0.44161962638802243, disc_loss = 0.08069997546069908
Trained batch 217 in epoch 4, gen_loss = 0.4414944226315262, disc_loss = 0.08205376826055827
Trained batch 218 in epoch 4, gen_loss = 0.44137922119876566, disc_loss = 0.08320506618753688
Trained batch 219 in epoch 4, gen_loss = 0.4413310676813126, disc_loss = 0.08325497647747397
Trained batch 220 in epoch 4, gen_loss = 0.44123537710349486, disc_loss = 0.08352718280619895
Trained batch 221 in epoch 4, gen_loss = 0.4409211269907049, disc_loss = 0.08363866209480408
Trained batch 222 in epoch 4, gen_loss = 0.441254590926149, disc_loss = 0.08419800573968299
Trained batch 223 in epoch 4, gen_loss = 0.4411219261320574, disc_loss = 0.08464951408261966
Trained batch 224 in epoch 4, gen_loss = 0.4408408933215671, disc_loss = 0.08444902914265792
Trained batch 225 in epoch 4, gen_loss = 0.4407717621168204, disc_loss = 0.08439599733338156
Trained batch 226 in epoch 4, gen_loss = 0.4407639969550565, disc_loss = 0.08436037315310098
Trained batch 227 in epoch 4, gen_loss = 0.4408047388781581, disc_loss = 0.08413201370358206
Trained batch 228 in epoch 4, gen_loss = 0.44068959511523687, disc_loss = 0.08420920449280582
Trained batch 229 in epoch 4, gen_loss = 0.44071297528951064, disc_loss = 0.08476739654560451
Trained batch 230 in epoch 4, gen_loss = 0.4404703764430372, disc_loss = 0.08548218739981
Trained batch 231 in epoch 4, gen_loss = 0.4401669443167489, disc_loss = 0.08538944999173541
Trained batch 232 in epoch 4, gen_loss = 0.4401331413457322, disc_loss = 0.08539843648000592
Trained batch 233 in epoch 4, gen_loss = 0.439830658527521, disc_loss = 0.08564235402955714
Trained batch 234 in epoch 4, gen_loss = 0.4397432488329867, disc_loss = 0.08549252560639635
Trained batch 235 in epoch 4, gen_loss = 0.4397965850213827, disc_loss = 0.08533764355105616
Trained batch 236 in epoch 4, gen_loss = 0.4400785639567717, disc_loss = 0.08510220138835504
Trained batch 237 in epoch 4, gen_loss = 0.44031909671651215, disc_loss = 0.08496148585334044
Trained batch 238 in epoch 4, gen_loss = 0.4403555640116895, disc_loss = 0.08480366302272266
Trained batch 239 in epoch 4, gen_loss = 0.4403331559151411, disc_loss = 0.08473746641539037
Trained batch 240 in epoch 4, gen_loss = 0.44023159838810993, disc_loss = 0.08509621477040512
Trained batch 241 in epoch 4, gen_loss = 0.44022884903367887, disc_loss = 0.08499836332110827
Trained batch 242 in epoch 4, gen_loss = 0.4399731509970049, disc_loss = 0.08494966500151305
Trained batch 243 in epoch 4, gen_loss = 0.4399157548781301, disc_loss = 0.08483173571465934
Trained batch 244 in epoch 4, gen_loss = 0.44025487182091694, disc_loss = 0.08474532507207928
Trained batch 245 in epoch 4, gen_loss = 0.4400827999764342, disc_loss = 0.0845307964013844
Trained batch 246 in epoch 4, gen_loss = 0.439975504571127, disc_loss = 0.08434438637574675
Trained batch 247 in epoch 4, gen_loss = 0.4399449884170486, disc_loss = 0.08411995977944424
Trained batch 248 in epoch 4, gen_loss = 0.4397215645715415, disc_loss = 0.0842341845144469
Trained batch 249 in epoch 4, gen_loss = 0.44042373406887053, disc_loss = 0.08494738648831844
Trained batch 250 in epoch 4, gen_loss = 0.4402642998087454, disc_loss = 0.0849262520938043
Trained batch 251 in epoch 4, gen_loss = 0.44061000858034405, disc_loss = 0.08468153502141672
Trained batch 252 in epoch 4, gen_loss = 0.4409337571487125, disc_loss = 0.0846660013490986
Trained batch 253 in epoch 4, gen_loss = 0.44074555574439644, disc_loss = 0.08457038877165224
Trained batch 254 in epoch 4, gen_loss = 0.44043286279136057, disc_loss = 0.08491371802839578
Trained batch 255 in epoch 4, gen_loss = 0.44043719570618123, disc_loss = 0.08473267895169556
Trained batch 256 in epoch 4, gen_loss = 0.4407424508133751, disc_loss = 0.0847177999782655
Trained batch 257 in epoch 4, gen_loss = 0.4405551963998366, disc_loss = 0.08472788105754889
Trained batch 258 in epoch 4, gen_loss = 0.44053997761034136, disc_loss = 0.08451033938086401
Trained batch 259 in epoch 4, gen_loss = 0.4405653307071099, disc_loss = 0.08425811846525623
Trained batch 260 in epoch 4, gen_loss = 0.4403547397975264, disc_loss = 0.08408817185724148
Trained batch 261 in epoch 4, gen_loss = 0.44054553925081064, disc_loss = 0.08396101298649575
Trained batch 262 in epoch 4, gen_loss = 0.4405575611065549, disc_loss = 0.08429661500108333
Trained batch 263 in epoch 4, gen_loss = 0.4403691539032893, disc_loss = 0.08479024954563515
Trained batch 264 in epoch 4, gen_loss = 0.4405960156107849, disc_loss = 0.08494793445855942
Trained batch 265 in epoch 4, gen_loss = 0.4406679103473075, disc_loss = 0.08473912239270776
Trained batch 266 in epoch 4, gen_loss = 0.4405898190616222, disc_loss = 0.08475599414930585
Trained batch 267 in epoch 4, gen_loss = 0.440635465975128, disc_loss = 0.08457094096620359
Trained batch 268 in epoch 4, gen_loss = 0.44084284806340157, disc_loss = 0.08440717707862419
Trained batch 269 in epoch 4, gen_loss = 0.4408234276153423, disc_loss = 0.08445997444429883
Trained batch 270 in epoch 4, gen_loss = 0.4409978763643666, disc_loss = 0.08419012773190918
Trained batch 271 in epoch 4, gen_loss = 0.4412948191165924, disc_loss = 0.08403168622787822
Trained batch 272 in epoch 4, gen_loss = 0.44148750652323715, disc_loss = 0.08381672988171543
Trained batch 273 in epoch 4, gen_loss = 0.44154612839657026, disc_loss = 0.08363762999592471
Trained batch 274 in epoch 4, gen_loss = 0.4414878805117174, disc_loss = 0.08336614597250115
Trained batch 275 in epoch 4, gen_loss = 0.441593869332818, disc_loss = 0.08310301811771764
Trained batch 276 in epoch 4, gen_loss = 0.4415024457640596, disc_loss = 0.08286972769573062
Trained batch 277 in epoch 4, gen_loss = 0.4414029540561086, disc_loss = 0.08277312971035139
Trained batch 278 in epoch 4, gen_loss = 0.44133404367286244, disc_loss = 0.08290124761347915
Trained batch 279 in epoch 4, gen_loss = 0.44160181315881863, disc_loss = 0.08285605366607862
Trained batch 280 in epoch 4, gen_loss = 0.44188473604327844, disc_loss = 0.08273285763252036
Trained batch 281 in epoch 4, gen_loss = 0.44198458266596424, disc_loss = 0.08267320077602111
Trained batch 282 in epoch 4, gen_loss = 0.442062140564194, disc_loss = 0.0824111443467096
Trained batch 283 in epoch 4, gen_loss = 0.4418151338755245, disc_loss = 0.0822806807962889
Trained batch 284 in epoch 4, gen_loss = 0.44174314611836485, disc_loss = 0.08211048890820198
Trained batch 285 in epoch 4, gen_loss = 0.44155110012401233, disc_loss = 0.08196410223828642
Trained batch 286 in epoch 4, gen_loss = 0.44195109813470873, disc_loss = 0.08172135056687668
Trained batch 287 in epoch 4, gen_loss = 0.4420372135937214, disc_loss = 0.08146149515879289
Trained batch 288 in epoch 4, gen_loss = 0.4421602994925423, disc_loss = 0.08129041747167501
Trained batch 289 in epoch 4, gen_loss = 0.44215050452742083, disc_loss = 0.08117440565938837
Trained batch 290 in epoch 4, gen_loss = 0.44201753854341935, disc_loss = 0.0809982734079444
Trained batch 291 in epoch 4, gen_loss = 0.4420474917717176, disc_loss = 0.08075570950622683
Trained batch 292 in epoch 4, gen_loss = 0.44180822504665257, disc_loss = 0.08058422404172935
Trained batch 293 in epoch 4, gen_loss = 0.4417028332851371, disc_loss = 0.08082889838517979
Trained batch 294 in epoch 4, gen_loss = 0.4421090646315429, disc_loss = 0.08094027971343722
Trained batch 295 in epoch 4, gen_loss = 0.4419267746443684, disc_loss = 0.08076478052110336
Trained batch 296 in epoch 4, gen_loss = 0.44211368217612756, disc_loss = 0.08054595537991686
Trained batch 297 in epoch 4, gen_loss = 0.4418852612276205, disc_loss = 0.08033161632397881
Trained batch 298 in epoch 4, gen_loss = 0.44191834848860034, disc_loss = 0.08014209882627213
Trained batch 299 in epoch 4, gen_loss = 0.44204033503929774, disc_loss = 0.0799722228711471
Trained batch 300 in epoch 4, gen_loss = 0.44191134787873176, disc_loss = 0.07987487667775481
Trained batch 301 in epoch 4, gen_loss = 0.44185471761700335, disc_loss = 0.07991439099300233
Trained batch 302 in epoch 4, gen_loss = 0.4421288228467746, disc_loss = 0.07987908660142187
Trained batch 303 in epoch 4, gen_loss = 0.4421667302713582, disc_loss = 0.07968340678857394
Trained batch 304 in epoch 4, gen_loss = 0.44224158085760523, disc_loss = 0.07978159921610209
Trained batch 305 in epoch 4, gen_loss = 0.4423420660051645, disc_loss = 0.0801021580849135
Trained batch 306 in epoch 4, gen_loss = 0.4420660507989629, disc_loss = 0.08014218693186533
Trained batch 307 in epoch 4, gen_loss = 0.4421148527558748, disc_loss = 0.08003948861884268
Trained batch 308 in epoch 4, gen_loss = 0.4424049637271363, disc_loss = 0.0803295530237161
Trained batch 309 in epoch 4, gen_loss = 0.44227272839315473, disc_loss = 0.0802764922455554
Trained batch 310 in epoch 4, gen_loss = 0.4422927920458018, disc_loss = 0.08011089251721068
Trained batch 311 in epoch 4, gen_loss = 0.4422619406802532, disc_loss = 0.07995224085737927
Trained batch 312 in epoch 4, gen_loss = 0.44232800431525743, disc_loss = 0.07985831999008695
Trained batch 313 in epoch 4, gen_loss = 0.4421941447220031, disc_loss = 0.07977408201101527
Trained batch 314 in epoch 4, gen_loss = 0.44206882138100884, disc_loss = 0.0796019135619558
Trained batch 315 in epoch 4, gen_loss = 0.4420959917427618, disc_loss = 0.0794775767408052
Trained batch 316 in epoch 4, gen_loss = 0.44216557566299797, disc_loss = 0.07941841921836655
Trained batch 317 in epoch 4, gen_loss = 0.4421397425093741, disc_loss = 0.07957027775364336
Trained batch 318 in epoch 4, gen_loss = 0.44238133434217924, disc_loss = 0.0794743271471588
Trained batch 319 in epoch 4, gen_loss = 0.4425148324109614, disc_loss = 0.07927036955807125
Trained batch 320 in epoch 4, gen_loss = 0.4424589294882207, disc_loss = 0.07909360833065672
Trained batch 321 in epoch 4, gen_loss = 0.44229022575461346, disc_loss = 0.0791700544712128
Trained batch 322 in epoch 4, gen_loss = 0.44239950133920086, disc_loss = 0.07901785729003165
Trained batch 323 in epoch 4, gen_loss = 0.44256448019065975, disc_loss = 0.07894329247093633
Trained batch 324 in epoch 4, gen_loss = 0.442638914676813, disc_loss = 0.07902397755103616
Trained batch 325 in epoch 4, gen_loss = 0.4427405302327103, disc_loss = 0.07887735431356802
Trained batch 326 in epoch 4, gen_loss = 0.4427635039940522, disc_loss = 0.0788037565149458
Trained batch 327 in epoch 4, gen_loss = 0.44271591696433904, disc_loss = 0.07873498197366688
Trained batch 328 in epoch 4, gen_loss = 0.4428395673315576, disc_loss = 0.0785577279532549
Trained batch 329 in epoch 4, gen_loss = 0.4429515475576574, disc_loss = 0.07839143896955207
Trained batch 330 in epoch 4, gen_loss = 0.4425280485808669, disc_loss = 0.07856546592085518
Trained batch 331 in epoch 4, gen_loss = 0.4427975700741791, disc_loss = 0.07855574268123966
Trained batch 332 in epoch 4, gen_loss = 0.4428562404694142, disc_loss = 0.0783857395774587
Trained batch 333 in epoch 4, gen_loss = 0.44285224021194936, disc_loss = 0.07838968537653054
Trained batch 334 in epoch 4, gen_loss = 0.4427985613915458, disc_loss = 0.07903914689433886
Trained batch 335 in epoch 4, gen_loss = 0.4426251998437302, disc_loss = 0.07945621547904531
Trained batch 336 in epoch 4, gen_loss = 0.4428396659187464, disc_loss = 0.07942867404933278
Trained batch 337 in epoch 4, gen_loss = 0.4427096699116498, disc_loss = 0.07938223975688527
Trained batch 338 in epoch 4, gen_loss = 0.4425061636969755, disc_loss = 0.07976146600453683
Trained batch 339 in epoch 4, gen_loss = 0.44279756230466505, disc_loss = 0.0798911873894908
Trained batch 340 in epoch 4, gen_loss = 0.442836476823102, disc_loss = 0.0796992700079953
Trained batch 341 in epoch 4, gen_loss = 0.44270278278150055, disc_loss = 0.07961385942892069
Trained batch 342 in epoch 4, gen_loss = 0.4426323321400856, disc_loss = 0.07943400026111709
Trained batch 343 in epoch 4, gen_loss = 0.44258399532977927, disc_loss = 0.07933785169802303
Trained batch 344 in epoch 4, gen_loss = 0.44253793998041013, disc_loss = 0.07920956782375772
Trained batch 345 in epoch 4, gen_loss = 0.4424881502727553, disc_loss = 0.07930489877276553
Trained batch 346 in epoch 4, gen_loss = 0.44230067867367, disc_loss = 0.07924575040986498
Trained batch 347 in epoch 4, gen_loss = 0.44235176250509833, disc_loss = 0.07915926050400125
Trained batch 348 in epoch 4, gen_loss = 0.44255276370185154, disc_loss = 0.07903727376833558
Trained batch 349 in epoch 4, gen_loss = 0.4425145993913923, disc_loss = 0.07904627231747977
Trained batch 350 in epoch 4, gen_loss = 0.4426209580185067, disc_loss = 0.07896293132059128
Trained batch 351 in epoch 4, gen_loss = 0.4427725721827962, disc_loss = 0.07879188373309179
Trained batch 352 in epoch 4, gen_loss = 0.44277713926925877, disc_loss = 0.0786081915074912
Trained batch 353 in epoch 4, gen_loss = 0.4426411821343805, disc_loss = 0.0786223891598967
Trained batch 354 in epoch 4, gen_loss = 0.4426696449098453, disc_loss = 0.07861742888983916
Trained batch 355 in epoch 4, gen_loss = 0.4424431324005127, disc_loss = 0.0784942977970173
Trained batch 356 in epoch 4, gen_loss = 0.4422825877906896, disc_loss = 0.07871269062813632
Trained batch 357 in epoch 4, gen_loss = 0.4422876631747411, disc_loss = 0.07866037097582645
Trained batch 358 in epoch 4, gen_loss = 0.4421050588400583, disc_loss = 0.07864445167357585
Trained batch 359 in epoch 4, gen_loss = 0.4424275742636787, disc_loss = 0.07872342121295837
Trained batch 360 in epoch 4, gen_loss = 0.44252240335842247, disc_loss = 0.07874249749097179
Trained batch 361 in epoch 4, gen_loss = 0.44252584759372376, disc_loss = 0.0785666879469745
Trained batch 362 in epoch 4, gen_loss = 0.4426228755433369, disc_loss = 0.07856173324206274
Trained batch 363 in epoch 4, gen_loss = 0.4425487429886074, disc_loss = 0.0784223696337194
Trained batch 364 in epoch 4, gen_loss = 0.44237255429568356, disc_loss = 0.07886003559353212
Trained batch 365 in epoch 4, gen_loss = 0.4420101088090021, disc_loss = 0.07899467591476204
Trained batch 366 in epoch 4, gen_loss = 0.4419691633301145, disc_loss = 0.07928166326708909
Trained batch 367 in epoch 4, gen_loss = 0.4418340435494547, disc_loss = 0.07926902733110498
Trained batch 368 in epoch 4, gen_loss = 0.4415472944577535, disc_loss = 0.07956379352561463
Trained batch 369 in epoch 4, gen_loss = 0.4415855278034468, disc_loss = 0.0794679421465844
Trained batch 370 in epoch 4, gen_loss = 0.4415436321191711, disc_loss = 0.0792869343196426
Trained batch 371 in epoch 4, gen_loss = 0.4414495488488546, disc_loss = 0.0791670408948595
Trained batch 372 in epoch 4, gen_loss = 0.4417769609283826, disc_loss = 0.07917536112876863
Trained batch 373 in epoch 4, gen_loss = 0.4418109276077964, disc_loss = 0.07918695805539541
Trained batch 374 in epoch 4, gen_loss = 0.4417473081747691, disc_loss = 0.07918932931497694
Trained batch 375 in epoch 4, gen_loss = 0.4418859486567213, disc_loss = 0.07907897736158896
Trained batch 376 in epoch 4, gen_loss = 0.4418969970957354, disc_loss = 0.07900739797027856
Trained batch 377 in epoch 4, gen_loss = 0.4420626610517502, disc_loss = 0.07885770602077836
Trained batch 378 in epoch 4, gen_loss = 0.4422736343261749, disc_loss = 0.07874908920323433
Trained batch 379 in epoch 4, gen_loss = 0.44207558757380433, disc_loss = 0.07877396998902489
Trained batch 380 in epoch 4, gen_loss = 0.44221955678594393, disc_loss = 0.07861644641576906
Trained batch 381 in epoch 4, gen_loss = 0.4423011402497117, disc_loss = 0.0787205057528299
Trained batch 382 in epoch 4, gen_loss = 0.442167749137231, disc_loss = 0.0788096032888378
Trained batch 383 in epoch 4, gen_loss = 0.4422393723701437, disc_loss = 0.07876773151292582
Trained batch 384 in epoch 4, gen_loss = 0.4420603584159504, disc_loss = 0.0787396849350786
Trained batch 385 in epoch 4, gen_loss = 0.44206556801351243, disc_loss = 0.07884182981601458
Trained batch 386 in epoch 4, gen_loss = 0.4419814513789283, disc_loss = 0.07889220771050076
Trained batch 387 in epoch 4, gen_loss = 0.44203871465528133, disc_loss = 0.07873937569092959
Trained batch 388 in epoch 4, gen_loss = 0.4421446545571472, disc_loss = 0.07860039562288586
Trained batch 389 in epoch 4, gen_loss = 0.4421572834253311, disc_loss = 0.07865778067244743
Trained batch 390 in epoch 4, gen_loss = 0.4422134809634265, disc_loss = 0.07907629901867198
Trained batch 391 in epoch 4, gen_loss = 0.4420710371769204, disc_loss = 0.07938661495561009
Trained batch 392 in epoch 4, gen_loss = 0.44201514170370027, disc_loss = 0.07933336332246055
Trained batch 393 in epoch 4, gen_loss = 0.44203417184691746, disc_loss = 0.07922281115788607
Trained batch 394 in epoch 4, gen_loss = 0.4418222099165373, disc_loss = 0.07917482597234694
Trained batch 395 in epoch 4, gen_loss = 0.44182007842593723, disc_loss = 0.0789959482987402
Trained batch 396 in epoch 4, gen_loss = 0.44185470558834317, disc_loss = 0.07886654737590805
Trained batch 397 in epoch 4, gen_loss = 0.441800763633982, disc_loss = 0.07879481262798847
Trained batch 398 in epoch 4, gen_loss = 0.44186249659174964, disc_loss = 0.07869315699541143
Trained batch 399 in epoch 4, gen_loss = 0.44196550734341145, disc_loss = 0.0787943331093993
Trained batch 400 in epoch 4, gen_loss = 0.44199509156909667, disc_loss = 0.07899975382195706
Trained batch 401 in epoch 4, gen_loss = 0.44191898583476225, disc_loss = 0.07897558553834719
Trained batch 402 in epoch 4, gen_loss = 0.4419053785558374, disc_loss = 0.07881387335735907
Trained batch 403 in epoch 4, gen_loss = 0.4418170579736776, disc_loss = 0.07870431043009393
Trained batch 404 in epoch 4, gen_loss = 0.4418992046220803, disc_loss = 0.07855078107159999
Trained batch 405 in epoch 4, gen_loss = 0.4418859253522798, disc_loss = 0.07852334424674401
Trained batch 406 in epoch 4, gen_loss = 0.44202011926168305, disc_loss = 0.07848037192735281
Trained batch 407 in epoch 4, gen_loss = 0.44203807406273543, disc_loss = 0.0784026070089335
Trained batch 408 in epoch 4, gen_loss = 0.44201897561987336, disc_loss = 0.07826929894779196
Trained batch 409 in epoch 4, gen_loss = 0.4421568262140925, disc_loss = 0.07830789127477968
Trained batch 410 in epoch 4, gen_loss = 0.4419076383984002, disc_loss = 0.078435823449371
Trained batch 411 in epoch 4, gen_loss = 0.44198257924572937, disc_loss = 0.078493471484568
Trained batch 412 in epoch 4, gen_loss = 0.44187767901085767, disc_loss = 0.07840637403673359
Trained batch 413 in epoch 4, gen_loss = 0.44177959463446614, disc_loss = 0.07849253923857162
Trained batch 414 in epoch 4, gen_loss = 0.4417559541851641, disc_loss = 0.07842987963525826
Trained batch 415 in epoch 4, gen_loss = 0.4418596181158836, disc_loss = 0.0784375700806357
Trained batch 416 in epoch 4, gen_loss = 0.44200175786189894, disc_loss = 0.07831681483230896
Trained batch 417 in epoch 4, gen_loss = 0.44203360728099583, disc_loss = 0.0783033537551422
Trained batch 418 in epoch 4, gen_loss = 0.4423106153426705, disc_loss = 0.07839802237503177
Trained batch 419 in epoch 4, gen_loss = 0.4424073989902224, disc_loss = 0.07832770271426333
Trained batch 420 in epoch 4, gen_loss = 0.44230017611079997, disc_loss = 0.07836397574559703
Trained batch 421 in epoch 4, gen_loss = 0.4424158043770994, disc_loss = 0.07846477657878745
Trained batch 422 in epoch 4, gen_loss = 0.44253025325477546, disc_loss = 0.0783321920432256
Trained batch 423 in epoch 4, gen_loss = 0.44248893259550043, disc_loss = 0.07816971272322402
Trained batch 424 in epoch 4, gen_loss = 0.4423875021934509, disc_loss = 0.07802466566619627
Trained batch 425 in epoch 4, gen_loss = 0.4423658327317574, disc_loss = 0.07786577672942459
Trained batch 426 in epoch 4, gen_loss = 0.4422959307736479, disc_loss = 0.07782610098938228
Trained batch 427 in epoch 4, gen_loss = 0.44212666662218414, disc_loss = 0.0778966261580952
Trained batch 428 in epoch 4, gen_loss = 0.44214119458254125, disc_loss = 0.07788772187749302
Trained batch 429 in epoch 4, gen_loss = 0.4421426127816355, disc_loss = 0.07774694466768482
Trained batch 430 in epoch 4, gen_loss = 0.4419860935957968, disc_loss = 0.0776291113279829
Trained batch 431 in epoch 4, gen_loss = 0.4421354262503209, disc_loss = 0.07752825067210425
Trained batch 432 in epoch 4, gen_loss = 0.44227574762240845, disc_loss = 0.0773910579495304
Trained batch 433 in epoch 4, gen_loss = 0.44215668394543606, disc_loss = 0.07744900717545936
Trained batch 434 in epoch 4, gen_loss = 0.44226158199639154, disc_loss = 0.07762946921625528
Trained batch 435 in epoch 4, gen_loss = 0.4420304971003751, disc_loss = 0.07791319585281399
Trained batch 436 in epoch 4, gen_loss = 0.44218232347981606, disc_loss = 0.0780176562811216
Trained batch 437 in epoch 4, gen_loss = 0.44221630971453507, disc_loss = 0.07797005617901785
Trained batch 438 in epoch 4, gen_loss = 0.4422076666273669, disc_loss = 0.07787873256624865
Trained batch 439 in epoch 4, gen_loss = 0.44213625145229424, disc_loss = 0.07787760101703249
Trained batch 440 in epoch 4, gen_loss = 0.44220785705410703, disc_loss = 0.07782569722865884
Trained batch 441 in epoch 4, gen_loss = 0.442086709503135, disc_loss = 0.07777588946926008
Trained batch 442 in epoch 4, gen_loss = 0.44216116166276265, disc_loss = 0.0778393155693352
Trained batch 443 in epoch 4, gen_loss = 0.4420601505417008, disc_loss = 0.0778547234692703
Trained batch 444 in epoch 4, gen_loss = 0.442324935720208, disc_loss = 0.0778146430776779
Trained batch 445 in epoch 4, gen_loss = 0.4424092582523021, disc_loss = 0.07783625865534717
Trained batch 446 in epoch 4, gen_loss = 0.44252256472372103, disc_loss = 0.07830064688023738
Trained batch 447 in epoch 4, gen_loss = 0.44240514295441763, disc_loss = 0.0784237401021528
Trained batch 448 in epoch 4, gen_loss = 0.4424392187382968, disc_loss = 0.07826932069673338
Trained batch 449 in epoch 4, gen_loss = 0.4424168039692773, disc_loss = 0.07821771778683695
Trained batch 450 in epoch 4, gen_loss = 0.4421279553299204, disc_loss = 0.07816593889704598
Trained batch 451 in epoch 4, gen_loss = 0.4420951276490119, disc_loss = 0.07825834929337314
Trained batch 452 in epoch 4, gen_loss = 0.44209591356860617, disc_loss = 0.07813757612877761
Trained batch 453 in epoch 4, gen_loss = 0.4421688208627281, disc_loss = 0.07827359799906973
Trained batch 454 in epoch 4, gen_loss = 0.44201289873856764, disc_loss = 0.07822584278247022
Trained batch 455 in epoch 4, gen_loss = 0.44191772150888775, disc_loss = 0.07810950664121233
Trained batch 456 in epoch 4, gen_loss = 0.4420074907251729, disc_loss = 0.07806965836814933
Trained batch 457 in epoch 4, gen_loss = 0.44182572295832323, disc_loss = 0.078206684172975
Trained batch 458 in epoch 4, gen_loss = 0.4419699134000766, disc_loss = 0.0781162014334566
Trained batch 459 in epoch 4, gen_loss = 0.44206821024417875, disc_loss = 0.07819324548902881
Trained batch 460 in epoch 4, gen_loss = 0.4419616257808214, disc_loss = 0.07818089605060582
Trained batch 461 in epoch 4, gen_loss = 0.4420394680716775, disc_loss = 0.07827891567540536
Trained batch 462 in epoch 4, gen_loss = 0.4419323072062713, disc_loss = 0.07824787951414483
Trained batch 463 in epoch 4, gen_loss = 0.4420002171577051, disc_loss = 0.07813934682454945
Trained batch 464 in epoch 4, gen_loss = 0.44205684431137576, disc_loss = 0.07804264693911518
Trained batch 465 in epoch 4, gen_loss = 0.44205138739598154, disc_loss = 0.07793330873738447
Trained batch 466 in epoch 4, gen_loss = 0.4420236382928599, disc_loss = 0.07800170362127319
Trained batch 467 in epoch 4, gen_loss = 0.44184571772049636, disc_loss = 0.0784182510085993
Trained batch 468 in epoch 4, gen_loss = 0.4420509963655777, disc_loss = 0.07846018803149049
Trained batch 469 in epoch 4, gen_loss = 0.4420486351276966, disc_loss = 0.07835562830057709
Trained batch 470 in epoch 4, gen_loss = 0.442142928671685, disc_loss = 0.07822806126440059
Trained batch 471 in epoch 4, gen_loss = 0.44201947843371814, disc_loss = 0.0781677296174043
Trained batch 472 in epoch 4, gen_loss = 0.44220054811201437, disc_loss = 0.07857499210297841
Trained batch 473 in epoch 4, gen_loss = 0.44212084430179516, disc_loss = 0.07914653316804282
Trained batch 474 in epoch 4, gen_loss = 0.44204246878623965, disc_loss = 0.07954925966988269
Trained batch 475 in epoch 4, gen_loss = 0.4418790259656786, disc_loss = 0.07988720885067083
Trained batch 476 in epoch 4, gen_loss = 0.4418655546456263, disc_loss = 0.08001407328114477
Trained batch 477 in epoch 4, gen_loss = 0.4418269725648928, disc_loss = 0.08037563033156471
Trained batch 478 in epoch 4, gen_loss = 0.44159403480667164, disc_loss = 0.08078665795030232
Trained batch 479 in epoch 4, gen_loss = 0.4414473584542672, disc_loss = 0.08087347503848528
Trained batch 480 in epoch 4, gen_loss = 0.4415083169441461, disc_loss = 0.08092121115504239
Trained batch 481 in epoch 4, gen_loss = 0.4415540802775577, disc_loss = 0.0808256344407936
Trained batch 482 in epoch 4, gen_loss = 0.4415016582170135, disc_loss = 0.08079855944710643
Trained batch 483 in epoch 4, gen_loss = 0.44149859194174285, disc_loss = 0.08081738438461099
Trained batch 484 in epoch 4, gen_loss = 0.4415329305781532, disc_loss = 0.08096552620325045
Trained batch 485 in epoch 4, gen_loss = 0.44148494413605444, disc_loss = 0.08100754914924103
Trained batch 486 in epoch 4, gen_loss = 0.44141537214206716, disc_loss = 0.08088215830730125
Trained batch 487 in epoch 4, gen_loss = 0.44153422398156805, disc_loss = 0.08081851143973925
Trained batch 488 in epoch 4, gen_loss = 0.44151857470929745, disc_loss = 0.0807936801479897
Trained batch 489 in epoch 4, gen_loss = 0.44156196147811655, disc_loss = 0.08070115831072386
Trained batch 490 in epoch 4, gen_loss = 0.44155789137857754, disc_loss = 0.08061735281273116
Trained batch 491 in epoch 4, gen_loss = 0.4414634744568569, disc_loss = 0.08057383544141108
Trained batch 492 in epoch 4, gen_loss = 0.44153720140457153, disc_loss = 0.08052096911186529
Trained batch 493 in epoch 4, gen_loss = 0.4415130732875121, disc_loss = 0.08051076551865378
Trained batch 494 in epoch 4, gen_loss = 0.44145234624544777, disc_loss = 0.08070526462556286
Trained batch 495 in epoch 4, gen_loss = 0.44134557066905883, disc_loss = 0.08075379199562444
Trained batch 496 in epoch 4, gen_loss = 0.4412994453125077, disc_loss = 0.08062234251165924
Trained batch 497 in epoch 4, gen_loss = 0.4414349398220399, disc_loss = 0.08071293699906683
Trained batch 498 in epoch 4, gen_loss = 0.44127347115763205, disc_loss = 0.080709358375848
Trained batch 499 in epoch 4, gen_loss = 0.441252312541008, disc_loss = 0.08056132314819843
Trained batch 500 in epoch 4, gen_loss = 0.4412902921973588, disc_loss = 0.08046617840478074
Trained batch 501 in epoch 4, gen_loss = 0.44130995180977295, disc_loss = 0.08040111745425696
Trained batch 502 in epoch 4, gen_loss = 0.4413309595575389, disc_loss = 0.08032444280629633
Trained batch 503 in epoch 4, gen_loss = 0.44126133614825824, disc_loss = 0.08027640621950259
Trained batch 504 in epoch 4, gen_loss = 0.4411652905516105, disc_loss = 0.08024177956717586
Trained batch 505 in epoch 4, gen_loss = 0.44121906709058484, disc_loss = 0.08016747252172661
Trained batch 506 in epoch 4, gen_loss = 0.4412231694546912, disc_loss = 0.08011941784162523
Trained batch 507 in epoch 4, gen_loss = 0.44114980488780914, disc_loss = 0.0799860651650664
Trained batch 508 in epoch 4, gen_loss = 0.44114440591724075, disc_loss = 0.07992651896946469
Trained batch 509 in epoch 4, gen_loss = 0.4410950735503552, disc_loss = 0.07980510779181678
Trained batch 510 in epoch 4, gen_loss = 0.4410674829189091, disc_loss = 0.07976493086035266
Trained batch 511 in epoch 4, gen_loss = 0.4410450257710181, disc_loss = 0.0797761882395207
Trained batch 512 in epoch 4, gen_loss = 0.44091942534576845, disc_loss = 0.0797786231163606
Trained batch 513 in epoch 4, gen_loss = 0.44111035764217377, disc_loss = 0.0797577820807072
Trained batch 514 in epoch 4, gen_loss = 0.4411851459336512, disc_loss = 0.07970793785852859
Trained batch 515 in epoch 4, gen_loss = 0.44119037046682, disc_loss = 0.07966472159858158
Trained batch 516 in epoch 4, gen_loss = 0.4412027162786148, disc_loss = 0.07958561384228979
Trained batch 517 in epoch 4, gen_loss = 0.4412037162361918, disc_loss = 0.07946046718403438
Trained batch 518 in epoch 4, gen_loss = 0.44129722322802095, disc_loss = 0.07942874041010907
Trained batch 519 in epoch 4, gen_loss = 0.44152078399291406, disc_loss = 0.07942159365450677
Trained batch 520 in epoch 4, gen_loss = 0.4414886101193712, disc_loss = 0.07929226557586536
Trained batch 521 in epoch 4, gen_loss = 0.4413101428199088, disc_loss = 0.07938432472515351
Trained batch 522 in epoch 4, gen_loss = 0.44149005658084073, disc_loss = 0.07953005871267181
Trained batch 523 in epoch 4, gen_loss = 0.44148766823852337, disc_loss = 0.07941507542672929
Trained batch 524 in epoch 4, gen_loss = 0.4414276213305337, disc_loss = 0.07939350026260529
Trained batch 525 in epoch 4, gen_loss = 0.44150654206711076, disc_loss = 0.079257446145568
Trained batch 526 in epoch 4, gen_loss = 0.44158366311207214, disc_loss = 0.0791684457602817
Trained batch 527 in epoch 4, gen_loss = 0.4416035738293872, disc_loss = 0.07906248833133953
Trained batch 528 in epoch 4, gen_loss = 0.44154073683886536, disc_loss = 0.07898051517668739
Trained batch 529 in epoch 4, gen_loss = 0.44158948249412033, disc_loss = 0.07891313113746637
Trained batch 530 in epoch 4, gen_loss = 0.4415702366335019, disc_loss = 0.07880816612087485
Trained batch 531 in epoch 4, gen_loss = 0.44156166827096077, disc_loss = 0.07888768699380773
Trained batch 532 in epoch 4, gen_loss = 0.4417056637566264, disc_loss = 0.07878772893354409
Trained batch 533 in epoch 4, gen_loss = 0.4418140021379521, disc_loss = 0.07867729597836594
Trained batch 534 in epoch 4, gen_loss = 0.4418487664695098, disc_loss = 0.07858911909633011
Trained batch 535 in epoch 4, gen_loss = 0.44181764531713813, disc_loss = 0.07867239600085695
Trained batch 536 in epoch 4, gen_loss = 0.4419234923921262, disc_loss = 0.07876753203095643
Trained batch 537 in epoch 4, gen_loss = 0.44194092643083693, disc_loss = 0.07863946255819255
Trained batch 538 in epoch 4, gen_loss = 0.4417808265433904, disc_loss = 0.07859279021382304
Trained batch 539 in epoch 4, gen_loss = 0.4417737287503702, disc_loss = 0.07848799165459004
Trained batch 540 in epoch 4, gen_loss = 0.441763620169458, disc_loss = 0.07840737000421075
Trained batch 541 in epoch 4, gen_loss = 0.4418277723432907, disc_loss = 0.0783333941921248
Trained batch 542 in epoch 4, gen_loss = 0.4417613732112266, disc_loss = 0.07836146362753615
Trained batch 543 in epoch 4, gen_loss = 0.4416542535319048, disc_loss = 0.07835544046846575
Trained batch 544 in epoch 4, gen_loss = 0.44174978027649975, disc_loss = 0.07826085751192695
Trained batch 545 in epoch 4, gen_loss = 0.44180663071927573, disc_loss = 0.0783864607302738
Trained batch 546 in epoch 4, gen_loss = 0.44167449825206667, disc_loss = 0.07874888131544812
Trained batch 547 in epoch 4, gen_loss = 0.4415395721031802, disc_loss = 0.078706974900382
Trained batch 548 in epoch 4, gen_loss = 0.4414702796110907, disc_loss = 0.07867436696145894
Trained batch 549 in epoch 4, gen_loss = 0.4415350545536388, disc_loss = 0.07864621031267399
Trained batch 550 in epoch 4, gen_loss = 0.44161221433681064, disc_loss = 0.07877560618659735
Trained batch 551 in epoch 4, gen_loss = 0.4415336724208749, disc_loss = 0.07878267996104273
Trained batch 552 in epoch 4, gen_loss = 0.4414090171429391, disc_loss = 0.07891555962019733
Trained batch 553 in epoch 4, gen_loss = 0.4415281013676406, disc_loss = 0.07932119048872983
Trained batch 554 in epoch 4, gen_loss = 0.44143543662251655, disc_loss = 0.07937805632733412
Trained batch 555 in epoch 4, gen_loss = 0.4412791211184838, disc_loss = 0.0793670901665196
Trained batch 556 in epoch 4, gen_loss = 0.44142979661694975, disc_loss = 0.07933649982123417
Trained batch 557 in epoch 4, gen_loss = 0.4413482084816929, disc_loss = 0.07930997992351678
Trained batch 558 in epoch 4, gen_loss = 0.4413117396916814, disc_loss = 0.07927494133157865
Trained batch 559 in epoch 4, gen_loss = 0.4413575154862234, disc_loss = 0.07922545586562982
Trained batch 560 in epoch 4, gen_loss = 0.4412990126911544, disc_loss = 0.07919823270998297
Trained batch 561 in epoch 4, gen_loss = 0.4412618921638808, disc_loss = 0.07923794656020865
Trained batch 562 in epoch 4, gen_loss = 0.4413287395058898, disc_loss = 0.0792700620938827
Trained batch 563 in epoch 4, gen_loss = 0.4412092965439702, disc_loss = 0.07935502392269592
Trained batch 564 in epoch 4, gen_loss = 0.4412242677359454, disc_loss = 0.07936643415040015
Trained batch 565 in epoch 4, gen_loss = 0.44122251826124564, disc_loss = 0.07972216332584699
Trained batch 566 in epoch 4, gen_loss = 0.44144410189287164, disc_loss = 0.07997428976915895
Trained batch 567 in epoch 4, gen_loss = 0.44150486037554876, disc_loss = 0.07992081959571191
Trained batch 568 in epoch 4, gen_loss = 0.4413527100492655, disc_loss = 0.0799092105589807
Trained batch 569 in epoch 4, gen_loss = 0.44128732472135307, disc_loss = 0.07985767172077637
Trained batch 570 in epoch 4, gen_loss = 0.4411975454845696, disc_loss = 0.0798004145861233
Trained batch 571 in epoch 4, gen_loss = 0.44120038378905585, disc_loss = 0.0797255038002089
Trained batch 572 in epoch 4, gen_loss = 0.44116936969923515, disc_loss = 0.07978227184142715
Trained batch 573 in epoch 4, gen_loss = 0.44116754471632663, disc_loss = 0.07974698074820746
Trained batch 574 in epoch 4, gen_loss = 0.441086244220319, disc_loss = 0.07997193911396291
Trained batch 575 in epoch 4, gen_loss = 0.44124672401489484, disc_loss = 0.08043447938446964
Trained batch 576 in epoch 4, gen_loss = 0.44140691159089684, disc_loss = 0.08042013620234625
Trained batch 577 in epoch 4, gen_loss = 0.44129519432680003, disc_loss = 0.08059430883788088
Trained batch 578 in epoch 4, gen_loss = 0.4412150331523546, disc_loss = 0.08050804353192037
Trained batch 579 in epoch 4, gen_loss = 0.4412511106708954, disc_loss = 0.08053297591475962
Trained batch 580 in epoch 4, gen_loss = 0.4411593034940414, disc_loss = 0.08056999245023742
Trained batch 581 in epoch 4, gen_loss = 0.44107566804615495, disc_loss = 0.08066982347950262
Trained batch 582 in epoch 4, gen_loss = 0.4409866943367554, disc_loss = 0.08060270546828469
Trained batch 583 in epoch 4, gen_loss = 0.4410613847717847, disc_loss = 0.080569842705114
Trained batch 584 in epoch 4, gen_loss = 0.4408927180318751, disc_loss = 0.08058761871762128
Trained batch 585 in epoch 4, gen_loss = 0.4407036660982887, disc_loss = 0.08062655522182914
Trained batch 586 in epoch 4, gen_loss = 0.4406013461353426, disc_loss = 0.08057954127057829
Trained batch 587 in epoch 4, gen_loss = 0.44071110829609594, disc_loss = 0.08054320350983085
Trained batch 588 in epoch 4, gen_loss = 0.44079638407873983, disc_loss = 0.08051220733270757
Trained batch 589 in epoch 4, gen_loss = 0.44089845651287146, disc_loss = 0.08044587700406752
Trained batch 590 in epoch 4, gen_loss = 0.44093137394554927, disc_loss = 0.08042952567953522
Trained batch 591 in epoch 4, gen_loss = 0.44093900400440433, disc_loss = 0.08034497219046603
Trained batch 592 in epoch 4, gen_loss = 0.44098207771677594, disc_loss = 0.08036228442960379
Trained batch 593 in epoch 4, gen_loss = 0.44084523999530456, disc_loss = 0.0802956799865208
Trained batch 594 in epoch 4, gen_loss = 0.44088356224428704, disc_loss = 0.08020026767313355
Trained batch 595 in epoch 4, gen_loss = 0.4408325720453422, disc_loss = 0.080169916167799
Trained batch 596 in epoch 4, gen_loss = 0.441009992081516, disc_loss = 0.08023342298237697
Trained batch 597 in epoch 4, gen_loss = 0.44099025353540144, disc_loss = 0.08027514825531447
Trained batch 598 in epoch 4, gen_loss = 0.4410847402574224, disc_loss = 0.0802698711668746
Testing Epoch 4
Training Epoch 5
------------------------------------------------------------
WARNING    : Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
SOURCE     : matplotlib.image.set_data
TIME STAMP : 2022-09-01 14:33:22,950
------------------------------------------------------------
------------------------------------------------------------
WARNING    : Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
SOURCE     : matplotlib.image.set_data
TIME STAMP : 2022-09-01 14:33:22,956
------------------------------------------------------------
Trained batch 0 in epoch 5, gen_loss = 0.40992018580436707, disc_loss = 0.05865857005119324
Trained batch 1 in epoch 5, gen_loss = 0.40552085638046265, disc_loss = 0.06176390126347542
Trained batch 2 in epoch 5, gen_loss = 0.4211444656054179, disc_loss = 0.07694368312756221
Trained batch 3 in epoch 5, gen_loss = 0.4463535100221634, disc_loss = 0.07603038474917412
Trained batch 4 in epoch 5, gen_loss = 0.44393281936645507, disc_loss = 0.07066819742321968
Trained batch 5 in epoch 5, gen_loss = 0.4392956991990407, disc_loss = 0.06864868849515915
Trained batch 6 in epoch 5, gen_loss = 0.4361739754676819, disc_loss = 0.06784961904798235
Trained batch 7 in epoch 5, gen_loss = 0.4320494942367077, disc_loss = 0.06393864005804062
Trained batch 8 in epoch 5, gen_loss = 0.44258539875348407, disc_loss = 0.06413121687041388
Trained batch 9 in epoch 5, gen_loss = 0.43578422665596006, disc_loss = 0.06409887820482255
Trained batch 10 in epoch 5, gen_loss = 0.4370501122691415, disc_loss = 0.06249597736380317
Trained batch 11 in epoch 5, gen_loss = 0.4404327819744746, disc_loss = 0.06094643659889698
Trained batch 12 in epoch 5, gen_loss = 0.4418758451938629, disc_loss = 0.06478434915726002
Trained batch 13 in epoch 5, gen_loss = 0.444062169109072, disc_loss = 0.06208983143525464
Trained batch 14 in epoch 5, gen_loss = 0.4464308003584544, disc_loss = 0.05928674712777138
Trained batch 15 in epoch 5, gen_loss = 0.4438798055052757, disc_loss = 0.0593182323500514
Trained batch 16 in epoch 5, gen_loss = 0.4428955614566803, disc_loss = 0.06067226739490733
Trained batch 17 in epoch 5, gen_loss = 0.44234030279848313, disc_loss = 0.06027835193607542
Trained batch 18 in epoch 5, gen_loss = 0.441069024173837, disc_loss = 0.06793038547039032
Trained batch 19 in epoch 5, gen_loss = 0.44249454885721207, disc_loss = 0.07116813883185387
Trained batch 20 in epoch 5, gen_loss = 0.44064548185893465, disc_loss = 0.06880394094401882
Trained batch 21 in epoch 5, gen_loss = 0.4392835877158425, disc_loss = 0.0745473989200863
Trained batch 22 in epoch 5, gen_loss = 0.44074944309566333, disc_loss = 0.07431986191026542
Trained batch 23 in epoch 5, gen_loss = 0.44034511720140773, disc_loss = 0.07545002992264926
Trained batch 24 in epoch 5, gen_loss = 0.4355879485607147, disc_loss = 0.07630800195038319
Trained batch 25 in epoch 5, gen_loss = 0.4342424731988173, disc_loss = 0.0751195067826372
Trained batch 26 in epoch 5, gen_loss = 0.43588578701019287, disc_loss = 0.0764908814733779
Trained batch 27 in epoch 5, gen_loss = 0.43612999256168095, disc_loss = 0.07643473594050322
Trained batch 28 in epoch 5, gen_loss = 0.4383801622637387, disc_loss = 0.07430267199103174
Trained batch 29 in epoch 5, gen_loss = 0.4392848362525304, disc_loss = 0.07353629413992166
Trained batch 30 in epoch 5, gen_loss = 0.4372666843475834, disc_loss = 0.07469299333470483
Trained batch 31 in epoch 5, gen_loss = 0.435784718953073, disc_loss = 0.08118867123266682
Trained batch 32 in epoch 5, gen_loss = 0.43906647418484546, disc_loss = 0.08087094190220039
Trained batch 33 in epoch 5, gen_loss = 0.4416211624355877, disc_loss = 0.07935330414158456
Trained batch 34 in epoch 5, gen_loss = 0.43856299434389384, disc_loss = 0.08146770862596375
Trained batch 35 in epoch 5, gen_loss = 0.4357272957762082, disc_loss = 0.08119354407406515
Trained batch 36 in epoch 5, gen_loss = 0.4360877388232463, disc_loss = 0.08042135099704201
Trained batch 37 in epoch 5, gen_loss = 0.4359329640865326, disc_loss = 0.07898571430460403
Trained batch 38 in epoch 5, gen_loss = 0.4363681062673911, disc_loss = 0.0772410115847985
Trained batch 39 in epoch 5, gen_loss = 0.4360811300575733, disc_loss = 0.07604926908388734
Trained batch 40 in epoch 5, gen_loss = 0.4344805907912371, disc_loss = 0.07488429709905531
Trained batch 41 in epoch 5, gen_loss = 0.43518911869752974, disc_loss = 0.07435362537701924
Trained batch 42 in epoch 5, gen_loss = 0.43494783792384833, disc_loss = 0.07526733119820439
Trained batch 43 in epoch 5, gen_loss = 0.43341725726019253, disc_loss = 0.07570351236923174
Trained batch 44 in epoch 5, gen_loss = 0.4339301261636946, disc_loss = 0.07564373761415481
Trained batch 45 in epoch 5, gen_loss = 0.4350863559090573, disc_loss = 0.07754788725920346
Trained batch 46 in epoch 5, gen_loss = 0.43393355544577256, disc_loss = 0.0773236832403122
Trained batch 47 in epoch 5, gen_loss = 0.4362694602459669, disc_loss = 0.0766244566378494
Trained batch 48 in epoch 5, gen_loss = 0.43596944030450313, disc_loss = 0.07620552919652997
Trained batch 49 in epoch 5, gen_loss = 0.4362547487020493, disc_loss = 0.07633332796394825
Trained batch 50 in epoch 5, gen_loss = 0.4359116419857624, disc_loss = 0.07765862090038318
Trained batch 51 in epoch 5, gen_loss = 0.43613241899472016, disc_loss = 0.08117283687282068
Trained batch 52 in epoch 5, gen_loss = 0.435260238512507, disc_loss = 0.08175095472976847
Trained batch 53 in epoch 5, gen_loss = 0.4347984763207259, disc_loss = 0.08076451204855133
Trained batch 54 in epoch 5, gen_loss = 0.4345649713819677, disc_loss = 0.07973602082241665
Trained batch 55 in epoch 5, gen_loss = 0.43526429310441017, disc_loss = 0.07876397895493678
Trained batch 56 in epoch 5, gen_loss = 0.43549254327489617, disc_loss = 0.0781345868058372
Trained batch 57 in epoch 5, gen_loss = 0.43547054714169997, disc_loss = 0.0780396873837915
Trained batch 58 in epoch 5, gen_loss = 0.436108508352506, disc_loss = 0.07721170944051217
Trained batch 59 in epoch 5, gen_loss = 0.43550086617469785, disc_loss = 0.076328188739717
Trained batch 60 in epoch 5, gen_loss = 0.4344683934430607, disc_loss = 0.0766529385305819
Trained batch 61 in epoch 5, gen_loss = 0.4348551755951297, disc_loss = 0.08383500317652379
Trained batch 62 in epoch 5, gen_loss = 0.43546300369595725, disc_loss = 0.08336695934098864
Trained batch 63 in epoch 5, gen_loss = 0.43617154844105244, disc_loss = 0.0827600151533261
Trained batch 64 in epoch 5, gen_loss = 0.4369006798817561, disc_loss = 0.08225588076389753
Trained batch 65 in epoch 5, gen_loss = 0.436556033112786, disc_loss = 0.08192128891294653
Trained batch 66 in epoch 5, gen_loss = 0.4357539753415691, disc_loss = 0.08196457619987317
Trained batch 67 in epoch 5, gen_loss = 0.43556704328340645, disc_loss = 0.08311021656674497
Trained batch 68 in epoch 5, gen_loss = 0.43388907417007117, disc_loss = 0.08254274013249771
Trained batch 69 in epoch 5, gen_loss = 0.4339361582483564, disc_loss = 0.08182430102356843
Trained batch 70 in epoch 5, gen_loss = 0.4329939476201232, disc_loss = 0.08116524440931602
Trained batch 71 in epoch 5, gen_loss = 0.43310896969503826, disc_loss = 0.08048179471451375
Trained batch 72 in epoch 5, gen_loss = 0.4326039303655494, disc_loss = 0.08013385717999445
Trained batch 73 in epoch 5, gen_loss = 0.4327134473903759, disc_loss = 0.082548145305466
Trained batch 74 in epoch 5, gen_loss = 0.4324003374576569, disc_loss = 0.08416411658128102
Trained batch 75 in epoch 5, gen_loss = 0.4321359717532208, disc_loss = 0.08439674365677331
Trained batch 76 in epoch 5, gen_loss = 0.43243951069844233, disc_loss = 0.08415951763654685
Trained batch 77 in epoch 5, gen_loss = 0.4320075985712883, disc_loss = 0.08434803153459842
Trained batch 78 in epoch 5, gen_loss = 0.4325136398967308, disc_loss = 0.0838728501826902
Trained batch 79 in epoch 5, gen_loss = 0.4336400985717773, disc_loss = 0.0836616599932313
Trained batch 80 in epoch 5, gen_loss = 0.4334589356993451, disc_loss = 0.08305705393905993
Trained batch 81 in epoch 5, gen_loss = 0.43427528004820753, disc_loss = 0.0822717733681202
Trained batch 82 in epoch 5, gen_loss = 0.43461750573422536, disc_loss = 0.08236514426857593
Trained batch 83 in epoch 5, gen_loss = 0.43492218532732557, disc_loss = 0.0823170297025215
Trained batch 84 in epoch 5, gen_loss = 0.4348742909291211, disc_loss = 0.08188692616189228
Trained batch 85 in epoch 5, gen_loss = 0.4349796428929928, disc_loss = 0.08196262049293795
Trained batch 86 in epoch 5, gen_loss = 0.4342817198271039, disc_loss = 0.08268057293761735
Trained batch 87 in epoch 5, gen_loss = 0.4351262904026292, disc_loss = 0.08282445993443782
Trained batch 88 in epoch 5, gen_loss = 0.435705645700519, disc_loss = 0.0820856098964643
Trained batch 89 in epoch 5, gen_loss = 0.4370998117658827, disc_loss = 0.08172176107764244
Trained batch 90 in epoch 5, gen_loss = 0.43763078176058257, disc_loss = 0.0814582354256085
Trained batch 91 in epoch 5, gen_loss = 0.43832030114920245, disc_loss = 0.0808843698595529
Trained batch 92 in epoch 5, gen_loss = 0.43888269989721235, disc_loss = 0.08025205728187355
Trained batch 93 in epoch 5, gen_loss = 0.438774011870648, disc_loss = 0.07950087121509491
Trained batch 94 in epoch 5, gen_loss = 0.4392327114155418, disc_loss = 0.07890611926191732
Trained batch 95 in epoch 5, gen_loss = 0.43913441772262257, disc_loss = 0.07843085021401446
Trained batch 96 in epoch 5, gen_loss = 0.43892383022406667, disc_loss = 0.0782817172020981
Trained batch 97 in epoch 5, gen_loss = 0.43858578770744555, disc_loss = 0.0810805887592082
Trained batch 98 in epoch 5, gen_loss = 0.4388189005731332, disc_loss = 0.08048322672645251
Trained batch 99 in epoch 5, gen_loss = 0.43871784567832944, disc_loss = 0.08007073730230331
Trained batch 100 in epoch 5, gen_loss = 0.43865904566084984, disc_loss = 0.07953319436695316
Trained batch 101 in epoch 5, gen_loss = 0.438664593240794, disc_loss = 0.07902377756202922
Trained batch 102 in epoch 5, gen_loss = 0.4387711792894938, disc_loss = 0.07880421539822828
Trained batch 103 in epoch 5, gen_loss = 0.43911749984209353, disc_loss = 0.07834145853009361
Trained batch 104 in epoch 5, gen_loss = 0.4402457345099676, disc_loss = 0.07838876329007603
Trained batch 105 in epoch 5, gen_loss = 0.44020357025119494, disc_loss = 0.077755834011115
Trained batch 106 in epoch 5, gen_loss = 0.4393415679441434, disc_loss = 0.07845383452547487
Trained batch 107 in epoch 5, gen_loss = 0.4401626509648782, disc_loss = 0.07797566665060542
Trained batch 108 in epoch 5, gen_loss = 0.44070282387077264, disc_loss = 0.07814794452433739
Trained batch 109 in epoch 5, gen_loss = 0.4401273545893756, disc_loss = 0.07842952258546244
Trained batch 110 in epoch 5, gen_loss = 0.4394589302776096, disc_loss = 0.07829326802344473
Trained batch 111 in epoch 5, gen_loss = 0.4392939829932792, disc_loss = 0.07861173713380205
Trained batch 112 in epoch 5, gen_loss = 0.4396835518094291, disc_loss = 0.07863895003312985
Trained batch 113 in epoch 5, gen_loss = 0.4394977037843905, disc_loss = 0.07829411924212125
Trained batch 114 in epoch 5, gen_loss = 0.43953445139138597, disc_loss = 0.07791399996241798
Trained batch 115 in epoch 5, gen_loss = 0.4403719627137842, disc_loss = 0.07790844060544824
Trained batch 116 in epoch 5, gen_loss = 0.4398012184179746, disc_loss = 0.07751026687522729
Trained batch 117 in epoch 5, gen_loss = 0.44026026180235006, disc_loss = 0.07695920345515518
Trained batch 118 in epoch 5, gen_loss = 0.4406003563844857, disc_loss = 0.07659496104016024
Trained batch 119 in epoch 5, gen_loss = 0.44080652395884196, disc_loss = 0.07639716854318976
Trained batch 120 in epoch 5, gen_loss = 0.4409579472108321, disc_loss = 0.07702969534953763
Trained batch 121 in epoch 5, gen_loss = 0.44084894803703806, disc_loss = 0.07698651332957823
Trained batch 122 in epoch 5, gen_loss = 0.44046590386367424, disc_loss = 0.07679201435388588
Trained batch 123 in epoch 5, gen_loss = 0.44035158570735683, disc_loss = 0.07755127011407767
Trained batch 124 in epoch 5, gen_loss = 0.44047248363494873, disc_loss = 0.07720414316654205
Trained batch 125 in epoch 5, gen_loss = 0.43947102862691123, disc_loss = 0.07696961457767183
Trained batch 126 in epoch 5, gen_loss = 0.4394057524485851, disc_loss = 0.07659335616301363
Trained batch 127 in epoch 5, gen_loss = 0.4398778462782502, disc_loss = 0.07627850602148101
Trained batch 128 in epoch 5, gen_loss = 0.4392422312913939, disc_loss = 0.07599286726394365
Trained batch 129 in epoch 5, gen_loss = 0.43933152556419375, disc_loss = 0.07546807039672365
Trained batch 130 in epoch 5, gen_loss = 0.4392843935780853, disc_loss = 0.07524650389655628
Trained batch 131 in epoch 5, gen_loss = 0.43914126740260556, disc_loss = 0.07489027257190284
Trained batch 132 in epoch 5, gen_loss = 0.4393168766247599, disc_loss = 0.07442730492247003
Trained batch 133 in epoch 5, gen_loss = 0.4392168710925686, disc_loss = 0.07433242315370868
Trained batch 134 in epoch 5, gen_loss = 0.4394354314715774, disc_loss = 0.0739313548154853
Trained batch 135 in epoch 5, gen_loss = 0.4393022590700318, disc_loss = 0.07465919904986068
Trained batch 136 in epoch 5, gen_loss = 0.4399034224287437, disc_loss = 0.07496947091562252
Trained batch 137 in epoch 5, gen_loss = 0.44024142666139465, disc_loss = 0.07473001967224738
Trained batch 138 in epoch 5, gen_loss = 0.4398638676825187, disc_loss = 0.07466661483183396
Trained batch 139 in epoch 5, gen_loss = 0.43952828070947103, disc_loss = 0.07424554876051843
Trained batch 140 in epoch 5, gen_loss = 0.43950278961912115, disc_loss = 0.07409583616684726
Trained batch 141 in epoch 5, gen_loss = 0.43944402018063505, disc_loss = 0.07367970690157422
Trained batch 142 in epoch 5, gen_loss = 0.4392323402258066, disc_loss = 0.07355501188186707
Trained batch 143 in epoch 5, gen_loss = 0.4401158119241397, disc_loss = 0.07327894122055215
Trained batch 144 in epoch 5, gen_loss = 0.4406671507605191, disc_loss = 0.07289086822420358
Trained batch 145 in epoch 5, gen_loss = 0.4404563134255475, disc_loss = 0.0725528026344127
Trained batch 146 in epoch 5, gen_loss = 0.44041276647120103, disc_loss = 0.07249155651372509
Trained batch 147 in epoch 5, gen_loss = 0.44009475953675603, disc_loss = 0.07214330923995255
Trained batch 148 in epoch 5, gen_loss = 0.44026820671638384, disc_loss = 0.07172470286663547
Trained batch 149 in epoch 5, gen_loss = 0.4405497080087662, disc_loss = 0.07128675041099389
Trained batch 150 in epoch 5, gen_loss = 0.4401250596078026, disc_loss = 0.0711557755357777
Trained batch 151 in epoch 5, gen_loss = 0.43978398391290713, disc_loss = 0.07073294337054617
Trained batch 152 in epoch 5, gen_loss = 0.44010573060683955, disc_loss = 0.07042082968880148
Trained batch 153 in epoch 5, gen_loss = 0.4400973664475726, disc_loss = 0.07022749499550887
Trained batch 154 in epoch 5, gen_loss = 0.4400094134192313, disc_loss = 0.06986824996288746
Trained batch 155 in epoch 5, gen_loss = 0.4402132355249845, disc_loss = 0.06956970274973756
Trained batch 156 in epoch 5, gen_loss = 0.4404945903143306, disc_loss = 0.06944680511714167
Trained batch 157 in epoch 5, gen_loss = 0.4402096426185173, disc_loss = 0.06921655820281822
Trained batch 158 in epoch 5, gen_loss = 0.44059015032630294, disc_loss = 0.06899991489759406
Trained batch 159 in epoch 5, gen_loss = 0.44036042876541615, disc_loss = 0.06868665475631133
Trained batch 160 in epoch 5, gen_loss = 0.4402533084709452, disc_loss = 0.06860695558351389
Trained batch 161 in epoch 5, gen_loss = 0.44079178866044977, disc_loss = 0.06923795198262842
Trained batch 162 in epoch 5, gen_loss = 0.4402750756111613, disc_loss = 0.06939767997003406
Trained batch 163 in epoch 5, gen_loss = 0.43995940467206446, disc_loss = 0.06935576341546527
Trained batch 164 in epoch 5, gen_loss = 0.43984623605554757, disc_loss = 0.07002230423192184
Trained batch 165 in epoch 5, gen_loss = 0.43955840260149487, disc_loss = 0.06991055294736681
Trained batch 166 in epoch 5, gen_loss = 0.43965200000180454, disc_loss = 0.07124725672343891
Trained batch 167 in epoch 5, gen_loss = 0.4401327364501499, disc_loss = 0.0710468506551392
Trained batch 168 in epoch 5, gen_loss = 0.44083974911616397, disc_loss = 0.07113382856212777
Trained batch 169 in epoch 5, gen_loss = 0.44073065624517554, disc_loss = 0.07088782098144293
Trained batch 170 in epoch 5, gen_loss = 0.44019120286779795, disc_loss = 0.07071089492947386
Trained batch 171 in epoch 5, gen_loss = 0.4404412970639939, disc_loss = 0.07051802778529913
Trained batch 172 in epoch 5, gen_loss = 0.440270935352138, disc_loss = 0.07042203696089329
Trained batch 173 in epoch 5, gen_loss = 0.439893022522159, disc_loss = 0.07054855587795891
Trained batch 174 in epoch 5, gen_loss = 0.4398579398223332, disc_loss = 0.07026117161980697
Trained batch 175 in epoch 5, gen_loss = 0.44018312865360215, disc_loss = 0.06996839099817655
Trained batch 176 in epoch 5, gen_loss = 0.4402096500504488, disc_loss = 0.0698189385193216
Trained batch 177 in epoch 5, gen_loss = 0.44039498252815074, disc_loss = 0.06956239872392309
Trained batch 178 in epoch 5, gen_loss = 0.44052775462246474, disc_loss = 0.06943936730271943
Trained batch 179 in epoch 5, gen_loss = 0.44010816630389954, disc_loss = 0.06917708575104674
Trained batch 180 in epoch 5, gen_loss = 0.43970257570730387, disc_loss = 0.06980828546728547
Trained batch 181 in epoch 5, gen_loss = 0.43958367325447417, disc_loss = 0.07008446541174755
Trained batch 182 in epoch 5, gen_loss = 0.4398316563478584, disc_loss = 0.06978626709044632
Trained batch 183 in epoch 5, gen_loss = 0.4395264651140441, disc_loss = 0.07021163368557135
Trained batch 184 in epoch 5, gen_loss = 0.4397471416640926, disc_loss = 0.07120456982504678
Trained batch 185 in epoch 5, gen_loss = 0.4393315255962392, disc_loss = 0.07151977186121287
Trained batch 186 in epoch 5, gen_loss = 0.43911168074862844, disc_loss = 0.0718026250142624
Trained batch 187 in epoch 5, gen_loss = 0.4390782671088868, disc_loss = 0.07167822066100037
Trained batch 188 in epoch 5, gen_loss = 0.4390317663629219, disc_loss = 0.07154213578967505
Trained batch 189 in epoch 5, gen_loss = 0.43891072932042574, disc_loss = 0.07141939575146687
Trained batch 190 in epoch 5, gen_loss = 0.43870925965733554, disc_loss = 0.0715342442266136
Trained batch 191 in epoch 5, gen_loss = 0.4388394371295969, disc_loss = 0.07128314912552014
Trained batch 192 in epoch 5, gen_loss = 0.43846989542709114, disc_loss = 0.07112716931676
Trained batch 193 in epoch 5, gen_loss = 0.43841357237284945, disc_loss = 0.07079110795046328
Trained batch 194 in epoch 5, gen_loss = 0.4385356809848394, disc_loss = 0.07064275118068625
Trained batch 195 in epoch 5, gen_loss = 0.4384246102097083, disc_loss = 0.07096843911116296
Trained batch 196 in epoch 5, gen_loss = 0.43866643022159635, disc_loss = 0.07094423381403693
Trained batch 197 in epoch 5, gen_loss = 0.4390472920254023, disc_loss = 0.07096876365113815
Trained batch 198 in epoch 5, gen_loss = 0.4389117114507972, disc_loss = 0.07073013224503279
Trained batch 199 in epoch 5, gen_loss = 0.4386706928908825, disc_loss = 0.07069204898783937
Trained batch 200 in epoch 5, gen_loss = 0.438749025413646, disc_loss = 0.07043273173578417
Trained batch 201 in epoch 5, gen_loss = 0.4387842890354666, disc_loss = 0.0704107160361871
Trained batch 202 in epoch 5, gen_loss = 0.4390648985143953, disc_loss = 0.07039432316844173
Trained batch 203 in epoch 5, gen_loss = 0.43925129563785065, disc_loss = 0.07013642737030179
Trained batch 204 in epoch 5, gen_loss = 0.43939108296138485, disc_loss = 0.069962214626281
Trained batch 205 in epoch 5, gen_loss = 0.43914015330735917, disc_loss = 0.0697416771605647
Trained batch 206 in epoch 5, gen_loss = 0.43935138663807927, disc_loss = 0.06985500918539322
Trained batch 207 in epoch 5, gen_loss = 0.4394476634378617, disc_loss = 0.07019741391951147
Trained batch 208 in epoch 5, gen_loss = 0.43960185455933715, disc_loss = 0.07014529862659472
Trained batch 209 in epoch 5, gen_loss = 0.4394397924343745, disc_loss = 0.06996830404913497
Trained batch 210 in epoch 5, gen_loss = 0.43955426052283336, disc_loss = 0.06980007584317106
Trained batch 211 in epoch 5, gen_loss = 0.4395721897764026, disc_loss = 0.06969014206628825
Trained batch 212 in epoch 5, gen_loss = 0.43964826668931845, disc_loss = 0.0696142924962644
Trained batch 213 in epoch 5, gen_loss = 0.43953006805103517, disc_loss = 0.06965098374470999
Trained batch 214 in epoch 5, gen_loss = 0.43983020103254983, disc_loss = 0.06945582331309831
Trained batch 215 in epoch 5, gen_loss = 0.43968010417841097, disc_loss = 0.06940617796283698
Trained batch 216 in epoch 5, gen_loss = 0.43982952709571554, disc_loss = 0.06923200670106139
Trained batch 217 in epoch 5, gen_loss = 0.43956356652832906, disc_loss = 0.06920598860223427
Trained batch 218 in epoch 5, gen_loss = 0.440065925932366, disc_loss = 0.06966679916848943
Trained batch 219 in epoch 5, gen_loss = 0.44013769721443, disc_loss = 0.06977122455877675
Trained batch 220 in epoch 5, gen_loss = 0.4402427781221554, disc_loss = 0.0696449229489523
Trained batch 221 in epoch 5, gen_loss = 0.4401982022566838, disc_loss = 0.06940539248564558
Trained batch 222 in epoch 5, gen_loss = 0.44016304131046, disc_loss = 0.06915781666804523
Trained batch 223 in epoch 5, gen_loss = 0.4399912105873227, disc_loss = 0.06909225638082717
Trained batch 224 in epoch 5, gen_loss = 0.4400764256053501, disc_loss = 0.06885960777393646
Trained batch 225 in epoch 5, gen_loss = 0.4403951463446153, disc_loss = 0.0689102108940581
Trained batch 226 in epoch 5, gen_loss = 0.44026751560261596, disc_loss = 0.06864810870582902
Trained batch 227 in epoch 5, gen_loss = 0.440215779762519, disc_loss = 0.06873693481586024
Trained batch 228 in epoch 5, gen_loss = 0.4402282444931014, disc_loss = 0.06857979975388626
Trained batch 229 in epoch 5, gen_loss = 0.44049454629421236, disc_loss = 0.06872607191984097
Trained batch 230 in epoch 5, gen_loss = 0.44087723155558367, disc_loss = 0.06853769022318257
Trained batch 231 in epoch 5, gen_loss = 0.44116308116193476, disc_loss = 0.0685334434222976
Trained batch 232 in epoch 5, gen_loss = 0.44086166832580076, disc_loss = 0.06841299271354924
Trained batch 233 in epoch 5, gen_loss = 0.44067717579185456, disc_loss = 0.06834330047783242
Trained batch 234 in epoch 5, gen_loss = 0.4405489925374376, disc_loss = 0.06810131667657418
Trained batch 235 in epoch 5, gen_loss = 0.440605360698902, disc_loss = 0.06790690206314863
Trained batch 236 in epoch 5, gen_loss = 0.44046571511256544, disc_loss = 0.0680880794942159
Trained batch 237 in epoch 5, gen_loss = 0.44088341258153196, disc_loss = 0.06839048324207611
Trained batch 238 in epoch 5, gen_loss = 0.4408272822781088, disc_loss = 0.06850536735182838
Trained batch 239 in epoch 5, gen_loss = 0.4408911269158125, disc_loss = 0.0684162030792019
Trained batch 240 in epoch 5, gen_loss = 0.4410420552328909, disc_loss = 0.06842883804782113
Trained batch 241 in epoch 5, gen_loss = 0.44088643247430975, disc_loss = 0.06862022335379392
Trained batch 242 in epoch 5, gen_loss = 0.44097635505621324, disc_loss = 0.06844776412165521
Trained batch 243 in epoch 5, gen_loss = 0.4412250814379239, disc_loss = 0.06830724649566425
Trained batch 244 in epoch 5, gen_loss = 0.4413209416428391, disc_loss = 0.06811503593296725
Trained batch 245 in epoch 5, gen_loss = 0.4413766178900633, disc_loss = 0.06793941614384634
Trained batch 246 in epoch 5, gen_loss = 0.4417589040179002, disc_loss = 0.06779704186575193
Trained batch 247 in epoch 5, gen_loss = 0.44174739393976425, disc_loss = 0.06758849015797398
Trained batch 248 in epoch 5, gen_loss = 0.4417058783602044, disc_loss = 0.0674142805152539
Trained batch 249 in epoch 5, gen_loss = 0.4415320372581482, disc_loss = 0.06719828260876239
Trained batch 250 in epoch 5, gen_loss = 0.4415198562154732, disc_loss = 0.06702147884502176
Trained batch 251 in epoch 5, gen_loss = 0.44166165755854714, disc_loss = 0.06685608822209317
Trained batch 252 in epoch 5, gen_loss = 0.441659795201343, disc_loss = 0.06667046032647193
Trained batch 253 in epoch 5, gen_loss = 0.4415455364336179, disc_loss = 0.06655922925327061
Trained batch 254 in epoch 5, gen_loss = 0.4417334430357989, disc_loss = 0.0665897999926671
Trained batch 255 in epoch 5, gen_loss = 0.441885604057461, disc_loss = 0.0664459956697101
Trained batch 256 in epoch 5, gen_loss = 0.44193224150846905, disc_loss = 0.06624140065156127
Trained batch 257 in epoch 5, gen_loss = 0.44205268697683203, disc_loss = 0.06602641895175153
Trained batch 258 in epoch 5, gen_loss = 0.44199345321268646, disc_loss = 0.06651701851348792
Trained batch 259 in epoch 5, gen_loss = 0.4414753055343261, disc_loss = 0.06732452106124794
Trained batch 260 in epoch 5, gen_loss = 0.4414410398152596, disc_loss = 0.06716241357648224
Trained batch 261 in epoch 5, gen_loss = 0.4414168688404651, disc_loss = 0.06702757209987302
Trained batch 262 in epoch 5, gen_loss = 0.4415714736220501, disc_loss = 0.06698563931325713
Trained batch 263 in epoch 5, gen_loss = 0.4416400007903576, disc_loss = 0.06701547523896972
Trained batch 264 in epoch 5, gen_loss = 0.44179938480539144, disc_loss = 0.06702170575670195
Trained batch 265 in epoch 5, gen_loss = 0.4418603072040959, disc_loss = 0.06702797250521082
Trained batch 266 in epoch 5, gen_loss = 0.4418976692001471, disc_loss = 0.06696515587378252
Trained batch 267 in epoch 5, gen_loss = 0.44174437602954125, disc_loss = 0.06674670655134399
Trained batch 268 in epoch 5, gen_loss = 0.4418026266488001, disc_loss = 0.06676464682084865
Trained batch 269 in epoch 5, gen_loss = 0.44182262575184855, disc_loss = 0.06673264258403193
Trained batch 270 in epoch 5, gen_loss = 0.4421652579659465, disc_loss = 0.06653711922652332
Trained batch 271 in epoch 5, gen_loss = 0.442164616768851, disc_loss = 0.06638263409566957
Trained batch 272 in epoch 5, gen_loss = 0.442047302212034, disc_loss = 0.06651610760836975
Trained batch 273 in epoch 5, gen_loss = 0.4421133032462893, disc_loss = 0.066332395166417
Trained batch 274 in epoch 5, gen_loss = 0.4422112659974532, disc_loss = 0.06612985861403022
Trained batch 275 in epoch 5, gen_loss = 0.44230066466590634, disc_loss = 0.06610735671668974
Trained batch 276 in epoch 5, gen_loss = 0.4424849403248797, disc_loss = 0.06650253144405541
Trained batch 277 in epoch 5, gen_loss = 0.44249488563417533, disc_loss = 0.06633069499382388
Trained batch 278 in epoch 5, gen_loss = 0.44247988047992887, disc_loss = 0.06634332898396691
Trained batch 279 in epoch 5, gen_loss = 0.44245403483510015, disc_loss = 0.06616936769569293
Trained batch 280 in epoch 5, gen_loss = 0.4427172799339498, disc_loss = 0.0662148396444782
Trained batch 281 in epoch 5, gen_loss = 0.4430754492257504, disc_loss = 0.06637219093072869
Trained batch 282 in epoch 5, gen_loss = 0.4427976086998997, disc_loss = 0.0666106302380009
Trained batch 283 in epoch 5, gen_loss = 0.442608618505404, disc_loss = 0.06703627803920388
Trained batch 284 in epoch 5, gen_loss = 0.44264851735349287, disc_loss = 0.06747149209933061
Trained batch 285 in epoch 5, gen_loss = 0.44292343715270915, disc_loss = 0.06737344268338194
Trained batch 286 in epoch 5, gen_loss = 0.44281051964709983, disc_loss = 0.06736484322314011
Trained batch 287 in epoch 5, gen_loss = 0.4426617950407995, disc_loss = 0.06722259407494373
Trained batch 288 in epoch 5, gen_loss = 0.4425490373764896, disc_loss = 0.06727086285863935
Trained batch 289 in epoch 5, gen_loss = 0.44275761832451, disc_loss = 0.06728335356757302
Trained batch 290 in epoch 5, gen_loss = 0.44246607752600076, disc_loss = 0.06723534654909137
Trained batch 291 in epoch 5, gen_loss = 0.44256138076929197, disc_loss = 0.06706233068579834
Trained batch 292 in epoch 5, gen_loss = 0.44247366004836436, disc_loss = 0.06695153948027678
Trained batch 293 in epoch 5, gen_loss = 0.44256679186610137, disc_loss = 0.06728449260949024
Trained batch 294 in epoch 5, gen_loss = 0.44229481189937914, disc_loss = 0.06743809328083013
Trained batch 295 in epoch 5, gen_loss = 0.4422145078109728, disc_loss = 0.06738134857260848
Trained batch 296 in epoch 5, gen_loss = 0.44252783270797347, disc_loss = 0.06739829388926878
Trained batch 297 in epoch 5, gen_loss = 0.44255764382397567, disc_loss = 0.06724357297300243
Trained batch 298 in epoch 5, gen_loss = 0.44243915573410364, disc_loss = 0.0672014192428851
Trained batch 299 in epoch 5, gen_loss = 0.44224420696496963, disc_loss = 0.06714057888680448
Trained batch 300 in epoch 5, gen_loss = 0.4420439785105049, disc_loss = 0.06697789869701298
Trained batch 301 in epoch 5, gen_loss = 0.4418275382937185, disc_loss = 0.06678990379981203
Trained batch 302 in epoch 5, gen_loss = 0.44190698773554055, disc_loss = 0.0666203986432268
Trained batch 303 in epoch 5, gen_loss = 0.44168941598189504, disc_loss = 0.06674730373197235
Trained batch 304 in epoch 5, gen_loss = 0.4417648883139501, disc_loss = 0.06688333388082073
Trained batch 305 in epoch 5, gen_loss = 0.44149093242252574, disc_loss = 0.06677258511232151
Trained batch 306 in epoch 5, gen_loss = 0.4414981478394437, disc_loss = 0.06679526417810433
Trained batch 307 in epoch 5, gen_loss = 0.4416772801574175, disc_loss = 0.06675590198432615
Trained batch 308 in epoch 5, gen_loss = 0.4415973964053836, disc_loss = 0.06669282101691493
Trained batch 309 in epoch 5, gen_loss = 0.4415615051984787, disc_loss = 0.06663230199577107
Trained batch 310 in epoch 5, gen_loss = 0.4414164185332332, disc_loss = 0.0665213930318761
Trained batch 311 in epoch 5, gen_loss = 0.4412966170945229, disc_loss = 0.0664090931472273
Trained batch 312 in epoch 5, gen_loss = 0.4412142113565256, disc_loss = 0.06648832189288145
Trained batch 313 in epoch 5, gen_loss = 0.4411753150308208, disc_loss = 0.06632083568241519
Trained batch 314 in epoch 5, gen_loss = 0.4412596723390004, disc_loss = 0.06620387185867581
Trained batch 315 in epoch 5, gen_loss = 0.4411330567319182, disc_loss = 0.06621298428972641
Trained batch 316 in epoch 5, gen_loss = 0.4414234199922544, disc_loss = 0.06650783670831131
Trained batch 317 in epoch 5, gen_loss = 0.44130833053363944, disc_loss = 0.06635811368923096
Trained batch 318 in epoch 5, gen_loss = 0.4411104303729198, disc_loss = 0.06669666285722933
Trained batch 319 in epoch 5, gen_loss = 0.4413661797530949, disc_loss = 0.06666592628898797
Trained batch 320 in epoch 5, gen_loss = 0.4414082260518059, disc_loss = 0.06660329742426767
Trained batch 321 in epoch 5, gen_loss = 0.4412129153005825, disc_loss = 0.06670101624855668
Trained batch 322 in epoch 5, gen_loss = 0.44123825624631285, disc_loss = 0.06673382570240474
Trained batch 323 in epoch 5, gen_loss = 0.441104717184732, disc_loss = 0.06660726733568964
Trained batch 324 in epoch 5, gen_loss = 0.44101089257460374, disc_loss = 0.06669994696258352
Trained batch 325 in epoch 5, gen_loss = 0.44116682966062626, disc_loss = 0.06673644202407107
Trained batch 326 in epoch 5, gen_loss = 0.4412379246603823, disc_loss = 0.06656759484480235
Trained batch 327 in epoch 5, gen_loss = 0.4412334096140978, disc_loss = 0.06642232789720477
Trained batch 328 in epoch 5, gen_loss = 0.4411513461168052, disc_loss = 0.06624972417039122
Trained batch 329 in epoch 5, gen_loss = 0.4412343285300515, disc_loss = 0.06619513146438157
Trained batch 330 in epoch 5, gen_loss = 0.4410595238388845, disc_loss = 0.06633685593242866
Trained batch 331 in epoch 5, gen_loss = 0.4407843779548105, disc_loss = 0.06658513055053955
Trained batch 332 in epoch 5, gen_loss = 0.4408121933271219, disc_loss = 0.06654771941912559
Trained batch 333 in epoch 5, gen_loss = 0.44062645554899454, disc_loss = 0.06643923304969455
Trained batch 334 in epoch 5, gen_loss = 0.4404820670832449, disc_loss = 0.06636607840295826
Trained batch 335 in epoch 5, gen_loss = 0.4404240830668381, disc_loss = 0.06668992972395028
Trained batch 336 in epoch 5, gen_loss = 0.44053823277575327, disc_loss = 0.06744037513159636
Trained batch 337 in epoch 5, gen_loss = 0.44055984896668315, disc_loss = 0.06757841664697072
Trained batch 338 in epoch 5, gen_loss = 0.4405441947039601, disc_loss = 0.06806088148706914
Trained batch 339 in epoch 5, gen_loss = 0.44023864558514425, disc_loss = 0.06795701630933977
Trained batch 340 in epoch 5, gen_loss = 0.44028076546982237, disc_loss = 0.06794781835279988
Trained batch 341 in epoch 5, gen_loss = 0.4403186622593138, disc_loss = 0.06786706376880712
Trained batch 342 in epoch 5, gen_loss = 0.4402864882966867, disc_loss = 0.06790227171321435
Trained batch 343 in epoch 5, gen_loss = 0.4401960807830788, disc_loss = 0.06778947108961252
Trained batch 344 in epoch 5, gen_loss = 0.4401932459810506, disc_loss = 0.06770267076115462
Trained batch 345 in epoch 5, gen_loss = 0.44021067410879744, disc_loss = 0.06758823563247876
Trained batch 346 in epoch 5, gen_loss = 0.4402123745477165, disc_loss = 0.0674532967947037
Trained batch 347 in epoch 5, gen_loss = 0.44006081105306233, disc_loss = 0.06747281947306989
Trained batch 348 in epoch 5, gen_loss = 0.44012565061151127, disc_loss = 0.0673078082750063
Trained batch 349 in epoch 5, gen_loss = 0.4405601647070476, disc_loss = 0.06747724382073751
Trained batch 350 in epoch 5, gen_loss = 0.4402680003914738, disc_loss = 0.06759311785348333
Trained batch 351 in epoch 5, gen_loss = 0.4402779648080468, disc_loss = 0.06745660617360211
Trained batch 352 in epoch 5, gen_loss = 0.44016041456808785, disc_loss = 0.06734888535388679
Trained batch 353 in epoch 5, gen_loss = 0.4403447777369602, disc_loss = 0.06735586399333499
Trained batch 354 in epoch 5, gen_loss = 0.4403435610549551, disc_loss = 0.0672227081816486
Trained batch 355 in epoch 5, gen_loss = 0.4403753408722663, disc_loss = 0.0672204753271503
Trained batch 356 in epoch 5, gen_loss = 0.44020742303183097, disc_loss = 0.06722124673410498
Trained batch 357 in epoch 5, gen_loss = 0.4402476266109744, disc_loss = 0.06718401741054346
Trained batch 358 in epoch 5, gen_loss = 0.4402028269920509, disc_loss = 0.0671321519749099
Trained batch 359 in epoch 5, gen_loss = 0.4400689414805836, disc_loss = 0.06697966234060004
Trained batch 360 in epoch 5, gen_loss = 0.4401910017732108, disc_loss = 0.06683618322123162
Trained batch 361 in epoch 5, gen_loss = 0.4400963520641485, disc_loss = 0.06670654335223879
Trained batch 362 in epoch 5, gen_loss = 0.44021053969367474, disc_loss = 0.06663522655503522
Trained batch 363 in epoch 5, gen_loss = 0.44020878351651704, disc_loss = 0.06650556584149804
Trained batch 364 in epoch 5, gen_loss = 0.44018717114239525, disc_loss = 0.06635218206410334
Trained batch 365 in epoch 5, gen_loss = 0.4402991828045558, disc_loss = 0.0662033779208187
Trained batch 366 in epoch 5, gen_loss = 0.4403042478197602, disc_loss = 0.06612113996583978
Trained batch 367 in epoch 5, gen_loss = 0.44023340681324835, disc_loss = 0.06622802461472178
Trained batch 368 in epoch 5, gen_loss = 0.4404952385561253, disc_loss = 0.06628656493711883
Trained batch 369 in epoch 5, gen_loss = 0.4404864982978718, disc_loss = 0.06614720563001528
Trained batch 370 in epoch 5, gen_loss = 0.4404297023609963, disc_loss = 0.06606735894958567
Trained batch 371 in epoch 5, gen_loss = 0.4406872560740799, disc_loss = 0.06601705926255153
Trained batch 372 in epoch 5, gen_loss = 0.44071419213476515, disc_loss = 0.06595103969378022
Trained batch 373 in epoch 5, gen_loss = 0.44079392415316987, disc_loss = 0.06602101182729445
Trained batch 374 in epoch 5, gen_loss = 0.4407682983080546, disc_loss = 0.06586475883920988
Trained batch 375 in epoch 5, gen_loss = 0.4405374899506569, disc_loss = 0.06577109326014018
Trained batch 376 in epoch 5, gen_loss = 0.44044540170333113, disc_loss = 0.06566164620833308
Trained batch 377 in epoch 5, gen_loss = 0.44057110716741554, disc_loss = 0.06565917521794007
Trained batch 378 in epoch 5, gen_loss = 0.4406795213121852, disc_loss = 0.06566195134908984
Trained batch 379 in epoch 5, gen_loss = 0.4407525513517229, disc_loss = 0.06556815149164513
Trained batch 380 in epoch 5, gen_loss = 0.44080217342989964, disc_loss = 0.06546473657599897
Trained batch 381 in epoch 5, gen_loss = 0.4407140195993853, disc_loss = 0.06544748378712781
Trained batch 382 in epoch 5, gen_loss = 0.44073769706970095, disc_loss = 0.06531327634359231
Trained batch 383 in epoch 5, gen_loss = 0.4408092903904617, disc_loss = 0.06530996790631131
Trained batch 384 in epoch 5, gen_loss = 0.4408696563986989, disc_loss = 0.06525870126418092
Trained batch 385 in epoch 5, gen_loss = 0.44105242146420354, disc_loss = 0.06520832225998835
Trained batch 386 in epoch 5, gen_loss = 0.441117128198461, disc_loss = 0.06527893074116735
Trained batch 387 in epoch 5, gen_loss = 0.440743108385617, disc_loss = 0.06554162243294731
Trained batch 388 in epoch 5, gen_loss = 0.44069466048463757, disc_loss = 0.06611473872003105
Trained batch 389 in epoch 5, gen_loss = 0.440478367683215, disc_loss = 0.06630165873286434
Trained batch 390 in epoch 5, gen_loss = 0.4406164081962517, disc_loss = 0.06622886824685975
Trained batch 391 in epoch 5, gen_loss = 0.4406388801123415, disc_loss = 0.06622967560423956
Trained batch 392 in epoch 5, gen_loss = 0.44059223353711097, disc_loss = 0.06620281185177522
Trained batch 393 in epoch 5, gen_loss = 0.440440902023146, disc_loss = 0.06630089734610038
Trained batch 394 in epoch 5, gen_loss = 0.4402951054180725, disc_loss = 0.06651613621064756
Trained batch 395 in epoch 5, gen_loss = 0.4401039546637824, disc_loss = 0.06657337471889803
Trained batch 396 in epoch 5, gen_loss = 0.4400985552471891, disc_loss = 0.06661418060858919
Trained batch 397 in epoch 5, gen_loss = 0.44025613487365856, disc_loss = 0.06650543783150202
Trained batch 398 in epoch 5, gen_loss = 0.4404722060027875, disc_loss = 0.06639252855841603
Trained batch 399 in epoch 5, gen_loss = 0.4404133126139641, disc_loss = 0.06660683224676177
Trained batch 400 in epoch 5, gen_loss = 0.44029245999388567, disc_loss = 0.06667066483231182
Trained batch 401 in epoch 5, gen_loss = 0.4403880173294105, disc_loss = 0.06660199310602759
Trained batch 402 in epoch 5, gen_loss = 0.44031554408759693, disc_loss = 0.06655487232141326
Trained batch 403 in epoch 5, gen_loss = 0.4405487053612671, disc_loss = 0.0665816247606152
Trained batch 404 in epoch 5, gen_loss = 0.44048644480881866, disc_loss = 0.06654560255737585
Trained batch 405 in epoch 5, gen_loss = 0.4407261516073067, disc_loss = 0.0664594118630174
Trained batch 406 in epoch 5, gen_loss = 0.4407528238302367, disc_loss = 0.06650580223009027
Trained batch 407 in epoch 5, gen_loss = 0.44104023401935893, disc_loss = 0.06650864335425272
Trained batch 408 in epoch 5, gen_loss = 0.44098046917495637, disc_loss = 0.06641045903381698
Trained batch 409 in epoch 5, gen_loss = 0.44098195033829385, disc_loss = 0.06656128947918372
Trained batch 410 in epoch 5, gen_loss = 0.4407276187064874, disc_loss = 0.06688277146251025
Trained batch 411 in epoch 5, gen_loss = 0.4406915652086434, disc_loss = 0.06678295585561941
Trained batch 412 in epoch 5, gen_loss = 0.44085316096610655, disc_loss = 0.06667022242213061
Trained batch 413 in epoch 5, gen_loss = 0.44077757727984646, disc_loss = 0.06672379652776075
Trained batch 414 in epoch 5, gen_loss = 0.44064493344490785, disc_loss = 0.06701938216630594
Trained batch 415 in epoch 5, gen_loss = 0.4408188642074282, disc_loss = 0.06720552064451532
Trained batch 416 in epoch 5, gen_loss = 0.4406926863485103, disc_loss = 0.06711139874555153
Trained batch 417 in epoch 5, gen_loss = 0.4405881155050542, disc_loss = 0.0671598268873348
Trained batch 418 in epoch 5, gen_loss = 0.4406924463968573, disc_loss = 0.06738611173578193
Trained batch 419 in epoch 5, gen_loss = 0.44053573466482615, disc_loss = 0.06728310160826714
Trained batch 420 in epoch 5, gen_loss = 0.4404655618509034, disc_loss = 0.067312375045074
Trained batch 421 in epoch 5, gen_loss = 0.4404121080846018, disc_loss = 0.06724917474401435
Trained batch 422 in epoch 5, gen_loss = 0.44027246326983116, disc_loss = 0.06716162775451621
Trained batch 423 in epoch 5, gen_loss = 0.4402190729413392, disc_loss = 0.06712099374491581
Trained batch 424 in epoch 5, gen_loss = 0.44032886568237756, disc_loss = 0.06703164838473587
Trained batch 425 in epoch 5, gen_loss = 0.4403279676263881, disc_loss = 0.06693286753255227
Trained batch 426 in epoch 5, gen_loss = 0.440526188327222, disc_loss = 0.06688316114273019
Trained batch 427 in epoch 5, gen_loss = 0.44045100890308897, disc_loss = 0.06684318456633417
Trained batch 428 in epoch 5, gen_loss = 0.44038308514303814, disc_loss = 0.06677513496867774
Trained batch 429 in epoch 5, gen_loss = 0.44033858720646346, disc_loss = 0.06666745142578039
Trained batch 430 in epoch 5, gen_loss = 0.44057653439847055, disc_loss = 0.06662238080901571
Trained batch 431 in epoch 5, gen_loss = 0.4406584528171354, disc_loss = 0.06658508677975516
Trained batch 432 in epoch 5, gen_loss = 0.44065076271050524, disc_loss = 0.06654315145243192
Trained batch 433 in epoch 5, gen_loss = 0.4405338262907371, disc_loss = 0.06656500131690077
Trained batch 434 in epoch 5, gen_loss = 0.44063861685237665, disc_loss = 0.06644637005125312
Trained batch 435 in epoch 5, gen_loss = 0.44062584788974274, disc_loss = 0.06637287087131873
Trained batch 436 in epoch 5, gen_loss = 0.44067110997588466, disc_loss = 0.06627294820364675
Trained batch 437 in epoch 5, gen_loss = 0.4405653958451258, disc_loss = 0.0661599064632808
Trained batch 438 in epoch 5, gen_loss = 0.44056970980824534, disc_loss = 0.06606837071622626
Trained batch 439 in epoch 5, gen_loss = 0.44072896892374214, disc_loss = 0.06595721178984439
Trained batch 440 in epoch 5, gen_loss = 0.44074903769828294, disc_loss = 0.06585775937699204
Trained batch 441 in epoch 5, gen_loss = 0.4406592266052557, disc_loss = 0.06596805713438678
Trained batch 442 in epoch 5, gen_loss = 0.44074408006991006, disc_loss = 0.0658401122493312
Trained batch 443 in epoch 5, gen_loss = 0.44075770548603554, disc_loss = 0.06572523987684231
Trained batch 444 in epoch 5, gen_loss = 0.44079287420497854, disc_loss = 0.06560639093598623
Trained batch 445 in epoch 5, gen_loss = 0.44069992694084953, disc_loss = 0.06552754612764837
Trained batch 446 in epoch 5, gen_loss = 0.4406517760065578, disc_loss = 0.06560688803776665
Trained batch 447 in epoch 5, gen_loss = 0.4405849336513451, disc_loss = 0.06567127356954318
Trained batch 448 in epoch 5, gen_loss = 0.4407445238799454, disc_loss = 0.06554908370536924
Trained batch 449 in epoch 5, gen_loss = 0.4407660500208537, disc_loss = 0.06557486195117235
Trained batch 450 in epoch 5, gen_loss = 0.44066476379159814, disc_loss = 0.06550859718969683
Trained batch 451 in epoch 5, gen_loss = 0.44089151477128, disc_loss = 0.06541262621439137
Trained batch 452 in epoch 5, gen_loss = 0.4409152238442671, disc_loss = 0.06536876560737755
Trained batch 453 in epoch 5, gen_loss = 0.44082999091579, disc_loss = 0.0653102216823642
Trained batch 454 in epoch 5, gen_loss = 0.4409546516098819, disc_loss = 0.0652168048115877
Trained batch 455 in epoch 5, gen_loss = 0.44118628775080043, disc_loss = 0.06513295735624668
Trained batch 456 in epoch 5, gen_loss = 0.4412334651993975, disc_loss = 0.06506546434724227
Trained batch 457 in epoch 5, gen_loss = 0.44122879207134247, disc_loss = 0.06500974504529258
Trained batch 458 in epoch 5, gen_loss = 0.4411975474529017, disc_loss = 0.06489446916067587
Trained batch 459 in epoch 5, gen_loss = 0.441327025125856, disc_loss = 0.06480485671604781
Trained batch 460 in epoch 5, gen_loss = 0.4413337987441561, disc_loss = 0.06475410123361747
Trained batch 461 in epoch 5, gen_loss = 0.4413784520450609, disc_loss = 0.06471365906531999
Trained batch 462 in epoch 5, gen_loss = 0.44150299632008594, disc_loss = 0.06459691441068768
Trained batch 463 in epoch 5, gen_loss = 0.4416538830204257, disc_loss = 0.064497753496057
Trained batch 464 in epoch 5, gen_loss = 0.4416582204321379, disc_loss = 0.06438099886941653
Trained batch 465 in epoch 5, gen_loss = 0.44165978762980695, disc_loss = 0.0643037467307607
Trained batch 466 in epoch 5, gen_loss = 0.44164549500324485, disc_loss = 0.06419076387445409
Trained batch 467 in epoch 5, gen_loss = 0.441786018319619, disc_loss = 0.0640749073961479
Trained batch 468 in epoch 5, gen_loss = 0.4418645175154021, disc_loss = 0.06397983660973085
Trained batch 469 in epoch 5, gen_loss = 0.4418411541492381, disc_loss = 0.06387812388624917
Trained batch 470 in epoch 5, gen_loss = 0.4420446251101808, disc_loss = 0.06377010602867844
Trained batch 471 in epoch 5, gen_loss = 0.4421036694261987, disc_loss = 0.06367361294776518
Trained batch 472 in epoch 5, gen_loss = 0.4423030367865371, disc_loss = 0.06356996148391518
Trained batch 473 in epoch 5, gen_loss = 0.4424995186459666, disc_loss = 0.06349762603994223
Trained batch 474 in epoch 5, gen_loss = 0.4424284690304806, disc_loss = 0.06340877630796872
Trained batch 475 in epoch 5, gen_loss = 0.442483512168171, disc_loss = 0.06331921650386345
Trained batch 476 in epoch 5, gen_loss = 0.4425559066376596, disc_loss = 0.06325393503402951
Trained batch 477 in epoch 5, gen_loss = 0.4426056503875485, disc_loss = 0.06315218513854877
Trained batch 478 in epoch 5, gen_loss = 0.4427198412398456, disc_loss = 0.06304972205458827
Trained batch 479 in epoch 5, gen_loss = 0.44296408041069907, disc_loss = 0.06293340505314214
Trained batch 480 in epoch 5, gen_loss = 0.4430264782880795, disc_loss = 0.0628436297602301
Trained batch 481 in epoch 5, gen_loss = 0.44315635607697657, disc_loss = 0.06274760529472342
Trained batch 482 in epoch 5, gen_loss = 0.44299603156421496, disc_loss = 0.06274003712421834
Trained batch 483 in epoch 5, gen_loss = 0.44304276005295684, disc_loss = 0.0627300999779639
Trained batch 484 in epoch 5, gen_loss = 0.44306546781480927, disc_loss = 0.06262260488301669
Trained batch 485 in epoch 5, gen_loss = 0.44323950098375237, disc_loss = 0.06256897515548324
Trained batch 486 in epoch 5, gen_loss = 0.44320707705476203, disc_loss = 0.06246206257970396
Trained batch 487 in epoch 5, gen_loss = 0.44306160637834036, disc_loss = 0.0623881805441953
Trained batch 488 in epoch 5, gen_loss = 0.4431416141231123, disc_loss = 0.06228818689855787
Trained batch 489 in epoch 5, gen_loss = 0.4433434221209312, disc_loss = 0.06218507374180671
Trained batch 490 in epoch 5, gen_loss = 0.4433088424006693, disc_loss = 0.06209479499126494
Trained batch 491 in epoch 5, gen_loss = 0.4433037692574951, disc_loss = 0.06206156241393277
Trained batch 492 in epoch 5, gen_loss = 0.44336745505642455, disc_loss = 0.06195467736092198
Trained batch 493 in epoch 5, gen_loss = 0.4433121414561021, disc_loss = 0.06187912432556059
Trained batch 494 in epoch 5, gen_loss = 0.4431920927582365, disc_loss = 0.06178301282208225
Trained batch 495 in epoch 5, gen_loss = 0.4431151555430505, disc_loss = 0.06171221178186487
Trained batch 496 in epoch 5, gen_loss = 0.44310519656904745, disc_loss = 0.061668635504339
Trained batch 497 in epoch 5, gen_loss = 0.4430788332319643, disc_loss = 0.06162460736582527
Trained batch 498 in epoch 5, gen_loss = 0.44311071654598794, disc_loss = 0.06162390248282609
Trained batch 499 in epoch 5, gen_loss = 0.4429594948887825, disc_loss = 0.06173370146285743
Trained batch 500 in epoch 5, gen_loss = 0.44300688580124675, disc_loss = 0.06167295059382529
Trained batch 501 in epoch 5, gen_loss = 0.44312553428321244, disc_loss = 0.061643249992526086
Trained batch 502 in epoch 5, gen_loss = 0.44305175892401405, disc_loss = 0.06178188481262587
Trained batch 503 in epoch 5, gen_loss = 0.4431943234115366, disc_loss = 0.06203619840403368
Trained batch 504 in epoch 5, gen_loss = 0.4431371969751792, disc_loss = 0.062003122221235885
Trained batch 505 in epoch 5, gen_loss = 0.4430732668152911, disc_loss = 0.06192204444816432
Trained batch 506 in epoch 5, gen_loss = 0.44307324349057275, disc_loss = 0.06214514724759631
Trained batch 507 in epoch 5, gen_loss = 0.44329953058732774, disc_loss = 0.0621520447330256
Trained batch 508 in epoch 5, gen_loss = 0.44340004322570997, disc_loss = 0.06210658604403581
Trained batch 509 in epoch 5, gen_loss = 0.44335938242136264, disc_loss = 0.06222899072876602
Trained batch 510 in epoch 5, gen_loss = 0.44322621746539137, disc_loss = 0.062136862686709475
Trained batch 511 in epoch 5, gen_loss = 0.44311859022127464, disc_loss = 0.06212124653120554
Trained batch 512 in epoch 5, gen_loss = 0.44331552823152226, disc_loss = 0.06229166445171653
Trained batch 513 in epoch 5, gen_loss = 0.44337960677620036, disc_loss = 0.06220739584593719
Trained batch 514 in epoch 5, gen_loss = 0.4432707248382198, disc_loss = 0.06213326880672169
Trained batch 515 in epoch 5, gen_loss = 0.44317338921765026, disc_loss = 0.062079538718450726
Trained batch 516 in epoch 5, gen_loss = 0.4430958692063677, disc_loss = 0.062048183207362315
Trained batch 517 in epoch 5, gen_loss = 0.44304355415138036, disc_loss = 0.061966680483820646
Trained batch 518 in epoch 5, gen_loss = 0.4431114464366597, disc_loss = 0.06194528228619454
Trained batch 519 in epoch 5, gen_loss = 0.4431467608763621, disc_loss = 0.06213022350566462
Trained batch 520 in epoch 5, gen_loss = 0.44312075449729377, disc_loss = 0.06227990456243652
Trained batch 521 in epoch 5, gen_loss = 0.4429925367864156, disc_loss = 0.0622738691883597
Trained batch 522 in epoch 5, gen_loss = 0.4432578612809883, disc_loss = 0.06301085296644336
Trained batch 523 in epoch 5, gen_loss = 0.44308483907739626, disc_loss = 0.063177440419459
Trained batch 524 in epoch 5, gen_loss = 0.44307676672935487, disc_loss = 0.06311310471257284
Trained batch 525 in epoch 5, gen_loss = 0.44300478577840463, disc_loss = 0.06336408942502289
Trained batch 526 in epoch 5, gen_loss = 0.44285603339803287, disc_loss = 0.06349634435434297
Trained batch 527 in epoch 5, gen_loss = 0.4426604529673403, disc_loss = 0.06342757327894849
Trained batch 528 in epoch 5, gen_loss = 0.44278336810705116, disc_loss = 0.06349270165209538
Trained batch 529 in epoch 5, gen_loss = 0.442689005215213, disc_loss = 0.06354029032155731
Trained batch 530 in epoch 5, gen_loss = 0.4425676877552507, disc_loss = 0.06372680732271793
Trained batch 531 in epoch 5, gen_loss = 0.4424922424263524, disc_loss = 0.06382158157482211
Trained batch 532 in epoch 5, gen_loss = 0.4422742586310317, disc_loss = 0.06415099788747211
Trained batch 533 in epoch 5, gen_loss = 0.44224993287400804, disc_loss = 0.0641419061953167
Trained batch 534 in epoch 5, gen_loss = 0.44213619454998837, disc_loss = 0.06412467984134489
Trained batch 535 in epoch 5, gen_loss = 0.44209741300611355, disc_loss = 0.06415545117238593
Trained batch 536 in epoch 5, gen_loss = 0.44204731277247383, disc_loss = 0.06418323648392849
Trained batch 537 in epoch 5, gen_loss = 0.4419697531426263, disc_loss = 0.06426266635955072
Trained batch 538 in epoch 5, gen_loss = 0.4418722876591231, disc_loss = 0.06422515079147546
Trained batch 539 in epoch 5, gen_loss = 0.4418196933688941, disc_loss = 0.06428661344797108
Trained batch 540 in epoch 5, gen_loss = 0.4416760576961221, disc_loss = 0.06426779629469827
Trained batch 541 in epoch 5, gen_loss = 0.4415191724841445, disc_loss = 0.06449615519332297
Trained batch 542 in epoch 5, gen_loss = 0.441410045048589, disc_loss = 0.06450444620195261
Trained batch 543 in epoch 5, gen_loss = 0.4415567463592571, disc_loss = 0.06454400401579573
Trained batch 544 in epoch 5, gen_loss = 0.44146531235187425, disc_loss = 0.06455472993211599
Trained batch 545 in epoch 5, gen_loss = 0.44140955631112877, disc_loss = 0.06451993202023044
Trained batch 546 in epoch 5, gen_loss = 0.44143502950886265, disc_loss = 0.06459070829048044
Trained batch 547 in epoch 5, gen_loss = 0.441372858564349, disc_loss = 0.0645927758793938
Trained batch 548 in epoch 5, gen_loss = 0.4412434435498736, disc_loss = 0.0645201200210508
Trained batch 549 in epoch 5, gen_loss = 0.44127786993980406, disc_loss = 0.06448426274836741
Trained batch 550 in epoch 5, gen_loss = 0.4412508738343815, disc_loss = 0.06445050302186403
Trained batch 551 in epoch 5, gen_loss = 0.4412583370247613, disc_loss = 0.064607314256769
Trained batch 552 in epoch 5, gen_loss = 0.4412089774880228, disc_loss = 0.06470576412790534
Trained batch 553 in epoch 5, gen_loss = 0.44130860656392273, disc_loss = 0.06486153461809005
Trained batch 554 in epoch 5, gen_loss = 0.4412344702192255, disc_loss = 0.06484207875170821
Trained batch 555 in epoch 5, gen_loss = 0.44125725752372535, disc_loss = 0.06486152961143299
Trained batch 556 in epoch 5, gen_loss = 0.4412656197963112, disc_loss = 0.06483306336221645
Trained batch 557 in epoch 5, gen_loss = 0.4412776347663667, disc_loss = 0.06481039539183153
Trained batch 558 in epoch 5, gen_loss = 0.4411419849169702, disc_loss = 0.06473921414394739
Trained batch 559 in epoch 5, gen_loss = 0.44133447190480574, disc_loss = 0.06465641253245329
Trained batch 560 in epoch 5, gen_loss = 0.44141258811993184, disc_loss = 0.06459117642024435
Trained batch 561 in epoch 5, gen_loss = 0.44145678694350016, disc_loss = 0.06449769987903695
Trained batch 562 in epoch 5, gen_loss = 0.4414923156662902, disc_loss = 0.06441700582675385
Trained batch 563 in epoch 5, gen_loss = 0.4415638435182842, disc_loss = 0.06431992216190945
Trained batch 564 in epoch 5, gen_loss = 0.44157953293977587, disc_loss = 0.06432403082324736
Trained batch 565 in epoch 5, gen_loss = 0.44158453086239713, disc_loss = 0.06429612528871706
Trained batch 566 in epoch 5, gen_loss = 0.44166195255948965, disc_loss = 0.06425561393468232
Trained batch 567 in epoch 5, gen_loss = 0.44159222336512216, disc_loss = 0.06423563252672107
Trained batch 568 in epoch 5, gen_loss = 0.4415949712947718, disc_loss = 0.06416120933637233
Trained batch 569 in epoch 5, gen_loss = 0.4414295731929311, disc_loss = 0.06410434775691676
Trained batch 570 in epoch 5, gen_loss = 0.4415658765624158, disc_loss = 0.06404846038542127
Trained batch 571 in epoch 5, gen_loss = 0.44167309582650244, disc_loss = 0.0639625849890998
Trained batch 572 in epoch 5, gen_loss = 0.441842413281479, disc_loss = 0.06387260305511572
Trained batch 573 in epoch 5, gen_loss = 0.4418160274676745, disc_loss = 0.06378205992583225
Trained batch 574 in epoch 5, gen_loss = 0.441788032003071, disc_loss = 0.06371106523939449
Trained batch 575 in epoch 5, gen_loss = 0.4417302390663988, disc_loss = 0.06365405275412034
Trained batch 576 in epoch 5, gen_loss = 0.44176199877282774, disc_loss = 0.06356789618552997
Trained batch 577 in epoch 5, gen_loss = 0.4417029867741476, disc_loss = 0.06348764066984007
Trained batch 578 in epoch 5, gen_loss = 0.44178021123989875, disc_loss = 0.06339911503447075
Trained batch 579 in epoch 5, gen_loss = 0.44186640839124547, disc_loss = 0.0633053183130085
Trained batch 580 in epoch 5, gen_loss = 0.44180693576134833, disc_loss = 0.06326167835820332
Trained batch 581 in epoch 5, gen_loss = 0.4419686938171944, disc_loss = 0.06320162632989079
Trained batch 582 in epoch 5, gen_loss = 0.4419869815301323, disc_loss = 0.06313791750542065
Trained batch 583 in epoch 5, gen_loss = 0.44199211359636426, disc_loss = 0.06306344153892172
Trained batch 584 in epoch 5, gen_loss = 0.4420729655995328, disc_loss = 0.06298227794388803
Trained batch 585 in epoch 5, gen_loss = 0.4420672041767693, disc_loss = 0.06291289045475423
Trained batch 586 in epoch 5, gen_loss = 0.44202569716021395, disc_loss = 0.0628154556238405
Trained batch 587 in epoch 5, gen_loss = 0.4421188339185553, disc_loss = 0.06274476741063631
Trained batch 588 in epoch 5, gen_loss = 0.4421716723053484, disc_loss = 0.0626992421099799
Trained batch 589 in epoch 5, gen_loss = 0.4421436719975229, disc_loss = 0.06261356986222505
Trained batch 590 in epoch 5, gen_loss = 0.4421467153251474, disc_loss = 0.06253733447092615
Trained batch 591 in epoch 5, gen_loss = 0.4420731123536825, disc_loss = 0.06246811173135742
Trained batch 592 in epoch 5, gen_loss = 0.4420424378641942, disc_loss = 0.062373909499326606
Trained batch 593 in epoch 5, gen_loss = 0.4420753691834633, disc_loss = 0.06227710095989935
Trained batch 594 in epoch 5, gen_loss = 0.44209318506617507, disc_loss = 0.0621840295217493
Trained batch 595 in epoch 5, gen_loss = 0.4421042325912706, disc_loss = 0.06233115162194125
Trained batch 596 in epoch 5, gen_loss = 0.44211191513031173, disc_loss = 0.062400052138296906
Trained batch 597 in epoch 5, gen_loss = 0.44212102242138074, disc_loss = 0.0623276382201915
Trained batch 598 in epoch 5, gen_loss = 0.4423231174034348, disc_loss = 0.06238525688107155
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 0.41147786378860474, disc_loss = 0.017821410670876503
Trained batch 1 in epoch 6, gen_loss = 0.40387552976608276, disc_loss = 0.059949723072350025
Trained batch 2 in epoch 6, gen_loss = 0.4309396743774414, disc_loss = 0.05178249689439932
Trained batch 3 in epoch 6, gen_loss = 0.4293707236647606, disc_loss = 0.07332024956122041
Trained batch 4 in epoch 6, gen_loss = 0.41347508430480956, disc_loss = 0.07787198908627033
Trained batch 5 in epoch 6, gen_loss = 0.40349751710891724, disc_loss = 0.0743863449121515
Trained batch 6 in epoch 6, gen_loss = 0.4135682923453195, disc_loss = 0.07363482165549483
Trained batch 7 in epoch 6, gen_loss = 0.42317240685224533, disc_loss = 0.06786504457704723
Trained batch 8 in epoch 6, gen_loss = 0.4245214131143358, disc_loss = 0.06364697073068884
Trained batch 9 in epoch 6, gen_loss = 0.4307039350271225, disc_loss = 0.06241439078003168
Trained batch 10 in epoch 6, gen_loss = 0.4295187131925063, disc_loss = 0.060372328724373474
Trained batch 11 in epoch 6, gen_loss = 0.43139786769946414, disc_loss = 0.05727882885063688
Trained batch 12 in epoch 6, gen_loss = 0.43345677623381984, disc_loss = 0.05334929108189849
Trained batch 13 in epoch 6, gen_loss = 0.4333547183445522, disc_loss = 0.05068185862286815
Trained batch 14 in epoch 6, gen_loss = 0.4341551144917806, disc_loss = 0.04813830259566506
Trained batch 15 in epoch 6, gen_loss = 0.43361165188252926, disc_loss = 0.04697743317228742
Trained batch 16 in epoch 6, gen_loss = 0.435465041328879, disc_loss = 0.04501385929282097
Trained batch 17 in epoch 6, gen_loss = 0.43648402724001145, disc_loss = 0.04449082939471635
Trained batch 18 in epoch 6, gen_loss = 0.43698124979671676, disc_loss = 0.042764883856044
Trained batch 19 in epoch 6, gen_loss = 0.43744237422943116, disc_loss = 0.0414585450431332
Trained batch 20 in epoch 6, gen_loss = 0.4352401750428336, disc_loss = 0.03967689403465816
Trained batch 21 in epoch 6, gen_loss = 0.433060269464146, disc_loss = 0.03816709424030374
Trained batch 22 in epoch 6, gen_loss = 0.434074632499529, disc_loss = 0.03740402013468354
Trained batch 23 in epoch 6, gen_loss = 0.4352964870631695, disc_loss = 0.036880532066182546
Trained batch 24 in epoch 6, gen_loss = 0.4350757014751434, disc_loss = 0.03596585603430867
Trained batch 25 in epoch 6, gen_loss = 0.43646960992079514, disc_loss = 0.037231753956383236
Trained batch 26 in epoch 6, gen_loss = 0.4374176793628269, disc_loss = 0.03670556810512035
Trained batch 27 in epoch 6, gen_loss = 0.43766957202128004, disc_loss = 0.03568963974248618
Trained batch 28 in epoch 6, gen_loss = 0.4370667564457861, disc_loss = 0.034735885625383975
Trained batch 29 in epoch 6, gen_loss = 0.4382199952999751, disc_loss = 0.03420776800873379
Trained batch 30 in epoch 6, gen_loss = 0.43954866643874874, disc_loss = 0.033506076106981884
Trained batch 31 in epoch 6, gen_loss = 0.4408780066296458, disc_loss = 0.03311451546323951
Trained batch 32 in epoch 6, gen_loss = 0.4391205527565696, disc_loss = 0.03250654347974694
Trained batch 33 in epoch 6, gen_loss = 0.43777641916976257, disc_loss = 0.0319145085865303
Trained batch 34 in epoch 6, gen_loss = 0.43861879365784784, disc_loss = 0.0325771985974695
Trained batch 35 in epoch 6, gen_loss = 0.43735407210058636, disc_loss = 0.0338669115703346
Trained batch 36 in epoch 6, gen_loss = 0.43759064658268076, disc_loss = 0.03410057941250302
Trained batch 37 in epoch 6, gen_loss = 0.43649376536670487, disc_loss = 0.033518810646216333
Trained batch 38 in epoch 6, gen_loss = 0.4383712135828458, disc_loss = 0.03317273578916987
Trained batch 39 in epoch 6, gen_loss = 0.4378151401877403, disc_loss = 0.03260319413384423
Trained batch 40 in epoch 6, gen_loss = 0.43911681742202946, disc_loss = 0.03196223444736949
Trained batch 41 in epoch 6, gen_loss = 0.43952547084717525, disc_loss = 0.03138659085102734
Trained batch 42 in epoch 6, gen_loss = 0.4390633785447409, disc_loss = 0.031181950446997963
Trained batch 43 in epoch 6, gen_loss = 0.43912411616607144, disc_loss = 0.030685300028628924
Trained batch 44 in epoch 6, gen_loss = 0.4377496957778931, disc_loss = 0.03043296376450194
Trained batch 45 in epoch 6, gen_loss = 0.43846897456956946, disc_loss = 0.029913672387761915
Trained batch 46 in epoch 6, gen_loss = 0.4395648222020332, disc_loss = 0.029670193335635864
Trained batch 47 in epoch 6, gen_loss = 0.44031778164207935, disc_loss = 0.029161534058706213
Trained batch 48 in epoch 6, gen_loss = 0.4398659242659199, disc_loss = 0.02899170596608702
Trained batch 49 in epoch 6, gen_loss = 0.43825744211673734, disc_loss = 0.028505156775936485
Trained batch 50 in epoch 6, gen_loss = 0.4361947494394639, disc_loss = 0.02843324203665058
Trained batch 51 in epoch 6, gen_loss = 0.43595528316039306, disc_loss = 0.027998539968393743
Trained batch 52 in epoch 6, gen_loss = 0.43631932701704634, disc_loss = 0.0280931928581646
Trained batch 53 in epoch 6, gen_loss = 0.4343581514226066, disc_loss = 0.02804129186983186
Trained batch 54 in epoch 6, gen_loss = 0.4342204045165669, disc_loss = 0.028140746624293653
Trained batch 55 in epoch 6, gen_loss = 0.4343781316918986, disc_loss = 0.028898508046820228
Trained batch 56 in epoch 6, gen_loss = 0.43382224440574646, disc_loss = 0.028535491713371715
Trained batch 57 in epoch 6, gen_loss = 0.4340096635037455, disc_loss = 0.02839033752840398
Trained batch 58 in epoch 6, gen_loss = 0.43492854449708584, disc_loss = 0.028258524464159194
Trained batch 59 in epoch 6, gen_loss = 0.4361169308423996, disc_loss = 0.028939456127894423
Trained batch 60 in epoch 6, gen_loss = 0.43711966764731486, disc_loss = 0.028788476640389103
Trained batch 61 in epoch 6, gen_loss = 0.437874176329182, disc_loss = 0.029478170646114216
Trained batch 62 in epoch 6, gen_loss = 0.4380014392118605, disc_loss = 0.029973310913654076
Trained batch 63 in epoch 6, gen_loss = 0.43838692875579, disc_loss = 0.029625279508763924
Trained batch 64 in epoch 6, gen_loss = 0.4382710410998418, disc_loss = 0.029848159247866043
Trained batch 65 in epoch 6, gen_loss = 0.439535834572532, disc_loss = 0.029783350923521953
Trained batch 66 in epoch 6, gen_loss = 0.4403383135795593, disc_loss = 0.030086341661526197
Trained batch 67 in epoch 6, gen_loss = 0.44008604217978087, disc_loss = 0.029990274952176738
Trained batch 68 in epoch 6, gen_loss = 0.43943519868712494, disc_loss = 0.02984902673009513
Trained batch 69 in epoch 6, gen_loss = 0.43956726917198724, disc_loss = 0.029625030287674495
Trained batch 70 in epoch 6, gen_loss = 0.440835778562116, disc_loss = 0.030106439242060756
Trained batch 71 in epoch 6, gen_loss = 0.44093221550186473, disc_loss = 0.02979650385936515
Trained batch 72 in epoch 6, gen_loss = 0.44086894025541334, disc_loss = 0.029472138464757023
Trained batch 73 in epoch 6, gen_loss = 0.4412701774287868, disc_loss = 0.030033643672091735
Trained batch 74 in epoch 6, gen_loss = 0.44210326035817465, disc_loss = 0.030121644424895445
Trained batch 75 in epoch 6, gen_loss = 0.44131216093113546, disc_loss = 0.03127233810281675
Trained batch 76 in epoch 6, gen_loss = 0.44243376673042, disc_loss = 0.03179525989168263
Trained batch 77 in epoch 6, gen_loss = 0.4419514181522223, disc_loss = 0.0323626552708447
Trained batch 78 in epoch 6, gen_loss = 0.44273351076283035, disc_loss = 0.033472910983181454
Trained batch 79 in epoch 6, gen_loss = 0.44194215051829816, disc_loss = 0.03383448667591438
Trained batch 80 in epoch 6, gen_loss = 0.4420384061925205, disc_loss = 0.03386347873113406
Trained batch 81 in epoch 6, gen_loss = 0.441797418201842, disc_loss = 0.033644705227144606
Trained batch 82 in epoch 6, gen_loss = 0.4428964540900954, disc_loss = 0.0357561387368534
Trained batch 83 in epoch 6, gen_loss = 0.4423561135218257, disc_loss = 0.0375273032003038
Trained batch 84 in epoch 6, gen_loss = 0.44301756760653327, disc_loss = 0.03837570963317857
Trained batch 85 in epoch 6, gen_loss = 0.442390161198239, disc_loss = 0.039229450216733436
Trained batch 86 in epoch 6, gen_loss = 0.44323527059335815, disc_loss = 0.039150962788055
Trained batch 87 in epoch 6, gen_loss = 0.4424925727600401, disc_loss = 0.03968597693495791
Trained batch 88 in epoch 6, gen_loss = 0.44264387314239245, disc_loss = 0.03943884141450183
Trained batch 89 in epoch 6, gen_loss = 0.4434851265615887, disc_loss = 0.039561524438775246
Trained batch 90 in epoch 6, gen_loss = 0.4439080567150326, disc_loss = 0.03922025855262201
Trained batch 91 in epoch 6, gen_loss = 0.4432900748823, disc_loss = 0.04043732903411855
Trained batch 92 in epoch 6, gen_loss = 0.4429630714078103, disc_loss = 0.04269683292956762
Trained batch 93 in epoch 6, gen_loss = 0.4428208308651092, disc_loss = 0.0424051286375269
Trained batch 94 in epoch 6, gen_loss = 0.4426332922358262, disc_loss = 0.042187835942757754
Trained batch 95 in epoch 6, gen_loss = 0.4436807883903384, disc_loss = 0.041850679457032434
Trained batch 96 in epoch 6, gen_loss = 0.44422562742970656, disc_loss = 0.04151808881421679
Trained batch 97 in epoch 6, gen_loss = 0.44363147628550625, disc_loss = 0.04126435850879976
Trained batch 98 in epoch 6, gen_loss = 0.443236821528637, disc_loss = 0.040894889084603446
Trained batch 99 in epoch 6, gen_loss = 0.4432766446471214, disc_loss = 0.04072520273737609
Trained batch 100 in epoch 6, gen_loss = 0.4434160905899388, disc_loss = 0.0405670666956518
Trained batch 101 in epoch 6, gen_loss = 0.4432632563745274, disc_loss = 0.040239852428545844
Trained batch 102 in epoch 6, gen_loss = 0.4433107156198002, disc_loss = 0.040092441275969004
Trained batch 103 in epoch 6, gen_loss = 0.4434059176307458, disc_loss = 0.039783045931611784
Trained batch 104 in epoch 6, gen_loss = 0.44332599412827267, disc_loss = 0.039481496451688664
Trained batch 105 in epoch 6, gen_loss = 0.4433881103430154, disc_loss = 0.03959639401631957
Trained batch 106 in epoch 6, gen_loss = 0.4425416226698973, disc_loss = 0.03980443755025479
Trained batch 107 in epoch 6, gen_loss = 0.4425007402896881, disc_loss = 0.03956875765989362
Trained batch 108 in epoch 6, gen_loss = 0.44246995886531443, disc_loss = 0.03955554899358011
Trained batch 109 in epoch 6, gen_loss = 0.44221496852961456, disc_loss = 0.03957783070562238
Trained batch 110 in epoch 6, gen_loss = 0.4423504632872504, disc_loss = 0.03963600285770791
Trained batch 111 in epoch 6, gen_loss = 0.44201475142368246, disc_loss = 0.03967968822273958
Trained batch 112 in epoch 6, gen_loss = 0.44155307733907107, disc_loss = 0.03956032874458264
Trained batch 113 in epoch 6, gen_loss = 0.4413004956747356, disc_loss = 0.039786387173655
Trained batch 114 in epoch 6, gen_loss = 0.4411737965500873, disc_loss = 0.039995745152397
Trained batch 115 in epoch 6, gen_loss = 0.44075458625267294, disc_loss = 0.04005027479283383
Trained batch 116 in epoch 6, gen_loss = 0.4409088314089001, disc_loss = 0.03981546345604663
Trained batch 117 in epoch 6, gen_loss = 0.44140797701932616, disc_loss = 0.0400580834021192
Trained batch 118 in epoch 6, gen_loss = 0.4411373967383088, disc_loss = 0.04086548347855691
Trained batch 119 in epoch 6, gen_loss = 0.44099612658222515, disc_loss = 0.040727649702845765
Trained batch 120 in epoch 6, gen_loss = 0.44068983246472254, disc_loss = 0.0410884519738784
Trained batch 121 in epoch 6, gen_loss = 0.4406475932871709, disc_loss = 0.040982418338630776
Trained batch 122 in epoch 6, gen_loss = 0.4404688327293086, disc_loss = 0.04079536910024964
Trained batch 123 in epoch 6, gen_loss = 0.44102187550836996, disc_loss = 0.04053159200421144
Trained batch 124 in epoch 6, gen_loss = 0.44071087646484375, disc_loss = 0.040278239320963624
Trained batch 125 in epoch 6, gen_loss = 0.44042451821622397, disc_loss = 0.04008087100061987
Trained batch 126 in epoch 6, gen_loss = 0.4404258035768674, disc_loss = 0.04002156344381726
Trained batch 127 in epoch 6, gen_loss = 0.44035213883034885, disc_loss = 0.03981937056596507
Trained batch 128 in epoch 6, gen_loss = 0.44072380015092305, disc_loss = 0.03967167453320567
Trained batch 129 in epoch 6, gen_loss = 0.4409662237534156, disc_loss = 0.04006460141748763
Trained batch 130 in epoch 6, gen_loss = 0.4403686302763815, disc_loss = 0.04039562839431731
Trained batch 131 in epoch 6, gen_loss = 0.4411226720972495, disc_loss = 0.04139029944781214
Trained batch 132 in epoch 6, gen_loss = 0.4411085413810902, disc_loss = 0.04146304465060059
Trained batch 133 in epoch 6, gen_loss = 0.4410944509862074, disc_loss = 0.04157789753847269
Trained batch 134 in epoch 6, gen_loss = 0.4410524814217179, disc_loss = 0.044310257739077014
Trained batch 135 in epoch 6, gen_loss = 0.44071143558796716, disc_loss = 0.04523009096395553
Trained batch 136 in epoch 6, gen_loss = 0.44071709544119175, disc_loss = 0.04505948085052362
Trained batch 137 in epoch 6, gen_loss = 0.4404366029345471, disc_loss = 0.04517565140217219
Trained batch 138 in epoch 6, gen_loss = 0.44085063608430275, disc_loss = 0.04514858321280038
Trained batch 139 in epoch 6, gen_loss = 0.4406240422810827, disc_loss = 0.04593326621356287
Trained batch 140 in epoch 6, gen_loss = 0.440826821834483, disc_loss = 0.04578717585639856
Trained batch 141 in epoch 6, gen_loss = 0.4407717992722149, disc_loss = 0.04584558461923939
Trained batch 142 in epoch 6, gen_loss = 0.44076929413355315, disc_loss = 0.045598211232572794
Trained batch 143 in epoch 6, gen_loss = 0.4403219376173284, disc_loss = 0.04587450725375675
Trained batch 144 in epoch 6, gen_loss = 0.44028538342179924, disc_loss = 0.045718222686314376
Trained batch 145 in epoch 6, gen_loss = 0.44026932406098873, disc_loss = 0.04557517043008686
Trained batch 146 in epoch 6, gen_loss = 0.4400503213713769, disc_loss = 0.04542027257674304
Trained batch 147 in epoch 6, gen_loss = 0.4399883380612811, disc_loss = 0.045196311199106276
Trained batch 148 in epoch 6, gen_loss = 0.44010849287045883, disc_loss = 0.0449623422690936
Trained batch 149 in epoch 6, gen_loss = 0.43994835058848064, disc_loss = 0.04512909294726948
Trained batch 150 in epoch 6, gen_loss = 0.43911959497344416, disc_loss = 0.0461651967215469
Trained batch 151 in epoch 6, gen_loss = 0.439571247877259, disc_loss = 0.0463751830117728
Trained batch 152 in epoch 6, gen_loss = 0.4397515925317029, disc_loss = 0.046875811690233304
Trained batch 153 in epoch 6, gen_loss = 0.43979740355695995, disc_loss = 0.047417876797474244
Trained batch 154 in epoch 6, gen_loss = 0.4392320629089109, disc_loss = 0.047292994506536956
Trained batch 155 in epoch 6, gen_loss = 0.43860813134755844, disc_loss = 0.047399560625378326
Trained batch 156 in epoch 6, gen_loss = 0.43904893147717616, disc_loss = 0.04725966154401944
Trained batch 157 in epoch 6, gen_loss = 0.4390761533492728, disc_loss = 0.047147224660184756
Trained batch 158 in epoch 6, gen_loss = 0.4394123597340014, disc_loss = 0.04691432587767266
Trained batch 159 in epoch 6, gen_loss = 0.43901498187333343, disc_loss = 0.04686349514231551
Trained batch 160 in epoch 6, gen_loss = 0.4388948521628883, disc_loss = 0.04697272158661707
Trained batch 161 in epoch 6, gen_loss = 0.43878172246026403, disc_loss = 0.04679554126248407
Trained batch 162 in epoch 6, gen_loss = 0.4397552598473485, disc_loss = 0.04725392990419927
Trained batch 163 in epoch 6, gen_loss = 0.4396921932333853, disc_loss = 0.04745140340372284
Trained batch 164 in epoch 6, gen_loss = 0.4393664968736244, disc_loss = 0.04755524600376234
Trained batch 165 in epoch 6, gen_loss = 0.43972031448978977, disc_loss = 0.04785949234424316
Trained batch 166 in epoch 6, gen_loss = 0.43954179601041143, disc_loss = 0.04764311772096389
Trained batch 167 in epoch 6, gen_loss = 0.4390566320646377, disc_loss = 0.047535797084925606
Trained batch 168 in epoch 6, gen_loss = 0.4387603793623885, disc_loss = 0.04736381745208385
Trained batch 169 in epoch 6, gen_loss = 0.43866563895169425, disc_loss = 0.047183291101828215
Trained batch 170 in epoch 6, gen_loss = 0.43855221979102194, disc_loss = 0.047400625142110894
Trained batch 171 in epoch 6, gen_loss = 0.43869031567213146, disc_loss = 0.048160056055653405
Trained batch 172 in epoch 6, gen_loss = 0.43827488346595983, disc_loss = 0.048094910663697935
Trained batch 173 in epoch 6, gen_loss = 0.4383810111160936, disc_loss = 0.048083096541913936
Trained batch 174 in epoch 6, gen_loss = 0.43814133405685424, disc_loss = 0.04807378748963986
Trained batch 175 in epoch 6, gen_loss = 0.4384398751638152, disc_loss = 0.048140888115581634
Trained batch 176 in epoch 6, gen_loss = 0.4382672998528023, disc_loss = 0.04859168593124565
Trained batch 177 in epoch 6, gen_loss = 0.43835296456733447, disc_loss = 0.0484671771782712
Trained batch 178 in epoch 6, gen_loss = 0.43903543929147987, disc_loss = 0.04852589789268108
Trained batch 179 in epoch 6, gen_loss = 0.4388961412840419, disc_loss = 0.04849198021046403
Trained batch 180 in epoch 6, gen_loss = 0.439021869258986, disc_loss = 0.04857246605782301
Trained batch 181 in epoch 6, gen_loss = 0.43941711069463374, disc_loss = 0.04890443961095106
Trained batch 182 in epoch 6, gen_loss = 0.43939253101583386, disc_loss = 0.04880536426255693
Trained batch 183 in epoch 6, gen_loss = 0.4390611050893431, disc_loss = 0.04873786861856427
Trained batch 184 in epoch 6, gen_loss = 0.4391139914860597, disc_loss = 0.04866943012268559
Trained batch 185 in epoch 6, gen_loss = 0.43887269368735693, disc_loss = 0.04853449481719684
Trained batch 186 in epoch 6, gen_loss = 0.4386107124746802, disc_loss = 0.04855940383634864
Trained batch 187 in epoch 6, gen_loss = 0.43872161162026385, disc_loss = 0.04833086930522497
Trained batch 188 in epoch 6, gen_loss = 0.43896799459659236, disc_loss = 0.04819391467534597
Trained batch 189 in epoch 6, gen_loss = 0.4386605225111309, disc_loss = 0.048151492726940075
Trained batch 190 in epoch 6, gen_loss = 0.43895812777324494, disc_loss = 0.04806486028368483
Trained batch 191 in epoch 6, gen_loss = 0.43899929880475, disc_loss = 0.048030629819550086
Trained batch 192 in epoch 6, gen_loss = 0.43878547422626474, disc_loss = 0.04798608953422756
Trained batch 193 in epoch 6, gen_loss = 0.4385917953301951, disc_loss = 0.048862019733804246
Trained batch 194 in epoch 6, gen_loss = 0.438949914314808, disc_loss = 0.04873398460017947
Trained batch 195 in epoch 6, gen_loss = 0.43922540393410897, disc_loss = 0.04860263762339873
Trained batch 196 in epoch 6, gen_loss = 0.4393161288675318, disc_loss = 0.048402416966571875
Trained batch 197 in epoch 6, gen_loss = 0.4391962083602192, disc_loss = 0.04821079644148774
Trained batch 198 in epoch 6, gen_loss = 0.4394667542459977, disc_loss = 0.04800994282625803
Trained batch 199 in epoch 6, gen_loss = 0.43979744032025336, disc_loss = 0.04786145676160231
Trained batch 200 in epoch 6, gen_loss = 0.43974222991597, disc_loss = 0.0477068462242275
Trained batch 201 in epoch 6, gen_loss = 0.43969074024422333, disc_loss = 0.0475640672715473
Trained batch 202 in epoch 6, gen_loss = 0.43949352799378005, disc_loss = 0.04742748161153914
Trained batch 203 in epoch 6, gen_loss = 0.4390866660019931, disc_loss = 0.04753719685900518
Trained batch 204 in epoch 6, gen_loss = 0.4392910015292284, disc_loss = 0.047364337490190096
Trained batch 205 in epoch 6, gen_loss = 0.4395935512283473, disc_loss = 0.047214307345323336
Trained batch 206 in epoch 6, gen_loss = 0.4397166243209931, disc_loss = 0.047033859455085175
Trained batch 207 in epoch 6, gen_loss = 0.43995236017956185, disc_loss = 0.04689712327448293
Trained batch 208 in epoch 6, gen_loss = 0.43992073113838454, disc_loss = 0.04685095447431983
Trained batch 209 in epoch 6, gen_loss = 0.4402661820252736, disc_loss = 0.046661383762866965
Trained batch 210 in epoch 6, gen_loss = 0.4403752734028333, disc_loss = 0.04646639601587896
Trained batch 211 in epoch 6, gen_loss = 0.44039141175881874, disc_loss = 0.04650273945244064
Trained batch 212 in epoch 6, gen_loss = 0.44059757391611737, disc_loss = 0.04667128109867234
Trained batch 213 in epoch 6, gen_loss = 0.44067538174513343, disc_loss = 0.04664050924992102
Trained batch 214 in epoch 6, gen_loss = 0.44073330940202227, disc_loss = 0.04658692979665343
Trained batch 215 in epoch 6, gen_loss = 0.440817059190185, disc_loss = 0.04652350235307865
Trained batch 216 in epoch 6, gen_loss = 0.44109547522760206, disc_loss = 0.04648993129751856
Trained batch 217 in epoch 6, gen_loss = 0.44106453000952345, disc_loss = 0.04630230618170847
Trained batch 218 in epoch 6, gen_loss = 0.4410313141944746, disc_loss = 0.04612304012559048
Trained batch 219 in epoch 6, gen_loss = 0.4407481159676205, disc_loss = 0.0460390889424492
Trained batch 220 in epoch 6, gen_loss = 0.4406329557906449, disc_loss = 0.0459619989846222
Trained batch 221 in epoch 6, gen_loss = 0.4403605973935342, disc_loss = 0.04582735688870286
Trained batch 222 in epoch 6, gen_loss = 0.4402264156149107, disc_loss = 0.04596963388669918
Trained batch 223 in epoch 6, gen_loss = 0.44050727624978336, disc_loss = 0.04590652218653953
Trained batch 224 in epoch 6, gen_loss = 0.44083969778484766, disc_loss = 0.04593540955748823
Trained batch 225 in epoch 6, gen_loss = 0.4408691137765361, disc_loss = 0.045896433796568784
Trained batch 226 in epoch 6, gen_loss = 0.4408457484014234, disc_loss = 0.046010968976937204
Trained batch 227 in epoch 6, gen_loss = 0.4415249455916254, disc_loss = 0.046541671489218346
Trained batch 228 in epoch 6, gen_loss = 0.4415369735274252, disc_loss = 0.046377462822960194
Trained batch 229 in epoch 6, gen_loss = 0.44151059894458106, disc_loss = 0.04656791139960937
Trained batch 230 in epoch 6, gen_loss = 0.44156039444915146, disc_loss = 0.04650356772545225
Trained batch 231 in epoch 6, gen_loss = 0.44151451374436246, disc_loss = 0.04639921872475152
Trained batch 232 in epoch 6, gen_loss = 0.44133123793827106, disc_loss = 0.04644941008158124
Trained batch 233 in epoch 6, gen_loss = 0.4412559219914624, disc_loss = 0.046316523307886645
Trained batch 234 in epoch 6, gen_loss = 0.4412368579113737, disc_loss = 0.0461762644152375
Trained batch 235 in epoch 6, gen_loss = 0.441124896629382, disc_loss = 0.04606870455683162
Trained batch 236 in epoch 6, gen_loss = 0.44121940666613196, disc_loss = 0.04591910619257246
Trained batch 237 in epoch 6, gen_loss = 0.44128059451820467, disc_loss = 0.04578169766703949
Trained batch 238 in epoch 6, gen_loss = 0.4413776097187936, disc_loss = 0.04568003187789952
Trained batch 239 in epoch 6, gen_loss = 0.4413510446747144, disc_loss = 0.04563274918667351
Trained batch 240 in epoch 6, gen_loss = 0.4413294177579682, disc_loss = 0.046556687094580336
Trained batch 241 in epoch 6, gen_loss = 0.44108635704379434, disc_loss = 0.04715025543104395
Trained batch 242 in epoch 6, gen_loss = 0.4412591015851056, disc_loss = 0.047216451412580386
Trained batch 243 in epoch 6, gen_loss = 0.44118906826269433, disc_loss = 0.047237000622801846
Trained batch 244 in epoch 6, gen_loss = 0.4409985885328176, disc_loss = 0.04771300517402741
Trained batch 245 in epoch 6, gen_loss = 0.44081458631085185, disc_loss = 0.04868175088980697
Trained batch 246 in epoch 6, gen_loss = 0.44048014162523064, disc_loss = 0.048812830764121615
Trained batch 247 in epoch 6, gen_loss = 0.44020123515398274, disc_loss = 0.04888386215879432
Trained batch 248 in epoch 6, gen_loss = 0.43980751925682926, disc_loss = 0.04917975819957663
Trained batch 249 in epoch 6, gen_loss = 0.43979351258277893, disc_loss = 0.049352852668613195
Trained batch 250 in epoch 6, gen_loss = 0.4395759096183625, disc_loss = 0.04973415118749754
Trained batch 251 in epoch 6, gen_loss = 0.4394134907495408, disc_loss = 0.04978720476806518
Trained batch 252 in epoch 6, gen_loss = 0.43950591351203766, disc_loss = 0.049810743286999554
Trained batch 253 in epoch 6, gen_loss = 0.43944376085217546, disc_loss = 0.04983152953291854
Trained batch 254 in epoch 6, gen_loss = 0.4397732438994389, disc_loss = 0.05001967826529461
Trained batch 255 in epoch 6, gen_loss = 0.4397328846389428, disc_loss = 0.05004893685327261
Trained batch 256 in epoch 6, gen_loss = 0.4395353072812121, disc_loss = 0.05042774864773226
Trained batch 257 in epoch 6, gen_loss = 0.43953226391197175, disc_loss = 0.05033477981639809
Trained batch 258 in epoch 6, gen_loss = 0.4395901321444272, disc_loss = 0.050183177501337176
Trained batch 259 in epoch 6, gen_loss = 0.4392962546302722, disc_loss = 0.05023351855074557
Trained batch 260 in epoch 6, gen_loss = 0.4390185745968216, disc_loss = 0.05085553598886363
Trained batch 261 in epoch 6, gen_loss = 0.4390493161578215, disc_loss = 0.05085997295189108
Trained batch 262 in epoch 6, gen_loss = 0.4389216078324916, disc_loss = 0.05101248650623932
Trained batch 263 in epoch 6, gen_loss = 0.4390192518405842, disc_loss = 0.05107563121992192
Trained batch 264 in epoch 6, gen_loss = 0.43920688707873506, disc_loss = 0.050984135906229605
Trained batch 265 in epoch 6, gen_loss = 0.4390855736302254, disc_loss = 0.0508447964255579
Trained batch 266 in epoch 6, gen_loss = 0.43905289878559467, disc_loss = 0.05084699521029598
Trained batch 267 in epoch 6, gen_loss = 0.43887430974351826, disc_loss = 0.05080528571548413
Trained batch 268 in epoch 6, gen_loss = 0.43888500321753404, disc_loss = 0.05064233132122174
Trained batch 269 in epoch 6, gen_loss = 0.438805200987392, disc_loss = 0.050601200469666055
Trained batch 270 in epoch 6, gen_loss = 0.43899880882998676, disc_loss = 0.050499028234134304
Trained batch 271 in epoch 6, gen_loss = 0.43896389697842736, disc_loss = 0.0504834468010813
Trained batch 272 in epoch 6, gen_loss = 0.43892651588925513, disc_loss = 0.05034868434862994
Trained batch 273 in epoch 6, gen_loss = 0.439031313153079, disc_loss = 0.05068230601095588
Trained batch 274 in epoch 6, gen_loss = 0.43899380402131516, disc_loss = 0.05081669543954459
Trained batch 275 in epoch 6, gen_loss = 0.4390112949886184, disc_loss = 0.05065604722113821
Trained batch 276 in epoch 6, gen_loss = 0.4394033189715031, disc_loss = 0.05127632243067887
Trained batch 277 in epoch 6, gen_loss = 0.43929009128817553, disc_loss = 0.051459204609901145
Trained batch 278 in epoch 6, gen_loss = 0.43939857574773944, disc_loss = 0.0517408493338787
Trained batch 279 in epoch 6, gen_loss = 0.439562715696437, disc_loss = 0.05208383986526834
Trained batch 280 in epoch 6, gen_loss = 0.43908479884001705, disc_loss = 0.0527240400272173
Trained batch 281 in epoch 6, gen_loss = 0.4388200117552534, disc_loss = 0.053269498436612654
Trained batch 282 in epoch 6, gen_loss = 0.4389177713503686, disc_loss = 0.05447891935403377
Trained batch 283 in epoch 6, gen_loss = 0.4389075750196484, disc_loss = 0.054427800178659
Trained batch 284 in epoch 6, gen_loss = 0.43877838578140527, disc_loss = 0.05436728440159768
Trained batch 285 in epoch 6, gen_loss = 0.43874596945055716, disc_loss = 0.05423264417445639
Trained batch 286 in epoch 6, gen_loss = 0.43879860193056514, disc_loss = 0.054092241885977756
Trained batch 287 in epoch 6, gen_loss = 0.43882589300887453, disc_loss = 0.05395589180665815
Trained batch 288 in epoch 6, gen_loss = 0.43887616296952986, disc_loss = 0.0540009436316814
Trained batch 289 in epoch 6, gen_loss = 0.4386825679705061, disc_loss = 0.05397008510049561
Trained batch 290 in epoch 6, gen_loss = 0.43870190431162254, disc_loss = 0.05385475319288543
Trained batch 291 in epoch 6, gen_loss = 0.4389137558332861, disc_loss = 0.053734290378474416
Trained batch 292 in epoch 6, gen_loss = 0.4389089111988862, disc_loss = 0.053578166640760955
Trained batch 293 in epoch 6, gen_loss = 0.4390177442913964, disc_loss = 0.0534391309780886
Trained batch 294 in epoch 6, gen_loss = 0.4389956497539908, disc_loss = 0.053299603109263766
Trained batch 295 in epoch 6, gen_loss = 0.43888320572472905, disc_loss = 0.053462810830112444
Trained batch 296 in epoch 6, gen_loss = 0.43870923625499714, disc_loss = 0.05360598276723615
Trained batch 297 in epoch 6, gen_loss = 0.4385943834813649, disc_loss = 0.05357536418838489
Trained batch 298 in epoch 6, gen_loss = 0.43866122925161916, disc_loss = 0.053420105080017474
Trained batch 299 in epoch 6, gen_loss = 0.4388389192024867, disc_loss = 0.053395807739968104
Trained batch 300 in epoch 6, gen_loss = 0.4387032019339527, disc_loss = 0.053414617399019856
Trained batch 301 in epoch 6, gen_loss = 0.43855549878631994, disc_loss = 0.053302162027738936
Trained batch 302 in epoch 6, gen_loss = 0.4385139200553642, disc_loss = 0.05331463016655677
Trained batch 303 in epoch 6, gen_loss = 0.4383514000004844, disc_loss = 0.05373995728165794
Trained batch 304 in epoch 6, gen_loss = 0.4383617313181768, disc_loss = 0.0537307698981928
Trained batch 305 in epoch 6, gen_loss = 0.4383367213353612, disc_loss = 0.05366052368509711
Trained batch 306 in epoch 6, gen_loss = 0.4384162305620672, disc_loss = 0.05352751305781863
Trained batch 307 in epoch 6, gen_loss = 0.4383974147887973, disc_loss = 0.05339978475655828
Trained batch 308 in epoch 6, gen_loss = 0.4383912262986007, disc_loss = 0.0532473779003163
Trained batch 309 in epoch 6, gen_loss = 0.438466334054547, disc_loss = 0.053098787872060654
Trained batch 310 in epoch 6, gen_loss = 0.43851899401167965, disc_loss = 0.053092765019925076
Trained batch 311 in epoch 6, gen_loss = 0.4385121458998093, disc_loss = 0.05328608291128125
Trained batch 312 in epoch 6, gen_loss = 0.43868501574848406, disc_loss = 0.05352950597199769
Trained batch 313 in epoch 6, gen_loss = 0.4387116701739609, disc_loss = 0.05340171471285592
Trained batch 314 in epoch 6, gen_loss = 0.4385199101198287, disc_loss = 0.05326509597519087
Trained batch 315 in epoch 6, gen_loss = 0.4387740116519264, disc_loss = 0.05318486585600089
Trained batch 316 in epoch 6, gen_loss = 0.4387720040154382, disc_loss = 0.05303894273190515
Trained batch 317 in epoch 6, gen_loss = 0.4388738178044745, disc_loss = 0.05289561162796457
Trained batch 318 in epoch 6, gen_loss = 0.43890152670746685, disc_loss = 0.052746080479593394
Trained batch 319 in epoch 6, gen_loss = 0.438952908758074, disc_loss = 0.05265660179866245
Trained batch 320 in epoch 6, gen_loss = 0.43917583815776673, disc_loss = 0.05251032625240886
Trained batch 321 in epoch 6, gen_loss = 0.4392362918172564, disc_loss = 0.05236308331607106
Trained batch 322 in epoch 6, gen_loss = 0.43958357686966937, disc_loss = 0.05237697720550716
Trained batch 323 in epoch 6, gen_loss = 0.4395386882034349, disc_loss = 0.05224128834972227
Trained batch 324 in epoch 6, gen_loss = 0.4395652395945329, disc_loss = 0.05218350547437484
Trained batch 325 in epoch 6, gen_loss = 0.4397427369297648, disc_loss = 0.052042167120973114
Trained batch 326 in epoch 6, gen_loss = 0.43992805581209493, disc_loss = 0.051965990318811356
Trained batch 327 in epoch 6, gen_loss = 0.4399412263457368, disc_loss = 0.05190806333458323
Trained batch 328 in epoch 6, gen_loss = 0.43994469338275016, disc_loss = 0.051783911958846365
Trained batch 329 in epoch 6, gen_loss = 0.4398104201663624, disc_loss = 0.051685087101985557
Trained batch 330 in epoch 6, gen_loss = 0.4397556057869488, disc_loss = 0.05172127355987437
Trained batch 331 in epoch 6, gen_loss = 0.4399703502295965, disc_loss = 0.051672366381824826
Trained batch 332 in epoch 6, gen_loss = 0.4400880751130101, disc_loss = 0.05154917445788915
Trained batch 333 in epoch 6, gen_loss = 0.4396821268482836, disc_loss = 0.05156926958665564
Trained batch 334 in epoch 6, gen_loss = 0.4395333235833182, disc_loss = 0.05221500019334368
Trained batch 335 in epoch 6, gen_loss = 0.4397411464403073, disc_loss = 0.05216438883854564
Trained batch 336 in epoch 6, gen_loss = 0.43975476350204173, disc_loss = 0.052146906631470875
Trained batch 337 in epoch 6, gen_loss = 0.4398708690905712, disc_loss = 0.05210006588204769
Trained batch 338 in epoch 6, gen_loss = 0.43973307984065163, disc_loss = 0.05207226957966488
Trained batch 339 in epoch 6, gen_loss = 0.4397204489392393, disc_loss = 0.05200712043819401
Trained batch 340 in epoch 6, gen_loss = 0.43957576417853056, disc_loss = 0.051938905603255085
Trained batch 341 in epoch 6, gen_loss = 0.4399187081215674, disc_loss = 0.0520027249912617
Trained batch 342 in epoch 6, gen_loss = 0.4397926905759917, disc_loss = 0.051973287104398184
Trained batch 343 in epoch 6, gen_loss = 0.4396794325737066, disc_loss = 0.05186472434501792
Trained batch 344 in epoch 6, gen_loss = 0.43948122392530026, disc_loss = 0.051852717918708276
Trained batch 345 in epoch 6, gen_loss = 0.439276736681861, disc_loss = 0.05178905426890649
Trained batch 346 in epoch 6, gen_loss = 0.43923727691345327, disc_loss = 0.052434095708916356
Trained batch 347 in epoch 6, gen_loss = 0.43906374284248245, disc_loss = 0.05268072060593029
Trained batch 348 in epoch 6, gen_loss = 0.4390344600964412, disc_loss = 0.05260234331327856
Trained batch 349 in epoch 6, gen_loss = 0.43908371678420477, disc_loss = 0.05251664990692266
Trained batch 350 in epoch 6, gen_loss = 0.4391184205513055, disc_loss = 0.0525069725062921
Trained batch 351 in epoch 6, gen_loss = 0.43893902537158946, disc_loss = 0.052471011029080146
Trained batch 352 in epoch 6, gen_loss = 0.4388320288138079, disc_loss = 0.052469959950850215
Trained batch 353 in epoch 6, gen_loss = 0.4385540027402889, disc_loss = 0.05248566410546375
Trained batch 354 in epoch 6, gen_loss = 0.4384239054061997, disc_loss = 0.05259163197995701
Trained batch 355 in epoch 6, gen_loss = 0.43864370078853004, disc_loss = 0.05254151405154445
Trained batch 356 in epoch 6, gen_loss = 0.43861326767282993, disc_loss = 0.05242185442935394
Trained batch 357 in epoch 6, gen_loss = 0.4386013521495478, disc_loss = 0.05233098987058096
Trained batch 358 in epoch 6, gen_loss = 0.43872286483105843, disc_loss = 0.052248424859484006
Trained batch 359 in epoch 6, gen_loss = 0.4388092469010088, disc_loss = 0.052138235949031594
Trained batch 360 in epoch 6, gen_loss = 0.43871799152643726, disc_loss = 0.0520554841031679
Trained batch 361 in epoch 6, gen_loss = 0.4386358564071234, disc_loss = 0.05196487989652264
Trained batch 362 in epoch 6, gen_loss = 0.4387248340717032, disc_loss = 0.05186429624022408
Trained batch 363 in epoch 6, gen_loss = 0.43883994188937514, disc_loss = 0.05177423061296385
Trained batch 364 in epoch 6, gen_loss = 0.4389139662866723, disc_loss = 0.052159457481530024
Trained batch 365 in epoch 6, gen_loss = 0.4388239166287125, disc_loss = 0.052057689286086485
Trained batch 366 in epoch 6, gen_loss = 0.43880077157098524, disc_loss = 0.05200402229156457
Trained batch 367 in epoch 6, gen_loss = 0.43875297636765503, disc_loss = 0.05201723842259051
Trained batch 368 in epoch 6, gen_loss = 0.43878761289242485, disc_loss = 0.05194147614267501
Trained batch 369 in epoch 6, gen_loss = 0.4388717265547933, disc_loss = 0.051941285641058474
Trained batch 370 in epoch 6, gen_loss = 0.4389106180629319, disc_loss = 0.05182036859261981
Trained batch 371 in epoch 6, gen_loss = 0.43893230538214406, disc_loss = 0.05171732637425384
Trained batch 372 in epoch 6, gen_loss = 0.43905495438754716, disc_loss = 0.051644612481972406
Trained batch 373 in epoch 6, gen_loss = 0.4392552826015707, disc_loss = 0.05157730755157131
Trained batch 374 in epoch 6, gen_loss = 0.4393677264849345, disc_loss = 0.05162395817910632
Trained batch 375 in epoch 6, gen_loss = 0.4393939998080122, disc_loss = 0.05156088996297145
Trained batch 376 in epoch 6, gen_loss = 0.43936355068133426, disc_loss = 0.0518280103227089
Trained batch 377 in epoch 6, gen_loss = 0.43928344823696, disc_loss = 0.051970388832694246
Trained batch 378 in epoch 6, gen_loss = 0.4391902258182264, disc_loss = 0.05191896819831474
Trained batch 379 in epoch 6, gen_loss = 0.43931465368521844, disc_loss = 0.051936333826252894
Trained batch 380 in epoch 6, gen_loss = 0.4396550961992559, disc_loss = 0.05224169157518763
Trained batch 381 in epoch 6, gen_loss = 0.4393414976709176, disc_loss = 0.05258127629966597
Trained batch 382 in epoch 6, gen_loss = 0.43930437196016936, disc_loss = 0.052489085087683976
Trained batch 383 in epoch 6, gen_loss = 0.43921974184922874, disc_loss = 0.05262817094020041
Trained batch 384 in epoch 6, gen_loss = 0.4390203530138189, disc_loss = 0.052629551899849206
Trained batch 385 in epoch 6, gen_loss = 0.43901332734162324, disc_loss = 0.05258547543509443
Trained batch 386 in epoch 6, gen_loss = 0.4391437431638555, disc_loss = 0.0528495154820036
Trained batch 387 in epoch 6, gen_loss = 0.4392122872096976, disc_loss = 0.05281171480016111
Trained batch 388 in epoch 6, gen_loss = 0.43909988665335586, disc_loss = 0.0527271148916286
Trained batch 389 in epoch 6, gen_loss = 0.4391471455494563, disc_loss = 0.052747027761040205
Trained batch 390 in epoch 6, gen_loss = 0.4391106409032631, disc_loss = 0.05276955028071695
Trained batch 391 in epoch 6, gen_loss = 0.4392222943810784, disc_loss = 0.05271475125764668
Trained batch 392 in epoch 6, gen_loss = 0.43922949891357327, disc_loss = 0.05264063722053519
Trained batch 393 in epoch 6, gen_loss = 0.43910428223573617, disc_loss = 0.05261982730022504
Trained batch 394 in epoch 6, gen_loss = 0.439116281120083, disc_loss = 0.05254527394883806
Trained batch 395 in epoch 6, gen_loss = 0.43902335428830347, disc_loss = 0.052456757391219716
Trained batch 396 in epoch 6, gen_loss = 0.4389451982392472, disc_loss = 0.05234094118812035
Trained batch 397 in epoch 6, gen_loss = 0.43890329806049866, disc_loss = 0.052321689089891224
Trained batch 398 in epoch 6, gen_loss = 0.4389784806653073, disc_loss = 0.05227092969905874
Trained batch 399 in epoch 6, gen_loss = 0.439213339984417, disc_loss = 0.052282503003953026
Trained batch 400 in epoch 6, gen_loss = 0.43927125435814895, disc_loss = 0.05216481956650974
Trained batch 401 in epoch 6, gen_loss = 0.4392519848263679, disc_loss = 0.05205156761267922
Trained batch 402 in epoch 6, gen_loss = 0.4391441682432189, disc_loss = 0.05195166074576101
Trained batch 403 in epoch 6, gen_loss = 0.43923396388492963, disc_loss = 0.051848786508452406
Trained batch 404 in epoch 6, gen_loss = 0.4391612965383647, disc_loss = 0.05178558131403945
Trained batch 405 in epoch 6, gen_loss = 0.43914974616666147, disc_loss = 0.05172222063032534
Trained batch 406 in epoch 6, gen_loss = 0.43911703849893235, disc_loss = 0.05173685511857894
Trained batch 407 in epoch 6, gen_loss = 0.4392442959634697, disc_loss = 0.05165745990748024
Trained batch 408 in epoch 6, gen_loss = 0.4391588573788081, disc_loss = 0.05170437142430534
Trained batch 409 in epoch 6, gen_loss = 0.4391976214036709, disc_loss = 0.051607777622369365
Trained batch 410 in epoch 6, gen_loss = 0.43914025536128787, disc_loss = 0.05174482130579233
Trained batch 411 in epoch 6, gen_loss = 0.4393714674323508, disc_loss = 0.05185379690911115
Trained batch 412 in epoch 6, gen_loss = 0.43932005589868484, disc_loss = 0.05176921416475431
Trained batch 413 in epoch 6, gen_loss = 0.4394002443782373, disc_loss = 0.051727550962471947
Trained batch 414 in epoch 6, gen_loss = 0.43928894730935614, disc_loss = 0.051642330294946234
Trained batch 415 in epoch 6, gen_loss = 0.43931656144559383, disc_loss = 0.05187566374101712
Trained batch 416 in epoch 6, gen_loss = 0.4392852441584178, disc_loss = 0.05182040593423825
Trained batch 417 in epoch 6, gen_loss = 0.4393885858606494, disc_loss = 0.051886659970007944
Trained batch 418 in epoch 6, gen_loss = 0.43937557928601995, disc_loss = 0.05179818822648865
Trained batch 419 in epoch 6, gen_loss = 0.43935058471702393, disc_loss = 0.05180405607070064
Trained batch 420 in epoch 6, gen_loss = 0.43910895433108765, disc_loss = 0.05215569748266682
Trained batch 421 in epoch 6, gen_loss = 0.4389866720443653, disc_loss = 0.05219197751605504
Trained batch 422 in epoch 6, gen_loss = 0.4388604835556472, disc_loss = 0.05221504686250578
Trained batch 423 in epoch 6, gen_loss = 0.43889427894972405, disc_loss = 0.05244701318684438
Trained batch 424 in epoch 6, gen_loss = 0.4388637053966522, disc_loss = 0.05246925806188408
Trained batch 425 in epoch 6, gen_loss = 0.43885859588222326, disc_loss = 0.052399294239910486
Trained batch 426 in epoch 6, gen_loss = 0.43902535160754824, disc_loss = 0.05250555410243972
Trained batch 427 in epoch 6, gen_loss = 0.43888648738649405, disc_loss = 0.05319389346530052
Trained batch 428 in epoch 6, gen_loss = 0.43889055156207585, disc_loss = 0.05311634035841811
Trained batch 429 in epoch 6, gen_loss = 0.43898272126219995, disc_loss = 0.05316169477111205
Trained batch 430 in epoch 6, gen_loss = 0.43905786730850377, disc_loss = 0.053102177063223586
Trained batch 431 in epoch 6, gen_loss = 0.4390826170781144, disc_loss = 0.05302151141114774
Trained batch 432 in epoch 6, gen_loss = 0.4390555757160275, disc_loss = 0.05300075820094409
Trained batch 433 in epoch 6, gen_loss = 0.43913210159347904, disc_loss = 0.05292225015684447
Trained batch 434 in epoch 6, gen_loss = 0.4391010586557717, disc_loss = 0.0528534056672334
Trained batch 435 in epoch 6, gen_loss = 0.43915267562100646, disc_loss = 0.052748698712360764
Trained batch 436 in epoch 6, gen_loss = 0.43906558964836245, disc_loss = 0.0526790194590608
Trained batch 437 in epoch 6, gen_loss = 0.4390584216814607, disc_loss = 0.052587343053466996
Trained batch 438 in epoch 6, gen_loss = 0.4389732372787927, disc_loss = 0.05248180451614099
Trained batch 439 in epoch 6, gen_loss = 0.4391958985816349, disc_loss = 0.05241480831014501
Trained batch 440 in epoch 6, gen_loss = 0.4391497353983034, disc_loss = 0.052311637760889707
Trained batch 441 in epoch 6, gen_loss = 0.4391103554095618, disc_loss = 0.05224605100503301
Trained batch 442 in epoch 6, gen_loss = 0.4391861424085518, disc_loss = 0.052151209587529807
Trained batch 443 in epoch 6, gen_loss = 0.4392934207980697, disc_loss = 0.052063309989223545
Trained batch 444 in epoch 6, gen_loss = 0.43928615484344824, disc_loss = 0.052025338797045226
Trained batch 445 in epoch 6, gen_loss = 0.43939514144119124, disc_loss = 0.05196124995482309
Trained batch 446 in epoch 6, gen_loss = 0.4393842893025486, disc_loss = 0.05194545447538863
Trained batch 447 in epoch 6, gen_loss = 0.43933840268956764, disc_loss = 0.05184953840528449
Trained batch 448 in epoch 6, gen_loss = 0.43927912623154824, disc_loss = 0.05195748822074923
Trained batch 449 in epoch 6, gen_loss = 0.4393751150369644, disc_loss = 0.051962066925027306
Trained batch 450 in epoch 6, gen_loss = 0.43930240903883977, disc_loss = 0.05189325928403077
Trained batch 451 in epoch 6, gen_loss = 0.4391924591191047, disc_loss = 0.051854807392084167
Trained batch 452 in epoch 6, gen_loss = 0.43937150084682913, disc_loss = 0.05189429674499049
Trained batch 453 in epoch 6, gen_loss = 0.43942181647874184, disc_loss = 0.051814450475178034
Trained batch 454 in epoch 6, gen_loss = 0.439542156457901, disc_loss = 0.051768283291136495
Trained batch 455 in epoch 6, gen_loss = 0.43965324413096696, disc_loss = 0.05173597102392498
Trained batch 456 in epoch 6, gen_loss = 0.4396275770351193, disc_loss = 0.05164045203758375
Trained batch 457 in epoch 6, gen_loss = 0.43950646354381695, disc_loss = 0.05155224126039732
Trained batch 458 in epoch 6, gen_loss = 0.4393894392550641, disc_loss = 0.05145272448322125
Trained batch 459 in epoch 6, gen_loss = 0.4392543154566184, disc_loss = 0.05152647757356096
Trained batch 460 in epoch 6, gen_loss = 0.4394606679613316, disc_loss = 0.051579293757555864
Trained batch 461 in epoch 6, gen_loss = 0.43950292351958037, disc_loss = 0.05153206376322581
Trained batch 462 in epoch 6, gen_loss = 0.43957242440456445, disc_loss = 0.05145210219289681
Trained batch 463 in epoch 6, gen_loss = 0.4398512625745658, disc_loss = 0.051363499657499825
Trained batch 464 in epoch 6, gen_loss = 0.4397516349310516, disc_loss = 0.0512730956047533
Trained batch 465 in epoch 6, gen_loss = 0.4398279456749494, disc_loss = 0.05123343328793449
Trained batch 466 in epoch 6, gen_loss = 0.43984479867161214, disc_loss = 0.05114233602592183
Trained batch 467 in epoch 6, gen_loss = 0.4398168799841506, disc_loss = 0.05125005707506918
Trained batch 468 in epoch 6, gen_loss = 0.43976310848681405, disc_loss = 0.051416957416315516
Trained batch 469 in epoch 6, gen_loss = 0.43988585979380507, disc_loss = 0.051333923236605655
Trained batch 470 in epoch 6, gen_loss = 0.4399525156825971, disc_loss = 0.0512630933541765
Trained batch 471 in epoch 6, gen_loss = 0.439941434158107, disc_loss = 0.05124903569625438
Trained batch 472 in epoch 6, gen_loss = 0.439883443568272, disc_loss = 0.0513048562158222
Trained batch 473 in epoch 6, gen_loss = 0.4398679332139623, disc_loss = 0.05121534268316746
Trained batch 474 in epoch 6, gen_loss = 0.43981173941963597, disc_loss = 0.05111658901466351
Trained batch 475 in epoch 6, gen_loss = 0.4398024705778651, disc_loss = 0.051047182376809545
Trained batch 476 in epoch 6, gen_loss = 0.43987034539256703, disc_loss = 0.0509717681413942
Trained batch 477 in epoch 6, gen_loss = 0.4396990051329385, disc_loss = 0.05091183810790993
Trained batch 478 in epoch 6, gen_loss = 0.439675421953699, disc_loss = 0.050906512292300296
Trained batch 479 in epoch 6, gen_loss = 0.4397054579108953, disc_loss = 0.05088727969074777
Trained batch 480 in epoch 6, gen_loss = 0.43976115015589023, disc_loss = 0.050852962842176275
Trained batch 481 in epoch 6, gen_loss = 0.4398238887059738, disc_loss = 0.05078243760728273
Trained batch 482 in epoch 6, gen_loss = 0.43970708120190083, disc_loss = 0.050791093795203586
Trained batch 483 in epoch 6, gen_loss = 0.43988829278502584, disc_loss = 0.05076804936166914
Trained batch 484 in epoch 6, gen_loss = 0.4400182069576893, disc_loss = 0.0506867096144898
Trained batch 485 in epoch 6, gen_loss = 0.439930624248069, disc_loss = 0.050800653275125375
Trained batch 486 in epoch 6, gen_loss = 0.4400057790827702, disc_loss = 0.05088335870874155
Trained batch 487 in epoch 6, gen_loss = 0.4400814516988934, disc_loss = 0.0508121748647622
Trained batch 488 in epoch 6, gen_loss = 0.44003751288893767, disc_loss = 0.050923073059614514
Trained batch 489 in epoch 6, gen_loss = 0.44014509715596023, disc_loss = 0.050886750701168666
Trained batch 490 in epoch 6, gen_loss = 0.44023920950724493, disc_loss = 0.05082103692833524
Trained batch 491 in epoch 6, gen_loss = 0.44038259050225825, disc_loss = 0.0507720245012438
Trained batch 492 in epoch 6, gen_loss = 0.4404915166191349, disc_loss = 0.050703127814634395
Trained batch 493 in epoch 6, gen_loss = 0.44045689810625455, disc_loss = 0.050679809561843876
Trained batch 494 in epoch 6, gen_loss = 0.44065077690163046, disc_loss = 0.0506466387582924
Trained batch 495 in epoch 6, gen_loss = 0.44070905272758776, disc_loss = 0.051010635209217246
Trained batch 496 in epoch 6, gen_loss = 0.44072203850842095, disc_loss = 0.051119835302421084
Trained batch 497 in epoch 6, gen_loss = 0.4406491678402606, disc_loss = 0.051156134229624665
Trained batch 498 in epoch 6, gen_loss = 0.44046545727458414, disc_loss = 0.05146854591158355
Trained batch 499 in epoch 6, gen_loss = 0.4406995195746422, disc_loss = 0.05161339817289263
Trained batch 500 in epoch 6, gen_loss = 0.440704542065333, disc_loss = 0.051638039487958726
Trained batch 501 in epoch 6, gen_loss = 0.4406874972391888, disc_loss = 0.05176092060264274
Trained batch 502 in epoch 6, gen_loss = 0.44069304511276913, disc_loss = 0.05182751434879233
Trained batch 503 in epoch 6, gen_loss = 0.44062955275414484, disc_loss = 0.051767224469037344
Trained batch 504 in epoch 6, gen_loss = 0.4405593698567683, disc_loss = 0.05170443325515578
Trained batch 505 in epoch 6, gen_loss = 0.44057922660126514, disc_loss = 0.051675589354856034
Trained batch 506 in epoch 6, gen_loss = 0.4405731835661555, disc_loss = 0.0516497349408795
Trained batch 507 in epoch 6, gen_loss = 0.4403413120569207, disc_loss = 0.051886018575535806
Trained batch 508 in epoch 6, gen_loss = 0.4401770637522512, disc_loss = 0.051804350689968394
Trained batch 509 in epoch 6, gen_loss = 0.44016114075978596, disc_loss = 0.051921218419082316
Trained batch 510 in epoch 6, gen_loss = 0.4400721878804806, disc_loss = 0.05215047969557564
Trained batch 511 in epoch 6, gen_loss = 0.44010014657396823, disc_loss = 0.05206887566691876
Trained batch 512 in epoch 6, gen_loss = 0.4403685718251948, disc_loss = 0.05232008826986071
Trained batch 513 in epoch 6, gen_loss = 0.4401754438297294, disc_loss = 0.052582711909973726
Trained batch 514 in epoch 6, gen_loss = 0.4401647500621462, disc_loss = 0.052613293271945805
Trained batch 515 in epoch 6, gen_loss = 0.4403158715066984, disc_loss = 0.052911489293188604
Trained batch 516 in epoch 6, gen_loss = 0.44034659067021115, disc_loss = 0.05291440369691015
Trained batch 517 in epoch 6, gen_loss = 0.44023505819810405, disc_loss = 0.05295300469410149
Trained batch 518 in epoch 6, gen_loss = 0.4402116508957049, disc_loss = 0.052911091316850255
Trained batch 519 in epoch 6, gen_loss = 0.4403515754410854, disc_loss = 0.052985654399694444
Trained batch 520 in epoch 6, gen_loss = 0.44023919477343787, disc_loss = 0.053319185286681677
Trained batch 521 in epoch 6, gen_loss = 0.44030235867619055, disc_loss = 0.0532688595242156
Trained batch 522 in epoch 6, gen_loss = 0.4401954611332421, disc_loss = 0.05340527771325714
Trained batch 523 in epoch 6, gen_loss = 0.44002687038128613, disc_loss = 0.05335947653040546
Trained batch 524 in epoch 6, gen_loss = 0.4399069990998223, disc_loss = 0.05349368926403778
Trained batch 525 in epoch 6, gen_loss = 0.44001495243252003, disc_loss = 0.053413267715695975
Trained batch 526 in epoch 6, gen_loss = 0.4402410413440762, disc_loss = 0.053451684684416655
Trained batch 527 in epoch 6, gen_loss = 0.44029511008976085, disc_loss = 0.05342847987688429
Trained batch 528 in epoch 6, gen_loss = 0.44036750408111314, disc_loss = 0.05334170215405763
Trained batch 529 in epoch 6, gen_loss = 0.4403913655933344, disc_loss = 0.053292973612804176
Trained batch 530 in epoch 6, gen_loss = 0.44029319460333627, disc_loss = 0.053203794430843124
Trained batch 531 in epoch 6, gen_loss = 0.44030495654595525, disc_loss = 0.05313245139935551
Trained batch 532 in epoch 6, gen_loss = 0.44030603928592815, disc_loss = 0.0530647344259968
Trained batch 533 in epoch 6, gen_loss = 0.4403092477205541, disc_loss = 0.052982282677442115
Trained batch 534 in epoch 6, gen_loss = 0.44025417443747833, disc_loss = 0.05291545170611728
Trained batch 535 in epoch 6, gen_loss = 0.4402887943520475, disc_loss = 0.05286914615721595
Trained batch 536 in epoch 6, gen_loss = 0.4403384967778204, disc_loss = 0.052914681931995756
Trained batch 537 in epoch 6, gen_loss = 0.44038827152278787, disc_loss = 0.05305103544530123
Trained batch 538 in epoch 6, gen_loss = 0.4403954872616147, disc_loss = 0.05298159125559931
Trained batch 539 in epoch 6, gen_loss = 0.4403117350958012, disc_loss = 0.05295432488589237
Trained batch 540 in epoch 6, gen_loss = 0.4401844547658663, disc_loss = 0.052923096856016275
Trained batch 541 in epoch 6, gen_loss = 0.440196280549813, disc_loss = 0.05288094043906957
Trained batch 542 in epoch 6, gen_loss = 0.4402527115402081, disc_loss = 0.05288977168661647
Trained batch 543 in epoch 6, gen_loss = 0.4401805113234064, disc_loss = 0.05291649523475345
Trained batch 544 in epoch 6, gen_loss = 0.4400894315964585, disc_loss = 0.052862529206269104
Trained batch 545 in epoch 6, gen_loss = 0.4402540712566166, disc_loss = 0.052799170754078924
Trained batch 546 in epoch 6, gen_loss = 0.44024262758452015, disc_loss = 0.05271639803873964
Trained batch 547 in epoch 6, gen_loss = 0.44025899388276746, disc_loss = 0.052631511052145905
Trained batch 548 in epoch 6, gen_loss = 0.4402212409916688, disc_loss = 0.052598344733792685
Trained batch 549 in epoch 6, gen_loss = 0.4402990205179561, disc_loss = 0.05263358765535734
Trained batch 550 in epoch 6, gen_loss = 0.44011762435336726, disc_loss = 0.05275665038855182
Trained batch 551 in epoch 6, gen_loss = 0.4400675519221071, disc_loss = 0.05274478930379332
Trained batch 552 in epoch 6, gen_loss = 0.44014545164961927, disc_loss = 0.05278836251160712
Trained batch 553 in epoch 6, gen_loss = 0.44016659275934583, disc_loss = 0.05271531374022257
Trained batch 554 in epoch 6, gen_loss = 0.44029435579841203, disc_loss = 0.05300362382822477
Trained batch 555 in epoch 6, gen_loss = 0.44011768655811284, disc_loss = 0.053000627985063324
Trained batch 556 in epoch 6, gen_loss = 0.44003407140822554, disc_loss = 0.05303432599974117
Trained batch 557 in epoch 6, gen_loss = 0.440066327437705, disc_loss = 0.05298619208136393
Trained batch 558 in epoch 6, gen_loss = 0.4401836638373851, disc_loss = 0.05306141669753679
Trained batch 559 in epoch 6, gen_loss = 0.4399678024862494, disc_loss = 0.053046850409425264
Trained batch 560 in epoch 6, gen_loss = 0.4399281211609084, disc_loss = 0.053239858433697204
Trained batch 561 in epoch 6, gen_loss = 0.4400238003913194, disc_loss = 0.05318535139015296
Trained batch 562 in epoch 6, gen_loss = 0.43997216695790603, disc_loss = 0.05323720995839652
Trained batch 563 in epoch 6, gen_loss = 0.43987851003383066, disc_loss = 0.05330260601125869
Trained batch 564 in epoch 6, gen_loss = 0.4399204132831202, disc_loss = 0.05328437565141811
Trained batch 565 in epoch 6, gen_loss = 0.4399252350149222, disc_loss = 0.05326712501890194
Trained batch 566 in epoch 6, gen_loss = 0.43985148917430295, disc_loss = 0.05340011748181397
Trained batch 567 in epoch 6, gen_loss = 0.4398924152196293, disc_loss = 0.05334527645437178
Trained batch 568 in epoch 6, gen_loss = 0.43991455640021865, disc_loss = 0.053339325158360866
Trained batch 569 in epoch 6, gen_loss = 0.43996482925456865, disc_loss = 0.05357609996898917
Trained batch 570 in epoch 6, gen_loss = 0.44003997328193717, disc_loss = 0.05352309774672662
Trained batch 571 in epoch 6, gen_loss = 0.440030010742741, disc_loss = 0.05349168960832164
Trained batch 572 in epoch 6, gen_loss = 0.4398650452624649, disc_loss = 0.05342961402275123
Trained batch 573 in epoch 6, gen_loss = 0.4400217066346976, disc_loss = 0.053383489718615285
Trained batch 574 in epoch 6, gen_loss = 0.4400333539817644, disc_loss = 0.053394250200818415
Trained batch 575 in epoch 6, gen_loss = 0.44008309451035327, disc_loss = 0.05332014637113187
Trained batch 576 in epoch 6, gen_loss = 0.4401121180846745, disc_loss = 0.05341515722208409
Trained batch 577 in epoch 6, gen_loss = 0.4400322546080322, disc_loss = 0.053357021481920175
Trained batch 578 in epoch 6, gen_loss = 0.43990834337853807, disc_loss = 0.05330881601061176
Trained batch 579 in epoch 6, gen_loss = 0.43993187526176714, disc_loss = 0.053236728580668566
Trained batch 580 in epoch 6, gen_loss = 0.4399229230650936, disc_loss = 0.053181805189461695
Trained batch 581 in epoch 6, gen_loss = 0.44001933246134073, disc_loss = 0.05315502643220357
Trained batch 582 in epoch 6, gen_loss = 0.4400798732584173, disc_loss = 0.053081386003764684
Trained batch 583 in epoch 6, gen_loss = 0.4401410211847253, disc_loss = 0.05303335174350451
Trained batch 584 in epoch 6, gen_loss = 0.4401319269950573, disc_loss = 0.05298853946260662
Trained batch 585 in epoch 6, gen_loss = 0.44004131121236717, disc_loss = 0.053082823910696415
Trained batch 586 in epoch 6, gen_loss = 0.44014757785317843, disc_loss = 0.05300540893673389
Trained batch 587 in epoch 6, gen_loss = 0.44025739545927567, disc_loss = 0.05302710185258263
Trained batch 588 in epoch 6, gen_loss = 0.4401464232058598, disc_loss = 0.05339375065231667
Trained batch 589 in epoch 6, gen_loss = 0.44006778693805304, disc_loss = 0.05358490908865706
Trained batch 590 in epoch 6, gen_loss = 0.44005845711517655, disc_loss = 0.05353616754163542
Trained batch 591 in epoch 6, gen_loss = 0.44010227536027496, disc_loss = 0.05354194675345678
Trained batch 592 in epoch 6, gen_loss = 0.44007286675663865, disc_loss = 0.05360695455870379
Trained batch 593 in epoch 6, gen_loss = 0.4399775534567207, disc_loss = 0.05358508135809842
Trained batch 594 in epoch 6, gen_loss = 0.4399573082683467, disc_loss = 0.05352322438246563
Trained batch 595 in epoch 6, gen_loss = 0.43983336428067826, disc_loss = 0.05352859148105619
Trained batch 596 in epoch 6, gen_loss = 0.43988833590168847, disc_loss = 0.05347795084655484
Trained batch 597 in epoch 6, gen_loss = 0.4399588979705919, disc_loss = 0.05340423546482289
Trained batch 598 in epoch 6, gen_loss = 0.4400056749831058, disc_loss = 0.053388171171604694
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 0.40623217821121216, disc_loss = 0.05874663591384888
Trained batch 1 in epoch 7, gen_loss = 0.41055071353912354, disc_loss = 0.03937278129160404
Trained batch 2 in epoch 7, gen_loss = 0.4501265486081441, disc_loss = 0.0468142107129097
Trained batch 3 in epoch 7, gen_loss = 0.4614623934030533, disc_loss = 0.038098108023405075
Trained batch 4 in epoch 7, gen_loss = 0.457867431640625, disc_loss = 0.039417286217212674
Trained batch 5 in epoch 7, gen_loss = 0.46403540174166363, disc_loss = 0.04777060945828756
Trained batch 6 in epoch 7, gen_loss = 0.4530571230820247, disc_loss = 0.05331167791570936
Trained batch 7 in epoch 7, gen_loss = 0.4569335766136646, disc_loss = 0.04935305006802082
Trained batch 8 in epoch 7, gen_loss = 0.4554408888022105, disc_loss = 0.06575486229525672
Trained batch 9 in epoch 7, gen_loss = 0.4520196706056595, disc_loss = 0.06954275220632553
Trained batch 10 in epoch 7, gen_loss = 0.45356806028972974, disc_loss = 0.06741860170256007
Trained batch 11 in epoch 7, gen_loss = 0.455597127477328, disc_loss = 0.0654357314730684
Trained batch 12 in epoch 7, gen_loss = 0.45895450390302217, disc_loss = 0.06382368590969306
Trained batch 13 in epoch 7, gen_loss = 0.45152924742017475, disc_loss = 0.06148642487823963
Trained batch 14 in epoch 7, gen_loss = 0.4485572079817454, disc_loss = 0.058424222220977144
Trained batch 15 in epoch 7, gen_loss = 0.44626965187489986, disc_loss = 0.06107083265669644
Trained batch 16 in epoch 7, gen_loss = 0.44879474885323467, disc_loss = 0.06338928223532789
Trained batch 17 in epoch 7, gen_loss = 0.44510135220156777, disc_loss = 0.0645949954373969
Trained batch 18 in epoch 7, gen_loss = 0.445995242972123, disc_loss = 0.062061010026618055
Trained batch 19 in epoch 7, gen_loss = 0.4508818209171295, disc_loss = 0.061434699967503545
Trained batch 20 in epoch 7, gen_loss = 0.451138375770478, disc_loss = 0.061398256924890336
Trained batch 21 in epoch 7, gen_loss = 0.4505384076725353, disc_loss = 0.06697364811870185
Trained batch 22 in epoch 7, gen_loss = 0.4496301477370055, disc_loss = 0.06600942543667296
Trained batch 23 in epoch 7, gen_loss = 0.44947544236977893, disc_loss = 0.06540017994120717
Trained batch 24 in epoch 7, gen_loss = 0.44997886180877683, disc_loss = 0.06491632416844367
Trained batch 25 in epoch 7, gen_loss = 0.45246798258561355, disc_loss = 0.06634631251486448
Trained batch 26 in epoch 7, gen_loss = 0.45493646021242495, disc_loss = 0.06943699289803151
Trained batch 27 in epoch 7, gen_loss = 0.45413514758859364, disc_loss = 0.06803547564361777
Trained batch 28 in epoch 7, gen_loss = 0.4532853179964526, disc_loss = 0.06646001088465082
Trained batch 29 in epoch 7, gen_loss = 0.4526331881682078, disc_loss = 0.064668285412093
Trained batch 30 in epoch 7, gen_loss = 0.44996719206533126, disc_loss = 0.06371886974140521
Trained batch 31 in epoch 7, gen_loss = 0.44922905694693327, disc_loss = 0.062276193872094154
Trained batch 32 in epoch 7, gen_loss = 0.4460295014309161, disc_loss = 0.061280302590493
Trained batch 33 in epoch 7, gen_loss = 0.4444911769207786, disc_loss = 0.059915775734492964
Trained batch 34 in epoch 7, gen_loss = 0.4459510624408722, disc_loss = 0.05898073616304568
Trained batch 35 in epoch 7, gen_loss = 0.4473493860827552, disc_loss = 0.057617271422512
Trained batch 36 in epoch 7, gen_loss = 0.4473346165708593, disc_loss = 0.05634417475478069
Trained batch 37 in epoch 7, gen_loss = 0.44747040224702733, disc_loss = 0.055281377446494605
Trained batch 38 in epoch 7, gen_loss = 0.4474740036022969, disc_loss = 0.05407469514279793
Trained batch 39 in epoch 7, gen_loss = 0.4461681187152863, disc_loss = 0.05504723829217255
Trained batch 40 in epoch 7, gen_loss = 0.4465957298511412, disc_loss = 0.05873595655146169
Trained batch 41 in epoch 7, gen_loss = 0.44645792671612333, disc_loss = 0.05806819522487266
Trained batch 42 in epoch 7, gen_loss = 0.4452147560064183, disc_loss = 0.05831350485772588
Trained batch 43 in epoch 7, gen_loss = 0.44543947821313684, disc_loss = 0.05765144738622687
Trained batch 44 in epoch 7, gen_loss = 0.4447043730152978, disc_loss = 0.057060258587201436
Trained batch 45 in epoch 7, gen_loss = 0.4449152091275091, disc_loss = 0.056154576231442065
Trained batch 46 in epoch 7, gen_loss = 0.4453032485982205, disc_loss = 0.05642158765979904
Trained batch 47 in epoch 7, gen_loss = 0.44388014388581115, disc_loss = 0.05546846229117364
Trained batch 48 in epoch 7, gen_loss = 0.445214503273672, disc_loss = 0.05457259496027718
Trained batch 49 in epoch 7, gen_loss = 0.4447612589597702, disc_loss = 0.05426070036366582
Trained batch 50 in epoch 7, gen_loss = 0.44395310680071515, disc_loss = 0.05552485236423273
Trained batch 51 in epoch 7, gen_loss = 0.44452932935494643, disc_loss = 0.05540027621632012
Trained batch 52 in epoch 7, gen_loss = 0.4453644831225557, disc_loss = 0.05487656053858546
Trained batch 53 in epoch 7, gen_loss = 0.4452791489936687, disc_loss = 0.05422421839709083
Trained batch 54 in epoch 7, gen_loss = 0.4439362498846921, disc_loss = 0.05344922065057538
Trained batch 55 in epoch 7, gen_loss = 0.44335354545286726, disc_loss = 0.05285691765935293
Trained batch 56 in epoch 7, gen_loss = 0.4427100043547781, disc_loss = 0.05275582250926578
Trained batch 57 in epoch 7, gen_loss = 0.44214924193661787, disc_loss = 0.053467007578703866
Trained batch 58 in epoch 7, gen_loss = 0.44311515709101146, disc_loss = 0.053055424527344054
Trained batch 59 in epoch 7, gen_loss = 0.44324929018815357, disc_loss = 0.05313333400214712
Trained batch 60 in epoch 7, gen_loss = 0.4442863698865547, disc_loss = 0.05296561271562928
Trained batch 61 in epoch 7, gen_loss = 0.4445629119873047, disc_loss = 0.05271750018601456
Trained batch 62 in epoch 7, gen_loss = 0.4439149603011116, disc_loss = 0.05200929403127659
Trained batch 63 in epoch 7, gen_loss = 0.44454343570396304, disc_loss = 0.051536985018174164
Trained batch 64 in epoch 7, gen_loss = 0.4451012927752275, disc_loss = 0.050996051628429157
Trained batch 65 in epoch 7, gen_loss = 0.4454397897828709, disc_loss = 0.050513160711323675
Trained batch 66 in epoch 7, gen_loss = 0.4462145273365192, disc_loss = 0.051951799361007425
Trained batch 67 in epoch 7, gen_loss = 0.44569339033435373, disc_loss = 0.05182186573031632
Trained batch 68 in epoch 7, gen_loss = 0.446240762869517, disc_loss = 0.05143452480273402
Trained batch 69 in epoch 7, gen_loss = 0.44722812005451745, disc_loss = 0.05105999656287687
Trained batch 70 in epoch 7, gen_loss = 0.44799284196235767, disc_loss = 0.050893102746299455
Trained batch 71 in epoch 7, gen_loss = 0.4492398922642072, disc_loss = 0.050649057207111686
Trained batch 72 in epoch 7, gen_loss = 0.4505587065056579, disc_loss = 0.05045908828559395
Trained batch 73 in epoch 7, gen_loss = 0.4503581346692266, disc_loss = 0.05029580179551566
Trained batch 74 in epoch 7, gen_loss = 0.45090465982755024, disc_loss = 0.04993338774889708
Trained batch 75 in epoch 7, gen_loss = 0.45132483894887726, disc_loss = 0.04960842804346038
Trained batch 76 in epoch 7, gen_loss = 0.4513566822974713, disc_loss = 0.049061717223617934
Trained batch 77 in epoch 7, gen_loss = 0.45146454641452205, disc_loss = 0.04852261859923601
Trained batch 78 in epoch 7, gen_loss = 0.45141857937921454, disc_loss = 0.04865544720824006
Trained batch 79 in epoch 7, gen_loss = 0.45067408233880996, disc_loss = 0.048299725796096024
Trained batch 80 in epoch 7, gen_loss = 0.4502718617886673, disc_loss = 0.047791415083877464
Trained batch 81 in epoch 7, gen_loss = 0.4504108679730718, disc_loss = 0.04737510146550471
Trained batch 82 in epoch 7, gen_loss = 0.4500070404575532, disc_loss = 0.04686918105728116
Trained batch 83 in epoch 7, gen_loss = 0.45075004193044843, disc_loss = 0.04651901640907107
Trained batch 84 in epoch 7, gen_loss = 0.45087967409807095, disc_loss = 0.046085694580174544
Trained batch 85 in epoch 7, gen_loss = 0.4502082279948301, disc_loss = 0.045620298440849714
Trained batch 86 in epoch 7, gen_loss = 0.44982713392411156, disc_loss = 0.04515421620687877
Trained batch 87 in epoch 7, gen_loss = 0.4500902599909089, disc_loss = 0.04484083292878826
Trained batch 88 in epoch 7, gen_loss = 0.4501916494932068, disc_loss = 0.04444809581330988
Trained batch 89 in epoch 7, gen_loss = 0.45023540953795116, disc_loss = 0.04411670471438103
Trained batch 90 in epoch 7, gen_loss = 0.4500657477221646, disc_loss = 0.044304724056069014
Trained batch 91 in epoch 7, gen_loss = 0.4495978423434755, disc_loss = 0.04535558071675832
Trained batch 92 in epoch 7, gen_loss = 0.45007451791917125, disc_loss = 0.045778585267403436
Trained batch 93 in epoch 7, gen_loss = 0.4494978481150688, disc_loss = 0.04658078700502185
Trained batch 94 in epoch 7, gen_loss = 0.4479229895692123, disc_loss = 0.04757356860331799
Trained batch 95 in epoch 7, gen_loss = 0.4474737588316202, disc_loss = 0.04807369314949028
Trained batch 96 in epoch 7, gen_loss = 0.4478618748409232, disc_loss = 0.04782185979072273
Trained batch 97 in epoch 7, gen_loss = 0.447541389234212, disc_loss = 0.04933407483622432
Trained batch 98 in epoch 7, gen_loss = 0.4475546181201935, disc_loss = 0.04895511883866004
Trained batch 99 in epoch 7, gen_loss = 0.4464859160780907, disc_loss = 0.050043672593310475
Trained batch 100 in epoch 7, gen_loss = 0.44658210755574823, disc_loss = 0.049844737865473374
Trained batch 101 in epoch 7, gen_loss = 0.4467574290785135, disc_loss = 0.04961124120061012
Trained batch 102 in epoch 7, gen_loss = 0.44729138317617395, disc_loss = 0.04932293888109112
Trained batch 103 in epoch 7, gen_loss = 0.44669463628759754, disc_loss = 0.0489622248032202
Trained batch 104 in epoch 7, gen_loss = 0.4464474746159145, disc_loss = 0.04895414489188365
Trained batch 105 in epoch 7, gen_loss = 0.44633918410202245, disc_loss = 0.04877238220728512
Trained batch 106 in epoch 7, gen_loss = 0.44661130916292424, disc_loss = 0.04846943238593429
Trained batch 107 in epoch 7, gen_loss = 0.4472866444676011, disc_loss = 0.048563064722758204
Trained batch 108 in epoch 7, gen_loss = 0.44748862730253725, disc_loss = 0.048417608116949916
Trained batch 109 in epoch 7, gen_loss = 0.4477768274870786, disc_loss = 0.048138866666704416
Trained batch 110 in epoch 7, gen_loss = 0.44767055398709066, disc_loss = 0.04811144327358888
Trained batch 111 in epoch 7, gen_loss = 0.44767051429620813, disc_loss = 0.04790964174649811
Trained batch 112 in epoch 7, gen_loss = 0.4476086486757329, disc_loss = 0.04754009722130357
Trained batch 113 in epoch 7, gen_loss = 0.4472736282306805, disc_loss = 0.04718554930826813
Trained batch 114 in epoch 7, gen_loss = 0.4472698071728582, disc_loss = 0.04686571796951087
Trained batch 115 in epoch 7, gen_loss = 0.4473830232846326, disc_loss = 0.04656210743244095
Trained batch 116 in epoch 7, gen_loss = 0.4470239161935627, disc_loss = 0.04637978591311436
Trained batch 117 in epoch 7, gen_loss = 0.4469552499763036, disc_loss = 0.0460827997096388
Trained batch 118 in epoch 7, gen_loss = 0.44708358014331145, disc_loss = 0.04573455532746656
Trained batch 119 in epoch 7, gen_loss = 0.44699939886728923, disc_loss = 0.04546903256947796
Trained batch 120 in epoch 7, gen_loss = 0.4469979760075404, disc_loss = 0.04528908011280308
Trained batch 121 in epoch 7, gen_loss = 0.4468527675652113, disc_loss = 0.04500351224064094
Trained batch 122 in epoch 7, gen_loss = 0.44668685590348595, disc_loss = 0.04472451494264651
Trained batch 123 in epoch 7, gen_loss = 0.4470328683814695, disc_loss = 0.04451297320455553
Trained batch 124 in epoch 7, gen_loss = 0.44677925801277163, disc_loss = 0.0442159254476428
Trained batch 125 in epoch 7, gen_loss = 0.44689780852151295, disc_loss = 0.04417085720758353
Trained batch 126 in epoch 7, gen_loss = 0.4467989903266036, disc_loss = 0.04396890972806947
Trained batch 127 in epoch 7, gen_loss = 0.4473609991837293, disc_loss = 0.04380788672278868
Trained batch 128 in epoch 7, gen_loss = 0.4482554259688355, disc_loss = 0.04360502457982579
Trained batch 129 in epoch 7, gen_loss = 0.44820880568944493, disc_loss = 0.043604288386324276
Trained batch 130 in epoch 7, gen_loss = 0.44815152269283326, disc_loss = 0.04368875578813653
Trained batch 131 in epoch 7, gen_loss = 0.4479408291253177, disc_loss = 0.0435881517248962
Trained batch 132 in epoch 7, gen_loss = 0.4477864678641011, disc_loss = 0.04337753392615937
Trained batch 133 in epoch 7, gen_loss = 0.4478747515536066, disc_loss = 0.04317248354791038
Trained batch 134 in epoch 7, gen_loss = 0.4475911685714015, disc_loss = 0.042930749093216876
Trained batch 135 in epoch 7, gen_loss = 0.44763632140615406, disc_loss = 0.042650353923604334
Trained batch 136 in epoch 7, gen_loss = 0.4476635118905645, disc_loss = 0.042376183836727685
Trained batch 137 in epoch 7, gen_loss = 0.4479361966900203, disc_loss = 0.04213991807773709
Trained batch 138 in epoch 7, gen_loss = 0.44722948678963476, disc_loss = 0.042632879253825265
Trained batch 139 in epoch 7, gen_loss = 0.44723836800881794, disc_loss = 0.043392243908186044
Trained batch 140 in epoch 7, gen_loss = 0.4473148210251585, disc_loss = 0.04313707457696821
Trained batch 141 in epoch 7, gen_loss = 0.44674896774157674, disc_loss = 0.0429281585187402
Trained batch 142 in epoch 7, gen_loss = 0.4459034450404294, disc_loss = 0.0429003917468855
Trained batch 143 in epoch 7, gen_loss = 0.4457412333124214, disc_loss = 0.042666862851345085
Trained batch 144 in epoch 7, gen_loss = 0.44552533667663047, disc_loss = 0.042428294251319665
Trained batch 145 in epoch 7, gen_loss = 0.44551924442591734, disc_loss = 0.04221895490517865
Trained batch 146 in epoch 7, gen_loss = 0.44577053513656667, disc_loss = 0.04201817430467123
Trained batch 147 in epoch 7, gen_loss = 0.4457413306510126, disc_loss = 0.04243952125575192
Trained batch 148 in epoch 7, gen_loss = 0.44524984711768645, disc_loss = 0.042315903016609833
Trained batch 149 in epoch 7, gen_loss = 0.4457371842861175, disc_loss = 0.04214887589526673
Trained batch 150 in epoch 7, gen_loss = 0.44576575760020326, disc_loss = 0.04202528174855555
Trained batch 151 in epoch 7, gen_loss = 0.4455132988330565, disc_loss = 0.041844051824515
Trained batch 152 in epoch 7, gen_loss = 0.4456635306473651, disc_loss = 0.04167774344301399
Trained batch 153 in epoch 7, gen_loss = 0.4459453095476349, disc_loss = 0.04203424844951308
Trained batch 154 in epoch 7, gen_loss = 0.4460220673391896, disc_loss = 0.042282965878445294
Trained batch 155 in epoch 7, gen_loss = 0.4462680281736912, disc_loss = 0.04219036036206839
Trained batch 156 in epoch 7, gen_loss = 0.4466697102899005, disc_loss = 0.0421672083324735
Trained batch 157 in epoch 7, gen_loss = 0.4469769661185108, disc_loss = 0.04204861191690817
Trained batch 158 in epoch 7, gen_loss = 0.4472627156185654, disc_loss = 0.041849012354845706
Trained batch 159 in epoch 7, gen_loss = 0.44720618762075903, disc_loss = 0.041645580905606036
Trained batch 160 in epoch 7, gen_loss = 0.44717887876937107, disc_loss = 0.04172161448550243
Trained batch 161 in epoch 7, gen_loss = 0.4479042383623712, disc_loss = 0.041940628519327734
Trained batch 162 in epoch 7, gen_loss = 0.44814269308663585, disc_loss = 0.041810855295143425
Trained batch 163 in epoch 7, gen_loss = 0.44815018064365153, disc_loss = 0.041760905035317125
Trained batch 164 in epoch 7, gen_loss = 0.44822970032691956, disc_loss = 0.041550875706315944
Trained batch 165 in epoch 7, gen_loss = 0.4483380457722997, disc_loss = 0.04133201393310026
Trained batch 166 in epoch 7, gen_loss = 0.4482265118353381, disc_loss = 0.04113859857270818
Trained batch 167 in epoch 7, gen_loss = 0.44808313463415417, disc_loss = 0.04094517281988547
Trained batch 168 in epoch 7, gen_loss = 0.4478728750048304, disc_loss = 0.04079907663034264
Trained batch 169 in epoch 7, gen_loss = 0.4477854125639972, disc_loss = 0.04061942515785203
Trained batch 170 in epoch 7, gen_loss = 0.44733059458565294, disc_loss = 0.04046454328542564
Trained batch 171 in epoch 7, gen_loss = 0.44751796247654185, disc_loss = 0.04038742696866393
Trained batch 172 in epoch 7, gen_loss = 0.44818365212120764, disc_loss = 0.04024496822041928
Trained batch 173 in epoch 7, gen_loss = 0.4482234786639268, disc_loss = 0.040088755094671046
Trained batch 174 in epoch 7, gen_loss = 0.44820055178233553, disc_loss = 0.0399635119789413
Trained batch 175 in epoch 7, gen_loss = 0.4478078836744482, disc_loss = 0.039795420756986874
Trained batch 176 in epoch 7, gen_loss = 0.4476055669582496, disc_loss = 0.0396030274835431
Trained batch 177 in epoch 7, gen_loss = 0.44765355329165296, disc_loss = 0.03944955338211207
Trained batch 178 in epoch 7, gen_loss = 0.447518401805249, disc_loss = 0.03929083209547251
Trained batch 179 in epoch 7, gen_loss = 0.44747332980235416, disc_loss = 0.03915964962086744
Trained batch 180 in epoch 7, gen_loss = 0.44702911278160895, disc_loss = 0.038965288693733634
Trained batch 181 in epoch 7, gen_loss = 0.44736088795976325, disc_loss = 0.038777044628859385
Trained batch 182 in epoch 7, gen_loss = 0.4474487320972922, disc_loss = 0.03860182339284834
Trained batch 183 in epoch 7, gen_loss = 0.4473114502818688, disc_loss = 0.03842577726438479
Trained batch 184 in epoch 7, gen_loss = 0.44738855216954204, disc_loss = 0.03829275481402874
Trained batch 185 in epoch 7, gen_loss = 0.4474041700683614, disc_loss = 0.038163183497325066
Trained batch 186 in epoch 7, gen_loss = 0.44718407357440276, disc_loss = 0.03797830610640626
Trained batch 187 in epoch 7, gen_loss = 0.4468948132497199, disc_loss = 0.03780265790261725
Trained batch 188 in epoch 7, gen_loss = 0.44725592789195834, disc_loss = 0.037625164512998216
Trained batch 189 in epoch 7, gen_loss = 0.44707278515163223, disc_loss = 0.03744292855752926
Trained batch 190 in epoch 7, gen_loss = 0.44708163341926654, disc_loss = 0.03733260922270452
Trained batch 191 in epoch 7, gen_loss = 0.4471244889621933, disc_loss = 0.037154124946634205
Trained batch 192 in epoch 7, gen_loss = 0.44680468653150174, disc_loss = 0.037176864244613236
Trained batch 193 in epoch 7, gen_loss = 0.44658525964033974, disc_loss = 0.03700872673773082
Trained batch 194 in epoch 7, gen_loss = 0.44684452307529937, disc_loss = 0.03718906035288595
Trained batch 195 in epoch 7, gen_loss = 0.44661471247673035, disc_loss = 0.0376989956058999
Trained batch 196 in epoch 7, gen_loss = 0.44683492365222294, disc_loss = 0.03759777136407036
Trained batch 197 in epoch 7, gen_loss = 0.4472834895355533, disc_loss = 0.03753189274904817
Trained batch 198 in epoch 7, gen_loss = 0.44772038208180337, disc_loss = 0.0375274220123494
Trained batch 199 in epoch 7, gen_loss = 0.4477128627896309, disc_loss = 0.03738806204288267
Trained batch 200 in epoch 7, gen_loss = 0.4477193597240828, disc_loss = 0.037232918807291494
Trained batch 201 in epoch 7, gen_loss = 0.4477978093494283, disc_loss = 0.037068882093783284
Trained batch 202 in epoch 7, gen_loss = 0.4476869122441766, disc_loss = 0.036915643809344895
Trained batch 203 in epoch 7, gen_loss = 0.4474724671419929, disc_loss = 0.03675696657007268
Trained batch 204 in epoch 7, gen_loss = 0.44732597426670356, disc_loss = 0.03660243658871367
Trained batch 205 in epoch 7, gen_loss = 0.44719213377503514, disc_loss = 0.03643752346651683
Trained batch 206 in epoch 7, gen_loss = 0.4470426350975958, disc_loss = 0.03627703012561129
Trained batch 207 in epoch 7, gen_loss = 0.4472392755918778, disc_loss = 0.03612001904940161
Trained batch 208 in epoch 7, gen_loss = 0.4470387332177048, disc_loss = 0.03596128556547624
Trained batch 209 in epoch 7, gen_loss = 0.44718346141633536, disc_loss = 0.035805988877213424
Trained batch 210 in epoch 7, gen_loss = 0.44704814318797037, disc_loss = 0.03565614645576802
Trained batch 211 in epoch 7, gen_loss = 0.4470037341399013, disc_loss = 0.035501538236616705
Trained batch 212 in epoch 7, gen_loss = 0.4471079616199637, disc_loss = 0.03535316124702738
Trained batch 213 in epoch 7, gen_loss = 0.44743542930233143, disc_loss = 0.035218694502983906
Trained batch 214 in epoch 7, gen_loss = 0.44741432514301566, disc_loss = 0.035083352457082204
Trained batch 215 in epoch 7, gen_loss = 0.4474644845834485, disc_loss = 0.03494851879615992
Trained batch 216 in epoch 7, gen_loss = 0.4473631645677276, disc_loss = 0.034801657319128994
Trained batch 217 in epoch 7, gen_loss = 0.4470908701966662, disc_loss = 0.034655450397905886
Trained batch 218 in epoch 7, gen_loss = 0.44721772872149673, disc_loss = 0.03450860096924177
Trained batch 219 in epoch 7, gen_loss = 0.44704866761511025, disc_loss = 0.03436255895913663
Trained batch 220 in epoch 7, gen_loss = 0.44716362769787127, disc_loss = 0.03422174781742105
Trained batch 221 in epoch 7, gen_loss = 0.44697675498219225, disc_loss = 0.03407983953733131
Trained batch 222 in epoch 7, gen_loss = 0.4468152160869051, disc_loss = 0.03393517998193345
Trained batch 223 in epoch 7, gen_loss = 0.4465141859171646, disc_loss = 0.03381524901695749
Trained batch 224 in epoch 7, gen_loss = 0.44639420562320287, disc_loss = 0.03368712520019876
Trained batch 225 in epoch 7, gen_loss = 0.4463599349281429, disc_loss = 0.03356419774637747
Trained batch 226 in epoch 7, gen_loss = 0.44638622476665984, disc_loss = 0.033431920783988114
Trained batch 227 in epoch 7, gen_loss = 0.44639871740027476, disc_loss = 0.03329611602218887
Trained batch 228 in epoch 7, gen_loss = 0.446139691568358, disc_loss = 0.03316026542734306
Trained batch 229 in epoch 7, gen_loss = 0.4461540837650714, disc_loss = 0.03302902899196614
Trained batch 230 in epoch 7, gen_loss = 0.44592708800778247, disc_loss = 0.03289618065935515
Trained batch 231 in epoch 7, gen_loss = 0.44587036800281754, disc_loss = 0.032802750169829434
Trained batch 232 in epoch 7, gen_loss = 0.44610269962462235, disc_loss = 0.03270208086746509
Trained batch 233 in epoch 7, gen_loss = 0.44598240997546756, disc_loss = 0.03259847871760209
Trained batch 234 in epoch 7, gen_loss = 0.44592815003496533, disc_loss = 0.03248790085830904
Trained batch 235 in epoch 7, gen_loss = 0.4455808558959072, disc_loss = 0.03236203183522606
Trained batch 236 in epoch 7, gen_loss = 0.445547466916877, disc_loss = 0.03223933907469365
Trained batch 237 in epoch 7, gen_loss = 0.4452923170658721, disc_loss = 0.03212235684256155
Trained batch 238 in epoch 7, gen_loss = 0.4454108793366404, disc_loss = 0.032002798352725646
Trained batch 239 in epoch 7, gen_loss = 0.44553172116478285, disc_loss = 0.031886069865625664
Trained batch 240 in epoch 7, gen_loss = 0.4452469447836342, disc_loss = 0.03176953349961934
Trained batch 241 in epoch 7, gen_loss = 0.44512027625210027, disc_loss = 0.031654503626541104
Trained batch 242 in epoch 7, gen_loss = 0.44514071463066857, disc_loss = 0.03154703506858782
Trained batch 243 in epoch 7, gen_loss = 0.44523508431481534, disc_loss = 0.03145242664966824
Trained batch 244 in epoch 7, gen_loss = 0.4450424288000379, disc_loss = 0.031332432434951166
Trained batch 245 in epoch 7, gen_loss = 0.44522168251072486, disc_loss = 0.03123428999650769
Trained batch 246 in epoch 7, gen_loss = 0.4452006837375734, disc_loss = 0.031141493556199044
Trained batch 247 in epoch 7, gen_loss = 0.44536750307006223, disc_loss = 0.03103002510033548
Trained batch 248 in epoch 7, gen_loss = 0.44524668498211595, disc_loss = 0.03092031652317289
Trained batch 249 in epoch 7, gen_loss = 0.4453356908559799, disc_loss = 0.030817897638306023
Trained batch 250 in epoch 7, gen_loss = 0.4453308666607298, disc_loss = 0.030707026612889245
Trained batch 251 in epoch 7, gen_loss = 0.4452442600140496, disc_loss = 0.03060182729100306
Trained batch 252 in epoch 7, gen_loss = 0.44502143803321326, disc_loss = 0.030497016749628212
Trained batch 253 in epoch 7, gen_loss = 0.44486786706710424, disc_loss = 0.03038997177995272
Trained batch 254 in epoch 7, gen_loss = 0.4446714020242878, disc_loss = 0.03028675229562556
Trained batch 255 in epoch 7, gen_loss = 0.4445295352488756, disc_loss = 0.030179744790075347
Trained batch 256 in epoch 7, gen_loss = 0.44438089610073817, disc_loss = 0.03007394210562284
Trained batch 257 in epoch 7, gen_loss = 0.4442753325137057, disc_loss = 0.029965961277087817
Trained batch 258 in epoch 7, gen_loss = 0.4442439325527795, disc_loss = 0.029866083125084007
Trained batch 259 in epoch 7, gen_loss = 0.4439951473703751, disc_loss = 0.029759578235769787
Trained batch 260 in epoch 7, gen_loss = 0.4440565925676704, disc_loss = 0.02966019353236989
Trained batch 261 in epoch 7, gen_loss = 0.44395014677793926, disc_loss = 0.029557292083925248
Trained batch 262 in epoch 7, gen_loss = 0.4436607512684376, disc_loss = 0.02946207553817547
Trained batch 263 in epoch 7, gen_loss = 0.44363139140786545, disc_loss = 0.029363488639126335
Trained batch 264 in epoch 7, gen_loss = 0.443582801773863, disc_loss = 0.029267543636895012
Trained batch 265 in epoch 7, gen_loss = 0.4436152557233222, disc_loss = 0.02916735656125317
Trained batch 266 in epoch 7, gen_loss = 0.4434886502192708, disc_loss = 0.029070573370582824
Trained batch 267 in epoch 7, gen_loss = 0.4435416023010638, disc_loss = 0.02896877047657939
Trained batch 268 in epoch 7, gen_loss = 0.4432066049717616, disc_loss = 0.028876789183387028
Trained batch 269 in epoch 7, gen_loss = 0.4432910446767454, disc_loss = 0.02877804264684932
Trained batch 270 in epoch 7, gen_loss = 0.44325480260972167, disc_loss = 0.028684429139606792
Trained batch 271 in epoch 7, gen_loss = 0.44333894572713795, disc_loss = 0.02859013897336006
Trained batch 272 in epoch 7, gen_loss = 0.44349301014191067, disc_loss = 0.028521010105501548
Trained batch 273 in epoch 7, gen_loss = 0.44352249192060345, disc_loss = 0.028437446812201752
Trained batch 274 in epoch 7, gen_loss = 0.443535317290913, disc_loss = 0.028382217595353722
Trained batch 275 in epoch 7, gen_loss = 0.4435873991553334, disc_loss = 0.02830684767863916
Trained batch 276 in epoch 7, gen_loss = 0.44354811450634624, disc_loss = 0.028227362041243955
Trained batch 277 in epoch 7, gen_loss = 0.44326680426974946, disc_loss = 0.02815000583474665
Trained batch 278 in epoch 7, gen_loss = 0.44324970993089846, disc_loss = 0.028062733009584433
Trained batch 279 in epoch 7, gen_loss = 0.44303707224982125, disc_loss = 0.027973443043551274
Trained batch 280 in epoch 7, gen_loss = 0.44304722208145253, disc_loss = 0.027887259166707614
Trained batch 281 in epoch 7, gen_loss = 0.44271259707339267, disc_loss = 0.02780945567457098
Trained batch 282 in epoch 7, gen_loss = 0.4427264589724187, disc_loss = 0.027763095129011428
Trained batch 283 in epoch 7, gen_loss = 0.4427193346577631, disc_loss = 0.027681813476128424
Trained batch 284 in epoch 7, gen_loss = 0.4426252542880543, disc_loss = 0.02765597834970737
Trained batch 285 in epoch 7, gen_loss = 0.4426200711852187, disc_loss = 0.027609704315525615
Trained batch 286 in epoch 7, gen_loss = 0.4426924117973873, disc_loss = 0.02755558858658041
Trained batch 287 in epoch 7, gen_loss = 0.4426875139276187, disc_loss = 0.027502919061387528
Trained batch 288 in epoch 7, gen_loss = 0.44265928781981284, disc_loss = 0.027587096744207312
Trained batch 289 in epoch 7, gen_loss = 0.44255680935136205, disc_loss = 0.027769339604078437
Trained batch 290 in epoch 7, gen_loss = 0.4425239497443655, disc_loss = 0.02770506783190129
Trained batch 291 in epoch 7, gen_loss = 0.4423887807212464, disc_loss = 0.028087044778209794
Trained batch 292 in epoch 7, gen_loss = 0.4426287209214611, disc_loss = 0.028110821492200774
Trained batch 293 in epoch 7, gen_loss = 0.44237327879788924, disc_loss = 0.02807200561217381
Trained batch 294 in epoch 7, gen_loss = 0.44218224681029883, disc_loss = 0.027999718180241977
Trained batch 295 in epoch 7, gen_loss = 0.442127215600497, disc_loss = 0.027935937936638004
Trained batch 296 in epoch 7, gen_loss = 0.441920640091302, disc_loss = 0.02796694366277042
Trained batch 297 in epoch 7, gen_loss = 0.4418014622974716, disc_loss = 0.02794896597714607
Trained batch 298 in epoch 7, gen_loss = 0.4417234512675167, disc_loss = 0.028024365062541936
Trained batch 299 in epoch 7, gen_loss = 0.44169492145379385, disc_loss = 0.027960686304140836
Trained batch 300 in epoch 7, gen_loss = 0.44163341775685055, disc_loss = 0.027903533969971774
Trained batch 301 in epoch 7, gen_loss = 0.44145999325821733, disc_loss = 0.027904653211666998
Trained batch 302 in epoch 7, gen_loss = 0.44125665050528623, disc_loss = 0.02783245825755837
Trained batch 303 in epoch 7, gen_loss = 0.44151242734178114, disc_loss = 0.027807235093572864
Trained batch 304 in epoch 7, gen_loss = 0.4417528604874845, disc_loss = 0.027803025462618862
Trained batch 305 in epoch 7, gen_loss = 0.4417385242733301, disc_loss = 0.02772872408721109
Trained batch 306 in epoch 7, gen_loss = 0.44170013536071157, disc_loss = 0.027779833751151197
Trained batch 307 in epoch 7, gen_loss = 0.441677157271218, disc_loss = 0.02797422790975467
Trained batch 308 in epoch 7, gen_loss = 0.4415578771756305, disc_loss = 0.028130023086949892
Trained batch 309 in epoch 7, gen_loss = 0.44147753186764255, disc_loss = 0.028558626248981926
Trained batch 310 in epoch 7, gen_loss = 0.4414298098378626, disc_loss = 0.028640383196443655
Trained batch 311 in epoch 7, gen_loss = 0.44135689133634937, disc_loss = 0.02910128539765421
Trained batch 312 in epoch 7, gen_loss = 0.44142038020463037, disc_loss = 0.029125694251699617
Trained batch 313 in epoch 7, gen_loss = 0.44145043403100054, disc_loss = 0.029093233934473127
Trained batch 314 in epoch 7, gen_loss = 0.4414815222460126, disc_loss = 0.029037317051921807
Trained batch 315 in epoch 7, gen_loss = 0.4414690117104144, disc_loss = 0.028967549301583698
Trained batch 316 in epoch 7, gen_loss = 0.4414291937456522, disc_loss = 0.028947338563968847
Trained batch 317 in epoch 7, gen_loss = 0.44125162421157527, disc_loss = 0.028912358128746866
Trained batch 318 in epoch 7, gen_loss = 0.4413387065397161, disc_loss = 0.028837060378455678
Trained batch 319 in epoch 7, gen_loss = 0.44155631586909294, disc_loss = 0.028822885131376097
Trained batch 320 in epoch 7, gen_loss = 0.4421257439803483, disc_loss = 0.02874980933566772
Trained batch 321 in epoch 7, gen_loss = 0.44211411309538423, disc_loss = 0.028699706582589687
Trained batch 322 in epoch 7, gen_loss = 0.4422645162871748, disc_loss = 0.0286488215815299
Trained batch 323 in epoch 7, gen_loss = 0.44207080205281574, disc_loss = 0.02857029124631627
Trained batch 324 in epoch 7, gen_loss = 0.4420225019638355, disc_loss = 0.02849990479863034
Trained batch 325 in epoch 7, gen_loss = 0.4422350364045863, disc_loss = 0.02843897318556059
Trained batch 326 in epoch 7, gen_loss = 0.4423436711140729, disc_loss = 0.02836481125566778
Trained batch 327 in epoch 7, gen_loss = 0.4424574656820879, disc_loss = 0.0282935352730508
Trained batch 328 in epoch 7, gen_loss = 0.4426159836963317, disc_loss = 0.028274040205664593
Trained batch 329 in epoch 7, gen_loss = 0.4424685118776379, disc_loss = 0.02828340756241232
Trained batch 330 in epoch 7, gen_loss = 0.4423394391363841, disc_loss = 0.028214943964523898
Trained batch 331 in epoch 7, gen_loss = 0.442230373800519, disc_loss = 0.02820455916969285
Trained batch 332 in epoch 7, gen_loss = 0.442032107540795, disc_loss = 0.028220229399706552
Trained batch 333 in epoch 7, gen_loss = 0.4418263035620044, disc_loss = 0.02822499455741891
Trained batch 334 in epoch 7, gen_loss = 0.4419016882554809, disc_loss = 0.028279149232765855
Trained batch 335 in epoch 7, gen_loss = 0.44201441517188433, disc_loss = 0.028445800822477656
Trained batch 336 in epoch 7, gen_loss = 0.44215584446839123, disc_loss = 0.02851242651729029
Trained batch 337 in epoch 7, gen_loss = 0.4420153868974313, disc_loss = 0.028499209945442805
Trained batch 338 in epoch 7, gen_loss = 0.4418325600898371, disc_loss = 0.028522306015429287
Trained batch 339 in epoch 7, gen_loss = 0.4418321224696496, disc_loss = 0.02853227026609923
Trained batch 340 in epoch 7, gen_loss = 0.4416290977833208, disc_loss = 0.028504572044702962
Trained batch 341 in epoch 7, gen_loss = 0.4413878912465614, disc_loss = 0.02870154476721842
Trained batch 342 in epoch 7, gen_loss = 0.4413092906203979, disc_loss = 0.028749488848709547
Trained batch 343 in epoch 7, gen_loss = 0.4415396171253781, disc_loss = 0.02883444851072137
Trained batch 344 in epoch 7, gen_loss = 0.4415833322034366, disc_loss = 0.028865649595019825
Trained batch 345 in epoch 7, gen_loss = 0.4417075122884243, disc_loss = 0.028858034958325413
Trained batch 346 in epoch 7, gen_loss = 0.44181461662311716, disc_loss = 0.029118494933836097
Trained batch 347 in epoch 7, gen_loss = 0.44179990108328304, disc_loss = 0.02906215942702952
Trained batch 348 in epoch 7, gen_loss = 0.44164090323926386, disc_loss = 0.02936806056160149
Trained batch 349 in epoch 7, gen_loss = 0.44169307444776806, disc_loss = 0.029330559381549912
Trained batch 350 in epoch 7, gen_loss = 0.4416853579191061, disc_loss = 0.02952515999149754
Trained batch 351 in epoch 7, gen_loss = 0.4416880381547592, disc_loss = 0.02962564377296737
Trained batch 352 in epoch 7, gen_loss = 0.44184292181693124, disc_loss = 0.029566218924151982
Trained batch 353 in epoch 7, gen_loss = 0.4416100221165156, disc_loss = 0.029587015552356797
Trained batch 354 in epoch 7, gen_loss = 0.44146310544349776, disc_loss = 0.02975666898722485
Trained batch 355 in epoch 7, gen_loss = 0.44141315509763995, disc_loss = 0.02973975052892262
Trained batch 356 in epoch 7, gen_loss = 0.4412769027450839, disc_loss = 0.029927375437483108
Trained batch 357 in epoch 7, gen_loss = 0.44156089558281714, disc_loss = 0.029929614465231045
Trained batch 358 in epoch 7, gen_loss = 0.44146609580284374, disc_loss = 0.0298988295409019
Trained batch 359 in epoch 7, gen_loss = 0.44140290121237435, disc_loss = 0.029941446893563907
Trained batch 360 in epoch 7, gen_loss = 0.4414476461687907, disc_loss = 0.029889905168042824
Trained batch 361 in epoch 7, gen_loss = 0.4415889915017133, disc_loss = 0.029841521246106627
Trained batch 362 in epoch 7, gen_loss = 0.44151986064004506, disc_loss = 0.029775470277787118
Trained batch 363 in epoch 7, gen_loss = 0.44138066249561836, disc_loss = 0.029726018134509674
Trained batch 364 in epoch 7, gen_loss = 0.44125375192459315, disc_loss = 0.029667697676572284
Trained batch 365 in epoch 7, gen_loss = 0.44114254683744714, disc_loss = 0.029675549805250855
Trained batch 366 in epoch 7, gen_loss = 0.44096975268070315, disc_loss = 0.02967419072653215
Trained batch 367 in epoch 7, gen_loss = 0.4409264684047388, disc_loss = 0.029635779572898806
Trained batch 368 in epoch 7, gen_loss = 0.4409778466231132, disc_loss = 0.029581821034599328
Trained batch 369 in epoch 7, gen_loss = 0.4409478730446584, disc_loss = 0.029531777713674347
Trained batch 370 in epoch 7, gen_loss = 0.4410249946734333, disc_loss = 0.02947977674570226
Trained batch 371 in epoch 7, gen_loss = 0.44125309770786636, disc_loss = 0.02955915239421771
Trained batch 372 in epoch 7, gen_loss = 0.4410841523322599, disc_loss = 0.029557065177464172
Trained batch 373 in epoch 7, gen_loss = 0.44088201798538473, disc_loss = 0.02964267384990512
Trained batch 374 in epoch 7, gen_loss = 0.4409094175497691, disc_loss = 0.029585431360329192
Trained batch 375 in epoch 7, gen_loss = 0.44108262158771777, disc_loss = 0.029572806844334217
Trained batch 376 in epoch 7, gen_loss = 0.4411993821198491, disc_loss = 0.029516004728133587
Trained batch 377 in epoch 7, gen_loss = 0.44124049989003983, disc_loss = 0.0295042601277283
Trained batch 378 in epoch 7, gen_loss = 0.4411708195951809, disc_loss = 0.029445769391231495
Trained batch 379 in epoch 7, gen_loss = 0.4411735216253682, disc_loss = 0.02945483498777704
Trained batch 380 in epoch 7, gen_loss = 0.44138756198832996, disc_loss = 0.029443537193690267
Trained batch 381 in epoch 7, gen_loss = 0.44161467589633, disc_loss = 0.029408858979915645
Trained batch 382 in epoch 7, gen_loss = 0.44142316900407674, disc_loss = 0.029503549065552748
Trained batch 383 in epoch 7, gen_loss = 0.44129566429182887, disc_loss = 0.029460322939485195
Trained batch 384 in epoch 7, gen_loss = 0.44106946703675504, disc_loss = 0.029749814153032062
Trained batch 385 in epoch 7, gen_loss = 0.4411685476803409, disc_loss = 0.029707991110928204
Trained batch 386 in epoch 7, gen_loss = 0.4411973900111147, disc_loss = 0.029824939292304467
Trained batch 387 in epoch 7, gen_loss = 0.441448678598576, disc_loss = 0.029791539605135656
Trained batch 388 in epoch 7, gen_loss = 0.44138364114614254, disc_loss = 0.029749497542023697
Trained batch 389 in epoch 7, gen_loss = 0.441404887346121, disc_loss = 0.029726601512028047
Trained batch 390 in epoch 7, gen_loss = 0.44121443386882775, disc_loss = 0.029691813885808334
Trained batch 391 in epoch 7, gen_loss = 0.4411746218648492, disc_loss = 0.02962901637407153
Trained batch 392 in epoch 7, gen_loss = 0.4412728497241896, disc_loss = 0.02958050244914382
Trained batch 393 in epoch 7, gen_loss = 0.441274886128261, disc_loss = 0.02951966979727622
Trained batch 394 in epoch 7, gen_loss = 0.44125716950319993, disc_loss = 0.029477769830205208
Trained batch 395 in epoch 7, gen_loss = 0.4410896330620303, disc_loss = 0.02942493615138128
Trained batch 396 in epoch 7, gen_loss = 0.44087223832493166, disc_loss = 0.029976303098601307
Trained batch 397 in epoch 7, gen_loss = 0.44088023676345095, disc_loss = 0.029958572892130508
Trained batch 398 in epoch 7, gen_loss = 0.4409516473909966, disc_loss = 0.02993886959669005
Trained batch 399 in epoch 7, gen_loss = 0.4408411271870136, disc_loss = 0.029894154316862112
Trained batch 400 in epoch 7, gen_loss = 0.44060472404570356, disc_loss = 0.02993289673261976
Trained batch 401 in epoch 7, gen_loss = 0.4408075323152305, disc_loss = 0.029901562094693048
Trained batch 402 in epoch 7, gen_loss = 0.44108955972543723, disc_loss = 0.029929244020149556
Trained batch 403 in epoch 7, gen_loss = 0.44123409555690124, disc_loss = 0.02987159445413877
Trained batch 404 in epoch 7, gen_loss = 0.4411657429771659, disc_loss = 0.02988141126482299
Trained batch 405 in epoch 7, gen_loss = 0.4411096473045537, disc_loss = 0.029820040319679223
Trained batch 406 in epoch 7, gen_loss = 0.4411029037298676, disc_loss = 0.02975800481203861
Trained batch 407 in epoch 7, gen_loss = 0.44108395519502025, disc_loss = 0.02970959459073093
Trained batch 408 in epoch 7, gen_loss = 0.4410357245751873, disc_loss = 0.029646005355673306
Trained batch 409 in epoch 7, gen_loss = 0.44092379648511004, disc_loss = 0.029583347171386023
Trained batch 410 in epoch 7, gen_loss = 0.44099895471203937, disc_loss = 0.02954455132260828
Trained batch 411 in epoch 7, gen_loss = 0.4412320485537492, disc_loss = 0.02949786930202588
Trained batch 412 in epoch 7, gen_loss = 0.44124268908188935, disc_loss = 0.029439059778998355
Trained batch 413 in epoch 7, gen_loss = 0.4411905917568483, disc_loss = 0.02945214352550228
Trained batch 414 in epoch 7, gen_loss = 0.4410245738115655, disc_loss = 0.02948521439446114
Trained batch 415 in epoch 7, gen_loss = 0.440929276152299, disc_loss = 0.029428536881124064
Trained batch 416 in epoch 7, gen_loss = 0.4409047242977636, disc_loss = 0.029389878420596965
Trained batch 417 in epoch 7, gen_loss = 0.44090858030547364, disc_loss = 0.02958073429863579
Trained batch 418 in epoch 7, gen_loss = 0.44115438879532004, disc_loss = 0.030067497355916798
Trained batch 419 in epoch 7, gen_loss = 0.4411587266694932, disc_loss = 0.030063091620381566
Trained batch 420 in epoch 7, gen_loss = 0.44119571577624866, disc_loss = 0.030020015173195694
Trained batch 421 in epoch 7, gen_loss = 0.4410238229974186, disc_loss = 0.030045656103892385
Trained batch 422 in epoch 7, gen_loss = 0.44119534826447776, disc_loss = 0.029990092965159962
Trained batch 423 in epoch 7, gen_loss = 0.4413809753110949, disc_loss = 0.03009980977326192
Trained batch 424 in epoch 7, gen_loss = 0.4413017988906187, disc_loss = 0.030063060374711365
Trained batch 425 in epoch 7, gen_loss = 0.44107376262895376, disc_loss = 0.030341154140936202
Trained batch 426 in epoch 7, gen_loss = 0.4411436835133778, disc_loss = 0.03033570805837158
Trained batch 427 in epoch 7, gen_loss = 0.4411850745015055, disc_loss = 0.030441259079129722
Trained batch 428 in epoch 7, gen_loss = 0.44102998963602774, disc_loss = 0.030400337752862237
Trained batch 429 in epoch 7, gen_loss = 0.4410136019767717, disc_loss = 0.0307103467731585
Trained batch 430 in epoch 7, gen_loss = 0.4413356200863203, disc_loss = 0.030789188126084804
Trained batch 431 in epoch 7, gen_loss = 0.4414382122319054, disc_loss = 0.030748453536135558
Trained batch 432 in epoch 7, gen_loss = 0.44141970158449223, disc_loss = 0.030707173390899015
Trained batch 433 in epoch 7, gen_loss = 0.44150713299001965, disc_loss = 0.030681663211585292
Trained batch 434 in epoch 7, gen_loss = 0.4415188072741717, disc_loss = 0.03067215506105159
Trained batch 435 in epoch 7, gen_loss = 0.4414664193167599, disc_loss = 0.03068294866307459
Trained batch 436 in epoch 7, gen_loss = 0.4412649151798789, disc_loss = 0.03116841213319459
Trained batch 437 in epoch 7, gen_loss = 0.4410113798428888, disc_loss = 0.03141513709818783
Trained batch 438 in epoch 7, gen_loss = 0.4411672713544754, disc_loss = 0.031575216431751985
Trained batch 439 in epoch 7, gen_loss = 0.44105893847617234, disc_loss = 0.03179155636991544
Trained batch 440 in epoch 7, gen_loss = 0.4412399466886542, disc_loss = 0.03188741269369363
Trained batch 441 in epoch 7, gen_loss = 0.44112469040160807, disc_loss = 0.03200406206685342
Trained batch 442 in epoch 7, gen_loss = 0.4411558850624222, disc_loss = 0.032024867602983495
Trained batch 443 in epoch 7, gen_loss = 0.44133981364267366, disc_loss = 0.032221580567656435
Trained batch 444 in epoch 7, gen_loss = 0.44129985175775677, disc_loss = 0.032196892502330494
Trained batch 445 in epoch 7, gen_loss = 0.44116708729833765, disc_loss = 0.0322084061257466
Trained batch 446 in epoch 7, gen_loss = 0.44126976929788353, disc_loss = 0.03219910677036966
Trained batch 447 in epoch 7, gen_loss = 0.4413241893053055, disc_loss = 0.03239897356823868
Trained batch 448 in epoch 7, gen_loss = 0.44107103998252173, disc_loss = 0.032401071336091325
Trained batch 449 in epoch 7, gen_loss = 0.44093093044228027, disc_loss = 0.0326271638703636
Trained batch 450 in epoch 7, gen_loss = 0.4409514103258264, disc_loss = 0.03262252296308704
Trained batch 451 in epoch 7, gen_loss = 0.4409315944772906, disc_loss = 0.03270226552313919
Trained batch 452 in epoch 7, gen_loss = 0.4410039714761654, disc_loss = 0.03289140765986942
Trained batch 453 in epoch 7, gen_loss = 0.4409417028862999, disc_loss = 0.03283006181921974
Trained batch 454 in epoch 7, gen_loss = 0.44092110585380384, disc_loss = 0.03281218746196028
Trained batch 455 in epoch 7, gen_loss = 0.44084476712241505, disc_loss = 0.03276128396381657
Trained batch 456 in epoch 7, gen_loss = 0.44085106566646165, disc_loss = 0.03273316750891865
Trained batch 457 in epoch 7, gen_loss = 0.44088727287850527, disc_loss = 0.03272248722976846
Trained batch 458 in epoch 7, gen_loss = 0.4410663974311097, disc_loss = 0.032687105361700934
Trained batch 459 in epoch 7, gen_loss = 0.44112910511701003, disc_loss = 0.03266227394899191
Trained batch 460 in epoch 7, gen_loss = 0.4412559669085025, disc_loss = 0.032626251580492635
Trained batch 461 in epoch 7, gen_loss = 0.4410787220254089, disc_loss = 0.03258948621704965
Trained batch 462 in epoch 7, gen_loss = 0.44114722945520224, disc_loss = 0.032541872997371955
Trained batch 463 in epoch 7, gen_loss = 0.4410647721639995, disc_loss = 0.03255974797979559
Trained batch 464 in epoch 7, gen_loss = 0.44121186464063583, disc_loss = 0.03251146940684687
Trained batch 465 in epoch 7, gen_loss = 0.4412381138029017, disc_loss = 0.032492819611410824
Trained batch 466 in epoch 7, gen_loss = 0.4412267156407971, disc_loss = 0.03266221332479452
Trained batch 467 in epoch 7, gen_loss = 0.44127688735214055, disc_loss = 0.03264219339879262
Trained batch 468 in epoch 7, gen_loss = 0.44126722350049374, disc_loss = 0.032651216615297234
Trained batch 469 in epoch 7, gen_loss = 0.4412931807497714, disc_loss = 0.032637292790187004
Trained batch 470 in epoch 7, gen_loss = 0.44129875295987303, disc_loss = 0.03276098038034312
Trained batch 471 in epoch 7, gen_loss = 0.4412700192276704, disc_loss = 0.0327598781387077
Trained batch 472 in epoch 7, gen_loss = 0.4413242778616778, disc_loss = 0.03278716186693541
Trained batch 473 in epoch 7, gen_loss = 0.44115197759137376, disc_loss = 0.03288751310238591
Trained batch 474 in epoch 7, gen_loss = 0.4412964612559268, disc_loss = 0.03287297049782386
Trained batch 475 in epoch 7, gen_loss = 0.4413230683372802, disc_loss = 0.03294893230669623
Trained batch 476 in epoch 7, gen_loss = 0.4411538620040102, disc_loss = 0.03312132629542465
Trained batch 477 in epoch 7, gen_loss = 0.4411106191918441, disc_loss = 0.033154264047145686
Trained batch 478 in epoch 7, gen_loss = 0.44123505102567734, disc_loss = 0.03352936677827202
Trained batch 479 in epoch 7, gen_loss = 0.44120473774770896, disc_loss = 0.03382314032399639
Trained batch 480 in epoch 7, gen_loss = 0.441153790499713, disc_loss = 0.033769674457342455
Trained batch 481 in epoch 7, gen_loss = 0.44108898962434395, disc_loss = 0.03400155308094123
Trained batch 482 in epoch 7, gen_loss = 0.4410552326319874, disc_loss = 0.03412288388547798
Trained batch 483 in epoch 7, gen_loss = 0.4409236645649287, disc_loss = 0.034351210807900386
Trained batch 484 in epoch 7, gen_loss = 0.4410386723341401, disc_loss = 0.034559646446123415
Trained batch 485 in epoch 7, gen_loss = 0.440884624550372, disc_loss = 0.034512264563495085
Trained batch 486 in epoch 7, gen_loss = 0.44066486802923605, disc_loss = 0.034669144635109776
Trained batch 487 in epoch 7, gen_loss = 0.4407783760765537, disc_loss = 0.035197846417326754
Trained batch 488 in epoch 7, gen_loss = 0.4407464251805912, disc_loss = 0.03519710824645842
Trained batch 489 in epoch 7, gen_loss = 0.4406350025108882, disc_loss = 0.03533921937543747
Trained batch 490 in epoch 7, gen_loss = 0.4405294597877262, disc_loss = 0.03531262603429072
Trained batch 491 in epoch 7, gen_loss = 0.4404719325948537, disc_loss = 0.03540797866417125
Trained batch 492 in epoch 7, gen_loss = 0.44050320269611737, disc_loss = 0.03574318683736449
Trained batch 493 in epoch 7, gen_loss = 0.44043799360030095, disc_loss = 0.03572458574154343
Trained batch 494 in epoch 7, gen_loss = 0.44035347688077675, disc_loss = 0.03572963326557944
Trained batch 495 in epoch 7, gen_loss = 0.4402741712908591, disc_loss = 0.03573367425621742
Trained batch 496 in epoch 7, gen_loss = 0.4402577110699245, disc_loss = 0.03567941078468333
Trained batch 497 in epoch 7, gen_loss = 0.4403904526827326, disc_loss = 0.03565140829438411
Trained batch 498 in epoch 7, gen_loss = 0.44038717403918326, disc_loss = 0.035645806114422626
Trained batch 499 in epoch 7, gen_loss = 0.44026321172714233, disc_loss = 0.035602446522098034
Trained batch 500 in epoch 7, gen_loss = 0.44034378715379985, disc_loss = 0.036202818359305965
Trained batch 501 in epoch 7, gen_loss = 0.440361245219926, disc_loss = 0.036223921356667056
Trained batch 502 in epoch 7, gen_loss = 0.4402920370310486, disc_loss = 0.03641170193256059
Trained batch 503 in epoch 7, gen_loss = 0.4402172103051155, disc_loss = 0.03641717478453684
Trained batch 504 in epoch 7, gen_loss = 0.44012644290924074, disc_loss = 0.036740443371881794
Trained batch 505 in epoch 7, gen_loss = 0.4400061044414995, disc_loss = 0.03675778167048035
Trained batch 506 in epoch 7, gen_loss = 0.4400183502621434, disc_loss = 0.03670456592880807
Trained batch 507 in epoch 7, gen_loss = 0.439973283412419, disc_loss = 0.03666397075188955
Trained batch 508 in epoch 7, gen_loss = 0.43995538927717154, disc_loss = 0.03661662058526017
Trained batch 509 in epoch 7, gen_loss = 0.4398939711790459, disc_loss = 0.0366517614733026
Trained batch 510 in epoch 7, gen_loss = 0.4398776201236038, disc_loss = 0.03660027847129582
Trained batch 511 in epoch 7, gen_loss = 0.43982211622642353, disc_loss = 0.03654978949589349
Trained batch 512 in epoch 7, gen_loss = 0.43972276043706005, disc_loss = 0.03650253204870279
Trained batch 513 in epoch 7, gen_loss = 0.4397943959161929, disc_loss = 0.03646289139165242
Trained batch 514 in epoch 7, gen_loss = 0.43986334407213823, disc_loss = 0.03640240532327986
Trained batch 515 in epoch 7, gen_loss = 0.4399493537092394, disc_loss = 0.0363906589575841
Trained batch 516 in epoch 7, gen_loss = 0.4399795914411084, disc_loss = 0.03634069692316452
Trained batch 517 in epoch 7, gen_loss = 0.43995920283914075, disc_loss = 0.03633349516355292
Trained batch 518 in epoch 7, gen_loss = 0.4399855434320336, disc_loss = 0.036273271954835526
Trained batch 519 in epoch 7, gen_loss = 0.4400551175268797, disc_loss = 0.03623482794545663
Trained batch 520 in epoch 7, gen_loss = 0.4400950268111165, disc_loss = 0.03622812542200961
Trained batch 521 in epoch 7, gen_loss = 0.43995533284099625, disc_loss = 0.03624027084346889
Trained batch 522 in epoch 7, gen_loss = 0.4399788070819118, disc_loss = 0.03618948841707899
Trained batch 523 in epoch 7, gen_loss = 0.44009175936456857, disc_loss = 0.0361518258258224
Trained batch 524 in epoch 7, gen_loss = 0.4401631990500859, disc_loss = 0.03613352608689595
Trained batch 525 in epoch 7, gen_loss = 0.4402269041130298, disc_loss = 0.03615879294942328
Trained batch 526 in epoch 7, gen_loss = 0.44032639932361, disc_loss = 0.036135140458736885
Trained batch 527 in epoch 7, gen_loss = 0.44023854985381616, disc_loss = 0.03607904527973116
Trained batch 528 in epoch 7, gen_loss = 0.44009604312071054, disc_loss = 0.03602376639084197
Trained batch 529 in epoch 7, gen_loss = 0.44012477763418884, disc_loss = 0.035967041181734286
Trained batch 530 in epoch 7, gen_loss = 0.440003457603706, disc_loss = 0.035945663599143064
Trained batch 531 in epoch 7, gen_loss = 0.4401321923150156, disc_loss = 0.035985232171991184
Trained batch 532 in epoch 7, gen_loss = 0.440153804214542, disc_loss = 0.035988116922122594
Trained batch 533 in epoch 7, gen_loss = 0.4401049705480368, disc_loss = 0.036064745023347826
Trained batch 534 in epoch 7, gen_loss = 0.44017707087169183, disc_loss = 0.036079460405527015
Trained batch 535 in epoch 7, gen_loss = 0.4401991613654058, disc_loss = 0.03608684614517921
Trained batch 536 in epoch 7, gen_loss = 0.44015417124528017, disc_loss = 0.036096445788166294
Trained batch 537 in epoch 7, gen_loss = 0.4401908979429188, disc_loss = 0.03604646051885927
Trained batch 538 in epoch 7, gen_loss = 0.44021921603489456, disc_loss = 0.03599688247518341
Trained batch 539 in epoch 7, gen_loss = 0.44032933976915145, disc_loss = 0.03595753318190368
Trained batch 540 in epoch 7, gen_loss = 0.44038300130812386, disc_loss = 0.03605026183538001
Trained batch 541 in epoch 7, gen_loss = 0.4402796371506589, disc_loss = 0.03613719732347683
Trained batch 542 in epoch 7, gen_loss = 0.44020717435998374, disc_loss = 0.036099776552310885
Trained batch 543 in epoch 7, gen_loss = 0.4399817534448469, disc_loss = 0.03609218697195448
Trained batch 544 in epoch 7, gen_loss = 0.43997734161691926, disc_loss = 0.03607364110862238
Trained batch 545 in epoch 7, gen_loss = 0.4401472195600852, disc_loss = 0.036183201580397076
Trained batch 546 in epoch 7, gen_loss = 0.4401113328811673, disc_loss = 0.036167665538369545
Trained batch 547 in epoch 7, gen_loss = 0.44001524340714854, disc_loss = 0.03615825754007406
Trained batch 548 in epoch 7, gen_loss = 0.4399367218026264, disc_loss = 0.03617810694974099
Trained batch 549 in epoch 7, gen_loss = 0.439999655214223, disc_loss = 0.03614978326526894
Trained batch 550 in epoch 7, gen_loss = 0.44007962882626944, disc_loss = 0.03611781709310269
Trained batch 551 in epoch 7, gen_loss = 0.4401315492780312, disc_loss = 0.03608287947692746
Trained batch 552 in epoch 7, gen_loss = 0.4400569905424204, disc_loss = 0.03629525772305997
Trained batch 553 in epoch 7, gen_loss = 0.4400224391949306, disc_loss = 0.03637935442972713
Trained batch 554 in epoch 7, gen_loss = 0.4400575107819325, disc_loss = 0.03641331188321986
Trained batch 555 in epoch 7, gen_loss = 0.44014600567894874, disc_loss = 0.036394521978050605
Trained batch 556 in epoch 7, gen_loss = 0.4401593055823547, disc_loss = 0.03649440833996092
Trained batch 557 in epoch 7, gen_loss = 0.4401535604376092, disc_loss = 0.03650954706422437
Trained batch 558 in epoch 7, gen_loss = 0.440103015820754, disc_loss = 0.03651928966523403
Trained batch 559 in epoch 7, gen_loss = 0.4401782125234604, disc_loss = 0.03651227874756192
Trained batch 560 in epoch 7, gen_loss = 0.44026205373957833, disc_loss = 0.03663409380001512
Trained batch 561 in epoch 7, gen_loss = 0.4402644670306576, disc_loss = 0.03659689551247516
Trained batch 562 in epoch 7, gen_loss = 0.4402608591963936, disc_loss = 0.03663457239494985
Trained batch 563 in epoch 7, gen_loss = 0.44024707635877824, disc_loss = 0.03659889442352446
Trained batch 564 in epoch 7, gen_loss = 0.44036081021865914, disc_loss = 0.036574588121384775
Trained batch 565 in epoch 7, gen_loss = 0.4403774390266978, disc_loss = 0.03651823185083157
Trained batch 566 in epoch 7, gen_loss = 0.44040327176215155, disc_loss = 0.03646744408142117
Trained batch 567 in epoch 7, gen_loss = 0.44044624101108226, disc_loss = 0.03642472791408425
Trained batch 568 in epoch 7, gen_loss = 0.4403201428574292, disc_loss = 0.03637198754749957
Trained batch 569 in epoch 7, gen_loss = 0.44014666033418554, disc_loss = 0.036349763086049314
Trained batch 570 in epoch 7, gen_loss = 0.4401339228328598, disc_loss = 0.036318786153993886
Trained batch 571 in epoch 7, gen_loss = 0.44002234315747146, disc_loss = 0.036309169239439464
Trained batch 572 in epoch 7, gen_loss = 0.4399323544057044, disc_loss = 0.03660853444939938
Trained batch 573 in epoch 7, gen_loss = 0.44008824099439364, disc_loss = 0.03663806578197974
Trained batch 574 in epoch 7, gen_loss = 0.4400595720436262, disc_loss = 0.03686138852661395
Trained batch 575 in epoch 7, gen_loss = 0.44008277185882133, disc_loss = 0.03684946138471585
Trained batch 576 in epoch 7, gen_loss = 0.4399994064761613, disc_loss = 0.03707549336731137
Trained batch 577 in epoch 7, gen_loss = 0.4400946432434564, disc_loss = 0.037153621425346235
Trained batch 578 in epoch 7, gen_loss = 0.4401639626845589, disc_loss = 0.03731285391290172
Trained batch 579 in epoch 7, gen_loss = 0.44019036688681307, disc_loss = 0.03726657404090631
Trained batch 580 in epoch 7, gen_loss = 0.44017995937555876, disc_loss = 0.03724193640843534
Trained batch 581 in epoch 7, gen_loss = 0.4401659095512633, disc_loss = 0.03722585521876825
Trained batch 582 in epoch 7, gen_loss = 0.440191622765968, disc_loss = 0.03719643079020773
Trained batch 583 in epoch 7, gen_loss = 0.4401226429498359, disc_loss = 0.037163477440839886
Trained batch 584 in epoch 7, gen_loss = 0.4399598323381864, disc_loss = 0.03727011620624261
Trained batch 585 in epoch 7, gen_loss = 0.440010088804232, disc_loss = 0.03741725926953384
Trained batch 586 in epoch 7, gen_loss = 0.43996931056553906, disc_loss = 0.0375329633525
Trained batch 587 in epoch 7, gen_loss = 0.4398299177893165, disc_loss = 0.03767973176864147
Trained batch 588 in epoch 7, gen_loss = 0.43983464461635857, disc_loss = 0.037659461044347475
Trained batch 589 in epoch 7, gen_loss = 0.43993633475344057, disc_loss = 0.0378348099624233
Trained batch 590 in epoch 7, gen_loss = 0.43991029297841583, disc_loss = 0.03814573811844634
Trained batch 591 in epoch 7, gen_loss = 0.4399637132883072, disc_loss = 0.03821557747849855
Trained batch 592 in epoch 7, gen_loss = 0.4398826909507507, disc_loss = 0.03821450880411416
Trained batch 593 in epoch 7, gen_loss = 0.4398675308083043, disc_loss = 0.03830967675651477
Trained batch 594 in epoch 7, gen_loss = 0.43984641848492023, disc_loss = 0.03831151104845232
Trained batch 595 in epoch 7, gen_loss = 0.4399555259502974, disc_loss = 0.03834090657702541
Trained batch 596 in epoch 7, gen_loss = 0.4400154834915845, disc_loss = 0.0383622608661583
Trained batch 597 in epoch 7, gen_loss = 0.44010512117159406, disc_loss = 0.03832333845383858
Trained batch 598 in epoch 7, gen_loss = 0.44033232027779834, disc_loss = 0.03828465081603641
Testing Epoch 7
Training Epoch 8
------------------------------------------------------------
WARNING    : Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
SOURCE     : matplotlib.image.set_data
TIME STAMP : 2022-09-01 14:43:15,527
------------------------------------------------------------
------------------------------------------------------------
WARNING    : Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
SOURCE     : matplotlib.image.set_data
TIME STAMP : 2022-09-01 14:43:15,533
------------------------------------------------------------
Trained batch 0 in epoch 8, gen_loss = 0.4827047884464264, disc_loss = 0.013429433107376099
Trained batch 1 in epoch 8, gen_loss = 0.45314352214336395, disc_loss = 0.02288002520799637
Trained batch 2 in epoch 8, gen_loss = 0.4608118037382762, disc_loss = 0.01697830855846405
Trained batch 3 in epoch 8, gen_loss = 0.4653276056051254, disc_loss = 0.019175640307366848
Trained batch 4 in epoch 8, gen_loss = 0.4636714577674866, disc_loss = 0.01742299012839794
Trained batch 5 in epoch 8, gen_loss = 0.4604575534661611, disc_loss = 0.017794533011813957
Trained batch 6 in epoch 8, gen_loss = 0.4648729009287698, disc_loss = 0.018187712345804487
Trained batch 7 in epoch 8, gen_loss = 0.4672871381044388, disc_loss = 0.018117692787200212
Trained batch 8 in epoch 8, gen_loss = 0.47014401356379193, disc_loss = 0.016953678594695196
Trained batch 9 in epoch 8, gen_loss = 0.461667874455452, disc_loss = 0.016391133703291417
Trained batch 10 in epoch 8, gen_loss = 0.45816516605290497, disc_loss = 0.022312139414928177
Trained batch 11 in epoch 8, gen_loss = 0.4601241946220398, disc_loss = 0.026905398971090715
Trained batch 12 in epoch 8, gen_loss = 0.4592618873486152, disc_loss = 0.04878899813271486
Trained batch 13 in epoch 8, gen_loss = 0.4545063866036279, disc_loss = 0.06625452757413898
Trained batch 14 in epoch 8, gen_loss = 0.4549469808737437, disc_loss = 0.06339820710321267
Trained batch 15 in epoch 8, gen_loss = 0.4539380148053169, disc_loss = 0.0663920872611925
Trained batch 16 in epoch 8, gen_loss = 0.4504017233848572, disc_loss = 0.0665877815335989
Trained batch 17 in epoch 8, gen_loss = 0.44754478500949013, disc_loss = 0.06710414122790098
Trained batch 18 in epoch 8, gen_loss = 0.4495408770285155, disc_loss = 0.06402593449150261
Trained batch 19 in epoch 8, gen_loss = 0.4501819387078285, disc_loss = 0.06339592365548015
Trained batch 20 in epoch 8, gen_loss = 0.45090224345525104, disc_loss = 0.06365325967116016
Trained batch 21 in epoch 8, gen_loss = 0.4501038816842166, disc_loss = 0.061712505973198196
Trained batch 22 in epoch 8, gen_loss = 0.44827783366908197, disc_loss = 0.05925653016437655
Trained batch 23 in epoch 8, gen_loss = 0.4471367672085762, disc_loss = 0.05714621321142962
Trained batch 24 in epoch 8, gen_loss = 0.4427673208713532, disc_loss = 0.05555523615330458
Trained batch 25 in epoch 8, gen_loss = 0.44245340388554794, disc_loss = 0.053795102124030776
Trained batch 26 in epoch 8, gen_loss = 0.4421601957745022, disc_loss = 0.052052859113448195
Trained batch 27 in epoch 8, gen_loss = 0.4377914241382054, disc_loss = 0.05259045669143753
Trained batch 28 in epoch 8, gen_loss = 0.43597512923437975, disc_loss = 0.062376189109837187
Trained batch 29 in epoch 8, gen_loss = 0.4352920879920324, disc_loss = 0.0674801948480308
Trained batch 30 in epoch 8, gen_loss = 0.4349312984174298, disc_loss = 0.0673938314580629
Trained batch 31 in epoch 8, gen_loss = 0.4333437876775861, disc_loss = 0.06628070239094086
Trained batch 32 in epoch 8, gen_loss = 0.4342054905313434, disc_loss = 0.06530858285612229
Trained batch 33 in epoch 8, gen_loss = 0.4363061557797825, disc_loss = 0.06773019343724146
Trained batch 34 in epoch 8, gen_loss = 0.43843938623155865, disc_loss = 0.06620257158896753
Trained batch 35 in epoch 8, gen_loss = 0.4385998903049363, disc_loss = 0.06483099777768883
Trained batch 36 in epoch 8, gen_loss = 0.43854673972000946, disc_loss = 0.06324989531138861
Trained batch 37 in epoch 8, gen_loss = 0.436600798839017, disc_loss = 0.0625565687415043
Trained batch 38 in epoch 8, gen_loss = 0.4332362115383148, disc_loss = 0.06185147797879882
Trained batch 39 in epoch 8, gen_loss = 0.4331876181066036, disc_loss = 0.06094767107861117
Trained batch 40 in epoch 8, gen_loss = 0.43273629865995267, disc_loss = 0.06069135485307836
Trained batch 41 in epoch 8, gen_loss = 0.43053256117162253, disc_loss = 0.0647170781490526
Trained batch 42 in epoch 8, gen_loss = 0.4306408520354781, disc_loss = 0.06448410634427916
Trained batch 43 in epoch 8, gen_loss = 0.4309952198104425, disc_loss = 0.06343053472863341
Trained batch 44 in epoch 8, gen_loss = 0.43136713173654345, disc_loss = 0.06231888887575931
Trained batch 45 in epoch 8, gen_loss = 0.43039468643457995, disc_loss = 0.06120395604723498
Trained batch 46 in epoch 8, gen_loss = 0.42872531680350606, disc_loss = 0.06076030973146888
Trained batch 47 in epoch 8, gen_loss = 0.42920143778125447, disc_loss = 0.05968363390032513
Trained batch 48 in epoch 8, gen_loss = 0.43027089809884833, disc_loss = 0.059080003257080606
Trained batch 49 in epoch 8, gen_loss = 0.43019565880298616, disc_loss = 0.058080033520236614
Trained batch 50 in epoch 8, gen_loss = 0.42898179269304465, disc_loss = 0.05786908798686722
Trained batch 51 in epoch 8, gen_loss = 0.4295728882917991, disc_loss = 0.0569513380760327
Trained batch 52 in epoch 8, gen_loss = 0.430016872455489, disc_loss = 0.05643408387934543
Trained batch 53 in epoch 8, gen_loss = 0.4305189323646051, disc_loss = 0.055767482017270394
Trained batch 54 in epoch 8, gen_loss = 0.43034799586642875, disc_loss = 0.054958962962370024
Trained batch 55 in epoch 8, gen_loss = 0.4290718755551747, disc_loss = 0.055288451831854345
Trained batch 56 in epoch 8, gen_loss = 0.4300684730211894, disc_loss = 0.05532055116961138
Trained batch 57 in epoch 8, gen_loss = 0.4302244150433047, disc_loss = 0.054686574241274905
Trained batch 58 in epoch 8, gen_loss = 0.4300877118514756, disc_loss = 0.05430257311722232
Trained batch 59 in epoch 8, gen_loss = 0.430200357735157, disc_loss = 0.054417833724680044
Trained batch 60 in epoch 8, gen_loss = 0.43159057028958053, disc_loss = 0.05362822381840622
Trained batch 61 in epoch 8, gen_loss = 0.431658276146458, disc_loss = 0.053384714166543654
Trained batch 62 in epoch 8, gen_loss = 0.4309128849279313, disc_loss = 0.052606799292363345
Trained batch 63 in epoch 8, gen_loss = 0.43063308764249086, disc_loss = 0.05221644709672546
Trained batch 64 in epoch 8, gen_loss = 0.4306676250237685, disc_loss = 0.05150889722773662
Trained batch 65 in epoch 8, gen_loss = 0.43151837135806226, disc_loss = 0.05127653719462229
Trained batch 66 in epoch 8, gen_loss = 0.4336935504158931, disc_loss = 0.051009266206355236
Trained batch 67 in epoch 8, gen_loss = 0.4343222809188506, disc_loss = 0.05036146451226052
Trained batch 68 in epoch 8, gen_loss = 0.43573514015778253, disc_loss = 0.050087572439857155
Trained batch 69 in epoch 8, gen_loss = 0.43574995824268886, disc_loss = 0.049526683560439516
Trained batch 70 in epoch 8, gen_loss = 0.4359185049231623, disc_loss = 0.0489136517821798
Trained batch 71 in epoch 8, gen_loss = 0.43660736208160716, disc_loss = 0.04832019900722015
Trained batch 72 in epoch 8, gen_loss = 0.43753363947345786, disc_loss = 0.0482137955482794
Trained batch 73 in epoch 8, gen_loss = 0.43863404965078506, disc_loss = 0.04763404777701441
Trained batch 74 in epoch 8, gen_loss = 0.43875316182772317, disc_loss = 0.04709493951871991
Trained batch 75 in epoch 8, gen_loss = 0.43889980763196945, disc_loss = 0.046636502950844407
Trained batch 76 in epoch 8, gen_loss = 0.4389938890159904, disc_loss = 0.046187631404874
Trained batch 77 in epoch 8, gen_loss = 0.4390997542784764, disc_loss = 0.04568141785402519
Trained batch 78 in epoch 8, gen_loss = 0.43924737882010545, disc_loss = 0.04517501263136539
Trained batch 79 in epoch 8, gen_loss = 0.4396520100533962, disc_loss = 0.04468780419556424
Trained batch 80 in epoch 8, gen_loss = 0.4393531621238332, disc_loss = 0.044199976351480055
Trained batch 81 in epoch 8, gen_loss = 0.4389330257729786, disc_loss = 0.04374184917158833
Trained batch 82 in epoch 8, gen_loss = 0.43899367193141614, disc_loss = 0.04338410284639482
Trained batch 83 in epoch 8, gen_loss = 0.43909974254312967, disc_loss = 0.04301328284089409
Trained batch 84 in epoch 8, gen_loss = 0.43909404207678404, disc_loss = 0.0436050941948505
Trained batch 85 in epoch 8, gen_loss = 0.43893899959187177, disc_loss = 0.043227805788520465
Trained batch 86 in epoch 8, gen_loss = 0.4388962867616237, disc_loss = 0.042908428086974156
Trained batch 87 in epoch 8, gen_loss = 0.43902395936575805, disc_loss = 0.04246707675470547
Trained batch 88 in epoch 8, gen_loss = 0.43884558657581885, disc_loss = 0.04212864999021037
Trained batch 89 in epoch 8, gen_loss = 0.4391624712281757, disc_loss = 0.041713540819990964
Trained batch 90 in epoch 8, gen_loss = 0.4390899280270377, disc_loss = 0.04131803551565979
Trained batch 91 in epoch 8, gen_loss = 0.4393622136634329, disc_loss = 0.040976396260742586
Trained batch 92 in epoch 8, gen_loss = 0.4395758307749225, disc_loss = 0.040953373221019586
Trained batch 93 in epoch 8, gen_loss = 0.440306008813229, disc_loss = 0.041279785240940906
Trained batch 94 in epoch 8, gen_loss = 0.44088063083196943, disc_loss = 0.04104897854849696
Trained batch 95 in epoch 8, gen_loss = 0.44098891721417505, disc_loss = 0.04070021950853212
Trained batch 96 in epoch 8, gen_loss = 0.4414612703102151, disc_loss = 0.040469426407296324
Trained batch 97 in epoch 8, gen_loss = 0.4417148144269476, disc_loss = 0.040201710323251934
Trained batch 98 in epoch 8, gen_loss = 0.44227831502153414, disc_loss = 0.039918069911161154
Trained batch 99 in epoch 8, gen_loss = 0.44276812851428987, disc_loss = 0.03964337716344744
Trained batch 100 in epoch 8, gen_loss = 0.44287067917313905, disc_loss = 0.03947289637059416
Trained batch 101 in epoch 8, gen_loss = 0.44269119086218817, disc_loss = 0.039226259027297296
Trained batch 102 in epoch 8, gen_loss = 0.44250280938102204, disc_loss = 0.03891871586098399
Trained batch 103 in epoch 8, gen_loss = 0.44261185681590665, disc_loss = 0.03867616696516052
Trained batch 104 in epoch 8, gen_loss = 0.44234633843104043, disc_loss = 0.03837617588273826
Trained batch 105 in epoch 8, gen_loss = 0.44202271131974347, disc_loss = 0.03820830603341027
Trained batch 106 in epoch 8, gen_loss = 0.4414553578211882, disc_loss = 0.037909658543034415
Trained batch 107 in epoch 8, gen_loss = 0.4421857907264321, disc_loss = 0.037614961167693965
Trained batch 108 in epoch 8, gen_loss = 0.44216930018652467, disc_loss = 0.037303416470680896
Trained batch 109 in epoch 8, gen_loss = 0.4423391962593252, disc_loss = 0.03707893259865655
Trained batch 110 in epoch 8, gen_loss = 0.44256906144253844, disc_loss = 0.03678268979739834
Trained batch 111 in epoch 8, gen_loss = 0.44251834068979534, disc_loss = 0.03648851022548375
Trained batch 112 in epoch 8, gen_loss = 0.44254500702419114, disc_loss = 0.03621043294330284
Trained batch 113 in epoch 8, gen_loss = 0.4427303802548793, disc_loss = 0.03593829279691961
Trained batch 114 in epoch 8, gen_loss = 0.4429167586824168, disc_loss = 0.035689378442728646
Trained batch 115 in epoch 8, gen_loss = 0.44330669862443, disc_loss = 0.035546488716700596
Trained batch 116 in epoch 8, gen_loss = 0.4434405213747269, disc_loss = 0.03527629644705508
Trained batch 117 in epoch 8, gen_loss = 0.4435568191742493, disc_loss = 0.03509773184758437
Trained batch 118 in epoch 8, gen_loss = 0.4438130940709795, disc_loss = 0.034894214694568215
Trained batch 119 in epoch 8, gen_loss = 0.44364849279324214, disc_loss = 0.03463510132472341
Trained batch 120 in epoch 8, gen_loss = 0.44349789570185766, disc_loss = 0.03436978610063141
Trained batch 121 in epoch 8, gen_loss = 0.44322972414923495, disc_loss = 0.03421796810217812
Trained batch 122 in epoch 8, gen_loss = 0.44278380420149827, disc_loss = 0.03401004861495117
Trained batch 123 in epoch 8, gen_loss = 0.44244290503763384, disc_loss = 0.033762145652285504
Trained batch 124 in epoch 8, gen_loss = 0.44234711718559266, disc_loss = 0.03357385228574276
Trained batch 125 in epoch 8, gen_loss = 0.4424018207050505, disc_loss = 0.033360878700420024
Trained batch 126 in epoch 8, gen_loss = 0.44228459437062423, disc_loss = 0.03311999768429384
Trained batch 127 in epoch 8, gen_loss = 0.4421611267607659, disc_loss = 0.03294829113292508
Trained batch 128 in epoch 8, gen_loss = 0.44240267909774483, disc_loss = 0.03272450470560512
Trained batch 129 in epoch 8, gen_loss = 0.44238767944849455, disc_loss = 0.032547746161715345
Trained batch 130 in epoch 8, gen_loss = 0.44273279686920514, disc_loss = 0.03234575643694697
Trained batch 131 in epoch 8, gen_loss = 0.4429327335321542, disc_loss = 0.032167546722727515
Trained batch 132 in epoch 8, gen_loss = 0.44314910885982944, disc_loss = 0.03200327047265898
Trained batch 133 in epoch 8, gen_loss = 0.44332737575716047, disc_loss = 0.03180960894895912
Trained batch 134 in epoch 8, gen_loss = 0.4432118351812716, disc_loss = 0.03162176392765509
Trained batch 135 in epoch 8, gen_loss = 0.4427771495983881, disc_loss = 0.03141018147546086
Trained batch 136 in epoch 8, gen_loss = 0.44245971880690027, disc_loss = 0.03122610624804821
Trained batch 137 in epoch 8, gen_loss = 0.44220038967719977, disc_loss = 0.031163367687427588
Trained batch 138 in epoch 8, gen_loss = 0.44243724483380215, disc_loss = 0.030964836690963494
Trained batch 139 in epoch 8, gen_loss = 0.442648403772286, disc_loss = 0.030839200595593346
Trained batch 140 in epoch 8, gen_loss = 0.44263206158123963, disc_loss = 0.030665574372409188
Trained batch 141 in epoch 8, gen_loss = 0.44243609800305167, disc_loss = 0.030541149828858465
Trained batch 142 in epoch 8, gen_loss = 0.44233850269884495, disc_loss = 0.03040167931109094
Trained batch 143 in epoch 8, gen_loss = 0.4419931986679633, disc_loss = 0.0302517762320349
Trained batch 144 in epoch 8, gen_loss = 0.4419120761854895, disc_loss = 0.030134455450200315
Trained batch 145 in epoch 8, gen_loss = 0.4422576449913521, disc_loss = 0.02996899770119878
Trained batch 146 in epoch 8, gen_loss = 0.4424195005780175, disc_loss = 0.029921679581724564
Trained batch 147 in epoch 8, gen_loss = 0.44279397943535365, disc_loss = 0.02980241715763318
Trained batch 148 in epoch 8, gen_loss = 0.4432518738228203, disc_loss = 0.02967064124032005
Trained batch 149 in epoch 8, gen_loss = 0.4434238177537918, disc_loss = 0.029526308931720754
Trained batch 150 in epoch 8, gen_loss = 0.4432074431552003, disc_loss = 0.029529858918687858
Trained batch 151 in epoch 8, gen_loss = 0.4431806249838126, disc_loss = 0.029579277611398874
Trained batch 152 in epoch 8, gen_loss = 0.44352061608258414, disc_loss = 0.029469558855007384
Trained batch 153 in epoch 8, gen_loss = 0.4437540816022204, disc_loss = 0.029331305809621396
Trained batch 154 in epoch 8, gen_loss = 0.44448848962783816, disc_loss = 0.029221275077772238
Trained batch 155 in epoch 8, gen_loss = 0.4451906524407558, disc_loss = 0.02909033699110389
Trained batch 156 in epoch 8, gen_loss = 0.44500517408559276, disc_loss = 0.029137780250696715
Trained batch 157 in epoch 8, gen_loss = 0.4451010649717307, disc_loss = 0.029068880480171852
Trained batch 158 in epoch 8, gen_loss = 0.44544909360273827, disc_loss = 0.02894692237887227
Trained batch 159 in epoch 8, gen_loss = 0.44536841493099927, disc_loss = 0.02879204060736811
Trained batch 160 in epoch 8, gen_loss = 0.44529294097645683, disc_loss = 0.028652197520844407
Trained batch 161 in epoch 8, gen_loss = 0.44524614328955425, disc_loss = 0.02854932296337031
Trained batch 162 in epoch 8, gen_loss = 0.4452703251429131, disc_loss = 0.02839383558210191
Trained batch 163 in epoch 8, gen_loss = 0.44529080082003664, disc_loss = 0.028241547156784046
Trained batch 164 in epoch 8, gen_loss = 0.44558123819755785, disc_loss = 0.028090973342345518
Trained batch 165 in epoch 8, gen_loss = 0.4457276395286422, disc_loss = 0.027938872309266984
Trained batch 166 in epoch 8, gen_loss = 0.4455437049894276, disc_loss = 0.027807259625437373
Trained batch 167 in epoch 8, gen_loss = 0.44537905000504996, disc_loss = 0.02767812187916466
Trained batch 168 in epoch 8, gen_loss = 0.4453497902881464, disc_loss = 0.027542249751470144
Trained batch 169 in epoch 8, gen_loss = 0.4453897786491057, disc_loss = 0.027431640516528313
Trained batch 170 in epoch 8, gen_loss = 0.44570524964416236, disc_loss = 0.02735571074707989
Trained batch 171 in epoch 8, gen_loss = 0.44576332475556885, disc_loss = 0.02730029082293947
Trained batch 172 in epoch 8, gen_loss = 0.44582317657553394, disc_loss = 0.02721594002722316
Trained batch 173 in epoch 8, gen_loss = 0.44597894843967484, disc_loss = 0.027096770810841143
Trained batch 174 in epoch 8, gen_loss = 0.44641845396586827, disc_loss = 0.026995626028094973
Trained batch 175 in epoch 8, gen_loss = 0.44646527770568023, disc_loss = 0.026981770547784188
Trained batch 176 in epoch 8, gen_loss = 0.44612605911863723, disc_loss = 0.026936882317571315
Trained batch 177 in epoch 8, gen_loss = 0.4462375103422765, disc_loss = 0.026823735699120364
Trained batch 178 in epoch 8, gen_loss = 0.44636849617824875, disc_loss = 0.026743153992041364
Trained batch 179 in epoch 8, gen_loss = 0.445996399058236, disc_loss = 0.026610205290166455
Trained batch 180 in epoch 8, gen_loss = 0.4455577785468233, disc_loss = 0.026496182781134768
Trained batch 181 in epoch 8, gen_loss = 0.4456445874421151, disc_loss = 0.026393810091386704
Trained batch 182 in epoch 8, gen_loss = 0.4458889615991728, disc_loss = 0.026404011861008943
Trained batch 183 in epoch 8, gen_loss = 0.4459970471975596, disc_loss = 0.02642259767921844
Trained batch 184 in epoch 8, gen_loss = 0.4463230260320612, disc_loss = 0.026482322981983827
Trained batch 185 in epoch 8, gen_loss = 0.4464949816465378, disc_loss = 0.026386356445640247
Trained batch 186 in epoch 8, gen_loss = 0.4465489838531311, disc_loss = 0.026336176234999682
Trained batch 187 in epoch 8, gen_loss = 0.4469270869455439, disc_loss = 0.026294885365480677
Trained batch 188 in epoch 8, gen_loss = 0.44677838399296715, disc_loss = 0.02630336226269642
Trained batch 189 in epoch 8, gen_loss = 0.4466357656215367, disc_loss = 0.02625492928231037
Trained batch 190 in epoch 8, gen_loss = 0.4466523894776849, disc_loss = 0.026149065110647164
Trained batch 191 in epoch 8, gen_loss = 0.4469514046795666, disc_loss = 0.026312557309817446
Trained batch 192 in epoch 8, gen_loss = 0.4467505350940586, disc_loss = 0.026342319188292086
Trained batch 193 in epoch 8, gen_loss = 0.4467282064796723, disc_loss = 0.026380325378322033
Trained batch 194 in epoch 8, gen_loss = 0.4469572273584513, disc_loss = 0.02631335865873366
Trained batch 195 in epoch 8, gen_loss = 0.4472490030587936, disc_loss = 0.027358045952385102
Trained batch 196 in epoch 8, gen_loss = 0.447057005415108, disc_loss = 0.027336800639957266
Trained batch 197 in epoch 8, gen_loss = 0.4470537479477699, disc_loss = 0.027342509129084647
Trained batch 198 in epoch 8, gen_loss = 0.44771715983673555, disc_loss = 0.027275161750979684
Trained batch 199 in epoch 8, gen_loss = 0.44780342921614646, disc_loss = 0.027282516796840354
Trained batch 200 in epoch 8, gen_loss = 0.44776818245204525, disc_loss = 0.027251978241491007
Trained batch 201 in epoch 8, gen_loss = 0.44776830962388825, disc_loss = 0.027292726145328787
Trained batch 202 in epoch 8, gen_loss = 0.4476256831526169, disc_loss = 0.02722793570123246
Trained batch 203 in epoch 8, gen_loss = 0.44741616938628403, disc_loss = 0.02737225844483713
Trained batch 204 in epoch 8, gen_loss = 0.447116779554181, disc_loss = 0.027632022089120453
Trained batch 205 in epoch 8, gen_loss = 0.4470349692025231, disc_loss = 0.02758059181720561
Trained batch 206 in epoch 8, gen_loss = 0.4470614969442432, disc_loss = 0.0275710502376213
Trained batch 207 in epoch 8, gen_loss = 0.44715605618862003, disc_loss = 0.02755359866848896
Trained batch 208 in epoch 8, gen_loss = 0.44728243607653384, disc_loss = 0.02753233760216554
Trained batch 209 in epoch 8, gen_loss = 0.447146271665891, disc_loss = 0.02783751108439728
Trained batch 210 in epoch 8, gen_loss = 0.4472287575498011, disc_loss = 0.027927325538611172
Trained batch 211 in epoch 8, gen_loss = 0.4471911918723358, disc_loss = 0.027889033106269914
Trained batch 212 in epoch 8, gen_loss = 0.4466768833393222, disc_loss = 0.027897243413138487
Trained batch 213 in epoch 8, gen_loss = 0.4465709061266106, disc_loss = 0.027878717670574017
Trained batch 214 in epoch 8, gen_loss = 0.4465400828871616, disc_loss = 0.02778617502623346
Trained batch 215 in epoch 8, gen_loss = 0.44671133339956953, disc_loss = 0.027703402799993962
Trained batch 216 in epoch 8, gen_loss = 0.4465368245878527, disc_loss = 0.027637014233116663
Trained batch 217 in epoch 8, gen_loss = 0.4461209171135491, disc_loss = 0.028437879969314628
Trained batch 218 in epoch 8, gen_loss = 0.44582400882625145, disc_loss = 0.029353332343260378
Trained batch 219 in epoch 8, gen_loss = 0.4458233840086243, disc_loss = 0.02946625936839899
Trained batch 220 in epoch 8, gen_loss = 0.4457501322705282, disc_loss = 0.029519041358573337
Trained batch 221 in epoch 8, gen_loss = 0.4452688028146555, disc_loss = 0.029714062229965116
Trained batch 222 in epoch 8, gen_loss = 0.4450311318641286, disc_loss = 0.02968278100334041
Trained batch 223 in epoch 8, gen_loss = 0.444881148503295, disc_loss = 0.029744580029468386
Trained batch 224 in epoch 8, gen_loss = 0.44466230352719627, disc_loss = 0.029854474472295906
Trained batch 225 in epoch 8, gen_loss = 0.4441184356676794, disc_loss = 0.030058120969740625
Trained batch 226 in epoch 8, gen_loss = 0.44430157699774014, disc_loss = 0.03021570889890555
Trained batch 227 in epoch 8, gen_loss = 0.4440430830183782, disc_loss = 0.030219828079887583
Trained batch 228 in epoch 8, gen_loss = 0.4441378922181359, disc_loss = 0.030282393056191667
Trained batch 229 in epoch 8, gen_loss = 0.4440616129533104, disc_loss = 0.030719865104386016
Trained batch 230 in epoch 8, gen_loss = 0.4436162839204202, disc_loss = 0.03079986345583323
Trained batch 231 in epoch 8, gen_loss = 0.4436321713287255, disc_loss = 0.03073699960127826
Trained batch 232 in epoch 8, gen_loss = 0.4437730545138085, disc_loss = 0.030698825312426608
Trained batch 233 in epoch 8, gen_loss = 0.44367745518684387, disc_loss = 0.030611570362343937
Trained batch 234 in epoch 8, gen_loss = 0.4436847340553365, disc_loss = 0.030576536006868837
Trained batch 235 in epoch 8, gen_loss = 0.4435210407285367, disc_loss = 0.030503448816134704
Trained batch 236 in epoch 8, gen_loss = 0.44321549089649054, disc_loss = 0.030424204536120287
Trained batch 237 in epoch 8, gen_loss = 0.4432431345476824, disc_loss = 0.03038499236181222
Trained batch 238 in epoch 8, gen_loss = 0.4430000715924107, disc_loss = 0.03036414906207207
Trained batch 239 in epoch 8, gen_loss = 0.442688994978865, disc_loss = 0.030294325407400416
Trained batch 240 in epoch 8, gen_loss = 0.44253203309917843, disc_loss = 0.03025857827827118
Trained batch 241 in epoch 8, gen_loss = 0.4426644098413877, disc_loss = 0.03024980012031103
Trained batch 242 in epoch 8, gen_loss = 0.4425243637198774, disc_loss = 0.030189293136804865
Trained batch 243 in epoch 8, gen_loss = 0.4429540150478238, disc_loss = 0.030707427265206505
Trained batch 244 in epoch 8, gen_loss = 0.4428721914486009, disc_loss = 0.03146046367663966
Trained batch 245 in epoch 8, gen_loss = 0.442611797553737, disc_loss = 0.03189035133568464
Trained batch 246 in epoch 8, gen_loss = 0.4423911833328757, disc_loss = 0.03209134849893148
Trained batch 247 in epoch 8, gen_loss = 0.4424030767573464, disc_loss = 0.03221649941969513
Trained batch 248 in epoch 8, gen_loss = 0.4419954109144019, disc_loss = 0.032482554226268424
Trained batch 249 in epoch 8, gen_loss = 0.4416393966674805, disc_loss = 0.032658847550861535
Trained batch 250 in epoch 8, gen_loss = 0.4415975526509532, disc_loss = 0.032713498054740144
Trained batch 251 in epoch 8, gen_loss = 0.44172491346086773, disc_loss = 0.03284514649117011
Trained batch 252 in epoch 8, gen_loss = 0.4414811638504149, disc_loss = 0.03286185094501396
Trained batch 253 in epoch 8, gen_loss = 0.4413509103726214, disc_loss = 0.033047811189615056
Trained batch 254 in epoch 8, gen_loss = 0.4412136998831057, disc_loss = 0.03406972598339267
Trained batch 255 in epoch 8, gen_loss = 0.44113897520583123, disc_loss = 0.03431433409696183
Trained batch 256 in epoch 8, gen_loss = 0.4409293828075498, disc_loss = 0.034322990121769245
Trained batch 257 in epoch 8, gen_loss = 0.4409023905678313, disc_loss = 0.03427717962045973
Trained batch 258 in epoch 8, gen_loss = 0.4407419800528228, disc_loss = 0.03432886127263854
Trained batch 259 in epoch 8, gen_loss = 0.4408130658360628, disc_loss = 0.034388742928142445
Trained batch 260 in epoch 8, gen_loss = 0.4406833390623217, disc_loss = 0.034361957985429646
Trained batch 261 in epoch 8, gen_loss = 0.4407080732684099, disc_loss = 0.034377988338122105
Trained batch 262 in epoch 8, gen_loss = 0.4406705907769076, disc_loss = 0.03430838430629682
Trained batch 263 in epoch 8, gen_loss = 0.44095396848790575, disc_loss = 0.034258397644435085
Trained batch 264 in epoch 8, gen_loss = 0.44083338492321517, disc_loss = 0.034153453727200064
Trained batch 265 in epoch 8, gen_loss = 0.440686629118776, disc_loss = 0.03406682979101945
Trained batch 266 in epoch 8, gen_loss = 0.44057105018404985, disc_loss = 0.03396961987908051
Trained batch 267 in epoch 8, gen_loss = 0.44047509100454957, disc_loss = 0.0338575118959798
Trained batch 268 in epoch 8, gen_loss = 0.4403733064915611, disc_loss = 0.03388296363816413
Trained batch 269 in epoch 8, gen_loss = 0.44042520456843903, disc_loss = 0.03394658911576563
Trained batch 270 in epoch 8, gen_loss = 0.4404382406565536, disc_loss = 0.03408860163402321
Trained batch 271 in epoch 8, gen_loss = 0.4402523622574175, disc_loss = 0.03422837774012484
Trained batch 272 in epoch 8, gen_loss = 0.44046560104513344, disc_loss = 0.03453616539763471
Trained batch 273 in epoch 8, gen_loss = 0.4401403749293655, disc_loss = 0.03451126611733768
Trained batch 274 in epoch 8, gen_loss = 0.4401897838982669, disc_loss = 0.034428120445968075
Trained batch 275 in epoch 8, gen_loss = 0.4401001420573912, disc_loss = 0.03433330151998182
Trained batch 276 in epoch 8, gen_loss = 0.4401944296885053, disc_loss = 0.03441077581142825
Trained batch 277 in epoch 8, gen_loss = 0.44064488921234074, disc_loss = 0.03453517890210337
Trained batch 278 in epoch 8, gen_loss = 0.4403808060299111, disc_loss = 0.03468429612406399
Trained batch 279 in epoch 8, gen_loss = 0.4404122843274048, disc_loss = 0.03469001951577541
Trained batch 280 in epoch 8, gen_loss = 0.4404431252717123, disc_loss = 0.03471025501152507
Trained batch 281 in epoch 8, gen_loss = 0.4404959837172894, disc_loss = 0.03463037644351126
Trained batch 282 in epoch 8, gen_loss = 0.4405359010814357, disc_loss = 0.03461297117124308
Trained batch 283 in epoch 8, gen_loss = 0.44068867597781436, disc_loss = 0.03460092001847109
Trained batch 284 in epoch 8, gen_loss = 0.44061762680087174, disc_loss = 0.03488429229330729
Trained batch 285 in epoch 8, gen_loss = 0.4403832752804656, disc_loss = 0.034875417233223314
Trained batch 286 in epoch 8, gen_loss = 0.4404824348069234, disc_loss = 0.035173589825299195
Trained batch 287 in epoch 8, gen_loss = 0.4405309711065557, disc_loss = 0.03543632409047051
Trained batch 288 in epoch 8, gen_loss = 0.4408646056808815, disc_loss = 0.03555096924437087
Trained batch 289 in epoch 8, gen_loss = 0.4407934585521961, disc_loss = 0.03553427392376009
Trained batch 290 in epoch 8, gen_loss = 0.4406421971075314, disc_loss = 0.03580072400627395
Trained batch 291 in epoch 8, gen_loss = 0.440770612799958, disc_loss = 0.036053404965508115
Trained batch 292 in epoch 8, gen_loss = 0.4403410204034616, disc_loss = 0.0361611036394656
Trained batch 293 in epoch 8, gen_loss = 0.44029338272655905, disc_loss = 0.036125813022439626
Trained batch 294 in epoch 8, gen_loss = 0.4401165016626908, disc_loss = 0.0362194954978018
Trained batch 295 in epoch 8, gen_loss = 0.4399452115836981, disc_loss = 0.03624670986617865
Trained batch 296 in epoch 8, gen_loss = 0.43990968503935973, disc_loss = 0.036298688991083086
Trained batch 297 in epoch 8, gen_loss = 0.43993374995337237, disc_loss = 0.03629836657681446
Trained batch 298 in epoch 8, gen_loss = 0.439921122430559, disc_loss = 0.03632169187047136
Trained batch 299 in epoch 8, gen_loss = 0.43971709301074346, disc_loss = 0.03642623605905101
Trained batch 300 in epoch 8, gen_loss = 0.43970563463198387, disc_loss = 0.03645413688328303
Trained batch 301 in epoch 8, gen_loss = 0.4395688105103196, disc_loss = 0.03647361927749034
Trained batch 302 in epoch 8, gen_loss = 0.43955904746999835, disc_loss = 0.0365740883574443
Trained batch 303 in epoch 8, gen_loss = 0.439707006180757, disc_loss = 0.036959791311681714
Trained batch 304 in epoch 8, gen_loss = 0.43953580416616844, disc_loss = 0.03701601760141307
Trained batch 305 in epoch 8, gen_loss = 0.4398486219784793, disc_loss = 0.03696677922134233
Trained batch 306 in epoch 8, gen_loss = 0.4398626825902672, disc_loss = 0.03688391138866228
Trained batch 307 in epoch 8, gen_loss = 0.4398321845121198, disc_loss = 0.03694067427105355
Trained batch 308 in epoch 8, gen_loss = 0.4397448731471805, disc_loss = 0.0368945645356798
Trained batch 309 in epoch 8, gen_loss = 0.4395891482791593, disc_loss = 0.03682214707031005
Trained batch 310 in epoch 8, gen_loss = 0.43947642993697017, disc_loss = 0.03672814855301136
Trained batch 311 in epoch 8, gen_loss = 0.4392271371415028, disc_loss = 0.03663853861358709
Trained batch 312 in epoch 8, gen_loss = 0.43925993035014826, disc_loss = 0.036603051238505845
Trained batch 313 in epoch 8, gen_loss = 0.4391026928736146, disc_loss = 0.03682167017550629
Trained batch 314 in epoch 8, gen_loss = 0.43904874769468155, disc_loss = 0.03702210633542448
Trained batch 315 in epoch 8, gen_loss = 0.43908593407537366, disc_loss = 0.03706025809441587
Trained batch 316 in epoch 8, gen_loss = 0.43905634045224834, disc_loss = 0.03699283083028245
Trained batch 317 in epoch 8, gen_loss = 0.4388956479119055, disc_loss = 0.03699350657905071
Trained batch 318 in epoch 8, gen_loss = 0.4390630694952878, disc_loss = 0.036913029508676885
Trained batch 319 in epoch 8, gen_loss = 0.43901523053646085, disc_loss = 0.03683893172201351
Trained batch 320 in epoch 8, gen_loss = 0.4390136913347096, disc_loss = 0.03704002155266656
Trained batch 321 in epoch 8, gen_loss = 0.4388186294839989, disc_loss = 0.03701215752571104
Trained batch 322 in epoch 8, gen_loss = 0.43869258892425445, disc_loss = 0.03717515190080062
Trained batch 323 in epoch 8, gen_loss = 0.43878287104544816, disc_loss = 0.03714934084923754
Trained batch 324 in epoch 8, gen_loss = 0.43895487822019136, disc_loss = 0.037139636889243356
Trained batch 325 in epoch 8, gen_loss = 0.43874707443216826, disc_loss = 0.037125760955776035
Trained batch 326 in epoch 8, gen_loss = 0.4389330748388891, disc_loss = 0.037169375292392906
Trained batch 327 in epoch 8, gen_loss = 0.43911999136936375, disc_loss = 0.037181135066131854
Trained batch 328 in epoch 8, gen_loss = 0.4391600475122863, disc_loss = 0.037118301455831684
Trained batch 329 in epoch 8, gen_loss = 0.43887924353281654, disc_loss = 0.03709955469803941
Trained batch 330 in epoch 8, gen_loss = 0.43882015572573846, disc_loss = 0.03704895734508434
Trained batch 331 in epoch 8, gen_loss = 0.43887453651930913, disc_loss = 0.03696301363826539
Trained batch 332 in epoch 8, gen_loss = 0.43901057178909714, disc_loss = 0.037056556556726225
Trained batch 333 in epoch 8, gen_loss = 0.4389515105121864, disc_loss = 0.03704799867645018
Trained batch 334 in epoch 8, gen_loss = 0.43888936380841836, disc_loss = 0.037007682001106997
Trained batch 335 in epoch 8, gen_loss = 0.4389695382366578, disc_loss = 0.03694055594539913
Trained batch 336 in epoch 8, gen_loss = 0.43924353287198775, disc_loss = 0.03712893391611159
Trained batch 337 in epoch 8, gen_loss = 0.4391385847647515, disc_loss = 0.03716562269875482
Trained batch 338 in epoch 8, gen_loss = 0.4394243032531401, disc_loss = 0.037085708819335234
Trained batch 339 in epoch 8, gen_loss = 0.4395720990265117, disc_loss = 0.03706385950790718
Trained batch 340 in epoch 8, gen_loss = 0.43969418785788794, disc_loss = 0.037011906002782
Trained batch 341 in epoch 8, gen_loss = 0.4397167113789341, disc_loss = 0.0370602133358442
Trained batch 342 in epoch 8, gen_loss = 0.4397593540283403, disc_loss = 0.03700779945964303
Trained batch 343 in epoch 8, gen_loss = 0.4395478262111198, disc_loss = 0.03694292897058023
Trained batch 344 in epoch 8, gen_loss = 0.43937682820403057, disc_loss = 0.03715710729104129
Trained batch 345 in epoch 8, gen_loss = 0.43938270219833175, disc_loss = 0.037211329547682984
Trained batch 346 in epoch 8, gen_loss = 0.4396891546695995, disc_loss = 0.03744378100385519
Trained batch 347 in epoch 8, gen_loss = 0.4395776845771691, disc_loss = 0.03761341798068399
Trained batch 348 in epoch 8, gen_loss = 0.4396484538613896, disc_loss = 0.03758928821859801
Trained batch 349 in epoch 8, gen_loss = 0.4395660540035793, disc_loss = 0.03757847423598702
Trained batch 350 in epoch 8, gen_loss = 0.4396248360474904, disc_loss = 0.037512324262872085
Trained batch 351 in epoch 8, gen_loss = 0.4395636489445513, disc_loss = 0.03757545079001416
Trained batch 352 in epoch 8, gen_loss = 0.4395663385350711, disc_loss = 0.03790954221897461
Trained batch 353 in epoch 8, gen_loss = 0.43963867627968223, disc_loss = 0.03781716379607991
Trained batch 354 in epoch 8, gen_loss = 0.4393802008998226, disc_loss = 0.0382786132637936
Trained batch 355 in epoch 8, gen_loss = 0.43946170145541097, disc_loss = 0.038323215704039786
Trained batch 356 in epoch 8, gen_loss = 0.43966092524074374, disc_loss = 0.03843544547039108
Trained batch 357 in epoch 8, gen_loss = 0.43965311423360304, disc_loss = 0.038636448437363614
Trained batch 358 in epoch 8, gen_loss = 0.4396015506932994, disc_loss = 0.03931067915423189
Trained batch 359 in epoch 8, gen_loss = 0.43950323743952646, disc_loss = 0.03939817790265402
Trained batch 360 in epoch 8, gen_loss = 0.43944004978829804, disc_loss = 0.03968348152164133
Trained batch 361 in epoch 8, gen_loss = 0.4394092767278134, disc_loss = 0.04010964920088258
Trained batch 362 in epoch 8, gen_loss = 0.43916983955819416, disc_loss = 0.04033258961983148
Trained batch 363 in epoch 8, gen_loss = 0.43920600176840036, disc_loss = 0.04053331795212516
Trained batch 364 in epoch 8, gen_loss = 0.4391435195321906, disc_loss = 0.04063503430224955
Trained batch 365 in epoch 8, gen_loss = 0.4391907184827523, disc_loss = 0.04065565083270048
Trained batch 366 in epoch 8, gen_loss = 0.43934987278335424, disc_loss = 0.04064083718872383
Trained batch 367 in epoch 8, gen_loss = 0.4392771648000116, disc_loss = 0.04063120938182059
Trained batch 368 in epoch 8, gen_loss = 0.43929939113335237, disc_loss = 0.040567876536999815
Trained batch 369 in epoch 8, gen_loss = 0.43920986241585497, disc_loss = 0.04058446860305864
Trained batch 370 in epoch 8, gen_loss = 0.4392909564258596, disc_loss = 0.04055130904266797
Trained batch 371 in epoch 8, gen_loss = 0.43926528016085264, disc_loss = 0.040550867484266596
Trained batch 372 in epoch 8, gen_loss = 0.43920134083834794, disc_loss = 0.040551195563448855
Trained batch 373 in epoch 8, gen_loss = 0.43918322512810243, disc_loss = 0.04048007626377823
Trained batch 374 in epoch 8, gen_loss = 0.43909485840797424, disc_loss = 0.040473758412525054
Trained batch 375 in epoch 8, gen_loss = 0.4391149298307743, disc_loss = 0.04042228126831531
Trained batch 376 in epoch 8, gen_loss = 0.4394072909253978, disc_loss = 0.04045298677592462
Trained batch 377 in epoch 8, gen_loss = 0.4393847416002284, disc_loss = 0.040379059558276024
Trained batch 378 in epoch 8, gen_loss = 0.4392368828872892, disc_loss = 0.04030263083888645
Trained batch 379 in epoch 8, gen_loss = 0.4390799595337165, disc_loss = 0.04034305677663437
Trained batch 380 in epoch 8, gen_loss = 0.4391299156848527, disc_loss = 0.04028050918828725
Trained batch 381 in epoch 8, gen_loss = 0.4393109211902968, disc_loss = 0.040613874720521664
Trained batch 382 in epoch 8, gen_loss = 0.4391246076974794, disc_loss = 0.04075095131956819
Trained batch 383 in epoch 8, gen_loss = 0.4391398682879905, disc_loss = 0.04094711406469287
Trained batch 384 in epoch 8, gen_loss = 0.43923307347607304, disc_loss = 0.04097002427843581
Trained batch 385 in epoch 8, gen_loss = 0.43919727484179283, disc_loss = 0.0418365049601769
Trained batch 386 in epoch 8, gen_loss = 0.43906342359476314, disc_loss = 0.042460125397520206
Trained batch 387 in epoch 8, gen_loss = 0.43911789503601406, disc_loss = 0.04250212010421032
Trained batch 388 in epoch 8, gen_loss = 0.439224929153766, disc_loss = 0.042587114929563935
Trained batch 389 in epoch 8, gen_loss = 0.4390289144638257, disc_loss = 0.0425433389036558
Trained batch 390 in epoch 8, gen_loss = 0.43885119621406127, disc_loss = 0.04246450226117983
Trained batch 391 in epoch 8, gen_loss = 0.43870466194894847, disc_loss = 0.042487856077282136
Trained batch 392 in epoch 8, gen_loss = 0.43865785563871756, disc_loss = 0.042436129463902905
Trained batch 393 in epoch 8, gen_loss = 0.43868916946921854, disc_loss = 0.0425958835672313
Trained batch 394 in epoch 8, gen_loss = 0.4386400296718259, disc_loss = 0.04255282202252199
Trained batch 395 in epoch 8, gen_loss = 0.4385554427751387, disc_loss = 0.04256532401977709
Trained batch 396 in epoch 8, gen_loss = 0.43856191500007957, disc_loss = 0.042497472261062236
Trained batch 397 in epoch 8, gen_loss = 0.43860235712935575, disc_loss = 0.042445522752337754
Trained batch 398 in epoch 8, gen_loss = 0.4384719194624956, disc_loss = 0.042510986025270106
Trained batch 399 in epoch 8, gen_loss = 0.43845770694315434, disc_loss = 0.04243947814044077
Trained batch 400 in epoch 8, gen_loss = 0.43833104511746146, disc_loss = 0.04243097072316245
Trained batch 401 in epoch 8, gen_loss = 0.43832152281234515, disc_loss = 0.0424149801649978
Trained batch 402 in epoch 8, gen_loss = 0.4383634403532847, disc_loss = 0.0424544287749587
Trained batch 403 in epoch 8, gen_loss = 0.4383346884705053, disc_loss = 0.04236576560767146
Trained batch 404 in epoch 8, gen_loss = 0.43831906966221185, disc_loss = 0.04230529623922467
Trained batch 405 in epoch 8, gen_loss = 0.438242529413383, disc_loss = 0.04221506531893968
Trained batch 406 in epoch 8, gen_loss = 0.43818065179946675, disc_loss = 0.042129823652551454
Trained batch 407 in epoch 8, gen_loss = 0.4380878275808166, disc_loss = 0.042209178759994935
Trained batch 408 in epoch 8, gen_loss = 0.43811207885847114, disc_loss = 0.042132357088165824
Trained batch 409 in epoch 8, gen_loss = 0.43804136856300074, disc_loss = 0.0424770314638253
Trained batch 410 in epoch 8, gen_loss = 0.43833573550493465, disc_loss = 0.042512737036118436
Trained batch 411 in epoch 8, gen_loss = 0.43835317198801965, disc_loss = 0.042520668966248086
Trained batch 412 in epoch 8, gen_loss = 0.4382979602126752, disc_loss = 0.04246402428413293
Trained batch 413 in epoch 8, gen_loss = 0.43830048656406034, disc_loss = 0.042438999649051776
Trained batch 414 in epoch 8, gen_loss = 0.4381040656422994, disc_loss = 0.042400998180642364
Trained batch 415 in epoch 8, gen_loss = 0.4380315671889828, disc_loss = 0.04243378805795846
Trained batch 416 in epoch 8, gen_loss = 0.43804128200030157, disc_loss = 0.042486153443051365
Trained batch 417 in epoch 8, gen_loss = 0.4381367794492028, disc_loss = 0.04240610037928082
Trained batch 418 in epoch 8, gen_loss = 0.4379873706788038, disc_loss = 0.04234428485124183
Trained batch 419 in epoch 8, gen_loss = 0.4380639026562373, disc_loss = 0.04226227948674932
Trained batch 420 in epoch 8, gen_loss = 0.4380806489115373, disc_loss = 0.04221646094887192
Trained batch 421 in epoch 8, gen_loss = 0.4381189940947492, disc_loss = 0.042132211454605495
Trained batch 422 in epoch 8, gen_loss = 0.43814907154292926, disc_loss = 0.04204886425429642
Trained batch 423 in epoch 8, gen_loss = 0.43793979561272656, disc_loss = 0.0419803606505497
Trained batch 424 in epoch 8, gen_loss = 0.4377778708934784, disc_loss = 0.042006721451111576
Trained batch 425 in epoch 8, gen_loss = 0.43783994872525267, disc_loss = 0.04195921285954597
Trained batch 426 in epoch 8, gen_loss = 0.4377728163218889, disc_loss = 0.04190831808798643
Trained batch 427 in epoch 8, gen_loss = 0.43787377870807026, disc_loss = 0.04184016184587571
Trained batch 428 in epoch 8, gen_loss = 0.43795627390310204, disc_loss = 0.041760872581122675
Trained batch 429 in epoch 8, gen_loss = 0.4379345229198766, disc_loss = 0.04171038310769079
Trained batch 430 in epoch 8, gen_loss = 0.4380564445547604, disc_loss = 0.04165367799456687
Trained batch 431 in epoch 8, gen_loss = 0.43801246728334164, disc_loss = 0.041579682164916046
Trained batch 432 in epoch 8, gen_loss = 0.4380241679264271, disc_loss = 0.0414943112448658
Trained batch 433 in epoch 8, gen_loss = 0.4383924985261557, disc_loss = 0.04157341031351208
Trained batch 434 in epoch 8, gen_loss = 0.4383784372231056, disc_loss = 0.041523411861974106
Trained batch 435 in epoch 8, gen_loss = 0.4381925560055523, disc_loss = 0.041456479998412246
Trained batch 436 in epoch 8, gen_loss = 0.43797009467260245, disc_loss = 0.041372887019251285
Trained batch 437 in epoch 8, gen_loss = 0.43814248316092036, disc_loss = 0.041292936584197804
Trained batch 438 in epoch 8, gen_loss = 0.4380212329107428, disc_loss = 0.04121495920428603
Trained batch 439 in epoch 8, gen_loss = 0.43796974698250946, disc_loss = 0.04114064782572148
Trained batch 440 in epoch 8, gen_loss = 0.43794686277977735, disc_loss = 0.04106183473576207
Trained batch 441 in epoch 8, gen_loss = 0.4379737199836187, disc_loss = 0.04097965404094193
Trained batch 442 in epoch 8, gen_loss = 0.43801848250640973, disc_loss = 0.04105193901788149
Trained batch 443 in epoch 8, gen_loss = 0.4379094318226651, disc_loss = 0.04105250600899511
Trained batch 444 in epoch 8, gen_loss = 0.43798290792475925, disc_loss = 0.041094231142484575
Trained batch 445 in epoch 8, gen_loss = 0.4379993548842289, disc_loss = 0.0411310165743615
Trained batch 446 in epoch 8, gen_loss = 0.4381922786134468, disc_loss = 0.04126042089845894
Trained batch 447 in epoch 8, gen_loss = 0.43815488488014254, disc_loss = 0.04118181976757894
Trained batch 448 in epoch 8, gen_loss = 0.438123081999526, disc_loss = 0.04112824223954272
Trained batch 449 in epoch 8, gen_loss = 0.43803108771642046, disc_loss = 0.04104966969901903
Trained batch 450 in epoch 8, gen_loss = 0.4380201027292899, disc_loss = 0.04097313541834327
Trained batch 451 in epoch 8, gen_loss = 0.4379879929850587, disc_loss = 0.04091422737780052
Trained batch 452 in epoch 8, gen_loss = 0.43805417957948006, disc_loss = 0.04085792831729102
Trained batch 453 in epoch 8, gen_loss = 0.4380036468416584, disc_loss = 0.04082294734397961
Trained batch 454 in epoch 8, gen_loss = 0.43789964351025257, disc_loss = 0.040930063993373254
Trained batch 455 in epoch 8, gen_loss = 0.437899233152469, disc_loss = 0.04093904244629748
Trained batch 456 in epoch 8, gen_loss = 0.437919582723267, disc_loss = 0.040895600397143864
Trained batch 457 in epoch 8, gen_loss = 0.4379516812000733, disc_loss = 0.04087969040504238
Trained batch 458 in epoch 8, gen_loss = 0.43798151274652003, disc_loss = 0.040988642823312244
Trained batch 459 in epoch 8, gen_loss = 0.4381048738956451, disc_loss = 0.040945012417480185
Trained batch 460 in epoch 8, gen_loss = 0.43825300487158353, disc_loss = 0.04111304047210405
Trained batch 461 in epoch 8, gen_loss = 0.43793660034606985, disc_loss = 0.04161699769718097
Trained batch 462 in epoch 8, gen_loss = 0.4379096616292875, disc_loss = 0.04175784992764163
Trained batch 463 in epoch 8, gen_loss = 0.4380075188417887, disc_loss = 0.041739031403016394
Trained batch 464 in epoch 8, gen_loss = 0.43783878446907126, disc_loss = 0.04175952469018759
Trained batch 465 in epoch 8, gen_loss = 0.43786904772207974, disc_loss = 0.041687409069225224
Trained batch 466 in epoch 8, gen_loss = 0.43775751969798987, disc_loss = 0.04168046872845474
Trained batch 467 in epoch 8, gen_loss = 0.437837391327589, disc_loss = 0.041753117750800796
Trained batch 468 in epoch 8, gen_loss = 0.437779043783257, disc_loss = 0.041748553950851884
Trained batch 469 in epoch 8, gen_loss = 0.437804879343256, disc_loss = 0.04168774119746733
Trained batch 470 in epoch 8, gen_loss = 0.43774736288246835, disc_loss = 0.04180764244333495
Trained batch 471 in epoch 8, gen_loss = 0.4377627505968183, disc_loss = 0.04204476580874189
Trained batch 472 in epoch 8, gen_loss = 0.43767647580666974, disc_loss = 0.04200767162137805
Trained batch 473 in epoch 8, gen_loss = 0.437596966760068, disc_loss = 0.042111499167739055
Trained batch 474 in epoch 8, gen_loss = 0.4374809656017705, disc_loss = 0.04203412650594194
Trained batch 475 in epoch 8, gen_loss = 0.43747167871529313, disc_loss = 0.04196549219249537
Trained batch 476 in epoch 8, gen_loss = 0.43762201951734675, disc_loss = 0.041890517714290844
Trained batch 477 in epoch 8, gen_loss = 0.43745553842648305, disc_loss = 0.04195855797324953
Trained batch 478 in epoch 8, gen_loss = 0.437501016327633, disc_loss = 0.042112968015797544
Trained batch 479 in epoch 8, gen_loss = 0.4373359280327956, disc_loss = 0.04205507059959927
Trained batch 480 in epoch 8, gen_loss = 0.4372821913067863, disc_loss = 0.04206080046741838
Trained batch 481 in epoch 8, gen_loss = 0.43726454928702835, disc_loss = 0.04207117217679844
Trained batch 482 in epoch 8, gen_loss = 0.4373913340687011, disc_loss = 0.04237060621139781
Trained batch 483 in epoch 8, gen_loss = 0.43737591538301185, disc_loss = 0.04241715609201823
Trained batch 484 in epoch 8, gen_loss = 0.4372698488309211, disc_loss = 0.04243051757431138
Trained batch 485 in epoch 8, gen_loss = 0.437440982510033, disc_loss = 0.04261554983576737
Trained batch 486 in epoch 8, gen_loss = 0.4373967824408161, disc_loss = 0.04266325539423562
Trained batch 487 in epoch 8, gen_loss = 0.43738552457729324, disc_loss = 0.042826882309230714
Trained batch 488 in epoch 8, gen_loss = 0.43729692161205114, disc_loss = 0.04277185561822952
Trained batch 489 in epoch 8, gen_loss = 0.4373100424299435, disc_loss = 0.04272925937880895
Trained batch 490 in epoch 8, gen_loss = 0.4373981776645373, disc_loss = 0.04265521328977846
Trained batch 491 in epoch 8, gen_loss = 0.43733914063228824, disc_loss = 0.04277947981514385
Trained batch 492 in epoch 8, gen_loss = 0.4373909579571072, disc_loss = 0.0428965625822597
Trained batch 493 in epoch 8, gen_loss = 0.4376559236995604, disc_loss = 0.042909134959383505
Trained batch 494 in epoch 8, gen_loss = 0.437550047491536, disc_loss = 0.04287538259722894
Trained batch 495 in epoch 8, gen_loss = 0.4374124856605645, disc_loss = 0.04290470931511898
Trained batch 496 in epoch 8, gen_loss = 0.4375545001725556, disc_loss = 0.042835738018466164
Trained batch 497 in epoch 8, gen_loss = 0.43754606649100064, disc_loss = 0.04283479453358111
Trained batch 498 in epoch 8, gen_loss = 0.4376333188078924, disc_loss = 0.042761859584334705
Trained batch 499 in epoch 8, gen_loss = 0.43772324484586717, disc_loss = 0.042746319429483266
Trained batch 500 in epoch 8, gen_loss = 0.4376613210418267, disc_loss = 0.042720759337202846
Trained batch 501 in epoch 8, gen_loss = 0.43762666034508513, disc_loss = 0.04266252112064689
Trained batch 502 in epoch 8, gen_loss = 0.43771135285644835, disc_loss = 0.04258998843219139
Trained batch 503 in epoch 8, gen_loss = 0.43758199564994327, disc_loss = 0.04252015062957071
Trained batch 504 in epoch 8, gen_loss = 0.43774914269400117, disc_loss = 0.04245363836877491
Trained batch 505 in epoch 8, gen_loss = 0.43763737904695654, disc_loss = 0.04238433420626822
Trained batch 506 in epoch 8, gen_loss = 0.4375941316639413, disc_loss = 0.042309897707011074
Trained batch 507 in epoch 8, gen_loss = 0.4376563040876952, disc_loss = 0.042239287528521054
Trained batch 508 in epoch 8, gen_loss = 0.43765895698065843, disc_loss = 0.042166491823585624
Trained batch 509 in epoch 8, gen_loss = 0.4376244119569367, disc_loss = 0.042091396875569925
Trained batch 510 in epoch 8, gen_loss = 0.43764546280271155, disc_loss = 0.042022986259172924
Trained batch 511 in epoch 8, gen_loss = 0.43754747667117044, disc_loss = 0.0419541272585775
Trained batch 512 in epoch 8, gen_loss = 0.4376430143157409, disc_loss = 0.04188665136745741
Trained batch 513 in epoch 8, gen_loss = 0.4374680400822413, disc_loss = 0.04183133159934431
Trained batch 514 in epoch 8, gen_loss = 0.43739905924472994, disc_loss = 0.041790091759950215
Trained batch 515 in epoch 8, gen_loss = 0.4374497193236684, disc_loss = 0.04173885308776426
Trained batch 516 in epoch 8, gen_loss = 0.43746220074031983, disc_loss = 0.04173266780841915
Trained batch 517 in epoch 8, gen_loss = 0.4374268419148839, disc_loss = 0.04171644355993876
Trained batch 518 in epoch 8, gen_loss = 0.4375909284934373, disc_loss = 0.0416522308347858
Trained batch 519 in epoch 8, gen_loss = 0.4376171943086844, disc_loss = 0.04161043080250518
Trained batch 520 in epoch 8, gen_loss = 0.43765675489595895, disc_loss = 0.041625766364246204
Trained batch 521 in epoch 8, gen_loss = 0.43762991157756453, disc_loss = 0.04159410171731735
Trained batch 522 in epoch 8, gen_loss = 0.4375280814804493, disc_loss = 0.041710812386559826
Trained batch 523 in epoch 8, gen_loss = 0.4374767861520971, disc_loss = 0.04164951523758812
Trained batch 524 in epoch 8, gen_loss = 0.4374684737409864, disc_loss = 0.041606523807914485
Trained batch 525 in epoch 8, gen_loss = 0.43744075904554286, disc_loss = 0.04158524897820653
Trained batch 526 in epoch 8, gen_loss = 0.43761624709704794, disc_loss = 0.04164692008270541
Trained batch 527 in epoch 8, gen_loss = 0.4374463956125758, disc_loss = 0.041620328212791886
Trained batch 528 in epoch 8, gen_loss = 0.43731569607226295, disc_loss = 0.041740653429018414
Trained batch 529 in epoch 8, gen_loss = 0.4373678853489318, disc_loss = 0.04191612866443564
Trained batch 530 in epoch 8, gen_loss = 0.43730089584761866, disc_loss = 0.041866673203974455
Trained batch 531 in epoch 8, gen_loss = 0.43723856321627036, disc_loss = 0.04188353426341331
Trained batch 532 in epoch 8, gen_loss = 0.43723208086799276, disc_loss = 0.04195615949238499
Trained batch 533 in epoch 8, gen_loss = 0.43724117001120966, disc_loss = 0.041996712131907095
Trained batch 534 in epoch 8, gen_loss = 0.4373456307103701, disc_loss = 0.041974483989179134
Trained batch 535 in epoch 8, gen_loss = 0.4372846381877785, disc_loss = 0.042042136138457975
Trained batch 536 in epoch 8, gen_loss = 0.4373317461884, disc_loss = 0.04198967667341621
Trained batch 537 in epoch 8, gen_loss = 0.43732214821537185, disc_loss = 0.041979227656477776
Trained batch 538 in epoch 8, gen_loss = 0.4373031179515683, disc_loss = 0.04193597035534362
Trained batch 539 in epoch 8, gen_loss = 0.43738830967081915, disc_loss = 0.04189985070412082
Trained batch 540 in epoch 8, gen_loss = 0.43736820873182936, disc_loss = 0.04184567155195968
Trained batch 541 in epoch 8, gen_loss = 0.4373981250498128, disc_loss = 0.04190910638677733
Trained batch 542 in epoch 8, gen_loss = 0.437526056944336, disc_loss = 0.04190555053829982
Trained batch 543 in epoch 8, gen_loss = 0.43743946737445455, disc_loss = 0.041947381237097195
Trained batch 544 in epoch 8, gen_loss = 0.43738985242099937, disc_loss = 0.04194955728913939
Trained batch 545 in epoch 8, gen_loss = 0.4373529720983226, disc_loss = 0.041937460019270255
Trained batch 546 in epoch 8, gen_loss = 0.4374381790322403, disc_loss = 0.04192599927465103
Trained batch 547 in epoch 8, gen_loss = 0.43737195399555845, disc_loss = 0.042155994124452235
Trained batch 548 in epoch 8, gen_loss = 0.4374001015839464, disc_loss = 0.04210062997961902
Trained batch 549 in epoch 8, gen_loss = 0.4373037300868468, disc_loss = 0.042040069577368826
Trained batch 550 in epoch 8, gen_loss = 0.4373365280957058, disc_loss = 0.04198004230654066
Trained batch 551 in epoch 8, gen_loss = 0.43728416310488316, disc_loss = 0.041945364987612636
Trained batch 552 in epoch 8, gen_loss = 0.4372561995418335, disc_loss = 0.04187829779868585
Trained batch 553 in epoch 8, gen_loss = 0.43727782739844134, disc_loss = 0.04181457564591124
Trained batch 554 in epoch 8, gen_loss = 0.43720768566604135, disc_loss = 0.04180849677304158
Trained batch 555 in epoch 8, gen_loss = 0.43718821887704107, disc_loss = 0.041821986103510796
Trained batch 556 in epoch 8, gen_loss = 0.4371725070412326, disc_loss = 0.04176554547813412
Trained batch 557 in epoch 8, gen_loss = 0.43735500134020294, disc_loss = 0.04170194652522363
Trained batch 558 in epoch 8, gen_loss = 0.4374089831742916, disc_loss = 0.04164429070021498
Trained batch 559 in epoch 8, gen_loss = 0.4374342457524368, disc_loss = 0.041622382403251584
Trained batch 560 in epoch 8, gen_loss = 0.4374895174448078, disc_loss = 0.04155875698027472
Trained batch 561 in epoch 8, gen_loss = 0.4375159549543442, disc_loss = 0.041685528835294985
Trained batch 562 in epoch 8, gen_loss = 0.4373602342542069, disc_loss = 0.04198805116477619
Trained batch 563 in epoch 8, gen_loss = 0.43738482364103304, disc_loss = 0.042039876348827804
Trained batch 564 in epoch 8, gen_loss = 0.4372083124861253, disc_loss = 0.04204771469998281
Trained batch 565 in epoch 8, gen_loss = 0.43742049414361744, disc_loss = 0.04200259717296506
Trained batch 566 in epoch 8, gen_loss = 0.437419051951622, disc_loss = 0.0421934357246407
Trained batch 567 in epoch 8, gen_loss = 0.4373292273933619, disc_loss = 0.04236119411128219
Trained batch 568 in epoch 8, gen_loss = 0.4373485460117957, disc_loss = 0.04230296628726466
Trained batch 569 in epoch 8, gen_loss = 0.43734252426707954, disc_loss = 0.042344133594285766
Trained batch 570 in epoch 8, gen_loss = 0.4373581721569736, disc_loss = 0.042310006928755764
Trained batch 571 in epoch 8, gen_loss = 0.43727907699930085, disc_loss = 0.042267063283361495
Trained batch 572 in epoch 8, gen_loss = 0.43732165598536454, disc_loss = 0.042227940226744136
Trained batch 573 in epoch 8, gen_loss = 0.4372842834697783, disc_loss = 0.04216254081573818
Trained batch 574 in epoch 8, gen_loss = 0.43716997328011886, disc_loss = 0.04210296443865999
Trained batch 575 in epoch 8, gen_loss = 0.4371820258287092, disc_loss = 0.042041506994185816
Trained batch 576 in epoch 8, gen_loss = 0.4371427373001852, disc_loss = 0.04197710917687989
Trained batch 577 in epoch 8, gen_loss = 0.43722831692456376, disc_loss = 0.0419588925753588
Trained batch 578 in epoch 8, gen_loss = 0.4372386656997529, disc_loss = 0.04201900478314113
Trained batch 579 in epoch 8, gen_loss = 0.4373245905699401, disc_loss = 0.04202466747033057
Trained batch 580 in epoch 8, gen_loss = 0.4373258194804397, disc_loss = 0.041977189534957715
Trained batch 581 in epoch 8, gen_loss = 0.4373239165626441, disc_loss = 0.04194254050098513
Trained batch 582 in epoch 8, gen_loss = 0.43744997795204765, disc_loss = 0.04189987161067373
Trained batch 583 in epoch 8, gen_loss = 0.4374976476577863, disc_loss = 0.04186096720394283
Trained batch 584 in epoch 8, gen_loss = 0.43762343734757514, disc_loss = 0.04186848362462006
Trained batch 585 in epoch 8, gen_loss = 0.4375349680413158, disc_loss = 0.042054657451649526
Trained batch 586 in epoch 8, gen_loss = 0.4375810820666448, disc_loss = 0.042106470838030464
Trained batch 587 in epoch 8, gen_loss = 0.4375734562877895, disc_loss = 0.04207207393582251
Trained batch 588 in epoch 8, gen_loss = 0.43755698244519065, disc_loss = 0.04203066717381059
Trained batch 589 in epoch 8, gen_loss = 0.4375962334669242, disc_loss = 0.041987600132538855
Trained batch 590 in epoch 8, gen_loss = 0.4376391245528123, disc_loss = 0.041951651490323386
Trained batch 591 in epoch 8, gen_loss = 0.43766232469194644, disc_loss = 0.042024354289153694
Trained batch 592 in epoch 8, gen_loss = 0.43752124920663304, disc_loss = 0.04226981506967198
Trained batch 593 in epoch 8, gen_loss = 0.4376666856935931, disc_loss = 0.04226397217082029
Trained batch 594 in epoch 8, gen_loss = 0.4377032402182828, disc_loss = 0.042220777576053595
Trained batch 595 in epoch 8, gen_loss = 0.4377272420581555, disc_loss = 0.04217486805673189
Trained batch 596 in epoch 8, gen_loss = 0.43777018870340917, disc_loss = 0.04218129632320611
Trained batch 597 in epoch 8, gen_loss = 0.4378736534445581, disc_loss = 0.042133247581805824
Trained batch 598 in epoch 8, gen_loss = 0.43774298355854013, disc_loss = 0.042077288982335585
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 0.47488027811050415, disc_loss = 0.03544972836971283
Trained batch 1 in epoch 9, gen_loss = 0.5231935083866119, disc_loss = 0.024844888597726822
Trained batch 2 in epoch 9, gen_loss = 0.47737671931584674, disc_loss = 0.024825885891914368
Trained batch 3 in epoch 9, gen_loss = 0.4630245938897133, disc_loss = 0.021229107631370425
Trained batch 4 in epoch 9, gen_loss = 0.46995182037353517, disc_loss = 0.01985663827508688
Trained batch 5 in epoch 9, gen_loss = 0.46817829708258313, disc_loss = 0.018678513665994007
Trained batch 6 in epoch 9, gen_loss = 0.47193974256515503, disc_loss = 0.017130553988473757
Trained batch 7 in epoch 9, gen_loss = 0.47390246391296387, disc_loss = 0.0164517987286672
Trained batch 8 in epoch 9, gen_loss = 0.4730006522602505, disc_loss = 0.017907795703245535
Trained batch 9 in epoch 9, gen_loss = 0.46806727945804594, disc_loss = 0.01739743733778596
Trained batch 10 in epoch 9, gen_loss = 0.4706476384943182, disc_loss = 0.021197104403241115
Trained batch 11 in epoch 9, gen_loss = 0.47203340629736584, disc_loss = 0.019948006879227858
Trained batch 12 in epoch 9, gen_loss = 0.47667036148218006, disc_loss = 0.0216523941534643
Trained batch 13 in epoch 9, gen_loss = 0.47642228858811514, disc_loss = 0.021148151950910687
Trained batch 14 in epoch 9, gen_loss = 0.4775643686453501, disc_loss = 0.020524803331742683
Trained batch 15 in epoch 9, gen_loss = 0.47373392432928085, disc_loss = 0.023560805740999058
Trained batch 16 in epoch 9, gen_loss = 0.47794398139504823, disc_loss = 0.029513013302622473
Trained batch 17 in epoch 9, gen_loss = 0.47638628549045986, disc_loss = 0.02838706341572106
Trained batch 18 in epoch 9, gen_loss = 0.47524050819246394, disc_loss = 0.02738430343666359
Trained batch 19 in epoch 9, gen_loss = 0.4775346502661705, disc_loss = 0.027910306048579515
Trained batch 20 in epoch 9, gen_loss = 0.4733284598305112, disc_loss = 0.02821871986435283
Trained batch 21 in epoch 9, gen_loss = 0.4692379412325946, disc_loss = 0.029097136046568103
Trained batch 22 in epoch 9, gen_loss = 0.46837070973023126, disc_loss = 0.028354046036205862
Trained batch 23 in epoch 9, gen_loss = 0.4670182739694913, disc_loss = 0.02855442454650377
Trained batch 24 in epoch 9, gen_loss = 0.464599677324295, disc_loss = 0.028898838367313148
Trained batch 25 in epoch 9, gen_loss = 0.46787188488703507, disc_loss = 0.0302072788337962
Trained batch 26 in epoch 9, gen_loss = 0.46722814440727234, disc_loss = 0.03006336036034756
Trained batch 27 in epoch 9, gen_loss = 0.4645053574017116, disc_loss = 0.03011404801093574
Trained batch 28 in epoch 9, gen_loss = 0.4629401595428072, disc_loss = 0.02968394651944781
Trained batch 29 in epoch 9, gen_loss = 0.460361326734225, disc_loss = 0.030424995829040805
Trained batch 30 in epoch 9, gen_loss = 0.45742451375530613, disc_loss = 0.031243632863005324
Trained batch 31 in epoch 9, gen_loss = 0.4573186496272683, disc_loss = 0.03136576617544051
Trained batch 32 in epoch 9, gen_loss = 0.4562792380650838, disc_loss = 0.030734460561000036
Trained batch 33 in epoch 9, gen_loss = 0.4565725002218695, disc_loss = 0.03011690210277105
Trained batch 34 in epoch 9, gen_loss = 0.4578803070953914, disc_loss = 0.029426532491509404
Trained batch 35 in epoch 9, gen_loss = 0.45850975894265705, disc_loss = 0.028835496904018026
Trained batch 36 in epoch 9, gen_loss = 0.45918614236084193, disc_loss = 0.028209693717292032
Trained batch 37 in epoch 9, gen_loss = 0.4582059595145677, disc_loss = 0.027866185483473697
Trained batch 38 in epoch 9, gen_loss = 0.46011294691990584, disc_loss = 0.02784915993181177
Trained batch 39 in epoch 9, gen_loss = 0.4609268344938755, disc_loss = 0.02732166142668575
Trained batch 40 in epoch 9, gen_loss = 0.46125338499138996, disc_loss = 0.027441132064090996
Trained batch 41 in epoch 9, gen_loss = 0.4611881226301193, disc_loss = 0.027298818364562022
Trained batch 42 in epoch 9, gen_loss = 0.4609405114207157, disc_loss = 0.027040255039410536
Trained batch 43 in epoch 9, gen_loss = 0.4597798098217357, disc_loss = 0.026784794002940707
Trained batch 44 in epoch 9, gen_loss = 0.4599957201215956, disc_loss = 0.026511041737265057
Trained batch 45 in epoch 9, gen_loss = 0.46098313772160077, disc_loss = 0.02671691370399102
Trained batch 46 in epoch 9, gen_loss = 0.4619037800646843, disc_loss = 0.02735386115122349
Trained batch 47 in epoch 9, gen_loss = 0.46131474773089093, disc_loss = 0.026995570767515648
Trained batch 48 in epoch 9, gen_loss = 0.4587612352809127, disc_loss = 0.027473014969454736
Trained batch 49 in epoch 9, gen_loss = 0.45759220480918883, disc_loss = 0.02778476407751441
Trained batch 50 in epoch 9, gen_loss = 0.45954035777671665, disc_loss = 0.02786514402239346
Trained batch 51 in epoch 9, gen_loss = 0.45906029412379634, disc_loss = 0.029416565049009826
Trained batch 52 in epoch 9, gen_loss = 0.45754179470943956, disc_loss = 0.029188042594436206
Trained batch 53 in epoch 9, gen_loss = 0.4581327857794585, disc_loss = 0.029132722411304712
Trained batch 54 in epoch 9, gen_loss = 0.4578263916752555, disc_loss = 0.028886635381389747
Trained batch 55 in epoch 9, gen_loss = 0.4582433652664934, disc_loss = 0.02861739753279835
Trained batch 56 in epoch 9, gen_loss = 0.45849033039912845, disc_loss = 0.02825109066703079
Trained batch 57 in epoch 9, gen_loss = 0.4582914355499991, disc_loss = 0.028351886077494972
Trained batch 58 in epoch 9, gen_loss = 0.45898929137294575, disc_loss = 0.02862736514090734
Trained batch 59 in epoch 9, gen_loss = 0.4581069678068161, disc_loss = 0.028283800130399564
Trained batch 60 in epoch 9, gen_loss = 0.45792220948172396, disc_loss = 0.02804589631096994
Trained batch 61 in epoch 9, gen_loss = 0.45788260092658384, disc_loss = 0.028473787783314625
Trained batch 62 in epoch 9, gen_loss = 0.4580102458832756, disc_loss = 0.029842249982591187
Trained batch 63 in epoch 9, gen_loss = 0.4579901983961463, disc_loss = 0.029539961738919374
Trained batch 64 in epoch 9, gen_loss = 0.45856998425263623, disc_loss = 0.029193200629491073
Trained batch 65 in epoch 9, gen_loss = 0.45804825967008417, disc_loss = 0.029089442087393818
Trained batch 66 in epoch 9, gen_loss = 0.45672958822392706, disc_loss = 0.028997303334189886
Trained batch 67 in epoch 9, gen_loss = 0.457508343984099, disc_loss = 0.02903929610243615
Trained batch 68 in epoch 9, gen_loss = 0.45677538626435876, disc_loss = 0.02867753408930224
Trained batch 69 in epoch 9, gen_loss = 0.45626092978886196, disc_loss = 0.028328096600515502
Trained batch 70 in epoch 9, gen_loss = 0.45585040055530174, disc_loss = 0.02799080863175258
Trained batch 71 in epoch 9, gen_loss = 0.45492778966824216, disc_loss = 0.02767267290295826
Trained batch 72 in epoch 9, gen_loss = 0.45385197335726596, disc_loss = 0.027543396880365396
Trained batch 73 in epoch 9, gen_loss = 0.4540952709881035, disc_loss = 0.027264196280943783
Trained batch 74 in epoch 9, gen_loss = 0.4538163526852926, disc_loss = 0.02703359292820096
Trained batch 75 in epoch 9, gen_loss = 0.45399402003539235, disc_loss = 0.026748037192431327
Trained batch 76 in epoch 9, gen_loss = 0.45333940100360226, disc_loss = 0.02644860604777932
Trained batch 77 in epoch 9, gen_loss = 0.4543903676363138, disc_loss = 0.026174178114160895
Trained batch 78 in epoch 9, gen_loss = 0.4537962961800491, disc_loss = 0.025883979953919785
Trained batch 79 in epoch 9, gen_loss = 0.45264581255614755, disc_loss = 0.025600237620528786
Trained batch 80 in epoch 9, gen_loss = 0.4526456016817211, disc_loss = 0.025318398238102228
Trained batch 81 in epoch 9, gen_loss = 0.4519902260565176, disc_loss = 0.025047017681616837
Trained batch 82 in epoch 9, gen_loss = 0.4520761162401682, disc_loss = 0.024798931385648537
Trained batch 83 in epoch 9, gen_loss = 0.4521520020706313, disc_loss = 0.02453934012668296
Trained batch 84 in epoch 9, gen_loss = 0.4515789498301113, disc_loss = 0.024301480266320355
Trained batch 85 in epoch 9, gen_loss = 0.4520658161057982, disc_loss = 0.024053744923020173
Trained batch 86 in epoch 9, gen_loss = 0.4518710868111972, disc_loss = 0.02382923749907092
Trained batch 87 in epoch 9, gen_loss = 0.4521292627535083, disc_loss = 0.023718678620008923
Trained batch 88 in epoch 9, gen_loss = 0.45115167237399667, disc_loss = 0.023482970691945278
Trained batch 89 in epoch 9, gen_loss = 0.4507697410053677, disc_loss = 0.023267483077425925
Trained batch 90 in epoch 9, gen_loss = 0.4501244032775963, disc_loss = 0.02304184581613639
Trained batch 91 in epoch 9, gen_loss = 0.44999149376931397, disc_loss = 0.022828687610023695
Trained batch 92 in epoch 9, gen_loss = 0.4493389626344045, disc_loss = 0.022608192329625448
Trained batch 93 in epoch 9, gen_loss = 0.44913692265114885, disc_loss = 0.02241884606167119
Trained batch 94 in epoch 9, gen_loss = 0.4484612144921955, disc_loss = 0.02223413503532739
Trained batch 95 in epoch 9, gen_loss = 0.4480011605968078, disc_loss = 0.022149383519717958
Trained batch 96 in epoch 9, gen_loss = 0.44799515328456446, disc_loss = 0.021985214690860247
Trained batch 97 in epoch 9, gen_loss = 0.4479004926219278, disc_loss = 0.021806833398414358
Trained batch 98 in epoch 9, gen_loss = 0.447523429839298, disc_loss = 0.02161852565048394
Trained batch 99 in epoch 9, gen_loss = 0.4471305790543556, disc_loss = 0.021428963257931172
Trained batch 100 in epoch 9, gen_loss = 0.4470001078478181, disc_loss = 0.021244070667884137
Trained batch 101 in epoch 9, gen_loss = 0.44628457374432506, disc_loss = 0.021059493105128117
Trained batch 102 in epoch 9, gen_loss = 0.44573710120997384, disc_loss = 0.020872647238859128
Trained batch 103 in epoch 9, gen_loss = 0.4461498767710649, disc_loss = 0.02069660305726127
Trained batch 104 in epoch 9, gen_loss = 0.4453775615919204, disc_loss = 0.0205312319986877
Trained batch 105 in epoch 9, gen_loss = 0.44483108649838643, disc_loss = 0.020374012851806463
Trained batch 106 in epoch 9, gen_loss = 0.4443842278462704, disc_loss = 0.020308510813792455
Trained batch 107 in epoch 9, gen_loss = 0.4438643416872731, disc_loss = 0.020208006159885338
Trained batch 108 in epoch 9, gen_loss = 0.44305399114932487, disc_loss = 0.0200389403563608
Trained batch 109 in epoch 9, gen_loss = 0.44285259571942415, disc_loss = 0.019889696101150052
Trained batch 110 in epoch 9, gen_loss = 0.4427843963777697, disc_loss = 0.019752132553221273
Trained batch 111 in epoch 9, gen_loss = 0.44265630149415564, disc_loss = 0.019599412902607583
Trained batch 112 in epoch 9, gen_loss = 0.4424454134649935, disc_loss = 0.0194573740503726
Trained batch 113 in epoch 9, gen_loss = 0.44223604730346744, disc_loss = 0.019318404797415593
Trained batch 114 in epoch 9, gen_loss = 0.4422448280064956, disc_loss = 0.01924926240361579
Trained batch 115 in epoch 9, gen_loss = 0.4422777921989046, disc_loss = 0.019152183408832884
Trained batch 116 in epoch 9, gen_loss = 0.44201179065256035, disc_loss = 0.019016850349676404
Trained batch 117 in epoch 9, gen_loss = 0.4420598017967353, disc_loss = 0.018876054193982382
Trained batch 118 in epoch 9, gen_loss = 0.44208309605342, disc_loss = 0.018733506612362293
Trained batch 119 in epoch 9, gen_loss = 0.4424695990979671, disc_loss = 0.018603815051998634
Trained batch 120 in epoch 9, gen_loss = 0.44235641577027063, disc_loss = 0.018482376585622157
Trained batch 121 in epoch 9, gen_loss = 0.44148348858121966, disc_loss = 0.018383087597016366
Trained batch 122 in epoch 9, gen_loss = 0.44158908312882833, disc_loss = 0.01825499622722921
Trained batch 123 in epoch 9, gen_loss = 0.4415691230566271, disc_loss = 0.01814492760627951
Trained batch 124 in epoch 9, gen_loss = 0.4406224000453949, disc_loss = 0.018020896728150545
Trained batch 125 in epoch 9, gen_loss = 0.4408267107274797, disc_loss = 0.017905546720915783
Trained batch 126 in epoch 9, gen_loss = 0.4407591566326111, disc_loss = 0.017839819206636194
Trained batch 127 in epoch 9, gen_loss = 0.44115431932732463, disc_loss = 0.017749400491993583
Trained batch 128 in epoch 9, gen_loss = 0.44132269699444143, disc_loss = 0.017630690774634885
Trained batch 129 in epoch 9, gen_loss = 0.4409303396940231, disc_loss = 0.017521151815218707
Trained batch 130 in epoch 9, gen_loss = 0.4409545969417077, disc_loss = 0.017430647611369216
Trained batch 131 in epoch 9, gen_loss = 0.4409730802431251, disc_loss = 0.017325778083459503
Trained batch 132 in epoch 9, gen_loss = 0.441062496344846, disc_loss = 0.017207984055420456
Trained batch 133 in epoch 9, gen_loss = 0.44089019565439935, disc_loss = 0.01709186024320965
Trained batch 134 in epoch 9, gen_loss = 0.4406259651537295, disc_loss = 0.016980400984175505
Trained batch 135 in epoch 9, gen_loss = 0.44057685268275876, disc_loss = 0.01690207931524663
Trained batch 136 in epoch 9, gen_loss = 0.4405253000938109, disc_loss = 0.016806982898656415
Trained batch 137 in epoch 9, gen_loss = 0.4403425858936448, disc_loss = 0.016705136465252905
Trained batch 138 in epoch 9, gen_loss = 0.43995991627947034, disc_loss = 0.016599097350283976
Trained batch 139 in epoch 9, gen_loss = 0.4400716091905321, disc_loss = 0.01651482485051799
Trained batch 140 in epoch 9, gen_loss = 0.4405479887698559, disc_loss = 0.016411046457893038
Trained batch 141 in epoch 9, gen_loss = 0.4402750251998364, disc_loss = 0.016310304349196524
Trained batch 142 in epoch 9, gen_loss = 0.44069018355616324, disc_loss = 0.016222420532803435
Trained batch 143 in epoch 9, gen_loss = 0.44095596195095116, disc_loss = 0.016241519181575213
Trained batch 144 in epoch 9, gen_loss = 0.44069290859945887, disc_loss = 0.016196747535261614
Trained batch 145 in epoch 9, gen_loss = 0.44025870055368505, disc_loss = 0.0161250871127752
Trained batch 146 in epoch 9, gen_loss = 0.44042208283936896, disc_loss = 0.016033848212258953
Trained batch 147 in epoch 9, gen_loss = 0.4406578381722038, disc_loss = 0.01596852093368668
Trained batch 148 in epoch 9, gen_loss = 0.4402310366198521, disc_loss = 0.01587693750758299
Trained batch 149 in epoch 9, gen_loss = 0.44006272693475085, disc_loss = 0.01578838603881498
Trained batch 150 in epoch 9, gen_loss = 0.43986458474437135, disc_loss = 0.015698049165037097
Trained batch 151 in epoch 9, gen_loss = 0.4399424256070664, disc_loss = 0.01560707868989802
Trained batch 152 in epoch 9, gen_loss = 0.4399155444569058, disc_loss = 0.015517535349323713
Trained batch 153 in epoch 9, gen_loss = 0.4399654149235069, disc_loss = 0.015440508113212448
Trained batch 154 in epoch 9, gen_loss = 0.4401622689539386, disc_loss = 0.015370129205797228
Trained batch 155 in epoch 9, gen_loss = 0.4400391588226343, disc_loss = 0.015287425544393511
Trained batch 156 in epoch 9, gen_loss = 0.44006524363141153, disc_loss = 0.01522804095756832
Trained batch 157 in epoch 9, gen_loss = 0.4400171252745616, disc_loss = 0.01515141924286167
Trained batch 158 in epoch 9, gen_loss = 0.4397566174186251, disc_loss = 0.015070742431811333
Trained batch 159 in epoch 9, gen_loss = 0.4399476632475853, disc_loss = 0.015010963487293338
Trained batch 160 in epoch 9, gen_loss = 0.43967777194443697, disc_loss = 0.014958861581142414
Trained batch 161 in epoch 9, gen_loss = 0.43953838926038624, disc_loss = 0.014889903710781378
Trained batch 162 in epoch 9, gen_loss = 0.439432298661741, disc_loss = 0.014809246714929678
Trained batch 163 in epoch 9, gen_loss = 0.4394030452864926, disc_loss = 0.014729081014193958
Trained batch 164 in epoch 9, gen_loss = 0.43919178157141714, disc_loss = 0.014665671229136713
Trained batch 165 in epoch 9, gen_loss = 0.43920818545732154, disc_loss = 0.014589370772556728
Trained batch 166 in epoch 9, gen_loss = 0.4392167463630973, disc_loss = 0.014512308838381293
Trained batch 167 in epoch 9, gen_loss = 0.43907699467880384, disc_loss = 0.014437208671422144
Trained batch 168 in epoch 9, gen_loss = 0.4388052099907892, disc_loss = 0.014362104801935028
Trained batch 169 in epoch 9, gen_loss = 0.43866363097639643, disc_loss = 0.014288002778502071
Trained batch 170 in epoch 9, gen_loss = 0.43869286008745606, disc_loss = 0.01423170183082683
Trained batch 171 in epoch 9, gen_loss = 0.4384329627419627, disc_loss = 0.01416423466045756
Trained batch 172 in epoch 9, gen_loss = 0.4381063604630487, disc_loss = 0.014121179213219813
Trained batch 173 in epoch 9, gen_loss = 0.43842096010158804, disc_loss = 0.014053831947432167
Trained batch 174 in epoch 9, gen_loss = 0.43841559835842675, disc_loss = 0.014000912383198737
Trained batch 175 in epoch 9, gen_loss = 0.4381803267381408, disc_loss = 0.013933192709704268
Trained batch 176 in epoch 9, gen_loss = 0.43769153009700235, disc_loss = 0.013862484731279988
Trained batch 177 in epoch 9, gen_loss = 0.4379407855566968, disc_loss = 0.013804202697245048
Trained batch 178 in epoch 9, gen_loss = 0.4383041980213293, disc_loss = 0.013742189416687874
Trained batch 179 in epoch 9, gen_loss = 0.4382575828168127, disc_loss = 0.01367766965348791
Trained batch 180 in epoch 9, gen_loss = 0.43833727648903653, disc_loss = 0.013611912908089135
Trained batch 181 in epoch 9, gen_loss = 0.43803108082367825, disc_loss = 0.013561403699306218
Trained batch 182 in epoch 9, gen_loss = 0.4379037441125984, disc_loss = 0.013497120825461839
Trained batch 183 in epoch 9, gen_loss = 0.43786847623793973, disc_loss = 0.013438015828243173
Trained batch 184 in epoch 9, gen_loss = 0.43747677770820825, disc_loss = 0.013376617747535175
Trained batch 185 in epoch 9, gen_loss = 0.43796077050188537, disc_loss = 0.013356771669350564
Trained batch 186 in epoch 9, gen_loss = 0.43789619685494324, disc_loss = 0.013302150756409541
Trained batch 187 in epoch 9, gen_loss = 0.43792356471432015, disc_loss = 0.013241020241192482
Trained batch 188 in epoch 9, gen_loss = 0.437962506971662, disc_loss = 0.013246412775183599
Trained batch 189 in epoch 9, gen_loss = 0.43788353251783474, disc_loss = 0.013187059857514932
Trained batch 190 in epoch 9, gen_loss = 0.4380940654514972, disc_loss = 0.013139652082798953
Trained batch 191 in epoch 9, gen_loss = 0.4382601861531536, disc_loss = 0.013490111668337098
Trained batch 192 in epoch 9, gen_loss = 0.4377328480154739, disc_loss = 0.013525287089314447
Trained batch 193 in epoch 9, gen_loss = 0.4376223904570353, disc_loss = 0.013571849922750375
Trained batch 194 in epoch 9, gen_loss = 0.43741364295666035, disc_loss = 0.013540859445810127
Trained batch 195 in epoch 9, gen_loss = 0.43739904311238503, disc_loss = 0.01354227445209494
Trained batch 196 in epoch 9, gen_loss = 0.4373740919955491, disc_loss = 0.013505824332758973
Trained batch 197 in epoch 9, gen_loss = 0.43696402856195815, disc_loss = 0.014423836969812824
Trained batch 198 in epoch 9, gen_loss = 0.43718958844491584, disc_loss = 0.014466838664890047
Trained batch 199 in epoch 9, gen_loss = 0.43728586688637733, disc_loss = 0.014551886438275687
Trained batch 200 in epoch 9, gen_loss = 0.43731193830124776, disc_loss = 0.014511826841406228
Trained batch 201 in epoch 9, gen_loss = 0.43771430540202866, disc_loss = 0.014535555209720157
Trained batch 202 in epoch 9, gen_loss = 0.4377058518343958, disc_loss = 0.014568846084962008
Trained batch 203 in epoch 9, gen_loss = 0.4373019264609206, disc_loss = 0.014668267384039093
Trained batch 204 in epoch 9, gen_loss = 0.4369481493787068, disc_loss = 0.015015096216825995
Trained batch 205 in epoch 9, gen_loss = 0.43681356976333174, disc_loss = 0.014989623600431691
Trained batch 206 in epoch 9, gen_loss = 0.436324474748206, disc_loss = 0.015168643677449708
Trained batch 207 in epoch 9, gen_loss = 0.4365419808488626, disc_loss = 0.015140164320585497
Trained batch 208 in epoch 9, gen_loss = 0.4368510537170337, disc_loss = 0.015125847621553501
Trained batch 209 in epoch 9, gen_loss = 0.43666251117274874, disc_loss = 0.015085574830993122
Trained batch 210 in epoch 9, gen_loss = 0.4366748075914609, disc_loss = 0.01503112269245459
Trained batch 211 in epoch 9, gen_loss = 0.43666518198431664, disc_loss = 0.015045214055066506
Trained batch 212 in epoch 9, gen_loss = 0.4364608850837314, disc_loss = 0.015102499402390505
Trained batch 213 in epoch 9, gen_loss = 0.4365755735992271, disc_loss = 0.015051596703891269
Trained batch 214 in epoch 9, gen_loss = 0.43690205659977227, disc_loss = 0.01504320326575273
Trained batch 215 in epoch 9, gen_loss = 0.43697961337036556, disc_loss = 0.01501800042428335
Trained batch 216 in epoch 9, gen_loss = 0.43723497344052187, disc_loss = 0.014978378639376212
Trained batch 217 in epoch 9, gen_loss = 0.43723667488185636, disc_loss = 0.014939016125852737
Trained batch 218 in epoch 9, gen_loss = 0.4372844871592848, disc_loss = 0.014891703767791288
Trained batch 219 in epoch 9, gen_loss = 0.437213771045208, disc_loss = 0.014851403993617913
Trained batch 220 in epoch 9, gen_loss = 0.43717846854240106, disc_loss = 0.014858298664765087
Trained batch 221 in epoch 9, gen_loss = 0.43718803277960766, disc_loss = 0.014821718849120074
Trained batch 222 in epoch 9, gen_loss = 0.4370880495806981, disc_loss = 0.014806174660089004
Trained batch 223 in epoch 9, gen_loss = 0.43705176814858404, disc_loss = 0.01477016341180258
Trained batch 224 in epoch 9, gen_loss = 0.43690890828768414, disc_loss = 0.014773617276611428
Trained batch 225 in epoch 9, gen_loss = 0.4367438842237523, disc_loss = 0.01483554885654702
Trained batch 226 in epoch 9, gen_loss = 0.4365791775581595, disc_loss = 0.014916836589242491
Trained batch 227 in epoch 9, gen_loss = 0.43691389184249074, disc_loss = 0.015247629299298288
Trained batch 228 in epoch 9, gen_loss = 0.4370815337485101, disc_loss = 0.015197389916207756
Trained batch 229 in epoch 9, gen_loss = 0.43736352402230966, disc_loss = 0.01516107672309179
Trained batch 230 in epoch 9, gen_loss = 0.4374817565922097, disc_loss = 0.015455862128748296
Trained batch 231 in epoch 9, gen_loss = 0.43768105039308813, disc_loss = 0.015624268061244572
Trained batch 232 in epoch 9, gen_loss = 0.43771333001202267, disc_loss = 0.015725543491178603
Trained batch 233 in epoch 9, gen_loss = 0.4379174887624561, disc_loss = 0.01587559236661316
Trained batch 234 in epoch 9, gen_loss = 0.4377146433008478, disc_loss = 0.016003132057178054
Trained batch 235 in epoch 9, gen_loss = 0.4377023179904889, disc_loss = 0.016014337690124857
Trained batch 236 in epoch 9, gen_loss = 0.43754101742672014, disc_loss = 0.01603890008456172
Trained batch 237 in epoch 9, gen_loss = 0.43801761262056205, disc_loss = 0.016238570581640296
Trained batch 238 in epoch 9, gen_loss = 0.43764328582516276, disc_loss = 0.01699023222342274
Trained batch 239 in epoch 9, gen_loss = 0.43792627975344656, disc_loss = 0.017402654320176226
Trained batch 240 in epoch 9, gen_loss = 0.4381842454934021, disc_loss = 0.017410588292772127
Trained batch 241 in epoch 9, gen_loss = 0.438234539810291, disc_loss = 0.017356454587660823
Trained batch 242 in epoch 9, gen_loss = 0.43802521000673744, disc_loss = 0.017302740657023717
Trained batch 243 in epoch 9, gen_loss = 0.43791321494051666, disc_loss = 0.01730179231753191
Trained batch 244 in epoch 9, gen_loss = 0.4378830300301922, disc_loss = 0.017274933411473674
Trained batch 245 in epoch 9, gen_loss = 0.4382045817811315, disc_loss = 0.017220805973151503
Trained batch 246 in epoch 9, gen_loss = 0.43821418526684225, disc_loss = 0.017218882767087686
Trained batch 247 in epoch 9, gen_loss = 0.4382019639015198, disc_loss = 0.017164958203906164
Trained batch 248 in epoch 9, gen_loss = 0.4381802911499897, disc_loss = 0.017107287192264623
Trained batch 249 in epoch 9, gen_loss = 0.43836991703510286, disc_loss = 0.017049856204073875
Trained batch 250 in epoch 9, gen_loss = 0.4381323392647671, disc_loss = 0.0170230141157225
Trained batch 251 in epoch 9, gen_loss = 0.4380226963096195, disc_loss = 0.016980617424927742
Trained batch 252 in epoch 9, gen_loss = 0.4380957538431341, disc_loss = 0.01693506108867483
Trained batch 253 in epoch 9, gen_loss = 0.43821579757637863, disc_loss = 0.016877912144876987
Trained batch 254 in epoch 9, gen_loss = 0.4383850329062518, disc_loss = 0.01681993287924093
Trained batch 255 in epoch 9, gen_loss = 0.4384245603578165, disc_loss = 0.016774263812749268
Trained batch 256 in epoch 9, gen_loss = 0.4383278954121853, disc_loss = 0.016728983330902742
Trained batch 257 in epoch 9, gen_loss = 0.4384140719970067, disc_loss = 0.01667707179837261
Trained batch 258 in epoch 9, gen_loss = 0.4384821540600545, disc_loss = 0.016624532514575394
Trained batch 259 in epoch 9, gen_loss = 0.4385365010454105, disc_loss = 0.01657139241399888
Trained batch 260 in epoch 9, gen_loss = 0.4384932095520341, disc_loss = 0.016516384398796637
Trained batch 261 in epoch 9, gen_loss = 0.4385895421941772, disc_loss = 0.016466943994573255
Trained batch 262 in epoch 9, gen_loss = 0.43854830110934295, disc_loss = 0.016436895585314373
Trained batch 263 in epoch 9, gen_loss = 0.4384215250611305, disc_loss = 0.016383696566635714
Trained batch 264 in epoch 9, gen_loss = 0.43853574248979676, disc_loss = 0.01634683815700898
Trained batch 265 in epoch 9, gen_loss = 0.43842708750774984, disc_loss = 0.016300292330692502
Trained batch 266 in epoch 9, gen_loss = 0.43839302893435017, disc_loss = 0.016248064328853586
Trained batch 267 in epoch 9, gen_loss = 0.43844801465522, disc_loss = 0.01619786209185302
Trained batch 268 in epoch 9, gen_loss = 0.4385296669148158, disc_loss = 0.01615269341095797
Trained batch 269 in epoch 9, gen_loss = 0.43856699886145417, disc_loss = 0.01611625370612644
Trained batch 270 in epoch 9, gen_loss = 0.4388022768101569, disc_loss = 0.016069360847612395
Trained batch 271 in epoch 9, gen_loss = 0.43855823927065907, disc_loss = 0.016020595150407376
Trained batch 272 in epoch 9, gen_loss = 0.4383660293979086, disc_loss = 0.0159717573722033
Trained batch 273 in epoch 9, gen_loss = 0.4382661632160201, disc_loss = 0.01621822834339496
Trained batch 274 in epoch 9, gen_loss = 0.4381711628220298, disc_loss = 0.01628694520374252
Trained batch 275 in epoch 9, gen_loss = 0.4382084571364997, disc_loss = 0.016358339790831847
Trained batch 276 in epoch 9, gen_loss = 0.4381357279710391, disc_loss = 0.016313504578549052
Trained batch 277 in epoch 9, gen_loss = 0.4381659048066722, disc_loss = 0.01628549745023291
Trained batch 278 in epoch 9, gen_loss = 0.43860522692348797, disc_loss = 0.01626069979586949
Trained batch 279 in epoch 9, gen_loss = 0.43867073208093643, disc_loss = 0.016212507849974956
Trained batch 280 in epoch 9, gen_loss = 0.4384878041269092, disc_loss = 0.01620271200773197
Trained batch 281 in epoch 9, gen_loss = 0.43842738444078055, disc_loss = 0.016154621919726043
Trained batch 282 in epoch 9, gen_loss = 0.43840575091830414, disc_loss = 0.01610847210631683
Trained batch 283 in epoch 9, gen_loss = 0.4383744633113834, disc_loss = 0.016061428780618295
Trained batch 284 in epoch 9, gen_loss = 0.438417537170544, disc_loss = 0.01601226847790378
Trained batch 285 in epoch 9, gen_loss = 0.43820237529861344, disc_loss = 0.015966397896164806
Trained batch 286 in epoch 9, gen_loss = 0.43816747960313274, disc_loss = 0.015920544828074087
Trained batch 287 in epoch 9, gen_loss = 0.4383381122930182, disc_loss = 0.015875760277898127
Trained batch 288 in epoch 9, gen_loss = 0.43834822441879856, disc_loss = 0.01583991449762935
Trained batch 289 in epoch 9, gen_loss = 0.4383122944626315, disc_loss = 0.015794970883168922
Trained batch 290 in epoch 9, gen_loss = 0.4382738558082646, disc_loss = 0.015755551673161488
Trained batch 291 in epoch 9, gen_loss = 0.43824334626328454, disc_loss = 0.01572020830744431
Trained batch 292 in epoch 9, gen_loss = 0.4381701459046517, disc_loss = 0.015706081030359524
Trained batch 293 in epoch 9, gen_loss = 0.43802491185211, disc_loss = 0.015676189633323907
Trained batch 294 in epoch 9, gen_loss = 0.4382220778424861, disc_loss = 0.015663966165176766
Trained batch 295 in epoch 9, gen_loss = 0.43813649756280154, disc_loss = 0.015844998435617576
Trained batch 296 in epoch 9, gen_loss = 0.4383106752477511, disc_loss = 0.016692255791010153
Trained batch 297 in epoch 9, gen_loss = 0.43829283088245646, disc_loss = 0.01670322591718599
Trained batch 298 in epoch 9, gen_loss = 0.4379957881460222, disc_loss = 0.01694363566936246
Trained batch 299 in epoch 9, gen_loss = 0.4381304258108139, disc_loss = 0.016910834670610105
Trained batch 300 in epoch 9, gen_loss = 0.4382250936720458, disc_loss = 0.016944770720954426
Trained batch 301 in epoch 9, gen_loss = 0.4382185929066298, disc_loss = 0.0169835149704491
Trained batch 302 in epoch 9, gen_loss = 0.4382055619172137, disc_loss = 0.016991650972672103
Trained batch 303 in epoch 9, gen_loss = 0.4382095806496708, disc_loss = 0.017115818469487988
Trained batch 304 in epoch 9, gen_loss = 0.4383008020823119, disc_loss = 0.01717328007645966
Trained batch 305 in epoch 9, gen_loss = 0.43837347081284117, disc_loss = 0.01726516082790053
Trained batch 306 in epoch 9, gen_loss = 0.4382099837355971, disc_loss = 0.017227901832552486
Trained batch 307 in epoch 9, gen_loss = 0.43797349997542123, disc_loss = 0.017249562923853927
Trained batch 308 in epoch 9, gen_loss = 0.43799674964259744, disc_loss = 0.01748690147873641
Trained batch 309 in epoch 9, gen_loss = 0.4379098887405088, disc_loss = 0.01761432820142457
Trained batch 310 in epoch 9, gen_loss = 0.4379903123118103, disc_loss = 0.01757535994033422
Trained batch 311 in epoch 9, gen_loss = 0.4380529733995597, disc_loss = 0.017545994255879823
Trained batch 312 in epoch 9, gen_loss = 0.43786717556155147, disc_loss = 0.017519115034071282
Trained batch 313 in epoch 9, gen_loss = 0.4376227044186015, disc_loss = 0.017500989074940396
Trained batch 314 in epoch 9, gen_loss = 0.43764796096181113, disc_loss = 0.017456717182704737
Trained batch 315 in epoch 9, gen_loss = 0.43770690460371064, disc_loss = 0.017412410818756545
Trained batch 316 in epoch 9, gen_loss = 0.4377567504858745, disc_loss = 0.017383188511280206
Trained batch 317 in epoch 9, gen_loss = 0.4377036010319332, disc_loss = 0.01736652244829848
Trained batch 318 in epoch 9, gen_loss = 0.4374148826987766, disc_loss = 0.017328278523239198
Trained batch 319 in epoch 9, gen_loss = 0.437662772461772, disc_loss = 0.017303013713899418
Trained batch 320 in epoch 9, gen_loss = 0.4375555679619869, disc_loss = 0.01728315748284481
Trained batch 321 in epoch 9, gen_loss = 0.43759448289501, disc_loss = 0.017238641372861584
Trained batch 322 in epoch 9, gen_loss = 0.43755923105467215, disc_loss = 0.017384524957057747
Trained batch 323 in epoch 9, gen_loss = 0.4374538950714064, disc_loss = 0.01751339415564018
Trained batch 324 in epoch 9, gen_loss = 0.4374442209647252, disc_loss = 0.01747477077628271
Trained batch 325 in epoch 9, gen_loss = 0.4375100730021307, disc_loss = 0.01751158471709186
Trained batch 326 in epoch 9, gen_loss = 0.4377516502634101, disc_loss = 0.017486811562481164
Trained batch 327 in epoch 9, gen_loss = 0.4378211486448602, disc_loss = 0.017492203633570704
Trained batch 328 in epoch 9, gen_loss = 0.4375882594418743, disc_loss = 0.018281263874993747
Trained batch 329 in epoch 9, gen_loss = 0.4372162454056017, disc_loss = 0.019035045487566314
Trained batch 330 in epoch 9, gen_loss = 0.4373413262230392, disc_loss = 0.019039224187162595
Trained batch 331 in epoch 9, gen_loss = 0.4374076055295496, disc_loss = 0.019352127602590384
Trained batch 332 in epoch 9, gen_loss = 0.43723600279461516, disc_loss = 0.019424261873120907
Trained batch 333 in epoch 9, gen_loss = 0.43682338743509647, disc_loss = 0.01961981801387246
Trained batch 334 in epoch 9, gen_loss = 0.4367460095170719, disc_loss = 0.01979145400552774
Trained batch 335 in epoch 9, gen_loss = 0.43693149134161924, disc_loss = 0.019818958511418065
Trained batch 336 in epoch 9, gen_loss = 0.43707964823578516, disc_loss = 0.01991420549386145
Trained batch 337 in epoch 9, gen_loss = 0.4371516526450772, disc_loss = 0.01987898662877848
Trained batch 338 in epoch 9, gen_loss = 0.43706375879172377, disc_loss = 0.019940795009793674
Trained batch 339 in epoch 9, gen_loss = 0.4370015262680895, disc_loss = 0.019903258651645633
Trained batch 340 in epoch 9, gen_loss = 0.4370154181708339, disc_loss = 0.01998294368925671
Trained batch 341 in epoch 9, gen_loss = 0.43709089890209557, disc_loss = 0.02000669533848403
Trained batch 342 in epoch 9, gen_loss = 0.43709322653776006, disc_loss = 0.020096314512668367
Trained batch 343 in epoch 9, gen_loss = 0.4373705869670524, disc_loss = 0.02032351971510527
Trained batch 344 in epoch 9, gen_loss = 0.43727644742399024, disc_loss = 0.020506535136761764
Trained batch 345 in epoch 9, gen_loss = 0.4373739460816962, disc_loss = 0.020583541935640846
Trained batch 346 in epoch 9, gen_loss = 0.43747352205367185, disc_loss = 0.020544920818174328
Trained batch 347 in epoch 9, gen_loss = 0.43726868379390105, disc_loss = 0.02066868747385144
Trained batch 348 in epoch 9, gen_loss = 0.43729187005911996, disc_loss = 0.020904447022427865
Trained batch 349 in epoch 9, gen_loss = 0.4370287710428238, disc_loss = 0.021095728388255727
Trained batch 350 in epoch 9, gen_loss = 0.4369891466748001, disc_loss = 0.021068719511206906
Trained batch 351 in epoch 9, gen_loss = 0.437143575146117, disc_loss = 0.021091640594518554
Trained batch 352 in epoch 9, gen_loss = 0.4371224001852041, disc_loss = 0.021265062248590205
Trained batch 353 in epoch 9, gen_loss = 0.43718053358422837, disc_loss = 0.02130685271636062
Trained batch 354 in epoch 9, gen_loss = 0.4372898734791178, disc_loss = 0.021315386813645528
Trained batch 355 in epoch 9, gen_loss = 0.4373223717962758, disc_loss = 0.021442437383249465
Trained batch 356 in epoch 9, gen_loss = 0.4372925249969258, disc_loss = 0.021404187537727132
Trained batch 357 in epoch 9, gen_loss = 0.43722888977167995, disc_loss = 0.02159231433523923
Trained batch 358 in epoch 9, gen_loss = 0.437341004444032, disc_loss = 0.021632949275244805
Trained batch 359 in epoch 9, gen_loss = 0.4374254998233583, disc_loss = 0.02184495595380819
Trained batch 360 in epoch 9, gen_loss = 0.43749863817421025, disc_loss = 0.021829626036335783
Trained batch 361 in epoch 9, gen_loss = 0.4374417270744703, disc_loss = 0.02191644183132355
Trained batch 362 in epoch 9, gen_loss = 0.4375094985666354, disc_loss = 0.02188732534404536
Trained batch 363 in epoch 9, gen_loss = 0.4376190090244943, disc_loss = 0.021846219222764945
Trained batch 364 in epoch 9, gen_loss = 0.4375987121503647, disc_loss = 0.021806962957465384
Trained batch 365 in epoch 9, gen_loss = 0.43730687639100957, disc_loss = 0.02184309760112407
Trained batch 366 in epoch 9, gen_loss = 0.4371737934425676, disc_loss = 0.0218745181219632
Trained batch 367 in epoch 9, gen_loss = 0.4371114728729362, disc_loss = 0.021905260156452878
Trained batch 368 in epoch 9, gen_loss = 0.43724981895307213, disc_loss = 0.022165670421486847
Trained batch 369 in epoch 9, gen_loss = 0.4373909769831477, disc_loss = 0.02243751802550931
Trained batch 370 in epoch 9, gen_loss = 0.43744915129360806, disc_loss = 0.022450840367679546
Trained batch 371 in epoch 9, gen_loss = 0.43759456725530727, disc_loss = 0.0224228126096404
Trained batch 372 in epoch 9, gen_loss = 0.43765246412709313, disc_loss = 0.022421662504385268
Trained batch 373 in epoch 9, gen_loss = 0.4374436089858652, disc_loss = 0.022416785833448232
Trained batch 374 in epoch 9, gen_loss = 0.437345690647761, disc_loss = 0.02238161975486825
Trained batch 375 in epoch 9, gen_loss = 0.43728075168551284, disc_loss = 0.022346673281603256
Trained batch 376 in epoch 9, gen_loss = 0.43723439917324075, disc_loss = 0.022318224875634382
Trained batch 377 in epoch 9, gen_loss = 0.43712732456033193, disc_loss = 0.022273153368144658
Trained batch 378 in epoch 9, gen_loss = 0.43726543000945944, disc_loss = 0.0222601467325158
Trained batch 379 in epoch 9, gen_loss = 0.43733027318590567, disc_loss = 0.022447964706838033
Trained batch 380 in epoch 9, gen_loss = 0.43746593250377286, disc_loss = 0.02316524131496112
Trained batch 381 in epoch 9, gen_loss = 0.43739437097342226, disc_loss = 0.02317408700101809
Trained batch 382 in epoch 9, gen_loss = 0.43717993838668806, disc_loss = 0.023229609956957557
Trained batch 383 in epoch 9, gen_loss = 0.43700392032042146, disc_loss = 0.02342049739278688
Trained batch 384 in epoch 9, gen_loss = 0.4368910791037919, disc_loss = 0.023420885094901086
Trained batch 385 in epoch 9, gen_loss = 0.43699394452139506, disc_loss = 0.02351549601301773
Trained batch 386 in epoch 9, gen_loss = 0.4371190563960901, disc_loss = 0.023481177552049686
Trained batch 387 in epoch 9, gen_loss = 0.43720251252663506, disc_loss = 0.02343802593171971
Trained batch 388 in epoch 9, gen_loss = 0.4369745826813127, disc_loss = 0.023409899710533914
Trained batch 389 in epoch 9, gen_loss = 0.43679681030603557, disc_loss = 0.02336690631808522
Trained batch 390 in epoch 9, gen_loss = 0.4369887650927619, disc_loss = 0.02331881977402179
Trained batch 391 in epoch 9, gen_loss = 0.43683401031457647, disc_loss = 0.023309631991539893
Trained batch 392 in epoch 9, gen_loss = 0.43690035384119924, disc_loss = 0.023266960733745522
Trained batch 393 in epoch 9, gen_loss = 0.43681685384457486, disc_loss = 0.023224455162322594
Trained batch 394 in epoch 9, gen_loss = 0.4369902868059617, disc_loss = 0.02317932195153936
Trained batch 395 in epoch 9, gen_loss = 0.4369604096117646, disc_loss = 0.023134343965494103
Trained batch 396 in epoch 9, gen_loss = 0.4368956527421697, disc_loss = 0.023102945265458703
Trained batch 397 in epoch 9, gen_loss = 0.43703387999654414, disc_loss = 0.023098704114675652
Trained batch 398 in epoch 9, gen_loss = 0.43696642250644235, disc_loss = 0.023191325903057884
Trained batch 399 in epoch 9, gen_loss = 0.4370739818364382, disc_loss = 0.02316027094348101
Trained batch 400 in epoch 9, gen_loss = 0.4374482410952932, disc_loss = 0.02326640935162979
Trained batch 401 in epoch 9, gen_loss = 0.43749164460013756, disc_loss = 0.023231156626473
Trained batch 402 in epoch 9, gen_loss = 0.43743615203696506, disc_loss = 0.02323780743787689
Trained batch 403 in epoch 9, gen_loss = 0.4375367840327839, disc_loss = 0.023228357607985174
Trained batch 404 in epoch 9, gen_loss = 0.43748398849993575, disc_loss = 0.02318633882139154
Trained batch 405 in epoch 9, gen_loss = 0.4373876850299647, disc_loss = 0.023158595520771322
Trained batch 406 in epoch 9, gen_loss = 0.4372912649001185, disc_loss = 0.023139358271332115
Trained batch 407 in epoch 9, gen_loss = 0.4371017579938851, disc_loss = 0.023161262994821585
Trained batch 408 in epoch 9, gen_loss = 0.43710454504180946, disc_loss = 0.023116147968505935
Trained batch 409 in epoch 9, gen_loss = 0.43708717975674605, disc_loss = 0.023101805957749758
Trained batch 410 in epoch 9, gen_loss = 0.436972977906248, disc_loss = 0.023074534672670465
Trained batch 411 in epoch 9, gen_loss = 0.43692306783592816, disc_loss = 0.023106146552679084
Trained batch 412 in epoch 9, gen_loss = 0.43707597111385615, disc_loss = 0.023064294472262353
Trained batch 413 in epoch 9, gen_loss = 0.43696903563352024, disc_loss = 0.02301752713372805
Trained batch 414 in epoch 9, gen_loss = 0.4371581073266914, disc_loss = 0.02297489419551454
Trained batch 415 in epoch 9, gen_loss = 0.43728013136065924, disc_loss = 0.022954704208342055
Trained batch 416 in epoch 9, gen_loss = 0.437298056247423, disc_loss = 0.022912239939213354
Trained batch 417 in epoch 9, gen_loss = 0.4373686847646841, disc_loss = 0.02316383423220197
Trained batch 418 in epoch 9, gen_loss = 0.4371221019999793, disc_loss = 0.0236204965837491
Trained batch 419 in epoch 9, gen_loss = 0.4370167744301614, disc_loss = 0.023863252582460907
Trained batch 420 in epoch 9, gen_loss = 0.43706140700825036, disc_loss = 0.024003294800660373
Trained batch 421 in epoch 9, gen_loss = 0.43701971269331835, disc_loss = 0.024021036810102602
Trained batch 422 in epoch 9, gen_loss = 0.4368329569521243, disc_loss = 0.02403209419413547
Trained batch 423 in epoch 9, gen_loss = 0.4366984229605153, disc_loss = 0.024034700859151343
Trained batch 424 in epoch 9, gen_loss = 0.4367099217807545, disc_loss = 0.024002579533604577
Trained batch 425 in epoch 9, gen_loss = 0.43667283885076014, disc_loss = 0.024116071907119136
Trained batch 426 in epoch 9, gen_loss = 0.4366361074481133, disc_loss = 0.024085561031381878
Trained batch 427 in epoch 9, gen_loss = 0.4367116667399897, disc_loss = 0.02408989120647964
Trained batch 428 in epoch 9, gen_loss = 0.43679671368120987, disc_loss = 0.02405369487544413
Trained batch 429 in epoch 9, gen_loss = 0.4367788137391556, disc_loss = 0.024230425328092088
Trained batch 430 in epoch 9, gen_loss = 0.43680260283764444, disc_loss = 0.024624143798161392
Trained batch 431 in epoch 9, gen_loss = 0.43683115475707585, disc_loss = 0.02458876927132089
Trained batch 432 in epoch 9, gen_loss = 0.43687393841512207, disc_loss = 0.024641389835692563
Trained batch 433 in epoch 9, gen_loss = 0.4368280600842243, disc_loss = 0.02464020077524329
Trained batch 434 in epoch 9, gen_loss = 0.4369482123988798, disc_loss = 0.024719673536193355
Trained batch 435 in epoch 9, gen_loss = 0.4369438337760234, disc_loss = 0.024798439563318248
Trained batch 436 in epoch 9, gen_loss = 0.436977907162782, disc_loss = 0.024776052559717415
Trained batch 437 in epoch 9, gen_loss = 0.4369839780270781, disc_loss = 0.024877199405308848
Trained batch 438 in epoch 9, gen_loss = 0.43698818150033714, disc_loss = 0.025005667353449876
Trained batch 439 in epoch 9, gen_loss = 0.43689455396749755, disc_loss = 0.025287872116578826
Trained batch 440 in epoch 9, gen_loss = 0.4369788142153465, disc_loss = 0.025326394984686574
Trained batch 441 in epoch 9, gen_loss = 0.43703332914216486, disc_loss = 0.02532094757033647
Trained batch 442 in epoch 9, gen_loss = 0.4370599559951851, disc_loss = 0.025292642708630228
Trained batch 443 in epoch 9, gen_loss = 0.4368229349991223, disc_loss = 0.02526664718128699
Trained batch 444 in epoch 9, gen_loss = 0.4367119715454873, disc_loss = 0.025225010791301645
Trained batch 445 in epoch 9, gen_loss = 0.43665020949637406, disc_loss = 0.02520354067976691
Trained batch 446 in epoch 9, gen_loss = 0.43648348345319166, disc_loss = 0.025181628226915113
Trained batch 447 in epoch 9, gen_loss = 0.43652040637763484, disc_loss = 0.02515959362868411
Trained batch 448 in epoch 9, gen_loss = 0.436642320955251, disc_loss = 0.025243477234959122
Trained batch 449 in epoch 9, gen_loss = 0.43669748233424294, disc_loss = 0.02520976648847055
Trained batch 450 in epoch 9, gen_loss = 0.43661565037894406, disc_loss = 0.025213493247714696
Trained batch 451 in epoch 9, gen_loss = 0.4366026758092695, disc_loss = 0.025343938824149936
Trained batch 452 in epoch 9, gen_loss = 0.4368494829331539, disc_loss = 0.02603421413168007
Trained batch 453 in epoch 9, gen_loss = 0.4368634838364723, disc_loss = 0.026005451664654743
Trained batch 454 in epoch 9, gen_loss = 0.43677600753176343, disc_loss = 0.025974990610432413
Trained batch 455 in epoch 9, gen_loss = 0.43666295824866547, disc_loss = 0.025964421892830727
Trained batch 456 in epoch 9, gen_loss = 0.4365426050234154, disc_loss = 0.025963086702889424
Trained batch 457 in epoch 9, gen_loss = 0.43645710546897487, disc_loss = 0.02594955469960526
Trained batch 458 in epoch 9, gen_loss = 0.4365408092672269, disc_loss = 0.026489978354608878
Trained batch 459 in epoch 9, gen_loss = 0.43645567200754, disc_loss = 0.026810030860613787
Trained batch 460 in epoch 9, gen_loss = 0.43637155187104115, disc_loss = 0.026802864001201236
Trained batch 461 in epoch 9, gen_loss = 0.4364373782625446, disc_loss = 0.026881037613334643
Trained batch 462 in epoch 9, gen_loss = 0.4363835584653891, disc_loss = 0.026842544829627786
Trained batch 463 in epoch 9, gen_loss = 0.43620884379950065, disc_loss = 0.026838282906753413
Trained batch 464 in epoch 9, gen_loss = 0.436203146109017, disc_loss = 0.02687192942661744
Trained batch 465 in epoch 9, gen_loss = 0.43611166706156834, disc_loss = 0.026841436719367992
Trained batch 466 in epoch 9, gen_loss = 0.4359444441070393, disc_loss = 0.0268227151389148
Trained batch 467 in epoch 9, gen_loss = 0.43590173711124647, disc_loss = 0.026852748025174882
Trained batch 468 in epoch 9, gen_loss = 0.43599097421174365, disc_loss = 0.02686752371270575
Trained batch 469 in epoch 9, gen_loss = 0.43605218884792735, disc_loss = 0.026871697971983712
Trained batch 470 in epoch 9, gen_loss = 0.4360024140645491, disc_loss = 0.026838649778860184
Trained batch 471 in epoch 9, gen_loss = 0.43596973813186257, disc_loss = 0.026833816004031084
Trained batch 472 in epoch 9, gen_loss = 0.4360327386074792, disc_loss = 0.026793527295547154
Trained batch 473 in epoch 9, gen_loss = 0.4361121780887435, disc_loss = 0.026818676598965415
Trained batch 474 in epoch 9, gen_loss = 0.43605814877309296, disc_loss = 0.026777123125319026
Trained batch 475 in epoch 9, gen_loss = 0.43598734631257896, disc_loss = 0.026817552047584035
Trained batch 476 in epoch 9, gen_loss = 0.43583906759006175, disc_loss = 0.026785197566981882
Trained batch 477 in epoch 9, gen_loss = 0.43570336898999235, disc_loss = 0.026788728407858852
Trained batch 478 in epoch 9, gen_loss = 0.4357958170964474, disc_loss = 0.027282337456628572
Trained batch 479 in epoch 9, gen_loss = 0.43561544629434745, disc_loss = 0.027681117499741958
Trained batch 480 in epoch 9, gen_loss = 0.4355366538567256, disc_loss = 0.02797709237624409
Trained batch 481 in epoch 9, gen_loss = 0.43560058274209745, disc_loss = 0.028120057953712897
Trained batch 482 in epoch 9, gen_loss = 0.43546485160448534, disc_loss = 0.028455884092464256
Trained batch 483 in epoch 9, gen_loss = 0.4354515410651845, disc_loss = 0.028659683208448875
Trained batch 484 in epoch 9, gen_loss = 0.43559793344478015, disc_loss = 0.02897396809157445
Trained batch 485 in epoch 9, gen_loss = 0.43557262512636774, disc_loss = 0.029009258714475794
Trained batch 486 in epoch 9, gen_loss = 0.4355606472834914, disc_loss = 0.029181194985792178
Trained batch 487 in epoch 9, gen_loss = 0.4355603587798408, disc_loss = 0.02923649925329211
Trained batch 488 in epoch 9, gen_loss = 0.435630862942015, disc_loss = 0.02919613811542644
Trained batch 489 in epoch 9, gen_loss = 0.43565049852643695, disc_loss = 0.02930969310881646
Trained batch 490 in epoch 9, gen_loss = 0.4354520627655954, disc_loss = 0.02978107103363795
Trained batch 491 in epoch 9, gen_loss = 0.43548443235032924, disc_loss = 0.02984543080414206
Trained batch 492 in epoch 9, gen_loss = 0.43558933653889514, disc_loss = 0.031574424054675775
Trained batch 493 in epoch 9, gen_loss = 0.4355442547484448, disc_loss = 0.03160052009088059
Trained batch 494 in epoch 9, gen_loss = 0.4353652385148135, disc_loss = 0.03165328400374174
Trained batch 495 in epoch 9, gen_loss = 0.43516754941834557, disc_loss = 0.03167448271016192
Trained batch 496 in epoch 9, gen_loss = 0.43515690231707016, disc_loss = 0.03170025204818966
Trained batch 497 in epoch 9, gen_loss = 0.435119106707324, disc_loss = 0.0317176112455847
Trained batch 498 in epoch 9, gen_loss = 0.4351860936992393, disc_loss = 0.031805215340680655
Trained batch 499 in epoch 9, gen_loss = 0.4349244942069054, disc_loss = 0.03184702977607958
Trained batch 500 in epoch 9, gen_loss = 0.4348760703485645, disc_loss = 0.03191532139659872
Trained batch 501 in epoch 9, gen_loss = 0.43492746228478346, disc_loss = 0.031979054272633076
Trained batch 502 in epoch 9, gen_loss = 0.43484483680004626, disc_loss = 0.03205429869319755
Trained batch 503 in epoch 9, gen_loss = 0.4349094020823638, disc_loss = 0.03216026430752771
Trained batch 504 in epoch 9, gen_loss = 0.43473785991715913, disc_loss = 0.03220622261483591
Trained batch 505 in epoch 9, gen_loss = 0.4347067605483202, disc_loss = 0.03218591674907398
Trained batch 506 in epoch 9, gen_loss = 0.4346836780655314, disc_loss = 0.0322210445154653
Trained batch 507 in epoch 9, gen_loss = 0.4346468947886482, disc_loss = 0.03218640304811291
Trained batch 508 in epoch 9, gen_loss = 0.4346600560753191, disc_loss = 0.03214390503314885
Trained batch 509 in epoch 9, gen_loss = 0.43455867340751725, disc_loss = 0.032280596717050775
Trained batch 510 in epoch 9, gen_loss = 0.43442465951064796, disc_loss = 0.03258518467009352
Trained batch 511 in epoch 9, gen_loss = 0.4342644829885103, disc_loss = 0.032655963389288445
Trained batch 512 in epoch 9, gen_loss = 0.43436062701961453, disc_loss = 0.03285328690103322
Trained batch 513 in epoch 9, gen_loss = 0.43433827387915513, disc_loss = 0.03282902663612579
Trained batch 514 in epoch 9, gen_loss = 0.4342252678662828, disc_loss = 0.03293352148662891
Trained batch 515 in epoch 9, gen_loss = 0.4341702177658562, disc_loss = 0.033083903190613065
Trained batch 516 in epoch 9, gen_loss = 0.4342184839788212, disc_loss = 0.03303820872116416
Trained batch 517 in epoch 9, gen_loss = 0.4341638301675384, disc_loss = 0.03298659311067205
Trained batch 518 in epoch 9, gen_loss = 0.43420423363444893, disc_loss = 0.03295626703928797
Trained batch 519 in epoch 9, gen_loss = 0.4341912164137914, disc_loss = 0.03299913325575359
Trained batch 520 in epoch 9, gen_loss = 0.4341225998186562, disc_loss = 0.032985078054480255
Trained batch 521 in epoch 9, gen_loss = 0.4340469144655827, disc_loss = 0.03293994377377011
Trained batch 522 in epoch 9, gen_loss = 0.4339783928476374, disc_loss = 0.03316334818768534
Trained batch 523 in epoch 9, gen_loss = 0.433913005558589, disc_loss = 0.033164502910421875
Trained batch 524 in epoch 9, gen_loss = 0.43401354466165815, disc_loss = 0.033186989305762665
Trained batch 525 in epoch 9, gen_loss = 0.43379677384525195, disc_loss = 0.033660067429282695
Trained batch 526 in epoch 9, gen_loss = 0.4337095224653747, disc_loss = 0.03365276989626895
Trained batch 527 in epoch 9, gen_loss = 0.4336569206506917, disc_loss = 0.033817218118973404
Trained batch 528 in epoch 9, gen_loss = 0.43352493542353915, disc_loss = 0.03391339995705528
Trained batch 529 in epoch 9, gen_loss = 0.43376956419000084, disc_loss = 0.03404113159334849
Trained batch 530 in epoch 9, gen_loss = 0.4338561271206807, disc_loss = 0.03400286276173197
Trained batch 531 in epoch 9, gen_loss = 0.433858441511043, disc_loss = 0.033970941239539046
Trained batch 532 in epoch 9, gen_loss = 0.4337984159113542, disc_loss = 0.034012596211815516
Trained batch 533 in epoch 9, gen_loss = 0.4339980831306972, disc_loss = 0.034049320892537226
Trained batch 534 in epoch 9, gen_loss = 0.4339380547265026, disc_loss = 0.034017079842067977
Trained batch 535 in epoch 9, gen_loss = 0.4338554514210616, disc_loss = 0.03398046506296864
Trained batch 536 in epoch 9, gen_loss = 0.43368503490195814, disc_loss = 0.034034640096202565
Trained batch 537 in epoch 9, gen_loss = 0.4337842020735865, disc_loss = 0.034007338626737806
Trained batch 538 in epoch 9, gen_loss = 0.43389876322312787, disc_loss = 0.03401608294431562
Trained batch 539 in epoch 9, gen_loss = 0.4338453792311527, disc_loss = 0.03397581288914403
Trained batch 540 in epoch 9, gen_loss = 0.43384530071630495, disc_loss = 0.03393158631622206
Trained batch 541 in epoch 9, gen_loss = 0.433858772320501, disc_loss = 0.033881265619156255
Trained batch 542 in epoch 9, gen_loss = 0.4338254582816066, disc_loss = 0.03399653376434273
Trained batch 543 in epoch 9, gen_loss = 0.43395605935331655, disc_loss = 0.0344316369127602
Trained batch 544 in epoch 9, gen_loss = 0.43392429745525396, disc_loss = 0.03486936068175139
Trained batch 545 in epoch 9, gen_loss = 0.4339153238814392, disc_loss = 0.03521460076796587
Trained batch 546 in epoch 9, gen_loss = 0.4338166921295675, disc_loss = 0.035488665325888916
Trained batch 547 in epoch 9, gen_loss = 0.43364468363732317, disc_loss = 0.03561237982340857
Trained batch 548 in epoch 9, gen_loss = 0.43342194791700017, disc_loss = 0.03589217677328206
Trained batch 549 in epoch 9, gen_loss = 0.4333000626889142, disc_loss = 0.03602428160332651
Trained batch 550 in epoch 9, gen_loss = 0.4332464883093825, disc_loss = 0.03620434586637351
Trained batch 551 in epoch 9, gen_loss = 0.43323144565025967, disc_loss = 0.036349056441078734
Trained batch 552 in epoch 9, gen_loss = 0.4330427925797957, disc_loss = 0.036399336491970795
Trained batch 553 in epoch 9, gen_loss = 0.43296436120887094, disc_loss = 0.03641346071839218
Trained batch 554 in epoch 9, gen_loss = 0.43309942999401607, disc_loss = 0.03642534091124764
Trained batch 555 in epoch 9, gen_loss = 0.43307611019276887, disc_loss = 0.0364375506976214
Trained batch 556 in epoch 9, gen_loss = 0.4330147478589036, disc_loss = 0.036466153459564936
Trained batch 557 in epoch 9, gen_loss = 0.43296074653611816, disc_loss = 0.036426644791276476
Trained batch 558 in epoch 9, gen_loss = 0.43291506011285597, disc_loss = 0.03642014050768765
Trained batch 559 in epoch 9, gen_loss = 0.4328077432832548, disc_loss = 0.036366931360472726
Trained batch 560 in epoch 9, gen_loss = 0.4326366843811756, disc_loss = 0.036341514290433294
Trained batch 561 in epoch 9, gen_loss = 0.4327426931930182, disc_loss = 0.03634738499026089
Trained batch 562 in epoch 9, gen_loss = 0.4329087745338731, disc_loss = 0.03639579265064942
Trained batch 563 in epoch 9, gen_loss = 0.4328557818810991, disc_loss = 0.0363850863037403
Trained batch 564 in epoch 9, gen_loss = 0.43270032453325996, disc_loss = 0.03633947301371666
Trained batch 565 in epoch 9, gen_loss = 0.43265970962207645, disc_loss = 0.03632783699371809
Trained batch 566 in epoch 9, gen_loss = 0.43265652377979674, disc_loss = 0.0363604808684087
Trained batch 567 in epoch 9, gen_loss = 0.4326107736519525, disc_loss = 0.03662291013543054
Trained batch 568 in epoch 9, gen_loss = 0.4326632523054817, disc_loss = 0.036717023070114346
Trained batch 569 in epoch 9, gen_loss = 0.4327544653624819, disc_loss = 0.03666975039216739
Trained batch 570 in epoch 9, gen_loss = 0.4327366442897483, disc_loss = 0.03664890031314793
Trained batch 571 in epoch 9, gen_loss = 0.43269812482428716, disc_loss = 0.03662944582296646
Trained batch 572 in epoch 9, gen_loss = 0.4325556355101068, disc_loss = 0.03661340869533265
Trained batch 573 in epoch 9, gen_loss = 0.43244460463939227, disc_loss = 0.036607511411137064
Trained batch 574 in epoch 9, gen_loss = 0.43247931480407714, disc_loss = 0.03657492057602529
Trained batch 575 in epoch 9, gen_loss = 0.43244863187687266, disc_loss = 0.036531378160766
Trained batch 576 in epoch 9, gen_loss = 0.4324350607043949, disc_loss = 0.03655017148747724
Trained batch 577 in epoch 9, gen_loss = 0.4324332155983341, disc_loss = 0.03655465404969514
Trained batch 578 in epoch 9, gen_loss = 0.43233007130845225, disc_loss = 0.036555596591706915
Trained batch 579 in epoch 9, gen_loss = 0.432399418641781, disc_loss = 0.03652703525189407
Trained batch 580 in epoch 9, gen_loss = 0.43234210893537417, disc_loss = 0.03648826838475003
Trained batch 581 in epoch 9, gen_loss = 0.4323902921783146, disc_loss = 0.03647370281676471
Trained batch 582 in epoch 9, gen_loss = 0.4324725493149733, disc_loss = 0.036479505406585594
Trained batch 583 in epoch 9, gen_loss = 0.4323575036370591, disc_loss = 0.03652798414867441
Trained batch 584 in epoch 9, gen_loss = 0.4322246745101407, disc_loss = 0.036591674716800894
Trained batch 585 in epoch 9, gen_loss = 0.4322441143489128, disc_loss = 0.03656743976518785
Trained batch 586 in epoch 9, gen_loss = 0.43234672528109314, disc_loss = 0.0365399181431483
Trained batch 587 in epoch 9, gen_loss = 0.43237295214618954, disc_loss = 0.036502558615836345
Trained batch 588 in epoch 9, gen_loss = 0.43237031118371894, disc_loss = 0.03646676741830581
Trained batch 589 in epoch 9, gen_loss = 0.4323161327232749, disc_loss = 0.03646379845449701
Trained batch 590 in epoch 9, gen_loss = 0.43226640564334373, disc_loss = 0.03642790278088138
Trained batch 591 in epoch 9, gen_loss = 0.4323492550064583, disc_loss = 0.036410589231849914
Trained batch 592 in epoch 9, gen_loss = 0.4322845578495206, disc_loss = 0.03637595248701519
Trained batch 593 in epoch 9, gen_loss = 0.4323035428921382, disc_loss = 0.03635526759693437
Trained batch 594 in epoch 9, gen_loss = 0.4324267279701073, disc_loss = 0.03630611624611745
Trained batch 595 in epoch 9, gen_loss = 0.43252298410906886, disc_loss = 0.036287722110415456
Trained batch 596 in epoch 9, gen_loss = 0.43246314358870985, disc_loss = 0.0362870513757541
Trained batch 597 in epoch 9, gen_loss = 0.43260560222094674, disc_loss = 0.03631845803251552
Trained batch 598 in epoch 9, gen_loss = 0.4324953196343277, disc_loss = 0.036453044587530146
Testing Epoch 9
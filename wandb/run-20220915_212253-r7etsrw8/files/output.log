/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 3.0881776809692383, disc_loss = 0.609685480594635
Trained batch 1 in epoch 0, gen_loss = 2.7160375118255615, disc_loss = 0.5651646554470062
Trained batch 2 in epoch 0, gen_loss = 2.7869957288106284, disc_loss = 0.6323187947273254
Trained batch 3 in epoch 0, gen_loss = 2.610826790332794, disc_loss = 0.6319401413202286
Trained batch 4 in epoch 0, gen_loss = 2.6069227695465087, disc_loss = 0.5738835334777832
Trained batch 5 in epoch 0, gen_loss = 2.6141525506973267, disc_loss = 0.5342167665561041
Trained batch 6 in epoch 0, gen_loss = 2.55181200163705, disc_loss = 0.49581189666475567
Trained batch 7 in epoch 0, gen_loss = 2.5346014499664307, disc_loss = 0.463349137455225
Trained batch 8 in epoch 0, gen_loss = 2.475324895646837, disc_loss = 0.43552624848153854
Trained batch 9 in epoch 0, gen_loss = 2.4512721061706544, disc_loss = 0.4117755353450775
Trained batch 10 in epoch 0, gen_loss = 2.419747157530351, disc_loss = 0.3888911388137124
Trained batch 11 in epoch 0, gen_loss = 2.413863480091095, disc_loss = 0.3682615968088309
Trained batch 12 in epoch 0, gen_loss = 2.419460113231952, disc_loss = 0.35029264940665317
Trained batch 13 in epoch 0, gen_loss = 2.4019208465303694, disc_loss = 0.3343891618507249
Trained batch 14 in epoch 0, gen_loss = 2.398360840479533, disc_loss = 0.3210186054309209
Trained batch 15 in epoch 0, gen_loss = 2.406427815556526, disc_loss = 0.3094376511871815
Trained batch 16 in epoch 0, gen_loss = 2.4142934294307934, disc_loss = 0.301188176169115
Trained batch 17 in epoch 0, gen_loss = 2.4186491701338024, disc_loss = 0.2919413306646877
Trained batch 18 in epoch 0, gen_loss = 2.4268520254837838, disc_loss = 0.2817597828413311
Trained batch 19 in epoch 0, gen_loss = 2.443112349510193, disc_loss = 0.272125406190753
Trained batch 20 in epoch 0, gen_loss = 2.424763656797863, disc_loss = 0.26463871804021655
Trained batch 21 in epoch 0, gen_loss = 2.425911632451144, disc_loss = 0.256489157338034
Trained batch 22 in epoch 0, gen_loss = 2.408765595892201, disc_loss = 0.24956920969745386
Trained batch 23 in epoch 0, gen_loss = 2.4206210374832153, disc_loss = 0.2426779130473733
Trained batch 24 in epoch 0, gen_loss = 2.4186893463134767, disc_loss = 0.23595799267292022
Trained batch 25 in epoch 0, gen_loss = 2.4353511333465576, disc_loss = 0.22967189435775465
Trained batch 26 in epoch 0, gen_loss = 2.4324319274337203, disc_loss = 0.22418484892006274
Trained batch 27 in epoch 0, gen_loss = 2.4394742250442505, disc_loss = 0.2193714561206954
Trained batch 28 in epoch 0, gen_loss = 2.435242825541003, disc_loss = 0.21490937599848056
Trained batch 29 in epoch 0, gen_loss = 2.423785909016927, disc_loss = 0.21058343723416328
Trained batch 30 in epoch 0, gen_loss = 2.423001681604693, disc_loss = 0.2069310928064008
Trained batch 31 in epoch 0, gen_loss = 2.421648807823658, disc_loss = 0.203795867273584
Trained batch 32 in epoch 0, gen_loss = 2.4314333886811226, disc_loss = 0.20001592712871957
Trained batch 33 in epoch 0, gen_loss = 2.4226305695141064, disc_loss = 0.19581066729391322
Trained batch 34 in epoch 0, gen_loss = 2.421307931627546, disc_loss = 0.19293163652930942
Trained batch 35 in epoch 0, gen_loss = 2.4249834749433727, disc_loss = 0.19027820581363308
Trained batch 36 in epoch 0, gen_loss = 2.428819443728473, disc_loss = 0.1870684867372384
Trained batch 37 in epoch 0, gen_loss = 2.4268733764949597, disc_loss = 0.18414997878043274
Trained batch 38 in epoch 0, gen_loss = 2.4364595107543163, disc_loss = 0.18246654115426234
Trained batch 39 in epoch 0, gen_loss = 2.443194717168808, disc_loss = 0.18160993475466966
Trained batch 40 in epoch 0, gen_loss = 2.441713292424272, disc_loss = 0.17894157367508587
Trained batch 41 in epoch 0, gen_loss = 2.43951640242622, disc_loss = 0.17726525096666246
Trained batch 42 in epoch 0, gen_loss = 2.4408226124075956, disc_loss = 0.17526345162890677
Trained batch 43 in epoch 0, gen_loss = 2.436702072620392, disc_loss = 0.17244937304746022
Trained batch 44 in epoch 0, gen_loss = 2.4371634324391684, disc_loss = 0.1697834054629008
Trained batch 45 in epoch 0, gen_loss = 2.4343532375667407, disc_loss = 0.16909165939559107
Trained batch 46 in epoch 0, gen_loss = 2.4339266635001975, disc_loss = 0.1726704512504821
Trained batch 47 in epoch 0, gen_loss = 2.4296950002511344, disc_loss = 0.1708548575018843
Trained batch 48 in epoch 0, gen_loss = 2.4267154226497727, disc_loss = 0.1688719841898704
Trained batch 49 in epoch 0, gen_loss = 2.4283557081222535, disc_loss = 0.16624295547604562
Trained batch 50 in epoch 0, gen_loss = 2.428236377005484, disc_loss = 0.1638166382908821
Trained batch 51 in epoch 0, gen_loss = 2.4259428152671227, disc_loss = 0.16124897733187446
Trained batch 52 in epoch 0, gen_loss = 2.4272680822408423, disc_loss = 0.1587430447832031
Trained batch 53 in epoch 0, gen_loss = 2.4324718802063554, disc_loss = 0.1562685619832741
Trained batch 54 in epoch 0, gen_loss = 2.429629681327126, disc_loss = 0.1539621634578163
Trained batch 55 in epoch 0, gen_loss = 2.42859753540584, disc_loss = 0.15162231916162586
Trained batch 56 in epoch 0, gen_loss = 2.4260473000375846, disc_loss = 0.14944710664189698
Trained batch 57 in epoch 0, gen_loss = 2.4270818027956733, disc_loss = 0.14736307158680825
Trained batch 58 in epoch 0, gen_loss = 2.424383971650722, disc_loss = 0.14555600875893893
Trained batch 59 in epoch 0, gen_loss = 2.4198074261347453, disc_loss = 0.14373254735643665
Trained batch 60 in epoch 0, gen_loss = 2.4189669577801816, disc_loss = 0.14194826088601448
Trained batch 61 in epoch 0, gen_loss = 2.420312900697031, disc_loss = 0.14020095834688795
Trained batch 62 in epoch 0, gen_loss = 2.4143527046082514, disc_loss = 0.13852727439786708
Trained batch 63 in epoch 0, gen_loss = 2.4143035784363747, disc_loss = 0.1368542508862447
Trained batch 64 in epoch 0, gen_loss = 2.411324016864483, disc_loss = 0.13526119999587535
Trained batch 65 in epoch 0, gen_loss = 2.413303823182077, disc_loss = 0.13358821976704127
Trained batch 66 in epoch 0, gen_loss = 2.411234777365158, disc_loss = 0.13197957068236907
Trained batch 67 in epoch 0, gen_loss = 2.414279208463781, disc_loss = 0.13062921100679567
Trained batch 68 in epoch 0, gen_loss = 2.4138764989548833, disc_loss = 0.12947529808118724
Trained batch 69 in epoch 0, gen_loss = 2.414267843110221, disc_loss = 0.12860258876213004
Trained batch 70 in epoch 0, gen_loss = 2.416452471639069, disc_loss = 0.1276280482784963
Trained batch 71 in epoch 0, gen_loss = 2.41650836997562, disc_loss = 0.12660518024737635
Trained batch 72 in epoch 0, gen_loss = 2.4110359361726945, disc_loss = 0.12546317151760403
Trained batch 73 in epoch 0, gen_loss = 2.4099382290969023, disc_loss = 0.12423060205135797
Trained batch 74 in epoch 0, gen_loss = 2.411675640741984, disc_loss = 0.1228755185008049
Trained batch 75 in epoch 0, gen_loss = 2.416652023792267, disc_loss = 0.12157892092670265
Trained batch 76 in epoch 0, gen_loss = 2.417188127319534, disc_loss = 0.12033343837632761
Trained batch 77 in epoch 0, gen_loss = 2.4206909797130485, disc_loss = 0.11914397224497336
Trained batch 78 in epoch 0, gen_loss = 2.4206684269482577, disc_loss = 0.11800362313567084
Trained batch 79 in epoch 0, gen_loss = 2.4225093692541124, disc_loss = 0.11704929603729397
Trained batch 80 in epoch 0, gen_loss = 2.423228081361747, disc_loss = 0.11688793940400635
Trained batch 81 in epoch 0, gen_loss = 2.424360001959452, disc_loss = 0.11818602792464378
Trained batch 82 in epoch 0, gen_loss = 2.4247160388762694, disc_loss = 0.11933028377053967
Trained batch 83 in epoch 0, gen_loss = 2.4238279859224954, disc_loss = 0.1235544405034965
Trained batch 84 in epoch 0, gen_loss = 2.42802955122555, disc_loss = 0.12580262214383658
Trained batch 85 in epoch 0, gen_loss = 2.427312961844511, disc_loss = 0.1276272230586687
Trained batch 86 in epoch 0, gen_loss = 2.4316118311607973, disc_loss = 0.130970922031108
Trained batch 87 in epoch 0, gen_loss = 2.4350131885571913, disc_loss = 0.1324272921351208
Trained batch 88 in epoch 0, gen_loss = 2.4327447950170282, disc_loss = 0.13200732774697663
Trained batch 89 in epoch 0, gen_loss = 2.430345058441162, disc_loss = 0.13136855655660232
Trained batch 90 in epoch 0, gen_loss = 2.429465555882716, disc_loss = 0.13045892403921583
Trained batch 91 in epoch 0, gen_loss = 2.430606238220049, disc_loss = 0.1294472686662946
Trained batch 92 in epoch 0, gen_loss = 2.4265249313846713, disc_loss = 0.12850116011035698
Trained batch 93 in epoch 0, gen_loss = 2.4264293021344123, disc_loss = 0.12741537675499282
Trained batch 94 in epoch 0, gen_loss = 2.4293505342383135, disc_loss = 0.12631652059131546
Trained batch 95 in epoch 0, gen_loss = 2.433940460284551, disc_loss = 0.12522459257161245
Trained batch 96 in epoch 0, gen_loss = 2.4353215276580498, disc_loss = 0.1241871747620327
Trained batch 97 in epoch 0, gen_loss = 2.432545564612564, disc_loss = 0.1231922041054587
Trained batch 98 in epoch 0, gen_loss = 2.4318122478446575, disc_loss = 0.12218164191628346
Trained batch 99 in epoch 0, gen_loss = 2.435473852157593, disc_loss = 0.12114724222570658
Trained batch 100 in epoch 0, gen_loss = 2.435691200860656, disc_loss = 0.12015488788042919
Trained batch 101 in epoch 0, gen_loss = 2.4397795247096643, disc_loss = 0.11925392939398687
Trained batch 102 in epoch 0, gen_loss = 2.4397736405863344, disc_loss = 0.11835025764495424
Trained batch 103 in epoch 0, gen_loss = 2.4401451418033013, disc_loss = 0.11739591147320774
Trained batch 104 in epoch 0, gen_loss = 2.440951935450236, disc_loss = 0.11642949190877733
Trained batch 105 in epoch 0, gen_loss = 2.439137431810487, disc_loss = 0.11557767779197332
Trained batch 106 in epoch 0, gen_loss = 2.4352902742189784, disc_loss = 0.11475183139337558
Trained batch 107 in epoch 0, gen_loss = 2.4350193363648875, disc_loss = 0.11386766224340708
Trained batch 108 in epoch 0, gen_loss = 2.4356884278288673, disc_loss = 0.112950944196467
Trained batch 109 in epoch 0, gen_loss = 2.435696268081665, disc_loss = 0.11210569893433289
Trained batch 110 in epoch 0, gen_loss = 2.4362894651052116, disc_loss = 0.11129224862534183
Trained batch 111 in epoch 0, gen_loss = 2.43346620457513, disc_loss = 0.1104535921643089
Trained batch 112 in epoch 0, gen_loss = 2.4330087045652675, disc_loss = 0.1096152211910328
Trained batch 113 in epoch 0, gen_loss = 2.4346402988099216, disc_loss = 0.10884939568738143
Trained batch 114 in epoch 0, gen_loss = 2.4359892513441004, disc_loss = 0.10811011805806471
Trained batch 115 in epoch 0, gen_loss = 2.435243234552186, disc_loss = 0.10736225611241214
Trained batch 116 in epoch 0, gen_loss = 2.4374193330096383, disc_loss = 0.10658736555622174
Trained batch 117 in epoch 0, gen_loss = 2.4368141424857965, disc_loss = 0.10579925480346053
Trained batch 118 in epoch 0, gen_loss = 2.4357486893148983, disc_loss = 0.10504294415356732
Trained batch 119 in epoch 0, gen_loss = 2.4329918841520946, disc_loss = 0.10433677285909652
Trained batch 120 in epoch 0, gen_loss = 2.434378495886306, disc_loss = 0.10357884888745043
Trained batch 121 in epoch 0, gen_loss = 2.434650821763961, disc_loss = 0.10282853129701536
Trained batch 122 in epoch 0, gen_loss = 2.4342586160675297, disc_loss = 0.10210719319984196
Trained batch 123 in epoch 0, gen_loss = 2.4376513919522687, disc_loss = 0.10141504342637715
Trained batch 124 in epoch 0, gen_loss = 2.436144649505615, disc_loss = 0.10072115563601255
Trained batch 125 in epoch 0, gen_loss = 2.436411183977884, disc_loss = 0.10003513120676553
Trained batch 126 in epoch 0, gen_loss = 2.4364211240152676, disc_loss = 0.09936703609551971
Trained batch 127 in epoch 0, gen_loss = 2.437097154557705, disc_loss = 0.09871379908872768
Trained batch 128 in epoch 0, gen_loss = 2.4359488635100135, disc_loss = 0.09808460985447547
Trained batch 129 in epoch 0, gen_loss = 2.4352251291275024, disc_loss = 0.09744621314681494
Trained batch 130 in epoch 0, gen_loss = 2.4357126669119333, disc_loss = 0.0967880011685477
Trained batch 131 in epoch 0, gen_loss = 2.436719025626327, disc_loss = 0.09614174086318324
Trained batch 132 in epoch 0, gen_loss = 2.436270810607681, disc_loss = 0.09552097614658506
Trained batch 133 in epoch 0, gen_loss = 2.436443412481849, disc_loss = 0.09492625760387129
Trained batch 134 in epoch 0, gen_loss = 2.4371539575082286, disc_loss = 0.09435161752281365
Trained batch 135 in epoch 0, gen_loss = 2.4387761494692635, disc_loss = 0.09380432793541867
Trained batch 136 in epoch 0, gen_loss = 2.4393931166098937, disc_loss = 0.09328251145780087
Trained batch 137 in epoch 0, gen_loss = 2.4408870088881343, disc_loss = 0.0927119479528156
Trained batch 138 in epoch 0, gen_loss = 2.442711689489351, disc_loss = 0.0921441621059994
Trained batch 139 in epoch 0, gen_loss = 2.4444403290748595, disc_loss = 0.09158145918377808
Trained batch 140 in epoch 0, gen_loss = 2.4426695624141828, disc_loss = 0.09102425792961256
Trained batch 141 in epoch 0, gen_loss = 2.4440444556760115, disc_loss = 0.09045621506135229
Trained batch 142 in epoch 0, gen_loss = 2.4437519687039035, disc_loss = 0.08988600749183785
Trained batch 143 in epoch 0, gen_loss = 2.4434814784261913, disc_loss = 0.0893404638627544
Trained batch 144 in epoch 0, gen_loss = 2.441856162301425, disc_loss = 0.08879488468298624
Trained batch 145 in epoch 0, gen_loss = 2.439944133366624, disc_loss = 0.08825458718897546
Trained batch 146 in epoch 0, gen_loss = 2.440414018371478, disc_loss = 0.08778975760804958
Trained batch 147 in epoch 0, gen_loss = 2.440057615976076, disc_loss = 0.08750622698131043
Trained batch 148 in epoch 0, gen_loss = 2.4425708047495593, disc_loss = 0.08721221239624807
Trained batch 149 in epoch 0, gen_loss = 2.4425587193171183, disc_loss = 0.08676649807641904
Trained batch 150 in epoch 0, gen_loss = 2.445589536073192, disc_loss = 0.08630611363872392
Trained batch 151 in epoch 0, gen_loss = 2.444908833817432, disc_loss = 0.08580283430944148
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 2.0288352966308594, disc_loss = 0.017947470769286156
Trained batch 1 in epoch 1, gen_loss = 2.037130355834961, disc_loss = 0.017268714495003223
Trained batch 2 in epoch 1, gen_loss = 2.163912773132324, disc_loss = 0.015884458397825558
Trained batch 3 in epoch 1, gen_loss = 2.1934434175491333, disc_loss = 0.013687106198631227
Trained batch 4 in epoch 1, gen_loss = 2.2268520832061767, disc_loss = 0.01254316559061408
Trained batch 5 in epoch 1, gen_loss = 2.303002715110779, disc_loss = 0.012386237038299441
Trained batch 6 in epoch 1, gen_loss = 2.3147763184138705, disc_loss = 0.012044796254485846
Trained batch 7 in epoch 1, gen_loss = 2.3143841326236725, disc_loss = 0.01166933897184208
Trained batch 8 in epoch 1, gen_loss = 2.3357853094736734, disc_loss = 0.011217306419793103
Trained batch 9 in epoch 1, gen_loss = 2.380782055854797, disc_loss = 0.010749668488278985
Trained batch 10 in epoch 1, gen_loss = 2.3685881441289727, disc_loss = 0.01051553317599676
Trained batch 11 in epoch 1, gen_loss = 2.3811988830566406, disc_loss = 0.010598157028046748
Trained batch 12 in epoch 1, gen_loss = 2.3679315126859226, disc_loss = 0.011322903769234052
Trained batch 13 in epoch 1, gen_loss = 2.383550831249782, disc_loss = 0.014620319773842181
Trained batch 14 in epoch 1, gen_loss = 2.331206027666728, disc_loss = 0.02832884363209208
Trained batch 15 in epoch 1, gen_loss = 2.349693663418293, disc_loss = 0.028310485737165436
Trained batch 16 in epoch 1, gen_loss = 2.387409609906814, disc_loss = 0.029647534904891953
Trained batch 17 in epoch 1, gen_loss = 2.3777209056748285, disc_loss = 0.029236720642074943
Trained batch 18 in epoch 1, gen_loss = 2.3826798828024613, disc_loss = 0.028930930494281807
Trained batch 19 in epoch 1, gen_loss = 2.3781013786792755, disc_loss = 0.02805534170474857
Trained batch 20 in epoch 1, gen_loss = 2.389344096183777, disc_loss = 0.027145872225186655
Trained batch 21 in epoch 1, gen_loss = 2.3816607919606296, disc_loss = 0.02707629970444197
Trained batch 22 in epoch 1, gen_loss = 2.3845413508622544, disc_loss = 0.027523475800357435
Trained batch 23 in epoch 1, gen_loss = 2.390826220313708, disc_loss = 0.02748184750089422
Trained batch 24 in epoch 1, gen_loss = 2.4097081232070923, disc_loss = 0.026806293595582245
Trained batch 25 in epoch 1, gen_loss = 2.415576948569371, disc_loss = 0.026062990395495526
Trained batch 26 in epoch 1, gen_loss = 2.411851198584945, disc_loss = 0.0255157342525544
Trained batch 27 in epoch 1, gen_loss = 2.4100428266184672, disc_loss = 0.025073179941890494
Trained batch 28 in epoch 1, gen_loss = 2.4160933289034614, disc_loss = 0.024558735658125632
Trained batch 29 in epoch 1, gen_loss = 2.421698208649953, disc_loss = 0.023947725848605234
Trained batch 30 in epoch 1, gen_loss = 2.4311064635553667, disc_loss = 0.023364358912071875
Trained batch 31 in epoch 1, gen_loss = 2.437401954084635, disc_loss = 0.022807163244578987
Trained batch 32 in epoch 1, gen_loss = 2.452756292892225, disc_loss = 0.022333328315818853
Trained batch 33 in epoch 1, gen_loss = 2.4482281663838554, disc_loss = 0.022115173270268476
Trained batch 34 in epoch 1, gen_loss = 2.4371887717928207, disc_loss = 0.021886019315570594
Trained batch 35 in epoch 1, gen_loss = 2.444933318429523, disc_loss = 0.021531369368959632
Trained batch 36 in epoch 1, gen_loss = 2.4353821696461857, disc_loss = 0.021231568582053925
Trained batch 37 in epoch 1, gen_loss = 2.4374734947555945, disc_loss = 0.021027485288581567
Trained batch 38 in epoch 1, gen_loss = 2.451271023505773, disc_loss = 0.020783889692467757
Trained batch 39 in epoch 1, gen_loss = 2.4510099798440934, disc_loss = 0.020550805318634957
Trained batch 40 in epoch 1, gen_loss = 2.456769794952579, disc_loss = 0.020225266130959114
Trained batch 41 in epoch 1, gen_loss = 2.455546103772663, disc_loss = 0.019896352574938818
Trained batch 42 in epoch 1, gen_loss = 2.4502612851386845, disc_loss = 0.01965654446461866
Trained batch 43 in epoch 1, gen_loss = 2.4450147937644613, disc_loss = 0.019428516484119675
Trained batch 44 in epoch 1, gen_loss = 2.4553799125883313, disc_loss = 0.019153659573445718
Trained batch 45 in epoch 1, gen_loss = 2.4548133844914646, disc_loss = 0.01885909824024724
Trained batch 46 in epoch 1, gen_loss = 2.4620114108349416, disc_loss = 0.01858286059243565
Trained batch 47 in epoch 1, gen_loss = 2.4575220122933388, disc_loss = 0.018343187655167032
Trained batch 48 in epoch 1, gen_loss = 2.458266489359797, disc_loss = 0.018127220929885397
Trained batch 49 in epoch 1, gen_loss = 2.4544997000694275, disc_loss = 0.017904638573527337
Trained batch 50 in epoch 1, gen_loss = 2.448783011997447, disc_loss = 0.01768238263606441
Trained batch 51 in epoch 1, gen_loss = 2.4446240732303033, disc_loss = 0.017492093754789002
Trained batch 52 in epoch 1, gen_loss = 2.4450293104603604, disc_loss = 0.017350393804317375
Trained batch 53 in epoch 1, gen_loss = 2.450116905901167, disc_loss = 0.01724259174187426
Trained batch 54 in epoch 1, gen_loss = 2.447310488874262, disc_loss = 0.017122069797055287
Trained batch 55 in epoch 1, gen_loss = 2.4520832491772517, disc_loss = 0.017005145849127854
Trained batch 56 in epoch 1, gen_loss = 2.455764935727705, disc_loss = 0.01690779657413562
Trained batch 57 in epoch 1, gen_loss = 2.4545036574889876, disc_loss = 0.01673411359560901
Trained batch 58 in epoch 1, gen_loss = 2.4548002360230785, disc_loss = 0.016532212543159217
Trained batch 59 in epoch 1, gen_loss = 2.4524436136086782, disc_loss = 0.016345154214650392
Trained batch 60 in epoch 1, gen_loss = 2.448079161956662, disc_loss = 0.016473199714158403
Trained batch 61 in epoch 1, gen_loss = 2.445166920461962, disc_loss = 0.016569118436065414
Trained batch 62 in epoch 1, gen_loss = 2.4468032159502546, disc_loss = 0.016473931230841173
Trained batch 63 in epoch 1, gen_loss = 2.447432527318597, disc_loss = 0.016341934227966703
Trained batch 64 in epoch 1, gen_loss = 2.4462804665932287, disc_loss = 0.016181668280982053
Trained batch 65 in epoch 1, gen_loss = 2.4480024052388742, disc_loss = 0.015997015835830207
Trained batch 66 in epoch 1, gen_loss = 2.450372074967, disc_loss = 0.01588496882051452
Trained batch 67 in epoch 1, gen_loss = 2.4526651869801914, disc_loss = 0.01575193406931837
Trained batch 68 in epoch 1, gen_loss = 2.454043127488399, disc_loss = 0.01561040159287876
Trained batch 69 in epoch 1, gen_loss = 2.4496557899883817, disc_loss = 0.015496832631262286
Trained batch 70 in epoch 1, gen_loss = 2.4424833160051156, disc_loss = 0.015478881869570051
Trained batch 71 in epoch 1, gen_loss = 2.4457258764240475, disc_loss = 0.015437153782436831
Trained batch 72 in epoch 1, gen_loss = 2.4442671178138418, disc_loss = 0.015533400973789904
Trained batch 73 in epoch 1, gen_loss = 2.4443659154144495, disc_loss = 0.015550627190670048
Trained batch 74 in epoch 1, gen_loss = 2.448942020734151, disc_loss = 0.015465622426321109
Trained batch 75 in epoch 1, gen_loss = 2.4479343655862307, disc_loss = 0.015364637733192035
Trained batch 76 in epoch 1, gen_loss = 2.45264547056966, disc_loss = 0.015241775758467711
Trained batch 77 in epoch 1, gen_loss = 2.4536968790567837, disc_loss = 0.015121486211100068
Trained batch 78 in epoch 1, gen_loss = 2.4556392129463487, disc_loss = 0.01498862096002396
Trained batch 79 in epoch 1, gen_loss = 2.453316552937031, disc_loss = 0.014870279171736911
Trained batch 80 in epoch 1, gen_loss = 2.4533357164006175, disc_loss = 0.014779105086891372
Trained batch 81 in epoch 1, gen_loss = 2.4525915602358377, disc_loss = 0.014700638510786542
Trained batch 82 in epoch 1, gen_loss = 2.45050429292472, disc_loss = 0.014634841609835983
Trained batch 83 in epoch 1, gen_loss = 2.44769330677532, disc_loss = 0.014522786313180058
Trained batch 84 in epoch 1, gen_loss = 2.450535573678858, disc_loss = 0.014447151447701104
Trained batch 85 in epoch 1, gen_loss = 2.4542723381242086, disc_loss = 0.014425405317397659
Trained batch 86 in epoch 1, gen_loss = 2.452005752201738, disc_loss = 0.014399872830501575
Trained batch 87 in epoch 1, gen_loss = 2.4490401379086753, disc_loss = 0.014324606581464071
Trained batch 88 in epoch 1, gen_loss = 2.4495895377705605, disc_loss = 0.01421162351610118
Trained batch 89 in epoch 1, gen_loss = 2.449076659149594, disc_loss = 0.014159754192870523
Trained batch 90 in epoch 1, gen_loss = 2.4484049579599403, disc_loss = 0.014066774224105117
Trained batch 91 in epoch 1, gen_loss = 2.448231700969779, disc_loss = 0.014110604837617797
Trained batch 92 in epoch 1, gen_loss = 2.447879174704193, disc_loss = 0.014247898723409381
Trained batch 93 in epoch 1, gen_loss = 2.4499696125375463, disc_loss = 0.014182459592739952
Trained batch 94 in epoch 1, gen_loss = 2.4501922619970222, disc_loss = 0.014126570248290112
Trained batch 95 in epoch 1, gen_loss = 2.4496350350479283, disc_loss = 0.014068500245533263
Trained batch 96 in epoch 1, gen_loss = 2.4498979983870517, disc_loss = 0.013980146046228631
Trained batch 97 in epoch 1, gen_loss = 2.449898278226658, disc_loss = 0.013902939875058981
Trained batch 98 in epoch 1, gen_loss = 2.44599046731236, disc_loss = 0.013821641787547956
Trained batch 99 in epoch 1, gen_loss = 2.444754091501236, disc_loss = 0.013748389226384461
Trained batch 100 in epoch 1, gen_loss = 2.446099778213123, disc_loss = 0.01368017118922112
Trained batch 101 in epoch 1, gen_loss = 2.44624344624725, disc_loss = 0.013600426392775833
Trained batch 102 in epoch 1, gen_loss = 2.4452181684160696, disc_loss = 0.013518908015877297
Trained batch 103 in epoch 1, gen_loss = 2.44300909111133, disc_loss = 0.013435173188694395
Trained batch 104 in epoch 1, gen_loss = 2.442943671771458, disc_loss = 0.013371514803951694
Trained batch 105 in epoch 1, gen_loss = 2.440929596154195, disc_loss = 0.01329091329672286
Trained batch 106 in epoch 1, gen_loss = 2.4386264063487544, disc_loss = 0.01321479631587863
Trained batch 107 in epoch 1, gen_loss = 2.43823731497482, disc_loss = 0.013128667060906688
Trained batch 108 in epoch 1, gen_loss = 2.4358895120270754, disc_loss = 0.013076626353922788
Trained batch 109 in epoch 1, gen_loss = 2.436258455840024, disc_loss = 0.013015109499577772
Trained batch 110 in epoch 1, gen_loss = 2.4365369897704943, disc_loss = 0.012938627826368756
Trained batch 111 in epoch 1, gen_loss = 2.4358707911201884, disc_loss = 0.012868304200570233
Trained batch 112 in epoch 1, gen_loss = 2.4366825776817524, disc_loss = 0.01280998448074787
Trained batch 113 in epoch 1, gen_loss = 2.434760268320117, disc_loss = 0.012813972011045144
Trained batch 114 in epoch 1, gen_loss = 2.43913239085156, disc_loss = 0.012755911663660536
Trained batch 115 in epoch 1, gen_loss = 2.441408548889489, disc_loss = 0.012691566531931788
Trained batch 116 in epoch 1, gen_loss = 2.441048537564074, disc_loss = 0.012622489363082454
Trained batch 117 in epoch 1, gen_loss = 2.440973935490948, disc_loss = 0.012553058951398579
Trained batch 118 in epoch 1, gen_loss = 2.4400513522765217, disc_loss = 0.012480080718597193
Trained batch 119 in epoch 1, gen_loss = 2.4397100915511447, disc_loss = 0.012409666122402995
Trained batch 120 in epoch 1, gen_loss = 2.4406866446014277, disc_loss = 0.012347388835546891
Trained batch 121 in epoch 1, gen_loss = 2.4382325967804332, disc_loss = 0.012312605137341335
Trained batch 122 in epoch 1, gen_loss = 2.436999056397415, disc_loss = 0.012263692196125423
Trained batch 123 in epoch 1, gen_loss = 2.437510825933949, disc_loss = 0.012227086999994372
Trained batch 124 in epoch 1, gen_loss = 2.439643176078796, disc_loss = 0.012186327029019594
Trained batch 125 in epoch 1, gen_loss = 2.439757037730444, disc_loss = 0.012153817950526164
Trained batch 126 in epoch 1, gen_loss = 2.4381524643560093, disc_loss = 0.012096822463474639
Trained batch 127 in epoch 1, gen_loss = 2.4419158631935716, disc_loss = 0.012044415547279641
Trained batch 128 in epoch 1, gen_loss = 2.4410493050434794, disc_loss = 0.011995658101586178
Trained batch 129 in epoch 1, gen_loss = 2.440245099251087, disc_loss = 0.011952441042432418
Trained batch 130 in epoch 1, gen_loss = 2.441939061834612, disc_loss = 0.011900199008465723
Trained batch 131 in epoch 1, gen_loss = 2.439672996600469, disc_loss = 0.011857945168616645
Trained batch 132 in epoch 1, gen_loss = 2.4386334786737773, disc_loss = 0.011822458052013377
Trained batch 133 in epoch 1, gen_loss = 2.4402386777436553, disc_loss = 0.011802858718212194
Trained batch 134 in epoch 1, gen_loss = 2.440030897105182, disc_loss = 0.01178530371506457
Trained batch 135 in epoch 1, gen_loss = 2.4428965598344803, disc_loss = 0.011735462703440776
Trained batch 136 in epoch 1, gen_loss = 2.443422029488278, disc_loss = 0.011675708558424001
Trained batch 137 in epoch 1, gen_loss = 2.442919783834098, disc_loss = 0.011637073032139544
Trained batch 138 in epoch 1, gen_loss = 2.4423685099581163, disc_loss = 0.011579393633648002
Trained batch 139 in epoch 1, gen_loss = 2.4424301496573855, disc_loss = 0.011527912358620338
Trained batch 140 in epoch 1, gen_loss = 2.4427316197266817, disc_loss = 0.011466929807941964
Trained batch 141 in epoch 1, gen_loss = 2.4450685902380607, disc_loss = 0.011410786053756068
Trained batch 142 in epoch 1, gen_loss = 2.4450804728728075, disc_loss = 0.011354822429365941
Trained batch 143 in epoch 1, gen_loss = 2.446567186878787, disc_loss = 0.011301264727889147
Trained batch 144 in epoch 1, gen_loss = 2.4482751344812326, disc_loss = 0.011256370810663392
Trained batch 145 in epoch 1, gen_loss = 2.4496287327923185, disc_loss = 0.011215830593344385
Trained batch 146 in epoch 1, gen_loss = 2.450126355197154, disc_loss = 0.011161820049125219
Trained batch 147 in epoch 1, gen_loss = 2.450602086009206, disc_loss = 0.011106111126561725
Trained batch 148 in epoch 1, gen_loss = 2.4511453537332932, disc_loss = 0.011052535134273888
Trained batch 149 in epoch 1, gen_loss = 2.4503772314389547, disc_loss = 0.01106603632370631
Trained batch 150 in epoch 1, gen_loss = 2.4517260789871216, disc_loss = 0.011119545073501321
Trained batch 151 in epoch 1, gen_loss = 2.451597518826786, disc_loss = 0.011138932460820988
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 2.6529836654663086, disc_loss = 0.008045259863138199
Trained batch 1 in epoch 2, gen_loss = 2.565159559249878, disc_loss = 0.006548098288476467
Trained batch 2 in epoch 2, gen_loss = 2.62587300936381, disc_loss = 0.005450021863604586
Trained batch 3 in epoch 2, gen_loss = 2.636314272880554, disc_loss = 0.0056281358120031655
Trained batch 4 in epoch 2, gen_loss = 2.6330092906951905, disc_loss = 0.005092709371820092
Trained batch 5 in epoch 2, gen_loss = 2.6116515398025513, disc_loss = 0.004758237162604928
Trained batch 6 in epoch 2, gen_loss = 2.60832371030535, disc_loss = 0.004554083504314933
Trained batch 7 in epoch 2, gen_loss = 2.5541390478610992, disc_loss = 0.004464931320399046
Trained batch 8 in epoch 2, gen_loss = 2.5340824921925864, disc_loss = 0.004305150152908431
Trained batch 9 in epoch 2, gen_loss = 2.517403817176819, disc_loss = 0.004212605278007686
Trained batch 10 in epoch 2, gen_loss = 2.5094582601027056, disc_loss = 0.004215180937370116
Trained batch 11 in epoch 2, gen_loss = 2.49286558230718, disc_loss = 0.004221959796268493
Trained batch 12 in epoch 2, gen_loss = 2.4918072590461144, disc_loss = 0.004266005743724795
Trained batch 13 in epoch 2, gen_loss = 2.480635779244559, disc_loss = 0.004405797808431089
Trained batch 14 in epoch 2, gen_loss = 2.449356969197591, disc_loss = 0.0048538933352877695
Trained batch 15 in epoch 2, gen_loss = 2.4565330147743225, disc_loss = 0.005275404386338778
Trained batch 16 in epoch 2, gen_loss = 2.451883652630974, disc_loss = 0.005405499175300493
Trained batch 17 in epoch 2, gen_loss = 2.429924395349291, disc_loss = 0.00553641148791131
Trained batch 18 in epoch 2, gen_loss = 2.420951479359677, disc_loss = 0.005595223451229303
Trained batch 19 in epoch 2, gen_loss = 2.4222416281700134, disc_loss = 0.005487252364400774
Trained batch 20 in epoch 2, gen_loss = 2.416843595958891, disc_loss = 0.005437468100960056
Trained batch 21 in epoch 2, gen_loss = 2.4204946864734995, disc_loss = 0.005334170397625051
Trained batch 22 in epoch 2, gen_loss = 2.409035827802575, disc_loss = 0.005301882948159524
Trained batch 23 in epoch 2, gen_loss = 2.403261641661326, disc_loss = 0.005283086609172945
Trained batch 24 in epoch 2, gen_loss = 2.415739860534668, disc_loss = 0.005374544272199273
Trained batch 25 in epoch 2, gen_loss = 2.4194543086565456, disc_loss = 0.0053946252357071406
Trained batch 26 in epoch 2, gen_loss = 2.4156354091785572, disc_loss = 0.005333261184946254
Trained batch 27 in epoch 2, gen_loss = 2.4093061004366194, disc_loss = 0.0052247312601788765
Trained batch 28 in epoch 2, gen_loss = 2.4156342374867408, disc_loss = 0.0051356353395586385
Trained batch 29 in epoch 2, gen_loss = 2.416629942258199, disc_loss = 0.005033597233705223
Trained batch 30 in epoch 2, gen_loss = 2.4242819124652493, disc_loss = 0.004935068746788367
Trained batch 31 in epoch 2, gen_loss = 2.423171289265156, disc_loss = 0.004847890762903262
Trained batch 32 in epoch 2, gen_loss = 2.4255482572497744, disc_loss = 0.004770091135111271
Trained batch 33 in epoch 2, gen_loss = 2.425425971255583, disc_loss = 0.00470055962282726
Trained batch 34 in epoch 2, gen_loss = 2.4372379507337296, disc_loss = 0.004678569607702749
Trained batch 35 in epoch 2, gen_loss = 2.4291201498773365, disc_loss = 0.004868021267207546
Trained batch 36 in epoch 2, gen_loss = 2.4248160607105977, disc_loss = 0.005163383122684585
Trained batch 37 in epoch 2, gen_loss = 2.4290260578456677, disc_loss = 0.005278928652650824
Trained batch 38 in epoch 2, gen_loss = 2.4429133244049854, disc_loss = 0.0053118401481650574
Trained batch 39 in epoch 2, gen_loss = 2.4421198964118958, disc_loss = 0.005316590791335329
Trained batch 40 in epoch 2, gen_loss = 2.4434211254119873, disc_loss = 0.00533882500717371
Trained batch 41 in epoch 2, gen_loss = 2.4335682278587702, disc_loss = 0.005475092540672492
Trained batch 42 in epoch 2, gen_loss = 2.422300194585046, disc_loss = 0.005858230204213151
Trained batch 43 in epoch 2, gen_loss = 2.4240181879563765, disc_loss = 0.006320923730858009
Trained batch 44 in epoch 2, gen_loss = 2.4227637555864123, disc_loss = 0.006424022398682104
Trained batch 45 in epoch 2, gen_loss = 2.417383162871651, disc_loss = 0.006495391216088572
Trained batch 46 in epoch 2, gen_loss = 2.425862078971051, disc_loss = 0.006443209544894226
Trained batch 47 in epoch 2, gen_loss = 2.4256606499354043, disc_loss = 0.006419758385163732
Trained batch 48 in epoch 2, gen_loss = 2.4295156293985793, disc_loss = 0.006391594381242686
Trained batch 49 in epoch 2, gen_loss = 2.429765191078186, disc_loss = 0.006366152488626539
Trained batch 50 in epoch 2, gen_loss = 2.4295815299539005, disc_loss = 0.006334007640058796
Trained batch 51 in epoch 2, gen_loss = 2.425136291063749, disc_loss = 0.006277728185523301
Trained batch 52 in epoch 2, gen_loss = 2.4247699638582625, disc_loss = 0.006215356628603811
Trained batch 53 in epoch 2, gen_loss = 2.424683513464751, disc_loss = 0.006142820141071247
Trained batch 54 in epoch 2, gen_loss = 2.423490524291992, disc_loss = 0.006067931249907071
Trained batch 55 in epoch 2, gen_loss = 2.4247710747378215, disc_loss = 0.006016077319925118
Trained batch 56 in epoch 2, gen_loss = 2.4234061784911574, disc_loss = 0.00598839282777095
Trained batch 57 in epoch 2, gen_loss = 2.423571360522303, disc_loss = 0.005975173212234573
Trained batch 58 in epoch 2, gen_loss = 2.4206763485730707, disc_loss = 0.005952814250584628
Trained batch 59 in epoch 2, gen_loss = 2.4230807701746624, disc_loss = 0.005898011875494073
Trained batch 60 in epoch 2, gen_loss = 2.4174206530461544, disc_loss = 0.005871337529302376
Trained batch 61 in epoch 2, gen_loss = 2.4169671881583428, disc_loss = 0.005846562566265704
Trained batch 62 in epoch 2, gen_loss = 2.423217784790766, disc_loss = 0.005842617664870525
Trained batch 63 in epoch 2, gen_loss = 2.4242734275758266, disc_loss = 0.005813203719299054
Trained batch 64 in epoch 2, gen_loss = 2.4251570481520432, disc_loss = 0.005784697325613636
Trained batch 65 in epoch 2, gen_loss = 2.421928189017556, disc_loss = 0.005760337462451196
Trained batch 66 in epoch 2, gen_loss = 2.424977658399895, disc_loss = 0.0057996687402865335
Trained batch 67 in epoch 2, gen_loss = 2.424386746743146, disc_loss = 0.0057543020400985636
Trained batch 68 in epoch 2, gen_loss = 2.4217018286387124, disc_loss = 0.0071023260479442015
Trained batch 69 in epoch 2, gen_loss = 2.4220470837184362, disc_loss = 0.011798638800558234
Trained batch 70 in epoch 2, gen_loss = 2.415875362678313, disc_loss = 0.013136572037285693
Trained batch 71 in epoch 2, gen_loss = 2.4198154658079147, disc_loss = 0.014476075513003808
Trained batch 72 in epoch 2, gen_loss = 2.4189242189877653, disc_loss = 0.015413664029400847
Trained batch 73 in epoch 2, gen_loss = 2.419805389803809, disc_loss = 0.0158012605530235
Trained batch 74 in epoch 2, gen_loss = 2.4181941843032835, disc_loss = 0.01604846681468189
Trained batch 75 in epoch 2, gen_loss = 2.415792852640152, disc_loss = 0.01659897102447423
Trained batch 76 in epoch 2, gen_loss = 2.4256939934445665, disc_loss = 0.016880933246756723
Trained batch 77 in epoch 2, gen_loss = 2.424023302701803, disc_loss = 0.0169210764967526
Trained batch 78 in epoch 2, gen_loss = 2.422072556954396, disc_loss = 0.017059732891642785
Trained batch 79 in epoch 2, gen_loss = 2.4227822557091714, disc_loss = 0.017148167596315034
Trained batch 80 in epoch 2, gen_loss = 2.422087382387232, disc_loss = 0.0172680045656262
Trained batch 81 in epoch 2, gen_loss = 2.42138726100689, disc_loss = 0.017266018296273927
Trained batch 82 in epoch 2, gen_loss = 2.4219198356191796, disc_loss = 0.017220654134941567
Trained batch 83 in epoch 2, gen_loss = 2.4218211954548243, disc_loss = 0.017160257615614682
Trained batch 84 in epoch 2, gen_loss = 2.4212800292407763, disc_loss = 0.017050103100893253
Trained batch 85 in epoch 2, gen_loss = 2.4234595700751904, disc_loss = 0.0169280499875069
Trained batch 86 in epoch 2, gen_loss = 2.4274095817543992, disc_loss = 0.016828034332707183
Trained batch 87 in epoch 2, gen_loss = 2.423592138019475, disc_loss = 0.016784928625301374
Trained batch 88 in epoch 2, gen_loss = 2.4202986741333863, disc_loss = 0.016709125268513734
Trained batch 89 in epoch 2, gen_loss = 2.419140570693546, disc_loss = 0.016723376111541358
Trained batch 90 in epoch 2, gen_loss = 2.41959702706599, disc_loss = 0.01678158825130335
Trained batch 91 in epoch 2, gen_loss = 2.4195805101290992, disc_loss = 0.016841145872604102
Trained batch 92 in epoch 2, gen_loss = 2.423496788547885, disc_loss = 0.01694443943329476
Trained batch 93 in epoch 2, gen_loss = 2.4240349594582904, disc_loss = 0.01688459139327182
Trained batch 94 in epoch 2, gen_loss = 2.4228666694540726, disc_loss = 0.016851525873828092
Trained batch 95 in epoch 2, gen_loss = 2.4275054124494395, disc_loss = 0.01683176502168256
Trained batch 96 in epoch 2, gen_loss = 2.4276692609197084, disc_loss = 0.01674486333072262
Trained batch 97 in epoch 2, gen_loss = 2.4274725926165677, disc_loss = 0.016741738856618046
Trained batch 98 in epoch 2, gen_loss = 2.4265470179644497, disc_loss = 0.016667664335626695
Trained batch 99 in epoch 2, gen_loss = 2.4257324755191805, disc_loss = 0.016552726507652552
Trained batch 100 in epoch 2, gen_loss = 2.4233515581282057, disc_loss = 0.016481065995862135
Trained batch 101 in epoch 2, gen_loss = 2.426550478327508, disc_loss = 0.016444831541008956
Trained batch 102 in epoch 2, gen_loss = 2.427880290642525, disc_loss = 0.01641268782471352
Trained batch 103 in epoch 2, gen_loss = 2.4315142253270516, disc_loss = 0.016373416232034706
Trained batch 104 in epoch 2, gen_loss = 2.4323008389700025, disc_loss = 0.016295151352616295
Trained batch 105 in epoch 2, gen_loss = 2.433730810318353, disc_loss = 0.016241873906626594
Trained batch 106 in epoch 2, gen_loss = 2.433810190619709, disc_loss = 0.01617661636609967
Trained batch 107 in epoch 2, gen_loss = 2.4331284816618317, disc_loss = 0.016080767164196545
Trained batch 108 in epoch 2, gen_loss = 2.4344647269730175, disc_loss = 0.01596677222784711
Trained batch 109 in epoch 2, gen_loss = 2.4355095267295837, disc_loss = 0.01585678043140268
Trained batch 110 in epoch 2, gen_loss = 2.436729174476486, disc_loss = 0.015755373969892256
Trained batch 111 in epoch 2, gen_loss = 2.4373242865715707, disc_loss = 0.015685580115781965
Trained batch 112 in epoch 2, gen_loss = 2.438246476966723, disc_loss = 0.015586547654501237
Trained batch 113 in epoch 2, gen_loss = 2.437030117762716, disc_loss = 0.015504731018537362
Trained batch 114 in epoch 2, gen_loss = 2.4389680333759474, disc_loss = 0.015417834150645396
Trained batch 115 in epoch 2, gen_loss = 2.4410189811525673, disc_loss = 0.015318310357919284
Trained batch 116 in epoch 2, gen_loss = 2.4404677947362265, disc_loss = 0.015233516466254607
Trained batch 117 in epoch 2, gen_loss = 2.443192980047, disc_loss = 0.015147568756651323
Trained batch 118 in epoch 2, gen_loss = 2.4428207944421207, disc_loss = 0.015050228501223967
Trained batch 119 in epoch 2, gen_loss = 2.4448962340752285, disc_loss = 0.014964079961646348
Trained batch 120 in epoch 2, gen_loss = 2.4461437700208553, disc_loss = 0.014875648470118272
Trained batch 121 in epoch 2, gen_loss = 2.445335959801908, disc_loss = 0.014781904882049097
Trained batch 122 in epoch 2, gen_loss = 2.442860681836198, disc_loss = 0.014706590555502268
Trained batch 123 in epoch 2, gen_loss = 2.444411023009208, disc_loss = 0.014658009890662205
Trained batch 124 in epoch 2, gen_loss = 2.4430340070724488, disc_loss = 0.014604249941185117
Trained batch 125 in epoch 2, gen_loss = 2.4410609829993475, disc_loss = 0.014532678932439359
Trained batch 126 in epoch 2, gen_loss = 2.4379380866298526, disc_loss = 0.014461390147953638
Trained batch 127 in epoch 2, gen_loss = 2.437118145637214, disc_loss = 0.014432706529987627
Trained batch 128 in epoch 2, gen_loss = 2.436642435169959, disc_loss = 0.014374648504204644
Trained batch 129 in epoch 2, gen_loss = 2.434698103941404, disc_loss = 0.014313207984042283
Trained batch 130 in epoch 2, gen_loss = 2.4322270154953003, disc_loss = 0.014273322864528034
Trained batch 131 in epoch 2, gen_loss = 2.4305402212070697, disc_loss = 0.014236394903326238
Trained batch 132 in epoch 2, gen_loss = 2.431594110969314, disc_loss = 0.014185973465848798
Trained batch 133 in epoch 2, gen_loss = 2.4311861004402386, disc_loss = 0.014122277889192215
Trained batch 134 in epoch 2, gen_loss = 2.4317640048486213, disc_loss = 0.014064568807198493
Trained batch 135 in epoch 2, gen_loss = 2.4315825481625164, disc_loss = 0.013992789675659664
Trained batch 136 in epoch 2, gen_loss = 2.429992485220415, disc_loss = 0.013924979572490294
Trained batch 137 in epoch 2, gen_loss = 2.431401777094689, disc_loss = 0.013852439235315483
Trained batch 138 in epoch 2, gen_loss = 2.431023343003911, disc_loss = 0.013779657583000312
Trained batch 139 in epoch 2, gen_loss = 2.4343552138124194, disc_loss = 0.013705867954662868
Trained batch 140 in epoch 2, gen_loss = 2.4369579959422984, disc_loss = 0.013641419701595256
Trained batch 141 in epoch 2, gen_loss = 2.4347245819132093, disc_loss = 0.013578597321765314
Trained batch 142 in epoch 2, gen_loss = 2.433554993642794, disc_loss = 0.013516079885168718
Trained batch 143 in epoch 2, gen_loss = 2.433917344444328, disc_loss = 0.01345630168604354
Trained batch 144 in epoch 2, gen_loss = 2.4335576624705872, disc_loss = 0.013399691590718155
Trained batch 145 in epoch 2, gen_loss = 2.4345202209198313, disc_loss = 0.013363462164742898
Trained batch 146 in epoch 2, gen_loss = 2.4343695600016586, disc_loss = 0.01331839642050315
Trained batch 147 in epoch 2, gen_loss = 2.434457117641294, disc_loss = 0.013278778680172321
Trained batch 148 in epoch 2, gen_loss = 2.435843402907352, disc_loss = 0.01321731481526122
Trained batch 149 in epoch 2, gen_loss = 2.437807409763336, disc_loss = 0.01315417348096768
Trained batch 150 in epoch 2, gen_loss = 2.436278102413708, disc_loss = 0.013091934548801934
Trained batch 151 in epoch 2, gen_loss = 2.4353803733461783, disc_loss = 0.013025069449979224
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 2.8075528144836426, disc_loss = 0.0034861816093325615
Trained batch 1 in epoch 3, gen_loss = 2.6564143896102905, disc_loss = 0.004230531165376306
Trained batch 2 in epoch 3, gen_loss = 2.583975871404012, disc_loss = 0.004523347287128369
Trained batch 3 in epoch 3, gen_loss = 2.5262649059295654, disc_loss = 0.004609357565641403
Trained batch 4 in epoch 3, gen_loss = 2.4856160163879393, disc_loss = 0.004581404104828835
Trained batch 5 in epoch 3, gen_loss = 2.449215610822042, disc_loss = 0.004395219769018392
Trained batch 6 in epoch 3, gen_loss = 2.4380472728184293, disc_loss = 0.004354057201583471
Trained batch 7 in epoch 3, gen_loss = 2.4013798236846924, disc_loss = 0.005362637952202931
Trained batch 8 in epoch 3, gen_loss = 2.4288297759162054, disc_loss = 0.007894041766929958
Trained batch 9 in epoch 3, gen_loss = 2.4373010635375976, disc_loss = 0.009175536152906717
Trained batch 10 in epoch 3, gen_loss = 2.4208136038346724, disc_loss = 0.010569635037840768
Trained batch 11 in epoch 3, gen_loss = 2.4232407808303833, disc_loss = 0.011394019180443138
Trained batch 12 in epoch 3, gen_loss = 2.4344791632432203, disc_loss = 0.0112583759204986
Trained batch 13 in epoch 3, gen_loss = 2.456064394542149, disc_loss = 0.010955900336349649
Trained batch 14 in epoch 3, gen_loss = 2.4631628672281902, disc_loss = 0.010670272028073668
Trained batch 15 in epoch 3, gen_loss = 2.4711338728666306, disc_loss = 0.010179059856454842
Trained batch 16 in epoch 3, gen_loss = 2.4840719138874725, disc_loss = 0.009816917412749985
Trained batch 17 in epoch 3, gen_loss = 2.4839495023091636, disc_loss = 0.009554915168943504
Trained batch 18 in epoch 3, gen_loss = 2.474689609126041, disc_loss = 0.0092179218282629
Trained batch 19 in epoch 3, gen_loss = 2.475337827205658, disc_loss = 0.008848215162288398
Trained batch 20 in epoch 3, gen_loss = 2.4683983212425593, disc_loss = 0.008566188759037427
Trained batch 21 in epoch 3, gen_loss = 2.4763323935595425, disc_loss = 0.008378553754565391
Trained batch 22 in epoch 3, gen_loss = 2.4823686765587847, disc_loss = 0.008169803829134806
Trained batch 23 in epoch 3, gen_loss = 2.467944105466207, disc_loss = 0.007916410434215019
Trained batch 24 in epoch 3, gen_loss = 2.4663351249694823, disc_loss = 0.00772009065374732
Trained batch 25 in epoch 3, gen_loss = 2.470868890102093, disc_loss = 0.0075373530226687975
Trained batch 26 in epoch 3, gen_loss = 2.4693570048720748, disc_loss = 0.0073564451325822755
Trained batch 27 in epoch 3, gen_loss = 2.474536989416395, disc_loss = 0.007224927631406379
Trained batch 28 in epoch 3, gen_loss = 2.457422868958835, disc_loss = 0.007138051116710593
Trained batch 29 in epoch 3, gen_loss = 2.4583420316378275, disc_loss = 0.007063884870149195
Trained batch 30 in epoch 3, gen_loss = 2.4566482305526733, disc_loss = 0.006913739249050137
Trained batch 31 in epoch 3, gen_loss = 2.460946511477232, disc_loss = 0.00678350778616732
Trained batch 32 in epoch 3, gen_loss = 2.4545617284196797, disc_loss = 0.006653749906091076
Trained batch 33 in epoch 3, gen_loss = 2.449016209910898, disc_loss = 0.006569446728783934
Trained batch 34 in epoch 3, gen_loss = 2.453057176726205, disc_loss = 0.006495572686461466
Trained batch 35 in epoch 3, gen_loss = 2.459146562549803, disc_loss = 0.006413306368307935
Trained batch 36 in epoch 3, gen_loss = 2.447394689998111, disc_loss = 0.006553601121177545
Trained batch 37 in epoch 3, gen_loss = 2.440179909530439, disc_loss = 0.007276814578003005
Trained batch 38 in epoch 3, gen_loss = 2.4456766232466087, disc_loss = 0.008832435147502484
Trained batch 39 in epoch 3, gen_loss = 2.4405506044626235, disc_loss = 0.009024458518251777
Trained batch 40 in epoch 3, gen_loss = 2.440528709714006, disc_loss = 0.009395132295605613
Trained batch 41 in epoch 3, gen_loss = 2.4315638343493142, disc_loss = 0.011886990983926114
Trained batch 42 in epoch 3, gen_loss = 2.420439412427503, disc_loss = 0.021138956856935523
Trained batch 43 in epoch 3, gen_loss = 2.419671126387336, disc_loss = 0.024849004154516893
Trained batch 44 in epoch 3, gen_loss = 2.420342591073778, disc_loss = 0.02705389902823501
Trained batch 45 in epoch 3, gen_loss = 2.418742669665295, disc_loss = 0.02808692577578451
Trained batch 46 in epoch 3, gen_loss = 2.4117768952187073, disc_loss = 0.028055783598981004
Trained batch 47 in epoch 3, gen_loss = 2.417049345870813, disc_loss = 0.02784467744641006
Trained batch 48 in epoch 3, gen_loss = 2.417992584559382, disc_loss = 0.027413941634704873
Trained batch 49 in epoch 3, gen_loss = 2.4177001118659973, disc_loss = 0.027039117012172938
Trained batch 50 in epoch 3, gen_loss = 2.4283124535691503, disc_loss = 0.026683367368783437
Trained batch 51 in epoch 3, gen_loss = 2.4293213188648224, disc_loss = 0.026299182862903062
Trained batch 52 in epoch 3, gen_loss = 2.4298796406332053, disc_loss = 0.02593944592506818
Trained batch 53 in epoch 3, gen_loss = 2.4286454055044384, disc_loss = 0.02556119620351604
Trained batch 54 in epoch 3, gen_loss = 2.4343522787094116, disc_loss = 0.025165226496756076
Trained batch 55 in epoch 3, gen_loss = 2.4389042066676274, disc_loss = 0.02478709095989221
Trained batch 56 in epoch 3, gen_loss = 2.43878506150162, disc_loss = 0.02443085036550959
Trained batch 57 in epoch 3, gen_loss = 2.4353816776440063, disc_loss = 0.02406037429042546
Trained batch 58 in epoch 3, gen_loss = 2.433380407802129, disc_loss = 0.02372763757751781
Trained batch 59 in epoch 3, gen_loss = 2.4397840956846872, disc_loss = 0.023418575901693352
Trained batch 60 in epoch 3, gen_loss = 2.4381548205360035, disc_loss = 0.023110711729520412
Trained batch 61 in epoch 3, gen_loss = 2.4404947700039035, disc_loss = 0.02281401337560026
Trained batch 62 in epoch 3, gen_loss = 2.444453861978319, disc_loss = 0.022512865899544623
Trained batch 63 in epoch 3, gen_loss = 2.445168213918805, disc_loss = 0.02223341810531565
Trained batch 64 in epoch 3, gen_loss = 2.4425557191555316, disc_loss = 0.021966325409280566
Trained batch 65 in epoch 3, gen_loss = 2.4433213851668616, disc_loss = 0.021684103973463854
Trained batch 66 in epoch 3, gen_loss = 2.445244659238787, disc_loss = 0.021411057968220827
Trained batch 67 in epoch 3, gen_loss = 2.4450905060066894, disc_loss = 0.021130572850405073
Trained batch 68 in epoch 3, gen_loss = 2.444539673086526, disc_loss = 0.020867294662267617
Trained batch 69 in epoch 3, gen_loss = 2.443935419831957, disc_loss = 0.02061501451701458
Trained batch 70 in epoch 3, gen_loss = 2.4466656983738213, disc_loss = 0.020366630461198132
Trained batch 71 in epoch 3, gen_loss = 2.444716531369421, disc_loss = 0.020116429649836693
Trained batch 72 in epoch 3, gen_loss = 2.4465050354395825, disc_loss = 0.01995691011838411
Trained batch 73 in epoch 3, gen_loss = 2.4444622784047514, disc_loss = 0.019802642888641236
Trained batch 74 in epoch 3, gen_loss = 2.443996272087097, disc_loss = 0.019586526385198037
Trained batch 75 in epoch 3, gen_loss = 2.443704311784945, disc_loss = 0.019438015523758765
Trained batch 76 in epoch 3, gen_loss = 2.4407574681492594, disc_loss = 0.01937949832214357
Trained batch 77 in epoch 3, gen_loss = 2.441449124079484, disc_loss = 0.019328384988535292
Trained batch 78 in epoch 3, gen_loss = 2.44219038607199, disc_loss = 0.019192311187758097
Trained batch 79 in epoch 3, gen_loss = 2.440450756251812, disc_loss = 0.019008638331433757
Trained batch 80 in epoch 3, gen_loss = 2.4415574147377486, disc_loss = 0.01884421691827384
Trained batch 81 in epoch 3, gen_loss = 2.4383357283545704, disc_loss = 0.01865580285013449
Trained batch 82 in epoch 3, gen_loss = 2.442152251680213, disc_loss = 0.018462344897484564
Trained batch 83 in epoch 3, gen_loss = 2.440562564702261, disc_loss = 0.018313189685743834
Trained batch 84 in epoch 3, gen_loss = 2.4389346641652723, disc_loss = 0.01815565959276522
Trained batch 85 in epoch 3, gen_loss = 2.438274878402089, disc_loss = 0.017975772303247522
Trained batch 86 in epoch 3, gen_loss = 2.4409025606067702, disc_loss = 0.017794735892943437
Trained batch 87 in epoch 3, gen_loss = 2.4415558617223394, disc_loss = 0.01761668613074686
Trained batch 88 in epoch 3, gen_loss = 2.443581893202964, disc_loss = 0.017441591739738256
Trained batch 89 in epoch 3, gen_loss = 2.4422722697257995, disc_loss = 0.017289157951664594
Trained batch 90 in epoch 3, gen_loss = 2.44048096714439, disc_loss = 0.01712127516025698
Trained batch 91 in epoch 3, gen_loss = 2.4384929732136102, disc_loss = 0.016963645965164607
Trained batch 92 in epoch 3, gen_loss = 2.4414120040914065, disc_loss = 0.016839051151007253
Trained batch 93 in epoch 3, gen_loss = 2.444754266992528, disc_loss = 0.016693148603464696
Trained batch 94 in epoch 3, gen_loss = 2.4428595906809756, disc_loss = 0.016540143276123624
Trained batch 95 in epoch 3, gen_loss = 2.4441182129085064, disc_loss = 0.016389664849460434
Trained batch 96 in epoch 3, gen_loss = 2.4433372303382637, disc_loss = 0.016238528112976897
Trained batch 97 in epoch 3, gen_loss = 2.438606545633199, disc_loss = 0.0161618418357221
Trained batch 98 in epoch 3, gen_loss = 2.440818209840794, disc_loss = 0.016139548903359384
Trained batch 99 in epoch 3, gen_loss = 2.442134643793106, disc_loss = 0.016033436838770284
Trained batch 100 in epoch 3, gen_loss = 2.4394615204027383, disc_loss = 0.015936168529655747
Trained batch 101 in epoch 3, gen_loss = 2.4395972081259187, disc_loss = 0.015830297270725827
Trained batch 102 in epoch 3, gen_loss = 2.438567618721897, disc_loss = 0.015733684730734134
Trained batch 103 in epoch 3, gen_loss = 2.438374795592748, disc_loss = 0.015618084142960679
Trained batch 104 in epoch 3, gen_loss = 2.4344923711958386, disc_loss = 0.015536335630652804
Trained batch 105 in epoch 3, gen_loss = 2.43333004892997, disc_loss = 0.01545490195451937
Trained batch 106 in epoch 3, gen_loss = 2.4363643955961565, disc_loss = 0.015331212493208037
Trained batch 107 in epoch 3, gen_loss = 2.4346049792236752, disc_loss = 0.015221758347858364
Trained batch 108 in epoch 3, gen_loss = 2.4352294644084544, disc_loss = 0.015117879124964938
Trained batch 109 in epoch 3, gen_loss = 2.4365199533375828, disc_loss = 0.015014760715844618
Trained batch 110 in epoch 3, gen_loss = 2.4320833092337257, disc_loss = 0.014948861626278911
Trained batch 111 in epoch 3, gen_loss = 2.4304299258760045, disc_loss = 0.014956312589804708
Trained batch 112 in epoch 3, gen_loss = 2.4327657824069, disc_loss = 0.014932549248482472
Trained batch 113 in epoch 3, gen_loss = 2.433154596571337, disc_loss = 0.01483172560907214
Trained batch 114 in epoch 3, gen_loss = 2.435175208423449, disc_loss = 0.01475003071271045
Trained batch 115 in epoch 3, gen_loss = 2.433901171232092, disc_loss = 0.014656404518032575
Trained batch 116 in epoch 3, gen_loss = 2.432854859237997, disc_loss = 0.014550016766103605
Trained batch 117 in epoch 3, gen_loss = 2.43636459314217, disc_loss = 0.014484545025556206
Trained batch 118 in epoch 3, gen_loss = 2.4332885331466416, disc_loss = 0.014423063626520712
Trained batch 119 in epoch 3, gen_loss = 2.431191181143125, disc_loss = 0.014332793677264513
Trained batch 120 in epoch 3, gen_loss = 2.432740303110485, disc_loss = 0.014244347686633036
Trained batch 121 in epoch 3, gen_loss = 2.434182078134818, disc_loss = 0.014149191051713939
Trained batch 122 in epoch 3, gen_loss = 2.434428091940841, disc_loss = 0.014049991095491602
Trained batch 123 in epoch 3, gen_loss = 2.433833896152435, disc_loss = 0.01395722306352259
Trained batch 124 in epoch 3, gen_loss = 2.433521580696106, disc_loss = 0.013860925702378154
Trained batch 125 in epoch 3, gen_loss = 2.4313764846514143, disc_loss = 0.013793294737485074
Trained batch 126 in epoch 3, gen_loss = 2.4350290345394705, disc_loss = 0.013728379262757934
Trained batch 127 in epoch 3, gen_loss = 2.4340955233201385, disc_loss = 0.013642126783452113
Trained batch 128 in epoch 3, gen_loss = 2.435500901798869, disc_loss = 0.01355966814620377
Trained batch 129 in epoch 3, gen_loss = 2.4338203439345727, disc_loss = 0.013496897120673496
Trained batch 130 in epoch 3, gen_loss = 2.433537942762593, disc_loss = 0.013419028231163175
Trained batch 131 in epoch 3, gen_loss = 2.4346781652985197, disc_loss = 0.013336316363138118
Trained batch 132 in epoch 3, gen_loss = 2.4339965492262876, disc_loss = 0.013249448707145183
Trained batch 133 in epoch 3, gen_loss = 2.432832213480081, disc_loss = 0.013165989100112956
Trained batch 134 in epoch 3, gen_loss = 2.433913228246901, disc_loss = 0.01308792168446989
Trained batch 135 in epoch 3, gen_loss = 2.435245116843897, disc_loss = 0.013007763127782656
Trained batch 136 in epoch 3, gen_loss = 2.434541683997551, disc_loss = 0.01293633370762215
Trained batch 137 in epoch 3, gen_loss = 2.434783050115558, disc_loss = 0.012875049189407971
Trained batch 138 in epoch 3, gen_loss = 2.4371612800968636, disc_loss = 0.012792624309558501
Trained batch 139 in epoch 3, gen_loss = 2.437279792342867, disc_loss = 0.012718006250880924
Trained batch 140 in epoch 3, gen_loss = 2.4370511161520128, disc_loss = 0.012644744247812381
Trained batch 141 in epoch 3, gen_loss = 2.43580424365863, disc_loss = 0.01257033971003847
Trained batch 142 in epoch 3, gen_loss = 2.4349920324512295, disc_loss = 0.012500393211717841
Trained batch 143 in epoch 3, gen_loss = 2.437971158987946, disc_loss = 0.012426275128543947
Trained batch 144 in epoch 3, gen_loss = 2.438233442142092, disc_loss = 0.012354830805822435
Trained batch 145 in epoch 3, gen_loss = 2.4379846453666687, disc_loss = 0.012283231851753255
Trained batch 146 in epoch 3, gen_loss = 2.436826152055442, disc_loss = 0.01221081996447451
Trained batch 147 in epoch 3, gen_loss = 2.4373215799396104, disc_loss = 0.012152914759369466
Trained batch 148 in epoch 3, gen_loss = 2.4354693577593607, disc_loss = 0.012096907337971231
Trained batch 149 in epoch 3, gen_loss = 2.4360577575365703, disc_loss = 0.012026462260788927
Trained batch 150 in epoch 3, gen_loss = 2.436296162226342, disc_loss = 0.011959884362757847
Trained batch 151 in epoch 3, gen_loss = 2.4366406837576315, disc_loss = 0.011893942720857203
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 2.40507173538208, disc_loss = 0.0013343226164579391
Trained batch 1 in epoch 4, gen_loss = 2.6851898431777954, disc_loss = 0.0016956246690824628
Trained batch 2 in epoch 4, gen_loss = 2.664708216985067, disc_loss = 0.0016943291605760653
Trained batch 3 in epoch 4, gen_loss = 2.667029917240143, disc_loss = 0.0016182185499928892
Trained batch 4 in epoch 4, gen_loss = 2.5834900379180907, disc_loss = 0.0017697826959192752
Trained batch 5 in epoch 4, gen_loss = 2.5531673431396484, disc_loss = 0.0019800724306454263
Trained batch 6 in epoch 4, gen_loss = 2.551804338182722, disc_loss = 0.0020827784069946836
Trained batch 7 in epoch 4, gen_loss = 2.5476932525634766, disc_loss = 0.0022487406386062503
Trained batch 8 in epoch 4, gen_loss = 2.4951709376441107, disc_loss = 0.00687662460323837
Trained batch 9 in epoch 4, gen_loss = 2.4513175249099732, disc_loss = 0.03284106878563762
Trained batch 10 in epoch 4, gen_loss = 2.484221501783891, disc_loss = 0.039784306406297466
Trained batch 11 in epoch 4, gen_loss = 2.4601138830184937, disc_loss = 0.047094775596633554
Trained batch 12 in epoch 4, gen_loss = 2.4137012224930983, disc_loss = 0.05329940948062218
Trained batch 13 in epoch 4, gen_loss = 2.4006327050072804, disc_loss = 0.05368857345144663
Trained batch 14 in epoch 4, gen_loss = 2.4007635593414305, disc_loss = 0.05282339720676343
Trained batch 15 in epoch 4, gen_loss = 2.3860604614019394, disc_loss = 0.05015539767919108
Trained batch 16 in epoch 4, gen_loss = 2.39416644152473, disc_loss = 0.047651775619562936
Trained batch 17 in epoch 4, gen_loss = 2.4028393692440457, disc_loss = 0.0454547768458724
Trained batch 18 in epoch 4, gen_loss = 2.4005943599500155, disc_loss = 0.043316709294326995
Trained batch 19 in epoch 4, gen_loss = 2.376928687095642, disc_loss = 0.04157946149352938
Trained batch 20 in epoch 4, gen_loss = 2.360527265639532, disc_loss = 0.04020675092137286
Trained batch 21 in epoch 4, gen_loss = 2.371474168517373, disc_loss = 0.0386627527080815
Trained batch 22 in epoch 4, gen_loss = 2.3772353607675303, disc_loss = 0.037192762323209776
Trained batch 23 in epoch 4, gen_loss = 2.366750111182531, disc_loss = 0.035928633549095444
Trained batch 24 in epoch 4, gen_loss = 2.361743965148926, disc_loss = 0.03474313182756305
Trained batch 25 in epoch 4, gen_loss = 2.36746031504411, disc_loss = 0.03352715726941824
Trained batch 26 in epoch 4, gen_loss = 2.3822461940624096, disc_loss = 0.03242005168080882
Trained batch 27 in epoch 4, gen_loss = 2.37385846887316, disc_loss = 0.03140642582106271
Trained batch 28 in epoch 4, gen_loss = 2.3709263801574707, disc_loss = 0.03042668493560933
Trained batch 29 in epoch 4, gen_loss = 2.372664038340251, disc_loss = 0.02953500566072762
Trained batch 30 in epoch 4, gen_loss = 2.375930909187563, disc_loss = 0.028737066148389733
Trained batch 31 in epoch 4, gen_loss = 2.380821518599987, disc_loss = 0.027998496356303804
Trained batch 32 in epoch 4, gen_loss = 2.383021434148153, disc_loss = 0.027370290365070105
Trained batch 33 in epoch 4, gen_loss = 2.3791806978337906, disc_loss = 0.026721738155602533
Trained batch 34 in epoch 4, gen_loss = 2.386453219822475, disc_loss = 0.02610619013596858
Trained batch 35 in epoch 4, gen_loss = 2.396596524450514, disc_loss = 0.025545080606308248
Trained batch 36 in epoch 4, gen_loss = 2.3986190976323307, disc_loss = 0.024931518549754006
Trained batch 37 in epoch 4, gen_loss = 2.3978864644703113, disc_loss = 0.024334278178254242
Trained batch 38 in epoch 4, gen_loss = 2.406226023649558, disc_loss = 0.023794965406593222
Trained batch 39 in epoch 4, gen_loss = 2.413008815050125, disc_loss = 0.02328565915231593
Trained batch 40 in epoch 4, gen_loss = 2.4163403336594746, disc_loss = 0.022815276056573523
Trained batch 41 in epoch 4, gen_loss = 2.4200408912840343, disc_loss = 0.022376458454389302
Trained batch 42 in epoch 4, gen_loss = 2.42302400012349, disc_loss = 0.021931762725851216
Trained batch 43 in epoch 4, gen_loss = 2.4235515757040544, disc_loss = 0.02148110211022537
Trained batch 44 in epoch 4, gen_loss = 2.4182608763376874, disc_loss = 0.021085338294506074
Trained batch 45 in epoch 4, gen_loss = 2.416231227957684, disc_loss = 0.02069542943702444
Trained batch 46 in epoch 4, gen_loss = 2.4151749103627305, disc_loss = 0.02030023434100316
Trained batch 47 in epoch 4, gen_loss = 2.4152700901031494, disc_loss = 0.01993256238347385
Trained batch 48 in epoch 4, gen_loss = 2.4220599009066213, disc_loss = 0.0195844931651515
Trained batch 49 in epoch 4, gen_loss = 2.420939359664917, disc_loss = 0.019233171329833567
Trained batch 50 in epoch 4, gen_loss = 2.421309639425839, disc_loss = 0.0189069879706949
Trained batch 51 in epoch 4, gen_loss = 2.426065742969513, disc_loss = 0.018608642392791808
Trained batch 52 in epoch 4, gen_loss = 2.4228569471611165, disc_loss = 0.01833921087519178
Trained batch 53 in epoch 4, gen_loss = 2.4208523564868503, disc_loss = 0.018039507377478812
Trained batch 54 in epoch 4, gen_loss = 2.419735084880482, disc_loss = 0.01773760285736485
Trained batch 55 in epoch 4, gen_loss = 2.4163894993918285, disc_loss = 0.017502068824666952
Trained batch 56 in epoch 4, gen_loss = 2.415348613471316, disc_loss = 0.017325262318512325
Trained batch 57 in epoch 4, gen_loss = 2.4127424297661615, disc_loss = 0.01735606557561149
Trained batch 58 in epoch 4, gen_loss = 2.411354590270479, disc_loss = 0.01759109364317383
Trained batch 59 in epoch 4, gen_loss = 2.4133489529291787, disc_loss = 0.01757112718963375
Trained batch 60 in epoch 4, gen_loss = 2.424520703612781, disc_loss = 0.017403633402446744
Trained batch 61 in epoch 4, gen_loss = 2.4206479826281146, disc_loss = 0.017159814567064807
Trained batch 62 in epoch 4, gen_loss = 2.418601153388856, disc_loss = 0.016955802516479577
Trained batch 63 in epoch 4, gen_loss = 2.42390151694417, disc_loss = 0.01672944758684025
Trained batch 64 in epoch 4, gen_loss = 2.421043340976422, disc_loss = 0.01656611842962985
Trained batch 65 in epoch 4, gen_loss = 2.4175296407757383, disc_loss = 0.016362394985855754
Trained batch 66 in epoch 4, gen_loss = 2.4141467542790656, disc_loss = 0.016158938946536007
Trained batch 67 in epoch 4, gen_loss = 2.4220173288794125, disc_loss = 0.01595710571649868
Trained batch 68 in epoch 4, gen_loss = 2.423977278280949, disc_loss = 0.01576042605523506
Trained batch 69 in epoch 4, gen_loss = 2.429049277305603, disc_loss = 0.015571304194496146
Trained batch 70 in epoch 4, gen_loss = 2.429476677531927, disc_loss = 0.015404085336830204
Trained batch 71 in epoch 4, gen_loss = 2.4273752007219525, disc_loss = 0.015213865219266154
Trained batch 72 in epoch 4, gen_loss = 2.4255448334837615, disc_loss = 0.015028959068418671
Trained batch 73 in epoch 4, gen_loss = 2.425031323690672, disc_loss = 0.014852928984092196
Trained batch 74 in epoch 4, gen_loss = 2.419820483525594, disc_loss = 0.014706934195322294
Trained batch 75 in epoch 4, gen_loss = 2.416565129631444, disc_loss = 0.01454150122988626
Trained batch 76 in epoch 4, gen_loss = 2.4176609639997606, disc_loss = 0.014397929523853803
Trained batch 77 in epoch 4, gen_loss = 2.4175124871425138, disc_loss = 0.014246613484246131
Trained batch 78 in epoch 4, gen_loss = 2.4195904882648325, disc_loss = 0.014096150226313385
Trained batch 79 in epoch 4, gen_loss = 2.4197194427251816, disc_loss = 0.013942500263510738
Trained batch 80 in epoch 4, gen_loss = 2.4198516033313893, disc_loss = 0.013799744078969974
Trained batch 81 in epoch 4, gen_loss = 2.4171979369186776, disc_loss = 0.01364558217791477
Trained batch 82 in epoch 4, gen_loss = 2.419884026768696, disc_loss = 0.013501850911977151
Trained batch 83 in epoch 4, gen_loss = 2.4158061061586653, disc_loss = 0.013387248267896385
Trained batch 84 in epoch 4, gen_loss = 2.411551727968104, disc_loss = 0.013288514216101784
Trained batch 85 in epoch 4, gen_loss = 2.40964038427486, disc_loss = 0.013187453506763504
Trained batch 86 in epoch 4, gen_loss = 2.4100915590922036, disc_loss = 0.013073668198328165
Trained batch 87 in epoch 4, gen_loss = 2.411410009319132, disc_loss = 0.012942618140104141
Trained batch 88 in epoch 4, gen_loss = 2.409369200802921, disc_loss = 0.012827060355417681
Trained batch 89 in epoch 4, gen_loss = 2.408933464686076, disc_loss = 0.012724238574608332
Trained batch 90 in epoch 4, gen_loss = 2.4091338980328905, disc_loss = 0.012601225798089918
Trained batch 91 in epoch 4, gen_loss = 2.404285043478012, disc_loss = 0.01329190143049978
Trained batch 92 in epoch 4, gen_loss = 2.398301100218168, disc_loss = 0.017204166307384448
Trained batch 93 in epoch 4, gen_loss = 2.3976056994275843, disc_loss = 0.019083862497590164
Trained batch 94 in epoch 4, gen_loss = 2.4023620417243556, disc_loss = 0.023453482718353992
Trained batch 95 in epoch 4, gen_loss = 2.400708083063364, disc_loss = 0.02538112353795441
Trained batch 96 in epoch 4, gen_loss = 2.404663173193784, disc_loss = 0.0269896396190965
Trained batch 97 in epoch 4, gen_loss = 2.4051719186257343, disc_loss = 0.028427476678708836
Trained batch 98 in epoch 4, gen_loss = 2.4018557733959622, disc_loss = 0.029121361868079714
Trained batch 99 in epoch 4, gen_loss = 2.403474508523941, disc_loss = 0.029106824870686977
Trained batch 100 in epoch 4, gen_loss = 2.4015716149075197, disc_loss = 0.02905091092608279
Trained batch 101 in epoch 4, gen_loss = 2.4040347840271745, disc_loss = 0.02904449091703795
Trained batch 102 in epoch 4, gen_loss = 2.4041330386134026, disc_loss = 0.028870449453429543
Trained batch 103 in epoch 4, gen_loss = 2.404596731066704, disc_loss = 0.028670464496826753
Trained batch 104 in epoch 4, gen_loss = 2.4061739637738184, disc_loss = 0.028497118740120814
Trained batch 105 in epoch 4, gen_loss = 2.4084158359833485, disc_loss = 0.028268316433378408
Trained batch 106 in epoch 4, gen_loss = 2.408807539494238, disc_loss = 0.02807329486071994
Trained batch 107 in epoch 4, gen_loss = 2.408195207516352, disc_loss = 0.02788274082208604
Trained batch 108 in epoch 4, gen_loss = 2.4065489933031414, disc_loss = 0.027677123278909182
Trained batch 109 in epoch 4, gen_loss = 2.4067774241620845, disc_loss = 0.02745940918737853
Trained batch 110 in epoch 4, gen_loss = 2.4055990367322355, disc_loss = 0.027252634804746188
Trained batch 111 in epoch 4, gen_loss = 2.4073174563901767, disc_loss = 0.027064306792453863
Trained batch 112 in epoch 4, gen_loss = 2.4071448218505993, disc_loss = 0.026855906712682506
Trained batch 113 in epoch 4, gen_loss = 2.407380021454995, disc_loss = 0.026644094248727095
Trained batch 114 in epoch 4, gen_loss = 2.4075397087180095, disc_loss = 0.02644513080139523
Trained batch 115 in epoch 4, gen_loss = 2.4098181282651834, disc_loss = 0.02624299093591178
Trained batch 116 in epoch 4, gen_loss = 2.4080957011279898, disc_loss = 0.026102459891977854
Trained batch 117 in epoch 4, gen_loss = 2.4061036766585655, disc_loss = 0.025938428241870034
Trained batch 118 in epoch 4, gen_loss = 2.405001412920591, disc_loss = 0.02579679912809251
Trained batch 119 in epoch 4, gen_loss = 2.408022321263949, disc_loss = 0.025617722870083525
Trained batch 120 in epoch 4, gen_loss = 2.408974892836957, disc_loss = 0.025437760949981483
Trained batch 121 in epoch 4, gen_loss = 2.409396604436343, disc_loss = 0.025254198691624475
Trained batch 122 in epoch 4, gen_loss = 2.4080161108234064, disc_loss = 0.025068580735156814
Trained batch 123 in epoch 4, gen_loss = 2.4097438098922854, disc_loss = 0.024882558199967587
Trained batch 124 in epoch 4, gen_loss = 2.4121892671585083, disc_loss = 0.0246984690874815
Trained batch 125 in epoch 4, gen_loss = 2.4123520368621465, disc_loss = 0.024518694534587365
Trained batch 126 in epoch 4, gen_loss = 2.4123159815945963, disc_loss = 0.02434519007545346
Trained batch 127 in epoch 4, gen_loss = 2.4110007723793387, disc_loss = 0.02417914329089399
Trained batch 128 in epoch 4, gen_loss = 2.4091719148695008, disc_loss = 0.024018460994788497
Trained batch 129 in epoch 4, gen_loss = 2.409396750193376, disc_loss = 0.023872262166024973
Trained batch 130 in epoch 4, gen_loss = 2.4123852662457765, disc_loss = 0.023714263473800918
Trained batch 131 in epoch 4, gen_loss = 2.4129133161270255, disc_loss = 0.023556927996899256
Trained batch 132 in epoch 4, gen_loss = 2.416144773476106, disc_loss = 0.023398125596708598
Trained batch 133 in epoch 4, gen_loss = 2.4184355015185344, disc_loss = 0.02323807948425329
Trained batch 134 in epoch 4, gen_loss = 2.4167225687592118, disc_loss = 0.023104146768821887
Trained batch 135 in epoch 4, gen_loss = 2.416281290790614, disc_loss = 0.02296078844964915
Trained batch 136 in epoch 4, gen_loss = 2.415915977345766, disc_loss = 0.022822189684379438
Trained batch 137 in epoch 4, gen_loss = 2.4147663505181023, disc_loss = 0.022680049008804548
Trained batch 138 in epoch 4, gen_loss = 2.4148209240796756, disc_loss = 0.022536003792142534
Trained batch 139 in epoch 4, gen_loss = 2.415020304918289, disc_loss = 0.02239644550635213
Trained batch 140 in epoch 4, gen_loss = 2.415406791030938, disc_loss = 0.022282442625394052
Trained batch 141 in epoch 4, gen_loss = 2.4163359059414393, disc_loss = 0.022141280793092986
Trained batch 142 in epoch 4, gen_loss = 2.418134219996579, disc_loss = 0.021996940583010185
Trained batch 143 in epoch 4, gen_loss = 2.420828379690647, disc_loss = 0.02185516651014849
Trained batch 144 in epoch 4, gen_loss = 2.4217115163803102, disc_loss = 0.02171747610374386
Trained batch 145 in epoch 4, gen_loss = 2.421684824440577, disc_loss = 0.021581804377428727
Trained batch 146 in epoch 4, gen_loss = 2.421679963059977, disc_loss = 0.02145695041304416
Trained batch 147 in epoch 4, gen_loss = 2.42109047319438, disc_loss = 0.021323879023642606
Trained batch 148 in epoch 4, gen_loss = 2.421633178755741, disc_loss = 0.021190717878076405
Trained batch 149 in epoch 4, gen_loss = 2.4209445468584696, disc_loss = 0.0210634228020596
Trained batch 150 in epoch 4, gen_loss = 2.4197262099247103, disc_loss = 0.020940986390237924
Trained batch 151 in epoch 4, gen_loss = 2.4215265567365445, disc_loss = 0.020821231863871952
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 2.3530876636505127, disc_loss = 0.00244705006480217
Trained batch 1 in epoch 5, gen_loss = 2.3834824562072754, disc_loss = 0.0030812034383416176
Trained batch 2 in epoch 5, gen_loss = 2.549904187520345, disc_loss = 0.002776342754562696
Trained batch 3 in epoch 5, gen_loss = 2.5490397810935974, disc_loss = 0.002515529078664258
Trained batch 4 in epoch 5, gen_loss = 2.5439476013183593, disc_loss = 0.002351846848614514
Trained batch 5 in epoch 5, gen_loss = 2.4982945919036865, disc_loss = 0.002255961997434497
Trained batch 6 in epoch 5, gen_loss = 2.507854529789516, disc_loss = 0.002156973084700959
Trained batch 7 in epoch 5, gen_loss = 2.499083310365677, disc_loss = 0.00205996647127904
Trained batch 8 in epoch 5, gen_loss = 2.534634987513224, disc_loss = 0.002017744066607621
Trained batch 9 in epoch 5, gen_loss = 2.5529133796691896, disc_loss = 0.0020516777643933893
Trained batch 10 in epoch 5, gen_loss = 2.5528521104292436, disc_loss = 0.002010084297084673
Trained batch 11 in epoch 5, gen_loss = 2.5555317203203836, disc_loss = 0.0019522155732071649
Trained batch 12 in epoch 5, gen_loss = 2.5644772052764893, disc_loss = 0.0019177560282584566
Trained batch 13 in epoch 5, gen_loss = 2.5871123926980153, disc_loss = 0.001909494524755116
Trained batch 14 in epoch 5, gen_loss = 2.574561659495036, disc_loss = 0.0018873618527625998
Trained batch 15 in epoch 5, gen_loss = 2.5647164583206177, disc_loss = 0.0018613058200571686
Trained batch 16 in epoch 5, gen_loss = 2.561961664873011, disc_loss = 0.0018464801901513163
Trained batch 17 in epoch 5, gen_loss = 2.5735892322328358, disc_loss = 0.001895964863554885
Trained batch 18 in epoch 5, gen_loss = 2.5508243535694324, disc_loss = 0.0020237411311092345
Trained batch 19 in epoch 5, gen_loss = 2.5317127108573914, disc_loss = 0.0020875502901617437
Trained batch 20 in epoch 5, gen_loss = 2.5348124390556697, disc_loss = 0.002081501081452838
Trained batch 21 in epoch 5, gen_loss = 2.5355417728424072, disc_loss = 0.002112613646948541
Trained batch 22 in epoch 5, gen_loss = 2.5175840647324272, disc_loss = 0.0022192538422329917
Trained batch 23 in epoch 5, gen_loss = 2.5158028304576874, disc_loss = 0.0022787039391308403
Trained batch 24 in epoch 5, gen_loss = 2.504812631607056, disc_loss = 0.002309275255538523
Trained batch 25 in epoch 5, gen_loss = 2.50037958071782, disc_loss = 0.002278798564265554
Trained batch 26 in epoch 5, gen_loss = 2.4974576278969094, disc_loss = 0.002246594052175405
Trained batch 27 in epoch 5, gen_loss = 2.506873760904585, disc_loss = 0.002222300794008853
Trained batch 28 in epoch 5, gen_loss = 2.501997997020853, disc_loss = 0.002215202733199915
Trained batch 29 in epoch 5, gen_loss = 2.503342620531718, disc_loss = 0.00220262334914878
Trained batch 30 in epoch 5, gen_loss = 2.5056678325899187, disc_loss = 0.002188523664259382
Trained batch 31 in epoch 5, gen_loss = 2.506294958293438, disc_loss = 0.0021794790191052016
Trained batch 32 in epoch 5, gen_loss = 2.4948660966121787, disc_loss = 0.0021577164439032927
Trained batch 33 in epoch 5, gen_loss = 2.501400358536664, disc_loss = 0.002219862849040724
Trained batch 34 in epoch 5, gen_loss = 2.4947770391191755, disc_loss = 0.002236719772086612
Trained batch 35 in epoch 5, gen_loss = 2.502214723163181, disc_loss = 0.002216823822689346
Trained batch 36 in epoch 5, gen_loss = 2.4908938279023043, disc_loss = 0.0022971858742420336
Trained batch 37 in epoch 5, gen_loss = 2.490366584376285, disc_loss = 0.002371969764537521
Trained batch 38 in epoch 5, gen_loss = 2.485642359806941, disc_loss = 0.0024202246165189603
Trained batch 39 in epoch 5, gen_loss = 2.488079786300659, disc_loss = 0.0024226319830631836
Trained batch 40 in epoch 5, gen_loss = 2.4848652816400296, disc_loss = 0.00242378468136871
Trained batch 41 in epoch 5, gen_loss = 2.485326471782866, disc_loss = 0.0024009631874616303
Trained batch 42 in epoch 5, gen_loss = 2.486877896064936, disc_loss = 0.0023718964535916266
Trained batch 43 in epoch 5, gen_loss = 2.483374974944375, disc_loss = 0.0023560337246056984
Trained batch 44 in epoch 5, gen_loss = 2.48079309463501, disc_loss = 0.002336255660177105
Trained batch 45 in epoch 5, gen_loss = 2.474274790805319, disc_loss = 0.0023659471872910535
Trained batch 46 in epoch 5, gen_loss = 2.466840830255062, disc_loss = 0.0024217608251034264
Trained batch 47 in epoch 5, gen_loss = 2.466854825615883, disc_loss = 0.0024944531833170913
Trained batch 48 in epoch 5, gen_loss = 2.4625354932279, disc_loss = 0.0025283328034173772
Trained batch 49 in epoch 5, gen_loss = 2.462112698554993, disc_loss = 0.002520510156173259
Trained batch 50 in epoch 5, gen_loss = 2.46174178871454, disc_loss = 0.0025137115712734123
Trained batch 51 in epoch 5, gen_loss = 2.4613338571328383, disc_loss = 0.0025265658690701597
Trained batch 52 in epoch 5, gen_loss = 2.4642024085206806, disc_loss = 0.002513721084468207
Trained batch 53 in epoch 5, gen_loss = 2.46240375218568, disc_loss = 0.002494417527621543
Trained batch 54 in epoch 5, gen_loss = 2.457652404091575, disc_loss = 0.0024795214603231712
Trained batch 55 in epoch 5, gen_loss = 2.4584649077483585, disc_loss = 0.002514592883276886
Trained batch 56 in epoch 5, gen_loss = 2.458194845601132, disc_loss = 0.0025839531230495163
Trained batch 57 in epoch 5, gen_loss = 2.45446488775056, disc_loss = 0.002656174851742027
Trained batch 58 in epoch 5, gen_loss = 2.4542784367577504, disc_loss = 0.0026844756922416264
Trained batch 59 in epoch 5, gen_loss = 2.450341049830119, disc_loss = 0.0026881900615990163
Trained batch 60 in epoch 5, gen_loss = 2.45304506723998, disc_loss = 0.002689689428347056
Trained batch 61 in epoch 5, gen_loss = 2.456134165486982, disc_loss = 0.0027125315485341897
Trained batch 62 in epoch 5, gen_loss = 2.45870734396435, disc_loss = 0.0027006332252529405
Trained batch 63 in epoch 5, gen_loss = 2.4625572189688683, disc_loss = 0.0026944657365675084
Trained batch 64 in epoch 5, gen_loss = 2.461786930377667, disc_loss = 0.002692655807074446
Trained batch 65 in epoch 5, gen_loss = 2.4595836075869473, disc_loss = 0.0026726869982667267
Trained batch 66 in epoch 5, gen_loss = 2.456794279724804, disc_loss = 0.0026853577835040526
Trained batch 67 in epoch 5, gen_loss = 2.4567640634144055, disc_loss = 0.00267171224935309
Trained batch 68 in epoch 5, gen_loss = 2.460322556288346, disc_loss = 0.002668888874999855
Trained batch 69 in epoch 5, gen_loss = 2.4570277963365825, disc_loss = 0.002659090485290757
Trained batch 70 in epoch 5, gen_loss = 2.4544397777235005, disc_loss = 0.0026671552053377243
Trained batch 71 in epoch 5, gen_loss = 2.4577420916822224, disc_loss = 0.002645564110328754
Trained batch 72 in epoch 5, gen_loss = 2.4541973708427114, disc_loss = 0.0026331053080343426
Trained batch 73 in epoch 5, gen_loss = 2.45426361625259, disc_loss = 0.002615820962583294
Trained batch 74 in epoch 5, gen_loss = 2.4533204491933187, disc_loss = 0.002596336854621768
Trained batch 75 in epoch 5, gen_loss = 2.451551189548091, disc_loss = 0.002589569791636773
Trained batch 76 in epoch 5, gen_loss = 2.4528259023443444, disc_loss = 0.0025731950980163627
Trained batch 77 in epoch 5, gen_loss = 2.4570320538985424, disc_loss = 0.0025607053002414224
Trained batch 78 in epoch 5, gen_loss = 2.451085820982728, disc_loss = 0.002564910632746789
Trained batch 79 in epoch 5, gen_loss = 2.450649207830429, disc_loss = 0.002581874378665816
Trained batch 80 in epoch 5, gen_loss = 2.4520108905839333, disc_loss = 0.0025688112069519216
Trained batch 81 in epoch 5, gen_loss = 2.4515487566226866, disc_loss = 0.002550792001562602
Trained batch 82 in epoch 5, gen_loss = 2.4488659738058067, disc_loss = 0.002545941257793232
Trained batch 83 in epoch 5, gen_loss = 2.4452831830297197, disc_loss = 0.002533599220138664
Trained batch 84 in epoch 5, gen_loss = 2.4432263458476347, disc_loss = 0.002518335883231724
Trained batch 85 in epoch 5, gen_loss = 2.439827844154003, disc_loss = 0.0025029518563018808
Trained batch 86 in epoch 5, gen_loss = 2.4394654323314797, disc_loss = 0.002492940124263452
Trained batch 87 in epoch 5, gen_loss = 2.442592043768276, disc_loss = 0.0024794604184783316
Trained batch 88 in epoch 5, gen_loss = 2.4405222983842485, disc_loss = 0.002472886858832384
Trained batch 89 in epoch 5, gen_loss = 2.436852690908644, disc_loss = 0.0024648297500486174
Trained batch 90 in epoch 5, gen_loss = 2.433811379003001, disc_loss = 0.0024530715373047925
Trained batch 91 in epoch 5, gen_loss = 2.4329902633376745, disc_loss = 0.002452198870267476
Trained batch 92 in epoch 5, gen_loss = 2.4312207468094362, disc_loss = 0.0024458149971280205
Trained batch 93 in epoch 5, gen_loss = 2.4330719633305327, disc_loss = 0.0024399788743083147
Trained batch 94 in epoch 5, gen_loss = 2.4315060565346167, disc_loss = 0.0024289413698409734
Trained batch 95 in epoch 5, gen_loss = 2.432462359468142, disc_loss = 0.0024324753734011515
Trained batch 96 in epoch 5, gen_loss = 2.4346323603207303, disc_loss = 0.0024328357108014146
Trained batch 97 in epoch 5, gen_loss = 2.4337742717898623, disc_loss = 0.002431709331232218
Trained batch 98 in epoch 5, gen_loss = 2.433644063544996, disc_loss = 0.0024686754620022546
Trained batch 99 in epoch 5, gen_loss = 2.4351668548583985, disc_loss = 0.0024592818913515657
Trained batch 100 in epoch 5, gen_loss = 2.440655602086889, disc_loss = 0.002463736309725238
Trained batch 101 in epoch 5, gen_loss = 2.4413430994632197, disc_loss = 0.0024531156694352187
Trained batch 102 in epoch 5, gen_loss = 2.4405132937199863, disc_loss = 0.0024526542091054967
Trained batch 103 in epoch 5, gen_loss = 2.4404032161602607, disc_loss = 0.0024402252266344684
Trained batch 104 in epoch 5, gen_loss = 2.4394562403361, disc_loss = 0.002429432511728789
Trained batch 105 in epoch 5, gen_loss = 2.4394641934700734, disc_loss = 0.002415290398892226
Trained batch 106 in epoch 5, gen_loss = 2.4394534881983962, disc_loss = 0.0024059830313966236
Trained batch 107 in epoch 5, gen_loss = 2.4371894664234586, disc_loss = 0.0023943106848660304
Trained batch 108 in epoch 5, gen_loss = 2.437488973687548, disc_loss = 0.002383614834739801
Trained batch 109 in epoch 5, gen_loss = 2.4375776854428377, disc_loss = 0.002371920271649618
Trained batch 110 in epoch 5, gen_loss = 2.4355302458410866, disc_loss = 0.002372863976209349
Trained batch 111 in epoch 5, gen_loss = 2.4364528379270007, disc_loss = 0.0023733287848049906
Trained batch 112 in epoch 5, gen_loss = 2.4359200464940702, disc_loss = 0.002361851044831616
Trained batch 113 in epoch 5, gen_loss = 2.4362855898706535, disc_loss = 0.0023544447888669217
Trained batch 114 in epoch 5, gen_loss = 2.439204819306083, disc_loss = 0.002341406527177795
Trained batch 115 in epoch 5, gen_loss = 2.437255752497706, disc_loss = 0.0023338969250948265
Trained batch 116 in epoch 5, gen_loss = 2.4415709605583777, disc_loss = 0.0023294109920772095
Trained batch 117 in epoch 5, gen_loss = 2.442730440931805, disc_loss = 0.0023244690678824306
Trained batch 118 in epoch 5, gen_loss = 2.4409536153328517, disc_loss = 0.002318298610459481
Trained batch 119 in epoch 5, gen_loss = 2.4401611924171447, disc_loss = 0.0023131938418373466
Trained batch 120 in epoch 5, gen_loss = 2.4381710084016657, disc_loss = 0.002307999136372785
Trained batch 121 in epoch 5, gen_loss = 2.438406463529243, disc_loss = 0.0023019746266549727
Trained batch 122 in epoch 5, gen_loss = 2.4388670204131584, disc_loss = 0.002300407584166018
Trained batch 123 in epoch 5, gen_loss = 2.437669563678003, disc_loss = 0.002301443632947461
Trained batch 124 in epoch 5, gen_loss = 2.4348930568695066, disc_loss = 0.0025786694530397654
Trained batch 125 in epoch 5, gen_loss = 2.428982845374516, disc_loss = 0.006375759036191518
Trained batch 126 in epoch 5, gen_loss = 2.4273430709763777, disc_loss = 0.007703849556305864
Trained batch 127 in epoch 5, gen_loss = 2.424306374974549, disc_loss = 0.009272787743611843
Trained batch 128 in epoch 5, gen_loss = 2.4229672112206155, disc_loss = 0.010246346417684541
Trained batch 129 in epoch 5, gen_loss = 2.421374387924488, disc_loss = 0.010841572422605868
Trained batch 130 in epoch 5, gen_loss = 2.4241179300628546, disc_loss = 0.011328508460695165
Trained batch 131 in epoch 5, gen_loss = 2.4194357756412392, disc_loss = 0.012417618038880668
Trained batch 132 in epoch 5, gen_loss = 2.415908343809888, disc_loss = 0.01322148955441115
Trained batch 133 in epoch 5, gen_loss = 2.411089498605301, disc_loss = 0.013846720744327488
Trained batch 134 in epoch 5, gen_loss = 2.4086327146600794, disc_loss = 0.013883480934978083
Trained batch 135 in epoch 5, gen_loss = 2.40819355319528, disc_loss = 0.01387416381861412
Trained batch 136 in epoch 5, gen_loss = 2.4067642288486453, disc_loss = 0.013952515511195699
Trained batch 137 in epoch 5, gen_loss = 2.409494996070862, disc_loss = 0.015296493516897486
Trained batch 138 in epoch 5, gen_loss = 2.4063826868002365, disc_loss = 0.017454030684014556
Trained batch 139 in epoch 5, gen_loss = 2.4056926122733526, disc_loss = 0.017983338112078074
Trained batch 140 in epoch 5, gen_loss = 2.4022741461476538, disc_loss = 0.019422722394175248
Trained batch 141 in epoch 5, gen_loss = 2.4012166051797466, disc_loss = 0.020098709076656108
Trained batch 142 in epoch 5, gen_loss = 2.400484517737702, disc_loss = 0.020441050486560988
Trained batch 143 in epoch 5, gen_loss = 2.400415282282564, disc_loss = 0.02082623425748251
Trained batch 144 in epoch 5, gen_loss = 2.400213893528642, disc_loss = 0.021115565898924552
Trained batch 145 in epoch 5, gen_loss = 2.3994962393421018, disc_loss = 0.021195217439177613
Trained batch 146 in epoch 5, gen_loss = 2.402100194068182, disc_loss = 0.021138781195405087
Trained batch 147 in epoch 5, gen_loss = 2.4039805942290537, disc_loss = 0.021064355348022906
Trained batch 148 in epoch 5, gen_loss = 2.4042314146989145, disc_loss = 0.020976114088369396
Trained batch 149 in epoch 5, gen_loss = 2.4032561977704368, disc_loss = 0.021358607456398507
Trained batch 150 in epoch 5, gen_loss = 2.4005263806968333, disc_loss = 0.022868353548145155
Trained batch 151 in epoch 5, gen_loss = 2.3991981329102265, disc_loss = 0.023228337444475312
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 2.2091989517211914, disc_loss = 0.07941620796918869
Trained batch 1 in epoch 6, gen_loss = 2.3879640102386475, disc_loss = 0.05789095349609852
Trained batch 2 in epoch 6, gen_loss = 2.5650440057118735, disc_loss = 0.04579663028319677
Trained batch 3 in epoch 6, gen_loss = 2.748480975627899, disc_loss = 0.043608841486275196
Trained batch 4 in epoch 6, gen_loss = 2.608435773849487, disc_loss = 0.04510744512081146
Trained batch 5 in epoch 6, gen_loss = 2.605789621671041, disc_loss = 0.042624255642294884
Trained batch 6 in epoch 6, gen_loss = 2.577852351324899, disc_loss = 0.03759156992392881
Trained batch 7 in epoch 6, gen_loss = 2.5561313927173615, disc_loss = 0.034883559914305806
Trained batch 8 in epoch 6, gen_loss = 2.5627308421664767, disc_loss = 0.03160995586464802
Trained batch 9 in epoch 6, gen_loss = 2.5539007902145388, disc_loss = 0.029861604887992145
Trained batch 10 in epoch 6, gen_loss = 2.522240248593417, disc_loss = 0.02775858376513828
Trained batch 11 in epoch 6, gen_loss = 2.503642459710439, disc_loss = 0.02607680845540017
Trained batch 12 in epoch 6, gen_loss = 2.4963219349200907, disc_loss = 0.024542177024369057
Trained batch 13 in epoch 6, gen_loss = 2.4941607202802385, disc_loss = 0.023083964761878763
Trained batch 14 in epoch 6, gen_loss = 2.495009930928548, disc_loss = 0.02177155204117298
Trained batch 15 in epoch 6, gen_loss = 2.506912663578987, disc_loss = 0.020611652740626596
Trained batch 16 in epoch 6, gen_loss = 2.5118280438815845, disc_loss = 0.019606512724695838
Trained batch 17 in epoch 6, gen_loss = 2.5059972604115806, disc_loss = 0.018812482555707295
Trained batch 18 in epoch 6, gen_loss = 2.5233318178277266, disc_loss = 0.018094939816939205
Trained batch 19 in epoch 6, gen_loss = 2.5136046767234803, disc_loss = 0.017594068264588713
Trained batch 20 in epoch 6, gen_loss = 2.4957781519208635, disc_loss = 0.017053761430794283
Trained batch 21 in epoch 6, gen_loss = 2.468902273611589, disc_loss = 0.018223401116715235
Trained batch 22 in epoch 6, gen_loss = 2.4555103675178858, disc_loss = 0.02353486058342716
Trained batch 23 in epoch 6, gen_loss = 2.465414742628733, disc_loss = 0.025924145826138556
Trained batch 24 in epoch 6, gen_loss = 2.476154842376709, disc_loss = 0.026238740645349024
Trained batch 25 in epoch 6, gen_loss = 2.476546425085801, disc_loss = 0.025710373006474514
Trained batch 26 in epoch 6, gen_loss = 2.4668713763908103, disc_loss = 0.025269157805100636
Trained batch 27 in epoch 6, gen_loss = 2.456699882234846, disc_loss = 0.024710362743852392
Trained batch 28 in epoch 6, gen_loss = 2.4523861819300157, disc_loss = 0.02403295165377444
Trained batch 29 in epoch 6, gen_loss = 2.4523324966430664, disc_loss = 0.023345981910824775
Trained batch 30 in epoch 6, gen_loss = 2.455895516180223, disc_loss = 0.022698661687994195
Trained batch 31 in epoch 6, gen_loss = 2.455389492213726, disc_loss = 0.02209364847658435
Trained batch 32 in epoch 6, gen_loss = 2.4546627637111778, disc_loss = 0.02151355669466835
Trained batch 33 in epoch 6, gen_loss = 2.468404861057506, disc_loss = 0.020978874711812857
Trained batch 34 in epoch 6, gen_loss = 2.464712578909738, disc_loss = 0.02049099634002362
Trained batch 35 in epoch 6, gen_loss = 2.4665077328681946, disc_loss = 0.02000817774225854
Trained batch 36 in epoch 6, gen_loss = 2.4636877034161544, disc_loss = 0.019556350672516872
Trained batch 37 in epoch 6, gen_loss = 2.4629275987022803, disc_loss = 0.01913456306915338
Trained batch 38 in epoch 6, gen_loss = 2.460016519595415, disc_loss = 0.018704142678194702
Trained batch 39 in epoch 6, gen_loss = 2.473785769939423, disc_loss = 0.01832139274920337
Trained batch 40 in epoch 6, gen_loss = 2.4729854944275647, disc_loss = 0.017943461147341425
Trained batch 41 in epoch 6, gen_loss = 2.4797056913375854, disc_loss = 0.017592478149925313
Trained batch 42 in epoch 6, gen_loss = 2.48371699244477, disc_loss = 0.017236229221791376
Trained batch 43 in epoch 6, gen_loss = 2.481193233620037, disc_loss = 0.016889501865741542
Trained batch 44 in epoch 6, gen_loss = 2.477369875378079, disc_loss = 0.016674304944980477
Trained batch 45 in epoch 6, gen_loss = 2.4725401453349902, disc_loss = 0.016437080390143976
Trained batch 46 in epoch 6, gen_loss = 2.472157209477526, disc_loss = 0.016158791452131057
Trained batch 47 in epoch 6, gen_loss = 2.470413406689962, disc_loss = 0.015944028714632925
Trained batch 48 in epoch 6, gen_loss = 2.469463810628774, disc_loss = 0.015689348744950732
Trained batch 49 in epoch 6, gen_loss = 2.462054009437561, disc_loss = 0.015535176265984774
Trained batch 50 in epoch 6, gen_loss = 2.4556347856334613, disc_loss = 0.01542392930052444
Trained batch 51 in epoch 6, gen_loss = 2.454685953947214, disc_loss = 0.015186454021694282
Trained batch 52 in epoch 6, gen_loss = 2.455467422053499, disc_loss = 0.014938569711169825
Trained batch 53 in epoch 6, gen_loss = 2.455913751213639, disc_loss = 0.014721410374881493
Trained batch 54 in epoch 6, gen_loss = 2.449833124334162, disc_loss = 0.01449171711944721
Trained batch 55 in epoch 6, gen_loss = 2.448068759271077, disc_loss = 0.01434439014909523
Trained batch 56 in epoch 6, gen_loss = 2.447831392288208, disc_loss = 0.014147364558946145
Trained batch 57 in epoch 6, gen_loss = 2.4508814565066634, disc_loss = 0.013944753397513053
Trained batch 58 in epoch 6, gen_loss = 2.444446539474746, disc_loss = 0.013790536419314853
Trained batch 59 in epoch 6, gen_loss = 2.444123903910319, disc_loss = 0.013624680934784313
Trained batch 60 in epoch 6, gen_loss = 2.4454427547142155, disc_loss = 0.013436857500250955
Trained batch 61 in epoch 6, gen_loss = 2.440847900605971, disc_loss = 0.01328561604849153
Trained batch 62 in epoch 6, gen_loss = 2.445464493736388, disc_loss = 0.013126469450071454
Trained batch 63 in epoch 6, gen_loss = 2.44360126927495, disc_loss = 0.012965482663275907
Trained batch 64 in epoch 6, gen_loss = 2.4457045885232778, disc_loss = 0.012807118058061371
Trained batch 65 in epoch 6, gen_loss = 2.4512429851474185, disc_loss = 0.012649397154084661
Trained batch 66 in epoch 6, gen_loss = 2.453890181299466, disc_loss = 0.012504981274702657
Trained batch 67 in epoch 6, gen_loss = 2.452185960376964, disc_loss = 0.012358929184676312
Trained batch 68 in epoch 6, gen_loss = 2.455797447674516, disc_loss = 0.012237111541807004
Trained batch 69 in epoch 6, gen_loss = 2.455887866020203, disc_loss = 0.012093998175779623
Trained batch 70 in epoch 6, gen_loss = 2.455861622179058, disc_loss = 0.01195394481912675
Trained batch 71 in epoch 6, gen_loss = 2.458780219157537, disc_loss = 0.011842551873996854
Trained batch 72 in epoch 6, gen_loss = 2.4562311597066384, disc_loss = 0.011721083693435951
Trained batch 73 in epoch 6, gen_loss = 2.461240781320108, disc_loss = 0.01160795391990325
Trained batch 74 in epoch 6, gen_loss = 2.4600494956970214, disc_loss = 0.011502646959076325
Trained batch 75 in epoch 6, gen_loss = 2.4609012697872363, disc_loss = 0.011387880003128788
Trained batch 76 in epoch 6, gen_loss = 2.4554843283318855, disc_loss = 0.01133742853515334
Trained batch 77 in epoch 6, gen_loss = 2.4564451712828417, disc_loss = 0.011336734470648643
Trained batch 78 in epoch 6, gen_loss = 2.4554543193382554, disc_loss = 0.011256607072545758
Trained batch 79 in epoch 6, gen_loss = 2.4614402502775192, disc_loss = 0.011252774798776954
Trained batch 80 in epoch 6, gen_loss = 2.459204676710529, disc_loss = 0.011173219816690241
Trained batch 81 in epoch 6, gen_loss = 2.4557179677777174, disc_loss = 0.011106705310095737
Trained batch 82 in epoch 6, gen_loss = 2.451237652675215, disc_loss = 0.011450014890631638
Trained batch 83 in epoch 6, gen_loss = 2.4489698097819375, disc_loss = 0.013682084928621493
Trained batch 84 in epoch 6, gen_loss = 2.450391275742475, disc_loss = 0.014535969818997033
Trained batch 85 in epoch 6, gen_loss = 2.4465943658074667, disc_loss = 0.014623809492128879
Trained batch 86 in epoch 6, gen_loss = 2.446038251635672, disc_loss = 0.014677453630914291
Trained batch 87 in epoch 6, gen_loss = 2.4428333152424204, disc_loss = 0.014659975650085305
Trained batch 88 in epoch 6, gen_loss = 2.445077550545167, disc_loss = 0.0145712964226272
Trained batch 89 in epoch 6, gen_loss = 2.4414443148507012, disc_loss = 0.0145154670243048
Trained batch 90 in epoch 6, gen_loss = 2.437316278834919, disc_loss = 0.014406492345157888
Trained batch 91 in epoch 6, gen_loss = 2.4335165930830915, disc_loss = 0.014339206158183515
Trained batch 92 in epoch 6, gen_loss = 2.432525929584298, disc_loss = 0.014226242889880492
Trained batch 93 in epoch 6, gen_loss = 2.4377906804389142, disc_loss = 0.014107280098734068
Trained batch 94 in epoch 6, gen_loss = 2.4385103501771628, disc_loss = 0.013992407569955838
Trained batch 95 in epoch 6, gen_loss = 2.4368846838672957, disc_loss = 0.013870277369278483
Trained batch 96 in epoch 6, gen_loss = 2.4417180548009183, disc_loss = 0.013754006758447467
Trained batch 97 in epoch 6, gen_loss = 2.4432531789857515, disc_loss = 0.013654128073391562
Trained batch 98 in epoch 6, gen_loss = 2.443514019551903, disc_loss = 0.013695958583154763
Trained batch 99 in epoch 6, gen_loss = 2.446933286190033, disc_loss = 0.013813954475335777
Trained batch 100 in epoch 6, gen_loss = 2.450693744243962, disc_loss = 0.013744129684043697
Trained batch 101 in epoch 6, gen_loss = 2.4499211919073964, disc_loss = 0.013652917253328305
Trained batch 102 in epoch 6, gen_loss = 2.448956635391828, disc_loss = 0.013564546452383103
Trained batch 103 in epoch 6, gen_loss = 2.4468152889838586, disc_loss = 0.013640240295969237
Trained batch 104 in epoch 6, gen_loss = 2.445946877343314, disc_loss = 0.013685004940877358
Trained batch 105 in epoch 6, gen_loss = 2.4463158126147286, disc_loss = 0.013582721104370957
Trained batch 106 in epoch 6, gen_loss = 2.4451415650198394, disc_loss = 0.013485736511734741
Trained batch 107 in epoch 6, gen_loss = 2.4460924400223627, disc_loss = 0.013381205617743372
Trained batch 108 in epoch 6, gen_loss = 2.4443189988442517, disc_loss = 0.013277059015091679
Trained batch 109 in epoch 6, gen_loss = 2.4416855682026255, disc_loss = 0.013180967085910114
Trained batch 110 in epoch 6, gen_loss = 2.4407995455973857, disc_loss = 0.013083192192622134
Trained batch 111 in epoch 6, gen_loss = 2.439988455602101, disc_loss = 0.012983945963372077
Trained batch 112 in epoch 6, gen_loss = 2.4389567586172998, disc_loss = 0.01288569475466435
Trained batch 113 in epoch 6, gen_loss = 2.4344564801768254, disc_loss = 0.013020539272315147
Trained batch 114 in epoch 6, gen_loss = 2.428304551995319, disc_loss = 0.013875387325558973
Trained batch 115 in epoch 6, gen_loss = 2.4300088471379775, disc_loss = 0.01434019982718445
Trained batch 116 in epoch 6, gen_loss = 2.42893403615707, disc_loss = 0.01443400271396097
Trained batch 117 in epoch 6, gen_loss = 2.4273278470766746, disc_loss = 0.014481260196574159
Trained batch 118 in epoch 6, gen_loss = 2.427811670704048, disc_loss = 0.01451822995607342
Trained batch 119 in epoch 6, gen_loss = 2.4283408919970193, disc_loss = 0.01442030823091045
Trained batch 120 in epoch 6, gen_loss = 2.432696109960887, disc_loss = 0.014369517560925119
Trained batch 121 in epoch 6, gen_loss = 2.4325082966538725, disc_loss = 0.014279416023723047
Trained batch 122 in epoch 6, gen_loss = 2.432490356569368, disc_loss = 0.014189687741132892
Trained batch 123 in epoch 6, gen_loss = 2.431214407567055, disc_loss = 0.014100491780892855
Trained batch 124 in epoch 6, gen_loss = 2.4321278781890867, disc_loss = 0.01401481239683926
Trained batch 125 in epoch 6, gen_loss = 2.4315773589270457, disc_loss = 0.013943087481450112
Trained batch 126 in epoch 6, gen_loss = 2.4317882023458406, disc_loss = 0.01387505450901964
Trained batch 127 in epoch 6, gen_loss = 2.4333086032420397, disc_loss = 0.013791421575660934
Trained batch 128 in epoch 6, gen_loss = 2.4313551455505134, disc_loss = 0.013831376410342117
Trained batch 129 in epoch 6, gen_loss = 2.4259728761819694, disc_loss = 0.014092227058986632
Trained batch 130 in epoch 6, gen_loss = 2.4306687416921133, disc_loss = 0.014156121321605476
Trained batch 131 in epoch 6, gen_loss = 2.431754632429643, disc_loss = 0.01420760562706908
Trained batch 132 in epoch 6, gen_loss = 2.4323271181350363, disc_loss = 0.014149672010409316
Trained batch 133 in epoch 6, gen_loss = 2.4304606078275994, disc_loss = 0.014088089801996613
Trained batch 134 in epoch 6, gen_loss = 2.4291708593015318, disc_loss = 0.014028586786999194
Trained batch 135 in epoch 6, gen_loss = 2.4272382224307343, disc_loss = 0.013957882921471643
Trained batch 136 in epoch 6, gen_loss = 2.427719253693184, disc_loss = 0.013870700203004653
Trained batch 137 in epoch 6, gen_loss = 2.429969689120417, disc_loss = 0.013784459503570004
Trained batch 138 in epoch 6, gen_loss = 2.4299884957375286, disc_loss = 0.013696578178862981
Trained batch 139 in epoch 6, gen_loss = 2.4286682520593916, disc_loss = 0.013610521018771188
Trained batch 140 in epoch 6, gen_loss = 2.427686500211134, disc_loss = 0.013537786285069289
Trained batch 141 in epoch 6, gen_loss = 2.425393599859426, disc_loss = 0.013459980243515276
Trained batch 142 in epoch 6, gen_loss = 2.424798571980083, disc_loss = 0.013387553385699857
Trained batch 143 in epoch 6, gen_loss = 2.424932324224048, disc_loss = 0.013310112726887584
Trained batch 144 in epoch 6, gen_loss = 2.4234374556048164, disc_loss = 0.013237302080760228
Trained batch 145 in epoch 6, gen_loss = 2.422402559894405, disc_loss = 0.0131628473324395
Trained batch 146 in epoch 6, gen_loss = 2.4228649009652687, disc_loss = 0.013090884555321263
Trained batch 147 in epoch 6, gen_loss = 2.422895637718407, disc_loss = 0.013013253762462252
Trained batch 148 in epoch 6, gen_loss = 2.423021116512734, disc_loss = 0.012936953870085812
Trained batch 149 in epoch 6, gen_loss = 2.4245699564615886, disc_loss = 0.012859730153189352
Trained batch 150 in epoch 6, gen_loss = 2.424266417294938, disc_loss = 0.012786471123023835
Trained batch 151 in epoch 6, gen_loss = 2.422444563162954, disc_loss = 0.012739680004367409
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 2.16500186920166, disc_loss = 0.002003681380301714
Trained batch 1 in epoch 7, gen_loss = 2.215150475502014, disc_loss = 0.001965209608897567
Trained batch 2 in epoch 7, gen_loss = 2.37698761622111, disc_loss = 0.0018040666667123635
Trained batch 3 in epoch 7, gen_loss = 2.365302801132202, disc_loss = 0.0016788886860013008
Trained batch 4 in epoch 7, gen_loss = 2.3040516853332518, disc_loss = 0.0016050121281296014
Trained batch 5 in epoch 7, gen_loss = 2.2979857126871743, disc_loss = 0.0017652394017204642
Trained batch 6 in epoch 7, gen_loss = 2.273221560886928, disc_loss = 0.00380917322555823
Trained batch 7 in epoch 7, gen_loss = 2.296196699142456, disc_loss = 0.004722304554888979
Trained batch 8 in epoch 7, gen_loss = 2.2932578722635903, disc_loss = 0.004948593753700455
Trained batch 9 in epoch 7, gen_loss = 2.272381401062012, disc_loss = 0.004701285529881716
Trained batch 10 in epoch 7, gen_loss = 2.2806589820168237, disc_loss = 0.004597056678242304
Trained batch 11 in epoch 7, gen_loss = 2.3004767894744873, disc_loss = 0.004419819296648105
Trained batch 12 in epoch 7, gen_loss = 2.327497280561007, disc_loss = 0.004321114088480289
Trained batch 13 in epoch 7, gen_loss = 2.335884554045541, disc_loss = 0.004295628185250929
Trained batch 14 in epoch 7, gen_loss = 2.3335609277089437, disc_loss = 0.004223184349636237
Trained batch 15 in epoch 7, gen_loss = 2.3440137207508087, disc_loss = 0.004093709372682497
Trained batch 16 in epoch 7, gen_loss = 2.3530555051915787, disc_loss = 0.003953019684344968
Trained batch 17 in epoch 7, gen_loss = 2.34872837861379, disc_loss = 0.0038018536870367825
Trained batch 18 in epoch 7, gen_loss = 2.34021940984224, disc_loss = 0.003686921223752985
Trained batch 19 in epoch 7, gen_loss = 2.3403440833091738, disc_loss = 0.0035919134737923742
Trained batch 20 in epoch 7, gen_loss = 2.357105504898798, disc_loss = 0.003504490413303886
Trained batch 21 in epoch 7, gen_loss = 2.3693683472546665, disc_loss = 0.0034102518958124247
Trained batch 22 in epoch 7, gen_loss = 2.373871834381767, disc_loss = 0.003344060620293021
Trained batch 23 in epoch 7, gen_loss = 2.3690574963887534, disc_loss = 0.003272468107752502
Trained batch 24 in epoch 7, gen_loss = 2.3694628143310545, disc_loss = 0.0031939612701535223
Trained batch 25 in epoch 7, gen_loss = 2.3688568885509786, disc_loss = 0.0031138051596756736
Trained batch 26 in epoch 7, gen_loss = 2.3813348876105414, disc_loss = 0.003060598538636609
Trained batch 27 in epoch 7, gen_loss = 2.389950837407793, disc_loss = 0.0030088625956393245
Trained batch 28 in epoch 7, gen_loss = 2.3910343647003174, disc_loss = 0.002953431681440822
Trained batch 29 in epoch 7, gen_loss = 2.3944894393285114, disc_loss = 0.0028862597343201437
Trained batch 30 in epoch 7, gen_loss = 2.3971111082261607, disc_loss = 0.002838471025649098
Trained batch 31 in epoch 7, gen_loss = 2.397588297724724, disc_loss = 0.0027997512006550096
Trained batch 32 in epoch 7, gen_loss = 2.4000815478238193, disc_loss = 0.0027617355702783575
Trained batch 33 in epoch 7, gen_loss = 2.4102089124567367, disc_loss = 0.002734782119445941
Trained batch 34 in epoch 7, gen_loss = 2.4137896060943604, disc_loss = 0.0027141035268349305
Trained batch 35 in epoch 7, gen_loss = 2.4127839340104, disc_loss = 0.0026730040295256507
Trained batch 36 in epoch 7, gen_loss = 2.4022940236168937, disc_loss = 0.0027197950041374644
Trained batch 37 in epoch 7, gen_loss = 2.405519353715997, disc_loss = 0.002687302837761021
Trained batch 38 in epoch 7, gen_loss = 2.401897302040687, disc_loss = 0.0026642767569193472
Trained batch 39 in epoch 7, gen_loss = 2.404197007417679, disc_loss = 0.002628411041223444
Trained batch 40 in epoch 7, gen_loss = 2.412129489386954, disc_loss = 0.0025986148833819643
Trained batch 41 in epoch 7, gen_loss = 2.4059390737896873, disc_loss = 0.002577044305369435
Trained batch 42 in epoch 7, gen_loss = 2.404828343280526, disc_loss = 0.0025519928055663787
Trained batch 43 in epoch 7, gen_loss = 2.413771455938166, disc_loss = 0.002544265116078102
Trained batch 44 in epoch 7, gen_loss = 2.4183516714307998, disc_loss = 0.002518112271920674
Trained batch 45 in epoch 7, gen_loss = 2.4134200966876485, disc_loss = 0.0025019245374056955
Trained batch 46 in epoch 7, gen_loss = 2.4176749016376253, disc_loss = 0.002475735236038553
Trained batch 47 in epoch 7, gen_loss = 2.4153519173463187, disc_loss = 0.0024610372929601
Trained batch 48 in epoch 7, gen_loss = 2.4124069797749423, disc_loss = 0.002432212183651115
Trained batch 49 in epoch 7, gen_loss = 2.4055763864517212, disc_loss = 0.002413271013647318
Trained batch 50 in epoch 7, gen_loss = 2.4071855124305275, disc_loss = 0.0024130473589049836
Trained batch 51 in epoch 7, gen_loss = 2.4056916741224437, disc_loss = 0.002400790775517145
Trained batch 52 in epoch 7, gen_loss = 2.4035436972132267, disc_loss = 0.002412093601207126
Trained batch 53 in epoch 7, gen_loss = 2.4051727365564415, disc_loss = 0.002406087212471498
Trained batch 54 in epoch 7, gen_loss = 2.404037007418546, disc_loss = 0.0023896269203925674
Trained batch 55 in epoch 7, gen_loss = 2.399959832429886, disc_loss = 0.0024085549562836866
Trained batch 56 in epoch 7, gen_loss = 2.403870984127647, disc_loss = 0.0023958185573288225
Trained batch 57 in epoch 7, gen_loss = 2.412473510051596, disc_loss = 0.0023871884532754534
Trained batch 58 in epoch 7, gen_loss = 2.413709604133994, disc_loss = 0.0023697658927353507
Trained batch 59 in epoch 7, gen_loss = 2.4128189285596213, disc_loss = 0.0023603558132890613
Trained batch 60 in epoch 7, gen_loss = 2.411497100454862, disc_loss = 0.002346020646118483
Trained batch 61 in epoch 7, gen_loss = 2.411940005517775, disc_loss = 0.0023376308344004136
Trained batch 62 in epoch 7, gen_loss = 2.410463779691666, disc_loss = 0.002336015411105657
Trained batch 63 in epoch 7, gen_loss = 2.4070892855525017, disc_loss = 0.002326700403500581
Trained batch 64 in epoch 7, gen_loss = 2.410095581641564, disc_loss = 0.0023055766888249378
Trained batch 65 in epoch 7, gen_loss = 2.407990914402586, disc_loss = 0.0022924259890604653
Trained batch 66 in epoch 7, gen_loss = 2.4057675795768625, disc_loss = 0.002286906387142615
Trained batch 67 in epoch 7, gen_loss = 2.4034759752890644, disc_loss = 0.0022753406939206317
Trained batch 68 in epoch 7, gen_loss = 2.4070497941279756, disc_loss = 0.002256607724542635
Trained batch 69 in epoch 7, gen_loss = 2.406472965649196, disc_loss = 0.0022431408587310995
Trained batch 70 in epoch 7, gen_loss = 2.4035429417247505, disc_loss = 0.0022371640350197404
Trained batch 71 in epoch 7, gen_loss = 2.400112575954861, disc_loss = 0.002231355598067037
Trained batch 72 in epoch 7, gen_loss = 2.400978058984835, disc_loss = 0.0022319456345516525
Trained batch 73 in epoch 7, gen_loss = 2.398777423678218, disc_loss = 0.002218722299723005
Trained batch 74 in epoch 7, gen_loss = 2.398976974487305, disc_loss = 0.0022037135312954585
Trained batch 75 in epoch 7, gen_loss = 2.393477352041947, disc_loss = 0.0025067090939142203
Trained batch 76 in epoch 7, gen_loss = 2.3961297536825206, disc_loss = 0.002751271905643599
Trained batch 77 in epoch 7, gen_loss = 2.3908163660611863, disc_loss = 0.0034404475098619093
Trained batch 78 in epoch 7, gen_loss = 2.397615247134921, disc_loss = 0.004461856370296659
Trained batch 79 in epoch 7, gen_loss = 2.3943253055214884, disc_loss = 0.0059360218001529574
Trained batch 80 in epoch 7, gen_loss = 2.3920219077004328, disc_loss = 0.01062497061987718
Trained batch 81 in epoch 7, gen_loss = 2.391815931331821, disc_loss = 0.011311391118641307
Trained batch 82 in epoch 7, gen_loss = 2.39010589524924, disc_loss = 0.012610418048788267
Trained batch 83 in epoch 7, gen_loss = 2.3874296049276986, disc_loss = 0.013068609316611574
Trained batch 84 in epoch 7, gen_loss = 2.388239093387828, disc_loss = 0.013263737519874292
Trained batch 85 in epoch 7, gen_loss = 2.3831719839295675, disc_loss = 0.01518604893583891
Trained batch 86 in epoch 7, gen_loss = 2.382106036975466, disc_loss = 0.0178625986793603
Trained batch 87 in epoch 7, gen_loss = 2.3732580203901636, disc_loss = 0.01902393596670167
Trained batch 88 in epoch 7, gen_loss = 2.3731666321165106, disc_loss = 0.01977135900282458
Trained batch 89 in epoch 7, gen_loss = 2.373358356952667, disc_loss = 0.020242749465008578
Trained batch 90 in epoch 7, gen_loss = 2.3700685461798865, disc_loss = 0.020413723149961167
Trained batch 91 in epoch 7, gen_loss = 2.3724377764307936, disc_loss = 0.020377143225430147
Trained batch 92 in epoch 7, gen_loss = 2.3692690416048934, disc_loss = 0.020517819330737156
Trained batch 93 in epoch 7, gen_loss = 2.369562553598526, disc_loss = 0.020520895045805485
Trained batch 94 in epoch 7, gen_loss = 2.3721664064808894, disc_loss = 0.020384284540226585
Trained batch 95 in epoch 7, gen_loss = 2.371366330732902, disc_loss = 0.020286209202216316
Trained batch 96 in epoch 7, gen_loss = 2.375157045334885, disc_loss = 0.020171329455891836
Trained batch 97 in epoch 7, gen_loss = 2.3742442532461516, disc_loss = 0.02009165249004656
Trained batch 98 in epoch 7, gen_loss = 2.3752192451496317, disc_loss = 0.020004626927953777
Trained batch 99 in epoch 7, gen_loss = 2.3757592236995695, disc_loss = 0.019904969586059452
Trained batch 100 in epoch 7, gen_loss = 2.376483687079779, disc_loss = 0.019792848829143117
Trained batch 101 in epoch 7, gen_loss = 2.375966774482353, disc_loss = 0.019646446540148233
Trained batch 102 in epoch 7, gen_loss = 2.3761090873514563, disc_loss = 0.019481678190415058
Trained batch 103 in epoch 7, gen_loss = 2.3744207127736163, disc_loss = 0.01940213786348557
Trained batch 104 in epoch 7, gen_loss = 2.3770923898333596, disc_loss = 0.01928494204545305
Trained batch 105 in epoch 7, gen_loss = 2.3756811989928193, disc_loss = 0.019151820862700918
Trained batch 106 in epoch 7, gen_loss = 2.37695296122649, disc_loss = 0.019014606078233673
Trained batch 107 in epoch 7, gen_loss = 2.3744423069335796, disc_loss = 0.018883265412619546
Trained batch 108 in epoch 7, gen_loss = 2.376203986482883, disc_loss = 0.018743539893350335
Trained batch 109 in epoch 7, gen_loss = 2.378182256221771, disc_loss = 0.018634026605551215
Trained batch 110 in epoch 7, gen_loss = 2.3804328259047085, disc_loss = 0.018491225872977492
Trained batch 111 in epoch 7, gen_loss = 2.378529396440302, disc_loss = 0.0183513283035219
Trained batch 112 in epoch 7, gen_loss = 2.380304276415732, disc_loss = 0.018213803082523225
Trained batch 113 in epoch 7, gen_loss = 2.381734499805852, disc_loss = 0.018082136719226184
Trained batch 114 in epoch 7, gen_loss = 2.3817069043283876, disc_loss = 0.017946734402895622
Trained batch 115 in epoch 7, gen_loss = 2.3819137698617476, disc_loss = 0.017834426937544525
Trained batch 116 in epoch 7, gen_loss = 2.3807053779944396, disc_loss = 0.017708423010145243
Trained batch 117 in epoch 7, gen_loss = 2.3804429597773793, disc_loss = 0.017585612794037087
Trained batch 118 in epoch 7, gen_loss = 2.38165170705619, disc_loss = 0.01746113567433062
Trained batch 119 in epoch 7, gen_loss = 2.381195130944252, disc_loss = 0.017334652055675786
Trained batch 120 in epoch 7, gen_loss = 2.3825835225995906, disc_loss = 0.017210138603767827
Trained batch 121 in epoch 7, gen_loss = 2.382402964302751, disc_loss = 0.017086611898448012
Trained batch 122 in epoch 7, gen_loss = 2.383791823697284, disc_loss = 0.016977355446348468
Trained batch 123 in epoch 7, gen_loss = 2.3868627673195255, disc_loss = 0.016862892093242057
Trained batch 124 in epoch 7, gen_loss = 2.3858991441726682, disc_loss = 0.016747215321287513
Trained batch 125 in epoch 7, gen_loss = 2.3876138178129045, disc_loss = 0.0166279434887988
Trained batch 126 in epoch 7, gen_loss = 2.3883243160923633, disc_loss = 0.01651127616266214
Trained batch 127 in epoch 7, gen_loss = 2.3886732878163457, disc_loss = 0.016399749285483267
Trained batch 128 in epoch 7, gen_loss = 2.390007810999257, disc_loss = 0.016289329307890215
Trained batch 129 in epoch 7, gen_loss = 2.3891560710393467, disc_loss = 0.016179255145387008
Trained batch 130 in epoch 7, gen_loss = 2.3881676624749453, disc_loss = 0.016082320341001485
Trained batch 131 in epoch 7, gen_loss = 2.3891974768855353, disc_loss = 0.01597928617918638
Trained batch 132 in epoch 7, gen_loss = 2.388277366645354, disc_loss = 0.01588085566339244
Trained batch 133 in epoch 7, gen_loss = 2.389069979760184, disc_loss = 0.01577494487013501
Trained batch 134 in epoch 7, gen_loss = 2.3905803636268335, disc_loss = 0.015670255230981166
Trained batch 135 in epoch 7, gen_loss = 2.391246293397511, disc_loss = 0.015567410800619708
Trained batch 136 in epoch 7, gen_loss = 2.392476613504173, disc_loss = 0.01547176388337066
Trained batch 137 in epoch 7, gen_loss = 2.394613500090613, disc_loss = 0.015373758954819346
Trained batch 138 in epoch 7, gen_loss = 2.3957498287983077, disc_loss = 0.015280310208607706
Trained batch 139 in epoch 7, gen_loss = 2.3950356134346555, disc_loss = 0.015186642308253794
Trained batch 140 in epoch 7, gen_loss = 2.3915137323081916, disc_loss = 0.015372186170970189
Trained batch 141 in epoch 7, gen_loss = 2.388912683641407, disc_loss = 0.016021591950614582
Trained batch 142 in epoch 7, gen_loss = 2.3876952583139595, disc_loss = 0.015992740896966805
Trained batch 143 in epoch 7, gen_loss = 2.3863153068555727, disc_loss = 0.016191111242126983
Trained batch 144 in epoch 7, gen_loss = 2.387142637680317, disc_loss = 0.016423498696230096
Trained batch 145 in epoch 7, gen_loss = 2.389453300874527, disc_loss = 0.016744243553584465
Trained batch 146 in epoch 7, gen_loss = 2.387885658919406, disc_loss = 0.017415305065802064
Trained batch 147 in epoch 7, gen_loss = 2.3920883173878127, disc_loss = 0.017692419560311513
Trained batch 148 in epoch 7, gen_loss = 2.394636110171376, disc_loss = 0.01777475978397833
Trained batch 149 in epoch 7, gen_loss = 2.3945153323809305, disc_loss = 0.017910192818380893
Trained batch 150 in epoch 7, gen_loss = 2.394072276077523, disc_loss = 0.018120327839529177
Trained batch 151 in epoch 7, gen_loss = 2.395355924963951, disc_loss = 0.018155320999396377
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 2.208862781524658, disc_loss = 0.006783896125853062
Trained batch 1 in epoch 8, gen_loss = 2.431154489517212, disc_loss = 0.006860449444502592
Trained batch 2 in epoch 8, gen_loss = 2.388997793197632, disc_loss = 0.005785149211684863
Trained batch 3 in epoch 8, gen_loss = 2.3630489706993103, disc_loss = 0.005461792694404721
Trained batch 4 in epoch 8, gen_loss = 2.4403433322906496, disc_loss = 0.005283649917691946
Trained batch 5 in epoch 8, gen_loss = 2.4523860613505044, disc_loss = 0.005080721884345015
Trained batch 6 in epoch 8, gen_loss = 2.4778983933585033, disc_loss = 0.004626874712162784
Trained batch 7 in epoch 8, gen_loss = 2.502581298351288, disc_loss = 0.0043682723480742425
Trained batch 8 in epoch 8, gen_loss = 2.5285850630866156, disc_loss = 0.004494243741242422
Trained batch 9 in epoch 8, gen_loss = 2.5332662582397463, disc_loss = 0.0046027405885979535
Trained batch 10 in epoch 8, gen_loss = 2.533584963191639, disc_loss = 0.004368768560446121
Trained batch 11 in epoch 8, gen_loss = 2.536618649959564, disc_loss = 0.004121764640634258
Trained batch 12 in epoch 8, gen_loss = 2.5266174169687123, disc_loss = 0.003935038497170003
Trained batch 13 in epoch 8, gen_loss = 2.543818405696324, disc_loss = 0.0038313291484623085
Trained batch 14 in epoch 8, gen_loss = 2.539701477686564, disc_loss = 0.003745662490837276
Trained batch 15 in epoch 8, gen_loss = 2.5279621183872223, disc_loss = 0.003648390185844619
Trained batch 16 in epoch 8, gen_loss = 2.5199929545907414, disc_loss = 0.0036541703362565708
Trained batch 17 in epoch 8, gen_loss = 2.5360031525293985, disc_loss = 0.003629257611464709
Trained batch 18 in epoch 8, gen_loss = 2.5321888547194633, disc_loss = 0.0035538635351450034
Trained batch 19 in epoch 8, gen_loss = 2.5199628114700316, disc_loss = 0.003562632616376504
Trained batch 20 in epoch 8, gen_loss = 2.5245642775581, disc_loss = 0.003505155793391168
Trained batch 21 in epoch 8, gen_loss = 2.5258306698365645, disc_loss = 0.0034332393446344545
Trained batch 22 in epoch 8, gen_loss = 2.5163996426955513, disc_loss = 0.003379300464471073
Trained batch 23 in epoch 8, gen_loss = 2.5105076928933463, disc_loss = 0.0034027890311942124
Trained batch 24 in epoch 8, gen_loss = 2.5113573265075684, disc_loss = 0.003369156806729734
Trained batch 25 in epoch 8, gen_loss = 2.5048044461470385, disc_loss = 0.0033987511549359905
Trained batch 26 in epoch 8, gen_loss = 2.498092050905581, disc_loss = 0.0034350197443186684
Trained batch 27 in epoch 8, gen_loss = 2.509125300816127, disc_loss = 0.0034709894721994977
Trained batch 28 in epoch 8, gen_loss = 2.5081534714534364, disc_loss = 0.003492106229933942
Trained batch 29 in epoch 8, gen_loss = 2.5013981580734255, disc_loss = 0.0034726230854478977
Trained batch 30 in epoch 8, gen_loss = 2.4974658104681198, disc_loss = 0.0034142147426703766
Trained batch 31 in epoch 8, gen_loss = 2.490817055106163, disc_loss = 0.0036405614846444223
Trained batch 32 in epoch 8, gen_loss = 2.4848425821824507, disc_loss = 0.003899051105801129
Trained batch 33 in epoch 8, gen_loss = 2.481402172761805, disc_loss = 0.003967875453835244
Trained batch 34 in epoch 8, gen_loss = 2.4815301145826067, disc_loss = 0.00402221592209701
Trained batch 35 in epoch 8, gen_loss = 2.475571586026086, disc_loss = 0.003964220057241619
Trained batch 36 in epoch 8, gen_loss = 2.472005264179127, disc_loss = 0.0039025149119363443
Trained batch 37 in epoch 8, gen_loss = 2.4630920698768213, disc_loss = 0.0039307325772058805
Trained batch 38 in epoch 8, gen_loss = 2.4605470376136975, disc_loss = 0.003917097579687834
Trained batch 39 in epoch 8, gen_loss = 2.4532777428627015, disc_loss = 0.00398068631766364
Trained batch 40 in epoch 8, gen_loss = 2.448516095556864, disc_loss = 0.004007252387520744
Trained batch 41 in epoch 8, gen_loss = 2.4472595112664357, disc_loss = 0.0039563915758792844
Trained batch 42 in epoch 8, gen_loss = 2.442398642384729, disc_loss = 0.003933073860744751
Trained batch 43 in epoch 8, gen_loss = 2.4419042576443064, disc_loss = 0.0039105300992642615
Trained batch 44 in epoch 8, gen_loss = 2.441113085216946, disc_loss = 0.003896044230916434
Trained batch 45 in epoch 8, gen_loss = 2.444673460462819, disc_loss = 0.0038572578012700314
Trained batch 46 in epoch 8, gen_loss = 2.4463853328785996, disc_loss = 0.003907203590101067
Trained batch 47 in epoch 8, gen_loss = 2.4433694034814835, disc_loss = 0.003917844708970127
Trained batch 48 in epoch 8, gen_loss = 2.447040100486911, disc_loss = 0.004100009832265121
Trained batch 49 in epoch 8, gen_loss = 2.4470664167404177, disc_loss = 0.004344243514351547
Trained batch 50 in epoch 8, gen_loss = 2.450748803568821, disc_loss = 0.0048077941698697856
Trained batch 51 in epoch 8, gen_loss = 2.4483969119878917, disc_loss = 0.004822109418455511
Trained batch 52 in epoch 8, gen_loss = 2.445571332607629, disc_loss = 0.004848337771792738
Trained batch 53 in epoch 8, gen_loss = 2.4530058172014026, disc_loss = 0.004807366243632579
Trained batch 54 in epoch 8, gen_loss = 2.4500464352694427, disc_loss = 0.0047698943071406
Trained batch 55 in epoch 8, gen_loss = 2.4531809048993245, disc_loss = 0.004710152753562268
Trained batch 56 in epoch 8, gen_loss = 2.4525126197881866, disc_loss = 0.00466418583272842
Trained batch 57 in epoch 8, gen_loss = 2.457016743462661, disc_loss = 0.004614161476011163
Trained batch 58 in epoch 8, gen_loss = 2.454449362674002, disc_loss = 0.004562059255569416
Trained batch 59 in epoch 8, gen_loss = 2.455266845226288, disc_loss = 0.0045050513561970245
Trained batch 60 in epoch 8, gen_loss = 2.455146207184088, disc_loss = 0.004461069667681319
Trained batch 61 in epoch 8, gen_loss = 2.4529405640017603, disc_loss = 0.004432763172043187
Trained batch 62 in epoch 8, gen_loss = 2.4483744984581355, disc_loss = 0.00438766275340366
Trained batch 63 in epoch 8, gen_loss = 2.4471242502331734, disc_loss = 0.004349894115875941
Trained batch 64 in epoch 8, gen_loss = 2.453018298515907, disc_loss = 0.004299692055568672
Trained batch 65 in epoch 8, gen_loss = 2.4482216871146, disc_loss = 0.004267890801808487
Trained batch 66 in epoch 8, gen_loss = 2.4473617041288915, disc_loss = 0.004230775913821339
Trained batch 67 in epoch 8, gen_loss = 2.4459338118048275, disc_loss = 0.004205415119512883
Trained batch 68 in epoch 8, gen_loss = 2.445628335510475, disc_loss = 0.00419229831026894
Trained batch 69 in epoch 8, gen_loss = 2.4431654351098198, disc_loss = 0.0041590143859918625
Trained batch 70 in epoch 8, gen_loss = 2.4438445030803413, disc_loss = 0.004136334186498548
Trained batch 71 in epoch 8, gen_loss = 2.4439743194315167, disc_loss = 0.004094685511922257
Trained batch 72 in epoch 8, gen_loss = 2.4467990855648094, disc_loss = 0.004061408588114156
Trained batch 73 in epoch 8, gen_loss = 2.4420046161960913, disc_loss = 0.0040294665236000875
Trained batch 74 in epoch 8, gen_loss = 2.440282201766968, disc_loss = 0.003994485566702982
Trained batch 75 in epoch 8, gen_loss = 2.4406406565716394, disc_loss = 0.003989138617486644
Trained batch 76 in epoch 8, gen_loss = 2.44043087649655, disc_loss = 0.003957138008244529
Trained batch 77 in epoch 8, gen_loss = 2.439098141132257, disc_loss = 0.003937128535770358
Trained batch 78 in epoch 8, gen_loss = 2.4379374467873873, disc_loss = 0.0039001966169386914
Trained batch 79 in epoch 8, gen_loss = 2.435397121310234, disc_loss = 0.0038851641278597527
Trained batch 80 in epoch 8, gen_loss = 2.4363936730373053, disc_loss = 0.00386827499864416
Trained batch 81 in epoch 8, gen_loss = 2.4370836339345794, disc_loss = 0.003843656457142859
Trained batch 82 in epoch 8, gen_loss = 2.433889098914273, disc_loss = 0.003812632714229894
Trained batch 83 in epoch 8, gen_loss = 2.432744386650267, disc_loss = 0.0037792680765657374
Trained batch 84 in epoch 8, gen_loss = 2.433432497697718, disc_loss = 0.0037511737551540135
Trained batch 85 in epoch 8, gen_loss = 2.43575535541357, disc_loss = 0.003721508414073046
Trained batch 86 in epoch 8, gen_loss = 2.435862683701789, disc_loss = 0.003688923219732683
Trained batch 87 in epoch 8, gen_loss = 2.4388872655955227, disc_loss = 0.0036603904895442115
Trained batch 88 in epoch 8, gen_loss = 2.437736720181583, disc_loss = 0.003639214244420023
Trained batch 89 in epoch 8, gen_loss = 2.436836618847317, disc_loss = 0.003617987153120339
Trained batch 90 in epoch 8, gen_loss = 2.438613778942234, disc_loss = 0.0035938925089335047
Trained batch 91 in epoch 8, gen_loss = 2.438791793325673, disc_loss = 0.0035672316570644793
Trained batch 92 in epoch 8, gen_loss = 2.4357541504726616, disc_loss = 0.0035529740064615205
Trained batch 93 in epoch 8, gen_loss = 2.4336569968690265, disc_loss = 0.003545879086657883
Trained batch 94 in epoch 8, gen_loss = 2.4306492880771033, disc_loss = 0.003573939917413028
Trained batch 95 in epoch 8, gen_loss = 2.4312952359517417, disc_loss = 0.003558512224117294
Trained batch 96 in epoch 8, gen_loss = 2.4288135607218004, disc_loss = 0.00355797666653069
Trained batch 97 in epoch 8, gen_loss = 2.4304225542107405, disc_loss = 0.0035409786244284132
Trained batch 98 in epoch 8, gen_loss = 2.433376914322978, disc_loss = 0.003523048773088088
Trained batch 99 in epoch 8, gen_loss = 2.4301970648765563, disc_loss = 0.0035022217710502447
Trained batch 100 in epoch 8, gen_loss = 2.429413849764531, disc_loss = 0.0034848140854628223
Trained batch 101 in epoch 8, gen_loss = 2.4299635022294286, disc_loss = 0.0034671039035196836
Trained batch 102 in epoch 8, gen_loss = 2.4292109984796024, disc_loss = 0.00345426208217565
Trained batch 103 in epoch 8, gen_loss = 2.4273625956131863, disc_loss = 0.0034316444082203535
Trained batch 104 in epoch 8, gen_loss = 2.428207306634812, disc_loss = 0.0034079055967075485
Trained batch 105 in epoch 8, gen_loss = 2.4276674693485476, disc_loss = 0.003391311042678525
Trained batch 106 in epoch 8, gen_loss = 2.427045144767405, disc_loss = 0.003371116470232188
Trained batch 107 in epoch 8, gen_loss = 2.4297126023857682, disc_loss = 0.003359912952873856
Trained batch 108 in epoch 8, gen_loss = 2.4276010705790387, disc_loss = 0.003342200726390295
Trained batch 109 in epoch 8, gen_loss = 2.429812344637784, disc_loss = 0.0033208651214160704
Trained batch 110 in epoch 8, gen_loss = 2.425798526755324, disc_loss = 0.003301352838280837
Trained batch 111 in epoch 8, gen_loss = 2.42853366370712, disc_loss = 0.0032811927095670918
Trained batch 112 in epoch 8, gen_loss = 2.426740223327569, disc_loss = 0.0032737223581880727
Trained batch 113 in epoch 8, gen_loss = 2.428491545350928, disc_loss = 0.003266776892511795
Trained batch 114 in epoch 8, gen_loss = 2.4265514010968414, disc_loss = 0.0032550247568313194
Trained batch 115 in epoch 8, gen_loss = 2.4283072568219284, disc_loss = 0.0032374088879241125
Trained batch 116 in epoch 8, gen_loss = 2.42660690474714, disc_loss = 0.003226271914079403
Trained batch 117 in epoch 8, gen_loss = 2.4257641677129067, disc_loss = 0.0032082123512212754
Trained batch 118 in epoch 8, gen_loss = 2.422359972440896, disc_loss = 0.0031972869021520646
Trained batch 119 in epoch 8, gen_loss = 2.4232295046250028, disc_loss = 0.0031792228081030773
Trained batch 120 in epoch 8, gen_loss = 2.422236260303781, disc_loss = 0.0031646802272909313
Trained batch 121 in epoch 8, gen_loss = 2.4187495776864347, disc_loss = 0.0031603606614345288
Trained batch 122 in epoch 8, gen_loss = 2.419588107403701, disc_loss = 0.003151841865799473
Trained batch 123 in epoch 8, gen_loss = 2.4191421664530233, disc_loss = 0.0031477816171959164
Trained batch 124 in epoch 8, gen_loss = 2.4191568746566774, disc_loss = 0.003139742841012776
Trained batch 125 in epoch 8, gen_loss = 2.4187317812253557, disc_loss = 0.0031287791216672058
Trained batch 126 in epoch 8, gen_loss = 2.4190971166130124, disc_loss = 0.003115587443384657
Trained batch 127 in epoch 8, gen_loss = 2.416531235910952, disc_loss = 0.003100991321844049
Trained batch 128 in epoch 8, gen_loss = 2.41715675453807, disc_loss = 0.0030838312629011076
Trained batch 129 in epoch 8, gen_loss = 2.417255118260017, disc_loss = 0.0030671991555629155
Trained batch 130 in epoch 8, gen_loss = 2.416970437719622, disc_loss = 0.003049120374507349
Trained batch 131 in epoch 8, gen_loss = 2.4168431930469745, disc_loss = 0.0030360242059087436
Trained batch 132 in epoch 8, gen_loss = 2.4198834008740304, disc_loss = 0.0030184975060235176
Trained batch 133 in epoch 8, gen_loss = 2.422881613026804, disc_loss = 0.0030062750265099553
Trained batch 134 in epoch 8, gen_loss = 2.4238567255161425, disc_loss = 0.002989995564954976
Trained batch 135 in epoch 8, gen_loss = 2.4237181114799835, disc_loss = 0.0029734620338251047
Trained batch 136 in epoch 8, gen_loss = 2.4234695599897065, disc_loss = 0.002960918126219924
Trained batch 137 in epoch 8, gen_loss = 2.4242635300194006, disc_loss = 0.002945891667521842
Trained batch 138 in epoch 8, gen_loss = 2.4240754499709865, disc_loss = 0.0029343496874082004
Trained batch 139 in epoch 8, gen_loss = 2.4236835709639957, disc_loss = 0.0029241709803630197
Trained batch 140 in epoch 8, gen_loss = 2.423322673385025, disc_loss = 0.002908669762620504
Trained batch 141 in epoch 8, gen_loss = 2.4251608168575127, disc_loss = 0.0028982108879447455
Trained batch 142 in epoch 8, gen_loss = 2.4231906379019463, disc_loss = 0.002888010472459784
Trained batch 143 in epoch 8, gen_loss = 2.4241506366266146, disc_loss = 0.002880048408971763
Trained batch 144 in epoch 8, gen_loss = 2.4240418606791003, disc_loss = 0.002868782151249591
Trained batch 145 in epoch 8, gen_loss = 2.4224981714601386, disc_loss = 0.002859533476971779
Trained batch 146 in epoch 8, gen_loss = 2.4207597484393997, disc_loss = 0.0028455755772341523
Trained batch 147 in epoch 8, gen_loss = 2.421310659195926, disc_loss = 0.002832806924424084
Trained batch 148 in epoch 8, gen_loss = 2.4220618265587213, disc_loss = 0.0028198914756317117
Trained batch 149 in epoch 8, gen_loss = 2.4195059037208555, disc_loss = 0.0028101032805473852
Trained batch 150 in epoch 8, gen_loss = 2.4180108119320396, disc_loss = 0.0028050772044715157
Trained batch 151 in epoch 8, gen_loss = 2.4155465811491013, disc_loss = 0.0028033399832661657
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 2.0307490825653076, disc_loss = 0.0023077514488250017
Trained batch 1 in epoch 9, gen_loss = 2.099373698234558, disc_loss = 0.0019522889633662999
Trained batch 2 in epoch 9, gen_loss = 2.1795034408569336, disc_loss = 0.001693169237114489
Trained batch 3 in epoch 9, gen_loss = 2.255078136920929, disc_loss = 0.0014733902353327721
Trained batch 4 in epoch 9, gen_loss = 2.2796512126922606, disc_loss = 0.0014035556465387343
Trained batch 5 in epoch 9, gen_loss = 2.269504110018412, disc_loss = 0.0012978745119956632
Trained batch 6 in epoch 9, gen_loss = 2.2616586685180664, disc_loss = 0.0013255187077447772
Trained batch 7 in epoch 9, gen_loss = 2.256647378206253, disc_loss = 0.0013595622876891866
Trained batch 8 in epoch 9, gen_loss = 2.282593700620863, disc_loss = 0.0013710415223613381
Trained batch 9 in epoch 9, gen_loss = 2.2579272031784057, disc_loss = 0.0013205270399339498
Trained batch 10 in epoch 9, gen_loss = 2.2526374513452705, disc_loss = 0.0012941575206985528
Trained batch 11 in epoch 9, gen_loss = 2.265957216421763, disc_loss = 0.0012614559576225777
Trained batch 12 in epoch 9, gen_loss = 2.253679037094116, disc_loss = 0.0012218285432586877
Trained batch 13 in epoch 9, gen_loss = 2.2528789724622453, disc_loss = 0.001201699034676754
Trained batch 14 in epoch 9, gen_loss = 2.2637595812479656, disc_loss = 0.0011904848700699706
Trained batch 15 in epoch 9, gen_loss = 2.2719926685094833, disc_loss = 0.0011872757277160417
Trained batch 16 in epoch 9, gen_loss = 2.288719555910896, disc_loss = 0.00117820587269414
Trained batch 17 in epoch 9, gen_loss = 2.285346176889208, disc_loss = 0.0011854138283524662
Trained batch 18 in epoch 9, gen_loss = 2.31101215513129, disc_loss = 0.0012296482485620991
Trained batch 19 in epoch 9, gen_loss = 2.303699791431427, disc_loss = 0.001258054407662712
Trained batch 20 in epoch 9, gen_loss = 2.3073416437421526, disc_loss = 0.0012428846093825996
Trained batch 21 in epoch 9, gen_loss = 2.3086311383680864, disc_loss = 0.001224577466597442
Trained batch 22 in epoch 9, gen_loss = 2.307331779728765, disc_loss = 0.0012174524017609656
Trained batch 23 in epoch 9, gen_loss = 2.3008250494798026, disc_loss = 0.001214620072763258
Trained batch 24 in epoch 9, gen_loss = 2.3031172275543215, disc_loss = 0.0012050644005648793
Trained batch 25 in epoch 9, gen_loss = 2.3073555322793813, disc_loss = 0.0011900913109107374
Trained batch 26 in epoch 9, gen_loss = 2.3276392618815103, disc_loss = 0.001191653024525968
Trained batch 27 in epoch 9, gen_loss = 2.3342210224696567, disc_loss = 0.0011773543893858524
Trained batch 28 in epoch 9, gen_loss = 2.3318949156794053, disc_loss = 0.0011727428565540448
Trained batch 29 in epoch 9, gen_loss = 2.3335846106211346, disc_loss = 0.0011676928823969015
Trained batch 30 in epoch 9, gen_loss = 2.3297496149616856, disc_loss = 0.0011583100384732167
Trained batch 31 in epoch 9, gen_loss = 2.328037679195404, disc_loss = 0.0011408696100261295
Trained batch 32 in epoch 9, gen_loss = 2.331194429686575, disc_loss = 0.0011239135637879372
Trained batch 33 in epoch 9, gen_loss = 2.325927257537842, disc_loss = 0.0011100538883029537
Trained batch 34 in epoch 9, gen_loss = 2.3384919915880475, disc_loss = 0.0011214055154206498
Trained batch 35 in epoch 9, gen_loss = 2.3396321998702154, disc_loss = 0.0011133997726978527
Trained batch 36 in epoch 9, gen_loss = 2.334737745491234, disc_loss = 0.0011178483884479549
Trained batch 37 in epoch 9, gen_loss = 2.3294454938487004, disc_loss = 0.0011213902770051438
Trained batch 38 in epoch 9, gen_loss = 2.329154466971373, disc_loss = 0.0011153660314635206
Trained batch 39 in epoch 9, gen_loss = 2.3292214274406433, disc_loss = 0.0011081329168519006
Trained batch 40 in epoch 9, gen_loss = 2.333462645367878, disc_loss = 0.0011071813968578127
Trained batch 41 in epoch 9, gen_loss = 2.334506528718131, disc_loss = 0.0011125128616445831
Trained batch 42 in epoch 9, gen_loss = 2.3429654919823935, disc_loss = 0.0011119389944428274
Trained batch 43 in epoch 9, gen_loss = 2.3367652242833916, disc_loss = 0.001108740257967094
Trained batch 44 in epoch 9, gen_loss = 2.340680895911323, disc_loss = 0.001109872070244617
Trained batch 45 in epoch 9, gen_loss = 2.3296085596084595, disc_loss = 0.001123440707527587
Trained batch 46 in epoch 9, gen_loss = 2.3333598958685045, disc_loss = 0.0011327949530900792
Trained batch 47 in epoch 9, gen_loss = 2.338763232032458, disc_loss = 0.0011230375797216159
Trained batch 48 in epoch 9, gen_loss = 2.337314547324667, disc_loss = 0.0011308068357294007
Trained batch 49 in epoch 9, gen_loss = 2.3388812828063963, disc_loss = 0.0011370950867421925
Trained batch 50 in epoch 9, gen_loss = 2.3384436065075445, disc_loss = 0.001125883958165479
Trained batch 51 in epoch 9, gen_loss = 2.330229809651008, disc_loss = 0.00115399405946776
Trained batch 52 in epoch 9, gen_loss = 2.333650377561461, disc_loss = 0.001156718069292113
Trained batch 53 in epoch 9, gen_loss = 2.340654351093151, disc_loss = 0.0011553316262843847
Trained batch 54 in epoch 9, gen_loss = 2.332621528885581, disc_loss = 0.00115213843210685
Trained batch 55 in epoch 9, gen_loss = 2.331787183880806, disc_loss = 0.0011492639927642553
Trained batch 56 in epoch 9, gen_loss = 2.330128943710996, disc_loss = 0.0011650427569341111
Trained batch 57 in epoch 9, gen_loss = 2.3313868066360213, disc_loss = 0.0011593053691442414
Trained batch 58 in epoch 9, gen_loss = 2.3356891910908586, disc_loss = 0.001151506765350952
Trained batch 59 in epoch 9, gen_loss = 2.337536948919296, disc_loss = 0.0011420383855390052
Trained batch 60 in epoch 9, gen_loss = 2.3348728340180194, disc_loss = 0.0011371372450814873
Trained batch 61 in epoch 9, gen_loss = 2.332050202354308, disc_loss = 0.0011305056668202123
Trained batch 62 in epoch 9, gen_loss = 2.3349949197163657, disc_loss = 0.0011270865677885475
Trained batch 63 in epoch 9, gen_loss = 2.333198508247733, disc_loss = 0.0011190211080247536
Trained batch 64 in epoch 9, gen_loss = 2.3369735919512236, disc_loss = 0.0011130695643190008
Trained batch 65 in epoch 9, gen_loss = 2.3391453118035286, disc_loss = 0.0011061738134065474
Trained batch 66 in epoch 9, gen_loss = 2.3383400173329596, disc_loss = 0.0011005368467712246
Trained batch 67 in epoch 9, gen_loss = 2.3381002492764416, disc_loss = 0.0010991230981958592
Trained batch 68 in epoch 9, gen_loss = 2.33731006021085, disc_loss = 0.0010940994910450409
Trained batch 69 in epoch 9, gen_loss = 2.335032594203949, disc_loss = 0.0010872099573524402
Trained batch 70 in epoch 9, gen_loss = 2.336169963151636, disc_loss = 0.0010846969335418667
Trained batch 71 in epoch 9, gen_loss = 2.3337123145659766, disc_loss = 0.0010805555818175587
Trained batch 72 in epoch 9, gen_loss = 2.3307909753224623, disc_loss = 0.0010749303085142619
Trained batch 73 in epoch 9, gen_loss = 2.326557563768851, disc_loss = 0.0010807244280176993
Trained batch 74 in epoch 9, gen_loss = 2.3265791527430215, disc_loss = 0.0010832710641746719
Trained batch 75 in epoch 9, gen_loss = 2.329225143319682, disc_loss = 0.0010815974812047851
Trained batch 76 in epoch 9, gen_loss = 2.332330621682204, disc_loss = 0.0010773873367866912
Trained batch 77 in epoch 9, gen_loss = 2.330383525444911, disc_loss = 0.0010786053623096682
Trained batch 78 in epoch 9, gen_loss = 2.3320524164392977, disc_loss = 0.0010764649111329567
Trained batch 79 in epoch 9, gen_loss = 2.3301687851548194, disc_loss = 0.0010732621944043786
Trained batch 80 in epoch 9, gen_loss = 2.328577396310406, disc_loss = 0.00107715679993738
Trained batch 81 in epoch 9, gen_loss = 2.3277238273039096, disc_loss = 0.0010745240312932832
Trained batch 82 in epoch 9, gen_loss = 2.3297098300543175, disc_loss = 0.001075605307817908
Trained batch 83 in epoch 9, gen_loss = 2.331407054549172, disc_loss = 0.001074012422967436
Trained batch 84 in epoch 9, gen_loss = 2.3305471602608177, disc_loss = 0.0010686986278468633
Trained batch 85 in epoch 9, gen_loss = 2.3313051836435186, disc_loss = 0.0010645726728144773
Trained batch 86 in epoch 9, gen_loss = 2.3315405092020143, disc_loss = 0.001061261003307099
Trained batch 87 in epoch 9, gen_loss = 2.3318601860241457, disc_loss = 0.0010600132604436526
Trained batch 88 in epoch 9, gen_loss = 2.330037479989984, disc_loss = 0.001054540156187971
Trained batch 89 in epoch 9, gen_loss = 2.327262704902225, disc_loss = 0.0010538907087821927
Trained batch 90 in epoch 9, gen_loss = 2.326800132845784, disc_loss = 0.0010599322990606447
Trained batch 91 in epoch 9, gen_loss = 2.3329473695029384, disc_loss = 0.0010662365277075087
Trained batch 92 in epoch 9, gen_loss = 2.3336411560735395, disc_loss = 0.001065609710020644
Trained batch 93 in epoch 9, gen_loss = 2.334404155294946, disc_loss = 0.0010652831109101944
Trained batch 94 in epoch 9, gen_loss = 2.3316626636605515, disc_loss = 0.001070413749517971
Trained batch 95 in epoch 9, gen_loss = 2.3310190799335637, disc_loss = 0.0010667553833627608
Trained batch 96 in epoch 9, gen_loss = 2.329229882082988, disc_loss = 0.0010623037449045817
Trained batch 97 in epoch 9, gen_loss = 2.3306913728616676, disc_loss = 0.001057275971849164
Trained batch 98 in epoch 9, gen_loss = 2.330320894116103, disc_loss = 0.0010536100257968887
Trained batch 99 in epoch 9, gen_loss = 2.3294951236248016, disc_loss = 0.0010553107521263884
Trained batch 100 in epoch 9, gen_loss = 2.3298133729708077, disc_loss = 0.0010625817634322043
Trained batch 101 in epoch 9, gen_loss = 2.3301495021464778, disc_loss = 0.0010652377768921868
Trained batch 102 in epoch 9, gen_loss = 2.330342905035297, disc_loss = 0.0010648654288955902
Trained batch 103 in epoch 9, gen_loss = 2.328427792741702, disc_loss = 0.0010616017696940196
Trained batch 104 in epoch 9, gen_loss = 2.3274673200788953, disc_loss = 0.0010602066498471513
Trained batch 105 in epoch 9, gen_loss = 2.3327138660089024, disc_loss = 0.0010633438892601022
Trained batch 106 in epoch 9, gen_loss = 2.3340234901303445, disc_loss = 0.0010592488470818047
Trained batch 107 in epoch 9, gen_loss = 2.3361207059136144, disc_loss = 0.0010569594758433392
Trained batch 108 in epoch 9, gen_loss = 2.3378574312280076, disc_loss = 0.0010577189461584416
Trained batch 109 in epoch 9, gen_loss = 2.3378743182529105, disc_loss = 0.0010541912988463248
Trained batch 110 in epoch 9, gen_loss = 2.3387831535425274, disc_loss = 0.0010516837287509629
Trained batch 111 in epoch 9, gen_loss = 2.3394071896161353, disc_loss = 0.0010493186709936708
Trained batch 112 in epoch 9, gen_loss = 2.3381565155181208, disc_loss = 0.0010450914768971899
Trained batch 113 in epoch 9, gen_loss = 2.338476807401891, disc_loss = 0.0010420078572024706
Trained batch 114 in epoch 9, gen_loss = 2.34057833733766, disc_loss = 0.0010390856136243951
Trained batch 115 in epoch 9, gen_loss = 2.340349249798676, disc_loss = 0.0010358153763106734
Trained batch 116 in epoch 9, gen_loss = 2.343976027945168, disc_loss = 0.0010322504472902888
Trained batch 117 in epoch 9, gen_loss = 2.3434161745895774, disc_loss = 0.001029011759397937
Trained batch 118 in epoch 9, gen_loss = 2.346017155326715, disc_loss = 0.0010272466167690186
Trained batch 119 in epoch 9, gen_loss = 2.344002561767896, disc_loss = 0.001034269628871698
Trained batch 120 in epoch 9, gen_loss = 2.3446107787534225, disc_loss = 0.0010317584296711528
Trained batch 121 in epoch 9, gen_loss = 2.342685528465959, disc_loss = 0.0010354837615493319
Trained batch 122 in epoch 9, gen_loss = 2.3429492808938996, disc_loss = 0.0010350606100429304
Trained batch 123 in epoch 9, gen_loss = 2.3436141158303907, disc_loss = 0.0010330442648058037
Trained batch 124 in epoch 9, gen_loss = 2.3435116415023804, disc_loss = 0.0010319726918824018
Trained batch 125 in epoch 9, gen_loss = 2.343315063014863, disc_loss = 0.001028409019382375
Trained batch 126 in epoch 9, gen_loss = 2.3412564974131547, disc_loss = 0.0010284325112515371
Trained batch 127 in epoch 9, gen_loss = 2.3393055638298392, disc_loss = 0.0010269151375723595
Trained batch 128 in epoch 9, gen_loss = 2.338817042897838, disc_loss = 0.0010251097273724081
Trained batch 129 in epoch 9, gen_loss = 2.3371536630850573, disc_loss = 0.0010279920458113058
Trained batch 130 in epoch 9, gen_loss = 2.3371874603606364, disc_loss = 0.0010265483185897745
Trained batch 131 in epoch 9, gen_loss = 2.3370628131158426, disc_loss = 0.0010240278793251932
Trained batch 132 in epoch 9, gen_loss = 2.3376488569087552, disc_loss = 0.0010221312859767866
Trained batch 133 in epoch 9, gen_loss = 2.3371350613992607, disc_loss = 0.001018224970381985
Trained batch 134 in epoch 9, gen_loss = 2.339132127938447, disc_loss = 0.0010146399632234265
Trained batch 135 in epoch 9, gen_loss = 2.3425371953669716, disc_loss = 0.0010116761807105778
Trained batch 136 in epoch 9, gen_loss = 2.33930054894329, disc_loss = 0.0010123902432158263
Trained batch 137 in epoch 9, gen_loss = 2.339862961699997, disc_loss = 0.001009761801654257
Trained batch 138 in epoch 9, gen_loss = 2.339876344735674, disc_loss = 0.0010066519750168265
Trained batch 139 in epoch 9, gen_loss = 2.340615027291434, disc_loss = 0.0010039605395702113
Trained batch 140 in epoch 9, gen_loss = 2.3409228105071587, disc_loss = 0.001001188929063922
Trained batch 141 in epoch 9, gen_loss = 2.342429950203694, disc_loss = 0.0009982661933566012
Trained batch 142 in epoch 9, gen_loss = 2.3436865056311333, disc_loss = 0.0009955139382957267
Trained batch 143 in epoch 9, gen_loss = 2.3440472135941186, disc_loss = 0.000994451591395773
Trained batch 144 in epoch 9, gen_loss = 2.341750064389459, disc_loss = 0.0009935082534552905
Trained batch 145 in epoch 9, gen_loss = 2.340520285580256, disc_loss = 0.0009971600466835223
Trained batch 146 in epoch 9, gen_loss = 2.340228242939021, disc_loss = 0.0009993175452505396
Trained batch 147 in epoch 9, gen_loss = 2.339068274240236, disc_loss = 0.000997367237908514
Trained batch 148 in epoch 9, gen_loss = 2.336366555834777, disc_loss = 0.0009998483755219504
Trained batch 149 in epoch 9, gen_loss = 2.33533505598704, disc_loss = 0.0009991798569293072
Trained batch 150 in epoch 9, gen_loss = 2.3331361022216597, disc_loss = 0.0009987819323081844
Trained batch 151 in epoch 9, gen_loss = 2.3328019741334414, disc_loss = 0.0009980591260644264
Testing Epoch 9
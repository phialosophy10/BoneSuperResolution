/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 2.578169107437134, disc_loss = 0.5264127254486084
Trained batch 1 in epoch 0, gen_loss = 2.6478124856948853, disc_loss = 1.2255361080169678
Trained batch 2 in epoch 0, gen_loss = 2.644721746444702, disc_loss = 0.9605011145273844
Trained batch 3 in epoch 0, gen_loss = 2.6834364533424377, disc_loss = 0.8427646309137344
Trained batch 4 in epoch 0, gen_loss = 2.635419416427612, disc_loss = 0.7447664022445679
Trained batch 5 in epoch 0, gen_loss = 2.5791353782018027, disc_loss = 0.6774856050809225
Trained batch 6 in epoch 0, gen_loss = 2.520152841295515, disc_loss = 0.6231847149985177
Trained batch 7 in epoch 0, gen_loss = 2.5084128677845, disc_loss = 0.5782560519874096
Trained batch 8 in epoch 0, gen_loss = 2.477382686403063, disc_loss = 0.5403257343504164
Trained batch 9 in epoch 0, gen_loss = 2.462806463241577, disc_loss = 0.5064985603094101
Trained batch 10 in epoch 0, gen_loss = 2.473089261488481, disc_loss = 0.47802718661048194
Trained batch 11 in epoch 0, gen_loss = 2.440607786178589, disc_loss = 0.45207133889198303
Trained batch 12 in epoch 0, gen_loss = 2.446010974737314, disc_loss = 0.42920531447117144
Trained batch 13 in epoch 0, gen_loss = 2.4289627415793285, disc_loss = 0.408125248338495
Trained batch 14 in epoch 0, gen_loss = 2.4105886618296304, disc_loss = 0.38895742694536845
Trained batch 15 in epoch 0, gen_loss = 2.393122285604477, disc_loss = 0.3727241773158312
Trained batch 16 in epoch 0, gen_loss = 2.4026102598975685, disc_loss = 0.3571537684868364
Trained batch 17 in epoch 0, gen_loss = 2.401293502913581, disc_loss = 0.34367810148331857
Trained batch 18 in epoch 0, gen_loss = 2.3938532503027665, disc_loss = 0.33124727677357824
Trained batch 19 in epoch 0, gen_loss = 2.4041155695915224, disc_loss = 0.3204011287540197
Trained batch 20 in epoch 0, gen_loss = 2.402723255611601, disc_loss = 0.31023581361486796
Trained batch 21 in epoch 0, gen_loss = 2.4290538267655806, disc_loss = 0.3010433353483677
Trained batch 22 in epoch 0, gen_loss = 2.4437513558760933, disc_loss = 0.2922195471499277
Trained batch 23 in epoch 0, gen_loss = 2.431733081738154, disc_loss = 0.2853003619238734
Trained batch 24 in epoch 0, gen_loss = 2.4418708801269533, disc_loss = 0.2805622234940529
Trained batch 25 in epoch 0, gen_loss = 2.439682822961074, disc_loss = 0.27571456449536175
Trained batch 26 in epoch 0, gen_loss = 2.4515641177142107, disc_loss = 0.26925058828459847
Trained batch 27 in epoch 0, gen_loss = 2.439135789871216, disc_loss = 0.26292836346796583
Trained batch 28 in epoch 0, gen_loss = 2.4323863243234567, disc_loss = 0.25651159214562386
Trained batch 29 in epoch 0, gen_loss = 2.4332103808720906, disc_loss = 0.2501552854975065
Trained batch 30 in epoch 0, gen_loss = 2.42315165458187, disc_loss = 0.24427153122040532
Trained batch 31 in epoch 0, gen_loss = 2.4148459658026695, disc_loss = 0.23978977580554783
Trained batch 32 in epoch 0, gen_loss = 2.423428130872322, disc_loss = 0.23529076598810428
Trained batch 33 in epoch 0, gen_loss = 2.4338003046372356, disc_loss = 0.23154836914995136
Trained batch 34 in epoch 0, gen_loss = 2.4345416000911166, disc_loss = 0.23252821415662767
Trained batch 35 in epoch 0, gen_loss = 2.4391998714870877, disc_loss = 0.23880617092880937
Trained batch 36 in epoch 0, gen_loss = 2.439852508338722, disc_loss = 0.24091978431553454
Trained batch 37 in epoch 0, gen_loss = 2.445086454090319, disc_loss = 0.23869896699723445
Trained batch 38 in epoch 0, gen_loss = 2.4404856058267446, disc_loss = 0.23487388151578414
Trained batch 39 in epoch 0, gen_loss = 2.44117448925972, disc_loss = 0.2307925818488002
Trained batch 40 in epoch 0, gen_loss = 2.4345437084756245, disc_loss = 0.2273081370243212
Trained batch 41 in epoch 0, gen_loss = 2.4323460261027017, disc_loss = 0.22323104632752283
Trained batch 42 in epoch 0, gen_loss = 2.4266048808430516, disc_loss = 0.21956557884465816
Trained batch 43 in epoch 0, gen_loss = 2.4216961698098616, disc_loss = 0.21612568301233379
Trained batch 44 in epoch 0, gen_loss = 2.42707789738973, disc_loss = 0.2123181629512045
Trained batch 45 in epoch 0, gen_loss = 2.4326230598532637, disc_loss = 0.2088122178354989
Trained batch 46 in epoch 0, gen_loss = 2.4308505210470646, disc_loss = 0.20554752394239953
Trained batch 47 in epoch 0, gen_loss = 2.429542526602745, disc_loss = 0.20225060738933584
Trained batch 48 in epoch 0, gen_loss = 2.4292986490288557, disc_loss = 0.1988052877084333
Trained batch 49 in epoch 0, gen_loss = 2.425945448875427, disc_loss = 0.19570560336112977
Trained batch 50 in epoch 0, gen_loss = 2.423476111655142, disc_loss = 0.1925495326080743
Trained batch 51 in epoch 0, gen_loss = 2.4257458677658668, disc_loss = 0.18946555794145054
Trained batch 52 in epoch 0, gen_loss = 2.4202719499480048, disc_loss = 0.18658869938468034
Trained batch 53 in epoch 0, gen_loss = 2.4163401744983815, disc_loss = 0.18386376787115027
Trained batch 54 in epoch 0, gen_loss = 2.412574716047807, disc_loss = 0.18127118714831092
Trained batch 55 in epoch 0, gen_loss = 2.4106906141553606, disc_loss = 0.1787145795699741
Trained batch 56 in epoch 0, gen_loss = 2.4179506803813733, disc_loss = 0.17610635036569938
Trained batch 57 in epoch 0, gen_loss = 2.4133250096748613, disc_loss = 0.1735854407387047
Trained batch 58 in epoch 0, gen_loss = 2.420753208257384, disc_loss = 0.17113381652635032
Trained batch 59 in epoch 0, gen_loss = 2.4193950295448303, disc_loss = 0.16893925688539943
Trained batch 60 in epoch 0, gen_loss = 2.423706148491531, disc_loss = 0.1668641848459107
Trained batch 61 in epoch 0, gen_loss = 2.4234374953854467, disc_loss = 0.1651074829541387
Trained batch 62 in epoch 0, gen_loss = 2.424595068371485, disc_loss = 0.16329686447150177
Trained batch 63 in epoch 0, gen_loss = 2.4240496195852757, disc_loss = 0.1613721226749476
Trained batch 64 in epoch 0, gen_loss = 2.4308381960942196, disc_loss = 0.15925261896963303
Trained batch 65 in epoch 0, gen_loss = 2.429717085578225, disc_loss = 0.1573932986198501
Trained batch 66 in epoch 0, gen_loss = 2.428531401192964, disc_loss = 0.15562257818432887
Trained batch 67 in epoch 0, gen_loss = 2.4273866485146915, disc_loss = 0.15396738011280403
Trained batch 68 in epoch 0, gen_loss = 2.4259643623794336, disc_loss = 0.1523266877655102
Trained batch 69 in epoch 0, gen_loss = 2.431007395471845, disc_loss = 0.1509326573195202
Trained batch 70 in epoch 0, gen_loss = 2.429441881851411, disc_loss = 0.14944187953123744
Trained batch 71 in epoch 0, gen_loss = 2.427846093972524, disc_loss = 0.1478266936675128
Trained batch 72 in epoch 0, gen_loss = 2.425127790398794, disc_loss = 0.14627249214849244
Trained batch 73 in epoch 0, gen_loss = 2.4240948155119613, disc_loss = 0.14470454418679346
Trained batch 74 in epoch 0, gen_loss = 2.4276120789845783, disc_loss = 0.14305121319989364
Trained batch 75 in epoch 0, gen_loss = 2.4300729193185506, disc_loss = 0.14146207628379526
Trained batch 76 in epoch 0, gen_loss = 2.431669102086649, disc_loss = 0.13990721994309457
Trained batch 77 in epoch 0, gen_loss = 2.427222499480614, disc_loss = 0.13858542202088314
Trained batch 78 in epoch 0, gen_loss = 2.436750529687616, disc_loss = 0.13754398349814023
Trained batch 79 in epoch 0, gen_loss = 2.436597028374672, disc_loss = 0.13649795383680613
Trained batch 80 in epoch 0, gen_loss = 2.438977356310244, disc_loss = 0.13577207198573482
Trained batch 81 in epoch 0, gen_loss = 2.4406894968777166, disc_loss = 0.13510385303326497
Trained batch 82 in epoch 0, gen_loss = 2.4414394332701903, disc_loss = 0.13461066515420575
Trained batch 83 in epoch 0, gen_loss = 2.4370072143418446, disc_loss = 0.13439557224600798
Trained batch 84 in epoch 0, gen_loss = 2.433388146232156, disc_loss = 0.1334249189890483
Trained batch 85 in epoch 0, gen_loss = 2.439313536466554, disc_loss = 0.13336801271192555
Trained batch 86 in epoch 0, gen_loss = 2.4385392474031997, disc_loss = 0.13261441982768732
Trained batch 87 in epoch 0, gen_loss = 2.4350242018699646, disc_loss = 0.13202947380275212
Trained batch 88 in epoch 0, gen_loss = 2.437727606698368, disc_loss = 0.13110787465414975
Trained batch 89 in epoch 0, gen_loss = 2.436476320690579, disc_loss = 0.13012227244261237
Trained batch 90 in epoch 0, gen_loss = 2.440068698191381, disc_loss = 0.12902321398340083
Trained batch 91 in epoch 0, gen_loss = 2.439342700916788, disc_loss = 0.1278709534191243
Trained batch 92 in epoch 0, gen_loss = 2.439884252445672, disc_loss = 0.12693668234973185
Trained batch 93 in epoch 0, gen_loss = 2.4391008082856525, disc_loss = 0.12583730827541428
Trained batch 94 in epoch 0, gen_loss = 2.4357247352600098, disc_loss = 0.124845632577413
Trained batch 95 in epoch 0, gen_loss = 2.4385411019126573, disc_loss = 0.12382330427256723
Trained batch 96 in epoch 0, gen_loss = 2.4384728682409857, disc_loss = 0.12278665976656467
Trained batch 97 in epoch 0, gen_loss = 2.440803595951625, disc_loss = 0.12175678053148548
Trained batch 98 in epoch 0, gen_loss = 2.4437823030683727, disc_loss = 0.12071283490895623
Trained batch 99 in epoch 0, gen_loss = 2.445203149318695, disc_loss = 0.11968393854796887
Trained batch 100 in epoch 0, gen_loss = 2.443232873878857, disc_loss = 0.1186287702144225
Trained batch 101 in epoch 0, gen_loss = 2.44363772167879, disc_loss = 0.11765696980314803
Trained batch 102 in epoch 0, gen_loss = 2.4448555418588582, disc_loss = 0.11666659716950747
Trained batch 103 in epoch 0, gen_loss = 2.447424462208381, disc_loss = 0.11567995923822029
Trained batch 104 in epoch 0, gen_loss = 2.448762237458002, disc_loss = 0.1147176286826531
Trained batch 105 in epoch 0, gen_loss = 2.4434677429918974, disc_loss = 0.11382846558853141
Trained batch 106 in epoch 0, gen_loss = 2.4446489298455067, disc_loss = 0.11293012077841803
Trained batch 107 in epoch 0, gen_loss = 2.4455539407553495, disc_loss = 0.11286296509206295
Trained batch 108 in epoch 0, gen_loss = 2.446636232761068, disc_loss = 0.1125559552547035
Trained batch 109 in epoch 0, gen_loss = 2.445320825143294, disc_loss = 0.11230475150726059
Trained batch 110 in epoch 0, gen_loss = 2.4465818727338635, disc_loss = 0.11202272578134193
Trained batch 111 in epoch 0, gen_loss = 2.4440678443227495, disc_loss = 0.11131865630990692
Trained batch 112 in epoch 0, gen_loss = 2.4445761326140008, disc_loss = 0.11067807384296856
Trained batch 113 in epoch 0, gen_loss = 2.4437058892166403, disc_loss = 0.10989066487864445
Trained batch 114 in epoch 0, gen_loss = 2.4418658297994864, disc_loss = 0.10907380757448466
Trained batch 115 in epoch 0, gen_loss = 2.4417857013899704, disc_loss = 0.10827476298436522
Trained batch 116 in epoch 0, gen_loss = 2.444942125907311, disc_loss = 0.10749223565635009
Trained batch 117 in epoch 0, gen_loss = 2.442041522365505, disc_loss = 0.10672851367774656
Trained batch 118 in epoch 0, gen_loss = 2.445156678432176, disc_loss = 0.10595627793525698
Trained batch 119 in epoch 0, gen_loss = 2.4477686007817585, disc_loss = 0.10535954933147877
Trained batch 120 in epoch 0, gen_loss = 2.443915575989022, disc_loss = 0.10490799154162653
Trained batch 121 in epoch 0, gen_loss = 2.4498472350542664, disc_loss = 0.10419469260320556
Trained batch 122 in epoch 0, gen_loss = 2.450104630090357, disc_loss = 0.10345587233550907
Trained batch 123 in epoch 0, gen_loss = 2.4515632083339076, disc_loss = 0.102736227830211
Trained batch 124 in epoch 0, gen_loss = 2.451480239868164, disc_loss = 0.10214005546271801
Trained batch 125 in epoch 0, gen_loss = 2.451508149268135, disc_loss = 0.10146884083570469
Trained batch 126 in epoch 0, gen_loss = 2.4525941600949746, disc_loss = 0.1007440915023248
Trained batch 127 in epoch 0, gen_loss = 2.4534964244812727, disc_loss = 0.10003549205430318
Trained batch 128 in epoch 0, gen_loss = 2.452703882557477, disc_loss = 0.09936783970297539
Trained batch 129 in epoch 0, gen_loss = 2.452204381502592, disc_loss = 0.09870769794170674
Trained batch 130 in epoch 0, gen_loss = 2.452444398676166, disc_loss = 0.09815721289176522
Trained batch 131 in epoch 0, gen_loss = 2.452569668943232, disc_loss = 0.09762086674119487
Trained batch 132 in epoch 0, gen_loss = 2.452171427862985, disc_loss = 0.09699828930451233
Trained batch 133 in epoch 0, gen_loss = 2.45225069949876, disc_loss = 0.09637145240749441
Trained batch 134 in epoch 0, gen_loss = 2.4525994300842284, disc_loss = 0.09578746308883031
Trained batch 135 in epoch 0, gen_loss = 2.457310536328484, disc_loss = 0.09518471820389524
Trained batch 136 in epoch 0, gen_loss = 2.454713802268035, disc_loss = 0.09466894408755928
Trained batch 137 in epoch 0, gen_loss = 2.4515358486037324, disc_loss = 0.09432569483592027
Trained batch 138 in epoch 0, gen_loss = 2.4552478910350115, disc_loss = 0.09387833571476902
Trained batch 139 in epoch 0, gen_loss = 2.456152900627681, disc_loss = 0.0933394527594958
Trained batch 140 in epoch 0, gen_loss = 2.4580554387248155, disc_loss = 0.09277775425278971
Trained batch 141 in epoch 0, gen_loss = 2.4571454424253654, disc_loss = 0.0922050235110899
Trained batch 142 in epoch 0, gen_loss = 2.458605812979745, disc_loss = 0.0916405807711653
Trained batch 143 in epoch 0, gen_loss = 2.4593452397320004, disc_loss = 0.09109835382292254
Trained batch 144 in epoch 0, gen_loss = 2.4620643286869446, disc_loss = 0.09053400151174644
Trained batch 145 in epoch 0, gen_loss = 2.4645228614545847, disc_loss = 0.08998114447275253
Trained batch 146 in epoch 0, gen_loss = 2.463108356307153, disc_loss = 0.08967345760387628
Trained batch 147 in epoch 0, gen_loss = 2.4594916443567016, disc_loss = 0.08989289307312386
Trained batch 148 in epoch 0, gen_loss = 2.460471166060275, disc_loss = 0.08956223281237903
Trained batch 149 in epoch 0, gen_loss = 2.460354693730672, disc_loss = 0.08908124403407176
Trained batch 150 in epoch 0, gen_loss = 2.4624379802223864, disc_loss = 0.08857712732467628
Trained batch 151 in epoch 0, gen_loss = 2.462250910307232, disc_loss = 0.0880943719224122
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 2.2865066528320312, disc_loss = 0.015560967847704887
Trained batch 1 in epoch 1, gen_loss = 2.497884750366211, disc_loss = 0.012427282519638538
Trained batch 2 in epoch 1, gen_loss = 2.599884827931722, disc_loss = 0.011768989264965057
Trained batch 3 in epoch 1, gen_loss = 2.5341286063194275, disc_loss = 0.014076432213187218
Trained batch 4 in epoch 1, gen_loss = 2.5356587409973144, disc_loss = 0.016838377714157103
Trained batch 5 in epoch 1, gen_loss = 2.519685745239258, disc_loss = 0.02027882511417071
Trained batch 6 in epoch 1, gen_loss = 2.534149782998221, disc_loss = 0.02024917091642107
Trained batch 7 in epoch 1, gen_loss = 2.5566592812538147, disc_loss = 0.01922551786992699
Trained batch 8 in epoch 1, gen_loss = 2.551598654852973, disc_loss = 0.01840798691329029
Trained batch 9 in epoch 1, gen_loss = 2.5397102355957033, disc_loss = 0.017966428585350514
Trained batch 10 in epoch 1, gen_loss = 2.539095575159246, disc_loss = 0.01802628334950317
Trained batch 11 in epoch 1, gen_loss = 2.512549618879954, disc_loss = 0.017685899666200083
Trained batch 12 in epoch 1, gen_loss = 2.5072042025052586, disc_loss = 0.01827776231444799
Trained batch 13 in epoch 1, gen_loss = 2.512397680963789, disc_loss = 0.01787637234000223
Trained batch 14 in epoch 1, gen_loss = 2.4996553897857665, disc_loss = 0.019354380232592425
Trained batch 15 in epoch 1, gen_loss = 2.4683757573366165, disc_loss = 0.02169865445466712
Trained batch 16 in epoch 1, gen_loss = 2.4648437359753776, disc_loss = 0.021177942864596844
Trained batch 17 in epoch 1, gen_loss = 2.458582785394457, disc_loss = 0.021310492263485987
Trained batch 18 in epoch 1, gen_loss = 2.456235672298231, disc_loss = 0.021089820926518815
Trained batch 19 in epoch 1, gen_loss = 2.4493041396141053, disc_loss = 0.02074635508470237
Trained batch 20 in epoch 1, gen_loss = 2.461318708601452, disc_loss = 0.020213506494959194
Trained batch 21 in epoch 1, gen_loss = 2.453461159359325, disc_loss = 0.019717877646061508
Trained batch 22 in epoch 1, gen_loss = 2.4697536903878916, disc_loss = 0.019280057926864727
Trained batch 23 in epoch 1, gen_loss = 2.4770857890446982, disc_loss = 0.01889384239135931
Trained batch 24 in epoch 1, gen_loss = 2.4946477031707763, disc_loss = 0.018441920876502992
Trained batch 25 in epoch 1, gen_loss = 2.486989085490887, disc_loss = 0.01799847687093111
Trained batch 26 in epoch 1, gen_loss = 2.484975364473131, disc_loss = 0.017748877337133442
Trained batch 27 in epoch 1, gen_loss = 2.4910948361669267, disc_loss = 0.017462902436298982
Trained batch 28 in epoch 1, gen_loss = 2.4921139273150215, disc_loss = 0.017362762595815904
Trained batch 29 in epoch 1, gen_loss = 2.4875745217005414, disc_loss = 0.01729536084458232
Trained batch 30 in epoch 1, gen_loss = 2.485246689088883, disc_loss = 0.017041259505335363
Trained batch 31 in epoch 1, gen_loss = 2.5126342102885246, disc_loss = 0.01685346569865942
Trained batch 32 in epoch 1, gen_loss = 2.507318872393984, disc_loss = 0.0169155854506023
Trained batch 33 in epoch 1, gen_loss = 2.4977305917178882, disc_loss = 0.01700434384538847
Trained batch 34 in epoch 1, gen_loss = 2.498397554670061, disc_loss = 0.016976732122046607
Trained batch 35 in epoch 1, gen_loss = 2.4990651276376514, disc_loss = 0.016767142004229955
Trained batch 36 in epoch 1, gen_loss = 2.500678423288706, disc_loss = 0.016714102261372515
Trained batch 37 in epoch 1, gen_loss = 2.4957557853899504, disc_loss = 0.01663437757739111
Trained batch 38 in epoch 1, gen_loss = 2.4951343597509923, disc_loss = 0.016522016161336348
Trained batch 39 in epoch 1, gen_loss = 2.5017450034618376, disc_loss = 0.016570992837660014
Trained batch 40 in epoch 1, gen_loss = 2.4952163987043425, disc_loss = 0.016510667211217123
Trained batch 41 in epoch 1, gen_loss = 2.5043693553833735, disc_loss = 0.016352222434112003
Trained batch 42 in epoch 1, gen_loss = 2.5023418415424437, disc_loss = 0.016260381203231422
Trained batch 43 in epoch 1, gen_loss = 2.506455730308186, disc_loss = 0.016319204354658723
Trained batch 44 in epoch 1, gen_loss = 2.5023856004079184, disc_loss = 0.01640662830322981
Trained batch 45 in epoch 1, gen_loss = 2.498456892759904, disc_loss = 0.016451885984481676
Trained batch 46 in epoch 1, gen_loss = 2.503868929883267, disc_loss = 0.01630467198234289
Trained batch 47 in epoch 1, gen_loss = 2.503844584027926, disc_loss = 0.016250730666797608
Trained batch 48 in epoch 1, gen_loss = 2.507990141304172, disc_loss = 0.016242023424378464
Trained batch 49 in epoch 1, gen_loss = 2.506107053756714, disc_loss = 0.01610110657289624
Trained batch 50 in epoch 1, gen_loss = 2.510941884096931, disc_loss = 0.015916460631963086
Trained batch 51 in epoch 1, gen_loss = 2.5134387016296387, disc_loss = 0.015789947418782573
Trained batch 52 in epoch 1, gen_loss = 2.5088104167074525, disc_loss = 0.015716651612717025
Trained batch 53 in epoch 1, gen_loss = 2.5038224944361933, disc_loss = 0.015722551607285386
Trained batch 54 in epoch 1, gen_loss = 2.5071243676272306, disc_loss = 0.015761194395070725
Trained batch 55 in epoch 1, gen_loss = 2.504918417760304, disc_loss = 0.01703613140021584
Trained batch 56 in epoch 1, gen_loss = 2.500010971437421, disc_loss = 0.019368524042268593
Trained batch 57 in epoch 1, gen_loss = 2.4990361846726517, disc_loss = 0.024864806135281407
Trained batch 58 in epoch 1, gen_loss = 2.495695954662258, disc_loss = 0.035204595381046755
Trained batch 59 in epoch 1, gen_loss = 2.489901089668274, disc_loss = 0.0468490510713309
Trained batch 60 in epoch 1, gen_loss = 2.5043426263527793, disc_loss = 0.06933715983797781
Trained batch 61 in epoch 1, gen_loss = 2.503118315050679, disc_loss = 0.08244667606308095
Trained batch 62 in epoch 1, gen_loss = 2.4984704047914534, disc_loss = 0.08535934720070117
Trained batch 63 in epoch 1, gen_loss = 2.4965173676609993, disc_loss = 0.08790200478688348
Trained batch 64 in epoch 1, gen_loss = 2.4902029550992526, disc_loss = 0.08994568834224573
Trained batch 65 in epoch 1, gen_loss = 2.4838766365340263, disc_loss = 0.09146708223234976
Trained batch 66 in epoch 1, gen_loss = 2.4754467010498047, disc_loss = 0.09280909104411726
Trained batch 67 in epoch 1, gen_loss = 2.476304566158968, disc_loss = 0.09279355238301351
Trained batch 68 in epoch 1, gen_loss = 2.4720379580622134, disc_loss = 0.09276381076947934
Trained batch 69 in epoch 1, gen_loss = 2.465655371120998, disc_loss = 0.09245348590027008
Trained batch 70 in epoch 1, gen_loss = 2.456894505191857, disc_loss = 0.09203687820478644
Trained batch 71 in epoch 1, gen_loss = 2.4515432284937964, disc_loss = 0.09130785951856524
Trained batch 72 in epoch 1, gen_loss = 2.451730290504351, disc_loss = 0.0905580613124248
Trained batch 73 in epoch 1, gen_loss = 2.45247170731828, disc_loss = 0.08978671163974984
Trained batch 74 in epoch 1, gen_loss = 2.453676338195801, disc_loss = 0.08903806409488121
Trained batch 75 in epoch 1, gen_loss = 2.4484718943897046, disc_loss = 0.08851572597938541
Trained batch 76 in epoch 1, gen_loss = 2.4473998608527245, disc_loss = 0.08806465649614473
Trained batch 77 in epoch 1, gen_loss = 2.449822031534635, disc_loss = 0.08776083078760749
Trained batch 78 in epoch 1, gen_loss = 2.4530713829813124, disc_loss = 0.08755248206184257
Trained batch 79 in epoch 1, gen_loss = 2.4551252156496046, disc_loss = 0.086907033494208
Trained batch 80 in epoch 1, gen_loss = 2.458606696423189, disc_loss = 0.08611917515273815
Trained batch 81 in epoch 1, gen_loss = 2.461487112975702, disc_loss = 0.0854493620033126
Trained batch 82 in epoch 1, gen_loss = 2.4576291549636657, disc_loss = 0.08495200422020202
Trained batch 83 in epoch 1, gen_loss = 2.4575154128528776, disc_loss = 0.08454423248102623
Trained batch 84 in epoch 1, gen_loss = 2.4568123761345357, disc_loss = 0.08391386214643717
Trained batch 85 in epoch 1, gen_loss = 2.4559064659961436, disc_loss = 0.0831309642404491
Trained batch 86 in epoch 1, gen_loss = 2.4537146036652313, disc_loss = 0.08244255267554658
Trained batch 87 in epoch 1, gen_loss = 2.458350260149349, disc_loss = 0.0816896910123019
Trained batch 88 in epoch 1, gen_loss = 2.4560181558801886, disc_loss = 0.08097742390138714
Trained batch 89 in epoch 1, gen_loss = 2.4530906041463214, disc_loss = 0.08024608659454519
Trained batch 90 in epoch 1, gen_loss = 2.4555814528203275, disc_loss = 0.07950675023903886
Trained batch 91 in epoch 1, gen_loss = 2.4558679072753242, disc_loss = 0.07878776173026342
Trained batch 92 in epoch 1, gen_loss = 2.4555028971805366, disc_loss = 0.07813041868509464
Trained batch 93 in epoch 1, gen_loss = 2.461877257265943, disc_loss = 0.0774578178856284
Trained batch 94 in epoch 1, gen_loss = 2.463398313522339, disc_loss = 0.07678117154068069
Trained batch 95 in epoch 1, gen_loss = 2.464656842251619, disc_loss = 0.07612039709541325
Trained batch 96 in epoch 1, gen_loss = 2.463508768179982, disc_loss = 0.07546701985075302
Trained batch 97 in epoch 1, gen_loss = 2.4632338772014695, disc_loss = 0.074792183080346
Trained batch 98 in epoch 1, gen_loss = 2.460939245994645, disc_loss = 0.0741935715154566
Trained batch 99 in epoch 1, gen_loss = 2.4624984788894655, disc_loss = 0.07370507007464766
Trained batch 100 in epoch 1, gen_loss = 2.4640395003970306, disc_loss = 0.07315253667385861
Trained batch 101 in epoch 1, gen_loss = 2.4624815267675064, disc_loss = 0.07259608465520774
Trained batch 102 in epoch 1, gen_loss = 2.459956722352111, disc_loss = 0.07209407415204835
Trained batch 103 in epoch 1, gen_loss = 2.4592303060568295, disc_loss = 0.07152224661639103
Trained batch 104 in epoch 1, gen_loss = 2.4626161961328417, disc_loss = 0.07094993369565124
Trained batch 105 in epoch 1, gen_loss = 2.462810073258742, disc_loss = 0.07039870558974315
Trained batch 106 in epoch 1, gen_loss = 2.463613648280919, disc_loss = 0.06988450470511044
Trained batch 107 in epoch 1, gen_loss = 2.462389014385365, disc_loss = 0.0695791368338245
Trained batch 108 in epoch 1, gen_loss = 2.4607910038134375, disc_loss = 0.06982785138651865
Trained batch 109 in epoch 1, gen_loss = 2.463470738584345, disc_loss = 0.06980298340997913
Trained batch 110 in epoch 1, gen_loss = 2.464444319407145, disc_loss = 0.06939871592430381
Trained batch 111 in epoch 1, gen_loss = 2.4675106086901257, disc_loss = 0.06896172425643142
Trained batch 112 in epoch 1, gen_loss = 2.46278233971216, disc_loss = 0.06929228166365518
Trained batch 113 in epoch 1, gen_loss = 2.458905170884049, disc_loss = 0.06988214801081963
Trained batch 114 in epoch 1, gen_loss = 2.4607085881025896, disc_loss = 0.0696493133092704
Trained batch 115 in epoch 1, gen_loss = 2.4588895059865097, disc_loss = 0.06941903050153933
Trained batch 116 in epoch 1, gen_loss = 2.455303240026164, disc_loss = 0.06941861189647108
Trained batch 117 in epoch 1, gen_loss = 2.4591804470046092, disc_loss = 0.07087159429882038
Trained batch 118 in epoch 1, gen_loss = 2.4549654752266505, disc_loss = 0.0709947016591034
Trained batch 119 in epoch 1, gen_loss = 2.453026223182678, disc_loss = 0.07062444317465028
Trained batch 120 in epoch 1, gen_loss = 2.4568169018453805, disc_loss = 0.0701877016204694
Trained batch 121 in epoch 1, gen_loss = 2.4594709189211734, disc_loss = 0.06974762517836738
Trained batch 122 in epoch 1, gen_loss = 2.460779069885006, disc_loss = 0.06938335623561852
Trained batch 123 in epoch 1, gen_loss = 2.458444551114113, disc_loss = 0.06904403896882169
Trained batch 124 in epoch 1, gen_loss = 2.45648122215271, disc_loss = 0.06865470115840434
Trained batch 125 in epoch 1, gen_loss = 2.454986674445016, disc_loss = 0.06820227216840499
Trained batch 126 in epoch 1, gen_loss = 2.4556392159048968, disc_loss = 0.06777067131208857
Trained batch 127 in epoch 1, gen_loss = 2.454561810940504, disc_loss = 0.06751071566395694
Trained batch 128 in epoch 1, gen_loss = 2.452818005584007, disc_loss = 0.06720538388995469
Trained batch 129 in epoch 1, gen_loss = 2.451413453542269, disc_loss = 0.06683378492553647
Trained batch 130 in epoch 1, gen_loss = 2.4541954320805672, disc_loss = 0.06639026153747363
Trained batch 131 in epoch 1, gen_loss = 2.4562698963916665, disc_loss = 0.0659599900104557
Trained batch 132 in epoch 1, gen_loss = 2.4572226893632934, disc_loss = 0.06555168694795523
Trained batch 133 in epoch 1, gen_loss = 2.457849077324369, disc_loss = 0.06512640127495153
Trained batch 134 in epoch 1, gen_loss = 2.4593899444297507, disc_loss = 0.06471534691475056
Trained batch 135 in epoch 1, gen_loss = 2.456768239245695, disc_loss = 0.06479268871686038
Trained batch 136 in epoch 1, gen_loss = 2.4541586402558933, disc_loss = 0.06526899229000954
Trained batch 137 in epoch 1, gen_loss = 2.456606351810953, disc_loss = 0.06498627141927896
Trained batch 138 in epoch 1, gen_loss = 2.4575881289063597, disc_loss = 0.06478208537957222
Trained batch 139 in epoch 1, gen_loss = 2.4574052453041078, disc_loss = 0.06439033362216183
Trained batch 140 in epoch 1, gen_loss = 2.4581695262421954, disc_loss = 0.06401732877055381
Trained batch 141 in epoch 1, gen_loss = 2.4556044541614157, disc_loss = 0.06366116242011038
Trained batch 142 in epoch 1, gen_loss = 2.4544719232545864, disc_loss = 0.0632729155525982
Trained batch 143 in epoch 1, gen_loss = 2.4558290011352963, disc_loss = 0.06289883765728316
Trained batch 144 in epoch 1, gen_loss = 2.4553423651333515, disc_loss = 0.06253935464111895
Trained batch 145 in epoch 1, gen_loss = 2.4548352254580146, disc_loss = 0.06218901668254235
Trained batch 146 in epoch 1, gen_loss = 2.4552339777654533, disc_loss = 0.0618065847273992
Trained batch 147 in epoch 1, gen_loss = 2.4536283306173376, disc_loss = 0.061448452855787566
Trained batch 148 in epoch 1, gen_loss = 2.455698235722996, disc_loss = 0.06108836551515648
Trained batch 149 in epoch 1, gen_loss = 2.453931220372518, disc_loss = 0.06072141047567129
Trained batch 150 in epoch 1, gen_loss = 2.451890527017859, disc_loss = 0.060404028601648396
Trained batch 151 in epoch 1, gen_loss = 2.4506846791819523, disc_loss = 0.06007620300117292
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 2.6084351539611816, disc_loss = 0.012899534776806831
Trained batch 1 in epoch 2, gen_loss = 2.5967365503311157, disc_loss = 0.010376057587563992
Trained batch 2 in epoch 2, gen_loss = 2.5882426102956138, disc_loss = 0.009232725171993176
Trained batch 3 in epoch 2, gen_loss = 2.5975139141082764, disc_loss = 0.008802327676676214
Trained batch 4 in epoch 2, gen_loss = 2.6041666507720946, disc_loss = 0.008320898283272982
Trained batch 5 in epoch 2, gen_loss = 2.4982949693997702, disc_loss = 0.021592500697200496
Trained batch 6 in epoch 2, gen_loss = 2.4553060701915195, disc_loss = 0.05345620035326907
Trained batch 7 in epoch 2, gen_loss = 2.4719736129045486, disc_loss = 0.05127672787057236
Trained batch 8 in epoch 2, gen_loss = 2.462094955974155, disc_loss = 0.05337356719084912
Trained batch 9 in epoch 2, gen_loss = 2.45060955286026, disc_loss = 0.05042047225870192
Trained batch 10 in epoch 2, gen_loss = 2.4290319897911767, disc_loss = 0.04714705088091167
Trained batch 11 in epoch 2, gen_loss = 2.4286607205867767, disc_loss = 0.04412032970382521
Trained batch 12 in epoch 2, gen_loss = 2.426543501707224, disc_loss = 0.04133931873366237
Trained batch 13 in epoch 2, gen_loss = 2.431929119995662, disc_loss = 0.03884718789985137
Trained batch 14 in epoch 2, gen_loss = 2.4200450499852497, disc_loss = 0.03714305724327763
Trained batch 15 in epoch 2, gen_loss = 2.42539893835783, disc_loss = 0.03559720821795054
Trained batch 16 in epoch 2, gen_loss = 2.4105999960618862, disc_loss = 0.033982641584075546
Trained batch 17 in epoch 2, gen_loss = 2.4241943293147616, disc_loss = 0.03242086060345173
Trained batch 18 in epoch 2, gen_loss = 2.424962363745037, disc_loss = 0.03126625050055353
Trained batch 19 in epoch 2, gen_loss = 2.422092300653458, disc_loss = 0.03023768626153469
Trained batch 20 in epoch 2, gen_loss = 2.427429375194368, disc_loss = 0.02921137794674862
Trained batch 21 in epoch 2, gen_loss = 2.4371491833166643, disc_loss = 0.028190206312997776
Trained batch 22 in epoch 2, gen_loss = 2.44663769784181, disc_loss = 0.027161133637570816
Trained batch 23 in epoch 2, gen_loss = 2.454679861664772, disc_loss = 0.026395982325387497
Trained batch 24 in epoch 2, gen_loss = 2.4596852827072144, disc_loss = 0.025567377265542746
Trained batch 25 in epoch 2, gen_loss = 2.4620477190384498, disc_loss = 0.024813730878612168
Trained batch 26 in epoch 2, gen_loss = 2.4607448710335627, disc_loss = 0.024052510762380228
Trained batch 27 in epoch 2, gen_loss = 2.455357266323907, disc_loss = 0.023485275451093912
Trained batch 28 in epoch 2, gen_loss = 2.444241897813205, disc_loss = 0.0228945419577689
Trained batch 29 in epoch 2, gen_loss = 2.430518178145091, disc_loss = 0.022407645856340728
Trained batch 30 in epoch 2, gen_loss = 2.421176045171676, disc_loss = 0.022024388815606793
Trained batch 31 in epoch 2, gen_loss = 2.413945209234953, disc_loss = 0.021598170773359016
Trained batch 32 in epoch 2, gen_loss = 2.4125558426885894, disc_loss = 0.02115188062078122
Trained batch 33 in epoch 2, gen_loss = 2.4130306068588707, disc_loss = 0.020699655719320562
Trained batch 34 in epoch 2, gen_loss = 2.4210318395069668, disc_loss = 0.020277948917022774
Trained batch 35 in epoch 2, gen_loss = 2.424092408683565, disc_loss = 0.01986086981681486
Trained batch 36 in epoch 2, gen_loss = 2.428246346679894, disc_loss = 0.019441364131666517
Trained batch 37 in epoch 2, gen_loss = 2.4331234160222506, disc_loss = 0.019047877359154978
Trained batch 38 in epoch 2, gen_loss = 2.4359995187857213, disc_loss = 0.018711190670728683
Trained batch 39 in epoch 2, gen_loss = 2.428742542862892, disc_loss = 0.018427525472361594
Trained batch 40 in epoch 2, gen_loss = 2.4318420916068844, disc_loss = 0.01810401624704643
Trained batch 41 in epoch 2, gen_loss = 2.424169026670002, disc_loss = 0.0178721850139222
Trained batch 42 in epoch 2, gen_loss = 2.419198194215464, disc_loss = 0.01761755068938053
Trained batch 43 in epoch 2, gen_loss = 2.423195484009656, disc_loss = 0.017366525177335876
Trained batch 44 in epoch 2, gen_loss = 2.427896194987827, disc_loss = 0.01711842544997732
Trained batch 45 in epoch 2, gen_loss = 2.425024180308632, disc_loss = 0.016897627577671537
Trained batch 46 in epoch 2, gen_loss = 2.4278483619081213, disc_loss = 0.01662996470769669
Trained batch 47 in epoch 2, gen_loss = 2.4283158654967942, disc_loss = 0.016385496011935174
Trained batch 48 in epoch 2, gen_loss = 2.4294547913025837, disc_loss = 0.016150741400767346
Trained batch 49 in epoch 2, gen_loss = 2.4331383061408998, disc_loss = 0.01592093173414469
Trained batch 50 in epoch 2, gen_loss = 2.4378307263056436, disc_loss = 0.01571259517953092
Trained batch 51 in epoch 2, gen_loss = 2.434995506818478, disc_loss = 0.015523605353127305
Trained batch 52 in epoch 2, gen_loss = 2.4381327246719935, disc_loss = 0.015310174240818564
Trained batch 53 in epoch 2, gen_loss = 2.436059137185415, disc_loss = 0.015142015405689125
Trained batch 54 in epoch 2, gen_loss = 2.436103571544994, disc_loss = 0.014974800903688778
Trained batch 55 in epoch 2, gen_loss = 2.4441048226186206, disc_loss = 0.014826368873140641
Trained batch 56 in epoch 2, gen_loss = 2.4461381832758584, disc_loss = 0.014654426410663546
Trained batch 57 in epoch 2, gen_loss = 2.447044440384569, disc_loss = 0.014556686618718607
Trained batch 58 in epoch 2, gen_loss = 2.4433167526277444, disc_loss = 0.01460832534200054
Trained batch 59 in epoch 2, gen_loss = 2.435849541425705, disc_loss = 0.014890099751452605
Trained batch 60 in epoch 2, gen_loss = 2.444407660453046, disc_loss = 0.015058521608837316
Trained batch 61 in epoch 2, gen_loss = 2.4413273776731184, disc_loss = 0.01495866653239054
Trained batch 62 in epoch 2, gen_loss = 2.4465752840042114, disc_loss = 0.01483107917749929
Trained batch 63 in epoch 2, gen_loss = 2.4458277728408575, disc_loss = 0.014670053213194478
Trained batch 64 in epoch 2, gen_loss = 2.4440066832762497, disc_loss = 0.014558291872246908
Trained batch 65 in epoch 2, gen_loss = 2.446201235959024, disc_loss = 0.014395877023961282
Trained batch 66 in epoch 2, gen_loss = 2.4443614038068855, disc_loss = 0.014229968919960865
Trained batch 67 in epoch 2, gen_loss = 2.4412795042290405, disc_loss = 0.01409152545281412
Trained batch 68 in epoch 2, gen_loss = 2.4413245052531147, disc_loss = 0.013938395762006226
Trained batch 69 in epoch 2, gen_loss = 2.4351040175982885, disc_loss = 0.01558077750128827
Trained batch 70 in epoch 2, gen_loss = 2.427072249667745, disc_loss = 0.020932446374938313
Trained batch 71 in epoch 2, gen_loss = 2.4196947481897144, disc_loss = 0.02194617377891619
Trained batch 72 in epoch 2, gen_loss = 2.4193583710552895, disc_loss = 0.023222422657840667
Trained batch 73 in epoch 2, gen_loss = 2.4171633655960494, disc_loss = 0.023954823811387492
Trained batch 74 in epoch 2, gen_loss = 2.4165890884399412, disc_loss = 0.024415469712888202
Trained batch 75 in epoch 2, gen_loss = 2.4187485858013758, disc_loss = 0.024878538945861357
Trained batch 76 in epoch 2, gen_loss = 2.4217501089170383, disc_loss = 0.025270029318869694
Trained batch 77 in epoch 2, gen_loss = 2.4225979370948596, disc_loss = 0.025538692677703995
Trained batch 78 in epoch 2, gen_loss = 2.4211104308502582, disc_loss = 0.02546597583089731
Trained batch 79 in epoch 2, gen_loss = 2.4210399389266968, disc_loss = 0.025388437949004583
Trained batch 80 in epoch 2, gen_loss = 2.421520389156577, disc_loss = 0.025194802077165172
Trained batch 81 in epoch 2, gen_loss = 2.423840671050839, disc_loss = 0.02502095181120151
Trained batch 82 in epoch 2, gen_loss = 2.4247237199760345, disc_loss = 0.02480859694026231
Trained batch 83 in epoch 2, gen_loss = 2.4264373892829534, disc_loss = 0.0245770407325056
Trained batch 84 in epoch 2, gen_loss = 2.4280152657452754, disc_loss = 0.024361740690929924
Trained batch 85 in epoch 2, gen_loss = 2.4280455888703814, disc_loss = 0.024156171094821117
Trained batch 86 in epoch 2, gen_loss = 2.4284328235976997, disc_loss = 0.023940001242398017
Trained batch 87 in epoch 2, gen_loss = 2.426905786449259, disc_loss = 0.02374870563190515
Trained batch 88 in epoch 2, gen_loss = 2.4250600070096135, disc_loss = 0.0236703591928765
Trained batch 89 in epoch 2, gen_loss = 2.4214128361807927, disc_loss = 0.02372181935287598
Trained batch 90 in epoch 2, gen_loss = 2.4262579797388435, disc_loss = 0.02361498431527762
Trained batch 91 in epoch 2, gen_loss = 2.4241948775623157, disc_loss = 0.02347413151089669
Trained batch 92 in epoch 2, gen_loss = 2.424969273228799, disc_loss = 0.023371024340170847
Trained batch 93 in epoch 2, gen_loss = 2.424542602072371, disc_loss = 0.023203958576406412
Trained batch 94 in epoch 2, gen_loss = 2.42768514281825, disc_loss = 0.023075161469904217
Trained batch 95 in epoch 2, gen_loss = 2.426002030571302, disc_loss = 0.02292129027531094
Trained batch 96 in epoch 2, gen_loss = 2.4243450386008036, disc_loss = 0.02276827481133652
Trained batch 97 in epoch 2, gen_loss = 2.426887733595712, disc_loss = 0.02259993508733733
Trained batch 98 in epoch 2, gen_loss = 2.426717517351863, disc_loss = 0.022421704344169208
Trained batch 99 in epoch 2, gen_loss = 2.4302188205718993, disc_loss = 0.022265163033735005
Trained batch 100 in epoch 2, gen_loss = 2.431869886889316, disc_loss = 0.022107459090668524
Trained batch 101 in epoch 2, gen_loss = 2.4342284810309316, disc_loss = 0.022009991330788563
Trained batch 102 in epoch 2, gen_loss = 2.4358588190912043, disc_loss = 0.02184720787002696
Trained batch 103 in epoch 2, gen_loss = 2.437206364594973, disc_loss = 0.021698547466747604
Trained batch 104 in epoch 2, gen_loss = 2.436274955386207, disc_loss = 0.021564869930790292
Trained batch 105 in epoch 2, gen_loss = 2.434410180685655, disc_loss = 0.021415470266837697
Trained batch 106 in epoch 2, gen_loss = 2.437389391604985, disc_loss = 0.021253396428372956
Trained batch 107 in epoch 2, gen_loss = 2.436765441188106, disc_loss = 0.02112447291276314
Trained batch 108 in epoch 2, gen_loss = 2.433620118219918, disc_loss = 0.020989768820122705
Trained batch 109 in epoch 2, gen_loss = 2.4351050463589754, disc_loss = 0.020836497417820447
Trained batch 110 in epoch 2, gen_loss = 2.436910049335377, disc_loss = 0.020685404507644677
Trained batch 111 in epoch 2, gen_loss = 2.436869572315897, disc_loss = 0.02055436965435677
Trained batch 112 in epoch 2, gen_loss = 2.4344528839651463, disc_loss = 0.020448629190090353
Trained batch 113 in epoch 2, gen_loss = 2.4348344342750416, disc_loss = 0.020339495720946343
Trained batch 114 in epoch 2, gen_loss = 2.4318663845891537, disc_loss = 0.02021899564070222
Trained batch 115 in epoch 2, gen_loss = 2.4319951965891082, disc_loss = 0.020127041415905517
Trained batch 116 in epoch 2, gen_loss = 2.4324468955015526, disc_loss = 0.020011588817653365
Trained batch 117 in epoch 2, gen_loss = 2.4301501189248036, disc_loss = 0.01987658885220792
Trained batch 118 in epoch 2, gen_loss = 2.4304276213926426, disc_loss = 0.019744063522118854
Trained batch 119 in epoch 2, gen_loss = 2.43307147026062, disc_loss = 0.019610051676863804
Trained batch 120 in epoch 2, gen_loss = 2.4337432798275276, disc_loss = 0.01947462107516702
Trained batch 121 in epoch 2, gen_loss = 2.435851272989492, disc_loss = 0.01934396988353463
Trained batch 122 in epoch 2, gen_loss = 2.4373252605035054, disc_loss = 0.019227173071490918
Trained batch 123 in epoch 2, gen_loss = 2.434291466589897, disc_loss = 0.0191595735940932
Trained batch 124 in epoch 2, gen_loss = 2.433659852981567, disc_loss = 0.01906214761547744
Trained batch 125 in epoch 2, gen_loss = 2.4323030483155024, disc_loss = 0.01916492999243062
Trained batch 126 in epoch 2, gen_loss = 2.4325042503086602, disc_loss = 0.019580799204436696
Trained batch 127 in epoch 2, gen_loss = 2.4373094998300076, disc_loss = 0.01965789109635807
Trained batch 128 in epoch 2, gen_loss = 2.4376069704691568, disc_loss = 0.019896375374550853
Trained batch 129 in epoch 2, gen_loss = 2.4365743490365834, disc_loss = 0.019870350952260196
Trained batch 130 in epoch 2, gen_loss = 2.437645677391809, disc_loss = 0.019836682305521977
Trained batch 131 in epoch 2, gen_loss = 2.4394336613741787, disc_loss = 0.019726125299436688
Trained batch 132 in epoch 2, gen_loss = 2.438854316123446, disc_loss = 0.01961565291670088
Trained batch 133 in epoch 2, gen_loss = 2.4376400887076533, disc_loss = 0.01950036195183256
Trained batch 134 in epoch 2, gen_loss = 2.436695284313626, disc_loss = 0.019382223616250686
Trained batch 135 in epoch 2, gen_loss = 2.4362853467464447, disc_loss = 0.019265753602239248
Trained batch 136 in epoch 2, gen_loss = 2.433774415593948, disc_loss = 0.019146272951709856
Trained batch 137 in epoch 2, gen_loss = 2.4346977282261504, disc_loss = 0.01903832627399622
Trained batch 138 in epoch 2, gen_loss = 2.4344972209107105, disc_loss = 0.018940551791058705
Trained batch 139 in epoch 2, gen_loss = 2.4348630377224514, disc_loss = 0.018842627439049204
Trained batch 140 in epoch 2, gen_loss = 2.4360439270100693, disc_loss = 0.018741262817411876
Trained batch 141 in epoch 2, gen_loss = 2.435375175005953, disc_loss = 0.018631205684177473
Trained batch 142 in epoch 2, gen_loss = 2.438122007396671, disc_loss = 0.0185353672848298
Trained batch 143 in epoch 2, gen_loss = 2.4383852167261972, disc_loss = 0.018435573017793812
Trained batch 144 in epoch 2, gen_loss = 2.4388286902986724, disc_loss = 0.018336575613196553
Trained batch 145 in epoch 2, gen_loss = 2.4422433866213447, disc_loss = 0.01823201390582915
Trained batch 146 in epoch 2, gen_loss = 2.4409975064855045, disc_loss = 0.01813039127705606
Trained batch 147 in epoch 2, gen_loss = 2.4416689099492253, disc_loss = 0.01802522030098968
Trained batch 148 in epoch 2, gen_loss = 2.441540356450433, disc_loss = 0.017921741122079875
Trained batch 149 in epoch 2, gen_loss = 2.4425228039423623, disc_loss = 0.017821106157886485
Trained batch 150 in epoch 2, gen_loss = 2.4424152595317916, disc_loss = 0.017727458184979707
Trained batch 151 in epoch 2, gen_loss = 2.444682003636109, disc_loss = 0.017636599881562257
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 2.315579891204834, disc_loss = 0.0064093805849552155
Trained batch 1 in epoch 3, gen_loss = 2.3251672983169556, disc_loss = 0.005982969421893358
Trained batch 2 in epoch 3, gen_loss = 2.3398759365081787, disc_loss = 0.004899630788713694
Trained batch 3 in epoch 3, gen_loss = 2.3571054339408875, disc_loss = 0.00471665826626122
Trained batch 4 in epoch 3, gen_loss = 2.450729322433472, disc_loss = 0.00445994883775711
Trained batch 5 in epoch 3, gen_loss = 2.42656672000885, disc_loss = 0.004145884537138045
Trained batch 6 in epoch 3, gen_loss = 2.455174582345145, disc_loss = 0.003983661299571395
Trained batch 7 in epoch 3, gen_loss = 2.4340375661849976, disc_loss = 0.003878574352711439
Trained batch 8 in epoch 3, gen_loss = 2.403037601047092, disc_loss = 0.003781107978688346
Trained batch 9 in epoch 3, gen_loss = 2.417884421348572, disc_loss = 0.003682147618383169
Trained batch 10 in epoch 3, gen_loss = 2.4293262741782446, disc_loss = 0.003605137367478826
Trained batch 11 in epoch 3, gen_loss = 2.439114769299825, disc_loss = 0.0035772265788788595
Trained batch 12 in epoch 3, gen_loss = 2.443028083214393, disc_loss = 0.003516251758600657
Trained batch 13 in epoch 3, gen_loss = 2.4186926569257463, disc_loss = 0.0034626207447477748
Trained batch 14 in epoch 3, gen_loss = 2.4161038716634113, disc_loss = 0.0034278023988008497
Trained batch 15 in epoch 3, gen_loss = 2.406101167201996, disc_loss = 0.0034869330702349544
Trained batch 16 in epoch 3, gen_loss = 2.41186383191277, disc_loss = 0.0034694222815553934
Trained batch 17 in epoch 3, gen_loss = 2.42086308532291, disc_loss = 0.0034888548543676734
Trained batch 18 in epoch 3, gen_loss = 2.402210963399787, disc_loss = 0.0075544640789494705
Trained batch 19 in epoch 3, gen_loss = 2.382851779460907, disc_loss = 0.01799683760618791
Trained batch 20 in epoch 3, gen_loss = 2.4015608855656216, disc_loss = 0.01877249567769468
Trained batch 21 in epoch 3, gen_loss = 2.4070053425702183, disc_loss = 0.020883387494408948
Trained batch 22 in epoch 3, gen_loss = 2.4168960840805718, disc_loss = 0.020378477618341214
Trained batch 23 in epoch 3, gen_loss = 2.4197006821632385, disc_loss = 0.020009033255822335
Trained batch 24 in epoch 3, gen_loss = 2.425334711074829, disc_loss = 0.019480454409494995
Trained batch 25 in epoch 3, gen_loss = 2.4380752856914816, disc_loss = 0.018934118856962483
Trained batch 26 in epoch 3, gen_loss = 2.447716571666576, disc_loss = 0.018392239912861475
Trained batch 27 in epoch 3, gen_loss = 2.4552415779658725, disc_loss = 0.017881498198091452
Trained batch 28 in epoch 3, gen_loss = 2.4527273178100586, disc_loss = 0.017373346908274908
Trained batch 29 in epoch 3, gen_loss = 2.4486257870992025, disc_loss = 0.01689535876891265
Trained batch 30 in epoch 3, gen_loss = 2.431957410227868, disc_loss = 0.017625095750836116
Trained batch 31 in epoch 3, gen_loss = 2.420202147215605, disc_loss = 0.017832920835644472
Trained batch 32 in epoch 3, gen_loss = 2.4120972337144795, disc_loss = 0.01760883632849789
Trained batch 33 in epoch 3, gen_loss = 2.4057713992455425, disc_loss = 0.017489780486999628
Trained batch 34 in epoch 3, gen_loss = 2.4071946859359743, disc_loss = 0.017267939215525985
Trained batch 35 in epoch 3, gen_loss = 2.4061295754379697, disc_loss = 0.01699785317113209
Trained batch 36 in epoch 3, gen_loss = 2.4146988552969857, disc_loss = 0.016950113931670785
Trained batch 37 in epoch 3, gen_loss = 2.4144226406749927, disc_loss = 0.017430759947992078
Trained batch 38 in epoch 3, gen_loss = 2.4275077214607825, disc_loss = 0.01848367437457618
Trained batch 39 in epoch 3, gen_loss = 2.427768948674202, disc_loss = 0.01856764376279898
Trained batch 40 in epoch 3, gen_loss = 2.4307154417037964, disc_loss = 0.0184123889350037
Trained batch 41 in epoch 3, gen_loss = 2.4315331180890403, disc_loss = 0.018198184608038338
Trained batch 42 in epoch 3, gen_loss = 2.43199575501819, disc_loss = 0.017880432378110843
Trained batch 43 in epoch 3, gen_loss = 2.4331322664564308, disc_loss = 0.01757868612714281
Trained batch 44 in epoch 3, gen_loss = 2.4299243582619563, disc_loss = 0.017286220777572858
Trained batch 45 in epoch 3, gen_loss = 2.4337623508080193, disc_loss = 0.01707901456899455
Trained batch 46 in epoch 3, gen_loss = 2.440894646847502, disc_loss = 0.016859282268845338
Trained batch 47 in epoch 3, gen_loss = 2.4413811837633452, disc_loss = 0.016582111003420625
Trained batch 48 in epoch 3, gen_loss = 2.4372633306347593, disc_loss = 0.016767845688653842
Trained batch 49 in epoch 3, gen_loss = 2.428273494243622, disc_loss = 0.016740980884060265
Trained batch 50 in epoch 3, gen_loss = 2.423438789797764, disc_loss = 0.01687307063234495
Trained batch 51 in epoch 3, gen_loss = 2.424877962240806, disc_loss = 0.01666198284007036
Trained batch 52 in epoch 3, gen_loss = 2.4301481584333025, disc_loss = 0.016579709824104356
Trained batch 53 in epoch 3, gen_loss = 2.429820067352719, disc_loss = 0.016393197277836776
Trained batch 54 in epoch 3, gen_loss = 2.4269926266236737, disc_loss = 0.01618629705838182
Trained batch 55 in epoch 3, gen_loss = 2.4191762059926987, disc_loss = 0.016017010651661882
Trained batch 56 in epoch 3, gen_loss = 2.423642344642104, disc_loss = 0.015852753628502813
Trained batch 57 in epoch 3, gen_loss = 2.4241116314098754, disc_loss = 0.015655911615889133
Trained batch 58 in epoch 3, gen_loss = 2.4257627483141624, disc_loss = 0.01547014454411248
Trained batch 59 in epoch 3, gen_loss = 2.4269823849201204, disc_loss = 0.015253732237033546
Trained batch 60 in epoch 3, gen_loss = 2.424057782673445, disc_loss = 0.015057605740873784
Trained batch 61 in epoch 3, gen_loss = 2.424443692930283, disc_loss = 0.014859818519213266
Trained batch 62 in epoch 3, gen_loss = 2.4234313832388983, disc_loss = 0.014663484276434968
Trained batch 63 in epoch 3, gen_loss = 2.423923807218671, disc_loss = 0.01448139766944223
Trained batch 64 in epoch 3, gen_loss = 2.423762293962332, disc_loss = 0.01430104228739555
Trained batch 65 in epoch 3, gen_loss = 2.4298655860351794, disc_loss = 0.014132073752328077
Trained batch 66 in epoch 3, gen_loss = 2.428601167095241, disc_loss = 0.013972378130863184
Trained batch 67 in epoch 3, gen_loss = 2.428749696296804, disc_loss = 0.013818403853185694
Trained batch 68 in epoch 3, gen_loss = 2.429162607676741, disc_loss = 0.013717277093615005
Trained batch 69 in epoch 3, gen_loss = 2.4309231093951635, disc_loss = 0.013578285100603743
Trained batch 70 in epoch 3, gen_loss = 2.4293633665837033, disc_loss = 0.013425252934865338
Trained batch 71 in epoch 3, gen_loss = 2.4320151458183923, disc_loss = 0.0132871681093497
Trained batch 72 in epoch 3, gen_loss = 2.430166239607824, disc_loss = 0.013154111180633102
Trained batch 73 in epoch 3, gen_loss = 2.432628990830602, disc_loss = 0.013015161372242949
Trained batch 74 in epoch 3, gen_loss = 2.4316275358200072, disc_loss = 0.012875114036723971
Trained batch 75 in epoch 3, gen_loss = 2.4352677574283197, disc_loss = 0.01274293570129789
Trained batch 76 in epoch 3, gen_loss = 2.4370765051284393, disc_loss = 0.012607967713847756
Trained batch 77 in epoch 3, gen_loss = 2.433760091280326, disc_loss = 0.012482388168931581
Trained batch 78 in epoch 3, gen_loss = 2.4340137816682645, disc_loss = 0.0123603857694123
Trained batch 79 in epoch 3, gen_loss = 2.435705988109112, disc_loss = 0.012235750988475047
Trained batch 80 in epoch 3, gen_loss = 2.4346136384540134, disc_loss = 0.012116453084335834
Trained batch 81 in epoch 3, gen_loss = 2.434993631956054, disc_loss = 0.011993830364833518
Trained batch 82 in epoch 3, gen_loss = 2.4382046949432556, disc_loss = 0.011876055308763522
Trained batch 83 in epoch 3, gen_loss = 2.4417460404691242, disc_loss = 0.011768753019471964
Trained batch 84 in epoch 3, gen_loss = 2.443488871350008, disc_loss = 0.011655791887246511
Trained batch 85 in epoch 3, gen_loss = 2.444625617459763, disc_loss = 0.011554572671695157
Trained batch 86 in epoch 3, gen_loss = 2.442964790881365, disc_loss = 0.011453683100019893
Trained batch 87 in epoch 3, gen_loss = 2.4438564574176613, disc_loss = 0.011356801379323852
Trained batch 88 in epoch 3, gen_loss = 2.4419433119591702, disc_loss = 0.011257368221020933
Trained batch 89 in epoch 3, gen_loss = 2.438961597283681, disc_loss = 0.011168941428574422
Trained batch 90 in epoch 3, gen_loss = 2.437540218070313, disc_loss = 0.011076663167901582
Trained batch 91 in epoch 3, gen_loss = 2.4366195940453075, disc_loss = 0.010996729479697735
Trained batch 92 in epoch 3, gen_loss = 2.4434864482572003, disc_loss = 0.01092018304963506
Trained batch 93 in epoch 3, gen_loss = 2.4452980414349983, disc_loss = 0.010834857633218486
Trained batch 94 in epoch 3, gen_loss = 2.445627976718702, disc_loss = 0.010752542358578036
Trained batch 95 in epoch 3, gen_loss = 2.4446290222307048, disc_loss = 0.01066406973162278
Trained batch 96 in epoch 3, gen_loss = 2.4437807282221686, disc_loss = 0.010605429037541305
Trained batch 97 in epoch 3, gen_loss = 2.443627032698417, disc_loss = 0.010538900050106553
Trained batch 98 in epoch 3, gen_loss = 2.4410737993741276, disc_loss = 0.010644606632095847
Trained batch 99 in epoch 3, gen_loss = 2.4380636394023893, disc_loss = 0.011021489228587597
Trained batch 100 in epoch 3, gen_loss = 2.441345721188158, disc_loss = 0.011149647864651415
Trained batch 101 in epoch 3, gen_loss = 2.443370614566055, disc_loss = 0.011174230925355326
Trained batch 102 in epoch 3, gen_loss = 2.4442667370861018, disc_loss = 0.011129644299287674
Trained batch 103 in epoch 3, gen_loss = 2.4413397094378104, disc_loss = 0.011250711214065982
Trained batch 104 in epoch 3, gen_loss = 2.4408265533901394, disc_loss = 0.01140280315164654
Trained batch 105 in epoch 3, gen_loss = 2.4392672743437425, disc_loss = 0.011368323392059022
Trained batch 106 in epoch 3, gen_loss = 2.4387666254400093, disc_loss = 0.011479710892417302
Trained batch 107 in epoch 3, gen_loss = 2.4395106776996895, disc_loss = 0.01162951004355111
Trained batch 108 in epoch 3, gen_loss = 2.4450018351231146, disc_loss = 0.01164705930234984
Trained batch 109 in epoch 3, gen_loss = 2.445815895904194, disc_loss = 0.011603601795451885
Trained batch 110 in epoch 3, gen_loss = 2.4498348697885737, disc_loss = 0.011525079391913506
Trained batch 111 in epoch 3, gen_loss = 2.448559485375881, disc_loss = 0.011451767892659908
Trained batch 112 in epoch 3, gen_loss = 2.448441540245461, disc_loss = 0.011382185996188659
Trained batch 113 in epoch 3, gen_loss = 2.4482894665316532, disc_loss = 0.011303507782143066
Trained batch 114 in epoch 3, gen_loss = 2.446458299263664, disc_loss = 0.011422679988343431
Trained batch 115 in epoch 3, gen_loss = 2.445608966309449, disc_loss = 0.011502575155363643
Trained batch 116 in epoch 3, gen_loss = 2.4426847166485257, disc_loss = 0.011481187284454448
Trained batch 117 in epoch 3, gen_loss = 2.442248046398163, disc_loss = 0.011408032018738657
Trained batch 118 in epoch 3, gen_loss = 2.4457307613196493, disc_loss = 0.011348301628917581
Trained batch 119 in epoch 3, gen_loss = 2.445732475320498, disc_loss = 0.011275335069512948
Trained batch 120 in epoch 3, gen_loss = 2.4450494425355895, disc_loss = 0.011207484128338493
Trained batch 121 in epoch 3, gen_loss = 2.4449757894531627, disc_loss = 0.011137915695025051
Trained batch 122 in epoch 3, gen_loss = 2.4438170020173238, disc_loss = 0.011074579404137
Trained batch 123 in epoch 3, gen_loss = 2.4427715222681723, disc_loss = 0.01100186036426514
Trained batch 124 in epoch 3, gen_loss = 2.4445173177719117, disc_loss = 0.010929104713723064
Trained batch 125 in epoch 3, gen_loss = 2.443301124232156, disc_loss = 0.010860121101214891
Trained batch 126 in epoch 3, gen_loss = 2.4418165542947965, disc_loss = 0.010814753623209952
Trained batch 127 in epoch 3, gen_loss = 2.4413812505081296, disc_loss = 0.010761400330011384
Trained batch 128 in epoch 3, gen_loss = 2.4409383295118348, disc_loss = 0.010701851422949007
Trained batch 129 in epoch 3, gen_loss = 2.4433586166455195, disc_loss = 0.010641133006160649
Trained batch 130 in epoch 3, gen_loss = 2.4441733897187325, disc_loss = 0.010586414855855111
Trained batch 131 in epoch 3, gen_loss = 2.4431124952706424, disc_loss = 0.0105291294237373
Trained batch 132 in epoch 3, gen_loss = 2.443614677379006, disc_loss = 0.010465226409242566
Trained batch 133 in epoch 3, gen_loss = 2.445946656945926, disc_loss = 0.010403892461474596
Trained batch 134 in epoch 3, gen_loss = 2.445339078373379, disc_loss = 0.010340941764621272
Trained batch 135 in epoch 3, gen_loss = 2.44252714777694, disc_loss = 0.010282268977094004
Trained batch 136 in epoch 3, gen_loss = 2.4432106809894534, disc_loss = 0.010220249669531183
Trained batch 137 in epoch 3, gen_loss = 2.445476527663245, disc_loss = 0.010158973985581079
Trained batch 138 in epoch 3, gen_loss = 2.44661513078127, disc_loss = 0.010101441633988092
Trained batch 139 in epoch 3, gen_loss = 2.4492261826992037, disc_loss = 0.010044085179522102
Trained batch 140 in epoch 3, gen_loss = 2.447482108224368, disc_loss = 0.009991758199184075
Trained batch 141 in epoch 3, gen_loss = 2.4457696970079987, disc_loss = 0.009966767452080066
Trained batch 142 in epoch 3, gen_loss = 2.446269219571894, disc_loss = 0.009932088861046554
Trained batch 143 in epoch 3, gen_loss = 2.444102354347706, disc_loss = 0.009892266993928287
Trained batch 144 in epoch 3, gen_loss = 2.4452871807690326, disc_loss = 0.009845628017752335
Trained batch 145 in epoch 3, gen_loss = 2.443829499695399, disc_loss = 0.009800924136533006
Trained batch 146 in epoch 3, gen_loss = 2.4448502963903, disc_loss = 0.009755940802179936
Trained batch 147 in epoch 3, gen_loss = 2.4440647162295677, disc_loss = 0.009705168611961542
Trained batch 148 in epoch 3, gen_loss = 2.446078712508182, disc_loss = 0.009653357806109241
Trained batch 149 in epoch 3, gen_loss = 2.4463760940233867, disc_loss = 0.009609221302283307
Trained batch 150 in epoch 3, gen_loss = 2.4463972200621042, disc_loss = 0.009565174155591043
Trained batch 151 in epoch 3, gen_loss = 2.4468083373810114, disc_loss = 0.009519198123598471
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 2.550147533416748, disc_loss = 0.0020394138991832733
Trained batch 1 in epoch 4, gen_loss = 2.623403787612915, disc_loss = 0.0020516753429546952
Trained batch 2 in epoch 4, gen_loss = 2.472148815790812, disc_loss = 0.0019452214085807402
Trained batch 3 in epoch 4, gen_loss = 2.4645631313323975, disc_loss = 0.002017348015215248
Trained batch 4 in epoch 4, gen_loss = 2.457131290435791, disc_loss = 0.0022747172974050046
Trained batch 5 in epoch 4, gen_loss = 2.4221483866373696, disc_loss = 0.0022183141748731336
Trained batch 6 in epoch 4, gen_loss = 2.4128101212637767, disc_loss = 0.0022150291396038873
Trained batch 7 in epoch 4, gen_loss = 2.3814842104911804, disc_loss = 0.002205243130447343
Trained batch 8 in epoch 4, gen_loss = 2.440733697679308, disc_loss = 0.0022236705085055698
Trained batch 9 in epoch 4, gen_loss = 2.4472574472427366, disc_loss = 0.00221944332588464
Trained batch 10 in epoch 4, gen_loss = 2.483076897534457, disc_loss = 0.0021896330978382716
Trained batch 11 in epoch 4, gen_loss = 2.505604406197866, disc_loss = 0.002258591470308602
Trained batch 12 in epoch 4, gen_loss = 2.5048252802628737, disc_loss = 0.0022547269383302103
Trained batch 13 in epoch 4, gen_loss = 2.4877691439219882, disc_loss = 0.0022178127131025705
Trained batch 14 in epoch 4, gen_loss = 2.4925312201182046, disc_loss = 0.002198783440204958
Trained batch 15 in epoch 4, gen_loss = 2.48881134390831, disc_loss = 0.0021864772788831033
Trained batch 16 in epoch 4, gen_loss = 2.5034898589639103, disc_loss = 0.002149651778916664
Trained batch 17 in epoch 4, gen_loss = 2.4921684397591486, disc_loss = 0.0021208926983591584
Trained batch 18 in epoch 4, gen_loss = 2.494470997860557, disc_loss = 0.0021663773069648365
Trained batch 19 in epoch 4, gen_loss = 2.4823935985565186, disc_loss = 0.002165000094100833
Trained batch 20 in epoch 4, gen_loss = 2.472399984087263, disc_loss = 0.002173325346250619
Trained batch 21 in epoch 4, gen_loss = 2.4720376404848965, disc_loss = 0.0021701852304183626
Trained batch 22 in epoch 4, gen_loss = 2.4693971820499585, disc_loss = 0.002178529854458959
Trained batch 23 in epoch 4, gen_loss = 2.4584818383057914, disc_loss = 0.002203998223800833
Trained batch 24 in epoch 4, gen_loss = 2.4560983848571776, disc_loss = 0.002211335003376007
Trained batch 25 in epoch 4, gen_loss = 2.4500443568596473, disc_loss = 0.002204647878758036
Trained batch 26 in epoch 4, gen_loss = 2.4438132886533386, disc_loss = 0.0021950709417945255
Trained batch 27 in epoch 4, gen_loss = 2.4333628756659373, disc_loss = 0.0025176377925423105
Trained batch 28 in epoch 4, gen_loss = 2.427573302696491, disc_loss = 0.0030105902034596637
Trained batch 29 in epoch 4, gen_loss = 2.427424923578898, disc_loss = 0.0030301232861044505
Trained batch 30 in epoch 4, gen_loss = 2.436879127256332, disc_loss = 0.0032213451979201165
Trained batch 31 in epoch 4, gen_loss = 2.44060031324625, disc_loss = 0.003265416180511238
Trained batch 32 in epoch 4, gen_loss = 2.4352564522714326, disc_loss = 0.003296460988084701
Trained batch 33 in epoch 4, gen_loss = 2.4347302072188435, disc_loss = 0.003292585356736227
Trained batch 34 in epoch 4, gen_loss = 2.434114442552839, disc_loss = 0.003271556782004024
Trained batch 35 in epoch 4, gen_loss = 2.4324364132351346, disc_loss = 0.0032482668789776247
Trained batch 36 in epoch 4, gen_loss = 2.440925843006856, disc_loss = 0.0032932043761468013
Trained batch 37 in epoch 4, gen_loss = 2.439072979123969, disc_loss = 0.0032700570575941944
Trained batch 38 in epoch 4, gen_loss = 2.4460642093267198, disc_loss = 0.0032444795480189035
Trained batch 39 in epoch 4, gen_loss = 2.4449729919433594, disc_loss = 0.003247020186972804
Trained batch 40 in epoch 4, gen_loss = 2.4511910589729866, disc_loss = 0.0032402441138401628
Trained batch 41 in epoch 4, gen_loss = 2.454273155757359, disc_loss = 0.0032094184425659478
Trained batch 42 in epoch 4, gen_loss = 2.456244485322819, disc_loss = 0.003176037869199591
Trained batch 43 in epoch 4, gen_loss = 2.4546538266268643, disc_loss = 0.0031362367312381552
Trained batch 44 in epoch 4, gen_loss = 2.450324291653103, disc_loss = 0.0031003256199053594
Trained batch 45 in epoch 4, gen_loss = 2.4430580761121665, disc_loss = 0.003071939560038078
Trained batch 46 in epoch 4, gen_loss = 2.442944384635763, disc_loss = 0.0030463455824498486
Trained batch 47 in epoch 4, gen_loss = 2.4472602854172387, disc_loss = 0.0030171283578965813
Trained batch 48 in epoch 4, gen_loss = 2.4458597971468556, disc_loss = 0.0029978828067530176
Trained batch 49 in epoch 4, gen_loss = 2.441533770561218, disc_loss = 0.0029841101355850695
Trained batch 50 in epoch 4, gen_loss = 2.448958406261369, disc_loss = 0.0029634906129692405
Trained batch 51 in epoch 4, gen_loss = 2.446836517407344, disc_loss = 0.0029464506459100028
Trained batch 52 in epoch 4, gen_loss = 2.4399550096044003, disc_loss = 0.003003053228757432
Trained batch 53 in epoch 4, gen_loss = 2.436139393735815, disc_loss = 0.003138299878358979
Trained batch 54 in epoch 4, gen_loss = 2.430462035265836, disc_loss = 0.0031437734882770615
Trained batch 55 in epoch 4, gen_loss = 2.4246331410748616, disc_loss = 0.003151233077265455
Trained batch 56 in epoch 4, gen_loss = 2.422150917220534, disc_loss = 0.0031590257146346724
Trained batch 57 in epoch 4, gen_loss = 2.4191601975210784, disc_loss = 0.0032033658213110575
Trained batch 58 in epoch 4, gen_loss = 2.421185440936331, disc_loss = 0.0032024714302555735
Trained batch 59 in epoch 4, gen_loss = 2.418656543890635, disc_loss = 0.003195563313784078
Trained batch 60 in epoch 4, gen_loss = 2.420940395261421, disc_loss = 0.003181585021026921
Trained batch 61 in epoch 4, gen_loss = 2.4205830481744584, disc_loss = 0.0031597715119020113
Trained batch 62 in epoch 4, gen_loss = 2.417898863080948, disc_loss = 0.0031353423615828866
Trained batch 63 in epoch 4, gen_loss = 2.4198539964854717, disc_loss = 0.0031225385864672717
Trained batch 64 in epoch 4, gen_loss = 2.4227540713090163, disc_loss = 0.003098953594095432
Trained batch 65 in epoch 4, gen_loss = 2.4190233729102393, disc_loss = 0.0030880782358122597
Trained batch 66 in epoch 4, gen_loss = 2.41828577554048, disc_loss = 0.0030690679924367968
Trained batch 67 in epoch 4, gen_loss = 2.4215738212361053, disc_loss = 0.003059499602600494
Trained batch 68 in epoch 4, gen_loss = 2.420187853384709, disc_loss = 0.003059364585340887
Trained batch 69 in epoch 4, gen_loss = 2.421019983291626, disc_loss = 0.0030559782936636893
Trained batch 70 in epoch 4, gen_loss = 2.421644052989046, disc_loss = 0.0030435735333553503
Trained batch 71 in epoch 4, gen_loss = 2.4182181424564786, disc_loss = 0.003101952044138064
Trained batch 72 in epoch 4, gen_loss = 2.4159007692990238, disc_loss = 0.003144930352852361
Trained batch 73 in epoch 4, gen_loss = 2.418561919315441, disc_loss = 0.0031598464749451423
Trained batch 74 in epoch 4, gen_loss = 2.418868703842163, disc_loss = 0.0031517568603158
Trained batch 75 in epoch 4, gen_loss = 2.416664255292792, disc_loss = 0.0031559350716538334
Trained batch 76 in epoch 4, gen_loss = 2.412212913686579, disc_loss = 0.0031614802088346574
Trained batch 77 in epoch 4, gen_loss = 2.4136727926058645, disc_loss = 0.0031803184702323796
Trained batch 78 in epoch 4, gen_loss = 2.410808892189702, disc_loss = 0.0031850009366775614
Trained batch 79 in epoch 4, gen_loss = 2.4140829175710676, disc_loss = 0.0031761825346620755
Trained batch 80 in epoch 4, gen_loss = 2.4148673481411405, disc_loss = 0.0031650778981224623
Trained batch 81 in epoch 4, gen_loss = 2.4194813065412566, disc_loss = 0.0031490384405138106
Trained batch 82 in epoch 4, gen_loss = 2.4171348020254846, disc_loss = 0.0031644067185627946
Trained batch 83 in epoch 4, gen_loss = 2.4157013297080994, disc_loss = 0.003177639267440619
Trained batch 84 in epoch 4, gen_loss = 2.4160832545336555, disc_loss = 0.0031744298210148424
Trained batch 85 in epoch 4, gen_loss = 2.415366621904595, disc_loss = 0.0031721849646960754
Trained batch 86 in epoch 4, gen_loss = 2.417206040744124, disc_loss = 0.0031665647067878953
Trained batch 87 in epoch 4, gen_loss = 2.4179056232625786, disc_loss = 0.003149548911923458
Trained batch 88 in epoch 4, gen_loss = 2.4212515488099515, disc_loss = 0.003133607556091182
Trained batch 89 in epoch 4, gen_loss = 2.423824177847968, disc_loss = 0.0031137540380263493
Trained batch 90 in epoch 4, gen_loss = 2.4262241007207512, disc_loss = 0.003098828765399918
Trained batch 91 in epoch 4, gen_loss = 2.4271863802619604, disc_loss = 0.003084392229894824
Trained batch 92 in epoch 4, gen_loss = 2.4244702349426928, disc_loss = 0.0030756414710213583
Trained batch 93 in epoch 4, gen_loss = 2.420631560873478, disc_loss = 0.004654043038286507
Trained batch 94 in epoch 4, gen_loss = 2.4194221421291955, disc_loss = 0.010736463710322584
Trained batch 95 in epoch 4, gen_loss = 2.4125791750848293, disc_loss = 0.013743550653695516
Trained batch 96 in epoch 4, gen_loss = 2.4103500855337714, disc_loss = 0.018707821492499374
Trained batch 97 in epoch 4, gen_loss = 2.4105059163911, disc_loss = 0.021800157805306038
Trained batch 98 in epoch 4, gen_loss = 2.4046299806748976, disc_loss = 0.024030362398156688
Trained batch 99 in epoch 4, gen_loss = 2.404569298028946, disc_loss = 0.025827353877248244
Trained batch 100 in epoch 4, gen_loss = 2.403465267455224, disc_loss = 0.02744024768955821
Trained batch 101 in epoch 4, gen_loss = 2.4007288018862405, disc_loss = 0.02888027693752163
Trained batch 102 in epoch 4, gen_loss = 2.395913700455601, disc_loss = 0.030158455059773208
Trained batch 103 in epoch 4, gen_loss = 2.3903769094210405, disc_loss = 0.031229236504609268
Trained batch 104 in epoch 4, gen_loss = 2.3869577771141417, disc_loss = 0.03220175616554029
Trained batch 105 in epoch 4, gen_loss = 2.3828370728582704, disc_loss = 0.03306930777638764
Trained batch 106 in epoch 4, gen_loss = 2.3782594092538423, disc_loss = 0.033735884041264305
Trained batch 107 in epoch 4, gen_loss = 2.3737964585975364, disc_loss = 0.03429295941950167
Trained batch 108 in epoch 4, gen_loss = 2.3758045599001263, disc_loss = 0.034597598273657396
Trained batch 109 in epoch 4, gen_loss = 2.3763102184642446, disc_loss = 0.03493623318764466
Trained batch 110 in epoch 4, gen_loss = 2.3750926288398535, disc_loss = 0.03535906244006411
Trained batch 111 in epoch 4, gen_loss = 2.374915389078004, disc_loss = 0.035405115607967934
Trained batch 112 in epoch 4, gen_loss = 2.374945547728412, disc_loss = 0.03544909775821673
Trained batch 113 in epoch 4, gen_loss = 2.378904371930842, disc_loss = 0.03566924598692965
Trained batch 114 in epoch 4, gen_loss = 2.3796357880467953, disc_loss = 0.03620267729173698
Trained batch 115 in epoch 4, gen_loss = 2.378304154708468, disc_loss = 0.03656395523234848
Trained batch 116 in epoch 4, gen_loss = 2.3798682485890184, disc_loss = 0.03653306834117119
Trained batch 117 in epoch 4, gen_loss = 2.3818550332117887, disc_loss = 0.03677234711950266
Trained batch 118 in epoch 4, gen_loss = 2.3776772052300075, disc_loss = 0.03817348471870098
Trained batch 119 in epoch 4, gen_loss = 2.3787324279546738, disc_loss = 0.04031931337376591
Trained batch 120 in epoch 4, gen_loss = 2.3740814027707438, disc_loss = 0.04179363951860535
Trained batch 121 in epoch 4, gen_loss = 2.372899051572456, disc_loss = 0.04262632206483118
Trained batch 122 in epoch 4, gen_loss = 2.3705373372488876, disc_loss = 0.042813455989788765
Trained batch 123 in epoch 4, gen_loss = 2.3687220254252033, disc_loss = 0.04303049423915875
Trained batch 124 in epoch 4, gen_loss = 2.367471389770508, disc_loss = 0.043027183906175194
Trained batch 125 in epoch 4, gen_loss = 2.366192562239511, disc_loss = 0.042866678362424
Trained batch 126 in epoch 4, gen_loss = 2.3676677444788417, disc_loss = 0.042738086273563715
Trained batch 127 in epoch 4, gen_loss = 2.3680660128593445, disc_loss = 0.04263156153410819
Trained batch 128 in epoch 4, gen_loss = 2.3706277858379274, disc_loss = 0.042472847124612204
Trained batch 129 in epoch 4, gen_loss = 2.369817405480605, disc_loss = 0.042265330284583166
Trained batch 130 in epoch 4, gen_loss = 2.3713309091466073, disc_loss = 0.0420339276937711
Trained batch 131 in epoch 4, gen_loss = 2.372369636188854, disc_loss = 0.04181917754767434
Trained batch 132 in epoch 4, gen_loss = 2.3724931379906216, disc_loss = 0.04160064715923587
Trained batch 133 in epoch 4, gen_loss = 2.374251977721257, disc_loss = 0.041373851320727156
Trained batch 134 in epoch 4, gen_loss = 2.3731387668185766, disc_loss = 0.04131685532715723
Trained batch 135 in epoch 4, gen_loss = 2.371097073835485, disc_loss = 0.04211620870131917
Trained batch 136 in epoch 4, gen_loss = 2.3729595024220265, disc_loss = 0.044821031487642035
Trained batch 137 in epoch 4, gen_loss = 2.371190953945768, disc_loss = 0.04534330271754711
Trained batch 138 in epoch 4, gen_loss = 2.3690763583286203, disc_loss = 0.045772314487902865
Trained batch 139 in epoch 4, gen_loss = 2.367058164732797, disc_loss = 0.04609528714874094
Trained batch 140 in epoch 4, gen_loss = 2.364297980112387, disc_loss = 0.046235675547859824
Trained batch 141 in epoch 4, gen_loss = 2.3644257431298916, disc_loss = 0.046238704926406464
Trained batch 142 in epoch 4, gen_loss = 2.365003103976483, disc_loss = 0.04624431378491405
Trained batch 143 in epoch 4, gen_loss = 2.36520315375593, disc_loss = 0.04628910764667024
Trained batch 144 in epoch 4, gen_loss = 2.367987366380363, disc_loss = 0.04626425524033478
Trained batch 145 in epoch 4, gen_loss = 2.3700229207130326, disc_loss = 0.046073522929848516
Trained batch 146 in epoch 4, gen_loss = 2.3707999096435755, disc_loss = 0.04582470563021773
Trained batch 147 in epoch 4, gen_loss = 2.371515770216246, disc_loss = 0.04559344880210513
Trained batch 148 in epoch 4, gen_loss = 2.3709267401855265, disc_loss = 0.04537696047645412
Trained batch 149 in epoch 4, gen_loss = 2.373009934425354, disc_loss = 0.04514400092962508
Trained batch 150 in epoch 4, gen_loss = 2.371748311630148, disc_loss = 0.044997014667351565
Trained batch 151 in epoch 4, gen_loss = 2.3715964273402563, disc_loss = 0.04489263077955816
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 2.334817886352539, disc_loss = 0.01903984136879444
Trained batch 1 in epoch 5, gen_loss = 2.4382004737854004, disc_loss = 0.017845417372882366
Trained batch 2 in epoch 5, gen_loss = 2.416312058766683, disc_loss = 0.015440104529261589
Trained batch 3 in epoch 5, gen_loss = 2.4930571913719177, disc_loss = 0.016547558829188347
Trained batch 4 in epoch 5, gen_loss = 2.516533041000366, disc_loss = 0.01610472723841667
Trained batch 5 in epoch 5, gen_loss = 2.483181039492289, disc_loss = 0.01476476372530063
Trained batch 6 in epoch 5, gen_loss = 2.4564288343702043, disc_loss = 0.013689865823835135
Trained batch 7 in epoch 5, gen_loss = 2.4471977055072784, disc_loss = 0.012877244444098324
Trained batch 8 in epoch 5, gen_loss = 2.439789295196533, disc_loss = 0.013670887539370192
Trained batch 9 in epoch 5, gen_loss = 2.4174822330474854, disc_loss = 0.016861285036429762
Trained batch 10 in epoch 5, gen_loss = 2.4000878767533735, disc_loss = 0.017106814606284552
Trained batch 11 in epoch 5, gen_loss = 2.4382561246554055, disc_loss = 0.01672427375645687
Trained batch 12 in epoch 5, gen_loss = 2.413131383749155, disc_loss = 0.01628892908159357
Trained batch 13 in epoch 5, gen_loss = 2.4141862392425537, disc_loss = 0.015852392351787006
Trained batch 14 in epoch 5, gen_loss = 2.4074289798736572, disc_loss = 0.015484488103538752
Trained batch 15 in epoch 5, gen_loss = 2.408631816506386, disc_loss = 0.01491011944017373
Trained batch 16 in epoch 5, gen_loss = 2.4078746402964875, disc_loss = 0.014439690693774643
Trained batch 17 in epoch 5, gen_loss = 2.4064052634769015, disc_loss = 0.014718840571327342
Trained batch 18 in epoch 5, gen_loss = 2.421172154577155, disc_loss = 0.014553491516332877
Trained batch 19 in epoch 5, gen_loss = 2.419667649269104, disc_loss = 0.015073911845684051
Trained batch 20 in epoch 5, gen_loss = 2.4103181589217413, disc_loss = 0.016177904925176075
Trained batch 21 in epoch 5, gen_loss = 2.412845015525818, disc_loss = 0.015798291699452835
Trained batch 22 in epoch 5, gen_loss = 2.4133897967960523, disc_loss = 0.01617410179713498
Trained batch 23 in epoch 5, gen_loss = 2.420177479585012, disc_loss = 0.016626950353384018
Trained batch 24 in epoch 5, gen_loss = 2.4194859981536867, disc_loss = 0.016513168960809708
Trained batch 25 in epoch 5, gen_loss = 2.419056167969337, disc_loss = 0.026384624294363536
Trained batch 26 in epoch 5, gen_loss = 2.407237688700358, disc_loss = 0.04228579239160926
Trained batch 27 in epoch 5, gen_loss = 2.3854978127138957, disc_loss = 0.045617434728358476
Trained batch 28 in epoch 5, gen_loss = 2.388756805452807, disc_loss = 0.04954357971918994
Trained batch 29 in epoch 5, gen_loss = 2.372398253281911, disc_loss = 0.05094230435788631
Trained batch 30 in epoch 5, gen_loss = 2.3643433009424517, disc_loss = 0.05243659848647733
Trained batch 31 in epoch 5, gen_loss = 2.359539922326803, disc_loss = 0.05344135838095099
Trained batch 32 in epoch 5, gen_loss = 2.365539287075852, disc_loss = 0.05357893228982434
Trained batch 33 in epoch 5, gen_loss = 2.3616045187501347, disc_loss = 0.05389830612522714
Trained batch 34 in epoch 5, gen_loss = 2.3571340322494505, disc_loss = 0.05401662098509925
Trained batch 35 in epoch 5, gen_loss = 2.356170803308487, disc_loss = 0.05388081384201845
Trained batch 36 in epoch 5, gen_loss = 2.3708590720150924, disc_loss = 0.05500379828987895
Trained batch 37 in epoch 5, gen_loss = 2.3675568260644613, disc_loss = 0.05645147024800903
Trained batch 38 in epoch 5, gen_loss = 2.387867013613383, disc_loss = 0.059122259609210186
Trained batch 39 in epoch 5, gen_loss = 2.391003540158272, disc_loss = 0.0595452481880784
Trained batch 40 in epoch 5, gen_loss = 2.387546844598724, disc_loss = 0.05940150033410003
Trained batch 41 in epoch 5, gen_loss = 2.384857646056584, disc_loss = 0.05861297985982327
Trained batch 42 in epoch 5, gen_loss = 2.3902912611185116, disc_loss = 0.05765154862473177
Trained batch 43 in epoch 5, gen_loss = 2.396414130926132, disc_loss = 0.056838401169939476
Trained batch 44 in epoch 5, gen_loss = 2.4018211550182764, disc_loss = 0.055908876802358363
Trained batch 45 in epoch 5, gen_loss = 2.4072318569473596, disc_loss = 0.05487772504515622
Trained batch 46 in epoch 5, gen_loss = 2.4086801625312644, disc_loss = 0.05390483753240489
Trained batch 47 in epoch 5, gen_loss = 2.4101309701800346, disc_loss = 0.05296640006902938
Trained batch 48 in epoch 5, gen_loss = 2.414151155218786, disc_loss = 0.05216296382096349
Trained batch 49 in epoch 5, gen_loss = 2.413775236606598, disc_loss = 0.05143919814378023
Trained batch 50 in epoch 5, gen_loss = 2.411824672829871, disc_loss = 0.05070098484044566
Trained batch 51 in epoch 5, gen_loss = 2.416745889645356, disc_loss = 0.04983691767287942
Trained batch 52 in epoch 5, gen_loss = 2.4197941433708623, disc_loss = 0.04910579810516452
Trained batch 53 in epoch 5, gen_loss = 2.4157726875057928, disc_loss = 0.04856140347611573
Trained batch 54 in epoch 5, gen_loss = 2.412730574607849, disc_loss = 0.048192538913678036
Trained batch 55 in epoch 5, gen_loss = 2.406274440033095, disc_loss = 0.0488043761911935
Trained batch 56 in epoch 5, gen_loss = 2.4120285782897684, disc_loss = 0.050867572345100996
Trained batch 57 in epoch 5, gen_loss = 2.4071735986347855, disc_loss = 0.05175691462475164
Trained batch 58 in epoch 5, gen_loss = 2.403929312350386, disc_loss = 0.051249577190285014
Trained batch 59 in epoch 5, gen_loss = 2.4064479847749074, disc_loss = 0.05082065430469811
Trained batch 60 in epoch 5, gen_loss = 2.407144356946476, disc_loss = 0.0501838714861479
Trained batch 61 in epoch 5, gen_loss = 2.405268774878594, disc_loss = 0.04953167022716615
Trained batch 62 in epoch 5, gen_loss = 2.4083852446268477, disc_loss = 0.04903906450739929
Trained batch 63 in epoch 5, gen_loss = 2.409694204106927, disc_loss = 0.04854159351089038
Trained batch 64 in epoch 5, gen_loss = 2.4118712260172916, disc_loss = 0.0479157959899077
Trained batch 65 in epoch 5, gen_loss = 2.4127141363693005, disc_loss = 0.04746864840501186
Trained batch 66 in epoch 5, gen_loss = 2.41594891227893, disc_loss = 0.04691888575456036
Trained batch 67 in epoch 5, gen_loss = 2.4150298570885376, disc_loss = 0.046340411289266366
Trained batch 68 in epoch 5, gen_loss = 2.4155788197033647, disc_loss = 0.04575805091366604
Trained batch 69 in epoch 5, gen_loss = 2.416979399749211, disc_loss = 0.04520580876352531
Trained batch 70 in epoch 5, gen_loss = 2.4164636957813315, disc_loss = 0.04465226550966921
Trained batch 71 in epoch 5, gen_loss = 2.4141839295625687, disc_loss = 0.0441040614581046
Trained batch 72 in epoch 5, gen_loss = 2.4164412789148826, disc_loss = 0.043568748942487044
Trained batch 73 in epoch 5, gen_loss = 2.4187442918081543, disc_loss = 0.04311858098702254
Trained batch 74 in epoch 5, gen_loss = 2.4183280865351358, disc_loss = 0.042604374277095
Trained batch 75 in epoch 5, gen_loss = 2.4170670932845066, disc_loss = 0.04223306785876814
Trained batch 76 in epoch 5, gen_loss = 2.4176900742889997, disc_loss = 0.042003206739371475
Trained batch 77 in epoch 5, gen_loss = 2.421105899871924, disc_loss = 0.04156077081242051
Trained batch 78 in epoch 5, gen_loss = 2.4218060351625272, disc_loss = 0.04111047831800165
Trained batch 79 in epoch 5, gen_loss = 2.420226277410984, disc_loss = 0.04066375908441842
Trained batch 80 in epoch 5, gen_loss = 2.4187455398065074, disc_loss = 0.04024685653110529
Trained batch 81 in epoch 5, gen_loss = 2.4164195860304485, disc_loss = 0.039836662486422716
Trained batch 82 in epoch 5, gen_loss = 2.4162340753049736, disc_loss = 0.03940492681597909
Trained batch 83 in epoch 5, gen_loss = 2.413650922832035, disc_loss = 0.0389869516560187
Trained batch 84 in epoch 5, gen_loss = 2.4159495984806734, disc_loss = 0.03858126230976161
Trained batch 85 in epoch 5, gen_loss = 2.4211992233298547, disc_loss = 0.03824357384122735
Trained batch 86 in epoch 5, gen_loss = 2.417177766218953, disc_loss = 0.037945783600724974
Trained batch 87 in epoch 5, gen_loss = 2.4175985387780448, disc_loss = 0.03774272246201607
Trained batch 88 in epoch 5, gen_loss = 2.42203243528859, disc_loss = 0.03745831819146537
Trained batch 89 in epoch 5, gen_loss = 2.4245737857288785, disc_loss = 0.03711421798086829
Trained batch 90 in epoch 5, gen_loss = 2.4258391660648386, disc_loss = 0.03681022005544587
Trained batch 91 in epoch 5, gen_loss = 2.430428031993949, disc_loss = 0.03648094108591423
Trained batch 92 in epoch 5, gen_loss = 2.4296038061059932, disc_loss = 0.036236740924137575
Trained batch 93 in epoch 5, gen_loss = 2.431411604932014, disc_loss = 0.03597762386631617
Trained batch 94 in epoch 5, gen_loss = 2.4319724296268665, disc_loss = 0.035670275432302764
Trained batch 95 in epoch 5, gen_loss = 2.4347100543479123, disc_loss = 0.0354128649875444
Trained batch 96 in epoch 5, gen_loss = 2.4375955333414767, disc_loss = 0.035122279140176536
Trained batch 97 in epoch 5, gen_loss = 2.4373448296469085, disc_loss = 0.034808287658367534
Trained batch 98 in epoch 5, gen_loss = 2.437688115871314, disc_loss = 0.03448971233452962
Trained batch 99 in epoch 5, gen_loss = 2.440297418832779, disc_loss = 0.03419167247600854
Trained batch 100 in epoch 5, gen_loss = 2.4379615488618906, disc_loss = 0.03390073214685268
Trained batch 101 in epoch 5, gen_loss = 2.4389096580299676, disc_loss = 0.033624091678682494
Trained batch 102 in epoch 5, gen_loss = 2.438383460044861, disc_loss = 0.03334485607908912
Trained batch 103 in epoch 5, gen_loss = 2.4388504269031377, disc_loss = 0.03306100839220632
Trained batch 104 in epoch 5, gen_loss = 2.4361852384748914, disc_loss = 0.03280457150235418
Trained batch 105 in epoch 5, gen_loss = 2.4356090673860513, disc_loss = 0.032530757198813105
Trained batch 106 in epoch 5, gen_loss = 2.4319754148198065, disc_loss = 0.032273318065835215
Trained batch 107 in epoch 5, gen_loss = 2.432262677837301, disc_loss = 0.03201640216650924
Trained batch 108 in epoch 5, gen_loss = 2.432334266671347, disc_loss = 0.03176119309260484
Trained batch 109 in epoch 5, gen_loss = 2.433375142921101, disc_loss = 0.03151265293444422
Trained batch 110 in epoch 5, gen_loss = 2.434452444583446, disc_loss = 0.03129620834983684
Trained batch 111 in epoch 5, gen_loss = 2.4369816599147662, disc_loss = 0.03113085762431313
Trained batch 112 in epoch 5, gen_loss = 2.4394213973948387, disc_loss = 0.030888650860983583
Trained batch 113 in epoch 5, gen_loss = 2.4382088215727555, disc_loss = 0.030708933647378887
Trained batch 114 in epoch 5, gen_loss = 2.436996386362159, disc_loss = 0.03048033424977051
Trained batch 115 in epoch 5, gen_loss = 2.435913740560926, disc_loss = 0.030248222477204198
Trained batch 116 in epoch 5, gen_loss = 2.437079868764959, disc_loss = 0.03003156375593673
Trained batch 117 in epoch 5, gen_loss = 2.4391967957302674, disc_loss = 0.02981176626892224
Trained batch 118 in epoch 5, gen_loss = 2.440588898017627, disc_loss = 0.029596824537446144
Trained batch 119 in epoch 5, gen_loss = 2.441414100925128, disc_loss = 0.02938389225746505
Trained batch 120 in epoch 5, gen_loss = 2.441452190895711, disc_loss = 0.029180843242605732
Trained batch 121 in epoch 5, gen_loss = 2.442509620893197, disc_loss = 0.028969546405934406
Trained batch 122 in epoch 5, gen_loss = 2.4459470045275804, disc_loss = 0.028776147955559134
Trained batch 123 in epoch 5, gen_loss = 2.4458308421796366, disc_loss = 0.0285798258996839
Trained batch 124 in epoch 5, gen_loss = 2.445567852973938, disc_loss = 0.02837245500832796
Trained batch 125 in epoch 5, gen_loss = 2.4442146590777805, disc_loss = 0.028220092929485772
Trained batch 126 in epoch 5, gen_loss = 2.446820520979213, disc_loss = 0.028119282166319568
Trained batch 127 in epoch 5, gen_loss = 2.4463553754612803, disc_loss = 0.027956887548498344
Trained batch 128 in epoch 5, gen_loss = 2.447264921757602, disc_loss = 0.02777276329638422
Trained batch 129 in epoch 5, gen_loss = 2.447851601930765, disc_loss = 0.02758781317119988
Trained batch 130 in epoch 5, gen_loss = 2.446960648507562, disc_loss = 0.027396111766885937
Trained batch 131 in epoch 5, gen_loss = 2.44683037833734, disc_loss = 0.027212987020682318
Trained batch 132 in epoch 5, gen_loss = 2.444055776847036, disc_loss = 0.027048073703759258
Trained batch 133 in epoch 5, gen_loss = 2.4430760349800336, disc_loss = 0.026896987994785296
Trained batch 134 in epoch 5, gen_loss = 2.4437368013240675, disc_loss = 0.02672251348418218
Trained batch 135 in epoch 5, gen_loss = 2.4441149436375675, disc_loss = 0.026557635533048168
Trained batch 136 in epoch 5, gen_loss = 2.442872436377254, disc_loss = 0.02639346927010121
Trained batch 137 in epoch 5, gen_loss = 2.443240565666254, disc_loss = 0.02624416736332511
Trained batch 138 in epoch 5, gen_loss = 2.443823919879447, disc_loss = 0.026073703972837158
Trained batch 139 in epoch 5, gen_loss = 2.442351781470435, disc_loss = 0.025931411633999753
Trained batch 140 in epoch 5, gen_loss = 2.4413438122323217, disc_loss = 0.025802004344246173
Trained batch 141 in epoch 5, gen_loss = 2.438545372284634, disc_loss = 0.025687203370362625
Trained batch 142 in epoch 5, gen_loss = 2.438624816341, disc_loss = 0.025555712006452097
Trained batch 143 in epoch 5, gen_loss = 2.440034166806274, disc_loss = 0.02545031225276438
Trained batch 144 in epoch 5, gen_loss = 2.439776893319755, disc_loss = 0.025307580762831815
Trained batch 145 in epoch 5, gen_loss = 2.442924144333356, disc_loss = 0.025173012171999538
Trained batch 146 in epoch 5, gen_loss = 2.441034345399766, disc_loss = 0.025117489000858396
Trained batch 147 in epoch 5, gen_loss = 2.43887382665196, disc_loss = 0.025113634895722103
Trained batch 148 in epoch 5, gen_loss = 2.4398205464318297, disc_loss = 0.02497574019920856
Trained batch 149 in epoch 5, gen_loss = 2.440066700776418, disc_loss = 0.024848876448037724
Trained batch 150 in epoch 5, gen_loss = 2.438268046505404, disc_loss = 0.024755242430228766
Trained batch 151 in epoch 5, gen_loss = 2.437962680270797, disc_loss = 0.02483360604903857
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 2.276313304901123, disc_loss = 0.07867790758609772
Trained batch 1 in epoch 6, gen_loss = 2.5926034450531006, disc_loss = 0.06932462751865387
Trained batch 2 in epoch 6, gen_loss = 2.561491092046102, disc_loss = 0.047780369563649096
Trained batch 3 in epoch 6, gen_loss = 2.515868127346039, disc_loss = 0.039354198961518705
Trained batch 4 in epoch 6, gen_loss = 2.4948076725006105, disc_loss = 0.03272834541276097
Trained batch 5 in epoch 6, gen_loss = 2.4575639963150024, disc_loss = 0.032714639867966376
Trained batch 6 in epoch 6, gen_loss = 2.4389289787837436, disc_loss = 0.032963752547012906
Trained batch 7 in epoch 6, gen_loss = 2.424193263053894, disc_loss = 0.029868029116187245
Trained batch 8 in epoch 6, gen_loss = 2.4547724193996854, disc_loss = 0.029664979471514624
Trained batch 9 in epoch 6, gen_loss = 2.4399049997329714, disc_loss = 0.028305861027911307
Trained batch 10 in epoch 6, gen_loss = 2.443599224090576, disc_loss = 0.026339140255004168
Trained batch 11 in epoch 6, gen_loss = 2.4541407028834024, disc_loss = 0.024429324509886403
Trained batch 12 in epoch 6, gen_loss = 2.4810121609614444, disc_loss = 0.022803324113528315
Trained batch 13 in epoch 6, gen_loss = 2.4680208138057163, disc_loss = 0.021559197305967764
Trained batch 14 in epoch 6, gen_loss = 2.480323489507039, disc_loss = 0.02063978163835903
Trained batch 15 in epoch 6, gen_loss = 2.4785119742155075, disc_loss = 0.019876240912708454
Trained batch 16 in epoch 6, gen_loss = 2.490926504135132, disc_loss = 0.019005774780560064
Trained batch 17 in epoch 6, gen_loss = 2.496552175945706, disc_loss = 0.01817763916268531
Trained batch 18 in epoch 6, gen_loss = 2.4819962476429187, disc_loss = 0.017409996889335543
Trained batch 19 in epoch 6, gen_loss = 2.4948219060897827, disc_loss = 0.016731831606011837
Trained batch 20 in epoch 6, gen_loss = 2.4843922342572893, disc_loss = 0.016063668931435262
Trained batch 21 in epoch 6, gen_loss = 2.4711205525831743, disc_loss = 0.015486490626988763
Trained batch 22 in epoch 6, gen_loss = 2.4667859077453613, disc_loss = 0.014938105191306575
Trained batch 23 in epoch 6, gen_loss = 2.461146096388499, disc_loss = 0.014409810605381304
Trained batch 24 in epoch 6, gen_loss = 2.462468595504761, disc_loss = 0.013920673113316297
Trained batch 25 in epoch 6, gen_loss = 2.4549216215427103, disc_loss = 0.013485258830209764
Trained batch 26 in epoch 6, gen_loss = 2.45345256946705, disc_loss = 0.013084025734483643
Trained batch 27 in epoch 6, gen_loss = 2.4453090769904002, disc_loss = 0.012711005210543849
Trained batch 28 in epoch 6, gen_loss = 2.4419964181965796, disc_loss = 0.012380910202346999
Trained batch 29 in epoch 6, gen_loss = 2.429499928156535, disc_loss = 0.012073877065752943
Trained batch 30 in epoch 6, gen_loss = 2.422737229254938, disc_loss = 0.01176689615503194
Trained batch 31 in epoch 6, gen_loss = 2.4280188605189323, disc_loss = 0.011524619498231914
Trained batch 32 in epoch 6, gen_loss = 2.4225482073697178, disc_loss = 0.011265418746254661
Trained batch 33 in epoch 6, gen_loss = 2.4208748621099136, disc_loss = 0.010997286792296697
Trained batch 34 in epoch 6, gen_loss = 2.4320476804460798, disc_loss = 0.010746093187481164
Trained batch 35 in epoch 6, gen_loss = 2.4303038318951926, disc_loss = 0.010519500032791661
Trained batch 36 in epoch 6, gen_loss = 2.4306805262694486, disc_loss = 0.010311208766054463
Trained batch 37 in epoch 6, gen_loss = 2.4168330587838827, disc_loss = 0.012974614865685763
Trained batch 38 in epoch 6, gen_loss = 2.410304842851101, disc_loss = 0.015578948821012791
Trained batch 39 in epoch 6, gen_loss = 2.4100712925195693, disc_loss = 0.015901908092200757
Trained batch 40 in epoch 6, gen_loss = 2.4085443979356347, disc_loss = 0.015660287687418666
Trained batch 41 in epoch 6, gen_loss = 2.4155692060788474, disc_loss = 0.015449025834511434
Trained batch 42 in epoch 6, gen_loss = 2.4202065717342287, disc_loss = 0.015211849484246137
Trained batch 43 in epoch 6, gen_loss = 2.410489423708482, disc_loss = 0.015065698069520295
Trained batch 44 in epoch 6, gen_loss = 2.4108383867475722, disc_loss = 0.014858361447436942
Trained batch 45 in epoch 6, gen_loss = 2.407541891802912, disc_loss = 0.014751825005868855
Trained batch 46 in epoch 6, gen_loss = 2.4134499012155737, disc_loss = 0.014584796225770991
Trained batch 47 in epoch 6, gen_loss = 2.408888190984726, disc_loss = 0.014403017160172263
Trained batch 48 in epoch 6, gen_loss = 2.4120863213831063, disc_loss = 0.014187339607778252
Trained batch 49 in epoch 6, gen_loss = 2.4150248622894286, disc_loss = 0.013959162044338882
Trained batch 50 in epoch 6, gen_loss = 2.4113937966963825, disc_loss = 0.013729783441579225
Trained batch 51 in epoch 6, gen_loss = 2.4085217943558326, disc_loss = 0.013531312547946492
Trained batch 52 in epoch 6, gen_loss = 2.4112589449252724, disc_loss = 0.013336808425110747
Trained batch 53 in epoch 6, gen_loss = 2.407522099989432, disc_loss = 0.013179588377372257
Trained batch 54 in epoch 6, gen_loss = 2.408035677129572, disc_loss = 0.012997911307452755
Trained batch 55 in epoch 6, gen_loss = 2.4091510432107106, disc_loss = 0.012828754294397575
Trained batch 56 in epoch 6, gen_loss = 2.4082742783061244, disc_loss = 0.012676517136002841
Trained batch 57 in epoch 6, gen_loss = 2.40529361264459, disc_loss = 0.012565682618075917
Trained batch 58 in epoch 6, gen_loss = 2.4043199813972085, disc_loss = 0.012418767879322425
Trained batch 59 in epoch 6, gen_loss = 2.397097444534302, disc_loss = 0.014675228763371706
Trained batch 60 in epoch 6, gen_loss = 2.3950012668234404, disc_loss = 0.016458401761826922
Trained batch 61 in epoch 6, gen_loss = 2.389831377613929, disc_loss = 0.016820127294669227
Trained batch 62 in epoch 6, gen_loss = 2.3930268817477756, disc_loss = 0.017062094328658923
Trained batch 63 in epoch 6, gen_loss = 2.3910613507032394, disc_loss = 0.017006241687340662
Trained batch 64 in epoch 6, gen_loss = 2.387267439181988, disc_loss = 0.016828403163414735
Trained batch 65 in epoch 6, gen_loss = 2.388350233887181, disc_loss = 0.016776260256654386
Trained batch 66 in epoch 6, gen_loss = 2.38540472201447, disc_loss = 0.01661563157312461
Trained batch 67 in epoch 6, gen_loss = 2.390791829894571, disc_loss = 0.01651342141935054
Trained batch 68 in epoch 6, gen_loss = 2.3889291010041167, disc_loss = 0.016319048348004402
Trained batch 69 in epoch 6, gen_loss = 2.387871643475124, disc_loss = 0.016146943046312246
Trained batch 70 in epoch 6, gen_loss = 2.39160500445836, disc_loss = 0.015969494321632763
Trained batch 71 in epoch 6, gen_loss = 2.3916210896439023, disc_loss = 0.015816269937204197
Trained batch 72 in epoch 6, gen_loss = 2.3907044064508725, disc_loss = 0.01563196697540275
Trained batch 73 in epoch 6, gen_loss = 2.390414614935179, disc_loss = 0.015466304275685468
Trained batch 74 in epoch 6, gen_loss = 2.3900647894541422, disc_loss = 0.015317194381107886
Trained batch 75 in epoch 6, gen_loss = 2.390465679921602, disc_loss = 0.01517594201294215
Trained batch 76 in epoch 6, gen_loss = 2.389500655137099, disc_loss = 0.015010247218676588
Trained batch 77 in epoch 6, gen_loss = 2.387260629580571, disc_loss = 0.014847550308331847
Trained batch 78 in epoch 6, gen_loss = 2.386540922937514, disc_loss = 0.014698590278696222
Trained batch 79 in epoch 6, gen_loss = 2.390988138318062, disc_loss = 0.014578587005962618
Trained batch 80 in epoch 6, gen_loss = 2.389503864594448, disc_loss = 0.014478204774750788
Trained batch 81 in epoch 6, gen_loss = 2.3879653215408325, disc_loss = 0.014347176504798415
Trained batch 82 in epoch 6, gen_loss = 2.3912950136575355, disc_loss = 0.014220978871144983
Trained batch 83 in epoch 6, gen_loss = 2.392508577732813, disc_loss = 0.014089277185987504
Trained batch 84 in epoch 6, gen_loss = 2.397938316008624, disc_loss = 0.013959506469066529
Trained batch 85 in epoch 6, gen_loss = 2.3960315820782685, disc_loss = 0.013849811409166905
Trained batch 86 in epoch 6, gen_loss = 2.396815604177015, disc_loss = 0.013718375526689764
Trained batch 87 in epoch 6, gen_loss = 2.3965197720310907, disc_loss = 0.013601425479547206
Trained batch 88 in epoch 6, gen_loss = 2.3943065311131853, disc_loss = 0.013477728265243467
Trained batch 89 in epoch 6, gen_loss = 2.393267125553555, disc_loss = 0.013372673148599764
Trained batch 90 in epoch 6, gen_loss = 2.3953934423216094, disc_loss = 0.013270576978307013
Trained batch 91 in epoch 6, gen_loss = 2.396498265473739, disc_loss = 0.013170805853366366
Trained batch 92 in epoch 6, gen_loss = 2.3952108762597524, disc_loss = 0.013049838386015386
Trained batch 93 in epoch 6, gen_loss = 2.3960056939023606, disc_loss = 0.012949991785485218
Trained batch 94 in epoch 6, gen_loss = 2.3923374125832004, disc_loss = 0.012845340503477737
Trained batch 95 in epoch 6, gen_loss = 2.3906037136912346, disc_loss = 0.012766254352754913
Trained batch 96 in epoch 6, gen_loss = 2.3899854360167514, disc_loss = 0.012707413510256206
Trained batch 97 in epoch 6, gen_loss = 2.3865138000371506, disc_loss = 0.012638392078937317
Trained batch 98 in epoch 6, gen_loss = 2.385391004157789, disc_loss = 0.012569265741139951
Trained batch 99 in epoch 6, gen_loss = 2.387952375411987, disc_loss = 0.01248322483152151
Trained batch 100 in epoch 6, gen_loss = 2.386794326328995, disc_loss = 0.012384448050622745
Trained batch 101 in epoch 6, gen_loss = 2.3946005246218514, disc_loss = 0.012431036806482748
Trained batch 102 in epoch 6, gen_loss = 2.393885707392276, disc_loss = 0.012447494975047059
Trained batch 103 in epoch 6, gen_loss = 2.3941853665388546, disc_loss = 0.012377171085413115
Trained batch 104 in epoch 6, gen_loss = 2.3951210998353503, disc_loss = 0.012295378476292605
Trained batch 105 in epoch 6, gen_loss = 2.3971637689842367, disc_loss = 0.012205909439011143
Trained batch 106 in epoch 6, gen_loss = 2.399943634728405, disc_loss = 0.012116957508097185
Trained batch 107 in epoch 6, gen_loss = 2.4004466357054532, disc_loss = 0.012032188343625792
Trained batch 108 in epoch 6, gen_loss = 2.398637399760955, disc_loss = 0.01194133802846826
Trained batch 109 in epoch 6, gen_loss = 2.397608839381825, disc_loss = 0.011852284959009425
Trained batch 110 in epoch 6, gen_loss = 2.3988068962956333, disc_loss = 0.011759703783821818
Trained batch 111 in epoch 6, gen_loss = 2.4010906921965733, disc_loss = 0.011669774319411122
Trained batch 112 in epoch 6, gen_loss = 2.4000584572817374, disc_loss = 0.011587099238109272
Trained batch 113 in epoch 6, gen_loss = 2.398026759164375, disc_loss = 0.011648679013249645
Trained batch 114 in epoch 6, gen_loss = 2.3982003149778945, disc_loss = 0.011653557160626287
Trained batch 115 in epoch 6, gen_loss = 2.3987173438072205, disc_loss = 0.011617515894488013
Trained batch 116 in epoch 6, gen_loss = 2.3992844178126407, disc_loss = 0.01160877361957334
Trained batch 117 in epoch 6, gen_loss = 2.3999518014616887, disc_loss = 0.011536077128612768
Trained batch 118 in epoch 6, gen_loss = 2.3982163397203973, disc_loss = 0.011474438549700278
Trained batch 119 in epoch 6, gen_loss = 2.3985112686951955, disc_loss = 0.011404083768138663
Trained batch 120 in epoch 6, gen_loss = 2.398352008220578, disc_loss = 0.011353356600161795
Trained batch 121 in epoch 6, gen_loss = 2.398880051784828, disc_loss = 0.011330952285788953
Trained batch 122 in epoch 6, gen_loss = 2.40175888208839, disc_loss = 0.011292123476164491
Trained batch 123 in epoch 6, gen_loss = 2.4012802108641593, disc_loss = 0.01123852228122433
Trained batch 124 in epoch 6, gen_loss = 2.400763931274414, disc_loss = 0.011180488551035523
Trained batch 125 in epoch 6, gen_loss = 2.4035892827170238, disc_loss = 0.011108538446327051
Trained batch 126 in epoch 6, gen_loss = 2.403352444566141, disc_loss = 0.011038982580731235
Trained batch 127 in epoch 6, gen_loss = 2.405404608696699, disc_loss = 0.010969900271447841
Trained batch 128 in epoch 6, gen_loss = 2.4058167952899785, disc_loss = 0.010897532877035786
Trained batch 129 in epoch 6, gen_loss = 2.4064549629504866, disc_loss = 0.010843616345216736
Trained batch 130 in epoch 6, gen_loss = 2.409547487288031, disc_loss = 0.010786412778765474
Trained batch 131 in epoch 6, gen_loss = 2.4067913763450854, disc_loss = 0.010738172177683957
Trained batch 132 in epoch 6, gen_loss = 2.4058223917968293, disc_loss = 0.010706612046394861
Trained batch 133 in epoch 6, gen_loss = 2.405659695169819, disc_loss = 0.010642528138644716
Trained batch 134 in epoch 6, gen_loss = 2.4054235228785763, disc_loss = 0.01058494954076768
Trained batch 135 in epoch 6, gen_loss = 2.405170828104019, disc_loss = 0.010521402032121414
Trained batch 136 in epoch 6, gen_loss = 2.4047287032552007, disc_loss = 0.010459585364289365
Trained batch 137 in epoch 6, gen_loss = 2.405339128729226, disc_loss = 0.010398427647896166
Trained batch 138 in epoch 6, gen_loss = 2.4055238010214386, disc_loss = 0.010338457524876962
Trained batch 139 in epoch 6, gen_loss = 2.4066527026040214, disc_loss = 0.010273352577184727
Trained batch 140 in epoch 6, gen_loss = 2.4060213785644966, disc_loss = 0.010212291135280955
Trained batch 141 in epoch 6, gen_loss = 2.4057639467884115, disc_loss = 0.010163084188194185
Trained batch 142 in epoch 6, gen_loss = 2.4061126959073795, disc_loss = 0.01011513503694946
Trained batch 143 in epoch 6, gen_loss = 2.4067923525969186, disc_loss = 0.01007000021167591
Trained batch 144 in epoch 6, gen_loss = 2.405835672904705, disc_loss = 0.010014860880368485
Trained batch 145 in epoch 6, gen_loss = 2.408072776990394, disc_loss = 0.009975683271776477
Trained batch 146 in epoch 6, gen_loss = 2.409739807349484, disc_loss = 0.009926748752663686
Trained batch 147 in epoch 6, gen_loss = 2.4101788272728792, disc_loss = 0.009877636140634029
Trained batch 148 in epoch 6, gen_loss = 2.4093733361903453, disc_loss = 0.009824824065513809
Trained batch 149 in epoch 6, gen_loss = 2.412154639561971, disc_loss = 0.009795245257361482
Trained batch 150 in epoch 6, gen_loss = 2.4113725779072337, disc_loss = 0.00975290135347858
Trained batch 151 in epoch 6, gen_loss = 2.4109186828136444, disc_loss = 0.009705074931844138
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 2.514716625213623, disc_loss = 0.003170458134263754
Trained batch 1 in epoch 7, gen_loss = 2.4808170795440674, disc_loss = 0.002935069380328059
Trained batch 2 in epoch 7, gen_loss = 2.470557610193888, disc_loss = 0.0025467823337142668
Trained batch 3 in epoch 7, gen_loss = 2.5005932450294495, disc_loss = 0.0025178845098707825
Trained batch 4 in epoch 7, gen_loss = 2.4512861728668214, disc_loss = 0.002594500803388655
Trained batch 5 in epoch 7, gen_loss = 2.4615870316823325, disc_loss = 0.0027988162473775446
Trained batch 6 in epoch 7, gen_loss = 2.4751703398568288, disc_loss = 0.002653085410461894
Trained batch 7 in epoch 7, gen_loss = 2.4516193866729736, disc_loss = 0.002588634015410207
Trained batch 8 in epoch 7, gen_loss = 2.4098010857899985, disc_loss = 0.007412218475817806
Trained batch 9 in epoch 7, gen_loss = 2.3741734266281127, disc_loss = 0.03829970963997766
Trained batch 10 in epoch 7, gen_loss = 2.378324183550748, disc_loss = 0.04478626637931236
Trained batch 11 in epoch 7, gen_loss = 2.369574030240377, disc_loss = 0.050838005486487724
Trained batch 12 in epoch 7, gen_loss = 2.363853784707876, disc_loss = 0.05303312729721746
Trained batch 13 in epoch 7, gen_loss = 2.34638249874115, disc_loss = 0.05325171516908865
Trained batch 14 in epoch 7, gen_loss = 2.3491348107655843, disc_loss = 0.05197789326775819
Trained batch 15 in epoch 7, gen_loss = 2.3561132699251175, disc_loss = 0.05010830150422407
Trained batch 16 in epoch 7, gen_loss = 2.3506970826317284, disc_loss = 0.04835106831673971
Trained batch 17 in epoch 7, gen_loss = 2.377715786298116, disc_loss = 0.046986226451634944
Trained batch 18 in epoch 7, gen_loss = 2.3561949290727315, disc_loss = 0.04724888115704648
Trained batch 19 in epoch 7, gen_loss = 2.3669601738452912, disc_loss = 0.05130575452349149
Trained batch 20 in epoch 7, gen_loss = 2.354804373922802, disc_loss = 0.050593572574490236
Trained batch 21 in epoch 7, gen_loss = 2.3642529303377326, disc_loss = 0.04948145171775567
Trained batch 22 in epoch 7, gen_loss = 2.356224915255671, disc_loss = 0.04913369731714382
Trained batch 23 in epoch 7, gen_loss = 2.3626386572917304, disc_loss = 0.04756811435314982
Trained batch 24 in epoch 7, gen_loss = 2.3624122762680053, disc_loss = 0.046052573691122235
Trained batch 25 in epoch 7, gen_loss = 2.3626248790667606, disc_loss = 0.04452495428715618
Trained batch 26 in epoch 7, gen_loss = 2.357903935291149, disc_loss = 0.04351337179455354
Trained batch 27 in epoch 7, gen_loss = 2.356849334069661, disc_loss = 0.04239649898954667
Trained batch 28 in epoch 7, gen_loss = 2.3499113650157533, disc_loss = 0.041287913191902996
Trained batch 29 in epoch 7, gen_loss = 2.3508025209108987, disc_loss = 0.04003706724615767
Trained batch 30 in epoch 7, gen_loss = 2.3499161851021553, disc_loss = 0.03894771379794205
Trained batch 31 in epoch 7, gen_loss = 2.3654936961829662, disc_loss = 0.0378332540167321
Trained batch 32 in epoch 7, gen_loss = 2.3719283631353667, disc_loss = 0.036836213478112986
Trained batch 33 in epoch 7, gen_loss = 2.378428925486172, disc_loss = 0.03584534296533093
Trained batch 34 in epoch 7, gen_loss = 2.3704423597880773, disc_loss = 0.035131078050471845
Trained batch 35 in epoch 7, gen_loss = 2.3575365675820246, disc_loss = 0.0345732437466116
Trained batch 36 in epoch 7, gen_loss = 2.3551744383734627, disc_loss = 0.03465971091095157
Trained batch 37 in epoch 7, gen_loss = 2.357504919955605, disc_loss = 0.03418381112370346
Trained batch 38 in epoch 7, gen_loss = 2.3597631332201834, disc_loss = 0.03345062184589318
Trained batch 39 in epoch 7, gen_loss = 2.359166479110718, disc_loss = 0.032675641149398874
Trained batch 40 in epoch 7, gen_loss = 2.361087240823885, disc_loss = 0.031969995399732595
Trained batch 41 in epoch 7, gen_loss = 2.356920679410299, disc_loss = 0.031260627845767885
Trained batch 42 in epoch 7, gen_loss = 2.357973436976588, disc_loss = 0.03064876408478635
Trained batch 43 in epoch 7, gen_loss = 2.3554555665362966, disc_loss = 0.03008462096278725
Trained batch 44 in epoch 7, gen_loss = 2.357109848658244, disc_loss = 0.029493790422566234
Trained batch 45 in epoch 7, gen_loss = 2.3685228876445605, disc_loss = 0.028929005308663876
Trained batch 46 in epoch 7, gen_loss = 2.36849626074446, disc_loss = 0.02838540262730911
Trained batch 47 in epoch 7, gen_loss = 2.37102705736955, disc_loss = 0.027970796482501708
Trained batch 48 in epoch 7, gen_loss = 2.373631156220728, disc_loss = 0.027474681288479085
Trained batch 49 in epoch 7, gen_loss = 2.3667860078811644, disc_loss = 0.027033694128040225
Trained batch 50 in epoch 7, gen_loss = 2.3643970536250696, disc_loss = 0.026602081682843465
Trained batch 51 in epoch 7, gen_loss = 2.3683529679591837, disc_loss = 0.02612839172853945
Trained batch 52 in epoch 7, gen_loss = 2.368723468960456, disc_loss = 0.025711709468730918
Trained batch 53 in epoch 7, gen_loss = 2.3685455278114036, disc_loss = 0.025283099956275826
Trained batch 54 in epoch 7, gen_loss = 2.3640030774203216, disc_loss = 0.024882165238853882
Trained batch 55 in epoch 7, gen_loss = 2.3613828165190562, disc_loss = 0.02449983016413171
Trained batch 56 in epoch 7, gen_loss = 2.362282351443642, disc_loss = 0.024105978118696886
Trained batch 57 in epoch 7, gen_loss = 2.3656982265669724, disc_loss = 0.023731918288956814
Trained batch 58 in epoch 7, gen_loss = 2.3612751637474965, disc_loss = 0.023363751302062835
Trained batch 59 in epoch 7, gen_loss = 2.3639010787010193, disc_loss = 0.023011799527254576
Trained batch 60 in epoch 7, gen_loss = 2.3636209964752197, disc_loss = 0.02268727283092735
Trained batch 61 in epoch 7, gen_loss = 2.369028933586613, disc_loss = 0.02244572412605668
Trained batch 62 in epoch 7, gen_loss = 2.366857536255367, disc_loss = 0.022136105034160355
Trained batch 63 in epoch 7, gen_loss = 2.372039619833231, disc_loss = 0.021841494091859204
Trained batch 64 in epoch 7, gen_loss = 2.3694528616391697, disc_loss = 0.021542501813158966
Trained batch 65 in epoch 7, gen_loss = 2.3721949620680376, disc_loss = 0.021270013998163806
Trained batch 66 in epoch 7, gen_loss = 2.374068021774292, disc_loss = 0.02099641988839287
Trained batch 67 in epoch 7, gen_loss = 2.375847774393418, disc_loss = 0.02083920028149698
Trained batch 68 in epoch 7, gen_loss = 2.3744063100953032, disc_loss = 0.020651677928770474
Trained batch 69 in epoch 7, gen_loss = 2.368907310281481, disc_loss = 0.02042700379721022
Trained batch 70 in epoch 7, gen_loss = 2.3656007488008957, disc_loss = 0.02017390980011403
Trained batch 71 in epoch 7, gen_loss = 2.3676610307561026, disc_loss = 0.01996192425495893
Trained batch 72 in epoch 7, gen_loss = 2.3692781418970186, disc_loss = 0.019725066990821227
Trained batch 73 in epoch 7, gen_loss = 2.3708502908010742, disc_loss = 0.01948510533091738
Trained batch 74 in epoch 7, gen_loss = 2.373058590888977, disc_loss = 0.01928282751236111
Trained batch 75 in epoch 7, gen_loss = 2.3719007670879364, disc_loss = 0.01910487428693542
Trained batch 76 in epoch 7, gen_loss = 2.3736509487226414, disc_loss = 0.018898581773006393
Trained batch 77 in epoch 7, gen_loss = 2.373179797942822, disc_loss = 0.018680702274044354
Trained batch 78 in epoch 7, gen_loss = 2.3733707334421856, disc_loss = 0.01846851487172461
Trained batch 79 in epoch 7, gen_loss = 2.3781251683831215, disc_loss = 0.01825529626221396
Trained batch 80 in epoch 7, gen_loss = 2.3776510306346563, disc_loss = 0.01804713022257029
Trained batch 81 in epoch 7, gen_loss = 2.374755116497598, disc_loss = 0.017880339293297742
Trained batch 82 in epoch 7, gen_loss = 2.3735635926924554, disc_loss = 0.01770822325558682
Trained batch 83 in epoch 7, gen_loss = 2.3738070655436743, disc_loss = 0.017543164113747133
Trained batch 84 in epoch 7, gen_loss = 2.3740084521910725, disc_loss = 0.017381464392768546
Trained batch 85 in epoch 7, gen_loss = 2.376073475493941, disc_loss = 0.01721995658116675
Trained batch 86 in epoch 7, gen_loss = 2.3743779289311377, disc_loss = 0.017046331777237356
Trained batch 87 in epoch 7, gen_loss = 2.3776754669167777, disc_loss = 0.016934217098010282
Trained batch 88 in epoch 7, gen_loss = 2.381685019878859, disc_loss = 0.01676895600361645
Trained batch 89 in epoch 7, gen_loss = 2.385361773437924, disc_loss = 0.016619294226014367
Trained batch 90 in epoch 7, gen_loss = 2.386545559862158, disc_loss = 0.016477441790022446
Trained batch 91 in epoch 7, gen_loss = 2.38832117293192, disc_loss = 0.016327666109883347
Trained batch 92 in epoch 7, gen_loss = 2.3884356162881337, disc_loss = 0.016169762858490068
Trained batch 93 in epoch 7, gen_loss = 2.3869863710504897, disc_loss = 0.01603120874410416
Trained batch 94 in epoch 7, gen_loss = 2.3886126781764783, disc_loss = 0.0158788663359653
Trained batch 95 in epoch 7, gen_loss = 2.3892544520397982, disc_loss = 0.015741677137460403
Trained batch 96 in epoch 7, gen_loss = 2.387141725451676, disc_loss = 0.015599776537051982
Trained batch 97 in epoch 7, gen_loss = 2.3859048777697036, disc_loss = 0.015463688375181233
Trained batch 98 in epoch 7, gen_loss = 2.384527751893708, disc_loss = 0.015327982515134293
Trained batch 99 in epoch 7, gen_loss = 2.3853045046329497, disc_loss = 0.015200369232334197
Trained batch 100 in epoch 7, gen_loss = 2.3855859985445984, disc_loss = 0.01506738021213672
Trained batch 101 in epoch 7, gen_loss = 2.390671371244917, disc_loss = 0.014938632163273938
Trained batch 102 in epoch 7, gen_loss = 2.3884366287768466, disc_loss = 0.01484644000228603
Trained batch 103 in epoch 7, gen_loss = 2.387454636968099, disc_loss = 0.014726054021873726
Trained batch 104 in epoch 7, gen_loss = 2.389565003485907, disc_loss = 0.014622170859504314
Trained batch 105 in epoch 7, gen_loss = 2.389135980381156, disc_loss = 0.014520022530495277
Trained batch 106 in epoch 7, gen_loss = 2.389637250766576, disc_loss = 0.014396264120962506
Trained batch 107 in epoch 7, gen_loss = 2.3916156038090035, disc_loss = 0.014281362052618837
Trained batch 108 in epoch 7, gen_loss = 2.3898450792382615, disc_loss = 0.014172333105757764
Trained batch 109 in epoch 7, gen_loss = 2.391657609289343, disc_loss = 0.014074597354258665
Trained batch 110 in epoch 7, gen_loss = 2.3919569919775197, disc_loss = 0.01396724721731467
Trained batch 111 in epoch 7, gen_loss = 2.3924097770026753, disc_loss = 0.013864056389138568
Trained batch 112 in epoch 7, gen_loss = 2.3915721642232572, disc_loss = 0.013763307147675844
Trained batch 113 in epoch 7, gen_loss = 2.390804436123162, disc_loss = 0.01365822174467898
Trained batch 114 in epoch 7, gen_loss = 2.3900095348772794, disc_loss = 0.013555827166925629
Trained batch 115 in epoch 7, gen_loss = 2.3904550106360993, disc_loss = 0.01345141862563243
Trained batch 116 in epoch 7, gen_loss = 2.3908083204530244, disc_loss = 0.013348909037219536
Trained batch 117 in epoch 7, gen_loss = 2.389205095121416, disc_loss = 0.013249479327942798
Trained batch 118 in epoch 7, gen_loss = 2.387812827815529, disc_loss = 0.013154434441283596
Trained batch 119 in epoch 7, gen_loss = 2.386228759090106, disc_loss = 0.013060142109558607
Trained batch 120 in epoch 7, gen_loss = 2.3855837366797705, disc_loss = 0.012983036040874921
Trained batch 121 in epoch 7, gen_loss = 2.3848367880602352, disc_loss = 0.012896074814202844
Trained batch 122 in epoch 7, gen_loss = 2.384764767274624, disc_loss = 0.01280554122579231
Trained batch 123 in epoch 7, gen_loss = 2.3861886426325767, disc_loss = 0.01271464823249487
Trained batch 124 in epoch 7, gen_loss = 2.3883086099624635, disc_loss = 0.012624849830754101
Trained batch 125 in epoch 7, gen_loss = 2.3901884167913408, disc_loss = 0.01253702365590023
Trained batch 126 in epoch 7, gen_loss = 2.3885486398156233, disc_loss = 0.012461812947656754
Trained batch 127 in epoch 7, gen_loss = 2.387094127945602, disc_loss = 0.012386216881168366
Trained batch 128 in epoch 7, gen_loss = 2.387202165847601, disc_loss = 0.012307002691934679
Trained batch 129 in epoch 7, gen_loss = 2.386811316013336, disc_loss = 0.012223075564879064
Trained batch 130 in epoch 7, gen_loss = 2.385358665735667, disc_loss = 0.012145368988405316
Trained batch 131 in epoch 7, gen_loss = 2.385592978109013, disc_loss = 0.012071550321045586
Trained batch 132 in epoch 7, gen_loss = 2.3866098509695295, disc_loss = 0.011991595266442886
Trained batch 133 in epoch 7, gen_loss = 2.3881445971887505, disc_loss = 0.01192131984471552
Trained batch 134 in epoch 7, gen_loss = 2.390644477031849, disc_loss = 0.011868842313480047
Trained batch 135 in epoch 7, gen_loss = 2.3910618871450424, disc_loss = 0.01180748613927897
Trained batch 136 in epoch 7, gen_loss = 2.3882245277836374, disc_loss = 0.01173813849769152
Trained batch 137 in epoch 7, gen_loss = 2.3871823385141897, disc_loss = 0.011674314683330233
Trained batch 138 in epoch 7, gen_loss = 2.386632451908194, disc_loss = 0.011607239808445033
Trained batch 139 in epoch 7, gen_loss = 2.389369033915656, disc_loss = 0.011555830507339644
Trained batch 140 in epoch 7, gen_loss = 2.388453814154821, disc_loss = 0.011488493706978171
Trained batch 141 in epoch 7, gen_loss = 2.385438604254118, disc_loss = 0.011442559321974995
Trained batch 142 in epoch 7, gen_loss = 2.3877595296272864, disc_loss = 0.011413123530264083
Trained batch 143 in epoch 7, gen_loss = 2.388309088846048, disc_loss = 0.011365836224285886
Trained batch 144 in epoch 7, gen_loss = 2.387788102544587, disc_loss = 0.011302855352325173
Trained batch 145 in epoch 7, gen_loss = 2.3863878176636892, disc_loss = 0.011236988670632804
Trained batch 146 in epoch 7, gen_loss = 2.3882038131052132, disc_loss = 0.011179971105583823
Trained batch 147 in epoch 7, gen_loss = 2.3858578503131866, disc_loss = 0.011128151395225999
Trained batch 148 in epoch 7, gen_loss = 2.3854018833813253, disc_loss = 0.011067688229943832
Trained batch 149 in epoch 7, gen_loss = 2.3864317107200623, disc_loss = 0.01101652080581213
Trained batch 150 in epoch 7, gen_loss = 2.386214233392122, disc_loss = 0.01095495063392137
Trained batch 151 in epoch 7, gen_loss = 2.3851713702866904, disc_loss = 0.010895881467915484
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 2.4789509773254395, disc_loss = 0.002816983498632908
Trained batch 1 in epoch 8, gen_loss = 2.6138665676116943, disc_loss = 0.0030141157330945134
Trained batch 2 in epoch 8, gen_loss = 2.4362691243489585, disc_loss = 0.0026786739472299814
Trained batch 3 in epoch 8, gen_loss = 2.3755643367767334, disc_loss = 0.002621067629661411
Trained batch 4 in epoch 8, gen_loss = 2.4580099105834963, disc_loss = 0.0025104778353124855
Trained batch 5 in epoch 8, gen_loss = 2.4541549682617188, disc_loss = 0.002426729343521098
Trained batch 6 in epoch 8, gen_loss = 2.4492548874446323, disc_loss = 0.0022875123790332247
Trained batch 7 in epoch 8, gen_loss = 2.4200946390628815, disc_loss = 0.002257992746308446
Trained batch 8 in epoch 8, gen_loss = 2.406102630827162, disc_loss = 0.002274393905988998
Trained batch 9 in epoch 8, gen_loss = 2.404224991798401, disc_loss = 0.00219248728826642
Trained batch 10 in epoch 8, gen_loss = 2.434825745495883, disc_loss = 0.002124638423662294
Trained batch 11 in epoch 8, gen_loss = 2.4200897415479026, disc_loss = 0.002048536562748874
Trained batch 12 in epoch 8, gen_loss = 2.4429321655860314, disc_loss = 0.002084754595461373
Trained batch 13 in epoch 8, gen_loss = 2.4177048206329346, disc_loss = 0.0021331958289790365
Trained batch 14 in epoch 8, gen_loss = 2.406938330332438, disc_loss = 0.0021491598105058073
Trained batch 15 in epoch 8, gen_loss = 2.399669885635376, disc_loss = 0.002109540182573255
Trained batch 16 in epoch 8, gen_loss = 2.4385374714346493, disc_loss = 0.00221884496482637
Trained batch 17 in epoch 8, gen_loss = 2.4423952367570667, disc_loss = 0.002242705830010689
Trained batch 18 in epoch 8, gen_loss = 2.4341995590611507, disc_loss = 0.002213963289058914
Trained batch 19 in epoch 8, gen_loss = 2.4378990650177004, disc_loss = 0.002188297768589109
Trained batch 20 in epoch 8, gen_loss = 2.446591309138707, disc_loss = 0.002171835889818058
Trained batch 21 in epoch 8, gen_loss = 2.4566462256691675, disc_loss = 0.00217848153128712
Trained batch 22 in epoch 8, gen_loss = 2.4547730425129766, disc_loss = 0.002140609542434306
Trained batch 23 in epoch 8, gen_loss = 2.4418054620424905, disc_loss = 0.002159998048834192
Trained batch 24 in epoch 8, gen_loss = 2.425821399688721, disc_loss = 0.0022627334436401726
Trained batch 25 in epoch 8, gen_loss = 2.4195350867051344, disc_loss = 0.0023186154117306266
Trained batch 26 in epoch 8, gen_loss = 2.414696764062952, disc_loss = 0.002308768095207159
Trained batch 27 in epoch 8, gen_loss = 2.418633895260947, disc_loss = 0.0022841331249635133
Trained batch 28 in epoch 8, gen_loss = 2.4153565702767206, disc_loss = 0.002317414795658712
Trained batch 29 in epoch 8, gen_loss = 2.411172850926717, disc_loss = 0.0023143091316645344
Trained batch 30 in epoch 8, gen_loss = 2.4019190880560104, disc_loss = 0.002327032454852616
Trained batch 31 in epoch 8, gen_loss = 2.4055362716317177, disc_loss = 0.002306344438693486
Trained batch 32 in epoch 8, gen_loss = 2.4141815647934424, disc_loss = 0.0022896168344287257
Trained batch 33 in epoch 8, gen_loss = 2.4162542819976807, disc_loss = 0.0023181107484132927
Trained batch 34 in epoch 8, gen_loss = 2.417451306751796, disc_loss = 0.002283623578426029
Trained batch 35 in epoch 8, gen_loss = 2.4184699257214866, disc_loss = 0.002300144228178801
Trained batch 36 in epoch 8, gen_loss = 2.4195831273053146, disc_loss = 0.0022717252077937527
Trained batch 37 in epoch 8, gen_loss = 2.41820636548494, disc_loss = 0.002270629914403942
Trained batch 38 in epoch 8, gen_loss = 2.42550182953859, disc_loss = 0.0022497459058052837
Trained batch 39 in epoch 8, gen_loss = 2.416974413394928, disc_loss = 0.002261784838628955
Trained batch 40 in epoch 8, gen_loss = 2.4170316952030833, disc_loss = 0.002299385846637916
Trained batch 41 in epoch 8, gen_loss = 2.4139859278996787, disc_loss = 0.0022883175988681614
Trained batch 42 in epoch 8, gen_loss = 2.417493509691815, disc_loss = 0.0022678492444589042
Trained batch 43 in epoch 8, gen_loss = 2.411953091621399, disc_loss = 0.0022846965717194094
Trained batch 44 in epoch 8, gen_loss = 2.412436040242513, disc_loss = 0.002270557296772798
Trained batch 45 in epoch 8, gen_loss = 2.413002449533214, disc_loss = 0.0022719578270840902
Trained batch 46 in epoch 8, gen_loss = 2.4131867429043385, disc_loss = 0.0022875022569156076
Trained batch 47 in epoch 8, gen_loss = 2.4125771870215735, disc_loss = 0.002289319318758013
Trained batch 48 in epoch 8, gen_loss = 2.417372411611129, disc_loss = 0.0022840443856025835
Trained batch 49 in epoch 8, gen_loss = 2.419839720726013, disc_loss = 0.00228559244889766
Trained batch 50 in epoch 8, gen_loss = 2.425250273124844, disc_loss = 0.002279108970006015
Trained batch 51 in epoch 8, gen_loss = 2.4250070498539853, disc_loss = 0.002284531683052102
Trained batch 52 in epoch 8, gen_loss = 2.4205517588921315, disc_loss = 0.0022880180018409243
Trained batch 53 in epoch 8, gen_loss = 2.4152088165283203, disc_loss = 0.002272688818198663
Trained batch 54 in epoch 8, gen_loss = 2.4140917908061637, disc_loss = 0.002300704253668135
Trained batch 55 in epoch 8, gen_loss = 2.4123299547604153, disc_loss = 0.0023245163527982576
Trained batch 56 in epoch 8, gen_loss = 2.4136205639755515, disc_loss = 0.0023110087862924524
Trained batch 57 in epoch 8, gen_loss = 2.4062730217802115, disc_loss = 0.0024656721326554642
Trained batch 58 in epoch 8, gen_loss = 2.4058789661375144, disc_loss = 0.0025929815246392104
Trained batch 59 in epoch 8, gen_loss = 2.4037443538506826, disc_loss = 0.002640119039764007
Trained batch 60 in epoch 8, gen_loss = 2.4099424061228016, disc_loss = 0.00278757567532727
Trained batch 61 in epoch 8, gen_loss = 2.408832202034612, disc_loss = 0.0028077900229442503
Trained batch 62 in epoch 8, gen_loss = 2.4131211534379022, disc_loss = 0.0027891656084518346
Trained batch 63 in epoch 8, gen_loss = 2.410489020869136, disc_loss = 0.002830792689564987
Trained batch 64 in epoch 8, gen_loss = 2.409708461394677, disc_loss = 0.002822599927178369
Trained batch 65 in epoch 8, gen_loss = 2.4097828196756765, disc_loss = 0.0028035258750826347
Trained batch 66 in epoch 8, gen_loss = 2.4056189932040315, disc_loss = 0.0028229010475577035
Trained batch 67 in epoch 8, gen_loss = 2.402910868911182, disc_loss = 0.0028175375516772926
Trained batch 68 in epoch 8, gen_loss = 2.4099202415217524, disc_loss = 0.002930156803905856
Trained batch 69 in epoch 8, gen_loss = 2.4153603638921464, disc_loss = 0.0030205838099521187
Trained batch 70 in epoch 8, gen_loss = 2.414370931370158, disc_loss = 0.003038958907061794
Trained batch 71 in epoch 8, gen_loss = 2.4192136178414025, disc_loss = 0.0030361122707189578
Trained batch 72 in epoch 8, gen_loss = 2.4203139641513562, disc_loss = 0.0030832141239119514
Trained batch 73 in epoch 8, gen_loss = 2.4225719893300854, disc_loss = 0.0030659111940327124
Trained batch 74 in epoch 8, gen_loss = 2.422931005160014, disc_loss = 0.003044553541888793
Trained batch 75 in epoch 8, gen_loss = 2.4161859217442965, disc_loss = 0.0033253508950828723
Trained batch 76 in epoch 8, gen_loss = 2.4125768178469174, disc_loss = 0.0044177908196368
Trained batch 77 in epoch 8, gen_loss = 2.414999689811315, disc_loss = 0.0064360606543815285
Trained batch 78 in epoch 8, gen_loss = 2.406371472757074, disc_loss = 0.007597201627596647
Trained batch 79 in epoch 8, gen_loss = 2.4043768107891084, disc_loss = 0.007650880276923999
Trained batch 80 in epoch 8, gen_loss = 2.4006297323438854, disc_loss = 0.007811023928454996
Trained batch 81 in epoch 8, gen_loss = 2.398165016639523, disc_loss = 0.007826176750269241
Trained batch 82 in epoch 8, gen_loss = 2.3957187698548097, disc_loss = 0.007791473047740488
Trained batch 83 in epoch 8, gen_loss = 2.394715522016798, disc_loss = 0.007777201621571467
Trained batch 84 in epoch 8, gen_loss = 2.393813935448142, disc_loss = 0.007765254833023338
Trained batch 85 in epoch 8, gen_loss = 2.394368989523067, disc_loss = 0.00771534398501349
Trained batch 86 in epoch 8, gen_loss = 2.391404151916504, disc_loss = 0.0076592330735219625
Trained batch 87 in epoch 8, gen_loss = 2.3894211785359816, disc_loss = 0.007602189752188596
Trained batch 88 in epoch 8, gen_loss = 2.3856968209984597, disc_loss = 0.0075495594228209735
Trained batch 89 in epoch 8, gen_loss = 2.383045630984836, disc_loss = 0.007530218184304734
Trained batch 90 in epoch 8, gen_loss = 2.3800552546323, disc_loss = 0.007510983704967977
Trained batch 91 in epoch 8, gen_loss = 2.378794382447782, disc_loss = 0.0075123026111649106
Trained batch 92 in epoch 8, gen_loss = 2.3820589819262104, disc_loss = 0.0076000322813108085
Trained batch 93 in epoch 8, gen_loss = 2.380230297433569, disc_loss = 0.007546843879142816
Trained batch 94 in epoch 8, gen_loss = 2.3833859293084396, disc_loss = 0.007519747588881537
Trained batch 95 in epoch 8, gen_loss = 2.385552555322647, disc_loss = 0.007470207950973418
Trained batch 96 in epoch 8, gen_loss = 2.3924512076623663, disc_loss = 0.007468132059733124
Trained batch 97 in epoch 8, gen_loss = 2.3911760753514817, disc_loss = 0.007427574729318826
Trained batch 98 in epoch 8, gen_loss = 2.387617494120742, disc_loss = 0.007399552073705979
Trained batch 99 in epoch 8, gen_loss = 2.3865557074546815, disc_loss = 0.007376088644377887
Trained batch 100 in epoch 8, gen_loss = 2.3904994171444733, disc_loss = 0.007353035322768558
Trained batch 101 in epoch 8, gen_loss = 2.3894300834805358, disc_loss = 0.007314516459682993
Trained batch 102 in epoch 8, gen_loss = 2.3897504852813425, disc_loss = 0.007266041542430526
Trained batch 103 in epoch 8, gen_loss = 2.3888879074500156, disc_loss = 0.007210309505283546
Trained batch 104 in epoch 8, gen_loss = 2.3903604484739756, disc_loss = 0.007153766080071884
Trained batch 105 in epoch 8, gen_loss = 2.392579177640519, disc_loss = 0.007102673230824535
Trained batch 106 in epoch 8, gen_loss = 2.3918526440023262, disc_loss = 0.007053973182609357
Trained batch 107 in epoch 8, gen_loss = 2.3918777858769453, disc_loss = 0.007005977908934087
Trained batch 108 in epoch 8, gen_loss = 2.393629542184532, disc_loss = 0.006973527968912428
Trained batch 109 in epoch 8, gen_loss = 2.3925508347424596, disc_loss = 0.006945049594452774
Trained batch 110 in epoch 8, gen_loss = 2.3928298542091437, disc_loss = 0.006909682697549395
Trained batch 111 in epoch 8, gen_loss = 2.3913237558943883, disc_loss = 0.006886185526257448
Trained batch 112 in epoch 8, gen_loss = 2.3888619368055224, disc_loss = 0.0068656369452405955
Trained batch 113 in epoch 8, gen_loss = 2.385371840836709, disc_loss = 0.0068539705897452665
Trained batch 114 in epoch 8, gen_loss = 2.3845676515413365, disc_loss = 0.006852006378745579
Trained batch 115 in epoch 8, gen_loss = 2.3863918421597314, disc_loss = 0.006815729210161251
Trained batch 116 in epoch 8, gen_loss = 2.387845427562029, disc_loss = 0.006795016946231262
Trained batch 117 in epoch 8, gen_loss = 2.385952126171629, disc_loss = 0.006757935508099085
Trained batch 118 in epoch 8, gen_loss = 2.3830398801995925, disc_loss = 0.006733647517335578
Trained batch 119 in epoch 8, gen_loss = 2.3817829221487044, disc_loss = 0.006718201633581581
Trained batch 120 in epoch 8, gen_loss = 2.382859089157798, disc_loss = 0.006682687439986558
Trained batch 121 in epoch 8, gen_loss = 2.381972126296309, disc_loss = 0.006658698326228644
Trained batch 122 in epoch 8, gen_loss = 2.3819465957036834, disc_loss = 0.0066257621099172935
Trained batch 123 in epoch 8, gen_loss = 2.381449498476521, disc_loss = 0.006586130868996524
Trained batch 124 in epoch 8, gen_loss = 2.3845830125808716, disc_loss = 0.006550240729935467
Trained batch 125 in epoch 8, gen_loss = 2.3848699567809937, disc_loss = 0.006509462061951617
Trained batch 126 in epoch 8, gen_loss = 2.3849003268039133, disc_loss = 0.006470479979546462
Trained batch 127 in epoch 8, gen_loss = 2.3846316589042544, disc_loss = 0.006437450722842186
Trained batch 128 in epoch 8, gen_loss = 2.3848736554153205, disc_loss = 0.006407105146416341
Trained batch 129 in epoch 8, gen_loss = 2.384559980722574, disc_loss = 0.006369852080332259
Trained batch 130 in epoch 8, gen_loss = 2.3832351624510673, disc_loss = 0.0063302050067382005
Trained batch 131 in epoch 8, gen_loss = 2.382618688272707, disc_loss = 0.006291121172993867
Trained batch 132 in epoch 8, gen_loss = 2.381598186672182, disc_loss = 0.006252262610907113
Trained batch 133 in epoch 8, gen_loss = 2.3815004674356377, disc_loss = 0.006213448630687572
Trained batch 134 in epoch 8, gen_loss = 2.380026180655868, disc_loss = 0.006182372476905585
Trained batch 135 in epoch 8, gen_loss = 2.378638987155522, disc_loss = 0.006153202112353242
Trained batch 136 in epoch 8, gen_loss = 2.3778795160516335, disc_loss = 0.006127690481715394
Trained batch 137 in epoch 8, gen_loss = 2.377815620622773, disc_loss = 0.006096397130918837
Trained batch 138 in epoch 8, gen_loss = 2.378504381762992, disc_loss = 0.0060688729067969556
Trained batch 139 in epoch 8, gen_loss = 2.3771894480500904, disc_loss = 0.006040331492632893
Trained batch 140 in epoch 8, gen_loss = 2.3778647049098995, disc_loss = 0.006012596610226794
Trained batch 141 in epoch 8, gen_loss = 2.376582467220199, disc_loss = 0.006000589065312762
Trained batch 142 in epoch 8, gen_loss = 2.3751161373578586, disc_loss = 0.005974261209831111
Trained batch 143 in epoch 8, gen_loss = 2.3741460003786616, disc_loss = 0.005962797449481311
Trained batch 144 in epoch 8, gen_loss = 2.3737908355120956, disc_loss = 0.005934137042515494
Trained batch 145 in epoch 8, gen_loss = 2.372961294977632, disc_loss = 0.005912623786820379
Trained batch 146 in epoch 8, gen_loss = 2.3721377857688335, disc_loss = 0.005882551620372248
Trained batch 147 in epoch 8, gen_loss = 2.3748202799139797, disc_loss = 0.005856148035712288
Trained batch 148 in epoch 8, gen_loss = 2.3753044997285677, disc_loss = 0.005828543870097289
Trained batch 149 in epoch 8, gen_loss = 2.373919970989227, disc_loss = 0.005799346910013507
Trained batch 150 in epoch 8, gen_loss = 2.3716969561103163, disc_loss = 0.005773228178392873
Trained batch 151 in epoch 8, gen_loss = 2.3710148263918724, disc_loss = 0.0057459138418045385
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 2.32804012298584, disc_loss = 0.0038987663574516773
Trained batch 1 in epoch 9, gen_loss = 2.4335830211639404, disc_loss = 0.0029945317655801773
Trained batch 2 in epoch 9, gen_loss = 2.371156851450602, disc_loss = 0.0027026076956341663
Trained batch 3 in epoch 9, gen_loss = 2.3470702171325684, disc_loss = 0.0024095517583191395
Trained batch 4 in epoch 9, gen_loss = 2.3040382862091064, disc_loss = 0.0022004595259204505
Trained batch 5 in epoch 9, gen_loss = 2.3307981491088867, disc_loss = 0.0020714332931675017
Trained batch 6 in epoch 9, gen_loss = 2.334788833345686, disc_loss = 0.002004418605273323
Trained batch 7 in epoch 9, gen_loss = 2.3058847188949585, disc_loss = 0.0019991270237369463
Trained batch 8 in epoch 9, gen_loss = 2.3003878593444824, disc_loss = 0.0020478289548514616
Trained batch 9 in epoch 9, gen_loss = 2.2763998985290526, disc_loss = 0.0020608925609849394
Trained batch 10 in epoch 9, gen_loss = 2.2810919935053047, disc_loss = 0.001994672485373237
Trained batch 11 in epoch 9, gen_loss = 2.2948250571886697, disc_loss = 0.0019829891389235854
Trained batch 12 in epoch 9, gen_loss = 2.3212217734410214, disc_loss = 0.0019394452773177852
Trained batch 13 in epoch 9, gen_loss = 2.3339560542787825, disc_loss = 0.001880992852550532
Trained batch 14 in epoch 9, gen_loss = 2.339139525095622, disc_loss = 0.0018548501112187902
Trained batch 15 in epoch 9, gen_loss = 2.3399858325719833, disc_loss = 0.0019395177296246402
Trained batch 16 in epoch 9, gen_loss = 2.332382917404175, disc_loss = 0.0019882444004692577
Trained batch 17 in epoch 9, gen_loss = 2.3679810762405396, disc_loss = 0.0021991992252878845
Trained batch 18 in epoch 9, gen_loss = 2.362584954813907, disc_loss = 0.0023996795858501605
Trained batch 19 in epoch 9, gen_loss = 2.3570907711982727, disc_loss = 0.002684934687567875
Trained batch 20 in epoch 9, gen_loss = 2.3648856367383684, disc_loss = 0.0026723615924960802
Trained batch 21 in epoch 9, gen_loss = 2.3733938065442173, disc_loss = 0.0026206057677468793
Trained batch 22 in epoch 9, gen_loss = 2.3697475661402163, disc_loss = 0.002634464454351236
Trained batch 23 in epoch 9, gen_loss = 2.369825690984726, disc_loss = 0.0026724035803151005
Trained batch 24 in epoch 9, gen_loss = 2.377799015045166, disc_loss = 0.0026350044179707767
Trained batch 25 in epoch 9, gen_loss = 2.3909816375145545, disc_loss = 0.002577452835304519
Trained batch 26 in epoch 9, gen_loss = 2.3879930531537092, disc_loss = 0.0026142614833251747
Trained batch 27 in epoch 9, gen_loss = 2.3940375532422746, disc_loss = 0.0025972618896048516
Trained batch 28 in epoch 9, gen_loss = 2.3886612037132524, disc_loss = 0.002544731178706319
Trained batch 29 in epoch 9, gen_loss = 2.3920557181040447, disc_loss = 0.0025009604830605286
Trained batch 30 in epoch 9, gen_loss = 2.3938983101998605, disc_loss = 0.0024563794797887247
Trained batch 31 in epoch 9, gen_loss = 2.388944447040558, disc_loss = 0.0024375437606067862
Trained batch 32 in epoch 9, gen_loss = 2.385436347036651, disc_loss = 0.002415308690009018
Trained batch 33 in epoch 9, gen_loss = 2.3904832671670353, disc_loss = 0.00241179544793661
Trained batch 34 in epoch 9, gen_loss = 2.390367807660784, disc_loss = 0.0023730886867269875
Trained batch 35 in epoch 9, gen_loss = 2.3843722343444824, disc_loss = 0.002334841278045335
Trained batch 36 in epoch 9, gen_loss = 2.3845969792958854, disc_loss = 0.0023093762323008597
Trained batch 37 in epoch 9, gen_loss = 2.390597105026245, disc_loss = 0.002300076465441012
Trained batch 38 in epoch 9, gen_loss = 2.3813862739465175, disc_loss = 0.004603315129852257
Trained batch 39 in epoch 9, gen_loss = 2.365295395255089, disc_loss = 0.015475102778873406
Trained batch 40 in epoch 9, gen_loss = 2.355674636073229, disc_loss = 0.01845847132399951
Trained batch 41 in epoch 9, gen_loss = 2.3590834623291377, disc_loss = 0.02257412306997659
Trained batch 42 in epoch 9, gen_loss = 2.35733714491822, disc_loss = 0.02623364388628668
Trained batch 43 in epoch 9, gen_loss = 2.356520335782658, disc_loss = 0.0316827885504939
Trained batch 44 in epoch 9, gen_loss = 2.3560814989937677, disc_loss = 0.03437431908678264
Trained batch 45 in epoch 9, gen_loss = 2.3544280036636023, disc_loss = 0.034905829089794956
Trained batch 46 in epoch 9, gen_loss = 2.346682165531402, disc_loss = 0.0352029449162767
Trained batch 47 in epoch 9, gen_loss = 2.3391828536987305, disc_loss = 0.03526591803286768
Trained batch 48 in epoch 9, gen_loss = 2.3394679585281684, disc_loss = 0.03508627170231193
Trained batch 49 in epoch 9, gen_loss = 2.3391523599624633, disc_loss = 0.03471988311735913
Trained batch 50 in epoch 9, gen_loss = 2.3372458616892495, disc_loss = 0.034357718454546056
Trained batch 51 in epoch 9, gen_loss = 2.342464190263015, disc_loss = 0.03387515229629711
Trained batch 52 in epoch 9, gen_loss = 2.339433067249802, disc_loss = 0.03372527972382124
Trained batch 53 in epoch 9, gen_loss = 2.333126677407159, disc_loss = 0.03645058725400035
Trained batch 54 in epoch 9, gen_loss = 2.343705584786155, disc_loss = 0.04001762681344355
Trained batch 55 in epoch 9, gen_loss = 2.339018634387425, disc_loss = 0.04244093148528399
Trained batch 56 in epoch 9, gen_loss = 2.337845258545457, disc_loss = 0.0430141614582553
Trained batch 57 in epoch 9, gen_loss = 2.336113395362065, disc_loss = 0.04304685563065818
Trained batch 58 in epoch 9, gen_loss = 2.336983159437018, disc_loss = 0.04323126051093499
Trained batch 59 in epoch 9, gen_loss = 2.337037213643392, disc_loss = 0.0428857963590417
Trained batch 60 in epoch 9, gen_loss = 2.336653955647203, disc_loss = 0.042375436134743275
Trained batch 61 in epoch 9, gen_loss = 2.3378580193365774, disc_loss = 0.04183490373637347
Trained batch 62 in epoch 9, gen_loss = 2.3396594637916204, disc_loss = 0.041339868906929735
Trained batch 63 in epoch 9, gen_loss = 2.3386973217129707, disc_loss = 0.040873159688999294
Trained batch 64 in epoch 9, gen_loss = 2.3362975413982685, disc_loss = 0.04037615538467295
Trained batch 65 in epoch 9, gen_loss = 2.3323659752354478, disc_loss = 0.03988615195372735
Trained batch 66 in epoch 9, gen_loss = 2.330316308719009, disc_loss = 0.03944818093615181
Trained batch 67 in epoch 9, gen_loss = 2.3285656886942245, disc_loss = 0.03896835554384298
Trained batch 68 in epoch 9, gen_loss = 2.325588938118755, disc_loss = 0.038589125591924116
Trained batch 69 in epoch 9, gen_loss = 2.325267791748047, disc_loss = 0.038149475863402976
Trained batch 70 in epoch 9, gen_loss = 2.3254265516576633, disc_loss = 0.037697176617885034
Trained batch 71 in epoch 9, gen_loss = 2.3258544736438327, disc_loss = 0.03731860279771758
Trained batch 72 in epoch 9, gen_loss = 2.326335707755938, disc_loss = 0.03705042707638126
Trained batch 73 in epoch 9, gen_loss = 2.328461643811819, disc_loss = 0.03674400072840571
Trained batch 74 in epoch 9, gen_loss = 2.3245194085439045, disc_loss = 0.036357915319191914
Trained batch 75 in epoch 9, gen_loss = 2.3224382745592216, disc_loss = 0.036144577816900746
Trained batch 76 in epoch 9, gen_loss = 2.329378214749423, disc_loss = 0.03613683389493736
Trained batch 77 in epoch 9, gen_loss = 2.3302174714895396, disc_loss = 0.03580837512167935
Trained batch 78 in epoch 9, gen_loss = 2.330116742773901, disc_loss = 0.0354091978346033
Trained batch 79 in epoch 9, gen_loss = 2.3272396087646485, disc_loss = 0.035499982033798005
Trained batch 80 in epoch 9, gen_loss = 2.3220244543052013, disc_loss = 0.03797798912920472
Trained batch 81 in epoch 9, gen_loss = 2.3204395218593317, disc_loss = 0.038541910816381524
Trained batch 82 in epoch 9, gen_loss = 2.320133467754686, disc_loss = 0.03903328704630889
Trained batch 83 in epoch 9, gen_loss = 2.318443993727366, disc_loss = 0.03931806321738155
Trained batch 84 in epoch 9, gen_loss = 2.316930221108829, disc_loss = 0.03926711153540322
Trained batch 85 in epoch 9, gen_loss = 2.320561464442763, disc_loss = 0.03936379481794659
Trained batch 86 in epoch 9, gen_loss = 2.3154261345150826, disc_loss = 0.040020856801581024
Trained batch 87 in epoch 9, gen_loss = 2.3185790330171585, disc_loss = 0.040130579049053434
Trained batch 88 in epoch 9, gen_loss = 2.319052633274807, disc_loss = 0.03991778133034162
Trained batch 89 in epoch 9, gen_loss = 2.3201451102892556, disc_loss = 0.039623260962414655
Trained batch 90 in epoch 9, gen_loss = 2.321791327916659, disc_loss = 0.03946270722931681
Trained batch 91 in epoch 9, gen_loss = 2.320731508990993, disc_loss = 0.03935532813319815
Trained batch 92 in epoch 9, gen_loss = 2.3211342942330146, disc_loss = 0.039042133866729195
Trained batch 93 in epoch 9, gen_loss = 2.3216895334264067, disc_loss = 0.03876517478133889
Trained batch 94 in epoch 9, gen_loss = 2.3201378257651077, disc_loss = 0.03867735842022261
Trained batch 95 in epoch 9, gen_loss = 2.320841579387585, disc_loss = 0.03835425716897589
Trained batch 96 in epoch 9, gen_loss = 2.3222568833950867, disc_loss = 0.03830261275858724
Trained batch 97 in epoch 9, gen_loss = 2.3222716523676503, disc_loss = 0.03842384787157596
Trained batch 98 in epoch 9, gen_loss = 2.3246961446723553, disc_loss = 0.03808662605194394
Trained batch 99 in epoch 9, gen_loss = 2.3274425685405733, disc_loss = 0.03776671448140405
Trained batch 100 in epoch 9, gen_loss = 2.3285370050090375, disc_loss = 0.03741699565400249
Trained batch 101 in epoch 9, gen_loss = 2.3276969182725047, disc_loss = 0.03712576881904776
Trained batch 102 in epoch 9, gen_loss = 2.3306372732792084, disc_loss = 0.03700927399365611
Trained batch 103 in epoch 9, gen_loss = 2.332078297550862, disc_loss = 0.036857041748589836
Trained batch 104 in epoch 9, gen_loss = 2.3319156907853626, disc_loss = 0.03664749272145508
Trained batch 105 in epoch 9, gen_loss = 2.3342773543213897, disc_loss = 0.03639090344428419
Trained batch 106 in epoch 9, gen_loss = 2.3351786192332473, disc_loss = 0.036132791195996106
Trained batch 107 in epoch 9, gen_loss = 2.3371907351193606, disc_loss = 0.035857752576703206
Trained batch 108 in epoch 9, gen_loss = 2.3390219966205983, disc_loss = 0.03555836081996116
Trained batch 109 in epoch 9, gen_loss = 2.3409786560318686, disc_loss = 0.03530268623726442
Trained batch 110 in epoch 9, gen_loss = 2.3416900881775864, disc_loss = 0.03503396296097586
Trained batch 111 in epoch 9, gen_loss = 2.3403433252658163, disc_loss = 0.03478504399598543
Trained batch 112 in epoch 9, gen_loss = 2.340748363891534, disc_loss = 0.034543678542574355
Trained batch 113 in epoch 9, gen_loss = 2.346058162680843, disc_loss = 0.03431266105811422
Trained batch 114 in epoch 9, gen_loss = 2.3436048124147497, disc_loss = 0.03405762512297572
Trained batch 115 in epoch 9, gen_loss = 2.3409317351620773, disc_loss = 0.03382836610122969
Trained batch 116 in epoch 9, gen_loss = 2.3403848144743176, disc_loss = 0.03357900241608771
Trained batch 117 in epoch 9, gen_loss = 2.3420987321158586, disc_loss = 0.03331219760989139
Trained batch 118 in epoch 9, gen_loss = 2.3407608190504443, disc_loss = 0.033059775975078906
Trained batch 119 in epoch 9, gen_loss = 2.3421572357416154, disc_loss = 0.03282496966518617
Trained batch 120 in epoch 9, gen_loss = 2.343448823148554, disc_loss = 0.032654526929201726
Trained batch 121 in epoch 9, gen_loss = 2.3450527025050802, disc_loss = 0.032457222330925954
Trained batch 122 in epoch 9, gen_loss = 2.3459373363634435, disc_loss = 0.032215058590603494
Trained batch 123 in epoch 9, gen_loss = 2.345632407934435, disc_loss = 0.03201646201083467
Trained batch 124 in epoch 9, gen_loss = 2.34462304019928, disc_loss = 0.031794818948023024
Trained batch 125 in epoch 9, gen_loss = 2.3474232346292525, disc_loss = 0.03156397146235649
Trained batch 126 in epoch 9, gen_loss = 2.3468507209162075, disc_loss = 0.03133403211300386
Trained batch 127 in epoch 9, gen_loss = 2.3490318497642875, disc_loss = 0.031129163605328358
Trained batch 128 in epoch 9, gen_loss = 2.3487391129944677, disc_loss = 0.03092290694164762
Trained batch 129 in epoch 9, gen_loss = 2.3458569875130286, disc_loss = 0.031201564197321063
Trained batch 130 in epoch 9, gen_loss = 2.34416499210678, disc_loss = 0.03281757539006675
Trained batch 131 in epoch 9, gen_loss = 2.34464771639217, disc_loss = 0.03317921108365143
Trained batch 132 in epoch 9, gen_loss = 2.343826797671784, disc_loss = 0.03308486594569946
Trained batch 133 in epoch 9, gen_loss = 2.341272163746962, disc_loss = 0.03300127462716773
Trained batch 134 in epoch 9, gen_loss = 2.3420495209870515, disc_loss = 0.03287725042189575
Trained batch 135 in epoch 9, gen_loss = 2.341954264570685, disc_loss = 0.0327326382351149
Trained batch 136 in epoch 9, gen_loss = 2.341674912584959, disc_loss = 0.03252944373270755
Trained batch 137 in epoch 9, gen_loss = 2.342878840971684, disc_loss = 0.03234332853141983
Trained batch 138 in epoch 9, gen_loss = 2.345180139267187, disc_loss = 0.032139670860069205
Trained batch 139 in epoch 9, gen_loss = 2.3474414978708538, disc_loss = 0.031967839883873236
Trained batch 140 in epoch 9, gen_loss = 2.351424624733891, disc_loss = 0.03181115549027999
Trained batch 141 in epoch 9, gen_loss = 2.350105968999191, disc_loss = 0.03167914350526932
Trained batch 142 in epoch 9, gen_loss = 2.3515632802789863, disc_loss = 0.03154375051047288
Trained batch 143 in epoch 9, gen_loss = 2.350360827313529, disc_loss = 0.03138712529633065
Trained batch 144 in epoch 9, gen_loss = 2.349575328826904, disc_loss = 0.031198713821680126
Trained batch 145 in epoch 9, gen_loss = 2.3478147542639953, disc_loss = 0.031038639935416053
Trained batch 146 in epoch 9, gen_loss = 2.3472058448661755, disc_loss = 0.030871948600290532
Trained batch 147 in epoch 9, gen_loss = 2.3475871327761055, disc_loss = 0.030715194605511136
Trained batch 148 in epoch 9, gen_loss = 2.3476498543016064, disc_loss = 0.030567603703782014
Trained batch 149 in epoch 9, gen_loss = 2.348548992474874, disc_loss = 0.03038188081467524
Trained batch 150 in epoch 9, gen_loss = 2.3471272118044215, disc_loss = 0.030228815645146005
Trained batch 151 in epoch 9, gen_loss = 2.3458417261901654, disc_loss = 0.03008275385256734
Testing Epoch 9
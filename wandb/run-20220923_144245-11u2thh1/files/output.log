/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 1.5991528034210205, disc_loss = 0.5915661454200745
Trained batch 1 in epoch 0, gen_loss = 1.597386121749878, disc_loss = 0.6132937371730804
Trained batch 2 in epoch 0, gen_loss = 1.5330768426259358, disc_loss = 0.6095317602157593
Trained batch 3 in epoch 0, gen_loss = 1.4493142366409302, disc_loss = 0.5715426951646805
Trained batch 4 in epoch 0, gen_loss = 1.392326784133911, disc_loss = 0.507530128955841
Trained batch 5 in epoch 0, gen_loss = 1.364377995332082, disc_loss = 0.45456096281607944
Trained batch 6 in epoch 0, gen_loss = 1.3453757933207922, disc_loss = 0.41387009833540234
Trained batch 7 in epoch 0, gen_loss = 1.3363559693098068, disc_loss = 0.3806384224444628
Trained batch 8 in epoch 0, gen_loss = 1.3254740238189697, disc_loss = 0.35113778627581066
Trained batch 9 in epoch 0, gen_loss = 1.2934152960777283, disc_loss = 0.3315915875136852
Trained batch 10 in epoch 0, gen_loss = 1.2846469337289983, disc_loss = 0.31651006300341
Trained batch 11 in epoch 0, gen_loss = 1.2872638702392578, disc_loss = 0.3052891797075669
Trained batch 12 in epoch 0, gen_loss = 1.3005579985105074, disc_loss = 0.2999630897090985
Trained batch 13 in epoch 0, gen_loss = 1.2905104330607824, disc_loss = 0.29092791729739736
Trained batch 14 in epoch 0, gen_loss = 1.2910796483357747, disc_loss = 0.28069299111763635
Trained batch 15 in epoch 0, gen_loss = 1.2863164693117142, disc_loss = 0.27440387522801757
Trained batch 16 in epoch 0, gen_loss = 1.2931191780987907, disc_loss = 0.2698038233553662
Trained batch 17 in epoch 0, gen_loss = 1.298353374004364, disc_loss = 0.2659365348517895
Trained batch 18 in epoch 0, gen_loss = 1.2967716769168252, disc_loss = 0.26035813242197037
Trained batch 19 in epoch 0, gen_loss = 1.2921951293945313, disc_loss = 0.2532105803489685
Trained batch 20 in epoch 0, gen_loss = 1.2796787534441267, disc_loss = 0.25056726875759305
Trained batch 21 in epoch 0, gen_loss = 1.2823509628122503, disc_loss = 0.24735552207990127
Trained batch 22 in epoch 0, gen_loss = 1.2773121180741682, disc_loss = 0.24331142980119455
Trained batch 23 in epoch 0, gen_loss = 1.2793926745653152, disc_loss = 0.2372912292679151
Trained batch 24 in epoch 0, gen_loss = 1.2894248342514039, disc_loss = 0.23152556091547014
Trained batch 25 in epoch 0, gen_loss = 1.2909953273259676, disc_loss = 0.2258825792142978
Trained batch 26 in epoch 0, gen_loss = 1.2944079725830644, disc_loss = 0.22010683295903383
Trained batch 27 in epoch 0, gen_loss = 1.3014078182833535, disc_loss = 0.21460780714239394
Trained batch 28 in epoch 0, gen_loss = 1.304996708343769, disc_loss = 0.20955680207959537
Trained batch 29 in epoch 0, gen_loss = 1.304413946469625, disc_loss = 0.20488172993063927
Trained batch 30 in epoch 0, gen_loss = 1.316588121075784, disc_loss = 0.20186740208056667
Trained batch 31 in epoch 0, gen_loss = 1.3116403110325336, disc_loss = 0.20059796888381243
Trained batch 32 in epoch 0, gen_loss = 1.3289121100396821, disc_loss = 0.19836746111060632
Trained batch 33 in epoch 0, gen_loss = 1.335167432532591, disc_loss = 0.1977004899698145
Trained batch 34 in epoch 0, gen_loss = 1.3398219789777484, disc_loss = 0.19639040827751159
Trained batch 35 in epoch 0, gen_loss = 1.3447771999571059, disc_loss = 0.1935847776217593
Trained batch 36 in epoch 0, gen_loss = 1.350997679942363, disc_loss = 0.19021217061861143
Trained batch 37 in epoch 0, gen_loss = 1.3512349128723145, disc_loss = 0.18713892761029696
Trained batch 38 in epoch 0, gen_loss = 1.3551421471131153, disc_loss = 0.1839564616481463
Trained batch 39 in epoch 0, gen_loss = 1.3600907623767853, disc_loss = 0.18072295552119613
Trained batch 40 in epoch 0, gen_loss = 1.3628240503915927, disc_loss = 0.17762818232905575
Trained batch 41 in epoch 0, gen_loss = 1.3656747426305498, disc_loss = 0.17490464759369692
Trained batch 42 in epoch 0, gen_loss = 1.3712091917215392, disc_loss = 0.17201812729932542
Trained batch 43 in epoch 0, gen_loss = 1.3759733059189536, disc_loss = 0.16917736345732753
Trained batch 44 in epoch 0, gen_loss = 1.3774095959133572, disc_loss = 0.16672936727603277
Trained batch 45 in epoch 0, gen_loss = 1.3812341949214106, disc_loss = 0.16414534867457722
Trained batch 46 in epoch 0, gen_loss = 1.3913348025463996, disc_loss = 0.16192180964540928
Trained batch 47 in epoch 0, gen_loss = 1.3825184653202693, disc_loss = 0.16324446691821018
Trained batch 48 in epoch 0, gen_loss = 1.4047366113078839, disc_loss = 0.16544039364980193
Trained batch 49 in epoch 0, gen_loss = 1.3986757564544678, disc_loss = 0.16502991557121277
Trained batch 50 in epoch 0, gen_loss = 1.3944328602622538, disc_loss = 0.1645218624788172
Trained batch 51 in epoch 0, gen_loss = 1.395766670887287, disc_loss = 0.16350305510255006
Trained batch 52 in epoch 0, gen_loss = 1.3976732807339363, disc_loss = 0.1630502331931636
Trained batch 53 in epoch 0, gen_loss = 1.3967701240822121, disc_loss = 0.16219953254417138
Trained batch 54 in epoch 0, gen_loss = 1.3935774543068626, disc_loss = 0.1610850751399994
Trained batch 55 in epoch 0, gen_loss = 1.3963670496429716, disc_loss = 0.1597439009430153
Trained batch 56 in epoch 0, gen_loss = 1.3980119751210798, disc_loss = 0.15852683063661843
Trained batch 57 in epoch 0, gen_loss = 1.3979334975111073, disc_loss = 0.1572679971055738
Trained batch 58 in epoch 0, gen_loss = 1.3962750939999597, disc_loss = 0.15613886474047678
Trained batch 59 in epoch 0, gen_loss = 1.4010091602802277, disc_loss = 0.15521755988399188
Trained batch 60 in epoch 0, gen_loss = 1.400872404458093, disc_loss = 0.15366763682639012
Trained batch 61 in epoch 0, gen_loss = 1.4038350505213584, disc_loss = 0.15196031223862402
Trained batch 62 in epoch 0, gen_loss = 1.405132320192125, disc_loss = 0.1502716802060604
Trained batch 63 in epoch 0, gen_loss = 1.4096361137926579, disc_loss = 0.14874425978632644
Trained batch 64 in epoch 0, gen_loss = 1.4077276633335993, disc_loss = 0.14762173736324677
Trained batch 65 in epoch 0, gen_loss = 1.4132787802002647, disc_loss = 0.14647562547840856
Trained batch 66 in epoch 0, gen_loss = 1.4112067222595215, disc_loss = 0.14540463836113018
Trained batch 67 in epoch 0, gen_loss = 1.4128918472458334, disc_loss = 0.14402003421941223
Trained batch 68 in epoch 0, gen_loss = 1.4158998088560242, disc_loss = 0.14290507191765137
Trained batch 69 in epoch 0, gen_loss = 1.4109032835279192, disc_loss = 0.1432139621249267
Trained batch 70 in epoch 0, gen_loss = 1.4263961012934294, disc_loss = 0.14536685622493986
Trained batch 71 in epoch 0, gen_loss = 1.4189002861579258, disc_loss = 0.14716264967703158
Trained batch 72 in epoch 0, gen_loss = 1.4179458079272753, disc_loss = 0.14673860197606153
Trained batch 73 in epoch 0, gen_loss = 1.421442286388294, disc_loss = 0.1462183705455548
Trained batch 74 in epoch 0, gen_loss = 1.4221805016199747, disc_loss = 0.14532665272553763
Trained batch 75 in epoch 0, gen_loss = 1.4217317496475421, disc_loss = 0.1443718520826415
Trained batch 76 in epoch 0, gen_loss = 1.4211940068703193, disc_loss = 0.14331500986953835
Trained batch 77 in epoch 0, gen_loss = 1.421909627241966, disc_loss = 0.1420996759373408
Trained batch 78 in epoch 0, gen_loss = 1.4233766945102546, disc_loss = 0.1408685538682002
Trained batch 79 in epoch 0, gen_loss = 1.424070692062378, disc_loss = 0.13959423820488154
Trained batch 80 in epoch 0, gen_loss = 1.4250592685040133, disc_loss = 0.13833639140666268
Trained batch 81 in epoch 0, gen_loss = 1.4282939521277822, disc_loss = 0.13724806386886573
Trained batch 82 in epoch 0, gen_loss = 1.4245367466685284, disc_loss = 0.13657436618603855
Trained batch 83 in epoch 0, gen_loss = 1.431070823045004, disc_loss = 0.13713123471963973
Trained batch 84 in epoch 0, gen_loss = 1.4229674170998965, disc_loss = 0.14004633040989148
Trained batch 85 in epoch 0, gen_loss = 1.4251012774400933, disc_loss = 0.13944485800903897
Trained batch 86 in epoch 0, gen_loss = 1.4266587797252612, disc_loss = 0.13877230240353222
Trained batch 87 in epoch 0, gen_loss = 1.423795778643001, disc_loss = 0.13802151627499948
Trained batch 88 in epoch 0, gen_loss = 1.421916310706835, disc_loss = 0.1370343128114604
Trained batch 89 in epoch 0, gen_loss = 1.4239202075534396, disc_loss = 0.13609229909876983
Trained batch 90 in epoch 0, gen_loss = 1.4211100745987106, disc_loss = 0.13530476444533893
Trained batch 91 in epoch 0, gen_loss = 1.4198443785957668, disc_loss = 0.1343872132103728
Trained batch 92 in epoch 0, gen_loss = 1.418703180487438, disc_loss = 0.13372101005847736
Trained batch 93 in epoch 0, gen_loss = 1.4141046113156257, disc_loss = 0.1334138669152843
Trained batch 94 in epoch 0, gen_loss = 1.4198508940244976, disc_loss = 0.1349287934601307
Trained batch 95 in epoch 0, gen_loss = 1.4121290724724531, disc_loss = 0.1379752535916244
Trained batch 96 in epoch 0, gen_loss = 1.4131699929532318, disc_loss = 0.13755124142950342
Trained batch 97 in epoch 0, gen_loss = 1.4102343229614958, disc_loss = 0.1373124766942798
Trained batch 98 in epoch 0, gen_loss = 1.4081114115137043, disc_loss = 0.1367023234641311
Trained batch 99 in epoch 0, gen_loss = 1.407464457154274, disc_loss = 0.13603189643472433
Trained batch 100 in epoch 0, gen_loss = 1.403947628960751, disc_loss = 0.13584996726695853
Trained batch 101 in epoch 0, gen_loss = 1.4026096515795763, disc_loss = 0.1358189624825529
Trained batch 102 in epoch 0, gen_loss = 1.402456874407611, disc_loss = 0.13643018781994154
Trained batch 103 in epoch 0, gen_loss = 1.4017290467253098, disc_loss = 0.13656738181956685
Trained batch 104 in epoch 0, gen_loss = 1.3989953807422093, disc_loss = 0.13637687241037685
Trained batch 105 in epoch 0, gen_loss = 1.3967905848656061, disc_loss = 0.13613223597266763
Trained batch 106 in epoch 0, gen_loss = 1.3965059134447686, disc_loss = 0.1361051766184446
Trained batch 107 in epoch 0, gen_loss = 1.3900653642636758, disc_loss = 0.13868267271943666
Trained batch 108 in epoch 0, gen_loss = 1.39478259677187, disc_loss = 0.14022564741039495
Trained batch 109 in epoch 0, gen_loss = 1.3895821668884971, disc_loss = 0.1410548993470994
Trained batch 110 in epoch 0, gen_loss = 1.3847827390507534, disc_loss = 0.1414149624068995
Trained batch 111 in epoch 0, gen_loss = 1.3817662985197134, disc_loss = 0.1416081637476704
Trained batch 112 in epoch 0, gen_loss = 1.3800174899860822, disc_loss = 0.14214086338086465
Trained batch 113 in epoch 0, gen_loss = 1.3771023964672757, disc_loss = 0.14232467967820794
Trained batch 114 in epoch 0, gen_loss = 1.372725600781648, disc_loss = 0.14260145493823548
Trained batch 115 in epoch 0, gen_loss = 1.3714553035538772, disc_loss = 0.1427166209202902
Trained batch 116 in epoch 0, gen_loss = 1.3696057388925145, disc_loss = 0.14288141613459995
Trained batch 117 in epoch 0, gen_loss = 1.367052935947806, disc_loss = 0.14279643285198737
Trained batch 118 in epoch 0, gen_loss = 1.365592717122631, disc_loss = 0.14276557137109652
Trained batch 119 in epoch 0, gen_loss = 1.3625283832351367, disc_loss = 0.14277880915130178
Trained batch 120 in epoch 0, gen_loss = 1.3606229532848706, disc_loss = 0.14261334909757306
Trained batch 121 in epoch 0, gen_loss = 1.3585427310623106, disc_loss = 0.14237909174722727
Trained batch 122 in epoch 0, gen_loss = 1.355786253281725, disc_loss = 0.14200779398888108
Trained batch 123 in epoch 0, gen_loss = 1.358044306597402, disc_loss = 0.1421757978837817
Trained batch 124 in epoch 0, gen_loss = 1.3535273785591126, disc_loss = 0.14347213211655616
Trained batch 125 in epoch 0, gen_loss = 1.3535556334351737, disc_loss = 0.1430822829937651
Trained batch 126 in epoch 0, gen_loss = 1.356679751647739, disc_loss = 0.14334933521358048
Trained batch 127 in epoch 0, gen_loss = 1.3522733370773494, disc_loss = 0.14392297135782428
Trained batch 128 in epoch 0, gen_loss = 1.3518486905467602, disc_loss = 0.14388357590912848
Trained batch 129 in epoch 0, gen_loss = 1.3496727892985712, disc_loss = 0.14410771145843543
Trained batch 130 in epoch 0, gen_loss = 1.3465951676587111, disc_loss = 0.14443331015587763
Trained batch 131 in epoch 0, gen_loss = 1.3467625799504193, disc_loss = 0.1445233579442808
Trained batch 132 in epoch 0, gen_loss = 1.3442351096554805, disc_loss = 0.14436221786571624
Trained batch 133 in epoch 0, gen_loss = 1.3427955939698575, disc_loss = 0.14452824232849612
Trained batch 134 in epoch 0, gen_loss = 1.3406282473493505, disc_loss = 0.1445032522910171
Trained batch 135 in epoch 0, gen_loss = 1.340180734939435, disc_loss = 0.14445486470289967
Trained batch 136 in epoch 0, gen_loss = 1.3387320872640958, disc_loss = 0.14448255531653
Trained batch 137 in epoch 0, gen_loss = 1.3370842436949413, disc_loss = 0.14449234363501487
Trained batch 138 in epoch 0, gen_loss = 1.3382773746689447, disc_loss = 0.14444051674908873
Trained batch 139 in epoch 0, gen_loss = 1.3363276800939015, disc_loss = 0.14497042215828385
Trained batch 140 in epoch 0, gen_loss = 1.3401345475345638, disc_loss = 0.14682835808142702
Trained batch 141 in epoch 0, gen_loss = 1.3358884210317907, disc_loss = 0.1483944075470659
Trained batch 142 in epoch 0, gen_loss = 1.3423423133529984, disc_loss = 0.1499885756496366
Trained batch 143 in epoch 0, gen_loss = 1.3388749965363078, disc_loss = 0.1509046513432016
Trained batch 144 in epoch 0, gen_loss = 1.3370168948995655, disc_loss = 0.15128264481137538
Trained batch 145 in epoch 0, gen_loss = 1.3349896620397699, disc_loss = 0.15149470543718502
Trained batch 146 in epoch 0, gen_loss = 1.3341738415413162, disc_loss = 0.15211757898432057
Trained batch 147 in epoch 0, gen_loss = 1.3313556426280253, disc_loss = 0.15258164172740402
Trained batch 148 in epoch 0, gen_loss = 1.3299308847260956, disc_loss = 0.15297190607494157
Trained batch 149 in epoch 0, gen_loss = 1.327647249698639, disc_loss = 0.15325173698365688
Trained batch 150 in epoch 0, gen_loss = 1.325562529216539, disc_loss = 0.1535979975384987
Trained batch 151 in epoch 0, gen_loss = 1.3228520547088825, disc_loss = 0.1538500121402505
Trained batch 152 in epoch 0, gen_loss = 1.3207236949135275, disc_loss = 0.15403345317330236
Trained batch 153 in epoch 0, gen_loss = 1.3178727750654344, disc_loss = 0.15416898232485568
Trained batch 154 in epoch 0, gen_loss = 1.316288435074591, disc_loss = 0.15430132085757872
Trained batch 155 in epoch 0, gen_loss = 1.3163436246223938, disc_loss = 0.15423827334187734
Trained batch 156 in epoch 0, gen_loss = 1.3134701810065348, disc_loss = 0.15465258472379606
Trained batch 157 in epoch 0, gen_loss = 1.313734438977664, disc_loss = 0.15494213029270684
Trained batch 158 in epoch 0, gen_loss = 1.3128581598119915, disc_loss = 0.15476413991934848
Trained batch 159 in epoch 0, gen_loss = 1.3115733247250319, disc_loss = 0.154380696057342
Trained batch 160 in epoch 0, gen_loss = 1.3112604288580996, disc_loss = 0.15413787301560367
Trained batch 161 in epoch 0, gen_loss = 1.3109523267657668, disc_loss = 0.15363806893152218
Trained batch 162 in epoch 0, gen_loss = 1.3099064494203205, disc_loss = 0.1535677366141527
Trained batch 163 in epoch 0, gen_loss = 1.3078473072226455, disc_loss = 0.15355529374920013
Trained batch 164 in epoch 0, gen_loss = 1.311095235564492, disc_loss = 0.15387303641799724
Trained batch 165 in epoch 0, gen_loss = 1.307784969548145, disc_loss = 0.1549087993755757
Trained batch 166 in epoch 0, gen_loss = 1.3071106536659651, disc_loss = 0.15503457886819355
Trained batch 167 in epoch 0, gen_loss = 1.3070948194889795, disc_loss = 0.1556119500393314
Trained batch 168 in epoch 0, gen_loss = 1.3034788800414496, disc_loss = 0.1564610046968305
Trained batch 169 in epoch 0, gen_loss = 1.3025486195788665, disc_loss = 0.15631636742721586
Trained batch 170 in epoch 0, gen_loss = 1.3022193023335864, disc_loss = 0.15641865031848176
Trained batch 171 in epoch 0, gen_loss = 1.301777495201244, disc_loss = 0.15615932589266882
Trained batch 172 in epoch 0, gen_loss = 1.299714918081471, disc_loss = 0.15599260033468978
Trained batch 173 in epoch 0, gen_loss = 1.2980635700554684, disc_loss = 0.15603965338876194
Trained batch 174 in epoch 0, gen_loss = 1.2991419764927454, disc_loss = 0.1559735452064446
Trained batch 175 in epoch 0, gen_loss = 1.2966186560013078, disc_loss = 0.15612508955580945
Trained batch 176 in epoch 0, gen_loss = 1.2983565633579837, disc_loss = 0.15579542915447284
Trained batch 177 in epoch 0, gen_loss = 1.2972239523791196, disc_loss = 0.1555385161609797
Trained batch 178 in epoch 0, gen_loss = 1.295902340105792, disc_loss = 0.15533344574563995
Trained batch 179 in epoch 0, gen_loss = 1.2961642271942562, disc_loss = 0.1552115262589521
Trained batch 180 in epoch 0, gen_loss = 1.2941463500755268, disc_loss = 0.155052803765509
Trained batch 181 in epoch 0, gen_loss = 1.294181153669462, disc_loss = 0.15478709395360815
Trained batch 182 in epoch 0, gen_loss = 1.2934343378400541, disc_loss = 0.15452146112837425
Trained batch 183 in epoch 0, gen_loss = 1.2919321092574492, disc_loss = 0.15432468714678418
Trained batch 184 in epoch 0, gen_loss = 1.2937564418122576, disc_loss = 0.15421436213561007
Trained batch 185 in epoch 0, gen_loss = 1.2931340580345483, disc_loss = 0.15359267265966503
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 0.8395417332649231, disc_loss = 0.14892640709877014
Trained batch 1 in epoch 1, gen_loss = 1.4303959906101227, disc_loss = 0.22610510885715485
Trained batch 2 in epoch 1, gen_loss = 1.2244499723116558, disc_loss = 0.22218561172485352
Trained batch 3 in epoch 1, gen_loss = 1.1806284934282303, disc_loss = 0.20988509431481361
Trained batch 4 in epoch 1, gen_loss = 1.2719929099082947, disc_loss = 0.2116304099559784
Trained batch 5 in epoch 1, gen_loss = 1.2169496615727742, disc_loss = 0.21164346734682718
Trained batch 6 in epoch 1, gen_loss = 1.180020000253405, disc_loss = 0.20966539638383047
Trained batch 7 in epoch 1, gen_loss = 1.19576845318079, disc_loss = 0.20180972665548325
Trained batch 8 in epoch 1, gen_loss = 1.1911764211124845, disc_loss = 0.19035061366028255
Trained batch 9 in epoch 1, gen_loss = 1.1757230818271638, disc_loss = 0.1803788274526596
Trained batch 10 in epoch 1, gen_loss = 1.1768650846047835, disc_loss = 0.17348803783004935
Trained batch 11 in epoch 1, gen_loss = 1.169377828637759, disc_loss = 0.17082462521890798
Trained batch 12 in epoch 1, gen_loss = 1.158930214551779, disc_loss = 0.17063938023952338
Trained batch 13 in epoch 1, gen_loss = 1.171104520559311, disc_loss = 0.16608281061053276
Trained batch 14 in epoch 1, gen_loss = 1.1584505995114645, disc_loss = 0.16198982646067936
Trained batch 15 in epoch 1, gen_loss = 1.1596194989979267, disc_loss = 0.15590248862281442
Trained batch 16 in epoch 1, gen_loss = 1.1631186884992264, disc_loss = 0.15234808930579355
Trained batch 17 in epoch 1, gen_loss = 1.1681480308373768, disc_loss = 0.14848781997958818
Trained batch 18 in epoch 1, gen_loss = 1.17680246265311, disc_loss = 0.14325366443709323
Trained batch 19 in epoch 1, gen_loss = 1.1748766988515853, disc_loss = 0.14084772989153863
Trained batch 20 in epoch 1, gen_loss = 1.2209116702988034, disc_loss = 0.1415802403574898
Trained batch 21 in epoch 1, gen_loss = 1.200143190947446, disc_loss = 0.15354522588578137
Trained batch 22 in epoch 1, gen_loss = 1.2269399062446926, disc_loss = 0.15282146632671356
Trained batch 23 in epoch 1, gen_loss = 1.2212410022815068, disc_loss = 0.15007343826194605
Trained batch 24 in epoch 1, gen_loss = 1.214898705482483, disc_loss = 0.1483303964138031
Trained batch 25 in epoch 1, gen_loss = 1.2192469239234924, disc_loss = 0.14695641283805555
Trained batch 26 in epoch 1, gen_loss = 1.209710043889505, disc_loss = 0.14598987831009758
Trained batch 27 in epoch 1, gen_loss = 1.2299114614725113, disc_loss = 0.1437785912837301
Trained batch 28 in epoch 1, gen_loss = 1.2191608609824345, disc_loss = 0.1444484190694217
Trained batch 29 in epoch 1, gen_loss = 1.2224120497703552, disc_loss = 0.14501656691233317
Trained batch 30 in epoch 1, gen_loss = 1.2142662655922674, disc_loss = 0.14546190442577486
Trained batch 31 in epoch 1, gen_loss = 1.2204191125929356, disc_loss = 0.14577855821698904
Trained batch 32 in epoch 1, gen_loss = 1.2176953481905388, disc_loss = 0.14470360044277075
Trained batch 33 in epoch 1, gen_loss = 1.2123680290053873, disc_loss = 0.1447668689138749
Trained batch 34 in epoch 1, gen_loss = 1.2184505598885673, disc_loss = 0.14458938922200884
Trained batch 35 in epoch 1, gen_loss = 1.2260682847764757, disc_loss = 0.141276807938185
Trained batch 36 in epoch 1, gen_loss = 1.221375052993362, disc_loss = 0.14062913074283986
Trained batch 37 in epoch 1, gen_loss = 1.2247619472051923, disc_loss = 0.1400301506448733
Trained batch 38 in epoch 1, gen_loss = 1.2214324810566046, disc_loss = 0.13918278012902308
Trained batch 39 in epoch 1, gen_loss = 1.2203659802675246, disc_loss = 0.13877273695543407
Trained batch 40 in epoch 1, gen_loss = 1.2155488322420818, disc_loss = 0.13826168973634884
Trained batch 41 in epoch 1, gen_loss = 1.240683825243087, disc_loss = 0.13900696743457092
Trained batch 42 in epoch 1, gen_loss = 1.2285227997358454, disc_loss = 0.1472863521167012
Trained batch 43 in epoch 1, gen_loss = 1.2300004904920405, disc_loss = 0.14693903423507104
Trained batch 44 in epoch 1, gen_loss = 1.228562969631619, disc_loss = 0.14725352235966258
Trained batch 45 in epoch 1, gen_loss = 1.223028399374174, disc_loss = 0.14755636688483798
Trained batch 46 in epoch 1, gen_loss = 1.2190192950532792, disc_loss = 0.14703856955500358
Trained batch 47 in epoch 1, gen_loss = 1.2191052548587322, disc_loss = 0.14650473503085473
Trained batch 48 in epoch 1, gen_loss = 1.2155116103133377, disc_loss = 0.14616883660153468
Trained batch 49 in epoch 1, gen_loss = 1.2148188650608063, disc_loss = 0.14458831824362278
Trained batch 50 in epoch 1, gen_loss = 1.2104279024928224, disc_loss = 0.14402438824375471
Trained batch 51 in epoch 1, gen_loss = 1.2131900936365128, disc_loss = 0.14474331938589996
Trained batch 52 in epoch 1, gen_loss = 1.2126830220222473, disc_loss = 0.1438769223695656
Trained batch 53 in epoch 1, gen_loss = 1.2064872350957658, disc_loss = 0.1436113326775807
Trained batch 54 in epoch 1, gen_loss = 1.2205067970535972, disc_loss = 0.1477710066193884
Trained batch 55 in epoch 1, gen_loss = 1.2135992550424166, disc_loss = 0.14885161025449634
Trained batch 56 in epoch 1, gen_loss = 1.2102818060339542, disc_loss = 0.14793075287812635
Trained batch 57 in epoch 1, gen_loss = 1.2123271997632652, disc_loss = 0.1481143383245016
Trained batch 58 in epoch 1, gen_loss = 1.2116497744948178, disc_loss = 0.147167502634101
Trained batch 59 in epoch 1, gen_loss = 1.209628368417422, disc_loss = 0.14653129360328118
Trained batch 60 in epoch 1, gen_loss = 1.2075729633941026, disc_loss = 0.1461276781485706
Trained batch 61 in epoch 1, gen_loss = 1.2094427222205746, disc_loss = 0.14511599866372923
Trained batch 62 in epoch 1, gen_loss = 1.2062556923381866, disc_loss = 0.14473213332276497
Trained batch 63 in epoch 1, gen_loss = 1.2072052946314216, disc_loss = 0.14456694113323465
Trained batch 64 in epoch 1, gen_loss = 1.208532072030581, disc_loss = 0.14311487732025294
Trained batch 65 in epoch 1, gen_loss = 1.2053142126762506, disc_loss = 0.14259642227129501
Trained batch 66 in epoch 1, gen_loss = 1.20838435995045, disc_loss = 0.14216523595265487
Trained batch 67 in epoch 1, gen_loss = 1.2047882404397516, disc_loss = 0.14174125716090202
Trained batch 68 in epoch 1, gen_loss = 1.2103888323341592, disc_loss = 0.1407565541457439
Trained batch 69 in epoch 1, gen_loss = 1.2133525294916971, disc_loss = 0.13914347839142596
Trained batch 70 in epoch 1, gen_loss = 1.211330557373208, disc_loss = 0.13829037426433094
Trained batch 71 in epoch 1, gen_loss = 1.2225093137886789, disc_loss = 0.1383354012440476
Trained batch 72 in epoch 1, gen_loss = 1.2169696721312118, disc_loss = 0.1391249848657275
Trained batch 73 in epoch 1, gen_loss = 1.2217411390832953, disc_loss = 0.13842304206981854
Trained batch 74 in epoch 1, gen_loss = 1.2237580275535584, disc_loss = 0.1373316398759683
Trained batch 75 in epoch 1, gen_loss = 1.2212448786748082, disc_loss = 0.13668722517200207
Trained batch 76 in epoch 1, gen_loss = 1.2225961739366704, disc_loss = 0.1359553008594296
Trained batch 77 in epoch 1, gen_loss = 1.221728693980437, disc_loss = 0.13532868844385332
Trained batch 78 in epoch 1, gen_loss = 1.2214965013009083, disc_loss = 0.1346505206502691
Trained batch 79 in epoch 1, gen_loss = 1.2224787034094333, disc_loss = 0.13449359252117574
Trained batch 80 in epoch 1, gen_loss = 1.2277101830199912, disc_loss = 0.13347427813727178
Trained batch 81 in epoch 1, gen_loss = 1.224027568974146, disc_loss = 0.1337771323941103
Trained batch 82 in epoch 1, gen_loss = 1.2321813946746918, disc_loss = 0.13388015769691353
Trained batch 83 in epoch 1, gen_loss = 1.2290021351405553, disc_loss = 0.1333591623143071
Trained batch 84 in epoch 1, gen_loss = 1.230431702557732, disc_loss = 0.1331804400857757
Trained batch 85 in epoch 1, gen_loss = 1.2289358114087305, disc_loss = 0.13274382791200348
Trained batch 86 in epoch 1, gen_loss = 1.2312360097622048, disc_loss = 0.13304355406555637
Trained batch 87 in epoch 1, gen_loss = 1.2288154607469386, disc_loss = 0.1325432878326286
Trained batch 88 in epoch 1, gen_loss = 1.232071840361263, disc_loss = 0.1320608632450693
Trained batch 89 in epoch 1, gen_loss = 1.22631868786282, disc_loss = 0.13351684105065134
Trained batch 90 in epoch 1, gen_loss = 1.2323414847091003, disc_loss = 0.13502836644977004
Trained batch 91 in epoch 1, gen_loss = 1.227922110453896, disc_loss = 0.1360227659182704
Trained batch 92 in epoch 1, gen_loss = 1.2257366705966253, disc_loss = 0.13655570750274965
Trained batch 93 in epoch 1, gen_loss = 1.2269179034740367, disc_loss = 0.1366172971085031
Trained batch 94 in epoch 1, gen_loss = 1.2229510131635164, disc_loss = 0.13679455871644772
Trained batch 95 in epoch 1, gen_loss = 1.222509606430928, disc_loss = 0.13674064174604914
Trained batch 96 in epoch 1, gen_loss = 1.2218485259518181, disc_loss = 0.13644205970862477
Trained batch 97 in epoch 1, gen_loss = 1.2187953487950929, disc_loss = 0.1361810108076553
Trained batch 98 in epoch 1, gen_loss = 1.2182969210123775, disc_loss = 0.13576823894423667
Trained batch 99 in epoch 1, gen_loss = 1.2163642627000808, disc_loss = 0.13559383668005467
Trained batch 100 in epoch 1, gen_loss = 1.2164551686532428, disc_loss = 0.13540281775859322
Trained batch 101 in epoch 1, gen_loss = 1.220415183726479, disc_loss = 0.13429461255231323
Trained batch 102 in epoch 1, gen_loss = 1.2149091351379468, disc_loss = 0.1357112707371272
Trained batch 103 in epoch 1, gen_loss = 1.2209483528366456, disc_loss = 0.13685537656196034
Trained batch 104 in epoch 1, gen_loss = 1.218872554529281, disc_loss = 0.13674452060035297
Trained batch 105 in epoch 1, gen_loss = 1.2150136294229976, disc_loss = 0.13713410914928284
Trained batch 106 in epoch 1, gen_loss = 1.219162308724127, disc_loss = 0.13789352673654245
Trained batch 107 in epoch 1, gen_loss = 1.216748947898547, disc_loss = 0.1377199432571177
Trained batch 108 in epoch 1, gen_loss = 1.218801539425456, disc_loss = 0.13685244591821225
Trained batch 109 in epoch 1, gen_loss = 1.21697803681547, disc_loss = 0.13647351478311148
Trained batch 110 in epoch 1, gen_loss = 1.2144409767142288, disc_loss = 0.1363904499994205
Trained batch 111 in epoch 1, gen_loss = 1.2155097451593195, disc_loss = 0.136104609850528
Trained batch 112 in epoch 1, gen_loss = 1.2136060606061885, disc_loss = 0.13580558366611994
Trained batch 113 in epoch 1, gen_loss = 1.2132335174501987, disc_loss = 0.13537897793739512
Trained batch 114 in epoch 1, gen_loss = 1.2136915875517804, disc_loss = 0.13489557488457016
Trained batch 115 in epoch 1, gen_loss = 1.2172710736250054, disc_loss = 0.13440461941705695
Trained batch 116 in epoch 1, gen_loss = 1.2153485076040285, disc_loss = 0.1343780769687942
Trained batch 117 in epoch 1, gen_loss = 1.2180797922409188, disc_loss = 0.13360882108494387
Trained batch 118 in epoch 1, gen_loss = 1.22036541510029, disc_loss = 0.13280261289171813
Trained batch 119 in epoch 1, gen_loss = 1.2200701971848806, disc_loss = 0.13216135473921894
Trained batch 120 in epoch 1, gen_loss = 1.221335192357213, disc_loss = 0.13145559746002364
Trained batch 121 in epoch 1, gen_loss = 1.2234997260765952, disc_loss = 0.13063065626765372
Trained batch 122 in epoch 1, gen_loss = 1.2302653072326164, disc_loss = 0.12982358781969158
Trained batch 123 in epoch 1, gen_loss = 1.2322163341506835, disc_loss = 0.12903985037137905
Trained batch 124 in epoch 1, gen_loss = 1.2343911561965943, disc_loss = 0.12819990761578082
Trained batch 125 in epoch 1, gen_loss = 1.2415046303991288, disc_loss = 0.12756364935979483
Trained batch 126 in epoch 1, gen_loss = 1.2410047992946596, disc_loss = 0.12688966484109718
Trained batch 127 in epoch 1, gen_loss = 1.2437183037400246, disc_loss = 0.126069864796591
Trained batch 128 in epoch 1, gen_loss = 1.2439514740492947, disc_loss = 0.12530638369940972
Trained batch 129 in epoch 1, gen_loss = 1.2508177518844605, disc_loss = 0.12472272612727606
Trained batch 130 in epoch 1, gen_loss = 1.2530704600210407, disc_loss = 0.12395318947334326
Trained batch 131 in epoch 1, gen_loss = 1.254059326468092, disc_loss = 0.12325820191340013
Trained batch 132 in epoch 1, gen_loss = 1.2529632247480236, disc_loss = 0.1227309566579367
Trained batch 133 in epoch 1, gen_loss = 1.2556620329173642, disc_loss = 0.12285683265150484
Trained batch 134 in epoch 1, gen_loss = 1.2513259216591164, disc_loss = 0.12391645041880785
Trained batch 135 in epoch 1, gen_loss = 1.2563451028922026, disc_loss = 0.12637577551033566
Trained batch 136 in epoch 1, gen_loss = 1.2531095073170906, disc_loss = 0.126967691972743
Trained batch 137 in epoch 1, gen_loss = 1.251160230325616, disc_loss = 0.12687442883633185
Trained batch 138 in epoch 1, gen_loss = 1.252170836325172, disc_loss = 0.12750976087806895
Trained batch 139 in epoch 1, gen_loss = 1.2511128434113095, disc_loss = 0.12866213247179986
Trained batch 140 in epoch 1, gen_loss = 1.2489815954620958, disc_loss = 0.12917760754307955
Trained batch 141 in epoch 1, gen_loss = 1.248578301198046, disc_loss = 0.1293936890195793
Trained batch 142 in epoch 1, gen_loss = 1.246223127508497, disc_loss = 0.12946085100407367
Trained batch 143 in epoch 1, gen_loss = 1.2455258232851822, disc_loss = 0.1294984146952629
Trained batch 144 in epoch 1, gen_loss = 1.243435077831663, disc_loss = 0.12940156254275093
Trained batch 145 in epoch 1, gen_loss = 1.2427172097441268, disc_loss = 0.12937696176032498
Trained batch 146 in epoch 1, gen_loss = 1.2400493402870334, disc_loss = 0.12945175333087947
Trained batch 147 in epoch 1, gen_loss = 1.2397899531029366, disc_loss = 0.12965240440255887
Trained batch 148 in epoch 1, gen_loss = 1.2373808686365217, disc_loss = 0.12968157001789785
Trained batch 149 in epoch 1, gen_loss = 1.238128306865692, disc_loss = 0.12934178243080774
Trained batch 150 in epoch 1, gen_loss = 1.2371265659269117, disc_loss = 0.12905395583601187
Trained batch 151 in epoch 1, gen_loss = 1.2366262501791905, disc_loss = 0.1285757699393128
Trained batch 152 in epoch 1, gen_loss = 1.2360230146669875, disc_loss = 0.12835802585860484
Trained batch 153 in epoch 1, gen_loss = 1.2369631172774673, disc_loss = 0.12775274743507434
Trained batch 154 in epoch 1, gen_loss = 1.236096522115892, disc_loss = 0.12728370807824596
Trained batch 155 in epoch 1, gen_loss = 1.2365017968874712, disc_loss = 0.12702617646218875
Trained batch 156 in epoch 1, gen_loss = 1.236785157470946, disc_loss = 0.12646632591725154
Trained batch 157 in epoch 1, gen_loss = 1.2377910372577137, disc_loss = 0.12581089358258096
Trained batch 158 in epoch 1, gen_loss = 1.23898143588372, disc_loss = 0.12522840277297692
Trained batch 159 in epoch 1, gen_loss = 1.2367521062493325, disc_loss = 0.12517372893635184
Trained batch 160 in epoch 1, gen_loss = 1.2435291968517421, disc_loss = 0.12628249780084036
Trained batch 161 in epoch 1, gen_loss = 1.2402689607790958, disc_loss = 0.12751799566602265
Trained batch 162 in epoch 1, gen_loss = 1.2401505492947584, disc_loss = 0.1270997361765683
Trained batch 163 in epoch 1, gen_loss = 1.2394259059574546, disc_loss = 0.12725743308390786
Trained batch 164 in epoch 1, gen_loss = 1.2385249148715627, disc_loss = 0.1270556379674059
Trained batch 165 in epoch 1, gen_loss = 1.2361405197396336, disc_loss = 0.12717715662017645
Trained batch 166 in epoch 1, gen_loss = 1.2370501271264995, disc_loss = 0.12711103958730213
Trained batch 167 in epoch 1, gen_loss = 1.2387454275574004, disc_loss = 0.12654585794856152
Trained batch 168 in epoch 1, gen_loss = 1.2360667392346987, disc_loss = 0.12683366358103837
Trained batch 169 in epoch 1, gen_loss = 1.2375406531726614, disc_loss = 0.1267073278041447
Trained batch 170 in epoch 1, gen_loss = 1.2378337222930285, disc_loss = 0.1263192132856065
Trained batch 171 in epoch 1, gen_loss = 1.2353292405605316, disc_loss = 0.12632064787714287
Trained batch 172 in epoch 1, gen_loss = 1.2369517646083943, disc_loss = 0.1264479717379705
Trained batch 173 in epoch 1, gen_loss = 1.2361005106191525, disc_loss = 0.1261215422559401
Trained batch 174 in epoch 1, gen_loss = 1.2342274338858468, disc_loss = 0.12601665609649249
Trained batch 175 in epoch 1, gen_loss = 1.2361797013066032, disc_loss = 0.12616049830632453
Trained batch 176 in epoch 1, gen_loss = 1.2340709833102037, disc_loss = 0.12629129297736674
Trained batch 177 in epoch 1, gen_loss = 1.2344846182994629, disc_loss = 0.12609454263210967
Trained batch 178 in epoch 1, gen_loss = 1.2334693583696248, disc_loss = 0.12578359947607504
Trained batch 179 in epoch 1, gen_loss = 1.2335377679930792, disc_loss = 0.12548770881775353
Trained batch 180 in epoch 1, gen_loss = 1.2342435035916324, disc_loss = 0.12517937278961608
Trained batch 181 in epoch 1, gen_loss = 1.2332582971551915, disc_loss = 0.1248696259130816
Trained batch 182 in epoch 1, gen_loss = 1.2362303662169827, disc_loss = 0.1244227682835743
Trained batch 183 in epoch 1, gen_loss = 1.2339430010837058, disc_loss = 0.12448850527162784
Trained batch 184 in epoch 1, gen_loss = 1.2367072079632733, disc_loss = 0.12490471659882649
Trained batch 185 in epoch 1, gen_loss = 1.234536128659402, disc_loss = 0.12497717408483387
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 1.305922508239746, disc_loss = 0.058614328503608704
Trained batch 1 in epoch 2, gen_loss = 1.3011322021484375, disc_loss = 0.07009327411651611
Trained batch 2 in epoch 2, gen_loss = 1.1514232953389485, disc_loss = 0.08888632555802663
Trained batch 3 in epoch 2, gen_loss = 1.1877399384975433, disc_loss = 0.0919620431959629
Trained batch 4 in epoch 2, gen_loss = 1.1687118291854859, disc_loss = 0.08800996541976928
Trained batch 5 in epoch 2, gen_loss = 1.1824793020884197, disc_loss = 0.08913749953111012
Trained batch 6 in epoch 2, gen_loss = 1.1686258997235979, disc_loss = 0.08247425939355578
Trained batch 7 in epoch 2, gen_loss = 1.179706647992134, disc_loss = 0.08234073035418987
Trained batch 8 in epoch 2, gen_loss = 1.1904689868291218, disc_loss = 0.07933235499593946
Trained batch 9 in epoch 2, gen_loss = 1.1797808051109313, disc_loss = 0.07930428981781006
Trained batch 10 in epoch 2, gen_loss = 1.195535052906383, disc_loss = 0.07782541621815074
Trained batch 11 in epoch 2, gen_loss = 1.18071116010348, disc_loss = 0.07811345222095649
Trained batch 12 in epoch 2, gen_loss = 1.2124551626352162, disc_loss = 0.09128431230783463
Trained batch 13 in epoch 2, gen_loss = 1.1781541492257799, disc_loss = 0.10206672921776772
Trained batch 14 in epoch 2, gen_loss = 1.1750455339749655, disc_loss = 0.10233812928199768
Trained batch 15 in epoch 2, gen_loss = 1.1889352314174175, disc_loss = 0.10454585775732994
Trained batch 16 in epoch 2, gen_loss = 1.1669550222509049, disc_loss = 0.10701748991713804
Trained batch 17 in epoch 2, gen_loss = 1.1640571885638766, disc_loss = 0.10688101831409666
Trained batch 18 in epoch 2, gen_loss = 1.1706186721199436, disc_loss = 0.10673753721149344
Trained batch 19 in epoch 2, gen_loss = 1.1737189292907715, disc_loss = 0.10432203691452742
Trained batch 20 in epoch 2, gen_loss = 1.1640258999097914, disc_loss = 0.10580373927950859
Trained batch 21 in epoch 2, gen_loss = 1.2025502838871696, disc_loss = 0.11348905329677192
Trained batch 22 in epoch 2, gen_loss = 1.1768638647120933, disc_loss = 0.12474504356151042
Trained batch 23 in epoch 2, gen_loss = 1.1800190831224124, disc_loss = 0.1279029273428023
Trained batch 24 in epoch 2, gen_loss = 1.177631537914276, disc_loss = 0.13420323237776757
Trained batch 25 in epoch 2, gen_loss = 1.171258841569607, disc_loss = 0.13742072120881998
Trained batch 26 in epoch 2, gen_loss = 1.1643987849906638, disc_loss = 0.13814463149066325
Trained batch 27 in epoch 2, gen_loss = 1.158341258764267, disc_loss = 0.13865390619529144
Trained batch 28 in epoch 2, gen_loss = 1.1563719428818802, disc_loss = 0.1390691665482932
Trained batch 29 in epoch 2, gen_loss = 1.1488083362579347, disc_loss = 0.13853562908867995
Trained batch 30 in epoch 2, gen_loss = 1.1503895367345502, disc_loss = 0.13782391853390202
Trained batch 31 in epoch 2, gen_loss = 1.1440419349819422, disc_loss = 0.13811096304561943
Trained batch 32 in epoch 2, gen_loss = 1.1376476486523945, disc_loss = 0.13734986621773604
Trained batch 33 in epoch 2, gen_loss = 1.1406726994935203, disc_loss = 0.13658829044331522
Trained batch 34 in epoch 2, gen_loss = 1.1335004006113325, disc_loss = 0.13610783272555896
Trained batch 35 in epoch 2, gen_loss = 1.1297711100843217, disc_loss = 0.13488721009343863
Trained batch 36 in epoch 2, gen_loss = 1.140073560379647, disc_loss = 0.1367559436003904
Trained batch 37 in epoch 2, gen_loss = 1.1274972934471934, disc_loss = 0.14071826509347088
Trained batch 38 in epoch 2, gen_loss = 1.1260149050981572, disc_loss = 0.13991616714077118
Trained batch 39 in epoch 2, gen_loss = 1.1356986790895462, disc_loss = 0.14086473332718014
Trained batch 40 in epoch 2, gen_loss = 1.1257623739358855, disc_loss = 0.1419456929150151
Trained batch 41 in epoch 2, gen_loss = 1.127056094862166, disc_loss = 0.14109017762045065
Trained batch 42 in epoch 2, gen_loss = 1.1313210102014764, disc_loss = 0.14060206858571186
Trained batch 43 in epoch 2, gen_loss = 1.1254441209814765, disc_loss = 0.14003282506018877
Trained batch 44 in epoch 2, gen_loss = 1.1236212637689378, disc_loss = 0.13938490971922873
Trained batch 45 in epoch 2, gen_loss = 1.1304742007151893, disc_loss = 0.1397470238254122
Trained batch 46 in epoch 2, gen_loss = 1.1257494003214734, disc_loss = 0.1409647657357632
Trained batch 47 in epoch 2, gen_loss = 1.1291390508413315, disc_loss = 0.14039627253077924
Trained batch 48 in epoch 2, gen_loss = 1.1316355929082753, disc_loss = 0.13900657005760134
Trained batch 49 in epoch 2, gen_loss = 1.1373100280761719, disc_loss = 0.1367918746173382
Trained batch 50 in epoch 2, gen_loss = 1.135349568198709, disc_loss = 0.1354229486748284
Trained batch 51 in epoch 2, gen_loss = 1.137883722782135, disc_loss = 0.13398637665578952
Trained batch 52 in epoch 2, gen_loss = 1.1452981211104483, disc_loss = 0.13254276381910973
Trained batch 53 in epoch 2, gen_loss = 1.1504708727200825, disc_loss = 0.13053009000227409
Trained batch 54 in epoch 2, gen_loss = 1.1534161372618241, disc_loss = 0.1286620711738413
Trained batch 55 in epoch 2, gen_loss = 1.1587329081126623, disc_loss = 0.12718776174421823
Trained batch 56 in epoch 2, gen_loss = 1.164116621017456, disc_loss = 0.12518615226604438
Trained batch 57 in epoch 2, gen_loss = 1.1674387002813404, disc_loss = 0.12345675870390801
Trained batch 58 in epoch 2, gen_loss = 1.1734482696500874, disc_loss = 0.12201392622191017
Trained batch 59 in epoch 2, gen_loss = 1.1766090532143911, disc_loss = 0.1203643820869426
Trained batch 60 in epoch 2, gen_loss = 1.175748881746511, disc_loss = 0.11909264658928895
Trained batch 61 in epoch 2, gen_loss = 1.1839384821153456, disc_loss = 0.1203577522368681
Trained batch 62 in epoch 2, gen_loss = 1.1753340022904533, disc_loss = 0.12365177548712208
Trained batch 63 in epoch 2, gen_loss = 1.180944605730474, disc_loss = 0.12286561579094268
Trained batch 64 in epoch 2, gen_loss = 1.1786861245448772, disc_loss = 0.1225009637669875
Trained batch 65 in epoch 2, gen_loss = 1.1756490044521564, disc_loss = 0.12227544383230535
Trained batch 66 in epoch 2, gen_loss = 1.1751230661548786, disc_loss = 0.12190532742707587
Trained batch 67 in epoch 2, gen_loss = 1.1750637336688883, disc_loss = 0.12157744040493579
Trained batch 68 in epoch 2, gen_loss = 1.1726328920626985, disc_loss = 0.1211072334182867
Trained batch 69 in epoch 2, gen_loss = 1.175431933573314, disc_loss = 0.12013525890984705
Trained batch 70 in epoch 2, gen_loss = 1.1746104812957872, disc_loss = 0.11928028521508398
Trained batch 71 in epoch 2, gen_loss = 1.1739566135737631, disc_loss = 0.11863954574801028
Trained batch 72 in epoch 2, gen_loss = 1.1758571528408626, disc_loss = 0.11777576189233016
Trained batch 73 in epoch 2, gen_loss = 1.1730744830659918, disc_loss = 0.11742852363936804
Trained batch 74 in epoch 2, gen_loss = 1.1823908193906147, disc_loss = 0.1185837147384882
Trained batch 75 in epoch 2, gen_loss = 1.1746977630414461, disc_loss = 0.12110693024863538
Trained batch 76 in epoch 2, gen_loss = 1.1732972782927673, disc_loss = 0.12038149633868174
Trained batch 77 in epoch 2, gen_loss = 1.1773211405827448, disc_loss = 0.12065158323504221
Trained batch 78 in epoch 2, gen_loss = 1.1767377159263515, disc_loss = 0.12037655840851838
Trained batch 79 in epoch 2, gen_loss = 1.1740806490182876, disc_loss = 0.1202186926966533
Trained batch 80 in epoch 2, gen_loss = 1.174079950944877, disc_loss = 0.11959055275368838
Trained batch 81 in epoch 2, gen_loss = 1.17576922149193, disc_loss = 0.11917657566415828
Trained batch 82 in epoch 2, gen_loss = 1.1719182428107204, disc_loss = 0.11912164251398609
Trained batch 83 in epoch 2, gen_loss = 1.173789611884526, disc_loss = 0.1202184055665774
Trained batch 84 in epoch 2, gen_loss = 1.1710397159352022, disc_loss = 0.11999807636089185
Trained batch 85 in epoch 2, gen_loss = 1.1730827342632204, disc_loss = 0.11937265078602143
Trained batch 86 in epoch 2, gen_loss = 1.1738071140201611, disc_loss = 0.11861593132817197
Trained batch 87 in epoch 2, gen_loss = 1.1747993176633662, disc_loss = 0.11766805544241586
Trained batch 88 in epoch 2, gen_loss = 1.17569247122561, disc_loss = 0.11692529759798827
Trained batch 89 in epoch 2, gen_loss = 1.1752651413281758, disc_loss = 0.11624153473724921
Trained batch 90 in epoch 2, gen_loss = 1.1809274429803367, disc_loss = 0.11602176138414787
Trained batch 91 in epoch 2, gen_loss = 1.17784896881684, disc_loss = 0.11616681615376602
Trained batch 92 in epoch 2, gen_loss = 1.178180089560888, disc_loss = 0.11590221478173168
Trained batch 93 in epoch 2, gen_loss = 1.1782413771811953, disc_loss = 0.11530724019208487
Trained batch 94 in epoch 2, gen_loss = 1.1794105504688464, disc_loss = 0.11478272921552783
Trained batch 95 in epoch 2, gen_loss = 1.179695578912894, disc_loss = 0.11413153022294864
Trained batch 96 in epoch 2, gen_loss = 1.1848982056391608, disc_loss = 0.11365792418340433
Trained batch 97 in epoch 2, gen_loss = 1.190380542862172, disc_loss = 0.11274781127517321
Trained batch 98 in epoch 2, gen_loss = 1.1876666913128862, disc_loss = 0.11301407914119538
Trained batch 99 in epoch 2, gen_loss = 1.190086722970009, disc_loss = 0.11216666013002395
Trained batch 100 in epoch 2, gen_loss = 1.1962428547368191, disc_loss = 0.1121764619751732
Trained batch 101 in epoch 2, gen_loss = 1.1948070204725452, disc_loss = 0.11149204949684002
Trained batch 102 in epoch 2, gen_loss = 1.1932262859298188, disc_loss = 0.11110440073806105
Trained batch 103 in epoch 2, gen_loss = 1.1968784051445813, disc_loss = 0.11072541719589096
Trained batch 104 in epoch 2, gen_loss = 1.196415737129393, disc_loss = 0.11004659707347551
Trained batch 105 in epoch 2, gen_loss = 1.197486379798853, disc_loss = 0.1094352283497464
Trained batch 106 in epoch 2, gen_loss = 1.19588651556835, disc_loss = 0.10898599509045342
Trained batch 107 in epoch 2, gen_loss = 1.2008398644350193, disc_loss = 0.10897145868727455
Trained batch 108 in epoch 2, gen_loss = 1.2020005310347321, disc_loss = 0.10825385770188012
Trained batch 109 in epoch 2, gen_loss = 1.1992138228633187, disc_loss = 0.10836176162754947
Trained batch 110 in epoch 2, gen_loss = 1.2015929603361868, disc_loss = 0.10778412160774072
Trained batch 111 in epoch 2, gen_loss = 1.204969531191247, disc_loss = 0.10765350136041109
Trained batch 112 in epoch 2, gen_loss = 1.201011534813231, disc_loss = 0.10839928203649753
Trained batch 113 in epoch 2, gen_loss = 1.2049091149840438, disc_loss = 0.1085298991222915
Trained batch 114 in epoch 2, gen_loss = 1.2091957304788672, disc_loss = 0.1083707136142513
Trained batch 115 in epoch 2, gen_loss = 1.206009371013477, disc_loss = 0.10902052326127887
Trained batch 116 in epoch 2, gen_loss = 1.2074824719347506, disc_loss = 0.10854655270202038
Trained batch 117 in epoch 2, gen_loss = 1.2070354693016763, disc_loss = 0.10830884441038814
Trained batch 118 in epoch 2, gen_loss = 1.2103939141545976, disc_loss = 0.10786328297264937
Trained batch 119 in epoch 2, gen_loss = 1.2071992769837379, disc_loss = 0.10794623632294437
Trained batch 120 in epoch 2, gen_loss = 1.2089268998666243, disc_loss = 0.10759340671529947
Trained batch 121 in epoch 2, gen_loss = 1.2128133680976805, disc_loss = 0.1069816250628868
Trained batch 122 in epoch 2, gen_loss = 1.2099136855544113, disc_loss = 0.10705992547658885
Trained batch 123 in epoch 2, gen_loss = 1.2122189099750211, disc_loss = 0.10670063751299054
Trained batch 124 in epoch 2, gen_loss = 1.2131790814399719, disc_loss = 0.10619696740806103
Trained batch 125 in epoch 2, gen_loss = 1.2115671506949834, disc_loss = 0.10585012906304901
Trained batch 126 in epoch 2, gen_loss = 1.2136042235404487, disc_loss = 0.10582227176275309
Trained batch 127 in epoch 2, gen_loss = 1.2109800716862082, disc_loss = 0.10577318990544882
Trained batch 128 in epoch 2, gen_loss = 1.2115694007208182, disc_loss = 0.10560943964551124
Trained batch 129 in epoch 2, gen_loss = 1.211319875717163, disc_loss = 0.10543156620115042
Trained batch 130 in epoch 2, gen_loss = 1.2126075966667582, disc_loss = 0.10484638342363689
Trained batch 131 in epoch 2, gen_loss = 1.2122819044373252, disc_loss = 0.10444833302983281
Trained batch 132 in epoch 2, gen_loss = 1.21765042606153, disc_loss = 0.10420904099885234
Trained batch 133 in epoch 2, gen_loss = 1.2148120483355735, disc_loss = 0.10446184649785507
Trained batch 134 in epoch 2, gen_loss = 1.2157429845244796, disc_loss = 0.10415004242073607
Trained batch 135 in epoch 2, gen_loss = 1.2182306761250776, disc_loss = 0.10389005490030874
Trained batch 136 in epoch 2, gen_loss = 1.214825183805758, disc_loss = 0.10418359846909986
Trained batch 137 in epoch 2, gen_loss = 1.2170214350672737, disc_loss = 0.10409534597040518
Trained batch 138 in epoch 2, gen_loss = 1.2185556845699284, disc_loss = 0.10362789858963421
Trained batch 139 in epoch 2, gen_loss = 1.219294877563204, disc_loss = 0.10307588312508804
Trained batch 140 in epoch 2, gen_loss = 1.2197037089801004, disc_loss = 0.10252630513769093
Trained batch 141 in epoch 2, gen_loss = 1.221795401942562, disc_loss = 0.10195416100585544
Trained batch 142 in epoch 2, gen_loss = 1.2267470784954257, disc_loss = 0.10147463846821468
Trained batch 143 in epoch 2, gen_loss = 1.2256768834259775, disc_loss = 0.10120293514854792
Trained batch 144 in epoch 2, gen_loss = 1.2277532289768087, disc_loss = 0.1006566030583505
Trained batch 145 in epoch 2, gen_loss = 1.230515907072041, disc_loss = 0.10008655547177138
Trained batch 146 in epoch 2, gen_loss = 1.2319899383856325, disc_loss = 0.09961392781158694
Trained batch 147 in epoch 2, gen_loss = 1.2303103361580823, disc_loss = 0.09952409510072824
Trained batch 148 in epoch 2, gen_loss = 1.23367236764639, disc_loss = 0.09927208679134414
Trained batch 149 in epoch 2, gen_loss = 1.2332375733057659, disc_loss = 0.09896627329289913
Trained batch 150 in epoch 2, gen_loss = 1.23160149798488, disc_loss = 0.09902688167643862
Trained batch 151 in epoch 2, gen_loss = 1.2366424202919006, disc_loss = 0.09969213622083005
Trained batch 152 in epoch 2, gen_loss = 1.2338529790149015, disc_loss = 0.10004906227288682
Trained batch 153 in epoch 2, gen_loss = 1.2346673139504023, disc_loss = 0.09991242240678955
Trained batch 154 in epoch 2, gen_loss = 1.2356899526811416, disc_loss = 0.0996805498436574
Trained batch 155 in epoch 2, gen_loss = 1.235836426799114, disc_loss = 0.09931160089297172
Trained batch 156 in epoch 2, gen_loss = 1.2401799217910523, disc_loss = 0.09890741385092401
Trained batch 157 in epoch 2, gen_loss = 1.237442751851263, disc_loss = 0.09919411651318587
Trained batch 158 in epoch 2, gen_loss = 1.241201937198639, disc_loss = 0.09969308569371325
Trained batch 159 in epoch 2, gen_loss = 1.2380937535315752, disc_loss = 0.10003515537828207
Trained batch 160 in epoch 2, gen_loss = 1.2385805449130372, disc_loss = 0.10004394006284868
Trained batch 161 in epoch 2, gen_loss = 1.23709319734279, disc_loss = 0.09997272220106772
Trained batch 162 in epoch 2, gen_loss = 1.236841776253987, disc_loss = 0.09979281771036745
Trained batch 163 in epoch 2, gen_loss = 1.2353574600888462, disc_loss = 0.09967550926092195
Trained batch 164 in epoch 2, gen_loss = 1.2349958105520769, disc_loss = 0.09962600334124132
Trained batch 165 in epoch 2, gen_loss = 1.2327278906322388, disc_loss = 0.09970777104777026
Trained batch 166 in epoch 2, gen_loss = 1.2336258142294285, disc_loss = 0.0998278919629708
Trained batch 167 in epoch 2, gen_loss = 1.2316545059993154, disc_loss = 0.09974942183388132
Trained batch 168 in epoch 2, gen_loss = 1.230910032105869, disc_loss = 0.09954976409497346
Trained batch 169 in epoch 2, gen_loss = 1.2305960686767803, disc_loss = 0.09930411472040064
Trained batch 170 in epoch 2, gen_loss = 1.2318835415338214, disc_loss = 0.09937372903900536
Trained batch 171 in epoch 2, gen_loss = 1.230176182333813, disc_loss = 0.09926393784062806
Trained batch 172 in epoch 2, gen_loss = 1.2328892460448204, disc_loss = 0.09913864533680712
Trained batch 173 in epoch 2, gen_loss = 1.2327931985772889, disc_loss = 0.09878989488914094
Trained batch 174 in epoch 2, gen_loss = 1.2312282259123666, disc_loss = 0.09867956233876092
Trained batch 175 in epoch 2, gen_loss = 1.2359420071271332, disc_loss = 0.09888201676817103
Trained batch 176 in epoch 2, gen_loss = 1.234527285489659, disc_loss = 0.09883561583056961
Trained batch 177 in epoch 2, gen_loss = 1.2337777601199205, disc_loss = 0.09865912313709098
Trained batch 178 in epoch 2, gen_loss = 1.2357518066907063, disc_loss = 0.0985977002445546
Trained batch 179 in epoch 2, gen_loss = 1.2360389159785377, disc_loss = 0.09829164656500021
Trained batch 180 in epoch 2, gen_loss = 1.2377344712368032, disc_loss = 0.0978305626104879
Trained batch 181 in epoch 2, gen_loss = 1.2366312716033432, disc_loss = 0.09761227937517586
Trained batch 182 in epoch 2, gen_loss = 1.236357980738572, disc_loss = 0.09735326249091351
Trained batch 183 in epoch 2, gen_loss = 1.2399686225082562, disc_loss = 0.09753292523648428
Trained batch 184 in epoch 2, gen_loss = 1.2382107792673884, disc_loss = 0.0975227149757179
Trained batch 185 in epoch 2, gen_loss = 1.2372996390506785, disc_loss = 0.09728688350127589
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 1.662154197692871, disc_loss = 0.07868295907974243
Trained batch 1 in epoch 3, gen_loss = 1.6092148423194885, disc_loss = 0.04946272633969784
Trained batch 2 in epoch 3, gen_loss = 1.3913392424583435, disc_loss = 0.06178053095936775
Trained batch 3 in epoch 3, gen_loss = 1.3464130908250809, disc_loss = 0.06711215805262327
Trained batch 4 in epoch 3, gen_loss = 1.2768423795700072, disc_loss = 0.07072527930140496
Trained batch 5 in epoch 3, gen_loss = 1.3141559958457947, disc_loss = 0.0820459791769584
Trained batch 6 in epoch 3, gen_loss = 1.3290573358535767, disc_loss = 0.0754566059580871
Trained batch 7 in epoch 3, gen_loss = 1.2716780230402946, disc_loss = 0.08378926804289222
Trained batch 8 in epoch 3, gen_loss = 1.3077010777261522, disc_loss = 0.08238529786467552
Trained batch 9 in epoch 3, gen_loss = 1.3061274230480193, disc_loss = 0.07731312550604344
Trained batch 10 in epoch 3, gen_loss = 1.3524024432355708, disc_loss = 0.07326239076527682
Trained batch 11 in epoch 3, gen_loss = 1.3238167117039363, disc_loss = 0.07311239341894786
Trained batch 12 in epoch 3, gen_loss = 1.3069274196257958, disc_loss = 0.07115002606923763
Trained batch 13 in epoch 3, gen_loss = 1.3237592279911041, disc_loss = 0.07264734006353787
Trained batch 14 in epoch 3, gen_loss = 1.3000577886899312, disc_loss = 0.0730217918753624
Trained batch 15 in epoch 3, gen_loss = 1.2866994105279446, disc_loss = 0.07235452113673091
Trained batch 16 in epoch 3, gen_loss = 1.2902355299276465, disc_loss = 0.071366798132658
Trained batch 17 in epoch 3, gen_loss = 1.2847033043702443, disc_loss = 0.06966655432350105
Trained batch 18 in epoch 3, gen_loss = 1.2976702420335067, disc_loss = 0.06741918535216858
Trained batch 19 in epoch 3, gen_loss = 1.3086261063814164, disc_loss = 0.06489905780181289
Trained batch 20 in epoch 3, gen_loss = 1.2881246152378263, disc_loss = 0.06865894217931089
Trained batch 21 in epoch 3, gen_loss = 1.3015933822501788, disc_loss = 0.06839063585820523
Trained batch 22 in epoch 3, gen_loss = 1.3184472918510437, disc_loss = 0.06943936184372591
Trained batch 23 in epoch 3, gen_loss = 1.326314277946949, disc_loss = 0.06799285820064445
Trained batch 24 in epoch 3, gen_loss = 1.3020448064804078, disc_loss = 0.07322765372693539
Trained batch 25 in epoch 3, gen_loss = 1.31017483656223, disc_loss = 0.07334659757235876
Trained batch 26 in epoch 3, gen_loss = 1.3231956384800099, disc_loss = 0.07227773198650943
Trained batch 27 in epoch 3, gen_loss = 1.3216287706579481, disc_loss = 0.07052420831418463
Trained batch 28 in epoch 3, gen_loss = 1.3192066735234753, disc_loss = 0.06881658058485081
Trained batch 29 in epoch 3, gen_loss = 1.3225230614344279, disc_loss = 0.06712145134806632
Trained batch 30 in epoch 3, gen_loss = 1.3195661498654274, disc_loss = 0.06591660180880178
Trained batch 31 in epoch 3, gen_loss = 1.325210653245449, disc_loss = 0.06502155878115445
Trained batch 32 in epoch 3, gen_loss = 1.338025764985518, disc_loss = 0.06363983531341408
Trained batch 33 in epoch 3, gen_loss = 1.3277184086687424, disc_loss = 0.06381322739317137
Trained batch 34 in epoch 3, gen_loss = 1.3235862834112986, disc_loss = 0.06296443800841059
Trained batch 35 in epoch 3, gen_loss = 1.3266480697525873, disc_loss = 0.06286189736177523
Trained batch 36 in epoch 3, gen_loss = 1.3257201942237649, disc_loss = 0.06227961736353668
Trained batch 37 in epoch 3, gen_loss = 1.316829347296765, disc_loss = 0.0621412344472973
Trained batch 38 in epoch 3, gen_loss = 1.3222269049057593, disc_loss = 0.06265809568457115
Trained batch 39 in epoch 3, gen_loss = 1.3202754154801368, disc_loss = 0.06201915955170989
Trained batch 40 in epoch 3, gen_loss = 1.317864675347398, disc_loss = 0.06139817861158673
Trained batch 41 in epoch 3, gen_loss = 1.3172539146173567, disc_loss = 0.060598189144262245
Trained batch 42 in epoch 3, gen_loss = 1.3350029449130214, disc_loss = 0.06091087419799594
Trained batch 43 in epoch 3, gen_loss = 1.3368700864640148, disc_loss = 0.059949168131094084
Trained batch 44 in epoch 3, gen_loss = 1.3257257686720954, disc_loss = 0.06133320898645454
Trained batch 45 in epoch 3, gen_loss = 1.3249143478663072, disc_loss = 0.060973725605594074
Trained batch 46 in epoch 3, gen_loss = 1.3364136713616392, disc_loss = 0.06330917304025051
Trained batch 47 in epoch 3, gen_loss = 1.324298221617937, disc_loss = 0.06597391830291599
Trained batch 48 in epoch 3, gen_loss = 1.3174482705641766, disc_loss = 0.06642076072796267
Trained batch 49 in epoch 3, gen_loss = 1.3167404842376709, disc_loss = 0.06883551601320505
Trained batch 50 in epoch 3, gen_loss = 1.3109897281609328, disc_loss = 0.07013218780504722
Trained batch 51 in epoch 3, gen_loss = 1.3023430888469403, disc_loss = 0.07253115341210595
Trained batch 52 in epoch 3, gen_loss = 1.3104312667306863, disc_loss = 0.07572023180436413
Trained batch 53 in epoch 3, gen_loss = 1.304721728519157, disc_loss = 0.07752331763643909
Trained batch 54 in epoch 3, gen_loss = 1.2984236933968283, disc_loss = 0.07822609574280003
Trained batch 55 in epoch 3, gen_loss = 1.2981241175106593, disc_loss = 0.08039452697682593
Trained batch 56 in epoch 3, gen_loss = 1.2938461220055295, disc_loss = 0.08055173347524383
Trained batch 57 in epoch 3, gen_loss = 1.292750070834982, disc_loss = 0.08132029572052174
Trained batch 58 in epoch 3, gen_loss = 1.2852248418129097, disc_loss = 0.08175691826490022
Trained batch 59 in epoch 3, gen_loss = 1.2837248623371125, disc_loss = 0.08154752071325978
Trained batch 60 in epoch 3, gen_loss = 1.2847059183433407, disc_loss = 0.08124100871872707
Trained batch 61 in epoch 3, gen_loss = 1.2838841657484732, disc_loss = 0.08042147392106633
Trained batch 62 in epoch 3, gen_loss = 1.2797731709858728, disc_loss = 0.0800527355204972
Trained batch 63 in epoch 3, gen_loss = 1.280679039657116, disc_loss = 0.07991618578671478
Trained batch 64 in epoch 3, gen_loss = 1.2793369843409612, disc_loss = 0.07938029906497551
Trained batch 65 in epoch 3, gen_loss = 1.2742302896398487, disc_loss = 0.0792515231860858
Trained batch 66 in epoch 3, gen_loss = 1.2781617685930053, disc_loss = 0.07883345077175703
Trained batch 67 in epoch 3, gen_loss = 1.2747224858578514, disc_loss = 0.07852029452538666
Trained batch 68 in epoch 3, gen_loss = 1.2759893467460854, disc_loss = 0.07788320925032748
Trained batch 69 in epoch 3, gen_loss = 1.274288454226085, disc_loss = 0.07736691345593759
Trained batch 70 in epoch 3, gen_loss = 1.2760424336916965, disc_loss = 0.07691753411691793
Trained batch 71 in epoch 3, gen_loss = 1.2728381380438805, disc_loss = 0.07661962506568266
Trained batch 72 in epoch 3, gen_loss = 1.274124072839136, disc_loss = 0.07628054403993365
Trained batch 73 in epoch 3, gen_loss = 1.274982269551303, disc_loss = 0.07662103715277202
Trained batch 74 in epoch 3, gen_loss = 1.2708370351791383, disc_loss = 0.07683747000992298
Trained batch 75 in epoch 3, gen_loss = 1.2701559427537417, disc_loss = 0.0761440297784774
Trained batch 76 in epoch 3, gen_loss = 1.2767921562318678, disc_loss = 0.07588379322127863
Trained batch 77 in epoch 3, gen_loss = 1.2799552113581927, disc_loss = 0.07515533464268231
Trained batch 78 in epoch 3, gen_loss = 1.2759967370878291, disc_loss = 0.07526084408164024
Trained batch 79 in epoch 3, gen_loss = 1.2792502440512181, disc_loss = 0.07492279633879662
Trained batch 80 in epoch 3, gen_loss = 1.2856489029931433, disc_loss = 0.07464513201036571
Trained batch 81 in epoch 3, gen_loss = 1.2855782865024195, disc_loss = 0.07420846956168733
Trained batch 82 in epoch 3, gen_loss = 1.2865389607038842, disc_loss = 0.0735885079456381
Trained batch 83 in epoch 3, gen_loss = 1.2859156479438145, disc_loss = 0.07295846167419638
Trained batch 84 in epoch 3, gen_loss = 1.2915924668312073, disc_loss = 0.07286253159537034
Trained batch 85 in epoch 3, gen_loss = 1.2891181409358978, disc_loss = 0.07275118505538897
Trained batch 86 in epoch 3, gen_loss = 1.2884251735676293, disc_loss = 0.07235768308927273
Trained batch 87 in epoch 3, gen_loss = 1.2968173291195522, disc_loss = 0.07266073555431583
Trained batch 88 in epoch 3, gen_loss = 1.2962774701332778, disc_loss = 0.07222282275390089
Trained batch 89 in epoch 3, gen_loss = 1.295462558666865, disc_loss = 0.071807235893276
Trained batch 90 in epoch 3, gen_loss = 1.2994781791508854, disc_loss = 0.07129023768580876
Trained batch 91 in epoch 3, gen_loss = 1.300611414987108, disc_loss = 0.07073262082817762
Trained batch 92 in epoch 3, gen_loss = 1.3002075847759043, disc_loss = 0.070290971266967
Trained batch 93 in epoch 3, gen_loss = 1.3013308016543692, disc_loss = 0.06968063568854903
Trained batch 94 in epoch 3, gen_loss = 1.3020851731300354, disc_loss = 0.06914577475307804
Trained batch 95 in epoch 3, gen_loss = 1.305669842287898, disc_loss = 0.06854053983503643
Trained batch 96 in epoch 3, gen_loss = 1.3097796765799374, disc_loss = 0.06797181620003329
Trained batch 97 in epoch 3, gen_loss = 1.3094585616977847, disc_loss = 0.06757404635261212
Trained batch 98 in epoch 3, gen_loss = 1.3108225753813079, disc_loss = 0.06708015060296865
Trained batch 99 in epoch 3, gen_loss = 1.3115128523111343, disc_loss = 0.0666618229355663
Trained batch 100 in epoch 3, gen_loss = 1.3177598402051642, disc_loss = 0.0663666936043318
Trained batch 101 in epoch 3, gen_loss = 1.3130556970250373, disc_loss = 0.06701897551287331
Trained batch 102 in epoch 3, gen_loss = 1.3165122276370964, disc_loss = 0.06694284037153408
Trained batch 103 in epoch 3, gen_loss = 1.3155354817326252, disc_loss = 0.06666334749808392
Trained batch 104 in epoch 3, gen_loss = 1.3178747216860454, disc_loss = 0.06639192167314745
Trained batch 105 in epoch 3, gen_loss = 1.3182967445760403, disc_loss = 0.0659716043814595
Trained batch 106 in epoch 3, gen_loss = 1.315981140203565, disc_loss = 0.06569316282555043
Trained batch 107 in epoch 3, gen_loss = 1.3204358093164585, disc_loss = 0.06537836978936361
Trained batch 108 in epoch 3, gen_loss = 1.3207402420700143, disc_loss = 0.0649035232175791
Trained batch 109 in epoch 3, gen_loss = 1.3211815189231526, disc_loss = 0.06444345548410307
Trained batch 110 in epoch 3, gen_loss = 1.318669933993537, disc_loss = 0.06432018971053867
Trained batch 111 in epoch 3, gen_loss = 1.3202857444328921, disc_loss = 0.06462173215446196
Trained batch 112 in epoch 3, gen_loss = 1.317550330562929, disc_loss = 0.06457920918092791
Trained batch 113 in epoch 3, gen_loss = 1.3169594454137903, disc_loss = 0.06430784441334636
Trained batch 114 in epoch 3, gen_loss = 1.3180359171784441, disc_loss = 0.06431480489023354
Trained batch 115 in epoch 3, gen_loss = 1.314729894029683, disc_loss = 0.06442985804109223
Trained batch 116 in epoch 3, gen_loss = 1.3159630298614502, disc_loss = 0.06402956893365098
Trained batch 117 in epoch 3, gen_loss = 1.3191502862057443, disc_loss = 0.06419550843726275
Trained batch 118 in epoch 3, gen_loss = 1.314748433457703, disc_loss = 0.06471840926140797
Trained batch 119 in epoch 3, gen_loss = 1.3150042692820232, disc_loss = 0.06444326255780955
Trained batch 120 in epoch 3, gen_loss = 1.3161539538832736, disc_loss = 0.06432581460488236
Trained batch 121 in epoch 3, gen_loss = 1.3144655833478833, disc_loss = 0.06421410678656864
Trained batch 122 in epoch 3, gen_loss = 1.3139567317032232, disc_loss = 0.06416237616260362
Trained batch 123 in epoch 3, gen_loss = 1.3114453919472233, disc_loss = 0.06430120154794666
Trained batch 124 in epoch 3, gen_loss = 1.3136700887680053, disc_loss = 0.0643092492967844
Trained batch 125 in epoch 3, gen_loss = 1.3133360024482486, disc_loss = 0.06408854037345875
Trained batch 126 in epoch 3, gen_loss = 1.3143105046955619, disc_loss = 0.06371157682376115
Trained batch 127 in epoch 3, gen_loss = 1.3131422363221645, disc_loss = 0.06349798721203115
Trained batch 128 in epoch 3, gen_loss = 1.3128639468851016, disc_loss = 0.063891513677415
Trained batch 129 in epoch 3, gen_loss = 1.3095657261518332, disc_loss = 0.06408618555332606
Trained batch 130 in epoch 3, gen_loss = 1.3116514441621212, disc_loss = 0.06378407462123241
Trained batch 131 in epoch 3, gen_loss = 1.3157910573663134, disc_loss = 0.06378566077204817
Trained batch 132 in epoch 3, gen_loss = 1.311680891908201, disc_loss = 0.06459089563249197
Trained batch 133 in epoch 3, gen_loss = 1.3129242983326983, disc_loss = 0.06420677171936676
Trained batch 134 in epoch 3, gen_loss = 1.320168873557338, disc_loss = 0.0643825841722665
Trained batch 135 in epoch 3, gen_loss = 1.321633116725613, disc_loss = 0.06403145591235336
Trained batch 136 in epoch 3, gen_loss = 1.319281528030869, disc_loss = 0.06412281234660287
Trained batch 137 in epoch 3, gen_loss = 1.3186252890289694, disc_loss = 0.06383826557978772
Trained batch 138 in epoch 3, gen_loss = 1.3225963385842687, disc_loss = 0.06498606927800092
Trained batch 139 in epoch 3, gen_loss = 1.3190949563469205, disc_loss = 0.06559664464688726
Trained batch 140 in epoch 3, gen_loss = 1.3181301427225696, disc_loss = 0.06638714867967663
Trained batch 141 in epoch 3, gen_loss = 1.3183635720904445, disc_loss = 0.06753230237887359
Trained batch 142 in epoch 3, gen_loss = 1.3187890957285475, disc_loss = 0.06801382912049343
Trained batch 143 in epoch 3, gen_loss = 1.317937074850003, disc_loss = 0.0682696372192974
Trained batch 144 in epoch 3, gen_loss = 1.3160536054907175, disc_loss = 0.06834240803687737
Trained batch 145 in epoch 3, gen_loss = 1.3156343776069275, disc_loss = 0.06838500781673683
Trained batch 146 in epoch 3, gen_loss = 1.3131652778508711, disc_loss = 0.0684355353036908
Trained batch 147 in epoch 3, gen_loss = 1.3148164402794194, disc_loss = 0.06900058964871474
Trained batch 148 in epoch 3, gen_loss = 1.3114121620287031, disc_loss = 0.0694970496173873
Trained batch 149 in epoch 3, gen_loss = 1.3112937128543853, disc_loss = 0.06937925240645806
Trained batch 150 in epoch 3, gen_loss = 1.3102960898386722, disc_loss = 0.06918098973665411
Trained batch 151 in epoch 3, gen_loss = 1.3118544373857348, disc_loss = 0.06913398744195308
Trained batch 152 in epoch 3, gen_loss = 1.3105384543830274, disc_loss = 0.06889301834299284
Trained batch 153 in epoch 3, gen_loss = 1.3083942660263606, disc_loss = 0.06882445174329854
Trained batch 154 in epoch 3, gen_loss = 1.3092257526613051, disc_loss = 0.06914778499593657
Trained batch 155 in epoch 3, gen_loss = 1.308831851833906, disc_loss = 0.06892648858662981
Trained batch 156 in epoch 3, gen_loss = 1.3081289002090504, disc_loss = 0.06875660219437378
Trained batch 157 in epoch 3, gen_loss = 1.3065990824488145, disc_loss = 0.06867348807097613
Trained batch 158 in epoch 3, gen_loss = 1.305903101492228, disc_loss = 0.06842737541821017
Trained batch 159 in epoch 3, gen_loss = 1.30666100718081, disc_loss = 0.06824853837024421
Trained batch 160 in epoch 3, gen_loss = 1.3056808543501432, disc_loss = 0.06800292786326467
Trained batch 161 in epoch 3, gen_loss = 1.3042303960264465, disc_loss = 0.0682130144380125
Trained batch 162 in epoch 3, gen_loss = 1.3043475023076578, disc_loss = 0.06798276550884992
Trained batch 163 in epoch 3, gen_loss = 1.3045409071009333, disc_loss = 0.0676856734676332
Trained batch 164 in epoch 3, gen_loss = 1.3038818630305204, disc_loss = 0.06746406528082761
Trained batch 165 in epoch 3, gen_loss = 1.3052137576671967, disc_loss = 0.06730679364269038
Trained batch 166 in epoch 3, gen_loss = 1.304745123414936, disc_loss = 0.06707294358910915
Trained batch 167 in epoch 3, gen_loss = 1.3050817524393399, disc_loss = 0.06690019444518146
Trained batch 168 in epoch 3, gen_loss = 1.305260916786081, disc_loss = 0.0666252740344705
Trained batch 169 in epoch 3, gen_loss = 1.3045298446627225, disc_loss = 0.06636851955862606
Trained batch 170 in epoch 3, gen_loss = 1.3064849833298844, disc_loss = 0.06624732497665617
Trained batch 171 in epoch 3, gen_loss = 1.3050103392018828, disc_loss = 0.06617310831626487
Trained batch 172 in epoch 3, gen_loss = 1.3065312677036132, disc_loss = 0.06610487737407574
Trained batch 173 in epoch 3, gen_loss = 1.3072995546905475, disc_loss = 0.06581675184184108
Trained batch 174 in epoch 3, gen_loss = 1.3049089956283568, disc_loss = 0.06601846763065883
Trained batch 175 in epoch 3, gen_loss = 1.3075765411962161, disc_loss = 0.06604785146191716
Trained batch 176 in epoch 3, gen_loss = 1.3073313343996382, disc_loss = 0.06577904727625644
Trained batch 177 in epoch 3, gen_loss = 1.306994653149937, disc_loss = 0.06581746865315048
Trained batch 178 in epoch 3, gen_loss = 1.3044350486893894, disc_loss = 0.06610383046530811
Trained batch 179 in epoch 3, gen_loss = 1.3047967983616724, disc_loss = 0.06610950524401334
Trained batch 180 in epoch 3, gen_loss = 1.3071793489034664, disc_loss = 0.06624011126300577
Trained batch 181 in epoch 3, gen_loss = 1.3047946802862398, disc_loss = 0.06669458475700774
Trained batch 182 in epoch 3, gen_loss = 1.305308344585648, disc_loss = 0.06665524590984394
Trained batch 183 in epoch 3, gen_loss = 1.307213413974513, disc_loss = 0.06672433414496481
Trained batch 184 in epoch 3, gen_loss = 1.3058263675586597, disc_loss = 0.06674223633835445
Trained batch 185 in epoch 3, gen_loss = 1.304636622628858, disc_loss = 0.06663111109607002
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 1.9158024787902832, disc_loss = 0.07415245473384857
Trained batch 1 in epoch 4, gen_loss = 1.6965365409851074, disc_loss = 0.04839867167174816
Trained batch 2 in epoch 4, gen_loss = 1.467332363128662, disc_loss = 0.0512097105383873
Trained batch 3 in epoch 4, gen_loss = 1.3989543914794922, disc_loss = 0.049940137192606926
Trained batch 4 in epoch 4, gen_loss = 1.4269465923309326, disc_loss = 0.042761288769543174
Trained batch 5 in epoch 4, gen_loss = 1.4175999363263447, disc_loss = 0.06507402549808224
Trained batch 6 in epoch 4, gen_loss = 1.337631378855024, disc_loss = 0.07130688335746527
Trained batch 7 in epoch 4, gen_loss = 1.31246717274189, disc_loss = 0.06787953909952193
Trained batch 8 in epoch 4, gen_loss = 1.3228661219278972, disc_loss = 0.07124330030961169
Trained batch 9 in epoch 4, gen_loss = 1.2910430431365967, disc_loss = 0.07062027910724282
Trained batch 10 in epoch 4, gen_loss = 1.274226264520125, disc_loss = 0.06803400213406845
Trained batch 11 in epoch 4, gen_loss = 1.2975050906340282, disc_loss = 0.06825993652455509
Trained batch 12 in epoch 4, gen_loss = 1.2816719642052283, disc_loss = 0.06615544748134337
Trained batch 13 in epoch 4, gen_loss = 1.2765644788742065, disc_loss = 0.06517339291583214
Trained batch 14 in epoch 4, gen_loss = 1.2731719493865967, disc_loss = 0.06326969719181458
Trained batch 15 in epoch 4, gen_loss = 1.2868779972195625, disc_loss = 0.062239792256150395
Trained batch 16 in epoch 4, gen_loss = 1.2875559961094576, disc_loss = 0.05947688172626145
Trained batch 17 in epoch 4, gen_loss = 1.28066176838345, disc_loss = 0.05772445573368006
Trained batch 18 in epoch 4, gen_loss = 1.2687489045293707, disc_loss = 0.05765172226452514
Trained batch 19 in epoch 4, gen_loss = 1.2868386447429656, disc_loss = 0.05677161193452775
Trained batch 20 in epoch 4, gen_loss = 1.2837239844458443, disc_loss = 0.05519102021519627
Trained batch 21 in epoch 4, gen_loss = 1.3009405461224643, disc_loss = 0.05356186463243582
Trained batch 22 in epoch 4, gen_loss = 1.289688027423361, disc_loss = 0.05338754314605309
Trained batch 23 in epoch 4, gen_loss = 1.2932750185330708, disc_loss = 0.05375765981928756
Trained batch 24 in epoch 4, gen_loss = 1.300444974899292, disc_loss = 0.052019398398697375
Trained batch 25 in epoch 4, gen_loss = 1.2997894470508282, disc_loss = 0.0507737728050695
Trained batch 26 in epoch 4, gen_loss = 1.2982754839791193, disc_loss = 0.04962343663943035
Trained batch 27 in epoch 4, gen_loss = 1.3042537101677485, disc_loss = 0.05028929903970233
Trained batch 28 in epoch 4, gen_loss = 1.2920682882440502, disc_loss = 0.05101343934777482
Trained batch 29 in epoch 4, gen_loss = 1.2973323464393616, disc_loss = 0.05018339868014057
Trained batch 30 in epoch 4, gen_loss = 1.3023550971861808, disc_loss = 0.04923184946059219
Trained batch 31 in epoch 4, gen_loss = 1.3082465305924416, disc_loss = 0.04922458771034144
Trained batch 32 in epoch 4, gen_loss = 1.2904941873116926, disc_loss = 0.05419229792261666
Trained batch 33 in epoch 4, gen_loss = 1.3086505654980154, disc_loss = 0.056549021070275235
Trained batch 34 in epoch 4, gen_loss = 1.309489333629608, disc_loss = 0.056305327026971747
Trained batch 35 in epoch 4, gen_loss = 1.3013600326246686, disc_loss = 0.05680109071545303
Trained batch 36 in epoch 4, gen_loss = 1.3097846427479305, disc_loss = 0.05703860810781653
Trained batch 37 in epoch 4, gen_loss = 1.2985718265960091, disc_loss = 0.057643685171282606
Trained batch 38 in epoch 4, gen_loss = 1.2937964583054566, disc_loss = 0.05728663769192421
Trained batch 39 in epoch 4, gen_loss = 1.3163132950663567, disc_loss = 0.05942098868545145
Trained batch 40 in epoch 4, gen_loss = 1.308191510235391, disc_loss = 0.05985228969465669
Trained batch 41 in epoch 4, gen_loss = 1.3051660245373136, disc_loss = 0.0590159270158481
Trained batch 42 in epoch 4, gen_loss = 1.3124078331991684, disc_loss = 0.0597130817166248
Trained batch 43 in epoch 4, gen_loss = 1.3101837756958874, disc_loss = 0.05901874760589139
Trained batch 44 in epoch 4, gen_loss = 1.3023475461535983, disc_loss = 0.05932690292182896
Trained batch 45 in epoch 4, gen_loss = 1.3167548101881277, disc_loss = 0.060317804206810564
Trained batch 46 in epoch 4, gen_loss = 1.310508722954608, disc_loss = 0.060547420854105596
Trained batch 47 in epoch 4, gen_loss = 1.3051719665527344, disc_loss = 0.06014874397078529
Trained batch 48 in epoch 4, gen_loss = 1.3046225649969918, disc_loss = 0.06001077947795999
Trained batch 49 in epoch 4, gen_loss = 1.2981425309181214, disc_loss = 0.06063113084062934
Trained batch 50 in epoch 4, gen_loss = 1.299393041461122, disc_loss = 0.06014536903696317
Trained batch 51 in epoch 4, gen_loss = 1.3006661305060754, disc_loss = 0.059983356622979045
Trained batch 52 in epoch 4, gen_loss = 1.2996186130451706, disc_loss = 0.05929794308360455
Trained batch 53 in epoch 4, gen_loss = 1.2928025667314176, disc_loss = 0.05974991348813529
Trained batch 54 in epoch 4, gen_loss = 1.2965334968133406, disc_loss = 0.05900581060824069
Trained batch 55 in epoch 4, gen_loss = 1.3088007771543093, disc_loss = 0.059692468643853705
Trained batch 56 in epoch 4, gen_loss = 1.3057459540534437, disc_loss = 0.05917463051318599
Trained batch 57 in epoch 4, gen_loss = 1.3016168793727612, disc_loss = 0.05891383225740544
Trained batch 58 in epoch 4, gen_loss = 1.300040603694269, disc_loss = 0.058239092308459646
Trained batch 59 in epoch 4, gen_loss = 1.3063871651887893, disc_loss = 0.05878672554778556
Trained batch 60 in epoch 4, gen_loss = 1.3067222902032196, disc_loss = 0.05805232232344932
Trained batch 61 in epoch 4, gen_loss = 1.306891296179064, disc_loss = 0.05738672824396241
Trained batch 62 in epoch 4, gen_loss = 1.3051729173887343, disc_loss = 0.05694854493060755
Trained batch 63 in epoch 4, gen_loss = 1.3118631253018975, disc_loss = 0.056729825417278334
Trained batch 64 in epoch 4, gen_loss = 1.311667186480302, disc_loss = 0.05607107022347359
Trained batch 65 in epoch 4, gen_loss = 1.314342066194072, disc_loss = 0.05556298774017981
Trained batch 66 in epoch 4, gen_loss = 1.3102524965556699, disc_loss = 0.05554778155273021
Trained batch 67 in epoch 4, gen_loss = 1.312017971101929, disc_loss = 0.055125377182026994
Trained batch 68 in epoch 4, gen_loss = 1.3122106712797414, disc_loss = 0.0545319439843297
Trained batch 69 in epoch 4, gen_loss = 1.3119417539664677, disc_loss = 0.05408027120200651
Trained batch 70 in epoch 4, gen_loss = 1.319217326775403, disc_loss = 0.05475670278964328
Trained batch 71 in epoch 4, gen_loss = 1.3137931202848752, disc_loss = 0.05527176698928492
Trained batch 72 in epoch 4, gen_loss = 1.3082491322739485, disc_loss = 0.055549933498546686
Trained batch 73 in epoch 4, gen_loss = 1.316311520499152, disc_loss = 0.05728373154242699
Trained batch 74 in epoch 4, gen_loss = 1.3127185074488321, disc_loss = 0.05739153237392505
Trained batch 75 in epoch 4, gen_loss = 1.309601349265952, disc_loss = 0.05760223321665667
Trained batch 76 in epoch 4, gen_loss = 1.3129480365034822, disc_loss = 0.0585844824574404
Trained batch 77 in epoch 4, gen_loss = 1.310162420456226, disc_loss = 0.05927215059263966
Trained batch 78 in epoch 4, gen_loss = 1.3065045196798784, disc_loss = 0.05992464165945974
Trained batch 79 in epoch 4, gen_loss = 1.3067930489778519, disc_loss = 0.06042806833283976
Trained batch 80 in epoch 4, gen_loss = 1.3050669210928458, disc_loss = 0.06054568613798898
Trained batch 81 in epoch 4, gen_loss = 1.3063923309488994, disc_loss = 0.06055610246456614
Trained batch 82 in epoch 4, gen_loss = 1.3041534064764, disc_loss = 0.06048712584313499
Trained batch 83 in epoch 4, gen_loss = 1.3072504841146015, disc_loss = 0.05996347556910699
Trained batch 84 in epoch 4, gen_loss = 1.308441613702213, disc_loss = 0.05947666199987425
Trained batch 85 in epoch 4, gen_loss = 1.3062449444171995, disc_loss = 0.05929553470855882
Trained batch 86 in epoch 4, gen_loss = 1.3039696189178818, disc_loss = 0.05927261205968158
Trained batch 87 in epoch 4, gen_loss = 1.3021630577065728, disc_loss = 0.058914164917289534
Trained batch 88 in epoch 4, gen_loss = 1.305339148875033, disc_loss = 0.058830889287205895
Trained batch 89 in epoch 4, gen_loss = 1.3036572284168668, disc_loss = 0.05848560357052419
Trained batch 90 in epoch 4, gen_loss = 1.305460511983096, disc_loss = 0.058010855239334996
Trained batch 91 in epoch 4, gen_loss = 1.304994190516679, disc_loss = 0.057622956172765596
Trained batch 92 in epoch 4, gen_loss = 1.3057639483482606, disc_loss = 0.05715172246138575
Trained batch 93 in epoch 4, gen_loss = 1.3093266956349636, disc_loss = 0.056699361830474214
Trained batch 94 in epoch 4, gen_loss = 1.312217678521809, disc_loss = 0.05620217856607939
Trained batch 95 in epoch 4, gen_loss = 1.3128924258053303, disc_loss = 0.05572908439595873
Trained batch 96 in epoch 4, gen_loss = 1.3147747430604757, disc_loss = 0.05523147217007642
Trained batch 97 in epoch 4, gen_loss = 1.3126820958390528, disc_loss = 0.05504780621933086
Trained batch 98 in epoch 4, gen_loss = 1.3170051984112672, disc_loss = 0.05486650653936044
Trained batch 99 in epoch 4, gen_loss = 1.3156618189811706, disc_loss = 0.05463531481102109
Trained batch 100 in epoch 4, gen_loss = 1.3176759209963356, disc_loss = 0.054197981363475915
Trained batch 101 in epoch 4, gen_loss = 1.3195200293671852, disc_loss = 0.05376737643325446
Trained batch 102 in epoch 4, gen_loss = 1.3216966934574461, disc_loss = 0.05332389947714158
Trained batch 103 in epoch 4, gen_loss = 1.3210601313756063, disc_loss = 0.052938687561366424
Trained batch 104 in epoch 4, gen_loss = 1.3233063039325532, disc_loss = 0.052565522403234526
Trained batch 105 in epoch 4, gen_loss = 1.3245912025559623, disc_loss = 0.052404784597456455
Trained batch 106 in epoch 4, gen_loss = 1.3220597293889411, disc_loss = 0.05237064059719304
Trained batch 107 in epoch 4, gen_loss = 1.3212430079778035, disc_loss = 0.05205753904387907
Trained batch 108 in epoch 4, gen_loss = 1.3248243485022029, disc_loss = 0.05214015589257993
Trained batch 109 in epoch 4, gen_loss = 1.323477851260792, disc_loss = 0.05249850624664263
Trained batch 110 in epoch 4, gen_loss = 1.3183902212091394, disc_loss = 0.05332027372341972
Trained batch 111 in epoch 4, gen_loss = 1.3202931944813048, disc_loss = 0.05302557212832783
Trained batch 112 in epoch 4, gen_loss = 1.3208376190303701, disc_loss = 0.05266914117784627
Trained batch 113 in epoch 4, gen_loss = 1.3221218763736255, disc_loss = 0.05238779849911991
Trained batch 114 in epoch 4, gen_loss = 1.327086155310921, disc_loss = 0.052170918315001154
Trained batch 115 in epoch 4, gen_loss = 1.3259081521938587, disc_loss = 0.05197063311613325
Trained batch 116 in epoch 4, gen_loss = 1.3265245113617334, disc_loss = 0.051641552581682675
Trained batch 117 in epoch 4, gen_loss = 1.3254119642710283, disc_loss = 0.051395715380055926
Trained batch 118 in epoch 4, gen_loss = 1.3325576441628593, disc_loss = 0.05149370778602462
Trained batch 119 in epoch 4, gen_loss = 1.3366795917352041, disc_loss = 0.051292086586666605
Trained batch 120 in epoch 4, gen_loss = 1.335703044883476, disc_loss = 0.051185567339897646
Trained batch 121 in epoch 4, gen_loss = 1.336609842347317, disc_loss = 0.05096927898187862
Trained batch 122 in epoch 4, gen_loss = 1.3358866179861673, disc_loss = 0.05073189767971029
Trained batch 123 in epoch 4, gen_loss = 1.3390641645077737, disc_loss = 0.050449977786610686
Trained batch 124 in epoch 4, gen_loss = 1.33894384765625, disc_loss = 0.050162679880857465
Trained batch 125 in epoch 4, gen_loss = 1.3362610510417394, disc_loss = 0.05025363379409389
Trained batch 126 in epoch 4, gen_loss = 1.3381102554441437, disc_loss = 0.050094538375617954
Trained batch 127 in epoch 4, gen_loss = 1.3417522609233856, disc_loss = 0.04992238583508879
Trained batch 128 in epoch 4, gen_loss = 1.3408183598703192, disc_loss = 0.04986220332541207
Trained batch 129 in epoch 4, gen_loss = 1.3403786750940176, disc_loss = 0.049668628292588085
Trained batch 130 in epoch 4, gen_loss = 1.3441006482102489, disc_loss = 0.04967771015549434
Trained batch 131 in epoch 4, gen_loss = 1.3432954116301103, disc_loss = 0.04951965513949593
Trained batch 132 in epoch 4, gen_loss = 1.3420287173493464, disc_loss = 0.04949095658957958
Trained batch 133 in epoch 4, gen_loss = 1.3451044185837704, disc_loss = 0.04966856104168874
Trained batch 134 in epoch 4, gen_loss = 1.345562971079791, disc_loss = 0.04960238540338145
Trained batch 135 in epoch 4, gen_loss = 1.3467026992755777, disc_loss = 0.049590452450930196
Trained batch 136 in epoch 4, gen_loss = 1.350633187885702, disc_loss = 0.04951629375726202
Trained batch 137 in epoch 4, gen_loss = 1.3505293614622476, disc_loss = 0.049284256279360554
Trained batch 138 in epoch 4, gen_loss = 1.3510915341137124, disc_loss = 0.04909130283664885
Trained batch 139 in epoch 4, gen_loss = 1.3501530545098441, disc_loss = 0.04895299167505333
Trained batch 140 in epoch 4, gen_loss = 1.3512216231501695, disc_loss = 0.04869869587850486
Trained batch 141 in epoch 4, gen_loss = 1.3540394356552983, disc_loss = 0.04886898276409213
Trained batch 142 in epoch 4, gen_loss = 1.3524651744148948, disc_loss = 0.04889249748231231
Trained batch 143 in epoch 4, gen_loss = 1.352234894202815, disc_loss = 0.04865294897980574
Trained batch 144 in epoch 4, gen_loss = 1.3559277518042203, disc_loss = 0.04854630587686753
Trained batch 145 in epoch 4, gen_loss = 1.3555843838273662, disc_loss = 0.04836059875837336
Trained batch 146 in epoch 4, gen_loss = 1.3572988356051803, disc_loss = 0.04813955282019514
Trained batch 147 in epoch 4, gen_loss = 1.357492674846907, disc_loss = 0.04788270097452443
Trained batch 148 in epoch 4, gen_loss = 1.3575263111383322, disc_loss = 0.04771819223818563
Trained batch 149 in epoch 4, gen_loss = 1.3573488386472066, disc_loss = 0.04746430362264315
Trained batch 150 in epoch 4, gen_loss = 1.3595280797276277, disc_loss = 0.04723737258094036
Trained batch 151 in epoch 4, gen_loss = 1.3638127046196085, disc_loss = 0.04715807816797966
Trained batch 152 in epoch 4, gen_loss = 1.3660932288450354, disc_loss = 0.04700642421208565
Trained batch 153 in epoch 4, gen_loss = 1.3636699295663215, disc_loss = 0.047217306052032226
Trained batch 154 in epoch 4, gen_loss = 1.3644379631165535, disc_loss = 0.0469998890473958
Trained batch 155 in epoch 4, gen_loss = 1.3670135553066547, disc_loss = 0.04697626500796431
Trained batch 156 in epoch 4, gen_loss = 1.3667765681151371, disc_loss = 0.046832246266922374
Trained batch 157 in epoch 4, gen_loss = 1.3682598765892318, disc_loss = 0.04659819690204119
Trained batch 158 in epoch 4, gen_loss = 1.369383120686753, disc_loss = 0.046359412336968026
Trained batch 159 in epoch 4, gen_loss = 1.3717551127076149, disc_loss = 0.04618830580729991
Trained batch 160 in epoch 4, gen_loss = 1.3727148608391329, disc_loss = 0.04596366482260435
Trained batch 161 in epoch 4, gen_loss = 1.3737067646450467, disc_loss = 0.04572860574648704
Trained batch 162 in epoch 4, gen_loss = 1.3749755716031313, disc_loss = 0.045496026848220024
Trained batch 163 in epoch 4, gen_loss = 1.37538556500179, disc_loss = 0.04526512004241983
Trained batch 164 in epoch 4, gen_loss = 1.3758552731889666, disc_loss = 0.0450338123281571
Trained batch 165 in epoch 4, gen_loss = 1.376292370888124, disc_loss = 0.04481498816566744
Trained batch 166 in epoch 4, gen_loss = 1.3780464654911064, disc_loss = 0.04460576000695903
Trained batch 167 in epoch 4, gen_loss = 1.3785557853324073, disc_loss = 0.04437940258399716
Trained batch 168 in epoch 4, gen_loss = 1.3780371585541222, disc_loss = 0.044219266876754676
Trained batch 169 in epoch 4, gen_loss = 1.379903513543746, disc_loss = 0.044079093098202175
Trained batch 170 in epoch 4, gen_loss = 1.3792717352248074, disc_loss = 0.04396661205424203
Trained batch 171 in epoch 4, gen_loss = 1.379598277945851, disc_loss = 0.04380788724479634
Trained batch 172 in epoch 4, gen_loss = 1.3805468054865138, disc_loss = 0.04364968921364732
Trained batch 173 in epoch 4, gen_loss = 1.3815316914141864, disc_loss = 0.04352389717067795
Trained batch 174 in epoch 4, gen_loss = 1.381879448890686, disc_loss = 0.04343289230551038
Trained batch 175 in epoch 4, gen_loss = 1.3827210468324749, disc_loss = 0.04328602255025709
Trained batch 176 in epoch 4, gen_loss = 1.3834758303259727, disc_loss = 0.04309003830671647
Trained batch 177 in epoch 4, gen_loss = 1.3842651803841752, disc_loss = 0.04291184668774518
Trained batch 178 in epoch 4, gen_loss = 1.3856335658600876, disc_loss = 0.042721497888713246
Trained batch 179 in epoch 4, gen_loss = 1.385355175866021, disc_loss = 0.04255934712063107
Trained batch 180 in epoch 4, gen_loss = 1.3884995023189988, disc_loss = 0.04261145187613878
Trained batch 181 in epoch 4, gen_loss = 1.387099740924416, disc_loss = 0.04252551788218565
Trained batch 182 in epoch 4, gen_loss = 1.386307838184586, disc_loss = 0.04238008437525542
Trained batch 183 in epoch 4, gen_loss = 1.3870107719431752, disc_loss = 0.042294436959428305
Trained batch 184 in epoch 4, gen_loss = 1.3868173695899344, disc_loss = 0.042114254172790695
Trained batch 185 in epoch 4, gen_loss = 1.3885432180537973, disc_loss = 0.04194640746260042
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 1.347300410270691, disc_loss = 0.008534911088645458
Trained batch 1 in epoch 5, gen_loss = 1.2777333855628967, disc_loss = 0.015437334310263395
Trained batch 2 in epoch 5, gen_loss = 1.4063254594802856, disc_loss = 0.02322338738789161
Trained batch 3 in epoch 5, gen_loss = 1.3480541408061981, disc_loss = 0.024208824848756194
Trained batch 4 in epoch 5, gen_loss = 1.412914514541626, disc_loss = 0.021115791983902454
Trained batch 5 in epoch 5, gen_loss = 1.4864264726638794, disc_loss = 0.020951072530200083
Trained batch 6 in epoch 5, gen_loss = 1.4793507712227958, disc_loss = 0.01902495770316039
Trained batch 7 in epoch 5, gen_loss = 1.4638168513774872, disc_loss = 0.017832400219049305
Trained batch 8 in epoch 5, gen_loss = 1.4280010064442952, disc_loss = 0.018525252894808848
Trained batch 9 in epoch 5, gen_loss = 1.4281873464584351, disc_loss = 0.018575623398646712
Trained batch 10 in epoch 5, gen_loss = 1.4235601208426736, disc_loss = 0.017538018820976668
Trained batch 11 in epoch 5, gen_loss = 1.4106331169605255, disc_loss = 0.018410054151900113
Trained batch 12 in epoch 5, gen_loss = 1.4193821136768048, disc_loss = 0.017501220286179047
Trained batch 13 in epoch 5, gen_loss = 1.415510824748448, disc_loss = 0.016770309070125222
Trained batch 14 in epoch 5, gen_loss = 1.4392533779144288, disc_loss = 0.016412528014431396
Trained batch 15 in epoch 5, gen_loss = 1.4475151225924492, disc_loss = 0.015877562429523095
Trained batch 16 in epoch 5, gen_loss = 1.4269098744672888, disc_loss = 0.017348850337678894
Trained batch 17 in epoch 5, gen_loss = 1.4276766512129042, disc_loss = 0.01716482445287208
Trained batch 18 in epoch 5, gen_loss = 1.444872260093689, disc_loss = 0.017168510435639245
Trained batch 19 in epoch 5, gen_loss = 1.4394693076610565, disc_loss = 0.01669580542948097
Trained batch 20 in epoch 5, gen_loss = 1.4258572601136708, disc_loss = 0.018220310742478995
Trained batch 21 in epoch 5, gen_loss = 1.4192821166732095, disc_loss = 0.018031663240187547
Trained batch 22 in epoch 5, gen_loss = 1.4152385618375696, disc_loss = 0.017968270016591185
Trained batch 23 in epoch 5, gen_loss = 1.427877316872279, disc_loss = 0.0189741762005724
Trained batch 24 in epoch 5, gen_loss = 1.4173250484466553, disc_loss = 0.019297492410987615
Trained batch 25 in epoch 5, gen_loss = 1.4233535803281343, disc_loss = 0.018994877132802054
Trained batch 26 in epoch 5, gen_loss = 1.4285155932108562, disc_loss = 0.01888561098732882
Trained batch 27 in epoch 5, gen_loss = 1.4175157334123338, disc_loss = 0.01940445723344705
Trained batch 28 in epoch 5, gen_loss = 1.4133446257689903, disc_loss = 0.019138468830878365
Trained batch 29 in epoch 5, gen_loss = 1.4391520380973817, disc_loss = 0.02034279115808507
Trained batch 30 in epoch 5, gen_loss = 1.4426889534919494, disc_loss = 0.019898184740375125
Trained batch 31 in epoch 5, gen_loss = 1.4277337118983269, disc_loss = 0.020878914176137187
Trained batch 32 in epoch 5, gen_loss = 1.4289763768513997, disc_loss = 0.020774123131890188
Trained batch 33 in epoch 5, gen_loss = 1.4321295373580034, disc_loss = 0.020619488663642722
Trained batch 34 in epoch 5, gen_loss = 1.433499526977539, disc_loss = 0.02029280286016209
Trained batch 35 in epoch 5, gen_loss = 1.420479158560435, disc_loss = 0.021176654496230185
Trained batch 36 in epoch 5, gen_loss = 1.4186921828501933, disc_loss = 0.02110112736605712
Trained batch 37 in epoch 5, gen_loss = 1.4247673812665438, disc_loss = 0.022588383957841678
Trained batch 38 in epoch 5, gen_loss = 1.4078291425338159, disc_loss = 0.025655109112939008
Trained batch 39 in epoch 5, gen_loss = 1.401530386507511, disc_loss = 0.025754825689364224
Trained batch 40 in epoch 5, gen_loss = 1.4159967448653243, disc_loss = 0.02765363283319081
Trained batch 41 in epoch 5, gen_loss = 1.4190856204146431, disc_loss = 0.02737499100510918
Trained batch 42 in epoch 5, gen_loss = 1.4066215906032296, disc_loss = 0.028757969664712977
Trained batch 43 in epoch 5, gen_loss = 1.4019446711648593, disc_loss = 0.029140521952120416
Trained batch 44 in epoch 5, gen_loss = 1.4064689119656881, disc_loss = 0.029480035861747134
Trained batch 45 in epoch 5, gen_loss = 1.3961198938929515, disc_loss = 0.030063648029918903
Trained batch 46 in epoch 5, gen_loss = 1.3922663736850658, disc_loss = 0.029969745503857413
Trained batch 47 in epoch 5, gen_loss = 1.3936780281364918, disc_loss = 0.0295839672035072
Trained batch 48 in epoch 5, gen_loss = 1.388835540839604, disc_loss = 0.03014964981916912
Trained batch 49 in epoch 5, gen_loss = 1.3924853932857513, disc_loss = 0.029821447310969234
Trained batch 50 in epoch 5, gen_loss = 1.3876767637682896, disc_loss = 0.029888937898053258
Trained batch 51 in epoch 5, gen_loss = 1.3862099888233037, disc_loss = 0.030074148967217367
Trained batch 52 in epoch 5, gen_loss = 1.3897767483063463, disc_loss = 0.030442790347942204
Trained batch 53 in epoch 5, gen_loss = 1.3923512553727184, disc_loss = 0.030155232650469297
Trained batch 54 in epoch 5, gen_loss = 1.392579127441753, disc_loss = 0.029815303864465518
Trained batch 55 in epoch 5, gen_loss = 1.3938056475349836, disc_loss = 0.029571736090084805
Trained batch 56 in epoch 5, gen_loss = 1.3971590148775201, disc_loss = 0.029202355325156658
Trained batch 57 in epoch 5, gen_loss = 1.3979361704711257, disc_loss = 0.02885061941623431
Trained batch 58 in epoch 5, gen_loss = 1.4015592528601823, disc_loss = 0.028637237239123908
Trained batch 59 in epoch 5, gen_loss = 1.4117661327123643, disc_loss = 0.028824851809379954
Trained batch 60 in epoch 5, gen_loss = 1.4125013068074086, disc_loss = 0.028695824258334814
Trained batch 61 in epoch 5, gen_loss = 1.4051928952816994, disc_loss = 0.029388930941481265
Trained batch 62 in epoch 5, gen_loss = 1.4022905249444266, disc_loss = 0.029187827260189113
Trained batch 63 in epoch 5, gen_loss = 1.4129722332581878, disc_loss = 0.030195850900781807
Trained batch 64 in epoch 5, gen_loss = 1.4143366254293002, disc_loss = 0.029928398855890218
Trained batch 65 in epoch 5, gen_loss = 1.4070171316464741, disc_loss = 0.03066736914810132
Trained batch 66 in epoch 5, gen_loss = 1.4105913229842684, disc_loss = 0.03046190958998319
Trained batch 67 in epoch 5, gen_loss = 1.4134421436225666, disc_loss = 0.03016179582953234
Trained batch 68 in epoch 5, gen_loss = 1.4129025262335073, disc_loss = 0.029894818464105112
Trained batch 69 in epoch 5, gen_loss = 1.4110502702849252, disc_loss = 0.030304977650355017
Trained batch 70 in epoch 5, gen_loss = 1.4077327805505673, disc_loss = 0.030676339431600252
Trained batch 71 in epoch 5, gen_loss = 1.4042270928621292, disc_loss = 0.030659708511343017
Trained batch 72 in epoch 5, gen_loss = 1.4051016944728485, disc_loss = 0.030383986937622093
Trained batch 73 in epoch 5, gen_loss = 1.4070291035884135, disc_loss = 0.030128252384177334
Trained batch 74 in epoch 5, gen_loss = 1.4096705500284832, disc_loss = 0.02995957416171829
Trained batch 75 in epoch 5, gen_loss = 1.409209590209158, disc_loss = 0.029709169389925114
Trained batch 76 in epoch 5, gen_loss = 1.4033340184719532, disc_loss = 0.03025645331491704
Trained batch 77 in epoch 5, gen_loss = 1.4030001988777747, disc_loss = 0.03000382852788346
Trained batch 78 in epoch 5, gen_loss = 1.4037692863729936, disc_loss = 0.030167409448731173
Trained batch 79 in epoch 5, gen_loss = 1.4037316247820855, disc_loss = 0.029928546800510956
Trained batch 80 in epoch 5, gen_loss = 1.4095230558772145, disc_loss = 0.029925775409526664
Trained batch 81 in epoch 5, gen_loss = 1.405907921674775, disc_loss = 0.029961918168360503
Trained batch 82 in epoch 5, gen_loss = 1.4093081592077232, disc_loss = 0.029738688824631005
Trained batch 83 in epoch 5, gen_loss = 1.4065538701556979, disc_loss = 0.02966753163352786
Trained batch 84 in epoch 5, gen_loss = 1.4044544360216926, disc_loss = 0.029705410280867536
Trained batch 85 in epoch 5, gen_loss = 1.408176648062329, disc_loss = 0.02952933706191563
Trained batch 86 in epoch 5, gen_loss = 1.406327432599561, disc_loss = 0.029519471784132993
Trained batch 87 in epoch 5, gen_loss = 1.4012650684876875, disc_loss = 0.029755212012043394
Trained batch 88 in epoch 5, gen_loss = 1.4021208621142955, disc_loss = 0.029565823824260005
Trained batch 89 in epoch 5, gen_loss = 1.40384169154697, disc_loss = 0.030025082355779078
Trained batch 90 in epoch 5, gen_loss = 1.4017816821297446, disc_loss = 0.029877862744647394
Trained batch 91 in epoch 5, gen_loss = 1.3963286131620407, disc_loss = 0.030477810716863885
Trained batch 92 in epoch 5, gen_loss = 1.3978297768100616, disc_loss = 0.030617658995212085
Trained batch 93 in epoch 5, gen_loss = 1.396878108699271, disc_loss = 0.03054559621662694
Trained batch 94 in epoch 5, gen_loss = 1.3964898266290364, disc_loss = 0.030372573459815037
Trained batch 95 in epoch 5, gen_loss = 1.3943773849556844, disc_loss = 0.03032530018147857
Trained batch 96 in epoch 5, gen_loss = 1.3919066024809768, disc_loss = 0.0302806720569653
Trained batch 97 in epoch 5, gen_loss = 1.393774584239843, disc_loss = 0.03017276081218555
Trained batch 98 in epoch 5, gen_loss = 1.3948848157218008, disc_loss = 0.02998350467062508
Trained batch 99 in epoch 5, gen_loss = 1.3941859287023544, disc_loss = 0.02980313189793378
Trained batch 100 in epoch 5, gen_loss = 1.3941641662380484, disc_loss = 0.029590576688878902
Trained batch 101 in epoch 5, gen_loss = 1.3938001341679518, disc_loss = 0.029480028993395323
Trained batch 102 in epoch 5, gen_loss = 1.3955580071338172, disc_loss = 0.02926273065736716
Trained batch 103 in epoch 5, gen_loss = 1.3963126947100346, disc_loss = 0.029123540005037703
Trained batch 104 in epoch 5, gen_loss = 1.3958384122167315, disc_loss = 0.02900120595115281
Trained batch 105 in epoch 5, gen_loss = 1.3979568970653247, disc_loss = 0.02890225178737826
Trained batch 106 in epoch 5, gen_loss = 1.396681629051672, disc_loss = 0.02880972793116887
Trained batch 107 in epoch 5, gen_loss = 1.3992837452226214, disc_loss = 0.028797100888806635
Trained batch 108 in epoch 5, gen_loss = 1.3977364219656778, disc_loss = 0.029063996717914802
Trained batch 109 in epoch 5, gen_loss = 1.3968925275585868, disc_loss = 0.028925324108620937
Trained batch 110 in epoch 5, gen_loss = 1.393273400293814, disc_loss = 0.029278918710612768
Trained batch 111 in epoch 5, gen_loss = 1.3917470867080348, disc_loss = 0.0292611915875958
Trained batch 112 in epoch 5, gen_loss = 1.398377196451204, disc_loss = 0.029724557195847805
Trained batch 113 in epoch 5, gen_loss = 1.3952839703936326, disc_loss = 0.02985929689174028
Trained batch 114 in epoch 5, gen_loss = 1.3965442071790282, disc_loss = 0.02983228756600748
Trained batch 115 in epoch 5, gen_loss = 1.3971552884784237, disc_loss = 0.029630472213190436
Trained batch 116 in epoch 5, gen_loss = 1.395364642652691, disc_loss = 0.029560916527755495
Trained batch 117 in epoch 5, gen_loss = 1.393601282673367, disc_loss = 0.02952156269970208
Trained batch 118 in epoch 5, gen_loss = 1.3949839903526948, disc_loss = 0.029368632156088825
Trained batch 119 in epoch 5, gen_loss = 1.397288862367471, disc_loss = 0.029403278592508287
Trained batch 120 in epoch 5, gen_loss = 1.3925067378469735, disc_loss = 0.029970098059809158
Trained batch 121 in epoch 5, gen_loss = 1.392731661190752, disc_loss = 0.029837677579709006
Trained batch 122 in epoch 5, gen_loss = 1.3940251052864199, disc_loss = 0.029734205655238734
Trained batch 123 in epoch 5, gen_loss = 1.397515451235156, disc_loss = 0.030095946513146402
Trained batch 124 in epoch 5, gen_loss = 1.3913359031677246, disc_loss = 0.031637076009064916
Trained batch 125 in epoch 5, gen_loss = 1.3919329643249512, disc_loss = 0.03164234969188415
Trained batch 126 in epoch 5, gen_loss = 1.3907696252732764, disc_loss = 0.03244704335531968
Trained batch 127 in epoch 5, gen_loss = 1.3890387024730444, disc_loss = 0.032564250333962264
Trained batch 128 in epoch 5, gen_loss = 1.3875810693400774, disc_loss = 0.03251956275108364
Trained batch 129 in epoch 5, gen_loss = 1.3883108927653387, disc_loss = 0.032441205162411696
Trained batch 130 in epoch 5, gen_loss = 1.389847742692205, disc_loss = 0.03230477171729653
Trained batch 131 in epoch 5, gen_loss = 1.3882671856518947, disc_loss = 0.03234553352971985
Trained batch 132 in epoch 5, gen_loss = 1.389906516648773, disc_loss = 0.03217159606922502
Trained batch 133 in epoch 5, gen_loss = 1.3895464432773306, disc_loss = 0.03209465595115143
Trained batch 134 in epoch 5, gen_loss = 1.3904785889166373, disc_loss = 0.03191406652331352
Trained batch 135 in epoch 5, gen_loss = 1.3917080304201912, disc_loss = 0.03193217882996097
Trained batch 136 in epoch 5, gen_loss = 1.3897905802204662, disc_loss = 0.03201103922876999
Trained batch 137 in epoch 5, gen_loss = 1.3870440963385762, disc_loss = 0.032147766428365226
Trained batch 138 in epoch 5, gen_loss = 1.3878964528763036, disc_loss = 0.03204194182972256
Trained batch 139 in epoch 5, gen_loss = 1.3882844933441707, disc_loss = 0.03192865259147116
Trained batch 140 in epoch 5, gen_loss = 1.3872908742715282, disc_loss = 0.03178165761212297
Trained batch 141 in epoch 5, gen_loss = 1.3854382743298168, disc_loss = 0.03171547251084531
Trained batch 142 in epoch 5, gen_loss = 1.3851858377456665, disc_loss = 0.0315649526167687
Trained batch 143 in epoch 5, gen_loss = 1.3868076470163133, disc_loss = 0.03145372315258202
Trained batch 144 in epoch 5, gen_loss = 1.3884647566696693, disc_loss = 0.03133950282915913
Trained batch 145 in epoch 5, gen_loss = 1.3841893677025625, disc_loss = 0.032024965283448156
Trained batch 146 in epoch 5, gen_loss = 1.3866835309534657, disc_loss = 0.031961132860964254
Trained batch 147 in epoch 5, gen_loss = 1.3876758761502601, disc_loss = 0.031965107310915716
Trained batch 148 in epoch 5, gen_loss = 1.3865069778973624, disc_loss = 0.03189475157441909
Trained batch 149 in epoch 5, gen_loss = 1.385551214615504, disc_loss = 0.03184214064851403
Trained batch 150 in epoch 5, gen_loss = 1.3849540842289956, disc_loss = 0.03173095048929484
Trained batch 151 in epoch 5, gen_loss = 1.388706860965804, disc_loss = 0.03203487643163259
Trained batch 152 in epoch 5, gen_loss = 1.3883744170463164, disc_loss = 0.032031269701429055
Trained batch 153 in epoch 5, gen_loss = 1.3882352458192158, disc_loss = 0.031912839009922436
Trained batch 154 in epoch 5, gen_loss = 1.3888751256850458, disc_loss = 0.03179118327435947
Trained batch 155 in epoch 5, gen_loss = 1.3875502321200492, disc_loss = 0.03173168010126131
Trained batch 156 in epoch 5, gen_loss = 1.3896138626299086, disc_loss = 0.03192352906320315
Trained batch 157 in epoch 5, gen_loss = 1.3871372157259831, disc_loss = 0.032109268286701624
Trained batch 158 in epoch 5, gen_loss = 1.3849328670111842, disc_loss = 0.03220291168036513
Trained batch 159 in epoch 5, gen_loss = 1.3848658736795187, disc_loss = 0.032256628287723285
Trained batch 160 in epoch 5, gen_loss = 1.3854127911307057, disc_loss = 0.03236140384228889
Trained batch 161 in epoch 5, gen_loss = 1.3842008669435242, disc_loss = 0.0322955514902226
Trained batch 162 in epoch 5, gen_loss = 1.3842296084743335, disc_loss = 0.032179747411032765
Trained batch 163 in epoch 5, gen_loss = 1.3832155099002326, disc_loss = 0.032102282176066824
Trained batch 164 in epoch 5, gen_loss = 1.3836678956494186, disc_loss = 0.031949151679873465
Trained batch 165 in epoch 5, gen_loss = 1.3845685537321022, disc_loss = 0.03181218368236918
Trained batch 166 in epoch 5, gen_loss = 1.3853209978806045, disc_loss = 0.031660417725003054
Trained batch 167 in epoch 5, gen_loss = 1.3839978479913302, disc_loss = 0.03160189250151494
Trained batch 168 in epoch 5, gen_loss = 1.3854720920500672, disc_loss = 0.03161001289759338
Trained batch 169 in epoch 5, gen_loss = 1.3851952135562897, disc_loss = 0.03147821685518412
Trained batch 170 in epoch 5, gen_loss = 1.3830873920903568, disc_loss = 0.031510920623284686
Trained batch 171 in epoch 5, gen_loss = 1.386178259586179, disc_loss = 0.03155334877001858
Trained batch 172 in epoch 5, gen_loss = 1.3887762689177012, disc_loss = 0.031537461848229684
Trained batch 173 in epoch 5, gen_loss = 1.38803385968866, disc_loss = 0.03152483430337803
Trained batch 174 in epoch 5, gen_loss = 1.3893597381455558, disc_loss = 0.03141072636736291
Trained batch 175 in epoch 5, gen_loss = 1.3929896120997993, disc_loss = 0.0314962734754028
Trained batch 176 in epoch 5, gen_loss = 1.3934095912733995, disc_loss = 0.03139968057515594
Trained batch 177 in epoch 5, gen_loss = 1.3932721772220698, disc_loss = 0.031316944670057696
Trained batch 178 in epoch 5, gen_loss = 1.3940591329302867, disc_loss = 0.03122528735548258
Trained batch 179 in epoch 5, gen_loss = 1.3930696272187764, disc_loss = 0.031273504196562704
Trained batch 180 in epoch 5, gen_loss = 1.3923759193710201, disc_loss = 0.031249677252991753
Trained batch 181 in epoch 5, gen_loss = 1.395006774218528, disc_loss = 0.03124534794651381
Trained batch 182 in epoch 5, gen_loss = 1.3944668740522665, disc_loss = 0.031136678114451997
Trained batch 183 in epoch 5, gen_loss = 1.3941581524584605, disc_loss = 0.031023048380713746
Trained batch 184 in epoch 5, gen_loss = 1.3944841033703572, disc_loss = 0.03088955383345082
Trained batch 185 in epoch 5, gen_loss = 1.3956766593199905, disc_loss = 0.030880803667930185
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 1.0911283493041992, disc_loss = 0.07085082679986954
Trained batch 1 in epoch 6, gen_loss = 0.9761509299278259, disc_loss = 0.08003060519695282
Trained batch 2 in epoch 6, gen_loss = 1.0293333133061726, disc_loss = 0.06331792287528515
Trained batch 3 in epoch 6, gen_loss = 1.209111899137497, disc_loss = 0.057580923195928335
Trained batch 4 in epoch 6, gen_loss = 1.1928449153900147, disc_loss = 0.052292245998978616
Trained batch 5 in epoch 6, gen_loss = 1.2631759643554688, disc_loss = 0.04771323719372352
Trained batch 6 in epoch 6, gen_loss = 1.2828202928815569, disc_loss = 0.04181585580642734
Trained batch 7 in epoch 6, gen_loss = 1.2615354806184769, disc_loss = 0.04104488960001618
Trained batch 8 in epoch 6, gen_loss = 1.2721525960498385, disc_loss = 0.03751170893924104
Trained batch 9 in epoch 6, gen_loss = 1.3176945567131042, disc_loss = 0.035349419061094525
Trained batch 10 in epoch 6, gen_loss = 1.3484362797303633, disc_loss = 0.033625148998742756
Trained batch 11 in epoch 6, gen_loss = 1.33172145485878, disc_loss = 0.0336967254212747
Trained batch 12 in epoch 6, gen_loss = 1.3214121231665978, disc_loss = 0.033263132764169805
Trained batch 13 in epoch 6, gen_loss = 1.3403977240834917, disc_loss = 0.0329806484681155
Trained batch 14 in epoch 6, gen_loss = 1.324015998840332, disc_loss = 0.03238748790075382
Trained batch 15 in epoch 6, gen_loss = 1.3538635894656181, disc_loss = 0.03145007375860587
Trained batch 16 in epoch 6, gen_loss = 1.3432765918619491, disc_loss = 0.03565989746986067
Trained batch 17 in epoch 6, gen_loss = 1.3097940617137485, disc_loss = 0.04157986952405837
Trained batch 18 in epoch 6, gen_loss = 1.3152852685827958, disc_loss = 0.039758099439112765
Trained batch 19 in epoch 6, gen_loss = 1.3286941826343537, disc_loss = 0.03820166131481528
Trained batch 20 in epoch 6, gen_loss = 1.3526414405731928, disc_loss = 0.04406558323119368
Trained batch 21 in epoch 6, gen_loss = 1.320560406554829, disc_loss = 0.05227640669115565
Trained batch 22 in epoch 6, gen_loss = 1.3191410199455593, disc_loss = 0.06149382298083409
Trained batch 23 in epoch 6, gen_loss = 1.3012082899610202, disc_loss = 0.06315588694997132
Trained batch 24 in epoch 6, gen_loss = 1.3112405133247376, disc_loss = 0.06579050414264202
Trained batch 25 in epoch 6, gen_loss = 1.302869899914815, disc_loss = 0.072808748182769
Trained batch 26 in epoch 6, gen_loss = 1.2944030342278656, disc_loss = 0.07639475711793811
Trained batch 27 in epoch 6, gen_loss = 1.3136755121605737, disc_loss = 0.08092254500037857
Trained batch 28 in epoch 6, gen_loss = 1.295799249205096, disc_loss = 0.08361883763352344
Trained batch 29 in epoch 6, gen_loss = 1.2936839918295542, disc_loss = 0.085796247360607
Trained batch 30 in epoch 6, gen_loss = 1.2941313732054927, disc_loss = 0.08881135951847799
Trained batch 31 in epoch 6, gen_loss = 1.2762433849275112, disc_loss = 0.09543384186690673
Trained batch 32 in epoch 6, gen_loss = 1.2780365546544392, disc_loss = 0.09458901072767648
Trained batch 33 in epoch 6, gen_loss = 1.2788381260984085, disc_loss = 0.09568793759407367
Trained batch 34 in epoch 6, gen_loss = 1.2660306896482194, disc_loss = 0.09568143311355795
Trained batch 35 in epoch 6, gen_loss = 1.2580390009615157, disc_loss = 0.09483011020347476
Trained batch 36 in epoch 6, gen_loss = 1.2611467870506081, disc_loss = 0.09310646299776193
Trained batch 37 in epoch 6, gen_loss = 1.2608715578129417, disc_loss = 0.09214114294828553
Trained batch 38 in epoch 6, gen_loss = 1.2533615063398311, disc_loss = 0.09123735086849102
Trained batch 39 in epoch 6, gen_loss = 1.2533730447292328, disc_loss = 0.09055225509218871
Trained batch 40 in epoch 6, gen_loss = 1.2486564066351913, disc_loss = 0.08956785350129372
Trained batch 41 in epoch 6, gen_loss = 1.2452048858006795, disc_loss = 0.08873036002651566
Trained batch 42 in epoch 6, gen_loss = 1.2472935693208562, disc_loss = 0.0875549666843442
Trained batch 43 in epoch 6, gen_loss = 1.245246261358261, disc_loss = 0.08625888883728873
Trained batch 44 in epoch 6, gen_loss = 1.2402870019276937, disc_loss = 0.0850807071559959
Trained batch 45 in epoch 6, gen_loss = 1.241003243819527, disc_loss = 0.08413300744217375
Trained batch 46 in epoch 6, gen_loss = 1.2380841666079583, disc_loss = 0.0830826648372285
Trained batch 47 in epoch 6, gen_loss = 1.2446860074996948, disc_loss = 0.08202116556155185
Trained batch 48 in epoch 6, gen_loss = 1.2469463007790702, disc_loss = 0.0806864178834521
Trained batch 49 in epoch 6, gen_loss = 1.2451718902587892, disc_loss = 0.07961729075759649
Trained batch 50 in epoch 6, gen_loss = 1.246656008795196, disc_loss = 0.07855124168974512
Trained batch 51 in epoch 6, gen_loss = 1.24706058548047, disc_loss = 0.07762757706670807
Trained batch 52 in epoch 6, gen_loss = 1.244486689567566, disc_loss = 0.07720124317368246
Trained batch 53 in epoch 6, gen_loss = 1.2411016115435847, disc_loss = 0.07654948784383359
Trained batch 54 in epoch 6, gen_loss = 1.2466648903760043, disc_loss = 0.07528093745085326
Trained batch 55 in epoch 6, gen_loss = 1.2530746098075594, disc_loss = 0.07427837922503906
Trained batch 56 in epoch 6, gen_loss = 1.258812937820167, disc_loss = 0.07319712932956846
Trained batch 57 in epoch 6, gen_loss = 1.2603876426302154, disc_loss = 0.07212430038007683
Trained batch 58 in epoch 6, gen_loss = 1.263070037809469, disc_loss = 0.07123283213162321
Trained batch 59 in epoch 6, gen_loss = 1.2654310981432597, disc_loss = 0.07021793850387135
Trained batch 60 in epoch 6, gen_loss = 1.2660949699214248, disc_loss = 0.06929116845741624
Trained batch 61 in epoch 6, gen_loss = 1.2713477246222957, disc_loss = 0.06839174708171238
Trained batch 62 in epoch 6, gen_loss = 1.2759048673841689, disc_loss = 0.06742748794781547
Trained batch 63 in epoch 6, gen_loss = 1.2719574104994535, disc_loss = 0.06695936479809461
Trained batch 64 in epoch 6, gen_loss = 1.2705602682553805, disc_loss = 0.06633797270030929
Trained batch 65 in epoch 6, gen_loss = 1.2728315664060188, disc_loss = 0.06655515859496187
Trained batch 66 in epoch 6, gen_loss = 1.2702432176960048, disc_loss = 0.06625117816781598
Trained batch 67 in epoch 6, gen_loss = 1.2698415622991674, disc_loss = 0.06553143108784057
Trained batch 68 in epoch 6, gen_loss = 1.267417565636013, disc_loss = 0.0651367472930123
Trained batch 69 in epoch 6, gen_loss = 1.2741184847695486, disc_loss = 0.06480927636979945
Trained batch 70 in epoch 6, gen_loss = 1.2778659975025015, disc_loss = 0.06398283790560885
Trained batch 71 in epoch 6, gen_loss = 1.2826198389132817, disc_loss = 0.06330525529079346
Trained batch 72 in epoch 6, gen_loss = 1.2801984728199163, disc_loss = 0.06301821814849973
Trained batch 73 in epoch 6, gen_loss = 1.2849873997069694, disc_loss = 0.06294027404431757
Trained batch 74 in epoch 6, gen_loss = 1.284733953475952, disc_loss = 0.062256867146740356
Trained batch 75 in epoch 6, gen_loss = 1.2839243913951672, disc_loss = 0.061693955513060485
Trained batch 76 in epoch 6, gen_loss = 1.2843831607273646, disc_loss = 0.06107164876438774
Trained batch 77 in epoch 6, gen_loss = 1.2860248761299329, disc_loss = 0.06052520570870584
Trained batch 78 in epoch 6, gen_loss = 1.2911996539634993, disc_loss = 0.05992730925614132
Trained batch 79 in epoch 6, gen_loss = 1.2901512265205384, disc_loss = 0.05940001026610844
Trained batch 80 in epoch 6, gen_loss = 1.2923797913539556, disc_loss = 0.05884302767959458
Trained batch 81 in epoch 6, gen_loss = 1.2945684078263073, disc_loss = 0.058212445657018844
Trained batch 82 in epoch 6, gen_loss = 1.2952799940683755, disc_loss = 0.05769982177158257
Trained batch 83 in epoch 6, gen_loss = 1.2927177605174838, disc_loss = 0.057438992335283684
Trained batch 84 in epoch 6, gen_loss = 1.296886176221511, disc_loss = 0.05704644365674433
Trained batch 85 in epoch 6, gen_loss = 1.2968146094056063, disc_loss = 0.057003055368875004
Trained batch 86 in epoch 6, gen_loss = 1.2934497896282153, disc_loss = 0.057110619008669566
Trained batch 87 in epoch 6, gen_loss = 1.2938269742510535, disc_loss = 0.05662336697357453
Trained batch 88 in epoch 6, gen_loss = 1.3013722655478488, disc_loss = 0.05687109127201224
Trained batch 89 in epoch 6, gen_loss = 1.3001810126834445, disc_loss = 0.05679456307552755
Trained batch 90 in epoch 6, gen_loss = 1.2991787457204127, disc_loss = 0.05635895597963379
Trained batch 91 in epoch 6, gen_loss = 1.301247160071912, disc_loss = 0.055977843939731625
Trained batch 92 in epoch 6, gen_loss = 1.3017443623594058, disc_loss = 0.05594402362882931
Trained batch 93 in epoch 6, gen_loss = 1.2961509088252454, disc_loss = 0.05666622380290101
Trained batch 94 in epoch 6, gen_loss = 1.2962267235705727, disc_loss = 0.05620789066643307
Trained batch 95 in epoch 6, gen_loss = 1.2950947942833106, disc_loss = 0.05600360037351493
Trained batch 96 in epoch 6, gen_loss = 1.2987824703000255, disc_loss = 0.056141029404879535
Trained batch 97 in epoch 6, gen_loss = 1.3006176084888226, disc_loss = 0.055665331412752976
Trained batch 98 in epoch 6, gen_loss = 1.2963338921768497, disc_loss = 0.055841688739342824
Trained batch 99 in epoch 6, gen_loss = 1.2965558183193207, disc_loss = 0.055410128547810016
Trained batch 100 in epoch 6, gen_loss = 1.301331334775037, disc_loss = 0.055730651524655596
Trained batch 101 in epoch 6, gen_loss = 1.2999267017140108, disc_loss = 0.05549978586735532
Trained batch 102 in epoch 6, gen_loss = 1.2962725799060562, disc_loss = 0.05577182282865482
Trained batch 103 in epoch 6, gen_loss = 1.2984607024834707, disc_loss = 0.05560851997534673
Trained batch 104 in epoch 6, gen_loss = 1.3013902448472523, disc_loss = 0.05550077519867392
Trained batch 105 in epoch 6, gen_loss = 1.3000790589260605, disc_loss = 0.055210567777976394
Trained batch 106 in epoch 6, gen_loss = 1.2970339093252876, disc_loss = 0.05527457718032403
Trained batch 107 in epoch 6, gen_loss = 1.3033428335631336, disc_loss = 0.055240228543644423
Trained batch 108 in epoch 6, gen_loss = 1.303292894582136, disc_loss = 0.054887194848627946
Trained batch 109 in epoch 6, gen_loss = 1.3066066536036405, disc_loss = 0.054501303094862535
Trained batch 110 in epoch 6, gen_loss = 1.3048093028970666, disc_loss = 0.05426572136966898
Trained batch 111 in epoch 6, gen_loss = 1.3085151836276054, disc_loss = 0.053913485080037
Trained batch 112 in epoch 6, gen_loss = 1.3077990354689877, disc_loss = 0.05357743659988046
Trained batch 113 in epoch 6, gen_loss = 1.309150689526608, disc_loss = 0.05341319656898186
Trained batch 114 in epoch 6, gen_loss = 1.30845787939818, disc_loss = 0.05322142430054753
Trained batch 115 in epoch 6, gen_loss = 1.3096927250253743, disc_loss = 0.05296304143146323
Trained batch 116 in epoch 6, gen_loss = 1.3098380046013074, disc_loss = 0.05269226507068826
Trained batch 117 in epoch 6, gen_loss = 1.3114073529081829, disc_loss = 0.05255389057683869
Trained batch 118 in epoch 6, gen_loss = 1.3094572009158736, disc_loss = 0.052418908984752516
Trained batch 119 in epoch 6, gen_loss = 1.3085259636243185, disc_loss = 0.05216822846559808
Trained batch 120 in epoch 6, gen_loss = 1.312053270576414, disc_loss = 0.051840011573065656
Trained batch 121 in epoch 6, gen_loss = 1.3096773751446458, disc_loss = 0.05178782504555754
Trained batch 122 in epoch 6, gen_loss = 1.3131970138084599, disc_loss = 0.051797982415078374
Trained batch 123 in epoch 6, gen_loss = 1.3134560527340058, disc_loss = 0.05146866235806937
Trained batch 124 in epoch 6, gen_loss = 1.315377613067627, disc_loss = 0.051154172163456677
Trained batch 125 in epoch 6, gen_loss = 1.3119935487943983, disc_loss = 0.05145491787882906
Trained batch 126 in epoch 6, gen_loss = 1.3127673028960942, disc_loss = 0.05113428797000858
Trained batch 127 in epoch 6, gen_loss = 1.3162660468369722, disc_loss = 0.051107748888171045
Trained batch 128 in epoch 6, gen_loss = 1.3170438644497893, disc_loss = 0.05084536147715394
Trained batch 129 in epoch 6, gen_loss = 1.3146257950709417, disc_loss = 0.05086937702547472
Trained batch 130 in epoch 6, gen_loss = 1.313310417510171, disc_loss = 0.05079490419491443
Trained batch 131 in epoch 6, gen_loss = 1.3164368335044745, disc_loss = 0.05052736677779732
Trained batch 132 in epoch 6, gen_loss = 1.318382653974949, disc_loss = 0.050197898315727935
Trained batch 133 in epoch 6, gen_loss = 1.3179900023474622, disc_loss = 0.04989540703080372
Trained batch 134 in epoch 6, gen_loss = 1.3193178371146874, disc_loss = 0.04957427127217805
Trained batch 135 in epoch 6, gen_loss = 1.3184602313181932, disc_loss = 0.04934108436710256
Trained batch 136 in epoch 6, gen_loss = 1.318350450835959, disc_loss = 0.0490593178075378
Trained batch 137 in epoch 6, gen_loss = 1.3179793331934058, disc_loss = 0.04878801564969446
Trained batch 138 in epoch 6, gen_loss = 1.3202050118137607, disc_loss = 0.04873310888467504
Trained batch 139 in epoch 6, gen_loss = 1.3197627110140664, disc_loss = 0.04847929876829896
Trained batch 140 in epoch 6, gen_loss = 1.3185393869454134, disc_loss = 0.04830927922264904
Trained batch 141 in epoch 6, gen_loss = 1.3223075749168933, disc_loss = 0.048119335264807016
Trained batch 142 in epoch 6, gen_loss = 1.3239929217558641, disc_loss = 0.04784038992455372
Trained batch 143 in epoch 6, gen_loss = 1.323639185892211, disc_loss = 0.04760466788947168
Trained batch 144 in epoch 6, gen_loss = 1.3228770971298218, disc_loss = 0.047381441282301116
Trained batch 145 in epoch 6, gen_loss = 1.3230305428374303, disc_loss = 0.04713916358831402
Trained batch 146 in epoch 6, gen_loss = 1.3266228859116431, disc_loss = 0.0469540083388082
Trained batch 147 in epoch 6, gen_loss = 1.3260972854253408, disc_loss = 0.0467224474241202
Trained batch 148 in epoch 6, gen_loss = 1.3270768223192868, disc_loss = 0.046472672960602195
Trained batch 149 in epoch 6, gen_loss = 1.3282341686884562, disc_loss = 0.04620213752612472
Trained batch 150 in epoch 6, gen_loss = 1.3296862027503007, disc_loss = 0.045956441879716536
Trained batch 151 in epoch 6, gen_loss = 1.3271029313143932, disc_loss = 0.046013204264454544
Trained batch 152 in epoch 6, gen_loss = 1.329027594694125, disc_loss = 0.04589635805147731
Trained batch 153 in epoch 6, gen_loss = 1.3288904889063402, disc_loss = 0.045649805886356476
Trained batch 154 in epoch 6, gen_loss = 1.3309747199858388, disc_loss = 0.045429645923356854
Trained batch 155 in epoch 6, gen_loss = 1.3318579697456114, disc_loss = 0.04521742568184168
Trained batch 156 in epoch 6, gen_loss = 1.3307368797101793, disc_loss = 0.045067557863369107
Trained batch 157 in epoch 6, gen_loss = 1.3311498402794706, disc_loss = 0.04482065815525719
Trained batch 158 in epoch 6, gen_loss = 1.3303282317125573, disc_loss = 0.04486828480126723
Trained batch 159 in epoch 6, gen_loss = 1.3321334343403577, disc_loss = 0.04482041466981172
Trained batch 160 in epoch 6, gen_loss = 1.3308869826127283, disc_loss = 0.044679768371933735
Trained batch 161 in epoch 6, gen_loss = 1.3292041071403173, disc_loss = 0.044667776593547544
Trained batch 162 in epoch 6, gen_loss = 1.3287625521238595, disc_loss = 0.04447772431021636
Trained batch 163 in epoch 6, gen_loss = 1.330520484869073, disc_loss = 0.04501028640036721
Trained batch 164 in epoch 6, gen_loss = 1.3299192172108274, disc_loss = 0.044875577402611576
Trained batch 165 in epoch 6, gen_loss = 1.3295230926519417, disc_loss = 0.0447661649738719
Trained batch 166 in epoch 6, gen_loss = 1.3286207511039552, disc_loss = 0.04463929181617356
Trained batch 167 in epoch 6, gen_loss = 1.3279110537398429, disc_loss = 0.044468861511198894
Trained batch 168 in epoch 6, gen_loss = 1.3320240046851028, disc_loss = 0.04455163245524704
Trained batch 169 in epoch 6, gen_loss = 1.3316765557317172, disc_loss = 0.04436966529225602
Trained batch 170 in epoch 6, gen_loss = 1.3298418664792826, disc_loss = 0.04439833516265914
Trained batch 171 in epoch 6, gen_loss = 1.3330254100782926, disc_loss = 0.044377486156516294
Trained batch 172 in epoch 6, gen_loss = 1.332557608971017, disc_loss = 0.04424649662192846
Trained batch 173 in epoch 6, gen_loss = 1.3321391792818047, disc_loss = 0.04419287174254998
Trained batch 174 in epoch 6, gen_loss = 1.3323464723995753, disc_loss = 0.0440383867174387
Trained batch 175 in epoch 6, gen_loss = 1.3310604451054877, disc_loss = 0.043951359926722944
Trained batch 176 in epoch 6, gen_loss = 1.3295879434731046, disc_loss = 0.04396463535978633
Trained batch 177 in epoch 6, gen_loss = 1.3327874477659718, disc_loss = 0.043999391482368616
Trained batch 178 in epoch 6, gen_loss = 1.333210249519881, disc_loss = 0.04385596040282502
Trained batch 179 in epoch 6, gen_loss = 1.334121819668346, disc_loss = 0.04365338968475246
Trained batch 180 in epoch 6, gen_loss = 1.3319520624303027, disc_loss = 0.04378842183476242
Trained batch 181 in epoch 6, gen_loss = 1.3323673085196988, disc_loss = 0.04369276364661426
Trained batch 182 in epoch 6, gen_loss = 1.3322731963272303, disc_loss = 0.04365792326741124
Trained batch 183 in epoch 6, gen_loss = 1.3315344456097353, disc_loss = 0.043586275740222925
Trained batch 184 in epoch 6, gen_loss = 1.330061669285233, disc_loss = 0.043536463175975794
Trained batch 185 in epoch 6, gen_loss = 1.333600252866745, disc_loss = 0.04393136481033458
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 0.9056196212768555, disc_loss = 0.06968801468610764
Trained batch 1 in epoch 7, gen_loss = 1.0066596269607544, disc_loss = 0.048339564353227615
Trained batch 2 in epoch 7, gen_loss = 1.2790838877360027, disc_loss = 0.06585365782181422
Trained batch 3 in epoch 7, gen_loss = 1.259139895439148, disc_loss = 0.054927289485931396
Trained batch 4 in epoch 7, gen_loss = 1.2128793239593505, disc_loss = 0.05205271542072296
Trained batch 5 in epoch 7, gen_loss = 1.2052915692329407, disc_loss = 0.04880552055935065
Trained batch 6 in epoch 7, gen_loss = 1.2856436286653792, disc_loss = 0.05443216807075909
Trained batch 7 in epoch 7, gen_loss = 1.254082903265953, disc_loss = 0.05467693554237485
Trained batch 8 in epoch 7, gen_loss = 1.2733343442281086, disc_loss = 0.05457933578226301
Trained batch 9 in epoch 7, gen_loss = 1.2388638019561768, disc_loss = 0.05661706551909447
Trained batch 10 in epoch 7, gen_loss = 1.2305038950660012, disc_loss = 0.0570564903318882
Trained batch 11 in epoch 7, gen_loss = 1.263097236553828, disc_loss = 0.056559465204675995
Trained batch 12 in epoch 7, gen_loss = 1.283887973198524, disc_loss = 0.053451491663089164
Trained batch 13 in epoch 7, gen_loss = 1.2775814958981104, disc_loss = 0.051721545069345405
Trained batch 14 in epoch 7, gen_loss = 1.2731495062510172, disc_loss = 0.049441289405028024
Trained batch 15 in epoch 7, gen_loss = 1.2968885749578476, disc_loss = 0.04754768265411258
Trained batch 16 in epoch 7, gen_loss = 1.308822751045227, disc_loss = 0.04611028906177072
Trained batch 17 in epoch 7, gen_loss = 1.29633367061615, disc_loss = 0.04556554100579686
Trained batch 18 in epoch 7, gen_loss = 1.2883007526397705, disc_loss = 0.044171285276350225
Trained batch 19 in epoch 7, gen_loss = 1.2852570295333863, disc_loss = 0.04500256348401308
Trained batch 20 in epoch 7, gen_loss = 1.3251347655341739, disc_loss = 0.047788928484632856
Trained batch 21 in epoch 7, gen_loss = 1.3186147538098423, disc_loss = 0.04680180795152079
Trained batch 22 in epoch 7, gen_loss = 1.3106764295826787, disc_loss = 0.04617025824668615
Trained batch 23 in epoch 7, gen_loss = 1.315984030564626, disc_loss = 0.04457180469762534
Trained batch 24 in epoch 7, gen_loss = 1.332187900543213, disc_loss = 0.043917282857000826
Trained batch 25 in epoch 7, gen_loss = 1.3370374486996577, disc_loss = 0.04250403289468242
Trained batch 26 in epoch 7, gen_loss = 1.3385117804562603, disc_loss = 0.04122778811250572
Trained batch 27 in epoch 7, gen_loss = 1.333116501569748, disc_loss = 0.04048210512181478
Trained batch 28 in epoch 7, gen_loss = 1.3392731074629158, disc_loss = 0.03923656942387079
Trained batch 29 in epoch 7, gen_loss = 1.3609153985977174, disc_loss = 0.03918211419756214
Trained batch 30 in epoch 7, gen_loss = 1.3522689034861903, disc_loss = 0.039087578744417234
Trained batch 31 in epoch 7, gen_loss = 1.3627922758460045, disc_loss = 0.038167889608303085
Trained batch 32 in epoch 7, gen_loss = 1.3659443205053157, disc_loss = 0.037739066491750156
Trained batch 33 in epoch 7, gen_loss = 1.3610119469025557, disc_loss = 0.037197598612264675
Trained batch 34 in epoch 7, gen_loss = 1.354035016468593, disc_loss = 0.03684770174856697
Trained batch 35 in epoch 7, gen_loss = 1.3599094284905329, disc_loss = 0.036903337135704026
Trained batch 36 in epoch 7, gen_loss = 1.3594055884593241, disc_loss = 0.03743774753466651
Trained batch 37 in epoch 7, gen_loss = 1.3474648563485396, disc_loss = 0.038136255657790524
Trained batch 38 in epoch 7, gen_loss = 1.349501377496964, disc_loss = 0.037309966838130586
Trained batch 39 in epoch 7, gen_loss = 1.3588688403367997, disc_loss = 0.036872034007683394
Trained batch 40 in epoch 7, gen_loss = 1.3499123483169368, disc_loss = 0.03707909352350526
Trained batch 41 in epoch 7, gen_loss = 1.358347868635541, disc_loss = 0.0372487764716858
Trained batch 42 in epoch 7, gen_loss = 1.3582464470419773, disc_loss = 0.03656865023942881
Trained batch 43 in epoch 7, gen_loss = 1.3517477065324783, disc_loss = 0.036509045653722504
Trained batch 44 in epoch 7, gen_loss = 1.3486806909243265, disc_loss = 0.036324195605185294
Trained batch 45 in epoch 7, gen_loss = 1.3455205935498942, disc_loss = 0.03619755768095669
Trained batch 46 in epoch 7, gen_loss = 1.3424358380601762, disc_loss = 0.03599457529948113
Trained batch 47 in epoch 7, gen_loss = 1.3489828395346801, disc_loss = 0.03546970069874078
Trained batch 48 in epoch 7, gen_loss = 1.352024529661451, disc_loss = 0.0349755430670113
Trained batch 49 in epoch 7, gen_loss = 1.3493812382221222, disc_loss = 0.03464001415297389
Trained batch 50 in epoch 7, gen_loss = 1.3468585306522893, disc_loss = 0.03426940196796375
Trained batch 51 in epoch 7, gen_loss = 1.3527978028242404, disc_loss = 0.033922733076346606
Trained batch 52 in epoch 7, gen_loss = 1.3497606594607514, disc_loss = 0.03391971099981159
Trained batch 53 in epoch 7, gen_loss = 1.3492985268433888, disc_loss = 0.03395027368915854
Trained batch 54 in epoch 7, gen_loss = 1.352813266624104, disc_loss = 0.03500041844831272
Trained batch 55 in epoch 7, gen_loss = 1.3460089042782784, disc_loss = 0.03558491734189114
Trained batch 56 in epoch 7, gen_loss = 1.3456338968193322, disc_loss = 0.03524890435826883
Trained batch 57 in epoch 7, gen_loss = 1.3474593028940003, disc_loss = 0.0359451398092868
Trained batch 58 in epoch 7, gen_loss = 1.3435352141574277, disc_loss = 0.03585767065632647
Trained batch 59 in epoch 7, gen_loss = 1.343153656522433, disc_loss = 0.035461674661686024
Trained batch 60 in epoch 7, gen_loss = 1.3451819859567236, disc_loss = 0.03510376966756876
Trained batch 61 in epoch 7, gen_loss = 1.3462805969099845, disc_loss = 0.0346209188893197
Trained batch 62 in epoch 7, gen_loss = 1.342941805483803, disc_loss = 0.03503502185441672
Trained batch 63 in epoch 7, gen_loss = 1.3462091190740466, disc_loss = 0.03465577262977604
Trained batch 64 in epoch 7, gen_loss = 1.3536945443886976, disc_loss = 0.034733166273396746
Trained batch 65 in epoch 7, gen_loss = 1.3508347769578297, disc_loss = 0.03480854406106201
Trained batch 66 in epoch 7, gen_loss = 1.3462584365659684, disc_loss = 0.03523976301579778
Trained batch 67 in epoch 7, gen_loss = 1.3471868765704773, disc_loss = 0.03545132204068496
Trained batch 68 in epoch 7, gen_loss = 1.3500490352727366, disc_loss = 0.03508399897997362
Trained batch 69 in epoch 7, gen_loss = 1.3466240278312138, disc_loss = 0.035164772626012565
Trained batch 70 in epoch 7, gen_loss = 1.3479076246140709, disc_loss = 0.03573302506193728
Trained batch 71 in epoch 7, gen_loss = 1.3408658032615979, disc_loss = 0.036356381464025214
Trained batch 72 in epoch 7, gen_loss = 1.3439455775365436, disc_loss = 0.036206250614805584
Trained batch 73 in epoch 7, gen_loss = 1.3445465202267106, disc_loss = 0.03599295466886582
Trained batch 74 in epoch 7, gen_loss = 1.3424439899126688, disc_loss = 0.03575652439147234
Trained batch 75 in epoch 7, gen_loss = 1.343701154777878, disc_loss = 0.035434306047758775
Trained batch 76 in epoch 7, gen_loss = 1.3442570412313783, disc_loss = 0.035095764674826876
Trained batch 77 in epoch 7, gen_loss = 1.3423892328372369, disc_loss = 0.03486296089175038
Trained batch 78 in epoch 7, gen_loss = 1.3438719594025914, disc_loss = 0.03460062820983084
Trained batch 79 in epoch 7, gen_loss = 1.3459054209291934, disc_loss = 0.03431142823537812
Trained batch 80 in epoch 7, gen_loss = 1.3411369139765517, disc_loss = 0.03470365789339498
Trained batch 81 in epoch 7, gen_loss = 1.3509090113930586, disc_loss = 0.03537044741167891
Trained batch 82 in epoch 7, gen_loss = 1.3541185604520591, disc_loss = 0.035077181083700025
Trained batch 83 in epoch 7, gen_loss = 1.3481276099170958, disc_loss = 0.03599763551859984
Trained batch 84 in epoch 7, gen_loss = 1.3477840879384209, disc_loss = 0.03576056923278991
Trained batch 85 in epoch 7, gen_loss = 1.35000095325847, disc_loss = 0.035711142137040235
Trained batch 86 in epoch 7, gen_loss = 1.3540185669372822, disc_loss = 0.03562246109947734
Trained batch 87 in epoch 7, gen_loss = 1.3502352583137425, disc_loss = 0.0357313236666166
Trained batch 88 in epoch 7, gen_loss = 1.3466954586211215, disc_loss = 0.035889567838709675
Trained batch 89 in epoch 7, gen_loss = 1.353292892376582, disc_loss = 0.036907718465146094
Trained batch 90 in epoch 7, gen_loss = 1.3504586488335997, disc_loss = 0.036997780132179074
Trained batch 91 in epoch 7, gen_loss = 1.351106122136116, disc_loss = 0.036969744246048125
Trained batch 92 in epoch 7, gen_loss = 1.3494516220144046, disc_loss = 0.03686227566332266
Trained batch 93 in epoch 7, gen_loss = 1.3472915944900918, disc_loss = 0.03685827257032407
Trained batch 94 in epoch 7, gen_loss = 1.346978629890241, disc_loss = 0.03680061475422822
Trained batch 95 in epoch 7, gen_loss = 1.349004906291763, disc_loss = 0.036501900729490444
Trained batch 96 in epoch 7, gen_loss = 1.3491143301590203, disc_loss = 0.03622411844349399
Trained batch 97 in epoch 7, gen_loss = 1.348699229712389, disc_loss = 0.035952409444262784
Trained batch 98 in epoch 7, gen_loss = 1.3506773017873668, disc_loss = 0.035798933112410586
Trained batch 99 in epoch 7, gen_loss = 1.349822317957878, disc_loss = 0.035670127607882025
Trained batch 100 in epoch 7, gen_loss = 1.3549141877948647, disc_loss = 0.03563596105369011
Trained batch 101 in epoch 7, gen_loss = 1.3532905105282278, disc_loss = 0.035540635204490495
Trained batch 102 in epoch 7, gen_loss = 1.353811422019329, disc_loss = 0.035318241002562555
Trained batch 103 in epoch 7, gen_loss = 1.352893742804344, disc_loss = 0.03518279257696122
Trained batch 104 in epoch 7, gen_loss = 1.3483837297984531, disc_loss = 0.03563929068013316
Trained batch 105 in epoch 7, gen_loss = 1.34990168405029, disc_loss = 0.03579360052486354
Trained batch 106 in epoch 7, gen_loss = 1.3512591769762128, disc_loss = 0.03588127312642113
Trained batch 107 in epoch 7, gen_loss = 1.3506277192521978, disc_loss = 0.035722170775342316
Trained batch 108 in epoch 7, gen_loss = 1.349388130214236, disc_loss = 0.035550605428806684
Trained batch 109 in epoch 7, gen_loss = 1.3476100238886746, disc_loss = 0.03545093481344255
Trained batch 110 in epoch 7, gen_loss = 1.3494386050078246, disc_loss = 0.03526949744067482
Trained batch 111 in epoch 7, gen_loss = 1.3491204647081239, disc_loss = 0.035758599597362
Trained batch 112 in epoch 7, gen_loss = 1.3458751661587605, disc_loss = 0.036023375627675415
Trained batch 113 in epoch 7, gen_loss = 1.3471736343283403, disc_loss = 0.03615788791099923
Trained batch 114 in epoch 7, gen_loss = 1.3497191760850988, disc_loss = 0.03595945065760094
Trained batch 115 in epoch 7, gen_loss = 1.3487331312278221, disc_loss = 0.035772867669383514
Trained batch 116 in epoch 7, gen_loss = 1.3478992708727844, disc_loss = 0.03558390753932743
Trained batch 117 in epoch 7, gen_loss = 1.3482864812269049, disc_loss = 0.03533611839668731
Trained batch 118 in epoch 7, gen_loss = 1.3508299599174691, disc_loss = 0.03511296759727372
Trained batch 119 in epoch 7, gen_loss = 1.3501531640688578, disc_loss = 0.03513281341486921
Trained batch 120 in epoch 7, gen_loss = 1.3525684648308873, disc_loss = 0.03496454482944297
Trained batch 121 in epoch 7, gen_loss = 1.3528736487763826, disc_loss = 0.03478079182324839
Trained batch 122 in epoch 7, gen_loss = 1.3530415102718323, disc_loss = 0.03460535198086646
Trained batch 123 in epoch 7, gen_loss = 1.3531180956671316, disc_loss = 0.034430571260952184
Trained batch 124 in epoch 7, gen_loss = 1.3550751628875732, disc_loss = 0.03429473036527634
Trained batch 125 in epoch 7, gen_loss = 1.3570897881946866, disc_loss = 0.034181872264496864
Trained batch 126 in epoch 7, gen_loss = 1.3564010698964277, disc_loss = 0.034250198474784534
Trained batch 127 in epoch 7, gen_loss = 1.3626264054328203, disc_loss = 0.03499923934577964
Trained batch 128 in epoch 7, gen_loss = 1.3613505677659383, disc_loss = 0.03517592429768208
Trained batch 129 in epoch 7, gen_loss = 1.3597459371273335, disc_loss = 0.0352293160958932
Trained batch 130 in epoch 7, gen_loss = 1.3616491965665163, disc_loss = 0.03569902636053908
Trained batch 131 in epoch 7, gen_loss = 1.3618736492865013, disc_loss = 0.03562248086161686
Trained batch 132 in epoch 7, gen_loss = 1.364078328125459, disc_loss = 0.0355577349830839
Trained batch 133 in epoch 7, gen_loss = 1.3633329654807476, disc_loss = 0.03548440043883982
Trained batch 134 in epoch 7, gen_loss = 1.3648174930501866, disc_loss = 0.035320257657655965
Trained batch 135 in epoch 7, gen_loss = 1.3623549859313404, disc_loss = 0.03547691963339115
Trained batch 136 in epoch 7, gen_loss = 1.3646772647426075, disc_loss = 0.035455416575291734
Trained batch 137 in epoch 7, gen_loss = 1.3668389700461125, disc_loss = 0.03538928078352541
Trained batch 138 in epoch 7, gen_loss = 1.3675828142989455, disc_loss = 0.035199718945157187
Trained batch 139 in epoch 7, gen_loss = 1.3661080607346126, disc_loss = 0.0351476537263287
Trained batch 140 in epoch 7, gen_loss = 1.3650916544258171, disc_loss = 0.03501689336956181
Trained batch 141 in epoch 7, gen_loss = 1.3653514175347878, disc_loss = 0.03481935157152024
Trained batch 142 in epoch 7, gen_loss = 1.3715072903599772, disc_loss = 0.03502548489576349
Trained batch 143 in epoch 7, gen_loss = 1.3756515102254019, disc_loss = 0.03502243026095028
Trained batch 144 in epoch 7, gen_loss = 1.3723482551245854, disc_loss = 0.035430199765311234
Trained batch 145 in epoch 7, gen_loss = 1.3716595393337616, disc_loss = 0.03528564847202027
Trained batch 146 in epoch 7, gen_loss = 1.3725817698199734, disc_loss = 0.03520392459582816
Trained batch 147 in epoch 7, gen_loss = 1.3753622117880229, disc_loss = 0.03508463439317672
Trained batch 148 in epoch 7, gen_loss = 1.3771383498339045, disc_loss = 0.034936446762149964
Trained batch 149 in epoch 7, gen_loss = 1.3744394266605378, disc_loss = 0.03509171020550032
Trained batch 150 in epoch 7, gen_loss = 1.3764813779205676, disc_loss = 0.03494192868631506
Trained batch 151 in epoch 7, gen_loss = 1.3777866030209942, disc_loss = 0.03479973970311939
Trained batch 152 in epoch 7, gen_loss = 1.3817522031029845, disc_loss = 0.03480088663001368
Trained batch 153 in epoch 7, gen_loss = 1.3830390468046263, disc_loss = 0.03464473246645134
Trained batch 154 in epoch 7, gen_loss = 1.3822267274702749, disc_loss = 0.03455257171524628
Trained batch 155 in epoch 7, gen_loss = 1.380201709958223, disc_loss = 0.0345460742037409
Trained batch 156 in epoch 7, gen_loss = 1.3796092602098065, disc_loss = 0.034430481526099004
Trained batch 157 in epoch 7, gen_loss = 1.3824115301234812, disc_loss = 0.03451659194123047
Trained batch 158 in epoch 7, gen_loss = 1.3820601615515895, disc_loss = 0.03443511074947767
Trained batch 159 in epoch 7, gen_loss = 1.382205433025956, disc_loss = 0.034251744949142446
Trained batch 160 in epoch 7, gen_loss = 1.3829811896596635, disc_loss = 0.03407228585934232
Trained batch 161 in epoch 7, gen_loss = 1.3814158980493192, disc_loss = 0.033979326216389
Trained batch 162 in epoch 7, gen_loss = 1.379893936628213, disc_loss = 0.03387415210824985
Trained batch 163 in epoch 7, gen_loss = 1.3817932638453274, disc_loss = 0.03397193660664304
Trained batch 164 in epoch 7, gen_loss = 1.3803827094309258, disc_loss = 0.033887382737840664
Trained batch 165 in epoch 7, gen_loss = 1.3780112751277096, disc_loss = 0.03394124298412577
Trained batch 166 in epoch 7, gen_loss = 1.3790148821419586, disc_loss = 0.03433046749274352
Trained batch 167 in epoch 7, gen_loss = 1.3751493390826952, disc_loss = 0.03496019316593274
Trained batch 168 in epoch 7, gen_loss = 1.3753713655048574, disc_loss = 0.03493775280203516
Trained batch 169 in epoch 7, gen_loss = 1.374114047429141, disc_loss = 0.0348819072906147
Trained batch 170 in epoch 7, gen_loss = 1.3738772963222705, disc_loss = 0.03472635786087192
Trained batch 171 in epoch 7, gen_loss = 1.3726398428512174, disc_loss = 0.03463938320055604
Trained batch 172 in epoch 7, gen_loss = 1.372477952800045, disc_loss = 0.034790393966384704
Trained batch 173 in epoch 7, gen_loss = 1.3735122711494052, disc_loss = 0.03463788515748991
Trained batch 174 in epoch 7, gen_loss = 1.3725350758007595, disc_loss = 0.0345183794519731
Trained batch 175 in epoch 7, gen_loss = 1.372023255648938, disc_loss = 0.034418660808693276
Trained batch 176 in epoch 7, gen_loss = 1.371715661159343, disc_loss = 0.034278277149897514
Trained batch 177 in epoch 7, gen_loss = 1.3741160246093622, disc_loss = 0.03424690311167682
Trained batch 178 in epoch 7, gen_loss = 1.3756991961148863, disc_loss = 0.03417141209018297
Trained batch 179 in epoch 7, gen_loss = 1.3767384876807531, disc_loss = 0.03403167672869232
Trained batch 180 in epoch 7, gen_loss = 1.3767257016666687, disc_loss = 0.033922616659936324
Trained batch 181 in epoch 7, gen_loss = 1.3776502985875685, disc_loss = 0.033783986432743926
Trained batch 182 in epoch 7, gen_loss = 1.3780285025554928, disc_loss = 0.0336582260918829
Trained batch 183 in epoch 7, gen_loss = 1.3766266369949216, disc_loss = 0.033617783626339034
Trained batch 184 in epoch 7, gen_loss = 1.3751229933790259, disc_loss = 0.03360287382493953
Trained batch 185 in epoch 7, gen_loss = 1.3751868583181852, disc_loss = 0.033892062768059714
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 1.6378480195999146, disc_loss = 0.02810061350464821
Trained batch 1 in epoch 8, gen_loss = 1.2471731901168823, disc_loss = 0.06324681080877781
Trained batch 2 in epoch 8, gen_loss = 1.234677751859029, disc_loss = 0.04705188423395157
Trained batch 3 in epoch 8, gen_loss = 1.2596977651119232, disc_loss = 0.039504673797637224
Trained batch 4 in epoch 8, gen_loss = 1.3027273416519165, disc_loss = 0.03824607022106648
Trained batch 5 in epoch 8, gen_loss = 1.3110082546869914, disc_loss = 0.03372524927059809
Trained batch 6 in epoch 8, gen_loss = 1.307655658040728, disc_loss = 0.03066521404044969
Trained batch 7 in epoch 8, gen_loss = 1.3431721031665802, disc_loss = 0.027966569177806377
Trained batch 8 in epoch 8, gen_loss = 1.339316235648261, disc_loss = 0.026692899150980845
Trained batch 9 in epoch 8, gen_loss = 1.3757993578910828, disc_loss = 0.025268403068184852
Trained batch 10 in epoch 8, gen_loss = 1.3974738988009365, disc_loss = 0.02373404868624427
Trained batch 11 in epoch 8, gen_loss = 1.3948221802711487, disc_loss = 0.022421359938258927
Trained batch 12 in epoch 8, gen_loss = 1.3825111847657423, disc_loss = 0.022460102963332947
Trained batch 13 in epoch 8, gen_loss = 1.3769209725516183, disc_loss = 0.021644034289887974
Trained batch 14 in epoch 8, gen_loss = 1.376166582107544, disc_loss = 0.020609298658867677
Trained batch 15 in epoch 8, gen_loss = 1.3687742203474045, disc_loss = 0.01988042629091069
Trained batch 16 in epoch 8, gen_loss = 1.3654236723394955, disc_loss = 0.019148599959033376
Trained batch 17 in epoch 8, gen_loss = 1.37040862109926, disc_loss = 0.021973224098069802
Trained batch 18 in epoch 8, gen_loss = 1.372474388072365, disc_loss = 0.02135485386181819
Trained batch 19 in epoch 8, gen_loss = 1.3720840394496918, disc_loss = 0.020756658585742115
Trained batch 20 in epoch 8, gen_loss = 1.3742834386371432, disc_loss = 0.020353514834174087
Trained batch 21 in epoch 8, gen_loss = 1.357365521517667, disc_loss = 0.022058175834403795
Trained batch 22 in epoch 8, gen_loss = 1.3437424379846323, disc_loss = 0.022487211931982765
Trained batch 23 in epoch 8, gen_loss = 1.353986953695615, disc_loss = 0.022817366872914135
Trained batch 24 in epoch 8, gen_loss = 1.369524540901184, disc_loss = 0.02261934269219637
Trained batch 25 in epoch 8, gen_loss = 1.3589377678357637, disc_loss = 0.02295560106778374
Trained batch 26 in epoch 8, gen_loss = 1.3570974049744782, disc_loss = 0.022720756526622508
Trained batch 27 in epoch 8, gen_loss = 1.3556303126471383, disc_loss = 0.022200726105698516
Trained batch 28 in epoch 8, gen_loss = 1.3630123426174294, disc_loss = 0.021814119327684928
Trained batch 29 in epoch 8, gen_loss = 1.364879349867503, disc_loss = 0.022053739180167516
Trained batch 30 in epoch 8, gen_loss = 1.36660082878605, disc_loss = 0.0216722832091393
Trained batch 31 in epoch 8, gen_loss = 1.3556980453431606, disc_loss = 0.022326214937493205
Trained batch 32 in epoch 8, gen_loss = 1.355583982034163, disc_loss = 0.02189388131779252
Trained batch 33 in epoch 8, gen_loss = 1.3728710237671347, disc_loss = 0.025260754203533426
Trained batch 34 in epoch 8, gen_loss = 1.357199559892927, disc_loss = 0.02739435120352677
Trained batch 35 in epoch 8, gen_loss = 1.3510005209181044, disc_loss = 0.028008079208019707
Trained batch 36 in epoch 8, gen_loss = 1.3489316089733228, disc_loss = 0.027986859651030722
Trained batch 37 in epoch 8, gen_loss = 1.3516750712143748, disc_loss = 0.027562385081852738
Trained batch 38 in epoch 8, gen_loss = 1.3496543688651843, disc_loss = 0.027260827521483105
Trained batch 39 in epoch 8, gen_loss = 1.3499596148729325, disc_loss = 0.02671254575252533
Trained batch 40 in epoch 8, gen_loss = 1.3423574348775351, disc_loss = 0.026980357471762632
Trained batch 41 in epoch 8, gen_loss = 1.3516492474646795, disc_loss = 0.026931652577505225
Trained batch 42 in epoch 8, gen_loss = 1.3511341255764628, disc_loss = 0.02675237342022186
Trained batch 43 in epoch 8, gen_loss = 1.3487699952992527, disc_loss = 0.02667696054347537
Trained batch 44 in epoch 8, gen_loss = 1.3405342102050781, disc_loss = 0.027206611384948096
Trained batch 45 in epoch 8, gen_loss = 1.3385243882303652, disc_loss = 0.02691093245116265
Trained batch 46 in epoch 8, gen_loss = 1.3555947111008015, disc_loss = 0.029620571616799273
Trained batch 47 in epoch 8, gen_loss = 1.350161609550317, disc_loss = 0.030141824041493237
Trained batch 48 in epoch 8, gen_loss = 1.3475269614433756, disc_loss = 0.03286035856878271
Trained batch 49 in epoch 8, gen_loss = 1.339251823425293, disc_loss = 0.033794469647109505
Trained batch 50 in epoch 8, gen_loss = 1.3322020769119263, disc_loss = 0.03432142687048398
Trained batch 51 in epoch 8, gen_loss = 1.3440696505399852, disc_loss = 0.04148548279100886
Trained batch 52 in epoch 8, gen_loss = 1.330206721458795, disc_loss = 0.04628140813196605
Trained batch 53 in epoch 8, gen_loss = 1.3323954376909468, disc_loss = 0.05039739122407304
Trained batch 54 in epoch 8, gen_loss = 1.3346072207797657, disc_loss = 0.05840264568951997
Trained batch 55 in epoch 8, gen_loss = 1.3329538628458977, disc_loss = 0.06898254166091126
Trained batch 56 in epoch 8, gen_loss = 1.3404944204447562, disc_loss = 0.08857925742733896
Trained batch 57 in epoch 8, gen_loss = 1.348712700194326, disc_loss = 0.10147755011787703
Trained batch 58 in epoch 8, gen_loss = 1.344957279956947, disc_loss = 0.10756829794559439
Trained batch 59 in epoch 8, gen_loss = 1.3354211588700613, disc_loss = 0.10901413867250084
Trained batch 60 in epoch 8, gen_loss = 1.3312670246499483, disc_loss = 0.1109133397885522
Trained batch 61 in epoch 8, gen_loss = 1.322260820096539, disc_loss = 0.11182273404612657
Trained batch 62 in epoch 8, gen_loss = 1.3159615255537487, disc_loss = 0.11234753504986801
Trained batch 63 in epoch 8, gen_loss = 1.3068891195580363, disc_loss = 0.11334801683551632
Trained batch 64 in epoch 8, gen_loss = 1.300796180505019, disc_loss = 0.11360685077424233
Trained batch 65 in epoch 8, gen_loss = 1.2929539481798809, disc_loss = 0.1141418158500032
Trained batch 66 in epoch 8, gen_loss = 1.2862869598972264, disc_loss = 0.11434473461513199
Trained batch 67 in epoch 8, gen_loss = 1.284150001757285, disc_loss = 0.11356800430289962
Trained batch 68 in epoch 8, gen_loss = 1.278725652591042, disc_loss = 0.11377213946611121
Trained batch 69 in epoch 8, gen_loss = 1.2713921001979283, disc_loss = 0.11408983668578522
Trained batch 70 in epoch 8, gen_loss = 1.2652421484530811, disc_loss = 0.11403403134727982
Trained batch 71 in epoch 8, gen_loss = 1.2619447824027803, disc_loss = 0.11443950781702167
Trained batch 72 in epoch 8, gen_loss = 1.2596008140746862, disc_loss = 0.11387207407555351
Trained batch 73 in epoch 8, gen_loss = 1.2551212777962555, disc_loss = 0.11333217539799374
Trained batch 74 in epoch 8, gen_loss = 1.2505093304316204, disc_loss = 0.11307668931782246
Trained batch 75 in epoch 8, gen_loss = 1.2502002496468394, disc_loss = 0.11294326252353035
Trained batch 76 in epoch 8, gen_loss = 1.2462420463562012, disc_loss = 0.11214433008103401
Trained batch 77 in epoch 8, gen_loss = 1.2398475935825934, disc_loss = 0.1123577944504527
Trained batch 78 in epoch 8, gen_loss = 1.240123758587656, disc_loss = 0.11237041385773616
Trained batch 79 in epoch 8, gen_loss = 1.2365434370934962, disc_loss = 0.11195111179258674
Trained batch 80 in epoch 8, gen_loss = 1.2345362894329024, disc_loss = 0.11113528500276583
Trained batch 81 in epoch 8, gen_loss = 1.2362789300883688, disc_loss = 0.11071773570757813
Trained batch 82 in epoch 8, gen_loss = 1.233180731894022, disc_loss = 0.11022730905517757
Trained batch 83 in epoch 8, gen_loss = 1.2298674420231865, disc_loss = 0.10970174288377166
Trained batch 84 in epoch 8, gen_loss = 1.2308470172040602, disc_loss = 0.10889784866834389
Trained batch 85 in epoch 8, gen_loss = 1.2312661347001097, disc_loss = 0.10779225059546703
Trained batch 86 in epoch 8, gen_loss = 1.2308146850816135, disc_loss = 0.10737787910747802
Trained batch 87 in epoch 8, gen_loss = 1.2273861528797583, disc_loss = 0.10694742215458643
Trained batch 88 in epoch 8, gen_loss = 1.2279662931903024, disc_loss = 0.10652762864915173
Trained batch 89 in epoch 8, gen_loss = 1.2294145935111576, disc_loss = 0.10547877027549678
Trained batch 90 in epoch 8, gen_loss = 1.2285043466222154, disc_loss = 0.10456983709278014
Trained batch 91 in epoch 8, gen_loss = 1.2300897998654323, disc_loss = 0.10355838959145805
Trained batch 92 in epoch 8, gen_loss = 1.2291361522930924, disc_loss = 0.1033509987736902
Trained batch 93 in epoch 8, gen_loss = 1.2313689963614687, disc_loss = 0.10258668046840962
Trained batch 94 in epoch 8, gen_loss = 1.2253085945781907, disc_loss = 0.10329182638149513
Trained batch 95 in epoch 8, gen_loss = 1.2319016139954329, disc_loss = 0.10332380984133731
Trained batch 96 in epoch 8, gen_loss = 1.23189109195139, disc_loss = 0.10240678743641708
Trained batch 97 in epoch 8, gen_loss = 1.2295763158068365, disc_loss = 0.10184251806907813
Trained batch 98 in epoch 8, gen_loss = 1.2281361414928629, disc_loss = 0.10117881512739743
Trained batch 99 in epoch 8, gen_loss = 1.2283552235364914, disc_loss = 0.10089369506575167
Trained batch 100 in epoch 8, gen_loss = 1.228022319845634, disc_loss = 0.10036935222952968
Trained batch 101 in epoch 8, gen_loss = 1.2257509564652163, disc_loss = 0.09994320258242535
Trained batch 102 in epoch 8, gen_loss = 1.2274223838037657, disc_loss = 0.09910519172446532
Trained batch 103 in epoch 8, gen_loss = 1.225396152299184, disc_loss = 0.09863831558658813
Trained batch 104 in epoch 8, gen_loss = 1.227386580762409, disc_loss = 0.09846610729360865
Trained batch 105 in epoch 8, gen_loss = 1.2264949977397919, disc_loss = 0.09782096559954982
Trained batch 106 in epoch 8, gen_loss = 1.2239730536380662, disc_loss = 0.09736347500513369
Trained batch 107 in epoch 8, gen_loss = 1.2253327226197277, disc_loss = 0.0982047164450503
Trained batch 108 in epoch 8, gen_loss = 1.2221025315993423, disc_loss = 0.09846922682615322
Trained batch 109 in epoch 8, gen_loss = 1.2196319189938631, disc_loss = 0.09816031025045298
Trained batch 110 in epoch 8, gen_loss = 1.2163546160534695, disc_loss = 0.09803618989918414
Trained batch 111 in epoch 8, gen_loss = 1.2173748346311706, disc_loss = 0.097697387507651
Trained batch 112 in epoch 8, gen_loss = 1.217120672749207, disc_loss = 0.0978366581525291
Trained batch 113 in epoch 8, gen_loss = 1.2144977497427087, disc_loss = 0.09751963235535904
Trained batch 114 in epoch 8, gen_loss = 1.2129378458727962, disc_loss = 0.09722990444658891
Trained batch 115 in epoch 8, gen_loss = 1.2152541767934273, disc_loss = 0.09704523686929767
Trained batch 116 in epoch 8, gen_loss = 1.2128296239763243, disc_loss = 0.09664894251200633
Trained batch 117 in epoch 8, gen_loss = 1.2112864867105322, disc_loss = 0.0962574935865478
Trained batch 118 in epoch 8, gen_loss = 1.211041248646103, disc_loss = 0.0956403447252487
Trained batch 119 in epoch 8, gen_loss = 1.2140787129600843, disc_loss = 0.09556018977891653
Trained batch 120 in epoch 8, gen_loss = 1.2137159655902012, disc_loss = 0.09497220470177486
Trained batch 121 in epoch 8, gen_loss = 1.2118714769355585, disc_loss = 0.09459788896540394
Trained batch 122 in epoch 8, gen_loss = 1.214347546178151, disc_loss = 0.09427859344163804
Trained batch 123 in epoch 8, gen_loss = 1.2135701616925578, disc_loss = 0.09381818498725132
Trained batch 124 in epoch 8, gen_loss = 1.213210889339447, disc_loss = 0.09323527150601149
Trained batch 125 in epoch 8, gen_loss = 1.2129456244763874, disc_loss = 0.0927916759225939
Trained batch 126 in epoch 8, gen_loss = 1.2137352786664888, disc_loss = 0.09220219747434685
Trained batch 127 in epoch 8, gen_loss = 1.2136175953783095, disc_loss = 0.09162821503559826
Trained batch 128 in epoch 8, gen_loss = 1.2157992027526678, disc_loss = 0.09106802829909463
Trained batch 129 in epoch 8, gen_loss = 1.2183670396988209, disc_loss = 0.09049444110490955
Trained batch 130 in epoch 8, gen_loss = 1.2184108900659867, disc_loss = 0.09005077343206597
Trained batch 131 in epoch 8, gen_loss = 1.215754465171785, disc_loss = 0.09004187104856652
Trained batch 132 in epoch 8, gen_loss = 1.2212241381630862, disc_loss = 0.08987761250367962
Trained batch 133 in epoch 8, gen_loss = 1.2214865831296835, disc_loss = 0.0893442959441289
Trained batch 134 in epoch 8, gen_loss = 1.2234323294074447, disc_loss = 0.08874934632331133
Trained batch 135 in epoch 8, gen_loss = 1.224809084306745, disc_loss = 0.08825586339705349
Trained batch 136 in epoch 8, gen_loss = 1.224532355792331, disc_loss = 0.08776662413737853
Trained batch 137 in epoch 8, gen_loss = 1.2231357119221618, disc_loss = 0.08743021990159068
Trained batch 138 in epoch 8, gen_loss = 1.2265317101272748, disc_loss = 0.08708453325139319
Trained batch 139 in epoch 8, gen_loss = 1.2272034240620477, disc_loss = 0.08653147496016962
Trained batch 140 in epoch 8, gen_loss = 1.2279471120935805, disc_loss = 0.08617679723241228
Trained batch 141 in epoch 8, gen_loss = 1.2265721043230782, disc_loss = 0.08585899563270136
Trained batch 142 in epoch 8, gen_loss = 1.2291471787265964, disc_loss = 0.08532502069105427
Trained batch 143 in epoch 8, gen_loss = 1.2310631635288398, disc_loss = 0.08495661129321282
Trained batch 144 in epoch 8, gen_loss = 1.2305862397983156, disc_loss = 0.08456291011052913
Trained batch 145 in epoch 8, gen_loss = 1.2322832905266383, disc_loss = 0.08402885023938263
Trained batch 146 in epoch 8, gen_loss = 1.2319317054586345, disc_loss = 0.08358492804247708
Trained batch 147 in epoch 8, gen_loss = 1.231092099805136, disc_loss = 0.08330889771742797
Trained batch 148 in epoch 8, gen_loss = 1.2345178691332772, disc_loss = 0.08292550744251317
Trained batch 149 in epoch 8, gen_loss = 1.2385031259059907, disc_loss = 0.0825764405541122
Trained batch 150 in epoch 8, gen_loss = 1.2383961586762737, disc_loss = 0.08225271488780415
Trained batch 151 in epoch 8, gen_loss = 1.2374022638327198, disc_loss = 0.08191661354718044
Trained batch 152 in epoch 8, gen_loss = 1.2388347523664338, disc_loss = 0.08148160779519993
Trained batch 153 in epoch 8, gen_loss = 1.2419812087114754, disc_loss = 0.08145881984261917
Trained batch 154 in epoch 8, gen_loss = 1.2395599688253096, disc_loss = 0.08161882684235611
Trained batch 155 in epoch 8, gen_loss = 1.2384329331226838, disc_loss = 0.08170828145021239
Trained batch 156 in epoch 8, gen_loss = 1.2391063271054796, disc_loss = 0.0814968930604826
Trained batch 157 in epoch 8, gen_loss = 1.238151084018659, disc_loss = 0.081166444257892
Trained batch 158 in epoch 8, gen_loss = 1.2388749227583784, disc_loss = 0.08081915944744393
Trained batch 159 in epoch 8, gen_loss = 1.2403048068284988, disc_loss = 0.08044866982963868
Trained batch 160 in epoch 8, gen_loss = 1.2390801121729502, disc_loss = 0.08013574508892268
Trained batch 161 in epoch 8, gen_loss = 1.2389750797071575, disc_loss = 0.07977539149722383
Trained batch 162 in epoch 8, gen_loss = 1.238605909552311, disc_loss = 0.07940466998522085
Trained batch 163 in epoch 8, gen_loss = 1.2414621514518087, disc_loss = 0.07922430644834005
Trained batch 164 in epoch 8, gen_loss = 1.2404189117027051, disc_loss = 0.07899823522364552
Trained batch 165 in epoch 8, gen_loss = 1.2413184010838887, disc_loss = 0.07864368189103811
Trained batch 166 in epoch 8, gen_loss = 1.2437038335971489, disc_loss = 0.07823473145951054
Trained batch 167 in epoch 8, gen_loss = 1.2477824205443973, disc_loss = 0.07819016554969407
Trained batch 168 in epoch 8, gen_loss = 1.2446440860364565, disc_loss = 0.07871363486146786
Trained batch 169 in epoch 8, gen_loss = 1.247726394148434, disc_loss = 0.07867063750677249
Trained batch 170 in epoch 8, gen_loss = 1.2494590296382793, disc_loss = 0.07832592242119606
Trained batch 171 in epoch 8, gen_loss = 1.2510792758575706, disc_loss = 0.07794018559764292
Trained batch 172 in epoch 8, gen_loss = 1.2522547286369896, disc_loss = 0.07756309187028966
Trained batch 173 in epoch 8, gen_loss = 1.252969776761943, disc_loss = 0.07719303389219032
Trained batch 174 in epoch 8, gen_loss = 1.2540011092594692, disc_loss = 0.07681613959372044
Trained batch 175 in epoch 8, gen_loss = 1.25593702359633, disc_loss = 0.07642997765320945
Trained batch 176 in epoch 8, gen_loss = 1.258599869948996, disc_loss = 0.07607757478510424
Trained batch 177 in epoch 8, gen_loss = 1.2590879027763109, disc_loss = 0.07572265187529532
Trained batch 178 in epoch 8, gen_loss = 1.2599359863963207, disc_loss = 0.07542130122658428
Trained batch 179 in epoch 8, gen_loss = 1.2600217541058858, disc_loss = 0.07511344774005314
Trained batch 180 in epoch 8, gen_loss = 1.2615744632910628, disc_loss = 0.07473536126716937
Trained batch 181 in epoch 8, gen_loss = 1.262045796755906, disc_loss = 0.07440374284256045
Trained batch 182 in epoch 8, gen_loss = 1.264515824656669, disc_loss = 0.07405316331194806
Trained batch 183 in epoch 8, gen_loss = 1.2672646836094235, disc_loss = 0.07382096783713558
Trained batch 184 in epoch 8, gen_loss = 1.2680646213325295, disc_loss = 0.07348247797958352
Trained batch 185 in epoch 8, gen_loss = 1.2671190077258694, disc_loss = 0.07326539516979728
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 1.6505436897277832, disc_loss = 0.008796293288469315
Trained batch 1 in epoch 9, gen_loss = 1.761548399925232, disc_loss = 0.013304732739925385
Trained batch 2 in epoch 9, gen_loss = 1.6447481314341228, disc_loss = 0.012412408366799355
Trained batch 3 in epoch 9, gen_loss = 1.6019440293312073, disc_loss = 0.012057265266776085
Trained batch 4 in epoch 9, gen_loss = 1.5746495723724365, disc_loss = 0.013048828393220902
Trained batch 5 in epoch 9, gen_loss = 1.5838796099026997, disc_loss = 0.012000063279022774
Trained batch 6 in epoch 9, gen_loss = 1.5055904218128748, disc_loss = 0.017514088191092014
Trained batch 7 in epoch 9, gen_loss = 1.532281681895256, disc_loss = 0.020766415516845882
Trained batch 8 in epoch 9, gen_loss = 1.5426696274015639, disc_loss = 0.01992002408951521
Trained batch 9 in epoch 9, gen_loss = 1.5302088737487793, disc_loss = 0.01933467825874686
Trained batch 10 in epoch 9, gen_loss = 1.5222063931551846, disc_loss = 0.018362607722255318
Trained batch 11 in epoch 9, gen_loss = 1.5001362562179565, disc_loss = 0.018905686447396874
Trained batch 12 in epoch 9, gen_loss = 1.5157343240884633, disc_loss = 0.018341521732509136
Trained batch 13 in epoch 9, gen_loss = 1.513382145336696, disc_loss = 0.018067402698631798
Trained batch 14 in epoch 9, gen_loss = 1.5033749262491862, disc_loss = 0.017359888615707555
Trained batch 15 in epoch 9, gen_loss = 1.5221779942512512, disc_loss = 0.01740981318289414
Trained batch 16 in epoch 9, gen_loss = 1.5008567501516903, disc_loss = 0.01816948574474629
Trained batch 17 in epoch 9, gen_loss = 1.4993493027157254, disc_loss = 0.01747277759326001
Trained batch 18 in epoch 9, gen_loss = 1.5441127827292995, disc_loss = 0.02046577992702001
Trained batch 19 in epoch 9, gen_loss = 1.5466934263706207, disc_loss = 0.019961628946475685
Trained batch 20 in epoch 9, gen_loss = 1.5520870288213093, disc_loss = 0.020144078769676742
Trained batch 21 in epoch 9, gen_loss = 1.5435882535847751, disc_loss = 0.019620701056820424
Trained batch 22 in epoch 9, gen_loss = 1.518906787685726, disc_loss = 0.020868593644674704
Trained batch 23 in epoch 9, gen_loss = 1.5177693987886112, disc_loss = 0.022098522536301363
Trained batch 24 in epoch 9, gen_loss = 1.5058264183998107, disc_loss = 0.021790873389691115
Trained batch 25 in epoch 9, gen_loss = 1.4938910855696752, disc_loss = 0.02180741954809771
Trained batch 26 in epoch 9, gen_loss = 1.5069557273829426, disc_loss = 0.021973712697487185
Trained batch 27 in epoch 9, gen_loss = 1.503385188324111, disc_loss = 0.021379752101243606
Trained batch 28 in epoch 9, gen_loss = 1.5160014526597385, disc_loss = 0.021373025510973972
Trained batch 29 in epoch 9, gen_loss = 1.5128351867198944, disc_loss = 0.020885860066240033
Trained batch 30 in epoch 9, gen_loss = 1.506392780811556, disc_loss = 0.020527705745471102
Trained batch 31 in epoch 9, gen_loss = 1.519289182499051, disc_loss = 0.020778169055120088
Trained batch 32 in epoch 9, gen_loss = 1.5141503901192637, disc_loss = 0.02054807059749058
Trained batch 33 in epoch 9, gen_loss = 1.5086351860972012, disc_loss = 0.020281270214849535
Trained batch 34 in epoch 9, gen_loss = 1.5037328158106122, disc_loss = 0.02002484621480107
Trained batch 35 in epoch 9, gen_loss = 1.5032531602515116, disc_loss = 0.019625855920215447
Trained batch 36 in epoch 9, gen_loss = 1.4991930803737126, disc_loss = 0.0192948744154057
Trained batch 37 in epoch 9, gen_loss = 1.5009022464877682, disc_loss = 0.019152668843928137
Trained batch 38 in epoch 9, gen_loss = 1.5014600096604762, disc_loss = 0.018913976680964995
Trained batch 39 in epoch 9, gen_loss = 1.4931554958224296, disc_loss = 0.019028115575201808
Trained batch 40 in epoch 9, gen_loss = 1.4878886603727572, disc_loss = 0.018970632630332215
Trained batch 41 in epoch 9, gen_loss = 1.4923087599731626, disc_loss = 0.018810922679092203
Trained batch 42 in epoch 9, gen_loss = 1.4933089475299037, disc_loss = 0.018702534395594928
Trained batch 43 in epoch 9, gen_loss = 1.4921569648114117, disc_loss = 0.018872800071469763
Trained batch 44 in epoch 9, gen_loss = 1.4938262422879538, disc_loss = 0.019702239375975397
Trained batch 45 in epoch 9, gen_loss = 1.4901970819286678, disc_loss = 0.0204405107980837
Trained batch 46 in epoch 9, gen_loss = 1.4908290632227634, disc_loss = 0.020239065738117443
Trained batch 47 in epoch 9, gen_loss = 1.4922504387795925, disc_loss = 0.02070936223026365
Trained batch 48 in epoch 9, gen_loss = 1.4842865673863157, disc_loss = 0.02096258449767317
Trained batch 49 in epoch 9, gen_loss = 1.477738300561905, disc_loss = 0.020988777466118335
Trained batch 50 in epoch 9, gen_loss = 1.4802389179959017, disc_loss = 0.020941297359326306
Trained batch 51 in epoch 9, gen_loss = 1.48312251499066, disc_loss = 0.020705938446693696
Trained batch 52 in epoch 9, gen_loss = 1.4822921291837152, disc_loss = 0.020471681717712926
Trained batch 53 in epoch 9, gen_loss = 1.4802889547966145, disc_loss = 0.020260147853857942
Trained batch 54 in epoch 9, gen_loss = 1.4757297851822593, disc_loss = 0.020191463794220578
Trained batch 55 in epoch 9, gen_loss = 1.4832544060690063, disc_loss = 0.020340672760669674
Trained batch 56 in epoch 9, gen_loss = 1.489390506033312, disc_loss = 0.020383528842214952
Trained batch 57 in epoch 9, gen_loss = 1.482011193859166, disc_loss = 0.020935149285300023
Trained batch 58 in epoch 9, gen_loss = 1.4817433710825645, disc_loss = 0.020697098130644378
Trained batch 59 in epoch 9, gen_loss = 1.483147953947385, disc_loss = 0.020582577927658954
Trained batch 60 in epoch 9, gen_loss = 1.4798809964148725, disc_loss = 0.020460307399635433
Trained batch 61 in epoch 9, gen_loss = 1.480237248443788, disc_loss = 0.020283745857135903
Trained batch 62 in epoch 9, gen_loss = 1.4808473369431874, disc_loss = 0.020096485650846884
Trained batch 63 in epoch 9, gen_loss = 1.4801412364467978, disc_loss = 0.019862769775500055
Trained batch 64 in epoch 9, gen_loss = 1.4788406876417306, disc_loss = 0.01964335382127991
Trained batch 65 in epoch 9, gen_loss = 1.47758066202655, disc_loss = 0.01943913933990354
Trained batch 66 in epoch 9, gen_loss = 1.4781092930195936, disc_loss = 0.019289118230843276
Trained batch 67 in epoch 9, gen_loss = 1.4774852473946178, disc_loss = 0.019074138027944547
Trained batch 68 in epoch 9, gen_loss = 1.4793324375498123, disc_loss = 0.01896512756070149
Trained batch 69 in epoch 9, gen_loss = 1.4802805687699998, disc_loss = 0.01878060239500233
Trained batch 70 in epoch 9, gen_loss = 1.478162319727347, disc_loss = 0.018616289143043925
Trained batch 71 in epoch 9, gen_loss = 1.4727452240056462, disc_loss = 0.018745373527053744
Trained batch 72 in epoch 9, gen_loss = 1.4746536563520563, disc_loss = 0.018772986481502038
Trained batch 73 in epoch 9, gen_loss = 1.4732082300894969, disc_loss = 0.018610627258297156
Trained batch 74 in epoch 9, gen_loss = 1.468978939851125, disc_loss = 0.01863314081604282
Trained batch 75 in epoch 9, gen_loss = 1.4679564433662515, disc_loss = 0.018464582825177593
Trained batch 76 in epoch 9, gen_loss = 1.4693645138245124, disc_loss = 0.018638445862701962
Trained batch 77 in epoch 9, gen_loss = 1.4647931357224782, disc_loss = 0.01871581533207343
Trained batch 78 in epoch 9, gen_loss = 1.4660810647131521, disc_loss = 0.018588266417950014
Trained batch 79 in epoch 9, gen_loss = 1.4611664988100528, disc_loss = 0.018745818920433522
Trained batch 80 in epoch 9, gen_loss = 1.4633121586140292, disc_loss = 0.018898608714894013
Trained batch 81 in epoch 9, gen_loss = 1.462882324689772, disc_loss = 0.01873509909548774
Trained batch 82 in epoch 9, gen_loss = 1.4566568725080375, disc_loss = 0.01924727117665202
Trained batch 83 in epoch 9, gen_loss = 1.4570811845007396, disc_loss = 0.019123275886245426
Trained batch 84 in epoch 9, gen_loss = 1.4541977994582231, disc_loss = 0.019243375639266827
Trained batch 85 in epoch 9, gen_loss = 1.4549714021904523, disc_loss = 0.019180358993972458
Trained batch 86 in epoch 9, gen_loss = 1.454793480620987, disc_loss = 0.019011752417675037
Trained batch 87 in epoch 9, gen_loss = 1.4528592188249936, disc_loss = 0.018945024078923532
Trained batch 88 in epoch 9, gen_loss = 1.454413664474916, disc_loss = 0.019085837658913283
Trained batch 89 in epoch 9, gen_loss = 1.4472115212016636, disc_loss = 0.019885781516010562
Trained batch 90 in epoch 9, gen_loss = 1.4459317477194817, disc_loss = 0.019770476429794844
Trained batch 91 in epoch 9, gen_loss = 1.4453337114790212, disc_loss = 0.02040833906452779
Trained batch 92 in epoch 9, gen_loss = 1.447246975796197, disc_loss = 0.02031890606828114
Trained batch 93 in epoch 9, gen_loss = 1.4392829169618322, disc_loss = 0.02173810649881179
Trained batch 94 in epoch 9, gen_loss = 1.4378728151321412, disc_loss = 0.02160901144441021
Trained batch 95 in epoch 9, gen_loss = 1.438318310926358, disc_loss = 0.02276034870010335
Trained batch 96 in epoch 9, gen_loss = 1.433352563799042, disc_loss = 0.023130025786645327
Trained batch 97 in epoch 9, gen_loss = 1.4345441278146238, disc_loss = 0.023059577011142154
Trained batch 98 in epoch 9, gen_loss = 1.4344054147450611, disc_loss = 0.022987824925832977
Trained batch 99 in epoch 9, gen_loss = 1.430230177640915, disc_loss = 0.02311608792748302
Trained batch 100 in epoch 9, gen_loss = 1.4307908409892922, disc_loss = 0.022934379715398693
Trained batch 101 in epoch 9, gen_loss = 1.432854551894992, disc_loss = 0.022927960723309833
Trained batch 102 in epoch 9, gen_loss = 1.4325800590144777, disc_loss = 0.022744450885440828
Trained batch 103 in epoch 9, gen_loss = 1.426798517887409, disc_loss = 0.02355363333257488
Trained batch 104 in epoch 9, gen_loss = 1.4290465956642515, disc_loss = 0.023837017538469462
Trained batch 105 in epoch 9, gen_loss = 1.4278653151584122, disc_loss = 0.023765148581796378
Trained batch 106 in epoch 9, gen_loss = 1.4272992287840798, disc_loss = 0.023797505513425465
Trained batch 107 in epoch 9, gen_loss = 1.423916381818277, disc_loss = 0.02385811104559926
Trained batch 108 in epoch 9, gen_loss = 1.4215275147639284, disc_loss = 0.023911319745687443
Trained batch 109 in epoch 9, gen_loss = 1.4219685218550941, disc_loss = 0.024145469107580454
Trained batch 110 in epoch 9, gen_loss = 1.4178747271632288, disc_loss = 0.024402192051245553
Trained batch 111 in epoch 9, gen_loss = 1.4157289905207497, disc_loss = 0.0243632692851991
Trained batch 112 in epoch 9, gen_loss = 1.4148300822857207, disc_loss = 0.025153796876722995
Trained batch 113 in epoch 9, gen_loss = 1.4149550335449086, disc_loss = 0.025009003676179992
Trained batch 114 in epoch 9, gen_loss = 1.4126714519832446, disc_loss = 0.025007631010173455
Trained batch 115 in epoch 9, gen_loss = 1.4115977133142537, disc_loss = 0.02500594817985106
Trained batch 116 in epoch 9, gen_loss = 1.4122600616552892, disc_loss = 0.024893681801314283
Trained batch 117 in epoch 9, gen_loss = 1.4091490143436496, disc_loss = 0.0251910472012488
Trained batch 118 in epoch 9, gen_loss = 1.407671900356517, disc_loss = 0.025117409145537794
Trained batch 119 in epoch 9, gen_loss = 1.4086311678091685, disc_loss = 0.025074830437855175
Trained batch 120 in epoch 9, gen_loss = 1.4091619903391057, disc_loss = 0.02491680683552726
Trained batch 121 in epoch 9, gen_loss = 1.4077929541712901, disc_loss = 0.024903090395888346
Trained batch 122 in epoch 9, gen_loss = 1.407279112474705, disc_loss = 0.024801027219045937
Trained batch 123 in epoch 9, gen_loss = 1.4095141233936432, disc_loss = 0.024990218879294493
Trained batch 124 in epoch 9, gen_loss = 1.4052000780105591, disc_loss = 0.025333453871309756
Trained batch 125 in epoch 9, gen_loss = 1.4068723548026312, disc_loss = 0.02526904647755954
Trained batch 126 in epoch 9, gen_loss = 1.4077492023077536, disc_loss = 0.02513604685224182
Trained batch 127 in epoch 9, gen_loss = 1.4098199009895325, disc_loss = 0.025017492916958872
Trained batch 128 in epoch 9, gen_loss = 1.4090115136878436, disc_loss = 0.024889350652174895
Trained batch 129 in epoch 9, gen_loss = 1.4062631176068232, disc_loss = 0.025006258423225236
Trained batch 130 in epoch 9, gen_loss = 1.4098155898902252, disc_loss = 0.025310993016846764
Trained batch 131 in epoch 9, gen_loss = 1.4100499062827139, disc_loss = 0.02519329551917811
Trained batch 132 in epoch 9, gen_loss = 1.4064227956578248, disc_loss = 0.02558270505020269
Trained batch 133 in epoch 9, gen_loss = 1.406184349042266, disc_loss = 0.025532182215699063
Trained batch 134 in epoch 9, gen_loss = 1.405850021485929, disc_loss = 0.02549341200264516
Trained batch 135 in epoch 9, gen_loss = 1.4026895051493364, disc_loss = 0.02591153306146974
Trained batch 136 in epoch 9, gen_loss = 1.4019398054067236, disc_loss = 0.02579929360127362
Trained batch 137 in epoch 9, gen_loss = 1.4032447338104248, disc_loss = 0.025743368864599346
Trained batch 138 in epoch 9, gen_loss = 1.402714429141806, disc_loss = 0.02560638010555463
Trained batch 139 in epoch 9, gen_loss = 1.4017997809818812, disc_loss = 0.025510600009667022
Trained batch 140 in epoch 9, gen_loss = 1.4016883728351999, disc_loss = 0.02545813761704357
Trained batch 141 in epoch 9, gen_loss = 1.4037708732443797, disc_loss = 0.025438802946411387
Trained batch 142 in epoch 9, gen_loss = 1.4017775917386675, disc_loss = 0.02546480552039363
Trained batch 143 in epoch 9, gen_loss = 1.4022489479846425, disc_loss = 0.025321691904941365
Trained batch 144 in epoch 9, gen_loss = 1.4032449335887514, disc_loss = 0.02519475937146565
Trained batch 145 in epoch 9, gen_loss = 1.402703823292092, disc_loss = 0.025101298415293433
Trained batch 146 in epoch 9, gen_loss = 1.4045147855265612, disc_loss = 0.02499526773965886
Trained batch 147 in epoch 9, gen_loss = 1.405599263068792, disc_loss = 0.02486213282807856
Trained batch 148 in epoch 9, gen_loss = 1.403610582319682, disc_loss = 0.024889870252985283
Trained batch 149 in epoch 9, gen_loss = 1.4038444447517395, disc_loss = 0.02479178166637818
Trained batch 150 in epoch 9, gen_loss = 1.4019262009109092, disc_loss = 0.024797593409948002
Trained batch 151 in epoch 9, gen_loss = 1.4022404771102102, disc_loss = 0.024894697579408164
Trained batch 152 in epoch 9, gen_loss = 1.4030838994418873, disc_loss = 0.024786069051794757
Trained batch 153 in epoch 9, gen_loss = 1.4033081647637602, disc_loss = 0.02465796356948165
Trained batch 154 in epoch 9, gen_loss = 1.3997948961873208, disc_loss = 0.025098630809976208
Trained batch 155 in epoch 9, gen_loss = 1.4022701130463526, disc_loss = 0.0252689557054486
Trained batch 156 in epoch 9, gen_loss = 1.402134867990093, disc_loss = 0.025141258471924218
Trained batch 157 in epoch 9, gen_loss = 1.4021698402453073, disc_loss = 0.02504342692149685
Trained batch 158 in epoch 9, gen_loss = 1.4011118876859077, disc_loss = 0.02496492756975803
Trained batch 159 in epoch 9, gen_loss = 1.4003871634602547, disc_loss = 0.02493540151917841
Trained batch 160 in epoch 9, gen_loss = 1.3998659530781812, disc_loss = 0.02488116466191522
Trained batch 161 in epoch 9, gen_loss = 1.400177056406751, disc_loss = 0.024794610720242798
Trained batch 162 in epoch 9, gen_loss = 1.3979360208920906, disc_loss = 0.024833399376780526
Trained batch 163 in epoch 9, gen_loss = 1.400837399610659, disc_loss = 0.024819052059816698
Trained batch 164 in epoch 9, gen_loss = 1.404242289427555, disc_loss = 0.025116237577502476
Trained batch 165 in epoch 9, gen_loss = 1.4040244386856815, disc_loss = 0.025059064566887106
Trained batch 166 in epoch 9, gen_loss = 1.4011772963815106, disc_loss = 0.025282795521469708
Trained batch 167 in epoch 9, gen_loss = 1.4017323099431538, disc_loss = 0.025250806171070075
Trained batch 168 in epoch 9, gen_loss = 1.4003566157888379, disc_loss = 0.025371018033915546
Trained batch 169 in epoch 9, gen_loss = 1.3995856221984415, disc_loss = 0.02538517628905966
Trained batch 170 in epoch 9, gen_loss = 1.398696292213529, disc_loss = 0.0253111302760043
Trained batch 171 in epoch 9, gen_loss = 1.3970555635385735, disc_loss = 0.025412492245587327
Trained batch 172 in epoch 9, gen_loss = 1.396159162411111, disc_loss = 0.025341292334494392
Trained batch 173 in epoch 9, gen_loss = 1.3972818755555427, disc_loss = 0.025402274108545363
Trained batch 174 in epoch 9, gen_loss = 1.3960551990781511, disc_loss = 0.025381278552647147
Trained batch 175 in epoch 9, gen_loss = 1.3952904445203869, disc_loss = 0.02531852858109315
Trained batch 176 in epoch 9, gen_loss = 1.3970373606277724, disc_loss = 0.025285498520601437
Trained batch 177 in epoch 9, gen_loss = 1.3954876393414615, disc_loss = 0.025300952095768593
Trained batch 178 in epoch 9, gen_loss = 1.397037938320437, disc_loss = 0.025305375771586622
Trained batch 179 in epoch 9, gen_loss = 1.3964129851924048, disc_loss = 0.025245486564623814
Trained batch 180 in epoch 9, gen_loss = 1.398433865104591, disc_loss = 0.025183017033754296
Trained batch 181 in epoch 9, gen_loss = 1.397867528291849, disc_loss = 0.025165141184026234
Trained batch 182 in epoch 9, gen_loss = 1.3992813877720651, disc_loss = 0.025081216192249556
Trained batch 183 in epoch 9, gen_loss = 1.3984931389922681, disc_loss = 0.025011251612222226
Trained batch 184 in epoch 9, gen_loss = 1.3986844236786302, disc_loss = 0.025117231998592615
Trained batch 185 in epoch 9, gen_loss = 1.3974064838501714, disc_loss = 0.02516528434540716
Testing Epoch 9
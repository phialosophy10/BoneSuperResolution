/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 1.7001562118530273, disc_loss = 0.5792700052261353
Trained batch 1 in epoch 0, gen_loss = 1.79063880443573, disc_loss = 0.8970703482627869
Trained batch 2 in epoch 0, gen_loss = 1.8523306846618652, disc_loss = 0.8713937203089396
Trained batch 3 in epoch 0, gen_loss = 1.8501758575439453, disc_loss = 0.7547310814261436
Trained batch 4 in epoch 0, gen_loss = 1.7893618583679198, disc_loss = 0.6861526072025299
Trained batch 5 in epoch 0, gen_loss = 1.7747017343839009, disc_loss = 0.6187550127506256
Trained batch 6 in epoch 0, gen_loss = 1.7212628296443395, disc_loss = 0.568208030291966
Trained batch 7 in epoch 0, gen_loss = 1.6827544271945953, disc_loss = 0.5247682798653841
Trained batch 8 in epoch 0, gen_loss = 1.6600226561228435, disc_loss = 0.4857175946235657
Trained batch 9 in epoch 0, gen_loss = 1.6583671808242797, disc_loss = 0.4566551446914673
Trained batch 10 in epoch 0, gen_loss = 1.67067674073306, disc_loss = 0.4393746825781735
Trained batch 11 in epoch 0, gen_loss = 1.6727287073930104, disc_loss = 0.4211845820148786
Trained batch 12 in epoch 0, gen_loss = 1.6649688940781813, disc_loss = 0.4037506144780379
Trained batch 13 in epoch 0, gen_loss = 1.6581011073929923, disc_loss = 0.38579386259828297
Trained batch 14 in epoch 0, gen_loss = 1.6627711693445841, disc_loss = 0.3696385552485784
Trained batch 15 in epoch 0, gen_loss = 1.639734648168087, disc_loss = 0.35444741044193506
Trained batch 16 in epoch 0, gen_loss = 1.638956069946289, disc_loss = 0.33990717810742993
Trained batch 17 in epoch 0, gen_loss = 1.653980831305186, disc_loss = 0.3292856456504928
Trained batch 18 in epoch 0, gen_loss = 1.6594294184132625, disc_loss = 0.3183700607011193
Trained batch 19 in epoch 0, gen_loss = 1.6732036530971528, disc_loss = 0.30797665044665334
Trained batch 20 in epoch 0, gen_loss = 1.6776219038736253, disc_loss = 0.299747061871347
Trained batch 21 in epoch 0, gen_loss = 1.6831127676096829, disc_loss = 0.29209287803281436
Trained batch 22 in epoch 0, gen_loss = 1.6905787146609763, disc_loss = 0.2836857347384743
Trained batch 23 in epoch 0, gen_loss = 1.6836569706598918, disc_loss = 0.2758073741570115
Trained batch 24 in epoch 0, gen_loss = 1.6882731533050537, disc_loss = 0.2681893071532249
Trained batch 25 in epoch 0, gen_loss = 1.6938483577508192, disc_loss = 0.2611031449184968
Trained batch 26 in epoch 0, gen_loss = 1.7037141367241189, disc_loss = 0.25406930926773286
Trained batch 27 in epoch 0, gen_loss = 1.7202282420226507, disc_loss = 0.2469978980453951
Trained batch 28 in epoch 0, gen_loss = 1.7203374731129613, disc_loss = 0.24113851721430646
Trained batch 29 in epoch 0, gen_loss = 1.7164084394772847, disc_loss = 0.23577189358572165
Trained batch 30 in epoch 0, gen_loss = 1.7271850070645731, disc_loss = 0.23055935134330102
Trained batch 31 in epoch 0, gen_loss = 1.7188989482820034, disc_loss = 0.22706036816816777
Trained batch 32 in epoch 0, gen_loss = 1.7148772983840017, disc_loss = 0.22352212859374104
Trained batch 33 in epoch 0, gen_loss = 1.718665904858533, disc_loss = 0.22197908086373525
Trained batch 34 in epoch 0, gen_loss = 1.722492470060076, disc_loss = 0.22295499624950546
Trained batch 35 in epoch 0, gen_loss = 1.7228728599018521, disc_loss = 0.21985756947348514
Trained batch 36 in epoch 0, gen_loss = 1.7222588932192004, disc_loss = 0.21591133271922935
Trained batch 37 in epoch 0, gen_loss = 1.7211100396357084, disc_loss = 0.21193938202371723
Trained batch 38 in epoch 0, gen_loss = 1.728495912674146, disc_loss = 0.20786163077140465
Trained batch 39 in epoch 0, gen_loss = 1.7282575041055679, disc_loss = 0.20433975104242563
Trained batch 40 in epoch 0, gen_loss = 1.7269837042180503, disc_loss = 0.20063536759556794
Trained batch 41 in epoch 0, gen_loss = 1.7238091826438904, disc_loss = 0.19733320362865925
Trained batch 42 in epoch 0, gen_loss = 1.7229215544323588, disc_loss = 0.19398650873539058
Trained batch 43 in epoch 0, gen_loss = 1.7306676777926358, disc_loss = 0.19072817494584757
Trained batch 44 in epoch 0, gen_loss = 1.7346715185377333, disc_loss = 0.1882903757194678
Trained batch 45 in epoch 0, gen_loss = 1.7438133488530698, disc_loss = 0.1857725866948781
Trained batch 46 in epoch 0, gen_loss = 1.736528330660881, disc_loss = 0.18327525567184103
Trained batch 47 in epoch 0, gen_loss = 1.7406168480714161, disc_loss = 0.18096093297936022
Trained batch 48 in epoch 0, gen_loss = 1.7472509121408268, disc_loss = 0.17859376214292585
Trained batch 49 in epoch 0, gen_loss = 1.7477871108055114, disc_loss = 0.17628358520567416
Trained batch 50 in epoch 0, gen_loss = 1.746381579660902, disc_loss = 0.17444023321948798
Trained batch 51 in epoch 0, gen_loss = 1.7461452323656816, disc_loss = 0.1739659017811601
Trained batch 52 in epoch 0, gen_loss = 1.7471151959221318, disc_loss = 0.17412172461736877
Trained batch 53 in epoch 0, gen_loss = 1.747745414574941, disc_loss = 0.17392885471107783
Trained batch 54 in epoch 0, gen_loss = 1.7584797404029153, disc_loss = 0.17264292599125342
Trained batch 55 in epoch 0, gen_loss = 1.7614587396383286, disc_loss = 0.17143583597083176
Trained batch 56 in epoch 0, gen_loss = 1.7587334377723827, disc_loss = 0.16926043297637972
Trained batch 57 in epoch 0, gen_loss = 1.7598942785427487, disc_loss = 0.16696262635804457
Trained batch 58 in epoch 0, gen_loss = 1.7554231740660586, disc_loss = 0.16479217178993305
Trained batch 59 in epoch 0, gen_loss = 1.7566059370835623, disc_loss = 0.16274987341215214
Trained batch 60 in epoch 0, gen_loss = 1.761428201784853, disc_loss = 0.1607939938663459
Trained batch 61 in epoch 0, gen_loss = 1.760947794683518, disc_loss = 0.1586935892701149
Trained batch 62 in epoch 0, gen_loss = 1.7621566549180046, disc_loss = 0.15685492635719359
Trained batch 63 in epoch 0, gen_loss = 1.7633581273257732, disc_loss = 0.15498657163698226
Trained batch 64 in epoch 0, gen_loss = 1.7636516204247108, disc_loss = 0.15305153856483789
Trained batch 65 in epoch 0, gen_loss = 1.762576988249114, disc_loss = 0.15115179773420095
Trained batch 66 in epoch 0, gen_loss = 1.7599498656258654, disc_loss = 0.14927742571861885
Trained batch 67 in epoch 0, gen_loss = 1.7571447982507593, disc_loss = 0.1476780031259884
Trained batch 68 in epoch 0, gen_loss = 1.7541784169017405, disc_loss = 0.14617749452051046
Trained batch 69 in epoch 0, gen_loss = 1.7574650236538478, disc_loss = 0.14467820852462734
Trained batch 70 in epoch 0, gen_loss = 1.7587835268235543, disc_loss = 0.14320076800043313
Trained batch 71 in epoch 0, gen_loss = 1.756265241238806, disc_loss = 0.14195204647775325
Trained batch 72 in epoch 0, gen_loss = 1.754923351823467, disc_loss = 0.14056158451082773
Trained batch 73 in epoch 0, gen_loss = 1.7548934704548604, disc_loss = 0.13922246240985556
Trained batch 74 in epoch 0, gen_loss = 1.7538915189107258, disc_loss = 0.13786811403930188
Trained batch 75 in epoch 0, gen_loss = 1.7545261649708999, disc_loss = 0.1364041437689019
Trained batch 76 in epoch 0, gen_loss = 1.7527404110153, disc_loss = 0.13499439248887748
Trained batch 77 in epoch 0, gen_loss = 1.7537951683386779, disc_loss = 0.13381437367449203
Trained batch 78 in epoch 0, gen_loss = 1.7577012188826935, disc_loss = 0.1325910336844906
Trained batch 79 in epoch 0, gen_loss = 1.7583992406725883, disc_loss = 0.13130955391097815
Trained batch 80 in epoch 0, gen_loss = 1.7567426481364685, disc_loss = 0.1301176423597851
Trained batch 81 in epoch 0, gen_loss = 1.757087089666506, disc_loss = 0.12880079432322486
Trained batch 82 in epoch 0, gen_loss = 1.7592363012842385, disc_loss = 0.12755864582596774
Trained batch 83 in epoch 0, gen_loss = 1.7573987302326022, disc_loss = 0.1266496454454249
Trained batch 84 in epoch 0, gen_loss = 1.7546583806767184, disc_loss = 0.12554318153244606
Trained batch 85 in epoch 0, gen_loss = 1.752086969309075, disc_loss = 0.12439588093480398
Trained batch 86 in epoch 0, gen_loss = 1.7516763237701065, disc_loss = 0.12324323941921365
Trained batch 87 in epoch 0, gen_loss = 1.7509035739031704, disc_loss = 0.12208982455459508
Trained batch 88 in epoch 0, gen_loss = 1.751913327849313, disc_loss = 0.12097203076471773
Trained batch 89 in epoch 0, gen_loss = 1.753251232041253, disc_loss = 0.12000172401054038
Trained batch 90 in epoch 0, gen_loss = 1.7514942177049406, disc_loss = 0.11899895124792398
Trained batch 91 in epoch 0, gen_loss = 1.754247140625249, disc_loss = 0.1180277264515019
Trained batch 92 in epoch 0, gen_loss = 1.757320120770444, disc_loss = 0.11701061949133873
Trained batch 93 in epoch 0, gen_loss = 1.75662370311453, disc_loss = 0.11600814050340906
Trained batch 94 in epoch 0, gen_loss = 1.7558197146967838, disc_loss = 0.11498087336750407
Trained batch 95 in epoch 0, gen_loss = 1.7536133155226707, disc_loss = 0.11452789672572787
Trained batch 96 in epoch 0, gen_loss = 1.752200829614069, disc_loss = 0.11388413099207215
Trained batch 97 in epoch 0, gen_loss = 1.7534214537970874, disc_loss = 0.11299100790020762
Trained batch 98 in epoch 0, gen_loss = 1.7537962174174762, disc_loss = 0.1121471608716129
Trained batch 99 in epoch 0, gen_loss = 1.7551872384548188, disc_loss = 0.11121810317039489
Trained batch 100 in epoch 0, gen_loss = 1.754424228526578, disc_loss = 0.11032666682754413
Trained batch 101 in epoch 0, gen_loss = 1.7526378900397057, disc_loss = 0.10976587977333396
Trained batch 102 in epoch 0, gen_loss = 1.7527370846387251, disc_loss = 0.10927976740216747
Trained batch 103 in epoch 0, gen_loss = 1.7553214797606835, disc_loss = 0.10867898882581638
Trained batch 104 in epoch 0, gen_loss = 1.7524200246447608, disc_loss = 0.10880006487880434
Trained batch 105 in epoch 0, gen_loss = 1.7509736025108482, disc_loss = 0.10848873649846832
Trained batch 106 in epoch 0, gen_loss = 1.749676100561552, disc_loss = 0.10790459609755845
Trained batch 107 in epoch 0, gen_loss = 1.7499331346264593, disc_loss = 0.10709077264699671
Trained batch 108 in epoch 0, gen_loss = 1.7511642635415454, disc_loss = 0.10628597706624675
Trained batch 109 in epoch 0, gen_loss = 1.754989038814198, disc_loss = 0.1055227731269869
Trained batch 110 in epoch 0, gen_loss = 1.7548793661701787, disc_loss = 0.10473894331235069
Trained batch 111 in epoch 0, gen_loss = 1.755583185170378, disc_loss = 0.10397234377783857
Trained batch 112 in epoch 0, gen_loss = 1.754292214866233, disc_loss = 0.10315995909834066
Trained batch 113 in epoch 0, gen_loss = 1.752075116885336, disc_loss = 0.10242252812410395
Trained batch 114 in epoch 0, gen_loss = 1.753811762643897, disc_loss = 0.10183777374255916
Trained batch 115 in epoch 0, gen_loss = 1.7516004515105281, disc_loss = 0.10121032198216638
Trained batch 116 in epoch 0, gen_loss = 1.7547128414496398, disc_loss = 0.10049655690438981
Trained batch 117 in epoch 0, gen_loss = 1.7554642436868053, disc_loss = 0.09981137977407897
Trained batch 118 in epoch 0, gen_loss = 1.7555053865208345, disc_loss = 0.09919523869586341
Trained batch 119 in epoch 0, gen_loss = 1.75589253505071, disc_loss = 0.09861608173232525
Trained batch 120 in epoch 0, gen_loss = 1.756776714127911, disc_loss = 0.09801592652431944
Trained batch 121 in epoch 0, gen_loss = 1.755042025300323, disc_loss = 0.09740484099010707
Trained batch 122 in epoch 0, gen_loss = 1.754939048270869, disc_loss = 0.09679374423604913
Trained batch 123 in epoch 0, gen_loss = 1.75448678962646, disc_loss = 0.09614891556632374
Trained batch 124 in epoch 0, gen_loss = 1.753647334098816, disc_loss = 0.09555510542541742
Trained batch 125 in epoch 0, gen_loss = 1.754765424463484, disc_loss = 0.09493546153137845
Trained batch 126 in epoch 0, gen_loss = 1.7558894129249993, disc_loss = 0.09438799262252145
Trained batch 127 in epoch 0, gen_loss = 1.753368454053998, disc_loss = 0.09444701583561255
Trained batch 128 in epoch 0, gen_loss = 1.7519306822340617, disc_loss = 0.09399400743143271
Trained batch 129 in epoch 0, gen_loss = 1.7539113283157348, disc_loss = 0.09362263340646258
Trained batch 130 in epoch 0, gen_loss = 1.7545256669284732, disc_loss = 0.09307789402295842
Trained batch 131 in epoch 0, gen_loss = 1.7569812789107815, disc_loss = 0.09253262170364684
Trained batch 132 in epoch 0, gen_loss = 1.756246763064449, disc_loss = 0.0919676683072869
Trained batch 133 in epoch 0, gen_loss = 1.757219164229151, disc_loss = 0.09139959507885931
Trained batch 134 in epoch 0, gen_loss = 1.7583840944148876, disc_loss = 0.09090081059408409
Trained batch 135 in epoch 0, gen_loss = 1.7605184395523632, disc_loss = 0.09035872027743608
Trained batch 136 in epoch 0, gen_loss = 1.7610034037680522, disc_loss = 0.08983499856570559
Trained batch 137 in epoch 0, gen_loss = 1.763332271921462, disc_loss = 0.0893163153078353
Trained batch 138 in epoch 0, gen_loss = 1.7661070532078365, disc_loss = 0.08879532238213922
Trained batch 139 in epoch 0, gen_loss = 1.7640357102666582, disc_loss = 0.0882866622547486
Trained batch 140 in epoch 0, gen_loss = 1.762535295587905, disc_loss = 0.08778794843650667
Trained batch 141 in epoch 0, gen_loss = 1.7622664637968575, disc_loss = 0.08727899123586609
Trained batch 142 in epoch 0, gen_loss = 1.7616369515865833, disc_loss = 0.08682457517207294
Trained batch 143 in epoch 0, gen_loss = 1.7601097499330838, disc_loss = 0.08631510791989665
Trained batch 144 in epoch 0, gen_loss = 1.7603433518574156, disc_loss = 0.08582750156136422
Trained batch 145 in epoch 0, gen_loss = 1.7583864167945025, disc_loss = 0.08540411429377655
Trained batch 146 in epoch 0, gen_loss = 1.7582603944402162, disc_loss = 0.0849274689154256
Trained batch 147 in epoch 0, gen_loss = 1.7615862665949642, disc_loss = 0.08447364537120872
Trained batch 148 in epoch 0, gen_loss = 1.761839955445104, disc_loss = 0.08404191952798791
Trained batch 149 in epoch 0, gen_loss = 1.7606524674097697, disc_loss = 0.08363786576315761
Trained batch 150 in epoch 0, gen_loss = 1.7594445959621707, disc_loss = 0.08320771597498497
Trained batch 151 in epoch 0, gen_loss = 1.758061455268609, disc_loss = 0.08277522661649671
Trained batch 152 in epoch 0, gen_loss = 1.7557981325909982, disc_loss = 0.08232966017318902
Trained batch 153 in epoch 0, gen_loss = 1.7554300574513224, disc_loss = 0.08192108133082072
Trained batch 154 in epoch 0, gen_loss = 1.7556619036582208, disc_loss = 0.08149574333501439
Trained batch 155 in epoch 0, gen_loss = 1.7568481763203938, disc_loss = 0.0810426210757727
Trained batch 156 in epoch 0, gen_loss = 1.757984012555165, disc_loss = 0.08062478965800848
Trained batch 157 in epoch 0, gen_loss = 1.7590229201920424, disc_loss = 0.08020632286685743
Trained batch 158 in epoch 0, gen_loss = 1.758270283914962, disc_loss = 0.07979368599448002
Trained batch 159 in epoch 0, gen_loss = 1.7589099727571011, disc_loss = 0.07938573080464266
Trained batch 160 in epoch 0, gen_loss = 1.7574855281699517, disc_loss = 0.07902708396847759
Trained batch 161 in epoch 0, gen_loss = 1.7573251878773724, disc_loss = 0.07863879837900584
Trained batch 162 in epoch 0, gen_loss = 1.7598234415054321, disc_loss = 0.07823405726212848
Trained batch 163 in epoch 0, gen_loss = 1.760801424340504, disc_loss = 0.0778275525663048
Trained batch 164 in epoch 0, gen_loss = 1.7623150883298933, disc_loss = 0.0774205685282747
Trained batch 165 in epoch 0, gen_loss = 1.7608741478747632, disc_loss = 0.0770363748657057
Trained batch 166 in epoch 0, gen_loss = 1.7623756488640152, disc_loss = 0.07671720458718831
Trained batch 167 in epoch 0, gen_loss = 1.7605910847584407, disc_loss = 0.07634471224377021
Trained batch 168 in epoch 0, gen_loss = 1.758941948766539, disc_loss = 0.07594765774001913
Trained batch 169 in epoch 0, gen_loss = 1.7582390231244704, disc_loss = 0.07557172536959543
Trained batch 170 in epoch 0, gen_loss = 1.757928572900114, disc_loss = 0.07518448958946773
Trained batch 171 in epoch 0, gen_loss = 1.7565104309902635, disc_loss = 0.07480561751114248
Trained batch 172 in epoch 0, gen_loss = 1.7569726106059345, disc_loss = 0.07445291570263964
Trained batch 173 in epoch 0, gen_loss = 1.7573647978662075, disc_loss = 0.07407969740037432
Trained batch 174 in epoch 0, gen_loss = 1.7580375957489014, disc_loss = 0.07371420112571546
Trained batch 175 in epoch 0, gen_loss = 1.7573365474289113, disc_loss = 0.07341988770481707
Trained batch 176 in epoch 0, gen_loss = 1.7568342678964475, disc_loss = 0.07307034801418162
Trained batch 177 in epoch 0, gen_loss = 1.7561876445673825, disc_loss = 0.0727646460631088
Trained batch 178 in epoch 0, gen_loss = 1.7576324320372256, disc_loss = 0.07241935618013642
Trained batch 179 in epoch 0, gen_loss = 1.7566321273644765, disc_loss = 0.07207644421917697
Trained batch 180 in epoch 0, gen_loss = 1.755831176404795, disc_loss = 0.07173803578856407
Trained batch 181 in epoch 0, gen_loss = 1.7550233248825913, disc_loss = 0.07138038053596904
Trained batch 182 in epoch 0, gen_loss = 1.752708467629438, disc_loss = 0.07108252933706904
Trained batch 183 in epoch 0, gen_loss = 1.7525241491587267, disc_loss = 0.07077058960946844
Trained batch 184 in epoch 0, gen_loss = 1.7503137034338874, disc_loss = 0.07044135470043969
Trained batch 185 in epoch 0, gen_loss = 1.7534797870984642, disc_loss = 0.07014713894015037
Trained batch 186 in epoch 0, gen_loss = 1.753176288171248, disc_loss = 0.06983374256421537
Trained batch 187 in epoch 0, gen_loss = 1.7523703974612215, disc_loss = 0.06951139811822708
Trained batch 188 in epoch 0, gen_loss = 1.753369857394506, disc_loss = 0.06918989374208703
Trained batch 189 in epoch 0, gen_loss = 1.7541749954223633, disc_loss = 0.06886762335504357
Trained batch 190 in epoch 0, gen_loss = 1.7540558745099613, disc_loss = 0.0685449192588125
Trained batch 191 in epoch 0, gen_loss = 1.7547260938833158, disc_loss = 0.06823519051007072
Trained batch 192 in epoch 0, gen_loss = 1.7527847932410363, disc_loss = 0.06794709305235527
Trained batch 193 in epoch 0, gen_loss = 1.7522491763547523, disc_loss = 0.06764714824775062
Trained batch 194 in epoch 0, gen_loss = 1.751612363106165, disc_loss = 0.06737464719619124
Trained batch 195 in epoch 0, gen_loss = 1.7509480733044294, disc_loss = 0.0671119152791608
Trained batch 196 in epoch 0, gen_loss = 1.749854890223082, disc_loss = 0.06681683449415007
Trained batch 197 in epoch 0, gen_loss = 1.751043520792566, disc_loss = 0.06654484209491673
Trained batch 198 in epoch 0, gen_loss = 1.7492779127916498, disc_loss = 0.06628100813399233
Trained batch 199 in epoch 0, gen_loss = 1.7495265662670136, disc_loss = 0.0660198232694529
Trained batch 200 in epoch 0, gen_loss = 1.750448462974966, disc_loss = 0.06577286557688271
Trained batch 201 in epoch 0, gen_loss = 1.7489881851885578, disc_loss = 0.06555037007501147
Trained batch 202 in epoch 0, gen_loss = 1.748781257075042, disc_loss = 0.06528790374263534
Trained batch 203 in epoch 0, gen_loss = 1.7485757879182404, disc_loss = 0.06503041073287308
Trained batch 204 in epoch 0, gen_loss = 1.7483039251187953, disc_loss = 0.06482611397826453
Trained batch 205 in epoch 0, gen_loss = 1.748493704981017, disc_loss = 0.06462732805798138
Trained batch 206 in epoch 0, gen_loss = 1.7491525866559163, disc_loss = 0.06438474707386416
Trained batch 207 in epoch 0, gen_loss = 1.749254733324051, disc_loss = 0.06413888978959921
Trained batch 208 in epoch 0, gen_loss = 1.748891504187333, disc_loss = 0.0638756753462389
Trained batch 209 in epoch 0, gen_loss = 1.7496624361901056, disc_loss = 0.06361426600875954
Trained batch 210 in epoch 0, gen_loss = 1.7507114031868523, disc_loss = 0.06335436029059556
Trained batch 211 in epoch 0, gen_loss = 1.7515397875938776, disc_loss = 0.06308811539037258
Trained batch 212 in epoch 0, gen_loss = 1.7513632354602007, disc_loss = 0.06282188978588357
Trained batch 213 in epoch 0, gen_loss = 1.751504243534302, disc_loss = 0.06255654520442204
Trained batch 214 in epoch 0, gen_loss = 1.7519896851029506, disc_loss = 0.06229712385900838
Trained batch 215 in epoch 0, gen_loss = 1.7519982722070482, disc_loss = 0.06204957673455485
Trained batch 216 in epoch 0, gen_loss = 1.7512048109335834, disc_loss = 0.06178709077927786
Trained batch 217 in epoch 0, gen_loss = 1.7512499859573645, disc_loss = 0.061536219003054934
Trained batch 218 in epoch 0, gen_loss = 1.7496295339984982, disc_loss = 0.06129038119348421
Trained batch 219 in epoch 0, gen_loss = 1.7497956454753876, disc_loss = 0.06105566715440628
Trained batch 220 in epoch 0, gen_loss = 1.751195228477409, disc_loss = 0.060813715986958054
Trained batch 221 in epoch 0, gen_loss = 1.7505285680831015, disc_loss = 0.060577787121187325
Trained batch 222 in epoch 0, gen_loss = 1.7513639841379072, disc_loss = 0.06033329224431127
Trained batch 223 in epoch 0, gen_loss = 1.75237043893763, disc_loss = 0.06009331566123625
Trained batch 224 in epoch 0, gen_loss = 1.7512333175871106, disc_loss = 0.05985694486233923
Trained batch 225 in epoch 0, gen_loss = 1.7503756622297575, disc_loss = 0.05963618215173483
Trained batch 226 in epoch 0, gen_loss = 1.7500430140726366, disc_loss = 0.05944040945694179
Trained batch 227 in epoch 0, gen_loss = 1.7504407303375111, disc_loss = 0.05922115888658976
Trained batch 228 in epoch 0, gen_loss = 1.7501222431399417, disc_loss = 0.059008073464328806
Trained batch 229 in epoch 0, gen_loss = 1.750015920141469, disc_loss = 0.05878550953272244
Trained batch 230 in epoch 0, gen_loss = 1.7495711262607987, disc_loss = 0.0585635384641491
Trained batch 231 in epoch 0, gen_loss = 1.7492523100869408, disc_loss = 0.05837216233465307
Trained batch 232 in epoch 0, gen_loss = 1.7496097584139123, disc_loss = 0.058168447020867355
Trained batch 233 in epoch 0, gen_loss = 1.748134857059544, disc_loss = 0.057949403356601537
Trained batch 234 in epoch 0, gen_loss = 1.7485350832026056, disc_loss = 0.057729320608555006
Trained batch 235 in epoch 0, gen_loss = 1.7478139117612677, disc_loss = 0.05752517709950522
Trained batch 236 in epoch 0, gen_loss = 1.746609093770699, disc_loss = 0.05733964984395584
Trained batch 237 in epoch 0, gen_loss = 1.7449873310177266, disc_loss = 0.057125717849556765
Trained batch 238 in epoch 0, gen_loss = 1.7450444259404139, disc_loss = 0.0569136040187811
Trained batch 239 in epoch 0, gen_loss = 1.743963142732779, disc_loss = 0.05670329800341278
Trained batch 240 in epoch 0, gen_loss = 1.7435439656878902, disc_loss = 0.05650493242542155
Trained batch 241 in epoch 0, gen_loss = 1.743481726193231, disc_loss = 0.056301110349056764
Trained batch 242 in epoch 0, gen_loss = 1.7427188427850542, disc_loss = 0.05610030583861004
Trained batch 243 in epoch 0, gen_loss = 1.7429154710691483, disc_loss = 0.05590160996233281
Trained batch 244 in epoch 0, gen_loss = 1.741597168786185, disc_loss = 0.055701137706637385
Trained batch 245 in epoch 0, gen_loss = 1.7410722602673663, disc_loss = 0.05549414781285677
Trained batch 246 in epoch 0, gen_loss = 1.7410709877245822, disc_loss = 0.055298318047649585
Trained batch 247 in epoch 0, gen_loss = 1.7408641956506237, disc_loss = 0.05511355645496458
Trained batch 248 in epoch 0, gen_loss = 1.7392378389595982, disc_loss = 0.05491128848701057
Trained batch 249 in epoch 0, gen_loss = 1.7396884832382202, disc_loss = 0.05473189526610076
Trained batch 250 in epoch 0, gen_loss = 1.7400626157859407, disc_loss = 0.05453591967981116
Trained batch 251 in epoch 0, gen_loss = 1.7404890798387074, disc_loss = 0.05434537618347104
Trained batch 252 in epoch 0, gen_loss = 1.7401117298442856, disc_loss = 0.05424678358046905
Trained batch 253 in epoch 0, gen_loss = 1.7405439619942913, disc_loss = 0.05405532986138339
Trained batch 254 in epoch 0, gen_loss = 1.741158714013941, disc_loss = 0.05389007400976969
Trained batch 255 in epoch 0, gen_loss = 1.7414099141024053, disc_loss = 0.05370353089165292
Trained batch 256 in epoch 0, gen_loss = 1.7406571964345554, disc_loss = 0.05352418615884992
Trained batch 257 in epoch 0, gen_loss = 1.7412204090939012, disc_loss = 0.05334388574246
Trained batch 258 in epoch 0, gen_loss = 1.7417270051006184, disc_loss = 0.05317163413289834
Trained batch 259 in epoch 0, gen_loss = 1.7417658411539518, disc_loss = 0.05298920090381916
Trained batch 260 in epoch 0, gen_loss = 1.7414233789590128, disc_loss = 0.05280635094669758
Trained batch 261 in epoch 0, gen_loss = 1.7424557122565407, disc_loss = 0.05263405147484923
Trained batch 262 in epoch 0, gen_loss = 1.7427541701965912, disc_loss = 0.052470150917145235
Trained batch 263 in epoch 0, gen_loss = 1.7430460556890026, disc_loss = 0.052317015061183185
Trained batch 264 in epoch 0, gen_loss = 1.7426817295686254, disc_loss = 0.05214329549410152
Trained batch 265 in epoch 0, gen_loss = 1.741896260501747, disc_loss = 0.0519857193304828
Trained batch 266 in epoch 0, gen_loss = 1.7416424108355233, disc_loss = 0.05183295192796918
Trained batch 267 in epoch 0, gen_loss = 1.740083306583006, disc_loss = 0.05166029732556207
Trained batch 268 in epoch 0, gen_loss = 1.7392128980735864, disc_loss = 0.05151759643197669
Trained batch 269 in epoch 0, gen_loss = 1.7380722730248064, disc_loss = 0.051548082614317536
Trained batch 270 in epoch 0, gen_loss = 1.7374480087378807, disc_loss = 0.051483221556578945
Trained batch 271 in epoch 0, gen_loss = 1.7359835330177755, disc_loss = 0.051352658430593744
Trained batch 272 in epoch 0, gen_loss = 1.7366166437938537, disc_loss = 0.05120141058307373
Trained batch 273 in epoch 0, gen_loss = 1.7362980685964988, disc_loss = 0.05105023474745235
Trained batch 274 in epoch 0, gen_loss = 1.7360139049183239, disc_loss = 0.05090189777822657
Trained batch 275 in epoch 0, gen_loss = 1.7356037912161455, disc_loss = 0.05074006591694079
Trained batch 276 in epoch 0, gen_loss = 1.7352468765169275, disc_loss = 0.05061720479750461
Trained batch 277 in epoch 0, gen_loss = 1.7360628453090037, disc_loss = 0.05046631126470274
Trained batch 278 in epoch 0, gen_loss = 1.7353906464833084, disc_loss = 0.05039636673252215
Trained batch 279 in epoch 0, gen_loss = 1.7361794390848704, disc_loss = 0.05024545414905463
Trained batch 280 in epoch 0, gen_loss = 1.7358980539430502, disc_loss = 0.05010235790176536
Trained batch 281 in epoch 0, gen_loss = 1.736107145218139, disc_loss = 0.049960408485263376
Trained batch 282 in epoch 0, gen_loss = 1.735599717908529, disc_loss = 0.0498235180197356
Trained batch 283 in epoch 0, gen_loss = 1.7348994062819951, disc_loss = 0.0496950790607436
Trained batch 284 in epoch 0, gen_loss = 1.7337149812464128, disc_loss = 0.04955307892605401
Trained batch 285 in epoch 0, gen_loss = 1.733806750574312, disc_loss = 0.04941737399456072
Trained batch 286 in epoch 0, gen_loss = 1.7341802070365135, disc_loss = 0.049273860160559936
Trained batch 287 in epoch 0, gen_loss = 1.734082651635011, disc_loss = 0.04912272414528868
Trained batch 288 in epoch 0, gen_loss = 1.7343824528492857, disc_loss = 0.0489758572019121
Trained batch 289 in epoch 0, gen_loss = 1.7347561104544278, disc_loss = 0.04883826475365666
Trained batch 290 in epoch 0, gen_loss = 1.7342316891319562, disc_loss = 0.04869834813241338
Trained batch 291 in epoch 0, gen_loss = 1.7339925516958106, disc_loss = 0.04855517093060308
Trained batch 292 in epoch 0, gen_loss = 1.734537911089614, disc_loss = 0.048407855710656776
Trained batch 293 in epoch 0, gen_loss = 1.7336976524112986, disc_loss = 0.04827012619966654
Trained batch 294 in epoch 0, gen_loss = 1.7334752434391087, disc_loss = 0.04813092462876338
Trained batch 295 in epoch 0, gen_loss = 1.7334118304220405, disc_loss = 0.04800150926835281
Trained batch 296 in epoch 0, gen_loss = 1.734053985839741, disc_loss = 0.047876612353844175
Trained batch 297 in epoch 0, gen_loss = 1.7346580148543287, disc_loss = 0.047745392659379035
Trained batch 298 in epoch 0, gen_loss = 1.734345312899969, disc_loss = 0.04760402161628008
Trained batch 299 in epoch 0, gen_loss = 1.7341670604546864, disc_loss = 0.04747203394460182
Trained batch 300 in epoch 0, gen_loss = 1.7332884627719258, disc_loss = 0.047335467762329254
Trained batch 301 in epoch 0, gen_loss = 1.7330674659337428, disc_loss = 0.047205146241760414
Trained batch 302 in epoch 0, gen_loss = 1.731948192363525, disc_loss = 0.04707588064530403
Trained batch 303 in epoch 0, gen_loss = 1.7312938798415034, disc_loss = 0.04694242633137803
Trained batch 304 in epoch 0, gen_loss = 1.73213957645854, disc_loss = 0.04680893404226078
Trained batch 305 in epoch 0, gen_loss = 1.7322779687401515, disc_loss = 0.046688682118162905
Trained batch 306 in epoch 0, gen_loss = 1.7323470255451017, disc_loss = 0.04656413956378444
Trained batch 307 in epoch 0, gen_loss = 1.7322648264370955, disc_loss = 0.04644021243552447
Trained batch 308 in epoch 0, gen_loss = 1.7326654384822908, disc_loss = 0.046309914941745765
Trained batch 309 in epoch 0, gen_loss = 1.7317875762139596, disc_loss = 0.04617856389903013
Trained batch 310 in epoch 0, gen_loss = 1.7315634914533118, disc_loss = 0.04604221443373147
Trained batch 311 in epoch 0, gen_loss = 1.7315668845788026, disc_loss = 0.04590732037859897
Trained batch 312 in epoch 0, gen_loss = 1.730443249876126, disc_loss = 0.04581868897427242
Trained batch 313 in epoch 0, gen_loss = 1.7301400087441607, disc_loss = 0.04573220316658781
Trained batch 314 in epoch 0, gen_loss = 1.730230702672686, disc_loss = 0.04560845702117871
Trained batch 315 in epoch 0, gen_loss = 1.730136351872094, disc_loss = 0.04548128511420675
Trained batch 316 in epoch 0, gen_loss = 1.7302613833725264, disc_loss = 0.04535890101052656
Trained batch 317 in epoch 0, gen_loss = 1.7307425325021804, disc_loss = 0.04523856971418754
Trained batch 318 in epoch 0, gen_loss = 1.7303658589300317, disc_loss = 0.04511799721549437
Trained batch 319 in epoch 0, gen_loss = 1.7293400414288045, disc_loss = 0.044993963684828484
Trained batch 320 in epoch 0, gen_loss = 1.7285451150014763, disc_loss = 0.044895387122645465
Trained batch 321 in epoch 0, gen_loss = 1.7292643781774533, disc_loss = 0.044785531398244434
Trained batch 322 in epoch 0, gen_loss = 1.7311258718325258, disc_loss = 0.044677635829249863
Trained batch 323 in epoch 0, gen_loss = 1.7309024941038202, disc_loss = 0.044560618276052455
Trained batch 324 in epoch 0, gen_loss = 1.7315505684339083, disc_loss = 0.04444223493767473
Trained batch 325 in epoch 0, gen_loss = 1.7307678355029756, disc_loss = 0.04433153746106828
Trained batch 326 in epoch 0, gen_loss = 1.7311543288216313, disc_loss = 0.044219747497571994
Trained batch 327 in epoch 0, gen_loss = 1.730952130585182, disc_loss = 0.04409764323059878
Trained batch 328 in epoch 0, gen_loss = 1.7298598611970804, disc_loss = 0.04397777568316795
Trained batch 329 in epoch 0, gen_loss = 1.7300497824495489, disc_loss = 0.04385827970691025
Trained batch 330 in epoch 0, gen_loss = 1.7301171456218847, disc_loss = 0.04373795723576335
Trained batch 331 in epoch 0, gen_loss = 1.7301842660070903, disc_loss = 0.043618895370142914
Trained batch 332 in epoch 0, gen_loss = 1.729489547354323, disc_loss = 0.043507640377279964
Trained batch 333 in epoch 0, gen_loss = 1.7292109809949727, disc_loss = 0.04339222047717762
Trained batch 334 in epoch 0, gen_loss = 1.7281307003391322, disc_loss = 0.04327191617131344
Trained batch 335 in epoch 0, gen_loss = 1.7275228663569404, disc_loss = 0.043162891887255854
Trained batch 336 in epoch 0, gen_loss = 1.7266197696283947, disc_loss = 0.04304422114738084
Trained batch 337 in epoch 0, gen_loss = 1.725602174299003, disc_loss = 0.0429419833641863
Trained batch 338 in epoch 0, gen_loss = 1.7264514015135863, disc_loss = 0.0428419497769304
Trained batch 339 in epoch 0, gen_loss = 1.7255787877475515, disc_loss = 0.04272753223708338
Trained batch 340 in epoch 0, gen_loss = 1.7254906854321879, disc_loss = 0.04262215856809573
Trained batch 341 in epoch 0, gen_loss = 1.7257104627570214, disc_loss = 0.042510511396501804
Trained batch 342 in epoch 0, gen_loss = 1.7247389638389166, disc_loss = 0.04239950834572554
Trained batch 343 in epoch 0, gen_loss = 1.7245527457359224, disc_loss = 0.04229935040618943
Trained batch 344 in epoch 0, gen_loss = 1.7243157072343689, disc_loss = 0.04218798373434423
Trained batch 345 in epoch 0, gen_loss = 1.7229958500476241, disc_loss = 0.04212963462381952
Trained batch 346 in epoch 0, gen_loss = 1.7221242045119447, disc_loss = 0.04207526971062683
Trained batch 347 in epoch 0, gen_loss = 1.722172893326858, disc_loss = 0.041975893572657956
Trained batch 348 in epoch 0, gen_loss = 1.7216069612940266, disc_loss = 0.04189230936091062
Trained batch 349 in epoch 0, gen_loss = 1.7219019852365767, disc_loss = 0.04181655521371535
Trained batch 350 in epoch 0, gen_loss = 1.7213943673674537, disc_loss = 0.041722477177566615
Trained batch 351 in epoch 0, gen_loss = 1.7215764945880934, disc_loss = 0.04162426883174868
Trained batch 352 in epoch 0, gen_loss = 1.722013462366531, disc_loss = 0.04153284609117268
Trained batch 353 in epoch 0, gen_loss = 1.721627955719576, disc_loss = 0.04143208594424492
Trained batch 354 in epoch 0, gen_loss = 1.721859619986843, disc_loss = 0.041335053878351
Trained batch 355 in epoch 0, gen_loss = 1.7211805602137962, disc_loss = 0.04125153075045582
Trained batch 356 in epoch 0, gen_loss = 1.7213778085067493, disc_loss = 0.04114771603557075
Trained batch 357 in epoch 0, gen_loss = 1.721399597615503, disc_loss = 0.041054384197581915
Trained batch 358 in epoch 0, gen_loss = 1.721985199325264, disc_loss = 0.04096452467672755
Trained batch 359 in epoch 0, gen_loss = 1.7211121552520328, disc_loss = 0.04086503342518376
Trained batch 360 in epoch 0, gen_loss = 1.7212194650126957, disc_loss = 0.04078018629195948
Trained batch 361 in epoch 0, gen_loss = 1.7213655028553958, disc_loss = 0.04070519202630658
Trained batch 362 in epoch 0, gen_loss = 1.7211501417738018, disc_loss = 0.040614527045972335
Trained batch 363 in epoch 0, gen_loss = 1.7212067406911116, disc_loss = 0.04052109347149771
Trained batch 364 in epoch 0, gen_loss = 1.7206926029022427, disc_loss = 0.040431076461729935
Trained batch 365 in epoch 0, gen_loss = 1.7204928766182863, disc_loss = 0.040330652080735836
Trained batch 366 in epoch 0, gen_loss = 1.72003357644302, disc_loss = 0.040231048204360034
Trained batch 367 in epoch 0, gen_loss = 1.7199086213241452, disc_loss = 0.040141512877712754
Trained batch 368 in epoch 0, gen_loss = 1.7198816150184568, disc_loss = 0.040042276499883796
Trained batch 369 in epoch 0, gen_loss = 1.7190030494251767, disc_loss = 0.039950467622838916
Trained batch 370 in epoch 0, gen_loss = 1.7190901233822187, disc_loss = 0.03985983819319212
Trained batch 371 in epoch 0, gen_loss = 1.7182665601853402, disc_loss = 0.03976438946268391
Trained batch 372 in epoch 0, gen_loss = 1.7184151244866623, disc_loss = 0.03966944769646563
Trained batch 373 in epoch 0, gen_loss = 1.7177272525063172, disc_loss = 0.03957286128154234
Trained batch 374 in epoch 0, gen_loss = 1.717763946533203, disc_loss = 0.03947613805904984
Trained batch 375 in epoch 0, gen_loss = 1.7174335883018819, disc_loss = 0.0393862728775043
Trained batch 376 in epoch 0, gen_loss = 1.7182668077534642, disc_loss = 0.03929800103821196
Trained batch 377 in epoch 0, gen_loss = 1.717590637938686, disc_loss = 0.039205216323444377
Trained batch 378 in epoch 0, gen_loss = 1.7179126673449312, disc_loss = 0.03911362827256676
Trained batch 379 in epoch 0, gen_loss = 1.7182523338418259, disc_loss = 0.03901955311394934
Trained batch 380 in epoch 0, gen_loss = 1.716978935119048, disc_loss = 0.03893612454806667
Trained batch 381 in epoch 0, gen_loss = 1.71651316750112, disc_loss = 0.03885525555279184
Trained batch 382 in epoch 0, gen_loss = 1.7162082951622906, disc_loss = 0.038765107464487844
Trained batch 383 in epoch 0, gen_loss = 1.7157603185623884, disc_loss = 0.03869051081528596
Trained batch 384 in epoch 0, gen_loss = 1.7154892723281663, disc_loss = 0.03860323052284876
Trained batch 385 in epoch 0, gen_loss = 1.7153930086545994, disc_loss = 0.038513886333935425
Trained batch 386 in epoch 0, gen_loss = 1.7149074197739593, disc_loss = 0.0384337117862996
Trained batch 387 in epoch 0, gen_loss = 1.7145878294694055, disc_loss = 0.038354177027340675
Trained batch 388 in epoch 0, gen_loss = 1.7145187012027652, disc_loss = 0.03826425825772391
Trained batch 389 in epoch 0, gen_loss = 1.7140754562157852, disc_loss = 0.03817937296445076
Trained batch 390 in epoch 0, gen_loss = 1.7144829577497205, disc_loss = 0.03809682532008785
Trained batch 391 in epoch 0, gen_loss = 1.7141491956248576, disc_loss = 0.03801210584981386
Trained batch 392 in epoch 0, gen_loss = 1.714345049008765, disc_loss = 0.03792772806159508
Trained batch 393 in epoch 0, gen_loss = 1.715110947335432, disc_loss = 0.037841445086216605
Trained batch 394 in epoch 0, gen_loss = 1.7149561163745348, disc_loss = 0.03775514942782495
Trained batch 395 in epoch 0, gen_loss = 1.7150116105272313, disc_loss = 0.037669733130829317
Trained batch 396 in epoch 0, gen_loss = 1.7160811790591224, disc_loss = 0.03758408376121288
Trained batch 397 in epoch 0, gen_loss = 1.716811707870445, disc_loss = 0.03749910128377752
Trained batch 398 in epoch 0, gen_loss = 1.7177104633254814, disc_loss = 0.037412613491413366
Trained batch 399 in epoch 0, gen_loss = 1.7175113353133202, disc_loss = 0.037333962880074976
Trained batch 400 in epoch 0, gen_loss = 1.7176945857573627, disc_loss = 0.03724934655866421
Trained batch 401 in epoch 0, gen_loss = 1.7171609057715875, disc_loss = 0.03717355764660966
Trained batch 402 in epoch 0, gen_loss = 1.7176208732737501, disc_loss = 0.037093996192807004
Trained batch 403 in epoch 0, gen_loss = 1.7179285196384582, disc_loss = 0.037014406598588026
Trained batch 404 in epoch 0, gen_loss = 1.7179296343414872, disc_loss = 0.036933816635958204
Trained batch 405 in epoch 0, gen_loss = 1.717362368635356, disc_loss = 0.03685331196189294
Trained batch 406 in epoch 0, gen_loss = 1.7164077562547726, disc_loss = 0.03679303225605801
Trained batch 407 in epoch 0, gen_loss = 1.7167152777022006, disc_loss = 0.03672367144905615
Trained batch 408 in epoch 0, gen_loss = 1.7165626112581174, disc_loss = 0.03664330042577588
Trained batch 409 in epoch 0, gen_loss = 1.7161699972501616, disc_loss = 0.036569958858805277
Trained batch 410 in epoch 0, gen_loss = 1.7166549817198964, disc_loss = 0.03649249987126104
Trained batch 411 in epoch 0, gen_loss = 1.7169083906608877, disc_loss = 0.0364101322862835
Trained batch 412 in epoch 0, gen_loss = 1.7170022679876185, disc_loss = 0.03633186108710077
Trained batch 413 in epoch 0, gen_loss = 1.717373384081799, disc_loss = 0.03625328836800611
Trained batch 414 in epoch 0, gen_loss = 1.7167835301663503, disc_loss = 0.03618123959974352
Trained batch 415 in epoch 0, gen_loss = 1.7168787835309138, disc_loss = 0.03611466117973368
Trained batch 416 in epoch 0, gen_loss = 1.7169636350741488, disc_loss = 0.036037228930053664
Trained batch 417 in epoch 0, gen_loss = 1.7163708158657311, disc_loss = 0.03597052093220955
Trained batch 418 in epoch 0, gen_loss = 1.7165403360398686, disc_loss = 0.035905324344952236
Trained batch 419 in epoch 0, gen_loss = 1.7168475026176089, disc_loss = 0.03583904517637122
Trained batch 420 in epoch 0, gen_loss = 1.7162726160466246, disc_loss = 0.03576709314375549
Trained batch 421 in epoch 0, gen_loss = 1.7165708725486322, disc_loss = 0.03569672704493335
Trained batch 422 in epoch 0, gen_loss = 1.7169682424400996, disc_loss = 0.03562729116132919
Trained batch 423 in epoch 0, gen_loss = 1.717318592487641, disc_loss = 0.03555546084831838
Trained batch 424 in epoch 0, gen_loss = 1.7170383125192978, disc_loss = 0.03548314107691541
Trained batch 425 in epoch 0, gen_loss = 1.7170621968211142, disc_loss = 0.035424193789299244
Trained batch 426 in epoch 0, gen_loss = 1.7171019430182857, disc_loss = 0.035367315194506276
Trained batch 427 in epoch 0, gen_loss = 1.717369070955526, disc_loss = 0.035298053867174925
Trained batch 428 in epoch 0, gen_loss = 1.7174117506800832, disc_loss = 0.03523271950938693
Trained batch 429 in epoch 0, gen_loss = 1.7175925024720125, disc_loss = 0.03516624811820166
Trained batch 430 in epoch 0, gen_loss = 1.7181737016359226, disc_loss = 0.03510310972139689
Trained batch 431 in epoch 0, gen_loss = 1.718180764052603, disc_loss = 0.03503880522610551
Trained batch 432 in epoch 0, gen_loss = 1.7174645395256907, disc_loss = 0.034967690590106584
Trained batch 433 in epoch 0, gen_loss = 1.7167752722990677, disc_loss = 0.03489590231822761
Trained batch 434 in epoch 0, gen_loss = 1.7166559087819067, disc_loss = 0.03482679930547702
Trained batch 435 in epoch 0, gen_loss = 1.7166797401161369, disc_loss = 0.03475288957690632
Trained batch 436 in epoch 0, gen_loss = 1.7163472901219907, disc_loss = 0.03468166303967959
Trained batch 437 in epoch 0, gen_loss = 1.716190179733381, disc_loss = 0.03461395297093172
Trained batch 438 in epoch 0, gen_loss = 1.7161059982412767, disc_loss = 0.03454497746448616
Trained batch 439 in epoch 0, gen_loss = 1.7155634804205462, disc_loss = 0.03447364534050311
Trained batch 440 in epoch 0, gen_loss = 1.7153977644957112, disc_loss = 0.03440336944628296
Trained batch 441 in epoch 0, gen_loss = 1.7149061409596404, disc_loss = 0.03433462574117189
Trained batch 442 in epoch 0, gen_loss = 1.714660998929973, disc_loss = 0.03426278141878007
Trained batch 443 in epoch 0, gen_loss = 1.7139966654347945, disc_loss = 0.03418997621115482
Trained batch 444 in epoch 0, gen_loss = 1.713414715649037, disc_loss = 0.0341197989436306
Trained batch 445 in epoch 0, gen_loss = 1.7128156145591906, disc_loss = 0.03406433778399426
Trained batch 446 in epoch 0, gen_loss = 1.7124229106860407, disc_loss = 0.03400113848371377
Trained batch 447 in epoch 0, gen_loss = 1.7125654939029897, disc_loss = 0.033932715317600275
Trained batch 448 in epoch 0, gen_loss = 1.7121916743854106, disc_loss = 0.03386435159928018
Trained batch 449 in epoch 0, gen_loss = 1.7120135058297052, disc_loss = 0.033794334741930165
Trained batch 450 in epoch 0, gen_loss = 1.7118059764151563, disc_loss = 0.033728872532202574
Trained batch 451 in epoch 0, gen_loss = 1.712314549800569, disc_loss = 0.03366086541765691
Trained batch 452 in epoch 0, gen_loss = 1.7118530447119908, disc_loss = 0.033596364519133275
Trained batch 453 in epoch 0, gen_loss = 1.7112241715586658, disc_loss = 0.033529721426117
Trained batch 454 in epoch 0, gen_loss = 1.7108955137022248, disc_loss = 0.033462589842031945
Trained batch 455 in epoch 0, gen_loss = 1.7104518842278866, disc_loss = 0.03339407503300575
Trained batch 456 in epoch 0, gen_loss = 1.7103518422375101, disc_loss = 0.03332725371727292
Trained batch 457 in epoch 0, gen_loss = 1.7102613844725763, disc_loss = 0.03326054979024219
Trained batch 458 in epoch 0, gen_loss = 1.7103198013534213, disc_loss = 0.03319636124596081
Trained batch 459 in epoch 0, gen_loss = 1.7097696648991627, disc_loss = 0.03313354151677745
Trained batch 460 in epoch 0, gen_loss = 1.709906210609734, disc_loss = 0.03306979275361075
Trained batch 461 in epoch 0, gen_loss = 1.7097203434803785, disc_loss = 0.033003931800084936
Trained batch 462 in epoch 0, gen_loss = 1.7092053941722565, disc_loss = 0.032937395002705004
Trained batch 463 in epoch 0, gen_loss = 1.7096634173187717, disc_loss = 0.032874583014776804
Trained batch 464 in epoch 0, gen_loss = 1.7107341217738326, disc_loss = 0.03281252813094886
Trained batch 465 in epoch 0, gen_loss = 1.7108119183855508, disc_loss = 0.032750417558824074
Trained batch 466 in epoch 0, gen_loss = 1.7103682268865614, disc_loss = 0.03268518826248208
Trained batch 467 in epoch 0, gen_loss = 1.7095161722256587, disc_loss = 0.032621794427510224
Trained batch 468 in epoch 0, gen_loss = 1.7093138303329696, disc_loss = 0.03256079841550114
Trained batch 469 in epoch 0, gen_loss = 1.7092686077381702, disc_loss = 0.03249876324701658
Trained batch 470 in epoch 0, gen_loss = 1.7083849269113722, disc_loss = 0.03243777160819485
Trained batch 471 in epoch 0, gen_loss = 1.7079287454233332, disc_loss = 0.03237685712224062
Trained batch 472 in epoch 0, gen_loss = 1.7081427032297307, disc_loss = 0.03231551547448129
Trained batch 473 in epoch 0, gen_loss = 1.7078481210937984, disc_loss = 0.032251889684300414
Trained batch 474 in epoch 0, gen_loss = 1.7080420278248034, disc_loss = 0.03219081752100273
Trained batch 475 in epoch 0, gen_loss = 1.7084336516236056, disc_loss = 0.032130709077435066
Trained batch 476 in epoch 0, gen_loss = 1.7073929584751089, disc_loss = 0.03207834107914561
Trained batch 477 in epoch 0, gen_loss = 1.7080248160342293, disc_loss = 0.032023105026070794
Trained batch 478 in epoch 0, gen_loss = 1.7079778563752304, disc_loss = 0.03196442656176231
Trained batch 479 in epoch 0, gen_loss = 1.708283783495426, disc_loss = 0.03190615266309275
Trained batch 480 in epoch 0, gen_loss = 1.7080884723306446, disc_loss = 0.03184532528363648
Trained batch 481 in epoch 0, gen_loss = 1.7073131975296623, disc_loss = 0.031784161777502214
Trained batch 482 in epoch 0, gen_loss = 1.7073724272335045, disc_loss = 0.031725362185716595
Trained batch 483 in epoch 0, gen_loss = 1.7068737865972126, disc_loss = 0.03166624248145179
Trained batch 484 in epoch 0, gen_loss = 1.7067927289254887, disc_loss = 0.03160518288045891
Trained batch 485 in epoch 0, gen_loss = 1.7068716368557495, disc_loss = 0.03154508735737361
Trained batch 486 in epoch 0, gen_loss = 1.706715601180858, disc_loss = 0.031488978713693466
Trained batch 487 in epoch 0, gen_loss = 1.7065247385228266, disc_loss = 0.03142996937261711
Trained batch 488 in epoch 0, gen_loss = 1.706888626445778, disc_loss = 0.03137616631203542
Trained batch 489 in epoch 0, gen_loss = 1.706342976190606, disc_loss = 0.031320690753280506
Trained batch 490 in epoch 0, gen_loss = 1.706436881951062, disc_loss = 0.03126339944384901
Trained batch 491 in epoch 0, gen_loss = 1.705974293675849, disc_loss = 0.031208089277871345
Trained batch 492 in epoch 0, gen_loss = 1.7054890715809914, disc_loss = 0.031150488888950636
Trained batch 493 in epoch 0, gen_loss = 1.7052516860035267, disc_loss = 0.03110457551222566
Trained batch 494 in epoch 0, gen_loss = 1.7046343451798565, disc_loss = 0.031070126793958774
Trained batch 495 in epoch 0, gen_loss = 1.704390771927372, disc_loss = 0.031031148661690343
Trained batch 496 in epoch 0, gen_loss = 1.7036863822092712, disc_loss = 0.031001317020134637
Trained batch 497 in epoch 0, gen_loss = 1.7043028931062385, disc_loss = 0.030960406666251283
Trained batch 498 in epoch 0, gen_loss = 1.70467426447209, disc_loss = 0.03090670206285416
Trained batch 499 in epoch 0, gen_loss = 1.7048603677749634, disc_loss = 0.030850733356084674
Trained batch 500 in epoch 0, gen_loss = 1.7043906209949486, disc_loss = 0.030795170706668925
Trained batch 501 in epoch 0, gen_loss = 1.703846744807118, disc_loss = 0.030741850969351947
Trained batch 502 in epoch 0, gen_loss = 1.703565051731011, disc_loss = 0.030685646412708975
Trained batch 503 in epoch 0, gen_loss = 1.7037785240109005, disc_loss = 0.030632886503885928
Trained batch 504 in epoch 0, gen_loss = 1.7040567910317148, disc_loss = 0.030576603561363155
Trained batch 505 in epoch 0, gen_loss = 1.7037812655151126, disc_loss = 0.030519811484848586
Trained batch 506 in epoch 0, gen_loss = 1.70372562178023, disc_loss = 0.030465215835371283
Trained batch 507 in epoch 0, gen_loss = 1.703294660397402, disc_loss = 0.030409712789902888
Trained batch 508 in epoch 0, gen_loss = 1.7041146921502583, disc_loss = 0.03035970842410867
Trained batch 509 in epoch 0, gen_loss = 1.7042081463570689, disc_loss = 0.030305276436767743
Trained batch 510 in epoch 0, gen_loss = 1.7041597790914038, disc_loss = 0.03025193359710116
Trained batch 511 in epoch 0, gen_loss = 1.7040276173502207, disc_loss = 0.030201228670193814
Trained batch 512 in epoch 0, gen_loss = 1.7035041520005314, disc_loss = 0.030155141344094253
Trained batch 513 in epoch 0, gen_loss = 1.7032302682965645, disc_loss = 0.03010304431215378
Trained batch 514 in epoch 0, gen_loss = 1.7036355370456733, disc_loss = 0.0300494761662829
Trained batch 515 in epoch 0, gen_loss = 1.704336558663568, disc_loss = 0.029997431785012633
Trained batch 516 in epoch 0, gen_loss = 1.7044296451417345, disc_loss = 0.029943512327522327
Trained batch 517 in epoch 0, gen_loss = 1.704263267599938, disc_loss = 0.029891314943281493
Trained batch 518 in epoch 0, gen_loss = 1.704290084296798, disc_loss = 0.02984101060815586
Trained batch 519 in epoch 0, gen_loss = 1.7043712969009692, disc_loss = 0.02979036704950536
Trained batch 520 in epoch 0, gen_loss = 1.7036145662391942, disc_loss = 0.029736947734355784
Trained batch 521 in epoch 0, gen_loss = 1.703357924446749, disc_loss = 0.029686725267094927
Trained batch 522 in epoch 0, gen_loss = 1.703107491733923, disc_loss = 0.029635517788965463
Trained batch 523 in epoch 0, gen_loss = 1.7029860754504458, disc_loss = 0.029583284830877146
Trained batch 524 in epoch 0, gen_loss = 1.7028986099788121, disc_loss = 0.02953211974529993
Trained batch 525 in epoch 0, gen_loss = 1.7027822431502686, disc_loss = 0.029483608472136207
Trained batch 526 in epoch 0, gen_loss = 1.7026584094118122, disc_loss = 0.029439741279929876
Trained batch 527 in epoch 0, gen_loss = 1.7033342777779608, disc_loss = 0.029391038196274276
Trained batch 528 in epoch 0, gen_loss = 1.7028822281410203, disc_loss = 0.02934064657606945
Trained batch 529 in epoch 0, gen_loss = 1.7032294372342667, disc_loss = 0.029290184966850815
Trained batch 530 in epoch 0, gen_loss = 1.7029811078770236, disc_loss = 0.029242169421092517
Trained batch 531 in epoch 0, gen_loss = 1.7029486305283426, disc_loss = 0.029195624489872892
Trained batch 532 in epoch 0, gen_loss = 1.7025284205771298, disc_loss = 0.02914694514943332
Trained batch 533 in epoch 0, gen_loss = 1.7028857078891568, disc_loss = 0.029099050451031703
Trained batch 534 in epoch 0, gen_loss = 1.7023360499711795, disc_loss = 0.02905200705776496
Trained batch 535 in epoch 0, gen_loss = 1.7017896704709352, disc_loss = 0.02900324314754498
Trained batch 536 in epoch 0, gen_loss = 1.7014064380354499, disc_loss = 0.028954076591542675
Trained batch 537 in epoch 0, gen_loss = 1.7016697366441493, disc_loss = 0.028905116213783343
Trained batch 538 in epoch 0, gen_loss = 1.7018730567426097, disc_loss = 0.02885552954424608
Trained batch 539 in epoch 0, gen_loss = 1.7015030033058591, disc_loss = 0.028807968572127047
Trained batch 540 in epoch 0, gen_loss = 1.7009632380303967, disc_loss = 0.028758560791060796
Trained batch 541 in epoch 0, gen_loss = 1.7017118411750372, disc_loss = 0.028709067933852493
Trained batch 542 in epoch 0, gen_loss = 1.7015143365052083, disc_loss = 0.028661513781264206
Trained batch 543 in epoch 0, gen_loss = 1.701535487876219, disc_loss = 0.02861375442444114
Trained batch 544 in epoch 0, gen_loss = 1.7017489625773299, disc_loss = 0.028564297978407403
Trained batch 545 in epoch 0, gen_loss = 1.701706668396136, disc_loss = 0.028516248741652817
Trained batch 546 in epoch 0, gen_loss = 1.701386367163231, disc_loss = 0.028469840423255083
Trained batch 547 in epoch 0, gen_loss = 1.7012350861608547, disc_loss = 0.028424664037888462
Trained batch 548 in epoch 0, gen_loss = 1.7013239782364642, disc_loss = 0.02838047269586718
Trained batch 549 in epoch 0, gen_loss = 1.7010098656741055, disc_loss = 0.028332028015178035
Trained batch 550 in epoch 0, gen_loss = 1.7003653752609087, disc_loss = 0.028285744116166623
Trained batch 551 in epoch 0, gen_loss = 1.7000115917644638, disc_loss = 0.028241936926834584
Trained batch 552 in epoch 0, gen_loss = 1.6996704003694476, disc_loss = 0.0282041927674115
Trained batch 553 in epoch 0, gen_loss = 1.700026388417943, disc_loss = 0.028158040464240454
Trained batch 554 in epoch 0, gen_loss = 1.699547274477847, disc_loss = 0.028111504257430097
Trained batch 555 in epoch 0, gen_loss = 1.7004647666601826, disc_loss = 0.02806530471073745
Trained batch 556 in epoch 0, gen_loss = 1.700322112018373, disc_loss = 0.028019622011742216
Trained batch 557 in epoch 0, gen_loss = 1.7005657220399508, disc_loss = 0.027972484134115932
Trained batch 558 in epoch 0, gen_loss = 1.6998174994490867, disc_loss = 0.02792962244899247
Trained batch 559 in epoch 0, gen_loss = 1.6995048491018159, disc_loss = 0.027886369537736756
Trained batch 560 in epoch 0, gen_loss = 1.6997390698621617, disc_loss = 0.027841406920219237
Trained batch 561 in epoch 0, gen_loss = 1.6992559770248115, disc_loss = 0.027795639071568807
Trained batch 562 in epoch 0, gen_loss = 1.6996597134198854, disc_loss = 0.027750871164292482
Trained batch 563 in epoch 0, gen_loss = 1.699621432639183, disc_loss = 0.02771022342453407
Trained batch 564 in epoch 0, gen_loss = 1.6989534719855384, disc_loss = 0.027669374303752145
Trained batch 565 in epoch 0, gen_loss = 1.6985082548414439, disc_loss = 0.027628354592678258
Trained batch 566 in epoch 0, gen_loss = 1.6983433305901825, disc_loss = 0.02758621805280979
Trained batch 567 in epoch 0, gen_loss = 1.698288307853148, disc_loss = 0.02754359400661459
Trained batch 568 in epoch 0, gen_loss = 1.6984937689635373, disc_loss = 0.027501729146171498
Trained batch 569 in epoch 0, gen_loss = 1.6987484279431795, disc_loss = 0.027457644432791296
Trained batch 570 in epoch 0, gen_loss = 1.6985075035362445, disc_loss = 0.027413052741002662
Trained batch 571 in epoch 0, gen_loss = 1.6982339537227071, disc_loss = 0.027369486401875184
Trained batch 572 in epoch 0, gen_loss = 1.6977272094024205, disc_loss = 0.027326117072824917
Trained batch 573 in epoch 0, gen_loss = 1.697465006275044, disc_loss = 0.02728194086662354
Trained batch 574 in epoch 0, gen_loss = 1.697464739136074, disc_loss = 0.02723736427947069
Trained batch 575 in epoch 0, gen_loss = 1.6973135945283704, disc_loss = 0.027192985807131562
Trained batch 576 in epoch 0, gen_loss = 1.6973807299364378, disc_loss = 0.02714964554344903
Trained batch 577 in epoch 0, gen_loss = 1.6971377575686233, disc_loss = 0.027107635931479246
Trained batch 578 in epoch 0, gen_loss = 1.6978999353649291, disc_loss = 0.027063966369246725
Trained batch 579 in epoch 0, gen_loss = 1.6977931959875698, disc_loss = 0.027020638259850314
Trained batch 580 in epoch 0, gen_loss = 1.697190340948187, disc_loss = 0.026976703500043338
Trained batch 581 in epoch 0, gen_loss = 1.6969240158284242, disc_loss = 0.02693404795748383
Trained batch 582 in epoch 0, gen_loss = 1.6969662379237023, disc_loss = 0.02689265474572452
Trained batch 583 in epoch 0, gen_loss = 1.6966890200768432, disc_loss = 0.02685033378716756
Trained batch 584 in epoch 0, gen_loss = 1.6964748957218267, disc_loss = 0.026811243183552647
Trained batch 585 in epoch 0, gen_loss = 1.6968859480916436, disc_loss = 0.02677106382877569
Trained batch 586 in epoch 0, gen_loss = 1.6966593783393222, disc_loss = 0.02673067662883169
Trained batch 587 in epoch 0, gen_loss = 1.6960193022173278, disc_loss = 0.026689537784019737
Trained batch 588 in epoch 0, gen_loss = 1.6958624436211707, disc_loss = 0.026647726170511532
Trained batch 589 in epoch 0, gen_loss = 1.695463934591261, disc_loss = 0.02660831005640044
Trained batch 590 in epoch 0, gen_loss = 1.6951590108790777, disc_loss = 0.026568527709867635
Trained batch 591 in epoch 0, gen_loss = 1.6950977108365781, disc_loss = 0.02652811481105321
Trained batch 592 in epoch 0, gen_loss = 1.695211841927411, disc_loss = 0.026486906941711564
Trained batch 593 in epoch 0, gen_loss = 1.6949704937661938, disc_loss = 0.02644611942532444
Trained batch 594 in epoch 0, gen_loss = 1.6949367090433585, disc_loss = 0.02640507440806656
Trained batch 595 in epoch 0, gen_loss = 1.6948440938987988, disc_loss = 0.02636432086548068
Trained batch 596 in epoch 0, gen_loss = 1.694680413009733, disc_loss = 0.02632301011383284
Trained batch 597 in epoch 0, gen_loss = 1.6953144785153826, disc_loss = 0.026284847032422058
Trained batch 598 in epoch 0, gen_loss = 1.6952817987321016, disc_loss = 0.026243997757394607
Trained batch 599 in epoch 0, gen_loss = 1.6947523178656896, disc_loss = 0.02620478561516696
Trained batch 600 in epoch 0, gen_loss = 1.6953175720478255, disc_loss = 0.026166385531498308
Trained batch 601 in epoch 0, gen_loss = 1.6949899665937076, disc_loss = 0.026129873763991094
Trained batch 602 in epoch 0, gen_loss = 1.694729116030198, disc_loss = 0.02609070728376205
Trained batch 603 in epoch 0, gen_loss = 1.6940975769466122, disc_loss = 0.02605255628417135
Trained batch 604 in epoch 0, gen_loss = 1.6938915106875838, disc_loss = 0.026016703503368006
Trained batch 605 in epoch 0, gen_loss = 1.6938726719063106, disc_loss = 0.02598066281249882
Trained batch 606 in epoch 0, gen_loss = 1.6933580621266875, disc_loss = 0.02594340356435823
Trained batch 607 in epoch 0, gen_loss = 1.6928415880783607, disc_loss = 0.02590447286236572
Trained batch 608 in epoch 0, gen_loss = 1.6928060865167327, disc_loss = 0.025864495726054527
Trained batch 609 in epoch 0, gen_loss = 1.6929810101868676, disc_loss = 0.025827245636018695
Trained batch 610 in epoch 0, gen_loss = 1.6925515714916972, disc_loss = 0.025790543480640592
Trained batch 611 in epoch 0, gen_loss = 1.692629307703255, disc_loss = 0.025753924158992234
Trained batch 612 in epoch 0, gen_loss = 1.6925868437690796, disc_loss = 0.025715478085935554
Trained batch 613 in epoch 0, gen_loss = 1.6923266552170246, disc_loss = 0.025678499244192937
Trained batch 614 in epoch 0, gen_loss = 1.6920318130555192, disc_loss = 0.02564197179626643
Trained batch 615 in epoch 0, gen_loss = 1.6920141169390122, disc_loss = 0.02560505021345354
Trained batch 616 in epoch 0, gen_loss = 1.6923164283823542, disc_loss = 0.025566155403570198
Trained batch 617 in epoch 0, gen_loss = 1.6924792964095823, disc_loss = 0.025527188655751543
Trained batch 618 in epoch 0, gen_loss = 1.692267817326239, disc_loss = 0.025488341971554813
Trained batch 619 in epoch 0, gen_loss = 1.6925515495961712, disc_loss = 0.025449854748759177
Trained batch 620 in epoch 0, gen_loss = 1.6925358993035775, disc_loss = 0.02541106839078642
Trained batch 621 in epoch 0, gen_loss = 1.6925826028612265, disc_loss = 0.025372671815372068
Trained batch 622 in epoch 0, gen_loss = 1.6927713174881178, disc_loss = 0.02533400063361841
Trained batch 623 in epoch 0, gen_loss = 1.6923466857809286, disc_loss = 0.025299934306717776
Trained batch 624 in epoch 0, gen_loss = 1.6925361028671264, disc_loss = 0.02526319582555443
Trained batch 625 in epoch 0, gen_loss = 1.6925498660380087, disc_loss = 0.025230851341462947
Trained batch 626 in epoch 0, gen_loss = 1.6923432036450035, disc_loss = 0.025197411952146656
Trained batch 627 in epoch 0, gen_loss = 1.6928504316290474, disc_loss = 0.025161321143134775
Trained batch 628 in epoch 0, gen_loss = 1.692354093674446, disc_loss = 0.025125452995985828
Trained batch 629 in epoch 0, gen_loss = 1.6922566165999762, disc_loss = 0.025089150223518826
Trained batch 630 in epoch 0, gen_loss = 1.6920881057881327, disc_loss = 0.02505319412644929
Trained batch 631 in epoch 0, gen_loss = 1.691737820641904, disc_loss = 0.0250199555290076
Trained batch 632 in epoch 0, gen_loss = 1.692264560086279, disc_loss = 0.0249830618481215
Trained batch 633 in epoch 0, gen_loss = 1.6919119999235737, disc_loss = 0.024946237496160595
Trained batch 634 in epoch 0, gen_loss = 1.6917136877540528, disc_loss = 0.02491082744727894
Trained batch 635 in epoch 0, gen_loss = 1.6912501943561267, disc_loss = 0.024876574056373862
Trained batch 636 in epoch 0, gen_loss = 1.690664294188962, disc_loss = 0.024840607812074034
Trained batch 637 in epoch 0, gen_loss = 1.6905043384871887, disc_loss = 0.02480408351566952
Trained batch 638 in epoch 0, gen_loss = 1.6904012804300013, disc_loss = 0.024767987480378346
Trained batch 639 in epoch 0, gen_loss = 1.6903211364522577, disc_loss = 0.02473216704602237
Trained batch 640 in epoch 0, gen_loss = 1.690432972357537, disc_loss = 0.024696872183143533
Trained batch 641 in epoch 0, gen_loss = 1.6902703026373438, disc_loss = 0.024660896487037922
Trained batch 642 in epoch 0, gen_loss = 1.6902404011315544, disc_loss = 0.024626424994166146
Trained batch 643 in epoch 0, gen_loss = 1.6896687995943223, disc_loss = 0.02459090056786493
Trained batch 644 in epoch 0, gen_loss = 1.6895667070566223, disc_loss = 0.024554959622341707
Trained batch 645 in epoch 0, gen_loss = 1.6892923136982756, disc_loss = 0.024519183602863086
Trained batch 646 in epoch 0, gen_loss = 1.6895390220182203, disc_loss = 0.02448586897454563
Trained batch 647 in epoch 0, gen_loss = 1.6890496760606766, disc_loss = 0.02445084542031745
Trained batch 648 in epoch 0, gen_loss = 1.688497708464624, disc_loss = 0.02453165438394988
Trained batch 649 in epoch 0, gen_loss = 1.6879964151749245, disc_loss = 0.024914300902030215
Trained batch 650 in epoch 0, gen_loss = 1.687613833152021, disc_loss = 0.024940571399010753
Trained batch 651 in epoch 0, gen_loss = 1.6875611980634233, disc_loss = 0.024966045450262063
Trained batch 652 in epoch 0, gen_loss = 1.6877234538883017, disc_loss = 0.024960538066116377
Trained batch 653 in epoch 0, gen_loss = 1.68693975680465, disc_loss = 0.024955128218810605
Trained batch 654 in epoch 0, gen_loss = 1.6873747144946616, disc_loss = 0.02496476864890117
Trained batch 655 in epoch 0, gen_loss = 1.6870886727077206, disc_loss = 0.024949780549277642
Trained batch 656 in epoch 0, gen_loss = 1.6867972420049404, disc_loss = 0.024924476625669968
Trained batch 657 in epoch 0, gen_loss = 1.6866783506964478, disc_loss = 0.024898486740187964
Trained batch 658 in epoch 0, gen_loss = 1.686485152866844, disc_loss = 0.024875319536354207
Trained batch 659 in epoch 0, gen_loss = 1.6863796792247079, disc_loss = 0.02485765528082001
Trained batch 660 in epoch 0, gen_loss = 1.685765095629959, disc_loss = 0.02483373466610018
Trained batch 661 in epoch 0, gen_loss = 1.685932419091193, disc_loss = 0.024820618099656824
Trained batch 662 in epoch 0, gen_loss = 1.6859102170032254, disc_loss = 0.024831488041971356
Trained batch 663 in epoch 0, gen_loss = 1.6856211653674942, disc_loss = 0.024806102224785544
Trained batch 664 in epoch 0, gen_loss = 1.6857866864455373, disc_loss = 0.024785172838815733
Trained batch 665 in epoch 0, gen_loss = 1.685502330104152, disc_loss = 0.024768461935101887
Trained batch 666 in epoch 0, gen_loss = 1.6854936518947938, disc_loss = 0.02474413918592371
Trained batch 667 in epoch 0, gen_loss = 1.6858065087281302, disc_loss = 0.024713829021362734
Trained batch 668 in epoch 0, gen_loss = 1.6855285322719624, disc_loss = 0.024683874721676446
Trained batch 669 in epoch 0, gen_loss = 1.685355174363549, disc_loss = 0.02465976946674454
Trained batch 670 in epoch 0, gen_loss = 1.6854114434758172, disc_loss = 0.024638200988271308
Trained batch 671 in epoch 0, gen_loss = 1.6850983956385226, disc_loss = 0.0246078168486184
Trained batch 672 in epoch 0, gen_loss = 1.6848818026538412, disc_loss = 0.02458327640723963
Trained batch 673 in epoch 0, gen_loss = 1.6844679686718949, disc_loss = 0.024555341531633114
Trained batch 674 in epoch 0, gen_loss = 1.6844361633724636, disc_loss = 0.02453130637364531
Trained batch 675 in epoch 0, gen_loss = 1.6843316794852534, disc_loss = 0.024499110204164908
Trained batch 676 in epoch 0, gen_loss = 1.684319028121858, disc_loss = 0.02447745684799814
Trained batch 677 in epoch 0, gen_loss = 1.6843077225671053, disc_loss = 0.02445089217765768
Trained batch 678 in epoch 0, gen_loss = 1.684469983398651, disc_loss = 0.024421063830955325
Trained batch 679 in epoch 0, gen_loss = 1.6846347600221634, disc_loss = 0.024389905595521937
Trained batch 680 in epoch 0, gen_loss = 1.6844029860699579, disc_loss = 0.024357921516361392
Trained batch 681 in epoch 0, gen_loss = 1.6847083673449206, disc_loss = 0.024328617414574295
Trained batch 682 in epoch 0, gen_loss = 1.6847681084628685, disc_loss = 0.024303577890780536
Trained batch 683 in epoch 0, gen_loss = 1.684757762136515, disc_loss = 0.024274198248524937
Trained batch 684 in epoch 0, gen_loss = 1.68461371947379, disc_loss = 0.024243148693638125
Trained batch 685 in epoch 0, gen_loss = 1.6846888581448325, disc_loss = 0.024214292902217053
Trained batch 686 in epoch 0, gen_loss = 1.6842798614085501, disc_loss = 0.02418262081619303
Trained batch 687 in epoch 0, gen_loss = 1.6837809387334557, disc_loss = 0.024152453822966363
Trained batch 688 in epoch 0, gen_loss = 1.6835734197121055, disc_loss = 0.024121968088474218
Trained batch 689 in epoch 0, gen_loss = 1.6830785637316497, disc_loss = 0.02409458982663742
Trained batch 690 in epoch 0, gen_loss = 1.6833150008997937, disc_loss = 0.024069250724379473
Trained batch 691 in epoch 0, gen_loss = 1.6834246952065153, disc_loss = 0.024043626207831407
Trained batch 692 in epoch 0, gen_loss = 1.683610823419359, disc_loss = 0.024013777667640415
Trained batch 693 in epoch 0, gen_loss = 1.6838533515888952, disc_loss = 0.02398376427664655
Trained batch 694 in epoch 0, gen_loss = 1.6836634754276962, disc_loss = 0.023957696060897957
Trained batch 695 in epoch 0, gen_loss = 1.68373204168232, disc_loss = 0.02393107592287452
Trained batch 696 in epoch 0, gen_loss = 1.6832357687792785, disc_loss = 0.02390297764606261
Trained batch 697 in epoch 0, gen_loss = 1.6829040310102752, disc_loss = 0.02387695181027407
Trained batch 698 in epoch 0, gen_loss = 1.6828562517534509, disc_loss = 0.0238478861093649
Trained batch 699 in epoch 0, gen_loss = 1.682837599175317, disc_loss = 0.023821631469098586
Trained batch 700 in epoch 0, gen_loss = 1.6827998484422408, disc_loss = 0.02379200961068804
Trained batch 701 in epoch 0, gen_loss = 1.6828065234371739, disc_loss = 0.023764363476778367
Trained batch 702 in epoch 0, gen_loss = 1.682156110386421, disc_loss = 0.023738606893861532
Trained batch 703 in epoch 0, gen_loss = 1.6816914540461518, disc_loss = 0.023713280721329447
Trained batch 704 in epoch 0, gen_loss = 1.6812989989071028, disc_loss = 0.023685173361383854
Trained batch 705 in epoch 0, gen_loss = 1.680905048300119, disc_loss = 0.023656216854685996
Trained batch 706 in epoch 0, gen_loss = 1.6808306354781695, disc_loss = 0.023629170644546227
Trained batch 707 in epoch 0, gen_loss = 1.680680667949935, disc_loss = 0.02359877729500344
Trained batch 708 in epoch 0, gen_loss = 1.6804088944272362, disc_loss = 0.023571218876562203
Trained batch 709 in epoch 0, gen_loss = 1.6799175698992233, disc_loss = 0.023541196880035732
Trained batch 710 in epoch 0, gen_loss = 1.679789981593898, disc_loss = 0.023511125531595112
Trained batch 711 in epoch 0, gen_loss = 1.6793998357620132, disc_loss = 0.023497386198174312
Trained batch 712 in epoch 0, gen_loss = 1.679213248161915, disc_loss = 0.023477542439742122
Trained batch 713 in epoch 0, gen_loss = 1.6788851712264268, disc_loss = 0.02345229187264193
Trained batch 714 in epoch 0, gen_loss = 1.6786659540829958, disc_loss = 0.023423872944423472
Trained batch 715 in epoch 0, gen_loss = 1.6783795561537396, disc_loss = 0.023394488524346398
Trained batch 716 in epoch 0, gen_loss = 1.6782259118108072, disc_loss = 0.02336532466348671
Trained batch 717 in epoch 0, gen_loss = 1.677906348678727, disc_loss = 0.023338794427104088
Trained batch 718 in epoch 0, gen_loss = 1.678395269809081, disc_loss = 0.023316013143282587
Trained batch 719 in epoch 0, gen_loss = 1.6779680780238575, disc_loss = 0.023292422322750403
Trained batch 720 in epoch 0, gen_loss = 1.6778353631248422, disc_loss = 0.023266184652332687
Trained batch 721 in epoch 0, gen_loss = 1.6781965733565123, disc_loss = 0.023238816466879027
Trained batch 722 in epoch 0, gen_loss = 1.678376243322222, disc_loss = 0.023219174333818433
Trained batch 723 in epoch 0, gen_loss = 1.6782906493429322, disc_loss = 0.023193812289131158
Trained batch 724 in epoch 0, gen_loss = 1.67814311553692, disc_loss = 0.02317062146062481
Trained batch 725 in epoch 0, gen_loss = 1.6782745336369707, disc_loss = 0.023145018734894794
Trained batch 726 in epoch 0, gen_loss = 1.6780659411271632, disc_loss = 0.02312238396374711
Trained batch 727 in epoch 0, gen_loss = 1.677976361342839, disc_loss = 0.023099338653072673
Trained batch 728 in epoch 0, gen_loss = 1.677593600439273, disc_loss = 0.023075138412886113
Trained batch 729 in epoch 0, gen_loss = 1.6771181939399407, disc_loss = 0.023055017307043485
Trained batch 730 in epoch 0, gen_loss = 1.6773247695980256, disc_loss = 0.023035307474709568
Trained batch 731 in epoch 0, gen_loss = 1.6773192262063261, disc_loss = 0.023008361250757562
Trained batch 732 in epoch 0, gen_loss = 1.676716841584501, disc_loss = 0.022980707607995643
Trained batch 733 in epoch 0, gen_loss = 1.6762697131497333, disc_loss = 0.022951700507215293
Trained batch 734 in epoch 0, gen_loss = 1.676083753222511, disc_loss = 0.022923340653639514
Trained batch 735 in epoch 0, gen_loss = 1.6757980591577033, disc_loss = 0.022897881121183593
Trained batch 736 in epoch 0, gen_loss = 1.6759179979360572, disc_loss = 0.02286901009781476
Trained batch 737 in epoch 0, gen_loss = 1.6763889729815125, disc_loss = 0.02284270696998839
Trained batch 738 in epoch 0, gen_loss = 1.6763402330052708, disc_loss = 0.02281583682901739
Trained batch 739 in epoch 0, gen_loss = 1.6766096422801147, disc_loss = 0.02279026219920205
Trained batch 740 in epoch 0, gen_loss = 1.676626169086307, disc_loss = 0.022769168513077948
Trained batch 741 in epoch 0, gen_loss = 1.676551106323129, disc_loss = 0.022743839490499768
Trained batch 742 in epoch 0, gen_loss = 1.6766854348124918, disc_loss = 0.022716757172842737
Trained batch 743 in epoch 0, gen_loss = 1.676129087805748, disc_loss = 0.02269124422051508
Trained batch 744 in epoch 0, gen_loss = 1.6761308116400802, disc_loss = 0.022668899189924582
Trained batch 745 in epoch 0, gen_loss = 1.6756611017375465, disc_loss = 0.022644266731950927
Trained batch 746 in epoch 0, gen_loss = 1.6757034861259512, disc_loss = 0.022616586529330625
Trained batch 747 in epoch 0, gen_loss = 1.6755386582989107, disc_loss = 0.0225887867700829
Trained batch 748 in epoch 0, gen_loss = 1.6758229383957561, disc_loss = 0.02256223745535293
Trained batch 749 in epoch 0, gen_loss = 1.6751581190427145, disc_loss = 0.022535338076918075
Trained batch 750 in epoch 0, gen_loss = 1.6749922195858709, disc_loss = 0.02250919714442934
Trained batch 751 in epoch 0, gen_loss = 1.67492646264269, disc_loss = 0.022481455797536368
Trained batch 752 in epoch 0, gen_loss = 1.6750531487889182, disc_loss = 0.022457544316950774
Trained batch 753 in epoch 0, gen_loss = 1.6752560635144262, disc_loss = 0.022433634590331604
Trained batch 754 in epoch 0, gen_loss = 1.674506205280885, disc_loss = 0.022407511786237014
Trained batch 755 in epoch 0, gen_loss = 1.6744701430280373, disc_loss = 0.022385306123406355
Trained batch 756 in epoch 0, gen_loss = 1.6744790034690968, disc_loss = 0.022363205135079
Trained batch 757 in epoch 0, gen_loss = 1.674142782637815, disc_loss = 0.022337619100831263
Trained batch 758 in epoch 0, gen_loss = 1.673947999442833, disc_loss = 0.022312033247375646
Trained batch 759 in epoch 0, gen_loss = 1.6742884741017694, disc_loss = 0.022289411652079587
Trained batch 760 in epoch 0, gen_loss = 1.6745375026697868, disc_loss = 0.022264533483915265
Trained batch 761 in epoch 0, gen_loss = 1.6744994838719607, disc_loss = 0.022238266881796094
Trained batch 762 in epoch 0, gen_loss = 1.6739048617226737, disc_loss = 0.022212950523599718
Trained batch 763 in epoch 0, gen_loss = 1.6741592578238842, disc_loss = 0.022189431071509388
Trained batch 764 in epoch 0, gen_loss = 1.6746796177882775, disc_loss = 0.022167957278753758
Trained batch 765 in epoch 0, gen_loss = 1.674395759485409, disc_loss = 0.022145070038783285
Trained batch 766 in epoch 0, gen_loss = 1.6746666454740422, disc_loss = 0.022119573637572356
Trained batch 767 in epoch 0, gen_loss = 1.6747861617865663, disc_loss = 0.02209345979235877
Trained batch 768 in epoch 0, gen_loss = 1.674683046278935, disc_loss = 0.022069505774488695
Trained batch 769 in epoch 0, gen_loss = 1.6749574464636963, disc_loss = 0.02204690198973426
Trained batch 770 in epoch 0, gen_loss = 1.6746858794401591, disc_loss = 0.022023632164093896
Trained batch 771 in epoch 0, gen_loss = 1.6745756844473627, disc_loss = 0.021997185349627277
Trained batch 772 in epoch 0, gen_loss = 1.675142760264457, disc_loss = 0.021972311259293147
Trained batch 773 in epoch 0, gen_loss = 1.6749131420786068, disc_loss = 0.02195200548270833
Trained batch 774 in epoch 0, gen_loss = 1.6746976920097105, disc_loss = 0.021929893272388125
Trained batch 775 in epoch 0, gen_loss = 1.6745483775421517, disc_loss = 0.02190437994716742
Trained batch 776 in epoch 0, gen_loss = 1.6742200592156389, disc_loss = 0.021880287852197013
Trained batch 777 in epoch 0, gen_loss = 1.6741874178148481, disc_loss = 0.02185411316418666
Trained batch 778 in epoch 0, gen_loss = 1.674049833160616, disc_loss = 0.021827839374116625
Trained batch 779 in epoch 0, gen_loss = 1.6738463195470663, disc_loss = 0.02180927099648099
Trained batch 780 in epoch 0, gen_loss = 1.6735348562577623, disc_loss = 0.0217863774724858
Trained batch 781 in epoch 0, gen_loss = 1.6733592195279152, disc_loss = 0.02176068514934443
Trained batch 782 in epoch 0, gen_loss = 1.6734053846520025, disc_loss = 0.02173531746805799
Trained batch 783 in epoch 0, gen_loss = 1.673046743839371, disc_loss = 0.02171037108779942
Trained batch 784 in epoch 0, gen_loss = 1.6728191646041384, disc_loss = 0.021689500843595926
Trained batch 785 in epoch 0, gen_loss = 1.6728755200788872, disc_loss = 0.021670665774428055
Trained batch 786 in epoch 0, gen_loss = 1.672542861183535, disc_loss = 0.021646633672645122
Trained batch 787 in epoch 0, gen_loss = 1.6724783424193483, disc_loss = 0.02162867176185745
Trained batch 788 in epoch 0, gen_loss = 1.6727154693071682, disc_loss = 0.02160852945720156
Trained batch 789 in epoch 0, gen_loss = 1.6727735367002365, disc_loss = 0.021585355788068493
Trained batch 790 in epoch 0, gen_loss = 1.6729663134224044, disc_loss = 0.0215613416675125
Trained batch 791 in epoch 0, gen_loss = 1.6722340451346502, disc_loss = 0.021543083643667738
Trained batch 792 in epoch 0, gen_loss = 1.6720551728901616, disc_loss = 0.021520894855227964
Trained batch 793 in epoch 0, gen_loss = 1.672015424639512, disc_loss = 0.021496916721429515
Trained batch 794 in epoch 0, gen_loss = 1.6719989280280827, disc_loss = 0.021472559899162007
Trained batch 795 in epoch 0, gen_loss = 1.6721069808281845, disc_loss = 0.021447966075923537
Trained batch 796 in epoch 0, gen_loss = 1.6726536925793292, disc_loss = 0.021424607390717814
Trained batch 797 in epoch 0, gen_loss = 1.672802924213553, disc_loss = 0.021402848783511678
Trained batch 798 in epoch 0, gen_loss = 1.6729861897729963, disc_loss = 0.021382769810453114
Trained batch 799 in epoch 0, gen_loss = 1.6728467546403407, disc_loss = 0.021360075803822837
Trained batch 800 in epoch 0, gen_loss = 1.6727616057711445, disc_loss = 0.02133736054740902
Trained batch 801 in epoch 0, gen_loss = 1.6727289755148187, disc_loss = 0.021315498245320284
Trained batch 802 in epoch 0, gen_loss = 1.6728343209472125, disc_loss = 0.021291728542913516
Trained batch 803 in epoch 0, gen_loss = 1.6729416077706352, disc_loss = 0.021267632011785196
Trained batch 804 in epoch 0, gen_loss = 1.6734863510783415, disc_loss = 0.021246639959895924
Trained batch 805 in epoch 0, gen_loss = 1.6732042813419408, disc_loss = 0.021223011604283772
Trained batch 806 in epoch 0, gen_loss = 1.6731283726745378, disc_loss = 0.021199317657373744
Trained batch 807 in epoch 0, gen_loss = 1.67328510057218, disc_loss = 0.021175361709700354
Trained batch 808 in epoch 0, gen_loss = 1.6731294722138583, disc_loss = 0.021151855820646034
Trained batch 809 in epoch 0, gen_loss = 1.6731506393279558, disc_loss = 0.021130923564218123
Trained batch 810 in epoch 0, gen_loss = 1.6728354945282753, disc_loss = 0.021109134790949228
Trained batch 811 in epoch 0, gen_loss = 1.673069038855031, disc_loss = 0.021085717368227536
Trained batch 812 in epoch 0, gen_loss = 1.672542704720632, disc_loss = 0.021061954363295065
Trained batch 813 in epoch 0, gen_loss = 1.6722973652495212, disc_loss = 0.021038213753483557
Trained batch 814 in epoch 0, gen_loss = 1.6726320926397125, disc_loss = 0.021018877201085123
Trained batch 815 in epoch 0, gen_loss = 1.6722027739765597, disc_loss = 0.021000414819818437
Trained batch 816 in epoch 0, gen_loss = 1.6720792567277625, disc_loss = 0.020984370722104836
Trained batch 817 in epoch 0, gen_loss = 1.6716700795227275, disc_loss = 0.02096299205700045
Trained batch 818 in epoch 0, gen_loss = 1.6715867055059208, disc_loss = 0.020944009694357214
Trained batch 819 in epoch 0, gen_loss = 1.6717878706571532, disc_loss = 0.020921720497497562
Trained batch 820 in epoch 0, gen_loss = 1.672010587135854, disc_loss = 0.02089885781827098
Trained batch 821 in epoch 0, gen_loss = 1.6722275561079782, disc_loss = 0.020878121239408496
Trained batch 822 in epoch 0, gen_loss = 1.672295303854589, disc_loss = 0.02085594355679238
Trained batch 823 in epoch 0, gen_loss = 1.6722718011407018, disc_loss = 0.020833461536507086
Trained batch 824 in epoch 0, gen_loss = 1.672185745239258, disc_loss = 0.020810210164071936
Trained batch 825 in epoch 0, gen_loss = 1.6722806471312017, disc_loss = 0.02078866729564676
Trained batch 826 in epoch 0, gen_loss = 1.6722348478713953, disc_loss = 0.02077011810334122
Trained batch 827 in epoch 0, gen_loss = 1.6720783320314065, disc_loss = 0.02075028546370458
Trained batch 828 in epoch 0, gen_loss = 1.6721534540627345, disc_loss = 0.020728904898845747
Trained batch 829 in epoch 0, gen_loss = 1.6719688761665161, disc_loss = 0.02070594578420362
Trained batch 830 in epoch 0, gen_loss = 1.6719397643556377, disc_loss = 0.020683635393814345
Trained batch 831 in epoch 0, gen_loss = 1.6719750019793327, disc_loss = 0.020661769679393798
Trained batch 832 in epoch 0, gen_loss = 1.6720632336148264, disc_loss = 0.020640109587429453
Trained batch 833 in epoch 0, gen_loss = 1.6722446667204658, disc_loss = 0.02062010272390408
Trained batch 834 in epoch 0, gen_loss = 1.6720334201515792, disc_loss = 0.02059770412910395
Trained batch 835 in epoch 0, gen_loss = 1.6719655199199202, disc_loss = 0.02057554478741487
Trained batch 836 in epoch 0, gen_loss = 1.671800194390501, disc_loss = 0.020552951968976007
Trained batch 837 in epoch 0, gen_loss = 1.6719040704228714, disc_loss = 0.020530383967931175
Trained batch 838 in epoch 0, gen_loss = 1.6717228623766438, disc_loss = 0.020508613890448765
Trained batch 839 in epoch 0, gen_loss = 1.6718467140481585, disc_loss = 0.02048705036993072
Trained batch 840 in epoch 0, gen_loss = 1.6720370913232265, disc_loss = 0.020465372132351146
Trained batch 841 in epoch 0, gen_loss = 1.672508828288869, disc_loss = 0.020443006407446285
Trained batch 842 in epoch 0, gen_loss = 1.672572721507343, disc_loss = 0.020420418237612172
Trained batch 843 in epoch 0, gen_loss = 1.6726390021672182, disc_loss = 0.020398396494913124
Trained batch 844 in epoch 0, gen_loss = 1.6722627467657687, disc_loss = 0.02037632030299892
Trained batch 845 in epoch 0, gen_loss = 1.6718543338155634, disc_loss = 0.02035412137357003
Trained batch 846 in epoch 0, gen_loss = 1.6717506956744503, disc_loss = 0.020332135655944716
Trained batch 847 in epoch 0, gen_loss = 1.672021506951665, disc_loss = 0.020309834713874087
Trained batch 848 in epoch 0, gen_loss = 1.672163604847534, disc_loss = 0.020287348156042388
Trained batch 849 in epoch 0, gen_loss = 1.6719262660250944, disc_loss = 0.020267965786487742
Trained batch 850 in epoch 0, gen_loss = 1.6718986069413666, disc_loss = 0.020250129649693586
Trained batch 851 in epoch 0, gen_loss = 1.6718796767259427, disc_loss = 0.02022879240113997
Trained batch 852 in epoch 0, gen_loss = 1.6719722754790383, disc_loss = 0.020208398063622353
Trained batch 853 in epoch 0, gen_loss = 1.6717133171664469, disc_loss = 0.020186428653389276
Trained batch 854 in epoch 0, gen_loss = 1.6716805870770013, disc_loss = 0.020164636366766447
Trained batch 855 in epoch 0, gen_loss = 1.6717055687837512, disc_loss = 0.020142835724574436
Trained batch 856 in epoch 0, gen_loss = 1.671546718620781, disc_loss = 0.020121127175484525
Trained batch 857 in epoch 0, gen_loss = 1.6711108331635838, disc_loss = 0.020099668580406977
Trained batch 858 in epoch 0, gen_loss = 1.6713542118061409, disc_loss = 0.020081881769554423
Trained batch 859 in epoch 0, gen_loss = 1.6713394321674524, disc_loss = 0.02006125379933131
Trained batch 860 in epoch 0, gen_loss = 1.6716359639140095, disc_loss = 0.020040080791612944
Trained batch 861 in epoch 0, gen_loss = 1.6718405475472629, disc_loss = 0.02001919063159833
Trained batch 862 in epoch 0, gen_loss = 1.6716395630344731, disc_loss = 0.019998066157247193
Trained batch 863 in epoch 0, gen_loss = 1.6715663007839963, disc_loss = 0.01997763741490888
Trained batch 864 in epoch 0, gen_loss = 1.671562124538973, disc_loss = 0.019956419229738932
Trained batch 865 in epoch 0, gen_loss = 1.6711662802630154, disc_loss = 0.019936306138472377
Trained batch 866 in epoch 0, gen_loss = 1.6709409336180285, disc_loss = 0.01991591327074451
Trained batch 867 in epoch 0, gen_loss = 1.670896572039424, disc_loss = 0.019894726424073493
Trained batch 868 in epoch 0, gen_loss = 1.6708179966078254, disc_loss = 0.0198738521504322
Trained batch 869 in epoch 0, gen_loss = 1.6707472529904597, disc_loss = 0.019852978210419887
Trained batch 870 in epoch 0, gen_loss = 1.6707749006805683, disc_loss = 0.01983175820020914
Trained batch 871 in epoch 0, gen_loss = 1.670623164248029, disc_loss = 0.01981071438218484
Trained batch 872 in epoch 0, gen_loss = 1.6706304253854567, disc_loss = 0.019790379817779993
Trained batch 873 in epoch 0, gen_loss = 1.670758327166603, disc_loss = 0.01976987630998912
Trained batch 874 in epoch 0, gen_loss = 1.6710324944087438, disc_loss = 0.01974917291663587
Trained batch 875 in epoch 0, gen_loss = 1.6706873256049743, disc_loss = 0.01972987797652418
Trained batch 876 in epoch 0, gen_loss = 1.6707807586293673, disc_loss = 0.019711610386700305
Trained batch 877 in epoch 0, gen_loss = 1.671144585810381, disc_loss = 0.019692423476324182
Trained batch 878 in epoch 0, gen_loss = 1.6710158016901375, disc_loss = 0.019672849449987043
Trained batch 879 in epoch 0, gen_loss = 1.671071994440122, disc_loss = 0.019651923382083294
Trained batch 880 in epoch 0, gen_loss = 1.6713481796450838, disc_loss = 0.019630894298262463
Trained batch 881 in epoch 0, gen_loss = 1.6712636055589534, disc_loss = 0.019609690345021264
Trained batch 882 in epoch 0, gen_loss = 1.6711705060399402, disc_loss = 0.019589489426870967
Trained batch 883 in epoch 0, gen_loss = 1.6713343686108135, disc_loss = 0.019569381700124913
Trained batch 884 in epoch 0, gen_loss = 1.6712383857554636, disc_loss = 0.019548556301611248
Trained batch 885 in epoch 0, gen_loss = 1.6710354727493182, disc_loss = 0.019529523626080257
Trained batch 886 in epoch 0, gen_loss = 1.6707570921071084, disc_loss = 0.01951252786023175
Trained batch 887 in epoch 0, gen_loss = 1.671064164724436, disc_loss = 0.01949547676892368
Trained batch 888 in epoch 0, gen_loss = 1.671108256845292, disc_loss = 0.019475205124542327
Trained batch 889 in epoch 0, gen_loss = 1.6708649754524232, disc_loss = 0.019457986207778326
Trained batch 890 in epoch 0, gen_loss = 1.6709192640719859, disc_loss = 0.01943777555374556
Trained batch 891 in epoch 0, gen_loss = 1.6704874342065221, disc_loss = 0.019418952890411813
Trained batch 892 in epoch 0, gen_loss = 1.6703976496870547, disc_loss = 0.019399361621952445
Trained batch 893 in epoch 0, gen_loss = 1.67041572081696, disc_loss = 0.01938075975942586
Trained batch 894 in epoch 0, gen_loss = 1.6704769436873537, disc_loss = 0.01936353883880331
Trained batch 895 in epoch 0, gen_loss = 1.67054651557867, disc_loss = 0.019345054039539327
Trained batch 896 in epoch 0, gen_loss = 1.6701531246753043, disc_loss = 0.019328003936528188
Trained batch 897 in epoch 0, gen_loss = 1.669772767409981, disc_loss = 0.01931321833327823
Trained batch 898 in epoch 0, gen_loss = 1.6697530906908504, disc_loss = 0.01929627071941236
Trained batch 899 in epoch 0, gen_loss = 1.6692216005590228, disc_loss = 0.019278045791175424
Trained batch 900 in epoch 0, gen_loss = 1.669114914374399, disc_loss = 0.019260708725759006
Trained batch 901 in epoch 0, gen_loss = 1.668881491123969, disc_loss = 0.019241426862567714
Trained batch 902 in epoch 0, gen_loss = 1.668680310117314, disc_loss = 0.019221995096006004
Trained batch 903 in epoch 0, gen_loss = 1.6688851106219587, disc_loss = 0.01920293877879982
Trained batch 904 in epoch 0, gen_loss = 1.668783374912831, disc_loss = 0.01918524648860426
Trained batch 905 in epoch 0, gen_loss = 1.6688060019716258, disc_loss = 0.01917047451392112
Trained batch 906 in epoch 0, gen_loss = 1.6684159860589933, disc_loss = 0.019154189520052406
Trained batch 907 in epoch 0, gen_loss = 1.668436039255579, disc_loss = 0.01913582263124639
Trained batch 908 in epoch 0, gen_loss = 1.668145607931517, disc_loss = 0.01911998422031585
Trained batch 909 in epoch 0, gen_loss = 1.6679337166167878, disc_loss = 0.01910456780774089
Trained batch 910 in epoch 0, gen_loss = 1.6680801480059828, disc_loss = 0.019086582061214094
Trained batch 911 in epoch 0, gen_loss = 1.6678590706565923, disc_loss = 0.019067769075806148
Trained batch 912 in epoch 0, gen_loss = 1.6678622635928066, disc_loss = 0.019050560908076872
Trained batch 913 in epoch 0, gen_loss = 1.6678907924720965, disc_loss = 0.019032857792591576
Trained batch 914 in epoch 0, gen_loss = 1.6677492304577854, disc_loss = 0.019013783112397327
Trained batch 915 in epoch 0, gen_loss = 1.667678596931774, disc_loss = 0.01899420663101322
Trained batch 916 in epoch 0, gen_loss = 1.667953075473415, disc_loss = 0.018974873335826876
Trained batch 917 in epoch 0, gen_loss = 1.6677057114561658, disc_loss = 0.018955771691720802
Trained batch 918 in epoch 0, gen_loss = 1.6675091033661587, disc_loss = 0.018936413202573617
Trained batch 919 in epoch 0, gen_loss = 1.6677057823409205, disc_loss = 0.018917553982844212
Trained batch 920 in epoch 0, gen_loss = 1.6677323608263825, disc_loss = 0.018897800921335063
Trained batch 921 in epoch 0, gen_loss = 1.6678769070000556, disc_loss = 0.0188785023712543
Trained batch 922 in epoch 0, gen_loss = 1.6681288925048976, disc_loss = 0.018859681857871912
Trained batch 923 in epoch 0, gen_loss = 1.6679022749523065, disc_loss = 0.018841605039703502
Trained batch 924 in epoch 0, gen_loss = 1.6680146535667213, disc_loss = 0.01882349745760596
Trained batch 925 in epoch 0, gen_loss = 1.667906679679714, disc_loss = 0.018804629750576948
Trained batch 926 in epoch 0, gen_loss = 1.6678022323688644, disc_loss = 0.018785473296470023
Trained batch 927 in epoch 0, gen_loss = 1.667613422433878, disc_loss = 0.01876761045184986
Trained batch 928 in epoch 0, gen_loss = 1.6675881457919068, disc_loss = 0.018748568661162073
Trained batch 929 in epoch 0, gen_loss = 1.6680017062412795, disc_loss = 0.018730541254563998
Trained batch 930 in epoch 0, gen_loss = 1.667837872797129, disc_loss = 0.018712775032991336
Trained batch 931 in epoch 0, gen_loss = 1.6674806189127747, disc_loss = 0.018695146902644198
Trained batch 932 in epoch 0, gen_loss = 1.6675450574418995, disc_loss = 0.018676830890876944
Trained batch 933 in epoch 0, gen_loss = 1.667448821746818, disc_loss = 0.018658557180833764
Trained batch 934 in epoch 0, gen_loss = 1.6676390832758206, disc_loss = 0.018639717176979917
Trained batch 935 in epoch 0, gen_loss = 1.6672846509350672, disc_loss = 0.018621492170122787
Trained batch 936 in epoch 0, gen_loss = 1.667062353553487, disc_loss = 0.01860292766304347
Trained batch 937 in epoch 0, gen_loss = 1.6670510062276682, disc_loss = 0.01858460515385557
Trained batch 938 in epoch 0, gen_loss = 1.666865230368349, disc_loss = 0.018566013627370207
Trained batch 939 in epoch 0, gen_loss = 1.666685176529783, disc_loss = 0.01854894576046834
Trained batch 940 in epoch 0, gen_loss = 1.6665272124895507, disc_loss = 0.01853182640035046
Trained batch 941 in epoch 0, gen_loss = 1.6670516843249084, disc_loss = 0.018515172318457538
Trained batch 942 in epoch 0, gen_loss = 1.6669989601804747, disc_loss = 0.018497108154182547
Trained batch 943 in epoch 0, gen_loss = 1.6670047466532658, disc_loss = 0.018478911271875217
Trained batch 944 in epoch 0, gen_loss = 1.666867424949767, disc_loss = 0.01846102059513291
Trained batch 945 in epoch 0, gen_loss = 1.666843640375843, disc_loss = 0.01844296555724448
Trained batch 946 in epoch 0, gen_loss = 1.6668280867865621, disc_loss = 0.018425379872150965
Trained batch 947 in epoch 0, gen_loss = 1.6665735594330962, disc_loss = 0.018407218602784606
Trained batch 948 in epoch 0, gen_loss = 1.6663668180793303, disc_loss = 0.01838881738349703
Trained batch 949 in epoch 0, gen_loss = 1.6663466410887868, disc_loss = 0.01837102045752353
Trained batch 950 in epoch 0, gen_loss = 1.6664529689102894, disc_loss = 0.018352922409531472
Trained batch 951 in epoch 0, gen_loss = 1.666719965073241, disc_loss = 0.018336122788959908
Trained batch 952 in epoch 0, gen_loss = 1.666508714649885, disc_loss = 0.01831802376454348
Trained batch 953 in epoch 0, gen_loss = 1.666530329226448, disc_loss = 0.018300502912780323
Trained batch 954 in epoch 0, gen_loss = 1.6663720535358209, disc_loss = 0.018282881693692674
Trained batch 955 in epoch 0, gen_loss = 1.6662164492587166, disc_loss = 0.018266463716610365
Trained batch 956 in epoch 0, gen_loss = 1.666305278411355, disc_loss = 0.01825393157089791
Trained batch 957 in epoch 0, gen_loss = 1.6661648313536275, disc_loss = 0.018242631601483223
Trained batch 958 in epoch 0, gen_loss = 1.6659567922944196, disc_loss = 0.01822701657228065
Trained batch 959 in epoch 0, gen_loss = 1.6659112258503834, disc_loss = 0.01820991754145022
Trained batch 960 in epoch 0, gen_loss = 1.665506495273324, disc_loss = 0.01819298037481189
Trained batch 961 in epoch 0, gen_loss = 1.6653328529266707, disc_loss = 0.018176484748291765
Trained batch 962 in epoch 0, gen_loss = 1.665563877250299, disc_loss = 0.018162719973376037
Trained batch 963 in epoch 0, gen_loss = 1.6653709399254986, disc_loss = 0.01814759543864298
Trained batch 964 in epoch 0, gen_loss = 1.6654255267869624, disc_loss = 0.018130322108636344
Trained batch 965 in epoch 0, gen_loss = 1.6652513727638292, disc_loss = 0.018112313693910392
Trained batch 966 in epoch 0, gen_loss = 1.6648376071835254, disc_loss = 0.018095523320562704
Trained batch 967 in epoch 0, gen_loss = 1.6646445814735633, disc_loss = 0.018080066769801884
Trained batch 968 in epoch 0, gen_loss = 1.6644942404931051, disc_loss = 0.018064247849443014
Trained batch 969 in epoch 0, gen_loss = 1.6647243901626352, disc_loss = 0.01804713073586229
Trained batch 970 in epoch 0, gen_loss = 1.6648354079770011, disc_loss = 0.018030296588576966
Trained batch 971 in epoch 0, gen_loss = 1.6648540215973011, disc_loss = 0.01801370803539597
Trained batch 972 in epoch 0, gen_loss = 1.6647503137098432, disc_loss = 0.01799696637957643
Trained batch 973 in epoch 0, gen_loss = 1.6646669286722031, disc_loss = 0.0179800753296067
Trained batch 974 in epoch 0, gen_loss = 1.664713604022295, disc_loss = 0.017963224409733157
Trained batch 975 in epoch 0, gen_loss = 1.664368449175944, disc_loss = 0.01794594169333606
Trained batch 976 in epoch 0, gen_loss = 1.664285253965989, disc_loss = 0.017929365333613435
Trained batch 977 in epoch 0, gen_loss = 1.6639921604246206, disc_loss = 0.017913106989564474
Trained batch 978 in epoch 0, gen_loss = 1.6637723224277516, disc_loss = 0.017896624735950856
Trained batch 979 in epoch 0, gen_loss = 1.6637472988391409, disc_loss = 0.017879763854327803
Trained batch 980 in epoch 0, gen_loss = 1.6634176162647787, disc_loss = 0.01786331788578121
Trained batch 981 in epoch 0, gen_loss = 1.6633516896038094, disc_loss = 0.01784672144599602
Trained batch 982 in epoch 0, gen_loss = 1.662986001429941, disc_loss = 0.01783034329271581
Trained batch 983 in epoch 0, gen_loss = 1.6631277129659807, disc_loss = 0.017814226564300546
Trained batch 984 in epoch 0, gen_loss = 1.6626968201041827, disc_loss = 0.017799019246057226
Trained batch 985 in epoch 0, gen_loss = 1.6620962802343389, disc_loss = 0.017782654734335473
Trained batch 986 in epoch 0, gen_loss = 1.662003592758797, disc_loss = 0.01776804761854241
Trained batch 987 in epoch 0, gen_loss = 1.662084729685957, disc_loss = 0.017752687158503734
Trained batch 988 in epoch 0, gen_loss = 1.6620885242224945, disc_loss = 0.017736263856086013
Trained batch 989 in epoch 0, gen_loss = 1.661931891995247, disc_loss = 0.017719885753408885
Trained batch 990 in epoch 0, gen_loss = 1.6619231774275287, disc_loss = 0.017703832560568938
Trained batch 991 in epoch 0, gen_loss = 1.661836955456003, disc_loss = 0.0176870906313026
Trained batch 992 in epoch 0, gen_loss = 1.661818375040037, disc_loss = 0.017670791586385036
Trained batch 993 in epoch 0, gen_loss = 1.6617944260957975, disc_loss = 0.017655534193847775
Trained batch 994 in epoch 0, gen_loss = 1.661563458873998, disc_loss = 0.017642199383854362
Trained batch 995 in epoch 0, gen_loss = 1.661533390901175, disc_loss = 0.017628958419839157
Trained batch 996 in epoch 0, gen_loss = 1.6617904761609965, disc_loss = 0.017613969458869137
Trained batch 997 in epoch 0, gen_loss = 1.6619121573253242, disc_loss = 0.017597404925396687
Trained batch 998 in epoch 0, gen_loss = 1.6617692458379019, disc_loss = 0.017582252877729444
Trained batch 999 in epoch 0, gen_loss = 1.6621046353578568, disc_loss = 0.017567201726313215
Trained batch 1000 in epoch 0, gen_loss = 1.6621289215126, disc_loss = 0.017550424750758006
Trained batch 1001 in epoch 0, gen_loss = 1.6621825266740993, disc_loss = 0.0175345590979557
Trained batch 1002 in epoch 0, gen_loss = 1.6621514186783064, disc_loss = 0.017518034315626728
Trained batch 1003 in epoch 0, gen_loss = 1.662221528619409, disc_loss = 0.01750262623470308
Trained batch 1004 in epoch 0, gen_loss = 1.6623080789746336, disc_loss = 0.01748695276227006
Trained batch 1005 in epoch 0, gen_loss = 1.6621716091220469, disc_loss = 0.017471473388918666
Trained batch 1006 in epoch 0, gen_loss = 1.6622817982746567, disc_loss = 0.017456786697621754
Trained batch 1007 in epoch 0, gen_loss = 1.66211941152338, disc_loss = 0.01744163176951429
Trained batch 1008 in epoch 0, gen_loss = 1.662072084585668, disc_loss = 0.017426672117746313
Trained batch 1009 in epoch 0, gen_loss = 1.6621657402208536, disc_loss = 0.017410462964752616
Trained batch 1010 in epoch 0, gen_loss = 1.661900544850456, disc_loss = 0.01739524708100218
Trained batch 1011 in epoch 0, gen_loss = 1.6620157275039689, disc_loss = 0.0173805392524545
Trained batch 1012 in epoch 0, gen_loss = 1.6615526948017523, disc_loss = 0.0173648695303665
Trained batch 1013 in epoch 0, gen_loss = 1.6612883711002282, disc_loss = 0.017349348645700927
Trained batch 1014 in epoch 0, gen_loss = 1.661244082920657, disc_loss = 0.017335073873022196
Trained batch 1015 in epoch 0, gen_loss = 1.6611780567666676, disc_loss = 0.017321089010786057
Trained batch 1016 in epoch 0, gen_loss = 1.6610370146489777, disc_loss = 0.01730612861197451
Trained batch 1017 in epoch 0, gen_loss = 1.6610547615643334, disc_loss = 0.017290327553159315
Trained batch 1018 in epoch 0, gen_loss = 1.6608223511496516, disc_loss = 0.017274635737513717
Trained batch 1019 in epoch 0, gen_loss = 1.6605657737629087, disc_loss = 0.017258886148520818
Trained batch 1020 in epoch 0, gen_loss = 1.6603737186848475, disc_loss = 0.017243265602192644
Trained batch 1021 in epoch 0, gen_loss = 1.6602452003092683, disc_loss = 0.017227369810168862
Trained batch 1022 in epoch 0, gen_loss = 1.6600758393139434, disc_loss = 0.01721193126721657
Trained batch 1023 in epoch 0, gen_loss = 1.6603990399744362, disc_loss = 0.0171970020520007
Trained batch 1024 in epoch 0, gen_loss = 1.6600553149711794, disc_loss = 0.0171819004184203
Trained batch 1025 in epoch 0, gen_loss = 1.6601480873007524, disc_loss = 0.017166339600044368
Trained batch 1026 in epoch 0, gen_loss = 1.6603472639082004, disc_loss = 0.017151342103715276
Trained batch 1027 in epoch 0, gen_loss = 1.6602184157891031, disc_loss = 0.01713617499773925
Trained batch 1028 in epoch 0, gen_loss = 1.6602535799247067, disc_loss = 0.0171205365765714
Trained batch 1029 in epoch 0, gen_loss = 1.6602669364040337, disc_loss = 0.017105310765893007
Trained batch 1030 in epoch 0, gen_loss = 1.6605138214436928, disc_loss = 0.01708971517763275
Trained batch 1031 in epoch 0, gen_loss = 1.6605792045593262, disc_loss = 0.017074802215222375
Trained batch 1032 in epoch 0, gen_loss = 1.660587566404352, disc_loss = 0.01705998467649527
Trained batch 1033 in epoch 0, gen_loss = 1.661170216662741, disc_loss = 0.017045842768316836
Trained batch 1034 in epoch 0, gen_loss = 1.6615042572436125, disc_loss = 0.017031676828656524
Trained batch 1035 in epoch 0, gen_loss = 1.661716007127725, disc_loss = 0.017016917264570382
Trained batch 1036 in epoch 0, gen_loss = 1.6614456489437917, disc_loss = 0.017001873919600667
Trained batch 1037 in epoch 0, gen_loss = 1.6610022947508016, disc_loss = 0.016987969996400898
Trained batch 1038 in epoch 0, gen_loss = 1.6605313450700394, disc_loss = 0.016974811767184475
Trained batch 1039 in epoch 0, gen_loss = 1.6606751018991837, disc_loss = 0.016961556625196512
Trained batch 1040 in epoch 0, gen_loss = 1.6607651290243115, disc_loss = 0.016948335440429042
Trained batch 1041 in epoch 0, gen_loss = 1.6611071013900918, disc_loss = 0.016933446535257437
Trained batch 1042 in epoch 0, gen_loss = 1.6609116233778136, disc_loss = 0.016918494637280058
Trained batch 1043 in epoch 0, gen_loss = 1.6611523217168347, disc_loss = 0.016903559667657313
Trained batch 1044 in epoch 0, gen_loss = 1.6608278757077084, disc_loss = 0.016888598476717042
Trained batch 1045 in epoch 0, gen_loss = 1.6607037122801203, disc_loss = 0.016873354341598392
Trained batch 1046 in epoch 0, gen_loss = 1.6605026818733617, disc_loss = 0.016858869513602163
Trained batch 1047 in epoch 0, gen_loss = 1.6604843650382894, disc_loss = 0.016844235867217897
Trained batch 1048 in epoch 0, gen_loss = 1.660098032114958, disc_loss = 0.016829415489118225
Trained batch 1049 in epoch 0, gen_loss = 1.6598681192171005, disc_loss = 0.016814473676439817
Trained batch 1050 in epoch 0, gen_loss = 1.6597712330314571, disc_loss = 0.016799524486772487
Trained batch 1051 in epoch 0, gen_loss = 1.6594861235908682, disc_loss = 0.016784243374074075
Trained batch 1052 in epoch 0, gen_loss = 1.6596478085685433, disc_loss = 0.01677095488030888
Trained batch 1053 in epoch 0, gen_loss = 1.6598152034196727, disc_loss = 0.0167568340532851
Trained batch 1054 in epoch 0, gen_loss = 1.6598504991892955, disc_loss = 0.016742409785030967
Trained batch 1055 in epoch 0, gen_loss = 1.659555369705865, disc_loss = 0.016729995962977584
Trained batch 1056 in epoch 0, gen_loss = 1.6596380698872606, disc_loss = 0.016717163299504657
Trained batch 1057 in epoch 0, gen_loss = 1.6599605263744275, disc_loss = 0.01670376814750863
Trained batch 1058 in epoch 0, gen_loss = 1.6596771155583396, disc_loss = 0.016690190743968925
Trained batch 1059 in epoch 0, gen_loss = 1.6592879962246374, disc_loss = 0.016676807084740227
Trained batch 1060 in epoch 0, gen_loss = 1.6592539617410815, disc_loss = 0.016663490607303152
Trained batch 1061 in epoch 0, gen_loss = 1.659077146183524, disc_loss = 0.016650612580589072
Trained batch 1062 in epoch 0, gen_loss = 1.6594104154538345, disc_loss = 0.016636766147359976
Trained batch 1063 in epoch 0, gen_loss = 1.6595067353849124, disc_loss = 0.01662243234290815
Trained batch 1064 in epoch 0, gen_loss = 1.6597109296512156, disc_loss = 0.0166085612360047
Trained batch 1065 in epoch 0, gen_loss = 1.6597278720889708, disc_loss = 0.01659595914847719
Trained batch 1066 in epoch 0, gen_loss = 1.6595648587476235, disc_loss = 0.016582033478553672
Trained batch 1067 in epoch 0, gen_loss = 1.6593692254707608, disc_loss = 0.016568352676398723
Trained batch 1068 in epoch 0, gen_loss = 1.6595033771864602, disc_loss = 0.0165557493454619
Trained batch 1069 in epoch 0, gen_loss = 1.6594358239218454, disc_loss = 0.01654281328643333
Trained batch 1070 in epoch 0, gen_loss = 1.6597243762261171, disc_loss = 0.016530436199627133
Trained batch 1071 in epoch 0, gen_loss = 1.6595056098121315, disc_loss = 0.016519118201073584
Trained batch 1072 in epoch 0, gen_loss = 1.6594429548277772, disc_loss = 0.01650581268048155
Trained batch 1073 in epoch 0, gen_loss = 1.6597560039223684, disc_loss = 0.016491545339004834
Trained batch 1074 in epoch 0, gen_loss = 1.6594468902987103, disc_loss = 0.016478214031626838
Trained batch 1075 in epoch 0, gen_loss = 1.6593342906480386, disc_loss = 0.01646442710585134
Trained batch 1076 in epoch 0, gen_loss = 1.659481412078234, disc_loss = 0.016450308715883977
Trained batch 1077 in epoch 0, gen_loss = 1.6594331372867932, disc_loss = 0.01643591475104334
Trained batch 1078 in epoch 0, gen_loss = 1.6591420627723037, disc_loss = 0.0164218256678894
Trained batch 1079 in epoch 0, gen_loss = 1.6590376181734934, disc_loss = 0.016407836159568333
Trained batch 1080 in epoch 0, gen_loss = 1.658913979256848, disc_loss = 0.016393554406942738
Trained batch 1081 in epoch 0, gen_loss = 1.6590378130209424, disc_loss = 0.016379132579425488
Trained batch 1082 in epoch 0, gen_loss = 1.6592587857805572, disc_loss = 0.01636481304938491
Trained batch 1083 in epoch 0, gen_loss = 1.6592999564765565, disc_loss = 0.016350742978708838
Trained batch 1084 in epoch 0, gen_loss = 1.6593885943636917, disc_loss = 0.016336872724468567
Trained batch 1085 in epoch 0, gen_loss = 1.6594260574265298, disc_loss = 0.016323005240200462
Trained batch 1086 in epoch 0, gen_loss = 1.659609532729134, disc_loss = 0.01630926139923901
Trained batch 1087 in epoch 0, gen_loss = 1.6595070766394628, disc_loss = 0.0162952313079158
Trained batch 1088 in epoch 0, gen_loss = 1.6594101452192547, disc_loss = 0.01628110657490557
Trained batch 1089 in epoch 0, gen_loss = 1.6596860675636782, disc_loss = 0.016267494331413043
Trained batch 1090 in epoch 0, gen_loss = 1.6594887191718264, disc_loss = 0.01625474007765222
Trained batch 1091 in epoch 0, gen_loss = 1.6595002102764536, disc_loss = 0.016241468824557074
Trained batch 1092 in epoch 0, gen_loss = 1.6598780798672104, disc_loss = 0.01622819209881195
Trained batch 1093 in epoch 0, gen_loss = 1.659696901738099, disc_loss = 0.016215555312816852
Trained batch 1094 in epoch 0, gen_loss = 1.659732353523986, disc_loss = 0.016201947637425405
Trained batch 1095 in epoch 0, gen_loss = 1.659605204623981, disc_loss = 0.01618811651441034
Trained batch 1096 in epoch 0, gen_loss = 1.6591622694688377, disc_loss = 0.016184814844502064
Trained batch 1097 in epoch 0, gen_loss = 1.6591044951006364, disc_loss = 0.016175925507840406
Trained batch 1098 in epoch 0, gen_loss = 1.658889651949347, disc_loss = 0.016165249951432092
Trained batch 1099 in epoch 0, gen_loss = 1.6588588076288049, disc_loss = 0.016153384312161838
Trained batch 1100 in epoch 0, gen_loss = 1.6587499688691598, disc_loss = 0.016140455696232733
Trained batch 1101 in epoch 0, gen_loss = 1.65869849563294, disc_loss = 0.016127192961456028
Trained batch 1102 in epoch 0, gen_loss = 1.6587644741952365, disc_loss = 0.01611542787697548
Trained batch 1103 in epoch 0, gen_loss = 1.6586953793530879, disc_loss = 0.01610266483043813
Trained batch 1104 in epoch 0, gen_loss = 1.6583127865424523, disc_loss = 0.01608988300442055
Trained batch 1105 in epoch 0, gen_loss = 1.6586930635393635, disc_loss = 0.0160770513422351
Trained batch 1106 in epoch 0, gen_loss = 1.6583568826923525, disc_loss = 0.016064006934180527
Trained batch 1107 in epoch 0, gen_loss = 1.6584532264122465, disc_loss = 0.016050619612105816
Trained batch 1108 in epoch 0, gen_loss = 1.6583673955084937, disc_loss = 0.016036885498176397
Trained batch 1109 in epoch 0, gen_loss = 1.6582981724996824, disc_loss = 0.01602303676500178
Trained batch 1110 in epoch 0, gen_loss = 1.6580635701934032, disc_loss = 0.016009335277030374
Trained batch 1111 in epoch 0, gen_loss = 1.6581238153383886, disc_loss = 0.015995632662360804
Trained batch 1112 in epoch 0, gen_loss = 1.6581367907605509, disc_loss = 0.01598216954289006
Trained batch 1113 in epoch 0, gen_loss = 1.658057691913961, disc_loss = 0.01596885311285191
Trained batch 1114 in epoch 0, gen_loss = 1.6579202849768737, disc_loss = 0.015955641163792878
Trained batch 1115 in epoch 0, gen_loss = 1.657734829785576, disc_loss = 0.01594294879890521
Trained batch 1116 in epoch 0, gen_loss = 1.6574462919013246, disc_loss = 0.015929598049944368
Trained batch 1117 in epoch 0, gen_loss = 1.6575753154609625, disc_loss = 0.015916185556568974
Trained batch 1118 in epoch 0, gen_loss = 1.6573765342847058, disc_loss = 0.015903797731337398
Trained batch 1119 in epoch 0, gen_loss = 1.6573641058589732, disc_loss = 0.015893006322013598
Trained batch 1120 in epoch 0, gen_loss = 1.657518068559461, disc_loss = 0.01588266855619813
Trained batch 1121 in epoch 0, gen_loss = 1.6579088995800937, disc_loss = 0.015872232336374564
Trained batch 1122 in epoch 0, gen_loss = 1.657735083109549, disc_loss = 0.01586151155965562
Trained batch 1123 in epoch 0, gen_loss = 1.6574461348752534, disc_loss = 0.01585035527358453
Trained batch 1124 in epoch 0, gen_loss = 1.6572376516130236, disc_loss = 0.015839496997857673
Trained batch 1125 in epoch 0, gen_loss = 1.6570913145851285, disc_loss = 0.015828797932154685
Trained batch 1126 in epoch 0, gen_loss = 1.6574210566340448, disc_loss = 0.015817588232133285
Trained batch 1127 in epoch 0, gen_loss = 1.657628578919891, disc_loss = 0.015806502511661668
Trained batch 1128 in epoch 0, gen_loss = 1.657361750057886, disc_loss = 0.015795651622571502
Trained batch 1129 in epoch 0, gen_loss = 1.6569100910583427, disc_loss = 0.015783267542750747
Trained batch 1130 in epoch 0, gen_loss = 1.6567063106044428, disc_loss = 0.01577067901156999
Trained batch 1131 in epoch 0, gen_loss = 1.6563800818717942, disc_loss = 0.015757823813336
Trained batch 1132 in epoch 0, gen_loss = 1.6562987314528947, disc_loss = 0.015745809419639163
Trained batch 1133 in epoch 0, gen_loss = 1.6564094702823242, disc_loss = 0.015733738119352192
Trained batch 1134 in epoch 0, gen_loss = 1.656237968579263, disc_loss = 0.0157224183130316
Trained batch 1135 in epoch 0, gen_loss = 1.6560292544079498, disc_loss = 0.015710742896925707
Trained batch 1136 in epoch 0, gen_loss = 1.656032831708695, disc_loss = 0.015698640107387297
Trained batch 1137 in epoch 0, gen_loss = 1.6558932717529458, disc_loss = 0.015686255591781974
Trained batch 1138 in epoch 0, gen_loss = 1.6560202045750472, disc_loss = 0.015673457520134514
Trained batch 1139 in epoch 0, gen_loss = 1.6561507357839953, disc_loss = 0.01566046300005135
Trained batch 1140 in epoch 0, gen_loss = 1.656194217888333, disc_loss = 0.015648307028168603
Trained batch 1141 in epoch 0, gen_loss = 1.6559526762695111, disc_loss = 0.015635857973883872
Trained batch 1142 in epoch 0, gen_loss = 1.655677437260812, disc_loss = 0.015623374323483657
Trained batch 1143 in epoch 0, gen_loss = 1.655492411001579, disc_loss = 0.015610628904224459
Trained batch 1144 in epoch 0, gen_loss = 1.6553938065033291, disc_loss = 0.015598201774280339
Trained batch 1145 in epoch 0, gen_loss = 1.6552542438681837, disc_loss = 0.015585825865499897
Trained batch 1146 in epoch 0, gen_loss = 1.6550796508996926, disc_loss = 0.015572938290166847
Trained batch 1147 in epoch 0, gen_loss = 1.6547382874771277, disc_loss = 0.015560279964120127
Trained batch 1148 in epoch 0, gen_loss = 1.654468008079562, disc_loss = 0.015548159524519158
Trained batch 1149 in epoch 0, gen_loss = 1.6543986183664072, disc_loss = 0.01553626851011675
Trained batch 1150 in epoch 0, gen_loss = 1.654387112185812, disc_loss = 0.015524202138341261
Trained batch 1151 in epoch 0, gen_loss = 1.6541831258477435, disc_loss = 0.015511481391968118
Trained batch 1152 in epoch 0, gen_loss = 1.6540159456438328, disc_loss = 0.015506997226980972
Trained batch 1153 in epoch 0, gen_loss = 1.6541199284368413, disc_loss = 0.015501602077334102
Trained batch 1154 in epoch 0, gen_loss = 1.653835035712172, disc_loss = 0.015493048776547905
Trained batch 1155 in epoch 0, gen_loss = 1.653504457956367, disc_loss = 0.015480800265086586
Trained batch 1156 in epoch 0, gen_loss = 1.6534815531098441, disc_loss = 0.01546989620176032
Trained batch 1157 in epoch 0, gen_loss = 1.6533502029425533, disc_loss = 0.015457279102543823
Trained batch 1158 in epoch 0, gen_loss = 1.6532221425700744, disc_loss = 0.01544581336789701
Trained batch 1159 in epoch 0, gen_loss = 1.6531615104140907, disc_loss = 0.015433977684608243
Trained batch 1160 in epoch 0, gen_loss = 1.6531024959762994, disc_loss = 0.015422343491323126
Trained batch 1161 in epoch 0, gen_loss = 1.6529929521982518, disc_loss = 0.01540974493980249
Trained batch 1162 in epoch 0, gen_loss = 1.6529754853310097, disc_loss = 0.015398059625137335
Trained batch 1163 in epoch 0, gen_loss = 1.6529067399370712, disc_loss = 0.015387338906843807
Trained batch 1164 in epoch 0, gen_loss = 1.6527972731979108, disc_loss = 0.01537621880510758
Trained batch 1165 in epoch 0, gen_loss = 1.6526262054721446, disc_loss = 0.015364997252499634
Trained batch 1166 in epoch 0, gen_loss = 1.6524736325558986, disc_loss = 0.015353752921872885
Trained batch 1167 in epoch 0, gen_loss = 1.6525958260036495, disc_loss = 0.015342524693850253
Trained batch 1168 in epoch 0, gen_loss = 1.6524912334079922, disc_loss = 0.015331395295115189
Trained batch 1169 in epoch 0, gen_loss = 1.6523535705020285, disc_loss = 0.01532109152037117
Trained batch 1170 in epoch 0, gen_loss = 1.6522218414497212, disc_loss = 0.015309954208692092
Trained batch 1171 in epoch 0, gen_loss = 1.6524310407988447, disc_loss = 0.015297905314439962
Trained batch 1172 in epoch 0, gen_loss = 1.652365220172326, disc_loss = 0.015286350069328974
Trained batch 1173 in epoch 0, gen_loss = 1.6525114424387073, disc_loss = 0.01527506660774558
Trained batch 1174 in epoch 0, gen_loss = 1.6525598259175078, disc_loss = 0.015264152268373823
Trained batch 1175 in epoch 0, gen_loss = 1.652606686159056, disc_loss = 0.015254214720958512
Trained batch 1176 in epoch 0, gen_loss = 1.6523582139254225, disc_loss = 0.015244182670588257
Trained batch 1177 in epoch 0, gen_loss = 1.6525287856877557, disc_loss = 0.01523300775729795
Trained batch 1178 in epoch 0, gen_loss = 1.6521982216450801, disc_loss = 0.015222138490958773
Trained batch 1179 in epoch 0, gen_loss = 1.6518163907325873, disc_loss = 0.015213820837404564
Trained batch 1180 in epoch 0, gen_loss = 1.6518431214535267, disc_loss = 0.015203685689728177
Trained batch 1181 in epoch 0, gen_loss = 1.6518581279643296, disc_loss = 0.015192875086222326
Trained batch 1182 in epoch 0, gen_loss = 1.652149839010263, disc_loss = 0.015182044795513175
Trained batch 1183 in epoch 0, gen_loss = 1.6520018737662483, disc_loss = 0.015171271266808617
Trained batch 1184 in epoch 0, gen_loss = 1.6517453410957432, disc_loss = 0.015159530342283426
Trained batch 1185 in epoch 0, gen_loss = 1.6515276629044273, disc_loss = 0.015147932764238162
Trained batch 1186 in epoch 0, gen_loss = 1.651507268759415, disc_loss = 0.015135831105434152
Trained batch 1187 in epoch 0, gen_loss = 1.651533421843943, disc_loss = 0.015124706876572372
Trained batch 1188 in epoch 0, gen_loss = 1.6514313888710221, disc_loss = 0.015114589346983197
Trained batch 1189 in epoch 0, gen_loss = 1.6515439989186134, disc_loss = 0.015105185914635971
Trained batch 1190 in epoch 0, gen_loss = 1.6516323516991436, disc_loss = 0.015096094697990668
Trained batch 1191 in epoch 0, gen_loss = 1.6515622403997703, disc_loss = 0.015084983794946043
Trained batch 1192 in epoch 0, gen_loss = 1.6513888031519068, disc_loss = 0.015073653316685004
Trained batch 1193 in epoch 0, gen_loss = 1.6511701175715257, disc_loss = 0.01506261194155628
Trained batch 1194 in epoch 0, gen_loss = 1.6511853660998483, disc_loss = 0.015051109903924572
Trained batch 1195 in epoch 0, gen_loss = 1.6512277041589936, disc_loss = 0.015039169505810097
Trained batch 1196 in epoch 0, gen_loss = 1.6511538453966554, disc_loss = 0.015027623408868498
Trained batch 1197 in epoch 0, gen_loss = 1.6509388038431463, disc_loss = 0.015016029544566479
Trained batch 1198 in epoch 0, gen_loss = 1.6509829557767204, disc_loss = 0.015004735300783457
Trained batch 1199 in epoch 0, gen_loss = 1.6510749197006225, disc_loss = 0.014993055347198
Trained batch 1200 in epoch 0, gen_loss = 1.6510050564781018, disc_loss = 0.01498109051214452
Trained batch 1201 in epoch 0, gen_loss = 1.6513208884764432, disc_loss = 0.014969762601326382
Trained batch 1202 in epoch 0, gen_loss = 1.6510730562661948, disc_loss = 0.01495956055363617
Trained batch 1203 in epoch 0, gen_loss = 1.6512407405035836, disc_loss = 0.014948913533696161
Trained batch 1204 in epoch 0, gen_loss = 1.6512038211110223, disc_loss = 0.014937292537854838
Trained batch 1205 in epoch 0, gen_loss = 1.651187885361129, disc_loss = 0.014925936113370761
Trained batch 1206 in epoch 0, gen_loss = 1.650961067820741, disc_loss = 0.014915199802913367
Trained batch 1207 in epoch 0, gen_loss = 1.6509873695326167, disc_loss = 0.014904680662194424
Trained batch 1208 in epoch 0, gen_loss = 1.6510133510586444, disc_loss = 0.01489377744435976
Trained batch 1209 in epoch 0, gen_loss = 1.6511410810730673, disc_loss = 0.014883461893268684
Trained batch 1210 in epoch 0, gen_loss = 1.65082751808828, disc_loss = 0.014875659879505046
Trained batch 1211 in epoch 0, gen_loss = 1.6507428579597976, disc_loss = 0.014869040566031274
Trained batch 1212 in epoch 0, gen_loss = 1.651071977929841, disc_loss = 0.014860033600117784
Trained batch 1213 in epoch 0, gen_loss = 1.6512612509963147, disc_loss = 0.014849371654474402
Trained batch 1214 in epoch 0, gen_loss = 1.651556364989575, disc_loss = 0.014838697864250528
Trained batch 1215 in epoch 0, gen_loss = 1.6520164464845468, disc_loss = 0.014827962120331281
Trained batch 1216 in epoch 0, gen_loss = 1.651989088846017, disc_loss = 0.014817792277478198
Trained batch 1217 in epoch 0, gen_loss = 1.6517389285544848, disc_loss = 0.01480784474741874
Trained batch 1218 in epoch 0, gen_loss = 1.6514736636923022, disc_loss = 0.01479750307702969
Trained batch 1219 in epoch 0, gen_loss = 1.651505087829027, disc_loss = 0.014786660815369659
Trained batch 1220 in epoch 0, gen_loss = 1.6514953315306842, disc_loss = 0.014775449772627397
Trained batch 1221 in epoch 0, gen_loss = 1.6516460800717192, disc_loss = 0.01476490892015082
Trained batch 1222 in epoch 0, gen_loss = 1.6515203539894334, disc_loss = 0.014755424167147974
Trained batch 1223 in epoch 0, gen_loss = 1.6516901367630055, disc_loss = 0.014745919976097735
Trained batch 1224 in epoch 0, gen_loss = 1.6518407843064289, disc_loss = 0.01473542983933561
Trained batch 1225 in epoch 0, gen_loss = 1.651653282210644, disc_loss = 0.014724118808209577
Trained batch 1226 in epoch 0, gen_loss = 1.6519127647956406, disc_loss = 0.01471288130413126
Trained batch 1227 in epoch 0, gen_loss = 1.651945678535424, disc_loss = 0.01470148236085418
Trained batch 1228 in epoch 0, gen_loss = 1.6519279027974538, disc_loss = 0.014691565871489537
Trained batch 1229 in epoch 0, gen_loss = 1.6515164142701684, disc_loss = 0.014695714442040469
Trained batch 1230 in epoch 0, gen_loss = 1.6514599385249915, disc_loss = 0.01469942796542245
Trained batch 1231 in epoch 0, gen_loss = 1.6511445234154727, disc_loss = 0.014694451336206886
Trained batch 1232 in epoch 0, gen_loss = 1.6512289819732877, disc_loss = 0.014699944205010357
Trained batch 1233 in epoch 0, gen_loss = 1.6513298206043399, disc_loss = 0.014715035539478926
Trained batch 1234 in epoch 0, gen_loss = 1.6514601205524646, disc_loss = 0.014711460633192076
Trained batch 1235 in epoch 0, gen_loss = 1.6514841657626205, disc_loss = 0.01470580569407782
Trained batch 1236 in epoch 0, gen_loss = 1.651301013334393, disc_loss = 0.014705294753626598
Trained batch 1237 in epoch 0, gen_loss = 1.651281289599824, disc_loss = 0.014708796326392248
Trained batch 1238 in epoch 0, gen_loss = 1.651189004922702, disc_loss = 0.01470620533302231
Trained batch 1239 in epoch 0, gen_loss = 1.6514359704909787, disc_loss = 0.014696486645111544
Trained batch 1240 in epoch 0, gen_loss = 1.6512891082010568, disc_loss = 0.014688939852080939
Trained batch 1241 in epoch 0, gen_loss = 1.651411739812381, disc_loss = 0.01468019677153991
Trained batch 1242 in epoch 0, gen_loss = 1.6514403786471268, disc_loss = 0.01467013420237038
Trained batch 1243 in epoch 0, gen_loss = 1.6514156254733108, disc_loss = 0.01465948941506119
Trained batch 1244 in epoch 0, gen_loss = 1.6514905998505742, disc_loss = 0.014648877189730306
Trained batch 1245 in epoch 0, gen_loss = 1.6516526218019365, disc_loss = 0.014638091944663353
Trained batch 1246 in epoch 0, gen_loss = 1.6515869038909936, disc_loss = 0.014626943158594863
Trained batch 1247 in epoch 0, gen_loss = 1.6516299413946958, disc_loss = 0.01461643182096267
Trained batch 1248 in epoch 0, gen_loss = 1.651475482792545, disc_loss = 0.014606565948725985
Trained batch 1249 in epoch 0, gen_loss = 1.6513762172698974, disc_loss = 0.014596162620792165
Trained batch 1250 in epoch 0, gen_loss = 1.6511411196131596, disc_loss = 0.014586850474497376
Trained batch 1251 in epoch 0, gen_loss = 1.6510977875500823, disc_loss = 0.01457877641030663
Trained batch 1252 in epoch 0, gen_loss = 1.650969787016927, disc_loss = 0.014568065774263941
Trained batch 1253 in epoch 0, gen_loss = 1.6509512448044674, disc_loss = 0.014558213937515541
Trained batch 1254 in epoch 0, gen_loss = 1.6509336752720563, disc_loss = 0.014549936954557257
Trained batch 1255 in epoch 0, gen_loss = 1.6509103361208728, disc_loss = 0.014540885592031124
Trained batch 1256 in epoch 0, gen_loss = 1.6508448919608845, disc_loss = 0.014530984356092895
Trained batch 1257 in epoch 0, gen_loss = 1.6506931325968575, disc_loss = 0.014521993608267635
Trained batch 1258 in epoch 0, gen_loss = 1.6505313390204601, disc_loss = 0.014512801415505549
Trained batch 1259 in epoch 0, gen_loss = 1.6503033459186554, disc_loss = 0.01450262523781959
Trained batch 1260 in epoch 0, gen_loss = 1.6504591925573386, disc_loss = 0.014493852476602306
Trained batch 1261 in epoch 0, gen_loss = 1.6503418228705597, disc_loss = 0.014485944147568961
Trained batch 1262 in epoch 0, gen_loss = 1.6500766702049419, disc_loss = 0.014476710250824233
Trained batch 1263 in epoch 0, gen_loss = 1.649696108283876, disc_loss = 0.014486834479289945
Trained batch 1264 in epoch 0, gen_loss = 1.6495338223197245, disc_loss = 0.014488531323932038
Trained batch 1265 in epoch 0, gen_loss = 1.649473337953878, disc_loss = 0.014490134380163777
Trained batch 1266 in epoch 0, gen_loss = 1.649335218962479, disc_loss = 0.014480768062180568
Trained batch 1267 in epoch 0, gen_loss = 1.6493156924608754, disc_loss = 0.014472322679561422
Trained batch 1268 in epoch 0, gen_loss = 1.648983726734435, disc_loss = 0.014465910546275015
Trained batch 1269 in epoch 0, gen_loss = 1.6487246689833994, disc_loss = 0.014475681433338657
Trained batch 1270 in epoch 0, gen_loss = 1.6488329895268643, disc_loss = 0.014478354799122652
Trained batch 1271 in epoch 0, gen_loss = 1.6490419864092234, disc_loss = 0.01447341899368685
Trained batch 1272 in epoch 0, gen_loss = 1.6489986407878543, disc_loss = 0.014471329293623113
Trained batch 1273 in epoch 0, gen_loss = 1.6490368808457392, disc_loss = 0.014466649014987067
Trained batch 1274 in epoch 0, gen_loss = 1.6492846116832658, disc_loss = 0.014462424402043005
Trained batch 1275 in epoch 0, gen_loss = 1.6492198077862539, disc_loss = 0.014455229706004288
Trained batch 1276 in epoch 0, gen_loss = 1.6489898168956665, disc_loss = 0.014446931009823727
Trained batch 1277 in epoch 0, gen_loss = 1.648629492810448, disc_loss = 0.014439382805740053
Trained batch 1278 in epoch 0, gen_loss = 1.6486913369352507, disc_loss = 0.014432692158345767
Trained batch 1279 in epoch 0, gen_loss = 1.6487366136163473, disc_loss = 0.014425514745425971
Trained batch 1280 in epoch 0, gen_loss = 1.6488140312421145, disc_loss = 0.014417732897886002
Trained batch 1281 in epoch 0, gen_loss = 1.6490936018933373, disc_loss = 0.01440853561829905
Trained batch 1282 in epoch 0, gen_loss = 1.649326715075403, disc_loss = 0.0143986633007991
Trained batch 1283 in epoch 0, gen_loss = 1.6494105694078582, disc_loss = 0.01439016993739461
Trained batch 1284 in epoch 0, gen_loss = 1.6494221243876892, disc_loss = 0.01438246876411756
Trained batch 1285 in epoch 0, gen_loss = 1.6495234164442654, disc_loss = 0.014375670870281191
Trained batch 1286 in epoch 0, gen_loss = 1.6494331948036545, disc_loss = 0.014373526145787671
Trained batch 1287 in epoch 0, gen_loss = 1.6493939078002242, disc_loss = 0.014365337708480844
Trained batch 1288 in epoch 0, gen_loss = 1.6494957028293535, disc_loss = 0.014356621905275865
Trained batch 1289 in epoch 0, gen_loss = 1.6497626555058382, disc_loss = 0.014346806388646148
Trained batch 1290 in epoch 0, gen_loss = 1.6498273514113069, disc_loss = 0.014339319668577856
Trained batch 1291 in epoch 0, gen_loss = 1.6496678699649894, disc_loss = 0.014329736096355213
Trained batch 1292 in epoch 0, gen_loss = 1.6497041731035627, disc_loss = 0.01431976541802424
Trained batch 1293 in epoch 0, gen_loss = 1.649654454757478, disc_loss = 0.014309503936733824
Trained batch 1294 in epoch 0, gen_loss = 1.6496084158945268, disc_loss = 0.014299503351700165
Trained batch 1295 in epoch 0, gen_loss = 1.6498401857636593, disc_loss = 0.014290095024832371
Trained batch 1296 in epoch 0, gen_loss = 1.6500987156409894, disc_loss = 0.014280888362496491
Trained batch 1297 in epoch 0, gen_loss = 1.6502922397732551, disc_loss = 0.014272207241548075
Trained batch 1298 in epoch 0, gen_loss = 1.6501764483044383, disc_loss = 0.014262194956878301
Trained batch 1299 in epoch 0, gen_loss = 1.6501460918096396, disc_loss = 0.014251932785085115
Trained batch 1300 in epoch 0, gen_loss = 1.6499567204122814, disc_loss = 0.01424203781323539
Trained batch 1301 in epoch 0, gen_loss = 1.650162955766083, disc_loss = 0.014234085763064635
Trained batch 1302 in epoch 0, gen_loss = 1.6502804068172334, disc_loss = 0.014226233995284068
Trained batch 1303 in epoch 0, gen_loss = 1.6502716872224048, disc_loss = 0.01421710440957386
Trained batch 1304 in epoch 0, gen_loss = 1.6503883370037737, disc_loss = 0.01420717371410915
Trained batch 1305 in epoch 0, gen_loss = 1.6502274981319083, disc_loss = 0.014197450515945695
Trained batch 1306 in epoch 0, gen_loss = 1.6501344275456307, disc_loss = 0.014188421381412639
Trained batch 1307 in epoch 0, gen_loss = 1.6499057146934195, disc_loss = 0.014183088170910263
Trained batch 1308 in epoch 0, gen_loss = 1.64973711011244, disc_loss = 0.014173989977719258
Trained batch 1309 in epoch 0, gen_loss = 1.649752002453986, disc_loss = 0.014165536953244743
Trained batch 1310 in epoch 0, gen_loss = 1.6497424758180783, disc_loss = 0.014157216547919802
Trained batch 1311 in epoch 0, gen_loss = 1.649793942254491, disc_loss = 0.014147922594929696
Trained batch 1312 in epoch 0, gen_loss = 1.6496342331602296, disc_loss = 0.014139108856196918
Trained batch 1313 in epoch 0, gen_loss = 1.6494510191942096, disc_loss = 0.014129270911399244
Trained batch 1314 in epoch 0, gen_loss = 1.6494264398690865, disc_loss = 0.014120304645012582
Trained batch 1315 in epoch 0, gen_loss = 1.6495245569201589, disc_loss = 0.01411057971831019
Trained batch 1316 in epoch 0, gen_loss = 1.6494790637864247, disc_loss = 0.014100646143879928
Trained batch 1317 in epoch 0, gen_loss = 1.6495609230987942, disc_loss = 0.014091261806648736
Trained batch 1318 in epoch 0, gen_loss = 1.649509922494664, disc_loss = 0.014081505812548165
Trained batch 1319 in epoch 0, gen_loss = 1.649225700172511, disc_loss = 0.014072724605361917
Trained batch 1320 in epoch 0, gen_loss = 1.6489245884351709, disc_loss = 0.014063329335640874
Trained batch 1321 in epoch 0, gen_loss = 1.6489975694989654, disc_loss = 0.014053685441671317
Trained batch 1322 in epoch 0, gen_loss = 1.648959505404835, disc_loss = 0.01404502903902692
Trained batch 1323 in epoch 0, gen_loss = 1.6488374935356152, disc_loss = 0.01403549303051142
Trained batch 1324 in epoch 0, gen_loss = 1.6488186203758672, disc_loss = 0.014025935821349398
Trained batch 1325 in epoch 0, gen_loss = 1.648997437900008, disc_loss = 0.01401648565367051
Trained batch 1326 in epoch 0, gen_loss = 1.648873014924395, disc_loss = 0.014007385202149069
Trained batch 1327 in epoch 0, gen_loss = 1.648623439741422, disc_loss = 0.013998289325852046
Trained batch 1328 in epoch 0, gen_loss = 1.6487640607975944, disc_loss = 0.013988616749245892
Trained batch 1329 in epoch 0, gen_loss = 1.6486428083333755, disc_loss = 0.013979739182640945
Trained batch 1330 in epoch 0, gen_loss = 1.6488120196727234, disc_loss = 0.013970590517326145
Trained batch 1331 in epoch 0, gen_loss = 1.6484610593175746, disc_loss = 0.013963367199473147
Trained batch 1332 in epoch 0, gen_loss = 1.6485831615000135, disc_loss = 0.013957320645041777
Trained batch 1333 in epoch 0, gen_loss = 1.648405229044461, disc_loss = 0.01394972582608622
Trained batch 1334 in epoch 0, gen_loss = 1.6485210170460105, disc_loss = 0.013940607708545702
Trained batch 1335 in epoch 0, gen_loss = 1.648215089550989, disc_loss = 0.013931192954924463
Trained batch 1336 in epoch 0, gen_loss = 1.6482545749055153, disc_loss = 0.013921706926674222
Trained batch 1337 in epoch 0, gen_loss = 1.6481739458125446, disc_loss = 0.013912823043079066
Trained batch 1338 in epoch 0, gen_loss = 1.6479388655255853, disc_loss = 0.013904889536260949
Trained batch 1339 in epoch 0, gen_loss = 1.6479818425961394, disc_loss = 0.01389588692487016
Trained batch 1340 in epoch 0, gen_loss = 1.6479153536221236, disc_loss = 0.013886277918454877
Trained batch 1341 in epoch 0, gen_loss = 1.647977244125571, disc_loss = 0.013877074437827668
Trained batch 1342 in epoch 0, gen_loss = 1.6477708961212716, disc_loss = 0.013867669422392702
Trained batch 1343 in epoch 0, gen_loss = 1.647618369421079, disc_loss = 0.01385835574326068
Trained batch 1344 in epoch 0, gen_loss = 1.6475788837028702, disc_loss = 0.013850023602369175
Trained batch 1345 in epoch 0, gen_loss = 1.647482922048838, disc_loss = 0.013840417300242333
Trained batch 1346 in epoch 0, gen_loss = 1.6473804807875363, disc_loss = 0.013831078506654935
Trained batch 1347 in epoch 0, gen_loss = 1.647333750296771, disc_loss = 0.013821551115690793
Trained batch 1348 in epoch 0, gen_loss = 1.6471228637546853, disc_loss = 0.013812571145843347
Trained batch 1349 in epoch 0, gen_loss = 1.647056472654696, disc_loss = 0.013804430314770865
Trained batch 1350 in epoch 0, gen_loss = 1.6470462718246426, disc_loss = 0.01379507339446096
Trained batch 1351 in epoch 0, gen_loss = 1.6468267453140055, disc_loss = 0.01378561486593398
Trained batch 1352 in epoch 0, gen_loss = 1.6470761055075849, disc_loss = 0.013776107205002977
Trained batch 1353 in epoch 0, gen_loss = 1.647074598329282, disc_loss = 0.013766581888396245
Trained batch 1354 in epoch 0, gen_loss = 1.647066711939569, disc_loss = 0.01375694123162919
Trained batch 1355 in epoch 0, gen_loss = 1.6468911443488083, disc_loss = 0.013747452261126572
Trained batch 1356 in epoch 0, gen_loss = 1.6468378592697064, disc_loss = 0.013738170243717672
Trained batch 1357 in epoch 0, gen_loss = 1.647010804276052, disc_loss = 0.013729185967996582
Trained batch 1358 in epoch 0, gen_loss = 1.6469435732183955, disc_loss = 0.013719915250335793
Trained batch 1359 in epoch 0, gen_loss = 1.646796852350235, disc_loss = 0.013710515861063921
Trained batch 1360 in epoch 0, gen_loss = 1.646638618156719, disc_loss = 0.013701115557258439
Trained batch 1361 in epoch 0, gen_loss = 1.6467794779463836, disc_loss = 0.013692164715188358
Trained batch 1362 in epoch 0, gen_loss = 1.6466950153657294, disc_loss = 0.013682865229924158
Trained batch 1363 in epoch 0, gen_loss = 1.6466765228079911, disc_loss = 0.013673597775084579
Trained batch 1364 in epoch 0, gen_loss = 1.646590934218941, disc_loss = 0.013664086659152348
Trained batch 1365 in epoch 0, gen_loss = 1.6467934772699504, disc_loss = 0.01365462035832328
Trained batch 1366 in epoch 0, gen_loss = 1.6466534120284821, disc_loss = 0.013645154282175775
Trained batch 1367 in epoch 0, gen_loss = 1.646660245388572, disc_loss = 0.013636534438189052
Trained batch 1368 in epoch 0, gen_loss = 1.6465173833469477, disc_loss = 0.013627538473967468
Trained batch 1369 in epoch 0, gen_loss = 1.6464655232255476, disc_loss = 0.013618506213954317
Trained batch 1370 in epoch 0, gen_loss = 1.6464837207835925, disc_loss = 0.013609381903220717
Trained batch 1371 in epoch 0, gen_loss = 1.6464731284897807, disc_loss = 0.013600411661926035
Trained batch 1372 in epoch 0, gen_loss = 1.6465315188444711, disc_loss = 0.01359098991987927
Trained batch 1373 in epoch 0, gen_loss = 1.6462619526764537, disc_loss = 0.013582365956680043
Trained batch 1374 in epoch 0, gen_loss = 1.6459377608732744, disc_loss = 0.013574179404753852
Trained batch 1375 in epoch 0, gen_loss = 1.6457544656167196, disc_loss = 0.013565202941864236
Trained batch 1376 in epoch 0, gen_loss = 1.6455912441989176, disc_loss = 0.013556127497498906
Trained batch 1377 in epoch 0, gen_loss = 1.645454530878579, disc_loss = 0.013547064164715598
Trained batch 1378 in epoch 0, gen_loss = 1.6452258464821532, disc_loss = 0.013537831695738875
Trained batch 1379 in epoch 0, gen_loss = 1.645055089480635, disc_loss = 0.013528616285369988
Trained batch 1380 in epoch 0, gen_loss = 1.6450037861284703, disc_loss = 0.013519448665601919
Trained batch 1381 in epoch 0, gen_loss = 1.6448503888809216, disc_loss = 0.013510666166209143
Trained batch 1382 in epoch 0, gen_loss = 1.644735757630542, disc_loss = 0.013501230050819445
Trained batch 1383 in epoch 0, gen_loss = 1.6448560694738619, disc_loss = 0.013491967847785103
Trained batch 1384 in epoch 0, gen_loss = 1.644695041239907, disc_loss = 0.01348315453419919
Trained batch 1385 in epoch 0, gen_loss = 1.6445145776433518, disc_loss = 0.013475245381424923
Trained batch 1386 in epoch 0, gen_loss = 1.6446203598463889, disc_loss = 0.013467777167772909
Trained batch 1387 in epoch 0, gen_loss = 1.6444638449623536, disc_loss = 0.013459621525749695
Trained batch 1388 in epoch 0, gen_loss = 1.6445403511014407, disc_loss = 0.0134508498070431
Trained batch 1389 in epoch 0, gen_loss = 1.6449659579091793, disc_loss = 0.013442230383947613
Trained batch 1390 in epoch 0, gen_loss = 1.645061807783279, disc_loss = 0.013433289594017973
Trained batch 1391 in epoch 0, gen_loss = 1.6450043113409787, disc_loss = 0.013424489283059449
Trained batch 1392 in epoch 0, gen_loss = 1.6450271202520081, disc_loss = 0.013415260702754022
Trained batch 1393 in epoch 0, gen_loss = 1.6450721547114455, disc_loss = 0.013406274263253316
Trained batch 1394 in epoch 0, gen_loss = 1.6449762986979604, disc_loss = 0.013397048439790485
Trained batch 1395 in epoch 0, gen_loss = 1.6448121382547995, disc_loss = 0.013387914435280203
Trained batch 1396 in epoch 0, gen_loss = 1.6445951538591106, disc_loss = 0.013378788458635736
Trained batch 1397 in epoch 0, gen_loss = 1.6446280154547466, disc_loss = 0.013370441009338149
Trained batch 1398 in epoch 0, gen_loss = 1.6445416656879974, disc_loss = 0.01336263423182937
Trained batch 1399 in epoch 0, gen_loss = 1.6445895645448139, disc_loss = 0.01335413540152201
Trained batch 1400 in epoch 0, gen_loss = 1.6446202135698698, disc_loss = 0.013345241897912639
Trained batch 1401 in epoch 0, gen_loss = 1.6445708429592312, disc_loss = 0.01333626943994805
Trained batch 1402 in epoch 0, gen_loss = 1.6445616159112812, disc_loss = 0.013327624097765845
Trained batch 1403 in epoch 0, gen_loss = 1.644548637659801, disc_loss = 0.013319035425040595
Trained batch 1404 in epoch 0, gen_loss = 1.6443552252236635, disc_loss = 0.013310180004815375
Trained batch 1405 in epoch 0, gen_loss = 1.6445204590157119, disc_loss = 0.013302189815053544
Trained batch 1406 in epoch 0, gen_loss = 1.6443531703847303, disc_loss = 0.013294808354838364
Trained batch 1407 in epoch 0, gen_loss = 1.644524840722707, disc_loss = 0.01328787683045944
Trained batch 1408 in epoch 0, gen_loss = 1.644668194653719, disc_loss = 0.013281441463446383
Trained batch 1409 in epoch 0, gen_loss = 1.6444632657030795, disc_loss = 0.013274437243511888
Trained batch 1410 in epoch 0, gen_loss = 1.6445696446846598, disc_loss = 0.01326609719617254
Trained batch 1411 in epoch 0, gen_loss = 1.644475378159423, disc_loss = 0.01325774933679805
Trained batch 1412 in epoch 0, gen_loss = 1.6446532216041712, disc_loss = 0.01324897681782121
Trained batch 1413 in epoch 0, gen_loss = 1.6444010581120405, disc_loss = 0.013240314811129581
Trained batch 1414 in epoch 0, gen_loss = 1.6443170669643281, disc_loss = 0.01323240361976118
Trained batch 1415 in epoch 0, gen_loss = 1.644436553373175, disc_loss = 0.013224268202471946
Trained batch 1416 in epoch 0, gen_loss = 1.6443937223565015, disc_loss = 0.013215498806351379
Trained batch 1417 in epoch 0, gen_loss = 1.6444405488806484, disc_loss = 0.01320659655703912
Trained batch 1418 in epoch 0, gen_loss = 1.6444309630639289, disc_loss = 0.01319787976344479
Trained batch 1419 in epoch 0, gen_loss = 1.644388270546013, disc_loss = 0.013189038792280743
Trained batch 1420 in epoch 0, gen_loss = 1.6441854633637334, disc_loss = 0.013180533964970109
Trained batch 1421 in epoch 0, gen_loss = 1.6442337725232925, disc_loss = 0.01317248832838513
Trained batch 1422 in epoch 0, gen_loss = 1.644118430659709, disc_loss = 0.01316409067379066
Trained batch 1423 in epoch 0, gen_loss = 1.6441399672727905, disc_loss = 0.013155551681071362
Trained batch 1424 in epoch 0, gen_loss = 1.6444135542083205, disc_loss = 0.013147764739400724
Trained batch 1425 in epoch 0, gen_loss = 1.6444100109758417, disc_loss = 0.013139322619208593
Trained batch 1426 in epoch 0, gen_loss = 1.6445828312831736, disc_loss = 0.013131196328279573
Trained batch 1427 in epoch 0, gen_loss = 1.6443896758623149, disc_loss = 0.013124259938704403
Trained batch 1428 in epoch 0, gen_loss = 1.6441553690952384, disc_loss = 0.01311905813532796
Trained batch 1429 in epoch 0, gen_loss = 1.6440697432397962, disc_loss = 0.013112463497546977
Trained batch 1430 in epoch 0, gen_loss = 1.6440209146982137, disc_loss = 0.013104144814176905
Trained batch 1431 in epoch 0, gen_loss = 1.643786099786199, disc_loss = 0.013095937316860696
Trained batch 1432 in epoch 0, gen_loss = 1.6436771044594711, disc_loss = 0.013087950228253317
Trained batch 1433 in epoch 0, gen_loss = 1.6435880651866375, disc_loss = 0.013079841976311199
Trained batch 1434 in epoch 0, gen_loss = 1.6437572048100861, disc_loss = 0.013072779135882387
Trained batch 1435 in epoch 0, gen_loss = 1.643702197124699, disc_loss = 0.013064499263143204
Trained batch 1436 in epoch 0, gen_loss = 1.6437221080292905, disc_loss = 0.01305695762306908
Trained batch 1437 in epoch 0, gen_loss = 1.6436168605329595, disc_loss = 0.013049179507968028
Trained batch 1438 in epoch 0, gen_loss = 1.6435884256343034, disc_loss = 0.013040918691499292
Trained batch 1439 in epoch 0, gen_loss = 1.643440742459562, disc_loss = 0.013032318266778021
Trained batch 1440 in epoch 0, gen_loss = 1.6434434031877643, disc_loss = 0.013023759872283552
Trained batch 1441 in epoch 0, gen_loss = 1.6432203323103685, disc_loss = 0.013015169756720811
Trained batch 1442 in epoch 0, gen_loss = 1.6433381622067278, disc_loss = 0.013006839600852506
Trained batch 1443 in epoch 0, gen_loss = 1.6434174804971489, disc_loss = 0.012998704137435374
Trained batch 1444 in epoch 0, gen_loss = 1.6433666592238272, disc_loss = 0.012990474349184277
Trained batch 1445 in epoch 0, gen_loss = 1.6433814902523247, disc_loss = 0.012981859226635417
Trained batch 1446 in epoch 0, gen_loss = 1.6433874822602077, disc_loss = 0.012973543382792024
Trained batch 1447 in epoch 0, gen_loss = 1.6432108939187962, disc_loss = 0.012965500864686858
Trained batch 1448 in epoch 0, gen_loss = 1.6431681667219942, disc_loss = 0.012957456965217003
Trained batch 1449 in epoch 0, gen_loss = 1.643068794217603, disc_loss = 0.01294911346847898
Trained batch 1450 in epoch 0, gen_loss = 1.6429011872683945, disc_loss = 0.012940755607982293
Trained batch 1451 in epoch 0, gen_loss = 1.6428422936066451, disc_loss = 0.012933017028447243
Trained batch 1452 in epoch 0, gen_loss = 1.6428205448434177, disc_loss = 0.012925449842293872
Trained batch 1453 in epoch 0, gen_loss = 1.6427453905548977, disc_loss = 0.012917104497239021
Trained batch 1454 in epoch 0, gen_loss = 1.6426913446577145, disc_loss = 0.012909474475525281
Trained batch 1455 in epoch 0, gen_loss = 1.6423825644529784, disc_loss = 0.012902565154425767
Trained batch 1456 in epoch 0, gen_loss = 1.642250040171485, disc_loss = 0.012895588054299014
Trained batch 1457 in epoch 0, gen_loss = 1.6420307093196445, disc_loss = 0.012887500426072477
Trained batch 1458 in epoch 0, gen_loss = 1.6419220163529666, disc_loss = 0.012879339087908644
Trained batch 1459 in epoch 0, gen_loss = 1.6419760798754757, disc_loss = 0.012871463338354896
Trained batch 1460 in epoch 0, gen_loss = 1.641818133141389, disc_loss = 0.012863222001251763
Trained batch 1461 in epoch 0, gen_loss = 1.6415880165087051, disc_loss = 0.012855244457572648
Trained batch 1462 in epoch 0, gen_loss = 1.6414151357936273, disc_loss = 0.012846861008133915
Trained batch 1463 in epoch 0, gen_loss = 1.6413043791153392, disc_loss = 0.012838752649616656
Trained batch 1464 in epoch 0, gen_loss = 1.6411621956288205, disc_loss = 0.012830830541949516
Trained batch 1465 in epoch 0, gen_loss = 1.6410307613433952, disc_loss = 0.012822574350918105
Trained batch 1466 in epoch 0, gen_loss = 1.6408413752618904, disc_loss = 0.012814752937687513
Trained batch 1467 in epoch 0, gen_loss = 1.640728643463483, disc_loss = 0.012806498941525116
Trained batch 1468 in epoch 0, gen_loss = 1.640818391712934, disc_loss = 0.012798265330452242
Trained batch 1469 in epoch 0, gen_loss = 1.640669203615513, disc_loss = 0.012790334084448183
Trained batch 1470 in epoch 0, gen_loss = 1.6403176606228205, disc_loss = 0.012782383272183754
Trained batch 1471 in epoch 0, gen_loss = 1.6403599035642717, disc_loss = 0.012774727000799865
Trained batch 1472 in epoch 0, gen_loss = 1.6402470441554082, disc_loss = 0.012766945455523647
Trained batch 1473 in epoch 0, gen_loss = 1.6401450356602507, disc_loss = 0.012759141626738118
Trained batch 1474 in epoch 0, gen_loss = 1.6400195239762128, disc_loss = 0.01275103297127979
Trained batch 1475 in epoch 0, gen_loss = 1.6398900349934895, disc_loss = 0.012743194270896383
Trained batch 1476 in epoch 0, gen_loss = 1.6397530680664827, disc_loss = 0.012736712502132465
Trained batch 1477 in epoch 0, gen_loss = 1.6394446328463832, disc_loss = 0.012730286892808165
Trained batch 1478 in epoch 0, gen_loss = 1.63945175281161, disc_loss = 0.01272294389352705
Trained batch 1479 in epoch 0, gen_loss = 1.6395855375238366, disc_loss = 0.012716295004222932
Trained batch 1480 in epoch 0, gen_loss = 1.639422367184167, disc_loss = 0.01270962542703169
Trained batch 1481 in epoch 0, gen_loss = 1.639242271260533, disc_loss = 0.01270233134184675
Trained batch 1482 in epoch 0, gen_loss = 1.6393908785551847, disc_loss = 0.012694830008613201
Trained batch 1483 in epoch 0, gen_loss = 1.6390924527638684, disc_loss = 0.01268796319504566
Trained batch 1484 in epoch 0, gen_loss = 1.6389384128429272, disc_loss = 0.012681810139962205
Trained batch 1485 in epoch 0, gen_loss = 1.6387985020595155, disc_loss = 0.012674381579596782
Trained batch 1486 in epoch 0, gen_loss = 1.6385904105621933, disc_loss = 0.012666913240475652
Trained batch 1487 in epoch 0, gen_loss = 1.6386984160510443, disc_loss = 0.012659176168326472
Trained batch 1488 in epoch 0, gen_loss = 1.6384633946851086, disc_loss = 0.01265114487669211
Trained batch 1489 in epoch 0, gen_loss = 1.6384899509833164, disc_loss = 0.012643495996032636
Trained batch 1490 in epoch 0, gen_loss = 1.6384591623730982, disc_loss = 0.01263559134253866
Trained batch 1491 in epoch 0, gen_loss = 1.6384035717226544, disc_loss = 0.0126278492644393
Trained batch 1492 in epoch 0, gen_loss = 1.6382700685518985, disc_loss = 0.012620573096901767
Trained batch 1493 in epoch 0, gen_loss = 1.638234977581734, disc_loss = 0.012612788508714138
Trained batch 1494 in epoch 0, gen_loss = 1.6382534025504836, disc_loss = 0.012605450083937708
Trained batch 1495 in epoch 0, gen_loss = 1.6381288440151012, disc_loss = 0.012598103137744746
Trained batch 1496 in epoch 0, gen_loss = 1.6378882808054616, disc_loss = 0.012590306936470827
Trained batch 1497 in epoch 0, gen_loss = 1.637735387591399, disc_loss = 0.01258238800342825
Trained batch 1498 in epoch 0, gen_loss = 1.6376752512227541, disc_loss = 0.012574860905427573
Trained batch 1499 in epoch 0, gen_loss = 1.637631430943807, disc_loss = 0.012567146565997974
Trained batch 1500 in epoch 0, gen_loss = 1.637460078977093, disc_loss = 0.01255926858450098
Trained batch 1501 in epoch 0, gen_loss = 1.637660968478288, disc_loss = 0.012551495516049576
Trained batch 1502 in epoch 0, gen_loss = 1.6375389677321839, disc_loss = 0.012544347205433527
Trained batch 1503 in epoch 0, gen_loss = 1.6374919322576929, disc_loss = 0.012538255381591722
Trained batch 1504 in epoch 0, gen_loss = 1.637442653440558, disc_loss = 0.012531282112042595
Trained batch 1505 in epoch 0, gen_loss = 1.6375007886652295, disc_loss = 0.012523871374342486
Trained batch 1506 in epoch 0, gen_loss = 1.6374306822740723, disc_loss = 0.012515996735915047
Trained batch 1507 in epoch 0, gen_loss = 1.6375882970243296, disc_loss = 0.012508573781004773
Trained batch 1508 in epoch 0, gen_loss = 1.637533044641266, disc_loss = 0.012501070966062768
Trained batch 1509 in epoch 0, gen_loss = 1.6373931703188562, disc_loss = 0.012494117949953587
Trained batch 1510 in epoch 0, gen_loss = 1.637349310180038, disc_loss = 0.012486903263474146
Trained batch 1511 in epoch 0, gen_loss = 1.637346483412243, disc_loss = 0.012480175427361958
Trained batch 1512 in epoch 0, gen_loss = 1.6373519520056776, disc_loss = 0.01247310842050674
Trained batch 1513 in epoch 0, gen_loss = 1.6372352205462941, disc_loss = 0.012465551161684608
Trained batch 1514 in epoch 0, gen_loss = 1.637320349004009, disc_loss = 0.012457800325676307
Trained batch 1515 in epoch 0, gen_loss = 1.637265664291885, disc_loss = 0.01245040292246513
Trained batch 1516 in epoch 0, gen_loss = 1.6370674816494957, disc_loss = 0.012442961625875163
Trained batch 1517 in epoch 0, gen_loss = 1.6370252286806721, disc_loss = 0.012435188588296089
Trained batch 1518 in epoch 0, gen_loss = 1.6369415164543186, disc_loss = 0.012427584429900268
Trained batch 1519 in epoch 0, gen_loss = 1.6367353575794321, disc_loss = 0.012420226367899695
Trained batch 1520 in epoch 0, gen_loss = 1.636493843688062, disc_loss = 0.012414576943875287
Trained batch 1521 in epoch 0, gen_loss = 1.6364460151236255, disc_loss = 0.01241045889123245
Trained batch 1522 in epoch 0, gen_loss = 1.6361975269104725, disc_loss = 0.012404417571526398
Trained batch 1523 in epoch 0, gen_loss = 1.6362932813292725, disc_loss = 0.0123970661780371
Trained batch 1524 in epoch 0, gen_loss = 1.6362042967217867, disc_loss = 0.01238968574934349
Trained batch 1525 in epoch 0, gen_loss = 1.6361467982807134, disc_loss = 0.012382053484464904
Trained batch 1526 in epoch 0, gen_loss = 1.63634567379405, disc_loss = 0.01237455057910355
Trained batch 1527 in epoch 0, gen_loss = 1.6363937567665938, disc_loss = 0.012366977060492229
Trained batch 1528 in epoch 0, gen_loss = 1.6365197981160167, disc_loss = 0.012359368522039952
Trained batch 1529 in epoch 0, gen_loss = 1.6364602748864616, disc_loss = 0.012351899681265885
Trained batch 1530 in epoch 0, gen_loss = 1.6363690157173352, disc_loss = 0.012344536093379365
Trained batch 1531 in epoch 0, gen_loss = 1.6364832234133628, disc_loss = 0.012337063067641617
Trained batch 1532 in epoch 0, gen_loss = 1.6367134106213643, disc_loss = 0.012329393991599356
Trained batch 1533 in epoch 0, gen_loss = 1.6367459974823595, disc_loss = 0.01232188274974466
Trained batch 1534 in epoch 0, gen_loss = 1.6365845097781004, disc_loss = 0.01231448354153266
Trained batch 1535 in epoch 0, gen_loss = 1.6365437196412433, disc_loss = 0.01230716222899749
Trained batch 1536 in epoch 0, gen_loss = 1.636532754113167, disc_loss = 0.012299559973206047
Trained batch 1537 in epoch 0, gen_loss = 1.636238197433933, disc_loss = 0.012291946525365157
Trained batch 1538 in epoch 0, gen_loss = 1.6360695701361168, disc_loss = 0.0122847000390831
Trained batch 1539 in epoch 0, gen_loss = 1.635852903359896, disc_loss = 0.012277423819850574
Trained batch 1540 in epoch 0, gen_loss = 1.6359516108368681, disc_loss = 0.012270395971044758
Trained batch 1541 in epoch 0, gen_loss = 1.6357880727171743, disc_loss = 0.012263104776778149
Trained batch 1542 in epoch 0, gen_loss = 1.6354763422859078, disc_loss = 0.012256031019983744
Trained batch 1543 in epoch 0, gen_loss = 1.6353963536302043, disc_loss = 0.012248701977825825
Trained batch 1544 in epoch 0, gen_loss = 1.6352975984221523, disc_loss = 0.012241493035816139
Trained batch 1545 in epoch 0, gen_loss = 1.635280033595195, disc_loss = 0.01223417369120653
Trained batch 1546 in epoch 0, gen_loss = 1.6350707764308068, disc_loss = 0.012227449084699223
Trained batch 1547 in epoch 0, gen_loss = 1.634882025324405, disc_loss = 0.012220582833523544
Trained batch 1548 in epoch 0, gen_loss = 1.6347310814725113, disc_loss = 0.012213622591465176
Trained batch 1549 in epoch 0, gen_loss = 1.6347163293438574, disc_loss = 0.012206428231739048
Trained batch 1550 in epoch 0, gen_loss = 1.6345698957209585, disc_loss = 0.012199486097716322
Trained batch 1551 in epoch 0, gen_loss = 1.63452113289194, disc_loss = 0.01219245178233286
Trained batch 1552 in epoch 0, gen_loss = 1.6343620405301538, disc_loss = 0.012185409712296038
Trained batch 1553 in epoch 0, gen_loss = 1.634088160755398, disc_loss = 0.012178323231450195
Trained batch 1554 in epoch 0, gen_loss = 1.6340917814199565, disc_loss = 0.012172469162192027
Trained batch 1555 in epoch 0, gen_loss = 1.6338315390069564, disc_loss = 0.012166795747527904
Trained batch 1556 in epoch 0, gen_loss = 1.6336219079538883, disc_loss = 0.01216015799772431
Trained batch 1557 in epoch 0, gen_loss = 1.6336569879419232, disc_loss = 0.01215360180616937
Trained batch 1558 in epoch 0, gen_loss = 1.6334751467432558, disc_loss = 0.012146838264104643
Trained batch 1559 in epoch 0, gen_loss = 1.6335131651315933, disc_loss = 0.012139675379036747
Trained batch 1560 in epoch 0, gen_loss = 1.6333925079489884, disc_loss = 0.012132982958520153
Trained batch 1561 in epoch 0, gen_loss = 1.6334227833338797, disc_loss = 0.012126794875703487
Trained batch 1562 in epoch 0, gen_loss = 1.6333523261875047, disc_loss = 0.012120531809685177
Trained batch 1563 in epoch 0, gen_loss = 1.6331445000055806, disc_loss = 0.012114007221607794
Trained batch 1564 in epoch 0, gen_loss = 1.6330905624091054, disc_loss = 0.012106800827267655
Trained batch 1565 in epoch 0, gen_loss = 1.6329813735847425, disc_loss = 0.012099759799101488
Trained batch 1566 in epoch 0, gen_loss = 1.6326922602005345, disc_loss = 0.012092460813373743
Trained batch 1567 in epoch 0, gen_loss = 1.6325114100259177, disc_loss = 0.01208559085638886
Trained batch 1568 in epoch 0, gen_loss = 1.6326628578476574, disc_loss = 0.012079140046349364
Trained batch 1569 in epoch 0, gen_loss = 1.6324615397271078, disc_loss = 0.012071874180948065
Trained batch 1570 in epoch 0, gen_loss = 1.6324342892930281, disc_loss = 0.012064728362316516
Trained batch 1571 in epoch 0, gen_loss = 1.6325778185411264, disc_loss = 0.012057673456440572
Trained batch 1572 in epoch 0, gen_loss = 1.6325330369728657, disc_loss = 0.012050451143619292
Trained batch 1573 in epoch 0, gen_loss = 1.6324598661220362, disc_loss = 0.012043423099967554
Trained batch 1574 in epoch 0, gen_loss = 1.6324372702553158, disc_loss = 0.012036448393667501
Trained batch 1575 in epoch 0, gen_loss = 1.632533847907473, disc_loss = 0.01202925925899024
Trained batch 1576 in epoch 0, gen_loss = 1.6325840863836818, disc_loss = 0.012021919631406006
Trained batch 1577 in epoch 0, gen_loss = 1.6323974350861572, disc_loss = 0.012014803471430576
Trained batch 1578 in epoch 0, gen_loss = 1.6325155101749549, disc_loss = 0.012007923497403473
Trained batch 1579 in epoch 0, gen_loss = 1.632425282650356, disc_loss = 0.01200141160099773
Trained batch 1580 in epoch 0, gen_loss = 1.632496584751122, disc_loss = 0.011994464215676723
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 1.9960055351257324, disc_loss = 0.0007953790482133627
Trained batch 1 in epoch 1, gen_loss = 1.9789026975631714, disc_loss = 0.0007446532254107296
Trained batch 2 in epoch 1, gen_loss = 1.836859663327535, disc_loss = 0.000754389155190438
Trained batch 3 in epoch 1, gen_loss = 1.692708820104599, disc_loss = 0.0007912170112831518
Trained batch 4 in epoch 1, gen_loss = 1.648045039176941, disc_loss = 0.0008002606802619994
Trained batch 5 in epoch 1, gen_loss = 1.6485954920450847, disc_loss = 0.0007519524175828943
Trained batch 6 in epoch 1, gen_loss = 1.5857655661446708, disc_loss = 0.0007527777509364698
Trained batch 7 in epoch 1, gen_loss = 1.555405616760254, disc_loss = 0.0008381437146454118
Trained batch 8 in epoch 1, gen_loss = 1.5947399801678128, disc_loss = 0.0008212192462653749
Trained batch 9 in epoch 1, gen_loss = 1.577802264690399, disc_loss = 0.0008527529484126717
Trained batch 10 in epoch 1, gen_loss = 1.5731802528554744, disc_loss = 0.000867295719217509
Trained batch 11 in epoch 1, gen_loss = 1.5611112018426259, disc_loss = 0.0008893382667641466
Trained batch 12 in epoch 1, gen_loss = 1.547361997457651, disc_loss = 0.000874754439931936
Trained batch 13 in epoch 1, gen_loss = 1.5323703459330968, disc_loss = 0.0009207001962100289
Trained batch 14 in epoch 1, gen_loss = 1.5425303300221762, disc_loss = 0.0009507533667298655
Trained batch 15 in epoch 1, gen_loss = 1.5450662896037102, disc_loss = 0.0009334846945421305
Trained batch 16 in epoch 1, gen_loss = 1.5333672481424667, disc_loss = 0.000919927260838449
Trained batch 17 in epoch 1, gen_loss = 1.5316205355856154, disc_loss = 0.0009097378093024923
Trained batch 18 in epoch 1, gen_loss = 1.5334945791646053, disc_loss = 0.000883407288806905
Trained batch 19 in epoch 1, gen_loss = 1.5407098472118377, disc_loss = 0.0008595101098762825
Trained batch 20 in epoch 1, gen_loss = 1.5397114810489474, disc_loss = 0.0008458371628962812
Trained batch 21 in epoch 1, gen_loss = 1.538777855309573, disc_loss = 0.0008623928508975289
Trained batch 22 in epoch 1, gen_loss = 1.534196376800537, disc_loss = 0.0008693256506534374
Trained batch 23 in epoch 1, gen_loss = 1.5242308874924977, disc_loss = 0.0008524417450341085
Trained batch 24 in epoch 1, gen_loss = 1.523528904914856, disc_loss = 0.0008785493578761816
Trained batch 25 in epoch 1, gen_loss = 1.5245404977064867, disc_loss = 0.0009475779236079409
Trained batch 26 in epoch 1, gen_loss = 1.5118813514709473, disc_loss = 0.0009604729194608
Trained batch 27 in epoch 1, gen_loss = 1.5111936841692244, disc_loss = 0.000952362985117361
Trained batch 28 in epoch 1, gen_loss = 1.514183784353322, disc_loss = 0.0009491980288595218
Trained batch 29 in epoch 1, gen_loss = 1.5143661896387737, disc_loss = 0.0009892707554778706
Trained batch 30 in epoch 1, gen_loss = 1.5193565699361986, disc_loss = 0.0010536520370101976
Trained batch 31 in epoch 1, gen_loss = 1.5222884304821491, disc_loss = 0.0010605206789477961
Trained batch 32 in epoch 1, gen_loss = 1.5197274432037815, disc_loss = 0.0010481231800054736
Trained batch 33 in epoch 1, gen_loss = 1.5211922876975115, disc_loss = 0.001048900791348013
Trained batch 34 in epoch 1, gen_loss = 1.518278057234628, disc_loss = 0.0010497281211428345
Trained batch 35 in epoch 1, gen_loss = 1.522885862323973, disc_loss = 0.0010651801146903178
Trained batch 36 in epoch 1, gen_loss = 1.5216861576647371, disc_loss = 0.001115733293526982
Trained batch 37 in epoch 1, gen_loss = 1.5201374166890194, disc_loss = 0.0011082326343871262
Trained batch 38 in epoch 1, gen_loss = 1.5148580563374054, disc_loss = 0.0011015683203601302
Trained batch 39 in epoch 1, gen_loss = 1.5168296575546265, disc_loss = 0.0011081488541094587
Trained batch 40 in epoch 1, gen_loss = 1.5099299302915248, disc_loss = 0.0011096728437512023
Trained batch 41 in epoch 1, gen_loss = 1.514776266756512, disc_loss = 0.0011056548433511385
Trained batch 42 in epoch 1, gen_loss = 1.516795183337012, disc_loss = 0.0011168944968863628
Trained batch 43 in epoch 1, gen_loss = 1.5239180597391995, disc_loss = 0.0011446718258825554
Trained batch 44 in epoch 1, gen_loss = 1.5232833253012763, disc_loss = 0.0011859722461344468
Trained batch 45 in epoch 1, gen_loss = 1.5219014209249746, disc_loss = 0.001191710129521949
Trained batch 46 in epoch 1, gen_loss = 1.5201135062156839, disc_loss = 0.0011840271082350074
Trained batch 47 in epoch 1, gen_loss = 1.5251961847146351, disc_loss = 0.001186083125503501
Trained batch 48 in epoch 1, gen_loss = 1.5241422434242404, disc_loss = 0.0011836235774966071
Trained batch 49 in epoch 1, gen_loss = 1.5232518911361694, disc_loss = 0.0011743080790620297
Trained batch 50 in epoch 1, gen_loss = 1.5212806252872242, disc_loss = 0.0011679148826492475
Trained batch 51 in epoch 1, gen_loss = 1.5192171060121977, disc_loss = 0.0011689300053358937
Trained batch 52 in epoch 1, gen_loss = 1.525341623234299, disc_loss = 0.0011604407457371224
Trained batch 53 in epoch 1, gen_loss = 1.5307943291134305, disc_loss = 0.0011524555997716056
Trained batch 54 in epoch 1, gen_loss = 1.5351469885219227, disc_loss = 0.0011545685035261241
Trained batch 55 in epoch 1, gen_loss = 1.5360251516103745, disc_loss = 0.0011705819883250765
Trained batch 56 in epoch 1, gen_loss = 1.533438383487233, disc_loss = 0.0011863917716893187
Trained batch 57 in epoch 1, gen_loss = 1.5319940303934032, disc_loss = 0.0011956220099317103
Trained batch 58 in epoch 1, gen_loss = 1.5334118988554357, disc_loss = 0.001197975466296203
Trained batch 59 in epoch 1, gen_loss = 1.540959362188975, disc_loss = 0.0011958240900033464
Trained batch 60 in epoch 1, gen_loss = 1.5449000733797666, disc_loss = 0.0012128767003992298
Trained batch 61 in epoch 1, gen_loss = 1.546972555498923, disc_loss = 0.001245943452006266
Trained batch 62 in epoch 1, gen_loss = 1.5455190832652743, disc_loss = 0.001249694095421878
Trained batch 63 in epoch 1, gen_loss = 1.5463870018720627, disc_loss = 0.0012400511268424452
Trained batch 64 in epoch 1, gen_loss = 1.5469617036672738, disc_loss = 0.0012333856832880813
Trained batch 65 in epoch 1, gen_loss = 1.5485621185013743, disc_loss = 0.0012243948365335889
Trained batch 66 in epoch 1, gen_loss = 1.5488824381757138, disc_loss = 0.0012146160084712527
Trained batch 67 in epoch 1, gen_loss = 1.5494617399047403, disc_loss = 0.0012099465041982887
Trained batch 68 in epoch 1, gen_loss = 1.5453925409178804, disc_loss = 0.0012092271446844266
Trained batch 69 in epoch 1, gen_loss = 1.5438511099134173, disc_loss = 0.0011994447317972246
Trained batch 70 in epoch 1, gen_loss = 1.5401196479797363, disc_loss = 0.00120846377964407
Trained batch 71 in epoch 1, gen_loss = 1.537619627184338, disc_loss = 0.0012442506760837408
Trained batch 72 in epoch 1, gen_loss = 1.5378261592290172, disc_loss = 0.0012612349859260226
Trained batch 73 in epoch 1, gen_loss = 1.5387492727588963, disc_loss = 0.0012566105193596937
Trained batch 74 in epoch 1, gen_loss = 1.5356740140914917, disc_loss = 0.00125493272440508
Trained batch 75 in epoch 1, gen_loss = 1.534847113646959, disc_loss = 0.0012476981907016843
Trained batch 76 in epoch 1, gen_loss = 1.5380976339439294, disc_loss = 0.0012441610655892494
Trained batch 77 in epoch 1, gen_loss = 1.5368232834033477, disc_loss = 0.0012444232012897443
Trained batch 78 in epoch 1, gen_loss = 1.5339301673671868, disc_loss = 0.0012369296797904881
Trained batch 79 in epoch 1, gen_loss = 1.5335699543356895, disc_loss = 0.001226331313228002
Trained batch 80 in epoch 1, gen_loss = 1.5360240597783783, disc_loss = 0.0012172504405801494
Trained batch 81 in epoch 1, gen_loss = 1.5349610564185352, disc_loss = 0.001212016818477068
Trained batch 82 in epoch 1, gen_loss = 1.5360368863645806, disc_loss = 0.0012070389523406524
Trained batch 83 in epoch 1, gen_loss = 1.5395846324307578, disc_loss = 0.0011996063168182793
Trained batch 84 in epoch 1, gen_loss = 1.5410200736101936, disc_loss = 0.0011906082327614593
Trained batch 85 in epoch 1, gen_loss = 1.5383960133375123, disc_loss = 0.0011846417419715287
Trained batch 86 in epoch 1, gen_loss = 1.5365969216686555, disc_loss = 0.0011940729364768826
Trained batch 87 in epoch 1, gen_loss = 1.5377302196892826, disc_loss = 0.001189418417197885
Trained batch 88 in epoch 1, gen_loss = 1.5386305203598536, disc_loss = 0.00118660195920292
Trained batch 89 in epoch 1, gen_loss = 1.5360116375817192, disc_loss = 0.0011841242774001633
Trained batch 90 in epoch 1, gen_loss = 1.5317185003678877, disc_loss = 0.0012113781403468738
Trained batch 91 in epoch 1, gen_loss = 1.5318759161493052, disc_loss = 0.0012402233503804462
Trained batch 92 in epoch 1, gen_loss = 1.5339068699908514, disc_loss = 0.0012452244631550526
Trained batch 93 in epoch 1, gen_loss = 1.5319642551401829, disc_loss = 0.0012624852084975808
Trained batch 94 in epoch 1, gen_loss = 1.532345125549718, disc_loss = 0.001286910405982972
Trained batch 95 in epoch 1, gen_loss = 1.5318823667864006, disc_loss = 0.001287121196279865
Trained batch 96 in epoch 1, gen_loss = 1.5298153432374149, disc_loss = 0.0012867646978942427
Trained batch 97 in epoch 1, gen_loss = 1.5319761962306744, disc_loss = 0.0013043051220272307
Trained batch 98 in epoch 1, gen_loss = 1.5302744935257266, disc_loss = 0.001315191184991331
Trained batch 99 in epoch 1, gen_loss = 1.5297348010540008, disc_loss = 0.001315385753114242
Trained batch 100 in epoch 1, gen_loss = 1.5347782656697944, disc_loss = 0.001318155534595417
Trained batch 101 in epoch 1, gen_loss = 1.5338950215601455, disc_loss = 0.0013118018113720395
Trained batch 102 in epoch 1, gen_loss = 1.535816991213456, disc_loss = 0.0013173169445684994
Trained batch 103 in epoch 1, gen_loss = 1.5353565089977705, disc_loss = 0.0013308247079504116
Trained batch 104 in epoch 1, gen_loss = 1.5348911841710409, disc_loss = 0.001335987385772612
Trained batch 105 in epoch 1, gen_loss = 1.5348854121172204, disc_loss = 0.0013389769133799797
Trained batch 106 in epoch 1, gen_loss = 1.5342671525812595, disc_loss = 0.0013680534002645307
Trained batch 107 in epoch 1, gen_loss = 1.5344510464756578, disc_loss = 0.0013965947795508396
Trained batch 108 in epoch 1, gen_loss = 1.5381251475132933, disc_loss = 0.0013978806884485135
Trained batch 109 in epoch 1, gen_loss = 1.5367572806098244, disc_loss = 0.0013947605570799417
Trained batch 110 in epoch 1, gen_loss = 1.5365583993293144, disc_loss = 0.0013925621628463436
Trained batch 111 in epoch 1, gen_loss = 1.537749592747007, disc_loss = 0.0013874142083035881
Trained batch 112 in epoch 1, gen_loss = 1.5377799219789758, disc_loss = 0.0013824185457974837
Trained batch 113 in epoch 1, gen_loss = 1.5400391482470328, disc_loss = 0.0013843015259593365
Trained batch 114 in epoch 1, gen_loss = 1.543272874666297, disc_loss = 0.0014054797734032668
Trained batch 115 in epoch 1, gen_loss = 1.5445304954874104, disc_loss = 0.0014151170298332702
Trained batch 116 in epoch 1, gen_loss = 1.546224160072131, disc_loss = 0.0014148597273693029
Trained batch 117 in epoch 1, gen_loss = 1.5447470808433275, disc_loss = 0.0014140907227618116
Trained batch 118 in epoch 1, gen_loss = 1.5440640990473644, disc_loss = 0.001407989681582945
Trained batch 119 in epoch 1, gen_loss = 1.5430097649494807, disc_loss = 0.0014055715071056814
Trained batch 120 in epoch 1, gen_loss = 1.5426237514196348, disc_loss = 0.0014156848242725746
Trained batch 121 in epoch 1, gen_loss = 1.544457769784771, disc_loss = 0.0014297383253893921
Trained batch 122 in epoch 1, gen_loss = 1.5438278613051748, disc_loss = 0.001431387007980403
Trained batch 123 in epoch 1, gen_loss = 1.5430911414084896, disc_loss = 0.0014298456674535578
Trained batch 124 in epoch 1, gen_loss = 1.5422545566558838, disc_loss = 0.0014249813889618964
Trained batch 125 in epoch 1, gen_loss = 1.545621066812485, disc_loss = 0.0014242642142880146
Trained batch 126 in epoch 1, gen_loss = 1.5445496087937842, disc_loss = 0.0014212699806387353
Trained batch 127 in epoch 1, gen_loss = 1.5443053897470236, disc_loss = 0.0014151621837754647
Trained batch 128 in epoch 1, gen_loss = 1.5450198890626892, disc_loss = 0.0014116776989350573
Trained batch 129 in epoch 1, gen_loss = 1.5464437869878915, disc_loss = 0.0014106825394824577
Trained batch 130 in epoch 1, gen_loss = 1.5465260043399025, disc_loss = 0.0014054537944065562
Trained batch 131 in epoch 1, gen_loss = 1.5456149036234075, disc_loss = 0.001400768224839615
Trained batch 132 in epoch 1, gen_loss = 1.543509917151659, disc_loss = 0.0014007920239565376
Trained batch 133 in epoch 1, gen_loss = 1.5439415885441339, disc_loss = 0.0013972584819751306
Trained batch 134 in epoch 1, gen_loss = 1.545559695031908, disc_loss = 0.0013960772950667888
Trained batch 135 in epoch 1, gen_loss = 1.5447701399817186, disc_loss = 0.0013915212811672758
Trained batch 136 in epoch 1, gen_loss = 1.5456966039908193, disc_loss = 0.0013852705271918
Trained batch 137 in epoch 1, gen_loss = 1.5479443375615105, disc_loss = 0.0013786207260715817
Trained batch 138 in epoch 1, gen_loss = 1.5486647079316833, disc_loss = 0.0013749211879611257
Trained batch 139 in epoch 1, gen_loss = 1.5512158964361464, disc_loss = 0.001372765916208404
Trained batch 140 in epoch 1, gen_loss = 1.5518223622166518, disc_loss = 0.0013680524580388707
Trained batch 141 in epoch 1, gen_loss = 1.5544746946281112, disc_loss = 0.0013674042352826111
Trained batch 142 in epoch 1, gen_loss = 1.5520508564435518, disc_loss = 0.0013701838131430658
Trained batch 143 in epoch 1, gen_loss = 1.551444488267104, disc_loss = 0.0013681386099051451
Trained batch 144 in epoch 1, gen_loss = 1.5536730100368632, disc_loss = 0.001364346069950161
Trained batch 145 in epoch 1, gen_loss = 1.552349471066096, disc_loss = 0.001361686041640845
Trained batch 146 in epoch 1, gen_loss = 1.5535870814809993, disc_loss = 0.0013575760216442679
Trained batch 147 in epoch 1, gen_loss = 1.5552575765429317, disc_loss = 0.0013524932986222888
Trained batch 148 in epoch 1, gen_loss = 1.5558239661607167, disc_loss = 0.001348335839903307
Trained batch 149 in epoch 1, gen_loss = 1.5559960047403971, disc_loss = 0.0013441032072296366
Trained batch 150 in epoch 1, gen_loss = 1.5568853766712922, disc_loss = 0.0013426445181318096
Trained batch 151 in epoch 1, gen_loss = 1.5559447705745697, disc_loss = 0.0013441878930423531
Trained batch 152 in epoch 1, gen_loss = 1.5554504869810117, disc_loss = 0.0013482170120517729
Trained batch 153 in epoch 1, gen_loss = 1.555934261191975, disc_loss = 0.00134674193320173
Trained batch 154 in epoch 1, gen_loss = 1.5557419476970549, disc_loss = 0.0013414729835330359
Trained batch 155 in epoch 1, gen_loss = 1.5555951175017235, disc_loss = 0.0013381767156459272
Trained batch 156 in epoch 1, gen_loss = 1.5546625746283562, disc_loss = 0.0013376908926634344
Trained batch 157 in epoch 1, gen_loss = 1.5556933562966841, disc_loss = 0.001346482143588541
Trained batch 158 in epoch 1, gen_loss = 1.5555132904892448, disc_loss = 0.0013611141807156608
Trained batch 159 in epoch 1, gen_loss = 1.5539542734622955, disc_loss = 0.0013592021094154915
Trained batch 160 in epoch 1, gen_loss = 1.5526395362356435, disc_loss = 0.0013635505664361908
Trained batch 161 in epoch 1, gen_loss = 1.551105918707671, disc_loss = 0.0013810634592556635
Trained batch 162 in epoch 1, gen_loss = 1.5533072304871915, disc_loss = 0.0013973818185947767
Trained batch 163 in epoch 1, gen_loss = 1.5536838537309228, disc_loss = 0.0013994447389694227
Trained batch 164 in epoch 1, gen_loss = 1.5524223240939055, disc_loss = 0.0013961984005149905
Trained batch 165 in epoch 1, gen_loss = 1.5514429491686534, disc_loss = 0.001397746247456813
Trained batch 166 in epoch 1, gen_loss = 1.5516234200871633, disc_loss = 0.00139420676866998
Trained batch 167 in epoch 1, gen_loss = 1.5529576937357585, disc_loss = 0.0013906331599476591
Trained batch 168 in epoch 1, gen_loss = 1.5524972282217804, disc_loss = 0.0013938697663579444
Trained batch 169 in epoch 1, gen_loss = 1.5520477358032676, disc_loss = 0.0014025696216027855
Trained batch 170 in epoch 1, gen_loss = 1.5522668075840376, disc_loss = 0.0014114965817806644
Trained batch 171 in epoch 1, gen_loss = 1.5531333470067312, disc_loss = 0.001414337482940958
Trained batch 172 in epoch 1, gen_loss = 1.551392402263046, disc_loss = 0.0014144690238636504
Trained batch 173 in epoch 1, gen_loss = 1.5517697745356067, disc_loss = 0.0014104817553367145
Trained batch 174 in epoch 1, gen_loss = 1.551635172707694, disc_loss = 0.001405808598834223
Trained batch 175 in epoch 1, gen_loss = 1.5509490363977172, disc_loss = 0.0014014316708529475
Trained batch 176 in epoch 1, gen_loss = 1.5508482449472287, disc_loss = 0.0013998684206632844
Trained batch 177 in epoch 1, gen_loss = 1.54987852626972, disc_loss = 0.0014009334310808145
Trained batch 178 in epoch 1, gen_loss = 1.548754235219689, disc_loss = 0.001401689508572148
Trained batch 179 in epoch 1, gen_loss = 1.548662707540724, disc_loss = 0.0014002103114358357
Trained batch 180 in epoch 1, gen_loss = 1.547571789493877, disc_loss = 0.0013979783293582725
Trained batch 181 in epoch 1, gen_loss = 1.5475407878121177, disc_loss = 0.0013937924946671107
Trained batch 182 in epoch 1, gen_loss = 1.5485879684406552, disc_loss = 0.001392280940084764
Trained batch 183 in epoch 1, gen_loss = 1.548854802613673, disc_loss = 0.0013876679689059054
Trained batch 184 in epoch 1, gen_loss = 1.5487212135985091, disc_loss = 0.0013831538042821292
Trained batch 185 in epoch 1, gen_loss = 1.5480043010045124, disc_loss = 0.0013802847911050463
Trained batch 186 in epoch 1, gen_loss = 1.5486707292138573, disc_loss = 0.0013758078761296696
Trained batch 187 in epoch 1, gen_loss = 1.549263562293763, disc_loss = 0.001372829443580679
Trained batch 188 in epoch 1, gen_loss = 1.5495824416478474, disc_loss = 0.0013733248239587597
Trained batch 189 in epoch 1, gen_loss = 1.5480202405076278, disc_loss = 0.0013727749537027097
Trained batch 190 in epoch 1, gen_loss = 1.548017625409271, disc_loss = 0.0013704486451835826
Trained batch 191 in epoch 1, gen_loss = 1.5504663760463397, disc_loss = 0.0013678740140979546
Trained batch 192 in epoch 1, gen_loss = 1.5500869639796915, disc_loss = 0.0013644790008164691
Trained batch 193 in epoch 1, gen_loss = 1.5501258428563778, disc_loss = 0.0013637326403638616
Trained batch 194 in epoch 1, gen_loss = 1.5484274161167635, disc_loss = 0.00136567661493945
Trained batch 195 in epoch 1, gen_loss = 1.547986059772725, disc_loss = 0.0013640430402212624
Trained batch 196 in epoch 1, gen_loss = 1.5466514541412972, disc_loss = 0.0013601056745968438
Trained batch 197 in epoch 1, gen_loss = 1.5469596644844672, disc_loss = 0.0013560931496098732
Trained batch 198 in epoch 1, gen_loss = 1.5477068699784016, disc_loss = 0.0013518420818212661
Trained batch 199 in epoch 1, gen_loss = 1.5466457635164261, disc_loss = 0.001348683978576446
Trained batch 200 in epoch 1, gen_loss = 1.5465008797337167, disc_loss = 0.0013452601334976672
Trained batch 201 in epoch 1, gen_loss = 1.5460734503103954, disc_loss = 0.0013436820618243483
Trained batch 202 in epoch 1, gen_loss = 1.5464130205473876, disc_loss = 0.0013430880724161112
Trained batch 203 in epoch 1, gen_loss = 1.5473480756376303, disc_loss = 0.0013440194231282244
Trained batch 204 in epoch 1, gen_loss = 1.5471068568345978, disc_loss = 0.0013439991169257044
Trained batch 205 in epoch 1, gen_loss = 1.546182380717935, disc_loss = 0.0013444169125806774
Trained batch 206 in epoch 1, gen_loss = 1.5490472633481602, disc_loss = 0.0013425660490874957
Trained batch 207 in epoch 1, gen_loss = 1.5497852724332075, disc_loss = 0.0013435159244881317
Trained batch 208 in epoch 1, gen_loss = 1.5513878490365864, disc_loss = 0.0013535982010380308
Trained batch 209 in epoch 1, gen_loss = 1.5517820568311782, disc_loss = 0.0013576866805254083
Trained batch 210 in epoch 1, gen_loss = 1.5506000298459384, disc_loss = 0.0013556513722635082
Trained batch 211 in epoch 1, gen_loss = 1.5506050738523591, disc_loss = 0.001352727348517565
Trained batch 212 in epoch 1, gen_loss = 1.5512469256987593, disc_loss = 0.0013510049141762
Trained batch 213 in epoch 1, gen_loss = 1.5525561253601146, disc_loss = 0.0013502268007767133
Trained batch 214 in epoch 1, gen_loss = 1.5511875496354215, disc_loss = 0.0013492934894477298
Trained batch 215 in epoch 1, gen_loss = 1.550489862759908, disc_loss = 0.0013480599738142228
Trained batch 216 in epoch 1, gen_loss = 1.55045615747777, disc_loss = 0.001345812510039168
Trained batch 217 in epoch 1, gen_loss = 1.550986417389791, disc_loss = 0.0013433586814870135
Trained batch 218 in epoch 1, gen_loss = 1.5522470365376233, disc_loss = 0.0013407668943748677
Trained batch 219 in epoch 1, gen_loss = 1.5533586236563597, disc_loss = 0.001337457534364975
Trained batch 220 in epoch 1, gen_loss = 1.5522130943531365, disc_loss = 0.0013339252550127532
Trained batch 221 in epoch 1, gen_loss = 1.55139779453879, disc_loss = 0.001333189232412281
Trained batch 222 in epoch 1, gen_loss = 1.551500757178918, disc_loss = 0.00133231280237382
Trained batch 223 in epoch 1, gen_loss = 1.5507911693836962, disc_loss = 0.0013321150596051926
Trained batch 224 in epoch 1, gen_loss = 1.5515917857487997, disc_loss = 0.0013340771993777404
Trained batch 225 in epoch 1, gen_loss = 1.5523455390887977, disc_loss = 0.0013328741614416291
Trained batch 226 in epoch 1, gen_loss = 1.5535421423975067, disc_loss = 0.0013291482713139137
Trained batch 227 in epoch 1, gen_loss = 1.554316498731312, disc_loss = 0.001326725098279942
Trained batch 228 in epoch 1, gen_loss = 1.5546634676154525, disc_loss = 0.0013265379279542829
Trained batch 229 in epoch 1, gen_loss = 1.5551189049430516, disc_loss = 0.001325985351982324
Trained batch 230 in epoch 1, gen_loss = 1.554588524294106, disc_loss = 0.0013242319487821457
Trained batch 231 in epoch 1, gen_loss = 1.5539655901234726, disc_loss = 0.0013219434419217326
Trained batch 232 in epoch 1, gen_loss = 1.5521982529644291, disc_loss = 0.0013276247955686833
Trained batch 233 in epoch 1, gen_loss = 1.5522237083850763, disc_loss = 0.0013386372849444707
Trained batch 234 in epoch 1, gen_loss = 1.551760451844398, disc_loss = 0.0013420756056686824
Trained batch 235 in epoch 1, gen_loss = 1.5514206093246654, disc_loss = 0.0013387155284023827
Trained batch 236 in epoch 1, gen_loss = 1.5506268342336018, disc_loss = 0.0013392772756414763
Trained batch 237 in epoch 1, gen_loss = 1.5527795833699845, disc_loss = 0.0013455037705545477
Trained batch 238 in epoch 1, gen_loss = 1.5526394060964863, disc_loss = 0.0013462269506280828
Trained batch 239 in epoch 1, gen_loss = 1.5533079380790393, disc_loss = 0.0013444348204454096
Trained batch 240 in epoch 1, gen_loss = 1.5547875893066534, disc_loss = 0.0013438545861107556
Trained batch 241 in epoch 1, gen_loss = 1.554174852765296, disc_loss = 0.0013429090791489651
Trained batch 242 in epoch 1, gen_loss = 1.5558294543513544, disc_loss = 0.0013407412935584906
Trained batch 243 in epoch 1, gen_loss = 1.5550325542199808, disc_loss = 0.0013419249649426793
Trained batch 244 in epoch 1, gen_loss = 1.554798240077739, disc_loss = 0.0013462037385004212
Trained batch 245 in epoch 1, gen_loss = 1.555217723051707, disc_loss = 0.0013447824247537286
Trained batch 246 in epoch 1, gen_loss = 1.5546741113971603, disc_loss = 0.0013446139990868657
Trained batch 247 in epoch 1, gen_loss = 1.5537390665661903, disc_loss = 0.0013433582949331931
Trained batch 248 in epoch 1, gen_loss = 1.5550672050460754, disc_loss = 0.001341598871655867
Trained batch 249 in epoch 1, gen_loss = 1.5561397557258605, disc_loss = 0.0013412170696537943
Trained batch 250 in epoch 1, gen_loss = 1.5575935379917403, disc_loss = 0.0013390735549614783
Trained batch 251 in epoch 1, gen_loss = 1.5568744100275493, disc_loss = 0.0013360286689093632
Trained batch 252 in epoch 1, gen_loss = 1.5577795284067688, disc_loss = 0.001333438760505275
Trained batch 253 in epoch 1, gen_loss = 1.5587623443190508, disc_loss = 0.0013306636453100193
Trained batch 254 in epoch 1, gen_loss = 1.5571990583457198, disc_loss = 0.0013288858552079866
Trained batch 255 in epoch 1, gen_loss = 1.5572024350985885, disc_loss = 0.0013272683027025778
Trained batch 256 in epoch 1, gen_loss = 1.5558358806580421, disc_loss = 0.0013264141390679934
Trained batch 257 in epoch 1, gen_loss = 1.555493291958358, disc_loss = 0.0013245494493424113
Trained batch 258 in epoch 1, gen_loss = 1.555720434225664, disc_loss = 0.0013243070145993417
Trained batch 259 in epoch 1, gen_loss = 1.5551820158958436, disc_loss = 0.0013206954105184055
Trained batch 260 in epoch 1, gen_loss = 1.5549579580168158, disc_loss = 0.0013183953726246696
Trained batch 261 in epoch 1, gen_loss = 1.5568505807687307, disc_loss = 0.0013168758420781979
Trained batch 262 in epoch 1, gen_loss = 1.5567416836553654, disc_loss = 0.0013148114439312495
Trained batch 263 in epoch 1, gen_loss = 1.5570288770126575, disc_loss = 0.0013160566846967083
Trained batch 264 in epoch 1, gen_loss = 1.5570814955909298, disc_loss = 0.0013197191551608859
Trained batch 265 in epoch 1, gen_loss = 1.5581304094845192, disc_loss = 0.001318906315714401
Trained batch 266 in epoch 1, gen_loss = 1.5571236155006323, disc_loss = 0.0013169355891917026
Trained batch 267 in epoch 1, gen_loss = 1.5567456777416058, disc_loss = 0.0013160039583888295
Trained batch 268 in epoch 1, gen_loss = 1.5571791580618535, disc_loss = 0.0013131902243277286
Trained batch 269 in epoch 1, gen_loss = 1.5567562681657297, disc_loss = 0.0013118860421754005
Trained batch 270 in epoch 1, gen_loss = 1.5581057203651794, disc_loss = 0.0013107120111409396
Trained batch 271 in epoch 1, gen_loss = 1.5573813739944906, disc_loss = 0.0013099212864129666
Trained batch 272 in epoch 1, gen_loss = 1.556559253524948, disc_loss = 0.0013084559668974454
Trained batch 273 in epoch 1, gen_loss = 1.5563095425167224, disc_loss = 0.001306220975765673
Trained batch 274 in epoch 1, gen_loss = 1.5559296980771151, disc_loss = 0.0013039628304117783
Trained batch 275 in epoch 1, gen_loss = 1.5547946700151416, disc_loss = 0.0013047458299864218
Trained batch 276 in epoch 1, gen_loss = 1.5550964554294353, disc_loss = 0.0013032077300187456
Trained batch 277 in epoch 1, gen_loss = 1.5561727512654642, disc_loss = 0.0013018553846653068
Trained batch 278 in epoch 1, gen_loss = 1.5556597201200368, disc_loss = 0.00130146389929778
Trained batch 279 in epoch 1, gen_loss = 1.5559907696076802, disc_loss = 0.0013010353429958091
Trained batch 280 in epoch 1, gen_loss = 1.5559767650115532, disc_loss = 0.0012982672716746126
Trained batch 281 in epoch 1, gen_loss = 1.5557844545824309, disc_loss = 0.0012961312870871514
Trained batch 282 in epoch 1, gen_loss = 1.5564142158090437, disc_loss = 0.0012961334780075787
Trained batch 283 in epoch 1, gen_loss = 1.5562607469693037, disc_loss = 0.0012971986795145966
Trained batch 284 in epoch 1, gen_loss = 1.5565081926814297, disc_loss = 0.0012969799004821925
Trained batch 285 in epoch 1, gen_loss = 1.5570863739593879, disc_loss = 0.0012947213893000791
Trained batch 286 in epoch 1, gen_loss = 1.5570366486439722, disc_loss = 0.0012917708004589552
Trained batch 287 in epoch 1, gen_loss = 1.5570494859582849, disc_loss = 0.0012934314267517442
Trained batch 288 in epoch 1, gen_loss = 1.5551652681456305, disc_loss = 0.0013049685092728302
Trained batch 289 in epoch 1, gen_loss = 1.5556307319937082, disc_loss = 0.0013091172791158394
Trained batch 290 in epoch 1, gen_loss = 1.5551004954629748, disc_loss = 0.001308377182588807
Trained batch 291 in epoch 1, gen_loss = 1.5559330643856362, disc_loss = 0.0013080259023771673
Trained batch 292 in epoch 1, gen_loss = 1.5553616403312813, disc_loss = 0.0013096259833184792
Trained batch 293 in epoch 1, gen_loss = 1.5553586616808055, disc_loss = 0.0013103675118807487
Trained batch 294 in epoch 1, gen_loss = 1.554733958082684, disc_loss = 0.0013108356935721901
Trained batch 295 in epoch 1, gen_loss = 1.553852393417745, disc_loss = 0.0013110316752784922
Trained batch 296 in epoch 1, gen_loss = 1.553246937616907, disc_loss = 0.0013119170571769892
Trained batch 297 in epoch 1, gen_loss = 1.5531319579822105, disc_loss = 0.0013113562608545572
Trained batch 298 in epoch 1, gen_loss = 1.5532116570998993, disc_loss = 0.0013108252008238426
Trained batch 299 in epoch 1, gen_loss = 1.5529456492265066, disc_loss = 0.0013097540061183584
Trained batch 300 in epoch 1, gen_loss = 1.5520180376661181, disc_loss = 0.001307629928804247
Trained batch 301 in epoch 1, gen_loss = 1.553236835445, disc_loss = 0.001307669759204531
Trained batch 302 in epoch 1, gen_loss = 1.5533714668192091, disc_loss = 0.001310367000127125
Trained batch 303 in epoch 1, gen_loss = 1.5528142711049633, disc_loss = 0.0013120384852587257
Trained batch 304 in epoch 1, gen_loss = 1.553509533209879, disc_loss = 0.0013110693568004997
Trained batch 305 in epoch 1, gen_loss = 1.5537288372033562, disc_loss = 0.0013092168123846313
Trained batch 306 in epoch 1, gen_loss = 1.5536745969169692, disc_loss = 0.0013078019368585126
Trained batch 307 in epoch 1, gen_loss = 1.553385380413625, disc_loss = 0.0013085954066467255
Trained batch 308 in epoch 1, gen_loss = 1.553445969970481, disc_loss = 0.001307314600773656
Trained batch 309 in epoch 1, gen_loss = 1.5533478486922478, disc_loss = 0.0013053545440104039
Trained batch 310 in epoch 1, gen_loss = 1.552787120319256, disc_loss = 0.0013037641291091836
Trained batch 311 in epoch 1, gen_loss = 1.552640594350986, disc_loss = 0.001301919981648471
Trained batch 312 in epoch 1, gen_loss = 1.5532878827744019, disc_loss = 0.0013000943214288904
Trained batch 313 in epoch 1, gen_loss = 1.555173127134894, disc_loss = 0.0012984783498972215
Trained batch 314 in epoch 1, gen_loss = 1.5555069079474797, disc_loss = 0.0012962160736418491
Trained batch 315 in epoch 1, gen_loss = 1.5551470446435711, disc_loss = 0.0012939309376576338
Trained batch 316 in epoch 1, gen_loss = 1.5557066262332422, disc_loss = 0.0012925059841438975
Trained batch 317 in epoch 1, gen_loss = 1.5560414468717274, disc_loss = 0.001293710079948336
Trained batch 318 in epoch 1, gen_loss = 1.5562593806126275, disc_loss = 0.0012946768508177414
Trained batch 319 in epoch 1, gen_loss = 1.5560220345854758, disc_loss = 0.001293403347608546
Trained batch 320 in epoch 1, gen_loss = 1.5566052068431058, disc_loss = 0.0012922334462814788
Trained batch 321 in epoch 1, gen_loss = 1.5573974736729024, disc_loss = 0.0012915047009074945
Trained batch 322 in epoch 1, gen_loss = 1.557307062872423, disc_loss = 0.0012904403787272068
Trained batch 323 in epoch 1, gen_loss = 1.557371954859039, disc_loss = 0.0012915127124331236
Trained batch 324 in epoch 1, gen_loss = 1.5572550755280714, disc_loss = 0.001295002518633667
Trained batch 325 in epoch 1, gen_loss = 1.5570511492483454, disc_loss = 0.0012952432808990481
Trained batch 326 in epoch 1, gen_loss = 1.5561855597598109, disc_loss = 0.0012935976504415147
Trained batch 327 in epoch 1, gen_loss = 1.5550002433904788, disc_loss = 0.0012928230984160596
Trained batch 328 in epoch 1, gen_loss = 1.5548101141822375, disc_loss = 0.0012919451340949475
Trained batch 329 in epoch 1, gen_loss = 1.5552270000631159, disc_loss = 0.0012906698517988183
Trained batch 330 in epoch 1, gen_loss = 1.5556877376089644, disc_loss = 0.0012894467164212247
Trained batch 331 in epoch 1, gen_loss = 1.5551399832748505, disc_loss = 0.0012870863875470977
Trained batch 332 in epoch 1, gen_loss = 1.5544880428113736, disc_loss = 0.001284553832391993
Trained batch 333 in epoch 1, gen_loss = 1.5541770261918713, disc_loss = 0.001282669027237651
Trained batch 334 in epoch 1, gen_loss = 1.554766296628696, disc_loss = 0.0012821174319659764
Trained batch 335 in epoch 1, gen_loss = 1.5550161298541796, disc_loss = 0.0012880440386825718
Trained batch 336 in epoch 1, gen_loss = 1.5544117250499103, disc_loss = 0.0012992900054043751
Trained batch 337 in epoch 1, gen_loss = 1.5540178640354314, disc_loss = 0.0012998960146056377
Trained batch 338 in epoch 1, gen_loss = 1.5539189672048113, disc_loss = 0.001297471584315387
Trained batch 339 in epoch 1, gen_loss = 1.5542542618863724, disc_loss = 0.001296485068365548
Trained batch 340 in epoch 1, gen_loss = 1.553988690949605, disc_loss = 0.0012955230480139184
Trained batch 341 in epoch 1, gen_loss = 1.5532528709249886, disc_loss = 0.0012939724162675723
Trained batch 342 in epoch 1, gen_loss = 1.5536026721793084, disc_loss = 0.0012939347987030647
Trained batch 343 in epoch 1, gen_loss = 1.5538696982832843, disc_loss = 0.0012954375045008545
Trained batch 344 in epoch 1, gen_loss = 1.5542323496030725, disc_loss = 0.0012957753935842302
Trained batch 345 in epoch 1, gen_loss = 1.5544578929167951, disc_loss = 0.001295016002686522
Trained batch 346 in epoch 1, gen_loss = 1.5550035485616678, disc_loss = 0.0012940306082952994
Trained batch 347 in epoch 1, gen_loss = 1.5559715337451847, disc_loss = 0.0012918781367366084
Trained batch 348 in epoch 1, gen_loss = 1.5562691924223586, disc_loss = 0.0012905664772347662
Trained batch 349 in epoch 1, gen_loss = 1.5567995524406433, disc_loss = 0.0012888709131428707
Trained batch 350 in epoch 1, gen_loss = 1.5566403397128112, disc_loss = 0.0012883745736516799
Trained batch 351 in epoch 1, gen_loss = 1.556696085089987, disc_loss = 0.0012886164128179769
Trained batch 352 in epoch 1, gen_loss = 1.557089210907393, disc_loss = 0.0012873880000898441
Trained batch 353 in epoch 1, gen_loss = 1.5569117288131498, disc_loss = 0.00128600484836915
Trained batch 354 in epoch 1, gen_loss = 1.5567888400924037, disc_loss = 0.001284763802328265
Trained batch 355 in epoch 1, gen_loss = 1.557585334509946, disc_loss = 0.00128738474515476
Trained batch 356 in epoch 1, gen_loss = 1.5576422281291973, disc_loss = 0.0013114849372221685
Trained batch 357 in epoch 1, gen_loss = 1.5602117470522832, disc_loss = 0.0013370885498764503
Trained batch 358 in epoch 1, gen_loss = 1.5613922468467012, disc_loss = 0.0014090259033475788
Trained batch 359 in epoch 1, gen_loss = 1.5620998362700145, disc_loss = 0.0015022447892180126
Trained batch 360 in epoch 1, gen_loss = 1.5633409736559332, disc_loss = 0.001644059926996374
Trained batch 361 in epoch 1, gen_loss = 1.5638791803496976, disc_loss = 0.002144624097388526
Trained batch 362 in epoch 1, gen_loss = 1.5652790686972542, disc_loss = 0.0029214241226991388
Trained batch 363 in epoch 1, gen_loss = 1.5658951159361953, disc_loss = 0.004305594891455577
Trained batch 364 in epoch 1, gen_loss = 1.566949658851101, disc_loss = 0.00649209707777641
Trained batch 365 in epoch 1, gen_loss = 1.5689475699200657, disc_loss = 0.00744849898823145
Trained batch 366 in epoch 1, gen_loss = 1.569029750226304, disc_loss = 0.007569353595155238
Trained batch 367 in epoch 1, gen_loss = 1.5688050538301468, disc_loss = 0.007798518928883941
Trained batch 368 in epoch 1, gen_loss = 1.568275064956851, disc_loss = 0.007960988601434946
Trained batch 369 in epoch 1, gen_loss = 1.5679291754155547, disc_loss = 0.008005052844276401
Trained batch 370 in epoch 1, gen_loss = 1.567720180251849, disc_loss = 0.008043382536793113
Trained batch 371 in epoch 1, gen_loss = 1.5674697535653268, disc_loss = 0.008077089839066649
Trained batch 372 in epoch 1, gen_loss = 1.567391795063786, disc_loss = 0.008096201384337694
Trained batch 373 in epoch 1, gen_loss = 1.5669612785711646, disc_loss = 0.008102469379393592
Trained batch 374 in epoch 1, gen_loss = 1.5662000347773235, disc_loss = 0.008294941558502614
Trained batch 375 in epoch 1, gen_loss = 1.5646127947467439, disc_loss = 0.008664259225429788
Trained batch 376 in epoch 1, gen_loss = 1.5653179238898685, disc_loss = 0.008737826965988888
Trained batch 377 in epoch 1, gen_loss = 1.566520671049754, disc_loss = 0.008789837965556968
Trained batch 378 in epoch 1, gen_loss = 1.566749749523354, disc_loss = 0.0088434609720277
Trained batch 379 in epoch 1, gen_loss = 1.5662670110401353, disc_loss = 0.008873377469870703
Trained batch 380 in epoch 1, gen_loss = 1.566602271685763, disc_loss = 0.008871705595494352
Trained batch 381 in epoch 1, gen_loss = 1.5664540376338658, disc_loss = 0.008869137245910583
Trained batch 382 in epoch 1, gen_loss = 1.5667548855042022, disc_loss = 0.008863502361096792
Trained batch 383 in epoch 1, gen_loss = 1.5669265718509753, disc_loss = 0.008852618544248495
Trained batch 384 in epoch 1, gen_loss = 1.5668495407352199, disc_loss = 0.00884922748558562
Trained batch 385 in epoch 1, gen_loss = 1.5665412220930188, disc_loss = 0.008834438223254245
Trained batch 386 in epoch 1, gen_loss = 1.5663532298972749, disc_loss = 0.008820150674137862
Trained batch 387 in epoch 1, gen_loss = 1.5675211321447313, disc_loss = 0.008842855131135984
Trained batch 388 in epoch 1, gen_loss = 1.5676418021895893, disc_loss = 0.008879229374610578
Trained batch 389 in epoch 1, gen_loss = 1.5687929187065517, disc_loss = 0.008880167534180845
Trained batch 390 in epoch 1, gen_loss = 1.5696294152218362, disc_loss = 0.00886799610735577
Trained batch 391 in epoch 1, gen_loss = 1.569648794981898, disc_loss = 0.008851916330560034
Trained batch 392 in epoch 1, gen_loss = 1.5701830478114935, disc_loss = 0.00883528607294352
Trained batch 393 in epoch 1, gen_loss = 1.5699951082921875, disc_loss = 0.008820333870584004
Trained batch 394 in epoch 1, gen_loss = 1.5700458010540732, disc_loss = 0.00881048112524131
Trained batch 395 in epoch 1, gen_loss = 1.5697872930704946, disc_loss = 0.008792359925773596
Trained batch 396 in epoch 1, gen_loss = 1.5696370742783439, disc_loss = 0.009385981452146953
Trained batch 397 in epoch 1, gen_loss = 1.568465238240496, disc_loss = 0.009634280846987725
Trained batch 398 in epoch 1, gen_loss = 1.5668422924844843, disc_loss = 0.010528658638663944
Trained batch 399 in epoch 1, gen_loss = 1.5663368886709212, disc_loss = 0.010721474828314967
Trained batch 400 in epoch 1, gen_loss = 1.567485198713003, disc_loss = 0.010924684453379373
Trained batch 401 in epoch 1, gen_loss = 1.566933566658058, disc_loss = 0.01108628640991557
Trained batch 402 in epoch 1, gen_loss = 1.5663326996431752, disc_loss = 0.011237250625389274
Trained batch 403 in epoch 1, gen_loss = 1.565645808925723, disc_loss = 0.011360315945446675
Trained batch 404 in epoch 1, gen_loss = 1.566166372652407, disc_loss = 0.011450296022388853
Trained batch 405 in epoch 1, gen_loss = 1.5663123204203075, disc_loss = 0.01145367141585944
Trained batch 406 in epoch 1, gen_loss = 1.5666008686843609, disc_loss = 0.011474930123524416
Trained batch 407 in epoch 1, gen_loss = 1.5661096905960756, disc_loss = 0.011472466726463251
Trained batch 408 in epoch 1, gen_loss = 1.5667817583876893, disc_loss = 0.011471888292375906
Trained batch 409 in epoch 1, gen_loss = 1.5664477365772898, disc_loss = 0.011472913155491213
Trained batch 410 in epoch 1, gen_loss = 1.5666213343033246, disc_loss = 0.011456060323551514
Trained batch 411 in epoch 1, gen_loss = 1.5664112330640403, disc_loss = 0.01144025124580084
Trained batch 412 in epoch 1, gen_loss = 1.5683408949623385, disc_loss = 0.011432404888649505
Trained batch 413 in epoch 1, gen_loss = 1.5684599536628538, disc_loss = 0.011416076081310025
Trained batch 414 in epoch 1, gen_loss = 1.5683000397969442, disc_loss = 0.011396082911460874
Trained batch 415 in epoch 1, gen_loss = 1.567974276554126, disc_loss = 0.011424091661375804
Trained batch 416 in epoch 1, gen_loss = 1.567690777264053, disc_loss = 0.011427641340377305
Trained batch 417 in epoch 1, gen_loss = 1.567617454597254, disc_loss = 0.011422084509640149
Trained batch 418 in epoch 1, gen_loss = 1.5670336009778953, disc_loss = 0.011465236370125007
Trained batch 419 in epoch 1, gen_loss = 1.5662741019612267, disc_loss = 0.011694182600781677
Trained batch 420 in epoch 1, gen_loss = 1.5682277900306176, disc_loss = 0.011732276435056591
Trained batch 421 in epoch 1, gen_loss = 1.5687686569317822, disc_loss = 0.011753732756760095
Trained batch 422 in epoch 1, gen_loss = 1.5688430070877075, disc_loss = 0.0117480518597995
Trained batch 423 in epoch 1, gen_loss = 1.5682680508438147, disc_loss = 0.011731521136408567
Trained batch 424 in epoch 1, gen_loss = 1.5684192480760462, disc_loss = 0.01172571922707207
Trained batch 425 in epoch 1, gen_loss = 1.567748703027555, disc_loss = 0.011713211285824856
Trained batch 426 in epoch 1, gen_loss = 1.567776647328772, disc_loss = 0.0116922109937448
Trained batch 427 in epoch 1, gen_loss = 1.5671604985945693, disc_loss = 0.01167031519156315
Trained batch 428 in epoch 1, gen_loss = 1.5672532370040466, disc_loss = 0.01164847599789674
Trained batch 429 in epoch 1, gen_loss = 1.5675607911376066, disc_loss = 0.011633840611551044
Trained batch 430 in epoch 1, gen_loss = 1.5680999542886862, disc_loss = 0.01161288240224365
Trained batch 431 in epoch 1, gen_loss = 1.5678161037740883, disc_loss = 0.011593392698732377
Trained batch 432 in epoch 1, gen_loss = 1.5676939614099938, disc_loss = 0.011572415523734331
Trained batch 433 in epoch 1, gen_loss = 1.5678474070839068, disc_loss = 0.011550714178676052
Trained batch 434 in epoch 1, gen_loss = 1.5672581845316393, disc_loss = 0.01153183531112455
Trained batch 435 in epoch 1, gen_loss = 1.567946485149751, disc_loss = 0.011510750821924026
Trained batch 436 in epoch 1, gen_loss = 1.5679762336154823, disc_loss = 0.011488773620013975
Trained batch 437 in epoch 1, gen_loss = 1.568210047401794, disc_loss = 0.011467567240749167
Trained batch 438 in epoch 1, gen_loss = 1.567875848272667, disc_loss = 0.011444711201964265
Trained batch 439 in epoch 1, gen_loss = 1.5679770076816733, disc_loss = 0.01142474610956428
Trained batch 440 in epoch 1, gen_loss = 1.5674362439417244, disc_loss = 0.011406320313259942
Trained batch 441 in epoch 1, gen_loss = 1.5673502732186295, disc_loss = 0.011385593421354772
Trained batch 442 in epoch 1, gen_loss = 1.5678802397665537, disc_loss = 0.0113640276436078
Trained batch 443 in epoch 1, gen_loss = 1.5678437046102576, disc_loss = 0.011342946290267162
Trained batch 444 in epoch 1, gen_loss = 1.5684458625450564, disc_loss = 0.0113270662277623
Trained batch 445 in epoch 1, gen_loss = 1.5676751649967757, disc_loss = 0.011309047734663475
Trained batch 446 in epoch 1, gen_loss = 1.5678059900100332, disc_loss = 0.01128699652974596
Trained batch 447 in epoch 1, gen_loss = 1.567609284871391, disc_loss = 0.01126950508920085
Trained batch 448 in epoch 1, gen_loss = 1.5672602916347953, disc_loss = 0.011247405868162606
Trained batch 449 in epoch 1, gen_loss = 1.5670018082194859, disc_loss = 0.011228764823689643
Trained batch 450 in epoch 1, gen_loss = 1.566993675845161, disc_loss = 0.011208480748269467
Trained batch 451 in epoch 1, gen_loss = 1.5666169342214027, disc_loss = 0.01118951291232205
Trained batch 452 in epoch 1, gen_loss = 1.5662783805371383, disc_loss = 0.011167535009674694
Trained batch 453 in epoch 1, gen_loss = 1.5656984107084737, disc_loss = 0.011147900421679069
Trained batch 454 in epoch 1, gen_loss = 1.5651608422562315, disc_loss = 0.011128708527034537
Trained batch 455 in epoch 1, gen_loss = 1.5650960920672667, disc_loss = 0.011107976471784672
Trained batch 456 in epoch 1, gen_loss = 1.5649793453237422, disc_loss = 0.011092325968003507
Trained batch 457 in epoch 1, gen_loss = 1.5647756249102962, disc_loss = 0.011073965034305269
Trained batch 458 in epoch 1, gen_loss = 1.5657592617088933, disc_loss = 0.011054450768291594
Trained batch 459 in epoch 1, gen_loss = 1.5655789631864299, disc_loss = 0.011034625238465632
Trained batch 460 in epoch 1, gen_loss = 1.5648537388075459, disc_loss = 0.011017579237077942
Trained batch 461 in epoch 1, gen_loss = 1.5643301988060856, disc_loss = 0.010998281335520652
Trained batch 462 in epoch 1, gen_loss = 1.564011123473907, disc_loss = 0.010976577175380843
Trained batch 463 in epoch 1, gen_loss = 1.5646227580206147, disc_loss = 0.010958095932939362
Trained batch 464 in epoch 1, gen_loss = 1.5645023151110578, disc_loss = 0.010936872088800996
Trained batch 465 in epoch 1, gen_loss = 1.5640463389040575, disc_loss = 0.010927970995307129
Trained batch 466 in epoch 1, gen_loss = 1.564660740868693, disc_loss = 0.010909208982018255
Trained batch 467 in epoch 1, gen_loss = 1.564368611217564, disc_loss = 0.010889481375756092
Trained batch 468 in epoch 1, gen_loss = 1.5647650827476973, disc_loss = 0.010868450179686155
Trained batch 469 in epoch 1, gen_loss = 1.5644268028279569, disc_loss = 0.010847493090191262
Trained batch 470 in epoch 1, gen_loss = 1.5630979505061091, disc_loss = 0.010867100619788097
Trained batch 471 in epoch 1, gen_loss = 1.5634924920938782, disc_loss = 0.010852107787563986
Trained batch 472 in epoch 1, gen_loss = 1.563268196759214, disc_loss = 0.010834197314893216
Trained batch 473 in epoch 1, gen_loss = 1.5630525481348803, disc_loss = 0.010816181993666046
Trained batch 474 in epoch 1, gen_loss = 1.5633137002744173, disc_loss = 0.010796174549644716
Trained batch 475 in epoch 1, gen_loss = 1.5628737919971722, disc_loss = 0.010776609833892278
Trained batch 476 in epoch 1, gen_loss = 1.5626152298985287, disc_loss = 0.01075565280486484
Trained batch 477 in epoch 1, gen_loss = 1.562997311977163, disc_loss = 0.010735756161118075
Trained batch 478 in epoch 1, gen_loss = 1.562778541339962, disc_loss = 0.010714823822563783
Trained batch 479 in epoch 1, gen_loss = 1.5629309723774591, disc_loss = 0.010696837881429626
Trained batch 480 in epoch 1, gen_loss = 1.5626751930450946, disc_loss = 0.01067695814354748
Trained batch 481 in epoch 1, gen_loss = 1.5623563305470953, disc_loss = 0.010658464017850675
Trained batch 482 in epoch 1, gen_loss = 1.5618999068534645, disc_loss = 0.010640626125482121
Trained batch 483 in epoch 1, gen_loss = 1.562105440157504, disc_loss = 0.010620104888966884
Trained batch 484 in epoch 1, gen_loss = 1.561992334582142, disc_loss = 0.010599764581942528
Trained batch 485 in epoch 1, gen_loss = 1.561955445833167, disc_loss = 0.010580123682437395
Trained batch 486 in epoch 1, gen_loss = 1.5614011084519372, disc_loss = 0.010560271770739258
Trained batch 487 in epoch 1, gen_loss = 1.5609715646896205, disc_loss = 0.010569395313037513
Trained batch 488 in epoch 1, gen_loss = 1.5604866055623154, disc_loss = 0.010556868988599682
Trained batch 489 in epoch 1, gen_loss = 1.560910845289425, disc_loss = 0.0105449407130993
Trained batch 490 in epoch 1, gen_loss = 1.5604730053006268, disc_loss = 0.010527048597838767
Trained batch 491 in epoch 1, gen_loss = 1.56045481998746, disc_loss = 0.010511048149262608
Trained batch 492 in epoch 1, gen_loss = 1.5605930312410088, disc_loss = 0.010496240644526818
Trained batch 493 in epoch 1, gen_loss = 1.5606068944641454, disc_loss = 0.010477777098226343
Trained batch 494 in epoch 1, gen_loss = 1.5610262714251124, disc_loss = 0.01045880565476237
Trained batch 495 in epoch 1, gen_loss = 1.561195984242424, disc_loss = 0.010440625696754713
Trained batch 496 in epoch 1, gen_loss = 1.5610691021145948, disc_loss = 0.010422581326594984
Trained batch 497 in epoch 1, gen_loss = 1.561218175303984, disc_loss = 0.010404658670972913
Trained batch 498 in epoch 1, gen_loss = 1.5617498842652193, disc_loss = 0.010386763945901262
Trained batch 499 in epoch 1, gen_loss = 1.5628820359706879, disc_loss = 0.010368887430755421
Trained batch 500 in epoch 1, gen_loss = 1.5629140476504724, disc_loss = 0.010351430408855502
Trained batch 501 in epoch 1, gen_loss = 1.5628783401265087, disc_loss = 0.010333215979909324
Trained batch 502 in epoch 1, gen_loss = 1.5623509639774118, disc_loss = 0.0103146510986078
Trained batch 503 in epoch 1, gen_loss = 1.5626659906572766, disc_loss = 0.010296790276437864
Trained batch 504 in epoch 1, gen_loss = 1.562906815509985, disc_loss = 0.01028665244224306
Trained batch 505 in epoch 1, gen_loss = 1.5626992698714668, disc_loss = 0.010271980795087182
Trained batch 506 in epoch 1, gen_loss = 1.5637824098034019, disc_loss = 0.010259086242509562
Trained batch 507 in epoch 1, gen_loss = 1.5634666521718183, disc_loss = 0.010243876900672398
Trained batch 508 in epoch 1, gen_loss = 1.5633623852945264, disc_loss = 0.010228649250410995
Trained batch 509 in epoch 1, gen_loss = 1.5629047398473703, disc_loss = 0.01021242461226625
Trained batch 510 in epoch 1, gen_loss = 1.5632821669083985, disc_loss = 0.010198003830936775
Trained batch 511 in epoch 1, gen_loss = 1.563147138338536, disc_loss = 0.010180572976196345
Trained batch 512 in epoch 1, gen_loss = 1.5626664816984657, disc_loss = 0.010166654942174157
Trained batch 513 in epoch 1, gen_loss = 1.562388452342512, disc_loss = 0.010149599246160717
Trained batch 514 in epoch 1, gen_loss = 1.562430843566228, disc_loss = 0.010134724912559161
Trained batch 515 in epoch 1, gen_loss = 1.5624404022859972, disc_loss = 0.010118151341236463
Trained batch 516 in epoch 1, gen_loss = 1.562083222879893, disc_loss = 0.010100001599180298
Trained batch 517 in epoch 1, gen_loss = 1.5627077939887766, disc_loss = 0.010083313659417828
Trained batch 518 in epoch 1, gen_loss = 1.5626977872756636, disc_loss = 0.01006605497517431
Trained batch 519 in epoch 1, gen_loss = 1.5630201747784247, disc_loss = 0.010048923703009048
Trained batch 520 in epoch 1, gen_loss = 1.5628266519868672, disc_loss = 0.010033524730832686
Trained batch 521 in epoch 1, gen_loss = 1.5625059275791562, disc_loss = 0.010017871714627077
Trained batch 522 in epoch 1, gen_loss = 1.5628722475318106, disc_loss = 0.010000749109633424
Trained batch 523 in epoch 1, gen_loss = 1.562775410086144, disc_loss = 0.009984998221736657
Trained batch 524 in epoch 1, gen_loss = 1.5630693501517887, disc_loss = 0.00996883091339398
Trained batch 525 in epoch 1, gen_loss = 1.5636406255312292, disc_loss = 0.009954754495550612
Trained batch 526 in epoch 1, gen_loss = 1.5635784778468296, disc_loss = 0.009937333828346375
Trained batch 527 in epoch 1, gen_loss = 1.563959367121711, disc_loss = 0.009922142446488248
Trained batch 528 in epoch 1, gen_loss = 1.5642695280464476, disc_loss = 0.009906493884485765
Trained batch 529 in epoch 1, gen_loss = 1.5639166253917622, disc_loss = 0.009891470551670898
Trained batch 530 in epoch 1, gen_loss = 1.5635752886702112, disc_loss = 0.009876969812473846
Trained batch 531 in epoch 1, gen_loss = 1.563168110479986, disc_loss = 0.00986125164950193
Trained batch 532 in epoch 1, gen_loss = 1.5633848028827115, disc_loss = 0.009845799238462086
Trained batch 533 in epoch 1, gen_loss = 1.5634358938267168, disc_loss = 0.009829417125593124
Trained batch 534 in epoch 1, gen_loss = 1.5631925304359364, disc_loss = 0.009812743229264934
Trained batch 535 in epoch 1, gen_loss = 1.5632088500172345, disc_loss = 0.0097969371957727
Trained batch 536 in epoch 1, gen_loss = 1.5628539929842815, disc_loss = 0.009782439590847116
Trained batch 537 in epoch 1, gen_loss = 1.5627080543333713, disc_loss = 0.009767805202020207
Trained batch 538 in epoch 1, gen_loss = 1.5626738715039112, disc_loss = 0.009751852014614355
Trained batch 539 in epoch 1, gen_loss = 1.5628308876797006, disc_loss = 0.009735817527204442
Trained batch 540 in epoch 1, gen_loss = 1.5626161929199303, disc_loss = 0.00972104063952624
Trained batch 541 in epoch 1, gen_loss = 1.5621696048557099, disc_loss = 0.00970575393371308
Trained batch 542 in epoch 1, gen_loss = 1.5623095553663335, disc_loss = 0.009689322779015989
Trained batch 543 in epoch 1, gen_loss = 1.5624664776465471, disc_loss = 0.009674302452635054
Trained batch 544 in epoch 1, gen_loss = 1.5624924990015292, disc_loss = 0.009660147704342124
Trained batch 545 in epoch 1, gen_loss = 1.5621402678472218, disc_loss = 0.009645694712941934
Trained batch 546 in epoch 1, gen_loss = 1.5621698223040787, disc_loss = 0.009629112272587191
Trained batch 547 in epoch 1, gen_loss = 1.5626633526199925, disc_loss = 0.009613047622761987
Trained batch 548 in epoch 1, gen_loss = 1.5622999750634143, disc_loss = 0.009598115613138666
Trained batch 549 in epoch 1, gen_loss = 1.562162296555259, disc_loss = 0.009582556556508115
Trained batch 550 in epoch 1, gen_loss = 1.562047177996696, disc_loss = 0.009568012247141789
Trained batch 551 in epoch 1, gen_loss = 1.5621984611818756, disc_loss = 0.009552204818528085
Trained batch 552 in epoch 1, gen_loss = 1.5624713908483494, disc_loss = 0.00953631741081063
Trained batch 553 in epoch 1, gen_loss = 1.5622834748309442, disc_loss = 0.0095212907228402
Trained batch 554 in epoch 1, gen_loss = 1.562472306500684, disc_loss = 0.009506390407484293
Trained batch 555 in epoch 1, gen_loss = 1.5621295099635777, disc_loss = 0.0094925435977065
Trained batch 556 in epoch 1, gen_loss = 1.5616135637892854, disc_loss = 0.009477350315019735
Trained batch 557 in epoch 1, gen_loss = 1.5615101238732696, disc_loss = 0.009462111738658975
Trained batch 558 in epoch 1, gen_loss = 1.5611191177624069, disc_loss = 0.00944929546572448
Trained batch 559 in epoch 1, gen_loss = 1.5609055793711117, disc_loss = 0.009434303434889962
Trained batch 560 in epoch 1, gen_loss = 1.561023807143145, disc_loss = 0.00941937365473718
Trained batch 561 in epoch 1, gen_loss = 1.5612868908461304, disc_loss = 0.009404749781045784
Trained batch 562 in epoch 1, gen_loss = 1.56087769644722, disc_loss = 0.009389978682549528
Trained batch 563 in epoch 1, gen_loss = 1.5609345890528767, disc_loss = 0.009374548997507094
Trained batch 564 in epoch 1, gen_loss = 1.5607020734685713, disc_loss = 0.009361082015031602
Trained batch 565 in epoch 1, gen_loss = 1.561598878235362, disc_loss = 0.009347185126609455
Trained batch 566 in epoch 1, gen_loss = 1.5611749424925978, disc_loss = 0.00933422815860323
Trained batch 567 in epoch 1, gen_loss = 1.5610843317609437, disc_loss = 0.009319246841904471
Trained batch 568 in epoch 1, gen_loss = 1.5618850849634314, disc_loss = 0.009307580617639467
Trained batch 569 in epoch 1, gen_loss = 1.5618807550062213, disc_loss = 0.009294818739382257
Trained batch 570 in epoch 1, gen_loss = 1.5623632573413349, disc_loss = 0.009279939593525436
Trained batch 571 in epoch 1, gen_loss = 1.5621077232844347, disc_loss = 0.009265755428981453
Trained batch 572 in epoch 1, gen_loss = 1.5625826467810293, disc_loss = 0.00925105895831235
Trained batch 573 in epoch 1, gen_loss = 1.5626199937032905, disc_loss = 0.009236592854286352
Trained batch 574 in epoch 1, gen_loss = 1.5628578289695407, disc_loss = 0.009221853925137902
Trained batch 575 in epoch 1, gen_loss = 1.5628166693366237, disc_loss = 0.009207500757333441
Trained batch 576 in epoch 1, gen_loss = 1.5626642152382968, disc_loss = 0.00919300472352531
Trained batch 577 in epoch 1, gen_loss = 1.5628205568732687, disc_loss = 0.009178199000079764
Trained batch 578 in epoch 1, gen_loss = 1.563279882613859, disc_loss = 0.009164278920649813
Trained batch 579 in epoch 1, gen_loss = 1.5631325489488141, disc_loss = 0.00915129861055777
Trained batch 580 in epoch 1, gen_loss = 1.563358093292906, disc_loss = 0.009137436148442854
Trained batch 581 in epoch 1, gen_loss = 1.562797950100653, disc_loss = 0.009122732446566577
Trained batch 582 in epoch 1, gen_loss = 1.5620613672721038, disc_loss = 0.009108655983090918
Trained batch 583 in epoch 1, gen_loss = 1.5619882786110655, disc_loss = 0.00909421431584035
Trained batch 584 in epoch 1, gen_loss = 1.56127796865936, disc_loss = 0.009080037638111216
Trained batch 585 in epoch 1, gen_loss = 1.561166827182314, disc_loss = 0.009066437219794833
Trained batch 586 in epoch 1, gen_loss = 1.5612008669104243, disc_loss = 0.00905332522154619
Trained batch 587 in epoch 1, gen_loss = 1.561667546934011, disc_loss = 0.00903947065082667
Trained batch 588 in epoch 1, gen_loss = 1.562138616532745, disc_loss = 0.00902545206015139
Trained batch 589 in epoch 1, gen_loss = 1.5619270409567882, disc_loss = 0.009012162075595046
Trained batch 590 in epoch 1, gen_loss = 1.5618653146143493, disc_loss = 0.008997853449230632
Trained batch 591 in epoch 1, gen_loss = 1.5616904909949045, disc_loss = 0.008984695564101235
Trained batch 592 in epoch 1, gen_loss = 1.561046131746765, disc_loss = 0.008973036356966058
Trained batch 593 in epoch 1, gen_loss = 1.5606095993558968, disc_loss = 0.008961044047702016
Trained batch 594 in epoch 1, gen_loss = 1.5601888177775536, disc_loss = 0.008947127182506212
Trained batch 595 in epoch 1, gen_loss = 1.5598227669728681, disc_loss = 0.008933519571570323
Trained batch 596 in epoch 1, gen_loss = 1.5597561531929514, disc_loss = 0.008921043681260822
Trained batch 597 in epoch 1, gen_loss = 1.5595688953447502, disc_loss = 0.008907736364045776
Trained batch 598 in epoch 1, gen_loss = 1.5588458322722447, disc_loss = 0.008908035232936606
Trained batch 599 in epoch 1, gen_loss = 1.5587199745575586, disc_loss = 0.008900510287785436
Trained batch 600 in epoch 1, gen_loss = 1.558324427057225, disc_loss = 0.008891801036504592
Trained batch 601 in epoch 1, gen_loss = 1.5580741901730382, disc_loss = 0.008879433405075835
Trained batch 602 in epoch 1, gen_loss = 1.5578900674484657, disc_loss = 0.008867498741397915
Trained batch 603 in epoch 1, gen_loss = 1.557701046498406, disc_loss = 0.008859005672737666
Trained batch 604 in epoch 1, gen_loss = 1.5580850274109643, disc_loss = 0.00884924757819669
Trained batch 605 in epoch 1, gen_loss = 1.5577747528702512, disc_loss = 0.008837517019627898
Trained batch 606 in epoch 1, gen_loss = 1.5573849071191603, disc_loss = 0.00882544687477706
Trained batch 607 in epoch 1, gen_loss = 1.5568133257329464, disc_loss = 0.008812905749628522
Trained batch 608 in epoch 1, gen_loss = 1.5564144229262529, disc_loss = 0.008800901036823478
Trained batch 609 in epoch 1, gen_loss = 1.556470561027527, disc_loss = 0.008789025667050976
Trained batch 610 in epoch 1, gen_loss = 1.5568673522889906, disc_loss = 0.008779182330588619
Trained batch 611 in epoch 1, gen_loss = 1.5568335027086968, disc_loss = 0.008772339387374529
Trained batch 612 in epoch 1, gen_loss = 1.557291221657546, disc_loss = 0.008762645180512608
Trained batch 613 in epoch 1, gen_loss = 1.5569388396576873, disc_loss = 0.008752475759709945
Trained batch 614 in epoch 1, gen_loss = 1.5566402943153692, disc_loss = 0.008741032508129966
Trained batch 615 in epoch 1, gen_loss = 1.5568676739931107, disc_loss = 0.008730972429050295
Trained batch 616 in epoch 1, gen_loss = 1.5571037511578256, disc_loss = 0.008720408940844002
Trained batch 617 in epoch 1, gen_loss = 1.5570312900450622, disc_loss = 0.008708051998001707
Trained batch 618 in epoch 1, gen_loss = 1.557583351512718, disc_loss = 0.008696232230559755
Trained batch 619 in epoch 1, gen_loss = 1.5575092394505778, disc_loss = 0.008683514405669073
Trained batch 620 in epoch 1, gen_loss = 1.5576854729230085, disc_loss = 0.00867078871169651
Trained batch 621 in epoch 1, gen_loss = 1.5578564499352139, disc_loss = 0.008658297362282926
Trained batch 622 in epoch 1, gen_loss = 1.5581743282835518, disc_loss = 0.008648814972924341
Trained batch 623 in epoch 1, gen_loss = 1.558417031589227, disc_loss = 0.00863730588314819
Trained batch 624 in epoch 1, gen_loss = 1.558725358390808, disc_loss = 0.008625021225772798
Trained batch 625 in epoch 1, gen_loss = 1.558951028238851, disc_loss = 0.008613800357159869
Trained batch 626 in epoch 1, gen_loss = 1.5589667705067418, disc_loss = 0.008601913265208082
Trained batch 627 in epoch 1, gen_loss = 1.5592794357591373, disc_loss = 0.008589571434744947
Trained batch 628 in epoch 1, gen_loss = 1.5598440841195693, disc_loss = 0.008577472276375621
Trained batch 629 in epoch 1, gen_loss = 1.5595756502378555, disc_loss = 0.008565251379355137
Trained batch 630 in epoch 1, gen_loss = 1.5598249446760077, disc_loss = 0.008554431094150406
Trained batch 631 in epoch 1, gen_loss = 1.5599822237899033, disc_loss = 0.008543959848436858
Trained batch 632 in epoch 1, gen_loss = 1.5601882676566006, disc_loss = 0.008531789548436142
Trained batch 633 in epoch 1, gen_loss = 1.5598439984141088, disc_loss = 0.00852052033555691
Trained batch 634 in epoch 1, gen_loss = 1.5597324684848937, disc_loss = 0.008508676098380972
Trained batch 635 in epoch 1, gen_loss = 1.5599111502275527, disc_loss = 0.00849786884449393
Trained batch 636 in epoch 1, gen_loss = 1.5598175112082033, disc_loss = 0.00848576541148635
Trained batch 637 in epoch 1, gen_loss = 1.5597363981333645, disc_loss = 0.008474337097460281
Trained batch 638 in epoch 1, gen_loss = 1.5595439355324878, disc_loss = 0.008464531902863654
Trained batch 639 in epoch 1, gen_loss = 1.5609123872593045, disc_loss = 0.008453600568282127
Trained batch 640 in epoch 1, gen_loss = 1.5617634150985622, disc_loss = 0.008441852902929632
Trained batch 641 in epoch 1, gen_loss = 1.5615543789952715, disc_loss = 0.008432167190898825
Trained batch 642 in epoch 1, gen_loss = 1.560772625691783, disc_loss = 0.008422741808741705
Trained batch 643 in epoch 1, gen_loss = 1.560994998823782, disc_loss = 0.008412035667483539
Trained batch 644 in epoch 1, gen_loss = 1.5606368172076321, disc_loss = 0.008400594154842083
Trained batch 645 in epoch 1, gen_loss = 1.560644136862858, disc_loss = 0.008389184233226493
Trained batch 646 in epoch 1, gen_loss = 1.5602725314946595, disc_loss = 0.008377211629571408
Trained batch 647 in epoch 1, gen_loss = 1.559937149838165, disc_loss = 0.008366173806055564
Trained batch 648 in epoch 1, gen_loss = 1.5597051220425104, disc_loss = 0.00835466922263691
Trained batch 649 in epoch 1, gen_loss = 1.5595093219096845, disc_loss = 0.008342969635447773
Trained batch 650 in epoch 1, gen_loss = 1.559563326396151, disc_loss = 0.008331124383699401
Trained batch 651 in epoch 1, gen_loss = 1.5590262884742643, disc_loss = 0.008319533575559035
Trained batch 652 in epoch 1, gen_loss = 1.559629844852465, disc_loss = 0.008308353028930496
Trained batch 653 in epoch 1, gen_loss = 1.5593213302279831, disc_loss = 0.008297368451712271
Trained batch 654 in epoch 1, gen_loss = 1.559350645997142, disc_loss = 0.008285636462107698
Trained batch 655 in epoch 1, gen_loss = 1.5593634843826294, disc_loss = 0.008274378266189781
Trained batch 656 in epoch 1, gen_loss = 1.5591730661406729, disc_loss = 0.008262865637114366
Trained batch 657 in epoch 1, gen_loss = 1.5590883931852764, disc_loss = 0.00825175216662454
Trained batch 658 in epoch 1, gen_loss = 1.559105992678988, disc_loss = 0.008241155625116759
Trained batch 659 in epoch 1, gen_loss = 1.558838245904807, disc_loss = 0.008230269993884686
Trained batch 660 in epoch 1, gen_loss = 1.5587528651853553, disc_loss = 0.008218960876508972
Trained batch 661 in epoch 1, gen_loss = 1.5584693428612908, disc_loss = 0.008207585288737858
Trained batch 662 in epoch 1, gen_loss = 1.5587080472554915, disc_loss = 0.00819636083432427
Trained batch 663 in epoch 1, gen_loss = 1.5583459982670933, disc_loss = 0.008185866275779111
Trained batch 664 in epoch 1, gen_loss = 1.558634424747381, disc_loss = 0.008175187911120544
Trained batch 665 in epoch 1, gen_loss = 1.5588607773766503, disc_loss = 0.008165747151614304
Trained batch 666 in epoch 1, gen_loss = 1.558761213494205, disc_loss = 0.008154589071942457
Trained batch 667 in epoch 1, gen_loss = 1.5591925816264696, disc_loss = 0.008143575898473414
Trained batch 668 in epoch 1, gen_loss = 1.5594049565638841, disc_loss = 0.008132165139426181
Trained batch 669 in epoch 1, gen_loss = 1.5593754273741993, disc_loss = 0.00812101860247455
Trained batch 670 in epoch 1, gen_loss = 1.559781147008859, disc_loss = 0.008109940430992623
Trained batch 671 in epoch 1, gen_loss = 1.5594430590669315, disc_loss = 0.008098414932430301
Trained batch 672 in epoch 1, gen_loss = 1.5588793347175904, disc_loss = 0.008087057311734445
Trained batch 673 in epoch 1, gen_loss = 1.5591788695191064, disc_loss = 0.00807578960489392
Trained batch 674 in epoch 1, gen_loss = 1.5594337578173036, disc_loss = 0.008064880392867726
Trained batch 675 in epoch 1, gen_loss = 1.5592567883652342, disc_loss = 0.008054056820212024
Trained batch 676 in epoch 1, gen_loss = 1.5595448652785848, disc_loss = 0.008043461121703694
Trained batch 677 in epoch 1, gen_loss = 1.5602372686068218, disc_loss = 0.008033437075347167
Trained batch 678 in epoch 1, gen_loss = 1.5602149391033864, disc_loss = 0.008023325085496963
Trained batch 679 in epoch 1, gen_loss = 1.5606527672094457, disc_loss = 0.008012563191647025
Trained batch 680 in epoch 1, gen_loss = 1.5603705471307696, disc_loss = 0.00800202128120285
Trained batch 681 in epoch 1, gen_loss = 1.5600251646335523, disc_loss = 0.007992297634876694
Trained batch 682 in epoch 1, gen_loss = 1.5594899280877623, disc_loss = 0.007981401387376078
Trained batch 683 in epoch 1, gen_loss = 1.5598901776891005, disc_loss = 0.007970819014408121
Trained batch 684 in epoch 1, gen_loss = 1.559726184476031, disc_loss = 0.007960474378145538
Trained batch 685 in epoch 1, gen_loss = 1.5593300962239591, disc_loss = 0.007950970225462773
Trained batch 686 in epoch 1, gen_loss = 1.559471659785275, disc_loss = 0.007940560971121365
Trained batch 687 in epoch 1, gen_loss = 1.5593322622914647, disc_loss = 0.007930222815090484
Trained batch 688 in epoch 1, gen_loss = 1.559152342584552, disc_loss = 0.007919619742337227
Trained batch 689 in epoch 1, gen_loss = 1.5591407150462053, disc_loss = 0.007908731749858303
Trained batch 690 in epoch 1, gen_loss = 1.5589381885942606, disc_loss = 0.007898402058144738
Trained batch 691 in epoch 1, gen_loss = 1.558828574384568, disc_loss = 0.007888744895432596
Trained batch 692 in epoch 1, gen_loss = 1.5581593441240715, disc_loss = 0.007879410354315719
Trained batch 693 in epoch 1, gen_loss = 1.5582205210020632, disc_loss = 0.007869445174910337
Trained batch 694 in epoch 1, gen_loss = 1.5583138966731889, disc_loss = 0.007859380479747925
Trained batch 695 in epoch 1, gen_loss = 1.5587018673447357, disc_loss = 0.00784975992486914
Trained batch 696 in epoch 1, gen_loss = 1.5583927044738486, disc_loss = 0.007840350217157855
Trained batch 697 in epoch 1, gen_loss = 1.5588434902166568, disc_loss = 0.007831394085980803
Trained batch 698 in epoch 1, gen_loss = 1.5585004173123274, disc_loss = 0.007820703141241054
Trained batch 699 in epoch 1, gen_loss = 1.5585052158151353, disc_loss = 0.007811029109247362
Trained batch 700 in epoch 1, gen_loss = 1.5578988069474442, disc_loss = 0.007801161963433179
Trained batch 701 in epoch 1, gen_loss = 1.5576601081084662, disc_loss = 0.00779133637892938
Trained batch 702 in epoch 1, gen_loss = 1.5576694125301638, disc_loss = 0.007780887819732212
Trained batch 703 in epoch 1, gen_loss = 1.5574359949678183, disc_loss = 0.0077705391303921215
Trained batch 704 in epoch 1, gen_loss = 1.5576870769473679, disc_loss = 0.0077606556013619515
Trained batch 705 in epoch 1, gen_loss = 1.5575781601346586, disc_loss = 0.007751569473545763
Trained batch 706 in epoch 1, gen_loss = 1.5582263304455446, disc_loss = 0.007741764510836508
Trained batch 707 in epoch 1, gen_loss = 1.5583207997898598, disc_loss = 0.007732716724722144
Trained batch 708 in epoch 1, gen_loss = 1.5582652766210237, disc_loss = 0.007723384196710759
Trained batch 709 in epoch 1, gen_loss = 1.558645806681942, disc_loss = 0.007713895048872358
Trained batch 710 in epoch 1, gen_loss = 1.558486179460453, disc_loss = 0.00770374377952848
Trained batch 711 in epoch 1, gen_loss = 1.5588099645094926, disc_loss = 0.007693635489916876
Trained batch 712 in epoch 1, gen_loss = 1.5587934767213476, disc_loss = 0.007684097639071137
Trained batch 713 in epoch 1, gen_loss = 1.5588720005099512, disc_loss = 0.007674485472210615
Trained batch 714 in epoch 1, gen_loss = 1.558818176242855, disc_loss = 0.007664402645086167
Trained batch 715 in epoch 1, gen_loss = 1.5588218486508845, disc_loss = 0.0076548208382326
Trained batch 716 in epoch 1, gen_loss = 1.5591804374378262, disc_loss = 0.007645510333663923
Trained batch 717 in epoch 1, gen_loss = 1.5590778967796262, disc_loss = 0.007636964669044799
Trained batch 718 in epoch 1, gen_loss = 1.5591714209740948, disc_loss = 0.007627333209308133
Trained batch 719 in epoch 1, gen_loss = 1.559397607213921, disc_loss = 0.007617603663149768
Trained batch 720 in epoch 1, gen_loss = 1.5593991992212366, disc_loss = 0.007607853588954598
Trained batch 721 in epoch 1, gen_loss = 1.5591485749651521, disc_loss = 0.007597739792903279
Trained batch 722 in epoch 1, gen_loss = 1.5591291466194563, disc_loss = 0.007587903234054609
Trained batch 723 in epoch 1, gen_loss = 1.5591295975677215, disc_loss = 0.007578365572838201
Trained batch 724 in epoch 1, gen_loss = 1.5593419548560834, disc_loss = 0.007569065310044921
Trained batch 725 in epoch 1, gen_loss = 1.5590910790051968, disc_loss = 0.0075597486508588154
Trained batch 726 in epoch 1, gen_loss = 1.5591026680669562, disc_loss = 0.0075501806054333485
Trained batch 727 in epoch 1, gen_loss = 1.5590119263628026, disc_loss = 0.007541430648736103
Trained batch 728 in epoch 1, gen_loss = 1.5599936428384036, disc_loss = 0.0075327500482811624
Trained batch 729 in epoch 1, gen_loss = 1.559980134441428, disc_loss = 0.007523741263558144
Trained batch 730 in epoch 1, gen_loss = 1.560449621419737, disc_loss = 0.007514560789604979
Trained batch 731 in epoch 1, gen_loss = 1.560158883939024, disc_loss = 0.007505776439354465
Trained batch 732 in epoch 1, gen_loss = 1.5602602166661137, disc_loss = 0.007497045242463939
Trained batch 733 in epoch 1, gen_loss = 1.560079252037755, disc_loss = 0.00748906330708592
Trained batch 734 in epoch 1, gen_loss = 1.5604795598659387, disc_loss = 0.007480195752379871
Trained batch 735 in epoch 1, gen_loss = 1.560195347375196, disc_loss = 0.007470692442004055
Trained batch 736 in epoch 1, gen_loss = 1.560621888537258, disc_loss = 0.007461350578257152
Trained batch 737 in epoch 1, gen_loss = 1.5604936876271152, disc_loss = 0.007452230406904576
Trained batch 738 in epoch 1, gen_loss = 1.560391697412576, disc_loss = 0.00744273700013017
Trained batch 739 in epoch 1, gen_loss = 1.5603471991178153, disc_loss = 0.007433298281968156
Trained batch 740 in epoch 1, gen_loss = 1.5602903115121942, disc_loss = 0.007425060920430191
Trained batch 741 in epoch 1, gen_loss = 1.560816516934058, disc_loss = 0.007417068866182262
Trained batch 742 in epoch 1, gen_loss = 1.5604680330564002, disc_loss = 0.007408498138545613
Trained batch 743 in epoch 1, gen_loss = 1.5604228261978395, disc_loss = 0.007399147967296285
Trained batch 744 in epoch 1, gen_loss = 1.5605451443051332, disc_loss = 0.0073905516092762375
Trained batch 745 in epoch 1, gen_loss = 1.5606201062573184, disc_loss = 0.007381755317976116
Trained batch 746 in epoch 1, gen_loss = 1.5610104901404425, disc_loss = 0.007372519878180912
Trained batch 747 in epoch 1, gen_loss = 1.5612231754364176, disc_loss = 0.007363358440889571
Trained batch 748 in epoch 1, gen_loss = 1.5610618624731758, disc_loss = 0.007354150443848904
Trained batch 749 in epoch 1, gen_loss = 1.5608851110140483, disc_loss = 0.007345623444300145
Trained batch 750 in epoch 1, gen_loss = 1.5607547044119092, disc_loss = 0.007336690332960665
Trained batch 751 in epoch 1, gen_loss = 1.5608745524857908, disc_loss = 0.007327514367677802
Trained batch 752 in epoch 1, gen_loss = 1.5606578938356275, disc_loss = 0.007318339820502568
Trained batch 753 in epoch 1, gen_loss = 1.5604558933318768, disc_loss = 0.007309147153301066
Trained batch 754 in epoch 1, gen_loss = 1.5602464331696364, disc_loss = 0.007300097308667463
Trained batch 755 in epoch 1, gen_loss = 1.560878908823407, disc_loss = 0.007291435383392064
Trained batch 756 in epoch 1, gen_loss = 1.5604936201002355, disc_loss = 0.007282799438762883
Trained batch 757 in epoch 1, gen_loss = 1.5604040144615878, disc_loss = 0.007273887415412853
Trained batch 758 in epoch 1, gen_loss = 1.560389063889173, disc_loss = 0.0072647520692679145
Trained batch 759 in epoch 1, gen_loss = 1.560955938069444, disc_loss = 0.007255837902668741
Trained batch 760 in epoch 1, gen_loss = 1.560982051252849, disc_loss = 0.007246920427597531
Trained batch 761 in epoch 1, gen_loss = 1.5610887156383886, disc_loss = 0.007238025782771012
Trained batch 762 in epoch 1, gen_loss = 1.560893905584653, disc_loss = 0.007229345628877597
Trained batch 763 in epoch 1, gen_loss = 1.5610251359602543, disc_loss = 0.007220924426530273
Trained batch 764 in epoch 1, gen_loss = 1.561198164434994, disc_loss = 0.007213416264858097
Trained batch 765 in epoch 1, gen_loss = 1.5610812609874238, disc_loss = 0.007204998319457327
Trained batch 766 in epoch 1, gen_loss = 1.5607341507733878, disc_loss = 0.007197378401118154
Trained batch 767 in epoch 1, gen_loss = 1.5607615013917286, disc_loss = 0.007190270789957746
Trained batch 768 in epoch 1, gen_loss = 1.560187608584936, disc_loss = 0.007182019048156059
Trained batch 769 in epoch 1, gen_loss = 1.5598581893103463, disc_loss = 0.0071736445150779584
Trained batch 770 in epoch 1, gen_loss = 1.5599345834647944, disc_loss = 0.007165410907560991
Trained batch 771 in epoch 1, gen_loss = 1.5602780921780384, disc_loss = 0.007157018780120205
Trained batch 772 in epoch 1, gen_loss = 1.5598788904496028, disc_loss = 0.007148798526370751
Trained batch 773 in epoch 1, gen_loss = 1.5597640527003187, disc_loss = 0.007140014263419542
Trained batch 774 in epoch 1, gen_loss = 1.5591661485548942, disc_loss = 0.007131824826694003
Trained batch 775 in epoch 1, gen_loss = 1.5591130353433569, disc_loss = 0.007123525683072302
Trained batch 776 in epoch 1, gen_loss = 1.5594272641141442, disc_loss = 0.0071150392040048764
Trained batch 777 in epoch 1, gen_loss = 1.5593297337505077, disc_loss = 0.007106575391973263
Trained batch 778 in epoch 1, gen_loss = 1.5593535121200326, disc_loss = 0.007098011474710302
Trained batch 779 in epoch 1, gen_loss = 1.5591967810422946, disc_loss = 0.007089461695450621
Trained batch 780 in epoch 1, gen_loss = 1.5592696262230183, disc_loss = 0.007081284539439571
Trained batch 781 in epoch 1, gen_loss = 1.5592588555172582, disc_loss = 0.007073571089469969
Trained batch 782 in epoch 1, gen_loss = 1.559253904554579, disc_loss = 0.007065337380700022
Trained batch 783 in epoch 1, gen_loss = 1.5590588295338106, disc_loss = 0.007059168532800775
Trained batch 784 in epoch 1, gen_loss = 1.5591802997953572, disc_loss = 0.0070511149161696955
Trained batch 785 in epoch 1, gen_loss = 1.559235780293705, disc_loss = 0.007043490375545582
Trained batch 786 in epoch 1, gen_loss = 1.5590946495608726, disc_loss = 0.00703534589622707
Trained batch 787 in epoch 1, gen_loss = 1.5594352719747475, disc_loss = 0.007027425430877593
Trained batch 788 in epoch 1, gen_loss = 1.559522022614763, disc_loss = 0.007019476883549536
Trained batch 789 in epoch 1, gen_loss = 1.559434297114988, disc_loss = 0.007011094281031408
Trained batch 790 in epoch 1, gen_loss = 1.5592790187987606, disc_loss = 0.007002719845138573
Trained batch 791 in epoch 1, gen_loss = 1.5589153873498993, disc_loss = 0.006994504145353343
Trained batch 792 in epoch 1, gen_loss = 1.5586840380335516, disc_loss = 0.006986179675950644
Trained batch 793 in epoch 1, gen_loss = 1.5587876670306515, disc_loss = 0.006977749059276751
Trained batch 794 in epoch 1, gen_loss = 1.558753564072855, disc_loss = 0.006969638554922616
Trained batch 795 in epoch 1, gen_loss = 1.5586671090904791, disc_loss = 0.006961246516697996
Trained batch 796 in epoch 1, gen_loss = 1.5587854292641021, disc_loss = 0.006953056925465733
Trained batch 797 in epoch 1, gen_loss = 1.558615872136931, disc_loss = 0.006944895574921056
Trained batch 798 in epoch 1, gen_loss = 1.5585273860840685, disc_loss = 0.006936949095178806
Trained batch 799 in epoch 1, gen_loss = 1.5582307659089565, disc_loss = 0.0069293527074478336
Trained batch 800 in epoch 1, gen_loss = 1.5583490552973658, disc_loss = 0.006921192192787609
Trained batch 801 in epoch 1, gen_loss = 1.5580390566899591, disc_loss = 0.006913393595084047
Trained batch 802 in epoch 1, gen_loss = 1.5578808529142425, disc_loss = 0.006905858338100704
Trained batch 803 in epoch 1, gen_loss = 1.5578317959510273, disc_loss = 0.0068987478888408275
Trained batch 804 in epoch 1, gen_loss = 1.5577538362941385, disc_loss = 0.006891901344812898
Trained batch 805 in epoch 1, gen_loss = 1.5577503714904595, disc_loss = 0.006884265380360362
Trained batch 806 in epoch 1, gen_loss = 1.5572076136294795, disc_loss = 0.006876625751691629
Trained batch 807 in epoch 1, gen_loss = 1.5573974478952954, disc_loss = 0.00686873549528911
Trained batch 808 in epoch 1, gen_loss = 1.5570662777562372, disc_loss = 0.006861695734630322
Trained batch 809 in epoch 1, gen_loss = 1.5568815800878737, disc_loss = 0.006854455110280671
Trained batch 810 in epoch 1, gen_loss = 1.557144415216881, disc_loss = 0.006846875106196956
Trained batch 811 in epoch 1, gen_loss = 1.5571008653476321, disc_loss = 0.006839393165388048
Trained batch 812 in epoch 1, gen_loss = 1.5569281017941596, disc_loss = 0.006831488902083464
Trained batch 813 in epoch 1, gen_loss = 1.5571175952801248, disc_loss = 0.0068239701336666745
Trained batch 814 in epoch 1, gen_loss = 1.5568709137980923, disc_loss = 0.006816961295492776
Trained batch 815 in epoch 1, gen_loss = 1.556730795870809, disc_loss = 0.006809387693768561
Trained batch 816 in epoch 1, gen_loss = 1.5569631198336766, disc_loss = 0.006801916989721552
Trained batch 817 in epoch 1, gen_loss = 1.5567995986029104, disc_loss = 0.006795991213872976
Trained batch 818 in epoch 1, gen_loss = 1.5565738787144532, disc_loss = 0.00678852555628153
Trained batch 819 in epoch 1, gen_loss = 1.556806427531126, disc_loss = 0.006782449107999039
Trained batch 820 in epoch 1, gen_loss = 1.5574792341831687, disc_loss = 0.006775600000815784
Trained batch 821 in epoch 1, gen_loss = 1.55727307349806, disc_loss = 0.006768032211328544
Trained batch 822 in epoch 1, gen_loss = 1.5571248983264983, disc_loss = 0.006760290138469274
Trained batch 823 in epoch 1, gen_loss = 1.5571208821917044, disc_loss = 0.006752976356455672
Trained batch 824 in epoch 1, gen_loss = 1.5565420855897845, disc_loss = 0.006745681380711947
Trained batch 825 in epoch 1, gen_loss = 1.5563352437053986, disc_loss = 0.006737930383916593
Trained batch 826 in epoch 1, gen_loss = 1.556574326184237, disc_loss = 0.006730975183977001
Trained batch 827 in epoch 1, gen_loss = 1.5571006795634394, disc_loss = 0.006724423221323711
Trained batch 828 in epoch 1, gen_loss = 1.557234262240954, disc_loss = 0.006716888221237748
Trained batch 829 in epoch 1, gen_loss = 1.5573923392468187, disc_loss = 0.006709836504852725
Trained batch 830 in epoch 1, gen_loss = 1.5571372484615706, disc_loss = 0.006702809563646581
Trained batch 831 in epoch 1, gen_loss = 1.5573860563051243, disc_loss = 0.0066953514283341065
Trained batch 832 in epoch 1, gen_loss = 1.5571981455240789, disc_loss = 0.006688066348840179
Trained batch 833 in epoch 1, gen_loss = 1.5571332483840503, disc_loss = 0.006681468789023236
Trained batch 834 in epoch 1, gen_loss = 1.5570228222601428, disc_loss = 0.006674722632676262
Trained batch 835 in epoch 1, gen_loss = 1.5569577947187652, disc_loss = 0.006667765864591909
Trained batch 836 in epoch 1, gen_loss = 1.556941476204347, disc_loss = 0.0066602077330459855
Trained batch 837 in epoch 1, gen_loss = 1.5573598352707656, disc_loss = 0.006653035869998335
Trained batch 838 in epoch 1, gen_loss = 1.5573036065402843, disc_loss = 0.006645553524327588
Trained batch 839 in epoch 1, gen_loss = 1.5574422451711836, disc_loss = 0.006638118361124292
Trained batch 840 in epoch 1, gen_loss = 1.55726845837093, disc_loss = 0.006630782031086766
Trained batch 841 in epoch 1, gen_loss = 1.5576476661439747, disc_loss = 0.006623477096193207
Trained batch 842 in epoch 1, gen_loss = 1.557562342600749, disc_loss = 0.006616266936777449
Trained batch 843 in epoch 1, gen_loss = 1.5573334926960027, disc_loss = 0.006609189909467942
Trained batch 844 in epoch 1, gen_loss = 1.556960153720788, disc_loss = 0.006602086970987647
Trained batch 845 in epoch 1, gen_loss = 1.5572772283926077, disc_loss = 0.006595598284750142
Trained batch 846 in epoch 1, gen_loss = 1.5574947308480669, disc_loss = 0.006588506057128363
Trained batch 847 in epoch 1, gen_loss = 1.557400110195268, disc_loss = 0.006581584511877736
Trained batch 848 in epoch 1, gen_loss = 1.5570421086885342, disc_loss = 0.0065746657298444535
Trained batch 849 in epoch 1, gen_loss = 1.5570013812009027, disc_loss = 0.006567769889747176
Trained batch 850 in epoch 1, gen_loss = 1.5566752161458572, disc_loss = 0.006560368752314957
Trained batch 851 in epoch 1, gen_loss = 1.5567815885857237, disc_loss = 0.006553135942532451
Trained batch 852 in epoch 1, gen_loss = 1.5569879252633902, disc_loss = 0.006546149319762491
Trained batch 853 in epoch 1, gen_loss = 1.5568063173975264, disc_loss = 0.0065389539452040115
Trained batch 854 in epoch 1, gen_loss = 1.5566575008526182, disc_loss = 0.006532030252703025
Trained batch 855 in epoch 1, gen_loss = 1.5564077244462253, disc_loss = 0.006525894304554938
Trained batch 856 in epoch 1, gen_loss = 1.5563045390984838, disc_loss = 0.006518857695996086
Trained batch 857 in epoch 1, gen_loss = 1.5559289096952318, disc_loss = 0.006511817428090453
Trained batch 858 in epoch 1, gen_loss = 1.5558874650106995, disc_loss = 0.006504797056143588
Trained batch 859 in epoch 1, gen_loss = 1.5556112371211828, disc_loss = 0.006498177513056489
Trained batch 860 in epoch 1, gen_loss = 1.5551540058248965, disc_loss = 0.006491769870447588
Trained batch 861 in epoch 1, gen_loss = 1.5550894608630381, disc_loss = 0.006485388837715561
Trained batch 862 in epoch 1, gen_loss = 1.5550192973014239, disc_loss = 0.006478792581962732
Trained batch 863 in epoch 1, gen_loss = 1.5556450264045485, disc_loss = 0.006472063396864137
Trained batch 864 in epoch 1, gen_loss = 1.5555990604995993, disc_loss = 0.0064654221420103655
Trained batch 865 in epoch 1, gen_loss = 1.5555475107792067, disc_loss = 0.006459628955957665
Trained batch 866 in epoch 1, gen_loss = 1.5555687753661969, disc_loss = 0.006452827605722588
Trained batch 867 in epoch 1, gen_loss = 1.555386190727559, disc_loss = 0.006445962511501135
Trained batch 868 in epoch 1, gen_loss = 1.5555783179604692, disc_loss = 0.006439295077423958
Trained batch 869 in epoch 1, gen_loss = 1.5555476063969491, disc_loss = 0.006432820865436157
Trained batch 870 in epoch 1, gen_loss = 1.5554206460269528, disc_loss = 0.006426563220111713
Trained batch 871 in epoch 1, gen_loss = 1.5553108166664018, disc_loss = 0.006420291931836475
Trained batch 872 in epoch 1, gen_loss = 1.5552075559194418, disc_loss = 0.006414407962525929
Trained batch 873 in epoch 1, gen_loss = 1.5552478529495832, disc_loss = 0.006407568694455432
Trained batch 874 in epoch 1, gen_loss = 1.5555936004093716, disc_loss = 0.006401202000511278
Trained batch 875 in epoch 1, gen_loss = 1.5559008543349837, disc_loss = 0.006395083351333713
Trained batch 876 in epoch 1, gen_loss = 1.556282147850115, disc_loss = 0.006388634851964577
Trained batch 877 in epoch 1, gen_loss = 1.5563532510488072, disc_loss = 0.006381929630010838
Trained batch 878 in epoch 1, gen_loss = 1.5564991672426902, disc_loss = 0.006375929894222718
Trained batch 879 in epoch 1, gen_loss = 1.5563859699801965, disc_loss = 0.006370019633223737
Trained batch 880 in epoch 1, gen_loss = 1.5560990833126591, disc_loss = 0.006363405783127657
Trained batch 881 in epoch 1, gen_loss = 1.5565231100501928, disc_loss = 0.0063571959012702775
Trained batch 882 in epoch 1, gen_loss = 1.5565927922388165, disc_loss = 0.006350544915029079
Trained batch 883 in epoch 1, gen_loss = 1.556602246755928, disc_loss = 0.006343778087387474
Trained batch 884 in epoch 1, gen_loss = 1.5567588645859627, disc_loss = 0.006337090747530893
Trained batch 885 in epoch 1, gen_loss = 1.5564885194629903, disc_loss = 0.0063342787308300974
Trained batch 886 in epoch 1, gen_loss = 1.5560797081993558, disc_loss = 0.006329158703736717
Trained batch 887 in epoch 1, gen_loss = 1.5558718726173177, disc_loss = 0.006323479048054044
Trained batch 888 in epoch 1, gen_loss = 1.5559665248954524, disc_loss = 0.006316835730071038
Trained batch 889 in epoch 1, gen_loss = 1.5560089610935597, disc_loss = 0.006310359403239877
Trained batch 890 in epoch 1, gen_loss = 1.556116459613162, disc_loss = 0.00630381352791571
Trained batch 891 in epoch 1, gen_loss = 1.555801629886499, disc_loss = 0.006297424494084222
Trained batch 892 in epoch 1, gen_loss = 1.555561685749024, disc_loss = 0.006291127683775247
Trained batch 893 in epoch 1, gen_loss = 1.555334658830758, disc_loss = 0.00628449412556162
Trained batch 894 in epoch 1, gen_loss = 1.5551341395138363, disc_loss = 0.0062782502620332675
Trained batch 895 in epoch 1, gen_loss = 1.5550736617296934, disc_loss = 0.006271918515689582
Trained batch 896 in epoch 1, gen_loss = 1.5551383726572912, disc_loss = 0.006265354626691343
Trained batch 897 in epoch 1, gen_loss = 1.5549951106774516, disc_loss = 0.0062589359672660765
Trained batch 898 in epoch 1, gen_loss = 1.555121752788811, disc_loss = 0.006252362564325517
Trained batch 899 in epoch 1, gen_loss = 1.5547873629464044, disc_loss = 0.006246123210067809
Trained batch 900 in epoch 1, gen_loss = 1.5547011864436717, disc_loss = 0.006239819040098956
Trained batch 901 in epoch 1, gen_loss = 1.5546183270255636, disc_loss = 0.006233385582308661
Trained batch 902 in epoch 1, gen_loss = 1.5546338708693799, disc_loss = 0.006226933803378397
Trained batch 903 in epoch 1, gen_loss = 1.5543923908102828, disc_loss = 0.006220659886708842
Trained batch 904 in epoch 1, gen_loss = 1.5545030798042676, disc_loss = 0.006214403658294896
Trained batch 905 in epoch 1, gen_loss = 1.5547633730286268, disc_loss = 0.0062079488164675884
Trained batch 906 in epoch 1, gen_loss = 1.554864245186567, disc_loss = 0.006201670687783524
Trained batch 907 in epoch 1, gen_loss = 1.5548308886883018, disc_loss = 0.006195509305003556
Trained batch 908 in epoch 1, gen_loss = 1.5545978028126413, disc_loss = 0.006188912524389512
Trained batch 909 in epoch 1, gen_loss = 1.5549212607708607, disc_loss = 0.006182526110445666
Trained batch 910 in epoch 1, gen_loss = 1.5547565158975896, disc_loss = 0.006176256498736053
Trained batch 911 in epoch 1, gen_loss = 1.554687033489085, disc_loss = 0.006169799729912228
Trained batch 912 in epoch 1, gen_loss = 1.5545601578427302, disc_loss = 0.006163378312448953
Trained batch 913 in epoch 1, gen_loss = 1.554446473945935, disc_loss = 0.006157116376030278
Trained batch 914 in epoch 1, gen_loss = 1.5545250414499168, disc_loss = 0.00615070752471576
Trained batch 915 in epoch 1, gen_loss = 1.5546339553776787, disc_loss = 0.006144341726732866
Trained batch 916 in epoch 1, gen_loss = 1.5546186606002608, disc_loss = 0.006138174351280776
Trained batch 917 in epoch 1, gen_loss = 1.5544611650614437, disc_loss = 0.0061324102597072475
Trained batch 918 in epoch 1, gen_loss = 1.5542612468846086, disc_loss = 0.006126240593980024
Trained batch 919 in epoch 1, gen_loss = 1.5540831909231518, disc_loss = 0.006120112186418619
Trained batch 920 in epoch 1, gen_loss = 1.5540809293523286, disc_loss = 0.006113865145480985
Trained batch 921 in epoch 1, gen_loss = 1.553888347040288, disc_loss = 0.006107748066542449
Trained batch 922 in epoch 1, gen_loss = 1.5542447737469576, disc_loss = 0.006101897281329329
Trained batch 923 in epoch 1, gen_loss = 1.5542216891850227, disc_loss = 0.006096215023260661
Trained batch 924 in epoch 1, gen_loss = 1.5544005388826938, disc_loss = 0.006090446448573415
Trained batch 925 in epoch 1, gen_loss = 1.5544704628814632, disc_loss = 0.00608443292490517
Trained batch 926 in epoch 1, gen_loss = 1.5541239063845227, disc_loss = 0.00607885497519779
Trained batch 927 in epoch 1, gen_loss = 1.5544880602894158, disc_loss = 0.006073355422860663
Trained batch 928 in epoch 1, gen_loss = 1.5547301238011748, disc_loss = 0.006067284364505788
Trained batch 929 in epoch 1, gen_loss = 1.554619595055939, disc_loss = 0.006061361141810169
Trained batch 930 in epoch 1, gen_loss = 1.5545956578853948, disc_loss = 0.006055317125768975
Trained batch 931 in epoch 1, gen_loss = 1.554462415977609, disc_loss = 0.00604905862789756
Trained batch 932 in epoch 1, gen_loss = 1.554409041282065, disc_loss = 0.006042963925859864
Trained batch 933 in epoch 1, gen_loss = 1.5541728107015378, disc_loss = 0.006036812210469497
Trained batch 934 in epoch 1, gen_loss = 1.5537058923333724, disc_loss = 0.006031090399389837
Trained batch 935 in epoch 1, gen_loss = 1.5533855612206662, disc_loss = 0.006025648910182122
Trained batch 936 in epoch 1, gen_loss = 1.5531867882485324, disc_loss = 0.006019656575952578
Trained batch 937 in epoch 1, gen_loss = 1.553354210690903, disc_loss = 0.006013716230195499
Trained batch 938 in epoch 1, gen_loss = 1.5531324209115756, disc_loss = 0.006008186350836686
Trained batch 939 in epoch 1, gen_loss = 1.5532048640098977, disc_loss = 0.0060024349959232805
Trained batch 940 in epoch 1, gen_loss = 1.5531661369848708, disc_loss = 0.0059963974902343484
Trained batch 941 in epoch 1, gen_loss = 1.5530724682372594, disc_loss = 0.005990383395834454
Trained batch 942 in epoch 1, gen_loss = 1.5531469663152766, disc_loss = 0.00598458085935153
Trained batch 943 in epoch 1, gen_loss = 1.5530208678821387, disc_loss = 0.005978600343704614
Trained batch 944 in epoch 1, gen_loss = 1.552742085507307, disc_loss = 0.005972739377504993
Trained batch 945 in epoch 1, gen_loss = 1.5527074314323086, disc_loss = 0.005966805356553949
Trained batch 946 in epoch 1, gen_loss = 1.5526638345708312, disc_loss = 0.005960857450273409
Trained batch 947 in epoch 1, gen_loss = 1.5525267307768391, disc_loss = 0.0059548951734242
Trained batch 948 in epoch 1, gen_loss = 1.552834852352283, disc_loss = 0.005949247555859491
Trained batch 949 in epoch 1, gen_loss = 1.5527119728138572, disc_loss = 0.005943369557621496
Trained batch 950 in epoch 1, gen_loss = 1.5528985750788018, disc_loss = 0.005937532667456475
Trained batch 951 in epoch 1, gen_loss = 1.5526267182426292, disc_loss = 0.0059319548862800395
Trained batch 952 in epoch 1, gen_loss = 1.5527027829121192, disc_loss = 0.005926220024712843
Trained batch 953 in epoch 1, gen_loss = 1.5526024528019584, disc_loss = 0.005920395708089622
Trained batch 954 in epoch 1, gen_loss = 1.552248152637981, disc_loss = 0.005914907703140789
Trained batch 955 in epoch 1, gen_loss = 1.5525742336546526, disc_loss = 0.005909277077209717
Trained batch 956 in epoch 1, gen_loss = 1.5525228796583233, disc_loss = 0.005903703241265752
Trained batch 957 in epoch 1, gen_loss = 1.5522664030061137, disc_loss = 0.005898367727690839
Trained batch 958 in epoch 1, gen_loss = 1.5526071907457146, disc_loss = 0.0058926892600921045
Trained batch 959 in epoch 1, gen_loss = 1.5522704417506854, disc_loss = 0.005887377042472508
Trained batch 960 in epoch 1, gen_loss = 1.5519879085092216, disc_loss = 0.005883315774198073
Trained batch 961 in epoch 1, gen_loss = 1.5521100744636045, disc_loss = 0.005878572892527127
Trained batch 962 in epoch 1, gen_loss = 1.5521639706808705, disc_loss = 0.005872919874037069
Trained batch 963 in epoch 1, gen_loss = 1.5519831554028998, disc_loss = 0.0058673447179385845
Trained batch 964 in epoch 1, gen_loss = 1.5520340603250296, disc_loss = 0.005861794141451756
Trained batch 965 in epoch 1, gen_loss = 1.5520035318459537, disc_loss = 0.0058560941892150135
Trained batch 966 in epoch 1, gen_loss = 1.5520253603066383, disc_loss = 0.005850439890105549
Trained batch 967 in epoch 1, gen_loss = 1.5521270701707888, disc_loss = 0.0058449533083877805
Trained batch 968 in epoch 1, gen_loss = 1.5519629613533847, disc_loss = 0.005839553857922614
Trained batch 969 in epoch 1, gen_loss = 1.5518265622178304, disc_loss = 0.005834159446783008
Trained batch 970 in epoch 1, gen_loss = 1.5513838733384342, disc_loss = 0.005828747079302686
Trained batch 971 in epoch 1, gen_loss = 1.5511589076048062, disc_loss = 0.005823385166697762
Trained batch 972 in epoch 1, gen_loss = 1.5508140093988652, disc_loss = 0.005818446018781661
Trained batch 973 in epoch 1, gen_loss = 1.5509085993012852, disc_loss = 0.005813799984555919
Trained batch 974 in epoch 1, gen_loss = 1.5504721332207705, disc_loss = 0.00580977242687741
Trained batch 975 in epoch 1, gen_loss = 1.5507286943373133, disc_loss = 0.005805474796377029
Trained batch 976 in epoch 1, gen_loss = 1.5504611963625452, disc_loss = 0.005800671564092662
Trained batch 977 in epoch 1, gen_loss = 1.5505424776935381, disc_loss = 0.0057954192751671465
Trained batch 978 in epoch 1, gen_loss = 1.5507334306364284, disc_loss = 0.005789925457314665
Trained batch 979 in epoch 1, gen_loss = 1.5508659742316422, disc_loss = 0.005784590516479363
Trained batch 980 in epoch 1, gen_loss = 1.5507340562452965, disc_loss = 0.005779410841830633
Trained batch 981 in epoch 1, gen_loss = 1.5505484908272924, disc_loss = 0.005773930315656422
Trained batch 982 in epoch 1, gen_loss = 1.5505674394683218, disc_loss = 0.005768497301141721
Trained batch 983 in epoch 1, gen_loss = 1.550363043944041, disc_loss = 0.005763232105699552
Trained batch 984 in epoch 1, gen_loss = 1.550402460969644, disc_loss = 0.005757710483601213
Trained batch 985 in epoch 1, gen_loss = 1.5509851924304305, disc_loss = 0.005752820990678361
Trained batch 986 in epoch 1, gen_loss = 1.5509126036604366, disc_loss = 0.005747348645114856
Trained batch 987 in epoch 1, gen_loss = 1.5510336065340622, disc_loss = 0.00574202275131419
Trained batch 988 in epoch 1, gen_loss = 1.551064811775007, disc_loss = 0.005736874671283539
Trained batch 989 in epoch 1, gen_loss = 1.5512395489095436, disc_loss = 0.0057315169699840495
Trained batch 990 in epoch 1, gen_loss = 1.5509790191737, disc_loss = 0.005726059345702578
Trained batch 991 in epoch 1, gen_loss = 1.5508229346765625, disc_loss = 0.005720745536564209
Trained batch 992 in epoch 1, gen_loss = 1.5509491916389504, disc_loss = 0.005715372651931009
Trained batch 993 in epoch 1, gen_loss = 1.5506834507708098, disc_loss = 0.005710131437589145
Trained batch 994 in epoch 1, gen_loss = 1.5510923872041942, disc_loss = 0.005705015811848047
Trained batch 995 in epoch 1, gen_loss = 1.5507644785934662, disc_loss = 0.005699806847175009
Trained batch 996 in epoch 1, gen_loss = 1.5506005445000162, disc_loss = 0.005694432615403155
Trained batch 997 in epoch 1, gen_loss = 1.5506461849193536, disc_loss = 0.0056894145636104945
Trained batch 998 in epoch 1, gen_loss = 1.5504905204992514, disc_loss = 0.005685040560879375
Trained batch 999 in epoch 1, gen_loss = 1.5502620804309846, disc_loss = 0.005679911047482164
Trained batch 1000 in epoch 1, gen_loss = 1.550038988535459, disc_loss = 0.005674733772154453
Trained batch 1001 in epoch 1, gen_loss = 1.5497795358865323, disc_loss = 0.005669763745077116
Trained batch 1002 in epoch 1, gen_loss = 1.549856172126169, disc_loss = 0.005664450607071273
Trained batch 1003 in epoch 1, gen_loss = 1.549626935763188, disc_loss = 0.005659166114193534
Trained batch 1004 in epoch 1, gen_loss = 1.5495874744149583, disc_loss = 0.00565384923531419
Trained batch 1005 in epoch 1, gen_loss = 1.5497295689393227, disc_loss = 0.005648626129038328
Trained batch 1006 in epoch 1, gen_loss = 1.5493130772684394, disc_loss = 0.005644301800408734
Trained batch 1007 in epoch 1, gen_loss = 1.5489274628815197, disc_loss = 0.005639873527956846
Trained batch 1008 in epoch 1, gen_loss = 1.5488047565530147, disc_loss = 0.005635437013454942
Trained batch 1009 in epoch 1, gen_loss = 1.548557724811063, disc_loss = 0.005630239898755013
Trained batch 1010 in epoch 1, gen_loss = 1.548541833809646, disc_loss = 0.005625209261247111
Trained batch 1011 in epoch 1, gen_loss = 1.548234425514583, disc_loss = 0.005620596291739614
Trained batch 1012 in epoch 1, gen_loss = 1.5482204984229975, disc_loss = 0.005615770739489644
Trained batch 1013 in epoch 1, gen_loss = 1.5481673078189, disc_loss = 0.005610850581749346
Trained batch 1014 in epoch 1, gen_loss = 1.548377743730404, disc_loss = 0.00560583210756126
Trained batch 1015 in epoch 1, gen_loss = 1.5484426833513214, disc_loss = 0.005600886579629769
Trained batch 1016 in epoch 1, gen_loss = 1.5485804054003316, disc_loss = 0.005595682583301261
Trained batch 1017 in epoch 1, gen_loss = 1.548635722494781, disc_loss = 0.005590730559929139
Trained batch 1018 in epoch 1, gen_loss = 1.5484306747943777, disc_loss = 0.0055859378927514795
Trained batch 1019 in epoch 1, gen_loss = 1.5485430421782476, disc_loss = 0.005580813904645552
Trained batch 1020 in epoch 1, gen_loss = 1.5484424677698432, disc_loss = 0.0055758096575593335
Trained batch 1021 in epoch 1, gen_loss = 1.5481822935102503, disc_loss = 0.0055708414390002
Trained batch 1022 in epoch 1, gen_loss = 1.5479622794968875, disc_loss = 0.005565719385882876
Trained batch 1023 in epoch 1, gen_loss = 1.5480364738032222, disc_loss = 0.005560786649567717
Trained batch 1024 in epoch 1, gen_loss = 1.5480117223320937, disc_loss = 0.005555847299018329
Trained batch 1025 in epoch 1, gen_loss = 1.5479728408724245, disc_loss = 0.0055510503636547375
Trained batch 1026 in epoch 1, gen_loss = 1.5481551097453858, disc_loss = 0.005546562629508148
Trained batch 1027 in epoch 1, gen_loss = 1.5477453073638887, disc_loss = 0.005541778931056524
Trained batch 1028 in epoch 1, gen_loss = 1.5474976946475787, disc_loss = 0.005536825836835695
Trained batch 1029 in epoch 1, gen_loss = 1.5474661840975863, disc_loss = 0.005531993801581212
Trained batch 1030 in epoch 1, gen_loss = 1.5475203748123953, disc_loss = 0.0055271725456102075
Trained batch 1031 in epoch 1, gen_loss = 1.5472571421270223, disc_loss = 0.005522105097043095
Trained batch 1032 in epoch 1, gen_loss = 1.547301583807097, disc_loss = 0.005517627041033421
Trained batch 1033 in epoch 1, gen_loss = 1.5470564435713527, disc_loss = 0.005513531736187624
Trained batch 1034 in epoch 1, gen_loss = 1.546995026593047, disc_loss = 0.005508929291309267
Trained batch 1035 in epoch 1, gen_loss = 1.547017730801262, disc_loss = 0.005504105809513474
Trained batch 1036 in epoch 1, gen_loss = 1.5468212095957712, disc_loss = 0.005499342096970159
Trained batch 1037 in epoch 1, gen_loss = 1.5469397637196358, disc_loss = 0.005494453036271193
Trained batch 1038 in epoch 1, gen_loss = 1.5467292064652063, disc_loss = 0.0054896434512338044
Trained batch 1039 in epoch 1, gen_loss = 1.5469062736401191, disc_loss = 0.0054851574043613465
Trained batch 1040 in epoch 1, gen_loss = 1.5467744748484733, disc_loss = 0.005480510233449647
Trained batch 1041 in epoch 1, gen_loss = 1.5469035392988209, disc_loss = 0.005475765629202278
Trained batch 1042 in epoch 1, gen_loss = 1.546891588378387, disc_loss = 0.0054708346215821
Trained batch 1043 in epoch 1, gen_loss = 1.5470193404119132, disc_loss = 0.005465965548565235
Trained batch 1044 in epoch 1, gen_loss = 1.547197525010725, disc_loss = 0.005461127307704922
Trained batch 1045 in epoch 1, gen_loss = 1.546878068556521, disc_loss = 0.005456626024994248
Trained batch 1046 in epoch 1, gen_loss = 1.5471120956634041, disc_loss = 0.005451854773395257
Trained batch 1047 in epoch 1, gen_loss = 1.5472481347449862, disc_loss = 0.005446993222022261
Trained batch 1048 in epoch 1, gen_loss = 1.5470950633031737, disc_loss = 0.005442265583206904
Trained batch 1049 in epoch 1, gen_loss = 1.5472087290173486, disc_loss = 0.0054375294401654084
Trained batch 1050 in epoch 1, gen_loss = 1.5470770802756473, disc_loss = 0.005432643462443231
Trained batch 1051 in epoch 1, gen_loss = 1.5471563280308656, disc_loss = 0.0054278361648195
Trained batch 1052 in epoch 1, gen_loss = 1.5473079766303386, disc_loss = 0.005423163597118012
Trained batch 1053 in epoch 1, gen_loss = 1.5471638496505693, disc_loss = 0.0054185900762242015
Trained batch 1054 in epoch 1, gen_loss = 1.5472837991624082, disc_loss = 0.005413866562187292
Trained batch 1055 in epoch 1, gen_loss = 1.547374297610738, disc_loss = 0.005409209598286851
Trained batch 1056 in epoch 1, gen_loss = 1.5472246994922605, disc_loss = 0.0054042783004999186
Trained batch 1057 in epoch 1, gen_loss = 1.5470717783686343, disc_loss = 0.005399664666489144
Trained batch 1058 in epoch 1, gen_loss = 1.546953541136103, disc_loss = 0.005394998204395724
Trained batch 1059 in epoch 1, gen_loss = 1.5469540508288258, disc_loss = 0.0053903219051206624
Trained batch 1060 in epoch 1, gen_loss = 1.5466805679634088, disc_loss = 0.0053854965003069955
Trained batch 1061 in epoch 1, gen_loss = 1.546392361659788, disc_loss = 0.0053808106295139616
Trained batch 1062 in epoch 1, gen_loss = 1.5463525052353222, disc_loss = 0.005376320846383403
Trained batch 1063 in epoch 1, gen_loss = 1.5464127487257908, disc_loss = 0.005371661811446223
Trained batch 1064 in epoch 1, gen_loss = 1.54640211376226, disc_loss = 0.005366914332303231
Trained batch 1065 in epoch 1, gen_loss = 1.546328604445001, disc_loss = 0.005362231896324852
Trained batch 1066 in epoch 1, gen_loss = 1.5462965196611285, disc_loss = 0.005358356313599709
Trained batch 1067 in epoch 1, gen_loss = 1.546246509092131, disc_loss = 0.005355839309017069
Trained batch 1068 in epoch 1, gen_loss = 1.5461370847958957, disc_loss = 0.005352669041523217
Trained batch 1069 in epoch 1, gen_loss = 1.5459766449215255, disc_loss = 0.0053487269134395625
Trained batch 1070 in epoch 1, gen_loss = 1.5460105752633289, disc_loss = 0.005344231350529577
Trained batch 1071 in epoch 1, gen_loss = 1.5457479358831447, disc_loss = 0.005339667385873218
Trained batch 1072 in epoch 1, gen_loss = 1.5452955057992073, disc_loss = 0.005335339440079709
Trained batch 1073 in epoch 1, gen_loss = 1.5453387552133486, disc_loss = 0.005330925113634246
Trained batch 1074 in epoch 1, gen_loss = 1.5452205611384193, disc_loss = 0.005326509572522238
Trained batch 1075 in epoch 1, gen_loss = 1.5454691549880797, disc_loss = 0.0053222879266377615
Trained batch 1076 in epoch 1, gen_loss = 1.545830701829774, disc_loss = 0.00531818870165988
Trained batch 1077 in epoch 1, gen_loss = 1.5455026166558488, disc_loss = 0.005314228875730584
Trained batch 1078 in epoch 1, gen_loss = 1.5455226109357096, disc_loss = 0.005310519959700343
Trained batch 1079 in epoch 1, gen_loss = 1.5455070418340189, disc_loss = 0.005306299974984507
Trained batch 1080 in epoch 1, gen_loss = 1.54543195776538, disc_loss = 0.00530182324136865
Trained batch 1081 in epoch 1, gen_loss = 1.5453734628153817, disc_loss = 0.005297311468967865
Trained batch 1082 in epoch 1, gen_loss = 1.5455582401649004, disc_loss = 0.0052929007318081546
Trained batch 1083 in epoch 1, gen_loss = 1.5456127335224645, disc_loss = 0.005288422697183342
Trained batch 1084 in epoch 1, gen_loss = 1.5455227032235141, disc_loss = 0.005283817507365229
Trained batch 1085 in epoch 1, gen_loss = 1.545635377504549, disc_loss = 0.005279353011365634
Trained batch 1086 in epoch 1, gen_loss = 1.5454502807589112, disc_loss = 0.005275575605552239
Trained batch 1087 in epoch 1, gen_loss = 1.5453143080367762, disc_loss = 0.005271314589663234
Trained batch 1088 in epoch 1, gen_loss = 1.545267583800632, disc_loss = 0.005267019926720445
Trained batch 1089 in epoch 1, gen_loss = 1.5453890296297337, disc_loss = 0.005262981929630468
Trained batch 1090 in epoch 1, gen_loss = 1.5452261437635484, disc_loss = 0.005258655970306652
Trained batch 1091 in epoch 1, gen_loss = 1.5453268659638835, disc_loss = 0.005255204528841384
Trained batch 1092 in epoch 1, gen_loss = 1.5451337075080767, disc_loss = 0.0052511063379351445
Trained batch 1093 in epoch 1, gen_loss = 1.5454852196372624, disc_loss = 0.005247018362461015
Trained batch 1094 in epoch 1, gen_loss = 1.5459180549943827, disc_loss = 0.005242739699262122
Trained batch 1095 in epoch 1, gen_loss = 1.5459994671553592, disc_loss = 0.005238517055028359
Trained batch 1096 in epoch 1, gen_loss = 1.5462884322664578, disc_loss = 0.0052341559663909056
Trained batch 1097 in epoch 1, gen_loss = 1.5465321525632791, disc_loss = 0.005229969368144897
Trained batch 1098 in epoch 1, gen_loss = 1.5462551470557813, disc_loss = 0.005225979600053406
Trained batch 1099 in epoch 1, gen_loss = 1.5463095547936179, disc_loss = 0.005221685400359671
Trained batch 1100 in epoch 1, gen_loss = 1.5462771767816361, disc_loss = 0.005217433276958002
Trained batch 1101 in epoch 1, gen_loss = 1.5466514297924976, disc_loss = 0.005213273699978914
Trained batch 1102 in epoch 1, gen_loss = 1.5465249309513855, disc_loss = 0.005209158442195518
Trained batch 1103 in epoch 1, gen_loss = 1.5464654070311699, disc_loss = 0.005204730964380914
Trained batch 1104 in epoch 1, gen_loss = 1.5462318722478945, disc_loss = 0.005200302902513238
Trained batch 1105 in epoch 1, gen_loss = 1.5464942621279367, disc_loss = 0.005195872478159086
Trained batch 1106 in epoch 1, gen_loss = 1.5463636535293042, disc_loss = 0.0051914859804618844
Trained batch 1107 in epoch 1, gen_loss = 1.5465705463602224, disc_loss = 0.005187128738939152
Trained batch 1108 in epoch 1, gen_loss = 1.546715806796811, disc_loss = 0.005182798807998419
Trained batch 1109 in epoch 1, gen_loss = 1.546847447081729, disc_loss = 0.005178586851023054
Trained batch 1110 in epoch 1, gen_loss = 1.5467936839207563, disc_loss = 0.00517417883753406
Trained batch 1111 in epoch 1, gen_loss = 1.5466915862165767, disc_loss = 0.005169833530979683
Trained batch 1112 in epoch 1, gen_loss = 1.5472676835398576, disc_loss = 0.005165813678707375
Trained batch 1113 in epoch 1, gen_loss = 1.5471627151516651, disc_loss = 0.005161533315492128
Trained batch 1114 in epoch 1, gen_loss = 1.5474379272204344, disc_loss = 0.005157336472291416
Trained batch 1115 in epoch 1, gen_loss = 1.5473594220094784, disc_loss = 0.005152973863970085
Trained batch 1116 in epoch 1, gen_loss = 1.5477247531646687, disc_loss = 0.005148749645851926
Trained batch 1117 in epoch 1, gen_loss = 1.5478848804301568, disc_loss = 0.005144373394635527
Trained batch 1118 in epoch 1, gen_loss = 1.5479012423055953, disc_loss = 0.005140121711446746
Trained batch 1119 in epoch 1, gen_loss = 1.5479046999343804, disc_loss = 0.005135788591750108
Trained batch 1120 in epoch 1, gen_loss = 1.5478434423375194, disc_loss = 0.005131443287588633
Trained batch 1121 in epoch 1, gen_loss = 1.5479329997630469, disc_loss = 0.005127197476350843
Trained batch 1122 in epoch 1, gen_loss = 1.5479106013517983, disc_loss = 0.0051230526254437735
Trained batch 1123 in epoch 1, gen_loss = 1.547924120124973, disc_loss = 0.005118972510569629
Trained batch 1124 in epoch 1, gen_loss = 1.5477705721325346, disc_loss = 0.005114668907959842
Trained batch 1125 in epoch 1, gen_loss = 1.5480595702176407, disc_loss = 0.005110390614679945
Trained batch 1126 in epoch 1, gen_loss = 1.5478791737831474, disc_loss = 0.0051063483148598805
Trained batch 1127 in epoch 1, gen_loss = 1.5481374184501933, disc_loss = 0.005102537440203984
Trained batch 1128 in epoch 1, gen_loss = 1.5482600485993445, disc_loss = 0.005098427403132547
Trained batch 1129 in epoch 1, gen_loss = 1.5481328262692005, disc_loss = 0.005094297003027761
Trained batch 1130 in epoch 1, gen_loss = 1.5481064980479071, disc_loss = 0.005090046582429997
Trained batch 1131 in epoch 1, gen_loss = 1.548209729759095, disc_loss = 0.005085850270678307
Trained batch 1132 in epoch 1, gen_loss = 1.548208306557503, disc_loss = 0.005081915696746886
Trained batch 1133 in epoch 1, gen_loss = 1.5483221962548648, disc_loss = 0.005078414305610331
Trained batch 1134 in epoch 1, gen_loss = 1.548408768460614, disc_loss = 0.0050746353286972865
Trained batch 1135 in epoch 1, gen_loss = 1.548349319734204, disc_loss = 0.0050711925679780495
Trained batch 1136 in epoch 1, gen_loss = 1.5482073091265394, disc_loss = 0.0050673440336354205
Trained batch 1137 in epoch 1, gen_loss = 1.5482174035534917, disc_loss = 0.005063346828468453
Trained batch 1138 in epoch 1, gen_loss = 1.5482164256085, disc_loss = 0.005059316027665239
Trained batch 1139 in epoch 1, gen_loss = 1.5479880807692545, disc_loss = 0.00505556226388874
Trained batch 1140 in epoch 1, gen_loss = 1.5481568175799798, disc_loss = 0.005052311685360522
Trained batch 1141 in epoch 1, gen_loss = 1.5479221973444242, disc_loss = 0.005048400596369934
Trained batch 1142 in epoch 1, gen_loss = 1.5480388953616926, disc_loss = 0.005044291195024151
Trained batch 1143 in epoch 1, gen_loss = 1.54807531656502, disc_loss = 0.005040172678274973
Trained batch 1144 in epoch 1, gen_loss = 1.54794173396831, disc_loss = 0.005036132674568687
Trained batch 1145 in epoch 1, gen_loss = 1.548036938562443, disc_loss = 0.0050320597537429545
Trained batch 1146 in epoch 1, gen_loss = 1.548192839988336, disc_loss = 0.005028059045838374
Trained batch 1147 in epoch 1, gen_loss = 1.5481700009377577, disc_loss = 0.0050240887795404195
Trained batch 1148 in epoch 1, gen_loss = 1.5480157302917865, disc_loss = 0.005020488528010952
Trained batch 1149 in epoch 1, gen_loss = 1.548363963521045, disc_loss = 0.005016422627934093
Trained batch 1150 in epoch 1, gen_loss = 1.5484028549219193, disc_loss = 0.005012753515233845
Trained batch 1151 in epoch 1, gen_loss = 1.5482989534114797, disc_loss = 0.0050091758160862
Trained batch 1152 in epoch 1, gen_loss = 1.5481835831173172, disc_loss = 0.005005214305684223
Trained batch 1153 in epoch 1, gen_loss = 1.5482956843524913, disc_loss = 0.0050012998532990485
Trained batch 1154 in epoch 1, gen_loss = 1.5483090905400065, disc_loss = 0.00499732966284828
Trained batch 1155 in epoch 1, gen_loss = 1.5482475210019875, disc_loss = 0.004993338652116659
Trained batch 1156 in epoch 1, gen_loss = 1.548048591964082, disc_loss = 0.0049894179368746615
Trained batch 1157 in epoch 1, gen_loss = 1.5481121881844055, disc_loss = 0.004985303346352975
Trained batch 1158 in epoch 1, gen_loss = 1.5481167909294702, disc_loss = 0.004981238466165791
Trained batch 1159 in epoch 1, gen_loss = 1.5480906580028864, disc_loss = 0.004977174144080672
Trained batch 1160 in epoch 1, gen_loss = 1.5483017779957313, disc_loss = 0.0049731741652775455
Trained batch 1161 in epoch 1, gen_loss = 1.5484740015972092, disc_loss = 0.0049692865854288285
Trained batch 1162 in epoch 1, gen_loss = 1.54849174652034, disc_loss = 0.004965214840706433
Trained batch 1163 in epoch 1, gen_loss = 1.5484166272317421, disc_loss = 0.004961162428782662
Trained batch 1164 in epoch 1, gen_loss = 1.5484053526825148, disc_loss = 0.004957136185115299
Trained batch 1165 in epoch 1, gen_loss = 1.5483163966322846, disc_loss = 0.004953233989545281
Trained batch 1166 in epoch 1, gen_loss = 1.548227513663873, disc_loss = 0.004949236646865797
Trained batch 1167 in epoch 1, gen_loss = 1.5482296468052146, disc_loss = 0.004945305415463262
Trained batch 1168 in epoch 1, gen_loss = 1.5478525272896393, disc_loss = 0.004941741727850017
Trained batch 1169 in epoch 1, gen_loss = 1.5478489338842212, disc_loss = 0.004938170890563614
Trained batch 1170 in epoch 1, gen_loss = 1.5477247931425842, disc_loss = 0.004934654103590647
Trained batch 1171 in epoch 1, gen_loss = 1.5475187819362093, disc_loss = 0.004931314782432794
Trained batch 1172 in epoch 1, gen_loss = 1.5473873152858868, disc_loss = 0.004927787537529123
Trained batch 1173 in epoch 1, gen_loss = 1.5471688478525087, disc_loss = 0.004924093960526358
Trained batch 1174 in epoch 1, gen_loss = 1.5472271409947822, disc_loss = 0.004920373561747491
Trained batch 1175 in epoch 1, gen_loss = 1.5471889992960457, disc_loss = 0.004916779231106851
Trained batch 1176 in epoch 1, gen_loss = 1.5473188753338718, disc_loss = 0.0049131751016125375
Trained batch 1177 in epoch 1, gen_loss = 1.5469161177936352, disc_loss = 0.004909376347685946
Trained batch 1178 in epoch 1, gen_loss = 1.5469532608480348, disc_loss = 0.0049055156568679455
Trained batch 1179 in epoch 1, gen_loss = 1.5469227644346528, disc_loss = 0.004901792592308839
Trained batch 1180 in epoch 1, gen_loss = 1.5472371682184012, disc_loss = 0.004898369945005129
Trained batch 1181 in epoch 1, gen_loss = 1.547390991762003, disc_loss = 0.004895047324034149
Trained batch 1182 in epoch 1, gen_loss = 1.5474656844481713, disc_loss = 0.004891224976560921
Trained batch 1183 in epoch 1, gen_loss = 1.547277005540358, disc_loss = 0.004887437897441733
Trained batch 1184 in epoch 1, gen_loss = 1.547391151275313, disc_loss = 0.004883650053839714
Trained batch 1185 in epoch 1, gen_loss = 1.5470941472817432, disc_loss = 0.004880086548590497
Trained batch 1186 in epoch 1, gen_loss = 1.5469755957682993, disc_loss = 0.0048769648825969835
Trained batch 1187 in epoch 1, gen_loss = 1.5468634935942562, disc_loss = 0.004873821118448489
Trained batch 1188 in epoch 1, gen_loss = 1.5467050401376414, disc_loss = 0.004870005853829946
Trained batch 1189 in epoch 1, gen_loss = 1.5466179628332122, disc_loss = 0.004866330285224978
Trained batch 1190 in epoch 1, gen_loss = 1.546625855887867, disc_loss = 0.004862546390578374
Trained batch 1191 in epoch 1, gen_loss = 1.54644714255861, disc_loss = 0.00485877664823725
Trained batch 1192 in epoch 1, gen_loss = 1.5464918750329668, disc_loss = 0.004855309882058199
Trained batch 1193 in epoch 1, gen_loss = 1.546533051946854, disc_loss = 0.004851725973847784
Trained batch 1194 in epoch 1, gen_loss = 1.5463574393523787, disc_loss = 0.004849147495193111
Trained batch 1195 in epoch 1, gen_loss = 1.5462799294537126, disc_loss = 0.004845870387160109
Trained batch 1196 in epoch 1, gen_loss = 1.5463204062174236, disc_loss = 0.004842097319345711
Trained batch 1197 in epoch 1, gen_loss = 1.546200747083941, disc_loss = 0.004838327647939725
Trained batch 1198 in epoch 1, gen_loss = 1.5462624955117652, disc_loss = 0.004834752613263014
Trained batch 1199 in epoch 1, gen_loss = 1.5465537355343502, disc_loss = 0.004831244793895167
Trained batch 1200 in epoch 1, gen_loss = 1.5465151148969982, disc_loss = 0.004827870332192378
Trained batch 1201 in epoch 1, gen_loss = 1.5465142579126279, disc_loss = 0.004824238913236403
Trained batch 1202 in epoch 1, gen_loss = 1.5467706799804422, disc_loss = 0.004820625204389724
Trained batch 1203 in epoch 1, gen_loss = 1.5466874206184944, disc_loss = 0.004816812200529676
Trained batch 1204 in epoch 1, gen_loss = 1.5468855215800748, disc_loss = 0.004813019348406503
Trained batch 1205 in epoch 1, gen_loss = 1.546799388987508, disc_loss = 0.0048092724287838624
Trained batch 1206 in epoch 1, gen_loss = 1.5466389795325468, disc_loss = 0.004805793745720326
Trained batch 1207 in epoch 1, gen_loss = 1.5465444023443373, disc_loss = 0.004802542738724883
Trained batch 1208 in epoch 1, gen_loss = 1.5466049018233545, disc_loss = 0.004798896905542521
Trained batch 1209 in epoch 1, gen_loss = 1.5463793694480392, disc_loss = 0.004795338485251885
Trained batch 1210 in epoch 1, gen_loss = 1.5462132742540784, disc_loss = 0.004791801372300437
Trained batch 1211 in epoch 1, gen_loss = 1.546038936762133, disc_loss = 0.004788136138393341
Trained batch 1212 in epoch 1, gen_loss = 1.5460074882515187, disc_loss = 0.004784500567478693
Trained batch 1213 in epoch 1, gen_loss = 1.5459784816281603, disc_loss = 0.004780937312139698
Trained batch 1214 in epoch 1, gen_loss = 1.5459772310139221, disc_loss = 0.004777394469102573
Trained batch 1215 in epoch 1, gen_loss = 1.5457217441381592, disc_loss = 0.004773701780837463
Trained batch 1216 in epoch 1, gen_loss = 1.546015521592553, disc_loss = 0.004770193201624719
Trained batch 1217 in epoch 1, gen_loss = 1.545743201851649, disc_loss = 0.004767099004941828
Trained batch 1218 in epoch 1, gen_loss = 1.5457916780022738, disc_loss = 0.004763922288408293
Trained batch 1219 in epoch 1, gen_loss = 1.545961526866819, disc_loss = 0.004760523913387633
Trained batch 1220 in epoch 1, gen_loss = 1.5458194060368582, disc_loss = 0.00475684651492816
Trained batch 1221 in epoch 1, gen_loss = 1.5459558540397307, disc_loss = 0.004753261694822094
Trained batch 1222 in epoch 1, gen_loss = 1.5458228622219743, disc_loss = 0.004749619480152881
Trained batch 1223 in epoch 1, gen_loss = 1.5455690994371776, disc_loss = 0.004745979635331691
Trained batch 1224 in epoch 1, gen_loss = 1.5453584375186842, disc_loss = 0.004742284050848031
Trained batch 1225 in epoch 1, gen_loss = 1.5452110790700742, disc_loss = 0.004738708949365067
Trained batch 1226 in epoch 1, gen_loss = 1.5455177589072964, disc_loss = 0.004735241433905936
Trained batch 1227 in epoch 1, gen_loss = 1.5455517884380265, disc_loss = 0.004731592095485647
Trained batch 1228 in epoch 1, gen_loss = 1.5455692275158266, disc_loss = 0.004727940443846658
Trained batch 1229 in epoch 1, gen_loss = 1.545413334485961, disc_loss = 0.004724589469442731
Trained batch 1230 in epoch 1, gen_loss = 1.5450992519346125, disc_loss = 0.004723042082988618
Trained batch 1231 in epoch 1, gen_loss = 1.5451917256434242, disc_loss = 0.004721039926684548
Trained batch 1232 in epoch 1, gen_loss = 1.5451577147718183, disc_loss = 0.00471828853749394
Trained batch 1233 in epoch 1, gen_loss = 1.5450031022198583, disc_loss = 0.004716470594326094
Trained batch 1234 in epoch 1, gen_loss = 1.5448496558888238, disc_loss = 0.004713323851469961
Trained batch 1235 in epoch 1, gen_loss = 1.544550634414247, disc_loss = 0.004713486302496611
Trained batch 1236 in epoch 1, gen_loss = 1.5446674125080833, disc_loss = 0.004711600081500011
Trained batch 1237 in epoch 1, gen_loss = 1.5445228394283423, disc_loss = 0.004708654950312222
Trained batch 1238 in epoch 1, gen_loss = 1.544449446661228, disc_loss = 0.004705399906407359
Trained batch 1239 in epoch 1, gen_loss = 1.5443553291020855, disc_loss = 0.004702148893733054
Trained batch 1240 in epoch 1, gen_loss = 1.5446057420503123, disc_loss = 0.004699263196135271
Trained batch 1241 in epoch 1, gen_loss = 1.5446583441490136, disc_loss = 0.004696787402875801
Trained batch 1242 in epoch 1, gen_loss = 1.5447506596748617, disc_loss = 0.004693935329990543
Trained batch 1243 in epoch 1, gen_loss = 1.5452088639858834, disc_loss = 0.004691468920126626
Trained batch 1244 in epoch 1, gen_loss = 1.5450461398166826, disc_loss = 0.004689080653238544
Trained batch 1245 in epoch 1, gen_loss = 1.5450704023122406, disc_loss = 0.004686285538169018
Trained batch 1246 in epoch 1, gen_loss = 1.545393828496803, disc_loss = 0.004683150233136159
Trained batch 1247 in epoch 1, gen_loss = 1.5454042439277356, disc_loss = 0.004679726371402164
Trained batch 1248 in epoch 1, gen_loss = 1.545408114707403, disc_loss = 0.004676357445466367
Trained batch 1249 in epoch 1, gen_loss = 1.5455106538772583, disc_loss = 0.00467310773973586
Trained batch 1250 in epoch 1, gen_loss = 1.5457853678223803, disc_loss = 0.004669999807582536
Trained batch 1251 in epoch 1, gen_loss = 1.5458904478115776, disc_loss = 0.004666619415956303
Trained batch 1252 in epoch 1, gen_loss = 1.545819751186934, disc_loss = 0.004663238143079642
Trained batch 1253 in epoch 1, gen_loss = 1.5458739332415081, disc_loss = 0.004659862364405128
Trained batch 1254 in epoch 1, gen_loss = 1.5458097792241678, disc_loss = 0.004656595360189472
Trained batch 1255 in epoch 1, gen_loss = 1.5459244824518823, disc_loss = 0.0046534497052944405
Trained batch 1256 in epoch 1, gen_loss = 1.5457172189900679, disc_loss = 0.004650347815747721
Trained batch 1257 in epoch 1, gen_loss = 1.5455740066704198, disc_loss = 0.0046470232756105284
Trained batch 1258 in epoch 1, gen_loss = 1.5457661732309294, disc_loss = 0.004643724066223539
Trained batch 1259 in epoch 1, gen_loss = 1.5458439604630545, disc_loss = 0.004640444574264591
Trained batch 1260 in epoch 1, gen_loss = 1.5455257568351812, disc_loss = 0.004637018321266174
Trained batch 1261 in epoch 1, gen_loss = 1.54599920647269, disc_loss = 0.004633943908102054
Trained batch 1262 in epoch 1, gen_loss = 1.5462555195354604, disc_loss = 0.004630681338836808
Trained batch 1263 in epoch 1, gen_loss = 1.5464184727472594, disc_loss = 0.004627333438500362
Trained batch 1264 in epoch 1, gen_loss = 1.54655590943197, disc_loss = 0.004624052472532682
Trained batch 1265 in epoch 1, gen_loss = 1.5464111862212748, disc_loss = 0.004620930753167999
Trained batch 1266 in epoch 1, gen_loss = 1.5465302586837744, disc_loss = 0.004617596746901702
Trained batch 1267 in epoch 1, gen_loss = 1.5464615320745703, disc_loss = 0.004614483615369642
Trained batch 1268 in epoch 1, gen_loss = 1.5463748624514557, disc_loss = 0.004611209650262783
Trained batch 1269 in epoch 1, gen_loss = 1.546788910993441, disc_loss = 0.004608061266881982
Trained batch 1270 in epoch 1, gen_loss = 1.54659850966921, disc_loss = 0.004604839390427417
Trained batch 1271 in epoch 1, gen_loss = 1.5464540526926893, disc_loss = 0.004601763833381266
Trained batch 1272 in epoch 1, gen_loss = 1.546142714190277, disc_loss = 0.004598414114220906
Trained batch 1273 in epoch 1, gen_loss = 1.54627441789142, disc_loss = 0.0045951299073248245
Trained batch 1274 in epoch 1, gen_loss = 1.5461527006298887, disc_loss = 0.0045919529842007355
Trained batch 1275 in epoch 1, gen_loss = 1.5460120092925607, disc_loss = 0.004589253625112018
Trained batch 1276 in epoch 1, gen_loss = 1.546002437009789, disc_loss = 0.004586264634150381
Trained batch 1277 in epoch 1, gen_loss = 1.5459528746366127, disc_loss = 0.00458294835847488
Trained batch 1278 in epoch 1, gen_loss = 1.545968706762539, disc_loss = 0.004579885154274879
Trained batch 1279 in epoch 1, gen_loss = 1.5460281283594668, disc_loss = 0.004577321428143932
Trained batch 1280 in epoch 1, gen_loss = 1.5461241862068504, disc_loss = 0.004574190267695861
Trained batch 1281 in epoch 1, gen_loss = 1.546004615224282, disc_loss = 0.004570887341655231
Trained batch 1282 in epoch 1, gen_loss = 1.5460517988108324, disc_loss = 0.00456772599849875
Trained batch 1283 in epoch 1, gen_loss = 1.5461125732210939, disc_loss = 0.004564910812852952
Trained batch 1284 in epoch 1, gen_loss = 1.5458815441057376, disc_loss = 0.004561754375714755
Trained batch 1285 in epoch 1, gen_loss = 1.5458343266328423, disc_loss = 0.004559054937982489
Trained batch 1286 in epoch 1, gen_loss = 1.5459209492527057, disc_loss = 0.004556571090480051
Trained batch 1287 in epoch 1, gen_loss = 1.5458550469845718, disc_loss = 0.004553799682325464
Trained batch 1288 in epoch 1, gen_loss = 1.5458821204394866, disc_loss = 0.004550688428849164
Trained batch 1289 in epoch 1, gen_loss = 1.5457863801209502, disc_loss = 0.004547564739367271
Trained batch 1290 in epoch 1, gen_loss = 1.5457942444256902, disc_loss = 0.004545280021707034
Trained batch 1291 in epoch 1, gen_loss = 1.54590292759355, disc_loss = 0.004542955182943347
Trained batch 1292 in epoch 1, gen_loss = 1.5457593509603267, disc_loss = 0.004541969358201581
Trained batch 1293 in epoch 1, gen_loss = 1.545749702261994, disc_loss = 0.004539612169096183
Trained batch 1294 in epoch 1, gen_loss = 1.5456514517773072, disc_loss = 0.004537680078961735
Trained batch 1295 in epoch 1, gen_loss = 1.5458116335449394, disc_loss = 0.004538766187287376
Trained batch 1296 in epoch 1, gen_loss = 1.5456917301544155, disc_loss = 0.004537379428884427
Trained batch 1297 in epoch 1, gen_loss = 1.5456473142230087, disc_loss = 0.004534892842049537
Trained batch 1298 in epoch 1, gen_loss = 1.5456080493603972, disc_loss = 0.004532800187567644
Trained batch 1299 in epoch 1, gen_loss = 1.5454977462841915, disc_loss = 0.004529860213168342
Trained batch 1300 in epoch 1, gen_loss = 1.5451815579140946, disc_loss = 0.0045267842593983134
Trained batch 1301 in epoch 1, gen_loss = 1.5451160397397758, disc_loss = 0.004523899672476853
Trained batch 1302 in epoch 1, gen_loss = 1.5451878204038303, disc_loss = 0.0045206869614280365
Trained batch 1303 in epoch 1, gen_loss = 1.5454613808656763, disc_loss = 0.0045177104146350315
Trained batch 1304 in epoch 1, gen_loss = 1.5457585172178188, disc_loss = 0.004514736601477578
Trained batch 1305 in epoch 1, gen_loss = 1.5458010342000637, disc_loss = 0.004511638105836512
Trained batch 1306 in epoch 1, gen_loss = 1.5456776753945851, disc_loss = 0.004508547239162241
Trained batch 1307 in epoch 1, gen_loss = 1.54564559477914, disc_loss = 0.004505444256277219
Trained batch 1308 in epoch 1, gen_loss = 1.5457047671193471, disc_loss = 0.004502214614152599
Trained batch 1309 in epoch 1, gen_loss = 1.5458491587456855, disc_loss = 0.0044997042870235215
Trained batch 1310 in epoch 1, gen_loss = 1.5457527113724627, disc_loss = 0.004497599762491544
Trained batch 1311 in epoch 1, gen_loss = 1.5457580456646478, disc_loss = 0.004494463571207722
Trained batch 1312 in epoch 1, gen_loss = 1.5455537418872458, disc_loss = 0.004491648541433862
Trained batch 1313 in epoch 1, gen_loss = 1.5455677633597609, disc_loss = 0.004488984851210106
Trained batch 1314 in epoch 1, gen_loss = 1.545343940883535, disc_loss = 0.004485975467401182
Trained batch 1315 in epoch 1, gen_loss = 1.5455007180798017, disc_loss = 0.0044828506614559074
Trained batch 1316 in epoch 1, gen_loss = 1.5454757149326321, disc_loss = 0.004480036825166422
Trained batch 1317 in epoch 1, gen_loss = 1.5454959363785428, disc_loss = 0.004477261318165822
Trained batch 1318 in epoch 1, gen_loss = 1.545695962193701, disc_loss = 0.004474175412952671
Trained batch 1319 in epoch 1, gen_loss = 1.5459028082363533, disc_loss = 0.004471056192932972
Trained batch 1320 in epoch 1, gen_loss = 1.545935623488762, disc_loss = 0.004468023429557672
Trained batch 1321 in epoch 1, gen_loss = 1.5460261730491303, disc_loss = 0.0044649717847512135
Trained batch 1322 in epoch 1, gen_loss = 1.5459812054197986, disc_loss = 0.004462213225140291
Trained batch 1323 in epoch 1, gen_loss = 1.5458533346112762, disc_loss = 0.004459045355627542
Trained batch 1324 in epoch 1, gen_loss = 1.5461220343607776, disc_loss = 0.004456065445578271
Trained batch 1325 in epoch 1, gen_loss = 1.5458818902437144, disc_loss = 0.004452923250635808
Trained batch 1326 in epoch 1, gen_loss = 1.5459486182327098, disc_loss = 0.004450091808103463
Trained batch 1327 in epoch 1, gen_loss = 1.5458363297294422, disc_loss = 0.004447607672433611
Trained batch 1328 in epoch 1, gen_loss = 1.545718619032315, disc_loss = 0.004444556705382733
Trained batch 1329 in epoch 1, gen_loss = 1.5454860522334737, disc_loss = 0.004441620631629682
Trained batch 1330 in epoch 1, gen_loss = 1.5454211707047105, disc_loss = 0.004438816222893918
Trained batch 1331 in epoch 1, gen_loss = 1.5453298181384891, disc_loss = 0.004436225578722991
Trained batch 1332 in epoch 1, gen_loss = 1.5452500033539573, disc_loss = 0.004433351969290074
Trained batch 1333 in epoch 1, gen_loss = 1.5451039996282987, disc_loss = 0.004430352692461152
Trained batch 1334 in epoch 1, gen_loss = 1.5450601943869715, disc_loss = 0.004427869690131756
Trained batch 1335 in epoch 1, gen_loss = 1.5451039793248662, disc_loss = 0.004425330943480524
Trained batch 1336 in epoch 1, gen_loss = 1.5449196139466166, disc_loss = 0.00442236414773342
Trained batch 1337 in epoch 1, gen_loss = 1.54531306634213, disc_loss = 0.004419476288853764
Trained batch 1338 in epoch 1, gen_loss = 1.5451805758066726, disc_loss = 0.004416691931936166
Trained batch 1339 in epoch 1, gen_loss = 1.545214472332997, disc_loss = 0.004413849237379739
Trained batch 1340 in epoch 1, gen_loss = 1.545155061615838, disc_loss = 0.004410998712058629
Trained batch 1341 in epoch 1, gen_loss = 1.5450196122270405, disc_loss = 0.004408047410769054
Trained batch 1342 in epoch 1, gen_loss = 1.5449711525520102, disc_loss = 0.004405060024822893
Trained batch 1343 in epoch 1, gen_loss = 1.5448700867238498, disc_loss = 0.004402015628383673
Trained batch 1344 in epoch 1, gen_loss = 1.5447794338141232, disc_loss = 0.004399058079534404
Trained batch 1345 in epoch 1, gen_loss = 1.5447726730606, disc_loss = 0.0043960724541638775
Trained batch 1346 in epoch 1, gen_loss = 1.5447553232500264, disc_loss = 0.004393391599279307
Trained batch 1347 in epoch 1, gen_loss = 1.544600403450363, disc_loss = 0.0043908011292969115
Trained batch 1348 in epoch 1, gen_loss = 1.544559323230967, disc_loss = 0.004388075138498225
Trained batch 1349 in epoch 1, gen_loss = 1.5444266494115193, disc_loss = 0.004385790944722464
Trained batch 1350 in epoch 1, gen_loss = 1.544307159548067, disc_loss = 0.004383519199816148
Trained batch 1351 in epoch 1, gen_loss = 1.5443703713854389, disc_loss = 0.004380667827222734
Trained batch 1352 in epoch 1, gen_loss = 1.5447276722301135, disc_loss = 0.004378435407422847
Trained batch 1353 in epoch 1, gen_loss = 1.54469529265315, disc_loss = 0.004376649500453859
Trained batch 1354 in epoch 1, gen_loss = 1.5444824407901272, disc_loss = 0.004374563684560294
Trained batch 1355 in epoch 1, gen_loss = 1.5443461304393138, disc_loss = 0.004371931818568448
Trained batch 1356 in epoch 1, gen_loss = 1.5444142954614817, disc_loss = 0.0043693735746824815
Trained batch 1357 in epoch 1, gen_loss = 1.544594104493665, disc_loss = 0.0043669639562400825
Trained batch 1358 in epoch 1, gen_loss = 1.544402371354626, disc_loss = 0.004364767325062506
Trained batch 1359 in epoch 1, gen_loss = 1.5444179417455897, disc_loss = 0.004362153872320692
Trained batch 1360 in epoch 1, gen_loss = 1.5442509075721162, disc_loss = 0.004360218619898082
Trained batch 1361 in epoch 1, gen_loss = 1.5440303413703402, disc_loss = 0.004357893633285333
Trained batch 1362 in epoch 1, gen_loss = 1.5438109256726193, disc_loss = 0.004355198945344928
Trained batch 1363 in epoch 1, gen_loss = 1.5436857734257874, disc_loss = 0.004352420651947665
Trained batch 1364 in epoch 1, gen_loss = 1.5437187411409594, disc_loss = 0.004349450843509768
Trained batch 1365 in epoch 1, gen_loss = 1.5437608010423305, disc_loss = 0.004346650923583278
Trained batch 1366 in epoch 1, gen_loss = 1.5439450565532078, disc_loss = 0.004343882666730177
Trained batch 1367 in epoch 1, gen_loss = 1.5437278119269868, disc_loss = 0.004341053504434946
Trained batch 1368 in epoch 1, gen_loss = 1.5435353197086632, disc_loss = 0.004338084329001709
Trained batch 1369 in epoch 1, gen_loss = 1.54353949231823, disc_loss = 0.004335076250184759
Trained batch 1370 in epoch 1, gen_loss = 1.5437588320432312, disc_loss = 0.004332121560181678
Trained batch 1371 in epoch 1, gen_loss = 1.5436237227638678, disc_loss = 0.004329378472330302
Trained batch 1372 in epoch 1, gen_loss = 1.5433699125281581, disc_loss = 0.004326602042332927
Trained batch 1373 in epoch 1, gen_loss = 1.5433519914681213, disc_loss = 0.004323799879864361
Trained batch 1374 in epoch 1, gen_loss = 1.5432773392417214, disc_loss = 0.00432092468471224
Trained batch 1375 in epoch 1, gen_loss = 1.543498632086571, disc_loss = 0.004318066498822297
Trained batch 1376 in epoch 1, gen_loss = 1.5433422520096611, disc_loss = 0.004315151721707879
Trained batch 1377 in epoch 1, gen_loss = 1.5430721206312084, disc_loss = 0.004312326039485576
Trained batch 1378 in epoch 1, gen_loss = 1.5431783713665106, disc_loss = 0.004309530508291416
Trained batch 1379 in epoch 1, gen_loss = 1.543119849415793, disc_loss = 0.004306660184311508
Trained batch 1380 in epoch 1, gen_loss = 1.542971540930304, disc_loss = 0.004303708864775268
Trained batch 1381 in epoch 1, gen_loss = 1.5429908608217142, disc_loss = 0.004300852050875801
Trained batch 1382 in epoch 1, gen_loss = 1.5430804260899342, disc_loss = 0.0042981021460308175
Trained batch 1383 in epoch 1, gen_loss = 1.5430650257995362, disc_loss = 0.004295138900414781
Trained batch 1384 in epoch 1, gen_loss = 1.5431882861719235, disc_loss = 0.004292382467809194
Trained batch 1385 in epoch 1, gen_loss = 1.5430101361797657, disc_loss = 0.004289663223843114
Trained batch 1386 in epoch 1, gen_loss = 1.54300188433806, disc_loss = 0.0042867308836452974
Trained batch 1387 in epoch 1, gen_loss = 1.542860510198115, disc_loss = 0.004283820940478103
Trained batch 1388 in epoch 1, gen_loss = 1.5432657405916437, disc_loss = 0.004281367036980233
Trained batch 1389 in epoch 1, gen_loss = 1.5431537610163792, disc_loss = 0.004279543538801891
Trained batch 1390 in epoch 1, gen_loss = 1.543109306579524, disc_loss = 0.0042776341615561935
Trained batch 1391 in epoch 1, gen_loss = 1.543050137573275, disc_loss = 0.004274989428936926
Trained batch 1392 in epoch 1, gen_loss = 1.5429559329047275, disc_loss = 0.004272529976413624
Trained batch 1393 in epoch 1, gen_loss = 1.5427865829837202, disc_loss = 0.004270162139831754
Trained batch 1394 in epoch 1, gen_loss = 1.542608569770731, disc_loss = 0.0042676292394357145
Trained batch 1395 in epoch 1, gen_loss = 1.5425425005334839, disc_loss = 0.004265043847979614
Trained batch 1396 in epoch 1, gen_loss = 1.542660440729615, disc_loss = 0.004262301018878664
Trained batch 1397 in epoch 1, gen_loss = 1.5427953750960988, disc_loss = 0.0042595309352850145
Trained batch 1398 in epoch 1, gen_loss = 1.5427385569470877, disc_loss = 0.004256843559175089
Trained batch 1399 in epoch 1, gen_loss = 1.542851899606841, disc_loss = 0.004254072587303069
Trained batch 1400 in epoch 1, gen_loss = 1.5428312942013411, disc_loss = 0.004251230790080462
Trained batch 1401 in epoch 1, gen_loss = 1.5429278531360218, disc_loss = 0.004248452232945089
Trained batch 1402 in epoch 1, gen_loss = 1.5429445692070536, disc_loss = 0.0042459760574098376
Trained batch 1403 in epoch 1, gen_loss = 1.5427445832990174, disc_loss = 0.004243810386941294
Trained batch 1404 in epoch 1, gen_loss = 1.5428234087614827, disc_loss = 0.004241105758664165
Trained batch 1405 in epoch 1, gen_loss = 1.5430228334572034, disc_loss = 0.004238429122509956
Trained batch 1406 in epoch 1, gen_loss = 1.5430422782389595, disc_loss = 0.004235732522907709
Trained batch 1407 in epoch 1, gen_loss = 1.5432366656816818, disc_loss = 0.004233136865970912
Trained batch 1408 in epoch 1, gen_loss = 1.543125583738025, disc_loss = 0.004230274831076124
Trained batch 1409 in epoch 1, gen_loss = 1.5429889859037196, disc_loss = 0.00422742456832037
Trained batch 1410 in epoch 1, gen_loss = 1.5431527207710487, disc_loss = 0.004224619102146734
Trained batch 1411 in epoch 1, gen_loss = 1.543055766365008, disc_loss = 0.0042218540192108635
Trained batch 1412 in epoch 1, gen_loss = 1.543015980332436, disc_loss = 0.004219089591410917
Trained batch 1413 in epoch 1, gen_loss = 1.5429574714017218, disc_loss = 0.004216371102978873
Trained batch 1414 in epoch 1, gen_loss = 1.543120899638523, disc_loss = 0.004213903200997339
Trained batch 1415 in epoch 1, gen_loss = 1.5430097638887201, disc_loss = 0.004211366400443689
Trained batch 1416 in epoch 1, gen_loss = 1.5429090487763506, disc_loss = 0.0042085665771053335
Trained batch 1417 in epoch 1, gen_loss = 1.5428103934894664, disc_loss = 0.0042057315359851485
Trained batch 1418 in epoch 1, gen_loss = 1.542786033494612, disc_loss = 0.004202988000067395
Trained batch 1419 in epoch 1, gen_loss = 1.5427535738743527, disc_loss = 0.00420024348167714
Trained batch 1420 in epoch 1, gen_loss = 1.5426870129798014, disc_loss = 0.004197487872410392
Trained batch 1421 in epoch 1, gen_loss = 1.5428694874760807, disc_loss = 0.004194753629408182
Trained batch 1422 in epoch 1, gen_loss = 1.5428227827905854, disc_loss = 0.004192153385999313
Trained batch 1423 in epoch 1, gen_loss = 1.5426456398341093, disc_loss = 0.004189528769713659
Trained batch 1424 in epoch 1, gen_loss = 1.542490487767939, disc_loss = 0.004186875276428876
Trained batch 1425 in epoch 1, gen_loss = 1.5422832944951586, disc_loss = 0.00418417065885079
Trained batch 1426 in epoch 1, gen_loss = 1.5422708829466747, disc_loss = 0.004181398637656018
Trained batch 1427 in epoch 1, gen_loss = 1.5421678573310542, disc_loss = 0.004178646986571441
Trained batch 1428 in epoch 1, gen_loss = 1.5421035189658632, disc_loss = 0.004175921019587156
Trained batch 1429 in epoch 1, gen_loss = 1.542158793152629, disc_loss = 0.004173442416051419
Trained batch 1430 in epoch 1, gen_loss = 1.5420645394581836, disc_loss = 0.004171039555942985
Trained batch 1431 in epoch 1, gen_loss = 1.5420237961927605, disc_loss = 0.004168386689750084
Trained batch 1432 in epoch 1, gen_loss = 1.5419690099032044, disc_loss = 0.004166058961286038
Trained batch 1433 in epoch 1, gen_loss = 1.5417358535270478, disc_loss = 0.004163386947056068
Trained batch 1434 in epoch 1, gen_loss = 1.5416907992512507, disc_loss = 0.004160867013247726
Trained batch 1435 in epoch 1, gen_loss = 1.541754247086294, disc_loss = 0.004158421812979436
Trained batch 1436 in epoch 1, gen_loss = 1.5417124704096827, disc_loss = 0.004155788820414907
Trained batch 1437 in epoch 1, gen_loss = 1.5416663235185541, disc_loss = 0.00415353465834265
Trained batch 1438 in epoch 1, gen_loss = 1.5419538480030985, disc_loss = 0.004151160291076445
Trained batch 1439 in epoch 1, gen_loss = 1.541928067141109, disc_loss = 0.004148505165388391
Trained batch 1440 in epoch 1, gen_loss = 1.5418600106222773, disc_loss = 0.004146075224172887
Trained batch 1441 in epoch 1, gen_loss = 1.5415724778803641, disc_loss = 0.004143432460375496
Trained batch 1442 in epoch 1, gen_loss = 1.5416299026209037, disc_loss = 0.004140834760609243
Trained batch 1443 in epoch 1, gen_loss = 1.541533102454241, disc_loss = 0.004138178710133296
Trained batch 1444 in epoch 1, gen_loss = 1.5414602801874022, disc_loss = 0.004135688212947923
Trained batch 1445 in epoch 1, gen_loss = 1.5418054679122704, disc_loss = 0.004133434775431545
Trained batch 1446 in epoch 1, gen_loss = 1.5417685796247322, disc_loss = 0.004131503839754311
Trained batch 1447 in epoch 1, gen_loss = 1.541892517913771, disc_loss = 0.0041295947892106884
Trained batch 1448 in epoch 1, gen_loss = 1.5418449172980215, disc_loss = 0.0041270623242737545
Trained batch 1449 in epoch 1, gen_loss = 1.5417306292468105, disc_loss = 0.004124366847711921
Trained batch 1450 in epoch 1, gen_loss = 1.5416058114608513, disc_loss = 0.004121709877999707
Trained batch 1451 in epoch 1, gen_loss = 1.541506917516062, disc_loss = 0.0041190488311769495
Trained batch 1452 in epoch 1, gen_loss = 1.5414453852365366, disc_loss = 0.004116376500054909
Trained batch 1453 in epoch 1, gen_loss = 1.5413119720789556, disc_loss = 0.004113707607902652
Trained batch 1454 in epoch 1, gen_loss = 1.5413958443808802, disc_loss = 0.004111096262471763
Trained batch 1455 in epoch 1, gen_loss = 1.5414408082654187, disc_loss = 0.004108483304222758
Trained batch 1456 in epoch 1, gen_loss = 1.5413061794387042, disc_loss = 0.004106342480878276
Trained batch 1457 in epoch 1, gen_loss = 1.5413844074404943, disc_loss = 0.004104089280742921
Trained batch 1458 in epoch 1, gen_loss = 1.5413546100555011, disc_loss = 0.004101542277593386
Trained batch 1459 in epoch 1, gen_loss = 1.5412485268018017, disc_loss = 0.004098971673783413
Trained batch 1460 in epoch 1, gen_loss = 1.5413832495589521, disc_loss = 0.004096327939090363
Trained batch 1461 in epoch 1, gen_loss = 1.5412827885101987, disc_loss = 0.004093682723188812
Trained batch 1462 in epoch 1, gen_loss = 1.5413599761479209, disc_loss = 0.0040915242823164515
Trained batch 1463 in epoch 1, gen_loss = 1.5413042290614603, disc_loss = 0.004089417365222026
Trained batch 1464 in epoch 1, gen_loss = 1.541324167202764, disc_loss = 0.0040875563034255364
Trained batch 1465 in epoch 1, gen_loss = 1.541171080256224, disc_loss = 0.00408520421210888
Trained batch 1466 in epoch 1, gen_loss = 1.5410050517779754, disc_loss = 0.00408279756074165
Trained batch 1467 in epoch 1, gen_loss = 1.5411034573163909, disc_loss = 0.004080559479510279
Trained batch 1468 in epoch 1, gen_loss = 1.5411701262443547, disc_loss = 0.004078141479147345
Trained batch 1469 in epoch 1, gen_loss = 1.5413766785543792, disc_loss = 0.004075615917673797
Trained batch 1470 in epoch 1, gen_loss = 1.5413148021471088, disc_loss = 0.004073163819595707
Trained batch 1471 in epoch 1, gen_loss = 1.5412389228687338, disc_loss = 0.004070597052403806
Trained batch 1472 in epoch 1, gen_loss = 1.5412844094142408, disc_loss = 0.0040682438822918065
Trained batch 1473 in epoch 1, gen_loss = 1.5413271716847672, disc_loss = 0.004066372129432269
Trained batch 1474 in epoch 1, gen_loss = 1.5414806281105946, disc_loss = 0.004064128476617289
Trained batch 1475 in epoch 1, gen_loss = 1.541606614663995, disc_loss = 0.004061874631361822
Trained batch 1476 in epoch 1, gen_loss = 1.5418207450097046, disc_loss = 0.0040594463220038615
Trained batch 1477 in epoch 1, gen_loss = 1.541818741693871, disc_loss = 0.004056906416176986
Trained batch 1478 in epoch 1, gen_loss = 1.5420170326826135, disc_loss = 0.004054657458883419
Trained batch 1479 in epoch 1, gen_loss = 1.5418580449916222, disc_loss = 0.004052207150439122
Trained batch 1480 in epoch 1, gen_loss = 1.5418654602174418, disc_loss = 0.0040497555400830975
Trained batch 1481 in epoch 1, gen_loss = 1.5418124029993527, disc_loss = 0.004047266662692056
Trained batch 1482 in epoch 1, gen_loss = 1.5417578104614649, disc_loss = 0.0040448407160122305
Trained batch 1483 in epoch 1, gen_loss = 1.5416884118655942, disc_loss = 0.004042477274099095
Trained batch 1484 in epoch 1, gen_loss = 1.541663077704433, disc_loss = 0.004039963118568132
Trained batch 1485 in epoch 1, gen_loss = 1.5417402004810554, disc_loss = 0.004037732990754895
Trained batch 1486 in epoch 1, gen_loss = 1.5416873274991074, disc_loss = 0.0040354134611653575
Trained batch 1487 in epoch 1, gen_loss = 1.54167758769566, disc_loss = 0.004032914361604164
Trained batch 1488 in epoch 1, gen_loss = 1.5416934819250319, disc_loss = 0.004030451838849982
Trained batch 1489 in epoch 1, gen_loss = 1.5417804550804548, disc_loss = 0.004028221353655681
Trained batch 1490 in epoch 1, gen_loss = 1.541698744679201, disc_loss = 0.004025893847646703
Trained batch 1491 in epoch 1, gen_loss = 1.5416406422613773, disc_loss = 0.004023584742885553
Trained batch 1492 in epoch 1, gen_loss = 1.541424078823174, disc_loss = 0.004021232693862514
Trained batch 1493 in epoch 1, gen_loss = 1.5415362159570696, disc_loss = 0.004018777099090791
Trained batch 1494 in epoch 1, gen_loss = 1.5415272558811914, disc_loss = 0.00401630370973463
Trained batch 1495 in epoch 1, gen_loss = 1.5413800859674414, disc_loss = 0.0040138542173862365
Trained batch 1496 in epoch 1, gen_loss = 1.5412575858548712, disc_loss = 0.0040114259959491555
Trained batch 1497 in epoch 1, gen_loss = 1.5413898352946396, disc_loss = 0.0040090860991218984
Trained batch 1498 in epoch 1, gen_loss = 1.5414245072963477, disc_loss = 0.004006667544299848
Trained batch 1499 in epoch 1, gen_loss = 1.5413668642044067, disc_loss = 0.0040041498060454615
Trained batch 1500 in epoch 1, gen_loss = 1.5414390471043546, disc_loss = 0.004001622647401873
Trained batch 1501 in epoch 1, gen_loss = 1.5414094559044718, disc_loss = 0.003999250008115503
Trained batch 1502 in epoch 1, gen_loss = 1.5412459181533682, disc_loss = 0.0039968438118517914
Trained batch 1503 in epoch 1, gen_loss = 1.5411113766913718, disc_loss = 0.003994947741965858
Trained batch 1504 in epoch 1, gen_loss = 1.541106142158128, disc_loss = 0.003993750783002571
Trained batch 1505 in epoch 1, gen_loss = 1.5410944693591966, disc_loss = 0.003993268281226105
Trained batch 1506 in epoch 1, gen_loss = 1.5409477946769345, disc_loss = 0.003992062235228589
Trained batch 1507 in epoch 1, gen_loss = 1.5407217791605374, disc_loss = 0.003990382328361229
Trained batch 1508 in epoch 1, gen_loss = 1.5406815958307467, disc_loss = 0.003990647774798017
Trained batch 1509 in epoch 1, gen_loss = 1.5405309362916757, disc_loss = 0.003991033836733935
Trained batch 1510 in epoch 1, gen_loss = 1.5404396202294421, disc_loss = 0.003990307135189191
Trained batch 1511 in epoch 1, gen_loss = 1.5404379705272655, disc_loss = 0.003988334493399071
Trained batch 1512 in epoch 1, gen_loss = 1.540400145310719, disc_loss = 0.003986007623827736
Trained batch 1513 in epoch 1, gen_loss = 1.5403689049194165, disc_loss = 0.0039836896547663665
Trained batch 1514 in epoch 1, gen_loss = 1.540289847528187, disc_loss = 0.003981460866596313
Trained batch 1515 in epoch 1, gen_loss = 1.5402938140099156, disc_loss = 0.0039791408026544715
Trained batch 1516 in epoch 1, gen_loss = 1.540079157448318, disc_loss = 0.003977050708501168
Trained batch 1517 in epoch 1, gen_loss = 1.539915353256095, disc_loss = 0.003974949711879973
Trained batch 1518 in epoch 1, gen_loss = 1.539807889632601, disc_loss = 0.0039730422839995535
Trained batch 1519 in epoch 1, gen_loss = 1.5398248913256745, disc_loss = 0.00397094378670437
Trained batch 1520 in epoch 1, gen_loss = 1.5399300557543463, disc_loss = 0.003969123110664292
Trained batch 1521 in epoch 1, gen_loss = 1.5397133999522505, disc_loss = 0.0039668582948337
Trained batch 1522 in epoch 1, gen_loss = 1.5395675322294078, disc_loss = 0.003964726775291086
Trained batch 1523 in epoch 1, gen_loss = 1.5394416565657287, disc_loss = 0.003962790324533187
Trained batch 1524 in epoch 1, gen_loss = 1.5394477948986116, disc_loss = 0.0039608501104664694
Trained batch 1525 in epoch 1, gen_loss = 1.539508529524972, disc_loss = 0.003959698607964086
Trained batch 1526 in epoch 1, gen_loss = 1.5394401638509405, disc_loss = 0.0039594476840734945
Trained batch 1527 in epoch 1, gen_loss = 1.5395834687804677, disc_loss = 0.003957939885881792
Trained batch 1528 in epoch 1, gen_loss = 1.5395866293311509, disc_loss = 0.003956114294325602
Trained batch 1529 in epoch 1, gen_loss = 1.53981551298129, disc_loss = 0.003954726491293496
Trained batch 1530 in epoch 1, gen_loss = 1.539683065096745, disc_loss = 0.003953428366935872
Trained batch 1531 in epoch 1, gen_loss = 1.5401070835384936, disc_loss = 0.00395131911089066
Trained batch 1532 in epoch 1, gen_loss = 1.5399533948008717, disc_loss = 0.003949309463511508
Trained batch 1533 in epoch 1, gen_loss = 1.5400297637091467, disc_loss = 0.003947703720797373
Trained batch 1534 in epoch 1, gen_loss = 1.5397930833338138, disc_loss = 0.003945552100075169
Trained batch 1535 in epoch 1, gen_loss = 1.5399061106921483, disc_loss = 0.0039437080040348365
Trained batch 1536 in epoch 1, gen_loss = 1.5401175306769417, disc_loss = 0.003942536935140167
Trained batch 1537 in epoch 1, gen_loss = 1.5398699439703565, disc_loss = 0.003940804009025681
Trained batch 1538 in epoch 1, gen_loss = 1.539694268568682, disc_loss = 0.003938513083372927
Trained batch 1539 in epoch 1, gen_loss = 1.5393702583653586, disc_loss = 0.003936865428236219
Trained batch 1540 in epoch 1, gen_loss = 1.5392835099228321, disc_loss = 0.0039348147507343115
Trained batch 1541 in epoch 1, gen_loss = 1.5393875380434414, disc_loss = 0.003932676596771856
Trained batch 1542 in epoch 1, gen_loss = 1.5394841610265102, disc_loss = 0.003930521340486117
Trained batch 1543 in epoch 1, gen_loss = 1.5394016251817269, disc_loss = 0.003928209714881561
Trained batch 1544 in epoch 1, gen_loss = 1.539490287898042, disc_loss = 0.003925961272933816
Trained batch 1545 in epoch 1, gen_loss = 1.5393986970301896, disc_loss = 0.003923774656252246
Trained batch 1546 in epoch 1, gen_loss = 1.5393262851138074, disc_loss = 0.003921467332499696
Trained batch 1547 in epoch 1, gen_loss = 1.5391681034127562, disc_loss = 0.003919181256462596
Trained batch 1548 in epoch 1, gen_loss = 1.5391725276346127, disc_loss = 0.003916858184570942
Trained batch 1549 in epoch 1, gen_loss = 1.5390167691630703, disc_loss = 0.003914582245906199
Trained batch 1550 in epoch 1, gen_loss = 1.5389696135204274, disc_loss = 0.003912460430306299
Trained batch 1551 in epoch 1, gen_loss = 1.5391151962667395, disc_loss = 0.003910628154764858
Trained batch 1552 in epoch 1, gen_loss = 1.5391321880005286, disc_loss = 0.003908913476108597
Trained batch 1553 in epoch 1, gen_loss = 1.539071039113299, disc_loss = 0.00390688575410152
Trained batch 1554 in epoch 1, gen_loss = 1.5392471898407032, disc_loss = 0.0039046413692180814
Trained batch 1555 in epoch 1, gen_loss = 1.5392299374148901, disc_loss = 0.0039023961769643623
Trained batch 1556 in epoch 1, gen_loss = 1.5388736366536575, disc_loss = 0.0039003631384461114
Trained batch 1557 in epoch 1, gen_loss = 1.538890263771062, disc_loss = 0.0038983311937189845
Trained batch 1558 in epoch 1, gen_loss = 1.5389258463157913, disc_loss = 0.003896299565571684
Trained batch 1559 in epoch 1, gen_loss = 1.5390882737361469, disc_loss = 0.0038940144690385726
Trained batch 1560 in epoch 1, gen_loss = 1.539013270534513, disc_loss = 0.0038918944445215996
Trained batch 1561 in epoch 1, gen_loss = 1.5390744446639673, disc_loss = 0.0038900807784942857
Trained batch 1562 in epoch 1, gen_loss = 1.5390255869159466, disc_loss = 0.0038883753477723707
Trained batch 1563 in epoch 1, gen_loss = 1.5393477297195084, disc_loss = 0.003886407941568728
Trained batch 1564 in epoch 1, gen_loss = 1.5392751618315237, disc_loss = 0.003884315988993251
Trained batch 1565 in epoch 1, gen_loss = 1.539153381554103, disc_loss = 0.0038823283855421355
Trained batch 1566 in epoch 1, gen_loss = 1.5392142177464936, disc_loss = 0.0038800538051557707
Trained batch 1567 in epoch 1, gen_loss = 1.5391070980350583, disc_loss = 0.003877748872295045
Trained batch 1568 in epoch 1, gen_loss = 1.5390121415589857, disc_loss = 0.003875511024872401
Trained batch 1569 in epoch 1, gen_loss = 1.538915608794826, disc_loss = 0.0038734474487526335
Trained batch 1570 in epoch 1, gen_loss = 1.5388504838123964, disc_loss = 0.0038714981344911605
Trained batch 1571 in epoch 1, gen_loss = 1.5387971076649867, disc_loss = 0.0038693353588490375
Trained batch 1572 in epoch 1, gen_loss = 1.5386885712272562, disc_loss = 0.0038671921945040992
Trained batch 1573 in epoch 1, gen_loss = 1.5387178269395987, disc_loss = 0.0038649417692333135
Trained batch 1574 in epoch 1, gen_loss = 1.5388098920337738, disc_loss = 0.003862988755119861
Trained batch 1575 in epoch 1, gen_loss = 1.5388597827121087, disc_loss = 0.003860789130476636
Trained batch 1576 in epoch 1, gen_loss = 1.5389157828456175, disc_loss = 0.0038585515143548343
Trained batch 1577 in epoch 1, gen_loss = 1.5387624947139367, disc_loss = 0.0038565960541667495
Trained batch 1578 in epoch 1, gen_loss = 1.538821946600708, disc_loss = 0.003854690178652014
Trained batch 1579 in epoch 1, gen_loss = 1.5386720425720457, disc_loss = 0.0038525270687617343
Trained batch 1580 in epoch 1, gen_loss = 1.538618915899881, disc_loss = 0.0038505031698334645
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 1.4883983135223389, disc_loss = 0.00029578516841866076
Trained batch 1 in epoch 2, gen_loss = 1.4372296333312988, disc_loss = 0.00042372655298095196
Trained batch 2 in epoch 2, gen_loss = 1.6026080052057903, disc_loss = 0.000554330307447041
Trained batch 3 in epoch 2, gen_loss = 1.588469237089157, disc_loss = 0.0006410802525351755
Trained batch 4 in epoch 2, gen_loss = 1.6114740371704102, disc_loss = 0.0005966689437627793
Trained batch 5 in epoch 2, gen_loss = 1.6039610703786213, disc_loss = 0.0005466286190009365
Trained batch 6 in epoch 2, gen_loss = 1.5769703728812081, disc_loss = 0.0005080355206570987
Trained batch 7 in epoch 2, gen_loss = 1.5627527236938477, disc_loss = 0.00047469561104662716
Trained batch 8 in epoch 2, gen_loss = 1.5440964698791504, disc_loss = 0.0004500161869347923
Trained batch 9 in epoch 2, gen_loss = 1.5546232223510743, disc_loss = 0.00042828777950489896
Trained batch 10 in epoch 2, gen_loss = 1.5723615559664639, disc_loss = 0.00042017634603491223
Trained batch 11 in epoch 2, gen_loss = 1.5761996905008953, disc_loss = 0.00040402804006589577
Trained batch 12 in epoch 2, gen_loss = 1.5925582097126887, disc_loss = 0.00040649155450340075
Trained batch 13 in epoch 2, gen_loss = 1.598770090511867, disc_loss = 0.0003992076817667112
Trained batch 14 in epoch 2, gen_loss = 1.5960462013880412, disc_loss = 0.0003888848179485649
Trained batch 15 in epoch 2, gen_loss = 1.580443188548088, disc_loss = 0.0003795112970692571
Trained batch 16 in epoch 2, gen_loss = 1.5796797345666325, disc_loss = 0.0003775838841273285
Trained batch 17 in epoch 2, gen_loss = 1.576082342200809, disc_loss = 0.0003845036569853417
Trained batch 18 in epoch 2, gen_loss = 1.5733414135481183, disc_loss = 0.000374346596225606
Trained batch 19 in epoch 2, gen_loss = 1.5749933063983916, disc_loss = 0.00037330922059481965
Trained batch 20 in epoch 2, gen_loss = 1.5681347676685877, disc_loss = 0.0003723151291654046
Trained batch 21 in epoch 2, gen_loss = 1.5549269643696872, disc_loss = 0.0003943366980158978
Trained batch 22 in epoch 2, gen_loss = 1.5631594813388328, disc_loss = 0.0004239264488442922
Trained batch 23 in epoch 2, gen_loss = 1.5594346274932225, disc_loss = 0.00045079195964111324
Trained batch 24 in epoch 2, gen_loss = 1.5546162271499633, disc_loss = 0.00045176048995926977
Trained batch 25 in epoch 2, gen_loss = 1.5476385217446547, disc_loss = 0.0004525150221665032
Trained batch 26 in epoch 2, gen_loss = 1.5353651841481526, disc_loss = 0.0004510745962357356
Trained batch 27 in epoch 2, gen_loss = 1.5331520778792245, disc_loss = 0.0004510095916754965
Trained batch 28 in epoch 2, gen_loss = 1.5245564394983753, disc_loss = 0.0004678517881106457
Trained batch 29 in epoch 2, gen_loss = 1.5276846011479697, disc_loss = 0.00046831622215298316
Trained batch 30 in epoch 2, gen_loss = 1.5177091744638258, disc_loss = 0.00046449464618138247
Trained batch 31 in epoch 2, gen_loss = 1.5158079750835896, disc_loss = 0.0004776892874360783
Trained batch 32 in epoch 2, gen_loss = 1.5130014455679692, disc_loss = 0.0004908341868554778
Trained batch 33 in epoch 2, gen_loss = 1.5102828706012053, disc_loss = 0.0004847445251310573
Trained batch 34 in epoch 2, gen_loss = 1.5287858179637364, disc_loss = 0.0004907789972743818
Trained batch 35 in epoch 2, gen_loss = 1.523299753665924, disc_loss = 0.0005093175859656185
Trained batch 36 in epoch 2, gen_loss = 1.5108683012627266, disc_loss = 0.0005145943802277985
Trained batch 37 in epoch 2, gen_loss = 1.510513518985949, disc_loss = 0.0005067863492417688
Trained batch 38 in epoch 2, gen_loss = 1.5019036684280787, disc_loss = 0.0005111476579585519
Trained batch 39 in epoch 2, gen_loss = 1.509100902080536, disc_loss = 0.0005217280937358737
Trained batch 40 in epoch 2, gen_loss = 1.503211309270161, disc_loss = 0.0005345997491442576
Trained batch 41 in epoch 2, gen_loss = 1.4995496585255577, disc_loss = 0.0005418763030320406
Trained batch 42 in epoch 2, gen_loss = 1.5068873555161233, disc_loss = 0.0005389417523009227
Trained batch 43 in epoch 2, gen_loss = 1.5187232250517064, disc_loss = 0.0005354942986741662
Trained batch 44 in epoch 2, gen_loss = 1.5206236177020602, disc_loss = 0.0005323958001099526
Trained batch 45 in epoch 2, gen_loss = 1.528575044611226, disc_loss = 0.0005276777943515259
Trained batch 46 in epoch 2, gen_loss = 1.5231482906544462, disc_loss = 0.0005228251164303498
Trained batch 47 in epoch 2, gen_loss = 1.5220220362146695, disc_loss = 0.0005281618675023007
Trained batch 48 in epoch 2, gen_loss = 1.5182316157282616, disc_loss = 0.0005277001396372762
Trained batch 49 in epoch 2, gen_loss = 1.5192040252685546, disc_loss = 0.0005275874782819301
Trained batch 50 in epoch 2, gen_loss = 1.519695702721091, disc_loss = 0.0005377683795385939
Trained batch 51 in epoch 2, gen_loss = 1.5213719927347624, disc_loss = 0.0005536498535478201
Trained batch 52 in epoch 2, gen_loss = 1.521156425745982, disc_loss = 0.000564049528516337
Trained batch 53 in epoch 2, gen_loss = 1.5251110902539007, disc_loss = 0.0005704474945863088
Trained batch 54 in epoch 2, gen_loss = 1.5221177664670078, disc_loss = 0.0005707415392283689
Trained batch 55 in epoch 2, gen_loss = 1.5204341113567352, disc_loss = 0.0005662997760477342
Trained batch 56 in epoch 2, gen_loss = 1.519104146120841, disc_loss = 0.0005653994607232642
Trained batch 57 in epoch 2, gen_loss = 1.530742937120898, disc_loss = 0.0005631744118953316
Trained batch 58 in epoch 2, gen_loss = 1.5263035701493086, disc_loss = 0.000562365352318196
Trained batch 59 in epoch 2, gen_loss = 1.5283990661303202, disc_loss = 0.0005618642967116709
Trained batch 60 in epoch 2, gen_loss = 1.5271304474502314, disc_loss = 0.0005622096216596175
Trained batch 61 in epoch 2, gen_loss = 1.525148699360509, disc_loss = 0.0005590710676305236
Trained batch 62 in epoch 2, gen_loss = 1.5267471623799158, disc_loss = 0.0005543495044260035
Trained batch 63 in epoch 2, gen_loss = 1.5259771794080734, disc_loss = 0.0005511415165528888
Trained batch 64 in epoch 2, gen_loss = 1.5241140915797307, disc_loss = 0.0005471877391056086
Trained batch 65 in epoch 2, gen_loss = 1.5204454479795513, disc_loss = 0.0005489012282024222
Trained batch 66 in epoch 2, gen_loss = 1.519760638920229, disc_loss = 0.0005564229999870451
Trained batch 67 in epoch 2, gen_loss = 1.514943745206384, disc_loss = 0.0005601119607009049
Trained batch 68 in epoch 2, gen_loss = 1.5105038587597832, disc_loss = 0.0005599814015811822
Trained batch 69 in epoch 2, gen_loss = 1.5157090629850114, disc_loss = 0.000557703192628521
Trained batch 70 in epoch 2, gen_loss = 1.514897433804794, disc_loss = 0.0005552388680934853
Trained batch 71 in epoch 2, gen_loss = 1.5214762190977733, disc_loss = 0.0005522039613828787
Trained batch 72 in epoch 2, gen_loss = 1.5266918515505856, disc_loss = 0.0005535807242068424
Trained batch 73 in epoch 2, gen_loss = 1.5206060635076988, disc_loss = 0.0005507509965871184
Trained batch 74 in epoch 2, gen_loss = 1.5228502257664998, disc_loss = 0.0005510485230479389
Trained batch 75 in epoch 2, gen_loss = 1.5250541661915027, disc_loss = 0.000551528208904385
Trained batch 76 in epoch 2, gen_loss = 1.5242252349853516, disc_loss = 0.0005521818102706321
Trained batch 77 in epoch 2, gen_loss = 1.5235127760813787, disc_loss = 0.0005484112636902585
Trained batch 78 in epoch 2, gen_loss = 1.5209260681007482, disc_loss = 0.0005460087330776114
Trained batch 79 in epoch 2, gen_loss = 1.5223380297422409, disc_loss = 0.0005429962933703791
Trained batch 80 in epoch 2, gen_loss = 1.520318384523745, disc_loss = 0.0005398350742639813
Trained batch 81 in epoch 2, gen_loss = 1.5243999492831346, disc_loss = 0.0005361962379893379
Trained batch 82 in epoch 2, gen_loss = 1.5273962451750973, disc_loss = 0.0005323166404261691
Trained batch 83 in epoch 2, gen_loss = 1.5280094898882366, disc_loss = 0.0005289705292116629
Trained batch 84 in epoch 2, gen_loss = 1.526476946999045, disc_loss = 0.000528057267793509
Trained batch 85 in epoch 2, gen_loss = 1.5276679285736972, disc_loss = 0.000532521367097425
Trained batch 86 in epoch 2, gen_loss = 1.5259414938674576, disc_loss = 0.0005357664639809994
Trained batch 87 in epoch 2, gen_loss = 1.5268210348757831, disc_loss = 0.0005355219086182346
Trained batch 88 in epoch 2, gen_loss = 1.5297025924318293, disc_loss = 0.0005354098082922944
Trained batch 89 in epoch 2, gen_loss = 1.5275273164113363, disc_loss = 0.0005370154934805922
Trained batch 90 in epoch 2, gen_loss = 1.524004346721775, disc_loss = 0.0005353855744393153
Trained batch 91 in epoch 2, gen_loss = 1.5267615629279094, disc_loss = 0.0005330380973527613
Trained batch 92 in epoch 2, gen_loss = 1.52944601351215, disc_loss = 0.0005322014233873537
Trained batch 93 in epoch 2, gen_loss = 1.529240164350956, disc_loss = 0.0005312811300292254
Trained batch 94 in epoch 2, gen_loss = 1.5293879885422557, disc_loss = 0.0005347301095944682
Trained batch 95 in epoch 2, gen_loss = 1.5272933567563693, disc_loss = 0.0005388483583980511
Trained batch 96 in epoch 2, gen_loss = 1.5257890199877553, disc_loss = 0.0005381457338388049
Trained batch 97 in epoch 2, gen_loss = 1.5241415719596707, disc_loss = 0.0005372787602435874
Trained batch 98 in epoch 2, gen_loss = 1.5297428863217133, disc_loss = 0.0005373499306821914
Trained batch 99 in epoch 2, gen_loss = 1.5284701323509216, disc_loss = 0.0005430213396903127
Trained batch 100 in epoch 2, gen_loss = 1.5269795455554924, disc_loss = 0.0005463982441250493
Trained batch 101 in epoch 2, gen_loss = 1.5281472813849355, disc_loss = 0.0005565651945824571
Trained batch 102 in epoch 2, gen_loss = 1.5269889252857096, disc_loss = 0.0005860378439040873
Trained batch 103 in epoch 2, gen_loss = 1.5275013527044883, disc_loss = 0.0006034918557046554
Trained batch 104 in epoch 2, gen_loss = 1.5270933752968199, disc_loss = 0.0006026824237778782
Trained batch 105 in epoch 2, gen_loss = 1.5293188421231396, disc_loss = 0.0006106943540046659
Trained batch 106 in epoch 2, gen_loss = 1.5309664334092186, disc_loss = 0.0006183056176039521
Trained batch 107 in epoch 2, gen_loss = 1.5305669782338318, disc_loss = 0.000615563662129851
Trained batch 108 in epoch 2, gen_loss = 1.531545454209004, disc_loss = 0.0006219357118083147
Trained batch 109 in epoch 2, gen_loss = 1.5286450158465992, disc_loss = 0.0006258504594866695
Trained batch 110 in epoch 2, gen_loss = 1.5318623856381253, disc_loss = 0.0006260569545603987
Trained batch 111 in epoch 2, gen_loss = 1.5312716045549937, disc_loss = 0.0006254834903042397
Trained batch 112 in epoch 2, gen_loss = 1.5327515918596657, disc_loss = 0.0006260639888469328
Trained batch 113 in epoch 2, gen_loss = 1.533169829008872, disc_loss = 0.0006266781412322368
Trained batch 114 in epoch 2, gen_loss = 1.5308640117230623, disc_loss = 0.000625066797795665
Trained batch 115 in epoch 2, gen_loss = 1.5306441794181693, disc_loss = 0.0006233679332894851
Trained batch 116 in epoch 2, gen_loss = 1.5297977445472, disc_loss = 0.0006276623504614441
Trained batch 117 in epoch 2, gen_loss = 1.527903120396501, disc_loss = 0.0006341478613232878
Trained batch 118 in epoch 2, gen_loss = 1.5290691822516818, disc_loss = 0.00063586380198684
Trained batch 119 in epoch 2, gen_loss = 1.5294415712356568, disc_loss = 0.0006345025108506282
Trained batch 120 in epoch 2, gen_loss = 1.5321160613997908, disc_loss = 0.0006319484538745043
Trained batch 121 in epoch 2, gen_loss = 1.5305363897417412, disc_loss = 0.0006292245143711505
Trained batch 122 in epoch 2, gen_loss = 1.5296618570157183, disc_loss = 0.0006263152316659386
Trained batch 123 in epoch 2, gen_loss = 1.5294497186137783, disc_loss = 0.0006244317830292388
Trained batch 124 in epoch 2, gen_loss = 1.5280281887054443, disc_loss = 0.000621809474658221
Trained batch 125 in epoch 2, gen_loss = 1.5282199221944053, disc_loss = 0.0006220209987885836
Trained batch 126 in epoch 2, gen_loss = 1.5276210768016305, disc_loss = 0.0006252092966538539
Trained batch 127 in epoch 2, gen_loss = 1.5262689655646682, disc_loss = 0.0006236625454221212
Trained batch 128 in epoch 2, gen_loss = 1.526139269503512, disc_loss = 0.0006211653499333405
Trained batch 129 in epoch 2, gen_loss = 1.5259617099395164, disc_loss = 0.0006186276958592665
Trained batch 130 in epoch 2, gen_loss = 1.5252614612797744, disc_loss = 0.0006170257026656666
Trained batch 131 in epoch 2, gen_loss = 1.5231426177602825, disc_loss = 0.0006144327013647522
Trained batch 132 in epoch 2, gen_loss = 1.5248042596013922, disc_loss = 0.0006121838013676548
Trained batch 133 in epoch 2, gen_loss = 1.524574326935099, disc_loss = 0.0006096971741662041
Trained batch 134 in epoch 2, gen_loss = 1.5258605515515362, disc_loss = 0.0006074046422899873
Trained batch 135 in epoch 2, gen_loss = 1.5240637870395886, disc_loss = 0.000604559838607469
Trained batch 136 in epoch 2, gen_loss = 1.5241398480686827, disc_loss = 0.0006032468834772951
Trained batch 137 in epoch 2, gen_loss = 1.5245689689249233, disc_loss = 0.0006010365565695489
Trained batch 138 in epoch 2, gen_loss = 1.52220199777068, disc_loss = 0.0005999147329184649
Trained batch 139 in epoch 2, gen_loss = 1.5205171431813922, disc_loss = 0.0005980694965858545
Trained batch 140 in epoch 2, gen_loss = 1.5202265343767531, disc_loss = 0.0006027507764148585
Trained batch 141 in epoch 2, gen_loss = 1.5211718653289366, disc_loss = 0.0006096201848802747
Trained batch 142 in epoch 2, gen_loss = 1.5200432897447707, disc_loss = 0.0006118215640055967
Trained batch 143 in epoch 2, gen_loss = 1.520481136937936, disc_loss = 0.0006095320360246762
Trained batch 144 in epoch 2, gen_loss = 1.5185983189221086, disc_loss = 0.000607602114203097
Trained batch 145 in epoch 2, gen_loss = 1.5197211838748357, disc_loss = 0.000606064124340638
Trained batch 146 in epoch 2, gen_loss = 1.5175045582712914, disc_loss = 0.0006036463434741433
Trained batch 147 in epoch 2, gen_loss = 1.5206568047807023, disc_loss = 0.000602150615737333
Trained batch 148 in epoch 2, gen_loss = 1.5201609902733924, disc_loss = 0.0006046323619404771
Trained batch 149 in epoch 2, gen_loss = 1.5219803301493326, disc_loss = 0.0006122795350772018
Trained batch 150 in epoch 2, gen_loss = 1.5208378074974414, disc_loss = 0.0006158969452564561
Trained batch 151 in epoch 2, gen_loss = 1.5207658166948117, disc_loss = 0.0006162762849845948
Trained batch 152 in epoch 2, gen_loss = 1.521602904874515, disc_loss = 0.0006161262568472915
Trained batch 153 in epoch 2, gen_loss = 1.5228676563733583, disc_loss = 0.0006162685105144712
Trained batch 154 in epoch 2, gen_loss = 1.523808095532079, disc_loss = 0.0006147568371342194
Trained batch 155 in epoch 2, gen_loss = 1.5236981549324133, disc_loss = 0.0006123606543928289
Trained batch 156 in epoch 2, gen_loss = 1.5252418259906162, disc_loss = 0.0006106497696155955
Trained batch 157 in epoch 2, gen_loss = 1.5246609871900534, disc_loss = 0.0006113676343236968
Trained batch 158 in epoch 2, gen_loss = 1.521903169979839, disc_loss = 0.0006209016245286091
Trained batch 159 in epoch 2, gen_loss = 1.522908253967762, disc_loss = 0.0006247660920053022
Trained batch 160 in epoch 2, gen_loss = 1.521319293827744, disc_loss = 0.0006236130874589525
Trained batch 161 in epoch 2, gen_loss = 1.5198589475066573, disc_loss = 0.0006222754110004408
Trained batch 162 in epoch 2, gen_loss = 1.5208021139074688, disc_loss = 0.000623759738436723
Trained batch 163 in epoch 2, gen_loss = 1.5208928039888057, disc_loss = 0.0006223502829770284
Trained batch 164 in epoch 2, gen_loss = 1.519538789806944, disc_loss = 0.0006206948735229107
Trained batch 165 in epoch 2, gen_loss = 1.5177595112697189, disc_loss = 0.0006211675043955602
Trained batch 166 in epoch 2, gen_loss = 1.516926198662398, disc_loss = 0.0006250505658733787
Trained batch 167 in epoch 2, gen_loss = 1.5172906901155199, disc_loss = 0.0006291661527592666
Trained batch 168 in epoch 2, gen_loss = 1.5179313555271667, disc_loss = 0.0006295919816833562
Trained batch 169 in epoch 2, gen_loss = 1.5160709051524892, disc_loss = 0.0006299791263539672
Trained batch 170 in epoch 2, gen_loss = 1.5144900850385252, disc_loss = 0.0006318133317917171
Trained batch 171 in epoch 2, gen_loss = 1.5147296862546789, disc_loss = 0.0006324828091026067
Trained batch 172 in epoch 2, gen_loss = 1.513121050217248, disc_loss = 0.0006315820457446093
Trained batch 173 in epoch 2, gen_loss = 1.5108588954498028, disc_loss = 0.0006313415946058886
Trained batch 174 in epoch 2, gen_loss = 1.5111931834902081, disc_loss = 0.0006295367905737034
Trained batch 175 in epoch 2, gen_loss = 1.5122429383071987, disc_loss = 0.0006273118602951978
Trained batch 176 in epoch 2, gen_loss = 1.5108587829406652, disc_loss = 0.0006254570568368459
Trained batch 177 in epoch 2, gen_loss = 1.5113901274927546, disc_loss = 0.0006230970821899278
Trained batch 178 in epoch 2, gen_loss = 1.511777489544959, disc_loss = 0.0006207884831566041
Trained batch 179 in epoch 2, gen_loss = 1.514201178153356, disc_loss = 0.0006188191796051494
Trained batch 180 in epoch 2, gen_loss = 1.5132931339148, disc_loss = 0.0006175827575385705
Trained batch 181 in epoch 2, gen_loss = 1.5139938114763616, disc_loss = 0.0006158094333291596
Trained batch 182 in epoch 2, gen_loss = 1.5137704317686989, disc_loss = 0.0006139506535799258
Trained batch 183 in epoch 2, gen_loss = 1.5140585828086603, disc_loss = 0.0006142316789286585
Trained batch 184 in epoch 2, gen_loss = 1.515137229094634, disc_loss = 0.0006147469561452651
Trained batch 185 in epoch 2, gen_loss = 1.5161787553500103, disc_loss = 0.0006140136881762745
Trained batch 186 in epoch 2, gen_loss = 1.5163428056686319, disc_loss = 0.0006137251201674671
Trained batch 187 in epoch 2, gen_loss = 1.5152861330103367, disc_loss = 0.0006117321920217054
Trained batch 188 in epoch 2, gen_loss = 1.5137771765391033, disc_loss = 0.0006102811252247424
Trained batch 189 in epoch 2, gen_loss = 1.5139478369763022, disc_loss = 0.000610924869818662
Trained batch 190 in epoch 2, gen_loss = 1.5137695317493058, disc_loss = 0.0006111558703205875
Trained batch 191 in epoch 2, gen_loss = 1.514327732225259, disc_loss = 0.0006119893273535126
Trained batch 192 in epoch 2, gen_loss = 1.5153896055073317, disc_loss = 0.0006135176251089886
Trained batch 193 in epoch 2, gen_loss = 1.514534247290228, disc_loss = 0.0006143105672084313
Trained batch 194 in epoch 2, gen_loss = 1.5145016798606286, disc_loss = 0.0006129724455651087
Trained batch 195 in epoch 2, gen_loss = 1.513673121831855, disc_loss = 0.0006127079928885404
Trained batch 196 in epoch 2, gen_loss = 1.5129143278005766, disc_loss = 0.0006117696776633922
Trained batch 197 in epoch 2, gen_loss = 1.5137771939990496, disc_loss = 0.0006098139377292058
Trained batch 198 in epoch 2, gen_loss = 1.5145604137200206, disc_loss = 0.0006090618550646395
Trained batch 199 in epoch 2, gen_loss = 1.5145475965738298, disc_loss = 0.0006087699730414897
Trained batch 200 in epoch 2, gen_loss = 1.5164872514667795, disc_loss = 0.0006092858323549379
Trained batch 201 in epoch 2, gen_loss = 1.5172915659328499, disc_loss = 0.0006089341169163252
Trained batch 202 in epoch 2, gen_loss = 1.5155703933368176, disc_loss = 0.0006082956694935912
Trained batch 203 in epoch 2, gen_loss = 1.5152296581689049, disc_loss = 0.0006080822796302885
Trained batch 204 in epoch 2, gen_loss = 1.5158801927799133, disc_loss = 0.0006069763488329311
Trained batch 205 in epoch 2, gen_loss = 1.515642604781586, disc_loss = 0.0006056776729715283
Trained batch 206 in epoch 2, gen_loss = 1.5142794346463853, disc_loss = 0.0006046049279421748
Trained batch 207 in epoch 2, gen_loss = 1.5136429925377552, disc_loss = 0.0006046672975711632
Trained batch 208 in epoch 2, gen_loss = 1.5141637456474122, disc_loss = 0.0006031074135622197
Trained batch 209 in epoch 2, gen_loss = 1.514859300000327, disc_loss = 0.0006016784627544915
Trained batch 210 in epoch 2, gen_loss = 1.514966677150455, disc_loss = 0.0005999938929696254
Trained batch 211 in epoch 2, gen_loss = 1.5138687418316894, disc_loss = 0.0005986474340184117
Trained batch 212 in epoch 2, gen_loss = 1.515000773707466, disc_loss = 0.0005979262345127255
Trained batch 213 in epoch 2, gen_loss = 1.5146054748062776, disc_loss = 0.000597814489814244
Trained batch 214 in epoch 2, gen_loss = 1.514573335647583, disc_loss = 0.0005962240404102865
Trained batch 215 in epoch 2, gen_loss = 1.5143786762599591, disc_loss = 0.0005960318920659591
Trained batch 216 in epoch 2, gen_loss = 1.512670917445064, disc_loss = 0.0005951254225705111
Trained batch 217 in epoch 2, gen_loss = 1.5134077498672205, disc_loss = 0.0005935997115565601
Trained batch 218 in epoch 2, gen_loss = 1.5129495510771938, disc_loss = 0.000592277428219265
Trained batch 219 in epoch 2, gen_loss = 1.5122866148298437, disc_loss = 0.000591182563088792
Trained batch 220 in epoch 2, gen_loss = 1.511647019990429, disc_loss = 0.0005914465392828072
Trained batch 221 in epoch 2, gen_loss = 1.5107406796635807, disc_loss = 0.0005901221244654677
Trained batch 222 in epoch 2, gen_loss = 1.5116564591369286, disc_loss = 0.0005884784870366503
Trained batch 223 in epoch 2, gen_loss = 1.512047472276858, disc_loss = 0.0005874337851829685
Trained batch 224 in epoch 2, gen_loss = 1.512365444501241, disc_loss = 0.0005872226529107946
Trained batch 225 in epoch 2, gen_loss = 1.5119599900414458, disc_loss = 0.0005874239405760319
Trained batch 226 in epoch 2, gen_loss = 1.5109759038765525, disc_loss = 0.00058672914702275
Trained batch 227 in epoch 2, gen_loss = 1.509341980281629, disc_loss = 0.0005858077484733433
Trained batch 228 in epoch 2, gen_loss = 1.5099402468277376, disc_loss = 0.0005855793641106425
Trained batch 229 in epoch 2, gen_loss = 1.5091432509214981, disc_loss = 0.0005852826614737633
Trained batch 230 in epoch 2, gen_loss = 1.5094138316777876, disc_loss = 0.0005856024854674379
Trained batch 231 in epoch 2, gen_loss = 1.5110460047064156, disc_loss = 0.000587187017149047
Trained batch 232 in epoch 2, gen_loss = 1.5107795977285492, disc_loss = 0.0005880109228212746
Trained batch 233 in epoch 2, gen_loss = 1.5101522421225524, disc_loss = 0.0005889440683073874
Trained batch 234 in epoch 2, gen_loss = 1.5100573387551814, disc_loss = 0.0005902730279597157
Trained batch 235 in epoch 2, gen_loss = 1.5104110629881842, disc_loss = 0.0005904946500762026
Trained batch 236 in epoch 2, gen_loss = 1.5095146155055565, disc_loss = 0.0005899200197883964
Trained batch 237 in epoch 2, gen_loss = 1.5092418709722888, disc_loss = 0.0005927245591071575
Trained batch 238 in epoch 2, gen_loss = 1.5097286591469992, disc_loss = 0.0005974477487854917
Trained batch 239 in epoch 2, gen_loss = 1.5087764913837114, disc_loss = 0.0005978419021630543
Trained batch 240 in epoch 2, gen_loss = 1.509018172366985, disc_loss = 0.0005968818255662493
Trained batch 241 in epoch 2, gen_loss = 1.5081997651699162, disc_loss = 0.0005992904961737419
Trained batch 242 in epoch 2, gen_loss = 1.508491928685349, disc_loss = 0.0006030069469735831
Trained batch 243 in epoch 2, gen_loss = 1.5088924174426033, disc_loss = 0.0006038636119094426
Trained batch 244 in epoch 2, gen_loss = 1.508870531101616, disc_loss = 0.0006026704909104132
Trained batch 245 in epoch 2, gen_loss = 1.5088307368076914, disc_loss = 0.0006020409565554303
Trained batch 246 in epoch 2, gen_loss = 1.5087261919067938, disc_loss = 0.000600756009155036
Trained batch 247 in epoch 2, gen_loss = 1.5085460538825681, disc_loss = 0.0005995304401303949
Trained batch 248 in epoch 2, gen_loss = 1.50824209245812, disc_loss = 0.0005987347554238737
Trained batch 249 in epoch 2, gen_loss = 1.5090037412643433, disc_loss = 0.0005988691097008995
Trained batch 250 in epoch 2, gen_loss = 1.5087097403537704, disc_loss = 0.0005987186315427702
Trained batch 251 in epoch 2, gen_loss = 1.5073237693499004, disc_loss = 0.0005989387126834434
Trained batch 252 in epoch 2, gen_loss = 1.5064838771292344, disc_loss = 0.0005984600880592803
Trained batch 253 in epoch 2, gen_loss = 1.506182875689559, disc_loss = 0.0005974914827846966
Trained batch 254 in epoch 2, gen_loss = 1.5051890256358127, disc_loss = 0.0005963835235817504
Trained batch 255 in epoch 2, gen_loss = 1.5052763777785003, disc_loss = 0.0005956846034109731
Trained batch 256 in epoch 2, gen_loss = 1.5059236909628841, disc_loss = 0.0005948646958343909
Trained batch 257 in epoch 2, gen_loss = 1.5056278243545413, disc_loss = 0.0005935326270157176
Trained batch 258 in epoch 2, gen_loss = 1.5059538909367152, disc_loss = 0.0005919307613705778
Trained batch 259 in epoch 2, gen_loss = 1.50577600644185, disc_loss = 0.000590638677106024
Trained batch 260 in epoch 2, gen_loss = 1.5047032919880075, disc_loss = 0.0005897921253570223
Trained batch 261 in epoch 2, gen_loss = 1.5036225564607226, disc_loss = 0.0005887486882603777
Trained batch 262 in epoch 2, gen_loss = 1.503450131235014, disc_loss = 0.0005875093382809792
Trained batch 263 in epoch 2, gen_loss = 1.501832295096282, disc_loss = 0.0005868773364592485
Trained batch 264 in epoch 2, gen_loss = 1.5018825301584209, disc_loss = 0.0005888038650945813
Trained batch 265 in epoch 2, gen_loss = 1.502863367249195, disc_loss = 0.0005927048722033465
Trained batch 266 in epoch 2, gen_loss = 1.5027481237154328, disc_loss = 0.0005945337760569144
Trained batch 267 in epoch 2, gen_loss = 1.50152460452336, disc_loss = 0.0005941486525620376
Trained batch 268 in epoch 2, gen_loss = 1.5027584896654889, disc_loss = 0.0005953144723528712
Trained batch 269 in epoch 2, gen_loss = 1.501793215892933, disc_loss = 0.000606713892409095
Trained batch 270 in epoch 2, gen_loss = 1.5014536671093028, disc_loss = 0.0006129079218266525
Trained batch 271 in epoch 2, gen_loss = 1.5019978894030346, disc_loss = 0.0006130797619869769
Trained batch 272 in epoch 2, gen_loss = 1.5028682265962874, disc_loss = 0.0006131047950955211
Trained batch 273 in epoch 2, gen_loss = 1.5031215191757592, disc_loss = 0.0006135770006710324
Trained batch 274 in epoch 2, gen_loss = 1.502178354696794, disc_loss = 0.0006174226181412285
Trained batch 275 in epoch 2, gen_loss = 1.502723083116006, disc_loss = 0.0006213118195655229
Trained batch 276 in epoch 2, gen_loss = 1.5021883038407198, disc_loss = 0.0006223366749624214
Trained batch 277 in epoch 2, gen_loss = 1.5013411611104184, disc_loss = 0.0006233284186250229
Trained batch 278 in epoch 2, gen_loss = 1.5013562885236569, disc_loss = 0.0006255195012957018
Trained batch 279 in epoch 2, gen_loss = 1.5023611988340104, disc_loss = 0.0006296900412832786
Trained batch 280 in epoch 2, gen_loss = 1.5025396610069954, disc_loss = 0.0006346329247075203
Trained batch 281 in epoch 2, gen_loss = 1.5021922119120334, disc_loss = 0.0006355619452669159
Trained batch 282 in epoch 2, gen_loss = 1.501198020924949, disc_loss = 0.0006362023465532823
Trained batch 283 in epoch 2, gen_loss = 1.5000819828308805, disc_loss = 0.0006384692625404978
Trained batch 284 in epoch 2, gen_loss = 1.5011228356445045, disc_loss = 0.000639965405213859
Trained batch 285 in epoch 2, gen_loss = 1.501400190216678, disc_loss = 0.0006404020115277255
Trained batch 286 in epoch 2, gen_loss = 1.5006115964065445, disc_loss = 0.0006402751472648818
Trained batch 287 in epoch 2, gen_loss = 1.5014707400567002, disc_loss = 0.0006400264816572113
Trained batch 288 in epoch 2, gen_loss = 1.5005939415169423, disc_loss = 0.000640103500819794
Trained batch 289 in epoch 2, gen_loss = 1.5019041969858367, disc_loss = 0.0006393717300821224
Trained batch 290 in epoch 2, gen_loss = 1.5019926602897775, disc_loss = 0.000640710334123922
Trained batch 291 in epoch 2, gen_loss = 1.5016014963796693, disc_loss = 0.000641422488564013
Trained batch 292 in epoch 2, gen_loss = 1.5019753459370584, disc_loss = 0.0006406427146119952
Trained batch 293 in epoch 2, gen_loss = 1.5018989906019093, disc_loss = 0.0006396992636534075
Trained batch 294 in epoch 2, gen_loss = 1.5017704248428345, disc_loss = 0.0006405714737503963
Trained batch 295 in epoch 2, gen_loss = 1.5009021658349682, disc_loss = 0.0006445946842054458
Trained batch 296 in epoch 2, gen_loss = 1.500878894770587, disc_loss = 0.0006477676899570608
Trained batch 297 in epoch 2, gen_loss = 1.499984673205638, disc_loss = 0.0006473410502310542
Trained batch 298 in epoch 2, gen_loss = 1.4988572924432149, disc_loss = 0.0006464832795458382
Trained batch 299 in epoch 2, gen_loss = 1.4984548020362853, disc_loss = 0.0006452292072935961
Trained batch 300 in epoch 2, gen_loss = 1.4987829072134835, disc_loss = 0.0006446066085075916
Trained batch 301 in epoch 2, gen_loss = 1.4996645474276007, disc_loss = 0.0006432361030678992
Trained batch 302 in epoch 2, gen_loss = 1.5005654057260394, disc_loss = 0.0006419480007457648
Trained batch 303 in epoch 2, gen_loss = 1.5010697492643406, disc_loss = 0.0006406627394665664
Trained batch 304 in epoch 2, gen_loss = 1.5009714122678413, disc_loss = 0.0006398473360068089
Trained batch 305 in epoch 2, gen_loss = 1.5000054657069686, disc_loss = 0.0006396088532223123
Trained batch 306 in epoch 2, gen_loss = 1.500256077474414, disc_loss = 0.0006394820008256264
Trained batch 307 in epoch 2, gen_loss = 1.500811784685432, disc_loss = 0.0006382350804486052
Trained batch 308 in epoch 2, gen_loss = 1.4998509293621025, disc_loss = 0.0006374497872021525
Trained batch 309 in epoch 2, gen_loss = 1.4999242840274687, disc_loss = 0.0006373233877727011
Trained batch 310 in epoch 2, gen_loss = 1.4993563008845043, disc_loss = 0.0006361813569412241
Trained batch 311 in epoch 2, gen_loss = 1.4988925071098866, disc_loss = 0.0006359719426631599
Trained batch 312 in epoch 2, gen_loss = 1.498812945125202, disc_loss = 0.0006369649066337601
Trained batch 313 in epoch 2, gen_loss = 1.4982466113035846, disc_loss = 0.0006364320671674499
Trained batch 314 in epoch 2, gen_loss = 1.4974423351741972, disc_loss = 0.0006359977351542238
Trained batch 315 in epoch 2, gen_loss = 1.4971516807622547, disc_loss = 0.0006362357625094555
Trained batch 316 in epoch 2, gen_loss = 1.496595371784848, disc_loss = 0.000635186069024718
Trained batch 317 in epoch 2, gen_loss = 1.49720732108602, disc_loss = 0.0006341464379959763
Trained batch 318 in epoch 2, gen_loss = 1.4980719534207287, disc_loss = 0.0006333652178616027
Trained batch 319 in epoch 2, gen_loss = 1.4978531155735255, disc_loss = 0.0006328416887754429
Trained batch 320 in epoch 2, gen_loss = 1.4974032840996145, disc_loss = 0.000633360206530679
Trained batch 321 in epoch 2, gen_loss = 1.4974598880880368, disc_loss = 0.0006340353348656118
Trained batch 322 in epoch 2, gen_loss = 1.4984540060946816, disc_loss = 0.0006343516543772124
Trained batch 323 in epoch 2, gen_loss = 1.497937544628426, disc_loss = 0.0006363327674877422
Trained batch 324 in epoch 2, gen_loss = 1.4982017949911264, disc_loss = 0.0006375374372314231
Trained batch 325 in epoch 2, gen_loss = 1.4988899428420273, disc_loss = 0.0006393055171127991
Trained batch 326 in epoch 2, gen_loss = 1.498604333364271, disc_loss = 0.0006422943695763764
Trained batch 327 in epoch 2, gen_loss = 1.4974971551720688, disc_loss = 0.0006426200848736476
Trained batch 328 in epoch 2, gen_loss = 1.497947949044248, disc_loss = 0.0006446361464875011
Trained batch 329 in epoch 2, gen_loss = 1.4982637611302463, disc_loss = 0.0006460553585026046
Trained batch 330 in epoch 2, gen_loss = 1.4988268051983007, disc_loss = 0.0006468302318020907
Trained batch 331 in epoch 2, gen_loss = 1.4990077905626182, disc_loss = 0.0006489277072093051
Trained batch 332 in epoch 2, gen_loss = 1.498807349362531, disc_loss = 0.0006494280093754349
Trained batch 333 in epoch 2, gen_loss = 1.4996514505968837, disc_loss = 0.0006491846925963113
Trained batch 334 in epoch 2, gen_loss = 1.500013077436988, disc_loss = 0.0006485772965938103
Trained batch 335 in epoch 2, gen_loss = 1.4998517724729719, disc_loss = 0.0006494749442849535
Trained batch 336 in epoch 2, gen_loss = 1.5000446854430065, disc_loss = 0.0006507183824550466
Trained batch 337 in epoch 2, gen_loss = 1.499570518908416, disc_loss = 0.0006508543451000474
Trained batch 338 in epoch 2, gen_loss = 1.500576268255183, disc_loss = 0.0006507653920313036
Trained batch 339 in epoch 2, gen_loss = 1.5008880369803486, disc_loss = 0.00065200343126301
Trained batch 340 in epoch 2, gen_loss = 1.5016924251209607, disc_loss = 0.0006514040449319429
Trained batch 341 in epoch 2, gen_loss = 1.5025273655590259, disc_loss = 0.0006519646895011173
Trained batch 342 in epoch 2, gen_loss = 1.5022121577499212, disc_loss = 0.0006538968430692873
Trained batch 343 in epoch 2, gen_loss = 1.5024455917436024, disc_loss = 0.0006563336248587422
Trained batch 344 in epoch 2, gen_loss = 1.5020133609357087, disc_loss = 0.0006576072409043791
Trained batch 345 in epoch 2, gen_loss = 1.5016644783102708, disc_loss = 0.0006573062749344699
Trained batch 346 in epoch 2, gen_loss = 1.5008929871688315, disc_loss = 0.0006582467430200755
Trained batch 347 in epoch 2, gen_loss = 1.5007918853869384, disc_loss = 0.0006599729653128728
Trained batch 348 in epoch 2, gen_loss = 1.4999817452662996, disc_loss = 0.0006612173318219128
Trained batch 349 in epoch 2, gen_loss = 1.500733104433332, disc_loss = 0.0006602082130016892
Trained batch 350 in epoch 2, gen_loss = 1.50155845530692, disc_loss = 0.0006605875308136522
Trained batch 351 in epoch 2, gen_loss = 1.501701066439802, disc_loss = 0.0006631835588615849
Trained batch 352 in epoch 2, gen_loss = 1.5023885749217134, disc_loss = 0.0006706633549576056
Trained batch 353 in epoch 2, gen_loss = 1.5026419344594923, disc_loss = 0.000678735422909373
Trained batch 354 in epoch 2, gen_loss = 1.501740906272136, disc_loss = 0.0006854897425231249
Trained batch 355 in epoch 2, gen_loss = 1.5010654618231098, disc_loss = 0.0006891454700717383
Trained batch 356 in epoch 2, gen_loss = 1.5006106317210264, disc_loss = 0.0006887307683647028
Trained batch 357 in epoch 2, gen_loss = 1.500306297280935, disc_loss = 0.0006907739534349098
Trained batch 358 in epoch 2, gen_loss = 1.4996522834374049, disc_loss = 0.0006934846961766372
Trained batch 359 in epoch 2, gen_loss = 1.5002595100137923, disc_loss = 0.0006932867908795338
Trained batch 360 in epoch 2, gen_loss = 1.5006612489758435, disc_loss = 0.0006930179193140578
Trained batch 361 in epoch 2, gen_loss = 1.5003567107474607, disc_loss = 0.0006925740844209277
Trained batch 362 in epoch 2, gen_loss = 1.501354526553929, disc_loss = 0.0006922359974620627
Trained batch 363 in epoch 2, gen_loss = 1.5010564546663683, disc_loss = 0.0006923461292539647
Trained batch 364 in epoch 2, gen_loss = 1.500726286679098, disc_loss = 0.0006919031166583172
Trained batch 365 in epoch 2, gen_loss = 1.5012586908262284, disc_loss = 0.0006921241651756735
Trained batch 366 in epoch 2, gen_loss = 1.5003226865539758, disc_loss = 0.0006960462407276861
Trained batch 367 in epoch 2, gen_loss = 1.4995776573600976, disc_loss = 0.000696201585687168
Trained batch 368 in epoch 2, gen_loss = 1.4987749307136224, disc_loss = 0.000697052108430238
Trained batch 369 in epoch 2, gen_loss = 1.4982768274642326, disc_loss = 0.0006996282696884402
Trained batch 370 in epoch 2, gen_loss = 1.4983514688728312, disc_loss = 0.0007005519659375782
Trained batch 371 in epoch 2, gen_loss = 1.4981807742708473, disc_loss = 0.0007001660977880175
Trained batch 372 in epoch 2, gen_loss = 1.4977851128130752, disc_loss = 0.0006996838657367081
Trained batch 373 in epoch 2, gen_loss = 1.4972572578465875, disc_loss = 0.0006992791229245791
Trained batch 374 in epoch 2, gen_loss = 1.4968821007410684, disc_loss = 0.0006991885325793798
Trained batch 375 in epoch 2, gen_loss = 1.4975978462619985, disc_loss = 0.0007011684433274104
Trained batch 376 in epoch 2, gen_loss = 1.4976651633766032, disc_loss = 0.0007038794905895278
Trained batch 377 in epoch 2, gen_loss = 1.4978728168225162, disc_loss = 0.0007043052966341194
Trained batch 378 in epoch 2, gen_loss = 1.4977582038864297, disc_loss = 0.0007034948412903356
Trained batch 379 in epoch 2, gen_loss = 1.4976849813210338, disc_loss = 0.0007028532502054556
Trained batch 380 in epoch 2, gen_loss = 1.4972160253624904, disc_loss = 0.000701706400261813
Trained batch 381 in epoch 2, gen_loss = 1.4962113852276229, disc_loss = 0.0007009804585941882
Trained batch 382 in epoch 2, gen_loss = 1.496730017599798, disc_loss = 0.0007017950921981443
Trained batch 383 in epoch 2, gen_loss = 1.4961949040492375, disc_loss = 0.0007035383343539555
Trained batch 384 in epoch 2, gen_loss = 1.4975643888696448, disc_loss = 0.0007059046048020895
Trained batch 385 in epoch 2, gen_loss = 1.4981688736633934, disc_loss = 0.0007061960050547279
Trained batch 386 in epoch 2, gen_loss = 1.49791156537157, disc_loss = 0.0007055479562308914
Trained batch 387 in epoch 2, gen_loss = 1.4972808569976963, disc_loss = 0.0007045463432414462
Trained batch 388 in epoch 2, gen_loss = 1.4979732281751068, disc_loss = 0.0007034422524718108
Trained batch 389 in epoch 2, gen_loss = 1.4979086282925729, disc_loss = 0.0007027790506701702
Trained batch 390 in epoch 2, gen_loss = 1.4972753918079464, disc_loss = 0.0007037072326875437
Trained batch 391 in epoch 2, gen_loss = 1.496833668375502, disc_loss = 0.0007064492752872364
Trained batch 392 in epoch 2, gen_loss = 1.4959369676410395, disc_loss = 0.000712925975343376
Trained batch 393 in epoch 2, gen_loss = 1.495680749718913, disc_loss = 0.0007176896892792337
Trained batch 394 in epoch 2, gen_loss = 1.4952344254602359, disc_loss = 0.0007191222660240564
Trained batch 395 in epoch 2, gen_loss = 1.4954215601237133, disc_loss = 0.0007197293115946149
Trained batch 396 in epoch 2, gen_loss = 1.494928981555199, disc_loss = 0.0007197194424752846
Trained batch 397 in epoch 2, gen_loss = 1.4949064006158455, disc_loss = 0.0007197412338044059
Trained batch 398 in epoch 2, gen_loss = 1.4945541279656547, disc_loss = 0.0007213372393977481
Trained batch 399 in epoch 2, gen_loss = 1.4941224294900894, disc_loss = 0.0007222890159391682
Trained batch 400 in epoch 2, gen_loss = 1.493725973471739, disc_loss = 0.0007224320464153795
Trained batch 401 in epoch 2, gen_loss = 1.4937395370421718, disc_loss = 0.0007214906594101502
Trained batch 402 in epoch 2, gen_loss = 1.4941007020159927, disc_loss = 0.0007212008492227888
Trained batch 403 in epoch 2, gen_loss = 1.4946130558405772, disc_loss = 0.0007213394521458402
Trained batch 404 in epoch 2, gen_loss = 1.4939000615367184, disc_loss = 0.0007207729959685102
Trained batch 405 in epoch 2, gen_loss = 1.493573306522933, disc_loss = 0.0007197247829080073
Trained batch 406 in epoch 2, gen_loss = 1.4938193729527167, disc_loss = 0.0007186287881263603
Trained batch 407 in epoch 2, gen_loss = 1.4933880269527435, disc_loss = 0.0007175815163802826
Trained batch 408 in epoch 2, gen_loss = 1.4934466421458423, disc_loss = 0.0007166399942181007
Trained batch 409 in epoch 2, gen_loss = 1.4929677509680026, disc_loss = 0.0007164245660533197
Trained batch 410 in epoch 2, gen_loss = 1.4934587876001995, disc_loss = 0.0007186552135847676
Trained batch 411 in epoch 2, gen_loss = 1.4931256177934629, disc_loss = 0.0007192880390011321
Trained batch 412 in epoch 2, gen_loss = 1.4936577817718284, disc_loss = 0.0007203568832469049
Trained batch 413 in epoch 2, gen_loss = 1.4946370884992075, disc_loss = 0.0007245626363069255
Trained batch 414 in epoch 2, gen_loss = 1.4950647230607919, disc_loss = 0.000728700191788207
Trained batch 415 in epoch 2, gen_loss = 1.4947316457445805, disc_loss = 0.0007299156156057926
Trained batch 416 in epoch 2, gen_loss = 1.4945739167485592, disc_loss = 0.0007289647137898644
Trained batch 417 in epoch 2, gen_loss = 1.4943828993436823, disc_loss = 0.0007287500604486392
Trained batch 418 in epoch 2, gen_loss = 1.4948682440778236, disc_loss = 0.0007279241685202647
Trained batch 419 in epoch 2, gen_loss = 1.4952646053972698, disc_loss = 0.0007268182912888559
Trained batch 420 in epoch 2, gen_loss = 1.4947948101863726, disc_loss = 0.0007260130383967446
Trained batch 421 in epoch 2, gen_loss = 1.4942269717912537, disc_loss = 0.0007247847451602762
Trained batch 422 in epoch 2, gen_loss = 1.4940235724685886, disc_loss = 0.0007246753536855546
Trained batch 423 in epoch 2, gen_loss = 1.4948595112787102, disc_loss = 0.0007263819334184518
Trained batch 424 in epoch 2, gen_loss = 1.4948081765455359, disc_loss = 0.0007291148586184992
Trained batch 425 in epoch 2, gen_loss = 1.4945585002921558, disc_loss = 0.0007292436578400114
Trained batch 426 in epoch 2, gen_loss = 1.4944640654869883, disc_loss = 0.0007285762266967494
Trained batch 427 in epoch 2, gen_loss = 1.4940369209953557, disc_loss = 0.0007280171097097941
Trained batch 428 in epoch 2, gen_loss = 1.4946887479239688, disc_loss = 0.0007273722781584271
Trained batch 429 in epoch 2, gen_loss = 1.4949409163275431, disc_loss = 0.0007265068624144268
Trained batch 430 in epoch 2, gen_loss = 1.4943447804506307, disc_loss = 0.0007272208434096894
Trained batch 431 in epoch 2, gen_loss = 1.4949523751382474, disc_loss = 0.0007313961965606992
Trained batch 432 in epoch 2, gen_loss = 1.495274646177578, disc_loss = 0.0007384851740984521
Trained batch 433 in epoch 2, gen_loss = 1.4951452244811343, disc_loss = 0.0007406069561750585
Trained batch 434 in epoch 2, gen_loss = 1.4952976585804731, disc_loss = 0.0007406679652136183
Trained batch 435 in epoch 2, gen_loss = 1.4949408414167003, disc_loss = 0.0007409099736098742
Trained batch 436 in epoch 2, gen_loss = 1.4949339576389478, disc_loss = 0.0007406349881758351
Trained batch 437 in epoch 2, gen_loss = 1.4948251364437957, disc_loss = 0.0007400249203650566
Trained batch 438 in epoch 2, gen_loss = 1.4944953888586823, disc_loss = 0.0007402638521627258
Trained batch 439 in epoch 2, gen_loss = 1.4949907804077323, disc_loss = 0.0007415295203166103
Trained batch 440 in epoch 2, gen_loss = 1.496064758895476, disc_loss = 0.0007416902596298331
Trained batch 441 in epoch 2, gen_loss = 1.497155486458567, disc_loss = 0.000740964121346697
Trained batch 442 in epoch 2, gen_loss = 1.4970520487219163, disc_loss = 0.0007406764056517283
Trained batch 443 in epoch 2, gen_loss = 1.4970177433512233, disc_loss = 0.00073973231039483
Trained batch 444 in epoch 2, gen_loss = 1.4982145577334287, disc_loss = 0.0007391172684559055
Trained batch 445 in epoch 2, gen_loss = 1.4987696454663981, disc_loss = 0.0007390726067377944
Trained batch 446 in epoch 2, gen_loss = 1.4989874213600585, disc_loss = 0.0007395146684385149
Trained batch 447 in epoch 2, gen_loss = 1.4985508788377047, disc_loss = 0.0007397912274232762
Trained batch 448 in epoch 2, gen_loss = 1.4990875097053884, disc_loss = 0.0007392125174583129
Trained batch 449 in epoch 2, gen_loss = 1.4991434632407294, disc_loss = 0.0007395574604096408
Trained batch 450 in epoch 2, gen_loss = 1.4986512129692704, disc_loss = 0.0007427348536859987
Trained batch 451 in epoch 2, gen_loss = 1.4991615351322478, disc_loss = 0.0007439501887427919
Trained batch 452 in epoch 2, gen_loss = 1.4987809500157439, disc_loss = 0.0007437521012725564
Trained batch 453 in epoch 2, gen_loss = 1.499956375701837, disc_loss = 0.0007453448177786598
Trained batch 454 in epoch 2, gen_loss = 1.4993491565788186, disc_loss = 0.000747487515404278
Trained batch 455 in epoch 2, gen_loss = 1.499662804499007, disc_loss = 0.0007505925854945273
Trained batch 456 in epoch 2, gen_loss = 1.4992502977342, disc_loss = 0.0007534244365435342
Trained batch 457 in epoch 2, gen_loss = 1.499030505205346, disc_loss = 0.0007533048450584345
Trained batch 458 in epoch 2, gen_loss = 1.498239748618182, disc_loss = 0.0007525284648484861
Trained batch 459 in epoch 2, gen_loss = 1.4981025734673377, disc_loss = 0.0007521842499757085
Trained batch 460 in epoch 2, gen_loss = 1.497991907622447, disc_loss = 0.0007521167836329292
Trained batch 461 in epoch 2, gen_loss = 1.4980343185461962, disc_loss = 0.0007517394329483209
Trained batch 462 in epoch 2, gen_loss = 1.4979322293922144, disc_loss = 0.0007511837040282862
Trained batch 463 in epoch 2, gen_loss = 1.4976112968448936, disc_loss = 0.000750588532355323
Trained batch 464 in epoch 2, gen_loss = 1.4977236129904306, disc_loss = 0.0007499490945627513
Trained batch 465 in epoch 2, gen_loss = 1.4976007992105935, disc_loss = 0.0007504801978314667
Trained batch 466 in epoch 2, gen_loss = 1.4977594634450222, disc_loss = 0.0007520204737951492
Trained batch 467 in epoch 2, gen_loss = 1.4977453661780071, disc_loss = 0.0007539096893282492
Trained batch 468 in epoch 2, gen_loss = 1.4979756585062185, disc_loss = 0.000755293595723496
Trained batch 469 in epoch 2, gen_loss = 1.4975566191876188, disc_loss = 0.0007562128382058755
Trained batch 470 in epoch 2, gen_loss = 1.497025215195496, disc_loss = 0.0007577335226610046
Trained batch 471 in epoch 2, gen_loss = 1.4969659126916175, disc_loss = 0.0007586491155037084
Trained batch 472 in epoch 2, gen_loss = 1.4974435698910444, disc_loss = 0.0007591549441920806
Trained batch 473 in epoch 2, gen_loss = 1.4973687552198578, disc_loss = 0.0007583156638773343
Trained batch 474 in epoch 2, gen_loss = 1.497684611772236, disc_loss = 0.0007581125059177314
Trained batch 475 in epoch 2, gen_loss = 1.4975234735913638, disc_loss = 0.0007586952935311916
Trained batch 476 in epoch 2, gen_loss = 1.4977974726718926, disc_loss = 0.000757921204993265
Trained batch 477 in epoch 2, gen_loss = 1.4969755545819654, disc_loss = 0.0007572587054706506
Trained batch 478 in epoch 2, gen_loss = 1.497030753930078, disc_loss = 0.000756735840574391
Trained batch 479 in epoch 2, gen_loss = 1.4965347131093343, disc_loss = 0.0007566874301422406
Trained batch 480 in epoch 2, gen_loss = 1.4961853765896105, disc_loss = 0.0007566604874904699
Trained batch 481 in epoch 2, gen_loss = 1.4959828833821402, disc_loss = 0.0007561624902544477
Trained batch 482 in epoch 2, gen_loss = 1.49530908089, disc_loss = 0.000755693773286153
Trained batch 483 in epoch 2, gen_loss = 1.4955721532017732, disc_loss = 0.000755461768232996
Trained batch 484 in epoch 2, gen_loss = 1.4951065714826288, disc_loss = 0.0007556699828746412
Trained batch 485 in epoch 2, gen_loss = 1.4950550301575367, disc_loss = 0.0007556805216408825
Trained batch 486 in epoch 2, gen_loss = 1.4952845686025442, disc_loss = 0.0007568045007554983
Trained batch 487 in epoch 2, gen_loss = 1.494337112444346, disc_loss = 0.0007602849011283204
Trained batch 488 in epoch 2, gen_loss = 1.4944800016582622, disc_loss = 0.0007643169775647578
Trained batch 489 in epoch 2, gen_loss = 1.4942713350665813, disc_loss = 0.0007655979992111442
Trained batch 490 in epoch 2, gen_loss = 1.4944596623209003, disc_loss = 0.0007655085742868608
Trained batch 491 in epoch 2, gen_loss = 1.4949729294796301, disc_loss = 0.0007659995723319357
Trained batch 492 in epoch 2, gen_loss = 1.4948166778073109, disc_loss = 0.0007662687227321206
Trained batch 493 in epoch 2, gen_loss = 1.4947419919465716, disc_loss = 0.0007666595998516605
Trained batch 494 in epoch 2, gen_loss = 1.4946410198404332, disc_loss = 0.0007663734190488196
Trained batch 495 in epoch 2, gen_loss = 1.494042502776269, disc_loss = 0.0007672880140695094
Trained batch 496 in epoch 2, gen_loss = 1.4937834967549897, disc_loss = 0.0007682633271473188
Trained batch 497 in epoch 2, gen_loss = 1.4937182025737072, disc_loss = 0.0007699279447544804
Trained batch 498 in epoch 2, gen_loss = 1.4938979597989925, disc_loss = 0.0007706155119156315
Trained batch 499 in epoch 2, gen_loss = 1.4941109507083892, disc_loss = 0.00077013740412076
Trained batch 500 in epoch 2, gen_loss = 1.4948062220971265, disc_loss = 0.0007696551485547142
Trained batch 501 in epoch 2, gen_loss = 1.4942151953974567, disc_loss = 0.0007691635458094283
Trained batch 502 in epoch 2, gen_loss = 1.4940539411237652, disc_loss = 0.0007687194761970574
Trained batch 503 in epoch 2, gen_loss = 1.4941395530624995, disc_loss = 0.0007683740439836309
Trained batch 504 in epoch 2, gen_loss = 1.4939831186049055, disc_loss = 0.0007688061576532569
Trained batch 505 in epoch 2, gen_loss = 1.4932893307312676, disc_loss = 0.0007696075817552145
Trained batch 506 in epoch 2, gen_loss = 1.4925745629229725, disc_loss = 0.0007689636806221275
Trained batch 507 in epoch 2, gen_loss = 1.492027371417819, disc_loss = 0.0007679171001826922
Trained batch 508 in epoch 2, gen_loss = 1.4918377596175039, disc_loss = 0.000767370504479213
Trained batch 509 in epoch 2, gen_loss = 1.4916055083274842, disc_loss = 0.0007676571771084769
Trained batch 510 in epoch 2, gen_loss = 1.4910822301928077, disc_loss = 0.0007688061945259283
Trained batch 511 in epoch 2, gen_loss = 1.4914262786041945, disc_loss = 0.0007690480082658269
Trained batch 512 in epoch 2, gen_loss = 1.4912699563229062, disc_loss = 0.0007680885928724284
Trained batch 513 in epoch 2, gen_loss = 1.4904806741480698, disc_loss = 0.0007675774784743739
Trained batch 514 in epoch 2, gen_loss = 1.4896568298339843, disc_loss = 0.0007667732759869377
Trained batch 515 in epoch 2, gen_loss = 1.490388545879098, disc_loss = 0.0007661047049849059
Trained batch 516 in epoch 2, gen_loss = 1.490140616086742, disc_loss = 0.0007652544406748411
Trained batch 517 in epoch 2, gen_loss = 1.4903204795476552, disc_loss = 0.0007651786087698871
Trained batch 518 in epoch 2, gen_loss = 1.490160358664158, disc_loss = 0.0007654202406136284
Trained batch 519 in epoch 2, gen_loss = 1.490394552395894, disc_loss = 0.0007659371502086287
Trained batch 520 in epoch 2, gen_loss = 1.4911728342297896, disc_loss = 0.0007652651664996233
Trained batch 521 in epoch 2, gen_loss = 1.4912382923780274, disc_loss = 0.000765250910813269
Trained batch 522 in epoch 2, gen_loss = 1.4913490741704207, disc_loss = 0.0007660463989062776
Trained batch 523 in epoch 2, gen_loss = 1.4920142691099008, disc_loss = 0.000766176838172957
Trained batch 524 in epoch 2, gen_loss = 1.4916869601749239, disc_loss = 0.0007653460073717205
Trained batch 525 in epoch 2, gen_loss = 1.4916101431212045, disc_loss = 0.0007647061150309899
Trained batch 526 in epoch 2, gen_loss = 1.491280362321032, disc_loss = 0.0007644787677234583
Trained batch 527 in epoch 2, gen_loss = 1.4913849611625527, disc_loss = 0.0007636862282831289
Trained batch 528 in epoch 2, gen_loss = 1.4918679095846945, disc_loss = 0.0007631848013591433
Trained batch 529 in epoch 2, gen_loss = 1.491760930250276, disc_loss = 0.0007623941856952613
Trained batch 530 in epoch 2, gen_loss = 1.4912987538874711, disc_loss = 0.0007618475583872605
Trained batch 531 in epoch 2, gen_loss = 1.4912002102324837, disc_loss = 0.0007615701464314235
Trained batch 532 in epoch 2, gen_loss = 1.4908644900313015, disc_loss = 0.0007614030704060814
Trained batch 533 in epoch 2, gen_loss = 1.4913856483130865, disc_loss = 0.0007612543645319668
Trained batch 534 in epoch 2, gen_loss = 1.491168699977554, disc_loss = 0.0007609977631418417
Trained batch 535 in epoch 2, gen_loss = 1.4906230301999335, disc_loss = 0.0007602793480078046
Trained batch 536 in epoch 2, gen_loss = 1.4907249485314225, disc_loss = 0.000759928306304326
Trained batch 537 in epoch 2, gen_loss = 1.4907085244097231, disc_loss = 0.0007600348267683042
Trained batch 538 in epoch 2, gen_loss = 1.4904905221457827, disc_loss = 0.0007604825206898785
Trained batch 539 in epoch 2, gen_loss = 1.4901768580630974, disc_loss = 0.000761047131743032
Trained batch 540 in epoch 2, gen_loss = 1.491097203244123, disc_loss = 0.0007614411076420209
Trained batch 541 in epoch 2, gen_loss = 1.491016860597688, disc_loss = 0.000761164508314719
Trained batch 542 in epoch 2, gen_loss = 1.490995483723354, disc_loss = 0.0007606931310264963
Trained batch 543 in epoch 2, gen_loss = 1.490727038725334, disc_loss = 0.0007597678823806157
Trained batch 544 in epoch 2, gen_loss = 1.4903215668617038, disc_loss = 0.0007596071896307735
Trained batch 545 in epoch 2, gen_loss = 1.490066035544916, disc_loss = 0.0007605688138611208
Trained batch 546 in epoch 2, gen_loss = 1.4901149320863936, disc_loss = 0.0007597298016956831
Trained batch 547 in epoch 2, gen_loss = 1.4907770043742048, disc_loss = 0.0007589526245734624
Trained batch 548 in epoch 2, gen_loss = 1.490330773841705, disc_loss = 0.0007583176011195447
Trained batch 549 in epoch 2, gen_loss = 1.491081568111073, disc_loss = 0.0007580306883425113
Trained batch 550 in epoch 2, gen_loss = 1.491093259108694, disc_loss = 0.0007578918435211512
Trained batch 551 in epoch 2, gen_loss = 1.4913864461840063, disc_loss = 0.0007570488998180076
Trained batch 552 in epoch 2, gen_loss = 1.4918327430704403, disc_loss = 0.0007565361085281729
Trained batch 553 in epoch 2, gen_loss = 1.491551988822028, disc_loss = 0.0007564731335781417
Trained batch 554 in epoch 2, gen_loss = 1.4922980276313988, disc_loss = 0.000755688202801278
Trained batch 555 in epoch 2, gen_loss = 1.491930487558996, disc_loss = 0.0007548437514997727
Trained batch 556 in epoch 2, gen_loss = 1.491256411456548, disc_loss = 0.0007547811561197634
Trained batch 557 in epoch 2, gen_loss = 1.4910313764780654, disc_loss = 0.0007546470589665813
Trained batch 558 in epoch 2, gen_loss = 1.4906770095415747, disc_loss = 0.0007542403744567396
Trained batch 559 in epoch 2, gen_loss = 1.491678057398115, disc_loss = 0.0007546990197494908
Trained batch 560 in epoch 2, gen_loss = 1.4919525886389449, disc_loss = 0.0007561992017028076
Trained batch 561 in epoch 2, gen_loss = 1.4916935531270037, disc_loss = 0.0007583410663746076
Trained batch 562 in epoch 2, gen_loss = 1.4914030994869252, disc_loss = 0.000760414766059439
Trained batch 563 in epoch 2, gen_loss = 1.4919719112680314, disc_loss = 0.0007614557493689836
Trained batch 564 in epoch 2, gen_loss = 1.4917874395319846, disc_loss = 0.0007608270385679665
Trained batch 565 in epoch 2, gen_loss = 1.4919591063745452, disc_loss = 0.0007602941313383742
Trained batch 566 in epoch 2, gen_loss = 1.49169408980711, disc_loss = 0.0007603831554163902
Trained batch 567 in epoch 2, gen_loss = 1.4917766479119448, disc_loss = 0.0007605570898332689
Trained batch 568 in epoch 2, gen_loss = 1.4915659081956834, disc_loss = 0.0007604982903456767
Trained batch 569 in epoch 2, gen_loss = 1.4915330893114993, disc_loss = 0.0007605830324137698
Trained batch 570 in epoch 2, gen_loss = 1.4912188547922727, disc_loss = 0.0007601508140270786
Trained batch 571 in epoch 2, gen_loss = 1.4911916433097598, disc_loss = 0.0007594285998747837
Trained batch 572 in epoch 2, gen_loss = 1.4915896697818296, disc_loss = 0.0007584785298366314
Trained batch 573 in epoch 2, gen_loss = 1.4914451160497366, disc_loss = 0.0007575782543135067
Trained batch 574 in epoch 2, gen_loss = 1.4911782129951145, disc_loss = 0.0007567869248779733
Trained batch 575 in epoch 2, gen_loss = 1.490890119017826, disc_loss = 0.000756640882223615
Trained batch 576 in epoch 2, gen_loss = 1.4913757217198973, disc_loss = 0.0007567082431778293
Trained batch 577 in epoch 2, gen_loss = 1.4913035831236923, disc_loss = 0.0007564899046678953
Trained batch 578 in epoch 2, gen_loss = 1.4909554938166458, disc_loss = 0.0007565499513891779
Trained batch 579 in epoch 2, gen_loss = 1.4908134824243084, disc_loss = 0.0007559250311119129
Trained batch 580 in epoch 2, gen_loss = 1.4908131012202541, disc_loss = 0.0007554695717794035
Trained batch 581 in epoch 2, gen_loss = 1.4908934878729463, disc_loss = 0.0007548132763605059
Trained batch 582 in epoch 2, gen_loss = 1.4912067893029894, disc_loss = 0.0007542330695006288
Trained batch 583 in epoch 2, gen_loss = 1.4908199175579908, disc_loss = 0.0007540753634713513
Trained batch 584 in epoch 2, gen_loss = 1.491123274452666, disc_loss = 0.0007541693733113572
Trained batch 585 in epoch 2, gen_loss = 1.4910002084315432, disc_loss = 0.0007541768867506585
Trained batch 586 in epoch 2, gen_loss = 1.490909816459253, disc_loss = 0.0007532553126695573
Trained batch 587 in epoch 2, gen_loss = 1.4903527437424173, disc_loss = 0.0007523708749072686
Trained batch 588 in epoch 2, gen_loss = 1.490270979942814, disc_loss = 0.0007515136739375475
Trained batch 589 in epoch 2, gen_loss = 1.4904236155041193, disc_loss = 0.0007508737992315743
Trained batch 590 in epoch 2, gen_loss = 1.490523772392983, disc_loss = 0.000750258020618765
Trained batch 591 in epoch 2, gen_loss = 1.4903474089664381, disc_loss = 0.0007496434007997457
Trained batch 592 in epoch 2, gen_loss = 1.4903690843115769, disc_loss = 0.0007487510174756688
Trained batch 593 in epoch 2, gen_loss = 1.4903420053347192, disc_loss = 0.0007478498843404847
Trained batch 594 in epoch 2, gen_loss = 1.4906280641796208, disc_loss = 0.0007470917240608906
Trained batch 595 in epoch 2, gen_loss = 1.491358332385953, disc_loss = 0.0007468858632837631
Trained batch 596 in epoch 2, gen_loss = 1.4910635025657002, disc_loss = 0.0007475407712851453
Trained batch 597 in epoch 2, gen_loss = 1.49124462468967, disc_loss = 0.0007478955887691398
Trained batch 598 in epoch 2, gen_loss = 1.4910110284967693, disc_loss = 0.0007473544406116503
Trained batch 599 in epoch 2, gen_loss = 1.4910776994625727, disc_loss = 0.0007466535691492027
Trained batch 600 in epoch 2, gen_loss = 1.4911395644586216, disc_loss = 0.0007461781607766073
Trained batch 601 in epoch 2, gen_loss = 1.4910863869610023, disc_loss = 0.0007460854279290826
Trained batch 602 in epoch 2, gen_loss = 1.4909173430099614, disc_loss = 0.0007455220881968838
Trained batch 603 in epoch 2, gen_loss = 1.4911773350854582, disc_loss = 0.0007450891483896211
Trained batch 604 in epoch 2, gen_loss = 1.4913549947344567, disc_loss = 0.0007445231202002692
Trained batch 605 in epoch 2, gen_loss = 1.4918447174254816, disc_loss = 0.0007438823172663916
Trained batch 606 in epoch 2, gen_loss = 1.4915338564154736, disc_loss = 0.0007432439576946061
Trained batch 607 in epoch 2, gen_loss = 1.4912845692352246, disc_loss = 0.0007426042104127287
Trained batch 608 in epoch 2, gen_loss = 1.4913290429780832, disc_loss = 0.0007422707258975623
Trained batch 609 in epoch 2, gen_loss = 1.4912761596382642, disc_loss = 0.0007419779097812143
Trained batch 610 in epoch 2, gen_loss = 1.4908103960430563, disc_loss = 0.0007418004406794049
Trained batch 611 in epoch 2, gen_loss = 1.4910309918565687, disc_loss = 0.0007419178673563437
Trained batch 612 in epoch 2, gen_loss = 1.4905200235995344, disc_loss = 0.0007417111411008173
Trained batch 613 in epoch 2, gen_loss = 1.489875034128804, disc_loss = 0.0007416664633673543
Trained batch 614 in epoch 2, gen_loss = 1.4891360025095746, disc_loss = 0.0007425675190165564
Trained batch 615 in epoch 2, gen_loss = 1.4893568969005113, disc_loss = 0.0007436774377346375
Trained batch 616 in epoch 2, gen_loss = 1.4892375115637262, disc_loss = 0.0007437213298868814
Trained batch 617 in epoch 2, gen_loss = 1.4892758808089692, disc_loss = 0.0007433738304190202
Trained batch 618 in epoch 2, gen_loss = 1.489389876364121, disc_loss = 0.000742932647177596
Trained batch 619 in epoch 2, gen_loss = 1.4899161604142959, disc_loss = 0.000742372259663816
Trained batch 620 in epoch 2, gen_loss = 1.4899267898857498, disc_loss = 0.0007415100247970364
Trained batch 621 in epoch 2, gen_loss = 1.4893668121463617, disc_loss = 0.0007411075029855331
Trained batch 622 in epoch 2, gen_loss = 1.489230642157994, disc_loss = 0.0007426288765298284
Trained batch 623 in epoch 2, gen_loss = 1.4892344896992047, disc_loss = 0.0007423374642642627
Trained batch 624 in epoch 2, gen_loss = 1.4893398862838745, disc_loss = 0.0007415769066195935
Trained batch 625 in epoch 2, gen_loss = 1.489228713817109, disc_loss = 0.0007409037085444913
Trained batch 626 in epoch 2, gen_loss = 1.4893544800163647, disc_loss = 0.0007403970826372647
Trained batch 627 in epoch 2, gen_loss = 1.4894169563320792, disc_loss = 0.0007398694376038554
Trained batch 628 in epoch 2, gen_loss = 1.489252923402953, disc_loss = 0.0007400231225644083
Trained batch 629 in epoch 2, gen_loss = 1.4892453116083901, disc_loss = 0.0007396311393850261
Trained batch 630 in epoch 2, gen_loss = 1.489341629477197, disc_loss = 0.0007390386279485677
Trained batch 631 in epoch 2, gen_loss = 1.489477449014217, disc_loss = 0.0007382701400205451
Trained batch 632 in epoch 2, gen_loss = 1.4899486578282963, disc_loss = 0.0007375668101935937
Trained batch 633 in epoch 2, gen_loss = 1.4899742417155004, disc_loss = 0.0007375175862228615
Trained batch 634 in epoch 2, gen_loss = 1.4896497033712433, disc_loss = 0.0007389657180591333
Trained batch 635 in epoch 2, gen_loss = 1.4896579562867962, disc_loss = 0.0007411923885778173
Trained batch 636 in epoch 2, gen_loss = 1.489539147733332, disc_loss = 0.0007430992536140779
Trained batch 637 in epoch 2, gen_loss = 1.4893774251952814, disc_loss = 0.000743338074449371
Trained batch 638 in epoch 2, gen_loss = 1.489767637797551, disc_loss = 0.0007431642480754965
Trained batch 639 in epoch 2, gen_loss = 1.489682844467461, disc_loss = 0.0007433208531892888
Trained batch 640 in epoch 2, gen_loss = 1.489543541359269, disc_loss = 0.0007430605211948276
Trained batch 641 in epoch 2, gen_loss = 1.4889639927962115, disc_loss = 0.0007437344762802014
Trained batch 642 in epoch 2, gen_loss = 1.4893080581958706, disc_loss = 0.000744739432993358
Trained batch 643 in epoch 2, gen_loss = 1.4890401607714825, disc_loss = 0.0007453853033879997
Trained batch 644 in epoch 2, gen_loss = 1.4889870264733485, disc_loss = 0.0007449865314113192
Trained batch 645 in epoch 2, gen_loss = 1.4887379383893204, disc_loss = 0.0007445152029726689
Trained batch 646 in epoch 2, gen_loss = 1.4884777417322952, disc_loss = 0.0007447919530694702
Trained batch 647 in epoch 2, gen_loss = 1.4879186118458525, disc_loss = 0.0007448869865685184
Trained batch 648 in epoch 2, gen_loss = 1.4885570903772198, disc_loss = 0.0007446870929418055
Trained batch 649 in epoch 2, gen_loss = 1.4887651975338276, disc_loss = 0.0007440929302426341
Trained batch 650 in epoch 2, gen_loss = 1.4882523303024597, disc_loss = 0.0007434335067212301
Trained batch 651 in epoch 2, gen_loss = 1.48789096280841, disc_loss = 0.0007429926343632868
Trained batch 652 in epoch 2, gen_loss = 1.4872779316778022, disc_loss = 0.0007432750238595562
Trained batch 653 in epoch 2, gen_loss = 1.4868613891645308, disc_loss = 0.0007430232558182273
Trained batch 654 in epoch 2, gen_loss = 1.4867823642628792, disc_loss = 0.000742788826433572
Trained batch 655 in epoch 2, gen_loss = 1.4870418088465203, disc_loss = 0.0007424415357601857
Trained batch 656 in epoch 2, gen_loss = 1.487300277844956, disc_loss = 0.0007417866174940337
Trained batch 657 in epoch 2, gen_loss = 1.4876080798523041, disc_loss = 0.0007411492634621254
Trained batch 658 in epoch 2, gen_loss = 1.4874096054227652, disc_loss = 0.0007405487513303903
Trained batch 659 in epoch 2, gen_loss = 1.4875726864193426, disc_loss = 0.0007398322601202932
Trained batch 660 in epoch 2, gen_loss = 1.4869537261538714, disc_loss = 0.0007392207945030572
Trained batch 661 in epoch 2, gen_loss = 1.4866136587998657, disc_loss = 0.0007387889948148798
Trained batch 662 in epoch 2, gen_loss = 1.4871690057521492, disc_loss = 0.0007382926831304954
Trained batch 663 in epoch 2, gen_loss = 1.4872854341225452, disc_loss = 0.0007375136201407729
Trained batch 664 in epoch 2, gen_loss = 1.4878084397853766, disc_loss = 0.0007367639278965001
Trained batch 665 in epoch 2, gen_loss = 1.487916891460304, disc_loss = 0.0007359234422309654
Trained batch 666 in epoch 2, gen_loss = 1.4876189190765907, disc_loss = 0.0007351701684289848
Trained batch 667 in epoch 2, gen_loss = 1.4873761875543765, disc_loss = 0.0007345034465250213
Trained batch 668 in epoch 2, gen_loss = 1.487270877500286, disc_loss = 0.0007340037501023829
Trained batch 669 in epoch 2, gen_loss = 1.4872158258708554, disc_loss = 0.0007334972550195934
Trained batch 670 in epoch 2, gen_loss = 1.487299800629765, disc_loss = 0.0007330265809867209
Trained batch 671 in epoch 2, gen_loss = 1.487576361745596, disc_loss = 0.0007326107105698265
Trained batch 672 in epoch 2, gen_loss = 1.4878106599045366, disc_loss = 0.0007329103736262935
Trained batch 673 in epoch 2, gen_loss = 1.48784568454816, disc_loss = 0.0007338807904745317
Trained batch 674 in epoch 2, gen_loss = 1.4877490296187224, disc_loss = 0.000735091555527308
Trained batch 675 in epoch 2, gen_loss = 1.487546862053448, disc_loss = 0.0007361966334149026
Trained batch 676 in epoch 2, gen_loss = 1.4871782360260033, disc_loss = 0.000736958314116117
Trained batch 677 in epoch 2, gen_loss = 1.4875146212127708, disc_loss = 0.000736620542491995
Trained batch 678 in epoch 2, gen_loss = 1.4880039756884456, disc_loss = 0.0007358993511970685
Trained batch 679 in epoch 2, gen_loss = 1.487763360843939, disc_loss = 0.0007354742688595947
Trained batch 680 in epoch 2, gen_loss = 1.4878583495312325, disc_loss = 0.0007354166492817734
Trained batch 681 in epoch 2, gen_loss = 1.4876146445875644, disc_loss = 0.0007360385496751747
Trained batch 682 in epoch 2, gen_loss = 1.4879002248211102, disc_loss = 0.0007360558537987919
Trained batch 683 in epoch 2, gen_loss = 1.487827333790517, disc_loss = 0.0007364873394212816
Trained batch 684 in epoch 2, gen_loss = 1.4878297624796846, disc_loss = 0.0007374523637942072
Trained batch 685 in epoch 2, gen_loss = 1.4883573722561316, disc_loss = 0.0007381989078344397
Trained batch 686 in epoch 2, gen_loss = 1.4879637574871902, disc_loss = 0.000739044903682984
Trained batch 687 in epoch 2, gen_loss = 1.4872338475529538, disc_loss = 0.0007514438360843531
Trained batch 688 in epoch 2, gen_loss = 1.4867910115570047, disc_loss = 0.0007692823201807889
Trained batch 689 in epoch 2, gen_loss = 1.486108073808145, disc_loss = 0.0011375315710514162
Trained batch 690 in epoch 2, gen_loss = 1.487217667306384, disc_loss = 0.0014807118376930597
Trained batch 691 in epoch 2, gen_loss = 1.4878903839284974, disc_loss = 0.001771001210559033
Trained batch 692 in epoch 2, gen_loss = 1.4880506357589325, disc_loss = 0.002161462124059794
Trained batch 693 in epoch 2, gen_loss = 1.4878770463404807, disc_loss = 0.002724669391320554
Trained batch 694 in epoch 2, gen_loss = 1.4877704405956131, disc_loss = 0.0031326220733056635
Trained batch 695 in epoch 2, gen_loss = 1.4878028930946328, disc_loss = 0.003285234420061521
Trained batch 696 in epoch 2, gen_loss = 1.4873619000915133, disc_loss = 0.0033777617940687877
Trained batch 697 in epoch 2, gen_loss = 1.4872080559033718, disc_loss = 0.0034665387120237307
Trained batch 698 in epoch 2, gen_loss = 1.486994370711549, disc_loss = 0.0034891203404667365
Trained batch 699 in epoch 2, gen_loss = 1.48700960959707, disc_loss = 0.0035123504332815565
Trained batch 700 in epoch 2, gen_loss = 1.4866226673466332, disc_loss = 0.003527643359022098
Trained batch 701 in epoch 2, gen_loss = 1.4865091850614955, disc_loss = 0.0035444914325265787
Trained batch 702 in epoch 2, gen_loss = 1.4863144033833553, disc_loss = 0.003551512104162687
Trained batch 703 in epoch 2, gen_loss = 1.4861180467361754, disc_loss = 0.0035600407765162922
Trained batch 704 in epoch 2, gen_loss = 1.485892362121149, disc_loss = 0.003574306906922555
Trained batch 705 in epoch 2, gen_loss = 1.4864446154397202, disc_loss = 0.003610420970171334
Trained batch 706 in epoch 2, gen_loss = 1.4861867876336126, disc_loss = 0.0036617186812692502
Trained batch 707 in epoch 2, gen_loss = 1.4859506902048143, disc_loss = 0.003678502949748233
Trained batch 708 in epoch 2, gen_loss = 1.4855687487108582, disc_loss = 0.0036897505752164976
Trained batch 709 in epoch 2, gen_loss = 1.485766599883496, disc_loss = 0.0037036689634936614
Trained batch 710 in epoch 2, gen_loss = 1.4854668585056996, disc_loss = 0.003714371602970821
Trained batch 711 in epoch 2, gen_loss = 1.4854408825716277, disc_loss = 0.003716458103482499
Trained batch 712 in epoch 2, gen_loss = 1.4853647052823744, disc_loss = 0.0037210802476200684
Trained batch 713 in epoch 2, gen_loss = 1.4856147452228878, disc_loss = 0.0037233016926274147
Trained batch 714 in epoch 2, gen_loss = 1.486380953888793, disc_loss = 0.0037268776707497743
Trained batch 715 in epoch 2, gen_loss = 1.48619286674361, disc_loss = 0.0037493495604003176
Trained batch 716 in epoch 2, gen_loss = 1.4863180432525804, disc_loss = 0.0037671698457766014
Trained batch 717 in epoch 2, gen_loss = 1.4862669191652687, disc_loss = 0.00377130149322929
Trained batch 718 in epoch 2, gen_loss = 1.4861553075084766, disc_loss = 0.0037824083372619602
Trained batch 719 in epoch 2, gen_loss = 1.486438275873661, disc_loss = 0.0038019576517803622
Trained batch 720 in epoch 2, gen_loss = 1.4862696980636427, disc_loss = 0.0038139637625933176
Trained batch 721 in epoch 2, gen_loss = 1.486292369312857, disc_loss = 0.003822448616371738
Trained batch 722 in epoch 2, gen_loss = 1.4863280460217847, disc_loss = 0.0038255466558287155
Trained batch 723 in epoch 2, gen_loss = 1.4860414750668225, disc_loss = 0.003841054205210604
Trained batch 724 in epoch 2, gen_loss = 1.4860353997658038, disc_loss = 0.003842015570262447
Trained batch 725 in epoch 2, gen_loss = 1.4863934232840526, disc_loss = 0.003843356300436907
Trained batch 726 in epoch 2, gen_loss = 1.4865117150126985, disc_loss = 0.0038499783659613263
Trained batch 727 in epoch 2, gen_loss = 1.486586250610404, disc_loss = 0.003851924252168309
Trained batch 728 in epoch 2, gen_loss = 1.4865431911497287, disc_loss = 0.003854366780818595
Trained batch 729 in epoch 2, gen_loss = 1.4869698638785376, disc_loss = 0.003857417594145486
Trained batch 730 in epoch 2, gen_loss = 1.48693810050693, disc_loss = 0.0038562045743890877
Trained batch 731 in epoch 2, gen_loss = 1.487280439809372, disc_loss = 0.003862320180243464
Trained batch 732 in epoch 2, gen_loss = 1.487118263361724, disc_loss = 0.0038619453111986817
Trained batch 733 in epoch 2, gen_loss = 1.4866702809970451, disc_loss = 0.0038620191594926456
Trained batch 734 in epoch 2, gen_loss = 1.4863729324470571, disc_loss = 0.003865063557326857
Trained batch 735 in epoch 2, gen_loss = 1.486176826869664, disc_loss = 0.003866365345857048
Trained batch 736 in epoch 2, gen_loss = 1.4860847803436756, disc_loss = 0.0038656769428175356
Trained batch 737 in epoch 2, gen_loss = 1.485823204685356, disc_loss = 0.003863657271367407
Trained batch 738 in epoch 2, gen_loss = 1.4854912865952323, disc_loss = 0.003860243405721116
Trained batch 739 in epoch 2, gen_loss = 1.4854680062951269, disc_loss = 0.0038587217806363354
Trained batch 740 in epoch 2, gen_loss = 1.4855246582494575, disc_loss = 0.0038632068316205234
Trained batch 741 in epoch 2, gen_loss = 1.4858580403572144, disc_loss = 0.0038623875749534036
Trained batch 742 in epoch 2, gen_loss = 1.4855649904479569, disc_loss = 0.0038612089855085637
Trained batch 743 in epoch 2, gen_loss = 1.4858874316497515, disc_loss = 0.0038669704378946177
Trained batch 744 in epoch 2, gen_loss = 1.4859168692723217, disc_loss = 0.003869376909308098
Trained batch 745 in epoch 2, gen_loss = 1.4858266035289611, disc_loss = 0.003868574588242781
Trained batch 746 in epoch 2, gen_loss = 1.485886677042388, disc_loss = 0.003865633967341581
Trained batch 747 in epoch 2, gen_loss = 1.485976954354322, disc_loss = 0.00386244118657059
Trained batch 748 in epoch 2, gen_loss = 1.4859940634868811, disc_loss = 0.003858790552662934
Trained batch 749 in epoch 2, gen_loss = 1.4859488355318706, disc_loss = 0.003856693958281539
Trained batch 750 in epoch 2, gen_loss = 1.4863754548975694, disc_loss = 0.003853485560717096
Trained batch 751 in epoch 2, gen_loss = 1.486093542835814, disc_loss = 0.0038586882250881975
Trained batch 752 in epoch 2, gen_loss = 1.48627230940587, disc_loss = 0.003860166743665174
Trained batch 753 in epoch 2, gen_loss = 1.486435054151702, disc_loss = 0.0038605175225082068
Trained batch 754 in epoch 2, gen_loss = 1.4862756760704596, disc_loss = 0.0038842921091678446
Trained batch 755 in epoch 2, gen_loss = 1.4866405681327537, disc_loss = 0.00389161479934864
Trained batch 756 in epoch 2, gen_loss = 1.4862950641853807, disc_loss = 0.003889388721160987
Trained batch 757 in epoch 2, gen_loss = 1.4865423264792852, disc_loss = 0.003892807437588908
Trained batch 758 in epoch 2, gen_loss = 1.4864609373416826, disc_loss = 0.003891061659424096
Trained batch 759 in epoch 2, gen_loss = 1.486561990411658, disc_loss = 0.003888368463690552
Trained batch 760 in epoch 2, gen_loss = 1.4863849528985644, disc_loss = 0.0038847192008927608
Trained batch 761 in epoch 2, gen_loss = 1.486290960643548, disc_loss = 0.003882606231659135
Trained batch 762 in epoch 2, gen_loss = 1.4865911236596763, disc_loss = 0.0038825330505807315
Trained batch 763 in epoch 2, gen_loss = 1.4867985448288044, disc_loss = 0.0038824112339908897
Trained batch 764 in epoch 2, gen_loss = 1.4866496960322062, disc_loss = 0.003881900177338751
Trained batch 765 in epoch 2, gen_loss = 1.4868540342109322, disc_loss = 0.0038799792156185755
Trained batch 766 in epoch 2, gen_loss = 1.4863773536184777, disc_loss = 0.003880927841777997
Trained batch 767 in epoch 2, gen_loss = 1.486194231857856, disc_loss = 0.0038824216194749774
Trained batch 768 in epoch 2, gen_loss = 1.4862746138256455, disc_loss = 0.0038791033821207713
Trained batch 769 in epoch 2, gen_loss = 1.4862243398443444, disc_loss = 0.0038780156456844203
Trained batch 770 in epoch 2, gen_loss = 1.4859974820326274, disc_loss = 0.0038746727892694736
Trained batch 771 in epoch 2, gen_loss = 1.4864319277242057, disc_loss = 0.003872359969414628
Trained batch 772 in epoch 2, gen_loss = 1.4862811810603271, disc_loss = 0.0038699991445711912
Trained batch 773 in epoch 2, gen_loss = 1.486142304670595, disc_loss = 0.0038676204800064907
Trained batch 774 in epoch 2, gen_loss = 1.486305823018474, disc_loss = 0.0038674203921184543
Trained batch 775 in epoch 2, gen_loss = 1.4862484374304408, disc_loss = 0.0038658810700916988
Trained batch 776 in epoch 2, gen_loss = 1.4860791112158442, disc_loss = 0.0038650299902562475
Trained batch 777 in epoch 2, gen_loss = 1.4867191455664548, disc_loss = 0.003871467253164829
Trained batch 778 in epoch 2, gen_loss = 1.4867530029759632, disc_loss = 0.0038749792194128422
Trained batch 779 in epoch 2, gen_loss = 1.4871052071070059, disc_loss = 0.0038724595817023863
Trained batch 780 in epoch 2, gen_loss = 1.4873693674688302, disc_loss = 0.0038732756971528873
Trained batch 781 in epoch 2, gen_loss = 1.487545602156988, disc_loss = 0.003870385578129967
Trained batch 782 in epoch 2, gen_loss = 1.4873458530711032, disc_loss = 0.003868060270099845
Trained batch 783 in epoch 2, gen_loss = 1.487030685708231, disc_loss = 0.003866182571630129
Trained batch 784 in epoch 2, gen_loss = 1.4873772952207334, disc_loss = 0.003863713446786556
Trained batch 785 in epoch 2, gen_loss = 1.4872389860432262, disc_loss = 0.003860448012443949
Trained batch 786 in epoch 2, gen_loss = 1.4874978942519677, disc_loss = 0.003856991572470346
Trained batch 787 in epoch 2, gen_loss = 1.487150956985309, disc_loss = 0.004415024130767374
Trained batch 788 in epoch 2, gen_loss = 1.4864924011423863, disc_loss = 0.004929343370417681
Trained batch 789 in epoch 2, gen_loss = 1.4864560471305364, disc_loss = 0.005053428317386291
Trained batch 790 in epoch 2, gen_loss = 1.4866987935511111, disc_loss = 0.00513043354667032
Trained batch 791 in epoch 2, gen_loss = 1.4868762657196835, disc_loss = 0.005173111430610673
Trained batch 792 in epoch 2, gen_loss = 1.487179416575919, disc_loss = 0.005179800107010228
Trained batch 793 in epoch 2, gen_loss = 1.4874877588875048, disc_loss = 0.005185046636475126
Trained batch 794 in epoch 2, gen_loss = 1.4877546037518004, disc_loss = 0.0051845049231134515
Trained batch 795 in epoch 2, gen_loss = 1.4877789119380203, disc_loss = 0.0051822958806375784
Trained batch 796 in epoch 2, gen_loss = 1.4877680604401018, disc_loss = 0.0051794995579280195
Trained batch 797 in epoch 2, gen_loss = 1.4878322277451517, disc_loss = 0.005175074703682431
Trained batch 798 in epoch 2, gen_loss = 1.4874602468201754, disc_loss = 0.005173496567495272
Trained batch 799 in epoch 2, gen_loss = 1.4874468591809273, disc_loss = 0.005172238281847968
Trained batch 800 in epoch 2, gen_loss = 1.4879482655638314, disc_loss = 0.005169944741802997
Trained batch 801 in epoch 2, gen_loss = 1.4879246599359108, disc_loss = 0.005166850429345584
Trained batch 802 in epoch 2, gen_loss = 1.4877419103572556, disc_loss = 0.0051631335277301125
Trained batch 803 in epoch 2, gen_loss = 1.48790896339203, disc_loss = 0.005160483203294619
Trained batch 804 in epoch 2, gen_loss = 1.487858409763123, disc_loss = 0.005156486880891777
Trained batch 805 in epoch 2, gen_loss = 1.4882465592093266, disc_loss = 0.0051514100348452685
Trained batch 806 in epoch 2, gen_loss = 1.4886225522524659, disc_loss = 0.005147155317054632
Trained batch 807 in epoch 2, gen_loss = 1.4885545071989004, disc_loss = 0.005142202257245865
Trained batch 808 in epoch 2, gen_loss = 1.4881711194777518, disc_loss = 0.005197174927602235
Trained batch 809 in epoch 2, gen_loss = 1.4881242045649776, disc_loss = 0.005207777832653431
Trained batch 810 in epoch 2, gen_loss = 1.4885574460176592, disc_loss = 0.005226289660420955
Trained batch 811 in epoch 2, gen_loss = 1.488205056472365, disc_loss = 0.005229048624073024
Trained batch 812 in epoch 2, gen_loss = 1.488010319983094, disc_loss = 0.005229248733898089
Trained batch 813 in epoch 2, gen_loss = 1.4880515572772859, disc_loss = 0.005236559813959165
Trained batch 814 in epoch 2, gen_loss = 1.4880579518394237, disc_loss = 0.005234785984088866
Trained batch 815 in epoch 2, gen_loss = 1.4879728212368255, disc_loss = 0.0052354646766830494
Trained batch 816 in epoch 2, gen_loss = 1.4880275164560997, disc_loss = 0.005233869242011381
Trained batch 817 in epoch 2, gen_loss = 1.488093895405021, disc_loss = 0.005230413995631105
Trained batch 818 in epoch 2, gen_loss = 1.4877855106733366, disc_loss = 0.005528382160872851
Trained batch 819 in epoch 2, gen_loss = 1.4872372845324073, disc_loss = 0.006408009128311433
Trained batch 820 in epoch 2, gen_loss = 1.4866898446077261, disc_loss = 0.006718574080342
Trained batch 821 in epoch 2, gen_loss = 1.486446978837034, disc_loss = 0.00702886302874581
Trained batch 822 in epoch 2, gen_loss = 1.4861518750069063, disc_loss = 0.007344701251458944
Trained batch 823 in epoch 2, gen_loss = 1.4864586089710587, disc_loss = 0.007654786268052774
Trained batch 824 in epoch 2, gen_loss = 1.4863371671329846, disc_loss = 0.007918531944248543
Trained batch 825 in epoch 2, gen_loss = 1.4857411123361195, disc_loss = 0.008223180345562062
Trained batch 826 in epoch 2, gen_loss = 1.485556671812572, disc_loss = 0.00853387938921189
Trained batch 827 in epoch 2, gen_loss = 1.484886369123551, disc_loss = 0.008822169798154414
Trained batch 828 in epoch 2, gen_loss = 1.4846523718322, disc_loss = 0.00908344760706364
Trained batch 829 in epoch 2, gen_loss = 1.484095288184752, disc_loss = 0.00954345676094905
Trained batch 830 in epoch 2, gen_loss = 1.4833879313744363, disc_loss = 0.009812448568151543
Trained batch 831 in epoch 2, gen_loss = 1.4830211970525293, disc_loss = 0.010073038708994248
Trained batch 832 in epoch 2, gen_loss = 1.4828035786372273, disc_loss = 0.010270269545045875
Trained batch 833 in epoch 2, gen_loss = 1.482341673234098, disc_loss = 0.010485506131783031
Trained batch 834 in epoch 2, gen_loss = 1.48183643268254, disc_loss = 0.010694676169095294
Trained batch 835 in epoch 2, gen_loss = 1.4817629266155965, disc_loss = 0.010858675344568915
Trained batch 836 in epoch 2, gen_loss = 1.4817505282313166, disc_loss = 0.011041550310569222
Trained batch 837 in epoch 2, gen_loss = 1.481764419053221, disc_loss = 0.011202587036929662
Trained batch 838 in epoch 2, gen_loss = 1.4817710842790706, disc_loss = 0.011373412352355299
Trained batch 839 in epoch 2, gen_loss = 1.481635962000915, disc_loss = 0.011543737790842508
Trained batch 840 in epoch 2, gen_loss = 1.481588303617575, disc_loss = 0.011637499323287784
Trained batch 841 in epoch 2, gen_loss = 1.4812067450508652, disc_loss = 0.01178038016287527
Trained batch 842 in epoch 2, gen_loss = 1.481190216286751, disc_loss = 0.011873583780986357
Trained batch 843 in epoch 2, gen_loss = 1.481168878798801, disc_loss = 0.011962564816480222
Trained batch 844 in epoch 2, gen_loss = 1.4812304939038654, disc_loss = 0.012084775329767258
Trained batch 845 in epoch 2, gen_loss = 1.4812250886262168, disc_loss = 0.01217812501834887
Trained batch 846 in epoch 2, gen_loss = 1.4813142489232871, disc_loss = 0.01219165136470952
Trained batch 847 in epoch 2, gen_loss = 1.4808084127616208, disc_loss = 0.012219065795813189
Trained batch 848 in epoch 2, gen_loss = 1.4805406237238288, disc_loss = 0.012223967336656007
Trained batch 849 in epoch 2, gen_loss = 1.4806294148809769, disc_loss = 0.012226954862810946
Trained batch 850 in epoch 2, gen_loss = 1.4806980472473925, disc_loss = 0.01222497465671861
Trained batch 851 in epoch 2, gen_loss = 1.4807694152067525, disc_loss = 0.012219851448408606
Trained batch 852 in epoch 2, gen_loss = 1.4806460752157367, disc_loss = 0.012213495217602436
Trained batch 853 in epoch 2, gen_loss = 1.4804976170040685, disc_loss = 0.012203316873194927
Trained batch 854 in epoch 2, gen_loss = 1.4809775535823309, disc_loss = 0.012196155860155483
Trained batch 855 in epoch 2, gen_loss = 1.4814078463154419, disc_loss = 0.012186941984943255
Trained batch 856 in epoch 2, gen_loss = 1.4814329913088153, disc_loss = 0.01218010245213397
Trained batch 857 in epoch 2, gen_loss = 1.481700831429386, disc_loss = 0.012172249132135854
Trained batch 858 in epoch 2, gen_loss = 1.481677962057249, disc_loss = 0.012163301330712722
Trained batch 859 in epoch 2, gen_loss = 1.4815948279098023, disc_loss = 0.012154447458864482
Trained batch 860 in epoch 2, gen_loss = 1.4813144714436326, disc_loss = 0.012147649818049467
Trained batch 861 in epoch 2, gen_loss = 1.4813239445127633, disc_loss = 0.012136564092401884
Trained batch 862 in epoch 2, gen_loss = 1.4812255628830036, disc_loss = 0.012132223490912948
Trained batch 863 in epoch 2, gen_loss = 1.4809324014931917, disc_loss = 0.01213462354822965
Trained batch 864 in epoch 2, gen_loss = 1.4806404293617073, disc_loss = 0.012125122154062893
Trained batch 865 in epoch 2, gen_loss = 1.4805110447263607, disc_loss = 0.012122133009972677
Trained batch 866 in epoch 2, gen_loss = 1.4805898921437466, disc_loss = 0.012117843889028979
Trained batch 867 in epoch 2, gen_loss = 1.4802463753020159, disc_loss = 0.012131097729642144
Trained batch 868 in epoch 2, gen_loss = 1.4799040868038138, disc_loss = 0.012127360929093315
Trained batch 869 in epoch 2, gen_loss = 1.479781089363427, disc_loss = 0.012130988187901943
Trained batch 870 in epoch 2, gen_loss = 1.4800311587708141, disc_loss = 0.012126760907909843
Trained batch 871 in epoch 2, gen_loss = 1.4799714467804366, disc_loss = 0.01212146442903258
Trained batch 872 in epoch 2, gen_loss = 1.4801987238219787, disc_loss = 0.012119435721146633
Trained batch 873 in epoch 2, gen_loss = 1.4800934754056299, disc_loss = 0.012114711913438162
Trained batch 874 in epoch 2, gen_loss = 1.4801855028016226, disc_loss = 0.012111256260857252
Trained batch 875 in epoch 2, gen_loss = 1.48035403752708, disc_loss = 0.012107674934967479
Trained batch 876 in epoch 2, gen_loss = 1.4808642913841195, disc_loss = 0.012100576228673752
Trained batch 877 in epoch 2, gen_loss = 1.48089931134754, disc_loss = 0.012100243950396583
Trained batch 878 in epoch 2, gen_loss = 1.4809200508060174, disc_loss = 0.012100666743287058
Trained batch 879 in epoch 2, gen_loss = 1.4808281938460741, disc_loss = 0.01209698086277058
Trained batch 880 in epoch 2, gen_loss = 1.4808683072668198, disc_loss = 0.012086738864437991
Trained batch 881 in epoch 2, gen_loss = 1.4808809852519003, disc_loss = 0.012077908359934964
Trained batch 882 in epoch 2, gen_loss = 1.481084147031553, disc_loss = 0.012070815462207988
Trained batch 883 in epoch 2, gen_loss = 1.4810124234511302, disc_loss = 0.01206346778652754
Trained batch 884 in epoch 2, gen_loss = 1.4813786340298625, disc_loss = 0.012054759772174786
Trained batch 885 in epoch 2, gen_loss = 1.4816344261303982, disc_loss = 0.012046974863859396
Trained batch 886 in epoch 2, gen_loss = 1.481570865887531, disc_loss = 0.012038225356785774
Trained batch 887 in epoch 2, gen_loss = 1.481952527420478, disc_loss = 0.01203261386448552
Trained batch 888 in epoch 2, gen_loss = 1.4817544104546074, disc_loss = 0.012023758447418174
Trained batch 889 in epoch 2, gen_loss = 1.4819306383641917, disc_loss = 0.012021080277280704
Trained batch 890 in epoch 2, gen_loss = 1.4819683302800128, disc_loss = 0.012014331339366418
Trained batch 891 in epoch 2, gen_loss = 1.4820827229006943, disc_loss = 0.012004207852490992
Trained batch 892 in epoch 2, gen_loss = 1.4821288406114697, disc_loss = 0.011993268807607673
Trained batch 893 in epoch 2, gen_loss = 1.4824460597512972, disc_loss = 0.011983791197358706
Trained batch 894 in epoch 2, gen_loss = 1.4823440881414787, disc_loss = 0.011973463983682125
Trained batch 895 in epoch 2, gen_loss = 1.482503041824592, disc_loss = 0.011964099953502227
Trained batch 896 in epoch 2, gen_loss = 1.4825058374782336, disc_loss = 0.011954633008389929
Trained batch 897 in epoch 2, gen_loss = 1.4824659660425377, disc_loss = 0.01195660074940081
Trained batch 898 in epoch 2, gen_loss = 1.4825558671033687, disc_loss = 0.011955027615769847
Trained batch 899 in epoch 2, gen_loss = 1.4823251246743732, disc_loss = 0.011944328525472277
Trained batch 900 in epoch 2, gen_loss = 1.4824206758286396, disc_loss = 0.011936875589076404
Trained batch 901 in epoch 2, gen_loss = 1.4821247774983721, disc_loss = 0.011928278812060924
Trained batch 902 in epoch 2, gen_loss = 1.4825282542412463, disc_loss = 0.011918986039211692
Trained batch 903 in epoch 2, gen_loss = 1.4824089554954418, disc_loss = 0.011909871165280332
Trained batch 904 in epoch 2, gen_loss = 1.4823436359674231, disc_loss = 0.011904773137111536
Trained batch 905 in epoch 2, gen_loss = 1.4821409495592643, disc_loss = 0.011896163083734474
Trained batch 906 in epoch 2, gen_loss = 1.481969460434267, disc_loss = 0.01188968446315831
Trained batch 907 in epoch 2, gen_loss = 1.4820196301007587, disc_loss = 0.011882028791091624
Trained batch 908 in epoch 2, gen_loss = 1.4819836289313497, disc_loss = 0.011873372950227685
Trained batch 909 in epoch 2, gen_loss = 1.4822543446179275, disc_loss = 0.011863778375382127
Trained batch 910 in epoch 2, gen_loss = 1.482054738849238, disc_loss = 0.011854209612732198
Trained batch 911 in epoch 2, gen_loss = 1.4816862728381366, disc_loss = 0.011844373313387654
Trained batch 912 in epoch 2, gen_loss = 1.481996646259074, disc_loss = 0.011833654102689035
Trained batch 913 in epoch 2, gen_loss = 1.4820589709464518, disc_loss = 0.011823782628699903
Trained batch 914 in epoch 2, gen_loss = 1.4819685613522764, disc_loss = 0.01181325148399843
Trained batch 915 in epoch 2, gen_loss = 1.4817321905012215, disc_loss = 0.011802664080663435
Trained batch 916 in epoch 2, gen_loss = 1.4816649666659314, disc_loss = 0.01179491363241969
Trained batch 917 in epoch 2, gen_loss = 1.4823750823021975, disc_loss = 0.011788208495318527
Trained batch 918 in epoch 2, gen_loss = 1.4822420964303291, disc_loss = 0.011781963004085353
Trained batch 919 in epoch 2, gen_loss = 1.4822383365553358, disc_loss = 0.01178046603419479
Trained batch 920 in epoch 2, gen_loss = 1.4821360870370648, disc_loss = 0.011774197284666412
Trained batch 921 in epoch 2, gen_loss = 1.4820658998349743, disc_loss = 0.011764165203077184
Trained batch 922 in epoch 2, gen_loss = 1.4822386946864143, disc_loss = 0.01175728508005527
Trained batch 923 in epoch 2, gen_loss = 1.482684284900174, disc_loss = 0.01174650560108591
Trained batch 924 in epoch 2, gen_loss = 1.4824083434568869, disc_loss = 0.011736555127080881
Trained batch 925 in epoch 2, gen_loss = 1.4824447544939316, disc_loss = 0.011732411350996825
Trained batch 926 in epoch 2, gen_loss = 1.4822209411840224, disc_loss = 0.011727817848777125
Trained batch 927 in epoch 2, gen_loss = 1.4819651863312926, disc_loss = 0.011718710633713585
Trained batch 928 in epoch 2, gen_loss = 1.4817561512357837, disc_loss = 0.011709796105526775
Trained batch 929 in epoch 2, gen_loss = 1.481870331495039, disc_loss = 0.011700085282071634
Trained batch 930 in epoch 2, gen_loss = 1.4823951047037904, disc_loss = 0.011690187147823758
Trained batch 931 in epoch 2, gen_loss = 1.4825035031133456, disc_loss = 0.011680017876626909
Trained batch 932 in epoch 2, gen_loss = 1.4824736585315528, disc_loss = 0.011668799646576319
Trained batch 933 in epoch 2, gen_loss = 1.4826480291257322, disc_loss = 0.011657947298630173
Trained batch 934 in epoch 2, gen_loss = 1.4825536482474384, disc_loss = 0.01164709349517103
Trained batch 935 in epoch 2, gen_loss = 1.4824172756992853, disc_loss = 0.011635905301998595
Trained batch 936 in epoch 2, gen_loss = 1.4826840638732706, disc_loss = 0.011626321189419845
Trained batch 937 in epoch 2, gen_loss = 1.482768890636562, disc_loss = 0.011616317590710763
Trained batch 938 in epoch 2, gen_loss = 1.4832508428789937, disc_loss = 0.011606223667165684
Trained batch 939 in epoch 2, gen_loss = 1.483089273977787, disc_loss = 0.011598144886932246
Trained batch 940 in epoch 2, gen_loss = 1.4832296602657573, disc_loss = 0.011590059051062767
Trained batch 941 in epoch 2, gen_loss = 1.4838740056867052, disc_loss = 0.011580961946139237
Trained batch 942 in epoch 2, gen_loss = 1.4836617964196432, disc_loss = 0.011576982845053766
Trained batch 943 in epoch 2, gen_loss = 1.4836754005212904, disc_loss = 0.01157059590421618
Trained batch 944 in epoch 2, gen_loss = 1.4842076292113653, disc_loss = 0.011562006495229003
Trained batch 945 in epoch 2, gen_loss = 1.4843252565215557, disc_loss = 0.011552539903304567
Trained batch 946 in epoch 2, gen_loss = 1.4841828346881847, disc_loss = 0.011542732887509217
Trained batch 947 in epoch 2, gen_loss = 1.484076302828668, disc_loss = 0.011532179833364522
Trained batch 948 in epoch 2, gen_loss = 1.4843071801519243, disc_loss = 0.011521807831430659
Trained batch 949 in epoch 2, gen_loss = 1.4841952669620513, disc_loss = 0.01151267953060788
Trained batch 950 in epoch 2, gen_loss = 1.4841515346656462, disc_loss = 0.011503166082976425
Trained batch 951 in epoch 2, gen_loss = 1.4841877990284889, disc_loss = 0.01149429572969817
Trained batch 952 in epoch 2, gen_loss = 1.4842672825234884, disc_loss = 0.011484254800753886
Trained batch 953 in epoch 2, gen_loss = 1.4843477934786358, disc_loss = 0.011474069387075273
Trained batch 954 in epoch 2, gen_loss = 1.4842644211509466, disc_loss = 0.01146419941358078
Trained batch 955 in epoch 2, gen_loss = 1.4844330509960901, disc_loss = 0.011453610362596352
Trained batch 956 in epoch 2, gen_loss = 1.484573597133222, disc_loss = 0.011444835763191318
Trained batch 957 in epoch 2, gen_loss = 1.4846773786559733, disc_loss = 0.011434843550837941
Trained batch 958 in epoch 2, gen_loss = 1.4848332574767789, disc_loss = 0.01142466171041672
Trained batch 959 in epoch 2, gen_loss = 1.4850327940657735, disc_loss = 0.011414504754581382
Trained batch 960 in epoch 2, gen_loss = 1.4852015488973889, disc_loss = 0.01140420767118254
Trained batch 961 in epoch 2, gen_loss = 1.484990942812759, disc_loss = 0.011397429863447198
Trained batch 962 in epoch 2, gen_loss = 1.4848575075219848, disc_loss = 0.011387626845555221
Trained batch 963 in epoch 2, gen_loss = 1.4848519126532977, disc_loss = 0.011377535565763265
Trained batch 964 in epoch 2, gen_loss = 1.4850062614277855, disc_loss = 0.011367391902196988
Trained batch 965 in epoch 2, gen_loss = 1.4849209492374404, disc_loss = 0.011361938428022132
Trained batch 966 in epoch 2, gen_loss = 1.4850172010917821, disc_loss = 0.011353721876028924
Trained batch 967 in epoch 2, gen_loss = 1.485119032527297, disc_loss = 0.011344617275163494
Trained batch 968 in epoch 2, gen_loss = 1.4849944783315079, disc_loss = 0.011335208231754558
Trained batch 969 in epoch 2, gen_loss = 1.4853712330773934, disc_loss = 0.011325456374882931
Trained batch 970 in epoch 2, gen_loss = 1.4853845924967717, disc_loss = 0.011315078525565398
Trained batch 971 in epoch 2, gen_loss = 1.4853531807170484, disc_loss = 0.011304575457327966
Trained batch 972 in epoch 2, gen_loss = 1.485501574159036, disc_loss = 0.011293855401858895
Trained batch 973 in epoch 2, gen_loss = 1.4853062145641451, disc_loss = 0.011283073207100296
Trained batch 974 in epoch 2, gen_loss = 1.4853116555702992, disc_loss = 0.01127744495531377
Trained batch 975 in epoch 2, gen_loss = 1.4857757623444816, disc_loss = 0.011269241972170631
Trained batch 976 in epoch 2, gen_loss = 1.485797175792491, disc_loss = 0.011260330568094182
Trained batch 977 in epoch 2, gen_loss = 1.4859987079853416, disc_loss = 0.011250027884596602
Trained batch 978 in epoch 2, gen_loss = 1.4861485834506485, disc_loss = 0.011240027618110018
Trained batch 979 in epoch 2, gen_loss = 1.4860150487447272, disc_loss = 0.011229959974149765
Trained batch 980 in epoch 2, gen_loss = 1.4859479928842987, disc_loss = 0.011219203334094513
Trained batch 981 in epoch 2, gen_loss = 1.4861084015816146, disc_loss = 0.011210552340010874
Trained batch 982 in epoch 2, gen_loss = 1.4860176222127912, disc_loss = 0.01120035394197562
Trained batch 983 in epoch 2, gen_loss = 1.485846969836611, disc_loss = 0.01118989368591044
Trained batch 984 in epoch 2, gen_loss = 1.4862354724540323, disc_loss = 0.011180415834497593
Trained batch 985 in epoch 2, gen_loss = 1.4863433576137977, disc_loss = 0.011171067397635097
Trained batch 986 in epoch 2, gen_loss = 1.4864993034404341, disc_loss = 0.011160527610059841
Trained batch 987 in epoch 2, gen_loss = 1.486660948226809, disc_loss = 0.011150378404687836
Trained batch 988 in epoch 2, gen_loss = 1.486743781094122, disc_loss = 0.011140371532292652
Trained batch 989 in epoch 2, gen_loss = 1.4867678750042963, disc_loss = 0.011130307394584331
Trained batch 990 in epoch 2, gen_loss = 1.4868575904131176, disc_loss = 0.01112028349717345
Trained batch 991 in epoch 2, gen_loss = 1.4869676814564774, disc_loss = 0.011110074555055631
Trained batch 992 in epoch 2, gen_loss = 1.4871394109029665, disc_loss = 0.011100033096049294
Trained batch 993 in epoch 2, gen_loss = 1.4871886004984258, disc_loss = 0.011090310036807445
Trained batch 994 in epoch 2, gen_loss = 1.4874107409362218, disc_loss = 0.011080841945944091
Trained batch 995 in epoch 2, gen_loss = 1.487310411041999, disc_loss = 0.01107057467997509
Trained batch 996 in epoch 2, gen_loss = 1.4871124112259302, disc_loss = 0.011060980477804924
Trained batch 997 in epoch 2, gen_loss = 1.4870829732121829, disc_loss = 0.011050770836836801
Trained batch 998 in epoch 2, gen_loss = 1.4870381755633157, disc_loss = 0.01104073379088209
Trained batch 999 in epoch 2, gen_loss = 1.486963316500187, disc_loss = 0.011031438568868908
Trained batch 1000 in epoch 2, gen_loss = 1.4869806116872972, disc_loss = 0.011020899739621866
Trained batch 1001 in epoch 2, gen_loss = 1.4872241725107866, disc_loss = 0.011010916286480182
Trained batch 1002 in epoch 2, gen_loss = 1.4871466689309474, disc_loss = 0.011002137730110962
Trained batch 1003 in epoch 2, gen_loss = 1.4870177592295575, disc_loss = 0.010992648486662294
Trained batch 1004 in epoch 2, gen_loss = 1.4868545392852517, disc_loss = 0.01098316545909229
Trained batch 1005 in epoch 2, gen_loss = 1.486968759691739, disc_loss = 0.010973907089622082
Trained batch 1006 in epoch 2, gen_loss = 1.4869564338971037, disc_loss = 0.010964004250430356
Trained batch 1007 in epoch 2, gen_loss = 1.4869537542145403, disc_loss = 0.010955626623052965
Trained batch 1008 in epoch 2, gen_loss = 1.4869280489396057, disc_loss = 0.010945757774077032
Trained batch 1009 in epoch 2, gen_loss = 1.4868273729735082, disc_loss = 0.010935665832199664
Trained batch 1010 in epoch 2, gen_loss = 1.4869048349581415, disc_loss = 0.010928729457938933
Trained batch 1011 in epoch 2, gen_loss = 1.4872474552025436, disc_loss = 0.010919982986472936
Trained batch 1012 in epoch 2, gen_loss = 1.487143291831605, disc_loss = 0.010910922816883531
Trained batch 1013 in epoch 2, gen_loss = 1.4872445489410349, disc_loss = 0.010900936558705119
Trained batch 1014 in epoch 2, gen_loss = 1.4875409436930576, disc_loss = 0.010891052232074592
Trained batch 1015 in epoch 2, gen_loss = 1.4873790011748553, disc_loss = 0.010881371535371125
Trained batch 1016 in epoch 2, gen_loss = 1.4870113801932734, disc_loss = 0.010871379224396006
Trained batch 1017 in epoch 2, gen_loss = 1.4872315274825967, disc_loss = 0.010863023939340518
Trained batch 1018 in epoch 2, gen_loss = 1.4871898973187005, disc_loss = 0.010853749293893607
Trained batch 1019 in epoch 2, gen_loss = 1.4873189365746928, disc_loss = 0.010844370355976827
Trained batch 1020 in epoch 2, gen_loss = 1.487199568082957, disc_loss = 0.010835488955473187
Trained batch 1021 in epoch 2, gen_loss = 1.4873298687127705, disc_loss = 0.010826478792936996
Trained batch 1022 in epoch 2, gen_loss = 1.4871626383281755, disc_loss = 0.010817559262677775
Trained batch 1023 in epoch 2, gen_loss = 1.4876434142352082, disc_loss = 0.010809317190620504
Trained batch 1024 in epoch 2, gen_loss = 1.4875386952772374, disc_loss = 0.010799810773744135
Trained batch 1025 in epoch 2, gen_loss = 1.4880466264242318, disc_loss = 0.010791231231378404
Trained batch 1026 in epoch 2, gen_loss = 1.487902361845204, disc_loss = 0.010782795914040947
Trained batch 1027 in epoch 2, gen_loss = 1.4878388500051276, disc_loss = 0.01077442257174183
Trained batch 1028 in epoch 2, gen_loss = 1.487982200174452, disc_loss = 0.010765185379777312
Trained batch 1029 in epoch 2, gen_loss = 1.4878401715199925, disc_loss = 0.010758018874912522
Trained batch 1030 in epoch 2, gen_loss = 1.4878184245583157, disc_loss = 0.010749386514905817
Trained batch 1031 in epoch 2, gen_loss = 1.4879375359462212, disc_loss = 0.010739679266266613
Trained batch 1032 in epoch 2, gen_loss = 1.4881837121630224, disc_loss = 0.010730264747646275
Trained batch 1033 in epoch 2, gen_loss = 1.4879548644765894, disc_loss = 0.01072091159039349
Trained batch 1034 in epoch 2, gen_loss = 1.4878151818174095, disc_loss = 0.010714308446827726
Trained batch 1035 in epoch 2, gen_loss = 1.487718905088524, disc_loss = 0.010707700855785695
Trained batch 1036 in epoch 2, gen_loss = 1.4876343902189684, disc_loss = 0.010700075898061056
Trained batch 1037 in epoch 2, gen_loss = 1.487542104801461, disc_loss = 0.010691301173806192
Trained batch 1038 in epoch 2, gen_loss = 1.4874898107494725, disc_loss = 0.01068299609154962
Trained batch 1039 in epoch 2, gen_loss = 1.4872888629826215, disc_loss = 0.010674091932266422
Trained batch 1040 in epoch 2, gen_loss = 1.487295145317411, disc_loss = 0.010665034789639668
Trained batch 1041 in epoch 2, gen_loss = 1.4872009464165985, disc_loss = 0.010655903626813628
Trained batch 1042 in epoch 2, gen_loss = 1.4869165365099335, disc_loss = 0.010647071850396138
Trained batch 1043 in epoch 2, gen_loss = 1.4869943074453835, disc_loss = 0.010639143671838868
Trained batch 1044 in epoch 2, gen_loss = 1.4868387501205553, disc_loss = 0.010630305454443526
Trained batch 1045 in epoch 2, gen_loss = 1.4869323550059281, disc_loss = 0.010620869673241195
Trained batch 1046 in epoch 2, gen_loss = 1.486989389005568, disc_loss = 0.01061127696307167
Trained batch 1047 in epoch 2, gen_loss = 1.4871009426148794, disc_loss = 0.010602089344564504
Trained batch 1048 in epoch 2, gen_loss = 1.487113022883809, disc_loss = 0.010592703085515454
Trained batch 1049 in epoch 2, gen_loss = 1.4872267059485118, disc_loss = 0.010583115181403367
Trained batch 1050 in epoch 2, gen_loss = 1.487260964061962, disc_loss = 0.010573907177198588
Trained batch 1051 in epoch 2, gen_loss = 1.487064124910097, disc_loss = 0.010565292850833257
Trained batch 1052 in epoch 2, gen_loss = 1.4869596801365657, disc_loss = 0.01055756348522105
Trained batch 1053 in epoch 2, gen_loss = 1.4869375167241359, disc_loss = 0.010548866365609233
Trained batch 1054 in epoch 2, gen_loss = 1.4867646721867023, disc_loss = 0.010539701498158815
Trained batch 1055 in epoch 2, gen_loss = 1.486744735107729, disc_loss = 0.010530791477156692
Trained batch 1056 in epoch 2, gen_loss = 1.486678782057514, disc_loss = 0.010521765683814856
Trained batch 1057 in epoch 2, gen_loss = 1.486962509008797, disc_loss = 0.01051270422028463
Trained batch 1058 in epoch 2, gen_loss = 1.4869114810616706, disc_loss = 0.010503377293847102
Trained batch 1059 in epoch 2, gen_loss = 1.4869807914180575, disc_loss = 0.010495106544689372
Trained batch 1060 in epoch 2, gen_loss = 1.4869841509669823, disc_loss = 0.010486374203117677
Trained batch 1061 in epoch 2, gen_loss = 1.4869388752176713, disc_loss = 0.010477192497251181
Trained batch 1062 in epoch 2, gen_loss = 1.487115635080149, disc_loss = 0.010468246258677203
Trained batch 1063 in epoch 2, gen_loss = 1.4875488155206342, disc_loss = 0.010458996276139445
Trained batch 1064 in epoch 2, gen_loss = 1.4875487547525217, disc_loss = 0.010449893545920134
Trained batch 1065 in epoch 2, gen_loss = 1.487827527422395, disc_loss = 0.010440829995650262
Trained batch 1066 in epoch 2, gen_loss = 1.487784524497968, disc_loss = 0.01043223043185905
Trained batch 1067 in epoch 2, gen_loss = 1.4877736923958031, disc_loss = 0.010422766787128189
Trained batch 1068 in epoch 2, gen_loss = 1.4876880757824298, disc_loss = 0.010414323987094276
Trained batch 1069 in epoch 2, gen_loss = 1.4875924102056806, disc_loss = 0.010406953411255136
Trained batch 1070 in epoch 2, gen_loss = 1.4876857870767097, disc_loss = 0.010398639094286245
Trained batch 1071 in epoch 2, gen_loss = 1.4879812274072597, disc_loss = 0.010390279621950962
Trained batch 1072 in epoch 2, gen_loss = 1.4878094899021124, disc_loss = 0.010381474792510306
Trained batch 1073 in epoch 2, gen_loss = 1.4877882773538764, disc_loss = 0.010373315863112713
Trained batch 1074 in epoch 2, gen_loss = 1.4877498730393344, disc_loss = 0.010364560242525713
Trained batch 1075 in epoch 2, gen_loss = 1.487811303437864, disc_loss = 0.010355604345543262
Trained batch 1076 in epoch 2, gen_loss = 1.4877977623027459, disc_loss = 0.010347222906629016
Trained batch 1077 in epoch 2, gen_loss = 1.4878915921544764, disc_loss = 0.010338264299936313
Trained batch 1078 in epoch 2, gen_loss = 1.4880912989460837, disc_loss = 0.010329403125713782
Trained batch 1079 in epoch 2, gen_loss = 1.4878079610290351, disc_loss = 0.01032082155310221
Trained batch 1080 in epoch 2, gen_loss = 1.487795986421234, disc_loss = 0.010312046598626695
Trained batch 1081 in epoch 2, gen_loss = 1.4881112936353948, disc_loss = 0.01030337834875349
Trained batch 1082 in epoch 2, gen_loss = 1.4877991799062198, disc_loss = 0.010295878390206277
Trained batch 1083 in epoch 2, gen_loss = 1.487678746070809, disc_loss = 0.010287757211182665
Trained batch 1084 in epoch 2, gen_loss = 1.4876226304862905, disc_loss = 0.010278882732086983
Trained batch 1085 in epoch 2, gen_loss = 1.4877128136201898, disc_loss = 0.010270828695587889
Trained batch 1086 in epoch 2, gen_loss = 1.4877439855213217, disc_loss = 0.010262845274705265
Trained batch 1087 in epoch 2, gen_loss = 1.4876358635614024, disc_loss = 0.01025512335004083
Trained batch 1088 in epoch 2, gen_loss = 1.4876147024230852, disc_loss = 0.010246375472608978
Trained batch 1089 in epoch 2, gen_loss = 1.487241780375122, disc_loss = 0.010238991132638323
Trained batch 1090 in epoch 2, gen_loss = 1.4871393077751565, disc_loss = 0.010231134060562839
Trained batch 1091 in epoch 2, gen_loss = 1.4873932238136018, disc_loss = 0.01022376373528346
Trained batch 1092 in epoch 2, gen_loss = 1.4873091505409268, disc_loss = 0.010216214169095435
Trained batch 1093 in epoch 2, gen_loss = 1.4871865916840554, disc_loss = 0.010207732267770575
Trained batch 1094 in epoch 2, gen_loss = 1.4873419999531958, disc_loss = 0.010200433938160164
Trained batch 1095 in epoch 2, gen_loss = 1.4874346766919986, disc_loss = 0.010192206025868825
Trained batch 1096 in epoch 2, gen_loss = 1.4876344953217937, disc_loss = 0.01018378592254178
Trained batch 1097 in epoch 2, gen_loss = 1.4876668222506406, disc_loss = 0.010175754217866075
Trained batch 1098 in epoch 2, gen_loss = 1.4877446985873881, disc_loss = 0.010167970063077545
Trained batch 1099 in epoch 2, gen_loss = 1.4875995312495665, disc_loss = 0.010159493403519843
Trained batch 1100 in epoch 2, gen_loss = 1.4877485462906792, disc_loss = 0.010150744040531751
Trained batch 1101 in epoch 2, gen_loss = 1.4879176808680035, disc_loss = 0.010142666496412099
Trained batch 1102 in epoch 2, gen_loss = 1.4879711875565358, disc_loss = 0.010134284988209076
Trained batch 1103 in epoch 2, gen_loss = 1.4882023141759892, disc_loss = 0.010126344549950074
Trained batch 1104 in epoch 2, gen_loss = 1.488622346345116, disc_loss = 0.010118451444337321
Trained batch 1105 in epoch 2, gen_loss = 1.4884336391905117, disc_loss = 0.010110277568074751
Trained batch 1106 in epoch 2, gen_loss = 1.4882705734458828, disc_loss = 0.010101598777541977
Trained batch 1107 in epoch 2, gen_loss = 1.4883700013698653, disc_loss = 0.010093313449939514
Trained batch 1108 in epoch 2, gen_loss = 1.4885173490501074, disc_loss = 0.01008479944777753
Trained batch 1109 in epoch 2, gen_loss = 1.488583404684926, disc_loss = 0.010076294747246261
Trained batch 1110 in epoch 2, gen_loss = 1.4887964638045625, disc_loss = 0.010067834252697808
Trained batch 1111 in epoch 2, gen_loss = 1.4888061749742185, disc_loss = 0.010059304485870559
Trained batch 1112 in epoch 2, gen_loss = 1.48880094653941, disc_loss = 0.010050653631683658
Trained batch 1113 in epoch 2, gen_loss = 1.4890341954021522, disc_loss = 0.010041980943436687
Trained batch 1114 in epoch 2, gen_loss = 1.4888325184984592, disc_loss = 0.010034012225756188
Trained batch 1115 in epoch 2, gen_loss = 1.4888108898768715, disc_loss = 0.010025472651152516
Trained batch 1116 in epoch 2, gen_loss = 1.4887146563965397, disc_loss = 0.010016928812201887
Trained batch 1117 in epoch 2, gen_loss = 1.4884462774013152, disc_loss = 0.01000831831569516
Trained batch 1118 in epoch 2, gen_loss = 1.4882020498089112, disc_loss = 0.00999984360769515
Trained batch 1119 in epoch 2, gen_loss = 1.4883442262985878, disc_loss = 0.009991704010800666
Trained batch 1120 in epoch 2, gen_loss = 1.4881749647095415, disc_loss = 0.009983625923692358
Trained batch 1121 in epoch 2, gen_loss = 1.4885037784164177, disc_loss = 0.00997564699291729
Trained batch 1122 in epoch 2, gen_loss = 1.4888435340522128, disc_loss = 0.00996772714711511
Trained batch 1123 in epoch 2, gen_loss = 1.4888026788035322, disc_loss = 0.009959792806767963
Trained batch 1124 in epoch 2, gen_loss = 1.4887435285250346, disc_loss = 0.009951248303469684
Trained batch 1125 in epoch 2, gen_loss = 1.4885435329343244, disc_loss = 0.009942926002509617
Trained batch 1126 in epoch 2, gen_loss = 1.4888838492036394, disc_loss = 0.0099345120854846
Trained batch 1127 in epoch 2, gen_loss = 1.489060751882428, disc_loss = 0.009926514789275908
Trained batch 1128 in epoch 2, gen_loss = 1.4892850662882715, disc_loss = 0.009918352776007814
Trained batch 1129 in epoch 2, gen_loss = 1.4891072347628331, disc_loss = 0.009911159795669805
Trained batch 1130 in epoch 2, gen_loss = 1.4891124974827552, disc_loss = 0.009903551089677425
Trained batch 1131 in epoch 2, gen_loss = 1.4889100207140926, disc_loss = 0.009896950832086405
Trained batch 1132 in epoch 2, gen_loss = 1.4889980724503904, disc_loss = 0.009889446800693438
Trained batch 1133 in epoch 2, gen_loss = 1.489017342921918, disc_loss = 0.009882274890744343
Trained batch 1134 in epoch 2, gen_loss = 1.4888585376844532, disc_loss = 0.009874573511446903
Trained batch 1135 in epoch 2, gen_loss = 1.4888449196349567, disc_loss = 0.00986687045444572
Trained batch 1136 in epoch 2, gen_loss = 1.4886667196333356, disc_loss = 0.00985903264532847
Trained batch 1137 in epoch 2, gen_loss = 1.4885008538858753, disc_loss = 0.009851615620418558
Trained batch 1138 in epoch 2, gen_loss = 1.488378149935611, disc_loss = 0.009844572092300155
Trained batch 1139 in epoch 2, gen_loss = 1.4882169117530186, disc_loss = 0.009837438258967412
Trained batch 1140 in epoch 2, gen_loss = 1.4883151294159116, disc_loss = 0.00982978926011664
Trained batch 1141 in epoch 2, gen_loss = 1.4884801045086253, disc_loss = 0.009821981315594003
Trained batch 1142 in epoch 2, gen_loss = 1.4884012052601925, disc_loss = 0.00981390255455283
Trained batch 1143 in epoch 2, gen_loss = 1.4887620292447663, disc_loss = 0.009806041599257843
Trained batch 1144 in epoch 2, gen_loss = 1.4893377106783172, disc_loss = 0.009798258240436362
Trained batch 1145 in epoch 2, gen_loss = 1.4893977871427986, disc_loss = 0.00979076108676227
Trained batch 1146 in epoch 2, gen_loss = 1.4891143317521918, disc_loss = 0.009783341870773113
Trained batch 1147 in epoch 2, gen_loss = 1.4892689588281751, disc_loss = 0.009776925079249502
Trained batch 1148 in epoch 2, gen_loss = 1.4892616315029101, disc_loss = 0.009770623119195373
Trained batch 1149 in epoch 2, gen_loss = 1.48924241475437, disc_loss = 0.009762834053405601
Trained batch 1150 in epoch 2, gen_loss = 1.489070226947294, disc_loss = 0.009755244368135437
Trained batch 1151 in epoch 2, gen_loss = 1.4890637041276529, disc_loss = 0.009747542363078942
Trained batch 1152 in epoch 2, gen_loss = 1.4890830931928194, disc_loss = 0.009739474037492321
Trained batch 1153 in epoch 2, gen_loss = 1.4892343362757816, disc_loss = 0.009731526057104955
Trained batch 1154 in epoch 2, gen_loss = 1.4890917560754917, disc_loss = 0.009723555930014257
Trained batch 1155 in epoch 2, gen_loss = 1.4890847199412778, disc_loss = 0.00971599648745185
Trained batch 1156 in epoch 2, gen_loss = 1.4888461752502486, disc_loss = 0.00970818492952294
Trained batch 1157 in epoch 2, gen_loss = 1.4884837789136098, disc_loss = 0.009700829381975088
Trained batch 1158 in epoch 2, gen_loss = 1.4885613334600631, disc_loss = 0.009694041736124443
Trained batch 1159 in epoch 2, gen_loss = 1.4888711224856048, disc_loss = 0.00968622524406187
Trained batch 1160 in epoch 2, gen_loss = 1.489152531034468, disc_loss = 0.00967857080817477
Trained batch 1161 in epoch 2, gen_loss = 1.4890355115400535, disc_loss = 0.009671335902371405
Trained batch 1162 in epoch 2, gen_loss = 1.4891215022124817, disc_loss = 0.00966390916671358
Trained batch 1163 in epoch 2, gen_loss = 1.4893463128518403, disc_loss = 0.009656408882560488
Trained batch 1164 in epoch 2, gen_loss = 1.489260001090463, disc_loss = 0.009649246999401352
Trained batch 1165 in epoch 2, gen_loss = 1.4896042501844633, disc_loss = 0.009642415647018553
Trained batch 1166 in epoch 2, gen_loss = 1.4896616694144744, disc_loss = 0.009635819221427585
Trained batch 1167 in epoch 2, gen_loss = 1.4896566461108318, disc_loss = 0.009629293516024505
Trained batch 1168 in epoch 2, gen_loss = 1.4897075592196833, disc_loss = 0.009621707531614579
Trained batch 1169 in epoch 2, gen_loss = 1.4896224807979714, disc_loss = 0.009614438417792503
Trained batch 1170 in epoch 2, gen_loss = 1.4896531948465044, disc_loss = 0.009606908713832274
Trained batch 1171 in epoch 2, gen_loss = 1.4901352393037224, disc_loss = 0.009599912603008886
Trained batch 1172 in epoch 2, gen_loss = 1.4903638629657228, disc_loss = 0.009592470245288752
Trained batch 1173 in epoch 2, gen_loss = 1.4905561287419353, disc_loss = 0.009584760392500996
Trained batch 1174 in epoch 2, gen_loss = 1.4906450825041913, disc_loss = 0.009577245274236663
Trained batch 1175 in epoch 2, gen_loss = 1.4907851456886245, disc_loss = 0.00956973375502216
Trained batch 1176 in epoch 2, gen_loss = 1.4909469500475245, disc_loss = 0.00956208372550238
Trained batch 1177 in epoch 2, gen_loss = 1.490896454741878, disc_loss = 0.009554487267537366
Trained batch 1178 in epoch 2, gen_loss = 1.4907858525928144, disc_loss = 0.009546870886966503
Trained batch 1179 in epoch 2, gen_loss = 1.4905578878471406, disc_loss = 0.009539222462034697
Trained batch 1180 in epoch 2, gen_loss = 1.4908221800078991, disc_loss = 0.009531543787300097
Trained batch 1181 in epoch 2, gen_loss = 1.4906254493948168, disc_loss = 0.009523961775854045
Trained batch 1182 in epoch 2, gen_loss = 1.490506252643927, disc_loss = 0.00951642555164292
Trained batch 1183 in epoch 2, gen_loss = 1.4902212457177606, disc_loss = 0.009509234329139086
Trained batch 1184 in epoch 2, gen_loss = 1.4902481408561836, disc_loss = 0.00950162773556469
Trained batch 1185 in epoch 2, gen_loss = 1.4899421283507226, disc_loss = 0.009494158712241832
Trained batch 1186 in epoch 2, gen_loss = 1.4902143528105938, disc_loss = 0.00948675174032975
Trained batch 1187 in epoch 2, gen_loss = 1.4902912016569163, disc_loss = 0.009479169731397027
Trained batch 1188 in epoch 2, gen_loss = 1.490227325459906, disc_loss = 0.00947149883174589
Trained batch 1189 in epoch 2, gen_loss = 1.4904095821520862, disc_loss = 0.009463914139822376
Trained batch 1190 in epoch 2, gen_loss = 1.490411192654162, disc_loss = 0.009456281764096542
Trained batch 1191 in epoch 2, gen_loss = 1.4904290250183752, disc_loss = 0.009448705663358216
Trained batch 1192 in epoch 2, gen_loss = 1.4903382460109746, disc_loss = 0.009441109780399387
Trained batch 1193 in epoch 2, gen_loss = 1.4902383061609477, disc_loss = 0.009433920881410646
Trained batch 1194 in epoch 2, gen_loss = 1.4904632312483368, disc_loss = 0.009426900380579403
Trained batch 1195 in epoch 2, gen_loss = 1.4901433561657584, disc_loss = 0.009419603838509783
Trained batch 1196 in epoch 2, gen_loss = 1.490479054058604, disc_loss = 0.00941223843795782
Trained batch 1197 in epoch 2, gen_loss = 1.4905484324206095, disc_loss = 0.009404767803651109
Trained batch 1198 in epoch 2, gen_loss = 1.490465561731146, disc_loss = 0.009397334192282954
Trained batch 1199 in epoch 2, gen_loss = 1.4904820232093334, disc_loss = 0.009389948641570906
Trained batch 1200 in epoch 2, gen_loss = 1.4907010183743294, disc_loss = 0.009383026435936364
Trained batch 1201 in epoch 2, gen_loss = 1.4910215148810737, disc_loss = 0.009375762384659541
Trained batch 1202 in epoch 2, gen_loss = 1.4909807517443314, disc_loss = 0.00936872446689877
Trained batch 1203 in epoch 2, gen_loss = 1.491103523939947, disc_loss = 0.009362486319933968
Trained batch 1204 in epoch 2, gen_loss = 1.4908268497692598, disc_loss = 0.009355830642079772
Trained batch 1205 in epoch 2, gen_loss = 1.4907477369059379, disc_loss = 0.009349984713167085
Trained batch 1206 in epoch 2, gen_loss = 1.4909270798853833, disc_loss = 0.0093426742155395
Trained batch 1207 in epoch 2, gen_loss = 1.4909693862724778, disc_loss = 0.009336069332272283
Trained batch 1208 in epoch 2, gen_loss = 1.4909251467367162, disc_loss = 0.009329689438805305
Trained batch 1209 in epoch 2, gen_loss = 1.4907750897663683, disc_loss = 0.009322446193267045
Trained batch 1210 in epoch 2, gen_loss = 1.4908403487465383, disc_loss = 0.009315344091117594
Trained batch 1211 in epoch 2, gen_loss = 1.4910593284140325, disc_loss = 0.009308100689937154
Trained batch 1212 in epoch 2, gen_loss = 1.4909569319377531, disc_loss = 0.009301000462968965
Trained batch 1213 in epoch 2, gen_loss = 1.490791409029403, disc_loss = 0.009500435719339798
Trained batch 1214 in epoch 2, gen_loss = 1.4903517069639982, disc_loss = 0.009856989018670801
Trained batch 1215 in epoch 2, gen_loss = 1.4904655584771382, disc_loss = 0.009968210828303296
Trained batch 1216 in epoch 2, gen_loss = 1.4902726642009951, disc_loss = 0.010046442447338504
Trained batch 1217 in epoch 2, gen_loss = 1.4901543205790528, disc_loss = 0.01014186985872354
Trained batch 1218 in epoch 2, gen_loss = 1.490156281669185, disc_loss = 0.010179583898677099
Trained batch 1219 in epoch 2, gen_loss = 1.4902768568914444, disc_loss = 0.010220277555368947
Trained batch 1220 in epoch 2, gen_loss = 1.4901684771591674, disc_loss = 0.010233625766707173
Trained batch 1221 in epoch 2, gen_loss = 1.4903433172675475, disc_loss = 0.01026563094287719
Trained batch 1222 in epoch 2, gen_loss = 1.4902884310030684, disc_loss = 0.010272881467089906
Trained batch 1223 in epoch 2, gen_loss = 1.4904191243687486, disc_loss = 0.010273426441082752
Trained batch 1224 in epoch 2, gen_loss = 1.4903232360372738, disc_loss = 0.010271902806743295
Trained batch 1225 in epoch 2, gen_loss = 1.4904770848218225, disc_loss = 0.010269111351800937
Trained batch 1226 in epoch 2, gen_loss = 1.4904337962079846, disc_loss = 0.010271258210221013
Trained batch 1227 in epoch 2, gen_loss = 1.4906129082755857, disc_loss = 0.010269726561873482
Trained batch 1228 in epoch 2, gen_loss = 1.4909544199632376, disc_loss = 0.010275420799244808
Trained batch 1229 in epoch 2, gen_loss = 1.4908450276871037, disc_loss = 0.010317292964470202
Trained batch 1230 in epoch 2, gen_loss = 1.4909115533921702, disc_loss = 0.010322967410050893
Trained batch 1231 in epoch 2, gen_loss = 1.4911543369873779, disc_loss = 0.010325785675424366
Trained batch 1232 in epoch 2, gen_loss = 1.4914242145208836, disc_loss = 0.010325600790184306
Trained batch 1233 in epoch 2, gen_loss = 1.491152150800974, disc_loss = 0.01034249420777964
Trained batch 1234 in epoch 2, gen_loss = 1.491023482484856, disc_loss = 0.010350039998504902
Trained batch 1235 in epoch 2, gen_loss = 1.4910190072646032, disc_loss = 0.010347477304830191
Trained batch 1236 in epoch 2, gen_loss = 1.491051363771542, disc_loss = 0.010341872782388096
Trained batch 1237 in epoch 2, gen_loss = 1.491163418058047, disc_loss = 0.010339374402122308
Trained batch 1238 in epoch 2, gen_loss = 1.491251115552642, disc_loss = 0.010334942186327578
Trained batch 1239 in epoch 2, gen_loss = 1.49123369359201, disc_loss = 0.010329869677333327
Trained batch 1240 in epoch 2, gen_loss = 1.491006609319584, disc_loss = 0.01036286135469612
Trained batch 1241 in epoch 2, gen_loss = 1.490971874019758, disc_loss = 0.01038094575721403
Trained batch 1242 in epoch 2, gen_loss = 1.4908085751706137, disc_loss = 0.010381519392255262
Trained batch 1243 in epoch 2, gen_loss = 1.4908277227564257, disc_loss = 0.010376241289023414
Trained batch 1244 in epoch 2, gen_loss = 1.490669891824684, disc_loss = 0.010372549975730373
Trained batch 1245 in epoch 2, gen_loss = 1.4905547440339053, disc_loss = 0.010366555600773535
Trained batch 1246 in epoch 2, gen_loss = 1.4904722675095583, disc_loss = 0.010362006419865935
Trained batch 1247 in epoch 2, gen_loss = 1.4906228069120493, disc_loss = 0.010360192442534846
Trained batch 1248 in epoch 2, gen_loss = 1.4908772901690799, disc_loss = 0.010358091984330053
Trained batch 1249 in epoch 2, gen_loss = 1.4910381875038148, disc_loss = 0.010352416307246313
Trained batch 1250 in epoch 2, gen_loss = 1.490994737493239, disc_loss = 0.01034786375097113
Trained batch 1251 in epoch 2, gen_loss = 1.4913855872024744, disc_loss = 0.010343559070841035
Trained batch 1252 in epoch 2, gen_loss = 1.4914753338097575, disc_loss = 0.010338671749756142
Trained batch 1253 in epoch 2, gen_loss = 1.4914477976125202, disc_loss = 0.010335366157478798
Trained batch 1254 in epoch 2, gen_loss = 1.491516462265258, disc_loss = 0.01033131541490399
Trained batch 1255 in epoch 2, gen_loss = 1.491524108655893, disc_loss = 0.010324938156911555
Trained batch 1256 in epoch 2, gen_loss = 1.4915903263274126, disc_loss = 0.010318244958799124
Trained batch 1257 in epoch 2, gen_loss = 1.491658472578931, disc_loss = 0.010311657097051808
Trained batch 1258 in epoch 2, gen_loss = 1.4920844349054423, disc_loss = 0.010305736031809731
Trained batch 1259 in epoch 2, gen_loss = 1.4920547183543917, disc_loss = 0.010299597034602249
Trained batch 1260 in epoch 2, gen_loss = 1.4921863623595635, disc_loss = 0.010293546504284566
Trained batch 1261 in epoch 2, gen_loss = 1.492288330183165, disc_loss = 0.010286647353899517
Trained batch 1262 in epoch 2, gen_loss = 1.492436844681523, disc_loss = 0.01028074110062315
Trained batch 1263 in epoch 2, gen_loss = 1.4924896603709534, disc_loss = 0.010274222739513512
Trained batch 1264 in epoch 2, gen_loss = 1.492737226429664, disc_loss = 0.01026685256952707
Trained batch 1265 in epoch 2, gen_loss = 1.4927407690510743, disc_loss = 0.01025990097037565
Trained batch 1266 in epoch 2, gen_loss = 1.4927278700642634, disc_loss = 0.010252957380411305
Trained batch 1267 in epoch 2, gen_loss = 1.4926697175585508, disc_loss = 0.01024629931775001
Trained batch 1268 in epoch 2, gen_loss = 1.493015479816049, disc_loss = 0.01023908828952481
Trained batch 1269 in epoch 2, gen_loss = 1.493115504238549, disc_loss = 0.010231768205857241
Trained batch 1270 in epoch 2, gen_loss = 1.493145117789718, disc_loss = 0.010224579729122952
Trained batch 1271 in epoch 2, gen_loss = 1.4933195418719225, disc_loss = 0.010217811343858295
Trained batch 1272 in epoch 2, gen_loss = 1.4932618464247411, disc_loss = 0.010210671899156193
Trained batch 1273 in epoch 2, gen_loss = 1.4932398126114108, disc_loss = 0.010204360418199318
Trained batch 1274 in epoch 2, gen_loss = 1.4933475178363276, disc_loss = 0.010197566359523026
Trained batch 1275 in epoch 2, gen_loss = 1.4933443215199773, disc_loss = 0.010191291419852694
Trained batch 1276 in epoch 2, gen_loss = 1.4933720450897934, disc_loss = 0.01018436641188757
Trained batch 1277 in epoch 2, gen_loss = 1.4938794460281706, disc_loss = 0.010179136859884133
Trained batch 1278 in epoch 2, gen_loss = 1.4939932385117305, disc_loss = 0.010172114686776852
Trained batch 1279 in epoch 2, gen_loss = 1.4942860919982195, disc_loss = 0.010165266895455716
Trained batch 1280 in epoch 2, gen_loss = 1.4944509614919146, disc_loss = 0.0101583025943136
Trained batch 1281 in epoch 2, gen_loss = 1.4946506153588734, disc_loss = 0.010151206639590972
Trained batch 1282 in epoch 2, gen_loss = 1.4945350319541997, disc_loss = 0.010143995675157075
Trained batch 1283 in epoch 2, gen_loss = 1.4944306918393786, disc_loss = 0.010137156037875955
Trained batch 1284 in epoch 2, gen_loss = 1.4945298036248766, disc_loss = 0.010130163206825764
Trained batch 1285 in epoch 2, gen_loss = 1.4946104496671104, disc_loss = 0.010123032270081581
Trained batch 1286 in epoch 2, gen_loss = 1.4946854026538046, disc_loss = 0.010116126720506623
Trained batch 1287 in epoch 2, gen_loss = 1.4950237019646981, disc_loss = 0.010109623669896503
Trained batch 1288 in epoch 2, gen_loss = 1.4949522608467736, disc_loss = 0.010103203036417409
Trained batch 1289 in epoch 2, gen_loss = 1.494942634050236, disc_loss = 0.010097467495433539
Trained batch 1290 in epoch 2, gen_loss = 1.4948103013286103, disc_loss = 0.010091749683830824
Trained batch 1291 in epoch 2, gen_loss = 1.4947353279442979, disc_loss = 0.010085515749336929
Trained batch 1292 in epoch 2, gen_loss = 1.4947725503092484, disc_loss = 0.010080262798247305
Trained batch 1293 in epoch 2, gen_loss = 1.4949640858302344, disc_loss = 0.010073941133722413
Trained batch 1294 in epoch 2, gen_loss = 1.4950345130500646, disc_loss = 0.01006723216615265
Trained batch 1295 in epoch 2, gen_loss = 1.495025051964654, disc_loss = 0.010060293249235084
Trained batch 1296 in epoch 2, gen_loss = 1.4948678274014957, disc_loss = 0.01005360589637518
Trained batch 1297 in epoch 2, gen_loss = 1.494804817006474, disc_loss = 0.010046746028909741
Trained batch 1298 in epoch 2, gen_loss = 1.4948141122433294, disc_loss = 0.010039364465391708
Trained batch 1299 in epoch 2, gen_loss = 1.4947937995653886, disc_loss = 0.010032545045318189
Trained batch 1300 in epoch 2, gen_loss = 1.4948704384731202, disc_loss = 0.010025537132440697
Trained batch 1301 in epoch 2, gen_loss = 1.494846232475773, disc_loss = 0.010018987787923041
Trained batch 1302 in epoch 2, gen_loss = 1.4949566720543874, disc_loss = 0.010011903605585938
Trained batch 1303 in epoch 2, gen_loss = 1.4949953207757576, disc_loss = 0.01000489662480387
Trained batch 1304 in epoch 2, gen_loss = 1.4950999553176179, disc_loss = 0.00999823169797477
Trained batch 1305 in epoch 2, gen_loss = 1.4953073967835804, disc_loss = 0.009991226650819583
Trained batch 1306 in epoch 2, gen_loss = 1.4953230166125133, disc_loss = 0.009984140305224251
Trained batch 1307 in epoch 2, gen_loss = 1.4953296684890711, disc_loss = 0.009978482486746546
Trained batch 1308 in epoch 2, gen_loss = 1.495413061769251, disc_loss = 0.009972359698944005
Trained batch 1309 in epoch 2, gen_loss = 1.4955309391931724, disc_loss = 0.009965403699284982
Trained batch 1310 in epoch 2, gen_loss = 1.4954883876781624, disc_loss = 0.009960088065938533
Trained batch 1311 in epoch 2, gen_loss = 1.4958176622848685, disc_loss = 0.00995339134668739
Trained batch 1312 in epoch 2, gen_loss = 1.4959704041571809, disc_loss = 0.009947455204355297
Trained batch 1313 in epoch 2, gen_loss = 1.4961664717491359, disc_loss = 0.009941063037350713
Trained batch 1314 in epoch 2, gen_loss = 1.49617239758089, disc_loss = 0.009934114922610902
Trained batch 1315 in epoch 2, gen_loss = 1.4962288793459488, disc_loss = 0.009928107402510523
Trained batch 1316 in epoch 2, gen_loss = 1.4960872672594399, disc_loss = 0.00992146917738055
Trained batch 1317 in epoch 2, gen_loss = 1.4963155082216393, disc_loss = 0.009914994608507172
Trained batch 1318 in epoch 2, gen_loss = 1.4965006751124836, disc_loss = 0.009909225857102258
Trained batch 1319 in epoch 2, gen_loss = 1.4963761293526852, disc_loss = 0.009903233063916118
Trained batch 1320 in epoch 2, gen_loss = 1.4962213476168036, disc_loss = 0.009896974290660663
Trained batch 1321 in epoch 2, gen_loss = 1.496247299860898, disc_loss = 0.009890442796717412
Trained batch 1322 in epoch 2, gen_loss = 1.496258868291715, disc_loss = 0.009883536003289452
Trained batch 1323 in epoch 2, gen_loss = 1.4963130505243456, disc_loss = 0.009877454001672623
Trained batch 1324 in epoch 2, gen_loss = 1.4961224207788144, disc_loss = 0.009870796410107704
Trained batch 1325 in epoch 2, gen_loss = 1.4960479797461095, disc_loss = 0.009864005685994102
Trained batch 1326 in epoch 2, gen_loss = 1.4963935854386456, disc_loss = 0.009857627240799334
Trained batch 1327 in epoch 2, gen_loss = 1.496244944093457, disc_loss = 0.00985122598783153
Trained batch 1328 in epoch 2, gen_loss = 1.4963266306841974, disc_loss = 0.00984512874149252
Trained batch 1329 in epoch 2, gen_loss = 1.4963463909643933, disc_loss = 0.00983832083269166
Trained batch 1330 in epoch 2, gen_loss = 1.496318558120441, disc_loss = 0.009831330177854715
Trained batch 1331 in epoch 2, gen_loss = 1.4963720298565186, disc_loss = 0.009824556752219733
Trained batch 1332 in epoch 2, gen_loss = 1.496276015995681, disc_loss = 0.009818315974066232
Trained batch 1333 in epoch 2, gen_loss = 1.4963044035381106, disc_loss = 0.009812102687273368
Trained batch 1334 in epoch 2, gen_loss = 1.4963092205676247, disc_loss = 0.009805236038972523
Trained batch 1335 in epoch 2, gen_loss = 1.496110808706569, disc_loss = 0.009798495705924547
Trained batch 1336 in epoch 2, gen_loss = 1.4961473934670038, disc_loss = 0.009791710648760402
Trained batch 1337 in epoch 2, gen_loss = 1.4961482203594771, disc_loss = 0.009785253204053278
Trained batch 1338 in epoch 2, gen_loss = 1.4962768356153733, disc_loss = 0.009778940869788963
Trained batch 1339 in epoch 2, gen_loss = 1.4964850917680939, disc_loss = 0.009772409977058623
Trained batch 1340 in epoch 2, gen_loss = 1.4965990341749766, disc_loss = 0.009765688568603846
Trained batch 1341 in epoch 2, gen_loss = 1.496475998228957, disc_loss = 0.009759206579094746
Trained batch 1342 in epoch 2, gen_loss = 1.4963490313233854, disc_loss = 0.009752507428871814
Trained batch 1343 in epoch 2, gen_loss = 1.4960764110797928, disc_loss = 0.009747073104400832
Trained batch 1344 in epoch 2, gen_loss = 1.4960646399778061, disc_loss = 0.00974076571807241
Trained batch 1345 in epoch 2, gen_loss = 1.4958694834057324, disc_loss = 0.009734650772504466
Trained batch 1346 in epoch 2, gen_loss = 1.495754984103049, disc_loss = 0.009727854005771681
Trained batch 1347 in epoch 2, gen_loss = 1.4957778337093772, disc_loss = 0.00972135842577689
Trained batch 1348 in epoch 2, gen_loss = 1.4958541538204593, disc_loss = 0.00971548150046632
Trained batch 1349 in epoch 2, gen_loss = 1.4958221644825405, disc_loss = 0.009709104433013298
Trained batch 1350 in epoch 2, gen_loss = 1.4955111774667644, disc_loss = 0.009703267112678141
Trained batch 1351 in epoch 2, gen_loss = 1.4954210426327745, disc_loss = 0.009697474328643117
Trained batch 1352 in epoch 2, gen_loss = 1.4952505514168863, disc_loss = 0.009690945362616282
Trained batch 1353 in epoch 2, gen_loss = 1.4949715133079573, disc_loss = 0.009684416193832668
Trained batch 1354 in epoch 2, gen_loss = 1.4948039761328609, disc_loss = 0.009678394188292538
Trained batch 1355 in epoch 2, gen_loss = 1.4948907889271907, disc_loss = 0.009671935783930097
Trained batch 1356 in epoch 2, gen_loss = 1.4950062686587047, disc_loss = 0.009665942476969178
Trained batch 1357 in epoch 2, gen_loss = 1.4952079285051405, disc_loss = 0.009659538288621832
Trained batch 1358 in epoch 2, gen_loss = 1.49539306884833, disc_loss = 0.009653066081656047
Trained batch 1359 in epoch 2, gen_loss = 1.495299900805249, disc_loss = 0.009646703076000181
Trained batch 1360 in epoch 2, gen_loss = 1.495434843644248, disc_loss = 0.009640111566151195
Trained batch 1361 in epoch 2, gen_loss = 1.4956279463529938, disc_loss = 0.00963330382392581
Trained batch 1362 in epoch 2, gen_loss = 1.4956666944836836, disc_loss = 0.009627416837950745
Trained batch 1363 in epoch 2, gen_loss = 1.4955028591792254, disc_loss = 0.009621859953906544
Trained batch 1364 in epoch 2, gen_loss = 1.495652707941803, disc_loss = 0.00961592653832371
Trained batch 1365 in epoch 2, gen_loss = 1.4957675286302803, disc_loss = 0.009609898676788796
Trained batch 1366 in epoch 2, gen_loss = 1.4956741649562106, disc_loss = 0.00960411284695517
Trained batch 1367 in epoch 2, gen_loss = 1.4957532922775425, disc_loss = 0.009599354809005601
Trained batch 1368 in epoch 2, gen_loss = 1.495677838802686, disc_loss = 0.009594321233631806
Trained batch 1369 in epoch 2, gen_loss = 1.4957215830357404, disc_loss = 0.009588074848972717
Trained batch 1370 in epoch 2, gen_loss = 1.4956118242311096, disc_loss = 0.009582339504740984
Trained batch 1371 in epoch 2, gen_loss = 1.4957536120977764, disc_loss = 0.009576237351312362
Trained batch 1372 in epoch 2, gen_loss = 1.4958833828514193, disc_loss = 0.009569701552352898
Trained batch 1373 in epoch 2, gen_loss = 1.4957918503051935, disc_loss = 0.00956307510370297
Trained batch 1374 in epoch 2, gen_loss = 1.4957514268701726, disc_loss = 0.009560422612544656
Trained batch 1375 in epoch 2, gen_loss = 1.495701851193295, disc_loss = 0.009555734541737726
Trained batch 1376 in epoch 2, gen_loss = 1.4956144986156112, disc_loss = 0.00954931205784555
Trained batch 1377 in epoch 2, gen_loss = 1.4956884557173111, disc_loss = 0.009542715509766977
Trained batch 1378 in epoch 2, gen_loss = 1.4957624721388785, disc_loss = 0.009536215069107245
Trained batch 1379 in epoch 2, gen_loss = 1.4958478624406069, disc_loss = 0.009531154953667968
Trained batch 1380 in epoch 2, gen_loss = 1.4958198340710827, disc_loss = 0.00952559425429391
Trained batch 1381 in epoch 2, gen_loss = 1.4957983456713764, disc_loss = 0.009519355778521576
Trained batch 1382 in epoch 2, gen_loss = 1.4955668764879801, disc_loss = 0.009513702212147845
Trained batch 1383 in epoch 2, gen_loss = 1.4954724637414678, disc_loss = 0.009508456189027749
Trained batch 1384 in epoch 2, gen_loss = 1.4954431124112235, disc_loss = 0.009502522299710884
Trained batch 1385 in epoch 2, gen_loss = 1.4953224793141022, disc_loss = 0.00949599292951325
Trained batch 1386 in epoch 2, gen_loss = 1.4953852011818807, disc_loss = 0.009489477672216313
Trained batch 1387 in epoch 2, gen_loss = 1.4953085400529142, disc_loss = 0.009483053704788465
Trained batch 1388 in epoch 2, gen_loss = 1.4954771336417476, disc_loss = 0.009476645155176199
Trained batch 1389 in epoch 2, gen_loss = 1.4954553630712222, disc_loss = 0.00947054467120429
Trained batch 1390 in epoch 2, gen_loss = 1.495359235149249, disc_loss = 0.009464302460869238
Trained batch 1391 in epoch 2, gen_loss = 1.4954072606118245, disc_loss = 0.00945789824129014
Trained batch 1392 in epoch 2, gen_loss = 1.4954132438989653, disc_loss = 0.009451733962560844
Trained batch 1393 in epoch 2, gen_loss = 1.4953189090300496, disc_loss = 0.00944514829448125
Trained batch 1394 in epoch 2, gen_loss = 1.4954101021571826, disc_loss = 0.009438828736799017
Trained batch 1395 in epoch 2, gen_loss = 1.4955180201113736, disc_loss = 0.00943256588798666
Trained batch 1396 in epoch 2, gen_loss = 1.4954859276029495, disc_loss = 0.009426521140148393
Trained batch 1397 in epoch 2, gen_loss = 1.495607415920334, disc_loss = 0.009420905680219457
Trained batch 1398 in epoch 2, gen_loss = 1.4958522540488526, disc_loss = 0.009414558379061778
Trained batch 1399 in epoch 2, gen_loss = 1.496376913530486, disc_loss = 0.009409021478952907
Trained batch 1400 in epoch 2, gen_loss = 1.4965308642574586, disc_loss = 0.00940312599424415
Trained batch 1401 in epoch 2, gen_loss = 1.496795192509677, disc_loss = 0.009397105099980423
Trained batch 1402 in epoch 2, gen_loss = 1.4967608612431684, disc_loss = 0.009390811029337386
Trained batch 1403 in epoch 2, gen_loss = 1.4968133995845447, disc_loss = 0.009384642999574139
Trained batch 1404 in epoch 2, gen_loss = 1.4968864461281122, disc_loss = 0.009380008328169107
Trained batch 1405 in epoch 2, gen_loss = 1.4968571133837423, disc_loss = 0.00937525213333072
Trained batch 1406 in epoch 2, gen_loss = 1.4967728648189118, disc_loss = 0.00936927713418026
Trained batch 1407 in epoch 2, gen_loss = 1.4967935970053077, disc_loss = 0.009363240269274022
Trained batch 1408 in epoch 2, gen_loss = 1.4969457459838953, disc_loss = 0.009357685853136906
Trained batch 1409 in epoch 2, gen_loss = 1.4970310660964208, disc_loss = 0.009351734570904588
Trained batch 1410 in epoch 2, gen_loss = 1.4967788115703493, disc_loss = 0.009346595514268027
Trained batch 1411 in epoch 2, gen_loss = 1.4968497574160524, disc_loss = 0.009342009052334132
Trained batch 1412 in epoch 2, gen_loss = 1.4966785115547747, disc_loss = 0.00933627212144598
Trained batch 1413 in epoch 2, gen_loss = 1.496546338184551, disc_loss = 0.009330896974858713
Trained batch 1414 in epoch 2, gen_loss = 1.49642068008652, disc_loss = 0.00932527091683221
Trained batch 1415 in epoch 2, gen_loss = 1.496570326009039, disc_loss = 0.009319804552422921
Trained batch 1416 in epoch 2, gen_loss = 1.4964911894808375, disc_loss = 0.009313737930767448
Trained batch 1417 in epoch 2, gen_loss = 1.4963900235038887, disc_loss = 0.00930774104449772
Trained batch 1418 in epoch 2, gen_loss = 1.496283414920003, disc_loss = 0.009304170947163572
Trained batch 1419 in epoch 2, gen_loss = 1.496369212613979, disc_loss = 0.009298976324744601
Trained batch 1420 in epoch 2, gen_loss = 1.4964037881108927, disc_loss = 0.009293330773264878
Trained batch 1421 in epoch 2, gen_loss = 1.4964442953111083, disc_loss = 0.009287235158008986
Trained batch 1422 in epoch 2, gen_loss = 1.4965099410447786, disc_loss = 0.009281036333360618
Trained batch 1423 in epoch 2, gen_loss = 1.4965747558836187, disc_loss = 0.009275002650549672
Trained batch 1424 in epoch 2, gen_loss = 1.4965033426619412, disc_loss = 0.00926910559536497
Trained batch 1425 in epoch 2, gen_loss = 1.496606079676041, disc_loss = 0.009263137236541544
Trained batch 1426 in epoch 2, gen_loss = 1.4965754272892664, disc_loss = 0.009257583216623387
Trained batch 1427 in epoch 2, gen_loss = 1.4965222142323726, disc_loss = 0.009251777973446371
Trained batch 1428 in epoch 2, gen_loss = 1.496626726391434, disc_loss = 0.009245898676708672
Trained batch 1429 in epoch 2, gen_loss = 1.4967859895912918, disc_loss = 0.0092400599340664
Trained batch 1430 in epoch 2, gen_loss = 1.496794872480535, disc_loss = 0.009233974010199061
Trained batch 1431 in epoch 2, gen_loss = 1.4967634297449495, disc_loss = 0.009228124667741762
Trained batch 1432 in epoch 2, gen_loss = 1.4965833851447574, disc_loss = 0.009222381652519042
Trained batch 1433 in epoch 2, gen_loss = 1.4966208873267286, disc_loss = 0.009216481812483069
Trained batch 1434 in epoch 2, gen_loss = 1.4967891487095, disc_loss = 0.009210492084768214
Trained batch 1435 in epoch 2, gen_loss = 1.4970319251164088, disc_loss = 0.009204399753687028
Trained batch 1436 in epoch 2, gen_loss = 1.4968966316994314, disc_loss = 0.009198301425288744
Trained batch 1437 in epoch 2, gen_loss = 1.4967821849735456, disc_loss = 0.009192433794209913
Trained batch 1438 in epoch 2, gen_loss = 1.4967101120633992, disc_loss = 0.009186589133689022
Trained batch 1439 in epoch 2, gen_loss = 1.496739771631029, disc_loss = 0.009180495722345465
Trained batch 1440 in epoch 2, gen_loss = 1.4967305006706244, disc_loss = 0.00917440650962913
Trained batch 1441 in epoch 2, gen_loss = 1.496601123254276, disc_loss = 0.00916844432646439
Trained batch 1442 in epoch 2, gen_loss = 1.4965640676575078, disc_loss = 0.009162323477931162
Trained batch 1443 in epoch 2, gen_loss = 1.4966690050763107, disc_loss = 0.009156370328682368
Trained batch 1444 in epoch 2, gen_loss = 1.4967318896191344, disc_loss = 0.009150520452539111
Trained batch 1445 in epoch 2, gen_loss = 1.496683027239756, disc_loss = 0.009144683854835897
Trained batch 1446 in epoch 2, gen_loss = 1.496609534406629, disc_loss = 0.009138982948561828
Trained batch 1447 in epoch 2, gen_loss = 1.4967141502140635, disc_loss = 0.009133147460212179
Trained batch 1448 in epoch 2, gen_loss = 1.4967725984469376, disc_loss = 0.009127438121475762
Trained batch 1449 in epoch 2, gen_loss = 1.4970575871138738, disc_loss = 0.009121682962928578
Trained batch 1450 in epoch 2, gen_loss = 1.497197565171408, disc_loss = 0.009116433371161865
Trained batch 1451 in epoch 2, gen_loss = 1.4972137929486835, disc_loss = 0.009110987321107255
Trained batch 1452 in epoch 2, gen_loss = 1.4971305448600365, disc_loss = 0.009105229630635434
Trained batch 1453 in epoch 2, gen_loss = 1.4972365042694333, disc_loss = 0.009100018528063828
Trained batch 1454 in epoch 2, gen_loss = 1.4971109636870445, disc_loss = 0.009094525722741179
Trained batch 1455 in epoch 2, gen_loss = 1.4971046322485904, disc_loss = 0.00908883171677599
Trained batch 1456 in epoch 2, gen_loss = 1.4972919947330314, disc_loss = 0.009083214010130045
Trained batch 1457 in epoch 2, gen_loss = 1.4973181799278992, disc_loss = 0.009077398130629149
Trained batch 1458 in epoch 2, gen_loss = 1.4974804870717897, disc_loss = 0.00907170887106683
Trained batch 1459 in epoch 2, gen_loss = 1.4973886987934373, disc_loss = 0.00906591736896949
Trained batch 1460 in epoch 2, gen_loss = 1.4974520563834501, disc_loss = 0.009060059754343826
Trained batch 1461 in epoch 2, gen_loss = 1.4977298694498398, disc_loss = 0.00905463453131029
Trained batch 1462 in epoch 2, gen_loss = 1.4980003654508662, disc_loss = 0.009049121807769395
Trained batch 1463 in epoch 2, gen_loss = 1.4980308827155275, disc_loss = 0.009043758999639162
Trained batch 1464 in epoch 2, gen_loss = 1.49817145985548, disc_loss = 0.00903816845412239
Trained batch 1465 in epoch 2, gen_loss = 1.4982123967732772, disc_loss = 0.009032866029883735
Trained batch 1466 in epoch 2, gen_loss = 1.497984187328336, disc_loss = 0.009027595038571945
Trained batch 1467 in epoch 2, gen_loss = 1.497980937158704, disc_loss = 0.009022306480754404
Trained batch 1468 in epoch 2, gen_loss = 1.4978716008268789, disc_loss = 0.009017314358009405
Trained batch 1469 in epoch 2, gen_loss = 1.497929853484744, disc_loss = 0.009011941220667561
Trained batch 1470 in epoch 2, gen_loss = 1.4977701426686922, disc_loss = 0.009006449774992358
Trained batch 1471 in epoch 2, gen_loss = 1.4975395260135764, disc_loss = 0.009001014444176848
Trained batch 1472 in epoch 2, gen_loss = 1.4977716422776988, disc_loss = 0.008996002373175103
Trained batch 1473 in epoch 2, gen_loss = 1.4975484256181497, disc_loss = 0.008990963579464628
Trained batch 1474 in epoch 2, gen_loss = 1.4974072788529478, disc_loss = 0.008985934718294952
Trained batch 1475 in epoch 2, gen_loss = 1.4972565334825334, disc_loss = 0.008980991164409917
Trained batch 1476 in epoch 2, gen_loss = 1.4973090610232964, disc_loss = 0.008975769221971377
Trained batch 1477 in epoch 2, gen_loss = 1.4973812750937652, disc_loss = 0.008970259726109741
Trained batch 1478 in epoch 2, gen_loss = 1.4974231329054506, disc_loss = 0.008965930249081532
Trained batch 1479 in epoch 2, gen_loss = 1.4973283450345736, disc_loss = 0.008961544922577388
Trained batch 1480 in epoch 2, gen_loss = 1.4972431775607586, disc_loss = 0.00895631830988953
Trained batch 1481 in epoch 2, gen_loss = 1.4973244198903382, disc_loss = 0.008950777972561203
Trained batch 1482 in epoch 2, gen_loss = 1.4977383824192183, disc_loss = 0.008946542786659588
Trained batch 1483 in epoch 2, gen_loss = 1.4977822315018132, disc_loss = 0.008941422454504305
Trained batch 1484 in epoch 2, gen_loss = 1.4976899710568514, disc_loss = 0.008935968677167583
Trained batch 1485 in epoch 2, gen_loss = 1.4976699151710418, disc_loss = 0.008930259472916929
Trained batch 1486 in epoch 2, gen_loss = 1.4975736192512128, disc_loss = 0.008924677245126768
Trained batch 1487 in epoch 2, gen_loss = 1.4976769524716562, disc_loss = 0.008919014873910822
Trained batch 1488 in epoch 2, gen_loss = 1.497588057498791, disc_loss = 0.008913554978164293
Trained batch 1489 in epoch 2, gen_loss = 1.4979078021625545, disc_loss = 0.00890810226889924
Trained batch 1490 in epoch 2, gen_loss = 1.4976684370750872, disc_loss = 0.008903241309906199
Trained batch 1491 in epoch 2, gen_loss = 1.4977368958514115, disc_loss = 0.00889770508443499
Trained batch 1492 in epoch 2, gen_loss = 1.4978137726122631, disc_loss = 0.008892751039093615
Trained batch 1493 in epoch 2, gen_loss = 1.498006255511778, disc_loss = 0.008887555605324062
Trained batch 1494 in epoch 2, gen_loss = 1.497980849639229, disc_loss = 0.00888202255188774
Trained batch 1495 in epoch 2, gen_loss = 1.4979260609271055, disc_loss = 0.008876372736111877
Trained batch 1496 in epoch 2, gen_loss = 1.4979692171953007, disc_loss = 0.00887129887818818
Trained batch 1497 in epoch 2, gen_loss = 1.4979071164322153, disc_loss = 0.008865893608163849
Trained batch 1498 in epoch 2, gen_loss = 1.4979227749485426, disc_loss = 0.00886080475295198
Trained batch 1499 in epoch 2, gen_loss = 1.4978019839127859, disc_loss = 0.00891023864451563
Trained batch 1500 in epoch 2, gen_loss = 1.4976713176888676, disc_loss = 0.008963521841518999
Trained batch 1501 in epoch 2, gen_loss = 1.4975660862363924, disc_loss = 0.00897377654119905
Trained batch 1502 in epoch 2, gen_loss = 1.4976932722492688, disc_loss = 0.008976134885923071
Trained batch 1503 in epoch 2, gen_loss = 1.4979018444552066, disc_loss = 0.008976426919055465
Trained batch 1504 in epoch 2, gen_loss = 1.497779512246978, disc_loss = 0.008972272982428692
Trained batch 1505 in epoch 2, gen_loss = 1.49763977116006, disc_loss = 0.008968059990619517
Trained batch 1506 in epoch 2, gen_loss = 1.4975056709955288, disc_loss = 0.008964789932530822
Trained batch 1507 in epoch 2, gen_loss = 1.4974194863905008, disc_loss = 0.008964246710913228
Trained batch 1508 in epoch 2, gen_loss = 1.497374213634539, disc_loss = 0.00896054620505002
Trained batch 1509 in epoch 2, gen_loss = 1.4973877969956555, disc_loss = 0.008956871944150444
Trained batch 1510 in epoch 2, gen_loss = 1.4974290446521903, disc_loss = 0.00895307400389969
Trained batch 1511 in epoch 2, gen_loss = 1.4976168525597406, disc_loss = 0.008948069356327843
Trained batch 1512 in epoch 2, gen_loss = 1.497478826425758, disc_loss = 0.008943047426904596
Trained batch 1513 in epoch 2, gen_loss = 1.4974513548368507, disc_loss = 0.008937630442862615
Trained batch 1514 in epoch 2, gen_loss = 1.4973379583642035, disc_loss = 0.008933423697451289
Trained batch 1515 in epoch 2, gen_loss = 1.497266394560444, disc_loss = 0.008928894791322837
Trained batch 1516 in epoch 2, gen_loss = 1.497481126650117, disc_loss = 0.008924349717202337
Trained batch 1517 in epoch 2, gen_loss = 1.4975602230221543, disc_loss = 0.00891920526781379
Trained batch 1518 in epoch 2, gen_loss = 1.4973267232061138, disc_loss = 0.008914065541328746
Trained batch 1519 in epoch 2, gen_loss = 1.4972793273235623, disc_loss = 0.008908928355212035
Trained batch 1520 in epoch 2, gen_loss = 1.4972979022357749, disc_loss = 0.008904095046546887
Trained batch 1521 in epoch 2, gen_loss = 1.4972892014331793, disc_loss = 0.008899079375162522
Trained batch 1522 in epoch 2, gen_loss = 1.4972171158831291, disc_loss = 0.0088938645476291
Trained batch 1523 in epoch 2, gen_loss = 1.4972394309018853, disc_loss = 0.008888964771050648
Trained batch 1524 in epoch 2, gen_loss = 1.4973493554162198, disc_loss = 0.00888467659855063
Trained batch 1525 in epoch 2, gen_loss = 1.4973213507026082, disc_loss = 0.008879600986118947
Trained batch 1526 in epoch 2, gen_loss = 1.4975783842876211, disc_loss = 0.008875368335458877
Trained batch 1527 in epoch 2, gen_loss = 1.4976736616869872, disc_loss = 0.00887184517953075
Trained batch 1528 in epoch 2, gen_loss = 1.4976758868808135, disc_loss = 0.008866752521473727
Trained batch 1529 in epoch 2, gen_loss = 1.4975580895648284, disc_loss = 0.008862184435285147
Trained batch 1530 in epoch 2, gen_loss = 1.4976823899887652, disc_loss = 0.008858485673792243
Trained batch 1531 in epoch 2, gen_loss = 1.4978426915858496, disc_loss = 0.008854241922499118
Trained batch 1532 in epoch 2, gen_loss = 1.4980467340173242, disc_loss = 0.008849862530656354
Trained batch 1533 in epoch 2, gen_loss = 1.4979868531227112, disc_loss = 0.008844687876864847
Trained batch 1534 in epoch 2, gen_loss = 1.498053118615663, disc_loss = 0.00884034180559039
Trained batch 1535 in epoch 2, gen_loss = 1.498297570583721, disc_loss = 0.008836188790553479
Trained batch 1536 in epoch 2, gen_loss = 1.4984472743396102, disc_loss = 0.008831564892828252
Trained batch 1537 in epoch 2, gen_loss = 1.4983928067941505, disc_loss = 0.00882653810672528
Trained batch 1538 in epoch 2, gen_loss = 1.4984558461315063, disc_loss = 0.008821319727517714
Trained batch 1539 in epoch 2, gen_loss = 1.4984117640303327, disc_loss = 0.008816267830238816
Trained batch 1540 in epoch 2, gen_loss = 1.4984325062215211, disc_loss = 0.00881104104329728
Trained batch 1541 in epoch 2, gen_loss = 1.4984502635422694, disc_loss = 0.008806217175712247
Trained batch 1542 in epoch 2, gen_loss = 1.4984928928870933, disc_loss = 0.008801135065815516
Trained batch 1543 in epoch 2, gen_loss = 1.49873608543774, disc_loss = 0.008796326729958037
Trained batch 1544 in epoch 2, gen_loss = 1.4987821923876272, disc_loss = 0.008791272767610745
Trained batch 1545 in epoch 2, gen_loss = 1.4990351364344243, disc_loss = 0.008786252382154008
Trained batch 1546 in epoch 2, gen_loss = 1.4992504982926727, disc_loss = 0.008781386097439649
Trained batch 1547 in epoch 2, gen_loss = 1.4993624759582893, disc_loss = 0.008776515414672862
Trained batch 1548 in epoch 2, gen_loss = 1.4995125197379184, disc_loss = 0.008771876789480803
Trained batch 1549 in epoch 2, gen_loss = 1.4994903529074883, disc_loss = 0.008767338290626574
Trained batch 1550 in epoch 2, gen_loss = 1.4994368193458543, disc_loss = 0.00876256537633536
Trained batch 1551 in epoch 2, gen_loss = 1.4993157285390442, disc_loss = 0.0087578111631337
Trained batch 1552 in epoch 2, gen_loss = 1.499245375721054, disc_loss = 0.008752961274960119
Trained batch 1553 in epoch 2, gen_loss = 1.4992235084298033, disc_loss = 0.008747753470422469
Trained batch 1554 in epoch 2, gen_loss = 1.499170321590264, disc_loss = 0.00874299477485242
Trained batch 1555 in epoch 2, gen_loss = 1.4992639294473555, disc_loss = 0.008738200827418668
Trained batch 1556 in epoch 2, gen_loss = 1.4991272861711016, disc_loss = 0.008733256372498879
Trained batch 1557 in epoch 2, gen_loss = 1.4993440590712777, disc_loss = 0.008729176645888827
Trained batch 1558 in epoch 2, gen_loss = 1.4995439707124134, disc_loss = 0.008724207802460755
Trained batch 1559 in epoch 2, gen_loss = 1.4995346258848141, disc_loss = 0.008719276382534866
Trained batch 1560 in epoch 2, gen_loss = 1.4993678972096416, disc_loss = 0.00871401850348097
Trained batch 1561 in epoch 2, gen_loss = 1.4995358961034524, disc_loss = 0.008708799350570747
Trained batch 1562 in epoch 2, gen_loss = 1.499536971899461, disc_loss = 0.008704246182669632
Trained batch 1563 in epoch 2, gen_loss = 1.4995064130219657, disc_loss = 0.008699755066801953
Trained batch 1564 in epoch 2, gen_loss = 1.4996147422363963, disc_loss = 0.008694650197290807
Trained batch 1565 in epoch 2, gen_loss = 1.4994505737476422, disc_loss = 0.008690077364756214
Trained batch 1566 in epoch 2, gen_loss = 1.499530969947177, disc_loss = 0.008686185821925154
Trained batch 1567 in epoch 2, gen_loss = 1.4994162988601898, disc_loss = 0.008681318230777165
Trained batch 1568 in epoch 2, gen_loss = 1.4993256361641043, disc_loss = 0.008676265271013565
Trained batch 1569 in epoch 2, gen_loss = 1.499298001550565, disc_loss = 0.008671879414139036
Trained batch 1570 in epoch 2, gen_loss = 1.4991278888919717, disc_loss = 0.008666906169823026
Trained batch 1571 in epoch 2, gen_loss = 1.4990525325291029, disc_loss = 0.008662642202642658
Trained batch 1572 in epoch 2, gen_loss = 1.4988832248674406, disc_loss = 0.008659636062561479
Trained batch 1573 in epoch 2, gen_loss = 1.4990400300849953, disc_loss = 0.00865556790285671
Trained batch 1574 in epoch 2, gen_loss = 1.498932200613476, disc_loss = 0.0086513690434448
Trained batch 1575 in epoch 2, gen_loss = 1.4989155844837276, disc_loss = 0.00864701643823643
Trained batch 1576 in epoch 2, gen_loss = 1.4988094398925482, disc_loss = 0.008642328964036517
Trained batch 1577 in epoch 2, gen_loss = 1.498758442803783, disc_loss = 0.008638676894657964
Trained batch 1578 in epoch 2, gen_loss = 1.499209471787736, disc_loss = 0.008634163120031171
Trained batch 1579 in epoch 2, gen_loss = 1.4993539771701716, disc_loss = 0.008629605665348346
Trained batch 1580 in epoch 2, gen_loss = 1.4992353006075787, disc_loss = 0.008624922523461606
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 1.3682727813720703, disc_loss = 0.0009444104507565498
Trained batch 1 in epoch 3, gen_loss = 1.571259319782257, disc_loss = 0.0009078971343114972
Trained batch 2 in epoch 3, gen_loss = 1.5624206066131592, disc_loss = 0.0008042319289719065
Trained batch 3 in epoch 3, gen_loss = 1.596773475408554, disc_loss = 0.0007333189714699984
Trained batch 4 in epoch 3, gen_loss = 1.5378822803497314, disc_loss = 0.0008408897323533892
Trained batch 5 in epoch 3, gen_loss = 1.5392521818478901, disc_loss = 0.0008324919617734849
Trained batch 6 in epoch 3, gen_loss = 1.559566787311009, disc_loss = 0.0008082868132208075
Trained batch 7 in epoch 3, gen_loss = 1.6013854146003723, disc_loss = 0.0008777488401392475
Trained batch 8 in epoch 3, gen_loss = 1.5994462569554646, disc_loss = 0.0010711132005477946
Trained batch 9 in epoch 3, gen_loss = 1.5886986136436463, disc_loss = 0.0010510162101127207
Trained batch 10 in epoch 3, gen_loss = 1.5846871571107344, disc_loss = 0.0010479348394173112
Trained batch 11 in epoch 3, gen_loss = 1.5688556333382924, disc_loss = 0.001061209652107209
Trained batch 12 in epoch 3, gen_loss = 1.5784470576506395, disc_loss = 0.001022630102502612
Trained batch 13 in epoch 3, gen_loss = 1.5813954387392317, disc_loss = 0.0009903074990558838
Trained batch 14 in epoch 3, gen_loss = 1.5805262883504232, disc_loss = 0.0009860004725245138
Trained batch 15 in epoch 3, gen_loss = 1.577532634139061, disc_loss = 0.0009969749335141387
Trained batch 16 in epoch 3, gen_loss = 1.5742415820851046, disc_loss = 0.000983746609349242
Trained batch 17 in epoch 3, gen_loss = 1.5571876234478421, disc_loss = 0.000973067951336917
Trained batch 18 in epoch 3, gen_loss = 1.5822132135692395, disc_loss = 0.0009663102253781338
Trained batch 19 in epoch 3, gen_loss = 1.5956672549247741, disc_loss = 0.0009471981262322515
Trained batch 20 in epoch 3, gen_loss = 1.6135928119931902, disc_loss = 0.0009384489995205687
Trained batch 21 in epoch 3, gen_loss = 1.600333723154935, disc_loss = 0.0009160858012778176
Trained batch 22 in epoch 3, gen_loss = 1.6008838674296504, disc_loss = 0.0009098364642578299
Trained batch 23 in epoch 3, gen_loss = 1.6014495193958282, disc_loss = 0.000891513654399508
Trained batch 24 in epoch 3, gen_loss = 1.5970318603515625, disc_loss = 0.0008751608314923942
Trained batch 25 in epoch 3, gen_loss = 1.5870110575969403, disc_loss = 0.0008656242078779122
Trained batch 26 in epoch 3, gen_loss = 1.589523054935314, disc_loss = 0.0008536089530766562
Trained batch 27 in epoch 3, gen_loss = 1.5816238905702318, disc_loss = 0.0008477690238838217
Trained batch 28 in epoch 3, gen_loss = 1.5780144354392742, disc_loss = 0.000838404364787556
Trained batch 29 in epoch 3, gen_loss = 1.5807683030764261, disc_loss = 0.0008422912195480118
Trained batch 30 in epoch 3, gen_loss = 1.5735835375324372, disc_loss = 0.0008369805422731706
Trained batch 31 in epoch 3, gen_loss = 1.5709715373814106, disc_loss = 0.0008275446416519117
Trained batch 32 in epoch 3, gen_loss = 1.5642531315485637, disc_loss = 0.000839898577947734
Trained batch 33 in epoch 3, gen_loss = 1.560663672054515, disc_loss = 0.0008299063004361576
Trained batch 34 in epoch 3, gen_loss = 1.5661726679120744, disc_loss = 0.0008228146520975445
Trained batch 35 in epoch 3, gen_loss = 1.56311211321089, disc_loss = 0.0008099656891621029
Trained batch 36 in epoch 3, gen_loss = 1.5634823747583337, disc_loss = 0.0007978757250286337
Trained batch 37 in epoch 3, gen_loss = 1.5584039468514292, disc_loss = 0.0007890693101982929
Trained batch 38 in epoch 3, gen_loss = 1.5563727128200042, disc_loss = 0.0007778859521166828
Trained batch 39 in epoch 3, gen_loss = 1.5464503645896912, disc_loss = 0.0007671927247429267
Trained batch 40 in epoch 3, gen_loss = 1.5454870113512365, disc_loss = 0.0007549270791592212
Trained batch 41 in epoch 3, gen_loss = 1.5464701170013064, disc_loss = 0.0007452793305717586
Trained batch 42 in epoch 3, gen_loss = 1.5453710583753364, disc_loss = 0.0007509927381761372
Trained batch 43 in epoch 3, gen_loss = 1.5471590947021137, disc_loss = 0.000749803596673618
Trained batch 44 in epoch 3, gen_loss = 1.5428943501578436, disc_loss = 0.0007414276433539474
Trained batch 45 in epoch 3, gen_loss = 1.5445050312125164, disc_loss = 0.0007375067387171009
Trained batch 46 in epoch 3, gen_loss = 1.5394446190367355, disc_loss = 0.0007312529493727662
Trained batch 47 in epoch 3, gen_loss = 1.5394859910011292, disc_loss = 0.0007427048797884103
Trained batch 48 in epoch 3, gen_loss = 1.5362383735423186, disc_loss = 0.0007624599770215169
Trained batch 49 in epoch 3, gen_loss = 1.537788882255554, disc_loss = 0.0007631097902776673
Trained batch 50 in epoch 3, gen_loss = 1.54132482584785, disc_loss = 0.0007543267354633951
Trained batch 51 in epoch 3, gen_loss = 1.538626287992184, disc_loss = 0.0007555840526877616
Trained batch 52 in epoch 3, gen_loss = 1.5384962648715612, disc_loss = 0.0007529788917448934
Trained batch 53 in epoch 3, gen_loss = 1.537542345347228, disc_loss = 0.0007617417372616559
Trained batch 54 in epoch 3, gen_loss = 1.532668610052629, disc_loss = 0.000764698405559598
Trained batch 55 in epoch 3, gen_loss = 1.538625378693853, disc_loss = 0.0007669636454790764
Trained batch 56 in epoch 3, gen_loss = 1.5357326185494138, disc_loss = 0.0007710224645530903
Trained batch 57 in epoch 3, gen_loss = 1.53390994359707, disc_loss = 0.0007630964186130863
Trained batch 58 in epoch 3, gen_loss = 1.5285051515546895, disc_loss = 0.0007710145994570991
Trained batch 59 in epoch 3, gen_loss = 1.5259207844734193, disc_loss = 0.0007672074284831372
Trained batch 60 in epoch 3, gen_loss = 1.5264453653429375, disc_loss = 0.0007648293427993223
Trained batch 61 in epoch 3, gen_loss = 1.5243708202915807, disc_loss = 0.0007618583448704392
Trained batch 62 in epoch 3, gen_loss = 1.5209515586731925, disc_loss = 0.0007690271572394681
Trained batch 63 in epoch 3, gen_loss = 1.5207925364375114, disc_loss = 0.0007624316467627068
Trained batch 64 in epoch 3, gen_loss = 1.5199735641479493, disc_loss = 0.0007620630848508041
Trained batch 65 in epoch 3, gen_loss = 1.5243371291594072, disc_loss = 0.0007616204454803444
Trained batch 66 in epoch 3, gen_loss = 1.5280171508219704, disc_loss = 0.0007613699834571401
Trained batch 67 in epoch 3, gen_loss = 1.5249271392822266, disc_loss = 0.0007614731405149488
Trained batch 68 in epoch 3, gen_loss = 1.5206894978233005, disc_loss = 0.000756286926554057
Trained batch 69 in epoch 3, gen_loss = 1.5174197707857404, disc_loss = 0.0007520665090331542
Trained batch 70 in epoch 3, gen_loss = 1.5192883551960261, disc_loss = 0.0007491763574595917
Trained batch 71 in epoch 3, gen_loss = 1.517311281628079, disc_loss = 0.0007443853262682549
Trained batch 72 in epoch 3, gen_loss = 1.5158003062418062, disc_loss = 0.0007463696154395807
Trained batch 73 in epoch 3, gen_loss = 1.5114497171865928, disc_loss = 0.000745212785880761
Trained batch 74 in epoch 3, gen_loss = 1.5112730614344279, disc_loss = 0.0007411996601149439
Trained batch 75 in epoch 3, gen_loss = 1.5119307276449705, disc_loss = 0.0007472421949435221
Trained batch 76 in epoch 3, gen_loss = 1.5091622944002028, disc_loss = 0.0007569443422381754
Trained batch 77 in epoch 3, gen_loss = 1.5083065460889766, disc_loss = 0.0007580006099604548
Trained batch 78 in epoch 3, gen_loss = 1.50945751576484, disc_loss = 0.0007541339974879888
Trained batch 79 in epoch 3, gen_loss = 1.510745345056057, disc_loss = 0.0007521902709413553
Trained batch 80 in epoch 3, gen_loss = 1.5089736985571591, disc_loss = 0.0007495747129634069
Trained batch 81 in epoch 3, gen_loss = 1.505467356705084, disc_loss = 0.00074962456888099
Trained batch 82 in epoch 3, gen_loss = 1.5048636284219212, disc_loss = 0.0007467119143125657
Trained batch 83 in epoch 3, gen_loss = 1.504002413579396, disc_loss = 0.0007448516092457188
Trained batch 84 in epoch 3, gen_loss = 1.5056226618149702, disc_loss = 0.000748738507836071
Trained batch 85 in epoch 3, gen_loss = 1.511897369872692, disc_loss = 0.0007460426365236513
Trained batch 86 in epoch 3, gen_loss = 1.5124849779852505, disc_loss = 0.0007460164719116714
Trained batch 87 in epoch 3, gen_loss = 1.5113509134812788, disc_loss = 0.0007409543805723926
Trained batch 88 in epoch 3, gen_loss = 1.5120546215035942, disc_loss = 0.0007376193142171656
Trained batch 89 in epoch 3, gen_loss = 1.5109139535162184, disc_loss = 0.0007336995270129087
Trained batch 90 in epoch 3, gen_loss = 1.5152372161110679, disc_loss = 0.0007348424146734792
Trained batch 91 in epoch 3, gen_loss = 1.5162602170653965, disc_loss = 0.0007375382034376304
Trained batch 92 in epoch 3, gen_loss = 1.5165478426923034, disc_loss = 0.0007342606928745305
Trained batch 93 in epoch 3, gen_loss = 1.517293449412001, disc_loss = 0.000733199344509519
Trained batch 94 in epoch 3, gen_loss = 1.5160510276493273, disc_loss = 0.0007313223374933984
Trained batch 95 in epoch 3, gen_loss = 1.5201445147395134, disc_loss = 0.0007308473695957218
Trained batch 96 in epoch 3, gen_loss = 1.5172351549581153, disc_loss = 0.0007290242581277817
Trained batch 97 in epoch 3, gen_loss = 1.5184234879454788, disc_loss = 0.0007288294861554073
Trained batch 98 in epoch 3, gen_loss = 1.5186996664663759, disc_loss = 0.0007312193726344655
Trained batch 99 in epoch 3, gen_loss = 1.5214738023281098, disc_loss = 0.0007292973334551789
Trained batch 100 in epoch 3, gen_loss = 1.5241544211264884, disc_loss = 0.0007397386635593738
Trained batch 101 in epoch 3, gen_loss = 1.5221275056109709, disc_loss = 0.0007498717901648442
Trained batch 102 in epoch 3, gen_loss = 1.5240694608503176, disc_loss = 0.0007488926495674057
Trained batch 103 in epoch 3, gen_loss = 1.5223955065011978, disc_loss = 0.000751781923519537
Trained batch 104 in epoch 3, gen_loss = 1.519827733721052, disc_loss = 0.0007524362269101575
Trained batch 105 in epoch 3, gen_loss = 1.5189277878347434, disc_loss = 0.0007517274437836846
Trained batch 106 in epoch 3, gen_loss = 1.5197365573633497, disc_loss = 0.0007494874366572144
Trained batch 107 in epoch 3, gen_loss = 1.5177866198398449, disc_loss = 0.0007476677330689401
Trained batch 108 in epoch 3, gen_loss = 1.5180487479638616, disc_loss = 0.0007431842453474469
Trained batch 109 in epoch 3, gen_loss = 1.5170062585310502, disc_loss = 0.0007428568123776296
Trained batch 110 in epoch 3, gen_loss = 1.5173116610930846, disc_loss = 0.0007404062725490312
Trained batch 111 in epoch 3, gen_loss = 1.5178556059088026, disc_loss = 0.0007374549116190922
Trained batch 112 in epoch 3, gen_loss = 1.5171687856184697, disc_loss = 0.000733851897118168
Trained batch 113 in epoch 3, gen_loss = 1.515111205870645, disc_loss = 0.0007311963693753473
Trained batch 114 in epoch 3, gen_loss = 1.5149328573890355, disc_loss = 0.0007278341157159403
Trained batch 115 in epoch 3, gen_loss = 1.5145134884735634, disc_loss = 0.0007261185889766583
Trained batch 116 in epoch 3, gen_loss = 1.5135236866453774, disc_loss = 0.0007231654273445567
Trained batch 117 in epoch 3, gen_loss = 1.5134703183578233, disc_loss = 0.0007201122093878655
Trained batch 118 in epoch 3, gen_loss = 1.512926083652913, disc_loss = 0.0007164266174209124
Trained batch 119 in epoch 3, gen_loss = 1.5105678329865138, disc_loss = 0.0007143358307075687
Trained batch 120 in epoch 3, gen_loss = 1.5117821525936284, disc_loss = 0.0007112450769732992
Trained batch 121 in epoch 3, gen_loss = 1.513127791099861, disc_loss = 0.0007082746425246606
Trained batch 122 in epoch 3, gen_loss = 1.5124525422972392, disc_loss = 0.0007056470854374451
Trained batch 123 in epoch 3, gen_loss = 1.5123920296469042, disc_loss = 0.0007022431720190892
Trained batch 124 in epoch 3, gen_loss = 1.5109043893814087, disc_loss = 0.0007038574940524995
Trained batch 125 in epoch 3, gen_loss = 1.5090870327419705, disc_loss = 0.0007025021186564118
Trained batch 126 in epoch 3, gen_loss = 1.507841185321958, disc_loss = 0.0007024675472016175
Trained batch 127 in epoch 3, gen_loss = 1.5086039742454886, disc_loss = 0.0007089149048624677
Trained batch 128 in epoch 3, gen_loss = 1.5096327029457388, disc_loss = 0.00072462060723396
Trained batch 129 in epoch 3, gen_loss = 1.5101448893547058, disc_loss = 0.0007290651466554174
Trained batch 130 in epoch 3, gen_loss = 1.5088569544653856, disc_loss = 0.0007307162821179128
Trained batch 131 in epoch 3, gen_loss = 1.5059517296877774, disc_loss = 0.0007308210355624782
Trained batch 132 in epoch 3, gen_loss = 1.5062785623665143, disc_loss = 0.0007268623304483306
Trained batch 133 in epoch 3, gen_loss = 1.503623437525621, disc_loss = 0.0007262066255997755
Trained batch 134 in epoch 3, gen_loss = 1.5052090927406594, disc_loss = 0.000724723140053727
Trained batch 135 in epoch 3, gen_loss = 1.5032778312178219, disc_loss = 0.0007222759379467735
Trained batch 136 in epoch 3, gen_loss = 1.502502406600618, disc_loss = 0.000722353545274164
Trained batch 137 in epoch 3, gen_loss = 1.5003840508668318, disc_loss = 0.0007232736348616553
Trained batch 138 in epoch 3, gen_loss = 1.5006992662553307, disc_loss = 0.0007257856260700379
Trained batch 139 in epoch 3, gen_loss = 1.501576908145632, disc_loss = 0.0007260623851574824
Trained batch 140 in epoch 3, gen_loss = 1.5026013927256807, disc_loss = 0.000724102111602638
Trained batch 141 in epoch 3, gen_loss = 1.5059326240714168, disc_loss = 0.0007234145563364711
Trained batch 142 in epoch 3, gen_loss = 1.5039672476428372, disc_loss = 0.0007233293149034147
Trained batch 143 in epoch 3, gen_loss = 1.5051725813084178, disc_loss = 0.0007236207457026467
Trained batch 144 in epoch 3, gen_loss = 1.504358875340429, disc_loss = 0.0007232675686125354
Trained batch 145 in epoch 3, gen_loss = 1.5029775426812368, disc_loss = 0.000726584796012341
Trained batch 146 in epoch 3, gen_loss = 1.5016755506294925, disc_loss = 0.0007280593537598798
Trained batch 147 in epoch 3, gen_loss = 1.5007724536431801, disc_loss = 0.0007281631331204915
Trained batch 148 in epoch 3, gen_loss = 1.4992037443506638, disc_loss = 0.00072919394377144
Trained batch 149 in epoch 3, gen_loss = 1.5014761694272358, disc_loss = 0.0007305346212039391
Trained batch 150 in epoch 3, gen_loss = 1.4992542590526556, disc_loss = 0.0007282363727691873
Trained batch 151 in epoch 3, gen_loss = 1.4980217445837825, disc_loss = 0.0007299396294049649
Trained batch 152 in epoch 3, gen_loss = 1.4985238835702535, disc_loss = 0.0007303758135165873
Trained batch 153 in epoch 3, gen_loss = 1.4995972490929939, disc_loss = 0.0007299195603518928
Trained batch 154 in epoch 3, gen_loss = 1.4977037922028573, disc_loss = 0.000727540519531636
Trained batch 155 in epoch 3, gen_loss = 1.4977893424339783, disc_loss = 0.000725707720751719
Trained batch 156 in epoch 3, gen_loss = 1.498441040895547, disc_loss = 0.0007230557573982959
Trained batch 157 in epoch 3, gen_loss = 1.498676442647282, disc_loss = 0.0007207904228737248
Trained batch 158 in epoch 3, gen_loss = 1.4995262247961272, disc_loss = 0.0007183246066319352
Trained batch 159 in epoch 3, gen_loss = 1.4977988086640834, disc_loss = 0.0007177158688136843
Trained batch 160 in epoch 3, gen_loss = 1.498596523859486, disc_loss = 0.0007156164845255036
Trained batch 161 in epoch 3, gen_loss = 1.499294242741149, disc_loss = 0.0007145312671509376
Trained batch 162 in epoch 3, gen_loss = 1.4981261060281765, disc_loss = 0.0007146267713893182
Trained batch 163 in epoch 3, gen_loss = 1.4990135547591419, disc_loss = 0.0007132713288273208
Trained batch 164 in epoch 3, gen_loss = 1.4974330959898052, disc_loss = 0.0007137998338845191
Trained batch 165 in epoch 3, gen_loss = 1.4975707473525082, disc_loss = 0.0007112218708386196
Trained batch 166 in epoch 3, gen_loss = 1.4960413692954058, disc_loss = 0.0007101193059606667
Trained batch 167 in epoch 3, gen_loss = 1.4967794524771827, disc_loss = 0.0007087663379068198
Trained batch 168 in epoch 3, gen_loss = 1.4966070955321633, disc_loss = 0.0007065595210303922
Trained batch 169 in epoch 3, gen_loss = 1.4979569820796743, disc_loss = 0.0007051894564510269
Trained batch 170 in epoch 3, gen_loss = 1.4979304744486224, disc_loss = 0.0007053431625919123
Trained batch 171 in epoch 3, gen_loss = 1.4977660976177039, disc_loss = 0.0007071699757605444
Trained batch 172 in epoch 3, gen_loss = 1.496252361060567, disc_loss = 0.0007061646144966341
Trained batch 173 in epoch 3, gen_loss = 1.495922381165384, disc_loss = 0.0007044297570079008
Trained batch 174 in epoch 3, gen_loss = 1.494966049194336, disc_loss = 0.0007023204251059464
Trained batch 175 in epoch 3, gen_loss = 1.4956482377919285, disc_loss = 0.000701004273816414
Trained batch 176 in epoch 3, gen_loss = 1.495748993367125, disc_loss = 0.0006998186062174286
Trained batch 177 in epoch 3, gen_loss = 1.4946949796730213, disc_loss = 0.000697919167251211
Trained batch 178 in epoch 3, gen_loss = 1.4940959381657606, disc_loss = 0.0006956895889763788
Trained batch 179 in epoch 3, gen_loss = 1.4951385974884033, disc_loss = 0.0006929612025689696
Trained batch 180 in epoch 3, gen_loss = 1.4976834763479496, disc_loss = 0.000691183902132222
Trained batch 181 in epoch 3, gen_loss = 1.498164041356726, disc_loss = 0.000690919996586572
Trained batch 182 in epoch 3, gen_loss = 1.4979507082798442, disc_loss = 0.0006938443255650206
Trained batch 183 in epoch 3, gen_loss = 1.4966955534789874, disc_loss = 0.0006922620903661364
Trained batch 184 in epoch 3, gen_loss = 1.4971135899827288, disc_loss = 0.0006909879074727714
Trained batch 185 in epoch 3, gen_loss = 1.4959289912254579, disc_loss = 0.000689738182622003
Trained batch 186 in epoch 3, gen_loss = 1.4961892627777262, disc_loss = 0.0006892121491740821
Trained batch 187 in epoch 3, gen_loss = 1.4965342448112813, disc_loss = 0.0006886051613695058
Trained batch 188 in epoch 3, gen_loss = 1.4953237462926794, disc_loss = 0.0006891249060149122
Trained batch 189 in epoch 3, gen_loss = 1.4951968920858283, disc_loss = 0.0006951340946742627
Trained batch 190 in epoch 3, gen_loss = 1.4956467657189094, disc_loss = 0.0007005839497222765
Trained batch 191 in epoch 3, gen_loss = 1.4972713198512793, disc_loss = 0.0007000356179105438
Trained batch 192 in epoch 3, gen_loss = 1.497412846496068, disc_loss = 0.0007003404778685334
Trained batch 193 in epoch 3, gen_loss = 1.4964089534946323, disc_loss = 0.0006977101002871443
Trained batch 194 in epoch 3, gen_loss = 1.4975141837046697, disc_loss = 0.0006967068849077735
Trained batch 195 in epoch 3, gen_loss = 1.4967580419413897, disc_loss = 0.0006971070530309997
Trained batch 196 in epoch 3, gen_loss = 1.4959504089984796, disc_loss = 0.0006965807730510481
Trained batch 197 in epoch 3, gen_loss = 1.4964914135258607, disc_loss = 0.0006950479736486967
Trained batch 198 in epoch 3, gen_loss = 1.496361549775205, disc_loss = 0.0006935056223652218
Trained batch 199 in epoch 3, gen_loss = 1.4984329748153686, disc_loss = 0.0006924587397224969
Trained batch 200 in epoch 3, gen_loss = 1.4981192925676186, disc_loss = 0.0006906105385976265
Trained batch 201 in epoch 3, gen_loss = 1.5001463252719085, disc_loss = 0.0006891715412787715
Trained batch 202 in epoch 3, gen_loss = 1.4990353907270384, disc_loss = 0.0006886286398807651
Trained batch 203 in epoch 3, gen_loss = 1.4986008610211166, disc_loss = 0.0006876693000331037
Trained batch 204 in epoch 3, gen_loss = 1.498489647376828, disc_loss = 0.0006856165382664696
Trained batch 205 in epoch 3, gen_loss = 1.4981765880168063, disc_loss = 0.0006857612135665247
Trained batch 206 in epoch 3, gen_loss = 1.4987802350002786, disc_loss = 0.0006874528378759992
Trained batch 207 in epoch 3, gen_loss = 1.4989969541247075, disc_loss = 0.0006869384937649906
Trained batch 208 in epoch 3, gen_loss = 1.5004246120817923, disc_loss = 0.000687305068217873
Trained batch 209 in epoch 3, gen_loss = 1.5011006519907997, disc_loss = 0.0006880637842446699
Trained batch 210 in epoch 3, gen_loss = 1.5011004209518433, disc_loss = 0.0006861927158666015
Trained batch 211 in epoch 3, gen_loss = 1.50045966483512, disc_loss = 0.0006844485630934733
Trained batch 212 in epoch 3, gen_loss = 1.4996984251228296, disc_loss = 0.0006825142586357813
Trained batch 213 in epoch 3, gen_loss = 1.4998424331718516, disc_loss = 0.0006806498594559233
Trained batch 214 in epoch 3, gen_loss = 1.501494595061901, disc_loss = 0.0006790864051909858
Trained batch 215 in epoch 3, gen_loss = 1.500748070301833, disc_loss = 0.0006780883306621237
Trained batch 216 in epoch 3, gen_loss = 1.5017446455318257, disc_loss = 0.0006766235680520011
Trained batch 217 in epoch 3, gen_loss = 1.5020457976454988, disc_loss = 0.000675250419990668
Trained batch 218 in epoch 3, gen_loss = 1.5015915855425133, disc_loss = 0.0006741281702065177
Trained batch 219 in epoch 3, gen_loss = 1.5018246986649253, disc_loss = 0.0006722776585031005
Trained batch 220 in epoch 3, gen_loss = 1.501476393026464, disc_loss = 0.0006707299879843756
Trained batch 221 in epoch 3, gen_loss = 1.5024681633657164, disc_loss = 0.0006693261948876662
Trained batch 222 in epoch 3, gen_loss = 1.5020976275071969, disc_loss = 0.0006678003618507249
Trained batch 223 in epoch 3, gen_loss = 1.5020310394465923, disc_loss = 0.0006660526087866206
Trained batch 224 in epoch 3, gen_loss = 1.5014855453703138, disc_loss = 0.0006641496703054549
Trained batch 225 in epoch 3, gen_loss = 1.5018662557137752, disc_loss = 0.0006625827578173547
Trained batch 226 in epoch 3, gen_loss = 1.5024658005668203, disc_loss = 0.0006605191187679743
Trained batch 227 in epoch 3, gen_loss = 1.5023276502625984, disc_loss = 0.0006601986013329384
Trained batch 228 in epoch 3, gen_loss = 1.5014828073926367, disc_loss = 0.000661764042840876
Trained batch 229 in epoch 3, gen_loss = 1.5030156560566115, disc_loss = 0.000661579399108988
Trained batch 230 in epoch 3, gen_loss = 1.502504230061651, disc_loss = 0.0006605908829639203
Trained batch 231 in epoch 3, gen_loss = 1.503218778248491, disc_loss = 0.0006602003800723871
Trained batch 232 in epoch 3, gen_loss = 1.5026160171615208, disc_loss = 0.0006595147380034755
Trained batch 233 in epoch 3, gen_loss = 1.501897053840833, disc_loss = 0.0006585612313639827
Trained batch 234 in epoch 3, gen_loss = 1.50314620504988, disc_loss = 0.0006582962359584115
Trained batch 235 in epoch 3, gen_loss = 1.501990226365752, disc_loss = 0.0006581994807135543
Trained batch 236 in epoch 3, gen_loss = 1.5024921501739115, disc_loss = 0.000658429821205074
Trained batch 237 in epoch 3, gen_loss = 1.5016590046281575, disc_loss = 0.0006578772357775548
Trained batch 238 in epoch 3, gen_loss = 1.5016412994352843, disc_loss = 0.0006562475197014271
Trained batch 239 in epoch 3, gen_loss = 1.5028398225704829, disc_loss = 0.0006549201983943931
Trained batch 240 in epoch 3, gen_loss = 1.5029359556332664, disc_loss = 0.0006528869582242545
Trained batch 241 in epoch 3, gen_loss = 1.502429991221625, disc_loss = 0.0006538500974107772
Trained batch 242 in epoch 3, gen_loss = 1.5035849054163866, disc_loss = 0.0006531885941393114
Trained batch 243 in epoch 3, gen_loss = 1.5040033142097662, disc_loss = 0.0006519971889769086
Trained batch 244 in epoch 3, gen_loss = 1.5038833301894519, disc_loss = 0.0006522803237704484
Trained batch 245 in epoch 3, gen_loss = 1.5021181237406847, disc_loss = 0.0006519351573968571
Trained batch 246 in epoch 3, gen_loss = 1.5011698152372228, disc_loss = 0.0006511717665820809
Trained batch 247 in epoch 3, gen_loss = 1.5010731821098635, disc_loss = 0.0006517898491438245
Trained batch 248 in epoch 3, gen_loss = 1.5014862391843375, disc_loss = 0.0006505692309076266
Trained batch 249 in epoch 3, gen_loss = 1.501962043762207, disc_loss = 0.0006497929046745412
Trained batch 250 in epoch 3, gen_loss = 1.501663444526642, disc_loss = 0.0006503809641270279
Trained batch 251 in epoch 3, gen_loss = 1.5007633519551111, disc_loss = 0.0006496734218556427
Trained batch 252 in epoch 3, gen_loss = 1.5005048508700647, disc_loss = 0.0006488411851929457
Trained batch 253 in epoch 3, gen_loss = 1.501586149058004, disc_loss = 0.0006475215419686004
Trained batch 254 in epoch 3, gen_loss = 1.501146232848074, disc_loss = 0.0006460968737705045
Trained batch 255 in epoch 3, gen_loss = 1.5008999300189316, disc_loss = 0.0006450448675536791
Trained batch 256 in epoch 3, gen_loss = 1.5008642093680713, disc_loss = 0.0006446405679122491
Trained batch 257 in epoch 3, gen_loss = 1.5005222896272823, disc_loss = 0.0006439705231419201
Trained batch 258 in epoch 3, gen_loss = 1.501308102865477, disc_loss = 0.0006436327224328546
Trained batch 259 in epoch 3, gen_loss = 1.5022349398869734, disc_loss = 0.00064306170416575
Trained batch 260 in epoch 3, gen_loss = 1.5022233546465293, disc_loss = 0.0006420983395104786
Trained batch 261 in epoch 3, gen_loss = 1.5025162269140928, disc_loss = 0.0006414525978332066
Trained batch 262 in epoch 3, gen_loss = 1.5019198696876206, disc_loss = 0.0006409992235150549
Trained batch 263 in epoch 3, gen_loss = 1.5015442375883912, disc_loss = 0.0006405820020683512
Trained batch 264 in epoch 3, gen_loss = 1.5007329423472566, disc_loss = 0.0006393428033608767
Trained batch 265 in epoch 3, gen_loss = 1.501916153538496, disc_loss = 0.0006379160236920006
Trained batch 266 in epoch 3, gen_loss = 1.5023679643981018, disc_loss = 0.0006366155545985019
Trained batch 267 in epoch 3, gen_loss = 1.501900986504199, disc_loss = 0.0006356866791459502
Trained batch 268 in epoch 3, gen_loss = 1.50110180980654, disc_loss = 0.0006359345617736119
Trained batch 269 in epoch 3, gen_loss = 1.502370442725994, disc_loss = 0.0006346072547280023
Trained batch 270 in epoch 3, gen_loss = 1.5030050625220437, disc_loss = 0.0006331456064786143
Trained batch 271 in epoch 3, gen_loss = 1.5016745797851507, disc_loss = 0.0006335061569937834
Trained batch 272 in epoch 3, gen_loss = 1.501462832911984, disc_loss = 0.0006344640932827096
Trained batch 273 in epoch 3, gen_loss = 1.5024123078715192, disc_loss = 0.0006341213720721485
Trained batch 274 in epoch 3, gen_loss = 1.5034870126030662, disc_loss = 0.0006337173405865377
Trained batch 275 in epoch 3, gen_loss = 1.5043458726958951, disc_loss = 0.0006330696876672016
Trained batch 276 in epoch 3, gen_loss = 1.5035614295987016, disc_loss = 0.0006324260454416437
Trained batch 277 in epoch 3, gen_loss = 1.502911589128508, disc_loss = 0.0006309824488682693
Trained batch 278 in epoch 3, gen_loss = 1.5018543821081893, disc_loss = 0.0006296641219304674
Trained batch 279 in epoch 3, gen_loss = 1.5009253608328956, disc_loss = 0.000628972887924257
Trained batch 280 in epoch 3, gen_loss = 1.5009000343784318, disc_loss = 0.0006275244250444503
Trained batch 281 in epoch 3, gen_loss = 1.5004259846734662, disc_loss = 0.0006268027067020971
Trained batch 282 in epoch 3, gen_loss = 1.5006806593480464, disc_loss = 0.0006259705221598027
Trained batch 283 in epoch 3, gen_loss = 1.500775739340715, disc_loss = 0.0006250241352409177
Trained batch 284 in epoch 3, gen_loss = 1.5014789639857777, disc_loss = 0.0006246348073003454
Trained batch 285 in epoch 3, gen_loss = 1.501922538647285, disc_loss = 0.0006244961456053767
Trained batch 286 in epoch 3, gen_loss = 1.50185884208214, disc_loss = 0.0006239288603158453
Trained batch 287 in epoch 3, gen_loss = 1.5015087984502316, disc_loss = 0.0006229570542725722
Trained batch 288 in epoch 3, gen_loss = 1.5020931109425106, disc_loss = 0.000622195587755313
Trained batch 289 in epoch 3, gen_loss = 1.5027899824339768, disc_loss = 0.000621235868110771
Trained batch 290 in epoch 3, gen_loss = 1.5025481817238928, disc_loss = 0.0006201914041559132
Trained batch 291 in epoch 3, gen_loss = 1.5023324171157733, disc_loss = 0.0006188578750780299
Trained batch 292 in epoch 3, gen_loss = 1.5024854546927755, disc_loss = 0.0006173320253476589
Trained batch 293 in epoch 3, gen_loss = 1.502154297974645, disc_loss = 0.0006157860173138974
Trained batch 294 in epoch 3, gen_loss = 1.5023669849007817, disc_loss = 0.0006142222137048335
Trained batch 295 in epoch 3, gen_loss = 1.5030874070283529, disc_loss = 0.0006128094363383432
Trained batch 296 in epoch 3, gen_loss = 1.5030166918179804, disc_loss = 0.0006118511211954885
Trained batch 297 in epoch 3, gen_loss = 1.5025904002605668, disc_loss = 0.0006111646846527446
Trained batch 298 in epoch 3, gen_loss = 1.503996195601779, disc_loss = 0.0006114261241997266
Trained batch 299 in epoch 3, gen_loss = 1.5036801024278006, disc_loss = 0.0006115577107993886
Trained batch 300 in epoch 3, gen_loss = 1.5031451054189688, disc_loss = 0.0006115029481289123
Trained batch 301 in epoch 3, gen_loss = 1.502544770967092, disc_loss = 0.0006110284316341165
Trained batch 302 in epoch 3, gen_loss = 1.5027187622026248, disc_loss = 0.0006127873310364365
Trained batch 303 in epoch 3, gen_loss = 1.5029248407012539, disc_loss = 0.0006124193094269446
Trained batch 304 in epoch 3, gen_loss = 1.5019399224734697, disc_loss = 0.0006113977146670833
Trained batch 305 in epoch 3, gen_loss = 1.5011441532303305, disc_loss = 0.0006103657402502969
Trained batch 306 in epoch 3, gen_loss = 1.5005908851126506, disc_loss = 0.0006096727722506448
Trained batch 307 in epoch 3, gen_loss = 1.5016416094519875, disc_loss = 0.0006094253022910108
Trained batch 308 in epoch 3, gen_loss = 1.50193348594468, disc_loss = 0.0006088379551626405
Trained batch 309 in epoch 3, gen_loss = 1.5023307100419074, disc_loss = 0.000607473001019248
Trained batch 310 in epoch 3, gen_loss = 1.5019808287022582, disc_loss = 0.0006066396408729327
Trained batch 311 in epoch 3, gen_loss = 1.5018014304148846, disc_loss = 0.0006056354454463312
Trained batch 312 in epoch 3, gen_loss = 1.5016168778696761, disc_loss = 0.0006049813736362543
Trained batch 313 in epoch 3, gen_loss = 1.5006054632223336, disc_loss = 0.0006044639769799201
Trained batch 314 in epoch 3, gen_loss = 1.5009178608182876, disc_loss = 0.0006035701671083058
Trained batch 315 in epoch 3, gen_loss = 1.501251495714429, disc_loss = 0.0006033088801917915
Trained batch 316 in epoch 3, gen_loss = 1.5007561655826749, disc_loss = 0.0006024100511461167
Trained batch 317 in epoch 3, gen_loss = 1.500580204732763, disc_loss = 0.0006016728645058805
Trained batch 318 in epoch 3, gen_loss = 1.5005749501404717, disc_loss = 0.0006015921213378002
Trained batch 319 in epoch 3, gen_loss = 1.50055496878922, disc_loss = 0.0006012647851093789
Trained batch 320 in epoch 3, gen_loss = 1.5012173842046863, disc_loss = 0.0006013012125238057
Trained batch 321 in epoch 3, gen_loss = 1.500640589257945, disc_loss = 0.0006013311720843664
Trained batch 322 in epoch 3, gen_loss = 1.5004147058669997, disc_loss = 0.0006009815457196266
Trained batch 323 in epoch 3, gen_loss = 1.50005089500804, disc_loss = 0.0005999876241584848
Trained batch 324 in epoch 3, gen_loss = 1.500836891761193, disc_loss = 0.0005995277620744533
Trained batch 325 in epoch 3, gen_loss = 1.5002669688382764, disc_loss = 0.000599267708006932
Trained batch 326 in epoch 3, gen_loss = 1.5000501940374344, disc_loss = 0.0005989707629901246
Trained batch 327 in epoch 3, gen_loss = 1.5005695365551042, disc_loss = 0.0005984415885638843
Trained batch 328 in epoch 3, gen_loss = 1.4996735393819838, disc_loss = 0.0006000051198995709
Trained batch 329 in epoch 3, gen_loss = 1.4993264350024136, disc_loss = 0.0005997091848367938
Trained batch 330 in epoch 3, gen_loss = 1.4988878547605071, disc_loss = 0.0005986271318371107
Trained batch 331 in epoch 3, gen_loss = 1.4992105120635895, disc_loss = 0.0005988973002731435
Trained batch 332 in epoch 3, gen_loss = 1.4987111156051223, disc_loss = 0.0005987721406445662
Trained batch 333 in epoch 3, gen_loss = 1.4982518653669756, disc_loss = 0.0005984620856798065
Trained batch 334 in epoch 3, gen_loss = 1.4975222527091183, disc_loss = 0.0005992000946451896
Trained batch 335 in epoch 3, gen_loss = 1.4972384770711262, disc_loss = 0.000599437687188107
Trained batch 336 in epoch 3, gen_loss = 1.4974440520170536, disc_loss = 0.0005992839338022314
Trained batch 337 in epoch 3, gen_loss = 1.4997603628762375, disc_loss = 0.0006003702259067992
Trained batch 338 in epoch 3, gen_loss = 1.4991813208852898, disc_loss = 0.0006017324019406831
Trained batch 339 in epoch 3, gen_loss = 1.4986354957608616, disc_loss = 0.0006012580614718472
Trained batch 340 in epoch 3, gen_loss = 1.4990659392823922, disc_loss = 0.0006006834352995977
Trained batch 341 in epoch 3, gen_loss = 1.4988125454612642, disc_loss = 0.0006006629220621895
Trained batch 342 in epoch 3, gen_loss = 1.4980471290582817, disc_loss = 0.0006024537544983301
Trained batch 343 in epoch 3, gen_loss = 1.4984706162020218, disc_loss = 0.0006044933799235285
Trained batch 344 in epoch 3, gen_loss = 1.4982386077659717, disc_loss = 0.0006036761374992278
Trained batch 345 in epoch 3, gen_loss = 1.4984427986806528, disc_loss = 0.0006026876107449751
Trained batch 346 in epoch 3, gen_loss = 1.4982456418897645, disc_loss = 0.000601902256995877
Trained batch 347 in epoch 3, gen_loss = 1.4985114630611462, disc_loss = 0.0006017954743667318
Trained batch 348 in epoch 3, gen_loss = 1.4986758925511707, disc_loss = 0.0006031134233120855
Trained batch 349 in epoch 3, gen_loss = 1.498325092792511, disc_loss = 0.000604036876590856
Trained batch 350 in epoch 3, gen_loss = 1.4975460828878941, disc_loss = 0.000603219010196215
Trained batch 351 in epoch 3, gen_loss = 1.498456128618934, disc_loss = 0.0006024667065751353
Trained batch 352 in epoch 3, gen_loss = 1.497787882518498, disc_loss = 0.0006018604571807724
Trained batch 353 in epoch 3, gen_loss = 1.4981226116250463, disc_loss = 0.0006011568974143836
Trained batch 354 in epoch 3, gen_loss = 1.4977747383251996, disc_loss = 0.000600595772799275
Trained batch 355 in epoch 3, gen_loss = 1.4970839244596075, disc_loss = 0.0006005607354157118
Trained batch 356 in epoch 3, gen_loss = 1.4968425058851056, disc_loss = 0.0006011374298752486
Trained batch 357 in epoch 3, gen_loss = 1.4963340845853923, disc_loss = 0.0006010941153424063
Trained batch 358 in epoch 3, gen_loss = 1.4967143090654549, disc_loss = 0.0006010450071653268
Trained batch 359 in epoch 3, gen_loss = 1.4973148673772811, disc_loss = 0.0006002987788734673
Trained batch 360 in epoch 3, gen_loss = 1.4967383826538467, disc_loss = 0.000599349845015996
Trained batch 361 in epoch 3, gen_loss = 1.4977879609850888, disc_loss = 0.0005986482297402848
Trained batch 362 in epoch 3, gen_loss = 1.4986089993442715, disc_loss = 0.0005985861062473097
Trained batch 363 in epoch 3, gen_loss = 1.4991515380340619, disc_loss = 0.0005975366776500788
Trained batch 364 in epoch 3, gen_loss = 1.4992204244822671, disc_loss = 0.0005965271521334167
Trained batch 365 in epoch 3, gen_loss = 1.4990800485584905, disc_loss = 0.0005960210293748981
Trained batch 366 in epoch 3, gen_loss = 1.4982739193238095, disc_loss = 0.0005953827410065937
Trained batch 367 in epoch 3, gen_loss = 1.497502803478552, disc_loss = 0.0005954608642913745
Trained batch 368 in epoch 3, gen_loss = 1.496724636897162, disc_loss = 0.0005954552114042668
Trained batch 369 in epoch 3, gen_loss = 1.497344113362802, disc_loss = 0.0005948544726109233
Trained batch 370 in epoch 3, gen_loss = 1.4967386892863683, disc_loss = 0.0005937200798207487
Trained batch 371 in epoch 3, gen_loss = 1.497518721767651, disc_loss = 0.0005932845577712782
Trained batch 372 in epoch 3, gen_loss = 1.4975036491337794, disc_loss = 0.0005925064371217132
Trained batch 373 in epoch 3, gen_loss = 1.4975785925426586, disc_loss = 0.0005915891993878021
Trained batch 374 in epoch 3, gen_loss = 1.4977584931055705, disc_loss = 0.0005906777710964282
Trained batch 375 in epoch 3, gen_loss = 1.498223531753459, disc_loss = 0.0005902545775863976
Trained batch 376 in epoch 3, gen_loss = 1.4985297630573142, disc_loss = 0.0005893987915058688
Trained batch 377 in epoch 3, gen_loss = 1.4976134139394004, disc_loss = 0.0005891137384063018
Trained batch 378 in epoch 3, gen_loss = 1.4972667297775952, disc_loss = 0.0005882679093764274
Trained batch 379 in epoch 3, gen_loss = 1.4975463572301362, disc_loss = 0.0005877639114930245
Trained batch 380 in epoch 3, gen_loss = 1.4972244191357469, disc_loss = 0.0005873833801915131
Trained batch 381 in epoch 3, gen_loss = 1.4967868602712742, disc_loss = 0.000587174590129688
Trained batch 382 in epoch 3, gen_loss = 1.4974793917827756, disc_loss = 0.0005866332888766131
Trained batch 383 in epoch 3, gen_loss = 1.4969206371655066, disc_loss = 0.0005864087221804463
Trained batch 384 in epoch 3, gen_loss = 1.4969760517021278, disc_loss = 0.0005855890682614227
Trained batch 385 in epoch 3, gen_loss = 1.4964386972121007, disc_loss = 0.0005853228469908845
Trained batch 386 in epoch 3, gen_loss = 1.4961536007642129, disc_loss = 0.0005850660727023645
Trained batch 387 in epoch 3, gen_loss = 1.4956391444525767, disc_loss = 0.0005844493204404926
Trained batch 388 in epoch 3, gen_loss = 1.4956279024673305, disc_loss = 0.0005837687007498695
Trained batch 389 in epoch 3, gen_loss = 1.4961679770396306, disc_loss = 0.0005835848490301616
Trained batch 390 in epoch 3, gen_loss = 1.4957959993416086, disc_loss = 0.0005842565816095875
Trained batch 391 in epoch 3, gen_loss = 1.495040281086552, disc_loss = 0.0005853064227564147
Trained batch 392 in epoch 3, gen_loss = 1.494041897261719, disc_loss = 0.0005847361917357475
Trained batch 393 in epoch 3, gen_loss = 1.493061022710074, disc_loss = 0.000584242487758242
Trained batch 394 in epoch 3, gen_loss = 1.4931500585773323, disc_loss = 0.000584846064875704
Trained batch 395 in epoch 3, gen_loss = 1.492851926220788, disc_loss = 0.0005850649902254879
Trained batch 396 in epoch 3, gen_loss = 1.4930966227721207, disc_loss = 0.000585142345568259
Trained batch 397 in epoch 3, gen_loss = 1.4923546484966375, disc_loss = 0.0005847244262701162
Trained batch 398 in epoch 3, gen_loss = 1.4929050655293286, disc_loss = 0.0005851419712446004
Trained batch 399 in epoch 3, gen_loss = 1.4934195321798325, disc_loss = 0.0005847279980662279
Trained batch 400 in epoch 3, gen_loss = 1.4934684695151084, disc_loss = 0.0005838528407291693
Trained batch 401 in epoch 3, gen_loss = 1.494188506508348, disc_loss = 0.0005832696592710931
Trained batch 402 in epoch 3, gen_loss = 1.4938961521863345, disc_loss = 0.0005830916487692715
Trained batch 403 in epoch 3, gen_loss = 1.4928874096067826, disc_loss = 0.0005829600680107712
Trained batch 404 in epoch 3, gen_loss = 1.492579100455767, disc_loss = 0.0005825889009384461
Trained batch 405 in epoch 3, gen_loss = 1.4924305145963659, disc_loss = 0.0005823855388398039
Trained batch 406 in epoch 3, gen_loss = 1.4922172718610458, disc_loss = 0.000581592951883523
Trained batch 407 in epoch 3, gen_loss = 1.4925815918866325, disc_loss = 0.0005808785758477718
Trained batch 408 in epoch 3, gen_loss = 1.4923328032994911, disc_loss = 0.0005800517965170776
Trained batch 409 in epoch 3, gen_loss = 1.4921789183849241, disc_loss = 0.0005793499072485536
Trained batch 410 in epoch 3, gen_loss = 1.4920557284877247, disc_loss = 0.0005787514249138181
Trained batch 411 in epoch 3, gen_loss = 1.4917173197547209, disc_loss = 0.0005790950021637576
Trained batch 412 in epoch 3, gen_loss = 1.491860027174684, disc_loss = 0.0005797981545999962
Trained batch 413 in epoch 3, gen_loss = 1.491866723926747, disc_loss = 0.0005810309219334932
Trained batch 414 in epoch 3, gen_loss = 1.4916132633944592, disc_loss = 0.0005812252133226314
Trained batch 415 in epoch 3, gen_loss = 1.491285686309521, disc_loss = 0.0005815927448705994
Trained batch 416 in epoch 3, gen_loss = 1.4908809258783464, disc_loss = 0.0005810132486928853
Trained batch 417 in epoch 3, gen_loss = 1.4915902343663303, disc_loss = 0.0005802030799187426
Trained batch 418 in epoch 3, gen_loss = 1.4906653234099432, disc_loss = 0.0005797474720928738
Trained batch 419 in epoch 3, gen_loss = 1.4901401224590483, disc_loss = 0.0005795728369516188
Trained batch 420 in epoch 3, gen_loss = 1.4894121508700264, disc_loss = 0.0005786164594325292
Trained batch 421 in epoch 3, gen_loss = 1.489330529601653, disc_loss = 0.0005779668955122434
Trained batch 422 in epoch 3, gen_loss = 1.4896325515517106, disc_loss = 0.000577418891692107
Trained batch 423 in epoch 3, gen_loss = 1.4892222428659223, disc_loss = 0.0005766754459401918
Trained batch 424 in epoch 3, gen_loss = 1.4890887566173778, disc_loss = 0.0005764927711639115
Trained batch 425 in epoch 3, gen_loss = 1.490585037520234, disc_loss = 0.0005769958500854207
Trained batch 426 in epoch 3, gen_loss = 1.491263640010664, disc_loss = 0.0005762012323295911
Trained batch 427 in epoch 3, gen_loss = 1.4914825943028815, disc_loss = 0.0005755717928002362
Trained batch 428 in epoch 3, gen_loss = 1.4910364189903775, disc_loss = 0.0005748784362901836
Trained batch 429 in epoch 3, gen_loss = 1.4908656245054202, disc_loss = 0.0005749060277594253
Trained batch 430 in epoch 3, gen_loss = 1.4912306081391267, disc_loss = 0.0005747810927335294
Trained batch 431 in epoch 3, gen_loss = 1.49215597493781, disc_loss = 0.0005742915275698544
Trained batch 432 in epoch 3, gen_loss = 1.4925378073720954, disc_loss = 0.0005736244643724354
Trained batch 433 in epoch 3, gen_loss = 1.4929635667581163, disc_loss = 0.0005732081112428246
Trained batch 434 in epoch 3, gen_loss = 1.493283748626709, disc_loss = 0.000572496111271903
Trained batch 435 in epoch 3, gen_loss = 1.4944149600256473, disc_loss = 0.0005719965832321819
Trained batch 436 in epoch 3, gen_loss = 1.49517141654235, disc_loss = 0.000571538612685535
Trained batch 437 in epoch 3, gen_loss = 1.4948613447685764, disc_loss = 0.0005708328744855849
Trained batch 438 in epoch 3, gen_loss = 1.4950111265334562, disc_loss = 0.0005700819192725766
Trained batch 439 in epoch 3, gen_loss = 1.4950342806902799, disc_loss = 0.0005693636224763891
Trained batch 440 in epoch 3, gen_loss = 1.4942932045108337, disc_loss = 0.0005687336482808771
Trained batch 441 in epoch 3, gen_loss = 1.4939667779396022, disc_loss = 0.0005680244405858211
Trained batch 442 in epoch 3, gen_loss = 1.4939908502333321, disc_loss = 0.000568037392830678
Trained batch 443 in epoch 3, gen_loss = 1.4942363138134416, disc_loss = 0.0005680640967618381
Trained batch 444 in epoch 3, gen_loss = 1.4946726533804047, disc_loss = 0.0005672781102639215
Trained batch 445 in epoch 3, gen_loss = 1.4945711001686985, disc_loss = 0.0005665485531620518
Trained batch 446 in epoch 3, gen_loss = 1.4942846999605763, disc_loss = 0.0005676346148743963
Trained batch 447 in epoch 3, gen_loss = 1.4955472443252802, disc_loss = 0.0005670260074696541
Trained batch 448 in epoch 3, gen_loss = 1.4954786775903341, disc_loss = 0.0005666477244851886
Trained batch 449 in epoch 3, gen_loss = 1.4949213830629984, disc_loss = 0.0005666472873094285
Trained batch 450 in epoch 3, gen_loss = 1.4948892331704862, disc_loss = 0.0005663787397133194
Trained batch 451 in epoch 3, gen_loss = 1.4947649667748308, disc_loss = 0.0005656286904874744
Trained batch 452 in epoch 3, gen_loss = 1.493869426760979, disc_loss = 0.0005649912004537929
Trained batch 453 in epoch 3, gen_loss = 1.4939519382258344, disc_loss = 0.0005644725896300141
Trained batch 454 in epoch 3, gen_loss = 1.4941697319785316, disc_loss = 0.0005638397239905956
Trained batch 455 in epoch 3, gen_loss = 1.4937916013755297, disc_loss = 0.0005635132874247798
Trained batch 456 in epoch 3, gen_loss = 1.4934079315782376, disc_loss = 0.0005631241765274733
Trained batch 457 in epoch 3, gen_loss = 1.4934506658383333, disc_loss = 0.0005624111414903279
Trained batch 458 in epoch 3, gen_loss = 1.4930740919507925, disc_loss = 0.0005625257452935679
Trained batch 459 in epoch 3, gen_loss = 1.4928222311579662, disc_loss = 0.000563330754749072
Trained batch 460 in epoch 3, gen_loss = 1.4924414271646362, disc_loss = 0.0005630091734992142
Trained batch 461 in epoch 3, gen_loss = 1.4925975804721123, disc_loss = 0.0005627296482856905
Trained batch 462 in epoch 3, gen_loss = 1.4934916501426285, disc_loss = 0.0005625073916679067
Trained batch 463 in epoch 3, gen_loss = 1.4939910373811065, disc_loss = 0.0005618495788126141
Trained batch 464 in epoch 3, gen_loss = 1.4941073104899416, disc_loss = 0.0005612653138751905
Trained batch 465 in epoch 3, gen_loss = 1.4942204151542402, disc_loss = 0.0005616734251894592
Trained batch 466 in epoch 3, gen_loss = 1.4946804871140507, disc_loss = 0.0005613574658458698
Trained batch 467 in epoch 3, gen_loss = 1.4949438915802882, disc_loss = 0.0005605629470291882
Trained batch 468 in epoch 3, gen_loss = 1.4951702549513468, disc_loss = 0.0005602349461029484
Trained batch 469 in epoch 3, gen_loss = 1.4952989573174336, disc_loss = 0.0005597559689355895
Trained batch 470 in epoch 3, gen_loss = 1.4957705971541677, disc_loss = 0.0005595918468346982
Trained batch 471 in epoch 3, gen_loss = 1.495243494540958, disc_loss = 0.0005599289408749782
Trained batch 472 in epoch 3, gen_loss = 1.4944232475429962, disc_loss = 0.0005601904395968706
Trained batch 473 in epoch 3, gen_loss = 1.4945341728407622, disc_loss = 0.0005597151418138916
Trained batch 474 in epoch 3, gen_loss = 1.495008749961853, disc_loss = 0.0005595578025952962
Trained batch 475 in epoch 3, gen_loss = 1.4945110027529613, disc_loss = 0.0005589902027145208
Trained batch 476 in epoch 3, gen_loss = 1.494457869409765, disc_loss = 0.0005586248276676139
Trained batch 477 in epoch 3, gen_loss = 1.4945101311516062, disc_loss = 0.0005582754903158297
Trained batch 478 in epoch 3, gen_loss = 1.4948727320529722, disc_loss = 0.0005584820548567283
Trained batch 479 in epoch 3, gen_loss = 1.4951952142020066, disc_loss = 0.0005585945791608538
Trained batch 480 in epoch 3, gen_loss = 1.4959936838387948, disc_loss = 0.0005592314548584247
Trained batch 481 in epoch 3, gen_loss = 1.4966775980233158, disc_loss = 0.0005605638171985738
Trained batch 482 in epoch 3, gen_loss = 1.4974094513286962, disc_loss = 0.0005614754102625701
Trained batch 483 in epoch 3, gen_loss = 1.4974718483026364, disc_loss = 0.0005611365325248624
Trained batch 484 in epoch 3, gen_loss = 1.4979068141622642, disc_loss = 0.0005605881772071277
Trained batch 485 in epoch 3, gen_loss = 1.498233487086041, disc_loss = 0.0005598725072132642
Trained batch 486 in epoch 3, gen_loss = 1.4985841515127882, disc_loss = 0.0005597125853182847
Trained batch 487 in epoch 3, gen_loss = 1.4988392825986518, disc_loss = 0.0005596698977525029
Trained batch 488 in epoch 3, gen_loss = 1.4988091511229065, disc_loss = 0.0005589558873937421
Trained batch 489 in epoch 3, gen_loss = 1.4989366813581817, disc_loss = 0.0005584791769827146
Trained batch 490 in epoch 3, gen_loss = 1.4990138823048889, disc_loss = 0.0005579691069011431
Trained batch 491 in epoch 3, gen_loss = 1.4990506588928099, disc_loss = 0.0005575308702047062
Trained batch 492 in epoch 3, gen_loss = 1.4990217564797546, disc_loss = 0.0005572252190125442
Trained batch 493 in epoch 3, gen_loss = 1.498881622123332, disc_loss = 0.0005568615970075006
Trained batch 494 in epoch 3, gen_loss = 1.4984103508669921, disc_loss = 0.0005561963282584335
Trained batch 495 in epoch 3, gen_loss = 1.4989542590994989, disc_loss = 0.0005555893854585931
Trained batch 496 in epoch 3, gen_loss = 1.4987820648331518, disc_loss = 0.0005551182292319808
Trained batch 497 in epoch 3, gen_loss = 1.4985222127064164, disc_loss = 0.0005545608151900904
Trained batch 498 in epoch 3, gen_loss = 1.4983187328598542, disc_loss = 0.0005539423704274719
Trained batch 499 in epoch 3, gen_loss = 1.4983915648460389, disc_loss = 0.0005533657805353869
Trained batch 500 in epoch 3, gen_loss = 1.4979086300570095, disc_loss = 0.0005528219050889046
Trained batch 501 in epoch 3, gen_loss = 1.4981269891043583, disc_loss = 0.0005522593528584696
Trained batch 502 in epoch 3, gen_loss = 1.4980196746632783, disc_loss = 0.0005515679244285775
Trained batch 503 in epoch 3, gen_loss = 1.4976878414551418, disc_loss = 0.0005516029782845021
Trained batch 504 in epoch 3, gen_loss = 1.497726845033098, disc_loss = 0.0005514912466613096
Trained batch 505 in epoch 3, gen_loss = 1.4974796279616978, disc_loss = 0.0005513807062325142
Trained batch 506 in epoch 3, gen_loss = 1.4971302672485862, disc_loss = 0.0005510126557019751
Trained batch 507 in epoch 3, gen_loss = 1.4973736808994624, disc_loss = 0.0005508471616577287
Trained batch 508 in epoch 3, gen_loss = 1.4970304364071378, disc_loss = 0.0005514294168720213
Trained batch 509 in epoch 3, gen_loss = 1.4967251459757487, disc_loss = 0.0005523355118759141
Trained batch 510 in epoch 3, gen_loss = 1.4964120658643092, disc_loss = 0.000553198695282357
Trained batch 511 in epoch 3, gen_loss = 1.4968314711004496, disc_loss = 0.0005530194181062598
Trained batch 512 in epoch 3, gen_loss = 1.496638079600492, disc_loss = 0.0005532928721080162
Trained batch 513 in epoch 3, gen_loss = 1.4964867855788204, disc_loss = 0.0005539563093060384
Trained batch 514 in epoch 3, gen_loss = 1.4965559207119987, disc_loss = 0.0005538787426894929
Trained batch 515 in epoch 3, gen_loss = 1.4959464579127555, disc_loss = 0.0005539609622126788
Trained batch 516 in epoch 3, gen_loss = 1.4962286743942497, disc_loss = 0.0005541103444775076
Trained batch 517 in epoch 3, gen_loss = 1.49636544960346, disc_loss = 0.0005535898735721121
Trained batch 518 in epoch 3, gen_loss = 1.4960951478954454, disc_loss = 0.0005528701405991533
Trained batch 519 in epoch 3, gen_loss = 1.496719321837792, disc_loss = 0.0005522335840046602
Trained batch 520 in epoch 3, gen_loss = 1.4968062742200328, disc_loss = 0.0005514986314281246
Trained batch 521 in epoch 3, gen_loss = 1.4970755111212017, disc_loss = 0.0005510531721194631
Trained batch 522 in epoch 3, gen_loss = 1.496827533322584, disc_loss = 0.0005506669369761709
Trained batch 523 in epoch 3, gen_loss = 1.4972908715255389, disc_loss = 0.0005502538619292385
Trained batch 524 in epoch 3, gen_loss = 1.4970469804037185, disc_loss = 0.0005495861297129609
Trained batch 525 in epoch 3, gen_loss = 1.4964449546183016, disc_loss = 0.0005493494875394003
Trained batch 526 in epoch 3, gen_loss = 1.4957484748829475, disc_loss = 0.0005499236986774022
Trained batch 527 in epoch 3, gen_loss = 1.4954926938270077, disc_loss = 0.0005499256803611361
Trained batch 528 in epoch 3, gen_loss = 1.4953117397647273, disc_loss = 0.0005500894268463667
Trained batch 529 in epoch 3, gen_loss = 1.4952821583118079, disc_loss = 0.0005497799225026338
Trained batch 530 in epoch 3, gen_loss = 1.4950482670196705, disc_loss = 0.0005496532848140351
Trained batch 531 in epoch 3, gen_loss = 1.494649330476173, disc_loss = 0.0005496240024731925
Trained batch 532 in epoch 3, gen_loss = 1.4953581383259613, disc_loss = 0.0005492480984405399
Trained batch 533 in epoch 3, gen_loss = 1.4950152921319455, disc_loss = 0.0005488667724257743
Trained batch 534 in epoch 3, gen_loss = 1.4945592176134341, disc_loss = 0.0005488355103042412
Trained batch 535 in epoch 3, gen_loss = 1.494742743114927, disc_loss = 0.000548622068863687
Trained batch 536 in epoch 3, gen_loss = 1.494822267269511, disc_loss = 0.0005489302536737594
Trained batch 537 in epoch 3, gen_loss = 1.4951189563620046, disc_loss = 0.000549236891204171
Trained batch 538 in epoch 3, gen_loss = 1.4948042038420357, disc_loss = 0.0005487555005716795
Trained batch 539 in epoch 3, gen_loss = 1.495266595813963, disc_loss = 0.0005486304650494949
Trained batch 540 in epoch 3, gen_loss = 1.4958267950086188, disc_loss = 0.0005481041957486108
Trained batch 541 in epoch 3, gen_loss = 1.496420891962368, disc_loss = 0.0005474870991626775
Trained batch 542 in epoch 3, gen_loss = 1.4965086308193032, disc_loss = 0.0005468020294848692
Trained batch 543 in epoch 3, gen_loss = 1.496525884112891, disc_loss = 0.0005461573548606847
Trained batch 544 in epoch 3, gen_loss = 1.496300414505355, disc_loss = 0.0005454857178179786
Trained batch 545 in epoch 3, gen_loss = 1.4963236167317344, disc_loss = 0.0005448378486660712
Trained batch 546 in epoch 3, gen_loss = 1.4961393960433207, disc_loss = 0.000544568941088
Trained batch 547 in epoch 3, gen_loss = 1.495883876824901, disc_loss = 0.0005446734974306522
Trained batch 548 in epoch 3, gen_loss = 1.4961879173046035, disc_loss = 0.0005442265239372452
Trained batch 549 in epoch 3, gen_loss = 1.4963294170119545, disc_loss = 0.0005438276105930775
Trained batch 550 in epoch 3, gen_loss = 1.4959015047917998, disc_loss = 0.0005430868792367893
Trained batch 551 in epoch 3, gen_loss = 1.4955413134201714, disc_loss = 0.0005424526197189614
Trained batch 552 in epoch 3, gen_loss = 1.4954415255817324, disc_loss = 0.000542038422998691
Trained batch 553 in epoch 3, gen_loss = 1.4951809080929532, disc_loss = 0.0005415351681570129
Trained batch 554 in epoch 3, gen_loss = 1.495849405752646, disc_loss = 0.0005412848554614528
Trained batch 555 in epoch 3, gen_loss = 1.4959318054665764, disc_loss = 0.0005420336917837539
Trained batch 556 in epoch 3, gen_loss = 1.4953592392871795, disc_loss = 0.0005437620231297362
Trained batch 557 in epoch 3, gen_loss = 1.4952741619933891, disc_loss = 0.0005443724595518502
Trained batch 558 in epoch 3, gen_loss = 1.4950467926018567, disc_loss = 0.0005445894119325585
Trained batch 559 in epoch 3, gen_loss = 1.4949240201285907, disc_loss = 0.0005452753596078505
Trained batch 560 in epoch 3, gen_loss = 1.4951288704353645, disc_loss = 0.0005459974540348552
Trained batch 561 in epoch 3, gen_loss = 1.4950219505198061, disc_loss = 0.0005459984135461865
Trained batch 562 in epoch 3, gen_loss = 1.4953190168733073, disc_loss = 0.0005454977161766296
Trained batch 563 in epoch 3, gen_loss = 1.4949387166094272, disc_loss = 0.0005450411877225001
Trained batch 564 in epoch 3, gen_loss = 1.4947563114419449, disc_loss = 0.0005445432452592108
Trained batch 565 in epoch 3, gen_loss = 1.4949472196953035, disc_loss = 0.0005440128460265663
Trained batch 566 in epoch 3, gen_loss = 1.4953329973119907, disc_loss = 0.0005434589275757238
Trained batch 567 in epoch 3, gen_loss = 1.4953532875843452, disc_loss = 0.000542758990005995
Trained batch 568 in epoch 3, gen_loss = 1.4948025677870362, disc_loss = 0.0005425324934149678
Trained batch 569 in epoch 3, gen_loss = 1.494404585528792, disc_loss = 0.000542122735299799
Trained batch 570 in epoch 3, gen_loss = 1.4945739002444907, disc_loss = 0.0005415004126881714
Trained batch 571 in epoch 3, gen_loss = 1.4937645040608787, disc_loss = 0.0005412836053564988
Trained batch 572 in epoch 3, gen_loss = 1.4946798473128473, disc_loss = 0.0005407482579914873
Trained batch 573 in epoch 3, gen_loss = 1.4949714639045635, disc_loss = 0.000540726041999923
Trained batch 574 in epoch 3, gen_loss = 1.4954249703365823, disc_loss = 0.0005405387236564622
Trained batch 575 in epoch 3, gen_loss = 1.4960906102011602, disc_loss = 0.0005400329278270672
Trained batch 576 in epoch 3, gen_loss = 1.4961374938178105, disc_loss = 0.0005394821601245549
Trained batch 577 in epoch 3, gen_loss = 1.4974461179291088, disc_loss = 0.0005395664703022369
Trained batch 578 in epoch 3, gen_loss = 1.4975920794129578, disc_loss = 0.0005398328535531009
Trained batch 579 in epoch 3, gen_loss = 1.497922587805781, disc_loss = 0.0005399858625455166
Trained batch 580 in epoch 3, gen_loss = 1.4978268640997487, disc_loss = 0.0005400506658577753
Trained batch 581 in epoch 3, gen_loss = 1.4981976710643965, disc_loss = 0.0005402360971838227
Trained batch 582 in epoch 3, gen_loss = 1.4982646985896455, disc_loss = 0.0005407365295633843
Trained batch 583 in epoch 3, gen_loss = 1.4978069083331382, disc_loss = 0.0005406674113707084
Trained batch 584 in epoch 3, gen_loss = 1.4979957030369686, disc_loss = 0.0005401959462423658
Trained batch 585 in epoch 3, gen_loss = 1.4982715108695697, disc_loss = 0.0005406477864195574
Trained batch 586 in epoch 3, gen_loss = 1.4981021139853248, disc_loss = 0.0005417399384226932
Trained batch 587 in epoch 3, gen_loss = 1.49858432420257, disc_loss = 0.000542066493173578
Trained batch 588 in epoch 3, gen_loss = 1.498433970028759, disc_loss = 0.0005419389571801243
Trained batch 589 in epoch 3, gen_loss = 1.498872623201144, disc_loss = 0.0005429862159594373
Trained batch 590 in epoch 3, gen_loss = 1.4986387807907389, disc_loss = 0.0005433631386178862
Trained batch 591 in epoch 3, gen_loss = 1.499419031916438, disc_loss = 0.000542994979671651
Trained batch 592 in epoch 3, gen_loss = 1.4994665153111013, disc_loss = 0.000543344890979326
Trained batch 593 in epoch 3, gen_loss = 1.4990797917850893, disc_loss = 0.0005429637952175019
Trained batch 594 in epoch 3, gen_loss = 1.4989734056617032, disc_loss = 0.0005429806324952682
Trained batch 595 in epoch 3, gen_loss = 1.498639322167275, disc_loss = 0.0005432747776595479
Trained batch 596 in epoch 3, gen_loss = 1.4988527863069594, disc_loss = 0.0005434134148907188
Trained batch 597 in epoch 3, gen_loss = 1.4981320444556783, disc_loss = 0.0005430257898908385
Trained batch 598 in epoch 3, gen_loss = 1.4984650908408061, disc_loss = 0.00054262592541291
Trained batch 599 in epoch 3, gen_loss = 1.4982564860582352, disc_loss = 0.0005427925088103317
Trained batch 600 in epoch 3, gen_loss = 1.4985690265645997, disc_loss = 0.0005427601710847113
Trained batch 601 in epoch 3, gen_loss = 1.4981547623773745, disc_loss = 0.000542475392352952
Trained batch 602 in epoch 3, gen_loss = 1.4978204016661762, disc_loss = 0.0005424361480069833
Trained batch 603 in epoch 3, gen_loss = 1.4979874501559909, disc_loss = 0.0005423247393570294
Trained batch 604 in epoch 3, gen_loss = 1.4978109562692563, disc_loss = 0.0005426546312197043
Trained batch 605 in epoch 3, gen_loss = 1.4978279856958798, disc_loss = 0.0005425461024522747
Trained batch 606 in epoch 3, gen_loss = 1.4977630930638195, disc_loss = 0.0005426776576091043
Trained batch 607 in epoch 3, gen_loss = 1.4974000216706802, disc_loss = 0.000542535428178924
Trained batch 608 in epoch 3, gen_loss = 1.497396673866485, disc_loss = 0.000542501906331205
Trained batch 609 in epoch 3, gen_loss = 1.4974337874865922, disc_loss = 0.0005421370305798444
Trained batch 610 in epoch 3, gen_loss = 1.4973779942126983, disc_loss = 0.0005416472727246506
Trained batch 611 in epoch 3, gen_loss = 1.4975053395321167, disc_loss = 0.0005414686128419133
Trained batch 612 in epoch 3, gen_loss = 1.4971986307016594, disc_loss = 0.0005414872788009424
Trained batch 613 in epoch 3, gen_loss = 1.4973377037902609, disc_loss = 0.0005409524139027863
Trained batch 614 in epoch 3, gen_loss = 1.4970650694234584, disc_loss = 0.0005404943823899574
Trained batch 615 in epoch 3, gen_loss = 1.4969134609420578, disc_loss = 0.0005399445043232325
Trained batch 616 in epoch 3, gen_loss = 1.4970099300001196, disc_loss = 0.0005394938673623694
Trained batch 617 in epoch 3, gen_loss = 1.4978050197984023, disc_loss = 0.0005391186083586733
Trained batch 618 in epoch 3, gen_loss = 1.4978653727902735, disc_loss = 0.000539146566451136
Trained batch 619 in epoch 3, gen_loss = 1.4982848726934002, disc_loss = 0.000539028618955091
Trained batch 620 in epoch 3, gen_loss = 1.4982422574898664, disc_loss = 0.0005387145903903688
Trained batch 621 in epoch 3, gen_loss = 1.4984844639370296, disc_loss = 0.0005390785429433925
Trained batch 622 in epoch 3, gen_loss = 1.4982951165776384, disc_loss = 0.0005389243573573363
Trained batch 623 in epoch 3, gen_loss = 1.497996758000973, disc_loss = 0.000538657473276917
Trained batch 624 in epoch 3, gen_loss = 1.4977922130584718, disc_loss = 0.0005383891715435311
Trained batch 625 in epoch 3, gen_loss = 1.4974337631521133, disc_loss = 0.0005382850838755555
Trained batch 626 in epoch 3, gen_loss = 1.4972553298804179, disc_loss = 0.0005380288127353385
Trained batch 627 in epoch 3, gen_loss = 1.4971571727922768, disc_loss = 0.000537652082871579
Trained batch 628 in epoch 3, gen_loss = 1.4973420374723232, disc_loss = 0.0005372554182109389
Trained batch 629 in epoch 3, gen_loss = 1.4970753262913417, disc_loss = 0.0005367591716339885
Trained batch 630 in epoch 3, gen_loss = 1.4969828780592904, disc_loss = 0.0005364923076488287
Trained batch 631 in epoch 3, gen_loss = 1.4968959342075299, disc_loss = 0.0005361310067880218
Trained batch 632 in epoch 3, gen_loss = 1.496578241788192, disc_loss = 0.0005358883228598421
Trained batch 633 in epoch 3, gen_loss = 1.4964916931717929, disc_loss = 0.0005356327364834874
Trained batch 634 in epoch 3, gen_loss = 1.4963909879444153, disc_loss = 0.0005352383332581839
Trained batch 635 in epoch 3, gen_loss = 1.4967607679606985, disc_loss = 0.0005351931388032661
Trained batch 636 in epoch 3, gen_loss = 1.497281682547445, disc_loss = 0.0005356330803353881
Trained batch 637 in epoch 3, gen_loss = 1.4973699009530597, disc_loss = 0.0005354728961141187
Trained batch 638 in epoch 3, gen_loss = 1.4969496180380641, disc_loss = 0.0005352193010209059
Trained batch 639 in epoch 3, gen_loss = 1.496765057183802, disc_loss = 0.0005350095212861561
Trained batch 640 in epoch 3, gen_loss = 1.4966486294444377, disc_loss = 0.0005347832894399863
Trained batch 641 in epoch 3, gen_loss = 1.4968033239848888, disc_loss = 0.0005345320678089391
Trained batch 642 in epoch 3, gen_loss = 1.4967539104666348, disc_loss = 0.0005340403117692825
Trained batch 643 in epoch 3, gen_loss = 1.4967909072126662, disc_loss = 0.0005335275859551024
Trained batch 644 in epoch 3, gen_loss = 1.497571617503499, disc_loss = 0.0005330498813102815
Trained batch 645 in epoch 3, gen_loss = 1.497360365125048, disc_loss = 0.000532474085566409
Trained batch 646 in epoch 3, gen_loss = 1.4978010464672695, disc_loss = 0.0005319100711782573
Trained batch 647 in epoch 3, gen_loss = 1.4985104549078294, disc_loss = 0.000531514251049907
Trained batch 648 in epoch 3, gen_loss = 1.4988102102867444, disc_loss = 0.0005313607154468588
Trained batch 649 in epoch 3, gen_loss = 1.4988135722967295, disc_loss = 0.0005317885958804534
Trained batch 650 in epoch 3, gen_loss = 1.498669286477401, disc_loss = 0.0005318088075732626
Trained batch 651 in epoch 3, gen_loss = 1.4985283783242747, disc_loss = 0.0005315475574190346
Trained batch 652 in epoch 3, gen_loss = 1.4986916831587578, disc_loss = 0.0005312473598759263
Trained batch 653 in epoch 3, gen_loss = 1.498461788765152, disc_loss = 0.0005307137777559624
Trained batch 654 in epoch 3, gen_loss = 1.4985230380342207, disc_loss = 0.0005301859620372046
Trained batch 655 in epoch 3, gen_loss = 1.4991221077195027, disc_loss = 0.0005297307726966498
Trained batch 656 in epoch 3, gen_loss = 1.4995093610551622, disc_loss = 0.000529597898039937
Trained batch 657 in epoch 3, gen_loss = 1.4994253827808113, disc_loss = 0.0005293046722500331
Trained batch 658 in epoch 3, gen_loss = 1.500745051004818, disc_loss = 0.0005294107514257261
Trained batch 659 in epoch 3, gen_loss = 1.5008255367929286, disc_loss = 0.0005316601276166639
Trained batch 660 in epoch 3, gen_loss = 1.5004904506426535, disc_loss = 0.0005351439546224831
Trained batch 661 in epoch 3, gen_loss = 1.5008032604646826, disc_loss = 0.0005362502507328371
Trained batch 662 in epoch 3, gen_loss = 1.500299950530626, disc_loss = 0.0005364282270073456
Trained batch 663 in epoch 3, gen_loss = 1.5004822667463715, disc_loss = 0.0005364997429411693
Trained batch 664 in epoch 3, gen_loss = 1.4999268633978708, disc_loss = 0.0005371112792439325
Trained batch 665 in epoch 3, gen_loss = 1.5000076037985426, disc_loss = 0.0005368639635876193
Trained batch 666 in epoch 3, gen_loss = 1.5004514711371426, disc_loss = 0.0005367787133487266
Trained batch 667 in epoch 3, gen_loss = 1.500852363373705, disc_loss = 0.0005373602398539807
Trained batch 668 in epoch 3, gen_loss = 1.5011829451416996, disc_loss = 0.0005374981997865607
Trained batch 669 in epoch 3, gen_loss = 1.500922590049345, disc_loss = 0.0005373361766114205
Trained batch 670 in epoch 3, gen_loss = 1.5005564419594322, disc_loss = 0.0005369291307230101
Trained batch 671 in epoch 3, gen_loss = 1.5007142908871174, disc_loss = 0.0005365158432314708
Trained batch 672 in epoch 3, gen_loss = 1.5004770240316065, disc_loss = 0.0005360054631300968
Trained batch 673 in epoch 3, gen_loss = 1.5004917372581867, disc_loss = 0.0005362356103713505
Trained batch 674 in epoch 3, gen_loss = 1.5004599818476925, disc_loss = 0.000536658339443858
Trained batch 675 in epoch 3, gen_loss = 1.5008534325297767, disc_loss = 0.0005368722773903771
Trained batch 676 in epoch 3, gen_loss = 1.5010876604514072, disc_loss = 0.0005370737737845326
Trained batch 677 in epoch 3, gen_loss = 1.500909825869366, disc_loss = 0.000537593684339165
Trained batch 678 in epoch 3, gen_loss = 1.50065146419542, disc_loss = 0.0005380252936158181
Trained batch 679 in epoch 3, gen_loss = 1.5006166242501315, disc_loss = 0.0005380043278872857
Trained batch 680 in epoch 3, gen_loss = 1.5005740126849272, disc_loss = 0.0005383344934521607
Trained batch 681 in epoch 3, gen_loss = 1.5011375574422372, disc_loss = 0.0005383734521148808
Trained batch 682 in epoch 3, gen_loss = 1.5012245619803186, disc_loss = 0.0005381749672740207
Trained batch 683 in epoch 3, gen_loss = 1.5009059714295014, disc_loss = 0.0005377526802221199
Trained batch 684 in epoch 3, gen_loss = 1.5006850731633876, disc_loss = 0.0005373370160270536
Trained batch 685 in epoch 3, gen_loss = 1.5006361388256528, disc_loss = 0.0005371575259044224
Trained batch 686 in epoch 3, gen_loss = 1.5003734001079154, disc_loss = 0.0005368740984822963
Trained batch 687 in epoch 3, gen_loss = 1.50075159117926, disc_loss = 0.0005365278883441216
Trained batch 688 in epoch 3, gen_loss = 1.5007372933652128, disc_loss = 0.0005361718857334454
Trained batch 689 in epoch 3, gen_loss = 1.5004875098449597, disc_loss = 0.0005358451724295383
Trained batch 690 in epoch 3, gen_loss = 1.5000635554580026, disc_loss = 0.0005353700706375394
Trained batch 691 in epoch 3, gen_loss = 1.5001941299162849, disc_loss = 0.0005348630573469647
Trained batch 692 in epoch 3, gen_loss = 1.4999480292222545, disc_loss = 0.0005343291421926851
Trained batch 693 in epoch 3, gen_loss = 1.500045169327376, disc_loss = 0.0005338287669120246
Trained batch 694 in epoch 3, gen_loss = 1.500099620373129, disc_loss = 0.000533392896315438
Trained batch 695 in epoch 3, gen_loss = 1.500082118072729, disc_loss = 0.0005328500036290049
Trained batch 696 in epoch 3, gen_loss = 1.5002623120886696, disc_loss = 0.0005324869855508139
Trained batch 697 in epoch 3, gen_loss = 1.4998544229135813, disc_loss = 0.0005322370791516232
Trained batch 698 in epoch 3, gen_loss = 1.5002206981778998, disc_loss = 0.0005318357028218335
Trained batch 699 in epoch 3, gen_loss = 1.500245659010751, disc_loss = 0.0005316405998226921
Trained batch 700 in epoch 3, gen_loss = 1.5001591945680843, disc_loss = 0.0005313967854135302
Trained batch 701 in epoch 3, gen_loss = 1.5002255899953707, disc_loss = 0.0005311496697841849
Trained batch 702 in epoch 3, gen_loss = 1.5000730524022412, disc_loss = 0.0005307271839180766
Trained batch 703 in epoch 3, gen_loss = 1.4996027885512873, disc_loss = 0.0005305291406123367
Trained batch 704 in epoch 3, gen_loss = 1.4995992975032075, disc_loss = 0.0005306702626312601
Trained batch 705 in epoch 3, gen_loss = 1.4994031959147358, disc_loss = 0.000530769559732017
Trained batch 706 in epoch 3, gen_loss = 1.4991409913485256, disc_loss = 0.0005313073870252694
Trained batch 707 in epoch 3, gen_loss = 1.4988450835653617, disc_loss = 0.0005316958533286572
Trained batch 708 in epoch 3, gen_loss = 1.4985107496191652, disc_loss = 0.0005321082543430335
Trained batch 709 in epoch 3, gen_loss = 1.4985846549692288, disc_loss = 0.0005321876804834612
Trained batch 710 in epoch 3, gen_loss = 1.4986149040790886, disc_loss = 0.0005320526463457393
Trained batch 711 in epoch 3, gen_loss = 1.4989563070991065, disc_loss = 0.00053202505388184
Trained batch 712 in epoch 3, gen_loss = 1.4989404573012535, disc_loss = 0.0005317812162896534
Trained batch 713 in epoch 3, gen_loss = 1.4991265643878477, disc_loss = 0.0005313727299476379
Trained batch 714 in epoch 3, gen_loss = 1.4995013115289328, disc_loss = 0.0005310980652962075
Trained batch 715 in epoch 3, gen_loss = 1.4995708465576172, disc_loss = 0.0005309224536542601
Trained batch 716 in epoch 3, gen_loss = 1.4992066477133141, disc_loss = 0.0005312701960192017
Trained batch 717 in epoch 3, gen_loss = 1.4989069494364322, disc_loss = 0.0005314441055552658
Trained batch 718 in epoch 3, gen_loss = 1.498819453991504, disc_loss = 0.0005310444261560408
Trained batch 719 in epoch 3, gen_loss = 1.4989600835574999, disc_loss = 0.0005307719811753486
Trained batch 720 in epoch 3, gen_loss = 1.499015008526933, disc_loss = 0.0005308373871134418
Trained batch 721 in epoch 3, gen_loss = 1.4985594207890476, disc_loss = 0.0005307383969346503
Trained batch 722 in epoch 3, gen_loss = 1.4985701510190634, disc_loss = 0.000530539781669442
Trained batch 723 in epoch 3, gen_loss = 1.4985708696407507, disc_loss = 0.0005301593666234072
Trained batch 724 in epoch 3, gen_loss = 1.4983308433664255, disc_loss = 0.0005300604536173993
Trained batch 725 in epoch 3, gen_loss = 1.4983662831553415, disc_loss = 0.0005306869090578683
Trained batch 726 in epoch 3, gen_loss = 1.498357279756538, disc_loss = 0.0005314400303858093
Trained batch 727 in epoch 3, gen_loss = 1.498494457085054, disc_loss = 0.0005315859803226635
Trained batch 728 in epoch 3, gen_loss = 1.4985768333874612, disc_loss = 0.0005316847902142976
Trained batch 729 in epoch 3, gen_loss = 1.4986794564821948, disc_loss = 0.0005316356457937318
Trained batch 730 in epoch 3, gen_loss = 1.4983176399027438, disc_loss = 0.0005319827087849401
Trained batch 731 in epoch 3, gen_loss = 1.4982355261435274, disc_loss = 0.000531713424810772
Trained batch 732 in epoch 3, gen_loss = 1.4981657396722459, disc_loss = 0.0005315762000451612
Trained batch 733 in epoch 3, gen_loss = 1.498403210568493, disc_loss = 0.0005316450962203946
Trained batch 734 in epoch 3, gen_loss = 1.4982006042182041, disc_loss = 0.0005317382039906153
Trained batch 735 in epoch 3, gen_loss = 1.49822471630962, disc_loss = 0.0005318434751722594
Trained batch 736 in epoch 3, gen_loss = 1.4979217663872355, disc_loss = 0.0005319373479915095
Trained batch 737 in epoch 3, gen_loss = 1.4976081244021573, disc_loss = 0.0005318964434606856
Trained batch 738 in epoch 3, gen_loss = 1.4976370160408692, disc_loss = 0.0005321237655394018
Trained batch 739 in epoch 3, gen_loss = 1.4976090495650833, disc_loss = 0.0005325575609104645
Trained batch 740 in epoch 3, gen_loss = 1.497569329021109, disc_loss = 0.0005336858846639018
Trained batch 741 in epoch 3, gen_loss = 1.497922837894882, disc_loss = 0.000534567241399264
Trained batch 742 in epoch 3, gen_loss = 1.4973683732675833, disc_loss = 0.0005354880684763281
Trained batch 743 in epoch 3, gen_loss = 1.4976394572245177, disc_loss = 0.000536170252641852
Trained batch 744 in epoch 3, gen_loss = 1.4973383586678728, disc_loss = 0.000536191263669733
Trained batch 745 in epoch 3, gen_loss = 1.497332493837014, disc_loss = 0.000536166672043511
Trained batch 746 in epoch 3, gen_loss = 1.4968643084746927, disc_loss = 0.000535924472632429
Trained batch 747 in epoch 3, gen_loss = 1.4964462035798771, disc_loss = 0.0005358221814748246
Trained batch 748 in epoch 3, gen_loss = 1.4965061437940406, disc_loss = 0.0005355966970045057
Trained batch 749 in epoch 3, gen_loss = 1.4963129959106445, disc_loss = 0.0005353311727327915
Trained batch 750 in epoch 3, gen_loss = 1.4964282065034706, disc_loss = 0.0005350446177731156
Trained batch 751 in epoch 3, gen_loss = 1.4961966767590096, disc_loss = 0.0005346631405119935
Trained batch 752 in epoch 3, gen_loss = 1.4957788696643683, disc_loss = 0.0005345702862821874
Trained batch 753 in epoch 3, gen_loss = 1.4958847584079369, disc_loss = 0.0005349368743025031
Trained batch 754 in epoch 3, gen_loss = 1.495740961554824, disc_loss = 0.0005356783574463997
Trained batch 755 in epoch 3, gen_loss = 1.4954769280221727, disc_loss = 0.0005361324243138793
Trained batch 756 in epoch 3, gen_loss = 1.4952746654911118, disc_loss = 0.0005365668557751296
Trained batch 757 in epoch 3, gen_loss = 1.4950966674608417, disc_loss = 0.0005372684690811042
Trained batch 758 in epoch 3, gen_loss = 1.4948487457707622, disc_loss = 0.0005382489029688353
Trained batch 759 in epoch 3, gen_loss = 1.4950441631831621, disc_loss = 0.000539212784324742
Trained batch 760 in epoch 3, gen_loss = 1.494670405337751, disc_loss = 0.0005400588525556769
Trained batch 761 in epoch 3, gen_loss = 1.4943364846111908, disc_loss = 0.0005402097663482506
Trained batch 762 in epoch 3, gen_loss = 1.4946798365831688, disc_loss = 0.000539983950100191
Trained batch 763 in epoch 3, gen_loss = 1.494543500595692, disc_loss = 0.0005397250098446006
Trained batch 764 in epoch 3, gen_loss = 1.4950896543615004, disc_loss = 0.0005392865627262972
Trained batch 765 in epoch 3, gen_loss = 1.4947258903214578, disc_loss = 0.0005388709682645702
Trained batch 766 in epoch 3, gen_loss = 1.4950028926794656, disc_loss = 0.0005384480258799917
Trained batch 767 in epoch 3, gen_loss = 1.4948380310088396, disc_loss = 0.0005380506087817594
Trained batch 768 in epoch 3, gen_loss = 1.4949403739254559, disc_loss = 0.0005375626519867685
Trained batch 769 in epoch 3, gen_loss = 1.4950702247681555, disc_loss = 0.000537147922324192
Trained batch 770 in epoch 3, gen_loss = 1.4949951668193833, disc_loss = 0.000536661057062743
Trained batch 771 in epoch 3, gen_loss = 1.4953407941704586, disc_loss = 0.0005361833439428429
Trained batch 772 in epoch 3, gen_loss = 1.4952426448676441, disc_loss = 0.0005359984013210696
Trained batch 773 in epoch 3, gen_loss = 1.4953178024107172, disc_loss = 0.0005359166936769309
Trained batch 774 in epoch 3, gen_loss = 1.4952724026095483, disc_loss = 0.0005357633558319762
Trained batch 775 in epoch 3, gen_loss = 1.4950503183087123, disc_loss = 0.0005357189324077461
Trained batch 776 in epoch 3, gen_loss = 1.4950805699963368, disc_loss = 0.000535653931367573
Trained batch 777 in epoch 3, gen_loss = 1.4947399527677228, disc_loss = 0.000535601316993861
Trained batch 778 in epoch 3, gen_loss = 1.4944163335915248, disc_loss = 0.0005356385803158874
Trained batch 779 in epoch 3, gen_loss = 1.4946611465551913, disc_loss = 0.0005354278600209046
Trained batch 780 in epoch 3, gen_loss = 1.4947384524131706, disc_loss = 0.0005350364836267638
Trained batch 781 in epoch 3, gen_loss = 1.49438775485129, disc_loss = 0.0005346766653191715
Trained batch 782 in epoch 3, gen_loss = 1.494390307410619, disc_loss = 0.0005346683189378442
Trained batch 783 in epoch 3, gen_loss = 1.4943974332845942, disc_loss = 0.0005347016746169658
Trained batch 784 in epoch 3, gen_loss = 1.494329210907031, disc_loss = 0.0005345683817560399
Trained batch 785 in epoch 3, gen_loss = 1.494258618840128, disc_loss = 0.0005344838031833345
Trained batch 786 in epoch 3, gen_loss = 1.4940970554436632, disc_loss = 0.000534087500386733
Trained batch 787 in epoch 3, gen_loss = 1.4938181452642239, disc_loss = 0.0005337131391164166
Trained batch 788 in epoch 3, gen_loss = 1.4943090009447588, disc_loss = 0.0005336039681465652
Trained batch 789 in epoch 3, gen_loss = 1.4939359793180151, disc_loss = 0.0005335677561020078
Trained batch 790 in epoch 3, gen_loss = 1.4937994671531032, disc_loss = 0.0005350142027700011
Trained batch 791 in epoch 3, gen_loss = 1.4936136195454934, disc_loss = 0.0005361188629070635
Trained batch 792 in epoch 3, gen_loss = 1.493484472416689, disc_loss = 0.0005361589699722874
Trained batch 793 in epoch 3, gen_loss = 1.493883826120074, disc_loss = 0.0005361512412583357
Trained batch 794 in epoch 3, gen_loss = 1.4941566596241118, disc_loss = 0.0005358945346970416
Trained batch 795 in epoch 3, gen_loss = 1.4942631284196173, disc_loss = 0.0005356663079793686
Trained batch 796 in epoch 3, gen_loss = 1.4949607020489395, disc_loss = 0.0005360096199697974
Trained batch 797 in epoch 3, gen_loss = 1.4947332429109061, disc_loss = 0.0005363984028578276
Trained batch 798 in epoch 3, gen_loss = 1.4948982844812253, disc_loss = 0.0005366689904295118
Trained batch 799 in epoch 3, gen_loss = 1.494615513831377, disc_loss = 0.0005371191420636024
Trained batch 800 in epoch 3, gen_loss = 1.4945364967267611, disc_loss = 0.0005381370752688832
Trained batch 801 in epoch 3, gen_loss = 1.4949980407878942, disc_loss = 0.0005391338445519694
Trained batch 802 in epoch 3, gen_loss = 1.4945981158117576, disc_loss = 0.0005399897977797335
Trained batch 803 in epoch 3, gen_loss = 1.4948425046840117, disc_loss = 0.0005401099353448942
Trained batch 804 in epoch 3, gen_loss = 1.4945377752647637, disc_loss = 0.0005401229549861681
Trained batch 805 in epoch 3, gen_loss = 1.4944388592805224, disc_loss = 0.0005398978811481311
Trained batch 806 in epoch 3, gen_loss = 1.4945649280867168, disc_loss = 0.000539779039787918
Trained batch 807 in epoch 3, gen_loss = 1.494179565570142, disc_loss = 0.0005399163326206455
Trained batch 808 in epoch 3, gen_loss = 1.493710254267208, disc_loss = 0.0005395886116924181
Trained batch 809 in epoch 3, gen_loss = 1.493852064786134, disc_loss = 0.0005396221222910731
Trained batch 810 in epoch 3, gen_loss = 1.4936518960169594, disc_loss = 0.0005396657780748155
Trained batch 811 in epoch 3, gen_loss = 1.4937758115418438, disc_loss = 0.0005397513792881618
Trained batch 812 in epoch 3, gen_loss = 1.49379163518603, disc_loss = 0.0005396931514308329
Trained batch 813 in epoch 3, gen_loss = 1.4935496707220335, disc_loss = 0.0005398051876100513
Trained batch 814 in epoch 3, gen_loss = 1.494036508776659, disc_loss = 0.0005405254895938846
Trained batch 815 in epoch 3, gen_loss = 1.4940256682388924, disc_loss = 0.0005410621978109132
Trained batch 816 in epoch 3, gen_loss = 1.4940221759067756, disc_loss = 0.0005409415842149625
Trained batch 817 in epoch 3, gen_loss = 1.4945027493031509, disc_loss = 0.0005407432190066859
Trained batch 818 in epoch 3, gen_loss = 1.4943207505276206, disc_loss = 0.0005403700033350596
Trained batch 819 in epoch 3, gen_loss = 1.494110260504048, disc_loss = 0.000540098071129561
Trained batch 820 in epoch 3, gen_loss = 1.4943004090080307, disc_loss = 0.0005398285982168385
Trained batch 821 in epoch 3, gen_loss = 1.4943825270427695, disc_loss = 0.0005394502728016154
Trained batch 822 in epoch 3, gen_loss = 1.4941903823491, disc_loss = 0.0005389855712604678
Trained batch 823 in epoch 3, gen_loss = 1.4943404533330678, disc_loss = 0.0005386001838399979
Trained batch 824 in epoch 3, gen_loss = 1.4943564149105188, disc_loss = 0.0005381676333137985
Trained batch 825 in epoch 3, gen_loss = 1.494331160267098, disc_loss = 0.0005379076080270491
Trained batch 826 in epoch 3, gen_loss = 1.49415659342308, disc_loss = 0.0005376094051238663
Trained batch 827 in epoch 3, gen_loss = 1.4944096258009114, disc_loss = 0.0005375776146546991
Trained batch 828 in epoch 3, gen_loss = 1.4945390867237878, disc_loss = 0.0005379014381893379
Trained batch 829 in epoch 3, gen_loss = 1.4941914594317056, disc_loss = 0.000538327439277186
Trained batch 830 in epoch 3, gen_loss = 1.4938166021009645, disc_loss = 0.0005384180959239579
Trained batch 831 in epoch 3, gen_loss = 1.4939198794846351, disc_loss = 0.0005386035828590908
Trained batch 832 in epoch 3, gen_loss = 1.4938304764883858, disc_loss = 0.000539276307796174
Trained batch 833 in epoch 3, gen_loss = 1.4940316125357465, disc_loss = 0.000540700831529528
Trained batch 834 in epoch 3, gen_loss = 1.4936575118653075, disc_loss = 0.0005409744383089669
Trained batch 835 in epoch 3, gen_loss = 1.493751680451717, disc_loss = 0.0005407387622031628
Trained batch 836 in epoch 3, gen_loss = 1.493735914161983, disc_loss = 0.0005406992154039015
Trained batch 837 in epoch 3, gen_loss = 1.493868576313829, disc_loss = 0.0005404536827241775
Trained batch 838 in epoch 3, gen_loss = 1.4940062039515116, disc_loss = 0.0005403103792045878
Trained batch 839 in epoch 3, gen_loss = 1.4941061739410673, disc_loss = 0.000541316042134505
Trained batch 840 in epoch 3, gen_loss = 1.4937238314772616, disc_loss = 0.0005422807694841885
Trained batch 841 in epoch 3, gen_loss = 1.493454526552395, disc_loss = 0.0005421824089288513
Trained batch 842 in epoch 3, gen_loss = 1.4937082994309467, disc_loss = 0.0005418823428881771
Trained batch 843 in epoch 3, gen_loss = 1.4938280828191206, disc_loss = 0.0005416282484298505
Trained batch 844 in epoch 3, gen_loss = 1.4934829683698847, disc_loss = 0.0005412981234430253
Trained batch 845 in epoch 3, gen_loss = 1.4937866923375052, disc_loss = 0.000540995560128222
Trained batch 846 in epoch 3, gen_loss = 1.4940095282783192, disc_loss = 0.0005407812538182356
Trained batch 847 in epoch 3, gen_loss = 1.493725615008822, disc_loss = 0.0005406615098695082
Trained batch 848 in epoch 3, gen_loss = 1.4934338854957103, disc_loss = 0.0005404310725608488
Trained batch 849 in epoch 3, gen_loss = 1.4935849405737485, disc_loss = 0.0005401642621248303
Trained batch 850 in epoch 3, gen_loss = 1.4935299155294686, disc_loss = 0.0005399252168481817
Trained batch 851 in epoch 3, gen_loss = 1.4939225509133138, disc_loss = 0.0005394920243615472
Trained batch 852 in epoch 3, gen_loss = 1.4936943576875354, disc_loss = 0.0005392010728973275
Trained batch 853 in epoch 3, gen_loss = 1.493689056581859, disc_loss = 0.0005393840927171
Trained batch 854 in epoch 3, gen_loss = 1.4936278847923057, disc_loss = 0.0005402359383368636
Trained batch 855 in epoch 3, gen_loss = 1.4936361715336826, disc_loss = 0.0005417923715629802
Trained batch 856 in epoch 3, gen_loss = 1.4938183709926895, disc_loss = 0.0005421872892785956
Trained batch 857 in epoch 3, gen_loss = 1.49381225550925, disc_loss = 0.0005421412050453208
Trained batch 858 in epoch 3, gen_loss = 1.4935890257150386, disc_loss = 0.0005420809633023191
Trained batch 859 in epoch 3, gen_loss = 1.4937014005904974, disc_loss = 0.0005428480325188206
Trained batch 860 in epoch 3, gen_loss = 1.4934912733084649, disc_loss = 0.0005442470453209574
Trained batch 861 in epoch 3, gen_loss = 1.4934853475774248, disc_loss = 0.0005447607390674938
Trained batch 862 in epoch 3, gen_loss = 1.4937176725126777, disc_loss = 0.0005447441642347999
Trained batch 863 in epoch 3, gen_loss = 1.493836504165773, disc_loss = 0.0005447768483430047
Trained batch 864 in epoch 3, gen_loss = 1.4937654827371498, disc_loss = 0.0005448520932860694
Trained batch 865 in epoch 3, gen_loss = 1.493863206124471, disc_loss = 0.0005446542322936233
Trained batch 866 in epoch 3, gen_loss = 1.4936396016931588, disc_loss = 0.0005449594293289733
Trained batch 867 in epoch 3, gen_loss = 1.4935006147705465, disc_loss = 0.0005460272338667837
Trained batch 868 in epoch 3, gen_loss = 1.4936006612415555, disc_loss = 0.0005465826080665657
Trained batch 869 in epoch 3, gen_loss = 1.4934576455203967, disc_loss = 0.0005467710258163533
Trained batch 870 in epoch 3, gen_loss = 1.49329741718301, disc_loss = 0.000546880541378675
Trained batch 871 in epoch 3, gen_loss = 1.4936505252615027, disc_loss = 0.0005470035723375836
Trained batch 872 in epoch 3, gen_loss = 1.49372032609046, disc_loss = 0.0005471810566425165
Trained batch 873 in epoch 3, gen_loss = 1.4938677813968615, disc_loss = 0.0005469911017703442
Trained batch 874 in epoch 3, gen_loss = 1.493860649381365, disc_loss = 0.0005467508676727967
Trained batch 875 in epoch 3, gen_loss = 1.4940402665639032, disc_loss = 0.0005465235332421508
Trained batch 876 in epoch 3, gen_loss = 1.493968501466166, disc_loss = 0.0005463289468697332
Trained batch 877 in epoch 3, gen_loss = 1.493910831308039, disc_loss = 0.0005464920342715822
Trained batch 878 in epoch 3, gen_loss = 1.4935560976414686, disc_loss = 0.0005464556266273456
Trained batch 879 in epoch 3, gen_loss = 1.4934762357310816, disc_loss = 0.0005460854490097105
Trained batch 880 in epoch 3, gen_loss = 1.4934039770812642, disc_loss = 0.0005459033821804066
Trained batch 881 in epoch 3, gen_loss = 1.4929593793388938, disc_loss = 0.0005458499700722734
Trained batch 882 in epoch 3, gen_loss = 1.493118327309294, disc_loss = 0.0005458873948243173
Trained batch 883 in epoch 3, gen_loss = 1.493432727469578, disc_loss = 0.000545734363589362
Trained batch 884 in epoch 3, gen_loss = 1.4934226937213186, disc_loss = 0.0005453883323984189
Trained batch 885 in epoch 3, gen_loss = 1.4935898396016243, disc_loss = 0.0005451815523302843
Trained batch 886 in epoch 3, gen_loss = 1.49372178564749, disc_loss = 0.0005447825445402981
Trained batch 887 in epoch 3, gen_loss = 1.49414344373587, disc_loss = 0.000544392244338015
Trained batch 888 in epoch 3, gen_loss = 1.4942603716029628, disc_loss = 0.0005439519395883362
Trained batch 889 in epoch 3, gen_loss = 1.4943586168664225, disc_loss = 0.0005436603000990555
Trained batch 890 in epoch 3, gen_loss = 1.4940985010395413, disc_loss = 0.0005432418676594421
Trained batch 891 in epoch 3, gen_loss = 1.4941033936134902, disc_loss = 0.0005428881356927238
Trained batch 892 in epoch 3, gen_loss = 1.4949270339989316, disc_loss = 0.0005428269402675951
Trained batch 893 in epoch 3, gen_loss = 1.4947167780308648, disc_loss = 0.0005428892007297878
Trained batch 894 in epoch 3, gen_loss = 1.4943594696801468, disc_loss = 0.0005429621017960748
Trained batch 895 in epoch 3, gen_loss = 1.494279546530119, disc_loss = 0.0005425396320950833
Trained batch 896 in epoch 3, gen_loss = 1.494295427498876, disc_loss = 0.0005421887396278281
Trained batch 897 in epoch 3, gen_loss = 1.4943429436078315, disc_loss = 0.0005419220049909103
Trained batch 898 in epoch 3, gen_loss = 1.4943073549047858, disc_loss = 0.000541563626078089
Trained batch 899 in epoch 3, gen_loss = 1.494263000620736, disc_loss = 0.0005411216134638784
Trained batch 900 in epoch 3, gen_loss = 1.4938990354008732, disc_loss = 0.0005408469773783761
Trained batch 901 in epoch 3, gen_loss = 1.4940779067724612, disc_loss = 0.0005406346696576345
Trained batch 902 in epoch 3, gen_loss = 1.4937953731150326, disc_loss = 0.000540260599098057
Trained batch 903 in epoch 3, gen_loss = 1.4938623289355135, disc_loss = 0.0005398744334801836
Trained batch 904 in epoch 3, gen_loss = 1.4938251270115046, disc_loss = 0.0005394390828261738
Trained batch 905 in epoch 3, gen_loss = 1.493705877010396, disc_loss = 0.0005390742806946215
Trained batch 906 in epoch 3, gen_loss = 1.4937163312747959, disc_loss = 0.0005389693475159218
Trained batch 907 in epoch 3, gen_loss = 1.4938050196034267, disc_loss = 0.0005387023509058759
Trained batch 908 in epoch 3, gen_loss = 1.4938502501864375, disc_loss = 0.0005387793209694983
Trained batch 909 in epoch 3, gen_loss = 1.4936680336574932, disc_loss = 0.0005387319339046531
Trained batch 910 in epoch 3, gen_loss = 1.4938483549656119, disc_loss = 0.0005384253768275137
Trained batch 911 in epoch 3, gen_loss = 1.4942042644609486, disc_loss = 0.0005382433743299069
Trained batch 912 in epoch 3, gen_loss = 1.4941883909741471, disc_loss = 0.0005379279703647765
Trained batch 913 in epoch 3, gen_loss = 1.4939289515597554, disc_loss = 0.0005375504956795443
Trained batch 914 in epoch 3, gen_loss = 1.4939748448752315, disc_loss = 0.0005371696665110779
Trained batch 915 in epoch 3, gen_loss = 1.4938153087051675, disc_loss = 0.0005369464018707231
Trained batch 916 in epoch 3, gen_loss = 1.4937184596659703, disc_loss = 0.0005368094553076891
Trained batch 917 in epoch 3, gen_loss = 1.4936393699355115, disc_loss = 0.0005365325801876224
Trained batch 918 in epoch 3, gen_loss = 1.493989705779996, disc_loss = 0.0005366182414353982
Trained batch 919 in epoch 3, gen_loss = 1.4938030298637308, disc_loss = 0.0005368251620656456
Trained batch 920 in epoch 3, gen_loss = 1.4935578311046223, disc_loss = 0.0005368695814592509
Trained batch 921 in epoch 3, gen_loss = 1.493349180304306, disc_loss = 0.0005366729666387264
Trained batch 922 in epoch 3, gen_loss = 1.4930732000946094, disc_loss = 0.0005363280688825428
Trained batch 923 in epoch 3, gen_loss = 1.4935241487377133, disc_loss = 0.0005362160548496462
Trained batch 924 in epoch 3, gen_loss = 1.4934306049346924, disc_loss = 0.0005359280680312549
Trained batch 925 in epoch 3, gen_loss = 1.4932044958192896, disc_loss = 0.0005358132998981779
Trained batch 926 in epoch 3, gen_loss = 1.4930389128070818, disc_loss = 0.000536017591809224
Trained batch 927 in epoch 3, gen_loss = 1.4930300206459801, disc_loss = 0.000536019568855785
Trained batch 928 in epoch 3, gen_loss = 1.492932978051086, disc_loss = 0.0005356694680821066
Trained batch 929 in epoch 3, gen_loss = 1.4930837649171071, disc_loss = 0.0005355504460029444
Trained batch 930 in epoch 3, gen_loss = 1.4931103489196647, disc_loss = 0.0005353111605233464
Trained batch 931 in epoch 3, gen_loss = 1.4932390842826582, disc_loss = 0.0005349159457627384
Trained batch 932 in epoch 3, gen_loss = 1.4931028543433449, disc_loss = 0.0005347427178627441
Trained batch 933 in epoch 3, gen_loss = 1.4930591820649468, disc_loss = 0.0005345179408198378
Trained batch 934 in epoch 3, gen_loss = 1.492985074405364, disc_loss = 0.0005345916300812826
Trained batch 935 in epoch 3, gen_loss = 1.492971882606164, disc_loss = 0.0005344026250631397
Trained batch 936 in epoch 3, gen_loss = 1.493019205401776, disc_loss = 0.0005341052046215128
Trained batch 937 in epoch 3, gen_loss = 1.492866174371512, disc_loss = 0.0005340402500196568
Trained batch 938 in epoch 3, gen_loss = 1.492626589708054, disc_loss = 0.0005349087554547853
Trained batch 939 in epoch 3, gen_loss = 1.4926416172626171, disc_loss = 0.0005353662465263078
Trained batch 940 in epoch 3, gen_loss = 1.4924096103429034, disc_loss = 0.0005356188531095057
Trained batch 941 in epoch 3, gen_loss = 1.4922613543309984, disc_loss = 0.000535979038294733
Trained batch 942 in epoch 3, gen_loss = 1.491922819475354, disc_loss = 0.0005361488117235944
Trained batch 943 in epoch 3, gen_loss = 1.491794685564809, disc_loss = 0.00053582648140915
Trained batch 944 in epoch 3, gen_loss = 1.4920116249215667, disc_loss = 0.0005359453274794515
Trained batch 945 in epoch 3, gen_loss = 1.4918077556577847, disc_loss = 0.0005358949775072149
Trained batch 946 in epoch 3, gen_loss = 1.4916126631129505, disc_loss = 0.0005364527002271017
Trained batch 947 in epoch 3, gen_loss = 1.4916679352396147, disc_loss = 0.0005375240185373671
Trained batch 948 in epoch 3, gen_loss = 1.4916837849782818, disc_loss = 0.0005381623113373819
Trained batch 949 in epoch 3, gen_loss = 1.4920019610304582, disc_loss = 0.0005389026980724578
Trained batch 950 in epoch 3, gen_loss = 1.492241791370163, disc_loss = 0.0005389540311175308
Trained batch 951 in epoch 3, gen_loss = 1.4924320726334548, disc_loss = 0.0005387530057786909
Trained batch 952 in epoch 3, gen_loss = 1.4920510470179171, disc_loss = 0.0005387456355673131
Trained batch 953 in epoch 3, gen_loss = 1.4918073850607723, disc_loss = 0.0005386830433537847
Trained batch 954 in epoch 3, gen_loss = 1.4919611553871195, disc_loss = 0.000538692238322503
Trained batch 955 in epoch 3, gen_loss = 1.4920681354640417, disc_loss = 0.0005385870884246169
Trained batch 956 in epoch 3, gen_loss = 1.491802913268158, disc_loss = 0.0005383082513323749
Trained batch 957 in epoch 3, gen_loss = 1.491911497892567, disc_loss = 0.0005380508343719281
Trained batch 958 in epoch 3, gen_loss = 1.4919831725429817, disc_loss = 0.000537898988523438
Trained batch 959 in epoch 3, gen_loss = 1.4920280930896601, disc_loss = 0.0005379542939105401
Trained batch 960 in epoch 3, gen_loss = 1.492553221695629, disc_loss = 0.0005378859104241199
Trained batch 961 in epoch 3, gen_loss = 1.4926416103160802, disc_loss = 0.000537647645255665
Trained batch 962 in epoch 3, gen_loss = 1.4924189925565154, disc_loss = 0.0005374190479522786
Trained batch 963 in epoch 3, gen_loss = 1.4920576587010221, disc_loss = 0.0005370848019053305
Trained batch 964 in epoch 3, gen_loss = 1.4919237691503733, disc_loss = 0.0005366973947779483
Trained batch 965 in epoch 3, gen_loss = 1.4917937936743346, disc_loss = 0.0005363422254879919
Trained batch 966 in epoch 3, gen_loss = 1.491783638035006, disc_loss = 0.0005360124271702273
Trained batch 967 in epoch 3, gen_loss = 1.4916646683757955, disc_loss = 0.0005358390256836828
Trained batch 968 in epoch 3, gen_loss = 1.4917243952844657, disc_loss = 0.000535873272670678
Trained batch 969 in epoch 3, gen_loss = 1.4916356999849536, disc_loss = 0.0005366213279614254
Trained batch 970 in epoch 3, gen_loss = 1.4918420404410633, disc_loss = 0.0005369114756938329
Trained batch 971 in epoch 3, gen_loss = 1.4918441994445315, disc_loss = 0.0005367327611128092
Trained batch 972 in epoch 3, gen_loss = 1.491874184049781, disc_loss = 0.0005364918518307278
Trained batch 973 in epoch 3, gen_loss = 1.4919145216197693, disc_loss = 0.0005362317567346742
Trained batch 974 in epoch 3, gen_loss = 1.4915905157725016, disc_loss = 0.0005359894762454459
Trained batch 975 in epoch 3, gen_loss = 1.491408464239269, disc_loss = 0.000535834601906259
Trained batch 976 in epoch 3, gen_loss = 1.49120789503978, disc_loss = 0.0005356939631198965
Trained batch 977 in epoch 3, gen_loss = 1.4909552973228486, disc_loss = 0.00053542241076965
Trained batch 978 in epoch 3, gen_loss = 1.4907328088875322, disc_loss = 0.0005351258014166819
Trained batch 979 in epoch 3, gen_loss = 1.490630886384419, disc_loss = 0.0005347421648793341
Trained batch 980 in epoch 3, gen_loss = 1.4905544854814488, disc_loss = 0.0005344526147304689
Trained batch 981 in epoch 3, gen_loss = 1.4906157513742777, disc_loss = 0.0005341310043038721
Trained batch 982 in epoch 3, gen_loss = 1.4904091517049687, disc_loss = 0.0005338080205761809
Trained batch 983 in epoch 3, gen_loss = 1.4900002097938119, disc_loss = 0.0005336553326853346
Trained batch 984 in epoch 3, gen_loss = 1.489946914203276, disc_loss = 0.0005335169622135646
Trained batch 985 in epoch 3, gen_loss = 1.4901571383824455, disc_loss = 0.0005332382382167613
Trained batch 986 in epoch 3, gen_loss = 1.4905898880209725, disc_loss = 0.0005329833969284178
Trained batch 987 in epoch 3, gen_loss = 1.4907754565540112, disc_loss = 0.0005327573044674268
Trained batch 988 in epoch 3, gen_loss = 1.4905590918235276, disc_loss = 0.0005325329486415811
Trained batch 989 in epoch 3, gen_loss = 1.490300587090579, disc_loss = 0.0005323183855378172
Trained batch 990 in epoch 3, gen_loss = 1.4902193359842695, disc_loss = 0.0005319864638710083
Trained batch 991 in epoch 3, gen_loss = 1.4902848165121771, disc_loss = 0.0005316691697536894
Trained batch 992 in epoch 3, gen_loss = 1.4902838298081151, disc_loss = 0.0005312523359284161
Trained batch 993 in epoch 3, gen_loss = 1.490308275524999, disc_loss = 0.0005308870375236043
Trained batch 994 in epoch 3, gen_loss = 1.490166952741805, disc_loss = 0.0005330992002044828
Trained batch 995 in epoch 3, gen_loss = 1.4899002169988242, disc_loss = 0.0005346096397670226
Trained batch 996 in epoch 3, gen_loss = 1.4899202387933148, disc_loss = 0.0005354251174387917
Trained batch 997 in epoch 3, gen_loss = 1.4899053648860756, disc_loss = 0.0005365495503164327
Trained batch 998 in epoch 3, gen_loss = 1.4897881008841254, disc_loss = 0.0005371059029217664
Trained batch 999 in epoch 3, gen_loss = 1.4897569798231125, disc_loss = 0.0005374101748457179
Trained batch 1000 in epoch 3, gen_loss = 1.4896263645126389, disc_loss = 0.0005376930199712366
Trained batch 1001 in epoch 3, gen_loss = 1.4898696278859518, disc_loss = 0.000537729771675806
Trained batch 1002 in epoch 3, gen_loss = 1.4898645835051152, disc_loss = 0.0005375941647058827
Trained batch 1003 in epoch 3, gen_loss = 1.4896339244576564, disc_loss = 0.000537543824765566
Trained batch 1004 in epoch 3, gen_loss = 1.4897268378319433, disc_loss = 0.0005373479931937318
Trained batch 1005 in epoch 3, gen_loss = 1.489817049109912, disc_loss = 0.0005372641849397288
Trained batch 1006 in epoch 3, gen_loss = 1.489814221799788, disc_loss = 0.0005377471057282873
Trained batch 1007 in epoch 3, gen_loss = 1.4898957652705056, disc_loss = 0.0005377482911359356
Trained batch 1008 in epoch 3, gen_loss = 1.4901562918520304, disc_loss = 0.0005378111282214005
Trained batch 1009 in epoch 3, gen_loss = 1.4899564896479691, disc_loss = 0.0005380630483943047
Trained batch 1010 in epoch 3, gen_loss = 1.4901698321899957, disc_loss = 0.0005380497468335132
Trained batch 1011 in epoch 3, gen_loss = 1.490122927507393, disc_loss = 0.000537830749754389
Trained batch 1012 in epoch 3, gen_loss = 1.4898596667819761, disc_loss = 0.0005378681636665491
Trained batch 1013 in epoch 3, gen_loss = 1.4900820298778, disc_loss = 0.0005378363732890551
Trained batch 1014 in epoch 3, gen_loss = 1.4902158408329405, disc_loss = 0.0005375578159665955
Trained batch 1015 in epoch 3, gen_loss = 1.4902841291559024, disc_loss = 0.0005372991621497502
Trained batch 1016 in epoch 3, gen_loss = 1.4902231821033924, disc_loss = 0.0005372210189190967
Trained batch 1017 in epoch 3, gen_loss = 1.4901285312030546, disc_loss = 0.000537570482801485
Trained batch 1018 in epoch 3, gen_loss = 1.489730383392873, disc_loss = 0.0005380990668231945
Trained batch 1019 in epoch 3, gen_loss = 1.4895226302100162, disc_loss = 0.0005385541868414364
Trained batch 1020 in epoch 3, gen_loss = 1.4896253193277103, disc_loss = 0.0005388110609274507
Trained batch 1021 in epoch 3, gen_loss = 1.4897765077490164, disc_loss = 0.0005389944650916248
Trained batch 1022 in epoch 3, gen_loss = 1.4899710046231223, disc_loss = 0.0005387793824701176
Trained batch 1023 in epoch 3, gen_loss = 1.489805382792838, disc_loss = 0.0005387238618652646
Trained batch 1024 in epoch 3, gen_loss = 1.4900453488419696, disc_loss = 0.0005389317493919828
Trained batch 1025 in epoch 3, gen_loss = 1.4901389639977125, disc_loss = 0.0005395508680316088
Trained batch 1026 in epoch 3, gen_loss = 1.4897917966415495, disc_loss = 0.0005398594657040338
Trained batch 1027 in epoch 3, gen_loss = 1.4898895462431332, disc_loss = 0.000540315184862478
Trained batch 1028 in epoch 3, gen_loss = 1.489827387418645, disc_loss = 0.0005403518268851648
Trained batch 1029 in epoch 3, gen_loss = 1.4899632919181898, disc_loss = 0.000540685914349471
Trained batch 1030 in epoch 3, gen_loss = 1.4899824855399293, disc_loss = 0.0005407013604225488
Trained batch 1031 in epoch 3, gen_loss = 1.4898126891186072, disc_loss = 0.0005406955137879086
Trained batch 1032 in epoch 3, gen_loss = 1.4896542369338457, disc_loss = 0.0005404952818181615
Trained batch 1033 in epoch 3, gen_loss = 1.4893913026935128, disc_loss = 0.0005415789527427658
Trained batch 1034 in epoch 3, gen_loss = 1.489212289294183, disc_loss = 0.0005420378293473148
Trained batch 1035 in epoch 3, gen_loss = 1.4894277308438275, disc_loss = 0.0005422871355120179
Trained batch 1036 in epoch 3, gen_loss = 1.489190661458868, disc_loss = 0.0005421854191654602
Trained batch 1037 in epoch 3, gen_loss = 1.48906206912388, disc_loss = 0.0005420767921983105
Trained batch 1038 in epoch 3, gen_loss = 1.489317643057279, disc_loss = 0.0005420589661790386
Trained batch 1039 in epoch 3, gen_loss = 1.489470963867811, disc_loss = 0.0005419025904792272
Trained batch 1040 in epoch 3, gen_loss = 1.4894043049138974, disc_loss = 0.0005420264574096562
Trained batch 1041 in epoch 3, gen_loss = 1.4896262098182416, disc_loss = 0.000542578467380411
Trained batch 1042 in epoch 3, gen_loss = 1.4895249170859273, disc_loss = 0.0005430129131162494
Trained batch 1043 in epoch 3, gen_loss = 1.4893843834199212, disc_loss = 0.0005433911507446551
Trained batch 1044 in epoch 3, gen_loss = 1.4892529267443424, disc_loss = 0.0005433917218545211
Trained batch 1045 in epoch 3, gen_loss = 1.489091138652816, disc_loss = 0.0005434304137167077
Trained batch 1046 in epoch 3, gen_loss = 1.4888819446991826, disc_loss = 0.0005433760666959575
Trained batch 1047 in epoch 3, gen_loss = 1.4888292372454213, disc_loss = 0.0005433520789887802
Trained batch 1048 in epoch 3, gen_loss = 1.4889486550830227, disc_loss = 0.0005432561545038384
Trained batch 1049 in epoch 3, gen_loss = 1.488823216415587, disc_loss = 0.00054305300116539
Trained batch 1050 in epoch 3, gen_loss = 1.4889705177719088, disc_loss = 0.0005428144051653504
Trained batch 1051 in epoch 3, gen_loss = 1.4888636958236476, disc_loss = 0.0005425763810111012
Trained batch 1052 in epoch 3, gen_loss = 1.4886819343847653, disc_loss = 0.000542378421524161
Trained batch 1053 in epoch 3, gen_loss = 1.488590428566797, disc_loss = 0.0005420659909747625
Trained batch 1054 in epoch 3, gen_loss = 1.4884263246545295, disc_loss = 0.0005420655391721929
Trained batch 1055 in epoch 3, gen_loss = 1.4883457061016199, disc_loss = 0.0005420758689896585
Trained batch 1056 in epoch 3, gen_loss = 1.488238650103617, disc_loss = 0.0005419099475281329
Trained batch 1057 in epoch 3, gen_loss = 1.4883169538582657, disc_loss = 0.0005417190998471791
Trained batch 1058 in epoch 3, gen_loss = 1.4881792436578118, disc_loss = 0.0005415276298266452
Trained batch 1059 in epoch 3, gen_loss = 1.488109707944798, disc_loss = 0.0005414750606847382
Trained batch 1060 in epoch 3, gen_loss = 1.4881940803698612, disc_loss = 0.0005413994768186333
Trained batch 1061 in epoch 3, gen_loss = 1.4885921492863958, disc_loss = 0.0005411440908056885
Trained batch 1062 in epoch 3, gen_loss = 1.4882893232612933, disc_loss = 0.0005410399080351825
Trained batch 1063 in epoch 3, gen_loss = 1.4885108865293346, disc_loss = 0.0005411301805216318
Trained batch 1064 in epoch 3, gen_loss = 1.4881295215355959, disc_loss = 0.0005411735394512666
Trained batch 1065 in epoch 3, gen_loss = 1.4881235684283902, disc_loss = 0.0005410141767254694
Trained batch 1066 in epoch 3, gen_loss = 1.4879383760405793, disc_loss = 0.0005408703468619098
Trained batch 1067 in epoch 3, gen_loss = 1.4880536715412853, disc_loss = 0.0005406129084497408
Trained batch 1068 in epoch 3, gen_loss = 1.488114643030015, disc_loss = 0.0005404334140985497
Trained batch 1069 in epoch 3, gen_loss = 1.4880322468615024, disc_loss = 0.0005401065665303738
Trained batch 1070 in epoch 3, gen_loss = 1.4878639776388358, disc_loss = 0.0005398031314664297
Trained batch 1071 in epoch 3, gen_loss = 1.488235869292003, disc_loss = 0.0005395963601979779
Trained batch 1072 in epoch 3, gen_loss = 1.4883200668999779, disc_loss = 0.0005395107804316956
Trained batch 1073 in epoch 3, gen_loss = 1.4880546100534762, disc_loss = 0.0005396566372517595
Trained batch 1074 in epoch 3, gen_loss = 1.4879549598693849, disc_loss = 0.0005399820049493682
Trained batch 1075 in epoch 3, gen_loss = 1.4877930292409591, disc_loss = 0.0005400842493993956
Trained batch 1076 in epoch 3, gen_loss = 1.4878463216036033, disc_loss = 0.0005401260979105429
Trained batch 1077 in epoch 3, gen_loss = 1.4875450539013892, disc_loss = 0.0005399179846692636
Trained batch 1078 in epoch 3, gen_loss = 1.4874097991586284, disc_loss = 0.00053964597423614
Trained batch 1079 in epoch 3, gen_loss = 1.4873535801966986, disc_loss = 0.0005395745487880453
Trained batch 1080 in epoch 3, gen_loss = 1.4871836434239927, disc_loss = 0.000539423301206987
Trained batch 1081 in epoch 3, gen_loss = 1.487077283550763, disc_loss = 0.0005391708524970212
Trained batch 1082 in epoch 3, gen_loss = 1.4870272528101534, disc_loss = 0.0005387853873539536
Trained batch 1083 in epoch 3, gen_loss = 1.486916170458952, disc_loss = 0.0005385099707734711
Trained batch 1084 in epoch 3, gen_loss = 1.4866242637282692, disc_loss = 0.0005381520641865724
Trained batch 1085 in epoch 3, gen_loss = 1.4865738248956797, disc_loss = 0.0005378898706688704
Trained batch 1086 in epoch 3, gen_loss = 1.4867227691625824, disc_loss = 0.0005378321985177149
Trained batch 1087 in epoch 3, gen_loss = 1.4865739729036302, disc_loss = 0.0005376187561710942
Trained batch 1088 in epoch 3, gen_loss = 1.4863539790756883, disc_loss = 0.0005373502485125897
Trained batch 1089 in epoch 3, gen_loss = 1.4862214604648976, disc_loss = 0.0005370174574002479
Trained batch 1090 in epoch 3, gen_loss = 1.4861941785576362, disc_loss = 0.000536846690039205
Trained batch 1091 in epoch 3, gen_loss = 1.4861990546350514, disc_loss = 0.0005365219551274824
Trained batch 1092 in epoch 3, gen_loss = 1.4860523397073981, disc_loss = 0.0005363010260064967
Trained batch 1093 in epoch 3, gen_loss = 1.4861690988270413, disc_loss = 0.0005364297209383104
Trained batch 1094 in epoch 3, gen_loss = 1.4860755617760089, disc_loss = 0.0005365284021968261
Trained batch 1095 in epoch 3, gen_loss = 1.4860711731832392, disc_loss = 0.0005363700856036382
Trained batch 1096 in epoch 3, gen_loss = 1.4862076024522322, disc_loss = 0.0005363614136753638
Trained batch 1097 in epoch 3, gen_loss = 1.4862237086278711, disc_loss = 0.0005368622133625164
Trained batch 1098 in epoch 3, gen_loss = 1.4860749356414753, disc_loss = 0.0005380302779557644
Trained batch 1099 in epoch 3, gen_loss = 1.4859909050031141, disc_loss = 0.0005393417076795066
Trained batch 1100 in epoch 3, gen_loss = 1.4861816622580755, disc_loss = 0.0005402640103408813
Trained batch 1101 in epoch 3, gen_loss = 1.4860405315072047, disc_loss = 0.0005411783286184199
Trained batch 1102 in epoch 3, gen_loss = 1.4858598083338732, disc_loss = 0.000541537378121278
Trained batch 1103 in epoch 3, gen_loss = 1.4861021431675856, disc_loss = 0.0005415134021371857
Trained batch 1104 in epoch 3, gen_loss = 1.4858158524759215, disc_loss = 0.0005432188846313129
Trained batch 1105 in epoch 3, gen_loss = 1.4857548210116451, disc_loss = 0.0005441322962257289
Trained batch 1106 in epoch 3, gen_loss = 1.486153532280616, disc_loss = 0.0005448177065413198
Trained batch 1107 in epoch 3, gen_loss = 1.4860605273651302, disc_loss = 0.000545229278678736
Trained batch 1108 in epoch 3, gen_loss = 1.4860602166869814, disc_loss = 0.0005453511360923343
Trained batch 1109 in epoch 3, gen_loss = 1.485898458098506, disc_loss = 0.0005452479655473695
Trained batch 1110 in epoch 3, gen_loss = 1.4858270937209725, disc_loss = 0.0005451868159255738
Trained batch 1111 in epoch 3, gen_loss = 1.485656927065026, disc_loss = 0.0005452789362921361
Trained batch 1112 in epoch 3, gen_loss = 1.485692919960776, disc_loss = 0.0005458411996622896
Trained batch 1113 in epoch 3, gen_loss = 1.4854035410675583, disc_loss = 0.0005459298615084077
Trained batch 1114 in epoch 3, gen_loss = 1.4854545087557738, disc_loss = 0.0005461890335145695
Trained batch 1115 in epoch 3, gen_loss = 1.4852454337595185, disc_loss = 0.0005462824192494163
Trained batch 1116 in epoch 3, gen_loss = 1.4850361050509298, disc_loss = 0.0005464271142968955
Trained batch 1117 in epoch 3, gen_loss = 1.4850718930283684, disc_loss = 0.0005465946564404419
Trained batch 1118 in epoch 3, gen_loss = 1.4850170286347335, disc_loss = 0.0005465457052700063
Trained batch 1119 in epoch 3, gen_loss = 1.4849401189812592, disc_loss = 0.0005463886307682385
Trained batch 1120 in epoch 3, gen_loss = 1.4851305951612745, disc_loss = 0.0005462851473245559
Trained batch 1121 in epoch 3, gen_loss = 1.4849693133444284, disc_loss = 0.0005463259544553702
Trained batch 1122 in epoch 3, gen_loss = 1.4851263227573168, disc_loss = 0.000546259707376798
Trained batch 1123 in epoch 3, gen_loss = 1.4853348057465197, disc_loss = 0.0005462276242714619
Trained batch 1124 in epoch 3, gen_loss = 1.4856903138690525, disc_loss = 0.0005460749334112431
Trained batch 1125 in epoch 3, gen_loss = 1.4856756275542888, disc_loss = 0.000545974470611201
Trained batch 1126 in epoch 3, gen_loss = 1.4858766878825325, disc_loss = 0.00054575629675558
Trained batch 1127 in epoch 3, gen_loss = 1.4859088955196083, disc_loss = 0.0005455905030553142
Trained batch 1128 in epoch 3, gen_loss = 1.4859264719475678, disc_loss = 0.0005456431912755482
Trained batch 1129 in epoch 3, gen_loss = 1.4857752386447602, disc_loss = 0.0005461720094899647
Trained batch 1130 in epoch 3, gen_loss = 1.4859350949235979, disc_loss = 0.0005469335997772587
Trained batch 1131 in epoch 3, gen_loss = 1.485948808096323, disc_loss = 0.0005477526350589197
Trained batch 1132 in epoch 3, gen_loss = 1.4857740598974876, disc_loss = 0.00054823536169109
Trained batch 1133 in epoch 3, gen_loss = 1.4858219637231642, disc_loss = 0.00054899783031939
Trained batch 1134 in epoch 3, gen_loss = 1.4857482129781783, disc_loss = 0.0005491275185824778
Trained batch 1135 in epoch 3, gen_loss = 1.4857164777710403, disc_loss = 0.0005492396620494719
Trained batch 1136 in epoch 3, gen_loss = 1.4854176797254524, disc_loss = 0.000549357251991418
Trained batch 1137 in epoch 3, gen_loss = 1.4856851628878414, disc_loss = 0.000549713427495839
Trained batch 1138 in epoch 3, gen_loss = 1.485733840212265, disc_loss = 0.00055019227709714
Trained batch 1139 in epoch 3, gen_loss = 1.4855524489754124, disc_loss = 0.0005504628336399165
Trained batch 1140 in epoch 3, gen_loss = 1.4857083380379037, disc_loss = 0.0005507287601355707
Trained batch 1141 in epoch 3, gen_loss = 1.4858853844126552, disc_loss = 0.0005513657536821468
Trained batch 1142 in epoch 3, gen_loss = 1.4859545641788139, disc_loss = 0.0005517906618905673
Trained batch 1143 in epoch 3, gen_loss = 1.4859744547963976, disc_loss = 0.0005520798210957262
Trained batch 1144 in epoch 3, gen_loss = 1.4861524352860762, disc_loss = 0.0005523219206304326
Trained batch 1145 in epoch 3, gen_loss = 1.4858650896977796, disc_loss = 0.0005526427328979708
Trained batch 1146 in epoch 3, gen_loss = 1.4856992202316457, disc_loss = 0.0005526776763292049
Trained batch 1147 in epoch 3, gen_loss = 1.4856266751106608, disc_loss = 0.0005529912770903249
Trained batch 1148 in epoch 3, gen_loss = 1.4858039869652093, disc_loss = 0.0005530942640314121
Trained batch 1149 in epoch 3, gen_loss = 1.48575907147449, disc_loss = 0.0005528020459156402
Trained batch 1150 in epoch 3, gen_loss = 1.4857746324365186, disc_loss = 0.0005527269639330492
Trained batch 1151 in epoch 3, gen_loss = 1.485807058815327, disc_loss = 0.0005528341322739531
Trained batch 1152 in epoch 3, gen_loss = 1.4856841401855323, disc_loss = 0.0005526259388647011
Trained batch 1153 in epoch 3, gen_loss = 1.4854219888483837, disc_loss = 0.0005524627510978771
Trained batch 1154 in epoch 3, gen_loss = 1.4852798448496567, disc_loss = 0.0005523394922538383
Trained batch 1155 in epoch 3, gen_loss = 1.4853424378332383, disc_loss = 0.0005521268276834077
Trained batch 1156 in epoch 3, gen_loss = 1.4850696503549377, disc_loss = 0.0005518854167841636
Trained batch 1157 in epoch 3, gen_loss = 1.484972440105234, disc_loss = 0.0005517306373477149
Trained batch 1158 in epoch 3, gen_loss = 1.4850956588289264, disc_loss = 0.0005519368797375936
Trained batch 1159 in epoch 3, gen_loss = 1.4851362527444445, disc_loss = 0.0005525245553520829
Trained batch 1160 in epoch 3, gen_loss = 1.4852361781755261, disc_loss = 0.0005528581931623153
Trained batch 1161 in epoch 3, gen_loss = 1.485000525612429, disc_loss = 0.0005528117105162025
Trained batch 1162 in epoch 3, gen_loss = 1.4847317318002007, disc_loss = 0.0005527310583030569
Trained batch 1163 in epoch 3, gen_loss = 1.484581182502799, disc_loss = 0.000552515751401985
Trained batch 1164 in epoch 3, gen_loss = 1.4845602755894476, disc_loss = 0.0005522973143721455
Trained batch 1165 in epoch 3, gen_loss = 1.4843575968750549, disc_loss = 0.000552153034123918
Trained batch 1166 in epoch 3, gen_loss = 1.4844117082891652, disc_loss = 0.0005523994312976385
Trained batch 1167 in epoch 3, gen_loss = 1.4844889410146296, disc_loss = 0.0005525040983914936
Trained batch 1168 in epoch 3, gen_loss = 1.4844737524044014, disc_loss = 0.0005523122747644218
Trained batch 1169 in epoch 3, gen_loss = 1.4844374135009244, disc_loss = 0.0005520055408696007
Trained batch 1170 in epoch 3, gen_loss = 1.4846671318824631, disc_loss = 0.0005517004161753416
Trained batch 1171 in epoch 3, gen_loss = 1.4845770008531447, disc_loss = 0.0005513463786451755
Trained batch 1172 in epoch 3, gen_loss = 1.4844904339222043, disc_loss = 0.0005509894455884101
Trained batch 1173 in epoch 3, gen_loss = 1.484489612624024, disc_loss = 0.0005507374429279817
Trained batch 1174 in epoch 3, gen_loss = 1.4844200556328957, disc_loss = 0.0005504736256973936
Trained batch 1175 in epoch 3, gen_loss = 1.4844842485221876, disc_loss = 0.000550353463857354
Trained batch 1176 in epoch 3, gen_loss = 1.4844133166205407, disc_loss = 0.0005502459195158828
Trained batch 1177 in epoch 3, gen_loss = 1.484618456638932, disc_loss = 0.0005501078048960902
Trained batch 1178 in epoch 3, gen_loss = 1.4844759173874535, disc_loss = 0.0005498341218486627
Trained batch 1179 in epoch 3, gen_loss = 1.4846944061376282, disc_loss = 0.0005495238278191379
Trained batch 1180 in epoch 3, gen_loss = 1.4846552688120584, disc_loss = 0.0005491828900250502
Trained batch 1181 in epoch 3, gen_loss = 1.48448865809013, disc_loss = 0.0005488167893611897
Trained batch 1182 in epoch 3, gen_loss = 1.484613461506538, disc_loss = 0.000548631922118106
Trained batch 1183 in epoch 3, gen_loss = 1.4845731273494862, disc_loss = 0.0005484540220464083
Trained batch 1184 in epoch 3, gen_loss = 1.4847681296022632, disc_loss = 0.0005482487970440479
Trained batch 1185 in epoch 3, gen_loss = 1.484754082324332, disc_loss = 0.0005480794637628107
Trained batch 1186 in epoch 3, gen_loss = 1.4846620997563067, disc_loss = 0.0005478855278513613
Trained batch 1187 in epoch 3, gen_loss = 1.4847434044687033, disc_loss = 0.0005478746841905829
Trained batch 1188 in epoch 3, gen_loss = 1.4850147187559417, disc_loss = 0.0005487810106917861
Trained batch 1189 in epoch 3, gen_loss = 1.4849458009255032, disc_loss = 0.0005510378798945345
Trained batch 1190 in epoch 3, gen_loss = 1.4851546607830262, disc_loss = 0.0005536567050825623
Trained batch 1191 in epoch 3, gen_loss = 1.4854136381373308, disc_loss = 0.0005561088312379376
Trained batch 1192 in epoch 3, gen_loss = 1.4852578524072333, disc_loss = 0.0005580055115739398
Trained batch 1193 in epoch 3, gen_loss = 1.4851599326684846, disc_loss = 0.0005582765257756274
Trained batch 1194 in epoch 3, gen_loss = 1.4853195403909085, disc_loss = 0.0005582266297458309
Trained batch 1195 in epoch 3, gen_loss = 1.4855690954321603, disc_loss = 0.0005582097991430792
Trained batch 1196 in epoch 3, gen_loss = 1.4855239139364078, disc_loss = 0.0005583166258918073
Trained batch 1197 in epoch 3, gen_loss = 1.4854030319565723, disc_loss = 0.0005584261786083431
Trained batch 1198 in epoch 3, gen_loss = 1.4853471892391075, disc_loss = 0.000558686155931297
Trained batch 1199 in epoch 3, gen_loss = 1.4856455912192663, disc_loss = 0.0005593780089354065
Trained batch 1200 in epoch 3, gen_loss = 1.4856559344870561, disc_loss = 0.0005596512146121578
Trained batch 1201 in epoch 3, gen_loss = 1.4855190222949632, disc_loss = 0.0005596257496488431
Trained batch 1202 in epoch 3, gen_loss = 1.485509017459175, disc_loss = 0.0005594887634023562
Trained batch 1203 in epoch 3, gen_loss = 1.4854256029540913, disc_loss = 0.0005595791381074075
Trained batch 1204 in epoch 3, gen_loss = 1.4856228974844905, disc_loss = 0.0005596203190666774
Trained batch 1205 in epoch 3, gen_loss = 1.4854217376281966, disc_loss = 0.0005596131218837074
Trained batch 1206 in epoch 3, gen_loss = 1.4853111386002837, disc_loss = 0.0005596352675005673
Trained batch 1207 in epoch 3, gen_loss = 1.485147198205752, disc_loss = 0.0005598414867057462
Trained batch 1208 in epoch 3, gen_loss = 1.4855233742443366, disc_loss = 0.0005601458015805072
Trained batch 1209 in epoch 3, gen_loss = 1.4853768808782593, disc_loss = 0.0005602635385724523
Trained batch 1210 in epoch 3, gen_loss = 1.4853588584825876, disc_loss = 0.0005602858432914298
Trained batch 1211 in epoch 3, gen_loss = 1.4852675882109714, disc_loss = 0.000560161059514063
Trained batch 1212 in epoch 3, gen_loss = 1.4849716189078623, disc_loss = 0.0005604739593432545
Trained batch 1213 in epoch 3, gen_loss = 1.4852651619832637, disc_loss = 0.0005610057932809548
Trained batch 1214 in epoch 3, gen_loss = 1.4852558260591924, disc_loss = 0.0005614395602127161
Trained batch 1215 in epoch 3, gen_loss = 1.4856069754613073, disc_loss = 0.0005615900395480965
Trained batch 1216 in epoch 3, gen_loss = 1.4854350880510805, disc_loss = 0.0005616355185081681
Trained batch 1217 in epoch 3, gen_loss = 1.4853286603205702, disc_loss = 0.0005621465048901829
Trained batch 1218 in epoch 3, gen_loss = 1.4851877808668654, disc_loss = 0.0005625634331663366
Trained batch 1219 in epoch 3, gen_loss = 1.4851338503790683, disc_loss = 0.0005629033223844179
Trained batch 1220 in epoch 3, gen_loss = 1.4851995010438461, disc_loss = 0.000563067959991103
Trained batch 1221 in epoch 3, gen_loss = 1.4850581466858983, disc_loss = 0.0005630950986749893
Trained batch 1222 in epoch 3, gen_loss = 1.485025533768162, disc_loss = 0.000563709842959131
Trained batch 1223 in epoch 3, gen_loss = 1.4850730617451513, disc_loss = 0.0005640803211504819
Trained batch 1224 in epoch 3, gen_loss = 1.4850924669966405, disc_loss = 0.0005641987499286782
Trained batch 1225 in epoch 3, gen_loss = 1.4848578354468354, disc_loss = 0.000564096812280366
Trained batch 1226 in epoch 3, gen_loss = 1.4849005931746988, disc_loss = 0.0005638868102618625
Trained batch 1227 in epoch 3, gen_loss = 1.4850293519248403, disc_loss = 0.0005636198396692303
Trained batch 1228 in epoch 3, gen_loss = 1.4850087638207816, disc_loss = 0.0005634513396154627
Trained batch 1229 in epoch 3, gen_loss = 1.4851467584206806, disc_loss = 0.0005633769065072586
Trained batch 1230 in epoch 3, gen_loss = 1.485189745234436, disc_loss = 0.0005633694626148647
Trained batch 1231 in epoch 3, gen_loss = 1.484888552651777, disc_loss = 0.0005631816552345477
Trained batch 1232 in epoch 3, gen_loss = 1.484879979541992, disc_loss = 0.0005629450407783507
Trained batch 1233 in epoch 3, gen_loss = 1.4846450801413489, disc_loss = 0.000562734728591042
Trained batch 1234 in epoch 3, gen_loss = 1.4849664556835345, disc_loss = 0.0005625953089878499
Trained batch 1235 in epoch 3, gen_loss = 1.4851268775833464, disc_loss = 0.000562377502051733
Trained batch 1236 in epoch 3, gen_loss = 1.4850946427740777, disc_loss = 0.0005621407042563725
Trained batch 1237 in epoch 3, gen_loss = 1.4851015974708828, disc_loss = 0.0005619648770021647
Trained batch 1238 in epoch 3, gen_loss = 1.4853646121167483, disc_loss = 0.0005618729085186602
Trained batch 1239 in epoch 3, gen_loss = 1.4852014621419292, disc_loss = 0.0005618827787979934
Trained batch 1240 in epoch 3, gen_loss = 1.485280054793254, disc_loss = 0.0005620063319157826
Trained batch 1241 in epoch 3, gen_loss = 1.4853581415666282, disc_loss = 0.0005620932030412233
Trained batch 1242 in epoch 3, gen_loss = 1.4852099130926646, disc_loss = 0.0005622259413413081
Trained batch 1243 in epoch 3, gen_loss = 1.485192201145209, disc_loss = 0.0005623083760168507
Trained batch 1244 in epoch 3, gen_loss = 1.4852374742308774, disc_loss = 0.000562339477780103
Trained batch 1245 in epoch 3, gen_loss = 1.4853046425464256, disc_loss = 0.0005623047799100901
Trained batch 1246 in epoch 3, gen_loss = 1.4851549859991433, disc_loss = 0.000562099581168432
Trained batch 1247 in epoch 3, gen_loss = 1.4851647452093089, disc_loss = 0.0005618379817137909
Trained batch 1248 in epoch 3, gen_loss = 1.4852315867968422, disc_loss = 0.0005618050744377891
Trained batch 1249 in epoch 3, gen_loss = 1.4853928869247437, disc_loss = 0.00056157614919357
Trained batch 1250 in epoch 3, gen_loss = 1.4852876553623129, disc_loss = 0.0005614080699532926
Trained batch 1251 in epoch 3, gen_loss = 1.4850104183625108, disc_loss = 0.0005613475507833792
Trained batch 1252 in epoch 3, gen_loss = 1.4849311119065889, disc_loss = 0.0005613034406421574
Trained batch 1253 in epoch 3, gen_loss = 1.4849838230408359, disc_loss = 0.0005613431747194359
Trained batch 1254 in epoch 3, gen_loss = 1.4850081505528485, disc_loss = 0.0005618333695706841
Trained batch 1255 in epoch 3, gen_loss = 1.4848666957039742, disc_loss = 0.0005627303112624138
Trained batch 1256 in epoch 3, gen_loss = 1.4846753926151977, disc_loss = 0.0005635708605812443
Trained batch 1257 in epoch 3, gen_loss = 1.4845647408207951, disc_loss = 0.0005644652002077588
Trained batch 1258 in epoch 3, gen_loss = 1.484759804746099, disc_loss = 0.0005659808023920396
Trained batch 1259 in epoch 3, gen_loss = 1.484916795435406, disc_loss = 0.000566972089660657
Trained batch 1260 in epoch 3, gen_loss = 1.4849615335275406, disc_loss = 0.0005669996267619257
Trained batch 1261 in epoch 3, gen_loss = 1.484786617019097, disc_loss = 0.000566986448611369
Trained batch 1262 in epoch 3, gen_loss = 1.4848024410948524, disc_loss = 0.0005676366921976247
Trained batch 1263 in epoch 3, gen_loss = 1.4847879639909238, disc_loss = 0.0005685765379525889
Trained batch 1264 in epoch 3, gen_loss = 1.4847751140594483, disc_loss = 0.0005690391079969925
Trained batch 1265 in epoch 3, gen_loss = 1.484774342645401, disc_loss = 0.0005694240765724446
Trained batch 1266 in epoch 3, gen_loss = 1.484760103116566, disc_loss = 0.0005698019771014532
Trained batch 1267 in epoch 3, gen_loss = 1.4847760572794484, disc_loss = 0.0005699694014570458
Trained batch 1268 in epoch 3, gen_loss = 1.484842357248467, disc_loss = 0.000569991418550384
Trained batch 1269 in epoch 3, gen_loss = 1.4848447307826966, disc_loss = 0.0005698235732077907
Trained batch 1270 in epoch 3, gen_loss = 1.4847710352071526, disc_loss = 0.000569585128183558
Trained batch 1271 in epoch 3, gen_loss = 1.48474427664055, disc_loss = 0.000569480675108454
Trained batch 1272 in epoch 3, gen_loss = 1.4847382081369669, disc_loss = 0.0005691747084020938
Trained batch 1273 in epoch 3, gen_loss = 1.4846049625794966, disc_loss = 0.0005688573039217057
Trained batch 1274 in epoch 3, gen_loss = 1.4846022162717931, disc_loss = 0.000568516302463489
Trained batch 1275 in epoch 3, gen_loss = 1.4848137206418388, disc_loss = 0.000568232374926967
Trained batch 1276 in epoch 3, gen_loss = 1.484777521881725, disc_loss = 0.0005680568242286418
Trained batch 1277 in epoch 3, gen_loss = 1.4849173932194897, disc_loss = 0.0005679954033076627
Trained batch 1278 in epoch 3, gen_loss = 1.4849854135438743, disc_loss = 0.000567797072366207
Trained batch 1279 in epoch 3, gen_loss = 1.4850171983242035, disc_loss = 0.0005675700223832791
Trained batch 1280 in epoch 3, gen_loss = 1.484872734425684, disc_loss = 0.0005673136341433346
Trained batch 1281 in epoch 3, gen_loss = 1.4850261382491279, disc_loss = 0.0005670776415332773
Trained batch 1282 in epoch 3, gen_loss = 1.4850747616887556, disc_loss = 0.0005668841953272659
Trained batch 1283 in epoch 3, gen_loss = 1.4847452097407012, disc_loss = 0.0005667172616799732
Trained batch 1284 in epoch 3, gen_loss = 1.4845635769432157, disc_loss = 0.000566602842340967
Trained batch 1285 in epoch 3, gen_loss = 1.4846702282944142, disc_loss = 0.0005663002947066377
Trained batch 1286 in epoch 3, gen_loss = 1.484473353221422, disc_loss = 0.0005659554189975789
Trained batch 1287 in epoch 3, gen_loss = 1.4842815523192008, disc_loss = 0.000565673061811473
Trained batch 1288 in epoch 3, gen_loss = 1.4841716039818882, disc_loss = 0.0005654266618194544
Trained batch 1289 in epoch 3, gen_loss = 1.484137491107911, disc_loss = 0.00056533035624803
Trained batch 1290 in epoch 3, gen_loss = 1.483947484277183, disc_loss = 0.000565190643724
Trained batch 1291 in epoch 3, gen_loss = 1.4839216548222876, disc_loss = 0.0005651314862995321
Trained batch 1292 in epoch 3, gen_loss = 1.4840043956516145, disc_loss = 0.0005650643606439531
Trained batch 1293 in epoch 3, gen_loss = 1.484141994020117, disc_loss = 0.0005651277002144909
Trained batch 1294 in epoch 3, gen_loss = 1.4840184971172377, disc_loss = 0.0005651641685068859
Trained batch 1295 in epoch 3, gen_loss = 1.4840363251206317, disc_loss = 0.0005649791333376521
Trained batch 1296 in epoch 3, gen_loss = 1.4841038469360164, disc_loss = 0.0005647293098558835
Trained batch 1297 in epoch 3, gen_loss = 1.4844473974179413, disc_loss = 0.0005644960546430534
Trained batch 1298 in epoch 3, gen_loss = 1.4844159964325796, disc_loss = 0.0005644844286878657
Trained batch 1299 in epoch 3, gen_loss = 1.4845744064221016, disc_loss = 0.00056467306934512
Trained batch 1300 in epoch 3, gen_loss = 1.484687802885057, disc_loss = 0.0005650372736744416
Trained batch 1301 in epoch 3, gen_loss = 1.4848566581759768, disc_loss = 0.0005650699817998973
Trained batch 1302 in epoch 3, gen_loss = 1.484943760145836, disc_loss = 0.000565121216497206
Trained batch 1303 in epoch 3, gen_loss = 1.4848322763216275, disc_loss = 0.0005650283409260425
Trained batch 1304 in epoch 3, gen_loss = 1.4845997472375745, disc_loss = 0.0005653618849631955
Trained batch 1305 in epoch 3, gen_loss = 1.4846343954891013, disc_loss = 0.0005661787443910547
Trained batch 1306 in epoch 3, gen_loss = 1.484609875044206, disc_loss = 0.0005674462717089891
Trained batch 1307 in epoch 3, gen_loss = 1.4844370406884302, disc_loss = 0.0005684826174264614
Trained batch 1308 in epoch 3, gen_loss = 1.484345358232217, disc_loss = 0.0005685912433715012
Trained batch 1309 in epoch 3, gen_loss = 1.48438560625979, disc_loss = 0.000568567491172038
Trained batch 1310 in epoch 3, gen_loss = 1.4843254666761256, disc_loss = 0.0005691006922992095
Trained batch 1311 in epoch 3, gen_loss = 1.4842393560017026, disc_loss = 0.0005698427943038618
Trained batch 1312 in epoch 3, gen_loss = 1.4840309470097526, disc_loss = 0.0005705373278185612
Trained batch 1313 in epoch 3, gen_loss = 1.4840631303540466, disc_loss = 0.000571243012663476
Trained batch 1314 in epoch 3, gen_loss = 1.4838991350094175, disc_loss = 0.000572043719184461
Trained batch 1315 in epoch 3, gen_loss = 1.4838630266283783, disc_loss = 0.0005721686823515782
Trained batch 1316 in epoch 3, gen_loss = 1.4838165155213805, disc_loss = 0.0005720837253042275
Trained batch 1317 in epoch 3, gen_loss = 1.4837500929651564, disc_loss = 0.0005718785701923734
Trained batch 1318 in epoch 3, gen_loss = 1.4839205326141056, disc_loss = 0.0005715949828644693
Trained batch 1319 in epoch 3, gen_loss = 1.4837665276093916, disc_loss = 0.0005713137894693346
Trained batch 1320 in epoch 3, gen_loss = 1.4837155336687549, disc_loss = 0.0005709892063820946
Trained batch 1321 in epoch 3, gen_loss = 1.4837891103279934, disc_loss = 0.0005706929343030647
Trained batch 1322 in epoch 3, gen_loss = 1.4839502091851093, disc_loss = 0.0005704258700333098
Trained batch 1323 in epoch 3, gen_loss = 1.483964819112213, disc_loss = 0.0005701331172152169
Trained batch 1324 in epoch 3, gen_loss = 1.4840199033269343, disc_loss = 0.0005698320798066287
Trained batch 1325 in epoch 3, gen_loss = 1.4840235035883356, disc_loss = 0.0005695440287671584
Trained batch 1326 in epoch 3, gen_loss = 1.4840927862456263, disc_loss = 0.000569491619110871
Trained batch 1327 in epoch 3, gen_loss = 1.4843128277774316, disc_loss = 0.000569360783388165
Trained batch 1328 in epoch 3, gen_loss = 1.4844082028817378, disc_loss = 0.0005692087433013947
Trained batch 1329 in epoch 3, gen_loss = 1.4844347710896255, disc_loss = 0.0005691866452334785
Trained batch 1330 in epoch 3, gen_loss = 1.4844784689164539, disc_loss = 0.0005694265323377947
Trained batch 1331 in epoch 3, gen_loss = 1.4843305715390511, disc_loss = 0.0005695626355559767
Trained batch 1332 in epoch 3, gen_loss = 1.484208260544779, disc_loss = 0.0005694436558189719
Trained batch 1333 in epoch 3, gen_loss = 1.4843125649835396, disc_loss = 0.0005693689644372655
Trained batch 1334 in epoch 3, gen_loss = 1.4845102344112897, disc_loss = 0.0005694186713237818
Trained batch 1335 in epoch 3, gen_loss = 1.484453700973602, disc_loss = 0.0005694351640338578
Trained batch 1336 in epoch 3, gen_loss = 1.4842810075320498, disc_loss = 0.0005692800799685634
Trained batch 1337 in epoch 3, gen_loss = 1.4844205261880508, disc_loss = 0.0005690074161518858
Trained batch 1338 in epoch 3, gen_loss = 1.4842132232899627, disc_loss = 0.0005688060993717148
Trained batch 1339 in epoch 3, gen_loss = 1.4843511391931505, disc_loss = 0.0005685003258465136
Trained batch 1340 in epoch 3, gen_loss = 1.4843438916202805, disc_loss = 0.0005683287527225704
Trained batch 1341 in epoch 3, gen_loss = 1.4843903614760512, disc_loss = 0.0005682058173782455
Trained batch 1342 in epoch 3, gen_loss = 1.484788920039662, disc_loss = 0.0005683894363436182
Trained batch 1343 in epoch 3, gen_loss = 1.4848244588467336, disc_loss = 0.0005686931048374044
Trained batch 1344 in epoch 3, gen_loss = 1.4844796168316696, disc_loss = 0.0005689061537417877
Trained batch 1345 in epoch 3, gen_loss = 1.484463176171103, disc_loss = 0.0005687302267604423
Trained batch 1346 in epoch 3, gen_loss = 1.4844825404966506, disc_loss = 0.0005684971823906713
Trained batch 1347 in epoch 3, gen_loss = 1.484440118428154, disc_loss = 0.0005682698793276434
Trained batch 1348 in epoch 3, gen_loss = 1.4842164821320767, disc_loss = 0.0005682713215232788
Trained batch 1349 in epoch 3, gen_loss = 1.4842568443439625, disc_loss = 0.00056835853518418
Trained batch 1350 in epoch 3, gen_loss = 1.4842589336532208, disc_loss = 0.0005681583836059783
Trained batch 1351 in epoch 3, gen_loss = 1.4840980053124344, disc_loss = 0.0005680483349319272
Trained batch 1352 in epoch 3, gen_loss = 1.4841263739162256, disc_loss = 0.0005678320932959214
Trained batch 1353 in epoch 3, gen_loss = 1.4844280556174465, disc_loss = 0.000567612061520352
Trained batch 1354 in epoch 3, gen_loss = 1.4846929072453967, disc_loss = 0.0005673773922034749
Trained batch 1355 in epoch 3, gen_loss = 1.4846466799928728, disc_loss = 0.0005673792293773631
Trained batch 1356 in epoch 3, gen_loss = 1.4843817617230848, disc_loss = 0.0005677468666929323
Trained batch 1357 in epoch 3, gen_loss = 1.4842979455029315, disc_loss = 0.0005682136496607508
Trained batch 1358 in epoch 3, gen_loss = 1.484228726517549, disc_loss = 0.0005684859655645688
Trained batch 1359 in epoch 3, gen_loss = 1.4841178092009881, disc_loss = 0.0005688119538664229
Trained batch 1360 in epoch 3, gen_loss = 1.484034487379552, disc_loss = 0.0005688758596785101
Trained batch 1361 in epoch 3, gen_loss = 1.4838689468505624, disc_loss = 0.0005687726000423041
Trained batch 1362 in epoch 3, gen_loss = 1.4837777633834917, disc_loss = 0.0005686859471616845
Trained batch 1363 in epoch 3, gen_loss = 1.4837907068540623, disc_loss = 0.0005689162486662973
Trained batch 1364 in epoch 3, gen_loss = 1.4839216537091322, disc_loss = 0.0005698439118455782
Trained batch 1365 in epoch 3, gen_loss = 1.4839414281342425, disc_loss = 0.0005707806079392083
Trained batch 1366 in epoch 3, gen_loss = 1.4839568934304572, disc_loss = 0.0005713190959872788
Trained batch 1367 in epoch 3, gen_loss = 1.4838899336537423, disc_loss = 0.0005716370985937191
Trained batch 1368 in epoch 3, gen_loss = 1.483760393214452, disc_loss = 0.0005716050508513045
Trained batch 1369 in epoch 3, gen_loss = 1.4835118257216293, disc_loss = 0.0005714549363529595
Trained batch 1370 in epoch 3, gen_loss = 1.4835721698666384, disc_loss = 0.0005712663975763688
Trained batch 1371 in epoch 3, gen_loss = 1.4834026629132362, disc_loss = 0.0005710572896524585
Trained batch 1372 in epoch 3, gen_loss = 1.4834325966484254, disc_loss = 0.000570826855632602
Trained batch 1373 in epoch 3, gen_loss = 1.483462307737731, disc_loss = 0.0005706950347591667
Trained batch 1374 in epoch 3, gen_loss = 1.4835242740457708, disc_loss = 0.0005705376887397671
Trained batch 1375 in epoch 3, gen_loss = 1.4833529223363067, disc_loss = 0.0005703214728148237
Trained batch 1376 in epoch 3, gen_loss = 1.4832126164488284, disc_loss = 0.0005701492955558511
Trained batch 1377 in epoch 3, gen_loss = 1.4832575582454444, disc_loss = 0.0005699682243506956
Trained batch 1378 in epoch 3, gen_loss = 1.4832293750411623, disc_loss = 0.0005697245091896172
Trained batch 1379 in epoch 3, gen_loss = 1.4830716583175936, disc_loss = 0.0005695233536138456
Trained batch 1380 in epoch 3, gen_loss = 1.4830652757626699, disc_loss = 0.0005693368537093201
Trained batch 1381 in epoch 3, gen_loss = 1.4830487428284242, disc_loss = 0.0005691636740125571
Trained batch 1382 in epoch 3, gen_loss = 1.483037395832423, disc_loss = 0.0005689877757448393
Trained batch 1383 in epoch 3, gen_loss = 1.482871471974202, disc_loss = 0.0005687399999034319
Trained batch 1384 in epoch 3, gen_loss = 1.4827989215024542, disc_loss = 0.0005684714646785544
Trained batch 1385 in epoch 3, gen_loss = 1.4825959430972564, disc_loss = 0.0005682244089855893
Trained batch 1386 in epoch 3, gen_loss = 1.4825294106317752, disc_loss = 0.0005679582242815162
Trained batch 1387 in epoch 3, gen_loss = 1.482527141869927, disc_loss = 0.0005676795242084875
Trained batch 1388 in epoch 3, gen_loss = 1.4823648665258573, disc_loss = 0.0005674955842927999
Trained batch 1389 in epoch 3, gen_loss = 1.4823596191063202, disc_loss = 0.0005673086646527199
Trained batch 1390 in epoch 3, gen_loss = 1.4823099034540435, disc_loss = 0.0005672397177350405
Trained batch 1391 in epoch 3, gen_loss = 1.4822838000696281, disc_loss = 0.0005673770383823309
Trained batch 1392 in epoch 3, gen_loss = 1.4823956533207452, disc_loss = 0.0005676158142178497
Trained batch 1393 in epoch 3, gen_loss = 1.4823694952591249, disc_loss = 0.0005682954785412035
Trained batch 1394 in epoch 3, gen_loss = 1.4820468540260014, disc_loss = 0.0005694347179634997
Trained batch 1395 in epoch 3, gen_loss = 1.4820047096058429, disc_loss = 0.0005708347520584849
Trained batch 1396 in epoch 3, gen_loss = 1.481969070673501, disc_loss = 0.0005718559944957532
Trained batch 1397 in epoch 3, gen_loss = 1.4818580738976277, disc_loss = 0.0005719085933540006
Trained batch 1398 in epoch 3, gen_loss = 1.481867478352261, disc_loss = 0.0005717418162638802
Trained batch 1399 in epoch 3, gen_loss = 1.4818142919881003, disc_loss = 0.0005719128510931374
Trained batch 1400 in epoch 3, gen_loss = 1.481639200070345, disc_loss = 0.0005721436086978942
Trained batch 1401 in epoch 3, gen_loss = 1.481478665592667, disc_loss = 0.0005722215242458696
Trained batch 1402 in epoch 3, gen_loss = 1.4813037724131273, disc_loss = 0.0005723177732920363
Trained batch 1403 in epoch 3, gen_loss = 1.4814364325966252, disc_loss = 0.0005724054537438243
Trained batch 1404 in epoch 3, gen_loss = 1.4813717353386386, disc_loss = 0.0005723654033178696
Trained batch 1405 in epoch 3, gen_loss = 1.4812577698342662, disc_loss = 0.0005722176501566179
Trained batch 1406 in epoch 3, gen_loss = 1.481324208570696, disc_loss = 0.000572150365229234
Trained batch 1407 in epoch 3, gen_loss = 1.481090135025707, disc_loss = 0.0005719398404215264
Trained batch 1408 in epoch 3, gen_loss = 1.480990297748655, disc_loss = 0.0005717049918376766
Trained batch 1409 in epoch 3, gen_loss = 1.4811105268221374, disc_loss = 0.0005716165152447734
Trained batch 1410 in epoch 3, gen_loss = 1.4811830767328058, disc_loss = 0.0005718229123929808
Trained batch 1411 in epoch 3, gen_loss = 1.4809995065667474, disc_loss = 0.0005726962760153487
Trained batch 1412 in epoch 3, gen_loss = 1.4809630333913275, disc_loss = 0.0005733014134408726
Trained batch 1413 in epoch 3, gen_loss = 1.480964174365053, disc_loss = 0.0005735372093290781
Trained batch 1414 in epoch 3, gen_loss = 1.4811018908402944, disc_loss = 0.0005735087862103361
Trained batch 1415 in epoch 3, gen_loss = 1.480875624017527, disc_loss = 0.0005736661713427632
Trained batch 1416 in epoch 3, gen_loss = 1.4807734533187447, disc_loss = 0.0005738990022419658
Trained batch 1417 in epoch 3, gen_loss = 1.4806549083362681, disc_loss = 0.0005738627014413071
Trained batch 1418 in epoch 3, gen_loss = 1.480632807269241, disc_loss = 0.000573865965494743
Trained batch 1419 in epoch 3, gen_loss = 1.480538731897381, disc_loss = 0.0005739259739770409
Trained batch 1420 in epoch 3, gen_loss = 1.480572992106041, disc_loss = 0.0005737747292695953
Trained batch 1421 in epoch 3, gen_loss = 1.4806699146701314, disc_loss = 0.0005735556376277981
Trained batch 1422 in epoch 3, gen_loss = 1.4811202788637796, disc_loss = 0.0005735698269283528
Trained batch 1423 in epoch 3, gen_loss = 1.4812250175000576, disc_loss = 0.0005733518047961982
Trained batch 1424 in epoch 3, gen_loss = 1.481379296905116, disc_loss = 0.0005732554789191406
Trained batch 1425 in epoch 3, gen_loss = 1.48139304591429, disc_loss = 0.0005730431373257237
Trained batch 1426 in epoch 3, gen_loss = 1.4814816705814675, disc_loss = 0.0005728094864257474
Trained batch 1427 in epoch 3, gen_loss = 1.4814166324813158, disc_loss = 0.0005727238631993141
Trained batch 1428 in epoch 3, gen_loss = 1.481502814923574, disc_loss = 0.0005728685797437859
Trained batch 1429 in epoch 3, gen_loss = 1.481414737067856, disc_loss = 0.0005728798970120952
Trained batch 1430 in epoch 3, gen_loss = 1.4815834045076937, disc_loss = 0.0005728351382621981
Trained batch 1431 in epoch 3, gen_loss = 1.4814957500170063, disc_loss = 0.0005729097665506077
Trained batch 1432 in epoch 3, gen_loss = 1.4813770039965037, disc_loss = 0.0005731135452411866
Trained batch 1433 in epoch 3, gen_loss = 1.4813851234470619, disc_loss = 0.0005732672655957555
Trained batch 1434 in epoch 3, gen_loss = 1.4814776347489307, disc_loss = 0.000573288877405395
Trained batch 1435 in epoch 3, gen_loss = 1.4814161949669087, disc_loss = 0.0005734767200565355
Trained batch 1436 in epoch 3, gen_loss = 1.4813303963210571, disc_loss = 0.0005737244435563352
Trained batch 1437 in epoch 3, gen_loss = 1.4813952474998666, disc_loss = 0.0005737845343893837
Trained batch 1438 in epoch 3, gen_loss = 1.481484941263179, disc_loss = 0.0005738716147797308
Trained batch 1439 in epoch 3, gen_loss = 1.4813180955747762, disc_loss = 0.0005741869949916792
Trained batch 1440 in epoch 3, gen_loss = 1.48123809697312, disc_loss = 0.0005744300876959957
Trained batch 1441 in epoch 3, gen_loss = 1.4810915471115325, disc_loss = 0.0005746691929090551
Trained batch 1442 in epoch 3, gen_loss = 1.4812313816403648, disc_loss = 0.0005749769642195914
Trained batch 1443 in epoch 3, gen_loss = 1.4812334023023908, disc_loss = 0.0005753823748123484
Trained batch 1444 in epoch 3, gen_loss = 1.4810833598503192, disc_loss = 0.0005759461000191118
Trained batch 1445 in epoch 3, gen_loss = 1.4808793534546638, disc_loss = 0.0005764379791215314
Trained batch 1446 in epoch 3, gen_loss = 1.4806827636282445, disc_loss = 0.0005766342751827907
Trained batch 1447 in epoch 3, gen_loss = 1.4806069118377254, disc_loss = 0.0005766911850936674
Trained batch 1448 in epoch 3, gen_loss = 1.4808322428998821, disc_loss = 0.0005765912277722671
Trained batch 1449 in epoch 3, gen_loss = 1.4807332201661734, disc_loss = 0.0005765172768914109
Trained batch 1450 in epoch 3, gen_loss = 1.4806853093253096, disc_loss = 0.0005763801230585586
Trained batch 1451 in epoch 3, gen_loss = 1.4803831887639258, disc_loss = 0.0005763311822370808
Trained batch 1452 in epoch 3, gen_loss = 1.4803369804980915, disc_loss = 0.0005762780578989671
Trained batch 1453 in epoch 3, gen_loss = 1.480088077270345, disc_loss = 0.0005763130591323335
Trained batch 1454 in epoch 3, gen_loss = 1.4801083749102564, disc_loss = 0.0005763035066364993
Trained batch 1455 in epoch 3, gen_loss = 1.4803483504187929, disc_loss = 0.0005764146382197006
Trained batch 1456 in epoch 3, gen_loss = 1.4804891662885657, disc_loss = 0.0005766906165971703
Trained batch 1457 in epoch 3, gen_loss = 1.4805399405122295, disc_loss = 0.0005768726274274693
Trained batch 1458 in epoch 3, gen_loss = 1.4805335384104823, disc_loss = 0.0005770789896124607
Trained batch 1459 in epoch 3, gen_loss = 1.4806549840593992, disc_loss = 0.0005770135585980949
Trained batch 1460 in epoch 3, gen_loss = 1.4807564400386353, disc_loss = 0.0005769256416652135
Trained batch 1461 in epoch 3, gen_loss = 1.4807280612709421, disc_loss = 0.0005768944863112142
Trained batch 1462 in epoch 3, gen_loss = 1.4806834916423137, disc_loss = 0.0005768595649450202
Trained batch 1463 in epoch 3, gen_loss = 1.4805262602580702, disc_loss = 0.0005769052869090658
Trained batch 1464 in epoch 3, gen_loss = 1.4804989527516805, disc_loss = 0.000577144659523226
Trained batch 1465 in epoch 3, gen_loss = 1.4804709478907825, disc_loss = 0.0005773661160980711
Trained batch 1466 in epoch 3, gen_loss = 1.4806577318285141, disc_loss = 0.0005773280404575407
Trained batch 1467 in epoch 3, gen_loss = 1.4809397666103508, disc_loss = 0.0005772589261079593
Trained batch 1468 in epoch 3, gen_loss = 1.4808050738134053, disc_loss = 0.000577120696411768
Trained batch 1469 in epoch 3, gen_loss = 1.4809143840050212, disc_loss = 0.0005768601240734348
Trained batch 1470 in epoch 3, gen_loss = 1.4807051101726063, disc_loss = 0.0005766914351670771
Trained batch 1471 in epoch 3, gen_loss = 1.4805176535054394, disc_loss = 0.0005763783510602756
Trained batch 1472 in epoch 3, gen_loss = 1.480645190916819, disc_loss = 0.0005761486891906383
Trained batch 1473 in epoch 3, gen_loss = 1.480574997503366, disc_loss = 0.0005759497948330979
Trained batch 1474 in epoch 3, gen_loss = 1.4807810935327563, disc_loss = 0.0005758394102735635
Trained batch 1475 in epoch 3, gen_loss = 1.4806793119687698, disc_loss = 0.0005756961622753851
Trained batch 1476 in epoch 3, gen_loss = 1.4806111403712567, disc_loss = 0.0005756930444508914
Trained batch 1477 in epoch 3, gen_loss = 1.4805003707076603, disc_loss = 0.0005757367754493228
Trained batch 1478 in epoch 3, gen_loss = 1.480637199013035, disc_loss = 0.0005756252466395096
Trained batch 1479 in epoch 3, gen_loss = 1.4805174530357927, disc_loss = 0.0005753797363935076
Trained batch 1480 in epoch 3, gen_loss = 1.480311767142178, disc_loss = 0.0005751637976994244
Trained batch 1481 in epoch 3, gen_loss = 1.4803616766504912, disc_loss = 0.0005750653057102448
Trained batch 1482 in epoch 3, gen_loss = 1.4802596388197555, disc_loss = 0.0005750394744328484
Trained batch 1483 in epoch 3, gen_loss = 1.4804216901247071, disc_loss = 0.0005751219858339175
Trained batch 1484 in epoch 3, gen_loss = 1.4803422407670455, disc_loss = 0.000575401603580556
Trained batch 1485 in epoch 3, gen_loss = 1.4805477476537148, disc_loss = 0.00057562724521467
Trained batch 1486 in epoch 3, gen_loss = 1.4804224090120819, disc_loss = 0.0005757518123972174
Trained batch 1487 in epoch 3, gen_loss = 1.480269451936086, disc_loss = 0.000575624561460372
Trained batch 1488 in epoch 3, gen_loss = 1.4802912216686097, disc_loss = 0.0005755109244826531
Trained batch 1489 in epoch 3, gen_loss = 1.4801811255064588, disc_loss = 0.0005754855967122098
Trained batch 1490 in epoch 3, gen_loss = 1.4801366225254768, disc_loss = 0.0005753287798562665
Trained batch 1491 in epoch 3, gen_loss = 1.4799884471433091, disc_loss = 0.0005753106317775019
Trained batch 1492 in epoch 3, gen_loss = 1.4799661666693817, disc_loss = 0.0005754376879356157
Trained batch 1493 in epoch 3, gen_loss = 1.4799668701138682, disc_loss = 0.0005752975066010734
Trained batch 1494 in epoch 3, gen_loss = 1.4798198261388569, disc_loss = 0.0005751013959233142
Trained batch 1495 in epoch 3, gen_loss = 1.4799724286571543, disc_loss = 0.000574955718480063
Trained batch 1496 in epoch 3, gen_loss = 1.4797321857415444, disc_loss = 0.0005748164450047375
Trained batch 1497 in epoch 3, gen_loss = 1.4799122586746878, disc_loss = 0.000574676642663471
Trained batch 1498 in epoch 3, gen_loss = 1.4797630644862536, disc_loss = 0.0005744150008956868
Trained batch 1499 in epoch 3, gen_loss = 1.479638505379359, disc_loss = 0.0005743189694282289
Trained batch 1500 in epoch 3, gen_loss = 1.4798383656380416, disc_loss = 0.0005742344738239873
Trained batch 1501 in epoch 3, gen_loss = 1.480008887625566, disc_loss = 0.0005741664928510617
Trained batch 1502 in epoch 3, gen_loss = 1.4801376168916642, disc_loss = 0.000574110092329393
Trained batch 1503 in epoch 3, gen_loss = 1.4802531834612502, disc_loss = 0.0005740317097235598
Trained batch 1504 in epoch 3, gen_loss = 1.4805344527742, disc_loss = 0.0005739770376972817
Trained batch 1505 in epoch 3, gen_loss = 1.4805972601471353, disc_loss = 0.0005741074892816259
Trained batch 1506 in epoch 3, gen_loss = 1.4803536420795564, disc_loss = 0.0005749053668514124
Trained batch 1507 in epoch 3, gen_loss = 1.4804083421154426, disc_loss = 0.0005753685985866314
Trained batch 1508 in epoch 3, gen_loss = 1.480365528264055, disc_loss = 0.0005752823710053692
Trained batch 1509 in epoch 3, gen_loss = 1.4803619300292816, disc_loss = 0.0005750775854342266
Trained batch 1510 in epoch 3, gen_loss = 1.480531065295186, disc_loss = 0.0005750172800559509
Trained batch 1511 in epoch 3, gen_loss = 1.4804837166001557, disc_loss = 0.0005749143160876224
Trained batch 1512 in epoch 3, gen_loss = 1.480618733407958, disc_loss = 0.000574778900841086
Trained batch 1513 in epoch 3, gen_loss = 1.4805886228144405, disc_loss = 0.0005745324175088215
Trained batch 1514 in epoch 3, gen_loss = 1.4806879244228401, disc_loss = 0.0005742921870760466
Trained batch 1515 in epoch 3, gen_loss = 1.4807825185220915, disc_loss = 0.0005740547822011232
Trained batch 1516 in epoch 3, gen_loss = 1.4806265184261647, disc_loss = 0.0005738130576201655
Trained batch 1517 in epoch 3, gen_loss = 1.4806098495076296, disc_loss = 0.0005735440812550966
Trained batch 1518 in epoch 3, gen_loss = 1.4804806431474618, disc_loss = 0.0005733139915432421
Trained batch 1519 in epoch 3, gen_loss = 1.4802283094117517, disc_loss = 0.0005730852544729714
Trained batch 1520 in epoch 3, gen_loss = 1.4801695350751056, disc_loss = 0.00057288015165887
Trained batch 1521 in epoch 3, gen_loss = 1.4801468365922394, disc_loss = 0.0005726901372028338
Trained batch 1522 in epoch 3, gen_loss = 1.4802282944527099, disc_loss = 0.0005725001188999321
Trained batch 1523 in epoch 3, gen_loss = 1.4802637630560267, disc_loss = 0.0005723037856952269
Trained batch 1524 in epoch 3, gen_loss = 1.4800490564596458, disc_loss = 0.0005722061757925806
Trained batch 1525 in epoch 3, gen_loss = 1.4799951334455848, disc_loss = 0.0005723236771775709
Trained batch 1526 in epoch 3, gen_loss = 1.4799971946642614, disc_loss = 0.0005724197572545309
Trained batch 1527 in epoch 3, gen_loss = 1.479733649582763, disc_loss = 0.00057227218502327
Trained batch 1528 in epoch 3, gen_loss = 1.479624115617701, disc_loss = 0.0005721574252782124
Trained batch 1529 in epoch 3, gen_loss = 1.479607840379079, disc_loss = 0.0005724389329830374
Trained batch 1530 in epoch 3, gen_loss = 1.479475539389348, disc_loss = 0.0005725450472603446
Trained batch 1531 in epoch 3, gen_loss = 1.4794309845792406, disc_loss = 0.0005725027714384381
Trained batch 1532 in epoch 3, gen_loss = 1.479419146809637, disc_loss = 0.0005725200431770265
Trained batch 1533 in epoch 3, gen_loss = 1.4792764497704736, disc_loss = 0.0005725188941469099
Trained batch 1534 in epoch 3, gen_loss = 1.4793769223682267, disc_loss = 0.0005724911060861497
Trained batch 1535 in epoch 3, gen_loss = 1.4795887464812647, disc_loss = 0.0005723867607893377
Trained batch 1536 in epoch 3, gen_loss = 1.4795837171215784, disc_loss = 0.0005724727872557782
Trained batch 1537 in epoch 3, gen_loss = 1.479642799291251, disc_loss = 0.0005726489388293548
Trained batch 1538 in epoch 3, gen_loss = 1.4797931280594665, disc_loss = 0.0005728638490831874
Trained batch 1539 in epoch 3, gen_loss = 1.4797484609213742, disc_loss = 0.0005728449173821227
Trained batch 1540 in epoch 3, gen_loss = 1.4797928030811138, disc_loss = 0.0005727826663948527
Trained batch 1541 in epoch 3, gen_loss = 1.479606555052459, disc_loss = 0.0005728648264599323
Trained batch 1542 in epoch 3, gen_loss = 1.4795020261679233, disc_loss = 0.0005730581231703028
Trained batch 1543 in epoch 3, gen_loss = 1.4796848891621426, disc_loss = 0.0005733486938686442
Trained batch 1544 in epoch 3, gen_loss = 1.4797794442346566, disc_loss = 0.0005733521250856461
Trained batch 1545 in epoch 3, gen_loss = 1.479593818277159, disc_loss = 0.0005733763104626809
Trained batch 1546 in epoch 3, gen_loss = 1.479322257316259, disc_loss = 0.0005736003039264329
Trained batch 1547 in epoch 3, gen_loss = 1.4792672661385795, disc_loss = 0.0005742281457379632
Trained batch 1548 in epoch 3, gen_loss = 1.479288981836638, disc_loss = 0.0005749249460608978
Trained batch 1549 in epoch 3, gen_loss = 1.4794341671851374, disc_loss = 0.0005751060240342462
Trained batch 1550 in epoch 3, gen_loss = 1.4795351324351966, disc_loss = 0.0005749964174603008
Trained batch 1551 in epoch 3, gen_loss = 1.4796709815405078, disc_loss = 0.0005750242971583988
Trained batch 1552 in epoch 3, gen_loss = 1.4795466744354748, disc_loss = 0.0005750146547687874
Trained batch 1553 in epoch 3, gen_loss = 1.4797511115344182, disc_loss = 0.0005748457240365222
Trained batch 1554 in epoch 3, gen_loss = 1.4798692025555675, disc_loss = 0.0005748809882835709
Trained batch 1555 in epoch 3, gen_loss = 1.479819255806793, disc_loss = 0.0005748527743953135
Trained batch 1556 in epoch 3, gen_loss = 1.4799096454162206, disc_loss = 0.0005748105313550106
Trained batch 1557 in epoch 3, gen_loss = 1.480059805057168, disc_loss = 0.0005747443768265298
Trained batch 1558 in epoch 3, gen_loss = 1.4799397038373525, disc_loss = 0.0005746657383435384
Trained batch 1559 in epoch 3, gen_loss = 1.4801290253034005, disc_loss = 0.0005746063287985565
Trained batch 1560 in epoch 3, gen_loss = 1.480040082482479, disc_loss = 0.0005743985639897448
Trained batch 1561 in epoch 3, gen_loss = 1.4800927446685284, disc_loss = 0.0005742847667572508
Trained batch 1562 in epoch 3, gen_loss = 1.4799287935441225, disc_loss = 0.0005744739197885322
Trained batch 1563 in epoch 3, gen_loss = 1.4798274107296447, disc_loss = 0.0005748978806910423
Trained batch 1564 in epoch 3, gen_loss = 1.4796991436626203, disc_loss = 0.0005755829000447582
Trained batch 1565 in epoch 3, gen_loss = 1.4794717222490226, disc_loss = 0.0005764949818678934
Trained batch 1566 in epoch 3, gen_loss = 1.479560749958333, disc_loss = 0.0005781648136621422
Trained batch 1567 in epoch 3, gen_loss = 1.4795900548295098, disc_loss = 0.0005801878480956568
Trained batch 1568 in epoch 3, gen_loss = 1.4795862981055936, disc_loss = 0.0005816717619519921
Trained batch 1569 in epoch 3, gen_loss = 1.4794779154905089, disc_loss = 0.0005825337392272826
Trained batch 1570 in epoch 3, gen_loss = 1.4796083202641304, disc_loss = 0.0005824921180659082
Trained batch 1571 in epoch 3, gen_loss = 1.4797038292611828, disc_loss = 0.0005826703322469701
Trained batch 1572 in epoch 3, gen_loss = 1.4795777092901523, disc_loss = 0.0005833034072008703
Trained batch 1573 in epoch 3, gen_loss = 1.4795110146911505, disc_loss = 0.0005838648837626724
Trained batch 1574 in epoch 3, gen_loss = 1.4793756272300842, disc_loss = 0.0005838235461851582
Trained batch 1575 in epoch 3, gen_loss = 1.4793566808028875, disc_loss = 0.0005836417946051055
Trained batch 1576 in epoch 3, gen_loss = 1.4793778437939187, disc_loss = 0.0005834402651151763
Trained batch 1577 in epoch 3, gen_loss = 1.47927899052435, disc_loss = 0.0005832762372571856
Trained batch 1578 in epoch 3, gen_loss = 1.4790985999490884, disc_loss = 0.0005832285549180662
Trained batch 1579 in epoch 3, gen_loss = 1.4790213379678847, disc_loss = 0.0005829601849228898
Trained batch 1580 in epoch 3, gen_loss = 1.479063597983156, disc_loss = 0.0005827540638008327
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 1.2499229907989502, disc_loss = 0.0008767905528657138
Trained batch 1 in epoch 4, gen_loss = 1.3256697058677673, disc_loss = 0.0009073834517039359
Trained batch 2 in epoch 4, gen_loss = 1.3114752372105916, disc_loss = 0.0007212900479013721
Trained batch 3 in epoch 4, gen_loss = 1.359960675239563, disc_loss = 0.0006102078914409503
Trained batch 4 in epoch 4, gen_loss = 1.4048264026641846, disc_loss = 0.000570108531974256
Trained batch 5 in epoch 4, gen_loss = 1.4353440801302593, disc_loss = 0.0005106503158458509
Trained batch 6 in epoch 4, gen_loss = 1.4104218312672205, disc_loss = 0.0004880173593327137
Trained batch 7 in epoch 4, gen_loss = 1.419986143708229, disc_loss = 0.0004719464504887583
Trained batch 8 in epoch 4, gen_loss = 1.4055010080337524, disc_loss = 0.00043740544222398766
Trained batch 9 in epoch 4, gen_loss = 1.4533024787902833, disc_loss = 0.0004755321919219568
Trained batch 10 in epoch 4, gen_loss = 1.4421412619677456, disc_loss = 0.0005428200106094168
Trained batch 11 in epoch 4, gen_loss = 1.4466686447461445, disc_loss = 0.0005929863182245754
Trained batch 12 in epoch 4, gen_loss = 1.446128900234516, disc_loss = 0.0005911525289635533
Trained batch 13 in epoch 4, gen_loss = 1.4314501881599426, disc_loss = 0.0005750864781605612
Trained batch 14 in epoch 4, gen_loss = 1.4274223725001016, disc_loss = 0.0005719110621915509
Trained batch 15 in epoch 4, gen_loss = 1.4260395020246506, disc_loss = 0.0005798298097943189
Trained batch 16 in epoch 4, gen_loss = 1.4424791195813347, disc_loss = 0.0005816365609301583
Trained batch 17 in epoch 4, gen_loss = 1.4518316056993272, disc_loss = 0.0005657489770480121
Trained batch 18 in epoch 4, gen_loss = 1.4605952752263922, disc_loss = 0.0005447335937979484
Trained batch 19 in epoch 4, gen_loss = 1.4522653460502624, disc_loss = 0.0005287781925289892
Trained batch 20 in epoch 4, gen_loss = 1.4519526050204323, disc_loss = 0.0005228853884286114
Trained batch 21 in epoch 4, gen_loss = 1.449924496087161, disc_loss = 0.0005165386537555605
Trained batch 22 in epoch 4, gen_loss = 1.4498109247373498, disc_loss = 0.000503982217987473
Trained batch 23 in epoch 4, gen_loss = 1.4533371329307556, disc_loss = 0.000498600763118399
Trained batch 24 in epoch 4, gen_loss = 1.453317813873291, disc_loss = 0.0004943907196866349
Trained batch 25 in epoch 4, gen_loss = 1.4505135829632099, disc_loss = 0.0004883097129864977
Trained batch 26 in epoch 4, gen_loss = 1.4504226313696966, disc_loss = 0.00047740083957453154
Trained batch 27 in epoch 4, gen_loss = 1.4489222296646662, disc_loss = 0.0004669192172254303
Trained batch 28 in epoch 4, gen_loss = 1.4510026430261547, disc_loss = 0.0004606735952808682
Trained batch 29 in epoch 4, gen_loss = 1.453254234790802, disc_loss = 0.00045500207149113217
Trained batch 30 in epoch 4, gen_loss = 1.4551743076693626, disc_loss = 0.00044578046260041094
Trained batch 31 in epoch 4, gen_loss = 1.4444828256964684, disc_loss = 0.00044187085404701065
Trained batch 32 in epoch 4, gen_loss = 1.4549018505847815, disc_loss = 0.0004370815533382649
Trained batch 33 in epoch 4, gen_loss = 1.4575054750722998, disc_loss = 0.00043370137299301434
Trained batch 34 in epoch 4, gen_loss = 1.466032658304487, disc_loss = 0.00043202193503800247
Trained batch 35 in epoch 4, gen_loss = 1.4690828091568418, disc_loss = 0.00043039278211330786
Trained batch 36 in epoch 4, gen_loss = 1.4726586180764276, disc_loss = 0.0004287427794691679
Trained batch 37 in epoch 4, gen_loss = 1.4702045823398389, disc_loss = 0.00043255152903791324
Trained batch 38 in epoch 4, gen_loss = 1.472720253161895, disc_loss = 0.0004386664636862966
Trained batch 39 in epoch 4, gen_loss = 1.4702742129564286, disc_loss = 0.0004412017166032456
Trained batch 40 in epoch 4, gen_loss = 1.465732397102728, disc_loss = 0.0004380387963908838
Trained batch 41 in epoch 4, gen_loss = 1.4626016049158006, disc_loss = 0.0004353112308308482
Trained batch 42 in epoch 4, gen_loss = 1.4669786192650018, disc_loss = 0.00043075081626992934
Trained batch 43 in epoch 4, gen_loss = 1.4663293984803287, disc_loss = 0.000424829557397805
Trained batch 44 in epoch 4, gen_loss = 1.462425873014662, disc_loss = 0.0004201569174054182
Trained batch 45 in epoch 4, gen_loss = 1.45962103035139, disc_loss = 0.00041878279602236074
Trained batch 46 in epoch 4, gen_loss = 1.4603561898495288, disc_loss = 0.0004179768327455175
Trained batch 47 in epoch 4, gen_loss = 1.4625924229621887, disc_loss = 0.0004140572339868716
Trained batch 48 in epoch 4, gen_loss = 1.4711984128368145, disc_loss = 0.0004096285110976243
Trained batch 49 in epoch 4, gen_loss = 1.4665431737899781, disc_loss = 0.0004064062313409522
Trained batch 50 in epoch 4, gen_loss = 1.4644648701536889, disc_loss = 0.0004058231493485544
Trained batch 51 in epoch 4, gen_loss = 1.4651427154357617, disc_loss = 0.0004018370737657488
Trained batch 52 in epoch 4, gen_loss = 1.463489829369311, disc_loss = 0.0003972711142609423
Trained batch 53 in epoch 4, gen_loss = 1.46324650005058, disc_loss = 0.00039490030515783775
Trained batch 54 in epoch 4, gen_loss = 1.4628281918439, disc_loss = 0.00039318892416882924
Trained batch 55 in epoch 4, gen_loss = 1.4635965377092361, disc_loss = 0.00039311750567451654
Trained batch 56 in epoch 4, gen_loss = 1.4603225829308493, disc_loss = 0.0003929697569426999
Trained batch 57 in epoch 4, gen_loss = 1.4628901461075092, disc_loss = 0.0003905947809910466
Trained batch 58 in epoch 4, gen_loss = 1.463716363502761, disc_loss = 0.0003898766970111973
Trained batch 59 in epoch 4, gen_loss = 1.4660360316435497, disc_loss = 0.00039200081616096817
Trained batch 60 in epoch 4, gen_loss = 1.4683133793658898, disc_loss = 0.00039481027977403683
Trained batch 61 in epoch 4, gen_loss = 1.465273670611843, disc_loss = 0.00039236918171574813
Trained batch 62 in epoch 4, gen_loss = 1.465700073847695, disc_loss = 0.0003925558641120525
Trained batch 63 in epoch 4, gen_loss = 1.4647429306060076, disc_loss = 0.00040853231871551543
Trained batch 64 in epoch 4, gen_loss = 1.4618087841914251, disc_loss = 0.00043061795317603707
Trained batch 65 in epoch 4, gen_loss = 1.4580177466074626, disc_loss = 0.0004460343191043869
Trained batch 66 in epoch 4, gen_loss = 1.4558361288326889, disc_loss = 0.00044814916218999327
Trained batch 67 in epoch 4, gen_loss = 1.45719594113967, disc_loss = 0.00044472758899620897
Trained batch 68 in epoch 4, gen_loss = 1.4555452146391938, disc_loss = 0.0004457721517900464
Trained batch 69 in epoch 4, gen_loss = 1.4546732936586653, disc_loss = 0.00045189208758529277
Trained batch 70 in epoch 4, gen_loss = 1.4571560839532127, disc_loss = 0.00045666321792351214
Trained batch 71 in epoch 4, gen_loss = 1.4544560180770025, disc_loss = 0.0004589093704352207
Trained batch 72 in epoch 4, gen_loss = 1.4508892771315902, disc_loss = 0.00045775984970482757
Trained batch 73 in epoch 4, gen_loss = 1.451393863639316, disc_loss = 0.0004579592036001535
Trained batch 74 in epoch 4, gen_loss = 1.449851721127828, disc_loss = 0.00046842715819366275
Trained batch 75 in epoch 4, gen_loss = 1.4617384091803902, disc_loss = 0.0004793791981922512
Trained batch 76 in epoch 4, gen_loss = 1.4623079547634372, disc_loss = 0.0004875563132703643
Trained batch 77 in epoch 4, gen_loss = 1.465087502430647, disc_loss = 0.0004974337879013127
Trained batch 78 in epoch 4, gen_loss = 1.4632074440581888, disc_loss = 0.0005027244226340959
Trained batch 79 in epoch 4, gen_loss = 1.4678495869040489, disc_loss = 0.000502317022983334
Trained batch 80 in epoch 4, gen_loss = 1.4762788863829623, disc_loss = 0.0005015806930231643
Trained batch 81 in epoch 4, gen_loss = 1.4766535715359013, disc_loss = 0.0005001996376937846
Trained batch 82 in epoch 4, gen_loss = 1.4742745031793434, disc_loss = 0.0004982324015539903
Trained batch 83 in epoch 4, gen_loss = 1.4747408827145894, disc_loss = 0.0004957916122900011
Trained batch 84 in epoch 4, gen_loss = 1.4766377743552712, disc_loss = 0.0004927027071757681
Trained batch 85 in epoch 4, gen_loss = 1.4770802328752917, disc_loss = 0.0004909016121907138
Trained batch 86 in epoch 4, gen_loss = 1.477003978586745, disc_loss = 0.0004924890217598763
Trained batch 87 in epoch 4, gen_loss = 1.4769844805652446, disc_loss = 0.0004994631085124142
Trained batch 88 in epoch 4, gen_loss = 1.478035545081235, disc_loss = 0.0005048801509331221
Trained batch 89 in epoch 4, gen_loss = 1.475824491182963, disc_loss = 0.0005016407243803972
Trained batch 90 in epoch 4, gen_loss = 1.4720622890598172, disc_loss = 0.0005059933064730613
Trained batch 91 in epoch 4, gen_loss = 1.4730668547360792, disc_loss = 0.0005140996603902591
Trained batch 92 in epoch 4, gen_loss = 1.479269523774424, disc_loss = 0.0005185014007472864
Trained batch 93 in epoch 4, gen_loss = 1.4788975931228476, disc_loss = 0.0005263838213571208
Trained batch 94 in epoch 4, gen_loss = 1.4796389818191529, disc_loss = 0.0005380311086283703
Trained batch 95 in epoch 4, gen_loss = 1.4818842572470505, disc_loss = 0.0005584746625875899
Trained batch 96 in epoch 4, gen_loss = 1.4815025022349406, disc_loss = 0.0006052618450245139
Trained batch 97 in epoch 4, gen_loss = 1.4823517592585818, disc_loss = 0.00062872952548787
Trained batch 98 in epoch 4, gen_loss = 1.480625649895331, disc_loss = 0.0006397267829419838
Trained batch 99 in epoch 4, gen_loss = 1.4860627830028534, disc_loss = 0.0006686657189857215
Trained batch 100 in epoch 4, gen_loss = 1.49012293083833, disc_loss = 0.0006970835902663594
Trained batch 101 in epoch 4, gen_loss = 1.4880845792153303, disc_loss = 0.000706567702924504
Trained batch 102 in epoch 4, gen_loss = 1.4901801231995369, disc_loss = 0.0007084107339535885
Trained batch 103 in epoch 4, gen_loss = 1.4907258771933043, disc_loss = 0.0007088867110164406
Trained batch 104 in epoch 4, gen_loss = 1.490089173544021, disc_loss = 0.0007141650166539919
Trained batch 105 in epoch 4, gen_loss = 1.4876541079215284, disc_loss = 0.0007259072867696577
Trained batch 106 in epoch 4, gen_loss = 1.4880741266446693, disc_loss = 0.0007367305518519656
Trained batch 107 in epoch 4, gen_loss = 1.4877063852769357, disc_loss = 0.0007403586943702841
Trained batch 108 in epoch 4, gen_loss = 1.4865695774008374, disc_loss = 0.0007402720463829576
Trained batch 109 in epoch 4, gen_loss = 1.4858142386783253, disc_loss = 0.0007385900085368617
Trained batch 110 in epoch 4, gen_loss = 1.4886003840077031, disc_loss = 0.0007394115631426643
Trained batch 111 in epoch 4, gen_loss = 1.4869362807699613, disc_loss = 0.0007390126536068108
Trained batch 112 in epoch 4, gen_loss = 1.4855879249825943, disc_loss = 0.0007358483117139708
Trained batch 113 in epoch 4, gen_loss = 1.4836847353399845, disc_loss = 0.0007316812044703973
Trained batch 114 in epoch 4, gen_loss = 1.484132723186327, disc_loss = 0.0007285614913005543
Trained batch 115 in epoch 4, gen_loss = 1.4833177656962955, disc_loss = 0.0007241902547258209
Trained batch 116 in epoch 4, gen_loss = 1.485215063787933, disc_loss = 0.0007203998117265889
Trained batch 117 in epoch 4, gen_loss = 1.4851062853457564, disc_loss = 0.0007177627143761838
Trained batch 118 in epoch 4, gen_loss = 1.4846140136237906, disc_loss = 0.0007157516296455997
Trained batch 119 in epoch 4, gen_loss = 1.4832242846488952, disc_loss = 0.0007139723580621649
Trained batch 120 in epoch 4, gen_loss = 1.4870025619002414, disc_loss = 0.0007153226792415958
Trained batch 121 in epoch 4, gen_loss = 1.4865146982865256, disc_loss = 0.0007263620760478843
Trained batch 122 in epoch 4, gen_loss = 1.4856763622625087, disc_loss = 0.0007369168165681232
Trained batch 123 in epoch 4, gen_loss = 1.4856403816130854, disc_loss = 0.0007436155539190006
Trained batch 124 in epoch 4, gen_loss = 1.4880015411376952, disc_loss = 0.0007425225146580487
Trained batch 125 in epoch 4, gen_loss = 1.4862537573254297, disc_loss = 0.0007403225641206114
Trained batch 126 in epoch 4, gen_loss = 1.4861430295809048, disc_loss = 0.0007378252788710841
Trained batch 127 in epoch 4, gen_loss = 1.4862188789993525, disc_loss = 0.0007335486413921899
Trained batch 128 in epoch 4, gen_loss = 1.487364650696747, disc_loss = 0.0007293257981226527
Trained batch 129 in epoch 4, gen_loss = 1.4868947368401748, disc_loss = 0.0007267186340938609
Trained batch 130 in epoch 4, gen_loss = 1.4852836732645982, disc_loss = 0.0007241618743331619
Trained batch 131 in epoch 4, gen_loss = 1.4847970722299633, disc_loss = 0.0007200520656514334
Trained batch 132 in epoch 4, gen_loss = 1.4835454126946013, disc_loss = 0.000716945434254384
Trained batch 133 in epoch 4, gen_loss = 1.485214607929116, disc_loss = 0.0007143263565419839
Trained batch 134 in epoch 4, gen_loss = 1.4868522273169624, disc_loss = 0.0007109411620250385
Trained batch 135 in epoch 4, gen_loss = 1.4871367514133453, disc_loss = 0.0007071228301356314
Trained batch 136 in epoch 4, gen_loss = 1.4836738796999855, disc_loss = 0.0007077084120701196
Trained batch 137 in epoch 4, gen_loss = 1.4844196732493415, disc_loss = 0.0007102384283232665
Trained batch 138 in epoch 4, gen_loss = 1.4871266274143466, disc_loss = 0.0007162005589268231
Trained batch 139 in epoch 4, gen_loss = 1.4865117711680276, disc_loss = 0.0007272373534630917
Trained batch 140 in epoch 4, gen_loss = 1.4864055645381304, disc_loss = 0.0007337313226931101
Trained batch 141 in epoch 4, gen_loss = 1.4848497216130647, disc_loss = 0.0007420625449707535
Trained batch 142 in epoch 4, gen_loss = 1.484841415098497, disc_loss = 0.0007490995420440966
Trained batch 143 in epoch 4, gen_loss = 1.4866696099440257, disc_loss = 0.0007510694573890456
Trained batch 144 in epoch 4, gen_loss = 1.4863405556514346, disc_loss = 0.0007537732550127688
Trained batch 145 in epoch 4, gen_loss = 1.4877318503105477, disc_loss = 0.0007567249144999987
Trained batch 146 in epoch 4, gen_loss = 1.4867977885161938, disc_loss = 0.000758121011768417
Trained batch 147 in epoch 4, gen_loss = 1.4873617484762862, disc_loss = 0.0007594110957634748
Trained batch 148 in epoch 4, gen_loss = 1.4871199651052487, disc_loss = 0.0007594658921108638
Trained batch 149 in epoch 4, gen_loss = 1.4894444680213927, disc_loss = 0.0007587114336395946
Trained batch 150 in epoch 4, gen_loss = 1.4904553227077257, disc_loss = 0.0007583081369736966
Trained batch 151 in epoch 4, gen_loss = 1.4899519156468541, disc_loss = 0.0007573878552456767
Trained batch 152 in epoch 4, gen_loss = 1.4882144530614216, disc_loss = 0.0007558511356097262
Trained batch 153 in epoch 4, gen_loss = 1.487370477868365, disc_loss = 0.000752900666523235
Trained batch 154 in epoch 4, gen_loss = 1.4873898560001004, disc_loss = 0.0007497721159222325
Trained batch 155 in epoch 4, gen_loss = 1.4863210496230004, disc_loss = 0.0007476624237031688
Trained batch 156 in epoch 4, gen_loss = 1.4851785996916946, disc_loss = 0.0007462267192773177
Trained batch 157 in epoch 4, gen_loss = 1.4859802134429352, disc_loss = 0.0007451209021382965
Trained batch 158 in epoch 4, gen_loss = 1.485959490890023, disc_loss = 0.0007439370664479445
Trained batch 159 in epoch 4, gen_loss = 1.4860002979636193, disc_loss = 0.0007436259848873306
Trained batch 160 in epoch 4, gen_loss = 1.4873557460974463, disc_loss = 0.0007441733808868408
Trained batch 161 in epoch 4, gen_loss = 1.488168102723581, disc_loss = 0.0007472004554411224
Trained batch 162 in epoch 4, gen_loss = 1.4869118190250514, disc_loss = 0.0007495979011234501
Trained batch 163 in epoch 4, gen_loss = 1.4878453430606098, disc_loss = 0.0007468002789587112
Trained batch 164 in epoch 4, gen_loss = 1.4887936823295824, disc_loss = 0.000745157500337386
Trained batch 165 in epoch 4, gen_loss = 1.4885877564728978, disc_loss = 0.000744858896307204
Trained batch 166 in epoch 4, gen_loss = 1.4872390017538013, disc_loss = 0.0007442354478540099
Trained batch 167 in epoch 4, gen_loss = 1.4864076709463483, disc_loss = 0.0007419339520614207
Trained batch 168 in epoch 4, gen_loss = 1.4864043533449343, disc_loss = 0.0007397143343999464
Trained batch 169 in epoch 4, gen_loss = 1.4860418964834774, disc_loss = 0.0007375999070491696
Trained batch 170 in epoch 4, gen_loss = 1.4837780068492332, disc_loss = 0.0007354503117769967
Trained batch 171 in epoch 4, gen_loss = 1.485515003287515, disc_loss = 0.0007335311093748017
Trained batch 172 in epoch 4, gen_loss = 1.486927431442834, disc_loss = 0.0007309270676964291
Trained batch 173 in epoch 4, gen_loss = 1.4878553049317722, disc_loss = 0.0007279605280049948
Trained batch 174 in epoch 4, gen_loss = 1.4872335869925364, disc_loss = 0.0007249203937161447
Trained batch 175 in epoch 4, gen_loss = 1.4882738996635785, disc_loss = 0.0007221878244804843
Trained batch 176 in epoch 4, gen_loss = 1.4887063920834644, disc_loss = 0.0007204096950952353
Trained batch 177 in epoch 4, gen_loss = 1.4881872206591489, disc_loss = 0.0007181283869889167
Trained batch 178 in epoch 4, gen_loss = 1.4885515926936486, disc_loss = 0.0007157336089496017
Trained batch 179 in epoch 4, gen_loss = 1.4867234786351522, disc_loss = 0.0007145851346851688
Trained batch 180 in epoch 4, gen_loss = 1.4868872007612366, disc_loss = 0.000712145599797085
Trained batch 181 in epoch 4, gen_loss = 1.4879595532522096, disc_loss = 0.0007092795243766926
Trained batch 182 in epoch 4, gen_loss = 1.4878300467475516, disc_loss = 0.0007068169478338487
Trained batch 183 in epoch 4, gen_loss = 1.4902346386857654, disc_loss = 0.0007044466834169883
Trained batch 184 in epoch 4, gen_loss = 1.4902930221042117, disc_loss = 0.0007020271225121325
Trained batch 185 in epoch 4, gen_loss = 1.4903173600473711, disc_loss = 0.00070054921760006
Trained batch 186 in epoch 4, gen_loss = 1.489640724212728, disc_loss = 0.0007016901827179503
Trained batch 187 in epoch 4, gen_loss = 1.489518590429996, disc_loss = 0.0007028187479745805
Trained batch 188 in epoch 4, gen_loss = 1.4886357670738584, disc_loss = 0.0007022850261785572
Trained batch 189 in epoch 4, gen_loss = 1.4884732265221445, disc_loss = 0.0007008135596774273
Trained batch 190 in epoch 4, gen_loss = 1.4880915106279065, disc_loss = 0.0007010700176707689
Trained batch 191 in epoch 4, gen_loss = 1.4870592821389437, disc_loss = 0.000708001084224937
Trained batch 192 in epoch 4, gen_loss = 1.4873048147389307, disc_loss = 0.0007187037328662293
Trained batch 193 in epoch 4, gen_loss = 1.4858843278639096, disc_loss = 0.0007226353722892116
Trained batch 194 in epoch 4, gen_loss = 1.4861277085084181, disc_loss = 0.0007235387802118053
Trained batch 195 in epoch 4, gen_loss = 1.484581355537687, disc_loss = 0.0007231343036121926
Trained batch 196 in epoch 4, gen_loss = 1.4846651959540276, disc_loss = 0.0007251269117719848
Trained batch 197 in epoch 4, gen_loss = 1.4847372824495488, disc_loss = 0.0007272250470417232
Trained batch 198 in epoch 4, gen_loss = 1.4847017945955747, disc_loss = 0.0007275264295860517
Trained batch 199 in epoch 4, gen_loss = 1.4846138578653336, disc_loss = 0.0007282961534656352
Trained batch 200 in epoch 4, gen_loss = 1.484112092511571, disc_loss = 0.000728297694479069
Trained batch 201 in epoch 4, gen_loss = 1.4823402337508627, disc_loss = 0.0007259945525922628
Trained batch 202 in epoch 4, gen_loss = 1.4831655959190406, disc_loss = 0.0007262608462060329
Trained batch 203 in epoch 4, gen_loss = 1.4835057580003552, disc_loss = 0.0007268254079213412
Trained batch 204 in epoch 4, gen_loss = 1.4826602848564707, disc_loss = 0.0007260253929061724
Trained batch 205 in epoch 4, gen_loss = 1.4820197322993602, disc_loss = 0.0007263919148843926
Trained batch 206 in epoch 4, gen_loss = 1.4805153936579607, disc_loss = 0.0007277210673979812
Trained batch 207 in epoch 4, gen_loss = 1.481065178146729, disc_loss = 0.0007267680090920364
Trained batch 208 in epoch 4, gen_loss = 1.4793113606968564, disc_loss = 0.0007253473401921868
Trained batch 209 in epoch 4, gen_loss = 1.47828350123905, disc_loss = 0.0007232937851638001
Trained batch 210 in epoch 4, gen_loss = 1.4784700322490167, disc_loss = 0.0007214437733913035
Trained batch 211 in epoch 4, gen_loss = 1.478554960691704, disc_loss = 0.0007189974460760703
Trained batch 212 in epoch 4, gen_loss = 1.4776694819401128, disc_loss = 0.0007168299478490754
Trained batch 213 in epoch 4, gen_loss = 1.4777587011595752, disc_loss = 0.0007152775243097681
Trained batch 214 in epoch 4, gen_loss = 1.479755460938742, disc_loss = 0.0007151753389206173
Trained batch 215 in epoch 4, gen_loss = 1.4794797317849264, disc_loss = 0.0007171139691140356
Trained batch 216 in epoch 4, gen_loss = 1.4783565113621373, disc_loss = 0.0007188745603595178
Trained batch 217 in epoch 4, gen_loss = 1.4787609582647272, disc_loss = 0.0007174226466471269
Trained batch 218 in epoch 4, gen_loss = 1.4783271453151965, disc_loss = 0.0007161311233138717
Trained batch 219 in epoch 4, gen_loss = 1.479645046862689, disc_loss = 0.0007155892737500836
Trained batch 220 in epoch 4, gen_loss = 1.4789822220262898, disc_loss = 0.0007137828121331575
Trained batch 221 in epoch 4, gen_loss = 1.47729902117102, disc_loss = 0.0007116549324138334
Trained batch 222 in epoch 4, gen_loss = 1.4784145023790711, disc_loss = 0.000709966373942571
Trained batch 223 in epoch 4, gen_loss = 1.4790265980575765, disc_loss = 0.0007081289824912217
Trained batch 224 in epoch 4, gen_loss = 1.478021592564053, disc_loss = 0.0007060864210102914
Trained batch 225 in epoch 4, gen_loss = 1.4771059978324754, disc_loss = 0.0007039825096535826
Trained batch 226 in epoch 4, gen_loss = 1.4766845151716392, disc_loss = 0.0007030810572443907
Trained batch 227 in epoch 4, gen_loss = 1.4770365958673912, disc_loss = 0.0007042560481702248
Trained batch 228 in epoch 4, gen_loss = 1.4760827211313372, disc_loss = 0.0007064875624397786
Trained batch 229 in epoch 4, gen_loss = 1.4770096913627957, disc_loss = 0.0007074878446671748
Trained batch 230 in epoch 4, gen_loss = 1.4763242904241982, disc_loss = 0.0007071130491618784
Trained batch 231 in epoch 4, gen_loss = 1.4758574310047874, disc_loss = 0.0007059840786653161
Trained batch 232 in epoch 4, gen_loss = 1.475379820033716, disc_loss = 0.0007040793633377259
Trained batch 233 in epoch 4, gen_loss = 1.4740518749269664, disc_loss = 0.0007053018328320816
Trained batch 234 in epoch 4, gen_loss = 1.4731941121689818, disc_loss = 0.0007086624030365629
Trained batch 235 in epoch 4, gen_loss = 1.4729101819507147, disc_loss = 0.0007099141895211641
Trained batch 236 in epoch 4, gen_loss = 1.4731321354958578, disc_loss = 0.0007087383618826864
Trained batch 237 in epoch 4, gen_loss = 1.472893529579419, disc_loss = 0.0007068678872300774
Trained batch 238 in epoch 4, gen_loss = 1.4726850762028076, disc_loss = 0.0007056945063116294
Trained batch 239 in epoch 4, gen_loss = 1.47184313784043, disc_loss = 0.0007048196395165481
Trained batch 240 in epoch 4, gen_loss = 1.4706382791036392, disc_loss = 0.0007028587787321293
Trained batch 241 in epoch 4, gen_loss = 1.4700680074612957, disc_loss = 0.0007013917407780993
Trained batch 242 in epoch 4, gen_loss = 1.4709346304214541, disc_loss = 0.0007002701351194884
Trained batch 243 in epoch 4, gen_loss = 1.4713434015141158, disc_loss = 0.0006993542835412196
Trained batch 244 in epoch 4, gen_loss = 1.4710876756784868, disc_loss = 0.0006989555912120838
Trained batch 245 in epoch 4, gen_loss = 1.4705913706523617, disc_loss = 0.0007006960888573052
Trained batch 246 in epoch 4, gen_loss = 1.4694032688372531, disc_loss = 0.0007036353779819074
Trained batch 247 in epoch 4, gen_loss = 1.4693637105726427, disc_loss = 0.0007046190422120309
Trained batch 248 in epoch 4, gen_loss = 1.4695966641108196, disc_loss = 0.0007058622865576716
Trained batch 249 in epoch 4, gen_loss = 1.4687670884132384, disc_loss = 0.000705872378894128
Trained batch 250 in epoch 4, gen_loss = 1.4694439429210953, disc_loss = 0.0007044980450870981
Trained batch 251 in epoch 4, gen_loss = 1.4689832902143871, disc_loss = 0.0007050740421705303
Trained batch 252 in epoch 4, gen_loss = 1.4685515349090335, disc_loss = 0.0007061337711190134
Trained batch 253 in epoch 4, gen_loss = 1.4692367878485852, disc_loss = 0.000707491901639013
Trained batch 254 in epoch 4, gen_loss = 1.470024160310334, disc_loss = 0.0007078771518232922
Trained batch 255 in epoch 4, gen_loss = 1.4708669506944716, disc_loss = 0.0007090906531175278
Trained batch 256 in epoch 4, gen_loss = 1.4705355640515279, disc_loss = 0.0007100961230430709
Trained batch 257 in epoch 4, gen_loss = 1.4697316801825235, disc_loss = 0.0007100093238012389
Trained batch 258 in epoch 4, gen_loss = 1.4700828104866057, disc_loss = 0.000708728693277327
Trained batch 259 in epoch 4, gen_loss = 1.4685832862670605, disc_loss = 0.0007103689954069873
Trained batch 260 in epoch 4, gen_loss = 1.4682293847146162, disc_loss = 0.0007119981831401744
Trained batch 261 in epoch 4, gen_loss = 1.4674528541455742, disc_loss = 0.0007102525694596133
Trained batch 262 in epoch 4, gen_loss = 1.4683999575589546, disc_loss = 0.0007095998742913353
Trained batch 263 in epoch 4, gen_loss = 1.4684370841943857, disc_loss = 0.0007094891600100902
Trained batch 264 in epoch 4, gen_loss = 1.468395354162972, disc_loss = 0.0007097341301455602
Trained batch 265 in epoch 4, gen_loss = 1.4689934885591494, disc_loss = 0.0007102737515942453
Trained batch 266 in epoch 4, gen_loss = 1.4683625032839258, disc_loss = 0.0007116406710603892
Trained batch 267 in epoch 4, gen_loss = 1.467572357672364, disc_loss = 0.0007121609898549921
Trained batch 268 in epoch 4, gen_loss = 1.4677504912628117, disc_loss = 0.0007134769082659696
Trained batch 269 in epoch 4, gen_loss = 1.4671386339046337, disc_loss = 0.0007165193433778498
Trained batch 270 in epoch 4, gen_loss = 1.466110460432693, disc_loss = 0.0007192547038082391
Trained batch 271 in epoch 4, gen_loss = 1.465903172159896, disc_loss = 0.0007205462822158177
Trained batch 272 in epoch 4, gen_loss = 1.46571923044575, disc_loss = 0.0007186606007729633
Trained batch 273 in epoch 4, gen_loss = 1.4653921688560152, disc_loss = 0.0007175502909987275
Trained batch 274 in epoch 4, gen_loss = 1.4654354732686823, disc_loss = 0.0007168078964935955
Trained batch 275 in epoch 4, gen_loss = 1.465901915145957, disc_loss = 0.0007161513801121686
Trained batch 276 in epoch 4, gen_loss = 1.4655104565706494, disc_loss = 0.0007147488536986452
Trained batch 277 in epoch 4, gen_loss = 1.4656650844237786, disc_loss = 0.0007134518155718404
Trained batch 278 in epoch 4, gen_loss = 1.4663332478547182, disc_loss = 0.0007127646499628027
Trained batch 279 in epoch 4, gen_loss = 1.4651677936315537, disc_loss = 0.0007119706481067364
Trained batch 280 in epoch 4, gen_loss = 1.464009812293952, disc_loss = 0.0007107885546872088
Trained batch 281 in epoch 4, gen_loss = 1.4634673100836733, disc_loss = 0.0007094170826265146
Trained batch 282 in epoch 4, gen_loss = 1.4637590912121345, disc_loss = 0.0007077819506194304
Trained batch 283 in epoch 4, gen_loss = 1.4634315564598837, disc_loss = 0.0007067226555668192
Trained batch 284 in epoch 4, gen_loss = 1.4636036697186923, disc_loss = 0.0007057807065664971
Trained batch 285 in epoch 4, gen_loss = 1.4630533769414142, disc_loss = 0.0007053357630929832
Trained batch 286 in epoch 4, gen_loss = 1.4638005578144087, disc_loss = 0.0007049073956485754
Trained batch 287 in epoch 4, gen_loss = 1.4634464519719284, disc_loss = 0.0007040032178843427
Trained batch 288 in epoch 4, gen_loss = 1.4635211105577675, disc_loss = 0.0007026955369230728
Trained batch 289 in epoch 4, gen_loss = 1.4648800673155948, disc_loss = 0.0007011057785411109
Trained batch 290 in epoch 4, gen_loss = 1.4645437506056322, disc_loss = 0.0006991256758709889
Trained batch 291 in epoch 4, gen_loss = 1.463879061888342, disc_loss = 0.000697462514374957
Trained batch 292 in epoch 4, gen_loss = 1.4638875897833918, disc_loss = 0.0006968069143864285
Trained batch 293 in epoch 4, gen_loss = 1.464715630424266, disc_loss = 0.000696190768945091
Trained batch 294 in epoch 4, gen_loss = 1.4657962237374258, disc_loss = 0.0006949710432278245
Trained batch 295 in epoch 4, gen_loss = 1.4652243457935952, disc_loss = 0.0006938776884969746
Trained batch 296 in epoch 4, gen_loss = 1.4645380608561867, disc_loss = 0.0006930930272935536
Trained batch 297 in epoch 4, gen_loss = 1.4656872309294322, disc_loss = 0.000691919731460246
Trained batch 298 in epoch 4, gen_loss = 1.4644055254881996, disc_loss = 0.0006912190771882071
Trained batch 299 in epoch 4, gen_loss = 1.463484033346176, disc_loss = 0.0006918503679238105
Trained batch 300 in epoch 4, gen_loss = 1.463882869264216, disc_loss = 0.000692990962158737
Trained batch 301 in epoch 4, gen_loss = 1.4652239743447462, disc_loss = 0.0006941420371418306
Trained batch 302 in epoch 4, gen_loss = 1.4654456534401419, disc_loss = 0.0006933936975737296
Trained batch 303 in epoch 4, gen_loss = 1.4641236372684177, disc_loss = 0.0006917273489977417
Trained batch 304 in epoch 4, gen_loss = 1.4638563812756147, disc_loss = 0.0006902763461617784
Trained batch 305 in epoch 4, gen_loss = 1.4643542836694157, disc_loss = 0.0006906239715712206
Trained batch 306 in epoch 4, gen_loss = 1.4649204679731438, disc_loss = 0.0006945972504922422
Trained batch 307 in epoch 4, gen_loss = 1.4658110675873695, disc_loss = 0.0007013201412318468
Trained batch 308 in epoch 4, gen_loss = 1.466129699571233, disc_loss = 0.0007084058068352104
Trained batch 309 in epoch 4, gen_loss = 1.465967599807247, disc_loss = 0.0007100133921936034
Trained batch 310 in epoch 4, gen_loss = 1.4663747342069815, disc_loss = 0.000710198747247182
Trained batch 311 in epoch 4, gen_loss = 1.4661508355385218, disc_loss = 0.0007104844976894151
Trained batch 312 in epoch 4, gen_loss = 1.466142892456664, disc_loss = 0.0007102729502720193
Trained batch 313 in epoch 4, gen_loss = 1.4666840642880483, disc_loss = 0.0007092880623994965
Trained batch 314 in epoch 4, gen_loss = 1.4662308867015537, disc_loss = 0.0007081186168804943
Trained batch 315 in epoch 4, gen_loss = 1.4678156519237953, disc_loss = 0.0007073147058644615
Trained batch 316 in epoch 4, gen_loss = 1.46720681130322, disc_loss = 0.0007070986101769605
Trained batch 317 in epoch 4, gen_loss = 1.4667208048532594, disc_loss = 0.0007062808013961902
Trained batch 318 in epoch 4, gen_loss = 1.466566656450493, disc_loss = 0.0007050261435173394
Trained batch 319 in epoch 4, gen_loss = 1.4669552065432072, disc_loss = 0.000704316216888401
Trained batch 320 in epoch 4, gen_loss = 1.46690645990342, disc_loss = 0.0007043591390597428
Trained batch 321 in epoch 4, gen_loss = 1.4666566819137667, disc_loss = 0.0007045412399431528
Trained batch 322 in epoch 4, gen_loss = 1.4662352545711648, disc_loss = 0.00070385018835023
Trained batch 323 in epoch 4, gen_loss = 1.465979477137695, disc_loss = 0.0007032147320533563
Trained batch 324 in epoch 4, gen_loss = 1.4661710713459895, disc_loss = 0.0007019380154983642
Trained batch 325 in epoch 4, gen_loss = 1.4660208572639277, disc_loss = 0.0007009150293774252
Trained batch 326 in epoch 4, gen_loss = 1.46562188881982, disc_loss = 0.000699271569000016
Trained batch 327 in epoch 4, gen_loss = 1.4654096517621018, disc_loss = 0.0006980448828161149
Trained batch 328 in epoch 4, gen_loss = 1.4654692795501292, disc_loss = 0.0006969795604965346
Trained batch 329 in epoch 4, gen_loss = 1.4659102418205954, disc_loss = 0.0006956650490103515
Trained batch 330 in epoch 4, gen_loss = 1.4675879644123089, disc_loss = 0.0006942674902312069
Trained batch 331 in epoch 4, gen_loss = 1.4668599708252643, disc_loss = 0.0006926826345408195
Trained batch 332 in epoch 4, gen_loss = 1.4671453928446268, disc_loss = 0.000691026470485121
Trained batch 333 in epoch 4, gen_loss = 1.4680212882464518, disc_loss = 0.0006895780138212011
Trained batch 334 in epoch 4, gen_loss = 1.4679031258198751, disc_loss = 0.0006881227850159908
Trained batch 335 in epoch 4, gen_loss = 1.467255164824781, disc_loss = 0.0006871210641856166
Trained batch 336 in epoch 4, gen_loss = 1.46651131144617, disc_loss = 0.0006882616158388969
Trained batch 337 in epoch 4, gen_loss = 1.4657858299785818, disc_loss = 0.0006896233691654124
Trained batch 338 in epoch 4, gen_loss = 1.4650016541326292, disc_loss = 0.0006898715461526687
Trained batch 339 in epoch 4, gen_loss = 1.4656332994208616, disc_loss = 0.0006892256373248528
Trained batch 340 in epoch 4, gen_loss = 1.4647034647877266, disc_loss = 0.0006895592064331108
Trained batch 341 in epoch 4, gen_loss = 1.4638305219293337, disc_loss = 0.0006899301466727439
Trained batch 342 in epoch 4, gen_loss = 1.4639671133836574, disc_loss = 0.0006899253923684201
Trained batch 343 in epoch 4, gen_loss = 1.4632149588230043, disc_loss = 0.0006894959152664658
Trained batch 344 in epoch 4, gen_loss = 1.4624077472133914, disc_loss = 0.0006887119045342737
Trained batch 345 in epoch 4, gen_loss = 1.4620770650102912, disc_loss = 0.0006876627217209091
Trained batch 346 in epoch 4, gen_loss = 1.4623548105058477, disc_loss = 0.0006864690924280052
Trained batch 347 in epoch 4, gen_loss = 1.4617213086150158, disc_loss = 0.0006851254984212574
Trained batch 348 in epoch 4, gen_loss = 1.4610851282376613, disc_loss = 0.0006837488092794977
Trained batch 349 in epoch 4, gen_loss = 1.4615701328005108, disc_loss = 0.000682735204754863
Trained batch 350 in epoch 4, gen_loss = 1.4624267137288367, disc_loss = 0.0006815604686035915
Trained batch 351 in epoch 4, gen_loss = 1.462661419741132, disc_loss = 0.000680756851042216
Trained batch 352 in epoch 4, gen_loss = 1.4624230412518338, disc_loss = 0.0006804077264970886
Trained batch 353 in epoch 4, gen_loss = 1.461766916479768, disc_loss = 0.0006802463407038269
Trained batch 354 in epoch 4, gen_loss = 1.4605872268408118, disc_loss = 0.0006806840690125016
Trained batch 355 in epoch 4, gen_loss = 1.461267480019773, disc_loss = 0.0006807600015174634
Trained batch 356 in epoch 4, gen_loss = 1.461405165055219, disc_loss = 0.0006796403529030513
Trained batch 357 in epoch 4, gen_loss = 1.4612440243779614, disc_loss = 0.0006785187292658703
Trained batch 358 in epoch 4, gen_loss = 1.4618062893328228, disc_loss = 0.0006772822616210021
Trained batch 359 in epoch 4, gen_loss = 1.4619189666377173, disc_loss = 0.000676068050274302
Trained batch 360 in epoch 4, gen_loss = 1.4623467271678006, disc_loss = 0.0006752226514521847
Trained batch 361 in epoch 4, gen_loss = 1.4616259152059397, disc_loss = 0.0006748677547091685
Trained batch 362 in epoch 4, gen_loss = 1.4612378545372282, disc_loss = 0.0006739508157218204
Trained batch 363 in epoch 4, gen_loss = 1.4611160633983193, disc_loss = 0.0006736828620557719
Trained batch 364 in epoch 4, gen_loss = 1.4609502717240217, disc_loss = 0.0006731837954011759
Trained batch 365 in epoch 4, gen_loss = 1.460798863830462, disc_loss = 0.0006732627621179451
Trained batch 366 in epoch 4, gen_loss = 1.4613610876353624, disc_loss = 0.0006737955606003909
Trained batch 367 in epoch 4, gen_loss = 1.4609853547552358, disc_loss = 0.0006743686384968738
Trained batch 368 in epoch 4, gen_loss = 1.4607850287341813, disc_loss = 0.000674443798470008
Trained batch 369 in epoch 4, gen_loss = 1.4606796177657875, disc_loss = 0.0006741418482380214
Trained batch 370 in epoch 4, gen_loss = 1.460865861322038, disc_loss = 0.000673984951956883
Trained batch 371 in epoch 4, gen_loss = 1.4612671527811276, disc_loss = 0.0006735322779712332
Trained batch 372 in epoch 4, gen_loss = 1.4613967900621347, disc_loss = 0.0006724295602975933
Trained batch 373 in epoch 4, gen_loss = 1.461447368331134, disc_loss = 0.0006711883496485008
Trained batch 374 in epoch 4, gen_loss = 1.4609689292907715, disc_loss = 0.0006702190492845451
Trained batch 375 in epoch 4, gen_loss = 1.4608970671258075, disc_loss = 0.0006693845902810472
Trained batch 376 in epoch 4, gen_loss = 1.4610520206016318, disc_loss = 0.0006684777941767852
Trained batch 377 in epoch 4, gen_loss = 1.4611736504489152, disc_loss = 0.0006675869953666479
Trained batch 378 in epoch 4, gen_loss = 1.461251335282439, disc_loss = 0.0006665532043867801
Trained batch 379 in epoch 4, gen_loss = 1.4607854952937678, disc_loss = 0.0006654126962530426
Trained batch 380 in epoch 4, gen_loss = 1.4608895687919277, disc_loss = 0.0006642161905637202
Trained batch 381 in epoch 4, gen_loss = 1.4623723076900264, disc_loss = 0.0006633829669045597
Trained batch 382 in epoch 4, gen_loss = 1.4623942316045337, disc_loss = 0.000663263240495366
Trained batch 383 in epoch 4, gen_loss = 1.463175231590867, disc_loss = 0.0006631924369836876
Trained batch 384 in epoch 4, gen_loss = 1.463054338678137, disc_loss = 0.000663011322212224
Trained batch 385 in epoch 4, gen_loss = 1.462650425075867, disc_loss = 0.0006626971390060936
Trained batch 386 in epoch 4, gen_loss = 1.4635415234306985, disc_loss = 0.0006628852002641538
Trained batch 387 in epoch 4, gen_loss = 1.464346109899049, disc_loss = 0.0006630394631635503
Trained batch 388 in epoch 4, gen_loss = 1.4647736751634848, disc_loss = 0.0006637101089025209
Trained batch 389 in epoch 4, gen_loss = 1.465271463149633, disc_loss = 0.0006665473641941133
Trained batch 390 in epoch 4, gen_loss = 1.4657549278815385, disc_loss = 0.0006676894755375421
Trained batch 391 in epoch 4, gen_loss = 1.4651170892983068, disc_loss = 0.0006688786399573306
Trained batch 392 in epoch 4, gen_loss = 1.4650030885337266, disc_loss = 0.00067002168504353
Trained batch 393 in epoch 4, gen_loss = 1.465299806316492, disc_loss = 0.0006698310366497248
Trained batch 394 in epoch 4, gen_loss = 1.4659425267690345, disc_loss = 0.0006690625274477268
Trained batch 395 in epoch 4, gen_loss = 1.4655357617320437, disc_loss = 0.0006680348182492183
Trained batch 396 in epoch 4, gen_loss = 1.4647594197871403, disc_loss = 0.000666700831565464
Trained batch 397 in epoch 4, gen_loss = 1.4642635910355266, disc_loss = 0.0006653869366428309
Trained batch 398 in epoch 4, gen_loss = 1.4650936936376089, disc_loss = 0.0006640787545812169
Trained batch 399 in epoch 4, gen_loss = 1.4647283187508584, disc_loss = 0.0006633904502814403
Trained batch 400 in epoch 4, gen_loss = 1.4651363636192836, disc_loss = 0.0006634014523779727
Trained batch 401 in epoch 4, gen_loss = 1.4659216409891993, disc_loss = 0.0006636690998661902
Trained batch 402 in epoch 4, gen_loss = 1.4660357784100857, disc_loss = 0.0006645029928811384
Trained batch 403 in epoch 4, gen_loss = 1.4650953547789318, disc_loss = 0.0006645029464172947
Trained batch 404 in epoch 4, gen_loss = 1.4652231519604906, disc_loss = 0.0006637640305317616
Trained batch 405 in epoch 4, gen_loss = 1.4645280306562414, disc_loss = 0.0006627574935211373
Trained batch 406 in epoch 4, gen_loss = 1.4648869251443362, disc_loss = 0.0006618333789657261
Trained batch 407 in epoch 4, gen_loss = 1.4653698097841412, disc_loss = 0.0006613113029172882
Trained batch 408 in epoch 4, gen_loss = 1.4653527797871522, disc_loss = 0.0006614005852611348
Trained batch 409 in epoch 4, gen_loss = 1.4642134701333396, disc_loss = 0.0006628788776252782
Trained batch 410 in epoch 4, gen_loss = 1.4635657280901053, disc_loss = 0.000666112151396871
Trained batch 411 in epoch 4, gen_loss = 1.4639313247018648, disc_loss = 0.0006733499316202513
Trained batch 412 in epoch 4, gen_loss = 1.463529023650772, disc_loss = 0.0006807506898785637
Trained batch 413 in epoch 4, gen_loss = 1.4638241739664677, disc_loss = 0.0006845132499800518
Trained batch 414 in epoch 4, gen_loss = 1.4637670413557304, disc_loss = 0.0006850128522120326
Trained batch 415 in epoch 4, gen_loss = 1.4640448563374007, disc_loss = 0.0006852583192085149
Trained batch 416 in epoch 4, gen_loss = 1.463926054305024, disc_loss = 0.0006876345739221955
Trained batch 417 in epoch 4, gen_loss = 1.463635133213974, disc_loss = 0.0006887704368210598
Trained batch 418 in epoch 4, gen_loss = 1.4632005921980646, disc_loss = 0.0006883556398603096
Trained batch 419 in epoch 4, gen_loss = 1.463813568013055, disc_loss = 0.0006881143461214378
Trained batch 420 in epoch 4, gen_loss = 1.4633195306796076, disc_loss = 0.0006876467315661511
Trained batch 421 in epoch 4, gen_loss = 1.4630292617314236, disc_loss = 0.0006869283206297429
Trained batch 422 in epoch 4, gen_loss = 1.4641961902027716, disc_loss = 0.0006865156243663132
Trained batch 423 in epoch 4, gen_loss = 1.4633046082168255, disc_loss = 0.0006863847567111183
Trained batch 424 in epoch 4, gen_loss = 1.4634066051595351, disc_loss = 0.0006862713221241446
Trained batch 425 in epoch 4, gen_loss = 1.463191763056276, disc_loss = 0.0006857954818693081
Trained batch 426 in epoch 4, gen_loss = 1.4627689366039125, disc_loss = 0.0006852609177520259
Trained batch 427 in epoch 4, gen_loss = 1.4632048782344176, disc_loss = 0.000684184797511275
Trained batch 428 in epoch 4, gen_loss = 1.4630156869377011, disc_loss = 0.000684509759984307
Trained batch 429 in epoch 4, gen_loss = 1.462315683309422, disc_loss = 0.0006861232541268691
Trained batch 430 in epoch 4, gen_loss = 1.4625956409215375, disc_loss = 0.0006867936477275769
Trained batch 431 in epoch 4, gen_loss = 1.4624375640242189, disc_loss = 0.0006866304640290629
Trained batch 432 in epoch 4, gen_loss = 1.462261660820342, disc_loss = 0.0006861130550490826
Trained batch 433 in epoch 4, gen_loss = 1.461642877846819, disc_loss = 0.0006854703667582214
Trained batch 434 in epoch 4, gen_loss = 1.4616932049564932, disc_loss = 0.0006852897582575679
Trained batch 435 in epoch 4, gen_loss = 1.4624683575345836, disc_loss = 0.0006846732382797166
Trained batch 436 in epoch 4, gen_loss = 1.4628809150350994, disc_loss = 0.0006845191978099298
Trained batch 437 in epoch 4, gen_loss = 1.4634356234715953, disc_loss = 0.0006839380856442848
Trained batch 438 in epoch 4, gen_loss = 1.4629796873735676, disc_loss = 0.0006840312881962712
Trained batch 439 in epoch 4, gen_loss = 1.4620377789844166, disc_loss = 0.0006860475052566141
Trained batch 440 in epoch 4, gen_loss = 1.461876128806549, disc_loss = 0.0006874787360255537
Trained batch 441 in epoch 4, gen_loss = 1.4623928531262669, disc_loss = 0.0006876493691823897
Trained batch 442 in epoch 4, gen_loss = 1.4627416055842932, disc_loss = 0.0006867984140819489
Trained batch 443 in epoch 4, gen_loss = 1.4628905092810724, disc_loss = 0.00068568811453129
Trained batch 444 in epoch 4, gen_loss = 1.4626458114452576, disc_loss = 0.0006845961664960291
Trained batch 445 in epoch 4, gen_loss = 1.4624355347167215, disc_loss = 0.0006834591344477099
Trained batch 446 in epoch 4, gen_loss = 1.4625132766612692, disc_loss = 0.0006825812233240037
Trained batch 447 in epoch 4, gen_loss = 1.462945677872215, disc_loss = 0.0006820087467401338
Trained batch 448 in epoch 4, gen_loss = 1.463637418895628, disc_loss = 0.0006817766007104419
Trained batch 449 in epoch 4, gen_loss = 1.4636247295803493, disc_loss = 0.0006816187428517474
Trained batch 450 in epoch 4, gen_loss = 1.4634050696493517, disc_loss = 0.0006806996393899233
Trained batch 451 in epoch 4, gen_loss = 1.4634550203264287, disc_loss = 0.0006797508885455524
Trained batch 452 in epoch 4, gen_loss = 1.4630970310164866, disc_loss = 0.0006791776750045551
Trained batch 453 in epoch 4, gen_loss = 1.4628067405213343, disc_loss = 0.0006790757404911098
Trained batch 454 in epoch 4, gen_loss = 1.4637060424783728, disc_loss = 0.0006781496824619903
Trained batch 455 in epoch 4, gen_loss = 1.4636917001845544, disc_loss = 0.0006774905395695098
Trained batch 456 in epoch 4, gen_loss = 1.4627568009645724, disc_loss = 0.0006767688034417177
Trained batch 457 in epoch 4, gen_loss = 1.4632318816330756, disc_loss = 0.0006758618755947278
Trained batch 458 in epoch 4, gen_loss = 1.463778680186386, disc_loss = 0.0006749909626033912
Trained batch 459 in epoch 4, gen_loss = 1.4639110153136046, disc_loss = 0.0006742552209407618
Trained batch 460 in epoch 4, gen_loss = 1.464308611741552, disc_loss = 0.0006736787269649514
Trained batch 461 in epoch 4, gen_loss = 1.4638684536471511, disc_loss = 0.000672879358524259
Trained batch 462 in epoch 4, gen_loss = 1.4631072998561818, disc_loss = 0.0006718236245413574
Trained batch 463 in epoch 4, gen_loss = 1.4631838104848205, disc_loss = 0.0006707242627553882
Trained batch 464 in epoch 4, gen_loss = 1.4629113240908551, disc_loss = 0.0006695669975572376
Trained batch 465 in epoch 4, gen_loss = 1.4629105787420478, disc_loss = 0.0006686539516038293
Trained batch 466 in epoch 4, gen_loss = 1.4634238619365325, disc_loss = 0.0006683763503672843
Trained batch 467 in epoch 4, gen_loss = 1.462847965140628, disc_loss = 0.0006679576692212687
Trained batch 468 in epoch 4, gen_loss = 1.463041816693125, disc_loss = 0.0006672323625006064
Trained batch 469 in epoch 4, gen_loss = 1.4634848363856052, disc_loss = 0.0006662143783846949
Trained batch 470 in epoch 4, gen_loss = 1.463278876241858, disc_loss = 0.0006651794965499557
Trained batch 471 in epoch 4, gen_loss = 1.4639369335214971, disc_loss = 0.000664355803364434
Trained batch 472 in epoch 4, gen_loss = 1.4639408900924262, disc_loss = 0.0006637791420621541
Trained batch 473 in epoch 4, gen_loss = 1.4639716254004949, disc_loss = 0.0006630139225599737
Trained batch 474 in epoch 4, gen_loss = 1.4637994530326441, disc_loss = 0.0006620324724721477
Trained batch 475 in epoch 4, gen_loss = 1.464019496400817, disc_loss = 0.0006609322436135791
Trained batch 476 in epoch 4, gen_loss = 1.4642534995728818, disc_loss = 0.0006598598498019314
Trained batch 477 in epoch 4, gen_loss = 1.4644417298887564, disc_loss = 0.0006590560856143745
Trained batch 478 in epoch 4, gen_loss = 1.464394284190614, disc_loss = 0.0006584935270625094
Trained batch 479 in epoch 4, gen_loss = 1.464290448029836, disc_loss = 0.0006575123642202622
Trained batch 480 in epoch 4, gen_loss = 1.463817849228635, disc_loss = 0.0006564682660084179
Trained batch 481 in epoch 4, gen_loss = 1.4636040203798857, disc_loss = 0.0006557926358085095
Trained batch 482 in epoch 4, gen_loss = 1.463881092041916, disc_loss = 0.0006557496217094886
Trained batch 483 in epoch 4, gen_loss = 1.46337048007437, disc_loss = 0.0006558587397006148
Trained batch 484 in epoch 4, gen_loss = 1.4630159363304216, disc_loss = 0.0006554808113579974
Trained batch 485 in epoch 4, gen_loss = 1.462675290343202, disc_loss = 0.000654696255137592
Trained batch 486 in epoch 4, gen_loss = 1.4619245627087978, disc_loss = 0.0006538341189694
Trained batch 487 in epoch 4, gen_loss = 1.4621015088480027, disc_loss = 0.0006530032176550642
Trained batch 488 in epoch 4, gen_loss = 1.4620245880388287, disc_loss = 0.0006523773783652668
Trained batch 489 in epoch 4, gen_loss = 1.4617885528778543, disc_loss = 0.0006517894793247177
Trained batch 490 in epoch 4, gen_loss = 1.4622430832954143, disc_loss = 0.0006513090082195297
Trained batch 491 in epoch 4, gen_loss = 1.4615257098907377, disc_loss = 0.0006514544802189264
Trained batch 492 in epoch 4, gen_loss = 1.4618375117590172, disc_loss = 0.0006519909214611405
Trained batch 493 in epoch 4, gen_loss = 1.4616223021074828, disc_loss = 0.000652081357933315
Trained batch 494 in epoch 4, gen_loss = 1.4624014420942826, disc_loss = 0.0006520662905655406
Trained batch 495 in epoch 4, gen_loss = 1.4623540623053428, disc_loss = 0.0006517250232659976
Trained batch 496 in epoch 4, gen_loss = 1.4619925624168135, disc_loss = 0.0006518158824213498
Trained batch 497 in epoch 4, gen_loss = 1.4615761249898427, disc_loss = 0.0006517771098551894
Trained batch 498 in epoch 4, gen_loss = 1.4617448075262005, disc_loss = 0.000652296280957066
Trained batch 499 in epoch 4, gen_loss = 1.4619360160827637, disc_loss = 0.0006524559425015468
Trained batch 500 in epoch 4, gen_loss = 1.4619045464578504, disc_loss = 0.0006525216774539576
Trained batch 501 in epoch 4, gen_loss = 1.4624374527855224, disc_loss = 0.0006531268837168326
Trained batch 502 in epoch 4, gen_loss = 1.4619806047462327, disc_loss = 0.0006538824244297274
Trained batch 503 in epoch 4, gen_loss = 1.4624262045300196, disc_loss = 0.0006544546454062497
Trained batch 504 in epoch 4, gen_loss = 1.4624215952240593, disc_loss = 0.0006546692941441561
Trained batch 505 in epoch 4, gen_loss = 1.4621903835078003, disc_loss = 0.0006549793575154599
Trained batch 506 in epoch 4, gen_loss = 1.4622413646539993, disc_loss = 0.0006546813896657436
Trained batch 507 in epoch 4, gen_loss = 1.4618466796837455, disc_loss = 0.0006541642884315471
Trained batch 508 in epoch 4, gen_loss = 1.4620023813603669, disc_loss = 0.0006537020408234162
Trained batch 509 in epoch 4, gen_loss = 1.4621323870677574, disc_loss = 0.0006532880488735185
Trained batch 510 in epoch 4, gen_loss = 1.461729130866243, disc_loss = 0.0006531007548212301
Trained batch 511 in epoch 4, gen_loss = 1.462072558235377, disc_loss = 0.000652884751474403
Trained batch 512 in epoch 4, gen_loss = 1.4627871917702302, disc_loss = 0.0006530850509998114
Trained batch 513 in epoch 4, gen_loss = 1.4632531696720346, disc_loss = 0.0006531033606224526
Trained batch 514 in epoch 4, gen_loss = 1.4629758401981836, disc_loss = 0.0006525503009505733
Trained batch 515 in epoch 4, gen_loss = 1.463486910790436, disc_loss = 0.0006516008551718483
Trained batch 516 in epoch 4, gen_loss = 1.463601988104372, disc_loss = 0.0006506672117551086
Trained batch 517 in epoch 4, gen_loss = 1.4632234078576667, disc_loss = 0.000649860484776596
Trained batch 518 in epoch 4, gen_loss = 1.4632144316542814, disc_loss = 0.0006491107884841578
Trained batch 519 in epoch 4, gen_loss = 1.4635507879348901, disc_loss = 0.0006482359460138608
Trained batch 520 in epoch 4, gen_loss = 1.463840910660786, disc_loss = 0.0006472207008120952
Trained batch 521 in epoch 4, gen_loss = 1.4641093703065338, disc_loss = 0.0006465118839378715
Trained batch 522 in epoch 4, gen_loss = 1.4639828066069127, disc_loss = 0.0006469100655633493
Trained batch 523 in epoch 4, gen_loss = 1.464280067736866, disc_loss = 0.0006468590458487125
Trained batch 524 in epoch 4, gen_loss = 1.4639847251347133, disc_loss = 0.0006463605280788172
Trained batch 525 in epoch 4, gen_loss = 1.464164304642623, disc_loss = 0.0006457580311689526
Trained batch 526 in epoch 4, gen_loss = 1.463630368632655, disc_loss = 0.000644988059181105
Trained batch 527 in epoch 4, gen_loss = 1.4636745021650286, disc_loss = 0.0006444886133646254
Trained batch 528 in epoch 4, gen_loss = 1.4639292441604268, disc_loss = 0.0006437807024583319
Trained batch 529 in epoch 4, gen_loss = 1.4639392088044365, disc_loss = 0.0006429643470701709
Trained batch 530 in epoch 4, gen_loss = 1.4641878546519018, disc_loss = 0.0006429196614136291
Trained batch 531 in epoch 4, gen_loss = 1.463968621832984, disc_loss = 0.0006429891643500397
Trained batch 532 in epoch 4, gen_loss = 1.4637808285332083, disc_loss = 0.0006427767627682942
Trained batch 533 in epoch 4, gen_loss = 1.4639162122087086, disc_loss = 0.0006432434593999674
Trained batch 534 in epoch 4, gen_loss = 1.4634751910361175, disc_loss = 0.000644884715846818
Trained batch 535 in epoch 4, gen_loss = 1.4641093707351542, disc_loss = 0.000646526546861695
Trained batch 536 in epoch 4, gen_loss = 1.4638342491075313, disc_loss = 0.0006483511355279787
Trained batch 537 in epoch 4, gen_loss = 1.4644054271917804, disc_loss = 0.0006487259597904447
Trained batch 538 in epoch 4, gen_loss = 1.4640501699996127, disc_loss = 0.0006481940462383578
Trained batch 539 in epoch 4, gen_loss = 1.464476298182099, disc_loss = 0.0006473994903865753
Trained batch 540 in epoch 4, gen_loss = 1.464681849902747, disc_loss = 0.0006475770087372994
Trained batch 541 in epoch 4, gen_loss = 1.4646031867534033, disc_loss = 0.0006491651375046879
Trained batch 542 in epoch 4, gen_loss = 1.4654327385113823, disc_loss = 0.0006501893427683483
Trained batch 543 in epoch 4, gen_loss = 1.465216531253913, disc_loss = 0.0006501892103187856
Trained batch 544 in epoch 4, gen_loss = 1.4656474675607243, disc_loss = 0.0006498631071235232
Trained batch 545 in epoch 4, gen_loss = 1.4654966468339439, disc_loss = 0.0006494860214606821
Trained batch 546 in epoch 4, gen_loss = 1.4653490354635599, disc_loss = 0.0006500402328935393
Trained batch 547 in epoch 4, gen_loss = 1.4652011187842293, disc_loss = 0.000651625023118516
Trained batch 548 in epoch 4, gen_loss = 1.4654479220048109, disc_loss = 0.0006536422628686273
Trained batch 549 in epoch 4, gen_loss = 1.4654461418498645, disc_loss = 0.0006553056112765758
Trained batch 550 in epoch 4, gen_loss = 1.465181056470923, disc_loss = 0.0006563762256629704
Trained batch 551 in epoch 4, gen_loss = 1.465338209832924, disc_loss = 0.0006575161221363763
Trained batch 552 in epoch 4, gen_loss = 1.465142494084391, disc_loss = 0.0006583718447520769
Trained batch 553 in epoch 4, gen_loss = 1.465549210779073, disc_loss = 0.00065872540174427
Trained batch 554 in epoch 4, gen_loss = 1.464785050057076, disc_loss = 0.0006588816780676679
Trained batch 555 in epoch 4, gen_loss = 1.4646374977749885, disc_loss = 0.000660020432955495
Trained batch 556 in epoch 4, gen_loss = 1.4646294260367456, disc_loss = 0.0006610548969243671
Trained batch 557 in epoch 4, gen_loss = 1.464627157616359, disc_loss = 0.0006610648615279913
Trained batch 558 in epoch 4, gen_loss = 1.464327181387886, disc_loss = 0.0006609025325610308
Trained batch 559 in epoch 4, gen_loss = 1.4645644498722894, disc_loss = 0.0006619593087504785
Trained batch 560 in epoch 4, gen_loss = 1.464742467365163, disc_loss = 0.0006632778222183739
Trained batch 561 in epoch 4, gen_loss = 1.464887570443951, disc_loss = 0.0006633268257961824
Trained batch 562 in epoch 4, gen_loss = 1.465381325879275, disc_loss = 0.0006627009222722327
Trained batch 563 in epoch 4, gen_loss = 1.4649687455901017, disc_loss = 0.0006623034496442415
Trained batch 564 in epoch 4, gen_loss = 1.4653041506235578, disc_loss = 0.000662590242743047
Trained batch 565 in epoch 4, gen_loss = 1.4650046846470648, disc_loss = 0.0006632693404477426
Trained batch 566 in epoch 4, gen_loss = 1.4643234542227717, disc_loss = 0.0006638542037868685
Trained batch 567 in epoch 4, gen_loss = 1.464409450200242, disc_loss = 0.0006635815505586847
Trained batch 568 in epoch 4, gen_loss = 1.464008738789282, disc_loss = 0.0006636273662043287
Trained batch 569 in epoch 4, gen_loss = 1.4643502450825876, disc_loss = 0.0006636563086526861
Trained batch 570 in epoch 4, gen_loss = 1.4638075768008123, disc_loss = 0.0006633135123645655
Trained batch 571 in epoch 4, gen_loss = 1.4638476653115733, disc_loss = 0.0006626783916462128
Trained batch 572 in epoch 4, gen_loss = 1.463627499851673, disc_loss = 0.0006626241643450679
Trained batch 573 in epoch 4, gen_loss = 1.4636088210946592, disc_loss = 0.0006646041358104755
Trained batch 574 in epoch 4, gen_loss = 1.4630975020450094, disc_loss = 0.0006697683348624116
Trained batch 575 in epoch 4, gen_loss = 1.4631727795220084, disc_loss = 0.0006765246140376904
Trained batch 576 in epoch 4, gen_loss = 1.4627387653810313, disc_loss = 0.000680720379168129
Trained batch 577 in epoch 4, gen_loss = 1.4626479371608747, disc_loss = 0.0006813091952712226
Trained batch 578 in epoch 4, gen_loss = 1.462364932827793, disc_loss = 0.0006806526668064154
Trained batch 579 in epoch 4, gen_loss = 1.462707017413501, disc_loss = 0.0006801365904815109
Trained batch 580 in epoch 4, gen_loss = 1.462199297911534, disc_loss = 0.000680268131715058
Trained batch 581 in epoch 4, gen_loss = 1.461920541791162, disc_loss = 0.0006812263650802057
Trained batch 582 in epoch 4, gen_loss = 1.4619012588497704, disc_loss = 0.0006836775110636744
Trained batch 583 in epoch 4, gen_loss = 1.4616415102596152, disc_loss = 0.0006861802209878327
Trained batch 584 in epoch 4, gen_loss = 1.461203505238916, disc_loss = 0.0006873773535291672
Trained batch 585 in epoch 4, gen_loss = 1.4614051191880029, disc_loss = 0.0006877068103785363
Trained batch 586 in epoch 4, gen_loss = 1.4613967516556305, disc_loss = 0.0006890473448039942
Trained batch 587 in epoch 4, gen_loss = 1.4614069036075048, disc_loss = 0.0006904644575041281
Trained batch 588 in epoch 4, gen_loss = 1.460844239071391, disc_loss = 0.0006908780494143519
Trained batch 589 in epoch 4, gen_loss = 1.4610612477286387, disc_loss = 0.0006909771475120116
Trained batch 590 in epoch 4, gen_loss = 1.4610200759319687, disc_loss = 0.0006917959064175887
Trained batch 591 in epoch 4, gen_loss = 1.4604666800917805, disc_loss = 0.0006932660916071334
Trained batch 592 in epoch 4, gen_loss = 1.460913943601097, disc_loss = 0.0006947406649300561
Trained batch 593 in epoch 4, gen_loss = 1.4607411354077786, disc_loss = 0.0006955076030201533
Trained batch 594 in epoch 4, gen_loss = 1.461091778859371, disc_loss = 0.0006950955184963102
Trained batch 595 in epoch 4, gen_loss = 1.4614328602016373, disc_loss = 0.0006946519084314616
Trained batch 596 in epoch 4, gen_loss = 1.4615336722465018, disc_loss = 0.0006947524873777706
Trained batch 597 in epoch 4, gen_loss = 1.4613359911385986, disc_loss = 0.0006947850836826376
Trained batch 598 in epoch 4, gen_loss = 1.4613313245056865, disc_loss = 0.0006943478400411647
Trained batch 599 in epoch 4, gen_loss = 1.4612334730227787, disc_loss = 0.0006944098372089987
Trained batch 600 in epoch 4, gen_loss = 1.4618094098349776, disc_loss = 0.0006974897986222152
Trained batch 601 in epoch 4, gen_loss = 1.462130574688959, disc_loss = 0.0007027594569491909
Trained batch 602 in epoch 4, gen_loss = 1.462381146242765, disc_loss = 0.0007069843698055121
Trained batch 603 in epoch 4, gen_loss = 1.4629628946449582, disc_loss = 0.0007093949796591842
Trained batch 604 in epoch 4, gen_loss = 1.4627671895933545, disc_loss = 0.0007096687737806153
Trained batch 605 in epoch 4, gen_loss = 1.4626287570094119, disc_loss = 0.0007093743398661108
Trained batch 606 in epoch 4, gen_loss = 1.4627714443835238, disc_loss = 0.0007102840994883642
Trained batch 607 in epoch 4, gen_loss = 1.4631974026560783, disc_loss = 0.0007116901963040858
Trained batch 608 in epoch 4, gen_loss = 1.4631612387001025, disc_loss = 0.0007116614265729825
Trained batch 609 in epoch 4, gen_loss = 1.4632256292905963, disc_loss = 0.0007122320811012301
Trained batch 610 in epoch 4, gen_loss = 1.4636920304228163, disc_loss = 0.0007133158385858806
Trained batch 611 in epoch 4, gen_loss = 1.4638342197034873, disc_loss = 0.0007143584419585144
Trained batch 612 in epoch 4, gen_loss = 1.4639806634644699, disc_loss = 0.0007153975863357608
Trained batch 613 in epoch 4, gen_loss = 1.4637544912313405, disc_loss = 0.0007158745788773431
Trained batch 614 in epoch 4, gen_loss = 1.4637776049172007, disc_loss = 0.0007154996990513935
Trained batch 615 in epoch 4, gen_loss = 1.4638360351711124, disc_loss = 0.0007150929183820142
Trained batch 616 in epoch 4, gen_loss = 1.4641152083197522, disc_loss = 0.0007147339043981808
Trained batch 617 in epoch 4, gen_loss = 1.4644420690906859, disc_loss = 0.0007144110436471402
Trained batch 618 in epoch 4, gen_loss = 1.4639401570660617, disc_loss = 0.0007141861734161025
Trained batch 619 in epoch 4, gen_loss = 1.4639714752474138, disc_loss = 0.0007137721516154406
Trained batch 620 in epoch 4, gen_loss = 1.463635819737654, disc_loss = 0.000714477093424648
Trained batch 621 in epoch 4, gen_loss = 1.4634915392881804, disc_loss = 0.0007167909461128978
Trained batch 622 in epoch 4, gen_loss = 1.4634660604868808, disc_loss = 0.0007191017089018457
Trained batch 623 in epoch 4, gen_loss = 1.4631162043183277, disc_loss = 0.000719484650266494
Trained batch 624 in epoch 4, gen_loss = 1.4632175504684448, disc_loss = 0.0007189762201160192
Trained batch 625 in epoch 4, gen_loss = 1.4629632148879785, disc_loss = 0.0007186445222346308
Trained batch 626 in epoch 4, gen_loss = 1.462500325990826, disc_loss = 0.0007189948782413913
Trained batch 627 in epoch 4, gen_loss = 1.4621154500800333, disc_loss = 0.0007187982981840659
Trained batch 628 in epoch 4, gen_loss = 1.462502269562932, disc_loss = 0.0007181511340060957
Trained batch 629 in epoch 4, gen_loss = 1.462051666918255, disc_loss = 0.0007178115574846281
Trained batch 630 in epoch 4, gen_loss = 1.4622595899645388, disc_loss = 0.00071706865286335
Trained batch 631 in epoch 4, gen_loss = 1.462527271690248, disc_loss = 0.0007164102105521067
Trained batch 632 in epoch 4, gen_loss = 1.4623363119731017, disc_loss = 0.0007158266248933288
Trained batch 633 in epoch 4, gen_loss = 1.4625879072992582, disc_loss = 0.0007152352195632665
Trained batch 634 in epoch 4, gen_loss = 1.4630821665440958, disc_loss = 0.0007146184422501077
Trained batch 635 in epoch 4, gen_loss = 1.4630336141061482, disc_loss = 0.0007139528252139729
Trained batch 636 in epoch 4, gen_loss = 1.4629889683596193, disc_loss = 0.0007132894915197443
Trained batch 637 in epoch 4, gen_loss = 1.4634372799374094, disc_loss = 0.0007125566757122073
Trained batch 638 in epoch 4, gen_loss = 1.4637691360870624, disc_loss = 0.0007124645887809938
Trained batch 639 in epoch 4, gen_loss = 1.4642372705042361, disc_loss = 0.0007134984908589104
Trained batch 640 in epoch 4, gen_loss = 1.464302390860321, disc_loss = 0.000713508783377614
Trained batch 641 in epoch 4, gen_loss = 1.464296144117076, disc_loss = 0.0007129081766443136
Trained batch 642 in epoch 4, gen_loss = 1.464143596577978, disc_loss = 0.0007121078553473763
Trained batch 643 in epoch 4, gen_loss = 1.4640715333245555, disc_loss = 0.0007112424482668458
Trained batch 644 in epoch 4, gen_loss = 1.4640649307605833, disc_loss = 0.0007103692318083602
Trained batch 645 in epoch 4, gen_loss = 1.4637782732399625, disc_loss = 0.0007095505891758127
Trained batch 646 in epoch 4, gen_loss = 1.4638007151472514, disc_loss = 0.0007086541226619157
Trained batch 647 in epoch 4, gen_loss = 1.4636156257287956, disc_loss = 0.0007079237572646507
Trained batch 648 in epoch 4, gen_loss = 1.4634761450287006, disc_loss = 0.0007074409456109594
Trained batch 649 in epoch 4, gen_loss = 1.463490534562331, disc_loss = 0.0007075012809946202
Trained batch 650 in epoch 4, gen_loss = 1.463108034910328, disc_loss = 0.0007069987430122428
Trained batch 651 in epoch 4, gen_loss = 1.4628992784608361, disc_loss = 0.0007065606373460446
Trained batch 652 in epoch 4, gen_loss = 1.4624657720373015, disc_loss = 0.0007064406611665351
Trained batch 653 in epoch 4, gen_loss = 1.4622023811034106, disc_loss = 0.0007063154735634836
Trained batch 654 in epoch 4, gen_loss = 1.4624648230676434, disc_loss = 0.000706146792699725
Trained batch 655 in epoch 4, gen_loss = 1.4629032918956222, disc_loss = 0.000705714938348825
Trained batch 656 in epoch 4, gen_loss = 1.4632550374557982, disc_loss = 0.0007051566484002566
Trained batch 657 in epoch 4, gen_loss = 1.4632726108774226, disc_loss = 0.0007052452329432628
Trained batch 658 in epoch 4, gen_loss = 1.463735240905889, disc_loss = 0.0007057404728337475
Trained batch 659 in epoch 4, gen_loss = 1.463907368255384, disc_loss = 0.0007061550850322061
Trained batch 660 in epoch 4, gen_loss = 1.463535373041381, disc_loss = 0.0007063879224578477
Trained batch 661 in epoch 4, gen_loss = 1.4631624686393854, disc_loss = 0.0007065609514914112
Trained batch 662 in epoch 4, gen_loss = 1.4629918095932468, disc_loss = 0.0007061039557078921
Trained batch 663 in epoch 4, gen_loss = 1.4629919651042984, disc_loss = 0.0007053232915802572
Trained batch 664 in epoch 4, gen_loss = 1.463229332830673, disc_loss = 0.0007046784854168423
Trained batch 665 in epoch 4, gen_loss = 1.4633052451116544, disc_loss = 0.0007040139375371277
Trained batch 666 in epoch 4, gen_loss = 1.4633973322172036, disc_loss = 0.0007032504255893518
Trained batch 667 in epoch 4, gen_loss = 1.4630941709358536, disc_loss = 0.0007026084055184752
Trained batch 668 in epoch 4, gen_loss = 1.4629562683347808, disc_loss = 0.0007024699237946941
Trained batch 669 in epoch 4, gen_loss = 1.4629462037513505, disc_loss = 0.0007027402713264116
Trained batch 670 in epoch 4, gen_loss = 1.4626377250682756, disc_loss = 0.0007025382012254093
Trained batch 671 in epoch 4, gen_loss = 1.4631129357786405, disc_loss = 0.0007022100018860199
Trained batch 672 in epoch 4, gen_loss = 1.4629936914387287, disc_loss = 0.0007016608734533154
Trained batch 673 in epoch 4, gen_loss = 1.4634127172942686, disc_loss = 0.0007011143709641732
Trained batch 674 in epoch 4, gen_loss = 1.4633379625391076, disc_loss = 0.0007006935939339369
Trained batch 675 in epoch 4, gen_loss = 1.4631937080939141, disc_loss = 0.000699984164879769
Trained batch 676 in epoch 4, gen_loss = 1.463759069076493, disc_loss = 0.0006991782821888556
Trained batch 677 in epoch 4, gen_loss = 1.4634392279087618, disc_loss = 0.0006984201950633385
Trained batch 678 in epoch 4, gen_loss = 1.4633398821497876, disc_loss = 0.0006977019874229533
Trained batch 679 in epoch 4, gen_loss = 1.4633989165810977, disc_loss = 0.0006971128530601752
Trained batch 680 in epoch 4, gen_loss = 1.4637349402851996, disc_loss = 0.0006965379901305552
Trained batch 681 in epoch 4, gen_loss = 1.4637306388522173, disc_loss = 0.0006957399132728093
Trained batch 682 in epoch 4, gen_loss = 1.4639777597885355, disc_loss = 0.000695547545160846
Trained batch 683 in epoch 4, gen_loss = 1.4636650974290413, disc_loss = 0.0006956909137070983
Trained batch 684 in epoch 4, gen_loss = 1.4635782868322664, disc_loss = 0.0006959033530693243
Trained batch 685 in epoch 4, gen_loss = 1.4630619993015213, disc_loss = 0.0006957371171172532
Trained batch 686 in epoch 4, gen_loss = 1.4635518175025173, disc_loss = 0.0006950984867531983
Trained batch 687 in epoch 4, gen_loss = 1.4640134609369344, disc_loss = 0.0006950270104468029
Trained batch 688 in epoch 4, gen_loss = 1.4642183166456846, disc_loss = 0.0006954008172472657
Trained batch 689 in epoch 4, gen_loss = 1.46449437642443, disc_loss = 0.0006951849035154421
Trained batch 690 in epoch 4, gen_loss = 1.4645249929855944, disc_loss = 0.0006946786113685488
Trained batch 691 in epoch 4, gen_loss = 1.4651866555213928, disc_loss = 0.0006941629198675564
Trained batch 692 in epoch 4, gen_loss = 1.465203697547252, disc_loss = 0.00069358183235561
Trained batch 693 in epoch 4, gen_loss = 1.4655218598478466, disc_loss = 0.0006931861604002616
Trained batch 694 in epoch 4, gen_loss = 1.4654994024647225, disc_loss = 0.0006928496387504082
Trained batch 695 in epoch 4, gen_loss = 1.4654271306320168, disc_loss = 0.0006923615074528839
Trained batch 696 in epoch 4, gen_loss = 1.4655833926741328, disc_loss = 0.0006916446617256296
Trained batch 697 in epoch 4, gen_loss = 1.4651490881996374, disc_loss = 0.0006908893149356454
Trained batch 698 in epoch 4, gen_loss = 1.4648987406142622, disc_loss = 0.0006901323858189539
Trained batch 699 in epoch 4, gen_loss = 1.465249949353082, disc_loss = 0.0006895107959280722
Trained batch 700 in epoch 4, gen_loss = 1.4651168081457706, disc_loss = 0.0006890186358501632
Trained batch 701 in epoch 4, gen_loss = 1.4653334288175968, disc_loss = 0.0006883588883288847
Trained batch 702 in epoch 4, gen_loss = 1.4653555973834367, disc_loss = 0.0006878335949362707
Trained batch 703 in epoch 4, gen_loss = 1.4656462754038246, disc_loss = 0.0006877139463457835
Trained batch 704 in epoch 4, gen_loss = 1.4655955926746342, disc_loss = 0.0006876218755620512
Trained batch 705 in epoch 4, gen_loss = 1.4653465376359545, disc_loss = 0.0006871962451614128
Trained batch 706 in epoch 4, gen_loss = 1.4652960379693598, disc_loss = 0.0006865181052183621
Trained batch 707 in epoch 4, gen_loss = 1.4656653055700206, disc_loss = 0.000685899550308793
Trained batch 708 in epoch 4, gen_loss = 1.465764987620043, disc_loss = 0.0006857091089182209
Trained batch 709 in epoch 4, gen_loss = 1.4658715839117347, disc_loss = 0.000685676343351255
Trained batch 710 in epoch 4, gen_loss = 1.4660693103586404, disc_loss = 0.0006855005755456972
Trained batch 711 in epoch 4, gen_loss = 1.4663362616903326, disc_loss = 0.0006857793431346805
Trained batch 712 in epoch 4, gen_loss = 1.4660272920950934, disc_loss = 0.0006874081832616359
Trained batch 713 in epoch 4, gen_loss = 1.466391192931755, disc_loss = 0.0006893604461432054
Trained batch 714 in epoch 4, gen_loss = 1.4667864140930709, disc_loss = 0.0006909564969258487
Trained batch 715 in epoch 4, gen_loss = 1.4669514641415473, disc_loss = 0.0006917909297410219
Trained batch 716 in epoch 4, gen_loss = 1.466751374958948, disc_loss = 0.000691999433018401
Trained batch 717 in epoch 4, gen_loss = 1.4668546204447415, disc_loss = 0.0006916419208569589
Trained batch 718 in epoch 4, gen_loss = 1.4670611270114013, disc_loss = 0.00069125638231593
Trained batch 719 in epoch 4, gen_loss = 1.466808443599277, disc_loss = 0.0006906685874330126
Trained batch 720 in epoch 4, gen_loss = 1.4665180300872633, disc_loss = 0.0006903075481609645
Trained batch 721 in epoch 4, gen_loss = 1.4660754040337665, disc_loss = 0.0006906776939519717
Trained batch 722 in epoch 4, gen_loss = 1.4661798866293076, disc_loss = 0.0006918693546430861
Trained batch 723 in epoch 4, gen_loss = 1.4661651561602702, disc_loss = 0.0006935736592767376
Trained batch 724 in epoch 4, gen_loss = 1.466528210968807, disc_loss = 0.0006947585223202497
Trained batch 725 in epoch 4, gen_loss = 1.4666228456930681, disc_loss = 0.0006955726332242534
Trained batch 726 in epoch 4, gen_loss = 1.4665993120844132, disc_loss = 0.0006957674927090678
Trained batch 727 in epoch 4, gen_loss = 1.466457343690998, disc_loss = 0.0006954949140281015
Trained batch 728 in epoch 4, gen_loss = 1.4666566034403357, disc_loss = 0.0006949630001550592
Trained batch 729 in epoch 4, gen_loss = 1.4668861121347505, disc_loss = 0.0006946429823746918
Trained batch 730 in epoch 4, gen_loss = 1.4670832059288808, disc_loss = 0.0006939950065262726
Trained batch 731 in epoch 4, gen_loss = 1.4671452830398017, disc_loss = 0.0006934785068964222
Trained batch 732 in epoch 4, gen_loss = 1.4668627756191635, disc_loss = 0.0006928345842282498
Trained batch 733 in epoch 4, gen_loss = 1.4665708640940507, disc_loss = 0.0006921372475866698
Trained batch 734 in epoch 4, gen_loss = 1.466551001055711, disc_loss = 0.0006914241988802658
Trained batch 735 in epoch 4, gen_loss = 1.4663271879696327, disc_loss = 0.0006907099347858014
Trained batch 736 in epoch 4, gen_loss = 1.4660371076138727, disc_loss = 0.0006899867516647257
Trained batch 737 in epoch 4, gen_loss = 1.4658042712586359, disc_loss = 0.0006893474771846262
Trained batch 738 in epoch 4, gen_loss = 1.4659369921006757, disc_loss = 0.0006888587804336645
Trained batch 739 in epoch 4, gen_loss = 1.466131970850197, disc_loss = 0.0006882720409005226
Trained batch 740 in epoch 4, gen_loss = 1.46594033051438, disc_loss = 0.0006877268957855197
Trained batch 741 in epoch 4, gen_loss = 1.4658724919483668, disc_loss = 0.0006872600413114586
Trained batch 742 in epoch 4, gen_loss = 1.465737235337536, disc_loss = 0.0006869163350540578
Trained batch 743 in epoch 4, gen_loss = 1.4653804661125265, disc_loss = 0.0006865072500659153
Trained batch 744 in epoch 4, gen_loss = 1.4650679429905527, disc_loss = 0.0006861841775267541
Trained batch 745 in epoch 4, gen_loss = 1.465379044293718, disc_loss = 0.0006862174641623738
Trained batch 746 in epoch 4, gen_loss = 1.4656345651172091, disc_loss = 0.000686544666546453
Trained batch 747 in epoch 4, gen_loss = 1.4655745174476806, disc_loss = 0.0006870438962571577
Trained batch 748 in epoch 4, gen_loss = 1.4653541158452053, disc_loss = 0.0006875865649384073
Trained batch 749 in epoch 4, gen_loss = 1.4649867259661356, disc_loss = 0.0006881390404499447
Trained batch 750 in epoch 4, gen_loss = 1.464810296952645, disc_loss = 0.0006882996807515388
Trained batch 751 in epoch 4, gen_loss = 1.4650126579911151, disc_loss = 0.0006881379947717119
Trained batch 752 in epoch 4, gen_loss = 1.4649478998158874, disc_loss = 0.0006880427693010025
Trained batch 753 in epoch 4, gen_loss = 1.4647239331225186, disc_loss = 0.0006878540608540934
Trained batch 754 in epoch 4, gen_loss = 1.4648592131027323, disc_loss = 0.0006874487054956744
Trained batch 755 in epoch 4, gen_loss = 1.4647990506162087, disc_loss = 0.0006870561113895814
Trained batch 756 in epoch 4, gen_loss = 1.46524071126507, disc_loss = 0.000686728665299155
Trained batch 757 in epoch 4, gen_loss = 1.4651750003756823, disc_loss = 0.0006860466660531778
Trained batch 758 in epoch 4, gen_loss = 1.4655151217979563, disc_loss = 0.0006853834113087113
Trained batch 759 in epoch 4, gen_loss = 1.4652689375375447, disc_loss = 0.0006846803211374208
Trained batch 760 in epoch 4, gen_loss = 1.46504158259378, disc_loss = 0.0006838930426958646
Trained batch 761 in epoch 4, gen_loss = 1.4654221838227721, disc_loss = 0.0006835414406179977
Trained batch 762 in epoch 4, gen_loss = 1.4651148375489922, disc_loss = 0.0006834549864856765
Trained batch 763 in epoch 4, gen_loss = 1.4654508595067168, disc_loss = 0.000682977669932456
Trained batch 764 in epoch 4, gen_loss = 1.465771633659313, disc_loss = 0.0006825359647479548
Trained batch 765 in epoch 4, gen_loss = 1.4661338867780123, disc_loss = 0.0006821686592410949
Trained batch 766 in epoch 4, gen_loss = 1.4657069865852166, disc_loss = 0.0006817365140063571
Trained batch 767 in epoch 4, gen_loss = 1.4654589376101892, disc_loss = 0.0006812972700439938
Trained batch 768 in epoch 4, gen_loss = 1.4653317167172972, disc_loss = 0.0006808474349977191
Trained batch 769 in epoch 4, gen_loss = 1.4655403866396322, disc_loss = 0.0006803644205048202
Trained batch 770 in epoch 4, gen_loss = 1.465367525931926, disc_loss = 0.0006798154291194493
Trained batch 771 in epoch 4, gen_loss = 1.4656594259751274, disc_loss = 0.0006792796211811947
Trained batch 772 in epoch 4, gen_loss = 1.4655405873623117, disc_loss = 0.0006787746754432919
Trained batch 773 in epoch 4, gen_loss = 1.4656852731717034, disc_loss = 0.0006785390754889856
Trained batch 774 in epoch 4, gen_loss = 1.4657963491255237, disc_loss = 0.0006784109224569082
Trained batch 775 in epoch 4, gen_loss = 1.4657024393991096, disc_loss = 0.0006781819289507129
Trained batch 776 in epoch 4, gen_loss = 1.4656756725090352, disc_loss = 0.0006777336343106612
Trained batch 777 in epoch 4, gen_loss = 1.4657986819897335, disc_loss = 0.0006771404231536522
Trained batch 778 in epoch 4, gen_loss = 1.4659869545384456, disc_loss = 0.0006766832221601432
Trained batch 779 in epoch 4, gen_loss = 1.4664230765440525, disc_loss = 0.0006765788195386846
Trained batch 780 in epoch 4, gen_loss = 1.4663251113342108, disc_loss = 0.0006765531344124159
Trained batch 781 in epoch 4, gen_loss = 1.4661769380654825, disc_loss = 0.0006768620339576708
Trained batch 782 in epoch 4, gen_loss = 1.465984529310107, disc_loss = 0.0006771459409540804
Trained batch 783 in epoch 4, gen_loss = 1.4657990853397214, disc_loss = 0.0006775905728912277
Trained batch 784 in epoch 4, gen_loss = 1.4655997109261287, disc_loss = 0.0006783787012533996
Trained batch 785 in epoch 4, gen_loss = 1.465339786223783, disc_loss = 0.0006788358733055161
Trained batch 786 in epoch 4, gen_loss = 1.4651604286445898, disc_loss = 0.0006791907476263181
Trained batch 787 in epoch 4, gen_loss = 1.464844162542808, disc_loss = 0.0006790629035704161
Trained batch 788 in epoch 4, gen_loss = 1.4649080183116203, disc_loss = 0.0006786029358738674
Trained batch 789 in epoch 4, gen_loss = 1.464976011499574, disc_loss = 0.000677996831443205
Trained batch 790 in epoch 4, gen_loss = 1.4649089062409817, disc_loss = 0.0006774632500668701
Trained batch 791 in epoch 4, gen_loss = 1.4648379581143158, disc_loss = 0.000676803680998817
Trained batch 792 in epoch 4, gen_loss = 1.464916467666626, disc_loss = 0.000676242070588413
Trained batch 793 in epoch 4, gen_loss = 1.4646830384617189, disc_loss = 0.0006761898563145361
Trained batch 794 in epoch 4, gen_loss = 1.4642790491475999, disc_loss = 0.0006765273809941842
Trained batch 795 in epoch 4, gen_loss = 1.46413120896972, disc_loss = 0.0006774187415302819
Trained batch 796 in epoch 4, gen_loss = 1.4642432159282632, disc_loss = 0.0006781804809150919
Trained batch 797 in epoch 4, gen_loss = 1.4643551653489135, disc_loss = 0.0006786538448743027
Trained batch 798 in epoch 4, gen_loss = 1.4641762510855894, disc_loss = 0.0006784591828460528
Trained batch 799 in epoch 4, gen_loss = 1.4639038033783436, disc_loss = 0.0006784226948639116
Trained batch 800 in epoch 4, gen_loss = 1.4639299695709076, disc_loss = 0.0006782112804865121
Trained batch 801 in epoch 4, gen_loss = 1.4639221923309669, disc_loss = 0.000677934222393585
Trained batch 802 in epoch 4, gen_loss = 1.4644362674109814, disc_loss = 0.0006777434083116287
Trained batch 803 in epoch 4, gen_loss = 1.464176357978612, disc_loss = 0.0006773105315412759
Trained batch 804 in epoch 4, gen_loss = 1.4640495263271451, disc_loss = 0.0006766886239483091
Trained batch 805 in epoch 4, gen_loss = 1.4639281815393983, disc_loss = 0.0006761478378362209
Trained batch 806 in epoch 4, gen_loss = 1.4639982788683905, disc_loss = 0.0006755781316062374
Trained batch 807 in epoch 4, gen_loss = 1.463736173687595, disc_loss = 0.0006750335119024817
Trained batch 808 in epoch 4, gen_loss = 1.4635957075727295, disc_loss = 0.0006744798550089995
Trained batch 809 in epoch 4, gen_loss = 1.4641281868204659, disc_loss = 0.0006740017807816104
Trained batch 810 in epoch 4, gen_loss = 1.4640871717074355, disc_loss = 0.0006735963193196878
Trained batch 811 in epoch 4, gen_loss = 1.4641836831722352, disc_loss = 0.0006735288591748201
Trained batch 812 in epoch 4, gen_loss = 1.464063942798976, disc_loss = 0.0006733741595580639
Trained batch 813 in epoch 4, gen_loss = 1.4637497730864353, disc_loss = 0.0006737860405440207
Trained batch 814 in epoch 4, gen_loss = 1.4636774560425179, disc_loss = 0.0006747289469406334
Trained batch 815 in epoch 4, gen_loss = 1.4637818565847827, disc_loss = 0.0006769967280353525
Trained batch 816 in epoch 4, gen_loss = 1.4636828509801167, disc_loss = 0.0006796070579824841
Trained batch 817 in epoch 4, gen_loss = 1.4636697234326295, disc_loss = 0.0006809808647811263
Trained batch 818 in epoch 4, gen_loss = 1.4636313468399793, disc_loss = 0.0006833901921471538
Trained batch 819 in epoch 4, gen_loss = 1.463358384516181, disc_loss = 0.0006858943216307457
Trained batch 820 in epoch 4, gen_loss = 1.4632064613732583, disc_loss = 0.0006875394738393997
Trained batch 821 in epoch 4, gen_loss = 1.4634951035471728, disc_loss = 0.0006883050903761924
Trained batch 822 in epoch 4, gen_loss = 1.4633258172692245, disc_loss = 0.0006894168312798417
Trained batch 823 in epoch 4, gen_loss = 1.4632733445433737, disc_loss = 0.0006902501056651338
Trained batch 824 in epoch 4, gen_loss = 1.4632276646296183, disc_loss = 0.0006916574624483473
Trained batch 825 in epoch 4, gen_loss = 1.4631508422821544, disc_loss = 0.0006936237075990861
Trained batch 826 in epoch 4, gen_loss = 1.4635066096699079, disc_loss = 0.0006960758537157808
Trained batch 827 in epoch 4, gen_loss = 1.4637944964682998, disc_loss = 0.0006973705779576752
Trained batch 828 in epoch 4, gen_loss = 1.4636816073959498, disc_loss = 0.0006972901063016447
Trained batch 829 in epoch 4, gen_loss = 1.4637941113437514, disc_loss = 0.0006969127973842473
Trained batch 830 in epoch 4, gen_loss = 1.4633906140080715, disc_loss = 0.00069668855578937
Trained batch 831 in epoch 4, gen_loss = 1.4631574268524463, disc_loss = 0.0006965958765127093
Trained batch 832 in epoch 4, gen_loss = 1.4633202813252681, disc_loss = 0.0006961159356540635
Trained batch 833 in epoch 4, gen_loss = 1.4635422923010317, disc_loss = 0.000695768604559304
Trained batch 834 in epoch 4, gen_loss = 1.4635781306706503, disc_loss = 0.0006955268437723897
Trained batch 835 in epoch 4, gen_loss = 1.463789531488738, disc_loss = 0.0006953266447758258
Trained batch 836 in epoch 4, gen_loss = 1.4634552437772033, disc_loss = 0.0006955897927233753
Trained batch 837 in epoch 4, gen_loss = 1.463438855435228, disc_loss = 0.000695460841802145
Trained batch 838 in epoch 4, gen_loss = 1.4633280554602057, disc_loss = 0.0006948902816699703
Trained batch 839 in epoch 4, gen_loss = 1.4634411249841963, disc_loss = 0.0006943518845478788
Trained batch 840 in epoch 4, gen_loss = 1.4634726243126832, disc_loss = 0.000693937361594547
Trained batch 841 in epoch 4, gen_loss = 1.4633142051957282, disc_loss = 0.0006936288259707357
Trained batch 842 in epoch 4, gen_loss = 1.4631847710230454, disc_loss = 0.000693895520181779
Trained batch 843 in epoch 4, gen_loss = 1.462856243006991, disc_loss = 0.000694031020011866
Trained batch 844 in epoch 4, gen_loss = 1.463315706422343, disc_loss = 0.0006937839088843689
Trained batch 845 in epoch 4, gen_loss = 1.463451181743162, disc_loss = 0.0006942820221950915
Trained batch 846 in epoch 4, gen_loss = 1.463286921434729, disc_loss = 0.0006944832185681479
Trained batch 847 in epoch 4, gen_loss = 1.4634040327004667, disc_loss = 0.0006940829866148564
Trained batch 848 in epoch 4, gen_loss = 1.4635624811141033, disc_loss = 0.000693712695672117
Trained batch 849 in epoch 4, gen_loss = 1.4634735737127416, disc_loss = 0.0006931982448697775
Trained batch 850 in epoch 4, gen_loss = 1.4632944786170394, disc_loss = 0.0006928522528448638
Trained batch 851 in epoch 4, gen_loss = 1.4632266962752096, disc_loss = 0.0006925161840439094
Trained batch 852 in epoch 4, gen_loss = 1.4631590660124283, disc_loss = 0.0006922923909107322
Trained batch 853 in epoch 4, gen_loss = 1.4632091361689066, disc_loss = 0.0006918950214744431
Trained batch 854 in epoch 4, gen_loss = 1.4630816341143602, disc_loss = 0.0006915039804369914
Trained batch 855 in epoch 4, gen_loss = 1.462809600701956, disc_loss = 0.000691279080864295
Trained batch 856 in epoch 4, gen_loss = 1.4631523479519535, disc_loss = 0.0006913506014269447
Trained batch 857 in epoch 4, gen_loss = 1.463376373261005, disc_loss = 0.0006915656425819883
Trained batch 858 in epoch 4, gen_loss = 1.463350957708392, disc_loss = 0.0006915602656393702
Trained batch 859 in epoch 4, gen_loss = 1.4631434132886487, disc_loss = 0.0006911859488968201
Trained batch 860 in epoch 4, gen_loss = 1.4630359296322424, disc_loss = 0.000690691768141795
Trained batch 861 in epoch 4, gen_loss = 1.4628964977861834, disc_loss = 0.0006902984696648515
Trained batch 862 in epoch 4, gen_loss = 1.462885118995039, disc_loss = 0.0006899015433689863
Trained batch 863 in epoch 4, gen_loss = 1.4627465636089996, disc_loss = 0.0006894901213635657
Trained batch 864 in epoch 4, gen_loss = 1.4626410058468065, disc_loss = 0.0006892429847176714
Trained batch 865 in epoch 4, gen_loss = 1.46275905607479, disc_loss = 0.0006889086132754187
Trained batch 866 in epoch 4, gen_loss = 1.4627012393878818, disc_loss = 0.0006882587455634287
Trained batch 867 in epoch 4, gen_loss = 1.462611507572886, disc_loss = 0.0006875811295308497
Trained batch 868 in epoch 4, gen_loss = 1.4623828831421355, disc_loss = 0.0006869691876453826
Trained batch 869 in epoch 4, gen_loss = 1.4630022583336666, disc_loss = 0.0006867015681376055
Trained batch 870 in epoch 4, gen_loss = 1.4628403805427244, disc_loss = 0.0006866361592261011
Trained batch 871 in epoch 4, gen_loss = 1.4629228108246393, disc_loss = 0.0006864244290335833
Trained batch 872 in epoch 4, gen_loss = 1.4627481404039049, disc_loss = 0.0006859002889566447
Trained batch 873 in epoch 4, gen_loss = 1.4624073115311715, disc_loss = 0.0006856693880076683
Trained batch 874 in epoch 4, gen_loss = 1.4625523643493652, disc_loss = 0.0006852091821160035
Trained batch 875 in epoch 4, gen_loss = 1.4626068385768698, disc_loss = 0.000684970487342054
Trained batch 876 in epoch 4, gen_loss = 1.4624265403812804, disc_loss = 0.000684740217313308
Trained batch 877 in epoch 4, gen_loss = 1.4622561144122774, disc_loss = 0.0006842217242629888
Trained batch 878 in epoch 4, gen_loss = 1.4622283265316718, disc_loss = 0.0006838970410221561
Trained batch 879 in epoch 4, gen_loss = 1.462183201583949, disc_loss = 0.000683588614819283
Trained batch 880 in epoch 4, gen_loss = 1.4623844639803034, disc_loss = 0.0006836056312126325
Trained batch 881 in epoch 4, gen_loss = 1.4625792331706369, disc_loss = 0.0006840616538314875
Trained batch 882 in epoch 4, gen_loss = 1.462610007547441, disc_loss = 0.0006847435822401229
Trained batch 883 in epoch 4, gen_loss = 1.4627485442485204, disc_loss = 0.0006851480607460522
Trained batch 884 in epoch 4, gen_loss = 1.4626843168237116, disc_loss = 0.0006853702199815688
Trained batch 885 in epoch 4, gen_loss = 1.4628126907833006, disc_loss = 0.000685968870747691
Trained batch 886 in epoch 4, gen_loss = 1.4627078239382858, disc_loss = 0.0006860008687218635
Trained batch 887 in epoch 4, gen_loss = 1.4627843909972422, disc_loss = 0.0006855923554810632
Trained batch 888 in epoch 4, gen_loss = 1.4625390981260113, disc_loss = 0.0006849640883770258
Trained batch 889 in epoch 4, gen_loss = 1.462555865223488, disc_loss = 0.0006845065746950169
Trained batch 890 in epoch 4, gen_loss = 1.4623275246015435, disc_loss = 0.0006844599032954221
Trained batch 891 in epoch 4, gen_loss = 1.462618579110757, disc_loss = 0.0006841539881306866
Trained batch 892 in epoch 4, gen_loss = 1.4628084628339044, disc_loss = 0.0006836102107272657
Trained batch 893 in epoch 4, gen_loss = 1.4628279570498455, disc_loss = 0.0006832722853384136
Trained batch 894 in epoch 4, gen_loss = 1.4628307061488401, disc_loss = 0.0006831237544450654
Trained batch 895 in epoch 4, gen_loss = 1.4628288797768099, disc_loss = 0.0006828745934188062
Trained batch 896 in epoch 4, gen_loss = 1.4629292811039698, disc_loss = 0.0006824159050663884
Trained batch 897 in epoch 4, gen_loss = 1.4626311638572964, disc_loss = 0.0006819212090149226
Trained batch 898 in epoch 4, gen_loss = 1.4628209990839804, disc_loss = 0.0006814818170479887
Trained batch 899 in epoch 4, gen_loss = 1.462892054716746, disc_loss = 0.0006809472995923392
Trained batch 900 in epoch 4, gen_loss = 1.462884897794099, disc_loss = 0.0006804987415681039
Trained batch 901 in epoch 4, gen_loss = 1.4628279036005956, disc_loss = 0.0006800080842133679
Trained batch 902 in epoch 4, gen_loss = 1.462854163063193, disc_loss = 0.0006797105813175796
Trained batch 903 in epoch 4, gen_loss = 1.4629357531007412, disc_loss = 0.0006791943225464747
Trained batch 904 in epoch 4, gen_loss = 1.4629475564587842, disc_loss = 0.000678686074420838
Trained batch 905 in epoch 4, gen_loss = 1.4630641147790366, disc_loss = 0.0006782538651613489
Trained batch 906 in epoch 4, gen_loss = 1.4628081547780232, disc_loss = 0.0006777393064433283
Trained batch 907 in epoch 4, gen_loss = 1.4630668064833738, disc_loss = 0.0006775383516337229
Trained batch 908 in epoch 4, gen_loss = 1.4632093026430824, disc_loss = 0.0006771699125886581
Trained batch 909 in epoch 4, gen_loss = 1.4632656135401882, disc_loss = 0.0006766553752550953
Trained batch 910 in epoch 4, gen_loss = 1.4633919758278504, disc_loss = 0.0006762511408235443
Trained batch 911 in epoch 4, gen_loss = 1.4635665616706799, disc_loss = 0.0006757934830490916
Trained batch 912 in epoch 4, gen_loss = 1.463288469486926, disc_loss = 0.0006753326268179514
Trained batch 913 in epoch 4, gen_loss = 1.4631790286602546, disc_loss = 0.0006753552358335009
Trained batch 914 in epoch 4, gen_loss = 1.4631479725811651, disc_loss = 0.0006763229707922008
Trained batch 915 in epoch 4, gen_loss = 1.4628779517250812, disc_loss = 0.0006782745691834147
Trained batch 916 in epoch 4, gen_loss = 1.4627641696836333, disc_loss = 0.0006788227470746419
Trained batch 917 in epoch 4, gen_loss = 1.4625609641760782, disc_loss = 0.0006788666421188775
Trained batch 918 in epoch 4, gen_loss = 1.4622642603480906, disc_loss = 0.0006800983613138432
Trained batch 919 in epoch 4, gen_loss = 1.4624246664669203, disc_loss = 0.0006831759716236696
Trained batch 920 in epoch 4, gen_loss = 1.4622632015282115, disc_loss = 0.0006859820244320512
Trained batch 921 in epoch 4, gen_loss = 1.4622343729478418, disc_loss = 0.0006869696621330927
Trained batch 922 in epoch 4, gen_loss = 1.462062105843202, disc_loss = 0.000686681946210262
Trained batch 923 in epoch 4, gen_loss = 1.4620245435795227, disc_loss = 0.0006863461218033368
Trained batch 924 in epoch 4, gen_loss = 1.46195628514161, disc_loss = 0.0006857989105392826
Trained batch 925 in epoch 4, gen_loss = 1.462111111336084, disc_loss = 0.0006852719641551974
Trained batch 926 in epoch 4, gen_loss = 1.4624286707422365, disc_loss = 0.0006847709541968442
Trained batch 927 in epoch 4, gen_loss = 1.4620356941274528, disc_loss = 0.0006843953267748318
Trained batch 928 in epoch 4, gen_loss = 1.4619987398482241, disc_loss = 0.0006838944058877715
Trained batch 929 in epoch 4, gen_loss = 1.4620773115465717, disc_loss = 0.0006835263300613845
Trained batch 930 in epoch 4, gen_loss = 1.4619096703227172, disc_loss = 0.0006834721053466196
Trained batch 931 in epoch 4, gen_loss = 1.4620940657132684, disc_loss = 0.0006840475761756184
Trained batch 932 in epoch 4, gen_loss = 1.4618671865453035, disc_loss = 0.0006844611303220875
Trained batch 933 in epoch 4, gen_loss = 1.4620664752780497, disc_loss = 0.0006850367511980454
Trained batch 934 in epoch 4, gen_loss = 1.4623079914460209, disc_loss = 0.0006860490196635374
Trained batch 935 in epoch 4, gen_loss = 1.4628363894855874, disc_loss = 0.000686128758723063
Trained batch 936 in epoch 4, gen_loss = 1.463178548639841, disc_loss = 0.0006860451037339392
Trained batch 937 in epoch 4, gen_loss = 1.463638564925204, disc_loss = 0.0006858418200475681
Trained batch 938 in epoch 4, gen_loss = 1.4637816146539804, disc_loss = 0.0006855833860452304
Trained batch 939 in epoch 4, gen_loss = 1.4640226471931377, disc_loss = 0.0006853044154961529
Trained batch 940 in epoch 4, gen_loss = 1.4639220579777716, disc_loss = 0.0006849158536758463
Trained batch 941 in epoch 4, gen_loss = 1.4640706209366994, disc_loss = 0.0006846582794147607
Trained batch 942 in epoch 4, gen_loss = 1.4642140644099781, disc_loss = 0.0006844801910283673
Trained batch 943 in epoch 4, gen_loss = 1.4639506871669978, disc_loss = 0.0006843306536889724
Trained batch 944 in epoch 4, gen_loss = 1.4638441972631626, disc_loss = 0.0006838567531159488
Trained batch 945 in epoch 4, gen_loss = 1.464067395469351, disc_loss = 0.0006832741422817553
Trained batch 946 in epoch 4, gen_loss = 1.4639446160105993, disc_loss = 0.0006828216411576679
Trained batch 947 in epoch 4, gen_loss = 1.4640912797129104, disc_loss = 0.0006823176292819585
Trained batch 948 in epoch 4, gen_loss = 1.464769246957576, disc_loss = 0.0006818383894100794
Trained batch 949 in epoch 4, gen_loss = 1.464957112889541, disc_loss = 0.0006812393125437666
Trained batch 950 in epoch 4, gen_loss = 1.4650423022850831, disc_loss = 0.0006806809217383234
Trained batch 951 in epoch 4, gen_loss = 1.4649174491397472, disc_loss = 0.0006801654506091859
Trained batch 952 in epoch 4, gen_loss = 1.4648400668957802, disc_loss = 0.0006796920117605131
Trained batch 953 in epoch 4, gen_loss = 1.4646463351679548, disc_loss = 0.0006794634447763142
Trained batch 954 in epoch 4, gen_loss = 1.4643658402078439, disc_loss = 0.0006797202787296822
Trained batch 955 in epoch 4, gen_loss = 1.4644204067635236, disc_loss = 0.0006816013096167465
Trained batch 956 in epoch 4, gen_loss = 1.4644236204641614, disc_loss = 0.0006841882479977657
Trained batch 957 in epoch 4, gen_loss = 1.4642937022858225, disc_loss = 0.0006861168240410999
Trained batch 958 in epoch 4, gen_loss = 1.4643913153189936, disc_loss = 0.0006866489122702441
Trained batch 959 in epoch 4, gen_loss = 1.4641798151036103, disc_loss = 0.0006865049846434582
Trained batch 960 in epoch 4, gen_loss = 1.4639795769265738, disc_loss = 0.0006870103986843821
Trained batch 961 in epoch 4, gen_loss = 1.4638821295541933, disc_loss = 0.0006892362104590499
Trained batch 962 in epoch 4, gen_loss = 1.4637375262915036, disc_loss = 0.000692039569506486
Trained batch 963 in epoch 4, gen_loss = 1.4636346116600194, disc_loss = 0.0006935800153705223
Trained batch 964 in epoch 4, gen_loss = 1.4635884583922865, disc_loss = 0.0006936421420698421
Trained batch 965 in epoch 4, gen_loss = 1.4636283121987652, disc_loss = 0.0006933940344904795
Trained batch 966 in epoch 4, gen_loss = 1.463947461704187, disc_loss = 0.0006932664380123865
Trained batch 967 in epoch 4, gen_loss = 1.4640162205400546, disc_loss = 0.0006931664375687516
Trained batch 968 in epoch 4, gen_loss = 1.4637563104353946, disc_loss = 0.0006929237643808585
Trained batch 969 in epoch 4, gen_loss = 1.4634559713688093, disc_loss = 0.000692598119393992
Trained batch 970 in epoch 4, gen_loss = 1.4635132219715294, disc_loss = 0.0006922619922970082
Trained batch 971 in epoch 4, gen_loss = 1.4637730829264401, disc_loss = 0.0006918389642905897
Trained batch 972 in epoch 4, gen_loss = 1.4638892967188837, disc_loss = 0.0006917840881117731
Trained batch 973 in epoch 4, gen_loss = 1.4637014241678759, disc_loss = 0.0006922608047826679
Trained batch 974 in epoch 4, gen_loss = 1.4637069666691316, disc_loss = 0.0006925966816085677
Trained batch 975 in epoch 4, gen_loss = 1.463499262073978, disc_loss = 0.0006928737663925023
Trained batch 976 in epoch 4, gen_loss = 1.4635331786886818, disc_loss = 0.0006933129142590097
Trained batch 977 in epoch 4, gen_loss = 1.4633174350900398, disc_loss = 0.0006937704274754287
Trained batch 978 in epoch 4, gen_loss = 1.4630137621077868, disc_loss = 0.0006941412098480905
Trained batch 979 in epoch 4, gen_loss = 1.462800713826199, disc_loss = 0.0006946508331733343
Trained batch 980 in epoch 4, gen_loss = 1.4631049624519854, disc_loss = 0.0006946510025485804
Trained batch 981 in epoch 4, gen_loss = 1.4632873246237605, disc_loss = 0.0006946227706859364
Trained batch 982 in epoch 4, gen_loss = 1.4630315784035233, disc_loss = 0.0006944986778546038
Trained batch 983 in epoch 4, gen_loss = 1.4629415520807592, disc_loss = 0.0006942790433470699
Trained batch 984 in epoch 4, gen_loss = 1.4630139097949575, disc_loss = 0.0006939480414860504
Trained batch 985 in epoch 4, gen_loss = 1.462927166032501, disc_loss = 0.0006934662986898953
Trained batch 986 in epoch 4, gen_loss = 1.4627898708061364, disc_loss = 0.0006929702176163402
Trained batch 987 in epoch 4, gen_loss = 1.4628089674812579, disc_loss = 0.0006926077657767693
Trained batch 988 in epoch 4, gen_loss = 1.4626387584317924, disc_loss = 0.0006921510228823519
Trained batch 989 in epoch 4, gen_loss = 1.4626035554240449, disc_loss = 0.0006918716260494848
Trained batch 990 in epoch 4, gen_loss = 1.4624196312622393, disc_loss = 0.000692244266441708
Trained batch 991 in epoch 4, gen_loss = 1.4623797464995616, disc_loss = 0.0006942436868059538
Trained batch 992 in epoch 4, gen_loss = 1.4622268258985076, disc_loss = 0.0006960013853760614
Trained batch 993 in epoch 4, gen_loss = 1.46226989791187, disc_loss = 0.0006965586183961248
Trained batch 994 in epoch 4, gen_loss = 1.4621203614239717, disc_loss = 0.0006968630196619662
Trained batch 995 in epoch 4, gen_loss = 1.4621951011529408, disc_loss = 0.0006996055734520905
Trained batch 996 in epoch 4, gen_loss = 1.4620054883727338, disc_loss = 0.0007030548165031427
Trained batch 997 in epoch 4, gen_loss = 1.4617055713055367, disc_loss = 0.0007050917782122153
Trained batch 998 in epoch 4, gen_loss = 1.4617587399554324, disc_loss = 0.0007057806366580413
Trained batch 999 in epoch 4, gen_loss = 1.4616178642511368, disc_loss = 0.0007056933128260425
Trained batch 1000 in epoch 4, gen_loss = 1.4615710161544464, disc_loss = 0.0007058932722022698
Trained batch 1001 in epoch 4, gen_loss = 1.4615611871797405, disc_loss = 0.0007061493191007732
Trained batch 1002 in epoch 4, gen_loss = 1.4612817544404673, disc_loss = 0.0007066494850000179
Trained batch 1003 in epoch 4, gen_loss = 1.4611876418153604, disc_loss = 0.0007067175713989609
Trained batch 1004 in epoch 4, gen_loss = 1.4612051379028244, disc_loss = 0.0007063747919903053
Trained batch 1005 in epoch 4, gen_loss = 1.4610991172240695, disc_loss = 0.0007061853867195335
Trained batch 1006 in epoch 4, gen_loss = 1.4614507293748524, disc_loss = 0.0007058191540844201
Trained batch 1007 in epoch 4, gen_loss = 1.4615859421236175, disc_loss = 0.0007054023987967369
Trained batch 1008 in epoch 4, gen_loss = 1.4616708574729822, disc_loss = 0.0007050322001251093
Trained batch 1009 in epoch 4, gen_loss = 1.4614651461639026, disc_loss = 0.0007048303734768749
Trained batch 1010 in epoch 4, gen_loss = 1.4614221289179092, disc_loss = 0.0007044651731074341
Trained batch 1011 in epoch 4, gen_loss = 1.461197095897358, disc_loss = 0.0007039928003233281
Trained batch 1012 in epoch 4, gen_loss = 1.4613611693443456, disc_loss = 0.000703553398206027
Trained batch 1013 in epoch 4, gen_loss = 1.461499784119736, disc_loss = 0.0007030922345170375
Trained batch 1014 in epoch 4, gen_loss = 1.4616308514120544, disc_loss = 0.0007026851281802986
Trained batch 1015 in epoch 4, gen_loss = 1.461453707551393, disc_loss = 0.0007021608355318863
Trained batch 1016 in epoch 4, gen_loss = 1.461512149024971, disc_loss = 0.0007017475225460293
Trained batch 1017 in epoch 4, gen_loss = 1.4614057721229807, disc_loss = 0.0007012980484411332
Trained batch 1018 in epoch 4, gen_loss = 1.461279943366046, disc_loss = 0.000700808811667012
Trained batch 1019 in epoch 4, gen_loss = 1.4611743409259648, disc_loss = 0.0007003849412142824
Trained batch 1020 in epoch 4, gen_loss = 1.4613526394037961, disc_loss = 0.0006998980709213748
Trained batch 1021 in epoch 4, gen_loss = 1.461199622098247, disc_loss = 0.0006993966932936937
Trained batch 1022 in epoch 4, gen_loss = 1.4610153910934285, disc_loss = 0.0006990205712239431
Trained batch 1023 in epoch 4, gen_loss = 1.460841050138697, disc_loss = 0.0006988465530000099
Trained batch 1024 in epoch 4, gen_loss = 1.4607016849517822, disc_loss = 0.0006990145804948264
Trained batch 1025 in epoch 4, gen_loss = 1.4605691802431966, disc_loss = 0.0006993704655914695
Trained batch 1026 in epoch 4, gen_loss = 1.4605151896583535, disc_loss = 0.0006993512862459793
Trained batch 1027 in epoch 4, gen_loss = 1.4601412451452782, disc_loss = 0.000699195166526746
Trained batch 1028 in epoch 4, gen_loss = 1.460132925341266, disc_loss = 0.0006988774303369386
Trained batch 1029 in epoch 4, gen_loss = 1.4604505507691392, disc_loss = 0.0006984131686144748
Trained batch 1030 in epoch 4, gen_loss = 1.4602714337618112, disc_loss = 0.0006979442118407022
Trained batch 1031 in epoch 4, gen_loss = 1.4600764864174895, disc_loss = 0.0006975557771017851
Trained batch 1032 in epoch 4, gen_loss = 1.4599601444639518, disc_loss = 0.0006972073064308405
Trained batch 1033 in epoch 4, gen_loss = 1.459735649927903, disc_loss = 0.0006971627899369147
Trained batch 1034 in epoch 4, gen_loss = 1.459852337491685, disc_loss = 0.0006973488259217522
Trained batch 1035 in epoch 4, gen_loss = 1.459917078377197, disc_loss = 0.000697858211859752
Trained batch 1036 in epoch 4, gen_loss = 1.4597758999670942, disc_loss = 0.0006981077853848116
Trained batch 1037 in epoch 4, gen_loss = 1.4593345377027185, disc_loss = 0.0006979340734568704
Trained batch 1038 in epoch 4, gen_loss = 1.4593615615677673, disc_loss = 0.0006977269030873587
Trained batch 1039 in epoch 4, gen_loss = 1.4592238139647704, disc_loss = 0.0006976702780635745
Trained batch 1040 in epoch 4, gen_loss = 1.4593088591362169, disc_loss = 0.0006973697086537277
Trained batch 1041 in epoch 4, gen_loss = 1.4592016666498386, disc_loss = 0.0006969205544408051
Trained batch 1042 in epoch 4, gen_loss = 1.4592364503004636, disc_loss = 0.0006964291484041692
Trained batch 1043 in epoch 4, gen_loss = 1.4592729282790218, disc_loss = 0.0006961038225164599
Trained batch 1044 in epoch 4, gen_loss = 1.4590498113175898, disc_loss = 0.0006956939754350908
Trained batch 1045 in epoch 4, gen_loss = 1.4592882479126092, disc_loss = 0.0006953269815870741
Trained batch 1046 in epoch 4, gen_loss = 1.459200994105371, disc_loss = 0.0006948102134823734
Trained batch 1047 in epoch 4, gen_loss = 1.4589493423700333, disc_loss = 0.0006943251969633675
Trained batch 1048 in epoch 4, gen_loss = 1.4588718019972766, disc_loss = 0.0006939429423680908
Trained batch 1049 in epoch 4, gen_loss = 1.4588807064010982, disc_loss = 0.000693514759082713
Trained batch 1050 in epoch 4, gen_loss = 1.4590563818344493, disc_loss = 0.0006931337379462434
Trained batch 1051 in epoch 4, gen_loss = 1.4590809601341364, disc_loss = 0.0006928696438713648
Trained batch 1052 in epoch 4, gen_loss = 1.459233097201399, disc_loss = 0.0006926900377024008
Trained batch 1053 in epoch 4, gen_loss = 1.4592418867451415, disc_loss = 0.0006929260621886577
Trained batch 1054 in epoch 4, gen_loss = 1.4592337741671015, disc_loss = 0.0006930649140477291
Trained batch 1055 in epoch 4, gen_loss = 1.4591647332364863, disc_loss = 0.0006928797178550832
Trained batch 1056 in epoch 4, gen_loss = 1.459111140827695, disc_loss = 0.0006924691991623365
Trained batch 1057 in epoch 4, gen_loss = 1.4589421690524413, disc_loss = 0.0006920239584618279
Trained batch 1058 in epoch 4, gen_loss = 1.4587580038760495, disc_loss = 0.0006916831763476292
Trained batch 1059 in epoch 4, gen_loss = 1.4585882253241989, disc_loss = 0.0006914051641220829
Trained batch 1060 in epoch 4, gen_loss = 1.458445073634695, disc_loss = 0.0006910590690907471
Trained batch 1061 in epoch 4, gen_loss = 1.4587648596242773, disc_loss = 0.0006906024099083941
Trained batch 1062 in epoch 4, gen_loss = 1.458410055706889, disc_loss = 0.0006901711696058074
Trained batch 1063 in epoch 4, gen_loss = 1.4584465207237947, disc_loss = 0.0006898543554058065
Trained batch 1064 in epoch 4, gen_loss = 1.4584767999783368, disc_loss = 0.0006894618615537047
Trained batch 1065 in epoch 4, gen_loss = 1.4584019387640603, disc_loss = 0.0006890230489000665
Trained batch 1066 in epoch 4, gen_loss = 1.4587244086994002, disc_loss = 0.0006886414830165831
Trained batch 1067 in epoch 4, gen_loss = 1.4585130884406272, disc_loss = 0.000688218026256988
Trained batch 1068 in epoch 4, gen_loss = 1.4586421492168902, disc_loss = 0.0006877931701238842
Trained batch 1069 in epoch 4, gen_loss = 1.4585015101967571, disc_loss = 0.0006876491258183612
Trained batch 1070 in epoch 4, gen_loss = 1.4585129222950013, disc_loss = 0.0006880104008221927
Trained batch 1071 in epoch 4, gen_loss = 1.4585412890831035, disc_loss = 0.0006884238658728206
Trained batch 1072 in epoch 4, gen_loss = 1.458483555665776, disc_loss = 0.0006885390118033433
Trained batch 1073 in epoch 4, gen_loss = 1.4583999742120781, disc_loss = 0.0006883486270287453
Trained batch 1074 in epoch 4, gen_loss = 1.4585183927624725, disc_loss = 0.0006880233403455011
Trained batch 1075 in epoch 4, gen_loss = 1.4584567660957464, disc_loss = 0.0006875868255445508
Trained batch 1076 in epoch 4, gen_loss = 1.4584970874928056, disc_loss = 0.0006872899003908754
Trained batch 1077 in epoch 4, gen_loss = 1.4584244790457617, disc_loss = 0.0006879230235754154
Trained batch 1078 in epoch 4, gen_loss = 1.458712573179611, disc_loss = 0.0006888635335979398
Trained batch 1079 in epoch 4, gen_loss = 1.4587050728223943, disc_loss = 0.0006897088632252201
Trained batch 1080 in epoch 4, gen_loss = 1.4587804467230345, disc_loss = 0.0006898302052496453
Trained batch 1081 in epoch 4, gen_loss = 1.4591525454838483, disc_loss = 0.0006896377080937313
Trained batch 1082 in epoch 4, gen_loss = 1.4589151790157469, disc_loss = 0.0006895231268985566
Trained batch 1083 in epoch 4, gen_loss = 1.458848078972299, disc_loss = 0.0006892784847649707
Trained batch 1084 in epoch 4, gen_loss = 1.4588756427237515, disc_loss = 0.0006889241212892586
Trained batch 1085 in epoch 4, gen_loss = 1.4588127435900229, disc_loss = 0.0006884514090613549
Trained batch 1086 in epoch 4, gen_loss = 1.4588249741942925, disc_loss = 0.0006881291890870193
Trained batch 1087 in epoch 4, gen_loss = 1.4590340689482058, disc_loss = 0.0006879805711017017
Trained batch 1088 in epoch 4, gen_loss = 1.4592118170197892, disc_loss = 0.0006877191511313243
Trained batch 1089 in epoch 4, gen_loss = 1.4593033649505824, disc_loss = 0.0006875547627080552
Trained batch 1090 in epoch 4, gen_loss = 1.4595523919674587, disc_loss = 0.0006877148763039645
Trained batch 1091 in epoch 4, gen_loss = 1.4595983716157765, disc_loss = 0.0006884579180113288
Trained batch 1092 in epoch 4, gen_loss = 1.4595675084532016, disc_loss = 0.000689144800524434
Trained batch 1093 in epoch 4, gen_loss = 1.4596115540324879, disc_loss = 0.0006894358025677651
Trained batch 1094 in epoch 4, gen_loss = 1.4597785089658275, disc_loss = 0.0006891611733005518
Trained batch 1095 in epoch 4, gen_loss = 1.4598024818148927, disc_loss = 0.0006888728890625694
Trained batch 1096 in epoch 4, gen_loss = 1.460102122592839, disc_loss = 0.00068854700670141
Trained batch 1097 in epoch 4, gen_loss = 1.4601614821586886, disc_loss = 0.0006882748330066142
Trained batch 1098 in epoch 4, gen_loss = 1.4599389009198023, disc_loss = 0.0006879331260405076
Trained batch 1099 in epoch 4, gen_loss = 1.459885480187156, disc_loss = 0.0006875352239942665
Trained batch 1100 in epoch 4, gen_loss = 1.4600104670650194, disc_loss = 0.0006873420773244372
Trained batch 1101 in epoch 4, gen_loss = 1.4599203890334889, disc_loss = 0.0006872306606793474
Trained batch 1102 in epoch 4, gen_loss = 1.460177815511674, disc_loss = 0.0006872706060771786
Trained batch 1103 in epoch 4, gen_loss = 1.459804777001989, disc_loss = 0.000687794133629749
Trained batch 1104 in epoch 4, gen_loss = 1.4598120708810798, disc_loss = 0.0006884841233841144
Trained batch 1105 in epoch 4, gen_loss = 1.4602093579109496, disc_loss = 0.0006890869855397709
Trained batch 1106 in epoch 4, gen_loss = 1.4602270216799687, disc_loss = 0.000689245406377086
Trained batch 1107 in epoch 4, gen_loss = 1.460384153502082, disc_loss = 0.0006890786970138785
Trained batch 1108 in epoch 4, gen_loss = 1.4603178371063108, disc_loss = 0.000688866571219824
Trained batch 1109 in epoch 4, gen_loss = 1.4604359226183847, disc_loss = 0.0006884358273931833
Trained batch 1110 in epoch 4, gen_loss = 1.4604187924834011, disc_loss = 0.0006879654921927953
Trained batch 1111 in epoch 4, gen_loss = 1.4606298749609816, disc_loss = 0.0006875104223097538
Trained batch 1112 in epoch 4, gen_loss = 1.460599538772254, disc_loss = 0.0006870951603914307
Trained batch 1113 in epoch 4, gen_loss = 1.4603936395054447, disc_loss = 0.0006867898058252725
Trained batch 1114 in epoch 4, gen_loss = 1.4606282419153394, disc_loss = 0.0006866909514143207
Trained batch 1115 in epoch 4, gen_loss = 1.4605827452247715, disc_loss = 0.0006867747853257536
Trained batch 1116 in epoch 4, gen_loss = 1.4607011669964907, disc_loss = 0.0006865319084165465
Trained batch 1117 in epoch 4, gen_loss = 1.460706766261611, disc_loss = 0.0006861573718275274
Trained batch 1118 in epoch 4, gen_loss = 1.4607726312088476, disc_loss = 0.0006858588945741351
Trained batch 1119 in epoch 4, gen_loss = 1.4609419392687935, disc_loss = 0.0006857515157792347
Trained batch 1120 in epoch 4, gen_loss = 1.461044156157896, disc_loss = 0.000685375118337106
Trained batch 1121 in epoch 4, gen_loss = 1.4612935456362637, disc_loss = 0.0006849719668314074
Trained batch 1122 in epoch 4, gen_loss = 1.4611496895631295, disc_loss = 0.000684573511495962
Trained batch 1123 in epoch 4, gen_loss = 1.4611356359147516, disc_loss = 0.0006841508000246535
Trained batch 1124 in epoch 4, gen_loss = 1.4609974506166246, disc_loss = 0.0006837662133556377
Trained batch 1125 in epoch 4, gen_loss = 1.460627651765122, disc_loss = 0.0006835096972549626
Trained batch 1126 in epoch 4, gen_loss = 1.4604962442232214, disc_loss = 0.0006834151509084975
Trained batch 1127 in epoch 4, gen_loss = 1.4603201728974673, disc_loss = 0.0006836518433367844
Trained batch 1128 in epoch 4, gen_loss = 1.4602017855623108, disc_loss = 0.0006840324776552463
Trained batch 1129 in epoch 4, gen_loss = 1.4600798205991763, disc_loss = 0.0006842804841959408
Trained batch 1130 in epoch 4, gen_loss = 1.4599716535824574, disc_loss = 0.0006842843828120995
Trained batch 1131 in epoch 4, gen_loss = 1.4597967740924958, disc_loss = 0.0006841478790504658
Trained batch 1132 in epoch 4, gen_loss = 1.4599926282322102, disc_loss = 0.0006837750445940492
Trained batch 1133 in epoch 4, gen_loss = 1.460202185985693, disc_loss = 0.0006839542183062621
Trained batch 1134 in epoch 4, gen_loss = 1.4603012452566677, disc_loss = 0.0006850763588247817
Trained batch 1135 in epoch 4, gen_loss = 1.4601822156511561, disc_loss = 0.0006861249006517386
Trained batch 1136 in epoch 4, gen_loss = 1.4603530332092245, disc_loss = 0.0006864981146563822
Trained batch 1137 in epoch 4, gen_loss = 1.4602387210187258, disc_loss = 0.0006862530033315367
Trained batch 1138 in epoch 4, gen_loss = 1.4602615878286855, disc_loss = 0.0006858231855029076
Trained batch 1139 in epoch 4, gen_loss = 1.459995810086267, disc_loss = 0.0006854960623489828
Trained batch 1140 in epoch 4, gen_loss = 1.459876301098455, disc_loss = 0.0006852455034843968
Trained batch 1141 in epoch 4, gen_loss = 1.4598329828207213, disc_loss = 0.0006853606223804903
Trained batch 1142 in epoch 4, gen_loss = 1.459984686848164, disc_loss = 0.0006856202056400957
Trained batch 1143 in epoch 4, gen_loss = 1.459878465199804, disc_loss = 0.0006856294223223915
Trained batch 1144 in epoch 4, gen_loss = 1.4602174252922357, disc_loss = 0.0006854830846136058
Trained batch 1145 in epoch 4, gen_loss = 1.4604664662329523, disc_loss = 0.0006856186162901536
Trained batch 1146 in epoch 4, gen_loss = 1.4603687196372381, disc_loss = 0.0006860294720382184
Trained batch 1147 in epoch 4, gen_loss = 1.4603780491426848, disc_loss = 0.0006864344330490035
Trained batch 1148 in epoch 4, gen_loss = 1.4606178046517833, disc_loss = 0.0006866181183027754
Trained batch 1149 in epoch 4, gen_loss = 1.460667769494264, disc_loss = 0.0006867330735511369
Trained batch 1150 in epoch 4, gen_loss = 1.460598185619616, disc_loss = 0.0006867489064208695
Trained batch 1151 in epoch 4, gen_loss = 1.4605505683769782, disc_loss = 0.0006866797979417546
Trained batch 1152 in epoch 4, gen_loss = 1.4606664415452135, disc_loss = 0.0006865400370012615
Trained batch 1153 in epoch 4, gen_loss = 1.4606394444429276, disc_loss = 0.0006863190421326254
Trained batch 1154 in epoch 4, gen_loss = 1.4606671234229942, disc_loss = 0.0006860744009851236
Trained batch 1155 in epoch 4, gen_loss = 1.460795232890799, disc_loss = 0.0006857284490667323
Trained batch 1156 in epoch 4, gen_loss = 1.4608998151307695, disc_loss = 0.0006853787530835516
Trained batch 1157 in epoch 4, gen_loss = 1.4607499915083455, disc_loss = 0.0006850330450521104
Trained batch 1158 in epoch 4, gen_loss = 1.4605593057003794, disc_loss = 0.0006847409555643601
Trained batch 1159 in epoch 4, gen_loss = 1.4610405657825798, disc_loss = 0.0006848181236160473
Trained batch 1160 in epoch 4, gen_loss = 1.4607921635457712, disc_loss = 0.0006854042065878636
Trained batch 1161 in epoch 4, gen_loss = 1.460834192121706, disc_loss = 0.0006863483544537759
Trained batch 1162 in epoch 4, gen_loss = 1.4606587788408825, disc_loss = 0.0006870880685725148
Trained batch 1163 in epoch 4, gen_loss = 1.4603363033832144, disc_loss = 0.0006869915336104133
Trained batch 1164 in epoch 4, gen_loss = 1.460892950721053, disc_loss = 0.0006870157775419661
Trained batch 1165 in epoch 4, gen_loss = 1.4606810932911893, disc_loss = 0.0006873991361328087
Trained batch 1166 in epoch 4, gen_loss = 1.4609667453994686, disc_loss = 0.0006877896329629931
Trained batch 1167 in epoch 4, gen_loss = 1.4609966111713892, disc_loss = 0.0006881633554531954
Trained batch 1168 in epoch 4, gen_loss = 1.4609335805739574, disc_loss = 0.0006880359519578272
Trained batch 1169 in epoch 4, gen_loss = 1.460745308541844, disc_loss = 0.0006878541921363431
Trained batch 1170 in epoch 4, gen_loss = 1.46081361619964, disc_loss = 0.0006878551925506373
Trained batch 1171 in epoch 4, gen_loss = 1.4606964804816978, disc_loss = 0.0006876471422677927
Trained batch 1172 in epoch 4, gen_loss = 1.4605624729613411, disc_loss = 0.0006873614362936537
Trained batch 1173 in epoch 4, gen_loss = 1.4604792928979995, disc_loss = 0.000687264494183269
Trained batch 1174 in epoch 4, gen_loss = 1.460552586190244, disc_loss = 0.0006877430682528784
Trained batch 1175 in epoch 4, gen_loss = 1.460528483500286, disc_loss = 0.0006895098731052514
Trained batch 1176 in epoch 4, gen_loss = 1.4606010274757444, disc_loss = 0.0006914622428455191
Trained batch 1177 in epoch 4, gen_loss = 1.4605969540736874, disc_loss = 0.0006920919853584474
Trained batch 1178 in epoch 4, gen_loss = 1.460617812737456, disc_loss = 0.0006918933417787203
Trained batch 1179 in epoch 4, gen_loss = 1.4605170504521516, disc_loss = 0.0006919971539530907
Trained batch 1180 in epoch 4, gen_loss = 1.4605177049410736, disc_loss = 0.000692774157393355
Trained batch 1181 in epoch 4, gen_loss = 1.4605989051752688, disc_loss = 0.0006930429392257196
Trained batch 1182 in epoch 4, gen_loss = 1.460654764888857, disc_loss = 0.000693029244629391
Trained batch 1183 in epoch 4, gen_loss = 1.4606134393126577, disc_loss = 0.0006928513014126774
Trained batch 1184 in epoch 4, gen_loss = 1.4604427350724296, disc_loss = 0.0006927801062854475
Trained batch 1185 in epoch 4, gen_loss = 1.4605741351089028, disc_loss = 0.0006924964031719419
Trained batch 1186 in epoch 4, gen_loss = 1.4608188092256658, disc_loss = 0.000692307074142986
Trained batch 1187 in epoch 4, gen_loss = 1.4610174817067605, disc_loss = 0.0006920259506918387
Trained batch 1188 in epoch 4, gen_loss = 1.460896481276561, disc_loss = 0.0006918407698084844
Trained batch 1189 in epoch 4, gen_loss = 1.460821171868749, disc_loss = 0.0006919592144782166
Trained batch 1190 in epoch 4, gen_loss = 1.4609527498808956, disc_loss = 0.0006927052193636909
Trained batch 1191 in epoch 4, gen_loss = 1.4609868726474327, disc_loss = 0.0006946525230118243
Trained batch 1192 in epoch 4, gen_loss = 1.460994449065497, disc_loss = 0.0006968478010124753
Trained batch 1193 in epoch 4, gen_loss = 1.4610468270990318, disc_loss = 0.0006978342993765733
Trained batch 1194 in epoch 4, gen_loss = 1.4608464400638597, disc_loss = 0.0006981033446361257
Trained batch 1195 in epoch 4, gen_loss = 1.4612656101135904, disc_loss = 0.0006981025012510296
Trained batch 1196 in epoch 4, gen_loss = 1.4613855715682333, disc_loss = 0.0006982258556044697
Trained batch 1197 in epoch 4, gen_loss = 1.4613266707660757, disc_loss = 0.0006982987437981553
Trained batch 1198 in epoch 4, gen_loss = 1.4613432779821185, disc_loss = 0.000698192723128089
Trained batch 1199 in epoch 4, gen_loss = 1.4614307156205177, disc_loss = 0.0006980501224279578
Trained batch 1200 in epoch 4, gen_loss = 1.461343437606945, disc_loss = 0.0006979704313523478
Trained batch 1201 in epoch 4, gen_loss = 1.4611405790744725, disc_loss = 0.0006978950942855367
Trained batch 1202 in epoch 4, gen_loss = 1.461207406677411, disc_loss = 0.0006977985716411431
Trained batch 1203 in epoch 4, gen_loss = 1.461222626343122, disc_loss = 0.0006974915408456727
Trained batch 1204 in epoch 4, gen_loss = 1.46135555599735, disc_loss = 0.0006972100179513464
Trained batch 1205 in epoch 4, gen_loss = 1.4612467451079765, disc_loss = 0.0006969601719485843
Trained batch 1206 in epoch 4, gen_loss = 1.4612327102006915, disc_loss = 0.000696646063031319
Trained batch 1207 in epoch 4, gen_loss = 1.4613552434949686, disc_loss = 0.0006962680183206002
Trained batch 1208 in epoch 4, gen_loss = 1.461327883307849, disc_loss = 0.0006960914078533223
Trained batch 1209 in epoch 4, gen_loss = 1.46164653281535, disc_loss = 0.0006961163378420213
Trained batch 1210 in epoch 4, gen_loss = 1.461768147474867, disc_loss = 0.0006959467049707616
Trained batch 1211 in epoch 4, gen_loss = 1.461455929692429, disc_loss = 0.000695713641095425
Trained batch 1212 in epoch 4, gen_loss = 1.461265236999216, disc_loss = 0.0006955148385954666
Trained batch 1213 in epoch 4, gen_loss = 1.4615629008024489, disc_loss = 0.0006952822651902326
Trained batch 1214 in epoch 4, gen_loss = 1.4613842575638383, disc_loss = 0.0006949394924502432
Trained batch 1215 in epoch 4, gen_loss = 1.4612368860919225, disc_loss = 0.0006945206782024558
Trained batch 1216 in epoch 4, gen_loss = 1.461156403127026, disc_loss = 0.0006941671668447691
Trained batch 1217 in epoch 4, gen_loss = 1.4610904988592677, disc_loss = 0.0006938250514554691
Trained batch 1218 in epoch 4, gen_loss = 1.4609245117616223, disc_loss = 0.0006935560412590249
Trained batch 1219 in epoch 4, gen_loss = 1.461091141329437, disc_loss = 0.0006934549448547454
Trained batch 1220 in epoch 4, gen_loss = 1.4612913978187692, disc_loss = 0.0006933018909215704
Trained batch 1221 in epoch 4, gen_loss = 1.4614066358673983, disc_loss = 0.000693070598265738
Trained batch 1222 in epoch 4, gen_loss = 1.4613880498040823, disc_loss = 0.0006927772010891213
Trained batch 1223 in epoch 4, gen_loss = 1.4610933734505784, disc_loss = 0.000692375309994698
Trained batch 1224 in epoch 4, gen_loss = 1.4611572919573104, disc_loss = 0.0006919064838261039
Trained batch 1225 in epoch 4, gen_loss = 1.4611158742406822, disc_loss = 0.0006914499742748557
Trained batch 1226 in epoch 4, gen_loss = 1.4610599183220152, disc_loss = 0.00069108925750518
Trained batch 1227 in epoch 4, gen_loss = 1.4609618350038311, disc_loss = 0.0006907029953760687
Trained batch 1228 in epoch 4, gen_loss = 1.4612323263973799, disc_loss = 0.0006902757793912824
Trained batch 1229 in epoch 4, gen_loss = 1.4611438163896886, disc_loss = 0.0006898630538383192
Trained batch 1230 in epoch 4, gen_loss = 1.4613703041905606, disc_loss = 0.0006894056000194027
Trained batch 1231 in epoch 4, gen_loss = 1.4615285060815997, disc_loss = 0.0006889323255870897
Trained batch 1232 in epoch 4, gen_loss = 1.4612285793069313, disc_loss = 0.00068850819021487
Trained batch 1233 in epoch 4, gen_loss = 1.4610568024157704, disc_loss = 0.0006880646405679402
Trained batch 1234 in epoch 4, gen_loss = 1.4607380885344285, disc_loss = 0.0006876542598849468
Trained batch 1235 in epoch 4, gen_loss = 1.4607164771039896, disc_loss = 0.0006874372813287685
Trained batch 1236 in epoch 4, gen_loss = 1.4607829235211052, disc_loss = 0.0006871808711915102
Trained batch 1237 in epoch 4, gen_loss = 1.4609328720219108, disc_loss = 0.0006867353274698631
Trained batch 1238 in epoch 4, gen_loss = 1.4608491402272739, disc_loss = 0.0006863517390624311
Trained batch 1239 in epoch 4, gen_loss = 1.4607958703271804, disc_loss = 0.0006859314510297883
Trained batch 1240 in epoch 4, gen_loss = 1.4608754321128299, disc_loss = 0.0006855622182679843
Trained batch 1241 in epoch 4, gen_loss = 1.4608396868582894, disc_loss = 0.000685132013660514
Trained batch 1242 in epoch 4, gen_loss = 1.4609865000050393, disc_loss = 0.0006847140403987135
Trained batch 1243 in epoch 4, gen_loss = 1.461143574722327, disc_loss = 0.0006843042055623014
Trained batch 1244 in epoch 4, gen_loss = 1.461140364719682, disc_loss = 0.0006838869295575297
Trained batch 1245 in epoch 4, gen_loss = 1.4609843019880415, disc_loss = 0.0006834998632000403
Trained batch 1246 in epoch 4, gen_loss = 1.4608968555592687, disc_loss = 0.0006831951747211417
Trained batch 1247 in epoch 4, gen_loss = 1.4611452066172392, disc_loss = 0.0006830305823115897
Trained batch 1248 in epoch 4, gen_loss = 1.4610194208337557, disc_loss = 0.0006827868683707977
Trained batch 1249 in epoch 4, gen_loss = 1.4609859761238098, disc_loss = 0.0006824295500351582
Trained batch 1250 in epoch 4, gen_loss = 1.4609940479889953, disc_loss = 0.0006821261444686001
Trained batch 1251 in epoch 4, gen_loss = 1.4610085825379284, disc_loss = 0.0006819285583344735
Trained batch 1252 in epoch 4, gen_loss = 1.4610472586472703, disc_loss = 0.0006818418308046085
Trained batch 1253 in epoch 4, gen_loss = 1.4609509049610279, disc_loss = 0.0006816641281790489
Trained batch 1254 in epoch 4, gen_loss = 1.4608757846383935, disc_loss = 0.0006813307436597274
Trained batch 1255 in epoch 4, gen_loss = 1.4606484392076542, disc_loss = 0.0006809467633594896
Trained batch 1256 in epoch 4, gen_loss = 1.4608990365584502, disc_loss = 0.0006806716363382594
Trained batch 1257 in epoch 4, gen_loss = 1.4607047671733486, disc_loss = 0.0006804518694430904
Trained batch 1258 in epoch 4, gen_loss = 1.460612877670785, disc_loss = 0.0006804396132813272
Trained batch 1259 in epoch 4, gen_loss = 1.4606030691237677, disc_loss = 0.0006805687755014145
Trained batch 1260 in epoch 4, gen_loss = 1.4604763104554492, disc_loss = 0.0006807040358634801
Trained batch 1261 in epoch 4, gen_loss = 1.460354617866208, disc_loss = 0.000680494265587347
Trained batch 1262 in epoch 4, gen_loss = 1.4602242720476333, disc_loss = 0.000680170743423173
Trained batch 1263 in epoch 4, gen_loss = 1.460254328726213, disc_loss = 0.000679819956444647
Trained batch 1264 in epoch 4, gen_loss = 1.460230265116032, disc_loss = 0.0006795741503737525
Trained batch 1265 in epoch 4, gen_loss = 1.46028093609953, disc_loss = 0.0006793374806679958
Trained batch 1266 in epoch 4, gen_loss = 1.460346664983453, disc_loss = 0.0006791670737414946
Trained batch 1267 in epoch 4, gen_loss = 1.4603626915144996, disc_loss = 0.0006789352804620597
Trained batch 1268 in epoch 4, gen_loss = 1.4602860997660692, disc_loss = 0.0006787489685735891
Trained batch 1269 in epoch 4, gen_loss = 1.4601542447495648, disc_loss = 0.0006784036695807311
Trained batch 1270 in epoch 4, gen_loss = 1.460248512606467, disc_loss = 0.000678044706036439
Trained batch 1271 in epoch 4, gen_loss = 1.460107463429559, disc_loss = 0.0006777730273001307
Trained batch 1272 in epoch 4, gen_loss = 1.4599164596993626, disc_loss = 0.000677549270926951
Trained batch 1273 in epoch 4, gen_loss = 1.4598953123182479, disc_loss = 0.0006771717460285905
Trained batch 1274 in epoch 4, gen_loss = 1.45984984108046, disc_loss = 0.0006767460203206843
Trained batch 1275 in epoch 4, gen_loss = 1.459880858472896, disc_loss = 0.0006763579647462661
Trained batch 1276 in epoch 4, gen_loss = 1.4596266893082144, disc_loss = 0.0006760393469109887
Trained batch 1277 in epoch 4, gen_loss = 1.4594404241288772, disc_loss = 0.000675743298008843
Trained batch 1278 in epoch 4, gen_loss = 1.4596846089687452, disc_loss = 0.0006754424935846191
Trained batch 1279 in epoch 4, gen_loss = 1.459474549163133, disc_loss = 0.0006752149589431156
Trained batch 1280 in epoch 4, gen_loss = 1.4593052334565841, disc_loss = 0.0006750101469198418
Trained batch 1281 in epoch 4, gen_loss = 1.4592491303702784, disc_loss = 0.000674689126492875
Trained batch 1282 in epoch 4, gen_loss = 1.4592936625261375, disc_loss = 0.0006743618134311284
Trained batch 1283 in epoch 4, gen_loss = 1.4592163361307244, disc_loss = 0.0006740072667610964
Trained batch 1284 in epoch 4, gen_loss = 1.4593622852392234, disc_loss = 0.0006736669425727122
Trained batch 1285 in epoch 4, gen_loss = 1.4593412074293728, disc_loss = 0.0006732728562407318
Trained batch 1286 in epoch 4, gen_loss = 1.4596112979505076, disc_loss = 0.0006729622653815493
Trained batch 1287 in epoch 4, gen_loss = 1.459525752604378, disc_loss = 0.0006726039074796887
Trained batch 1288 in epoch 4, gen_loss = 1.4594568898272755, disc_loss = 0.0006722345245245514
Trained batch 1289 in epoch 4, gen_loss = 1.459678814300271, disc_loss = 0.0006718158571836051
Trained batch 1290 in epoch 4, gen_loss = 1.4596584750920834, disc_loss = 0.0006713849888248554
Trained batch 1291 in epoch 4, gen_loss = 1.4594173556879948, disc_loss = 0.0006712196599980892
Trained batch 1292 in epoch 4, gen_loss = 1.4593502762514956, disc_loss = 0.0006711294980891562
Trained batch 1293 in epoch 4, gen_loss = 1.459683607774319, disc_loss = 0.0006709969449865072
Trained batch 1294 in epoch 4, gen_loss = 1.4597034506816202, disc_loss = 0.000670808286822543
Trained batch 1295 in epoch 4, gen_loss = 1.4600304073573631, disc_loss = 0.0006706835971822273
Trained batch 1296 in epoch 4, gen_loss = 1.4598075140414095, disc_loss = 0.0006707532421116065
Trained batch 1297 in epoch 4, gen_loss = 1.4598262366050931, disc_loss = 0.0006706035025920507
Trained batch 1298 in epoch 4, gen_loss = 1.4599534380518537, disc_loss = 0.0006703806187168608
Trained batch 1299 in epoch 4, gen_loss = 1.4603013399014106, disc_loss = 0.0006702682313502569
Trained batch 1300 in epoch 4, gen_loss = 1.46064417532643, disc_loss = 0.0006702947599712139
Trained batch 1301 in epoch 4, gen_loss = 1.4607419446682968, disc_loss = 0.0006705064931412756
Trained batch 1302 in epoch 4, gen_loss = 1.4609639782770176, disc_loss = 0.0006710120781010044
Trained batch 1303 in epoch 4, gen_loss = 1.4606551028833799, disc_loss = 0.0006717591952244438
Trained batch 1304 in epoch 4, gen_loss = 1.4606206742283028, disc_loss = 0.0006725490239809688
Trained batch 1305 in epoch 4, gen_loss = 1.460690650238925, disc_loss = 0.0006729869525601954
Trained batch 1306 in epoch 4, gen_loss = 1.4607373586390524, disc_loss = 0.0006730019078403729
Trained batch 1307 in epoch 4, gen_loss = 1.460594104882045, disc_loss = 0.0006727040558023216
Trained batch 1308 in epoch 4, gen_loss = 1.4603933242553058, disc_loss = 0.0006722579102262316
Trained batch 1309 in epoch 4, gen_loss = 1.4603060765120819, disc_loss = 0.0006719119280906846
Trained batch 1310 in epoch 4, gen_loss = 1.4603621104943851, disc_loss = 0.0006717310606367999
Trained batch 1311 in epoch 4, gen_loss = 1.4603753305244735, disc_loss = 0.0006716555287988651
Trained batch 1312 in epoch 4, gen_loss = 1.4606699069219968, disc_loss = 0.0006715314284201356
Trained batch 1313 in epoch 4, gen_loss = 1.4606264990214344, disc_loss = 0.0006712329484790524
Trained batch 1314 in epoch 4, gen_loss = 1.4605067908537253, disc_loss = 0.0006708757320368935
Trained batch 1315 in epoch 4, gen_loss = 1.4605620691841497, disc_loss = 0.0006705911438658712
Trained batch 1316 in epoch 4, gen_loss = 1.4608270415955633, disc_loss = 0.0006703515393608116
Trained batch 1317 in epoch 4, gen_loss = 1.4607143873329047, disc_loss = 0.000670127074158182
Trained batch 1318 in epoch 4, gen_loss = 1.460451418292441, disc_loss = 0.0006700026870138468
Trained batch 1319 in epoch 4, gen_loss = 1.460497984380433, disc_loss = 0.0006698732698416941
Trained batch 1320 in epoch 4, gen_loss = 1.4603973958277503, disc_loss = 0.0006695327734374011
Trained batch 1321 in epoch 4, gen_loss = 1.4605492862017542, disc_loss = 0.0006692551376245498
Trained batch 1322 in epoch 4, gen_loss = 1.4605895952122372, disc_loss = 0.0006689991539833699
Trained batch 1323 in epoch 4, gen_loss = 1.4605289217748672, disc_loss = 0.0006687042971221738
Trained batch 1324 in epoch 4, gen_loss = 1.460492504497744, disc_loss = 0.0006683361467428699
Trained batch 1325 in epoch 4, gen_loss = 1.4604441039882274, disc_loss = 0.0006680156498496244
Trained batch 1326 in epoch 4, gen_loss = 1.4604168648816809, disc_loss = 0.0006679056029601079
Trained batch 1327 in epoch 4, gen_loss = 1.4602381846452335, disc_loss = 0.0006677263953181875
Trained batch 1328 in epoch 4, gen_loss = 1.4601753271998454, disc_loss = 0.000667343988445119
Trained batch 1329 in epoch 4, gen_loss = 1.4603656045476296, disc_loss = 0.0006671643634801608
Trained batch 1330 in epoch 4, gen_loss = 1.460360935717754, disc_loss = 0.0006673559856587152
Trained batch 1331 in epoch 4, gen_loss = 1.46057990193367, disc_loss = 0.0006678081649447271
Trained batch 1332 in epoch 4, gen_loss = 1.4606510348008794, disc_loss = 0.0006685248136086601
Trained batch 1333 in epoch 4, gen_loss = 1.4606805516147185, disc_loss = 0.0006687837721247346
Trained batch 1334 in epoch 4, gen_loss = 1.4608501393250313, disc_loss = 0.00066878440496551
Trained batch 1335 in epoch 4, gen_loss = 1.4609795616058532, disc_loss = 0.0006688888293963632
Trained batch 1336 in epoch 4, gen_loss = 1.460731859249951, disc_loss = 0.0006691481884279937
Trained batch 1337 in epoch 4, gen_loss = 1.4606978079841455, disc_loss = 0.0006696825471823016
Trained batch 1338 in epoch 4, gen_loss = 1.4607952895495677, disc_loss = 0.000670212491699437
Trained batch 1339 in epoch 4, gen_loss = 1.4605164639095762, disc_loss = 0.0006706034467147694
Trained batch 1340 in epoch 4, gen_loss = 1.460157887069793, disc_loss = 0.0006707742329623768
Trained batch 1341 in epoch 4, gen_loss = 1.4600091156412343, disc_loss = 0.0006708270064231107
Trained batch 1342 in epoch 4, gen_loss = 1.459849337189391, disc_loss = 0.0006707418118089063
Trained batch 1343 in epoch 4, gen_loss = 1.4599490508082367, disc_loss = 0.0006704334197571544
Trained batch 1344 in epoch 4, gen_loss = 1.4598296258529322, disc_loss = 0.0006700820498309985
Trained batch 1345 in epoch 4, gen_loss = 1.4597966121883308, disc_loss = 0.0006698072683743778
Trained batch 1346 in epoch 4, gen_loss = 1.4598140898862413, disc_loss = 0.0006697332860376743
Trained batch 1347 in epoch 4, gen_loss = 1.459715463375833, disc_loss = 0.0006695595691063029
Trained batch 1348 in epoch 4, gen_loss = 1.4594752740824637, disc_loss = 0.0006693347477415122
Trained batch 1349 in epoch 4, gen_loss = 1.459527573497207, disc_loss = 0.0006691771061580059
Trained batch 1350 in epoch 4, gen_loss = 1.4595492969699297, disc_loss = 0.0006689603286725951
Trained batch 1351 in epoch 4, gen_loss = 1.459591632764015, disc_loss = 0.0006686243040612626
Trained batch 1352 in epoch 4, gen_loss = 1.4594260475323628, disc_loss = 0.000668256873102848
Trained batch 1353 in epoch 4, gen_loss = 1.459238481046178, disc_loss = 0.0006679213125511204
Trained batch 1354 in epoch 4, gen_loss = 1.4593084198082504, disc_loss = 0.0006676558832858339
Trained batch 1355 in epoch 4, gen_loss = 1.4591711875611701, disc_loss = 0.000667793329098445
Trained batch 1356 in epoch 4, gen_loss = 1.4590798469703692, disc_loss = 0.000668427541840373
Trained batch 1357 in epoch 4, gen_loss = 1.459052840546761, disc_loss = 0.0006691827847950579
Trained batch 1358 in epoch 4, gen_loss = 1.4590274207814815, disc_loss = 0.0006694963925653528
Trained batch 1359 in epoch 4, gen_loss = 1.4590537249165423, disc_loss = 0.0006694496153292729
Trained batch 1360 in epoch 4, gen_loss = 1.4589514385506477, disc_loss = 0.0006693194369186475
Trained batch 1361 in epoch 4, gen_loss = 1.4590288244855212, disc_loss = 0.0006690480988572277
Trained batch 1362 in epoch 4, gen_loss = 1.4591360344050652, disc_loss = 0.0006687051894312594
Trained batch 1363 in epoch 4, gen_loss = 1.4592513083712446, disc_loss = 0.0006683252167691599
Trained batch 1364 in epoch 4, gen_loss = 1.459312396870428, disc_loss = 0.0006679332730624289
Trained batch 1365 in epoch 4, gen_loss = 1.45937493954012, disc_loss = 0.0006676381162780158
Trained batch 1366 in epoch 4, gen_loss = 1.4594706686727306, disc_loss = 0.0006673350463818126
Trained batch 1367 in epoch 4, gen_loss = 1.4592011864596641, disc_loss = 0.0006671102403408057
Trained batch 1368 in epoch 4, gen_loss = 1.4592907595930524, disc_loss = 0.0006668631782573872
Trained batch 1369 in epoch 4, gen_loss = 1.4592392026072871, disc_loss = 0.0006665950111378185
Trained batch 1370 in epoch 4, gen_loss = 1.4591109610056026, disc_loss = 0.0006662171113011081
Trained batch 1371 in epoch 4, gen_loss = 1.45911438515513, disc_loss = 0.0006659860907663587
Trained batch 1372 in epoch 4, gen_loss = 1.4591168571543016, disc_loss = 0.0006660927732026823
Trained batch 1373 in epoch 4, gen_loss = 1.4594146390669211, disc_loss = 0.0006661454027265211
Trained batch 1374 in epoch 4, gen_loss = 1.4594657080390236, disc_loss = 0.0006659922171013684
Trained batch 1375 in epoch 4, gen_loss = 1.4594909411010355, disc_loss = 0.0006658445888660935
Trained batch 1376 in epoch 4, gen_loss = 1.459601365922583, disc_loss = 0.0006655993746616336
Trained batch 1377 in epoch 4, gen_loss = 1.4594708786647448, disc_loss = 0.0006654203950726283
Trained batch 1378 in epoch 4, gen_loss = 1.4593712540101624, disc_loss = 0.0006655433052407285
Trained batch 1379 in epoch 4, gen_loss = 1.4592630614405093, disc_loss = 0.0006657679662738161
Trained batch 1380 in epoch 4, gen_loss = 1.4593990834876303, disc_loss = 0.0006658734596059334
Trained batch 1381 in epoch 4, gen_loss = 1.459365993004977, disc_loss = 0.0006657754477636512
Trained batch 1382 in epoch 4, gen_loss = 1.4594278491586339, disc_loss = 0.0006655187186622499
Trained batch 1383 in epoch 4, gen_loss = 1.4592235173620929, disc_loss = 0.0006653153337759045
Trained batch 1384 in epoch 4, gen_loss = 1.4592564926250746, disc_loss = 0.0006652682449801872
Trained batch 1385 in epoch 4, gen_loss = 1.4593511314963195, disc_loss = 0.0006652443849031519
Trained batch 1386 in epoch 4, gen_loss = 1.459306732647352, disc_loss = 0.0006651562398080761
Trained batch 1387 in epoch 4, gen_loss = 1.4591942122930752, disc_loss = 0.0006649339563176469
Trained batch 1388 in epoch 4, gen_loss = 1.4592532125456543, disc_loss = 0.0006648375543575385
Trained batch 1389 in epoch 4, gen_loss = 1.4591363884562212, disc_loss = 0.0006646559753829174
Trained batch 1390 in epoch 4, gen_loss = 1.459300129641568, disc_loss = 0.0006644852691476727
Trained batch 1391 in epoch 4, gen_loss = 1.4591677171745518, disc_loss = 0.0006643122002509929
Trained batch 1392 in epoch 4, gen_loss = 1.4593089311480607, disc_loss = 0.0006640771836151799
Trained batch 1393 in epoch 4, gen_loss = 1.4592706601281078, disc_loss = 0.0006637464585364379
Trained batch 1394 in epoch 4, gen_loss = 1.4592340975252103, disc_loss = 0.000663391560342999
Trained batch 1395 in epoch 4, gen_loss = 1.4591008275320332, disc_loss = 0.000663077224548304
Trained batch 1396 in epoch 4, gen_loss = 1.458882235507924, disc_loss = 0.0006627351457405847
Trained batch 1397 in epoch 4, gen_loss = 1.4590170493453358, disc_loss = 0.0006624250082718059
Trained batch 1398 in epoch 4, gen_loss = 1.4589673524417563, disc_loss = 0.0006621471697095035
Trained batch 1399 in epoch 4, gen_loss = 1.4590082653079715, disc_loss = 0.00066183783337952
Trained batch 1400 in epoch 4, gen_loss = 1.4590184785569251, disc_loss = 0.0006615909766465233
Trained batch 1401 in epoch 4, gen_loss = 1.4588782807729723, disc_loss = 0.0006612876912370273
Trained batch 1402 in epoch 4, gen_loss = 1.458723504375069, disc_loss = 0.0006609899066509338
Trained batch 1403 in epoch 4, gen_loss = 1.458912990286819, disc_loss = 0.0006607290801692584
Trained batch 1404 in epoch 4, gen_loss = 1.4587416292509574, disc_loss = 0.000660860884471281
Trained batch 1405 in epoch 4, gen_loss = 1.4588630050208795, disc_loss = 0.0006615939462241723
Trained batch 1406 in epoch 4, gen_loss = 1.458736307161788, disc_loss = 0.0006630170011009499
Trained batch 1407 in epoch 4, gen_loss = 1.4585506135428494, disc_loss = 0.0006641289634888959
Trained batch 1408 in epoch 4, gen_loss = 1.4585884351777725, disc_loss = 0.0006656715492615057
Trained batch 1409 in epoch 4, gen_loss = 1.4585701555225021, disc_loss = 0.0006670457422178063
Trained batch 1410 in epoch 4, gen_loss = 1.4584737316587137, disc_loss = 0.0006674849354548721
Trained batch 1411 in epoch 4, gen_loss = 1.458366842935173, disc_loss = 0.0006675657476456397
Trained batch 1412 in epoch 4, gen_loss = 1.4584972439973134, disc_loss = 0.000667527174865766
Trained batch 1413 in epoch 4, gen_loss = 1.4587300532778047, disc_loss = 0.0006675857706103705
Trained batch 1414 in epoch 4, gen_loss = 1.458853683623324, disc_loss = 0.000667859417526833
Trained batch 1415 in epoch 4, gen_loss = 1.4589665190311476, disc_loss = 0.0006682350440828461
Trained batch 1416 in epoch 4, gen_loss = 1.4589237123622638, disc_loss = 0.0006682206336553038
Trained batch 1417 in epoch 4, gen_loss = 1.4588937755195983, disc_loss = 0.0006678814079427527
Trained batch 1418 in epoch 4, gen_loss = 1.4587942279502486, disc_loss = 0.0006677362019091715
Trained batch 1419 in epoch 4, gen_loss = 1.4588154517428975, disc_loss = 0.000668322140449112
Trained batch 1420 in epoch 4, gen_loss = 1.4586935058435364, disc_loss = 0.0006696264652951416
Trained batch 1421 in epoch 4, gen_loss = 1.4587953262523592, disc_loss = 0.0006711222294784094
Trained batch 1422 in epoch 4, gen_loss = 1.4591219639660855, disc_loss = 0.0006723631523385201
Trained batch 1423 in epoch 4, gen_loss = 1.459236226389917, disc_loss = 0.0006728534173581986
Trained batch 1424 in epoch 4, gen_loss = 1.4591373507181804, disc_loss = 0.0006728047326466542
Trained batch 1425 in epoch 4, gen_loss = 1.4593326353257703, disc_loss = 0.000672645152719823
Trained batch 1426 in epoch 4, gen_loss = 1.4595310258631449, disc_loss = 0.0006727233181955811
Trained batch 1427 in epoch 4, gen_loss = 1.4594056604623127, disc_loss = 0.0006727732988638155
Trained batch 1428 in epoch 4, gen_loss = 1.4591846049791286, disc_loss = 0.0006727851596517124
Trained batch 1429 in epoch 4, gen_loss = 1.4591794084002088, disc_loss = 0.0006728141820715607
Trained batch 1430 in epoch 4, gen_loss = 1.4594762826782268, disc_loss = 0.0006728968572217349
Trained batch 1431 in epoch 4, gen_loss = 1.4595669490498537, disc_loss = 0.0006729178129966151
Trained batch 1432 in epoch 4, gen_loss = 1.4596819987433487, disc_loss = 0.000672726712168452
Trained batch 1433 in epoch 4, gen_loss = 1.459735313053743, disc_loss = 0.0006725748572741701
Trained batch 1434 in epoch 4, gen_loss = 1.459654875333301, disc_loss = 0.0006730866835212079
Trained batch 1435 in epoch 4, gen_loss = 1.4594983809671693, disc_loss = 0.0006750690687533638
Trained batch 1436 in epoch 4, gen_loss = 1.4593990460484079, disc_loss = 0.0006777896859822681
Trained batch 1437 in epoch 4, gen_loss = 1.4592278324513177, disc_loss = 0.0006796038294102467
Trained batch 1438 in epoch 4, gen_loss = 1.4592110042028579, disc_loss = 0.0006797537949609556
Trained batch 1439 in epoch 4, gen_loss = 1.4593495956725544, disc_loss = 0.0006797305043265725
Trained batch 1440 in epoch 4, gen_loss = 1.4591840577572275, disc_loss = 0.0006799130726693793
Trained batch 1441 in epoch 4, gen_loss = 1.4590060269452332, disc_loss = 0.000680594098037611
Trained batch 1442 in epoch 4, gen_loss = 1.4589355730465197, disc_loss = 0.0006811731225334232
Trained batch 1443 in epoch 4, gen_loss = 1.4591825573067916, disc_loss = 0.0006815739839754652
Trained batch 1444 in epoch 4, gen_loss = 1.4592378497536207, disc_loss = 0.0006819091841349279
Trained batch 1445 in epoch 4, gen_loss = 1.4592138988843102, disc_loss = 0.0006818592861377429
Trained batch 1446 in epoch 4, gen_loss = 1.4592609967374768, disc_loss = 0.0006820704827864162
Trained batch 1447 in epoch 4, gen_loss = 1.4591225477048706, disc_loss = 0.0006823563178700446
Trained batch 1448 in epoch 4, gen_loss = 1.4593112064773581, disc_loss = 0.0006824641185272354
Trained batch 1449 in epoch 4, gen_loss = 1.459176704225869, disc_loss = 0.0006825727434048092
Trained batch 1450 in epoch 4, gen_loss = 1.4593001001050439, disc_loss = 0.0006823938309290347
Trained batch 1451 in epoch 4, gen_loss = 1.4592194439786854, disc_loss = 0.0006821118784215242
Trained batch 1452 in epoch 4, gen_loss = 1.4597618695545918, disc_loss = 0.0006819162697206233
Trained batch 1453 in epoch 4, gen_loss = 1.4600201625443554, disc_loss = 0.0006819189585499293
Trained batch 1454 in epoch 4, gen_loss = 1.4598554192539752, disc_loss = 0.0006819953278210766
Trained batch 1455 in epoch 4, gen_loss = 1.459679694047996, disc_loss = 0.0006817896023976274
Trained batch 1456 in epoch 4, gen_loss = 1.4596979832436503, disc_loss = 0.0006814180780519755
Trained batch 1457 in epoch 4, gen_loss = 1.4596266766143924, disc_loss = 0.0006810666521860172
Trained batch 1458 in epoch 4, gen_loss = 1.4593565553896553, disc_loss = 0.000681048029325521
Trained batch 1459 in epoch 4, gen_loss = 1.4593180942208799, disc_loss = 0.0006818012955404375
Trained batch 1460 in epoch 4, gen_loss = 1.4595467028431823, disc_loss = 0.0006821609832245482
Trained batch 1461 in epoch 4, gen_loss = 1.4596075120441891, disc_loss = 0.0006819972614595675
Trained batch 1462 in epoch 4, gen_loss = 1.459546556313072, disc_loss = 0.0006818372909430753
Trained batch 1463 in epoch 4, gen_loss = 1.4595527569941484, disc_loss = 0.0006815690062492033
Trained batch 1464 in epoch 4, gen_loss = 1.4595225326844044, disc_loss = 0.0006814711541106286
Trained batch 1465 in epoch 4, gen_loss = 1.4595399764029748, disc_loss = 0.0006819630350792824
Trained batch 1466 in epoch 4, gen_loss = 1.459544625669088, disc_loss = 0.0006825691288068967
Trained batch 1467 in epoch 4, gen_loss = 1.4594931045410093, disc_loss = 0.0006827356763354491
Trained batch 1468 in epoch 4, gen_loss = 1.4595398603449719, disc_loss = 0.0006827446493254629
Trained batch 1469 in epoch 4, gen_loss = 1.459560819061435, disc_loss = 0.0006826791474225433
Trained batch 1470 in epoch 4, gen_loss = 1.4597639747414761, disc_loss = 0.0006828033069571981
Trained batch 1471 in epoch 4, gen_loss = 1.45996454147541, disc_loss = 0.0006827627917958955
Trained batch 1472 in epoch 4, gen_loss = 1.459960019515634, disc_loss = 0.0006825543170890395
Trained batch 1473 in epoch 4, gen_loss = 1.4599667506107967, disc_loss = 0.0006823699490271532
Trained batch 1474 in epoch 4, gen_loss = 1.4598336589942544, disc_loss = 0.0006823030948861881
Trained batch 1475 in epoch 4, gen_loss = 1.4596084850590403, disc_loss = 0.0006821185639849375
Trained batch 1476 in epoch 4, gen_loss = 1.459586296601318, disc_loss = 0.0006818065863631469
Trained batch 1477 in epoch 4, gen_loss = 1.459624000911945, disc_loss = 0.000681526653829709
Trained batch 1478 in epoch 4, gen_loss = 1.4595929676814206, disc_loss = 0.0006812983091407489
Trained batch 1479 in epoch 4, gen_loss = 1.4598078460306734, disc_loss = 0.0006811260796009289
Trained batch 1480 in epoch 4, gen_loss = 1.4596989851880122, disc_loss = 0.0006813829638453242
Trained batch 1481 in epoch 4, gen_loss = 1.4599383272301008, disc_loss = 0.0006822473258435599
Trained batch 1482 in epoch 4, gen_loss = 1.4598456429856417, disc_loss = 0.0006834559333942839
Trained batch 1483 in epoch 4, gen_loss = 1.4597438537688912, disc_loss = 0.0006839583778625302
Trained batch 1484 in epoch 4, gen_loss = 1.459675961793071, disc_loss = 0.0006841968966505697
Trained batch 1485 in epoch 4, gen_loss = 1.459622170771115, disc_loss = 0.0006841633651920824
Trained batch 1486 in epoch 4, gen_loss = 1.459598618381041, disc_loss = 0.0006840347370216808
Trained batch 1487 in epoch 4, gen_loss = 1.4596164156031866, disc_loss = 0.0006838046395054706
Trained batch 1488 in epoch 4, gen_loss = 1.4595769484464236, disc_loss = 0.0006836605087269233
Trained batch 1489 in epoch 4, gen_loss = 1.4594634596133391, disc_loss = 0.0006836479050062375
Trained batch 1490 in epoch 4, gen_loss = 1.4595505590010296, disc_loss = 0.0006835322291451684
Trained batch 1491 in epoch 4, gen_loss = 1.4593318453103543, disc_loss = 0.0006834201589050774
Trained batch 1492 in epoch 4, gen_loss = 1.459312767608806, disc_loss = 0.0006833325215627885
Trained batch 1493 in epoch 4, gen_loss = 1.4592745637638342, disc_loss = 0.000683236888272152
Trained batch 1494 in epoch 4, gen_loss = 1.459419598866466, disc_loss = 0.0006832836306060938
Trained batch 1495 in epoch 4, gen_loss = 1.4593361846425317, disc_loss = 0.0006833657386053535
Trained batch 1496 in epoch 4, gen_loss = 1.4594001343987668, disc_loss = 0.0006832491334964542
Trained batch 1497 in epoch 4, gen_loss = 1.4594832237794975, disc_loss = 0.0006829381346665195
Trained batch 1498 in epoch 4, gen_loss = 1.4593978507905263, disc_loss = 0.0006830513950549063
Trained batch 1499 in epoch 4, gen_loss = 1.4593759666283925, disc_loss = 0.0006832293136928153
Trained batch 1500 in epoch 4, gen_loss = 1.459356340466143, disc_loss = 0.0006832993050804439
Trained batch 1501 in epoch 4, gen_loss = 1.4593163196954841, disc_loss = 0.0006833974345285769
Trained batch 1502 in epoch 4, gen_loss = 1.4592428251020289, disc_loss = 0.0006835804271949124
Trained batch 1503 in epoch 4, gen_loss = 1.459316988336913, disc_loss = 0.0006835601694847161
Trained batch 1504 in epoch 4, gen_loss = 1.4592497137297824, disc_loss = 0.0006833832083992038
Trained batch 1505 in epoch 4, gen_loss = 1.4593675560052017, disc_loss = 0.0006832794031091724
Trained batch 1506 in epoch 4, gen_loss = 1.4595379490842864, disc_loss = 0.0006832391467850699
Trained batch 1507 in epoch 4, gen_loss = 1.4594447639639878, disc_loss = 0.0006831956799763897
Trained batch 1508 in epoch 4, gen_loss = 1.4594331280611619, disc_loss = 0.0006830496066783381
Trained batch 1509 in epoch 4, gen_loss = 1.4593500663113121, disc_loss = 0.0006829339926605597
Trained batch 1510 in epoch 4, gen_loss = 1.4592378986031704, disc_loss = 0.0006826965459430986
Trained batch 1511 in epoch 4, gen_loss = 1.4591458113420577, disc_loss = 0.0006823375899676605
Trained batch 1512 in epoch 4, gen_loss = 1.4591736051316144, disc_loss = 0.0006820333764077132
Trained batch 1513 in epoch 4, gen_loss = 1.4591590266876524, disc_loss = 0.0006816676939411111
Trained batch 1514 in epoch 4, gen_loss = 1.4592087397874385, disc_loss = 0.0006813391382034127
Trained batch 1515 in epoch 4, gen_loss = 1.4591492309104799, disc_loss = 0.0006809872865518613
Trained batch 1516 in epoch 4, gen_loss = 1.459246919747631, disc_loss = 0.0006806196253151625
Trained batch 1517 in epoch 4, gen_loss = 1.4590617009930618, disc_loss = 0.0006802711616588431
Trained batch 1518 in epoch 4, gen_loss = 1.4591095998461423, disc_loss = 0.0006798973046755525
Trained batch 1519 in epoch 4, gen_loss = 1.4590409687475154, disc_loss = 0.0006796010538461192
Trained batch 1520 in epoch 4, gen_loss = 1.4590932088490773, disc_loss = 0.0006793538837125791
Trained batch 1521 in epoch 4, gen_loss = 1.4592352772667594, disc_loss = 0.000679064703918894
Trained batch 1522 in epoch 4, gen_loss = 1.4591806785730022, disc_loss = 0.0006787429892490355
Trained batch 1523 in epoch 4, gen_loss = 1.4591680605580488, disc_loss = 0.0006783660282771985
Trained batch 1524 in epoch 4, gen_loss = 1.4590441825741627, disc_loss = 0.0006780163138975069
Trained batch 1525 in epoch 4, gen_loss = 1.459131459499249, disc_loss = 0.0006777163922655802
Trained batch 1526 in epoch 4, gen_loss = 1.459100356895157, disc_loss = 0.0006775081766406092
Trained batch 1527 in epoch 4, gen_loss = 1.459401852173331, disc_loss = 0.0006772381869063674
Trained batch 1528 in epoch 4, gen_loss = 1.4592364908746054, disc_loss = 0.0006769234141251291
Trained batch 1529 in epoch 4, gen_loss = 1.4591725177235073, disc_loss = 0.0006766473970986946
Trained batch 1530 in epoch 4, gen_loss = 1.459093827114317, disc_loss = 0.0006764498744098346
Trained batch 1531 in epoch 4, gen_loss = 1.459485302161299, disc_loss = 0.0006763675648884881
Trained batch 1532 in epoch 4, gen_loss = 1.4594774781996644, disc_loss = 0.0006762400307535088
Trained batch 1533 in epoch 4, gen_loss = 1.4593410911584925, disc_loss = 0.0006760073816667085
Trained batch 1534 in epoch 4, gen_loss = 1.459415774857959, disc_loss = 0.0006758860497737716
Trained batch 1535 in epoch 4, gen_loss = 1.4597441758960485, disc_loss = 0.0006757553715696455
Trained batch 1536 in epoch 4, gen_loss = 1.4596809186792714, disc_loss = 0.0006753641191998583
Trained batch 1537 in epoch 4, gen_loss = 1.4597040992254398, disc_loss = 0.0006751419252220823
Trained batch 1538 in epoch 4, gen_loss = 1.4596576536530563, disc_loss = 0.000675017398159453
Trained batch 1539 in epoch 4, gen_loss = 1.4598049935582396, disc_loss = 0.000674695237991385
Trained batch 1540 in epoch 4, gen_loss = 1.4597769804700174, disc_loss = 0.000674440473997479
Trained batch 1541 in epoch 4, gen_loss = 1.4597436849090686, disc_loss = 0.0006741850239732218
Trained batch 1542 in epoch 4, gen_loss = 1.4597555312411938, disc_loss = 0.0006739059239536148
Trained batch 1543 in epoch 4, gen_loss = 1.459815976996496, disc_loss = 0.0006736080976191925
Trained batch 1544 in epoch 4, gen_loss = 1.4598954318024966, disc_loss = 0.0006732986407530792
Trained batch 1545 in epoch 4, gen_loss = 1.4598835049748884, disc_loss = 0.0006729542238841569
Trained batch 1546 in epoch 4, gen_loss = 1.4600450570304393, disc_loss = 0.0006726282449060197
Trained batch 1547 in epoch 4, gen_loss = 1.4601381920104803, disc_loss = 0.0006725206689793888
Trained batch 1548 in epoch 4, gen_loss = 1.460145901140665, disc_loss = 0.0006725242182143751
Trained batch 1549 in epoch 4, gen_loss = 1.460073127746582, disc_loss = 0.0006725438519178199
Trained batch 1550 in epoch 4, gen_loss = 1.4600306542591461, disc_loss = 0.0006723901556814083
Trained batch 1551 in epoch 4, gen_loss = 1.460043277015391, disc_loss = 0.0006722697828231456
Trained batch 1552 in epoch 4, gen_loss = 1.4602529297931226, disc_loss = 0.00067213079505672
Trained batch 1553 in epoch 4, gen_loss = 1.4604176146336658, disc_loss = 0.0006718848219497652
Trained batch 1554 in epoch 4, gen_loss = 1.4604122135033561, disc_loss = 0.0006715486000570502
Trained batch 1555 in epoch 4, gen_loss = 1.4604148050353583, disc_loss = 0.0006711718305570339
Trained batch 1556 in epoch 4, gen_loss = 1.4605401083683462, disc_loss = 0.000670897141287207
Trained batch 1557 in epoch 4, gen_loss = 1.4604521868929783, disc_loss = 0.0006707037570143214
Trained batch 1558 in epoch 4, gen_loss = 1.4604074101634634, disc_loss = 0.0006704728559674435
Trained batch 1559 in epoch 4, gen_loss = 1.4606323472964458, disc_loss = 0.0006702022885525739
Trained batch 1560 in epoch 4, gen_loss = 1.4605517543179343, disc_loss = 0.0006698917125485296
Trained batch 1561 in epoch 4, gen_loss = 1.460665674887302, disc_loss = 0.0006695351033329844
Trained batch 1562 in epoch 4, gen_loss = 1.4607210725984432, disc_loss = 0.0006691883821950189
Trained batch 1563 in epoch 4, gen_loss = 1.460635321524442, disc_loss = 0.0006688635164053853
Trained batch 1564 in epoch 4, gen_loss = 1.4604360525600446, disc_loss = 0.0006686451687682465
Trained batch 1565 in epoch 4, gen_loss = 1.4602310576049151, disc_loss = 0.0006685081770185885
Trained batch 1566 in epoch 4, gen_loss = 1.4600035195603216, disc_loss = 0.0006682739488327839
Trained batch 1567 in epoch 4, gen_loss = 1.4598728730058184, disc_loss = 0.0006679617615089005
Trained batch 1568 in epoch 4, gen_loss = 1.459700651955954, disc_loss = 0.0006676191834857467
Trained batch 1569 in epoch 4, gen_loss = 1.4596423982055324, disc_loss = 0.000667524006721752
Trained batch 1570 in epoch 4, gen_loss = 1.4595416751657604, disc_loss = 0.0006677169122782899
Trained batch 1571 in epoch 4, gen_loss = 1.4596164620862966, disc_loss = 0.0006683288396715821
Trained batch 1572 in epoch 4, gen_loss = 1.4596727890189256, disc_loss = 0.0006694173289239641
Trained batch 1573 in epoch 4, gen_loss = 1.4597508929281708, disc_loss = 0.0006698404945457325
Trained batch 1574 in epoch 4, gen_loss = 1.4595104445351494, disc_loss = 0.000669763813470675
Trained batch 1575 in epoch 4, gen_loss = 1.459616959397563, disc_loss = 0.0006695527628262934
Trained batch 1576 in epoch 4, gen_loss = 1.4594778079508828, disc_loss = 0.000669530209816764
Trained batch 1577 in epoch 4, gen_loss = 1.4593304617021172, disc_loss = 0.0006694593734018424
Trained batch 1578 in epoch 4, gen_loss = 1.4594842315550618, disc_loss = 0.0006692992566986746
Trained batch 1579 in epoch 4, gen_loss = 1.459627686874776, disc_loss = 0.0006692960849088909
Trained batch 1580 in epoch 4, gen_loss = 1.4594723295366214, disc_loss = 0.0006691879314600707
Testing Epoch 4

wandb: WARNING Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 0.49984443187713623, disc_loss = 0.6236605644226074
Trained batch 1 in epoch 0, gen_loss = 0.5541642010211945, disc_loss = 0.8091251254081726
Trained batch 2 in epoch 0, gen_loss = 0.5532798965771993, disc_loss = 0.6805163025856018
Trained batch 3 in epoch 0, gen_loss = 0.5375786572694778, disc_loss = 0.596401609480381
Trained batch 4 in epoch 0, gen_loss = 0.5085874438285828, disc_loss = 0.5282491981983185
Trained batch 5 in epoch 0, gen_loss = 0.5104771653811137, disc_loss = 0.47242021063963574
Trained batch 6 in epoch 0, gen_loss = 0.5036351042134422, disc_loss = 0.4316444673708507
Trained batch 7 in epoch 0, gen_loss = 0.4949917159974575, disc_loss = 0.3978064116090536
Trained batch 8 in epoch 0, gen_loss = 0.48473761479059857, disc_loss = 0.36924998462200165
Trained batch 9 in epoch 0, gen_loss = 0.4867550253868103, disc_loss = 0.3513982191681862
Trained batch 10 in epoch 0, gen_loss = 0.48548150062561035, disc_loss = 0.3351107036525553
Trained batch 11 in epoch 0, gen_loss = 0.48348577320575714, disc_loss = 0.31821345786253613
Trained batch 12 in epoch 0, gen_loss = 0.48084190029364365, disc_loss = 0.30346211791038513
Trained batch 13 in epoch 0, gen_loss = 0.4779537149838039, disc_loss = 0.29021089311156956
Trained batch 14 in epoch 0, gen_loss = 0.4825169603029887, disc_loss = 0.27760967016220095
Trained batch 15 in epoch 0, gen_loss = 0.4805071260780096, disc_loss = 0.265329129062593
Trained batch 16 in epoch 0, gen_loss = 0.4783388323643628, disc_loss = 0.2567771120983012
Trained batch 17 in epoch 0, gen_loss = 0.47813166346814895, disc_loss = 0.24910792542828453
Trained batch 18 in epoch 0, gen_loss = 0.4750634667120482, disc_loss = 0.24056200369408257
Trained batch 19 in epoch 0, gen_loss = 0.4715714380145073, disc_loss = 0.23851918280124665
Trained batch 20 in epoch 0, gen_loss = 0.47333429966654095, disc_loss = 0.23368989711716062
Trained batch 21 in epoch 0, gen_loss = 0.47318408435041254, disc_loss = 0.22841227122328497
Trained batch 22 in epoch 0, gen_loss = 0.4715406052444292, disc_loss = 0.22343179292005041
Trained batch 23 in epoch 0, gen_loss = 0.46774886796871823, disc_loss = 0.216754672738413
Trained batch 24 in epoch 0, gen_loss = 0.4712423324584961, disc_loss = 0.21172457545995713
Trained batch 25 in epoch 0, gen_loss = 0.46855142827217394, disc_loss = 0.2101349592781984
Trained batch 26 in epoch 0, gen_loss = 0.469773437137957, disc_loss = 0.20925731708606085
Trained batch 27 in epoch 0, gen_loss = 0.46880970363106045, disc_loss = 0.20590925083628722
Trained batch 28 in epoch 0, gen_loss = 0.46777514959203786, disc_loss = 0.20144683251093173
Trained batch 29 in epoch 0, gen_loss = 0.4663593530654907, disc_loss = 0.19694631323218345
Trained batch 30 in epoch 0, gen_loss = 0.4665567663408095, disc_loss = 0.19229919078849977
Trained batch 31 in epoch 0, gen_loss = 0.4646225105971098, disc_loss = 0.1894947283435613
Trained batch 32 in epoch 0, gen_loss = 0.46397858677488385, disc_loss = 0.1884781720511841
Trained batch 33 in epoch 0, gen_loss = 0.4634741623612011, disc_loss = 0.18533632378367818
Trained batch 34 in epoch 0, gen_loss = 0.46575072918619426, disc_loss = 0.18149614397968564
Trained batch 35 in epoch 0, gen_loss = 0.46793113234970307, disc_loss = 0.1779891550540924
Trained batch 36 in epoch 0, gen_loss = 0.46763207300289256, disc_loss = 0.1743188640354453
Trained batch 37 in epoch 0, gen_loss = 0.4673096702287072, disc_loss = 0.17073741672854675
Trained batch 38 in epoch 0, gen_loss = 0.4684287531253619, disc_loss = 0.16732820429098913
Trained batch 39 in epoch 0, gen_loss = 0.46944965198636057, disc_loss = 0.16474462989717722
Trained batch 40 in epoch 0, gen_loss = 0.46825909251120035, disc_loss = 0.1638502538567636
Trained batch 41 in epoch 0, gen_loss = 0.4693718290045148, disc_loss = 0.16281346054304213
Trained batch 42 in epoch 0, gen_loss = 0.4703886335672334, disc_loss = 0.16029858745114747
Trained batch 43 in epoch 0, gen_loss = 0.47200479629364883, disc_loss = 0.15780067850242963
Trained batch 44 in epoch 0, gen_loss = 0.47131795552041794, disc_loss = 0.15557869126399357
Trained batch 45 in epoch 0, gen_loss = 0.47169746717681055, disc_loss = 0.1534516663978929
Trained batch 46 in epoch 0, gen_loss = 0.4731464595236677, disc_loss = 0.15107380448186652
Trained batch 47 in epoch 0, gen_loss = 0.4737499101708333, disc_loss = 0.14885189345416924
Trained batch 48 in epoch 0, gen_loss = 0.47368026327113716, disc_loss = 0.14677680352208566
Trained batch 49 in epoch 0, gen_loss = 0.47424151122570035, disc_loss = 0.1447095337510109
Trained batch 50 in epoch 0, gen_loss = 0.47397954031532885, disc_loss = 0.14244137189405806
Trained batch 51 in epoch 0, gen_loss = 0.4750480233476712, disc_loss = 0.1403550050364664
Trained batch 52 in epoch 0, gen_loss = 0.47422380829757116, disc_loss = 0.13869679666493298
Trained batch 53 in epoch 0, gen_loss = 0.4747127095858256, disc_loss = 0.13703628950234917
Trained batch 54 in epoch 0, gen_loss = 0.4756050066514449, disc_loss = 0.13525642234493385
Trained batch 55 in epoch 0, gen_loss = 0.4760752192565373, disc_loss = 0.13343571010045707
Trained batch 56 in epoch 0, gen_loss = 0.47719951575262504, disc_loss = 0.13172261407108685
Trained batch 57 in epoch 0, gen_loss = 0.4774168159427314, disc_loss = 0.13003816523043246
Trained batch 58 in epoch 0, gen_loss = 0.47676453297421084, disc_loss = 0.12836889477478244
Trained batch 59 in epoch 0, gen_loss = 0.4759221171339353, disc_loss = 0.12687875364596646
Trained batch 60 in epoch 0, gen_loss = 0.47532005974503816, disc_loss = 0.12521430159934233
Trained batch 61 in epoch 0, gen_loss = 0.47557199674267925, disc_loss = 0.12359203296082635
Trained batch 62 in epoch 0, gen_loss = 0.4760043838667491, disc_loss = 0.12198378252131599
Trained batch 63 in epoch 0, gen_loss = 0.47614418156445026, disc_loss = 0.12045123041025363
Trained batch 64 in epoch 0, gen_loss = 0.4760247991635249, disc_loss = 0.11901334825043496
Trained batch 65 in epoch 0, gen_loss = 0.4756370231960759, disc_loss = 0.11758954109003146
Trained batch 66 in epoch 0, gen_loss = 0.47614800663136725, disc_loss = 0.1162203950390442
Trained batch 67 in epoch 0, gen_loss = 0.4755143181366079, disc_loss = 0.1151080999578185
Trained batch 68 in epoch 0, gen_loss = 0.4752593485341556, disc_loss = 0.11581070831828359
Trained batch 69 in epoch 0, gen_loss = 0.47586343501295364, disc_loss = 0.11785722547875983
Trained batch 70 in epoch 0, gen_loss = 0.4750162572927878, disc_loss = 0.11685022074256984
Trained batch 71 in epoch 0, gen_loss = 0.4752025314503246, disc_loss = 0.11597335848232938
Trained batch 72 in epoch 0, gen_loss = 0.47453432866971784, disc_loss = 0.11485096794387249
Trained batch 73 in epoch 0, gen_loss = 0.4745745683038557, disc_loss = 0.11382003428062072
Trained batch 74 in epoch 0, gen_loss = 0.47504727125167845, disc_loss = 0.11274091012775898
Trained batch 75 in epoch 0, gen_loss = 0.4752109250740001, disc_loss = 0.1116446626960839
Trained batch 76 in epoch 0, gen_loss = 0.47578351180274764, disc_loss = 0.1105606554487309
Trained batch 77 in epoch 0, gen_loss = 0.47604659008674133, disc_loss = 0.10957348036269347
Trained batch 78 in epoch 0, gen_loss = 0.4773530035833769, disc_loss = 0.10875745688246775
Trained batch 79 in epoch 0, gen_loss = 0.47684663273394107, disc_loss = 0.10795656410045922
Trained batch 80 in epoch 0, gen_loss = 0.4766636814600156, disc_loss = 0.10745015239090096
Trained batch 81 in epoch 0, gen_loss = 0.476735598066958, disc_loss = 0.10660552274344898
Trained batch 82 in epoch 0, gen_loss = 0.4761042465646583, disc_loss = 0.10588725804384932
Trained batch 83 in epoch 0, gen_loss = 0.4753384714325269, disc_loss = 0.10605098267218896
Trained batch 84 in epoch 0, gen_loss = 0.4767417048706728, disc_loss = 0.10550627029117415
Trained batch 85 in epoch 0, gen_loss = 0.4768190491338109, disc_loss = 0.10488081528523634
Trained batch 86 in epoch 0, gen_loss = 0.47636577863802854, disc_loss = 0.10472535329132245
Trained batch 87 in epoch 0, gen_loss = 0.4762179340151223, disc_loss = 0.10391352435743267
Trained batch 88 in epoch 0, gen_loss = 0.4764933060394244, disc_loss = 0.10318059135186539
Trained batch 89 in epoch 0, gen_loss = 0.4773558778895272, disc_loss = 0.10242415960464213
Trained batch 90 in epoch 0, gen_loss = 0.4778500444941468, disc_loss = 0.10221720933095439
Trained batch 91 in epoch 0, gen_loss = 0.47904365833686746, disc_loss = 0.10277909651884566
Trained batch 92 in epoch 0, gen_loss = 0.4788736153033472, disc_loss = 0.10498724537350798
Trained batch 93 in epoch 0, gen_loss = 0.48060327102529243, disc_loss = 0.11199347987929557
Trained batch 94 in epoch 0, gen_loss = 0.4808180034160614, disc_loss = 0.11401672108392967
Trained batch 95 in epoch 0, gen_loss = 0.4810219161833326, disc_loss = 0.1192474178581809
Trained batch 96 in epoch 0, gen_loss = 0.4808306878375024, disc_loss = 0.1232112332333609
Trained batch 97 in epoch 0, gen_loss = 0.4808928768853752, disc_loss = 0.12442215163336724
Trained batch 98 in epoch 0, gen_loss = 0.48082813831290816, disc_loss = 0.12482242854406135
Trained batch 99 in epoch 0, gen_loss = 0.48065088599920275, disc_loss = 0.1244553430750966
Trained batch 100 in epoch 0, gen_loss = 0.4809195880252536, disc_loss = 0.12411807171336495
Trained batch 101 in epoch 0, gen_loss = 0.48031725223157923, disc_loss = 0.12456528510094858
Trained batch 102 in epoch 0, gen_loss = 0.4798978905654648, disc_loss = 0.12659301619651248
Trained batch 103 in epoch 0, gen_loss = 0.4792083083437039, disc_loss = 0.12884847780403036
Trained batch 104 in epoch 0, gen_loss = 0.4783804215136028, disc_loss = 0.1291635979144346
Trained batch 105 in epoch 0, gen_loss = 0.4776193294322716, disc_loss = 0.12945012273794076
Trained batch 106 in epoch 0, gen_loss = 0.47672612115601515, disc_loss = 0.1293544492501522
Trained batch 107 in epoch 0, gen_loss = 0.47685682166505744, disc_loss = 0.12899262709888043
Trained batch 108 in epoch 0, gen_loss = 0.4761053865109015, disc_loss = 0.1295687145117773
Trained batch 109 in epoch 0, gen_loss = 0.4745302444154566, disc_loss = 0.12982477847148072
Trained batch 110 in epoch 0, gen_loss = 0.47452458148604043, disc_loss = 0.12985488064251505
Trained batch 111 in epoch 0, gen_loss = 0.4740831631102732, disc_loss = 0.13060137459875218
Trained batch 112 in epoch 0, gen_loss = 0.4736008003222204, disc_loss = 0.13123183615044154
Trained batch 113 in epoch 0, gen_loss = 0.47331367485355913, disc_loss = 0.1323662213654372
Trained batch 114 in epoch 0, gen_loss = 0.4726130757642829, disc_loss = 0.13269711204844972
Trained batch 115 in epoch 0, gen_loss = 0.4721288804350228, disc_loss = 0.1332332506326252
Trained batch 116 in epoch 0, gen_loss = 0.47186645483359313, disc_loss = 0.13300627473200488
Trained batch 117 in epoch 0, gen_loss = 0.471371362522497, disc_loss = 0.13358196493048788
Trained batch 118 in epoch 0, gen_loss = 0.4703082279497836, disc_loss = 0.13502132995915012
Trained batch 119 in epoch 0, gen_loss = 0.4701723732054234, disc_loss = 0.13511316667621334
Trained batch 120 in epoch 0, gen_loss = 0.4704580501583982, disc_loss = 0.13459998433870718
Trained batch 121 in epoch 0, gen_loss = 0.4697476447117133, disc_loss = 0.13469591446709436
Trained batch 122 in epoch 0, gen_loss = 0.4690039480120186, disc_loss = 0.13477656684391867
Trained batch 123 in epoch 0, gen_loss = 0.46872210094044287, disc_loss = 0.1340233828091333
Trained batch 124 in epoch 0, gen_loss = 0.46845794463157653, disc_loss = 0.13390172454714774
Trained batch 125 in epoch 0, gen_loss = 0.4679175674442261, disc_loss = 0.13441560296193947
Trained batch 126 in epoch 0, gen_loss = 0.4674095128934214, disc_loss = 0.13665602112731595
Trained batch 127 in epoch 0, gen_loss = 0.46728707291185856, disc_loss = 0.13605196590651758
Trained batch 128 in epoch 0, gen_loss = 0.46711391649504963, disc_loss = 0.13596800908215287
Trained batch 129 in epoch 0, gen_loss = 0.46709844607573286, disc_loss = 0.13554829098284243
Trained batch 130 in epoch 0, gen_loss = 0.46702671233024307, disc_loss = 0.1351679492713386
Trained batch 131 in epoch 0, gen_loss = 0.4665264997518424, disc_loss = 0.1347108291687839
Trained batch 132 in epoch 0, gen_loss = 0.4666142819967485, disc_loss = 0.13434687405264467
Trained batch 133 in epoch 0, gen_loss = 0.4666523900049836, disc_loss = 0.1340449446562066
Trained batch 134 in epoch 0, gen_loss = 0.46639493416856836, disc_loss = 0.1336867996112064
Trained batch 135 in epoch 0, gen_loss = 0.46659062342608676, disc_loss = 0.13412872123915484
Trained batch 136 in epoch 0, gen_loss = 0.4663586562132313, disc_loss = 0.1357102127895303
Trained batch 137 in epoch 0, gen_loss = 0.46674027542273205, disc_loss = 0.136073748189686
Trained batch 138 in epoch 0, gen_loss = 0.4669082685769033, disc_loss = 0.13556900548098758
Trained batch 139 in epoch 0, gen_loss = 0.4661225344453539, disc_loss = 0.13565529842994042
Trained batch 140 in epoch 0, gen_loss = 0.46520785617490185, disc_loss = 0.1363215334713459
Trained batch 141 in epoch 0, gen_loss = 0.4652230915888934, disc_loss = 0.13591666721647055
Trained batch 142 in epoch 0, gen_loss = 0.4653667674198017, disc_loss = 0.13539066829985671
Trained batch 143 in epoch 0, gen_loss = 0.465519392862916, disc_loss = 0.13534337947041625
Trained batch 144 in epoch 0, gen_loss = 0.46443265183218596, disc_loss = 0.13530094225344988
Trained batch 145 in epoch 0, gen_loss = 0.4641645711986986, disc_loss = 0.13625006227154438
Trained batch 146 in epoch 0, gen_loss = 0.46437262454811407, disc_loss = 0.13843842968344688
Trained batch 147 in epoch 0, gen_loss = 0.46448535311060984, disc_loss = 0.1385236546850285
Trained batch 148 in epoch 0, gen_loss = 0.46440751960613585, disc_loss = 0.13904784162272543
Trained batch 149 in epoch 0, gen_loss = 0.4636013948917389, disc_loss = 0.13983279856542746
Trained batch 150 in epoch 0, gen_loss = 0.4635603820646046, disc_loss = 0.13940740324902218
Trained batch 151 in epoch 0, gen_loss = 0.46259830009780434, disc_loss = 0.13929825484458552
Trained batch 152 in epoch 0, gen_loss = 0.4621088469729704, disc_loss = 0.13901702273223135
Trained batch 153 in epoch 0, gen_loss = 0.46139850999627796, disc_loss = 0.13859685657957158
Trained batch 154 in epoch 0, gen_loss = 0.46060437290899214, disc_loss = 0.1383905515795754
Trained batch 155 in epoch 0, gen_loss = 0.4596722166125591, disc_loss = 0.13818522349286538
Trained batch 156 in epoch 0, gen_loss = 0.4597267066217532, disc_loss = 0.13757014635262216
Trained batch 157 in epoch 0, gen_loss = 0.4595253031842316, disc_loss = 0.13707756222803383
Trained batch 158 in epoch 0, gen_loss = 0.4591424789443706, disc_loss = 0.13663847008778615
Trained batch 159 in epoch 0, gen_loss = 0.4583212690427899, disc_loss = 0.13717189976014196
Trained batch 160 in epoch 0, gen_loss = 0.4582409188614128, disc_loss = 0.1380253636411258
Trained batch 161 in epoch 0, gen_loss = 0.45763982942810766, disc_loss = 0.13818615017297828
Trained batch 162 in epoch 0, gen_loss = 0.4567418721921605, disc_loss = 0.13823348434607677
Trained batch 163 in epoch 0, gen_loss = 0.4571804725905744, disc_loss = 0.13858420379096414
Trained batch 164 in epoch 0, gen_loss = 0.45718614982836175, disc_loss = 0.13847871684666835
Trained batch 165 in epoch 0, gen_loss = 0.45708970510097874, disc_loss = 0.1382535681667098
Trained batch 166 in epoch 0, gen_loss = 0.45761350368311304, disc_loss = 0.1379140150582719
Trained batch 167 in epoch 0, gen_loss = 0.45750293880701065, disc_loss = 0.13747133199302924
Trained batch 168 in epoch 0, gen_loss = 0.45726014717796143, disc_loss = 0.1369540919963072
Trained batch 169 in epoch 0, gen_loss = 0.4574008484097088, disc_loss = 0.13652599052909542
Trained batch 170 in epoch 0, gen_loss = 0.45774739126712954, disc_loss = 0.13605268892140415
Trained batch 171 in epoch 0, gen_loss = 0.45815671373938405, disc_loss = 0.13566849792246208
Trained batch 172 in epoch 0, gen_loss = 0.45801252298961487, disc_loss = 0.13545173591788792
Trained batch 173 in epoch 0, gen_loss = 0.4581763317872738, disc_loss = 0.13553751743901735
Trained batch 174 in epoch 0, gen_loss = 0.4578257131576538, disc_loss = 0.1376831847855023
Trained batch 175 in epoch 0, gen_loss = 0.4580486606467854, disc_loss = 0.13770955585112626
Trained batch 176 in epoch 0, gen_loss = 0.45829085172232936, disc_loss = 0.13800918891773387
Trained batch 177 in epoch 0, gen_loss = 0.4581308699725719, disc_loss = 0.13804131901163733
Trained batch 178 in epoch 0, gen_loss = 0.45823008404763715, disc_loss = 0.13781546156166652
Trained batch 179 in epoch 0, gen_loss = 0.4583901979857021, disc_loss = 0.1374718645794524
Trained batch 180 in epoch 0, gen_loss = 0.4587336477324449, disc_loss = 0.13727999141038452
Trained batch 181 in epoch 0, gen_loss = 0.4590760854246852, disc_loss = 0.13723213147822316
Trained batch 182 in epoch 0, gen_loss = 0.45847579038859715, disc_loss = 0.137388426627292
Trained batch 183 in epoch 0, gen_loss = 0.45838491602436354, disc_loss = 0.1375705325652076
Trained batch 184 in epoch 0, gen_loss = 0.4583820768304773, disc_loss = 0.13957715594285244
Trained batch 185 in epoch 0, gen_loss = 0.45785870379017246, disc_loss = 0.14067990432984084
Trained batch 186 in epoch 0, gen_loss = 0.45770080746176406, disc_loss = 0.14131263404447128
Trained batch 187 in epoch 0, gen_loss = 0.45702055271001574, disc_loss = 0.14210079812464563
Trained batch 188 in epoch 0, gen_loss = 0.45669590733038684, disc_loss = 0.14228092382351556
Trained batch 189 in epoch 0, gen_loss = 0.4568990552111676, disc_loss = 0.14231665867723917
Trained batch 190 in epoch 0, gen_loss = 0.45669575901555765, disc_loss = 0.14210242075913865
Trained batch 191 in epoch 0, gen_loss = 0.45636331600447494, disc_loss = 0.1418845858036851
Trained batch 192 in epoch 0, gen_loss = 0.4559631969953448, disc_loss = 0.14170150389325434
Trained batch 193 in epoch 0, gen_loss = 0.45566495868963064, disc_loss = 0.14151063968533092
Trained batch 194 in epoch 0, gen_loss = 0.4551194388132829, disc_loss = 0.14124563130048606
Trained batch 195 in epoch 0, gen_loss = 0.45517780403701624, disc_loss = 0.14101100777636985
Trained batch 196 in epoch 0, gen_loss = 0.45501856846252675, disc_loss = 0.14214023679192297
Trained batch 197 in epoch 0, gen_loss = 0.4548534449904856, disc_loss = 0.14289175971138357
Trained batch 198 in epoch 0, gen_loss = 0.4550216344732735, disc_loss = 0.14345244056166118
Trained batch 199 in epoch 0, gen_loss = 0.45457602217793464, disc_loss = 0.14381637562066316
Trained batch 200 in epoch 0, gen_loss = 0.45413434890965326, disc_loss = 0.14394190977906707
Trained batch 201 in epoch 0, gen_loss = 0.4540753998968861, disc_loss = 0.1439559054330434
Trained batch 202 in epoch 0, gen_loss = 0.45397827454975676, disc_loss = 0.14383065759254793
Trained batch 203 in epoch 0, gen_loss = 0.453373471603674, disc_loss = 0.1438359247118819
Trained batch 204 in epoch 0, gen_loss = 0.4526982396114163, disc_loss = 0.14363282224754007
Trained batch 205 in epoch 0, gen_loss = 0.45201187023838746, disc_loss = 0.14361182849818063
Trained batch 206 in epoch 0, gen_loss = 0.4521530217306625, disc_loss = 0.1434571471983108
Trained batch 207 in epoch 0, gen_loss = 0.4522499515173527, disc_loss = 0.14332176469123134
Trained batch 208 in epoch 0, gen_loss = 0.4521392723589993, disc_loss = 0.14329912834332892
Trained batch 209 in epoch 0, gen_loss = 0.4517516404390335, disc_loss = 0.14326742593021619
Trained batch 210 in epoch 0, gen_loss = 0.4518129821354744, disc_loss = 0.1435472130139857
Trained batch 211 in epoch 0, gen_loss = 0.45153196423121217, disc_loss = 0.14395642277064188
Trained batch 212 in epoch 0, gen_loss = 0.4513933178684521, disc_loss = 0.1444635256565233
Trained batch 213 in epoch 0, gen_loss = 0.4514131642112108, disc_loss = 0.14448117656267692
Trained batch 214 in epoch 0, gen_loss = 0.45147147012311356, disc_loss = 0.14441640228033065
Trained batch 215 in epoch 0, gen_loss = 0.45151351378471766, disc_loss = 0.14418961904529068
Trained batch 216 in epoch 0, gen_loss = 0.45130205456562306, disc_loss = 0.14423354797511606
Trained batch 217 in epoch 0, gen_loss = 0.45080484217460004, disc_loss = 0.14456906132058267
Trained batch 218 in epoch 0, gen_loss = 0.4505820534272825, disc_loss = 0.14493149985053225
Trained batch 219 in epoch 0, gen_loss = 0.4502326512878591, disc_loss = 0.14490961625494742
Trained batch 220 in epoch 0, gen_loss = 0.44986712258325984, disc_loss = 0.14527015694800546
Trained batch 221 in epoch 0, gen_loss = 0.4493185201206723, disc_loss = 0.14520410968510955
Trained batch 222 in epoch 0, gen_loss = 0.44900898976176307, disc_loss = 0.14528163769720917
Trained batch 223 in epoch 0, gen_loss = 0.4490157254040241, disc_loss = 0.14614870409215136
Trained batch 224 in epoch 0, gen_loss = 0.4485434285799662, disc_loss = 0.1461390323440234
Trained batch 225 in epoch 0, gen_loss = 0.44790284230118305, disc_loss = 0.14710237155050304
Trained batch 226 in epoch 0, gen_loss = 0.4474469765955131, disc_loss = 0.14751852008345895
Trained batch 227 in epoch 0, gen_loss = 0.4472848242312147, disc_loss = 0.14752444654311003
Trained batch 228 in epoch 0, gen_loss = 0.447021033566071, disc_loss = 0.14761533445015745
Trained batch 229 in epoch 0, gen_loss = 0.4464757520219554, disc_loss = 0.14766799558116042
Trained batch 230 in epoch 0, gen_loss = 0.44578260609081816, disc_loss = 0.1476789592599972
Trained batch 231 in epoch 0, gen_loss = 0.44544643716051663, disc_loss = 0.14774407520247945
Trained batch 232 in epoch 0, gen_loss = 0.4453570237742985, disc_loss = 0.1479430528349631
Trained batch 233 in epoch 0, gen_loss = 0.4452119220016349, disc_loss = 0.14803978122579745
Trained batch 234 in epoch 0, gen_loss = 0.4452592214371296, disc_loss = 0.1480854441193824
Trained batch 235 in epoch 0, gen_loss = 0.444983394469245, disc_loss = 0.14810652169004335
Trained batch 236 in epoch 0, gen_loss = 0.4447683621559465, disc_loss = 0.14811817870990132
Trained batch 237 in epoch 0, gen_loss = 0.44485928043097006, disc_loss = 0.14825517067513547
Trained batch 238 in epoch 0, gen_loss = 0.44484133588220287, disc_loss = 0.14903135083335214
Trained batch 239 in epoch 0, gen_loss = 0.44449843317270277, disc_loss = 0.1491252119652927
Trained batch 240 in epoch 0, gen_loss = 0.44417869018321215, disc_loss = 0.14905804510062165
Trained batch 241 in epoch 0, gen_loss = 0.44376330385523394, disc_loss = 0.14911787276548788
Trained batch 242 in epoch 0, gen_loss = 0.4438321644386637, disc_loss = 0.14907266828135698
Trained batch 243 in epoch 0, gen_loss = 0.4436503515624609, disc_loss = 0.14897663998188543
Trained batch 244 in epoch 0, gen_loss = 0.44302061905666273, disc_loss = 0.14911542671675584
Trained batch 245 in epoch 0, gen_loss = 0.44294491119501067, disc_loss = 0.14992375275104997
Trained batch 246 in epoch 0, gen_loss = 0.4426957193897803, disc_loss = 0.15186360927849163
Trained batch 247 in epoch 0, gen_loss = 0.4423024558251904, disc_loss = 0.15265080167521392
Trained batch 248 in epoch 0, gen_loss = 0.4418807367244399, disc_loss = 0.15420486628410807
Trained batch 249 in epoch 0, gen_loss = 0.44146729743480684, disc_loss = 0.15506041565537454
Trained batch 250 in epoch 0, gen_loss = 0.44138836872530174, disc_loss = 0.15568575064143336
Trained batch 251 in epoch 0, gen_loss = 0.44086786241285386, disc_loss = 0.15623064696907052
Trained batch 252 in epoch 0, gen_loss = 0.4404162519534115, disc_loss = 0.1570067342385473
Trained batch 253 in epoch 0, gen_loss = 0.43975818520925175, disc_loss = 0.15744064903752072
Trained batch 254 in epoch 0, gen_loss = 0.43937840835720887, disc_loss = 0.1577591888752638
Trained batch 255 in epoch 0, gen_loss = 0.43901456508319825, disc_loss = 0.15803758820402436
Trained batch 256 in epoch 0, gen_loss = 0.4385949425428294, disc_loss = 0.15832007021175748
Trained batch 257 in epoch 0, gen_loss = 0.438336168033208, disc_loss = 0.15852253886964895
Trained batch 258 in epoch 0, gen_loss = 0.4377217870421391, disc_loss = 0.15880135055559483
Trained batch 259 in epoch 0, gen_loss = 0.4375037286144037, disc_loss = 0.15900169871747494
Trained batch 260 in epoch 0, gen_loss = 0.4372760325784427, disc_loss = 0.15917926869744084
Trained batch 261 in epoch 0, gen_loss = 0.43683882706037913, disc_loss = 0.1594052972513756
Trained batch 262 in epoch 0, gen_loss = 0.43684620265724994, disc_loss = 0.15953855157011815
Trained batch 263 in epoch 0, gen_loss = 0.4366050444994912, disc_loss = 0.1597831053094882
Trained batch 264 in epoch 0, gen_loss = 0.43650450459066426, disc_loss = 0.15997224728453835
Trained batch 265 in epoch 0, gen_loss = 0.43660065912662593, disc_loss = 0.1601166739443639
Trained batch 266 in epoch 0, gen_loss = 0.43631742063086576, disc_loss = 0.1603624505105983
Trained batch 267 in epoch 0, gen_loss = 0.4359668448789796, disc_loss = 0.16061747888686942
Trained batch 268 in epoch 0, gen_loss = 0.4356695514407743, disc_loss = 0.16077503802940304
Trained batch 269 in epoch 0, gen_loss = 0.4352485679917865, disc_loss = 0.16095722474985652
Trained batch 270 in epoch 0, gen_loss = 0.4351756483646336, disc_loss = 0.1611997276489585
Trained batch 271 in epoch 0, gen_loss = 0.43487947280792627, disc_loss = 0.161386135226006
Trained batch 272 in epoch 0, gen_loss = 0.43497450939028254, disc_loss = 0.16155238839842023
Trained batch 273 in epoch 0, gen_loss = 0.4347531612772141, disc_loss = 0.16172083236113952
Trained batch 274 in epoch 0, gen_loss = 0.4342515537955544, disc_loss = 0.16185010641813277
Trained batch 275 in epoch 0, gen_loss = 0.43384738396043365, disc_loss = 0.16192901558310224
Trained batch 276 in epoch 0, gen_loss = 0.433709517390289, disc_loss = 0.16203991334468448
Trained batch 277 in epoch 0, gen_loss = 0.4334536308436085, disc_loss = 0.16219182465252258
Trained batch 278 in epoch 0, gen_loss = 0.43316033375733215, disc_loss = 0.16234159173183543
Trained batch 279 in epoch 0, gen_loss = 0.43267479858228136, disc_loss = 0.1628309888765216
Trained batch 280 in epoch 0, gen_loss = 0.43198673225594586, disc_loss = 0.1630873665531759
Trained batch 281 in epoch 0, gen_loss = 0.4315714589353149, disc_loss = 0.16318477809112122
Trained batch 282 in epoch 0, gen_loss = 0.4315276960496768, disc_loss = 0.16316708545908068
Trained batch 283 in epoch 0, gen_loss = 0.431175862032343, disc_loss = 0.16338154917556635
Trained batch 284 in epoch 0, gen_loss = 0.4308293089009168, disc_loss = 0.16393142282439951
Trained batch 285 in epoch 0, gen_loss = 0.4306032961377731, disc_loss = 0.16435335527037406
Trained batch 286 in epoch 0, gen_loss = 0.43041311796326254, disc_loss = 0.16442549797196837
Trained batch 287 in epoch 0, gen_loss = 0.43008217262104154, disc_loss = 0.16468121574467254
Trained batch 288 in epoch 0, gen_loss = 0.4298047665184344, disc_loss = 0.16477977082287976
Trained batch 289 in epoch 0, gen_loss = 0.42940818343696924, disc_loss = 0.16484010597241336
Trained batch 290 in epoch 0, gen_loss = 0.42910188021733586, disc_loss = 0.16487283935559163
Trained batch 291 in epoch 0, gen_loss = 0.42896117081176743, disc_loss = 0.16490141662118368
Trained batch 292 in epoch 0, gen_loss = 0.42851349747018197, disc_loss = 0.16499837594736153
Trained batch 293 in epoch 0, gen_loss = 0.4282923722449614, disc_loss = 0.16553643733567122
Trained batch 294 in epoch 0, gen_loss = 0.4282734705735061, disc_loss = 0.16614388815932354
Trained batch 295 in epoch 0, gen_loss = 0.42800674753615986, disc_loss = 0.16631258860532497
Trained batch 296 in epoch 0, gen_loss = 0.4277885430288636, disc_loss = 0.16655193668122242
Trained batch 297 in epoch 0, gen_loss = 0.4278045187160473, disc_loss = 0.1665854395285949
Trained batch 298 in epoch 0, gen_loss = 0.4275714329951583, disc_loss = 0.1667925840785671
Trained batch 299 in epoch 0, gen_loss = 0.4270921944081783, disc_loss = 0.16697832482556502
Trained batch 300 in epoch 0, gen_loss = 0.42649665172907997, disc_loss = 0.16716700151216152
Trained batch 301 in epoch 0, gen_loss = 0.4261774727149515, disc_loss = 0.16728856481167653
Trained batch 302 in epoch 0, gen_loss = 0.42612565129306845, disc_loss = 0.16741480245546933
Trained batch 303 in epoch 0, gen_loss = 0.4258275416826731, disc_loss = 0.16759838480012199
Trained batch 304 in epoch 0, gen_loss = 0.42570149405080765, disc_loss = 0.16812662396763192
Trained batch 305 in epoch 0, gen_loss = 0.42534224820487637, disc_loss = 0.16865668998532046
Trained batch 306 in epoch 0, gen_loss = 0.4251969796923939, disc_loss = 0.1687406493951521
Trained batch 307 in epoch 0, gen_loss = 0.425098405401041, disc_loss = 0.16879607662074753
Trained batch 308 in epoch 0, gen_loss = 0.42506392792011927, disc_loss = 0.16876224404303386
Trained batch 309 in epoch 0, gen_loss = 0.4247975049960998, disc_loss = 0.16880913422473015
Trained batch 310 in epoch 0, gen_loss = 0.4246114398984664, disc_loss = 0.16887486874578084
Trained batch 311 in epoch 0, gen_loss = 0.4244481183301944, disc_loss = 0.16889461342436382
Trained batch 312 in epoch 0, gen_loss = 0.4242444126465069, disc_loss = 0.16891325798373633
Trained batch 313 in epoch 0, gen_loss = 0.4241108277895648, disc_loss = 0.16899453627930325
Trained batch 314 in epoch 0, gen_loss = 0.4238607725926808, disc_loss = 0.16898155673628762
Trained batch 315 in epoch 0, gen_loss = 0.4235824921368798, disc_loss = 0.1692281220391204
Trained batch 316 in epoch 0, gen_loss = 0.4233566444096881, disc_loss = 0.16985554877985914
Trained batch 317 in epoch 0, gen_loss = 0.42330813431327446, disc_loss = 0.16999538385736868
Trained batch 318 in epoch 0, gen_loss = 0.4232431561875866, disc_loss = 0.1700377073080562
Trained batch 319 in epoch 0, gen_loss = 0.42317779758013785, disc_loss = 0.17005691232625395
Trained batch 320 in epoch 0, gen_loss = 0.42330487805920597, disc_loss = 0.169980112381999
Trained batch 321 in epoch 0, gen_loss = 0.42312161712357715, disc_loss = 0.16992766171786355
Trained batch 322 in epoch 0, gen_loss = 0.4229960622894506, disc_loss = 0.16993905172536247
Trained batch 323 in epoch 0, gen_loss = 0.4227731426096993, disc_loss = 0.17012509650746246
Trained batch 324 in epoch 0, gen_loss = 0.4226882972625586, disc_loss = 0.1704969704380402
Trained batch 325 in epoch 0, gen_loss = 0.4222866700379395, disc_loss = 0.17090125859606486
Trained batch 326 in epoch 0, gen_loss = 0.42182096314904155, disc_loss = 0.17100448986167938
Trained batch 327 in epoch 0, gen_loss = 0.42143780615453313, disc_loss = 0.1711689670138606
Trained batch 328 in epoch 0, gen_loss = 0.42130567921512396, disc_loss = 0.17124812800924105
Trained batch 329 in epoch 0, gen_loss = 0.42105318050492896, disc_loss = 0.1712906350466338
Trained batch 330 in epoch 0, gen_loss = 0.4207836347674315, disc_loss = 0.17133832461794338
Trained batch 331 in epoch 0, gen_loss = 0.4207507332854242, disc_loss = 0.17133183030030094
Trained batch 332 in epoch 0, gen_loss = 0.42053633440543225, disc_loss = 0.17131098726758728
Trained batch 333 in epoch 0, gen_loss = 0.42038834313611073, disc_loss = 0.17150533875216267
Trained batch 334 in epoch 0, gen_loss = 0.4200502361379453, disc_loss = 0.1716454925599383
Trained batch 335 in epoch 0, gen_loss = 0.41990194465255454, disc_loss = 0.17176990794195307
Trained batch 336 in epoch 0, gen_loss = 0.41977154169485903, disc_loss = 0.17184822604015956
Trained batch 337 in epoch 0, gen_loss = 0.41959858597559335, disc_loss = 0.1719086040362451
Trained batch 338 in epoch 0, gen_loss = 0.41950915841753855, disc_loss = 0.17193122979550235
Trained batch 339 in epoch 0, gen_loss = 0.41961957343360956, disc_loss = 0.17212036587297916
Trained batch 340 in epoch 0, gen_loss = 0.41944801680678145, disc_loss = 0.17224051112915414
Trained batch 341 in epoch 0, gen_loss = 0.41913470316525786, disc_loss = 0.1726357486992203
Trained batch 342 in epoch 0, gen_loss = 0.41894151591872336, disc_loss = 0.17273628005741637
Trained batch 343 in epoch 0, gen_loss = 0.41879762661491715, disc_loss = 0.17281861323863268
Trained batch 344 in epoch 0, gen_loss = 0.41846079251904417, disc_loss = 0.17288076525581056
Trained batch 345 in epoch 0, gen_loss = 0.4183786822795179, disc_loss = 0.17295622883762926
Trained batch 346 in epoch 0, gen_loss = 0.418300479264012, disc_loss = 0.17326714384023326
Trained batch 347 in epoch 0, gen_loss = 0.4180431570215472, disc_loss = 0.17322398557316984
Trained batch 348 in epoch 0, gen_loss = 0.4177546967835003, disc_loss = 0.17357884238562132
Trained batch 349 in epoch 0, gen_loss = 0.4177041691115924, disc_loss = 0.174002253391913
Trained batch 350 in epoch 0, gen_loss = 0.41764840182245966, disc_loss = 0.17401804278294244
Trained batch 351 in epoch 0, gen_loss = 0.417402540883896, disc_loss = 0.17416088314811615
Trained batch 352 in epoch 0, gen_loss = 0.41721587862407855, disc_loss = 0.174181509562491
Trained batch 353 in epoch 0, gen_loss = 0.4170269820902307, disc_loss = 0.17417287963342531
Trained batch 354 in epoch 0, gen_loss = 0.4167650594257973, disc_loss = 0.17414285064163343
Trained batch 355 in epoch 0, gen_loss = 0.4165193577077282, disc_loss = 0.17411733893782236
Trained batch 356 in epoch 0, gen_loss = 0.4163743225382824, disc_loss = 0.17424997067501566
Trained batch 357 in epoch 0, gen_loss = 0.4163509815848073, disc_loss = 0.17434982678660468
Trained batch 358 in epoch 0, gen_loss = 0.4163164635471647, disc_loss = 0.17416888616543294
Trained batch 359 in epoch 0, gen_loss = 0.41618078098528916, disc_loss = 0.17407974865701464
Trained batch 360 in epoch 0, gen_loss = 0.41591663295377324, disc_loss = 0.17410547028287957
Trained batch 361 in epoch 0, gen_loss = 0.41558447196174064, disc_loss = 0.1741684464871554
Trained batch 362 in epoch 0, gen_loss = 0.4153301811497402, disc_loss = 0.17433756622729552
Trained batch 363 in epoch 0, gen_loss = 0.4155487989249465, disc_loss = 0.17467727119123544
Trained batch 364 in epoch 0, gen_loss = 0.4153752859732876, disc_loss = 0.17482391955101326
Trained batch 365 in epoch 0, gen_loss = 0.4152636609849383, disc_loss = 0.17492559360838977
Trained batch 366 in epoch 0, gen_loss = 0.4151887480748122, disc_loss = 0.17483326139014813
Trained batch 367 in epoch 0, gen_loss = 0.4150386285441725, disc_loss = 0.1747406658756992
Trained batch 368 in epoch 0, gen_loss = 0.4150378550213527, disc_loss = 0.17458268458927226
Trained batch 369 in epoch 0, gen_loss = 0.4148442673924807, disc_loss = 0.17509741050166053
Trained batch 370 in epoch 0, gen_loss = 0.41483527642858, disc_loss = 0.17551044087525647
Trained batch 371 in epoch 0, gen_loss = 0.41499519920957983, disc_loss = 0.17570569173943612
Trained batch 372 in epoch 0, gen_loss = 0.41492933318538255, disc_loss = 0.17569308969674097
Trained batch 373 in epoch 0, gen_loss = 0.4147641014526872, disc_loss = 0.1755969813242953
Trained batch 374 in epoch 0, gen_loss = 0.4146688278118769, disc_loss = 0.1755747607946396
Trained batch 375 in epoch 0, gen_loss = 0.41447129294751806, disc_loss = 0.17571016250455634
Trained batch 376 in epoch 0, gen_loss = 0.414381091529874, disc_loss = 0.17556017070060068
Trained batch 377 in epoch 0, gen_loss = 0.41425485337379747, disc_loss = 0.1755424580048947
Trained batch 378 in epoch 0, gen_loss = 0.4142531130197495, disc_loss = 0.17558998948744545
Trained batch 379 in epoch 0, gen_loss = 0.4140843299266539, disc_loss = 0.17547046497072044
Trained batch 380 in epoch 0, gen_loss = 0.41384191975349516, disc_loss = 0.1755560788465297
Trained batch 381 in epoch 0, gen_loss = 0.41392865429842035, disc_loss = 0.17539994215778032
Trained batch 382 in epoch 0, gen_loss = 0.41382389167425837, disc_loss = 0.17536599782366044
Trained batch 383 in epoch 0, gen_loss = 0.4136496476906662, disc_loss = 0.17537009871254364
Trained batch 384 in epoch 0, gen_loss = 0.41372026386973143, disc_loss = 0.1752534791246637
Trained batch 385 in epoch 0, gen_loss = 0.4137516283077897, disc_loss = 0.1752712888343964
Trained batch 386 in epoch 0, gen_loss = 0.41375903338578934, disc_loss = 0.1751627580910074
Trained batch 387 in epoch 0, gen_loss = 0.41394142334147827, disc_loss = 0.17501484022773417
Trained batch 388 in epoch 0, gen_loss = 0.41390266980027784, disc_loss = 0.1749953261760942
Trained batch 389 in epoch 0, gen_loss = 0.4138037056877063, disc_loss = 0.17524097252350587
Trained batch 390 in epoch 0, gen_loss = 0.4138353728043759, disc_loss = 0.17564832154289842
Trained batch 391 in epoch 0, gen_loss = 0.41390256899199923, disc_loss = 0.17548904227739087
Trained batch 392 in epoch 0, gen_loss = 0.41390609441671056, disc_loss = 0.17533155035881595
Trained batch 393 in epoch 0, gen_loss = 0.41380490994241637, disc_loss = 0.17523843749676865
Trained batch 394 in epoch 0, gen_loss = 0.4138305267578439, disc_loss = 0.17511731329598004
Trained batch 395 in epoch 0, gen_loss = 0.41357264325323734, disc_loss = 0.17527129963943452
Trained batch 396 in epoch 0, gen_loss = 0.4134230114125485, disc_loss = 0.17570841991781289
Trained batch 397 in epoch 0, gen_loss = 0.4133785076851222, disc_loss = 0.17600661714622123
Trained batch 398 in epoch 0, gen_loss = 0.41329495974800046, disc_loss = 0.1761617917838252
Trained batch 399 in epoch 0, gen_loss = 0.4131848348304629, disc_loss = 0.17634298212826252
Trained batch 400 in epoch 0, gen_loss = 0.41306582282754845, disc_loss = 0.17618999639502786
Trained batch 401 in epoch 0, gen_loss = 0.4128538674457156, disc_loss = 0.17612428677764105
Trained batch 402 in epoch 0, gen_loss = 0.4128294586765559, disc_loss = 0.17612152762951389
Trained batch 403 in epoch 0, gen_loss = 0.4125595360920571, disc_loss = 0.17595958141702236
Trained batch 404 in epoch 0, gen_loss = 0.4125414378481147, disc_loss = 0.17581754668995186
Trained batch 405 in epoch 0, gen_loss = 0.41257840420665415, disc_loss = 0.1757558248019571
Trained batch 406 in epoch 0, gen_loss = 0.4123145646852709, disc_loss = 0.17576646749891287
Trained batch 407 in epoch 0, gen_loss = 0.41194684631830336, disc_loss = 0.17603197346861457
Trained batch 408 in epoch 0, gen_loss = 0.4119832153206641, disc_loss = 0.1760062538178451
Trained batch 409 in epoch 0, gen_loss = 0.41193797897274903, disc_loss = 0.17584452563669623
Trained batch 410 in epoch 0, gen_loss = 0.4118361380631036, disc_loss = 0.1757624968705096
Trained batch 411 in epoch 0, gen_loss = 0.41169825127547227, disc_loss = 0.17558622150455863
Trained batch 412 in epoch 0, gen_loss = 0.41156007313410825, disc_loss = 0.1754142293665946
Trained batch 413 in epoch 0, gen_loss = 0.411567686656535, disc_loss = 0.1753933798107836
Trained batch 414 in epoch 0, gen_loss = 0.41178597035896347, disc_loss = 0.17578691867101623
Trained batch 415 in epoch 0, gen_loss = 0.41188303492246914, disc_loss = 0.17561443547646588
Trained batch 416 in epoch 0, gen_loss = 0.4117815958724605, disc_loss = 0.17545140075454896
Trained batch 417 in epoch 0, gen_loss = 0.41163970997031224, disc_loss = 0.1754597546666433
Trained batch 418 in epoch 0, gen_loss = 0.41165195462385057, disc_loss = 0.1753639406691303
Trained batch 419 in epoch 0, gen_loss = 0.4117219698216234, disc_loss = 0.17513320208305405
Trained batch 420 in epoch 0, gen_loss = 0.41148709716394793, disc_loss = 0.17520179031438896
Trained batch 421 in epoch 0, gen_loss = 0.4113064780831337, disc_loss = 0.17535485281339755
Trained batch 422 in epoch 0, gen_loss = 0.411426256769656, disc_loss = 0.1753378954691808
Trained batch 423 in epoch 0, gen_loss = 0.4113012539960866, disc_loss = 0.17523433672229075
Trained batch 424 in epoch 0, gen_loss = 0.4111116542886285, disc_loss = 0.17532644710120032
Trained batch 425 in epoch 0, gen_loss = 0.41113771753551814, disc_loss = 0.1751835090873387
Trained batch 426 in epoch 0, gen_loss = 0.4112398078974851, disc_loss = 0.17506643051425522
Trained batch 427 in epoch 0, gen_loss = 0.4111590280641462, disc_loss = 0.1749633563525766
Trained batch 428 in epoch 0, gen_loss = 0.4111101941003666, disc_loss = 0.17519288202682576
Trained batch 429 in epoch 0, gen_loss = 0.41109196949143745, disc_loss = 0.17533992390299952
Trained batch 430 in epoch 0, gen_loss = 0.410992933018025, disc_loss = 0.175723181108311
Trained batch 431 in epoch 0, gen_loss = 0.41089715956951733, disc_loss = 0.1757556721913042
Trained batch 432 in epoch 0, gen_loss = 0.4106311677991656, disc_loss = 0.17571717834500186
Trained batch 433 in epoch 0, gen_loss = 0.4103795813593996, disc_loss = 0.17567426220337917
Trained batch 434 in epoch 0, gen_loss = 0.41019427683846704, disc_loss = 0.1755757855957952
Trained batch 435 in epoch 0, gen_loss = 0.41014719183701986, disc_loss = 0.17548200112143789
Trained batch 436 in epoch 0, gen_loss = 0.4101786629490776, disc_loss = 0.17535957574707967
Trained batch 437 in epoch 0, gen_loss = 0.4101479157261108, disc_loss = 0.17532911417010713
Trained batch 438 in epoch 0, gen_loss = 0.410095209989841, disc_loss = 0.1751087022465834
Trained batch 439 in epoch 0, gen_loss = 0.41004701395603743, disc_loss = 0.17500584921376272
Trained batch 440 in epoch 0, gen_loss = 0.4098373970139324, disc_loss = 0.1750010796685338
Trained batch 441 in epoch 0, gen_loss = 0.40969597844921085, disc_loss = 0.17506133876235236
Trained batch 442 in epoch 0, gen_loss = 0.40978564389268646, disc_loss = 0.17539471878962376
Trained batch 443 in epoch 0, gen_loss = 0.409598256452932, disc_loss = 0.1751985410983498
Trained batch 444 in epoch 0, gen_loss = 0.4093433872032701, disc_loss = 0.17523290816317783
Trained batch 445 in epoch 0, gen_loss = 0.4091924935779764, disc_loss = 0.17528691817693112
Trained batch 446 in epoch 0, gen_loss = 0.4091894510275032, disc_loss = 0.17506637849263698
Trained batch 447 in epoch 0, gen_loss = 0.4090407902175294, disc_loss = 0.17486439725118025
Trained batch 448 in epoch 0, gen_loss = 0.4088122598113355, disc_loss = 0.1747372906596995
Trained batch 449 in epoch 0, gen_loss = 0.40873248202933204, disc_loss = 0.17468234355250994
Trained batch 450 in epoch 0, gen_loss = 0.4087441498516933, disc_loss = 0.17451412941095834
Trained batch 451 in epoch 0, gen_loss = 0.4086650452716688, disc_loss = 0.174468092373119
Trained batch 452 in epoch 0, gen_loss = 0.4085416027054881, disc_loss = 0.17427510570808752
Trained batch 453 in epoch 0, gen_loss = 0.4084337384230765, disc_loss = 0.17401375678995631
Trained batch 454 in epoch 0, gen_loss = 0.4082295777051003, disc_loss = 0.17388483056655296
Trained batch 455 in epoch 0, gen_loss = 0.40819568536652806, disc_loss = 0.17371717041456386
Trained batch 456 in epoch 0, gen_loss = 0.40829463055279896, disc_loss = 0.17339397204685264
Trained batch 457 in epoch 0, gen_loss = 0.408188292650937, disc_loss = 0.17356573797632252
Trained batch 458 in epoch 0, gen_loss = 0.40859976868613873, disc_loss = 0.1740928972484889
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 0.474719375371933, disc_loss = 0.1962631642818451
Trained batch 1 in epoch 1, gen_loss = 0.44890858232975006, disc_loss = 0.2886113375425339
Trained batch 2 in epoch 1, gen_loss = 0.456513911485672, disc_loss = 0.3010678291320801
Trained batch 3 in epoch 1, gen_loss = 0.4415111318230629, disc_loss = 0.28858309239149094
Trained batch 4 in epoch 1, gen_loss = 0.44145105481147767, disc_loss = 0.2787856698036194
Trained batch 5 in epoch 1, gen_loss = 0.424501712123553, disc_loss = 0.2728060881296794
Trained batch 6 in epoch 1, gen_loss = 0.42270632301058086, disc_loss = 0.2628213252340044
Trained batch 7 in epoch 1, gen_loss = 0.41888968646526337, disc_loss = 0.25754316709935665
Trained batch 8 in epoch 1, gen_loss = 0.41120848390791154, disc_loss = 0.24926922884252337
Trained batch 9 in epoch 1, gen_loss = 0.4039096623659134, disc_loss = 0.241605906188488
Trained batch 10 in epoch 1, gen_loss = 0.39880933273922314, disc_loss = 0.2349455627528104
Trained batch 11 in epoch 1, gen_loss = 0.3984554211298625, disc_loss = 0.22906677052378654
Trained batch 12 in epoch 1, gen_loss = 0.3960240620833177, disc_loss = 0.22393172406233275
Trained batch 13 in epoch 1, gen_loss = 0.39937159419059753, disc_loss = 0.2178116153393473
Trained batch 14 in epoch 1, gen_loss = 0.3993020117282867, disc_loss = 0.21281273464361827
Trained batch 15 in epoch 1, gen_loss = 0.4020518157631159, disc_loss = 0.21431284956634045
Trained batch 16 in epoch 1, gen_loss = 0.403180471237968, disc_loss = 0.21971735884161556
Trained batch 17 in epoch 1, gen_loss = 0.399330766664611, disc_loss = 0.22085291230016285
Trained batch 18 in epoch 1, gen_loss = 0.39265607375847666, disc_loss = 0.2227776089781209
Trained batch 19 in epoch 1, gen_loss = 0.39118511229753494, disc_loss = 0.22349071577191354
Trained batch 20 in epoch 1, gen_loss = 0.3881264456680843, disc_loss = 0.22437340801670438
Trained batch 21 in epoch 1, gen_loss = 0.3855895698070526, disc_loss = 0.22314509004354477
Trained batch 22 in epoch 1, gen_loss = 0.3848999816438426, disc_loss = 0.21974907945031705
Trained batch 23 in epoch 1, gen_loss = 0.38452448199192685, disc_loss = 0.2166364248842001
Trained batch 24 in epoch 1, gen_loss = 0.3838081657886505, disc_loss = 0.21850982844829558
Trained batch 25 in epoch 1, gen_loss = 0.3844029949261592, disc_loss = 0.22577279404951975
Trained batch 26 in epoch 1, gen_loss = 0.3830494218402439, disc_loss = 0.22434171979074125
Trained batch 27 in epoch 1, gen_loss = 0.37807936274579595, disc_loss = 0.22434321471623012
Trained batch 28 in epoch 1, gen_loss = 0.3765335673915929, disc_loss = 0.22204172662619887
Trained batch 29 in epoch 1, gen_loss = 0.3787362431486448, disc_loss = 0.2183308000365893
Trained batch 30 in epoch 1, gen_loss = 0.37738637530034586, disc_loss = 0.21661685022615618
Trained batch 31 in epoch 1, gen_loss = 0.3771110656671226, disc_loss = 0.21752567496150732
Trained batch 32 in epoch 1, gen_loss = 0.37881293486465106, disc_loss = 0.21427622031081806
Trained batch 33 in epoch 1, gen_loss = 0.3802732724477263, disc_loss = 0.21515962744460387
Trained batch 34 in epoch 1, gen_loss = 0.378729515842029, disc_loss = 0.21372448163373128
Trained batch 35 in epoch 1, gen_loss = 0.37814755034115577, disc_loss = 0.2114730009602176
Trained batch 36 in epoch 1, gen_loss = 0.37922384730867437, disc_loss = 0.2134629781987216
Trained batch 37 in epoch 1, gen_loss = 0.37741540803721074, disc_loss = 0.2100559200503324
Trained batch 38 in epoch 1, gen_loss = 0.37600532517983365, disc_loss = 0.20820825432355589
Trained batch 39 in epoch 1, gen_loss = 0.3748244773596525, disc_loss = 0.20643124561756848
Trained batch 40 in epoch 1, gen_loss = 0.3753851270530282, disc_loss = 0.20425828110154082
Trained batch 41 in epoch 1, gen_loss = 0.3758214559583437, disc_loss = 0.20119475413646018
Trained batch 42 in epoch 1, gen_loss = 0.37515705650629, disc_loss = 0.20036547388448273
Trained batch 43 in epoch 1, gen_loss = 0.37555748799985106, disc_loss = 0.2007813709364696
Trained batch 44 in epoch 1, gen_loss = 0.3775621086359024, disc_loss = 0.19928880350457298
Trained batch 45 in epoch 1, gen_loss = 0.37619377834641415, disc_loss = 0.19703255253641502
Trained batch 46 in epoch 1, gen_loss = 0.37621040642261505, disc_loss = 0.19545129940230796
Trained batch 47 in epoch 1, gen_loss = 0.3774934619044264, disc_loss = 0.19421848111475506
Trained batch 48 in epoch 1, gen_loss = 0.3765135507802574, disc_loss = 0.1935587940471513
Trained batch 49 in epoch 1, gen_loss = 0.3768610879778862, disc_loss = 0.19135549440979957
Trained batch 50 in epoch 1, gen_loss = 0.3757237905965132, disc_loss = 0.19196724029732684
Trained batch 51 in epoch 1, gen_loss = 0.37596074463083196, disc_loss = 0.19908665879987753
Trained batch 52 in epoch 1, gen_loss = 0.37535917280979875, disc_loss = 0.1989067889890581
Trained batch 53 in epoch 1, gen_loss = 0.3754253351578006, disc_loss = 0.2003601542501538
Trained batch 54 in epoch 1, gen_loss = 0.3761825585907156, disc_loss = 0.20038303150372072
Trained batch 55 in epoch 1, gen_loss = 0.37512861165617195, disc_loss = 0.2016134737059474
Trained batch 56 in epoch 1, gen_loss = 0.37429550995952204, disc_loss = 0.20083747346673095
Trained batch 57 in epoch 1, gen_loss = 0.37502817167290325, disc_loss = 0.19947466485459228
Trained batch 58 in epoch 1, gen_loss = 0.3743488715361741, disc_loss = 0.1983774455927186
Trained batch 59 in epoch 1, gen_loss = 0.3746413605908553, disc_loss = 0.1972946633895238
Trained batch 60 in epoch 1, gen_loss = 0.3756287662220783, disc_loss = 0.19729305681635123
Trained batch 61 in epoch 1, gen_loss = 0.375015715677892, disc_loss = 0.19598318083632377
Trained batch 62 in epoch 1, gen_loss = 0.3745147834221522, disc_loss = 0.19474863958737207
Trained batch 63 in epoch 1, gen_loss = 0.3747247576247901, disc_loss = 0.1932735180016607
Trained batch 64 in epoch 1, gen_loss = 0.37582968863157123, disc_loss = 0.19191662050210512
Trained batch 65 in epoch 1, gen_loss = 0.37625359201973135, disc_loss = 0.19071745082284464
Trained batch 66 in epoch 1, gen_loss = 0.3755368663748698, disc_loss = 0.1898643654673847
Trained batch 67 in epoch 1, gen_loss = 0.3747291562750059, disc_loss = 0.1887373941786149
Trained batch 68 in epoch 1, gen_loss = 0.3748933618915254, disc_loss = 0.1889558620211007
Trained batch 69 in epoch 1, gen_loss = 0.3756724151117461, disc_loss = 0.18947768232652118
Trained batch 70 in epoch 1, gen_loss = 0.37533650242946515, disc_loss = 0.1902758605043653
Trained batch 71 in epoch 1, gen_loss = 0.3745106311721934, disc_loss = 0.18923007127725416
Trained batch 72 in epoch 1, gen_loss = 0.37493841309253484, disc_loss = 0.18827726447010693
Trained batch 73 in epoch 1, gen_loss = 0.37424958980566747, disc_loss = 0.18747390011275136
Trained batch 74 in epoch 1, gen_loss = 0.3744676508506139, disc_loss = 0.1864428519209226
Trained batch 75 in epoch 1, gen_loss = 0.37434696464946393, disc_loss = 0.18676494993269444
Trained batch 76 in epoch 1, gen_loss = 0.37414332353449486, disc_loss = 0.1866606885156074
Trained batch 77 in epoch 1, gen_loss = 0.3744218649390416, disc_loss = 0.18537242471789703
Trained batch 78 in epoch 1, gen_loss = 0.3754257237232184, disc_loss = 0.18569235003824475
Trained batch 79 in epoch 1, gen_loss = 0.37412622291594744, disc_loss = 0.18578709000721574
Trained batch 80 in epoch 1, gen_loss = 0.3746558282478356, disc_loss = 0.18620229641228547
Trained batch 81 in epoch 1, gen_loss = 0.374858034274927, disc_loss = 0.18554842499334637
Trained batch 82 in epoch 1, gen_loss = 0.3747521159519632, disc_loss = 0.1848329268844731
Trained batch 83 in epoch 1, gen_loss = 0.3742557755183606, disc_loss = 0.1836281737223977
Trained batch 84 in epoch 1, gen_loss = 0.3746468258254668, disc_loss = 0.18277933299541474
Trained batch 85 in epoch 1, gen_loss = 0.3752345638566239, disc_loss = 0.18223980519660685
Trained batch 86 in epoch 1, gen_loss = 0.37538368383358267, disc_loss = 0.1813100692869603
Trained batch 87 in epoch 1, gen_loss = 0.376225764609196, disc_loss = 0.1803240513598377
Trained batch 88 in epoch 1, gen_loss = 0.37621508337808457, disc_loss = 0.17949288832337668
Trained batch 89 in epoch 1, gen_loss = 0.3760981584588687, disc_loss = 0.17845691500438585
Trained batch 90 in epoch 1, gen_loss = 0.3759608715772629, disc_loss = 0.1775613979815127
Trained batch 91 in epoch 1, gen_loss = 0.3757611262085645, disc_loss = 0.17750889103373754
Trained batch 92 in epoch 1, gen_loss = 0.37708955602620237, disc_loss = 0.17845461133026308
Trained batch 93 in epoch 1, gen_loss = 0.3774535226378035, disc_loss = 0.17769510259336613
Trained batch 94 in epoch 1, gen_loss = 0.37697643967051253, disc_loss = 0.17756792816676592
Trained batch 95 in epoch 1, gen_loss = 0.376945903369536, disc_loss = 0.17762501607649028
Trained batch 96 in epoch 1, gen_loss = 0.377630434546274, disc_loss = 0.17813066131982608
Trained batch 97 in epoch 1, gen_loss = 0.37795221212567115, disc_loss = 0.17729732857979075
Trained batch 98 in epoch 1, gen_loss = 0.37903275890181765, disc_loss = 0.17673479803282804
Trained batch 99 in epoch 1, gen_loss = 0.3789216183125973, disc_loss = 0.17641255602240563
Trained batch 100 in epoch 1, gen_loss = 0.37829595081286854, disc_loss = 0.17610790189540032
Trained batch 101 in epoch 1, gen_loss = 0.3779450969076624, disc_loss = 0.17508420026769825
Trained batch 102 in epoch 1, gen_loss = 0.37789299664566817, disc_loss = 0.17437663464580924
Trained batch 103 in epoch 1, gen_loss = 0.37804354541003704, disc_loss = 0.1750805166621621
Trained batch 104 in epoch 1, gen_loss = 0.37867785876705534, disc_loss = 0.17445701374894096
Trained batch 105 in epoch 1, gen_loss = 0.37939849566176254, disc_loss = 0.17410584370482643
Trained batch 106 in epoch 1, gen_loss = 0.3800895814305154, disc_loss = 0.17333929115366714
Trained batch 107 in epoch 1, gen_loss = 0.38000944160200933, disc_loss = 0.17265225546779456
Trained batch 108 in epoch 1, gen_loss = 0.37996235421491326, disc_loss = 0.17327020802629103
Trained batch 109 in epoch 1, gen_loss = 0.38043212308125063, disc_loss = 0.17612949230454183
Trained batch 110 in epoch 1, gen_loss = 0.3798768000828253, disc_loss = 0.17670682072639465
Trained batch 111 in epoch 1, gen_loss = 0.3791137160733342, disc_loss = 0.17755580374172755
Trained batch 112 in epoch 1, gen_loss = 0.378909541837937, disc_loss = 0.1778703210628138
Trained batch 113 in epoch 1, gen_loss = 0.37902499330148365, disc_loss = 0.17815025503698148
Trained batch 114 in epoch 1, gen_loss = 0.37908160725365514, disc_loss = 0.17867623399133267
Trained batch 115 in epoch 1, gen_loss = 0.3789306176376754, disc_loss = 0.17873860086346494
Trained batch 116 in epoch 1, gen_loss = 0.37927815076122934, disc_loss = 0.1795583080786925
Trained batch 117 in epoch 1, gen_loss = 0.37979534154726285, disc_loss = 0.1802213822128409
Trained batch 118 in epoch 1, gen_loss = 0.3793692104205364, disc_loss = 0.1804798598549947
Trained batch 119 in epoch 1, gen_loss = 0.3787907941887776, disc_loss = 0.1806998483836651
Trained batch 120 in epoch 1, gen_loss = 0.3787568136433925, disc_loss = 0.18053320567469952
Trained batch 121 in epoch 1, gen_loss = 0.37868347702944866, disc_loss = 0.18037161365395687
Trained batch 122 in epoch 1, gen_loss = 0.37862334878948645, disc_loss = 0.18047798491590392
Trained batch 123 in epoch 1, gen_loss = 0.37873004004359245, disc_loss = 0.1806597589485107
Trained batch 124 in epoch 1, gen_loss = 0.37910896718502046, disc_loss = 0.18065604436397553
Trained batch 125 in epoch 1, gen_loss = 0.37881216394995887, disc_loss = 0.18048613553955442
Trained batch 126 in epoch 1, gen_loss = 0.3788392185930192, disc_loss = 0.18042313630186665
Trained batch 127 in epoch 1, gen_loss = 0.3794129773741588, disc_loss = 0.18214234546758235
Trained batch 128 in epoch 1, gen_loss = 0.37925429965636526, disc_loss = 0.1819773085357607
Trained batch 129 in epoch 1, gen_loss = 0.3789476719040137, disc_loss = 0.18291024886644802
Trained batch 130 in epoch 1, gen_loss = 0.37895456877828554, disc_loss = 0.18293689634963756
Trained batch 131 in epoch 1, gen_loss = 0.37873023895151686, disc_loss = 0.1830669544411428
Trained batch 132 in epoch 1, gen_loss = 0.37884563801432014, disc_loss = 0.1826096412382628
Trained batch 133 in epoch 1, gen_loss = 0.3790372459968524, disc_loss = 0.1818477679322015
Trained batch 134 in epoch 1, gen_loss = 0.37903236978583865, disc_loss = 0.18164349639857258
Trained batch 135 in epoch 1, gen_loss = 0.3789007230935728, disc_loss = 0.18155746523510008
Trained batch 136 in epoch 1, gen_loss = 0.37858247115229166, disc_loss = 0.18174804540446204
Trained batch 137 in epoch 1, gen_loss = 0.37852177315432095, disc_loss = 0.18176049188427304
Trained batch 138 in epoch 1, gen_loss = 0.37902409427886385, disc_loss = 0.1815670417795936
Trained batch 139 in epoch 1, gen_loss = 0.37931098544171876, disc_loss = 0.1811814273042338
Trained batch 140 in epoch 1, gen_loss = 0.37841116230115823, disc_loss = 0.18124913968515735
Trained batch 141 in epoch 1, gen_loss = 0.37878504699804416, disc_loss = 0.18083844596231488
Trained batch 142 in epoch 1, gen_loss = 0.3789156688885255, disc_loss = 0.1804073077815396
Trained batch 143 in epoch 1, gen_loss = 0.3786189505416486, disc_loss = 0.180912252722515
Trained batch 144 in epoch 1, gen_loss = 0.379238502629872, disc_loss = 0.18053857879392032
Trained batch 145 in epoch 1, gen_loss = 0.3790901853409532, disc_loss = 0.18059595980464596
Trained batch 146 in epoch 1, gen_loss = 0.3785738124936616, disc_loss = 0.1805795732201362
Trained batch 147 in epoch 1, gen_loss = 0.3782992110260435, disc_loss = 0.180174149421824
Trained batch 148 in epoch 1, gen_loss = 0.37845198370066263, disc_loss = 0.18001961113022477
Trained batch 149 in epoch 1, gen_loss = 0.37830074518918994, disc_loss = 0.17951443865895272
Trained batch 150 in epoch 1, gen_loss = 0.3783177679145573, disc_loss = 0.17895501067504188
Trained batch 151 in epoch 1, gen_loss = 0.3783619783230518, disc_loss = 0.17850518795220474
Trained batch 152 in epoch 1, gen_loss = 0.37819618892435936, disc_loss = 0.17790336984824512
Trained batch 153 in epoch 1, gen_loss = 0.37854438913719995, disc_loss = 0.1776134656234221
Trained batch 154 in epoch 1, gen_loss = 0.3786287474055444, disc_loss = 0.17712223746122852
Trained batch 155 in epoch 1, gen_loss = 0.37852118498621845, disc_loss = 0.1772729636480411
Trained batch 156 in epoch 1, gen_loss = 0.3782446406259658, disc_loss = 0.17820446055596043
Trained batch 157 in epoch 1, gen_loss = 0.3782335407560385, disc_loss = 0.17769553517050382
Trained batch 158 in epoch 1, gen_loss = 0.37799198419417973, disc_loss = 0.17718439886592469
Trained batch 159 in epoch 1, gen_loss = 0.3777120030485094, disc_loss = 0.1771163171622902
Trained batch 160 in epoch 1, gen_loss = 0.37705927078398116, disc_loss = 0.17696195521524974
Trained batch 161 in epoch 1, gen_loss = 0.37711068408356774, disc_loss = 0.17654132346312204
Trained batch 162 in epoch 1, gen_loss = 0.37672524958666115, disc_loss = 0.17662965145213472
Trained batch 163 in epoch 1, gen_loss = 0.37705406537506636, disc_loss = 0.17631768644219492
Trained batch 164 in epoch 1, gen_loss = 0.37709785293449055, disc_loss = 0.17644551387338928
Trained batch 165 in epoch 1, gen_loss = 0.3771712633680148, disc_loss = 0.17601298886429834
Trained batch 166 in epoch 1, gen_loss = 0.3768243935115323, disc_loss = 0.17525607972087975
Trained batch 167 in epoch 1, gen_loss = 0.3764912577434665, disc_loss = 0.17451537200914963
Trained batch 168 in epoch 1, gen_loss = 0.3762940744147498, disc_loss = 0.1745989437727533
Trained batch 169 in epoch 1, gen_loss = 0.37646462785847046, disc_loss = 0.17440233664477572
Trained batch 170 in epoch 1, gen_loss = 0.37678421057804284, disc_loss = 0.1737959153993785
Trained batch 171 in epoch 1, gen_loss = 0.3773884238718554, disc_loss = 0.17333067156547724
Trained batch 172 in epoch 1, gen_loss = 0.3771483532093853, disc_loss = 0.17298613372393426
Trained batch 173 in epoch 1, gen_loss = 0.3772873435726111, disc_loss = 0.17211422910806776
Trained batch 174 in epoch 1, gen_loss = 0.3775099118266787, disc_loss = 0.17132913504328046
Trained batch 175 in epoch 1, gen_loss = 0.3776385532692075, disc_loss = 0.1706363418224183
Trained batch 176 in epoch 1, gen_loss = 0.37752665730856233, disc_loss = 0.16980953489319753
Trained batch 177 in epoch 1, gen_loss = 0.3776984687769011, disc_loss = 0.16918569198401456
Trained batch 178 in epoch 1, gen_loss = 0.3781425890476344, disc_loss = 0.16843684492164485
Trained batch 179 in epoch 1, gen_loss = 0.3777715658975972, disc_loss = 0.167940886815389
Trained batch 180 in epoch 1, gen_loss = 0.37827368459319544, disc_loss = 0.1685520005489581
Trained batch 181 in epoch 1, gen_loss = 0.37831522860042344, disc_loss = 0.16791260080759998
Trained batch 182 in epoch 1, gen_loss = 0.3780185002935389, disc_loss = 0.16791018853829207
Trained batch 183 in epoch 1, gen_loss = 0.37812566862482094, disc_loss = 0.16882692724871246
Trained batch 184 in epoch 1, gen_loss = 0.37826910832443755, disc_loss = 0.16932044699788093
Trained batch 185 in epoch 1, gen_loss = 0.37819886343773973, disc_loss = 0.16904819258038076
Trained batch 186 in epoch 1, gen_loss = 0.37831723570504927, disc_loss = 0.16844813455952043
Trained batch 187 in epoch 1, gen_loss = 0.37871360184347375, disc_loss = 0.16770167124675625
Trained batch 188 in epoch 1, gen_loss = 0.3783606892382657, disc_loss = 0.1672593138264443
Trained batch 189 in epoch 1, gen_loss = 0.3777144843810483, disc_loss = 0.16802239315094133
Trained batch 190 in epoch 1, gen_loss = 0.37794620212147995, disc_loss = 0.16764679643769226
Trained batch 191 in epoch 1, gen_loss = 0.3781294561146448, disc_loss = 0.16827390248848437
Trained batch 192 in epoch 1, gen_loss = 0.3778739538371872, disc_loss = 0.16851863403046996
Trained batch 193 in epoch 1, gen_loss = 0.3783418856484374, disc_loss = 0.1687601068796417
Trained batch 194 in epoch 1, gen_loss = 0.3788209833395787, disc_loss = 0.16842085798390402
Trained batch 195 in epoch 1, gen_loss = 0.3787494494142581, disc_loss = 0.16842558861196955
Trained batch 196 in epoch 1, gen_loss = 0.3785250086318418, disc_loss = 0.16829887897646065
Trained batch 197 in epoch 1, gen_loss = 0.37834142712932645, disc_loss = 0.1684173173506302
Trained batch 198 in epoch 1, gen_loss = 0.37816769266547867, disc_loss = 0.16852539331282504
Trained batch 199 in epoch 1, gen_loss = 0.3784217933565378, disc_loss = 0.1687680400442332
Trained batch 200 in epoch 1, gen_loss = 0.37826700656864776, disc_loss = 0.16820439825121739
Trained batch 201 in epoch 1, gen_loss = 0.37794466088018797, disc_loss = 0.16774458551576527
Trained batch 202 in epoch 1, gen_loss = 0.3776189943986573, disc_loss = 0.16746873517745528
Trained batch 203 in epoch 1, gen_loss = 0.37762263570638266, disc_loss = 0.16712789853815646
Trained batch 204 in epoch 1, gen_loss = 0.3780551604381422, disc_loss = 0.1666123409732813
Trained batch 205 in epoch 1, gen_loss = 0.3782463563443388, disc_loss = 0.16624324319395914
Trained batch 206 in epoch 1, gen_loss = 0.37842733164628345, disc_loss = 0.16557349404095165
Trained batch 207 in epoch 1, gen_loss = 0.37821190410222, disc_loss = 0.16530563971565032
Trained batch 208 in epoch 1, gen_loss = 0.37880565454229786, disc_loss = 0.16491518903113722
Trained batch 209 in epoch 1, gen_loss = 0.3790421084988685, disc_loss = 0.16529288422316313
Trained batch 210 in epoch 1, gen_loss = 0.378997194187901, disc_loss = 0.16483026060553807
Trained batch 211 in epoch 1, gen_loss = 0.378963967328364, disc_loss = 0.16473833031354929
Trained batch 212 in epoch 1, gen_loss = 0.37875812469233927, disc_loss = 0.16492343105445725
Trained batch 213 in epoch 1, gen_loss = 0.37870583070494307, disc_loss = 0.16517992758966774
Trained batch 214 in epoch 1, gen_loss = 0.3788975269988526, disc_loss = 0.16531810943297176
Trained batch 215 in epoch 1, gen_loss = 0.3790301626065263, disc_loss = 0.16471886899563726
Trained batch 216 in epoch 1, gen_loss = 0.37933873024679, disc_loss = 0.16464887891599933
Trained batch 217 in epoch 1, gen_loss = 0.3792157545685768, disc_loss = 0.1640547929639253
Trained batch 218 in epoch 1, gen_loss = 0.3792230332414854, disc_loss = 0.1636852369001603
Trained batch 219 in epoch 1, gen_loss = 0.3790659611198035, disc_loss = 0.1633493694815446
Trained batch 220 in epoch 1, gen_loss = 0.37938813649421366, disc_loss = 0.16279540822011043
Trained batch 221 in epoch 1, gen_loss = 0.37949984453551405, disc_loss = 0.16231070768490835
Trained batch 222 in epoch 1, gen_loss = 0.3799642683278285, disc_loss = 0.16187333754126
Trained batch 223 in epoch 1, gen_loss = 0.38009965253461686, disc_loss = 0.1612578158715873
Trained batch 224 in epoch 1, gen_loss = 0.380001624888844, disc_loss = 0.1606796298507187
Trained batch 225 in epoch 1, gen_loss = 0.38012337097815707, disc_loss = 0.16004187355757551
Trained batch 226 in epoch 1, gen_loss = 0.38026707635839607, disc_loss = 0.15939062430076137
Trained batch 227 in epoch 1, gen_loss = 0.379722327451434, disc_loss = 0.15929641656316162
Trained batch 228 in epoch 1, gen_loss = 0.38011909787051024, disc_loss = 0.15899496561314863
Trained batch 229 in epoch 1, gen_loss = 0.38046314152686495, disc_loss = 0.15838868462521097
Trained batch 230 in epoch 1, gen_loss = 0.3802643549261671, disc_loss = 0.15855492961097073
Trained batch 231 in epoch 1, gen_loss = 0.38081615540231095, disc_loss = 0.15918157885557618
Trained batch 232 in epoch 1, gen_loss = 0.38098932457328355, disc_loss = 0.15878906922790625
Trained batch 233 in epoch 1, gen_loss = 0.3808742669275683, disc_loss = 0.15870424958630505
Trained batch 234 in epoch 1, gen_loss = 0.3806910441910967, disc_loss = 0.16029408593127067
Trained batch 235 in epoch 1, gen_loss = 0.38055546007166474, disc_loss = 0.1601426223198236
Trained batch 236 in epoch 1, gen_loss = 0.38061942776295704, disc_loss = 0.15999925123991343
Trained batch 237 in epoch 1, gen_loss = 0.38059459683023583, disc_loss = 0.15959140852469356
Trained batch 238 in epoch 1, gen_loss = 0.38041833909735023, disc_loss = 0.1593982066694164
Trained batch 239 in epoch 1, gen_loss = 0.3800459401682019, disc_loss = 0.15912514887750148
Trained batch 240 in epoch 1, gen_loss = 0.37942316466594633, disc_loss = 0.15909102484893006
Trained batch 241 in epoch 1, gen_loss = 0.37935615195469424, disc_loss = 0.15877473896200006
Trained batch 242 in epoch 1, gen_loss = 0.37960290412108105, disc_loss = 0.15870483857368736
Trained batch 243 in epoch 1, gen_loss = 0.37929236394215804, disc_loss = 0.15852525879125126
Trained batch 244 in epoch 1, gen_loss = 0.37935254044678746, disc_loss = 0.15807678664521296
Trained batch 245 in epoch 1, gen_loss = 0.3793232715347918, disc_loss = 0.15759999630594157
Trained batch 246 in epoch 1, gen_loss = 0.3795305691387972, disc_loss = 0.15722426794740835
Trained batch 247 in epoch 1, gen_loss = 0.3794764176371597, disc_loss = 0.15685682261603012
Trained batch 248 in epoch 1, gen_loss = 0.3794904816222478, disc_loss = 0.15650502420273651
Trained batch 249 in epoch 1, gen_loss = 0.3797706256508827, disc_loss = 0.15650233559310436
Trained batch 250 in epoch 1, gen_loss = 0.379719828763806, disc_loss = 0.15609105922786362
Trained batch 251 in epoch 1, gen_loss = 0.37952064101894695, disc_loss = 0.15613709372423945
Trained batch 252 in epoch 1, gen_loss = 0.37969147752631793, disc_loss = 0.1573104076823698
Trained batch 253 in epoch 1, gen_loss = 0.37975934048102594, disc_loss = 0.15704899460194618
Trained batch 254 in epoch 1, gen_loss = 0.37966939812781764, disc_loss = 0.15738946032874723
Trained batch 255 in epoch 1, gen_loss = 0.38014581956667826, disc_loss = 0.15717748735914938
Trained batch 256 in epoch 1, gen_loss = 0.3804976396871448, disc_loss = 0.1570666406579055
Trained batch 257 in epoch 1, gen_loss = 0.3807313565251439, disc_loss = 0.15679155059101046
Trained batch 258 in epoch 1, gen_loss = 0.38059284161186585, disc_loss = 0.1572176921091485
Trained batch 259 in epoch 1, gen_loss = 0.38040336318887197, disc_loss = 0.15707347000447602
Trained batch 260 in epoch 1, gen_loss = 0.38013109148005414, disc_loss = 0.15723776237832177
Trained batch 261 in epoch 1, gen_loss = 0.379967346730578, disc_loss = 0.15719275037182195
Trained batch 262 in epoch 1, gen_loss = 0.37991208104352986, disc_loss = 0.15762192914581116
Trained batch 263 in epoch 1, gen_loss = 0.3796998933522087, disc_loss = 0.15769611211550055
Trained batch 264 in epoch 1, gen_loss = 0.3794319386189839, disc_loss = 0.15788338063460475
Trained batch 265 in epoch 1, gen_loss = 0.378971613831538, disc_loss = 0.15770573533119114
Trained batch 266 in epoch 1, gen_loss = 0.3791040619102757, disc_loss = 0.15825114290366013
Trained batch 267 in epoch 1, gen_loss = 0.3792975399809987, disc_loss = 0.15856959048046995
Trained batch 268 in epoch 1, gen_loss = 0.3794337922644881, disc_loss = 0.15841725939490095
Trained batch 269 in epoch 1, gen_loss = 0.37945985313918856, disc_loss = 0.158286993564279
Trained batch 270 in epoch 1, gen_loss = 0.37936147679042115, disc_loss = 0.158087405441432
Trained batch 271 in epoch 1, gen_loss = 0.37928609555477605, disc_loss = 0.15833547399105394
Trained batch 272 in epoch 1, gen_loss = 0.37906698358582924, disc_loss = 0.1584394049622637
Trained batch 273 in epoch 1, gen_loss = 0.3789988494593732, disc_loss = 0.15828509427552676
Trained batch 274 in epoch 1, gen_loss = 0.37919191311706196, disc_loss = 0.15824052772738717
Trained batch 275 in epoch 1, gen_loss = 0.37901684074946074, disc_loss = 0.1582291295239027
Trained batch 276 in epoch 1, gen_loss = 0.37886388782774927, disc_loss = 0.1583587260452849
Trained batch 277 in epoch 1, gen_loss = 0.3790602773535166, disc_loss = 0.15836033048175222
Trained batch 278 in epoch 1, gen_loss = 0.3790758181109651, disc_loss = 0.15824049876795876
Trained batch 279 in epoch 1, gen_loss = 0.3793030444532633, disc_loss = 0.1580444377980062
Trained batch 280 in epoch 1, gen_loss = 0.3793059449072834, disc_loss = 0.15794648664913993
Trained batch 281 in epoch 1, gen_loss = 0.37934310126600534, disc_loss = 0.1583375835143928
Trained batch 282 in epoch 1, gen_loss = 0.37958966300891905, disc_loss = 0.1582312380151277
Trained batch 283 in epoch 1, gen_loss = 0.37967930477060063, disc_loss = 0.15845609970495733
Trained batch 284 in epoch 1, gen_loss = 0.3794991587860542, disc_loss = 0.15827913064705698
Trained batch 285 in epoch 1, gen_loss = 0.3796199055297391, disc_loss = 0.15820807963609695
Trained batch 286 in epoch 1, gen_loss = 0.37975434958934784, disc_loss = 0.15856698960169682
Trained batch 287 in epoch 1, gen_loss = 0.37984991368527216, disc_loss = 0.15835399855859578
Trained batch 288 in epoch 1, gen_loss = 0.3797298315590228, disc_loss = 0.15828075899281716
Trained batch 289 in epoch 1, gen_loss = 0.37981771451645885, disc_loss = 0.15860673628490546
Trained batch 290 in epoch 1, gen_loss = 0.3797172176366819, disc_loss = 0.1588797435881346
Trained batch 291 in epoch 1, gen_loss = 0.3797827649300229, disc_loss = 0.15870557549371295
Trained batch 292 in epoch 1, gen_loss = 0.37985506709728634, disc_loss = 0.15894759527754052
Trained batch 293 in epoch 1, gen_loss = 0.3796807082027805, disc_loss = 0.15924594270027415
Trained batch 294 in epoch 1, gen_loss = 0.379654089828669, disc_loss = 0.1590425496131687
Trained batch 295 in epoch 1, gen_loss = 0.3796124172875205, disc_loss = 0.15899128056559209
Trained batch 296 in epoch 1, gen_loss = 0.3796295482000518, disc_loss = 0.15877157168757636
Trained batch 297 in epoch 1, gen_loss = 0.3794128632285451, disc_loss = 0.15872559176395404
Trained batch 298 in epoch 1, gen_loss = 0.37938515243920995, disc_loss = 0.15876147086205689
Trained batch 299 in epoch 1, gen_loss = 0.3796281619369984, disc_loss = 0.15858892763654392
Trained batch 300 in epoch 1, gen_loss = 0.3797570704126675, disc_loss = 0.15829622295013693
Trained batch 301 in epoch 1, gen_loss = 0.37992914933834643, disc_loss = 0.157971104915371
Trained batch 302 in epoch 1, gen_loss = 0.380204364854117, disc_loss = 0.15765214106529066
Trained batch 303 in epoch 1, gen_loss = 0.38011394642097385, disc_loss = 0.1574018278747405
Trained batch 304 in epoch 1, gen_loss = 0.37988123498002035, disc_loss = 0.15749460461198306
Trained batch 305 in epoch 1, gen_loss = 0.3798452772054018, disc_loss = 0.15738534350313393
Trained batch 306 in epoch 1, gen_loss = 0.38001719335585543, disc_loss = 0.15729283866645458
Trained batch 307 in epoch 1, gen_loss = 0.3803328935105305, disc_loss = 0.15725729312118772
Trained batch 308 in epoch 1, gen_loss = 0.38030177735780824, disc_loss = 0.1572056588472672
Trained batch 309 in epoch 1, gen_loss = 0.3800678062342828, disc_loss = 0.15728650157970767
Trained batch 310 in epoch 1, gen_loss = 0.3800628338116925, disc_loss = 0.15712854630310819
Trained batch 311 in epoch 1, gen_loss = 0.3804070327239923, disc_loss = 0.1570917377487207
Trained batch 312 in epoch 1, gen_loss = 0.38015900799832025, disc_loss = 0.156872861111126
Trained batch 313 in epoch 1, gen_loss = 0.3800406329286326, disc_loss = 0.1577667332948393
Trained batch 314 in epoch 1, gen_loss = 0.38038657473193277, disc_loss = 0.15797215028414652
Trained batch 315 in epoch 1, gen_loss = 0.380460019117292, disc_loss = 0.15807870643425592
Trained batch 316 in epoch 1, gen_loss = 0.38033083969674275, disc_loss = 0.15800795424435793
Trained batch 317 in epoch 1, gen_loss = 0.38035522368531555, disc_loss = 0.1577260044854392
Trained batch 318 in epoch 1, gen_loss = 0.38039973803261606, disc_loss = 0.15749308880313437
Trained batch 319 in epoch 1, gen_loss = 0.3804393986705691, disc_loss = 0.15718001548666508
Trained batch 320 in epoch 1, gen_loss = 0.38036257023937603, disc_loss = 0.15709855597802783
Trained batch 321 in epoch 1, gen_loss = 0.38034887227767744, disc_loss = 0.15696894955931243
Trained batch 322 in epoch 1, gen_loss = 0.38035948076299836, disc_loss = 0.1570701770276846
Trained batch 323 in epoch 1, gen_loss = 0.38034387296180666, disc_loss = 0.15789114642474386
Trained batch 324 in epoch 1, gen_loss = 0.3803268976853444, disc_loss = 0.1583460958645894
Trained batch 325 in epoch 1, gen_loss = 0.38031817492714687, disc_loss = 0.15826658758283393
Trained batch 326 in epoch 1, gen_loss = 0.38031805085661946, disc_loss = 0.1581848680243944
Trained batch 327 in epoch 1, gen_loss = 0.380379254270981, disc_loss = 0.1581477048556979
Trained batch 328 in epoch 1, gen_loss = 0.3804099204239512, disc_loss = 0.15810343559752119
Trained batch 329 in epoch 1, gen_loss = 0.38045640258174956, disc_loss = 0.15880206281488593
Trained batch 330 in epoch 1, gen_loss = 0.38033622642838344, disc_loss = 0.15902040709721718
Trained batch 331 in epoch 1, gen_loss = 0.3805322869265654, disc_loss = 0.15898318871496672
Trained batch 332 in epoch 1, gen_loss = 0.3803670680648214, disc_loss = 0.15886355954426545
Trained batch 333 in epoch 1, gen_loss = 0.3802143010104488, disc_loss = 0.15881255041517897
Trained batch 334 in epoch 1, gen_loss = 0.3803448967524429, disc_loss = 0.15871846408986334
Trained batch 335 in epoch 1, gen_loss = 0.3804246968190585, disc_loss = 0.15844714198084103
Trained batch 336 in epoch 1, gen_loss = 0.3804520713911566, disc_loss = 0.15831567411164502
Trained batch 337 in epoch 1, gen_loss = 0.3805768976990993, disc_loss = 0.1581266439304902
Trained batch 338 in epoch 1, gen_loss = 0.38067609920086765, disc_loss = 0.1582621081256937
Trained batch 339 in epoch 1, gen_loss = 0.380799362019581, disc_loss = 0.1581319713855491
Trained batch 340 in epoch 1, gen_loss = 0.38077688125396403, disc_loss = 0.15807138772304458
Trained batch 341 in epoch 1, gen_loss = 0.3809630500904301, disc_loss = 0.15793570115813735
Trained batch 342 in epoch 1, gen_loss = 0.3809799601055095, disc_loss = 0.1577095079395931
Trained batch 343 in epoch 1, gen_loss = 0.38093777984207455, disc_loss = 0.15752578372958786
Trained batch 344 in epoch 1, gen_loss = 0.3808070057112238, disc_loss = 0.15728680720363838
Trained batch 345 in epoch 1, gen_loss = 0.38080438648517423, disc_loss = 0.15717303546177858
Trained batch 346 in epoch 1, gen_loss = 0.3811072918025492, disc_loss = 0.15689445244046385
Trained batch 347 in epoch 1, gen_loss = 0.3809531407709094, disc_loss = 0.15677332790332965
Trained batch 348 in epoch 1, gen_loss = 0.38127233924872556, disc_loss = 0.1571106745682678
Trained batch 349 in epoch 1, gen_loss = 0.3812044781020709, disc_loss = 0.15685932495764324
Trained batch 350 in epoch 1, gen_loss = 0.3810523502592348, disc_loss = 0.15663930351323213
Trained batch 351 in epoch 1, gen_loss = 0.38127676401795313, disc_loss = 0.15641472268510948
Trained batch 352 in epoch 1, gen_loss = 0.38140227609754623, disc_loss = 0.15612845862595623
Trained batch 353 in epoch 1, gen_loss = 0.3813574074604417, disc_loss = 0.15596656929596334
Trained batch 354 in epoch 1, gen_loss = 0.38157523412939526, disc_loss = 0.15574849868114565
Trained batch 355 in epoch 1, gen_loss = 0.38170882209800605, disc_loss = 0.15547268272618228
Trained batch 356 in epoch 1, gen_loss = 0.38167115190282924, disc_loss = 0.1554914333072363
Trained batch 357 in epoch 1, gen_loss = 0.3818298663590207, disc_loss = 0.15526591285064234
Trained batch 358 in epoch 1, gen_loss = 0.3818566363751058, disc_loss = 0.15510277460461538
Trained batch 359 in epoch 1, gen_loss = 0.3818434591508574, disc_loss = 0.1549824978121453
Trained batch 360 in epoch 1, gen_loss = 0.3820197597517531, disc_loss = 0.154735225822952
Trained batch 361 in epoch 1, gen_loss = 0.38211294897518105, disc_loss = 0.154449878137003
Trained batch 362 in epoch 1, gen_loss = 0.3822714002089724, disc_loss = 0.15445327790602836
Trained batch 363 in epoch 1, gen_loss = 0.3822240725896516, disc_loss = 0.15491563842150863
Trained batch 364 in epoch 1, gen_loss = 0.38206472041672224, disc_loss = 0.1547406775187956
Trained batch 365 in epoch 1, gen_loss = 0.38204029255388866, disc_loss = 0.1546450963376161
Trained batch 366 in epoch 1, gen_loss = 0.38246997196115656, disc_loss = 0.15446472897800828
Trained batch 367 in epoch 1, gen_loss = 0.38255982947252365, disc_loss = 0.15421344252789151
Trained batch 368 in epoch 1, gen_loss = 0.3828956901946365, disc_loss = 0.15429899744628892
Trained batch 369 in epoch 1, gen_loss = 0.3826872864687765, disc_loss = 0.15446916164175883
Trained batch 370 in epoch 1, gen_loss = 0.3828137456326472, disc_loss = 0.15447516267431394
Trained batch 371 in epoch 1, gen_loss = 0.382823743526974, disc_loss = 0.15433964405649453
Trained batch 372 in epoch 1, gen_loss = 0.38288249107372346, disc_loss = 0.15410311871655186
Trained batch 373 in epoch 1, gen_loss = 0.38297749494008204, disc_loss = 0.15390024989604312
Trained batch 374 in epoch 1, gen_loss = 0.3830530283053716, disc_loss = 0.15388518931468328
Trained batch 375 in epoch 1, gen_loss = 0.3832407750268566, disc_loss = 0.15395695167256795
Trained batch 376 in epoch 1, gen_loss = 0.38323705309423906, disc_loss = 0.15371029554256077
Trained batch 377 in epoch 1, gen_loss = 0.3831463715938664, disc_loss = 0.15342750786631196
Trained batch 378 in epoch 1, gen_loss = 0.3831946786522551, disc_loss = 0.15323460062764252
Trained batch 379 in epoch 1, gen_loss = 0.38331789503756325, disc_loss = 0.1534695397082128
Trained batch 380 in epoch 1, gen_loss = 0.38330343197493416, disc_loss = 0.15364320040374915
Trained batch 381 in epoch 1, gen_loss = 0.38329198523497704, disc_loss = 0.15376804804146602
Trained batch 382 in epoch 1, gen_loss = 0.38331653722428155, disc_loss = 0.15379044495270083
Trained batch 383 in epoch 1, gen_loss = 0.38337807601783425, disc_loss = 0.15366292434434095
Trained batch 384 in epoch 1, gen_loss = 0.3834932180581155, disc_loss = 0.153495106217149
Trained batch 385 in epoch 1, gen_loss = 0.3833697158360728, disc_loss = 0.1532576392776299
Trained batch 386 in epoch 1, gen_loss = 0.38343687709757834, disc_loss = 0.1530008043910952
Trained batch 387 in epoch 1, gen_loss = 0.3832863964447656, disc_loss = 0.152744313327538
Trained batch 388 in epoch 1, gen_loss = 0.38339764642071905, disc_loss = 0.15262533529903405
Trained batch 389 in epoch 1, gen_loss = 0.38323390059746226, disc_loss = 0.15269028197687406
Trained batch 390 in epoch 1, gen_loss = 0.38323318032200077, disc_loss = 0.15250252750333007
Trained batch 391 in epoch 1, gen_loss = 0.38313538022339344, disc_loss = 0.15224074308133248
Trained batch 392 in epoch 1, gen_loss = 0.3833299774780832, disc_loss = 0.15202210329795307
Trained batch 393 in epoch 1, gen_loss = 0.3837699915476257, disc_loss = 0.1519440018623916
Trained batch 394 in epoch 1, gen_loss = 0.3840035995727853, disc_loss = 0.15173822501792184
Trained batch 395 in epoch 1, gen_loss = 0.38392258552138253, disc_loss = 0.15143729382279245
Trained batch 396 in epoch 1, gen_loss = 0.3839454429801225, disc_loss = 0.15110777312847468
Trained batch 397 in epoch 1, gen_loss = 0.38397513932768423, disc_loss = 0.15084622483045312
Trained batch 398 in epoch 1, gen_loss = 0.38400803215073465, disc_loss = 0.15069598834354775
Trained batch 399 in epoch 1, gen_loss = 0.3838296792283654, disc_loss = 0.15066934057511389
Trained batch 400 in epoch 1, gen_loss = 0.3839028648233176, disc_loss = 0.15041001805306373
Trained batch 401 in epoch 1, gen_loss = 0.3839743257087855, disc_loss = 0.15013290563626075
Trained batch 402 in epoch 1, gen_loss = 0.38406808474667314, disc_loss = 0.1501669129795827
Trained batch 403 in epoch 1, gen_loss = 0.38412648974226254, disc_loss = 0.15023149830279964
Trained batch 404 in epoch 1, gen_loss = 0.3841073433926076, disc_loss = 0.15008388069676765
Trained batch 405 in epoch 1, gen_loss = 0.3842121757970655, disc_loss = 0.14984683183209943
Trained batch 406 in epoch 1, gen_loss = 0.3841574458217738, disc_loss = 0.14985426605955973
Trained batch 407 in epoch 1, gen_loss = 0.38434078277764366, disc_loss = 0.15012158713686993
Trained batch 408 in epoch 1, gen_loss = 0.38420977550934465, disc_loss = 0.15004673240419414
Trained batch 409 in epoch 1, gen_loss = 0.3841772940464136, disc_loss = 0.14975912376511388
Trained batch 410 in epoch 1, gen_loss = 0.38412064143485974, disc_loss = 0.1496479470835695
Trained batch 411 in epoch 1, gen_loss = 0.3839459157033453, disc_loss = 0.1498351938552359
Trained batch 412 in epoch 1, gen_loss = 0.38404941815007976, disc_loss = 0.14973357884488442
Trained batch 413 in epoch 1, gen_loss = 0.38407530376444693, disc_loss = 0.14953447127903718
Trained batch 414 in epoch 1, gen_loss = 0.38418279624128915, disc_loss = 0.14932128170348075
Trained batch 415 in epoch 1, gen_loss = 0.38422307898648655, disc_loss = 0.1490908334067521
Trained batch 416 in epoch 1, gen_loss = 0.38426950198712106, disc_loss = 0.1489316929730294
Trained batch 417 in epoch 1, gen_loss = 0.3842304365700512, disc_loss = 0.14871424211091117
Trained batch 418 in epoch 1, gen_loss = 0.3841246765169153, disc_loss = 0.14859765683587525
Trained batch 419 in epoch 1, gen_loss = 0.38432341562140554, disc_loss = 0.14894453188670534
Trained batch 420 in epoch 1, gen_loss = 0.38418215460137345, disc_loss = 0.1488402785374971
Trained batch 421 in epoch 1, gen_loss = 0.3841311655126477, disc_loss = 0.14908076873075624
Trained batch 422 in epoch 1, gen_loss = 0.38461706658768036, disc_loss = 0.14908872351895833
Trained batch 423 in epoch 1, gen_loss = 0.38473664297950716, disc_loss = 0.14884174314661408
Trained batch 424 in epoch 1, gen_loss = 0.38459891182534833, disc_loss = 0.14876446343520108
Trained batch 425 in epoch 1, gen_loss = 0.3846247121691704, disc_loss = 0.148558188054903
Trained batch 426 in epoch 1, gen_loss = 0.3847046515771321, disc_loss = 0.14863581824567892
Trained batch 427 in epoch 1, gen_loss = 0.3847149145728517, disc_loss = 0.14887496395576222
Trained batch 428 in epoch 1, gen_loss = 0.3850052843352298, disc_loss = 0.14881242688371862
Trained batch 429 in epoch 1, gen_loss = 0.38498951706082324, disc_loss = 0.14861757154035013
Trained batch 430 in epoch 1, gen_loss = 0.38494988988972595, disc_loss = 0.14839101447064748
Trained batch 431 in epoch 1, gen_loss = 0.3850492358690611, disc_loss = 0.14824987921208418
Trained batch 432 in epoch 1, gen_loss = 0.38506600092107096, disc_loss = 0.1480609514507493
Trained batch 433 in epoch 1, gen_loss = 0.38515654944467104, disc_loss = 0.14776240931265913
Trained batch 434 in epoch 1, gen_loss = 0.38522239639156164, disc_loss = 0.14750508791071246
Trained batch 435 in epoch 1, gen_loss = 0.3852528308031209, disc_loss = 0.14731084599817565
Trained batch 436 in epoch 1, gen_loss = 0.3852460983484233, disc_loss = 0.14717746224228795
Trained batch 437 in epoch 1, gen_loss = 0.38522647624010364, disc_loss = 0.1471910608005306
Trained batch 438 in epoch 1, gen_loss = 0.3855324236502137, disc_loss = 0.14721533886935553
Trained batch 439 in epoch 1, gen_loss = 0.3856140457432378, disc_loss = 0.14717311547561127
Trained batch 440 in epoch 1, gen_loss = 0.3858276822872443, disc_loss = 0.14695784073669355
Trained batch 441 in epoch 1, gen_loss = 0.3860044709630142, disc_loss = 0.14667192022252945
Trained batch 442 in epoch 1, gen_loss = 0.38597098911185296, disc_loss = 0.1464547254565607
Trained batch 443 in epoch 1, gen_loss = 0.38614449955455893, disc_loss = 0.14633716736827884
Trained batch 444 in epoch 1, gen_loss = 0.3865481296616994, disc_loss = 0.14606305102535178
Trained batch 445 in epoch 1, gen_loss = 0.3866495541192491, disc_loss = 0.1458469536614859
Trained batch 446 in epoch 1, gen_loss = 0.3866760165032658, disc_loss = 0.14578563683735044
Trained batch 447 in epoch 1, gen_loss = 0.38687769094082924, disc_loss = 0.14561583910420137
Trained batch 448 in epoch 1, gen_loss = 0.38676891265175656, disc_loss = 0.14540795412304539
Trained batch 449 in epoch 1, gen_loss = 0.38677371723784343, disc_loss = 0.14567858998560243
Trained batch 450 in epoch 1, gen_loss = 0.386572602880239, disc_loss = 0.14593108277148392
Trained batch 451 in epoch 1, gen_loss = 0.38673088960019886, disc_loss = 0.14614794622134186
Trained batch 452 in epoch 1, gen_loss = 0.38659559933686627, disc_loss = 0.14626656664703988
Trained batch 453 in epoch 1, gen_loss = 0.38666768145587477, disc_loss = 0.1460869340964548
Trained batch 454 in epoch 1, gen_loss = 0.386790848662565, disc_loss = 0.1459995246645841
Trained batch 455 in epoch 1, gen_loss = 0.38685236678442414, disc_loss = 0.14592046826146543
Trained batch 456 in epoch 1, gen_loss = 0.3869304570575251, disc_loss = 0.1458687158484884
Trained batch 457 in epoch 1, gen_loss = 0.387076191669208, disc_loss = 0.14582563604443743
Trained batch 458 in epoch 1, gen_loss = 0.3870899332180002, disc_loss = 0.14617238006674257
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 0.24545449018478394, disc_loss = 0.3878439664840698
Trained batch 1 in epoch 2, gen_loss = 0.3155297636985779, disc_loss = 0.3604576736688614
Trained batch 2 in epoch 2, gen_loss = 0.344148983558019, disc_loss = 0.29682430624961853
Trained batch 3 in epoch 2, gen_loss = 0.3438783437013626, disc_loss = 0.2684219256043434
Trained batch 4 in epoch 2, gen_loss = 0.3422617733478546, disc_loss = 0.2561489224433899
Trained batch 5 in epoch 2, gen_loss = 0.3437806119521459, disc_loss = 0.2483281989892324
Trained batch 6 in epoch 2, gen_loss = 0.35153373224394663, disc_loss = 0.2504176838057382
Trained batch 7 in epoch 2, gen_loss = 0.3534730449318886, disc_loss = 0.24330636113882065
Trained batch 8 in epoch 2, gen_loss = 0.35067857305208844, disc_loss = 0.23588739335536957
Trained batch 9 in epoch 2, gen_loss = 0.35417269468307494, disc_loss = 0.23073384165763855
Trained batch 10 in epoch 2, gen_loss = 0.3575754734602841, disc_loss = 0.22663560780611905
Trained batch 11 in epoch 2, gen_loss = 0.3591710552573204, disc_loss = 0.22006850317120552
Trained batch 12 in epoch 2, gen_loss = 0.36113828191390407, disc_loss = 0.20928761821526748
Trained batch 13 in epoch 2, gen_loss = 0.3629569411277771, disc_loss = 0.2001071684062481
Trained batch 14 in epoch 2, gen_loss = 0.36771041750907896, disc_loss = 0.1933507685859998
Trained batch 15 in epoch 2, gen_loss = 0.3663055319339037, disc_loss = 0.18880720157176256
Trained batch 16 in epoch 2, gen_loss = 0.37238793162738576, disc_loss = 0.18418856008964427
Trained batch 17 in epoch 2, gen_loss = 0.3744649671845966, disc_loss = 0.1777148594458898
Trained batch 18 in epoch 2, gen_loss = 0.3746104742351331, disc_loss = 0.1738071767123122
Trained batch 19 in epoch 2, gen_loss = 0.37335697561502457, disc_loss = 0.17299374677240847
Trained batch 20 in epoch 2, gen_loss = 0.37550791246550425, disc_loss = 0.17600725910493306
Trained batch 21 in epoch 2, gen_loss = 0.3745550648732619, disc_loss = 0.17458462003957143
Trained batch 22 in epoch 2, gen_loss = 0.3755233689494755, disc_loss = 0.1702551893565966
Trained batch 23 in epoch 2, gen_loss = 0.3783633013566335, disc_loss = 0.16836126800626516
Trained batch 24 in epoch 2, gen_loss = 0.3798756635189056, disc_loss = 0.16668543726205826
Trained batch 25 in epoch 2, gen_loss = 0.38304418325424194, disc_loss = 0.1625632132188632
Trained batch 26 in epoch 2, gen_loss = 0.3859337623472567, disc_loss = 0.16407863450823007
Trained batch 27 in epoch 2, gen_loss = 0.3862739758832114, disc_loss = 0.16689129745853798
Trained batch 28 in epoch 2, gen_loss = 0.38691197489870005, disc_loss = 0.16338641569018364
Trained batch 29 in epoch 2, gen_loss = 0.38660682340463004, disc_loss = 0.16396503932774067
Trained batch 30 in epoch 2, gen_loss = 0.38541176819032236, disc_loss = 0.1669900983331665
Trained batch 31 in epoch 2, gen_loss = 0.38435179740190506, disc_loss = 0.16695322550367564
Trained batch 32 in epoch 2, gen_loss = 0.384133955745986, disc_loss = 0.1648063590806542
Trained batch 33 in epoch 2, gen_loss = 0.3833487428286496, disc_loss = 0.16516881994903088
Trained batch 34 in epoch 2, gen_loss = 0.3820942529610225, disc_loss = 0.16342277537499156
Trained batch 35 in epoch 2, gen_loss = 0.3848445076081488, disc_loss = 0.1613095828021566
Trained batch 36 in epoch 2, gen_loss = 0.383936410820162, disc_loss = 0.15959541066675573
Trained batch 37 in epoch 2, gen_loss = 0.3851126275564495, disc_loss = 0.15762677131906935
Trained batch 38 in epoch 2, gen_loss = 0.3848409599218613, disc_loss = 0.15785193643890894
Trained batch 39 in epoch 2, gen_loss = 0.3851809374988079, disc_loss = 0.15622460367158056
Trained batch 40 in epoch 2, gen_loss = 0.38529805366585895, disc_loss = 0.15332870158116993
Trained batch 41 in epoch 2, gen_loss = 0.3851393340598969, disc_loss = 0.15416648992825122
Trained batch 42 in epoch 2, gen_loss = 0.3850453946479531, disc_loss = 0.15480472329397535
Trained batch 43 in epoch 2, gen_loss = 0.3882428536360914, disc_loss = 0.1531822963363745
Trained batch 44 in epoch 2, gen_loss = 0.3885947797033522, disc_loss = 0.15288640765680206
Trained batch 45 in epoch 2, gen_loss = 0.3878107271764589, disc_loss = 0.15853785148457342
Trained batch 46 in epoch 2, gen_loss = 0.3879874329617683, disc_loss = 0.15685800676967235
Trained batch 47 in epoch 2, gen_loss = 0.38782125773529214, disc_loss = 0.15580618854922554
Trained batch 48 in epoch 2, gen_loss = 0.38738944396680713, disc_loss = 0.15558544934100035
Trained batch 49 in epoch 2, gen_loss = 0.38764865696430206, disc_loss = 0.15462415613234043
Trained batch 50 in epoch 2, gen_loss = 0.38976670772421596, disc_loss = 0.15397673984076463
Trained batch 51 in epoch 2, gen_loss = 0.3896884620189667, disc_loss = 0.15341051417188004
Trained batch 52 in epoch 2, gen_loss = 0.3895773212864714, disc_loss = 0.15311572215748284
Trained batch 53 in epoch 2, gen_loss = 0.38908384133268287, disc_loss = 0.1520169622230309
Trained batch 54 in epoch 2, gen_loss = 0.3896829204125838, disc_loss = 0.14979278485883366
Trained batch 55 in epoch 2, gen_loss = 0.38992550117628916, disc_loss = 0.14755403805923248
Trained batch 56 in epoch 2, gen_loss = 0.39056573677481266, disc_loss = 0.14621895979763122
Trained batch 57 in epoch 2, gen_loss = 0.38989614875152195, disc_loss = 0.14490995861204534
Trained batch 58 in epoch 2, gen_loss = 0.390220675933159, disc_loss = 0.1428701525585631
Trained batch 59 in epoch 2, gen_loss = 0.39154952218135197, disc_loss = 0.1408540970335404
Trained batch 60 in epoch 2, gen_loss = 0.39186962510718676, disc_loss = 0.1406064100685667
Trained batch 61 in epoch 2, gen_loss = 0.3916658715855691, disc_loss = 0.14346226412923105
Trained batch 62 in epoch 2, gen_loss = 0.3927770148194025, disc_loss = 0.14210786587662166
Trained batch 63 in epoch 2, gen_loss = 0.39299293840304017, disc_loss = 0.1405171799706295
Trained batch 64 in epoch 2, gen_loss = 0.39326798824163584, disc_loss = 0.14142175832620033
Trained batch 65 in epoch 2, gen_loss = 0.3942731492447131, disc_loss = 0.1402181831160278
Trained batch 66 in epoch 2, gen_loss = 0.3938996235826122, disc_loss = 0.13877644295345493
Trained batch 67 in epoch 2, gen_loss = 0.39433027672417026, disc_loss = 0.13759244759293163
Trained batch 68 in epoch 2, gen_loss = 0.3946756984012714, disc_loss = 0.13633205482493277
Trained batch 69 in epoch 2, gen_loss = 0.3937393763235637, disc_loss = 0.13729453352945192
Trained batch 70 in epoch 2, gen_loss = 0.39505651047531987, disc_loss = 0.14134139210825236
Trained batch 71 in epoch 2, gen_loss = 0.39353246324592167, disc_loss = 0.14238218932102123
Trained batch 72 in epoch 2, gen_loss = 0.3933267479073511, disc_loss = 0.14173356749831814
Trained batch 73 in epoch 2, gen_loss = 0.393946517158199, disc_loss = 0.14090675931121852
Trained batch 74 in epoch 2, gen_loss = 0.394319589138031, disc_loss = 0.1401225327452024
Trained batch 75 in epoch 2, gen_loss = 0.394835622294953, disc_loss = 0.13895482373865028
Trained batch 76 in epoch 2, gen_loss = 0.3949612568725239, disc_loss = 0.13865594720685637
Trained batch 77 in epoch 2, gen_loss = 0.39467952381341886, disc_loss = 0.13810771818344408
Trained batch 78 in epoch 2, gen_loss = 0.3954890438272983, disc_loss = 0.13894393040409572
Trained batch 79 in epoch 2, gen_loss = 0.39445101767778395, disc_loss = 0.14058892894536257
Trained batch 80 in epoch 2, gen_loss = 0.39436779235616143, disc_loss = 0.13975073792684226
Trained batch 81 in epoch 2, gen_loss = 0.3950392011462188, disc_loss = 0.13975887809221338
Trained batch 82 in epoch 2, gen_loss = 0.39499796478145094, disc_loss = 0.14091921884970493
Trained batch 83 in epoch 2, gen_loss = 0.3948578451360975, disc_loss = 0.1456499613289322
Trained batch 84 in epoch 2, gen_loss = 0.3940025813439313, disc_loss = 0.14459147501517744
Trained batch 85 in epoch 2, gen_loss = 0.3947323252295339, disc_loss = 0.14343183115124702
Trained batch 86 in epoch 2, gen_loss = 0.3948597863487814, disc_loss = 0.14277159045825058
Trained batch 87 in epoch 2, gen_loss = 0.3954292603514411, disc_loss = 0.14241146186197345
Trained batch 88 in epoch 2, gen_loss = 0.39523209983043456, disc_loss = 0.14254179086243168
Trained batch 89 in epoch 2, gen_loss = 0.3958371056450738, disc_loss = 0.1415790477146705
Trained batch 90 in epoch 2, gen_loss = 0.3965213004049364, disc_loss = 0.14095717705376856
Trained batch 91 in epoch 2, gen_loss = 0.3965944048503171, disc_loss = 0.14175594780270173
Trained batch 92 in epoch 2, gen_loss = 0.3961491607209688, disc_loss = 0.14444675709130944
Trained batch 93 in epoch 2, gen_loss = 0.3950228237725319, disc_loss = 0.14573620977078347
Trained batch 94 in epoch 2, gen_loss = 0.3947043406335931, disc_loss = 0.14595407204408395
Trained batch 95 in epoch 2, gen_loss = 0.3948513846844435, disc_loss = 0.1471098669571802
Trained batch 96 in epoch 2, gen_loss = 0.3941350373410687, disc_loss = 0.1468925150783406
Trained batch 97 in epoch 2, gen_loss = 0.39433618193986464, disc_loss = 0.14664332253136197
Trained batch 98 in epoch 2, gen_loss = 0.3939672133537254, disc_loss = 0.1462768381367428
Trained batch 99 in epoch 2, gen_loss = 0.39387003004550936, disc_loss = 0.1455876173451543
Trained batch 100 in epoch 2, gen_loss = 0.39413469439685933, disc_loss = 0.14470542506268708
Trained batch 101 in epoch 2, gen_loss = 0.39359672309136856, disc_loss = 0.14404327272638387
Trained batch 102 in epoch 2, gen_loss = 0.3941904037322813, disc_loss = 0.14312059898833626
Trained batch 103 in epoch 2, gen_loss = 0.39448750334290356, disc_loss = 0.14458089490206197
Trained batch 104 in epoch 2, gen_loss = 0.3933504416829064, disc_loss = 0.14473566693209466
Trained batch 105 in epoch 2, gen_loss = 0.3931353823193964, disc_loss = 0.1444131287412261
Trained batch 106 in epoch 2, gen_loss = 0.3928278127563334, disc_loss = 0.1438394895989761
Trained batch 107 in epoch 2, gen_loss = 0.392502428204925, disc_loss = 0.14319558100154003
Trained batch 108 in epoch 2, gen_loss = 0.39211807912642804, disc_loss = 0.1426098342950738
Trained batch 109 in epoch 2, gen_loss = 0.3921722864562815, disc_loss = 0.14297562881626866
Trained batch 110 in epoch 2, gen_loss = 0.39228732414073775, disc_loss = 0.1435344112147619
Trained batch 111 in epoch 2, gen_loss = 0.39245533091681345, disc_loss = 0.1438253884137209
Trained batch 112 in epoch 2, gen_loss = 0.3922240114317531, disc_loss = 0.14316047784105868
Trained batch 113 in epoch 2, gen_loss = 0.3926284924933785, disc_loss = 0.14275557309258402
Trained batch 114 in epoch 2, gen_loss = 0.39214193224906924, disc_loss = 0.14245006911780522
Trained batch 115 in epoch 2, gen_loss = 0.3922490567482751, disc_loss = 0.14297404207674594
Trained batch 116 in epoch 2, gen_loss = 0.3924381929075616, disc_loss = 0.14258260856199467
Trained batch 117 in epoch 2, gen_loss = 0.39217878170942855, disc_loss = 0.1417558525641591
Trained batch 118 in epoch 2, gen_loss = 0.39267414983581095, disc_loss = 0.1414585924636917
Trained batch 119 in epoch 2, gen_loss = 0.3926473801334699, disc_loss = 0.14118951624259352
Trained batch 120 in epoch 2, gen_loss = 0.39196515280353134, disc_loss = 0.14093563370098752
Trained batch 121 in epoch 2, gen_loss = 0.39196321661355066, disc_loss = 0.13986710338380004
Trained batch 122 in epoch 2, gen_loss = 0.3918292105682497, disc_loss = 0.1393391323556018
Trained batch 123 in epoch 2, gen_loss = 0.39152469534066414, disc_loss = 0.13890568138430676
Trained batch 124 in epoch 2, gen_loss = 0.3915826303958893, disc_loss = 0.13838889552652836
Trained batch 125 in epoch 2, gen_loss = 0.39189765401302823, disc_loss = 0.13935464882247506
Trained batch 126 in epoch 2, gen_loss = 0.39181096323831816, disc_loss = 0.1410965494899534
Trained batch 127 in epoch 2, gen_loss = 0.39182943757623434, disc_loss = 0.1411813454615185
Trained batch 128 in epoch 2, gen_loss = 0.39189182372056236, disc_loss = 0.14070965079662873
Trained batch 129 in epoch 2, gen_loss = 0.39135711445258214, disc_loss = 0.14086722543892952
Trained batch 130 in epoch 2, gen_loss = 0.3911323740737129, disc_loss = 0.14044675687399075
Trained batch 131 in epoch 2, gen_loss = 0.3913736679788792, disc_loss = 0.14062848214455176
Trained batch 132 in epoch 2, gen_loss = 0.39123033356845827, disc_loss = 0.1403547670075992
Trained batch 133 in epoch 2, gen_loss = 0.391258626731474, disc_loss = 0.14000923265772525
Trained batch 134 in epoch 2, gen_loss = 0.39161564420770717, disc_loss = 0.13964421982290567
Trained batch 135 in epoch 2, gen_loss = 0.3919482393299832, disc_loss = 0.1390102728790439
Trained batch 136 in epoch 2, gen_loss = 0.39207142634983483, disc_loss = 0.13844416699759718
Trained batch 137 in epoch 2, gen_loss = 0.39219053219194, disc_loss = 0.13788633209153794
Trained batch 138 in epoch 2, gen_loss = 0.39280915281755463, disc_loss = 0.13759590941313787
Trained batch 139 in epoch 2, gen_loss = 0.3929576450160572, disc_loss = 0.13949474126898817
Trained batch 140 in epoch 2, gen_loss = 0.39311230182647705, disc_loss = 0.13929507837809146
Trained batch 141 in epoch 2, gen_loss = 0.3928509778539899, disc_loss = 0.13908786162681563
Trained batch 142 in epoch 2, gen_loss = 0.39262301375815917, disc_loss = 0.13930603271754055
Trained batch 143 in epoch 2, gen_loss = 0.3918151304953628, disc_loss = 0.13996799749373975
Trained batch 144 in epoch 2, gen_loss = 0.39283538029111664, disc_loss = 0.14107228768026006
Trained batch 145 in epoch 2, gen_loss = 0.3926930029506553, disc_loss = 0.1408352485845146
Trained batch 146 in epoch 2, gen_loss = 0.3925236650064689, disc_loss = 0.1403651250032138
Trained batch 147 in epoch 2, gen_loss = 0.3921229891680382, disc_loss = 0.1397268701017507
Trained batch 148 in epoch 2, gen_loss = 0.392242336833237, disc_loss = 0.1396748394949124
Trained batch 149 in epoch 2, gen_loss = 0.3922137105464935, disc_loss = 0.14120557937771083
Trained batch 150 in epoch 2, gen_loss = 0.39226866360531737, disc_loss = 0.14100126126497392
Trained batch 151 in epoch 2, gen_loss = 0.3920595420426444, disc_loss = 0.14033222069816761
Trained batch 152 in epoch 2, gen_loss = 0.39278367824024624, disc_loss = 0.14021629040293834
Trained batch 153 in epoch 2, gen_loss = 0.3926746191142441, disc_loss = 0.13972652020150578
Trained batch 154 in epoch 2, gen_loss = 0.39258001235223583, disc_loss = 0.13917829003785886
Trained batch 155 in epoch 2, gen_loss = 0.39241445465729785, disc_loss = 0.1388955579425853
Trained batch 156 in epoch 2, gen_loss = 0.3920482522363116, disc_loss = 0.1387337898823676
Trained batch 157 in epoch 2, gen_loss = 0.39209916018232516, disc_loss = 0.13882890861198494
Trained batch 158 in epoch 2, gen_loss = 0.3924936534098859, disc_loss = 0.1383886646901099
Trained batch 159 in epoch 2, gen_loss = 0.39216853566467763, disc_loss = 0.13766866283258422
Trained batch 160 in epoch 2, gen_loss = 0.3922996615400966, disc_loss = 0.13715731786413593
Trained batch 161 in epoch 2, gen_loss = 0.39195173224549235, disc_loss = 0.13749036968996128
Trained batch 162 in epoch 2, gen_loss = 0.3920299003094983, disc_loss = 0.13925628084118016
Trained batch 163 in epoch 2, gen_loss = 0.3916140551247248, disc_loss = 0.1404929375843849
Trained batch 164 in epoch 2, gen_loss = 0.391534872488542, disc_loss = 0.1405118805328102
Trained batch 165 in epoch 2, gen_loss = 0.3911753041916583, disc_loss = 0.14022884386625276
Trained batch 166 in epoch 2, gen_loss = 0.39096161740982605, disc_loss = 0.14005437447594668
Trained batch 167 in epoch 2, gen_loss = 0.39072637135783833, disc_loss = 0.13990791380361078
Trained batch 168 in epoch 2, gen_loss = 0.3908221522379204, disc_loss = 0.14018128387982676
Trained batch 169 in epoch 2, gen_loss = 0.39090169580543743, disc_loss = 0.14031581158804543
Trained batch 170 in epoch 2, gen_loss = 0.3913754679654774, disc_loss = 0.13988844940319048
Trained batch 171 in epoch 2, gen_loss = 0.39158222252546354, disc_loss = 0.13951039993269151
Trained batch 172 in epoch 2, gen_loss = 0.39194261131948127, disc_loss = 0.13969333533391443
Trained batch 173 in epoch 2, gen_loss = 0.39232521290066596, disc_loss = 0.14056052099485164
Trained batch 174 in epoch 2, gen_loss = 0.3926918116637639, disc_loss = 0.1400629785550492
Trained batch 175 in epoch 2, gen_loss = 0.3928873007270423, disc_loss = 0.13960907649545168
Trained batch 176 in epoch 2, gen_loss = 0.3929412008005347, disc_loss = 0.13907838382332002
Trained batch 177 in epoch 2, gen_loss = 0.39276615990681596, disc_loss = 0.13865993625034442
Trained batch 178 in epoch 2, gen_loss = 0.3931831213016084, disc_loss = 0.13853145512497292
Trained batch 179 in epoch 2, gen_loss = 0.39287527584367327, disc_loss = 0.13852349164792233
Trained batch 180 in epoch 2, gen_loss = 0.39254186479426223, disc_loss = 0.13815666678572558
Trained batch 181 in epoch 2, gen_loss = 0.3924046469913734, disc_loss = 0.13801993860525416
Trained batch 182 in epoch 2, gen_loss = 0.39192256706008494, disc_loss = 0.13848218424601957
Trained batch 183 in epoch 2, gen_loss = 0.3923866311493127, disc_loss = 0.13865861868607285
Trained batch 184 in epoch 2, gen_loss = 0.3926858038515658, disc_loss = 0.13816439166060976
Trained batch 185 in epoch 2, gen_loss = 0.392603355870452, disc_loss = 0.137837192854814
Trained batch 186 in epoch 2, gen_loss = 0.3928427670728714, disc_loss = 0.1372230429959329
Trained batch 187 in epoch 2, gen_loss = 0.39333762212636625, disc_loss = 0.13703110509928554
Trained batch 188 in epoch 2, gen_loss = 0.39330991850328195, disc_loss = 0.13671855018449525
Trained batch 189 in epoch 2, gen_loss = 0.39317470349763567, disc_loss = 0.13668687866118392
Trained batch 190 in epoch 2, gen_loss = 0.39300088186538656, disc_loss = 0.13686510363681467
Trained batch 191 in epoch 2, gen_loss = 0.3933454131086667, disc_loss = 0.13760941045863243
Trained batch 192 in epoch 2, gen_loss = 0.3933019781668569, disc_loss = 0.13769682744817105
Trained batch 193 in epoch 2, gen_loss = 0.39366348901974785, disc_loss = 0.1374249939240285
Trained batch 194 in epoch 2, gen_loss = 0.3939505757429661, disc_loss = 0.1370849151355334
Trained batch 195 in epoch 2, gen_loss = 0.3935691172979316, disc_loss = 0.13664678399622135
Trained batch 196 in epoch 2, gen_loss = 0.3934528016802018, disc_loss = 0.13643299250244187
Trained batch 197 in epoch 2, gen_loss = 0.393623288683217, disc_loss = 0.13607358186496327
Trained batch 198 in epoch 2, gen_loss = 0.39359062910079956, disc_loss = 0.1357310940628525
Trained batch 199 in epoch 2, gen_loss = 0.3933387359976768, disc_loss = 0.13591660826466978
Trained batch 200 in epoch 2, gen_loss = 0.39380197931284927, disc_loss = 0.13559122523524572
Trained batch 201 in epoch 2, gen_loss = 0.3941789799102462, disc_loss = 0.1351216805102949
Trained batch 202 in epoch 2, gen_loss = 0.3939439321092784, disc_loss = 0.13486062534373675
Trained batch 203 in epoch 2, gen_loss = 0.39431488426292644, disc_loss = 0.13441367714903227
Trained batch 204 in epoch 2, gen_loss = 0.3941935735504802, disc_loss = 0.1341440909246846
Trained batch 205 in epoch 2, gen_loss = 0.3938099914094777, disc_loss = 0.13440148703283766
Trained batch 206 in epoch 2, gen_loss = 0.3934149049618394, disc_loss = 0.13559083097978777
Trained batch 207 in epoch 2, gen_loss = 0.3930594388108987, disc_loss = 0.13562896952498704
Trained batch 208 in epoch 2, gen_loss = 0.39320122739344693, disc_loss = 0.13542968178230325
Trained batch 209 in epoch 2, gen_loss = 0.3928820891039712, disc_loss = 0.13502333184615486
Trained batch 210 in epoch 2, gen_loss = 0.392855794932605, disc_loss = 0.13473140835867956
Trained batch 211 in epoch 2, gen_loss = 0.3923815543640335, disc_loss = 0.13450974966662954
Trained batch 212 in epoch 2, gen_loss = 0.3922966785833869, disc_loss = 0.13452699762100065
Trained batch 213 in epoch 2, gen_loss = 0.39257647361710807, disc_loss = 0.13560223199044155
Trained batch 214 in epoch 2, gen_loss = 0.3925786125105481, disc_loss = 0.13543228280925473
Trained batch 215 in epoch 2, gen_loss = 0.3923206653583933, disc_loss = 0.13558790497309356
Trained batch 216 in epoch 2, gen_loss = 0.39231826811342196, disc_loss = 0.13565375359754683
Trained batch 217 in epoch 2, gen_loss = 0.39252453140162546, disc_loss = 0.13533659996208522
Trained batch 218 in epoch 2, gen_loss = 0.3925765703802239, disc_loss = 0.13496829563386092
Trained batch 219 in epoch 2, gen_loss = 0.39250640164722095, disc_loss = 0.13465744501657106
Trained batch 220 in epoch 2, gen_loss = 0.39258099910360655, disc_loss = 0.13424394853682808
Trained batch 221 in epoch 2, gen_loss = 0.3928343030783507, disc_loss = 0.13383007426284724
Trained batch 222 in epoch 2, gen_loss = 0.3929258229486611, disc_loss = 0.13383054560376123
Trained batch 223 in epoch 2, gen_loss = 0.39340428316167425, disc_loss = 0.13449557445710525
Trained batch 224 in epoch 2, gen_loss = 0.39302057094044157, disc_loss = 0.13448294137087133
Trained batch 225 in epoch 2, gen_loss = 0.3928798446349338, disc_loss = 0.1344252603985699
Trained batch 226 in epoch 2, gen_loss = 0.39289043377674626, disc_loss = 0.13436374462944034
Trained batch 227 in epoch 2, gen_loss = 0.39280311841713755, disc_loss = 0.13417844890143005
Trained batch 228 in epoch 2, gen_loss = 0.39268460466351574, disc_loss = 0.1339111628507032
Trained batch 229 in epoch 2, gen_loss = 0.39250025166117625, disc_loss = 0.1338628452838115
Trained batch 230 in epoch 2, gen_loss = 0.3921290784429162, disc_loss = 0.13395960197594517
Trained batch 231 in epoch 2, gen_loss = 0.39234040780314083, disc_loss = 0.1338633071904167
Trained batch 232 in epoch 2, gen_loss = 0.3925105026351536, disc_loss = 0.1334705667514274
Trained batch 233 in epoch 2, gen_loss = 0.3922832210858663, disc_loss = 0.13307333324486628
Trained batch 234 in epoch 2, gen_loss = 0.39251148244167894, disc_loss = 0.13285591818709322
Trained batch 235 in epoch 2, gen_loss = 0.39238427819336874, disc_loss = 0.13266349417331108
Trained batch 236 in epoch 2, gen_loss = 0.39213521810020574, disc_loss = 0.13224081478950092
Trained batch 237 in epoch 2, gen_loss = 0.39248946284045694, disc_loss = 0.13189196045815693
Trained batch 238 in epoch 2, gen_loss = 0.3925672250811525, disc_loss = 0.13153368176183192
Trained batch 239 in epoch 2, gen_loss = 0.39284938300649325, disc_loss = 0.13118529230511436
Trained batch 240 in epoch 2, gen_loss = 0.39286532676566194, disc_loss = 0.13076370915096577
Trained batch 241 in epoch 2, gen_loss = 0.39303547414866363, disc_loss = 0.13028480027886954
Trained batch 242 in epoch 2, gen_loss = 0.39354569602895667, disc_loss = 0.13022206955179266
Trained batch 243 in epoch 2, gen_loss = 0.3935366743167893, disc_loss = 0.13085427494017315
Trained batch 244 in epoch 2, gen_loss = 0.3936580335607334, disc_loss = 0.1310751442246291
Trained batch 245 in epoch 2, gen_loss = 0.3935351686749032, disc_loss = 0.13091065920889378
Trained batch 246 in epoch 2, gen_loss = 0.39347152442102007, disc_loss = 0.13093241667638905
Trained batch 247 in epoch 2, gen_loss = 0.3936749983939432, disc_loss = 0.13059772579600254
Trained batch 248 in epoch 2, gen_loss = 0.3939440917059121, disc_loss = 0.13011187705469418
Trained batch 249 in epoch 2, gen_loss = 0.39393046939373016, disc_loss = 0.1297098391354084
Trained batch 250 in epoch 2, gen_loss = 0.3940824233440764, disc_loss = 0.12933651258449155
Trained batch 251 in epoch 2, gen_loss = 0.39433893218399985, disc_loss = 0.12925930068429028
Trained batch 252 in epoch 2, gen_loss = 0.39443137723466626, disc_loss = 0.12891640983845876
Trained batch 253 in epoch 2, gen_loss = 0.3944881753189357, disc_loss = 0.12921644948188246
Trained batch 254 in epoch 2, gen_loss = 0.39458531445147943, disc_loss = 0.12975977134763025
Trained batch 255 in epoch 2, gen_loss = 0.39438468182925135, disc_loss = 0.12971076388203073
Trained batch 256 in epoch 2, gen_loss = 0.39417025284544505, disc_loss = 0.12990228340377605
Trained batch 257 in epoch 2, gen_loss = 0.3943748022465743, disc_loss = 0.12990022249981875
Trained batch 258 in epoch 2, gen_loss = 0.3940202730732995, disc_loss = 0.12969773851018615
Trained batch 259 in epoch 2, gen_loss = 0.3941071503437482, disc_loss = 0.1293145963563942
Trained batch 260 in epoch 2, gen_loss = 0.3941051996530701, disc_loss = 0.12906811047359673
Trained batch 261 in epoch 2, gen_loss = 0.39432098653935294, disc_loss = 0.12879451288208935
Trained batch 262 in epoch 2, gen_loss = 0.3946144110576282, disc_loss = 0.12881566338354417
Trained batch 263 in epoch 2, gen_loss = 0.39443338097948016, disc_loss = 0.12940651921301402
Trained batch 264 in epoch 2, gen_loss = 0.39445540848767985, disc_loss = 0.12923355724592253
Trained batch 265 in epoch 2, gen_loss = 0.3942979831892745, disc_loss = 0.12903042645298674
Trained batch 266 in epoch 2, gen_loss = 0.39451907323987295, disc_loss = 0.12878018537403715
Trained batch 267 in epoch 2, gen_loss = 0.3943912033269654, disc_loss = 0.12851423733353393
Trained batch 268 in epoch 2, gen_loss = 0.39438838431383155, disc_loss = 0.12809313492343993
Trained batch 269 in epoch 2, gen_loss = 0.3947508821884791, disc_loss = 0.12784177431215843
Trained batch 270 in epoch 2, gen_loss = 0.39483722219607925, disc_loss = 0.12757251893489782
Trained batch 271 in epoch 2, gen_loss = 0.3948553009506534, disc_loss = 0.1272329147973591
Trained batch 272 in epoch 2, gen_loss = 0.394782291554706, disc_loss = 0.12686190625905117
Trained batch 273 in epoch 2, gen_loss = 0.3951079518037991, disc_loss = 0.1265050144254291
Trained batch 274 in epoch 2, gen_loss = 0.39532121539115905, disc_loss = 0.12609362479976632
Trained batch 275 in epoch 2, gen_loss = 0.3950894716857136, disc_loss = 0.12585925475181337
Trained batch 276 in epoch 2, gen_loss = 0.3954465733538466, disc_loss = 0.12637189237421062
Trained batch 277 in epoch 2, gen_loss = 0.3949911814156196, disc_loss = 0.1264781779542619
Trained batch 278 in epoch 2, gen_loss = 0.394995493807673, disc_loss = 0.12639007340502462
Trained batch 279 in epoch 2, gen_loss = 0.3950522408953735, disc_loss = 0.12642284221614578
Trained batch 280 in epoch 2, gen_loss = 0.39487001299858093, disc_loss = 0.12618061862687094
Trained batch 281 in epoch 2, gen_loss = 0.39467739361397763, disc_loss = 0.12688634142689142
Trained batch 282 in epoch 2, gen_loss = 0.3947516723993389, disc_loss = 0.12709284570831608
Trained batch 283 in epoch 2, gen_loss = 0.39453805552821763, disc_loss = 0.1270324207389806
Trained batch 284 in epoch 2, gen_loss = 0.3945414065269002, disc_loss = 0.1273770025392112
Trained batch 285 in epoch 2, gen_loss = 0.3946106232754834, disc_loss = 0.1270989744233658
Trained batch 286 in epoch 2, gen_loss = 0.39448148250995196, disc_loss = 0.12699070457005646
Trained batch 287 in epoch 2, gen_loss = 0.39447582171609, disc_loss = 0.12687203816797896
Trained batch 288 in epoch 2, gen_loss = 0.39464501134252056, disc_loss = 0.1269535194521699
Trained batch 289 in epoch 2, gen_loss = 0.39452405777470817, disc_loss = 0.12711923508744302
Trained batch 290 in epoch 2, gen_loss = 0.39433513853148494, disc_loss = 0.12679589759635249
Trained batch 291 in epoch 2, gen_loss = 0.3946440314797506, disc_loss = 0.12696794596220023
Trained batch 292 in epoch 2, gen_loss = 0.3948720034478874, disc_loss = 0.12663804567752743
Trained batch 293 in epoch 2, gen_loss = 0.3949046795870982, disc_loss = 0.12679484211301215
Trained batch 294 in epoch 2, gen_loss = 0.3950117977999024, disc_loss = 0.12698442712110483
Trained batch 295 in epoch 2, gen_loss = 0.3951845505350345, disc_loss = 0.12672696566851055
Trained batch 296 in epoch 2, gen_loss = 0.39526640987556794, disc_loss = 0.12670674197287973
Trained batch 297 in epoch 2, gen_loss = 0.3951578211264322, disc_loss = 0.12642260088004023
Trained batch 298 in epoch 2, gen_loss = 0.39529856690594983, disc_loss = 0.12673284863137382
Trained batch 299 in epoch 2, gen_loss = 0.3950133513410886, disc_loss = 0.12706408974714578
Trained batch 300 in epoch 2, gen_loss = 0.39496164771409525, disc_loss = 0.1268522317839966
Trained batch 301 in epoch 2, gen_loss = 0.39467481597764603, disc_loss = 0.12662870078871877
Trained batch 302 in epoch 2, gen_loss = 0.3948504245123847, disc_loss = 0.12634089026944373
Trained batch 303 in epoch 2, gen_loss = 0.3946704037095371, disc_loss = 0.1261167845927718
Trained batch 304 in epoch 2, gen_loss = 0.39467739511708744, disc_loss = 0.12611423741537528
Trained batch 305 in epoch 2, gen_loss = 0.39457178427503, disc_loss = 0.12603902844468656
Trained batch 306 in epoch 2, gen_loss = 0.3944538914225389, disc_loss = 0.1256924900726843
Trained batch 307 in epoch 2, gen_loss = 0.3943720981478691, disc_loss = 0.12556348246062635
Trained batch 308 in epoch 2, gen_loss = 0.3946286534414322, disc_loss = 0.1254530728050179
Trained batch 309 in epoch 2, gen_loss = 0.39433069094534845, disc_loss = 0.12529205541396815
Trained batch 310 in epoch 2, gen_loss = 0.39454224878185434, disc_loss = 0.12500924748515296
Trained batch 311 in epoch 2, gen_loss = 0.3945806448658307, disc_loss = 0.12466886327064668
Trained batch 312 in epoch 2, gen_loss = 0.3947168573403892, disc_loss = 0.12431468722074272
Trained batch 313 in epoch 2, gen_loss = 0.3948554609231888, disc_loss = 0.12407019742984016
Trained batch 314 in epoch 2, gen_loss = 0.3948898928506034, disc_loss = 0.1238272997033265
Trained batch 315 in epoch 2, gen_loss = 0.39494961537892304, disc_loss = 0.12362497772938938
Trained batch 316 in epoch 2, gen_loss = 0.3949853551312576, disc_loss = 0.12335790467245816
Trained batch 317 in epoch 2, gen_loss = 0.39503768929895366, disc_loss = 0.12306192391054155
Trained batch 318 in epoch 2, gen_loss = 0.39515297287683876, disc_loss = 0.12278685545064158
Trained batch 319 in epoch 2, gen_loss = 0.39539285022765397, disc_loss = 0.12268382896727417
Trained batch 320 in epoch 2, gen_loss = 0.39536548375712005, disc_loss = 0.12237207777508044
Trained batch 321 in epoch 2, gen_loss = 0.3952975863625544, disc_loss = 0.1220911986553197
Trained batch 322 in epoch 2, gen_loss = 0.3953228180438003, disc_loss = 0.12223017386711511
Trained batch 323 in epoch 2, gen_loss = 0.3954836984659419, disc_loss = 0.12195176662543765
Trained batch 324 in epoch 2, gen_loss = 0.3955537740083841, disc_loss = 0.12176649249803562
Trained batch 325 in epoch 2, gen_loss = 0.395387298398954, disc_loss = 0.12166592878992298
Trained batch 326 in epoch 2, gen_loss = 0.39547836826117394, disc_loss = 0.1216210145588725
Trained batch 327 in epoch 2, gen_loss = 0.395786576972502, disc_loss = 0.12192571631394236
Trained batch 328 in epoch 2, gen_loss = 0.3955029755559011, disc_loss = 0.12215377041917169
Trained batch 329 in epoch 2, gen_loss = 0.3953694474516493, disc_loss = 0.1219800903066767
Trained batch 330 in epoch 2, gen_loss = 0.39548644927693277, disc_loss = 0.1220771520007458
Trained batch 331 in epoch 2, gen_loss = 0.39549690107983276, disc_loss = 0.12198316144577441
Trained batch 332 in epoch 2, gen_loss = 0.3956407228031674, disc_loss = 0.1217682336571741
Trained batch 333 in epoch 2, gen_loss = 0.39555592237118475, disc_loss = 0.12157441417179154
Trained batch 334 in epoch 2, gen_loss = 0.39518188104700686, disc_loss = 0.12181195167741224
Trained batch 335 in epoch 2, gen_loss = 0.3951724142368351, disc_loss = 0.12284026689927227
Trained batch 336 in epoch 2, gen_loss = 0.39515091483246323, disc_loss = 0.12285074605178144
Trained batch 337 in epoch 2, gen_loss = 0.3948637690593505, disc_loss = 0.12282855515836699
Trained batch 338 in epoch 2, gen_loss = 0.39487021229611735, disc_loss = 0.1225273947871584
Trained batch 339 in epoch 2, gen_loss = 0.3948873767957968, disc_loss = 0.12234784191857805
Trained batch 340 in epoch 2, gen_loss = 0.394779501422759, disc_loss = 0.12237821985036135
Trained batch 341 in epoch 2, gen_loss = 0.3946258428326824, disc_loss = 0.1228735110373917
Trained batch 342 in epoch 2, gen_loss = 0.39471006193591973, disc_loss = 0.12292790993146664
Trained batch 343 in epoch 2, gen_loss = 0.39475817449910694, disc_loss = 0.1229630367597565
Trained batch 344 in epoch 2, gen_loss = 0.3947494125884512, disc_loss = 0.12325601178504851
Trained batch 345 in epoch 2, gen_loss = 0.3948470227463397, disc_loss = 0.12304762734983095
Trained batch 346 in epoch 2, gen_loss = 0.3948380966866738, disc_loss = 0.12288606524607032
Trained batch 347 in epoch 2, gen_loss = 0.3947031480827551, disc_loss = 0.12264420879180489
Trained batch 348 in epoch 2, gen_loss = 0.39472514237237183, disc_loss = 0.12251104874787239
Trained batch 349 in epoch 2, gen_loss = 0.3950669981752123, disc_loss = 0.12229301557210939
Trained batch 350 in epoch 2, gen_loss = 0.39500546098774314, disc_loss = 0.12217592350618536
Trained batch 351 in epoch 2, gen_loss = 0.3954030133106492, disc_loss = 0.12230021246465515
Trained batch 352 in epoch 2, gen_loss = 0.39536757138227946, disc_loss = 0.12252700183456157
Trained batch 353 in epoch 2, gen_loss = 0.39550116742398106, disc_loss = 0.12240223538414655
Trained batch 354 in epoch 2, gen_loss = 0.39559224441017904, disc_loss = 0.1221900601228568
Trained batch 355 in epoch 2, gen_loss = 0.39584657399172196, disc_loss = 0.12195795784139316
Trained batch 356 in epoch 2, gen_loss = 0.3958778448131572, disc_loss = 0.12172558302899786
Trained batch 357 in epoch 2, gen_loss = 0.3957690741429782, disc_loss = 0.121409487504741
Trained batch 358 in epoch 2, gen_loss = 0.39570166872072354, disc_loss = 0.12116317955834122
Trained batch 359 in epoch 2, gen_loss = 0.3953866169684463, disc_loss = 0.121116508776322
Trained batch 360 in epoch 2, gen_loss = 0.3953496660221977, disc_loss = 0.1208607648548327
Trained batch 361 in epoch 2, gen_loss = 0.39555614643334025, disc_loss = 0.12078434383259952
Trained batch 362 in epoch 2, gen_loss = 0.3956183185262128, disc_loss = 0.12088483849093934
Trained batch 363 in epoch 2, gen_loss = 0.39560028173766293, disc_loss = 0.12092501324202333
Trained batch 364 in epoch 2, gen_loss = 0.39558493584802706, disc_loss = 0.12072480770006572
Trained batch 365 in epoch 2, gen_loss = 0.3954117500879725, disc_loss = 0.12066727170283026
Trained batch 366 in epoch 2, gen_loss = 0.39553490670890185, disc_loss = 0.12041627403541547
Trained batch 367 in epoch 2, gen_loss = 0.39541728745983995, disc_loss = 0.12030275203490062
Trained batch 368 in epoch 2, gen_loss = 0.395384436538872, disc_loss = 0.12040194082591268
Trained batch 369 in epoch 2, gen_loss = 0.39563877840299866, disc_loss = 0.12065907174066917
Trained batch 370 in epoch 2, gen_loss = 0.3954706389627688, disc_loss = 0.12058570594438967
Trained batch 371 in epoch 2, gen_loss = 0.39547296573397933, disc_loss = 0.12037853378882651
Trained batch 372 in epoch 2, gen_loss = 0.39541910768514027, disc_loss = 0.12016214244567038
Trained batch 373 in epoch 2, gen_loss = 0.39527786694427225, disc_loss = 0.11998007205479286
Trained batch 374 in epoch 2, gen_loss = 0.3954011823336283, disc_loss = 0.1200403009057045
Trained batch 375 in epoch 2, gen_loss = 0.3951156476235136, disc_loss = 0.12040405100251132
Trained batch 376 in epoch 2, gen_loss = 0.3951038018619983, disc_loss = 0.12070711571673816
Trained batch 377 in epoch 2, gen_loss = 0.3950400507797009, disc_loss = 0.12057851570308524
Trained batch 378 in epoch 2, gen_loss = 0.3949518261138242, disc_loss = 0.12037398686784867
Trained batch 379 in epoch 2, gen_loss = 0.395068901541986, disc_loss = 0.12013026158276358
Trained batch 380 in epoch 2, gen_loss = 0.3952652246463956, disc_loss = 0.11998053020223232
Trained batch 381 in epoch 2, gen_loss = 0.3951572881163103, disc_loss = 0.119752933090816
Trained batch 382 in epoch 2, gen_loss = 0.3951813547480511, disc_loss = 0.11960358107486842
Trained batch 383 in epoch 2, gen_loss = 0.3953209884930402, disc_loss = 0.11945620674911576
Trained batch 384 in epoch 2, gen_loss = 0.3953027242963964, disc_loss = 0.11924732690314194
Trained batch 385 in epoch 2, gen_loss = 0.3952758290607077, disc_loss = 0.11906190403770907
Trained batch 386 in epoch 2, gen_loss = 0.3953181736999088, disc_loss = 0.11883668989443656
Trained batch 387 in epoch 2, gen_loss = 0.3953321143677554, disc_loss = 0.11865175280182325
Trained batch 388 in epoch 2, gen_loss = 0.39529710479444585, disc_loss = 0.11864349549602726
Trained batch 389 in epoch 2, gen_loss = 0.3952170193959505, disc_loss = 0.11859610784703341
Trained batch 390 in epoch 2, gen_loss = 0.3953450310718068, disc_loss = 0.11842121218171571
Trained batch 391 in epoch 2, gen_loss = 0.3955031587001012, disc_loss = 0.11828095222614249
Trained batch 392 in epoch 2, gen_loss = 0.395642685450367, disc_loss = 0.11806224381347345
Trained batch 393 in epoch 2, gen_loss = 0.3957109343128156, disc_loss = 0.11780316387846838
Trained batch 394 in epoch 2, gen_loss = 0.3956919790068759, disc_loss = 0.11764132301735727
Trained batch 395 in epoch 2, gen_loss = 0.39578669382767245, disc_loss = 0.11747042683771614
Trained batch 396 in epoch 2, gen_loss = 0.3959188149017411, disc_loss = 0.11722318280103525
Trained batch 397 in epoch 2, gen_loss = 0.39560816313453656, disc_loss = 0.11724270363548893
Trained batch 398 in epoch 2, gen_loss = 0.39579246097937565, disc_loss = 0.11765009702596449
Trained batch 399 in epoch 2, gen_loss = 0.3956773363053799, disc_loss = 0.11754655998200178
Trained batch 400 in epoch 2, gen_loss = 0.3955083551103635, disc_loss = 0.11735775227893024
Trained batch 401 in epoch 2, gen_loss = 0.3955078841145359, disc_loss = 0.11720136163839653
Trained batch 402 in epoch 2, gen_loss = 0.3955834956086303, disc_loss = 0.11712080084952173
Trained batch 403 in epoch 2, gen_loss = 0.39570071253150996, disc_loss = 0.11709745755732649
Trained batch 404 in epoch 2, gen_loss = 0.39555419271374925, disc_loss = 0.11695171180698606
Trained batch 405 in epoch 2, gen_loss = 0.39559453153257884, disc_loss = 0.11671950648827799
Trained batch 406 in epoch 2, gen_loss = 0.39548322638949834, disc_loss = 0.1166902314368132
Trained batch 407 in epoch 2, gen_loss = 0.39542412005510985, disc_loss = 0.11720558338999457
Trained batch 408 in epoch 2, gen_loss = 0.3955880560181252, disc_loss = 0.1171271912753582
Trained batch 409 in epoch 2, gen_loss = 0.39552744096372183, disc_loss = 0.11698929126851443
Trained batch 410 in epoch 2, gen_loss = 0.39586987728910145, disc_loss = 0.11696594319965718
Trained batch 411 in epoch 2, gen_loss = 0.39559793660362946, disc_loss = 0.11701956432023385
Trained batch 412 in epoch 2, gen_loss = 0.39574750514642376, disc_loss = 0.11720393927312359
Trained batch 413 in epoch 2, gen_loss = 0.3956251785087125, disc_loss = 0.11717019108650477
Trained batch 414 in epoch 2, gen_loss = 0.39547474535114796, disc_loss = 0.11696655616523272
Trained batch 415 in epoch 2, gen_loss = 0.39538158684109265, disc_loss = 0.11684152139171672
Trained batch 416 in epoch 2, gen_loss = 0.3955149754917593, disc_loss = 0.11659104892497155
Trained batch 417 in epoch 2, gen_loss = 0.39554939130276584, disc_loss = 0.11637802349858022
Trained batch 418 in epoch 2, gen_loss = 0.39543503850058326, disc_loss = 0.11621132118711892
Trained batch 419 in epoch 2, gen_loss = 0.3954161319704283, disc_loss = 0.11606788485355321
Trained batch 420 in epoch 2, gen_loss = 0.39562562766380943, disc_loss = 0.11603254156802159
Trained batch 421 in epoch 2, gen_loss = 0.39565818117693136, disc_loss = 0.11591277620203405
Trained batch 422 in epoch 2, gen_loss = 0.3957868100762649, disc_loss = 0.1157650274024224
Trained batch 423 in epoch 2, gen_loss = 0.3958561920191882, disc_loss = 0.11551835573990038
Trained batch 424 in epoch 2, gen_loss = 0.3959910723742317, disc_loss = 0.11539981745402603
Trained batch 425 in epoch 2, gen_loss = 0.3961551006131329, disc_loss = 0.11566785853924536
Trained batch 426 in epoch 2, gen_loss = 0.3961216009612385, disc_loss = 0.11550256063555317
Trained batch 427 in epoch 2, gen_loss = 0.39610998262868863, disc_loss = 0.11534630971804052
Trained batch 428 in epoch 2, gen_loss = 0.39601204612038354, disc_loss = 0.11535935419761426
Trained batch 429 in epoch 2, gen_loss = 0.3959099028692689, disc_loss = 0.1154569908261819
Trained batch 430 in epoch 2, gen_loss = 0.3959392977148087, disc_loss = 0.11526860525559314
Trained batch 431 in epoch 2, gen_loss = 0.3960343880785836, disc_loss = 0.11512807938399622
Trained batch 432 in epoch 2, gen_loss = 0.39581460903202964, disc_loss = 0.11501501167438254
Trained batch 433 in epoch 2, gen_loss = 0.3956248231472508, disc_loss = 0.11483876534827775
Trained batch 434 in epoch 2, gen_loss = 0.39581341387211594, disc_loss = 0.11461305324758948
Trained batch 435 in epoch 2, gen_loss = 0.3958409922795558, disc_loss = 0.11442515885653914
Trained batch 436 in epoch 2, gen_loss = 0.39598367054620653, disc_loss = 0.11423076572241922
Trained batch 437 in epoch 2, gen_loss = 0.39597313718436516, disc_loss = 0.11399236047368276
Trained batch 438 in epoch 2, gen_loss = 0.39590659893726704, disc_loss = 0.11383919900491121
Trained batch 439 in epoch 2, gen_loss = 0.39599220793355594, disc_loss = 0.1140445389255712
Trained batch 440 in epoch 2, gen_loss = 0.39586954626366666, disc_loss = 0.11401312707663597
Trained batch 441 in epoch 2, gen_loss = 0.39576591881691603, disc_loss = 0.11387739841071931
Trained batch 442 in epoch 2, gen_loss = 0.3958000552842633, disc_loss = 0.11370723611942196
Trained batch 443 in epoch 2, gen_loss = 0.39582355461410573, disc_loss = 0.11354328471923934
Trained batch 444 in epoch 2, gen_loss = 0.3959322672211722, disc_loss = 0.1133416331195262
Trained batch 445 in epoch 2, gen_loss = 0.39605986858162645, disc_loss = 0.11317328173007332
Trained batch 446 in epoch 2, gen_loss = 0.39601769403323234, disc_loss = 0.1130734730399395
Trained batch 447 in epoch 2, gen_loss = 0.39598954528836267, disc_loss = 0.11295110971592034
Trained batch 448 in epoch 2, gen_loss = 0.3959740732852494, disc_loss = 0.11274025934169646
Trained batch 449 in epoch 2, gen_loss = 0.39602180533938935, disc_loss = 0.11251590746972295
Trained batch 450 in epoch 2, gen_loss = 0.39608201642258467, disc_loss = 0.11233223279207086
Trained batch 451 in epoch 2, gen_loss = 0.3961639143196882, disc_loss = 0.11235642756244778
Trained batch 452 in epoch 2, gen_loss = 0.39611938108934736, disc_loss = 0.11251651053265493
Trained batch 453 in epoch 2, gen_loss = 0.3963116711325582, disc_loss = 0.11234269218954221
Trained batch 454 in epoch 2, gen_loss = 0.3964721225775205, disc_loss = 0.1123382813164166
Trained batch 455 in epoch 2, gen_loss = 0.39641925287351276, disc_loss = 0.11266647911581554
Trained batch 456 in epoch 2, gen_loss = 0.396570038482449, disc_loss = 0.11278165363313333
Trained batch 457 in epoch 2, gen_loss = 0.3964791214622264, disc_loss = 0.11269059881372744
Trained batch 458 in epoch 2, gen_loss = 0.3965636850831815, disc_loss = 0.11264967178207597
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 0.4060581624507904, disc_loss = 0.04023522883653641
Trained batch 1 in epoch 3, gen_loss = 0.3935304433107376, disc_loss = 0.05005199462175369
Trained batch 2 in epoch 3, gen_loss = 0.41331249475479126, disc_loss = 0.05164597059289614
Trained batch 3 in epoch 3, gen_loss = 0.40495143830776215, disc_loss = 0.05080651305615902
Trained batch 4 in epoch 3, gen_loss = 0.40548972487449647, disc_loss = 0.05894756466150284
Trained batch 5 in epoch 3, gen_loss = 0.4120054642359416, disc_loss = 0.059170990561445556
Trained batch 6 in epoch 3, gen_loss = 0.4106234014034271, disc_loss = 0.06411049568227359
Trained batch 7 in epoch 3, gen_loss = 0.4229704178869724, disc_loss = 0.06945848045870662
Trained batch 8 in epoch 3, gen_loss = 0.42096366816096836, disc_loss = 0.06536226222912471
Trained batch 9 in epoch 3, gen_loss = 0.4249214231967926, disc_loss = 0.06781327724456787
Trained batch 10 in epoch 3, gen_loss = 0.4260414811697873, disc_loss = 0.06390678814866325
Trained batch 11 in epoch 3, gen_loss = 0.43056004991134006, disc_loss = 0.060702698615690075
Trained batch 12 in epoch 3, gen_loss = 0.42297613391509425, disc_loss = 0.06101027159736706
Trained batch 13 in epoch 3, gen_loss = 0.42307972056525095, disc_loss = 0.058690810309989114
Trained batch 14 in epoch 3, gen_loss = 0.42421843608220416, disc_loss = 0.05581310248623292
Trained batch 15 in epoch 3, gen_loss = 0.4236598014831543, disc_loss = 0.05431326857069507
Trained batch 16 in epoch 3, gen_loss = 0.42337699848062854, disc_loss = 0.05182345753864331
Trained batch 17 in epoch 3, gen_loss = 0.41992074582311845, disc_loss = 0.050337856273270316
Trained batch 18 in epoch 3, gen_loss = 0.4216697717967786, disc_loss = 0.052467361337652334
Trained batch 19 in epoch 3, gen_loss = 0.42339308857917785, disc_loss = 0.05553404749371112
Trained batch 20 in epoch 3, gen_loss = 0.4220586121082306, disc_loss = 0.054201277726817695
Trained batch 21 in epoch 3, gen_loss = 0.41876026310703973, disc_loss = 0.057049813722683626
Trained batch 22 in epoch 3, gen_loss = 0.41955465985381085, disc_loss = 0.06580439999537624
Trained batch 23 in epoch 3, gen_loss = 0.41532644256949425, disc_loss = 0.06616335311749329
Trained batch 24 in epoch 3, gen_loss = 0.4180570924282074, disc_loss = 0.06439249586313962
Trained batch 25 in epoch 3, gen_loss = 0.41715865524915546, disc_loss = 0.06454772025776598
Trained batch 26 in epoch 3, gen_loss = 0.41119331562960587, disc_loss = 0.07276637393429324
Trained batch 27 in epoch 3, gen_loss = 0.41207998033080784, disc_loss = 0.07332398779025036
Trained batch 28 in epoch 3, gen_loss = 0.4103561968638979, disc_loss = 0.07190009974071691
Trained batch 29 in epoch 3, gen_loss = 0.4089747468630473, disc_loss = 0.07244443269446492
Trained batch 30 in epoch 3, gen_loss = 0.4083531383545168, disc_loss = 0.07380775647658494
Trained batch 31 in epoch 3, gen_loss = 0.4071703925728798, disc_loss = 0.07383091395604424
Trained batch 32 in epoch 3, gen_loss = 0.4092003477342201, disc_loss = 0.07265423382209106
Trained batch 33 in epoch 3, gen_loss = 0.40907108608414144, disc_loss = 0.07094582178465583
Trained batch 34 in epoch 3, gen_loss = 0.40969198431287496, disc_loss = 0.06955255522791828
Trained batch 35 in epoch 3, gen_loss = 0.4133620725737678, disc_loss = 0.0693110013121946
Trained batch 36 in epoch 3, gen_loss = 0.4121864148088404, disc_loss = 0.07002580153277597
Trained batch 37 in epoch 3, gen_loss = 0.4129077556886171, disc_loss = 0.07209129580051492
Trained batch 38 in epoch 3, gen_loss = 0.41167071079596496, disc_loss = 0.07290912847010753
Trained batch 39 in epoch 3, gen_loss = 0.4126839995384216, disc_loss = 0.07166736933868378
Trained batch 40 in epoch 3, gen_loss = 0.4133413942848764, disc_loss = 0.0715129352515427
Trained batch 41 in epoch 3, gen_loss = 0.4117040116162527, disc_loss = 0.07209962009940118
Trained batch 42 in epoch 3, gen_loss = 0.41061921313751576, disc_loss = 0.07107988677832276
Trained batch 43 in epoch 3, gen_loss = 0.4105962013656443, disc_loss = 0.07020422301932493
Trained batch 44 in epoch 3, gen_loss = 0.41114537517229716, disc_loss = 0.07086649977912506
Trained batch 45 in epoch 3, gen_loss = 0.40846313989680744, disc_loss = 0.07223856394462612
Trained batch 46 in epoch 3, gen_loss = 0.40812109632694976, disc_loss = 0.07188505467344472
Trained batch 47 in epoch 3, gen_loss = 0.40762315814693767, disc_loss = 0.0708747153209212
Trained batch 48 in epoch 3, gen_loss = 0.4091711828903276, disc_loss = 0.0697719917195488
Trained batch 49 in epoch 3, gen_loss = 0.40889085054397584, disc_loss = 0.07213762642815709
Trained batch 50 in epoch 3, gen_loss = 0.4117026656281714, disc_loss = 0.07532053807859912
Trained batch 51 in epoch 3, gen_loss = 0.4122716583884679, disc_loss = 0.07408551132091536
Trained batch 52 in epoch 3, gen_loss = 0.4106377233874123, disc_loss = 0.07447014459110093
Trained batch 53 in epoch 3, gen_loss = 0.4109171082576116, disc_loss = 0.0736347481228963
Trained batch 54 in epoch 3, gen_loss = 0.4121147567575628, disc_loss = 0.0727152493359013
Trained batch 55 in epoch 3, gen_loss = 0.41296561860612463, disc_loss = 0.07206232228782028
Trained batch 56 in epoch 3, gen_loss = 0.41312920994925917, disc_loss = 0.07134347257057302
Trained batch 57 in epoch 3, gen_loss = 0.41195248170145626, disc_loss = 0.070560357292536
Trained batch 58 in epoch 3, gen_loss = 0.41155267216391483, disc_loss = 0.06977253806603662
Trained batch 59 in epoch 3, gen_loss = 0.41105755120515824, disc_loss = 0.06947517315857113
Trained batch 60 in epoch 3, gen_loss = 0.41338133176819225, disc_loss = 0.06911518908731762
Trained batch 61 in epoch 3, gen_loss = 0.41367813848680063, disc_loss = 0.07034793792052134
Trained batch 62 in epoch 3, gen_loss = 0.413099770981168, disc_loss = 0.07479444390074128
Trained batch 63 in epoch 3, gen_loss = 0.4127269661985338, disc_loss = 0.07578999765974004
Trained batch 64 in epoch 3, gen_loss = 0.4133525559535393, disc_loss = 0.07504229870839761
Trained batch 65 in epoch 3, gen_loss = 0.41342184805508814, disc_loss = 0.07494129222168615
Trained batch 66 in epoch 3, gen_loss = 0.4132575472789024, disc_loss = 0.07443020713807487
Trained batch 67 in epoch 3, gen_loss = 0.41352716088294983, disc_loss = 0.07443692457095227
Trained batch 68 in epoch 3, gen_loss = 0.4140532634396484, disc_loss = 0.07356960562638183
Trained batch 69 in epoch 3, gen_loss = 0.41432419206414905, disc_loss = 0.0755453087256423
Trained batch 70 in epoch 3, gen_loss = 0.414844102842707, disc_loss = 0.07911056016479999
Trained batch 71 in epoch 3, gen_loss = 0.413852428810464, disc_loss = 0.0805567996447078
Trained batch 72 in epoch 3, gen_loss = 0.4131783467449554, disc_loss = 0.07977688209191985
Trained batch 73 in epoch 3, gen_loss = 0.4132762406323407, disc_loss = 0.07950394664815552
Trained batch 74 in epoch 3, gen_loss = 0.4122804359594981, disc_loss = 0.07955822799354792
Trained batch 75 in epoch 3, gen_loss = 0.4127367350615953, disc_loss = 0.0788982470985502
Trained batch 76 in epoch 3, gen_loss = 0.41275081038475037, disc_loss = 0.07814263759253474
Trained batch 77 in epoch 3, gen_loss = 0.4126423391012045, disc_loss = 0.07858918324256173
Trained batch 78 in epoch 3, gen_loss = 0.41239461604552935, disc_loss = 0.0803474980418252
Trained batch 79 in epoch 3, gen_loss = 0.4137023452669382, disc_loss = 0.08151533234631643
Trained batch 80 in epoch 3, gen_loss = 0.41320152746306527, disc_loss = 0.08190001881922837
Trained batch 81 in epoch 3, gen_loss = 0.41236559428819797, disc_loss = 0.08272896946703152
Trained batch 82 in epoch 3, gen_loss = 0.4124250577156802, disc_loss = 0.08542155091796653
Trained batch 83 in epoch 3, gen_loss = 0.4115773205246244, disc_loss = 0.08526526652054772
Trained batch 84 in epoch 3, gen_loss = 0.4113241739132825, disc_loss = 0.08479394666193163
Trained batch 85 in epoch 3, gen_loss = 0.412474597955859, disc_loss = 0.08441015609085213
Trained batch 86 in epoch 3, gen_loss = 0.41260404251087673, disc_loss = 0.08509708974167876
Trained batch 87 in epoch 3, gen_loss = 0.4124788652089509, disc_loss = 0.08653538537592712
Trained batch 88 in epoch 3, gen_loss = 0.41292918666025225, disc_loss = 0.08603982509145242
Trained batch 89 in epoch 3, gen_loss = 0.41311940881941056, disc_loss = 0.08580653914767834
Trained batch 90 in epoch 3, gen_loss = 0.4130821732374338, disc_loss = 0.08514609493847404
Trained batch 91 in epoch 3, gen_loss = 0.4132868644335996, disc_loss = 0.08457425673006345
Trained batch 92 in epoch 3, gen_loss = 0.4129720958330298, disc_loss = 0.08382121557670255
Trained batch 93 in epoch 3, gen_loss = 0.4128146751763973, disc_loss = 0.08314188355778127
Trained batch 94 in epoch 3, gen_loss = 0.412258674910194, disc_loss = 0.08243596189116177
Trained batch 95 in epoch 3, gen_loss = 0.41198807302862406, disc_loss = 0.08176607054580624
Trained batch 96 in epoch 3, gen_loss = 0.4122233768713843, disc_loss = 0.08101736814666961
Trained batch 97 in epoch 3, gen_loss = 0.412683828752868, disc_loss = 0.08039677674330924
Trained batch 98 in epoch 3, gen_loss = 0.4116808922603877, disc_loss = 0.08009347288558881
Trained batch 99 in epoch 3, gen_loss = 0.41215278685092926, disc_loss = 0.07955960112623871
Trained batch 100 in epoch 3, gen_loss = 0.41296514721200017, disc_loss = 0.07920933867998348
Trained batch 101 in epoch 3, gen_loss = 0.41286471515309575, disc_loss = 0.07857443994897254
Trained batch 102 in epoch 3, gen_loss = 0.4135373894450734, disc_loss = 0.07801612956648313
Trained batch 103 in epoch 3, gen_loss = 0.41322765757258123, disc_loss = 0.07745833039427033
Trained batch 104 in epoch 3, gen_loss = 0.41330847569874357, disc_loss = 0.0771060253892626
Trained batch 105 in epoch 3, gen_loss = 0.4140583172721683, disc_loss = 0.07651885482921915
Trained batch 106 in epoch 3, gen_loss = 0.41356089321252343, disc_loss = 0.07606437492454163
Trained batch 107 in epoch 3, gen_loss = 0.4144078567624092, disc_loss = 0.075533466965512
Trained batch 108 in epoch 3, gen_loss = 0.4143256145879763, disc_loss = 0.07493414790497734
Trained batch 109 in epoch 3, gen_loss = 0.4143307853828777, disc_loss = 0.07456134218214587
Trained batch 110 in epoch 3, gen_loss = 0.4133137706163767, disc_loss = 0.07479088000852514
Trained batch 111 in epoch 3, gen_loss = 0.41385479271411896, disc_loss = 0.07625836006731593
Trained batch 112 in epoch 3, gen_loss = 0.41307278834613026, disc_loss = 0.07676507353749687
Trained batch 113 in epoch 3, gen_loss = 0.4129928470703593, disc_loss = 0.07716696734719894
Trained batch 114 in epoch 3, gen_loss = 0.4125548709993777, disc_loss = 0.07970504513739243
Trained batch 115 in epoch 3, gen_loss = 0.4135884318886132, disc_loss = 0.08102958468752432
Trained batch 116 in epoch 3, gen_loss = 0.4133548153261853, disc_loss = 0.08086417659193787
Trained batch 117 in epoch 3, gen_loss = 0.4130267334186425, disc_loss = 0.08103121241744039
Trained batch 118 in epoch 3, gen_loss = 0.41214156576565336, disc_loss = 0.08107995541625414
Trained batch 119 in epoch 3, gen_loss = 0.4118540647129218, disc_loss = 0.0808890892735993
Trained batch 120 in epoch 3, gen_loss = 0.4121214877967992, disc_loss = 0.08053933314147814
Trained batch 121 in epoch 3, gen_loss = 0.41157579910559733, disc_loss = 0.08050654843052635
Trained batch 122 in epoch 3, gen_loss = 0.41150860742824835, disc_loss = 0.08040780176567595
Trained batch 123 in epoch 3, gen_loss = 0.4114652735091025, disc_loss = 0.07993450898286555
Trained batch 124 in epoch 3, gen_loss = 0.41195113921165466, disc_loss = 0.08065965121239424
Trained batch 125 in epoch 3, gen_loss = 0.4111655382882981, disc_loss = 0.0815182637408494
Trained batch 126 in epoch 3, gen_loss = 0.41104877980675286, disc_loss = 0.08132626156608655
Trained batch 127 in epoch 3, gen_loss = 0.41108282119967043, disc_loss = 0.08092015096190153
Trained batch 128 in epoch 3, gen_loss = 0.41168878522030145, disc_loss = 0.08057651457254046
Trained batch 129 in epoch 3, gen_loss = 0.41147788969370036, disc_loss = 0.08120101875840471
Trained batch 130 in epoch 3, gen_loss = 0.41185278724168095, disc_loss = 0.08156377818606055
Trained batch 131 in epoch 3, gen_loss = 0.4115817589741765, disc_loss = 0.08112808534960178
Trained batch 132 in epoch 3, gen_loss = 0.4109108725884803, disc_loss = 0.0810895801164714
Trained batch 133 in epoch 3, gen_loss = 0.4108240746740085, disc_loss = 0.08088310372167781
Trained batch 134 in epoch 3, gen_loss = 0.4104731272768091, disc_loss = 0.08098885834355045
Trained batch 135 in epoch 3, gen_loss = 0.4104726728709305, disc_loss = 0.0806745451888727
Trained batch 136 in epoch 3, gen_loss = 0.4101348528026664, disc_loss = 0.08070360255312092
Trained batch 137 in epoch 3, gen_loss = 0.41042879590953607, disc_loss = 0.08203096418520031
Trained batch 138 in epoch 3, gen_loss = 0.41085668733651687, disc_loss = 0.08238972702713536
Trained batch 139 in epoch 3, gen_loss = 0.41067966393062044, disc_loss = 0.08227916381854032
Trained batch 140 in epoch 3, gen_loss = 0.41039133579172987, disc_loss = 0.08240303017383983
Trained batch 141 in epoch 3, gen_loss = 0.41057102445145727, disc_loss = 0.08339592710163601
Trained batch 142 in epoch 3, gen_loss = 0.4100021736605184, disc_loss = 0.08424943821647993
Trained batch 143 in epoch 3, gen_loss = 0.4105854096512, disc_loss = 0.08395852891650672
Trained batch 144 in epoch 3, gen_loss = 0.410252846109456, disc_loss = 0.08416167490569681
Trained batch 145 in epoch 3, gen_loss = 0.4093122504753609, disc_loss = 0.08438989094598856
Trained batch 146 in epoch 3, gen_loss = 0.40946934012328684, disc_loss = 0.08399444402252533
Trained batch 147 in epoch 3, gen_loss = 0.4091041035748817, disc_loss = 0.08375902760245309
Trained batch 148 in epoch 3, gen_loss = 0.40899258852005005, disc_loss = 0.08348137237156597
Trained batch 149 in epoch 3, gen_loss = 0.4082271856069565, disc_loss = 0.08372920609389742
Trained batch 150 in epoch 3, gen_loss = 0.40902481588306805, disc_loss = 0.08496479065286995
Trained batch 151 in epoch 3, gen_loss = 0.4089746012499458, disc_loss = 0.0851267622477424
Trained batch 152 in epoch 3, gen_loss = 0.40852605906966466, disc_loss = 0.0863756310693871
Trained batch 153 in epoch 3, gen_loss = 0.4080690780243316, disc_loss = 0.08644901972578524
Trained batch 154 in epoch 3, gen_loss = 0.40776497952399715, disc_loss = 0.08654945763729273
Trained batch 155 in epoch 3, gen_loss = 0.40801536158109325, disc_loss = 0.08654262643092527
Trained batch 156 in epoch 3, gen_loss = 0.4076626185019305, disc_loss = 0.08664761115292645
Trained batch 157 in epoch 3, gen_loss = 0.4070790534532523, disc_loss = 0.08816396192164172
Trained batch 158 in epoch 3, gen_loss = 0.40735306998468795, disc_loss = 0.08825449469212279
Trained batch 159 in epoch 3, gen_loss = 0.4071493359282613, disc_loss = 0.08907333642127924
Trained batch 160 in epoch 3, gen_loss = 0.4065520619013295, disc_loss = 0.09055015085531133
Trained batch 161 in epoch 3, gen_loss = 0.4064332026022452, disc_loss = 0.09035951931052554
Trained batch 162 in epoch 3, gen_loss = 0.4063623350090776, disc_loss = 0.09004435671687674
Trained batch 163 in epoch 3, gen_loss = 0.406131857052082, disc_loss = 0.090309615513855
Trained batch 164 in epoch 3, gen_loss = 0.40634693051829485, disc_loss = 0.09044146733640722
Trained batch 165 in epoch 3, gen_loss = 0.4062083268381027, disc_loss = 0.09014948580346732
Trained batch 166 in epoch 3, gen_loss = 0.40569600909056064, disc_loss = 0.09008274309359446
Trained batch 167 in epoch 3, gen_loss = 0.40543713775419055, disc_loss = 0.08979577288985074
Trained batch 168 in epoch 3, gen_loss = 0.40514647801952247, disc_loss = 0.08983403053575542
Trained batch 169 in epoch 3, gen_loss = 0.40532378799775065, disc_loss = 0.089920247274944
Trained batch 170 in epoch 3, gen_loss = 0.40479450755649143, disc_loss = 0.08976099275771462
Trained batch 171 in epoch 3, gen_loss = 0.40473281089649643, disc_loss = 0.09027421437095591
Trained batch 172 in epoch 3, gen_loss = 0.40473477482106646, disc_loss = 0.09112608481758419
Trained batch 173 in epoch 3, gen_loss = 0.4046180486336522, disc_loss = 0.09072599910606427
Trained batch 174 in epoch 3, gen_loss = 0.4045059336934771, disc_loss = 0.09126507869256394
Trained batch 175 in epoch 3, gen_loss = 0.40481969409368257, disc_loss = 0.09136565774150024
Trained batch 176 in epoch 3, gen_loss = 0.40523490983214083, disc_loss = 0.09138125618446176
Trained batch 177 in epoch 3, gen_loss = 0.4048975260739916, disc_loss = 0.09254681226389294
Trained batch 178 in epoch 3, gen_loss = 0.405509038011455, disc_loss = 0.09263824812505998
Trained batch 179 in epoch 3, gen_loss = 0.40594149579604466, disc_loss = 0.0922221903120064
Trained batch 180 in epoch 3, gen_loss = 0.40571343487138906, disc_loss = 0.09219484005987809
Trained batch 181 in epoch 3, gen_loss = 0.40566350732530865, disc_loss = 0.0923145789560954
Trained batch 182 in epoch 3, gen_loss = 0.4052120891750836, disc_loss = 0.09257958922535181
Trained batch 183 in epoch 3, gen_loss = 0.4050024697638076, disc_loss = 0.09247109167905443
Trained batch 184 in epoch 3, gen_loss = 0.4051816254048734, disc_loss = 0.09210442533666217
Trained batch 185 in epoch 3, gen_loss = 0.40501689846797656, disc_loss = 0.0919239760917281
Trained batch 186 in epoch 3, gen_loss = 0.40454864932254037, disc_loss = 0.09161392413577772
Trained batch 187 in epoch 3, gen_loss = 0.4045785828790766, disc_loss = 0.09119803580316774
Trained batch 188 in epoch 3, gen_loss = 0.4043853806440162, disc_loss = 0.09095935234750704
Trained batch 189 in epoch 3, gen_loss = 0.40470887799012034, disc_loss = 0.09103680852016335
Trained batch 190 in epoch 3, gen_loss = 0.4047511594457776, disc_loss = 0.09083812659440553
Trained batch 191 in epoch 3, gen_loss = 0.40472533615926903, disc_loss = 0.09063597080724624
Trained batch 192 in epoch 3, gen_loss = 0.40484618878117495, disc_loss = 0.0902850734542843
Trained batch 193 in epoch 3, gen_loss = 0.40445845965872107, disc_loss = 0.09010290727979436
Trained batch 194 in epoch 3, gen_loss = 0.4048139899204939, disc_loss = 0.09169683392422322
Trained batch 195 in epoch 3, gen_loss = 0.4048555031114695, disc_loss = 0.09147504208685488
Trained batch 196 in epoch 3, gen_loss = 0.4044978356906, disc_loss = 0.0912971093702286
Trained batch 197 in epoch 3, gen_loss = 0.4038233340087563, disc_loss = 0.09107578541105142
Trained batch 198 in epoch 3, gen_loss = 0.4034903762328565, disc_loss = 0.09092248226492548
Trained batch 199 in epoch 3, gen_loss = 0.4032445099949837, disc_loss = 0.09205852649174631
Trained batch 200 in epoch 3, gen_loss = 0.40264453223688684, disc_loss = 0.09369082481076765
Trained batch 201 in epoch 3, gen_loss = 0.4026840706863026, disc_loss = 0.09359675253935085
Trained batch 202 in epoch 3, gen_loss = 0.4030270478114706, disc_loss = 0.09353970801411884
Trained batch 203 in epoch 3, gen_loss = 0.40309882266264335, disc_loss = 0.09327221626196713
Trained batch 204 in epoch 3, gen_loss = 0.40286817826875826, disc_loss = 0.09302902771387159
Trained batch 205 in epoch 3, gen_loss = 0.40282350865382593, disc_loss = 0.09306200797154197
Trained batch 206 in epoch 3, gen_loss = 0.40242659901651207, disc_loss = 0.09292812275605788
Trained batch 207 in epoch 3, gen_loss = 0.40204217542822546, disc_loss = 0.09277531827907436
Trained batch 208 in epoch 3, gen_loss = 0.40200880355241764, disc_loss = 0.09260989188185434
Trained batch 209 in epoch 3, gen_loss = 0.4022755529199328, disc_loss = 0.0928637833556249
Trained batch 210 in epoch 3, gen_loss = 0.40235912771586557, disc_loss = 0.0928393806555966
Trained batch 211 in epoch 3, gen_loss = 0.40227024678914053, disc_loss = 0.09273907764516068
Trained batch 212 in epoch 3, gen_loss = 0.4024641775469265, disc_loss = 0.09271638907771995
Trained batch 213 in epoch 3, gen_loss = 0.4026431278369137, disc_loss = 0.0925597446213398
Trained batch 214 in epoch 3, gen_loss = 0.40265108152877455, disc_loss = 0.09219637913412826
Trained batch 215 in epoch 3, gen_loss = 0.4032006821146718, disc_loss = 0.09225472864798373
Trained batch 216 in epoch 3, gen_loss = 0.4033083734424433, disc_loss = 0.09197051399108451
Trained batch 217 in epoch 3, gen_loss = 0.4034100862544611, disc_loss = 0.09165596977354737
Trained batch 218 in epoch 3, gen_loss = 0.4030507002791313, disc_loss = 0.09156652575690452
Trained batch 219 in epoch 3, gen_loss = 0.4033869071440263, disc_loss = 0.09150302062996409
Trained batch 220 in epoch 3, gen_loss = 0.40371841259671554, disc_loss = 0.0912598410444292
Trained batch 221 in epoch 3, gen_loss = 0.40339384422645913, disc_loss = 0.09135400320965427
Trained batch 222 in epoch 3, gen_loss = 0.40342444649191717, disc_loss = 0.09105316673159065
Trained batch 223 in epoch 3, gen_loss = 0.403557380129184, disc_loss = 0.09185211001230138
Trained batch 224 in epoch 3, gen_loss = 0.40332607759369743, disc_loss = 0.09374411834610832
Trained batch 225 in epoch 3, gen_loss = 0.40322463860553975, disc_loss = 0.09371723073114337
Trained batch 226 in epoch 3, gen_loss = 0.40348977506948464, disc_loss = 0.09396094113325758
Trained batch 227 in epoch 3, gen_loss = 0.4034215720337734, disc_loss = 0.09385345729165956
Trained batch 228 in epoch 3, gen_loss = 0.4036260787316285, disc_loss = 0.09388427110998912
Trained batch 229 in epoch 3, gen_loss = 0.4035380997087645, disc_loss = 0.09393462584070537
Trained batch 230 in epoch 3, gen_loss = 0.403356115668367, disc_loss = 0.09379468209944762
Trained batch 231 in epoch 3, gen_loss = 0.40344394383759336, disc_loss = 0.09380314194051356
Trained batch 232 in epoch 3, gen_loss = 0.40313422436877894, disc_loss = 0.09411651142293291
Trained batch 233 in epoch 3, gen_loss = 0.40327034406682366, disc_loss = 0.09408545115182543
Trained batch 234 in epoch 3, gen_loss = 0.40332168886002073, disc_loss = 0.09380024228482804
Trained batch 235 in epoch 3, gen_loss = 0.4030185128420086, disc_loss = 0.0936159870303157
Trained batch 236 in epoch 3, gen_loss = 0.4031992578556769, disc_loss = 0.0933054214744251
Trained batch 237 in epoch 3, gen_loss = 0.40308760269349364, disc_loss = 0.09300550473306109
Trained batch 238 in epoch 3, gen_loss = 0.4032498396091381, disc_loss = 0.09269030288516478
Trained batch 239 in epoch 3, gen_loss = 0.4035088988641898, disc_loss = 0.09234352408675477
Trained batch 240 in epoch 3, gen_loss = 0.4037794493046044, disc_loss = 0.09206302063269116
Trained batch 241 in epoch 3, gen_loss = 0.40363253419064293, disc_loss = 0.09184221998395875
Trained batch 242 in epoch 3, gen_loss = 0.4032168204401746, disc_loss = 0.0917150829209651
Trained batch 243 in epoch 3, gen_loss = 0.40332867913558834, disc_loss = 0.0914938598985738
Trained batch 244 in epoch 3, gen_loss = 0.40307574004543073, disc_loss = 0.09118171133177012
Trained batch 245 in epoch 3, gen_loss = 0.40322854085181786, disc_loss = 0.09086848016283135
Trained batch 246 in epoch 3, gen_loss = 0.40329577408821476, disc_loss = 0.09056282823204029
Trained batch 247 in epoch 3, gen_loss = 0.40309584609443144, disc_loss = 0.09046281310879896
Trained batch 248 in epoch 3, gen_loss = 0.40312513517567433, disc_loss = 0.09126242194848368
Trained batch 249 in epoch 3, gen_loss = 0.4037189222574234, disc_loss = 0.09172042311728
Trained batch 250 in epoch 3, gen_loss = 0.40353979330613793, disc_loss = 0.09148786699332564
Trained batch 251 in epoch 3, gen_loss = 0.4033950696152354, disc_loss = 0.09120850337462293
Trained batch 252 in epoch 3, gen_loss = 0.4036270736941236, disc_loss = 0.09091393754121814
Trained batch 253 in epoch 3, gen_loss = 0.40383141833966174, disc_loss = 0.09070452318827468
Trained batch 254 in epoch 3, gen_loss = 0.4036698979489944, disc_loss = 0.0905014410030608
Trained batch 255 in epoch 3, gen_loss = 0.4040059265680611, disc_loss = 0.09076804036158137
Trained batch 256 in epoch 3, gen_loss = 0.403720498085022, disc_loss = 0.09119699040159641
Trained batch 257 in epoch 3, gen_loss = 0.40413412012795147, disc_loss = 0.09103257463190907
Trained batch 258 in epoch 3, gen_loss = 0.404294512216649, disc_loss = 0.0914133906249374
Trained batch 259 in epoch 3, gen_loss = 0.40390611715041674, disc_loss = 0.09128386464256506
Trained batch 260 in epoch 3, gen_loss = 0.4034249484539032, disc_loss = 0.09167435394164702
Trained batch 261 in epoch 3, gen_loss = 0.40345296024821187, disc_loss = 0.09164217151417077
Trained batch 262 in epoch 3, gen_loss = 0.40317436270840723, disc_loss = 0.09167226199981378
Trained batch 263 in epoch 3, gen_loss = 0.4028182765751174, disc_loss = 0.09197822865098715
Trained batch 264 in epoch 3, gen_loss = 0.4027189532540879, disc_loss = 0.09176191653845445
Trained batch 265 in epoch 3, gen_loss = 0.4027053563666523, disc_loss = 0.09187231123223341
Trained batch 266 in epoch 3, gen_loss = 0.4024761408455809, disc_loss = 0.09248390922162417
Trained batch 267 in epoch 3, gen_loss = 0.4023510197650141, disc_loss = 0.09224286713679113
Trained batch 268 in epoch 3, gen_loss = 0.4024163904464821, disc_loss = 0.09207322359168175
Trained batch 269 in epoch 3, gen_loss = 0.40250306957297854, disc_loss = 0.09185543077549449
Trained batch 270 in epoch 3, gen_loss = 0.4023929106353394, disc_loss = 0.09182468139844847
Trained batch 271 in epoch 3, gen_loss = 0.4023764014024945, disc_loss = 0.09202412111164235
Trained batch 272 in epoch 3, gen_loss = 0.40252253271284555, disc_loss = 0.0918196883025296
Trained batch 273 in epoch 3, gen_loss = 0.40228500146500384, disc_loss = 0.09176296007268837
Trained batch 274 in epoch 3, gen_loss = 0.40245436657558786, disc_loss = 0.09162343467501077
Trained batch 275 in epoch 3, gen_loss = 0.4025339619189069, disc_loss = 0.0914089442635684
Trained batch 276 in epoch 3, gen_loss = 0.4024757107027171, disc_loss = 0.09139355707120164
Trained batch 277 in epoch 3, gen_loss = 0.40276294721545075, disc_loss = 0.09126803626661463
Trained batch 278 in epoch 3, gen_loss = 0.4026821425525091, disc_loss = 0.09108806342073453
Trained batch 279 in epoch 3, gen_loss = 0.4024792145405497, disc_loss = 0.09105367361834006
Trained batch 280 in epoch 3, gen_loss = 0.4028210031180195, disc_loss = 0.09087985708275512
Trained batch 281 in epoch 3, gen_loss = 0.4027191778869494, disc_loss = 0.09078295937745917
Trained batch 282 in epoch 3, gen_loss = 0.4030569385302783, disc_loss = 0.09049598845018093
Trained batch 283 in epoch 3, gen_loss = 0.4031564265909329, disc_loss = 0.09024069433323514
Trained batch 284 in epoch 3, gen_loss = 0.4032895267009735, disc_loss = 0.08996852933706945
Trained batch 285 in epoch 3, gen_loss = 0.4033204151408656, disc_loss = 0.08971646101819677
Trained batch 286 in epoch 3, gen_loss = 0.4033219587927496, disc_loss = 0.08967169461843236
Trained batch 287 in epoch 3, gen_loss = 0.4032144682067964, disc_loss = 0.08957018482679915
Trained batch 288 in epoch 3, gen_loss = 0.4030627043189474, disc_loss = 0.08930511378190097
Trained batch 289 in epoch 3, gen_loss = 0.4031820573683443, disc_loss = 0.08905295578056369
Trained batch 290 in epoch 3, gen_loss = 0.40341443017995643, disc_loss = 0.08883022712831645
Trained batch 291 in epoch 3, gen_loss = 0.4035967648641704, disc_loss = 0.08864608771894893
Trained batch 292 in epoch 3, gen_loss = 0.4036749023626282, disc_loss = 0.08837724913153225
Trained batch 293 in epoch 3, gen_loss = 0.40376145245672085, disc_loss = 0.08825477092292439
Trained batch 294 in epoch 3, gen_loss = 0.403736706507408, disc_loss = 0.08797666858250307
Trained batch 295 in epoch 3, gen_loss = 0.4036176329528963, disc_loss = 0.0877782522316871
Trained batch 296 in epoch 3, gen_loss = 0.4033372726303961, disc_loss = 0.08774415750733831
Trained batch 297 in epoch 3, gen_loss = 0.40374079656680956, disc_loss = 0.08773520572311026
Trained batch 298 in epoch 3, gen_loss = 0.403787276716934, disc_loss = 0.08771189651997094
Trained batch 299 in epoch 3, gen_loss = 0.4041190192103386, disc_loss = 0.08759019610472024
Trained batch 300 in epoch 3, gen_loss = 0.40422706578261036, disc_loss = 0.08739456966011924
Trained batch 301 in epoch 3, gen_loss = 0.40395813538933434, disc_loss = 0.08719994680684627
Trained batch 302 in epoch 3, gen_loss = 0.4038834873795903, disc_loss = 0.0874003701114861
Trained batch 303 in epoch 3, gen_loss = 0.4042373969170608, disc_loss = 0.08767782534337848
Trained batch 304 in epoch 3, gen_loss = 0.4043181646065634, disc_loss = 0.08774675749181235
Trained batch 305 in epoch 3, gen_loss = 0.4039582775698768, disc_loss = 0.08792531678112211
Trained batch 306 in epoch 3, gen_loss = 0.4039856021683845, disc_loss = 0.08779255906574986
Trained batch 307 in epoch 3, gen_loss = 0.4041282498797813, disc_loss = 0.08762575913668162
Trained batch 308 in epoch 3, gen_loss = 0.4041428339327037, disc_loss = 0.08755286469826518
Trained batch 309 in epoch 3, gen_loss = 0.40406473067498977, disc_loss = 0.08768446299157316
Trained batch 310 in epoch 3, gen_loss = 0.40418383047895035, disc_loss = 0.0874917516185396
Trained batch 311 in epoch 3, gen_loss = 0.4044902245394694, disc_loss = 0.08728596632882284
Trained batch 312 in epoch 3, gen_loss = 0.40474335349405915, disc_loss = 0.08706808999811594
Trained batch 313 in epoch 3, gen_loss = 0.4048686873191481, disc_loss = 0.08682853411171276
Trained batch 314 in epoch 3, gen_loss = 0.4048423803041852, disc_loss = 0.08658717542531945
Trained batch 315 in epoch 3, gen_loss = 0.40485439591015443, disc_loss = 0.08652641087228173
Trained batch 316 in epoch 3, gen_loss = 0.4047493368669263, disc_loss = 0.0865832526142759
Trained batch 317 in epoch 3, gen_loss = 0.4048331063123619, disc_loss = 0.08647530088376887
Trained batch 318 in epoch 3, gen_loss = 0.4049752618078154, disc_loss = 0.08625750741731597
Trained batch 319 in epoch 3, gen_loss = 0.4048190667293966, disc_loss = 0.08626841905643232
Trained batch 320 in epoch 3, gen_loss = 0.40481782377323255, disc_loss = 0.08605683894938213
Trained batch 321 in epoch 3, gen_loss = 0.405064465188832, disc_loss = 0.08582537537382812
Trained batch 322 in epoch 3, gen_loss = 0.4053532142572728, disc_loss = 0.08563266213026025
Trained batch 323 in epoch 3, gen_loss = 0.40546785524965806, disc_loss = 0.08560740658553478
Trained batch 324 in epoch 3, gen_loss = 0.40508772547428423, disc_loss = 0.08563927857348552
Trained batch 325 in epoch 3, gen_loss = 0.40528051308327656, disc_loss = 0.08543660447709948
Trained batch 326 in epoch 3, gen_loss = 0.40532081316735036, disc_loss = 0.08564591095056556
Trained batch 327 in epoch 3, gen_loss = 0.40530056115694163, disc_loss = 0.08573431764138727
Trained batch 328 in epoch 3, gen_loss = 0.4054537458079202, disc_loss = 0.08551411939314978
Trained batch 329 in epoch 3, gen_loss = 0.40563722270907776, disc_loss = 0.08534947625841155
Trained batch 330 in epoch 3, gen_loss = 0.405539300596606, disc_loss = 0.08521551431756005
Trained batch 331 in epoch 3, gen_loss = 0.4056524502405201, disc_loss = 0.08510853522962117
Trained batch 332 in epoch 3, gen_loss = 0.405587777450636, disc_loss = 0.0855556575430406
Trained batch 333 in epoch 3, gen_loss = 0.40560611475727515, disc_loss = 0.0859868536050805
Trained batch 334 in epoch 3, gen_loss = 0.405887689875133, disc_loss = 0.08599670954159837
Trained batch 335 in epoch 3, gen_loss = 0.4059578524458976, disc_loss = 0.08589686315861486
Trained batch 336 in epoch 3, gen_loss = 0.40561458769113445, disc_loss = 0.08578231342645357
Trained batch 337 in epoch 3, gen_loss = 0.4057152879661357, disc_loss = 0.08563621009330778
Trained batch 338 in epoch 3, gen_loss = 0.40569200707396225, disc_loss = 0.08545096194959495
Trained batch 339 in epoch 3, gen_loss = 0.40551922768354415, disc_loss = 0.08523446040721062
Trained batch 340 in epoch 3, gen_loss = 0.4053832925309883, disc_loss = 0.08505644247514849
Trained batch 341 in epoch 3, gen_loss = 0.40548684278078245, disc_loss = 0.08489640932039995
Trained batch 342 in epoch 3, gen_loss = 0.4054991979988254, disc_loss = 0.08480589045347434
Trained batch 343 in epoch 3, gen_loss = 0.4053962695910487, disc_loss = 0.08472316835866157
Trained batch 344 in epoch 3, gen_loss = 0.40520045722740283, disc_loss = 0.08456470462345127
Trained batch 345 in epoch 3, gen_loss = 0.4053909625276665, disc_loss = 0.08447121672945991
Trained batch 346 in epoch 3, gen_loss = 0.40561919880531705, disc_loss = 0.08436268277369675
Trained batch 347 in epoch 3, gen_loss = 0.4057662759361596, disc_loss = 0.08423585905265277
Trained batch 348 in epoch 3, gen_loss = 0.4059120748821849, disc_loss = 0.0841151485753307
Trained batch 349 in epoch 3, gen_loss = 0.40590537488460543, disc_loss = 0.08394210296283876
Trained batch 350 in epoch 3, gen_loss = 0.40624033733990117, disc_loss = 0.08380430841558424
Trained batch 351 in epoch 3, gen_loss = 0.40647428448904643, disc_loss = 0.08364434191290374
Trained batch 352 in epoch 3, gen_loss = 0.406716043229819, disc_loss = 0.08344731173048023
Trained batch 353 in epoch 3, gen_loss = 0.4067880133282667, disc_loss = 0.08323661044324185
Trained batch 354 in epoch 3, gen_loss = 0.40680243977358643, disc_loss = 0.08302134761822895
Trained batch 355 in epoch 3, gen_loss = 0.4067123700561148, disc_loss = 0.08284006469223774
Trained batch 356 in epoch 3, gen_loss = 0.40653014458528086, disc_loss = 0.08266700303354182
Trained batch 357 in epoch 3, gen_loss = 0.4065389106227033, disc_loss = 0.08246517196224805
Trained batch 358 in epoch 3, gen_loss = 0.4066701868450409, disc_loss = 0.08226585737364704
Trained batch 359 in epoch 3, gen_loss = 0.40677850345770517, disc_loss = 0.08205300189891002
Trained batch 360 in epoch 3, gen_loss = 0.40652736963657793, disc_loss = 0.08187808321499965
Trained batch 361 in epoch 3, gen_loss = 0.40665002537695744, disc_loss = 0.08168181661871463
Trained batch 362 in epoch 3, gen_loss = 0.40668048017937947, disc_loss = 0.0815641240283498
Trained batch 363 in epoch 3, gen_loss = 0.4064854152582504, disc_loss = 0.08158283312370039
Trained batch 364 in epoch 3, gen_loss = 0.40668395725015094, disc_loss = 0.08138721210320722
Trained batch 365 in epoch 3, gen_loss = 0.40668831578369347, disc_loss = 0.08147285659441246
Trained batch 366 in epoch 3, gen_loss = 0.4066247022444286, disc_loss = 0.08137431428755053
Trained batch 367 in epoch 3, gen_loss = 0.4065680131316185, disc_loss = 0.08119440559201631
Trained batch 368 in epoch 3, gen_loss = 0.4065176122556857, disc_loss = 0.0810576552603404
Trained batch 369 in epoch 3, gen_loss = 0.40650848947666784, disc_loss = 0.08089182314563644
Trained batch 370 in epoch 3, gen_loss = 0.40666081649916513, disc_loss = 0.08076999802518928
Trained batch 371 in epoch 3, gen_loss = 0.4069346413016319, disc_loss = 0.08095149429620153
Trained batch 372 in epoch 3, gen_loss = 0.40702341309181805, disc_loss = 0.08135061079995762
Trained batch 373 in epoch 3, gen_loss = 0.4073672407769902, disc_loss = 0.08154428692629193
Trained batch 374 in epoch 3, gen_loss = 0.40743451515833534, disc_loss = 0.08139753477896253
Trained batch 375 in epoch 3, gen_loss = 0.40731114799037893, disc_loss = 0.08124543166288392
Trained batch 376 in epoch 3, gen_loss = 0.40720621834383086, disc_loss = 0.08108490755514733
Trained batch 377 in epoch 3, gen_loss = 0.4073853706398969, disc_loss = 0.08090748362583182
Trained batch 378 in epoch 3, gen_loss = 0.4073116022081048, disc_loss = 0.08084704643017109
Trained batch 379 in epoch 3, gen_loss = 0.40768156859435534, disc_loss = 0.08075894641469379
Trained batch 380 in epoch 3, gen_loss = 0.4078463530290158, disc_loss = 0.0806331157236998
Trained batch 381 in epoch 3, gen_loss = 0.4078025655596668, disc_loss = 0.08046858720798337
Trained batch 382 in epoch 3, gen_loss = 0.407720217505572, disc_loss = 0.0802911427905467
Trained batch 383 in epoch 3, gen_loss = 0.4076779615134001, disc_loss = 0.08017101943187299
Trained batch 384 in epoch 3, gen_loss = 0.4076458821823071, disc_loss = 0.08002412740697527
Trained batch 385 in epoch 3, gen_loss = 0.40748143142060295, disc_loss = 0.07986546295376523
Trained batch 386 in epoch 3, gen_loss = 0.40756708737799674, disc_loss = 0.0797345972504438
Trained batch 387 in epoch 3, gen_loss = 0.40768105943792876, disc_loss = 0.07955268362042561
Trained batch 388 in epoch 3, gen_loss = 0.40773830560914653, disc_loss = 0.07955077476919195
Trained batch 389 in epoch 3, gen_loss = 0.4075762297098453, disc_loss = 0.0795240488822739
Trained batch 390 in epoch 3, gen_loss = 0.40774764231098887, disc_loss = 0.07934650084327745
Trained batch 391 in epoch 3, gen_loss = 0.4079479261928675, disc_loss = 0.0791748961759256
Trained batch 392 in epoch 3, gen_loss = 0.40803030921909345, disc_loss = 0.07904707000688022
Trained batch 393 in epoch 3, gen_loss = 0.4078415758567413, disc_loss = 0.07887375661228703
Trained batch 394 in epoch 3, gen_loss = 0.40778508752207215, disc_loss = 0.07872581908809421
Trained batch 395 in epoch 3, gen_loss = 0.4076930671328246, disc_loss = 0.07858234249417567
Trained batch 396 in epoch 3, gen_loss = 0.4075793668965549, disc_loss = 0.07840285036989701
Trained batch 397 in epoch 3, gen_loss = 0.4077007873873016, disc_loss = 0.07823654337102856
Trained batch 398 in epoch 3, gen_loss = 0.4075411943564738, disc_loss = 0.078071191791389
Trained batch 399 in epoch 3, gen_loss = 0.40759957894682886, disc_loss = 0.0778935632458888
Trained batch 400 in epoch 3, gen_loss = 0.40760323219465794, disc_loss = 0.07771896748592208
Trained batch 401 in epoch 3, gen_loss = 0.40745565072814033, disc_loss = 0.07763093769485455
Trained batch 402 in epoch 3, gen_loss = 0.40733521585133176, disc_loss = 0.07751671868438831
Trained batch 403 in epoch 3, gen_loss = 0.40745903433549524, disc_loss = 0.07734002215824652
Trained batch 404 in epoch 3, gen_loss = 0.40758859662362085, disc_loss = 0.07716931540656972
Trained batch 405 in epoch 3, gen_loss = 0.4075714139075115, disc_loss = 0.07699506501827774
Trained batch 406 in epoch 3, gen_loss = 0.40762926605175404, disc_loss = 0.07684289827869624
Trained batch 407 in epoch 3, gen_loss = 0.407615735104271, disc_loss = 0.07675859615133673
Trained batch 408 in epoch 3, gen_loss = 0.4078782530169032, disc_loss = 0.07661304713060628
Trained batch 409 in epoch 3, gen_loss = 0.40775096663614596, disc_loss = 0.07644887611769685
Trained batch 410 in epoch 3, gen_loss = 0.4078740442031201, disc_loss = 0.07633367036480611
Trained batch 411 in epoch 3, gen_loss = 0.4080886890731969, disc_loss = 0.07618300983166883
Trained batch 412 in epoch 3, gen_loss = 0.4081959478358668, disc_loss = 0.07609628755418858
Trained batch 413 in epoch 3, gen_loss = 0.40812466189193264, disc_loss = 0.07600125775937945
Trained batch 414 in epoch 3, gen_loss = 0.40821714738765397, disc_loss = 0.07583761559462691
Trained batch 415 in epoch 3, gen_loss = 0.408087635699373, disc_loss = 0.07569243133408375
Trained batch 416 in epoch 3, gen_loss = 0.4079355020031369, disc_loss = 0.07555242125346935
Trained batch 417 in epoch 3, gen_loss = 0.4079445397311991, disc_loss = 0.07538849144781891
Trained batch 418 in epoch 3, gen_loss = 0.40789498114927286, disc_loss = 0.07523190427064753
Trained batch 419 in epoch 3, gen_loss = 0.4077184900641441, disc_loss = 0.07510279795332324
Trained batch 420 in epoch 3, gen_loss = 0.4078633058241031, disc_loss = 0.07494479185080868
Trained batch 421 in epoch 3, gen_loss = 0.4081132833567841, disc_loss = 0.07478168219001302
Trained batch 422 in epoch 3, gen_loss = 0.40840705665572596, disc_loss = 0.07462287768963768
Trained batch 423 in epoch 3, gen_loss = 0.40846759565877466, disc_loss = 0.07448417449892797
Trained batch 424 in epoch 3, gen_loss = 0.4085056281089783, disc_loss = 0.07436301325502641
Trained batch 425 in epoch 3, gen_loss = 0.4086579793076, disc_loss = 0.07420668543967912
Trained batch 426 in epoch 3, gen_loss = 0.4088111713842709, disc_loss = 0.07406389131810542
Trained batch 427 in epoch 3, gen_loss = 0.40875338477509043, disc_loss = 0.07390288900144433
Trained batch 428 in epoch 3, gen_loss = 0.40860982284401404, disc_loss = 0.07374356824162227
Trained batch 429 in epoch 3, gen_loss = 0.4085739060196766, disc_loss = 0.07361060971675744
Trained batch 430 in epoch 3, gen_loss = 0.4086613220156207, disc_loss = 0.0736301037582316
Trained batch 431 in epoch 3, gen_loss = 0.4085456296387646, disc_loss = 0.07422508958067435
Trained batch 432 in epoch 3, gen_loss = 0.4087699955247566, disc_loss = 0.07445337772950117
Trained batch 433 in epoch 3, gen_loss = 0.40857744443526467, disc_loss = 0.07443426973358105
Trained batch 434 in epoch 3, gen_loss = 0.4084430631549879, disc_loss = 0.07445348495960065
Trained batch 435 in epoch 3, gen_loss = 0.4084328165568343, disc_loss = 0.07471791212126579
Trained batch 436 in epoch 3, gen_loss = 0.4082935061689372, disc_loss = 0.07476044766651786
Trained batch 437 in epoch 3, gen_loss = 0.4084102818955025, disc_loss = 0.07468098680037988
Trained batch 438 in epoch 3, gen_loss = 0.4084420345367223, disc_loss = 0.07472449762466658
Trained batch 439 in epoch 3, gen_loss = 0.40836005786603147, disc_loss = 0.07487861494512552
Trained batch 440 in epoch 3, gen_loss = 0.4083653918199258, disc_loss = 0.07531556683801571
Trained batch 441 in epoch 3, gen_loss = 0.408213256036534, disc_loss = 0.07537077437154949
Trained batch 442 in epoch 3, gen_loss = 0.4084175710753447, disc_loss = 0.07522325543266285
Trained batch 443 in epoch 3, gen_loss = 0.4084438263430252, disc_loss = 0.07509912965873776
Trained batch 444 in epoch 3, gen_loss = 0.4083158517151736, disc_loss = 0.07503716528018037
Trained batch 445 in epoch 3, gen_loss = 0.4081460303656189, disc_loss = 0.07498543611894708
Trained batch 446 in epoch 3, gen_loss = 0.4080842107334393, disc_loss = 0.07512947876252217
Trained batch 447 in epoch 3, gen_loss = 0.4082353309994297, disc_loss = 0.07538782781193731
Trained batch 448 in epoch 3, gen_loss = 0.4082812224172537, disc_loss = 0.07528860313726593
Trained batch 449 in epoch 3, gen_loss = 0.40812634434964923, disc_loss = 0.07521723147171239
Trained batch 450 in epoch 3, gen_loss = 0.4081922725272549, disc_loss = 0.07517524256976012
Trained batch 451 in epoch 3, gen_loss = 0.40826055658074606, disc_loss = 0.07502277945971891
Trained batch 452 in epoch 3, gen_loss = 0.40819572658991443, disc_loss = 0.07495782778970486
Trained batch 453 in epoch 3, gen_loss = 0.4080748433321058, disc_loss = 0.07489541248164021
Trained batch 454 in epoch 3, gen_loss = 0.40808332935794367, disc_loss = 0.07483652353307212
Trained batch 455 in epoch 3, gen_loss = 0.4080183792271112, disc_loss = 0.07471428871698056
Trained batch 456 in epoch 3, gen_loss = 0.4079333661160793, disc_loss = 0.07465954201247062
Trained batch 457 in epoch 3, gen_loss = 0.40803675412090584, disc_loss = 0.0745854770172973
Trained batch 458 in epoch 3, gen_loss = 0.4077596681959489, disc_loss = 0.07472603422871635
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 0.44033995270729065, disc_loss = 0.023959847167134285
Trained batch 1 in epoch 4, gen_loss = 0.436768040060997, disc_loss = 0.018116923980414867
Trained batch 2 in epoch 4, gen_loss = 0.43381378054618835, disc_loss = 0.03159737524886926
Trained batch 3 in epoch 4, gen_loss = 0.4598645940423012, disc_loss = 0.03582224203273654
Trained batch 4 in epoch 4, gen_loss = 0.45084255933761597, disc_loss = 0.0300207681953907
Trained batch 5 in epoch 4, gen_loss = 0.43878984451293945, disc_loss = 0.030415194109082222
Trained batch 6 in epoch 4, gen_loss = 0.4220691110406603, disc_loss = 0.03219978351678167
Trained batch 7 in epoch 4, gen_loss = 0.42541203275322914, disc_loss = 0.029489662032574415
Trained batch 8 in epoch 4, gen_loss = 0.40579168332947624, disc_loss = 0.03405911516812113
Trained batch 9 in epoch 4, gen_loss = 0.4121284157037735, disc_loss = 0.03867666907608509
Trained batch 10 in epoch 4, gen_loss = 0.4017124582420696, disc_loss = 0.043571856550195
Trained batch 11 in epoch 4, gen_loss = 0.40680918594201404, disc_loss = 0.044383613703151546
Trained batch 12 in epoch 4, gen_loss = 0.4014696157895602, disc_loss = 0.04359438843452013
Trained batch 13 in epoch 4, gen_loss = 0.3981427103281021, disc_loss = 0.04878879232066018
Trained batch 14 in epoch 4, gen_loss = 0.398223751783371, disc_loss = 0.04628012130657832
Trained batch 15 in epoch 4, gen_loss = 0.3963533528149128, disc_loss = 0.045879065757617354
Trained batch 16 in epoch 4, gen_loss = 0.39581430308959065, disc_loss = 0.048995835158754796
Trained batch 17 in epoch 4, gen_loss = 0.395539316866133, disc_loss = 0.054842096442977585
Trained batch 18 in epoch 4, gen_loss = 0.4029219432881004, disc_loss = 0.058439191430807114
Trained batch 19 in epoch 4, gen_loss = 0.40473206639289855, disc_loss = 0.061479944922029975
Trained batch 20 in epoch 4, gen_loss = 0.4089918150788262, disc_loss = 0.06170537092146419
Trained batch 21 in epoch 4, gen_loss = 0.40892336720770056, disc_loss = 0.06042706102810123
Trained batch 22 in epoch 4, gen_loss = 0.40797069798345154, disc_loss = 0.05897987633943558
Trained batch 23 in epoch 4, gen_loss = 0.4132738908131917, disc_loss = 0.05764975608326495
Trained batch 24 in epoch 4, gen_loss = 0.41249251961708067, disc_loss = 0.05634968057274818
Trained batch 25 in epoch 4, gen_loss = 0.4132088663486334, disc_loss = 0.05473178091387336
Trained batch 26 in epoch 4, gen_loss = 0.4160420916698597, disc_loss = 0.05314129449565102
Trained batch 27 in epoch 4, gen_loss = 0.4154657817312649, disc_loss = 0.051584241479369145
Trained batch 28 in epoch 4, gen_loss = 0.4150455265209593, disc_loss = 0.05007432250241781
Trained batch 29 in epoch 4, gen_loss = 0.41585834622383117, disc_loss = 0.049191880878061055
Trained batch 30 in epoch 4, gen_loss = 0.4149506611208762, disc_loss = 0.04961161246343005
Trained batch 31 in epoch 4, gen_loss = 0.415285499766469, disc_loss = 0.0486305489030201
Trained batch 32 in epoch 4, gen_loss = 0.41714348124735284, disc_loss = 0.0480206971423644
Trained batch 33 in epoch 4, gen_loss = 0.4177430061733021, disc_loss = 0.04712588605744874
Trained batch 34 in epoch 4, gen_loss = 0.4159356474876404, disc_loss = 0.04749437232634851
Trained batch 35 in epoch 4, gen_loss = 0.41703730821609497, disc_loss = 0.04686673609022465
Trained batch 36 in epoch 4, gen_loss = 0.41786044433310227, disc_loss = 0.04817389457713108
Trained batch 37 in epoch 4, gen_loss = 0.4145481719782478, disc_loss = 0.05217804938652798
Trained batch 38 in epoch 4, gen_loss = 0.416742857450094, disc_loss = 0.0532001625889769
Trained batch 39 in epoch 4, gen_loss = 0.41822937726974485, disc_loss = 0.05295295205432922
Trained batch 40 in epoch 4, gen_loss = 0.4166638582217984, disc_loss = 0.051822045022939765
Trained batch 41 in epoch 4, gen_loss = 0.41521192093690235, disc_loss = 0.05167442380583712
Trained batch 42 in epoch 4, gen_loss = 0.414780315964721, disc_loss = 0.05154036763015875
Trained batch 43 in epoch 4, gen_loss = 0.41443848406726663, disc_loss = 0.050534959956580264
Trained batch 44 in epoch 4, gen_loss = 0.41324045326974657, disc_loss = 0.04992821058258414
Trained batch 45 in epoch 4, gen_loss = 0.41336845898109936, disc_loss = 0.0490650010963335
Trained batch 46 in epoch 4, gen_loss = 0.41240696450497244, disc_loss = 0.048770959657478206
Trained batch 47 in epoch 4, gen_loss = 0.4129250297943751, disc_loss = 0.04811513225043503
Trained batch 48 in epoch 4, gen_loss = 0.4132639078461394, disc_loss = 0.047504781298719496
Trained batch 49 in epoch 4, gen_loss = 0.41374147951602935, disc_loss = 0.0474356575217098
Trained batch 50 in epoch 4, gen_loss = 0.4157002819519417, disc_loss = 0.047708355757754804
Trained batch 51 in epoch 4, gen_loss = 0.416109810081812, disc_loss = 0.04737957182805985
Trained batch 52 in epoch 4, gen_loss = 0.4165843832042982, disc_loss = 0.046663434042612896
Trained batch 53 in epoch 4, gen_loss = 0.4168137720337621, disc_loss = 0.045939249685034156
Trained batch 54 in epoch 4, gen_loss = 0.41810598319227044, disc_loss = 0.04521526549519463
Trained batch 55 in epoch 4, gen_loss = 0.41874908762318747, disc_loss = 0.04486901383747214
Trained batch 56 in epoch 4, gen_loss = 0.41778569786172165, disc_loss = 0.04427203213338528
Trained batch 57 in epoch 4, gen_loss = 0.4173553791539422, disc_loss = 0.04367533192070651
Trained batch 58 in epoch 4, gen_loss = 0.41646837582022456, disc_loss = 0.04315066227878807
Trained batch 59 in epoch 4, gen_loss = 0.41481642226378124, disc_loss = 0.04864711156891038
Trained batch 60 in epoch 4, gen_loss = 0.4129127190738428, disc_loss = 0.05215876015880313
Trained batch 61 in epoch 4, gen_loss = 0.4113876930167598, disc_loss = 0.05348565973972361
Trained batch 62 in epoch 4, gen_loss = 0.41150552885872976, disc_loss = 0.054164288691171104
Trained batch 63 in epoch 4, gen_loss = 0.41252460749819875, disc_loss = 0.0544369687922881
Trained batch 64 in epoch 4, gen_loss = 0.41207504685108476, disc_loss = 0.05441887135832356
Trained batch 65 in epoch 4, gen_loss = 0.41274714876304974, disc_loss = 0.05458140021161825
Trained batch 66 in epoch 4, gen_loss = 0.41228349840463097, disc_loss = 0.055213555783978595
Trained batch 67 in epoch 4, gen_loss = 0.41136878816520467, disc_loss = 0.055061207351493925
Trained batch 68 in epoch 4, gen_loss = 0.4121576439643252, disc_loss = 0.055514046065239374
Trained batch 69 in epoch 4, gen_loss = 0.4113872494016375, disc_loss = 0.055186312572498404
Trained batch 70 in epoch 4, gen_loss = 0.41015776907893975, disc_loss = 0.05511828415541792
Trained batch 71 in epoch 4, gen_loss = 0.40892208905683625, disc_loss = 0.05554846051381901
Trained batch 72 in epoch 4, gen_loss = 0.4097163926248681, disc_loss = 0.05563642460317032
Trained batch 73 in epoch 4, gen_loss = 0.41014201616918716, disc_loss = 0.05569467822568038
Trained batch 74 in epoch 4, gen_loss = 0.41005854845046996, disc_loss = 0.05532111039385199
Trained batch 75 in epoch 4, gen_loss = 0.4092840740555211, disc_loss = 0.055631903447455874
Trained batch 76 in epoch 4, gen_loss = 0.40954902342387606, disc_loss = 0.056581249297294134
Trained batch 77 in epoch 4, gen_loss = 0.40856735293681806, disc_loss = 0.058556828558301695
Trained batch 78 in epoch 4, gen_loss = 0.4088490488408487, disc_loss = 0.05984585742242163
Trained batch 79 in epoch 4, gen_loss = 0.4080255802720785, disc_loss = 0.059982414549449456
Trained batch 80 in epoch 4, gen_loss = 0.4087227542459229, disc_loss = 0.05945771627335085
Trained batch 81 in epoch 4, gen_loss = 0.4089176738407554, disc_loss = 0.05909870735869357
Trained batch 82 in epoch 4, gen_loss = 0.4087427998163614, disc_loss = 0.05901881480724158
Trained batch 83 in epoch 4, gen_loss = 0.4094945937395096, disc_loss = 0.05863658915872553
Trained batch 84 in epoch 4, gen_loss = 0.4098888453315286, disc_loss = 0.05807544276227846
Trained batch 85 in epoch 4, gen_loss = 0.4104895314504934, disc_loss = 0.057689047878781374
Trained batch 86 in epoch 4, gen_loss = 0.41119678267117205, disc_loss = 0.05762758860150459
Trained batch 87 in epoch 4, gen_loss = 0.4115501432256265, disc_loss = 0.05791991153753109
Trained batch 88 in epoch 4, gen_loss = 0.41194334324826015, disc_loss = 0.05755742723540811
Trained batch 89 in epoch 4, gen_loss = 0.41112039188543953, disc_loss = 0.05736168875979881
Trained batch 90 in epoch 4, gen_loss = 0.4115452501145038, disc_loss = 0.05817968885997658
Trained batch 91 in epoch 4, gen_loss = 0.4113239600606587, disc_loss = 0.05827977998769316
Trained batch 92 in epoch 4, gen_loss = 0.41074389411557105, disc_loss = 0.05774234335929636
Trained batch 93 in epoch 4, gen_loss = 0.4099004715681076, disc_loss = 0.05753025916365392
Trained batch 94 in epoch 4, gen_loss = 0.4104143682279085, disc_loss = 0.056987994610282935
Trained batch 95 in epoch 4, gen_loss = 0.4099222918351491, disc_loss = 0.05666461378859822
Trained batch 96 in epoch 4, gen_loss = 0.40986263321847033, disc_loss = 0.056342661471979825
Trained batch 97 in epoch 4, gen_loss = 0.4101015347607282, disc_loss = 0.056397312734162014
Trained batch 98 in epoch 4, gen_loss = 0.40902643312107434, disc_loss = 0.05723966189161545
Trained batch 99 in epoch 4, gen_loss = 0.4100154411792755, disc_loss = 0.06037224350031465
Trained batch 100 in epoch 4, gen_loss = 0.4087430604613653, disc_loss = 0.0631097318871998
Trained batch 101 in epoch 4, gen_loss = 0.40808363200402725, disc_loss = 0.0646539689635164
Trained batch 102 in epoch 4, gen_loss = 0.4082104908031167, disc_loss = 0.06814956865318626
Trained batch 103 in epoch 4, gen_loss = 0.4087990273076754, disc_loss = 0.07340502650745642
Trained batch 104 in epoch 4, gen_loss = 0.40858388088998343, disc_loss = 0.07809818157748807
Trained batch 105 in epoch 4, gen_loss = 0.40834479202639384, disc_loss = 0.08238774732651435
Trained batch 106 in epoch 4, gen_loss = 0.4074806721411019, disc_loss = 0.08295695815740206
Trained batch 107 in epoch 4, gen_loss = 0.40752358817391926, disc_loss = 0.08367022607665232
Trained batch 108 in epoch 4, gen_loss = 0.407460096232388, disc_loss = 0.0840725640151137
Trained batch 109 in epoch 4, gen_loss = 0.40671527629548854, disc_loss = 0.0847470081453635
Trained batch 110 in epoch 4, gen_loss = 0.4064404905379356, disc_loss = 0.08522257421518097
Trained batch 111 in epoch 4, gen_loss = 0.40621695906988214, disc_loss = 0.08559640894028624
Trained batch 112 in epoch 4, gen_loss = 0.4062110082765596, disc_loss = 0.085670499786306
Trained batch 113 in epoch 4, gen_loss = 0.4060391344522175, disc_loss = 0.08558135137795225
Trained batch 114 in epoch 4, gen_loss = 0.4054264154123223, disc_loss = 0.08682984539267162
Trained batch 115 in epoch 4, gen_loss = 0.40564953612870186, disc_loss = 0.08776341967589768
Trained batch 116 in epoch 4, gen_loss = 0.40515454788493294, disc_loss = 0.08781955873147927
Trained batch 117 in epoch 4, gen_loss = 0.4044400645514666, disc_loss = 0.0881845320109278
Trained batch 118 in epoch 4, gen_loss = 0.40460959277233155, disc_loss = 0.08772586077498663
Trained batch 119 in epoch 4, gen_loss = 0.4052836445470651, disc_loss = 0.0876891227865902
Trained batch 120 in epoch 4, gen_loss = 0.40504691448093444, disc_loss = 0.08737566061548827
Trained batch 121 in epoch 4, gen_loss = 0.4052231780818251, disc_loss = 0.08720042963787059
Trained batch 122 in epoch 4, gen_loss = 0.4055911682970156, disc_loss = 0.08673512694478883
Trained batch 123 in epoch 4, gen_loss = 0.4063762851780461, disc_loss = 0.08625106891662243
Trained batch 124 in epoch 4, gen_loss = 0.40650240874290466, disc_loss = 0.08578002260252833
Trained batch 125 in epoch 4, gen_loss = 0.40667296047248536, disc_loss = 0.08525539339993089
Trained batch 126 in epoch 4, gen_loss = 0.4071325568232949, disc_loss = 0.08478057859318815
Trained batch 127 in epoch 4, gen_loss = 0.407599761383608, disc_loss = 0.08472681353669032
Trained batch 128 in epoch 4, gen_loss = 0.40714197010956993, disc_loss = 0.08486079250989381
Trained batch 129 in epoch 4, gen_loss = 0.40764720302361707, disc_loss = 0.08780024102889002
Trained batch 130 in epoch 4, gen_loss = 0.40759330191685045, disc_loss = 0.08859256222374907
Trained batch 131 in epoch 4, gen_loss = 0.40755440181855, disc_loss = 0.08880993463875105
Trained batch 132 in epoch 4, gen_loss = 0.4066829764305201, disc_loss = 0.08845674016519933
Trained batch 133 in epoch 4, gen_loss = 0.40674645976344154, disc_loss = 0.08815511554799307
Trained batch 134 in epoch 4, gen_loss = 0.4064469728204939, disc_loss = 0.08767114880115345
Trained batch 135 in epoch 4, gen_loss = 0.4065243647817303, disc_loss = 0.08722500094582382
Trained batch 136 in epoch 4, gen_loss = 0.4057590539438011, disc_loss = 0.08749816106822696
Trained batch 137 in epoch 4, gen_loss = 0.40636136285636737, disc_loss = 0.08898847152991896
Trained batch 138 in epoch 4, gen_loss = 0.4060736791693049, disc_loss = 0.08901491870755236
Trained batch 139 in epoch 4, gen_loss = 0.40519265362194606, disc_loss = 0.08936606945935636
Trained batch 140 in epoch 4, gen_loss = 0.40549151440884207, disc_loss = 0.08928632025164387
Trained batch 141 in epoch 4, gen_loss = 0.4057182361122588, disc_loss = 0.08897604942518536
Trained batch 142 in epoch 4, gen_loss = 0.4056877291702724, disc_loss = 0.08873120077618665
Trained batch 143 in epoch 4, gen_loss = 0.40564859099686146, disc_loss = 0.08816162581853051
Trained batch 144 in epoch 4, gen_loss = 0.40590092046507475, disc_loss = 0.08772132287187309
Trained batch 145 in epoch 4, gen_loss = 0.40569568700986364, disc_loss = 0.08759106311321974
Trained batch 146 in epoch 4, gen_loss = 0.40540114876364364, disc_loss = 0.0881445091946342
Trained batch 147 in epoch 4, gen_loss = 0.40481700748205185, disc_loss = 0.08946301972782994
Trained batch 148 in epoch 4, gen_loss = 0.4051082920308081, disc_loss = 0.08921462890923323
Trained batch 149 in epoch 4, gen_loss = 0.4052694274981817, disc_loss = 0.08900026426650584
Trained batch 150 in epoch 4, gen_loss = 0.40530584505851697, disc_loss = 0.08861715909994103
Trained batch 151 in epoch 4, gen_loss = 0.40548024561844376, disc_loss = 0.08843467517841705
Trained batch 152 in epoch 4, gen_loss = 0.40546758287872364, disc_loss = 0.08797328351552483
Trained batch 153 in epoch 4, gen_loss = 0.40532277060019506, disc_loss = 0.08812975193760902
Trained batch 154 in epoch 4, gen_loss = 0.40482066196780053, disc_loss = 0.08925402902006623
Trained batch 155 in epoch 4, gen_loss = 0.4054340527225763, disc_loss = 0.08916079126095447
Trained batch 156 in epoch 4, gen_loss = 0.4053747061711208, disc_loss = 0.08869772493115562
Trained batch 157 in epoch 4, gen_loss = 0.40551361667958996, disc_loss = 0.08830140082790411
Trained batch 158 in epoch 4, gen_loss = 0.405603919014241, disc_loss = 0.08779016390454562
Trained batch 159 in epoch 4, gen_loss = 0.4054821148514748, disc_loss = 0.08735917497251648
Trained batch 160 in epoch 4, gen_loss = 0.4054401635383227, disc_loss = 0.08691157051506712
Trained batch 161 in epoch 4, gen_loss = 0.40538483177438195, disc_loss = 0.08651211299289616
Trained batch 162 in epoch 4, gen_loss = 0.40553806219364236, disc_loss = 0.08614287094892992
Trained batch 163 in epoch 4, gen_loss = 0.4057624272820426, disc_loss = 0.08616358617877179
Trained batch 164 in epoch 4, gen_loss = 0.4054700390859084, disc_loss = 0.08602456548956759
Trained batch 165 in epoch 4, gen_loss = 0.4058083705155246, disc_loss = 0.08559320426366505
Trained batch 166 in epoch 4, gen_loss = 0.4056726301501611, disc_loss = 0.08539507461399465
Trained batch 167 in epoch 4, gen_loss = 0.40594417069639477, disc_loss = 0.08526015014753544
Trained batch 168 in epoch 4, gen_loss = 0.40641878448294466, disc_loss = 0.08484457327141123
Trained batch 169 in epoch 4, gen_loss = 0.40642036094385037, disc_loss = 0.08452985385049354
Trained batch 170 in epoch 4, gen_loss = 0.4068615328498751, disc_loss = 0.08420073928050044
Trained batch 171 in epoch 4, gen_loss = 0.40602109719847523, disc_loss = 0.0840049853283089
Trained batch 172 in epoch 4, gen_loss = 0.40614546189418416, disc_loss = 0.08383330725122652
Trained batch 173 in epoch 4, gen_loss = 0.4060754561903833, disc_loss = 0.08341772772168377
Trained batch 174 in epoch 4, gen_loss = 0.4059098746095385, disc_loss = 0.08298661396705678
Trained batch 175 in epoch 4, gen_loss = 0.4055518958378922, disc_loss = 0.08265347479027696
Trained batch 176 in epoch 4, gen_loss = 0.4056730979243241, disc_loss = 0.08229020082965324
Trained batch 177 in epoch 4, gen_loss = 0.4056891171115168, disc_loss = 0.08189397429513713
Trained batch 178 in epoch 4, gen_loss = 0.40537277563324187, disc_loss = 0.08153235407379669
Trained batch 179 in epoch 4, gen_loss = 0.4050820327467389, disc_loss = 0.08127411846847583
Trained batch 180 in epoch 4, gen_loss = 0.4051014794170527, disc_loss = 0.08085533864127256
Trained batch 181 in epoch 4, gen_loss = 0.4053362069221643, disc_loss = 0.08048546401487029
Trained batch 182 in epoch 4, gen_loss = 0.4052743139814158, disc_loss = 0.0801207959942031
Trained batch 183 in epoch 4, gen_loss = 0.4050276342617429, disc_loss = 0.07981149112532401
Trained batch 184 in epoch 4, gen_loss = 0.4052963348659309, disc_loss = 0.07945359928432752
Trained batch 185 in epoch 4, gen_loss = 0.4054941190506822, disc_loss = 0.07912995281969748
Trained batch 186 in epoch 4, gen_loss = 0.40528892355169205, disc_loss = 0.07880792488159741
Trained batch 187 in epoch 4, gen_loss = 0.4052271097898483, disc_loss = 0.07842301076000675
Trained batch 188 in epoch 4, gen_loss = 0.4058033641053255, disc_loss = 0.07806173987962582
Trained batch 189 in epoch 4, gen_loss = 0.4057324169497741, disc_loss = 0.07798388980721173
Trained batch 190 in epoch 4, gen_loss = 0.4055686485392885, disc_loss = 0.0783166087656745
Trained batch 191 in epoch 4, gen_loss = 0.4056541350049277, disc_loss = 0.07802234314537297
Trained batch 192 in epoch 4, gen_loss = 0.40565288005097544, disc_loss = 0.07898974762216134
Trained batch 193 in epoch 4, gen_loss = 0.4055617430160955, disc_loss = 0.07888009564317379
Trained batch 194 in epoch 4, gen_loss = 0.40528736756398126, disc_loss = 0.07896113445361455
Trained batch 195 in epoch 4, gen_loss = 0.40552434173165536, disc_loss = 0.07875964104445005
Trained batch 196 in epoch 4, gen_loss = 0.40536086677294697, disc_loss = 0.07842562168004549
Trained batch 197 in epoch 4, gen_loss = 0.40568130004285563, disc_loss = 0.07812827061673608
Trained batch 198 in epoch 4, gen_loss = 0.4056210079085288, disc_loss = 0.07792042980167135
Trained batch 199 in epoch 4, gen_loss = 0.4059680524468422, disc_loss = 0.07785513186827302
Trained batch 200 in epoch 4, gen_loss = 0.4057303529177139, disc_loss = 0.07772962383888847
Trained batch 201 in epoch 4, gen_loss = 0.4061055229146882, disc_loss = 0.07739780584147365
Trained batch 202 in epoch 4, gen_loss = 0.4060794018172278, disc_loss = 0.07737170158899183
Trained batch 203 in epoch 4, gen_loss = 0.40583061572967793, disc_loss = 0.07710469082253528
Trained batch 204 in epoch 4, gen_loss = 0.4061548874145601, disc_loss = 0.076771790425225
Trained batch 205 in epoch 4, gen_loss = 0.4064172140313584, disc_loss = 0.076432226700437
Trained batch 206 in epoch 4, gen_loss = 0.40616488154383673, disc_loss = 0.07611095034269895
Trained batch 207 in epoch 4, gen_loss = 0.40635542614528763, disc_loss = 0.07579020117051326
Trained batch 208 in epoch 4, gen_loss = 0.4066567455182235, disc_loss = 0.07548051587702555
Trained batch 209 in epoch 4, gen_loss = 0.4062144032546452, disc_loss = 0.07553034960514023
Trained batch 210 in epoch 4, gen_loss = 0.40662933963734954, disc_loss = 0.0755693906150158
Trained batch 211 in epoch 4, gen_loss = 0.406853104959119, disc_loss = 0.07528998253796741
Trained batch 212 in epoch 4, gen_loss = 0.4067811807836165, disc_loss = 0.07501956401611438
Trained batch 213 in epoch 4, gen_loss = 0.40635192101803896, disc_loss = 0.07482543142912822
Trained batch 214 in epoch 4, gen_loss = 0.40618133434029513, disc_loss = 0.07459924260024414
Trained batch 215 in epoch 4, gen_loss = 0.40623432646195096, disc_loss = 0.07427957357571426
Trained batch 216 in epoch 4, gen_loss = 0.4062666085458571, disc_loss = 0.0740721124129945
Trained batch 217 in epoch 4, gen_loss = 0.4057699913552048, disc_loss = 0.07396076411359148
Trained batch 218 in epoch 4, gen_loss = 0.4060449079019294, disc_loss = 0.07370251389305409
Trained batch 219 in epoch 4, gen_loss = 0.40594342987645754, disc_loss = 0.07351852847813543
Trained batch 220 in epoch 4, gen_loss = 0.40575629769407245, disc_loss = 0.07342212737592704
Trained batch 221 in epoch 4, gen_loss = 0.40547835075103483, disc_loss = 0.07311336488068641
Trained batch 222 in epoch 4, gen_loss = 0.40544979615061805, disc_loss = 0.07280977857988244
Trained batch 223 in epoch 4, gen_loss = 0.40513129412595716, disc_loss = 0.07257637833078791
Trained batch 224 in epoch 4, gen_loss = 0.40536461843384636, disc_loss = 0.0722889897889561
Trained batch 225 in epoch 4, gen_loss = 0.40514529911817704, disc_loss = 0.07267338324305231
Trained batch 226 in epoch 4, gen_loss = 0.40504178693641124, disc_loss = 0.07420872089489966
Trained batch 227 in epoch 4, gen_loss = 0.4049286374397445, disc_loss = 0.07409125059973776
Trained batch 228 in epoch 4, gen_loss = 0.40532392862061745, disc_loss = 0.07419601177154149
Trained batch 229 in epoch 4, gen_loss = 0.40535839005656865, disc_loss = 0.07414136451223623
Trained batch 230 in epoch 4, gen_loss = 0.4051070116557084, disc_loss = 0.0746446925324279
Trained batch 231 in epoch 4, gen_loss = 0.4050850895201338, disc_loss = 0.07445538532117317
Trained batch 232 in epoch 4, gen_loss = 0.40499649833200313, disc_loss = 0.07453594865205462
Trained batch 233 in epoch 4, gen_loss = 0.4046766383525653, disc_loss = 0.07449908882506892
Trained batch 234 in epoch 4, gen_loss = 0.4045879604968619, disc_loss = 0.0742448515238914
Trained batch 235 in epoch 4, gen_loss = 0.40455668722674, disc_loss = 0.07404130198440309
Trained batch 236 in epoch 4, gen_loss = 0.40467065082320686, disc_loss = 0.07393214441364325
Trained batch 237 in epoch 4, gen_loss = 0.40478610654338065, disc_loss = 0.07370640569123901
Trained batch 238 in epoch 4, gen_loss = 0.40440203305567657, disc_loss = 0.07361837368941707
Trained batch 239 in epoch 4, gen_loss = 0.40469466572006546, disc_loss = 0.074412807651485
Trained batch 240 in epoch 4, gen_loss = 0.40476749064516726, disc_loss = 0.07423407228903157
Trained batch 241 in epoch 4, gen_loss = 0.40511123799095466, disc_loss = 0.07427976422073428
Trained batch 242 in epoch 4, gen_loss = 0.4051167355398092, disc_loss = 0.07408106556246555
Trained batch 243 in epoch 4, gen_loss = 0.4051452563678632, disc_loss = 0.07381383180770962
Trained batch 244 in epoch 4, gen_loss = 0.404915037933661, disc_loss = 0.07356669383541661
Trained batch 245 in epoch 4, gen_loss = 0.40473087325813323, disc_loss = 0.07339983432727858
Trained batch 246 in epoch 4, gen_loss = 0.4044555237418727, disc_loss = 0.07321562268865495
Trained batch 247 in epoch 4, gen_loss = 0.4043926460848701, disc_loss = 0.07296368089549604
Trained batch 248 in epoch 4, gen_loss = 0.40443093123206175, disc_loss = 0.07275090390913577
Trained batch 249 in epoch 4, gen_loss = 0.4047663527727127, disc_loss = 0.07252917983010411
Trained batch 250 in epoch 4, gen_loss = 0.40436121762036326, disc_loss = 0.07242765525853136
Trained batch 251 in epoch 4, gen_loss = 0.40433765959645074, disc_loss = 0.07217068823483137
Trained batch 252 in epoch 4, gen_loss = 0.40448105394133466, disc_loss = 0.07223662708631971
Trained batch 253 in epoch 4, gen_loss = 0.4043131115164344, disc_loss = 0.07214078840645631
Trained batch 254 in epoch 4, gen_loss = 0.40461601848695794, disc_loss = 0.07194593157619238
Trained batch 255 in epoch 4, gen_loss = 0.4050691296579316, disc_loss = 0.07168986426040647
Trained batch 256 in epoch 4, gen_loss = 0.4053978345969308, disc_loss = 0.07146505856024037
Trained batch 257 in epoch 4, gen_loss = 0.4053318582532942, disc_loss = 0.07124211543506777
Trained batch 258 in epoch 4, gen_loss = 0.4052986722425144, disc_loss = 0.07118649207932953
Trained batch 259 in epoch 4, gen_loss = 0.4053880547101681, disc_loss = 0.07108546493646617
Trained batch 260 in epoch 4, gen_loss = 0.40547442413381235, disc_loss = 0.07085394988842737
Trained batch 261 in epoch 4, gen_loss = 0.4053039233420641, disc_loss = 0.07063273668203873
Trained batch 262 in epoch 4, gen_loss = 0.4054559524748262, disc_loss = 0.07048594707290257
Trained batch 263 in epoch 4, gen_loss = 0.40553294494748116, disc_loss = 0.07045029320359004
Trained batch 264 in epoch 4, gen_loss = 0.40583829632345236, disc_loss = 0.0702952588855658
Trained batch 265 in epoch 4, gen_loss = 0.4062040060534513, disc_loss = 0.07008844937540983
Trained batch 266 in epoch 4, gen_loss = 0.4060194387418054, disc_loss = 0.06999112235919366
Trained batch 267 in epoch 4, gen_loss = 0.40604365205586845, disc_loss = 0.06984025893260294
Trained batch 268 in epoch 4, gen_loss = 0.40610000258484735, disc_loss = 0.06960462758379908
Trained batch 269 in epoch 4, gen_loss = 0.4059427703972216, disc_loss = 0.06939977695130639
Trained batch 270 in epoch 4, gen_loss = 0.4061230865351828, disc_loss = 0.06919716923356715
Trained batch 271 in epoch 4, gen_loss = 0.4063830429359394, disc_loss = 0.06899969145546064
Trained batch 272 in epoch 4, gen_loss = 0.406383651189315, disc_loss = 0.06920350583154203
Trained batch 273 in epoch 4, gen_loss = 0.4062199474033648, disc_loss = 0.06956634401296177
Trained batch 274 in epoch 4, gen_loss = 0.4060571877522902, disc_loss = 0.06939380215650255
Trained batch 275 in epoch 4, gen_loss = 0.40613632508810016, disc_loss = 0.06935760753391229
Trained batch 276 in epoch 4, gen_loss = 0.4060659059978995, disc_loss = 0.06919260034572992
Trained batch 277 in epoch 4, gen_loss = 0.40628612491724303, disc_loss = 0.06899215473639343
Trained batch 278 in epoch 4, gen_loss = 0.4061975026216131, disc_loss = 0.06883015513994253
Trained batch 279 in epoch 4, gen_loss = 0.4063460254243442, disc_loss = 0.06874203528610191
Trained batch 280 in epoch 4, gen_loss = 0.40592248509787154, disc_loss = 0.06897373588629784
Trained batch 281 in epoch 4, gen_loss = 0.4064094803646101, disc_loss = 0.06951684215112675
Trained batch 282 in epoch 4, gen_loss = 0.4065798894887257, disc_loss = 0.06930765461887467
Trained batch 283 in epoch 4, gen_loss = 0.4064456283206671, disc_loss = 0.06954878027891924
Trained batch 284 in epoch 4, gen_loss = 0.40629904918503346, disc_loss = 0.07100788380689266
Trained batch 285 in epoch 4, gen_loss = 0.40624863409495854, disc_loss = 0.07095327040415023
Trained batch 286 in epoch 4, gen_loss = 0.4061366077707204, disc_loss = 0.07086088722214778
Trained batch 287 in epoch 4, gen_loss = 0.406243035569787, disc_loss = 0.07064772751376343
Trained batch 288 in epoch 4, gen_loss = 0.4064348413251263, disc_loss = 0.07057362985329954
Trained batch 289 in epoch 4, gen_loss = 0.4060287896929116, disc_loss = 0.07056065499461417
Trained batch 290 in epoch 4, gen_loss = 0.40577463124625873, disc_loss = 0.07038143215400144
Trained batch 291 in epoch 4, gen_loss = 0.40582225675860495, disc_loss = 0.0706378184737357
Trained batch 292 in epoch 4, gen_loss = 0.40546447679451303, disc_loss = 0.07134854488087494
Trained batch 293 in epoch 4, gen_loss = 0.4055536835372042, disc_loss = 0.07152582947988392
Trained batch 294 in epoch 4, gen_loss = 0.40551925756163515, disc_loss = 0.07140131199700853
Trained batch 295 in epoch 4, gen_loss = 0.40559093110464717, disc_loss = 0.0712052350580642
Trained batch 296 in epoch 4, gen_loss = 0.40561050547895205, disc_loss = 0.07102800031139293
Trained batch 297 in epoch 4, gen_loss = 0.405494560431314, disc_loss = 0.07111537119923722
Trained batch 298 in epoch 4, gen_loss = 0.40528712872677425, disc_loss = 0.07097817982631084
Trained batch 299 in epoch 4, gen_loss = 0.4050152931610743, disc_loss = 0.07131814793062707
Trained batch 300 in epoch 4, gen_loss = 0.4052404680125341, disc_loss = 0.07253825729186848
Trained batch 301 in epoch 4, gen_loss = 0.405191953707215, disc_loss = 0.07270850596752092
Trained batch 302 in epoch 4, gen_loss = 0.40523012252924073, disc_loss = 0.07278599263331777
Trained batch 303 in epoch 4, gen_loss = 0.4050090200218715, disc_loss = 0.07267715853308082
Trained batch 304 in epoch 4, gen_loss = 0.4049263137285827, disc_loss = 0.07272920938605656
Trained batch 305 in epoch 4, gen_loss = 0.40491195587940465, disc_loss = 0.07260340485368776
Trained batch 306 in epoch 4, gen_loss = 0.4046749431846196, disc_loss = 0.07320919763054153
Trained batch 307 in epoch 4, gen_loss = 0.40442789616909897, disc_loss = 0.07384589637702259
Trained batch 308 in epoch 4, gen_loss = 0.40451743051072153, disc_loss = 0.07384361694702535
Trained batch 309 in epoch 4, gen_loss = 0.40431551894833967, disc_loss = 0.0738974810758185
Trained batch 310 in epoch 4, gen_loss = 0.40426879642094066, disc_loss = 0.07387281809648996
Trained batch 311 in epoch 4, gen_loss = 0.4042814013858636, disc_loss = 0.07375304560021807
Trained batch 312 in epoch 4, gen_loss = 0.4041465055256987, disc_loss = 0.0743523716789703
Trained batch 313 in epoch 4, gen_loss = 0.4037517723953648, disc_loss = 0.07549030724379002
Trained batch 314 in epoch 4, gen_loss = 0.40393619698191446, disc_loss = 0.07621913880168918
Trained batch 315 in epoch 4, gen_loss = 0.40365379011329217, disc_loss = 0.07632015993571074
Trained batch 316 in epoch 4, gen_loss = 0.40365103451235435, disc_loss = 0.07648247926075846
Trained batch 317 in epoch 4, gen_loss = 0.4035861226935057, disc_loss = 0.07643966549281148
Trained batch 318 in epoch 4, gen_loss = 0.4033007005165363, disc_loss = 0.07631692719181597
Trained batch 319 in epoch 4, gen_loss = 0.40335428798571227, disc_loss = 0.07616890352510382
Trained batch 320 in epoch 4, gen_loss = 0.4034124032544941, disc_loss = 0.07604098726481756
Trained batch 321 in epoch 4, gen_loss = 0.40331482970566485, disc_loss = 0.07614662533232607
Trained batch 322 in epoch 4, gen_loss = 0.4032388696729583, disc_loss = 0.07611648478017595
Trained batch 323 in epoch 4, gen_loss = 0.4032726444212007, disc_loss = 0.07616289507563191
Trained batch 324 in epoch 4, gen_loss = 0.40296257615089415, disc_loss = 0.07623807820276572
Trained batch 325 in epoch 4, gen_loss = 0.40306132291357943, disc_loss = 0.07610302338765168
Trained batch 326 in epoch 4, gen_loss = 0.40307891113677885, disc_loss = 0.07640370733705591
Trained batch 327 in epoch 4, gen_loss = 0.402856872576039, disc_loss = 0.07644483027127912
Trained batch 328 in epoch 4, gen_loss = 0.4027737796668948, disc_loss = 0.07623191537069422
Trained batch 329 in epoch 4, gen_loss = 0.4028499339566086, disc_loss = 0.0760951482352208
Trained batch 330 in epoch 4, gen_loss = 0.4029299425934737, disc_loss = 0.07593339037015089
Trained batch 331 in epoch 4, gen_loss = 0.40296286021370487, disc_loss = 0.0757888842918293
Trained batch 332 in epoch 4, gen_loss = 0.40313352962155957, disc_loss = 0.075656855084539
Trained batch 333 in epoch 4, gen_loss = 0.40348879234519547, disc_loss = 0.0756838796967027
Trained batch 334 in epoch 4, gen_loss = 0.40348379789893307, disc_loss = 0.07604360114783049
Trained batch 335 in epoch 4, gen_loss = 0.4035362085061414, disc_loss = 0.07590900110690632
Trained batch 336 in epoch 4, gen_loss = 0.4037094714910411, disc_loss = 0.07573354080352568
Trained batch 337 in epoch 4, gen_loss = 0.4038271891647542, disc_loss = 0.07555716616768368
Trained batch 338 in epoch 4, gen_loss = 0.4036186233734311, disc_loss = 0.07548801559998838
Trained batch 339 in epoch 4, gen_loss = 0.4035028331420001, disc_loss = 0.07530419332632686
Trained batch 340 in epoch 4, gen_loss = 0.4036714947643168, disc_loss = 0.07521283193122694
Trained batch 341 in epoch 4, gen_loss = 0.4037634436672891, disc_loss = 0.07501477752240342
Trained batch 342 in epoch 4, gen_loss = 0.4035045830397147, disc_loss = 0.07559652986824947
Trained batch 343 in epoch 4, gen_loss = 0.4036594877929188, disc_loss = 0.07695776440452265
Trained batch 344 in epoch 4, gen_loss = 0.40388068245804826, disc_loss = 0.07691903504934432
Trained batch 345 in epoch 4, gen_loss = 0.4039975472785145, disc_loss = 0.07674673689270899
Trained batch 346 in epoch 4, gen_loss = 0.40389406689649354, disc_loss = 0.07661964238409265
Trained batch 347 in epoch 4, gen_loss = 0.40387679919086655, disc_loss = 0.07646875064980624
Trained batch 348 in epoch 4, gen_loss = 0.40377362708649184, disc_loss = 0.0762858844487621
Trained batch 349 in epoch 4, gen_loss = 0.40380217398915974, disc_loss = 0.07609608923750265
Trained batch 350 in epoch 4, gen_loss = 0.4036586366997146, disc_loss = 0.07591079660502933
Trained batch 351 in epoch 4, gen_loss = 0.40370642571625387, disc_loss = 0.07574734492862428
Trained batch 352 in epoch 4, gen_loss = 0.40369434709589475, disc_loss = 0.0755869880972942
Trained batch 353 in epoch 4, gen_loss = 0.40358224039697377, disc_loss = 0.07542058474536838
Trained batch 354 in epoch 4, gen_loss = 0.40377579213867726, disc_loss = 0.07539527139718263
Trained batch 355 in epoch 4, gen_loss = 0.40384351428640025, disc_loss = 0.07535622445238607
Trained batch 356 in epoch 4, gen_loss = 0.4038674208630367, disc_loss = 0.0752460042416465
Trained batch 357 in epoch 4, gen_loss = 0.4038846011601347, disc_loss = 0.0752247446398745
Trained batch 358 in epoch 4, gen_loss = 0.40393174640979607, disc_loss = 0.07600129988760503
Trained batch 359 in epoch 4, gen_loss = 0.4037846705151929, disc_loss = 0.07591168457745678
Trained batch 360 in epoch 4, gen_loss = 0.4036326566066108, disc_loss = 0.07573509959302781
Trained batch 361 in epoch 4, gen_loss = 0.4037137327108594, disc_loss = 0.07559715804144822
Trained batch 362 in epoch 4, gen_loss = 0.4035356451985593, disc_loss = 0.07544642029017128
Trained batch 363 in epoch 4, gen_loss = 0.4034493206949024, disc_loss = 0.07546872296626424
Trained batch 364 in epoch 4, gen_loss = 0.403785602523856, disc_loss = 0.07535097313253847
Trained batch 365 in epoch 4, gen_loss = 0.403710153422069, disc_loss = 0.07517117902107252
Trained batch 366 in epoch 4, gen_loss = 0.40364156634995985, disc_loss = 0.0750438159620973
Trained batch 367 in epoch 4, gen_loss = 0.4035229175958944, disc_loss = 0.07490550433589227
Trained batch 368 in epoch 4, gen_loss = 0.40332205201875226, disc_loss = 0.07481813183947791
Trained batch 369 in epoch 4, gen_loss = 0.4032394259362607, disc_loss = 0.07485482927814528
Trained batch 370 in epoch 4, gen_loss = 0.40311765076336514, disc_loss = 0.07476447481973313
Trained batch 371 in epoch 4, gen_loss = 0.40308348329797866, disc_loss = 0.0746299464966581
Trained batch 372 in epoch 4, gen_loss = 0.40294832590438084, disc_loss = 0.07458083905359536
Trained batch 373 in epoch 4, gen_loss = 0.4028899632991954, disc_loss = 0.0745545493857188
Trained batch 374 in epoch 4, gen_loss = 0.4029584140777588, disc_loss = 0.0743836621666948
Trained batch 375 in epoch 4, gen_loss = 0.40297844673090794, disc_loss = 0.07421368652796174
Trained batch 376 in epoch 4, gen_loss = 0.40306294517744756, disc_loss = 0.07405892142961765
Trained batch 377 in epoch 4, gen_loss = 0.4031554604806597, disc_loss = 0.07392519381311205
Trained batch 378 in epoch 4, gen_loss = 0.40322725730395254, disc_loss = 0.07378521165503361
Trained batch 379 in epoch 4, gen_loss = 0.4032447982775538, disc_loss = 0.07362445015950422
Trained batch 380 in epoch 4, gen_loss = 0.4032996463494038, disc_loss = 0.07355654433741188
Trained batch 381 in epoch 4, gen_loss = 0.4032384338179184, disc_loss = 0.07352923391708685
Trained batch 382 in epoch 4, gen_loss = 0.40323272363012824, disc_loss = 0.07337333877660898
Trained batch 383 in epoch 4, gen_loss = 0.40337493775102, disc_loss = 0.07348719766014256
Trained batch 384 in epoch 4, gen_loss = 0.4032296186917788, disc_loss = 0.07350509498607029
Trained batch 385 in epoch 4, gen_loss = 0.4032279801955495, disc_loss = 0.07336442055750078
Trained batch 386 in epoch 4, gen_loss = 0.4033136943822067, disc_loss = 0.07341377359143524
Trained batch 387 in epoch 4, gen_loss = 0.40308942353909777, disc_loss = 0.0738462525679125
Trained batch 388 in epoch 4, gen_loss = 0.4034286738208143, disc_loss = 0.07374422021382572
Trained batch 389 in epoch 4, gen_loss = 0.4035498489936193, disc_loss = 0.07373422073821227
Trained batch 390 in epoch 4, gen_loss = 0.4036605398520789, disc_loss = 0.07357656576044266
Trained batch 391 in epoch 4, gen_loss = 0.4034704433716073, disc_loss = 0.073565055079264
Trained batch 392 in epoch 4, gen_loss = 0.40363935295862097, disc_loss = 0.07341092468995326
Trained batch 393 in epoch 4, gen_loss = 0.4038208907630843, disc_loss = 0.07329519453274115
Trained batch 394 in epoch 4, gen_loss = 0.40403157819675495, disc_loss = 0.07312662394929535
Trained batch 395 in epoch 4, gen_loss = 0.40407941520515117, disc_loss = 0.07305970655359102
Trained batch 396 in epoch 4, gen_loss = 0.40423500372720905, disc_loss = 0.0728945921665475
Trained batch 397 in epoch 4, gen_loss = 0.40419626445626494, disc_loss = 0.07328528382969861
Trained batch 398 in epoch 4, gen_loss = 0.40411859265246186, disc_loss = 0.07356843946123481
Trained batch 399 in epoch 4, gen_loss = 0.4041280702501535, disc_loss = 0.07350532823242246
Trained batch 400 in epoch 4, gen_loss = 0.40418711735720647, disc_loss = 0.07334125099327425
Trained batch 401 in epoch 4, gen_loss = 0.4041793387179351, disc_loss = 0.07318772909124914
Trained batch 402 in epoch 4, gen_loss = 0.4041372993152136, disc_loss = 0.07302618861457254
Trained batch 403 in epoch 4, gen_loss = 0.4041375914717665, disc_loss = 0.07286705870393405
Trained batch 404 in epoch 4, gen_loss = 0.4040520080077795, disc_loss = 0.07272700534236652
Trained batch 405 in epoch 4, gen_loss = 0.4041683900679274, disc_loss = 0.07256482934964628
Trained batch 406 in epoch 4, gen_loss = 0.40413670304073457, disc_loss = 0.07243319646814604
Trained batch 407 in epoch 4, gen_loss = 0.4043254359972243, disc_loss = 0.07230537929617818
Trained batch 408 in epoch 4, gen_loss = 0.4041874617119582, disc_loss = 0.07225350264805963
Trained batch 409 in epoch 4, gen_loss = 0.404314330656354, disc_loss = 0.07216049407086358
Trained batch 410 in epoch 4, gen_loss = 0.4044343724012955, disc_loss = 0.07201057100790913
Trained batch 411 in epoch 4, gen_loss = 0.4045233921084589, disc_loss = 0.07188579412312834
Trained batch 412 in epoch 4, gen_loss = 0.40459536733985235, disc_loss = 0.07176314924164849
Trained batch 413 in epoch 4, gen_loss = 0.4044225514654952, disc_loss = 0.07162166345000699
Trained batch 414 in epoch 4, gen_loss = 0.4045476897653327, disc_loss = 0.07146145007068135
Trained batch 415 in epoch 4, gen_loss = 0.4048327044225656, disc_loss = 0.0713104883638712
Trained batch 416 in epoch 4, gen_loss = 0.4047758416306201, disc_loss = 0.07123086342422796
Trained batch 417 in epoch 4, gen_loss = 0.4046572043992686, disc_loss = 0.07163121041498687
Trained batch 418 in epoch 4, gen_loss = 0.4048279412179687, disc_loss = 0.07198575441336574
Trained batch 419 in epoch 4, gen_loss = 0.4047448693996384, disc_loss = 0.07183334118287478
Trained batch 420 in epoch 4, gen_loss = 0.40458379760207586, disc_loss = 0.0718442885129936
Trained batch 421 in epoch 4, gen_loss = 0.40445655697329913, disc_loss = 0.07176842742215542
Trained batch 422 in epoch 4, gen_loss = 0.40456842650476643, disc_loss = 0.07191855695107445
Trained batch 423 in epoch 4, gen_loss = 0.4043462239908722, disc_loss = 0.0718049837478419
Trained batch 424 in epoch 4, gen_loss = 0.4040283655419069, disc_loss = 0.07190903659690828
Trained batch 425 in epoch 4, gen_loss = 0.40395856498272764, disc_loss = 0.07194209752490682
Trained batch 426 in epoch 4, gen_loss = 0.4040070767285394, disc_loss = 0.0718539876588544
Trained batch 427 in epoch 4, gen_loss = 0.4039032029632096, disc_loss = 0.0718039595086789
Trained batch 428 in epoch 4, gen_loss = 0.40402747374592407, disc_loss = 0.07177302095005701
Trained batch 429 in epoch 4, gen_loss = 0.40380881130695345, disc_loss = 0.07183552905483995
Trained batch 430 in epoch 4, gen_loss = 0.4039598437860228, disc_loss = 0.07208709029390059
Trained batch 431 in epoch 4, gen_loss = 0.40381442472614626, disc_loss = 0.07269369736227586
Trained batch 432 in epoch 4, gen_loss = 0.4038848708325666, disc_loss = 0.07357621868732482
Trained batch 433 in epoch 4, gen_loss = 0.40405298927412603, disc_loss = 0.07354592184712123
Trained batch 434 in epoch 4, gen_loss = 0.4039424074792314, disc_loss = 0.07352695343052519
Trained batch 435 in epoch 4, gen_loss = 0.40373676324929664, disc_loss = 0.0734334228893554
Trained batch 436 in epoch 4, gen_loss = 0.40359755579885137, disc_loss = 0.07333331350109261
Trained batch 437 in epoch 4, gen_loss = 0.4035299006662412, disc_loss = 0.07339710617633578
Trained batch 438 in epoch 4, gen_loss = 0.40340812616304816, disc_loss = 0.0738460228211991
Trained batch 439 in epoch 4, gen_loss = 0.4033410931175405, disc_loss = 0.07385534999299456
Trained batch 440 in epoch 4, gen_loss = 0.40335607690876035, disc_loss = 0.07409445380120455
Trained batch 441 in epoch 4, gen_loss = 0.40312377656746773, disc_loss = 0.0740866981640593
Trained batch 442 in epoch 4, gen_loss = 0.403270382913456, disc_loss = 0.07393601646701517
Trained batch 443 in epoch 4, gen_loss = 0.403317110227035, disc_loss = 0.07380537615526837
Trained batch 444 in epoch 4, gen_loss = 0.4033442859569292, disc_loss = 0.07370277122709523
Trained batch 445 in epoch 4, gen_loss = 0.40328061720982794, disc_loss = 0.07387023377587242
Trained batch 446 in epoch 4, gen_loss = 0.40326231664725865, disc_loss = 0.07463191494854038
Trained batch 447 in epoch 4, gen_loss = 0.40312834702698247, disc_loss = 0.07464014810518295
Trained batch 448 in epoch 4, gen_loss = 0.40308336651404875, disc_loss = 0.0746516825150043
Trained batch 449 in epoch 4, gen_loss = 0.4031704064210256, disc_loss = 0.07455315943600403
Trained batch 450 in epoch 4, gen_loss = 0.403074053266889, disc_loss = 0.0744341021122828
Trained batch 451 in epoch 4, gen_loss = 0.4030475381728822, disc_loss = 0.07430733661414578
Trained batch 452 in epoch 4, gen_loss = 0.4031921573164184, disc_loss = 0.07418651096563926
Trained batch 453 in epoch 4, gen_loss = 0.4031155815077248, disc_loss = 0.07404037383241406
Trained batch 454 in epoch 4, gen_loss = 0.40310986297471185, disc_loss = 0.07389868151109952
Trained batch 455 in epoch 4, gen_loss = 0.40294647870356576, disc_loss = 0.07381095131450709
Trained batch 456 in epoch 4, gen_loss = 0.40314674103546977, disc_loss = 0.0740472331227372
Trained batch 457 in epoch 4, gen_loss = 0.4030897379181791, disc_loss = 0.07406511455855645
Trained batch 458 in epoch 4, gen_loss = 0.40293322253590835, disc_loss = 0.07397809318289128
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 0.4043358564376831, disc_loss = 0.015291166491806507
Trained batch 1 in epoch 5, gen_loss = 0.3772934526205063, disc_loss = 0.018452749121934175
Trained batch 2 in epoch 5, gen_loss = 0.3680822253227234, disc_loss = 0.02212494021902482
Trained batch 3 in epoch 5, gen_loss = 0.349552683532238, disc_loss = 0.04324570414610207
Trained batch 4 in epoch 5, gen_loss = 0.3811522901058197, disc_loss = 0.10192617271095514
Trained batch 5 in epoch 5, gen_loss = 0.3878774444262187, disc_loss = 0.10645571180308859
Trained batch 6 in epoch 5, gen_loss = 0.3789199250085013, disc_loss = 0.10237808379211596
Trained batch 7 in epoch 5, gen_loss = 0.3753833472728729, disc_loss = 0.106201913789846
Trained batch 8 in epoch 5, gen_loss = 0.37640470928615993, disc_loss = 0.10313902019212644
Trained batch 9 in epoch 5, gen_loss = 0.37688933312892914, disc_loss = 0.09809544133022427
Trained batch 10 in epoch 5, gen_loss = 0.375040357763117, disc_loss = 0.09807241479442878
Trained batch 11 in epoch 5, gen_loss = 0.38330859939257306, disc_loss = 0.09841305118364592
Trained batch 12 in epoch 5, gen_loss = 0.3850152309124286, disc_loss = 0.09600106261384028
Trained batch 13 in epoch 5, gen_loss = 0.38620475786072866, disc_loss = 0.09119997153590832
Trained batch 14 in epoch 5, gen_loss = 0.38829416831334435, disc_loss = 0.08586578847219546
Trained batch 15 in epoch 5, gen_loss = 0.3917799722403288, disc_loss = 0.08172243140870705
Trained batch 16 in epoch 5, gen_loss = 0.39128633281763864, disc_loss = 0.07925404701381922
Trained batch 17 in epoch 5, gen_loss = 0.3874470972352558, disc_loss = 0.07807961442611283
Trained batch 18 in epoch 5, gen_loss = 0.38878478031409414, disc_loss = 0.07452890374942829
Trained batch 19 in epoch 5, gen_loss = 0.39377679526805875, disc_loss = 0.07209287229925394
Trained batch 20 in epoch 5, gen_loss = 0.3961385871682848, disc_loss = 0.06908650922455958
Trained batch 21 in epoch 5, gen_loss = 0.3967495452273976, disc_loss = 0.06765588961372321
Trained batch 22 in epoch 5, gen_loss = 0.39540207126866217, disc_loss = 0.06522149256552043
Trained batch 23 in epoch 5, gen_loss = 0.3981427699327469, disc_loss = 0.06277198713117589
Trained batch 24 in epoch 5, gen_loss = 0.399335697889328, disc_loss = 0.061542187593877314
Trained batch 25 in epoch 5, gen_loss = 0.39785029337956357, disc_loss = 0.06691073250168791
Trained batch 26 in epoch 5, gen_loss = 0.39817272071485166, disc_loss = 0.0748761309724715
Trained batch 27 in epoch 5, gen_loss = 0.39729113238198416, disc_loss = 0.07275749945880047
Trained batch 28 in epoch 5, gen_loss = 0.39540411480541887, disc_loss = 0.0715610892672477
Trained batch 29 in epoch 5, gen_loss = 0.3963129609823227, disc_loss = 0.07008081926032901
Trained batch 30 in epoch 5, gen_loss = 0.39658136137070193, disc_loss = 0.06799837460200633
Trained batch 31 in epoch 5, gen_loss = 0.39511325117200613, disc_loss = 0.06656879471847787
Trained batch 32 in epoch 5, gen_loss = 0.3959984788388917, disc_loss = 0.06485945547959118
Trained batch 33 in epoch 5, gen_loss = 0.39539269489400525, disc_loss = 0.0638472881880315
Trained batch 34 in epoch 5, gen_loss = 0.39649357795715334, disc_loss = 0.06273962054401636
Trained batch 35 in epoch 5, gen_loss = 0.3981882764233483, disc_loss = 0.061236481906639204
Trained batch 36 in epoch 5, gen_loss = 0.3993463000735721, disc_loss = 0.06031257402453873
Trained batch 37 in epoch 5, gen_loss = 0.4016836614985215, disc_loss = 0.059898602482127514
Trained batch 38 in epoch 5, gen_loss = 0.4018465769596589, disc_loss = 0.058574631881828494
Trained batch 39 in epoch 5, gen_loss = 0.40129271522164345, disc_loss = 0.05877276926767081
Trained batch 40 in epoch 5, gen_loss = 0.4017714516418736, disc_loss = 0.05972570151363204
Trained batch 41 in epoch 5, gen_loss = 0.4009178216968264, disc_loss = 0.05855186303545322
Trained batch 42 in epoch 5, gen_loss = 0.40172025492024976, disc_loss = 0.057590844477851726
Trained batch 43 in epoch 5, gen_loss = 0.4015234830704602, disc_loss = 0.05646413712846962
Trained batch 44 in epoch 5, gen_loss = 0.40205957624647354, disc_loss = 0.05610351955725087
Trained batch 45 in epoch 5, gen_loss = 0.40172593554724817, disc_loss = 0.05590023582234331
Trained batch 46 in epoch 5, gen_loss = 0.4038632201387527, disc_loss = 0.05594571461861438
Trained batch 47 in epoch 5, gen_loss = 0.403217817346255, disc_loss = 0.05493076245572107
Trained batch 48 in epoch 5, gen_loss = 0.4024041526171626, disc_loss = 0.05578727540274968
Trained batch 49 in epoch 5, gen_loss = 0.40264797806739805, disc_loss = 0.06093391097150743
Trained batch 50 in epoch 5, gen_loss = 0.40250351090057224, disc_loss = 0.060257837167192324
Trained batch 51 in epoch 5, gen_loss = 0.4026371699113112, disc_loss = 0.060037546638900846
Trained batch 52 in epoch 5, gen_loss = 0.4029423948728813, disc_loss = 0.05929860155502299
Trained batch 53 in epoch 5, gen_loss = 0.40256887508763206, disc_loss = 0.05829151146355326
Trained batch 54 in epoch 5, gen_loss = 0.4033409037373283, disc_loss = 0.057351887691766024
Trained batch 55 in epoch 5, gen_loss = 0.40329027974179815, disc_loss = 0.056502841986782314
Trained batch 56 in epoch 5, gen_loss = 0.40267841648637204, disc_loss = 0.0559381276058654
Trained batch 57 in epoch 5, gen_loss = 0.4030194703874917, disc_loss = 0.055495748368637826
Trained batch 58 in epoch 5, gen_loss = 0.4027673107082561, disc_loss = 0.05571279460879958
Trained batch 59 in epoch 5, gen_loss = 0.40264933506647743, disc_loss = 0.05697518364371111
Trained batch 60 in epoch 5, gen_loss = 0.40206281572091773, disc_loss = 0.057097585360351644
Trained batch 61 in epoch 5, gen_loss = 0.40222039866831993, disc_loss = 0.05729684558877301
Trained batch 62 in epoch 5, gen_loss = 0.40229956592832294, disc_loss = 0.05650474956732184
Trained batch 63 in epoch 5, gen_loss = 0.4020940391346812, disc_loss = 0.055901292282214854
Trained batch 64 in epoch 5, gen_loss = 0.40288720039220954, disc_loss = 0.05512285790621088
Trained batch 65 in epoch 5, gen_loss = 0.40249683369289746, disc_loss = 0.05457870393398811
Trained batch 66 in epoch 5, gen_loss = 0.4030974636326975, disc_loss = 0.05387680789233366
Trained batch 67 in epoch 5, gen_loss = 0.403042267788859, disc_loss = 0.054541863288785165
Trained batch 68 in epoch 5, gen_loss = 0.4044255765451901, disc_loss = 0.05628491269316578
Trained batch 69 in epoch 5, gen_loss = 0.4034701543194907, disc_loss = 0.05610914284230343
Trained batch 70 in epoch 5, gen_loss = 0.40365740027226193, disc_loss = 0.055498794396735836
Trained batch 71 in epoch 5, gen_loss = 0.40471431074870956, disc_loss = 0.055381328844103135
Trained batch 72 in epoch 5, gen_loss = 0.4038901872014346, disc_loss = 0.05553889289268688
Trained batch 73 in epoch 5, gen_loss = 0.4036555866131911, disc_loss = 0.05598382444775386
Trained batch 74 in epoch 5, gen_loss = 0.40271403272946676, disc_loss = 0.05663759265715877
Trained batch 75 in epoch 5, gen_loss = 0.40285269327853857, disc_loss = 0.056029333396030494
Trained batch 76 in epoch 5, gen_loss = 0.4032794225525546, disc_loss = 0.05576625244401685
Trained batch 77 in epoch 5, gen_loss = 0.4034407199957432, disc_loss = 0.05513274466666656
Trained batch 78 in epoch 5, gen_loss = 0.4031619161744661, disc_loss = 0.055559085870656784
Trained batch 79 in epoch 5, gen_loss = 0.4040416102856398, disc_loss = 0.055112430220469834
Trained batch 80 in epoch 5, gen_loss = 0.40453500512205526, disc_loss = 0.05460852775492786
Trained batch 81 in epoch 5, gen_loss = 0.40404947937988656, disc_loss = 0.05463342236854681
Trained batch 82 in epoch 5, gen_loss = 0.4043836198657392, disc_loss = 0.05486086455274777
Trained batch 83 in epoch 5, gen_loss = 0.40377711611134665, disc_loss = 0.05674450467562392
Trained batch 84 in epoch 5, gen_loss = 0.4046787156778223, disc_loss = 0.057571050480884664
Trained batch 85 in epoch 5, gen_loss = 0.4051603203596071, disc_loss = 0.056970936977196227
Trained batch 86 in epoch 5, gen_loss = 0.404665843166154, disc_loss = 0.057084869737897455
Trained batch 87 in epoch 5, gen_loss = 0.40550248697400093, disc_loss = 0.05692274565279314
Trained batch 88 in epoch 5, gen_loss = 0.4062961122293151, disc_loss = 0.05657386019553864
Trained batch 89 in epoch 5, gen_loss = 0.40521650744809046, disc_loss = 0.056357186717084715
Trained batch 90 in epoch 5, gen_loss = 0.4055784400347825, disc_loss = 0.0564244442087199
Trained batch 91 in epoch 5, gen_loss = 0.4053807504799055, disc_loss = 0.05595905357546618
Trained batch 92 in epoch 5, gen_loss = 0.4057876823409911, disc_loss = 0.05560081832170967
Trained batch 93 in epoch 5, gen_loss = 0.40613142258309304, disc_loss = 0.055140985943812955
Trained batch 94 in epoch 5, gen_loss = 0.40593346043636924, disc_loss = 0.05481732095052537
Trained batch 95 in epoch 5, gen_loss = 0.4060154588272174, disc_loss = 0.05468417005128382
Trained batch 96 in epoch 5, gen_loss = 0.40670544984414403, disc_loss = 0.05417719032116158
Trained batch 97 in epoch 5, gen_loss = 0.4073247687549007, disc_loss = 0.053899342460291724
Trained batch 98 in epoch 5, gen_loss = 0.4072471697523136, disc_loss = 0.0534915126521479
Trained batch 99 in epoch 5, gen_loss = 0.40775247663259506, disc_loss = 0.05317512927576899
Trained batch 100 in epoch 5, gen_loss = 0.40779282521493365, disc_loss = 0.0529397026368297
Trained batch 101 in epoch 5, gen_loss = 0.407717792134659, disc_loss = 0.052477780473875066
Trained batch 102 in epoch 5, gen_loss = 0.40730604847658025, disc_loss = 0.05319584005521339
Trained batch 103 in epoch 5, gen_loss = 0.4079526255910213, disc_loss = 0.05499868764756964
Trained batch 104 in epoch 5, gen_loss = 0.4081692922682989, disc_loss = 0.05460443564114117
Trained batch 105 in epoch 5, gen_loss = 0.4084368823271877, disc_loss = 0.054204457492198585
Trained batch 106 in epoch 5, gen_loss = 0.40895177354322415, disc_loss = 0.05385307177344215
Trained batch 107 in epoch 5, gen_loss = 0.40914442942098334, disc_loss = 0.05346439639106393
Trained batch 108 in epoch 5, gen_loss = 0.40882094819611364, disc_loss = 0.05316342184439712
Trained batch 109 in epoch 5, gen_loss = 0.40896573175083506, disc_loss = 0.05278647279536182
Trained batch 110 in epoch 5, gen_loss = 0.4093675989288468, disc_loss = 0.05250308152523127
Trained batch 111 in epoch 5, gen_loss = 0.4090700335800648, disc_loss = 0.052204626446057646
Trained batch 112 in epoch 5, gen_loss = 0.40936339798226823, disc_loss = 0.054101263494354436
Trained batch 113 in epoch 5, gen_loss = 0.40989860421732854, disc_loss = 0.05490277678166565
Trained batch 114 in epoch 5, gen_loss = 0.4102615475654602, disc_loss = 0.05463190094932266
Trained batch 115 in epoch 5, gen_loss = 0.40993977826217126, disc_loss = 0.05452053428723894
Trained batch 116 in epoch 5, gen_loss = 0.4100835017668895, disc_loss = 0.0541342239604037
Trained batch 117 in epoch 5, gen_loss = 0.4105601280422534, disc_loss = 0.05373815958530216
Trained batch 118 in epoch 5, gen_loss = 0.4107744701269294, disc_loss = 0.053407361355273665
Trained batch 119 in epoch 5, gen_loss = 0.41033172855774563, disc_loss = 0.0533558766823262
Trained batch 120 in epoch 5, gen_loss = 0.4104201980858795, disc_loss = 0.05358945308945888
Trained batch 121 in epoch 5, gen_loss = 0.41063593694421113, disc_loss = 0.05335344505481056
Trained batch 122 in epoch 5, gen_loss = 0.41031484366432436, disc_loss = 0.05307158617287632
Trained batch 123 in epoch 5, gen_loss = 0.40993083989427936, disc_loss = 0.05347267233376061
Trained batch 124 in epoch 5, gen_loss = 0.41082185769081114, disc_loss = 0.05544229681789875
Trained batch 125 in epoch 5, gen_loss = 0.4107768384237138, disc_loss = 0.055220417116606045
Trained batch 126 in epoch 5, gen_loss = 0.41069202723465564, disc_loss = 0.05584197476740897
Trained batch 127 in epoch 5, gen_loss = 0.4107922485563904, disc_loss = 0.0555429481464671
Trained batch 128 in epoch 5, gen_loss = 0.41073200430056844, disc_loss = 0.055739953781860745
Trained batch 129 in epoch 5, gen_loss = 0.41037459396398984, disc_loss = 0.05581685231568722
Trained batch 130 in epoch 5, gen_loss = 0.40942769537445245, disc_loss = 0.0555844504158688
Trained batch 131 in epoch 5, gen_loss = 0.40926945277235727, disc_loss = 0.05542171745081291
Trained batch 132 in epoch 5, gen_loss = 0.40963238276037056, disc_loss = 0.055257465172194896
Trained batch 133 in epoch 5, gen_loss = 0.4092418062153147, disc_loss = 0.05505255315063605
Trained batch 134 in epoch 5, gen_loss = 0.4092412780832361, disc_loss = 0.05497650545504358
Trained batch 135 in epoch 5, gen_loss = 0.4092818612561506, disc_loss = 0.05470500930267222
Trained batch 136 in epoch 5, gen_loss = 0.40963096187932646, disc_loss = 0.05477484130728854
Trained batch 137 in epoch 5, gen_loss = 0.4099517086709755, disc_loss = 0.05445950910233069
Trained batch 138 in epoch 5, gen_loss = 0.4104185471003004, disc_loss = 0.05435142971628861
Trained batch 139 in epoch 5, gen_loss = 0.4102788067289761, disc_loss = 0.05400520947961403
Trained batch 140 in epoch 5, gen_loss = 0.41058363390307057, disc_loss = 0.05384133201660522
Trained batch 141 in epoch 5, gen_loss = 0.41002661304574617, disc_loss = 0.05391674641270558
Trained batch 142 in epoch 5, gen_loss = 0.4104244181743035, disc_loss = 0.054661256922213554
Trained batch 143 in epoch 5, gen_loss = 0.4101045580787791, disc_loss = 0.05433198735894015
Trained batch 144 in epoch 5, gen_loss = 0.409930688553843, disc_loss = 0.054236549999693344
Trained batch 145 in epoch 5, gen_loss = 0.41033412475291997, disc_loss = 0.053908571556261546
Trained batch 146 in epoch 5, gen_loss = 0.41012348406979826, disc_loss = 0.05365228352016535
Trained batch 147 in epoch 5, gen_loss = 0.4100413231833561, disc_loss = 0.05355703375755331
Trained batch 148 in epoch 5, gen_loss = 0.4102940125353384, disc_loss = 0.05354170129328166
Trained batch 149 in epoch 5, gen_loss = 0.4106687678893407, disc_loss = 0.05340326818947991
Trained batch 150 in epoch 5, gen_loss = 0.41122943735280576, disc_loss = 0.05318740768271764
Trained batch 151 in epoch 5, gen_loss = 0.4120161766676526, disc_loss = 0.05297214516414035
Trained batch 152 in epoch 5, gen_loss = 0.41225818851414847, disc_loss = 0.05267718082500829
Trained batch 153 in epoch 5, gen_loss = 0.412297522286316, disc_loss = 0.05301151670176874
Trained batch 154 in epoch 5, gen_loss = 0.4122895363838442, disc_loss = 0.05391396874141308
Trained batch 155 in epoch 5, gen_loss = 0.41241014557771194, disc_loss = 0.05374754348005622
Trained batch 156 in epoch 5, gen_loss = 0.41269856976096037, disc_loss = 0.053558432574200024
Trained batch 157 in epoch 5, gen_loss = 0.4129626049271113, disc_loss = 0.05335608894547707
Trained batch 158 in epoch 5, gen_loss = 0.4124160264647982, disc_loss = 0.05315734467135286
Trained batch 159 in epoch 5, gen_loss = 0.4120671598240733, disc_loss = 0.053049330948852
Trained batch 160 in epoch 5, gen_loss = 0.4123650087703089, disc_loss = 0.053382743659041686
Trained batch 161 in epoch 5, gen_loss = 0.41156100012637953, disc_loss = 0.05379559046784301
Trained batch 162 in epoch 5, gen_loss = 0.4117646105816028, disc_loss = 0.05381898198025358
Trained batch 163 in epoch 5, gen_loss = 0.4118061338256045, disc_loss = 0.05364541127914336
Trained batch 164 in epoch 5, gen_loss = 0.4119073784712589, disc_loss = 0.05338783166512395
Trained batch 165 in epoch 5, gen_loss = 0.4120024259550026, disc_loss = 0.05324804403044912
Trained batch 166 in epoch 5, gen_loss = 0.41159937106920574, disc_loss = 0.0531295279799375
Trained batch 167 in epoch 5, gen_loss = 0.41123412726890474, disc_loss = 0.05290728875635458
Trained batch 168 in epoch 5, gen_loss = 0.4112903054296618, disc_loss = 0.05268350870695693
Trained batch 169 in epoch 5, gen_loss = 0.4108640721615623, disc_loss = 0.053728285267510834
Trained batch 170 in epoch 5, gen_loss = 0.41015112208344084, disc_loss = 0.05613110969333272
Trained batch 171 in epoch 5, gen_loss = 0.41015514436849326, disc_loss = 0.055985590518820426
Trained batch 172 in epoch 5, gen_loss = 0.4108336576492111, disc_loss = 0.05628370242785512
Trained batch 173 in epoch 5, gen_loss = 0.4104694124610945, disc_loss = 0.056959263584308924
Trained batch 174 in epoch 5, gen_loss = 0.41049058624676293, disc_loss = 0.05696901169206415
Trained batch 175 in epoch 5, gen_loss = 0.4099999312311411, disc_loss = 0.056877668047408486
Trained batch 176 in epoch 5, gen_loss = 0.4095454961903351, disc_loss = 0.056908326602335704
Trained batch 177 in epoch 5, gen_loss = 0.4097106794962722, disc_loss = 0.05664174515607484
Trained batch 178 in epoch 5, gen_loss = 0.40978327193739694, disc_loss = 0.05643909603003516
Trained batch 179 in epoch 5, gen_loss = 0.4099303364753723, disc_loss = 0.056251506709183254
Trained batch 180 in epoch 5, gen_loss = 0.4095994545280604, disc_loss = 0.05602244356163463
Trained batch 181 in epoch 5, gen_loss = 0.40961190386787877, disc_loss = 0.05586759529618935
Trained batch 182 in epoch 5, gen_loss = 0.40946563394343266, disc_loss = 0.055803676777076525
Trained batch 183 in epoch 5, gen_loss = 0.4094294529894124, disc_loss = 0.055777196959673384
Trained batch 184 in epoch 5, gen_loss = 0.4088211062792185, disc_loss = 0.055825244358463866
Trained batch 185 in epoch 5, gen_loss = 0.4087329784067728, disc_loss = 0.05559310022621385
Trained batch 186 in epoch 5, gen_loss = 0.40865083397391005, disc_loss = 0.05537557188062904
Trained batch 187 in epoch 5, gen_loss = 0.4083331893099115, disc_loss = 0.05519603318138484
Trained batch 188 in epoch 5, gen_loss = 0.40810612679789304, disc_loss = 0.05493315494565106
Trained batch 189 in epoch 5, gen_loss = 0.4080761183249323, disc_loss = 0.05468055403938419
Trained batch 190 in epoch 5, gen_loss = 0.407926556015514, disc_loss = 0.054432370802338835
Trained batch 191 in epoch 5, gen_loss = 0.40794925826291245, disc_loss = 0.05418377351694895
Trained batch 192 in epoch 5, gen_loss = 0.4076731626542739, disc_loss = 0.05411807375771857
Trained batch 193 in epoch 5, gen_loss = 0.4074720374702178, disc_loss = 0.05409420707464679
Trained batch 194 in epoch 5, gen_loss = 0.4071250802431351, disc_loss = 0.05386441477980369
Trained batch 195 in epoch 5, gen_loss = 0.4074917210608113, disc_loss = 0.05365344935229847
Trained batch 196 in epoch 5, gen_loss = 0.40759934961493244, disc_loss = 0.05340987845290887
Trained batch 197 in epoch 5, gen_loss = 0.40792135984608624, disc_loss = 0.053197809104628936
Trained batch 198 in epoch 5, gen_loss = 0.40815664895215825, disc_loss = 0.05297684716762759
Trained batch 199 in epoch 5, gen_loss = 0.40802362367510797, disc_loss = 0.05273791120853275
Trained batch 200 in epoch 5, gen_loss = 0.40800911618109365, disc_loss = 0.0525403321484354
Trained batch 201 in epoch 5, gen_loss = 0.4077755987349123, disc_loss = 0.05231829978396545
Trained batch 202 in epoch 5, gen_loss = 0.4081885965880502, disc_loss = 0.052087980189493725
Trained batch 203 in epoch 5, gen_loss = 0.40826042347094593, disc_loss = 0.051907490582807976
Trained batch 204 in epoch 5, gen_loss = 0.40816413164138793, disc_loss = 0.05171833866525714
Trained batch 205 in epoch 5, gen_loss = 0.4081955832763783, disc_loss = 0.05185272508002456
Trained batch 206 in epoch 5, gen_loss = 0.4087001209097784, disc_loss = 0.05256844595848506
Trained batch 207 in epoch 5, gen_loss = 0.4086009255395486, disc_loss = 0.052356243917109586
Trained batch 208 in epoch 5, gen_loss = 0.4084675534490193, disc_loss = 0.052279434897647234
Trained batch 209 in epoch 5, gen_loss = 0.40838593301318943, disc_loss = 0.05217085404853736
Trained batch 210 in epoch 5, gen_loss = 0.4089444327693415, disc_loss = 0.05226146746250267
Trained batch 211 in epoch 5, gen_loss = 0.40929900489325793, disc_loss = 0.05244422762408712
Trained batch 212 in epoch 5, gen_loss = 0.4092794521034044, disc_loss = 0.052361497703607374
Trained batch 213 in epoch 5, gen_loss = 0.4091377755470365, disc_loss = 0.05214696658000559
Trained batch 214 in epoch 5, gen_loss = 0.4094870741977248, disc_loss = 0.05202189301205582
Trained batch 215 in epoch 5, gen_loss = 0.40960127984484035, disc_loss = 0.05239832634321862
Trained batch 216 in epoch 5, gen_loss = 0.4097280130133651, disc_loss = 0.052852938031082465
Trained batch 217 in epoch 5, gen_loss = 0.41034509077531484, disc_loss = 0.05280668066532582
Trained batch 218 in epoch 5, gen_loss = 0.41046688940427073, disc_loss = 0.05275473577187282
Trained batch 219 in epoch 5, gen_loss = 0.4102427287535234, disc_loss = 0.05255792034070261
Trained batch 220 in epoch 5, gen_loss = 0.41013799304336446, disc_loss = 0.05252676817685433
Trained batch 221 in epoch 5, gen_loss = 0.41056404336615726, disc_loss = 0.052424295652271795
Trained batch 222 in epoch 5, gen_loss = 0.41047062227009656, disc_loss = 0.05231009923848804
Trained batch 223 in epoch 5, gen_loss = 0.40981311976377455, disc_loss = 0.052373228384697414
Trained batch 224 in epoch 5, gen_loss = 0.40993447687890794, disc_loss = 0.05250891446032458
Trained batch 225 in epoch 5, gen_loss = 0.40952810341805485, disc_loss = 0.05265639338897855
Trained batch 226 in epoch 5, gen_loss = 0.40949631118039204, disc_loss = 0.053793632369980804
Trained batch 227 in epoch 5, gen_loss = 0.40902906773906006, disc_loss = 0.05437644543902328
Trained batch 228 in epoch 5, gen_loss = 0.4094161624210891, disc_loss = 0.05432811863191719
Trained batch 229 in epoch 5, gen_loss = 0.4095910380715909, disc_loss = 0.05449599340841498
Trained batch 230 in epoch 5, gen_loss = 0.40936369581139964, disc_loss = 0.05429413464541236
Trained batch 231 in epoch 5, gen_loss = 0.40953745436051797, disc_loss = 0.05420878453878686
Trained batch 232 in epoch 5, gen_loss = 0.4097766620406777, disc_loss = 0.05403540543452417
Trained batch 233 in epoch 5, gen_loss = 0.4097860842688471, disc_loss = 0.05422646043877889
Trained batch 234 in epoch 5, gen_loss = 0.4099917839182184, disc_loss = 0.054127636530060086
Trained batch 235 in epoch 5, gen_loss = 0.40977999669010357, disc_loss = 0.05444889791286156
Trained batch 236 in epoch 5, gen_loss = 0.40955287934858586, disc_loss = 0.05530051828287385
Trained batch 237 in epoch 5, gen_loss = 0.4094459239174338, disc_loss = 0.05582836180526231
Trained batch 238 in epoch 5, gen_loss = 0.4095406464951806, disc_loss = 0.0571526732689323
Trained batch 239 in epoch 5, gen_loss = 0.40894702151417733, disc_loss = 0.05904704305382135
Trained batch 240 in epoch 5, gen_loss = 0.4086834247923491, disc_loss = 0.059826023206192055
Trained batch 241 in epoch 5, gen_loss = 0.40888535274454385, disc_loss = 0.06013324743806392
Trained batch 242 in epoch 5, gen_loss = 0.40894804606712404, disc_loss = 0.06050702111810875
Trained batch 243 in epoch 5, gen_loss = 0.4087496374229916, disc_loss = 0.060949612510024155
Trained batch 244 in epoch 5, gen_loss = 0.4085576904063322, disc_loss = 0.061215933284969354
Trained batch 245 in epoch 5, gen_loss = 0.4084909652791372, disc_loss = 0.06157568282811198
Trained batch 246 in epoch 5, gen_loss = 0.4084108021819157, disc_loss = 0.062359063891761816
Trained batch 247 in epoch 5, gen_loss = 0.40850008940023763, disc_loss = 0.06304259872582231
Trained batch 248 in epoch 5, gen_loss = 0.40845742546410924, disc_loss = 0.06290576385004992
Trained batch 249 in epoch 5, gen_loss = 0.40816678893566133, disc_loss = 0.06312543668784201
Trained batch 250 in epoch 5, gen_loss = 0.4080453035366013, disc_loss = 0.0629568881785638
Trained batch 251 in epoch 5, gen_loss = 0.407917883542795, disc_loss = 0.062883607490683
Trained batch 252 in epoch 5, gen_loss = 0.4076238106126371, disc_loss = 0.0630840192467946
Trained batch 253 in epoch 5, gen_loss = 0.40775742293812156, disc_loss = 0.06378306851238305
Trained batch 254 in epoch 5, gen_loss = 0.4073711250342575, disc_loss = 0.06392270511600609
Trained batch 255 in epoch 5, gen_loss = 0.4072202347451821, disc_loss = 0.06387895337866212
Trained batch 256 in epoch 5, gen_loss = 0.4072301609274942, disc_loss = 0.063924288393473
Trained batch 257 in epoch 5, gen_loss = 0.4072594077781189, disc_loss = 0.06375355160318662
Trained batch 258 in epoch 5, gen_loss = 0.4072297380007372, disc_loss = 0.06360905012835004
Trained batch 259 in epoch 5, gen_loss = 0.40727512549895506, disc_loss = 0.06342787742793847
Trained batch 260 in epoch 5, gen_loss = 0.40746437669713836, disc_loss = 0.0632237978582895
Trained batch 261 in epoch 5, gen_loss = 0.4074048909522195, disc_loss = 0.06324506652157555
Trained batch 262 in epoch 5, gen_loss = 0.4073717034361662, disc_loss = 0.0631027676097822
Trained batch 263 in epoch 5, gen_loss = 0.4077095624172326, disc_loss = 0.06297566422268353
Trained batch 264 in epoch 5, gen_loss = 0.40787694296746885, disc_loss = 0.06277516673512334
Trained batch 265 in epoch 5, gen_loss = 0.4081226041666547, disc_loss = 0.06269951372869537
Trained batch 266 in epoch 5, gen_loss = 0.4081958493266659, disc_loss = 0.06251892830290542
Trained batch 267 in epoch 5, gen_loss = 0.40835650854591116, disc_loss = 0.06234353764934827
Trained batch 268 in epoch 5, gen_loss = 0.4082147700635917, disc_loss = 0.062209011136890015
Trained batch 269 in epoch 5, gen_loss = 0.40839789222787926, disc_loss = 0.062051460052047064
Trained batch 270 in epoch 5, gen_loss = 0.4083454420865682, disc_loss = 0.06184923733718611
Trained batch 271 in epoch 5, gen_loss = 0.4083181630600901, disc_loss = 0.061668191581060565
Trained batch 272 in epoch 5, gen_loss = 0.4082021612824101, disc_loss = 0.061459301865144526
Trained batch 273 in epoch 5, gen_loss = 0.4083658365437584, disc_loss = 0.06127696141029579
Trained batch 274 in epoch 5, gen_loss = 0.40833418055014176, disc_loss = 0.06108865525912155
Trained batch 275 in epoch 5, gen_loss = 0.40853549604830536, disc_loss = 0.06091747955297646
Trained batch 276 in epoch 5, gen_loss = 0.4082184773920245, disc_loss = 0.061014622624708
Trained batch 277 in epoch 5, gen_loss = 0.4085658803689394, disc_loss = 0.06262583126106279
Trained batch 278 in epoch 5, gen_loss = 0.40882058714025765, disc_loss = 0.06250979329415975
Trained batch 279 in epoch 5, gen_loss = 0.40883827071104734, disc_loss = 0.06251152455806733
Trained batch 280 in epoch 5, gen_loss = 0.40885335429707453, disc_loss = 0.062345108269213356
Trained batch 281 in epoch 5, gen_loss = 0.4088115116171803, disc_loss = 0.06215866472479616
Trained batch 282 in epoch 5, gen_loss = 0.40891124692485525, disc_loss = 0.06195121316005584
Trained batch 283 in epoch 5, gen_loss = 0.40906857541749175, disc_loss = 0.06180111039675851
Trained batch 284 in epoch 5, gen_loss = 0.4090146986016056, disc_loss = 0.06169918118322497
Trained batch 285 in epoch 5, gen_loss = 0.4089247736480686, disc_loss = 0.061736714422956786
Trained batch 286 in epoch 5, gen_loss = 0.40859669457329273, disc_loss = 0.06227183912049992
Trained batch 287 in epoch 5, gen_loss = 0.40859954090168077, disc_loss = 0.062110363288310405
Trained batch 288 in epoch 5, gen_loss = 0.4086961089327261, disc_loss = 0.06279277212669666
Trained batch 289 in epoch 5, gen_loss = 0.40848230822332976, disc_loss = 0.06273984622836498
Trained batch 290 in epoch 5, gen_loss = 0.4083490975943628, disc_loss = 0.06294010171452313
Trained batch 291 in epoch 5, gen_loss = 0.4081034050004123, disc_loss = 0.06276374241920851
Trained batch 292 in epoch 5, gen_loss = 0.4079402786879816, disc_loss = 0.06262784205145065
Trained batch 293 in epoch 5, gen_loss = 0.4080215460386406, disc_loss = 0.06261023911283206
Trained batch 294 in epoch 5, gen_loss = 0.4081178398455604, disc_loss = 0.062417709102096444
Trained batch 295 in epoch 5, gen_loss = 0.407965520950588, disc_loss = 0.06230938103682412
Trained batch 296 in epoch 5, gen_loss = 0.4079427795378046, disc_loss = 0.06221374333836138
Trained batch 297 in epoch 5, gen_loss = 0.407961759391247, disc_loss = 0.062145102857424556
Trained batch 298 in epoch 5, gen_loss = 0.40757758402106753, disc_loss = 0.06201203678965095
Trained batch 299 in epoch 5, gen_loss = 0.4072901197274526, disc_loss = 0.06189573105502253
Trained batch 300 in epoch 5, gen_loss = 0.40755836155723496, disc_loss = 0.06227223170484939
Trained batch 301 in epoch 5, gen_loss = 0.40743272855187096, disc_loss = 0.06209873485252483
Trained batch 302 in epoch 5, gen_loss = 0.40751619622258856, disc_loss = 0.061985933772832305
Trained batch 303 in epoch 5, gen_loss = 0.40746061464673594, disc_loss = 0.062103100495541616
Trained batch 304 in epoch 5, gen_loss = 0.40748668987242903, disc_loss = 0.06209123463858469
Trained batch 305 in epoch 5, gen_loss = 0.4077206801355275, disc_loss = 0.061997507176106324
Trained batch 306 in epoch 5, gen_loss = 0.407717826312062, disc_loss = 0.0618137126304634
Trained batch 307 in epoch 5, gen_loss = 0.40729851207949896, disc_loss = 0.061661492395910206
Trained batch 308 in epoch 5, gen_loss = 0.4072871195652724, disc_loss = 0.06151739833801141
Trained batch 309 in epoch 5, gen_loss = 0.4074023820700184, disc_loss = 0.061336600270512846
Trained batch 310 in epoch 5, gen_loss = 0.40737195633998635, disc_loss = 0.061152540456497644
Trained batch 311 in epoch 5, gen_loss = 0.407290591356846, disc_loss = 0.06097679320522823
Trained batch 312 in epoch 5, gen_loss = 0.40710699662994654, disc_loss = 0.060859396676577554
Trained batch 313 in epoch 5, gen_loss = 0.4071216347870553, disc_loss = 0.06099442601764492
Trained batch 314 in epoch 5, gen_loss = 0.4073659234576755, disc_loss = 0.06140814017105315
Trained batch 315 in epoch 5, gen_loss = 0.40750410153141503, disc_loss = 0.06127274620915539
Trained batch 316 in epoch 5, gen_loss = 0.4075725791206119, disc_loss = 0.0611927245812614
Trained batch 317 in epoch 5, gen_loss = 0.4074210707309111, disc_loss = 0.061131689144714306
Trained batch 318 in epoch 5, gen_loss = 0.4074581435481583, disc_loss = 0.0609541163614843
Trained batch 319 in epoch 5, gen_loss = 0.40736045856028796, disc_loss = 0.061043617368704874
Trained batch 320 in epoch 5, gen_loss = 0.4069212522833518, disc_loss = 0.06117854950401201
Trained batch 321 in epoch 5, gen_loss = 0.4068187035573936, disc_loss = 0.061040688943123644
Trained batch 322 in epoch 5, gen_loss = 0.40703247898134287, disc_loss = 0.06088864829913128
Trained batch 323 in epoch 5, gen_loss = 0.40708281219373516, disc_loss = 0.06074788721844577
Trained batch 324 in epoch 5, gen_loss = 0.4071160640166356, disc_loss = 0.0606620553171692
Trained batch 325 in epoch 5, gen_loss = 0.40712852355527, disc_loss = 0.060755039563122566
Trained batch 326 in epoch 5, gen_loss = 0.4070511855845787, disc_loss = 0.06188996159329167
Trained batch 327 in epoch 5, gen_loss = 0.40719785259627717, disc_loss = 0.06175369374445503
Trained batch 328 in epoch 5, gen_loss = 0.40702164100658567, disc_loss = 0.06171908041980333
Trained batch 329 in epoch 5, gen_loss = 0.4070621879714908, disc_loss = 0.061598434043116865
Trained batch 330 in epoch 5, gen_loss = 0.40679686766376666, disc_loss = 0.06144024712298054
Trained batch 331 in epoch 5, gen_loss = 0.40667794797434864, disc_loss = 0.061274707933792465
Trained batch 332 in epoch 5, gen_loss = 0.40658908527534643, disc_loss = 0.06113395608287562
Trained batch 333 in epoch 5, gen_loss = 0.4064391507895407, disc_loss = 0.06102409848349426
Trained batch 334 in epoch 5, gen_loss = 0.40650140918902494, disc_loss = 0.06089967359065898
Trained batch 335 in epoch 5, gen_loss = 0.40621619627234484, disc_loss = 0.06096529504880198
Trained batch 336 in epoch 5, gen_loss = 0.40632588131137704, disc_loss = 0.0622106200348011
Trained batch 337 in epoch 5, gen_loss = 0.40617778509326236, disc_loss = 0.06213826266153214
Trained batch 338 in epoch 5, gen_loss = 0.40641395980629597, disc_loss = 0.06208691233837741
Trained batch 339 in epoch 5, gen_loss = 0.40633898394949297, disc_loss = 0.062001608311445175
Trained batch 340 in epoch 5, gen_loss = 0.40631871191986846, disc_loss = 0.062005421828855475
Trained batch 341 in epoch 5, gen_loss = 0.4063710589506473, disc_loss = 0.062071753087813
Trained batch 342 in epoch 5, gen_loss = 0.4062641452422295, disc_loss = 0.061984683622527355
Trained batch 343 in epoch 5, gen_loss = 0.40624954222246656, disc_loss = 0.06194945843822626
Trained batch 344 in epoch 5, gen_loss = 0.40619646604510323, disc_loss = 0.06180930539790163
Trained batch 345 in epoch 5, gen_loss = 0.4063342486675075, disc_loss = 0.06174475155337417
Trained batch 346 in epoch 5, gen_loss = 0.40603293955154307, disc_loss = 0.062048583518933796
Trained batch 347 in epoch 5, gen_loss = 0.40602710115155954, disc_loss = 0.06264375927844673
Trained batch 348 in epoch 5, gen_loss = 0.4060663180399078, disc_loss = 0.06268561458986327
Trained batch 349 in epoch 5, gen_loss = 0.40594378181866236, disc_loss = 0.06259810575882771
Trained batch 350 in epoch 5, gen_loss = 0.4058929738665578, disc_loss = 0.06257037430447115
Trained batch 351 in epoch 5, gen_loss = 0.4058080339296298, disc_loss = 0.06241942257871746
Trained batch 352 in epoch 5, gen_loss = 0.4057703683464115, disc_loss = 0.062267246892907926
Trained batch 353 in epoch 5, gen_loss = 0.4058714931630819, disc_loss = 0.06210124340187232
Trained batch 354 in epoch 5, gen_loss = 0.40576566029602373, disc_loss = 0.06196108978425323
Trained batch 355 in epoch 5, gen_loss = 0.4057178624560324, disc_loss = 0.06181482458879564
Trained batch 356 in epoch 5, gen_loss = 0.40547838523274377, disc_loss = 0.06170054428482882
Trained batch 357 in epoch 5, gen_loss = 0.4053479619532324, disc_loss = 0.06164702763078558
Trained batch 358 in epoch 5, gen_loss = 0.4052975084788288, disc_loss = 0.06152347384881965
Trained batch 359 in epoch 5, gen_loss = 0.40555180807908375, disc_loss = 0.061573467598969325
Trained batch 360 in epoch 5, gen_loss = 0.40555251470232934, disc_loss = 0.06153555446461751
Trained batch 361 in epoch 5, gen_loss = 0.4057639423160922, disc_loss = 0.06142022817148647
Trained batch 362 in epoch 5, gen_loss = 0.4058594344897047, disc_loss = 0.061730522861237286
Trained batch 363 in epoch 5, gen_loss = 0.4057964863521712, disc_loss = 0.06174145508327286
Trained batch 364 in epoch 5, gen_loss = 0.40593752150666224, disc_loss = 0.061591291138009256
Trained batch 365 in epoch 5, gen_loss = 0.4059117458394316, disc_loss = 0.061440620162967044
Trained batch 366 in epoch 5, gen_loss = 0.4059444494565761, disc_loss = 0.0612834858078743
Trained batch 367 in epoch 5, gen_loss = 0.40606663959181827, disc_loss = 0.06119757981935475
Trained batch 368 in epoch 5, gen_loss = 0.40612486974010625, disc_loss = 0.061068815074426935
Trained batch 369 in epoch 5, gen_loss = 0.406219743796297, disc_loss = 0.0609820877566833
Trained batch 370 in epoch 5, gen_loss = 0.4063935273419815, disc_loss = 0.060924475223097116
Trained batch 371 in epoch 5, gen_loss = 0.4063965739101492, disc_loss = 0.06091824351053845
Trained batch 372 in epoch 5, gen_loss = 0.40639299937291695, disc_loss = 0.06099229870144348
Trained batch 373 in epoch 5, gen_loss = 0.40624982469222126, disc_loss = 0.06096009506575046
Trained batch 374 in epoch 5, gen_loss = 0.40650904607772825, disc_loss = 0.0608232573159039
Trained batch 375 in epoch 5, gen_loss = 0.40674964956780696, disc_loss = 0.06070553721300267
Trained batch 376 in epoch 5, gen_loss = 0.40669026670468583, disc_loss = 0.06055725836108589
Trained batch 377 in epoch 5, gen_loss = 0.4067417211318142, disc_loss = 0.060422126044859255
Trained batch 378 in epoch 5, gen_loss = 0.4067591404380144, disc_loss = 0.06044059492387172
Trained batch 379 in epoch 5, gen_loss = 0.4069091124754203, disc_loss = 0.06065535243281996
Trained batch 380 in epoch 5, gen_loss = 0.4068783743018553, disc_loss = 0.06078915970566196
Trained batch 381 in epoch 5, gen_loss = 0.4070134503835159, disc_loss = 0.06065629847732943
Trained batch 382 in epoch 5, gen_loss = 0.4070050737409617, disc_loss = 0.06052535329155099
Trained batch 383 in epoch 5, gen_loss = 0.4068349108565599, disc_loss = 0.06046156067532138
Trained batch 384 in epoch 5, gen_loss = 0.4067898787461318, disc_loss = 0.06036365753426761
Trained batch 385 in epoch 5, gen_loss = 0.406850456959843, disc_loss = 0.060269345021493
Trained batch 386 in epoch 5, gen_loss = 0.40689956803038446, disc_loss = 0.060411118528052435
Trained batch 387 in epoch 5, gen_loss = 0.4068514957409544, disc_loss = 0.06084980585098689
Trained batch 388 in epoch 5, gen_loss = 0.4070351683848315, disc_loss = 0.06110284165156033
Trained batch 389 in epoch 5, gen_loss = 0.40699024009398926, disc_loss = 0.06101676443329033
Trained batch 390 in epoch 5, gen_loss = 0.4068992123426989, disc_loss = 0.06092866592923813
Trained batch 391 in epoch 5, gen_loss = 0.4069673991477003, disc_loss = 0.060810174067191095
Trained batch 392 in epoch 5, gen_loss = 0.40708099931251, disc_loss = 0.060710009676819006
Trained batch 393 in epoch 5, gen_loss = 0.40701798179427984, disc_loss = 0.06059386923573533
Trained batch 394 in epoch 5, gen_loss = 0.4070653624172452, disc_loss = 0.060461578712668974
Trained batch 395 in epoch 5, gen_loss = 0.4071193329914652, disc_loss = 0.060348095088924344
Trained batch 396 in epoch 5, gen_loss = 0.4069666235663128, disc_loss = 0.06021730272305815
Trained batch 397 in epoch 5, gen_loss = 0.40700448120958244, disc_loss = 0.060223479992733454
Trained batch 398 in epoch 5, gen_loss = 0.40672560346156433, disc_loss = 0.0608453302723554
Trained batch 399 in epoch 5, gen_loss = 0.40692804582417014, disc_loss = 0.06098130044410936
Trained batch 400 in epoch 5, gen_loss = 0.40676760398538925, disc_loss = 0.060857883739306076
Trained batch 401 in epoch 5, gen_loss = 0.40673971554236626, disc_loss = 0.06076399828956013
Trained batch 402 in epoch 5, gen_loss = 0.40655767599643017, disc_loss = 0.06063873402510883
Trained batch 403 in epoch 5, gen_loss = 0.406664051779426, disc_loss = 0.06054002160349363
Trained batch 404 in epoch 5, gen_loss = 0.4067495991418391, disc_loss = 0.060405380116706646
Trained batch 405 in epoch 5, gen_loss = 0.40684769570533863, disc_loss = 0.060273898922576764
Trained batch 406 in epoch 5, gen_loss = 0.4069431038980695, disc_loss = 0.06014689009211024
Trained batch 407 in epoch 5, gen_loss = 0.4068414222668199, disc_loss = 0.06007491096548334
Trained batch 408 in epoch 5, gen_loss = 0.40673460230267716, disc_loss = 0.060001816792973756
Trained batch 409 in epoch 5, gen_loss = 0.4067738192110527, disc_loss = 0.059920432269800365
Trained batch 410 in epoch 5, gen_loss = 0.4069848839383926, disc_loss = 0.059856113323991676
Trained batch 411 in epoch 5, gen_loss = 0.4068636998389531, disc_loss = 0.06038788542969749
Trained batch 412 in epoch 5, gen_loss = 0.40684643647572605, disc_loss = 0.06153385838737247
Trained batch 413 in epoch 5, gen_loss = 0.40689245024740983, disc_loss = 0.06202067164501742
Trained batch 414 in epoch 5, gen_loss = 0.40673174197415274, disc_loss = 0.06249312445723328
Trained batch 415 in epoch 5, gen_loss = 0.40669376789950407, disc_loss = 0.0626486061608795
Trained batch 416 in epoch 5, gen_loss = 0.4065066586009604, disc_loss = 0.06273907765732717
Trained batch 417 in epoch 5, gen_loss = 0.4064831745824175, disc_loss = 0.06269674713981814
Trained batch 418 in epoch 5, gen_loss = 0.40626181046831866, disc_loss = 0.06264104256361971
Trained batch 419 in epoch 5, gen_loss = 0.4060983627325013, disc_loss = 0.06254978270957336
Trained batch 420 in epoch 5, gen_loss = 0.4060672132957576, disc_loss = 0.0624366241082496
Trained batch 421 in epoch 5, gen_loss = 0.40587138882463014, disc_loss = 0.06233249046680875
Trained batch 422 in epoch 5, gen_loss = 0.4059116290816179, disc_loss = 0.062280202322985194
Trained batch 423 in epoch 5, gen_loss = 0.40584233206398085, disc_loss = 0.06226142228664479
Trained batch 424 in epoch 5, gen_loss = 0.40566473911790285, disc_loss = 0.06232368763645782
Trained batch 425 in epoch 5, gen_loss = 0.4056605083142088, disc_loss = 0.06256571660329863
Trained batch 426 in epoch 5, gen_loss = 0.40540345756454826, disc_loss = 0.06357363867846076
Trained batch 427 in epoch 5, gen_loss = 0.4056631151203797, disc_loss = 0.06361944915913915
Trained batch 428 in epoch 5, gen_loss = 0.40581561232502367, disc_loss = 0.06367092450976476
Trained batch 429 in epoch 5, gen_loss = 0.4056661415238713, disc_loss = 0.06384951740741557
Trained batch 430 in epoch 5, gen_loss = 0.4056089894539242, disc_loss = 0.06383256253671861
Trained batch 431 in epoch 5, gen_loss = 0.40552159391895487, disc_loss = 0.0637293955757438
Trained batch 432 in epoch 5, gen_loss = 0.4054399748735009, disc_loss = 0.0637200155411578
Trained batch 433 in epoch 5, gen_loss = 0.40517856551480186, disc_loss = 0.06387069323829757
Trained batch 434 in epoch 5, gen_loss = 0.40526683693644644, disc_loss = 0.06390947913965103
Trained batch 435 in epoch 5, gen_loss = 0.40533567958195277, disc_loss = 0.06387815162552299
Trained batch 436 in epoch 5, gen_loss = 0.4054555386918633, disc_loss = 0.06386598972262691
Trained batch 437 in epoch 5, gen_loss = 0.40549234032086584, disc_loss = 0.06383318942546266
Trained batch 438 in epoch 5, gen_loss = 0.40552991031242663, disc_loss = 0.0637231923921929
Trained batch 439 in epoch 5, gen_loss = 0.40552829815582797, disc_loss = 0.06361938867061823
Trained batch 440 in epoch 5, gen_loss = 0.4054255537570469, disc_loss = 0.06353866117277822
Trained batch 442 in epoch 5, gen_loss = 0.40517503507519415, disc_loss = 0.06356668400916672
Trained batch 443 in epoch 5, gen_loss = 0.4051931581652916, disc_loss = 0.06433615769020508
Trained batch 444 in epoch 5, gen_loss = 0.40529559375195023, disc_loss = 0.0644377205405761
Trained batch 445 in epoch 5, gen_loss = 0.4051050768973047, disc_loss = 0.06448091184950096
Trained batch 446 in epoch 5, gen_loss = 0.40493000000381896, disc_loss = 0.06454108749730908
Trained batch 447 in epoch 5, gen_loss = 0.40491055557504296, disc_loss = 0.06449928954680217
Trained batch 448 in epoch 5, gen_loss = 0.40487868303976504, disc_loss = 0.06451442482713236
Trained batch 449 in epoch 5, gen_loss = 0.4045515684949027, disc_loss = 0.06488052523901892
Trained batch 450 in epoch 5, gen_loss = 0.4046731907750445, disc_loss = 0.06491660027808104
Trained batch 451 in epoch 5, gen_loss = 0.4047531168413373, disc_loss = 0.06483076591213621
Trained batch 452 in epoch 5, gen_loss = 0.40478422139127784, disc_loss = 0.06476040832620221
Trained batch 453 in epoch 5, gen_loss = 0.4047654681400055, disc_loss = 0.06467241746791955
Trained batch 454 in epoch 5, gen_loss = 0.40485404683993415, disc_loss = 0.06460485134662672
Trained batch 455 in epoch 5, gen_loss = 0.4048109416637504, disc_loss = 0.06458430650353987
Trained batch 456 in epoch 5, gen_loss = 0.4048058755157813, disc_loss = 0.06458282587780766
Trained batch 457 in epoch 5, gen_loss = 0.40484228983976955, disc_loss = 0.06451598979130095
Trained batch 458 in epoch 5, gen_loss = 0.405127233344745, disc_loss = 0.06452442916345524
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 0.39720845222473145, disc_loss = 0.04770946130156517
Trained batch 1 in epoch 6, gen_loss = 0.41643062233924866, disc_loss = 0.028394163586199284
Trained batch 2 in epoch 6, gen_loss = 0.44909125566482544, disc_loss = 0.021234743607540924
Trained batch 3 in epoch 6, gen_loss = 0.4244740977883339, disc_loss = 0.023604775546118617
Trained batch 4 in epoch 6, gen_loss = 0.42313013076782224, disc_loss = 0.021672647446393967
Trained batch 5 in epoch 6, gen_loss = 0.4282698680957158, disc_loss = 0.024147186428308487
Trained batch 6 in epoch 6, gen_loss = 0.427323260477611, disc_loss = 0.022558224786605154
Trained batch 7 in epoch 6, gen_loss = 0.43041446805000305, disc_loss = 0.027977471007034183
Trained batch 8 in epoch 6, gen_loss = 0.41913307706514996, disc_loss = 0.03243135722974936
Trained batch 9 in epoch 6, gen_loss = 0.4253382533788681, disc_loss = 0.030037441197782754
Trained batch 10 in epoch 6, gen_loss = 0.42221151156858966, disc_loss = 0.031172448345883327
Trained batch 11 in epoch 6, gen_loss = 0.4214405119419098, disc_loss = 0.03663204680196941
Trained batch 12 in epoch 6, gen_loss = 0.4297550549873939, disc_loss = 0.04245299681161459
Trained batch 13 in epoch 6, gen_loss = 0.43126099024500164, disc_loss = 0.03979965166321823
Trained batch 14 in epoch 6, gen_loss = 0.429145226875941, disc_loss = 0.03838494196534157
Trained batch 15 in epoch 6, gen_loss = 0.4278458394110203, disc_loss = 0.039521881844848394
Trained batch 16 in epoch 6, gen_loss = 0.42425235054072213, disc_loss = 0.03998144759851344
Trained batch 17 in epoch 6, gen_loss = 0.4256063865290748, disc_loss = 0.03849394034801258
Trained batch 18 in epoch 6, gen_loss = 0.4225556536724693, disc_loss = 0.038469498437878336
Trained batch 19 in epoch 6, gen_loss = 0.42228244841098783, disc_loss = 0.0370230904314667
Trained batch 20 in epoch 6, gen_loss = 0.4197672747430347, disc_loss = 0.036135874378184475
Trained batch 21 in epoch 6, gen_loss = 0.4184992557222193, disc_loss = 0.03707452935420654
Trained batch 22 in epoch 6, gen_loss = 0.4166753888130188, disc_loss = 0.03875525202602148
Trained batch 23 in epoch 6, gen_loss = 0.41717302550872165, disc_loss = 0.038137381935181715
Trained batch 24 in epoch 6, gen_loss = 0.4190843749046326, disc_loss = 0.03699879724532366
Trained batch 25 in epoch 6, gen_loss = 0.4183139938574571, disc_loss = 0.0358265286956269
Trained batch 26 in epoch 6, gen_loss = 0.4163110079588713, disc_loss = 0.03497698692673886
Trained batch 27 in epoch 6, gen_loss = 0.41717954192842754, disc_loss = 0.03396717442332634
Trained batch 28 in epoch 6, gen_loss = 0.4172955946675662, disc_loss = 0.03297310510393361
Trained batch 29 in epoch 6, gen_loss = 0.4181970496972402, disc_loss = 0.03224990819580853
Trained batch 30 in epoch 6, gen_loss = 0.41489231298046725, disc_loss = 0.03208626090218463
Trained batch 31 in epoch 6, gen_loss = 0.414871146902442, disc_loss = 0.03242749247874599
Trained batch 32 in epoch 6, gen_loss = 0.41458174405675946, disc_loss = 0.0321860987777737
Trained batch 33 in epoch 6, gen_loss = 0.4135274825727238, disc_loss = 0.03138664586688666
Trained batch 34 in epoch 6, gen_loss = 0.41625230738094876, disc_loss = 0.030868658955608096
Trained batch 35 in epoch 6, gen_loss = 0.4157663500971264, disc_loss = 0.030249128842519388
Trained batch 36 in epoch 6, gen_loss = 0.41650606571017085, disc_loss = 0.02994276598297261
Trained batch 37 in epoch 6, gen_loss = 0.4160765221244411, disc_loss = 0.029369579137940156
Trained batch 38 in epoch 6, gen_loss = 0.41648355432045764, disc_loss = 0.029094833116500806
Trained batch 39 in epoch 6, gen_loss = 0.4156286187469959, disc_loss = 0.02881426471285522
Trained batch 40 in epoch 6, gen_loss = 0.4162010165249429, disc_loss = 0.02824578227520716
Trained batch 41 in epoch 6, gen_loss = 0.41659069274153027, disc_loss = 0.027674458399858503
Trained batch 42 in epoch 6, gen_loss = 0.41606281385865324, disc_loss = 0.027192886041607276
Trained batch 43 in epoch 6, gen_loss = 0.4148005558685823, disc_loss = 0.026994680805893786
Trained batch 44 in epoch 6, gen_loss = 0.4152649972173903, disc_loss = 0.02675637908072935
Trained batch 45 in epoch 6, gen_loss = 0.41631586396175885, disc_loss = 0.026401655454917447
Trained batch 46 in epoch 6, gen_loss = 0.4148475058535312, disc_loss = 0.02669053044209772
Trained batch 47 in epoch 6, gen_loss = 0.4141398773839076, disc_loss = 0.02675482237827964
Trained batch 48 in epoch 6, gen_loss = 0.4142004665063352, disc_loss = 0.026307965676319236
Trained batch 49 in epoch 6, gen_loss = 0.4132322144508362, disc_loss = 0.025921523002907634
Trained batch 50 in epoch 6, gen_loss = 0.4121559402521919, disc_loss = 0.025770242444659565
Trained batch 51 in epoch 6, gen_loss = 0.4120846207325275, disc_loss = 0.02536849595176486
Trained batch 52 in epoch 6, gen_loss = 0.4133100712074424, disc_loss = 0.025164511195331248
Trained batch 53 in epoch 6, gen_loss = 0.41371288343712137, disc_loss = 0.025208645948657283
Trained batch 54 in epoch 6, gen_loss = 0.4115188105539842, disc_loss = 0.030167543888092042
Trained batch 55 in epoch 6, gen_loss = 0.4118025340139866, disc_loss = 0.03461153752037457
Trained batch 56 in epoch 6, gen_loss = 0.4118453750484868, disc_loss = 0.0343377739844615
Trained batch 57 in epoch 6, gen_loss = 0.4104854063741092, disc_loss = 0.03393176348944162
Trained batch 58 in epoch 6, gen_loss = 0.40831523729582964, disc_loss = 0.03441837439471382
Trained batch 59 in epoch 6, gen_loss = 0.4075530216097832, disc_loss = 0.035027418130387865
Trained batch 60 in epoch 6, gen_loss = 0.4052951511789541, disc_loss = 0.036582798101618644
Trained batch 61 in epoch 6, gen_loss = 0.4047098505881525, disc_loss = 0.037308534637333884
Trained batch 62 in epoch 6, gen_loss = 0.4038516775010124, disc_loss = 0.03713561520571747
Trained batch 63 in epoch 6, gen_loss = 0.4039308908395469, disc_loss = 0.03708427256788127
Trained batch 64 in epoch 6, gen_loss = 0.4039420609290783, disc_loss = 0.037755360941474254
Trained batch 65 in epoch 6, gen_loss = 0.40309644558212976, disc_loss = 0.0440642074822928
Trained batch 66 in epoch 6, gen_loss = 0.40361630738671145, disc_loss = 0.04448014383774195
Trained batch 67 in epoch 6, gen_loss = 0.4028019155649578, disc_loss = 0.04501334739410702
Trained batch 68 in epoch 6, gen_loss = 0.40163882746212726, disc_loss = 0.045413034522662994
Trained batch 69 in epoch 6, gen_loss = 0.4025628511394773, disc_loss = 0.04524362164416484
Trained batch 70 in epoch 6, gen_loss = 0.4032120876748797, disc_loss = 0.04573495363370633
Trained batch 71 in epoch 6, gen_loss = 0.40333355425132644, disc_loss = 0.045336183703814946
Trained batch 72 in epoch 6, gen_loss = 0.4027633654744658, disc_loss = 0.04538696404699594
Trained batch 73 in epoch 6, gen_loss = 0.4023177643885484, disc_loss = 0.04565319411355902
Trained batch 74 in epoch 6, gen_loss = 0.4043595055739085, disc_loss = 0.047617347165942195
Trained batch 75 in epoch 6, gen_loss = 0.40485546698695735, disc_loss = 0.04719896487107402
Trained batch 76 in epoch 6, gen_loss = 0.4038843961505147, disc_loss = 0.04732178833771061
Trained batch 77 in epoch 6, gen_loss = 0.40464164507694733, disc_loss = 0.04681738514978534
Trained batch 78 in epoch 6, gen_loss = 0.4047315562073189, disc_loss = 0.04647921107096385
Trained batch 79 in epoch 6, gen_loss = 0.40399050936102865, disc_loss = 0.04761302719125524
Trained batch 80 in epoch 6, gen_loss = 0.403805978504228, disc_loss = 0.05198767768610039
Trained batch 81 in epoch 6, gen_loss = 0.4040256949459634, disc_loss = 0.052382830950635964
Trained batch 82 in epoch 6, gen_loss = 0.40411545246480457, disc_loss = 0.05331385491348534
Trained batch 83 in epoch 6, gen_loss = 0.40405079367614927, disc_loss = 0.053398433729030546
Trained batch 84 in epoch 6, gen_loss = 0.40464761818156525, disc_loss = 0.054445393832729144
Trained batch 85 in epoch 6, gen_loss = 0.40427897142809494, disc_loss = 0.05443333558261741
Trained batch 86 in epoch 6, gen_loss = 0.4042850020288051, disc_loss = 0.05398989172288399
Trained batch 87 in epoch 6, gen_loss = 0.403838612139225, disc_loss = 0.05378894536459649
Trained batch 88 in epoch 6, gen_loss = 0.4046435004539704, disc_loss = 0.05379126358023855
Trained batch 89 in epoch 6, gen_loss = 0.40444243881437514, disc_loss = 0.053700758051127194
Trained batch 90 in epoch 6, gen_loss = 0.4035213216320499, disc_loss = 0.05452185905037018
Trained batch 91 in epoch 6, gen_loss = 0.4034707565670428, disc_loss = 0.054064678949425404
Trained batch 92 in epoch 6, gen_loss = 0.4035812174120257, disc_loss = 0.05453990771365102
Trained batch 93 in epoch 6, gen_loss = 0.4031809127711235, disc_loss = 0.057812653987252334
Trained batch 94 in epoch 6, gen_loss = 0.4040053671912143, disc_loss = 0.05909952257612818
Trained batch 95 in epoch 6, gen_loss = 0.4038609989608328, disc_loss = 0.0597664215893019
Trained batch 96 in epoch 6, gen_loss = 0.4030682969953596, disc_loss = 0.05959676673693448
Trained batch 97 in epoch 6, gen_loss = 0.40215425588646714, disc_loss = 0.05978388178675455
Trained batch 98 in epoch 6, gen_loss = 0.4017653302712874, disc_loss = 0.05939090984751179
Trained batch 99 in epoch 6, gen_loss = 0.4013708004355431, disc_loss = 0.05887467941269278
Trained batch 100 in epoch 6, gen_loss = 0.4004293833628739, disc_loss = 0.05883933199883098
Trained batch 101 in epoch 6, gen_loss = 0.4002464512983958, disc_loss = 0.058772937577290865
Trained batch 102 in epoch 6, gen_loss = 0.4013361849831146, disc_loss = 0.05960292631344309
Trained batch 103 in epoch 6, gen_loss = 0.40072362984602267, disc_loss = 0.05926407703485053
Trained batch 104 in epoch 6, gen_loss = 0.39977443842660815, disc_loss = 0.06047235388486158
Trained batch 105 in epoch 6, gen_loss = 0.4012368220203328, disc_loss = 0.06045921753107939
Trained batch 106 in epoch 6, gen_loss = 0.401587096051635, disc_loss = 0.06159464668517358
Trained batch 107 in epoch 6, gen_loss = 0.4015466496348381, disc_loss = 0.062363416525638767
Trained batch 108 in epoch 6, gen_loss = 0.401351977652366, disc_loss = 0.061961766246945486
Trained batch 109 in epoch 6, gen_loss = 0.4014876446940682, disc_loss = 0.06150130734524944
Trained batch 110 in epoch 6, gen_loss = 0.4019045784129753, disc_loss = 0.06118105922464852
Trained batch 111 in epoch 6, gen_loss = 0.40152885392308235, disc_loss = 0.06228465087977903
Trained batch 112 in epoch 6, gen_loss = 0.40082687165884845, disc_loss = 0.06455195088565877
Trained batch 113 in epoch 6, gen_loss = 0.4006919215122859, disc_loss = 0.06470854345120881
Trained batch 114 in epoch 6, gen_loss = 0.4017298659552699, disc_loss = 0.06541602494923965
Trained batch 115 in epoch 6, gen_loss = 0.40151352640883675, disc_loss = 0.06554268095000036
Trained batch 116 in epoch 6, gen_loss = 0.40147526676838213, disc_loss = 0.06535205159049767
Trained batch 117 in epoch 6, gen_loss = 0.4011802337432312, disc_loss = 0.06501824407191095
Trained batch 118 in epoch 6, gen_loss = 0.4016199011762603, disc_loss = 0.06460369525461637
Trained batch 119 in epoch 6, gen_loss = 0.4019208592673143, disc_loss = 0.06438197642564773
Trained batch 120 in epoch 6, gen_loss = 0.4026716738200385, disc_loss = 0.06407974594203401
Trained batch 121 in epoch 6, gen_loss = 0.4021284660843552, disc_loss = 0.0641312575517375
Trained batch 122 in epoch 6, gen_loss = 0.40227009150070875, disc_loss = 0.06378049347398242
Trained batch 123 in epoch 6, gen_loss = 0.402817633844191, disc_loss = 0.06355472075782957
Trained batch 124 in epoch 6, gen_loss = 0.40328398275375366, disc_loss = 0.06339787085354329
Trained batch 125 in epoch 6, gen_loss = 0.4035959702635568, disc_loss = 0.06340667748794196
Trained batch 126 in epoch 6, gen_loss = 0.404037541761173, disc_loss = 0.06308333417327386
Trained batch 127 in epoch 6, gen_loss = 0.40439459937624633, disc_loss = 0.06293514274875633
Trained batch 128 in epoch 6, gen_loss = 0.4052226125269897, disc_loss = 0.06398238053964089
Trained batch 129 in epoch 6, gen_loss = 0.4048689461671389, disc_loss = 0.06456837674173024
Trained batch 130 in epoch 6, gen_loss = 0.40484902285437546, disc_loss = 0.06429622049322566
Trained batch 131 in epoch 6, gen_loss = 0.40517538356961624, disc_loss = 0.06422790636618932
Trained batch 132 in epoch 6, gen_loss = 0.4046566121112135, disc_loss = 0.06389492030318518
Trained batch 133 in epoch 6, gen_loss = 0.404459522953674, disc_loss = 0.0635757463803487
Trained batch 134 in epoch 6, gen_loss = 0.4046197816177651, disc_loss = 0.06329813006299513
Trained batch 135 in epoch 6, gen_loss = 0.4046353945399032, disc_loss = 0.06295583349214319
Trained batch 136 in epoch 6, gen_loss = 0.4044773045682559, disc_loss = 0.06277476018634591
Trained batch 137 in epoch 6, gen_loss = 0.40426288329172827, disc_loss = 0.0627785697174461
Trained batch 138 in epoch 6, gen_loss = 0.40446554220837655, disc_loss = 0.06315042272799735
Trained batch 139 in epoch 6, gen_loss = 0.40386514344385693, disc_loss = 0.06396589993632265
Trained batch 140 in epoch 6, gen_loss = 0.40482674528521, disc_loss = 0.06389746155774763
Trained batch 141 in epoch 6, gen_loss = 0.4049590933071056, disc_loss = 0.06426506417370598
Trained batch 142 in epoch 6, gen_loss = 0.40478959533718084, disc_loss = 0.06472860434307502
Trained batch 143 in epoch 6, gen_loss = 0.40480413287878036, disc_loss = 0.06439717794354591
Trained batch 144 in epoch 6, gen_loss = 0.40489151621687003, disc_loss = 0.06411708074397054
Trained batch 145 in epoch 6, gen_loss = 0.4044525829488284, disc_loss = 0.06389295289369479
Trained batch 146 in epoch 6, gen_loss = 0.4041699935384348, disc_loss = 0.06367738970688411
Trained batch 147 in epoch 6, gen_loss = 0.4039879106992, disc_loss = 0.06369504216756369
Trained batch 148 in epoch 6, gen_loss = 0.4043344359269878, disc_loss = 0.0635284732452175
Trained batch 149 in epoch 6, gen_loss = 0.40434289038181304, disc_loss = 0.06341180831193924
Trained batch 150 in epoch 6, gen_loss = 0.4042964634911114, disc_loss = 0.0632494759085952
Trained batch 151 in epoch 6, gen_loss = 0.4045223721155995, disc_loss = 0.06416559954615016
Trained batch 152 in epoch 6, gen_loss = 0.4037302738311244, disc_loss = 0.06683418339763592
Trained batch 153 in epoch 6, gen_loss = 0.4037407034790361, disc_loss = 0.06691073277940998
Trained batch 154 in epoch 6, gen_loss = 0.40398611541717283, disc_loss = 0.06698684750064726
Trained batch 155 in epoch 6, gen_loss = 0.40383309374252957, disc_loss = 0.06669094690527672
Trained batch 156 in epoch 6, gen_loss = 0.4039170362387493, disc_loss = 0.06639967431688006
Trained batch 157 in epoch 6, gen_loss = 0.4042313123428369, disc_loss = 0.0662152408327483
Trained batch 158 in epoch 6, gen_loss = 0.4044851962500398, disc_loss = 0.06593833965653519
Trained batch 159 in epoch 6, gen_loss = 0.4044861389324069, disc_loss = 0.06564826265675947
Trained batch 160 in epoch 6, gen_loss = 0.4040988046930443, disc_loss = 0.06537484411173355
Trained batch 161 in epoch 6, gen_loss = 0.4039025961616893, disc_loss = 0.06567162046507921
Trained batch 162 in epoch 6, gen_loss = 0.4037284946149112, disc_loss = 0.06595944445237426
Trained batch 163 in epoch 6, gen_loss = 0.4036929313002563, disc_loss = 0.06600308587502052
Trained batch 164 in epoch 6, gen_loss = 0.4036681332371452, disc_loss = 0.06569402102719654
Trained batch 165 in epoch 6, gen_loss = 0.40392218081347914, disc_loss = 0.06533541748053338
Trained batch 166 in epoch 6, gen_loss = 0.40383579381211787, disc_loss = 0.06504842949038495
Trained batch 167 in epoch 6, gen_loss = 0.4034718388602847, disc_loss = 0.06482260917047304
Trained batch 168 in epoch 6, gen_loss = 0.40320921631959766, disc_loss = 0.06468591291303112
Trained batch 169 in epoch 6, gen_loss = 0.4035120289115345, disc_loss = 0.06486977973185917
Trained batch 170 in epoch 6, gen_loss = 0.40365169846523574, disc_loss = 0.06453466572804235
Trained batch 171 in epoch 6, gen_loss = 0.40336784079324367, disc_loss = 0.06440802280747787
Trained batch 172 in epoch 6, gen_loss = 0.40322471784718467, disc_loss = 0.06408496508428643
Trained batch 173 in epoch 6, gen_loss = 0.4037912445164275, disc_loss = 0.06378305802956738
Trained batch 174 in epoch 6, gen_loss = 0.40390402163778033, disc_loss = 0.06356875701674393
Trained batch 175 in epoch 6, gen_loss = 0.4043868588791652, disc_loss = 0.06330968984614381
Trained batch 176 in epoch 6, gen_loss = 0.4040194120110765, disc_loss = 0.06366390818045975
Trained batch 177 in epoch 6, gen_loss = 0.40436344568649035, disc_loss = 0.06566354685745547
Trained batch 178 in epoch 6, gen_loss = 0.40447264027329133, disc_loss = 0.06535598188222454
Trained batch 179 in epoch 6, gen_loss = 0.4038442361685965, disc_loss = 0.06520686311026415
Trained batch 180 in epoch 6, gen_loss = 0.40391242701704333, disc_loss = 0.06520126196066978
Trained batch 181 in epoch 6, gen_loss = 0.40403551649261304, disc_loss = 0.06532303624591984
Trained batch 182 in epoch 6, gen_loss = 0.4037790651855573, disc_loss = 0.06521133423014416
Trained batch 183 in epoch 6, gen_loss = 0.40350860357284546, disc_loss = 0.0653275603266514
Trained batch 184 in epoch 6, gen_loss = 0.4043376039814305, disc_loss = 0.06533584248375249
Trained batch 185 in epoch 6, gen_loss = 0.4045911447335315, disc_loss = 0.06525153871024808
Trained batch 186 in epoch 6, gen_loss = 0.4039536112132557, disc_loss = 0.06610592709664992
Trained batch 187 in epoch 6, gen_loss = 0.40418438232959586, disc_loss = 0.0671003548468047
Trained batch 188 in epoch 6, gen_loss = 0.40409365974406086, disc_loss = 0.06738294633450331
Trained batch 189 in epoch 6, gen_loss = 0.40375657897246514, disc_loss = 0.06763371178194096
Trained batch 190 in epoch 6, gen_loss = 0.4032859092295482, disc_loss = 0.06796682040884856
Trained batch 191 in epoch 6, gen_loss = 0.4035933211756249, disc_loss = 0.068771062612844
Trained batch 192 in epoch 6, gen_loss = 0.4037761631098436, disc_loss = 0.06845132463944623
Trained batch 193 in epoch 6, gen_loss = 0.40365126775097604, disc_loss = 0.06828651471380337
Trained batch 194 in epoch 6, gen_loss = 0.4036831415616549, disc_loss = 0.06807459355690158
Trained batch 195 in epoch 6, gen_loss = 0.4036659507118926, disc_loss = 0.06783188557090732
Trained batch 196 in epoch 6, gen_loss = 0.4034817052371611, disc_loss = 0.06753093454996266
Trained batch 197 in epoch 6, gen_loss = 0.4031685014264752, disc_loss = 0.06737848507437968
Trained batch 198 in epoch 6, gen_loss = 0.40315912551616306, disc_loss = 0.0675131412077901
Trained batch 199 in epoch 6, gen_loss = 0.4031362600624561, disc_loss = 0.06775008377386257
Trained batch 200 in epoch 6, gen_loss = 0.40343521943139793, disc_loss = 0.06777870437056197
Trained batch 201 in epoch 6, gen_loss = 0.4034070778306168, disc_loss = 0.0676753557181115
Trained batch 202 in epoch 6, gen_loss = 0.4036801908110163, disc_loss = 0.0673889846797904
Trained batch 203 in epoch 6, gen_loss = 0.40373895551059763, disc_loss = 0.06710717001445957
Trained batch 204 in epoch 6, gen_loss = 0.403519253469095, disc_loss = 0.06684483906435894
Trained batch 205 in epoch 6, gen_loss = 0.40393143993558234, disc_loss = 0.06657125505853842
Trained batch 206 in epoch 6, gen_loss = 0.4038145809933759, disc_loss = 0.06627851221395503
Trained batch 207 in epoch 6, gen_loss = 0.4039586107604779, disc_loss = 0.06603208973851557
Trained batch 208 in epoch 6, gen_loss = 0.40405438433993945, disc_loss = 0.06573803571574212
Trained batch 209 in epoch 6, gen_loss = 0.4039809143259412, disc_loss = 0.0654450325228806
Trained batch 210 in epoch 6, gen_loss = 0.4039761183951138, disc_loss = 0.06544342963907744
Trained batch 211 in epoch 6, gen_loss = 0.4037564770793015, disc_loss = 0.06635893503739938
Trained batch 212 in epoch 6, gen_loss = 0.4040062080526576, disc_loss = 0.0669189768694691
Trained batch 213 in epoch 6, gen_loss = 0.40396932728379686, disc_loss = 0.06667628279173415
Trained batch 214 in epoch 6, gen_loss = 0.40405115637668343, disc_loss = 0.06651856492728342
Trained batch 215 in epoch 6, gen_loss = 0.4038433661615407, disc_loss = 0.06625350550274123
Trained batch 216 in epoch 6, gen_loss = 0.4039393417571547, disc_loss = 0.0659902372809496
Trained batch 217 in epoch 6, gen_loss = 0.4041206120351039, disc_loss = 0.06573671764916304
Trained batch 218 in epoch 6, gen_loss = 0.4037562831896081, disc_loss = 0.06565755804082098
Trained batch 219 in epoch 6, gen_loss = 0.40365151397206567, disc_loss = 0.06579038786320862
Trained batch 220 in epoch 6, gen_loss = 0.4034941435129934, disc_loss = 0.06653994484699217
Trained batch 221 in epoch 6, gen_loss = 0.4036689152320226, disc_loss = 0.06729245301008828
Trained batch 222 in epoch 6, gen_loss = 0.40313900278822723, disc_loss = 0.06718067578645631
Trained batch 223 in epoch 6, gen_loss = 0.4029418110315289, disc_loss = 0.06720549378120008
Trained batch 224 in epoch 6, gen_loss = 0.4029770551787482, disc_loss = 0.0669368980680075
Trained batch 225 in epoch 6, gen_loss = 0.40311952568260967, disc_loss = 0.06675413097831857
Trained batch 226 in epoch 6, gen_loss = 0.4026657115782935, disc_loss = 0.06673788018565674
Trained batch 227 in epoch 6, gen_loss = 0.4029872672338235, disc_loss = 0.06667287546626635
Trained batch 228 in epoch 6, gen_loss = 0.4030490492889454, disc_loss = 0.06642692887700086
Trained batch 229 in epoch 6, gen_loss = 0.40324324576751047, disc_loss = 0.06628219368867576
Trained batch 230 in epoch 6, gen_loss = 0.40336285009012596, disc_loss = 0.06617762216314416
Trained batch 231 in epoch 6, gen_loss = 0.40337529341722356, disc_loss = 0.06596527225538638
Trained batch 232 in epoch 6, gen_loss = 0.4033665229834201, disc_loss = 0.0657523878642194
Trained batch 233 in epoch 6, gen_loss = 0.4033445450994704, disc_loss = 0.06563878761660148
Trained batch 234 in epoch 6, gen_loss = 0.4032987148203748, disc_loss = 0.06564441787950853
Trained batch 235 in epoch 6, gen_loss = 0.4032603490908267, disc_loss = 0.06549967561998421
Trained batch 236 in epoch 6, gen_loss = 0.4033419035909548, disc_loss = 0.0652499337924275
Trained batch 237 in epoch 6, gen_loss = 0.40327618690598915, disc_loss = 0.06509950042295293
Trained batch 238 in epoch 6, gen_loss = 0.40332859218369965, disc_loss = 0.06486990417560337
Trained batch 239 in epoch 6, gen_loss = 0.4035834821561972, disc_loss = 0.06462674009962939
Trained batch 240 in epoch 6, gen_loss = 0.4035275329940052, disc_loss = 0.06443359985120625
Trained batch 241 in epoch 6, gen_loss = 0.40361393360067005, disc_loss = 0.06429108110841456
Trained batch 242 in epoch 6, gen_loss = 0.4034161291740559, disc_loss = 0.06408785672383115
Trained batch 243 in epoch 6, gen_loss = 0.40329139423174937, disc_loss = 0.06385970135318635
Trained batch 244 in epoch 6, gen_loss = 0.40356902857216037, disc_loss = 0.06370984905646468
Trained batch 245 in epoch 6, gen_loss = 0.4034240775234331, disc_loss = 0.06356512530843114
Trained batch 246 in epoch 6, gen_loss = 0.4034419152659443, disc_loss = 0.0633673362550797
Trained batch 247 in epoch 6, gen_loss = 0.40348343707380757, disc_loss = 0.06316597651382308
Trained batch 248 in epoch 6, gen_loss = 0.4038368100861469, disc_loss = 0.06295116024884773
Trained batch 249 in epoch 6, gen_loss = 0.40375463747978213, disc_loss = 0.06280000661127269
Trained batch 250 in epoch 6, gen_loss = 0.40360257872547284, disc_loss = 0.06290496459631509
Trained batch 251 in epoch 6, gen_loss = 0.4039324652107935, disc_loss = 0.06341252199351965
Trained batch 252 in epoch 6, gen_loss = 0.40415184877135535, disc_loss = 0.06319358141121009
Trained batch 253 in epoch 6, gen_loss = 0.4039435123834084, disc_loss = 0.06369926789445494
Trained batch 254 in epoch 6, gen_loss = 0.40391266322603414, disc_loss = 0.06350388082255627
Trained batch 255 in epoch 6, gen_loss = 0.4040599417639896, disc_loss = 0.06392768863042875
Trained batch 256 in epoch 6, gen_loss = 0.40390029050960613, disc_loss = 0.0638196667174334
Trained batch 257 in epoch 6, gen_loss = 0.40390020816825156, disc_loss = 0.06376771083960757
Trained batch 258 in epoch 6, gen_loss = 0.4039224075534629, disc_loss = 0.06365821639464227
Trained batch 259 in epoch 6, gen_loss = 0.4041895691018838, disc_loss = 0.06347039857915102
Trained batch 260 in epoch 6, gen_loss = 0.404179933313209, disc_loss = 0.06333374135888456
Trained batch 261 in epoch 6, gen_loss = 0.40398632922700345, disc_loss = 0.06352219145695273
Trained batch 262 in epoch 6, gen_loss = 0.40400853571783, disc_loss = 0.06443702200951741
Trained batch 263 in epoch 6, gen_loss = 0.4042670084445765, disc_loss = 0.06435852339244306
Trained batch 264 in epoch 6, gen_loss = 0.4040747618900155, disc_loss = 0.06440929724957864
Trained batch 265 in epoch 6, gen_loss = 0.4041182837988201, disc_loss = 0.06426876665205043
Trained batch 266 in epoch 6, gen_loss = 0.4043881025876892, disc_loss = 0.06409441091099315
Trained batch 267 in epoch 6, gen_loss = 0.40469532838063454, disc_loss = 0.06406589022163413
Trained batch 268 in epoch 6, gen_loss = 0.40488284704410454, disc_loss = 0.06402663465720847
Trained batch 269 in epoch 6, gen_loss = 0.4047486380294517, disc_loss = 0.0638190031827738
Trained batch 270 in epoch 6, gen_loss = 0.40450501375972564, disc_loss = 0.06364182369247409
Trained batch 271 in epoch 6, gen_loss = 0.40463418995632844, disc_loss = 0.06347003754618687
Trained batch 272 in epoch 6, gen_loss = 0.40454282330506014, disc_loss = 0.06352010628740702
Trained batch 273 in epoch 6, gen_loss = 0.4045722487851651, disc_loss = 0.06405571274574928
Trained batch 274 in epoch 6, gen_loss = 0.40434703068299727, disc_loss = 0.06406261853365736
Trained batch 275 in epoch 6, gen_loss = 0.40441106745730276, disc_loss = 0.06389703779258644
Trained batch 276 in epoch 6, gen_loss = 0.40465488265998095, disc_loss = 0.06372615473936664
Trained batch 277 in epoch 6, gen_loss = 0.4049428180396128, disc_loss = 0.0635821276140004
Trained batch 278 in epoch 6, gen_loss = 0.40457408295737374, disc_loss = 0.06343898292143552
Trained batch 279 in epoch 6, gen_loss = 0.4042076304554939, disc_loss = 0.06330574524888237
Trained batch 280 in epoch 6, gen_loss = 0.40426578301127697, disc_loss = 0.063134714246817
Trained batch 281 in epoch 6, gen_loss = 0.4041815791146975, disc_loss = 0.06296406954308932
Trained batch 282 in epoch 6, gen_loss = 0.40418017342318074, disc_loss = 0.0628315083165867
Trained batch 283 in epoch 6, gen_loss = 0.4041290275857482, disc_loss = 0.06292474571399023
Trained batch 284 in epoch 6, gen_loss = 0.404181910084005, disc_loss = 0.06338764896877763
Trained batch 285 in epoch 6, gen_loss = 0.4043399654068313, disc_loss = 0.06370793030128352
Trained batch 286 in epoch 6, gen_loss = 0.40424946043964877, disc_loss = 0.06357962832679057
Trained batch 287 in epoch 6, gen_loss = 0.4040545941227012, disc_loss = 0.06343650709055106
Trained batch 288 in epoch 6, gen_loss = 0.40388868589302246, disc_loss = 0.06337464482049783
Trained batch 289 in epoch 6, gen_loss = 0.40350593873139085, disc_loss = 0.06333065777856471
Trained batch 290 in epoch 6, gen_loss = 0.4034669790480964, disc_loss = 0.0632276560877581
Trained batch 291 in epoch 6, gen_loss = 0.40360545040401696, disc_loss = 0.0631210432716403
Trained batch 292 in epoch 6, gen_loss = 0.40376334731489316, disc_loss = 0.06320268538567546
Trained batch 293 in epoch 6, gen_loss = 0.4036590631316308, disc_loss = 0.06329269339583915
Trained batch 294 in epoch 6, gen_loss = 0.40381549061354943, disc_loss = 0.06319228397934872
Trained batch 295 in epoch 6, gen_loss = 0.40391974825714083, disc_loss = 0.06299984969538511
Trained batch 296 in epoch 6, gen_loss = 0.40408296787778936, disc_loss = 0.06285788970826953
Trained batch 297 in epoch 6, gen_loss = 0.40430370473221644, disc_loss = 0.06279678291784938
Trained batch 298 in epoch 6, gen_loss = 0.40404145873111225, disc_loss = 0.06282714015826035
Trained batch 299 in epoch 6, gen_loss = 0.4041743103663127, disc_loss = 0.06303941902083655
Trained batch 300 in epoch 6, gen_loss = 0.40393190397772677, disc_loss = 0.06303024278687579
Trained batch 301 in epoch 6, gen_loss = 0.4038733881435647, disc_loss = 0.06296564531605074
Trained batch 302 in epoch 6, gen_loss = 0.40399094501344285, disc_loss = 0.06279044882655635
Trained batch 303 in epoch 6, gen_loss = 0.40391363987797185, disc_loss = 0.06265652170220978
Trained batch 304 in epoch 6, gen_loss = 0.40396791549979666, disc_loss = 0.0625828902649342
Trained batch 305 in epoch 6, gen_loss = 0.40422604958605923, disc_loss = 0.06251782149965175
Trained batch 306 in epoch 6, gen_loss = 0.40432906548829345, disc_loss = 0.06235056740295518
Trained batch 307 in epoch 6, gen_loss = 0.4042046782258269, disc_loss = 0.06218075843273916
Trained batch 308 in epoch 6, gen_loss = 0.4040376380037721, disc_loss = 0.06207744139743951
Trained batch 309 in epoch 6, gen_loss = 0.40418855336404613, disc_loss = 0.06204326344173281
Trained batch 310 in epoch 6, gen_loss = 0.4041920276508454, disc_loss = 0.061964071954681364
Trained batch 311 in epoch 6, gen_loss = 0.40432464274076313, disc_loss = 0.062025045190985575
Trained batch 312 in epoch 6, gen_loss = 0.40426998206982595, disc_loss = 0.061887815312003366
Trained batch 313 in epoch 6, gen_loss = 0.4042762007303299, disc_loss = 0.06172847264938673
Trained batch 314 in epoch 6, gen_loss = 0.40423560133056036, disc_loss = 0.06184847308766274
Trained batch 315 in epoch 6, gen_loss = 0.4045281839333003, disc_loss = 0.061943899286038516
Trained batch 316 in epoch 6, gen_loss = 0.40458817192432633, disc_loss = 0.06192079260475252
Trained batch 317 in epoch 6, gen_loss = 0.4045423855946499, disc_loss = 0.0618554645059806
Trained batch 318 in epoch 6, gen_loss = 0.40441719276778004, disc_loss = 0.061748965313442074
Trained batch 319 in epoch 6, gen_loss = 0.4046826277859509, disc_loss = 0.06165848606033251
Trained batch 320 in epoch 6, gen_loss = 0.4045237925750816, disc_loss = 0.06150580680641894
Trained batch 321 in epoch 6, gen_loss = 0.4046273477699446, disc_loss = 0.06152450316730216
Trained batch 322 in epoch 6, gen_loss = 0.40454719679274426, disc_loss = 0.06207259710093862
Trained batch 323 in epoch 6, gen_loss = 0.40462358111952557, disc_loss = 0.06192566637800616
Trained batch 324 in epoch 6, gen_loss = 0.40425707661188565, disc_loss = 0.062343463616875504
Trained batch 325 in epoch 6, gen_loss = 0.4043189222278771, disc_loss = 0.062294457056359644
Trained batch 326 in epoch 6, gen_loss = 0.4045313584877446, disc_loss = 0.06228552507492927
Trained batch 327 in epoch 6, gen_loss = 0.4045628037576268, disc_loss = 0.062150150293302606
Trained batch 328 in epoch 6, gen_loss = 0.404676616191864, disc_loss = 0.06199879718995384
Trained batch 329 in epoch 6, gen_loss = 0.4047360934091337, disc_loss = 0.06183811631900343
Trained batch 330 in epoch 6, gen_loss = 0.4047506385879574, disc_loss = 0.06167062266738213
Trained batch 331 in epoch 6, gen_loss = 0.4046847090484148, disc_loss = 0.0614979237020689
Trained batch 332 in epoch 6, gen_loss = 0.40474761015660055, disc_loss = 0.06133072505853287
Trained batch 333 in epoch 6, gen_loss = 0.40470504189679724, disc_loss = 0.06120397681147306
Trained batch 334 in epoch 6, gen_loss = 0.40468637694173787, disc_loss = 0.06106826663851293
Trained batch 335 in epoch 6, gen_loss = 0.40477738582662176, disc_loss = 0.06105193635171634
Trained batch 336 in epoch 6, gen_loss = 0.4044689569699658, disc_loss = 0.061450591844227444
Trained batch 337 in epoch 6, gen_loss = 0.40484159779266493, disc_loss = 0.06289579112843208
Trained batch 338 in epoch 6, gen_loss = 0.40470235792584824, disc_loss = 0.06315261795622322
Trained batch 339 in epoch 6, gen_loss = 0.4045968401081422, disc_loss = 0.06322844718473361
Trained batch 340 in epoch 6, gen_loss = 0.4045301621610468, disc_loss = 0.0632549475119217
Trained batch 341 in epoch 6, gen_loss = 0.4046136426646807, disc_loss = 0.06314760433749585
Trained batch 342 in epoch 6, gen_loss = 0.40480945591676337, disc_loss = 0.06301651544510536
Trained batch 343 in epoch 6, gen_loss = 0.40488240581958795, disc_loss = 0.06290649960824657
Trained batch 344 in epoch 6, gen_loss = 0.40481737342433655, disc_loss = 0.06290575939945985
Trained batch 345 in epoch 6, gen_loss = 0.4047240440900615, disc_loss = 0.0627939889202099
Trained batch 346 in epoch 6, gen_loss = 0.4047295110198194, disc_loss = 0.06269957131359952
Trained batch 347 in epoch 6, gen_loss = 0.40451593859784907, disc_loss = 0.06258524010953462
Trained batch 348 in epoch 6, gen_loss = 0.40455370082554637, disc_loss = 0.06273628533003921
Trained batch 349 in epoch 6, gen_loss = 0.4043825340270996, disc_loss = 0.0638386814588947
Trained batch 350 in epoch 6, gen_loss = 0.40431467726020054, disc_loss = 0.06378815215654098
Trained batch 351 in epoch 6, gen_loss = 0.40435868908058514, disc_loss = 0.06416489485259676
Trained batch 352 in epoch 6, gen_loss = 0.40416733595534693, disc_loss = 0.06441493797519643
Trained batch 353 in epoch 6, gen_loss = 0.4040670609575207, disc_loss = 0.06429191577474529
Trained batch 354 in epoch 6, gen_loss = 0.4040732727084361, disc_loss = 0.06423092037177001
Trained batch 355 in epoch 6, gen_loss = 0.40403934852795653, disc_loss = 0.06425024003700845
Trained batch 356 in epoch 6, gen_loss = 0.4040657240970462, disc_loss = 0.0641996803294335
Trained batch 357 in epoch 6, gen_loss = 0.4041738424387724, disc_loss = 0.06403797689835702
Trained batch 358 in epoch 6, gen_loss = 0.4040951611769897, disc_loss = 0.06393088211764615
Trained batch 359 in epoch 6, gen_loss = 0.4040769122540951, disc_loss = 0.06377005711482424
Trained batch 360 in epoch 6, gen_loss = 0.40415645933547506, disc_loss = 0.0636639728396615
Trained batch 361 in epoch 6, gen_loss = 0.40406133835486946, disc_loss = 0.0635427654764579
Trained batch 362 in epoch 6, gen_loss = 0.40410829559173794, disc_loss = 0.06348834073776508
Trained batch 363 in epoch 6, gen_loss = 0.40390556223772384, disc_loss = 0.06352762587158685
Trained batch 364 in epoch 6, gen_loss = 0.40386906266212463, disc_loss = 0.06338064437476944
Trained batch 365 in epoch 6, gen_loss = 0.40395551626799536, disc_loss = 0.06325348486609839
Trained batch 366 in epoch 6, gen_loss = 0.40400130831578124, disc_loss = 0.06309465482470653
Trained batch 367 in epoch 6, gen_loss = 0.40415204786088155, disc_loss = 0.06296971555844799
Trained batch 368 in epoch 6, gen_loss = 0.40423606921663774, disc_loss = 0.06284097965357467
Trained batch 369 in epoch 6, gen_loss = 0.40393655743147877, disc_loss = 0.06277958054624096
Trained batch 370 in epoch 6, gen_loss = 0.4039690182054782, disc_loss = 0.06333256455268861
Trained batch 371 in epoch 6, gen_loss = 0.403417265783715, disc_loss = 0.06384825174351252
Trained batch 372 in epoch 6, gen_loss = 0.4033500105542088, disc_loss = 0.06375948822215678
Trained batch 373 in epoch 6, gen_loss = 0.40332157033331256, disc_loss = 0.06372119714555774
Trained batch 374 in epoch 6, gen_loss = 0.40334552264213563, disc_loss = 0.06364724431559443
Trained batch 375 in epoch 6, gen_loss = 0.4034032417421645, disc_loss = 0.06351774093878278
Trained batch 376 in epoch 6, gen_loss = 0.40329743664840173, disc_loss = 0.06344286564969771
Trained batch 377 in epoch 6, gen_loss = 0.4032327790581991, disc_loss = 0.06342724750247149
Trained batch 378 in epoch 6, gen_loss = 0.4032010226105008, disc_loss = 0.0633526761146228
Trained batch 379 in epoch 6, gen_loss = 0.4030519749773176, disc_loss = 0.06355403671653843
Trained batch 380 in epoch 6, gen_loss = 0.4027570591667506, disc_loss = 0.06450651513823256
Trained batch 381 in epoch 6, gen_loss = 0.40295709973854543, disc_loss = 0.06448163236588902
Trained batch 382 in epoch 6, gen_loss = 0.4032114731736345, disc_loss = 0.06459828604416382
Trained batch 383 in epoch 6, gen_loss = 0.4034183962115397, disc_loss = 0.06450547596735608
Trained batch 384 in epoch 6, gen_loss = 0.40340733233984416, disc_loss = 0.06451068724348367
Trained batch 385 in epoch 6, gen_loss = 0.40343579472346625, disc_loss = 0.06438588525815216
Trained batch 386 in epoch 6, gen_loss = 0.4036108430965926, disc_loss = 0.06423547648215902
Trained batch 387 in epoch 6, gen_loss = 0.40361254931110696, disc_loss = 0.06420126440094727
Trained batch 388 in epoch 6, gen_loss = 0.4036796020205039, disc_loss = 0.06415868034241554
Trained batch 389 in epoch 6, gen_loss = 0.40340179449472674, disc_loss = 0.06409732977238794
Trained batch 390 in epoch 6, gen_loss = 0.40337846506282193, disc_loss = 0.06406412583173197
Trained batch 391 in epoch 6, gen_loss = 0.40348852585468975, disc_loss = 0.06406566415965671
Trained batch 392 in epoch 6, gen_loss = 0.4033538948640265, disc_loss = 0.06410193700063736
Trained batch 393 in epoch 6, gen_loss = 0.40359299663964865, disc_loss = 0.06416851436118902
Trained batch 394 in epoch 6, gen_loss = 0.40359949816631363, disc_loss = 0.06402908757069631
Trained batch 395 in epoch 6, gen_loss = 0.40354538573460147, disc_loss = 0.06403636557139418
Trained batch 396 in epoch 6, gen_loss = 0.4036089416114749, disc_loss = 0.06396153205255005
Trained batch 397 in epoch 6, gen_loss = 0.40369019818365875, disc_loss = 0.06381390275241779
Trained batch 398 in epoch 6, gen_loss = 0.40377281968456163, disc_loss = 0.0636667080975154
Trained batch 399 in epoch 6, gen_loss = 0.40392908290028573, disc_loss = 0.06356654942734168
Trained batch 400 in epoch 6, gen_loss = 0.4040114362340913, disc_loss = 0.06344953442034207
Trained batch 401 in epoch 6, gen_loss = 0.4039968897157641, disc_loss = 0.06331881251306602
Trained batch 402 in epoch 6, gen_loss = 0.4040914643047465, disc_loss = 0.06324872835573946
Trained batch 403 in epoch 6, gen_loss = 0.4040511290330698, disc_loss = 0.06314662131849713
Trained batch 404 in epoch 6, gen_loss = 0.4040597176846163, disc_loss = 0.06301069403826087
Trained batch 405 in epoch 6, gen_loss = 0.4038675505245848, disc_loss = 0.06289787666890495
Trained batch 406 in epoch 6, gen_loss = 0.4040014834603162, disc_loss = 0.06280654301084304
Trained batch 407 in epoch 6, gen_loss = 0.4038047496886814, disc_loss = 0.06273738687684503
Trained batch 408 in epoch 6, gen_loss = 0.40389993393333734, disc_loss = 0.06260831659536781
Trained batch 409 in epoch 6, gen_loss = 0.4039209024935234, disc_loss = 0.062480949192512326
Trained batch 410 in epoch 6, gen_loss = 0.4040206509059943, disc_loss = 0.062386027095417906
Trained batch 411 in epoch 6, gen_loss = 0.4039509357179253, disc_loss = 0.06231175364420107
Trained batch 412 in epoch 6, gen_loss = 0.4039255750092698, disc_loss = 0.06222104568476394
Trained batch 413 in epoch 6, gen_loss = 0.40412039817243384, disc_loss = 0.062134399177767516
Trained batch 414 in epoch 6, gen_loss = 0.40425034107932123, disc_loss = 0.062084337382251956
Trained batch 415 in epoch 6, gen_loss = 0.4041489286061663, disc_loss = 0.062013126350043773
Trained batch 416 in epoch 6, gen_loss = 0.4041280584226695, disc_loss = 0.061902402366379755
Trained batch 417 in epoch 6, gen_loss = 0.4042061143086858, disc_loss = 0.06176838599608846
Trained batch 418 in epoch 6, gen_loss = 0.40414284151892105, disc_loss = 0.06164013322104916
Trained batch 419 in epoch 6, gen_loss = 0.4041556041865122, disc_loss = 0.06153358257198263
Trained batch 420 in epoch 6, gen_loss = 0.40398291482495013, disc_loss = 0.06142586429610034
Trained batch 421 in epoch 6, gen_loss = 0.4039441446698672, disc_loss = 0.06133927494261008
Trained batch 422 in epoch 6, gen_loss = 0.4040315901556759, disc_loss = 0.06128265641973162
Trained batch 423 in epoch 6, gen_loss = 0.40411992722524787, disc_loss = 0.06115084831857667
Trained batch 424 in epoch 6, gen_loss = 0.404167815657223, disc_loss = 0.06102763740236268
Trained batch 425 in epoch 6, gen_loss = 0.40416335898665756, disc_loss = 0.06089641780596874
Trained batch 426 in epoch 6, gen_loss = 0.4043711573932433, disc_loss = 0.06077801808932975
Trained batch 427 in epoch 6, gen_loss = 0.4044807128538595, disc_loss = 0.060754765166735676
Trained batch 428 in epoch 6, gen_loss = 0.404514871624522, disc_loss = 0.06084354947123564
Trained batch 429 in epoch 6, gen_loss = 0.404369454051173, disc_loss = 0.0608097619550346
Trained batch 430 in epoch 6, gen_loss = 0.40430753662525365, disc_loss = 0.06068224731072126
Trained batch 431 in epoch 6, gen_loss = 0.4043506909575727, disc_loss = 0.0605586441880506
Trained batch 432 in epoch 6, gen_loss = 0.4043943992800856, disc_loss = 0.060445797098391874
Trained batch 433 in epoch 6, gen_loss = 0.4043872642764298, disc_loss = 0.060396507910285405
Trained batch 434 in epoch 6, gen_loss = 0.40426309005967503, disc_loss = 0.06062999160039699
Trained batch 435 in epoch 6, gen_loss = 0.4042143512072913, disc_loss = 0.06074193374194
Trained batch 436 in epoch 6, gen_loss = 0.40410219020374305, disc_loss = 0.06078426529242054
Trained batch 437 in epoch 6, gen_loss = 0.40419455274054994, disc_loss = 0.060839655290285476
Trained batch 438 in epoch 6, gen_loss = 0.40417461317872677, disc_loss = 0.06101225703055196
Trained batch 439 in epoch 6, gen_loss = 0.4042581474239176, disc_loss = 0.060914019512181936
Trained batch 440 in epoch 6, gen_loss = 0.4042733722533228, disc_loss = 0.0610097628466937
Trained batch 441 in epoch 6, gen_loss = 0.4041869562136102, disc_loss = 0.06103855223137868
Trained batch 442 in epoch 6, gen_loss = 0.40389328858653256, disc_loss = 0.06110995165314147
Trained batch 443 in epoch 6, gen_loss = 0.40383497806819707, disc_loss = 0.06145758314377016
Trained batch 444 in epoch 6, gen_loss = 0.4036190775003326, disc_loss = 0.06135759646219484
Trained batch 445 in epoch 6, gen_loss = 0.4036785801162634, disc_loss = 0.061486663735333846
Trained batch 446 in epoch 6, gen_loss = 0.4038997540537943, disc_loss = 0.06162862830964111
Trained batch 447 in epoch 6, gen_loss = 0.4040139806456864, disc_loss = 0.06151523263127144
Trained batch 448 in epoch 6, gen_loss = 0.40396094614254074, disc_loss = 0.061570186292408305
Trained batch 449 in epoch 6, gen_loss = 0.40404343532191384, disc_loss = 0.06144863687766095
Trained batch 450 in epoch 6, gen_loss = 0.4040899977187095, disc_loss = 0.06140278293307202
Trained batch 451 in epoch 6, gen_loss = 0.40401827313203725, disc_loss = 0.06136410048260329
Trained batch 452 in epoch 6, gen_loss = 0.4040757016367207, disc_loss = 0.06124763415558942
Trained batch 453 in epoch 6, gen_loss = 0.4038864819226286, disc_loss = 0.0611757846243499
Trained batch 454 in epoch 6, gen_loss = 0.40393762608150857, disc_loss = 0.06110392677812622
Trained batch 455 in epoch 6, gen_loss = 0.40397012116093384, disc_loss = 0.06099104764973418
Trained batch 456 in epoch 6, gen_loss = 0.40386378393392336, disc_loss = 0.060912522205092516
Trained batch 457 in epoch 6, gen_loss = 0.4037100042838717, disc_loss = 0.060906933898138754
Trained batch 458 in epoch 6, gen_loss = 0.4039646914322132, disc_loss = 0.06173659162392966
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 0.4382289946079254, disc_loss = 0.019852083176374435
Trained batch 1 in epoch 7, gen_loss = 0.38881243765354156, disc_loss = 0.043251970782876015
Trained batch 2 in epoch 7, gen_loss = 0.40249169866244, disc_loss = 0.04275389884908994
Trained batch 3 in epoch 7, gen_loss = 0.3939649909734726, disc_loss = 0.08627043198794127
Trained batch 4 in epoch 7, gen_loss = 0.3860208034515381, disc_loss = 0.1024621568620205
Trained batch 5 in epoch 7, gen_loss = 0.3809860944747925, disc_loss = 0.08709932739535968
Trained batch 6 in epoch 7, gen_loss = 0.3834829713617052, disc_loss = 0.09436830771820885
Trained batch 7 in epoch 7, gen_loss = 0.3744795694947243, disc_loss = 0.09029103256762028
Trained batch 8 in epoch 7, gen_loss = 0.37153981460465324, disc_loss = 0.0813251460591952
Trained batch 9 in epoch 7, gen_loss = 0.3686788469552994, disc_loss = 0.07372229439206421
Trained batch 10 in epoch 7, gen_loss = 0.3729452301155437, disc_loss = 0.0682548307813704
Trained batch 11 in epoch 7, gen_loss = 0.37850076456864673, disc_loss = 0.0652240172882254
Trained batch 12 in epoch 7, gen_loss = 0.38024519040034366, disc_loss = 0.06273029855667399
Trained batch 13 in epoch 7, gen_loss = 0.37807624467781614, disc_loss = 0.06366049814304071
Trained batch 14 in epoch 7, gen_loss = 0.381023778518041, disc_loss = 0.06143504825110237
Trained batch 15 in epoch 7, gen_loss = 0.3826695214956999, disc_loss = 0.05798606522148475
Trained batch 16 in epoch 7, gen_loss = 0.3833150285131791, disc_loss = 0.05604610575691742
Trained batch 17 in epoch 7, gen_loss = 0.38558224505848354, disc_loss = 0.05391173338931468
Trained batch 18 in epoch 7, gen_loss = 0.3843333815273486, disc_loss = 0.052463845251814314
Trained batch 19 in epoch 7, gen_loss = 0.3879870980978012, disc_loss = 0.050246419943869115
Trained batch 20 in epoch 7, gen_loss = 0.39022518339611234, disc_loss = 0.04821512284910395
Trained batch 21 in epoch 7, gen_loss = 0.3873934881253676, disc_loss = 0.04669531870802695
Trained batch 22 in epoch 7, gen_loss = 0.38565663928570953, disc_loss = 0.04510452063835185
Trained batch 23 in epoch 7, gen_loss = 0.38456691180666286, disc_loss = 0.04381490219384432
Trained batch 24 in epoch 7, gen_loss = 0.3871293294429779, disc_loss = 0.04240463256835938
Trained batch 25 in epoch 7, gen_loss = 0.38764046361813176, disc_loss = 0.04112018211386525
Trained batch 26 in epoch 7, gen_loss = 0.3887299519998056, disc_loss = 0.0399460447607217
Trained batch 27 in epoch 7, gen_loss = 0.39084797884736744, disc_loss = 0.03925280026825411
Trained batch 28 in epoch 7, gen_loss = 0.39303114290895136, disc_loss = 0.03843787482714858
Trained batch 29 in epoch 7, gen_loss = 0.39343897898991903, disc_loss = 0.03761923046161731
Trained batch 30 in epoch 7, gen_loss = 0.3941756131187562, disc_loss = 0.036946033217733903
Trained batch 31 in epoch 7, gen_loss = 0.39170088060200214, disc_loss = 0.03988122980808839
Trained batch 32 in epoch 7, gen_loss = 0.3954695661862691, disc_loss = 0.04202920486303893
Trained batch 33 in epoch 7, gen_loss = 0.3950680196285248, disc_loss = 0.041021261487484854
Trained batch 34 in epoch 7, gen_loss = 0.394244738136019, disc_loss = 0.04187010240608028
Trained batch 35 in epoch 7, gen_loss = 0.3962923710544904, disc_loss = 0.041047800966124565
Trained batch 36 in epoch 7, gen_loss = 0.39762928920823176, disc_loss = 0.040650649914971075
Trained batch 37 in epoch 7, gen_loss = 0.3965790758007451, disc_loss = 0.04010354914996577
Trained batch 38 in epoch 7, gen_loss = 0.3952394471718715, disc_loss = 0.03947205097677234
Trained batch 39 in epoch 7, gen_loss = 0.39740863293409345, disc_loss = 0.03991349042626098
Trained batch 40 in epoch 7, gen_loss = 0.3966489048992715, disc_loss = 0.043209504801779985
Trained batch 41 in epoch 7, gen_loss = 0.3944695073933828, disc_loss = 0.05208890424996969
Trained batch 42 in epoch 7, gen_loss = 0.3936819912389267, disc_loss = 0.053357370728410264
Trained batch 43 in epoch 7, gen_loss = 0.3935213766314767, disc_loss = 0.054088041874241426
Trained batch 44 in epoch 7, gen_loss = 0.39336151944266423, disc_loss = 0.05468659004610446
Trained batch 45 in epoch 7, gen_loss = 0.39410099581531854, disc_loss = 0.054206152335214225
Trained batch 46 in epoch 7, gen_loss = 0.3951330844392168, disc_loss = 0.05351521345251735
Trained batch 47 in epoch 7, gen_loss = 0.39584430617590743, disc_loss = 0.05324154115320804
Trained batch 48 in epoch 7, gen_loss = 0.39876772737016486, disc_loss = 0.053942463237184046
Trained batch 49 in epoch 7, gen_loss = 0.3988552510738373, disc_loss = 0.06203100265003741
Trained batch 50 in epoch 7, gen_loss = 0.3988390956439224, disc_loss = 0.062424840012967005
Trained batch 51 in epoch 7, gen_loss = 0.4010329538813004, disc_loss = 0.06346510738456765
Trained batch 52 in epoch 7, gen_loss = 0.40130039374783355, disc_loss = 0.06295882995714838
Trained batch 53 in epoch 7, gen_loss = 0.4025139483036818, disc_loss = 0.062036787892726285
Trained batch 54 in epoch 7, gen_loss = 0.40379495241425256, disc_loss = 0.06138147641481324
Trained batch 55 in epoch 7, gen_loss = 0.4043370096811226, disc_loss = 0.062144370325508395
Trained batch 56 in epoch 7, gen_loss = 0.40478898140422087, disc_loss = 0.06645956253959683
Trained batch 57 in epoch 7, gen_loss = 0.40488966837011536, disc_loss = 0.06633133336034572
Trained batch 58 in epoch 7, gen_loss = 0.4052956675068807, disc_loss = 0.06584585247308773
Trained batch 59 in epoch 7, gen_loss = 0.4045641914010048, disc_loss = 0.06490801716378579
Trained batch 60 in epoch 7, gen_loss = 0.40450548637108724, disc_loss = 0.06427555431260681
Trained batch 61 in epoch 7, gen_loss = 0.4055182140681051, disc_loss = 0.06349125832709815
Trained batch 62 in epoch 7, gen_loss = 0.4049670880749112, disc_loss = 0.06342983078063717
Trained batch 63 in epoch 7, gen_loss = 0.40549915190786123, disc_loss = 0.06498427197948331
Trained batch 64 in epoch 7, gen_loss = 0.4036109617123237, disc_loss = 0.06921139334400113
Trained batch 65 in epoch 7, gen_loss = 0.4026819241769386, disc_loss = 0.06890402557187233
Trained batch 66 in epoch 7, gen_loss = 0.4048765043714153, disc_loss = 0.07101311660441223
Trained batch 67 in epoch 7, gen_loss = 0.404698240406373, disc_loss = 0.07127508020494133
Trained batch 68 in epoch 7, gen_loss = 0.4047655618709067, disc_loss = 0.07073666482650931
Trained batch 69 in epoch 7, gen_loss = 0.4056382728474481, disc_loss = 0.07049417328754706
Trained batch 70 in epoch 7, gen_loss = 0.40503439768938954, disc_loss = 0.06999468166564762
Trained batch 71 in epoch 7, gen_loss = 0.404101151559088, disc_loss = 0.06983185117779714
Trained batch 72 in epoch 7, gen_loss = 0.4044065720414462, disc_loss = 0.070094233946492
Trained batch 73 in epoch 7, gen_loss = 0.4034691134820113, disc_loss = 0.06996502030666012
Trained batch 74 in epoch 7, gen_loss = 0.4035324724515279, disc_loss = 0.06920209838077426
Trained batch 75 in epoch 7, gen_loss = 0.4039797535852382, disc_loss = 0.06839059310426053
Trained batch 76 in epoch 7, gen_loss = 0.40435578374119546, disc_loss = 0.06767178588099294
Trained batch 77 in epoch 7, gen_loss = 0.40481150914461184, disc_loss = 0.0668785356474706
Trained batch 78 in epoch 7, gen_loss = 0.40463817647740813, disc_loss = 0.06644699117168784
Trained batch 79 in epoch 7, gen_loss = 0.40527201592922213, disc_loss = 0.06695660667610355
Trained batch 80 in epoch 7, gen_loss = 0.4041164756557088, disc_loss = 0.06815100542304141
Trained batch 81 in epoch 7, gen_loss = 0.4042307280185746, disc_loss = 0.06905815494246781
Trained batch 82 in epoch 7, gen_loss = 0.4042274373841573, disc_loss = 0.06833797222541937
Trained batch 83 in epoch 7, gen_loss = 0.40425385321889606, disc_loss = 0.06775397652693625
Trained batch 84 in epoch 7, gen_loss = 0.4044500617419972, disc_loss = 0.06737567721592153
Trained batch 85 in epoch 7, gen_loss = 0.4043389569188273, disc_loss = 0.06688788386473302
Trained batch 86 in epoch 7, gen_loss = 0.4030591006251587, disc_loss = 0.06677884771756229
Trained batch 87 in epoch 7, gen_loss = 0.40416743978857994, disc_loss = 0.06690638377437029
Trained batch 88 in epoch 7, gen_loss = 0.40325753441017664, disc_loss = 0.0667184453635487
Trained batch 89 in epoch 7, gen_loss = 0.4039201955000559, disc_loss = 0.06616860537582801
Trained batch 90 in epoch 7, gen_loss = 0.4037745902826498, disc_loss = 0.0658513863141147
Trained batch 91 in epoch 7, gen_loss = 0.4031849817737289, disc_loss = 0.06625857046785076
Trained batch 92 in epoch 7, gen_loss = 0.40428292783357767, disc_loss = 0.06682833785351405
Trained batch 93 in epoch 7, gen_loss = 0.4038711722860945, disc_loss = 0.06625035875278742
Trained batch 94 in epoch 7, gen_loss = 0.40327992596124346, disc_loss = 0.06601298559751166
Trained batch 95 in epoch 7, gen_loss = 0.4028515073781212, disc_loss = 0.06561043096492843
Trained batch 96 in epoch 7, gen_loss = 0.40270208820854264, disc_loss = 0.0650433803543679
Trained batch 97 in epoch 7, gen_loss = 0.403289260304704, disc_loss = 0.06452977560859706
Trained batch 98 in epoch 7, gen_loss = 0.40370370763720886, disc_loss = 0.06400546475285382
Trained batch 99 in epoch 7, gen_loss = 0.40316280603408816, disc_loss = 0.06400775125715881
Trained batch 100 in epoch 7, gen_loss = 0.4043606720348396, disc_loss = 0.06366294337030833
Trained batch 101 in epoch 7, gen_loss = 0.4050389969465779, disc_loss = 0.06378293499880124
Trained batch 102 in epoch 7, gen_loss = 0.4045186586750364, disc_loss = 0.06421397599726192
Trained batch 103 in epoch 7, gen_loss = 0.4049307709703079, disc_loss = 0.06406969987661935
Trained batch 104 in epoch 7, gen_loss = 0.40581292992546447, disc_loss = 0.06353172582707235
Trained batch 105 in epoch 7, gen_loss = 0.4062836209558091, disc_loss = 0.06302556699528447
Trained batch 106 in epoch 7, gen_loss = 0.40658662809389773, disc_loss = 0.06250817933615958
Trained batch 107 in epoch 7, gen_loss = 0.4070087577457781, disc_loss = 0.061980217333055206
Trained batch 108 in epoch 7, gen_loss = 0.407423610534143, disc_loss = 0.061490552260651504
Trained batch 109 in epoch 7, gen_loss = 0.4070508577606895, disc_loss = 0.061049899577417154
Trained batch 110 in epoch 7, gen_loss = 0.40675685373512477, disc_loss = 0.06062994028131167
Trained batch 111 in epoch 7, gen_loss = 0.40656932682863306, disc_loss = 0.06056332488411239
Trained batch 112 in epoch 7, gen_loss = 0.40629949427283973, disc_loss = 0.061498044800441874
Trained batch 113 in epoch 7, gen_loss = 0.4063575103094703, disc_loss = 0.06309601697221137
Trained batch 114 in epoch 7, gen_loss = 0.4069380573604418, disc_loss = 0.06289134346272635
Trained batch 115 in epoch 7, gen_loss = 0.40641647320369195, disc_loss = 0.06301237588170273
Trained batch 116 in epoch 7, gen_loss = 0.40656883874510086, disc_loss = 0.06271540340131675
Trained batch 117 in epoch 7, gen_loss = 0.40583171632330295, disc_loss = 0.06420546894798339
Trained batch 118 in epoch 7, gen_loss = 0.4062367792890853, disc_loss = 0.0657046359470662
Trained batch 119 in epoch 7, gen_loss = 0.4062472522258759, disc_loss = 0.0658752792670081
Trained batch 120 in epoch 7, gen_loss = 0.406498570826428, disc_loss = 0.06547448437753295
Trained batch 121 in epoch 7, gen_loss = 0.40703527507234794, disc_loss = 0.06520055831394724
Trained batch 122 in epoch 7, gen_loss = 0.4079896608988444, disc_loss = 0.06511515480413185
Trained batch 123 in epoch 7, gen_loss = 0.40776427426645834, disc_loss = 0.06493819894028767
Trained batch 124 in epoch 7, gen_loss = 0.4076785662174225, disc_loss = 0.06468541692197323
Trained batch 125 in epoch 7, gen_loss = 0.4071545000114138, disc_loss = 0.06430603222300608
Trained batch 126 in epoch 7, gen_loss = 0.40681380596686534, disc_loss = 0.06433091484244884
Trained batch 127 in epoch 7, gen_loss = 0.4061431074514985, disc_loss = 0.06503475773206446
Trained batch 128 in epoch 7, gen_loss = 0.4065260432025259, disc_loss = 0.06482606324865374
Trained batch 129 in epoch 7, gen_loss = 0.407099430836164, disc_loss = 0.06499625612050294
Trained batch 130 in epoch 7, gen_loss = 0.40701409628373064, disc_loss = 0.06460449378937483
Trained batch 131 in epoch 7, gen_loss = 0.40644608415437466, disc_loss = 0.0647522648584775
Trained batch 132 in epoch 7, gen_loss = 0.4059011207935505, disc_loss = 0.06442809403922997
Trained batch 133 in epoch 7, gen_loss = 0.4062043728668298, disc_loss = 0.06434046740490776
Trained batch 134 in epoch 7, gen_loss = 0.4061057971583472, disc_loss = 0.0643789289933112
Trained batch 135 in epoch 7, gen_loss = 0.40586655521217513, disc_loss = 0.06428905277211658
Trained batch 136 in epoch 7, gen_loss = 0.405734119624117, disc_loss = 0.06481299399105954
Trained batch 137 in epoch 7, gen_loss = 0.4056795725355978, disc_loss = 0.06461927075397925
Trained batch 138 in epoch 7, gen_loss = 0.40582078716737763, disc_loss = 0.06423846019177343
Trained batch 139 in epoch 7, gen_loss = 0.40567600131034853, disc_loss = 0.06389863209665886
Trained batch 140 in epoch 7, gen_loss = 0.4058241070585048, disc_loss = 0.06361367629431453
Trained batch 141 in epoch 7, gen_loss = 0.4057296189204068, disc_loss = 0.06328934931497969
Trained batch 142 in epoch 7, gen_loss = 0.4059274517572843, disc_loss = 0.06328317884459987
Trained batch 143 in epoch 7, gen_loss = 0.4057334437966347, disc_loss = 0.06303762660698137
Trained batch 144 in epoch 7, gen_loss = 0.40564920367865726, disc_loss = 0.0626933444612499
Trained batch 145 in epoch 7, gen_loss = 0.4049452222781639, disc_loss = 0.06268946532389685
Trained batch 146 in epoch 7, gen_loss = 0.40581323885593285, disc_loss = 0.06234021866884159
Trained batch 147 in epoch 7, gen_loss = 0.40583667904138565, disc_loss = 0.06198577924530853
Trained batch 148 in epoch 7, gen_loss = 0.4062115812061617, disc_loss = 0.06167472625813828
Trained batch 149 in epoch 7, gen_loss = 0.4057323322693507, disc_loss = 0.06148296541844805
Trained batch 150 in epoch 7, gen_loss = 0.4058949507230165, disc_loss = 0.06140290755186452
Trained batch 151 in epoch 7, gen_loss = 0.40613528733190735, disc_loss = 0.06109306336944237
Trained batch 152 in epoch 7, gen_loss = 0.4058409263105953, disc_loss = 0.06087549564617327
Trained batch 153 in epoch 7, gen_loss = 0.40667907719488267, disc_loss = 0.06224291179595249
Trained batch 154 in epoch 7, gen_loss = 0.40641534347687996, disc_loss = 0.06303340886989908
Trained batch 155 in epoch 7, gen_loss = 0.406240745423696, disc_loss = 0.06292397770672463
Trained batch 156 in epoch 7, gen_loss = 0.4064992068299822, disc_loss = 0.06276750282805627
Trained batch 157 in epoch 7, gen_loss = 0.40608552003963083, disc_loss = 0.06243524904940513
Trained batch 158 in epoch 7, gen_loss = 0.4067385640909087, disc_loss = 0.06212022273256531
Trained batch 159 in epoch 7, gen_loss = 0.4064571887254715, disc_loss = 0.06189771119388752
Trained batch 160 in epoch 7, gen_loss = 0.4063066573616881, disc_loss = 0.06157546057163373
Trained batch 161 in epoch 7, gen_loss = 0.40628331347748087, disc_loss = 0.06156113103928941
Trained batch 162 in epoch 7, gen_loss = 0.40661394888637986, disc_loss = 0.06213623526980357
Trained batch 163 in epoch 7, gen_loss = 0.4064725497510375, disc_loss = 0.06303319593369053
Trained batch 164 in epoch 7, gen_loss = 0.4068381170431773, disc_loss = 0.06400192465181603
Trained batch 165 in epoch 7, gen_loss = 0.406584970383759, disc_loss = 0.06387338593759272
Trained batch 166 in epoch 7, gen_loss = 0.40666281641600377, disc_loss = 0.06357861084941618
Trained batch 167 in epoch 7, gen_loss = 0.40672778036622775, disc_loss = 0.0632767759684828
Trained batch 168 in epoch 7, gen_loss = 0.4065929899906971, disc_loss = 0.06301326142657085
Trained batch 169 in epoch 7, gen_loss = 0.40647554187213675, disc_loss = 0.06276962712187978
Trained batch 170 in epoch 7, gen_loss = 0.406569110371216, disc_loss = 0.06250660597450203
Trained batch 171 in epoch 7, gen_loss = 0.4068575428668843, disc_loss = 0.06229555668569235
Trained batch 172 in epoch 7, gen_loss = 0.4066721137203922, disc_loss = 0.06201717051855057
Trained batch 173 in epoch 7, gen_loss = 0.40613340749137705, disc_loss = 0.06202423539355226
Trained batch 174 in epoch 7, gen_loss = 0.4063213157653809, disc_loss = 0.06211519123188087
Trained batch 175 in epoch 7, gen_loss = 0.40605129589411343, disc_loss = 0.0625848797340454
Trained batch 176 in epoch 7, gen_loss = 0.40640977563831093, disc_loss = 0.06290618634367057
Trained batch 177 in epoch 7, gen_loss = 0.40636948889560914, disc_loss = 0.06298038904460963
Trained batch 178 in epoch 7, gen_loss = 0.40605767429207956, disc_loss = 0.06369984105187754
Trained batch 179 in epoch 7, gen_loss = 0.4057637645138635, disc_loss = 0.06343498579743835
Trained batch 180 in epoch 7, gen_loss = 0.4058327406480167, disc_loss = 0.06314594337706408
Trained batch 181 in epoch 7, gen_loss = 0.40607318380376795, disc_loss = 0.0628359400012254
Trained batch 182 in epoch 7, gen_loss = 0.40623648081972297, disc_loss = 0.0625346798062976
Trained batch 183 in epoch 7, gen_loss = 0.4062366530947063, disc_loss = 0.06221727255741944
Trained batch 184 in epoch 7, gen_loss = 0.40603781777459225, disc_loss = 0.061901312281151075
Trained batch 185 in epoch 7, gen_loss = 0.40600788737497023, disc_loss = 0.06162879991555406
Trained batch 186 in epoch 7, gen_loss = 0.40608243715954334, disc_loss = 0.061561281937249204
Trained batch 187 in epoch 7, gen_loss = 0.4057783839550424, disc_loss = 0.06137574330328944
Trained batch 188 in epoch 7, gen_loss = 0.40604455666567285, disc_loss = 0.061696239062166085
Trained batch 189 in epoch 7, gen_loss = 0.4063012785033176, disc_loss = 0.06200347700597424
Trained batch 190 in epoch 7, gen_loss = 0.4055834418816092, disc_loss = 0.06305441979065303
Trained batch 191 in epoch 7, gen_loss = 0.40582773244629305, disc_loss = 0.06412682450415257
Trained batch 192 in epoch 7, gen_loss = 0.40577401861625634, disc_loss = 0.06385667237496592
Trained batch 193 in epoch 7, gen_loss = 0.405655787163174, disc_loss = 0.06356370228237097
Trained batch 194 in epoch 7, gen_loss = 0.40527179745527414, disc_loss = 0.06329940312947982
Trained batch 195 in epoch 7, gen_loss = 0.405194562460695, disc_loss = 0.06308747683556712
Trained batch 196 in epoch 7, gen_loss = 0.40509575786929447, disc_loss = 0.06298292163513639
Trained batch 197 in epoch 7, gen_loss = 0.40491444956172595, disc_loss = 0.06289030551308333
Trained batch 198 in epoch 7, gen_loss = 0.4050402800042426, disc_loss = 0.06276721505438862
Trained batch 199 in epoch 7, gen_loss = 0.40492414131760596, disc_loss = 0.06264511451125145
Trained batch 200 in epoch 7, gen_loss = 0.4050727187104486, disc_loss = 0.0625057729396654
Trained batch 201 in epoch 7, gen_loss = 0.4050068045311635, disc_loss = 0.062327695973586325
Trained batch 202 in epoch 7, gen_loss = 0.4051105129014095, disc_loss = 0.062071774365940115
Trained batch 203 in epoch 7, gen_loss = 0.4049770114760773, disc_loss = 0.06192302828946827
Trained batch 204 in epoch 7, gen_loss = 0.40556252976743185, disc_loss = 0.06184194846669348
Trained batch 205 in epoch 7, gen_loss = 0.4061230107129199, disc_loss = 0.06162303599339087
Trained batch 206 in epoch 7, gen_loss = 0.4058318882460755, disc_loss = 0.061390562239440456
Trained batch 207 in epoch 7, gen_loss = 0.40562679518300754, disc_loss = 0.06114087535892255
Trained batch 208 in epoch 7, gen_loss = 0.4052363458717839, disc_loss = 0.061045697101494344
Trained batch 209 in epoch 7, gen_loss = 0.40538585909775326, disc_loss = 0.061275931864622095
Trained batch 210 in epoch 7, gen_loss = 0.40519783465783177, disc_loss = 0.06182616054835195
Trained batch 211 in epoch 7, gen_loss = 0.4058937746680008, disc_loss = 0.061802033255895915
Trained batch 212 in epoch 7, gen_loss = 0.4059353474999817, disc_loss = 0.06227709065265779
Trained batch 213 in epoch 7, gen_loss = 0.40630308086069944, disc_loss = 0.06206200612169281
Trained batch 214 in epoch 7, gen_loss = 0.4063215714554454, disc_loss = 0.06200208418764347
Trained batch 215 in epoch 7, gen_loss = 0.4063662748645853, disc_loss = 0.06222086735242219
Trained batch 216 in epoch 7, gen_loss = 0.40680268530472086, disc_loss = 0.06212037678996814
Trained batch 217 in epoch 7, gen_loss = 0.40701302298165243, disc_loss = 0.061885639820077006
Trained batch 218 in epoch 7, gen_loss = 0.40716224759136704, disc_loss = 0.06194623250123028
Trained batch 219 in epoch 7, gen_loss = 0.40651014067909935, disc_loss = 0.06187876452776519
Trained batch 220 in epoch 7, gen_loss = 0.4061962027625261, disc_loss = 0.06352555175307649
Trained batch 221 in epoch 7, gen_loss = 0.4064099528231062, disc_loss = 0.06426385504839656
Trained batch 222 in epoch 7, gen_loss = 0.4062719188730813, disc_loss = 0.06421341760409788
Trained batch 223 in epoch 7, gen_loss = 0.4061028582176992, disc_loss = 0.06469851436226495
Trained batch 224 in epoch 7, gen_loss = 0.40649967617458765, disc_loss = 0.06451169481707944
Trained batch 225 in epoch 7, gen_loss = 0.40644078695141106, disc_loss = 0.06444255446405274
Trained batch 226 in epoch 7, gen_loss = 0.40634780925276, disc_loss = 0.06425018671752335
Trained batch 227 in epoch 7, gen_loss = 0.4060098604674925, disc_loss = 0.06409416271765765
Trained batch 228 in epoch 7, gen_loss = 0.40608724053770173, disc_loss = 0.06395286771440349
Trained batch 229 in epoch 7, gen_loss = 0.40588017948295757, disc_loss = 0.06384742680289175
Trained batch 230 in epoch 7, gen_loss = 0.4061837327944768, disc_loss = 0.06390772404318507
Trained batch 231 in epoch 7, gen_loss = 0.406185076796803, disc_loss = 0.06407174428700116
Trained batch 232 in epoch 7, gen_loss = 0.4067556066318643, disc_loss = 0.06445636794514667
Trained batch 233 in epoch 7, gen_loss = 0.40658934006833625, disc_loss = 0.06438537189561842
Trained batch 234 in epoch 7, gen_loss = 0.406465182405837, disc_loss = 0.06486227841294827
Trained batch 235 in epoch 7, gen_loss = 0.4067117426607568, disc_loss = 0.06462363778787145
Trained batch 236 in epoch 7, gen_loss = 0.4071175580537772, disc_loss = 0.06463668919816802
Trained batch 237 in epoch 7, gen_loss = 0.40696957845146914, disc_loss = 0.06440271752565599
Trained batch 238 in epoch 7, gen_loss = 0.40715942223201734, disc_loss = 0.06415377988842429
Trained batch 239 in epoch 7, gen_loss = 0.40723792190353075, disc_loss = 0.06391401768584425
Trained batch 240 in epoch 7, gen_loss = 0.4072353582659203, disc_loss = 0.06367295488321002
Trained batch 241 in epoch 7, gen_loss = 0.4073908167683389, disc_loss = 0.06347568749742628
Trained batch 242 in epoch 7, gen_loss = 0.4072750615484921, disc_loss = 0.06323330942349731
Trained batch 243 in epoch 7, gen_loss = 0.40711673275857674, disc_loss = 0.06299691793287447
Trained batch 244 in epoch 7, gen_loss = 0.4066477836394797, disc_loss = 0.06279069400221414
Trained batch 245 in epoch 7, gen_loss = 0.40675654656034177, disc_loss = 0.06323492438229543
Trained batch 246 in epoch 7, gen_loss = 0.4065550235118943, disc_loss = 0.06468652214983153
Trained batch 247 in epoch 7, gen_loss = 0.4063509689463723, disc_loss = 0.06485841091864952
Trained batch 248 in epoch 7, gen_loss = 0.40652090418769654, disc_loss = 0.0648862563548647
Trained batch 249 in epoch 7, gen_loss = 0.4068946669101715, disc_loss = 0.06539463253878057
Trained batch 250 in epoch 7, gen_loss = 0.4068002236554347, disc_loss = 0.06585950937782567
Trained batch 251 in epoch 7, gen_loss = 0.40660885839708266, disc_loss = 0.06569031775847728
Trained batch 252 in epoch 7, gen_loss = 0.40681311900436645, disc_loss = 0.06570107686211882
Trained batch 253 in epoch 7, gen_loss = 0.4068989202262848, disc_loss = 0.06547923287648091
Trained batch 254 in epoch 7, gen_loss = 0.40684842490682416, disc_loss = 0.0653764629608714
Trained batch 255 in epoch 7, gen_loss = 0.4068451024359092, disc_loss = 0.06517846248789283
Trained batch 256 in epoch 7, gen_loss = 0.4066665915895529, disc_loss = 0.06513122648384842
Trained batch 257 in epoch 7, gen_loss = 0.4066152018170024, disc_loss = 0.06496144277621205
Trained batch 258 in epoch 7, gen_loss = 0.40638198435996953, disc_loss = 0.06513082208183799
Trained batch 259 in epoch 7, gen_loss = 0.40616515588301877, disc_loss = 0.06550822852071948
Trained batch 260 in epoch 7, gen_loss = 0.4061438892307866, disc_loss = 0.06535238303936361
Trained batch 261 in epoch 7, gen_loss = 0.4057457956648965, disc_loss = 0.06526555625174393
Trained batch 262 in epoch 7, gen_loss = 0.4058508871852672, disc_loss = 0.06541426288063139
Trained batch 263 in epoch 7, gen_loss = 0.40564616814707266, disc_loss = 0.06554168562411866
Trained batch 264 in epoch 7, gen_loss = 0.4061250036617495, disc_loss = 0.06538782463637444
Trained batch 265 in epoch 7, gen_loss = 0.4063695077609299, disc_loss = 0.06535268190694987
Trained batch 266 in epoch 7, gen_loss = 0.40633309534872963, disc_loss = 0.06521326580611564
Trained batch 267 in epoch 7, gen_loss = 0.40613799108498133, disc_loss = 0.06499649951088507
Trained batch 268 in epoch 7, gen_loss = 0.4057875430716901, disc_loss = 0.06482369145101498
Trained batch 269 in epoch 7, gen_loss = 0.40531929830710095, disc_loss = 0.06474605136275015
Trained batch 270 in epoch 7, gen_loss = 0.4052716642068321, disc_loss = 0.06465029721818452
Trained batch 271 in epoch 7, gen_loss = 0.40493126564166126, disc_loss = 0.0647958501444116
Trained batch 272 in epoch 7, gen_loss = 0.4052281345858242, disc_loss = 0.06470222380728675
Trained batch 273 in epoch 7, gen_loss = 0.4054107884638501, disc_loss = 0.06480924545678507
Trained batch 274 in epoch 7, gen_loss = 0.405416169274937, disc_loss = 0.06513823178512129
Trained batch 275 in epoch 7, gen_loss = 0.4061575342995533, disc_loss = 0.06501203336570736
Trained batch 276 in epoch 7, gen_loss = 0.40635760112359637, disc_loss = 0.06505136539998199
Trained batch 277 in epoch 7, gen_loss = 0.4065482388083026, disc_loss = 0.0648557973653748
Trained batch 278 in epoch 7, gen_loss = 0.40675796146461185, disc_loss = 0.06469594432361504
Trained batch 279 in epoch 7, gen_loss = 0.4066601274268968, disc_loss = 0.06450471400250016
Trained batch 280 in epoch 7, gen_loss = 0.4067414738105285, disc_loss = 0.06430182801029277
Trained batch 281 in epoch 7, gen_loss = 0.40681158524033023, disc_loss = 0.06409697523769917
Trained batch 282 in epoch 7, gen_loss = 0.40683915400252324, disc_loss = 0.06391969822880289
Trained batch 283 in epoch 7, gen_loss = 0.40679919688214716, disc_loss = 0.06372267956366684
Trained batch 284 in epoch 7, gen_loss = 0.4066610253693765, disc_loss = 0.06355354866470422
Trained batch 285 in epoch 7, gen_loss = 0.4064394897305882, disc_loss = 0.06336467275623936
Trained batch 286 in epoch 7, gen_loss = 0.4067225782298045, disc_loss = 0.06316900518252304
Trained batch 287 in epoch 7, gen_loss = 0.40673437093695003, disc_loss = 0.0631028693832276
Trained batch 288 in epoch 7, gen_loss = 0.4066188085862922, disc_loss = 0.06304777910043469
Trained batch 289 in epoch 7, gen_loss = 0.4066258013248444, disc_loss = 0.06292064810524983
Trained batch 290 in epoch 7, gen_loss = 0.40690039103383463, disc_loss = 0.06273940180130687
Trained batch 291 in epoch 7, gen_loss = 0.40701486241735824, disc_loss = 0.06256869788543155
Trained batch 292 in epoch 7, gen_loss = 0.40746765220124564, disc_loss = 0.06242299669679674
Trained batch 293 in epoch 7, gen_loss = 0.40733014939188145, disc_loss = 0.0623564862814054
Trained batch 294 in epoch 7, gen_loss = 0.40737197166782313, disc_loss = 0.062248324165594275
Trained batch 295 in epoch 7, gen_loss = 0.407564772846731, disc_loss = 0.06220372794416255
Trained batch 296 in epoch 7, gen_loss = 0.4071271736613829, disc_loss = 0.06256413628325268
Trained batch 297 in epoch 7, gen_loss = 0.40735381361622136, disc_loss = 0.06271032021918503
Trained batch 298 in epoch 7, gen_loss = 0.40736909036253605, disc_loss = 0.0625217215743626
Trained batch 299 in epoch 7, gen_loss = 0.4073583533366521, disc_loss = 0.06235006640199572
Trained batch 300 in epoch 7, gen_loss = 0.40717532646616433, disc_loss = 0.06228767423132478
Trained batch 301 in epoch 7, gen_loss = 0.40738476743761276, disc_loss = 0.06210180932489403
Trained batch 302 in epoch 7, gen_loss = 0.40748807325614955, disc_loss = 0.061987141108835
Trained batch 303 in epoch 7, gen_loss = 0.407472380093838, disc_loss = 0.06188942004748816
Trained batch 304 in epoch 7, gen_loss = 0.40739377873842836, disc_loss = 0.061731154665534124
Trained batch 305 in epoch 7, gen_loss = 0.4072373964233336, disc_loss = 0.06174161946066211
Trained batch 306 in epoch 7, gen_loss = 0.4068188379952496, disc_loss = 0.06187948833162068
Trained batch 307 in epoch 7, gen_loss = 0.40670331770723517, disc_loss = 0.06241213255592126
Trained batch 308 in epoch 7, gen_loss = 0.40657278557811355, disc_loss = 0.062446815981966684
Trained batch 309 in epoch 7, gen_loss = 0.4066616323686415, disc_loss = 0.06227248638357607
Trained batch 310 in epoch 7, gen_loss = 0.4066158669171226, disc_loss = 0.06213332117172826
Trained batch 311 in epoch 7, gen_loss = 0.4064100308296008, disc_loss = 0.061963383441205874
Trained batch 312 in epoch 7, gen_loss = 0.4062845752642939, disc_loss = 0.061786127626336514
Trained batch 313 in epoch 7, gen_loss = 0.40629910302769606, disc_loss = 0.06163292780524464
Trained batch 314 in epoch 7, gen_loss = 0.40617187051546005, disc_loss = 0.06147647174370904
Trained batch 315 in epoch 7, gen_loss = 0.40609498029645485, disc_loss = 0.061384199583561075
Trained batch 316 in epoch 7, gen_loss = 0.4061941913437768, disc_loss = 0.061210162660007124
Trained batch 317 in epoch 7, gen_loss = 0.4062316159032426, disc_loss = 0.0611389564195027
Trained batch 318 in epoch 7, gen_loss = 0.4061216771789479, disc_loss = 0.06162747156114367
Trained batch 319 in epoch 7, gen_loss = 0.4063036058098078, disc_loss = 0.06218537873792229
Trained batch 320 in epoch 7, gen_loss = 0.4064557725952422, disc_loss = 0.062027760776995775
Trained batch 321 in epoch 7, gen_loss = 0.4062976417889506, disc_loss = 0.06186456212293796
Trained batch 322 in epoch 7, gen_loss = 0.4061180230449228, disc_loss = 0.06170579685394194
Trained batch 323 in epoch 7, gen_loss = 0.40587583119854515, disc_loss = 0.06154093818802295
Trained batch 324 in epoch 7, gen_loss = 0.4058607587447533, disc_loss = 0.06138033594792852
Trained batch 325 in epoch 7, gen_loss = 0.40592054327938454, disc_loss = 0.06121114072635587
Trained batch 326 in epoch 7, gen_loss = 0.40592862059581536, disc_loss = 0.061128136035430866
Trained batch 327 in epoch 7, gen_loss = 0.4059876041804872, disc_loss = 0.0612112971778005
Trained batch 328 in epoch 7, gen_loss = 0.4060856544138088, disc_loss = 0.06207765247333104
Trained batch 329 in epoch 7, gen_loss = 0.4060554219014717, disc_loss = 0.06251491690054536
Trained batch 330 in epoch 7, gen_loss = 0.4060745643524965, disc_loss = 0.0628769623532081
Trained batch 331 in epoch 7, gen_loss = 0.406082430158753, disc_loss = 0.06280411465979933
Trained batch 332 in epoch 7, gen_loss = 0.4058239135119292, disc_loss = 0.0627492312537702
Trained batch 333 in epoch 7, gen_loss = 0.40584758798519294, disc_loss = 0.06272831862836988
Trained batch 334 in epoch 7, gen_loss = 0.40543648137975097, disc_loss = 0.06263431561137758
Trained batch 335 in epoch 7, gen_loss = 0.40523449677441803, disc_loss = 0.06274585349629411
Trained batch 336 in epoch 7, gen_loss = 0.4045829591659127, disc_loss = 0.06334074875422772
Trained batch 337 in epoch 7, gen_loss = 0.40458258025392274, disc_loss = 0.06355309450293523
Trained batch 338 in epoch 7, gen_loss = 0.40442691976341877, disc_loss = 0.06363365629132958
Trained batch 339 in epoch 7, gen_loss = 0.4042646699968506, disc_loss = 0.06408902664449723
Trained batch 340 in epoch 7, gen_loss = 0.40404338605942264, disc_loss = 0.0646597933040555
Trained batch 341 in epoch 7, gen_loss = 0.40416970936178465, disc_loss = 0.06477192834248408
Trained batch 342 in epoch 7, gen_loss = 0.40411595248619947, disc_loss = 0.06472649891472505
Trained batch 343 in epoch 7, gen_loss = 0.4039078658056814, disc_loss = 0.06471157185787466
Trained batch 344 in epoch 7, gen_loss = 0.4038698265517967, disc_loss = 0.06458663037451713
Trained batch 345 in epoch 7, gen_loss = 0.4036511760743367, disc_loss = 0.06445608146736301
Trained batch 346 in epoch 7, gen_loss = 0.40365305482825903, disc_loss = 0.06437536068958491
Trained batch 347 in epoch 7, gen_loss = 0.4036894817461913, disc_loss = 0.06447675254399321
Trained batch 348 in epoch 7, gen_loss = 0.4037744042524977, disc_loss = 0.0645301078971913
Trained batch 349 in epoch 7, gen_loss = 0.4035734680720738, disc_loss = 0.06474962894139545
Trained batch 350 in epoch 7, gen_loss = 0.40366015135392846, disc_loss = 0.06499125814580085
Trained batch 351 in epoch 7, gen_loss = 0.40350571037693456, disc_loss = 0.06545273404811848
Trained batch 352 in epoch 7, gen_loss = 0.40360790170285926, disc_loss = 0.06574231896697208
Trained batch 353 in epoch 7, gen_loss = 0.4034206014400148, disc_loss = 0.06590674844659906
Trained batch 354 in epoch 7, gen_loss = 0.4033869833173886, disc_loss = 0.06581310079708486
Trained batch 355 in epoch 7, gen_loss = 0.4034565602628033, disc_loss = 0.06576791084162222
Trained batch 356 in epoch 7, gen_loss = 0.4034719251784958, disc_loss = 0.06569756697654641
Trained batch 357 in epoch 7, gen_loss = 0.40354653243912, disc_loss = 0.06556448807898263
Trained batch 358 in epoch 7, gen_loss = 0.40340269118298394, disc_loss = 0.06575589356451064
Trained batch 359 in epoch 7, gen_loss = 0.4034385173685021, disc_loss = 0.06662748453155574
Trained batch 360 in epoch 7, gen_loss = 0.4033631391802653, disc_loss = 0.06654859465544326
Trained batch 361 in epoch 7, gen_loss = 0.4034684359698006, disc_loss = 0.06684681770355744
Trained batch 362 in epoch 7, gen_loss = 0.4032582998604157, disc_loss = 0.06699131272435599
Trained batch 363 in epoch 7, gen_loss = 0.40301088792282147, disc_loss = 0.06692464078858412
Trained batch 364 in epoch 7, gen_loss = 0.4031289628923756, disc_loss = 0.06709215275892248
Trained batch 365 in epoch 7, gen_loss = 0.4032295431758537, disc_loss = 0.06692877667065446
Trained batch 366 in epoch 7, gen_loss = 0.4030806050313591, disc_loss = 0.06704724538178064
Trained batch 367 in epoch 7, gen_loss = 0.4033131532209075, disc_loss = 0.06742143113439417
Trained batch 368 in epoch 7, gen_loss = 0.40303887027065927, disc_loss = 0.06733486890984663
Trained batch 369 in epoch 7, gen_loss = 0.4031214918639209, disc_loss = 0.06722412542062434
Trained batch 370 in epoch 7, gen_loss = 0.4032880891204844, disc_loss = 0.06709025909426318
Trained batch 371 in epoch 7, gen_loss = 0.40330759035323255, disc_loss = 0.06701200346021803
Trained batch 372 in epoch 7, gen_loss = 0.40331086995774235, disc_loss = 0.06698500391735068
Trained batch 373 in epoch 7, gen_loss = 0.4033762117758154, disc_loss = 0.06711743384310827
Trained batch 374 in epoch 7, gen_loss = 0.403317446231842, disc_loss = 0.06749744596829017
Trained batch 375 in epoch 7, gen_loss = 0.4035011036915982, disc_loss = 0.06739739736571829
Trained batch 376 in epoch 7, gen_loss = 0.4036319308793197, disc_loss = 0.06753956943266193
Trained batch 377 in epoch 7, gen_loss = 0.40384325519125297, disc_loss = 0.06754770955543905
Trained batch 378 in epoch 7, gen_loss = 0.4037723859727854, disc_loss = 0.06749187493180772
Trained batch 379 in epoch 7, gen_loss = 0.4036827358760332, disc_loss = 0.06745358657238906
Trained batch 380 in epoch 7, gen_loss = 0.40385407311084076, disc_loss = 0.06756883136820527
Trained batch 381 in epoch 7, gen_loss = 0.40413612665618276, disc_loss = 0.06744310779360499
Trained batch 382 in epoch 7, gen_loss = 0.40398718397237615, disc_loss = 0.06781198376882092
Trained batch 383 in epoch 7, gen_loss = 0.40384654235094786, disc_loss = 0.06784350567371196
Trained batch 384 in epoch 7, gen_loss = 0.4036926062850209, disc_loss = 0.06774910190807922
Trained batch 385 in epoch 7, gen_loss = 0.4035379634928827, disc_loss = 0.06771572258255874
Trained batch 386 in epoch 7, gen_loss = 0.40366667439771253, disc_loss = 0.0676931922013561
Trained batch 387 in epoch 7, gen_loss = 0.4037905381512396, disc_loss = 0.06755968342900046
Trained batch 388 in epoch 7, gen_loss = 0.40369270155852743, disc_loss = 0.0679230425521195
Trained batch 389 in epoch 7, gen_loss = 0.4037752138498502, disc_loss = 0.06873294503117601
Trained batch 390 in epoch 7, gen_loss = 0.40384753120829686, disc_loss = 0.06884549163958377
Trained batch 391 in epoch 7, gen_loss = 0.4036799965008181, disc_loss = 0.06880774427138801
Trained batch 392 in epoch 7, gen_loss = 0.40343853998123536, disc_loss = 0.0687422382623981
Trained batch 393 in epoch 7, gen_loss = 0.4033471661322008, disc_loss = 0.06859214294011595
Trained batch 394 in epoch 7, gen_loss = 0.4032831662063357, disc_loss = 0.06844597249704448
Trained batch 395 in epoch 7, gen_loss = 0.4033124738118865, disc_loss = 0.06836026075597137
Trained batch 396 in epoch 7, gen_loss = 0.40329545488585755, disc_loss = 0.06834755768713258
Trained batch 397 in epoch 7, gen_loss = 0.40322266668830087, disc_loss = 0.06837125637582574
Trained batch 398 in epoch 7, gen_loss = 0.40313325818618734, disc_loss = 0.06854963517586764
Trained batch 399 in epoch 7, gen_loss = 0.40314082071185114, disc_loss = 0.06870362034300342
Trained batch 400 in epoch 7, gen_loss = 0.40305657041934956, disc_loss = 0.06858830215488364
Trained batch 401 in epoch 7, gen_loss = 0.4029420309547168, disc_loss = 0.06865229216909305
Trained batch 402 in epoch 7, gen_loss = 0.40287949584849714, disc_loss = 0.06871126649702528
Trained batch 403 in epoch 7, gen_loss = 0.40287648296297185, disc_loss = 0.06855820429091812
Trained batch 404 in epoch 7, gen_loss = 0.40281269528247693, disc_loss = 0.068514296107776
Trained batch 405 in epoch 7, gen_loss = 0.40274811671872446, disc_loss = 0.06836742681698883
Trained batch 406 in epoch 7, gen_loss = 0.40277312802155424, disc_loss = 0.06850545065871072
Trained batch 407 in epoch 7, gen_loss = 0.4025639113696182, disc_loss = 0.06855980187823411
Trained batch 408 in epoch 7, gen_loss = 0.40238023073865614, disc_loss = 0.06849923368866731
Trained batch 409 in epoch 7, gen_loss = 0.4023186883548411, disc_loss = 0.06860080006668662
Trained batch 410 in epoch 7, gen_loss = 0.40239095528340396, disc_loss = 0.0685240289212234
Trained batch 411 in epoch 7, gen_loss = 0.40224480006879976, disc_loss = 0.06874244729423154
Trained batch 412 in epoch 7, gen_loss = 0.40230712604869073, disc_loss = 0.06885881361734239
Trained batch 413 in epoch 7, gen_loss = 0.4024436700603236, disc_loss = 0.06871365701244325
Trained batch 414 in epoch 7, gen_loss = 0.40229015802762597, disc_loss = 0.06862933236589454
Trained batch 415 in epoch 7, gen_loss = 0.4022866734661735, disc_loss = 0.06848171308453087
Trained batch 416 in epoch 7, gen_loss = 0.4024926594121279, disc_loss = 0.06834660244801884
Trained batch 417 in epoch 7, gen_loss = 0.4024422642859546, disc_loss = 0.06824833154566942
Trained batch 418 in epoch 7, gen_loss = 0.40235558173536967, disc_loss = 0.06810366976917288
Trained batch 419 in epoch 7, gen_loss = 0.40249002519108, disc_loss = 0.06799154559904266
Trained batch 420 in epoch 7, gen_loss = 0.4026231321189862, disc_loss = 0.06794237281525432
Trained batch 421 in epoch 7, gen_loss = 0.4025509248695102, disc_loss = 0.06815089336353668
Trained batch 422 in epoch 7, gen_loss = 0.40255962421426256, disc_loss = 0.06846911953123679
Trained batch 423 in epoch 7, gen_loss = 0.4025181645773492, disc_loss = 0.06834162381600659
Trained batch 424 in epoch 7, gen_loss = 0.40255206802312066, disc_loss = 0.06820988863049185
Trained batch 425 in epoch 7, gen_loss = 0.4026022202951807, disc_loss = 0.06806976416152617
Trained batch 426 in epoch 7, gen_loss = 0.40262097406443165, disc_loss = 0.06792332713145423
Trained batch 427 in epoch 7, gen_loss = 0.4023103585170808, disc_loss = 0.0678012084137544
Trained batch 428 in epoch 7, gen_loss = 0.4022826410673715, disc_loss = 0.06766109805041816
Trained batch 429 in epoch 7, gen_loss = 0.4022320622621581, disc_loss = 0.06752694478301807
Trained batch 430 in epoch 7, gen_loss = 0.40220034482031025, disc_loss = 0.06739556436748903
Trained batch 431 in epoch 7, gen_loss = 0.4020771806438764, disc_loss = 0.06727893378896017
Trained batch 432 in epoch 7, gen_loss = 0.4019618072906212, disc_loss = 0.06716960531338946
Trained batch 433 in epoch 7, gen_loss = 0.4019279372170224, disc_loss = 0.06711284778926367
Trained batch 434 in epoch 7, gen_loss = 0.40199989882008785, disc_loss = 0.06749563299804584
Trained batch 435 in epoch 7, gen_loss = 0.40190877751746307, disc_loss = 0.06767731833639085
Trained batch 436 in epoch 7, gen_loss = 0.4018492537041278, disc_loss = 0.0675513954551835
Trained batch 437 in epoch 7, gen_loss = 0.4019439882475492, disc_loss = 0.0676196630529583
Trained batch 438 in epoch 7, gen_loss = 0.4019092719212751, disc_loss = 0.06748793744068414
Trained batch 439 in epoch 7, gen_loss = 0.40194213552908464, disc_loss = 0.06736947288736701
Trained batch 440 in epoch 7, gen_loss = 0.4018621687986413, disc_loss = 0.06729164208515702
Trained batch 441 in epoch 7, gen_loss = 0.40200452890870797, disc_loss = 0.06716025310539013
Trained batch 442 in epoch 7, gen_loss = 0.402158965241021, disc_loss = 0.06729985861019411
Trained batch 443 in epoch 7, gen_loss = 0.4020680653619337, disc_loss = 0.06780941908558209
Trained batch 444 in epoch 7, gen_loss = 0.402097481154324, disc_loss = 0.06774869981441604
Trained batch 445 in epoch 7, gen_loss = 0.4022656739292658, disc_loss = 0.06769536214258372
Trained batch 446 in epoch 7, gen_loss = 0.4021817819117433, disc_loss = 0.06757234806565764
Trained batch 447 in epoch 7, gen_loss = 0.40222685970366, disc_loss = 0.06745044205412601
Trained batch 448 in epoch 7, gen_loss = 0.4021876487540774, disc_loss = 0.06733708046501158
Trained batch 449 in epoch 7, gen_loss = 0.4020680809020996, disc_loss = 0.06727486594890554
Trained batch 450 in epoch 7, gen_loss = 0.4023516704132182, disc_loss = 0.06720197677587525
Trained batch 451 in epoch 7, gen_loss = 0.4022043914394041, disc_loss = 0.06709229299361792
Trained batch 452 in epoch 7, gen_loss = 0.4023241171773696, disc_loss = 0.06701508757532892
Trained batch 453 in epoch 7, gen_loss = 0.40248062491154357, disc_loss = 0.06694130742479329
Trained batch 454 in epoch 7, gen_loss = 0.40252272689735497, disc_loss = 0.06684002818355521
Trained batch 455 in epoch 7, gen_loss = 0.4027822809784036, disc_loss = 0.06674032335030732
Trained batch 456 in epoch 7, gen_loss = 0.40294515323586744, disc_loss = 0.06661034453175228
Trained batch 457 in epoch 7, gen_loss = 0.4029297141529067, disc_loss = 0.06664156461008479
Trained batch 458 in epoch 7, gen_loss = 0.402801416473451, disc_loss = 0.067551680731999
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 0.4219928979873657, disc_loss = 0.07941731810569763
Trained batch 1 in epoch 8, gen_loss = 0.40085768699645996, disc_loss = 0.08495509251952171
Trained batch 2 in epoch 8, gen_loss = 0.3912309606870015, disc_loss = 0.07238374277949333
Trained batch 3 in epoch 8, gen_loss = 0.3840765804052353, disc_loss = 0.06371566746383905
Trained batch 4 in epoch 8, gen_loss = 0.3775425016880035, disc_loss = 0.05399067346006632
Trained batch 5 in epoch 8, gen_loss = 0.3896056016286214, disc_loss = 0.047137409914284945
Trained batch 6 in epoch 8, gen_loss = 0.38577309250831604, disc_loss = 0.0469942618427532
Trained batch 7 in epoch 8, gen_loss = 0.3993387147784233, disc_loss = 0.04539032781030983
Trained batch 8 in epoch 8, gen_loss = 0.4062984320852492, disc_loss = 0.04603393613878223
Trained batch 9 in epoch 8, gen_loss = 0.4003086030483246, disc_loss = 0.04825453674420714
Trained batch 10 in epoch 8, gen_loss = 0.4025703804059462, disc_loss = 0.044819143431430515
Trained batch 11 in epoch 8, gen_loss = 0.40594271570444107, disc_loss = 0.0419912226498127
Trained batch 12 in epoch 8, gen_loss = 0.4084871388398684, disc_loss = 0.04003333243039938
Trained batch 13 in epoch 8, gen_loss = 0.41230727306434084, disc_loss = 0.038434521960360665
Trained batch 14 in epoch 8, gen_loss = 0.40823718905448914, disc_loss = 0.03735749324162801
Trained batch 15 in epoch 8, gen_loss = 0.40660507790744305, disc_loss = 0.03837392316199839
Trained batch 16 in epoch 8, gen_loss = 0.40372563460293936, disc_loss = 0.04973387915421935
Trained batch 17 in epoch 8, gen_loss = 0.4062185221248203, disc_loss = 0.073733184279667
Trained batch 18 in epoch 8, gen_loss = 0.4045281143564927, disc_loss = 0.08095350959583332
Trained batch 19 in epoch 8, gen_loss = 0.4009153231978416, disc_loss = 0.08319569174200296
Trained batch 20 in epoch 8, gen_loss = 0.3987117693537757, disc_loss = 0.08539690662707601
Trained batch 21 in epoch 8, gen_loss = 0.3954391574317759, disc_loss = 0.08390254527330399
Trained batch 22 in epoch 8, gen_loss = 0.3927429331385571, disc_loss = 0.08238733786603679
Trained batch 23 in epoch 8, gen_loss = 0.3909135100742181, disc_loss = 0.07974589243531227
Trained batch 24 in epoch 8, gen_loss = 0.3882384753227234, disc_loss = 0.0785929098725319
Trained batch 25 in epoch 8, gen_loss = 0.3893836197944788, disc_loss = 0.0761144501515306
Trained batch 26 in epoch 8, gen_loss = 0.39179322785801357, disc_loss = 0.07417926537217917
Trained batch 27 in epoch 8, gen_loss = 0.393347404897213, disc_loss = 0.07208558491298131
Trained batch 28 in epoch 8, gen_loss = 0.3950634763158601, disc_loss = 0.07267198403333795
Trained batch 29 in epoch 8, gen_loss = 0.39711530605951945, disc_loss = 0.07743168299396833
Trained batch 30 in epoch 8, gen_loss = 0.395116634907261, disc_loss = 0.08182340019172238
Trained batch 31 in epoch 8, gen_loss = 0.3962404131889343, disc_loss = 0.08304735156707466
Trained batch 32 in epoch 8, gen_loss = 0.39840206232937897, disc_loss = 0.08214239584225597
Trained batch 33 in epoch 8, gen_loss = 0.3983642774469712, disc_loss = 0.08074947446584702
Trained batch 34 in epoch 8, gen_loss = 0.39855047804968696, disc_loss = 0.08026421261685235
Trained batch 35 in epoch 8, gen_loss = 0.3977675686279933, disc_loss = 0.07860038186320001
Trained batch 36 in epoch 8, gen_loss = 0.40125184606861425, disc_loss = 0.07823436692155697
Trained batch 37 in epoch 8, gen_loss = 0.40231645264123617, disc_loss = 0.07676159889486275
Trained batch 38 in epoch 8, gen_loss = 0.3997339285337008, disc_loss = 0.07674184732903273
Trained batch 39 in epoch 8, gen_loss = 0.40201650783419607, disc_loss = 0.07884420142509044
Trained batch 40 in epoch 8, gen_loss = 0.4019546356143021, disc_loss = 0.08036332654698593
Trained batch 41 in epoch 8, gen_loss = 0.40329362877777647, disc_loss = 0.08282623355764718
Trained batch 42 in epoch 8, gen_loss = 0.4014006638249686, disc_loss = 0.08542877873189228
Trained batch 43 in epoch 8, gen_loss = 0.4008465964685787, disc_loss = 0.08606529578735883
Trained batch 44 in epoch 8, gen_loss = 0.40041771597332426, disc_loss = 0.08507659795383612
Trained batch 45 in epoch 8, gen_loss = 0.3991289216539134, disc_loss = 0.0858363811655537
Trained batch 46 in epoch 8, gen_loss = 0.39823536352908356, disc_loss = 0.08502056231682605
Trained batch 47 in epoch 8, gen_loss = 0.39886525459587574, disc_loss = 0.08397244246831785
Trained batch 48 in epoch 8, gen_loss = 0.39879385245089627, disc_loss = 0.08286530250797466
Trained batch 49 in epoch 8, gen_loss = 0.39838104546070097, disc_loss = 0.08156453967094421
Trained batch 50 in epoch 8, gen_loss = 0.3976048523304509, disc_loss = 0.0807444743227725
Trained batch 51 in epoch 8, gen_loss = 0.3976272877592307, disc_loss = 0.08144730995767392
Trained batch 52 in epoch 8, gen_loss = 0.3960582265314066, disc_loss = 0.08353290643613294
Trained batch 53 in epoch 8, gen_loss = 0.3962582261474044, disc_loss = 0.0833504705655354
Trained batch 54 in epoch 8, gen_loss = 0.39649125933647156, disc_loss = 0.0819744008931924
Trained batch 55 in epoch 8, gen_loss = 0.39616637197988375, disc_loss = 0.08068444302937548
Trained batch 56 in epoch 8, gen_loss = 0.3976384715030068, disc_loss = 0.07936191417505606
Trained batch 57 in epoch 8, gen_loss = 0.39791053739087334, disc_loss = 0.07831232653577523
Trained batch 58 in epoch 8, gen_loss = 0.3980148086103342, disc_loss = 0.07707575081958104
Trained batch 59 in epoch 8, gen_loss = 0.3980524947245916, disc_loss = 0.07629490791199108
Trained batch 60 in epoch 8, gen_loss = 0.3961791454768572, disc_loss = 0.07591451684654248
Trained batch 61 in epoch 8, gen_loss = 0.39665508077990624, disc_loss = 0.07583010621789482
Trained batch 62 in epoch 8, gen_loss = 0.3980226895165822, disc_loss = 0.07570252027953901
Trained batch 63 in epoch 8, gen_loss = 0.3990088617429137, disc_loss = 0.07461678044637665
Trained batch 64 in epoch 8, gen_loss = 0.399626761674881, disc_loss = 0.0736110972527128
Trained batch 65 in epoch 8, gen_loss = 0.398992760163365, disc_loss = 0.07271332800331892
Trained batch 66 in epoch 8, gen_loss = 0.39900068338237593, disc_loss = 0.07239268568636321
Trained batch 67 in epoch 8, gen_loss = 0.39986170433899937, disc_loss = 0.07319589949432104
Trained batch 68 in epoch 8, gen_loss = 0.39865111613619153, disc_loss = 0.07395052892304417
Trained batch 69 in epoch 8, gen_loss = 0.3985767888171332, disc_loss = 0.07308369325473904
Trained batch 70 in epoch 8, gen_loss = 0.399036726901229, disc_loss = 0.07491740819171701
Trained batch 71 in epoch 8, gen_loss = 0.39801469321052235, disc_loss = 0.0779264137122987
Trained batch 72 in epoch 8, gen_loss = 0.39839747466453135, disc_loss = 0.07698411955051634
Trained batch 73 in epoch 8, gen_loss = 0.39893776500547257, disc_loss = 0.07704543253104831
Trained batch 74 in epoch 8, gen_loss = 0.3994706078370412, disc_loss = 0.07622210276623567
Trained batch 75 in epoch 8, gen_loss = 0.3999744606645484, disc_loss = 0.07580459527181167
Trained batch 76 in epoch 8, gen_loss = 0.4003159709565051, disc_loss = 0.07513703979164749
Trained batch 77 in epoch 8, gen_loss = 0.4001200493329611, disc_loss = 0.07452973503714953
Trained batch 78 in epoch 8, gen_loss = 0.3992208506487593, disc_loss = 0.07402728611155401
Trained batch 79 in epoch 8, gen_loss = 0.39963412620127203, disc_loss = 0.07366800121963024
Trained batch 80 in epoch 8, gen_loss = 0.3986149213196319, disc_loss = 0.07403633347999902
Trained batch 81 in epoch 8, gen_loss = 0.3986699279488587, disc_loss = 0.07565138852450906
Trained batch 82 in epoch 8, gen_loss = 0.3991151681865554, disc_loss = 0.07487328056560223
Trained batch 83 in epoch 8, gen_loss = 0.3984179851554689, disc_loss = 0.07546845258080534
Trained batch 84 in epoch 8, gen_loss = 0.39837170488694135, disc_loss = 0.07500520767096211
Trained batch 85 in epoch 8, gen_loss = 0.39870648779148277, disc_loss = 0.07425833814019381
Trained batch 86 in epoch 8, gen_loss = 0.3987744142269266, disc_loss = 0.0736247801232612
Trained batch 87 in epoch 8, gen_loss = 0.39993786269968207, disc_loss = 0.07299874200146984
Trained batch 88 in epoch 8, gen_loss = 0.3997673897930745, disc_loss = 0.07257973722946108
Trained batch 89 in epoch 8, gen_loss = 0.4004460841417313, disc_loss = 0.07188314158055517
Trained batch 90 in epoch 8, gen_loss = 0.3999762941192795, disc_loss = 0.07124604352309809
Trained batch 91 in epoch 8, gen_loss = 0.3995386222782342, disc_loss = 0.07058886805063357
Trained batch 92 in epoch 8, gen_loss = 0.39951224096359744, disc_loss = 0.07014559780157381
Trained batch 93 in epoch 8, gen_loss = 0.39921569729104955, disc_loss = 0.06992791056078165
Trained batch 94 in epoch 8, gen_loss = 0.3994739300326297, disc_loss = 0.06946892701089383
Trained batch 95 in epoch 8, gen_loss = 0.39920028671622276, disc_loss = 0.0688708500432161
Trained batch 96 in epoch 8, gen_loss = 0.39988764598197546, disc_loss = 0.06821565596943664
Trained batch 97 in epoch 8, gen_loss = 0.3998048113925116, disc_loss = 0.06764290497011068
Trained batch 98 in epoch 8, gen_loss = 0.4007063197969186, disc_loss = 0.06761347577728406
Trained batch 99 in epoch 8, gen_loss = 0.4012569198012352, disc_loss = 0.06708361037075519
Trained batch 100 in epoch 8, gen_loss = 0.40049590863803824, disc_loss = 0.06718811112465245
Trained batch 101 in epoch 8, gen_loss = 0.4008505110647164, disc_loss = 0.06675356022064008
Trained batch 102 in epoch 8, gen_loss = 0.4005128894616099, disc_loss = 0.06745297420155076
Trained batch 103 in epoch 8, gen_loss = 0.3999427674481502, disc_loss = 0.06694815004280266
Trained batch 104 in epoch 8, gen_loss = 0.40043278478440786, disc_loss = 0.06666902506812697
Trained batch 105 in epoch 8, gen_loss = 0.4004780692311953, disc_loss = 0.06634523210836188
Trained batch 106 in epoch 8, gen_loss = 0.4004705915941256, disc_loss = 0.06600945496009053
Trained batch 107 in epoch 8, gen_loss = 0.4007238778803084, disc_loss = 0.06545217720688218
Trained batch 108 in epoch 8, gen_loss = 0.4008264290083439, disc_loss = 0.0650589776678233
Trained batch 109 in epoch 8, gen_loss = 0.4006258663806048, disc_loss = 0.06459830805489963
Trained batch 110 in epoch 8, gen_loss = 0.4008833188731391, disc_loss = 0.06407727884665669
Trained batch 111 in epoch 8, gen_loss = 0.40054898602621897, disc_loss = 0.06376939802014801
Trained batch 112 in epoch 8, gen_loss = 0.4011883872800169, disc_loss = 0.06374056976436909
Trained batch 113 in epoch 8, gen_loss = 0.4013723804239641, disc_loss = 0.06398429266961389
Trained batch 114 in epoch 8, gen_loss = 0.40152225909025774, disc_loss = 0.06354055846433924
Trained batch 115 in epoch 8, gen_loss = 0.4022962582008592, disc_loss = 0.0641230563271855
Trained batch 116 in epoch 8, gen_loss = 0.4021371669239468, disc_loss = 0.06494862593821862
Trained batch 117 in epoch 8, gen_loss = 0.40218173598839063, disc_loss = 0.06465687954372143
Trained batch 118 in epoch 8, gen_loss = 0.40210974191417215, disc_loss = 0.06437810333132618
Trained batch 119 in epoch 8, gen_loss = 0.4027072437107563, disc_loss = 0.06391188506580268
Trained batch 120 in epoch 8, gen_loss = 0.4025777070975501, disc_loss = 0.06368063052746752
Trained batch 121 in epoch 8, gen_loss = 0.4025009086386102, disc_loss = 0.06322666023644145
Trained batch 122 in epoch 8, gen_loss = 0.4026444828122612, disc_loss = 0.06349271976169411
Trained batch 123 in epoch 8, gen_loss = 0.40173515941827526, disc_loss = 0.0642736165205978
Trained batch 124 in epoch 8, gen_loss = 0.40143910884857176, disc_loss = 0.06393788314983248
Trained batch 125 in epoch 8, gen_loss = 0.401726418071323, disc_loss = 0.0635221269802146
Trained batch 126 in epoch 8, gen_loss = 0.4012257165796175, disc_loss = 0.06311140676931017
Trained batch 127 in epoch 8, gen_loss = 0.40109665552154183, disc_loss = 0.06279769970205962
Trained batch 128 in epoch 8, gen_loss = 0.4011178605778273, disc_loss = 0.06279551208582382
Trained batch 129 in epoch 8, gen_loss = 0.40147306873248173, disc_loss = 0.06327322354325308
Trained batch 130 in epoch 8, gen_loss = 0.40158730449567315, disc_loss = 0.06501369962809991
Trained batch 131 in epoch 8, gen_loss = 0.401581079445102, disc_loss = 0.06469587284267288
Trained batch 132 in epoch 8, gen_loss = 0.40218977439672426, disc_loss = 0.06527671332408051
Trained batch 133 in epoch 8, gen_loss = 0.4020301617348372, disc_loss = 0.06502471524707751
Trained batch 134 in epoch 8, gen_loss = 0.40195975833468967, disc_loss = 0.06533097044944211
Trained batch 135 in epoch 8, gen_loss = 0.4019412361085415, disc_loss = 0.0656435876393088
Trained batch 136 in epoch 8, gen_loss = 0.40164334430311716, disc_loss = 0.06538052369847241
Trained batch 137 in epoch 8, gen_loss = 0.4009772161210793, disc_loss = 0.06536178660336071
Trained batch 138 in epoch 8, gen_loss = 0.4015296952758762, disc_loss = 0.06627381804379091
Trained batch 139 in epoch 8, gen_loss = 0.4006530908601625, disc_loss = 0.06668960044626146
Trained batch 140 in epoch 8, gen_loss = 0.4014970975141999, disc_loss = 0.0663629290449651
Trained batch 141 in epoch 8, gen_loss = 0.4020095492752505, disc_loss = 0.06658306675569588
Trained batch 142 in epoch 8, gen_loss = 0.4020249904035688, disc_loss = 0.06664700659929768
Trained batch 143 in epoch 8, gen_loss = 0.40195846288568443, disc_loss = 0.0670763491103167
Trained batch 144 in epoch 8, gen_loss = 0.40209411218248564, disc_loss = 0.0684579726918761
Trained batch 145 in epoch 8, gen_loss = 0.4024846121056439, disc_loss = 0.06900441554400509
Trained batch 146 in epoch 8, gen_loss = 0.4025572386323189, disc_loss = 0.0686497397461057
Trained batch 147 in epoch 8, gen_loss = 0.4030859770404326, disc_loss = 0.06825162326552074
Trained batch 148 in epoch 8, gen_loss = 0.40338022916909033, disc_loss = 0.06788081602949723
Trained batch 149 in epoch 8, gen_loss = 0.4030831923087438, disc_loss = 0.0675302652735263
Trained batch 150 in epoch 8, gen_loss = 0.40309669896466843, disc_loss = 0.06726170655352291
Trained batch 151 in epoch 8, gen_loss = 0.4027128852903843, disc_loss = 0.06695032474817708
Trained batch 152 in epoch 8, gen_loss = 0.4027119008154651, disc_loss = 0.06661357702322158
Trained batch 153 in epoch 8, gen_loss = 0.4025097156499887, disc_loss = 0.06630783290723218
Trained batch 154 in epoch 8, gen_loss = 0.40257171834668803, disc_loss = 0.06616792373299119
Trained batch 155 in epoch 8, gen_loss = 0.40258844922750425, disc_loss = 0.06617527495389088
Trained batch 156 in epoch 8, gen_loss = 0.4026862762536213, disc_loss = 0.06594846392596129
Trained batch 157 in epoch 8, gen_loss = 0.40234900577158866, disc_loss = 0.06569725672030656
Trained batch 158 in epoch 8, gen_loss = 0.40255725327527747, disc_loss = 0.06689818232443254
Trained batch 159 in epoch 8, gen_loss = 0.4021168252453208, disc_loss = 0.06660339170775842
Trained batch 160 in epoch 8, gen_loss = 0.40145567411221333, disc_loss = 0.06854873830568253
Trained batch 161 in epoch 8, gen_loss = 0.4014450558173804, disc_loss = 0.0692127837230348
Trained batch 162 in epoch 8, gen_loss = 0.4016112118410918, disc_loss = 0.06909368381167025
Trained batch 163 in epoch 8, gen_loss = 0.4014279108221938, disc_loss = 0.06893661979120225
Trained batch 164 in epoch 8, gen_loss = 0.40130828763499404, disc_loss = 0.06889370535077019
Trained batch 165 in epoch 8, gen_loss = 0.4013376442423786, disc_loss = 0.06900259183371911
Trained batch 166 in epoch 8, gen_loss = 0.4009386973823616, disc_loss = 0.06908505797821159
Trained batch 167 in epoch 8, gen_loss = 0.4010068497487477, disc_loss = 0.0688079839899382
Trained batch 168 in epoch 8, gen_loss = 0.4008199085850687, disc_loss = 0.06847819054675613
Trained batch 169 in epoch 8, gen_loss = 0.40105788602548487, disc_loss = 0.06816016031593522
Trained batch 170 in epoch 8, gen_loss = 0.4012030993985851, disc_loss = 0.0678090019211478
Trained batch 171 in epoch 8, gen_loss = 0.4014894643495249, disc_loss = 0.06760182912017457
Trained batch 172 in epoch 8, gen_loss = 0.40184716544399374, disc_loss = 0.06758158214960915
Trained batch 173 in epoch 8, gen_loss = 0.4023531526327133, disc_loss = 0.06748063368026981
Trained batch 174 in epoch 8, gen_loss = 0.4020865193435124, disc_loss = 0.06757697742166263
Trained batch 175 in epoch 8, gen_loss = 0.4018950127065182, disc_loss = 0.06895412612886337
Trained batch 176 in epoch 8, gen_loss = 0.40138471564330624, disc_loss = 0.06909955699407196
Trained batch 177 in epoch 8, gen_loss = 0.4016067340467753, disc_loss = 0.06896632041499605
Trained batch 178 in epoch 8, gen_loss = 0.40099271615790255, disc_loss = 0.06880057284962282
Trained batch 179 in epoch 8, gen_loss = 0.4006481882598665, disc_loss = 0.06884538202494797
Trained batch 180 in epoch 8, gen_loss = 0.40083167236812867, disc_loss = 0.06958885781353762
Trained batch 181 in epoch 8, gen_loss = 0.40023833005637915, disc_loss = 0.06960587218086553
Trained batch 182 in epoch 8, gen_loss = 0.39980463317183196, disc_loss = 0.06975080453805992
Trained batch 183 in epoch 8, gen_loss = 0.40065186211596365, disc_loss = 0.0710188900145864
Trained batch 184 in epoch 8, gen_loss = 0.4005391090302854, disc_loss = 0.07117457758584941
Trained batch 185 in epoch 8, gen_loss = 0.4004695226428329, disc_loss = 0.07114112840074124
Trained batch 186 in epoch 8, gen_loss = 0.40010946096583483, disc_loss = 0.07103329022629137
Trained batch 187 in epoch 8, gen_loss = 0.3998035306626178, disc_loss = 0.07084198217056295
Trained batch 188 in epoch 8, gen_loss = 0.4000223807241551, disc_loss = 0.07057390954572136
Trained batch 189 in epoch 8, gen_loss = 0.40011117897535625, disc_loss = 0.07089025736296255
Trained batch 190 in epoch 8, gen_loss = 0.3999649456346222, disc_loss = 0.07200361840202624
Trained batch 191 in epoch 8, gen_loss = 0.4003240115319689, disc_loss = 0.07271311918399685
Trained batch 192 in epoch 8, gen_loss = 0.40018088165960164, disc_loss = 0.07319845449555801
Trained batch 193 in epoch 8, gen_loss = 0.3999527869458051, disc_loss = 0.07306106307198168
Trained batch 194 in epoch 8, gen_loss = 0.399869139225055, disc_loss = 0.07293294323608279
Trained batch 195 in epoch 8, gen_loss = 0.3995799825203662, disc_loss = 0.0727402463636114
Trained batch 196 in epoch 8, gen_loss = 0.3991959163077592, disc_loss = 0.07253162314415659
Trained batch 197 in epoch 8, gen_loss = 0.39922106010143205, disc_loss = 0.07232278438915282
Trained batch 198 in epoch 8, gen_loss = 0.3991959833320062, disc_loss = 0.07205920680730261
Trained batch 199 in epoch 8, gen_loss = 0.3988415540754795, disc_loss = 0.07210800747619941
Trained batch 200 in epoch 8, gen_loss = 0.3991530008280455, disc_loss = 0.07354519152272473
Trained batch 201 in epoch 8, gen_loss = 0.3986153581945023, disc_loss = 0.07379131907329775
Trained batch 202 in epoch 8, gen_loss = 0.3984861623477466, disc_loss = 0.07624940026615715
Trained batch 203 in epoch 8, gen_loss = 0.39838073241944405, disc_loss = 0.07620348294913842
Trained batch 204 in epoch 8, gen_loss = 0.3985983083887798, disc_loss = 0.07627701656892896
Trained batch 205 in epoch 8, gen_loss = 0.3985049879377328, disc_loss = 0.0761400773438616
Trained batch 206 in epoch 8, gen_loss = 0.39831126139359774, disc_loss = 0.07591332283977797
Trained batch 207 in epoch 8, gen_loss = 0.3985758793468659, disc_loss = 0.07566050093737431
Trained batch 208 in epoch 8, gen_loss = 0.3983419759992207, disc_loss = 0.0755937948007511
Trained batch 209 in epoch 8, gen_loss = 0.3984243759087154, disc_loss = 0.0755082922610676
Trained batch 210 in epoch 8, gen_loss = 0.3981783141457074, disc_loss = 0.07546041573296297
Trained batch 211 in epoch 8, gen_loss = 0.3989714178836571, disc_loss = 0.0754002129839171
Trained batch 212 in epoch 8, gen_loss = 0.3988264429737145, disc_loss = 0.07510887697872491
Trained batch 213 in epoch 8, gen_loss = 0.3988253918485107, disc_loss = 0.07483937111944308
Trained batch 214 in epoch 8, gen_loss = 0.3988287112047506, disc_loss = 0.07471905370827678
Trained batch 215 in epoch 8, gen_loss = 0.39849937320859347, disc_loss = 0.07509342097478953
Trained batch 216 in epoch 8, gen_loss = 0.3988193299638511, disc_loss = 0.07522648029793311
Trained batch 217 in epoch 8, gen_loss = 0.3987457521191431, disc_loss = 0.0749503598236607
Trained batch 218 in epoch 8, gen_loss = 0.39860200677832514, disc_loss = 0.0746386688240893
Trained batch 219 in epoch 8, gen_loss = 0.3984271015633236, disc_loss = 0.07456324756018479
Trained batch 220 in epoch 8, gen_loss = 0.3987835997639738, disc_loss = 0.07429727435120428
Trained batch 221 in epoch 8, gen_loss = 0.3987840894643251, disc_loss = 0.07404668263562426
Trained batch 222 in epoch 8, gen_loss = 0.3988457364886331, disc_loss = 0.07377369623973698
Trained batch 223 in epoch 8, gen_loss = 0.39913305453956127, disc_loss = 0.07361450670578051
Trained batch 224 in epoch 8, gen_loss = 0.39933266361554465, disc_loss = 0.07348793354920215
Trained batch 225 in epoch 8, gen_loss = 0.3993025924515935, disc_loss = 0.07321318118437399
Trained batch 226 in epoch 8, gen_loss = 0.39949474211306296, disc_loss = 0.07309384128521915
Trained batch 227 in epoch 8, gen_loss = 0.39949353222261397, disc_loss = 0.07282221554410889
Trained batch 228 in epoch 8, gen_loss = 0.3990528517154627, disc_loss = 0.07283016357888106
Trained batch 229 in epoch 8, gen_loss = 0.3995918220799902, disc_loss = 0.0727071346330416
Trained batch 230 in epoch 8, gen_loss = 0.39975831067407286, disc_loss = 0.07291433584646552
Trained batch 231 in epoch 8, gen_loss = 0.3995076871380724, disc_loss = 0.07431124274594837
Trained batch 232 in epoch 8, gen_loss = 0.3997993965517298, disc_loss = 0.07414513169448071
Trained batch 233 in epoch 8, gen_loss = 0.39987154190356916, disc_loss = 0.07447331311364268
Trained batch 234 in epoch 8, gen_loss = 0.3999504772906608, disc_loss = 0.0743056397667115
Trained batch 235 in epoch 8, gen_loss = 0.3999719709410506, disc_loss = 0.07411614746463059
Trained batch 236 in epoch 8, gen_loss = 0.39959446463403825, disc_loss = 0.07395565397605174
Trained batch 237 in epoch 8, gen_loss = 0.39993922500049367, disc_loss = 0.07387997397268582
Trained batch 238 in epoch 8, gen_loss = 0.399668382550882, disc_loss = 0.07384053813527382
Trained batch 239 in epoch 8, gen_loss = 0.39948844475050765, disc_loss = 0.07403206961268248
Trained batch 240 in epoch 8, gen_loss = 0.40011128214385006, disc_loss = 0.07535825267287273
Trained batch 241 in epoch 8, gen_loss = 0.400249211133019, disc_loss = 0.07525811924152692
Trained batch 242 in epoch 8, gen_loss = 0.4001165600225268, disc_loss = 0.07510662272978773
Trained batch 243 in epoch 8, gen_loss = 0.3998820652238658, disc_loss = 0.0749448690903144
Trained batch 244 in epoch 8, gen_loss = 0.40008973260315095, disc_loss = 0.0747872089948125
Trained batch 245 in epoch 8, gen_loss = 0.40013063208359045, disc_loss = 0.0745877033966495
Trained batch 246 in epoch 8, gen_loss = 0.40014559476964384, disc_loss = 0.07446563581140478
Trained batch 247 in epoch 8, gen_loss = 0.40006170674197133, disc_loss = 0.07436447169428932
Trained batch 248 in epoch 8, gen_loss = 0.40007649056882744, disc_loss = 0.07430378044861927
Trained batch 249 in epoch 8, gen_loss = 0.40021134638786315, disc_loss = 0.07482196676172316
Trained batch 250 in epoch 8, gen_loss = 0.4005129577154182, disc_loss = 0.07648853025031814
Trained batch 251 in epoch 8, gen_loss = 0.40045601271447684, disc_loss = 0.07667910141522981
Trained batch 252 in epoch 8, gen_loss = 0.40021548794192285, disc_loss = 0.07686618364530177
Trained batch 253 in epoch 8, gen_loss = 0.4000728342711456, disc_loss = 0.07687276724439965
Trained batch 254 in epoch 8, gen_loss = 0.40039744003146305, disc_loss = 0.07671121069065788
Trained batch 255 in epoch 8, gen_loss = 0.4004038667771965, disc_loss = 0.07658607599478273
Trained batch 256 in epoch 8, gen_loss = 0.4005852924942506, disc_loss = 0.07634712460882064
Trained batch 257 in epoch 8, gen_loss = 0.40034764658573063, disc_loss = 0.07611411100419513
Trained batch 258 in epoch 8, gen_loss = 0.40038330271897626, disc_loss = 0.07590296023262802
Trained batch 259 in epoch 8, gen_loss = 0.4004133241680952, disc_loss = 0.07585588033275249
Trained batch 260 in epoch 8, gen_loss = 0.400744312453544, disc_loss = 0.07574586925842582
Trained batch 261 in epoch 8, gen_loss = 0.40068908126754615, disc_loss = 0.07555132325319218
Trained batch 262 in epoch 8, gen_loss = 0.4003633357046222, disc_loss = 0.0762567547921927
Trained batch 263 in epoch 8, gen_loss = 0.40054945094567357, disc_loss = 0.07671454819942344
Trained batch 264 in epoch 8, gen_loss = 0.4006891483405851, disc_loss = 0.07657729587078375
Trained batch 265 in epoch 8, gen_loss = 0.4006086062443884, disc_loss = 0.07636867530286816
Trained batch 266 in epoch 8, gen_loss = 0.4007066126619832, disc_loss = 0.07628307013845678
Trained batch 267 in epoch 8, gen_loss = 0.40078931991288913, disc_loss = 0.07603231264771755
Trained batch 268 in epoch 8, gen_loss = 0.4009888551049073, disc_loss = 0.07582804046010384
Trained batch 269 in epoch 8, gen_loss = 0.40078829880113953, disc_loss = 0.07563972172189366
Trained batch 270 in epoch 8, gen_loss = 0.4007862995471462, disc_loss = 0.07539411245353822
Trained batch 271 in epoch 8, gen_loss = 0.4005503607366015, disc_loss = 0.07533017615958884
Trained batch 272 in epoch 8, gen_loss = 0.40063512248870653, disc_loss = 0.07538752878876233
Trained batch 273 in epoch 8, gen_loss = 0.4006871402698712, disc_loss = 0.0752076481343213
Trained batch 274 in epoch 8, gen_loss = 0.40058408704670995, disc_loss = 0.07502467453649098
Trained batch 275 in epoch 8, gen_loss = 0.40075735769410065, disc_loss = 0.07484206808494755
Trained batch 276 in epoch 8, gen_loss = 0.400587888831266, disc_loss = 0.07492187823797661
Trained batch 277 in epoch 8, gen_loss = 0.40076844136920764, disc_loss = 0.0747147390113058
Trained batch 278 in epoch 8, gen_loss = 0.40101015023005904, disc_loss = 0.07464806356477321
Trained batch 279 in epoch 8, gen_loss = 0.4008416339755058, disc_loss = 0.07461330249539709
Trained batch 280 in epoch 8, gen_loss = 0.400645492552014, disc_loss = 0.07439224433412385
Trained batch 281 in epoch 8, gen_loss = 0.40058145571685005, disc_loss = 0.07418262868862044
Trained batch 282 in epoch 8, gen_loss = 0.4005103739959191, disc_loss = 0.07398819826155006
Trained batch 283 in epoch 8, gen_loss = 0.4003712233733123, disc_loss = 0.07440026894270797
Trained batch 284 in epoch 8, gen_loss = 0.39991460683053, disc_loss = 0.07536301333293842
Trained batch 285 in epoch 8, gen_loss = 0.4000096667062986, disc_loss = 0.07532513100113329
Trained batch 286 in epoch 8, gen_loss = 0.4000379464975217, disc_loss = 0.07516831347316452
Trained batch 287 in epoch 8, gen_loss = 0.3999915874252717, disc_loss = 0.07499116659326116
Trained batch 288 in epoch 8, gen_loss = 0.3999324002686669, disc_loss = 0.0749825434356438
Trained batch 289 in epoch 8, gen_loss = 0.3999795588953742, disc_loss = 0.07479938658050679
Trained batch 290 in epoch 8, gen_loss = 0.4000848086224389, disc_loss = 0.0746030658307482
Trained batch 291 in epoch 8, gen_loss = 0.4001402890641395, disc_loss = 0.07437572092589706
Trained batch 292 in epoch 8, gen_loss = 0.3999588146754906, disc_loss = 0.07432708738104729
Trained batch 293 in epoch 8, gen_loss = 0.39996873511343584, disc_loss = 0.07547214418351904
Trained batch 294 in epoch 8, gen_loss = 0.40014265189736575, disc_loss = 0.07590093874230476
Trained batch 295 in epoch 8, gen_loss = 0.4004377622056652, disc_loss = 0.07589098024716903
Trained batch 296 in epoch 8, gen_loss = 0.40043419770118766, disc_loss = 0.07572443311820778
Trained batch 297 in epoch 8, gen_loss = 0.40024801838718005, disc_loss = 0.07581403681652107
Trained batch 298 in epoch 8, gen_loss = 0.40051389687436084, disc_loss = 0.0756424041387055
Trained batch 299 in epoch 8, gen_loss = 0.4006132957339287, disc_loss = 0.07569969710117827
Trained batch 300 in epoch 8, gen_loss = 0.4005154318785747, disc_loss = 0.07642173347685276
Trained batch 301 in epoch 8, gen_loss = 0.4006888377942786, disc_loss = 0.07657368674979156
Trained batch 302 in epoch 8, gen_loss = 0.40046438869863454, disc_loss = 0.07665826514418615
Trained batch 303 in epoch 8, gen_loss = 0.4003970721050313, disc_loss = 0.07699926610650054
Trained batch 304 in epoch 8, gen_loss = 0.40031548582139564, disc_loss = 0.07765877795420953
Trained batch 305 in epoch 8, gen_loss = 0.40017178888414423, disc_loss = 0.07774529273901744
Trained batch 306 in epoch 8, gen_loss = 0.3998000985830537, disc_loss = 0.07780295298722988
Trained batch 307 in epoch 8, gen_loss = 0.4000582636950852, disc_loss = 0.0778707746407259
Trained batch 308 in epoch 8, gen_loss = 0.4002877957998356, disc_loss = 0.07768680969204958
Trained batch 309 in epoch 8, gen_loss = 0.4003493316711918, disc_loss = 0.07759750009694648
Trained batch 310 in epoch 8, gen_loss = 0.40047940851407804, disc_loss = 0.07737934103211645
Trained batch 311 in epoch 8, gen_loss = 0.4008050990792421, disc_loss = 0.07756447202364843
Trained batch 312 in epoch 8, gen_loss = 0.4008201306429915, disc_loss = 0.07748567765376295
Trained batch 313 in epoch 8, gen_loss = 0.4009603747896328, disc_loss = 0.07738808155872497
Trained batch 314 in epoch 8, gen_loss = 0.4010400893196227, disc_loss = 0.07718621813618239
Trained batch 315 in epoch 8, gen_loss = 0.40110204906403263, disc_loss = 0.07704348465622272
Trained batch 316 in epoch 8, gen_loss = 0.40087805899911877, disc_loss = 0.07683881507211068
Trained batch 317 in epoch 8, gen_loss = 0.4008037062748423, disc_loss = 0.0767024726762126
Trained batch 318 in epoch 8, gen_loss = 0.4007459303428387, disc_loss = 0.07649617853682476
Trained batch 319 in epoch 8, gen_loss = 0.40060725100338457, disc_loss = 0.07637597709108376
Trained batch 320 in epoch 8, gen_loss = 0.40096814795817914, disc_loss = 0.0764947153201379
Trained batch 321 in epoch 8, gen_loss = 0.4006556840787023, disc_loss = 0.07688472658447829
Trained batch 322 in epoch 8, gen_loss = 0.4006084021030934, disc_loss = 0.07668071968088809
Trained batch 323 in epoch 8, gen_loss = 0.40047955457811, disc_loss = 0.07711766431550783
Trained batch 324 in epoch 8, gen_loss = 0.40039702543845546, disc_loss = 0.07753883665714126
Trained batch 325 in epoch 8, gen_loss = 0.4003975726892612, disc_loss = 0.07745065413375436
Trained batch 326 in epoch 8, gen_loss = 0.4004380154318037, disc_loss = 0.07743244115918282
Trained batch 327 in epoch 8, gen_loss = 0.4003973826766014, disc_loss = 0.07744626858890648
Trained batch 328 in epoch 8, gen_loss = 0.40026956588301615, disc_loss = 0.07730205963566718
Trained batch 329 in epoch 8, gen_loss = 0.40042408641540644, disc_loss = 0.07736384265378794
Trained batch 330 in epoch 8, gen_loss = 0.40046802361205985, disc_loss = 0.07732626777339242
Trained batch 331 in epoch 8, gen_loss = 0.4006665437875024, disc_loss = 0.07713394795954003
Trained batch 332 in epoch 8, gen_loss = 0.400572328059165, disc_loss = 0.0769502067806999
Trained batch 333 in epoch 8, gen_loss = 0.40046900082491116, disc_loss = 0.07701793354155195
Trained batch 334 in epoch 8, gen_loss = 0.4005959226124322, disc_loss = 0.07747711491312331
Trained batch 335 in epoch 8, gen_loss = 0.40077404695607366, disc_loss = 0.07757651562929996
Trained batch 336 in epoch 8, gen_loss = 0.40078394101706033, disc_loss = 0.07741122691579805
Trained batch 337 in epoch 8, gen_loss = 0.40069594811758347, disc_loss = 0.07731434967253115
Trained batch 338 in epoch 8, gen_loss = 0.4005737229082788, disc_loss = 0.07722207721306291
Trained batch 339 in epoch 8, gen_loss = 0.4009166549233829, disc_loss = 0.07711091923445244
Trained batch 340 in epoch 8, gen_loss = 0.4007884616201574, disc_loss = 0.07722309455575962
Trained batch 341 in epoch 8, gen_loss = 0.4008140630192227, disc_loss = 0.07716309881431448
Trained batch 342 in epoch 8, gen_loss = 0.400583379991548, disc_loss = 0.07698208653930108
Trained batch 343 in epoch 8, gen_loss = 0.4007205193819002, disc_loss = 0.07678428364154168
Trained batch 344 in epoch 8, gen_loss = 0.4004455543946529, disc_loss = 0.07664511137223547
Trained batch 345 in epoch 8, gen_loss = 0.40055510849621945, disc_loss = 0.07662406984065266
Trained batch 346 in epoch 8, gen_loss = 0.40034232462517466, disc_loss = 0.07669277040835373
Trained batch 347 in epoch 8, gen_loss = 0.4006163651744525, disc_loss = 0.07649520691618024
Trained batch 348 in epoch 8, gen_loss = 0.4006009160789173, disc_loss = 0.07638257926724915
Trained batch 349 in epoch 8, gen_loss = 0.40057942714009964, disc_loss = 0.07621812657719212
Trained batch 350 in epoch 8, gen_loss = 0.40064640262527684, disc_loss = 0.07602807275149599
Trained batch 351 in epoch 8, gen_loss = 0.4006299185989933, disc_loss = 0.07589292494098614
Trained batch 352 in epoch 8, gen_loss = 0.4005668788895053, disc_loss = 0.07578962272634629
Trained batch 353 in epoch 8, gen_loss = 0.4006894156757721, disc_loss = 0.0757163570112533
Trained batch 354 in epoch 8, gen_loss = 0.4006284520659648, disc_loss = 0.07560638212008586
Trained batch 355 in epoch 8, gen_loss = 0.4007757851916752, disc_loss = 0.07542966064091855
Trained batch 356 in epoch 8, gen_loss = 0.4010753723419681, disc_loss = 0.0752813586566065
Trained batch 357 in epoch 8, gen_loss = 0.40133731708180304, disc_loss = 0.07512844586614832
Trained batch 358 in epoch 8, gen_loss = 0.40137763997970516, disc_loss = 0.07498686328597762
Trained batch 359 in epoch 8, gen_loss = 0.40107390218310884, disc_loss = 0.07497128521014626
Trained batch 360 in epoch 8, gen_loss = 0.40096980052641557, disc_loss = 0.07514906432763402
Trained batch 361 in epoch 8, gen_loss = 0.4011085344612269, disc_loss = 0.07565289389635359
Trained batch 362 in epoch 8, gen_loss = 0.4011266968795419, disc_loss = 0.07556809219801106
Trained batch 363 in epoch 8, gen_loss = 0.4009898352426487, disc_loss = 0.0755435617213332
Trained batch 364 in epoch 8, gen_loss = 0.40132575427016165, disc_loss = 0.07541723110113446
Trained batch 365 in epoch 8, gen_loss = 0.40128796625007046, disc_loss = 0.07525519093452784
Trained batch 366 in epoch 8, gen_loss = 0.4014381247417803, disc_loss = 0.07515114266806021
Trained batch 367 in epoch 8, gen_loss = 0.40125758200883865, disc_loss = 0.07503639104011793
Trained batch 368 in epoch 8, gen_loss = 0.4011061076872394, disc_loss = 0.0752375372130232
Trained batch 369 in epoch 8, gen_loss = 0.4008938395493739, disc_loss = 0.0764178445927698
Trained batch 370 in epoch 8, gen_loss = 0.40082865640159565, disc_loss = 0.07644985896482501
Trained batch 371 in epoch 8, gen_loss = 0.40101932293625286, disc_loss = 0.07633416651202346
Trained batch 372 in epoch 8, gen_loss = 0.40088936750435, disc_loss = 0.07639558158000936
Trained batch 373 in epoch 8, gen_loss = 0.400836669904663, disc_loss = 0.07649588132810027
Trained batch 374 in epoch 8, gen_loss = 0.4009538617928823, disc_loss = 0.07636410674576959
Trained batch 375 in epoch 8, gen_loss = 0.4005137872981264, disc_loss = 0.07693507190560922
Trained batch 376 in epoch 8, gen_loss = 0.40047346557483116, disc_loss = 0.07705247176030468
Trained batch 377 in epoch 8, gen_loss = 0.40024353224764425, disc_loss = 0.07704330333409999
Trained batch 378 in epoch 8, gen_loss = 0.40014945501387905, disc_loss = 0.07693400778647974
Trained batch 379 in epoch 8, gen_loss = 0.4000082397147229, disc_loss = 0.07690670208049644
Trained batch 380 in epoch 8, gen_loss = 0.40044725598312736, disc_loss = 0.07709144666091859
Trained batch 381 in epoch 8, gen_loss = 0.40055678254334715, disc_loss = 0.07690974552774343
Trained batch 382 in epoch 8, gen_loss = 0.40055772911163906, disc_loss = 0.07688753069171746
Trained batch 383 in epoch 8, gen_loss = 0.40046579864186543, disc_loss = 0.07678077679035293
Trained batch 384 in epoch 8, gen_loss = 0.40035431864973786, disc_loss = 0.07665593672132531
Trained batch 385 in epoch 8, gen_loss = 0.400389708076734, disc_loss = 0.07684441815719124
Trained batch 386 in epoch 8, gen_loss = 0.40023205770078557, disc_loss = 0.07775085688585498
Trained batch 387 in epoch 8, gen_loss = 0.4002363580403869, disc_loss = 0.07782237550133321
Trained batch 388 in epoch 8, gen_loss = 0.4001725429434396, disc_loss = 0.07772822319565863
Trained batch 389 in epoch 8, gen_loss = 0.40005670136366134, disc_loss = 0.07775010026824207
Trained batch 390 in epoch 8, gen_loss = 0.40019449805054824, disc_loss = 0.07766651686714471
Trained batch 391 in epoch 8, gen_loss = 0.4003549165719626, disc_loss = 0.07758775037566047
Trained batch 392 in epoch 8, gen_loss = 0.40028888487633857, disc_loss = 0.07771705003436323
Trained batch 393 in epoch 8, gen_loss = 0.40053016030546373, disc_loss = 0.07756346016578604
Trained batch 394 in epoch 8, gen_loss = 0.40072420669507375, disc_loss = 0.07740897068140816
Trained batch 395 in epoch 8, gen_loss = 0.40068818741675577, disc_loss = 0.07725629433072313
Trained batch 396 in epoch 8, gen_loss = 0.4006962172630752, disc_loss = 0.07711323207216127
Trained batch 397 in epoch 8, gen_loss = 0.40081454978216835, disc_loss = 0.07702509696763851
Trained batch 398 in epoch 8, gen_loss = 0.40092362250600544, disc_loss = 0.07692849997519738
Trained batch 399 in epoch 8, gen_loss = 0.4008509447425604, disc_loss = 0.07703062974964268
Trained batch 400 in epoch 8, gen_loss = 0.4008447513021436, disc_loss = 0.07752087750493031
Trained batch 401 in epoch 8, gen_loss = 0.40097026979152245, disc_loss = 0.07736314863860792
Trained batch 402 in epoch 8, gen_loss = 0.401089756423723, disc_loss = 0.07747927956195276
Trained batch 403 in epoch 8, gen_loss = 0.4009515882128536, disc_loss = 0.07739130021326503
Trained batch 404 in epoch 8, gen_loss = 0.400893051241651, disc_loss = 0.07722529304547258
Trained batch 405 in epoch 8, gen_loss = 0.40101969844014773, disc_loss = 0.07704980456123468
Trained batch 406 in epoch 8, gen_loss = 0.4010912644921708, disc_loss = 0.07689998659856745
Trained batch 407 in epoch 8, gen_loss = 0.4008719383501539, disc_loss = 0.07685887251464724
Trained batch 408 in epoch 8, gen_loss = 0.4009980751716129, disc_loss = 0.07673156499056587
Trained batch 409 in epoch 8, gen_loss = 0.4006392691193557, disc_loss = 0.07690372336996583
Trained batch 410 in epoch 8, gen_loss = 0.4007867902444807, disc_loss = 0.07754503949058135
Trained batch 411 in epoch 8, gen_loss = 0.4009053462628022, disc_loss = 0.07741454510284967
Trained batch 412 in epoch 8, gen_loss = 0.4006506989712288, disc_loss = 0.07748956697684042
Trained batch 413 in epoch 8, gen_loss = 0.4005324022781446, disc_loss = 0.07743083357086612
Trained batch 414 in epoch 8, gen_loss = 0.40039995262421757, disc_loss = 0.07727808670353997
Trained batch 415 in epoch 8, gen_loss = 0.4003334655784644, disc_loss = 0.07720524208651533
Trained batch 416 in epoch 8, gen_loss = 0.40044268651260173, disc_loss = 0.07706107189700151
Trained batch 417 in epoch 8, gen_loss = 0.40042930577645464, disc_loss = 0.07692547994398437
Trained batch 418 in epoch 8, gen_loss = 0.4002426984344291, disc_loss = 0.0769914198024443
Trained batch 419 in epoch 8, gen_loss = 0.4001067436876751, disc_loss = 0.07761409651554589
Trained batch 420 in epoch 8, gen_loss = 0.4002336927660854, disc_loss = 0.077790003879363
Trained batch 421 in epoch 8, gen_loss = 0.4002532669435745, disc_loss = 0.07768072103044256
Trained batch 422 in epoch 8, gen_loss = 0.4003068032557801, disc_loss = 0.0775680539339129
Trained batch 423 in epoch 8, gen_loss = 0.4001444674466016, disc_loss = 0.07788337677396517
Trained batch 424 in epoch 8, gen_loss = 0.400266355416354, disc_loss = 0.07830960408620098
Trained batch 425 in epoch 8, gen_loss = 0.400224067305735, disc_loss = 0.07825660089822267
Trained batch 426 in epoch 8, gen_loss = 0.40016982245501087, disc_loss = 0.07820980100667832
Trained batch 427 in epoch 8, gen_loss = 0.40025179902805347, disc_loss = 0.07813086757484267
Trained batch 428 in epoch 8, gen_loss = 0.40015032463696176, disc_loss = 0.07812673480321582
Trained batch 429 in epoch 8, gen_loss = 0.40009974061056625, disc_loss = 0.07799690674102411
Trained batch 430 in epoch 8, gen_loss = 0.400242291442756, disc_loss = 0.07800129885631862
Trained batch 431 in epoch 8, gen_loss = 0.40031156268108775, disc_loss = 0.07829737590725051
Trained batch 432 in epoch 8, gen_loss = 0.40050055943515506, disc_loss = 0.07820029249500836
Trained batch 433 in epoch 8, gen_loss = 0.4004158216962067, disc_loss = 0.07804509090830482
Trained batch 434 in epoch 8, gen_loss = 0.40049865821312214, disc_loss = 0.07791068273350255
Trained batch 435 in epoch 8, gen_loss = 0.40034180838580524, disc_loss = 0.07795226066736419
Trained batch 436 in epoch 8, gen_loss = 0.4004023836870215, disc_loss = 0.07795350253901677
Trained batch 437 in epoch 8, gen_loss = 0.4004126479636589, disc_loss = 0.07791252587666761
Trained batch 438 in epoch 8, gen_loss = 0.40037213893849105, disc_loss = 0.07775486063674636
Trained batch 439 in epoch 8, gen_loss = 0.4004551916637204, disc_loss = 0.07759908948157151
Trained batch 440 in epoch 8, gen_loss = 0.40049604980313047, disc_loss = 0.07746615433904962
Trained batch 441 in epoch 8, gen_loss = 0.40030683395010314, disc_loss = 0.07747130460796954
Trained batch 442 in epoch 8, gen_loss = 0.40021002258996125, disc_loss = 0.07751837423971053
Trained batch 443 in epoch 8, gen_loss = 0.40011854020056425, disc_loss = 0.07764621271000889
Trained batch 444 in epoch 8, gen_loss = 0.4001322048433711, disc_loss = 0.07780084302648901
Trained batch 445 in epoch 8, gen_loss = 0.3999088822191606, disc_loss = 0.07770681282559685
Trained batch 446 in epoch 8, gen_loss = 0.3999788991823559, disc_loss = 0.07757865879955542
Trained batch 447 in epoch 8, gen_loss = 0.39992140852180974, disc_loss = 0.07751013190448118
Trained batch 448 in epoch 8, gen_loss = 0.3999255099779779, disc_loss = 0.07737717443023433
Trained batch 449 in epoch 8, gen_loss = 0.40004875944720375, disc_loss = 0.07787093896729251
Trained batch 450 in epoch 8, gen_loss = 0.39981550361523344, disc_loss = 0.0790771049604299
Trained batch 451 in epoch 8, gen_loss = 0.3998260149254208, disc_loss = 0.0790805842931407
Trained batch 452 in epoch 8, gen_loss = 0.3997081143834996, disc_loss = 0.07917978551144204
Trained batch 453 in epoch 8, gen_loss = 0.3997399562124639, disc_loss = 0.07920165088269777
Trained batch 454 in epoch 8, gen_loss = 0.39974152917390343, disc_loss = 0.07915922531776212
Trained batch 455 in epoch 8, gen_loss = 0.39987012606702355, disc_loss = 0.07907049614311147
Trained batch 456 in epoch 8, gen_loss = 0.39978606591339444, disc_loss = 0.07951813396494388
Trained batch 457 in epoch 8, gen_loss = 0.3999120446662195, disc_loss = 0.07957486442176373
Trained batch 458 in epoch 8, gen_loss = 0.40036338769013063, disc_loss = 0.07947421966583218
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 0.32604074478149414, disc_loss = 0.027387022972106934
Trained batch 1 in epoch 9, gen_loss = 0.36364609003067017, disc_loss = 0.039096567779779434
Trained batch 2 in epoch 9, gen_loss = 0.38380923867225647, disc_loss = 0.034249535451332726
Trained batch 3 in epoch 9, gen_loss = 0.3854760155081749, disc_loss = 0.03723341226577759
Trained batch 4 in epoch 9, gen_loss = 0.38375030755996703, disc_loss = 0.07253812849521638
Trained batch 5 in epoch 9, gen_loss = 0.3916788200537364, disc_loss = 0.11252273867527644
Trained batch 6 in epoch 9, gen_loss = 0.40136063524654936, disc_loss = 0.10434963394488607
Trained batch 7 in epoch 9, gen_loss = 0.3960862122476101, disc_loss = 0.10011555952951312
Trained batch 8 in epoch 9, gen_loss = 0.39181503984663224, disc_loss = 0.11597322548429172
Trained batch 9 in epoch 9, gen_loss = 0.39931440353393555, disc_loss = 0.12245571427047253
Trained batch 10 in epoch 9, gen_loss = 0.39937525445764716, disc_loss = 0.11289461397311905
Trained batch 11 in epoch 9, gen_loss = 0.3939129561185837, disc_loss = 0.10719538728396098
Trained batch 12 in epoch 9, gen_loss = 0.39081038190768314, disc_loss = 0.1014632571202058
Trained batch 13 in epoch 9, gen_loss = 0.3947031263794218, disc_loss = 0.09654433466494083
Trained batch 14 in epoch 9, gen_loss = 0.39784546891848244, disc_loss = 0.09393237829208374
Trained batch 15 in epoch 9, gen_loss = 0.39088934287428856, disc_loss = 0.09974133037030697
Trained batch 16 in epoch 9, gen_loss = 0.3956066632972044, disc_loss = 0.09743306522860247
Trained batch 17 in epoch 9, gen_loss = 0.398391960395707, disc_loss = 0.09453437042733033
Trained batch 18 in epoch 9, gen_loss = 0.3998997227141732, disc_loss = 0.0909006328959214
Trained batch 19 in epoch 9, gen_loss = 0.3961537882685661, disc_loss = 0.09132368490099907
Trained batch 20 in epoch 9, gen_loss = 0.39523873868442716, disc_loss = 0.08828431190479369
Trained batch 21 in epoch 9, gen_loss = 0.4008767835118554, disc_loss = 0.08809629184278575
Trained batch 22 in epoch 9, gen_loss = 0.39954872105432593, disc_loss = 0.0861488911120788
Trained batch 23 in epoch 9, gen_loss = 0.40002481266856194, disc_loss = 0.08551951156308253
Trained batch 24 in epoch 9, gen_loss = 0.39959214329719545, disc_loss = 0.08744416803121567
Trained batch 25 in epoch 9, gen_loss = 0.4006684491267571, disc_loss = 0.08701959940103385
Trained batch 26 in epoch 9, gen_loss = 0.3982457794525005, disc_loss = 0.08885532838326914
Trained batch 27 in epoch 9, gen_loss = 0.3987214320472309, disc_loss = 0.08927967718669347
Trained batch 28 in epoch 9, gen_loss = 0.40105468445810777, disc_loss = 0.08703493224135761
Trained batch 29 in epoch 9, gen_loss = 0.3993747671445211, disc_loss = 0.08595363224546114
Trained batch 30 in epoch 9, gen_loss = 0.3993345383674868, disc_loss = 0.08363882431219663
Trained batch 31 in epoch 9, gen_loss = 0.39968535117805004, disc_loss = 0.08143278316128999
Trained batch 32 in epoch 9, gen_loss = 0.4004429569750121, disc_loss = 0.0793604353499232
Trained batch 33 in epoch 9, gen_loss = 0.3997327124371248, disc_loss = 0.07891146657878861
Trained batch 34 in epoch 9, gen_loss = 0.3977225797516959, disc_loss = 0.07947217050407614
Trained batch 35 in epoch 9, gen_loss = 0.3994499262836244, disc_loss = 0.07993746585109168
Trained batch 36 in epoch 9, gen_loss = 0.40200268577884984, disc_loss = 0.07881705820359089
Trained batch 37 in epoch 9, gen_loss = 0.4027186977235894, disc_loss = 0.07794636267384417
Trained batch 38 in epoch 9, gen_loss = 0.4024377709779984, disc_loss = 0.07609233953870642
Trained batch 39 in epoch 9, gen_loss = 0.4025153428316116, disc_loss = 0.07458560034865513
Trained batch 40 in epoch 9, gen_loss = 0.39936711075829295, disc_loss = 0.07542930576359717
Trained batch 41 in epoch 9, gen_loss = 0.40067319359098164, disc_loss = 0.07589873881079257
Trained batch 42 in epoch 9, gen_loss = 0.40129596618718877, disc_loss = 0.07426141892278264
Trained batch 43 in epoch 9, gen_loss = 0.40079508044502954, disc_loss = 0.07425690489948135
Trained batch 44 in epoch 9, gen_loss = 0.4022152450349596, disc_loss = 0.07318043821594782
Trained batch 45 in epoch 9, gen_loss = 0.40272339984126715, disc_loss = 0.07316667648315754
Trained batch 46 in epoch 9, gen_loss = 0.4040904203627972, disc_loss = 0.07271524967546476
Trained batch 47 in epoch 9, gen_loss = 0.4043801079193751, disc_loss = 0.07198204477511656
Trained batch 48 in epoch 9, gen_loss = 0.4052310032503946, disc_loss = 0.07067136397129115
Trained batch 49 in epoch 9, gen_loss = 0.40589584469795226, disc_loss = 0.07042397721670568
Trained batch 50 in epoch 9, gen_loss = 0.4051591327377394, disc_loss = 0.0716659147566294
Trained batch 51 in epoch 9, gen_loss = 0.40656432108237195, disc_loss = 0.07047758442170632
Trained batch 52 in epoch 9, gen_loss = 0.40699281332627785, disc_loss = 0.06948641221091714
Trained batch 53 in epoch 9, gen_loss = 0.4075271581058149, disc_loss = 0.06857347941129571
Trained batch 54 in epoch 9, gen_loss = 0.40663239305669613, disc_loss = 0.06799829491329464
Trained batch 55 in epoch 9, gen_loss = 0.40584090085966246, disc_loss = 0.0671540900283227
Trained batch 56 in epoch 9, gen_loss = 0.40649362980273734, disc_loss = 0.06850029002842412
Trained batch 57 in epoch 9, gen_loss = 0.404656850058457, disc_loss = 0.07563977788908985
Trained batch 58 in epoch 9, gen_loss = 0.4050019024792364, disc_loss = 0.075698802129255
Trained batch 59 in epoch 9, gen_loss = 0.4031984205047289, disc_loss = 0.07742102851625532
Trained batch 60 in epoch 9, gen_loss = 0.4026221188365436, disc_loss = 0.07739938952059286
Trained batch 61 in epoch 9, gen_loss = 0.4016545621618148, disc_loss = 0.08102432888511929
Trained batch 62 in epoch 9, gen_loss = 0.4044127516330235, disc_loss = 0.08053847678035261
Trained batch 63 in epoch 9, gen_loss = 0.4049625741317868, disc_loss = 0.08042039935389766
Trained batch 64 in epoch 9, gen_loss = 0.40578923408801737, disc_loss = 0.07952398483713086
Trained batch 65 in epoch 9, gen_loss = 0.40536907766804553, disc_loss = 0.07945269761804605
Trained batch 66 in epoch 9, gen_loss = 0.4050444409028808, disc_loss = 0.07843504657746474
Trained batch 67 in epoch 9, gen_loss = 0.4049922333044164, disc_loss = 0.07757109831607736
Trained batch 68 in epoch 9, gen_loss = 0.40525226662124414, disc_loss = 0.07690656947079992
Trained batch 69 in epoch 9, gen_loss = 0.4048302412033081, disc_loss = 0.07614984262867698
Trained batch 70 in epoch 9, gen_loss = 0.40592748640288767, disc_loss = 0.0756165306083858
Trained batch 71 in epoch 9, gen_loss = 0.4056354955666595, disc_loss = 0.0752417823467921
Trained batch 72 in epoch 9, gen_loss = 0.4049701204855148, disc_loss = 0.07566986014198972
Trained batch 73 in epoch 9, gen_loss = 0.4054287152515875, disc_loss = 0.07777391087792411
Trained batch 74 in epoch 9, gen_loss = 0.40564181089401247, disc_loss = 0.0770325191381077
Trained batch 75 in epoch 9, gen_loss = 0.4056967324332187, disc_loss = 0.07645367797292572
Trained batch 76 in epoch 9, gen_loss = 0.40546546431330893, disc_loss = 0.07556602304994867
Trained batch 77 in epoch 9, gen_loss = 0.4055768996477127, disc_loss = 0.07470647555489379
Trained batch 78 in epoch 9, gen_loss = 0.40547143922576423, disc_loss = 0.07391456077818441
Trained batch 79 in epoch 9, gen_loss = 0.40480845235288143, disc_loss = 0.07339657500269822
Trained batch 80 in epoch 9, gen_loss = 0.4044527323157699, disc_loss = 0.07288543513780575
Trained batch 81 in epoch 9, gen_loss = 0.4042574098197425, disc_loss = 0.07286842905053097
Trained batch 82 in epoch 9, gen_loss = 0.40364691758730326, disc_loss = 0.07304934351087873
Trained batch 83 in epoch 9, gen_loss = 0.4041991826324236, disc_loss = 0.07308287689617525
Trained batch 84 in epoch 9, gen_loss = 0.40389365238301894, disc_loss = 0.07336849545621697
Trained batch 85 in epoch 9, gen_loss = 0.40344187201455584, disc_loss = 0.07310281119439317
Trained batch 86 in epoch 9, gen_loss = 0.40387850314721296, disc_loss = 0.07244322388486445
Trained batch 87 in epoch 9, gen_loss = 0.40357760238376533, disc_loss = 0.07168658870928497
Trained batch 88 in epoch 9, gen_loss = 0.40328216921077686, disc_loss = 0.07102857131950474
Trained batch 89 in epoch 9, gen_loss = 0.40321919951173996, disc_loss = 0.0703809273067034
Trained batch 90 in epoch 9, gen_loss = 0.4036974540123573, disc_loss = 0.07013696548273111
Trained batch 91 in epoch 9, gen_loss = 0.40389179989047674, disc_loss = 0.06967172433075536
Trained batch 92 in epoch 9, gen_loss = 0.4028185849548668, disc_loss = 0.07317369104292924
Trained batch 93 in epoch 9, gen_loss = 0.4026065982402639, disc_loss = 0.07568133306848084
Trained batch 94 in epoch 9, gen_loss = 0.40306950274266695, disc_loss = 0.07500713999432168
Trained batch 95 in epoch 9, gen_loss = 0.40315754277010757, disc_loss = 0.07459560074009157
Trained batch 96 in epoch 9, gen_loss = 0.40282583451762644, disc_loss = 0.07445072903557076
Trained batch 97 in epoch 9, gen_loss = 0.4030168512646033, disc_loss = 0.07471883934162253
Trained batch 98 in epoch 9, gen_loss = 0.4025882241701839, disc_loss = 0.0774104905107783
Trained batch 99 in epoch 9, gen_loss = 0.4023979789018631, disc_loss = 0.07721720455680042
Trained batch 100 in epoch 9, gen_loss = 0.40259634445209314, disc_loss = 0.07719954950181712
Trained batch 101 in epoch 9, gen_loss = 0.4024864987415426, disc_loss = 0.07679597060561326
Trained batch 102 in epoch 9, gen_loss = 0.40199296248769295, disc_loss = 0.07654657343728016
Trained batch 103 in epoch 9, gen_loss = 0.40213956425969416, disc_loss = 0.07653289093510605
Trained batch 104 in epoch 9, gen_loss = 0.40055783774171555, disc_loss = 0.0768975127887513
Trained batch 105 in epoch 9, gen_loss = 0.4000565450427667, disc_loss = 0.07718148882465684
Trained batch 106 in epoch 9, gen_loss = 0.3998023211677498, disc_loss = 0.07653433697681143
Trained batch 107 in epoch 9, gen_loss = 0.40032302436453326, disc_loss = 0.0763578847852639
Trained batch 108 in epoch 9, gen_loss = 0.4003405093873313, disc_loss = 0.07660017959312151
Trained batch 109 in epoch 9, gen_loss = 0.40032649839466267, disc_loss = 0.0787890066858381
Trained batch 110 in epoch 9, gen_loss = 0.40166119721021737, disc_loss = 0.07852404927499257
Trained batch 111 in epoch 9, gen_loss = 0.4011690229443567, disc_loss = 0.07925410895092812
Trained batch 112 in epoch 9, gen_loss = 0.40160858011351225, disc_loss = 0.07862859026866809
Trained batch 113 in epoch 9, gen_loss = 0.40189229252568465, disc_loss = 0.07825155342569608
Trained batch 114 in epoch 9, gen_loss = 0.4013741497112357, disc_loss = 0.07762596905636399
Trained batch 115 in epoch 9, gen_loss = 0.40081351314639224, disc_loss = 0.07716352281016137
Trained batch 116 in epoch 9, gen_loss = 0.39969952608275616, disc_loss = 0.07766546595953086
Trained batch 117 in epoch 9, gen_loss = 0.39937021229731834, disc_loss = 0.07909750099041325
Trained batch 118 in epoch 9, gen_loss = 0.39888459957447375, disc_loss = 0.0786002921840536
Trained batch 119 in epoch 9, gen_loss = 0.39854357950389385, disc_loss = 0.07818367414874956
Trained batch 120 in epoch 9, gen_loss = 0.3991713392094147, disc_loss = 0.07789806321586583
Trained batch 121 in epoch 9, gen_loss = 0.3990517560331548, disc_loss = 0.07763300386074258
Trained batch 122 in epoch 9, gen_loss = 0.39929501300420217, disc_loss = 0.07718305408242877
Trained batch 123 in epoch 9, gen_loss = 0.3993182145059109, disc_loss = 0.07674273052778575
Trained batch 124 in epoch 9, gen_loss = 0.39927864730358126, disc_loss = 0.07623456417396665
Trained batch 125 in epoch 9, gen_loss = 0.3996324154829222, disc_loss = 0.07618953038140067
Trained batch 126 in epoch 9, gen_loss = 0.39903556303245813, disc_loss = 0.07955591989622458
Trained batch 127 in epoch 9, gen_loss = 0.399465509573929, disc_loss = 0.07954847636938212
Trained batch 128 in epoch 9, gen_loss = 0.39964441215807156, disc_loss = 0.07964110321386955
Trained batch 129 in epoch 9, gen_loss = 0.39892053798987315, disc_loss = 0.08141723268378813
Trained batch 130 in epoch 9, gen_loss = 0.39940610198119214, disc_loss = 0.0810956027223693
Trained batch 131 in epoch 9, gen_loss = 0.3994585687689709, disc_loss = 0.08101514533909997
Trained batch 132 in epoch 9, gen_loss = 0.39969262716017273, disc_loss = 0.08098184781261068
Trained batch 133 in epoch 9, gen_loss = 0.39996575697589276, disc_loss = 0.08093928400107395
Trained batch 134 in epoch 9, gen_loss = 0.40015269109496365, disc_loss = 0.08094668111384466
Trained batch 135 in epoch 9, gen_loss = 0.40007052055614833, disc_loss = 0.08112819217871327
Trained batch 136 in epoch 9, gen_loss = 0.3993496460853702, disc_loss = 0.08087076463253938
Trained batch 137 in epoch 9, gen_loss = 0.39975404901349026, disc_loss = 0.08039701352422328
Trained batch 138 in epoch 9, gen_loss = 0.4001220030535897, disc_loss = 0.07990392416434215
Trained batch 139 in epoch 9, gen_loss = 0.399843993889434, disc_loss = 0.07946994691488467
Trained batch 140 in epoch 9, gen_loss = 0.39992010413754914, disc_loss = 0.07898093353468158
Trained batch 141 in epoch 9, gen_loss = 0.3998323753476143, disc_loss = 0.0788400772939318
Trained batch 142 in epoch 9, gen_loss = 0.3993269316591583, disc_loss = 0.07961603129360746
Trained batch 143 in epoch 9, gen_loss = 0.3996637369402581, disc_loss = 0.08063534725159924
Trained batch 144 in epoch 9, gen_loss = 0.39916915944938003, disc_loss = 0.08022250908523285
Trained batch 145 in epoch 9, gen_loss = 0.39960955399764725, disc_loss = 0.07978292519213913
Trained batch 146 in epoch 9, gen_loss = 0.3997525233192509, disc_loss = 0.07937228265630246
Trained batch 147 in epoch 9, gen_loss = 0.3997242612814581, disc_loss = 0.07919303248825206
Trained batch 148 in epoch 9, gen_loss = 0.40007312995875444, disc_loss = 0.07970429778461588
Trained batch 149 in epoch 9, gen_loss = 0.39972997436920804, disc_loss = 0.08195964149199426
Trained batch 150 in epoch 9, gen_loss = 0.39995230714611657, disc_loss = 0.08202662646141372
Trained batch 151 in epoch 9, gen_loss = 0.3999217157497218, disc_loss = 0.08217463300771717
Trained batch 152 in epoch 9, gen_loss = 0.39980913289621767, disc_loss = 0.0818856104971001
Trained batch 153 in epoch 9, gen_loss = 0.39947975949420556, disc_loss = 0.08196184640544672
Trained batch 154 in epoch 9, gen_loss = 0.400034848047841, disc_loss = 0.08169874237970479
Trained batch 155 in epoch 9, gen_loss = 0.3997995355763497, disc_loss = 0.08269522851631524
Trained batch 156 in epoch 9, gen_loss = 0.3993495346824075, disc_loss = 0.08514626539211459
Trained batch 157 in epoch 9, gen_loss = 0.3991935465343391, disc_loss = 0.08518785206730702
Trained batch 158 in epoch 9, gen_loss = 0.3993442878595688, disc_loss = 0.08515453415061787
Trained batch 159 in epoch 9, gen_loss = 0.399480985570699, disc_loss = 0.08486141251923981
Trained batch 160 in epoch 9, gen_loss = 0.3992459038214654, disc_loss = 0.08459004957911483
Trained batch 161 in epoch 9, gen_loss = 0.3990597839892646, disc_loss = 0.08451467714801339
Trained batch 162 in epoch 9, gen_loss = 0.39935707817414057, disc_loss = 0.08429709411986126
Trained batch 163 in epoch 9, gen_loss = 0.40021642815412545, disc_loss = 0.08407110531485026
Trained batch 164 in epoch 9, gen_loss = 0.39955871927015707, disc_loss = 0.08487144854540626
Trained batch 165 in epoch 9, gen_loss = 0.39954499334815036, disc_loss = 0.08524777723689485
Trained batch 166 in epoch 9, gen_loss = 0.3993122864090754, disc_loss = 0.08522070486176603
Trained batch 167 in epoch 9, gen_loss = 0.39953554625667276, disc_loss = 0.0848578734328926
Trained batch 168 in epoch 9, gen_loss = 0.3992620294792412, disc_loss = 0.08453891192943122
Trained batch 169 in epoch 9, gen_loss = 0.39915524379295464, disc_loss = 0.0842345196123728
Trained batch 170 in epoch 9, gen_loss = 0.3988215629643167, disc_loss = 0.08410715969954753
Trained batch 171 in epoch 9, gen_loss = 0.3988580318211123, disc_loss = 0.08395861544332273
Trained batch 172 in epoch 9, gen_loss = 0.3989359580540244, disc_loss = 0.08400377734817263
Trained batch 173 in epoch 9, gen_loss = 0.3987284029523532, disc_loss = 0.08428560540176414
Trained batch 174 in epoch 9, gen_loss = 0.3987086935554232, disc_loss = 0.08430318773058908
Trained batch 175 in epoch 9, gen_loss = 0.39828218443488533, disc_loss = 0.08508587400270202
Trained batch 176 in epoch 9, gen_loss = 0.398786986194088, disc_loss = 0.08547389364438289
Trained batch 177 in epoch 9, gen_loss = 0.39913695807872196, disc_loss = 0.0850469760486877
Trained batch 178 in epoch 9, gen_loss = 0.3987243451053204, disc_loss = 0.08474195438213439
Trained batch 179 in epoch 9, gen_loss = 0.39829009630613854, disc_loss = 0.08446301993551768
Trained batch 180 in epoch 9, gen_loss = 0.3982273238963185, disc_loss = 0.08423327928079673
Trained batch 181 in epoch 9, gen_loss = 0.39821025049620934, disc_loss = 0.08393496992117674
Trained batch 182 in epoch 9, gen_loss = 0.39851208698879825, disc_loss = 0.08378325949061682
Trained batch 183 in epoch 9, gen_loss = 0.3978730892843526, disc_loss = 0.08427327021743859
Trained batch 184 in epoch 9, gen_loss = 0.39817415838306014, disc_loss = 0.08456098534720573
Trained batch 185 in epoch 9, gen_loss = 0.3982962476470137, disc_loss = 0.08419251112237332
Trained batch 186 in epoch 9, gen_loss = 0.39781160812008187, disc_loss = 0.0840011669228222
Trained batch 187 in epoch 9, gen_loss = 0.39787717171488923, disc_loss = 0.0836341771956018
Trained batch 188 in epoch 9, gen_loss = 0.39788868999670424, disc_loss = 0.08324388124137408
Trained batch 189 in epoch 9, gen_loss = 0.3980212524533272, disc_loss = 0.08286451987775141
Trained batch 190 in epoch 9, gen_loss = 0.39768603670347424, disc_loss = 0.08259585226949363
Trained batch 191 in epoch 9, gen_loss = 0.39751141557159525, disc_loss = 0.08233951812386901
Trained batch 192 in epoch 9, gen_loss = 0.39733107202720147, disc_loss = 0.08212033572601916
Trained batch 193 in epoch 9, gen_loss = 0.3973154286594735, disc_loss = 0.08202264859513908
Trained batch 194 in epoch 9, gen_loss = 0.39765983460805354, disc_loss = 0.08172510230245117
Trained batch 195 in epoch 9, gen_loss = 0.39839518929318507, disc_loss = 0.08170258157116798
Trained batch 196 in epoch 9, gen_loss = 0.3987362328065833, disc_loss = 0.08133162378669163
Trained batch 197 in epoch 9, gen_loss = 0.39899341844850117, disc_loss = 0.08109105689065399
Trained batch 198 in epoch 9, gen_loss = 0.3990896575564715, disc_loss = 0.08074159195047602
Trained batch 199 in epoch 9, gen_loss = 0.39913506515324115, disc_loss = 0.0803731210413389
Trained batch 200 in epoch 9, gen_loss = 0.3988546285018399, disc_loss = 0.08002759368663923
Trained batch 201 in epoch 9, gen_loss = 0.3991286874850198, disc_loss = 0.07984417015548316
Trained batch 202 in epoch 9, gen_loss = 0.3996251444951654, disc_loss = 0.08022872166561303
Trained batch 203 in epoch 9, gen_loss = 0.39938850985730395, disc_loss = 0.08010229726513739
Trained batch 204 in epoch 9, gen_loss = 0.3992900597613032, disc_loss = 0.08023121032364121
Trained batch 205 in epoch 9, gen_loss = 0.40012309931724976, disc_loss = 0.08072630738052856
Trained batch 206 in epoch 9, gen_loss = 0.4001791231730134, disc_loss = 0.0805902170345799
Trained batch 207 in epoch 9, gen_loss = 0.4002746782767085, disc_loss = 0.08053318649987116
Trained batch 208 in epoch 9, gen_loss = 0.4001703970312502, disc_loss = 0.08022257713066262
Trained batch 209 in epoch 9, gen_loss = 0.3998579551066671, disc_loss = 0.07987785008292468
Trained batch 210 in epoch 9, gen_loss = 0.3997278753756347, disc_loss = 0.07960616171986783
Trained batch 211 in epoch 9, gen_loss = 0.3998041329378227, disc_loss = 0.07936623296041463
Trained batch 212 in epoch 9, gen_loss = 0.39958238874522733, disc_loss = 0.0800722607700023
Trained batch 213 in epoch 9, gen_loss = 0.3993630833297132, disc_loss = 0.08115024457981583
Trained batch 214 in epoch 9, gen_loss = 0.39900088691434193, disc_loss = 0.0816909057174831
Trained batch 215 in epoch 9, gen_loss = 0.39902151051770757, disc_loss = 0.08177691160623606
Trained batch 216 in epoch 9, gen_loss = 0.3992254841849551, disc_loss = 0.08245522114083445
Trained batch 217 in epoch 9, gen_loss = 0.39864647094536265, disc_loss = 0.08303364380604562
Trained batch 218 in epoch 9, gen_loss = 0.3985680275720004, disc_loss = 0.08314511289428834
Trained batch 219 in epoch 9, gen_loss = 0.3982327894053676, disc_loss = 0.08297856105279855
Trained batch 220 in epoch 9, gen_loss = 0.3980790003797048, disc_loss = 0.08276373332332634
Trained batch 221 in epoch 9, gen_loss = 0.39811365648701386, disc_loss = 0.08260626388453618
Trained batch 222 in epoch 9, gen_loss = 0.3983014775899494, disc_loss = 0.08246502850513755
Trained batch 223 in epoch 9, gen_loss = 0.39827141012730344, disc_loss = 0.08227404200962544
Trained batch 224 in epoch 9, gen_loss = 0.39845679687129126, disc_loss = 0.08202323829755187
Trained batch 225 in epoch 9, gen_loss = 0.3981311216422942, disc_loss = 0.08225425598788512
Trained batch 226 in epoch 9, gen_loss = 0.39778566472068233, disc_loss = 0.08247803711837018
Trained batch 227 in epoch 9, gen_loss = 0.398114465503839, disc_loss = 0.08233643379348346
Trained batch 228 in epoch 9, gen_loss = 0.3982551828612407, disc_loss = 0.08224575051338326
Trained batch 229 in epoch 9, gen_loss = 0.3979037367131399, disc_loss = 0.08219189898758802
Trained batch 230 in epoch 9, gen_loss = 0.3981145126866056, disc_loss = 0.08191029100731273
Trained batch 231 in epoch 9, gen_loss = 0.39809384640177775, disc_loss = 0.08158444959654249
Trained batch 232 in epoch 9, gen_loss = 0.39810509736701655, disc_loss = 0.08127674638281693
Trained batch 233 in epoch 9, gen_loss = 0.39847798524504036, disc_loss = 0.08098967837440407
Trained batch 234 in epoch 9, gen_loss = 0.39838073792609763, disc_loss = 0.0807998176505591
Trained batch 235 in epoch 9, gen_loss = 0.3984409558697272, disc_loss = 0.08052715688344028
Trained batch 236 in epoch 9, gen_loss = 0.3982850019564608, disc_loss = 0.08035914924483008
Trained batch 237 in epoch 9, gen_loss = 0.3982763862033852, disc_loss = 0.0804602624065861
Trained batch 238 in epoch 9, gen_loss = 0.39787420898551223, disc_loss = 0.08172564651957366
Trained batch 239 in epoch 9, gen_loss = 0.39802159933994213, disc_loss = 0.08169508813104281
Trained batch 240 in epoch 9, gen_loss = 0.3983601326146066, disc_loss = 0.08161816774593102
Trained batch 241 in epoch 9, gen_loss = 0.398504777080264, disc_loss = 0.08159312994550329
Trained batch 242 in epoch 9, gen_loss = 0.39867194315778864, disc_loss = 0.08154707369030503
Trained batch 243 in epoch 9, gen_loss = 0.3987489030620114, disc_loss = 0.08182594590041725
Trained batch 244 in epoch 9, gen_loss = 0.3987835918762246, disc_loss = 0.08191188772266009
Trained batch 245 in epoch 9, gen_loss = 0.39873356808249544, disc_loss = 0.08165045219617403
Trained batch 246 in epoch 9, gen_loss = 0.3984222751759324, disc_loss = 0.08153955247026948
Trained batch 247 in epoch 9, gen_loss = 0.39854991574200893, disc_loss = 0.08147570001892745
Trained batch 248 in epoch 9, gen_loss = 0.3984035217019928, disc_loss = 0.08132160356993895
Trained batch 249 in epoch 9, gen_loss = 0.39873418837785723, disc_loss = 0.08110181968659162
Trained batch 250 in epoch 9, gen_loss = 0.39844475579689226, disc_loss = 0.08105281368640077
Trained batch 251 in epoch 9, gen_loss = 0.39861959544202635, disc_loss = 0.08158027900323744
Trained batch 252 in epoch 9, gen_loss = 0.39821797532761993, disc_loss = 0.08222099672634847
Trained batch 253 in epoch 9, gen_loss = 0.3983127051803071, disc_loss = 0.08201685266231927
Trained batch 254 in epoch 9, gen_loss = 0.3984322668874965, disc_loss = 0.0820062796274821
Trained batch 255 in epoch 9, gen_loss = 0.39812323538353667, disc_loss = 0.08179980330169201
Trained batch 256 in epoch 9, gen_loss = 0.3979666313656573, disc_loss = 0.08213061888626114
Trained batch 257 in epoch 9, gen_loss = 0.3982668828017028, disc_loss = 0.0822955656421277
Trained batch 258 in epoch 9, gen_loss = 0.39818061082749756, disc_loss = 0.08201092405740934
Trained batch 259 in epoch 9, gen_loss = 0.398358916835143, disc_loss = 0.08184143306615833
Trained batch 260 in epoch 9, gen_loss = 0.3979553207469626, disc_loss = 0.0818122465384703
Trained batch 261 in epoch 9, gen_loss = 0.39775487206136906, disc_loss = 0.0815767704239044
Trained batch 262 in epoch 9, gen_loss = 0.397487759873441, disc_loss = 0.08153665233970028
Trained batch 263 in epoch 9, gen_loss = 0.3973079308528792, disc_loss = 0.08199727019845424
Trained batch 264 in epoch 9, gen_loss = 0.39752188319305204, disc_loss = 0.08236025406996597
Trained batch 265 in epoch 9, gen_loss = 0.3975104754020397, disc_loss = 0.08241689060569594
Trained batch 266 in epoch 9, gen_loss = 0.39749084346080094, disc_loss = 0.08233768904184023
Trained batch 267 in epoch 9, gen_loss = 0.39744069088083595, disc_loss = 0.08237877419677132
Trained batch 268 in epoch 9, gen_loss = 0.397163132697233, disc_loss = 0.08231191745297949
Trained batch 269 in epoch 9, gen_loss = 0.39717536717653273, disc_loss = 0.08226622269592351
Trained batch 270 in epoch 9, gen_loss = 0.3975765851920821, disc_loss = 0.08224138387606043
Trained batch 271 in epoch 9, gen_loss = 0.3975357991259764, disc_loss = 0.08210842952008962
Trained batch 272 in epoch 9, gen_loss = 0.39743760703029213, disc_loss = 0.08201589156624489
Trained batch 273 in epoch 9, gen_loss = 0.39750052243471146, disc_loss = 0.08202081551285882
Trained batch 274 in epoch 9, gen_loss = 0.39761868742379275, disc_loss = 0.08306850435720249
Trained batch 275 in epoch 9, gen_loss = 0.39738071866441466, disc_loss = 0.08378881380380387
Trained batch 276 in epoch 9, gen_loss = 0.39724926521416604, disc_loss = 0.08368876172626384
Trained batch 277 in epoch 9, gen_loss = 0.39748865489265045, disc_loss = 0.08347699033069632
Trained batch 278 in epoch 9, gen_loss = 0.3977348943871836, disc_loss = 0.08324423640979768
Trained batch 279 in epoch 9, gen_loss = 0.397363867983222, disc_loss = 0.08332335667219012
Trained batch 280 in epoch 9, gen_loss = 0.39759872249224854, disc_loss = 0.08332284850489309
Trained batch 281 in epoch 9, gen_loss = 0.39743767715726336, disc_loss = 0.0831663868561757
Trained batch 282 in epoch 9, gen_loss = 0.39765898093528546, disc_loss = 0.08297746020695031
Trained batch 283 in epoch 9, gen_loss = 0.3977068033541592, disc_loss = 0.08308098604574694
Trained batch 284 in epoch 9, gen_loss = 0.397653842233775, disc_loss = 0.0839014639228321
Trained batch 285 in epoch 9, gen_loss = 0.39789100965628255, disc_loss = 0.08414773156189105
Trained batch 286 in epoch 9, gen_loss = 0.39784975183757754, disc_loss = 0.08404861052134414
Trained batch 287 in epoch 9, gen_loss = 0.39794222932929796, disc_loss = 0.08389325413089763
Trained batch 288 in epoch 9, gen_loss = 0.3980268395173921, disc_loss = 0.08395770307192031
Trained batch 289 in epoch 9, gen_loss = 0.3979215346019844, disc_loss = 0.08391110777919149
Trained batch 290 in epoch 9, gen_loss = 0.3982392725153887, disc_loss = 0.08367276747624591
Trained batch 291 in epoch 9, gen_loss = 0.39853017751688824, disc_loss = 0.08351775575492991
Trained batch 292 in epoch 9, gen_loss = 0.3984183341061296, disc_loss = 0.08337776664542765
Trained batch 293 in epoch 9, gen_loss = 0.39829225012031544, disc_loss = 0.08355215700267225
Trained batch 294 in epoch 9, gen_loss = 0.3980528973421808, disc_loss = 0.08407766376069542
Trained batch 295 in epoch 9, gen_loss = 0.3982838839795944, disc_loss = 0.08409887881055977
Trained batch 296 in epoch 9, gen_loss = 0.3983980300350221, disc_loss = 0.08395868315602895
Trained batch 297 in epoch 9, gen_loss = 0.39834370684103676, disc_loss = 0.08386096064838887
Trained batch 298 in epoch 9, gen_loss = 0.398230855929413, disc_loss = 0.08375634341796605
Trained batch 299 in epoch 9, gen_loss = 0.3984287942945957, disc_loss = 0.0835452876208971
Trained batch 300 in epoch 9, gen_loss = 0.39828075349726944, disc_loss = 0.0833330793318608
Trained batch 301 in epoch 9, gen_loss = 0.39819975350274156, disc_loss = 0.08327019483850195
Trained batch 302 in epoch 9, gen_loss = 0.39804474812726376, disc_loss = 0.08323586525905742
Trained batch 303 in epoch 9, gen_loss = 0.3985878768818159, disc_loss = 0.08359490994572345
Trained batch 304 in epoch 9, gen_loss = 0.39869243947208904, disc_loss = 0.08346339229982896
Trained batch 305 in epoch 9, gen_loss = 0.3984254038119628, disc_loss = 0.08329670077944601
Trained batch 306 in epoch 9, gen_loss = 0.3982991388352764, disc_loss = 0.0830477263948331
Trained batch 307 in epoch 9, gen_loss = 0.3982637408008049, disc_loss = 0.08294990565023058
Trained batch 308 in epoch 9, gen_loss = 0.3981098441533672, disc_loss = 0.08289464954347094
Trained batch 309 in epoch 9, gen_loss = 0.39819915789750315, disc_loss = 0.08282499962876881
Trained batch 310 in epoch 9, gen_loss = 0.3982589421644088, disc_loss = 0.08282279453788348
Trained batch 311 in epoch 9, gen_loss = 0.3983743760543756, disc_loss = 0.08288667693089408
Trained batch 312 in epoch 9, gen_loss = 0.3982201349525787, disc_loss = 0.08277483030368155
Trained batch 313 in epoch 9, gen_loss = 0.39802031755257566, disc_loss = 0.08264945308043128
Trained batch 314 in epoch 9, gen_loss = 0.3981471767028173, disc_loss = 0.08243834439605947
Trained batch 315 in epoch 9, gen_loss = 0.398275066732983, disc_loss = 0.08229675249467734
Trained batch 316 in epoch 9, gen_loss = 0.3981312823126369, disc_loss = 0.08213045713653323
Trained batch 317 in epoch 9, gen_loss = 0.3978587604075108, disc_loss = 0.08198912582307491
Trained batch 318 in epoch 9, gen_loss = 0.3978083792805298, disc_loss = 0.08184150440565845
Trained batch 319 in epoch 9, gen_loss = 0.397961602313444, disc_loss = 0.08205068339593709
Trained batch 320 in epoch 9, gen_loss = 0.39799745947215415, disc_loss = 0.08191718365358787
Trained batch 321 in epoch 9, gen_loss = 0.3978641154880849, disc_loss = 0.08233090416059731
Trained batch 322 in epoch 9, gen_loss = 0.3982452589199639, disc_loss = 0.08263480474151694
Trained batch 323 in epoch 9, gen_loss = 0.39820731711792356, disc_loss = 0.08246112693055177
Trained batch 324 in epoch 9, gen_loss = 0.39858700766013216, disc_loss = 0.08225259476556228
Trained batch 325 in epoch 9, gen_loss = 0.3986860680525288, disc_loss = 0.08204985387691874
Trained batch 326 in epoch 9, gen_loss = 0.3986042230774503, disc_loss = 0.08183165158028359
Trained batch 327 in epoch 9, gen_loss = 0.3985152362232528, disc_loss = 0.08161223642868785
Trained batch 328 in epoch 9, gen_loss = 0.39832082368139077, disc_loss = 0.0814404776970938
Trained batch 329 in epoch 9, gen_loss = 0.3984050889358376, disc_loss = 0.08124949077539372
Trained batch 330 in epoch 9, gen_loss = 0.398262178204571, disc_loss = 0.08119454294488149
Trained batch 331 in epoch 9, gen_loss = 0.398217963929995, disc_loss = 0.08139374824128597
Trained batch 332 in epoch 9, gen_loss = 0.39833538851759454, disc_loss = 0.0822897900578317
Trained batch 333 in epoch 9, gen_loss = 0.39817172614578716, disc_loss = 0.0823835746056127
Trained batch 334 in epoch 9, gen_loss = 0.39802013106310546, disc_loss = 0.08259056227198287
Trained batch 335 in epoch 9, gen_loss = 0.39801451319917325, disc_loss = 0.08253244103287302
Trained batch 336 in epoch 9, gen_loss = 0.3978989170726046, disc_loss = 0.08250945677168292
Trained batch 337 in epoch 9, gen_loss = 0.3977688934058833, disc_loss = 0.08244414428061635
Trained batch 338 in epoch 9, gen_loss = 0.3975180601563777, disc_loss = 0.08228512400634873
Trained batch 339 in epoch 9, gen_loss = 0.3972721092402935, disc_loss = 0.08216092490098055
Trained batch 340 in epoch 9, gen_loss = 0.3972850079672777, disc_loss = 0.08208401641013685
Trained batch 341 in epoch 9, gen_loss = 0.3970931717439702, disc_loss = 0.08262276714831068
Trained batch 342 in epoch 9, gen_loss = 0.39708124492154523, disc_loss = 0.08283140143222086
Trained batch 343 in epoch 9, gen_loss = 0.3970914534617995, disc_loss = 0.08265820749883734
Trained batch 344 in epoch 9, gen_loss = 0.3968693312095559, disc_loss = 0.08269656099703
Trained batch 345 in epoch 9, gen_loss = 0.396827639915006, disc_loss = 0.08271796002208842
Trained batch 346 in epoch 9, gen_loss = 0.39671074257632155, disc_loss = 0.08254942803050495
Trained batch 347 in epoch 9, gen_loss = 0.3967210699686374, disc_loss = 0.08251743539418468
Trained batch 348 in epoch 9, gen_loss = 0.39658291689133573, disc_loss = 0.08235620889802034
Trained batch 349 in epoch 9, gen_loss = 0.39639902868441174, disc_loss = 0.0827072376119239
Trained batch 350 in epoch 9, gen_loss = 0.39620060514011274, disc_loss = 0.08295493843591112
Trained batch 351 in epoch 9, gen_loss = 0.39613334102217446, disc_loss = 0.08286074664316732
Trained batch 352 in epoch 9, gen_loss = 0.3963963148360887, disc_loss = 0.08290365934583013
Trained batch 353 in epoch 9, gen_loss = 0.3963077728778629, disc_loss = 0.08270872248031494
Trained batch 354 in epoch 9, gen_loss = 0.3961957977271416, disc_loss = 0.08295114630649628
Trained batch 355 in epoch 9, gen_loss = 0.39642519516389024, disc_loss = 0.08311851099238135
Trained batch 356 in epoch 9, gen_loss = 0.39655205862027926, disc_loss = 0.08295006079583608
Trained batch 357 in epoch 9, gen_loss = 0.39650624786508815, disc_loss = 0.08291107919795553
Trained batch 358 in epoch 9, gen_loss = 0.39667594926769023, disc_loss = 0.0828068271424611
Trained batch 359 in epoch 9, gen_loss = 0.396616301809748, disc_loss = 0.08291987697076467
Trained batch 360 in epoch 9, gen_loss = 0.396379376506211, disc_loss = 0.08372855222580175
Trained batch 361 in epoch 9, gen_loss = 0.396386560361359, disc_loss = 0.08370367936707662
Trained batch 362 in epoch 9, gen_loss = 0.39640678654196504, disc_loss = 0.08368110540771945
Trained batch 363 in epoch 9, gen_loss = 0.3964268219258104, disc_loss = 0.08375557793488542
Trained batch 364 in epoch 9, gen_loss = 0.396371450285389, disc_loss = 0.08383635201886909
Trained batch 365 in epoch 9, gen_loss = 0.39649907287841285, disc_loss = 0.08380393699177953
Trained batch 366 in epoch 9, gen_loss = 0.3964720074828379, disc_loss = 0.08362263642576312
Trained batch 367 in epoch 9, gen_loss = 0.3967301918841574, disc_loss = 0.08379023403192506
Trained batch 368 in epoch 9, gen_loss = 0.39667589639422046, disc_loss = 0.08392896911578611
Trained batch 369 in epoch 9, gen_loss = 0.3966007836364411, disc_loss = 0.08377584881979872
Trained batch 370 in epoch 9, gen_loss = 0.3965344106492328, disc_loss = 0.0835962078842834
Trained batch 371 in epoch 9, gen_loss = 0.39660077121469284, disc_loss = 0.08339608801148271
Trained batch 372 in epoch 9, gen_loss = 0.3965384490768008, disc_loss = 0.08338789448102102
Trained batch 373 in epoch 9, gen_loss = 0.39654696732759476, disc_loss = 0.08321742700004482
Trained batch 374 in epoch 9, gen_loss = 0.3967160089413325, disc_loss = 0.08308107840518157
Trained batch 375 in epoch 9, gen_loss = 0.39689636083834984, disc_loss = 0.08291046257487479
Trained batch 376 in epoch 9, gen_loss = 0.3967274276030791, disc_loss = 0.0829464493156349
Trained batch 377 in epoch 9, gen_loss = 0.3969051594693194, disc_loss = 0.08306477056747233
Trained batch 378 in epoch 9, gen_loss = 0.3967125424844923, disc_loss = 0.08294913344242484
Trained batch 379 in epoch 9, gen_loss = 0.39648544721697504, disc_loss = 0.08287572579850491
Trained batch 380 in epoch 9, gen_loss = 0.3962269083173882, disc_loss = 0.08288978393680936
Trained batch 381 in epoch 9, gen_loss = 0.3962817950008427, disc_loss = 0.08284227834302561
Trained batch 382 in epoch 9, gen_loss = 0.3962693649779412, disc_loss = 0.08267983611838468
Trained batch 383 in epoch 9, gen_loss = 0.3961173188484584, disc_loss = 0.08253883244469762
Trained batch 384 in epoch 9, gen_loss = 0.3962268336639776, disc_loss = 0.08236010110900774
Trained batch 385 in epoch 9, gen_loss = 0.3963330121315205, disc_loss = 0.08216969148675704
Trained batch 386 in epoch 9, gen_loss = 0.39644016055943737, disc_loss = 0.0819962474033814
Trained batch 387 in epoch 9, gen_loss = 0.39657226677254304, disc_loss = 0.08185110656909414
Trained batch 388 in epoch 9, gen_loss = 0.39652357650753156, disc_loss = 0.08165858594753365
Trained batch 389 in epoch 9, gen_loss = 0.39653967324739847, disc_loss = 0.08177663386584474
Trained batch 390 in epoch 9, gen_loss = 0.39672706373359845, disc_loss = 0.0828899144435592
Trained batch 391 in epoch 9, gen_loss = 0.39657558094025874, disc_loss = 0.08319738964141556
Trained batch 392 in epoch 9, gen_loss = 0.39647461382942345, disc_loss = 0.08336792746677274
Trained batch 393 in epoch 9, gen_loss = 0.3963247768694374, disc_loss = 0.08329514126402095
Trained batch 394 in epoch 9, gen_loss = 0.39629477892495407, disc_loss = 0.0832963830095869
Trained batch 395 in epoch 9, gen_loss = 0.3962278443981301, disc_loss = 0.08314897705368096
Trained batch 396 in epoch 9, gen_loss = 0.39606578445404544, disc_loss = 0.08320911114411406
Trained batch 397 in epoch 9, gen_loss = 0.3962086198392825, disc_loss = 0.08304181423309685
Trained batch 398 in epoch 9, gen_loss = 0.3961010327688733, disc_loss = 0.0828837491781976
Trained batch 399 in epoch 9, gen_loss = 0.39614348534494637, disc_loss = 0.08290430224733428
Trained batch 400 in epoch 9, gen_loss = 0.3959871267811616, disc_loss = 0.08310960184206763
Trained batch 401 in epoch 9, gen_loss = 0.39616253367852217, disc_loss = 0.08292721817733266
Trained batch 402 in epoch 9, gen_loss = 0.3962887947449909, disc_loss = 0.08293164471307626
Trained batch 403 in epoch 9, gen_loss = 0.3961494325632506, disc_loss = 0.08277108877353223
Trained batch 404 in epoch 9, gen_loss = 0.3961536150287699, disc_loss = 0.08269614621674941
Trained batch 405 in epoch 9, gen_loss = 0.3962847650271331, disc_loss = 0.0825045310772882
Trained batch 406 in epoch 9, gen_loss = 0.39648989278649227, disc_loss = 0.08232128247389849
Trained batch 407 in epoch 9, gen_loss = 0.3964874238579297, disc_loss = 0.08222843325632971
Trained batch 408 in epoch 9, gen_loss = 0.39657038985808496, disc_loss = 0.08207308334095773
Trained batch 409 in epoch 9, gen_loss = 0.3966966461481118, disc_loss = 0.08205800907595492
Trained batch 410 in epoch 9, gen_loss = 0.3964794398151755, disc_loss = 0.08228756219755921
Trained batch 411 in epoch 9, gen_loss = 0.39648429344145997, disc_loss = 0.08352275298302542
Trained batch 412 in epoch 9, gen_loss = 0.3964222001755209, disc_loss = 0.08402801899252951
Trained batch 413 in epoch 9, gen_loss = 0.39636730813029886, disc_loss = 0.08422677669503191
Trained batch 414 in epoch 9, gen_loss = 0.39614274785461195, disc_loss = 0.08447117910282799
Trained batch 415 in epoch 9, gen_loss = 0.3960429123746088, disc_loss = 0.08464666589190109
Trained batch 416 in epoch 9, gen_loss = 0.3959102588091537, disc_loss = 0.0847754731162382
Trained batch 417 in epoch 9, gen_loss = 0.39583043964428194, disc_loss = 0.0847309035222318
Trained batch 418 in epoch 9, gen_loss = 0.39577620869462415, disc_loss = 0.08465420288258278
Trained batch 419 in epoch 9, gen_loss = 0.39542207561788106, disc_loss = 0.08466070465344404
Trained batch 420 in epoch 9, gen_loss = 0.39542042380840364, disc_loss = 0.08455718066897287
Trained batch 421 in epoch 9, gen_loss = 0.3954833943696949, disc_loss = 0.08443221145075573
Trained batch 422 in epoch 9, gen_loss = 0.39537625307168806, disc_loss = 0.0843284119242014
Trained batch 423 in epoch 9, gen_loss = 0.39564611284800294, disc_loss = 0.08431588604229169
Trained batch 424 in epoch 9, gen_loss = 0.3954113263943616, disc_loss = 0.08470006415730014
Trained batch 425 in epoch 9, gen_loss = 0.3954600909366294, disc_loss = 0.08545141452661073
Trained batch 426 in epoch 9, gen_loss = 0.39539191831749554, disc_loss = 0.08576634574018471
Trained batch 427 in epoch 9, gen_loss = 0.3952540549162392, disc_loss = 0.08594527602778905
Trained batch 428 in epoch 9, gen_loss = 0.3951683364686988, disc_loss = 0.0860569796878801
Trained batch 429 in epoch 9, gen_loss = 0.3949154512133709, disc_loss = 0.08612321077001303
Trained batch 430 in epoch 9, gen_loss = 0.39477397338973397, disc_loss = 0.08614623552434614
Trained batch 431 in epoch 9, gen_loss = 0.39463626634743476, disc_loss = 0.08608716475147823
Trained batch 432 in epoch 9, gen_loss = 0.39460781491931535, disc_loss = 0.08604472564795758
Trained batch 433 in epoch 9, gen_loss = 0.3945086905346488, disc_loss = 0.08599762531632583
Trained batch 434 in epoch 9, gen_loss = 0.394428888340106, disc_loss = 0.08594816315747883
Trained batch 435 in epoch 9, gen_loss = 0.3944350647133425, disc_loss = 0.08587180777589594
Trained batch 436 in epoch 9, gen_loss = 0.39420203281485516, disc_loss = 0.08613082485857422
Trained batch 437 in epoch 9, gen_loss = 0.39453599727861416, disc_loss = 0.08608481817619373
Trained batch 438 in epoch 9, gen_loss = 0.3945626256677719, disc_loss = 0.08602635042873426
Trained batch 439 in epoch 9, gen_loss = 0.3945717796005986, disc_loss = 0.08602796156086366
Trained batch 440 in epoch 9, gen_loss = 0.3947769368316581, disc_loss = 0.08608152730656522
Trained batch 441 in epoch 9, gen_loss = 0.39477596287004546, disc_loss = 0.08664204805406713
Trained batch 442 in epoch 9, gen_loss = 0.3948122805854806, disc_loss = 0.08762581621004482
Trained batch 443 in epoch 9, gen_loss = 0.39489701068079147, disc_loss = 0.08753081060199251
Trained batch 444 in epoch 9, gen_loss = 0.39489596104354, disc_loss = 0.08764816065308419
Trained batch 445 in epoch 9, gen_loss = 0.3947972329208135, disc_loss = 0.08755391270481885
Trained batch 446 in epoch 9, gen_loss = 0.3948122646984638, disc_loss = 0.08762618446601785
Trained batch 447 in epoch 9, gen_loss = 0.3949019692705146, disc_loss = 0.08751873018211752
Trained batch 448 in epoch 9, gen_loss = 0.3948767057107658, disc_loss = 0.0874585584780919
Trained batch 449 in epoch 9, gen_loss = 0.39496542771657306, disc_loss = 0.08734956203856402
Trained batch 450 in epoch 9, gen_loss = 0.3949963807927531, disc_loss = 0.08724839307838625
Trained batch 451 in epoch 9, gen_loss = 0.3950265116528072, disc_loss = 0.08715613097142
Trained batch 452 in epoch 9, gen_loss = 0.39510107428559144, disc_loss = 0.08699968515815126
Trained batch 453 in epoch 9, gen_loss = 0.3952711783185404, disc_loss = 0.08686301450035842
Trained batch 454 in epoch 9, gen_loss = 0.3951451420129001, disc_loss = 0.08680326048448518
Trained batch 455 in epoch 9, gen_loss = 0.3951431781445679, disc_loss = 0.0867939092476215
Trained batch 456 in epoch 9, gen_loss = 0.394952240149354, disc_loss = 0.08701569533802944
Trained batch 457 in epoch 9, gen_loss = 0.39520070522893463, disc_loss = 0.08696040684991724
Trained batch 458 in epoch 9, gen_loss = 0.39533117231720155, disc_loss = 0.0872322142525923
Testing Epoch 9
Training Epoch 10
Trained batch 0 in epoch 10, gen_loss = 0.3881261944770813, disc_loss = 0.056739386171102524
Trained batch 1 in epoch 10, gen_loss = 0.38424864411354065, disc_loss = 0.04516809806227684
Trained batch 2 in epoch 10, gen_loss = 0.40666864315668744, disc_loss = 0.05119345088799795
Trained batch 3 in epoch 10, gen_loss = 0.3933037146925926, disc_loss = 0.04784372076392174
Trained batch 4 in epoch 10, gen_loss = 0.38098891377449035, disc_loss = 0.048521222174167634
Trained batch 5 in epoch 10, gen_loss = 0.3817617992560069, disc_loss = 0.05644089604417483
Trained batch 6 in epoch 10, gen_loss = 0.38466428433145794, disc_loss = 0.06055216597659247
Trained batch 7 in epoch 10, gen_loss = 0.3735530562698841, disc_loss = 0.06755776517093182
Trained batch 8 in epoch 10, gen_loss = 0.3856193158361647, disc_loss = 0.06383976340293884
Trained batch 9 in epoch 10, gen_loss = 0.3855605870485306, disc_loss = 0.062256033346056935
Trained batch 10 in epoch 10, gen_loss = 0.3774651722474532, disc_loss = 0.0897230516103181
Trained batch 11 in epoch 10, gen_loss = 0.3864307999610901, disc_loss = 0.08874896882722776
Trained batch 12 in epoch 10, gen_loss = 0.386743215414194, disc_loss = 0.08762388131939448
Trained batch 13 in epoch 10, gen_loss = 0.37917210374559673, disc_loss = 0.08559229730495385
Trained batch 14 in epoch 10, gen_loss = 0.38109710613886516, disc_loss = 0.08279804438352585
Trained batch 15 in epoch 10, gen_loss = 0.3860474079847336, disc_loss = 0.07968640374019742
Trained batch 16 in epoch 10, gen_loss = 0.38450972297612357, disc_loss = 0.07817171514034271
Trained batch 17 in epoch 10, gen_loss = 0.3877312160200543, disc_loss = 0.07770258436600368
Trained batch 18 in epoch 10, gen_loss = 0.383779177540227, disc_loss = 0.07742282434513695
Trained batch 19 in epoch 10, gen_loss = 0.3815282300114632, disc_loss = 0.07933427542448043
Trained batch 20 in epoch 10, gen_loss = 0.38302094028109596, disc_loss = 0.07706407386632193
Trained batch 21 in epoch 10, gen_loss = 0.3864960616285151, disc_loss = 0.07382456661964004
Trained batch 22 in epoch 10, gen_loss = 0.39089796594951465, disc_loss = 0.07319974615845991
Trained batch 23 in epoch 10, gen_loss = 0.39271314442157745, disc_loss = 0.07307523527803521
Trained batch 24 in epoch 10, gen_loss = 0.392755811214447, disc_loss = 0.0718125792592764
Trained batch 25 in epoch 10, gen_loss = 0.3922235541618787, disc_loss = 0.0692987903737678
Trained batch 26 in epoch 10, gen_loss = 0.3899371325969696, disc_loss = 0.07005233541820888
Trained batch 27 in epoch 10, gen_loss = 0.3899729922413826, disc_loss = 0.08013580716215074
Trained batch 28 in epoch 10, gen_loss = 0.3893201217569154, disc_loss = 0.08104032718030543
Trained batch 29 in epoch 10, gen_loss = 0.3925184190273285, disc_loss = 0.08263636607055863
Trained batch 30 in epoch 10, gen_loss = 0.3927262790741459, disc_loss = 0.08141484679353814
Trained batch 31 in epoch 10, gen_loss = 0.39219270925968885, disc_loss = 0.07955039732041769
Trained batch 32 in epoch 10, gen_loss = 0.39181657993432245, disc_loss = 0.07800769255581227
Trained batch 33 in epoch 10, gen_loss = 0.3941894094733631, disc_loss = 0.07586591711322613
Trained batch 34 in epoch 10, gen_loss = 0.39431956495557513, disc_loss = 0.07401223921083978
Trained batch 35 in epoch 10, gen_loss = 0.3962818624244796, disc_loss = 0.07257029293881108
Trained batch 36 in epoch 10, gen_loss = 0.3954780423963392, disc_loss = 0.07330389183669074
Trained batch 37 in epoch 10, gen_loss = 0.3956978799481141, disc_loss = 0.07482850182752468
Trained batch 38 in epoch 10, gen_loss = 0.39528399247389573, disc_loss = 0.07393685579061127
Trained batch 39 in epoch 10, gen_loss = 0.39497642815113065, disc_loss = 0.07292011625831947
Trained batch 40 in epoch 10, gen_loss = 0.392081997743467, disc_loss = 0.07245274318563866
Trained batch 41 in epoch 10, gen_loss = 0.39282473283154623, disc_loss = 0.07194308177124531
Trained batch 42 in epoch 10, gen_loss = 0.3928967873717463, disc_loss = 0.0704367009727934
Trained batch 43 in epoch 10, gen_loss = 0.39254159141670575, disc_loss = 0.06971652565566315
Trained batch 44 in epoch 10, gen_loss = 0.39096951683362324, disc_loss = 0.06868692161515355
Trained batch 45 in epoch 10, gen_loss = 0.39182081105916394, disc_loss = 0.06743912820947236
Trained batch 46 in epoch 10, gen_loss = 0.3929396721910923, disc_loss = 0.06661347031315908
Trained batch 47 in epoch 10, gen_loss = 0.393974053983887, disc_loss = 0.0660579679630852
Trained batch 48 in epoch 10, gen_loss = 0.39421585263038167, disc_loss = 0.0672649896361542
Trained batch 49 in epoch 10, gen_loss = 0.3969384574890137, disc_loss = 0.0725293740723282
Trained batch 50 in epoch 10, gen_loss = 0.39779140785628675, disc_loss = 0.07133638074475468
Trained batch 51 in epoch 10, gen_loss = 0.3959627856428807, disc_loss = 0.07055544675005457
Trained batch 52 in epoch 10, gen_loss = 0.39521610905539317, disc_loss = 0.07032969355899489
Trained batch 53 in epoch 10, gen_loss = 0.39552308011938025, disc_loss = 0.07015535691580563
Trained batch 54 in epoch 10, gen_loss = 0.39643914862112567, disc_loss = 0.0690462686883455
Trained batch 55 in epoch 10, gen_loss = 0.3969902577144759, disc_loss = 0.06826507626932912
Trained batch 56 in epoch 10, gen_loss = 0.3974222122577199, disc_loss = 0.06732538341658942
Trained batch 57 in epoch 10, gen_loss = 0.39856234809447977, disc_loss = 0.06766921987532284
Trained batch 58 in epoch 10, gen_loss = 0.3987657806630862, disc_loss = 0.06674098238443672
Trained batch 59 in epoch 10, gen_loss = 0.3992748791972796, disc_loss = 0.06575865574801962
Trained batch 60 in epoch 10, gen_loss = 0.39930198182825183, disc_loss = 0.06495568690607782
Trained batch 61 in epoch 10, gen_loss = 0.3976019462270121, disc_loss = 0.06471681934330732
Trained batch 62 in epoch 10, gen_loss = 0.3985620987793756, disc_loss = 0.06466557425520723
Trained batch 63 in epoch 10, gen_loss = 0.39788788044825196, disc_loss = 0.06822783811367117
Trained batch 64 in epoch 10, gen_loss = 0.39648541028683004, disc_loss = 0.0725323707724993
Trained batch 65 in epoch 10, gen_loss = 0.3970146906195265, disc_loss = 0.0719907038534681
Trained batch 66 in epoch 10, gen_loss = 0.3981935413026098, disc_loss = 0.07511373806689213
Trained batch 67 in epoch 10, gen_loss = 0.39727549693163705, disc_loss = 0.07494230379405267
Trained batch 68 in epoch 10, gen_loss = 0.39581979228102643, disc_loss = 0.07505665360477523
Trained batch 69 in epoch 10, gen_loss = 0.3969058551958629, disc_loss = 0.07597731785582644
Trained batch 70 in epoch 10, gen_loss = 0.3975809934273572, disc_loss = 0.07525287744339923
Trained batch 71 in epoch 10, gen_loss = 0.3964371246596177, disc_loss = 0.07452972644629578
Trained batch 72 in epoch 10, gen_loss = 0.39736744026615195, disc_loss = 0.07379938991204517
Trained batch 73 in epoch 10, gen_loss = 0.39816527471349045, disc_loss = 0.07320197044896919
Trained batch 74 in epoch 10, gen_loss = 0.3972904630502065, disc_loss = 0.07509035823245844
Trained batch 75 in epoch 10, gen_loss = 0.3955551448621248, disc_loss = 0.07771415692312937
Trained batch 76 in epoch 10, gen_loss = 0.39732901926164504, disc_loss = 0.0776171311494205
Trained batch 77 in epoch 10, gen_loss = 0.39642765201055086, disc_loss = 0.07948666378760184
Trained batch 78 in epoch 10, gen_loss = 0.39583812635156174, disc_loss = 0.08290290971628472
Trained batch 79 in epoch 10, gen_loss = 0.3964110754430294, disc_loss = 0.08231378009077162
Trained batch 80 in epoch 10, gen_loss = 0.39719335422103785, disc_loss = 0.08201882397227081
Trained batch 81 in epoch 10, gen_loss = 0.3980794756150827, disc_loss = 0.08189912946758474
Trained batch 82 in epoch 10, gen_loss = 0.39805100768445484, disc_loss = 0.08207773136715572
Trained batch 83 in epoch 10, gen_loss = 0.39851718750737963, disc_loss = 0.08201200282201171
Trained batch 84 in epoch 10, gen_loss = 0.3987563823952394, disc_loss = 0.08472737509976415
Trained batch 85 in epoch 10, gen_loss = 0.3975577097992564, disc_loss = 0.08606567734116038
Trained batch 86 in epoch 10, gen_loss = 0.39755726477195474, disc_loss = 0.08831380836494353
Trained batch 87 in epoch 10, gen_loss = 0.397236129776998, disc_loss = 0.08905203943140805
Trained batch 88 in epoch 10, gen_loss = 0.39634216334042927, disc_loss = 0.08910390238664793
Trained batch 89 in epoch 10, gen_loss = 0.3959871460994085, disc_loss = 0.0886374936128656
Trained batch 90 in epoch 10, gen_loss = 0.39628940460446116, disc_loss = 0.08821576139838486
Trained batch 91 in epoch 10, gen_loss = 0.3957479239805885, disc_loss = 0.08780183677521089
Trained batch 92 in epoch 10, gen_loss = 0.3964023336928378, disc_loss = 0.08710251818661408
Trained batch 93 in epoch 10, gen_loss = 0.3960097368727339, disc_loss = 0.08660234536658576
Trained batch 94 in epoch 10, gen_loss = 0.3958378192625548, disc_loss = 0.08630075276290115
Trained batch 95 in epoch 10, gen_loss = 0.39586887788027525, disc_loss = 0.08605134054475154
Trained batch 96 in epoch 10, gen_loss = 0.3949558959179318, disc_loss = 0.08646420675531491
Trained batch 97 in epoch 10, gen_loss = 0.39467733034065794, disc_loss = 0.08683500144326566
Trained batch 98 in epoch 10, gen_loss = 0.39368233265298785, disc_loss = 0.08627874375970075
Trained batch 99 in epoch 10, gen_loss = 0.3936610502004623, disc_loss = 0.08560392355546355
Trained batch 100 in epoch 10, gen_loss = 0.3940067928616363, disc_loss = 0.0851637429124353
Trained batch 101 in epoch 10, gen_loss = 0.3944939643728967, disc_loss = 0.08519418035432988
Trained batch 102 in epoch 10, gen_loss = 0.39490977103270375, disc_loss = 0.08475560841412799
Trained batch 103 in epoch 10, gen_loss = 0.3952212660358502, disc_loss = 0.0856380201338862
Trained batch 104 in epoch 10, gen_loss = 0.39562264936310904, disc_loss = 0.0852343359341224
Trained batch 105 in epoch 10, gen_loss = 0.39575989825545616, disc_loss = 0.08452818591920834
Trained batch 106 in epoch 10, gen_loss = 0.3951761405044627, disc_loss = 0.0842404635710137
Trained batch 107 in epoch 10, gen_loss = 0.39495588066401305, disc_loss = 0.08377825248020666
Trained batch 108 in epoch 10, gen_loss = 0.39530182869062513, disc_loss = 0.08537967024593178
Trained batch 109 in epoch 10, gen_loss = 0.39491938921538267, disc_loss = 0.08528132845054973
Trained batch 110 in epoch 10, gen_loss = 0.39477959114152034, disc_loss = 0.08476045798208262
Trained batch 111 in epoch 10, gen_loss = 0.394919292735202, disc_loss = 0.08538453510430243
Trained batch 112 in epoch 10, gen_loss = 0.3945312452527274, disc_loss = 0.08588852466339558
Trained batch 113 in epoch 10, gen_loss = 0.39489877746816265, disc_loss = 0.08531555736012626
Trained batch 114 in epoch 10, gen_loss = 0.3948384748852771, disc_loss = 0.08481454925368662
Trained batch 115 in epoch 10, gen_loss = 0.3949994249590512, disc_loss = 0.08412839683447161
Trained batch 116 in epoch 10, gen_loss = 0.3952017431585198, disc_loss = 0.08379630422076353
Trained batch 117 in epoch 10, gen_loss = 0.39505941938545747, disc_loss = 0.08330221239761529
Trained batch 118 in epoch 10, gen_loss = 0.3946047755850463, disc_loss = 0.08290973433269923
Trained batch 119 in epoch 10, gen_loss = 0.3951398000121117, disc_loss = 0.08275696979059527
Trained batch 120 in epoch 10, gen_loss = 0.3950217760298863, disc_loss = 0.08420174103230238
Trained batch 121 in epoch 10, gen_loss = 0.3955387470663571, disc_loss = 0.08363469145031738
Trained batch 122 in epoch 10, gen_loss = 0.39645739178347394, disc_loss = 0.08361028666358168
Trained batch 123 in epoch 10, gen_loss = 0.3957901621057141, disc_loss = 0.083418961869733
Trained batch 124 in epoch 10, gen_loss = 0.3960196259021759, disc_loss = 0.0828439827412367
Trained batch 125 in epoch 10, gen_loss = 0.3958694355355369, disc_loss = 0.08226776792712155
Trained batch 126 in epoch 10, gen_loss = 0.39634203605764495, disc_loss = 0.08218457651009241
Trained batch 127 in epoch 10, gen_loss = 0.39587113400921226, disc_loss = 0.08356150578765664
Trained batch 128 in epoch 10, gen_loss = 0.39645784007486445, disc_loss = 0.08321177270696607
Trained batch 129 in epoch 10, gen_loss = 0.3973263733662092, disc_loss = 0.08491063351528003
Trained batch 130 in epoch 10, gen_loss = 0.3973552482273742, disc_loss = 0.08437592729584861
Trained batch 131 in epoch 10, gen_loss = 0.39749311475139676, disc_loss = 0.08440155394826875
Trained batch 132 in epoch 10, gen_loss = 0.3974133066664961, disc_loss = 0.08397087292339568
Trained batch 133 in epoch 10, gen_loss = 0.39719766244959476, disc_loss = 0.08341653601252544
Trained batch 134 in epoch 10, gen_loss = 0.39699773501466823, disc_loss = 0.0831296782043797
Trained batch 135 in epoch 10, gen_loss = 0.39625758984509635, disc_loss = 0.0830143775914193
Trained batch 136 in epoch 10, gen_loss = 0.39640043686776266, disc_loss = 0.08281269409170333
Trained batch 137 in epoch 10, gen_loss = 0.396149006874665, disc_loss = 0.08455290311299589
Trained batch 138 in epoch 10, gen_loss = 0.3952567448718942, disc_loss = 0.08622706666079571
Trained batch 139 in epoch 10, gen_loss = 0.39556188370500295, disc_loss = 0.08626910086854228
Trained batch 140 in epoch 10, gen_loss = 0.39596170334951253, disc_loss = 0.08596039973595675
Trained batch 141 in epoch 10, gen_loss = 0.3956707699198118, disc_loss = 0.08554846597310732
Trained batch 142 in epoch 10, gen_loss = 0.3957095162851827, disc_loss = 0.08513130313371653
Trained batch 143 in epoch 10, gen_loss = 0.395437417137954, disc_loss = 0.0846180439629178
Trained batch 144 in epoch 10, gen_loss = 0.3951194313065759, disc_loss = 0.08420201507236423
Trained batch 145 in epoch 10, gen_loss = 0.39501201024610705, disc_loss = 0.08382918221927056
Trained batch 146 in epoch 10, gen_loss = 0.3948399852327749, disc_loss = 0.08352550839511108
Trained batch 147 in epoch 10, gen_loss = 0.3952677606328114, disc_loss = 0.08317790835516879
Trained batch 148 in epoch 10, gen_loss = 0.3955354624546614, disc_loss = 0.08296890897463832
Trained batch 149 in epoch 10, gen_loss = 0.3955949910481771, disc_loss = 0.08350319853052497
Trained batch 150 in epoch 10, gen_loss = 0.3962954527494923, disc_loss = 0.08548592347405012
Trained batch 151 in epoch 10, gen_loss = 0.39576280901306554, disc_loss = 0.08547086259472723
Trained batch 152 in epoch 10, gen_loss = 0.395516836370518, disc_loss = 0.08542294800890232
Trained batch 153 in epoch 10, gen_loss = 0.39507261441125496, disc_loss = 0.08529681437225504
Trained batch 154 in epoch 10, gen_loss = 0.39484836766796727, disc_loss = 0.0850750648747048
Trained batch 155 in epoch 10, gen_loss = 0.39444142159743184, disc_loss = 0.08474745549476491
Trained batch 156 in epoch 10, gen_loss = 0.3937030871202991, disc_loss = 0.08497579016716807
Trained batch 157 in epoch 10, gen_loss = 0.39434879659851896, disc_loss = 0.084893998801944
Trained batch 158 in epoch 10, gen_loss = 0.3946402558365708, disc_loss = 0.08444558431353397
Trained batch 159 in epoch 10, gen_loss = 0.39438661839812994, disc_loss = 0.0840595053799916
Trained batch 160 in epoch 10, gen_loss = 0.394725654621302, disc_loss = 0.08363961562028398
Trained batch 161 in epoch 10, gen_loss = 0.39482186219574494, disc_loss = 0.08322480252518515
Trained batch 162 in epoch 10, gen_loss = 0.39482280282886484, disc_loss = 0.08353999033684563
Trained batch 163 in epoch 10, gen_loss = 0.3944697261946957, disc_loss = 0.08451212157222737
Trained batch 164 in epoch 10, gen_loss = 0.3945081936590599, disc_loss = 0.08638106725093993
Trained batch 165 in epoch 10, gen_loss = 0.39451648671943024, disc_loss = 0.08615101647776473
Trained batch 166 in epoch 10, gen_loss = 0.3939631534907632, disc_loss = 0.08643399016697428
Trained batch 167 in epoch 10, gen_loss = 0.39398164000539554, disc_loss = 0.08602202632131853
Trained batch 168 in epoch 10, gen_loss = 0.39397069353323716, disc_loss = 0.08558179157615237
Trained batch 169 in epoch 10, gen_loss = 0.3944761181578917, disc_loss = 0.08532173937624868
Trained batch 170 in epoch 10, gen_loss = 0.3946432828554633, disc_loss = 0.08486135211386527
Trained batch 171 in epoch 10, gen_loss = 0.3945923139189565, disc_loss = 0.08444374971914777
Trained batch 172 in epoch 10, gen_loss = 0.3942511743203753, disc_loss = 0.08425012841346981
Trained batch 173 in epoch 10, gen_loss = 0.39506729615145714, disc_loss = 0.08398055842938437
Trained batch 174 in epoch 10, gen_loss = 0.3958444779259818, disc_loss = 0.0835938274221761
Trained batch 175 in epoch 10, gen_loss = 0.3959377331828529, disc_loss = 0.08321871557696299
Trained batch 176 in epoch 10, gen_loss = 0.3956711149148348, disc_loss = 0.08286983498745719
Trained batch 177 in epoch 10, gen_loss = 0.39551423205418534, disc_loss = 0.08277606918068414
Trained batch 178 in epoch 10, gen_loss = 0.3955359580463537, disc_loss = 0.08277736475181313
Trained batch 179 in epoch 10, gen_loss = 0.3957666978240013, disc_loss = 0.08321050749056869
Trained batch 180 in epoch 10, gen_loss = 0.39605481074659865, disc_loss = 0.08279619236265756
Trained batch 181 in epoch 10, gen_loss = 0.39565732321896396, disc_loss = 0.08287693341109124
Trained batch 182 in epoch 10, gen_loss = 0.39565987225438726, disc_loss = 0.08249259476493942
Trained batch 183 in epoch 10, gen_loss = 0.3960708727979142, disc_loss = 0.08208254597190281
Trained batch 184 in epoch 10, gen_loss = 0.39602931190181423, disc_loss = 0.0816872601724557
Trained batch 185 in epoch 10, gen_loss = 0.3958420314455545, disc_loss = 0.08127171321401513
Trained batch 186 in epoch 10, gen_loss = 0.39563256247158357, disc_loss = 0.08092117570041814
Trained batch 187 in epoch 10, gen_loss = 0.395225705460031, disc_loss = 0.0808301085873725
Trained batch 188 in epoch 10, gen_loss = 0.3952022565420342, disc_loss = 0.08075873551289083
Trained batch 189 in epoch 10, gen_loss = 0.39507592179273304, disc_loss = 0.08086928424768541
Trained batch 190 in epoch 10, gen_loss = 0.3950049635315441, disc_loss = 0.08052912644593348
Trained batch 191 in epoch 10, gen_loss = 0.3952611944017311, disc_loss = 0.08052453535977595
Trained batch 192 in epoch 10, gen_loss = 0.3947869131602154, disc_loss = 0.08107190889455958
Trained batch 193 in epoch 10, gen_loss = 0.3948884855226143, disc_loss = 0.0814337893773216
Trained batch 194 in epoch 10, gen_loss = 0.3950465726546752, disc_loss = 0.0810810704357349
Trained batch 195 in epoch 10, gen_loss = 0.3946428358250735, disc_loss = 0.08117579738134328
Trained batch 196 in epoch 10, gen_loss = 0.3947320837659884, disc_loss = 0.08112865014162463
Trained batch 197 in epoch 10, gen_loss = 0.3951086904665436, disc_loss = 0.08077742761904091
Trained batch 198 in epoch 10, gen_loss = 0.3947884202303, disc_loss = 0.08061823406579656
Trained batch 199 in epoch 10, gen_loss = 0.39493890896439554, disc_loss = 0.08051182680297643
Trained batch 200 in epoch 10, gen_loss = 0.3950320769898334, disc_loss = 0.0804368786893748
Trained batch 201 in epoch 10, gen_loss = 0.39496909922892504, disc_loss = 0.08104526915928663
Trained batch 202 in epoch 10, gen_loss = 0.3946443098812855, disc_loss = 0.08257310915041
Trained batch 203 in epoch 10, gen_loss = 0.3948175295018682, disc_loss = 0.08262568603123666
Trained batch 204 in epoch 10, gen_loss = 0.39458978219730095, disc_loss = 0.08275416006856576
Trained batch 205 in epoch 10, gen_loss = 0.3945834220034405, disc_loss = 0.08283696374720306
Trained batch 206 in epoch 10, gen_loss = 0.39468869120602446, disc_loss = 0.08277577288214855
Trained batch 207 in epoch 10, gen_loss = 0.3946109341027645, disc_loss = 0.08266776395836271
Trained batch 208 in epoch 10, gen_loss = 0.3945437194913198, disc_loss = 0.08271912040197821
Trained batch 209 in epoch 10, gen_loss = 0.3942348748445511, disc_loss = 0.08297656817539108
Trained batch 210 in epoch 10, gen_loss = 0.394443814505898, disc_loss = 0.08372013765647654
Trained batch 211 in epoch 10, gen_loss = 0.39409825304206814, disc_loss = 0.08357151970706599
Trained batch 212 in epoch 10, gen_loss = 0.39394251071791136, disc_loss = 0.08418358009343556
Trained batch 213 in epoch 10, gen_loss = 0.3940007463793888, disc_loss = 0.08484047756173482
Trained batch 214 in epoch 10, gen_loss = 0.39414193131202874, disc_loss = 0.08453277536169734
Trained batch 215 in epoch 10, gen_loss = 0.3939486849639151, disc_loss = 0.0847777098512139
Trained batch 216 in epoch 10, gen_loss = 0.3937145672086197, disc_loss = 0.08472114354629533
Trained batch 217 in epoch 10, gen_loss = 0.39381316194840527, disc_loss = 0.08443210610197088
Trained batch 218 in epoch 10, gen_loss = 0.3936033346881605, disc_loss = 0.0843194533760349
Trained batch 219 in epoch 10, gen_loss = 0.39365599846298044, disc_loss = 0.08397687906822697
Trained batch 220 in epoch 10, gen_loss = 0.39401527538019065, disc_loss = 0.08363650869409558
Trained batch 221 in epoch 10, gen_loss = 0.3940196319206341, disc_loss = 0.08336237815066098
Trained batch 222 in epoch 10, gen_loss = 0.3936417714897293, disc_loss = 0.08322351175723723
Trained batch 223 in epoch 10, gen_loss = 0.3939201282337308, disc_loss = 0.08343188485014252
Trained batch 224 in epoch 10, gen_loss = 0.39371015005641513, disc_loss = 0.08376715753227472
Trained batch 225 in epoch 10, gen_loss = 0.39366650502238654, disc_loss = 0.08352143893974413
Trained batch 226 in epoch 10, gen_loss = 0.39384628300624797, disc_loss = 0.08327605654506037
Trained batch 227 in epoch 10, gen_loss = 0.39367017006142097, disc_loss = 0.08296610739719319
Trained batch 228 in epoch 10, gen_loss = 0.39345481731485593, disc_loss = 0.08281183642575184
Trained batch 229 in epoch 10, gen_loss = 0.3933189278063567, disc_loss = 0.08251993256499586
Trained batch 230 in epoch 10, gen_loss = 0.39342653286921514, disc_loss = 0.0828537546396578
Trained batch 231 in epoch 10, gen_loss = 0.39328232124961654, disc_loss = 0.08368893560616235
Trained batch 232 in epoch 10, gen_loss = 0.39337268394973657, disc_loss = 0.08372195789694402
Trained batch 233 in epoch 10, gen_loss = 0.3934232647347654, disc_loss = 0.0834779270972388
Trained batch 234 in epoch 10, gen_loss = 0.3930271682587076, disc_loss = 0.08356133857543799
Trained batch 235 in epoch 10, gen_loss = 0.3928725867200706, disc_loss = 0.08337144299126151
Trained batch 236 in epoch 10, gen_loss = 0.3927721440289091, disc_loss = 0.08303945842650935
Trained batch 237 in epoch 10, gen_loss = 0.3925436866634032, disc_loss = 0.0829288115619267
Trained batch 238 in epoch 10, gen_loss = 0.39243767164242316, disc_loss = 0.08340936301619002
Trained batch 239 in epoch 10, gen_loss = 0.39264979946116607, disc_loss = 0.08451740494347178
Trained batch 240 in epoch 10, gen_loss = 0.3928049447872827, disc_loss = 0.08448563937553788
Trained batch 241 in epoch 10, gen_loss = 0.3924098555460449, disc_loss = 0.08467298519243448
Trained batch 242 in epoch 10, gen_loss = 0.392073232450603, disc_loss = 0.0844951563997677
Trained batch 243 in epoch 10, gen_loss = 0.392255147949594, disc_loss = 0.08417584422067358
Trained batch 244 in epoch 10, gen_loss = 0.3924744862682965, disc_loss = 0.08392476637334544
Trained batch 245 in epoch 10, gen_loss = 0.392364207806626, disc_loss = 0.08371513536979815
Trained batch 246 in epoch 10, gen_loss = 0.39223908316268613, disc_loss = 0.08354616273941118
Trained batch 247 in epoch 10, gen_loss = 0.39250325663916524, disc_loss = 0.08336188704443855
Trained batch 248 in epoch 10, gen_loss = 0.3927852128404211, disc_loss = 0.08314533639572053
Trained batch 249 in epoch 10, gen_loss = 0.3928596074581146, disc_loss = 0.08389178055711091
Trained batch 250 in epoch 10, gen_loss = 0.3924936680679777, disc_loss = 0.08478427046271732
Trained batch 251 in epoch 10, gen_loss = 0.392349853165566, disc_loss = 0.08484808136967735
Trained batch 252 in epoch 10, gen_loss = 0.3927449161120554, disc_loss = 0.08454156825834289
Trained batch 253 in epoch 10, gen_loss = 0.3926930446324386, disc_loss = 0.08435455974976085
Trained batch 254 in epoch 10, gen_loss = 0.3928921694849052, disc_loss = 0.08418331655911078
Trained batch 255 in epoch 10, gen_loss = 0.3934944460634142, disc_loss = 0.08440900176174182
Trained batch 256 in epoch 10, gen_loss = 0.3932690575197049, disc_loss = 0.08414369777881392
Trained batch 257 in epoch 10, gen_loss = 0.3934580004492471, disc_loss = 0.08399511410046166
Trained batch 258 in epoch 10, gen_loss = 0.39367413428759485, disc_loss = 0.0837040673419977
Trained batch 259 in epoch 10, gen_loss = 0.39398279018127, disc_loss = 0.08345389471998295
Trained batch 260 in epoch 10, gen_loss = 0.39393352503064033, disc_loss = 0.08324796593501821
Trained batch 261 in epoch 10, gen_loss = 0.3939336010517965, disc_loss = 0.0833811410009605
Trained batch 262 in epoch 10, gen_loss = 0.3934612027139265, disc_loss = 0.08354098328385687
Trained batch 263 in epoch 10, gen_loss = 0.3936525373296304, disc_loss = 0.08333575121430455
Trained batch 264 in epoch 10, gen_loss = 0.39358883612560774, disc_loss = 0.08358349659357149
Trained batch 265 in epoch 10, gen_loss = 0.39317654263704344, disc_loss = 0.08422237416008081
Trained batch 266 in epoch 10, gen_loss = 0.39346677924363355, disc_loss = 0.08411880112200808
Trained batch 267 in epoch 10, gen_loss = 0.3934987713374309, disc_loss = 0.08412983517141652
Trained batch 268 in epoch 10, gen_loss = 0.39321808976754824, disc_loss = 0.08390251133542466
Trained batch 269 in epoch 10, gen_loss = 0.3925454319627197, disc_loss = 0.08419483490805658
Trained batch 270 in epoch 10, gen_loss = 0.3925681005324825, disc_loss = 0.08413575228640459
Trained batch 271 in epoch 10, gen_loss = 0.39264770805397453, disc_loss = 0.08416795527035206
Trained batch 272 in epoch 10, gen_loss = 0.39271125743240665, disc_loss = 0.08435550838838513
Trained batch 273 in epoch 10, gen_loss = 0.3926771408232459, disc_loss = 0.08453745481109477
Trained batch 274 in epoch 10, gen_loss = 0.39280284979126673, disc_loss = 0.08428774529390715
Trained batch 275 in epoch 10, gen_loss = 0.3926780632008677, disc_loss = 0.08443168366321133
Trained batch 276 in epoch 10, gen_loss = 0.3924209477669065, disc_loss = 0.0853454592126667
Trained batch 277 in epoch 10, gen_loss = 0.39273602778105426, disc_loss = 0.08546613823294157
Trained batch 278 in epoch 10, gen_loss = 0.39311176303467016, disc_loss = 0.08522899917370262
Trained batch 279 in epoch 10, gen_loss = 0.39322298978056225, disc_loss = 0.08512868911659877
Trained batch 280 in epoch 10, gen_loss = 0.39309444429611395, disc_loss = 0.0851206526117154
Trained batch 281 in epoch 10, gen_loss = 0.3931687833569574, disc_loss = 0.08501481812889852
Trained batch 282 in epoch 10, gen_loss = 0.39311618139381543, disc_loss = 0.08480681412994809
Trained batch 283 in epoch 10, gen_loss = 0.39309353748677484, disc_loss = 0.08475029531335064
Trained batch 284 in epoch 10, gen_loss = 0.39318151996846784, disc_loss = 0.08494517829171137
Trained batch 285 in epoch 10, gen_loss = 0.393179991862157, disc_loss = 0.08472156794774313
Trained batch 286 in epoch 10, gen_loss = 0.39311138636559145, disc_loss = 0.08514653161031807
Trained batch 287 in epoch 10, gen_loss = 0.39277428119546837, disc_loss = 0.08601283808982568
Trained batch 288 in epoch 10, gen_loss = 0.39277304580054895, disc_loss = 0.08583819113871578
Trained batch 289 in epoch 10, gen_loss = 0.3927526600401977, disc_loss = 0.0855873276013881
Trained batch 290 in epoch 10, gen_loss = 0.39279968765183415, disc_loss = 0.08537369291378102
Trained batch 291 in epoch 10, gen_loss = 0.39272278394192867, disc_loss = 0.08519593181809385
Trained batch 292 in epoch 10, gen_loss = 0.39292519501451745, disc_loss = 0.08503587957973824
Trained batch 293 in epoch 10, gen_loss = 0.3928699949566199, disc_loss = 0.08492510784322357
Trained batch 294 in epoch 10, gen_loss = 0.39277890375105, disc_loss = 0.0849077467522505
Trained batch 295 in epoch 10, gen_loss = 0.3928986697180851, disc_loss = 0.08503686801083638
Trained batch 296 in epoch 10, gen_loss = 0.3927720369714679, disc_loss = 0.0853196372315664
Trained batch 297 in epoch 10, gen_loss = 0.3931880667305633, disc_loss = 0.08507970203145489
Trained batch 298 in epoch 10, gen_loss = 0.3933323851995245, disc_loss = 0.08482960577474838
Trained batch 299 in epoch 10, gen_loss = 0.39327263782421745, disc_loss = 0.08465003251563757
Trained batch 300 in epoch 10, gen_loss = 0.39323126012304693, disc_loss = 0.08442757622280044
Trained batch 301 in epoch 10, gen_loss = 0.39316907564535836, disc_loss = 0.08423616151350076
Trained batch 302 in epoch 10, gen_loss = 0.39315027805051395, disc_loss = 0.08400634987119941
Trained batch 303 in epoch 10, gen_loss = 0.39326263885749013, disc_loss = 0.08382420639942498
Trained batch 304 in epoch 10, gen_loss = 0.39313408800813016, disc_loss = 0.08393276537631135
Trained batch 305 in epoch 10, gen_loss = 0.3932378513166328, disc_loss = 0.08377457250463563
Trained batch 306 in epoch 10, gen_loss = 0.39337400145561763, disc_loss = 0.08425422683691891
Trained batch 307 in epoch 10, gen_loss = 0.3930835172340467, disc_loss = 0.08498691376631282
Trained batch 308 in epoch 10, gen_loss = 0.3935079267881449, disc_loss = 0.0848004654951056
Trained batch 309 in epoch 10, gen_loss = 0.3938429541164829, disc_loss = 0.0847316117761957
Trained batch 310 in epoch 10, gen_loss = 0.3940356691933905, disc_loss = 0.0845351458251644
Trained batch 311 in epoch 10, gen_loss = 0.39397739724088937, disc_loss = 0.0843315450161194
Trained batch 312 in epoch 10, gen_loss = 0.3938365680531572, disc_loss = 0.08415608018035658
Trained batch 313 in epoch 10, gen_loss = 0.39366815272410205, disc_loss = 0.08409376805915147
Trained batch 314 in epoch 10, gen_loss = 0.39322802282515024, disc_loss = 0.08446188992894595
Trained batch 315 in epoch 10, gen_loss = 0.3933444148566149, disc_loss = 0.08449584422957246
Trained batch 316 in epoch 10, gen_loss = 0.3931999396450512, disc_loss = 0.08446804935124347
Trained batch 317 in epoch 10, gen_loss = 0.39311550941857154, disc_loss = 0.0844666881050399
Trained batch 318 in epoch 10, gen_loss = 0.3932059481973558, disc_loss = 0.08424936130286712
Trained batch 319 in epoch 10, gen_loss = 0.3933909743092954, disc_loss = 0.0840202811625204
Trained batch 320 in epoch 10, gen_loss = 0.3932489338693589, disc_loss = 0.08387753102678887
Trained batch 321 in epoch 10, gen_loss = 0.3934189810515931, disc_loss = 0.08371081967803401
Trained batch 322 in epoch 10, gen_loss = 0.39329391597963337, disc_loss = 0.08364954538752928
Trained batch 323 in epoch 10, gen_loss = 0.3935055437463301, disc_loss = 0.08351325312554607
Trained batch 324 in epoch 10, gen_loss = 0.39352241213505085, disc_loss = 0.08329432547808839
Trained batch 325 in epoch 10, gen_loss = 0.3936298800392385, disc_loss = 0.08323008403256307
Trained batch 326 in epoch 10, gen_loss = 0.3934235693117894, disc_loss = 0.08316769198705343
Trained batch 327 in epoch 10, gen_loss = 0.3933959381609428, disc_loss = 0.08298882898425956
Trained batch 328 in epoch 10, gen_loss = 0.39342375403117263, disc_loss = 0.08338734568280698
Trained batch 329 in epoch 10, gen_loss = 0.39335082950014055, disc_loss = 0.08366013889088098
Trained batch 330 in epoch 10, gen_loss = 0.39368450533587407, disc_loss = 0.08345544024924903
Trained batch 331 in epoch 10, gen_loss = 0.3939874761973519, disc_loss = 0.08333643011507545
Trained batch 332 in epoch 10, gen_loss = 0.3938001544625909, disc_loss = 0.08327356170633579
Trained batch 333 in epoch 10, gen_loss = 0.3936680289442668, disc_loss = 0.08357446098248446
Trained batch 334 in epoch 10, gen_loss = 0.39374617195841094, disc_loss = 0.08335506163342897
Trained batch 335 in epoch 10, gen_loss = 0.39391309147079784, disc_loss = 0.08327105182494658
Trained batch 336 in epoch 10, gen_loss = 0.39378575516383796, disc_loss = 0.0831484171611641
Trained batch 337 in epoch 10, gen_loss = 0.39370760542048505, disc_loss = 0.08301937746672103
Trained batch 338 in epoch 10, gen_loss = 0.39378372995199357, disc_loss = 0.08286620506324467
Trained batch 339 in epoch 10, gen_loss = 0.39361743348486283, disc_loss = 0.0828688438009361
Trained batch 340 in epoch 10, gen_loss = 0.39382326655373895, disc_loss = 0.08272275078599273
Trained batch 341 in epoch 10, gen_loss = 0.39393754939586795, disc_loss = 0.08264664213216662
Trained batch 342 in epoch 10, gen_loss = 0.3937612759823702, disc_loss = 0.08255388941914495
Trained batch 343 in epoch 10, gen_loss = 0.3937972545797049, disc_loss = 0.08242061454938118
Trained batch 344 in epoch 10, gen_loss = 0.39372532384983006, disc_loss = 0.0823912401791608
Trained batch 345 in epoch 10, gen_loss = 0.3934984991832965, disc_loss = 0.08232456286480877
Trained batch 346 in epoch 10, gen_loss = 0.3935812403386196, disc_loss = 0.08227613602794427
Trained batch 347 in epoch 10, gen_loss = 0.39368749290019617, disc_loss = 0.08237035384257163
Trained batch 348 in epoch 10, gen_loss = 0.3940026257133757, disc_loss = 0.08223380233937698
Trained batch 349 in epoch 10, gen_loss = 0.39405881098338535, disc_loss = 0.0825970745525722
Trained batch 350 in epoch 10, gen_loss = 0.3940191307978073, disc_loss = 0.08243182032074556
Trained batch 351 in epoch 10, gen_loss = 0.39387213210151956, disc_loss = 0.08312361850535539
Trained batch 352 in epoch 10, gen_loss = 0.3940103473643068, disc_loss = 0.0829357310889484
Trained batch 353 in epoch 10, gen_loss = 0.3942692483549064, disc_loss = 0.0827819168486101
Trained batch 354 in epoch 10, gen_loss = 0.3942634146817973, disc_loss = 0.08259698448073066
Trained batch 355 in epoch 10, gen_loss = 0.3944480960791031, disc_loss = 0.08243007850807077
Trained batch 356 in epoch 10, gen_loss = 0.39442411232061414, disc_loss = 0.08232512998757284
Trained batch 357 in epoch 10, gen_loss = 0.394298136650517, disc_loss = 0.08240941231003729
Trained batch 358 in epoch 10, gen_loss = 0.39417894670226117, disc_loss = 0.08232380990016801
Trained batch 359 in epoch 10, gen_loss = 0.39411403636137643, disc_loss = 0.08214856398214275
Trained batch 360 in epoch 10, gen_loss = 0.393894723412733, disc_loss = 0.08200058043441655
Trained batch 361 in epoch 10, gen_loss = 0.39382499003607924, disc_loss = 0.08233252150850442
Trained batch 362 in epoch 10, gen_loss = 0.39412824977856364, disc_loss = 0.08238077070948875
Trained batch 363 in epoch 10, gen_loss = 0.3942307591602042, disc_loss = 0.08226566645700567
Trained batch 364 in epoch 10, gen_loss = 0.3942778914758604, disc_loss = 0.08212030824554498
Trained batch 365 in epoch 10, gen_loss = 0.3942611772831672, disc_loss = 0.0820417406681233
Trained batch 366 in epoch 10, gen_loss = 0.3943479744874814, disc_loss = 0.08192273867456115
Trained batch 367 in epoch 10, gen_loss = 0.3941417683077895, disc_loss = 0.08207280867677384
Trained batch 368 in epoch 10, gen_loss = 0.39428593367742004, disc_loss = 0.08217478269549607
Trained batch 369 in epoch 10, gen_loss = 0.39442684843733505, disc_loss = 0.08203867150948861
Trained batch 370 in epoch 10, gen_loss = 0.39424104349953787, disc_loss = 0.08186154487364576
Trained batch 371 in epoch 10, gen_loss = 0.3942342159408395, disc_loss = 0.08171843222758021
Trained batch 372 in epoch 10, gen_loss = 0.394119375672481, disc_loss = 0.08157621536418876
Trained batch 373 in epoch 10, gen_loss = 0.39400426716728004, disc_loss = 0.08139267372699543
Trained batch 374 in epoch 10, gen_loss = 0.39386600502332053, disc_loss = 0.08148886297270655
Trained batch 375 in epoch 10, gen_loss = 0.39399901579352137, disc_loss = 0.08233922194971881
Trained batch 376 in epoch 10, gen_loss = 0.3940249222975511, disc_loss = 0.08217895675366571
Trained batch 377 in epoch 10, gen_loss = 0.3941707802670343, disc_loss = 0.08210101947508673
Trained batch 378 in epoch 10, gen_loss = 0.3941912531538186, disc_loss = 0.08194483531697956
Trained batch 379 in epoch 10, gen_loss = 0.39433382733872063, disc_loss = 0.08195568893815537
Trained batch 380 in epoch 10, gen_loss = 0.394271446103499, disc_loss = 0.08180109934705332
Trained batch 381 in epoch 10, gen_loss = 0.3941866114969653, disc_loss = 0.08186104686087221
Trained batch 382 in epoch 10, gen_loss = 0.39440789655356745, disc_loss = 0.08185889580780664
Trained batch 383 in epoch 10, gen_loss = 0.39429784364377457, disc_loss = 0.08169664981566409
Trained batch 384 in epoch 10, gen_loss = 0.3940290061684398, disc_loss = 0.0823167510197631
Trained batch 385 in epoch 10, gen_loss = 0.393951192420999, disc_loss = 0.0823398243039943
Trained batch 386 in epoch 10, gen_loss = 0.3940697316205471, disc_loss = 0.08223642801230614
Trained batch 387 in epoch 10, gen_loss = 0.39401327680373927, disc_loss = 0.08279357915480151
Trained batch 388 in epoch 10, gen_loss = 0.3940817985712409, disc_loss = 0.08312789708553098
Trained batch 389 in epoch 10, gen_loss = 0.39422650742225157, disc_loss = 0.08315081850100213
Trained batch 390 in epoch 10, gen_loss = 0.39412518482074105, disc_loss = 0.08321969664257849
Trained batch 391 in epoch 10, gen_loss = 0.3939893141540946, disc_loss = 0.08325632032106764
Trained batch 392 in epoch 10, gen_loss = 0.3942466570069165, disc_loss = 0.083144412616519
Trained batch 393 in epoch 10, gen_loss = 0.39424578512683134, disc_loss = 0.0830047472585749
Trained batch 394 in epoch 10, gen_loss = 0.3942108383661584, disc_loss = 0.08288836940486409
Trained batch 395 in epoch 10, gen_loss = 0.394114808301733, disc_loss = 0.08272109972430637
Trained batch 396 in epoch 10, gen_loss = 0.39414749352697764, disc_loss = 0.08265930282477506
Trained batch 397 in epoch 10, gen_loss = 0.39418433651552726, disc_loss = 0.08295377905143603
Trained batch 398 in epoch 10, gen_loss = 0.39425041248326315, disc_loss = 0.08302223039697622
Trained batch 399 in epoch 10, gen_loss = 0.3944684620201588, disc_loss = 0.0828746358549688
Trained batch 400 in epoch 10, gen_loss = 0.3945093505697655, disc_loss = 0.08273761659660876
Trained batch 401 in epoch 10, gen_loss = 0.3945514748790371, disc_loss = 0.08264101178626257
Trained batch 402 in epoch 10, gen_loss = 0.3946627612149449, disc_loss = 0.0824792740586914
Trained batch 403 in epoch 10, gen_loss = 0.3948052227497101, disc_loss = 0.08249934043131289
Trained batch 404 in epoch 10, gen_loss = 0.39482412647317955, disc_loss = 0.08258978799560372
Trained batch 405 in epoch 10, gen_loss = 0.39476974095617023, disc_loss = 0.08247185404540906
Trained batch 406 in epoch 10, gen_loss = 0.3949772991624453, disc_loss = 0.08237456501614879
Trained batch 407 in epoch 10, gen_loss = 0.39488614533169597, disc_loss = 0.08242969686626549
Trained batch 408 in epoch 10, gen_loss = 0.39512112627402496, disc_loss = 0.08247312470418937
Trained batch 409 in epoch 10, gen_loss = 0.3952740836434248, disc_loss = 0.08230395495959716
Trained batch 410 in epoch 10, gen_loss = 0.39524548861522163, disc_loss = 0.08230513670434156
Trained batch 411 in epoch 10, gen_loss = 0.39512040791580977, disc_loss = 0.08236535744248771
Trained batch 412 in epoch 10, gen_loss = 0.3951271912376182, disc_loss = 0.08283070246542446
Trained batch 413 in epoch 10, gen_loss = 0.3949478954652657, disc_loss = 0.08269022993522962
Trained batch 414 in epoch 10, gen_loss = 0.3947702299399548, disc_loss = 0.08269739684098995
Trained batch 415 in epoch 10, gen_loss = 0.39468741782296163, disc_loss = 0.08253009801242464
Trained batch 416 in epoch 10, gen_loss = 0.39485928630657335, disc_loss = 0.08239412930742693
Trained batch 417 in epoch 10, gen_loss = 0.39480075603752046, disc_loss = 0.08225649267181077
Trained batch 418 in epoch 10, gen_loss = 0.39496343467286776, disc_loss = 0.08209845271997314
Trained batch 419 in epoch 10, gen_loss = 0.39492807459263574, disc_loss = 0.08211190017006759
Trained batch 420 in epoch 10, gen_loss = 0.3947993650713896, disc_loss = 0.08209719844582776
Trained batch 421 in epoch 10, gen_loss = 0.3948563903005202, disc_loss = 0.08195278109316118
Trained batch 422 in epoch 10, gen_loss = 0.39486493617648494, disc_loss = 0.08194139343411189
Trained batch 423 in epoch 10, gen_loss = 0.3950751330352055, disc_loss = 0.08216350744280718
Trained batch 424 in epoch 10, gen_loss = 0.39492944689357984, disc_loss = 0.08268614545354948
Trained batch 425 in epoch 10, gen_loss = 0.395039965779009, disc_loss = 0.08268015531652516
Trained batch 426 in epoch 10, gen_loss = 0.39507691132938555, disc_loss = 0.08253244075823828
Trained batch 427 in epoch 10, gen_loss = 0.3952348877754167, disc_loss = 0.08237259309612667
Trained batch 428 in epoch 10, gen_loss = 0.39517103083483823, disc_loss = 0.08227980220560115
Trained batch 429 in epoch 10, gen_loss = 0.39512306895366933, disc_loss = 0.0821947981484321
Trained batch 430 in epoch 10, gen_loss = 0.39503286713237273, disc_loss = 0.08207165449317501
Trained batch 431 in epoch 10, gen_loss = 0.39504616797246317, disc_loss = 0.08197171523352154
Trained batch 432 in epoch 10, gen_loss = 0.3950777594129153, disc_loss = 0.08188926858190818
Trained batch 433 in epoch 10, gen_loss = 0.39508691347689123, disc_loss = 0.08185304436416362
Trained batch 434 in epoch 10, gen_loss = 0.3951788224022964, disc_loss = 0.08202180563868292
Trained batch 435 in epoch 10, gen_loss = 0.3950207098088133, disc_loss = 0.08234604908935213
Trained batch 436 in epoch 10, gen_loss = 0.39509932025073596, disc_loss = 0.08225257648155093
Trained batch 437 in epoch 10, gen_loss = 0.39497570530192494, disc_loss = 0.08217086275023107
Trained batch 438 in epoch 10, gen_loss = 0.39497665032438917, disc_loss = 0.08203274377670504
Trained batch 439 in epoch 10, gen_loss = 0.3951990339566361, disc_loss = 0.08194999772187492
Trained batch 440 in epoch 10, gen_loss = 0.3951334530939591, disc_loss = 0.08197449405662834
Trained batch 441 in epoch 10, gen_loss = 0.3950671746450312, disc_loss = 0.0818703720015284
Trained batch 442 in epoch 10, gen_loss = 0.395163046318037, disc_loss = 0.0822148900552659
Trained batch 443 in epoch 10, gen_loss = 0.3948779441751875, disc_loss = 0.08253218454564712
Trained batch 444 in epoch 10, gen_loss = 0.39496183422174347, disc_loss = 0.08242194778442885
Trained batch 445 in epoch 10, gen_loss = 0.3948492333627068, disc_loss = 0.08244282206324151
Trained batch 446 in epoch 10, gen_loss = 0.3948055792441571, disc_loss = 0.08243884931587232
Trained batch 447 in epoch 10, gen_loss = 0.3947362736133592, disc_loss = 0.08236787037770098
Trained batch 448 in epoch 10, gen_loss = 0.39467214847726123, disc_loss = 0.0822335147352802
Trained batch 449 in epoch 10, gen_loss = 0.3946338740322325, disc_loss = 0.08211688571402596
Trained batch 450 in epoch 10, gen_loss = 0.3946941079295131, disc_loss = 0.08217457918028973
Trained batch 451 in epoch 10, gen_loss = 0.39490484894640676, disc_loss = 0.08241851278271659
Trained batch 452 in epoch 10, gen_loss = 0.39480318211298643, disc_loss = 0.08251128709108196
Trained batch 453 in epoch 10, gen_loss = 0.3948476944069505, disc_loss = 0.0823918293724616
Trained batch 454 in epoch 10, gen_loss = 0.394879217003728, disc_loss = 0.08233447974588681
Trained batch 455 in epoch 10, gen_loss = 0.3946542717647134, disc_loss = 0.08267921136524692
Trained batch 456 in epoch 10, gen_loss = 0.3949117007088609, disc_loss = 0.08300554294942081
Trained batch 457 in epoch 10, gen_loss = 0.3947177485087032, disc_loss = 0.08293567675849073
Trained batch 458 in epoch 10, gen_loss = 0.39496158203008647, disc_loss = 0.08286055075085857
Testing Epoch 10
Training Epoch 11
Trained batch 0 in epoch 11, gen_loss = 0.3729639947414398, disc_loss = 0.19276584684848785
Trained batch 1 in epoch 11, gen_loss = 0.42313942313194275, disc_loss = 0.14937333017587662
Trained batch 2 in epoch 11, gen_loss = 0.43148065606753033, disc_loss = 0.11094921827316284
Trained batch 3 in epoch 11, gen_loss = 0.44172682613134384, disc_loss = 0.09183354396373034
Trained batch 4 in epoch 11, gen_loss = 0.41647784113883973, disc_loss = 0.08584474623203278
Trained batch 5 in epoch 11, gen_loss = 0.4367116043965022, disc_loss = 0.07397543297459681
Trained batch 6 in epoch 11, gen_loss = 0.43288340313094004, disc_loss = 0.06581427502845015
Trained batch 7 in epoch 11, gen_loss = 0.4278509356081486, disc_loss = 0.059740547090768814
Trained batch 8 in epoch 11, gen_loss = 0.43410344918568927, disc_loss = 0.05460910074826744
Trained batch 9 in epoch 11, gen_loss = 0.42506615817546844, disc_loss = 0.05430021649226546
Trained batch 10 in epoch 11, gen_loss = 0.423651784658432, disc_loss = 0.05868405027484352
Trained batch 11 in epoch 11, gen_loss = 0.42918023218711215, disc_loss = 0.055519821510339774
Trained batch 12 in epoch 11, gen_loss = 0.42280629735726577, disc_loss = 0.06821980363187882
Trained batch 13 in epoch 11, gen_loss = 0.42807240784168243, disc_loss = 0.0779735986808581
Trained batch 14 in epoch 11, gen_loss = 0.42927602330843606, disc_loss = 0.07359924657891194
Trained batch 15 in epoch 11, gen_loss = 0.42851688154041767, disc_loss = 0.07075729611096904
Trained batch 16 in epoch 11, gen_loss = 0.42534032464027405, disc_loss = 0.06790099857265458
Trained batch 17 in epoch 11, gen_loss = 0.42498457100656295, disc_loss = 0.06482479405692881
Trained batch 18 in epoch 11, gen_loss = 0.42263459218175786, disc_loss = 0.06240802527846474
Trained batch 19 in epoch 11, gen_loss = 0.4191370144486427, disc_loss = 0.06142808380536735
Trained batch 20 in epoch 11, gen_loss = 0.4156247803143093, disc_loss = 0.05947799160189572
Trained batch 21 in epoch 11, gen_loss = 0.41543667153878644, disc_loss = 0.06157591663808985
Trained batch 22 in epoch 11, gen_loss = 0.41585272809733514, disc_loss = 0.06259733790774709
Trained batch 23 in epoch 11, gen_loss = 0.4146835220356782, disc_loss = 0.060348283926335476
Trained batch 24 in epoch 11, gen_loss = 0.4138836419582367, disc_loss = 0.058492467366158964
Trained batch 25 in epoch 11, gen_loss = 0.41293196380138397, disc_loss = 0.056890095834835216
Trained batch 26 in epoch 11, gen_loss = 0.41190100378460354, disc_loss = 0.05776248944716321
Trained batch 27 in epoch 11, gen_loss = 0.4147345083100455, disc_loss = 0.05643148756852107
Trained batch 28 in epoch 11, gen_loss = 0.41239473531986104, disc_loss = 0.055627223072123935
Trained batch 29 in epoch 11, gen_loss = 0.4119554450114568, disc_loss = 0.054073182741800944
Trained batch 30 in epoch 11, gen_loss = 0.4106907123519528, disc_loss = 0.053673143468556866
Trained batch 31 in epoch 11, gen_loss = 0.41222588811069727, disc_loss = 0.052268887986429036
Trained batch 32 in epoch 11, gen_loss = 0.41346600290500757, disc_loss = 0.052380011727412544
Trained batch 33 in epoch 11, gen_loss = 0.41066910238826976, disc_loss = 0.0519053434186122
Trained batch 34 in epoch 11, gen_loss = 0.4135236774172102, disc_loss = 0.05173636951616832
Trained batch 35 in epoch 11, gen_loss = 0.4159715672334035, disc_loss = 0.05184139787322945
Trained batch 36 in epoch 11, gen_loss = 0.4163269746947933, disc_loss = 0.05092819543505037
Trained batch 37 in epoch 11, gen_loss = 0.41668707446048137, disc_loss = 0.05047515941489684
Trained batch 38 in epoch 11, gen_loss = 0.41652804689529616, disc_loss = 0.049488785987099014
Trained batch 39 in epoch 11, gen_loss = 0.41853497102856635, disc_loss = 0.04895566808991134
Trained batch 40 in epoch 11, gen_loss = 0.42049437979372534, disc_loss = 0.04879146791631129
Trained batch 41 in epoch 11, gen_loss = 0.4189937661091487, disc_loss = 0.04814737560671
Trained batch 42 in epoch 11, gen_loss = 0.4173272487729095, disc_loss = 0.04788474179804325
Trained batch 43 in epoch 11, gen_loss = 0.4198707030578093, disc_loss = 0.04701619366691871
Trained batch 44 in epoch 11, gen_loss = 0.4195866730478075, disc_loss = 0.0475147723323769
Trained batch 45 in epoch 11, gen_loss = 0.4181539617154909, disc_loss = 0.04782049066346625
Trained batch 46 in epoch 11, gen_loss = 0.41939946692040625, disc_loss = 0.04705873932293121
Trained batch 47 in epoch 11, gen_loss = 0.4182342241207759, disc_loss = 0.046303594504327826
Trained batch 48 in epoch 11, gen_loss = 0.41824062746398305, disc_loss = 0.045563419691610096
Trained batch 49 in epoch 11, gen_loss = 0.4176864516735077, disc_loss = 0.04509767511859536
Trained batch 50 in epoch 11, gen_loss = 0.4176827289310156, disc_loss = 0.04540057189981727
Trained batch 51 in epoch 11, gen_loss = 0.41664572002796024, disc_loss = 0.04510090186690482
Trained batch 52 in epoch 11, gen_loss = 0.4160685511130207, disc_loss = 0.04489279729929173
Trained batch 53 in epoch 11, gen_loss = 0.4176051798794005, disc_loss = 0.04454424320202735
Trained batch 54 in epoch 11, gen_loss = 0.41697700728069653, disc_loss = 0.0445104711943052
Trained batch 55 in epoch 11, gen_loss = 0.4166045407099383, disc_loss = 0.04630246989628566
Trained batch 56 in epoch 11, gen_loss = 0.4174104495006695, disc_loss = 0.04601176980098611
Trained batch 57 in epoch 11, gen_loss = 0.4190397411584854, disc_loss = 0.04559227854719963
Trained batch 58 in epoch 11, gen_loss = 0.41856457570851857, disc_loss = 0.04496067011002767
Trained batch 59 in epoch 11, gen_loss = 0.41883030384778974, disc_loss = 0.044763043771187463
Trained batch 60 in epoch 11, gen_loss = 0.41923405498754784, disc_loss = 0.04425097834013524
Trained batch 61 in epoch 11, gen_loss = 0.41956149185857466, disc_loss = 0.04449504382547832
Trained batch 62 in epoch 11, gen_loss = 0.4184290776177058, disc_loss = 0.049402682169798824
Trained batch 63 in epoch 11, gen_loss = 0.41926444228738546, disc_loss = 0.050897895911475644
Trained batch 64 in epoch 11, gen_loss = 0.42032098632592424, disc_loss = 0.050989354086609984
Trained batch 65 in epoch 11, gen_loss = 0.41837490417740564, disc_loss = 0.053290458085636296
Trained batch 66 in epoch 11, gen_loss = 0.41977136081724026, disc_loss = 0.05287799350361326
Trained batch 67 in epoch 11, gen_loss = 0.42001380464609933, disc_loss = 0.052337224376113975
Trained batch 68 in epoch 11, gen_loss = 0.4208615137183148, disc_loss = 0.052311471460954
Trained batch 69 in epoch 11, gen_loss = 0.41920392300401416, disc_loss = 0.0525961946696043
Trained batch 70 in epoch 11, gen_loss = 0.418569995483882, disc_loss = 0.052869699528099785
Trained batch 71 in epoch 11, gen_loss = 0.41873807418677544, disc_loss = 0.05349114573457175
Trained batch 72 in epoch 11, gen_loss = 0.41773224815930404, disc_loss = 0.0547317394552982
Trained batch 73 in epoch 11, gen_loss = 0.41799602516599604, disc_loss = 0.05509887378964875
Trained batch 74 in epoch 11, gen_loss = 0.4162923256556193, disc_loss = 0.05565771187345187
Trained batch 75 in epoch 11, gen_loss = 0.4176372485725503, disc_loss = 0.056658734665497354
Trained batch 76 in epoch 11, gen_loss = 0.41918165652782885, disc_loss = 0.056447278514697954
Trained batch 77 in epoch 11, gen_loss = 0.419075981546671, disc_loss = 0.05650035029229445
Trained batch 78 in epoch 11, gen_loss = 0.41934906719606135, disc_loss = 0.056237118766654895
Trained batch 79 in epoch 11, gen_loss = 0.41880767047405243, disc_loss = 0.0557841598521918
Trained batch 80 in epoch 11, gen_loss = 0.41832060431256707, disc_loss = 0.0552466060437354
Trained batch 81 in epoch 11, gen_loss = 0.41868478641277407, disc_loss = 0.05513708678460339
Trained batch 82 in epoch 11, gen_loss = 0.41745169981416447, disc_loss = 0.056180589024471234
Trained batch 83 in epoch 11, gen_loss = 0.41733533711660475, disc_loss = 0.05567897438249063
Trained batch 84 in epoch 11, gen_loss = 0.41792957993114693, disc_loss = 0.056657308066154224
Trained batch 85 in epoch 11, gen_loss = 0.41611858439999955, disc_loss = 0.057972020437117924
Trained batch 86 in epoch 11, gen_loss = 0.41552729236668556, disc_loss = 0.05765949959342165
Trained batch 87 in epoch 11, gen_loss = 0.41472282870249316, disc_loss = 0.057974144467152655
Trained batch 88 in epoch 11, gen_loss = 0.4146603530042627, disc_loss = 0.05892867987368549
Trained batch 89 in epoch 11, gen_loss = 0.4144260138273239, disc_loss = 0.05869121297986971
Trained batch 90 in epoch 11, gen_loss = 0.41490506143360345, disc_loss = 0.0581851385349592
Trained batch 91 in epoch 11, gen_loss = 0.41429104655981064, disc_loss = 0.058162656400109765
Trained batch 92 in epoch 11, gen_loss = 0.4141942259444985, disc_loss = 0.057998620844896764
Trained batch 93 in epoch 11, gen_loss = 0.41464873926436646, disc_loss = 0.06100653221909987
Trained batch 94 in epoch 11, gen_loss = 0.41324991176002907, disc_loss = 0.06506704043989119
Trained batch 95 in epoch 11, gen_loss = 0.41366808488965034, disc_loss = 0.06500605085360196
Trained batch 96 in epoch 11, gen_loss = 0.4133562107676083, disc_loss = 0.06505200238994409
Trained batch 97 in epoch 11, gen_loss = 0.41328506019650674, disc_loss = 0.06475981312556839
Trained batch 98 in epoch 11, gen_loss = 0.4133063295874933, disc_loss = 0.06469894850607773
Trained batch 99 in epoch 11, gen_loss = 0.41225425064563753, disc_loss = 0.0654535077046603
Trained batch 100 in epoch 11, gen_loss = 0.41110519548453905, disc_loss = 0.0652261651812656
Trained batch 101 in epoch 11, gen_loss = 0.4106290428077473, disc_loss = 0.06559661866220481
Trained batch 102 in epoch 11, gen_loss = 0.41090870337578855, disc_loss = 0.06629619554806392
Trained batch 103 in epoch 11, gen_loss = 0.41061489943128365, disc_loss = 0.06623917265544431
Trained batch 104 in epoch 11, gen_loss = 0.4108626885073526, disc_loss = 0.0658472958153912
Trained batch 105 in epoch 11, gen_loss = 0.4101026252193271, disc_loss = 0.06559914189724708
Trained batch 106 in epoch 11, gen_loss = 0.4100170689765538, disc_loss = 0.06538932357053055
Trained batch 107 in epoch 11, gen_loss = 0.4092661249968741, disc_loss = 0.0652738546486944
Trained batch 108 in epoch 11, gen_loss = 0.4087412543253067, disc_loss = 0.065691346670031
Trained batch 109 in epoch 11, gen_loss = 0.4085021438923749, disc_loss = 0.06536190903491594
Trained batch 110 in epoch 11, gen_loss = 0.4082791421327505, disc_loss = 0.06560534138970815
Trained batch 111 in epoch 11, gen_loss = 0.4086583855428866, disc_loss = 0.06508391246149715
Trained batch 112 in epoch 11, gen_loss = 0.40785904083631735, disc_loss = 0.06486986081767003
Trained batch 113 in epoch 11, gen_loss = 0.40775012420980555, disc_loss = 0.06440993462558509
Trained batch 114 in epoch 11, gen_loss = 0.40726212029871733, disc_loss = 0.06497924054527413
Trained batch 115 in epoch 11, gen_loss = 0.4065435007214546, disc_loss = 0.06619115943362101
Trained batch 116 in epoch 11, gen_loss = 0.4071523618494344, disc_loss = 0.06653951896895838
Trained batch 117 in epoch 11, gen_loss = 0.4074690152527922, disc_loss = 0.06629009291103458
Trained batch 118 in epoch 11, gen_loss = 0.4080024278965317, disc_loss = 0.0657879776759621
Trained batch 119 in epoch 11, gen_loss = 0.4085697211325169, disc_loss = 0.06538036121443534
Trained batch 120 in epoch 11, gen_loss = 0.4087862069449149, disc_loss = 0.06496164960448038
Trained batch 121 in epoch 11, gen_loss = 0.408734887349801, disc_loss = 0.06469194649443885
Trained batch 122 in epoch 11, gen_loss = 0.4090659528728423, disc_loss = 0.06432812790030508
Trained batch 123 in epoch 11, gen_loss = 0.40901876721651326, disc_loss = 0.06400387497213218
Trained batch 124 in epoch 11, gen_loss = 0.40896351408958437, disc_loss = 0.06382775518670677
Trained batch 125 in epoch 11, gen_loss = 0.4089286358110488, disc_loss = 0.06359700193732148
Trained batch 126 in epoch 11, gen_loss = 0.40854329175836457, disc_loss = 0.0635370928097487
Trained batch 127 in epoch 11, gen_loss = 0.4083968687336892, disc_loss = 0.06389932489037164
Trained batch 128 in epoch 11, gen_loss = 0.40793701082237005, disc_loss = 0.06657538803063276
Trained batch 129 in epoch 11, gen_loss = 0.4077216260708295, disc_loss = 0.06655886199396964
Trained batch 130 in epoch 11, gen_loss = 0.4074858197274099, disc_loss = 0.0673438759115418
Trained batch 131 in epoch 11, gen_loss = 0.4063737177939126, disc_loss = 0.06860957997780519
Trained batch 132 in epoch 11, gen_loss = 0.4063752143454731, disc_loss = 0.06854992559095635
Trained batch 133 in epoch 11, gen_loss = 0.40574061225599317, disc_loss = 0.06861006432741101
Trained batch 134 in epoch 11, gen_loss = 0.40594999525282116, disc_loss = 0.06820739810182541
Trained batch 135 in epoch 11, gen_loss = 0.40578292879988165, disc_loss = 0.06801629553014851
Trained batch 136 in epoch 11, gen_loss = 0.40553805253801556, disc_loss = 0.06809409331516737
Trained batch 137 in epoch 11, gen_loss = 0.4057533594145291, disc_loss = 0.06929947013723785
Trained batch 138 in epoch 11, gen_loss = 0.40602673858189753, disc_loss = 0.06904183150262391
Trained batch 139 in epoch 11, gen_loss = 0.405462640949658, disc_loss = 0.06912958972222571
Trained batch 140 in epoch 11, gen_loss = 0.405379334874187, disc_loss = 0.06939368688745808
Trained batch 141 in epoch 11, gen_loss = 0.4055154430614391, disc_loss = 0.06907928247385146
Trained batch 142 in epoch 11, gen_loss = 0.4048855046292285, disc_loss = 0.06944493246362447
Trained batch 143 in epoch 11, gen_loss = 0.4051889056960742, disc_loss = 0.07091705889454009
Trained batch 144 in epoch 11, gen_loss = 0.40528386091363844, disc_loss = 0.07101071795834035
Trained batch 145 in epoch 11, gen_loss = 0.40503405851044066, disc_loss = 0.0707885211697231
Trained batch 146 in epoch 11, gen_loss = 0.4047740310633264, disc_loss = 0.07072093713154294
Trained batch 147 in epoch 11, gen_loss = 0.4050453097836391, disc_loss = 0.07135039110152
Trained batch 148 in epoch 11, gen_loss = 0.4050670138141453, disc_loss = 0.07093951273272002
Trained batch 149 in epoch 11, gen_loss = 0.40392757962147396, disc_loss = 0.07236879415499667
Trained batch 150 in epoch 11, gen_loss = 0.40414044862946136, disc_loss = 0.07267383498059499
Trained batch 151 in epoch 11, gen_loss = 0.40426209108217764, disc_loss = 0.07235505376440032
Trained batch 152 in epoch 11, gen_loss = 0.40359870583013774, disc_loss = 0.07212603202674027
Trained batch 153 in epoch 11, gen_loss = 0.4029917733429314, disc_loss = 0.07296054939400744
Trained batch 154 in epoch 11, gen_loss = 0.4030207804133815, disc_loss = 0.07357912259176373
Trained batch 155 in epoch 11, gen_loss = 0.4029917826828284, disc_loss = 0.07324563039359279
Trained batch 156 in epoch 11, gen_loss = 0.4024620687316178, disc_loss = 0.07305080112318989
Trained batch 157 in epoch 11, gen_loss = 0.4021642757933351, disc_loss = 0.0741382975549779
Trained batch 158 in epoch 11, gen_loss = 0.40269624090419626, disc_loss = 0.07444571001666053
Trained batch 159 in epoch 11, gen_loss = 0.40281965071335435, disc_loss = 0.07500427016930189
Trained batch 160 in epoch 11, gen_loss = 0.402605659195355, disc_loss = 0.0751513287696918
Trained batch 161 in epoch 11, gen_loss = 0.4023926557030207, disc_loss = 0.07481344288824425
Trained batch 162 in epoch 11, gen_loss = 0.40213474475898625, disc_loss = 0.07447607736131805
Trained batch 163 in epoch 11, gen_loss = 0.4024705835050199, disc_loss = 0.07414506942249562
Trained batch 164 in epoch 11, gen_loss = 0.4022371796947537, disc_loss = 0.07401129498118253
Trained batch 165 in epoch 11, gen_loss = 0.4017082108970148, disc_loss = 0.07432716549374163
Trained batch 166 in epoch 11, gen_loss = 0.4014208979770809, disc_loss = 0.07610389147188046
Trained batch 167 in epoch 11, gen_loss = 0.40149932558692636, disc_loss = 0.07797271495274756
Trained batch 168 in epoch 11, gen_loss = 0.4012024950169953, disc_loss = 0.07783936822412194
Trained batch 169 in epoch 11, gen_loss = 0.40088481368387446, disc_loss = 0.07774125774500563
Trained batch 170 in epoch 11, gen_loss = 0.40138312607829335, disc_loss = 0.07764509114115471
Trained batch 171 in epoch 11, gen_loss = 0.40135272271757905, disc_loss = 0.07738081468431669
Trained batch 172 in epoch 11, gen_loss = 0.40101672864029175, disc_loss = 0.07760371313823354
Trained batch 173 in epoch 11, gen_loss = 0.4004328469264096, disc_loss = 0.0782481384297683
Trained batch 174 in epoch 11, gen_loss = 0.40062639619622914, disc_loss = 0.07822253660165839
Trained batch 175 in epoch 11, gen_loss = 0.4005113268609751, disc_loss = 0.07827947465226646
Trained batch 176 in epoch 11, gen_loss = 0.4000959621142533, disc_loss = 0.07829697870801987
Trained batch 177 in epoch 11, gen_loss = 0.4001231102293797, disc_loss = 0.07836947747861987
Trained batch 178 in epoch 11, gen_loss = 0.4000892465174531, disc_loss = 0.07814619287213716
Trained batch 179 in epoch 11, gen_loss = 0.400316352231635, disc_loss = 0.07794531025768568
Trained batch 180 in epoch 11, gen_loss = 0.39958362034341904, disc_loss = 0.07863611539373
Trained batch 181 in epoch 11, gen_loss = 0.3996830324714, disc_loss = 0.07972408811418483
Trained batch 182 in epoch 11, gen_loss = 0.39957984899236854, disc_loss = 0.07943431195126124
Trained batch 183 in epoch 11, gen_loss = 0.39908825549418514, disc_loss = 0.07934959921935249
Trained batch 184 in epoch 11, gen_loss = 0.39865426364782697, disc_loss = 0.07906527550186257
Trained batch 185 in epoch 11, gen_loss = 0.3985321575435259, disc_loss = 0.07887267458292666
Trained batch 186 in epoch 11, gen_loss = 0.3982655161364193, disc_loss = 0.07862765442350889
Trained batch 187 in epoch 11, gen_loss = 0.3981138376637976, disc_loss = 0.07845204605651583
Trained batch 188 in epoch 11, gen_loss = 0.39818310146293945, disc_loss = 0.07858933335682623
Trained batch 189 in epoch 11, gen_loss = 0.39844386459965453, disc_loss = 0.07843730407276828
Trained batch 190 in epoch 11, gen_loss = 0.39832746444260264, disc_loss = 0.07811964961275926
Trained batch 191 in epoch 11, gen_loss = 0.3981909775951256, disc_loss = 0.07800353848870145
Trained batch 192 in epoch 11, gen_loss = 0.398410832094405, disc_loss = 0.07770110329690298
Trained batch 193 in epoch 11, gen_loss = 0.3982599277010898, disc_loss = 0.07779097191019695
Trained batch 194 in epoch 11, gen_loss = 0.39856827679352885, disc_loss = 0.07749649009977778
Trained batch 195 in epoch 11, gen_loss = 0.39875537742461475, disc_loss = 0.07720693533204268
Trained batch 196 in epoch 11, gen_loss = 0.39838592375292997, disc_loss = 0.07727531114649878
Trained batch 197 in epoch 11, gen_loss = 0.39793010153854735, disc_loss = 0.07922427854594784
Trained batch 198 in epoch 11, gen_loss = 0.3981422939941512, disc_loss = 0.07907245948152551
Trained batch 199 in epoch 11, gen_loss = 0.39813530184328555, disc_loss = 0.07902906797593459
Trained batch 200 in epoch 11, gen_loss = 0.39815260796108054, disc_loss = 0.07906475837171004
Trained batch 201 in epoch 11, gen_loss = 0.3980060643931427, disc_loss = 0.07900243558422985
Trained batch 202 in epoch 11, gen_loss = 0.39757944966478304, disc_loss = 0.07912924463443201
Trained batch 203 in epoch 11, gen_loss = 0.3977263677207863, disc_loss = 0.079298192559851
Trained batch 204 in epoch 11, gen_loss = 0.39777086326261846, disc_loss = 0.07895346610784167
Trained batch 205 in epoch 11, gen_loss = 0.3980598188575032, disc_loss = 0.07876248449512116
Trained batch 206 in epoch 11, gen_loss = 0.39779188055635073, disc_loss = 0.07865802938082583
Trained batch 207 in epoch 11, gen_loss = 0.3978794545938189, disc_loss = 0.0783200151748203
Trained batch 208 in epoch 11, gen_loss = 0.3979199411053407, disc_loss = 0.07817414667430606
Trained batch 209 in epoch 11, gen_loss = 0.3974376518811498, disc_loss = 0.07800997602753341
Trained batch 210 in epoch 11, gen_loss = 0.3977656010626617, disc_loss = 0.07775654962233387
Trained batch 211 in epoch 11, gen_loss = 0.39775274279263784, disc_loss = 0.07810418143262209
Trained batch 212 in epoch 11, gen_loss = 0.39763919743293885, disc_loss = 0.07848070272213906
Trained batch 213 in epoch 11, gen_loss = 0.39801987009906326, disc_loss = 0.07830609562893824
Trained batch 214 in epoch 11, gen_loss = 0.3981741451246794, disc_loss = 0.07812692398898477
Trained batch 215 in epoch 11, gen_loss = 0.3980062499780346, disc_loss = 0.07780620480534034
Trained batch 216 in epoch 11, gen_loss = 0.3974943245473545, disc_loss = 0.07764646754930576
Trained batch 217 in epoch 11, gen_loss = 0.39759701456225244, disc_loss = 0.07736960846990552
Trained batch 218 in epoch 11, gen_loss = 0.39774016151417335, disc_loss = 0.07704879120034783
Trained batch 219 in epoch 11, gen_loss = 0.39748423742977057, disc_loss = 0.07702045252081006
Trained batch 220 in epoch 11, gen_loss = 0.3975409907857757, disc_loss = 0.07708786482969088
Trained batch 221 in epoch 11, gen_loss = 0.3975243406655552, disc_loss = 0.07681175201569122
Trained batch 222 in epoch 11, gen_loss = 0.39752695478933275, disc_loss = 0.07665017508847363
Trained batch 223 in epoch 11, gen_loss = 0.39765592657827903, disc_loss = 0.07639799159993085
Trained batch 224 in epoch 11, gen_loss = 0.3974279616276423, disc_loss = 0.07632879620831874
Trained batch 225 in epoch 11, gen_loss = 0.39775750852000397, disc_loss = 0.07626139322518313
Trained batch 226 in epoch 11, gen_loss = 0.39735474887135797, disc_loss = 0.07717295190614816
Trained batch 227 in epoch 11, gen_loss = 0.3979156441463713, disc_loss = 0.07820984625804908
Trained batch 228 in epoch 11, gen_loss = 0.39762663379246493, disc_loss = 0.07826235785665535
Trained batch 229 in epoch 11, gen_loss = 0.3973611157225526, disc_loss = 0.07868055182347156
Trained batch 230 in epoch 11, gen_loss = 0.3971489318908551, disc_loss = 0.07887817731578693
Trained batch 231 in epoch 11, gen_loss = 0.39698770468861894, disc_loss = 0.07989639518501494
Trained batch 232 in epoch 11, gen_loss = 0.3973988212101449, disc_loss = 0.08147410235603544
Trained batch 233 in epoch 11, gen_loss = 0.3971785245160771, disc_loss = 0.08198260120514175
Trained batch 234 in epoch 11, gen_loss = 0.39695825938214646, disc_loss = 0.0823662073628858
Trained batch 235 in epoch 11, gen_loss = 0.3968207350600574, disc_loss = 0.08239843209581924
Trained batch 236 in epoch 11, gen_loss = 0.3966990703646141, disc_loss = 0.08247243782175304
Trained batch 237 in epoch 11, gen_loss = 0.39676573365425866, disc_loss = 0.08234762855288925
Trained batch 238 in epoch 11, gen_loss = 0.39689398329377673, disc_loss = 0.08228738971685827
Trained batch 239 in epoch 11, gen_loss = 0.3967013853912552, disc_loss = 0.08211505292953612
Trained batch 240 in epoch 11, gen_loss = 0.3964018756794237, disc_loss = 0.08214036666853856
Trained batch 241 in epoch 11, gen_loss = 0.39655496309365124, disc_loss = 0.08202972284071763
Trained batch 242 in epoch 11, gen_loss = 0.3968310294205269, disc_loss = 0.08184386415161775
Trained batch 243 in epoch 11, gen_loss = 0.3966952172092727, disc_loss = 0.08191689310908379
Trained batch 244 in epoch 11, gen_loss = 0.3968066955707511, disc_loss = 0.08262088456362182
Trained batch 245 in epoch 11, gen_loss = 0.3966174046319675, disc_loss = 0.08257844019870508
Trained batch 246 in epoch 11, gen_loss = 0.39656310845241854, disc_loss = 0.08233883923583245
Trained batch 247 in epoch 11, gen_loss = 0.3964431914951532, disc_loss = 0.08224632961472737
Trained batch 248 in epoch 11, gen_loss = 0.39622219768633327, disc_loss = 0.08251223726063428
Trained batch 249 in epoch 11, gen_loss = 0.39626025658845904, disc_loss = 0.08243358618952334
Trained batch 250 in epoch 11, gen_loss = 0.3960852098773675, disc_loss = 0.08214655265293688
Trained batch 251 in epoch 11, gen_loss = 0.3960652079965387, disc_loss = 0.08189779933771148
Trained batch 252 in epoch 11, gen_loss = 0.39600895828173566, disc_loss = 0.08170680495406034
Trained batch 253 in epoch 11, gen_loss = 0.39617392309303356, disc_loss = 0.0815938640602197
Trained batch 254 in epoch 11, gen_loss = 0.3961505012769325, disc_loss = 0.08157759669474235
Trained batch 255 in epoch 11, gen_loss = 0.39594243810279295, disc_loss = 0.0815028330671339
Trained batch 256 in epoch 11, gen_loss = 0.3956641375670637, disc_loss = 0.08193684709783831
Trained batch 257 in epoch 11, gen_loss = 0.39591839233803194, disc_loss = 0.08311009310120933
Trained batch 258 in epoch 11, gen_loss = 0.39615172165010887, disc_loss = 0.08293438666683539
Trained batch 259 in epoch 11, gen_loss = 0.3960187489596697, disc_loss = 0.08332507405250977
Trained batch 260 in epoch 11, gen_loss = 0.39625889331216557, disc_loss = 0.08312016261484602
Trained batch 261 in epoch 11, gen_loss = 0.396412126833701, disc_loss = 0.08330577809384931
Trained batch 262 in epoch 11, gen_loss = 0.3963178896518715, disc_loss = 0.08321909675686248
Trained batch 263 in epoch 11, gen_loss = 0.39601141152282554, disc_loss = 0.08333573215041366
Trained batch 264 in epoch 11, gen_loss = 0.396312193769329, disc_loss = 0.08334835499068195
Trained batch 265 in epoch 11, gen_loss = 0.3962025501786318, disc_loss = 0.08315988799340014
Trained batch 266 in epoch 11, gen_loss = 0.39581218412083186, disc_loss = 0.08428640977378363
Trained batch 267 in epoch 11, gen_loss = 0.39584061153121847, disc_loss = 0.0859777193026506
Trained batch 268 in epoch 11, gen_loss = 0.3960450622339674, disc_loss = 0.08609802102614679
Trained batch 269 in epoch 11, gen_loss = 0.39559361818763944, disc_loss = 0.08642476704489026
Trained batch 270 in epoch 11, gen_loss = 0.39543229050082035, disc_loss = 0.08625552051174849
Trained batch 271 in epoch 11, gen_loss = 0.3951776512515019, disc_loss = 0.08605194153257317
Trained batch 272 in epoch 11, gen_loss = 0.395365120999979, disc_loss = 0.08584774657913344
Trained batch 273 in epoch 11, gen_loss = 0.39519065797981556, disc_loss = 0.0856569287941594
Trained batch 274 in epoch 11, gen_loss = 0.3946706110239029, disc_loss = 0.08557603322477503
Trained batch 275 in epoch 11, gen_loss = 0.394625977491555, disc_loss = 0.08550453872885555
Trained batch 276 in epoch 11, gen_loss = 0.3946430598678141, disc_loss = 0.0853871905534034
Trained batch 277 in epoch 11, gen_loss = 0.3944189128794258, disc_loss = 0.08536294382568047
Trained batch 278 in epoch 11, gen_loss = 0.3944456068311541, disc_loss = 0.08533533292532128
Trained batch 279 in epoch 11, gen_loss = 0.3945316010820014, disc_loss = 0.08510984276654199
Trained batch 280 in epoch 11, gen_loss = 0.3944621036803595, disc_loss = 0.08510815576083454
Trained batch 281 in epoch 11, gen_loss = 0.39428017837992796, disc_loss = 0.08550620621816644
Trained batch 282 in epoch 11, gen_loss = 0.3945596791514238, disc_loss = 0.0864629581580498
Trained batch 283 in epoch 11, gen_loss = 0.39423169379293077, disc_loss = 0.08651519439373376
Trained batch 284 in epoch 11, gen_loss = 0.39420427967581834, disc_loss = 0.08642921302500263
Trained batch 285 in epoch 11, gen_loss = 0.39409374237268957, disc_loss = 0.08636652893009042
Trained batch 286 in epoch 11, gen_loss = 0.39435530503244764, disc_loss = 0.08621057985960555
Trained batch 287 in epoch 11, gen_loss = 0.39422999958818156, disc_loss = 0.08596096856733008
Trained batch 288 in epoch 11, gen_loss = 0.39409617182498985, disc_loss = 0.08578957473072885
Trained batch 289 in epoch 11, gen_loss = 0.3940742869315476, disc_loss = 0.08565996947120233
Trained batch 290 in epoch 11, gen_loss = 0.39402460422098023, disc_loss = 0.0856064312508861
Trained batch 291 in epoch 11, gen_loss = 0.39417370066863217, disc_loss = 0.08551412448446483
Trained batch 292 in epoch 11, gen_loss = 0.3939963238943152, disc_loss = 0.08543607597827352
Trained batch 293 in epoch 11, gen_loss = 0.3942517442058544, disc_loss = 0.0854680391209086
Trained batch 294 in epoch 11, gen_loss = 0.39433093661979096, disc_loss = 0.08609511801909844
Trained batch 295 in epoch 11, gen_loss = 0.3943679529569439, disc_loss = 0.08600348697478152
Trained batch 296 in epoch 11, gen_loss = 0.394311384570719, disc_loss = 0.08588204116588741
Trained batch 297 in epoch 11, gen_loss = 0.39415370752947443, disc_loss = 0.08586566660384454
Trained batch 298 in epoch 11, gen_loss = 0.3943405846588588, disc_loss = 0.08567225746343217
Trained batch 299 in epoch 11, gen_loss = 0.39419295623898504, disc_loss = 0.0855302106604601
Trained batch 300 in epoch 11, gen_loss = 0.3944390610702014, disc_loss = 0.08577991361293533
Trained batch 301 in epoch 11, gen_loss = 0.39460604993120724, disc_loss = 0.08558684195367162
Trained batch 302 in epoch 11, gen_loss = 0.394440161168772, disc_loss = 0.08567506859460139
Trained batch 303 in epoch 11, gen_loss = 0.39469000260884823, disc_loss = 0.0855965462994247
Trained batch 304 in epoch 11, gen_loss = 0.39483031195695284, disc_loss = 0.08534223305855373
Trained batch 305 in epoch 11, gen_loss = 0.39483710884853124, disc_loss = 0.08509697793264648
Trained batch 306 in epoch 11, gen_loss = 0.3947394113101866, disc_loss = 0.08491727833693744
Trained batch 307 in epoch 11, gen_loss = 0.3945506584237922, disc_loss = 0.08484523404879471
Trained batch 308 in epoch 11, gen_loss = 0.3943676620143131, disc_loss = 0.0850016298239695
Trained batch 309 in epoch 11, gen_loss = 0.39461871736472653, disc_loss = 0.08567129854383247
Trained batch 310 in epoch 11, gen_loss = 0.39481562927029906, disc_loss = 0.08545698268770262
Trained batch 311 in epoch 11, gen_loss = 0.39466807002631515, disc_loss = 0.08551219428250662
Trained batch 312 in epoch 11, gen_loss = 0.39452237781053917, disc_loss = 0.08573654534580846
Trained batch 313 in epoch 11, gen_loss = 0.39456177616764787, disc_loss = 0.08556899283775336
Trained batch 314 in epoch 11, gen_loss = 0.39460820314430056, disc_loss = 0.0854987251867969
Trained batch 315 in epoch 11, gen_loss = 0.39434531156586694, disc_loss = 0.08550414155514416
Trained batch 316 in epoch 11, gen_loss = 0.39471957787918366, disc_loss = 0.08560421357918471
Trained batch 317 in epoch 11, gen_loss = 0.3949422627781172, disc_loss = 0.08537623890289017
Trained batch 318 in epoch 11, gen_loss = 0.39501084079002513, disc_loss = 0.08513212267186808
Trained batch 319 in epoch 11, gen_loss = 0.39488192605786027, disc_loss = 0.08492729289719136
Trained batch 320 in epoch 11, gen_loss = 0.39494481770977424, disc_loss = 0.0847650555693588
Trained batch 321 in epoch 11, gen_loss = 0.3948969254675119, disc_loss = 0.08458016870213637
Trained batch 322 in epoch 11, gen_loss = 0.3947449784622104, disc_loss = 0.08453962533956758
Trained batch 323 in epoch 11, gen_loss = 0.39471734779668444, disc_loss = 0.08438105809496554
Trained batch 324 in epoch 11, gen_loss = 0.39480833645050345, disc_loss = 0.08424334933694738
Trained batch 325 in epoch 11, gen_loss = 0.39479356432802104, disc_loss = 0.0840424473863095
Trained batch 326 in epoch 11, gen_loss = 0.3949167228528848, disc_loss = 0.08387549434124922
Trained batch 327 in epoch 11, gen_loss = 0.39458968122376176, disc_loss = 0.08394599100148942
Trained batch 328 in epoch 11, gen_loss = 0.3946930461288585, disc_loss = 0.08482587802447492
Trained batch 329 in epoch 11, gen_loss = 0.3945535304419922, disc_loss = 0.08466857358615733
Trained batch 330 in epoch 11, gen_loss = 0.3944706809214595, disc_loss = 0.08460767716422588
Trained batch 331 in epoch 11, gen_loss = 0.3943790818104543, disc_loss = 0.08442386318452612
Trained batch 332 in epoch 11, gen_loss = 0.3944663898991393, disc_loss = 0.08424962475453993
Trained batch 333 in epoch 11, gen_loss = 0.3942254103140203, disc_loss = 0.08413774910672919
Trained batch 334 in epoch 11, gen_loss = 0.3942130208460253, disc_loss = 0.08413815289429986
Trained batch 335 in epoch 11, gen_loss = 0.3940018170202772, disc_loss = 0.08444674126942464
Trained batch 336 in epoch 11, gen_loss = 0.39385867300125543, disc_loss = 0.08454490941741921
Trained batch 337 in epoch 11, gen_loss = 0.3941810955045491, disc_loss = 0.08488776221920973
Trained batch 338 in epoch 11, gen_loss = 0.3943272226415904, disc_loss = 0.0847346965006517
Trained batch 339 in epoch 11, gen_loss = 0.3944049428929301, disc_loss = 0.08464359723387614
Trained batch 340 in epoch 11, gen_loss = 0.39440903395326954, disc_loss = 0.08458103509510587
Trained batch 341 in epoch 11, gen_loss = 0.3944130122051602, disc_loss = 0.08446228618690015
Trained batch 342 in epoch 11, gen_loss = 0.3945074143545273, disc_loss = 0.08431211236793733
Trained batch 343 in epoch 11, gen_loss = 0.3944191972096992, disc_loss = 0.08435508278658786
Trained batch 344 in epoch 11, gen_loss = 0.3946490781462711, disc_loss = 0.08538669675075705
Trained batch 345 in epoch 11, gen_loss = 0.39478767103370216, disc_loss = 0.0856741136976254
Trained batch 346 in epoch 11, gen_loss = 0.3945119285188422, disc_loss = 0.08600263245087063
Trained batch 347 in epoch 11, gen_loss = 0.39446724107724496, disc_loss = 0.08581265677756833
Trained batch 348 in epoch 11, gen_loss = 0.39443866379110726, disc_loss = 0.0857867351439608
Trained batch 349 in epoch 11, gen_loss = 0.3943289136460849, disc_loss = 0.08560579978062638
Trained batch 350 in epoch 11, gen_loss = 0.3943573202927228, disc_loss = 0.08544630270339867
Trained batch 351 in epoch 11, gen_loss = 0.39431661016053776, disc_loss = 0.08524062664285091
Trained batch 352 in epoch 11, gen_loss = 0.3941647865025923, disc_loss = 0.085031526700116
Trained batch 353 in epoch 11, gen_loss = 0.39400376526817765, disc_loss = 0.0848360339924167
Trained batch 354 in epoch 11, gen_loss = 0.3940858870744705, disc_loss = 0.08465076283433698
Trained batch 355 in epoch 11, gen_loss = 0.39399382509709746, disc_loss = 0.08453801708960425
Trained batch 356 in epoch 11, gen_loss = 0.394103193358213, disc_loss = 0.08448427950399888
Trained batch 357 in epoch 11, gen_loss = 0.3940414592790204, disc_loss = 0.08467842868851841
Trained batch 358 in epoch 11, gen_loss = 0.3942890351944315, disc_loss = 0.08448061793082728
Trained batch 359 in epoch 11, gen_loss = 0.3943127806401915, disc_loss = 0.08438544242203029
Trained batch 360 in epoch 11, gen_loss = 0.3943946963779814, disc_loss = 0.08418220884122801
Trained batch 361 in epoch 11, gen_loss = 0.39453625370290396, disc_loss = 0.08412134571088406
Trained batch 362 in epoch 11, gen_loss = 0.394520617754663, disc_loss = 0.08397218722403665
Trained batch 363 in epoch 11, gen_loss = 0.39486009819985746, disc_loss = 0.08378190599294932
Trained batch 364 in epoch 11, gen_loss = 0.394979576582778, disc_loss = 0.08364140880102776
Trained batch 365 in epoch 11, gen_loss = 0.3946584847862603, disc_loss = 0.08350859137501343
Trained batch 366 in epoch 11, gen_loss = 0.3948529929085064, disc_loss = 0.0833982869117376
Trained batch 367 in epoch 11, gen_loss = 0.39484765303685615, disc_loss = 0.08326783949261247
Trained batch 368 in epoch 11, gen_loss = 0.3951679227878731, disc_loss = 0.08321222385169488
Trained batch 369 in epoch 11, gen_loss = 0.3949072533765355, disc_loss = 0.08330075492000057
Trained batch 370 in epoch 11, gen_loss = 0.3950797257156706, disc_loss = 0.0835162789681349
Trained batch 371 in epoch 11, gen_loss = 0.3948476725127748, disc_loss = 0.08332991708315388
Trained batch 372 in epoch 11, gen_loss = 0.3947109868075828, disc_loss = 0.08360128668099442
Trained batch 373 in epoch 11, gen_loss = 0.3949972534960604, disc_loss = 0.0834777760605781
Trained batch 374 in epoch 11, gen_loss = 0.3951278990507126, disc_loss = 0.08332096497838695
Trained batch 375 in epoch 11, gen_loss = 0.3951638040152636, disc_loss = 0.08311505294949846
Trained batch 376 in epoch 11, gen_loss = 0.3951265740378782, disc_loss = 0.08291126818788937
Trained batch 377 in epoch 11, gen_loss = 0.39495600622009347, disc_loss = 0.08272889889678155
Trained batch 378 in epoch 11, gen_loss = 0.3947270849527973, disc_loss = 0.08256051733126583
Trained batch 379 in epoch 11, gen_loss = 0.3947542240353007, disc_loss = 0.08244045008660147
Trained batch 380 in epoch 11, gen_loss = 0.39484723960477225, disc_loss = 0.08234906218593985
Trained batch 381 in epoch 11, gen_loss = 0.3947898685073977, disc_loss = 0.08255166328799818
Trained batch 382 in epoch 11, gen_loss = 0.39508607652884553, disc_loss = 0.0824761845356257
Trained batch 383 in epoch 11, gen_loss = 0.3952165972829486, disc_loss = 0.08229183141277947
Trained batch 384 in epoch 11, gen_loss = 0.39538152121104203, disc_loss = 0.08219209376770954
Trained batch 385 in epoch 11, gen_loss = 0.39533051682414166, disc_loss = 0.08260712542431188
Trained batch 386 in epoch 11, gen_loss = 0.39537332474569326, disc_loss = 0.08338322971276073
Trained batch 387 in epoch 11, gen_loss = 0.3952824314000066, disc_loss = 0.08329537700496845
Trained batch 388 in epoch 11, gen_loss = 0.39514009846053577, disc_loss = 0.083369187852679
Trained batch 389 in epoch 11, gen_loss = 0.3949033227868569, disc_loss = 0.08321665711700917
Trained batch 390 in epoch 11, gen_loss = 0.3949333680483996, disc_loss = 0.08308294215870787
Trained batch 391 in epoch 11, gen_loss = 0.39515480623409455, disc_loss = 0.08289414126549524
Trained batch 392 in epoch 11, gen_loss = 0.3952724034625459, disc_loss = 0.0827749059215643
Trained batch 393 in epoch 11, gen_loss = 0.39518141856199596, disc_loss = 0.0826174670920192
Trained batch 394 in epoch 11, gen_loss = 0.39495206976993175, disc_loss = 0.08258066537872523
Trained batch 395 in epoch 11, gen_loss = 0.3949480192604089, disc_loss = 0.08242751383504858
Trained batch 396 in epoch 11, gen_loss = 0.3948596453561591, disc_loss = 0.08226472671174208
Trained batch 397 in epoch 11, gen_loss = 0.3948966301041632, disc_loss = 0.08219461714680396
Trained batch 398 in epoch 11, gen_loss = 0.39496100311141863, disc_loss = 0.08214655705963385
Trained batch 399 in epoch 11, gen_loss = 0.3947795678302646, disc_loss = 0.08208018599776551
Trained batch 400 in epoch 11, gen_loss = 0.39467504037140017, disc_loss = 0.08205948073992929
Trained batch 401 in epoch 11, gen_loss = 0.39467990468835357, disc_loss = 0.08213977601647895
Trained batch 402 in epoch 11, gen_loss = 0.39486390577800223, disc_loss = 0.08229901559105508
Trained batch 403 in epoch 11, gen_loss = 0.39511863396752, disc_loss = 0.08216393470422982
Trained batch 404 in epoch 11, gen_loss = 0.39491608529179184, disc_loss = 0.08205347057247972
Trained batch 405 in epoch 11, gen_loss = 0.3948053293700876, disc_loss = 0.08197453583870541
Trained batch 406 in epoch 11, gen_loss = 0.3948870577668675, disc_loss = 0.08192425930337106
Trained batch 407 in epoch 11, gen_loss = 0.39498509360732986, disc_loss = 0.08181993218421862
Trained batch 408 in epoch 11, gen_loss = 0.3949768534135119, disc_loss = 0.0818951770840873
Trained batch 409 in epoch 11, gen_loss = 0.3951160337503363, disc_loss = 0.08225024459520128
Trained batch 410 in epoch 11, gen_loss = 0.39504006392619323, disc_loss = 0.08222369618324105
Trained batch 411 in epoch 11, gen_loss = 0.3947673942351225, disc_loss = 0.08214995511626662
Trained batch 412 in epoch 11, gen_loss = 0.3946972783411386, disc_loss = 0.08200795237047115
Trained batch 413 in epoch 11, gen_loss = 0.3947418332459846, disc_loss = 0.08188986836973092
Trained batch 414 in epoch 11, gen_loss = 0.3947754936404975, disc_loss = 0.08186364205531686
Trained batch 415 in epoch 11, gen_loss = 0.3950630809323719, disc_loss = 0.08169482578075705
Trained batch 416 in epoch 11, gen_loss = 0.39512811136617365, disc_loss = 0.08162827555277793
Trained batch 417 in epoch 11, gen_loss = 0.39522935860037234, disc_loss = 0.08213470367777148
Trained batch 418 in epoch 11, gen_loss = 0.39499485709644444, disc_loss = 0.082389254892036
Trained batch 419 in epoch 11, gen_loss = 0.3953323622899396, disc_loss = 0.08231833737254853
Trained batch 420 in epoch 11, gen_loss = 0.39531145515606125, disc_loss = 0.08226058223769246
Trained batch 421 in epoch 11, gen_loss = 0.3952516604444427, disc_loss = 0.08210288032765778
Trained batch 422 in epoch 11, gen_loss = 0.39516872791111046, disc_loss = 0.08204148133366806
Trained batch 423 in epoch 11, gen_loss = 0.3951193472757092, disc_loss = 0.08189124650462477
Trained batch 424 in epoch 11, gen_loss = 0.3951308934478199, disc_loss = 0.0818060505609302
Trained batch 425 in epoch 11, gen_loss = 0.39495794674460316, disc_loss = 0.08172100307988309
Trained batch 426 in epoch 11, gen_loss = 0.3949263801130813, disc_loss = 0.08162924008273827
Trained batch 427 in epoch 11, gen_loss = 0.39510887460870164, disc_loss = 0.08150209737593465
Trained batch 428 in epoch 11, gen_loss = 0.3950301941944447, disc_loss = 0.08144653366665879
Trained batch 429 in epoch 11, gen_loss = 0.39503687817689986, disc_loss = 0.08149059737577688
Trained batch 430 in epoch 11, gen_loss = 0.3953343353595092, disc_loss = 0.08151756803096724
Trained batch 431 in epoch 11, gen_loss = 0.39541240598730465, disc_loss = 0.0813596119362585
Trained batch 432 in epoch 11, gen_loss = 0.3954061349255934, disc_loss = 0.08133318119490945
Trained batch 433 in epoch 11, gen_loss = 0.3954789226848958, disc_loss = 0.08116514668993068
Trained batch 434 in epoch 11, gen_loss = 0.3955850614555951, disc_loss = 0.08103831929165399
Trained batch 435 in epoch 11, gen_loss = 0.3955250555017126, disc_loss = 0.08088174135714701
Trained batch 436 in epoch 11, gen_loss = 0.3956277091183979, disc_loss = 0.08074820482169941
Trained batch 437 in epoch 11, gen_loss = 0.3955589335871069, disc_loss = 0.08062890340195603
Trained batch 438 in epoch 11, gen_loss = 0.3956774620165314, disc_loss = 0.08076496620647661
Trained batch 439 in epoch 11, gen_loss = 0.39553474529900334, disc_loss = 0.08125723422377963
Trained batch 440 in epoch 11, gen_loss = 0.39575644013157235, disc_loss = 0.08153936711019602
Trained batch 441 in epoch 11, gen_loss = 0.39598877778554936, disc_loss = 0.08140288387547454
Trained batch 442 in epoch 11, gen_loss = 0.39598889440365354, disc_loss = 0.08124910734602278
Trained batch 443 in epoch 11, gen_loss = 0.39610765085698246, disc_loss = 0.08111951637148924
Trained batch 444 in epoch 11, gen_loss = 0.3960110472494297, disc_loss = 0.08096165256679393
Trained batch 445 in epoch 11, gen_loss = 0.3958531601747055, disc_loss = 0.08082114998460016
Trained batch 446 in epoch 11, gen_loss = 0.3958522801097874, disc_loss = 0.08066345392299246
Trained batch 447 in epoch 11, gen_loss = 0.39568635006435215, disc_loss = 0.08063383428088855
Trained batch 448 in epoch 11, gen_loss = 0.3958712657934308, disc_loss = 0.08062213952373092
Trained batch 449 in epoch 11, gen_loss = 0.3958703205651707, disc_loss = 0.08049503401542703
Trained batch 450 in epoch 11, gen_loss = 0.39582233712440584, disc_loss = 0.08053482048618225
Trained batch 451 in epoch 11, gen_loss = 0.3958712110411277, disc_loss = 0.08044628881173521
Trained batch 452 in epoch 11, gen_loss = 0.3959384810911372, disc_loss = 0.08085396935007891
Trained batch 453 in epoch 11, gen_loss = 0.3958612021042387, disc_loss = 0.08111113641156696
Trained batch 454 in epoch 11, gen_loss = 0.395959070455897, disc_loss = 0.08132498237908214
Trained batch 455 in epoch 11, gen_loss = 0.39587955755230625, disc_loss = 0.08120940421225928
Trained batch 456 in epoch 11, gen_loss = 0.39584005769154695, disc_loss = 0.08110604117903655
Trained batch 457 in epoch 11, gen_loss = 0.39578337118224804, disc_loss = 0.08098672121543617
Trained batch 458 in epoch 11, gen_loss = 0.39550772332028367, disc_loss = 0.08105612303737007
Testing Epoch 11
Training Epoch 12
Trained batch 0 in epoch 12, gen_loss = 0.4063017964363098, disc_loss = 0.041218407452106476
Trained batch 1 in epoch 12, gen_loss = 0.43262359499931335, disc_loss = 0.0403082687407732
Trained batch 2 in epoch 12, gen_loss = 0.39218761523564655, disc_loss = 0.07715034112334251
Trained batch 3 in epoch 12, gen_loss = 0.4171857386827469, disc_loss = 0.09765881020575762
Trained batch 4 in epoch 12, gen_loss = 0.4352425456047058, disc_loss = 0.08607315048575401
Trained batch 5 in epoch 12, gen_loss = 0.4290488411982854, disc_loss = 0.08357077650725842
Trained batch 6 in epoch 12, gen_loss = 0.43315047451428007, disc_loss = 0.07693397519843918
Trained batch 7 in epoch 12, gen_loss = 0.4300587326288223, disc_loss = 0.07014091545715928
Trained batch 8 in epoch 12, gen_loss = 0.4337927864657508, disc_loss = 0.06730525195598602
Trained batch 9 in epoch 12, gen_loss = 0.43239308297634127, disc_loss = 0.07503958493471145
Trained batch 10 in epoch 12, gen_loss = 0.4188276529312134, disc_loss = 0.09131863035938957
Trained batch 11 in epoch 12, gen_loss = 0.42081589500109357, disc_loss = 0.0854347104517122
Trained batch 12 in epoch 12, gen_loss = 0.4195826259943155, disc_loss = 0.0829178483153765
Trained batch 13 in epoch 12, gen_loss = 0.41840044941220966, disc_loss = 0.08111882356128522
Trained batch 14 in epoch 12, gen_loss = 0.41310847997665406, disc_loss = 0.08235026784241199
Trained batch 15 in epoch 12, gen_loss = 0.4128704871982336, disc_loss = 0.08074243308510631
Trained batch 16 in epoch 12, gen_loss = 0.40739355192464943, disc_loss = 0.07994158292079673
Trained batch 17 in epoch 12, gen_loss = 0.40477107134130264, disc_loss = 0.08486104332324532
Trained batch 18 in epoch 12, gen_loss = 0.40660871643769114, disc_loss = 0.08410732673579141
Trained batch 19 in epoch 12, gen_loss = 0.40690368264913557, disc_loss = 0.080857190862298
Trained batch 20 in epoch 12, gen_loss = 0.40684209551130024, disc_loss = 0.07813398912549019
Trained batch 21 in epoch 12, gen_loss = 0.40503340417688544, disc_loss = 0.08319454724815759
Trained batch 22 in epoch 12, gen_loss = 0.4083474459855453, disc_loss = 0.08662763707663702
Trained batch 23 in epoch 12, gen_loss = 0.4091195948421955, disc_loss = 0.0834433624598508
Trained batch 24 in epoch 12, gen_loss = 0.4101122558116913, disc_loss = 0.08070885114371777
Trained batch 25 in epoch 12, gen_loss = 0.4082810179545329, disc_loss = 0.07836477329524663
Trained batch 26 in epoch 12, gen_loss = 0.4064033539206893, disc_loss = 0.07694595900398714
Trained batch 27 in epoch 12, gen_loss = 0.4069079714162009, disc_loss = 0.0771071297515716
Trained batch 28 in epoch 12, gen_loss = 0.4044933504071729, disc_loss = 0.07706638875192609
Trained batch 29 in epoch 12, gen_loss = 0.404349085688591, disc_loss = 0.07616398533185323
Trained batch 30 in epoch 12, gen_loss = 0.4056134233551641, disc_loss = 0.07427845618897869
Trained batch 31 in epoch 12, gen_loss = 0.4041099129244685, disc_loss = 0.07378027972299606
Trained batch 32 in epoch 12, gen_loss = 0.4006765259034706, disc_loss = 0.08279074062452171
Trained batch 33 in epoch 12, gen_loss = 0.4029284338740742, disc_loss = 0.08482763532768278
Trained batch 34 in epoch 12, gen_loss = 0.40133079630987983, disc_loss = 0.08489758638398988
Trained batch 35 in epoch 12, gen_loss = 0.4010818170176612, disc_loss = 0.08472543240835269
Trained batch 36 in epoch 12, gen_loss = 0.40330098609666565, disc_loss = 0.0838558139229143
Trained batch 37 in epoch 12, gen_loss = 0.40153330486071737, disc_loss = 0.08200396715026152
Trained batch 38 in epoch 12, gen_loss = 0.4030523193188203, disc_loss = 0.08049676075386696
Trained batch 39 in epoch 12, gen_loss = 0.4037275336682796, disc_loss = 0.07926494502462447
Trained batch 40 in epoch 12, gen_loss = 0.4008596190592138, disc_loss = 0.07826700738472182
Trained batch 41 in epoch 12, gen_loss = 0.4018959395942234, disc_loss = 0.07744829911029055
Trained batch 42 in epoch 12, gen_loss = 0.40300967596298043, disc_loss = 0.07683385219858137
Trained batch 43 in epoch 12, gen_loss = 0.40365601669658313, disc_loss = 0.07995248691771518
Trained batch 44 in epoch 12, gen_loss = 0.4011970341205597, disc_loss = 0.083361558491985
Trained batch 45 in epoch 12, gen_loss = 0.4003648984691371, disc_loss = 0.08300761364238418
Trained batch 46 in epoch 12, gen_loss = 0.40024859791106365, disc_loss = 0.08490408548807844
Trained batch 47 in epoch 12, gen_loss = 0.4000739312420289, disc_loss = 0.08438002360829462
Trained batch 48 in epoch 12, gen_loss = 0.4010047103677477, disc_loss = 0.08308657349980607
Trained batch 49 in epoch 12, gen_loss = 0.3998504775762558, disc_loss = 0.08177707202732563
Trained batch 50 in epoch 12, gen_loss = 0.3996357415236679, disc_loss = 0.08059554799076389
Trained batch 51 in epoch 12, gen_loss = 0.4001441150903702, disc_loss = 0.0796725179355305
Trained batch 52 in epoch 12, gen_loss = 0.39943694337359015, disc_loss = 0.07907717741744698
Trained batch 53 in epoch 12, gen_loss = 0.399421571581452, disc_loss = 0.07868993175388486
Trained batch 54 in epoch 12, gen_loss = 0.3981813755902377, disc_loss = 0.07824026647616517
Trained batch 55 in epoch 12, gen_loss = 0.3981268640075411, disc_loss = 0.07834332266689412
Trained batch 56 in epoch 12, gen_loss = 0.3991473332831734, disc_loss = 0.07970705853873178
Trained batch 57 in epoch 12, gen_loss = 0.40036063358701507, disc_loss = 0.07847285485858548
Trained batch 58 in epoch 12, gen_loss = 0.39901984748193775, disc_loss = 0.07908203424412315
Trained batch 59 in epoch 12, gen_loss = 0.3999626815319061, disc_loss = 0.07819648142904043
Trained batch 60 in epoch 12, gen_loss = 0.40006124484734457, disc_loss = 0.07749311705348921
Trained batch 61 in epoch 12, gen_loss = 0.39887569940859274, disc_loss = 0.0781015151090199
Trained batch 62 in epoch 12, gen_loss = 0.40031261860378203, disc_loss = 0.07834531656569904
Trained batch 63 in epoch 12, gen_loss = 0.39930214872583747, disc_loss = 0.07795263279695064
Trained batch 64 in epoch 12, gen_loss = 0.39859335376666144, disc_loss = 0.07769290386484219
Trained batch 65 in epoch 12, gen_loss = 0.39766791101657983, disc_loss = 0.07751844682250962
Trained batch 66 in epoch 12, gen_loss = 0.398147753370342, disc_loss = 0.07671247759083313
Trained batch 67 in epoch 12, gen_loss = 0.399101416416028, disc_loss = 0.07754938153769164
Trained batch 68 in epoch 12, gen_loss = 0.39976689089899475, disc_loss = 0.07938155901712785
Trained batch 69 in epoch 12, gen_loss = 0.400273859500885, disc_loss = 0.07863238235669477
Trained batch 70 in epoch 12, gen_loss = 0.40035950927667213, disc_loss = 0.07785490758612122
Trained batch 71 in epoch 12, gen_loss = 0.40037858361999196, disc_loss = 0.07717210941741036
Trained batch 72 in epoch 12, gen_loss = 0.3992851245893191, disc_loss = 0.07705969687500229
Trained batch 73 in epoch 12, gen_loss = 0.4002066363353987, disc_loss = 0.07843875389143422
Trained batch 74 in epoch 12, gen_loss = 0.4002245000998179, disc_loss = 0.07783656693994999
Trained batch 75 in epoch 12, gen_loss = 0.3996667940365641, disc_loss = 0.07721898148424532
Trained batch 76 in epoch 12, gen_loss = 0.39953900118926905, disc_loss = 0.07639355229383166
Trained batch 77 in epoch 12, gen_loss = 0.3997224275118265, disc_loss = 0.07618983861249991
Trained batch 78 in epoch 12, gen_loss = 0.39890585405917106, disc_loss = 0.07916922440540188
Trained batch 79 in epoch 12, gen_loss = 0.3992169089615345, disc_loss = 0.07878657772671431
Trained batch 80 in epoch 12, gen_loss = 0.40027929382559696, disc_loss = 0.07847850979018359
Trained batch 81 in epoch 12, gen_loss = 0.39988538005003116, disc_loss = 0.0783162378456171
Trained batch 82 in epoch 12, gen_loss = 0.3993653967437974, disc_loss = 0.07883094428443765
Trained batch 83 in epoch 12, gen_loss = 0.39864321585212437, disc_loss = 0.0804479728630256
Trained batch 84 in epoch 12, gen_loss = 0.39888999006327464, disc_loss = 0.08069450327140444
Trained batch 85 in epoch 12, gen_loss = 0.3992573040169339, disc_loss = 0.08166223381061194
Trained batch 86 in epoch 12, gen_loss = 0.39950484688254606, disc_loss = 0.0809007535164041
Trained batch 87 in epoch 12, gen_loss = 0.39899692515080626, disc_loss = 0.08166178737089715
Trained batch 88 in epoch 12, gen_loss = 0.3996060299739409, disc_loss = 0.082914720739374
Trained batch 89 in epoch 12, gen_loss = 0.3998045355081558, disc_loss = 0.08220761511474847
Trained batch 90 in epoch 12, gen_loss = 0.3987169717694377, disc_loss = 0.0819927662979443
Trained batch 91 in epoch 12, gen_loss = 0.3987718431845955, disc_loss = 0.08127013424856831
Trained batch 92 in epoch 12, gen_loss = 0.39953423860252546, disc_loss = 0.0804962720221249
Trained batch 93 in epoch 12, gen_loss = 0.4000054803934503, disc_loss = 0.07989967771944531
Trained batch 94 in epoch 12, gen_loss = 0.3998293368439925, disc_loss = 0.07922182799758096
Trained batch 95 in epoch 12, gen_loss = 0.40019253951807815, disc_loss = 0.07867017109917167
Trained batch 96 in epoch 12, gen_loss = 0.3996780136811365, disc_loss = 0.07817988044860744
Trained batch 97 in epoch 12, gen_loss = 0.39912137875751574, disc_loss = 0.07881508973826255
Trained batch 98 in epoch 12, gen_loss = 0.3993262157897757, disc_loss = 0.07976482681591403
Trained batch 99 in epoch 12, gen_loss = 0.3999964141845703, disc_loss = 0.07952674300409854
Trained batch 100 in epoch 12, gen_loss = 0.3990419586696247, disc_loss = 0.07913023846611233
Trained batch 101 in epoch 12, gen_loss = 0.3992170808362026, disc_loss = 0.07852854934867982
Trained batch 102 in epoch 12, gen_loss = 0.3998307197996714, disc_loss = 0.07807902305486422
Trained batch 103 in epoch 12, gen_loss = 0.3999251542756191, disc_loss = 0.0775048681624377
Trained batch 104 in epoch 12, gen_loss = 0.39961286385854083, disc_loss = 0.07741693511073078
Trained batch 105 in epoch 12, gen_loss = 0.3999760921271342, disc_loss = 0.07716895679433672
Trained batch 106 in epoch 12, gen_loss = 0.3996188420558644, disc_loss = 0.07716566572296564
Trained batch 107 in epoch 12, gen_loss = 0.399818446625162, disc_loss = 0.07694375539991867
Trained batch 108 in epoch 12, gen_loss = 0.3995576727827755, disc_loss = 0.07808618709752592
Trained batch 109 in epoch 12, gen_loss = 0.39916356341405346, disc_loss = 0.07934576554901221
Trained batch 110 in epoch 12, gen_loss = 0.39922355692665856, disc_loss = 0.07898507982928742
Trained batch 111 in epoch 12, gen_loss = 0.3993609566241503, disc_loss = 0.07867012972045424
Trained batch 112 in epoch 12, gen_loss = 0.3988168200032901, disc_loss = 0.07840960216502436
Trained batch 113 in epoch 12, gen_loss = 0.39892391912769853, disc_loss = 0.07791755280637166
Trained batch 114 in epoch 12, gen_loss = 0.3995896769606549, disc_loss = 0.07767366421125506
Trained batch 115 in epoch 12, gen_loss = 0.399885347434159, disc_loss = 0.07723257225809683
Trained batch 116 in epoch 12, gen_loss = 0.3995313588370625, disc_loss = 0.076752497926036
Trained batch 117 in epoch 12, gen_loss = 0.3996123393713418, disc_loss = 0.07634831346981859
Trained batch 118 in epoch 12, gen_loss = 0.3997636500025998, disc_loss = 0.07600520273373157
Trained batch 119 in epoch 12, gen_loss = 0.39934888333082197, disc_loss = 0.07684986377911021
Trained batch 120 in epoch 12, gen_loss = 0.3996531608676122, disc_loss = 0.07664591579674936
Trained batch 121 in epoch 12, gen_loss = 0.40022928499784627, disc_loss = 0.07649143395151516
Trained batch 122 in epoch 12, gen_loss = 0.39938847320835763, disc_loss = 0.0765415196935457
Trained batch 123 in epoch 12, gen_loss = 0.39941608160734177, disc_loss = 0.0759893195898903
Trained batch 124 in epoch 12, gen_loss = 0.399731062412262, disc_loss = 0.07566837192326784
Trained batch 125 in epoch 12, gen_loss = 0.39993405696891604, disc_loss = 0.07519575637868708
Trained batch 126 in epoch 12, gen_loss = 0.39977619333530034, disc_loss = 0.07500956363712005
Trained batch 127 in epoch 12, gen_loss = 0.39965995750389993, disc_loss = 0.07477344643120887
Trained batch 128 in epoch 12, gen_loss = 0.40010147593742196, disc_loss = 0.07482127378182124
Trained batch 129 in epoch 12, gen_loss = 0.39995971826406623, disc_loss = 0.07480976009168304
Trained batch 130 in epoch 12, gen_loss = 0.39932028960635646, disc_loss = 0.07483677873885586
Trained batch 131 in epoch 12, gen_loss = 0.3995590374776811, disc_loss = 0.07437450708962526
Trained batch 132 in epoch 12, gen_loss = 0.39973826336681395, disc_loss = 0.07414462685557012
Trained batch 133 in epoch 12, gen_loss = 0.3996829810872007, disc_loss = 0.07413905997301883
Trained batch 134 in epoch 12, gen_loss = 0.39938593639267816, disc_loss = 0.07367018707510498
Trained batch 135 in epoch 12, gen_loss = 0.3993215736220865, disc_loss = 0.07326129639712985
Trained batch 136 in epoch 12, gen_loss = 0.39973116791161306, disc_loss = 0.07304570181499215
Trained batch 137 in epoch 12, gen_loss = 0.3994701612686765, disc_loss = 0.07301163149025777
Trained batch 138 in epoch 12, gen_loss = 0.4001128021761668, disc_loss = 0.07277090753019928
Trained batch 139 in epoch 12, gen_loss = 0.4005096869809287, disc_loss = 0.07244024866792773
Trained batch 140 in epoch 12, gen_loss = 0.4008262330758656, disc_loss = 0.07197197532637957
Trained batch 141 in epoch 12, gen_loss = 0.4000954422312723, disc_loss = 0.07233681247084284
Trained batch 142 in epoch 12, gen_loss = 0.4010944020498049, disc_loss = 0.07215653003642818
Trained batch 143 in epoch 12, gen_loss = 0.40150798112154007, disc_loss = 0.0721365498805729
Trained batch 144 in epoch 12, gen_loss = 0.40139024524853145, disc_loss = 0.07171241057201706
Trained batch 145 in epoch 12, gen_loss = 0.4014605647080565, disc_loss = 0.07144566147575436
Trained batch 146 in epoch 12, gen_loss = 0.40129926902096286, disc_loss = 0.07101381639158036
Trained batch 147 in epoch 12, gen_loss = 0.40148724333660024, disc_loss = 0.07077449115270094
Trained batch 148 in epoch 12, gen_loss = 0.4018081894656956, disc_loss = 0.07041728884706762
Trained batch 149 in epoch 12, gen_loss = 0.40187878052393594, disc_loss = 0.07009192949160933
Trained batch 150 in epoch 12, gen_loss = 0.40154596353998245, disc_loss = 0.069823042945998
Trained batch 151 in epoch 12, gen_loss = 0.40138658273376915, disc_loss = 0.06961040826832973
Trained batch 152 in epoch 12, gen_loss = 0.4019956943256403, disc_loss = 0.06945230853835158
Trained batch 153 in epoch 12, gen_loss = 0.40239875928148044, disc_loss = 0.06976319644479202
Trained batch 154 in epoch 12, gen_loss = 0.4023597292361721, disc_loss = 0.07014406619653586
Trained batch 155 in epoch 12, gen_loss = 0.4026870106657346, disc_loss = 0.06976845439595099
Trained batch 156 in epoch 12, gen_loss = 0.40319779629160646, disc_loss = 0.06997293323444523
Trained batch 157 in epoch 12, gen_loss = 0.4025251508890828, disc_loss = 0.07013593061791756
Trained batch 158 in epoch 12, gen_loss = 0.4026217837378664, disc_loss = 0.06975051755401886
Trained batch 159 in epoch 12, gen_loss = 0.40310228932648895, disc_loss = 0.06939075244008563
Trained batch 160 in epoch 12, gen_loss = 0.40325013339889715, disc_loss = 0.06924102709322057
Trained batch 161 in epoch 12, gen_loss = 0.40287681199886183, disc_loss = 0.06978275102022806
Trained batch 162 in epoch 12, gen_loss = 0.40272318768355014, disc_loss = 0.07092913637291982
Trained batch 163 in epoch 12, gen_loss = 0.402859252945679, disc_loss = 0.07067049488357109
Trained batch 164 in epoch 12, gen_loss = 0.40211891134579975, disc_loss = 0.07086390715769746
Trained batch 165 in epoch 12, gen_loss = 0.40252435297132977, disc_loss = 0.07072456596778279
Trained batch 166 in epoch 12, gen_loss = 0.40274611383141157, disc_loss = 0.07053889087150375
Trained batch 167 in epoch 12, gen_loss = 0.4024802643273558, disc_loss = 0.07141675634331823
Trained batch 168 in epoch 12, gen_loss = 0.40222719646769867, disc_loss = 0.0720403259068992
Trained batch 169 in epoch 12, gen_loss = 0.4019174682743409, disc_loss = 0.07268021863282603
Trained batch 170 in epoch 12, gen_loss = 0.40274199564554536, disc_loss = 0.07334564114806422
Trained batch 171 in epoch 12, gen_loss = 0.40235706644002783, disc_loss = 0.0734607383966186
Trained batch 172 in epoch 12, gen_loss = 0.4023629757710275, disc_loss = 0.07331023467004816
Trained batch 173 in epoch 12, gen_loss = 0.40170576980059175, disc_loss = 0.0731103259952332
Trained batch 174 in epoch 12, gen_loss = 0.40170806373868667, disc_loss = 0.07395490602191006
Trained batch 175 in epoch 12, gen_loss = 0.40080111736262386, disc_loss = 0.07491665221856568
Trained batch 176 in epoch 12, gen_loss = 0.40115581183447, disc_loss = 0.07491479627261896
Trained batch 177 in epoch 12, gen_loss = 0.40091427231437704, disc_loss = 0.07471049788899803
Trained batch 178 in epoch 12, gen_loss = 0.4007448764653179, disc_loss = 0.07445987454984941
Trained batch 179 in epoch 12, gen_loss = 0.40072818158401385, disc_loss = 0.07431668522767723
Trained batch 180 in epoch 12, gen_loss = 0.4004055902938158, disc_loss = 0.0746524061400505
Trained batch 181 in epoch 12, gen_loss = 0.39971952115768916, disc_loss = 0.07536313436659318
Trained batch 182 in epoch 12, gen_loss = 0.3999546076593503, disc_loss = 0.0763718623393139
Trained batch 183 in epoch 12, gen_loss = 0.39982543683246424, disc_loss = 0.07613774240725553
Trained batch 184 in epoch 12, gen_loss = 0.3993981413744591, disc_loss = 0.07642003875225782
Trained batch 185 in epoch 12, gen_loss = 0.3994520751218642, disc_loss = 0.07611189327473121
Trained batch 186 in epoch 12, gen_loss = 0.3991753839075884, disc_loss = 0.07703074113152085
Trained batch 187 in epoch 12, gen_loss = 0.3989514823448151, disc_loss = 0.07729039223805229
Trained batch 188 in epoch 12, gen_loss = 0.3988904277325938, disc_loss = 0.07692673869391597
Trained batch 189 in epoch 12, gen_loss = 0.3986499940878467, disc_loss = 0.07690174458058256
Trained batch 190 in epoch 12, gen_loss = 0.39848053775220643, disc_loss = 0.07681867464674705
Trained batch 191 in epoch 12, gen_loss = 0.3986021107217918, disc_loss = 0.07659918137748416
Trained batch 192 in epoch 12, gen_loss = 0.39877221428359727, disc_loss = 0.07634595864563408
Trained batch 193 in epoch 12, gen_loss = 0.3984275333506545, disc_loss = 0.07607517869586182
Trained batch 194 in epoch 12, gen_loss = 0.3983455036695187, disc_loss = 0.07595144231349994
Trained batch 195 in epoch 12, gen_loss = 0.3980455505756699, disc_loss = 0.07740783596373334
Trained batch 196 in epoch 12, gen_loss = 0.3984695331850633, disc_loss = 0.0777005930312999
Trained batch 197 in epoch 12, gen_loss = 0.39906932195328704, disc_loss = 0.0776044905486733
Trained batch 198 in epoch 12, gen_loss = 0.399374012896164, disc_loss = 0.07734107988039453
Trained batch 199 in epoch 12, gen_loss = 0.3992785958200693, disc_loss = 0.07712008154019713
Trained batch 200 in epoch 12, gen_loss = 0.3990733391461681, disc_loss = 0.07688929049752245
Trained batch 201 in epoch 12, gen_loss = 0.3991891085953996, disc_loss = 0.07659468702086718
Trained batch 202 in epoch 12, gen_loss = 0.39903055131435394, disc_loss = 0.07632632723325873
Trained batch 203 in epoch 12, gen_loss = 0.39908089729792934, disc_loss = 0.0762007935794399
Trained batch 204 in epoch 12, gen_loss = 0.3988067972223933, disc_loss = 0.07662454657256604
Trained batch 205 in epoch 12, gen_loss = 0.39865638004633985, disc_loss = 0.07818613587471757
Trained batch 206 in epoch 12, gen_loss = 0.39848286741309696, disc_loss = 0.0782488924563651
Trained batch 207 in epoch 12, gen_loss = 0.39854070666031194, disc_loss = 0.07824615090906334
Trained batch 208 in epoch 12, gen_loss = 0.39830956369210657, disc_loss = 0.07838142077710354
Trained batch 209 in epoch 12, gen_loss = 0.3983432026846068, disc_loss = 0.07860087911110548
Trained batch 210 in epoch 12, gen_loss = 0.3985482277039668, disc_loss = 0.07872697127479795
Trained batch 211 in epoch 12, gen_loss = 0.3985957387342768, disc_loss = 0.07839358956465181
Trained batch 212 in epoch 12, gen_loss = 0.398032020165327, disc_loss = 0.07835752541470416
Trained batch 213 in epoch 12, gen_loss = 0.3980628449086831, disc_loss = 0.07803957531594227
Trained batch 214 in epoch 12, gen_loss = 0.3981563539699067, disc_loss = 0.07781021239799123
Trained batch 215 in epoch 12, gen_loss = 0.3978618261300855, disc_loss = 0.07786142255214078
Trained batch 216 in epoch 12, gen_loss = 0.3982735374418821, disc_loss = 0.07779458798639785
Trained batch 217 in epoch 12, gen_loss = 0.39804347057681566, disc_loss = 0.07778125131554013
Trained batch 218 in epoch 12, gen_loss = 0.39810740818443907, disc_loss = 0.07765403070134115
Trained batch 219 in epoch 12, gen_loss = 0.3979669342664155, disc_loss = 0.07735333971848542
Trained batch 220 in epoch 12, gen_loss = 0.39758613092057843, disc_loss = 0.0772990073705286
Trained batch 221 in epoch 12, gen_loss = 0.39770696580678494, disc_loss = 0.0773802941396564
Trained batch 222 in epoch 12, gen_loss = 0.398081621982057, disc_loss = 0.07711816406203226
Trained batch 223 in epoch 12, gen_loss = 0.3979637329466641, disc_loss = 0.07685915690048464
Trained batch 224 in epoch 12, gen_loss = 0.3980050606860055, disc_loss = 0.07656696329928107
Trained batch 225 in epoch 12, gen_loss = 0.397916389579794, disc_loss = 0.07636742861282113
Trained batch 226 in epoch 12, gen_loss = 0.397787409272488, disc_loss = 0.07624760795680043
Trained batch 227 in epoch 12, gen_loss = 0.39754567929265794, disc_loss = 0.07653645615975715
Trained batch 228 in epoch 12, gen_loss = 0.3977393871701961, disc_loss = 0.07782294637397517
Trained batch 229 in epoch 12, gen_loss = 0.3979115933827732, disc_loss = 0.07771051445489992
Trained batch 230 in epoch 12, gen_loss = 0.39779487013558806, disc_loss = 0.07762747321245603
Trained batch 231 in epoch 12, gen_loss = 0.39767669918465204, disc_loss = 0.07744573232123693
Trained batch 232 in epoch 12, gen_loss = 0.3978888018320558, disc_loss = 0.07717765939657781
Trained batch 233 in epoch 12, gen_loss = 0.39782426837417817, disc_loss = 0.07690615935298876
Trained batch 234 in epoch 12, gen_loss = 0.39783210494416826, disc_loss = 0.07661025327967202
Trained batch 235 in epoch 12, gen_loss = 0.3979256029982688, disc_loss = 0.07632499351166189
Trained batch 236 in epoch 12, gen_loss = 0.3980019178697329, disc_loss = 0.07611158422198351
Trained batch 237 in epoch 12, gen_loss = 0.3980579309228088, disc_loss = 0.07584652174733766
Trained batch 238 in epoch 12, gen_loss = 0.39806504784518204, disc_loss = 0.07561248378773613
Trained batch 239 in epoch 12, gen_loss = 0.39801104956616956, disc_loss = 0.07548880004324018
Trained batch 240 in epoch 12, gen_loss = 0.3977789574020631, disc_loss = 0.07549830880093376
Trained batch 241 in epoch 12, gen_loss = 0.3974701403216882, disc_loss = 0.07532403744326151
Trained batch 242 in epoch 12, gen_loss = 0.3973257932275411, disc_loss = 0.07542924475645332
Trained batch 243 in epoch 12, gen_loss = 0.3970509438363255, disc_loss = 0.07529522124372545
Trained batch 244 in epoch 12, gen_loss = 0.3971236483783138, disc_loss = 0.0750471696637723
Trained batch 245 in epoch 12, gen_loss = 0.39737885481700663, disc_loss = 0.0748712304691837
Trained batch 246 in epoch 12, gen_loss = 0.3969293117885165, disc_loss = 0.0751226604633365
Trained batch 247 in epoch 12, gen_loss = 0.3971878434982031, disc_loss = 0.07520313007426599
Trained batch 248 in epoch 12, gen_loss = 0.39731035264859715, disc_loss = 0.0749286109334733
Trained batch 249 in epoch 12, gen_loss = 0.3970588741898537, disc_loss = 0.07483770295977593
Trained batch 250 in epoch 12, gen_loss = 0.3966973616901147, disc_loss = 0.07475194360214875
Trained batch 251 in epoch 12, gen_loss = 0.39685603852073353, disc_loss = 0.074632371480148
Trained batch 252 in epoch 12, gen_loss = 0.3972311722549054, disc_loss = 0.07438006679796183
Trained batch 253 in epoch 12, gen_loss = 0.3971104907590573, disc_loss = 0.07444953669859904
Trained batch 254 in epoch 12, gen_loss = 0.3967147507503921, disc_loss = 0.07477568216329696
Trained batch 255 in epoch 12, gen_loss = 0.39674748823745176, disc_loss = 0.07469982722977875
Trained batch 256 in epoch 12, gen_loss = 0.3968979270425752, disc_loss = 0.07445307599982166
Trained batch 257 in epoch 12, gen_loss = 0.39672219585771706, disc_loss = 0.0741872146054236
Trained batch 258 in epoch 12, gen_loss = 0.39694289817082834, disc_loss = 0.07402812021795271
Trained batch 259 in epoch 12, gen_loss = 0.397341916939387, disc_loss = 0.0738002939364658
Trained batch 260 in epoch 12, gen_loss = 0.3972973401633259, disc_loss = 0.07359932900417125
Trained batch 261 in epoch 12, gen_loss = 0.39714355704211096, disc_loss = 0.07383734801826813
Trained batch 262 in epoch 12, gen_loss = 0.3971642877325812, disc_loss = 0.07388046747179766
Trained batch 263 in epoch 12, gen_loss = 0.3973429240850788, disc_loss = 0.07373015344792018
Trained batch 264 in epoch 12, gen_loss = 0.39724536375054775, disc_loss = 0.07363657277288302
Trained batch 265 in epoch 12, gen_loss = 0.39747846255401026, disc_loss = 0.07347360359070669
Trained batch 266 in epoch 12, gen_loss = 0.3977278580937939, disc_loss = 0.07325575786053241
Trained batch 267 in epoch 12, gen_loss = 0.3976566382864518, disc_loss = 0.07315402635748484
Trained batch 268 in epoch 12, gen_loss = 0.3980689543441326, disc_loss = 0.07343217771375711
Trained batch 269 in epoch 12, gen_loss = 0.39812778758781925, disc_loss = 0.07372794164413655
Trained batch 270 in epoch 12, gen_loss = 0.398438277224773, disc_loss = 0.07374288996069854
Trained batch 271 in epoch 12, gen_loss = 0.39868741816676717, disc_loss = 0.07351644919596284
Trained batch 272 in epoch 12, gen_loss = 0.39854729879688433, disc_loss = 0.07346831031839599
Trained batch 273 in epoch 12, gen_loss = 0.398583294211948, disc_loss = 0.0733224462316691
Trained batch 274 in epoch 12, gen_loss = 0.39825870779427613, disc_loss = 0.07321797518906269
Trained batch 275 in epoch 12, gen_loss = 0.39819151200894, disc_loss = 0.07323657461118115
Trained batch 276 in epoch 12, gen_loss = 0.3978396424425208, disc_loss = 0.0732622753042015
Trained batch 277 in epoch 12, gen_loss = 0.39797003433215533, disc_loss = 0.07304477690310358
Trained batch 278 in epoch 12, gen_loss = 0.39812099597146433, disc_loss = 0.07297681552428072
Trained batch 279 in epoch 12, gen_loss = 0.3977164590465171, disc_loss = 0.07283126538885491
Trained batch 280 in epoch 12, gen_loss = 0.397890930657285, disc_loss = 0.07264117999963489
Trained batch 281 in epoch 12, gen_loss = 0.39776891855694724, disc_loss = 0.0725403736140711
Trained batch 282 in epoch 12, gen_loss = 0.3977312894781571, disc_loss = 0.07290028709615498
Trained batch 283 in epoch 12, gen_loss = 0.3974474107610508, disc_loss = 0.07292994468564719
Trained batch 284 in epoch 12, gen_loss = 0.3974090096720478, disc_loss = 0.07278705641888736
Trained batch 285 in epoch 12, gen_loss = 0.39762150642129923, disc_loss = 0.07280416604313818
Trained batch 286 in epoch 12, gen_loss = 0.39740555123377347, disc_loss = 0.07263226709766671
Trained batch 287 in epoch 12, gen_loss = 0.3975797133623726, disc_loss = 0.07246099950538741
Trained batch 288 in epoch 12, gen_loss = 0.3977496870970644, disc_loss = 0.0723066797421981
Trained batch 289 in epoch 12, gen_loss = 0.3980526042909458, disc_loss = 0.0723206381666763
Trained batch 290 in epoch 12, gen_loss = 0.3981998147526148, disc_loss = 0.07221127978023589
Trained batch 291 in epoch 12, gen_loss = 0.39816334971213996, disc_loss = 0.07219660762467817
Trained batch 292 in epoch 12, gen_loss = 0.39804172307354596, disc_loss = 0.07251042229959379
Trained batch 293 in epoch 12, gen_loss = 0.3981710321136883, disc_loss = 0.07301843207532248
Trained batch 294 in epoch 12, gen_loss = 0.3982881931430202, disc_loss = 0.07280067329815888
Trained batch 295 in epoch 12, gen_loss = 0.3984008777282528, disc_loss = 0.07260873405942442
Trained batch 296 in epoch 12, gen_loss = 0.39850279623611207, disc_loss = 0.07257484005582253
Trained batch 297 in epoch 12, gen_loss = 0.39825531535300635, disc_loss = 0.07241454026068017
Trained batch 298 in epoch 12, gen_loss = 0.39837525306537397, disc_loss = 0.07233048840285743
Trained batch 299 in epoch 12, gen_loss = 0.39811678891380625, disc_loss = 0.072964021358639
Trained batch 300 in epoch 12, gen_loss = 0.39799235038385045, disc_loss = 0.0734874288245194
Trained batch 301 in epoch 12, gen_loss = 0.39825134882271684, disc_loss = 0.0741937600557279
Trained batch 302 in epoch 12, gen_loss = 0.3983306234130765, disc_loss = 0.07406012164951355
Trained batch 303 in epoch 12, gen_loss = 0.39819263671769906, disc_loss = 0.073997182042436
Trained batch 304 in epoch 12, gen_loss = 0.3981127959294397, disc_loss = 0.07399399845448673
Trained batch 305 in epoch 12, gen_loss = 0.3978585009189213, disc_loss = 0.07388369133391606
Trained batch 306 in epoch 12, gen_loss = 0.39787162558846056, disc_loss = 0.07379882142603009
Trained batch 307 in epoch 12, gen_loss = 0.3977312579654254, disc_loss = 0.07370001384262721
Trained batch 308 in epoch 12, gen_loss = 0.39781992552156975, disc_loss = 0.0735305709324319
Trained batch 309 in epoch 12, gen_loss = 0.39788351409858275, disc_loss = 0.0735987106458314
Trained batch 310 in epoch 12, gen_loss = 0.39733261037677814, disc_loss = 0.07421750997543526
Trained batch 311 in epoch 12, gen_loss = 0.3972648150550249, disc_loss = 0.07467763038137211
Trained batch 312 in epoch 12, gen_loss = 0.39724803032776035, disc_loss = 0.07464745534232821
Trained batch 313 in epoch 12, gen_loss = 0.397188272778016, disc_loss = 0.07448895811844783
Trained batch 314 in epoch 12, gen_loss = 0.3971625855517766, disc_loss = 0.07443781295229518
Trained batch 315 in epoch 12, gen_loss = 0.3968845450708383, disc_loss = 0.07428529231420046
Trained batch 316 in epoch 12, gen_loss = 0.39686935110611116, disc_loss = 0.07440442274609575
Trained batch 317 in epoch 12, gen_loss = 0.3971659121742039, disc_loss = 0.07423612515811089
Trained batch 318 in epoch 12, gen_loss = 0.39723732614405105, disc_loss = 0.07411265942533748
Trained batch 319 in epoch 12, gen_loss = 0.3971872751135379, disc_loss = 0.07390446337813046
Trained batch 320 in epoch 12, gen_loss = 0.3972737590936114, disc_loss = 0.07376476663608696
Trained batch 321 in epoch 12, gen_loss = 0.39729630674079336, disc_loss = 0.0735806178313142
Trained batch 322 in epoch 12, gen_loss = 0.39726177499205706, disc_loss = 0.07340097256673749
Trained batch 323 in epoch 12, gen_loss = 0.3971212056959853, disc_loss = 0.07326077226043483
Trained batch 324 in epoch 12, gen_loss = 0.39685402443775764, disc_loss = 0.073329195861633
Trained batch 325 in epoch 12, gen_loss = 0.39655666679509577, disc_loss = 0.07330113471102861
Trained batch 326 in epoch 12, gen_loss = 0.3966359587710932, disc_loss = 0.07315161371381458
Trained batch 327 in epoch 12, gen_loss = 0.39642244318454734, disc_loss = 0.07321248501652806
Trained batch 328 in epoch 12, gen_loss = 0.3967929704845133, disc_loss = 0.07441916308255363
Trained batch 329 in epoch 12, gen_loss = 0.3966426264607545, disc_loss = 0.07470794458393798
Trained batch 330 in epoch 12, gen_loss = 0.3965737803014744, disc_loss = 0.07466773922327243
Trained batch 331 in epoch 12, gen_loss = 0.39645007912473507, disc_loss = 0.07470405065308673
Trained batch 332 in epoch 12, gen_loss = 0.3966040969700427, disc_loss = 0.07463226551833274
Trained batch 333 in epoch 12, gen_loss = 0.396676425136135, disc_loss = 0.07445787201763805
Trained batch 334 in epoch 12, gen_loss = 0.3965499319692156, disc_loss = 0.07435441678250904
Trained batch 335 in epoch 12, gen_loss = 0.3964392722451261, disc_loss = 0.07417676124688503
Trained batch 336 in epoch 12, gen_loss = 0.39644667625604113, disc_loss = 0.07413630692968118
Trained batch 337 in epoch 12, gen_loss = 0.3962258880395861, disc_loss = 0.07411587607809866
Trained batch 338 in epoch 12, gen_loss = 0.39619592961836003, disc_loss = 0.0751920982365631
Trained batch 339 in epoch 12, gen_loss = 0.3962350726565894, disc_loss = 0.0751429602421601
Trained batch 340 in epoch 12, gen_loss = 0.39594429525986446, disc_loss = 0.07535769105711378
Trained batch 341 in epoch 12, gen_loss = 0.395854894921445, disc_loss = 0.07540814608215676
Trained batch 342 in epoch 12, gen_loss = 0.3957597492995832, disc_loss = 0.07531389632362753
Trained batch 343 in epoch 12, gen_loss = 0.39574638463903306, disc_loss = 0.07535909643927373
Trained batch 344 in epoch 12, gen_loss = 0.3954197579967803, disc_loss = 0.07552367530061282
Trained batch 345 in epoch 12, gen_loss = 0.3955470462668838, disc_loss = 0.07578434027742185
Trained batch 346 in epoch 12, gen_loss = 0.39539612262839885, disc_loss = 0.07563102990657262
Trained batch 347 in epoch 12, gen_loss = 0.3952985714650017, disc_loss = 0.07557991823855915
Trained batch 348 in epoch 12, gen_loss = 0.39547212746389276, disc_loss = 0.07541239148747698
Trained batch 349 in epoch 12, gen_loss = 0.3953657787612506, disc_loss = 0.07554223401471973
Trained batch 350 in epoch 12, gen_loss = 0.3952933135110768, disc_loss = 0.07545455871282565
Trained batch 351 in epoch 12, gen_loss = 0.3954658232713965, disc_loss = 0.07537265241791663
Trained batch 352 in epoch 12, gen_loss = 0.39536792407123633, disc_loss = 0.07532212524688024
Trained batch 353 in epoch 12, gen_loss = 0.39505829502128614, disc_loss = 0.07556405914210751
Trained batch 354 in epoch 12, gen_loss = 0.3950419148508931, disc_loss = 0.07640409837148979
Trained batch 355 in epoch 12, gen_loss = 0.39492666047443165, disc_loss = 0.0764372579863274
Trained batch 356 in epoch 12, gen_loss = 0.39495620853593705, disc_loss = 0.07642729292657613
Trained batch 357 in epoch 12, gen_loss = 0.394679972537736, disc_loss = 0.07642389821700293
Trained batch 358 in epoch 12, gen_loss = 0.39463577849121145, disc_loss = 0.0763028950189191
Trained batch 359 in epoch 12, gen_loss = 0.39461667980584836, disc_loss = 0.07633922270033508
Trained batch 360 in epoch 12, gen_loss = 0.3945203778898947, disc_loss = 0.07626832491483466
Trained batch 361 in epoch 12, gen_loss = 0.39434672188199027, disc_loss = 0.07627457154153214
Trained batch 362 in epoch 12, gen_loss = 0.3944868723305132, disc_loss = 0.07614000214227878
Trained batch 363 in epoch 12, gen_loss = 0.394642108048384, disc_loss = 0.07604126173460467
Trained batch 364 in epoch 12, gen_loss = 0.3946333957453297, disc_loss = 0.07591471758556284
Trained batch 365 in epoch 12, gen_loss = 0.3944564344860165, disc_loss = 0.07610713243433605
Trained batch 366 in epoch 12, gen_loss = 0.39450939170183863, disc_loss = 0.0769571326241628
Trained batch 367 in epoch 12, gen_loss = 0.3944630990938648, disc_loss = 0.07717123263991317
Trained batch 368 in epoch 12, gen_loss = 0.3942986203806833, disc_loss = 0.07748150583962357
Trained batch 369 in epoch 12, gen_loss = 0.3942019686102867, disc_loss = 0.07739875992961429
Trained batch 370 in epoch 12, gen_loss = 0.39408939992481806, disc_loss = 0.07737153057370465
Trained batch 371 in epoch 12, gen_loss = 0.3939962600588158, disc_loss = 0.07725103517683844
Trained batch 372 in epoch 12, gen_loss = 0.39395684974602657, disc_loss = 0.07708779243807291
Trained batch 373 in epoch 12, gen_loss = 0.393762870547287, disc_loss = 0.07701824210773417
Trained batch 374 in epoch 12, gen_loss = 0.3937716502745946, disc_loss = 0.07696777935574452
Trained batch 375 in epoch 12, gen_loss = 0.3935853811575377, disc_loss = 0.07693181991170933
Trained batch 376 in epoch 12, gen_loss = 0.393784627871741, disc_loss = 0.07685622554865297
Trained batch 377 in epoch 12, gen_loss = 0.3938219762904934, disc_loss = 0.07673129818535276
Trained batch 378 in epoch 12, gen_loss = 0.39393804652867026, disc_loss = 0.07670343616893785
Trained batch 379 in epoch 12, gen_loss = 0.39400507333247287, disc_loss = 0.07656678379219221
Trained batch 380 in epoch 12, gen_loss = 0.3941140839355824, disc_loss = 0.07652989984428867
Trained batch 381 in epoch 12, gen_loss = 0.3939306225374107, disc_loss = 0.07683847411852622
Trained batch 382 in epoch 12, gen_loss = 0.39399243253173777, disc_loss = 0.0767439668609058
Trained batch 383 in epoch 12, gen_loss = 0.3941357230069116, disc_loss = 0.07659552533732494
Trained batch 384 in epoch 12, gen_loss = 0.39392091875726526, disc_loss = 0.07642380861057477
Trained batch 385 in epoch 12, gen_loss = 0.39409360478733485, disc_loss = 0.07627638643897028
Trained batch 386 in epoch 12, gen_loss = 0.393987385840071, disc_loss = 0.07611777774450545
Trained batch 387 in epoch 12, gen_loss = 0.3942435531656152, disc_loss = 0.07593941302686814
Trained batch 388 in epoch 12, gen_loss = 0.3940888789211876, disc_loss = 0.07578034445782285
Trained batch 389 in epoch 12, gen_loss = 0.3942321940492361, disc_loss = 0.07562424732396045
Trained batch 390 in epoch 12, gen_loss = 0.3941753974274906, disc_loss = 0.07564439705413435
Trained batch 391 in epoch 12, gen_loss = 0.39441666337756476, disc_loss = 0.07574255571448796
Trained batch 392 in epoch 12, gen_loss = 0.394515222075938, disc_loss = 0.0756786890960661
Trained batch 393 in epoch 12, gen_loss = 0.3946976750559613, disc_loss = 0.07552682466894804
Trained batch 394 in epoch 12, gen_loss = 0.3948707651111144, disc_loss = 0.07539152434520141
Trained batch 395 in epoch 12, gen_loss = 0.39497479642129907, disc_loss = 0.07531859052503914
Trained batch 396 in epoch 12, gen_loss = 0.3949710743628461, disc_loss = 0.07533409910379751
Trained batch 397 in epoch 12, gen_loss = 0.395038228126327, disc_loss = 0.0752886312875672
Trained batch 398 in epoch 12, gen_loss = 0.39521802005761847, disc_loss = 0.07547882692608282
Trained batch 399 in epoch 12, gen_loss = 0.39495895501226186, disc_loss = 0.07645109013072215
Trained batch 400 in epoch 12, gen_loss = 0.394913050933669, disc_loss = 0.0764571945043629
Trained batch 401 in epoch 12, gen_loss = 0.39493558822727914, disc_loss = 0.07652780093340694
Trained batch 402 in epoch 12, gen_loss = 0.394689201754021, disc_loss = 0.07651062430259274
Trained batch 403 in epoch 12, gen_loss = 0.394531431580239, disc_loss = 0.07645505318524187
Trained batch 404 in epoch 12, gen_loss = 0.3943268523172096, disc_loss = 0.07638811789522017
Trained batch 405 in epoch 12, gen_loss = 0.3941426096217973, disc_loss = 0.0765815828708941
Trained batch 406 in epoch 12, gen_loss = 0.3941812101174924, disc_loss = 0.07657760925732864
Trained batch 407 in epoch 12, gen_loss = 0.3940134865469208, disc_loss = 0.07661346656923164
Trained batch 408 in epoch 12, gen_loss = 0.39401491634857394, disc_loss = 0.07665764424189342
Trained batch 409 in epoch 12, gen_loss = 0.3940209024199625, disc_loss = 0.07659814344469185
Trained batch 410 in epoch 12, gen_loss = 0.39394600624150605, disc_loss = 0.07654115632335019
Trained batch 411 in epoch 12, gen_loss = 0.39405463936114776, disc_loss = 0.0765659089225064
Trained batch 412 in epoch 12, gen_loss = 0.3941014752188837, disc_loss = 0.07657053110868496
Trained batch 413 in epoch 12, gen_loss = 0.3942700111563655, disc_loss = 0.07679277835166361
Trained batch 414 in epoch 12, gen_loss = 0.3943835376615984, disc_loss = 0.07668433739994485
Trained batch 415 in epoch 12, gen_loss = 0.394362815333387, disc_loss = 0.07668302161059379
Trained batch 416 in epoch 12, gen_loss = 0.39454118607284355, disc_loss = 0.07683284222807209
Trained batch 417 in epoch 12, gen_loss = 0.3944883433896959, disc_loss = 0.07678476372916412
Trained batch 418 in epoch 12, gen_loss = 0.3946202181475259, disc_loss = 0.07664236365784147
Trained batch 419 in epoch 12, gen_loss = 0.3946022856448378, disc_loss = 0.07650298704060593
Trained batch 420 in epoch 12, gen_loss = 0.3946341183788703, disc_loss = 0.07636917815068095
Trained batch 421 in epoch 12, gen_loss = 0.3943716794323017, disc_loss = 0.07641864690589785
Trained batch 422 in epoch 12, gen_loss = 0.39446503808171474, disc_loss = 0.07677818442767499
Trained batch 423 in epoch 12, gen_loss = 0.3942452762275934, disc_loss = 0.07681494556644158
Trained batch 424 in epoch 12, gen_loss = 0.3942984130452661, disc_loss = 0.07666251825387864
Trained batch 425 in epoch 12, gen_loss = 0.3943663229335082, disc_loss = 0.07663254587946049
Trained batch 426 in epoch 12, gen_loss = 0.39414616354874205, disc_loss = 0.07652594478347227
Trained batch 427 in epoch 12, gen_loss = 0.3942008369785046, disc_loss = 0.07638487610073813
Trained batch 428 in epoch 12, gen_loss = 0.394343417042341, disc_loss = 0.07624303357510682
Trained batch 429 in epoch 12, gen_loss = 0.3942162457247113, disc_loss = 0.0763326899679161
Trained batch 430 in epoch 12, gen_loss = 0.39438529478563233, disc_loss = 0.07679148669097477
Trained batch 431 in epoch 12, gen_loss = 0.3942088828663583, disc_loss = 0.0766848736880261
Trained batch 432 in epoch 12, gen_loss = 0.3939641225764713, disc_loss = 0.07710804489030401
Trained batch 433 in epoch 12, gen_loss = 0.3940447763569893, disc_loss = 0.07721641408987687
Trained batch 434 in epoch 12, gen_loss = 0.3941682695314802, disc_loss = 0.07708730384942958
Trained batch 435 in epoch 12, gen_loss = 0.3942697322628367, disc_loss = 0.0769766381495299
Trained batch 436 in epoch 12, gen_loss = 0.3941830223771473, disc_loss = 0.07688344900711552
Trained batch 437 in epoch 12, gen_loss = 0.3942217099135869, disc_loss = 0.07673571558486347
Trained batch 438 in epoch 12, gen_loss = 0.3941402060906816, disc_loss = 0.07666559412477195
Trained batch 439 in epoch 12, gen_loss = 0.3941264087164944, disc_loss = 0.07668142984515394
Trained batch 440 in epoch 12, gen_loss = 0.3940881363996843, disc_loss = 0.07675989722630301
Trained batch 441 in epoch 12, gen_loss = 0.3940961386890433, disc_loss = 0.07673156902307805
Trained batch 442 in epoch 12, gen_loss = 0.39419098891334664, disc_loss = 0.07666170557027444
Trained batch 443 in epoch 12, gen_loss = 0.39423643163329847, disc_loss = 0.07659175726354357
Trained batch 444 in epoch 12, gen_loss = 0.3940615411889687, disc_loss = 0.07678356300725528
Trained batch 445 in epoch 12, gen_loss = 0.39424595768008, disc_loss = 0.07685887158196837
Trained batch 446 in epoch 12, gen_loss = 0.39449281937190617, disc_loss = 0.07671599153125079
Trained batch 447 in epoch 12, gen_loss = 0.39466227747366894, disc_loss = 0.07658250291985626
Trained batch 448 in epoch 12, gen_loss = 0.39449400496243897, disc_loss = 0.07666961655937517
Trained batch 449 in epoch 12, gen_loss = 0.394592554933495, disc_loss = 0.07677475018323296
Trained batch 450 in epoch 12, gen_loss = 0.39444204705649627, disc_loss = 0.07663570465148321
Trained batch 451 in epoch 12, gen_loss = 0.3943845613538164, disc_loss = 0.07677628500572513
Trained batch 452 in epoch 12, gen_loss = 0.3945216242117071, disc_loss = 0.07731485924484088
Trained batch 453 in epoch 12, gen_loss = 0.39458452096200725, disc_loss = 0.07717638117433546
Trained batch 454 in epoch 12, gen_loss = 0.39450711670157673, disc_loss = 0.0771272980341954
Trained batch 455 in epoch 12, gen_loss = 0.3946253300170627, disc_loss = 0.07703944350482504
Trained batch 456 in epoch 12, gen_loss = 0.3946306138448173, disc_loss = 0.07699008089647154
Trained batch 457 in epoch 12, gen_loss = 0.394544329673182, disc_loss = 0.0769213380863459
Trained batch 458 in epoch 12, gen_loss = 0.39479087429498533, disc_loss = 0.0767973178849517
Testing Epoch 12
Training Epoch 13
Trained batch 0 in epoch 13, gen_loss = 0.407787561416626, disc_loss = 0.03422464802861214
Trained batch 1 in epoch 13, gen_loss = 0.4444323629140854, disc_loss = 0.02851116470992565
Trained batch 2 in epoch 13, gen_loss = 0.46698257327079773, disc_loss = 0.025913132975498836
Trained batch 3 in epoch 13, gen_loss = 0.4383687749505043, disc_loss = 0.027813308872282505
Trained batch 4 in epoch 13, gen_loss = 0.43138766288757324, disc_loss = 0.03691834881901741
Trained batch 5 in epoch 13, gen_loss = 0.41597991685072583, disc_loss = 0.05104795408745607
Trained batch 6 in epoch 13, gen_loss = 0.41092577150889803, disc_loss = 0.04748552931206567
Trained batch 7 in epoch 13, gen_loss = 0.4071280434727669, disc_loss = 0.061849878169596195
Trained batch 8 in epoch 13, gen_loss = 0.3974555532137553, disc_loss = 0.06226774387889438
Trained batch 9 in epoch 13, gen_loss = 0.4029648780822754, disc_loss = 0.05689629018306732
Trained batch 10 in epoch 13, gen_loss = 0.4079846306280656, disc_loss = 0.0523963474499231
Trained batch 11 in epoch 13, gen_loss = 0.4060099596778552, disc_loss = 0.049149219140720866
Trained batch 12 in epoch 13, gen_loss = 0.40051060227247387, disc_loss = 0.05097824410320474
Trained batch 13 in epoch 13, gen_loss = 0.4052670810903822, disc_loss = 0.06319949739346546
Trained batch 14 in epoch 13, gen_loss = 0.40150723854700726, disc_loss = 0.062197538123776513
Trained batch 15 in epoch 13, gen_loss = 0.4043114688247442, disc_loss = 0.06817705268622376
Trained batch 16 in epoch 13, gen_loss = 0.40235263109207153, disc_loss = 0.07302680165123414
Trained batch 17 in epoch 13, gen_loss = 0.4034873942534129, disc_loss = 0.07012535375542939
Trained batch 18 in epoch 13, gen_loss = 0.40118171980506495, disc_loss = 0.06801943316761601
Trained batch 19 in epoch 13, gen_loss = 0.39848328977823255, disc_loss = 0.06716246299911291
Trained batch 20 in epoch 13, gen_loss = 0.40078901109241305, disc_loss = 0.06451717211997934
Trained batch 21 in epoch 13, gen_loss = 0.4015804109248248, disc_loss = 0.06292173238894479
Trained batch 22 in epoch 13, gen_loss = 0.4012371327566064, disc_loss = 0.06138993878646389
Trained batch 23 in epoch 13, gen_loss = 0.4022645466029644, disc_loss = 0.06240837258519605
Trained batch 24 in epoch 13, gen_loss = 0.4020916748046875, disc_loss = 0.07020823938772082
Trained batch 25 in epoch 13, gen_loss = 0.40470250753255993, disc_loss = 0.07200575088007519
Trained batch 26 in epoch 13, gen_loss = 0.4070100254482693, disc_loss = 0.07016342793832775
Trained batch 27 in epoch 13, gen_loss = 0.4042283722332546, disc_loss = 0.06831466411573014
Trained batch 28 in epoch 13, gen_loss = 0.4012230829945926, disc_loss = 0.06805898819182968
Trained batch 29 in epoch 13, gen_loss = 0.39989517629146576, disc_loss = 0.06788595869826773
Trained batch 30 in epoch 13, gen_loss = 0.3987388264748358, disc_loss = 0.06713316473929633
Trained batch 31 in epoch 13, gen_loss = 0.3978960486128926, disc_loss = 0.06685806372843217
Trained batch 32 in epoch 13, gen_loss = 0.3972278264435855, disc_loss = 0.0673989755609496
Trained batch 33 in epoch 13, gen_loss = 0.40089422727332397, disc_loss = 0.0730336021823699
Trained batch 34 in epoch 13, gen_loss = 0.39877821121897017, disc_loss = 0.07617522503382393
Trained batch 35 in epoch 13, gen_loss = 0.4006515045960744, disc_loss = 0.0746801273457499
Trained batch 36 in epoch 13, gen_loss = 0.4023132767226245, disc_loss = 0.07415334259889819
Trained batch 37 in epoch 13, gen_loss = 0.40055396682337713, disc_loss = 0.0733783467011036
Trained batch 38 in epoch 13, gen_loss = 0.39882850035642964, disc_loss = 0.07257661561314495
Trained batch 39 in epoch 13, gen_loss = 0.3989569343626499, disc_loss = 0.0717901879339479
Trained batch 40 in epoch 13, gen_loss = 0.40096278815734676, disc_loss = 0.07219735200221582
Trained batch 41 in epoch 13, gen_loss = 0.3999502793664024, disc_loss = 0.07341030305473223
Trained batch 42 in epoch 13, gen_loss = 0.40156515254530795, disc_loss = 0.07557971111693701
Trained batch 43 in epoch 13, gen_loss = 0.3993659561330622, disc_loss = 0.07717629584526135
Trained batch 44 in epoch 13, gen_loss = 0.39931445916493735, disc_loss = 0.07648153746914532
Trained batch 45 in epoch 13, gen_loss = 0.4012380942054417, disc_loss = 0.07525913387982418
Trained batch 46 in epoch 13, gen_loss = 0.4012539481863062, disc_loss = 0.07546236844574834
Trained batch 47 in epoch 13, gen_loss = 0.4006043014427026, disc_loss = 0.0748890042596031
Trained batch 48 in epoch 13, gen_loss = 0.39997858843024897, disc_loss = 0.07439966852377568
Trained batch 49 in epoch 13, gen_loss = 0.4008777493238449, disc_loss = 0.07369136708788573
Trained batch 50 in epoch 13, gen_loss = 0.40195192192115037, disc_loss = 0.07369844924987239
Trained batch 51 in epoch 13, gen_loss = 0.40222899271891666, disc_loss = 0.07692872979140912
Trained batch 52 in epoch 13, gen_loss = 0.4040036302692485, disc_loss = 0.07746519924159039
Trained batch 53 in epoch 13, gen_loss = 0.4056505235256972, disc_loss = 0.07634817739017308
Trained batch 54 in epoch 13, gen_loss = 0.4048206107182936, disc_loss = 0.07512415370649912
Trained batch 55 in epoch 13, gen_loss = 0.4037708358040878, disc_loss = 0.07416896286719878
Trained batch 56 in epoch 13, gen_loss = 0.40378656721951667, disc_loss = 0.07346744519217234
Trained batch 57 in epoch 13, gen_loss = 0.4035843703253516, disc_loss = 0.07283739312873061
Trained batch 58 in epoch 13, gen_loss = 0.4024019352460312, disc_loss = 0.0721255333510117
Trained batch 59 in epoch 13, gen_loss = 0.40028904130061466, disc_loss = 0.07343138553357373
Trained batch 60 in epoch 13, gen_loss = 0.40098767642114985, disc_loss = 0.07268812935646685
Trained batch 61 in epoch 13, gen_loss = 0.4008962983085263, disc_loss = 0.07415147342779223
Trained batch 62 in epoch 13, gen_loss = 0.40053607357872856, disc_loss = 0.07493932049218861
Trained batch 63 in epoch 13, gen_loss = 0.400632553268224, disc_loss = 0.07422490765020484
Trained batch 64 in epoch 13, gen_loss = 0.4014485886463752, disc_loss = 0.07331450049263927
Trained batch 65 in epoch 13, gen_loss = 0.4011317184477141, disc_loss = 0.0726217213298448
Trained batch 66 in epoch 13, gen_loss = 0.40225997389252505, disc_loss = 0.07224908138194414
Trained batch 67 in epoch 13, gen_loss = 0.4014338215484339, disc_loss = 0.07526962394031751
Trained batch 68 in epoch 13, gen_loss = 0.402089993590894, disc_loss = 0.07560623427043142
Trained batch 69 in epoch 13, gen_loss = 0.40230093598365785, disc_loss = 0.07518726673110256
Trained batch 70 in epoch 13, gen_loss = 0.4025148883671828, disc_loss = 0.07478331664944408
Trained batch 71 in epoch 13, gen_loss = 0.4033663802676731, disc_loss = 0.07458925780762608
Trained batch 72 in epoch 13, gen_loss = 0.4030354880306819, disc_loss = 0.0739444770135802
Trained batch 73 in epoch 13, gen_loss = 0.4028736880502185, disc_loss = 0.07339001963594677
Trained batch 74 in epoch 13, gen_loss = 0.40399513244628904, disc_loss = 0.0735738910548389
Trained batch 75 in epoch 13, gen_loss = 0.403158043168093, disc_loss = 0.0734245617641136
Trained batch 76 in epoch 13, gen_loss = 0.40263151464524205, disc_loss = 0.0763485394236813
Trained batch 77 in epoch 13, gen_loss = 0.40146077481599957, disc_loss = 0.07574391301172093
Trained batch 78 in epoch 13, gen_loss = 0.4024412175522575, disc_loss = 0.07514909030633825
Trained batch 79 in epoch 13, gen_loss = 0.4031375993043184, disc_loss = 0.07464834645506926
Trained batch 80 in epoch 13, gen_loss = 0.4030090798566371, disc_loss = 0.07419702349184656
Trained batch 81 in epoch 13, gen_loss = 0.40349383325111576, disc_loss = 0.07388085656708515
Trained batch 82 in epoch 13, gen_loss = 0.40358860162367305, disc_loss = 0.07355781063908734
Trained batch 83 in epoch 13, gen_loss = 0.40306105003470466, disc_loss = 0.07436828069677133
Trained batch 84 in epoch 13, gen_loss = 0.40334571354529436, disc_loss = 0.07477031808675212
Trained batch 85 in epoch 13, gen_loss = 0.40257143385188526, disc_loss = 0.07438996436919064
Trained batch 86 in epoch 13, gen_loss = 0.40221767007619486, disc_loss = 0.0750313754321943
Trained batch 87 in epoch 13, gen_loss = 0.4026742533526637, disc_loss = 0.07432109251385555
Trained batch 88 in epoch 13, gen_loss = 0.4021733527103167, disc_loss = 0.07468628429734472
Trained batch 89 in epoch 13, gen_loss = 0.4039714922507604, disc_loss = 0.07568241836399668
Trained batch 90 in epoch 13, gen_loss = 0.40529839317877214, disc_loss = 0.0750547486848638
Trained batch 91 in epoch 13, gen_loss = 0.4046053015019583, disc_loss = 0.07518726026983527
Trained batch 92 in epoch 13, gen_loss = 0.40422648031224484, disc_loss = 0.07487937774489163
Trained batch 93 in epoch 13, gen_loss = 0.40405537124643937, disc_loss = 0.07437202974935954
Trained batch 94 in epoch 13, gen_loss = 0.4048601592841901, disc_loss = 0.07432403068891481
Trained batch 95 in epoch 13, gen_loss = 0.4039840456098318, disc_loss = 0.07459759951355711
Trained batch 96 in epoch 13, gen_loss = 0.4042211875473101, disc_loss = 0.07449797670040087
Trained batch 97 in epoch 13, gen_loss = 0.40449994528780175, disc_loss = 0.07389242748957964
Trained batch 98 in epoch 13, gen_loss = 0.4043561247262088, disc_loss = 0.07445400711995634
Trained batch 99 in epoch 13, gen_loss = 0.4049139314889908, disc_loss = 0.07490722700487823
Trained batch 100 in epoch 13, gen_loss = 0.40436380924564774, disc_loss = 0.07442949117982003
Trained batch 101 in epoch 13, gen_loss = 0.4049004500403124, disc_loss = 0.07403145394032347
Trained batch 102 in epoch 13, gen_loss = 0.4049071310793312, disc_loss = 0.07342714557279516
Trained batch 103 in epoch 13, gen_loss = 0.40447618898290855, disc_loss = 0.07311914805233335
Trained batch 104 in epoch 13, gen_loss = 0.4042024266152155, disc_loss = 0.07301367433919083
Trained batch 105 in epoch 13, gen_loss = 0.40367236002436224, disc_loss = 0.07523006620324867
Trained batch 106 in epoch 13, gen_loss = 0.40264834198996285, disc_loss = 0.07629262229044721
Trained batch 107 in epoch 13, gen_loss = 0.4033563647557188, disc_loss = 0.07575928738461463
Trained batch 108 in epoch 13, gen_loss = 0.40395063025142075, disc_loss = 0.07558192228556636
Trained batch 109 in epoch 13, gen_loss = 0.4042811493981968, disc_loss = 0.07499362915669652
Trained batch 110 in epoch 13, gen_loss = 0.4042374250051138, disc_loss = 0.07460001236465466
Trained batch 111 in epoch 13, gen_loss = 0.40407690512282507, disc_loss = 0.07405870731703804
Trained batch 112 in epoch 13, gen_loss = 0.4032425487463453, disc_loss = 0.07389279202335572
Trained batch 113 in epoch 13, gen_loss = 0.40363862875260803, disc_loss = 0.07356719298108497
Trained batch 114 in epoch 13, gen_loss = 0.4024496622707533, disc_loss = 0.07400844684680519
Trained batch 115 in epoch 13, gen_loss = 0.4036480599436267, disc_loss = 0.07452134342848099
Trained batch 116 in epoch 13, gen_loss = 0.4034150619792123, disc_loss = 0.07419267867922656
Trained batch 117 in epoch 13, gen_loss = 0.40238701968880025, disc_loss = 0.074662784757724
Trained batch 118 in epoch 13, gen_loss = 0.4020370500428336, disc_loss = 0.07437468333827223
Trained batch 119 in epoch 13, gen_loss = 0.40249285275737445, disc_loss = 0.0747237557040838
Trained batch 120 in epoch 13, gen_loss = 0.4019991011658976, disc_loss = 0.07442770727086535
Trained batch 121 in epoch 13, gen_loss = 0.4019117707111796, disc_loss = 0.07534373381755269
Trained batch 122 in epoch 13, gen_loss = 0.40237051830059145, disc_loss = 0.07497357508561354
Trained batch 123 in epoch 13, gen_loss = 0.40281554864298913, disc_loss = 0.07581123118964775
Trained batch 124 in epoch 13, gen_loss = 0.40158409988880156, disc_loss = 0.07588880370184779
Trained batch 125 in epoch 13, gen_loss = 0.4016979600465487, disc_loss = 0.07552823623538846
Trained batch 126 in epoch 13, gen_loss = 0.4016198017231123, disc_loss = 0.07534465347380033
Trained batch 127 in epoch 13, gen_loss = 0.40126993611920625, disc_loss = 0.07504536742271739
Trained batch 128 in epoch 13, gen_loss = 0.401236794600191, disc_loss = 0.07479435039048855
Trained batch 129 in epoch 13, gen_loss = 0.40112958149268074, disc_loss = 0.07465675090296338
Trained batch 130 in epoch 13, gen_loss = 0.4011237804443782, disc_loss = 0.07477235129700248
Trained batch 131 in epoch 13, gen_loss = 0.4012270837344907, disc_loss = 0.07524112449380371
Trained batch 132 in epoch 13, gen_loss = 0.4011828562146739, disc_loss = 0.07499532052490832
Trained batch 133 in epoch 13, gen_loss = 0.4010368706797486, disc_loss = 0.07474622829233421
Trained batch 134 in epoch 13, gen_loss = 0.4014128138621648, disc_loss = 0.0744286448970713
Trained batch 135 in epoch 13, gen_loss = 0.40103559272692485, disc_loss = 0.07409372444689165
Trained batch 136 in epoch 13, gen_loss = 0.400836792631741, disc_loss = 0.07449009819772012
Trained batch 137 in epoch 13, gen_loss = 0.40151167164246243, disc_loss = 0.07480593777153695
Trained batch 138 in epoch 13, gen_loss = 0.401337001285107, disc_loss = 0.07443156523174412
Trained batch 139 in epoch 13, gen_loss = 0.4014986620417663, disc_loss = 0.0743767518649942
Trained batch 140 in epoch 13, gen_loss = 0.4011741611340367, disc_loss = 0.07395540965483227
Trained batch 141 in epoch 13, gen_loss = 0.40056494770335477, disc_loss = 0.07360725482912656
Trained batch 142 in epoch 13, gen_loss = 0.4003638234380242, disc_loss = 0.0733148506191279
Trained batch 143 in epoch 13, gen_loss = 0.4003052259277966, disc_loss = 0.07341073712450452
Trained batch 144 in epoch 13, gen_loss = 0.4005952669628735, disc_loss = 0.07441190728146968
Trained batch 145 in epoch 13, gen_loss = 0.40058677010748484, disc_loss = 0.07403532012799525
Trained batch 146 in epoch 13, gen_loss = 0.40009428094438954, disc_loss = 0.07407858339613493
Trained batch 147 in epoch 13, gen_loss = 0.39986609717881355, disc_loss = 0.07475127280073089
Trained batch 148 in epoch 13, gen_loss = 0.39988354898539163, disc_loss = 0.07478981835442601
Trained batch 149 in epoch 13, gen_loss = 0.39976657658815384, disc_loss = 0.07436359150645634
Trained batch 150 in epoch 13, gen_loss = 0.40016239279548066, disc_loss = 0.07415448105431452
Trained batch 151 in epoch 13, gen_loss = 0.3998725089783731, disc_loss = 0.07381184567930177
Trained batch 152 in epoch 13, gen_loss = 0.39941953142094455, disc_loss = 0.07353852895922423
Trained batch 153 in epoch 13, gen_loss = 0.3991050047727374, disc_loss = 0.0731140065956377
Trained batch 154 in epoch 13, gen_loss = 0.39939267375776843, disc_loss = 0.07283093687447328
Trained batch 155 in epoch 13, gen_loss = 0.3991061730835682, disc_loss = 0.07302674358316626
Trained batch 156 in epoch 13, gen_loss = 0.39906319871449925, disc_loss = 0.07542219144369292
Trained batch 157 in epoch 13, gen_loss = 0.3992821761890303, disc_loss = 0.07550142388024568
Trained batch 158 in epoch 13, gen_loss = 0.3989296320286937, disc_loss = 0.0757735395341315
Trained batch 159 in epoch 13, gen_loss = 0.3988406023941934, disc_loss = 0.07554030645114836
Trained batch 160 in epoch 13, gen_loss = 0.3991479350728278, disc_loss = 0.07527331705638989
Trained batch 161 in epoch 13, gen_loss = 0.3992522416843308, disc_loss = 0.07513863591902693
Trained batch 162 in epoch 13, gen_loss = 0.3984378326707091, disc_loss = 0.0754199407714779
Trained batch 163 in epoch 13, gen_loss = 0.3982795955749547, disc_loss = 0.07506860413009346
Trained batch 164 in epoch 13, gen_loss = 0.3981020413564913, disc_loss = 0.07482504483143038
Trained batch 165 in epoch 13, gen_loss = 0.3976949581719307, disc_loss = 0.07447026256774833
Trained batch 166 in epoch 13, gen_loss = 0.39801862309435887, disc_loss = 0.07408671531948947
Trained batch 167 in epoch 13, gen_loss = 0.39752401988066377, disc_loss = 0.07420067467250019
Trained batch 168 in epoch 13, gen_loss = 0.39790681348397183, disc_loss = 0.07394568372198199
Trained batch 169 in epoch 13, gen_loss = 0.3980362523128005, disc_loss = 0.07383055188693106
Trained batch 170 in epoch 13, gen_loss = 0.398691273833576, disc_loss = 0.07346763181069876
Trained batch 171 in epoch 13, gen_loss = 0.3986444940227409, disc_loss = 0.07389081271939239
Trained batch 172 in epoch 13, gen_loss = 0.39811055517265564, disc_loss = 0.07519442465619286
Trained batch 173 in epoch 13, gen_loss = 0.39785384232627935, disc_loss = 0.07524324489232881
Trained batch 174 in epoch 13, gen_loss = 0.39743155079228537, disc_loss = 0.07562072888282793
Trained batch 175 in epoch 13, gen_loss = 0.3973035112192685, disc_loss = 0.07555294619206424
Trained batch 176 in epoch 13, gen_loss = 0.39665202661759436, disc_loss = 0.0755143830484295
Trained batch 177 in epoch 13, gen_loss = 0.39694501735856025, disc_loss = 0.07526799823220275
Trained batch 178 in epoch 13, gen_loss = 0.3967387252513257, disc_loss = 0.07530155957171787
Trained batch 179 in epoch 13, gen_loss = 0.39660588709844485, disc_loss = 0.07514335354013989
Trained batch 180 in epoch 13, gen_loss = 0.3963863572198383, disc_loss = 0.07536708598812394
Trained batch 181 in epoch 13, gen_loss = 0.3959697541463506, disc_loss = 0.0758020876021544
Trained batch 182 in epoch 13, gen_loss = 0.3966177644136825, disc_loss = 0.07643726458162313
Trained batch 183 in epoch 13, gen_loss = 0.396579270210603, disc_loss = 0.07643980401537745
Trained batch 184 in epoch 13, gen_loss = 0.3962667205043741, disc_loss = 0.07636555588577648
Trained batch 185 in epoch 13, gen_loss = 0.3962820426270526, disc_loss = 0.07648499488520126
Trained batch 186 in epoch 13, gen_loss = 0.3963354080915451, disc_loss = 0.07630380324989477
Trained batch 187 in epoch 13, gen_loss = 0.3967246093807068, disc_loss = 0.07642244526056295
Trained batch 188 in epoch 13, gen_loss = 0.3969937711954117, disc_loss = 0.07649416951758284
Trained batch 189 in epoch 13, gen_loss = 0.3968046129534119, disc_loss = 0.0761772935548307
Trained batch 190 in epoch 13, gen_loss = 0.396978272271406, disc_loss = 0.0760094976340328
Trained batch 191 in epoch 13, gen_loss = 0.3970414759436001, disc_loss = 0.07582412712751345
Trained batch 192 in epoch 13, gen_loss = 0.39697177569174397, disc_loss = 0.07675393819664195
Trained batch 193 in epoch 13, gen_loss = 0.3967015567360465, disc_loss = 0.07846798945804001
Trained batch 194 in epoch 13, gen_loss = 0.3976357272802255, disc_loss = 0.07840626792122539
Trained batch 195 in epoch 13, gen_loss = 0.39794882713836066, disc_loss = 0.07812117996426034
Trained batch 196 in epoch 13, gen_loss = 0.3977808842652945, disc_loss = 0.07793517859160976
Trained batch 197 in epoch 13, gen_loss = 0.3978019815051194, disc_loss = 0.07775106303854798
Trained batch 198 in epoch 13, gen_loss = 0.39775348166425023, disc_loss = 0.07747859481825077
Trained batch 199 in epoch 13, gen_loss = 0.3977441669255495, disc_loss = 0.07729597937548532
Trained batch 200 in epoch 13, gen_loss = 0.3974492491329487, disc_loss = 0.07716828818428353
Trained batch 201 in epoch 13, gen_loss = 0.397284495432188, disc_loss = 0.07767741924548281
Trained batch 202 in epoch 13, gen_loss = 0.39705957017215016, disc_loss = 0.07869443411392898
Trained batch 203 in epoch 13, gen_loss = 0.39752623358485745, disc_loss = 0.07897556482074673
Trained batch 204 in epoch 13, gen_loss = 0.3976072064987043, disc_loss = 0.07870155949281847
Trained batch 205 in epoch 13, gen_loss = 0.3976677324152687, disc_loss = 0.07843912397601722
Trained batch 206 in epoch 13, gen_loss = 0.39752213599313285, disc_loss = 0.07841572285391354
Trained batch 207 in epoch 13, gen_loss = 0.3976896834344818, disc_loss = 0.07816788386061
Trained batch 208 in epoch 13, gen_loss = 0.3976329868062261, disc_loss = 0.07787346289355004
Trained batch 209 in epoch 13, gen_loss = 0.39729004764840714, disc_loss = 0.0778644658824695
Trained batch 210 in epoch 13, gen_loss = 0.3973868912288928, disc_loss = 0.07773680810406097
Trained batch 211 in epoch 13, gen_loss = 0.398045050296581, disc_loss = 0.07751828425273932
Trained batch 212 in epoch 13, gen_loss = 0.39810577853464746, disc_loss = 0.07729893574106371
Trained batch 213 in epoch 13, gen_loss = 0.39761022659384204, disc_loss = 0.07718915796281647
Trained batch 214 in epoch 13, gen_loss = 0.39780403465725656, disc_loss = 0.0769521143309079
Trained batch 215 in epoch 13, gen_loss = 0.3979682542245697, disc_loss = 0.0766273374880526
Trained batch 216 in epoch 13, gen_loss = 0.3981646083055004, disc_loss = 0.07634920007356095
Trained batch 217 in epoch 13, gen_loss = 0.3985315690483522, disc_loss = 0.07605012033536278
Trained batch 218 in epoch 13, gen_loss = 0.398624750781277, disc_loss = 0.07586837068974087
Trained batch 219 in epoch 13, gen_loss = 0.39844813150438396, disc_loss = 0.07597608588932252
Trained batch 220 in epoch 13, gen_loss = 0.39877911437960234, disc_loss = 0.0760174758997809
Trained batch 221 in epoch 13, gen_loss = 0.3987076781220264, disc_loss = 0.0757890891782973
Trained batch 222 in epoch 13, gen_loss = 0.3985616891507076, disc_loss = 0.07551761071569382
Trained batch 223 in epoch 13, gen_loss = 0.3984715319238603, disc_loss = 0.07529145043268468
Trained batch 224 in epoch 13, gen_loss = 0.39824862937132516, disc_loss = 0.07549553632529246
Trained batch 225 in epoch 13, gen_loss = 0.3986055353178387, disc_loss = 0.0753140206040765
Trained batch 226 in epoch 13, gen_loss = 0.39854855691021235, disc_loss = 0.07532198032741702
Trained batch 227 in epoch 13, gen_loss = 0.39799722748105987, disc_loss = 0.07600331085676883
Trained batch 228 in epoch 13, gen_loss = 0.3981669600483632, disc_loss = 0.07592658491756393
Trained batch 229 in epoch 13, gen_loss = 0.3982129580948664, disc_loss = 0.07573896322358886
Trained batch 230 in epoch 13, gen_loss = 0.3978442270389367, disc_loss = 0.07594879622897738
Trained batch 231 in epoch 13, gen_loss = 0.3977743224722558, disc_loss = 0.07568654560700766
Trained batch 232 in epoch 13, gen_loss = 0.3977884538311815, disc_loss = 0.0756149049108856
Trained batch 233 in epoch 13, gen_loss = 0.39754009584331107, disc_loss = 0.07565086384096907
Trained batch 234 in epoch 13, gen_loss = 0.397669825084666, disc_loss = 0.075538014618561
Trained batch 235 in epoch 13, gen_loss = 0.397643401524273, disc_loss = 0.07540735153883885
Trained batch 236 in epoch 13, gen_loss = 0.3975576061110959, disc_loss = 0.07543148175628565
Trained batch 237 in epoch 13, gen_loss = 0.39752849203949214, disc_loss = 0.07519885110121001
Trained batch 238 in epoch 13, gen_loss = 0.3977516252999525, disc_loss = 0.07501075489867369
Trained batch 239 in epoch 13, gen_loss = 0.39783712743471067, disc_loss = 0.0748431191915491
Trained batch 240 in epoch 13, gen_loss = 0.3978333386024499, disc_loss = 0.07487387056906873
Trained batch 241 in epoch 13, gen_loss = 0.39773007002004906, disc_loss = 0.07494736162460724
Trained batch 242 in epoch 13, gen_loss = 0.398297643771878, disc_loss = 0.0748892747797072
Trained batch 243 in epoch 13, gen_loss = 0.39837656542658806, disc_loss = 0.07464279801027514
Trained batch 244 in epoch 13, gen_loss = 0.39850272007134496, disc_loss = 0.07450430104508995
Trained batch 245 in epoch 13, gen_loss = 0.3986840918660164, disc_loss = 0.07457842999062221
Trained batch 246 in epoch 13, gen_loss = 0.39866727656922357, disc_loss = 0.07434958541720563
Trained batch 247 in epoch 13, gen_loss = 0.3985351458071701, disc_loss = 0.07449560200292317
Trained batch 248 in epoch 13, gen_loss = 0.39880168527723797, disc_loss = 0.07430503588641085
Trained batch 249 in epoch 13, gen_loss = 0.3989849883913994, disc_loss = 0.074079698683694
Trained batch 250 in epoch 13, gen_loss = 0.3992242015809177, disc_loss = 0.07393985400644254
Trained batch 251 in epoch 13, gen_loss = 0.3987781797491369, disc_loss = 0.07378949605054148
Trained batch 252 in epoch 13, gen_loss = 0.3986417483317522, disc_loss = 0.07372073536341192
Trained batch 253 in epoch 13, gen_loss = 0.39875100840499084, disc_loss = 0.07352791756105528
Trained batch 254 in epoch 13, gen_loss = 0.3987360537636514, disc_loss = 0.07332240995567511
Trained batch 255 in epoch 13, gen_loss = 0.3986482245963998, disc_loss = 0.0734698193064105
Trained batch 256 in epoch 13, gen_loss = 0.3986800709007315, disc_loss = 0.07413083869521778
Trained batch 257 in epoch 13, gen_loss = 0.3983504838606184, disc_loss = 0.07396779045671975
Trained batch 258 in epoch 13, gen_loss = 0.39837719143357514, disc_loss = 0.07398808239257991
Trained batch 259 in epoch 13, gen_loss = 0.39834617003798484, disc_loss = 0.07380855502739836
Trained batch 260 in epoch 13, gen_loss = 0.3981521110767606, disc_loss = 0.07360444103913574
Trained batch 261 in epoch 13, gen_loss = 0.3982766122194647, disc_loss = 0.07337088183542528
Trained batch 262 in epoch 13, gen_loss = 0.3985719520442839, disc_loss = 0.07319292795982481
Trained batch 263 in epoch 13, gen_loss = 0.39871328803851747, disc_loss = 0.07313605103197253
Trained batch 264 in epoch 13, gen_loss = 0.398877898870774, disc_loss = 0.07300771299292738
Trained batch 265 in epoch 13, gen_loss = 0.39866913849473895, disc_loss = 0.07296602981326107
Trained batch 266 in epoch 13, gen_loss = 0.398699881599637, disc_loss = 0.07298185809058476
Trained batch 267 in epoch 13, gen_loss = 0.39898724092253995, disc_loss = 0.07358125220713164
Trained batch 268 in epoch 13, gen_loss = 0.39884541718268485, disc_loss = 0.07403099211625284
Trained batch 269 in epoch 13, gen_loss = 0.3993093669966415, disc_loss = 0.07392476920072955
Trained batch 270 in epoch 13, gen_loss = 0.39911736932847774, disc_loss = 0.07395886686352181
Trained batch 271 in epoch 13, gen_loss = 0.39893518689581575, disc_loss = 0.07379315480733674
Trained batch 272 in epoch 13, gen_loss = 0.3989265739590257, disc_loss = 0.07366614830560791
Trained batch 273 in epoch 13, gen_loss = 0.3988589929947018, disc_loss = 0.07346266215279644
Trained batch 274 in epoch 13, gen_loss = 0.3987825267423283, disc_loss = 0.07334385139867663
Trained batch 275 in epoch 13, gen_loss = 0.39871562418082485, disc_loss = 0.07346127451687673
Trained batch 276 in epoch 13, gen_loss = 0.3988247100089001, disc_loss = 0.07405611049108181
Trained batch 277 in epoch 13, gen_loss = 0.39874153498479786, disc_loss = 0.07476333206646787
Trained batch 278 in epoch 13, gen_loss = 0.3987193862276693, disc_loss = 0.07478086121119959
Trained batch 279 in epoch 13, gen_loss = 0.39869885769273555, disc_loss = 0.07484334118697526
Trained batch 280 in epoch 13, gen_loss = 0.39855609335721176, disc_loss = 0.07494186042075533
Trained batch 281 in epoch 13, gen_loss = 0.39862869568961734, disc_loss = 0.07521208520509726
Trained batch 282 in epoch 13, gen_loss = 0.3985964506864548, disc_loss = 0.07500379118745877
Trained batch 283 in epoch 13, gen_loss = 0.39869118696996864, disc_loss = 0.0748117498899351
Trained batch 284 in epoch 13, gen_loss = 0.3985852314191952, disc_loss = 0.0746480333063294
Trained batch 285 in epoch 13, gen_loss = 0.39837851000207286, disc_loss = 0.07472603886805058
Trained batch 286 in epoch 13, gen_loss = 0.3985535241274053, disc_loss = 0.07531341088883813
Trained batch 287 in epoch 13, gen_loss = 0.39841456509505707, disc_loss = 0.07517094151019894
Trained batch 288 in epoch 13, gen_loss = 0.3984225399044558, disc_loss = 0.07498890888042567
Trained batch 289 in epoch 13, gen_loss = 0.39830669426712495, disc_loss = 0.07492034501588807
Trained batch 290 in epoch 13, gen_loss = 0.39827789663244356, disc_loss = 0.07472904633468215
Trained batch 291 in epoch 13, gen_loss = 0.3976083059016972, disc_loss = 0.07543226767950117
Trained batch 292 in epoch 13, gen_loss = 0.39793202240312464, disc_loss = 0.07551869462838606
Trained batch 293 in epoch 13, gen_loss = 0.3982057091938395, disc_loss = 0.07537971605660812
Trained batch 294 in epoch 13, gen_loss = 0.39819891028485055, disc_loss = 0.07516033619610687
Trained batch 295 in epoch 13, gen_loss = 0.39836530125624425, disc_loss = 0.0749654672470422
Trained batch 296 in epoch 13, gen_loss = 0.3982195360491974, disc_loss = 0.0747833293015984
Trained batch 297 in epoch 13, gen_loss = 0.3981238247564175, disc_loss = 0.07467362738914488
Trained batch 298 in epoch 13, gen_loss = 0.3980449345398906, disc_loss = 0.07454827154229667
Trained batch 299 in epoch 13, gen_loss = 0.3980247200528781, disc_loss = 0.07457068125872562
Trained batch 300 in epoch 13, gen_loss = 0.39779294933195525, disc_loss = 0.07447072052152401
Trained batch 301 in epoch 13, gen_loss = 0.3979729095239513, disc_loss = 0.0743383370780861
Trained batch 302 in epoch 13, gen_loss = 0.39814663651359355, disc_loss = 0.07421307217040815
Trained batch 303 in epoch 13, gen_loss = 0.39829660961894614, disc_loss = 0.07426610449788552
Trained batch 304 in epoch 13, gen_loss = 0.3978352129459381, disc_loss = 0.07435285916063385
Trained batch 305 in epoch 13, gen_loss = 0.39803510037512563, disc_loss = 0.07416781445727776
Trained batch 306 in epoch 13, gen_loss = 0.39809439236644034, disc_loss = 0.07399044092289546
Trained batch 307 in epoch 13, gen_loss = 0.39797525620692736, disc_loss = 0.07429761605113502
Trained batch 308 in epoch 13, gen_loss = 0.39783618268843224, disc_loss = 0.07545028555637955
Trained batch 309 in epoch 13, gen_loss = 0.3981107892528657, disc_loss = 0.07533154046433346
Trained batch 310 in epoch 13, gen_loss = 0.39828782008775176, disc_loss = 0.07565942848508525
Trained batch 311 in epoch 13, gen_loss = 0.3981824976702531, disc_loss = 0.0759997537989432
Trained batch 312 in epoch 13, gen_loss = 0.39803763500417766, disc_loss = 0.07608124174433537
Trained batch 313 in epoch 13, gen_loss = 0.3982948154021221, disc_loss = 0.07615512869154714
Trained batch 314 in epoch 13, gen_loss = 0.39808435865810937, disc_loss = 0.0761881135389327
Trained batch 315 in epoch 13, gen_loss = 0.3978846893657612, disc_loss = 0.07633363133549832
Trained batch 316 in epoch 13, gen_loss = 0.39774907754046684, disc_loss = 0.07687858507266321
Trained batch 317 in epoch 13, gen_loss = 0.3978749139691299, disc_loss = 0.07676490576521922
Trained batch 318 in epoch 13, gen_loss = 0.3980102667987907, disc_loss = 0.07667979969260601
Trained batch 319 in epoch 13, gen_loss = 0.39784653224051, disc_loss = 0.07665706781990593
Trained batch 320 in epoch 13, gen_loss = 0.3978883903531642, disc_loss = 0.07663459442062681
Trained batch 321 in epoch 13, gen_loss = 0.39752881293711456, disc_loss = 0.07682138896454704
Trained batch 322 in epoch 13, gen_loss = 0.3976054001518816, disc_loss = 0.07726720849559542
Trained batch 323 in epoch 13, gen_loss = 0.3977756162668452, disc_loss = 0.0770820449034534
Trained batch 324 in epoch 13, gen_loss = 0.39754160853532644, disc_loss = 0.07703114649280905
Trained batch 325 in epoch 13, gen_loss = 0.3975458063779433, disc_loss = 0.07683289706838414
Trained batch 326 in epoch 13, gen_loss = 0.3977037493242036, disc_loss = 0.07661683881649639
Trained batch 327 in epoch 13, gen_loss = 0.3978155351630071, disc_loss = 0.07645379013393255
Trained batch 328 in epoch 13, gen_loss = 0.39769288752579035, disc_loss = 0.07656563632473304
Trained batch 329 in epoch 13, gen_loss = 0.3979088296492895, disc_loss = 0.07731648719389782
Trained batch 330 in epoch 13, gen_loss = 0.39783934010839894, disc_loss = 0.07726764315148404
Trained batch 331 in epoch 13, gen_loss = 0.39774786546287766, disc_loss = 0.07713323868306196
Trained batch 332 in epoch 13, gen_loss = 0.39762317015602067, disc_loss = 0.07708625140524394
Trained batch 333 in epoch 13, gen_loss = 0.39767386661675164, disc_loss = 0.07701096850765234
Trained batch 334 in epoch 13, gen_loss = 0.39757008481381545, disc_loss = 0.07681598249934057
Trained batch 335 in epoch 13, gen_loss = 0.3974534431028934, disc_loss = 0.07666418075816528
Trained batch 336 in epoch 13, gen_loss = 0.39759515159561654, disc_loss = 0.07658782910599818
Trained batch 337 in epoch 13, gen_loss = 0.3976125657205751, disc_loss = 0.0764773052003918
Trained batch 338 in epoch 13, gen_loss = 0.3974776949326901, disc_loss = 0.0763454331293878
Trained batch 339 in epoch 13, gen_loss = 0.3974692741737646, disc_loss = 0.07621481779907995
Trained batch 340 in epoch 13, gen_loss = 0.39769080840597404, disc_loss = 0.07604671939606628
Trained batch 341 in epoch 13, gen_loss = 0.39758270761074377, disc_loss = 0.075966958689084
Trained batch 342 in epoch 13, gen_loss = 0.39761548826020243, disc_loss = 0.07602270385494819
Trained batch 343 in epoch 13, gen_loss = 0.3973087294157161, disc_loss = 0.07653712055938275
Trained batch 344 in epoch 13, gen_loss = 0.39745755152425905, disc_loss = 0.07639341377315746
Trained batch 345 in epoch 13, gen_loss = 0.3973577133665195, disc_loss = 0.07699247717997329
Trained batch 346 in epoch 13, gen_loss = 0.3970828885132023, disc_loss = 0.07741908614472715
Trained batch 347 in epoch 13, gen_loss = 0.39707273972788076, disc_loss = 0.07739491316746792
Trained batch 348 in epoch 13, gen_loss = 0.39712342124613786, disc_loss = 0.07747878863564278
Trained batch 349 in epoch 13, gen_loss = 0.3971122316803251, disc_loss = 0.07737889414653182
Trained batch 350 in epoch 13, gen_loss = 0.39692329630213247, disc_loss = 0.07731357134316127
Trained batch 351 in epoch 13, gen_loss = 0.3969914907250892, disc_loss = 0.07716001208014363
Trained batch 352 in epoch 13, gen_loss = 0.39715633826282815, disc_loss = 0.07702267053603029
Trained batch 353 in epoch 13, gen_loss = 0.3969819292341922, disc_loss = 0.07690080860103507
Trained batch 354 in epoch 13, gen_loss = 0.397043053952741, disc_loss = 0.07680123709404553
Trained batch 355 in epoch 13, gen_loss = 0.39686540874202597, disc_loss = 0.07689182412957124
Trained batch 356 in epoch 13, gen_loss = 0.3969379646771428, disc_loss = 0.07790645634291135
Trained batch 357 in epoch 13, gen_loss = 0.3969266241489176, disc_loss = 0.07817268653320117
Trained batch 358 in epoch 13, gen_loss = 0.39680829079702373, disc_loss = 0.07836527502667522
Trained batch 359 in epoch 13, gen_loss = 0.3965930896500746, disc_loss = 0.07846613065598326
Trained batch 360 in epoch 13, gen_loss = 0.39638181596251404, disc_loss = 0.07846322338615346
Trained batch 361 in epoch 13, gen_loss = 0.39623385659568217, disc_loss = 0.07841472231746954
Trained batch 362 in epoch 13, gen_loss = 0.3962329326418149, disc_loss = 0.07829264679425922
Trained batch 363 in epoch 13, gen_loss = 0.3961356120122658, disc_loss = 0.07817427836266438
Trained batch 364 in epoch 13, gen_loss = 0.3960022109828583, disc_loss = 0.07815104010323547
Trained batch 365 in epoch 13, gen_loss = 0.39588457060967636, disc_loss = 0.07802219926812202
Trained batch 366 in epoch 13, gen_loss = 0.3956839508841408, disc_loss = 0.07805374191378621
Trained batch 367 in epoch 13, gen_loss = 0.395778923254946, disc_loss = 0.07868120689501824
Trained batch 368 in epoch 13, gen_loss = 0.3955926800646433, disc_loss = 0.07862594276212337
Trained batch 369 in epoch 13, gen_loss = 0.3954765741889541, disc_loss = 0.07874917751178145
Trained batch 370 in epoch 13, gen_loss = 0.3954669164036805, disc_loss = 0.07916945617425072
Trained batch 371 in epoch 13, gen_loss = 0.39550291738843407, disc_loss = 0.0790723585748985
Trained batch 372 in epoch 13, gen_loss = 0.39539007662768016, disc_loss = 0.07903210717645391
Trained batch 373 in epoch 13, gen_loss = 0.3952082248135684, disc_loss = 0.07901527866830721
Trained batch 374 in epoch 13, gen_loss = 0.39506842215855914, disc_loss = 0.07909342087060213
Trained batch 375 in epoch 13, gen_loss = 0.39535997950650276, disc_loss = 0.07902191723746425
Trained batch 376 in epoch 13, gen_loss = 0.39536312894416425, disc_loss = 0.07888010365330177
Trained batch 377 in epoch 13, gen_loss = 0.3953932690084296, disc_loss = 0.07880246867647483
Trained batch 378 in epoch 13, gen_loss = 0.39537847254395797, disc_loss = 0.07867581247644484
Trained batch 379 in epoch 13, gen_loss = 0.3954831192367955, disc_loss = 0.07856943138482932
Trained batch 380 in epoch 13, gen_loss = 0.39535592367329936, disc_loss = 0.07844483313392701
Trained batch 381 in epoch 13, gen_loss = 0.3956388421551719, disc_loss = 0.07835347689834486
Trained batch 382 in epoch 13, gen_loss = 0.39540137370012446, disc_loss = 0.07818876123712362
Trained batch 383 in epoch 13, gen_loss = 0.39545182045549154, disc_loss = 0.07807962578469112
Trained batch 384 in epoch 13, gen_loss = 0.3953517941685466, disc_loss = 0.07843260712341055
Trained batch 385 in epoch 13, gen_loss = 0.39528705944051395, disc_loss = 0.0791374587169197
Trained batch 386 in epoch 13, gen_loss = 0.3956084188256769, disc_loss = 0.07918217406158146
Trained batch 387 in epoch 13, gen_loss = 0.3957251003108074, disc_loss = 0.07915841221098893
Trained batch 388 in epoch 13, gen_loss = 0.3954576699010511, disc_loss = 0.0794005494488159
Trained batch 389 in epoch 13, gen_loss = 0.3955832375929906, disc_loss = 0.07927913131335607
Trained batch 390 in epoch 13, gen_loss = 0.395632646044197, disc_loss = 0.07910943302847541
Trained batch 391 in epoch 13, gen_loss = 0.3955730228703849, disc_loss = 0.07907908682578377
Trained batch 392 in epoch 13, gen_loss = 0.3955323442096322, disc_loss = 0.07920942437519857
Trained batch 393 in epoch 13, gen_loss = 0.3955997736169602, disc_loss = 0.07943228464857273
Trained batch 394 in epoch 13, gen_loss = 0.39569385014002834, disc_loss = 0.07933006014061879
Trained batch 395 in epoch 13, gen_loss = 0.3956467920180523, disc_loss = 0.07946856488294975
Trained batch 396 in epoch 13, gen_loss = 0.3956746678208224, disc_loss = 0.07971878960653576
Trained batch 397 in epoch 13, gen_loss = 0.3955296969892991, disc_loss = 0.07956890102906443
Trained batch 398 in epoch 13, gen_loss = 0.39573471065153154, disc_loss = 0.0794460738362525
Trained batch 399 in epoch 13, gen_loss = 0.3954071445018053, disc_loss = 0.07964303232729435
Trained batch 400 in epoch 13, gen_loss = 0.3953884395577961, disc_loss = 0.07955332817579445
Trained batch 401 in epoch 13, gen_loss = 0.39546697523759966, disc_loss = 0.0794392539679411
Trained batch 402 in epoch 13, gen_loss = 0.3953996444162601, disc_loss = 0.07942901156084708
Trained batch 403 in epoch 13, gen_loss = 0.3954122497303651, disc_loss = 0.07932177918160906
Trained batch 404 in epoch 13, gen_loss = 0.39535581719728163, disc_loss = 0.07937537258789863
Trained batch 405 in epoch 13, gen_loss = 0.39554760439936165, disc_loss = 0.07944812089792026
Trained batch 406 in epoch 13, gen_loss = 0.39535223097707484, disc_loss = 0.07942486395121207
Trained batch 407 in epoch 13, gen_loss = 0.39508315285339074, disc_loss = 0.07970100067848084
Trained batch 408 in epoch 13, gen_loss = 0.3954310001108641, disc_loss = 0.0798442711311331
Trained batch 409 in epoch 13, gen_loss = 0.3954107484439524, disc_loss = 0.07985213507966298
Trained batch 410 in epoch 13, gen_loss = 0.3955118553916903, disc_loss = 0.0797367070024321
Trained batch 411 in epoch 13, gen_loss = 0.39546245618641956, disc_loss = 0.07971371173207621
Trained batch 412 in epoch 13, gen_loss = 0.3954569255757274, disc_loss = 0.07956595941205434
Trained batch 413 in epoch 13, gen_loss = 0.3954821215303624, disc_loss = 0.07943278836347342
Trained batch 414 in epoch 13, gen_loss = 0.39544772196965045, disc_loss = 0.07941267897027085
Trained batch 415 in epoch 13, gen_loss = 0.3954357478337792, disc_loss = 0.07956218380086984
Trained batch 416 in epoch 13, gen_loss = 0.3956959285467363, disc_loss = 0.0796433217037353
Trained batch 417 in epoch 13, gen_loss = 0.39546569490261624, disc_loss = 0.0796482814074846
Trained batch 418 in epoch 13, gen_loss = 0.395286957090965, disc_loss = 0.07973139716183371
Trained batch 419 in epoch 13, gen_loss = 0.39530064946129206, disc_loss = 0.07961193319143993
Trained batch 420 in epoch 13, gen_loss = 0.3952689781041723, disc_loss = 0.07953550247586114
Trained batch 421 in epoch 13, gen_loss = 0.39518516231769635, disc_loss = 0.07965808545826313
Trained batch 422 in epoch 13, gen_loss = 0.3952946715743829, disc_loss = 0.07958497515225664
Trained batch 423 in epoch 13, gen_loss = 0.395474817955269, disc_loss = 0.07947295558428005
Trained batch 424 in epoch 13, gen_loss = 0.395504750995075, disc_loss = 0.07933583333650056
Trained batch 425 in epoch 13, gen_loss = 0.39547571127123676, disc_loss = 0.07920305859822203
Trained batch 426 in epoch 13, gen_loss = 0.3955274830796959, disc_loss = 0.07906275353802311
Trained batch 427 in epoch 13, gen_loss = 0.3956036929772279, disc_loss = 0.0789344275248385
Trained batch 428 in epoch 13, gen_loss = 0.3956098196667669, disc_loss = 0.07896268525809953
Trained batch 429 in epoch 13, gen_loss = 0.395378249051959, disc_loss = 0.07920795722409736
Trained batch 430 in epoch 13, gen_loss = 0.39544599197303615, disc_loss = 0.07922553945237688
Trained batch 431 in epoch 13, gen_loss = 0.39568524400669114, disc_loss = 0.07909833615714754
Trained batch 432 in epoch 13, gen_loss = 0.39560839334206, disc_loss = 0.07902914184999521
Trained batch 433 in epoch 13, gen_loss = 0.3956494930153069, disc_loss = 0.07897607691174004
Trained batch 434 in epoch 13, gen_loss = 0.39559571016793965, disc_loss = 0.07888778244284378
Trained batch 435 in epoch 13, gen_loss = 0.3955914932516737, disc_loss = 0.07874171311727836
Trained batch 436 in epoch 13, gen_loss = 0.39571799013925635, disc_loss = 0.07871930247270748
Trained batch 437 in epoch 13, gen_loss = 0.3954756727365598, disc_loss = 0.07887886056982696
Trained batch 438 in epoch 13, gen_loss = 0.3955569711252877, disc_loss = 0.0788121136957631
Trained batch 439 in epoch 13, gen_loss = 0.395783618228002, disc_loss = 0.07870132200292904
Trained batch 440 in epoch 13, gen_loss = 0.39570522247528545, disc_loss = 0.07859869710383029
Trained batch 441 in epoch 13, gen_loss = 0.3956877554164213, disc_loss = 0.07845032645170302
Trained batch 442 in epoch 13, gen_loss = 0.3958600019493706, disc_loss = 0.07830822986443411
Trained batch 443 in epoch 13, gen_loss = 0.3960771327083175, disc_loss = 0.0781786212810894
Trained batch 444 in epoch 13, gen_loss = 0.3960798471831204, disc_loss = 0.07810329306619555
Trained batch 445 in epoch 13, gen_loss = 0.3959970301175866, disc_loss = 0.07800711918363322
Trained batch 446 in epoch 13, gen_loss = 0.39576184036214346, disc_loss = 0.07812014771979593
Trained batch 447 in epoch 13, gen_loss = 0.39601146609389354, disc_loss = 0.07797757628889355
Trained batch 448 in epoch 13, gen_loss = 0.3961758206708394, disc_loss = 0.07786738065658406
Trained batch 449 in epoch 13, gen_loss = 0.3961158788866467, disc_loss = 0.07773788391302029
Trained batch 450 in epoch 13, gen_loss = 0.3959774562630579, disc_loss = 0.07803210803202278
Trained batch 451 in epoch 13, gen_loss = 0.3960776139149624, disc_loss = 0.07861781227855688
Trained batch 452 in epoch 13, gen_loss = 0.3960006475843341, disc_loss = 0.07879236247184919
Trained batch 453 in epoch 13, gen_loss = 0.3957963904882843, disc_loss = 0.07907957369092408
Trained batch 454 in epoch 13, gen_loss = 0.39583942182771453, disc_loss = 0.07910505166829943
Trained batch 455 in epoch 13, gen_loss = 0.39589972101282656, disc_loss = 0.0790490068764867
Trained batch 456 in epoch 13, gen_loss = 0.39579231629486417, disc_loss = 0.07898289219963342
Trained batch 457 in epoch 13, gen_loss = 0.3957164969506743, disc_loss = 0.07892847505670578
Trained batch 458 in epoch 13, gen_loss = 0.39556974659558214, disc_loss = 0.07886262176749104
Testing Epoch 13
Training Epoch 14
Trained batch 0 in epoch 14, gen_loss = 0.3507744073867798, disc_loss = 0.1842690110206604
Trained batch 1 in epoch 14, gen_loss = 0.384294256567955, disc_loss = 0.12814944237470627
Trained batch 2 in epoch 14, gen_loss = 0.4145134786764781, disc_loss = 0.09280870916942756
Trained batch 3 in epoch 14, gen_loss = 0.40079207718372345, disc_loss = 0.07681747898459435
Trained batch 4 in epoch 14, gen_loss = 0.3932182967662811, disc_loss = 0.07147956117987633
Trained batch 5 in epoch 14, gen_loss = 0.3839555084705353, disc_loss = 0.0919203528513511
Trained batch 6 in epoch 14, gen_loss = 0.3940913677215576, disc_loss = 0.09432654455304146
Trained batch 7 in epoch 14, gen_loss = 0.39872416853904724, disc_loss = 0.08427890040911734
Trained batch 8 in epoch 14, gen_loss = 0.3941490285926395, disc_loss = 0.08095924701127741
Trained batch 9 in epoch 14, gen_loss = 0.39183622896671294, disc_loss = 0.07797248158603906
Trained batch 10 in epoch 14, gen_loss = 0.39517229253595526, disc_loss = 0.07280868850648403
Trained batch 11 in epoch 14, gen_loss = 0.38854607194662094, disc_loss = 0.07174373433614771
Trained batch 12 in epoch 14, gen_loss = 0.39025351175895107, disc_loss = 0.06824899536485855
Trained batch 13 in epoch 14, gen_loss = 0.39376939620290485, disc_loss = 0.06728990069989647
Trained batch 14 in epoch 14, gen_loss = 0.39051975806554157, disc_loss = 0.06354945134371519
Trained batch 15 in epoch 14, gen_loss = 0.38494058325886726, disc_loss = 0.06781130406307057
Trained batch 16 in epoch 14, gen_loss = 0.3864116458331837, disc_loss = 0.08082077898742522
Trained batch 17 in epoch 14, gen_loss = 0.38394025133715737, disc_loss = 0.0855986271570954
Trained batch 18 in epoch 14, gen_loss = 0.38297625435026067, disc_loss = 0.08210651620634292
Trained batch 19 in epoch 14, gen_loss = 0.3840283900499344, disc_loss = 0.07843332965858281
Trained batch 20 in epoch 14, gen_loss = 0.3862462980406625, disc_loss = 0.0763091009021515
Trained batch 21 in epoch 14, gen_loss = 0.38552893562750384, disc_loss = 0.07467894819141789
Trained batch 22 in epoch 14, gen_loss = 0.3844582166360772, disc_loss = 0.07278221177504114
Trained batch 23 in epoch 14, gen_loss = 0.38301357130209607, disc_loss = 0.0719139816161866
Trained batch 24 in epoch 14, gen_loss = 0.38403638362884523, disc_loss = 0.07003215607255697
Trained batch 25 in epoch 14, gen_loss = 0.3857574245104423, disc_loss = 0.06835429753678349
Trained batch 26 in epoch 14, gen_loss = 0.3895551805143003, disc_loss = 0.06806811107391561
Trained batch 27 in epoch 14, gen_loss = 0.38890071851866587, disc_loss = 0.06841863741699074
Trained batch 28 in epoch 14, gen_loss = 0.3888925498929517, disc_loss = 0.06851135653539978
Trained batch 29 in epoch 14, gen_loss = 0.3890571137269338, disc_loss = 0.06713144664342205
Trained batch 30 in epoch 14, gen_loss = 0.3926686413826481, disc_loss = 0.06552520739815888
Trained batch 31 in epoch 14, gen_loss = 0.3930418435484171, disc_loss = 0.06445670415996574
Trained batch 32 in epoch 14, gen_loss = 0.39129647161021375, disc_loss = 0.0642389263111082
Trained batch 33 in epoch 14, gen_loss = 0.3904414045460084, disc_loss = 0.06411095563431873
Trained batch 34 in epoch 14, gen_loss = 0.38945045045443943, disc_loss = 0.06379420190517392
Trained batch 35 in epoch 14, gen_loss = 0.38943953646553886, disc_loss = 0.0625765593463762
Trained batch 36 in epoch 14, gen_loss = 0.3898159837400591, disc_loss = 0.06171108049818793
Trained batch 37 in epoch 14, gen_loss = 0.3894266603808654, disc_loss = 0.0625768507046527
Trained batch 38 in epoch 14, gen_loss = 0.38998394440381956, disc_loss = 0.06442195972284445
Trained batch 39 in epoch 14, gen_loss = 0.3901412978768349, disc_loss = 0.06346475931350141
Trained batch 40 in epoch 14, gen_loss = 0.388290706204205, disc_loss = 0.07030209101645685
Trained batch 41 in epoch 14, gen_loss = 0.38866763029779705, disc_loss = 0.0704351500608027
Trained batch 42 in epoch 14, gen_loss = 0.3871389225471851, disc_loss = 0.07019853905969581
Trained batch 43 in epoch 14, gen_loss = 0.38705297627232294, disc_loss = 0.06936344735070386
Trained batch 44 in epoch 14, gen_loss = 0.38864646289083693, disc_loss = 0.06825768370181322
Trained batch 45 in epoch 14, gen_loss = 0.3875445069178291, disc_loss = 0.06918261024048147
Trained batch 46 in epoch 14, gen_loss = 0.3887053715421798, disc_loss = 0.07139884777604899
Trained batch 47 in epoch 14, gen_loss = 0.38818567246198654, disc_loss = 0.0710298863123171
Trained batch 48 in epoch 14, gen_loss = 0.3884891934540807, disc_loss = 0.0702826709353498
Trained batch 49 in epoch 14, gen_loss = 0.38653291523456573, disc_loss = 0.0694647659547627
Trained batch 50 in epoch 14, gen_loss = 0.3854788775537528, disc_loss = 0.06974619175946596
Trained batch 51 in epoch 14, gen_loss = 0.38532742399435777, disc_loss = 0.07359380749627374
Trained batch 52 in epoch 14, gen_loss = 0.38468938391163665, disc_loss = 0.07590195411851383
Trained batch 53 in epoch 14, gen_loss = 0.38413081290545287, disc_loss = 0.0752795326385509
Trained batch 54 in epoch 14, gen_loss = 0.383675171028484, disc_loss = 0.07462084098634394
Trained batch 55 in epoch 14, gen_loss = 0.38377793984753744, disc_loss = 0.07402149549618896
Trained batch 56 in epoch 14, gen_loss = 0.38362532278947664, disc_loss = 0.07334901374486978
Trained batch 57 in epoch 14, gen_loss = 0.38382898065550575, disc_loss = 0.07262772419650493
Trained batch 58 in epoch 14, gen_loss = 0.38457181645651994, disc_loss = 0.07218655029911611
Trained batch 59 in epoch 14, gen_loss = 0.384805599351724, disc_loss = 0.07193005663963656
Trained batch 60 in epoch 14, gen_loss = 0.38537873156735153, disc_loss = 0.07244054687621652
Trained batch 61 in epoch 14, gen_loss = 0.3860639501963892, disc_loss = 0.07255600256124331
Trained batch 62 in epoch 14, gen_loss = 0.38574358773609946, disc_loss = 0.07262022918947632
Trained batch 63 in epoch 14, gen_loss = 0.3864164240658283, disc_loss = 0.07236937935522292
Trained batch 64 in epoch 14, gen_loss = 0.38675048076189483, disc_loss = 0.07160142810585407
Trained batch 65 in epoch 14, gen_loss = 0.38588491353121673, disc_loss = 0.07179289448046774
Trained batch 66 in epoch 14, gen_loss = 0.3857687533791386, disc_loss = 0.07594138763344555
Trained batch 67 in epoch 14, gen_loss = 0.3870382449206184, disc_loss = 0.0758432662799297
Trained batch 68 in epoch 14, gen_loss = 0.38665510865225305, disc_loss = 0.07621880168554143
Trained batch 69 in epoch 14, gen_loss = 0.3865538571562086, disc_loss = 0.07566644912585616
Trained batch 70 in epoch 14, gen_loss = 0.38717715505143285, disc_loss = 0.0749037705597953
Trained batch 71 in epoch 14, gen_loss = 0.38703973922464585, disc_loss = 0.07446673430968076
Trained batch 72 in epoch 14, gen_loss = 0.38610823513710335, disc_loss = 0.07357513188856514
Trained batch 73 in epoch 14, gen_loss = 0.38674418507395564, disc_loss = 0.07311231802796593
Trained batch 74 in epoch 14, gen_loss = 0.38626315832138064, disc_loss = 0.0729378312205275
Trained batch 75 in epoch 14, gen_loss = 0.3868089455522989, disc_loss = 0.07210661967186943
Trained batch 76 in epoch 14, gen_loss = 0.3867658783089031, disc_loss = 0.07134643380905127
Trained batch 77 in epoch 14, gen_loss = 0.3873115388246683, disc_loss = 0.07059256290682615
Trained batch 78 in epoch 14, gen_loss = 0.3882189193103887, disc_loss = 0.07012145204728917
Trained batch 79 in epoch 14, gen_loss = 0.3876555599272251, disc_loss = 0.07055983825121075
Trained batch 80 in epoch 14, gen_loss = 0.3884772025508645, disc_loss = 0.07037798395771304
Trained batch 81 in epoch 14, gen_loss = 0.38876219566275433, disc_loss = 0.0704081069178334
Trained batch 82 in epoch 14, gen_loss = 0.38838280073131426, disc_loss = 0.07028665463159602
Trained batch 83 in epoch 14, gen_loss = 0.3880352111799376, disc_loss = 0.06990477941664201
Trained batch 84 in epoch 14, gen_loss = 0.38845410311923306, disc_loss = 0.06921101429444902
Trained batch 85 in epoch 14, gen_loss = 0.38845275342464447, disc_loss = 0.06855325603337828
Trained batch 86 in epoch 14, gen_loss = 0.38804131403736686, disc_loss = 0.06805781929100725
Trained batch 87 in epoch 14, gen_loss = 0.39025772566145117, disc_loss = 0.06820413879838517
Trained batch 88 in epoch 14, gen_loss = 0.3897829722152667, disc_loss = 0.06810211719882288
Trained batch 89 in epoch 14, gen_loss = 0.3899931619564692, disc_loss = 0.06748694606746236
Trained batch 90 in epoch 14, gen_loss = 0.39070436358451843, disc_loss = 0.06906025827053812
Trained batch 91 in epoch 14, gen_loss = 0.39002266299465427, disc_loss = 0.07036953576354553
Trained batch 92 in epoch 14, gen_loss = 0.3900939363946197, disc_loss = 0.0723057145212767
Trained batch 93 in epoch 14, gen_loss = 0.38990980069688025, disc_loss = 0.07219549053487309
Trained batch 94 in epoch 14, gen_loss = 0.3897575497627258, disc_loss = 0.07170219941947022
Trained batch 95 in epoch 14, gen_loss = 0.38964662545671064, disc_loss = 0.07116754367598332
Trained batch 96 in epoch 14, gen_loss = 0.3895021637075955, disc_loss = 0.07071122570328184
Trained batch 97 in epoch 14, gen_loss = 0.3888867911027402, disc_loss = 0.07026011875963636
Trained batch 98 in epoch 14, gen_loss = 0.3891354961828752, disc_loss = 0.07028645690003729
Trained batch 99 in epoch 14, gen_loss = 0.3887002542614937, disc_loss = 0.07051224908791483
Trained batch 100 in epoch 14, gen_loss = 0.388772456362696, disc_loss = 0.07027595057751578
Trained batch 101 in epoch 14, gen_loss = 0.3897448807370429, disc_loss = 0.06995502190080051
Trained batch 102 in epoch 14, gen_loss = 0.39007813201367275, disc_loss = 0.06994804974139027
Trained batch 103 in epoch 14, gen_loss = 0.39091418511592424, disc_loss = 0.07000708195846528
Trained batch 104 in epoch 14, gen_loss = 0.390840596812112, disc_loss = 0.0698408066782923
Trained batch 105 in epoch 14, gen_loss = 0.3917506354035072, disc_loss = 0.0692579749672902
Trained batch 106 in epoch 14, gen_loss = 0.3915702491720146, disc_loss = 0.06877767072694603
Trained batch 107 in epoch 14, gen_loss = 0.3924554153173058, disc_loss = 0.06874492965397183
Trained batch 108 in epoch 14, gen_loss = 0.39145673497007527, disc_loss = 0.07045592334326528
Trained batch 109 in epoch 14, gen_loss = 0.3917382145469839, disc_loss = 0.07199960060586984
Trained batch 110 in epoch 14, gen_loss = 0.391216497968983, disc_loss = 0.07207714814088635
Trained batch 111 in epoch 14, gen_loss = 0.3912261492971863, disc_loss = 0.07158957081680585
Trained batch 112 in epoch 14, gen_loss = 0.39152451505703206, disc_loss = 0.07149977644954898
Trained batch 113 in epoch 14, gen_loss = 0.3911740897517455, disc_loss = 0.071387709878189
Trained batch 114 in epoch 14, gen_loss = 0.39126335278801294, disc_loss = 0.07086972011982098
Trained batch 115 in epoch 14, gen_loss = 0.3911497700830986, disc_loss = 0.07040882766535826
Trained batch 116 in epoch 14, gen_loss = 0.39092023785297686, disc_loss = 0.07000191329031163
Trained batch 117 in epoch 14, gen_loss = 0.3914112117836031, disc_loss = 0.07048925969718119
Trained batch 118 in epoch 14, gen_loss = 0.39208448609384167, disc_loss = 0.07065760110262312
Trained batch 119 in epoch 14, gen_loss = 0.3926675202945868, disc_loss = 0.07016714587807656
Trained batch 120 in epoch 14, gen_loss = 0.39217118857320676, disc_loss = 0.07093687897378748
Trained batch 121 in epoch 14, gen_loss = 0.39338240491562204, disc_loss = 0.07102233623383475
Trained batch 122 in epoch 14, gen_loss = 0.3937122196685977, disc_loss = 0.07049907073832867
Trained batch 123 in epoch 14, gen_loss = 0.393979181445414, disc_loss = 0.07007618932684342
Trained batch 124 in epoch 14, gen_loss = 0.39391249465942385, disc_loss = 0.0697300636395812
Trained batch 125 in epoch 14, gen_loss = 0.3937666688173536, disc_loss = 0.06945142323624283
Trained batch 126 in epoch 14, gen_loss = 0.39439886761462595, disc_loss = 0.06909814787163275
Trained batch 127 in epoch 14, gen_loss = 0.3945873707998544, disc_loss = 0.06881750423781341
Trained batch 128 in epoch 14, gen_loss = 0.3945827675882236, disc_loss = 0.06858122602191775
Trained batch 129 in epoch 14, gen_loss = 0.3939700140402867, disc_loss = 0.06984845571076641
Trained batch 130 in epoch 14, gen_loss = 0.3945335563812547, disc_loss = 0.07145325838808568
Trained batch 131 in epoch 14, gen_loss = 0.39516401787598926, disc_loss = 0.0709922311150215
Trained batch 132 in epoch 14, gen_loss = 0.3954250344208309, disc_loss = 0.07066125296672485
Trained batch 133 in epoch 14, gen_loss = 0.3955515907771552, disc_loss = 0.07030396352508175
Trained batch 134 in epoch 14, gen_loss = 0.39537422590785554, disc_loss = 0.06994831784179917
Trained batch 135 in epoch 14, gen_loss = 0.395102868842728, disc_loss = 0.06955045831444509
Trained batch 136 in epoch 14, gen_loss = 0.39451900951183627, disc_loss = 0.06998017764765851
Trained batch 137 in epoch 14, gen_loss = 0.3943363233752873, disc_loss = 0.06993634871922541
Trained batch 138 in epoch 14, gen_loss = 0.3944944900145634, disc_loss = 0.07083296070960786
Trained batch 139 in epoch 14, gen_loss = 0.394298822752067, disc_loss = 0.07077067896191563
Trained batch 140 in epoch 14, gen_loss = 0.3939999897852012, disc_loss = 0.07047394243009547
Trained batch 141 in epoch 14, gen_loss = 0.3943337556761755, disc_loss = 0.0701019624248147
Trained batch 142 in epoch 14, gen_loss = 0.39451628444078085, disc_loss = 0.06991272689318741
Trained batch 143 in epoch 14, gen_loss = 0.39404553961422706, disc_loss = 0.06978171014796114
Trained batch 144 in epoch 14, gen_loss = 0.3940353599087945, disc_loss = 0.069655356491948
Trained batch 145 in epoch 14, gen_loss = 0.39414063136871547, disc_loss = 0.06939972004508727
Trained batch 146 in epoch 14, gen_loss = 0.3939538204751047, disc_loss = 0.06986150466108403
Trained batch 147 in epoch 14, gen_loss = 0.3935007338185568, disc_loss = 0.07128846842946636
Trained batch 148 in epoch 14, gen_loss = 0.3936693130323551, disc_loss = 0.07165721365119387
Trained batch 149 in epoch 14, gen_loss = 0.39381167173385623, disc_loss = 0.07187728465845188
Trained batch 150 in epoch 14, gen_loss = 0.393804641354163, disc_loss = 0.0730645094214883
Trained batch 151 in epoch 14, gen_loss = 0.3941125830537395, disc_loss = 0.07316849161380608
Trained batch 152 in epoch 14, gen_loss = 0.39383014530138255, disc_loss = 0.07403381506066306
Trained batch 153 in epoch 14, gen_loss = 0.39411098713224585, disc_loss = 0.07513237324869865
Trained batch 154 in epoch 14, gen_loss = 0.39365325108651195, disc_loss = 0.07536883739934813
Trained batch 155 in epoch 14, gen_loss = 0.39363089280250746, disc_loss = 0.07535339549231605
Trained batch 156 in epoch 14, gen_loss = 0.3941148109496779, disc_loss = 0.07511844608197167
Trained batch 157 in epoch 14, gen_loss = 0.3941858963498586, disc_loss = 0.07506987248559165
Trained batch 158 in epoch 14, gen_loss = 0.39454979641632465, disc_loss = 0.07483015878348605
Trained batch 159 in epoch 14, gen_loss = 0.394241101667285, disc_loss = 0.07462654173141345
Trained batch 160 in epoch 14, gen_loss = 0.3940989956352281, disc_loss = 0.07449538676033479
Trained batch 161 in epoch 14, gen_loss = 0.3938737647768892, disc_loss = 0.07529942225664854
Trained batch 162 in epoch 14, gen_loss = 0.39449306572873166, disc_loss = 0.07591421283964365
Trained batch 163 in epoch 14, gen_loss = 0.39472787972630524, disc_loss = 0.0756036271568297
Trained batch 164 in epoch 14, gen_loss = 0.3947211149967078, disc_loss = 0.07543533632926869
Trained batch 165 in epoch 14, gen_loss = 0.3945695362895368, disc_loss = 0.07522914833557534
Trained batch 166 in epoch 14, gen_loss = 0.39473776867289745, disc_loss = 0.0749119779061593
Trained batch 167 in epoch 14, gen_loss = 0.39524052380805924, disc_loss = 0.0746051810814866
Trained batch 168 in epoch 14, gen_loss = 0.3952799270138938, disc_loss = 0.07498527937651386
Trained batch 169 in epoch 14, gen_loss = 0.39590562546954433, disc_loss = 0.07591083424494546
Trained batch 170 in epoch 14, gen_loss = 0.39637179890571284, disc_loss = 0.07565757046230355
Trained batch 171 in epoch 14, gen_loss = 0.3963467009192289, disc_loss = 0.07546777906286162
Trained batch 172 in epoch 14, gen_loss = 0.39633823026811454, disc_loss = 0.07510407190403842
Trained batch 173 in epoch 14, gen_loss = 0.39666034743703643, disc_loss = 0.07482413449806385
Trained batch 174 in epoch 14, gen_loss = 0.39671711683273314, disc_loss = 0.07454136253467628
Trained batch 175 in epoch 14, gen_loss = 0.3969963396137411, disc_loss = 0.07428056766829369
Trained batch 176 in epoch 14, gen_loss = 0.39726280324203145, disc_loss = 0.07412101068444509
Trained batch 177 in epoch 14, gen_loss = 0.39744267219238066, disc_loss = 0.07425799510661471
Trained batch 178 in epoch 14, gen_loss = 0.3974329810901727, disc_loss = 0.07457400047787408
Trained batch 179 in epoch 14, gen_loss = 0.397737206849787, disc_loss = 0.07450833971508675
Trained batch 180 in epoch 14, gen_loss = 0.39781190018627527, disc_loss = 0.07421238611333937
Trained batch 181 in epoch 14, gen_loss = 0.39772801592454804, disc_loss = 0.07389588285605986
Trained batch 182 in epoch 14, gen_loss = 0.3978843724792772, disc_loss = 0.07376947726219729
Trained batch 183 in epoch 14, gen_loss = 0.397807652697615, disc_loss = 0.07383237690057444
Trained batch 184 in epoch 14, gen_loss = 0.39824422050166775, disc_loss = 0.07378037628289816
Trained batch 185 in epoch 14, gen_loss = 0.3984369207774439, disc_loss = 0.07383087798151919
Trained batch 186 in epoch 14, gen_loss = 0.3982505350508154, disc_loss = 0.07363030820447493
Trained batch 187 in epoch 14, gen_loss = 0.39845371167076393, disc_loss = 0.0733236100108541
Trained batch 188 in epoch 14, gen_loss = 0.39828416358226193, disc_loss = 0.07309092014594368
Trained batch 189 in epoch 14, gen_loss = 0.3986760614733947, disc_loss = 0.07277381322591712
Trained batch 190 in epoch 14, gen_loss = 0.3988213081946548, disc_loss = 0.07249877116696529
Trained batch 191 in epoch 14, gen_loss = 0.39877959185590345, disc_loss = 0.07220611825565963
Trained batch 192 in epoch 14, gen_loss = 0.39858031257446563, disc_loss = 0.07199260783068102
Trained batch 193 in epoch 14, gen_loss = 0.3982013063025229, disc_loss = 0.0719172231152116
Trained batch 194 in epoch 14, gen_loss = 0.3987316771959647, disc_loss = 0.07189401408705191
Trained batch 195 in epoch 14, gen_loss = 0.39887763270918203, disc_loss = 0.07159226761693704
Trained batch 196 in epoch 14, gen_loss = 0.39872177648665336, disc_loss = 0.07129100121576623
Trained batch 197 in epoch 14, gen_loss = 0.398732528090477, disc_loss = 0.0710029548193996
Trained batch 198 in epoch 14, gen_loss = 0.39843393061029253, disc_loss = 0.07070312765543935
Trained batch 199 in epoch 14, gen_loss = 0.3990047800540924, disc_loss = 0.07058314035180956
Trained batch 200 in epoch 14, gen_loss = 0.39897782099780754, disc_loss = 0.07051664817411063
Trained batch 201 in epoch 14, gen_loss = 0.3989152638333859, disc_loss = 0.07040225727815587
Trained batch 202 in epoch 14, gen_loss = 0.39905672825028743, disc_loss = 0.07011971356154516
Trained batch 203 in epoch 14, gen_loss = 0.39899472716976614, disc_loss = 0.0698324802340757
Trained batch 204 in epoch 14, gen_loss = 0.3989072764792093, disc_loss = 0.0699445710631042
Trained batch 205 in epoch 14, gen_loss = 0.39873720083421876, disc_loss = 0.06981662805056543
Trained batch 206 in epoch 14, gen_loss = 0.3988532315993655, disc_loss = 0.06955657314041243
Trained batch 207 in epoch 14, gen_loss = 0.39851465076208115, disc_loss = 0.06944899561438853
Trained batch 208 in epoch 14, gen_loss = 0.39888673350571446, disc_loss = 0.06997519588481153
Trained batch 209 in epoch 14, gen_loss = 0.3982530825194858, disc_loss = 0.07008796486382683
Trained batch 210 in epoch 14, gen_loss = 0.398367453101687, disc_loss = 0.06994726148244187
Trained batch 211 in epoch 14, gen_loss = 0.3988600534931669, disc_loss = 0.06970928215316304
Trained batch 212 in epoch 14, gen_loss = 0.398891439880004, disc_loss = 0.06956213451659596
Trained batch 213 in epoch 14, gen_loss = 0.39900630169382717, disc_loss = 0.06932830501121477
Trained batch 214 in epoch 14, gen_loss = 0.3987714067448017, disc_loss = 0.06915559978765803
Trained batch 215 in epoch 14, gen_loss = 0.39885890387274603, disc_loss = 0.06930764966765074
Trained batch 216 in epoch 14, gen_loss = 0.39870470157966087, disc_loss = 0.07079045710149585
Trained batch 217 in epoch 14, gen_loss = 0.3988737022384591, disc_loss = 0.07083919215861947
Trained batch 218 in epoch 14, gen_loss = 0.39899338176261345, disc_loss = 0.07066018202822638
Trained batch 219 in epoch 14, gen_loss = 0.39922212944789365, disc_loss = 0.07042933089912615
Trained batch 220 in epoch 14, gen_loss = 0.39908490717680745, disc_loss = 0.07031276461782095
Trained batch 221 in epoch 14, gen_loss = 0.39926971844187725, disc_loss = 0.07022477659975758
Trained batch 222 in epoch 14, gen_loss = 0.39935583049940954, disc_loss = 0.070591615124568
Trained batch 223 in epoch 14, gen_loss = 0.39908474404364824, disc_loss = 0.07117412745304007
Trained batch 224 in epoch 14, gen_loss = 0.3994338814417521, disc_loss = 0.07112592820078134
Trained batch 225 in epoch 14, gen_loss = 0.39966863723455276, disc_loss = 0.07095540476864022
Trained batch 226 in epoch 14, gen_loss = 0.3995978463326257, disc_loss = 0.0707204726192329
Trained batch 227 in epoch 14, gen_loss = 0.39965202502514185, disc_loss = 0.07046788222189143
Trained batch 228 in epoch 14, gen_loss = 0.39948248733079067, disc_loss = 0.0702144975233091
Trained batch 229 in epoch 14, gen_loss = 0.3993031742780105, disc_loss = 0.07004320332780481
Trained batch 230 in epoch 14, gen_loss = 0.39921651051674056, disc_loss = 0.06996660713041887
Trained batch 231 in epoch 14, gen_loss = 0.3989713604337183, disc_loss = 0.06992827970454277
Trained batch 232 in epoch 14, gen_loss = 0.3987397872583037, disc_loss = 0.06969322912522907
Trained batch 233 in epoch 14, gen_loss = 0.3987794346534289, disc_loss = 0.0699867549089667
Trained batch 234 in epoch 14, gen_loss = 0.3987300193056147, disc_loss = 0.0703460923138451
Trained batch 235 in epoch 14, gen_loss = 0.39912649269326256, disc_loss = 0.0702104096427181
Trained batch 236 in epoch 14, gen_loss = 0.39937229108709826, disc_loss = 0.07041860496790349
Trained batch 237 in epoch 14, gen_loss = 0.3992791014308689, disc_loss = 0.0702983756635745
Trained batch 238 in epoch 14, gen_loss = 0.39915327497107217, disc_loss = 0.07025691035308848
Trained batch 239 in epoch 14, gen_loss = 0.3990597233176231, disc_loss = 0.07005680767664065
Trained batch 240 in epoch 14, gen_loss = 0.3994907914850227, disc_loss = 0.06986035731972748
Trained batch 241 in epoch 14, gen_loss = 0.39967751687715863, disc_loss = 0.06968935716065987
Trained batch 242 in epoch 14, gen_loss = 0.39961200388370716, disc_loss = 0.06985381234881809
Trained batch 243 in epoch 14, gen_loss = 0.39943877827437196, disc_loss = 0.07075919652143951
Trained batch 244 in epoch 14, gen_loss = 0.39954787188646745, disc_loss = 0.07068268810303843
Trained batch 245 in epoch 14, gen_loss = 0.399266210271091, disc_loss = 0.07071625421626296
Trained batch 246 in epoch 14, gen_loss = 0.39900458003827916, disc_loss = 0.07092977965227988
Trained batch 247 in epoch 14, gen_loss = 0.399457490011569, disc_loss = 0.07114926805239051
Trained batch 248 in epoch 14, gen_loss = 0.3999021426740899, disc_loss = 0.0709007969687143
Trained batch 249 in epoch 14, gen_loss = 0.3997705068588257, disc_loss = 0.07073405952006578
Trained batch 250 in epoch 14, gen_loss = 0.39957834038126516, disc_loss = 0.07056206913731725
Trained batch 251 in epoch 14, gen_loss = 0.39930245611402726, disc_loss = 0.07052564349705501
Trained batch 252 in epoch 14, gen_loss = 0.39935561319584906, disc_loss = 0.07044624421642467
Trained batch 253 in epoch 14, gen_loss = 0.3992231477667966, disc_loss = 0.07026155259988205
Trained batch 254 in epoch 14, gen_loss = 0.39919505750431733, disc_loss = 0.07016622591398511
Trained batch 255 in epoch 14, gen_loss = 0.39937416557222605, disc_loss = 0.0701764405312133
Trained batch 256 in epoch 14, gen_loss = 0.39941734017565095, disc_loss = 0.07019072870365145
Trained batch 257 in epoch 14, gen_loss = 0.3998380078132762, disc_loss = 0.0704042837673495
Trained batch 258 in epoch 14, gen_loss = 0.39998394481003513, disc_loss = 0.07017075874875066
Trained batch 259 in epoch 14, gen_loss = 0.40004873218444675, disc_loss = 0.07022662464027794
Trained batch 260 in epoch 14, gen_loss = 0.40004299735200816, disc_loss = 0.07004217090177925
Trained batch 261 in epoch 14, gen_loss = 0.3999463224229012, disc_loss = 0.06982168622087431
Trained batch 262 in epoch 14, gen_loss = 0.40006097799924845, disc_loss = 0.06964415310396894
Trained batch 263 in epoch 14, gen_loss = 0.3997613187089111, disc_loss = 0.06979987605220893
Trained batch 264 in epoch 14, gen_loss = 0.3999828484823119, disc_loss = 0.07032141667210831
Trained batch 265 in epoch 14, gen_loss = 0.3996329175350361, disc_loss = 0.07043580877545633
Trained batch 266 in epoch 14, gen_loss = 0.3996538999821809, disc_loss = 0.07026530708768841
Trained batch 267 in epoch 14, gen_loss = 0.3999117274782551, disc_loss = 0.07004012141043126
Trained batch 268 in epoch 14, gen_loss = 0.39975447326787783, disc_loss = 0.07008749408626645
Trained batch 269 in epoch 14, gen_loss = 0.39986132670331886, disc_loss = 0.0707319089246017
Trained batch 270 in epoch 14, gen_loss = 0.400073903733074, disc_loss = 0.07082166922763265
Trained batch 271 in epoch 14, gen_loss = 0.40032995667527704, disc_loss = 0.0707025521517019
Trained batch 272 in epoch 14, gen_loss = 0.4000642432834639, disc_loss = 0.07068535501321593
Trained batch 273 in epoch 14, gen_loss = 0.400119762351043, disc_loss = 0.07056697869986078
Trained batch 274 in epoch 14, gen_loss = 0.4003893691843206, disc_loss = 0.07050128163261847
Trained batch 275 in epoch 14, gen_loss = 0.4003723332847374, disc_loss = 0.07035335610904124
Trained batch 276 in epoch 14, gen_loss = 0.4003324946556711, disc_loss = 0.07021996541627908
Trained batch 277 in epoch 14, gen_loss = 0.3999570586698518, disc_loss = 0.07015402820095312
Trained batch 278 in epoch 14, gen_loss = 0.4000876333337531, disc_loss = 0.07000129855501609
Trained batch 279 in epoch 14, gen_loss = 0.4001314004617078, disc_loss = 0.06995364712285145
Trained batch 280 in epoch 14, gen_loss = 0.40047155781997057, disc_loss = 0.07054994806806388
Trained batch 281 in epoch 14, gen_loss = 0.4003112233699636, disc_loss = 0.07112307119982463
Trained batch 282 in epoch 14, gen_loss = 0.4004855655107397, disc_loss = 0.07094145550428768
Trained batch 283 in epoch 14, gen_loss = 0.40079416859317835, disc_loss = 0.07096840354653311
Trained batch 284 in epoch 14, gen_loss = 0.4006721076212431, disc_loss = 0.07075364715174624
Trained batch 285 in epoch 14, gen_loss = 0.4007715069122248, disc_loss = 0.07076680962439183
Trained batch 286 in epoch 14, gen_loss = 0.4004039792441325, disc_loss = 0.07058852890227314
Trained batch 287 in epoch 14, gen_loss = 0.40069607966062093, disc_loss = 0.0703838082909998
Trained batch 288 in epoch 14, gen_loss = 0.4008148581717666, disc_loss = 0.0701861354686758
Trained batch 289 in epoch 14, gen_loss = 0.40077588650686985, disc_loss = 0.0700043879031878
Trained batch 290 in epoch 14, gen_loss = 0.4006502418378784, disc_loss = 0.06987499449197267
Trained batch 291 in epoch 14, gen_loss = 0.4005267866057892, disc_loss = 0.0698621134586275
Trained batch 292 in epoch 14, gen_loss = 0.4005096431681727, disc_loss = 0.06973844518370087
Trained batch 293 in epoch 14, gen_loss = 0.40062744905348535, disc_loss = 0.06961249777743099
Trained batch 294 in epoch 14, gen_loss = 0.40078488699460435, disc_loss = 0.06953768795514005
Trained batch 295 in epoch 14, gen_loss = 0.40083286095712634, disc_loss = 0.06960024445229587
Trained batch 296 in epoch 14, gen_loss = 0.40068439532209327, disc_loss = 0.06994862395090988
Trained batch 297 in epoch 14, gen_loss = 0.40064198808782053, disc_loss = 0.06975661035964653
Trained batch 298 in epoch 14, gen_loss = 0.4006533045633182, disc_loss = 0.06960389564704636
Trained batch 299 in epoch 14, gen_loss = 0.40040842930475873, disc_loss = 0.06955742044684787
Trained batch 300 in epoch 14, gen_loss = 0.40056680484467566, disc_loss = 0.06937722251301885
Trained batch 301 in epoch 14, gen_loss = 0.40048517572958736, disc_loss = 0.06919995642618726
Trained batch 302 in epoch 14, gen_loss = 0.4005560327087692, disc_loss = 0.06905374413190207
Trained batch 303 in epoch 14, gen_loss = 0.40058936374752147, disc_loss = 0.06889279391065142
Trained batch 304 in epoch 14, gen_loss = 0.4008680434500585, disc_loss = 0.06870009420653347
Trained batch 305 in epoch 14, gen_loss = 0.4012101838986079, disc_loss = 0.06858320829148094
Trained batch 306 in epoch 14, gen_loss = 0.40099315874351354, disc_loss = 0.06850613592077252
Trained batch 307 in epoch 14, gen_loss = 0.4015341284019606, disc_loss = 0.06833832662903352
Trained batch 308 in epoch 14, gen_loss = 0.40177064516783534, disc_loss = 0.06814088189859896
Trained batch 309 in epoch 14, gen_loss = 0.40175649081507037, disc_loss = 0.06808871926980153
Trained batch 310 in epoch 14, gen_loss = 0.40160009667421076, disc_loss = 0.06861445338576073
Trained batch 311 in epoch 14, gen_loss = 0.4018752091588118, disc_loss = 0.06916337887434146
Trained batch 312 in epoch 14, gen_loss = 0.40182483339081176, disc_loss = 0.06915835900226244
Trained batch 313 in epoch 14, gen_loss = 0.4019402961252601, disc_loss = 0.06907672095438762
Trained batch 314 in epoch 14, gen_loss = 0.4016759473180014, disc_loss = 0.06904125660362224
Trained batch 315 in epoch 14, gen_loss = 0.40152347191602367, disc_loss = 0.06897339943643141
Trained batch 316 in epoch 14, gen_loss = 0.40126483701757076, disc_loss = 0.06879444186772551
Trained batch 317 in epoch 14, gen_loss = 0.4013221833690907, disc_loss = 0.06881628390811619
Trained batch 318 in epoch 14, gen_loss = 0.4010673756696587, disc_loss = 0.06928724895135083
Trained batch 319 in epoch 14, gen_loss = 0.401323248911649, disc_loss = 0.06947636468394194
Trained batch 320 in epoch 14, gen_loss = 0.4013921402139456, disc_loss = 0.06929061263857694
Trained batch 321 in epoch 14, gen_loss = 0.4010370350587442, disc_loss = 0.06939672127146251
Trained batch 322 in epoch 14, gen_loss = 0.4012712943295576, disc_loss = 0.06930369557668642
Trained batch 323 in epoch 14, gen_loss = 0.40116747836639854, disc_loss = 0.06941913147916856
Trained batch 324 in epoch 14, gen_loss = 0.40080178059064425, disc_loss = 0.06962900016456842
Trained batch 325 in epoch 14, gen_loss = 0.4009640819273112, disc_loss = 0.06956999838363631
Trained batch 326 in epoch 14, gen_loss = 0.40113591218213424, disc_loss = 0.06981006308262228
Trained batch 327 in epoch 14, gen_loss = 0.4010460440342019, disc_loss = 0.06974744195084474
Trained batch 328 in epoch 14, gen_loss = 0.4009588507533436, disc_loss = 0.06965411678919042
Trained batch 329 in epoch 14, gen_loss = 0.400842230608969, disc_loss = 0.06959575195937898
Trained batch 330 in epoch 14, gen_loss = 0.4009826685726823, disc_loss = 0.06959119182800329
Trained batch 331 in epoch 14, gen_loss = 0.40092144367924654, disc_loss = 0.06946821635061629
Trained batch 332 in epoch 14, gen_loss = 0.4010606671238805, disc_loss = 0.06929289479390369
Trained batch 333 in epoch 14, gen_loss = 0.4012082243215538, disc_loss = 0.06913911033990587
Trained batch 334 in epoch 14, gen_loss = 0.4010278909064051, disc_loss = 0.06921331531354295
Trained batch 335 in epoch 14, gen_loss = 0.40093273554174674, disc_loss = 0.06943841970669815
Trained batch 336 in epoch 14, gen_loss = 0.400841374514011, disc_loss = 0.06927870532901245
Trained batch 337 in epoch 14, gen_loss = 0.4010721244050201, disc_loss = 0.06915213782119857
Trained batch 338 in epoch 14, gen_loss = 0.40111514556724415, disc_loss = 0.06900135859033879
Trained batch 339 in epoch 14, gen_loss = 0.40096699700636024, disc_loss = 0.06909971818437471
Trained batch 340 in epoch 14, gen_loss = 0.4011025308164334, disc_loss = 0.06979671944905061
Trained batch 341 in epoch 14, gen_loss = 0.40102301738415547, disc_loss = 0.06963290128998502
Trained batch 342 in epoch 14, gen_loss = 0.4007937432030547, disc_loss = 0.06985568868555672
Trained batch 343 in epoch 14, gen_loss = 0.40074583168986233, disc_loss = 0.06991656976589543
Trained batch 344 in epoch 14, gen_loss = 0.40061553699382835, disc_loss = 0.06977625545654176
Trained batch 345 in epoch 14, gen_loss = 0.40061400546503895, disc_loss = 0.06966491431439284
Trained batch 346 in epoch 14, gen_loss = 0.4002822199541141, disc_loss = 0.06958165140258905
Trained batch 347 in epoch 14, gen_loss = 0.40031023143694316, disc_loss = 0.06950072496968868
Trained batch 348 in epoch 14, gen_loss = 0.4000912236962414, disc_loss = 0.06952008413134896
Trained batch 349 in epoch 14, gen_loss = 0.40010194190910886, disc_loss = 0.0695629069235708
Trained batch 350 in epoch 14, gen_loss = 0.3997395624462356, disc_loss = 0.06949874633748053
Trained batch 351 in epoch 14, gen_loss = 0.3998410272496668, disc_loss = 0.0693720859311394
Trained batch 352 in epoch 14, gen_loss = 0.3998506539435292, disc_loss = 0.06920194964877016
Trained batch 353 in epoch 14, gen_loss = 0.40004278727843934, disc_loss = 0.06909601276971947
Trained batch 354 in epoch 14, gen_loss = 0.40007011202019704, disc_loss = 0.06903709878646572
Trained batch 355 in epoch 14, gen_loss = 0.40008123428299186, disc_loss = 0.0689476629682513
Trained batch 356 in epoch 14, gen_loss = 0.39997601083346773, disc_loss = 0.0688215089513182
Trained batch 357 in epoch 14, gen_loss = 0.4001473049378262, disc_loss = 0.06867991684150346
Trained batch 358 in epoch 14, gen_loss = 0.3999045515292866, disc_loss = 0.06862824931896414
Trained batch 359 in epoch 14, gen_loss = 0.3999445107248094, disc_loss = 0.06860643049650308
Trained batch 360 in epoch 14, gen_loss = 0.40010771815796636, disc_loss = 0.0684666968701495
Trained batch 361 in epoch 14, gen_loss = 0.4001675498419704, disc_loss = 0.0683106463994234
Trained batch 362 in epoch 14, gen_loss = 0.3999430967428139, disc_loss = 0.06829514158196932
Trained batch 363 in epoch 14, gen_loss = 0.3997741255622644, disc_loss = 0.06846161496538955
Trained batch 364 in epoch 14, gen_loss = 0.39996978607896255, disc_loss = 0.06831192422964394
Trained batch 365 in epoch 14, gen_loss = 0.4001201968538305, disc_loss = 0.06837927055153284
Trained batch 366 in epoch 14, gen_loss = 0.4000991991332831, disc_loss = 0.0691942303575961
Trained batch 367 in epoch 14, gen_loss = 0.4002359554009593, disc_loss = 0.06932025260808271
Trained batch 368 in epoch 14, gen_loss = 0.400223045733563, disc_loss = 0.0693542733157513
Trained batch 369 in epoch 14, gen_loss = 0.4001512015993531, disc_loss = 0.06921088540725209
Trained batch 370 in epoch 14, gen_loss = 0.400367469639791, disc_loss = 0.06905073755624079
Trained batch 371 in epoch 14, gen_loss = 0.4001119099957969, disc_loss = 0.06921820343291808
Trained batch 372 in epoch 14, gen_loss = 0.4000392094374342, disc_loss = 0.06908245270587404
Trained batch 373 in epoch 14, gen_loss = 0.3999793661788186, disc_loss = 0.069110431790571
Trained batch 374 in epoch 14, gen_loss = 0.4000701048374176, disc_loss = 0.06900462266554436
Trained batch 375 in epoch 14, gen_loss = 0.3999653418171913, disc_loss = 0.06916926722686262
Trained batch 376 in epoch 14, gen_loss = 0.39974589823727896, disc_loss = 0.0690483776210197
Trained batch 377 in epoch 14, gen_loss = 0.3997552077133189, disc_loss = 0.06928243259677574
Trained batch 378 in epoch 14, gen_loss = 0.3995673307328237, disc_loss = 0.0694230793751678
Trained batch 379 in epoch 14, gen_loss = 0.39962873239266244, disc_loss = 0.06930825783086843
Trained batch 380 in epoch 14, gen_loss = 0.3996053037680979, disc_loss = 0.06915282432889454
Trained batch 381 in epoch 14, gen_loss = 0.39968810195386095, disc_loss = 0.06899991912367456
Trained batch 382 in epoch 14, gen_loss = 0.39972256174597975, disc_loss = 0.06891890845745413
Trained batch 383 in epoch 14, gen_loss = 0.40002402717558044, disc_loss = 0.06883006978508395
Trained batch 384 in epoch 14, gen_loss = 0.39997838735580443, disc_loss = 0.06881539025283478
Trained batch 385 in epoch 14, gen_loss = 0.39986766481028935, disc_loss = 0.06872628981469518
Trained batch 386 in epoch 14, gen_loss = 0.39956068884802726, disc_loss = 0.06872229263648506
Trained batch 387 in epoch 14, gen_loss = 0.39970245312169655, disc_loss = 0.06883552777052847
Trained batch 388 in epoch 14, gen_loss = 0.3996058108720804, disc_loss = 0.06904615372764114
Trained batch 389 in epoch 14, gen_loss = 0.39965728353231383, disc_loss = 0.06904715585211912
Trained batch 390 in epoch 14, gen_loss = 0.39979379149654026, disc_loss = 0.06890412022257247
Trained batch 391 in epoch 14, gen_loss = 0.3995489380797561, disc_loss = 0.06879345533362001
Trained batch 392 in epoch 14, gen_loss = 0.399661885873052, disc_loss = 0.06865894386862374
Trained batch 393 in epoch 14, gen_loss = 0.39988192189768484, disc_loss = 0.0685116917788415
Trained batch 394 in epoch 14, gen_loss = 0.39975213355655914, disc_loss = 0.06840135041341375
Trained batch 395 in epoch 14, gen_loss = 0.3995905059455621, disc_loss = 0.06840640283189714
Trained batch 396 in epoch 14, gen_loss = 0.39993761648759435, disc_loss = 0.06895253647081273
Trained batch 397 in epoch 14, gen_loss = 0.39974080632679426, disc_loss = 0.06918329153275445
Trained batch 398 in epoch 14, gen_loss = 0.3994105643497075, disc_loss = 0.07055223767965435
Trained batch 399 in epoch 14, gen_loss = 0.3993237332254648, disc_loss = 0.07050679171690717
Trained batch 400 in epoch 14, gen_loss = 0.3994515149522006, disc_loss = 0.0704616230199499
Trained batch 401 in epoch 14, gen_loss = 0.399482232569462, disc_loss = 0.07069704351965245
Trained batch 402 in epoch 14, gen_loss = 0.3994918869387719, disc_loss = 0.07121232011709039
Trained batch 403 in epoch 14, gen_loss = 0.39960019674041486, disc_loss = 0.07115836300665863
Trained batch 404 in epoch 14, gen_loss = 0.39967748875971193, disc_loss = 0.07105943206697703
Trained batch 405 in epoch 14, gen_loss = 0.3998075184857317, disc_loss = 0.07098249405888575
Trained batch 406 in epoch 14, gen_loss = 0.3997688205587776, disc_loss = 0.0709614771869061
Trained batch 407 in epoch 14, gen_loss = 0.39978931756580577, disc_loss = 0.0708432306521846
Trained batch 408 in epoch 14, gen_loss = 0.3998142985085112, disc_loss = 0.07077973790712709
Trained batch 409 in epoch 14, gen_loss = 0.39978448290650437, disc_loss = 0.07077436453730958
Trained batch 410 in epoch 14, gen_loss = 0.3998979575877642, disc_loss = 0.07086045131168879
Trained batch 411 in epoch 14, gen_loss = 0.3998850056702651, disc_loss = 0.07085458732897289
Trained batch 412 in epoch 14, gen_loss = 0.3999795699379346, disc_loss = 0.0707831437616061
Trained batch 413 in epoch 14, gen_loss = 0.39998091886872833, disc_loss = 0.07064876853654854
Trained batch 414 in epoch 14, gen_loss = 0.4000389440950141, disc_loss = 0.07066054781113404
Trained batch 415 in epoch 14, gen_loss = 0.40011016530199695, disc_loss = 0.0707193611686727
Trained batch 416 in epoch 14, gen_loss = 0.39997925825542113, disc_loss = 0.07073786117502753
Trained batch 417 in epoch 14, gen_loss = 0.40007428546841634, disc_loss = 0.07066026580203592
Trained batch 418 in epoch 14, gen_loss = 0.40006029776570906, disc_loss = 0.07053715664324371
Trained batch 419 in epoch 14, gen_loss = 0.4001476487233525, disc_loss = 0.07045934744667084
Trained batch 420 in epoch 14, gen_loss = 0.4003145441306742, disc_loss = 0.07036398636783316
Trained batch 421 in epoch 14, gen_loss = 0.4001949284737709, disc_loss = 0.07024693990267496
Trained batch 422 in epoch 14, gen_loss = 0.40012248399409844, disc_loss = 0.0701399524773231
Trained batch 423 in epoch 14, gen_loss = 0.40013584550821557, disc_loss = 0.07014208411543085
Trained batch 424 in epoch 14, gen_loss = 0.3998791276006138, disc_loss = 0.07066778945353101
Trained batch 425 in epoch 14, gen_loss = 0.40007808545665563, disc_loss = 0.07068265307948274
Trained batch 426 in epoch 14, gen_loss = 0.4001074889783837, disc_loss = 0.0706394285255873
Trained batch 427 in epoch 14, gen_loss = 0.4000596456995634, disc_loss = 0.07063364341776714
Trained batch 428 in epoch 14, gen_loss = 0.39982467243721437, disc_loss = 0.07056621819656421
Trained batch 429 in epoch 14, gen_loss = 0.39997467142204907, disc_loss = 0.07052171133068759
Trained batch 430 in epoch 14, gen_loss = 0.4000582015293104, disc_loss = 0.07039956830381448
Trained batch 431 in epoch 14, gen_loss = 0.39995581270368014, disc_loss = 0.07030308287357911
Trained batch 432 in epoch 14, gen_loss = 0.39998024557534323, disc_loss = 0.07017319970796483
Trained batch 433 in epoch 14, gen_loss = 0.3997963291296761, disc_loss = 0.07006520879656626
Trained batch 434 in epoch 14, gen_loss = 0.3997357639088028, disc_loss = 0.06993227797378411
Trained batch 435 in epoch 14, gen_loss = 0.39998158833029074, disc_loss = 0.06983208207951841
Trained batch 436 in epoch 14, gen_loss = 0.39991524911035936, disc_loss = 0.06975712436432492
Trained batch 437 in epoch 14, gen_loss = 0.3999970728812152, disc_loss = 0.0699844728649241
Trained batch 438 in epoch 14, gen_loss = 0.39995328121413404, disc_loss = 0.07043803357869251
Trained batch 439 in epoch 14, gen_loss = 0.3999328332191164, disc_loss = 0.07031512821982192
Trained batch 440 in epoch 14, gen_loss = 0.4000011491261913, disc_loss = 0.07033259148948114
Trained batch 441 in epoch 14, gen_loss = 0.39999131190830767, disc_loss = 0.07027527225747435
Trained batch 442 in epoch 14, gen_loss = 0.3997699760287395, disc_loss = 0.07029877213916781
Trained batch 443 in epoch 14, gen_loss = 0.4000773891001134, disc_loss = 0.0705318752747566
Trained batch 444 in epoch 14, gen_loss = 0.3998640073819107, disc_loss = 0.07053019693435243
Trained batch 445 in epoch 14, gen_loss = 0.3997640510845612, disc_loss = 0.07053051759685168
Trained batch 446 in epoch 14, gen_loss = 0.39990359624760263, disc_loss = 0.07042978057466964
Trained batch 447 in epoch 14, gen_loss = 0.3999261419022722, disc_loss = 0.07039252797715433
Trained batch 448 in epoch 14, gen_loss = 0.39993201166325, disc_loss = 0.07026933379189208
Trained batch 449 in epoch 14, gen_loss = 0.4000541732708613, disc_loss = 0.07025339934560988
Trained batch 450 in epoch 14, gen_loss = 0.40022397417979866, disc_loss = 0.07011210949401765
Trained batch 451 in epoch 14, gen_loss = 0.4002566236046563, disc_loss = 0.07005476769867593
Trained batch 452 in epoch 14, gen_loss = 0.4000165369731701, disc_loss = 0.07004187158648147
Trained batch 453 in epoch 14, gen_loss = 0.39978624512708133, disc_loss = 0.07025750555377043
Trained batch 454 in epoch 14, gen_loss = 0.39985899257135915, disc_loss = 0.07014372361066577
Trained batch 455 in epoch 14, gen_loss = 0.3998961119928904, disc_loss = 0.07004013314451042
Trained batch 456 in epoch 14, gen_loss = 0.39992190750735596, disc_loss = 0.0699335712678649
Trained batch 457 in epoch 14, gen_loss = 0.3998587371610658, disc_loss = 0.07013932319854155
Trained batch 458 in epoch 14, gen_loss = 0.4001168476859988, disc_loss = 0.07020128966757545
Testing Epoch 14
Training Epoch 15
Trained batch 0 in epoch 15, gen_loss = 0.3564240038394928, disc_loss = 0.09935884177684784
Trained batch 1 in epoch 15, gen_loss = 0.3252645283937454, disc_loss = 0.20817630738019943
Trained batch 2 in epoch 15, gen_loss = 0.3397806187470754, disc_loss = 0.1703457087278366
Trained batch 3 in epoch 15, gen_loss = 0.3596745580434799, disc_loss = 0.13278471026569605
Trained batch 4 in epoch 15, gen_loss = 0.3751789450645447, disc_loss = 0.11199467442929745
Trained batch 5 in epoch 15, gen_loss = 0.38543906311194104, disc_loss = 0.09955123160034418
Trained batch 6 in epoch 15, gen_loss = 0.3823227754661015, disc_loss = 0.08902846622679915
Trained batch 7 in epoch 15, gen_loss = 0.37949489429593086, disc_loss = 0.08059551962651312
Trained batch 8 in epoch 15, gen_loss = 0.3789563808176253, disc_loss = 0.07483271095487806
Trained batch 9 in epoch 15, gen_loss = 0.37714947760105133, disc_loss = 0.07078319676220417
Trained batch 10 in epoch 15, gen_loss = 0.384591899134896, disc_loss = 0.0726505887101997
Trained batch 11 in epoch 15, gen_loss = 0.38170890013376874, disc_loss = 0.08645020456363757
Trained batch 12 in epoch 15, gen_loss = 0.38665929207435024, disc_loss = 0.08612886672982803
Trained batch 13 in epoch 15, gen_loss = 0.3861612890447889, disc_loss = 0.08463566457586628
Trained batch 14 in epoch 15, gen_loss = 0.3808262825012207, disc_loss = 0.08389769420027733
Trained batch 15 in epoch 15, gen_loss = 0.3855890557169914, disc_loss = 0.07948747696354985
Trained batch 16 in epoch 15, gen_loss = 0.386365615269717, disc_loss = 0.07667011373183306
Trained batch 17 in epoch 15, gen_loss = 0.3872886680894428, disc_loss = 0.07504169911974007
Trained batch 18 in epoch 15, gen_loss = 0.3913232778248034, disc_loss = 0.07172733677649185
Trained batch 19 in epoch 15, gen_loss = 0.38928297013044355, disc_loss = 0.06930364179424942
Trained batch 20 in epoch 15, gen_loss = 0.38892086630775813, disc_loss = 0.06780405018833421
Trained batch 21 in epoch 15, gen_loss = 0.3953294103795832, disc_loss = 0.0654924893328412
Trained batch 22 in epoch 15, gen_loss = 0.39773403172907623, disc_loss = 0.06413518706255633
Trained batch 23 in epoch 15, gen_loss = 0.39451107010245323, disc_loss = 0.06248865327021728
Trained batch 24 in epoch 15, gen_loss = 0.3916791033744812, disc_loss = 0.060907073356211185
Trained batch 25 in epoch 15, gen_loss = 0.39022305837044347, disc_loss = 0.06575525355023834
Trained batch 26 in epoch 15, gen_loss = 0.39421033417737045, disc_loss = 0.06454685002703357
Trained batch 27 in epoch 15, gen_loss = 0.39424167041267666, disc_loss = 0.06289631144941918
Trained batch 28 in epoch 15, gen_loss = 0.39422596117545816, disc_loss = 0.0612153434676343
Trained batch 29 in epoch 15, gen_loss = 0.39495348632335664, disc_loss = 0.06050936449319124
Trained batch 30 in epoch 15, gen_loss = 0.39562786971369096, disc_loss = 0.06010186618133899
Trained batch 31 in epoch 15, gen_loss = 0.3937033209949732, disc_loss = 0.059166009014006704
Trained batch 32 in epoch 15, gen_loss = 0.3922583054412495, disc_loss = 0.060294592414389954
Trained batch 33 in epoch 15, gen_loss = 0.39461364202639637, disc_loss = 0.06190190108164268
Trained batch 34 in epoch 15, gen_loss = 0.3933591084820884, disc_loss = 0.06037997185651745
Trained batch 35 in epoch 15, gen_loss = 0.3918306628863017, disc_loss = 0.059009333373978734
Trained batch 36 in epoch 15, gen_loss = 0.3924877836897567, disc_loss = 0.060739794620186895
Trained batch 37 in epoch 15, gen_loss = 0.39481795932117264, disc_loss = 0.0614611439063753
Trained batch 38 in epoch 15, gen_loss = 0.39791170908854556, disc_loss = 0.061161633127201825
Trained batch 39 in epoch 15, gen_loss = 0.3986952595412731, disc_loss = 0.060937246703542766
Trained batch 40 in epoch 15, gen_loss = 0.3987296957795213, disc_loss = 0.05986990559300998
Trained batch 41 in epoch 15, gen_loss = 0.39912344231492, disc_loss = 0.05866124046345552
Trained batch 42 in epoch 15, gen_loss = 0.3995496616807095, disc_loss = 0.05755385383963585
Trained batch 43 in epoch 15, gen_loss = 0.3981590934775092, disc_loss = 0.056727518920194016
Trained batch 44 in epoch 15, gen_loss = 0.39905280073483784, disc_loss = 0.056548272487190035
Trained batch 45 in epoch 15, gen_loss = 0.4002483156712159, disc_loss = 0.05789487104377021
Trained batch 46 in epoch 15, gen_loss = 0.4006077444299738, disc_loss = 0.05971626501451147
Trained batch 47 in epoch 15, gen_loss = 0.40152122142414254, disc_loss = 0.059879883114869394
Trained batch 48 in epoch 15, gen_loss = 0.4024403149984321, disc_loss = 0.05906219130419955
Trained batch 49 in epoch 15, gen_loss = 0.4019608396291733, disc_loss = 0.05830001194030046
Trained batch 50 in epoch 15, gen_loss = 0.4004041558387233, disc_loss = 0.05829628619054953
Trained batch 51 in epoch 15, gen_loss = 0.40046709030866623, disc_loss = 0.06025541648985101
Trained batch 52 in epoch 15, gen_loss = 0.40009340868805937, disc_loss = 0.06289392614842586
Trained batch 53 in epoch 15, gen_loss = 0.40128347443209755, disc_loss = 0.06202087844549506
Trained batch 54 in epoch 15, gen_loss = 0.40170530568469653, disc_loss = 0.06201990046961741
Trained batch 55 in epoch 15, gen_loss = 0.4021600346480097, disc_loss = 0.061256004796762555
Trained batch 56 in epoch 15, gen_loss = 0.40046062960959317, disc_loss = 0.06301249279395531
Trained batch 57 in epoch 15, gen_loss = 0.4009744021399268, disc_loss = 0.06478708882912479
Trained batch 58 in epoch 15, gen_loss = 0.4003435231871524, disc_loss = 0.06465741957269483
Trained batch 59 in epoch 15, gen_loss = 0.39977667679389317, disc_loss = 0.06666377351308862
Trained batch 60 in epoch 15, gen_loss = 0.3999998652544178, disc_loss = 0.06618770257737792
Trained batch 61 in epoch 15, gen_loss = 0.4001734525926651, disc_loss = 0.06552427718716283
Trained batch 62 in epoch 15, gen_loss = 0.3987422963929555, disc_loss = 0.06490938276762054
Trained batch 63 in epoch 15, gen_loss = 0.3989723571576178, disc_loss = 0.06428309256443754
Trained batch 64 in epoch 15, gen_loss = 0.3975322384100694, disc_loss = 0.06362703909667639
Trained batch 65 in epoch 15, gen_loss = 0.39857976003126666, disc_loss = 0.0631360581822016
Trained batch 66 in epoch 15, gen_loss = 0.3971276545702522, disc_loss = 0.06305172758649534
Trained batch 67 in epoch 15, gen_loss = 0.3986739161259988, disc_loss = 0.06326202355215654
Trained batch 68 in epoch 15, gen_loss = 0.39810994267463684, disc_loss = 0.06286016805772332
Trained batch 69 in epoch 15, gen_loss = 0.39828225331647055, disc_loss = 0.062382371058421475
Trained batch 70 in epoch 15, gen_loss = 0.3980522038231433, disc_loss = 0.06177473907739344
Trained batch 71 in epoch 15, gen_loss = 0.3986057560476992, disc_loss = 0.061421224692215524
Trained batch 72 in epoch 15, gen_loss = 0.40020049393993534, disc_loss = 0.06107545016358976
Trained batch 73 in epoch 15, gen_loss = 0.40059846156352275, disc_loss = 0.060914379871777585
Trained batch 74 in epoch 15, gen_loss = 0.3996391558647156, disc_loss = 0.061010224868853886
Trained batch 75 in epoch 15, gen_loss = 0.39887097321058573, disc_loss = 0.0606610563730723
Trained batch 76 in epoch 15, gen_loss = 0.3989222835410725, disc_loss = 0.06001417989564407
Trained batch 77 in epoch 15, gen_loss = 0.39912448059289884, disc_loss = 0.059503947432415605
Trained batch 78 in epoch 15, gen_loss = 0.39947982717163955, disc_loss = 0.05910073836110061
Trained batch 79 in epoch 15, gen_loss = 0.3995955254882574, disc_loss = 0.05859566491562873
Trained batch 80 in epoch 15, gen_loss = 0.4004346529642741, disc_loss = 0.058147787771843096
Trained batch 81 in epoch 15, gen_loss = 0.39950853041032464, disc_loss = 0.05874504930362469
Trained batch 82 in epoch 15, gen_loss = 0.39964574754956256, disc_loss = 0.06027115953255849
Trained batch 83 in epoch 15, gen_loss = 0.40015086921907606, disc_loss = 0.05986722279340029
Trained batch 84 in epoch 15, gen_loss = 0.4001491315224591, disc_loss = 0.06009687040658558
Trained batch 85 in epoch 15, gen_loss = 0.3995693911646688, disc_loss = 0.05984103484729002
Trained batch 86 in epoch 15, gen_loss = 0.4003820278863797, disc_loss = 0.05976597476622154
Trained batch 87 in epoch 15, gen_loss = 0.4002791660075838, disc_loss = 0.05997916167093949
Trained batch 88 in epoch 15, gen_loss = 0.40149193901694225, disc_loss = 0.05958663169922453
Trained batch 89 in epoch 15, gen_loss = 0.4018535703420639, disc_loss = 0.05906677128126224
Trained batch 90 in epoch 15, gen_loss = 0.4022747012940082, disc_loss = 0.058607542887330055
Trained batch 91 in epoch 15, gen_loss = 0.4028130400439967, disc_loss = 0.05857762578955811
Trained batch 92 in epoch 15, gen_loss = 0.4033690505130317, disc_loss = 0.0590999157478412
Trained batch 93 in epoch 15, gen_loss = 0.4042534571378789, disc_loss = 0.059152692457304354
Trained batch 94 in epoch 15, gen_loss = 0.4044183960086421, disc_loss = 0.05864501266103042
Trained batch 95 in epoch 15, gen_loss = 0.40491135014841956, disc_loss = 0.0581720608267157
Trained batch 96 in epoch 15, gen_loss = 0.40594614074402247, disc_loss = 0.05777031915819215
Trained batch 97 in epoch 15, gen_loss = 0.40606845884907, disc_loss = 0.05741339392617953
Trained batch 98 in epoch 15, gen_loss = 0.4057533430932748, disc_loss = 0.05712846646819151
Trained batch 99 in epoch 15, gen_loss = 0.4044298729300499, disc_loss = 0.0573091188352555
Trained batch 100 in epoch 15, gen_loss = 0.40520884052361594, disc_loss = 0.05750808535641668
Trained batch 101 in epoch 15, gen_loss = 0.40467870644494597, disc_loss = 0.05721180003099874
Trained batch 102 in epoch 15, gen_loss = 0.404073489522471, disc_loss = 0.05708641559789771
Trained batch 103 in epoch 15, gen_loss = 0.4036726653575897, disc_loss = 0.05666117466842899
Trained batch 104 in epoch 15, gen_loss = 0.4032577415307363, disc_loss = 0.05623639713795412
Trained batch 105 in epoch 15, gen_loss = 0.4023121215824811, disc_loss = 0.05638014874860363
Trained batch 106 in epoch 15, gen_loss = 0.40102936229973196, disc_loss = 0.05831343240200359
Trained batch 107 in epoch 15, gen_loss = 0.40175597093723436, disc_loss = 0.05820914559687177
Trained batch 108 in epoch 15, gen_loss = 0.4025603051579327, disc_loss = 0.058264834635438176
Trained batch 109 in epoch 15, gen_loss = 0.4022394361821088, disc_loss = 0.058292388120158155
Trained batch 110 in epoch 15, gen_loss = 0.40191681213207076, disc_loss = 0.05814728679487834
Trained batch 111 in epoch 15, gen_loss = 0.4024617584156139, disc_loss = 0.05787896823936275
Trained batch 112 in epoch 15, gen_loss = 0.40252216964696363, disc_loss = 0.05762985665186317
Trained batch 113 in epoch 15, gen_loss = 0.4024381674172586, disc_loss = 0.057403624776685445
Trained batch 114 in epoch 15, gen_loss = 0.4026290914286738, disc_loss = 0.05745151172513547
Trained batch 115 in epoch 15, gen_loss = 0.4032537582619437, disc_loss = 0.057554025138760435
Trained batch 116 in epoch 15, gen_loss = 0.4025684595108032, disc_loss = 0.05747523470821544
Trained batch 117 in epoch 15, gen_loss = 0.40281510050013913, disc_loss = 0.05713308905645952
Trained batch 118 in epoch 15, gen_loss = 0.40288064760320325, disc_loss = 0.05675790395525073
Trained batch 119 in epoch 15, gen_loss = 0.40301792497436206, disc_loss = 0.056637595493036014
Trained batch 120 in epoch 15, gen_loss = 0.40294370498539, disc_loss = 0.05883980476997854
Trained batch 121 in epoch 15, gen_loss = 0.4024667243977062, disc_loss = 0.060278119756000455
Trained batch 122 in epoch 15, gen_loss = 0.40290571107127804, disc_loss = 0.059901051321710516
Trained batch 123 in epoch 15, gen_loss = 0.40319805039513495, disc_loss = 0.059746841787390655
Trained batch 124 in epoch 15, gen_loss = 0.40261096382141115, disc_loss = 0.05958239457756281
Trained batch 125 in epoch 15, gen_loss = 0.40207328777464607, disc_loss = 0.0592206936359169
Trained batch 126 in epoch 15, gen_loss = 0.4021513612251582, disc_loss = 0.05925419866510733
Trained batch 127 in epoch 15, gen_loss = 0.40211518318392336, disc_loss = 0.05941986547259148
Trained batch 128 in epoch 15, gen_loss = 0.40262279284092806, disc_loss = 0.05904966465724531
Trained batch 129 in epoch 15, gen_loss = 0.40252512051508976, disc_loss = 0.05873802414593788
Trained batch 130 in epoch 15, gen_loss = 0.40201412493945987, disc_loss = 0.05903669596002757
Trained batch 131 in epoch 15, gen_loss = 0.40236924091974896, disc_loss = 0.05933932103498867
Trained batch 132 in epoch 15, gen_loss = 0.4022895095491768, disc_loss = 0.05904544504793515
Trained batch 133 in epoch 15, gen_loss = 0.4023793041706085, disc_loss = 0.05871149978197333
Trained batch 134 in epoch 15, gen_loss = 0.402578286992179, disc_loss = 0.058396069125996694
Trained batch 135 in epoch 15, gen_loss = 0.40237201794105415, disc_loss = 0.05807093060438467
Trained batch 136 in epoch 15, gen_loss = 0.40258221513163434, disc_loss = 0.05774790084628511
Trained batch 137 in epoch 15, gen_loss = 0.4021331151758415, disc_loss = 0.05800273251193373
Trained batch 138 in epoch 15, gen_loss = 0.4016329481018533, disc_loss = 0.05984918412035532
Trained batch 139 in epoch 15, gen_loss = 0.40175038278102876, disc_loss = 0.059827076118173346
Trained batch 140 in epoch 15, gen_loss = 0.40162978611939343, disc_loss = 0.06034731918430709
Trained batch 141 in epoch 15, gen_loss = 0.4016615632973926, disc_loss = 0.060022874033524534
Trained batch 142 in epoch 15, gen_loss = 0.4009688404890207, disc_loss = 0.060748181918023766
Trained batch 143 in epoch 15, gen_loss = 0.4009290610750516, disc_loss = 0.060452195783404425
Trained batch 144 in epoch 15, gen_loss = 0.4010325966210201, disc_loss = 0.06066868558911414
Trained batch 145 in epoch 15, gen_loss = 0.4007642289547071, disc_loss = 0.06146939646784369
Trained batch 146 in epoch 15, gen_loss = 0.40027904429403294, disc_loss = 0.061691311416121164
Trained batch 147 in epoch 15, gen_loss = 0.40013276725201996, disc_loss = 0.061726561288122796
Trained batch 148 in epoch 15, gen_loss = 0.4007298132317178, disc_loss = 0.06175487675397788
Trained batch 149 in epoch 15, gen_loss = 0.400247848033905, disc_loss = 0.061977576930075884
Trained batch 150 in epoch 15, gen_loss = 0.4005407106797427, disc_loss = 0.06222276095399596
Trained batch 151 in epoch 15, gen_loss = 0.40044169853392403, disc_loss = 0.062132808986414025
Trained batch 152 in epoch 15, gen_loss = 0.399955850995444, disc_loss = 0.06189750701651659
Trained batch 153 in epoch 15, gen_loss = 0.4001573941537312, disc_loss = 0.06154498777823982
Trained batch 154 in epoch 15, gen_loss = 0.4003429260946089, disc_loss = 0.061275669577861985
Trained batch 155 in epoch 15, gen_loss = 0.4003102892102339, disc_loss = 0.06115212626397037
Trained batch 156 in epoch 15, gen_loss = 0.40026599301654064, disc_loss = 0.06136424702467622
Trained batch 157 in epoch 15, gen_loss = 0.40007595925391476, disc_loss = 0.06310297365453613
Trained batch 158 in epoch 15, gen_loss = 0.4000062698838096, disc_loss = 0.06330455666841389
Trained batch 159 in epoch 15, gen_loss = 0.4000373290851712, disc_loss = 0.0632515579520259
Trained batch 160 in epoch 15, gen_loss = 0.3997098422198562, disc_loss = 0.06341158307695426
Trained batch 161 in epoch 15, gen_loss = 0.40018097522818014, disc_loss = 0.06312518831871358
Trained batch 162 in epoch 15, gen_loss = 0.3998722337140627, disc_loss = 0.06300262536030789
Trained batch 163 in epoch 15, gen_loss = 0.39991329301421236, disc_loss = 0.0628104241530797
Trained batch 164 in epoch 15, gen_loss = 0.4001962210192825, disc_loss = 0.06292539481073618
Trained batch 165 in epoch 15, gen_loss = 0.39956389870270187, disc_loss = 0.06436082799862845
Trained batch 166 in epoch 15, gen_loss = 0.400268976738353, disc_loss = 0.06481960405244264
Trained batch 167 in epoch 15, gen_loss = 0.40087511940371423, disc_loss = 0.06463052375086893
Trained batch 168 in epoch 15, gen_loss = 0.40064552443972706, disc_loss = 0.06440825763119924
Trained batch 169 in epoch 15, gen_loss = 0.40014410159167124, disc_loss = 0.06421391298337017
Trained batch 170 in epoch 15, gen_loss = 0.40010647432148805, disc_loss = 0.0639273635552902
Trained batch 171 in epoch 15, gen_loss = 0.4001642181429752, disc_loss = 0.06359113249548733
Trained batch 172 in epoch 15, gen_loss = 0.40012196602159844, disc_loss = 0.063286661060064
Trained batch 173 in epoch 15, gen_loss = 0.4001510854082546, disc_loss = 0.06314567058218708
Trained batch 174 in epoch 15, gen_loss = 0.399797808272498, disc_loss = 0.06314358823267477
Trained batch 175 in epoch 15, gen_loss = 0.4001689497381449, disc_loss = 0.06283052123035304
Trained batch 176 in epoch 15, gen_loss = 0.4002212464472668, disc_loss = 0.06273390185666708
Trained batch 177 in epoch 15, gen_loss = 0.3998117587539587, disc_loss = 0.06255626286317208
Trained batch 178 in epoch 15, gen_loss = 0.39986624497941087, disc_loss = 0.06245584144158153
Trained batch 179 in epoch 15, gen_loss = 0.4002474109331767, disc_loss = 0.06219548727644401
Trained batch 180 in epoch 15, gen_loss = 0.4007802669843916, disc_loss = 0.06245220559314717
Trained batch 181 in epoch 15, gen_loss = 0.4003065202262375, disc_loss = 0.0633636693761858
Trained batch 182 in epoch 15, gen_loss = 0.4007295063935994, disc_loss = 0.0637363336669902
Trained batch 183 in epoch 15, gen_loss = 0.4005437217976736, disc_loss = 0.06344756675610805
Trained batch 184 in epoch 15, gen_loss = 0.40012216342462076, disc_loss = 0.06352941620641867
Trained batch 185 in epoch 15, gen_loss = 0.3998363410593361, disc_loss = 0.06482962880694178
Trained batch 186 in epoch 15, gen_loss = 0.4000973779568698, disc_loss = 0.06458801693746193
Trained batch 187 in epoch 15, gen_loss = 0.40019341558218, disc_loss = 0.06483009553940451
Trained batch 188 in epoch 15, gen_loss = 0.39997750930685216, disc_loss = 0.06454780458586004
Trained batch 189 in epoch 15, gen_loss = 0.3995019793510437, disc_loss = 0.06460671500596953
Trained batch 190 in epoch 15, gen_loss = 0.3995034649422031, disc_loss = 0.06449020430884514
Trained batch 191 in epoch 15, gen_loss = 0.3994610416702926, disc_loss = 0.06444968131108908
Trained batch 192 in epoch 15, gen_loss = 0.3994628245039925, disc_loss = 0.06421048717496076
Trained batch 193 in epoch 15, gen_loss = 0.39963960063826176, disc_loss = 0.0643885840215365
Trained batch 194 in epoch 15, gen_loss = 0.3992530249632322, disc_loss = 0.06502424068032549
Trained batch 195 in epoch 15, gen_loss = 0.3994631288307054, disc_loss = 0.06486230727750808
Trained batch 196 in epoch 15, gen_loss = 0.3997733288912604, disc_loss = 0.06460215921187537
Trained batch 197 in epoch 15, gen_loss = 0.40005423068398177, disc_loss = 0.06443392416001345
Trained batch 198 in epoch 15, gen_loss = 0.4002295814866397, disc_loss = 0.06433033583985276
Trained batch 199 in epoch 15, gen_loss = 0.3999919414520264, disc_loss = 0.06421619534725323
Trained batch 200 in epoch 15, gen_loss = 0.3997684918825899, disc_loss = 0.06413532011627929
Trained batch 201 in epoch 15, gen_loss = 0.4000595430336376, disc_loss = 0.0638720879013106
Trained batch 202 in epoch 15, gen_loss = 0.4001891504367584, disc_loss = 0.06390477284522993
Trained batch 203 in epoch 15, gen_loss = 0.4000684291708703, disc_loss = 0.06412071121774394
Trained batch 204 in epoch 15, gen_loss = 0.40028767149622846, disc_loss = 0.06385552261433587
Trained batch 205 in epoch 15, gen_loss = 0.4002030211166271, disc_loss = 0.06362935976414642
Trained batch 206 in epoch 15, gen_loss = 0.400002785494938, disc_loss = 0.06344686089317508
Trained batch 207 in epoch 15, gen_loss = 0.4001214968470427, disc_loss = 0.06319954606050697
Trained batch 208 in epoch 15, gen_loss = 0.40020449067416947, disc_loss = 0.06344397495941896
Trained batch 209 in epoch 15, gen_loss = 0.3999727308750153, disc_loss = 0.06423592718007663
Trained batch 210 in epoch 15, gen_loss = 0.40041037447644634, disc_loss = 0.06447942355223954
Trained batch 211 in epoch 15, gen_loss = 0.4006919297126104, disc_loss = 0.06439967479618301
Trained batch 212 in epoch 15, gen_loss = 0.40064952029308804, disc_loss = 0.0644838129074046
Trained batch 213 in epoch 15, gen_loss = 0.40038393201114975, disc_loss = 0.06424849414022936
Trained batch 214 in epoch 15, gen_loss = 0.400778450245081, disc_loss = 0.0639853363228572
Trained batch 215 in epoch 15, gen_loss = 0.4009381389176404, disc_loss = 0.0637661225908367
Trained batch 216 in epoch 15, gen_loss = 0.4009053855447725, disc_loss = 0.06359390521525032
Trained batch 217 in epoch 15, gen_loss = 0.4010697277860904, disc_loss = 0.06349286001491779
Trained batch 218 in epoch 15, gen_loss = 0.40136486046934783, disc_loss = 0.0633099590147501
Trained batch 219 in epoch 15, gen_loss = 0.40179223323410207, disc_loss = 0.0632008645535362
Trained batch 220 in epoch 15, gen_loss = 0.4017035591656266, disc_loss = 0.06314964865743103
Trained batch 221 in epoch 15, gen_loss = 0.4018463187658035, disc_loss = 0.06309772246131287
Trained batch 222 in epoch 15, gen_loss = 0.4015588273916544, disc_loss = 0.06310347815340744
Trained batch 223 in epoch 15, gen_loss = 0.40172718718115774, disc_loss = 0.06290158894054391
Trained batch 224 in epoch 15, gen_loss = 0.40174606177541944, disc_loss = 0.06273883652562896
Trained batch 225 in epoch 15, gen_loss = 0.4019131664417486, disc_loss = 0.0627824127266134
Trained batch 226 in epoch 15, gen_loss = 0.4025290024175518, disc_loss = 0.06259410642292597
Trained batch 227 in epoch 15, gen_loss = 0.4025919778566611, disc_loss = 0.06303340517874938
Trained batch 228 in epoch 15, gen_loss = 0.4024258304110781, disc_loss = 0.0642844376837485
Trained batch 229 in epoch 15, gen_loss = 0.40253465836462765, disc_loss = 0.06425243691622239
Trained batch 230 in epoch 15, gen_loss = 0.4023865009799148, disc_loss = 0.06437872664083714
Trained batch 231 in epoch 15, gen_loss = 0.40260325860360574, disc_loss = 0.06439115708605547
Trained batch 232 in epoch 15, gen_loss = 0.4021959908530436, disc_loss = 0.0645143856981953
Trained batch 233 in epoch 15, gen_loss = 0.4022218556995066, disc_loss = 0.064856191072215
Trained batch 234 in epoch 15, gen_loss = 0.4022474819041313, disc_loss = 0.06476109979991267
Trained batch 235 in epoch 15, gen_loss = 0.402220256626606, disc_loss = 0.06484309515434365
Trained batch 236 in epoch 15, gen_loss = 0.40233471398615134, disc_loss = 0.06466571388781889
Trained batch 237 in epoch 15, gen_loss = 0.40237589280645386, disc_loss = 0.06452734730237734
Trained batch 238 in epoch 15, gen_loss = 0.40242761622911716, disc_loss = 0.06442578589917788
Trained batch 239 in epoch 15, gen_loss = 0.4023738233993451, disc_loss = 0.06484360537530544
Trained batch 240 in epoch 15, gen_loss = 0.4024216448617674, disc_loss = 0.06464252444138727
Trained batch 241 in epoch 15, gen_loss = 0.4028653810339526, disc_loss = 0.06527438174263567
Trained batch 242 in epoch 15, gen_loss = 0.4031546227480649, disc_loss = 0.06513179700108773
Trained batch 243 in epoch 15, gen_loss = 0.4030531690013213, disc_loss = 0.06520758620577818
Trained batch 244 in epoch 15, gen_loss = 0.4031880648768678, disc_loss = 0.06497481159143606
Trained batch 245 in epoch 15, gen_loss = 0.4031840796635403, disc_loss = 0.06476498845154495
Trained batch 246 in epoch 15, gen_loss = 0.40291793204029563, disc_loss = 0.06467714405200078
Trained batch 247 in epoch 15, gen_loss = 0.40253797185517126, disc_loss = 0.06515804576244386
Trained batch 248 in epoch 15, gen_loss = 0.402786107068081, disc_loss = 0.0651453773259189
Trained batch 249 in epoch 15, gen_loss = 0.40300214660167694, disc_loss = 0.06495581312663853
Trained batch 250 in epoch 15, gen_loss = 0.40307210189887727, disc_loss = 0.06485574946467917
Trained batch 251 in epoch 15, gen_loss = 0.40300277265764417, disc_loss = 0.0647482678815279
Trained batch 252 in epoch 15, gen_loss = 0.403264090242122, disc_loss = 0.06457129691583896
Trained batch 253 in epoch 15, gen_loss = 0.4034578381326255, disc_loss = 0.06441222991625684
Trained batch 254 in epoch 15, gen_loss = 0.40345292734164817, disc_loss = 0.06426782627936964
Trained batch 255 in epoch 15, gen_loss = 0.4038854973623529, disc_loss = 0.0641132502223627
Trained batch 256 in epoch 15, gen_loss = 0.4037771822181657, disc_loss = 0.06399199647959394
Trained batch 257 in epoch 15, gen_loss = 0.4036282953596854, disc_loss = 0.06391553104450826
Trained batch 258 in epoch 15, gen_loss = 0.4039489630336467, disc_loss = 0.06451322049312437
Trained batch 259 in epoch 15, gen_loss = 0.4038807074611004, disc_loss = 0.06546142729035077
Trained batch 260 in epoch 15, gen_loss = 0.40391767790034355, disc_loss = 0.06555012568039284
Trained batch 261 in epoch 15, gen_loss = 0.4038562510759776, disc_loss = 0.06538556861150868
Trained batch 262 in epoch 15, gen_loss = 0.4036512927863988, disc_loss = 0.06546949630093268
Trained batch 263 in epoch 15, gen_loss = 0.4036962168686318, disc_loss = 0.06533840368678229
Trained batch 264 in epoch 15, gen_loss = 0.40377628083498973, disc_loss = 0.06514643120913292
Trained batch 265 in epoch 15, gen_loss = 0.403537285171057, disc_loss = 0.06499969775270306
Trained batch 266 in epoch 15, gen_loss = 0.40373376625753965, disc_loss = 0.06502743936858876
Trained batch 267 in epoch 15, gen_loss = 0.4032994346387351, disc_loss = 0.06504292100313495
Trained batch 268 in epoch 15, gen_loss = 0.40312480173146414, disc_loss = 0.06486911551860684
Trained batch 269 in epoch 15, gen_loss = 0.4030522186447073, disc_loss = 0.06477505159909251
Trained batch 270 in epoch 15, gen_loss = 0.40286100724526436, disc_loss = 0.06485847139909753
Trained batch 271 in epoch 15, gen_loss = 0.40287041795604367, disc_loss = 0.06536945005748696
Trained batch 272 in epoch 15, gen_loss = 0.40280179182688397, disc_loss = 0.06530361031199168
Trained batch 273 in epoch 15, gen_loss = 0.4027165285427205, disc_loss = 0.06512520204801249
Trained batch 274 in epoch 15, gen_loss = 0.40271632812239905, disc_loss = 0.06495201041921973
Trained batch 275 in epoch 15, gen_loss = 0.4026501805022143, disc_loss = 0.06480123735863068
Trained batch 276 in epoch 15, gen_loss = 0.4025882936556847, disc_loss = 0.06464162916247648
Trained batch 277 in epoch 15, gen_loss = 0.4027279231616919, disc_loss = 0.06458766338509246
Trained batch 278 in epoch 15, gen_loss = 0.40254761251924714, disc_loss = 0.06448106731598575
Trained batch 279 in epoch 15, gen_loss = 0.4024103898022856, disc_loss = 0.06435152305722502
Trained batch 280 in epoch 15, gen_loss = 0.4022543051700999, disc_loss = 0.06472070586910716
Trained batch 281 in epoch 15, gen_loss = 0.40218364072184193, disc_loss = 0.06482250542142132
Trained batch 282 in epoch 15, gen_loss = 0.4018267527907139, disc_loss = 0.06474925846341906
Trained batch 283 in epoch 15, gen_loss = 0.4018660332535354, disc_loss = 0.06545421019570351
Trained batch 284 in epoch 15, gen_loss = 0.40223890417500546, disc_loss = 0.06530367030288305
Trained batch 285 in epoch 15, gen_loss = 0.40207994557343996, disc_loss = 0.06535667700894907
Trained batch 286 in epoch 15, gen_loss = 0.40232001281366114, disc_loss = 0.06518314415524075
Trained batch 287 in epoch 15, gen_loss = 0.40237634473790723, disc_loss = 0.06498914426224979
Trained batch 288 in epoch 15, gen_loss = 0.4021619223187127, disc_loss = 0.0650664128082769
Trained batch 289 in epoch 15, gen_loss = 0.4024430083817449, disc_loss = 0.06549260533607469
Trained batch 290 in epoch 15, gen_loss = 0.4022404310834367, disc_loss = 0.06549449986538168
Trained batch 291 in epoch 15, gen_loss = 0.40231587002946906, disc_loss = 0.06535076096889958
Trained batch 292 in epoch 15, gen_loss = 0.4022139930277554, disc_loss = 0.06531167089614903
Trained batch 293 in epoch 15, gen_loss = 0.4022985116965106, disc_loss = 0.06515444162124324
Trained batch 294 in epoch 15, gen_loss = 0.40211659094034613, disc_loss = 0.06505930550806856
Trained batch 295 in epoch 15, gen_loss = 0.40194091301512075, disc_loss = 0.0649829093521033
Trained batch 296 in epoch 15, gen_loss = 0.40193617223489164, disc_loss = 0.06507870110429147
Trained batch 297 in epoch 15, gen_loss = 0.40192575202692277, disc_loss = 0.06513889808514024
Trained batch 298 in epoch 15, gen_loss = 0.40187880755666905, disc_loss = 0.06495393193591648
Trained batch 299 in epoch 15, gen_loss = 0.40209291328986485, disc_loss = 0.06500362082229307
Trained batch 300 in epoch 15, gen_loss = 0.4017368697644864, disc_loss = 0.06539367004591613
Trained batch 301 in epoch 15, gen_loss = 0.4020153199205335, disc_loss = 0.065389236930252
Trained batch 302 in epoch 15, gen_loss = 0.40205106670313545, disc_loss = 0.06521259436519085
Trained batch 303 in epoch 15, gen_loss = 0.40195535672338384, disc_loss = 0.06509021370163139
Trained batch 304 in epoch 15, gen_loss = 0.40205949056343954, disc_loss = 0.06497440859828084
Trained batch 305 in epoch 15, gen_loss = 0.40194890672474903, disc_loss = 0.06516776357022619
Trained batch 306 in epoch 15, gen_loss = 0.4020461355630272, disc_loss = 0.06590514124222464
Trained batch 307 in epoch 15, gen_loss = 0.4020920251677563, disc_loss = 0.06604359808299304
Trained batch 308 in epoch 15, gen_loss = 0.4024619098427226, disc_loss = 0.06602232007635306
Trained batch 309 in epoch 15, gen_loss = 0.4021927248085699, disc_loss = 0.06592283073602424
Trained batch 310 in epoch 15, gen_loss = 0.40206767757605893, disc_loss = 0.06584177596398728
Trained batch 311 in epoch 15, gen_loss = 0.40184854878446996, disc_loss = 0.0656762806719575
Trained batch 312 in epoch 15, gen_loss = 0.40161751177364263, disc_loss = 0.06557089975103736
Trained batch 313 in epoch 15, gen_loss = 0.4017232180021371, disc_loss = 0.06541732741834204
Trained batch 314 in epoch 15, gen_loss = 0.4017007351867736, disc_loss = 0.06532540631643127
Trained batch 315 in epoch 15, gen_loss = 0.40170108828740786, disc_loss = 0.0653293059735052
Trained batch 316 in epoch 15, gen_loss = 0.40180795942947317, disc_loss = 0.06533380487804487
Trained batch 317 in epoch 15, gen_loss = 0.4018078443576705, disc_loss = 0.06539105062091828
Trained batch 318 in epoch 15, gen_loss = 0.40196986631913617, disc_loss = 0.06528061910220027
Trained batch 319 in epoch 15, gen_loss = 0.40206463597714903, disc_loss = 0.06532960260956315
Trained batch 320 in epoch 15, gen_loss = 0.4016043331207145, disc_loss = 0.06622208517213059
Trained batch 321 in epoch 15, gen_loss = 0.4018325791780993, disc_loss = 0.06619615634608296
Trained batch 322 in epoch 15, gen_loss = 0.40166465333740775, disc_loss = 0.0661815110256682
Trained batch 323 in epoch 15, gen_loss = 0.4014915346547409, disc_loss = 0.06626352200278851
Trained batch 324 in epoch 15, gen_loss = 0.4014594378838172, disc_loss = 0.06609927936098897
Trained batch 325 in epoch 15, gen_loss = 0.40147713000423335, disc_loss = 0.06596189664042572
Trained batch 326 in epoch 15, gen_loss = 0.4013389924068334, disc_loss = 0.06580430049796672
Trained batch 327 in epoch 15, gen_loss = 0.40118768329663973, disc_loss = 0.0656634163971786
Trained batch 328 in epoch 15, gen_loss = 0.40109589587229, disc_loss = 0.06554174861845229
Trained batch 329 in epoch 15, gen_loss = 0.4012429621183511, disc_loss = 0.0654165628436727
Trained batch 330 in epoch 15, gen_loss = 0.4010680862603951, disc_loss = 0.0653194890616411
Trained batch 331 in epoch 15, gen_loss = 0.40096957837960806, disc_loss = 0.06522143450818103
Trained batch 332 in epoch 15, gen_loss = 0.4009188495061777, disc_loss = 0.06538672763546621
Trained batch 333 in epoch 15, gen_loss = 0.400614259307256, disc_loss = 0.06592208910370971
Trained batch 334 in epoch 15, gen_loss = 0.40057802458307634, disc_loss = 0.06590543547645211
Trained batch 335 in epoch 15, gen_loss = 0.4006896976026751, disc_loss = 0.06600349782716616
Trained batch 336 in epoch 15, gen_loss = 0.4004519067992089, disc_loss = 0.06599975335729538
Trained batch 337 in epoch 15, gen_loss = 0.40047329161646805, disc_loss = 0.06594329065444862
Trained batch 338 in epoch 15, gen_loss = 0.40046878611795317, disc_loss = 0.06577790026198578
Trained batch 339 in epoch 15, gen_loss = 0.40071975492379247, disc_loss = 0.06567115759449628
Trained batch 340 in epoch 15, gen_loss = 0.40068064765496686, disc_loss = 0.06569947348088244
Trained batch 341 in epoch 15, gen_loss = 0.40076622201336753, disc_loss = 0.06555641683673606
Trained batch 342 in epoch 15, gen_loss = 0.4009209850439177, disc_loss = 0.0654242330274216
Trained batch 343 in epoch 15, gen_loss = 0.4009334109723568, disc_loss = 0.06526731759131085
Trained batch 344 in epoch 15, gen_loss = 0.40102725158567015, disc_loss = 0.06518392954696564
Trained batch 345 in epoch 15, gen_loss = 0.4010058797336038, disc_loss = 0.065109454653888
Trained batch 346 in epoch 15, gen_loss = 0.4008698130203599, disc_loss = 0.06502107041149859
Trained batch 347 in epoch 15, gen_loss = 0.4007259663836709, disc_loss = 0.06493142120748886
Trained batch 348 in epoch 15, gen_loss = 0.40081187237299615, disc_loss = 0.06477715630207029
Trained batch 349 in epoch 15, gen_loss = 0.4007722728593009, disc_loss = 0.0646596154690321
Trained batch 350 in epoch 15, gen_loss = 0.40095244623996595, disc_loss = 0.06452203079384149
Trained batch 351 in epoch 15, gen_loss = 0.40098342240195384, disc_loss = 0.06455431021458935
Trained batch 352 in epoch 15, gen_loss = 0.4009311770751186, disc_loss = 0.06501090005383149
Trained batch 353 in epoch 15, gen_loss = 0.4008967989245377, disc_loss = 0.0651027437333691
Trained batch 354 in epoch 15, gen_loss = 0.4007456859232674, disc_loss = 0.06498428737010124
Trained batch 355 in epoch 15, gen_loss = 0.4008901844198784, disc_loss = 0.06492927179310806
Trained batch 356 in epoch 15, gen_loss = 0.40055460622664596, disc_loss = 0.06491440000972536
Trained batch 357 in epoch 15, gen_loss = 0.40039967724730846, disc_loss = 0.06476516927092976
Trained batch 358 in epoch 15, gen_loss = 0.4006664447465647, disc_loss = 0.06491487196317165
Trained batch 359 in epoch 15, gen_loss = 0.4003592163324356, disc_loss = 0.0651465480021822
Trained batch 360 in epoch 15, gen_loss = 0.40054942564290646, disc_loss = 0.06505518977419368
Trained batch 361 in epoch 15, gen_loss = 0.40085066221036963, disc_loss = 0.06489709646502788
Trained batch 362 in epoch 15, gen_loss = 0.40103531942879855, disc_loss = 0.06478243491153128
Trained batch 363 in epoch 15, gen_loss = 0.4011282279759973, disc_loss = 0.06463142837894119
Trained batch 364 in epoch 15, gen_loss = 0.4009778286496254, disc_loss = 0.06449343225191513
Trained batch 365 in epoch 15, gen_loss = 0.40098927312535665, disc_loss = 0.06436971854291286
Trained batch 366 in epoch 15, gen_loss = 0.40096566267819106, disc_loss = 0.06428764620795846
Trained batch 367 in epoch 15, gen_loss = 0.40080026423801546, disc_loss = 0.06414544676891124
Trained batch 368 in epoch 15, gen_loss = 0.40062654438380624, disc_loss = 0.06407406899275456
Trained batch 369 in epoch 15, gen_loss = 0.4003931319391405, disc_loss = 0.06419476076734026
Trained batch 370 in epoch 15, gen_loss = 0.40059514371853955, disc_loss = 0.06411062489637749
Trained batch 371 in epoch 15, gen_loss = 0.40086445300489343, disc_loss = 0.06409485539376375
Trained batch 372 in epoch 15, gen_loss = 0.4007914991544974, disc_loss = 0.06397209649446144
Trained batch 373 in epoch 15, gen_loss = 0.4006943112229281, disc_loss = 0.06398602257691882
Trained batch 374 in epoch 15, gen_loss = 0.4008108133474986, disc_loss = 0.06443229636922479
Trained batch 375 in epoch 15, gen_loss = 0.40072066130790307, disc_loss = 0.0643317840753143
Trained batch 376 in epoch 15, gen_loss = 0.4006145235239985, disc_loss = 0.06428835314108103
Trained batch 377 in epoch 15, gen_loss = 0.4004419043108269, disc_loss = 0.06429456040711591
Trained batch 378 in epoch 15, gen_loss = 0.40025393055422637, disc_loss = 0.06429917758851654
Trained batch 379 in epoch 15, gen_loss = 0.40038458775532876, disc_loss = 0.06416835158597678
Trained batch 380 in epoch 15, gen_loss = 0.40036657585559554, disc_loss = 0.06410135573333525
Trained batch 381 in epoch 15, gen_loss = 0.40034315840424045, disc_loss = 0.06402229199902744
Trained batch 382 in epoch 15, gen_loss = 0.40021163590894354, disc_loss = 0.06402139848234331
Trained batch 383 in epoch 15, gen_loss = 0.4001820622943342, disc_loss = 0.06391309638881164
Trained batch 384 in epoch 15, gen_loss = 0.3999520986111133, disc_loss = 0.06390752674914993
Trained batch 385 in epoch 15, gen_loss = 0.4000506365546291, disc_loss = 0.06407614101153929
Trained batch 386 in epoch 15, gen_loss = 0.4001299039646021, disc_loss = 0.06399262206176493
Trained batch 387 in epoch 15, gen_loss = 0.40001106792196783, disc_loss = 0.0639767477675293
Trained batch 388 in epoch 15, gen_loss = 0.40008139464726483, disc_loss = 0.06386747662873417
Trained batch 389 in epoch 15, gen_loss = 0.4002466042072345, disc_loss = 0.0637731580171161
Trained batch 390 in epoch 15, gen_loss = 0.40024990224472395, disc_loss = 0.06364043174035218
Trained batch 391 in epoch 15, gen_loss = 0.4002434092060644, disc_loss = 0.0635274120176458
Trained batch 392 in epoch 15, gen_loss = 0.4002847558517796, disc_loss = 0.06341619866262675
Trained batch 393 in epoch 15, gen_loss = 0.40027145398449776, disc_loss = 0.0633467621522185
Trained batch 394 in epoch 15, gen_loss = 0.4001685845701, disc_loss = 0.06352678657969153
Trained batch 395 in epoch 15, gen_loss = 0.40024545788764954, disc_loss = 0.0636935346193066
Trained batch 396 in epoch 15, gen_loss = 0.4002669027230001, disc_loss = 0.06355048833949778
Trained batch 397 in epoch 15, gen_loss = 0.39999250506036843, disc_loss = 0.06343433789408125
Trained batch 398 in epoch 15, gen_loss = 0.3999544367156829, disc_loss = 0.06338244381204322
Trained batch 399 in epoch 15, gen_loss = 0.4000082729756832, disc_loss = 0.06349276009597815
Trained batch 400 in epoch 15, gen_loss = 0.39988943979032615, disc_loss = 0.06390334854942939
Trained batch 401 in epoch 15, gen_loss = 0.40008254260269566, disc_loss = 0.06384755793926468
Trained batch 402 in epoch 15, gen_loss = 0.39995676774540845, disc_loss = 0.063897416740887
Trained batch 403 in epoch 15, gen_loss = 0.40001736478050154, disc_loss = 0.06376138520957257
Trained batch 404 in epoch 15, gen_loss = 0.3999361389213138, disc_loss = 0.06368405240024498
Trained batch 405 in epoch 15, gen_loss = 0.39987057997968983, disc_loss = 0.06361210325691537
Trained batch 406 in epoch 15, gen_loss = 0.3998571387526444, disc_loss = 0.06367750807850638
Trained batch 407 in epoch 15, gen_loss = 0.3997698316679281, disc_loss = 0.06383572856315832
Trained batch 408 in epoch 15, gen_loss = 0.39975248565009286, disc_loss = 0.06398012659974706
Trained batch 409 in epoch 15, gen_loss = 0.39984839580407955, disc_loss = 0.06399290686723118
Trained batch 410 in epoch 15, gen_loss = 0.39963005232985005, disc_loss = 0.06419589428158608
Trained batch 411 in epoch 15, gen_loss = 0.399473132728373, disc_loss = 0.06421107601360825
Trained batch 412 in epoch 15, gen_loss = 0.3996030362119975, disc_loss = 0.06414129489076664
Trained batch 413 in epoch 15, gen_loss = 0.39963238531552653, disc_loss = 0.06416636490901922
Trained batch 414 in epoch 15, gen_loss = 0.399289255831615, disc_loss = 0.0644113170959235
Trained batch 415 in epoch 15, gen_loss = 0.3992954675967877, disc_loss = 0.06428979388818754
Trained batch 416 in epoch 15, gen_loss = 0.3993508527033049, disc_loss = 0.06417104565790839
Trained batch 417 in epoch 15, gen_loss = 0.3993321819738908, disc_loss = 0.06405509776284285
Trained batch 418 in epoch 15, gen_loss = 0.3996549752276382, disc_loss = 0.06393665245451868
Trained batch 419 in epoch 15, gen_loss = 0.3994853226201875, disc_loss = 0.06382744328584522
Trained batch 420 in epoch 15, gen_loss = 0.39945091402728883, disc_loss = 0.0637083338350146
Trained batch 421 in epoch 15, gen_loss = 0.39924494900974616, disc_loss = 0.06363486688500226
Trained batch 422 in epoch 15, gen_loss = 0.3991153066885387, disc_loss = 0.06354654872411285
Trained batch 423 in epoch 15, gen_loss = 0.3992284109710522, disc_loss = 0.06370193670824487
Trained batch 424 in epoch 15, gen_loss = 0.39903316259384153, disc_loss = 0.06376764475970584
Trained batch 425 in epoch 15, gen_loss = 0.39905757523478474, disc_loss = 0.06364770837569775
Trained batch 426 in epoch 15, gen_loss = 0.39903824970091256, disc_loss = 0.06363819589820936
Trained batch 427 in epoch 15, gen_loss = 0.3988251787758319, disc_loss = 0.06363360895057182
Trained batch 428 in epoch 15, gen_loss = 0.39894460270176957, disc_loss = 0.06350389250938396
Trained batch 429 in epoch 15, gen_loss = 0.399033016312954, disc_loss = 0.06337871731172294
Trained batch 430 in epoch 15, gen_loss = 0.3989335389120673, disc_loss = 0.06343578570900515
Trained batch 431 in epoch 15, gen_loss = 0.3988826044455723, disc_loss = 0.0639735016469516
Trained batch 432 in epoch 15, gen_loss = 0.3991596009109092, disc_loss = 0.0640423220913539
Trained batch 433 in epoch 15, gen_loss = 0.3994050909022582, disc_loss = 0.06392892781958362
Trained batch 434 in epoch 15, gen_loss = 0.39931237670196884, disc_loss = 0.06381844242007054
Trained batch 435 in epoch 15, gen_loss = 0.39940816396420153, disc_loss = 0.06372819983703724
Trained batch 436 in epoch 15, gen_loss = 0.3993429610467339, disc_loss = 0.06363162897991814
Trained batch 437 in epoch 15, gen_loss = 0.3994334030505185, disc_loss = 0.06351775157724647
Trained batch 438 in epoch 15, gen_loss = 0.3992700169461192, disc_loss = 0.06356185342552212
Trained batch 439 in epoch 15, gen_loss = 0.39938638366081497, disc_loss = 0.06343345219290561
Trained batch 440 in epoch 15, gen_loss = 0.3993891153881609, disc_loss = 0.06394449468224801
Trained batch 441 in epoch 15, gen_loss = 0.3991792917386439, disc_loss = 0.06413393694068815
Trained batch 442 in epoch 15, gen_loss = 0.39919417874538604, disc_loss = 0.06409317262273105
Trained batch 443 in epoch 15, gen_loss = 0.39914628722377726, disc_loss = 0.06402404358514023
Trained batch 444 in epoch 15, gen_loss = 0.39914299772026834, disc_loss = 0.06393467381784923
Trained batch 445 in epoch 15, gen_loss = 0.3991761778234901, disc_loss = 0.06383748846274755
Trained batch 446 in epoch 15, gen_loss = 0.39904222432398956, disc_loss = 0.06384082707853558
Trained batch 447 in epoch 15, gen_loss = 0.3992297995968589, disc_loss = 0.06377781235018379
Trained batch 448 in epoch 15, gen_loss = 0.3993724123274032, disc_loss = 0.06370207908893116
Trained batch 449 in epoch 15, gen_loss = 0.3993761291106542, disc_loss = 0.06364843968819413
Trained batch 450 in epoch 15, gen_loss = 0.3994096949729581, disc_loss = 0.06364119067858334
Trained batch 451 in epoch 15, gen_loss = 0.3994044375366869, disc_loss = 0.06359121245558712
Trained batch 452 in epoch 15, gen_loss = 0.3994080331546581, disc_loss = 0.06347145090315483
Trained batch 453 in epoch 15, gen_loss = 0.3997011004171708, disc_loss = 0.06352229220567
Trained batch 454 in epoch 15, gen_loss = 0.3995437651545137, disc_loss = 0.0634263943379315
Trained batch 455 in epoch 15, gen_loss = 0.39942326841124315, disc_loss = 0.06361578089867212
Trained batch 456 in epoch 15, gen_loss = 0.3997243174577959, disc_loss = 0.06359662913107995
Trained batch 457 in epoch 15, gen_loss = 0.3997821308119328, disc_loss = 0.06359091514465297
Trained batch 458 in epoch 15, gen_loss = 0.39959315556326724, disc_loss = 0.0639623798265615
Testing Epoch 15
Training Epoch 16
Trained batch 0 in epoch 16, gen_loss = 0.3538532257080078, disc_loss = 0.4569454789161682
Trained batch 1 in epoch 16, gen_loss = 0.3558656573295593, disc_loss = 0.30882275849580765
Trained batch 2 in epoch 16, gen_loss = 0.3791845937569936, disc_loss = 0.2581291198730469
Trained batch 3 in epoch 16, gen_loss = 0.38610218465328217, disc_loss = 0.22552631795406342
Trained batch 4 in epoch 16, gen_loss = 0.37735665440559385, disc_loss = 0.21911069750785828
Trained batch 5 in epoch 16, gen_loss = 0.37561894953250885, disc_loss = 0.2421891043583552
Trained batch 6 in epoch 16, gen_loss = 0.3772375243050711, disc_loss = 0.2455328447478158
Trained batch 7 in epoch 16, gen_loss = 0.36944958195090294, disc_loss = 0.2346423789858818
Trained batch 8 in epoch 16, gen_loss = 0.36381176114082336, disc_loss = 0.2294626533985138
Trained batch 9 in epoch 16, gen_loss = 0.3633527815341949, disc_loss = 0.22025544345378875
Trained batch 10 in epoch 16, gen_loss = 0.3642470646988262, disc_loss = 0.21299524469809097
Trained batch 11 in epoch 16, gen_loss = 0.36344195902347565, disc_loss = 0.20955570538838705
Trained batch 12 in epoch 16, gen_loss = 0.3626483128621028, disc_loss = 0.20352610257955697
Trained batch 13 in epoch 16, gen_loss = 0.36462278025490896, disc_loss = 0.20039692095347814
Trained batch 14 in epoch 16, gen_loss = 0.3664247234662374, disc_loss = 0.19291587968667348
Trained batch 15 in epoch 16, gen_loss = 0.3711673188954592, disc_loss = 0.18811845500022173
Trained batch 16 in epoch 16, gen_loss = 0.3758200862828423, disc_loss = 0.18469652095261743
Trained batch 17 in epoch 16, gen_loss = 0.3743491801950667, disc_loss = 0.18106011301279068
Trained batch 18 in epoch 16, gen_loss = 0.376348686845679, disc_loss = 0.17751998258264443
Trained batch 19 in epoch 16, gen_loss = 0.37722260057926177, disc_loss = 0.18132290318608285
Trained batch 20 in epoch 16, gen_loss = 0.3727605314481826, disc_loss = 0.17946508668717884
Trained batch 21 in epoch 16, gen_loss = 0.3724568079818379, disc_loss = 0.17394403131170708
Trained batch 22 in epoch 16, gen_loss = 0.3777679321558579, disc_loss = 0.1684542202755161
Trained batch 23 in epoch 16, gen_loss = 0.3748534731566906, disc_loss = 0.16774455783888698
Trained batch 24 in epoch 16, gen_loss = 0.37500202775001523, disc_loss = 0.1641820453107357
Trained batch 25 in epoch 16, gen_loss = 0.3754015438831769, disc_loss = 0.15989473949258143
Trained batch 26 in epoch 16, gen_loss = 0.37440508714428655, disc_loss = 0.15661793340135505
Trained batch 27 in epoch 16, gen_loss = 0.3759578008736883, disc_loss = 0.1516251669132284
Trained batch 28 in epoch 16, gen_loss = 0.377219884560026, disc_loss = 0.14780338635218554
Trained batch 29 in epoch 16, gen_loss = 0.3752682973941167, disc_loss = 0.14456237442791461
Trained batch 30 in epoch 16, gen_loss = 0.3769692317132027, disc_loss = 0.14311491469702414
Trained batch 31 in epoch 16, gen_loss = 0.37719865422695875, disc_loss = 0.13999742968007922
Trained batch 32 in epoch 16, gen_loss = 0.37738435738014453, disc_loss = 0.1421399595159473
Trained batch 33 in epoch 16, gen_loss = 0.37525999809012694, disc_loss = 0.14736140563207514
Trained batch 34 in epoch 16, gen_loss = 0.37540765830448697, disc_loss = 0.14636104660374777
Trained batch 35 in epoch 16, gen_loss = 0.37737033598952824, disc_loss = 0.14592420102821457
Trained batch 36 in epoch 16, gen_loss = 0.3758233560098184, disc_loss = 0.1451037930878433
Trained batch 37 in epoch 16, gen_loss = 0.3748629336294375, disc_loss = 0.14354793668577545
Trained batch 38 in epoch 16, gen_loss = 0.37347737183937657, disc_loss = 0.14124717305486018
Trained batch 39 in epoch 16, gen_loss = 0.37573477923870086, disc_loss = 0.13894029771909117
Trained batch 40 in epoch 16, gen_loss = 0.37355361042953117, disc_loss = 0.13717539181433072
Trained batch 41 in epoch 16, gen_loss = 0.3731816921915327, disc_loss = 0.13575412412839277
Trained batch 42 in epoch 16, gen_loss = 0.3744248359702354, disc_loss = 0.1337043470594772
Trained batch 43 in epoch 16, gen_loss = 0.3755826902660457, disc_loss = 0.13474094266579908
Trained batch 44 in epoch 16, gen_loss = 0.3740027685960134, disc_loss = 0.13953554506103197
Trained batch 45 in epoch 16, gen_loss = 0.37492708084375964, disc_loss = 0.1371522655143686
Trained batch 46 in epoch 16, gen_loss = 0.37634239678687237, disc_loss = 0.139197485164759
Trained batch 47 in epoch 16, gen_loss = 0.37435484677553177, disc_loss = 0.13848025312957665
Trained batch 48 in epoch 16, gen_loss = 0.37354459628766895, disc_loss = 0.13681758225572352
Trained batch 49 in epoch 16, gen_loss = 0.3752570480108261, disc_loss = 0.13469581715762616
Trained batch 50 in epoch 16, gen_loss = 0.3766038534688015, disc_loss = 0.13311150107605785
Trained batch 51 in epoch 16, gen_loss = 0.37729384463567, disc_loss = 0.1311861936432811
Trained batch 52 in epoch 16, gen_loss = 0.37571690892273524, disc_loss = 0.12987946023075086
Trained batch 53 in epoch 16, gen_loss = 0.37569973093492015, disc_loss = 0.1287623047138806
Trained batch 54 in epoch 16, gen_loss = 0.37669992609457537, disc_loss = 0.13037720640951936
Trained batch 55 in epoch 16, gen_loss = 0.3766208163329533, disc_loss = 0.12841149705595203
Trained batch 56 in epoch 16, gen_loss = 0.3757393281710775, disc_loss = 0.12921510734840444
Trained batch 57 in epoch 16, gen_loss = 0.3768295167848982, disc_loss = 0.12780387179347977
Trained batch 58 in epoch 16, gen_loss = 0.3783938303842383, disc_loss = 0.12664600714283475
Trained batch 59 in epoch 16, gen_loss = 0.378818491101265, disc_loss = 0.12501328941434622
Trained batch 60 in epoch 16, gen_loss = 0.379391007736081, disc_loss = 0.12327949192802437
Trained batch 61 in epoch 16, gen_loss = 0.3789128689996658, disc_loss = 0.1218476622635799
Trained batch 62 in epoch 16, gen_loss = 0.3790561168912857, disc_loss = 0.12027870482277303
Trained batch 63 in epoch 16, gen_loss = 0.3794086608104408, disc_loss = 0.11921560278278776
Trained batch 64 in epoch 16, gen_loss = 0.37954572760141814, disc_loss = 0.11910042066413623
Trained batch 65 in epoch 16, gen_loss = 0.3801154909711896, disc_loss = 0.1190116736529903
Trained batch 66 in epoch 16, gen_loss = 0.38005193400738846, disc_loss = 0.11810260847099681
Trained batch 67 in epoch 16, gen_loss = 0.38116832866388206, disc_loss = 0.11800490037592895
Trained batch 68 in epoch 16, gen_loss = 0.3801305160142373, disc_loss = 0.12195889438515987
Trained batch 69 in epoch 16, gen_loss = 0.3818294810397284, disc_loss = 0.12109432547752347
Trained batch 70 in epoch 16, gen_loss = 0.38248326954707296, disc_loss = 0.11994598011000895
Trained batch 71 in epoch 16, gen_loss = 0.3813839356104533, disc_loss = 0.11957975986620618
Trained batch 72 in epoch 16, gen_loss = 0.3816634379837611, disc_loss = 0.11922658788525078
Trained batch 73 in epoch 16, gen_loss = 0.3813091448029956, disc_loss = 0.11799651437212487
Trained batch 74 in epoch 16, gen_loss = 0.3812973662217458, disc_loss = 0.11692695421477159
Trained batch 75 in epoch 16, gen_loss = 0.3822070254307044, disc_loss = 0.1157906106918266
Trained batch 76 in epoch 16, gen_loss = 0.3821031242221981, disc_loss = 0.11512025440861652
Trained batch 77 in epoch 16, gen_loss = 0.38288636085314626, disc_loss = 0.11499561651203877
Trained batch 78 in epoch 16, gen_loss = 0.382577510574196, disc_loss = 0.11509641283486463
Trained batch 79 in epoch 16, gen_loss = 0.38290387094020845, disc_loss = 0.11427896926179529
Trained batch 80 in epoch 16, gen_loss = 0.3828900162084603, disc_loss = 0.11433286826919627
Trained batch 81 in epoch 16, gen_loss = 0.383308223107966, disc_loss = 0.11587376629070538
Trained batch 82 in epoch 16, gen_loss = 0.38336056794028683, disc_loss = 0.11511330266135285
Trained batch 83 in epoch 16, gen_loss = 0.3835859309349741, disc_loss = 0.11392959406865495
Trained batch 84 in epoch 16, gen_loss = 0.3823538499719956, disc_loss = 0.11401846395695911
Trained batch 85 in epoch 16, gen_loss = 0.38352072100306667, disc_loss = 0.11373480560994426
Trained batch 86 in epoch 16, gen_loss = 0.38386053257975083, disc_loss = 0.11313047187252977
Trained batch 87 in epoch 16, gen_loss = 0.3841924477707256, disc_loss = 0.11201284628954124
Trained batch 88 in epoch 16, gen_loss = 0.38463773888148617, disc_loss = 0.11138820461928844
Trained batch 89 in epoch 16, gen_loss = 0.3849554548660914, disc_loss = 0.1107970498295294
Trained batch 90 in epoch 16, gen_loss = 0.383896889594885, disc_loss = 0.11081533312060676
Trained batch 91 in epoch 16, gen_loss = 0.3847246493982232, disc_loss = 0.11172642783545282
Trained batch 92 in epoch 16, gen_loss = 0.3848942329165756, disc_loss = 0.11093835518645342
Trained batch 93 in epoch 16, gen_loss = 0.38474199587994434, disc_loss = 0.11002210925947478
Trained batch 94 in epoch 16, gen_loss = 0.3846241671788065, disc_loss = 0.10902750007808208
Trained batch 95 in epoch 16, gen_loss = 0.3849973489219944, disc_loss = 0.10815677591987576
Trained batch 96 in epoch 16, gen_loss = 0.3851739954702633, disc_loss = 0.1072526280528184
Trained batch 97 in epoch 16, gen_loss = 0.385959298026805, disc_loss = 0.10650132092818314
Trained batch 98 in epoch 16, gen_loss = 0.3850900717455931, disc_loss = 0.10611952688883651
Trained batch 99 in epoch 16, gen_loss = 0.38561319559812546, disc_loss = 0.10609280778095126
Trained batch 100 in epoch 16, gen_loss = 0.38494108366494134, disc_loss = 0.10720800982769763
Trained batch 101 in epoch 16, gen_loss = 0.38559123610748963, disc_loss = 0.10723854489989725
Trained batch 102 in epoch 16, gen_loss = 0.38645207505781676, disc_loss = 0.1062932556621658
Trained batch 103 in epoch 16, gen_loss = 0.3867139827746611, disc_loss = 0.10543255914504138
Trained batch 104 in epoch 16, gen_loss = 0.38630193046161104, disc_loss = 0.10458891686229478
Trained batch 105 in epoch 16, gen_loss = 0.3865078378398463, disc_loss = 0.10375259992367816
Trained batch 106 in epoch 16, gen_loss = 0.3868597005015222, disc_loss = 0.10299406695031674
Trained batch 107 in epoch 16, gen_loss = 0.3871600862454485, disc_loss = 0.10213147484938856
Trained batch 108 in epoch 16, gen_loss = 0.3875857129556323, disc_loss = 0.10125237185114977
Trained batch 109 in epoch 16, gen_loss = 0.3883901512080973, disc_loss = 0.10072879020378671
Trained batch 110 in epoch 16, gen_loss = 0.3882093383922233, disc_loss = 0.10013583995116589
Trained batch 111 in epoch 16, gen_loss = 0.3882771786302328, disc_loss = 0.09950927682803012
Trained batch 112 in epoch 16, gen_loss = 0.38898301256441437, disc_loss = 0.09908524812899727
Trained batch 113 in epoch 16, gen_loss = 0.38893446221686245, disc_loss = 0.09833003384093836
Trained batch 114 in epoch 16, gen_loss = 0.38929293207500293, disc_loss = 0.09817543787395824
Trained batch 115 in epoch 16, gen_loss = 0.38992916484331264, disc_loss = 0.09834988710293867
Trained batch 116 in epoch 16, gen_loss = 0.38991941855503964, disc_loss = 0.09757575662169829
Trained batch 117 in epoch 16, gen_loss = 0.3895129134594384, disc_loss = 0.09720677881249053
Trained batch 118 in epoch 16, gen_loss = 0.38951953469204303, disc_loss = 0.09648985666528094
Trained batch 119 in epoch 16, gen_loss = 0.39025540500879285, disc_loss = 0.09622417651504898
Trained batch 120 in epoch 16, gen_loss = 0.3897263639229388, disc_loss = 0.09735535307256274
Trained batch 121 in epoch 16, gen_loss = 0.39005836844444275, disc_loss = 0.0970545024572887
Trained batch 122 in epoch 16, gen_loss = 0.3901001990326052, disc_loss = 0.09643941129201918
Trained batch 123 in epoch 16, gen_loss = 0.3895421621780242, disc_loss = 0.09619584756587903
Trained batch 124 in epoch 16, gen_loss = 0.38979676556587217, disc_loss = 0.09587870727851987
Trained batch 125 in epoch 16, gen_loss = 0.39082007204729413, disc_loss = 0.09647033267861439
Trained batch 126 in epoch 16, gen_loss = 0.39102963997623114, disc_loss = 0.09684071847142314
Trained batch 127 in epoch 16, gen_loss = 0.3910246044397354, disc_loss = 0.09633279867193778
Trained batch 128 in epoch 16, gen_loss = 0.3907566077487413, disc_loss = 0.09623528660686556
Trained batch 129 in epoch 16, gen_loss = 0.3904107494996144, disc_loss = 0.09676340751421567
Trained batch 130 in epoch 16, gen_loss = 0.39066928761605996, disc_loss = 0.09639744263298752
Trained batch 131 in epoch 16, gen_loss = 0.39054383518117847, disc_loss = 0.09575258809579254
Trained batch 132 in epoch 16, gen_loss = 0.3910020029634461, disc_loss = 0.09529414587072972
Trained batch 133 in epoch 16, gen_loss = 0.39143325566355863, disc_loss = 0.0956147287993122
Trained batch 134 in epoch 16, gen_loss = 0.391111746540776, disc_loss = 0.095495106159123
Trained batch 135 in epoch 16, gen_loss = 0.3905317399869947, disc_loss = 0.09517309309654486
Trained batch 136 in epoch 16, gen_loss = 0.39061026242527647, disc_loss = 0.09476742740163077
Trained batch 137 in epoch 16, gen_loss = 0.39057877314263495, disc_loss = 0.09449636711118121
Trained batch 138 in epoch 16, gen_loss = 0.39043086681434575, disc_loss = 0.09425149436222671
Trained batch 139 in epoch 16, gen_loss = 0.3902169642703874, disc_loss = 0.09395790764330221
Trained batch 140 in epoch 16, gen_loss = 0.39005716324698, disc_loss = 0.0937683144154965
Trained batch 141 in epoch 16, gen_loss = 0.3903366377655889, disc_loss = 0.09323359332309747
Trained batch 142 in epoch 16, gen_loss = 0.3900918402038254, disc_loss = 0.09326847151924784
Trained batch 143 in epoch 16, gen_loss = 0.38990623338354957, disc_loss = 0.09376380917577383
Trained batch 144 in epoch 16, gen_loss = 0.3906159583864541, disc_loss = 0.09376228039698868
Trained batch 145 in epoch 16, gen_loss = 0.39117503554037175, disc_loss = 0.09354829496372338
Trained batch 146 in epoch 16, gen_loss = 0.3911862399707846, disc_loss = 0.09385790380959709
Trained batch 147 in epoch 16, gen_loss = 0.39164630706245834, disc_loss = 0.09332881982727731
Trained batch 148 in epoch 16, gen_loss = 0.39245740839298937, disc_loss = 0.09341700094120714
Trained batch 149 in epoch 16, gen_loss = 0.3923865892489751, disc_loss = 0.09305686207177738
Trained batch 150 in epoch 16, gen_loss = 0.3924599477392159, disc_loss = 0.09270847390486014
Trained batch 151 in epoch 16, gen_loss = 0.39271103845615135, disc_loss = 0.0922235044877437
Trained batch 152 in epoch 16, gen_loss = 0.3934626896786534, disc_loss = 0.09174089818231128
Trained batch 153 in epoch 16, gen_loss = 0.39347490803761914, disc_loss = 0.09211580196770465
Trained batch 154 in epoch 16, gen_loss = 0.3926824694679629, disc_loss = 0.09308913102854163
Trained batch 155 in epoch 16, gen_loss = 0.39299686004718143, disc_loss = 0.09283622674560413
Trained batch 156 in epoch 16, gen_loss = 0.39320791773735336, disc_loss = 0.09377049674001184
Trained batch 157 in epoch 16, gen_loss = 0.39320510342905796, disc_loss = 0.09333159307996401
Trained batch 158 in epoch 16, gen_loss = 0.3929192620628285, disc_loss = 0.09334877653797187
Trained batch 159 in epoch 16, gen_loss = 0.3931239014491439, disc_loss = 0.09288444670673926
Trained batch 160 in epoch 16, gen_loss = 0.39317432101468863, disc_loss = 0.09252679970705453
Trained batch 161 in epoch 16, gen_loss = 0.3928696286899072, disc_loss = 0.09236173679258812
Trained batch 162 in epoch 16, gen_loss = 0.3928146940067502, disc_loss = 0.09190599144110742
Trained batch 163 in epoch 16, gen_loss = 0.392996291743546, disc_loss = 0.09158984177870812
Trained batch 164 in epoch 16, gen_loss = 0.392696440039259, disc_loss = 0.091549632780141
Trained batch 165 in epoch 16, gen_loss = 0.3929667833698801, disc_loss = 0.09196679475044
Trained batch 166 in epoch 16, gen_loss = 0.392390885217461, disc_loss = 0.09155960623342209
Trained batch 167 in epoch 16, gen_loss = 0.3923938538701761, disc_loss = 0.09135841324626069
Trained batch 168 in epoch 16, gen_loss = 0.39284500338622097, disc_loss = 0.09140504900222787
Trained batch 169 in epoch 16, gen_loss = 0.3929336337482228, disc_loss = 0.09118267086553661
Trained batch 170 in epoch 16, gen_loss = 0.39303391579298946, disc_loss = 0.09082196488682377
Trained batch 171 in epoch 16, gen_loss = 0.3931293478885362, disc_loss = 0.0903810518983275
Trained batch 172 in epoch 16, gen_loss = 0.39298511068255915, disc_loss = 0.09021586684423978
Trained batch 173 in epoch 16, gen_loss = 0.3929924872414819, disc_loss = 0.09114321608942044
Trained batch 174 in epoch 16, gen_loss = 0.3930014862333025, disc_loss = 0.09101539880835584
Trained batch 175 in epoch 16, gen_loss = 0.3929625548083674, disc_loss = 0.09082602636243048
Trained batch 176 in epoch 16, gen_loss = 0.393188409717743, disc_loss = 0.09087446974695655
Trained batch 177 in epoch 16, gen_loss = 0.39339797098315166, disc_loss = 0.0906285316542084
Trained batch 178 in epoch 16, gen_loss = 0.3932432037825025, disc_loss = 0.09020161914623566
Trained batch 179 in epoch 16, gen_loss = 0.39336638980441624, disc_loss = 0.08973391474379848
Trained batch 180 in epoch 16, gen_loss = 0.39347388665320465, disc_loss = 0.08938101286233212
Trained batch 181 in epoch 16, gen_loss = 0.3938459143206313, disc_loss = 0.08896415840558053
Trained batch 182 in epoch 16, gen_loss = 0.3935247669454481, disc_loss = 0.08860363481729164
Trained batch 183 in epoch 16, gen_loss = 0.39360198524335155, disc_loss = 0.08817658441029894
Trained batch 184 in epoch 16, gen_loss = 0.3936822498166883, disc_loss = 0.08782272349187248
Trained batch 185 in epoch 16, gen_loss = 0.39373761335367796, disc_loss = 0.08776913693685445
Trained batch 186 in epoch 16, gen_loss = 0.3939642796223176, disc_loss = 0.08808402189447041
Trained batch 187 in epoch 16, gen_loss = 0.39389948103022066, disc_loss = 0.08834056356337239
Trained batch 188 in epoch 16, gen_loss = 0.39414759540053274, disc_loss = 0.08842330077347696
Trained batch 189 in epoch 16, gen_loss = 0.3941794213495756, disc_loss = 0.08800109707456279
Trained batch 190 in epoch 16, gen_loss = 0.3943598306303873, disc_loss = 0.08764281370847715
Trained batch 191 in epoch 16, gen_loss = 0.3942828648723662, disc_loss = 0.08732709973749782
Trained batch 192 in epoch 16, gen_loss = 0.39417177485060817, disc_loss = 0.08703902543527244
Trained batch 193 in epoch 16, gen_loss = 0.3939646503974482, disc_loss = 0.08696953132604585
Trained batch 194 in epoch 16, gen_loss = 0.3942093204229306, disc_loss = 0.08661782195409522
Trained batch 195 in epoch 16, gen_loss = 0.3943556411838045, disc_loss = 0.08644962231200949
Trained batch 196 in epoch 16, gen_loss = 0.39470507817219963, disc_loss = 0.08610292005253398
Trained batch 197 in epoch 16, gen_loss = 0.3950743797150525, disc_loss = 0.08585176825043604
Trained batch 198 in epoch 16, gen_loss = 0.39440326070665715, disc_loss = 0.08608977980771332
Trained batch 199 in epoch 16, gen_loss = 0.39462229937314985, disc_loss = 0.08625681651057676
Trained batch 200 in epoch 16, gen_loss = 0.39433631315753237, disc_loss = 0.08587146040969598
Trained batch 201 in epoch 16, gen_loss = 0.39419651518363763, disc_loss = 0.08591610302291072
Trained batch 202 in epoch 16, gen_loss = 0.394266994275483, disc_loss = 0.08576098991227635
Trained batch 203 in epoch 16, gen_loss = 0.3945543219645818, disc_loss = 0.08538324152822514
Trained batch 204 in epoch 16, gen_loss = 0.39465574375013024, disc_loss = 0.08518486221707085
Trained batch 205 in epoch 16, gen_loss = 0.3945785059222897, disc_loss = 0.08493176188310879
Trained batch 206 in epoch 16, gen_loss = 0.3947431862642224, disc_loss = 0.08465798564282233
Trained batch 207 in epoch 16, gen_loss = 0.3948840222393091, disc_loss = 0.08430636309472342
Trained batch 208 in epoch 16, gen_loss = 0.3947366280704024, disc_loss = 0.08416044154832737
Trained batch 209 in epoch 16, gen_loss = 0.39494775519484565, disc_loss = 0.08401359524356113
Trained batch 210 in epoch 16, gen_loss = 0.3952241801255122, disc_loss = 0.08370130216720474
Trained batch 211 in epoch 16, gen_loss = 0.3952962254297058, disc_loss = 0.0839425700097257
Trained batch 212 in epoch 16, gen_loss = 0.394892586508827, disc_loss = 0.08501972370680438
Trained batch 213 in epoch 16, gen_loss = 0.39490233041415707, disc_loss = 0.08476393927262973
Trained batch 214 in epoch 16, gen_loss = 0.39498178834138914, disc_loss = 0.08469273323019923
Trained batch 215 in epoch 16, gen_loss = 0.3948984118523421, disc_loss = 0.08468122179921786
Trained batch 216 in epoch 16, gen_loss = 0.39445934592304144, disc_loss = 0.08469061821072538
Trained batch 217 in epoch 16, gen_loss = 0.3945878282052661, disc_loss = 0.0844087496105103
Trained batch 218 in epoch 16, gen_loss = 0.39394225363862023, disc_loss = 0.08434836110355307
Trained batch 219 in epoch 16, gen_loss = 0.3937864458019083, disc_loss = 0.08480498011604967
Trained batch 220 in epoch 16, gen_loss = 0.393527342588114, disc_loss = 0.08476846820013219
Trained batch 221 in epoch 16, gen_loss = 0.3937165129023629, disc_loss = 0.08443422660206419
Trained batch 222 in epoch 16, gen_loss = 0.3938579908133622, disc_loss = 0.08415899390872618
Trained batch 223 in epoch 16, gen_loss = 0.3940275145162429, disc_loss = 0.08388181203918066
Trained batch 224 in epoch 16, gen_loss = 0.3934465715620253, disc_loss = 0.08412543820217251
Trained batch 225 in epoch 16, gen_loss = 0.39361640863713965, disc_loss = 0.08464553886488806
Trained batch 226 in epoch 16, gen_loss = 0.39355650832999645, disc_loss = 0.08448314012155463
Trained batch 227 in epoch 16, gen_loss = 0.3936028760253337, disc_loss = 0.08426001066905692
Trained batch 228 in epoch 16, gen_loss = 0.39374923758111147, disc_loss = 0.08402371806129162
Trained batch 229 in epoch 16, gen_loss = 0.3938939021981281, disc_loss = 0.0837537395261714
Trained batch 230 in epoch 16, gen_loss = 0.3939944083814497, disc_loss = 0.08351537370973658
Trained batch 231 in epoch 16, gen_loss = 0.39373336989304114, disc_loss = 0.08335790643669215
Trained batch 232 in epoch 16, gen_loss = 0.39386168940896127, disc_loss = 0.08370180608896546
Trained batch 233 in epoch 16, gen_loss = 0.39374848257782114, disc_loss = 0.08353123815658574
Trained batch 234 in epoch 16, gen_loss = 0.39372288660800203, disc_loss = 0.08342983445469686
Trained batch 235 in epoch 16, gen_loss = 0.3940855175004167, disc_loss = 0.08325762246632791
Trained batch 236 in epoch 16, gen_loss = 0.39444492436662504, disc_loss = 0.08301986238569461
Trained batch 237 in epoch 16, gen_loss = 0.3942403376352887, disc_loss = 0.08285246800607805
Trained batch 238 in epoch 16, gen_loss = 0.3946766196185076, disc_loss = 0.08253402236038546
Trained batch 239 in epoch 16, gen_loss = 0.39483792148530483, disc_loss = 0.08264401944276566
Trained batch 240 in epoch 16, gen_loss = 0.394659128179194, disc_loss = 0.08326724138791013
Trained batch 241 in epoch 16, gen_loss = 0.394922258440128, disc_loss = 0.08363703457823346
Trained batch 242 in epoch 16, gen_loss = 0.39457657577569594, disc_loss = 0.08345777556346154
Trained batch 243 in epoch 16, gen_loss = 0.394399529719939, disc_loss = 0.08341652911812922
Trained batch 244 in epoch 16, gen_loss = 0.3940977546633506, disc_loss = 0.08330042118548739
Trained batch 245 in epoch 16, gen_loss = 0.39398351057273584, disc_loss = 0.08303897124071552
Trained batch 246 in epoch 16, gen_loss = 0.3939772056423218, disc_loss = 0.08293093682496774
Trained batch 247 in epoch 16, gen_loss = 0.3941829364386297, disc_loss = 0.08287424376730117
Trained batch 248 in epoch 16, gen_loss = 0.39390296785228224, disc_loss = 0.08374696190891616
Trained batch 249 in epoch 16, gen_loss = 0.3942096556425095, disc_loss = 0.08375560807064175
Trained batch 250 in epoch 16, gen_loss = 0.3947488172833188, disc_loss = 0.0836338491858061
Trained batch 251 in epoch 16, gen_loss = 0.39447756561021957, disc_loss = 0.08365326565838167
Trained batch 252 in epoch 16, gen_loss = 0.394639114617359, disc_loss = 0.0834187906817073
Trained batch 253 in epoch 16, gen_loss = 0.39444223104968784, disc_loss = 0.08321297645759512
Trained batch 254 in epoch 16, gen_loss = 0.394203617292292, disc_loss = 0.08304319664032436
Trained batch 255 in epoch 16, gen_loss = 0.39398878172505647, disc_loss = 0.0829001353449712
Trained batch 256 in epoch 16, gen_loss = 0.39423171520697003, disc_loss = 0.08271012661420533
Trained batch 257 in epoch 16, gen_loss = 0.39439881055854087, disc_loss = 0.08250517651886326
Trained batch 258 in epoch 16, gen_loss = 0.39457185273004775, disc_loss = 0.08227032651355252
Trained batch 259 in epoch 16, gen_loss = 0.39464686776583013, disc_loss = 0.08211570738528211
Trained batch 260 in epoch 16, gen_loss = 0.3948358044998856, disc_loss = 0.081945664492004
Trained batch 261 in epoch 16, gen_loss = 0.39473895239466017, disc_loss = 0.08176851599256842
Trained batch 262 in epoch 16, gen_loss = 0.3949002685882293, disc_loss = 0.08177153983935997
Trained batch 263 in epoch 16, gen_loss = 0.3945562021073067, disc_loss = 0.08177135890053416
Trained batch 264 in epoch 16, gen_loss = 0.3945866010099087, disc_loss = 0.08157875879122964
Trained batch 265 in epoch 16, gen_loss = 0.3945251286477971, disc_loss = 0.08132040201987427
Trained batch 266 in epoch 16, gen_loss = 0.3941734538096167, disc_loss = 0.08110328502464718
Trained batch 267 in epoch 16, gen_loss = 0.3939033854585975, disc_loss = 0.08087217027613365
Trained batch 268 in epoch 16, gen_loss = 0.3938534407145915, disc_loss = 0.08096470036734325
Trained batch 269 in epoch 16, gen_loss = 0.394181900995749, disc_loss = 0.08144472239677
Trained batch 270 in epoch 16, gen_loss = 0.3942084126586844, disc_loss = 0.08121239348929857
Trained batch 271 in epoch 16, gen_loss = 0.3940364065415719, disc_loss = 0.0809832125361187
Trained batch 272 in epoch 16, gen_loss = 0.3940003265391339, disc_loss = 0.08081941983761477
Trained batch 273 in epoch 16, gen_loss = 0.39405523675636656, disc_loss = 0.08065815622422055
Trained batch 274 in epoch 16, gen_loss = 0.3943797771497206, disc_loss = 0.08043810424140908
Trained batch 275 in epoch 16, gen_loss = 0.3944819772589034, disc_loss = 0.08020531563290759
Trained batch 276 in epoch 16, gen_loss = 0.3946061221485964, disc_loss = 0.07996198052493352
Trained batch 277 in epoch 16, gen_loss = 0.3944842966554834, disc_loss = 0.07974175140328651
Trained batch 278 in epoch 16, gen_loss = 0.39440264368569977, disc_loss = 0.07953942226960348
Trained batch 279 in epoch 16, gen_loss = 0.39436101157750403, disc_loss = 0.07934834274929017
Trained batch 280 in epoch 16, gen_loss = 0.39452447575182253, disc_loss = 0.07918808042167874
Trained batch 281 in epoch 16, gen_loss = 0.3943826098602714, disc_loss = 0.07918034467832945
Trained batch 282 in epoch 16, gen_loss = 0.39447158859391096, disc_loss = 0.07905748480266164
Trained batch 283 in epoch 16, gen_loss = 0.39434075449973766, disc_loss = 0.07898749326172114
Trained batch 284 in epoch 16, gen_loss = 0.39417753627425745, disc_loss = 0.07914942015746707
Trained batch 285 in epoch 16, gen_loss = 0.3943762732344074, disc_loss = 0.07891432363605061
Trained batch 286 in epoch 16, gen_loss = 0.3943651159673618, disc_loss = 0.07866175291988389
Trained batch 287 in epoch 16, gen_loss = 0.3943696855049994, disc_loss = 0.07842972043888746
Trained batch 288 in epoch 16, gen_loss = 0.3942878982600044, disc_loss = 0.078222173878401
Trained batch 289 in epoch 16, gen_loss = 0.3941139107120448, disc_loss = 0.07810217860508067
Trained batch 290 in epoch 16, gen_loss = 0.3940722882952477, disc_loss = 0.0780772964831736
Trained batch 291 in epoch 16, gen_loss = 0.3939972194294407, disc_loss = 0.07812031242703024
Trained batch 292 in epoch 16, gen_loss = 0.39416472568040006, disc_loss = 0.07791629285192428
Trained batch 293 in epoch 16, gen_loss = 0.3942502152149369, disc_loss = 0.07820723721833557
Trained batch 294 in epoch 16, gen_loss = 0.39416568127729124, disc_loss = 0.07895334003398478
Trained batch 295 in epoch 16, gen_loss = 0.39419558312039116, disc_loss = 0.07903380706163778
Trained batch 296 in epoch 16, gen_loss = 0.394277742314419, disc_loss = 0.07909062935309077
Trained batch 297 in epoch 16, gen_loss = 0.39438997019057304, disc_loss = 0.07896962630931263
Trained batch 298 in epoch 16, gen_loss = 0.3941658415323914, disc_loss = 0.07892644137804425
Trained batch 299 in epoch 16, gen_loss = 0.39408707161744433, disc_loss = 0.07873238377583523
Trained batch 300 in epoch 16, gen_loss = 0.39437277768537454, disc_loss = 0.07856399756840793
Trained batch 301 in epoch 16, gen_loss = 0.3941871623527135, disc_loss = 0.07842803223749363
Trained batch 302 in epoch 16, gen_loss = 0.39394570587098404, disc_loss = 0.07852189902142429
Trained batch 303 in epoch 16, gen_loss = 0.39423599300023754, disc_loss = 0.07919757749799541
Trained batch 304 in epoch 16, gen_loss = 0.39418489336967466, disc_loss = 0.07917358623970239
Trained batch 305 in epoch 16, gen_loss = 0.39394376324672326, disc_loss = 0.07914214725210483
Trained batch 306 in epoch 16, gen_loss = 0.3936433108699438, disc_loss = 0.07928224764946326
Trained batch 307 in epoch 16, gen_loss = 0.3937222988574536, disc_loss = 0.07926660849011273
Trained batch 308 in epoch 16, gen_loss = 0.3940008419617094, disc_loss = 0.07916012365660331
Trained batch 309 in epoch 16, gen_loss = 0.39412073098844097, disc_loss = 0.07894729325067132
Trained batch 310 in epoch 16, gen_loss = 0.3939440748699225, disc_loss = 0.0788039817082489
Trained batch 311 in epoch 16, gen_loss = 0.39418368012859273, disc_loss = 0.07867005948299685
Trained batch 312 in epoch 16, gen_loss = 0.39422998565454453, disc_loss = 0.07850647500802438
Trained batch 313 in epoch 16, gen_loss = 0.3942573923783697, disc_loss = 0.07828591839606121
Trained batch 314 in epoch 16, gen_loss = 0.3940146634503016, disc_loss = 0.07825100837896268
Trained batch 315 in epoch 16, gen_loss = 0.39430083457050447, disc_loss = 0.07854026409538015
Trained batch 316 in epoch 16, gen_loss = 0.3941068831678445, disc_loss = 0.07838767583332133
Trained batch 317 in epoch 16, gen_loss = 0.3940883863647029, disc_loss = 0.07849142458817025
Trained batch 318 in epoch 16, gen_loss = 0.3942759048228727, disc_loss = 0.07841260235779991
Trained batch 319 in epoch 16, gen_loss = 0.3945910532027483, disc_loss = 0.07820279745792505
Trained batch 320 in epoch 16, gen_loss = 0.3944433200582166, disc_loss = 0.07799372177373769
Trained batch 321 in epoch 16, gen_loss = 0.3944160447727819, disc_loss = 0.07785781310373767
Trained batch 322 in epoch 16, gen_loss = 0.39452723803534967, disc_loss = 0.07765315220209744
Trained batch 323 in epoch 16, gen_loss = 0.39484839803642696, disc_loss = 0.07781535742034054
Trained batch 324 in epoch 16, gen_loss = 0.3946399731819446, disc_loss = 0.07825602532292787
Trained batch 325 in epoch 16, gen_loss = 0.39458293828861846, disc_loss = 0.07813717428012038
Trained batch 326 in epoch 16, gen_loss = 0.3945213854312897, disc_loss = 0.07824806878998283
Trained batch 327 in epoch 16, gen_loss = 0.3945231099681156, disc_loss = 0.07849737834582877
Trained batch 328 in epoch 16, gen_loss = 0.39471791163766273, disc_loss = 0.0783636786445613
Trained batch 329 in epoch 16, gen_loss = 0.39483431749271625, disc_loss = 0.0781701119249743
Trained batch 330 in epoch 16, gen_loss = 0.3949304535489788, disc_loss = 0.07809971996900988
Trained batch 331 in epoch 16, gen_loss = 0.3950217578964061, disc_loss = 0.07807190832120917
Trained batch 332 in epoch 16, gen_loss = 0.3947424706933019, disc_loss = 0.07803422395229428
Trained batch 333 in epoch 16, gen_loss = 0.39473380567784794, disc_loss = 0.07793077421904414
Trained batch 334 in epoch 16, gen_loss = 0.3946176307414895, disc_loss = 0.07778205587181138
Trained batch 335 in epoch 16, gen_loss = 0.39443475992551874, disc_loss = 0.07768580250142675
Trained batch 336 in epoch 16, gen_loss = 0.39445099420292795, disc_loss = 0.07751245610139579
Trained batch 337 in epoch 16, gen_loss = 0.39446988728272137, disc_loss = 0.07735276812158481
Trained batch 338 in epoch 16, gen_loss = 0.3942959617196986, disc_loss = 0.07729378522024834
Trained batch 339 in epoch 16, gen_loss = 0.39431385266430236, disc_loss = 0.07714094568646568
Trained batch 340 in epoch 16, gen_loss = 0.39420267257872216, disc_loss = 0.07704193108712386
Trained batch 341 in epoch 16, gen_loss = 0.39424930878898556, disc_loss = 0.07699015083837144
Trained batch 342 in epoch 16, gen_loss = 0.39413924606478945, disc_loss = 0.07680179060602414
Trained batch 343 in epoch 16, gen_loss = 0.39429112731717353, disc_loss = 0.07678780418030139
Trained batch 344 in epoch 16, gen_loss = 0.39428409916767176, disc_loss = 0.07686032358341027
Trained batch 345 in epoch 16, gen_loss = 0.39441592336734593, disc_loss = 0.07687692963545119
Trained batch 346 in epoch 16, gen_loss = 0.39426026890532084, disc_loss = 0.07696543568718416
Trained batch 347 in epoch 16, gen_loss = 0.39428645714946176, disc_loss = 0.07679366358106249
Trained batch 348 in epoch 16, gen_loss = 0.39428666891546166, disc_loss = 0.07675137609125977
Trained batch 349 in epoch 16, gen_loss = 0.39424992757184163, disc_loss = 0.0771773580275476
Trained batch 350 in epoch 16, gen_loss = 0.39468806379201404, disc_loss = 0.07751003350595548
Trained batch 351 in epoch 16, gen_loss = 0.39501866638999095, disc_loss = 0.07734217303963802
Trained batch 352 in epoch 16, gen_loss = 0.3951337211699391, disc_loss = 0.07720480845824264
Trained batch 353 in epoch 16, gen_loss = 0.3950469296025691, disc_loss = 0.07707972735387542
Trained batch 354 in epoch 16, gen_loss = 0.3950591036131684, disc_loss = 0.07690823334465983
Trained batch 355 in epoch 16, gen_loss = 0.3951474506031261, disc_loss = 0.07682675985734533
Trained batch 356 in epoch 16, gen_loss = 0.39517776530329923, disc_loss = 0.07681980535273208
Trained batch 357 in epoch 16, gen_loss = 0.39525110769871225, disc_loss = 0.07670659293269728
Trained batch 358 in epoch 16, gen_loss = 0.39518840723051, disc_loss = 0.07654968767704488
Trained batch 359 in epoch 16, gen_loss = 0.39520885712570614, disc_loss = 0.07646676308423694
Trained batch 360 in epoch 16, gen_loss = 0.3950073728931247, disc_loss = 0.0764109585098819
Trained batch 361 in epoch 16, gen_loss = 0.3950844682053308, disc_loss = 0.0764148416568767
Trained batch 362 in epoch 16, gen_loss = 0.3948782269455513, disc_loss = 0.07649807243276972
Trained batch 363 in epoch 16, gen_loss = 0.3949872264331514, disc_loss = 0.07637917904623344
Trained batch 364 in epoch 16, gen_loss = 0.3952952402095272, disc_loss = 0.07623047156335964
Trained batch 365 in epoch 16, gen_loss = 0.39539430620240384, disc_loss = 0.07620482571433232
Trained batch 366 in epoch 16, gen_loss = 0.3955846462165302, disc_loss = 0.07606145691085982
Trained batch 367 in epoch 16, gen_loss = 0.39563623127406056, disc_loss = 0.07593886231062123
Trained batch 368 in epoch 16, gen_loss = 0.3954348480959895, disc_loss = 0.07577746267352244
Trained batch 369 in epoch 16, gen_loss = 0.39519347371281804, disc_loss = 0.0759552199771074
Trained batch 370 in epoch 16, gen_loss = 0.395253734929221, disc_loss = 0.07637738093804076
Trained batch 371 in epoch 16, gen_loss = 0.3953769837496101, disc_loss = 0.0761975949575063
Trained batch 372 in epoch 16, gen_loss = 0.39545457316787247, disc_loss = 0.07605560002324169
Trained batch 373 in epoch 16, gen_loss = 0.3955119841079661, disc_loss = 0.07588956657209418
Trained batch 374 in epoch 16, gen_loss = 0.39534134928385417, disc_loss = 0.07572448176393906
Trained batch 375 in epoch 16, gen_loss = 0.3953404222080048, disc_loss = 0.07554362057906358
Trained batch 376 in epoch 16, gen_loss = 0.3953644423016819, disc_loss = 0.07538508485004662
Trained batch 377 in epoch 16, gen_loss = 0.3953850281143945, disc_loss = 0.07520278146559442
Trained batch 378 in epoch 16, gen_loss = 0.3952689409098713, disc_loss = 0.07504761410695267
Trained batch 379 in epoch 16, gen_loss = 0.39517752528190614, disc_loss = 0.0748737428459878
Trained batch 380 in epoch 16, gen_loss = 0.39497788090092617, disc_loss = 0.07472832709932187
Trained batch 381 in epoch 16, gen_loss = 0.3950568131751415, disc_loss = 0.07463537482057177
Trained batch 382 in epoch 16, gen_loss = 0.39486705836677055, disc_loss = 0.07456747722367005
Trained batch 383 in epoch 16, gen_loss = 0.39502467393564683, disc_loss = 0.07456471151817823
Trained batch 384 in epoch 16, gen_loss = 0.39492365454698536, disc_loss = 0.07444226989256485
Trained batch 385 in epoch 16, gen_loss = 0.3949076795052988, disc_loss = 0.07441349472088131
Trained batch 386 in epoch 16, gen_loss = 0.3948044357219716, disc_loss = 0.07425229635946357
Trained batch 387 in epoch 16, gen_loss = 0.39472194407711325, disc_loss = 0.07408286659431058
Trained batch 388 in epoch 16, gen_loss = 0.3948285388915888, disc_loss = 0.07391290451162962
Trained batch 389 in epoch 16, gen_loss = 0.394822527277164, disc_loss = 0.07376097072250186
Trained batch 390 in epoch 16, gen_loss = 0.39491287735112185, disc_loss = 0.07365023183976979
Trained batch 391 in epoch 16, gen_loss = 0.39476596457617624, disc_loss = 0.07359517942781427
Trained batch 392 in epoch 16, gen_loss = 0.3947986849695065, disc_loss = 0.07380569947328959
Trained batch 393 in epoch 16, gen_loss = 0.3949770561329604, disc_loss = 0.07455234724300237
Trained batch 394 in epoch 16, gen_loss = 0.3950206229958353, disc_loss = 0.07449185383517908
Trained batch 395 in epoch 16, gen_loss = 0.3951546844809946, disc_loss = 0.07436159005002918
Trained batch 396 in epoch 16, gen_loss = 0.3951723677685639, disc_loss = 0.07428843603335715
Trained batch 397 in epoch 16, gen_loss = 0.39520588479748925, disc_loss = 0.0743767179047979
Trained batch 398 in epoch 16, gen_loss = 0.39519145659037996, disc_loss = 0.07455834599076432
Trained batch 399 in epoch 16, gen_loss = 0.39526193112134933, disc_loss = 0.07450332487234845
Trained batch 400 in epoch 16, gen_loss = 0.3955493443030074, disc_loss = 0.07455228371522447
Trained batch 401 in epoch 16, gen_loss = 0.3956076625122953, disc_loss = 0.07445703754757545
Trained batch 402 in epoch 16, gen_loss = 0.3957328891044219, disc_loss = 0.07436546846235138
Trained batch 403 in epoch 16, gen_loss = 0.3958950247799996, disc_loss = 0.07424270667108053
Trained batch 404 in epoch 16, gen_loss = 0.3958376319320114, disc_loss = 0.0741635991582348
Trained batch 405 in epoch 16, gen_loss = 0.39575463166377817, disc_loss = 0.07415125602764522
Trained batch 406 in epoch 16, gen_loss = 0.3959546560005122, disc_loss = 0.07402976512844864
Trained batch 407 in epoch 16, gen_loss = 0.3960322313302872, disc_loss = 0.07389584649582485
Trained batch 408 in epoch 16, gen_loss = 0.39629233910868394, disc_loss = 0.0737505874466743
Trained batch 409 in epoch 16, gen_loss = 0.3963262222162107, disc_loss = 0.07368813243172154
Trained batch 410 in epoch 16, gen_loss = 0.3966575193869226, disc_loss = 0.07353874258334474
Trained batch 411 in epoch 16, gen_loss = 0.3966430477002292, disc_loss = 0.07350810596864056
Trained batch 412 in epoch 16, gen_loss = 0.39648874064334655, disc_loss = 0.0736333633802344
Trained batch 413 in epoch 16, gen_loss = 0.3963313513763861, disc_loss = 0.07347543504098115
Trained batch 414 in epoch 16, gen_loss = 0.396402404609933, disc_loss = 0.07378331927964127
Trained batch 415 in epoch 16, gen_loss = 0.39608734824623054, disc_loss = 0.07422367758072841
Trained batch 416 in epoch 16, gen_loss = 0.3959312550455546, disc_loss = 0.07442150930304536
Trained batch 417 in epoch 16, gen_loss = 0.3959359372631785, disc_loss = 0.07431097574861782
Trained batch 418 in epoch 16, gen_loss = 0.3958404290363157, disc_loss = 0.07419187090801951
Trained batch 419 in epoch 16, gen_loss = 0.39577935813438325, disc_loss = 0.07414210892637216
Trained batch 420 in epoch 16, gen_loss = 0.396013684553092, disc_loss = 0.07400171268253528
Trained batch 421 in epoch 16, gen_loss = 0.3959633790627475, disc_loss = 0.07392152459515144
Trained batch 422 in epoch 16, gen_loss = 0.3957318423346707, disc_loss = 0.07396840540819909
Trained batch 423 in epoch 16, gen_loss = 0.3956296991486594, disc_loss = 0.07382540656517278
Trained batch 424 in epoch 16, gen_loss = 0.39590517163276673, disc_loss = 0.07383254596853958
Trained batch 425 in epoch 16, gen_loss = 0.3959527248647851, disc_loss = 0.07379499922983103
Trained batch 426 in epoch 16, gen_loss = 0.3958860172320864, disc_loss = 0.07370908297947336
Trained batch 427 in epoch 16, gen_loss = 0.3959723363552138, disc_loss = 0.0735600251948165
Trained batch 428 in epoch 16, gen_loss = 0.39605845458857664, disc_loss = 0.07357424877948694
Trained batch 429 in epoch 16, gen_loss = 0.3956956808996755, disc_loss = 0.07397933060000109
Trained batch 430 in epoch 16, gen_loss = 0.3957626048968176, disc_loss = 0.07394420037482564
Trained batch 431 in epoch 16, gen_loss = 0.395989037670747, disc_loss = 0.0738459362010299
Trained batch 432 in epoch 16, gen_loss = 0.39600551558559544, disc_loss = 0.0738324248608348
Trained batch 433 in epoch 16, gen_loss = 0.3960026735053634, disc_loss = 0.07408365544601245
Trained batch 434 in epoch 16, gen_loss = 0.3961519121096052, disc_loss = 0.07407133956921512
Trained batch 435 in epoch 16, gen_loss = 0.3960696545967815, disc_loss = 0.0740026795142971
Trained batch 436 in epoch 16, gen_loss = 0.39628470056526177, disc_loss = 0.07388424088227939
Trained batch 437 in epoch 16, gen_loss = 0.39629802907302497, disc_loss = 0.07382893362444014
Trained batch 438 in epoch 16, gen_loss = 0.39626412358398044, disc_loss = 0.07379963356738481
Trained batch 439 in epoch 16, gen_loss = 0.3963977084579793, disc_loss = 0.07385267665271054
Trained batch 440 in epoch 16, gen_loss = 0.3964117955661415, disc_loss = 0.07377404660459548
Trained batch 441 in epoch 16, gen_loss = 0.3963275697099138, disc_loss = 0.07368093947311062
Trained batch 442 in epoch 16, gen_loss = 0.39654597280122356, disc_loss = 0.07359740554310937
Trained batch 443 in epoch 16, gen_loss = 0.39651491516479503, disc_loss = 0.07347158194091674
Trained batch 444 in epoch 16, gen_loss = 0.3963804374584991, disc_loss = 0.07362303508633979
Trained batch 445 in epoch 16, gen_loss = 0.39637333832915056, disc_loss = 0.07437118409293382
Trained batch 446 in epoch 16, gen_loss = 0.3963064803706453, disc_loss = 0.07434075531576838
Trained batch 447 in epoch 16, gen_loss = 0.3962109437145825, disc_loss = 0.0743552777566947
Trained batch 448 in epoch 16, gen_loss = 0.3962485458046397, disc_loss = 0.07427114424998882
Trained batch 449 in epoch 16, gen_loss = 0.3962716020147006, disc_loss = 0.07445164651506476
Trained batch 450 in epoch 16, gen_loss = 0.39610098401485155, disc_loss = 0.07434548196401405
Trained batch 451 in epoch 16, gen_loss = 0.39594527192216006, disc_loss = 0.07426528751322653
Trained batch 452 in epoch 16, gen_loss = 0.39603965872565644, disc_loss = 0.07412050284494627
Trained batch 453 in epoch 16, gen_loss = 0.39592264103600633, disc_loss = 0.07404168007591748
Trained batch 454 in epoch 16, gen_loss = 0.39588765799999237, disc_loss = 0.07396808729230703
Trained batch 455 in epoch 16, gen_loss = 0.395898244458071, disc_loss = 0.07387733417808225
Trained batch 456 in epoch 16, gen_loss = 0.3958448137378797, disc_loss = 0.07377563438152067
Trained batch 457 in epoch 16, gen_loss = 0.3957528427373374, disc_loss = 0.0738424895632215
Trained batch 458 in epoch 16, gen_loss = 0.395400968349837, disc_loss = 0.07490155094329567
Testing Epoch 16
Training Epoch 17
Trained batch 0 in epoch 17, gen_loss = 0.45781272649765015, disc_loss = 0.03946755826473236
Trained batch 1 in epoch 17, gen_loss = 0.4278527796268463, disc_loss = 0.07272490113973618
Trained batch 2 in epoch 17, gen_loss = 0.3879260718822479, disc_loss = 0.09327017764250438
Trained batch 3 in epoch 17, gen_loss = 0.39139624685049057, disc_loss = 0.11354516819119453
Trained batch 4 in epoch 17, gen_loss = 0.39289394617080686, disc_loss = 0.09836636185646057
Trained batch 5 in epoch 17, gen_loss = 0.3910802404085795, disc_loss = 0.09325900922218959
Trained batch 6 in epoch 17, gen_loss = 0.39099652426583426, disc_loss = 0.09296566992998123
Trained batch 7 in epoch 17, gen_loss = 0.3973957225680351, disc_loss = 0.08573897182941437
Trained batch 8 in epoch 17, gen_loss = 0.4011351433065202, disc_loss = 0.08255448068181674
Trained batch 9 in epoch 17, gen_loss = 0.3982291162014008, disc_loss = 0.08017781972885132
Trained batch 10 in epoch 17, gen_loss = 0.39236589724367316, disc_loss = 0.07603674077174881
Trained batch 11 in epoch 17, gen_loss = 0.3930695379773776, disc_loss = 0.07230217413355906
Trained batch 12 in epoch 17, gen_loss = 0.39527032008537877, disc_loss = 0.07020189555791709
Trained batch 13 in epoch 17, gen_loss = 0.3973187378474644, disc_loss = 0.06939772622925895
Trained batch 14 in epoch 17, gen_loss = 0.39108028610547385, disc_loss = 0.08213615218798319
Trained batch 15 in epoch 17, gen_loss = 0.3928087931126356, disc_loss = 0.10881339572370052
Trained batch 16 in epoch 17, gen_loss = 0.3922805172555587, disc_loss = 0.10352695755222265
Trained batch 17 in epoch 17, gen_loss = 0.3864403913418452, disc_loss = 0.10107168762220277
Trained batch 18 in epoch 17, gen_loss = 0.38372572942783956, disc_loss = 0.0975006850142228
Trained batch 19 in epoch 17, gen_loss = 0.3868802607059479, disc_loss = 0.09326865961775184
Trained batch 20 in epoch 17, gen_loss = 0.387286677247002, disc_loss = 0.09131191183058988
Trained batch 21 in epoch 17, gen_loss = 0.3856485188007355, disc_loss = 0.09266360044818032
Trained batch 22 in epoch 17, gen_loss = 0.38798269629478455, disc_loss = 0.08918156952637693
Trained batch 23 in epoch 17, gen_loss = 0.3859082522491614, disc_loss = 0.09057422719585399
Trained batch 24 in epoch 17, gen_loss = 0.3888766360282898, disc_loss = 0.09102924548089504
Trained batch 25 in epoch 17, gen_loss = 0.38827809347556186, disc_loss = 0.09046109099514209
Trained batch 26 in epoch 17, gen_loss = 0.39026686549186707, disc_loss = 0.09278486027485794
Trained batch 27 in epoch 17, gen_loss = 0.39263381489685606, disc_loss = 0.09043849731928535
Trained batch 28 in epoch 17, gen_loss = 0.39135260828610124, disc_loss = 0.0912780265227474
Trained batch 29 in epoch 17, gen_loss = 0.3920847773551941, disc_loss = 0.08929394837468863
Trained batch 30 in epoch 17, gen_loss = 0.390634750166247, disc_loss = 0.08879234263252828
Trained batch 31 in epoch 17, gen_loss = 0.39209738839417696, disc_loss = 0.087320314894896
Trained batch 32 in epoch 17, gen_loss = 0.3920113209522132, disc_loss = 0.08642097432730776
Trained batch 33 in epoch 17, gen_loss = 0.39110783443731423, disc_loss = 0.08656028028139297
Trained batch 34 in epoch 17, gen_loss = 0.39090712666511535, disc_loss = 0.0857072116541011
Trained batch 35 in epoch 17, gen_loss = 0.39139147682322395, disc_loss = 0.08484722917071646
Trained batch 36 in epoch 17, gen_loss = 0.3890574461704976, disc_loss = 0.08415451932799171
Trained batch 37 in epoch 17, gen_loss = 0.391640410611504, disc_loss = 0.08462438776500915
Trained batch 38 in epoch 17, gen_loss = 0.39084847768147785, disc_loss = 0.08336435836286117
Trained batch 39 in epoch 17, gen_loss = 0.39030716121196746, disc_loss = 0.08199913050048054
Trained batch 40 in epoch 17, gen_loss = 0.3893190934890654, disc_loss = 0.08118471853071596
Trained batch 41 in epoch 17, gen_loss = 0.38934034747736795, disc_loss = 0.07947772559488103
Trained batch 42 in epoch 17, gen_loss = 0.3892173011635625, disc_loss = 0.07885671160075554
Trained batch 43 in epoch 17, gen_loss = 0.392206726426428, disc_loss = 0.07779321417381818
Trained batch 44 in epoch 17, gen_loss = 0.3934554464287228, disc_loss = 0.07621038818938865
Trained batch 45 in epoch 17, gen_loss = 0.3927487763373748, disc_loss = 0.0752308554339992
Trained batch 46 in epoch 17, gen_loss = 0.3914570193341438, disc_loss = 0.07443048268001765
Trained batch 47 in epoch 17, gen_loss = 0.3917982087781032, disc_loss = 0.07341324512769158
Trained batch 48 in epoch 17, gen_loss = 0.3915064194980933, disc_loss = 0.07217491707023309
Trained batch 49 in epoch 17, gen_loss = 0.39150789558887483, disc_loss = 0.07150394827127457
Trained batch 50 in epoch 17, gen_loss = 0.3905784253980599, disc_loss = 0.071144024969316
Trained batch 51 in epoch 17, gen_loss = 0.38993506362804997, disc_loss = 0.07009883533016993
Trained batch 52 in epoch 17, gen_loss = 0.393978828529142, disc_loss = 0.06969182636096792
Trained batch 53 in epoch 17, gen_loss = 0.3943108104997211, disc_loss = 0.06923636525041527
Trained batch 54 in epoch 17, gen_loss = 0.3952757792039351, disc_loss = 0.06830504993823441
Trained batch 55 in epoch 17, gen_loss = 0.39567783155611586, disc_loss = 0.06832798806551311
Trained batch 56 in epoch 17, gen_loss = 0.394405208135906, disc_loss = 0.06979816913474024
Trained batch 57 in epoch 17, gen_loss = 0.39438125028692445, disc_loss = 0.06963573315919473
Trained batch 58 in epoch 17, gen_loss = 0.39433676357996666, disc_loss = 0.06864694537500203
Trained batch 59 in epoch 17, gen_loss = 0.39456794361273445, disc_loss = 0.06768913061047593
Trained batch 60 in epoch 17, gen_loss = 0.39305236105059016, disc_loss = 0.06682304579947816
Trained batch 61 in epoch 17, gen_loss = 0.39266261794874746, disc_loss = 0.06632009713399795
Trained batch 62 in epoch 17, gen_loss = 0.3923156942640032, disc_loss = 0.06596364577611287
Trained batch 63 in epoch 17, gen_loss = 0.39213886205106974, disc_loss = 0.06544034252874553
Trained batch 64 in epoch 17, gen_loss = 0.39276087008989774, disc_loss = 0.06522929336015995
Trained batch 65 in epoch 17, gen_loss = 0.39253071492368524, disc_loss = 0.06797284508744876
Trained batch 66 in epoch 17, gen_loss = 0.3942773351028784, disc_loss = 0.0687883248302474
Trained batch 67 in epoch 17, gen_loss = 0.3936610291985905, disc_loss = 0.06897076635676272
Trained batch 68 in epoch 17, gen_loss = 0.39486146534698596, disc_loss = 0.06910190180591914
Trained batch 69 in epoch 17, gen_loss = 0.3939721073423113, disc_loss = 0.06929234830396516
Trained batch 70 in epoch 17, gen_loss = 0.3950195589535673, disc_loss = 0.06961453789976281
Trained batch 71 in epoch 17, gen_loss = 0.3955824888414807, disc_loss = 0.06896890627427234
Trained batch 72 in epoch 17, gen_loss = 0.3948636373428449, disc_loss = 0.06909568638425984
Trained batch 73 in epoch 17, gen_loss = 0.396970449267207, disc_loss = 0.07019360232594851
Trained batch 74 in epoch 17, gen_loss = 0.398171960512797, disc_loss = 0.0694344399869442
Trained batch 75 in epoch 17, gen_loss = 0.3978333484969641, disc_loss = 0.06869390931617665
Trained batch 76 in epoch 17, gen_loss = 0.39783688489492836, disc_loss = 0.06841922349405366
Trained batch 77 in epoch 17, gen_loss = 0.39770873731527573, disc_loss = 0.06793094578031929
Trained batch 78 in epoch 17, gen_loss = 0.3972336747978307, disc_loss = 0.06743654822105472
Trained batch 79 in epoch 17, gen_loss = 0.39749725311994555, disc_loss = 0.06776280464837328
Trained batch 80 in epoch 17, gen_loss = 0.39814444566950385, disc_loss = 0.06703104185699313
Trained batch 81 in epoch 17, gen_loss = 0.3988254077550841, disc_loss = 0.06672287633551693
Trained batch 82 in epoch 17, gen_loss = 0.39902142623820935, disc_loss = 0.06601218769820519
Trained batch 83 in epoch 17, gen_loss = 0.39831255057028364, disc_loss = 0.06607673102657177
Trained batch 84 in epoch 17, gen_loss = 0.39768438514541177, disc_loss = 0.0662720295271891
Trained batch 85 in epoch 17, gen_loss = 0.3984873443841934, disc_loss = 0.06578536366848925
Trained batch 86 in epoch 17, gen_loss = 0.3980310446229474, disc_loss = 0.06534689322820511
Trained batch 87 in epoch 17, gen_loss = 0.3981699428775094, disc_loss = 0.06502644142495807
Trained batch 88 in epoch 17, gen_loss = 0.39989558632454175, disc_loss = 0.06558359088376164
Trained batch 89 in epoch 17, gen_loss = 0.39917981061670516, disc_loss = 0.06552492732492586
Trained batch 90 in epoch 17, gen_loss = 0.39861999992485886, disc_loss = 0.06496007869961662
Trained batch 91 in epoch 17, gen_loss = 0.39907700017742487, disc_loss = 0.06450306970889316
Trained batch 92 in epoch 17, gen_loss = 0.3991452923385046, disc_loss = 0.06396465404560009
Trained batch 93 in epoch 17, gen_loss = 0.39967806383650356, disc_loss = 0.06348925825466026
Trained batch 94 in epoch 17, gen_loss = 0.39949185346302235, disc_loss = 0.06302958117601903
Trained batch 95 in epoch 17, gen_loss = 0.3991061371440689, disc_loss = 0.06275059370576248
Trained batch 96 in epoch 17, gen_loss = 0.39966181873046247, disc_loss = 0.062358204299372805
Trained batch 97 in epoch 17, gen_loss = 0.39968015040670124, disc_loss = 0.061864451101353884
Trained batch 98 in epoch 17, gen_loss = 0.399199151330524, disc_loss = 0.06250332257795063
Trained batch 99 in epoch 17, gen_loss = 0.3998814168572426, disc_loss = 0.06485182381700724
Trained batch 100 in epoch 17, gen_loss = 0.40010420284648934, disc_loss = 0.06452970434957654
Trained batch 101 in epoch 17, gen_loss = 0.40022921036271486, disc_loss = 0.06423670790779094
Trained batch 102 in epoch 17, gen_loss = 0.40023677268074553, disc_loss = 0.06391815855213016
Trained batch 103 in epoch 17, gen_loss = 0.4003238973136132, disc_loss = 0.06369137161751635
Trained batch 104 in epoch 17, gen_loss = 0.4004522388889676, disc_loss = 0.06334697694207231
Trained batch 105 in epoch 17, gen_loss = 0.40049008828289107, disc_loss = 0.0631094142785823
Trained batch 106 in epoch 17, gen_loss = 0.40055951726770844, disc_loss = 0.06271617366523247
Trained batch 107 in epoch 17, gen_loss = 0.39931644554491397, disc_loss = 0.06273363331867451
Trained batch 108 in epoch 17, gen_loss = 0.39876520305598545, disc_loss = 0.06270642829375393
Trained batch 109 in epoch 17, gen_loss = 0.3981118091128089, disc_loss = 0.06360398711721328
Trained batch 110 in epoch 17, gen_loss = 0.3986447305829675, disc_loss = 0.06340289231272297
Trained batch 111 in epoch 17, gen_loss = 0.39805514817791326, disc_loss = 0.06362546715536155
Trained batch 112 in epoch 17, gen_loss = 0.3980911123541604, disc_loss = 0.06342834265144394
Trained batch 113 in epoch 17, gen_loss = 0.39826426981833946, disc_loss = 0.06301934482415386
Trained batch 114 in epoch 17, gen_loss = 0.39869565860084866, disc_loss = 0.06263099153647604
Trained batch 115 in epoch 17, gen_loss = 0.3985180752030734, disc_loss = 0.062445344977434085
Trained batch 116 in epoch 17, gen_loss = 0.39858099206899983, disc_loss = 0.06215829428874402
Trained batch 117 in epoch 17, gen_loss = 0.39952179461212484, disc_loss = 0.06174392955204062
Trained batch 118 in epoch 17, gen_loss = 0.3994283348071475, disc_loss = 0.06137125813519629
Trained batch 119 in epoch 17, gen_loss = 0.3992111379901568, disc_loss = 0.06136759230478977
Trained batch 120 in epoch 17, gen_loss = 0.3989270408291462, disc_loss = 0.06165994047610597
Trained batch 121 in epoch 17, gen_loss = 0.39951015764572584, disc_loss = 0.06270687987066073
Trained batch 122 in epoch 17, gen_loss = 0.39988660303557794, disc_loss = 0.062318624432645436
Trained batch 123 in epoch 17, gen_loss = 0.39949001203621587, disc_loss = 0.06249810746615572
Trained batch 124 in epoch 17, gen_loss = 0.39929957342147826, disc_loss = 0.06241361946240068
Trained batch 125 in epoch 17, gen_loss = 0.39969478145478265, disc_loss = 0.06321836281050411
Trained batch 126 in epoch 17, gen_loss = 0.3998114689597933, disc_loss = 0.06371628012376156
Trained batch 127 in epoch 17, gen_loss = 0.4005133241880685, disc_loss = 0.06362716085641296
Trained batch 128 in epoch 17, gen_loss = 0.40114980936050415, disc_loss = 0.06332945772049617
Trained batch 129 in epoch 17, gen_loss = 0.40052871062205386, disc_loss = 0.06311232456579231
Trained batch 130 in epoch 17, gen_loss = 0.4007205016740406, disc_loss = 0.0627681486315684
Trained batch 131 in epoch 17, gen_loss = 0.4010657241398638, disc_loss = 0.06259659498887644
Trained batch 132 in epoch 17, gen_loss = 0.40058771739328713, disc_loss = 0.06242407322336072
Trained batch 133 in epoch 17, gen_loss = 0.40039153063475197, disc_loss = 0.06217066496402136
Trained batch 134 in epoch 17, gen_loss = 0.4005608728638402, disc_loss = 0.06185288809032904
Trained batch 135 in epoch 17, gen_loss = 0.400241731063408, disc_loss = 0.06159632883431828
Trained batch 136 in epoch 17, gen_loss = 0.3998525066532358, disc_loss = 0.06134071466546968
Trained batch 137 in epoch 17, gen_loss = 0.39997672235620196, disc_loss = 0.06176587360560138
Trained batch 138 in epoch 17, gen_loss = 0.3993500494699684, disc_loss = 0.06290773708681516
Trained batch 139 in epoch 17, gen_loss = 0.39925401146922795, disc_loss = 0.06259615587935384
Trained batch 140 in epoch 17, gen_loss = 0.39917575446426445, disc_loss = 0.06235734044726119
Trained batch 141 in epoch 17, gen_loss = 0.3988949805498123, disc_loss = 0.06197824447520707
Trained batch 142 in epoch 17, gen_loss = 0.39899401981513816, disc_loss = 0.06175182064526252
Trained batch 143 in epoch 17, gen_loss = 0.3987224497314956, disc_loss = 0.06147208277252503
Trained batch 144 in epoch 17, gen_loss = 0.3989784294161303, disc_loss = 0.061093722267782896
Trained batch 145 in epoch 17, gen_loss = 0.398695583825242, disc_loss = 0.061183268162868405
Trained batch 146 in epoch 17, gen_loss = 0.3992241637236407, disc_loss = 0.06131187338242624
Trained batch 147 in epoch 17, gen_loss = 0.3993832154853924, disc_loss = 0.0609726112027577
Trained batch 148 in epoch 17, gen_loss = 0.4000473334485252, disc_loss = 0.06063296461802901
Trained batch 149 in epoch 17, gen_loss = 0.4000588182608287, disc_loss = 0.06036090777255595
Trained batch 150 in epoch 17, gen_loss = 0.4001141520130713, disc_loss = 0.060061426509467775
Trained batch 151 in epoch 17, gen_loss = 0.3995445625562417, disc_loss = 0.05976792427674426
Trained batch 152 in epoch 17, gen_loss = 0.3996944628120248, disc_loss = 0.05950719234077077
Trained batch 153 in epoch 17, gen_loss = 0.3994399483327742, disc_loss = 0.05926330006899094
Trained batch 154 in epoch 17, gen_loss = 0.39916398602147257, disc_loss = 0.05897897101277786
Trained batch 155 in epoch 17, gen_loss = 0.3991102369932028, disc_loss = 0.05870188103141024
Trained batch 156 in epoch 17, gen_loss = 0.3991079412068531, disc_loss = 0.058421874226065006
Trained batch 157 in epoch 17, gen_loss = 0.39935102643845954, disc_loss = 0.05884131507158185
Trained batch 158 in epoch 17, gen_loss = 0.39940742201775126, disc_loss = 0.059174793939334606
Trained batch 159 in epoch 17, gen_loss = 0.4000161634758115, disc_loss = 0.05884643150784541
Trained batch 160 in epoch 17, gen_loss = 0.4003363272047931, disc_loss = 0.058560988168746976
Trained batch 161 in epoch 17, gen_loss = 0.40093145179159845, disc_loss = 0.058600591142075484
Trained batch 162 in epoch 17, gen_loss = 0.40081638390301194, disc_loss = 0.05840091075051142
Trained batch 163 in epoch 17, gen_loss = 0.4009631828563969, disc_loss = 0.058188190039179126
Trained batch 164 in epoch 17, gen_loss = 0.40039932095643244, disc_loss = 0.057993278011792534
Trained batch 165 in epoch 17, gen_loss = 0.4000792596713606, disc_loss = 0.05769071024449834
Trained batch 166 in epoch 17, gen_loss = 0.400245857988289, disc_loss = 0.05771874182461621
Trained batch 167 in epoch 17, gen_loss = 0.39988725792084423, disc_loss = 0.05753905464717675
Trained batch 168 in epoch 17, gen_loss = 0.39966529501965764, disc_loss = 0.05734059174914332
Trained batch 169 in epoch 17, gen_loss = 0.399576882053824, disc_loss = 0.05712162214605247
Trained batch 170 in epoch 17, gen_loss = 0.4000405472273018, disc_loss = 0.0572468681337192
Trained batch 171 in epoch 17, gen_loss = 0.400206838409568, disc_loss = 0.058271424996471685
Trained batch 172 in epoch 17, gen_loss = 0.4005531701393899, disc_loss = 0.05854079086398114
Trained batch 173 in epoch 17, gen_loss = 0.40087496018272706, disc_loss = 0.058348216769424664
Trained batch 174 in epoch 17, gen_loss = 0.4007652063029153, disc_loss = 0.05805582637233393
Trained batch 175 in epoch 17, gen_loss = 0.40106646479530766, disc_loss = 0.057773818478877234
Trained batch 176 in epoch 17, gen_loss = 0.4011283259270555, disc_loss = 0.05756420809986059
Trained batch 177 in epoch 17, gen_loss = 0.40105968429131456, disc_loss = 0.05735270981938484
Trained batch 178 in epoch 17, gen_loss = 0.40093199417577774, disc_loss = 0.05709239369643301
Trained batch 179 in epoch 17, gen_loss = 0.40084758583042357, disc_loss = 0.05687121144081983
Trained batch 180 in epoch 17, gen_loss = 0.40034111593309685, disc_loss = 0.05670217324295261
Trained batch 181 in epoch 17, gen_loss = 0.4000645474745677, disc_loss = 0.05651849776936265
Trained batch 182 in epoch 17, gen_loss = 0.40034532188717786, disc_loss = 0.056394730989765274
Trained batch 183 in epoch 17, gen_loss = 0.4003178423837475, disc_loss = 0.0565367787114709
Trained batch 184 in epoch 17, gen_loss = 0.40090062763239886, disc_loss = 0.056435370993976657
Trained batch 185 in epoch 17, gen_loss = 0.40107958339234834, disc_loss = 0.05628213977881817
Trained batch 186 in epoch 17, gen_loss = 0.4013935254219382, disc_loss = 0.056122760607158755
Trained batch 187 in epoch 17, gen_loss = 0.4017467021625093, disc_loss = 0.056225424478860926
Trained batch 188 in epoch 17, gen_loss = 0.4022025391853676, disc_loss = 0.05616809239009858
Trained batch 189 in epoch 17, gen_loss = 0.4023543497449473, disc_loss = 0.05600464634695335
Trained batch 190 in epoch 17, gen_loss = 0.4023207206064494, disc_loss = 0.055837735148507574
Trained batch 191 in epoch 17, gen_loss = 0.4019553003211816, disc_loss = 0.05598553247303547
Trained batch 192 in epoch 17, gen_loss = 0.40245517918482965, disc_loss = 0.05664989592053884
Trained batch 193 in epoch 17, gen_loss = 0.4023035409831509, disc_loss = 0.056700415760470725
Trained batch 194 in epoch 17, gen_loss = 0.40229528225385225, disc_loss = 0.05659503675519656
Trained batch 195 in epoch 17, gen_loss = 0.40254030559135945, disc_loss = 0.056383316105763824
Trained batch 196 in epoch 17, gen_loss = 0.4029426461246413, disc_loss = 0.056358461967919986
Trained batch 197 in epoch 17, gen_loss = 0.40314582291275564, disc_loss = 0.05633391756470306
Trained batch 198 in epoch 17, gen_loss = 0.4030543168885025, disc_loss = 0.05613682962411163
Trained batch 199 in epoch 17, gen_loss = 0.4031698568165302, disc_loss = 0.05597801710944623
Trained batch 200 in epoch 17, gen_loss = 0.4033522405731144, disc_loss = 0.05597503104742931
Trained batch 201 in epoch 17, gen_loss = 0.402912838919328, disc_loss = 0.057080791723720804
Trained batch 202 in epoch 17, gen_loss = 0.4027004180283382, disc_loss = 0.057028898515100845
Trained batch 203 in epoch 17, gen_loss = 0.4026080727869389, disc_loss = 0.056956484854477
Trained batch 204 in epoch 17, gen_loss = 0.40310741008781803, disc_loss = 0.05699163676671139
Trained batch 205 in epoch 17, gen_loss = 0.4033676432174386, disc_loss = 0.05705742043831829
Trained batch 206 in epoch 17, gen_loss = 0.40305891676225525, disc_loss = 0.05693158244147249
Trained batch 207 in epoch 17, gen_loss = 0.4030032858539086, disc_loss = 0.05693537408324818
Trained batch 208 in epoch 17, gen_loss = 0.4029377544895884, disc_loss = 0.05680780385010408
Trained batch 209 in epoch 17, gen_loss = 0.402857400122143, disc_loss = 0.05706027729791545
Trained batch 210 in epoch 17, gen_loss = 0.4033525283867714, disc_loss = 0.05742966949992694
Trained batch 211 in epoch 17, gen_loss = 0.40363539530421205, disc_loss = 0.05720845034416273
Trained batch 212 in epoch 17, gen_loss = 0.4035044396427316, disc_loss = 0.05708476312528474
Trained batch 213 in epoch 17, gen_loss = 0.4032618977199091, disc_loss = 0.056914919560827386
Trained batch 214 in epoch 17, gen_loss = 0.4035069198109383, disc_loss = 0.056762523264732474
Trained batch 215 in epoch 17, gen_loss = 0.4036423552919317, disc_loss = 0.056856643624120844
Trained batch 216 in epoch 17, gen_loss = 0.4033694974563089, disc_loss = 0.057477647472979836
Trained batch 217 in epoch 17, gen_loss = 0.40378445004104474, disc_loss = 0.05734956871991584
Trained batch 218 in epoch 17, gen_loss = 0.40419389953896334, disc_loss = 0.058029712939031045
Trained batch 219 in epoch 17, gen_loss = 0.40393226756290956, disc_loss = 0.05786720853806897
Trained batch 220 in epoch 17, gen_loss = 0.40378889913472654, disc_loss = 0.05776978301819903
Trained batch 221 in epoch 17, gen_loss = 0.40340831191153137, disc_loss = 0.05800765119325202
Trained batch 222 in epoch 17, gen_loss = 0.40330440647933513, disc_loss = 0.059025905032395784
Trained batch 223 in epoch 17, gen_loss = 0.40332834968077286, disc_loss = 0.058871708619075695
Trained batch 224 in epoch 17, gen_loss = 0.4031179569827186, disc_loss = 0.058795978931917084
Trained batch 225 in epoch 17, gen_loss = 0.4028793702610826, disc_loss = 0.05860094375397384
Trained batch 226 in epoch 17, gen_loss = 0.40275527399016897, disc_loss = 0.0584206600111421
Trained batch 227 in epoch 17, gen_loss = 0.4027787496646245, disc_loss = 0.058273193928854244
Trained batch 228 in epoch 17, gen_loss = 0.402826625577227, disc_loss = 0.058446317484122434
Trained batch 229 in epoch 17, gen_loss = 0.4026158783746802, disc_loss = 0.05960627363022903
Trained batch 230 in epoch 17, gen_loss = 0.4031471259150154, disc_loss = 0.05946524343271921
Trained batch 231 in epoch 17, gen_loss = 0.40368863349330836, disc_loss = 0.059468595989465974
Trained batch 232 in epoch 17, gen_loss = 0.4038554418496308, disc_loss = 0.05936680761737501
Trained batch 233 in epoch 17, gen_loss = 0.40389418933126664, disc_loss = 0.05922767896061906
Trained batch 234 in epoch 17, gen_loss = 0.40404113455021634, disc_loss = 0.05914977068041868
Trained batch 235 in epoch 17, gen_loss = 0.40360144020642263, disc_loss = 0.059299699571457205
Trained batch 236 in epoch 17, gen_loss = 0.40358080215091946, disc_loss = 0.05914860509163091
Trained batch 237 in epoch 17, gen_loss = 0.40345475778860207, disc_loss = 0.05896872029631954
Trained batch 238 in epoch 17, gen_loss = 0.40359814471280725, disc_loss = 0.058843431234453264
Trained batch 239 in epoch 17, gen_loss = 0.40348274695376557, disc_loss = 0.059274166197671244
Trained batch 240 in epoch 17, gen_loss = 0.4033568625133562, disc_loss = 0.059328501615132284
Trained batch 241 in epoch 17, gen_loss = 0.4033376777713949, disc_loss = 0.05912340395845288
Trained batch 242 in epoch 17, gen_loss = 0.4032783926514441, disc_loss = 0.05890887458291319
Trained batch 243 in epoch 17, gen_loss = 0.4031824083601842, disc_loss = 0.0588194621711603
Trained batch 244 in epoch 17, gen_loss = 0.40311329766195647, disc_loss = 0.05885655336386087
Trained batch 245 in epoch 17, gen_loss = 0.4028700830006018, disc_loss = 0.058893291635544805
Trained batch 246 in epoch 17, gen_loss = 0.4033437035827019, disc_loss = 0.05881622622943359
Trained batch 247 in epoch 17, gen_loss = 0.40316079881402755, disc_loss = 0.058754248897575086
Trained batch 248 in epoch 17, gen_loss = 0.4035262990907493, disc_loss = 0.05858064712919145
Trained batch 249 in epoch 17, gen_loss = 0.40351268196105955, disc_loss = 0.058636655934154985
Trained batch 250 in epoch 17, gen_loss = 0.4033803344960232, disc_loss = 0.05917682063086812
Trained batch 251 in epoch 17, gen_loss = 0.40371773084477774, disc_loss = 0.059048219000004114
Trained batch 252 in epoch 17, gen_loss = 0.4039300589457802, disc_loss = 0.05898219374240387
Trained batch 253 in epoch 17, gen_loss = 0.4039468515341676, disc_loss = 0.058798287910827265
Trained batch 254 in epoch 17, gen_loss = 0.4040040969848633, disc_loss = 0.058712386657648226
Trained batch 255 in epoch 17, gen_loss = 0.4039513247553259, disc_loss = 0.05855192173839896
Trained batch 256 in epoch 17, gen_loss = 0.4043498834747285, disc_loss = 0.058836895722446506
Trained batch 257 in epoch 17, gen_loss = 0.4039208394612453, disc_loss = 0.0594523032701235
Trained batch 258 in epoch 17, gen_loss = 0.40379721421072384, disc_loss = 0.05951784637084224
Trained batch 259 in epoch 17, gen_loss = 0.403831194455807, disc_loss = 0.05952836979682056
Trained batch 260 in epoch 17, gen_loss = 0.4035576713267871, disc_loss = 0.05992480238606989
Trained batch 261 in epoch 17, gen_loss = 0.4033064164278161, disc_loss = 0.0599357086475512
Trained batch 262 in epoch 17, gen_loss = 0.4037504427333295, disc_loss = 0.059876044663271295
Trained batch 263 in epoch 17, gen_loss = 0.4035857017293121, disc_loss = 0.05991956086081424
Trained batch 264 in epoch 17, gen_loss = 0.4034669494853829, disc_loss = 0.059955570070108155
Trained batch 265 in epoch 17, gen_loss = 0.40365735323805557, disc_loss = 0.05975713820154674
Trained batch 266 in epoch 17, gen_loss = 0.403674013605725, disc_loss = 0.05959208805483769
Trained batch 267 in epoch 17, gen_loss = 0.4037366116892046, disc_loss = 0.0594216256572712
Trained batch 268 in epoch 17, gen_loss = 0.4035029917623031, disc_loss = 0.05938154067255584
Trained batch 269 in epoch 17, gen_loss = 0.403939797812038, disc_loss = 0.05919530680920515
Trained batch 270 in epoch 17, gen_loss = 0.40415166037988837, disc_loss = 0.0592351353424859
Trained batch 271 in epoch 17, gen_loss = 0.40404309825423884, disc_loss = 0.05906788537258228
Trained batch 272 in epoch 17, gen_loss = 0.40389079652426446, disc_loss = 0.059062126923297896
Trained batch 273 in epoch 17, gen_loss = 0.40369244431057116, disc_loss = 0.05891561363551793
Trained batch 274 in epoch 17, gen_loss = 0.4037269126285206, disc_loss = 0.05891922799870372
Trained batch 275 in epoch 17, gen_loss = 0.4032002390510794, disc_loss = 0.05957608946187395
Trained batch 276 in epoch 17, gen_loss = 0.40325450391545625, disc_loss = 0.059685372443204
Trained batch 277 in epoch 17, gen_loss = 0.4030741360976542, disc_loss = 0.05957529225668086
Trained batch 278 in epoch 17, gen_loss = 0.4027373101762546, disc_loss = 0.06001128478803568
Trained batch 279 in epoch 17, gen_loss = 0.4028489931353501, disc_loss = 0.06073203877978293
Trained batch 280 in epoch 17, gen_loss = 0.40286232196987737, disc_loss = 0.060665489524085854
Trained batch 281 in epoch 17, gen_loss = 0.4026431129545185, disc_loss = 0.060776136612440364
Trained batch 282 in epoch 17, gen_loss = 0.40254226790300107, disc_loss = 0.06063221692676942
Trained batch 283 in epoch 17, gen_loss = 0.402542248473201, disc_loss = 0.060460697467648754
Trained batch 284 in epoch 17, gen_loss = 0.4024389978040729, disc_loss = 0.06043129320370785
Trained batch 285 in epoch 17, gen_loss = 0.4023897882316496, disc_loss = 0.06042011069309722
Trained batch 286 in epoch 17, gen_loss = 0.4023617809242488, disc_loss = 0.06054685991873984
Trained batch 287 in epoch 17, gen_loss = 0.40233334247022867, disc_loss = 0.06069328204062509
Trained batch 288 in epoch 17, gen_loss = 0.40264836964310247, disc_loss = 0.06067159942232046
Trained batch 289 in epoch 17, gen_loss = 0.4027473805279567, disc_loss = 0.06063549296512943
Trained batch 290 in epoch 17, gen_loss = 0.40237904629346843, disc_loss = 0.06055478138618709
Trained batch 291 in epoch 17, gen_loss = 0.4022802731966319, disc_loss = 0.06095864492538704
Trained batch 292 in epoch 17, gen_loss = 0.40245901999213185, disc_loss = 0.061036213534747474
Trained batch 293 in epoch 17, gen_loss = 0.4026070224995516, disc_loss = 0.0608782364502169
Trained batch 294 in epoch 17, gen_loss = 0.4026995850821673, disc_loss = 0.06071093889837295
Trained batch 295 in epoch 17, gen_loss = 0.4026619785943547, disc_loss = 0.06058936813261007
Trained batch 296 in epoch 17, gen_loss = 0.40264309295500167, disc_loss = 0.06046799289200593
Trained batch 297 in epoch 17, gen_loss = 0.40259851635302474, disc_loss = 0.0605881147621037
Trained batch 298 in epoch 17, gen_loss = 0.4029407524145566, disc_loss = 0.061003267514304474
Trained batch 299 in epoch 17, gen_loss = 0.40288037319978076, disc_loss = 0.061098145195283
Trained batch 300 in epoch 17, gen_loss = 0.402718636581668, disc_loss = 0.060998229586837996
Trained batch 301 in epoch 17, gen_loss = 0.4026618181474951, disc_loss = 0.06107416904272376
Trained batch 302 in epoch 17, gen_loss = 0.40249793482298896, disc_loss = 0.06128152157256853
Trained batch 303 in epoch 17, gen_loss = 0.4022688330396226, disc_loss = 0.061153825683408956
Trained batch 304 in epoch 17, gen_loss = 0.40268477748651976, disc_loss = 0.06107841974857156
Trained batch 305 in epoch 17, gen_loss = 0.40272803234508614, disc_loss = 0.060927698228909984
Trained batch 306 in epoch 17, gen_loss = 0.4027872533091505, disc_loss = 0.060800608876995524
Trained batch 307 in epoch 17, gen_loss = 0.40282119297749036, disc_loss = 0.06063408275019958
Trained batch 308 in epoch 17, gen_loss = 0.4025048821875193, disc_loss = 0.06060304529934784
Trained batch 309 in epoch 17, gen_loss = 0.4022562183680073, disc_loss = 0.06116166562893458
Trained batch 310 in epoch 17, gen_loss = 0.40234735761424734, disc_loss = 0.0618009885991669
Trained batch 311 in epoch 17, gen_loss = 0.4020303351183732, disc_loss = 0.06170618912437931
Trained batch 312 in epoch 17, gen_loss = 0.4019842646754207, disc_loss = 0.06156432680851116
Trained batch 313 in epoch 17, gen_loss = 0.40199518279664836, disc_loss = 0.06145392997623392
Trained batch 314 in epoch 17, gen_loss = 0.40174882922853744, disc_loss = 0.061445037782606154
Trained batch 315 in epoch 17, gen_loss = 0.4014817452694796, disc_loss = 0.061464500435203594
Trained batch 316 in epoch 17, gen_loss = 0.4014194139546776, disc_loss = 0.061484370884494356
Trained batch 317 in epoch 17, gen_loss = 0.40115220816630237, disc_loss = 0.06151256040060811
Trained batch 318 in epoch 17, gen_loss = 0.4010336939070292, disc_loss = 0.061374981328553076
Trained batch 319 in epoch 17, gen_loss = 0.4013604797422886, disc_loss = 0.061252338530903214
Trained batch 320 in epoch 17, gen_loss = 0.40128453247643703, disc_loss = 0.06110445955895886
Trained batch 321 in epoch 17, gen_loss = 0.40109390973674586, disc_loss = 0.061133815546849775
Trained batch 322 in epoch 17, gen_loss = 0.4011587221002431, disc_loss = 0.0611778719411246
Trained batch 323 in epoch 17, gen_loss = 0.40108492298994536, disc_loss = 0.06102461759777119
Trained batch 324 in epoch 17, gen_loss = 0.40087436098318835, disc_loss = 0.06108884133828374
Trained batch 325 in epoch 17, gen_loss = 0.4009633924514969, disc_loss = 0.06112808556913004
Trained batch 326 in epoch 17, gen_loss = 0.4006962925651387, disc_loss = 0.0611070896219747
Trained batch 327 in epoch 17, gen_loss = 0.40063219953600954, disc_loss = 0.06112000693584133
Trained batch 328 in epoch 17, gen_loss = 0.4007694850757854, disc_loss = 0.061588304223475755
Trained batch 329 in epoch 17, gen_loss = 0.40109018963394744, disc_loss = 0.06164881327245949
Trained batch 330 in epoch 17, gen_loss = 0.40122442672259856, disc_loss = 0.06160118068312365
Trained batch 331 in epoch 17, gen_loss = 0.401005698884108, disc_loss = 0.061579489776112856
Trained batch 332 in epoch 17, gen_loss = 0.4007850773520656, disc_loss = 0.061459005174056454
Trained batch 333 in epoch 17, gen_loss = 0.4008786782711566, disc_loss = 0.061398668520007575
Trained batch 334 in epoch 17, gen_loss = 0.4009127780572692, disc_loss = 0.06160446855086667
Trained batch 335 in epoch 17, gen_loss = 0.4010116523575215, disc_loss = 0.061457619457671954
Trained batch 336 in epoch 17, gen_loss = 0.40106546984935726, disc_loss = 0.06182965232634182
Trained batch 337 in epoch 17, gen_loss = 0.4008619267735961, disc_loss = 0.06214116697651527
Trained batch 338 in epoch 17, gen_loss = 0.40093821454188816, disc_loss = 0.0620302402326469
Trained batch 339 in epoch 17, gen_loss = 0.4006818983484717, disc_loss = 0.06194119615452912
Trained batch 340 in epoch 17, gen_loss = 0.4008016958614249, disc_loss = 0.06198687294137574
Trained batch 341 in epoch 17, gen_loss = 0.40066627225680657, disc_loss = 0.06196780537516532
Trained batch 342 in epoch 17, gen_loss = 0.4005104008812251, disc_loss = 0.0620694531890789
Trained batch 343 in epoch 17, gen_loss = 0.4003812426397967, disc_loss = 0.062459014354782655
Trained batch 344 in epoch 17, gen_loss = 0.4002234768176424, disc_loss = 0.06232501695310508
Trained batch 345 in epoch 17, gen_loss = 0.4002557236679717, disc_loss = 0.06230347589966491
Trained batch 346 in epoch 17, gen_loss = 0.4002916933136646, disc_loss = 0.062171944198319395
Trained batch 347 in epoch 17, gen_loss = 0.39974870267270624, disc_loss = 0.06263948955985278
Trained batch 348 in epoch 17, gen_loss = 0.39980226797838947, disc_loss = 0.06262545516436925
Trained batch 349 in epoch 17, gen_loss = 0.40019537321158816, disc_loss = 0.062498401614970396
Trained batch 350 in epoch 17, gen_loss = 0.3999801365568427, disc_loss = 0.062466784079222175
Trained batch 351 in epoch 17, gen_loss = 0.3998312531039119, disc_loss = 0.06244034808928105
Trained batch 352 in epoch 17, gen_loss = 0.3998830058419333, disc_loss = 0.06237025036431701
Trained batch 353 in epoch 17, gen_loss = 0.3997823562325731, disc_loss = 0.06241813077759734
Trained batch 354 in epoch 17, gen_loss = 0.39985284058141035, disc_loss = 0.06249890871949389
Trained batch 355 in epoch 17, gen_loss = 0.3998507612876678, disc_loss = 0.06236532378779578
Trained batch 356 in epoch 17, gen_loss = 0.3998356186041311, disc_loss = 0.06263605158916917
Trained batch 357 in epoch 17, gen_loss = 0.3996937977535099, disc_loss = 0.06328345949803194
Trained batch 358 in epoch 17, gen_loss = 0.3995060966373486, disc_loss = 0.06356675086625979
Trained batch 359 in epoch 17, gen_loss = 0.39948944167958367, disc_loss = 0.06373212559071059
Trained batch 360 in epoch 17, gen_loss = 0.3995089856211168, disc_loss = 0.06403100373058314
Trained batch 361 in epoch 17, gen_loss = 0.3993657349058278, disc_loss = 0.06424917517492332
Trained batch 362 in epoch 17, gen_loss = 0.3989999049622822, disc_loss = 0.06439354851682857
Trained batch 363 in epoch 17, gen_loss = 0.3988823956185645, disc_loss = 0.06458881542542028
Trained batch 364 in epoch 17, gen_loss = 0.39890706286038435, disc_loss = 0.0644881911996803
Trained batch 365 in epoch 17, gen_loss = 0.39864112664767304, disc_loss = 0.06443002604360341
Trained batch 366 in epoch 17, gen_loss = 0.3985624408364621, disc_loss = 0.06452257377133586
Trained batch 367 in epoch 17, gen_loss = 0.3984476612151965, disc_loss = 0.06454640037871127
Trained batch 368 in epoch 17, gen_loss = 0.3986698825992543, disc_loss = 0.0644317334757608
Trained batch 369 in epoch 17, gen_loss = 0.3986646626446698, disc_loss = 0.06429196711050698
Trained batch 370 in epoch 17, gen_loss = 0.39866894355038746, disc_loss = 0.06415304058730964
Trained batch 371 in epoch 17, gen_loss = 0.39853986376716244, disc_loss = 0.06405873218255859
Trained batch 372 in epoch 17, gen_loss = 0.3984194414705118, disc_loss = 0.06403652324039119
Trained batch 373 in epoch 17, gen_loss = 0.3983619782057675, disc_loss = 0.06392484603145902
Trained batch 374 in epoch 17, gen_loss = 0.3983402458826701, disc_loss = 0.06387668588384986
Trained batch 375 in epoch 17, gen_loss = 0.39816731777279935, disc_loss = 0.06383500757077312
Trained batch 376 in epoch 17, gen_loss = 0.3982988403077467, disc_loss = 0.06383886494221715
Trained batch 377 in epoch 17, gen_loss = 0.39850726290039284, disc_loss = 0.06369992024413058
Trained batch 378 in epoch 17, gen_loss = 0.398272938810112, disc_loss = 0.06381391057754451
Trained batch 379 in epoch 17, gen_loss = 0.3985393335944728, disc_loss = 0.0637439914550142
Trained batch 380 in epoch 17, gen_loss = 0.3984493659393681, disc_loss = 0.06389836418586649
Trained batch 381 in epoch 17, gen_loss = 0.3984431306885175, disc_loss = 0.06378560179859127
Trained batch 382 in epoch 17, gen_loss = 0.3984597771192655, disc_loss = 0.06373752234503627
Trained batch 383 in epoch 17, gen_loss = 0.39831704235014814, disc_loss = 0.06368214542089845
Trained batch 384 in epoch 17, gen_loss = 0.3982894511965962, disc_loss = 0.06353667440352502
Trained batch 385 in epoch 17, gen_loss = 0.39842287053407166, disc_loss = 0.06343435324786395
Trained batch 386 in epoch 17, gen_loss = 0.39823242059357716, disc_loss = 0.0636068905441413
Trained batch 387 in epoch 17, gen_loss = 0.3984083728384726, disc_loss = 0.0635718889774505
Trained batch 388 in epoch 17, gen_loss = 0.3983412322164501, disc_loss = 0.06361292368208075
Trained batch 389 in epoch 17, gen_loss = 0.39809741186789976, disc_loss = 0.06380065683848583
Trained batch 390 in epoch 17, gen_loss = 0.3981445141308143, disc_loss = 0.06421047251414308
Trained batch 391 in epoch 17, gen_loss = 0.3979890378458159, disc_loss = 0.06431485705400761
Trained batch 392 in epoch 17, gen_loss = 0.3979705746543923, disc_loss = 0.06420399958111403
Trained batch 393 in epoch 17, gen_loss = 0.3981759325804444, disc_loss = 0.06423792725684226
Trained batch 394 in epoch 17, gen_loss = 0.39838857130159305, disc_loss = 0.06413565513359595
Trained batch 395 in epoch 17, gen_loss = 0.3984287223129561, disc_loss = 0.06405190408530861
Trained batch 396 in epoch 17, gen_loss = 0.3983334642963986, disc_loss = 0.06395298836081845
Trained batch 397 in epoch 17, gen_loss = 0.3983808582152554, disc_loss = 0.06383380834855626
Trained batch 398 in epoch 17, gen_loss = 0.3984032048468004, disc_loss = 0.06377045238824715
Trained batch 399 in epoch 17, gen_loss = 0.39841795437037947, disc_loss = 0.06366080421023071
Trained batch 400 in epoch 17, gen_loss = 0.39838069922608926, disc_loss = 0.06373269156439049
Trained batch 401 in epoch 17, gen_loss = 0.39844347025031474, disc_loss = 0.06378525674380177
Trained batch 402 in epoch 17, gen_loss = 0.39858622919241193, disc_loss = 0.063655515182902
Trained batch 403 in epoch 17, gen_loss = 0.3986498876520903, disc_loss = 0.06366307653329971
Trained batch 404 in epoch 17, gen_loss = 0.3982919534047445, disc_loss = 0.06374898333746341
Trained batch 405 in epoch 17, gen_loss = 0.3982568852273114, disc_loss = 0.06363458640350424
Trained batch 406 in epoch 17, gen_loss = 0.39841558745803646, disc_loss = 0.06356605472551151
Trained batch 407 in epoch 17, gen_loss = 0.39865630558308435, disc_loss = 0.06344941473228163
Trained batch 408 in epoch 17, gen_loss = 0.398603863267269, disc_loss = 0.06339180219262693
Trained batch 409 in epoch 17, gen_loss = 0.39850832863551816, disc_loss = 0.06328144726093586
Trained batch 410 in epoch 17, gen_loss = 0.3984945792061279, disc_loss = 0.06350633435159776
Trained batch 411 in epoch 17, gen_loss = 0.39817914193116344, disc_loss = 0.06383712823249545
Trained batch 412 in epoch 17, gen_loss = 0.39826606448568386, disc_loss = 0.06395764748360645
Trained batch 413 in epoch 17, gen_loss = 0.3982086913741153, disc_loss = 0.06383506079757775
Trained batch 414 in epoch 17, gen_loss = 0.39812266481928077, disc_loss = 0.06374684740755572
Trained batch 415 in epoch 17, gen_loss = 0.39803591628487295, disc_loss = 0.06362426411047076
Trained batch 416 in epoch 17, gen_loss = 0.39823127693409544, disc_loss = 0.06349669610835808
Trained batch 417 in epoch 17, gen_loss = 0.3980439200498271, disc_loss = 0.06339823655588062
Trained batch 418 in epoch 17, gen_loss = 0.3979691956947982, disc_loss = 0.06332059105000235
Trained batch 419 in epoch 17, gen_loss = 0.3983236402273178, disc_loss = 0.06319117606839254
Trained batch 420 in epoch 17, gen_loss = 0.3983404687351399, disc_loss = 0.06309999937452641
Trained batch 421 in epoch 17, gen_loss = 0.39837290509052187, disc_loss = 0.06314725885653241
Trained batch 422 in epoch 17, gen_loss = 0.3984461542985118, disc_loss = 0.06314475133786106
Trained batch 423 in epoch 17, gen_loss = 0.3984837679649299, disc_loss = 0.06302138133510456
Trained batch 424 in epoch 17, gen_loss = 0.39857834640671225, disc_loss = 0.06294974093270653
Trained batch 425 in epoch 17, gen_loss = 0.39872323473294574, disc_loss = 0.06288276274552998
Trained batch 426 in epoch 17, gen_loss = 0.3986279547772865, disc_loss = 0.06283096764323932
Trained batch 427 in epoch 17, gen_loss = 0.3985922237701505, disc_loss = 0.0627538073768787
Trained batch 428 in epoch 17, gen_loss = 0.39867433148386316, disc_loss = 0.0626640307211202
Trained batch 429 in epoch 17, gen_loss = 0.39859688559243844, disc_loss = 0.06255633997146128
Trained batch 430 in epoch 17, gen_loss = 0.39884792416942094, disc_loss = 0.0627069404443808
Trained batch 431 in epoch 17, gen_loss = 0.398702801377685, disc_loss = 0.06316355598391965
Trained batch 432 in epoch 17, gen_loss = 0.3988023471199062, disc_loss = 0.06308521930231577
Trained batch 433 in epoch 17, gen_loss = 0.39890297141767317, disc_loss = 0.06304521891524509
Trained batch 434 in epoch 17, gen_loss = 0.3989035065146698, disc_loss = 0.0630183248534456
Trained batch 435 in epoch 17, gen_loss = 0.39892031307067344, disc_loss = 0.06298699411307249
Trained batch 436 in epoch 17, gen_loss = 0.39911397643711255, disc_loss = 0.06286250099804022
Trained batch 437 in epoch 17, gen_loss = 0.399129782501421, disc_loss = 0.062780937781668
Trained batch 438 in epoch 17, gen_loss = 0.3989432466328823, disc_loss = 0.06268456061678283
Trained batch 439 in epoch 17, gen_loss = 0.3987946809692816, disc_loss = 0.06258665123658086
Trained batch 440 in epoch 17, gen_loss = 0.39885088091804866, disc_loss = 0.062472063253999024
Trained batch 441 in epoch 17, gen_loss = 0.39865105083355534, disc_loss = 0.06243787340111862
Trained batch 442 in epoch 17, gen_loss = 0.39853741063759507, disc_loss = 0.06247115927342636
Trained batch 443 in epoch 17, gen_loss = 0.39866199471929054, disc_loss = 0.062401497207984734
Trained batch 444 in epoch 17, gen_loss = 0.3987213375193349, disc_loss = 0.06252720135818707
Trained batch 445 in epoch 17, gen_loss = 0.3988588130928476, disc_loss = 0.06309052841579166
Trained batch 446 in epoch 17, gen_loss = 0.3987409918500273, disc_loss = 0.06313771823675307
Trained batch 447 in epoch 17, gen_loss = 0.39892597449943423, disc_loss = 0.06331270671216771
Trained batch 448 in epoch 17, gen_loss = 0.3986672186240853, disc_loss = 0.06341398730542187
Trained batch 449 in epoch 17, gen_loss = 0.398789417942365, disc_loss = 0.06338406912154622
Trained batch 450 in epoch 17, gen_loss = 0.3988363300749574, disc_loss = 0.06340947083121129
Trained batch 451 in epoch 17, gen_loss = 0.39895015130792044, disc_loss = 0.06333357362752468
Trained batch 452 in epoch 17, gen_loss = 0.39892315088255254, disc_loss = 0.06326014704377314
Trained batch 453 in epoch 17, gen_loss = 0.3989462682460373, disc_loss = 0.0632375099774171
Trained batch 454 in epoch 17, gen_loss = 0.39892718287614676, disc_loss = 0.0634677450203306
Trained batch 455 in epoch 17, gen_loss = 0.3987332809912531, disc_loss = 0.06379738676753875
Trained batch 456 in epoch 17, gen_loss = 0.3987037793812658, disc_loss = 0.06375381379455523
Trained batch 457 in epoch 17, gen_loss = 0.39878122137623584, disc_loss = 0.06380862169634698
Trained batch 458 in epoch 17, gen_loss = 0.39891251986582554, disc_loss = 0.06370117363148654
Testing Epoch 17
Training Epoch 18
Trained batch 0 in epoch 18, gen_loss = 0.3917641341686249, disc_loss = 0.14664392173290253
Trained batch 1 in epoch 18, gen_loss = 0.41394859552383423, disc_loss = 0.08697719499468803
Trained batch 2 in epoch 18, gen_loss = 0.41479821999867755, disc_loss = 0.08609738200902939
Trained batch 3 in epoch 18, gen_loss = 0.4033626541495323, disc_loss = 0.07858577370643616
Trained batch 4 in epoch 18, gen_loss = 0.3860215604305267, disc_loss = 0.07449831068515778
Trained batch 5 in epoch 18, gen_loss = 0.4023236731688182, disc_loss = 0.07035344218214352
Trained batch 6 in epoch 18, gen_loss = 0.3966137000492641, disc_loss = 0.06264285264270646
Trained batch 7 in epoch 18, gen_loss = 0.3929443545639515, disc_loss = 0.06088908948004246
Trained batch 8 in epoch 18, gen_loss = 0.400359355741077, disc_loss = 0.05567991671462854
Trained batch 9 in epoch 18, gen_loss = 0.4002153813838959, disc_loss = 0.05298974756151438
Trained batch 10 in epoch 18, gen_loss = 0.4010647345672954, disc_loss = 0.05365068516270681
Trained batch 11 in epoch 18, gen_loss = 0.4037887429197629, disc_loss = 0.053069515619426966
Trained batch 12 in epoch 18, gen_loss = 0.4067699932135068, disc_loss = 0.05212520048595392
Trained batch 13 in epoch 18, gen_loss = 0.4038923510483333, disc_loss = 0.05482911890638726
Trained batch 14 in epoch 18, gen_loss = 0.40924890637397765, disc_loss = 0.05733697650333246
Trained batch 15 in epoch 18, gen_loss = 0.4105037711560726, disc_loss = 0.05492659017909318
Trained batch 16 in epoch 18, gen_loss = 0.40441788995967193, disc_loss = 0.054847305859712994
Trained batch 17 in epoch 18, gen_loss = 0.40298110577795243, disc_loss = 0.05261178118073278
Trained batch 18 in epoch 18, gen_loss = 0.4043198792557967, disc_loss = 0.05017089434458237
Trained batch 19 in epoch 18, gen_loss = 0.40578105598688125, disc_loss = 0.04812971360515803
Trained batch 20 in epoch 18, gen_loss = 0.40510781747954233, disc_loss = 0.0462083335788477
Trained batch 21 in epoch 18, gen_loss = 0.4079627367583188, disc_loss = 0.04472187462008812
Trained batch 22 in epoch 18, gen_loss = 0.4053066917087721, disc_loss = 0.04376433494136385
Trained batch 23 in epoch 18, gen_loss = 0.40361755589644116, disc_loss = 0.04322240660743167
Trained batch 24 in epoch 18, gen_loss = 0.40161221861839297, disc_loss = 0.04284881372004747
Trained batch 25 in epoch 18, gen_loss = 0.3990483559094943, disc_loss = 0.043236174155026674
Trained batch 26 in epoch 18, gen_loss = 0.39695185974792196, disc_loss = 0.048413686074868394
Trained batch 27 in epoch 18, gen_loss = 0.4007377273270062, disc_loss = 0.0530879485886544
Trained batch 28 in epoch 18, gen_loss = 0.4040939694848554, disc_loss = 0.05181310354764092
Trained batch 29 in epoch 18, gen_loss = 0.402538334329923, disc_loss = 0.05156663510327538
Trained batch 30 in epoch 18, gen_loss = 0.3997231856469185, disc_loss = 0.05061405647786394
Trained batch 31 in epoch 18, gen_loss = 0.3994773104786873, disc_loss = 0.049377446790458634
Trained batch 32 in epoch 18, gen_loss = 0.3991265125346906, disc_loss = 0.04819098620139288
Trained batch 33 in epoch 18, gen_loss = 0.399208227501196, disc_loss = 0.04707612836843028
Trained batch 34 in epoch 18, gen_loss = 0.4010356094155993, disc_loss = 0.046269635590059414
Trained batch 35 in epoch 18, gen_loss = 0.4005563250846333, disc_loss = 0.04614684756638275
Trained batch 36 in epoch 18, gen_loss = 0.39854230510221944, disc_loss = 0.04796920258652519
Trained batch 37 in epoch 18, gen_loss = 0.39870899680413696, disc_loss = 0.04803914758131692
Trained batch 38 in epoch 18, gen_loss = 0.3981115970856104, disc_loss = 0.047893716977574885
Trained batch 39 in epoch 18, gen_loss = 0.3977523632347584, disc_loss = 0.04742797198705375
Trained batch 40 in epoch 18, gen_loss = 0.39836255442805407, disc_loss = 0.04649192528662885
Trained batch 41 in epoch 18, gen_loss = 0.3990395963191986, disc_loss = 0.0462007086857089
Trained batch 42 in epoch 18, gen_loss = 0.3973579032476558, disc_loss = 0.045801835892678694
Trained batch 43 in epoch 18, gen_loss = 0.3966250731186433, disc_loss = 0.04898319446312433
Trained batch 44 in epoch 18, gen_loss = 0.39473790129025776, disc_loss = 0.05338728910105096
Trained batch 45 in epoch 18, gen_loss = 0.3954606794792673, disc_loss = 0.05279452829500255
Trained batch 46 in epoch 18, gen_loss = 0.3972790355378009, disc_loss = 0.05204020018510996
Trained batch 47 in epoch 18, gen_loss = 0.3964869175106287, disc_loss = 0.05182911213099336
Trained batch 48 in epoch 18, gen_loss = 0.3949101311819894, disc_loss = 0.05162429678424889
Trained batch 49 in epoch 18, gen_loss = 0.39540216863155364, disc_loss = 0.05116893297061324
Trained batch 50 in epoch 18, gen_loss = 0.3955716046632505, disc_loss = 0.05116932961505418
Trained batch 51 in epoch 18, gen_loss = 0.393884753378538, disc_loss = 0.051338220498739526
Trained batch 52 in epoch 18, gen_loss = 0.39411099845508357, disc_loss = 0.051049799482636854
Trained batch 53 in epoch 18, gen_loss = 0.39425865312417346, disc_loss = 0.056453993664709504
Trained batch 54 in epoch 18, gen_loss = 0.3926655742255124, disc_loss = 0.05650642891837792
Trained batch 55 in epoch 18, gen_loss = 0.39038986606257303, disc_loss = 0.058427727099375
Trained batch 56 in epoch 18, gen_loss = 0.39077907696104885, disc_loss = 0.05799491368560938
Trained batch 57 in epoch 18, gen_loss = 0.39118594445031263, disc_loss = 0.05733639616840359
Trained batch 58 in epoch 18, gen_loss = 0.3918414232084307, disc_loss = 0.056943469617705224
Trained batch 59 in epoch 18, gen_loss = 0.3919066225488981, disc_loss = 0.05678942127463718
Trained batch 60 in epoch 18, gen_loss = 0.39230906523641995, disc_loss = 0.05777761705036535
Trained batch 61 in epoch 18, gen_loss = 0.39258387540617296, disc_loss = 0.058187351937616066
Trained batch 62 in epoch 18, gen_loss = 0.39312315696761724, disc_loss = 0.0578641395217606
Trained batch 63 in epoch 18, gen_loss = 0.39225924061611295, disc_loss = 0.06085333837836515
Trained batch 64 in epoch 18, gen_loss = 0.3941804505311526, disc_loss = 0.06314430722536948
Trained batch 65 in epoch 18, gen_loss = 0.39473522251302545, disc_loss = 0.062798813592191
Trained batch 66 in epoch 18, gen_loss = 0.3956834077835083, disc_loss = 0.06214982191962538
Trained batch 67 in epoch 18, gen_loss = 0.39595765576643105, disc_loss = 0.06159361472408123
Trained batch 68 in epoch 18, gen_loss = 0.39684363033460535, disc_loss = 0.0608913319023407
Trained batch 69 in epoch 18, gen_loss = 0.3973535286528724, disc_loss = 0.060155704976724726
Trained batch 70 in epoch 18, gen_loss = 0.3966254029475467, disc_loss = 0.05964752175176228
Trained batch 71 in epoch 18, gen_loss = 0.3973059273428387, disc_loss = 0.059070261182366975
Trained batch 72 in epoch 18, gen_loss = 0.397557697475773, disc_loss = 0.059046376432764204
Trained batch 73 in epoch 18, gen_loss = 0.3970088515732739, disc_loss = 0.05899147869314294
Trained batch 74 in epoch 18, gen_loss = 0.3961283548672994, disc_loss = 0.05878283151735862
Trained batch 75 in epoch 18, gen_loss = 0.39702035721979645, disc_loss = 0.05826685365632569
Trained batch 76 in epoch 18, gen_loss = 0.3967766502460876, disc_loss = 0.05812505171815684
Trained batch 77 in epoch 18, gen_loss = 0.39593238555468047, disc_loss = 0.058442186982108235
Trained batch 78 in epoch 18, gen_loss = 0.3956521326982522, disc_loss = 0.05901099754426675
Trained batch 79 in epoch 18, gen_loss = 0.39485084600746634, disc_loss = 0.05945598058169708
Trained batch 80 in epoch 18, gen_loss = 0.39516766608497245, disc_loss = 0.060401571788077736
Trained batch 81 in epoch 18, gen_loss = 0.3950917909785015, disc_loss = 0.05975434468014211
Trained batch 82 in epoch 18, gen_loss = 0.3951474489217781, disc_loss = 0.05982919982129551
Trained batch 83 in epoch 18, gen_loss = 0.3958767883124806, disc_loss = 0.05946972394096
Trained batch 84 in epoch 18, gen_loss = 0.39547442092615015, disc_loss = 0.05940553063855452
Trained batch 85 in epoch 18, gen_loss = 0.3956975035889204, disc_loss = 0.05929012964804505
Trained batch 86 in epoch 18, gen_loss = 0.3962963634523852, disc_loss = 0.05909022855861434
Trained batch 87 in epoch 18, gen_loss = 0.39541125670075417, disc_loss = 0.05985760955478658
Trained batch 88 in epoch 18, gen_loss = 0.3949769042181165, disc_loss = 0.05953097307866209
Trained batch 89 in epoch 18, gen_loss = 0.39580917391512127, disc_loss = 0.06061749290674925
Trained batch 90 in epoch 18, gen_loss = 0.3945661334546058, disc_loss = 0.06140197467591081
Trained batch 91 in epoch 18, gen_loss = 0.3944582006205683, disc_loss = 0.061532986937495676
Trained batch 92 in epoch 18, gen_loss = 0.3941230357334178, disc_loss = 0.06129038552202845
Trained batch 93 in epoch 18, gen_loss = 0.39416564430328127, disc_loss = 0.06091341988599681
Trained batch 94 in epoch 18, gen_loss = 0.3937100162631587, disc_loss = 0.06087090367157208
Trained batch 95 in epoch 18, gen_loss = 0.39340936827162903, disc_loss = 0.06067772099049762
Trained batch 96 in epoch 18, gen_loss = 0.3932233077963603, disc_loss = 0.060678750948654006
Trained batch 97 in epoch 18, gen_loss = 0.3935789906856965, disc_loss = 0.06043774130925232
Trained batch 98 in epoch 18, gen_loss = 0.39421772053747467, disc_loss = 0.05999104561980324
Trained batch 99 in epoch 18, gen_loss = 0.39366537988185885, disc_loss = 0.05968327380716801
Trained batch 100 in epoch 18, gen_loss = 0.39270163497122207, disc_loss = 0.05954870699655892
Trained batch 101 in epoch 18, gen_loss = 0.3929249524485831, disc_loss = 0.05924943693931781
Trained batch 102 in epoch 18, gen_loss = 0.39329242532693065, disc_loss = 0.058879090075209306
Trained batch 103 in epoch 18, gen_loss = 0.3936494439840317, disc_loss = 0.05859080320582367
Trained batch 104 in epoch 18, gen_loss = 0.3937458325000036, disc_loss = 0.05831615055600802
Trained batch 105 in epoch 18, gen_loss = 0.3930909869805822, disc_loss = 0.05803930903521349
Trained batch 106 in epoch 18, gen_loss = 0.3937602121139241, disc_loss = 0.059638282023022106
Trained batch 107 in epoch 18, gen_loss = 0.3933930634348481, disc_loss = 0.060852958268865394
Trained batch 108 in epoch 18, gen_loss = 0.39391259917425453, disc_loss = 0.06049102305545719
Trained batch 109 in epoch 18, gen_loss = 0.3943739481947639, disc_loss = 0.06104574366049333
Trained batch 110 in epoch 18, gen_loss = 0.39404354412276466, disc_loss = 0.061039554878129614
Trained batch 111 in epoch 18, gen_loss = 0.3947864749601909, disc_loss = 0.060673726606182754
Trained batch 112 in epoch 18, gen_loss = 0.39436213790842917, disc_loss = 0.060267606008369314
Trained batch 113 in epoch 18, gen_loss = 0.39348512155967846, disc_loss = 0.0600624446217951
Trained batch 114 in epoch 18, gen_loss = 0.3930446640304897, disc_loss = 0.06133756491801013
Trained batch 115 in epoch 18, gen_loss = 0.3931573770683387, disc_loss = 0.06380004162803807
Trained batch 116 in epoch 18, gen_loss = 0.393353969622881, disc_loss = 0.06398771381658366
Trained batch 117 in epoch 18, gen_loss = 0.39368826100381754, disc_loss = 0.06437542766206346
Trained batch 118 in epoch 18, gen_loss = 0.39270301426158233, disc_loss = 0.0647167518672322
Trained batch 119 in epoch 18, gen_loss = 0.3925735595325629, disc_loss = 0.06470611495897174
Trained batch 120 in epoch 18, gen_loss = 0.3921744500802568, disc_loss = 0.06503948461541459
Trained batch 121 in epoch 18, gen_loss = 0.392173202067125, disc_loss = 0.065128624164423
Trained batch 122 in epoch 18, gen_loss = 0.3919607764337121, disc_loss = 0.06480059942336587
Trained batch 123 in epoch 18, gen_loss = 0.3921461876842283, disc_loss = 0.06485178405719419
Trained batch 124 in epoch 18, gen_loss = 0.39194600129127505, disc_loss = 0.06508803969621658
Trained batch 125 in epoch 18, gen_loss = 0.39337222420033957, disc_loss = 0.06483203045550794
Trained batch 126 in epoch 18, gen_loss = 0.3942457791857832, disc_loss = 0.0644424186770137
Trained batch 127 in epoch 18, gen_loss = 0.3946002668235451, disc_loss = 0.06414286630752031
Trained batch 128 in epoch 18, gen_loss = 0.39434905731400777, disc_loss = 0.06405457823948804
Trained batch 129 in epoch 18, gen_loss = 0.39473546468294585, disc_loss = 0.06438325275308811
Trained batch 130 in epoch 18, gen_loss = 0.3949431105879427, disc_loss = 0.06446963933986107
Trained batch 131 in epoch 18, gen_loss = 0.3951257905273726, disc_loss = 0.0641294650197255
Trained batch 132 in epoch 18, gen_loss = 0.39526888884996114, disc_loss = 0.06380001811268635
Trained batch 133 in epoch 18, gen_loss = 0.394811551517515, disc_loss = 0.06376555247871733
Trained batch 134 in epoch 18, gen_loss = 0.394869903281883, disc_loss = 0.06353601702937374
Trained batch 135 in epoch 18, gen_loss = 0.3951944178518127, disc_loss = 0.06314518069848418
Trained batch 136 in epoch 18, gen_loss = 0.39562002977315525, disc_loss = 0.0627488065578968
Trained batch 137 in epoch 18, gen_loss = 0.395434669394424, disc_loss = 0.06258269333941997
Trained batch 138 in epoch 18, gen_loss = 0.3957734013632905, disc_loss = 0.06299894468577431
Trained batch 139 in epoch 18, gen_loss = 0.39549373941762106, disc_loss = 0.06323486188027476
Trained batch 140 in epoch 18, gen_loss = 0.39592245453638386, disc_loss = 0.06298094580333072
Trained batch 141 in epoch 18, gen_loss = 0.39627144852994195, disc_loss = 0.06290124529238109
Trained batch 142 in epoch 18, gen_loss = 0.39640385475192036, disc_loss = 0.06288044104495874
Trained batch 143 in epoch 18, gen_loss = 0.3964706226769421, disc_loss = 0.06250554748112336
Trained batch 144 in epoch 18, gen_loss = 0.39622497538040424, disc_loss = 0.062151516460139174
Trained batch 145 in epoch 18, gen_loss = 0.3964748551992521, disc_loss = 0.06191632696363616
Trained batch 146 in epoch 18, gen_loss = 0.39642143675259184, disc_loss = 0.06156817485964825
Trained batch 147 in epoch 18, gen_loss = 0.3963245930703911, disc_loss = 0.06159492669551558
Trained batch 148 in epoch 18, gen_loss = 0.3966246153284239, disc_loss = 0.0627675398171648
Trained batch 149 in epoch 18, gen_loss = 0.3962673775355021, disc_loss = 0.06349995937819282
Trained batch 150 in epoch 18, gen_loss = 0.3971124761151952, disc_loss = 0.06325444423081662
Trained batch 151 in epoch 18, gen_loss = 0.3971830559404273, disc_loss = 0.06304189706784918
Trained batch 152 in epoch 18, gen_loss = 0.3971794364499111, disc_loss = 0.06267426662402702
Trained batch 153 in epoch 18, gen_loss = 0.39695301922884857, disc_loss = 0.06231587512309772
Trained batch 154 in epoch 18, gen_loss = 0.3968318620035725, disc_loss = 0.0619582750353842
Trained batch 155 in epoch 18, gen_loss = 0.39683131854503584, disc_loss = 0.06166565766593871
Trained batch 156 in epoch 18, gen_loss = 0.3969901604637219, disc_loss = 0.061311883851885796
Trained batch 157 in epoch 18, gen_loss = 0.39672768851624257, disc_loss = 0.06111303560105683
Trained batch 158 in epoch 18, gen_loss = 0.39687376052328627, disc_loss = 0.06076200832407804
Trained batch 159 in epoch 18, gen_loss = 0.3969081252813339, disc_loss = 0.06046572575578466
Trained batch 160 in epoch 18, gen_loss = 0.39640445368630545, disc_loss = 0.06012932997289466
Trained batch 161 in epoch 18, gen_loss = 0.3962584794671447, disc_loss = 0.059793819604372536
Trained batch 162 in epoch 18, gen_loss = 0.3961279008286131, disc_loss = 0.05949591376755867
Trained batch 163 in epoch 18, gen_loss = 0.3963059713927711, disc_loss = 0.059243453734713354
Trained batch 164 in epoch 18, gen_loss = 0.3963465780922861, disc_loss = 0.059132770629543245
Trained batch 165 in epoch 18, gen_loss = 0.3963664283594453, disc_loss = 0.058829040490988506
Trained batch 166 in epoch 18, gen_loss = 0.3959835658887189, disc_loss = 0.058615766811424386
Trained batch 167 in epoch 18, gen_loss = 0.39595485088371096, disc_loss = 0.05851982113727856
Trained batch 168 in epoch 18, gen_loss = 0.3960836515624142, disc_loss = 0.05822521338470765
Trained batch 169 in epoch 18, gen_loss = 0.39613130565951854, disc_loss = 0.058120824358261686
Trained batch 170 in epoch 18, gen_loss = 0.39554590997640154, disc_loss = 0.05893051681484569
Trained batch 171 in epoch 18, gen_loss = 0.3955917971771817, disc_loss = 0.05977704562788266
Trained batch 172 in epoch 18, gen_loss = 0.39608742598164287, disc_loss = 0.05953330456715271
Trained batch 173 in epoch 18, gen_loss = 0.39656846687711517, disc_loss = 0.05926954217426393
Trained batch 174 in epoch 18, gen_loss = 0.39681241818836754, disc_loss = 0.059026579345975605
Trained batch 175 in epoch 18, gen_loss = 0.39651874046434055, disc_loss = 0.058792331838048995
Trained batch 176 in epoch 18, gen_loss = 0.39645186268677146, disc_loss = 0.05849731538318476
Trained batch 177 in epoch 18, gen_loss = 0.3962866680675678, disc_loss = 0.0582060160774612
Trained batch 178 in epoch 18, gen_loss = 0.3961512293229556, disc_loss = 0.05791529288057592
Trained batch 179 in epoch 18, gen_loss = 0.39668246375189886, disc_loss = 0.05771247101171563
Trained batch 180 in epoch 18, gen_loss = 0.3963873335340405, disc_loss = 0.057626431100379204
Trained batch 181 in epoch 18, gen_loss = 0.3965084688676583, disc_loss = 0.05738341260015719
Trained batch 182 in epoch 18, gen_loss = 0.39655520811758405, disc_loss = 0.05710420480171025
Trained batch 183 in epoch 18, gen_loss = 0.3966660332744536, disc_loss = 0.05685722631017637
Trained batch 184 in epoch 18, gen_loss = 0.396770967825039, disc_loss = 0.056616237291411776
Trained batch 185 in epoch 18, gen_loss = 0.3970285194214954, disc_loss = 0.05634062782540837
Trained batch 186 in epoch 18, gen_loss = 0.3964189475870387, disc_loss = 0.05646703413433649
Trained batch 187 in epoch 18, gen_loss = 0.39642926606726137, disc_loss = 0.056896009276858825
Trained batch 188 in epoch 18, gen_loss = 0.3961876316991433, disc_loss = 0.056673329956730994
Trained batch 189 in epoch 18, gen_loss = 0.39584818968647406, disc_loss = 0.056622735766301814
Trained batch 190 in epoch 18, gen_loss = 0.39626125889922936, disc_loss = 0.05637001086523786
Trained batch 191 in epoch 18, gen_loss = 0.396548504785945, disc_loss = 0.056159294416526485
Trained batch 192 in epoch 18, gen_loss = 0.3967241431764988, disc_loss = 0.056009191365845
Trained batch 193 in epoch 18, gen_loss = 0.39666774100864055, disc_loss = 0.05588836551490288
Trained batch 194 in epoch 18, gen_loss = 0.39673904883555877, disc_loss = 0.055670369065438326
Trained batch 195 in epoch 18, gen_loss = 0.3966107724272475, disc_loss = 0.0554363384904644
Trained batch 196 in epoch 18, gen_loss = 0.3968330990844572, disc_loss = 0.055261969928000934
Trained batch 197 in epoch 18, gen_loss = 0.396623408704093, disc_loss = 0.05507433756179355
Trained batch 198 in epoch 18, gen_loss = 0.3967094800280566, disc_loss = 0.055003892679478805
Trained batch 199 in epoch 18, gen_loss = 0.3962245997786522, disc_loss = 0.05534401412354782
Trained batch 200 in epoch 18, gen_loss = 0.39668961632904126, disc_loss = 0.055289551868237814
Trained batch 201 in epoch 18, gen_loss = 0.39687156293651843, disc_loss = 0.055405240167061436
Trained batch 202 in epoch 18, gen_loss = 0.3970818305250459, disc_loss = 0.05539575218466188
Trained batch 203 in epoch 18, gen_loss = 0.39706673750690386, disc_loss = 0.055199390904996176
Trained batch 204 in epoch 18, gen_loss = 0.3968596925095814, disc_loss = 0.054982247119542305
Trained batch 205 in epoch 18, gen_loss = 0.3968983811950221, disc_loss = 0.05477460879534121
Trained batch 206 in epoch 18, gen_loss = 0.3968825561988757, disc_loss = 0.05466416187287457
Trained batch 207 in epoch 18, gen_loss = 0.3973907664991342, disc_loss = 0.05454806763848934
Trained batch 208 in epoch 18, gen_loss = 0.39739261460646486, disc_loss = 0.05452983934013396
Trained batch 209 in epoch 18, gen_loss = 0.39703271090984343, disc_loss = 0.055204776539245534
Trained batch 210 in epoch 18, gen_loss = 0.3973210099466604, disc_loss = 0.0559423280972546
Trained batch 211 in epoch 18, gen_loss = 0.39714502922768863, disc_loss = 0.05575437016811503
Trained batch 212 in epoch 18, gen_loss = 0.39682885724613925, disc_loss = 0.056041388153732524
Trained batch 213 in epoch 18, gen_loss = 0.39723408389314313, disc_loss = 0.05584434098477049
Trained batch 214 in epoch 18, gen_loss = 0.3973963543426159, disc_loss = 0.05567277505084179
Trained batch 215 in epoch 18, gen_loss = 0.3973439370316488, disc_loss = 0.05555523097023575
Trained batch 216 in epoch 18, gen_loss = 0.3971845117582154, disc_loss = 0.05546933252681991
Trained batch 217 in epoch 18, gen_loss = 0.39685531439037497, disc_loss = 0.05534233241512893
Trained batch 218 in epoch 18, gen_loss = 0.3964722737601903, disc_loss = 0.055132585924254844
Trained batch 219 in epoch 18, gen_loss = 0.39623954120007426, disc_loss = 0.05492384018249471
Trained batch 220 in epoch 18, gen_loss = 0.39635769854303937, disc_loss = 0.054720396211800665
Trained batch 221 in epoch 18, gen_loss = 0.3966791970772786, disc_loss = 0.05460616861688191
Trained batch 222 in epoch 18, gen_loss = 0.39663424205886944, disc_loss = 0.054628438606540854
Trained batch 223 in epoch 18, gen_loss = 0.3967339960592134, disc_loss = 0.05449256476588614
Trained batch 224 in epoch 18, gen_loss = 0.39644459207852684, disc_loss = 0.05445027006376121
Trained batch 225 in epoch 18, gen_loss = 0.3967170346099719, disc_loss = 0.05430441011213162
Trained batch 226 in epoch 18, gen_loss = 0.3966456268327352, disc_loss = 0.05428843022352864
Trained batch 227 in epoch 18, gen_loss = 0.39644877756373925, disc_loss = 0.05448576692990109
Trained batch 228 in epoch 18, gen_loss = 0.3966872789714014, disc_loss = 0.054342516533233326
Trained batch 229 in epoch 18, gen_loss = 0.396761916772179, disc_loss = 0.054155806575537375
Trained batch 230 in epoch 18, gen_loss = 0.39709918362237673, disc_loss = 0.05396689020411728
Trained batch 231 in epoch 18, gen_loss = 0.3969040414125755, disc_loss = 0.053888658067645055
Trained batch 232 in epoch 18, gen_loss = 0.39677745014301186, disc_loss = 0.05372948406360116
Trained batch 233 in epoch 18, gen_loss = 0.39631548663999283, disc_loss = 0.05358168742874175
Trained batch 234 in epoch 18, gen_loss = 0.39661541264107886, disc_loss = 0.053400997292408915
Trained batch 235 in epoch 18, gen_loss = 0.396837508274337, disc_loss = 0.05320766581403944
Trained batch 236 in epoch 18, gen_loss = 0.39693754207232834, disc_loss = 0.053024660664284406
Trained batch 237 in epoch 18, gen_loss = 0.39725141289855254, disc_loss = 0.0528410820803065
Trained batch 238 in epoch 18, gen_loss = 0.3970322833400391, disc_loss = 0.05267978183512097
Trained batch 239 in epoch 18, gen_loss = 0.39685002056260904, disc_loss = 0.052604476841709887
Trained batch 240 in epoch 18, gen_loss = 0.3971000646407179, disc_loss = 0.052474069936564234
Trained batch 241 in epoch 18, gen_loss = 0.39684301750226453, disc_loss = 0.052497206885013574
Trained batch 242 in epoch 18, gen_loss = 0.3963377403378977, disc_loss = 0.052726213883516594
Trained batch 243 in epoch 18, gen_loss = 0.3964146903303803, disc_loss = 0.05267733649816364
Trained batch 244 in epoch 18, gen_loss = 0.3966042830019581, disc_loss = 0.05248515855863082
Trained batch 245 in epoch 18, gen_loss = 0.39658721893783505, disc_loss = 0.05229678060821583
Trained batch 246 in epoch 18, gen_loss = 0.39642513003426527, disc_loss = 0.052105110538331605
Trained batch 247 in epoch 18, gen_loss = 0.3966043157683265, disc_loss = 0.05195565074832449
Trained batch 248 in epoch 18, gen_loss = 0.396915649194794, disc_loss = 0.05182256341638814
Trained batch 249 in epoch 18, gen_loss = 0.39725443398952487, disc_loss = 0.05167297531291842
Trained batch 250 in epoch 18, gen_loss = 0.39745561072075986, disc_loss = 0.05156774991433103
Trained batch 251 in epoch 18, gen_loss = 0.3976956806958668, disc_loss = 0.0514546041413846
Trained batch 252 in epoch 18, gen_loss = 0.39767693613357696, disc_loss = 0.051343152987892215
Trained batch 253 in epoch 18, gen_loss = 0.39793382057054777, disc_loss = 0.05118282624029034
Trained batch 254 in epoch 18, gen_loss = 0.3981209057218888, disc_loss = 0.05101180565634779
Trained batch 255 in epoch 18, gen_loss = 0.3981922318926081, disc_loss = 0.05087382314741262
Trained batch 256 in epoch 18, gen_loss = 0.3982486396680082, disc_loss = 0.0507189239545613
Trained batch 257 in epoch 18, gen_loss = 0.3984271471583566, disc_loss = 0.0505782016661278
Trained batch 258 in epoch 18, gen_loss = 0.39827254955372754, disc_loss = 0.05048498961513567
Trained batch 259 in epoch 18, gen_loss = 0.39842094274667594, disc_loss = 0.050721847767440174
Trained batch 260 in epoch 18, gen_loss = 0.39805099231073227, disc_loss = 0.05077038252890338
Trained batch 261 in epoch 18, gen_loss = 0.39819263991053777, disc_loss = 0.050631557143371524
Trained batch 262 in epoch 18, gen_loss = 0.3983155298595646, disc_loss = 0.05049485556724634
Trained batch 263 in epoch 18, gen_loss = 0.3982337330552665, disc_loss = 0.05034068321004848
Trained batch 264 in epoch 18, gen_loss = 0.3983799394571556, disc_loss = 0.050192799468366606
Trained batch 265 in epoch 18, gen_loss = 0.3981936832791881, disc_loss = 0.05028381641898164
Trained batch 266 in epoch 18, gen_loss = 0.3986876947379737, disc_loss = 0.05050640029323458
Trained batch 267 in epoch 18, gen_loss = 0.3987539220434516, disc_loss = 0.05037125066937462
Trained batch 268 in epoch 18, gen_loss = 0.39867081241093605, disc_loss = 0.050663494601928837
Trained batch 269 in epoch 18, gen_loss = 0.3985916518502765, disc_loss = 0.05122785783821234
Trained batch 270 in epoch 18, gen_loss = 0.398620427204674, disc_loss = 0.051080226533912206
Trained batch 271 in epoch 18, gen_loss = 0.39866769226158366, disc_loss = 0.050981377669171817
Trained batch 272 in epoch 18, gen_loss = 0.3984807445889428, disc_loss = 0.050840078583567136
Trained batch 273 in epoch 18, gen_loss = 0.39877376569448597, disc_loss = 0.050690727338983416
Trained batch 274 in epoch 18, gen_loss = 0.3989209840514443, disc_loss = 0.050639419139108875
Trained batch 275 in epoch 18, gen_loss = 0.39879812030256656, disc_loss = 0.05055489884082066
Trained batch 276 in epoch 18, gen_loss = 0.39867617754729645, disc_loss = 0.050452932752399884
Trained batch 277 in epoch 18, gen_loss = 0.39872303594359393, disc_loss = 0.05031948480018073
Trained batch 278 in epoch 18, gen_loss = 0.3986412206644653, disc_loss = 0.050227020293020216
Trained batch 279 in epoch 18, gen_loss = 0.3987673544457981, disc_loss = 0.05011069398439889
Trained batch 280 in epoch 18, gen_loss = 0.39880888858723895, disc_loss = 0.049965430501835204
Trained batch 281 in epoch 18, gen_loss = 0.3989949039322265, disc_loss = 0.04997176101021733
Trained batch 282 in epoch 18, gen_loss = 0.3991006596981426, disc_loss = 0.05009669244500015
Trained batch 283 in epoch 18, gen_loss = 0.39954056506845315, disc_loss = 0.05008830208803566
Trained batch 284 in epoch 18, gen_loss = 0.3997084076990161, disc_loss = 0.049944272160268664
Trained batch 285 in epoch 18, gen_loss = 0.3997108571596079, disc_loss = 0.04980260594194377
Trained batch 286 in epoch 18, gen_loss = 0.3999598810274011, disc_loss = 0.04978050000134868
Trained batch 287 in epoch 18, gen_loss = 0.3997983726569348, disc_loss = 0.04993068868578929
Trained batch 288 in epoch 18, gen_loss = 0.4001559675977304, disc_loss = 0.04999606931988137
Trained batch 289 in epoch 18, gen_loss = 0.4002552713813453, disc_loss = 0.0498901732137491
Trained batch 290 in epoch 18, gen_loss = 0.4002692139230643, disc_loss = 0.04974199752275323
Trained batch 291 in epoch 18, gen_loss = 0.4003643091410807, disc_loss = 0.049591587617202365
Trained batch 292 in epoch 18, gen_loss = 0.4001480406054865, disc_loss = 0.049450080597029406
Trained batch 293 in epoch 18, gen_loss = 0.40034563038624876, disc_loss = 0.04935572825714338
Trained batch 294 in epoch 18, gen_loss = 0.4003802026732493, disc_loss = 0.04925742410439051
Trained batch 295 in epoch 18, gen_loss = 0.4003465945857602, disc_loss = 0.04923914270664288
Trained batch 296 in epoch 18, gen_loss = 0.4000365574552555, disc_loss = 0.049708814115611594
Trained batch 297 in epoch 18, gen_loss = 0.4000201376292529, disc_loss = 0.05001963073412744
Trained batch 298 in epoch 18, gen_loss = 0.40039522063772015, disc_loss = 0.05005122667309333
Trained batch 299 in epoch 18, gen_loss = 0.4004234460989634, disc_loss = 0.04993657568780085
Trained batch 300 in epoch 18, gen_loss = 0.40058553694094534, disc_loss = 0.049842622895350686
Trained batch 301 in epoch 18, gen_loss = 0.40050508743090346, disc_loss = 0.049755236747619135
Trained batch 302 in epoch 18, gen_loss = 0.40037126952272045, disc_loss = 0.04965519885111465
Trained batch 303 in epoch 18, gen_loss = 0.4003723786261521, disc_loss = 0.0497097781044431
Trained batch 304 in epoch 18, gen_loss = 0.4003313886337593, disc_loss = 0.04963089773950518
Trained batch 305 in epoch 18, gen_loss = 0.4004516489560308, disc_loss = 0.04949311362092499
Trained batch 306 in epoch 18, gen_loss = 0.40028312093660184, disc_loss = 0.0495308509873111
Trained batch 307 in epoch 18, gen_loss = 0.4006442797261399, disc_loss = 0.049454056733445106
Trained batch 308 in epoch 18, gen_loss = 0.4005380160986027, disc_loss = 0.04946365675506179
Trained batch 309 in epoch 18, gen_loss = 0.4008144067179772, disc_loss = 0.0493703601851819
Trained batch 310 in epoch 18, gen_loss = 0.40068674729568016, disc_loss = 0.04944761263032914
Trained batch 311 in epoch 18, gen_loss = 0.4009757985671361, disc_loss = 0.0493153274172726
Trained batch 312 in epoch 18, gen_loss = 0.40087876409387435, disc_loss = 0.04917702834291485
Trained batch 313 in epoch 18, gen_loss = 0.40059096788524823, disc_loss = 0.04912799196673712
Trained batch 314 in epoch 18, gen_loss = 0.4002511001768566, disc_loss = 0.049109740741550924
Trained batch 315 in epoch 18, gen_loss = 0.40036661630567116, disc_loss = 0.04904482544611998
Trained batch 316 in epoch 18, gen_loss = 0.40019552489560484, disc_loss = 0.048925418491924784
Trained batch 317 in epoch 18, gen_loss = 0.3998937317222919, disc_loss = 0.04887678572884614
Trained batch 318 in epoch 18, gen_loss = 0.39991177277505213, disc_loss = 0.04960661977354355
Trained batch 319 in epoch 18, gen_loss = 0.39966510916128756, disc_loss = 0.0504453652567463
Trained batch 320 in epoch 18, gen_loss = 0.39971128997401656, disc_loss = 0.050467976113647874
Trained batch 321 in epoch 18, gen_loss = 0.3998381301112797, disc_loss = 0.05055249568294757
Trained batch 322 in epoch 18, gen_loss = 0.3998660112128538, disc_loss = 0.050501493780351826
Trained batch 323 in epoch 18, gen_loss = 0.3996741431362835, disc_loss = 0.05053657635092092
Trained batch 324 in epoch 18, gen_loss = 0.3996531976186312, disc_loss = 0.050481025006335514
Trained batch 325 in epoch 18, gen_loss = 0.39961108373352355, disc_loss = 0.05048053878776592
Trained batch 326 in epoch 18, gen_loss = 0.3996739505081002, disc_loss = 0.05039047655173853
Trained batch 327 in epoch 18, gen_loss = 0.39980114732937116, disc_loss = 0.050327849316001844
Trained batch 328 in epoch 18, gen_loss = 0.3995724539626333, disc_loss = 0.05028040242016225
Trained batch 329 in epoch 18, gen_loss = 0.3995425975683964, disc_loss = 0.05021338236772201
Trained batch 330 in epoch 18, gen_loss = 0.3996428386322321, disc_loss = 0.05012347453254137
Trained batch 331 in epoch 18, gen_loss = 0.39955850475164784, disc_loss = 0.05002641088486346
Trained batch 332 in epoch 18, gen_loss = 0.3996141174355069, disc_loss = 0.04993582745404304
Trained batch 333 in epoch 18, gen_loss = 0.39992126635091746, disc_loss = 0.04995589288687724
Trained batch 334 in epoch 18, gen_loss = 0.40010837894767076, disc_loss = 0.05005931236239067
Trained batch 335 in epoch 18, gen_loss = 0.4002058022611198, disc_loss = 0.05057529661904222
Trained batch 336 in epoch 18, gen_loss = 0.40009824520402565, disc_loss = 0.050571403427475105
Trained batch 337 in epoch 18, gen_loss = 0.40043378608113916, disc_loss = 0.05069335005879843
Trained batch 338 in epoch 18, gen_loss = 0.4002608019517938, disc_loss = 0.05082639610356374
Trained batch 339 in epoch 18, gen_loss = 0.400153668663081, disc_loss = 0.0508066222866011
Trained batch 340 in epoch 18, gen_loss = 0.4004388255807312, disc_loss = 0.05112459319657332
Trained batch 341 in epoch 18, gen_loss = 0.4002743256196641, disc_loss = 0.051256163810973455
Trained batch 342 in epoch 18, gen_loss = 0.40031200786373705, disc_loss = 0.051246009476526314
Trained batch 343 in epoch 18, gen_loss = 0.4003177106727001, disc_loss = 0.051271329355036276
Trained batch 344 in epoch 18, gen_loss = 0.400382147319075, disc_loss = 0.051180117752780946
Trained batch 345 in epoch 18, gen_loss = 0.40035417340049856, disc_loss = 0.05116416268707442
Trained batch 346 in epoch 18, gen_loss = 0.4003384726535346, disc_loss = 0.051082410586606015
Trained batch 347 in epoch 18, gen_loss = 0.4004823723058591, disc_loss = 0.05101310401544746
Trained batch 348 in epoch 18, gen_loss = 0.4004125766733656, disc_loss = 0.05090179209221144
Trained batch 349 in epoch 18, gen_loss = 0.40075622992856164, disc_loss = 0.0509065121758197
Trained batch 350 in epoch 18, gen_loss = 0.40043058091419037, disc_loss = 0.05156714788921963
Trained batch 351 in epoch 18, gen_loss = 0.40077221706848254, disc_loss = 0.05218797561511482
Trained batch 352 in epoch 18, gen_loss = 0.4006872754596786, disc_loss = 0.05213231569361838
Trained batch 353 in epoch 18, gen_loss = 0.40058991792848553, disc_loss = 0.052071710456541534
Trained batch 354 in epoch 18, gen_loss = 0.4005019715134527, disc_loss = 0.05198574893858651
Trained batch 355 in epoch 18, gen_loss = 0.4006676156534238, disc_loss = 0.0518777991744449
Trained batch 356 in epoch 18, gen_loss = 0.40072617277043876, disc_loss = 0.05183317338270383
Trained batch 357 in epoch 18, gen_loss = 0.40070639259322394, disc_loss = 0.05180752358799957
Trained batch 358 in epoch 18, gen_loss = 0.4008430901676167, disc_loss = 0.05212726431813164
Trained batch 359 in epoch 18, gen_loss = 0.40056198578741814, disc_loss = 0.05236598371476349
Trained batch 360 in epoch 18, gen_loss = 0.4007151432314738, disc_loss = 0.052332456889265626
Trained batch 361 in epoch 18, gen_loss = 0.4009186307698982, disc_loss = 0.052278456944478316
Trained batch 362 in epoch 18, gen_loss = 0.40121274168497933, disc_loss = 0.05221235754414777
Trained batch 363 in epoch 18, gen_loss = 0.40122121621619217, disc_loss = 0.05225903532918092
Trained batch 364 in epoch 18, gen_loss = 0.40122227244181174, disc_loss = 0.052414233801401644
Trained batch 365 in epoch 18, gen_loss = 0.401271548997509, disc_loss = 0.05231504622958804
Trained batch 366 in epoch 18, gen_loss = 0.4014920822118868, disc_loss = 0.05224947328108289
Trained batch 367 in epoch 18, gen_loss = 0.40159483359235787, disc_loss = 0.052159424195491265
Trained batch 368 in epoch 18, gen_loss = 0.4013692210844862, disc_loss = 0.052261468691897746
Trained batch 369 in epoch 18, gen_loss = 0.40133173344908535, disc_loss = 0.05235841267465337
Trained batch 370 in epoch 18, gen_loss = 0.4013519829334917, disc_loss = 0.052304099253667496
Trained batch 371 in epoch 18, gen_loss = 0.401255193176449, disc_loss = 0.052261100173176776
Trained batch 372 in epoch 18, gen_loss = 0.4014513923239772, disc_loss = 0.052166973400471515
Trained batch 373 in epoch 18, gen_loss = 0.4017192937314192, disc_loss = 0.05204383318466856
Trained batch 374 in epoch 18, gen_loss = 0.40165083344777425, disc_loss = 0.052133873768150804
Trained batch 375 in epoch 18, gen_loss = 0.401375856329786, disc_loss = 0.05238612474467447
Trained batch 376 in epoch 18, gen_loss = 0.4014265922241565, disc_loss = 0.05238061982011843
Trained batch 377 in epoch 18, gen_loss = 0.40156445490620124, disc_loss = 0.05228545607151414
Trained batch 378 in epoch 18, gen_loss = 0.40150708534157686, disc_loss = 0.052249391681187855
Trained batch 379 in epoch 18, gen_loss = 0.4014517630401411, disc_loss = 0.05224411263816843
Trained batch 380 in epoch 18, gen_loss = 0.40133455035880483, disc_loss = 0.052190136396646346
Trained batch 381 in epoch 18, gen_loss = 0.40115949768982634, disc_loss = 0.05237258195204182
Trained batch 382 in epoch 18, gen_loss = 0.40143492771191014, disc_loss = 0.052725246509259895
Trained batch 383 in epoch 18, gen_loss = 0.4013472980974863, disc_loss = 0.05263233522661418
Trained batch 384 in epoch 18, gen_loss = 0.4012835849415172, disc_loss = 0.05270792286746301
Trained batch 385 in epoch 18, gen_loss = 0.40131513728070134, disc_loss = 0.05265367875802162
Trained batch 386 in epoch 18, gen_loss = 0.4012353893860366, disc_loss = 0.05272298786808431
Trained batch 387 in epoch 18, gen_loss = 0.40113569473482896, disc_loss = 0.053192054845642336
Trained batch 388 in epoch 18, gen_loss = 0.40130999829897845, disc_loss = 0.053144777152965034
Trained batch 389 in epoch 18, gen_loss = 0.40154974712775304, disc_loss = 0.0531481078825891
Trained batch 390 in epoch 18, gen_loss = 0.4014810813052575, disc_loss = 0.053089337049485624
Trained batch 391 in epoch 18, gen_loss = 0.4012591922465636, disc_loss = 0.05335413923306505
Trained batch 392 in epoch 18, gen_loss = 0.4013073457258045, disc_loss = 0.053343509665142945
Trained batch 393 in epoch 18, gen_loss = 0.4012185079494709, disc_loss = 0.05353911243010369
Trained batch 394 in epoch 18, gen_loss = 0.40111746463594555, disc_loss = 0.053515758443199384
Trained batch 395 in epoch 18, gen_loss = 0.40099248493259604, disc_loss = 0.05353896099029842
Trained batch 396 in epoch 18, gen_loss = 0.4011008136668794, disc_loss = 0.053579843645300766
Trained batch 397 in epoch 18, gen_loss = 0.4009754868158743, disc_loss = 0.05348908316446983
Trained batch 398 in epoch 18, gen_loss = 0.4009526070944946, disc_loss = 0.05366809629977571
Trained batch 399 in epoch 18, gen_loss = 0.4009629826247692, disc_loss = 0.05359215691452846
Trained batch 400 in epoch 18, gen_loss = 0.4011339627745146, disc_loss = 0.053509005782034186
Trained batch 401 in epoch 18, gen_loss = 0.4010528506924264, disc_loss = 0.053397312517097194
Trained batch 402 in epoch 18, gen_loss = 0.4009619234661311, disc_loss = 0.053287712133792284
Trained batch 403 in epoch 18, gen_loss = 0.4007699713848605, disc_loss = 0.05318498732014974
Trained batch 404 in epoch 18, gen_loss = 0.4008306735827599, disc_loss = 0.053093996099023905
Trained batch 405 in epoch 18, gen_loss = 0.4007646290245902, disc_loss = 0.05298739187235903
Trained batch 406 in epoch 18, gen_loss = 0.4007597198064556, disc_loss = 0.05293613601778004
Trained batch 407 in epoch 18, gen_loss = 0.40087221752779156, disc_loss = 0.052976491340600396
Trained batch 408 in epoch 18, gen_loss = 0.401246632515364, disc_loss = 0.05320125713507237
Trained batch 409 in epoch 18, gen_loss = 0.401092748525666, disc_loss = 0.053121741856561926
Trained batch 410 in epoch 18, gen_loss = 0.4008605114734956, disc_loss = 0.05317439927001214
Trained batch 411 in epoch 18, gen_loss = 0.40100473440387874, disc_loss = 0.05310062059083755
Trained batch 412 in epoch 18, gen_loss = 0.4010134208000312, disc_loss = 0.05309305317050464
Trained batch 413 in epoch 18, gen_loss = 0.400989869510494, disc_loss = 0.05300190189745331
Trained batch 414 in epoch 18, gen_loss = 0.4010611025683851, disc_loss = 0.05300125903169434
Trained batch 415 in epoch 18, gen_loss = 0.4011577038237682, disc_loss = 0.05293105506615785
Trained batch 416 in epoch 18, gen_loss = 0.4012450976766271, disc_loss = 0.052914306277976476
Trained batch 417 in epoch 18, gen_loss = 0.40117824426963566, disc_loss = 0.052867501918404725
Trained batch 418 in epoch 18, gen_loss = 0.40126860390699565, disc_loss = 0.052822077844674235
Trained batch 419 in epoch 18, gen_loss = 0.4010360489288966, disc_loss = 0.053090201724054556
Trained batch 420 in epoch 18, gen_loss = 0.4007042713657977, disc_loss = 0.05339695366139296
Trained batch 421 in epoch 18, gen_loss = 0.4006990445733635, disc_loss = 0.05384691078789638
Trained batch 422 in epoch 18, gen_loss = 0.4005447697273101, disc_loss = 0.05378069815580374
Trained batch 423 in epoch 18, gen_loss = 0.40031645995266035, disc_loss = 0.0538396173451131
Trained batch 424 in epoch 18, gen_loss = 0.4005375862121582, disc_loss = 0.05378846070126576
Trained batch 425 in epoch 18, gen_loss = 0.40046384266004875, disc_loss = 0.05384987977250291
Trained batch 426 in epoch 18, gen_loss = 0.40022189988464607, disc_loss = 0.0546370998038027
Trained batch 427 in epoch 18, gen_loss = 0.40017641997225933, disc_loss = 0.054675841144782224
Trained batch 428 in epoch 18, gen_loss = 0.4001375737584832, disc_loss = 0.054916771191730225
Trained batch 429 in epoch 18, gen_loss = 0.4000637382961983, disc_loss = 0.05521959826826703
Trained batch 430 in epoch 18, gen_loss = 0.40009510558608513, disc_loss = 0.055236099964210854
Trained batch 431 in epoch 18, gen_loss = 0.3999912422840242, disc_loss = 0.055141154997895854
Trained batch 432 in epoch 18, gen_loss = 0.4001917829414438, disc_loss = 0.05507546608007188
Trained batch 433 in epoch 18, gen_loss = 0.4000319964188035, disc_loss = 0.05507264868034402
Trained batch 434 in epoch 18, gen_loss = 0.4000287741765209, disc_loss = 0.055109073613481274
Trained batch 435 in epoch 18, gen_loss = 0.399912079129744, disc_loss = 0.055404706420206014
Trained batch 436 in epoch 18, gen_loss = 0.39991889235902434, disc_loss = 0.05546716404375482
Trained batch 437 in epoch 18, gen_loss = 0.4001782028234168, disc_loss = 0.05541507083897109
Trained batch 438 in epoch 18, gen_loss = 0.400241214349221, disc_loss = 0.05537129660054261
Trained batch 439 in epoch 18, gen_loss = 0.4002034666186029, disc_loss = 0.05532259498934516
Trained batch 440 in epoch 18, gen_loss = 0.39996970348617655, disc_loss = 0.055302835280781025
Trained batch 441 in epoch 18, gen_loss = 0.40005244348383595, disc_loss = 0.055225616141867176
Trained batch 442 in epoch 18, gen_loss = 0.4000115911255572, disc_loss = 0.05513089952431199
Trained batch 443 in epoch 18, gen_loss = 0.3999775142014564, disc_loss = 0.05508718554031204
Trained batch 444 in epoch 18, gen_loss = 0.40000478491354524, disc_loss = 0.0549955798919951
Trained batch 445 in epoch 18, gen_loss = 0.4000084289921773, disc_loss = 0.054911523247179427
Trained batch 446 in epoch 18, gen_loss = 0.39983492269612, disc_loss = 0.054877490430270265
Trained batch 447 in epoch 18, gen_loss = 0.4000316067332668, disc_loss = 0.05478300738364591
Trained batch 448 in epoch 18, gen_loss = 0.3999728987238189, disc_loss = 0.05470874522271294
Trained batch 449 in epoch 18, gen_loss = 0.399921561744478, disc_loss = 0.05463825235350264
Trained batch 450 in epoch 18, gen_loss = 0.3998785788098354, disc_loss = 0.054606089384982695
Trained batch 451 in epoch 18, gen_loss = 0.3998544556377208, disc_loss = 0.05471609562091463
Trained batch 452 in epoch 18, gen_loss = 0.39988536208407505, disc_loss = 0.05479266732585746
Trained batch 453 in epoch 18, gen_loss = 0.4000758530022289, disc_loss = 0.05469720318527802
Trained batch 454 in epoch 18, gen_loss = 0.4001862837718083, disc_loss = 0.054605788289272525
Trained batch 455 in epoch 18, gen_loss = 0.4003225092433001, disc_loss = 0.05450021389365327
Trained batch 456 in epoch 18, gen_loss = 0.40031713345118636, disc_loss = 0.05448182220254868
Trained batch 457 in epoch 18, gen_loss = 0.40015669726648706, disc_loss = 0.054418746410466436
Trained batch 458 in epoch 18, gen_loss = 0.39987480426146316, disc_loss = 0.05501735442133381
Testing Epoch 18
Training Epoch 19
Trained batch 0 in epoch 19, gen_loss = 0.31043118238449097, disc_loss = 0.11427551507949829
Trained batch 1 in epoch 19, gen_loss = 0.3950576186180115, disc_loss = 0.10696576535701752
Trained batch 2 in epoch 19, gen_loss = 0.37921396891276044, disc_loss = 0.08784198015928268
Trained batch 3 in epoch 19, gen_loss = 0.374825581908226, disc_loss = 0.07977719977498055
Trained batch 4 in epoch 19, gen_loss = 0.38180912733078004, disc_loss = 0.07106015384197235
Trained batch 5 in epoch 19, gen_loss = 0.38234464824199677, disc_loss = 0.07103470961252849
Trained batch 6 in epoch 19, gen_loss = 0.391440497977393, disc_loss = 0.06453744455107621
Trained batch 7 in epoch 19, gen_loss = 0.36993447318673134, disc_loss = 0.09379905858077109
Trained batch 8 in epoch 19, gen_loss = 0.38425641258557636, disc_loss = 0.10609101441999276
Trained batch 9 in epoch 19, gen_loss = 0.38323585093021395, disc_loss = 0.09840540904551745
Trained batch 10 in epoch 19, gen_loss = 0.38423802906816656, disc_loss = 0.09135696749118241
Trained batch 11 in epoch 19, gen_loss = 0.38281751175721485, disc_loss = 0.08925989937658112
Trained batch 12 in epoch 19, gen_loss = 0.3859096811367915, disc_loss = 0.08489699131594254
Trained batch 13 in epoch 19, gen_loss = 0.38825733746801105, disc_loss = 0.08024185589913811
Trained batch 14 in epoch 19, gen_loss = 0.38847328623135885, disc_loss = 0.07699830941855908
Trained batch 15 in epoch 19, gen_loss = 0.3887416832149029, disc_loss = 0.0765668909298256
Trained batch 16 in epoch 19, gen_loss = 0.38634463092860055, disc_loss = 0.07439307134379358
Trained batch 17 in epoch 19, gen_loss = 0.38615304231643677, disc_loss = 0.07788499910384417
Trained batch 18 in epoch 19, gen_loss = 0.39333586002651016, disc_loss = 0.07821369965217616
Trained batch 19 in epoch 19, gen_loss = 0.3938384175300598, disc_loss = 0.0769981506280601
Trained batch 20 in epoch 19, gen_loss = 0.3956805637904576, disc_loss = 0.07766155641348589
Trained batch 21 in epoch 19, gen_loss = 0.3941321616823023, disc_loss = 0.07946832435713573
Trained batch 22 in epoch 19, gen_loss = 0.39296595557876257, disc_loss = 0.07877284733821517
Trained batch 23 in epoch 19, gen_loss = 0.39531077196200687, disc_loss = 0.07642829022370279
Trained batch 24 in epoch 19, gen_loss = 0.39603612422943113, disc_loss = 0.07443704165518283
Trained batch 25 in epoch 19, gen_loss = 0.3928479930529228, disc_loss = 0.0733447912364052
Trained batch 26 in epoch 19, gen_loss = 0.39550697803497314, disc_loss = 0.07233418738124547
Trained batch 27 in epoch 19, gen_loss = 0.3955638749258859, disc_loss = 0.07067067728244833
Trained batch 28 in epoch 19, gen_loss = 0.39455273644677524, disc_loss = 0.07068941889908807
Trained batch 29 in epoch 19, gen_loss = 0.3934592554966609, disc_loss = 0.0790364093457659
Trained batch 30 in epoch 19, gen_loss = 0.3963146036671054, disc_loss = 0.07791565256493707
Trained batch 31 in epoch 19, gen_loss = 0.39481708966195583, disc_loss = 0.07861169328680262
Trained batch 32 in epoch 19, gen_loss = 0.39682060660737933, disc_loss = 0.07703142065667745
Trained batch 33 in epoch 19, gen_loss = 0.3962692074915942, disc_loss = 0.07581583361196167
Trained batch 34 in epoch 19, gen_loss = 0.40048229013170517, disc_loss = 0.07530369668134622
Trained batch 35 in epoch 19, gen_loss = 0.39980708724922603, disc_loss = 0.07482056428367893
Trained batch 36 in epoch 19, gen_loss = 0.39890927237433355, disc_loss = 0.07361530064529664
Trained batch 37 in epoch 19, gen_loss = 0.400631593246209, disc_loss = 0.07190943558357264
Trained batch 38 in epoch 19, gen_loss = 0.3997311729651231, disc_loss = 0.07165463679494002
Trained batch 39 in epoch 19, gen_loss = 0.4004731297492981, disc_loss = 0.0737089823000133
Trained batch 40 in epoch 19, gen_loss = 0.4014422929868465, disc_loss = 0.07260818629548317
Trained batch 41 in epoch 19, gen_loss = 0.4022516977219355, disc_loss = 0.07366471112306629
Trained batch 42 in epoch 19, gen_loss = 0.4026905499225439, disc_loss = 0.07588693512560324
Trained batch 43 in epoch 19, gen_loss = 0.40371792086146097, disc_loss = 0.07461300496519967
Trained batch 44 in epoch 19, gen_loss = 0.40404502550760907, disc_loss = 0.07352465134527948
Trained batch 45 in epoch 19, gen_loss = 0.4033029170139976, disc_loss = 0.07269447847552922
Trained batch 46 in epoch 19, gen_loss = 0.4055572596002132, disc_loss = 0.07159413001004686
Trained batch 47 in epoch 19, gen_loss = 0.40668624515334767, disc_loss = 0.07041496304251875
Trained batch 48 in epoch 19, gen_loss = 0.405627714736121, disc_loss = 0.06978557534439832
Trained batch 49 in epoch 19, gen_loss = 0.40525515913963317, disc_loss = 0.06922442587092519
Trained batch 50 in epoch 19, gen_loss = 0.404606560866038, disc_loss = 0.06877183032167308
Trained batch 51 in epoch 19, gen_loss = 0.4047576945561629, disc_loss = 0.067720606439532
Trained batch 52 in epoch 19, gen_loss = 0.4056015762518037, disc_loss = 0.06703803584612203
Trained batch 53 in epoch 19, gen_loss = 0.40564536054929096, disc_loss = 0.06733839995124274
Trained batch 54 in epoch 19, gen_loss = 0.4054956295273521, disc_loss = 0.06998971871693026
Trained batch 55 in epoch 19, gen_loss = 0.40793516486883163, disc_loss = 0.07047314737324736
Trained batch 56 in epoch 19, gen_loss = 0.40746367082261203, disc_loss = 0.06982718939125016
Trained batch 57 in epoch 19, gen_loss = 0.40690830144388923, disc_loss = 0.06924084678356504
Trained batch 58 in epoch 19, gen_loss = 0.4081192713672832, disc_loss = 0.06834930527197608
Trained batch 59 in epoch 19, gen_loss = 0.4087348570426305, disc_loss = 0.06744302799925209
Trained batch 60 in epoch 19, gen_loss = 0.4085204586630962, disc_loss = 0.06655048285839987
Trained batch 61 in epoch 19, gen_loss = 0.4073349790227029, disc_loss = 0.06589418307187096
Trained batch 62 in epoch 19, gen_loss = 0.4084431633116707, disc_loss = 0.06571498247129577
Trained batch 63 in epoch 19, gen_loss = 0.40803454304113984, disc_loss = 0.06498554040445015
Trained batch 64 in epoch 19, gen_loss = 0.4075531574395987, disc_loss = 0.06439670352981641
Trained batch 65 in epoch 19, gen_loss = 0.4077391791524309, disc_loss = 0.06379050800971912
Trained batch 66 in epoch 19, gen_loss = 0.4098001518356266, disc_loss = 0.06330142175750945
Trained batch 67 in epoch 19, gen_loss = 0.41012062263839383, disc_loss = 0.062477709978873676
Trained batch 68 in epoch 19, gen_loss = 0.4103787994903067, disc_loss = 0.062192169848181635
Trained batch 69 in epoch 19, gen_loss = 0.41086420033659254, disc_loss = 0.061699442039909104
Trained batch 70 in epoch 19, gen_loss = 0.4093440380734457, disc_loss = 0.06183827196864385
Trained batch 71 in epoch 19, gen_loss = 0.40995341415206593, disc_loss = 0.0666166674410407
Trained batch 72 in epoch 19, gen_loss = 0.40982227129478976, disc_loss = 0.06645776520878689
Trained batch 73 in epoch 19, gen_loss = 0.4096592688882673, disc_loss = 0.06645166990347207
Trained batch 74 in epoch 19, gen_loss = 0.4111219827334086, disc_loss = 0.06593095275883873
Trained batch 75 in epoch 19, gen_loss = 0.41219441984829147, disc_loss = 0.06549595686680589
Trained batch 76 in epoch 19, gen_loss = 0.4126282872317673, disc_loss = 0.06484463033810645
Trained batch 77 in epoch 19, gen_loss = 0.41267158778814167, disc_loss = 0.06437207578729169
Trained batch 78 in epoch 19, gen_loss = 0.412529031687145, disc_loss = 0.06390936643804741
Trained batch 79 in epoch 19, gen_loss = 0.41263191364705565, disc_loss = 0.06354352514608763
Trained batch 80 in epoch 19, gen_loss = 0.41248528604154233, disc_loss = 0.06294983713370231
Trained batch 81 in epoch 19, gen_loss = 0.41205489599123235, disc_loss = 0.06261577407784033
Trained batch 82 in epoch 19, gen_loss = 0.41217456381004974, disc_loss = 0.062443208583372545
Trained batch 83 in epoch 19, gen_loss = 0.4111836552619934, disc_loss = 0.061936773343144784
Trained batch 84 in epoch 19, gen_loss = 0.4112835035604589, disc_loss = 0.06127276838592747
Trained batch 85 in epoch 19, gen_loss = 0.4116761285898297, disc_loss = 0.06067592055580124
Trained batch 86 in epoch 19, gen_loss = 0.41223441389785415, disc_loss = 0.060056683784029605
Trained batch 87 in epoch 19, gen_loss = 0.411842349239371, disc_loss = 0.05969385776816952
Trained batch 88 in epoch 19, gen_loss = 0.4111999651689208, disc_loss = 0.06047698963705576
Trained batch 89 in epoch 19, gen_loss = 0.41182649003134836, disc_loss = 0.063596171218281
Trained batch 90 in epoch 19, gen_loss = 0.4124197498127654, disc_loss = 0.06329431805943886
Trained batch 91 in epoch 19, gen_loss = 0.41208993870279065, disc_loss = 0.06293814693597834
Trained batch 92 in epoch 19, gen_loss = 0.41188146189976765, disc_loss = 0.06287636903805598
Trained batch 93 in epoch 19, gen_loss = 0.4124190309580336, disc_loss = 0.062349521332083546
Trained batch 94 in epoch 19, gen_loss = 0.41143985045583625, disc_loss = 0.06226454909988924
Trained batch 95 in epoch 19, gen_loss = 0.41142523164550465, disc_loss = 0.06176855066344918
Trained batch 96 in epoch 19, gen_loss = 0.410799976476689, disc_loss = 0.06126880502213061
Trained batch 97 in epoch 19, gen_loss = 0.4105114176565287, disc_loss = 0.0607767817706858
Trained batch 98 in epoch 19, gen_loss = 0.4105280881578272, disc_loss = 0.060307085349440875
Trained batch 99 in epoch 19, gen_loss = 0.41049463242292406, disc_loss = 0.05992230160627514
Trained batch 100 in epoch 19, gen_loss = 0.4100334163349454, disc_loss = 0.05947089426237905
Trained batch 101 in epoch 19, gen_loss = 0.41085584549342885, disc_loss = 0.05919083589961862
Trained batch 102 in epoch 19, gen_loss = 0.41028770254653635, disc_loss = 0.058854361892072035
Trained batch 103 in epoch 19, gen_loss = 0.40962387793339217, disc_loss = 0.05876033766141448
Trained batch 104 in epoch 19, gen_loss = 0.40972834598450436, disc_loss = 0.05833534961566329
Trained batch 105 in epoch 19, gen_loss = 0.4101248029268013, disc_loss = 0.05805611481696789
Trained batch 106 in epoch 19, gen_loss = 0.4093284439817767, disc_loss = 0.05823128842357024
Trained batch 107 in epoch 19, gen_loss = 0.4097182251237057, disc_loss = 0.05795907035590736
Trained batch 108 in epoch 19, gen_loss = 0.40976749674989543, disc_loss = 0.05749635972988305
Trained batch 109 in epoch 19, gen_loss = 0.4093708645213734, disc_loss = 0.05712554475546561
Trained batch 110 in epoch 19, gen_loss = 0.4095893166623674, disc_loss = 0.05672869437399346
Trained batch 111 in epoch 19, gen_loss = 0.40944941554750713, disc_loss = 0.05631450830177138
Trained batch 112 in epoch 19, gen_loss = 0.4099598711570807, disc_loss = 0.056004888423413564
Trained batch 113 in epoch 19, gen_loss = 0.4104118937985939, disc_loss = 0.05823054619280523
Trained batch 114 in epoch 19, gen_loss = 0.41037820784941964, disc_loss = 0.05923596708427953
Trained batch 115 in epoch 19, gen_loss = 0.40960896040858896, disc_loss = 0.05923374835803206
Trained batch 116 in epoch 19, gen_loss = 0.4102525693229121, disc_loss = 0.05944482234314594
Trained batch 117 in epoch 19, gen_loss = 0.4104686008166459, disc_loss = 0.05938797750731267
Trained batch 118 in epoch 19, gen_loss = 0.41034447395501017, disc_loss = 0.059888289102642725
Trained batch 119 in epoch 19, gen_loss = 0.410258361697197, disc_loss = 0.060422549990471454
Trained batch 120 in epoch 19, gen_loss = 0.4102894020967247, disc_loss = 0.061579221139915964
Trained batch 121 in epoch 19, gen_loss = 0.41027043784250977, disc_loss = 0.06269033604729005
Trained batch 122 in epoch 19, gen_loss = 0.4096096458473826, disc_loss = 0.06261558915920011
Trained batch 123 in epoch 19, gen_loss = 0.41006041342212307, disc_loss = 0.062367432964815485
Trained batch 124 in epoch 19, gen_loss = 0.4101026744842529, disc_loss = 0.06215719497576356
Trained batch 125 in epoch 19, gen_loss = 0.40994994886337766, disc_loss = 0.06191264761478773
Trained batch 126 in epoch 19, gen_loss = 0.40992232195035677, disc_loss = 0.06165473739887903
Trained batch 127 in epoch 19, gen_loss = 0.40947719430550933, disc_loss = 0.061360020732536213
Trained batch 128 in epoch 19, gen_loss = 0.41018198395884314, disc_loss = 0.061342963894699204
Trained batch 129 in epoch 19, gen_loss = 0.4095359621139673, disc_loss = 0.06150742667870453
Trained batch 130 in epoch 19, gen_loss = 0.41016545709762864, disc_loss = 0.06113492129086197
Trained batch 131 in epoch 19, gen_loss = 0.41024656796997244, disc_loss = 0.06191186714479982
Trained batch 132 in epoch 19, gen_loss = 0.40966012894659115, disc_loss = 0.06267809985849754
Trained batch 133 in epoch 19, gen_loss = 0.4097069214973877, disc_loss = 0.0623823983295918
Trained batch 134 in epoch 19, gen_loss = 0.40940914109901144, disc_loss = 0.06269706362444494
Trained batch 135 in epoch 19, gen_loss = 0.4086466348346542, disc_loss = 0.0629396215252414
Trained batch 136 in epoch 19, gen_loss = 0.40846042541691857, disc_loss = 0.06257939415161301
Trained batch 137 in epoch 19, gen_loss = 0.40835232190463855, disc_loss = 0.06221364527954248
Trained batch 138 in epoch 19, gen_loss = 0.4082514399247204, disc_loss = 0.062204385434257256
Trained batch 139 in epoch 19, gen_loss = 0.4082601502537727, disc_loss = 0.061998355711278104
Trained batch 140 in epoch 19, gen_loss = 0.4082819512972595, disc_loss = 0.06170800969282046
Trained batch 141 in epoch 19, gen_loss = 0.4086144224438869, disc_loss = 0.06140391368904269
Trained batch 142 in epoch 19, gen_loss = 0.40870568427172577, disc_loss = 0.061029621038481696
Trained batch 143 in epoch 19, gen_loss = 0.40856932455466854, disc_loss = 0.06065630317445741
Trained batch 144 in epoch 19, gen_loss = 0.40853149520939797, disc_loss = 0.060319269663686385
Trained batch 145 in epoch 19, gen_loss = 0.4087212110218936, disc_loss = 0.059998558639638024
Trained batch 146 in epoch 19, gen_loss = 0.4086717983492378, disc_loss = 0.059860869009858694
Trained batch 147 in epoch 19, gen_loss = 0.40798036230577006, disc_loss = 0.05982284716997497
Trained batch 148 in epoch 19, gen_loss = 0.4083582274865784, disc_loss = 0.05947677817683192
Trained batch 149 in epoch 19, gen_loss = 0.40843392809232076, disc_loss = 0.059518453096970916
Trained batch 150 in epoch 19, gen_loss = 0.40826848366402635, disc_loss = 0.05940881654287115
Trained batch 151 in epoch 19, gen_loss = 0.40793835234485176, disc_loss = 0.05999275999401059
Trained batch 152 in epoch 19, gen_loss = 0.4090686006094116, disc_loss = 0.06193831072681967
Trained batch 153 in epoch 19, gen_loss = 0.4094967927251543, disc_loss = 0.06164908918624671
Trained batch 154 in epoch 19, gen_loss = 0.40981965891776545, disc_loss = 0.06145284521063009
Trained batch 155 in epoch 19, gen_loss = 0.4099563247500322, disc_loss = 0.06122759463659559
Trained batch 156 in epoch 19, gen_loss = 0.4100668392363627, disc_loss = 0.060935081015370644
Trained batch 157 in epoch 19, gen_loss = 0.4098996448365948, disc_loss = 0.06072595867894213
Trained batch 158 in epoch 19, gen_loss = 0.40995401593874087, disc_loss = 0.06067221615545498
Trained batch 159 in epoch 19, gen_loss = 0.4091287929564714, disc_loss = 0.060903267926187256
Trained batch 160 in epoch 19, gen_loss = 0.40900718906651373, disc_loss = 0.06091011041682792
Trained batch 161 in epoch 19, gen_loss = 0.4089925246842114, disc_loss = 0.060799664038773855
Trained batch 162 in epoch 19, gen_loss = 0.4089152114522969, disc_loss = 0.06078276551540004
Trained batch 163 in epoch 19, gen_loss = 0.408902471385351, disc_loss = 0.06070989928287795
Trained batch 164 in epoch 19, gen_loss = 0.4089260561899705, disc_loss = 0.06056576106189327
Trained batch 165 in epoch 19, gen_loss = 0.4086760880358248, disc_loss = 0.06032193337948656
Trained batch 166 in epoch 19, gen_loss = 0.4086485894140369, disc_loss = 0.06014900143999986
Trained batch 167 in epoch 19, gen_loss = 0.40796577007997603, disc_loss = 0.0599931918023642
Trained batch 168 in epoch 19, gen_loss = 0.4078635619236873, disc_loss = 0.06003638017735273
Trained batch 169 in epoch 19, gen_loss = 0.4074709795853671, disc_loss = 0.06000137999927735
Trained batch 170 in epoch 19, gen_loss = 0.40787279797576326, disc_loss = 0.05983730118275125
Trained batch 171 in epoch 19, gen_loss = 0.4082176565777424, disc_loss = 0.059675125906048995
Trained batch 172 in epoch 19, gen_loss = 0.4077288298248556, disc_loss = 0.0598751258110423
Trained batch 173 in epoch 19, gen_loss = 0.40807623767304696, disc_loss = 0.059571102933273064
Trained batch 174 in epoch 19, gen_loss = 0.40819074085780555, disc_loss = 0.05950126229386245
Trained batch 175 in epoch 19, gen_loss = 0.4083325271918015, disc_loss = 0.05926968380332586
Trained batch 176 in epoch 19, gen_loss = 0.4077614988647612, disc_loss = 0.05911915211301655
Trained batch 177 in epoch 19, gen_loss = 0.4075894879825999, disc_loss = 0.05927936097324481
Trained batch 178 in epoch 19, gen_loss = 0.4069775053242731, disc_loss = 0.059753847862567815
Trained batch 179 in epoch 19, gen_loss = 0.4071616356571515, disc_loss = 0.06010975888154159
Trained batch 180 in epoch 19, gen_loss = 0.4073158889514965, disc_loss = 0.059814413662135434
Trained batch 181 in epoch 19, gen_loss = 0.4069292840066847, disc_loss = 0.05967333627567923
Trained batch 182 in epoch 19, gen_loss = 0.40639174733657, disc_loss = 0.059482095714739926
Trained batch 183 in epoch 19, gen_loss = 0.4061031940838565, disc_loss = 0.05924094389648298
Trained batch 184 in epoch 19, gen_loss = 0.4057283971760724, disc_loss = 0.05935986326201945
Trained batch 185 in epoch 19, gen_loss = 0.40617241782526814, disc_loss = 0.059956878045653944
Trained batch 186 in epoch 19, gen_loss = 0.40577680892485346, disc_loss = 0.059749522532789624
Trained batch 187 in epoch 19, gen_loss = 0.40586086378452624, disc_loss = 0.05969171357053788
Trained batch 188 in epoch 19, gen_loss = 0.4055397162046382, disc_loss = 0.059522602492795576
Trained batch 189 in epoch 19, gen_loss = 0.40571520312836296, disc_loss = 0.0592464085496766
Trained batch 190 in epoch 19, gen_loss = 0.4058809912329569, disc_loss = 0.05918080233164249
Trained batch 191 in epoch 19, gen_loss = 0.40576258751874167, disc_loss = 0.0590103000504314
Trained batch 192 in epoch 19, gen_loss = 0.4060083921091544, disc_loss = 0.0587585430587473
Trained batch 193 in epoch 19, gen_loss = 0.40603751620066536, disc_loss = 0.05850433212820172
Trained batch 194 in epoch 19, gen_loss = 0.4059834396227812, disc_loss = 0.05833532927939907
Trained batch 195 in epoch 19, gen_loss = 0.40557763755929715, disc_loss = 0.05817854130041918
Trained batch 196 in epoch 19, gen_loss = 0.4058684059205999, disc_loss = 0.05812222063588687
Trained batch 197 in epoch 19, gen_loss = 0.4060805995355953, disc_loss = 0.058332626898349685
Trained batch 198 in epoch 19, gen_loss = 0.4059915713329411, disc_loss = 0.05876299756902022
Trained batch 199 in epoch 19, gen_loss = 0.40547428891062737, disc_loss = 0.05920831690775231
Trained batch 200 in epoch 19, gen_loss = 0.4058066590211878, disc_loss = 0.05933083400399012
Trained batch 201 in epoch 19, gen_loss = 0.4058534836415017, disc_loss = 0.059079302218973194
Trained batch 202 in epoch 19, gen_loss = 0.40568826072321734, disc_loss = 0.058889131995349245
Trained batch 203 in epoch 19, gen_loss = 0.4058788630600069, disc_loss = 0.05873878211851286
Trained batch 204 in epoch 19, gen_loss = 0.4056513547897339, disc_loss = 0.058561985696688655
Trained batch 205 in epoch 19, gen_loss = 0.40548594484051453, disc_loss = 0.05833921843949814
Trained batch 206 in epoch 19, gen_loss = 0.40557914626771124, disc_loss = 0.05811093797331343
Trained batch 207 in epoch 19, gen_loss = 0.4057248698977324, disc_loss = 0.05785323124011764
Trained batch 208 in epoch 19, gen_loss = 0.4057720541668851, disc_loss = 0.057714509869074566
Trained batch 209 in epoch 19, gen_loss = 0.4060791307971591, disc_loss = 0.05753617380479617
Trained batch 210 in epoch 19, gen_loss = 0.40629286506164697, disc_loss = 0.05738845688922075
Trained batch 211 in epoch 19, gen_loss = 0.4065720013008927, disc_loss = 0.05834374895521422
Trained batch 212 in epoch 19, gen_loss = 0.4064306934394747, disc_loss = 0.05839456217975614
Trained batch 213 in epoch 19, gen_loss = 0.4058440086719032, disc_loss = 0.05835843396756067
Trained batch 214 in epoch 19, gen_loss = 0.4058774651483048, disc_loss = 0.05822167502889453
Trained batch 215 in epoch 19, gen_loss = 0.40558197859812667, disc_loss = 0.05823075349434038
Trained batch 216 in epoch 19, gen_loss = 0.4053623569176494, disc_loss = 0.0584981479845117
Trained batch 217 in epoch 19, gen_loss = 0.4050953370442084, disc_loss = 0.05828197070380348
Trained batch 218 in epoch 19, gen_loss = 0.40562757495875773, disc_loss = 0.058180886373927466
Trained batch 219 in epoch 19, gen_loss = 0.405399189889431, disc_loss = 0.05801418588539078
Trained batch 220 in epoch 19, gen_loss = 0.4055643204380484, disc_loss = 0.057786058619770125
Trained batch 221 in epoch 19, gen_loss = 0.4053191486242655, disc_loss = 0.0575723654301082
Trained batch 222 in epoch 19, gen_loss = 0.405215925165356, disc_loss = 0.05738256095528536
Trained batch 223 in epoch 19, gen_loss = 0.4050525087597115, disc_loss = 0.05743477529072801
Trained batch 224 in epoch 19, gen_loss = 0.4047672563129001, disc_loss = 0.057689081651882995
Trained batch 225 in epoch 19, gen_loss = 0.4048811930470762, disc_loss = 0.057591938081947444
Trained batch 226 in epoch 19, gen_loss = 0.4051601499450364, disc_loss = 0.05737790064311828
Trained batch 227 in epoch 19, gen_loss = 0.4049309422833878, disc_loss = 0.05721586197001958
Trained batch 228 in epoch 19, gen_loss = 0.4047522556573543, disc_loss = 0.05718458228537154
Trained batch 229 in epoch 19, gen_loss = 0.40502350628376005, disc_loss = 0.05697014249415825
Trained batch 230 in epoch 19, gen_loss = 0.40488568141862946, disc_loss = 0.05707549979684479
Trained batch 231 in epoch 19, gen_loss = 0.4045386146111735, disc_loss = 0.05729679922484953
Trained batch 232 in epoch 19, gen_loss = 0.40474657989366886, disc_loss = 0.057102252375494385
Trained batch 233 in epoch 19, gen_loss = 0.4050628533984861, disc_loss = 0.0570640134302756
Trained batch 234 in epoch 19, gen_loss = 0.4051350090097874, disc_loss = 0.056909774023880984
Trained batch 235 in epoch 19, gen_loss = 0.4048694781327652, disc_loss = 0.056780452281631276
Trained batch 236 in epoch 19, gen_loss = 0.4050058232078069, disc_loss = 0.056580491043737295
Trained batch 237 in epoch 19, gen_loss = 0.40488105035629596, disc_loss = 0.05646292680772726
Trained batch 238 in epoch 19, gen_loss = 0.40512953567704396, disc_loss = 0.0563403514923068
Trained batch 239 in epoch 19, gen_loss = 0.40509880892932415, disc_loss = 0.05613392228842713
Trained batch 240 in epoch 19, gen_loss = 0.40539564866248007, disc_loss = 0.056039296189145306
Trained batch 241 in epoch 19, gen_loss = 0.4057003056461161, disc_loss = 0.056088611396984005
Trained batch 242 in epoch 19, gen_loss = 0.40553369124730426, disc_loss = 0.056051989954056934
Trained batch 243 in epoch 19, gen_loss = 0.40526576303556316, disc_loss = 0.05593946982808717
Trained batch 244 in epoch 19, gen_loss = 0.40530741920276564, disc_loss = 0.05589945294076995
Trained batch 245 in epoch 19, gen_loss = 0.4055711366539079, disc_loss = 0.05588086887368766
Trained batch 246 in epoch 19, gen_loss = 0.4052033307339981, disc_loss = 0.05574236243684222
Trained batch 247 in epoch 19, gen_loss = 0.4050630704770165, disc_loss = 0.055805427568679254
Trained batch 248 in epoch 19, gen_loss = 0.40528239866337146, disc_loss = 0.05697416233452388
Trained batch 249 in epoch 19, gen_loss = 0.40534383821487424, disc_loss = 0.05682029534690082
Trained batch 250 in epoch 19, gen_loss = 0.405287723023578, disc_loss = 0.05674062646828978
Trained batch 251 in epoch 19, gen_loss = 0.40523556537098354, disc_loss = 0.05665807761362798
Trained batch 252 in epoch 19, gen_loss = 0.4055847353614837, disc_loss = 0.056656419890362165
Trained batch 253 in epoch 19, gen_loss = 0.40551058396579714, disc_loss = 0.05651511160810808
Trained batch 254 in epoch 19, gen_loss = 0.4052466497701757, disc_loss = 0.056373735099081314
Trained batch 255 in epoch 19, gen_loss = 0.405049730790779, disc_loss = 0.05635566934324743
Trained batch 256 in epoch 19, gen_loss = 0.4051607060989053, disc_loss = 0.05641422934417073
Trained batch 257 in epoch 19, gen_loss = 0.4048521896434385, disc_loss = 0.05624739292741919
Trained batch 258 in epoch 19, gen_loss = 0.4048256643950709, disc_loss = 0.05628002401707428
Trained batch 259 in epoch 19, gen_loss = 0.4048610689548346, disc_loss = 0.05646565712522715
Trained batch 260 in epoch 19, gen_loss = 0.40486757074736085, disc_loss = 0.05629547967457737
Trained batch 261 in epoch 19, gen_loss = 0.40456476875843894, disc_loss = 0.05633279802953071
Trained batch 262 in epoch 19, gen_loss = 0.40494221154274596, disc_loss = 0.056288543700846086
Trained batch 263 in epoch 19, gen_loss = 0.40510910128553707, disc_loss = 0.05612013365007994
Trained batch 264 in epoch 19, gen_loss = 0.40493262117763734, disc_loss = 0.05594598806797052
Trained batch 265 in epoch 19, gen_loss = 0.4047073124718845, disc_loss = 0.05581762614884043
Trained batch 266 in epoch 19, gen_loss = 0.40447082992796596, disc_loss = 0.055748126282939195
Trained batch 267 in epoch 19, gen_loss = 0.40412637980571436, disc_loss = 0.05567806358483912
Trained batch 268 in epoch 19, gen_loss = 0.4043490957593386, disc_loss = 0.055508606656901126
Trained batch 269 in epoch 19, gen_loss = 0.40408986663376845, disc_loss = 0.05560219116267507
Trained batch 270 in epoch 19, gen_loss = 0.4037635594716371, disc_loss = 0.055652897731088294
Trained batch 271 in epoch 19, gen_loss = 0.4040149693541667, disc_loss = 0.05549604309250272
Trained batch 272 in epoch 19, gen_loss = 0.40381474514583965, disc_loss = 0.055449626430691706
Trained batch 273 in epoch 19, gen_loss = 0.4035177384197277, disc_loss = 0.05528023806876455
Trained batch 274 in epoch 19, gen_loss = 0.40352637139233677, disc_loss = 0.05524946917695078
Trained batch 275 in epoch 19, gen_loss = 0.4038500738316688, disc_loss = 0.05512735096272081
Trained batch 276 in epoch 19, gen_loss = 0.4038868267828807, disc_loss = 0.0551894655710066
Trained batch 277 in epoch 19, gen_loss = 0.40385652220935275, disc_loss = 0.05510878462257306
Trained batch 278 in epoch 19, gen_loss = 0.4041332255341246, disc_loss = 0.05496500781486913
Trained batch 279 in epoch 19, gen_loss = 0.4039623777781214, disc_loss = 0.05484667005782415
Trained batch 280 in epoch 19, gen_loss = 0.40409340065144983, disc_loss = 0.05471490221959787
Trained batch 281 in epoch 19, gen_loss = 0.4042539137897762, disc_loss = 0.054557890672540514
Trained batch 282 in epoch 19, gen_loss = 0.40420161477247313, disc_loss = 0.05440207549235899
Trained batch 283 in epoch 19, gen_loss = 0.40408224790868624, disc_loss = 0.05436774236510809
Trained batch 284 in epoch 19, gen_loss = 0.403766804933548, disc_loss = 0.0544397650923776
Trained batch 285 in epoch 19, gen_loss = 0.40368192668978153, disc_loss = 0.05430005768711282
Trained batch 286 in epoch 19, gen_loss = 0.40351174984659466, disc_loss = 0.054141175817983805
Trained batch 287 in epoch 19, gen_loss = 0.4034362461210953, disc_loss = 0.053982544145482175
Trained batch 288 in epoch 19, gen_loss = 0.40312491888405955, disc_loss = 0.05386093011203264
Trained batch 289 in epoch 19, gen_loss = 0.40281646436658397, disc_loss = 0.053792185180595725
Trained batch 290 in epoch 19, gen_loss = 0.40288549303189175, disc_loss = 0.053881387503119986
Trained batch 291 in epoch 19, gen_loss = 0.4029838200913717, disc_loss = 0.05375830804106256
Trained batch 292 in epoch 19, gen_loss = 0.40252129077504517, disc_loss = 0.05402453605295397
Trained batch 293 in epoch 19, gen_loss = 0.4028090010492169, disc_loss = 0.05413345250516471
Trained batch 294 in epoch 19, gen_loss = 0.4029511819451542, disc_loss = 0.053997340790485425
Trained batch 295 in epoch 19, gen_loss = 0.4029661727112693, disc_loss = 0.05383894061103363
Trained batch 296 in epoch 19, gen_loss = 0.40283259277793293, disc_loss = 0.05367886535008046
Trained batch 297 in epoch 19, gen_loss = 0.4027578640704187, disc_loss = 0.05352482258735987
Trained batch 298 in epoch 19, gen_loss = 0.4026474438383428, disc_loss = 0.053402393536150054
Trained batch 299 in epoch 19, gen_loss = 0.4026099993785222, disc_loss = 0.0532497592518727
Trained batch 300 in epoch 19, gen_loss = 0.4025163704968766, disc_loss = 0.05309758495007243
Trained batch 301 in epoch 19, gen_loss = 0.4024367854492554, disc_loss = 0.05294970261081066
Trained batch 302 in epoch 19, gen_loss = 0.40250715741229925, disc_loss = 0.05280327592536856
Trained batch 303 in epoch 19, gen_loss = 0.4027723264145224, disc_loss = 0.05265507982480094
Trained batch 304 in epoch 19, gen_loss = 0.40266219885622867, disc_loss = 0.05250704103592234
Trained batch 305 in epoch 19, gen_loss = 0.4025967405512442, disc_loss = 0.0523699763477506
Trained batch 306 in epoch 19, gen_loss = 0.4026460002998576, disc_loss = 0.05221874566736604
Trained batch 307 in epoch 19, gen_loss = 0.40263302720986405, disc_loss = 0.052071570234324835
Trained batch 308 in epoch 19, gen_loss = 0.4024509594664219, disc_loss = 0.051944772966061405
Trained batch 309 in epoch 19, gen_loss = 0.40241718446054764, disc_loss = 0.05181880048626373
Trained batch 310 in epoch 19, gen_loss = 0.40246611737744986, disc_loss = 0.05172777464283912
Trained batch 311 in epoch 19, gen_loss = 0.40260426776531416, disc_loss = 0.05160488212445321
Trained batch 312 in epoch 19, gen_loss = 0.4026594936085966, disc_loss = 0.05171508125710887
Trained batch 313 in epoch 19, gen_loss = 0.40235075791170644, disc_loss = 0.05270659995033957
Trained batch 314 in epoch 19, gen_loss = 0.40271963619050527, disc_loss = 0.053016394947374625
Trained batch 315 in epoch 19, gen_loss = 0.402802265331715, disc_loss = 0.05309091442665439
Trained batch 316 in epoch 19, gen_loss = 0.40293106229899434, disc_loss = 0.052964404369307806
Trained batch 317 in epoch 19, gen_loss = 0.4027957664158359, disc_loss = 0.052943325551730466
Trained batch 318 in epoch 19, gen_loss = 0.4027434673428909, disc_loss = 0.05282788747939103
Trained batch 319 in epoch 19, gen_loss = 0.40272566173225643, disc_loss = 0.05269287072878796
Trained batch 320 in epoch 19, gen_loss = 0.40268130020189136, disc_loss = 0.05255850385062141
Trained batch 321 in epoch 19, gen_loss = 0.4025889453680619, disc_loss = 0.05241846145992601
Trained batch 322 in epoch 19, gen_loss = 0.40248474174239685, disc_loss = 0.052315171159250266
Trained batch 323 in epoch 19, gen_loss = 0.40250902659731147, disc_loss = 0.0521885480955933
Trained batch 324 in epoch 19, gen_loss = 0.4021904588662661, disc_loss = 0.05212238554484569
Trained batch 325 in epoch 19, gen_loss = 0.40194689980679493, disc_loss = 0.052029792067989064
Trained batch 326 in epoch 19, gen_loss = 0.4020427344224504, disc_loss = 0.05195835246120662
Trained batch 327 in epoch 19, gen_loss = 0.4019271083539579, disc_loss = 0.05199362705291317
Trained batch 328 in epoch 19, gen_loss = 0.40210668665659827, disc_loss = 0.052739551950438585
Trained batch 329 in epoch 19, gen_loss = 0.40213184528278584, disc_loss = 0.05263623127600912
Trained batch 330 in epoch 19, gen_loss = 0.4020133936873376, disc_loss = 0.05258114428577376
Trained batch 331 in epoch 19, gen_loss = 0.4019213887043746, disc_loss = 0.05249064752035382
Trained batch 332 in epoch 19, gen_loss = 0.40191230195778627, disc_loss = 0.052370193436764204
Trained batch 333 in epoch 19, gen_loss = 0.4017850459514264, disc_loss = 0.052239145799177496
Trained batch 334 in epoch 19, gen_loss = 0.401836466433397, disc_loss = 0.052253879167473136
Trained batch 335 in epoch 19, gen_loss = 0.40205483076473075, disc_loss = 0.052228868212772624
Trained batch 336 in epoch 19, gen_loss = 0.4020485732958649, disc_loss = 0.05212166349373161
Trained batch 337 in epoch 19, gen_loss = 0.40216103451844504, disc_loss = 0.05198917717303662
Trained batch 338 in epoch 19, gen_loss = 0.402127251688358, disc_loss = 0.05195032063168323
Trained batch 339 in epoch 19, gen_loss = 0.4022128811653923, disc_loss = 0.052013386334018676
Trained batch 340 in epoch 19, gen_loss = 0.40211682078425837, disc_loss = 0.05190473239420971
Trained batch 341 in epoch 19, gen_loss = 0.40196908077998467, disc_loss = 0.05191300776160774
Trained batch 342 in epoch 19, gen_loss = 0.40232096573354204, disc_loss = 0.051803264647461586
Trained batch 343 in epoch 19, gen_loss = 0.40249405142872835, disc_loss = 0.05212786208924859
Trained batch 344 in epoch 19, gen_loss = 0.40258037387460904, disc_loss = 0.052374550656995915
Trained batch 345 in epoch 19, gen_loss = 0.4025719972876455, disc_loss = 0.05226577616517426
Trained batch 346 in epoch 19, gen_loss = 0.4028586783910691, disc_loss = 0.05216851437018825
Trained batch 347 in epoch 19, gen_loss = 0.4027522935949523, disc_loss = 0.05207703445085335
Trained batch 348 in epoch 19, gen_loss = 0.4025350275388078, disc_loss = 0.05200594024770069
Trained batch 349 in epoch 19, gen_loss = 0.40267147549561094, disc_loss = 0.051891480088233945
Trained batch 350 in epoch 19, gen_loss = 0.40275985775170503, disc_loss = 0.05176447986882509
Trained batch 351 in epoch 19, gen_loss = 0.402827942320569, disc_loss = 0.051657396549919875
Trained batch 352 in epoch 19, gen_loss = 0.40260000615552194, disc_loss = 0.051582612689563385
Trained batch 353 in epoch 19, gen_loss = 0.4026963565140794, disc_loss = 0.051483069011141774
Trained batch 354 in epoch 19, gen_loss = 0.4027692087099586, disc_loss = 0.05135768540334743
Trained batch 355 in epoch 19, gen_loss = 0.40284295648001556, disc_loss = 0.051387528811707
Trained batch 356 in epoch 19, gen_loss = 0.402374746168361, disc_loss = 0.051743791004282835
Trained batch 357 in epoch 19, gen_loss = 0.4024927195723496, disc_loss = 0.051652968550288225
Trained batch 358 in epoch 19, gen_loss = 0.40257661937007, disc_loss = 0.05164460431716942
Trained batch 359 in epoch 19, gen_loss = 0.4024775909880797, disc_loss = 0.051532462995965034
Trained batch 360 in epoch 19, gen_loss = 0.4024800848927855, disc_loss = 0.05143981546271912
Trained batch 361 in epoch 19, gen_loss = 0.40234436983890953, disc_loss = 0.05133144216462764
Trained batch 362 in epoch 19, gen_loss = 0.40234475942025827, disc_loss = 0.05123010978805666
Trained batch 363 in epoch 19, gen_loss = 0.40244977462750214, disc_loss = 0.05115363077685278
Trained batch 364 in epoch 19, gen_loss = 0.40243166464648833, disc_loss = 0.05104520421551719
Trained batch 365 in epoch 19, gen_loss = 0.4026362523029411, disc_loss = 0.050945836517583235
Trained batch 366 in epoch 19, gen_loss = 0.4025372700405381, disc_loss = 0.050994173764461796
Trained batch 367 in epoch 19, gen_loss = 0.40233351711345755, disc_loss = 0.05184763570381936
Trained batch 368 in epoch 19, gen_loss = 0.40226673296473536, disc_loss = 0.05295719296815313
Trained batch 369 in epoch 19, gen_loss = 0.4023441745622738, disc_loss = 0.05287722079460887
Trained batch 370 in epoch 19, gen_loss = 0.40226699448017417, disc_loss = 0.05279115995271709
Trained batch 371 in epoch 19, gen_loss = 0.4021290007938621, disc_loss = 0.05271852116716365
Trained batch 372 in epoch 19, gen_loss = 0.40213883162823183, disc_loss = 0.0526083776834683
Trained batch 373 in epoch 19, gen_loss = 0.4018393724678672, disc_loss = 0.052663387672198726
Trained batch 374 in epoch 19, gen_loss = 0.4018471032778422, disc_loss = 0.05255550265933077
Trained batch 375 in epoch 19, gen_loss = 0.40172512924417536, disc_loss = 0.05252592498065032
Trained batch 376 in epoch 19, gen_loss = 0.40171485301354204, disc_loss = 0.05246995063992686
Trained batch 377 in epoch 19, gen_loss = 0.4017045778572244, disc_loss = 0.052395837993740486
Trained batch 378 in epoch 19, gen_loss = 0.40168844867192977, disc_loss = 0.052315045788264916
Trained batch 379 in epoch 19, gen_loss = 0.40153869272846926, disc_loss = 0.05221308803455414
Trained batch 380 in epoch 19, gen_loss = 0.4016237826015693, disc_loss = 0.05212945764239027
Trained batch 381 in epoch 19, gen_loss = 0.401566702345903, disc_loss = 0.0522365821025661
Trained batch 382 in epoch 19, gen_loss = 0.4015977018495764, disc_loss = 0.05255442543937667
Trained batch 383 in epoch 19, gen_loss = 0.40176907391287386, disc_loss = 0.05247152328835606
Trained batch 384 in epoch 19, gen_loss = 0.4017285848592783, disc_loss = 0.05258552414522349
Trained batch 385 in epoch 19, gen_loss = 0.4018800342021211, disc_loss = 0.05301446125871584
Trained batch 386 in epoch 19, gen_loss = 0.40176444745186995, disc_loss = 0.05294524716425119
Trained batch 387 in epoch 19, gen_loss = 0.40165740243860126, disc_loss = 0.053111766569422
Trained batch 388 in epoch 19, gen_loss = 0.4018161782568708, disc_loss = 0.05303243245895962
Trained batch 389 in epoch 19, gen_loss = 0.40176136585382316, disc_loss = 0.05302771060393216
Trained batch 390 in epoch 19, gen_loss = 0.4018014759358848, disc_loss = 0.05293686464881463
Trained batch 391 in epoch 19, gen_loss = 0.4014969980534242, disc_loss = 0.05305805199717799
Trained batch 392 in epoch 19, gen_loss = 0.40172013048907274, disc_loss = 0.05327648100616178
Trained batch 393 in epoch 19, gen_loss = 0.40166837423283436, disc_loss = 0.053165051768188774
Trained batch 394 in epoch 19, gen_loss = 0.40157596046411537, disc_loss = 0.05323609761021371
Trained batch 395 in epoch 19, gen_loss = 0.4014420574813178, disc_loss = 0.053233460178645796
Trained batch 396 in epoch 19, gen_loss = 0.40149859892631357, disc_loss = 0.053121332331356456
Trained batch 397 in epoch 19, gen_loss = 0.4013018858193153, disc_loss = 0.053341315168859295
Trained batch 398 in epoch 19, gen_loss = 0.4014491573312229, disc_loss = 0.05405515215632723
Trained batch 399 in epoch 19, gen_loss = 0.40142484806478024, disc_loss = 0.05399089312064462
Trained batch 400 in epoch 19, gen_loss = 0.4013002378090361, disc_loss = 0.05396625472864419
Trained batch 401 in epoch 19, gen_loss = 0.40110490074501703, disc_loss = 0.053993959395696796
Trained batch 402 in epoch 19, gen_loss = 0.40111263832146715, disc_loss = 0.05417294159563947
Trained batch 403 in epoch 19, gen_loss = 0.401248128918728, disc_loss = 0.05412909090588109
Trained batch 404 in epoch 19, gen_loss = 0.4012883922936004, disc_loss = 0.0540439315220732
Trained batch 405 in epoch 19, gen_loss = 0.40109976017710025, disc_loss = 0.05403315409756463
Trained batch 406 in epoch 19, gen_loss = 0.40103517388535953, disc_loss = 0.054088841326287614
Trained batch 407 in epoch 19, gen_loss = 0.40115930322630733, disc_loss = 0.05410615615797795
Trained batch 408 in epoch 19, gen_loss = 0.40107680809818447, disc_loss = 0.05399370525820149
Trained batch 409 in epoch 19, gen_loss = 0.4011356810971004, disc_loss = 0.05404307897566114
Trained batch 410 in epoch 19, gen_loss = 0.4009402505237691, disc_loss = 0.0541415105850284
Trained batch 411 in epoch 19, gen_loss = 0.4009796855519119, disc_loss = 0.054030660800952285
Trained batch 412 in epoch 19, gen_loss = 0.40105756345153143, disc_loss = 0.05391827299085967
Trained batch 413 in epoch 19, gen_loss = 0.4010509738455648, disc_loss = 0.05385220843448263
Trained batch 414 in epoch 19, gen_loss = 0.4011699156588819, disc_loss = 0.05377162274713796
Trained batch 415 in epoch 19, gen_loss = 0.40119052950579387, disc_loss = 0.05367101710222554
Trained batch 416 in epoch 19, gen_loss = 0.40116847118885396, disc_loss = 0.05363112727483864
Trained batch 417 in epoch 19, gen_loss = 0.40119575356182297, disc_loss = 0.0535149912864558
Trained batch 418 in epoch 19, gen_loss = 0.40114636893488625, disc_loss = 0.05345773969072324
Trained batch 419 in epoch 19, gen_loss = 0.4011106080952145, disc_loss = 0.053382899715299054
Trained batch 420 in epoch 19, gen_loss = 0.40121677985100734, disc_loss = 0.05330434034638231
Trained batch 421 in epoch 19, gen_loss = 0.40138499565881575, disc_loss = 0.05327206801609864
Trained batch 422 in epoch 19, gen_loss = 0.40128223587435186, disc_loss = 0.05338905495536419
Trained batch 423 in epoch 19, gen_loss = 0.4014988937327322, disc_loss = 0.05357492002680511
Trained batch 424 in epoch 19, gen_loss = 0.40155489690163554, disc_loss = 0.053474140974747786
Trained batch 425 in epoch 19, gen_loss = 0.4014965783402394, disc_loss = 0.05345596961716426
Trained batch 426 in epoch 19, gen_loss = 0.4015107814405785, disc_loss = 0.05335829813639684
Trained batch 427 in epoch 19, gen_loss = 0.40153493203013857, disc_loss = 0.05326046983637438
Trained batch 428 in epoch 19, gen_loss = 0.40166303265344844, disc_loss = 0.053244725739179585
Trained batch 429 in epoch 19, gen_loss = 0.40156627865724787, disc_loss = 0.05336781896239277
Trained batch 430 in epoch 19, gen_loss = 0.4015500270296969, disc_loss = 0.05421368037987924
Trained batch 431 in epoch 19, gen_loss = 0.4015737243548588, disc_loss = 0.054152944842051645
Trained batch 432 in epoch 19, gen_loss = 0.4015447833246227, disc_loss = 0.054104157335256114
Trained batch 433 in epoch 19, gen_loss = 0.40141790109570674, disc_loss = 0.05405099774187233
Trained batch 434 in epoch 19, gen_loss = 0.40134976012953394, disc_loss = 0.05396888786284574
Trained batch 435 in epoch 19, gen_loss = 0.40138892699545675, disc_loss = 0.05389209006754938
Trained batch 436 in epoch 19, gen_loss = 0.40126865897626024, disc_loss = 0.05389927680235467
Trained batch 437 in epoch 19, gen_loss = 0.4012603158956249, disc_loss = 0.053794933131100724
Trained batch 438 in epoch 19, gen_loss = 0.4011573319690374, disc_loss = 0.05371680102737489
Trained batch 439 in epoch 19, gen_loss = 0.4012893315743316, disc_loss = 0.053613742674827915
Trained batch 440 in epoch 19, gen_loss = 0.4013238551935641, disc_loss = 0.053513680364041166
Trained batch 441 in epoch 19, gen_loss = 0.4014480368853694, disc_loss = 0.053406271506185175
Trained batch 442 in epoch 19, gen_loss = 0.40140739870394326, disc_loss = 0.05332110913440955
Trained batch 443 in epoch 19, gen_loss = 0.4014099261782191, disc_loss = 0.053250359459402596
Trained batch 444 in epoch 19, gen_loss = 0.40129709009374126, disc_loss = 0.05319667270595438
Trained batch 445 in epoch 19, gen_loss = 0.40135809391603344, disc_loss = 0.053673900559444335
Trained batch 446 in epoch 19, gen_loss = 0.40102448306094346, disc_loss = 0.05395509105517427
Trained batch 447 in epoch 19, gen_loss = 0.401176020303475, disc_loss = 0.05385586692552481
Trained batch 448 in epoch 19, gen_loss = 0.4011367011176451, disc_loss = 0.05382095724510191
Trained batch 449 in epoch 19, gen_loss = 0.40113322536150614, disc_loss = 0.053747526705265045
Trained batch 450 in epoch 19, gen_loss = 0.4009683504865862, disc_loss = 0.053712044836346166
Trained batch 451 in epoch 19, gen_loss = 0.4007743578569024, disc_loss = 0.053624246609438445
Trained batch 452 in epoch 19, gen_loss = 0.4007164408302728, disc_loss = 0.053521312505960726
Trained batch 453 in epoch 19, gen_loss = 0.4005801650789866, disc_loss = 0.05345452085777395
Trained batch 454 in epoch 19, gen_loss = 0.4005763367637173, disc_loss = 0.05344651571915045
Trained batch 455 in epoch 19, gen_loss = 0.40049701125213977, disc_loss = 0.05345673669178627
Trained batch 456 in epoch 19, gen_loss = 0.40043735034617084, disc_loss = 0.05341530036531731
Trained batch 457 in epoch 19, gen_loss = 0.4006135070688339, disc_loss = 0.05338597258219422
Trained batch 458 in epoch 19, gen_loss = 0.40054646413570394, disc_loss = 0.05366050420746954
Testing Epoch 19
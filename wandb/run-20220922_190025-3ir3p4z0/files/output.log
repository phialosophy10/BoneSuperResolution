/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 0.7437596321105957, disc_loss = 0.5537540912628174
Trained batch 1 in epoch 0, gen_loss = 0.821788489818573, disc_loss = 0.750238686800003
Trained batch 2 in epoch 0, gen_loss = 0.7230141758918762, disc_loss = 0.6466623743375143
Trained batch 3 in epoch 0, gen_loss = 0.6692143827676773, disc_loss = 0.5527131259441376
Trained batch 4 in epoch 0, gen_loss = 0.6400004267692566, disc_loss = 0.48779538571834563
Trained batch 5 in epoch 0, gen_loss = 0.6250499586264292, disc_loss = 0.44828349103530246
Trained batch 6 in epoch 0, gen_loss = 0.6046256593295506, disc_loss = 0.42933731206825804
Trained batch 7 in epoch 0, gen_loss = 0.5888106226921082, disc_loss = 0.40161674842238426
Trained batch 8 in epoch 0, gen_loss = 0.5852239396837022, disc_loss = 0.3753269447220696
Trained batch 9 in epoch 0, gen_loss = 0.5784082055091858, disc_loss = 0.3523445338010788
Trained batch 10 in epoch 0, gen_loss = 0.5719060681082986, disc_loss = 0.33517619290135126
Trained batch 11 in epoch 0, gen_loss = 0.5464832633733749, disc_loss = 0.32736040527621907
Trained batch 12 in epoch 0, gen_loss = 0.5462482571601868, disc_loss = 0.31875203205988956
Trained batch 13 in epoch 0, gen_loss = 0.5371068034853254, disc_loss = 0.31241244077682495
Trained batch 14 in epoch 0, gen_loss = 0.5306368271509806, disc_loss = 0.31180609464645387
Trained batch 15 in epoch 0, gen_loss = 0.5306151360273361, disc_loss = 0.3026113575324416
Trained batch 16 in epoch 0, gen_loss = 0.5193169765612659, disc_loss = 0.2957676272181904
Trained batch 17 in epoch 0, gen_loss = 0.5183623052305646, disc_loss = 0.2884424477815628
Trained batch 18 in epoch 0, gen_loss = 0.5166750032650796, disc_loss = 0.28319255380254044
Trained batch 19 in epoch 0, gen_loss = 0.5143312245607377, disc_loss = 0.2766840882599354
Trained batch 20 in epoch 0, gen_loss = 0.5091552138328552, disc_loss = 0.26953821664764765
Trained batch 21 in epoch 0, gen_loss = 0.5082849765365774, disc_loss = 0.2640864381735975
Trained batch 22 in epoch 0, gen_loss = 0.5047642109186753, disc_loss = 0.25846090200154676
Trained batch 23 in epoch 0, gen_loss = 0.5036121966938177, disc_loss = 0.2521797598650058
Trained batch 24 in epoch 0, gen_loss = 0.5037466895580291, disc_loss = 0.24532135009765624
Trained batch 25 in epoch 0, gen_loss = 0.5065695035916108, disc_loss = 0.23847428995829362
Trained batch 26 in epoch 0, gen_loss = 0.5095925761593713, disc_loss = 0.2318751754032241
Trained batch 27 in epoch 0, gen_loss = 0.5121965759566852, disc_loss = 0.22572217482541287
Trained batch 28 in epoch 0, gen_loss = 0.5155289430042793, disc_loss = 0.21979626653523282
Trained batch 29 in epoch 0, gen_loss = 0.5202819595734278, disc_loss = 0.2143014936397473
Trained batch 30 in epoch 0, gen_loss = 0.5253137052059174, disc_loss = 0.20909751266721757
Trained batch 31 in epoch 0, gen_loss = 0.5288544083014131, disc_loss = 0.2042043627006933
Trained batch 32 in epoch 0, gen_loss = 0.5313352608319485, disc_loss = 0.19953179698098789
Trained batch 33 in epoch 0, gen_loss = 0.534139129168847, disc_loss = 0.1949648943674915
Trained batch 34 in epoch 0, gen_loss = 0.5378421791962215, disc_loss = 0.1906189016997814
Trained batch 35 in epoch 0, gen_loss = 0.5393838890724711, disc_loss = 0.18656550140844452
Trained batch 36 in epoch 0, gen_loss = 0.5391012695995537, disc_loss = 0.1827740047026325
Trained batch 37 in epoch 0, gen_loss = 0.5361724840967279, disc_loss = 0.17977517157008774
Trained batch 38 in epoch 0, gen_loss = 0.5394505659739176, disc_loss = 0.1776102118385144
Trained batch 39 in epoch 0, gen_loss = 0.5335753679275512, disc_loss = 0.1765393579378724
Trained batch 40 in epoch 0, gen_loss = 0.54449345716616, disc_loss = 0.17644306199579704
Trained batch 41 in epoch 0, gen_loss = 0.551781679902758, disc_loss = 0.17616190140446028
Trained batch 42 in epoch 0, gen_loss = 0.5511830338211947, disc_loss = 0.17696257819269978
Trained batch 43 in epoch 0, gen_loss = 0.5550874972885306, disc_loss = 0.1751716145398942
Trained batch 44 in epoch 0, gen_loss = 0.55424831310908, disc_loss = 0.17244578078389167
Trained batch 45 in epoch 0, gen_loss = 0.5541169163973435, disc_loss = 0.16959447251713794
Trained batch 46 in epoch 0, gen_loss = 0.5528239962902475, disc_loss = 0.167077880431997
Trained batch 47 in epoch 0, gen_loss = 0.5532801871498426, disc_loss = 0.16440827026963234
Trained batch 48 in epoch 0, gen_loss = 0.55342976900996, disc_loss = 0.16175943590244468
Trained batch 49 in epoch 0, gen_loss = 0.5525099670886994, disc_loss = 0.1593146661669016
Trained batch 50 in epoch 0, gen_loss = 0.5531232812825371, disc_loss = 0.15697401754704177
Trained batch 51 in epoch 0, gen_loss = 0.5547582220572692, disc_loss = 0.15466757154522034
Trained batch 52 in epoch 0, gen_loss = 0.5513573367640657, disc_loss = 0.15319495542712933
Trained batch 53 in epoch 0, gen_loss = 0.5573713624918902, disc_loss = 0.15265775961732422
Trained batch 54 in epoch 0, gen_loss = 0.5550298679958691, disc_loss = 0.1507920542223887
Trained batch 55 in epoch 0, gen_loss = 0.5533092437045914, disc_loss = 0.14879445086366364
Trained batch 56 in epoch 0, gen_loss = 0.554947344880355, disc_loss = 0.14710438290708944
Trained batch 57 in epoch 0, gen_loss = 0.5529140932806607, disc_loss = 0.1453197548358605
Trained batch 58 in epoch 0, gen_loss = 0.5537781149654065, disc_loss = 0.14356576954409228
Trained batch 59 in epoch 0, gen_loss = 0.5530876169602076, disc_loss = 0.14170405107239883
Trained batch 60 in epoch 0, gen_loss = 0.5550320040984232, disc_loss = 0.13989757728136953
Trained batch 61 in epoch 0, gen_loss = 0.5534581306480593, disc_loss = 0.13844332898095732
Trained batch 62 in epoch 0, gen_loss = 0.555979510621419, disc_loss = 0.13722213588300206
Trained batch 63 in epoch 0, gen_loss = 0.5556720136664808, disc_loss = 0.1358615209464915
Trained batch 64 in epoch 0, gen_loss = 0.5561536307518299, disc_loss = 0.13435287710565788
Trained batch 65 in epoch 0, gen_loss = 0.556498805230314, disc_loss = 0.13278245079246434
Trained batch 66 in epoch 0, gen_loss = 0.5562129523327102, disc_loss = 0.13124632960491217
Trained batch 67 in epoch 0, gen_loss = 0.555977839319145, disc_loss = 0.1297245171633275
Trained batch 68 in epoch 0, gen_loss = 0.556107384139213, disc_loss = 0.1283462790745324
Trained batch 69 in epoch 0, gen_loss = 0.5557002420936312, disc_loss = 0.12697079998574087
Trained batch 70 in epoch 0, gen_loss = 0.5556079615169848, disc_loss = 0.12559039796322163
Trained batch 71 in epoch 0, gen_loss = 0.5571851842105389, disc_loss = 0.12424415743185414
Trained batch 72 in epoch 0, gen_loss = 0.556204715411957, disc_loss = 0.1230977667521124
Trained batch 73 in epoch 0, gen_loss = 0.5581208576221723, disc_loss = 0.12201750122413442
Trained batch 74 in epoch 0, gen_loss = 0.5582662308216095, disc_loss = 0.12086718887090683
Trained batch 75 in epoch 0, gen_loss = 0.5567556023597717, disc_loss = 0.11993320399013005
Trained batch 76 in epoch 0, gen_loss = 0.5610511960921349, disc_loss = 0.12035715265514015
Trained batch 77 in epoch 0, gen_loss = 0.5558288838618841, disc_loss = 0.12341405026232585
Trained batch 78 in epoch 0, gen_loss = 0.5584519995918756, disc_loss = 0.12333159898466702
Trained batch 79 in epoch 0, gen_loss = 0.5599296793341637, disc_loss = 0.12292536548338831
Trained batch 80 in epoch 0, gen_loss = 0.5581780274709066, disc_loss = 0.12234008326022713
Trained batch 81 in epoch 0, gen_loss = 0.5567808078556526, disc_loss = 0.12151292025497774
Trained batch 82 in epoch 0, gen_loss = 0.5572035621447735, disc_loss = 0.12073313830846763
Trained batch 83 in epoch 0, gen_loss = 0.556515535073621, disc_loss = 0.11976868047245912
Trained batch 84 in epoch 0, gen_loss = 0.555920139130424, disc_loss = 0.11876823604106904
Trained batch 85 in epoch 0, gen_loss = 0.5567810365626978, disc_loss = 0.11791258799128754
Trained batch 86 in epoch 0, gen_loss = 0.5555696477150095, disc_loss = 0.11714694914461553
Trained batch 87 in epoch 0, gen_loss = 0.5561673780056563, disc_loss = 0.11621057479219003
Trained batch 88 in epoch 0, gen_loss = 0.5560739244637865, disc_loss = 0.11526669026090858
Trained batch 89 in epoch 0, gen_loss = 0.5561086240741941, disc_loss = 0.11445217298136817
Trained batch 90 in epoch 0, gen_loss = 0.554930309345434, disc_loss = 0.11372906182493482
Trained batch 91 in epoch 0, gen_loss = 0.5571340293340061, disc_loss = 0.1129414779741479
Trained batch 92 in epoch 0, gen_loss = 0.5573533699717573, disc_loss = 0.1120711977603615
Trained batch 93 in epoch 0, gen_loss = 0.5573089176670034, disc_loss = 0.11119172720119674
Trained batch 94 in epoch 0, gen_loss = 0.5604404728663596, disc_loss = 0.11090434654370734
Trained batch 95 in epoch 0, gen_loss = 0.5589561148857077, disc_loss = 0.11125965934479609
Trained batch 96 in epoch 0, gen_loss = 0.5568310071512595, disc_loss = 0.11110359727952283
Trained batch 97 in epoch 0, gen_loss = 0.561745074330544, disc_loss = 0.11290456193062115
Trained batch 98 in epoch 0, gen_loss = 0.5600617004163337, disc_loss = 0.11267728492090798
Trained batch 99 in epoch 0, gen_loss = 0.5579199206829071, disc_loss = 0.11256105756387115
Trained batch 100 in epoch 0, gen_loss = 0.5599841617121555, disc_loss = 0.1136327817261514
Trained batch 101 in epoch 0, gen_loss = 0.5575142304102579, disc_loss = 0.11376192586898219
Trained batch 102 in epoch 0, gen_loss = 0.5550806507902238, disc_loss = 0.11391864100344551
Trained batch 103 in epoch 0, gen_loss = 0.5555188882236297, disc_loss = 0.11454063773943254
Trained batch 104 in epoch 0, gen_loss = 0.5542931678749267, disc_loss = 0.11459241053532987
Trained batch 105 in epoch 0, gen_loss = 0.5522416889105203, disc_loss = 0.11456655442082095
Trained batch 106 in epoch 0, gen_loss = 0.5522651964815978, disc_loss = 0.11427023176486804
Trained batch 107 in epoch 0, gen_loss = 0.5506381533212132, disc_loss = 0.11387399127017017
Trained batch 108 in epoch 0, gen_loss = 0.5504505303474742, disc_loss = 0.11341687912172681
Trained batch 109 in epoch 0, gen_loss = 0.5489534646272659, disc_loss = 0.11313466868278656
Trained batch 110 in epoch 0, gen_loss = 0.549511040384705, disc_loss = 0.11289988698118979
Trained batch 111 in epoch 0, gen_loss = 0.5460081290719765, disc_loss = 0.11420706085794206
Trained batch 112 in epoch 0, gen_loss = 0.5477077912176604, disc_loss = 0.11591714922239822
Trained batch 113 in epoch 0, gen_loss = 0.5445799500795833, disc_loss = 0.1173503684991023
Trained batch 114 in epoch 0, gen_loss = 0.543426336671995, disc_loss = 0.11776557083687057
Trained batch 115 in epoch 0, gen_loss = 0.5416911095380783, disc_loss = 0.11785788960947559
Trained batch 116 in epoch 0, gen_loss = 0.5403512385156419, disc_loss = 0.11810847516689035
Trained batch 117 in epoch 0, gen_loss = 0.5379039938166991, disc_loss = 0.11843355061581075
Trained batch 118 in epoch 0, gen_loss = 0.5383732659476144, disc_loss = 0.11862107759200725
Trained batch 119 in epoch 0, gen_loss = 0.5365655707816283, disc_loss = 0.1184411626153936
Trained batch 120 in epoch 0, gen_loss = 0.534708964184296, disc_loss = 0.11832839741625568
Trained batch 121 in epoch 0, gen_loss = 0.5357484561009486, disc_loss = 0.11905520591029867
Trained batch 122 in epoch 0, gen_loss = 0.5325250852156461, disc_loss = 0.12072252329226917
Trained batch 123 in epoch 0, gen_loss = 0.5311132216405484, disc_loss = 0.12089251448971129
Trained batch 124 in epoch 0, gen_loss = 0.5323135823011398, disc_loss = 0.12129615424573421
Trained batch 125 in epoch 0, gen_loss = 0.5299179881574616, disc_loss = 0.1214664423365205
Trained batch 126 in epoch 0, gen_loss = 0.5280391422547693, disc_loss = 0.12142185953365067
Trained batch 127 in epoch 0, gen_loss = 0.5279240295058116, disc_loss = 0.12132349050079938
Trained batch 128 in epoch 0, gen_loss = 0.5267644017472748, disc_loss = 0.12095056518970072
Trained batch 129 in epoch 0, gen_loss = 0.5252648551876729, disc_loss = 0.12064653966002739
Trained batch 130 in epoch 0, gen_loss = 0.5245809578941069, disc_loss = 0.12026541001867247
Trained batch 131 in epoch 0, gen_loss = 0.5245549002605857, disc_loss = 0.11973177755928853
Trained batch 132 in epoch 0, gen_loss = 0.5236844172827283, disc_loss = 0.11920917360462192
Trained batch 133 in epoch 0, gen_loss = 0.5225463802022721, disc_loss = 0.11875020947529753
Trained batch 134 in epoch 0, gen_loss = 0.5228236506382624, disc_loss = 0.11886299220776117
Trained batch 135 in epoch 0, gen_loss = 0.5200851353652337, disc_loss = 0.12023921520449221
Trained batch 136 in epoch 0, gen_loss = 0.5222246951430384, disc_loss = 0.12072382585900109
Trained batch 137 in epoch 0, gen_loss = 0.5200212208041246, disc_loss = 0.12088131603609392
Trained batch 138 in epoch 0, gen_loss = 0.5192998605880806, disc_loss = 0.12078037805748072
Trained batch 139 in epoch 0, gen_loss = 0.518365021369287, disc_loss = 0.12053616096132568
Trained batch 140 in epoch 0, gen_loss = 0.5172389886269333, disc_loss = 0.12027611479110328
Trained batch 141 in epoch 0, gen_loss = 0.5162669169441075, disc_loss = 0.12006501933481072
Trained batch 142 in epoch 0, gen_loss = 0.5158626934239915, disc_loss = 0.119664918253576
Trained batch 143 in epoch 0, gen_loss = 0.5167525846304165, disc_loss = 0.11935620947689232
Trained batch 144 in epoch 0, gen_loss = 0.5141047869263025, disc_loss = 0.12076715360684641
Trained batch 145 in epoch 0, gen_loss = 0.515707828512747, disc_loss = 0.1210715757070543
Trained batch 146 in epoch 0, gen_loss = 0.5146757055099319, disc_loss = 0.12074605315974375
Trained batch 147 in epoch 0, gen_loss = 0.5134577881041411, disc_loss = 0.12055033381172531
Trained batch 148 in epoch 0, gen_loss = 0.512765064035486, disc_loss = 0.12023129665461563
Trained batch 149 in epoch 0, gen_loss = 0.5122618211309115, disc_loss = 0.1200412658477823
Trained batch 150 in epoch 0, gen_loss = 0.5113233826215694, disc_loss = 0.11980804925574767
Trained batch 151 in epoch 0, gen_loss = 0.5103145105470168, disc_loss = 0.11951026924591708
Trained batch 152 in epoch 0, gen_loss = 0.5113470991647321, disc_loss = 0.1192896260569493
Trained batch 153 in epoch 0, gen_loss = 0.509136601411677, disc_loss = 0.1201984090488646
Trained batch 154 in epoch 0, gen_loss = 0.5102905658944961, disc_loss = 0.12208093381937474
Trained batch 155 in epoch 0, gen_loss = 0.5092483140910283, disc_loss = 0.12195179182797289
Trained batch 156 in epoch 0, gen_loss = 0.507320542813866, disc_loss = 0.12240490963931676
Trained batch 157 in epoch 0, gen_loss = 0.5080613922091979, disc_loss = 0.12262194218184752
Trained batch 158 in epoch 0, gen_loss = 0.5068335861155072, disc_loss = 0.1226121972684028
Trained batch 159 in epoch 0, gen_loss = 0.5062155732885003, disc_loss = 0.12232800658093765
Trained batch 160 in epoch 0, gen_loss = 0.5057956618922097, disc_loss = 0.1217826492274585
Trained batch 161 in epoch 0, gen_loss = 0.5061712057134251, disc_loss = 0.12120905236835465
Trained batch 162 in epoch 0, gen_loss = 0.5044506557880004, disc_loss = 0.12129722502471113
Trained batch 163 in epoch 0, gen_loss = 0.5047068890275025, disc_loss = 0.12179772877247959
Trained batch 164 in epoch 0, gen_loss = 0.5033367762059876, disc_loss = 0.12173194730597915
Trained batch 165 in epoch 0, gen_loss = 0.5037857694439141, disc_loss = 0.12139028955969107
Trained batch 166 in epoch 0, gen_loss = 0.5027422428488018, disc_loss = 0.12106902418870055
Trained batch 167 in epoch 0, gen_loss = 0.502100452425934, disc_loss = 0.12072661642118224
Trained batch 168 in epoch 0, gen_loss = 0.501983447187751, disc_loss = 0.1205512599898337
Trained batch 169 in epoch 0, gen_loss = 0.5015357157763313, disc_loss = 0.12014086670516168
Trained batch 170 in epoch 0, gen_loss = 0.5008572273784213, disc_loss = 0.1197692655048698
Trained batch 171 in epoch 0, gen_loss = 0.5024620831705803, disc_loss = 0.11991719337353526
Trained batch 172 in epoch 0, gen_loss = 0.5006939780849942, disc_loss = 0.12049881397945687
Trained batch 173 in epoch 0, gen_loss = 0.5022860708935507, disc_loss = 0.12207881882572653
Trained batch 174 in epoch 0, gen_loss = 0.5008667349815369, disc_loss = 0.12250995788191046
Trained batch 175 in epoch 0, gen_loss = 0.4990730778398839, disc_loss = 0.12313729963815687
Trained batch 176 in epoch 0, gen_loss = 0.4980113033184224, disc_loss = 0.12338691005893683
Trained batch 177 in epoch 0, gen_loss = 0.49744157526600224, disc_loss = 0.12393173900840992
Trained batch 178 in epoch 0, gen_loss = 0.4965243226323048, disc_loss = 0.12489809810740654
Trained batch 179 in epoch 0, gen_loss = 0.49564004838466647, disc_loss = 0.1258226753005551
Trained batch 180 in epoch 0, gen_loss = 0.4945163687289749, disc_loss = 0.12599682205907217
Trained batch 181 in epoch 0, gen_loss = 0.49413016258360265, disc_loss = 0.12592928671370168
Trained batch 182 in epoch 0, gen_loss = 0.4932328535885107, disc_loss = 0.12585165195899908
Trained batch 183 in epoch 0, gen_loss = 0.4924616659788982, disc_loss = 0.12557498854584992
Trained batch 184 in epoch 0, gen_loss = 0.4928333329187857, disc_loss = 0.12533957377277516
Trained batch 185 in epoch 0, gen_loss = 0.4914899715172347, disc_loss = 0.12527576744836824
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 0.6327396035194397, disc_loss = 0.10706010460853577
Trained batch 1 in epoch 1, gen_loss = 0.46896442770957947, disc_loss = 0.09700075909495354
Trained batch 2 in epoch 1, gen_loss = 0.4640604058901469, disc_loss = 0.09604308754205704
Trained batch 3 in epoch 1, gen_loss = 0.4146054983139038, disc_loss = 0.09942146763205528
Trained batch 4 in epoch 1, gen_loss = 0.459713876247406, disc_loss = 0.11016528010368347
Trained batch 5 in epoch 1, gen_loss = 0.40829967459042865, disc_loss = 0.14120806256930032
Trained batch 6 in epoch 1, gen_loss = 0.44739326408931185, disc_loss = 0.1383568069764546
Trained batch 7 in epoch 1, gen_loss = 0.4346522316336632, disc_loss = 0.13043352030217648
Trained batch 8 in epoch 1, gen_loss = 0.4244225687450833, disc_loss = 0.1254623317056232
Trained batch 9 in epoch 1, gen_loss = 0.43682650327682493, disc_loss = 0.12090532407164574
Trained batch 10 in epoch 1, gen_loss = 0.42428548498587176, disc_loss = 0.11765771968798204
Trained batch 11 in epoch 1, gen_loss = 0.44120627890030545, disc_loss = 0.11281624777863423
Trained batch 12 in epoch 1, gen_loss = 0.4363959294099074, disc_loss = 0.107997299100344
Trained batch 13 in epoch 1, gen_loss = 0.44494134187698364, disc_loss = 0.10255641011255127
Trained batch 14 in epoch 1, gen_loss = 0.44660698572794594, disc_loss = 0.09754268961648146
Trained batch 15 in epoch 1, gen_loss = 0.4475717395544052, disc_loss = 0.0936163900187239
Trained batch 16 in epoch 1, gen_loss = 0.4546874691458309, disc_loss = 0.0899274891571087
Trained batch 17 in epoch 1, gen_loss = 0.4542027430401908, disc_loss = 0.0870941998437047
Trained batch 18 in epoch 1, gen_loss = 0.46656219425954315, disc_loss = 0.08489178091679749
Trained batch 19 in epoch 1, gen_loss = 0.4611916452646255, disc_loss = 0.08353440342471004
Trained batch 20 in epoch 1, gen_loss = 0.4630538594155085, disc_loss = 0.08122721447476319
Trained batch 21 in epoch 1, gen_loss = 0.4682645987380635, disc_loss = 0.07930108760906891
Trained batch 22 in epoch 1, gen_loss = 0.45856066048145294, disc_loss = 0.0806007397401592
Trained batch 23 in epoch 1, gen_loss = 0.47121876664459705, disc_loss = 0.08674593386240304
Trained batch 24 in epoch 1, gen_loss = 0.4570087805390358, disc_loss = 0.09553289644420147
Trained batch 25 in epoch 1, gen_loss = 0.46057064630664313, disc_loss = 0.09843703982635187
Trained batch 26 in epoch 1, gen_loss = 0.45042530943950015, disc_loss = 0.10150081409072434
Trained batch 27 in epoch 1, gen_loss = 0.4476284898285355, disc_loss = 0.10253065285672035
Trained batch 28 in epoch 1, gen_loss = 0.4524096458636481, disc_loss = 0.10570693009629331
Trained batch 29 in epoch 1, gen_loss = 0.4431017987430096, disc_loss = 0.10919667277485132
Trained batch 30 in epoch 1, gen_loss = 0.44085555715907004, disc_loss = 0.10818152892733773
Trained batch 31 in epoch 1, gen_loss = 0.4493594078812748, disc_loss = 0.10780679452000186
Trained batch 32 in epoch 1, gen_loss = 0.44453001406156656, disc_loss = 0.1074185251173648
Trained batch 33 in epoch 1, gen_loss = 0.44740264402592883, disc_loss = 0.10546183547772028
Trained batch 34 in epoch 1, gen_loss = 0.4484219076378005, disc_loss = 0.103587681427598
Trained batch 35 in epoch 1, gen_loss = 0.4463856214036544, disc_loss = 0.1019716628620194
Trained batch 36 in epoch 1, gen_loss = 0.45271225817300176, disc_loss = 0.10011422186083085
Trained batch 37 in epoch 1, gen_loss = 0.4529396430834344, disc_loss = 0.09837210879318024
Trained batch 38 in epoch 1, gen_loss = 0.45157985446544796, disc_loss = 0.09682852636354092
Trained batch 39 in epoch 1, gen_loss = 0.45287732128053904, disc_loss = 0.09581422745250165
Trained batch 40 in epoch 1, gen_loss = 0.4522193824736083, disc_loss = 0.09460782227901424
Trained batch 41 in epoch 1, gen_loss = 0.4508881201701505, disc_loss = 0.09365525757450432
Trained batch 42 in epoch 1, gen_loss = 0.4540988277903823, disc_loss = 0.09213456641449484
Trained batch 43 in epoch 1, gen_loss = 0.45466547002169216, disc_loss = 0.09061354618858207
Trained batch 44 in epoch 1, gen_loss = 0.4518092064393891, disc_loss = 0.08993247780534956
Trained batch 45 in epoch 1, gen_loss = 0.45720140457801195, disc_loss = 0.09007172432282697
Trained batch 46 in epoch 1, gen_loss = 0.4540638785730017, disc_loss = 0.09030302645678216
Trained batch 47 in epoch 1, gen_loss = 0.4531791745685041, disc_loss = 0.08913990777606766
Trained batch 48 in epoch 1, gen_loss = 0.4566190937648014, disc_loss = 0.08904255668119508
Trained batch 49 in epoch 1, gen_loss = 0.45593383923172953, disc_loss = 0.08787504553794862
Trained batch 50 in epoch 1, gen_loss = 0.4606243116306324, disc_loss = 0.08656670726543549
Trained batch 51 in epoch 1, gen_loss = 0.45772482010607535, disc_loss = 0.08647825801745057
Trained batch 52 in epoch 1, gen_loss = 0.4641765166284903, disc_loss = 0.087589834412595
Trained batch 53 in epoch 1, gen_loss = 0.4626164051393668, disc_loss = 0.08700241227806718
Trained batch 54 in epoch 1, gen_loss = 0.45983508134430107, disc_loss = 0.0867094389078292
Trained batch 55 in epoch 1, gen_loss = 0.46406804943191154, disc_loss = 0.08605567994527519
Trained batch 56 in epoch 1, gen_loss = 0.46492858165711687, disc_loss = 0.08511574504276116
Trained batch 57 in epoch 1, gen_loss = 0.46371437673424853, disc_loss = 0.0844699199921612
Trained batch 58 in epoch 1, gen_loss = 0.46646185560246645, disc_loss = 0.08329200389463517
Trained batch 59 in epoch 1, gen_loss = 0.46651951434711614, disc_loss = 0.08225313656342527
Trained batch 60 in epoch 1, gen_loss = 0.4682145652468087, disc_loss = 0.0811779591728185
Trained batch 61 in epoch 1, gen_loss = 0.4693423852084144, disc_loss = 0.08018619334325194
Trained batch 62 in epoch 1, gen_loss = 0.4686783411436611, disc_loss = 0.07943343484981193
Trained batch 63 in epoch 1, gen_loss = 0.4754266069503501, disc_loss = 0.07963827445928473
Trained batch 64 in epoch 1, gen_loss = 0.46993951465074835, disc_loss = 0.08321771949816209
Trained batch 65 in epoch 1, gen_loss = 0.47478435651370976, disc_loss = 0.08791598820155769
Trained batch 66 in epoch 1, gen_loss = 0.47087047071154436, disc_loss = 0.08881157354465616
Trained batch 67 in epoch 1, gen_loss = 0.47042183917673197, disc_loss = 0.08839522199431325
Trained batch 68 in epoch 1, gen_loss = 0.4695008396022562, disc_loss = 0.08832142508818187
Trained batch 69 in epoch 1, gen_loss = 0.46822366363235884, disc_loss = 0.08826928156028901
Trained batch 70 in epoch 1, gen_loss = 0.4675342565481092, disc_loss = 0.08788487206304997
Trained batch 71 in epoch 1, gen_loss = 0.46726010977807975, disc_loss = 0.08747932900829862
Trained batch 72 in epoch 1, gen_loss = 0.470803352965884, disc_loss = 0.08694911621868202
Trained batch 73 in epoch 1, gen_loss = 0.4710251446309927, disc_loss = 0.0864971693529672
Trained batch 74 in epoch 1, gen_loss = 0.47190745105346044, disc_loss = 0.08587900232523679
Trained batch 75 in epoch 1, gen_loss = 0.46907326294795465, disc_loss = 0.08633280566305314
Trained batch 76 in epoch 1, gen_loss = 0.4740368571954888, disc_loss = 0.09023858878955052
Trained batch 77 in epoch 1, gen_loss = 0.47069896270449346, disc_loss = 0.09100908558003795
Trained batch 78 in epoch 1, gen_loss = 0.4704446514384656, disc_loss = 0.09038239209382218
Trained batch 79 in epoch 1, gen_loss = 0.4710833945311606, disc_loss = 0.08976688726106659
Trained batch 80 in epoch 1, gen_loss = 0.46993849021785056, disc_loss = 0.08916392063515054
Trained batch 81 in epoch 1, gen_loss = 0.4699634707010374, disc_loss = 0.08829567241823165
Trained batch 82 in epoch 1, gen_loss = 0.47018636646400014, disc_loss = 0.0875170830614775
Trained batch 83 in epoch 1, gen_loss = 0.4694507882176411, disc_loss = 0.08692062150553934
Trained batch 84 in epoch 1, gen_loss = 0.4685661891804022, disc_loss = 0.08678008617066285
Trained batch 85 in epoch 1, gen_loss = 0.4666333927144838, disc_loss = 0.0867371529795576
Trained batch 86 in epoch 1, gen_loss = 0.47094229249090985, disc_loss = 0.08709140448434942
Trained batch 87 in epoch 1, gen_loss = 0.4706515460698442, disc_loss = 0.08667513636067849
Trained batch 88 in epoch 1, gen_loss = 0.468476080241498, disc_loss = 0.08681418287327115
Trained batch 89 in epoch 1, gen_loss = 0.4691461176508003, disc_loss = 0.08708040110973848
Trained batch 90 in epoch 1, gen_loss = 0.4729849922951761, disc_loss = 0.08653960468063315
Trained batch 91 in epoch 1, gen_loss = 0.47463519523001235, disc_loss = 0.08579624955461401
Trained batch 92 in epoch 1, gen_loss = 0.47131381856818355, disc_loss = 0.08718007699816778
Trained batch 93 in epoch 1, gen_loss = 0.4747584561242702, disc_loss = 0.08799329884548454
Trained batch 94 in epoch 1, gen_loss = 0.47502096114974274, disc_loss = 0.08766596980981137
Trained batch 95 in epoch 1, gen_loss = 0.47237590335619944, disc_loss = 0.08806396280609381
Trained batch 96 in epoch 1, gen_loss = 0.4708593039936626, disc_loss = 0.08800935719315846
Trained batch 97 in epoch 1, gen_loss = 0.47170480059421793, disc_loss = 0.08846852400967357
Trained batch 98 in epoch 1, gen_loss = 0.468810048744534, disc_loss = 0.08922586316299258
Trained batch 99 in epoch 1, gen_loss = 0.46857671685516833, disc_loss = 0.08904213053174317
Trained batch 100 in epoch 1, gen_loss = 0.4723903065418253, disc_loss = 0.08901983629543297
Trained batch 101 in epoch 1, gen_loss = 0.4735521400237785, disc_loss = 0.08831487962172604
Trained batch 102 in epoch 1, gen_loss = 0.4747338070018778, disc_loss = 0.08767234929159139
Trained batch 103 in epoch 1, gen_loss = 0.47508312138513875, disc_loss = 0.08705023526608084
Trained batch 104 in epoch 1, gen_loss = 0.47394387558812184, disc_loss = 0.08670413743349768
Trained batch 105 in epoch 1, gen_loss = 0.4767611505428575, disc_loss = 0.08636127704895048
Trained batch 106 in epoch 1, gen_loss = 0.4774985119143379, disc_loss = 0.08571412791193367
Trained batch 107 in epoch 1, gen_loss = 0.47642372776236797, disc_loss = 0.08538096964669724
Trained batch 108 in epoch 1, gen_loss = 0.4758543175978398, disc_loss = 0.08503754034535874
Trained batch 109 in epoch 1, gen_loss = 0.47898235111074017, disc_loss = 0.08472355984320695
Trained batch 110 in epoch 1, gen_loss = 0.48035201410184036, disc_loss = 0.08407385668272639
Trained batch 111 in epoch 1, gen_loss = 0.47903392470574807, disc_loss = 0.08398078429412895
Trained batch 112 in epoch 1, gen_loss = 0.48175846376514014, disc_loss = 0.0839093204307477
Trained batch 113 in epoch 1, gen_loss = 0.48188337507216555, disc_loss = 0.0834716608862213
Trained batch 114 in epoch 1, gen_loss = 0.48142514416705007, disc_loss = 0.08311402983153644
Trained batch 115 in epoch 1, gen_loss = 0.48108260108736056, disc_loss = 0.08264926690126545
Trained batch 116 in epoch 1, gen_loss = 0.4826864858086293, disc_loss = 0.08277755871446979
Trained batch 117 in epoch 1, gen_loss = 0.4800725943582543, disc_loss = 0.08356352981527225
Trained batch 118 in epoch 1, gen_loss = 0.47958777988908674, disc_loss = 0.08341279028750517
Trained batch 119 in epoch 1, gen_loss = 0.48162036246309675, disc_loss = 0.08386966739005099
Trained batch 120 in epoch 1, gen_loss = 0.47871426579134524, disc_loss = 0.0852809085718487
Trained batch 121 in epoch 1, gen_loss = 0.47769820513051064, disc_loss = 0.08521663670076943
Trained batch 122 in epoch 1, gen_loss = 0.48006820018456237, disc_loss = 0.08584620377306289
Trained batch 123 in epoch 1, gen_loss = 0.48036907487098246, disc_loss = 0.08543015485479226
Trained batch 124 in epoch 1, gen_loss = 0.47862279957532883, disc_loss = 0.08570617339760066
Trained batch 125 in epoch 1, gen_loss = 0.47680460951394504, disc_loss = 0.08582102487395916
Trained batch 126 in epoch 1, gen_loss = 0.4797700715698595, disc_loss = 0.086962094376465
Trained batch 127 in epoch 1, gen_loss = 0.47957906377268955, disc_loss = 0.08657019580277847
Trained batch 128 in epoch 1, gen_loss = 0.47897311022808386, disc_loss = 0.08627278765649066
Trained batch 129 in epoch 1, gen_loss = 0.48016800760076594, disc_loss = 0.08584708910292158
Trained batch 130 in epoch 1, gen_loss = 0.481336651128212, disc_loss = 0.08530361055332514
Trained batch 131 in epoch 1, gen_loss = 0.48148404169037484, disc_loss = 0.08479077307592062
Trained batch 132 in epoch 1, gen_loss = 0.4815902518934773, disc_loss = 0.08429398245521282
Trained batch 133 in epoch 1, gen_loss = 0.48181000146180836, disc_loss = 0.08378792137825
Trained batch 134 in epoch 1, gen_loss = 0.48152083881475305, disc_loss = 0.08338568483099894
Trained batch 135 in epoch 1, gen_loss = 0.4824635410023963, disc_loss = 0.08301871028208338
Trained batch 136 in epoch 1, gen_loss = 0.48128073401477217, disc_loss = 0.08290321683769461
Trained batch 137 in epoch 1, gen_loss = 0.48288141207202623, disc_loss = 0.08255285126548531
Trained batch 138 in epoch 1, gen_loss = 0.482941998369831, disc_loss = 0.08215162748296698
Trained batch 139 in epoch 1, gen_loss = 0.48102744184434415, disc_loss = 0.08255697159495737
Trained batch 140 in epoch 1, gen_loss = 0.4831818943011, disc_loss = 0.08441275918975155
Trained batch 141 in epoch 1, gen_loss = 0.4824966429929498, disc_loss = 0.08420477133952606
Trained batch 142 in epoch 1, gen_loss = 0.48079636646109025, disc_loss = 0.0843481095637996
Trained batch 143 in epoch 1, gen_loss = 0.48043892692981494, disc_loss = 0.08427430765004829
Trained batch 144 in epoch 1, gen_loss = 0.47964545709305795, disc_loss = 0.08407138514749962
Trained batch 145 in epoch 1, gen_loss = 0.47934498561367594, disc_loss = 0.08376652452048577
Trained batch 146 in epoch 1, gen_loss = 0.47777651316251885, disc_loss = 0.08396719792084832
Trained batch 147 in epoch 1, gen_loss = 0.4781661778185013, disc_loss = 0.08400159269395108
Trained batch 148 in epoch 1, gen_loss = 0.47864469940830395, disc_loss = 0.08361272967026738
Trained batch 149 in epoch 1, gen_loss = 0.47732655361294746, disc_loss = 0.08367305574938655
Trained batch 150 in epoch 1, gen_loss = 0.4776327041107298, disc_loss = 0.08344610240803846
Trained batch 151 in epoch 1, gen_loss = 0.477709855051025, disc_loss = 0.0831456154548122
Trained batch 152 in epoch 1, gen_loss = 0.4796892811172928, disc_loss = 0.08289535171382763
Trained batch 153 in epoch 1, gen_loss = 0.47862847415464266, disc_loss = 0.08279915471476587
Trained batch 154 in epoch 1, gen_loss = 0.47940211656593507, disc_loss = 0.08243489597713755
Trained batch 155 in epoch 1, gen_loss = 0.4794734614686324, disc_loss = 0.08208631543227686
Trained batch 156 in epoch 1, gen_loss = 0.4795914994208676, disc_loss = 0.08164974471115193
Trained batch 157 in epoch 1, gen_loss = 0.4789103721798975, disc_loss = 0.08141280166639746
Trained batch 158 in epoch 1, gen_loss = 0.4796013647936425, disc_loss = 0.08137054046112224
Trained batch 159 in epoch 1, gen_loss = 0.47915773461572825, disc_loss = 0.0811325759452302
Trained batch 160 in epoch 1, gen_loss = 0.47999320188479394, disc_loss = 0.08076820229266926
Trained batch 161 in epoch 1, gen_loss = 0.47950381275128434, disc_loss = 0.08073963126581576
Trained batch 162 in epoch 1, gen_loss = 0.47753401909686305, disc_loss = 0.0815462341440693
Trained batch 163 in epoch 1, gen_loss = 0.479571394758617, disc_loss = 0.08391533731255771
Trained batch 164 in epoch 1, gen_loss = 0.4787850054376053, disc_loss = 0.08379519178221623
Trained batch 165 in epoch 1, gen_loss = 0.47766075575028555, disc_loss = 0.08409591551578369
Trained batch 166 in epoch 1, gen_loss = 0.47759027016198563, disc_loss = 0.0849930913784279
Trained batch 167 in epoch 1, gen_loss = 0.4755716717225455, disc_loss = 0.08592794714162924
Trained batch 168 in epoch 1, gen_loss = 0.47606639074679663, disc_loss = 0.08665277436926697
Trained batch 169 in epoch 1, gen_loss = 0.4751917777254301, disc_loss = 0.08696466801030671
Trained batch 170 in epoch 1, gen_loss = 0.47367401678136917, disc_loss = 0.08753590009649072
Trained batch 171 in epoch 1, gen_loss = 0.472716766084696, disc_loss = 0.08797107015866353
Trained batch 172 in epoch 1, gen_loss = 0.47175950987662885, disc_loss = 0.08826656452773106
Trained batch 173 in epoch 1, gen_loss = 0.4709967063504389, disc_loss = 0.08827648708468368
Trained batch 174 in epoch 1, gen_loss = 0.47081074054752076, disc_loss = 0.08810928306941475
Trained batch 175 in epoch 1, gen_loss = 0.4702936099757525, disc_loss = 0.08786113967124204
Trained batch 176 in epoch 1, gen_loss = 0.4694503790325364, disc_loss = 0.08774717821934297
Trained batch 177 in epoch 1, gen_loss = 0.4713033634039123, disc_loss = 0.08831073097319583
Trained batch 178 in epoch 1, gen_loss = 0.4699909873931102, disc_loss = 0.08850728142382212
Trained batch 179 in epoch 1, gen_loss = 0.4687472687413295, disc_loss = 0.08868717634533015
Trained batch 180 in epoch 1, gen_loss = 0.4701302946848764, disc_loss = 0.089879527610845
Trained batch 181 in epoch 1, gen_loss = 0.4696770126593637, disc_loss = 0.08966111832369979
Trained batch 182 in epoch 1, gen_loss = 0.4679547425746266, disc_loss = 0.09036160556121113
Trained batch 183 in epoch 1, gen_loss = 0.4674860258060305, disc_loss = 0.09044947623497927
Trained batch 184 in epoch 1, gen_loss = 0.46709813423253393, disc_loss = 0.09062321067762535
Trained batch 185 in epoch 1, gen_loss = 0.46609991784858446, disc_loss = 0.09061994334001855
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 0.4852984547615051, disc_loss = 0.052507251501083374
Trained batch 1 in epoch 2, gen_loss = 0.4152912497520447, disc_loss = 0.05671442113816738
Trained batch 2 in epoch 2, gen_loss = 0.40714458624521893, disc_loss = 0.05313339208563169
Trained batch 3 in epoch 2, gen_loss = 0.455569326877594, disc_loss = 0.04842887632548809
Trained batch 4 in epoch 2, gen_loss = 0.4528336524963379, disc_loss = 0.04372927993535995
Trained batch 5 in epoch 2, gen_loss = 0.4416336119174957, disc_loss = 0.043292649711171784
Trained batch 6 in epoch 2, gen_loss = 0.46733473028455463, disc_loss = 0.04325044900178909
Trained batch 7 in epoch 2, gen_loss = 0.45230767503380775, disc_loss = 0.04587853793054819
Trained batch 8 in epoch 2, gen_loss = 0.45190727710723877, disc_loss = 0.04488732872737779
Trained batch 9 in epoch 2, gen_loss = 0.4628859281539917, disc_loss = 0.04878926910459995
Trained batch 10 in epoch 2, gen_loss = 0.4350182779810645, disc_loss = 0.06506837396459146
Trained batch 11 in epoch 2, gen_loss = 0.46270009751121205, disc_loss = 0.07540793996304274
Trained batch 12 in epoch 2, gen_loss = 0.4559295097222695, disc_loss = 0.07625900237606122
Trained batch 13 in epoch 2, gen_loss = 0.48182065252746853, disc_loss = 0.07718952665371555
Trained batch 14 in epoch 2, gen_loss = 0.497398778796196, disc_loss = 0.07413991664846738
Trained batch 15 in epoch 2, gen_loss = 0.5012799622491002, disc_loss = 0.07179194898344576
Trained batch 16 in epoch 2, gen_loss = 0.5014565315316705, disc_loss = 0.06949297448291498
Trained batch 17 in epoch 2, gen_loss = 0.50044906222158, disc_loss = 0.06677842554118898
Trained batch 18 in epoch 2, gen_loss = 0.4989999979734421, disc_loss = 0.06445481951691602
Trained batch 19 in epoch 2, gen_loss = 0.5098902799189091, disc_loss = 0.06259823953732849
Trained batch 20 in epoch 2, gen_loss = 0.5124653755199342, disc_loss = 0.060185338547896775
Trained batch 21 in epoch 2, gen_loss = 0.5060641582716595, disc_loss = 0.059206745460290804
Trained batch 22 in epoch 2, gen_loss = 0.5063282257836798, disc_loss = 0.057356499014017376
Trained batch 23 in epoch 2, gen_loss = 0.5066037854800621, disc_loss = 0.05611851923943808
Trained batch 24 in epoch 2, gen_loss = 0.5037362891435623, disc_loss = 0.05480148438364267
Trained batch 25 in epoch 2, gen_loss = 0.5130180080349629, disc_loss = 0.05378344185793629
Trained batch 26 in epoch 2, gen_loss = 0.5171190218793021, disc_loss = 0.05229373283132359
Trained batch 27 in epoch 2, gen_loss = 0.5137592740356922, disc_loss = 0.051758296721215756
Trained batch 28 in epoch 2, gen_loss = 0.5146417879852755, disc_loss = 0.05034812462740931
Trained batch 29 in epoch 2, gen_loss = 0.5223183805743853, disc_loss = 0.04982895664870739
Trained batch 30 in epoch 2, gen_loss = 0.5218088583600137, disc_loss = 0.04870455387619234
Trained batch 31 in epoch 2, gen_loss = 0.5262931953184307, disc_loss = 0.047484822338446975
Trained batch 32 in epoch 2, gen_loss = 0.522472317923199, disc_loss = 0.0471947245074041
Trained batch 33 in epoch 2, gen_loss = 0.5269988578032044, disc_loss = 0.046243243795983935
Trained batch 34 in epoch 2, gen_loss = 0.5281764486006328, disc_loss = 0.045198443079633374
Trained batch 35 in epoch 2, gen_loss = 0.5258641669319736, disc_loss = 0.04446124696793655
Trained batch 36 in epoch 2, gen_loss = 0.5279576951587522, disc_loss = 0.04368345285891681
Trained batch 37 in epoch 2, gen_loss = 0.5264234131104067, disc_loss = 0.043017744307259194
Trained batch 38 in epoch 2, gen_loss = 0.5282099900337366, disc_loss = 0.042553350783120364
Trained batch 39 in epoch 2, gen_loss = 0.5250152569264174, disc_loss = 0.04225748113822192
Trained batch 40 in epoch 2, gen_loss = 0.5287709857632474, disc_loss = 0.04165478993388938
Trained batch 41 in epoch 2, gen_loss = 0.52573659909623, disc_loss = 0.041347825345361515
Trained batch 42 in epoch 2, gen_loss = 0.5238146369540414, disc_loss = 0.041171498834913556
Trained batch 43 in epoch 2, gen_loss = 0.5249517563391816, disc_loss = 0.04162214482626454
Trained batch 44 in epoch 2, gen_loss = 0.5274163355429967, disc_loss = 0.04116314635094669
Trained batch 45 in epoch 2, gen_loss = 0.5275952741503716, disc_loss = 0.0406719616452313
Trained batch 46 in epoch 2, gen_loss = 0.528087207928617, disc_loss = 0.04006912220427965
Trained batch 47 in epoch 2, gen_loss = 0.5259204615528384, disc_loss = 0.0398399427261514
Trained batch 48 in epoch 2, gen_loss = 0.5231924692586977, disc_loss = 0.03983825713167993
Trained batch 49 in epoch 2, gen_loss = 0.529590108692646, disc_loss = 0.04058350482955575
Trained batch 50 in epoch 2, gen_loss = 0.527101858865981, disc_loss = 0.040450407392984514
Trained batch 51 in epoch 2, gen_loss = 0.5257046254208455, disc_loss = 0.04023861840295677
Trained batch 52 in epoch 2, gen_loss = 0.5313324835502876, disc_loss = 0.040547500926790374
Trained batch 53 in epoch 2, gen_loss = 0.5341233497968426, disc_loss = 0.04022969014045817
Trained batch 54 in epoch 2, gen_loss = 0.5340814674442464, disc_loss = 0.03979223842986605
Trained batch 55 in epoch 2, gen_loss = 0.5309110887880836, disc_loss = 0.03994072080656354
Trained batch 56 in epoch 2, gen_loss = 0.5340902980482369, disc_loss = 0.04032526438108139
Trained batch 57 in epoch 2, gen_loss = 0.5347199766286488, disc_loss = 0.039749705601997413
Trained batch 58 in epoch 2, gen_loss = 0.5343623694221852, disc_loss = 0.03927948799426273
Trained batch 59 in epoch 2, gen_loss = 0.533270912617445, disc_loss = 0.03887119558639825
Trained batch 60 in epoch 2, gen_loss = 0.536171204975394, disc_loss = 0.03848164795791028
Trained batch 61 in epoch 2, gen_loss = 0.5355670593919293, disc_loss = 0.03801723153540684
Trained batch 62 in epoch 2, gen_loss = 0.5353815326141933, disc_loss = 0.03760004042100812
Trained batch 63 in epoch 2, gen_loss = 0.5337516206782311, disc_loss = 0.03731897259422112
Trained batch 64 in epoch 2, gen_loss = 0.5378167021733063, disc_loss = 0.0382170714581242
Trained batch 65 in epoch 2, gen_loss = 0.5351918012355313, disc_loss = 0.03832634647066394
Trained batch 66 in epoch 2, gen_loss = 0.5356572908696844, disc_loss = 0.037911898095105125
Trained batch 67 in epoch 2, gen_loss = 0.5363022612736505, disc_loss = 0.0374699999605689
Trained batch 68 in epoch 2, gen_loss = 0.5342511407275131, disc_loss = 0.037399190909944584
Trained batch 69 in epoch 2, gen_loss = 0.5354235838566508, disc_loss = 0.03707291687439595
Trained batch 70 in epoch 2, gen_loss = 0.5403593285402781, disc_loss = 0.036953667427977205
Trained batch 71 in epoch 2, gen_loss = 0.5449278315322267, disc_loss = 0.03671221741630385
Trained batch 72 in epoch 2, gen_loss = 0.546630350081888, disc_loss = 0.03631775853007215
Trained batch 73 in epoch 2, gen_loss = 0.5474319049232715, disc_loss = 0.035982834741573884
Trained batch 74 in epoch 2, gen_loss = 0.5481627808014552, disc_loss = 0.03565309058874846
Trained batch 75 in epoch 2, gen_loss = 0.5489059539609834, disc_loss = 0.035278919777881945
Trained batch 76 in epoch 2, gen_loss = 0.5496362457414726, disc_loss = 0.034909852719926214
Trained batch 77 in epoch 2, gen_loss = 0.5501214351791602, disc_loss = 0.03459417772216675
Trained batch 78 in epoch 2, gen_loss = 0.5501083861800689, disc_loss = 0.034255900149103964
Trained batch 79 in epoch 2, gen_loss = 0.5481179701164365, disc_loss = 0.03422413878142834
Trained batch 80 in epoch 2, gen_loss = 0.5520402842465743, disc_loss = 0.03444193542739491
Trained batch 81 in epoch 2, gen_loss = 0.5545427684740323, disc_loss = 0.03417595852984161
Trained batch 82 in epoch 2, gen_loss = 0.5556388247803034, disc_loss = 0.033858956095863535
Trained batch 83 in epoch 2, gen_loss = 0.5560530149156139, disc_loss = 0.03353332807975156
Trained batch 84 in epoch 2, gen_loss = 0.555494848594946, disc_loss = 0.033281619090806035
Trained batch 85 in epoch 2, gen_loss = 0.559282754223014, disc_loss = 0.03297336639424916
Trained batch 86 in epoch 2, gen_loss = 0.5633169071770262, disc_loss = 0.032714626072081684
Trained batch 87 in epoch 2, gen_loss = 0.5669619591737335, disc_loss = 0.03241063118383119
Trained batch 88 in epoch 2, gen_loss = 0.5700132125214245, disc_loss = 0.03210025753177116
Trained batch 89 in epoch 2, gen_loss = 0.5721981341640154, disc_loss = 0.03182855217924548
Trained batch 90 in epoch 2, gen_loss = 0.5733957816283781, disc_loss = 0.031549707817548255
Trained batch 91 in epoch 2, gen_loss = 0.5738877241054307, disc_loss = 0.0312615375733003
Trained batch 92 in epoch 2, gen_loss = 0.5742791918336704, disc_loss = 0.031001318651702133
Trained batch 93 in epoch 2, gen_loss = 0.5746386870741844, disc_loss = 0.030719357795339634
Trained batch 94 in epoch 2, gen_loss = 0.5752084407367204, disc_loss = 0.030444890334221878
Trained batch 95 in epoch 2, gen_loss = 0.575554266727219, disc_loss = 0.030169496560120024
Trained batch 96 in epoch 2, gen_loss = 0.5758230103967116, disc_loss = 0.029900913558823548
Trained batch 97 in epoch 2, gen_loss = 0.575907731086624, disc_loss = 0.029656532420111553
Trained batch 98 in epoch 2, gen_loss = 0.5763935363954968, disc_loss = 0.029402303006123714
Trained batch 99 in epoch 2, gen_loss = 0.5763225008547306, disc_loss = 0.02916025526355952
Trained batch 100 in epoch 2, gen_loss = 0.5753732395939307, disc_loss = 0.028975371110004068
Trained batch 101 in epoch 2, gen_loss = 0.5762467847443095, disc_loss = 0.02877349636115718
Trained batch 102 in epoch 2, gen_loss = 0.5765209471427121, disc_loss = 0.02854007983001546
Trained batch 103 in epoch 2, gen_loss = 0.5760870795123852, disc_loss = 0.0283180933060626
Trained batch 104 in epoch 2, gen_loss = 0.5743829334066027, disc_loss = 0.028284127447044567
Trained batch 105 in epoch 2, gen_loss = 0.5748572966681337, disc_loss = 0.028187201889934687
Trained batch 106 in epoch 2, gen_loss = 0.5751836092394089, disc_loss = 0.028000917664302565
Trained batch 107 in epoch 2, gen_loss = 0.5750596273552488, disc_loss = 0.027797695344176004
Trained batch 108 in epoch 2, gen_loss = 0.5725000294250085, disc_loss = 0.028139544761987455
Trained batch 109 in epoch 2, gen_loss = 0.5740758209065957, disc_loss = 0.02995333362540061
Trained batch 110 in epoch 2, gen_loss = 0.5744868217556326, disc_loss = 0.029788072590154032
Trained batch 111 in epoch 2, gen_loss = 0.5746255002117583, disc_loss = 0.029612009521640306
Trained batch 112 in epoch 2, gen_loss = 0.5746539769183218, disc_loss = 0.02941880976385643
Trained batch 113 in epoch 2, gen_loss = 0.5743587614412893, disc_loss = 0.0292317340142306
Trained batch 114 in epoch 2, gen_loss = 0.5719943327748257, disc_loss = 0.0295635545666775
Trained batch 115 in epoch 2, gen_loss = 0.5731132052324969, disc_loss = 0.029799453492661745
Trained batch 116 in epoch 2, gen_loss = 0.5731639455781024, disc_loss = 0.02963867471115584
Trained batch 117 in epoch 2, gen_loss = 0.5735195002565949, disc_loss = 0.029457750450030476
Trained batch 118 in epoch 2, gen_loss = 0.5734041534802493, disc_loss = 0.02929731734300486
Trained batch 119 in epoch 2, gen_loss = 0.5729161790261666, disc_loss = 0.029125744729147602
Trained batch 120 in epoch 2, gen_loss = 0.5712893510406668, disc_loss = 0.029152158128236197
Trained batch 121 in epoch 2, gen_loss = 0.5714961562733181, disc_loss = 0.029004295574134736
Trained batch 122 in epoch 2, gen_loss = 0.572760498014892, disc_loss = 0.029184797933946054
Trained batch 123 in epoch 2, gen_loss = 0.5732575591293073, disc_loss = 0.02901104584171046
Trained batch 124 in epoch 2, gen_loss = 0.5727063311338425, disc_loss = 0.02890506576374173
Trained batch 125 in epoch 2, gen_loss = 0.5716948148513598, disc_loss = 0.028862716545099542
Trained batch 126 in epoch 2, gen_loss = 0.5720388742647772, disc_loss = 0.02868694986224057
Trained batch 127 in epoch 2, gen_loss = 0.5709436597535387, disc_loss = 0.028617253057745984
Trained batch 128 in epoch 2, gen_loss = 0.5723392239143682, disc_loss = 0.0285584868668297
Trained batch 129 in epoch 2, gen_loss = 0.5733139685713328, disc_loss = 0.028405262569252115
Trained batch 130 in epoch 2, gen_loss = 0.5738872381794544, disc_loss = 0.028228279092981843
Trained batch 131 in epoch 2, gen_loss = 0.5739116805295149, disc_loss = 0.02806364253840663
Trained batch 132 in epoch 2, gen_loss = 0.5739421370558273, disc_loss = 0.027893075460386007
Trained batch 133 in epoch 2, gen_loss = 0.5740009262713034, disc_loss = 0.027837597535672918
Trained batch 134 in epoch 2, gen_loss = 0.5738820567175195, disc_loss = 0.02769971090472407
Trained batch 135 in epoch 2, gen_loss = 0.5737485404619399, disc_loss = 0.02755623114267912
Trained batch 136 in epoch 2, gen_loss = 0.5736922822947049, disc_loss = 0.027395494159882086
Trained batch 137 in epoch 2, gen_loss = 0.5734825074888658, disc_loss = 0.02724427725120947
Trained batch 138 in epoch 2, gen_loss = 0.5731549791509299, disc_loss = 0.027097610750054714
Trained batch 139 in epoch 2, gen_loss = 0.5706161478800433, disc_loss = 0.027711921617654817
Trained batch 140 in epoch 2, gen_loss = 0.5722803106756075, disc_loss = 0.029310917501595427
Trained batch 141 in epoch 2, gen_loss = 0.5724720200392562, disc_loss = 0.029192475759437387
Trained batch 142 in epoch 2, gen_loss = 0.5711401818723946, disc_loss = 0.02921851062691295
Trained batch 143 in epoch 2, gen_loss = 0.5691210622381833, disc_loss = 0.02958916924479935
Trained batch 144 in epoch 2, gen_loss = 0.5697301456640507, disc_loss = 0.029634271844707686
Trained batch 145 in epoch 2, gen_loss = 0.5701157661945853, disc_loss = 0.02951900632924413
Trained batch 146 in epoch 2, gen_loss = 0.5699537395417285, disc_loss = 0.02935902717947757
Trained batch 147 in epoch 2, gen_loss = 0.5694540383646617, disc_loss = 0.029240730954837556
Trained batch 148 in epoch 2, gen_loss = 0.5687565036468057, disc_loss = 0.029163016312624385
Trained batch 149 in epoch 2, gen_loss = 0.5680500935514768, disc_loss = 0.029079145609090726
Trained batch 150 in epoch 2, gen_loss = 0.5687767676762397, disc_loss = 0.028998216632630257
Trained batch 151 in epoch 2, gen_loss = 0.5691182745718643, disc_loss = 0.028854173871590512
Trained batch 152 in epoch 2, gen_loss = 0.5690013293931687, disc_loss = 0.028715711300036098
Trained batch 153 in epoch 2, gen_loss = 0.568456642716736, disc_loss = 0.02860688947310502
Trained batch 154 in epoch 2, gen_loss = 0.5679429997359553, disc_loss = 0.028484706214118388
Trained batch 155 in epoch 2, gen_loss = 0.5683762611678014, disc_loss = 0.028379342954558056
Trained batch 156 in epoch 2, gen_loss = 0.567948513824469, disc_loss = 0.028273151967982958
Trained batch 157 in epoch 2, gen_loss = 0.5668628307271607, disc_loss = 0.028257921827320433
Trained batch 158 in epoch 2, gen_loss = 0.5676894057659233, disc_loss = 0.02861227593589691
Trained batch 159 in epoch 2, gen_loss = 0.565136665571481, disc_loss = 0.029846027231542394
Trained batch 160 in epoch 2, gen_loss = 0.5655231236115746, disc_loss = 0.030634248588720093
Trained batch 161 in epoch 2, gen_loss = 0.5634862352852468, disc_loss = 0.03157558689399818
Trained batch 162 in epoch 2, gen_loss = 0.561945891727699, disc_loss = 0.031864972585138
Trained batch 163 in epoch 2, gen_loss = 0.5620505031107402, disc_loss = 0.032686677937418585
Trained batch 164 in epoch 2, gen_loss = 0.5602511954126936, disc_loss = 0.03308871259179079
Trained batch 165 in epoch 2, gen_loss = 0.5589341398283659, disc_loss = 0.033299854647996556
Trained batch 166 in epoch 2, gen_loss = 0.5588895716888462, disc_loss = 0.03373000580639004
Trained batch 167 in epoch 2, gen_loss = 0.5586005710952339, disc_loss = 0.0336032158672987
Trained batch 168 in epoch 2, gen_loss = 0.5560249688886326, disc_loss = 0.03490459073621493
Trained batch 169 in epoch 2, gen_loss = 0.5571757385835928, disc_loss = 0.03626455963753602
Trained batch 170 in epoch 2, gen_loss = 0.5549684085866862, disc_loss = 0.03706997285504439
Trained batch 171 in epoch 2, gen_loss = 0.5536067689400773, disc_loss = 0.0377087549003231
Trained batch 172 in epoch 2, gen_loss = 0.5524037227982042, disc_loss = 0.03851166790663507
Trained batch 173 in epoch 2, gen_loss = 0.5510040681766367, disc_loss = 0.03956768654244042
Trained batch 174 in epoch 2, gen_loss = 0.5503580186196736, disc_loss = 0.04051551062081541
Trained batch 175 in epoch 2, gen_loss = 0.5508112732151692, disc_loss = 0.04107574577739632
Trained batch 176 in epoch 2, gen_loss = 0.5487082497884999, disc_loss = 0.04192848108961421
Trained batch 177 in epoch 2, gen_loss = 0.5475717372773738, disc_loss = 0.042178540720782254
Trained batch 178 in epoch 2, gen_loss = 0.5479334754317833, disc_loss = 0.04250382175200811
Trained batch 179 in epoch 2, gen_loss = 0.54608510384957, disc_loss = 0.04307373816975289
Trained batch 180 in epoch 2, gen_loss = 0.545846931018882, disc_loss = 0.043256687453191583
Trained batch 181 in epoch 2, gen_loss = 0.5445126686449889, disc_loss = 0.043472740113489575
Trained batch 182 in epoch 2, gen_loss = 0.5439256454100374, disc_loss = 0.04357676095039141
Trained batch 183 in epoch 2, gen_loss = 0.543751373725093, disc_loss = 0.04351976059336701
Trained batch 184 in epoch 2, gen_loss = 0.5423196001632794, disc_loss = 0.04370853295801459
Trained batch 185 in epoch 2, gen_loss = 0.5424501218142048, disc_loss = 0.043624931245401344
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 0.47321122884750366, disc_loss = 0.05838208645582199
Trained batch 1 in epoch 3, gen_loss = 0.43097640573978424, disc_loss = 0.04770342633128166
Trained batch 2 in epoch 3, gen_loss = 0.46778445442517597, disc_loss = 0.035963244115312896
Trained batch 3 in epoch 3, gen_loss = 0.5408139750361443, disc_loss = 0.032611955888569355
Trained batch 4 in epoch 3, gen_loss = 0.5679379642009735, disc_loss = 0.02848591636866331
Trained batch 5 in epoch 3, gen_loss = 0.5725234001874924, disc_loss = 0.024938703204194706
Trained batch 6 in epoch 3, gen_loss = 0.5695705371243613, disc_loss = 0.022748574082340513
Trained batch 7 in epoch 3, gen_loss = 0.5682898424565792, disc_loss = 0.0206521995132789
Trained batch 8 in epoch 3, gen_loss = 0.569154206249449, disc_loss = 0.01889715835245119
Trained batch 9 in epoch 3, gen_loss = 0.5682673960924148, disc_loss = 0.018121039727702737
Trained batch 10 in epoch 3, gen_loss = 0.5659034170887687, disc_loss = 0.016975444021888754
Trained batch 11 in epoch 3, gen_loss = 0.5633070891102155, disc_loss = 0.015993697607579332
Trained batch 12 in epoch 3, gen_loss = 0.5616459502623632, disc_loss = 0.01510010828049137
Trained batch 13 in epoch 3, gen_loss = 0.5603206562144416, disc_loss = 0.01437512123292046
Trained batch 14 in epoch 3, gen_loss = 0.5606410523255666, disc_loss = 0.014358985889703035
Trained batch 15 in epoch 3, gen_loss = 0.558746675029397, disc_loss = 0.013833732198690996
Trained batch 16 in epoch 3, gen_loss = 0.5569635086199817, disc_loss = 0.013400161721031456
Trained batch 17 in epoch 3, gen_loss = 0.5566243976354599, disc_loss = 0.012910324536884824
Trained batch 18 in epoch 3, gen_loss = 0.556643795025976, disc_loss = 0.012489076042057652
Trained batch 19 in epoch 3, gen_loss = 0.5563493207097053, disc_loss = 0.012138500506989659
Trained batch 20 in epoch 3, gen_loss = 0.5549931710674649, disc_loss = 0.011981283780187368
Trained batch 21 in epoch 3, gen_loss = 0.5526380958882245, disc_loss = 0.011814330175349658
Trained batch 22 in epoch 3, gen_loss = 0.5526633767978005, disc_loss = 0.011542552434231924
Trained batch 23 in epoch 3, gen_loss = 0.55701336885492, disc_loss = 0.011434538095879057
Trained batch 24 in epoch 3, gen_loss = 0.5564806568622589, disc_loss = 0.011235883701592684
Trained batch 25 in epoch 3, gen_loss = 0.5536722712791883, disc_loss = 0.011183215896240793
Trained batch 26 in epoch 3, gen_loss = 0.5529748985060939, disc_loss = 0.011084343772381544
Trained batch 27 in epoch 3, gen_loss = 0.5598196121198791, disc_loss = 0.011583674383083624
Trained batch 28 in epoch 3, gen_loss = 0.5624461184287893, disc_loss = 0.011391542450492752
Trained batch 29 in epoch 3, gen_loss = 0.5621879269679387, disc_loss = 0.011356241178388397
Trained batch 30 in epoch 3, gen_loss = 0.5614571754009493, disc_loss = 0.011250497457841712
Trained batch 31 in epoch 3, gen_loss = 0.5623400500044227, disc_loss = 0.01104371047404129
Trained batch 32 in epoch 3, gen_loss = 0.5632660488287607, disc_loss = 0.010838541950127392
Trained batch 33 in epoch 3, gen_loss = 0.5621434388791814, disc_loss = 0.010730884147479254
Trained batch 34 in epoch 3, gen_loss = 0.5608224741050175, disc_loss = 0.010674446209200791
Trained batch 35 in epoch 3, gen_loss = 0.5614022157258458, disc_loss = 0.010555610474612977
Trained batch 36 in epoch 3, gen_loss = 0.5604521897999016, disc_loss = 0.01045794423820602
Trained batch 37 in epoch 3, gen_loss = 0.5622974940036473, disc_loss = 0.010692654385868656
Trained batch 38 in epoch 3, gen_loss = 0.5588288490588849, disc_loss = 0.0110771642305339
Trained batch 39 in epoch 3, gen_loss = 0.5632970809936524, disc_loss = 0.011270690301898867
Trained batch 40 in epoch 3, gen_loss = 0.5650516225070488, disc_loss = 0.011149085819630361
Trained batch 41 in epoch 3, gen_loss = 0.5633783702339444, disc_loss = 0.011156103584826702
Trained batch 42 in epoch 3, gen_loss = 0.5641413670639659, disc_loss = 0.0110723796560494
Trained batch 43 in epoch 3, gen_loss = 0.5647224465554411, disc_loss = 0.010924687069332735
Trained batch 44 in epoch 3, gen_loss = 0.5639855206012726, disc_loss = 0.010855882252669997
Trained batch 45 in epoch 3, gen_loss = 0.5653714686632156, disc_loss = 0.01077541224051105
Trained batch 46 in epoch 3, gen_loss = 0.5644943707800926, disc_loss = 0.01067736109797942
Trained batch 47 in epoch 3, gen_loss = 0.5633442817876736, disc_loss = 0.010671241005184129
Trained batch 48 in epoch 3, gen_loss = 0.5682168876638218, disc_loss = 0.010894849772888179
Trained batch 49 in epoch 3, gen_loss = 0.5721987408399581, disc_loss = 0.01087911139242351
Trained batch 50 in epoch 3, gen_loss = 0.5743021982557633, disc_loss = 0.010854540529715665
Trained batch 51 in epoch 3, gen_loss = 0.5753455408490621, disc_loss = 0.010889417214247469
Trained batch 52 in epoch 3, gen_loss = 0.5764281755348422, disc_loss = 0.010762562008820614
Trained batch 53 in epoch 3, gen_loss = 0.5777705527014203, disc_loss = 0.010642009580300914
Trained batch 54 in epoch 3, gen_loss = 0.5787164823575454, disc_loss = 0.01052440269426866
Trained batch 55 in epoch 3, gen_loss = 0.5793592073023319, disc_loss = 0.010457750160380133
Trained batch 56 in epoch 3, gen_loss = 0.5794488803336495, disc_loss = 0.01033886868441314
Trained batch 57 in epoch 3, gen_loss = 0.5792824692767242, disc_loss = 0.010281055146057544
Trained batch 58 in epoch 3, gen_loss = 0.5793144990832119, disc_loss = 0.010251932027670791
Trained batch 59 in epoch 3, gen_loss = 0.5794357056419055, disc_loss = 0.010144310141913592
Trained batch 60 in epoch 3, gen_loss = 0.5795464403316622, disc_loss = 0.010045644025638944
Trained batch 61 in epoch 3, gen_loss = 0.5798368545309189, disc_loss = 0.009946588423073052
Trained batch 62 in epoch 3, gen_loss = 0.580089918677769, disc_loss = 0.00984004109225694
Trained batch 63 in epoch 3, gen_loss = 0.5799809764139354, disc_loss = 0.009734852032124763
Trained batch 64 in epoch 3, gen_loss = 0.57993697982568, disc_loss = 0.009630090180927744
Trained batch 65 in epoch 3, gen_loss = 0.579367690465667, disc_loss = 0.009538046391257509
Trained batch 66 in epoch 3, gen_loss = 0.5794411199306374, disc_loss = 0.00943962499541022
Trained batch 67 in epoch 3, gen_loss = 0.5788007575799438, disc_loss = 0.009356813090990353
Trained batch 68 in epoch 3, gen_loss = 0.5801717340946198, disc_loss = 0.009341049234153352
Trained batch 69 in epoch 3, gen_loss = 0.5805345582110542, disc_loss = 0.009260657586024276
Trained batch 70 in epoch 3, gen_loss = 0.5780884564762384, disc_loss = 0.009429958160363242
Trained batch 71 in epoch 3, gen_loss = 0.5790680183304681, disc_loss = 0.009381738022461327
Trained batch 72 in epoch 3, gen_loss = 0.580447403535451, disc_loss = 0.00933248990802222
Trained batch 73 in epoch 3, gen_loss = 0.5813623795638213, disc_loss = 0.009265340855219276
Trained batch 74 in epoch 3, gen_loss = 0.5816548291842143, disc_loss = 0.009191734272365769
Trained batch 75 in epoch 3, gen_loss = 0.5820351501828745, disc_loss = 0.009116308117211846
Trained batch 76 in epoch 3, gen_loss = 0.58202569128631, disc_loss = 0.009132956157668263
Trained batch 77 in epoch 3, gen_loss = 0.5817452210646409, disc_loss = 0.009075478384963786
Trained batch 78 in epoch 3, gen_loss = 0.5815352110923091, disc_loss = 0.009051705843214936
Trained batch 79 in epoch 3, gen_loss = 0.5816656194627285, disc_loss = 0.008987786367652007
Trained batch 80 in epoch 3, gen_loss = 0.5819423544554063, disc_loss = 0.00891231997858411
Trained batch 81 in epoch 3, gen_loss = 0.5820835029206625, disc_loss = 0.008866805191401666
Trained batch 82 in epoch 3, gen_loss = 0.5785936856844339, disc_loss = 0.009568732517984617
Trained batch 83 in epoch 3, gen_loss = 0.5801489729256857, disc_loss = 0.010367238688992248
Trained batch 84 in epoch 3, gen_loss = 0.5806301663903629, disc_loss = 0.010332438475726282
Trained batch 85 in epoch 3, gen_loss = 0.5801084318826365, disc_loss = 0.010276932523824101
Trained batch 86 in epoch 3, gen_loss = 0.5792023381967654, disc_loss = 0.010240340391281008
Trained batch 87 in epoch 3, gen_loss = 0.5782191231846809, disc_loss = 0.010228550696576183
Trained batch 88 in epoch 3, gen_loss = 0.5767937640795547, disc_loss = 0.010288567324116659
Trained batch 89 in epoch 3, gen_loss = 0.5758258706993526, disc_loss = 0.010284952684823009
Trained batch 90 in epoch 3, gen_loss = 0.5739945294437828, disc_loss = 0.010529006565255778
Trained batch 91 in epoch 3, gen_loss = 0.5770555491680684, disc_loss = 0.011451177045945888
Trained batch 92 in epoch 3, gen_loss = 0.5794751737066495, disc_loss = 0.01142340314684696
Trained batch 93 in epoch 3, gen_loss = 0.5817133635282516, disc_loss = 0.01137743015436733
Trained batch 94 in epoch 3, gen_loss = 0.5831405943945834, disc_loss = 0.011329909247395239
Trained batch 95 in epoch 3, gen_loss = 0.5841015617673596, disc_loss = 0.011267206699509794
Trained batch 96 in epoch 3, gen_loss = 0.5846778673609507, disc_loss = 0.011200758695756038
Trained batch 97 in epoch 3, gen_loss = 0.5852249310332902, disc_loss = 0.011132469163181223
Trained batch 98 in epoch 3, gen_loss = 0.5854131889463675, disc_loss = 0.011060540573765534
Trained batch 99 in epoch 3, gen_loss = 0.5856169238686562, disc_loss = 0.011014102925546467
Trained batch 100 in epoch 3, gen_loss = 0.5851784799948777, disc_loss = 0.010974095853064025
Trained batch 101 in epoch 3, gen_loss = 0.5823756342425066, disc_loss = 0.01153299588180494
Trained batch 102 in epoch 3, gen_loss = 0.5815032763967236, disc_loss = 0.011568370071755162
Trained batch 103 in epoch 3, gen_loss = 0.5836572850552889, disc_loss = 0.012682080971829306
Trained batch 104 in epoch 3, gen_loss = 0.5841941069988977, disc_loss = 0.012674503981889714
Trained batch 105 in epoch 3, gen_loss = 0.5840006749022681, disc_loss = 0.012687384928488787
Trained batch 106 in epoch 3, gen_loss = 0.5838074313702984, disc_loss = 0.01266385260186045
Trained batch 107 in epoch 3, gen_loss = 0.5834494749153102, disc_loss = 0.012647223792521766
Trained batch 108 in epoch 3, gen_loss = 0.5806012167296278, disc_loss = 0.013621516760712096
Trained batch 109 in epoch 3, gen_loss = 0.5822841213508085, disc_loss = 0.013919828015125611
Trained batch 110 in epoch 3, gen_loss = 0.5828864464351723, disc_loss = 0.014145797164691193
Trained batch 111 in epoch 3, gen_loss = 0.5833884182253054, disc_loss = 0.0141426117001434
Trained batch 112 in epoch 3, gen_loss = 0.5831848322290235, disc_loss = 0.014105231497041156
Trained batch 113 in epoch 3, gen_loss = 0.5824504580936933, disc_loss = 0.014089968925538031
Trained batch 114 in epoch 3, gen_loss = 0.5818305764509284, disc_loss = 0.014053310231184182
Trained batch 115 in epoch 3, gen_loss = 0.5779084651891527, disc_loss = 0.016158959960789775
Trained batch 116 in epoch 3, gen_loss = 0.5799021441967059, disc_loss = 0.01701931658988962
Trained batch 117 in epoch 3, gen_loss = 0.5811071402188075, disc_loss = 0.01735871755991573
Trained batch 118 in epoch 3, gen_loss = 0.5783570700583338, disc_loss = 0.018037911445810264
Trained batch 119 in epoch 3, gen_loss = 0.5789281339695056, disc_loss = 0.017963846559481075
Trained batch 120 in epoch 3, gen_loss = 0.5793113084125124, disc_loss = 0.018164480062709612
Trained batch 121 in epoch 3, gen_loss = 0.5792095056567036, disc_loss = 0.01807769106273524
Trained batch 122 in epoch 3, gen_loss = 0.5787567982101828, disc_loss = 0.01801012030885956
Trained batch 123 in epoch 3, gen_loss = 0.5773408442976014, disc_loss = 0.018071688276024594
Trained batch 124 in epoch 3, gen_loss = 0.5774311343431473, disc_loss = 0.017993237853050233
Trained batch 125 in epoch 3, gen_loss = 0.5776111830085043, disc_loss = 0.01792486011981964
Trained batch 126 in epoch 3, gen_loss = 0.5771435514444442, disc_loss = 0.0178418987958626
Trained batch 127 in epoch 3, gen_loss = 0.5779365409398451, disc_loss = 0.017769882553693606
Trained batch 128 in epoch 3, gen_loss = 0.578541289581809, disc_loss = 0.017683549614464358
Trained batch 129 in epoch 3, gen_loss = 0.5786203385545657, disc_loss = 0.017579466100925437
Trained batch 130 in epoch 3, gen_loss = 0.5785021978707714, disc_loss = 0.017477061944295658
Trained batch 131 in epoch 3, gen_loss = 0.5781663205813278, disc_loss = 0.017378214683214373
Trained batch 132 in epoch 3, gen_loss = 0.5776081570333108, disc_loss = 0.017292830560888563
Trained batch 133 in epoch 3, gen_loss = 0.5763068064602453, disc_loss = 0.017314480506439706
Trained batch 134 in epoch 3, gen_loss = 0.5760979448203687, disc_loss = 0.01741221296014609
Trained batch 135 in epoch 3, gen_loss = 0.5768455283387619, disc_loss = 0.017349210889626515
Trained batch 136 in epoch 3, gen_loss = 0.5772701391991037, disc_loss = 0.01726160761322418
Trained batch 137 in epoch 3, gen_loss = 0.5772921022945556, disc_loss = 0.017172654027767156
Trained batch 138 in epoch 3, gen_loss = 0.5771667145782238, disc_loss = 0.01707481953529842
Trained batch 139 in epoch 3, gen_loss = 0.5762698636523315, disc_loss = 0.01704418390623427
Trained batch 140 in epoch 3, gen_loss = 0.5769007382452065, disc_loss = 0.016982348597813265
Trained batch 141 in epoch 3, gen_loss = 0.5773308485956259, disc_loss = 0.01690233086439138
Trained batch 142 in epoch 3, gen_loss = 0.5774060278297304, disc_loss = 0.0168220488846276
Trained batch 143 in epoch 3, gen_loss = 0.5772918229922652, disc_loss = 0.016740075401483208
Trained batch 144 in epoch 3, gen_loss = 0.5771875664077956, disc_loss = 0.01665504290080019
Trained batch 145 in epoch 3, gen_loss = 0.5765540345686756, disc_loss = 0.01659273229737141
Trained batch 146 in epoch 3, gen_loss = 0.576728938692281, disc_loss = 0.01650744450253238
Trained batch 147 in epoch 3, gen_loss = 0.5770571790635586, disc_loss = 0.016431391489301884
Trained batch 148 in epoch 3, gen_loss = 0.5770940151590629, disc_loss = 0.016350096330709205
Trained batch 149 in epoch 3, gen_loss = 0.5771075637141864, disc_loss = 0.016264770302611094
Trained batch 150 in epoch 3, gen_loss = 0.5771192800722375, disc_loss = 0.01617844255227867
Trained batch 151 in epoch 3, gen_loss = 0.5772082683091101, disc_loss = 0.016090527095672626
Trained batch 152 in epoch 3, gen_loss = 0.5773163619968626, disc_loss = 0.016001749511357712
Trained batch 153 in epoch 3, gen_loss = 0.5774062913540122, disc_loss = 0.015914372318158194
Trained batch 154 in epoch 3, gen_loss = 0.5774300401249239, disc_loss = 0.01583418746538941
Trained batch 155 in epoch 3, gen_loss = 0.5774687493267732, disc_loss = 0.015749715270104412
Trained batch 156 in epoch 3, gen_loss = 0.5773074189378957, disc_loss = 0.015670820505648945
Trained batch 157 in epoch 3, gen_loss = 0.5771904511353637, disc_loss = 0.01558928306750906
Trained batch 158 in epoch 3, gen_loss = 0.5771089817555446, disc_loss = 0.015508803102603686
Trained batch 159 in epoch 3, gen_loss = 0.5766840348951519, disc_loss = 0.015444555642898195
Trained batch 160 in epoch 3, gen_loss = 0.576388806567429, disc_loss = 0.015377613585673688
Trained batch 161 in epoch 3, gen_loss = 0.575429675663695, disc_loss = 0.015394483465862311
Trained batch 162 in epoch 3, gen_loss = 0.5760961130170003, disc_loss = 0.015403817770602696
Trained batch 163 in epoch 3, gen_loss = 0.5755169988587135, disc_loss = 0.015384947827153998
Trained batch 164 in epoch 3, gen_loss = 0.575972148234194, disc_loss = 0.015335919710835724
Trained batch 165 in epoch 3, gen_loss = 0.5762388075152075, disc_loss = 0.015300821111795593
Trained batch 166 in epoch 3, gen_loss = 0.5762635274026209, disc_loss = 0.015245115777622619
Trained batch 167 in epoch 3, gen_loss = 0.5761901254632643, disc_loss = 0.015174849352444567
Trained batch 168 in epoch 3, gen_loss = 0.576005954802389, disc_loss = 0.01511228049846267
Trained batch 169 in epoch 3, gen_loss = 0.575984788729864, disc_loss = 0.015042581914595383
Trained batch 170 in epoch 3, gen_loss = 0.5749444551112359, disc_loss = 0.01509250580790665
Trained batch 171 in epoch 3, gen_loss = 0.5752127968467945, disc_loss = 0.015346453114965021
Trained batch 172 in epoch 3, gen_loss = 0.5746860825429762, disc_loss = 0.015355232178443515
Trained batch 173 in epoch 3, gen_loss = 0.5720115025666939, disc_loss = 0.01705241379001574
Trained batch 174 in epoch 3, gen_loss = 0.5715918884107045, disc_loss = 0.017393776903461132
Trained batch 175 in epoch 3, gen_loss = 0.5718550637195056, disc_loss = 0.017991857435183854
Trained batch 176 in epoch 3, gen_loss = 0.5702788005609297, disc_loss = 0.018342108882721617
Trained batch 177 in epoch 3, gen_loss = 0.5712810273418266, disc_loss = 0.01836351956256529
Trained batch 178 in epoch 3, gen_loss = 0.571835096738192, disc_loss = 0.01833624341889342
Trained batch 179 in epoch 3, gen_loss = 0.5717796843085025, disc_loss = 0.018273975090899817
Trained batch 180 in epoch 3, gen_loss = 0.5714015204109539, disc_loss = 0.018222413819478773
Trained batch 181 in epoch 3, gen_loss = 0.5711290388480648, disc_loss = 0.018167593328353878
Trained batch 182 in epoch 3, gen_loss = 0.5709091806835164, disc_loss = 0.0181124799851776
Trained batch 183 in epoch 3, gen_loss = 0.5708902287904335, disc_loss = 0.01804001959238161
Trained batch 184 in epoch 3, gen_loss = 0.5710315676154317, disc_loss = 0.01797092111051284
Trained batch 185 in epoch 3, gen_loss = 0.5711046663183038, disc_loss = 0.017897197627462447
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 0.552269697189331, disc_loss = 0.005010091699659824
Trained batch 1 in epoch 4, gen_loss = 0.5671328604221344, disc_loss = 0.004294245736673474
Trained batch 2 in epoch 4, gen_loss = 0.5591299533843994, disc_loss = 0.004333598384012778
Trained batch 3 in epoch 4, gen_loss = 0.5621797442436218, disc_loss = 0.011142937815748155
Trained batch 4 in epoch 4, gen_loss = 0.5128861963748932, disc_loss = 0.019903003703802824
Trained batch 5 in epoch 4, gen_loss = 0.5324338326851527, disc_loss = 0.01846836064942181
Trained batch 6 in epoch 4, gen_loss = 0.5430364225591932, disc_loss = 0.017411737370171716
Trained batch 7 in epoch 4, gen_loss = 0.553215753287077, disc_loss = 0.016006351506803185
Trained batch 8 in epoch 4, gen_loss = 0.5510333345996009, disc_loss = 0.015039572750942575
Trained batch 9 in epoch 4, gen_loss = 0.5306128680706024, disc_loss = 0.017483271704986692
Trained batch 10 in epoch 4, gen_loss = 0.5422008850357749, disc_loss = 0.022391981741582804
Trained batch 11 in epoch 4, gen_loss = 0.5181465893983841, disc_loss = 0.027448448080879945
Trained batch 12 in epoch 4, gen_loss = 0.5179261473508981, disc_loss = 0.0274537094295598
Trained batch 13 in epoch 4, gen_loss = 0.5286654872553689, disc_loss = 0.0314074294708137
Trained batch 14 in epoch 4, gen_loss = 0.4998922382791837, disc_loss = 0.05203654843692978
Trained batch 15 in epoch 4, gen_loss = 0.4808515883050859, disc_loss = 0.06068148443591781
Trained batch 16 in epoch 4, gen_loss = 0.47237810098073063, disc_loss = 0.06905772211030126
Trained batch 17 in epoch 4, gen_loss = 0.4633505985968643, disc_loss = 0.07467676349915564
Trained batch 18 in epoch 4, gen_loss = 0.45623703497020823, disc_loss = 0.07965114303423386
Trained batch 19 in epoch 4, gen_loss = 0.44462717734277246, disc_loss = 0.0861041939118877
Trained batch 20 in epoch 4, gen_loss = 0.43495608192114604, disc_loss = 0.09162866060311596
Trained batch 21 in epoch 4, gen_loss = 0.4339022660119967, disc_loss = 0.09425238572823053
Trained batch 22 in epoch 4, gen_loss = 0.44500933231219003, disc_loss = 0.09384156846562805
Trained batch 23 in epoch 4, gen_loss = 0.4365346484507124, disc_loss = 0.09505289655256395
Trained batch 24 in epoch 4, gen_loss = 0.43778696566820147, disc_loss = 0.09493264572694898
Trained batch 25 in epoch 4, gen_loss = 0.43162142342099774, disc_loss = 0.09456040038583943
Trained batch 26 in epoch 4, gen_loss = 0.44419395288935415, disc_loss = 0.09719423634103602
Trained batch 27 in epoch 4, gen_loss = 0.448851166293025, disc_loss = 0.09585265949967184
Trained batch 28 in epoch 4, gen_loss = 0.44172503747816744, disc_loss = 0.09910285911233775
Trained batch 29 in epoch 4, gen_loss = 0.4478100431462129, disc_loss = 0.09970257805349926
Trained batch 30 in epoch 4, gen_loss = 0.453513425444403, disc_loss = 0.09785924012201928
Trained batch 31 in epoch 4, gen_loss = 0.44447472714819014, disc_loss = 0.10156013096275274
Trained batch 32 in epoch 4, gen_loss = 0.44460729058041715, disc_loss = 0.10236410052995339
Trained batch 33 in epoch 4, gen_loss = 0.44445523641565265, disc_loss = 0.1007736706695355
Trained batch 34 in epoch 4, gen_loss = 0.4429670753223555, disc_loss = 0.09892254313454032
Trained batch 35 in epoch 4, gen_loss = 0.44151846174564624, disc_loss = 0.09722368710208684
Trained batch 36 in epoch 4, gen_loss = 0.44519582088734655, disc_loss = 0.10085449026696183
Trained batch 37 in epoch 4, gen_loss = 0.4360183432306114, disc_loss = 0.10827512256065874
Trained batch 38 in epoch 4, gen_loss = 0.43025653465436053, disc_loss = 0.11123297345609619
Trained batch 39 in epoch 4, gen_loss = 0.43013319429010155, disc_loss = 0.11439117306144908
Trained batch 40 in epoch 4, gen_loss = 0.42916639240049737, disc_loss = 0.11677926670896208
Trained batch 41 in epoch 4, gen_loss = 0.4247214849151316, disc_loss = 0.11819975611398972
Trained batch 42 in epoch 4, gen_loss = 0.4210644431932028, disc_loss = 0.11912531597366513
Trained batch 43 in epoch 4, gen_loss = 0.4181055004962466, disc_loss = 0.12023331327575514
Trained batch 44 in epoch 4, gen_loss = 0.4155258336000972, disc_loss = 0.1203642355174654
Trained batch 45 in epoch 4, gen_loss = 0.4126897724750249, disc_loss = 0.12076572945300976
Trained batch 46 in epoch 4, gen_loss = 0.41004196617831573, disc_loss = 0.12092423725358033
Trained batch 47 in epoch 4, gen_loss = 0.40736702689900994, disc_loss = 0.12123384886460069
Trained batch 48 in epoch 4, gen_loss = 0.4049535142828007, disc_loss = 0.12132786549817846
Trained batch 49 in epoch 4, gen_loss = 0.4040928141772747, disc_loss = 0.12085826621390879
Trained batch 50 in epoch 4, gen_loss = 0.40214212487141293, disc_loss = 0.12063463164639532
Trained batch 51 in epoch 4, gen_loss = 0.401260945516137, disc_loss = 0.11991407508209634
Trained batch 52 in epoch 4, gen_loss = 0.39951361561158916, disc_loss = 0.11955338478404677
Trained batch 53 in epoch 4, gen_loss = 0.39999178590046036, disc_loss = 0.11925022429096754
Trained batch 54 in epoch 4, gen_loss = 0.39752193133939395, disc_loss = 0.11950221184471792
Trained batch 55 in epoch 4, gen_loss = 0.39710165227630306, disc_loss = 0.11905266584861758
Trained batch 56 in epoch 4, gen_loss = 0.40008124643773363, disc_loss = 0.11865635347765005
Trained batch 57 in epoch 4, gen_loss = 0.4038254267953593, disc_loss = 0.11706283978379235
Trained batch 58 in epoch 4, gen_loss = 0.40465638736041926, disc_loss = 0.115617782958799
Trained batch 59 in epoch 4, gen_loss = 0.4080966704835494, disc_loss = 0.11393143783789128
Trained batch 60 in epoch 4, gen_loss = 0.41184466136772124, disc_loss = 0.11226232652934115
Trained batch 61 in epoch 4, gen_loss = 0.412348207326666, disc_loss = 0.11084074074132068
Trained batch 62 in epoch 4, gen_loss = 0.41574887091678286, disc_loss = 0.1092853914310653
Trained batch 63 in epoch 4, gen_loss = 0.41890534514095634, disc_loss = 0.10775948073569452
Trained batch 64 in epoch 4, gen_loss = 0.4217325828396357, disc_loss = 0.10622185200022963
Trained batch 65 in epoch 4, gen_loss = 0.4243915066348784, disc_loss = 0.10473066042741817
Trained batch 66 in epoch 4, gen_loss = 0.4272198911700676, disc_loss = 0.10325628042971688
Trained batch 67 in epoch 4, gen_loss = 0.43001475086545243, disc_loss = 0.10181129171156927
Trained batch 68 in epoch 4, gen_loss = 0.43294249528992, disc_loss = 0.1004092764797742
Trained batch 69 in epoch 4, gen_loss = 0.4356540691639696, disc_loss = 0.0990427432049598
Trained batch 70 in epoch 4, gen_loss = 0.43847752656315414, disc_loss = 0.09772143562153822
Trained batch 71 in epoch 4, gen_loss = 0.44129937504314715, disc_loss = 0.09647077772792222
Trained batch 72 in epoch 4, gen_loss = 0.44371356243548327, disc_loss = 0.09520422489293022
Trained batch 73 in epoch 4, gen_loss = 0.4457283764070756, disc_loss = 0.09397966110751636
Trained batch 74 in epoch 4, gen_loss = 0.4476684787869453, disc_loss = 0.09277937261387706
Trained batch 75 in epoch 4, gen_loss = 0.4498471095177688, disc_loss = 0.09161347833976738
Trained batch 76 in epoch 4, gen_loss = 0.4518753153743682, disc_loss = 0.09047860271817484
Trained batch 77 in epoch 4, gen_loss = 0.45396737821209127, disc_loss = 0.08936603746424691
Trained batch 78 in epoch 4, gen_loss = 0.4559277872307391, disc_loss = 0.08827856051605902
Trained batch 79 in epoch 4, gen_loss = 0.45778922690078616, disc_loss = 0.08723559759673663
Trained batch 80 in epoch 4, gen_loss = 0.4594134131883397, disc_loss = 0.08623251903595196
Trained batch 81 in epoch 4, gen_loss = 0.461005739595105, disc_loss = 0.08522682341394901
Trained batch 82 in epoch 4, gen_loss = 0.4627360330827265, disc_loss = 0.08424293546353927
Trained batch 83 in epoch 4, gen_loss = 0.4644843363868339, disc_loss = 0.08327957227482416
Trained batch 84 in epoch 4, gen_loss = 0.4663429908016149, disc_loss = 0.08243163211873787
Trained batch 85 in epoch 4, gen_loss = 0.46771546184670093, disc_loss = 0.08152456090753075
Trained batch 86 in epoch 4, gen_loss = 0.4691472590483468, disc_loss = 0.08063293351984487
Trained batch 87 in epoch 4, gen_loss = 0.4706290109421719, disc_loss = 0.07977204808743078
Trained batch 88 in epoch 4, gen_loss = 0.4721799944056554, disc_loss = 0.07893323033179543
Trained batch 89 in epoch 4, gen_loss = 0.47383798650569386, disc_loss = 0.07812011621944193
Trained batch 90 in epoch 4, gen_loss = 0.4753214745567395, disc_loss = 0.07731499962744068
Trained batch 91 in epoch 4, gen_loss = 0.4767978699148997, disc_loss = 0.07654648415653197
Trained batch 92 in epoch 4, gen_loss = 0.47806785848512445, disc_loss = 0.07576151561212316
Trained batch 93 in epoch 4, gen_loss = 0.47916677047280554, disc_loss = 0.07501052143151297
Trained batch 94 in epoch 4, gen_loss = 0.4804308015264963, disc_loss = 0.07426048400566766
Trained batch 95 in epoch 4, gen_loss = 0.481896960719799, disc_loss = 0.073567241532146
Trained batch 96 in epoch 4, gen_loss = 0.4832541895742269, disc_loss = 0.07284374396345511
Trained batch 97 in epoch 4, gen_loss = 0.4844024524244727, disc_loss = 0.07213499547191421
Trained batch 98 in epoch 4, gen_loss = 0.4855050681666894, disc_loss = 0.07143872385054376
Trained batch 99 in epoch 4, gen_loss = 0.4867243381589651, disc_loss = 0.0707549500092864
Trained batch 100 in epoch 4, gen_loss = 0.4879686002536575, disc_loss = 0.07008657359176933
Trained batch 101 in epoch 4, gen_loss = 0.48914770891561227, disc_loss = 0.06942749564426348
Trained batch 102 in epoch 4, gen_loss = 0.49021244360115923, disc_loss = 0.0687831587302815
Trained batch 103 in epoch 4, gen_loss = 0.4914008696348621, disc_loss = 0.06815354267690474
Trained batch 104 in epoch 4, gen_loss = 0.4923280485329174, disc_loss = 0.06754520902232755
Trained batch 105 in epoch 4, gen_loss = 0.4931726519651008, disc_loss = 0.06693974005734935
Trained batch 106 in epoch 4, gen_loss = 0.49273261922263656, disc_loss = 0.06650629187237785
Trained batch 107 in epoch 4, gen_loss = 0.4946997714125448, disc_loss = 0.06600069132400677
Trained batch 108 in epoch 4, gen_loss = 0.49658179631747235, disc_loss = 0.06547213507465882
Trained batch 109 in epoch 4, gen_loss = 0.4978493914685466, disc_loss = 0.06490887217646972
Trained batch 110 in epoch 4, gen_loss = 0.49868745598438624, disc_loss = 0.06436567759007081
Trained batch 111 in epoch 4, gen_loss = 0.4996000620802598, disc_loss = 0.0638875260275589
Trained batch 112 in epoch 4, gen_loss = 0.5002062285764027, disc_loss = 0.06335456752366658
Trained batch 113 in epoch 4, gen_loss = 0.5008862679334063, disc_loss = 0.06282884999905435
Trained batch 114 in epoch 4, gen_loss = 0.5017020357043847, disc_loss = 0.062319339153802264
Trained batch 115 in epoch 4, gen_loss = 0.5026489256656376, disc_loss = 0.06181058130861292
Trained batch 116 in epoch 4, gen_loss = 0.5035395527369956, disc_loss = 0.0613135814658788
Trained batch 117 in epoch 4, gen_loss = 0.5042036061443514, disc_loss = 0.060826566958231694
Trained batch 118 in epoch 4, gen_loss = 0.504631074724578, disc_loss = 0.06035595740575124
Trained batch 119 in epoch 4, gen_loss = 0.5053172764057915, disc_loss = 0.059870850647954894
Trained batch 120 in epoch 4, gen_loss = 0.5059312125744898, disc_loss = 0.05939565750785664
Trained batch 121 in epoch 4, gen_loss = 0.5066374595902983, disc_loss = 0.0589250755538309
Trained batch 122 in epoch 4, gen_loss = 0.5073406959815723, disc_loss = 0.05846100447631282
Trained batch 123 in epoch 4, gen_loss = 0.5080149204380089, disc_loss = 0.05801778626365347
Trained batch 124 in epoch 4, gen_loss = 0.5085873462557793, disc_loss = 0.05757283936999738
Trained batch 125 in epoch 4, gen_loss = 0.5091138616322525, disc_loss = 0.05713874802163373
Trained batch 126 in epoch 4, gen_loss = 0.5098075934165106, disc_loss = 0.056707110327455824
Trained batch 127 in epoch 4, gen_loss = 0.5104491847450845, disc_loss = 0.05628256341697124
Trained batch 128 in epoch 4, gen_loss = 0.5110747270690378, disc_loss = 0.055862990888413185
Trained batch 129 in epoch 4, gen_loss = 0.5117084101415598, disc_loss = 0.055448873684956476
Trained batch 130 in epoch 4, gen_loss = 0.5123324527881528, disc_loss = 0.055041779698235274
Trained batch 131 in epoch 4, gen_loss = 0.512853560291908, disc_loss = 0.05464536000297151
Trained batch 132 in epoch 4, gen_loss = 0.5132983126922658, disc_loss = 0.05425093727032269
Trained batch 133 in epoch 4, gen_loss = 0.513820092346686, disc_loss = 0.053864928275179955
Trained batch 134 in epoch 4, gen_loss = 0.5143975391983986, disc_loss = 0.05348181189900195
Trained batch 135 in epoch 4, gen_loss = 0.5149897272862932, disc_loss = 0.053105655840173474
Trained batch 136 in epoch 4, gen_loss = 0.5154939608743591, disc_loss = 0.0527326547333386
Trained batch 137 in epoch 4, gen_loss = 0.5159923910986686, disc_loss = 0.05236720269633646
Trained batch 138 in epoch 4, gen_loss = 0.5165471127457756, disc_loss = 0.05200469788673113
Trained batch 139 in epoch 4, gen_loss = 0.5171301575111491, disc_loss = 0.05165121408811371
Trained batch 140 in epoch 4, gen_loss = 0.5177148662454693, disc_loss = 0.05129822966946514
Trained batch 141 in epoch 4, gen_loss = 0.5182908334257738, disc_loss = 0.05095007983413459
Trained batch 142 in epoch 4, gen_loss = 0.5188970980006498, disc_loss = 0.050607534036711116
Trained batch 143 in epoch 4, gen_loss = 0.519379805928717, disc_loss = 0.05026861533648722
Trained batch 144 in epoch 4, gen_loss = 0.5198315141016039, disc_loss = 0.0499351185497603
Trained batch 145 in epoch 4, gen_loss = 0.5203497966572846, disc_loss = 0.04962306317621332
Trained batch 146 in epoch 4, gen_loss = 0.5207938448000117, disc_loss = 0.049304749640053276
Trained batch 147 in epoch 4, gen_loss = 0.5211900506369971, disc_loss = 0.04898528132754428
Trained batch 148 in epoch 4, gen_loss = 0.5216644015788232, disc_loss = 0.048677602736748156
Trained batch 149 in epoch 4, gen_loss = 0.5220526080826918, disc_loss = 0.04837670114589855
Trained batch 150 in epoch 4, gen_loss = 0.5225996112093231, disc_loss = 0.048068161066991605
Trained batch 151 in epoch 4, gen_loss = 0.5231189893950757, disc_loss = 0.047765067755551026
Trained batch 152 in epoch 4, gen_loss = 0.5236083403034927, disc_loss = 0.04746707313347096
Trained batch 153 in epoch 4, gen_loss = 0.5240693856272605, disc_loss = 0.04717306013509341
Trained batch 154 in epoch 4, gen_loss = 0.5245354607701301, disc_loss = 0.046883312767491706
Trained batch 155 in epoch 4, gen_loss = 0.5250011225445912, disc_loss = 0.04659439548282908
Trained batch 156 in epoch 4, gen_loss = 0.525484505115421, disc_loss = 0.046308038449270804
Trained batch 157 in epoch 4, gen_loss = 0.5259583412752121, disc_loss = 0.046027190681205046
Trained batch 158 in epoch 4, gen_loss = 0.5263705075068293, disc_loss = 0.04574943418796145
Trained batch 159 in epoch 4, gen_loss = 0.5267477256711572, disc_loss = 0.04547512499339064
Trained batch 160 in epoch 4, gen_loss = 0.5271263334969556, disc_loss = 0.045207351686936216
Trained batch 161 in epoch 4, gen_loss = 0.5276169071870821, disc_loss = 0.04493963323823855
Trained batch 162 in epoch 4, gen_loss = 0.5281212667654629, disc_loss = 0.04467438232150797
Trained batch 163 in epoch 4, gen_loss = 0.5286531533319049, disc_loss = 0.044425663828605605
Trained batch 164 in epoch 4, gen_loss = 0.5290390362793749, disc_loss = 0.04416710649207799
Trained batch 165 in epoch 4, gen_loss = 0.5293311118989824, disc_loss = 0.04391397026168317
Trained batch 166 in epoch 4, gen_loss = 0.5297012990730965, disc_loss = 0.04366365270368465
Trained batch 167 in epoch 4, gen_loss = 0.5301064034214332, disc_loss = 0.043414696148829535
Trained batch 168 in epoch 4, gen_loss = 0.5305724713135753, disc_loss = 0.04317082037195872
Trained batch 169 in epoch 4, gen_loss = 0.5310026061447227, disc_loss = 0.04292873889344799
Trained batch 170 in epoch 4, gen_loss = 0.5314422944745822, disc_loss = 0.04268828875995214
Trained batch 171 in epoch 4, gen_loss = 0.5319194451927446, disc_loss = 0.04245241819528949
Trained batch 172 in epoch 4, gen_loss = 0.5322626930354648, disc_loss = 0.04221934986010065
Trained batch 173 in epoch 4, gen_loss = 0.5326186245114639, disc_loss = 0.04198750545104816
Trained batch 174 in epoch 4, gen_loss = 0.5329874796101025, disc_loss = 0.04177465140154319
Trained batch 175 in epoch 4, gen_loss = 0.5332279589281164, disc_loss = 0.041551493379467334
Trained batch 176 in epoch 4, gen_loss = 0.5334713568037512, disc_loss = 0.04133644136126643
Trained batch 177 in epoch 4, gen_loss = 0.533878696894043, disc_loss = 0.041115261864157794
Trained batch 178 in epoch 4, gen_loss = 0.5342758971802349, disc_loss = 0.04089484004662815
Trained batch 179 in epoch 4, gen_loss = 0.5346685129321284, disc_loss = 0.040677556455678616
Trained batch 180 in epoch 4, gen_loss = 0.5350445865843836, disc_loss = 0.04046461104803837
Trained batch 181 in epoch 4, gen_loss = 0.5353992235447679, disc_loss = 0.04025319862437875
Trained batch 182 in epoch 4, gen_loss = 0.5357482099060804, disc_loss = 0.04004652781572315
Trained batch 183 in epoch 4, gen_loss = 0.5360286667862016, disc_loss = 0.03983931947795614
Trained batch 184 in epoch 4, gen_loss = 0.5362469816127339, disc_loss = 0.039637086880896746
Trained batch 185 in epoch 4, gen_loss = 0.5365391063994618, disc_loss = 0.03943936144795409
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 0.580381453037262, disc_loss = 0.002372359624132514
Trained batch 1 in epoch 5, gen_loss = 0.5818572044372559, disc_loss = 0.002152123604901135
Trained batch 2 in epoch 5, gen_loss = 0.5854924917221069, disc_loss = 0.00201393140014261
Trained batch 3 in epoch 5, gen_loss = 0.5862104892730713, disc_loss = 0.0019446663500275463
Trained batch 4 in epoch 5, gen_loss = 0.5835897207260132, disc_loss = 0.001999894273467362
Trained batch 5 in epoch 5, gen_loss = 0.5779398381710052, disc_loss = 0.0025247003456267216
Trained batch 6 in epoch 5, gen_loss = 0.5896183337484088, disc_loss = 0.002632673746640129
Trained batch 7 in epoch 5, gen_loss = 0.5973193198442459, disc_loss = 0.0026180165441473946
Trained batch 8 in epoch 5, gen_loss = 0.5979817708333334, disc_loss = 0.0026195188337523076
Trained batch 9 in epoch 5, gen_loss = 0.5974170088768005, disc_loss = 0.0026402564137242733
Trained batch 10 in epoch 5, gen_loss = 0.5975754911249335, disc_loss = 0.0025705381360074334
Trained batch 11 in epoch 5, gen_loss = 0.5977406849463781, disc_loss = 0.002566795243183151
Trained batch 12 in epoch 5, gen_loss = 0.5965408912071815, disc_loss = 0.00256414520733345
Trained batch 13 in epoch 5, gen_loss = 0.5900896447045463, disc_loss = 0.002787258301395923
Trained batch 14 in epoch 5, gen_loss = 0.5880465030670166, disc_loss = 0.002941925257133941
Trained batch 15 in epoch 5, gen_loss = 0.5913597643375397, disc_loss = 0.003046770223591011
Trained batch 16 in epoch 5, gen_loss = 0.5873701502295101, disc_loss = 0.003311357070582316
Trained batch 17 in epoch 5, gen_loss = 0.5852108796437582, disc_loss = 0.0034273840008407002
Trained batch 18 in epoch 5, gen_loss = 0.5799707315470043, disc_loss = 0.0036662550287713345
Trained batch 19 in epoch 5, gen_loss = 0.582399745285511, disc_loss = 0.0038097578275483102
Trained batch 20 in epoch 5, gen_loss = 0.5859314671584538, disc_loss = 0.0038944585858622476
Trained batch 21 in epoch 5, gen_loss = 0.5826269591396506, disc_loss = 0.0040212168559347365
Trained batch 22 in epoch 5, gen_loss = 0.5820970289085222, disc_loss = 0.004059875075219442
Trained batch 23 in epoch 5, gen_loss = 0.5815170966088772, disc_loss = 0.0040593128408848616
Trained batch 24 in epoch 5, gen_loss = 0.5808729994297027, disc_loss = 0.004044188070110977
Trained batch 25 in epoch 5, gen_loss = 0.5815004992943543, disc_loss = 0.004105350983221657
Trained batch 26 in epoch 5, gen_loss = 0.5780734132837366, disc_loss = 0.004334706412110891
Trained batch 27 in epoch 5, gen_loss = 0.5761073359421321, disc_loss = 0.004440005082869902
Trained batch 28 in epoch 5, gen_loss = 0.5743741187556036, disc_loss = 0.005077262774334642
Trained batch 29 in epoch 5, gen_loss = 0.583213762442271, disc_loss = 0.005736493393002699
Trained batch 30 in epoch 5, gen_loss = 0.5886267692812027, disc_loss = 0.005972764045450716
Trained batch 31 in epoch 5, gen_loss = 0.5916996691375971, disc_loss = 0.0059759941323136445
Trained batch 32 in epoch 5, gen_loss = 0.593198709415667, disc_loss = 0.005960199696181173
Trained batch 33 in epoch 5, gen_loss = 0.5940676559420193, disc_loss = 0.005880819986273041
Trained batch 34 in epoch 5, gen_loss = 0.5947893227849688, disc_loss = 0.00579328543972224
Trained batch 35 in epoch 5, gen_loss = 0.5956241769923104, disc_loss = 0.005705454325329306
Trained batch 36 in epoch 5, gen_loss = 0.5964726854015041, disc_loss = 0.005628762807621545
Trained batch 37 in epoch 5, gen_loss = 0.5969425769228685, disc_loss = 0.005557901621183478
Trained batch 38 in epoch 5, gen_loss = 0.5970513209318503, disc_loss = 0.005492555828263553
Trained batch 39 in epoch 5, gen_loss = 0.5969145849347115, disc_loss = 0.005433929516584612
Trained batch 40 in epoch 5, gen_loss = 0.5970826396128026, disc_loss = 0.005374571407872547
Trained batch 41 in epoch 5, gen_loss = 0.5977431947276706, disc_loss = 0.005340018672757738
Trained batch 42 in epoch 5, gen_loss = 0.59772135213364, disc_loss = 0.005270132656902248
Trained batch 43 in epoch 5, gen_loss = 0.5975710424509916, disc_loss = 0.005203782181276686
Trained batch 44 in epoch 5, gen_loss = 0.5972725934452481, disc_loss = 0.0051490181668971974
Trained batch 45 in epoch 5, gen_loss = 0.5970403059669163, disc_loss = 0.0050947036032321985
Trained batch 46 in epoch 5, gen_loss = 0.596368153044518, disc_loss = 0.005063596367340615
Trained batch 47 in epoch 5, gen_loss = 0.5957110586265723, disc_loss = 0.005130958362618306
Trained batch 48 in epoch 5, gen_loss = 0.5942219848535499, disc_loss = 0.005149913407691127
Trained batch 49 in epoch 5, gen_loss = 0.5934440183639527, disc_loss = 0.005126499894540757
Trained batch 50 in epoch 5, gen_loss = 0.5937159341924331, disc_loss = 0.005088843590141658
Trained batch 51 in epoch 5, gen_loss = 0.5941699949594644, disc_loss = 0.0050546988115037
Trained batch 52 in epoch 5, gen_loss = 0.5940440274634451, disc_loss = 0.005006670795890661
Trained batch 53 in epoch 5, gen_loss = 0.5929837591118283, disc_loss = 0.00498549851666515
Trained batch 54 in epoch 5, gen_loss = 0.5924121824177828, disc_loss = 0.004949551738205958
Trained batch 55 in epoch 5, gen_loss = 0.5929285128201757, disc_loss = 0.004926301624176891
Trained batch 56 in epoch 5, gen_loss = 0.5934945418123614, disc_loss = 0.004911872895287448
Trained batch 57 in epoch 5, gen_loss = 0.5915279845739233, disc_loss = 0.0049936087292233675
Trained batch 58 in epoch 5, gen_loss = 0.5916819092580827, disc_loss = 0.005014675600312145
Trained batch 59 in epoch 5, gen_loss = 0.5923293883601825, disc_loss = 0.0050401877165616804
Trained batch 60 in epoch 5, gen_loss = 0.5935053752094018, disc_loss = 0.005080257803888716
Trained batch 61 in epoch 5, gen_loss = 0.5940987222617672, disc_loss = 0.0050736990655892555
Trained batch 62 in epoch 5, gen_loss = 0.5944639250399575, disc_loss = 0.005042090256225377
Trained batch 63 in epoch 5, gen_loss = 0.5945146880112588, disc_loss = 0.005054363688032026
Trained batch 64 in epoch 5, gen_loss = 0.5940773546695709, disc_loss = 0.005047414586162911
Trained batch 65 in epoch 5, gen_loss = 0.5937061269174922, disc_loss = 0.005024287502182591
Trained batch 66 in epoch 5, gen_loss = 0.5926805747978723, disc_loss = 0.00500620008314223
Trained batch 67 in epoch 5, gen_loss = 0.5928491840467733, disc_loss = 0.0049730904609211445
Trained batch 68 in epoch 5, gen_loss = 0.5910120317037555, disc_loss = 0.00504446633166863
Trained batch 69 in epoch 5, gen_loss = 0.5925825710807527, disc_loss = 0.005173540263370212
Trained batch 70 in epoch 5, gen_loss = 0.5935311422381603, disc_loss = 0.0052100244506170425
Trained batch 71 in epoch 5, gen_loss = 0.5933127721978558, disc_loss = 0.005186209191581131
Trained batch 72 in epoch 5, gen_loss = 0.5926679213569589, disc_loss = 0.005222574330879095
Trained batch 73 in epoch 5, gen_loss = 0.5924978807971284, disc_loss = 0.005191187199670821
Trained batch 74 in epoch 5, gen_loss = 0.5927090132236481, disc_loss = 0.005158540601842105
Trained batch 75 in epoch 5, gen_loss = 0.5930006782475271, disc_loss = 0.005122757585731482
Trained batch 76 in epoch 5, gen_loss = 0.5930604969526266, disc_loss = 0.005087856879131263
Trained batch 77 in epoch 5, gen_loss = 0.5926350450668579, disc_loss = 0.005046213711373126
Trained batch 78 in epoch 5, gen_loss = 0.5920878079118608, disc_loss = 0.0050184683803516095
Trained batch 79 in epoch 5, gen_loss = 0.5916413109749555, disc_loss = 0.004983172123320401
Trained batch 80 in epoch 5, gen_loss = 0.5913364714310493, disc_loss = 0.004948911852099829
Trained batch 81 in epoch 5, gen_loss = 0.5909683199190512, disc_loss = 0.0049191839118465416
Trained batch 82 in epoch 5, gen_loss = 0.5907293820237539, disc_loss = 0.00489709674133863
Trained batch 83 in epoch 5, gen_loss = 0.5908578779725802, disc_loss = 0.0048709642391518825
Trained batch 84 in epoch 5, gen_loss = 0.5906236581942614, disc_loss = 0.004832969373092055
Trained batch 85 in epoch 5, gen_loss = 0.5889734261950781, disc_loss = 0.0049274996718998215
Trained batch 86 in epoch 5, gen_loss = 0.590066351767244, disc_loss = 0.004970241164060673
Trained batch 87 in epoch 5, gen_loss = 0.5907664539461787, disc_loss = 0.004977477881104939
Trained batch 88 in epoch 5, gen_loss = 0.5906795434067759, disc_loss = 0.004946659740290783
Trained batch 89 in epoch 5, gen_loss = 0.5901310804817411, disc_loss = 0.004926107929916017
Trained batch 90 in epoch 5, gen_loss = 0.5884424123790238, disc_loss = 0.005040811019141105
Trained batch 91 in epoch 5, gen_loss = 0.5888779581240986, disc_loss = 0.005307046628212961
Trained batch 92 in epoch 5, gen_loss = 0.58611909260032, disc_loss = 0.005797451114161841
Trained batch 93 in epoch 5, gen_loss = 0.5850020028809284, disc_loss = 0.00594910017482223
Trained batch 94 in epoch 5, gen_loss = 0.5864429684061753, disc_loss = 0.006750782826719316
Trained batch 95 in epoch 5, gen_loss = 0.5859906924888492, disc_loss = 0.00682527923345333
Trained batch 96 in epoch 5, gen_loss = 0.5833771689650938, disc_loss = 0.0072078408562991116
Trained batch 97 in epoch 5, gen_loss = 0.5843192345025588, disc_loss = 0.007217864147197379
Trained batch 98 in epoch 5, gen_loss = 0.5854972968197832, disc_loss = 0.007222201042535781
Trained batch 99 in epoch 5, gen_loss = 0.5861878722906113, disc_loss = 0.007194497480522841
Trained batch 100 in epoch 5, gen_loss = 0.586371647839499, disc_loss = 0.0071496717691753465
Trained batch 101 in epoch 5, gen_loss = 0.5863591829935709, disc_loss = 0.007115617725432065
Trained batch 102 in epoch 5, gen_loss = 0.5863683883426258, disc_loss = 0.007078633510317762
Trained batch 103 in epoch 5, gen_loss = 0.586439701800163, disc_loss = 0.007030458285813578
Trained batch 104 in epoch 5, gen_loss = 0.586574489729745, disc_loss = 0.007004729434404344
Trained batch 105 in epoch 5, gen_loss = 0.5866017594652356, disc_loss = 0.006965095785727619
Trained batch 106 in epoch 5, gen_loss = 0.5864970650628348, disc_loss = 0.006921751444254105
Trained batch 107 in epoch 5, gen_loss = 0.5865031856077688, disc_loss = 0.006885714020528313
Trained batch 108 in epoch 5, gen_loss = 0.5866580583633633, disc_loss = 0.006843755011011018
Trained batch 109 in epoch 5, gen_loss = 0.5867528357289055, disc_loss = 0.006810045333325186
Trained batch 110 in epoch 5, gen_loss = 0.5867322849797773, disc_loss = 0.006808463947612558
Trained batch 111 in epoch 5, gen_loss = 0.5865297599562577, disc_loss = 0.006793735031221461
Trained batch 112 in epoch 5, gen_loss = 0.5864583939577626, disc_loss = 0.006755767936150716
Trained batch 113 in epoch 5, gen_loss = 0.5865745063413653, disc_loss = 0.006718473290420023
Trained batch 114 in epoch 5, gen_loss = 0.5866335495658542, disc_loss = 0.00667831978517706
Trained batch 115 in epoch 5, gen_loss = 0.5867210976008711, disc_loss = 0.0066361515752666085
Trained batch 116 in epoch 5, gen_loss = 0.5867178511415791, disc_loss = 0.006592999111948551
Trained batch 117 in epoch 5, gen_loss = 0.5866579792257083, disc_loss = 0.006549487196272082
Trained batch 118 in epoch 5, gen_loss = 0.5866346173927564, disc_loss = 0.006506663117119495
Trained batch 119 in epoch 5, gen_loss = 0.5865429148077965, disc_loss = 0.006465150157843406
Trained batch 120 in epoch 5, gen_loss = 0.5863399574579287, disc_loss = 0.006430096323948261
Trained batch 121 in epoch 5, gen_loss = 0.5864938087150698, disc_loss = 0.0063978585368785704
Trained batch 122 in epoch 5, gen_loss = 0.586162183827501, disc_loss = 0.006373879687133722
Trained batch 123 in epoch 5, gen_loss = 0.5859875717470723, disc_loss = 0.006344436801173875
Trained batch 124 in epoch 5, gen_loss = 0.5862491536140442, disc_loss = 0.006313734503462911
Trained batch 125 in epoch 5, gen_loss = 0.5863908817843785, disc_loss = 0.006282536839578478
Trained batch 126 in epoch 5, gen_loss = 0.5863384304084177, disc_loss = 0.006249812774462845
Trained batch 127 in epoch 5, gen_loss = 0.586273523978889, disc_loss = 0.006218492808329756
Trained batch 128 in epoch 5, gen_loss = 0.5861753678137018, disc_loss = 0.006189548036863291
Trained batch 129 in epoch 5, gen_loss = 0.5861525796926939, disc_loss = 0.006163110274176758
Trained batch 130 in epoch 5, gen_loss = 0.585618773489508, disc_loss = 0.006170776677993304
Trained batch 131 in epoch 5, gen_loss = 0.5857171718821381, disc_loss = 0.0061462600874206555
Trained batch 132 in epoch 5, gen_loss = 0.5860041496448947, disc_loss = 0.006126302620045897
Trained batch 133 in epoch 5, gen_loss = 0.5852290818940348, disc_loss = 0.006171519781198741
Trained batch 134 in epoch 5, gen_loss = 0.5847221259717588, disc_loss = 0.00616888293168611
Trained batch 135 in epoch 5, gen_loss = 0.5854497560683418, disc_loss = 0.006191057998769204
Trained batch 136 in epoch 5, gen_loss = 0.5860207481105832, disc_loss = 0.006182103118702878
Trained batch 137 in epoch 5, gen_loss = 0.5862929419330929, disc_loss = 0.006161515879363794
Trained batch 138 in epoch 5, gen_loss = 0.5861345628182665, disc_loss = 0.00614823293269163
Trained batch 139 in epoch 5, gen_loss = 0.5855898086513792, disc_loss = 0.006149262138309755
Trained batch 140 in epoch 5, gen_loss = 0.5847329518473741, disc_loss = 0.006193012562217125
Trained batch 141 in epoch 5, gen_loss = 0.5855369013799748, disc_loss = 0.0064082509382221275
Trained batch 142 in epoch 5, gen_loss = 0.5857420747096722, disc_loss = 0.006392913390198475
Trained batch 143 in epoch 5, gen_loss = 0.5856591272685263, disc_loss = 0.00637505965682471
Trained batch 144 in epoch 5, gen_loss = 0.5855732769801699, disc_loss = 0.00636375034549113
Trained batch 145 in epoch 5, gen_loss = 0.5854009912438589, disc_loss = 0.006345083031242024
Trained batch 146 in epoch 5, gen_loss = 0.5847330172451175, disc_loss = 0.006376019292542724
Trained batch 147 in epoch 5, gen_loss = 0.5846214489759626, disc_loss = 0.006360747945822171
Trained batch 148 in epoch 5, gen_loss = 0.582354585596379, disc_loss = 0.006935607935708241
Trained batch 149 in epoch 5, gen_loss = 0.5839067570368449, disc_loss = 0.007447458623598019
Trained batch 150 in epoch 5, gen_loss = 0.5844278900039117, disc_loss = 0.007743387298029385
Trained batch 151 in epoch 5, gen_loss = 0.5833601224187174, disc_loss = 0.00791082800194425
Trained batch 152 in epoch 5, gen_loss = 0.5827885293493084, disc_loss = 0.007951908136164051
Trained batch 153 in epoch 5, gen_loss = 0.5829497827337934, disc_loss = 0.007931099001124695
Trained batch 154 in epoch 5, gen_loss = 0.5834019303321838, disc_loss = 0.007915231711681812
Trained batch 155 in epoch 5, gen_loss = 0.5836822134562027, disc_loss = 0.007890182129370097
Trained batch 156 in epoch 5, gen_loss = 0.5836222543837918, disc_loss = 0.007859107471741499
Trained batch 157 in epoch 5, gen_loss = 0.5829547002345701, disc_loss = 0.007873191347911576
Trained batch 158 in epoch 5, gen_loss = 0.5825055350297652, disc_loss = 0.007871960105269023
Trained batch 159 in epoch 5, gen_loss = 0.5824794255197048, disc_loss = 0.007887881839997135
Trained batch 160 in epoch 5, gen_loss = 0.5816436048990451, disc_loss = 0.007932860482345271
Trained batch 161 in epoch 5, gen_loss = 0.5810228558602156, disc_loss = 0.008034410607644621
Trained batch 162 in epoch 5, gen_loss = 0.5819751713539194, disc_loss = 0.008140949678087345
Trained batch 163 in epoch 5, gen_loss = 0.5824542701607798, disc_loss = 0.00814646445839416
Trained batch 164 in epoch 5, gen_loss = 0.5825106293866129, disc_loss = 0.008181514514779503
Trained batch 165 in epoch 5, gen_loss = 0.5825709070426872, disc_loss = 0.008153335929074022
Trained batch 166 in epoch 5, gen_loss = 0.5826816143033033, disc_loss = 0.008127187518124095
Trained batch 167 in epoch 5, gen_loss = 0.5827956439128944, disc_loss = 0.008094842599738123
Trained batch 168 in epoch 5, gen_loss = 0.582990293848444, disc_loss = 0.00806255930808742
Trained batch 169 in epoch 5, gen_loss = 0.5831046895069234, disc_loss = 0.008045326796469882
Trained batch 170 in epoch 5, gen_loss = 0.5819727065618973, disc_loss = 0.008166267714947897
Trained batch 171 in epoch 5, gen_loss = 0.5823107567984004, disc_loss = 0.008230768240241031
Trained batch 172 in epoch 5, gen_loss = 0.5822965304631029, disc_loss = 0.008221951403488227
Trained batch 173 in epoch 5, gen_loss = 0.5820940676434286, disc_loss = 0.008206775986011428
Trained batch 174 in epoch 5, gen_loss = 0.5815887536321368, disc_loss = 0.008202911483656082
Trained batch 175 in epoch 5, gen_loss = 0.5811471942473542, disc_loss = 0.008187825829901902
Trained batch 176 in epoch 5, gen_loss = 0.5810512273998584, disc_loss = 0.008237196149641258
Trained batch 177 in epoch 5, gen_loss = 0.5816034081946598, disc_loss = 0.008241602895896505
Trained batch 178 in epoch 5, gen_loss = 0.581856950701282, disc_loss = 0.008235287219129877
Trained batch 179 in epoch 5, gen_loss = 0.5819174034727944, disc_loss = 0.00820423861215305
Trained batch 180 in epoch 5, gen_loss = 0.581860269301504, disc_loss = 0.00817903996064477
Trained batch 181 in epoch 5, gen_loss = 0.5819229106981676, disc_loss = 0.00814826648354858
Trained batch 182 in epoch 5, gen_loss = 0.5818945586355657, disc_loss = 0.008116502604890065
Trained batch 183 in epoch 5, gen_loss = 0.5818006247282028, disc_loss = 0.008086036495945376
Trained batch 184 in epoch 5, gen_loss = 0.5817815877295829, disc_loss = 0.00806345311119347
Trained batch 185 in epoch 5, gen_loss = 0.5816977543215598, disc_loss = 0.008030780152948473
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 0.5925602912902832, disc_loss = 0.0031878980807960033
Trained batch 1 in epoch 6, gen_loss = 0.5867420136928558, disc_loss = 0.0025991054717451334
Trained batch 2 in epoch 6, gen_loss = 0.5788383483886719, disc_loss = 0.0026054567812631526
Trained batch 3 in epoch 6, gen_loss = 0.5751203894615173, disc_loss = 0.0027126240893267095
Trained batch 4 in epoch 6, gen_loss = 0.5796192526817322, disc_loss = 0.0026284306775778534
Trained batch 5 in epoch 6, gen_loss = 0.5797100762526194, disc_loss = 0.0026203002392624817
Trained batch 6 in epoch 6, gen_loss = 0.5791646242141724, disc_loss = 0.0025999692734330893
Trained batch 7 in epoch 6, gen_loss = 0.5815886184573174, disc_loss = 0.0025709170440677553
Trained batch 8 in epoch 6, gen_loss = 0.5829969313409593, disc_loss = 0.002553276795273026
Trained batch 9 in epoch 6, gen_loss = 0.5819548904895783, disc_loss = 0.002532053808681667
Trained batch 10 in epoch 6, gen_loss = 0.5800717906518416, disc_loss = 0.0024746399351649666
Trained batch 11 in epoch 6, gen_loss = 0.5801295886437098, disc_loss = 0.002413129802638044
Trained batch 12 in epoch 6, gen_loss = 0.5805065952814542, disc_loss = 0.00234497704793914
Trained batch 13 in epoch 6, gen_loss = 0.5806032930101667, disc_loss = 0.002390832848115159
Trained batch 14 in epoch 6, gen_loss = 0.5785206198692322, disc_loss = 0.0024215026525780557
Trained batch 15 in epoch 6, gen_loss = 0.5784215331077576, disc_loss = 0.0024050133433775045
Trained batch 16 in epoch 6, gen_loss = 0.5802026671521804, disc_loss = 0.0023999927524367675
Trained batch 17 in epoch 6, gen_loss = 0.5806423193878598, disc_loss = 0.002424978295392874
Trained batch 18 in epoch 6, gen_loss = 0.5792602457498249, disc_loss = 0.002497511333785951
Trained batch 19 in epoch 6, gen_loss = 0.5762932389974594, disc_loss = 0.0027053212106693536
Trained batch 20 in epoch 6, gen_loss = 0.574255211012704, disc_loss = 0.002747543316911019
Trained batch 21 in epoch 6, gen_loss = 0.5723621601408179, disc_loss = 0.002785559251523492
Trained batch 22 in epoch 6, gen_loss = 0.5687313209409299, disc_loss = 0.0030713325275270186
Trained batch 23 in epoch 6, gen_loss = 0.5774163703123728, disc_loss = 0.0038970402432217575
Trained batch 24 in epoch 6, gen_loss = 0.580270709991455, disc_loss = 0.003990564602427185
Trained batch 25 in epoch 6, gen_loss = 0.580431383389693, disc_loss = 0.0041238997767392835
Trained batch 26 in epoch 6, gen_loss = 0.5792017623230263, disc_loss = 0.004118444755914863
Trained batch 27 in epoch 6, gen_loss = 0.5771596154996327, disc_loss = 0.004145776998484507
Trained batch 28 in epoch 6, gen_loss = 0.5724759492380865, disc_loss = 0.0046682180636080685
Trained batch 29 in epoch 6, gen_loss = 0.5749219516913097, disc_loss = 0.004700354234470675
Trained batch 30 in epoch 6, gen_loss = 0.5769229896606938, disc_loss = 0.00467862966545527
Trained batch 31 in epoch 6, gen_loss = 0.5776788406074047, disc_loss = 0.004644011267373571
Trained batch 32 in epoch 6, gen_loss = 0.5778938658309706, disc_loss = 0.004661375603807921
Trained batch 33 in epoch 6, gen_loss = 0.5778060765827403, disc_loss = 0.0046421822249505884
Trained batch 34 in epoch 6, gen_loss = 0.5774854898452759, disc_loss = 0.004634476004035345
Trained batch 35 in epoch 6, gen_loss = 0.5775228821569018, disc_loss = 0.004584471109814735
Trained batch 36 in epoch 6, gen_loss = 0.577411371308404, disc_loss = 0.00450647235344592
Trained batch 37 in epoch 6, gen_loss = 0.5768470952385351, disc_loss = 0.004460310961708035
Trained batch 38 in epoch 6, gen_loss = 0.5763208361772391, disc_loss = 0.004401783160387705
Trained batch 39 in epoch 6, gen_loss = 0.5758463501930237, disc_loss = 0.0043669351609423755
Trained batch 40 in epoch 6, gen_loss = 0.575305502589156, disc_loss = 0.004331184511368231
Trained batch 41 in epoch 6, gen_loss = 0.5750649145671299, disc_loss = 0.004285372976612832
Trained batch 42 in epoch 6, gen_loss = 0.5748282546220824, disc_loss = 0.004241258636940011
Trained batch 43 in epoch 6, gen_loss = 0.5717094730247151, disc_loss = 0.004448558389082213
Trained batch 44 in epoch 6, gen_loss = 0.5745070232285394, disc_loss = 0.00474735752472447
Trained batch 45 in epoch 6, gen_loss = 0.5759894886742467, disc_loss = 0.0047905344121239105
Trained batch 46 in epoch 6, gen_loss = 0.5755131384159656, disc_loss = 0.004806085801782443
Trained batch 47 in epoch 6, gen_loss = 0.5748673304915428, disc_loss = 0.004864807827592206
Trained batch 48 in epoch 6, gen_loss = 0.5749241137991146, disc_loss = 0.004808897984081081
Trained batch 49 in epoch 6, gen_loss = 0.5749301397800446, disc_loss = 0.004754675775766373
Trained batch 50 in epoch 6, gen_loss = 0.5748898725883633, disc_loss = 0.004690394234642678
Trained batch 51 in epoch 6, gen_loss = 0.5747828919153947, disc_loss = 0.004627999961555291
Trained batch 52 in epoch 6, gen_loss = 0.5744961635121759, disc_loss = 0.0045786519438239205
Trained batch 53 in epoch 6, gen_loss = 0.5740118799386201, disc_loss = 0.004530414102461051
Trained batch 54 in epoch 6, gen_loss = 0.5737602450630882, disc_loss = 0.004472191983156583
Trained batch 55 in epoch 6, gen_loss = 0.5736100269215447, disc_loss = 0.004414371256383934
Trained batch 56 in epoch 6, gen_loss = 0.5736613775554457, disc_loss = 0.00437014392912061
Trained batch 57 in epoch 6, gen_loss = 0.5734867823534998, disc_loss = 0.004319551868508731
Trained batch 58 in epoch 6, gen_loss = 0.5732810830665847, disc_loss = 0.004271982679680242
Trained batch 59 in epoch 6, gen_loss = 0.5732924769322078, disc_loss = 0.004223211986633639
Trained batch 60 in epoch 6, gen_loss = 0.5731210249369262, disc_loss = 0.004189088780310799
Trained batch 61 in epoch 6, gen_loss = 0.5731131011439908, disc_loss = 0.004148860522095234
Trained batch 62 in epoch 6, gen_loss = 0.5729476355371022, disc_loss = 0.004108438368088433
Trained batch 63 in epoch 6, gen_loss = 0.5717357629910111, disc_loss = 0.00413112029855256
Trained batch 64 in epoch 6, gen_loss = 0.5731096799557026, disc_loss = 0.004148715430010969
Trained batch 65 in epoch 6, gen_loss = 0.5735098611224781, disc_loss = 0.004127484947358343
Trained batch 66 in epoch 6, gen_loss = 0.5718109825653817, disc_loss = 0.004208098572275754
Trained batch 67 in epoch 6, gen_loss = 0.5727667909334687, disc_loss = 0.004195472858983147
Trained batch 68 in epoch 6, gen_loss = 0.5740452352641285, disc_loss = 0.0041969224061493
Trained batch 69 in epoch 6, gen_loss = 0.5751110804932458, disc_loss = 0.004206702196305352
Trained batch 70 in epoch 6, gen_loss = 0.5754478745897051, disc_loss = 0.004182885738719307
Trained batch 71 in epoch 6, gen_loss = 0.5755102779302332, disc_loss = 0.004187889872506882
Trained batch 72 in epoch 6, gen_loss = 0.5757791477523438, disc_loss = 0.004160908864147655
Trained batch 73 in epoch 6, gen_loss = 0.5760276547154864, disc_loss = 0.004131805211481814
Trained batch 74 in epoch 6, gen_loss = 0.5762202084064484, disc_loss = 0.004095401636635264
Trained batch 75 in epoch 6, gen_loss = 0.5762433484196663, disc_loss = 0.004063312080688775
Trained batch 76 in epoch 6, gen_loss = 0.5762561013946286, disc_loss = 0.004035250525679681
Trained batch 77 in epoch 6, gen_loss = 0.5761555131429281, disc_loss = 0.004003293269003431
Trained batch 78 in epoch 6, gen_loss = 0.5760551566564585, disc_loss = 0.003976884200768192
Trained batch 79 in epoch 6, gen_loss = 0.5761819493025542, disc_loss = 0.003943998597969766
Trained batch 80 in epoch 6, gen_loss = 0.5762867916513372, disc_loss = 0.003916015940499894
Trained batch 81 in epoch 6, gen_loss = 0.5762371199160088, disc_loss = 0.0038862958629956334
Trained batch 82 in epoch 6, gen_loss = 0.5761476256043078, disc_loss = 0.003857962635671159
Trained batch 83 in epoch 6, gen_loss = 0.5761937275528908, disc_loss = 0.003827189066214487
Trained batch 84 in epoch 6, gen_loss = 0.5763078545822816, disc_loss = 0.003804026364677531
Trained batch 85 in epoch 6, gen_loss = 0.5762952077527379, disc_loss = 0.0037769232863062168
Trained batch 86 in epoch 6, gen_loss = 0.5763891267365423, disc_loss = 0.003750949973593755
Trained batch 87 in epoch 6, gen_loss = 0.5762898457998579, disc_loss = 0.003727111651890234
Trained batch 88 in epoch 6, gen_loss = 0.5761766771921951, disc_loss = 0.003708184957033379
Trained batch 89 in epoch 6, gen_loss = 0.5761792245838377, disc_loss = 0.0036836462858546937
Trained batch 90 in epoch 6, gen_loss = 0.5761448914533133, disc_loss = 0.0036626924353825685
Trained batch 91 in epoch 6, gen_loss = 0.5762819275259972, disc_loss = 0.003644226527641244
Trained batch 92 in epoch 6, gen_loss = 0.5763514955197612, disc_loss = 0.003623301685307055
Trained batch 93 in epoch 6, gen_loss = 0.5762211024127109, disc_loss = 0.003600707685109228
Trained batch 94 in epoch 6, gen_loss = 0.5760663964246449, disc_loss = 0.0035788332761608455
Trained batch 95 in epoch 6, gen_loss = 0.5759043944999576, disc_loss = 0.003563714268238982
Trained batch 96 in epoch 6, gen_loss = 0.5759425111038169, disc_loss = 0.0035409087053567324
Trained batch 97 in epoch 6, gen_loss = 0.5758296862548712, disc_loss = 0.0035222542498317758
Trained batch 98 in epoch 6, gen_loss = 0.5759396935352171, disc_loss = 0.0035023249384730755
Trained batch 99 in epoch 6, gen_loss = 0.5755876693129539, disc_loss = 0.003486530389636755
Trained batch 100 in epoch 6, gen_loss = 0.5758760238047873, disc_loss = 0.0034722912512572097
Trained batch 101 in epoch 6, gen_loss = 0.5760408391555151, disc_loss = 0.0034520204085400144
Trained batch 102 in epoch 6, gen_loss = 0.5760255389421889, disc_loss = 0.0034416628135729905
Trained batch 103 in epoch 6, gen_loss = 0.575846632799277, disc_loss = 0.003446598332420063
Trained batch 104 in epoch 6, gen_loss = 0.5757930202143533, disc_loss = 0.0034308375535710227
Trained batch 105 in epoch 6, gen_loss = 0.5758276539591124, disc_loss = 0.0034136557786830896
Trained batch 106 in epoch 6, gen_loss = 0.5756590725662553, disc_loss = 0.0033991980740678647
Trained batch 107 in epoch 6, gen_loss = 0.5756002904640304, disc_loss = 0.003381149754945741
Trained batch 108 in epoch 6, gen_loss = 0.5746759736756666, disc_loss = 0.0034290277078713573
Trained batch 109 in epoch 6, gen_loss = 0.5749066090041941, disc_loss = 0.0034575376553799618
Trained batch 110 in epoch 6, gen_loss = 0.5748632424049549, disc_loss = 0.003449118593372069
Trained batch 111 in epoch 6, gen_loss = 0.5753094785447631, disc_loss = 0.0034452101182458656
Trained batch 112 in epoch 6, gen_loss = 0.5755009458655804, disc_loss = 0.0034316090611427757
Trained batch 113 in epoch 6, gen_loss = 0.5755501345061419, disc_loss = 0.003415556685802968
Trained batch 114 in epoch 6, gen_loss = 0.5754393466140912, disc_loss = 0.003401904264667436
Trained batch 115 in epoch 6, gen_loss = 0.5754303158871059, disc_loss = 0.003384736074528111
Trained batch 116 in epoch 6, gen_loss = 0.5754358821954483, disc_loss = 0.0033695042674612794
Trained batch 117 in epoch 6, gen_loss = 0.5754182220010434, disc_loss = 0.0033574711464313886
Trained batch 118 in epoch 6, gen_loss = 0.575358118580169, disc_loss = 0.003342771261906987
Trained batch 119 in epoch 6, gen_loss = 0.5752395855883757, disc_loss = 0.0033286224555922673
Trained batch 120 in epoch 6, gen_loss = 0.5751682064257377, disc_loss = 0.003313179243325202
Trained batch 121 in epoch 6, gen_loss = 0.5751089001776742, disc_loss = 0.003300808855813363
Trained batch 122 in epoch 6, gen_loss = 0.5749554297303766, disc_loss = 0.003287512155030135
Trained batch 123 in epoch 6, gen_loss = 0.5747248431847941, disc_loss = 0.0032760785261709844
Trained batch 124 in epoch 6, gen_loss = 0.5729745831489563, disc_loss = 0.003513153687119484
Trained batch 125 in epoch 6, gen_loss = 0.5736972438910651, disc_loss = 0.0035838687068058383
Trained batch 126 in epoch 6, gen_loss = 0.5745253933696296, disc_loss = 0.0036253449617056396
Trained batch 127 in epoch 6, gen_loss = 0.5748282880522311, disc_loss = 0.0036213366765878163
Trained batch 128 in epoch 6, gen_loss = 0.5747665471808855, disc_loss = 0.003617110562893425
Trained batch 129 in epoch 6, gen_loss = 0.5746907839408287, disc_loss = 0.00360654578006898
Trained batch 130 in epoch 6, gen_loss = 0.5745129994763672, disc_loss = 0.003594502591606201
Trained batch 131 in epoch 6, gen_loss = 0.5742902701551263, disc_loss = 0.003584266091682807
Trained batch 132 in epoch 6, gen_loss = 0.5740201769018531, disc_loss = 0.0035857318347333965
Trained batch 133 in epoch 6, gen_loss = 0.5738550335613649, disc_loss = 0.003572553576929356
Trained batch 134 in epoch 6, gen_loss = 0.5732564065191481, disc_loss = 0.003587047365942487
Trained batch 135 in epoch 6, gen_loss = 0.5730773263117847, disc_loss = 0.0035808589412173364
Trained batch 136 in epoch 6, gen_loss = 0.5737063514925268, disc_loss = 0.0035898470707292104
Trained batch 137 in epoch 6, gen_loss = 0.574133000512054, disc_loss = 0.00359001740867245
Trained batch 138 in epoch 6, gen_loss = 0.5742153032220525, disc_loss = 0.00358738736149004
Trained batch 139 in epoch 6, gen_loss = 0.5730716407299041, disc_loss = 0.003698259399139455
Trained batch 140 in epoch 6, gen_loss = 0.5733811077496684, disc_loss = 0.003696989806382157
Trained batch 141 in epoch 6, gen_loss = 0.5735611411887156, disc_loss = 0.0037514816044869137
Trained batch 142 in epoch 6, gen_loss = 0.5720212897220691, disc_loss = 0.003975384298816219
Trained batch 143 in epoch 6, gen_loss = 0.572634627421697, disc_loss = 0.004379240327074917
Trained batch 144 in epoch 6, gen_loss = 0.5726505830370147, disc_loss = 0.004377498885552431
Trained batch 145 in epoch 6, gen_loss = 0.570892380933239, disc_loss = 0.004707326930756234
Trained batch 146 in epoch 6, gen_loss = 0.5695133521443322, disc_loss = 0.004907053645041321
Trained batch 147 in epoch 6, gen_loss = 0.5706703513860703, disc_loss = 0.005112061626277864
Trained batch 148 in epoch 6, gen_loss = 0.5712251331182134, disc_loss = 0.00512595182197206
Trained batch 149 in epoch 6, gen_loss = 0.5712700486183167, disc_loss = 0.005148804361621539
Trained batch 150 in epoch 6, gen_loss = 0.5711637703788202, disc_loss = 0.005143192584398172
Trained batch 151 in epoch 6, gen_loss = 0.5711069126662455, disc_loss = 0.0051350463503408
Trained batch 152 in epoch 6, gen_loss = 0.5711071857439927, disc_loss = 0.00523882756904498
Trained batch 153 in epoch 6, gen_loss = 0.5707955170761455, disc_loss = 0.005249236675596179
Trained batch 154 in epoch 6, gen_loss = 0.5706189290169746, disc_loss = 0.005241324033047403
Trained batch 155 in epoch 6, gen_loss = 0.569744198750227, disc_loss = 0.005312436572216355
Trained batch 156 in epoch 6, gen_loss = 0.5709952632333063, disc_loss = 0.0053980425845499445
Trained batch 157 in epoch 6, gen_loss = 0.57170031644121, disc_loss = 0.005424244932040478
Trained batch 158 in epoch 6, gen_loss = 0.5718164717626272, disc_loss = 0.005416192259323204
Trained batch 159 in epoch 6, gen_loss = 0.5718498524278403, disc_loss = 0.005399457854218781
Trained batch 160 in epoch 6, gen_loss = 0.5718158694527904, disc_loss = 0.005379986072896245
Trained batch 161 in epoch 6, gen_loss = 0.5718721640698704, disc_loss = 0.005356897388004272
Trained batch 162 in epoch 6, gen_loss = 0.5719629493227766, disc_loss = 0.005332198313243139
Trained batch 163 in epoch 6, gen_loss = 0.5720712484383002, disc_loss = 0.0053134169706381944
Trained batch 164 in epoch 6, gen_loss = 0.5720767909830267, disc_loss = 0.005290774367467472
Trained batch 165 in epoch 6, gen_loss = 0.5721458684967224, disc_loss = 0.005269455561464855
Trained batch 166 in epoch 6, gen_loss = 0.572098468235153, disc_loss = 0.005251191320137572
Trained batch 167 in epoch 6, gen_loss = 0.5720422282105401, disc_loss = 0.005232733334109764
Trained batch 168 in epoch 6, gen_loss = 0.5720728558196119, disc_loss = 0.0052199771155234005
Trained batch 169 in epoch 6, gen_loss = 0.5720605050816255, disc_loss = 0.005206765211872099
Trained batch 170 in epoch 6, gen_loss = 0.5721164823275561, disc_loss = 0.0051869611951593335
Trained batch 171 in epoch 6, gen_loss = 0.572141581496527, disc_loss = 0.005164653122381762
Trained batch 172 in epoch 6, gen_loss = 0.5721630409273798, disc_loss = 0.005146060714288211
Trained batch 173 in epoch 6, gen_loss = 0.5721894084722147, disc_loss = 0.005127296434453121
Trained batch 174 in epoch 6, gen_loss = 0.57212822164808, disc_loss = 0.005105551501869091
Trained batch 175 in epoch 6, gen_loss = 0.5721615373410962, disc_loss = 0.005087056215746667
Trained batch 176 in epoch 6, gen_loss = 0.5721266124881593, disc_loss = 0.005068821894362737
Trained batch 177 in epoch 6, gen_loss = 0.5720791317773669, disc_loss = 0.005047600259847437
Trained batch 178 in epoch 6, gen_loss = 0.5720256097489895, disc_loss = 0.005027146200914789
Trained batch 179 in epoch 6, gen_loss = 0.5719565090205935, disc_loss = 0.005006716293024106
Trained batch 180 in epoch 6, gen_loss = 0.5719352160369494, disc_loss = 0.004986725420850581
Trained batch 181 in epoch 6, gen_loss = 0.5719416085835342, disc_loss = 0.004967582532317265
Trained batch 182 in epoch 6, gen_loss = 0.5719164606651973, disc_loss = 0.004948739188881031
Trained batch 183 in epoch 6, gen_loss = 0.5718229542607847, disc_loss = 0.004928393352716027
Trained batch 184 in epoch 6, gen_loss = 0.5717875876942197, disc_loss = 0.004909341066849191
Trained batch 185 in epoch 6, gen_loss = 0.5716984797549504, disc_loss = 0.004892763656674213
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 0.5500788688659668, disc_loss = 0.003257608041167259
Trained batch 1 in epoch 7, gen_loss = 0.5546543896198273, disc_loss = 0.002435700036585331
Trained batch 2 in epoch 7, gen_loss = 0.5564957857131958, disc_loss = 0.002389142755419016
Trained batch 3 in epoch 7, gen_loss = 0.5717615038156509, disc_loss = 0.0023839149507693946
Trained batch 4 in epoch 7, gen_loss = 0.56864333152771, disc_loss = 0.0023756644688546656
Trained batch 5 in epoch 7, gen_loss = 0.5709290901819865, disc_loss = 0.0023178935904676714
Trained batch 6 in epoch 7, gen_loss = 0.5694654158183506, disc_loss = 0.00228539840983493
Trained batch 7 in epoch 7, gen_loss = 0.5605692863464355, disc_loss = 0.002740427909884602
Trained batch 8 in epoch 7, gen_loss = 0.5686581532160441, disc_loss = 0.0029258988280263212
Trained batch 9 in epoch 7, gen_loss = 0.5697097182273865, disc_loss = 0.004236155701801181
Trained batch 10 in epoch 7, gen_loss = 0.5693324695933949, disc_loss = 0.004102340412580154
Trained batch 11 in epoch 7, gen_loss = 0.5334391395250956, disc_loss = 0.021315270976629108
Trained batch 12 in epoch 7, gen_loss = 0.5575178494820228, disc_loss = 0.04661805062698057
Trained batch 13 in epoch 7, gen_loss = 0.5386267559868949, disc_loss = 0.050036453192920556
Trained batch 14 in epoch 7, gen_loss = 0.5227421402931214, disc_loss = 0.05389758890184263
Trained batch 15 in epoch 7, gen_loss = 0.507451331242919, disc_loss = 0.06585666579485405
Trained batch 16 in epoch 7, gen_loss = 0.5115598352516398, disc_loss = 0.08737898263258531
Trained batch 17 in epoch 7, gen_loss = 0.5119781146446863, disc_loss = 0.09852018989881293
Trained batch 18 in epoch 7, gen_loss = 0.5032187261079487, disc_loss = 0.10242843506612669
Trained batch 19 in epoch 7, gen_loss = 0.4964705556631088, disc_loss = 0.10754490379476919
Trained batch 20 in epoch 7, gen_loss = 0.48703770410446895, disc_loss = 0.11316465795971453
Trained batch 21 in epoch 7, gen_loss = 0.4926786449822513, disc_loss = 0.11643586406187917
Trained batch 22 in epoch 7, gen_loss = 0.4928116306014683, disc_loss = 0.11518442530549415
Trained batch 23 in epoch 7, gen_loss = 0.488181268175443, disc_loss = 0.11286591223324649
Trained batch 24 in epoch 7, gen_loss = 0.4864598882198334, disc_loss = 0.11009646755643189
Trained batch 25 in epoch 7, gen_loss = 0.4836975530936168, disc_loss = 0.10737254783117141
Trained batch 26 in epoch 7, gen_loss = 0.4720871757577967, disc_loss = 0.11053213722900385
Trained batch 27 in epoch 7, gen_loss = 0.4723926622952734, disc_loss = 0.11294365219405986
Trained batch 28 in epoch 7, gen_loss = 0.4665425409530771, disc_loss = 0.11368501363803857
Trained batch 29 in epoch 7, gen_loss = 0.45787704885005953, disc_loss = 0.1156853777434056
Trained batch 30 in epoch 7, gen_loss = 0.457299078664472, disc_loss = 0.11496996324539425
Trained batch 31 in epoch 7, gen_loss = 0.45976218208670616, disc_loss = 0.11280744904797757
Trained batch 32 in epoch 7, gen_loss = 0.4638916506911769, disc_loss = 0.10971655192164083
Trained batch 33 in epoch 7, gen_loss = 0.4582520232481115, disc_loss = 0.10935851748731426
Trained batch 34 in epoch 7, gen_loss = 0.4619013633046831, disc_loss = 0.10820302764352943
Trained batch 35 in epoch 7, gen_loss = 0.4560663079222043, disc_loss = 0.1085210975789879
Trained batch 36 in epoch 7, gen_loss = 0.45598588763056574, disc_loss = 0.10895456084855706
Trained batch 37 in epoch 7, gen_loss = 0.44786860676188217, disc_loss = 0.11191116933294229
Trained batch 38 in epoch 7, gen_loss = 0.452641847041937, disc_loss = 0.11591311327468318
Trained batch 39 in epoch 7, gen_loss = 0.4446067616343498, disc_loss = 0.11949584514950402
Trained batch 40 in epoch 7, gen_loss = 0.43912817174341623, disc_loss = 0.12031129214390204
Trained batch 41 in epoch 7, gen_loss = 0.4386605503303664, disc_loss = 0.12125424254086933
Trained batch 42 in epoch 7, gen_loss = 0.4364964639724687, disc_loss = 0.12199197530334946
Trained batch 43 in epoch 7, gen_loss = 0.43325195901773195, disc_loss = 0.1225170536569997
Trained batch 44 in epoch 7, gen_loss = 0.4308392812808355, disc_loss = 0.12303118733171788
Trained batch 45 in epoch 7, gen_loss = 0.42967146537874057, disc_loss = 0.1233110757716729
Trained batch 46 in epoch 7, gen_loss = 0.4269988020049765, disc_loss = 0.12313684863236515
Trained batch 47 in epoch 7, gen_loss = 0.423512886899213, disc_loss = 0.12340149976565347
Trained batch 48 in epoch 7, gen_loss = 0.42061050479509393, disc_loss = 0.1239246264793815
Trained batch 49 in epoch 7, gen_loss = 0.41900561600923536, disc_loss = 0.12318898359779268
Trained batch 50 in epoch 7, gen_loss = 0.4191562810949251, disc_loss = 0.12182767874122981
Trained batch 51 in epoch 7, gen_loss = 0.4247014863559833, disc_loss = 0.12016996908306073
Trained batch 52 in epoch 7, gen_loss = 0.4197185537162817, disc_loss = 0.12245075849658053
Trained batch 53 in epoch 7, gen_loss = 0.4266438255155528, disc_loss = 0.12426115816062386
Trained batch 54 in epoch 7, gen_loss = 0.421805143085393, disc_loss = 0.1263484187635847
Trained batch 55 in epoch 7, gen_loss = 0.42443498729595114, disc_loss = 0.12615749581267924
Trained batch 56 in epoch 7, gen_loss = 0.4225062573688072, disc_loss = 0.12565071497259564
Trained batch 57 in epoch 7, gen_loss = 0.4212097651485739, disc_loss = 0.1253394033189799
Trained batch 58 in epoch 7, gen_loss = 0.42017746906159287, disc_loss = 0.12502382779730706
Trained batch 59 in epoch 7, gen_loss = 0.4190827759603659, disc_loss = 0.12401854453686004
Trained batch 60 in epoch 7, gen_loss = 0.4177554252206302, disc_loss = 0.12305194599416534
Trained batch 61 in epoch 7, gen_loss = 0.4182730199348542, disc_loss = 0.12228413811329031
Trained batch 62 in epoch 7, gen_loss = 0.4171753599057122, disc_loss = 0.12158602495707335
Trained batch 63 in epoch 7, gen_loss = 0.4162335505243391, disc_loss = 0.12142149483042886
Trained batch 64 in epoch 7, gen_loss = 0.4170092002703593, disc_loss = 0.1216601856231976
Trained batch 65 in epoch 7, gen_loss = 0.4155700168374813, disc_loss = 0.12170530592133715
Trained batch 66 in epoch 7, gen_loss = 0.41711379142839516, disc_loss = 0.12172760654921963
Trained batch 67 in epoch 7, gen_loss = 0.41367481539354606, disc_loss = 0.12290510608170949
Trained batch 68 in epoch 7, gen_loss = 0.41951579784137616, disc_loss = 0.12497607506879106
Trained batch 69 in epoch 7, gen_loss = 0.4150445120675223, disc_loss = 0.12919289370266987
Trained batch 70 in epoch 7, gen_loss = 0.4136783858420144, disc_loss = 0.12857049605546808
Trained batch 71 in epoch 7, gen_loss = 0.414881207048893, disc_loss = 0.12904389850963424
Trained batch 72 in epoch 7, gen_loss = 0.41298963476533757, disc_loss = 0.1288395773727855
Trained batch 73 in epoch 7, gen_loss = 0.4113047622345589, disc_loss = 0.12880657176877297
Trained batch 74 in epoch 7, gen_loss = 0.4105669951438904, disc_loss = 0.12840576148591937
Trained batch 75 in epoch 7, gen_loss = 0.40962767169663783, disc_loss = 0.12833404478825336
Trained batch 76 in epoch 7, gen_loss = 0.4091172872425674, disc_loss = 0.12766140850877702
Trained batch 77 in epoch 7, gen_loss = 0.4079546259763913, disc_loss = 0.12700286141345993
Trained batch 78 in epoch 7, gen_loss = 0.4079239768317983, disc_loss = 0.12624639005376662
Trained batch 79 in epoch 7, gen_loss = 0.4076955735683441, disc_loss = 0.12526371922867838
Trained batch 80 in epoch 7, gen_loss = 0.4098102825659293, disc_loss = 0.12569182776891982
Trained batch 81 in epoch 7, gen_loss = 0.40690744831794645, disc_loss = 0.12694946273582103
Trained batch 82 in epoch 7, gen_loss = 0.40545752034129867, disc_loss = 0.12720403251664555
Trained batch 83 in epoch 7, gen_loss = 0.4072866120508739, disc_loss = 0.12868671116164132
Trained batch 84 in epoch 7, gen_loss = 0.4042216171236599, disc_loss = 0.1301750179298003
Trained batch 85 in epoch 7, gen_loss = 0.40262317345585935, disc_loss = 0.1300358745989628
Trained batch 86 in epoch 7, gen_loss = 0.40270200714297677, disc_loss = 0.12988229598261244
Trained batch 87 in epoch 7, gen_loss = 0.4025254947218028, disc_loss = 0.12983262883128852
Trained batch 88 in epoch 7, gen_loss = 0.40183663334739345, disc_loss = 0.12942181968423172
Trained batch 89 in epoch 7, gen_loss = 0.4008979817231496, disc_loss = 0.12944188388323205
Trained batch 90 in epoch 7, gen_loss = 0.3998611569404602, disc_loss = 0.12891380248622006
Trained batch 91 in epoch 7, gen_loss = 0.40119867285956506, disc_loss = 0.1287391032421273
Trained batch 92 in epoch 7, gen_loss = 0.3995859395432216, disc_loss = 0.12850534344362396
Trained batch 93 in epoch 7, gen_loss = 0.39894043987101696, disc_loss = 0.1278230559521731
Trained batch 94 in epoch 7, gen_loss = 0.3991286343649814, disc_loss = 0.12768704206192572
Trained batch 95 in epoch 7, gen_loss = 0.39807317436983186, disc_loss = 0.12734381782017104
Trained batch 96 in epoch 7, gen_loss = 0.398980936438767, disc_loss = 0.12649900901380964
Trained batch 97 in epoch 7, gen_loss = 0.39897636126498787, disc_loss = 0.12585121725106194
Trained batch 98 in epoch 7, gen_loss = 0.3981985112633368, disc_loss = 0.12519332064042865
Trained batch 99 in epoch 7, gen_loss = 0.39982910692691803, disc_loss = 0.12525410046102478
Trained batch 100 in epoch 7, gen_loss = 0.3978568672543705, disc_loss = 0.1257295014433526
Trained batch 101 in epoch 7, gen_loss = 0.3974827297177969, disc_loss = 0.12523621135601298
Trained batch 102 in epoch 7, gen_loss = 0.3984482027951953, disc_loss = 0.12586013818367664
Trained batch 103 in epoch 7, gen_loss = 0.3964967163136372, disc_loss = 0.12630421558368163
Trained batch 104 in epoch 7, gen_loss = 0.3968986184824081, disc_loss = 0.12603458539760184
Trained batch 105 in epoch 7, gen_loss = 0.39672388642464046, disc_loss = 0.12590886094774348
Trained batch 106 in epoch 7, gen_loss = 0.3967739179312626, disc_loss = 0.12549823151126713
Trained batch 107 in epoch 7, gen_loss = 0.39772953810515227, disc_loss = 0.12469545770134707
Trained batch 108 in epoch 7, gen_loss = 0.39784868512678584, disc_loss = 0.12402422740893147
Trained batch 109 in epoch 7, gen_loss = 0.39929877763444727, disc_loss = 0.12319930813232945
Trained batch 110 in epoch 7, gen_loss = 0.4012042571295489, disc_loss = 0.12224716717704527
Trained batch 111 in epoch 7, gen_loss = 0.4035212506673166, disc_loss = 0.12143273213587236
Trained batch 112 in epoch 7, gen_loss = 0.40453224820373335, disc_loss = 0.12056317563844532
Trained batch 113 in epoch 7, gen_loss = 0.40608483788214234, disc_loss = 0.11963187735895381
Trained batch 114 in epoch 7, gen_loss = 0.40792585170787315, disc_loss = 0.11868352091709233
Trained batch 115 in epoch 7, gen_loss = 0.40894540810379487, disc_loss = 0.11773707851133278
Trained batch 116 in epoch 7, gen_loss = 0.4111095832453834, disc_loss = 0.11682783118369551
Trained batch 117 in epoch 7, gen_loss = 0.4103405942856255, disc_loss = 0.11633464154369055
Trained batch 118 in epoch 7, gen_loss = 0.41362349250737357, disc_loss = 0.11621957482230075
Trained batch 119 in epoch 7, gen_loss = 0.4146598197519779, disc_loss = 0.11537282581169468
Trained batch 120 in epoch 7, gen_loss = 0.41508433740001077, disc_loss = 0.11453750110154372
Trained batch 121 in epoch 7, gen_loss = 0.4163773142900623, disc_loss = 0.1136500679708437
Trained batch 122 in epoch 7, gen_loss = 0.4178731078054847, disc_loss = 0.11276346129531843
Trained batch 123 in epoch 7, gen_loss = 0.41926411659486834, disc_loss = 0.11189530551200733
Trained batch 124 in epoch 7, gen_loss = 0.42088008975982666, disc_loss = 0.11103419228084385
Trained batch 125 in epoch 7, gen_loss = 0.4222263480935778, disc_loss = 0.11017857952087763
Trained batch 126 in epoch 7, gen_loss = 0.4234417339009563, disc_loss = 0.10936789631139575
Trained batch 127 in epoch 7, gen_loss = 0.4238035664893687, disc_loss = 0.10861627105623484
Trained batch 128 in epoch 7, gen_loss = 0.42504650261975074, disc_loss = 0.10789734051497869
Trained batch 129 in epoch 7, gen_loss = 0.42512512826002563, disc_loss = 0.10721358818790087
Trained batch 130 in epoch 7, gen_loss = 0.4249119742681052, disc_loss = 0.10658779936551138
Trained batch 131 in epoch 7, gen_loss = 0.4262669639605464, disc_loss = 0.10633413479522322
Trained batch 132 in epoch 7, gen_loss = 0.4244904248113919, disc_loss = 0.10659745265554665
Trained batch 133 in epoch 7, gen_loss = 0.42469470658853875, disc_loss = 0.10605809078621331
Trained batch 134 in epoch 7, gen_loss = 0.426280215382576, disc_loss = 0.10564598419048168
Trained batch 135 in epoch 7, gen_loss = 0.42534392557161693, disc_loss = 0.10533884594983914
Trained batch 136 in epoch 7, gen_loss = 0.42519688878181205, disc_loss = 0.10491635291463267
Trained batch 137 in epoch 7, gen_loss = 0.42598810327657755, disc_loss = 0.10457560633295689
Trained batch 138 in epoch 7, gen_loss = 0.4254891343897195, disc_loss = 0.1041113646071163
Trained batch 139 in epoch 7, gen_loss = 0.42603582473737855, disc_loss = 0.10352458246052265
Trained batch 140 in epoch 7, gen_loss = 0.42743492665443017, disc_loss = 0.10294422133436017
Trained batch 141 in epoch 7, gen_loss = 0.42876232961114025, disc_loss = 0.10230153503919572
Trained batch 142 in epoch 7, gen_loss = 0.4293275195193457, disc_loss = 0.10165369199992685
Trained batch 143 in epoch 7, gen_loss = 0.43091612340261537, disc_loss = 0.1010753954696055
Trained batch 144 in epoch 7, gen_loss = 0.4319676176227372, disc_loss = 0.10046234620927737
Trained batch 145 in epoch 7, gen_loss = 0.432936149815174, disc_loss = 0.09982358079008145
Trained batch 146 in epoch 7, gen_loss = 0.43440990900101306, disc_loss = 0.09920130628572942
Trained batch 147 in epoch 7, gen_loss = 0.4327597370421564, disc_loss = 0.09950322515922724
Trained batch 148 in epoch 7, gen_loss = 0.433341641754112, disc_loss = 0.09949982965415057
Trained batch 149 in epoch 7, gen_loss = 0.43349654416243233, disc_loss = 0.09914746887050568
Trained batch 150 in epoch 7, gen_loss = 0.43438172439076256, disc_loss = 0.0985699423329769
Trained batch 151 in epoch 7, gen_loss = 0.4360007861335027, disc_loss = 0.09799782567547242
Trained batch 152 in epoch 7, gen_loss = 0.43727437791481516, disc_loss = 0.09742514035220143
Trained batch 153 in epoch 7, gen_loss = 0.43814323300665076, disc_loss = 0.09684891058676331
Trained batch 154 in epoch 7, gen_loss = 0.43891020724850316, disc_loss = 0.09637464250948641
Trained batch 155 in epoch 7, gen_loss = 0.4399895089176985, disc_loss = 0.09578479501084448
Trained batch 156 in epoch 7, gen_loss = 0.4413182186852595, disc_loss = 0.09519787666026004
Trained batch 157 in epoch 7, gen_loss = 0.4425214900623394, disc_loss = 0.09461699285886332
Trained batch 158 in epoch 7, gen_loss = 0.44355008530916656, disc_loss = 0.09432958700231411
Trained batch 159 in epoch 7, gen_loss = 0.443909222073853, disc_loss = 0.09382524891989305
Trained batch 160 in epoch 7, gen_loss = 0.4443725056900001, disc_loss = 0.0933284762645175
Trained batch 161 in epoch 7, gen_loss = 0.4454424140262015, disc_loss = 0.09278772902720964
Trained batch 162 in epoch 7, gen_loss = 0.446687787771225, disc_loss = 0.09224503823024638
Trained batch 163 in epoch 7, gen_loss = 0.44785591178550954, disc_loss = 0.09170396340352188
Trained batch 164 in epoch 7, gen_loss = 0.4487497913114952, disc_loss = 0.09116779960353266
Trained batch 165 in epoch 7, gen_loss = 0.449549304972212, disc_loss = 0.09064185934376914
Trained batch 166 in epoch 7, gen_loss = 0.45031002056812813, disc_loss = 0.09011258136252398
Trained batch 167 in epoch 7, gen_loss = 0.4511074233977568, disc_loss = 0.08959030047463741
Trained batch 168 in epoch 7, gen_loss = 0.4519536814393377, disc_loss = 0.08907202374570336
Trained batch 169 in epoch 7, gen_loss = 0.4527497486156576, disc_loss = 0.08856898059876746
Trained batch 170 in epoch 7, gen_loss = 0.4536499525719916, disc_loss = 0.0880662042331713
Trained batch 171 in epoch 7, gen_loss = 0.4544787391327148, disc_loss = 0.0875674431323247
Trained batch 172 in epoch 7, gen_loss = 0.4552591589489424, disc_loss = 0.08710773587038449
Trained batch 173 in epoch 7, gen_loss = 0.45589768800927305, disc_loss = 0.08662489929033079
Trained batch 174 in epoch 7, gen_loss = 0.456640008687973, disc_loss = 0.0861398816447971
Trained batch 175 in epoch 7, gen_loss = 0.45742116445167497, disc_loss = 0.08566000174521998
Trained batch 176 in epoch 7, gen_loss = 0.45818758364451134, disc_loss = 0.08518692892239466
Trained batch 177 in epoch 7, gen_loss = 0.4590066093742178, disc_loss = 0.08471964201706807
Trained batch 178 in epoch 7, gen_loss = 0.45978201351352244, disc_loss = 0.08425436853288085
Trained batch 179 in epoch 7, gen_loss = 0.46046941926081975, disc_loss = 0.08379583562814838
Trained batch 180 in epoch 7, gen_loss = 0.4612111826298645, disc_loss = 0.08334157851624988
Trained batch 181 in epoch 7, gen_loss = 0.4619039177567094, disc_loss = 0.08289230385587991
Trained batch 182 in epoch 7, gen_loss = 0.4626018494530454, disc_loss = 0.08247197397966752
Trained batch 183 in epoch 7, gen_loss = 0.4632621606730897, disc_loss = 0.0820393296390134
Trained batch 184 in epoch 7, gen_loss = 0.46378973351942526, disc_loss = 0.08162428062170039
Trained batch 185 in epoch 7, gen_loss = 0.4645153756744118, disc_loss = 0.08119788682476307
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 0.5969530940055847, disc_loss = 0.006573677994310856
Trained batch 1 in epoch 8, gen_loss = 0.5982686579227448, disc_loss = 0.005397508619353175
Trained batch 2 in epoch 8, gen_loss = 0.5984768271446228, disc_loss = 0.0043532402875522775
Trained batch 3 in epoch 8, gen_loss = 0.5956799238920212, disc_loss = 0.003839927667286247
Trained batch 4 in epoch 8, gen_loss = 0.5943711876869202, disc_loss = 0.003407779987901449
Trained batch 5 in epoch 8, gen_loss = 0.5940236548582712, disc_loss = 0.0030743115154715874
Trained batch 6 in epoch 8, gen_loss = 0.5927501235689435, disc_loss = 0.0028697639271350844
Trained batch 7 in epoch 8, gen_loss = 0.5926939845085144, disc_loss = 0.0027077075937995687
Trained batch 8 in epoch 8, gen_loss = 0.5925551917817857, disc_loss = 0.0027111622685980466
Trained batch 9 in epoch 8, gen_loss = 0.5916426181793213, disc_loss = 0.002601194311864674
Trained batch 10 in epoch 8, gen_loss = 0.5912467241287231, disc_loss = 0.0026468821716579523
Trained batch 11 in epoch 8, gen_loss = 0.5922490954399109, disc_loss = 0.0026268469324956336
Trained batch 12 in epoch 8, gen_loss = 0.5921361767328702, disc_loss = 0.0025978104318850315
Trained batch 13 in epoch 8, gen_loss = 0.591443977185658, disc_loss = 0.0025163936079479754
Trained batch 14 in epoch 8, gen_loss = 0.5904218633969625, disc_loss = 0.0024522564218689997
Trained batch 15 in epoch 8, gen_loss = 0.5899387411773205, disc_loss = 0.0024002404388738796
Trained batch 16 in epoch 8, gen_loss = 0.5911951590986813, disc_loss = 0.0023791999145246602
Trained batch 17 in epoch 8, gen_loss = 0.5925070146719614, disc_loss = 0.002378366318427854
Trained batch 18 in epoch 8, gen_loss = 0.5922041315781442, disc_loss = 0.002374430628199326
Trained batch 19 in epoch 8, gen_loss = 0.5916902005672455, disc_loss = 0.002388691809028387
Trained batch 20 in epoch 8, gen_loss = 0.5911079049110413, disc_loss = 0.0023731464032261144
Trained batch 21 in epoch 8, gen_loss = 0.5910215323621576, disc_loss = 0.0023435823756947434
Trained batch 22 in epoch 8, gen_loss = 0.5904847824055216, disc_loss = 0.0023140574947161517
Trained batch 23 in epoch 8, gen_loss = 0.5906439075867335, disc_loss = 0.0024132601198895522
Trained batch 24 in epoch 8, gen_loss = 0.590318078994751, disc_loss = 0.0023963495064526796
Trained batch 25 in epoch 8, gen_loss = 0.5897424450287452, disc_loss = 0.0023968010657252027
Trained batch 26 in epoch 8, gen_loss = 0.5902050733566284, disc_loss = 0.002375512978889876
Trained batch 27 in epoch 8, gen_loss = 0.5903262857879911, disc_loss = 0.002385142999368587
Trained batch 28 in epoch 8, gen_loss = 0.590572388007723, disc_loss = 0.002358487008364293
Trained batch 29 in epoch 8, gen_loss = 0.5904373268286387, disc_loss = 0.002359790257954349
Trained batch 30 in epoch 8, gen_loss = 0.5902660373718508, disc_loss = 0.0023366806900969915
Trained batch 31 in epoch 8, gen_loss = 0.5903489105403423, disc_loss = 0.002315213678230066
Trained batch 32 in epoch 8, gen_loss = 0.5904718565218376, disc_loss = 0.00229990575109806
Trained batch 33 in epoch 8, gen_loss = 0.5905306321733138, disc_loss = 0.002277357514043722
Trained batch 34 in epoch 8, gen_loss = 0.59062397309712, disc_loss = 0.002275583377507116
Trained batch 35 in epoch 8, gen_loss = 0.590054515335295, disc_loss = 0.0022523142526754076
Trained batch 36 in epoch 8, gen_loss = 0.5901276292027654, disc_loss = 0.0022741010462915576
Trained batch 37 in epoch 8, gen_loss = 0.5906170543871427, disc_loss = 0.0022661211091632907
Trained batch 38 in epoch 8, gen_loss = 0.590933471153944, disc_loss = 0.0022425451345789507
Trained batch 39 in epoch 8, gen_loss = 0.5909926816821098, disc_loss = 0.002254245107178576
Trained batch 40 in epoch 8, gen_loss = 0.5907271955071426, disc_loss = 0.0022326780414981084
Trained batch 41 in epoch 8, gen_loss = 0.5902741196609679, disc_loss = 0.0022119784345185117
Trained batch 42 in epoch 8, gen_loss = 0.5900260584298954, disc_loss = 0.0021905023144384804
Trained batch 43 in epoch 8, gen_loss = 0.5900912000374361, disc_loss = 0.0021928498092827135
Trained batch 44 in epoch 8, gen_loss = 0.5903405878278944, disc_loss = 0.0021895012171525095
Trained batch 45 in epoch 8, gen_loss = 0.5902860968009286, disc_loss = 0.0021817133858111565
Trained batch 46 in epoch 8, gen_loss = 0.5902507152963192, disc_loss = 0.0021640111895357356
Trained batch 47 in epoch 8, gen_loss = 0.5898803845047951, disc_loss = 0.002152338119534155
Trained batch 48 in epoch 8, gen_loss = 0.5897444961022358, disc_loss = 0.002135315931364134
Trained batch 49 in epoch 8, gen_loss = 0.5896605348587036, disc_loss = 0.0021355664101429285
Trained batch 50 in epoch 8, gen_loss = 0.5898139254719603, disc_loss = 0.002140064662158051
Trained batch 51 in epoch 8, gen_loss = 0.5903656448309238, disc_loss = 0.002151410491653503
Trained batch 52 in epoch 8, gen_loss = 0.5907872780314032, disc_loss = 0.00214780322583568
Trained batch 53 in epoch 8, gen_loss = 0.590479415875894, disc_loss = 0.002134960884211102
Trained batch 54 in epoch 8, gen_loss = 0.5903335105289113, disc_loss = 0.002123213133944029
Trained batch 55 in epoch 8, gen_loss = 0.5902139097452164, disc_loss = 0.002107554897000747
Trained batch 56 in epoch 8, gen_loss = 0.5901902014749092, disc_loss = 0.0020997531368936364
Trained batch 57 in epoch 8, gen_loss = 0.590196640327059, disc_loss = 0.0020860094669403442
Trained batch 58 in epoch 8, gen_loss = 0.5903648138046265, disc_loss = 0.0020747359988074433
Trained batch 59 in epoch 8, gen_loss = 0.5902582546075185, disc_loss = 0.0020652465522289277
Trained batch 60 in epoch 8, gen_loss = 0.5900927772287463, disc_loss = 0.002055694072385181
Trained batch 61 in epoch 8, gen_loss = 0.5900980051486723, disc_loss = 0.002045143082092005
Trained batch 62 in epoch 8, gen_loss = 0.5902745827795968, disc_loss = 0.0020349747445877818
Trained batch 63 in epoch 8, gen_loss = 0.5905461153015494, disc_loss = 0.002026679096161388
Trained batch 64 in epoch 8, gen_loss = 0.5905247349005479, disc_loss = 0.0020173461355555517
Trained batch 65 in epoch 8, gen_loss = 0.5904965617439963, disc_loss = 0.0020065054713720174
Trained batch 66 in epoch 8, gen_loss = 0.5904702766617732, disc_loss = 0.0020040104412404236
Trained batch 67 in epoch 8, gen_loss = 0.5905061951454948, disc_loss = 0.001996347720063675
Trained batch 68 in epoch 8, gen_loss = 0.5905394839203876, disc_loss = 0.0019869706644069242
Trained batch 69 in epoch 8, gen_loss = 0.5905217238834926, disc_loss = 0.0019765855611435005
Trained batch 70 in epoch 8, gen_loss = 0.5905513981698265, disc_loss = 0.0019795655495893788
Trained batch 71 in epoch 8, gen_loss = 0.5906164116329617, disc_loss = 0.0019712511049066153
Trained batch 72 in epoch 8, gen_loss = 0.5906485858028883, disc_loss = 0.001962142782796123
Trained batch 73 in epoch 8, gen_loss = 0.5905923972258696, disc_loss = 0.0019520210429421953
Trained batch 74 in epoch 8, gen_loss = 0.5903017481168111, disc_loss = 0.0019478752200181285
Trained batch 75 in epoch 8, gen_loss = 0.5903060365664331, disc_loss = 0.0019355144345593687
Trained batch 76 in epoch 8, gen_loss = 0.5905612707138062, disc_loss = 0.0019287401477673224
Trained batch 77 in epoch 8, gen_loss = 0.5905402165192825, disc_loss = 0.0019174823268818168
Trained batch 78 in epoch 8, gen_loss = 0.5905672922919069, disc_loss = 0.00195261400747054
Trained batch 79 in epoch 8, gen_loss = 0.5903308756649495, disc_loss = 0.0019468918471829966
Trained batch 80 in epoch 8, gen_loss = 0.5901252465483583, disc_loss = 0.001953105008183622
Trained batch 81 in epoch 8, gen_loss = 0.5901653548566307, disc_loss = 0.0019502659561112523
Trained batch 82 in epoch 8, gen_loss = 0.5902109016855079, disc_loss = 0.0019430979183055908
Trained batch 83 in epoch 8, gen_loss = 0.5902172433478492, disc_loss = 0.0019505206201713356
Trained batch 84 in epoch 8, gen_loss = 0.5903382588835323, disc_loss = 0.0019420863471596556
Trained batch 85 in epoch 8, gen_loss = 0.590580087068469, disc_loss = 0.001945094033523441
Trained batch 86 in epoch 8, gen_loss = 0.590621306978423, disc_loss = 0.0019410628003828313
Trained batch 87 in epoch 8, gen_loss = 0.5906876203688708, disc_loss = 0.0019338036760349166
Trained batch 88 in epoch 8, gen_loss = 0.5906964587361625, disc_loss = 0.0019326912124086632
Trained batch 89 in epoch 8, gen_loss = 0.5906808793544769, disc_loss = 0.001927548139873478
Trained batch 90 in epoch 8, gen_loss = 0.5906834366557362, disc_loss = 0.0019191208955637374
Trained batch 91 in epoch 8, gen_loss = 0.5907208129115726, disc_loss = 0.001940747750821807
Trained batch 92 in epoch 8, gen_loss = 0.5905631075623214, disc_loss = 0.0019438742229374506
Trained batch 93 in epoch 8, gen_loss = 0.5905632604943946, disc_loss = 0.001944400092705767
Trained batch 94 in epoch 8, gen_loss = 0.5903939196937963, disc_loss = 0.0019426304197527075
Trained batch 95 in epoch 8, gen_loss = 0.5903709679841995, disc_loss = 0.0019543272052639318
Trained batch 96 in epoch 8, gen_loss = 0.5904308170387426, disc_loss = 0.001952460023680145
Trained batch 97 in epoch 8, gen_loss = 0.5902356341177103, disc_loss = 0.001981798723359041
Trained batch 98 in epoch 8, gen_loss = 0.5910198200832714, disc_loss = 0.0020501592097747507
Trained batch 99 in epoch 8, gen_loss = 0.5906989574432373, disc_loss = 0.0020927769667468967
Trained batch 100 in epoch 8, gen_loss = 0.5889147410888483, disc_loss = 0.002280324289464567
Trained batch 101 in epoch 8, gen_loss = 0.5901424613069085, disc_loss = 0.002352610009028485
Trained batch 102 in epoch 8, gen_loss = 0.5909858528271462, disc_loss = 0.0024339309644894405
Trained batch 103 in epoch 8, gen_loss = 0.5910822402399319, disc_loss = 0.0024357364947298686
Trained batch 104 in epoch 8, gen_loss = 0.5908204439140502, disc_loss = 0.0024659712776719106
Trained batch 105 in epoch 8, gen_loss = 0.5907599866952536, disc_loss = 0.00246306828811835
Trained batch 106 in epoch 8, gen_loss = 0.5906136952270972, disc_loss = 0.002453583390582527
Trained batch 107 in epoch 8, gen_loss = 0.5908994020687209, disc_loss = 0.0024475301421868303
Trained batch 108 in epoch 8, gen_loss = 0.5910425128739908, disc_loss = 0.002437948289865611
Trained batch 109 in epoch 8, gen_loss = 0.5910864973610098, disc_loss = 0.002428619390014898
Trained batch 110 in epoch 8, gen_loss = 0.5911252442243937, disc_loss = 0.002428942737547127
Trained batch 111 in epoch 8, gen_loss = 0.5911502106381314, disc_loss = 0.002422317363587873
Trained batch 112 in epoch 8, gen_loss = 0.5911387561169346, disc_loss = 0.0024127938549767815
Trained batch 113 in epoch 8, gen_loss = 0.591022609880096, disc_loss = 0.0024056402433320486
Trained batch 114 in epoch 8, gen_loss = 0.5910933352035025, disc_loss = 0.0024027218768859038
Trained batch 115 in epoch 8, gen_loss = 0.5911908938453115, disc_loss = 0.0023989606185029423
Trained batch 116 in epoch 8, gen_loss = 0.5913180752187712, disc_loss = 0.002400550329619939
Trained batch 117 in epoch 8, gen_loss = 0.5914089530706406, disc_loss = 0.0023954365120300927
Trained batch 118 in epoch 8, gen_loss = 0.5915877751442564, disc_loss = 0.0023895801894147604
Trained batch 119 in epoch 8, gen_loss = 0.5916192861894767, disc_loss = 0.0023810804511109986
Trained batch 120 in epoch 8, gen_loss = 0.5917669694778348, disc_loss = 0.002373389639960956
Trained batch 121 in epoch 8, gen_loss = 0.5917847867383331, disc_loss = 0.0023681215243414044
Trained batch 122 in epoch 8, gen_loss = 0.5918357592772662, disc_loss = 0.002359528463651858
Trained batch 123 in epoch 8, gen_loss = 0.5918618274792549, disc_loss = 0.002358612606316925
Trained batch 124 in epoch 8, gen_loss = 0.5919450299739838, disc_loss = 0.0023569879289716484
Trained batch 125 in epoch 8, gen_loss = 0.5919108407364951, disc_loss = 0.0023487876853092557
Trained batch 126 in epoch 8, gen_loss = 0.5919265467820205, disc_loss = 0.0023423879972006394
Trained batch 127 in epoch 8, gen_loss = 0.5920452082064003, disc_loss = 0.0023333178814937128
Trained batch 128 in epoch 8, gen_loss = 0.5920790283716926, disc_loss = 0.002325339810453471
Trained batch 129 in epoch 8, gen_loss = 0.592163587304262, disc_loss = 0.002319158945017709
Trained batch 130 in epoch 8, gen_loss = 0.5920524640392711, disc_loss = 0.0023127821636677696
Trained batch 131 in epoch 8, gen_loss = 0.5920358907544252, disc_loss = 0.002311995877376334
Trained batch 132 in epoch 8, gen_loss = 0.5919879381369827, disc_loss = 0.002303339868321791
Trained batch 133 in epoch 8, gen_loss = 0.591989030811324, disc_loss = 0.002295529539349364
Trained batch 134 in epoch 8, gen_loss = 0.5920717237172304, disc_loss = 0.002309376132433061
Trained batch 135 in epoch 8, gen_loss = 0.5920319283271537, disc_loss = 0.002307356475605903
Trained batch 136 in epoch 8, gen_loss = 0.5920684204919495, disc_loss = 0.002305370162370322
Trained batch 137 in epoch 8, gen_loss = 0.5922523518835289, disc_loss = 0.0022993886419841883
Trained batch 138 in epoch 8, gen_loss = 0.5924244975443367, disc_loss = 0.002292631631181073
Trained batch 139 in epoch 8, gen_loss = 0.5925412895424026, disc_loss = 0.0022861039706705403
Trained batch 140 in epoch 8, gen_loss = 0.5925417599525857, disc_loss = 0.002279198700430017
Trained batch 141 in epoch 8, gen_loss = 0.5925137604206381, disc_loss = 0.002283725397280929
Trained batch 142 in epoch 8, gen_loss = 0.5924224672200796, disc_loss = 0.002280544842124454
Trained batch 143 in epoch 8, gen_loss = 0.5923617438723644, disc_loss = 0.002273603492034858
Trained batch 144 in epoch 8, gen_loss = 0.5924805071847192, disc_loss = 0.002274152540987165
Trained batch 145 in epoch 8, gen_loss = 0.592613763801039, disc_loss = 0.002270504162480978
Trained batch 146 in epoch 8, gen_loss = 0.592581161228167, disc_loss = 0.0022656902746886623
Trained batch 147 in epoch 8, gen_loss = 0.5926629173997287, disc_loss = 0.002257911494706531
Trained batch 148 in epoch 8, gen_loss = 0.5927374516957559, disc_loss = 0.002250036829457487
Trained batch 149 in epoch 8, gen_loss = 0.5927758663892746, disc_loss = 0.0022449428914114835
Trained batch 150 in epoch 8, gen_loss = 0.5928167758003765, disc_loss = 0.00224069802287892
Trained batch 151 in epoch 8, gen_loss = 0.5928632226821623, disc_loss = 0.0022340865888461274
Trained batch 152 in epoch 8, gen_loss = 0.5928415432085399, disc_loss = 0.00223033994838011
Trained batch 153 in epoch 8, gen_loss = 0.5928496561654202, disc_loss = 0.002224816211995173
Trained batch 154 in epoch 8, gen_loss = 0.5929298202837667, disc_loss = 0.0022228287968544228
Trained batch 155 in epoch 8, gen_loss = 0.5930226072669029, disc_loss = 0.002215464030786489
Trained batch 156 in epoch 8, gen_loss = 0.593008697982047, disc_loss = 0.0022088716616320194
Trained batch 157 in epoch 8, gen_loss = 0.5929868698497361, disc_loss = 0.0022020786661725443
Trained batch 158 in epoch 8, gen_loss = 0.5929708107837341, disc_loss = 0.0021949922314511154
Trained batch 159 in epoch 8, gen_loss = 0.5929908039048314, disc_loss = 0.0021871254313737152
Trained batch 160 in epoch 8, gen_loss = 0.5930661979299154, disc_loss = 0.0021811618834086085
Trained batch 161 in epoch 8, gen_loss = 0.5930454081591264, disc_loss = 0.002177291323379096
Trained batch 162 in epoch 8, gen_loss = 0.5929764807224274, disc_loss = 0.0021722930350678007
Trained batch 163 in epoch 8, gen_loss = 0.592953057369081, disc_loss = 0.0021654479581828616
Trained batch 164 in epoch 8, gen_loss = 0.5929179193395557, disc_loss = 0.0021619579077444295
Trained batch 165 in epoch 8, gen_loss = 0.5929537988211735, disc_loss = 0.002155609078234039
Trained batch 166 in epoch 8, gen_loss = 0.5930554786485113, disc_loss = 0.002150060618742408
Trained batch 167 in epoch 8, gen_loss = 0.5929917865211055, disc_loss = 0.0021451935456189815
Trained batch 168 in epoch 8, gen_loss = 0.592970208479808, disc_loss = 0.002139352625043038
Trained batch 169 in epoch 8, gen_loss = 0.5927758674411213, disc_loss = 0.0021400369066909395
Trained batch 170 in epoch 8, gen_loss = 0.5931095848655143, disc_loss = 0.0021442078504635143
Trained batch 171 in epoch 8, gen_loss = 0.5934202343572018, disc_loss = 0.0021448986067404145
Trained batch 172 in epoch 8, gen_loss = 0.5933722304126431, disc_loss = 0.002141465605882594
Trained batch 173 in epoch 8, gen_loss = 0.5931967488308062, disc_loss = 0.002140272781386672
Trained batch 174 in epoch 8, gen_loss = 0.5931246513979775, disc_loss = 0.0021455360742818033
Trained batch 175 in epoch 8, gen_loss = 0.5930781684477221, disc_loss = 0.002140625909801615
Trained batch 176 in epoch 8, gen_loss = 0.5930949730724938, disc_loss = 0.0021370736359865904
Trained batch 177 in epoch 8, gen_loss = 0.593176935663384, disc_loss = 0.0021321362661448923
Trained batch 178 in epoch 8, gen_loss = 0.5931427743514823, disc_loss = 0.0021287152574881495
Trained batch 179 in epoch 8, gen_loss = 0.5930939699212711, disc_loss = 0.002129358896571729
Trained batch 180 in epoch 8, gen_loss = 0.5932746755154752, disc_loss = 0.002128591797011004
Trained batch 181 in epoch 8, gen_loss = 0.5933821707308947, disc_loss = 0.0021252124212109125
Trained batch 182 in epoch 8, gen_loss = 0.5933923762027031, disc_loss = 0.002118931855189568
Trained batch 183 in epoch 8, gen_loss = 0.5933354394915311, disc_loss = 0.0021133961598262313
Trained batch 184 in epoch 8, gen_loss = 0.5932403933357548, disc_loss = 0.0021087506625524447
Trained batch 185 in epoch 8, gen_loss = 0.5932372028148303, disc_loss = 0.002103559467853898
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 0.5904049873352051, disc_loss = 0.0010292755905538797
Trained batch 1 in epoch 9, gen_loss = 0.5917327404022217, disc_loss = 0.0010243527358397841
Trained batch 2 in epoch 9, gen_loss = 0.5920084913571676, disc_loss = 0.0011752128290633361
Trained batch 3 in epoch 9, gen_loss = 0.5901033133268356, disc_loss = 0.0011850091977976263
Trained batch 4 in epoch 9, gen_loss = 0.5875541925430298, disc_loss = 0.0012111512478441
Trained batch 5 in epoch 9, gen_loss = 0.5905041694641113, disc_loss = 0.0011737318515467148
Trained batch 6 in epoch 9, gen_loss = 0.5906312721116203, disc_loss = 0.0013737836686362112
Trained batch 7 in epoch 9, gen_loss = 0.5900563821196556, disc_loss = 0.0013263895234558731
Trained batch 8 in epoch 9, gen_loss = 0.5890491472350227, disc_loss = 0.0013244703877717257
Trained batch 9 in epoch 9, gen_loss = 0.589488285779953, disc_loss = 0.0013450560625642538
Trained batch 10 in epoch 9, gen_loss = 0.5889834328131243, disc_loss = 0.0013099446554075587
Trained batch 11 in epoch 9, gen_loss = 0.5895311236381531, disc_loss = 0.001298753049923107
Trained batch 12 in epoch 9, gen_loss = 0.5902453019068792, disc_loss = 0.0012657719735915845
Trained batch 13 in epoch 9, gen_loss = 0.5907645310674395, disc_loss = 0.0012521960639527866
Trained batch 14 in epoch 9, gen_loss = 0.5913771351178487, disc_loss = 0.0012374864425510168
Trained batch 15 in epoch 9, gen_loss = 0.5908199027180672, disc_loss = 0.001229525645612739
Trained batch 16 in epoch 9, gen_loss = 0.5909303637111888, disc_loss = 0.0012227869592607021
Trained batch 17 in epoch 9, gen_loss = 0.5913191272152795, disc_loss = 0.001249689298371474
Trained batch 18 in epoch 9, gen_loss = 0.5910190751678065, disc_loss = 0.001237949099097597
Trained batch 19 in epoch 9, gen_loss = 0.590423509478569, disc_loss = 0.0012468327360693366
Trained batch 20 in epoch 9, gen_loss = 0.5903670816194444, disc_loss = 0.0012506810349545308
Trained batch 21 in epoch 9, gen_loss = 0.5908311605453491, disc_loss = 0.001234906035030938
Trained batch 22 in epoch 9, gen_loss = 0.5915149553962376, disc_loss = 0.001239411601209608
Trained batch 23 in epoch 9, gen_loss = 0.591575545569261, disc_loss = 0.001227234308316838
Trained batch 24 in epoch 9, gen_loss = 0.5916184616088868, disc_loss = 0.0012161019234918058
Trained batch 25 in epoch 9, gen_loss = 0.5914878455492166, disc_loss = 0.0012093933339481456
Trained batch 26 in epoch 9, gen_loss = 0.5914139306103742, disc_loss = 0.0011950096210326861
Trained batch 27 in epoch 9, gen_loss = 0.5911346908126559, disc_loss = 0.0011812327512806015
Trained batch 28 in epoch 9, gen_loss = 0.5910417252573473, disc_loss = 0.0011803767210322208
Trained batch 29 in epoch 9, gen_loss = 0.5913796365261078, disc_loss = 0.0012098983628675342
Trained batch 30 in epoch 9, gen_loss = 0.5912929234966156, disc_loss = 0.0012184229056020417
Trained batch 31 in epoch 9, gen_loss = 0.5910504423081875, disc_loss = 0.0012168012945039663
Trained batch 32 in epoch 9, gen_loss = 0.5903531168446396, disc_loss = 0.0012408552204512737
Trained batch 33 in epoch 9, gen_loss = 0.590557336807251, disc_loss = 0.0012565170763991773
Trained batch 34 in epoch 9, gen_loss = 0.5905656814575195, disc_loss = 0.001256270134555442
Trained batch 35 in epoch 9, gen_loss = 0.5901441110504998, disc_loss = 0.0012511786286874365
Trained batch 36 in epoch 9, gen_loss = 0.5899733739930231, disc_loss = 0.0012471657277814843
Trained batch 37 in epoch 9, gen_loss = 0.5900775664731076, disc_loss = 0.0012464980735737634
Trained batch 38 in epoch 9, gen_loss = 0.5901047893059559, disc_loss = 0.0012479074872457064
Trained batch 39 in epoch 9, gen_loss = 0.589849354326725, disc_loss = 0.0012435997719876467
Trained batch 40 in epoch 9, gen_loss = 0.5895313271662084, disc_loss = 0.0012501213052196474
Trained batch 41 in epoch 9, gen_loss = 0.588967353105545, disc_loss = 0.0012481286567414091
Trained batch 42 in epoch 9, gen_loss = 0.5866429313670757, disc_loss = 0.0014221892518879369
Trained batch 43 in epoch 9, gen_loss = 0.5870795148340139, disc_loss = 0.001505294423127039
Trained batch 44 in epoch 9, gen_loss = 0.5850047568480173, disc_loss = 0.0016085773189034728
Trained batch 45 in epoch 9, gen_loss = 0.5843080159114755, disc_loss = 0.0016797170873083498
Trained batch 46 in epoch 9, gen_loss = 0.5863783847778401, disc_loss = 0.0017928667663735277
Trained batch 47 in epoch 9, gen_loss = 0.5874906821797291, disc_loss = 0.001875129926096027
Trained batch 48 in epoch 9, gen_loss = 0.5870093003827699, disc_loss = 0.0019053828912045882
Trained batch 49 in epoch 9, gen_loss = 0.5859177929162979, disc_loss = 0.0020603730669245123
Trained batch 50 in epoch 9, gen_loss = 0.5854169393286985, disc_loss = 0.0020646783568914616
Trained batch 51 in epoch 9, gen_loss = 0.5856572120235517, disc_loss = 0.0020993687794543803
Trained batch 52 in epoch 9, gen_loss = 0.5851156829663042, disc_loss = 0.0021209907146908765
Trained batch 53 in epoch 9, gen_loss = 0.5847125014773121, disc_loss = 0.002121641154021577
Trained batch 54 in epoch 9, gen_loss = 0.5844955601475456, disc_loss = 0.0021131366618316284
Trained batch 55 in epoch 9, gen_loss = 0.585701694978135, disc_loss = 0.002159546790478219
Trained batch 56 in epoch 9, gen_loss = 0.5851847304586779, disc_loss = 0.0021606163375014276
Trained batch 57 in epoch 9, gen_loss = 0.5848362039903114, disc_loss = 0.0021596034378584088
Trained batch 58 in epoch 9, gen_loss = 0.5848256293999947, disc_loss = 0.0021478013230203574
Trained batch 59 in epoch 9, gen_loss = 0.5851726507147154, disc_loss = 0.0021387826767750085
Trained batch 60 in epoch 9, gen_loss = 0.584982631147885, disc_loss = 0.0021468540691755343
Trained batch 61 in epoch 9, gen_loss = 0.5845280582866361, disc_loss = 0.002148493512293264
Trained batch 62 in epoch 9, gen_loss = 0.5845229195223914, disc_loss = 0.002136915297587476
Trained batch 63 in epoch 9, gen_loss = 0.584500000346452, disc_loss = 0.0021277428622852312
Trained batch 64 in epoch 9, gen_loss = 0.5844102598153628, disc_loss = 0.002114037125228116
Trained batch 65 in epoch 9, gen_loss = 0.584055709567937, disc_loss = 0.002128747963896868
Trained batch 66 in epoch 9, gen_loss = 0.5838537220634631, disc_loss = 0.0021218951225086156
Trained batch 67 in epoch 9, gen_loss = 0.5843040062224164, disc_loss = 0.002115570397376466
Trained batch 68 in epoch 9, gen_loss = 0.5840363688227059, disc_loss = 0.002104923935553086
Trained batch 69 in epoch 9, gen_loss = 0.5835983748946871, disc_loss = 0.0021001506946049632
Trained batch 70 in epoch 9, gen_loss = 0.5832572466051075, disc_loss = 0.0021055683798589546
Trained batch 71 in epoch 9, gen_loss = 0.5830507564047972, disc_loss = 0.0021052198668864244
Trained batch 72 in epoch 9, gen_loss = 0.583663965332998, disc_loss = 0.00213307089472113
Trained batch 73 in epoch 9, gen_loss = 0.5827341260942253, disc_loss = 0.0021502666751149336
Trained batch 74 in epoch 9, gen_loss = 0.5821611416339875, disc_loss = 0.0021764844950909416
Trained batch 75 in epoch 9, gen_loss = 0.5851217237742323, disc_loss = 0.002422595548284191
Trained batch 76 in epoch 9, gen_loss = 0.5864940490815547, disc_loss = 0.002467106318693947
Trained batch 77 in epoch 9, gen_loss = 0.5866499508802707, disc_loss = 0.002500258695083455
Trained batch 78 in epoch 9, gen_loss = 0.58663348268859, disc_loss = 0.0025210100435357117
Trained batch 79 in epoch 9, gen_loss = 0.5867865961045027, disc_loss = 0.0025178272146149537
Trained batch 80 in epoch 9, gen_loss = 0.5870417087902258, disc_loss = 0.002506870467411239
Trained batch 81 in epoch 9, gen_loss = 0.5874099982220952, disc_loss = 0.002500747408570222
Trained batch 82 in epoch 9, gen_loss = 0.5875765376062279, disc_loss = 0.0024876231005056255
Trained batch 83 in epoch 9, gen_loss = 0.5875680286969457, disc_loss = 0.002474254037397692
Trained batch 84 in epoch 9, gen_loss = 0.5876818358898163, disc_loss = 0.002457171427907751
Trained batch 85 in epoch 9, gen_loss = 0.5877115154682204, disc_loss = 0.002446355166855853
Trained batch 86 in epoch 9, gen_loss = 0.587634497332847, disc_loss = 0.0024297291843820065
Trained batch 87 in epoch 9, gen_loss = 0.587614412673495, disc_loss = 0.002412492720891764
Trained batch 88 in epoch 9, gen_loss = 0.5875922920328848, disc_loss = 0.0024025205966200303
Trained batch 89 in epoch 9, gen_loss = 0.5877361201577717, disc_loss = 0.0023991742216619765
Trained batch 90 in epoch 9, gen_loss = 0.5876500996259543, disc_loss = 0.002381943336401421
Trained batch 91 in epoch 9, gen_loss = 0.5875782386764236, disc_loss = 0.0023661282997952935
Trained batch 92 in epoch 9, gen_loss = 0.5874537662152322, disc_loss = 0.002358274672666104
Trained batch 93 in epoch 9, gen_loss = 0.5875538508308694, disc_loss = 0.0023535421394316994
Trained batch 94 in epoch 9, gen_loss = 0.5874889841205195, disc_loss = 0.0023389933428629057
Trained batch 95 in epoch 9, gen_loss = 0.5874680420383811, disc_loss = 0.00234135011548157
Trained batch 96 in epoch 9, gen_loss = 0.5872532046332801, disc_loss = 0.0023285553510992104
Trained batch 97 in epoch 9, gen_loss = 0.5871497784950295, disc_loss = 0.002322017116001712
Trained batch 98 in epoch 9, gen_loss = 0.5871231041171334, disc_loss = 0.0023116450551003594
Trained batch 99 in epoch 9, gen_loss = 0.5872726705670357, disc_loss = 0.0022998418885981664
Trained batch 100 in epoch 9, gen_loss = 0.5873208332179797, disc_loss = 0.002321065006441077
Trained batch 101 in epoch 9, gen_loss = 0.5870188910002802, disc_loss = 0.002314366140590031
Trained batch 102 in epoch 9, gen_loss = 0.5868385303946375, disc_loss = 0.0023121649622058187
Trained batch 103 in epoch 9, gen_loss = 0.5868390933252298, disc_loss = 0.002306697857140814
Trained batch 104 in epoch 9, gen_loss = 0.5868413950715746, disc_loss = 0.0022949992285464845
Trained batch 105 in epoch 9, gen_loss = 0.586821622162495, disc_loss = 0.002281284572025058
Trained batch 106 in epoch 9, gen_loss = 0.5866990638113467, disc_loss = 0.0022701695719168076
Trained batch 107 in epoch 9, gen_loss = 0.586657109911795, disc_loss = 0.0022598380040748183
Trained batch 108 in epoch 9, gen_loss = 0.5867185661005317, disc_loss = 0.0022478400624929627
Trained batch 109 in epoch 9, gen_loss = 0.5868608011440797, disc_loss = 0.0022401048516092655
Trained batch 110 in epoch 9, gen_loss = 0.5867551396021972, disc_loss = 0.0022294566691811154
Trained batch 111 in epoch 9, gen_loss = 0.5864941331424883, disc_loss = 0.0022316236458469313
Trained batch 112 in epoch 9, gen_loss = 0.5864743761784208, disc_loss = 0.002221798619041137
Trained batch 113 in epoch 9, gen_loss = 0.586550080201082, disc_loss = 0.0022094568973938166
Trained batch 114 in epoch 9, gen_loss = 0.5864706803923068, disc_loss = 0.0021977724213881984
Trained batch 115 in epoch 9, gen_loss = 0.5864603429518896, disc_loss = 0.002185954815700072
Trained batch 116 in epoch 9, gen_loss = 0.5863372930604168, disc_loss = 0.0021737933842441402
Trained batch 117 in epoch 9, gen_loss = 0.5862406964524317, disc_loss = 0.0021626755838890133
Trained batch 118 in epoch 9, gen_loss = 0.5861294627690515, disc_loss = 0.002151340480987765
Trained batch 119 in epoch 9, gen_loss = 0.5860342668990294, disc_loss = 0.0021409634976104525
Trained batch 120 in epoch 9, gen_loss = 0.5859228015438585, disc_loss = 0.0021318546515573895
Trained batch 121 in epoch 9, gen_loss = 0.5858937729088987, disc_loss = 0.0021251070343690816
Trained batch 122 in epoch 9, gen_loss = 0.5859129513666882, disc_loss = 0.002114294924038818
Trained batch 123 in epoch 9, gen_loss = 0.5859071061976494, disc_loss = 0.0021090083117146167
Trained batch 124 in epoch 9, gen_loss = 0.5858711607456207, disc_loss = 0.00209783891402185
Trained batch 125 in epoch 9, gen_loss = 0.5858261379457655, disc_loss = 0.002090401127047482
Trained batch 126 in epoch 9, gen_loss = 0.5857345647229923, disc_loss = 0.0020807810653895725
Trained batch 127 in epoch 9, gen_loss = 0.5856519744265825, disc_loss = 0.002072236103231262
Trained batch 128 in epoch 9, gen_loss = 0.5855795378370803, disc_loss = 0.002062512097822488
Trained batch 129 in epoch 9, gen_loss = 0.5855315857208692, disc_loss = 0.0020522637753926506
Trained batch 130 in epoch 9, gen_loss = 0.5855201339448681, disc_loss = 0.0020433703441002215
Trained batch 131 in epoch 9, gen_loss = 0.58548510097193, disc_loss = 0.0020346163995175934
Trained batch 132 in epoch 9, gen_loss = 0.5854649035106028, disc_loss = 0.0020251853520197698
Trained batch 133 in epoch 9, gen_loss = 0.5851384968455158, disc_loss = 0.002023526313176045
Trained batch 134 in epoch 9, gen_loss = 0.5852295740886971, disc_loss = 0.002022434514516068
Trained batch 135 in epoch 9, gen_loss = 0.5852204480153673, disc_loss = 0.002013553428268471
Trained batch 136 in epoch 9, gen_loss = 0.5851355928139095, disc_loss = 0.002004800035523074
Trained batch 137 in epoch 9, gen_loss = 0.5850193312634593, disc_loss = 0.001996180131201349
Trained batch 138 in epoch 9, gen_loss = 0.5848349202022278, disc_loss = 0.0019885560601494083
Trained batch 139 in epoch 9, gen_loss = 0.5850247564060348, disc_loss = 0.001985782596083092
Trained batch 140 in epoch 9, gen_loss = 0.585009679515311, disc_loss = 0.0019788788615045607
Trained batch 141 in epoch 9, gen_loss = 0.5847326884387245, disc_loss = 0.0019750893968616574
Trained batch 142 in epoch 9, gen_loss = 0.5845703634765599, disc_loss = 0.001968543553216891
Trained batch 143 in epoch 9, gen_loss = 0.5847808323386643, disc_loss = 0.0019777412995204535
Trained batch 144 in epoch 9, gen_loss = 0.5845975191428744, disc_loss = 0.0019729059462531887
Trained batch 145 in epoch 9, gen_loss = 0.5843490409116222, disc_loss = 0.001969762926296114
Trained batch 146 in epoch 9, gen_loss = 0.5839677807830629, disc_loss = 0.0019722329310084483
Trained batch 147 in epoch 9, gen_loss = 0.5841855102696935, disc_loss = 0.0019714572959315235
Trained batch 148 in epoch 9, gen_loss = 0.5837989471502752, disc_loss = 0.0019733393885157753
Trained batch 149 in epoch 9, gen_loss = 0.5840673710902532, disc_loss = 0.0019745961010145642
Trained batch 150 in epoch 9, gen_loss = 0.5841995858593493, disc_loss = 0.001972160845631055
Trained batch 151 in epoch 9, gen_loss = 0.5840770623793727, disc_loss = 0.00196586017677634
Trained batch 152 in epoch 9, gen_loss = 0.583958395750694, disc_loss = 0.0019583803889938185
Trained batch 153 in epoch 9, gen_loss = 0.5836936879854697, disc_loss = 0.0019558083637188153
Trained batch 154 in epoch 9, gen_loss = 0.5835729912404091, disc_loss = 0.0019517692267864701
Trained batch 155 in epoch 9, gen_loss = 0.5831534161399572, disc_loss = 0.001958176203725788
Trained batch 156 in epoch 9, gen_loss = 0.5832387696785531, disc_loss = 0.001953646352671822
Trained batch 157 in epoch 9, gen_loss = 0.5833414262985881, disc_loss = 0.001953945420402444
Trained batch 158 in epoch 9, gen_loss = 0.5833189620536828, disc_loss = 0.0019469144889563555
Trained batch 159 in epoch 9, gen_loss = 0.5832639435306192, disc_loss = 0.0019409502816415624
Trained batch 160 in epoch 9, gen_loss = 0.5831562127015606, disc_loss = 0.0019355430170135885
Trained batch 161 in epoch 9, gen_loss = 0.5830518693467717, disc_loss = 0.001935372744574798
Trained batch 162 in epoch 9, gen_loss = 0.5828737552546285, disc_loss = 0.001930330978189395
Trained batch 163 in epoch 9, gen_loss = 0.5826810127714785, disc_loss = 0.0019260685988162394
Trained batch 164 in epoch 9, gen_loss = 0.5827045984340437, disc_loss = 0.0019209868186435691
Trained batch 165 in epoch 9, gen_loss = 0.5823279448661459, disc_loss = 0.0019258304147739861
Trained batch 166 in epoch 9, gen_loss = 0.5824917677990691, disc_loss = 0.0019264146696056747
Trained batch 167 in epoch 9, gen_loss = 0.5828786873746485, disc_loss = 0.0019366256612037042
Trained batch 168 in epoch 9, gen_loss = 0.5829925277882074, disc_loss = 0.0019327382672131722
Trained batch 169 in epoch 9, gen_loss = 0.5829183271702598, disc_loss = 0.0019267755430465673
Trained batch 170 in epoch 9, gen_loss = 0.5827210564710941, disc_loss = 0.0019224205759642591
Trained batch 171 in epoch 9, gen_loss = 0.5823778934603514, disc_loss = 0.0019250391538493162
Trained batch 172 in epoch 9, gen_loss = 0.5822835256254053, disc_loss = 0.001920104762969937
Trained batch 173 in epoch 9, gen_loss = 0.5819722539049456, disc_loss = 0.0019279701204371006
Trained batch 174 in epoch 9, gen_loss = 0.5821771861825671, disc_loss = 0.0019317672468189683
Trained batch 175 in epoch 9, gen_loss = 0.582382229749452, disc_loss = 0.0019294612806830132
Trained batch 176 in epoch 9, gen_loss = 0.5823402999147858, disc_loss = 0.0019293908012694137
Trained batch 177 in epoch 9, gen_loss = 0.5820417754100949, disc_loss = 0.0019350827905726148
Trained batch 178 in epoch 9, gen_loss = 0.5818792030465003, disc_loss = 0.0019321864394096439
Trained batch 179 in epoch 9, gen_loss = 0.5819197275572353, disc_loss = 0.0019291888372713908
Trained batch 180 in epoch 9, gen_loss = 0.5821104469549591, disc_loss = 0.001928961276879421
Trained batch 181 in epoch 9, gen_loss = 0.5820625078874629, disc_loss = 0.0019256453110406606
Trained batch 182 in epoch 9, gen_loss = 0.5819178153582609, disc_loss = 0.0019283996623956033
Trained batch 183 in epoch 9, gen_loss = 0.5818467099705468, disc_loss = 0.0019270752122595338
Trained batch 184 in epoch 9, gen_loss = 0.581871913735931, disc_loss = 0.0019220568913009923
Trained batch 185 in epoch 9, gen_loss = 0.5818525253124135, disc_loss = 0.0019294313106295322
Testing Epoch 9
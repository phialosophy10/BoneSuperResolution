/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 1.693444848060608, disc_loss = 0.564059317111969
Trained batch 1 in epoch 0, gen_loss = 1.7406288981437683, disc_loss = 0.7358775436878204
Trained batch 2 in epoch 0, gen_loss = 1.7443982362747192, disc_loss = 0.7887150645256042
Trained batch 3 in epoch 0, gen_loss = 1.711651474237442, disc_loss = 0.6973694637417793
Trained batch 4 in epoch 0, gen_loss = 1.7155200242996216, disc_loss = 0.6309586584568023
Trained batch 5 in epoch 0, gen_loss = 1.6821417212486267, disc_loss = 0.5748312224944433
Trained batch 6 in epoch 0, gen_loss = 1.6274277312414986, disc_loss = 0.5287546217441559
Trained batch 7 in epoch 0, gen_loss = 1.6066381931304932, disc_loss = 0.49483001604676247
Trained batch 8 in epoch 0, gen_loss = 1.5859301090240479, disc_loss = 0.46520279182328117
Trained batch 9 in epoch 0, gen_loss = 1.5658968210220336, disc_loss = 0.4451165676116943
Trained batch 10 in epoch 0, gen_loss = 1.5532878312197598, disc_loss = 0.42659181356430054
Trained batch 11 in epoch 0, gen_loss = 1.5403656959533691, disc_loss = 0.4086368965605895
Trained batch 12 in epoch 0, gen_loss = 1.530349456346952, disc_loss = 0.39502790111761826
Trained batch 13 in epoch 0, gen_loss = 1.532363772392273, disc_loss = 0.38330436817237307
Trained batch 14 in epoch 0, gen_loss = 1.5331166108449301, disc_loss = 0.37098647356033326
Trained batch 15 in epoch 0, gen_loss = 1.537015937268734, disc_loss = 0.358655771240592
Trained batch 16 in epoch 0, gen_loss = 1.5452555628383862, disc_loss = 0.34575439288335685
Trained batch 17 in epoch 0, gen_loss = 1.547363645500607, disc_loss = 0.33358543035056853
Trained batch 18 in epoch 0, gen_loss = 1.551305419520328, disc_loss = 0.3223181770820367
Trained batch 19 in epoch 0, gen_loss = 1.5539684295654297, disc_loss = 0.31204074509441854
Trained batch 20 in epoch 0, gen_loss = 1.5528734468278431, disc_loss = 0.3020520306059292
Trained batch 21 in epoch 0, gen_loss = 1.5530874566598372, disc_loss = 0.2922711233523759
Trained batch 22 in epoch 0, gen_loss = 1.5475406128427256, disc_loss = 0.28353285919065063
Trained batch 23 in epoch 0, gen_loss = 1.5524600644906361, disc_loss = 0.27519110093514126
Trained batch 24 in epoch 0, gen_loss = 1.560175576210022, disc_loss = 0.26890133440494535
Trained batch 25 in epoch 0, gen_loss = 1.5644463713352497, disc_loss = 0.26495785036912334
Trained batch 26 in epoch 0, gen_loss = 1.567931718296475, disc_loss = 0.2599192758401235
Trained batch 27 in epoch 0, gen_loss = 1.570042188678469, disc_loss = 0.2541202184345041
Trained batch 28 in epoch 0, gen_loss = 1.575455932781614, disc_loss = 0.24858254271334615
Trained batch 29 in epoch 0, gen_loss = 1.579893410205841, disc_loss = 0.243463580061992
Trained batch 30 in epoch 0, gen_loss = 1.5779931429893739, disc_loss = 0.23817954428734317
Trained batch 31 in epoch 0, gen_loss = 1.5777107290923595, disc_loss = 0.233377018943429
Trained batch 32 in epoch 0, gen_loss = 1.5803729512474753, disc_loss = 0.22891538183797489
Trained batch 33 in epoch 0, gen_loss = 1.586348929825951, disc_loss = 0.22531106783186688
Trained batch 34 in epoch 0, gen_loss = 1.5859506504876273, disc_loss = 0.22256561581577575
Trained batch 35 in epoch 0, gen_loss = 1.5879278149869707, disc_loss = 0.21860665558940834
Trained batch 36 in epoch 0, gen_loss = 1.592968911738009, disc_loss = 0.21467792887139964
Trained batch 37 in epoch 0, gen_loss = 1.5974631685959666, disc_loss = 0.2108582740551547
Trained batch 38 in epoch 0, gen_loss = 1.600715389618507, disc_loss = 0.20700350222297204
Trained batch 39 in epoch 0, gen_loss = 1.6081378787755967, disc_loss = 0.20365806156769395
Trained batch 40 in epoch 0, gen_loss = 1.609195970907444, disc_loss = 0.20014778978940917
Trained batch 41 in epoch 0, gen_loss = 1.6080327544893538, disc_loss = 0.196968983681429
Trained batch 42 in epoch 0, gen_loss = 1.609313726425171, disc_loss = 0.19363094225179317
Trained batch 43 in epoch 0, gen_loss = 1.612141950563951, disc_loss = 0.19061944328925826
Trained batch 44 in epoch 0, gen_loss = 1.6134281582302517, disc_loss = 0.1881298866536882
Trained batch 45 in epoch 0, gen_loss = 1.6132147649060125, disc_loss = 0.18505525216460228
Trained batch 46 in epoch 0, gen_loss = 1.6153852914242035, disc_loss = 0.18227251920294255
Trained batch 47 in epoch 0, gen_loss = 1.6165124376614888, disc_loss = 0.17945310597618422
Trained batch 48 in epoch 0, gen_loss = 1.6176759564146703, disc_loss = 0.17681341146936222
Trained batch 49 in epoch 0, gen_loss = 1.6206479692459106, disc_loss = 0.1743830318748951
Trained batch 50 in epoch 0, gen_loss = 1.6194061858981263, disc_loss = 0.17247768374634723
Trained batch 51 in epoch 0, gen_loss = 1.6208066940307617, disc_loss = 0.17132682424898332
Trained batch 52 in epoch 0, gen_loss = 1.6277839327758212, disc_loss = 0.16958205458128228
Trained batch 53 in epoch 0, gen_loss = 1.6295443000616852, disc_loss = 0.16802808200871502
Trained batch 54 in epoch 0, gen_loss = 1.6318296497518365, disc_loss = 0.16605031869628212
Trained batch 55 in epoch 0, gen_loss = 1.6324530435459954, disc_loss = 0.16396964201703668
Trained batch 56 in epoch 0, gen_loss = 1.6337092508349502, disc_loss = 0.16173196093816505
Trained batch 57 in epoch 0, gen_loss = 1.6359277141505275, disc_loss = 0.15992635687620477
Trained batch 58 in epoch 0, gen_loss = 1.6340354600195157, disc_loss = 0.15841761730232481
Trained batch 59 in epoch 0, gen_loss = 1.6320102830727896, disc_loss = 0.15648260737458866
Trained batch 60 in epoch 0, gen_loss = 1.6325789260082557, disc_loss = 0.15497490665951713
Trained batch 61 in epoch 0, gen_loss = 1.635021473130872, disc_loss = 0.15312766007358028
Trained batch 62 in epoch 0, gen_loss = 1.6311766703923543, disc_loss = 0.15115244719125923
Trained batch 63 in epoch 0, gen_loss = 1.631832154467702, disc_loss = 0.14943487613345496
Trained batch 64 in epoch 0, gen_loss = 1.6319911058132466, disc_loss = 0.14794691637731516
Trained batch 65 in epoch 0, gen_loss = 1.6310403617945584, disc_loss = 0.14617219079060084
Trained batch 66 in epoch 0, gen_loss = 1.6311345242742281, disc_loss = 0.1445164027443128
Trained batch 67 in epoch 0, gen_loss = 1.631389996584724, disc_loss = 0.142953518038506
Trained batch 68 in epoch 0, gen_loss = 1.6284770585488582, disc_loss = 0.14193094222118025
Trained batch 69 in epoch 0, gen_loss = 1.624603501388005, disc_loss = 0.14114435221999883
Trained batch 70 in epoch 0, gen_loss = 1.6296809256916316, disc_loss = 0.1405368001580658
Trained batch 71 in epoch 0, gen_loss = 1.6340571443239849, disc_loss = 0.13906261410253742
Trained batch 72 in epoch 0, gen_loss = 1.6310206994618455, disc_loss = 0.13797871526075553
Trained batch 73 in epoch 0, gen_loss = 1.6324529776702057, disc_loss = 0.13693924260803977
Trained batch 74 in epoch 0, gen_loss = 1.6377357927958172, disc_loss = 0.13595364632705847
Trained batch 75 in epoch 0, gen_loss = 1.6395163614498942, disc_loss = 0.13491692994476148
Trained batch 76 in epoch 0, gen_loss = 1.6410830764027384, disc_loss = 0.13383848657952502
Trained batch 77 in epoch 0, gen_loss = 1.6425090523866506, disc_loss = 0.13302708954478687
Trained batch 78 in epoch 0, gen_loss = 1.646034987666939, disc_loss = 0.13213545388153083
Trained batch 79 in epoch 0, gen_loss = 1.6486772134900094, disc_loss = 0.13131706251297146
Trained batch 80 in epoch 0, gen_loss = 1.6512146216851693, disc_loss = 0.13013752800538952
Trained batch 81 in epoch 0, gen_loss = 1.6547218459408457, disc_loss = 0.12895660277274323
Trained batch 82 in epoch 0, gen_loss = 1.6549891750496555, disc_loss = 0.12775980999850364
Trained batch 83 in epoch 0, gen_loss = 1.6539900203545888, disc_loss = 0.12702875446882986
Trained batch 84 in epoch 0, gen_loss = 1.6515403340844548, disc_loss = 0.12597047397319008
Trained batch 85 in epoch 0, gen_loss = 1.652085053366284, disc_loss = 0.12484959331016209
Trained batch 86 in epoch 0, gen_loss = 1.6525180134279975, disc_loss = 0.12369717524825842
Trained batch 87 in epoch 0, gen_loss = 1.6540410030971875, disc_loss = 0.12252945101565936
Trained batch 88 in epoch 0, gen_loss = 1.6506331395567133, disc_loss = 0.12151582367467077
Trained batch 89 in epoch 0, gen_loss = 1.6522024790445964, disc_loss = 0.1204884635284543
Trained batch 90 in epoch 0, gen_loss = 1.65128646840106, disc_loss = 0.11942337606880037
Trained batch 91 in epoch 0, gen_loss = 1.6517489137856856, disc_loss = 0.1184108010088296
Trained batch 92 in epoch 0, gen_loss = 1.6504438795069212, disc_loss = 0.11738697641719413
Trained batch 93 in epoch 0, gen_loss = 1.648510511885298, disc_loss = 0.11638326919142236
Trained batch 94 in epoch 0, gen_loss = 1.649849073510421, disc_loss = 0.11539049646572062
Trained batch 95 in epoch 0, gen_loss = 1.650480439265569, disc_loss = 0.1144315949253117
Trained batch 96 in epoch 0, gen_loss = 1.6503499648005693, disc_loss = 0.11349431452216562
Trained batch 97 in epoch 0, gen_loss = 1.6486847789920107, disc_loss = 0.1125325649900704
Trained batch 98 in epoch 0, gen_loss = 1.6466845755625252, disc_loss = 0.11159671224051654
Trained batch 99 in epoch 0, gen_loss = 1.645960763692856, disc_loss = 0.11063745893537998
Trained batch 100 in epoch 0, gen_loss = 1.6446131644862714, disc_loss = 0.10973099017939945
Trained batch 101 in epoch 0, gen_loss = 1.6454767865293167, disc_loss = 0.10886142870374754
Trained batch 102 in epoch 0, gen_loss = 1.6452740060472952, disc_loss = 0.10799627425601181
Trained batch 103 in epoch 0, gen_loss = 1.643568638425607, disc_loss = 0.10717215890494677
Trained batch 104 in epoch 0, gen_loss = 1.6426072449911209, disc_loss = 0.10645570237012136
Trained batch 105 in epoch 0, gen_loss = 1.6414163944856175, disc_loss = 0.10577483689588196
Trained batch 106 in epoch 0, gen_loss = 1.6404036873968961, disc_loss = 0.10500267746849595
Trained batch 107 in epoch 0, gen_loss = 1.638232652787809, disc_loss = 0.10423927878340085
Trained batch 108 in epoch 0, gen_loss = 1.6372476783367471, disc_loss = 0.10350282845693991
Trained batch 109 in epoch 0, gen_loss = 1.6383844007145274, disc_loss = 0.102839334173636
Trained batch 110 in epoch 0, gen_loss = 1.6380181011852917, disc_loss = 0.10217881363791388
Trained batch 111 in epoch 0, gen_loss = 1.6363288377012526, disc_loss = 0.1014378236473671
Trained batch 112 in epoch 0, gen_loss = 1.6365962197295332, disc_loss = 0.10068013822346662
Trained batch 113 in epoch 0, gen_loss = 1.6340976911678649, disc_loss = 0.09997621139413432
Trained batch 114 in epoch 0, gen_loss = 1.6329236631808073, disc_loss = 0.09927373509044232
Trained batch 115 in epoch 0, gen_loss = 1.6316652226036992, disc_loss = 0.09853131396310597
Trained batch 116 in epoch 0, gen_loss = 1.630098086137038, disc_loss = 0.09781552481855083
Trained batch 117 in epoch 0, gen_loss = 1.6302182512768244, disc_loss = 0.09716843703161862
Trained batch 118 in epoch 0, gen_loss = 1.6282375299630045, disc_loss = 0.09651530837687124
Trained batch 119 in epoch 0, gen_loss = 1.6266471922397614, disc_loss = 0.09586875558209916
Trained batch 120 in epoch 0, gen_loss = 1.6235945510470178, disc_loss = 0.09523943006561315
Trained batch 121 in epoch 0, gen_loss = 1.623336371828298, disc_loss = 0.09458475553079462
Trained batch 122 in epoch 0, gen_loss = 1.621836759210602, disc_loss = 0.09392144904297785
Trained batch 123 in epoch 0, gen_loss = 1.6219865160603677, disc_loss = 0.09326676672865306
Trained batch 124 in epoch 0, gen_loss = 1.6210376167297362, disc_loss = 0.09262831443548203
Trained batch 125 in epoch 0, gen_loss = 1.6201919714609783, disc_loss = 0.09202378281643467
Trained batch 126 in epoch 0, gen_loss = 1.6182369547566091, disc_loss = 0.09139916891833459
Trained batch 127 in epoch 0, gen_loss = 1.617861969396472, disc_loss = 0.09076748689403757
Trained batch 128 in epoch 0, gen_loss = 1.6175330868063047, disc_loss = 0.09016739932979032
Trained batch 129 in epoch 0, gen_loss = 1.6157615790000328, disc_loss = 0.08954960082729276
Trained batch 130 in epoch 0, gen_loss = 1.6156991401701484, disc_loss = 0.08894038661774106
Trained batch 131 in epoch 0, gen_loss = 1.6139106064131765, disc_loss = 0.08839444077404385
Trained batch 132 in epoch 0, gen_loss = 1.6129149440535926, disc_loss = 0.08782661746123008
Trained batch 133 in epoch 0, gen_loss = 1.6111254967860322, disc_loss = 0.08724427325373042
Trained batch 134 in epoch 0, gen_loss = 1.6097224915469135, disc_loss = 0.08668294718006143
Trained batch 135 in epoch 0, gen_loss = 1.6096067060442532, disc_loss = 0.0861326956861269
Trained batch 136 in epoch 0, gen_loss = 1.6091100377758054, disc_loss = 0.08562383154257588
Trained batch 137 in epoch 0, gen_loss = 1.607638943022576, disc_loss = 0.08514278876743671
Trained batch 138 in epoch 0, gen_loss = 1.6061915510849987, disc_loss = 0.08461982208109803
Trained batch 139 in epoch 0, gen_loss = 1.6054065942764282, disc_loss = 0.08416776060392814
Trained batch 140 in epoch 0, gen_loss = 1.6028327705166865, disc_loss = 0.08369097675705421
Trained batch 141 in epoch 0, gen_loss = 1.6017786843675963, disc_loss = 0.08319080798742427
Trained batch 142 in epoch 0, gen_loss = 1.601505938109818, disc_loss = 0.08268271519483386
Trained batch 143 in epoch 0, gen_loss = 1.6001056217485004, disc_loss = 0.08219469405917658
Trained batch 144 in epoch 0, gen_loss = 1.5984087319209659, disc_loss = 0.08169368222227384
Trained batch 145 in epoch 0, gen_loss = 1.5975982130390325, disc_loss = 0.08121542731453091
Trained batch 146 in epoch 0, gen_loss = 1.5952495255437837, disc_loss = 0.0807362612096124
Trained batch 147 in epoch 0, gen_loss = 1.5939905216565002, disc_loss = 0.08027976096255353
Trained batch 148 in epoch 0, gen_loss = 1.5921870214027047, disc_loss = 0.07984482408219935
Trained batch 149 in epoch 0, gen_loss = 1.5902272057533264, disc_loss = 0.07938315737371643
Trained batch 150 in epoch 0, gen_loss = 1.5887493653013216, disc_loss = 0.07891556185158279
Trained batch 151 in epoch 0, gen_loss = 1.5895231515169144, disc_loss = 0.07847140995344441
Trained batch 152 in epoch 0, gen_loss = 1.5884214444877276, disc_loss = 0.07801408884328564
Trained batch 153 in epoch 0, gen_loss = 1.5876832503777045, disc_loss = 0.0775812644233274
Trained batch 154 in epoch 0, gen_loss = 1.5867140893013247, disc_loss = 0.07717803138638696
Trained batch 155 in epoch 0, gen_loss = 1.5848965965784514, disc_loss = 0.07676934361314544
Trained batch 156 in epoch 0, gen_loss = 1.5843683754562572, disc_loss = 0.07633613825295192
Trained batch 157 in epoch 0, gen_loss = 1.5857867953143543, disc_loss = 0.07590913323426171
Trained batch 158 in epoch 0, gen_loss = 1.584161564239166, disc_loss = 0.07549728544534377
Trained batch 159 in epoch 0, gen_loss = 1.5827980950474738, disc_loss = 0.07509013515664265
Trained batch 160 in epoch 0, gen_loss = 1.5814592978969124, disc_loss = 0.07468908966189215
Trained batch 161 in epoch 0, gen_loss = 1.5806255767374864, disc_loss = 0.07428692357706619
Trained batch 162 in epoch 0, gen_loss = 1.579512936937297, disc_loss = 0.07388427850156108
Trained batch 163 in epoch 0, gen_loss = 1.5781771119047956, disc_loss = 0.07348404867892586
Trained batch 164 in epoch 0, gen_loss = 1.5781407717502478, disc_loss = 0.0731036101834792
Trained batch 165 in epoch 0, gen_loss = 1.5781051566801876, disc_loss = 0.07273852917736015
Trained batch 166 in epoch 0, gen_loss = 1.5782402910872133, disc_loss = 0.07235878756727109
Trained batch 167 in epoch 0, gen_loss = 1.5771654510781878, disc_loss = 0.07197511096906271
Trained batch 168 in epoch 0, gen_loss = 1.5773115898730488, disc_loss = 0.0716088417994641
Trained batch 169 in epoch 0, gen_loss = 1.5762022067518795, disc_loss = 0.0712603885680437
Trained batch 170 in epoch 0, gen_loss = 1.5749198644481905, disc_loss = 0.07091369913422574
Trained batch 171 in epoch 0, gen_loss = 1.5731679263503053, disc_loss = 0.07057386006466872
Trained batch 172 in epoch 0, gen_loss = 1.5716047445473644, disc_loss = 0.07033456343016184
Trained batch 173 in epoch 0, gen_loss = 1.570631552701709, disc_loss = 0.07003535269277877
Trained batch 174 in epoch 0, gen_loss = 1.5690916320255826, disc_loss = 0.0697133161819407
Trained batch 175 in epoch 0, gen_loss = 1.5684889365326276, disc_loss = 0.06941783312305977
Trained batch 176 in epoch 0, gen_loss = 1.5677232028400832, disc_loss = 0.06906647848144258
Trained batch 177 in epoch 0, gen_loss = 1.5671482889839772, disc_loss = 0.06873144089568699
Trained batch 178 in epoch 0, gen_loss = 1.566185730129647, disc_loss = 0.06840820791064528
Trained batch 179 in epoch 0, gen_loss = 1.565503011809455, disc_loss = 0.06807211378796232
Trained batch 180 in epoch 0, gen_loss = 1.5641243576344863, disc_loss = 0.0677576633530427
Trained batch 181 in epoch 0, gen_loss = 1.563087061866299, disc_loss = 0.06744628124307472
Trained batch 182 in epoch 0, gen_loss = 1.5616923805143013, disc_loss = 0.06713313066853525
Trained batch 183 in epoch 0, gen_loss = 1.5620400717724925, disc_loss = 0.06680784118361771
Trained batch 184 in epoch 0, gen_loss = 1.5633493397686933, disc_loss = 0.06650093550718314
Trained batch 185 in epoch 0, gen_loss = 1.5620433841982195, disc_loss = 0.06619479596835151
Trained batch 186 in epoch 0, gen_loss = 1.5616850629847316, disc_loss = 0.06589630897590183
Trained batch 187 in epoch 0, gen_loss = 1.560469629282647, disc_loss = 0.06563265647422126
Trained batch 188 in epoch 0, gen_loss = 1.5587380758669012, disc_loss = 0.0653812492847758
Trained batch 189 in epoch 0, gen_loss = 1.558960945982682, disc_loss = 0.06514276886652959
Trained batch 190 in epoch 0, gen_loss = 1.5583316562063407, disc_loss = 0.06485543157710298
Trained batch 191 in epoch 0, gen_loss = 1.5574095907310646, disc_loss = 0.06464050723297987
Trained batch 192 in epoch 0, gen_loss = 1.5557955626996687, disc_loss = 0.06436322523290629
Trained batch 193 in epoch 0, gen_loss = 1.5543784708091892, disc_loss = 0.06409670751945105
Trained batch 194 in epoch 0, gen_loss = 1.5530235467812954, disc_loss = 0.06380327056902341
Trained batch 195 in epoch 0, gen_loss = 1.5515863633885676, disc_loss = 0.06352867104816345
Trained batch 196 in epoch 0, gen_loss = 1.5507509206152204, disc_loss = 0.06324700531337013
Trained batch 197 in epoch 0, gen_loss = 1.5494401551256276, disc_loss = 0.06296356775647387
Trained batch 198 in epoch 0, gen_loss = 1.5483212075640809, disc_loss = 0.06268018435677467
Trained batch 199 in epoch 0, gen_loss = 1.5472526901960373, disc_loss = 0.06240892534377054
Trained batch 200 in epoch 0, gen_loss = 1.5471671653624197, disc_loss = 0.06212401256169105
Trained batch 201 in epoch 0, gen_loss = 1.546081841582119, disc_loss = 0.06185097058792368
Trained batch 202 in epoch 0, gen_loss = 1.5468300269742317, disc_loss = 0.06159078918415778
Trained batch 203 in epoch 0, gen_loss = 1.5454994679666032, disc_loss = 0.06132097162452398
Trained batch 204 in epoch 0, gen_loss = 1.5454200959787137, disc_loss = 0.06106114054053295
Trained batch 205 in epoch 0, gen_loss = 1.5440156257268294, disc_loss = 0.06079533964721034
Trained batch 206 in epoch 0, gen_loss = 1.543034335265413, disc_loss = 0.06053277662311847
Trained batch 207 in epoch 0, gen_loss = 1.5429696561052249, disc_loss = 0.06027684816553329
Trained batch 208 in epoch 0, gen_loss = 1.5431163459303276, disc_loss = 0.0600276010948719
Trained batch 209 in epoch 0, gen_loss = 1.5422150975181943, disc_loss = 0.05977421091603381
Trained batch 210 in epoch 0, gen_loss = 1.5425482282141374, disc_loss = 0.059534470934720966
Trained batch 211 in epoch 0, gen_loss = 1.5420938955163055, disc_loss = 0.0592832998174928
Trained batch 212 in epoch 0, gen_loss = 1.5410317680645438, disc_loss = 0.059049657154653414
Trained batch 213 in epoch 0, gen_loss = 1.5403711155196216, disc_loss = 0.05881881580914362
Trained batch 214 in epoch 0, gen_loss = 1.5400871592898702, disc_loss = 0.058588176413417556
Trained batch 215 in epoch 0, gen_loss = 1.53944801180451, disc_loss = 0.0583464764446641
Trained batch 216 in epoch 0, gen_loss = 1.5385667096634614, disc_loss = 0.0581173713400548
Trained batch 217 in epoch 0, gen_loss = 1.5383934668444712, disc_loss = 0.057895792857530194
Trained batch 218 in epoch 0, gen_loss = 1.537214488743647, disc_loss = 0.05766261225676836
Trained batch 219 in epoch 0, gen_loss = 1.5363501288674095, disc_loss = 0.0574387876867232
Trained batch 220 in epoch 0, gen_loss = 1.5362284615029038, disc_loss = 0.05721342563839857
Trained batch 221 in epoch 0, gen_loss = 1.535776591515756, disc_loss = 0.05698715822628556
Trained batch 222 in epoch 0, gen_loss = 1.5354108307928247, disc_loss = 0.0567669059450617
Trained batch 223 in epoch 0, gen_loss = 1.5356014727481775, disc_loss = 0.05654358189869007
Trained batch 224 in epoch 0, gen_loss = 1.5349174626668294, disc_loss = 0.0563214117123021
Trained batch 225 in epoch 0, gen_loss = 1.5339730951638348, disc_loss = 0.056114316320425905
Trained batch 226 in epoch 0, gen_loss = 1.5328317418497563, disc_loss = 0.05591458598324118
Trained batch 227 in epoch 0, gen_loss = 1.5322291960841732, disc_loss = 0.05571655436467968
Trained batch 228 in epoch 0, gen_loss = 1.5311888851973687, disc_loss = 0.05550852098693364
Trained batch 229 in epoch 0, gen_loss = 1.5305003715598064, disc_loss = 0.05530260478591789
Trained batch 230 in epoch 0, gen_loss = 1.529857079188029, disc_loss = 0.05509371548342756
Trained batch 231 in epoch 0, gen_loss = 1.5284573184005146, disc_loss = 0.05489823772122377
Trained batch 232 in epoch 0, gen_loss = 1.5275034786805575, disc_loss = 0.05470086776855294
Trained batch 233 in epoch 0, gen_loss = 1.5269372009823465, disc_loss = 0.054491374084455334
Trained batch 234 in epoch 0, gen_loss = 1.525925150830695, disc_loss = 0.054327530223638454
Trained batch 235 in epoch 0, gen_loss = 1.52455868609881, disc_loss = 0.05415503949053207
Trained batch 236 in epoch 0, gen_loss = 1.5236573958698707, disc_loss = 0.05401677787618295
Trained batch 237 in epoch 0, gen_loss = 1.522313217155072, disc_loss = 0.05385466578158261
Trained batch 238 in epoch 0, gen_loss = 1.5221666950561012, disc_loss = 0.053667747996217534
Trained batch 239 in epoch 0, gen_loss = 1.5208159695068995, disc_loss = 0.053511433815583584
Trained batch 240 in epoch 0, gen_loss = 1.52047042381714, disc_loss = 0.05337059560436678
Trained batch 241 in epoch 0, gen_loss = 1.519764373617724, disc_loss = 0.0532129384531093
Trained batch 242 in epoch 0, gen_loss = 1.5192140998173151, disc_loss = 0.05302667200044104
Trained batch 243 in epoch 0, gen_loss = 1.5196389160195336, disc_loss = 0.05284141110195244
Trained batch 244 in epoch 0, gen_loss = 1.519018418448312, disc_loss = 0.05266504887187359
Trained batch 245 in epoch 0, gen_loss = 1.5183774179559413, disc_loss = 0.05248366873257044
Trained batch 246 in epoch 0, gen_loss = 1.5177662087838177, disc_loss = 0.05230862465178074
Trained batch 247 in epoch 0, gen_loss = 1.5168112290482367, disc_loss = 0.05213698602071212
Trained batch 248 in epoch 0, gen_loss = 1.5160288537841244, disc_loss = 0.05195191350342878
Trained batch 249 in epoch 0, gen_loss = 1.5153232684135438, disc_loss = 0.051774637019261716
Trained batch 250 in epoch 0, gen_loss = 1.5149676220350532, disc_loss = 0.051593969577915996
Trained batch 251 in epoch 0, gen_loss = 1.514188894203731, disc_loss = 0.051418995588190027
Trained batch 252 in epoch 0, gen_loss = 1.514180088231686, disc_loss = 0.05124627896161242
Trained batch 253 in epoch 0, gen_loss = 1.5130961180671931, disc_loss = 0.051075052942963335
Trained batch 254 in epoch 0, gen_loss = 1.5121725512485877, disc_loss = 0.05092008932329276
Trained batch 255 in epoch 0, gen_loss = 1.5119347414001822, disc_loss = 0.05074285480804974
Trained batch 256 in epoch 0, gen_loss = 1.5113006983285748, disc_loss = 0.05057074387054093
Trained batch 257 in epoch 0, gen_loss = 1.5112095997315045, disc_loss = 0.05039398233738345
Trained batch 258 in epoch 0, gen_loss = 1.5107512243926295, disc_loss = 0.05022316333445861
Trained batch 259 in epoch 0, gen_loss = 1.5096751070939578, disc_loss = 0.05005749973934144
Trained batch 260 in epoch 0, gen_loss = 1.5093850290181536, disc_loss = 0.049897105905844674
Trained batch 261 in epoch 0, gen_loss = 1.5084272227214492, disc_loss = 0.04973333044411288
Trained batch 262 in epoch 0, gen_loss = 1.5074886156125666, disc_loss = 0.04956652776660405
Trained batch 263 in epoch 0, gen_loss = 1.50701594126947, disc_loss = 0.04940871513540377
Trained batch 264 in epoch 0, gen_loss = 1.506542411840187, disc_loss = 0.049249840606847464
Trained batch 265 in epoch 0, gen_loss = 1.505729351724897, disc_loss = 0.04908830798371114
Trained batch 266 in epoch 0, gen_loss = 1.5060673795835802, disc_loss = 0.048927374977674264
Trained batch 267 in epoch 0, gen_loss = 1.5052769068461747, disc_loss = 0.048789864199222134
Trained batch 268 in epoch 0, gen_loss = 1.5049866291670109, disc_loss = 0.048644569160617525
Trained batch 269 in epoch 0, gen_loss = 1.504181969607318, disc_loss = 0.04848536841950759
Trained batch 270 in epoch 0, gen_loss = 1.5044270362361332, disc_loss = 0.04832552575654044
Trained batch 271 in epoch 0, gen_loss = 1.5035233515150406, disc_loss = 0.04818369956474806
Trained batch 272 in epoch 0, gen_loss = 1.5030878738605933, disc_loss = 0.04803891016525172
Trained batch 273 in epoch 0, gen_loss = 1.502366208682095, disc_loss = 0.047892074095574715
Trained batch 274 in epoch 0, gen_loss = 1.5018696178089488, disc_loss = 0.047735391596162864
Trained batch 275 in epoch 0, gen_loss = 1.500995920188185, disc_loss = 0.04757768908967736
Trained batch 276 in epoch 0, gen_loss = 1.5007784306357483, disc_loss = 0.047428275658564126
Trained batch 277 in epoch 0, gen_loss = 1.500267195615837, disc_loss = 0.04728153759191523
Trained batch 278 in epoch 0, gen_loss = 1.499545370378802, disc_loss = 0.04713060854730534
Trained batch 279 in epoch 0, gen_loss = 1.4986415245703288, disc_loss = 0.04698420817564641
Trained batch 280 in epoch 0, gen_loss = 1.4976051714920913, disc_loss = 0.04684217502545313
Trained batch 281 in epoch 0, gen_loss = 1.496834842871267, disc_loss = 0.046697426610461154
Trained batch 282 in epoch 0, gen_loss = 1.4958506995292098, disc_loss = 0.04655660448641954
Trained batch 283 in epoch 0, gen_loss = 1.4954063808414297, disc_loss = 0.04641445426099842
Trained batch 284 in epoch 0, gen_loss = 1.4947878143243623, disc_loss = 0.04626706088974811
Trained batch 285 in epoch 0, gen_loss = 1.4943756636206087, disc_loss = 0.04612481029756315
Trained batch 286 in epoch 0, gen_loss = 1.4944810111348221, disc_loss = 0.045985901575756195
Trained batch 287 in epoch 0, gen_loss = 1.4941292045017083, disc_loss = 0.04584706571444662
Trained batch 288 in epoch 0, gen_loss = 1.4939715689028836, disc_loss = 0.04571091612498034
Trained batch 289 in epoch 0, gen_loss = 1.493353163784948, disc_loss = 0.045568565821981634
Trained batch 290 in epoch 0, gen_loss = 1.4925041174151235, disc_loss = 0.04542611398065264
Trained batch 291 in epoch 0, gen_loss = 1.4921930244524184, disc_loss = 0.04528781332152143
Trained batch 292 in epoch 0, gen_loss = 1.4922311318205486, disc_loss = 0.04514830875601429
Trained batch 293 in epoch 0, gen_loss = 1.4913371136399354, disc_loss = 0.04502298237065322
Trained batch 294 in epoch 0, gen_loss = 1.4912325180183024, disc_loss = 0.044894446159507766
Trained batch 295 in epoch 0, gen_loss = 1.4912155177947637, disc_loss = 0.04476292790511523
Trained batch 296 in epoch 0, gen_loss = 1.490858136202751, disc_loss = 0.044628901720699235
Trained batch 297 in epoch 0, gen_loss = 1.490653703276743, disc_loss = 0.04449152463231386
Trained batch 298 in epoch 0, gen_loss = 1.4901866673625832, disc_loss = 0.044357630543342255
Trained batch 299 in epoch 0, gen_loss = 1.489312351544698, disc_loss = 0.044225481300769996
Trained batch 300 in epoch 0, gen_loss = 1.4890728345345026, disc_loss = 0.04409547944930676
Trained batch 301 in epoch 0, gen_loss = 1.4889173081379063, disc_loss = 0.043964723115077625
Trained batch 302 in epoch 0, gen_loss = 1.4883110507486677, disc_loss = 0.043838040882463354
Trained batch 303 in epoch 0, gen_loss = 1.4883852506938733, disc_loss = 0.04372502429377116
Trained batch 304 in epoch 0, gen_loss = 1.4876443034312765, disc_loss = 0.04361902817427257
Trained batch 305 in epoch 0, gen_loss = 1.4869880372402715, disc_loss = 0.04350047525599769
Trained batch 306 in epoch 0, gen_loss = 1.48619121604323, disc_loss = 0.04337496779394921
Trained batch 307 in epoch 0, gen_loss = 1.4861368954955758, disc_loss = 0.043253532545066545
Trained batch 308 in epoch 0, gen_loss = 1.4858707667940256, disc_loss = 0.04313716356503901
Trained batch 309 in epoch 0, gen_loss = 1.4854997461841952, disc_loss = 0.04301610933241224
Trained batch 310 in epoch 0, gen_loss = 1.485140849156395, disc_loss = 0.0428957157278691
Trained batch 311 in epoch 0, gen_loss = 1.4849517330145225, disc_loss = 0.04277367321460938
Trained batch 312 in epoch 0, gen_loss = 1.4841896097500102, disc_loss = 0.04265418586160499
Trained batch 313 in epoch 0, gen_loss = 1.4836412383492585, disc_loss = 0.042542451950365524
Trained batch 314 in epoch 0, gen_loss = 1.4833756314383613, disc_loss = 0.04245374795448567
Trained batch 315 in epoch 0, gen_loss = 1.4835721424108819, disc_loss = 0.04235386261878582
Trained batch 316 in epoch 0, gen_loss = 1.4826537957326846, disc_loss = 0.04223645679220816
Trained batch 317 in epoch 0, gen_loss = 1.4822737079746318, disc_loss = 0.042119707095835054
Trained batch 318 in epoch 0, gen_loss = 1.481379856510222, disc_loss = 0.042006351892342995
Trained batch 319 in epoch 0, gen_loss = 1.4815192706882954, disc_loss = 0.04189872551723965
Trained batch 320 in epoch 0, gen_loss = 1.4810190605597333, disc_loss = 0.04179862736741725
Trained batch 321 in epoch 0, gen_loss = 1.4806015550720026, disc_loss = 0.041691890747795425
Trained batch 322 in epoch 0, gen_loss = 1.4798551871680623, disc_loss = 0.04157286775356084
Trained batch 323 in epoch 0, gen_loss = 1.4790633427508084, disc_loss = 0.04145853899571654
Trained batch 324 in epoch 0, gen_loss = 1.4788386774063111, disc_loss = 0.04134610138332041
Trained batch 325 in epoch 0, gen_loss = 1.4785907966958964, disc_loss = 0.04123393346289847
Trained batch 326 in epoch 0, gen_loss = 1.4786211999549048, disc_loss = 0.04111955045232555
Trained batch 327 in epoch 0, gen_loss = 1.4781864285469055, disc_loss = 0.04101042356697002
Trained batch 328 in epoch 0, gen_loss = 1.4782371477515501, disc_loss = 0.04089730811209098
Trained batch 329 in epoch 0, gen_loss = 1.4775954737807766, disc_loss = 0.040786982171773685
Trained batch 330 in epoch 0, gen_loss = 1.4773139139676743, disc_loss = 0.040682209674634734
Trained batch 331 in epoch 0, gen_loss = 1.4765939590442612, disc_loss = 0.04058350950510364
Trained batch 332 in epoch 0, gen_loss = 1.4760540491109855, disc_loss = 0.04048321301372045
Trained batch 333 in epoch 0, gen_loss = 1.476044439627025, disc_loss = 0.040376661410192756
Trained batch 334 in epoch 0, gen_loss = 1.4759020282261408, disc_loss = 0.040279114846167946
Trained batch 335 in epoch 0, gen_loss = 1.4757498073435964, disc_loss = 0.04017464842694435
Trained batch 336 in epoch 0, gen_loss = 1.4750166087900496, disc_loss = 0.040069716644697224
Trained batch 337 in epoch 0, gen_loss = 1.475132921390985, disc_loss = 0.039967119192963564
Trained batch 338 in epoch 0, gen_loss = 1.4748883683421268, disc_loss = 0.03986037904630171
Trained batch 339 in epoch 0, gen_loss = 1.4743949399274938, disc_loss = 0.03975149143815917
Trained batch 340 in epoch 0, gen_loss = 1.4738640680341077, disc_loss = 0.03964353165974365
Trained batch 341 in epoch 0, gen_loss = 1.4731453817490248, disc_loss = 0.03953958496761819
Trained batch 342 in epoch 0, gen_loss = 1.4735531316901782, disc_loss = 0.03943810952859917
Trained batch 343 in epoch 0, gen_loss = 1.4729757856491, disc_loss = 0.03933353436336484
Trained batch 344 in epoch 0, gen_loss = 1.4729170101276343, disc_loss = 0.039236219665980426
Trained batch 345 in epoch 0, gen_loss = 1.4731542375046394, disc_loss = 0.03914603280479551
Trained batch 346 in epoch 0, gen_loss = 1.472684304377531, disc_loss = 0.03905375211657983
Trained batch 347 in epoch 0, gen_loss = 1.4726267364518395, disc_loss = 0.03896738850811347
Trained batch 348 in epoch 0, gen_loss = 1.4720326925075498, disc_loss = 0.03886715638288497
Trained batch 349 in epoch 0, gen_loss = 1.4715168755395072, disc_loss = 0.03876833799162081
Trained batch 350 in epoch 0, gen_loss = 1.470981730355157, disc_loss = 0.03866581575801739
Trained batch 351 in epoch 0, gen_loss = 1.4707330770113252, disc_loss = 0.03856600507027575
Trained batch 352 in epoch 0, gen_loss = 1.4698541941115943, disc_loss = 0.03846555573815644
Trained batch 353 in epoch 0, gen_loss = 1.4687557563943379, disc_loss = 0.03860001770271736
Trained batch 354 in epoch 0, gen_loss = 1.467128637810828, disc_loss = 0.03968629936923758
Trained batch 355 in epoch 0, gen_loss = 1.4668844600072068, disc_loss = 0.039915336308388685
Trained batch 356 in epoch 0, gen_loss = 1.467878351024553, disc_loss = 0.040241726798707154
Trained batch 357 in epoch 0, gen_loss = 1.468053338913944, disc_loss = 0.04033638552733952
Trained batch 358 in epoch 0, gen_loss = 1.4674511493746616, disc_loss = 0.040286072461754294
Trained batch 359 in epoch 0, gen_loss = 1.466952853070365, disc_loss = 0.04021948239856606
Trained batch 360 in epoch 0, gen_loss = 1.4667855933762652, disc_loss = 0.04013819258771011
Trained batch 361 in epoch 0, gen_loss = 1.4665251538898405, disc_loss = 0.040050771318309177
Trained batch 362 in epoch 0, gen_loss = 1.4663641718793508, disc_loss = 0.03996520541472355
Trained batch 363 in epoch 0, gen_loss = 1.4660112314171843, disc_loss = 0.039872113890961264
Trained batch 364 in epoch 0, gen_loss = 1.4656220272795795, disc_loss = 0.03978261648013882
Trained batch 365 in epoch 0, gen_loss = 1.4651339021536822, disc_loss = 0.03968865361479442
Trained batch 366 in epoch 0, gen_loss = 1.4648437324596686, disc_loss = 0.039602479165957924
Trained batch 367 in epoch 0, gen_loss = 1.4648133020686067, disc_loss = 0.03950583157268778
Trained batch 368 in epoch 0, gen_loss = 1.4640846882409198, disc_loss = 0.03942134364528284
Trained batch 369 in epoch 0, gen_loss = 1.4634775864111411, disc_loss = 0.03933636041144161
Trained batch 370 in epoch 0, gen_loss = 1.46297418107241, disc_loss = 0.03925060142883453
Trained batch 371 in epoch 0, gen_loss = 1.463129828053136, disc_loss = 0.039158541465713896
Trained batch 372 in epoch 0, gen_loss = 1.4625040705018644, disc_loss = 0.03910067547349903
Trained batch 373 in epoch 0, gen_loss = 1.461742743770069, disc_loss = 0.0390304019693335
Trained batch 374 in epoch 0, gen_loss = 1.4618482548395793, disc_loss = 0.03894338198689123
Trained batch 375 in epoch 0, gen_loss = 1.4609110161979149, disc_loss = 0.03899555728817854
Trained batch 376 in epoch 0, gen_loss = 1.4604166607009321, disc_loss = 0.0390292438906951
Trained batch 377 in epoch 0, gen_loss = 1.4606209510848636, disc_loss = 0.03894509688923973
Trained batch 378 in epoch 0, gen_loss = 1.460774236115428, disc_loss = 0.03886352678438978
Trained batch 379 in epoch 0, gen_loss = 1.4605155856985794, disc_loss = 0.03878277499951716
Trained batch 380 in epoch 0, gen_loss = 1.4602177775125178, disc_loss = 0.03869253388371348
Trained batch 381 in epoch 0, gen_loss = 1.4598655697562932, disc_loss = 0.03860011832308297
Trained batch 382 in epoch 0, gen_loss = 1.4590602338158432, disc_loss = 0.0385092375538611
Trained batch 383 in epoch 0, gen_loss = 1.4582019603500764, disc_loss = 0.03842158969503847
Trained batch 384 in epoch 0, gen_loss = 1.4576531431891702, disc_loss = 0.038337285008112135
Trained batch 385 in epoch 0, gen_loss = 1.4577277092736003, disc_loss = 0.03824766122656416
Trained batch 386 in epoch 0, gen_loss = 1.457205128608132, disc_loss = 0.03815771612694886
Trained batch 387 in epoch 0, gen_loss = 1.456768902306704, disc_loss = 0.03806839471613297
Trained batch 388 in epoch 0, gen_loss = 1.4565741767613625, disc_loss = 0.03797869684574479
Trained batch 389 in epoch 0, gen_loss = 1.457692139270978, disc_loss = 0.03789105595459636
Trained batch 390 in epoch 0, gen_loss = 1.4571701074805101, disc_loss = 0.03780306865165815
Trained batch 391 in epoch 0, gen_loss = 1.457095938981796, disc_loss = 0.03771689231685667
Trained batch 392 in epoch 0, gen_loss = 1.4564759649393213, disc_loss = 0.037629969329774644
Trained batch 393 in epoch 0, gen_loss = 1.456446049177102, disc_loss = 0.037541727476923484
Trained batch 394 in epoch 0, gen_loss = 1.4561375092856492, disc_loss = 0.03745436866508349
Trained batch 395 in epoch 0, gen_loss = 1.456049612977288, disc_loss = 0.03736924139119572
Trained batch 396 in epoch 0, gen_loss = 1.456154507113344, disc_loss = 0.03728577838178433
Trained batch 397 in epoch 0, gen_loss = 1.4563237554463908, disc_loss = 0.037200483242541216
Trained batch 398 in epoch 0, gen_loss = 1.4558831336803006, disc_loss = 0.03711401961129952
Trained batch 399 in epoch 0, gen_loss = 1.455580752491951, disc_loss = 0.03702867513580713
Trained batch 400 in epoch 0, gen_loss = 1.4548476033674511, disc_loss = 0.036948947387485026
Trained batch 401 in epoch 0, gen_loss = 1.454576014879331, disc_loss = 0.036869922027904636
Trained batch 402 in epoch 0, gen_loss = 1.4540079204971086, disc_loss = 0.03678882358394674
Trained batch 403 in epoch 0, gen_loss = 1.4537676664272157, disc_loss = 0.03671122319929505
Trained batch 404 in epoch 0, gen_loss = 1.4540147328082427, disc_loss = 0.03663044315187927
Trained batch 405 in epoch 0, gen_loss = 1.453502854396557, disc_loss = 0.03654986317097462
Trained batch 406 in epoch 0, gen_loss = 1.4534444445767039, disc_loss = 0.03646980818413674
Trained batch 407 in epoch 0, gen_loss = 1.4534323189188452, disc_loss = 0.03638928297304494
Trained batch 408 in epoch 0, gen_loss = 1.453403815372066, disc_loss = 0.03630986990530071
Trained batch 409 in epoch 0, gen_loss = 1.4537916849299175, disc_loss = 0.03622878175399198
Trained batch 410 in epoch 0, gen_loss = 1.453292897437901, disc_loss = 0.036147782734851294
Trained batch 411 in epoch 0, gen_loss = 1.452524379040431, disc_loss = 0.03607510296046933
Trained batch 412 in epoch 0, gen_loss = 1.451924181734967, disc_loss = 0.035998986573375705
Trained batch 413 in epoch 0, gen_loss = 1.4519076695764699, disc_loss = 0.035922123722682574
Trained batch 414 in epoch 0, gen_loss = 1.4516380301441054, disc_loss = 0.035845146328771865
Trained batch 415 in epoch 0, gen_loss = 1.4510389222548559, disc_loss = 0.0357696076853944
Trained batch 416 in epoch 0, gen_loss = 1.4505632066612335, disc_loss = 0.03569049754054945
Trained batch 417 in epoch 0, gen_loss = 1.4500393245779155, disc_loss = 0.03561345973379607
Trained batch 418 in epoch 0, gen_loss = 1.449580449762094, disc_loss = 0.03553748715986767
Trained batch 419 in epoch 0, gen_loss = 1.4488574873833429, disc_loss = 0.03545872442191467
Trained batch 420 in epoch 0, gen_loss = 1.4482630108994146, disc_loss = 0.035383993829987644
Trained batch 421 in epoch 0, gen_loss = 1.448896482374996, disc_loss = 0.03530880061234237
Trained batch 422 in epoch 0, gen_loss = 1.4491076100238953, disc_loss = 0.03523858465985274
Trained batch 423 in epoch 0, gen_loss = 1.4494967657440114, disc_loss = 0.03516267800598212
Trained batch 424 in epoch 0, gen_loss = 1.4492289666568532, disc_loss = 0.035086857511059326
Trained batch 425 in epoch 0, gen_loss = 1.4487754876065142, disc_loss = 0.03501052236481801
Trained batch 426 in epoch 0, gen_loss = 1.4487106378519563, disc_loss = 0.03493431708677312
Trained batch 427 in epoch 0, gen_loss = 1.4484276117008423, disc_loss = 0.03486039050556632
Trained batch 428 in epoch 0, gen_loss = 1.4480777817728359, disc_loss = 0.03478477886413378
Trained batch 429 in epoch 0, gen_loss = 1.4483968047208564, disc_loss = 0.03470949666130595
Trained batch 430 in epoch 0, gen_loss = 1.447855226401663, disc_loss = 0.03463747051032368
Trained batch 431 in epoch 0, gen_loss = 1.4474566567827154, disc_loss = 0.03456582518777362
Trained batch 432 in epoch 0, gen_loss = 1.447028979418184, disc_loss = 0.0344972879438732
Trained batch 433 in epoch 0, gen_loss = 1.4464728565809364, disc_loss = 0.034431602521520534
Trained batch 434 in epoch 0, gen_loss = 1.4466324907609787, disc_loss = 0.03436245901360251
Trained batch 435 in epoch 0, gen_loss = 1.446709699313575, disc_loss = 0.034292036406866726
Trained batch 436 in epoch 0, gen_loss = 1.4462849875609445, disc_loss = 0.03422097727289803
Trained batch 437 in epoch 0, gen_loss = 1.4457899517120292, disc_loss = 0.03414868131029041
Trained batch 438 in epoch 0, gen_loss = 1.4459171843691676, disc_loss = 0.03408059342562779
Trained batch 439 in epoch 0, gen_loss = 1.445767879486084, disc_loss = 0.03401153174821626
Trained batch 440 in epoch 0, gen_loss = 1.4456784371075446, disc_loss = 0.033939996078534394
Trained batch 441 in epoch 0, gen_loss = 1.4452364935594446, disc_loss = 0.034009723059150364
Trained batch 442 in epoch 0, gen_loss = 1.4444462932797641, disc_loss = 0.03429185764645447
Trained batch 443 in epoch 0, gen_loss = 1.4443466223037995, disc_loss = 0.034271366268119496
Trained batch 444 in epoch 0, gen_loss = 1.4445634129342069, disc_loss = 0.03427230439808094
Trained batch 445 in epoch 0, gen_loss = 1.4449418743095055, disc_loss = 0.03421912918539693
Trained batch 446 in epoch 0, gen_loss = 1.444677887613608, disc_loss = 0.034159369953185054
Trained batch 447 in epoch 0, gen_loss = 1.4445109516382217, disc_loss = 0.0341035342872991
Trained batch 448 in epoch 0, gen_loss = 1.4443461071940467, disc_loss = 0.034042961514847384
Trained batch 449 in epoch 0, gen_loss = 1.4438788109355503, disc_loss = 0.03398098376165661
Trained batch 450 in epoch 0, gen_loss = 1.4437072826859163, disc_loss = 0.03391749009659344
Trained batch 451 in epoch 0, gen_loss = 1.443645439316741, disc_loss = 0.033850738412465706
Trained batch 452 in epoch 0, gen_loss = 1.4432092055053374, disc_loss = 0.033783955286230245
Trained batch 453 in epoch 0, gen_loss = 1.4432626983667785, disc_loss = 0.033718638682618964
Trained batch 454 in epoch 0, gen_loss = 1.4431578596869667, disc_loss = 0.033650818033717
Trained batch 455 in epoch 0, gen_loss = 1.4429447271844797, disc_loss = 0.03358352648680458
Trained batch 456 in epoch 0, gen_loss = 1.4426887139710607, disc_loss = 0.033522064526029405
Trained batch 457 in epoch 0, gen_loss = 1.4421833238226878, disc_loss = 0.03345957194001507
Trained batch 458 in epoch 0, gen_loss = 1.4417694648626322, disc_loss = 0.03339335699626579
Trained batch 459 in epoch 0, gen_loss = 1.44144857733146, disc_loss = 0.03333062807796523
Trained batch 460 in epoch 0, gen_loss = 1.44101290227017, disc_loss = 0.033265573608460726
Trained batch 461 in epoch 0, gen_loss = 1.440749260770294, disc_loss = 0.03320070697615544
Trained batch 462 in epoch 0, gen_loss = 1.4405661695204337, disc_loss = 0.033137299945139476
Trained batch 463 in epoch 0, gen_loss = 1.4403990746058266, disc_loss = 0.03307298504183438
Trained batch 464 in epoch 0, gen_loss = 1.4399423891498198, disc_loss = 0.03301061524168378
Trained batch 465 in epoch 0, gen_loss = 1.439382078821567, disc_loss = 0.03294522105566278
Trained batch 466 in epoch 0, gen_loss = 1.4389274498124704, disc_loss = 0.03288172248190536
Trained batch 467 in epoch 0, gen_loss = 1.4386424167543395, disc_loss = 0.0328168063917054
Trained batch 468 in epoch 0, gen_loss = 1.4383942481042988, disc_loss = 0.03275264968533617
Trained batch 469 in epoch 0, gen_loss = 1.437945990866803, disc_loss = 0.03269100363287045
Trained batch 470 in epoch 0, gen_loss = 1.4375364570354454, disc_loss = 0.03262806828717074
Trained batch 471 in epoch 0, gen_loss = 1.4373307437714884, disc_loss = 0.032563643719926004
Trained batch 472 in epoch 0, gen_loss = 1.437002262907855, disc_loss = 0.032501206690953535
Trained batch 473 in epoch 0, gen_loss = 1.436497986316681, disc_loss = 0.032439460878688764
Trained batch 474 in epoch 0, gen_loss = 1.4368171724520231, disc_loss = 0.032378233190331805
Trained batch 475 in epoch 0, gen_loss = 1.4366374501661092, disc_loss = 0.03231684686351927
Trained batch 476 in epoch 0, gen_loss = 1.4364135250355463, disc_loss = 0.032257586288552895
Trained batch 477 in epoch 0, gen_loss = 1.4356018798620631, disc_loss = 0.03220519045451617
Trained batch 478 in epoch 0, gen_loss = 1.435416371936838, disc_loss = 0.03216111522881481
Trained batch 479 in epoch 0, gen_loss = 1.4350935637950897, disc_loss = 0.03210201035205197
Trained batch 480 in epoch 0, gen_loss = 1.435149013872206, disc_loss = 0.032042269881528154
Trained batch 481 in epoch 0, gen_loss = 1.434798123430909, disc_loss = 0.03198240010919923
Trained batch 482 in epoch 0, gen_loss = 1.434583448228382, disc_loss = 0.03192448129782966
Trained batch 483 in epoch 0, gen_loss = 1.4343940563930953, disc_loss = 0.03186532383503716
Trained batch 484 in epoch 0, gen_loss = 1.4343601452935602, disc_loss = 0.031805214691023855
Trained batch 485 in epoch 0, gen_loss = 1.4340389910548803, disc_loss = 0.03174834745100588
Trained batch 486 in epoch 0, gen_loss = 1.4335882526648362, disc_loss = 0.0316921924135707
Trained batch 487 in epoch 0, gen_loss = 1.4337561812068595, disc_loss = 0.031632649852058346
Trained batch 488 in epoch 0, gen_loss = 1.4334467049756665, disc_loss = 0.03157358142692055
Trained batch 489 in epoch 0, gen_loss = 1.4333238633311525, disc_loss = 0.03151532378741445
Trained batch 490 in epoch 0, gen_loss = 1.4328395846904902, disc_loss = 0.03146901469755455
Trained batch 491 in epoch 0, gen_loss = 1.4324703713258107, disc_loss = 0.031414271519250594
Trained batch 492 in epoch 0, gen_loss = 1.4320318524784297, disc_loss = 0.03135677963602933
Trained batch 493 in epoch 0, gen_loss = 1.4323179528780794, disc_loss = 0.03129922733208549
Trained batch 494 in epoch 0, gen_loss = 1.4323304149839613, disc_loss = 0.031242349428228205
Trained batch 495 in epoch 0, gen_loss = 1.4319652306937403, disc_loss = 0.03119135219857262
Trained batch 496 in epoch 0, gen_loss = 1.4315413524447314, disc_loss = 0.031136193999953165
Trained batch 497 in epoch 0, gen_loss = 1.4314457295410126, disc_loss = 0.031079472311450744
Trained batch 498 in epoch 0, gen_loss = 1.4314037083623883, disc_loss = 0.031021978005763135
Trained batch 499 in epoch 0, gen_loss = 1.4309929511547088, disc_loss = 0.030963658699765802
Trained batch 500 in epoch 0, gen_loss = 1.4305256093571523, disc_loss = 0.030906989662991668
Trained batch 501 in epoch 0, gen_loss = 1.430400082314632, disc_loss = 0.03084920653173574
Trained batch 502 in epoch 0, gen_loss = 1.430086369542905, disc_loss = 0.030791198671610273
Trained batch 503 in epoch 0, gen_loss = 1.4303196167188978, disc_loss = 0.0307341988495503
Trained batch 504 in epoch 0, gen_loss = 1.429986590442091, disc_loss = 0.030677576641791895
Trained batch 505 in epoch 0, gen_loss = 1.4297175150614954, disc_loss = 0.03062432138327502
Trained batch 506 in epoch 0, gen_loss = 1.429266787845002, disc_loss = 0.0305687295774887
Trained batch 507 in epoch 0, gen_loss = 1.429107018577771, disc_loss = 0.03051746288506043
Trained batch 508 in epoch 0, gen_loss = 1.428921591087971, disc_loss = 0.030470518729455536
Trained batch 509 in epoch 0, gen_loss = 1.428584505296221, disc_loss = 0.030426266706576024
Trained batch 510 in epoch 0, gen_loss = 1.4285070427243256, disc_loss = 0.030374472025178605
Trained batch 511 in epoch 0, gen_loss = 1.4280866468325257, disc_loss = 0.03032130594397131
Trained batch 512 in epoch 0, gen_loss = 1.4283362034468623, disc_loss = 0.03027054052196305
Trained batch 513 in epoch 0, gen_loss = 1.427802656411197, disc_loss = 0.03021870437961485
Trained batch 514 in epoch 0, gen_loss = 1.4275910646012686, disc_loss = 0.03016396111071797
Trained batch 515 in epoch 0, gen_loss = 1.4270868250565936, disc_loss = 0.03011254453648048
Trained batch 516 in epoch 0, gen_loss = 1.4268089196206983, disc_loss = 0.03006075970568231
Trained batch 517 in epoch 0, gen_loss = 1.4263901264050753, disc_loss = 0.030007396154707967
Trained batch 518 in epoch 0, gen_loss = 1.4260072319953199, disc_loss = 0.02995360725687598
Trained batch 519 in epoch 0, gen_loss = 1.4256625136503807, disc_loss = 0.0299034575526513
Trained batch 520 in epoch 0, gen_loss = 1.425188223139567, disc_loss = 0.02985120189377069
Trained batch 521 in epoch 0, gen_loss = 1.425717437632696, disc_loss = 0.02979827516509748
Trained batch 522 in epoch 0, gen_loss = 1.425705471640563, disc_loss = 0.029746280300402463
Trained batch 523 in epoch 0, gen_loss = 1.4253704556982025, disc_loss = 0.029693126071951858
Trained batch 524 in epoch 0, gen_loss = 1.425086935815357, disc_loss = 0.029640231639856383
Trained batch 525 in epoch 0, gen_loss = 1.4250975482364119, disc_loss = 0.029589037865067447
Trained batch 526 in epoch 0, gen_loss = 1.425267202578188, disc_loss = 0.029537804952276557
Trained batch 527 in epoch 0, gen_loss = 1.4251995994286104, disc_loss = 0.02948559826340484
Trained batch 528 in epoch 0, gen_loss = 1.4250812649952216, disc_loss = 0.02943417121346385
Trained batch 529 in epoch 0, gen_loss = 1.4249694268658477, disc_loss = 0.02938289360960348
Trained batch 530 in epoch 0, gen_loss = 1.4246132317684914, disc_loss = 0.02933157559856071
Trained batch 531 in epoch 0, gen_loss = 1.4241091886857398, disc_loss = 0.02928551471322999
Trained batch 532 in epoch 0, gen_loss = 1.4240286793091508, disc_loss = 0.029246530960371636
Trained batch 533 in epoch 0, gen_loss = 1.4239619492591544, disc_loss = 0.029198821123483615
Trained batch 534 in epoch 0, gen_loss = 1.423609731353332, disc_loss = 0.02914821844173717
Trained batch 535 in epoch 0, gen_loss = 1.4232482903484087, disc_loss = 0.029100214986915965
Trained batch 536 in epoch 0, gen_loss = 1.4238074294237673, disc_loss = 0.029050054764843354
Trained batch 537 in epoch 0, gen_loss = 1.4237064646079194, disc_loss = 0.029000634900952057
Trained batch 538 in epoch 0, gen_loss = 1.4234767482099373, disc_loss = 0.02895197829711968
Trained batch 539 in epoch 0, gen_loss = 1.4230572175096583, disc_loss = 0.028904045875943092
Trained batch 540 in epoch 0, gen_loss = 1.4227428621373204, disc_loss = 0.02885862505975801
Trained batch 541 in epoch 0, gen_loss = 1.4223192499132613, disc_loss = 0.028810480952338485
Trained batch 542 in epoch 0, gen_loss = 1.4223641883821996, disc_loss = 0.028762686992506625
Trained batch 543 in epoch 0, gen_loss = 1.4223442542202331, disc_loss = 0.028717933864647743
Trained batch 544 in epoch 0, gen_loss = 1.4218610487946677, disc_loss = 0.028671022332401586
Trained batch 545 in epoch 0, gen_loss = 1.4215970484765021, disc_loss = 0.028621275490704215
Trained batch 546 in epoch 0, gen_loss = 1.4212293036459134, disc_loss = 0.028575680328667558
Trained batch 547 in epoch 0, gen_loss = 1.4211082767396077, disc_loss = 0.02852762886684177
Trained batch 548 in epoch 0, gen_loss = 1.4210705073153387, disc_loss = 0.02847988771436692
Trained batch 549 in epoch 0, gen_loss = 1.4210749134150418, disc_loss = 0.028432887992186642
Trained batch 550 in epoch 0, gen_loss = 1.4207449878841476, disc_loss = 0.028516872713093843
Trained batch 551 in epoch 0, gen_loss = 1.4200899983229844, disc_loss = 0.02865004742942393
Trained batch 552 in epoch 0, gen_loss = 1.4198326450144403, disc_loss = 0.028609344416388915
Trained batch 553 in epoch 0, gen_loss = 1.4197502250275458, disc_loss = 0.02858336510650296
Trained batch 554 in epoch 0, gen_loss = 1.4202634300197567, disc_loss = 0.028549122423361484
Trained batch 555 in epoch 0, gen_loss = 1.4199050231803236, disc_loss = 0.028510963770170636
Trained batch 556 in epoch 0, gen_loss = 1.4196045929482424, disc_loss = 0.028467164526833975
Trained batch 557 in epoch 0, gen_loss = 1.4191798821999608, disc_loss = 0.028424956960775506
Trained batch 558 in epoch 0, gen_loss = 1.4186432828630233, disc_loss = 0.028382194647273925
Trained batch 559 in epoch 0, gen_loss = 1.418401586157935, disc_loss = 0.02833905195979501
Trained batch 560 in epoch 0, gen_loss = 1.4177941054158882, disc_loss = 0.028292360863940536
Trained batch 561 in epoch 0, gen_loss = 1.417690987900907, disc_loss = 0.028248379000146075
Trained batch 562 in epoch 0, gen_loss = 1.4173290498726745, disc_loss = 0.028205811737318644
Trained batch 563 in epoch 0, gen_loss = 1.4172070256784453, disc_loss = 0.028162673316980177
Trained batch 564 in epoch 0, gen_loss = 1.416767927397669, disc_loss = 0.028120901684309727
Trained batch 565 in epoch 0, gen_loss = 1.4163104765406767, disc_loss = 0.028075321467038797
Trained batch 566 in epoch 0, gen_loss = 1.4160014786207276, disc_loss = 0.02803031611523215
Trained batch 567 in epoch 0, gen_loss = 1.4155034689416348, disc_loss = 0.027985319880724387
Trained batch 568 in epoch 0, gen_loss = 1.4150454991731158, disc_loss = 0.02793953661775783
Trained batch 569 in epoch 0, gen_loss = 1.4148106978650679, disc_loss = 0.027895283127987856
Trained batch 570 in epoch 0, gen_loss = 1.4147075439710333, disc_loss = 0.02784992763266985
Trained batch 571 in epoch 0, gen_loss = 1.414372091318344, disc_loss = 0.02780673707350177
Trained batch 572 in epoch 0, gen_loss = 1.4145050013460623, disc_loss = 0.027762070745164708
Trained batch 573 in epoch 0, gen_loss = 1.4141764480893204, disc_loss = 0.027718429582660777
Trained batch 574 in epoch 0, gen_loss = 1.4138146352767944, disc_loss = 0.027677374095048595
Trained batch 575 in epoch 0, gen_loss = 1.4138815781722467, disc_loss = 0.027633566908560978
Trained batch 576 in epoch 0, gen_loss = 1.413590573355478, disc_loss = 0.02759190103115007
Trained batch 577 in epoch 0, gen_loss = 1.413203686578876, disc_loss = 0.027546483937934504
Trained batch 578 in epoch 0, gen_loss = 1.4134350356248582, disc_loss = 0.027503265255325458
Trained batch 579 in epoch 0, gen_loss = 1.413112038373947, disc_loss = 0.027458820980572108
Trained batch 580 in epoch 0, gen_loss = 1.4132799334862556, disc_loss = 0.027415601430835903
Trained batch 581 in epoch 0, gen_loss = 1.4128795487364543, disc_loss = 0.02737202419686576
Trained batch 582 in epoch 0, gen_loss = 1.4125229240895136, disc_loss = 0.027328211793198377
Trained batch 583 in epoch 0, gen_loss = 1.4126126668224597, disc_loss = 0.027283949828315973
Trained batch 584 in epoch 0, gen_loss = 1.4120499859508286, disc_loss = 0.027243017645863194
Trained batch 585 in epoch 0, gen_loss = 1.4116530867973691, disc_loss = 0.027203572410398797
Trained batch 586 in epoch 0, gen_loss = 1.4110711869836057, disc_loss = 0.027162006400324075
Trained batch 587 in epoch 0, gen_loss = 1.4108955077573555, disc_loss = 0.02711975448317414
Trained batch 588 in epoch 0, gen_loss = 1.410620775813765, disc_loss = 0.027077230633353475
Trained batch 589 in epoch 0, gen_loss = 1.4110588190919262, disc_loss = 0.027036577206839003
Trained batch 590 in epoch 0, gen_loss = 1.410723208977688, disc_loss = 0.02699401058325963
Trained batch 591 in epoch 0, gen_loss = 1.4105572305821084, disc_loss = 0.026953914244045706
Trained batch 592 in epoch 0, gen_loss = 1.4101528053943062, disc_loss = 0.02691412799713684
Trained batch 593 in epoch 0, gen_loss = 1.4098687165915365, disc_loss = 0.02687262296120037
Trained batch 594 in epoch 0, gen_loss = 1.4093782879725223, disc_loss = 0.02683261890246087
Trained batch 595 in epoch 0, gen_loss = 1.4092592603008218, disc_loss = 0.02679248657640095
Trained batch 596 in epoch 0, gen_loss = 1.4092221747291347, disc_loss = 0.026751712045727464
Trained batch 597 in epoch 0, gen_loss = 1.4091919640633574, disc_loss = 0.02671061223372817
Trained batch 598 in epoch 0, gen_loss = 1.4091710785593532, disc_loss = 0.026669928233429965
Trained batch 599 in epoch 0, gen_loss = 1.4088747451702754, disc_loss = 0.02662762688395257
Trained batch 600 in epoch 0, gen_loss = 1.408618544183436, disc_loss = 0.026585844898605705
Trained batch 601 in epoch 0, gen_loss = 1.4084505858611427, disc_loss = 0.026545546219090117
Trained batch 602 in epoch 0, gen_loss = 1.4080492018862545, disc_loss = 0.02650512384897898
Trained batch 603 in epoch 0, gen_loss = 1.4077244231243007, disc_loss = 0.02646819173107047
Trained batch 604 in epoch 0, gen_loss = 1.4073543146622083, disc_loss = 0.026432610491352263
Trained batch 605 in epoch 0, gen_loss = 1.4071202498458006, disc_loss = 0.026395255838453206
Trained batch 606 in epoch 0, gen_loss = 1.4065508282754136, disc_loss = 0.026358195783837378
Trained batch 607 in epoch 0, gen_loss = 1.4063739453099275, disc_loss = 0.02631920351421669
Trained batch 608 in epoch 0, gen_loss = 1.4060050806975717, disc_loss = 0.026279444486278985
Trained batch 609 in epoch 0, gen_loss = 1.406377184977297, disc_loss = 0.026239653732856645
Trained batch 610 in epoch 0, gen_loss = 1.4065350838456723, disc_loss = 0.026199658207348417
Trained batch 611 in epoch 0, gen_loss = 1.4062930713681614, disc_loss = 0.02616032040366002
Trained batch 612 in epoch 0, gen_loss = 1.4064820781228593, disc_loss = 0.026120854969718305
Trained batch 613 in epoch 0, gen_loss = 1.4061537218016211, disc_loss = 0.02608601628849738
Trained batch 614 in epoch 0, gen_loss = 1.4060383077559433, disc_loss = 0.026049678763980424
Trained batch 615 in epoch 0, gen_loss = 1.4057003046785082, disc_loss = 0.026014623469930116
Trained batch 616 in epoch 0, gen_loss = 1.4052990491425006, disc_loss = 0.025979995047160375
Trained batch 617 in epoch 0, gen_loss = 1.404988888012167, disc_loss = 0.02594233796973999
Trained batch 618 in epoch 0, gen_loss = 1.4048837090154842, disc_loss = 0.025907492033403024
Trained batch 619 in epoch 0, gen_loss = 1.404893998945913, disc_loss = 0.025869344541382407
Trained batch 620 in epoch 0, gen_loss = 1.404571233548212, disc_loss = 0.0258340107632468
Trained batch 621 in epoch 0, gen_loss = 1.404413841353352, disc_loss = 0.025796560657441233
Trained batch 622 in epoch 0, gen_loss = 1.4046016483781425, disc_loss = 0.02575991614788986
Trained batch 623 in epoch 0, gen_loss = 1.4042750992454016, disc_loss = 0.025723612710209683
Trained batch 624 in epoch 0, gen_loss = 1.4048010271072389, disc_loss = 0.02568585122227669
Trained batch 625 in epoch 0, gen_loss = 1.4048377677274588, disc_loss = 0.025648308429902737
Trained batch 626 in epoch 0, gen_loss = 1.4046313125741159, disc_loss = 0.025610003303632473
Trained batch 627 in epoch 0, gen_loss = 1.4044973582598814, disc_loss = 0.025571907485633566
Trained batch 628 in epoch 0, gen_loss = 1.404326373897789, disc_loss = 0.025534989312291145
Trained batch 629 in epoch 0, gen_loss = 1.4041500988460722, disc_loss = 0.025496869310108382
Trained batch 630 in epoch 0, gen_loss = 1.4038489694262835, disc_loss = 0.025459658978661898
Trained batch 631 in epoch 0, gen_loss = 1.4035100014526634, disc_loss = 0.025421768293164882
Trained batch 632 in epoch 0, gen_loss = 1.4032591178330576, disc_loss = 0.025384447274186706
Trained batch 633 in epoch 0, gen_loss = 1.4038655622524419, disc_loss = 0.025347800773152736
Trained batch 634 in epoch 0, gen_loss = 1.4037268107331644, disc_loss = 0.02531099230194039
Trained batch 635 in epoch 0, gen_loss = 1.403453088593933, disc_loss = 0.025273633123054785
Trained batch 636 in epoch 0, gen_loss = 1.4037782432894506, disc_loss = 0.025236221071840023
Trained batch 637 in epoch 0, gen_loss = 1.4034851346643742, disc_loss = 0.025199550000525907
Trained batch 638 in epoch 0, gen_loss = 1.4038522090523828, disc_loss = 0.02516215174832033
Trained batch 639 in epoch 0, gen_loss = 1.4037618786096573, disc_loss = 0.025124948744633002
Trained batch 640 in epoch 0, gen_loss = 1.4036319095891276, disc_loss = 0.025088750387508532
Trained batch 641 in epoch 0, gen_loss = 1.4032962155119282, disc_loss = 0.025052006746101196
Trained batch 642 in epoch 0, gen_loss = 1.403342953736823, disc_loss = 0.025015701190206407
Trained batch 643 in epoch 0, gen_loss = 1.4029418400355749, disc_loss = 0.024981450663499175
Trained batch 644 in epoch 0, gen_loss = 1.402774344858273, disc_loss = 0.024946141383942765
Trained batch 645 in epoch 0, gen_loss = 1.402718331791668, disc_loss = 0.02491002480265895
Trained batch 646 in epoch 0, gen_loss = 1.4032157202592404, disc_loss = 0.02487401468330243
Trained batch 647 in epoch 0, gen_loss = 1.4029843579103918, disc_loss = 0.02483770226643645
Trained batch 648 in epoch 0, gen_loss = 1.4027669631828696, disc_loss = 0.024802929222926737
Trained batch 649 in epoch 0, gen_loss = 1.4026765363033, disc_loss = 0.02476839676194896
Trained batch 650 in epoch 0, gen_loss = 1.402545810112023, disc_loss = 0.02473238043572193
Trained batch 651 in epoch 0, gen_loss = 1.402174333670388, disc_loss = 0.02469679131708251
Trained batch 652 in epoch 0, gen_loss = 1.4018167038241354, disc_loss = 0.024661215173207497
Trained batch 653 in epoch 0, gen_loss = 1.401420607114786, disc_loss = 0.024625175576642816
Trained batch 654 in epoch 0, gen_loss = 1.4010614986638077, disc_loss = 0.024589187924871008
Trained batch 655 in epoch 0, gen_loss = 1.400766665797408, disc_loss = 0.024553352933009327
Trained batch 656 in epoch 0, gen_loss = 1.4009322225593903, disc_loss = 0.024518873354900612
Trained batch 657 in epoch 0, gen_loss = 1.4008910076234116, disc_loss = 0.024484020452075962
Trained batch 658 in epoch 0, gen_loss = 1.4009649728245366, disc_loss = 0.024449368432335195
Trained batch 659 in epoch 0, gen_loss = 1.4006455901897314, disc_loss = 0.024414998238419437
Trained batch 660 in epoch 0, gen_loss = 1.4003370443018048, disc_loss = 0.024382502761170686
Trained batch 661 in epoch 0, gen_loss = 1.4001562541345094, disc_loss = 0.024348868502921558
Trained batch 662 in epoch 0, gen_loss = 1.3998103598483906, disc_loss = 0.024315815083759795
Trained batch 663 in epoch 0, gen_loss = 1.3996369192399174, disc_loss = 0.024282907007973226
Trained batch 664 in epoch 0, gen_loss = 1.3999892776173757, disc_loss = 0.02425017209033853
Trained batch 665 in epoch 0, gen_loss = 1.4002027604673002, disc_loss = 0.02421619940105848
Trained batch 666 in epoch 0, gen_loss = 1.4003846723994036, disc_loss = 0.024182616787644263
Trained batch 667 in epoch 0, gen_loss = 1.4001202356672573, disc_loss = 0.02414946535147007
Trained batch 668 in epoch 0, gen_loss = 1.399909667548221, disc_loss = 0.024115893247631977
Trained batch 669 in epoch 0, gen_loss = 1.3998059178466227, disc_loss = 0.024081892404990243
Trained batch 670 in epoch 0, gen_loss = 1.3994619613610508, disc_loss = 0.02404940018764157
Trained batch 671 in epoch 0, gen_loss = 1.3993264896174271, disc_loss = 0.024016022746114425
Trained batch 672 in epoch 0, gen_loss = 1.3991258087696683, disc_loss = 0.02398297513774935
Trained batch 673 in epoch 0, gen_loss = 1.399216596379832, disc_loss = 0.02395046279038156
Trained batch 674 in epoch 0, gen_loss = 1.398953290692082, disc_loss = 0.023917748290114105
Trained batch 675 in epoch 0, gen_loss = 1.399059146995375, disc_loss = 0.02388460513913161
Trained batch 676 in epoch 0, gen_loss = 1.3986443689690031, disc_loss = 0.023852104425672413
Trained batch 677 in epoch 0, gen_loss = 1.3990029938804716, disc_loss = 0.02381927090948365
Trained batch 678 in epoch 0, gen_loss = 1.3987313679286413, disc_loss = 0.023787440372416983
Trained batch 679 in epoch 0, gen_loss = 1.3987751815248939, disc_loss = 0.02375501321238356
Trained batch 680 in epoch 0, gen_loss = 1.3987259689756777, disc_loss = 0.023723644856431914
Trained batch 681 in epoch 0, gen_loss = 1.3985134532724308, disc_loss = 0.02370063709798392
Trained batch 682 in epoch 0, gen_loss = 1.3983313724900408, disc_loss = 0.023673924844163863
Trained batch 683 in epoch 0, gen_loss = 1.3982483477968919, disc_loss = 0.02365402760541023
Trained batch 684 in epoch 0, gen_loss = 1.3981311907733445, disc_loss = 0.023632159772376617
Trained batch 685 in epoch 0, gen_loss = 1.3976669518315061, disc_loss = 0.02360276916945413
Trained batch 686 in epoch 0, gen_loss = 1.3973081130995326, disc_loss = 0.023574028528814666
Trained batch 687 in epoch 0, gen_loss = 1.3971147083265836, disc_loss = 0.023547661955046012
Trained batch 688 in epoch 0, gen_loss = 1.39707897969012, disc_loss = 0.023517459901982406
Trained batch 689 in epoch 0, gen_loss = 1.3966988136802894, disc_loss = 0.02348597435604619
Trained batch 690 in epoch 0, gen_loss = 1.3963510733092401, disc_loss = 0.023455696024793145
Trained batch 691 in epoch 0, gen_loss = 1.3961414920456836, disc_loss = 0.0234280255706604
Trained batch 692 in epoch 0, gen_loss = 1.3956928863841906, disc_loss = 0.023399260196791796
Trained batch 693 in epoch 0, gen_loss = 1.3954218574490946, disc_loss = 0.023368266381937956
Trained batch 694 in epoch 0, gen_loss = 1.395271505383279, disc_loss = 0.023336701154065647
Trained batch 695 in epoch 0, gen_loss = 1.395247581361354, disc_loss = 0.023306088489962035
Trained batch 696 in epoch 0, gen_loss = 1.395108368338608, disc_loss = 0.023275358129728325
Trained batch 697 in epoch 0, gen_loss = 1.394742880987916, disc_loss = 0.02324543838565342
Trained batch 698 in epoch 0, gen_loss = 1.3946312254931623, disc_loss = 0.023216023773037546
Trained batch 699 in epoch 0, gen_loss = 1.394603693996157, disc_loss = 0.02318605346704966
Trained batch 700 in epoch 0, gen_loss = 1.3943426750185826, disc_loss = 0.023155311510643088
Trained batch 701 in epoch 0, gen_loss = 1.3940671692546616, disc_loss = 0.023125941204630168
Trained batch 702 in epoch 0, gen_loss = 1.3938343789465566, disc_loss = 0.023096191320087427
Trained batch 703 in epoch 0, gen_loss = 1.3936258002438329, disc_loss = 0.023065957875752992
Trained batch 704 in epoch 0, gen_loss = 1.3933462760127182, disc_loss = 0.023035873725336598
Trained batch 705 in epoch 0, gen_loss = 1.3929696392067432, disc_loss = 0.023007116130442377
Trained batch 706 in epoch 0, gen_loss = 1.3927349106763005, disc_loss = 0.022978185574936416
Trained batch 707 in epoch 0, gen_loss = 1.392647341988181, disc_loss = 0.022949254946943668
Trained batch 708 in epoch 0, gen_loss = 1.3923602458956548, disc_loss = 0.022919780094956793
Trained batch 709 in epoch 0, gen_loss = 1.3922346875701153, disc_loss = 0.022890510259878257
Trained batch 710 in epoch 0, gen_loss = 1.3923688293677006, disc_loss = 0.02286267636242976
Trained batch 711 in epoch 0, gen_loss = 1.3923324475462517, disc_loss = 0.022833962912352106
Trained batch 712 in epoch 0, gen_loss = 1.3925578207989728, disc_loss = 0.022805598994186684
Trained batch 713 in epoch 0, gen_loss = 1.3922137384321176, disc_loss = 0.022776543195372454
Trained batch 714 in epoch 0, gen_loss = 1.3921355297515443, disc_loss = 0.02274779184701872
Trained batch 715 in epoch 0, gen_loss = 1.392044114999931, disc_loss = 0.022717617251832224
Trained batch 716 in epoch 0, gen_loss = 1.392085498180682, disc_loss = 0.022687735237022718
Trained batch 717 in epoch 0, gen_loss = 1.391842111405556, disc_loss = 0.022659917412297205
Trained batch 718 in epoch 0, gen_loss = 1.391758715824557, disc_loss = 0.022633354175351405
Trained batch 719 in epoch 0, gen_loss = 1.391615243918366, disc_loss = 0.022604621065288988
Trained batch 720 in epoch 0, gen_loss = 1.3917173041384694, disc_loss = 0.022575425000889705
Trained batch 721 in epoch 0, gen_loss = 1.391619765197141, disc_loss = 0.022545843618796812
Trained batch 722 in epoch 0, gen_loss = 1.3916692829395891, disc_loss = 0.0225163048019254
Trained batch 723 in epoch 0, gen_loss = 1.3914713019824159, disc_loss = 0.02249025381961323
Trained batch 724 in epoch 0, gen_loss = 1.3914940314457334, disc_loss = 0.022461512645000015
Trained batch 725 in epoch 0, gen_loss = 1.3912184862394306, disc_loss = 0.02243359284392063
Trained batch 726 in epoch 0, gen_loss = 1.390818092157293, disc_loss = 0.02240607062831234
Trained batch 727 in epoch 0, gen_loss = 1.3905328669390835, disc_loss = 0.022378202674879725
Trained batch 728 in epoch 0, gen_loss = 1.3909373080615972, disc_loss = 0.022349603622174464
Trained batch 729 in epoch 0, gen_loss = 1.391043811954864, disc_loss = 0.022321534648614184
Trained batch 730 in epoch 0, gen_loss = 1.3912346878390958, disc_loss = 0.022293398056750055
Trained batch 731 in epoch 0, gen_loss = 1.3908540775867109, disc_loss = 0.02226787542891205
Trained batch 732 in epoch 0, gen_loss = 1.3907193298391887, disc_loss = 0.02224159734653967
Trained batch 733 in epoch 0, gen_loss = 1.390554585313927, disc_loss = 0.022217943020322303
Trained batch 734 in epoch 0, gen_loss = 1.3904215848364798, disc_loss = 0.02219004450068131
Trained batch 735 in epoch 0, gen_loss = 1.3904971917686255, disc_loss = 0.0221633281281633
Trained batch 736 in epoch 0, gen_loss = 1.390856114462564, disc_loss = 0.022134980017646612
Trained batch 737 in epoch 0, gen_loss = 1.3909409603452294, disc_loss = 0.02210812223018311
Trained batch 738 in epoch 0, gen_loss = 1.3906660723589432, disc_loss = 0.0220811236478043
Trained batch 739 in epoch 0, gen_loss = 1.390330280001099, disc_loss = 0.02205426918478003
Trained batch 740 in epoch 0, gen_loss = 1.3899944174466667, disc_loss = 0.022026608437431698
Trained batch 741 in epoch 0, gen_loss = 1.390113345696277, disc_loss = 0.022000584531872914
Trained batch 742 in epoch 0, gen_loss = 1.3902891818158238, disc_loss = 0.02197323739293632
Trained batch 743 in epoch 0, gen_loss = 1.3900205406450457, disc_loss = 0.02194802046760351
Trained batch 744 in epoch 0, gen_loss = 1.3898174839531816, disc_loss = 0.021920641932492737
Trained batch 745 in epoch 0, gen_loss = 1.3894272841333384, disc_loss = 0.021893184142837665
Trained batch 746 in epoch 0, gen_loss = 1.3891749043700845, disc_loss = 0.021865339691026345
Trained batch 747 in epoch 0, gen_loss = 1.3891624919870957, disc_loss = 0.021838240459453026
Trained batch 748 in epoch 0, gen_loss = 1.3889500716022243, disc_loss = 0.02181133699963349
Trained batch 749 in epoch 0, gen_loss = 1.3888319743474324, disc_loss = 0.021785501554763564
Trained batch 750 in epoch 0, gen_loss = 1.3895726292809538, disc_loss = 0.021758475367100127
Trained batch 751 in epoch 0, gen_loss = 1.3896901487035955, disc_loss = 0.021731464425256683
Trained batch 752 in epoch 0, gen_loss = 1.3897103994174467, disc_loss = 0.021705597630889955
Trained batch 753 in epoch 0, gen_loss = 1.389743145169883, disc_loss = 0.021679844889593427
Trained batch 754 in epoch 0, gen_loss = 1.3895575458640295, disc_loss = 0.021652595303638143
Trained batch 755 in epoch 0, gen_loss = 1.3893976911665902, disc_loss = 0.02162572498098829
Trained batch 756 in epoch 0, gen_loss = 1.3892458263130139, disc_loss = 0.02159893094015134
Trained batch 757 in epoch 0, gen_loss = 1.3890116672402637, disc_loss = 0.021572211235276324
Trained batch 758 in epoch 0, gen_loss = 1.3889213187892446, disc_loss = 0.021545449366433513
Trained batch 759 in epoch 0, gen_loss = 1.388650064876205, disc_loss = 0.021519247103500866
Trained batch 760 in epoch 0, gen_loss = 1.3884405856376878, disc_loss = 0.021492806156643184
Trained batch 761 in epoch 0, gen_loss = 1.388236107632244, disc_loss = 0.02146856975298634
Trained batch 762 in epoch 0, gen_loss = 1.3883580488114964, disc_loss = 0.02144226655202306
Trained batch 763 in epoch 0, gen_loss = 1.3880778131372642, disc_loss = 0.021418201505341836
Trained batch 764 in epoch 0, gen_loss = 1.38770923785914, disc_loss = 0.02139469391888531
Trained batch 765 in epoch 0, gen_loss = 1.3879475034870616, disc_loss = 0.0213693185317617
Trained batch 766 in epoch 0, gen_loss = 1.3879509533244285, disc_loss = 0.021343436551273035
Trained batch 767 in epoch 0, gen_loss = 1.387626939297964, disc_loss = 0.02131703116871601
Trained batch 768 in epoch 0, gen_loss = 1.3873610764703144, disc_loss = 0.021291914412943144
Trained batch 769 in epoch 0, gen_loss = 1.3872478180117422, disc_loss = 0.021266328336296048
Trained batch 770 in epoch 0, gen_loss = 1.3870185183798447, disc_loss = 0.02124165334369161
Trained batch 771 in epoch 0, gen_loss = 1.3868495661359994, disc_loss = 0.021218243504722404
Trained batch 772 in epoch 0, gen_loss = 1.3865369057130998, disc_loss = 0.02119414716745747
Trained batch 773 in epoch 0, gen_loss = 1.3862857281083591, disc_loss = 0.02116846129281966
Trained batch 774 in epoch 0, gen_loss = 1.3863618132375901, disc_loss = 0.02114407222793107
Trained batch 775 in epoch 0, gen_loss = 1.3860310717034585, disc_loss = 0.02112159392926674
Trained batch 776 in epoch 0, gen_loss = 1.3860266596807629, disc_loss = 0.021099188847334256
Trained batch 777 in epoch 0, gen_loss = 1.386006230100568, disc_loss = 0.021076054679341184
Trained batch 778 in epoch 0, gen_loss = 1.3857859706695028, disc_loss = 0.02105105969327381
Trained batch 779 in epoch 0, gen_loss = 1.3854445969447111, disc_loss = 0.02102637301954345
Trained batch 780 in epoch 0, gen_loss = 1.385070388814704, disc_loss = 0.021001614696553712
Trained batch 781 in epoch 0, gen_loss = 1.385012559421227, disc_loss = 0.020976682582720067
Trained batch 782 in epoch 0, gen_loss = 1.3846943710346635, disc_loss = 0.020952113838194324
Trained batch 783 in epoch 0, gen_loss = 1.3850980612392327, disc_loss = 0.020927873971231747
Trained batch 784 in epoch 0, gen_loss = 1.384994232730501, disc_loss = 0.020903869365804656
Trained batch 785 in epoch 0, gen_loss = 1.3845804756834308, disc_loss = 0.020879541095269193
Trained batch 786 in epoch 0, gen_loss = 1.3842942157270341, disc_loss = 0.020854398587794344
Trained batch 787 in epoch 0, gen_loss = 1.3841555980861489, disc_loss = 0.020829085425132777
Trained batch 788 in epoch 0, gen_loss = 1.383911110451315, disc_loss = 0.02080655259223943
Trained batch 789 in epoch 0, gen_loss = 1.3838741887973833, disc_loss = 0.020784093219642467
Testing Epoch 0
Traceback (most recent call last):
  File "srgan_bones.py", line 358, in <module>
    img_grid1 = utils.make_images2(imgs_hr[:5], imgs_lr[:5], gen_hr[:5])
  File "/work3/soeba/HALOS/utils.py", line 133, in make_images2
    axs[i,0].imshow(target[i].cpu().detach(), interpolation='none', origin='upper', cmap=plt.cm.jet)
  File "/work3/soeba/HALOS/halos/lib/python3.8/site-packages/matplotlib/_api/deprecation.py", line 459, in wrapper
    return func(*args, **kwargs)
  File "/work3/soeba/HALOS/halos/lib/python3.8/site-packages/matplotlib/__init__.py", line 1412, in inner
    return func(ax, *map(sanitize_sequence, args), **kwargs)
  File "/work3/soeba/HALOS/halos/lib/python3.8/site-packages/matplotlib/axes/_axes.py", line 5481, in imshow
    im.set_data(X)
  File "/work3/soeba/HALOS/halos/lib/python3.8/site-packages/matplotlib/image.py", line 715, in set_data
    raise TypeError("Invalid shape {} for image data"
TypeError: Invalid shape (1, 128, 128) for image data
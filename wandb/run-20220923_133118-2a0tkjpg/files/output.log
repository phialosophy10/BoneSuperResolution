/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 1.2049791812896729, disc_loss = 0.43693411350250244
Trained batch 1 in epoch 0, gen_loss = 1.1808879971504211, disc_loss = 0.5998431742191315
Trained batch 2 in epoch 0, gen_loss = 1.1742353041966755, disc_loss = 0.584687332312266
Trained batch 3 in epoch 0, gen_loss = 1.1931602954864502, disc_loss = 0.5141485780477524
Trained batch 4 in epoch 0, gen_loss = 1.2136349201202392, disc_loss = 0.45971280336380005
Trained batch 5 in epoch 0, gen_loss = 1.2219131191571553, disc_loss = 0.42085806528727215
Trained batch 6 in epoch 0, gen_loss = 1.190059048788888, disc_loss = 0.3901946949107306
Trained batch 7 in epoch 0, gen_loss = 1.1679898649454117, disc_loss = 0.37226773239672184
Trained batch 8 in epoch 0, gen_loss = 1.1662393278545804, disc_loss = 0.3508811609612571
Trained batch 9 in epoch 0, gen_loss = 1.1726359486579896, disc_loss = 0.33056065291166303
Trained batch 10 in epoch 0, gen_loss = 1.1775384491140193, disc_loss = 0.31123570894653146
Trained batch 11 in epoch 0, gen_loss = 1.1713556945323944, disc_loss = 0.29382726550102234
Trained batch 12 in epoch 0, gen_loss = 1.1582645911436815, disc_loss = 0.2794720438810495
Trained batch 13 in epoch 0, gen_loss = 1.147824994155339, disc_loss = 0.26949307535375866
Trained batch 14 in epoch 0, gen_loss = 1.1437321186065674, disc_loss = 0.26642319361368816
Trained batch 15 in epoch 0, gen_loss = 1.1508058607578278, disc_loss = 0.2612522095441818
Trained batch 16 in epoch 0, gen_loss = 1.1312538315268124, disc_loss = 0.25766074657440186
Trained batch 17 in epoch 0, gen_loss = 1.1510846879747179, disc_loss = 0.2551298571957482
Trained batch 18 in epoch 0, gen_loss = 1.1425461267170154, disc_loss = 0.2486657413997148
Trained batch 19 in epoch 0, gen_loss = 1.1367006599903107, disc_loss = 0.24189550057053566
Trained batch 20 in epoch 0, gen_loss = 1.1438051348640805, disc_loss = 0.2359006819980485
Trained batch 21 in epoch 0, gen_loss = 1.1417888457124883, disc_loss = 0.2307175468992103
Trained batch 22 in epoch 0, gen_loss = 1.1418178703473962, disc_loss = 0.22511537632216577
Trained batch 23 in epoch 0, gen_loss = 1.1485860000054042, disc_loss = 0.21971122330675522
Trained batch 24 in epoch 0, gen_loss = 1.1430546236038208, disc_loss = 0.21514950096607208
Trained batch 25 in epoch 0, gen_loss = 1.1491517883080702, disc_loss = 0.20998647063970566
Trained batch 26 in epoch 0, gen_loss = 1.154185034610607, disc_loss = 0.20477671866063718
Trained batch 27 in epoch 0, gen_loss = 1.148478552699089, disc_loss = 0.2003488431551627
Trained batch 28 in epoch 0, gen_loss = 1.1536922927560478, disc_loss = 0.19624300994749727
Trained batch 29 in epoch 0, gen_loss = 1.1526520152886708, disc_loss = 0.19217769131064416
Trained batch 30 in epoch 0, gen_loss = 1.152863988953252, disc_loss = 0.18832929648699298
Trained batch 31 in epoch 0, gen_loss = 1.1598865110427141, disc_loss = 0.1847980886232108
Trained batch 32 in epoch 0, gen_loss = 1.1632316997556975, disc_loss = 0.18162768424460382
Trained batch 33 in epoch 0, gen_loss = 1.1703223217936123, disc_loss = 0.17824005182175076
Trained batch 34 in epoch 0, gen_loss = 1.1743031791278293, disc_loss = 0.1752493549670492
Trained batch 35 in epoch 0, gen_loss = 1.1818810916609235, disc_loss = 0.172239163890481
Trained batch 36 in epoch 0, gen_loss = 1.1850564109312522, disc_loss = 0.16939156542758685
Trained batch 37 in epoch 0, gen_loss = 1.1935976822125285, disc_loss = 0.1664005559133856
Trained batch 38 in epoch 0, gen_loss = 1.2020561129618914, disc_loss = 0.16360832101259476
Trained batch 39 in epoch 0, gen_loss = 1.2107843950390815, disc_loss = 0.16092438120394945
Trained batch 40 in epoch 0, gen_loss = 1.216815397506807, disc_loss = 0.158511751581256
Trained batch 41 in epoch 0, gen_loss = 1.223958425578617, disc_loss = 0.15598740038417636
Trained batch 42 in epoch 0, gen_loss = 1.2295619540436322, disc_loss = 0.15348589299030083
Trained batch 43 in epoch 0, gen_loss = 1.2325110205195167, disc_loss = 0.15100668082860383
Trained batch 44 in epoch 0, gen_loss = 1.2443716062439814, disc_loss = 0.14877597639958065
Trained batch 45 in epoch 0, gen_loss = 1.2582045728745668, disc_loss = 0.14703055892301642
Trained batch 46 in epoch 0, gen_loss = 1.2598003821170076, disc_loss = 0.14520378632748382
Trained batch 47 in epoch 0, gen_loss = 1.2709410078823566, disc_loss = 0.14310965624948344
Trained batch 48 in epoch 0, gen_loss = 1.276270930864373, disc_loss = 0.14098326458918806
Trained batch 49 in epoch 0, gen_loss = 1.2713300096988678, disc_loss = 0.13972820155322552
Trained batch 50 in epoch 0, gen_loss = 1.278618591673234, disc_loss = 0.13811463073772542
Trained batch 51 in epoch 0, gen_loss = 1.2742737978696823, disc_loss = 0.13650676851662305
Trained batch 52 in epoch 0, gen_loss = 1.2776100826713275, disc_loss = 0.13476157364136768
Trained batch 53 in epoch 0, gen_loss = 1.2835124300585852, disc_loss = 0.13356302768267966
Trained batch 54 in epoch 0, gen_loss = 1.2825926401398398, disc_loss = 0.13394158137115567
Trained batch 55 in epoch 0, gen_loss = 1.2963002036724771, disc_loss = 0.1360470911354891
Trained batch 56 in epoch 0, gen_loss = 1.2876934158174616, disc_loss = 0.136824406618089
Trained batch 57 in epoch 0, gen_loss = 1.3088352135543166, disc_loss = 0.14057482220232487
Trained batch 58 in epoch 0, gen_loss = 1.3123337848711822, disc_loss = 0.1397932296208406
Trained batch 59 in epoch 0, gen_loss = 1.3081550528605779, disc_loss = 0.13974898289889098
Trained batch 60 in epoch 0, gen_loss = 1.3052952631575163, disc_loss = 0.13888090378681167
Trained batch 61 in epoch 0, gen_loss = 1.31032369117583, disc_loss = 0.13787397195494944
Trained batch 62 in epoch 0, gen_loss = 1.3062641573330713, disc_loss = 0.1371454865568214
Trained batch 63 in epoch 0, gen_loss = 1.3081557815894485, disc_loss = 0.13646431028610095
Trained batch 64 in epoch 0, gen_loss = 1.307113411793342, disc_loss = 0.1362346668082934
Trained batch 65 in epoch 0, gen_loss = 1.3050542211893834, disc_loss = 0.13542106708116602
Trained batch 66 in epoch 0, gen_loss = 1.3041342843824357, disc_loss = 0.1345546186081509
Trained batch 67 in epoch 0, gen_loss = 1.3050024167579763, disc_loss = 0.13343774927232196
Trained batch 68 in epoch 0, gen_loss = 1.2991483392922774, disc_loss = 0.13276900216073229
Trained batch 69 in epoch 0, gen_loss = 1.3046628415584565, disc_loss = 0.1328764103885208
Trained batch 70 in epoch 0, gen_loss = 1.2978083256264807, disc_loss = 0.13328566680281934
Trained batch 71 in epoch 0, gen_loss = 1.296188241077794, disc_loss = 0.13205192600273424
Trained batch 72 in epoch 0, gen_loss = 1.2989887644166815, disc_loss = 0.131298192661919
Trained batch 73 in epoch 0, gen_loss = 1.2982584761606681, disc_loss = 0.13022174172707507
Trained batch 74 in epoch 0, gen_loss = 1.293011236190796, disc_loss = 0.12952453772226968
Trained batch 75 in epoch 0, gen_loss = 1.3006194375063245, disc_loss = 0.12935876787493103
Trained batch 76 in epoch 0, gen_loss = 1.2996243207485645, disc_loss = 0.12835921700318137
Trained batch 77 in epoch 0, gen_loss = 1.298272194006504, disc_loss = 0.12727407389917436
Trained batch 78 in epoch 0, gen_loss = 1.3005291540411454, disc_loss = 0.12609127574140513
Trained batch 79 in epoch 0, gen_loss = 1.2999263539910317, disc_loss = 0.12497820788994432
Trained batch 80 in epoch 0, gen_loss = 1.298984401020003, disc_loss = 0.12394057527000521
Trained batch 81 in epoch 0, gen_loss = 1.2970979155563727, disc_loss = 0.12301435285225147
Trained batch 82 in epoch 0, gen_loss = 1.3003781875932072, disc_loss = 0.12202635847301369
Trained batch 83 in epoch 0, gen_loss = 1.3000834385553997, disc_loss = 0.12096088117964211
Trained batch 84 in epoch 0, gen_loss = 1.3007168938131894, disc_loss = 0.11991016658789971
Trained batch 85 in epoch 0, gen_loss = 1.2994474380515342, disc_loss = 0.11910282547564008
Trained batch 86 in epoch 0, gen_loss = 1.3010710244891288, disc_loss = 0.1182476213608665
Trained batch 87 in epoch 0, gen_loss = 1.295567731965672, disc_loss = 0.11797934499653903
Trained batch 88 in epoch 0, gen_loss = 1.3016251312212999, disc_loss = 0.12038595890730955
Trained batch 89 in epoch 0, gen_loss = 1.2931989391644796, disc_loss = 0.12875805298487344
Trained batch 90 in epoch 0, gen_loss = 1.2860924509855418, disc_loss = 0.12967331625603057
Trained batch 91 in epoch 0, gen_loss = 1.284941064922706, disc_loss = 0.1305239950509175
Trained batch 92 in epoch 0, gen_loss = 1.282542142175859, disc_loss = 0.1315707831933934
Trained batch 93 in epoch 0, gen_loss = 1.2773197007940171, disc_loss = 0.13221488433315398
Trained batch 94 in epoch 0, gen_loss = 1.2721091383381893, disc_loss = 0.1326230874187068
Trained batch 95 in epoch 0, gen_loss = 1.2676507060726483, disc_loss = 0.1328359542724987
Trained batch 96 in epoch 0, gen_loss = 1.264569552288842, disc_loss = 0.13314224011504772
Trained batch 97 in epoch 0, gen_loss = 1.2612600454262324, disc_loss = 0.13316511073890996
Trained batch 98 in epoch 0, gen_loss = 1.2567895241458007, disc_loss = 0.13314586938029588
Trained batch 99 in epoch 0, gen_loss = 1.2542019605636596, disc_loss = 0.13341270208358766
Trained batch 100 in epoch 0, gen_loss = 1.2480519950980007, disc_loss = 0.13406360946079293
Trained batch 101 in epoch 0, gen_loss = 1.248004768408981, disc_loss = 0.13467012462662717
Trained batch 102 in epoch 0, gen_loss = 1.2438882450455602, disc_loss = 0.13452973426545708
Trained batch 103 in epoch 0, gen_loss = 1.23870483900492, disc_loss = 0.13454287513517416
Trained batch 104 in epoch 0, gen_loss = 1.2371957602955046, disc_loss = 0.1343732137055624
Trained batch 105 in epoch 0, gen_loss = 1.2328433996101595, disc_loss = 0.1343040054418006
Trained batch 106 in epoch 0, gen_loss = 1.2314318379509115, disc_loss = 0.13436303113665538
Trained batch 107 in epoch 0, gen_loss = 1.2254706008566751, disc_loss = 0.1354123438122096
Trained batch 108 in epoch 0, gen_loss = 1.2288882737859674, disc_loss = 0.13689771718388305
Trained batch 109 in epoch 0, gen_loss = 1.2228132394227114, disc_loss = 0.1376024599779736
Trained batch 110 in epoch 0, gen_loss = 1.2192226943669018, disc_loss = 0.13776662368495185
Trained batch 111 in epoch 0, gen_loss = 1.2163555632744516, disc_loss = 0.13815688408379043
Trained batch 112 in epoch 0, gen_loss = 1.2123306024391038, disc_loss = 0.1386402559227648
Trained batch 113 in epoch 0, gen_loss = 1.2084749241669972, disc_loss = 0.13890579120631805
Trained batch 114 in epoch 0, gen_loss = 1.206374010314112, disc_loss = 0.1394696848547977
Trained batch 115 in epoch 0, gen_loss = 1.201041650155495, disc_loss = 0.14061756136602369
Trained batch 116 in epoch 0, gen_loss = 1.2004599927837014, disc_loss = 0.1419439571790206
Trained batch 117 in epoch 0, gen_loss = 1.1969454732991882, disc_loss = 0.14280840034707118
Trained batch 118 in epoch 0, gen_loss = 1.1935682036295658, disc_loss = 0.14323273939745768
Trained batch 119 in epoch 0, gen_loss = 1.1907140627503394, disc_loss = 0.1434345499922832
Trained batch 120 in epoch 0, gen_loss = 1.1871716370267316, disc_loss = 0.14366777992445576
Trained batch 121 in epoch 0, gen_loss = 1.1838807424560922, disc_loss = 0.1438314338199428
Trained batch 122 in epoch 0, gen_loss = 1.1811337761762666, disc_loss = 0.14410259338413797
Trained batch 123 in epoch 0, gen_loss = 1.1774248336592028, disc_loss = 0.14438984939648258
Trained batch 124 in epoch 0, gen_loss = 1.1756182126998902, disc_loss = 0.14467410576343537
Trained batch 125 in epoch 0, gen_loss = 1.1716035178729467, disc_loss = 0.14504577798975837
Trained batch 126 in epoch 0, gen_loss = 1.1703292413020696, disc_loss = 0.14513750843645082
Trained batch 127 in epoch 0, gen_loss = 1.1657517761923373, disc_loss = 0.14575603452976793
Trained batch 128 in epoch 0, gen_loss = 1.1663073222766551, disc_loss = 0.14668767916601758
Trained batch 129 in epoch 0, gen_loss = 1.1612543335327736, disc_loss = 0.14795165348511477
Trained batch 130 in epoch 0, gen_loss = 1.1590849875493814, disc_loss = 0.14815206689233998
Trained batch 131 in epoch 0, gen_loss = 1.1565060755520156, disc_loss = 0.14852354054649672
Trained batch 132 in epoch 0, gen_loss = 1.1534259682311152, disc_loss = 0.14875608122438416
Trained batch 133 in epoch 0, gen_loss = 1.1520137088512308, disc_loss = 0.14897643607943806
Trained batch 134 in epoch 0, gen_loss = 1.1497895801508868, disc_loss = 0.1491478862585845
Trained batch 135 in epoch 0, gen_loss = 1.1463307935525389, disc_loss = 0.14925728190471144
Trained batch 136 in epoch 0, gen_loss = 1.1462917384440012, disc_loss = 0.1493254022224106
Trained batch 137 in epoch 0, gen_loss = 1.1428107433560966, disc_loss = 0.14945259074801984
Trained batch 138 in epoch 0, gen_loss = 1.1414451929305096, disc_loss = 0.14939074925810314
Trained batch 139 in epoch 0, gen_loss = 1.1398463112967354, disc_loss = 0.1492977360529559
Trained batch 140 in epoch 0, gen_loss = 1.137061376943656, disc_loss = 0.14924522568570806
Trained batch 141 in epoch 0, gen_loss = 1.1406012765118774, disc_loss = 0.15041310571029154
Trained batch 142 in epoch 0, gen_loss = 1.1370780763926205, disc_loss = 0.15104010367726947
Trained batch 143 in epoch 0, gen_loss = 1.1338602445191808, disc_loss = 0.15127915671716133
Trained batch 144 in epoch 0, gen_loss = 1.1358298194819483, disc_loss = 0.15204283995874998
Trained batch 145 in epoch 0, gen_loss = 1.132740897675083, disc_loss = 0.15217000317491897
Trained batch 146 in epoch 0, gen_loss = 1.1317498375769375, disc_loss = 0.15199099886579578
Trained batch 147 in epoch 0, gen_loss = 1.130449960360656, disc_loss = 0.15189452167298342
Trained batch 148 in epoch 0, gen_loss = 1.1277893621649517, disc_loss = 0.1517201614059858
Trained batch 149 in epoch 0, gen_loss = 1.1264332926273346, disc_loss = 0.15145614524682363
Trained batch 150 in epoch 0, gen_loss = 1.1243771377778211, disc_loss = 0.15121957487025797
Trained batch 151 in epoch 0, gen_loss = 1.1238816717737599, disc_loss = 0.15106420606178672
Trained batch 152 in epoch 0, gen_loss = 1.1213576513178207, disc_loss = 0.15091295993211223
Trained batch 153 in epoch 0, gen_loss = 1.122404372537291, disc_loss = 0.15086500796598273
Trained batch 154 in epoch 0, gen_loss = 1.1190950982032284, disc_loss = 0.1511703193668396
Trained batch 155 in epoch 0, gen_loss = 1.119057868153621, disc_loss = 0.15099110454320908
Trained batch 156 in epoch 0, gen_loss = 1.1182864748748245, disc_loss = 0.15071655297355288
Trained batch 157 in epoch 0, gen_loss = 1.1159329440774797, disc_loss = 0.15060882600425166
Trained batch 158 in epoch 0, gen_loss = 1.1194390632071585, disc_loss = 0.15117059460600968
Trained batch 159 in epoch 0, gen_loss = 1.115978455916047, disc_loss = 0.15176870422437788
Trained batch 160 in epoch 0, gen_loss = 1.115394883644507, disc_loss = 0.15185727114262787
Trained batch 161 in epoch 0, gen_loss = 1.1130887450259408, disc_loss = 0.1519481498334143
Trained batch 162 in epoch 0, gen_loss = 1.1115756455374641, disc_loss = 0.15199109253707838
Trained batch 163 in epoch 0, gen_loss = 1.1120739662792625, disc_loss = 0.1522624325461504
Trained batch 164 in epoch 0, gen_loss = 1.1090169447841067, disc_loss = 0.1526528345816063
Trained batch 165 in epoch 0, gen_loss = 1.1080261766910553, disc_loss = 0.1524669386626008
Trained batch 166 in epoch 0, gen_loss = 1.10838265511804, disc_loss = 0.15252954664523016
Trained batch 167 in epoch 0, gen_loss = 1.1058078525321824, disc_loss = 0.15257809280107418
Trained batch 168 in epoch 0, gen_loss = 1.1063348382887757, disc_loss = 0.1523803364948408
Trained batch 169 in epoch 0, gen_loss = 1.1047045455259434, disc_loss = 0.1521117907236604
Trained batch 170 in epoch 0, gen_loss = 1.1046947596365946, disc_loss = 0.15167100644773907
Trained batch 171 in epoch 0, gen_loss = 1.1053221731684928, disc_loss = 0.1512510652199041
Trained batch 172 in epoch 0, gen_loss = 1.1030530223267616, disc_loss = 0.1511208217354179
Trained batch 173 in epoch 0, gen_loss = 1.1055050858820992, disc_loss = 0.15121435600964503
Trained batch 174 in epoch 0, gen_loss = 1.102477330139705, disc_loss = 0.15137952655553819
Trained batch 175 in epoch 0, gen_loss = 1.102333219552582, disc_loss = 0.15119249043478208
Trained batch 176 in epoch 0, gen_loss = 1.101904787922983, disc_loss = 0.1510794249463216
Trained batch 177 in epoch 0, gen_loss = 1.0990942820404352, disc_loss = 0.15155430648768886
Trained batch 178 in epoch 0, gen_loss = 1.1032140065171865, disc_loss = 0.15271378271073602
Trained batch 179 in epoch 0, gen_loss = 1.1016109979814954, disc_loss = 0.15251405735810597
Trained batch 180 in epoch 0, gen_loss = 1.0993597247323936, disc_loss = 0.1528073937853397
Trained batch 181 in epoch 0, gen_loss = 1.09910350219234, disc_loss = 0.15275848501331205
Trained batch 182 in epoch 0, gen_loss = 1.0987609973370702, disc_loss = 0.1526843870435256
Trained batch 183 in epoch 0, gen_loss = 1.0963972039196803, disc_loss = 0.15287694618429826
Trained batch 184 in epoch 0, gen_loss = 1.096174723071021, disc_loss = 0.1528504430442243
Trained batch 185 in epoch 0, gen_loss = 1.0956110653056894, disc_loss = 0.15281502990632928
Testing Epoch 0

Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 0.7262521982192993, disc_loss = 0.13726870715618134
Trained batch 1 in epoch 1, gen_loss = 0.9687930941581726, disc_loss = 0.13489767909049988
Trained batch 2 in epoch 1, gen_loss = 0.9734487732251486, disc_loss = 0.11428451786438625
Trained batch 3 in epoch 1, gen_loss = 0.9881636947393417, disc_loss = 0.1041539516299963
Trained batch 4 in epoch 1, gen_loss = 0.9946271300315856, disc_loss = 0.10163018703460694
Trained batch 5 in epoch 1, gen_loss = 0.9798299769560496, disc_loss = 0.09797168150544167
Trained batch 6 in epoch 1, gen_loss = 1.0633776102747237, disc_loss = 0.10120106488466263
Trained batch 7 in epoch 1, gen_loss = 1.023436076939106, disc_loss = 0.10550459194928408
Trained batch 8 in epoch 1, gen_loss = 1.0177079505390592, disc_loss = 0.10238168388605118
Trained batch 9 in epoch 1, gen_loss = 1.0990823686122895, disc_loss = 0.11434496864676476
Trained batch 10 in epoch 1, gen_loss = 1.0381271947513928, disc_loss = 0.1442284658551216
Trained batch 11 in epoch 1, gen_loss = 1.0605957607428234, disc_loss = 0.1412529218941927
Trained batch 12 in epoch 1, gen_loss = 1.056197579090412, disc_loss = 0.13975533556479675
Trained batch 13 in epoch 1, gen_loss = 1.0346753767558508, disc_loss = 0.1399694015937192
Trained batch 14 in epoch 1, gen_loss = 1.036869716644287, disc_loss = 0.13727929691473642
Trained batch 15 in epoch 1, gen_loss = 1.0375339984893799, disc_loss = 0.13492504181340337
Trained batch 16 in epoch 1, gen_loss = 1.0134988812839283, disc_loss = 0.13578090466120663
Trained batch 17 in epoch 1, gen_loss = 1.0309192736943562, disc_loss = 0.1350684045917458
Trained batch 18 in epoch 1, gen_loss = 1.0196099657761424, disc_loss = 0.1326967630731432
Trained batch 19 in epoch 1, gen_loss = 1.008813014626503, disc_loss = 0.13171982690691947
Trained batch 20 in epoch 1, gen_loss = 1.0313569449243092, disc_loss = 0.13681968266055697
Trained batch 21 in epoch 1, gen_loss = 1.0107237642461604, disc_loss = 0.13952262970534238
Trained batch 22 in epoch 1, gen_loss = 1.000144626783288, disc_loss = 0.13913077245587888
Trained batch 23 in epoch 1, gen_loss = 1.0153477638959885, disc_loss = 0.14396058395504951
Trained batch 24 in epoch 1, gen_loss = 1.00897469997406, disc_loss = 0.14140847980976104
Trained batch 25 in epoch 1, gen_loss = 0.9997975138517526, disc_loss = 0.14055542504558197
Trained batch 26 in epoch 1, gen_loss = 1.0108276296544958, disc_loss = 0.1395781925982899
Trained batch 27 in epoch 1, gen_loss = 1.0175765071596419, disc_loss = 0.13727187445121153
Trained batch 28 in epoch 1, gen_loss = 1.0096754287851268, disc_loss = 0.13595015889611736
Trained batch 29 in epoch 1, gen_loss = 1.009830931822459, disc_loss = 0.13375623375177384
Trained batch 30 in epoch 1, gen_loss = 1.019129349339393, disc_loss = 0.1315220522303735
Trained batch 31 in epoch 1, gen_loss = 1.0151001922786236, disc_loss = 0.12962953909300268
Trained batch 32 in epoch 1, gen_loss = 1.0243821541468303, disc_loss = 0.12852915940862714
Trained batch 33 in epoch 1, gen_loss = 1.0156752502217012, disc_loss = 0.1281853050870054
Trained batch 34 in epoch 1, gen_loss = 1.0241242170333862, disc_loss = 0.12627212107181549
Trained batch 35 in epoch 1, gen_loss = 1.023758547173606, disc_loss = 0.12443279775066508
Trained batch 36 in epoch 1, gen_loss = 1.013373487704509, disc_loss = 0.12527503445744514
Trained batch 37 in epoch 1, gen_loss = 1.032314695810017, disc_loss = 0.1298784677331385
Trained batch 38 in epoch 1, gen_loss = 1.020472214772151, disc_loss = 0.13215745460146514
Trained batch 39 in epoch 1, gen_loss = 1.0150715351104735, disc_loss = 0.13295141505077482
Trained batch 40 in epoch 1, gen_loss = 1.0224333245579789, disc_loss = 0.13585545059020926
Trained batch 41 in epoch 1, gen_loss = 1.0189916704382216, disc_loss = 0.13518590577656314
Trained batch 42 in epoch 1, gen_loss = 1.0201918787734454, disc_loss = 0.1336751626154711
Trained batch 43 in epoch 1, gen_loss = 1.015657514333725, disc_loss = 0.13277660183269868
Trained batch 44 in epoch 1, gen_loss = 1.0176905711491904, disc_loss = 0.13171288892626762
Trained batch 45 in epoch 1, gen_loss = 1.0203138874924702, disc_loss = 0.12991217742471592
Trained batch 46 in epoch 1, gen_loss = 1.0127654506805095, disc_loss = 0.12983424731708587
Trained batch 47 in epoch 1, gen_loss = 1.0256144205729167, disc_loss = 0.1314706118622174
Trained batch 48 in epoch 1, gen_loss = 1.021492351074608, disc_loss = 0.13060847768674091
Trained batch 49 in epoch 1, gen_loss = 1.0121973741054535, disc_loss = 0.13216387145221234
Trained batch 50 in epoch 1, gen_loss = 1.0237641229349024, disc_loss = 0.13412623158564754
Trained batch 51 in epoch 1, gen_loss = 1.020748876608335, disc_loss = 0.13360944641037628
Trained batch 52 in epoch 1, gen_loss = 1.0126206469985675, disc_loss = 0.13426493073128304
Trained batch 53 in epoch 1, gen_loss = 1.0140606297387018, disc_loss = 0.13419474406098877
Trained batch 54 in epoch 1, gen_loss = 1.0182674191214822, disc_loss = 0.13365320109508255
Trained batch 55 in epoch 1, gen_loss = 1.0110370250684875, disc_loss = 0.13449997009177292
Trained batch 56 in epoch 1, gen_loss = 1.0138106628468162, disc_loss = 0.13404647463507818
Trained batch 57 in epoch 1, gen_loss = 1.0198418611082538, disc_loss = 0.13272130836186738
Trained batch 58 in epoch 1, gen_loss = 1.0159715343329867, disc_loss = 0.13200986612651308
Trained batch 59 in epoch 1, gen_loss = 1.0126962194840112, disc_loss = 0.1314359853665034
Trained batch 60 in epoch 1, gen_loss = 1.0177996051116067, disc_loss = 0.1316662125411581
Trained batch 61 in epoch 1, gen_loss = 1.0119245081178603, disc_loss = 0.13153358620982017
Trained batch 62 in epoch 1, gen_loss = 1.0125413650558108, disc_loss = 0.1305513797061784
Trained batch 63 in epoch 1, gen_loss = 1.0146006112918258, disc_loss = 0.12974183273036033
Trained batch 64 in epoch 1, gen_loss = 1.0065314109508807, disc_loss = 0.13140750882717278
Trained batch 65 in epoch 1, gen_loss = 1.01587334726796, disc_loss = 0.1327124002079169
Trained batch 66 in epoch 1, gen_loss = 1.0166469100695938, disc_loss = 0.13145196860405936
Trained batch 67 in epoch 1, gen_loss = 1.0123273826697294, disc_loss = 0.1311732874635388
Trained batch 68 in epoch 1, gen_loss = 1.0123609313066455, disc_loss = 0.13098498822554297
Trained batch 69 in epoch 1, gen_loss = 1.0076230432306017, disc_loss = 0.13129060513206892
Trained batch 70 in epoch 1, gen_loss = 1.0142094509702333, disc_loss = 0.13205448622015162
Trained batch 71 in epoch 1, gen_loss = 1.0130182347363896, disc_loss = 0.13112464878294203
Trained batch 72 in epoch 1, gen_loss = 1.006804150261291, disc_loss = 0.13209306316016473
Trained batch 73 in epoch 1, gen_loss = 1.0106661311677985, disc_loss = 0.13268775593590093
Trained batch 74 in epoch 1, gen_loss = 1.0088893675804138, disc_loss = 0.1321124400695165
Trained batch 75 in epoch 1, gen_loss = 1.0070961494194834, disc_loss = 0.13144026059461267
Trained batch 76 in epoch 1, gen_loss = 1.0035315604953023, disc_loss = 0.13132587239726798
Trained batch 77 in epoch 1, gen_loss = 1.0105030162212176, disc_loss = 0.1323356293141842
Trained batch 78 in epoch 1, gen_loss = 1.0057516497901724, disc_loss = 0.132606612824941
Trained batch 79 in epoch 1, gen_loss = 1.0047195985913278, disc_loss = 0.13194510145112873
Trained batch 80 in epoch 1, gen_loss = 1.0065174838643016, disc_loss = 0.13254446297148129
Trained batch 81 in epoch 1, gen_loss = 1.0018098339801882, disc_loss = 0.13331251800423716
Trained batch 82 in epoch 1, gen_loss = 1.0032706275043717, disc_loss = 0.1330825841750007
Trained batch 83 in epoch 1, gen_loss = 1.003390296584084, disc_loss = 0.13276810837643488
Trained batch 84 in epoch 1, gen_loss = 1.002928578853607, disc_loss = 0.13249056900248807
Trained batch 85 in epoch 1, gen_loss = 1.0030507909697155, disc_loss = 0.13186948122673256
Trained batch 86 in epoch 1, gen_loss = 1.001395091243174, disc_loss = 0.13160732765307373
Trained batch 87 in epoch 1, gen_loss = 1.0001783194867047, disc_loss = 0.13148468419570813
Trained batch 88 in epoch 1, gen_loss = 1.0001049456971416, disc_loss = 0.13111443122786082
Trained batch 89 in epoch 1, gen_loss = 1.0018089784516229, disc_loss = 0.13019587587979103
Trained batch 90 in epoch 1, gen_loss = 1.0077125410457233, disc_loss = 0.12910894472356682
Trained batch 91 in epoch 1, gen_loss = 1.0093775067640387, disc_loss = 0.12819338561562094
Trained batch 92 in epoch 1, gen_loss = 1.0058882941481888, disc_loss = 0.1283627136820747
Trained batch 93 in epoch 1, gen_loss = 1.0163605035619532, disc_loss = 0.13120330747296202
Trained batch 94 in epoch 1, gen_loss = 1.013013988419583, disc_loss = 0.13134683578422196
Trained batch 95 in epoch 1, gen_loss = 1.0098566263914108, disc_loss = 0.13177643176944306
Trained batch 96 in epoch 1, gen_loss = 1.009980511419552, disc_loss = 0.13279049225228348
Trained batch 97 in epoch 1, gen_loss = 1.0059093528864336, disc_loss = 0.13326589326013108
Trained batch 98 in epoch 1, gen_loss = 1.0033478002355556, disc_loss = 0.13341050726747272
Trained batch 99 in epoch 1, gen_loss = 1.0032432091236114, disc_loss = 0.13340909231454134
Trained batch 100 in epoch 1, gen_loss = 1.0050993992550539, disc_loss = 0.1328373446986817
Trained batch 101 in epoch 1, gen_loss = 1.0004588616829293, disc_loss = 0.13366949897916877
Trained batch 102 in epoch 1, gen_loss = 1.0033524713469941, disc_loss = 0.1337132723369066
Trained batch 103 in epoch 1, gen_loss = 1.002630828664853, disc_loss = 0.13341342668550518
Trained batch 104 in epoch 1, gen_loss = 1.000833679380871, disc_loss = 0.13301826385515078
Trained batch 105 in epoch 1, gen_loss = 1.0006882863224678, disc_loss = 0.1327547150892469
Trained batch 106 in epoch 1, gen_loss = 1.0037119990197299, disc_loss = 0.13187664910872407
Trained batch 107 in epoch 1, gen_loss = 1.0006630332381636, disc_loss = 0.13197960273397188
Trained batch 108 in epoch 1, gen_loss = 0.9992543136307953, disc_loss = 0.1318515815661041
Trained batch 109 in epoch 1, gen_loss = 1.0020848182114688, disc_loss = 0.13239168284291572
Trained batch 110 in epoch 1, gen_loss = 0.997787501360919, disc_loss = 0.13324362056346628
Trained batch 111 in epoch 1, gen_loss = 0.9971522284405572, disc_loss = 0.13323504574197745
Trained batch 112 in epoch 1, gen_loss = 0.9962429847337503, disc_loss = 0.1331674708795231
Trained batch 113 in epoch 1, gen_loss = 0.9951904755935335, disc_loss = 0.13303449178081855
Trained batch 114 in epoch 1, gen_loss = 0.9939693808555603, disc_loss = 0.13296792354920636
Trained batch 115 in epoch 1, gen_loss = 0.9920417460901984, disc_loss = 0.13279207542153268
Trained batch 116 in epoch 1, gen_loss = 0.9936977349794828, disc_loss = 0.13244420153080907
Trained batch 117 in epoch 1, gen_loss = 0.9943053156642591, disc_loss = 0.1316668087521852
Trained batch 118 in epoch 1, gen_loss = 0.9914158672845664, disc_loss = 0.13161367196746232
Trained batch 119 in epoch 1, gen_loss = 0.9982992629210155, disc_loss = 0.13309017661958933
Trained batch 120 in epoch 1, gen_loss = 0.9973709095608104, disc_loss = 0.13264342803846707
Trained batch 121 in epoch 1, gen_loss = 0.9935676851233498, disc_loss = 0.133507566312786
Trained batch 122 in epoch 1, gen_loss = 0.9958601458285882, disc_loss = 0.1344452775954231
Trained batch 123 in epoch 1, gen_loss = 0.9925392380645198, disc_loss = 0.1348462141449413
Trained batch 124 in epoch 1, gen_loss = 0.9901281781196595, disc_loss = 0.13508567160367965
Trained batch 125 in epoch 1, gen_loss = 0.9894103587619842, disc_loss = 0.1353695692405814
Trained batch 126 in epoch 1, gen_loss = 0.9875100644554679, disc_loss = 0.13554376569085233
Trained batch 127 in epoch 1, gen_loss = 0.9857459412887692, disc_loss = 0.1357151466072537
Trained batch 128 in epoch 1, gen_loss = 0.9859111068784728, disc_loss = 0.13564287282006685
Trained batch 129 in epoch 1, gen_loss = 0.9846919875878554, disc_loss = 0.13560046994915376
Trained batch 130 in epoch 1, gen_loss = 0.9840064066966981, disc_loss = 0.13531319979037948
Trained batch 131 in epoch 1, gen_loss = 0.9819306424169829, disc_loss = 0.13531901348720898
Trained batch 132 in epoch 1, gen_loss = 0.9857074676599717, disc_loss = 0.13615025815210843
Trained batch 133 in epoch 1, gen_loss = 0.9822190604103145, disc_loss = 0.13674280647911244
Trained batch 134 in epoch 1, gen_loss = 0.9833413481712341, disc_loss = 0.136176167483683
Trained batch 135 in epoch 1, gen_loss = 0.9851907390881988, disc_loss = 0.13586292706210823
Trained batch 136 in epoch 1, gen_loss = 0.9842678164913706, disc_loss = 0.1355036182777725
Trained batch 137 in epoch 1, gen_loss = 0.9844170726727748, disc_loss = 0.13486851533146008
Trained batch 138 in epoch 1, gen_loss = 0.9847259217028995, disc_loss = 0.13445105995956086
Trained batch 139 in epoch 1, gen_loss = 0.9841109842061997, disc_loss = 0.13420376115079438
Trained batch 140 in epoch 1, gen_loss = 0.9834027937118043, disc_loss = 0.13381216376491473
Trained batch 141 in epoch 1, gen_loss = 0.984745120078745, disc_loss = 0.1331064725216006
Trained batch 142 in epoch 1, gen_loss = 0.9839455718760723, disc_loss = 0.13270058217165354
Trained batch 143 in epoch 1, gen_loss = 0.984197842164172, disc_loss = 0.13256847040934694
Trained batch 144 in epoch 1, gen_loss = 0.9863555838321817, disc_loss = 0.1318896870160925
Trained batch 145 in epoch 1, gen_loss = 0.9859816019665705, disc_loss = 0.13139956679246198
Trained batch 146 in epoch 1, gen_loss = 0.9900051918970484, disc_loss = 0.13105268467243025
Trained batch 147 in epoch 1, gen_loss = 0.9888183957821614, disc_loss = 0.13072991723547112
Trained batch 148 in epoch 1, gen_loss = 0.9895033876367864, disc_loss = 0.1302105350882415
Trained batch 149 in epoch 1, gen_loss = 0.9899628456433615, disc_loss = 0.1298004360496998
Trained batch 150 in epoch 1, gen_loss = 0.9938142694384846, disc_loss = 0.12909922714264976
Trained batch 151 in epoch 1, gen_loss = 0.9921984049050432, disc_loss = 0.12900456433233462
Trained batch 152 in epoch 1, gen_loss = 0.9953082016870087, disc_loss = 0.1292852086374183
Trained batch 153 in epoch 1, gen_loss = 0.9914139029267547, disc_loss = 0.13105188726217715
Trained batch 154 in epoch 1, gen_loss = 0.992821688805857, disc_loss = 0.1310227834409283
Trained batch 155 in epoch 1, gen_loss = 0.9923426329325407, disc_loss = 0.13095786475027218
Trained batch 156 in epoch 1, gen_loss = 0.9923073915159626, disc_loss = 0.13122639643728354
Trained batch 157 in epoch 1, gen_loss = 0.9938232102726079, disc_loss = 0.1312015725747694
Trained batch 158 in epoch 1, gen_loss = 0.9915574672836928, disc_loss = 0.13146168176295622
Trained batch 159 in epoch 1, gen_loss = 0.9919805604964494, disc_loss = 0.13158812620677054
Trained batch 160 in epoch 1, gen_loss = 0.9910854197436978, disc_loss = 0.1315887160830616
Trained batch 161 in epoch 1, gen_loss = 0.9889356254795452, disc_loss = 0.13169522882427698
Trained batch 162 in epoch 1, gen_loss = 0.9912037297260542, disc_loss = 0.13201516660993085
Trained batch 163 in epoch 1, gen_loss = 0.9897464953544663, disc_loss = 0.13191665413721307
Trained batch 164 in epoch 1, gen_loss = 0.9910784313173006, disc_loss = 0.13155365721745924
Trained batch 165 in epoch 1, gen_loss = 0.9896381134728351, disc_loss = 0.13149189289255314
Trained batch 166 in epoch 1, gen_loss = 0.9894633582252228, disc_loss = 0.1311879778158165
Trained batch 167 in epoch 1, gen_loss = 0.9886563881522134, disc_loss = 0.13109824070263476
Trained batch 168 in epoch 1, gen_loss = 0.9899753543752186, disc_loss = 0.13062800387659015
Trained batch 169 in epoch 1, gen_loss = 0.9904411112560946, disc_loss = 0.13009933066718718
Trained batch 170 in epoch 1, gen_loss = 0.9900189732250414, disc_loss = 0.1296981315602336
Trained batch 171 in epoch 1, gen_loss = 0.9959402503662331, disc_loss = 0.13023615615485712
Trained batch 172 in epoch 1, gen_loss = 0.992578377957978, disc_loss = 0.13230056074485613
Trained batch 173 in epoch 1, gen_loss = 0.9935661818104229, disc_loss = 0.13276054808634452
Trained batch 174 in epoch 1, gen_loss = 0.9917048072814941, disc_loss = 0.13315035679510662
Trained batch 175 in epoch 1, gen_loss = 0.9899173771793192, disc_loss = 0.1339087496003644
Trained batch 176 in epoch 1, gen_loss = 0.9893804559599881, disc_loss = 0.1350981946297958
Trained batch 177 in epoch 1, gen_loss = 0.9899470357412703, disc_loss = 0.13586643300531956
Trained batch 178 in epoch 1, gen_loss = 0.9880339220249453, disc_loss = 0.1364780813871815
Trained batch 179 in epoch 1, gen_loss = 0.9866092973285251, disc_loss = 0.13656566031277179
Trained batch 180 in epoch 1, gen_loss = 0.9862520819869489, disc_loss = 0.13677764329956382
Trained batch 181 in epoch 1, gen_loss = 0.9852329708717682, disc_loss = 0.13686590326520112
Trained batch 182 in epoch 1, gen_loss = 0.983475153889161, disc_loss = 0.13705064791962096
Trained batch 183 in epoch 1, gen_loss = 0.9824288782218228, disc_loss = 0.13710560435024294
Trained batch 184 in epoch 1, gen_loss = 0.9817669949016056, disc_loss = 0.13711697044404778
Trained batch 185 in epoch 1, gen_loss = 0.9811196516277969, disc_loss = 0.1371153814577928
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 0.6734883785247803, disc_loss = 0.13011017441749573
Trained batch 1 in epoch 2, gen_loss = 0.7616893351078033, disc_loss = 0.13625633716583252
Trained batch 2 in epoch 2, gen_loss = 0.8193496068318685, disc_loss = 0.1312746231754621
Trained batch 3 in epoch 2, gen_loss = 0.8011102974414825, disc_loss = 0.12555449455976486
Trained batch 4 in epoch 2, gen_loss = 0.8487569332122803, disc_loss = 0.1249541774392128
Trained batch 5 in epoch 2, gen_loss = 0.8293629089991251, disc_loss = 0.12205541133880615
Trained batch 6 in epoch 2, gen_loss = 0.8498070410319737, disc_loss = 0.12053432422024864
Trained batch 7 in epoch 2, gen_loss = 0.8701703995466232, disc_loss = 0.12147589959204197
Trained batch 8 in epoch 2, gen_loss = 0.845415472984314, disc_loss = 0.12400839229424794
Trained batch 9 in epoch 2, gen_loss = 0.8767504572868348, disc_loss = 0.12447121739387512
Trained batch 10 in epoch 2, gen_loss = 0.8463955196467313, disc_loss = 0.13165574859489093
Trained batch 11 in epoch 2, gen_loss = 0.8867210398117701, disc_loss = 0.1393743741015593
Trained batch 12 in epoch 2, gen_loss = 0.868874769944411, disc_loss = 0.14101660480866066
Trained batch 13 in epoch 2, gen_loss = 0.8656975158623287, disc_loss = 0.1408418161528451
Trained batch 14 in epoch 2, gen_loss = 0.8962981502215067, disc_loss = 0.14507481853167217
Trained batch 15 in epoch 2, gen_loss = 0.8752227909862995, disc_loss = 0.14776070695370436
Trained batch 16 in epoch 2, gen_loss = 0.8710073337835424, disc_loss = 0.14732187022181117
Trained batch 17 in epoch 2, gen_loss = 0.8847015268272824, disc_loss = 0.15302231990628773
Trained batch 18 in epoch 2, gen_loss = 0.8741950204497889, disc_loss = 0.15425480902194977
Trained batch 19 in epoch 2, gen_loss = 0.8707030564546585, disc_loss = 0.15286707058548926
Trained batch 20 in epoch 2, gen_loss = 0.8789947061311632, disc_loss = 0.1519691220351628
Trained batch 21 in epoch 2, gen_loss = 0.8720942302183672, disc_loss = 0.1509464220567183
Trained batch 22 in epoch 2, gen_loss = 0.8695321031238722, disc_loss = 0.1497056218593017
Trained batch 23 in epoch 2, gen_loss = 0.8651009202003479, disc_loss = 0.14872104364136854
Trained batch 24 in epoch 2, gen_loss = 0.8732576942443848, disc_loss = 0.14717831134796142
Trained batch 25 in epoch 2, gen_loss = 0.8712118313862727, disc_loss = 0.1449292883850061
Trained batch 26 in epoch 2, gen_loss = 0.8737483245355112, disc_loss = 0.14372517499658796
Trained batch 27 in epoch 2, gen_loss = 0.8729262011391776, disc_loss = 0.1417962456388133
Trained batch 28 in epoch 2, gen_loss = 0.8791891213121086, disc_loss = 0.13900502976672402
Trained batch 29 in epoch 2, gen_loss = 0.8798276603221893, disc_loss = 0.13669781039158505
Trained batch 30 in epoch 2, gen_loss = 0.8858980075005563, disc_loss = 0.13433195602509282
Trained batch 31 in epoch 2, gen_loss = 0.8930969964712858, disc_loss = 0.13156442297622561
Trained batch 32 in epoch 2, gen_loss = 0.8979310754573706, disc_loss = 0.12862900825160922
Trained batch 33 in epoch 2, gen_loss = 0.9000667596564573, disc_loss = 0.12656531154232867
Trained batch 34 in epoch 2, gen_loss = 0.9127785733767918, disc_loss = 0.1269210540822574
Trained batch 35 in epoch 2, gen_loss = 0.9006759275992712, disc_loss = 0.1302658665097422
Trained batch 36 in epoch 2, gen_loss = 0.9116321592717558, disc_loss = 0.13113857020397443
Trained batch 37 in epoch 2, gen_loss = 0.9102543153260884, disc_loss = 0.1299280990895472
Trained batch 38 in epoch 2, gen_loss = 0.914674407396561, disc_loss = 0.12890033118235758
Trained batch 39 in epoch 2, gen_loss = 0.9118287220597268, disc_loss = 0.1281620167195797
Trained batch 40 in epoch 2, gen_loss = 0.9146996198630915, disc_loss = 0.126667238226751
Trained batch 41 in epoch 2, gen_loss = 0.9205016990502676, disc_loss = 0.12506730756944134
Trained batch 42 in epoch 2, gen_loss = 0.9269657869671666, disc_loss = 0.12302220517466235
Trained batch 43 in epoch 2, gen_loss = 0.9261124689470638, disc_loss = 0.12157978557727554
Trained batch 44 in epoch 2, gen_loss = 0.9282178627120123, disc_loss = 0.11989007410075929
Trained batch 45 in epoch 2, gen_loss = 0.9481471919495127, disc_loss = 0.12075668330425801
Trained batch 46 in epoch 2, gen_loss = 0.941482682177361, disc_loss = 0.12174040031559924
Trained batch 47 in epoch 2, gen_loss = 0.9600690566003323, disc_loss = 0.12090779608115554
Trained batch 48 in epoch 2, gen_loss = 0.954684245343111, disc_loss = 0.12133192392636319
Trained batch 49 in epoch 2, gen_loss = 0.9575137257575989, disc_loss = 0.12043067082762718
Trained batch 50 in epoch 2, gen_loss = 0.9807215601790185, disc_loss = 0.12061913063128789
Trained batch 51 in epoch 2, gen_loss = 0.9836019094173725, disc_loss = 0.11919745974815808
Trained batch 52 in epoch 2, gen_loss = 0.979946993431955, disc_loss = 0.1190535437385991
Trained batch 53 in epoch 2, gen_loss = 0.9839648229104502, disc_loss = 0.11753550509887713
Trained batch 54 in epoch 2, gen_loss = 0.9953272169286554, disc_loss = 0.11668768369338729
Trained batch 55 in epoch 2, gen_loss = 0.993374473282269, disc_loss = 0.1157516107362296
Trained batch 56 in epoch 2, gen_loss = 1.0005811536521243, disc_loss = 0.11454126108110997
Trained batch 57 in epoch 2, gen_loss = 1.003914397338341, disc_loss = 0.11289319890583384
Trained batch 58 in epoch 2, gen_loss = 1.0011156999458701, disc_loss = 0.11200595792319815
Trained batch 59 in epoch 2, gen_loss = 1.0015240132808685, disc_loss = 0.11136250055084626
Trained batch 60 in epoch 2, gen_loss = 1.0055258098195812, disc_loss = 0.11056919878379243
Trained batch 61 in epoch 2, gen_loss = 1.0022799382286687, disc_loss = 0.11020048245066597
Trained batch 62 in epoch 2, gen_loss = 1.0045870419532534, disc_loss = 0.1092286617864692
Trained batch 63 in epoch 2, gen_loss = 1.0053710686042905, disc_loss = 0.10843636112986133
Trained batch 64 in epoch 2, gen_loss = 1.0011556121019216, disc_loss = 0.10805048741973364
Trained batch 65 in epoch 2, gen_loss = 1.0048455623063175, disc_loss = 0.10768799263645303
Trained batch 66 in epoch 2, gen_loss = 1.0006238061990311, disc_loss = 0.10758621162220613
Trained batch 67 in epoch 2, gen_loss = 1.0033015433479757, disc_loss = 0.10740108399049324
Trained batch 68 in epoch 2, gen_loss = 1.001276617464812, disc_loss = 0.1072564545640911
Trained batch 69 in epoch 2, gen_loss = 1.004599802834647, disc_loss = 0.10674936702208859
Trained batch 70 in epoch 2, gen_loss = 1.0028026196318613, disc_loss = 0.10606743395328522
Trained batch 71 in epoch 2, gen_loss = 1.0038171749975946, disc_loss = 0.10541773111455971
Trained batch 72 in epoch 2, gen_loss = 1.002660924441194, disc_loss = 0.1048283996443226
Trained batch 73 in epoch 2, gen_loss = 1.0049450478038273, disc_loss = 0.10451575831787006
Trained batch 74 in epoch 2, gen_loss = 1.0009998869895935, disc_loss = 0.10425348371267319
Trained batch 75 in epoch 2, gen_loss = 1.0047945074344937, disc_loss = 0.10487259973428752
Trained batch 76 in epoch 2, gen_loss = 0.9998998456187063, disc_loss = 0.10557123389724013
Trained batch 77 in epoch 2, gen_loss = 1.0096516395226502, disc_loss = 0.1099020925660928
Trained batch 78 in epoch 2, gen_loss = 1.0022939013529428, disc_loss = 0.11364586585307423
Trained batch 79 in epoch 2, gen_loss = 1.0016976460814475, disc_loss = 0.11337435990571976
Trained batch 80 in epoch 2, gen_loss = 1.0010146682645067, disc_loss = 0.11418745436786133
Trained batch 81 in epoch 2, gen_loss = 0.9979421365551833, disc_loss = 0.11578523658397721
Trained batch 82 in epoch 2, gen_loss = 0.9955276739166443, disc_loss = 0.11618367465863745
Trained batch 83 in epoch 2, gen_loss = 0.9916384220123291, disc_loss = 0.11677956510157812
Trained batch 84 in epoch 2, gen_loss = 0.9912876620012171, disc_loss = 0.11710385697729447
Trained batch 85 in epoch 2, gen_loss = 0.991103376066962, disc_loss = 0.11763015285480855
Trained batch 86 in epoch 2, gen_loss = 0.9884026502740795, disc_loss = 0.11731540043463652
Trained batch 87 in epoch 2, gen_loss = 0.986124340783466, disc_loss = 0.11696566810662096
Trained batch 88 in epoch 2, gen_loss = 0.9878784900300959, disc_loss = 0.11682072298580341
Trained batch 89 in epoch 2, gen_loss = 0.9856740302509732, disc_loss = 0.11642484101984236
Trained batch 90 in epoch 2, gen_loss = 0.9859352596513518, disc_loss = 0.11618554215509813
Trained batch 91 in epoch 2, gen_loss = 0.9834552413743475, disc_loss = 0.11594947508495787
Trained batch 92 in epoch 2, gen_loss = 0.9823932993796564, disc_loss = 0.11577029301915118
Trained batch 93 in epoch 2, gen_loss = 0.982258472036808, disc_loss = 0.11536558907716832
Trained batch 94 in epoch 2, gen_loss = 0.980433746388084, disc_loss = 0.11504780916791213
Trained batch 95 in epoch 2, gen_loss = 0.9822776801884174, disc_loss = 0.11513428033019106
Trained batch 96 in epoch 2, gen_loss = 0.978807641058853, disc_loss = 0.11534534394741058
Trained batch 97 in epoch 2, gen_loss = 0.9817135261029614, disc_loss = 0.1151051580601809
Trained batch 98 in epoch 2, gen_loss = 0.981329655406451, disc_loss = 0.11455906728150869
Trained batch 99 in epoch 2, gen_loss = 0.9815753650665283, disc_loss = 0.11404812585562468
Trained batch 100 in epoch 2, gen_loss = 0.9812103498100054, disc_loss = 0.11361503287559689
Trained batch 101 in epoch 2, gen_loss = 0.9831827154346541, disc_loss = 0.11306430220457853
Trained batch 102 in epoch 2, gen_loss = 0.9820301683203688, disc_loss = 0.11255326328202359
Trained batch 103 in epoch 2, gen_loss = 0.9818136520110644, disc_loss = 0.11238981808464114
Trained batch 104 in epoch 2, gen_loss = 0.9844975573675973, disc_loss = 0.11173939864550318
Trained batch 105 in epoch 2, gen_loss = 0.9850971305145407, disc_loss = 0.11093767781583767
Trained batch 106 in epoch 2, gen_loss = 0.9836390040745245, disc_loss = 0.11058413021475355
Trained batch 107 in epoch 2, gen_loss = 0.9906362262037065, disc_loss = 0.11131821145062093
Trained batch 108 in epoch 2, gen_loss = 0.9870794481093731, disc_loss = 0.11202765399709753
Trained batch 109 in epoch 2, gen_loss = 0.9883528844876723, disc_loss = 0.11140747144818305
Trained batch 110 in epoch 2, gen_loss = 0.991467051140897, disc_loss = 0.11141076798106099
Trained batch 111 in epoch 2, gen_loss = 0.9895969251436847, disc_loss = 0.11145225200535995
Trained batch 112 in epoch 2, gen_loss = 0.989345235634694, disc_loss = 0.110942649300647
Trained batch 113 in epoch 2, gen_loss = 0.9914614992183551, disc_loss = 0.11106419661327412
Trained batch 114 in epoch 2, gen_loss = 0.9900304073872773, disc_loss = 0.11087260855280835
Trained batch 115 in epoch 2, gen_loss = 0.9893670888810322, disc_loss = 0.11064531557775777
Trained batch 116 in epoch 2, gen_loss = 0.990736091748262, disc_loss = 0.11041676877146094
Trained batch 117 in epoch 2, gen_loss = 0.9892360982248338, disc_loss = 0.11023586893738327
Trained batch 118 in epoch 2, gen_loss = 0.9916680219794521, disc_loss = 0.11021595917829946
Trained batch 119 in epoch 2, gen_loss = 0.9908135240276654, disc_loss = 0.10975240043674907
Trained batch 120 in epoch 2, gen_loss = 0.9919410012970286, disc_loss = 0.10902706258122094
Trained batch 121 in epoch 2, gen_loss = 0.9924396046849547, disc_loss = 0.10860928940418803
Trained batch 122 in epoch 2, gen_loss = 0.9929755814676362, disc_loss = 0.10810987383308934
Trained batch 123 in epoch 2, gen_loss = 0.9919257937900482, disc_loss = 0.10774141085904933
Trained batch 124 in epoch 2, gen_loss = 0.995067976474762, disc_loss = 0.10768143056333065
Trained batch 125 in epoch 2, gen_loss = 0.9935223706184871, disc_loss = 0.10759082979093941
Trained batch 126 in epoch 2, gen_loss = 0.992847634112741, disc_loss = 0.10705476780752028
Trained batch 127 in epoch 2, gen_loss = 0.9985031727701426, disc_loss = 0.10818283881235402
Trained batch 128 in epoch 2, gen_loss = 0.9961836458176605, disc_loss = 0.10812282988209596
Trained batch 129 in epoch 2, gen_loss = 0.993999849832975, disc_loss = 0.10847289549330107
Trained batch 130 in epoch 2, gen_loss = 0.9930937312941515, disc_loss = 0.10944726845633437
Trained batch 131 in epoch 2, gen_loss = 0.9906984662467783, disc_loss = 0.10959007442844185
Trained batch 132 in epoch 2, gen_loss = 0.9928393744884577, disc_loss = 0.10989583534349624
Trained batch 133 in epoch 2, gen_loss = 0.9889054974513267, disc_loss = 0.11083133339381485
Trained batch 134 in epoch 2, gen_loss = 0.9885198451854564, disc_loss = 0.11098098863882047
Trained batch 135 in epoch 2, gen_loss = 0.987883955678519, disc_loss = 0.11098510480266721
Trained batch 136 in epoch 2, gen_loss = 0.9867035955408193, disc_loss = 0.11130362557396836
Trained batch 137 in epoch 2, gen_loss = 0.9865535622921543, disc_loss = 0.11132887209617141
Trained batch 138 in epoch 2, gen_loss = 0.9858745327956385, disc_loss = 0.11160468657186134
Trained batch 139 in epoch 2, gen_loss = 0.9845017799309321, disc_loss = 0.11150895483525736
Trained batch 140 in epoch 2, gen_loss = 0.9864261395542334, disc_loss = 0.11139085739586793
Trained batch 141 in epoch 2, gen_loss = 0.9851214591885956, disc_loss = 0.11120466786948308
Trained batch 142 in epoch 2, gen_loss = 0.9843168617128493, disc_loss = 0.11108270723867666
Trained batch 143 in epoch 2, gen_loss = 0.9863860069049729, disc_loss = 0.11088498825362574
Trained batch 144 in epoch 2, gen_loss = 0.9845378809961779, disc_loss = 0.11081689841531474
Trained batch 145 in epoch 2, gen_loss = 0.9854880571365356, disc_loss = 0.11049735498908039
Trained batch 146 in epoch 2, gen_loss = 0.9863011658597155, disc_loss = 0.1104130857833186
Trained batch 147 in epoch 2, gen_loss = 0.9850107914692646, disc_loss = 0.11037649872486253
Trained batch 148 in epoch 2, gen_loss = 0.985225315862054, disc_loss = 0.1101288434818087
Trained batch 149 in epoch 2, gen_loss = 0.9863076607386271, disc_loss = 0.10997842598706484
Trained batch 150 in epoch 2, gen_loss = 0.9873940218363376, disc_loss = 0.10972311464909291
Trained batch 151 in epoch 2, gen_loss = 0.9859748439569223, disc_loss = 0.10953455770045127
Trained batch 152 in epoch 2, gen_loss = 0.9873087160727557, disc_loss = 0.1093188753972451
Trained batch 153 in epoch 2, gen_loss = 0.987000723550846, disc_loss = 0.10906782483851368
Trained batch 154 in epoch 2, gen_loss = 0.9891064101649869, disc_loss = 0.1087587263194784
Trained batch 155 in epoch 2, gen_loss = 0.9886364272007575, disc_loss = 0.10850205605563062
Trained batch 156 in epoch 2, gen_loss = 0.9891560472500552, disc_loss = 0.10835952324804607
Trained batch 157 in epoch 2, gen_loss = 0.9886418882804581, disc_loss = 0.10837454828610525
Trained batch 158 in epoch 2, gen_loss = 0.9900130190939274, disc_loss = 0.10859340250070365
Trained batch 159 in epoch 2, gen_loss = 0.9886597961187362, disc_loss = 0.10870601636124774
Trained batch 160 in epoch 2, gen_loss = 0.9908573708919265, disc_loss = 0.10893955510919509
Trained batch 161 in epoch 2, gen_loss = 0.9893777775175777, disc_loss = 0.10887490616490443
Trained batch 162 in epoch 2, gen_loss = 0.990161443049191, disc_loss = 0.10852217759959902
Trained batch 163 in epoch 2, gen_loss = 0.9920447141658969, disc_loss = 0.10836831610876976
Trained batch 164 in epoch 2, gen_loss = 0.9901814153700164, disc_loss = 0.108356114578518
Trained batch 165 in epoch 2, gen_loss = 0.9902473986148834, disc_loss = 0.10820443146155183
Trained batch 166 in epoch 2, gen_loss = 0.9917263552814186, disc_loss = 0.1077563830366927
Trained batch 167 in epoch 2, gen_loss = 0.9916525940809932, disc_loss = 0.10744798874172072
Trained batch 168 in epoch 2, gen_loss = 0.9917349445043936, disc_loss = 0.10704400592081292
Trained batch 169 in epoch 2, gen_loss = 0.9921777364085702, disc_loss = 0.10673276013968622
Trained batch 170 in epoch 2, gen_loss = 0.9932043834736473, disc_loss = 0.1063998923555278
Trained batch 171 in epoch 2, gen_loss = 0.9920285039169844, disc_loss = 0.10628790697516051
Trained batch 172 in epoch 2, gen_loss = 0.993831081886512, disc_loss = 0.10605445765820197
Trained batch 173 in epoch 2, gen_loss = 0.9936515699172842, disc_loss = 0.10569676310466282
Trained batch 174 in epoch 2, gen_loss = 0.9956111516271319, disc_loss = 0.10542507472847189
Trained batch 175 in epoch 2, gen_loss = 0.9946764633059502, disc_loss = 0.10536921975753186
Trained batch 176 in epoch 2, gen_loss = 0.9963688951427654, disc_loss = 0.1053587811457067
Trained batch 177 in epoch 2, gen_loss = 0.9954372798458914, disc_loss = 0.10544243675729867
Trained batch 178 in epoch 2, gen_loss = 0.9982586000218737, disc_loss = 0.10541395404943207
Trained batch 179 in epoch 2, gen_loss = 1.0007300125228034, disc_loss = 0.1049821794240011
Trained batch 180 in epoch 2, gen_loss = 1.0021683774600372, disc_loss = 0.10456069159573612
Trained batch 181 in epoch 2, gen_loss = 1.0017818032385228, disc_loss = 0.1042404876673942
Trained batch 182 in epoch 2, gen_loss = 1.0052515024044475, disc_loss = 0.10382312501633102
Trained batch 183 in epoch 2, gen_loss = 1.0073405371411988, disc_loss = 0.10339012695476413
Trained batch 184 in epoch 2, gen_loss = 1.0068502081407082, disc_loss = 0.10309407882191039
Trained batch 185 in epoch 2, gen_loss = 1.0083153436901748, disc_loss = 0.10268674897009968
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 0.9062821269035339, disc_loss = 0.046588025987148285
Trained batch 1 in epoch 3, gen_loss = 1.2046535909175873, disc_loss = 0.07144827023148537
Trained batch 2 in epoch 3, gen_loss = 1.0163090825080872, disc_loss = 0.09119473149379094
Trained batch 3 in epoch 3, gen_loss = 1.1168406158685684, disc_loss = 0.09542855061590672
Trained batch 4 in epoch 3, gen_loss = 1.070536243915558, disc_loss = 0.09335424304008484
Trained batch 5 in epoch 3, gen_loss = 1.0161777635415394, disc_loss = 0.0919927308956782
Trained batch 6 in epoch 3, gen_loss = 1.1036082761628287, disc_loss = 0.09619408633027758
Trained batch 7 in epoch 3, gen_loss = 1.0880300104618073, disc_loss = 0.09030031273141503
Trained batch 8 in epoch 3, gen_loss = 1.107542461819119, disc_loss = 0.08418590782417192
Trained batch 9 in epoch 3, gen_loss = 1.1484885334968566, disc_loss = 0.07887352108955384
Trained batch 10 in epoch 3, gen_loss = 1.1052800850434736, disc_loss = 0.08314922858368266
Trained batch 11 in epoch 3, gen_loss = 1.1493377288182576, disc_loss = 0.0831635141124328
Trained batch 12 in epoch 3, gen_loss = 1.201064210671645, disc_loss = 0.0799467171040865
Trained batch 13 in epoch 3, gen_loss = 1.1649941546576363, disc_loss = 0.08400244984243598
Trained batch 14 in epoch 3, gen_loss = 1.182659657796224, disc_loss = 0.07931004154185455
Trained batch 15 in epoch 3, gen_loss = 1.2146459370851517, disc_loss = 0.07936002488713712
Trained batch 16 in epoch 3, gen_loss = 1.1975352764129639, disc_loss = 0.07804203657981228
Trained batch 17 in epoch 3, gen_loss = 1.1820131871435378, disc_loss = 0.07634550612419844
Trained batch 18 in epoch 3, gen_loss = 1.18414432751505, disc_loss = 0.07342580568633582
Trained batch 19 in epoch 3, gen_loss = 1.1976787745952606, disc_loss = 0.07145072594285011
Trained batch 20 in epoch 3, gen_loss = 1.201370358467102, disc_loss = 0.0685888458752916
Trained batch 21 in epoch 3, gen_loss = 1.1903365687890486, disc_loss = 0.0670445558869026
Trained batch 22 in epoch 3, gen_loss = 1.1844397109487783, disc_loss = 0.06516561276562836
Trained batch 23 in epoch 3, gen_loss = 1.1939793576796849, disc_loss = 0.06526461592875421
Trained batch 24 in epoch 3, gen_loss = 1.18888249874115, disc_loss = 0.06372047938406468
Trained batch 25 in epoch 3, gen_loss = 1.1743985666678503, disc_loss = 0.06373371563565272
Trained batch 26 in epoch 3, gen_loss = 1.1841175534107067, disc_loss = 0.06303324571086301
Trained batch 27 in epoch 3, gen_loss = 1.1864258583102907, disc_loss = 0.061949781607836485
Trained batch 28 in epoch 3, gen_loss = 1.1889690633477836, disc_loss = 0.060257813347310854
Trained batch 29 in epoch 3, gen_loss = 1.1896043082078298, disc_loss = 0.05881064708034198
Trained batch 30 in epoch 3, gen_loss = 1.1913916045619595, disc_loss = 0.05759730226089878
Trained batch 31 in epoch 3, gen_loss = 1.197415268048644, disc_loss = 0.05805692507419735
Trained batch 32 in epoch 3, gen_loss = 1.1805207350037314, disc_loss = 0.0606143173169006
Trained batch 33 in epoch 3, gen_loss = 1.1795373857021332, disc_loss = 0.059470471104278284
Trained batch 34 in epoch 3, gen_loss = 1.1873098833220346, disc_loss = 0.06392466415252004
Trained batch 35 in epoch 3, gen_loss = 1.1670021249188318, disc_loss = 0.06845201500174072
Trained batch 36 in epoch 3, gen_loss = 1.156374043709523, disc_loss = 0.07031509109042786
Trained batch 37 in epoch 3, gen_loss = 1.1563467995116585, disc_loss = 0.07167964242398739
Trained batch 38 in epoch 3, gen_loss = 1.154552473471715, disc_loss = 0.07258807208675605
Trained batch 39 in epoch 3, gen_loss = 1.1457662090659142, disc_loss = 0.07479694904759526
Trained batch 40 in epoch 3, gen_loss = 1.1410058329745036, disc_loss = 0.0761478111693045
Trained batch 41 in epoch 3, gen_loss = 1.1397348784265064, disc_loss = 0.0773216589753117
Trained batch 42 in epoch 3, gen_loss = 1.1366802315379299, disc_loss = 0.07683324146755906
Trained batch 43 in epoch 3, gen_loss = 1.1321819533001294, disc_loss = 0.07671682595868003
Trained batch 44 in epoch 3, gen_loss = 1.1318133566114637, disc_loss = 0.07570749148726463
Trained batch 45 in epoch 3, gen_loss = 1.1329570283060488, disc_loss = 0.07489639512546685
Trained batch 46 in epoch 3, gen_loss = 1.1311620042679158, disc_loss = 0.07395928606708
Trained batch 47 in epoch 3, gen_loss = 1.1282521237929661, disc_loss = 0.07346362263585131
Trained batch 48 in epoch 3, gen_loss = 1.130640587028192, disc_loss = 0.0728409866593322
Trained batch 49 in epoch 3, gen_loss = 1.1261586880683898, disc_loss = 0.0723231815546751
Trained batch 50 in epoch 3, gen_loss = 1.125996851453594, disc_loss = 0.07161752434045661
Trained batch 51 in epoch 3, gen_loss = 1.1226900953512926, disc_loss = 0.07092141574965073
Trained batch 52 in epoch 3, gen_loss = 1.1285687774982092, disc_loss = 0.07195854819608184
Trained batch 53 in epoch 3, gen_loss = 1.121934950351715, disc_loss = 0.07205617910733929
Trained batch 54 in epoch 3, gen_loss = 1.1185453566637906, disc_loss = 0.0720123681155118
Trained batch 55 in epoch 3, gen_loss = 1.119678767664092, disc_loss = 0.07168598978647164
Trained batch 56 in epoch 3, gen_loss = 1.113087747180671, disc_loss = 0.07217001261418327
Trained batch 57 in epoch 3, gen_loss = 1.115892053678118, disc_loss = 0.07266461874904304
Trained batch 58 in epoch 3, gen_loss = 1.1124522948669175, disc_loss = 0.07254348670021962
Trained batch 59 in epoch 3, gen_loss = 1.1114374935626983, disc_loss = 0.07195754013955594
Trained batch 60 in epoch 3, gen_loss = 1.1099238845168566, disc_loss = 0.07135904165076427
Trained batch 61 in epoch 3, gen_loss = 1.1108583788717947, disc_loss = 0.07118589599286357
Trained batch 62 in epoch 3, gen_loss = 1.1116298342507982, disc_loss = 0.07063392118092567
Trained batch 63 in epoch 3, gen_loss = 1.1092374064028263, disc_loss = 0.07026341068558395
Trained batch 64 in epoch 3, gen_loss = 1.1099332882807804, disc_loss = 0.06964047121313902
Trained batch 65 in epoch 3, gen_loss = 1.115181778416489, disc_loss = 0.06999321874569762
Trained batch 66 in epoch 3, gen_loss = 1.1116929810438583, disc_loss = 0.0700987529065182
Trained batch 67 in epoch 3, gen_loss = 1.1122912948622423, disc_loss = 0.07007817830890417
Trained batch 68 in epoch 3, gen_loss = 1.108521042526632, disc_loss = 0.07005403757743213
Trained batch 69 in epoch 3, gen_loss = 1.1074718824454717, disc_loss = 0.06981895816113268
Trained batch 70 in epoch 3, gen_loss = 1.1198927810494328, disc_loss = 0.07039547496488396
Trained batch 71 in epoch 3, gen_loss = 1.1169201764795516, disc_loss = 0.07015256330163942
Trained batch 72 in epoch 3, gen_loss = 1.1127403231516277, disc_loss = 0.07009636575024422
Trained batch 73 in epoch 3, gen_loss = 1.1208038483117078, disc_loss = 0.07103423587977886
Trained batch 74 in epoch 3, gen_loss = 1.114034074942271, disc_loss = 0.07217910066246987
Trained batch 75 in epoch 3, gen_loss = 1.1132110804319382, disc_loss = 0.07230463658312433
Trained batch 76 in epoch 3, gen_loss = 1.1203442215919495, disc_loss = 0.0738279778365191
Trained batch 77 in epoch 3, gen_loss = 1.1169229111610315, disc_loss = 0.07397604614305191
Trained batch 78 in epoch 3, gen_loss = 1.1138203649581233, disc_loss = 0.0740247595630869
Trained batch 79 in epoch 3, gen_loss = 1.1128557078540324, disc_loss = 0.07432096670381724
Trained batch 80 in epoch 3, gen_loss = 1.1132442384590338, disc_loss = 0.07462727669396518
Trained batch 81 in epoch 3, gen_loss = 1.112500258335253, disc_loss = 0.07532127015292645
Trained batch 82 in epoch 3, gen_loss = 1.1090687434357334, disc_loss = 0.07552638995539711
Trained batch 83 in epoch 3, gen_loss = 1.109582590914908, disc_loss = 0.07543867582543975
Trained batch 84 in epoch 3, gen_loss = 1.1137023750473471, disc_loss = 0.07499758469707826
Trained batch 85 in epoch 3, gen_loss = 1.1086247909900755, disc_loss = 0.07519028968242712
Trained batch 86 in epoch 3, gen_loss = 1.111599672799823, disc_loss = 0.07528155631032483
Trained batch 87 in epoch 3, gen_loss = 1.1102964573285796, disc_loss = 0.07495109796185385
Trained batch 88 in epoch 3, gen_loss = 1.108488068821725, disc_loss = 0.07472516897689091
Trained batch 89 in epoch 3, gen_loss = 1.1086090637577906, disc_loss = 0.07426029845244354
Trained batch 90 in epoch 3, gen_loss = 1.1109342175525623, disc_loss = 0.07379264384508133
Trained batch 91 in epoch 3, gen_loss = 1.1087477064650992, disc_loss = 0.07342902716735135
Trained batch 92 in epoch 3, gen_loss = 1.1079604023246354, disc_loss = 0.07305171781329699
Trained batch 93 in epoch 3, gen_loss = 1.1093244717476216, disc_loss = 0.07285039396362102
Trained batch 94 in epoch 3, gen_loss = 1.1061320229580527, disc_loss = 0.0728197904009568
Trained batch 95 in epoch 3, gen_loss = 1.1094810292124748, disc_loss = 0.0725121891979749
Trained batch 96 in epoch 3, gen_loss = 1.107215682255853, disc_loss = 0.0723274493033124
Trained batch 97 in epoch 3, gen_loss = 1.1070800107352587, disc_loss = 0.07215517869561303
Trained batch 98 in epoch 3, gen_loss = 1.1084194580713909, disc_loss = 0.07170520497090889
Trained batch 99 in epoch 3, gen_loss = 1.1060130566358566, disc_loss = 0.07157192900776863
Trained batch 100 in epoch 3, gen_loss = 1.109412948093792, disc_loss = 0.07122981965099232
Trained batch 101 in epoch 3, gen_loss = 1.1111667477617078, disc_loss = 0.07068902513414037
Trained batch 102 in epoch 3, gen_loss = 1.1165092251833202, disc_loss = 0.07021137209410228
Trained batch 103 in epoch 3, gen_loss = 1.1145573075001056, disc_loss = 0.06987911246072215
Trained batch 104 in epoch 3, gen_loss = 1.1165545315969558, disc_loss = 0.06938730416198571
Trained batch 105 in epoch 3, gen_loss = 1.1201014529983953, disc_loss = 0.0692945387179278
Trained batch 106 in epoch 3, gen_loss = 1.1187888049633703, disc_loss = 0.06913036381320975
Trained batch 107 in epoch 3, gen_loss = 1.1212213922429968, disc_loss = 0.06899683244733347
Trained batch 108 in epoch 3, gen_loss = 1.1215327803148043, disc_loss = 0.0685574837336573
Trained batch 109 in epoch 3, gen_loss = 1.1248825853521174, disc_loss = 0.06810318179089915
Trained batch 110 in epoch 3, gen_loss = 1.1281458483085975, disc_loss = 0.06788857262749393
Trained batch 111 in epoch 3, gen_loss = 1.130925299865859, disc_loss = 0.06764852606491852
Trained batch 112 in epoch 3, gen_loss = 1.1349700541622871, disc_loss = 0.06750941149626685
Trained batch 113 in epoch 3, gen_loss = 1.1404976416052433, disc_loss = 0.06792864835772075
Trained batch 114 in epoch 3, gen_loss = 1.1513159243956856, disc_loss = 0.0712920655860849
Trained batch 115 in epoch 3, gen_loss = 1.1595053826940471, disc_loss = 0.07403847811229784
Trained batch 116 in epoch 3, gen_loss = 1.1652590729232528, disc_loss = 0.0766027369019058
Trained batch 117 in epoch 3, gen_loss = 1.1706395502817832, disc_loss = 0.0820732175262045
Trained batch 118 in epoch 3, gen_loss = 1.1748385319188863, disc_loss = 0.08387758205605655
Trained batch 119 in epoch 3, gen_loss = 1.1764412860075633, disc_loss = 0.08392953492390613
Trained batch 120 in epoch 3, gen_loss = 1.1747893543282817, disc_loss = 0.08389550138049381
Trained batch 121 in epoch 3, gen_loss = 1.173579826218183, disc_loss = 0.08361527597012579
Trained batch 122 in epoch 3, gen_loss = 1.1716303195410627, disc_loss = 0.08355634670129151
Trained batch 123 in epoch 3, gen_loss = 1.1717732385281594, disc_loss = 0.08331895431864166
Trained batch 124 in epoch 3, gen_loss = 1.1775039949417114, disc_loss = 0.08311085782945156
Trained batch 125 in epoch 3, gen_loss = 1.1757772281056358, disc_loss = 0.0828640101300109
Trained batch 126 in epoch 3, gen_loss = 1.172853855636176, disc_loss = 0.08276906678467755
Trained batch 127 in epoch 3, gen_loss = 1.1762946639209986, disc_loss = 0.08323459104576614
Trained batch 128 in epoch 3, gen_loss = 1.1730776969776597, disc_loss = 0.08318843217494414
Trained batch 129 in epoch 3, gen_loss = 1.1713723251452812, disc_loss = 0.08288647450793248
Trained batch 130 in epoch 3, gen_loss = 1.1762409451353641, disc_loss = 0.0828456200573963
Trained batch 131 in epoch 3, gen_loss = 1.1727933102484904, disc_loss = 0.08290373730106336
Trained batch 132 in epoch 3, gen_loss = 1.1730149047715324, disc_loss = 0.08281018084993488
Trained batch 133 in epoch 3, gen_loss = 1.1708420252622063, disc_loss = 0.08274959132019709
Trained batch 134 in epoch 3, gen_loss = 1.1694737858242459, disc_loss = 0.08234080978565746
Trained batch 135 in epoch 3, gen_loss = 1.1713560083333183, disc_loss = 0.08254707021200482
Trained batch 136 in epoch 3, gen_loss = 1.167579697431439, disc_loss = 0.08274078812368595
Trained batch 137 in epoch 3, gen_loss = 1.1654934611009515, disc_loss = 0.08252049825977588
Trained batch 138 in epoch 3, gen_loss = 1.1714145052347251, disc_loss = 0.08301401593916707
Trained batch 139 in epoch 3, gen_loss = 1.1675015394176755, disc_loss = 0.0833739420665162
Trained batch 140 in epoch 3, gen_loss = 1.1738021826067715, disc_loss = 0.08323004936918299
Trained batch 141 in epoch 3, gen_loss = 1.1728164238829009, disc_loss = 0.08287079448641187
Trained batch 142 in epoch 3, gen_loss = 1.1698892562539427, disc_loss = 0.08284197534089321
Trained batch 143 in epoch 3, gen_loss = 1.1702531547182136, disc_loss = 0.08277009867338671
Trained batch 144 in epoch 3, gen_loss = 1.1678517419716408, disc_loss = 0.08260340112550506
Trained batch 145 in epoch 3, gen_loss = 1.1669511366380405, disc_loss = 0.08230254694513262
Trained batch 146 in epoch 3, gen_loss = 1.169799337987186, disc_loss = 0.08194264883593637
Trained batch 147 in epoch 3, gen_loss = 1.1676548997292648, disc_loss = 0.08179016076531764
Trained batch 148 in epoch 3, gen_loss = 1.1707682637560288, disc_loss = 0.0814551918848649
Trained batch 149 in epoch 3, gen_loss = 1.173817001581192, disc_loss = 0.0810513506581386
Trained batch 150 in epoch 3, gen_loss = 1.1728471158356066, disc_loss = 0.08077128589251972
Trained batch 151 in epoch 3, gen_loss = 1.1710098068180836, disc_loss = 0.08054300846139852
Trained batch 152 in epoch 3, gen_loss = 1.1723385663593517, disc_loss = 0.08020889581321111
Trained batch 153 in epoch 3, gen_loss = 1.1721815749422295, disc_loss = 0.07989735175649841
Trained batch 154 in epoch 3, gen_loss = 1.1729578529634783, disc_loss = 0.07947101800311958
Trained batch 155 in epoch 3, gen_loss = 1.1709844703093553, disc_loss = 0.07927625865723269
Trained batch 156 in epoch 3, gen_loss = 1.1705426733205273, disc_loss = 0.07893400720563853
Trained batch 157 in epoch 3, gen_loss = 1.1712911313847651, disc_loss = 0.07861661161826569
Trained batch 158 in epoch 3, gen_loss = 1.170248549314415, disc_loss = 0.07836435913875606
Trained batch 159 in epoch 3, gen_loss = 1.16987163759768, disc_loss = 0.07807934801676311
Trained batch 160 in epoch 3, gen_loss = 1.1688557348636366, disc_loss = 0.07773722222896282
Trained batch 161 in epoch 3, gen_loss = 1.1690286511992232, disc_loss = 0.07734353912212415
Trained batch 162 in epoch 3, gen_loss = 1.1684708072363965, disc_loss = 0.07702070571185073
Trained batch 163 in epoch 3, gen_loss = 1.168495039024004, disc_loss = 0.07695670708128047
Trained batch 164 in epoch 3, gen_loss = 1.1662187345100172, disc_loss = 0.07685413997846119
Trained batch 165 in epoch 3, gen_loss = 1.1652425441397243, disc_loss = 0.07670257761737848
Trained batch 166 in epoch 3, gen_loss = 1.165634317312412, disc_loss = 0.07642900456903046
Trained batch 167 in epoch 3, gen_loss = 1.1655312336626507, disc_loss = 0.07608891334495552
Trained batch 168 in epoch 3, gen_loss = 1.1658670648315248, disc_loss = 0.0757166712583434
Trained batch 169 in epoch 3, gen_loss = 1.165539952586679, disc_loss = 0.07551570847520933
Trained batch 170 in epoch 3, gen_loss = 1.1667057777705945, disc_loss = 0.07514495377521417
Trained batch 171 in epoch 3, gen_loss = 1.1670211858527606, disc_loss = 0.0748004769624839
Trained batch 172 in epoch 3, gen_loss = 1.1692216237845448, disc_loss = 0.07446219146553147
Trained batch 173 in epoch 3, gen_loss = 1.169661765811087, disc_loss = 0.07410258659022465
Trained batch 174 in epoch 3, gen_loss = 1.1680937906673976, disc_loss = 0.07397282671183347
Trained batch 175 in epoch 3, gen_loss = 1.1696621000089429, disc_loss = 0.07378045258387415
Trained batch 176 in epoch 3, gen_loss = 1.1699407434059401, disc_loss = 0.07345985209222063
Trained batch 177 in epoch 3, gen_loss = 1.1695868523603075, disc_loss = 0.07315322394179327
Trained batch 178 in epoch 3, gen_loss = 1.1697232992955426, disc_loss = 0.07284563250694029
Trained batch 179 in epoch 3, gen_loss = 1.1689329243368574, disc_loss = 0.07259702645759615
Trained batch 180 in epoch 3, gen_loss = 1.1678447542269585, disc_loss = 0.0723874158591279
Trained batch 181 in epoch 3, gen_loss = 1.1711567309531536, disc_loss = 0.07230001379438973
Trained batch 182 in epoch 3, gen_loss = 1.170156568125949, disc_loss = 0.0721551874917143
Trained batch 183 in epoch 3, gen_loss = 1.1684831989848095, disc_loss = 0.07204142440130691
Trained batch 184 in epoch 3, gen_loss = 1.170417462168513, disc_loss = 0.07237894583896205
Trained batch 185 in epoch 3, gen_loss = 1.167083845343641, disc_loss = 0.07290632494535017
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 1.1499825716018677, disc_loss = 0.08721984177827835
Trained batch 1 in epoch 4, gen_loss = 1.0076181292533875, disc_loss = 0.07611843571066856
Trained batch 2 in epoch 4, gen_loss = 1.0530954599380493, disc_loss = 0.06499197830756505
Trained batch 3 in epoch 4, gen_loss = 1.0450244843959808, disc_loss = 0.05887589883059263
Trained batch 4 in epoch 4, gen_loss = 1.0636895895004272, disc_loss = 0.05253457315266132
Trained batch 5 in epoch 4, gen_loss = 1.093510905901591, disc_loss = 0.04757994754860798
Trained batch 6 in epoch 4, gen_loss = 1.0788512570517403, disc_loss = 0.04631404924605574
Trained batch 7 in epoch 4, gen_loss = 1.1171692907810211, disc_loss = 0.042244739015586674
Trained batch 8 in epoch 4, gen_loss = 1.099062032169766, disc_loss = 0.04126171446922752
Trained batch 9 in epoch 4, gen_loss = 1.1123428106307984, disc_loss = 0.04442654261365533
Trained batch 10 in epoch 4, gen_loss = 1.1178820458325474, disc_loss = 0.042423293756490406
Trained batch 11 in epoch 4, gen_loss = 1.0944732874631882, disc_loss = 0.04431883688084781
Trained batch 12 in epoch 4, gen_loss = 1.1333833795327406, disc_loss = 0.04655308799388317
Trained batch 13 in epoch 4, gen_loss = 1.1151731823171889, disc_loss = 0.04718681085588677
Trained batch 14 in epoch 4, gen_loss = 1.133146917819977, disc_loss = 0.04527663843085369
Trained batch 15 in epoch 4, gen_loss = 1.121303427964449, disc_loss = 0.044448914064560086
Trained batch 16 in epoch 4, gen_loss = 1.130452292806962, disc_loss = 0.047085177427267325
Trained batch 17 in epoch 4, gen_loss = 1.0951921608712938, disc_loss = 0.05636178790074256
Trained batch 18 in epoch 4, gen_loss = 1.1187398810135691, disc_loss = 0.06659218987548038
Trained batch 19 in epoch 4, gen_loss = 1.0984303891658782, disc_loss = 0.06953006838448346
Trained batch 20 in epoch 4, gen_loss = 1.0876332776887077, disc_loss = 0.07037306900712706
Trained batch 21 in epoch 4, gen_loss = 1.0836130190979352, disc_loss = 0.07053937293081121
Trained batch 22 in epoch 4, gen_loss = 1.0751155277957087, disc_loss = 0.0708729573323027
Trained batch 23 in epoch 4, gen_loss = 1.0639921550949414, disc_loss = 0.07188701943960041
Trained batch 24 in epoch 4, gen_loss = 1.053378269672394, disc_loss = 0.07168170366436243
Trained batch 25 in epoch 4, gen_loss = 1.0658342586113856, disc_loss = 0.07426289100056657
Trained batch 26 in epoch 4, gen_loss = 1.0665973137926172, disc_loss = 0.07238058431970852
Trained batch 27 in epoch 4, gen_loss = 1.049560472369194, disc_loss = 0.0744348058277475
Trained batch 28 in epoch 4, gen_loss = 1.0553626541433663, disc_loss = 0.07417962176661039
Trained batch 29 in epoch 4, gen_loss = 1.0488926390806834, disc_loss = 0.07422822431350748
Trained batch 30 in epoch 4, gen_loss = 1.0668935679620313, disc_loss = 0.076258065389289
Trained batch 31 in epoch 4, gen_loss = 1.0640119519084692, disc_loss = 0.07520507476874627
Trained batch 32 in epoch 4, gen_loss = 1.0551779830094539, disc_loss = 0.07521492008571372
Trained batch 33 in epoch 4, gen_loss = 1.064669305787367, disc_loss = 0.07379415349158294
Trained batch 34 in epoch 4, gen_loss = 1.0658024975231715, disc_loss = 0.07445328472448247
Trained batch 35 in epoch 4, gen_loss = 1.058705626262559, disc_loss = 0.07411843913400339
Trained batch 36 in epoch 4, gen_loss = 1.0630207110095669, disc_loss = 0.07287644657834962
Trained batch 37 in epoch 4, gen_loss = 1.0731821483687352, disc_loss = 0.07242795347089045
Trained batch 38 in epoch 4, gen_loss = 1.0697391384687178, disc_loss = 0.07136127832703866
Trained batch 39 in epoch 4, gen_loss = 1.0675573453307152, disc_loss = 0.07023700478021055
Trained batch 40 in epoch 4, gen_loss = 1.0751538814567938, disc_loss = 0.06920539385570985
Trained batch 41 in epoch 4, gen_loss = 1.0805715989498865, disc_loss = 0.06810849849578171
Trained batch 42 in epoch 4, gen_loss = 1.0729469851005908, disc_loss = 0.06828540180225012
Trained batch 43 in epoch 4, gen_loss = 1.0855607810345562, disc_loss = 0.06929977777922018
Trained batch 44 in epoch 4, gen_loss = 1.0885077436765036, disc_loss = 0.06850116714421246
Trained batch 45 in epoch 4, gen_loss = 1.0885175220344379, disc_loss = 0.06757362225376394
Trained batch 46 in epoch 4, gen_loss = 1.0890800458319643, disc_loss = 0.06649259396610742
Trained batch 47 in epoch 4, gen_loss = 1.0886483925084274, disc_loss = 0.06572063494240865
Trained batch 48 in epoch 4, gen_loss = 1.0967826636470095, disc_loss = 0.064782506140063
Trained batch 49 in epoch 4, gen_loss = 1.0944378101825714, disc_loss = 0.06424023123458028
Trained batch 50 in epoch 4, gen_loss = 1.0893547289511736, disc_loss = 0.06395982821271115
Trained batch 51 in epoch 4, gen_loss = 1.114212915301323, disc_loss = 0.06592463531817955
Trained batch 52 in epoch 4, gen_loss = 1.1193405963339895, disc_loss = 0.06504016750896315
Trained batch 53 in epoch 4, gen_loss = 1.1196923090351953, disc_loss = 0.06437467402537111
Trained batch 54 in epoch 4, gen_loss = 1.1283741615035316, disc_loss = 0.06349615053358403
Trained batch 55 in epoch 4, gen_loss = 1.1337901470916611, disc_loss = 0.0626696073949071
Trained batch 56 in epoch 4, gen_loss = 1.1315081569186427, disc_loss = 0.062180121854078355
Trained batch 57 in epoch 4, gen_loss = 1.1307374763077702, disc_loss = 0.06148102640270673
Trained batch 58 in epoch 4, gen_loss = 1.1359540193767872, disc_loss = 0.06076163471818476
Trained batch 59 in epoch 4, gen_loss = 1.1328733811775844, disc_loss = 0.060476859612390396
Trained batch 60 in epoch 4, gen_loss = 1.1381375701701055, disc_loss = 0.06013387638586955
Trained batch 61 in epoch 4, gen_loss = 1.1543464266484784, disc_loss = 0.060090788564975225
Trained batch 62 in epoch 4, gen_loss = 1.1620287280234078, disc_loss = 0.05955091185335602
Trained batch 63 in epoch 4, gen_loss = 1.16592503990978, disc_loss = 0.05881201989541296
Trained batch 64 in epoch 4, gen_loss = 1.1688677503512457, disc_loss = 0.05808226992017948
Trained batch 65 in epoch 4, gen_loss = 1.1701663922179828, disc_loss = 0.05739156172300378
Trained batch 66 in epoch 4, gen_loss = 1.1711590245588501, disc_loss = 0.05685245249865215
Trained batch 67 in epoch 4, gen_loss = 1.1707395727143568, disc_loss = 0.05630103656200364
Trained batch 68 in epoch 4, gen_loss = 1.1753182869026626, disc_loss = 0.05565727210563162
Trained batch 69 in epoch 4, gen_loss = 1.1736717811652593, disc_loss = 0.05519437986825194
Trained batch 70 in epoch 4, gen_loss = 1.180020398657087, disc_loss = 0.054594718536335816
Trained batch 71 in epoch 4, gen_loss = 1.1817357680863805, disc_loss = 0.05397940361096213
Trained batch 72 in epoch 4, gen_loss = 1.1802250612271976, disc_loss = 0.05356473686199074
Trained batch 73 in epoch 4, gen_loss = 1.1837063649216213, disc_loss = 0.052988741194476954
Trained batch 74 in epoch 4, gen_loss = 1.18336758852005, disc_loss = 0.05263661486407121
Trained batch 75 in epoch 4, gen_loss = 1.1859060392567986, disc_loss = 0.052060510129912904
Trained batch 76 in epoch 4, gen_loss = 1.1916071524867764, disc_loss = 0.051778989275554556
Trained batch 77 in epoch 4, gen_loss = 1.1930840619099445, disc_loss = 0.05143898374472673
Trained batch 78 in epoch 4, gen_loss = 1.1918735043911994, disc_loss = 0.05129222753398781
Trained batch 79 in epoch 4, gen_loss = 1.1913495190441608, disc_loss = 0.05084662726148963
Trained batch 80 in epoch 4, gen_loss = 1.194236605991552, disc_loss = 0.05039310547304742
Trained batch 81 in epoch 4, gen_loss = 1.2077255198141423, disc_loss = 0.05085613424094712
Trained batch 82 in epoch 4, gen_loss = 1.2121968405792511, disc_loss = 0.05035651964415987
Trained batch 83 in epoch 4, gen_loss = 1.2120592359985625, disc_loss = 0.05003852117806673
Trained batch 84 in epoch 4, gen_loss = 1.2130241667523103, disc_loss = 0.04958100163323038
Trained batch 85 in epoch 4, gen_loss = 1.2120844784171083, disc_loss = 0.049281009689493234
Trained batch 86 in epoch 4, gen_loss = 1.210057867669511, disc_loss = 0.04897815941822255
Trained batch 87 in epoch 4, gen_loss = 1.21244127438827, disc_loss = 0.04869313853454183
Trained batch 88 in epoch 4, gen_loss = 1.2128680977928505, disc_loss = 0.04822319551381502
Trained batch 89 in epoch 4, gen_loss = 1.2109441459178925, disc_loss = 0.048010260052978995
Trained batch 90 in epoch 4, gen_loss = 1.2103369805839035, disc_loss = 0.0476742358980598
Trained batch 91 in epoch 4, gen_loss = 1.2203052374331846, disc_loss = 0.04817874729633331
Trained batch 92 in epoch 4, gen_loss = 1.2195417977148486, disc_loss = 0.04805758443250451
Trained batch 93 in epoch 4, gen_loss = 1.2152755767741101, disc_loss = 0.04820624929159246
Trained batch 94 in epoch 4, gen_loss = 1.2159783237858823, disc_loss = 0.048118843844062405
Trained batch 95 in epoch 4, gen_loss = 1.2212119847536087, disc_loss = 0.04808561387471855
Trained batch 96 in epoch 4, gen_loss = 1.2185063786113386, disc_loss = 0.048150323369761105
Trained batch 97 in epoch 4, gen_loss = 1.215035839956634, disc_loss = 0.04817461621548448
Trained batch 98 in epoch 4, gen_loss = 1.2152419355180528, disc_loss = 0.04816565624993257
Trained batch 99 in epoch 4, gen_loss = 1.2187069988250732, disc_loss = 0.048303100019693374
Trained batch 100 in epoch 4, gen_loss = 1.2140343112520653, disc_loss = 0.04862482587594797
Trained batch 101 in epoch 4, gen_loss = 1.2112802670282476, disc_loss = 0.04853617078533359
Trained batch 102 in epoch 4, gen_loss = 1.2136612951176837, disc_loss = 0.048761520715593136
Trained batch 103 in epoch 4, gen_loss = 1.2153437063097954, disc_loss = 0.048394569052526586
Trained batch 104 in epoch 4, gen_loss = 1.2160182220595224, disc_loss = 0.04809140202899774
Trained batch 105 in epoch 4, gen_loss = 1.2153586672162109, disc_loss = 0.047734059358261666
Trained batch 106 in epoch 4, gen_loss = 1.2123235285839187, disc_loss = 0.047744439827783085
Trained batch 107 in epoch 4, gen_loss = 1.211915695004993, disc_loss = 0.047658338901345375
Trained batch 108 in epoch 4, gen_loss = 1.2123938252072815, disc_loss = 0.047362183938401005
Trained batch 109 in epoch 4, gen_loss = 1.210064947605133, disc_loss = 0.04729695720598102
Trained batch 110 in epoch 4, gen_loss = 1.2089010197837073, disc_loss = 0.047078715091957164
Trained batch 111 in epoch 4, gen_loss = 1.215731035385813, disc_loss = 0.04716066202049011
Trained batch 112 in epoch 4, gen_loss = 1.2147390483754925, disc_loss = 0.046902938729432304
Trained batch 113 in epoch 4, gen_loss = 1.215135605711686, disc_loss = 0.04660562841679182
Trained batch 114 in epoch 4, gen_loss = 1.2149841495182203, disc_loss = 0.04628163252997657
Trained batch 115 in epoch 4, gen_loss = 1.2150027721092618, disc_loss = 0.04595769007272761
Trained batch 116 in epoch 4, gen_loss = 1.2147437639725513, disc_loss = 0.04563483356251421
Trained batch 117 in epoch 4, gen_loss = 1.213760896254394, disc_loss = 0.04538145780531784
Trained batch 118 in epoch 4, gen_loss = 1.2140470202229603, disc_loss = 0.04527317425001319
Trained batch 119 in epoch 4, gen_loss = 1.2137723485628764, disc_loss = 0.0449800238556539
Trained batch 120 in epoch 4, gen_loss = 1.211186386336965, disc_loss = 0.04495465634621618
Trained batch 121 in epoch 4, gen_loss = 1.216600811872326, disc_loss = 0.045395732925991056
Trained batch 122 in epoch 4, gen_loss = 1.2155249574320104, disc_loss = 0.045255225023057885
Trained batch 123 in epoch 4, gen_loss = 1.2111062455561854, disc_loss = 0.04571451861861973
Trained batch 124 in epoch 4, gen_loss = 1.2119610567092896, disc_loss = 0.04577310650795698
Trained batch 125 in epoch 4, gen_loss = 1.214051227720957, disc_loss = 0.04563505405796662
Trained batch 126 in epoch 4, gen_loss = 1.2118285176322217, disc_loss = 0.04559757680023514
Trained batch 127 in epoch 4, gen_loss = 1.2088402793742716, disc_loss = 0.04569359911693027
Trained batch 128 in epoch 4, gen_loss = 1.2113545176594755, disc_loss = 0.045656757783000324
Trained batch 129 in epoch 4, gen_loss = 1.2142009647992942, disc_loss = 0.04550834926418387
Trained batch 130 in epoch 4, gen_loss = 1.211227294597917, disc_loss = 0.045612465597347905
Trained batch 131 in epoch 4, gen_loss = 1.2128064591776242, disc_loss = 0.04533649462444538
Trained batch 132 in epoch 4, gen_loss = 1.2105121603585725, disc_loss = 0.04528012984481297
Trained batch 133 in epoch 4, gen_loss = 1.213978077048686, disc_loss = 0.0454580214555695
Trained batch 134 in epoch 4, gen_loss = 1.2115381832476015, disc_loss = 0.045463401748350375
Trained batch 135 in epoch 4, gen_loss = 1.2115932098206352, disc_loss = 0.04526910630246515
Trained batch 136 in epoch 4, gen_loss = 1.2089781500127195, disc_loss = 0.0453468714058943
Trained batch 137 in epoch 4, gen_loss = 1.2103813627491826, disc_loss = 0.04576207665672553
Trained batch 138 in epoch 4, gen_loss = 1.2100262444653958, disc_loss = 0.04561978088785633
Trained batch 139 in epoch 4, gen_loss = 1.207438827412469, disc_loss = 0.04568881595374218
Trained batch 140 in epoch 4, gen_loss = 1.2065265406953527, disc_loss = 0.04578794196168793
Trained batch 141 in epoch 4, gen_loss = 1.2081177981806472, disc_loss = 0.045562350892947176
Trained batch 142 in epoch 4, gen_loss = 1.2094993091129755, disc_loss = 0.04532465134858043
Trained batch 143 in epoch 4, gen_loss = 1.2106489398413234, disc_loss = 0.04506216158754089
Trained batch 144 in epoch 4, gen_loss = 1.211722547432472, disc_loss = 0.04480307224559887
Trained batch 145 in epoch 4, gen_loss = 1.210868199394174, disc_loss = 0.04459777017991531
Trained batch 146 in epoch 4, gen_loss = 1.2104604146918472, disc_loss = 0.044441896867716595
Trained batch 147 in epoch 4, gen_loss = 1.2088799907549008, disc_loss = 0.04435688395971885
Trained batch 148 in epoch 4, gen_loss = 1.2089288150704147, disc_loss = 0.04425323061057485
Trained batch 149 in epoch 4, gen_loss = 1.2094873519738516, disc_loss = 0.04405322047881782
Trained batch 150 in epoch 4, gen_loss = 1.2085193249563508, disc_loss = 0.04387193436222459
Trained batch 151 in epoch 4, gen_loss = 1.2072457918211033, disc_loss = 0.0437557990080677
Trained batch 152 in epoch 4, gen_loss = 1.2090327377412833, disc_loss = 0.0437471316488204
Trained batch 153 in epoch 4, gen_loss = 1.209609138888198, disc_loss = 0.043525709326125005
Trained batch 154 in epoch 4, gen_loss = 1.2086920549792628, disc_loss = 0.04335646276332197
Trained batch 155 in epoch 4, gen_loss = 1.2119759363241684, disc_loss = 0.04365491611847224
Trained batch 156 in epoch 4, gen_loss = 1.208087705502844, disc_loss = 0.04434111195017293
Trained batch 157 in epoch 4, gen_loss = 1.207120478907718, disc_loss = 0.044261619380875666
Trained batch 158 in epoch 4, gen_loss = 1.2100397678291273, disc_loss = 0.04442556101957676
Trained batch 159 in epoch 4, gen_loss = 1.207370452210307, disc_loss = 0.04477888003748376
Trained batch 160 in epoch 4, gen_loss = 1.2059406793635825, disc_loss = 0.04467770992055165
Trained batch 161 in epoch 4, gen_loss = 1.2049353464885995, disc_loss = 0.04469789190068381
Trained batch 162 in epoch 4, gen_loss = 1.205176660985303, disc_loss = 0.04448907542688075
Trained batch 163 in epoch 4, gen_loss = 1.2049519583219435, disc_loss = 0.0442826231322592
Trained batch 164 in epoch 4, gen_loss = 1.206550521922834, disc_loss = 0.04458651284997662
Trained batch 165 in epoch 4, gen_loss = 1.2033686921539077, disc_loss = 0.044853955190292144
Trained batch 166 in epoch 4, gen_loss = 1.2026382952393173, disc_loss = 0.0446902010896561
Trained batch 167 in epoch 4, gen_loss = 1.2033567119921957, disc_loss = 0.04494074831572583
Trained batch 168 in epoch 4, gen_loss = 1.2014029988875756, disc_loss = 0.04498225384110794
Trained batch 169 in epoch 4, gen_loss = 1.1986360812888426, disc_loss = 0.045326402824481624
Trained batch 170 in epoch 4, gen_loss = 1.2012032957104912, disc_loss = 0.0453668216880607
Trained batch 171 in epoch 4, gen_loss = 1.2007116540226825, disc_loss = 0.04527200040201722
Trained batch 172 in epoch 4, gen_loss = 1.198584677511557, disc_loss = 0.0452861234066588
Trained batch 173 in epoch 4, gen_loss = 1.1993988666726254, disc_loss = 0.04565892726900163
Trained batch 174 in epoch 4, gen_loss = 1.1958540763173784, disc_loss = 0.04630095489057047
Trained batch 175 in epoch 4, gen_loss = 1.1991810239851475, disc_loss = 0.04647572235659358
Trained batch 176 in epoch 4, gen_loss = 1.196269477491325, disc_loss = 0.046722468417558796
Trained batch 177 in epoch 4, gen_loss = 1.1979029402973946, disc_loss = 0.04666263303259032
Trained batch 178 in epoch 4, gen_loss = 1.196961779501185, disc_loss = 0.046535952617648424
Trained batch 179 in epoch 4, gen_loss = 1.1957153545485601, disc_loss = 0.046415915420382384
Trained batch 180 in epoch 4, gen_loss = 1.197651532473485, disc_loss = 0.046578930101733015
Trained batch 181 in epoch 4, gen_loss = 1.1951351034772264, disc_loss = 0.046775892619964676
Trained batch 182 in epoch 4, gen_loss = 1.193034937798651, disc_loss = 0.04682205051254949
Trained batch 183 in epoch 4, gen_loss = 1.1935646135521971, disc_loss = 0.04698936252237257
Trained batch 184 in epoch 4, gen_loss = 1.1932115145631739, disc_loss = 0.04685470405210917
Trained batch 185 in epoch 4, gen_loss = 1.1928125379546997, disc_loss = 0.046676990853983066
Testing Epoch 4

Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 0.9574041366577148, disc_loss = 0.0373258963227272
Trained batch 1 in epoch 5, gen_loss = 1.0861830711364746, disc_loss = 0.0348478090018034
Trained batch 2 in epoch 5, gen_loss = 1.0776599645614624, disc_loss = 0.03151334822177887
Trained batch 3 in epoch 5, gen_loss = 1.108377993106842, disc_loss = 0.025873330887407064
Trained batch 4 in epoch 5, gen_loss = 1.1859114170074463, disc_loss = 0.031536736711859706
Trained batch 5 in epoch 5, gen_loss = 1.117148995399475, disc_loss = 0.04047369056691726
Trained batch 6 in epoch 5, gen_loss = 1.2530369418007987, disc_loss = 0.0446209159812757
Trained batch 7 in epoch 5, gen_loss = 1.3072026073932648, disc_loss = 0.0447134820278734
Trained batch 8 in epoch 5, gen_loss = 1.3011731306711833, disc_loss = 0.04190657763845391
Trained batch 9 in epoch 5, gen_loss = 1.2640320003032683, disc_loss = 0.04145616050809622
Trained batch 10 in epoch 5, gen_loss = 1.2483198046684265, disc_loss = 0.03933912938968702
Trained batch 11 in epoch 5, gen_loss = 1.2601648320754368, disc_loss = 0.03761044067020217
Trained batch 12 in epoch 5, gen_loss = 1.2626376014489393, disc_loss = 0.035454500609865554
Trained batch 13 in epoch 5, gen_loss = 1.2484862165791648, disc_loss = 0.03434134487594877
Trained batch 14 in epoch 5, gen_loss = 1.2429751753807068, disc_loss = 0.03273892533034086
Trained batch 15 in epoch 5, gen_loss = 1.2549958787858486, disc_loss = 0.0312698683119379
Trained batch 16 in epoch 5, gen_loss = 1.268224249867832, disc_loss = 0.03084437532679123
Trained batch 17 in epoch 5, gen_loss = 1.2688099708822038, disc_loss = 0.029819335995448962
Trained batch 18 in epoch 5, gen_loss = 1.2713114995705455, disc_loss = 0.028689576361916568
Trained batch 19 in epoch 5, gen_loss = 1.2762459546327591, disc_loss = 0.027803186466917394
Trained batch 20 in epoch 5, gen_loss = 1.2765880624453227, disc_loss = 0.02824053997617392
Trained batch 21 in epoch 5, gen_loss = 1.2594854858788578, disc_loss = 0.029288953635841608
Trained batch 22 in epoch 5, gen_loss = 1.2589284570320793, disc_loss = 0.02848582540679237
Trained batch 23 in epoch 5, gen_loss = 1.270407813290755, disc_loss = 0.030060210769685607
Trained batch 24 in epoch 5, gen_loss = 1.2600949835777282, disc_loss = 0.029894245453178883
Trained batch 25 in epoch 5, gen_loss = 1.2570462203942812, disc_loss = 0.029530807219159145
Trained batch 26 in epoch 5, gen_loss = 1.2674283738489505, disc_loss = 0.02905919226921267
Trained batch 27 in epoch 5, gen_loss = 1.2651770136186056, disc_loss = 0.028419883489342674
Trained batch 28 in epoch 5, gen_loss = 1.2605082392692566, disc_loss = 0.027904845292455162
Trained batch 29 in epoch 5, gen_loss = 1.2522832373778026, disc_loss = 0.028847619798034428
Trained batch 30 in epoch 5, gen_loss = 1.2609907754005925, disc_loss = 0.02839890413827473
Trained batch 31 in epoch 5, gen_loss = 1.2606538403779268, disc_loss = 0.02776321055716835
Trained batch 32 in epoch 5, gen_loss = 1.2542355945616057, disc_loss = 0.027458318452717678
Trained batch 33 in epoch 5, gen_loss = 1.2506107740542467, disc_loss = 0.02714292976238272
Trained batch 34 in epoch 5, gen_loss = 1.2558623262814113, disc_loss = 0.02678843345493078
Trained batch 35 in epoch 5, gen_loss = 1.2780387881729338, disc_loss = 0.028267473525678117
Trained batch 36 in epoch 5, gen_loss = 1.2693761877111487, disc_loss = 0.028998436884501495
Trained batch 37 in epoch 5, gen_loss = 1.263214886188507, disc_loss = 0.02875350280909946
Trained batch 38 in epoch 5, gen_loss = 1.2615132545813537, disc_loss = 0.028445201352811776
Trained batch 39 in epoch 5, gen_loss = 1.2690740436315537, disc_loss = 0.029019639384932815
Trained batch 40 in epoch 5, gen_loss = 1.2565117710974159, disc_loss = 0.03017349988676426
Trained batch 41 in epoch 5, gen_loss = 1.255674238715853, disc_loss = 0.030722007354987518
Trained batch 42 in epoch 5, gen_loss = 1.2470678534618644, disc_loss = 0.030950139536587304
Trained batch 43 in epoch 5, gen_loss = 1.2424447373910383, disc_loss = 0.030712609327482907
Trained batch 44 in epoch 5, gen_loss = 1.2421422481536866, disc_loss = 0.03144689208517472
Trained batch 45 in epoch 5, gen_loss = 1.2351085517717444, disc_loss = 0.03145471520964866
Trained batch 46 in epoch 5, gen_loss = 1.2322305263356959, disc_loss = 0.031317226648172165
Trained batch 47 in epoch 5, gen_loss = 1.2344183797637622, disc_loss = 0.03096187529930224
Trained batch 48 in epoch 5, gen_loss = 1.2390688268505796, disc_loss = 0.03082014110927679
Trained batch 49 in epoch 5, gen_loss = 1.233442884683609, disc_loss = 0.031071229353547097
Trained batch 50 in epoch 5, gen_loss = 1.2395161565612345, disc_loss = 0.030725026777123705
Trained batch 51 in epoch 5, gen_loss = 1.244920809681599, disc_loss = 0.03035353967705025
Trained batch 52 in epoch 5, gen_loss = 1.2412441597794586, disc_loss = 0.030178031356970093
Trained batch 53 in epoch 5, gen_loss = 1.23849775062667, disc_loss = 0.02988604049163836
Trained batch 54 in epoch 5, gen_loss = 1.2417248303239996, disc_loss = 0.030283126709136098
Trained batch 55 in epoch 5, gen_loss = 1.236447668501309, disc_loss = 0.03037619318014809
Trained batch 56 in epoch 5, gen_loss = 1.23514299434528, disc_loss = 0.03003857464513235
Trained batch 57 in epoch 5, gen_loss = 1.2353799240342502, disc_loss = 0.02999907150736143
Trained batch 58 in epoch 5, gen_loss = 1.2343021408986237, disc_loss = 0.029910152367616103
Trained batch 59 in epoch 5, gen_loss = 1.2328209400177002, disc_loss = 0.030047694966197015
Trained batch 60 in epoch 5, gen_loss = 1.2261099033668392, disc_loss = 0.030561718479043147
Trained batch 61 in epoch 5, gen_loss = 1.2277298838861528, disc_loss = 0.030781821497986393
Trained batch 62 in epoch 5, gen_loss = 1.2239006502287728, disc_loss = 0.030732974883109804
Trained batch 63 in epoch 5, gen_loss = 1.2259642807766795, disc_loss = 0.030740080896066502
Trained batch 64 in epoch 5, gen_loss = 1.2270072707763084, disc_loss = 0.030509869668346186
Trained batch 65 in epoch 5, gen_loss = 1.2268502233606395, disc_loss = 0.0301989737446561
Trained batch 66 in epoch 5, gen_loss = 1.2227713590237632, disc_loss = 0.030176617844558475
Trained batch 67 in epoch 5, gen_loss = 1.2235277479185778, disc_loss = 0.029904328204472277
Trained batch 68 in epoch 5, gen_loss = 1.2260059196016062, disc_loss = 0.029736572633618893
Trained batch 69 in epoch 5, gen_loss = 1.2313289105892182, disc_loss = 0.029553247083510672
Trained batch 70 in epoch 5, gen_loss = 1.2278063641467565, disc_loss = 0.0295034812264879
Trained batch 71 in epoch 5, gen_loss = 1.2280126851465967, disc_loss = 0.029218150121677253
Trained batch 72 in epoch 5, gen_loss = 1.2334824596365837, disc_loss = 0.029370707625599755
Trained batch 73 in epoch 5, gen_loss = 1.2313663774245494, disc_loss = 0.029228282010031713
Trained batch 74 in epoch 5, gen_loss = 1.2307595674196878, disc_loss = 0.028993106906612713
Trained batch 75 in epoch 5, gen_loss = 1.226040841717469, disc_loss = 0.029321808833628893
Trained batch 76 in epoch 5, gen_loss = 1.23316503190375, disc_loss = 0.02968627347477845
Trained batch 77 in epoch 5, gen_loss = 1.2258762151767046, disc_loss = 0.030647304362784594
Trained batch 78 in epoch 5, gen_loss = 1.2301405260834513, disc_loss = 0.031105436644033542
Trained batch 79 in epoch 5, gen_loss = 1.2275041148066521, disc_loss = 0.031061129225417972
Trained batch 80 in epoch 5, gen_loss = 1.2292414432690468, disc_loss = 0.030936131667759683
Trained batch 81 in epoch 5, gen_loss = 1.224414462723383, disc_loss = 0.03125451752779687
Trained batch 82 in epoch 5, gen_loss = 1.2284916258720031, disc_loss = 0.03140678043555783
Trained batch 83 in epoch 5, gen_loss = 1.2255257800931023, disc_loss = 0.03143194674824675
Trained batch 84 in epoch 5, gen_loss = 1.2253158856840696, disc_loss = 0.03120909164495328
Trained batch 85 in epoch 5, gen_loss = 1.2243887179119641, disc_loss = 0.03101300652853625
Trained batch 86 in epoch 5, gen_loss = 1.2252348832700444, disc_loss = 0.031111632195440518
Trained batch 87 in epoch 5, gen_loss = 1.2208574502305551, disc_loss = 0.031388013464906675
Trained batch 88 in epoch 5, gen_loss = 1.2193711453609253, disc_loss = 0.031258496246562247
Trained batch 89 in epoch 5, gen_loss = 1.2216703898376888, disc_loss = 0.03102160222414467
Trained batch 90 in epoch 5, gen_loss = 1.2191055980357495, disc_loss = 0.031436064024711705
Trained batch 91 in epoch 5, gen_loss = 1.2198158560887626, disc_loss = 0.031218791157817064
Trained batch 92 in epoch 5, gen_loss = 1.2190416634723704, disc_loss = 0.03108121893338619
Trained batch 93 in epoch 5, gen_loss = 1.2183548928575312, disc_loss = 0.03128665239807773
Trained batch 94 in epoch 5, gen_loss = 1.2156976950796028, disc_loss = 0.03122797063306758
Trained batch 95 in epoch 5, gen_loss = 1.2167035515109699, disc_loss = 0.031618196556034185
Trained batch 96 in epoch 5, gen_loss = 1.2122729918391435, disc_loss = 0.03243292472565297
Trained batch 97 in epoch 5, gen_loss = 1.2081167053203195, disc_loss = 0.03296531185659827
Trained batch 98 in epoch 5, gen_loss = 1.2160472448426063, disc_loss = 0.03449197666663112
Trained batch 99 in epoch 5, gen_loss = 1.2131977415084838, disc_loss = 0.03471688896417618
Trained batch 100 in epoch 5, gen_loss = 1.210431662526461, disc_loss = 0.03488510168424928
Trained batch 101 in epoch 5, gen_loss = 1.2101605435212452, disc_loss = 0.0352118308929836
Trained batch 102 in epoch 5, gen_loss = 1.2054006144838425, disc_loss = 0.03670068938755295
Trained batch 103 in epoch 5, gen_loss = 1.2066168939838042, disc_loss = 0.03933241103704159
Trained batch 104 in epoch 5, gen_loss = 1.208796253090813, disc_loss = 0.04212680033275059
Trained batch 105 in epoch 5, gen_loss = 1.206295594291867, disc_loss = 0.0428093247256189
Trained batch 106 in epoch 5, gen_loss = 1.2002289300767062, disc_loss = 0.044048469061049346
Trained batch 107 in epoch 5, gen_loss = 1.2023116951739345, disc_loss = 0.04567277224527465
Trained batch 108 in epoch 5, gen_loss = 1.1983720189934477, disc_loss = 0.04604879732525677
Trained batch 109 in epoch 5, gen_loss = 1.1943962709470228, disc_loss = 0.04654333415356549
Trained batch 110 in epoch 5, gen_loss = 1.194250221188004, disc_loss = 0.04655218832530417
Trained batch 111 in epoch 5, gen_loss = 1.1902332114321845, disc_loss = 0.0468780065421015
Trained batch 112 in epoch 5, gen_loss = 1.1891410540690464, disc_loss = 0.047855532901213235
Trained batch 113 in epoch 5, gen_loss = 1.1841918287570017, disc_loss = 0.04855095644138361
Trained batch 114 in epoch 5, gen_loss = 1.1820292027100272, disc_loss = 0.048597949451726415
Trained batch 115 in epoch 5, gen_loss = 1.182982205316938, disc_loss = 0.04919195454567671
Trained batch 116 in epoch 5, gen_loss = 1.178389677634606, disc_loss = 0.049760053268609904
Trained batch 117 in epoch 5, gen_loss = 1.1758351977598869, disc_loss = 0.05015367057995271
Trained batch 118 in epoch 5, gen_loss = 1.1755253482265633, disc_loss = 0.05009288973167163
Trained batch 119 in epoch 5, gen_loss = 1.1754026139775913, disc_loss = 0.05025259368121624
Trained batch 120 in epoch 5, gen_loss = 1.1721076103281383, disc_loss = 0.050303963220809114
Trained batch 121 in epoch 5, gen_loss = 1.172426512495416, disc_loss = 0.05016150203396062
Trained batch 122 in epoch 5, gen_loss = 1.1722922649809984, disc_loss = 0.0499386215749068
Trained batch 123 in epoch 5, gen_loss = 1.170376803605787, disc_loss = 0.04980199719448724
Trained batch 124 in epoch 5, gen_loss = 1.1707232961654663, disc_loss = 0.049475733973085884
Trained batch 125 in epoch 5, gen_loss = 1.1729383194257343, disc_loss = 0.04946083469789416
Trained batch 126 in epoch 5, gen_loss = 1.1766136481067326, disc_loss = 0.04925041609832386
Trained batch 127 in epoch 5, gen_loss = 1.1738997525535524, disc_loss = 0.0494719775088015
Trained batch 128 in epoch 5, gen_loss = 1.1756547056427298, disc_loss = 0.04919874772804883
Trained batch 129 in epoch 5, gen_loss = 1.1766752339326418, disc_loss = 0.04897776488931133
Trained batch 130 in epoch 5, gen_loss = 1.1780145536852247, disc_loss = 0.04868617397199833
Trained batch 131 in epoch 5, gen_loss = 1.1759927819172542, disc_loss = 0.04860900807420187
Trained batch 132 in epoch 5, gen_loss = 1.1767387394618272, disc_loss = 0.048311103380432256
Trained batch 133 in epoch 5, gen_loss = 1.1780509917593713, disc_loss = 0.048064071983933004
Trained batch 134 in epoch 5, gen_loss = 1.1799033187053822, disc_loss = 0.04790090942686355
Trained batch 135 in epoch 5, gen_loss = 1.1759363596930223, disc_loss = 0.048452951089369464
Trained batch 136 in epoch 5, gen_loss = 1.1755030233494557, disc_loss = 0.04830136950243346
Trained batch 137 in epoch 5, gen_loss = 1.1799168664476145, disc_loss = 0.048841109964996576
Trained batch 138 in epoch 5, gen_loss = 1.1766713737583847, disc_loss = 0.04910205337453446
Trained batch 139 in epoch 5, gen_loss = 1.1754568006311144, disc_loss = 0.04897954986164613
Trained batch 140 in epoch 5, gen_loss = 1.1746295064899093, disc_loss = 0.04912011875566227
Trained batch 141 in epoch 5, gen_loss = 1.1733945490608753, disc_loss = 0.04901956245434326
Trained batch 142 in epoch 5, gen_loss = 1.1730627713503536, disc_loss = 0.04880664584233419
Trained batch 143 in epoch 5, gen_loss = 1.171985333164533, disc_loss = 0.048640287500650935
Trained batch 144 in epoch 5, gen_loss = 1.1712929405015091, disc_loss = 0.048707486836817755
Trained batch 145 in epoch 5, gen_loss = 1.1690110343776337, disc_loss = 0.048760021379702305
Trained batch 146 in epoch 5, gen_loss = 1.170375478510954, disc_loss = 0.04865287532586427
Trained batch 147 in epoch 5, gen_loss = 1.1688417373476803, disc_loss = 0.04861541220138001
Trained batch 148 in epoch 5, gen_loss = 1.1691971921280726, disc_loss = 0.048469848249532634
Trained batch 149 in epoch 5, gen_loss = 1.1704648733139038, disc_loss = 0.04831985517715414
Trained batch 150 in epoch 5, gen_loss = 1.169349457254473, disc_loss = 0.04819644076613993
Trained batch 151 in epoch 5, gen_loss = 1.1680718511343002, disc_loss = 0.048194534751880715
Trained batch 152 in epoch 5, gen_loss = 1.1695684716592427, disc_loss = 0.04818011900057006
Trained batch 153 in epoch 5, gen_loss = 1.167622331674997, disc_loss = 0.0481928210741804
Trained batch 154 in epoch 5, gen_loss = 1.1684821828719107, disc_loss = 0.04795035400818432
Trained batch 155 in epoch 5, gen_loss = 1.1712277294733586, disc_loss = 0.04779126713028512
Trained batch 156 in epoch 5, gen_loss = 1.1700302935709619, disc_loss = 0.04764624730725387
Trained batch 157 in epoch 5, gen_loss = 1.1722094609013087, disc_loss = 0.047494380009843955
Trained batch 158 in epoch 5, gen_loss = 1.1743190307287301, disc_loss = 0.04730672306679892
Trained batch 159 in epoch 5, gen_loss = 1.1792790565639735, disc_loss = 0.04730563889606856
Trained batch 160 in epoch 5, gen_loss = 1.1823864631030871, disc_loss = 0.04732556006529872
Trained batch 161 in epoch 5, gen_loss = 1.1822335017316135, disc_loss = 0.04720762960129866
Trained batch 162 in epoch 5, gen_loss = 1.1846109376363227, disc_loss = 0.04702402650738603
Trained batch 163 in epoch 5, gen_loss = 1.1841410256740523, disc_loss = 0.04686360680725335
Trained batch 164 in epoch 5, gen_loss = 1.1846440434455872, disc_loss = 0.04665959087962454
Trained batch 165 in epoch 5, gen_loss = 1.1850470868219811, disc_loss = 0.046425873077059365
Trained batch 166 in epoch 5, gen_loss = 1.1845364288655584, disc_loss = 0.04622986204476057
Trained batch 167 in epoch 5, gen_loss = 1.187434199665274, disc_loss = 0.046077313555759336
Trained batch 168 in epoch 5, gen_loss = 1.1909873658383385, disc_loss = 0.045961588213341474
Trained batch 169 in epoch 5, gen_loss = 1.1902613727485432, disc_loss = 0.04583445875083699
Trained batch 170 in epoch 5, gen_loss = 1.190807947289874, disc_loss = 0.04561670196422359
Trained batch 171 in epoch 5, gen_loss = 1.1921100987251414, disc_loss = 0.04543035581361416
Trained batch 172 in epoch 5, gen_loss = 1.1918024172672648, disc_loss = 0.045256689589233755
Trained batch 173 in epoch 5, gen_loss = 1.1912314470472007, disc_loss = 0.04509887773672055
Trained batch 174 in epoch 5, gen_loss = 1.1937862481389727, disc_loss = 0.04512299952762468
Trained batch 175 in epoch 5, gen_loss = 1.1938225833529776, disc_loss = 0.044964677220295096
Trained batch 176 in epoch 5, gen_loss = 1.1933993394091977, disc_loss = 0.044800743786881196
Trained batch 177 in epoch 5, gen_loss = 1.1926481492733687, disc_loss = 0.04466465421104699
Trained batch 178 in epoch 5, gen_loss = 1.192455659032534, disc_loss = 0.04449243375292703
Trained batch 179 in epoch 5, gen_loss = 1.192770039041837, disc_loss = 0.044290921521476574
Trained batch 180 in epoch 5, gen_loss = 1.1931224004339778, disc_loss = 0.04409378974374322
Trained batch 181 in epoch 5, gen_loss = 1.1936521395877167, disc_loss = 0.04391234460194687
Trained batch 182 in epoch 5, gen_loss = 1.1957581789115739, disc_loss = 0.04408453508722977
Trained batch 183 in epoch 5, gen_loss = 1.193675075860127, disc_loss = 0.04430328092902251
Trained batch 184 in epoch 5, gen_loss = 1.1929901442012272, disc_loss = 0.04425212094509924
Trained batch 185 in epoch 5, gen_loss = 1.1935973792306838, disc_loss = 0.04407434287651252
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 0.9524121284484863, disc_loss = 0.03409619256854057
Trained batch 1 in epoch 6, gen_loss = 1.0469449758529663, disc_loss = 0.024914901703596115
Trained batch 2 in epoch 6, gen_loss = 1.0961216290791829, disc_loss = 0.024865397562583286
Trained batch 3 in epoch 6, gen_loss = 1.1486863493919373, disc_loss = 0.020252228248864412
Trained batch 4 in epoch 6, gen_loss = 1.1356861591339111, disc_loss = 0.01846335455775261
Trained batch 5 in epoch 6, gen_loss = 1.1264591018358867, disc_loss = 0.01993010441462199
Trained batch 6 in epoch 6, gen_loss = 1.1288598946162633, disc_loss = 0.02152504346200398
Trained batch 7 in epoch 6, gen_loss = 1.1614326238632202, disc_loss = 0.020357997971586883
Trained batch 8 in epoch 6, gen_loss = 1.1227778726153903, disc_loss = 0.02599459710634417
Trained batch 9 in epoch 6, gen_loss = 1.1675215244293213, disc_loss = 0.030269879009574653
Trained batch 10 in epoch 6, gen_loss = 1.1698131127790972, disc_loss = 0.02900383799252185
Trained batch 11 in epoch 6, gen_loss = 1.1638575494289398, disc_loss = 0.028025605172539752
Trained batch 12 in epoch 6, gen_loss = 1.1716594237547655, disc_loss = 0.030281216837465763
Trained batch 13 in epoch 6, gen_loss = 1.1489226094314031, disc_loss = 0.032049036784363646
Trained batch 14 in epoch 6, gen_loss = 1.161240271727244, disc_loss = 0.03195989994953076
Trained batch 15 in epoch 6, gen_loss = 1.1853629164397717, disc_loss = 0.031058637716341764
Trained batch 16 in epoch 6, gen_loss = 1.1811368921223808, disc_loss = 0.030819163657724857
Trained batch 17 in epoch 6, gen_loss = 1.1911738018194835, disc_loss = 0.029699673513985343
Trained batch 18 in epoch 6, gen_loss = 1.181535673768897, disc_loss = 0.03093969611156928
Trained batch 19 in epoch 6, gen_loss = 1.1701136916875838, disc_loss = 0.03231818997301161
Trained batch 20 in epoch 6, gen_loss = 1.1943052354313077, disc_loss = 0.03334419912702981
Trained batch 21 in epoch 6, gen_loss = 1.204649797894738, disc_loss = 0.033119323875077746
Trained batch 22 in epoch 6, gen_loss = 1.1948046399199443, disc_loss = 0.033668934448581676
Trained batch 23 in epoch 6, gen_loss = 1.2096588139732678, disc_loss = 0.03294396381049106
Trained batch 24 in epoch 6, gen_loss = 1.2173427748680115, disc_loss = 0.03202621653676033
Trained batch 25 in epoch 6, gen_loss = 1.2264068562250872, disc_loss = 0.03121254611043976
Trained batch 26 in epoch 6, gen_loss = 1.219976215450852, disc_loss = 0.030863643554901635
Trained batch 27 in epoch 6, gen_loss = 1.2210883689778191, disc_loss = 0.030317059751333936
Trained batch 28 in epoch 6, gen_loss = 1.203639079784525, disc_loss = 0.032197883320522716
Trained batch 29 in epoch 6, gen_loss = 1.2141916195551554, disc_loss = 0.03411193679397305
Trained batch 30 in epoch 6, gen_loss = 1.2133066192750008, disc_loss = 0.03331880731087539
Trained batch 31 in epoch 6, gen_loss = 1.2008781768381596, disc_loss = 0.034027714893454686
Trained batch 32 in epoch 6, gen_loss = 1.2034841161785703, disc_loss = 0.035294887609779835
Trained batch 33 in epoch 6, gen_loss = 1.2018096657360302, disc_loss = 0.03452222766902517
Trained batch 34 in epoch 6, gen_loss = 1.1952774729047502, disc_loss = 0.03428216102932181
Trained batch 35 in epoch 6, gen_loss = 1.1969871587223477, disc_loss = 0.034719655031545296
Trained batch 36 in epoch 6, gen_loss = 1.1972448664742548, disc_loss = 0.03409966952293306
Trained batch 37 in epoch 6, gen_loss = 1.2002821941124766, disc_loss = 0.03336634403584819
Trained batch 38 in epoch 6, gen_loss = 1.2062959090257301, disc_loss = 0.03298071724099991
Trained batch 39 in epoch 6, gen_loss = 1.1997944861650467, disc_loss = 0.03300014408305287
Trained batch 40 in epoch 6, gen_loss = 1.1985298860363844, disc_loss = 0.032500095233866357
Trained batch 41 in epoch 6, gen_loss = 1.2121837877091908, disc_loss = 0.03268174261652997
Trained batch 42 in epoch 6, gen_loss = 1.204380358374396, disc_loss = 0.03336044966221549
Trained batch 43 in epoch 6, gen_loss = 1.2012745155529543, disc_loss = 0.032969719751484015
Trained batch 44 in epoch 6, gen_loss = 1.2009521550602382, disc_loss = 0.03245417651616865
Trained batch 45 in epoch 6, gen_loss = 1.2005324687646783, disc_loss = 0.03240042092764507
Trained batch 46 in epoch 6, gen_loss = 1.1974931511473148, disc_loss = 0.03205246012657881
Trained batch 47 in epoch 6, gen_loss = 1.1988703000048797, disc_loss = 0.03161667646296943
Trained batch 48 in epoch 6, gen_loss = 1.2023503719543924, disc_loss = 0.03147420235814489
Trained batch 49 in epoch 6, gen_loss = 1.193254212141037, disc_loss = 0.0321223040856421
Trained batch 50 in epoch 6, gen_loss = 1.1967001089862748, disc_loss = 0.03215204962693593
Trained batch 51 in epoch 6, gen_loss = 1.1935478804203181, disc_loss = 0.032023839168966964
Trained batch 52 in epoch 6, gen_loss = 1.184914081726434, disc_loss = 0.03282979547204274
Trained batch 53 in epoch 6, gen_loss = 1.2018326178744987, disc_loss = 0.03658535436692613
Trained batch 54 in epoch 6, gen_loss = 1.1950226989659396, disc_loss = 0.03728999409147284
Trained batch 55 in epoch 6, gen_loss = 1.1925511179225785, disc_loss = 0.03834453911986202
Trained batch 56 in epoch 6, gen_loss = 1.1807323202752231, disc_loss = 0.04024217181365218
Trained batch 57 in epoch 6, gen_loss = 1.1815428476909111, disc_loss = 0.04034773807908441
Trained batch 58 in epoch 6, gen_loss = 1.1836369653879586, disc_loss = 0.0402040238634257
Trained batch 59 in epoch 6, gen_loss = 1.1767591297626496, disc_loss = 0.040750830946490166
Trained batch 60 in epoch 6, gen_loss = 1.176671917321252, disc_loss = 0.04073553607173142
Trained batch 61 in epoch 6, gen_loss = 1.178487152822556, disc_loss = 0.04184601493480225
Trained batch 62 in epoch 6, gen_loss = 1.169959511075701, disc_loss = 0.04303841105115319
Trained batch 63 in epoch 6, gen_loss = 1.1658723074942827, disc_loss = 0.043088092483230866
Trained batch 64 in epoch 6, gen_loss = 1.169805334164546, disc_loss = 0.04333961286510413
Trained batch 65 in epoch 6, gen_loss = 1.1722730687170317, disc_loss = 0.04307278089055961
Trained batch 66 in epoch 6, gen_loss = 1.1652550030110487, disc_loss = 0.0437164340140437
Trained batch 67 in epoch 6, gen_loss = 1.1708116575199015, disc_loss = 0.04419874006827526
Trained batch 68 in epoch 6, gen_loss = 1.1685703845991604, disc_loss = 0.044454353186639324
Trained batch 69 in epoch 6, gen_loss = 1.1590759669031416, disc_loss = 0.046267609471189124
Trained batch 70 in epoch 6, gen_loss = 1.1661343624894047, disc_loss = 0.046392705147220215
Trained batch 71 in epoch 6, gen_loss = 1.1668746719757717, disc_loss = 0.04814005944515682
Trained batch 72 in epoch 6, gen_loss = 1.1602478484584862, disc_loss = 0.048945097597188326
Trained batch 73 in epoch 6, gen_loss = 1.1566079226700035, disc_loss = 0.048973362251008686
Trained batch 74 in epoch 6, gen_loss = 1.1560514163970947, disc_loss = 0.04946065213531256
Trained batch 75 in epoch 6, gen_loss = 1.1540811453994952, disc_loss = 0.04924702238732655
Trained batch 76 in epoch 6, gen_loss = 1.1550555987791582, disc_loss = 0.048752133746619346
Trained batch 77 in epoch 6, gen_loss = 1.1533477688447022, disc_loss = 0.04881974808776226
Trained batch 78 in epoch 6, gen_loss = 1.1513913047464588, disc_loss = 0.04852833921867836
Trained batch 79 in epoch 6, gen_loss = 1.1495160602033139, disc_loss = 0.04854153275955468
Trained batch 80 in epoch 6, gen_loss = 1.1518993900146013, disc_loss = 0.04813331556448966
Trained batch 81 in epoch 6, gen_loss = 1.147270647490897, disc_loss = 0.04830131282257598
Trained batch 82 in epoch 6, gen_loss = 1.1523671509271645, disc_loss = 0.0480994701340615
Trained batch 83 in epoch 6, gen_loss = 1.152831956034615, disc_loss = 0.04764449620796811
Trained batch 84 in epoch 6, gen_loss = 1.1511613354963415, disc_loss = 0.04731081965215066
Trained batch 85 in epoch 6, gen_loss = 1.1517249720041143, disc_loss = 0.04706545050667469
Trained batch 86 in epoch 6, gen_loss = 1.152838417853432, disc_loss = 0.04703352015850873
Trained batch 87 in epoch 6, gen_loss = 1.1536503000692888, disc_loss = 0.04673617652786726
Trained batch 88 in epoch 6, gen_loss = 1.1540384265813934, disc_loss = 0.04636375390495477
Trained batch 89 in epoch 6, gen_loss = 1.153012877040439, disc_loss = 0.04604496026618613
Trained batch 90 in epoch 6, gen_loss = 1.158899812907963, disc_loss = 0.04699632392397949
Trained batch 91 in epoch 6, gen_loss = 1.151083031102367, disc_loss = 0.04935849941862018
Trained batch 92 in epoch 6, gen_loss = 1.1513557366786464, disc_loss = 0.04917383288103406
Trained batch 93 in epoch 6, gen_loss = 1.1527465008040692, disc_loss = 0.050016992249862946
Trained batch 94 in epoch 6, gen_loss = 1.148460369674783, disc_loss = 0.05036710883049588
Trained batch 95 in epoch 6, gen_loss = 1.1463190965975325, disc_loss = 0.050235676094113536
Trained batch 96 in epoch 6, gen_loss = 1.1497909693988329, disc_loss = 0.050013778692821864
Trained batch 97 in epoch 6, gen_loss = 1.1478251659748506, disc_loss = 0.04989165951478846
Trained batch 98 in epoch 6, gen_loss = 1.144628985060586, disc_loss = 0.05005393013583891
Trained batch 99 in epoch 6, gen_loss = 1.147405951321125, disc_loss = 0.050442884285002945
Trained batch 100 in epoch 6, gen_loss = 1.1481481451209228, disc_loss = 0.05036387941108482
Trained batch 101 in epoch 6, gen_loss = 1.14519293840025, disc_loss = 0.050425208538916765
Trained batch 102 in epoch 6, gen_loss = 1.1426171802201317, disc_loss = 0.050368065701671016
Trained batch 103 in epoch 6, gen_loss = 1.146679922651786, disc_loss = 0.050823291208451755
Trained batch 104 in epoch 6, gen_loss = 1.146563711336681, disc_loss = 0.050488599797799474
Trained batch 105 in epoch 6, gen_loss = 1.146013859026837, disc_loss = 0.050223338505569495
Trained batch 106 in epoch 6, gen_loss = 1.1435580200681061, disc_loss = 0.05041998213975229
Trained batch 107 in epoch 6, gen_loss = 1.1399226263165474, disc_loss = 0.05072815274750745
Trained batch 108 in epoch 6, gen_loss = 1.149169095885863, disc_loss = 0.051707776861453274
Trained batch 109 in epoch 6, gen_loss = 1.1454181137410078, disc_loss = 0.051998821916905316
Trained batch 110 in epoch 6, gen_loss = 1.1449931696191564, disc_loss = 0.05197758032931938
Trained batch 111 in epoch 6, gen_loss = 1.1426663747323411, disc_loss = 0.05187770654447377
Trained batch 112 in epoch 6, gen_loss = 1.14548484282156, disc_loss = 0.05160600998628456
Trained batch 113 in epoch 6, gen_loss = 1.1489683334764682, disc_loss = 0.05150951298051759
Trained batch 114 in epoch 6, gen_loss = 1.1443323200163633, disc_loss = 0.05204465658120487
Trained batch 115 in epoch 6, gen_loss = 1.1430373518117543, disc_loss = 0.051842972234790695
Trained batch 116 in epoch 6, gen_loss = 1.1463860240247514, disc_loss = 0.052012770587944575
Trained batch 117 in epoch 6, gen_loss = 1.1450874595823934, disc_loss = 0.05175116156243672
Trained batch 118 in epoch 6, gen_loss = 1.1446413705829812, disc_loss = 0.05143478851640174
Trained batch 119 in epoch 6, gen_loss = 1.145333006232977, disc_loss = 0.05110545558854938
Trained batch 120 in epoch 6, gen_loss = 1.1459726875971172, disc_loss = 0.05100522131836119
Trained batch 121 in epoch 6, gen_loss = 1.1457497255235423, disc_loss = 0.0507676792254702
Trained batch 122 in epoch 6, gen_loss = 1.1436590879428676, disc_loss = 0.05071237135103079
Trained batch 123 in epoch 6, gen_loss = 1.1427184422650645, disc_loss = 0.050528329106107835
Trained batch 124 in epoch 6, gen_loss = 1.143439087152481, disc_loss = 0.05048363637924194
Trained batch 125 in epoch 6, gen_loss = 1.144633635878563, disc_loss = 0.05028076771469343
Trained batch 126 in epoch 6, gen_loss = 1.1455561797919236, disc_loss = 0.05002289821254456
Trained batch 127 in epoch 6, gen_loss = 1.1446504874620587, disc_loss = 0.04998963988327887
Trained batch 128 in epoch 6, gen_loss = 1.1440908559995104, disc_loss = 0.049762453551786816
Trained batch 129 in epoch 6, gen_loss = 1.150829904125287, disc_loss = 0.05195784532966522
Trained batch 130 in epoch 6, gen_loss = 1.144940157200544, disc_loss = 0.05449782173995298
Trained batch 131 in epoch 6, gen_loss = 1.1459626864754793, disc_loss = 0.05457055956746141
Trained batch 132 in epoch 6, gen_loss = 1.1463450231498344, disc_loss = 0.05436487781598156
Trained batch 133 in epoch 6, gen_loss = 1.1429878030695133, disc_loss = 0.05471198194062532
Trained batch 134 in epoch 6, gen_loss = 1.1411683517473716, disc_loss = 0.054867881370915306
Trained batch 135 in epoch 6, gen_loss = 1.143339726197369, disc_loss = 0.05545759984456441
Trained batch 136 in epoch 6, gen_loss = 1.141222276174239, disc_loss = 0.05551938136128613
Trained batch 137 in epoch 6, gen_loss = 1.1396532203408256, disc_loss = 0.055524425689077034
Trained batch 138 in epoch 6, gen_loss = 1.1397231643577275, disc_loss = 0.05549892574119911
Trained batch 139 in epoch 6, gen_loss = 1.1385711020656994, disc_loss = 0.05548547862895897
Trained batch 140 in epoch 6, gen_loss = 1.1387406830669295, disc_loss = 0.05517440617533652
Trained batch 141 in epoch 6, gen_loss = 1.1389753161601617, disc_loss = 0.055209132049127786
Trained batch 142 in epoch 6, gen_loss = 1.1373181545234228, disc_loss = 0.05506374546932382
Trained batch 143 in epoch 6, gen_loss = 1.1356171537190676, disc_loss = 0.05509070672431133
Trained batch 144 in epoch 6, gen_loss = 1.1356286955290826, disc_loss = 0.05485960498837562
Trained batch 145 in epoch 6, gen_loss = 1.1356347041995558, disc_loss = 0.0548537364548506
Trained batch 146 in epoch 6, gen_loss = 1.1369927718120367, disc_loss = 0.05453521693062012
Trained batch 147 in epoch 6, gen_loss = 1.1370934717155792, disc_loss = 0.05424620637141571
Trained batch 148 in epoch 6, gen_loss = 1.1365159407958088, disc_loss = 0.0540326755656392
Trained batch 149 in epoch 6, gen_loss = 1.1372894543409346, disc_loss = 0.05380751335993409
Trained batch 150 in epoch 6, gen_loss = 1.1371601893017624, disc_loss = 0.053571324641292065
Trained batch 151 in epoch 6, gen_loss = 1.137262479451142, disc_loss = 0.05329153873639083
Trained batch 152 in epoch 6, gen_loss = 1.1373630865337023, disc_loss = 0.053096689752552634
Trained batch 153 in epoch 6, gen_loss = 1.1372728187155414, disc_loss = 0.0528429792286804
Trained batch 154 in epoch 6, gen_loss = 1.139474222929247, disc_loss = 0.052558428211317905
Trained batch 155 in epoch 6, gen_loss = 1.140122153247014, disc_loss = 0.05229038463977094
Trained batch 156 in epoch 6, gen_loss = 1.141995971559719, disc_loss = 0.05209747520957593
Trained batch 157 in epoch 6, gen_loss = 1.1395514518777026, disc_loss = 0.052213884271162594
Trained batch 158 in epoch 6, gen_loss = 1.1398741076202512, disc_loss = 0.05203104396965706
Trained batch 159 in epoch 6, gen_loss = 1.1421974996104836, disc_loss = 0.051855580083793026
Trained batch 160 in epoch 6, gen_loss = 1.1422643655945797, disc_loss = 0.05162973234557217
Trained batch 161 in epoch 6, gen_loss = 1.140921295976933, disc_loss = 0.05154960549631973
Trained batch 162 in epoch 6, gen_loss = 1.141899789586389, disc_loss = 0.05143563803628178
Trained batch 163 in epoch 6, gen_loss = 1.1435622374822454, disc_loss = 0.05118717256615438
Trained batch 164 in epoch 6, gen_loss = 1.1438579658667247, disc_loss = 0.05096406588387309
Trained batch 165 in epoch 6, gen_loss = 1.145740560558905, disc_loss = 0.050725865710796
Trained batch 166 in epoch 6, gen_loss = 1.14600229602374, disc_loss = 0.05047653576994906
Trained batch 167 in epoch 6, gen_loss = 1.1464797639775843, disc_loss = 0.050266255131213085
Trained batch 168 in epoch 6, gen_loss = 1.1498253005143453, disc_loss = 0.050175349382386054
Trained batch 169 in epoch 6, gen_loss = 1.147059536506148, disc_loss = 0.05043064618264051
Trained batch 170 in epoch 6, gen_loss = 1.1500649408638826, disc_loss = 0.05028087878327447
Trained batch 171 in epoch 6, gen_loss = 1.151606298983097, disc_loss = 0.05006890754258737
Trained batch 172 in epoch 6, gen_loss = 1.1496730138456202, disc_loss = 0.05010135404528738
Trained batch 173 in epoch 6, gen_loss = 1.151417307298759, disc_loss = 0.05005070455265285
Trained batch 174 in epoch 6, gen_loss = 1.1496689338343484, disc_loss = 0.05012442818177598
Trained batch 175 in epoch 6, gen_loss = 1.1522273792123252, disc_loss = 0.04996646741214632
Trained batch 176 in epoch 6, gen_loss = 1.1503346668461623, disc_loss = 0.04995817720027125
Trained batch 177 in epoch 6, gen_loss = 1.150778647386626, disc_loss = 0.049861846528319494
Trained batch 178 in epoch 6, gen_loss = 1.1505455106663305, disc_loss = 0.04977252381702875
Trained batch 179 in epoch 6, gen_loss = 1.1501479064424833, disc_loss = 0.04959181862262388
Trained batch 180 in epoch 6, gen_loss = 1.1492407102940492, disc_loss = 0.04957023957095917
Trained batch 181 in epoch 6, gen_loss = 1.1499871085960787, disc_loss = 0.04939333401149609
Trained batch 182 in epoch 6, gen_loss = 1.1526532503750806, disc_loss = 0.04941248126796197
Trained batch 183 in epoch 6, gen_loss = 1.150340705624093, disc_loss = 0.049610662542324026
Trained batch 184 in epoch 6, gen_loss = 1.1508137433915524, disc_loss = 0.049452765572916814
Trained batch 185 in epoch 6, gen_loss = 1.153077835838, disc_loss = 0.0492860639357679
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 1.0028696060180664, disc_loss = 0.026224886998534203
Trained batch 1 in epoch 7, gen_loss = 1.1944694519042969, disc_loss = 0.023189688101410866
Trained batch 2 in epoch 7, gen_loss = 1.1111476023991902, disc_loss = 0.024192492788036663
Trained batch 3 in epoch 7, gen_loss = 1.1376665234565735, disc_loss = 0.021974360570311546
Trained batch 4 in epoch 7, gen_loss = 1.193743896484375, disc_loss = 0.019394236244261266
Trained batch 5 in epoch 7, gen_loss = 1.2201008001963298, disc_loss = 0.01852684887126088
Trained batch 6 in epoch 7, gen_loss = 1.1895811898367745, disc_loss = 0.020026833218123232
Trained batch 7 in epoch 7, gen_loss = 1.2215465307235718, disc_loss = 0.018421643355395645
Trained batch 8 in epoch 7, gen_loss = 1.2538586325115628, disc_loss = 0.01792592705330915
Trained batch 9 in epoch 7, gen_loss = 1.3020890831947327, disc_loss = 0.01841952376998961
Trained batch 10 in epoch 7, gen_loss = 1.2854305614124646, disc_loss = 0.019766219849274916
Trained batch 11 in epoch 7, gen_loss = 1.2811120748519897, disc_loss = 0.01905092189554125
Trained batch 12 in epoch 7, gen_loss = 1.263405130459712, disc_loss = 0.020082526446248476
Trained batch 13 in epoch 7, gen_loss = 1.2667719636644637, disc_loss = 0.021485799358093312
Trained batch 14 in epoch 7, gen_loss = 1.2576643069585165, disc_loss = 0.02109413311506311
Trained batch 15 in epoch 7, gen_loss = 1.260015219449997, disc_loss = 0.020366075885249302
Trained batch 16 in epoch 7, gen_loss = 1.262585906421437, disc_loss = 0.019796967040747404
Trained batch 17 in epoch 7, gen_loss = 1.2708344989352756, disc_loss = 0.01935879780083067
Trained batch 18 in epoch 7, gen_loss = 1.2905395532909192, disc_loss = 0.01973129159427787
Trained batch 19 in epoch 7, gen_loss = 1.293051391839981, disc_loss = 0.019065454904921352
Trained batch 20 in epoch 7, gen_loss = 1.2766505706877935, disc_loss = 0.01976673528995542
Trained batch 21 in epoch 7, gen_loss = 1.2692842212590305, disc_loss = 0.019493164473467252
Trained batch 22 in epoch 7, gen_loss = 1.3268819425417029, disc_loss = 0.026339622113205816
Trained batch 23 in epoch 7, gen_loss = 1.3272700657447178, disc_loss = 0.025783058857390035
Trained batch 24 in epoch 7, gen_loss = 1.3083874845504762, disc_loss = 0.027589002829045056
Trained batch 25 in epoch 7, gen_loss = 1.3191824968044574, disc_loss = 0.027314407374853127
Trained batch 26 in epoch 7, gen_loss = 1.3304285296687373, disc_loss = 0.027386815511380082
Trained batch 27 in epoch 7, gen_loss = 1.3159629149096352, disc_loss = 0.027807947830297053
Trained batch 28 in epoch 7, gen_loss = 1.3132060930646698, disc_loss = 0.027114312694375885
Trained batch 29 in epoch 7, gen_loss = 1.330637236436208, disc_loss = 0.027750369145845374
Trained batch 30 in epoch 7, gen_loss = 1.3258851766586304, disc_loss = 0.027424939442425966
Trained batch 31 in epoch 7, gen_loss = 1.3130529783666134, disc_loss = 0.027796334223239683
Trained batch 32 in epoch 7, gen_loss = 1.3131877472906401, disc_loss = 0.02752073062583804
Trained batch 33 in epoch 7, gen_loss = 1.3146259293836706, disc_loss = 0.026986869914895472
Trained batch 34 in epoch 7, gen_loss = 1.3218488182340349, disc_loss = 0.026851249472903353
Trained batch 35 in epoch 7, gen_loss = 1.3144096699025896, disc_loss = 0.026877759425486956
Trained batch 36 in epoch 7, gen_loss = 1.3109076796351253, disc_loss = 0.02646708326112177
Trained batch 37 in epoch 7, gen_loss = 1.3132149828107733, disc_loss = 0.026352282895363476
Trained batch 38 in epoch 7, gen_loss = 1.3110397840157533, disc_loss = 0.02604883540278444
Trained batch 39 in epoch 7, gen_loss = 1.3107044458389283, disc_loss = 0.025707132590468973
Trained batch 40 in epoch 7, gen_loss = 1.3080357022401763, disc_loss = 0.025715447133179845
Trained batch 41 in epoch 7, gen_loss = 1.3105481096676417, disc_loss = 0.027429056564523352
Trained batch 42 in epoch 7, gen_loss = 1.3159123243287552, disc_loss = 0.031728996689496344
Trained batch 43 in epoch 7, gen_loss = 1.3275839578021655, disc_loss = 0.03420601707925512
Trained batch 44 in epoch 7, gen_loss = 1.3279183202319675, disc_loss = 0.03434784850105643
Trained batch 45 in epoch 7, gen_loss = 1.319517247054888, disc_loss = 0.034873475189037294
Trained batch 46 in epoch 7, gen_loss = 1.3164171969636957, disc_loss = 0.034893998271845125
Trained batch 47 in epoch 7, gen_loss = 1.3122172852357228, disc_loss = 0.034558026265585795
Trained batch 48 in epoch 7, gen_loss = 1.3129423686436243, disc_loss = 0.034914770895349126
Trained batch 49 in epoch 7, gen_loss = 1.3019098162651062, disc_loss = 0.03586511029861868
Trained batch 50 in epoch 7, gen_loss = 1.2984632534139298, disc_loss = 0.03614834402961766
Trained batch 51 in epoch 7, gen_loss = 1.2958102845228636, disc_loss = 0.03593919371577123
Trained batch 52 in epoch 7, gen_loss = 1.2935093078973159, disc_loss = 0.03554441944151273
Trained batch 53 in epoch 7, gen_loss = 1.289072659280565, disc_loss = 0.03525009788400321
Trained batch 54 in epoch 7, gen_loss = 1.2890112811868841, disc_loss = 0.03477664738046852
Trained batch 55 in epoch 7, gen_loss = 1.2918901635067803, disc_loss = 0.034557002155841995
Trained batch 56 in epoch 7, gen_loss = 1.2834650361747073, disc_loss = 0.03503753972778979
Trained batch 57 in epoch 7, gen_loss = 1.2873609045456196, disc_loss = 0.03487476085890727
Trained batch 58 in epoch 7, gen_loss = 1.2884996563701305, disc_loss = 0.034542950178038774
Trained batch 59 in epoch 7, gen_loss = 1.292758764823278, disc_loss = 0.034255762173173325
Trained batch 60 in epoch 7, gen_loss = 1.287886070423439, disc_loss = 0.034154260645574724
Trained batch 61 in epoch 7, gen_loss = 1.2843108369458107, disc_loss = 0.03383619058126163
Trained batch 62 in epoch 7, gen_loss = 1.2827506330278184, disc_loss = 0.033518471703347236
Trained batch 63 in epoch 7, gen_loss = 1.2822669800370932, disc_loss = 0.03364179870550288
Trained batch 64 in epoch 7, gen_loss = 1.2745633758031405, disc_loss = 0.03412669374822424
Trained batch 65 in epoch 7, gen_loss = 1.2698348435488613, disc_loss = 0.033970065407850074
Trained batch 66 in epoch 7, gen_loss = 1.2723598177753277, disc_loss = 0.03372856098185502
Trained batch 67 in epoch 7, gen_loss = 1.2699198372223799, disc_loss = 0.03353343089795945
Trained batch 68 in epoch 7, gen_loss = 1.273332118988037, disc_loss = 0.033951432774842215
Trained batch 69 in epoch 7, gen_loss = 1.2699456027575902, disc_loss = 0.033824685688263606
Trained batch 70 in epoch 7, gen_loss = 1.2695927687094246, disc_loss = 0.03344932367080744
Trained batch 71 in epoch 7, gen_loss = 1.2652578685018752, disc_loss = 0.033466337824292064
Trained batch 72 in epoch 7, gen_loss = 1.2675410721400013, disc_loss = 0.03321869854419811
Trained batch 73 in epoch 7, gen_loss = 1.266737251668363, disc_loss = 0.03287688770482468
Trained batch 74 in epoch 7, gen_loss = 1.266241070429484, disc_loss = 0.032525955016414324
Trained batch 75 in epoch 7, gen_loss = 1.2639584384466473, disc_loss = 0.032358003559669384
Trained batch 76 in epoch 7, gen_loss = 1.2627733032424728, disc_loss = 0.032316136282759825
Trained batch 77 in epoch 7, gen_loss = 1.2612965764143529, disc_loss = 0.03205842516408899
Trained batch 78 in epoch 7, gen_loss = 1.256833142872098, disc_loss = 0.03206986878538811
Trained batch 79 in epoch 7, gen_loss = 1.2582190692424775, disc_loss = 0.031873717776034025
Trained batch 80 in epoch 7, gen_loss = 1.2567951193562261, disc_loss = 0.031787262988035324
Trained batch 81 in epoch 7, gen_loss = 1.2561155252340364, disc_loss = 0.03149986621446726
Trained batch 82 in epoch 7, gen_loss = 1.2577144166073166, disc_loss = 0.03173240462699568
Trained batch 83 in epoch 7, gen_loss = 1.2503892651626043, disc_loss = 0.032696288877299855
Trained batch 84 in epoch 7, gen_loss = 1.250630929890801, disc_loss = 0.032516832474400015
Trained batch 85 in epoch 7, gen_loss = 1.2521406204201455, disc_loss = 0.03235311139115067
Trained batch 86 in epoch 7, gen_loss = 1.2526788149756947, disc_loss = 0.03230540818352809
Trained batch 87 in epoch 7, gen_loss = 1.2464259747754445, disc_loss = 0.03297647981989113
Trained batch 88 in epoch 7, gen_loss = 1.24563891365287, disc_loss = 0.03423248813225982
Trained batch 89 in epoch 7, gen_loss = 1.2411027736134, disc_loss = 0.034423856313029924
Trained batch 90 in epoch 7, gen_loss = 1.2379501298233704, disc_loss = 0.034410489129496145
Trained batch 91 in epoch 7, gen_loss = 1.2390300929546356, disc_loss = 0.03496885242993417
Trained batch 92 in epoch 7, gen_loss = 1.2350688217788615, disc_loss = 0.03512847952304348
Trained batch 93 in epoch 7, gen_loss = 1.2308244762268472, disc_loss = 0.03529227834115637
Trained batch 94 in epoch 7, gen_loss = 1.2344581334214462, disc_loss = 0.03633187060293398
Trained batch 95 in epoch 7, gen_loss = 1.233974291011691, disc_loss = 0.036204192127722
Trained batch 96 in epoch 7, gen_loss = 1.2312930963703037, disc_loss = 0.03608117936198244
Trained batch 97 in epoch 7, gen_loss = 1.2266994562684272, disc_loss = 0.03641357592173985
Trained batch 98 in epoch 7, gen_loss = 1.227141509754489, disc_loss = 0.03699955976370609
Trained batch 99 in epoch 7, gen_loss = 1.229848706126213, disc_loss = 0.03681095914915204
Trained batch 100 in epoch 7, gen_loss = 1.229803677242581, disc_loss = 0.036555217173282466
Trained batch 101 in epoch 7, gen_loss = 1.2280782654004938, disc_loss = 0.0364084979519248
Trained batch 102 in epoch 7, gen_loss = 1.2270462588199134, disc_loss = 0.03614257917133639
Trained batch 103 in epoch 7, gen_loss = 1.2273197431976979, disc_loss = 0.03640962303437006
Trained batch 104 in epoch 7, gen_loss = 1.2248534753209068, disc_loss = 0.036277893229964234
Trained batch 105 in epoch 7, gen_loss = 1.2250154991194886, disc_loss = 0.036027546031927725
Trained batch 106 in epoch 7, gen_loss = 1.2237960183731864, disc_loss = 0.035838141663121846
Trained batch 107 in epoch 7, gen_loss = 1.2251187391855098, disc_loss = 0.03596584958507231
Trained batch 108 in epoch 7, gen_loss = 1.2277398814848803, disc_loss = 0.03577534228973432
Trained batch 109 in epoch 7, gen_loss = 1.228217628327283, disc_loss = 0.035595312240448866
Trained batch 110 in epoch 7, gen_loss = 1.2256746834462828, disc_loss = 0.035672250732376766
Trained batch 111 in epoch 7, gen_loss = 1.2272344790399075, disc_loss = 0.035508628169606836
Trained batch 112 in epoch 7, gen_loss = 1.231235320061709, disc_loss = 0.03566434606909752
Trained batch 113 in epoch 7, gen_loss = 1.225789336258905, disc_loss = 0.03645254197742855
Trained batch 114 in epoch 7, gen_loss = 1.2275291012681049, disc_loss = 0.036870781850555666
Trained batch 115 in epoch 7, gen_loss = 1.2223197555747525, disc_loss = 0.03751035108520039
Trained batch 116 in epoch 7, gen_loss = 1.222331196324438, disc_loss = 0.03727871199480744
Trained batch 117 in epoch 7, gen_loss = 1.2232109303191556, disc_loss = 0.03720710174796187
Trained batch 118 in epoch 7, gen_loss = 1.2217619754687077, disc_loss = 0.037116104948232656
Trained batch 119 in epoch 7, gen_loss = 1.2193348690867425, disc_loss = 0.03718433380903055
Trained batch 120 in epoch 7, gen_loss = 1.2195775139430338, disc_loss = 0.0371588374726659
Trained batch 121 in epoch 7, gen_loss = 1.2201388258425916, disc_loss = 0.036900274753265204
Trained batch 122 in epoch 7, gen_loss = 1.2199454428703804, disc_loss = 0.036694465212645085
Trained batch 123 in epoch 7, gen_loss = 1.2174978289873368, disc_loss = 0.03664881822412774
Trained batch 124 in epoch 7, gen_loss = 1.2170589833259582, disc_loss = 0.03703756465762854
Trained batch 125 in epoch 7, gen_loss = 1.2149137584936052, disc_loss = 0.0370672683024572
Trained batch 126 in epoch 7, gen_loss = 1.2170495165614632, disc_loss = 0.03726654252638732
Trained batch 127 in epoch 7, gen_loss = 1.2120554270222783, disc_loss = 0.03814024925668491
Trained batch 128 in epoch 7, gen_loss = 1.2198116991871086, disc_loss = 0.03980306119390929
Trained batch 129 in epoch 7, gen_loss = 1.216008964410195, disc_loss = 0.04008217751263426
Trained batch 130 in epoch 7, gen_loss = 1.2129350996199455, disc_loss = 0.04047121027242819
Trained batch 131 in epoch 7, gen_loss = 1.2138207459991628, disc_loss = 0.04107476679862223
Trained batch 132 in epoch 7, gen_loss = 1.2117521453620796, disc_loss = 0.04116952104872107
Trained batch 133 in epoch 7, gen_loss = 1.2071428846067458, disc_loss = 0.04183676960502765
Trained batch 134 in epoch 7, gen_loss = 1.2083224716009917, disc_loss = 0.042958210567357366
Trained batch 135 in epoch 7, gen_loss = 1.2052683602361118, disc_loss = 0.04320199786931934
Trained batch 136 in epoch 7, gen_loss = 1.2039380639138884, disc_loss = 0.04327575236314187
Trained batch 137 in epoch 7, gen_loss = 1.2035320988599805, disc_loss = 0.04326006677676586
Trained batch 138 in epoch 7, gen_loss = 1.2015942399450343, disc_loss = 0.043242179279436736
Trained batch 139 in epoch 7, gen_loss = 1.1996480656521662, disc_loss = 0.04337391661080931
Trained batch 140 in epoch 7, gen_loss = 1.1986124037850834, disc_loss = 0.04318493504922652
Trained batch 141 in epoch 7, gen_loss = 1.1973596555246433, disc_loss = 0.04350837661792904
Trained batch 142 in epoch 7, gen_loss = 1.1964537576361969, disc_loss = 0.04335538406654463
Trained batch 143 in epoch 7, gen_loss = 1.1948458308147059, disc_loss = 0.043327229246238455
Trained batch 144 in epoch 7, gen_loss = 1.1980285681527236, disc_loss = 0.04323780291938576
Trained batch 145 in epoch 7, gen_loss = 1.1965676407291466, disc_loss = 0.0432159831964296
Trained batch 146 in epoch 7, gen_loss = 1.1964165758924419, disc_loss = 0.04346783739850432
Trained batch 147 in epoch 7, gen_loss = 1.1954665022927362, disc_loss = 0.04332443490951649
Trained batch 148 in epoch 7, gen_loss = 1.1927541774391328, disc_loss = 0.04342082370972673
Trained batch 149 in epoch 7, gen_loss = 1.193372053305308, disc_loss = 0.043303060575077934
Trained batch 150 in epoch 7, gen_loss = 1.1942451339683786, disc_loss = 0.043089154879531716
Trained batch 151 in epoch 7, gen_loss = 1.1919666658106602, disc_loss = 0.04309655634661842
Trained batch 152 in epoch 7, gen_loss = 1.1957966584006166, disc_loss = 0.043137775545367615
Trained batch 153 in epoch 7, gen_loss = 1.1955020818617437, disc_loss = 0.042958903979123025
Trained batch 154 in epoch 7, gen_loss = 1.1948011217578764, disc_loss = 0.04283342819901243
Trained batch 155 in epoch 7, gen_loss = 1.1952289361984303, disc_loss = 0.042633976005256556
Trained batch 156 in epoch 7, gen_loss = 1.1985512694735436, disc_loss = 0.042601840825644645
Trained batch 157 in epoch 7, gen_loss = 1.1967921849293044, disc_loss = 0.042569018081066355
Trained batch 158 in epoch 7, gen_loss = 1.196799803454921, disc_loss = 0.04235685569286909
Trained batch 159 in epoch 7, gen_loss = 1.1973756317049264, disc_loss = 0.042380186886293816
Trained batch 160 in epoch 7, gen_loss = 1.194686932963614, disc_loss = 0.04253729892697949
Trained batch 161 in epoch 7, gen_loss = 1.195894823766049, disc_loss = 0.042344266497012645
Trained batch 162 in epoch 7, gen_loss = 1.1970561161363051, disc_loss = 0.0421407406326909
Trained batch 163 in epoch 7, gen_loss = 1.198165131414809, disc_loss = 0.04202298843301833
Trained batch 164 in epoch 7, gen_loss = 1.1975647843245305, disc_loss = 0.04185768423997092
Trained batch 165 in epoch 7, gen_loss = 1.1954873563295387, disc_loss = 0.04189484464902296
Trained batch 166 in epoch 7, gen_loss = 1.1980911007898296, disc_loss = 0.041804616484501046
Trained batch 167 in epoch 7, gen_loss = 1.1990635586636407, disc_loss = 0.041691016511148996
Trained batch 168 in epoch 7, gen_loss = 1.1976137838420078, disc_loss = 0.04161801729792145
Trained batch 169 in epoch 7, gen_loss = 1.195859002716401, disc_loss = 0.04165528829154723
Trained batch 170 in epoch 7, gen_loss = 1.1982354277755782, disc_loss = 0.041586882434785366
Trained batch 171 in epoch 7, gen_loss = 1.1982348176629045, disc_loss = 0.04140823298718694
Trained batch 172 in epoch 7, gen_loss = 1.1984543307668212, disc_loss = 0.041231319389031455
Trained batch 173 in epoch 7, gen_loss = 1.2026944074822568, disc_loss = 0.041234252198288836
Trained batch 174 in epoch 7, gen_loss = 1.206550189767565, disc_loss = 0.04140094477683306
Trained batch 175 in epoch 7, gen_loss = 1.2054465030404655, disc_loss = 0.04138539009198377
Trained batch 176 in epoch 7, gen_loss = 1.2058685738488106, disc_loss = 0.04127530002766578
Trained batch 177 in epoch 7, gen_loss = 1.2061648238241003, disc_loss = 0.041178333285275134
Trained batch 178 in epoch 7, gen_loss = 1.206696567921665, disc_loss = 0.041064183487863844
Trained batch 179 in epoch 7, gen_loss = 1.2063140249914592, disc_loss = 0.040954796426619096
Trained batch 180 in epoch 7, gen_loss = 1.2060220323873487, disc_loss = 0.04081980282574563
Trained batch 181 in epoch 7, gen_loss = 1.2046961614063807, disc_loss = 0.040814910242641035
Trained batch 182 in epoch 7, gen_loss = 1.2053410570478178, disc_loss = 0.040628977903658575
Trained batch 183 in epoch 7, gen_loss = 1.205875709005024, disc_loss = 0.040548068430760635
Trained batch 184 in epoch 7, gen_loss = 1.2040298835651295, disc_loss = 0.04054754815391592
Trained batch 185 in epoch 7, gen_loss = 1.2041197835758168, disc_loss = 0.0403666696511209
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 1.1942130327224731, disc_loss = 0.020030681043863297
Trained batch 1 in epoch 8, gen_loss = 1.2381274700164795, disc_loss = 0.012977791484445333
Trained batch 2 in epoch 8, gen_loss = 1.2797284921010335, disc_loss = 0.010667557207246622
Trained batch 3 in epoch 8, gen_loss = 1.2094585299491882, disc_loss = 0.014089025789871812
Trained batch 4 in epoch 8, gen_loss = 1.3500416994094848, disc_loss = 0.024176579900085926
Trained batch 5 in epoch 8, gen_loss = 1.2962454160054524, disc_loss = 0.024745747602234285
Trained batch 6 in epoch 8, gen_loss = 1.2956063747406006, disc_loss = 0.022434046225888387
Trained batch 7 in epoch 8, gen_loss = 1.2966792285442352, disc_loss = 0.020460151717998087
Trained batch 8 in epoch 8, gen_loss = 1.3257323503494263, disc_loss = 0.019911776296794415
Trained batch 9 in epoch 8, gen_loss = 1.3230762839317323, disc_loss = 0.01864669960923493
Trained batch 10 in epoch 8, gen_loss = 1.2857899774204602, disc_loss = 0.019926086110486227
Trained batch 11 in epoch 8, gen_loss = 1.3207171261310577, disc_loss = 0.021154829339745145
Trained batch 12 in epoch 8, gen_loss = 1.309877450649555, disc_loss = 0.020427041579611026
Trained batch 13 in epoch 8, gen_loss = 1.2866509556770325, disc_loss = 0.02265244160246636
Trained batch 14 in epoch 8, gen_loss = 1.2905109167098998, disc_loss = 0.02179017330830296
Trained batch 15 in epoch 8, gen_loss = 1.2672645561397076, disc_loss = 0.022453225596109405
Trained batch 16 in epoch 8, gen_loss = 1.274114759529338, disc_loss = 0.024108262760016846
Trained batch 17 in epoch 8, gen_loss = 1.2574780186017354, disc_loss = 0.02433493342767987
Trained batch 18 in epoch 8, gen_loss = 1.2521573179646541, disc_loss = 0.02571450764509408
Trained batch 19 in epoch 8, gen_loss = 1.2219618201255797, disc_loss = 0.030416995682753623
Trained batch 20 in epoch 8, gen_loss = 1.2338525510969616, disc_loss = 0.02977171347343496
Trained batch 21 in epoch 8, gen_loss = 1.2471755038608203, disc_loss = 0.033997696422209796
Trained batch 22 in epoch 8, gen_loss = 1.2275626788968625, disc_loss = 0.03516906744841
Trained batch 23 in epoch 8, gen_loss = 1.211777778963248, disc_loss = 0.03631715338754778
Trained batch 24 in epoch 8, gen_loss = 1.2198186326026916, disc_loss = 0.040007619131356476
Trained batch 25 in epoch 8, gen_loss = 1.1993114696099207, disc_loss = 0.04224421759136021
Trained batch 26 in epoch 8, gen_loss = 1.191396571971752, disc_loss = 0.0419731889506457
Trained batch 27 in epoch 8, gen_loss = 1.1969836609704154, disc_loss = 0.04912847588171384
Trained batch 28 in epoch 8, gen_loss = 1.1755782283585647, disc_loss = 0.05279752652257167
Trained batch 29 in epoch 8, gen_loss = 1.1706948479016621, disc_loss = 0.05244005559943617
Trained batch 30 in epoch 8, gen_loss = 1.1790346061029742, disc_loss = 0.05394613419869734
Trained batch 31 in epoch 8, gen_loss = 1.162435533478856, disc_loss = 0.057857276071445085
Trained batch 32 in epoch 8, gen_loss = 1.158412566690734, disc_loss = 0.06031111888869694
Trained batch 33 in epoch 8, gen_loss = 1.1641257563058067, disc_loss = 0.06238085701239898
Trained batch 34 in epoch 8, gen_loss = 1.1619509645870754, disc_loss = 0.06258983432448335
Trained batch 35 in epoch 8, gen_loss = 1.1553597450256348, disc_loss = 0.06239911573680325
Trained batch 36 in epoch 8, gen_loss = 1.1531299578176963, disc_loss = 0.06146358659591626
Trained batch 37 in epoch 8, gen_loss = 1.1522143389049329, disc_loss = 0.06124571868904719
Trained batch 38 in epoch 8, gen_loss = 1.1482167549622364, disc_loss = 0.06123512592883064
Trained batch 39 in epoch 8, gen_loss = 1.139863336086273, disc_loss = 0.06091292715864256
Trained batch 40 in epoch 8, gen_loss = 1.1436726436382387, disc_loss = 0.06119337306562357
Trained batch 41 in epoch 8, gen_loss = 1.1369889946210952, disc_loss = 0.06106245279356483
Trained batch 42 in epoch 8, gen_loss = 1.1318216309990994, disc_loss = 0.060599071266086296
Trained batch 43 in epoch 8, gen_loss = 1.1386478746479207, disc_loss = 0.06013053275687112
Trained batch 44 in epoch 8, gen_loss = 1.1355534103181628, disc_loss = 0.059295310007615225
Trained batch 45 in epoch 8, gen_loss = 1.1269004306067592, disc_loss = 0.05950096420660291
Trained batch 46 in epoch 8, gen_loss = 1.1327846468763147, disc_loss = 0.060341496981601135
Trained batch 47 in epoch 8, gen_loss = 1.1338145198921363, disc_loss = 0.059457060968270525
Trained batch 48 in epoch 8, gen_loss = 1.1290213891438075, disc_loss = 0.05901438865468514
Trained batch 49 in epoch 8, gen_loss = 1.1289980101585388, disc_loss = 0.05850799159146845
Trained batch 50 in epoch 8, gen_loss = 1.1262500999020595, disc_loss = 0.0579343020422932
Trained batch 51 in epoch 8, gen_loss = 1.1311601984959383, disc_loss = 0.05708296237907444
Trained batch 52 in epoch 8, gen_loss = 1.1331155063971035, disc_loss = 0.0562871495209072
Trained batch 53 in epoch 8, gen_loss = 1.1296079401616697, disc_loss = 0.05592979962454626
Trained batch 54 in epoch 8, gen_loss = 1.1321454416621815, disc_loss = 0.05582723742012273
Trained batch 55 in epoch 8, gen_loss = 1.1347637517111642, disc_loss = 0.055020443471481224
Trained batch 56 in epoch 8, gen_loss = 1.1367823303791516, disc_loss = 0.05432866841325896
Trained batch 57 in epoch 8, gen_loss = 1.1381617332326954, disc_loss = 0.0537300202112388
Trained batch 58 in epoch 8, gen_loss = 1.1395819793313235, disc_loss = 0.05300421135942057
Trained batch 59 in epoch 8, gen_loss = 1.149995344877243, disc_loss = 0.052854707658601306
Trained batch 60 in epoch 8, gen_loss = 1.1454230683748838, disc_loss = 0.052659200970083475
Trained batch 61 in epoch 8, gen_loss = 1.1497195132317082, disc_loss = 0.052368412823266076
Trained batch 62 in epoch 8, gen_loss = 1.1608314268172732, disc_loss = 0.05209652654501417
Trained batch 63 in epoch 8, gen_loss = 1.1709936894476414, disc_loss = 0.05252003006899031
Trained batch 64 in epoch 8, gen_loss = 1.1661972568585321, disc_loss = 0.052611387585504696
Trained batch 65 in epoch 8, gen_loss = 1.1649758878982428, disc_loss = 0.05213411872726724
Trained batch 66 in epoch 8, gen_loss = 1.1654727948245718, disc_loss = 0.05157972371150086
Trained batch 67 in epoch 8, gen_loss = 1.1663302595124525, disc_loss = 0.05113834048867883
Trained batch 68 in epoch 8, gen_loss = 1.174521559390469, disc_loss = 0.05080662761558441
Trained batch 69 in epoch 8, gen_loss = 1.1719274716717856, disc_loss = 0.0506463470403105
Trained batch 70 in epoch 8, gen_loss = 1.1763844061905229, disc_loss = 0.050095428430645815
Trained batch 71 in epoch 8, gen_loss = 1.1716123405430052, disc_loss = 0.050047462980728596
Trained batch 72 in epoch 8, gen_loss = 1.1748960573379308, disc_loss = 0.04964654124022959
Trained batch 73 in epoch 8, gen_loss = 1.1731768991496112, disc_loss = 0.0491994563678934
Trained batch 74 in epoch 8, gen_loss = 1.1855717039108276, disc_loss = 0.04949147121980786
Trained batch 75 in epoch 8, gen_loss = 1.1803280499420667, disc_loss = 0.049774489481933415
Trained batch 76 in epoch 8, gen_loss = 1.1772832584071469, disc_loss = 0.049603758760812605
Trained batch 77 in epoch 8, gen_loss = 1.181724107418305, disc_loss = 0.05010183802089439
Trained batch 78 in epoch 8, gen_loss = 1.1811173407337334, disc_loss = 0.049608039604853604
Trained batch 79 in epoch 8, gen_loss = 1.1748671606183052, disc_loss = 0.05006118798046373
Trained batch 80 in epoch 8, gen_loss = 1.1818930881994743, disc_loss = 0.05110005343930773
Trained batch 81 in epoch 8, gen_loss = 1.1766411313196508, disc_loss = 0.05128686620126956
Trained batch 82 in epoch 8, gen_loss = 1.1800600864801063, disc_loss = 0.05111298390877354
Trained batch 83 in epoch 8, gen_loss = 1.178462028503418, disc_loss = 0.050724796302217455
Trained batch 84 in epoch 8, gen_loss = 1.1767347504110897, disc_loss = 0.05047582652529373
Trained batch 85 in epoch 8, gen_loss = 1.1749628283256708, disc_loss = 0.05049610685362199
Trained batch 86 in epoch 8, gen_loss = 1.1727930307388306, disc_loss = 0.050268653839098655
Trained batch 87 in epoch 8, gen_loss = 1.170084187252955, disc_loss = 0.05003233094678514
Trained batch 88 in epoch 8, gen_loss = 1.175347198931019, disc_loss = 0.050133102327543366
Trained batch 89 in epoch 8, gen_loss = 1.175404190354877, disc_loss = 0.04968155857899951
Trained batch 90 in epoch 8, gen_loss = 1.1715251482450044, disc_loss = 0.049681628056402714
Trained batch 91 in epoch 8, gen_loss = 1.1716742139795553, disc_loss = 0.049283571121201894
Trained batch 92 in epoch 8, gen_loss = 1.1731850818921161, disc_loss = 0.05000621271169474
Trained batch 93 in epoch 8, gen_loss = 1.1686381735700242, disc_loss = 0.05014914827560015
Trained batch 94 in epoch 8, gen_loss = 1.1685353429693925, disc_loss = 0.04973146365955472
Trained batch 95 in epoch 8, gen_loss = 1.1685274144013722, disc_loss = 0.04935474927090885
Trained batch 96 in epoch 8, gen_loss = 1.1705780692936218, disc_loss = 0.04893168396575703
Trained batch 97 in epoch 8, gen_loss = 1.1705378537275353, disc_loss = 0.04883206084997831
Trained batch 98 in epoch 8, gen_loss = 1.1689991120136145, disc_loss = 0.04860180466332369
Trained batch 99 in epoch 8, gen_loss = 1.1678273606300353, disc_loss = 0.0486630053864792
Trained batch 100 in epoch 8, gen_loss = 1.1668088931848508, disc_loss = 0.048361968733185885
Trained batch 101 in epoch 8, gen_loss = 1.1690116326014202, disc_loss = 0.04831224457616461
Trained batch 102 in epoch 8, gen_loss = 1.166802857686015, disc_loss = 0.048111262509725916
Trained batch 103 in epoch 8, gen_loss = 1.167101305264693, disc_loss = 0.047720051455633856
Trained batch 104 in epoch 8, gen_loss = 1.16871528057825, disc_loss = 0.04731975242584234
Trained batch 105 in epoch 8, gen_loss = 1.1687265375875078, disc_loss = 0.04695094973815359
Trained batch 106 in epoch 8, gen_loss = 1.1739281516208826, disc_loss = 0.046767730853372366
Trained batch 107 in epoch 8, gen_loss = 1.173309083338137, disc_loss = 0.04652513030278324
Trained batch 108 in epoch 8, gen_loss = 1.173274865937889, disc_loss = 0.04618196699067677
Trained batch 109 in epoch 8, gen_loss = 1.1758520483970643, disc_loss = 0.04606073803945698
Trained batch 110 in epoch 8, gen_loss = 1.1740242312620353, disc_loss = 0.04586242738825915
Trained batch 111 in epoch 8, gen_loss = 1.1722407516624247, disc_loss = 0.04568843272863887
Trained batch 112 in epoch 8, gen_loss = 1.1747680833909364, disc_loss = 0.04546728394348669
Trained batch 113 in epoch 8, gen_loss = 1.1745089015416932, disc_loss = 0.0452895290667616
Trained batch 114 in epoch 8, gen_loss = 1.1755008733790853, disc_loss = 0.04498750825372079
Trained batch 115 in epoch 8, gen_loss = 1.1748411979140907, disc_loss = 0.044708510535640705
Trained batch 116 in epoch 8, gen_loss = 1.1759459824643583, disc_loss = 0.0443932631960473
Trained batch 117 in epoch 8, gen_loss = 1.180724099025888, disc_loss = 0.04432573540025722
Trained batch 118 in epoch 8, gen_loss = 1.1780740202975875, disc_loss = 0.04438211873345891
Trained batch 119 in epoch 8, gen_loss = 1.1782572537660598, disc_loss = 0.044124140105365466
Trained batch 120 in epoch 8, gen_loss = 1.1787922175462582, disc_loss = 0.04383590915586707
Trained batch 121 in epoch 8, gen_loss = 1.1823801642558613, disc_loss = 0.043607675390256964
Trained batch 122 in epoch 8, gen_loss = 1.1839066811693393, disc_loss = 0.043326910195221016
Trained batch 123 in epoch 8, gen_loss = 1.1791710646883133, disc_loss = 0.044045067846684924
Trained batch 124 in epoch 8, gen_loss = 1.1839676623344422, disc_loss = 0.0442948510684073
Trained batch 125 in epoch 8, gen_loss = 1.1834757096237607, disc_loss = 0.04406027553883928
Trained batch 126 in epoch 8, gen_loss = 1.1815021399437913, disc_loss = 0.044005811819440036
Trained batch 127 in epoch 8, gen_loss = 1.183405205141753, disc_loss = 0.04411930033893441
Trained batch 128 in epoch 8, gen_loss = 1.1832481396290684, disc_loss = 0.04385878386466887
Trained batch 129 in epoch 8, gen_loss = 1.183099354688938, disc_loss = 0.043703123422053
Trained batch 130 in epoch 8, gen_loss = 1.184159747971833, disc_loss = 0.043422934837383395
Trained batch 131 in epoch 8, gen_loss = 1.1845551237012402, disc_loss = 0.04332616211578363
Trained batch 132 in epoch 8, gen_loss = 1.1818595214893943, disc_loss = 0.043421556714474036
Trained batch 133 in epoch 8, gen_loss = 1.1833212362296546, disc_loss = 0.044886894722177245
Trained batch 134 in epoch 8, gen_loss = 1.1794731087154813, disc_loss = 0.04527200485614163
Trained batch 135 in epoch 8, gen_loss = 1.180092553005499, disc_loss = 0.046048670051865935
Trained batch 136 in epoch 8, gen_loss = 1.1758342968286388, disc_loss = 0.0466758686348959
Trained batch 137 in epoch 8, gen_loss = 1.1742352942625682, disc_loss = 0.04683157621100005
Trained batch 138 in epoch 8, gen_loss = 1.176474623114085, disc_loss = 0.04719000060794701
Trained batch 139 in epoch 8, gen_loss = 1.1733183464833667, disc_loss = 0.04762981866952032
Trained batch 140 in epoch 8, gen_loss = 1.173720881025842, disc_loss = 0.04753351003156169
Trained batch 141 in epoch 8, gen_loss = 1.173676355204112, disc_loss = 0.0474324324266644
Trained batch 142 in epoch 8, gen_loss = 1.1733283067083025, disc_loss = 0.04729916812148648
Trained batch 143 in epoch 8, gen_loss = 1.171695262607601, disc_loss = 0.047211141975518935
Trained batch 144 in epoch 8, gen_loss = 1.1736232161521911, disc_loss = 0.04704225625007831
Trained batch 145 in epoch 8, gen_loss = 1.1725566440249142, disc_loss = 0.04690732312235624
Trained batch 146 in epoch 8, gen_loss = 1.1727623083964498, disc_loss = 0.04664156916963101
Trained batch 147 in epoch 8, gen_loss = 1.172603162156569, disc_loss = 0.04642392651215699
Trained batch 148 in epoch 8, gen_loss = 1.1734177382200357, disc_loss = 0.046235957292327344
Trained batch 149 in epoch 8, gen_loss = 1.172572584549586, disc_loss = 0.04611684033336739
Trained batch 150 in epoch 8, gen_loss = 1.17333535445447, disc_loss = 0.04594170187741814
Trained batch 151 in epoch 8, gen_loss = 1.1710661065421606, disc_loss = 0.04591416755360306
Trained batch 152 in epoch 8, gen_loss = 1.1714285919868868, disc_loss = 0.04585809710137303
Trained batch 153 in epoch 8, gen_loss = 1.1695425475572612, disc_loss = 0.04584579350269557
Trained batch 154 in epoch 8, gen_loss = 1.1709226758249345, disc_loss = 0.04587791176633008
Trained batch 155 in epoch 8, gen_loss = 1.168874082274926, disc_loss = 0.04590563671006702
Trained batch 156 in epoch 8, gen_loss = 1.168804011147493, disc_loss = 0.04578352751874715
Trained batch 157 in epoch 8, gen_loss = 1.170708307359792, disc_loss = 0.04556596234641215
Trained batch 158 in epoch 8, gen_loss = 1.170183154397041, disc_loss = 0.04539869358153932
Trained batch 159 in epoch 8, gen_loss = 1.1681223418563604, disc_loss = 0.045457969934795985
Trained batch 160 in epoch 8, gen_loss = 1.170268042117172, disc_loss = 0.045730089875782684
Trained batch 161 in epoch 8, gen_loss = 1.1708638480416051, disc_loss = 0.04551911546365806
Trained batch 162 in epoch 8, gen_loss = 1.1699125375484396, disc_loss = 0.045385223890489046
Trained batch 163 in epoch 8, gen_loss = 1.168164182000044, disc_loss = 0.04538569726879004
Trained batch 164 in epoch 8, gen_loss = 1.1723715702692667, disc_loss = 0.04567555541624174
Trained batch 165 in epoch 8, gen_loss = 1.1718821626111686, disc_loss = 0.04552232428364097
Trained batch 166 in epoch 8, gen_loss = 1.1718770965130743, disc_loss = 0.04549427510345143
Trained batch 167 in epoch 8, gen_loss = 1.1689367418487866, disc_loss = 0.04587189628398933
Trained batch 168 in epoch 8, gen_loss = 1.170625100827076, disc_loss = 0.04591416804803282
Trained batch 169 in epoch 8, gen_loss = 1.1694330166367923, disc_loss = 0.04594345322043142
Trained batch 170 in epoch 8, gen_loss = 1.169883770552295, disc_loss = 0.0458813362090429
Trained batch 171 in epoch 8, gen_loss = 1.1703182195508204, disc_loss = 0.045784699549183766
Trained batch 172 in epoch 8, gen_loss = 1.16765220110127, disc_loss = 0.04600713170817219
Trained batch 173 in epoch 8, gen_loss = 1.1702404727880982, disc_loss = 0.04587441724832116
Trained batch 174 in epoch 8, gen_loss = 1.1742868287222725, disc_loss = 0.04600747993215919
Trained batch 175 in epoch 8, gen_loss = 1.171997805210677, disc_loss = 0.046278594815786084
Trained batch 176 in epoch 8, gen_loss = 1.1704586131424555, disc_loss = 0.04622633939629978
Trained batch 177 in epoch 8, gen_loss = 1.171600300274538, disc_loss = 0.04641514860899345
Trained batch 178 in epoch 8, gen_loss = 1.1714267051419733, disc_loss = 0.04620452951795978
Trained batch 179 in epoch 8, gen_loss = 1.1694778846369849, disc_loss = 0.04623987641858144
Trained batch 180 in epoch 8, gen_loss = 1.1725833949463143, disc_loss = 0.04630203887007266
Trained batch 181 in epoch 8, gen_loss = 1.1733174114436893, disc_loss = 0.04608390556525562
Trained batch 182 in epoch 8, gen_loss = 1.1721042339267627, disc_loss = 0.04600412046913404
Trained batch 183 in epoch 8, gen_loss = 1.1711045889102893, disc_loss = 0.045896286595329315
Trained batch 184 in epoch 8, gen_loss = 1.1738870591730686, disc_loss = 0.04601998615607217
Trained batch 185 in epoch 8, gen_loss = 1.1734506401323503, disc_loss = 0.04588495916436597
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 1.035066843032837, disc_loss = 0.01838361658155918
Trained batch 1 in epoch 9, gen_loss = 0.928318053483963, disc_loss = 0.038984582759439945
Trained batch 2 in epoch 9, gen_loss = 1.2627175847689311, disc_loss = 0.047572558745741844
Trained batch 3 in epoch 9, gen_loss = 1.2012359946966171, disc_loss = 0.04087486118078232
Trained batch 4 in epoch 9, gen_loss = 1.17101708650589, disc_loss = 0.03638824969530106
Trained batch 5 in epoch 9, gen_loss = 1.1698192457358043, disc_loss = 0.05002486209074656
Trained batch 6 in epoch 9, gen_loss = 1.0849997912134444, disc_loss = 0.06340337863990239
Trained batch 7 in epoch 9, gen_loss = 1.1102840229868889, disc_loss = 0.06206714827567339
Trained batch 8 in epoch 9, gen_loss = 1.0986334681510925, disc_loss = 0.05970203421182103
Trained batch 9 in epoch 9, gen_loss = 1.068253618478775, disc_loss = 0.0590305645018816
Trained batch 10 in epoch 9, gen_loss = 1.1036671562628313, disc_loss = 0.0575502406467091
Trained batch 11 in epoch 9, gen_loss = 1.0975973655780156, disc_loss = 0.055018042835096516
Trained batch 12 in epoch 9, gen_loss = 1.1166547857798064, disc_loss = 0.051254374046738334
Trained batch 13 in epoch 9, gen_loss = 1.0995075447218758, disc_loss = 0.050271328671702316
Trained batch 14 in epoch 9, gen_loss = 1.1252113739649454, disc_loss = 0.04789225763330857
Trained batch 15 in epoch 9, gen_loss = 1.1215570867061615, disc_loss = 0.04583008005283773
Trained batch 16 in epoch 9, gen_loss = 1.1191433107151705, disc_loss = 0.04400294526096653
Trained batch 17 in epoch 9, gen_loss = 1.1383175717459784, disc_loss = 0.04227546902580394
Trained batch 18 in epoch 9, gen_loss = 1.1391289234161377, disc_loss = 0.04136727907155689
Trained batch 19 in epoch 9, gen_loss = 1.1373473048210143, disc_loss = 0.039996398333460095
Trained batch 20 in epoch 9, gen_loss = 1.141748893828619, disc_loss = 0.038539529733714606
Trained batch 21 in epoch 9, gen_loss = 1.1645708084106445, disc_loss = 0.037686776369810104
Trained batch 22 in epoch 9, gen_loss = 1.1575121464936629, disc_loss = 0.03696563815617043
Trained batch 23 in epoch 9, gen_loss = 1.1671787401040394, disc_loss = 0.03571720192364106
Trained batch 24 in epoch 9, gen_loss = 1.1610639476776123, disc_loss = 0.03519792515784502
Trained batch 25 in epoch 9, gen_loss = 1.1780062592946565, disc_loss = 0.035031451091456875
Trained batch 26 in epoch 9, gen_loss = 1.165601823065016, disc_loss = 0.03626372365074025
Trained batch 27 in epoch 9, gen_loss = 1.1823560042040688, disc_loss = 0.03602998414342957
Trained batch 28 in epoch 9, gen_loss = 1.1836656907509113, disc_loss = 0.0351904041358623
Trained batch 29 in epoch 9, gen_loss = 1.1860073725382487, disc_loss = 0.03482892100388805
Trained batch 30 in epoch 9, gen_loss = 1.1822590212668143, disc_loss = 0.03440128083551122
Trained batch 31 in epoch 9, gen_loss = 1.1751650497317314, disc_loss = 0.03523030490032397
Trained batch 32 in epoch 9, gen_loss = 1.1930405587861033, disc_loss = 0.03680630149601987
Trained batch 33 in epoch 9, gen_loss = 1.1964435367023243, disc_loss = 0.03594193403499529
Trained batch 34 in epoch 9, gen_loss = 1.1970378569194249, disc_loss = 0.03518270550827895
Trained batch 35 in epoch 9, gen_loss = 1.195263319545322, disc_loss = 0.03459673125245091
Trained batch 36 in epoch 9, gen_loss = 1.19246904270069, disc_loss = 0.03404510226352392
Trained batch 37 in epoch 9, gen_loss = 1.2024306874526174, disc_loss = 0.03352599266279293
Trained batch 38 in epoch 9, gen_loss = 1.2012335000894008, disc_loss = 0.032905634958297014
Trained batch 39 in epoch 9, gen_loss = 1.19805850982666, disc_loss = 0.032529810664709655
Trained batch 40 in epoch 9, gen_loss = 1.197374387485225, disc_loss = 0.03259409885717238
Trained batch 41 in epoch 9, gen_loss = 1.197370137487139, disc_loss = 0.03297431424393186
Trained batch 42 in epoch 9, gen_loss = 1.184195415918217, disc_loss = 0.034947083732329826
Trained batch 43 in epoch 9, gen_loss = 1.1908634088256143, disc_loss = 0.03506116402885792
Trained batch 44 in epoch 9, gen_loss = 1.1956168121761745, disc_loss = 0.034530855911887356
Trained batch 45 in epoch 9, gen_loss = 1.195017679877903, disc_loss = 0.03401451781594559
Trained batch 46 in epoch 9, gen_loss = 1.2005028420306267, disc_loss = 0.03352865758054751
Trained batch 47 in epoch 9, gen_loss = 1.2000916649897893, disc_loss = 0.03301193410879932
Trained batch 48 in epoch 9, gen_loss = 1.2001895028717664, disc_loss = 0.03244573363502111
Trained batch 49 in epoch 9, gen_loss = 1.1998163676261902, disc_loss = 0.03198000839911401
Trained batch 50 in epoch 9, gen_loss = 1.2013449645509906, disc_loss = 0.031618331951618776
Trained batch 51 in epoch 9, gen_loss = 1.2020271099530733, disc_loss = 0.03136070954720848
Trained batch 52 in epoch 9, gen_loss = 1.2023265204339657, disc_loss = 0.030987340122250455
Trained batch 53 in epoch 9, gen_loss = 1.2126519834553753, disc_loss = 0.030958841080535895
Trained batch 54 in epoch 9, gen_loss = 1.2159843119707974, disc_loss = 0.0305682412518019
Trained batch 55 in epoch 9, gen_loss = 1.2096121907234192, disc_loss = 0.03102236133833815
Trained batch 56 in epoch 9, gen_loss = 1.214655453698677, disc_loss = 0.03063713784509322
Trained batch 57 in epoch 9, gen_loss = 1.2187605931841095, disc_loss = 0.031020664762512876
Trained batch 58 in epoch 9, gen_loss = 1.2186809838828394, disc_loss = 0.030689638321114293
Trained batch 59 in epoch 9, gen_loss = 1.213586085041364, disc_loss = 0.03069930333488931
Trained batch 60 in epoch 9, gen_loss = 1.2132884527816148, disc_loss = 0.030307709384465316
Trained batch 61 in epoch 9, gen_loss = 1.2098911798769427, disc_loss = 0.030690188016442042
Trained batch 62 in epoch 9, gen_loss = 1.210826333553072, disc_loss = 0.03076396475265187
Trained batch 63 in epoch 9, gen_loss = 1.209941283799708, disc_loss = 0.030492165205942
Trained batch 64 in epoch 9, gen_loss = 1.2068874936837417, disc_loss = 0.03034960148282922
Trained batch 65 in epoch 9, gen_loss = 1.2087584020513478, disc_loss = 0.02996508449767575
Trained batch 66 in epoch 9, gen_loss = 1.2097981785660359, disc_loss = 0.02962910117748291
Trained batch 67 in epoch 9, gen_loss = 1.2120023273369844, disc_loss = 0.02939019530929406
Trained batch 68 in epoch 9, gen_loss = 1.2102192493452542, disc_loss = 0.02920649689959659
Trained batch 69 in epoch 9, gen_loss = 1.2024343294756754, disc_loss = 0.030159757532445448
Trained batch 70 in epoch 9, gen_loss = 1.2068173322879092, disc_loss = 0.031856491040228536
Trained batch 71 in epoch 9, gen_loss = 1.2053253079454105, disc_loss = 0.031636252747072525
Trained batch 72 in epoch 9, gen_loss = 1.198961466142576, disc_loss = 0.03244279769619238
Trained batch 73 in epoch 9, gen_loss = 1.2010880507327415, disc_loss = 0.03353542679090153
Trained batch 74 in epoch 9, gen_loss = 1.1997470768292744, disc_loss = 0.03346005954469244
Trained batch 75 in epoch 9, gen_loss = 1.198348362979136, disc_loss = 0.033308995820238795
Trained batch 76 in epoch 9, gen_loss = 1.196863432209213, disc_loss = 0.03313740986919442
Trained batch 77 in epoch 9, gen_loss = 1.1994031553085034, disc_loss = 0.0337541592008888
Trained batch 78 in epoch 9, gen_loss = 1.191721969767462, disc_loss = 0.03496301170037706
Trained batch 79 in epoch 9, gen_loss = 1.1961853601038457, disc_loss = 0.03493343969457783
Trained batch 80 in epoch 9, gen_loss = 1.194572146292086, disc_loss = 0.03491646364722171
Trained batch 81 in epoch 9, gen_loss = 1.192031774579025, disc_loss = 0.03488165558679256
Trained batch 82 in epoch 9, gen_loss = 1.19705066192581, disc_loss = 0.03489343490429133
Trained batch 83 in epoch 9, gen_loss = 1.196896098908924, disc_loss = 0.034747955860525724
Trained batch 84 in epoch 9, gen_loss = 1.1899974703788758, disc_loss = 0.03603875723064822
Trained batch 85 in epoch 9, gen_loss = 1.1990817916947742, disc_loss = 0.03662905216671873
Trained batch 86 in epoch 9, gen_loss = 1.1947049361535873, disc_loss = 0.0374961843789052
Trained batch 87 in epoch 9, gen_loss = 1.1913715533234857, disc_loss = 0.03761798941890116
Trained batch 88 in epoch 9, gen_loss = 1.192314899369572, disc_loss = 0.0375258839542695
Trained batch 89 in epoch 9, gen_loss = 1.194269593556722, disc_loss = 0.037387754193817575
Trained batch 90 in epoch 9, gen_loss = 1.1909959702701358, disc_loss = 0.0373178919480479
Trained batch 91 in epoch 9, gen_loss = 1.1884436251028725, disc_loss = 0.03726571235987965
Trained batch 92 in epoch 9, gen_loss = 1.1894892691284098, disc_loss = 0.036969230024604706
Trained batch 93 in epoch 9, gen_loss = 1.1947601456591423, disc_loss = 0.03695689066947299
Trained batch 94 in epoch 9, gen_loss = 1.1947179235910115, disc_loss = 0.036661153683732996
Trained batch 95 in epoch 9, gen_loss = 1.1952721420675516, disc_loss = 0.03637606482273744
Trained batch 96 in epoch 9, gen_loss = 1.1915870739012648, disc_loss = 0.036511601961803496
Trained batch 97 in epoch 9, gen_loss = 1.1986465715632146, disc_loss = 0.037019507869203785
Trained batch 98 in epoch 9, gen_loss = 1.198095106717312, disc_loss = 0.036784855164399353
Trained batch 99 in epoch 9, gen_loss = 1.1923281878232956, disc_loss = 0.03747926002833992
Trained batch 100 in epoch 9, gen_loss = 1.1930421124590505, disc_loss = 0.037734583891596236
Trained batch 101 in epoch 9, gen_loss = 1.1936432175776537, disc_loss = 0.03775919851956561
Trained batch 102 in epoch 9, gen_loss = 1.1913507916394948, disc_loss = 0.03778907369587173
Trained batch 103 in epoch 9, gen_loss = 1.1922614901111677, disc_loss = 0.03754358776719668
Trained batch 104 in epoch 9, gen_loss = 1.1963445180938357, disc_loss = 0.03739415242647131
Trained batch 105 in epoch 9, gen_loss = 1.1936691066004195, disc_loss = 0.03736716711384086
Trained batch 106 in epoch 9, gen_loss = 1.1912493583197905, disc_loss = 0.037273197343451116
Trained batch 107 in epoch 9, gen_loss = 1.1974347311037559, disc_loss = 0.037547097942377955
Trained batch 108 in epoch 9, gen_loss = 1.1981648283267239, disc_loss = 0.03737467813194482
Trained batch 109 in epoch 9, gen_loss = 1.19674663326957, disc_loss = 0.03732218609022146
Trained batch 110 in epoch 9, gen_loss = 1.1953966177261628, disc_loss = 0.03720703028427722
Trained batch 111 in epoch 9, gen_loss = 1.1956501752138138, disc_loss = 0.037083168767691986
Trained batch 112 in epoch 9, gen_loss = 1.1971713948038827, disc_loss = 0.03697722598465275
Trained batch 113 in epoch 9, gen_loss = 1.2006707797970688, disc_loss = 0.0368005325731805
Trained batch 114 in epoch 9, gen_loss = 1.199595310377038, disc_loss = 0.03676896097300493
Trained batch 115 in epoch 9, gen_loss = 1.2002364705348838, disc_loss = 0.03667272781905044
Trained batch 116 in epoch 9, gen_loss = 1.2010834033672626, disc_loss = 0.036502949626813844
Trained batch 117 in epoch 9, gen_loss = 1.1999745611417092, disc_loss = 0.03654952819648562
Trained batch 118 in epoch 9, gen_loss = 1.2019756932218535, disc_loss = 0.0363209810647957
Trained batch 119 in epoch 9, gen_loss = 1.2029580742120742, disc_loss = 0.03605868041825791
Trained batch 120 in epoch 9, gen_loss = 1.2018689587096538, disc_loss = 0.03593218580565669
Trained batch 121 in epoch 9, gen_loss = 1.2040028513455001, disc_loss = 0.03575994404887811
Trained batch 122 in epoch 9, gen_loss = 1.2036370164979764, disc_loss = 0.03553516097457671
Trained batch 123 in epoch 9, gen_loss = 1.2060658037662506, disc_loss = 0.035404940804226265
Trained batch 124 in epoch 9, gen_loss = 1.2044560270309448, disc_loss = 0.03530545205622911
Trained batch 125 in epoch 9, gen_loss = 1.205969438666389, disc_loss = 0.03508390530589081
Trained batch 126 in epoch 9, gen_loss = 1.2085945831509086, disc_loss = 0.03571471404724234
Trained batch 127 in epoch 9, gen_loss = 1.2035048953257501, disc_loss = 0.03667194416630082
Trained batch 128 in epoch 9, gen_loss = 1.2035700475522715, disc_loss = 0.03653162229777306
Trained batch 129 in epoch 9, gen_loss = 1.2035553487447592, disc_loss = 0.036384042610342684
Trained batch 130 in epoch 9, gen_loss = 1.204766842700143, disc_loss = 0.03649757000553699
Trained batch 131 in epoch 9, gen_loss = 1.2029126977378672, disc_loss = 0.03645479135836164
Trained batch 132 in epoch 9, gen_loss = 1.2039408867520498, disc_loss = 0.03624850274868926
Trained batch 133 in epoch 9, gen_loss = 1.204599219916472, disc_loss = 0.03604565204969093
Trained batch 134 in epoch 9, gen_loss = 1.206882525814904, disc_loss = 0.035924849314270195
Trained batch 135 in epoch 9, gen_loss = 1.206072659615208, disc_loss = 0.03575691820451004
Trained batch 136 in epoch 9, gen_loss = 1.2058008626429704, disc_loss = 0.035565373079892056
Trained batch 137 in epoch 9, gen_loss = 1.2069460728030275, disc_loss = 0.035378517603258726
Trained batch 138 in epoch 9, gen_loss = 1.2062911545629982, disc_loss = 0.03521624679188076
Trained batch 139 in epoch 9, gen_loss = 1.205020287632942, disc_loss = 0.03510380887559482
Trained batch 140 in epoch 9, gen_loss = 1.2047514657602243, disc_loss = 0.035102096221125714
Trained batch 141 in epoch 9, gen_loss = 1.2042183317768742, disc_loss = 0.03537391231093608
Trained batch 142 in epoch 9, gen_loss = 1.2015436304199112, disc_loss = 0.035506316988201406
Trained batch 143 in epoch 9, gen_loss = 1.204052912692229, disc_loss = 0.035691638813457556
Trained batch 144 in epoch 9, gen_loss = 1.2022534884255507, disc_loss = 0.03562957956616221
Trained batch 145 in epoch 9, gen_loss = 1.2009582180682927, disc_loss = 0.03551706139712709
Trained batch 146 in epoch 9, gen_loss = 1.204042290749193, disc_loss = 0.03548884464009684
Trained batch 147 in epoch 9, gen_loss = 1.2043685079426378, disc_loss = 0.03530506232149295
Trained batch 148 in epoch 9, gen_loss = 1.2034850772595245, disc_loss = 0.035243599519333584
Trained batch 149 in epoch 9, gen_loss = 1.2017626424630483, disc_loss = 0.03520836933205525
Trained batch 150 in epoch 9, gen_loss = 1.2066314042798731, disc_loss = 0.035527962167432765
Trained batch 151 in epoch 9, gen_loss = 1.2036633307212277, disc_loss = 0.03576127286559265
Trained batch 152 in epoch 9, gen_loss = 1.2026658202308456, disc_loss = 0.03565013720319162
Trained batch 153 in epoch 9, gen_loss = 1.202372434464368, disc_loss = 0.03578929670832374
Trained batch 154 in epoch 9, gen_loss = 1.2017131147846098, disc_loss = 0.03568504231591379
Trained batch 155 in epoch 9, gen_loss = 1.2000350512755222, disc_loss = 0.035685055841429114
Trained batch 156 in epoch 9, gen_loss = 1.2007786350645078, disc_loss = 0.03585104205331225
Trained batch 157 in epoch 9, gen_loss = 1.2023449853251251, disc_loss = 0.03574097023310163
Trained batch 158 in epoch 9, gen_loss = 1.2010786941966172, disc_loss = 0.03578109667876606
Trained batch 159 in epoch 9, gen_loss = 1.1986396454274655, disc_loss = 0.03611220068996772
Trained batch 160 in epoch 9, gen_loss = 1.2046543196861788, disc_loss = 0.03742928556542589
Trained batch 161 in epoch 9, gen_loss = 1.2023898399906394, disc_loss = 0.03755587736075675
Trained batch 162 in epoch 9, gen_loss = 1.2003945759469015, disc_loss = 0.03784497970132374
Trained batch 163 in epoch 9, gen_loss = 1.1989715960694523, disc_loss = 0.03807838530302411
Trained batch 164 in epoch 9, gen_loss = 1.1995970310586872, disc_loss = 0.03905207800368468
Trained batch 165 in epoch 9, gen_loss = 1.1977839236517986, disc_loss = 0.04017494507807206
Trained batch 166 in epoch 9, gen_loss = 1.1978556449541788, disc_loss = 0.04078664765609596
Trained batch 167 in epoch 9, gen_loss = 1.1966365891553106, disc_loss = 0.04104191921873107
Trained batch 168 in epoch 9, gen_loss = 1.1961870789527893, disc_loss = 0.04118953209877367
Trained batch 169 in epoch 9, gen_loss = 1.1968769427608041, disc_loss = 0.04124093758051886
Trained batch 170 in epoch 9, gen_loss = 1.196366706438232, disc_loss = 0.04127566547988103
Trained batch 171 in epoch 9, gen_loss = 1.1937373983998631, disc_loss = 0.04154643577761775
Trained batch 172 in epoch 9, gen_loss = 1.1938463838803286, disc_loss = 0.04150040496162252
Trained batch 173 in epoch 9, gen_loss = 1.194986536242496, disc_loss = 0.04165930284893718
Trained batch 174 in epoch 9, gen_loss = 1.1925399082047599, disc_loss = 0.04175167163567883
Trained batch 175 in epoch 9, gen_loss = 1.1908642195842483, disc_loss = 0.04174935969058424
Trained batch 176 in epoch 9, gen_loss = 1.1937018659828746, disc_loss = 0.0428024259222261
Trained batch 177 in epoch 9, gen_loss = 1.1901379883959051, disc_loss = 0.043615992390289064
Trained batch 178 in epoch 9, gen_loss = 1.187803621731657, disc_loss = 0.043980819958798045
Trained batch 179 in epoch 9, gen_loss = 1.1885658611853918, disc_loss = 0.04405136426082916
Trained batch 180 in epoch 9, gen_loss = 1.1877925280707975, disc_loss = 0.04409131867739048
Trained batch 181 in epoch 9, gen_loss = 1.185320604960997, disc_loss = 0.044229487786171855
Trained batch 182 in epoch 9, gen_loss = 1.1868359889489053, disc_loss = 0.04417504330516839
Trained batch 183 in epoch 9, gen_loss = 1.18541403244371, disc_loss = 0.04413391332870916
Trained batch 184 in epoch 9, gen_loss = 1.1840119461755494, disc_loss = 0.04536750806948623
Trained batch 185 in epoch 9, gen_loss = 1.1816012554912156, disc_loss = 0.045586922466354346
Testing Epoch 9
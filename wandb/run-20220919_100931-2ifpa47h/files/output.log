/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 1.0273144245147705, disc_loss = 0.4838177561759949
Trained batch 1 in epoch 0, gen_loss = 1.0120948553085327, disc_loss = 0.6074724495410919
Trained batch 2 in epoch 0, gen_loss = 1.4867876370747883, disc_loss = 1.4273998936017354
Trained batch 3 in epoch 0, gen_loss = 1.3122132420539856, disc_loss = 1.212439402937889
Trained batch 4 in epoch 0, gen_loss = 1.2436842799186707, disc_loss = 1.0541613698005676
Trained batch 5 in epoch 0, gen_loss = 1.1671071946620941, disc_loss = 0.9207977751890818
Trained batch 6 in epoch 0, gen_loss = 1.105354641165052, disc_loss = 0.8209542504378727
Trained batch 7 in epoch 0, gen_loss = 1.0493945255875587, disc_loss = 0.7489042095839977
Trained batch 8 in epoch 0, gen_loss = 1.0047323637538486, disc_loss = 0.6967451373736063
Trained batch 9 in epoch 0, gen_loss = 0.9828039228916168, disc_loss = 0.663840913772583
Trained batch 10 in epoch 0, gen_loss = 0.9703122810883955, disc_loss = 0.6385574340820312
Trained batch 11 in epoch 0, gen_loss = 0.9578408102194468, disc_loss = 0.6197502786914507
Trained batch 12 in epoch 0, gen_loss = 0.9402954486700205, disc_loss = 0.5994704342805423
Trained batch 13 in epoch 0, gen_loss = 0.9252029742513385, disc_loss = 0.571282154747418
Trained batch 14 in epoch 0, gen_loss = 0.9121699492136638, disc_loss = 0.5466307113567989
Trained batch 15 in epoch 0, gen_loss = 0.8967235498130322, disc_loss = 0.5238268971443176
Trained batch 16 in epoch 0, gen_loss = 0.8940609413034776, disc_loss = 0.5020262178252725
Trained batch 17 in epoch 0, gen_loss = 0.8826582233111063, disc_loss = 0.48337776793373954
Trained batch 18 in epoch 0, gen_loss = 0.8774431943893433, disc_loss = 0.46461329020951925
Trained batch 19 in epoch 0, gen_loss = 0.8710080921649933, disc_loss = 0.44709831438958647
Trained batch 20 in epoch 0, gen_loss = 0.8710160085133144, disc_loss = 0.4300967004327547
Trained batch 21 in epoch 0, gen_loss = 0.8650900613177906, disc_loss = 0.4141990684650161
Trained batch 22 in epoch 0, gen_loss = 0.8630634753600411, disc_loss = 0.39939802107603656
Trained batch 23 in epoch 0, gen_loss = 0.8678329735994339, disc_loss = 0.3851856190400819
Trained batch 24 in epoch 0, gen_loss = 0.8659892010688782, disc_loss = 0.3748353497684002
Trained batch 25 in epoch 0, gen_loss = 0.8763476541409125, disc_loss = 0.36568989876944286
Trained batch 26 in epoch 0, gen_loss = 0.8816315840791773, disc_loss = 0.3577087834753372
Trained batch 27 in epoch 0, gen_loss = 0.884167207138879, disc_loss = 0.35019516239741016
Trained batch 28 in epoch 0, gen_loss = 0.8886499733760439, disc_loss = 0.34050662622883404
Trained batch 29 in epoch 0, gen_loss = 0.8883731404940287, disc_loss = 0.33203047948578995
Trained batch 30 in epoch 0, gen_loss = 0.8895024445749098, disc_loss = 0.32604385515855205
Trained batch 31 in epoch 0, gen_loss = 0.8929612748324871, disc_loss = 0.3234845370752737
Trained batch 32 in epoch 0, gen_loss = 0.8996970798030044, disc_loss = 0.3222174137604959
Trained batch 33 in epoch 0, gen_loss = 0.9058026566224939, disc_loss = 0.3168353007777649
Trained batch 34 in epoch 0, gen_loss = 0.9105150563376291, disc_loss = 0.31115752256342344
Trained batch 35 in epoch 0, gen_loss = 0.9193161063724093, disc_loss = 0.3044922857855757
Trained batch 36 in epoch 0, gen_loss = 0.9226404718450598, disc_loss = 0.29787330057572675
Trained batch 37 in epoch 0, gen_loss = 0.9239246045288286, disc_loss = 0.2915687471824257
Trained batch 38 in epoch 0, gen_loss = 0.9274535316687363, disc_loss = 0.2850986160337925
Trained batch 39 in epoch 0, gen_loss = 0.931766326725483, disc_loss = 0.2788731289096177
Trained batch 40 in epoch 0, gen_loss = 0.9336490064132504, disc_loss = 0.27304678128623383
Trained batch 41 in epoch 0, gen_loss = 0.9341704888003213, disc_loss = 0.2674936694758279
Trained batch 42 in epoch 0, gen_loss = 0.9345341130744579, disc_loss = 0.2622462268485579
Trained batch 43 in epoch 0, gen_loss = 0.9346351298418912, disc_loss = 0.25764026221903885
Trained batch 44 in epoch 0, gen_loss = 0.9365574253929986, disc_loss = 0.2530108275512854
Trained batch 45 in epoch 0, gen_loss = 0.9356178330338519, disc_loss = 0.2482645967570336
Trained batch 46 in epoch 0, gen_loss = 0.9349892380389762, disc_loss = 0.24359091030473404
Trained batch 47 in epoch 0, gen_loss = 0.9400893189013004, disc_loss = 0.23954117119622728
Trained batch 48 in epoch 0, gen_loss = 0.9355810941482077, disc_loss = 0.2362573010732933
Trained batch 49 in epoch 0, gen_loss = 0.9382029759883881, disc_loss = 0.235602902546525
Trained batch 50 in epoch 0, gen_loss = 0.9330113985959221, disc_loss = 0.2343558117601217
Trained batch 51 in epoch 0, gen_loss = 0.9332626095184913, disc_loss = 0.23053833433928397
Trained batch 52 in epoch 0, gen_loss = 0.9345751798377847, disc_loss = 0.2271130035086623
Trained batch 53 in epoch 0, gen_loss = 0.9337146591257166, disc_loss = 0.22357167041412107
Trained batch 54 in epoch 0, gen_loss = 0.9315907738425515, disc_loss = 0.2202966805208813
Trained batch 55 in epoch 0, gen_loss = 0.9314908555575779, disc_loss = 0.2172256654926709
Trained batch 56 in epoch 0, gen_loss = 0.9316944532227098, disc_loss = 0.21397318226987855
Trained batch 57 in epoch 0, gen_loss = 0.9331499708109888, disc_loss = 0.21076895190595551
Trained batch 58 in epoch 0, gen_loss = 0.9327902127120454, disc_loss = 0.20769269401365417
Trained batch 59 in epoch 0, gen_loss = 0.9357433537642161, disc_loss = 0.20469394236182173
Trained batch 60 in epoch 0, gen_loss = 0.9344996555906827, disc_loss = 0.20193368608712173
Trained batch 61 in epoch 0, gen_loss = 0.93599104400604, disc_loss = 0.19933399843472627
Trained batch 62 in epoch 0, gen_loss = 0.9338794984514751, disc_loss = 0.19734357933085117
Trained batch 63 in epoch 0, gen_loss = 0.9376228842884302, disc_loss = 0.1958716921217274
Trained batch 64 in epoch 0, gen_loss = 0.9356976252335768, disc_loss = 0.19473300573344415
Trained batch 65 in epoch 0, gen_loss = 0.9380372130509579, disc_loss = 0.1924249388446862
Trained batch 66 in epoch 0, gen_loss = 0.9393905045381233, disc_loss = 0.1899970441278237
Trained batch 67 in epoch 0, gen_loss = 0.939487075104433, disc_loss = 0.1877529107801178
Trained batch 68 in epoch 0, gen_loss = 0.9408507485320603, disc_loss = 0.18539167514097862
Trained batch 69 in epoch 0, gen_loss = 0.942116641998291, disc_loss = 0.1829890408420137
Trained batch 70 in epoch 0, gen_loss = 0.9419845023625334, disc_loss = 0.1807768986311177
Trained batch 71 in epoch 0, gen_loss = 0.9438674913512336, disc_loss = 0.17875010791855553
Trained batch 72 in epoch 0, gen_loss = 0.94271125368876, disc_loss = 0.17677168055654388
Trained batch 73 in epoch 0, gen_loss = 0.9452886935826894, disc_loss = 0.1747935079289852
Trained batch 74 in epoch 0, gen_loss = 0.9467971849441529, disc_loss = 0.1727265104899804
Trained batch 75 in epoch 0, gen_loss = 0.9456083633397755, disc_loss = 0.17081376390629693
Trained batch 76 in epoch 0, gen_loss = 0.9484599751311463, disc_loss = 0.16890628834242943
Trained batch 77 in epoch 0, gen_loss = 0.9491797777322623, disc_loss = 0.1669164433096273
Trained batch 78 in epoch 0, gen_loss = 0.948610077175913, disc_loss = 0.16499730925771255
Trained batch 79 in epoch 0, gen_loss = 0.9478036969900131, disc_loss = 0.16321458613965661
Trained batch 80 in epoch 0, gen_loss = 0.9463580390553415, disc_loss = 0.16163163418295207
Trained batch 81 in epoch 0, gen_loss = 0.9474392780443517, disc_loss = 0.15985860046362732
Trained batch 82 in epoch 0, gen_loss = 0.9483180074806673, disc_loss = 0.15813978465206652
Trained batch 83 in epoch 0, gen_loss = 0.9487197590725762, disc_loss = 0.15643432101101748
Trained batch 84 in epoch 0, gen_loss = 0.9506646696258994, disc_loss = 0.15485647023819826
Trained batch 85 in epoch 0, gen_loss = 0.9518261337003042, disc_loss = 0.15323228533054853
Trained batch 86 in epoch 0, gen_loss = 0.9520614743232727, disc_loss = 0.1516147475347094
Trained batch 87 in epoch 0, gen_loss = 0.9516643631187353, disc_loss = 0.15007585306143897
Trained batch 88 in epoch 0, gen_loss = 0.951695296201813, disc_loss = 0.14853819975566662
Trained batch 89 in epoch 0, gen_loss = 0.9520446181297302, disc_loss = 0.14706915686320926
Trained batch 90 in epoch 0, gen_loss = 0.9527641390706156, disc_loss = 0.14561948315291615
Trained batch 91 in epoch 0, gen_loss = 0.9530707085910051, disc_loss = 0.1442714002104881
Trained batch 92 in epoch 0, gen_loss = 0.9529869165471805, disc_loss = 0.14303917778275346
Trained batch 93 in epoch 0, gen_loss = 0.9540607047841904, disc_loss = 0.14193358363464792
Trained batch 94 in epoch 0, gen_loss = 0.953726221385755, disc_loss = 0.14081267196881145
Trained batch 95 in epoch 0, gen_loss = 0.9564359237750372, disc_loss = 0.13973955577239394
Trained batch 96 in epoch 0, gen_loss = 0.9567531187509754, disc_loss = 0.13853681978491164
Trained batch 97 in epoch 0, gen_loss = 0.9570214030693989, disc_loss = 0.1375720400591286
Trained batch 98 in epoch 0, gen_loss = 0.9599319070276587, disc_loss = 0.13664008330817173
Trained batch 99 in epoch 0, gen_loss = 0.9609616422653198, disc_loss = 0.13552288876846433
Trained batch 100 in epoch 0, gen_loss = 0.9626424713890152, disc_loss = 0.13446516523340551
Trained batch 101 in epoch 0, gen_loss = 0.9644014274372774, disc_loss = 0.13346359741819255
Trained batch 102 in epoch 0, gen_loss = 0.9658026602661726, disc_loss = 0.13242380661003797
Trained batch 103 in epoch 0, gen_loss = 0.9667553867285068, disc_loss = 0.13143920740829065
Trained batch 104 in epoch 0, gen_loss = 0.9694631712777274, disc_loss = 0.13049250344435373
Trained batch 105 in epoch 0, gen_loss = 0.970824418202886, disc_loss = 0.12945912843394392
Trained batch 106 in epoch 0, gen_loss = 0.9714269036444548, disc_loss = 0.128506623173707
Trained batch 107 in epoch 0, gen_loss = 0.9720394611358643, disc_loss = 0.12748776624600092
Trained batch 108 in epoch 0, gen_loss = 0.9724482943158631, disc_loss = 0.1265374938316575
Trained batch 109 in epoch 0, gen_loss = 0.9733811259269715, disc_loss = 0.12562279829924758
Trained batch 110 in epoch 0, gen_loss = 0.9729627177521989, disc_loss = 0.12492906986861615
Trained batch 111 in epoch 0, gen_loss = 0.9756941805992808, disc_loss = 0.12804130564576813
Trained batch 112 in epoch 0, gen_loss = 0.9731376213310039, disc_loss = 0.13026519601060227
Trained batch 113 in epoch 0, gen_loss = 0.9733094552107024, disc_loss = 0.13239216614972082
Trained batch 114 in epoch 0, gen_loss = 0.9717782103497049, disc_loss = 0.1340124598663786
Trained batch 115 in epoch 0, gen_loss = 0.9709378347314638, disc_loss = 0.1381954306030068
Trained batch 116 in epoch 0, gen_loss = 0.970342438445132, disc_loss = 0.1437779636337207
Trained batch 117 in epoch 0, gen_loss = 0.9680738575377706, disc_loss = 0.1444204238132905
Trained batch 118 in epoch 0, gen_loss = 0.9662771715837366, disc_loss = 0.14517408565563314
Trained batch 119 in epoch 0, gen_loss = 0.9640080317854881, disc_loss = 0.14521039432535568
Trained batch 120 in epoch 0, gen_loss = 0.9613059192649589, disc_loss = 0.14513299786601186
Trained batch 121 in epoch 0, gen_loss = 0.9591493635881142, disc_loss = 0.14498475419937587
Trained batch 122 in epoch 0, gen_loss = 0.9567078264748178, disc_loss = 0.1448914162148305
Trained batch 123 in epoch 0, gen_loss = 0.9544485730509604, disc_loss = 0.14484496540840594
Trained batch 124 in epoch 0, gen_loss = 0.9524662942886353, disc_loss = 0.14502871412038804
Trained batch 125 in epoch 0, gen_loss = 0.9506799133997115, disc_loss = 0.1453361055325894
Trained batch 126 in epoch 0, gen_loss = 0.9481118199393506, disc_loss = 0.1456999007289804
Trained batch 127 in epoch 0, gen_loss = 0.9462973903864622, disc_loss = 0.14600859832717106
Trained batch 128 in epoch 0, gen_loss = 0.943509977455287, disc_loss = 0.1464440422349198
Trained batch 129 in epoch 0, gen_loss = 0.9426865353034093, disc_loss = 0.1467091656075074
Trained batch 130 in epoch 0, gen_loss = 0.9403859913804149, disc_loss = 0.14740514669937033
Trained batch 131 in epoch 0, gen_loss = 0.9394293996420774, disc_loss = 0.14783916582889628
Trained batch 132 in epoch 0, gen_loss = 0.9382262817002777, disc_loss = 0.14861942396352165
Trained batch 133 in epoch 0, gen_loss = 0.9374357350726625, disc_loss = 0.14917645175287972
Trained batch 134 in epoch 0, gen_loss = 0.9366996645927429, disc_loss = 0.14936528476300062
Trained batch 135 in epoch 0, gen_loss = 0.9340816004311338, disc_loss = 0.14984157949905186
Trained batch 136 in epoch 0, gen_loss = 0.9332426721162169, disc_loss = 0.14998044666365115
Trained batch 137 in epoch 0, gen_loss = 0.931180116922959, disc_loss = 0.15060014855386555
Trained batch 138 in epoch 0, gen_loss = 0.930623921130201, disc_loss = 0.15068837962776638
Trained batch 139 in epoch 0, gen_loss = 0.9292279234954289, disc_loss = 0.1506053172584091
Trained batch 140 in epoch 0, gen_loss = 0.9290128324894195, disc_loss = 0.15046390103744278
Trained batch 141 in epoch 0, gen_loss = 0.9277557411663969, disc_loss = 0.15054756765004615
Trained batch 142 in epoch 0, gen_loss = 0.9270240360206657, disc_loss = 0.1504899282659684
Trained batch 143 in epoch 0, gen_loss = 0.9258390714724859, disc_loss = 0.15031152425540817
Trained batch 144 in epoch 0, gen_loss = 0.9267498624735865, disc_loss = 0.15105810925878327
Trained batch 145 in epoch 0, gen_loss = 0.924030747315655, disc_loss = 0.15239158742231865
Trained batch 146 in epoch 0, gen_loss = 0.9230749550319853, disc_loss = 0.15218618948037932
Trained batch 147 in epoch 0, gen_loss = 0.923175778340649, disc_loss = 0.15213984009381887
Trained batch 148 in epoch 0, gen_loss = 0.9219536993327557, disc_loss = 0.15181452320926142
Trained batch 149 in epoch 0, gen_loss = 0.9206767141819, disc_loss = 0.15162085458636285
Trained batch 150 in epoch 0, gen_loss = 0.9203335642814636, disc_loss = 0.15157064455037086
Trained batch 151 in epoch 0, gen_loss = 0.9184106635419946, disc_loss = 0.1513069547026565
Trained batch 152 in epoch 0, gen_loss = 0.9171977643094031, disc_loss = 0.15099935238462647
Trained batch 153 in epoch 0, gen_loss = 0.9179054970865126, disc_loss = 0.15194419621453656
Trained batch 154 in epoch 0, gen_loss = 0.9154786017633254, disc_loss = 0.15312093703016158
Trained batch 155 in epoch 0, gen_loss = 0.9152494279237894, disc_loss = 0.15319743499350855
Trained batch 156 in epoch 0, gen_loss = 0.9152935864819083, disc_loss = 0.15338475627314513
Trained batch 157 in epoch 0, gen_loss = 0.9137229960930499, disc_loss = 0.15331733863376365
Trained batch 158 in epoch 0, gen_loss = 0.9120080122407878, disc_loss = 0.1536018336250347
Trained batch 159 in epoch 0, gen_loss = 0.9115937508642673, disc_loss = 0.15405459920875728
Trained batch 160 in epoch 0, gen_loss = 0.9108436329764609, disc_loss = 0.15406084130084294
Trained batch 161 in epoch 0, gen_loss = 0.9099321232901679, disc_loss = 0.15416109750484241
Trained batch 162 in epoch 0, gen_loss = 0.9089114984120328, disc_loss = 0.1542271893540043
Trained batch 163 in epoch 0, gen_loss = 0.9088098668470616, disc_loss = 0.154764616316775
Trained batch 164 in epoch 0, gen_loss = 0.9068101102655585, disc_loss = 0.15531741240710922
Trained batch 165 in epoch 0, gen_loss = 0.9077023181570582, disc_loss = 0.15650684184518204
Trained batch 166 in epoch 0, gen_loss = 0.907371875054822, disc_loss = 0.15639526432681228
Trained batch 167 in epoch 0, gen_loss = 0.9066966126362482, disc_loss = 0.15663001096496978
Trained batch 168 in epoch 0, gen_loss = 0.9052661622064353, disc_loss = 0.15690712961395817
Trained batch 169 in epoch 0, gen_loss = 0.9051693723482244, disc_loss = 0.1572662275941933
Trained batch 170 in epoch 0, gen_loss = 0.9041684893836752, disc_loss = 0.1573121564691527
Trained batch 171 in epoch 0, gen_loss = 0.9026385119488073, disc_loss = 0.15775213923391906
Trained batch 172 in epoch 0, gen_loss = 0.9015849043179109, disc_loss = 0.15768731953953044
Trained batch 173 in epoch 0, gen_loss = 0.900444755609008, disc_loss = 0.15778207560551577
Trained batch 174 in epoch 0, gen_loss = 0.8993334514754159, disc_loss = 0.15779238313436508
Trained batch 175 in epoch 0, gen_loss = 0.8992221321571957, disc_loss = 0.15758619999343698
Trained batch 176 in epoch 0, gen_loss = 0.8993301330986669, disc_loss = 0.15708231997523603
Trained batch 177 in epoch 0, gen_loss = 0.897554204035341, disc_loss = 0.15711528552549608
Trained batch 178 in epoch 0, gen_loss = 0.8979632265074959, disc_loss = 0.15712797779111223
Trained batch 179 in epoch 0, gen_loss = 0.8968314468860626, disc_loss = 0.15697294626798894
Trained batch 180 in epoch 0, gen_loss = 0.8959696786838341, disc_loss = 0.1568999404489006
Trained batch 181 in epoch 0, gen_loss = 0.8965183195177016, disc_loss = 0.15766010969713495
Trained batch 182 in epoch 0, gen_loss = 0.895022793545749, disc_loss = 0.15863316327007743
Trained batch 183 in epoch 0, gen_loss = 0.8954601083760676, disc_loss = 0.1597050030351333
Trained batch 184 in epoch 0, gen_loss = 0.8941688843675561, disc_loss = 0.16020418892841082
Trained batch 185 in epoch 0, gen_loss = 0.8924133886573136, disc_loss = 0.16069469180318616
Trained batch 186 in epoch 0, gen_loss = 0.8908499696037986, disc_loss = 0.16109149743688297
Trained batch 187 in epoch 0, gen_loss = 0.8900093880105526, disc_loss = 0.161396597650774
Trained batch 188 in epoch 0, gen_loss = 0.8886935307235314, disc_loss = 0.16188627233107886
Trained batch 189 in epoch 0, gen_loss = 0.8872368078482779, disc_loss = 0.1622672199810806
Trained batch 190 in epoch 0, gen_loss = 0.88601655516949, disc_loss = 0.16259139982973717
Trained batch 191 in epoch 0, gen_loss = 0.8850559579829375, disc_loss = 0.16285383883708468
Trained batch 192 in epoch 0, gen_loss = 0.8842521421032249, disc_loss = 0.16309264267510082
Trained batch 193 in epoch 0, gen_loss = 0.8829197548713881, disc_loss = 0.16315408262241746
Trained batch 194 in epoch 0, gen_loss = 0.8820971852693802, disc_loss = 0.16313929997193508
Trained batch 195 in epoch 0, gen_loss = 0.880995973944664, disc_loss = 0.1632598192640105
Trained batch 196 in epoch 0, gen_loss = 0.8801865441545011, disc_loss = 0.16319245444185237
Trained batch 197 in epoch 0, gen_loss = 0.8787755114261551, disc_loss = 0.16316039585555442
Trained batch 198 in epoch 0, gen_loss = 0.8788785622946581, disc_loss = 0.16359069145953836
Trained batch 199 in epoch 0, gen_loss = 0.8775428199768066, disc_loss = 0.16390506219118833
Trained batch 200 in epoch 0, gen_loss = 0.8767531582372106, disc_loss = 0.163927965236837
Trained batch 201 in epoch 0, gen_loss = 0.8765849128808125, disc_loss = 0.1636915537759219
Trained batch 202 in epoch 0, gen_loss = 0.8756665064783519, disc_loss = 0.1633045588954916
Trained batch 203 in epoch 0, gen_loss = 0.8751023896768981, disc_loss = 0.1629858705050805
Trained batch 204 in epoch 0, gen_loss = 0.8761034261889574, disc_loss = 0.16335442662239075
Trained batch 205 in epoch 0, gen_loss = 0.8750375688654705, disc_loss = 0.16344144513595452
Trained batch 206 in epoch 0, gen_loss = 0.8751197108899914, disc_loss = 0.16337216692270287
Trained batch 207 in epoch 0, gen_loss = 0.8745430813959012, disc_loss = 0.1631346456348323
Trained batch 208 in epoch 0, gen_loss = 0.8740770434648797, disc_loss = 0.1626810494578626
Trained batch 209 in epoch 0, gen_loss = 0.8742671813283648, disc_loss = 0.1621928869968369
Trained batch 210 in epoch 0, gen_loss = 0.8740079323827373, disc_loss = 0.16178214542956149
Trained batch 211 in epoch 0, gen_loss = 0.8753779193140426, disc_loss = 0.16131627243363633
Trained batch 212 in epoch 0, gen_loss = 0.8752531546382277, disc_loss = 0.16071453683533019
Trained batch 213 in epoch 0, gen_loss = 0.8748958918535821, disc_loss = 0.1601350611406509
Trained batch 214 in epoch 0, gen_loss = 0.8752555087555286, disc_loss = 0.15967792066377262
Trained batch 215 in epoch 0, gen_loss = 0.875368442248415, disc_loss = 0.15900793330554194
Trained batch 216 in epoch 0, gen_loss = 0.8765739460694625, disc_loss = 0.15836257528307662
Trained batch 217 in epoch 0, gen_loss = 0.8768118007467427, disc_loss = 0.15772730938731394
Trained batch 218 in epoch 0, gen_loss = 0.8784079116229053, disc_loss = 0.15713395055417465
Trained batch 219 in epoch 0, gen_loss = 0.8794413907961411, disc_loss = 0.1565006465608762
Trained batch 220 in epoch 0, gen_loss = 0.880146445192363, disc_loss = 0.15584318782729667
Trained batch 221 in epoch 0, gen_loss = 0.8806308685122309, disc_loss = 0.15519532459779634
Trained batch 222 in epoch 0, gen_loss = 0.8813738069192176, disc_loss = 0.1545456665872926
Trained batch 223 in epoch 0, gen_loss = 0.8820824628429753, disc_loss = 0.15390556067411257
Trained batch 224 in epoch 0, gen_loss = 0.8825959428151449, disc_loss = 0.15326918873108095
Trained batch 225 in epoch 0, gen_loss = 0.8828408760307109, disc_loss = 0.15262349885558726
Trained batch 226 in epoch 0, gen_loss = 0.8830611385437885, disc_loss = 0.15202007332143871
Trained batch 227 in epoch 0, gen_loss = 0.8835759314528683, disc_loss = 0.1514026696667108
Trained batch 228 in epoch 0, gen_loss = 0.8843359874325548, disc_loss = 0.15079887802041578
Trained batch 229 in epoch 0, gen_loss = 0.8850606410399727, disc_loss = 0.15018563910549426
Trained batch 230 in epoch 0, gen_loss = 0.8856657511228091, disc_loss = 0.1495662173740082
Trained batch 231 in epoch 0, gen_loss = 0.8864989511925598, disc_loss = 0.14895506079332774
Trained batch 232 in epoch 0, gen_loss = 0.8869902125755604, disc_loss = 0.1483493151339051
Trained batch 233 in epoch 0, gen_loss = 0.8873275666155367, disc_loss = 0.14774141626026577
Trained batch 234 in epoch 0, gen_loss = 0.8875490211425944, disc_loss = 0.1471338000267427
Trained batch 235 in epoch 0, gen_loss = 0.8876236290749857, disc_loss = 0.14652866535520148
Trained batch 236 in epoch 0, gen_loss = 0.887681270198983, disc_loss = 0.14592946135490065
Trained batch 237 in epoch 0, gen_loss = 0.8877956456496936, disc_loss = 0.14534212474930375
Trained batch 238 in epoch 0, gen_loss = 0.8878308614427575, disc_loss = 0.14475811066916486
Trained batch 239 in epoch 0, gen_loss = 0.8885270441571872, disc_loss = 0.14420775230003832
Trained batch 240 in epoch 0, gen_loss = 0.8881769546334675, disc_loss = 0.1436787706343805
Trained batch 241 in epoch 0, gen_loss = 0.8888081528923728, disc_loss = 0.14311292155430275
Trained batch 242 in epoch 0, gen_loss = 0.8894947801597815, disc_loss = 0.14255106761867617
Trained batch 243 in epoch 0, gen_loss = 0.8896388636260736, disc_loss = 0.14202113732787186
Trained batch 244 in epoch 0, gen_loss = 0.8905047961643764, disc_loss = 0.14173922449806514
Trained batch 245 in epoch 0, gen_loss = 0.8903883046251002, disc_loss = 0.14152577712495878
Trained batch 246 in epoch 0, gen_loss = 0.8892963309037057, disc_loss = 0.14183070736103937
Trained batch 247 in epoch 0, gen_loss = 0.8908065595934468, disc_loss = 0.14303856654723565
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 0.5459635853767395, disc_loss = 0.22547730803489685
Trained batch 1 in epoch 1, gen_loss = 0.6871553361415863, disc_loss = 0.18517176061868668
Trained batch 2 in epoch 1, gen_loss = 0.7172807256380717, disc_loss = 0.16524942219257355
Trained batch 3 in epoch 1, gen_loss = 0.6597733125090599, disc_loss = 0.183756485581398
Trained batch 4 in epoch 1, gen_loss = 0.6807718455791474, disc_loss = 0.17416284382343292
Trained batch 5 in epoch 1, gen_loss = 0.6893493384122849, disc_loss = 0.175281323492527
Trained batch 6 in epoch 1, gen_loss = 0.6690453674112048, disc_loss = 0.18529697614056723
Trained batch 7 in epoch 1, gen_loss = 0.6873526759445667, disc_loss = 0.18359620310366154
Trained batch 8 in epoch 1, gen_loss = 0.6819738447666168, disc_loss = 0.18356460498438942
Trained batch 9 in epoch 1, gen_loss = 0.6841924697160721, disc_loss = 0.1825628861784935
Trained batch 10 in epoch 1, gen_loss = 0.6825246838006106, disc_loss = 0.1796104542233727
Trained batch 11 in epoch 1, gen_loss = 0.687989371518294, disc_loss = 0.17732697849472365
Trained batch 12 in epoch 1, gen_loss = 0.6869060878570263, disc_loss = 0.17448744750939882
Trained batch 13 in epoch 1, gen_loss = 0.6878596097230911, disc_loss = 0.17230083686964853
Trained batch 14 in epoch 1, gen_loss = 0.7096415261427561, disc_loss = 0.1725072940190633
Trained batch 15 in epoch 1, gen_loss = 0.6977199148386717, disc_loss = 0.17962256260216236
Trained batch 16 in epoch 1, gen_loss = 0.7030008943641887, disc_loss = 0.1796258635380689
Trained batch 17 in epoch 1, gen_loss = 0.7209501514832178, disc_loss = 0.17555704961220422
Trained batch 18 in epoch 1, gen_loss = 0.7125162811655747, disc_loss = 0.1772276272899226
Trained batch 19 in epoch 1, gen_loss = 0.718030859529972, disc_loss = 0.17404646649956704
Trained batch 20 in epoch 1, gen_loss = 0.7231093716053736, disc_loss = 0.17246353697209132
Trained batch 21 in epoch 1, gen_loss = 0.7283208979801699, disc_loss = 0.16741981492801147
Trained batch 22 in epoch 1, gen_loss = 0.7269958166972451, disc_loss = 0.16649940415568973
Trained batch 23 in epoch 1, gen_loss = 0.7369934630890688, disc_loss = 0.16418353685488304
Trained batch 24 in epoch 1, gen_loss = 0.7459941589832306, disc_loss = 0.1594211584329605
Trained batch 25 in epoch 1, gen_loss = 0.7399565428495407, disc_loss = 0.16060133966115805
Trained batch 26 in epoch 1, gen_loss = 0.752688733515916, disc_loss = 0.16167517723860564
Trained batch 27 in epoch 1, gen_loss = 0.7590319950665746, disc_loss = 0.15704779193869658
Trained batch 28 in epoch 1, gen_loss = 0.7549565917459028, disc_loss = 0.15918318387763253
Trained batch 29 in epoch 1, gen_loss = 0.7563790529966354, disc_loss = 0.15617086018125217
Trained batch 30 in epoch 1, gen_loss = 0.7671910995437253, disc_loss = 0.1559842750430107
Trained batch 31 in epoch 1, gen_loss = 0.7783595072105527, disc_loss = 0.1518565324950032
Trained batch 32 in epoch 1, gen_loss = 0.7785753905773163, disc_loss = 0.14825421272579467
Trained batch 33 in epoch 1, gen_loss = 0.7797041491550558, disc_loss = 0.14596906890544822
Trained batch 34 in epoch 1, gen_loss = 0.7827835806778499, disc_loss = 0.14387685182903495
Trained batch 35 in epoch 1, gen_loss = 0.790063689980242, disc_loss = 0.1414569279489418
Trained batch 36 in epoch 1, gen_loss = 0.7923801049992845, disc_loss = 0.1382914617959712
Trained batch 37 in epoch 1, gen_loss = 0.8016384816483447, disc_loss = 0.13506651449164278
Trained batch 38 in epoch 1, gen_loss = 0.8079259922871223, disc_loss = 0.1320018710759588
Trained batch 39 in epoch 1, gen_loss = 0.812357795983553, disc_loss = 0.12914748305920512
Trained batch 40 in epoch 1, gen_loss = 0.8166888174487323, disc_loss = 0.1270028069479073
Trained batch 41 in epoch 1, gen_loss = 0.8245419952131453, disc_loss = 0.12472443213863742
Trained batch 42 in epoch 1, gen_loss = 0.8286308722440586, disc_loss = 0.1224866138857811
Trained batch 43 in epoch 1, gen_loss = 0.8348032242872498, disc_loss = 0.12021151187152347
Trained batch 44 in epoch 1, gen_loss = 0.8423014991813236, disc_loss = 0.11843239004827208
Trained batch 45 in epoch 1, gen_loss = 0.8503015332895777, disc_loss = 0.11832186824682614
Trained batch 46 in epoch 1, gen_loss = 0.8594328120667883, disc_loss = 0.12123996639584607
Trained batch 47 in epoch 1, gen_loss = 0.8656091000884771, disc_loss = 0.12064446246949956
Trained batch 48 in epoch 1, gen_loss = 0.8713348039558956, disc_loss = 0.11908077070375486
Trained batch 49 in epoch 1, gen_loss = 0.8744963604211807, disc_loss = 0.11711563618853688
Trained batch 50 in epoch 1, gen_loss = 0.8783397960896585, disc_loss = 0.11510591499288292
Trained batch 51 in epoch 1, gen_loss = 0.8825940541349925, disc_loss = 0.11308123744451083
Trained batch 52 in epoch 1, gen_loss = 0.8865590528497156, disc_loss = 0.11110753594142087
Trained batch 53 in epoch 1, gen_loss = 0.890612468123436, disc_loss = 0.10916788600109241
Trained batch 54 in epoch 1, gen_loss = 0.8940212363546545, disc_loss = 0.10731621741909872
Trained batch 55 in epoch 1, gen_loss = 0.8964062934475285, disc_loss = 0.10563906257240367
Trained batch 56 in epoch 1, gen_loss = 0.8995471298694611, disc_loss = 0.10388107702397463
Trained batch 57 in epoch 1, gen_loss = 0.9027832546110811, disc_loss = 0.10220028505789051
Trained batch 58 in epoch 1, gen_loss = 0.9057432842456689, disc_loss = 0.10057787227018153
Trained batch 59 in epoch 1, gen_loss = 0.9080561007062594, disc_loss = 0.09898173817588637
Trained batch 60 in epoch 1, gen_loss = 0.9102989987271731, disc_loss = 0.09744731849822842
Trained batch 61 in epoch 1, gen_loss = 0.9131474692013956, disc_loss = 0.09596933561166929
Trained batch 62 in epoch 1, gen_loss = 0.9164816845977117, disc_loss = 0.09452689580974125
Trained batch 63 in epoch 1, gen_loss = 0.9184731733985245, disc_loss = 0.09312665434845258
Trained batch 64 in epoch 1, gen_loss = 0.9202664269850804, disc_loss = 0.09178281704393718
Trained batch 65 in epoch 1, gen_loss = 0.9224194039901098, disc_loss = 0.09052168161636501
Trained batch 66 in epoch 1, gen_loss = 0.9235493749824922, disc_loss = 0.08926168088314694
Trained batch 67 in epoch 1, gen_loss = 0.9242120687575901, disc_loss = 0.0881983580697766
Trained batch 68 in epoch 1, gen_loss = 0.9258676788945129, disc_loss = 0.08701520459051582
Trained batch 69 in epoch 1, gen_loss = 0.927403489606721, disc_loss = 0.08589930843029703
Trained batch 70 in epoch 1, gen_loss = 0.929293476779696, disc_loss = 0.08477904075677965
Trained batch 71 in epoch 1, gen_loss = 0.9312875026630031, disc_loss = 0.0837233763627915
Trained batch 72 in epoch 1, gen_loss = 0.9337827085632168, disc_loss = 0.08268414289779859
Trained batch 73 in epoch 1, gen_loss = 0.9330812438919738, disc_loss = 0.08185467609783283
Trained batch 74 in epoch 1, gen_loss = 0.9386860501766204, disc_loss = 0.0812522731969754
Trained batch 75 in epoch 1, gen_loss = 0.9425929553414646, disc_loss = 0.08037280355040964
Trained batch 76 in epoch 1, gen_loss = 0.9435452009950366, disc_loss = 0.07944020373722563
Trained batch 77 in epoch 1, gen_loss = 0.9430198077207956, disc_loss = 0.07878936892852952
Trained batch 78 in epoch 1, gen_loss = 0.9424569686002369, disc_loss = 0.07793459214883137
Trained batch 79 in epoch 1, gen_loss = 0.9436994154006243, disc_loss = 0.07721866805804893
Trained batch 80 in epoch 1, gen_loss = 0.9413323553256047, disc_loss = 0.07677305562214719
Trained batch 81 in epoch 1, gen_loss = 0.9405452220178232, disc_loss = 0.07644340503824557
Trained batch 82 in epoch 1, gen_loss = 0.9435001126973026, disc_loss = 0.07662366158946092
Trained batch 83 in epoch 1, gen_loss = 0.9435220335920652, disc_loss = 0.07627376549256344
Trained batch 84 in epoch 1, gen_loss = 0.9423133769456078, disc_loss = 0.07573681658900835
Trained batch 85 in epoch 1, gen_loss = 0.9391161775173142, disc_loss = 0.07566814827407863
Trained batch 86 in epoch 1, gen_loss = 0.9431045675414732, disc_loss = 0.07573640339033699
Trained batch 87 in epoch 1, gen_loss = 0.9409093094820326, disc_loss = 0.07567409858827225
Trained batch 88 in epoch 1, gen_loss = 0.9434540054101622, disc_loss = 0.07558721564500855
Trained batch 89 in epoch 1, gen_loss = 0.9440420856078465, disc_loss = 0.07484425593995386
Trained batch 90 in epoch 1, gen_loss = 0.9439550405675239, disc_loss = 0.0742315063969447
Trained batch 91 in epoch 1, gen_loss = 0.9441879628145177, disc_loss = 0.07355310545181451
Trained batch 92 in epoch 1, gen_loss = 0.9440880344119124, disc_loss = 0.07284849613744726
Trained batch 93 in epoch 1, gen_loss = 0.9440968363208974, disc_loss = 0.072166144748793
Trained batch 94 in epoch 1, gen_loss = 0.9439457049495296, disc_loss = 0.07145395991637518
Trained batch 95 in epoch 1, gen_loss = 0.9433601011211673, disc_loss = 0.07076057862529221
Trained batch 96 in epoch 1, gen_loss = 0.942518123339132, disc_loss = 0.07008194029043169
Trained batch 97 in epoch 1, gen_loss = 0.942024074342786, disc_loss = 0.06942115324948515
Trained batch 98 in epoch 1, gen_loss = 0.9414224591520097, disc_loss = 0.06876117105812135
Trained batch 99 in epoch 1, gen_loss = 0.9413716813921928, disc_loss = 0.06811105691129342
Trained batch 100 in epoch 1, gen_loss = 0.9409961597164078, disc_loss = 0.0674852991204635
Trained batch 101 in epoch 1, gen_loss = 0.9401341878315982, disc_loss = 0.06689488590357132
Trained batch 102 in epoch 1, gen_loss = 0.9408037028845074, disc_loss = 0.06634949896602159
Trained batch 103 in epoch 1, gen_loss = 0.9415210499786414, disc_loss = 0.06576094324387108
Trained batch 104 in epoch 1, gen_loss = 0.9413182306857336, disc_loss = 0.06518004812699343
Trained batch 105 in epoch 1, gen_loss = 0.9409073622159239, disc_loss = 0.06460289739485267
Trained batch 106 in epoch 1, gen_loss = 0.9404466450214386, disc_loss = 0.06402812651619663
Trained batch 107 in epoch 1, gen_loss = 0.9399878528934938, disc_loss = 0.06348098248579642
Trained batch 108 in epoch 1, gen_loss = 0.9399164688149724, disc_loss = 0.06293930055855543
Trained batch 109 in epoch 1, gen_loss = 0.9395421518520876, disc_loss = 0.06239711055743762
Trained batch 110 in epoch 1, gen_loss = 0.9390027617012058, disc_loss = 0.06186851244293959
Trained batch 111 in epoch 1, gen_loss = 0.9385856004165751, disc_loss = 0.061371167629009245
Trained batch 112 in epoch 1, gen_loss = 0.9381472776948878, disc_loss = 0.06088854369822791
Trained batch 113 in epoch 1, gen_loss = 0.9378946530714369, disc_loss = 0.0603802619183338
Trained batch 114 in epoch 1, gen_loss = 0.9375687124936477, disc_loss = 0.05988975762916
Trained batch 115 in epoch 1, gen_loss = 0.937189372192169, disc_loss = 0.05939927217871722
Trained batch 116 in epoch 1, gen_loss = 0.9370859441084739, disc_loss = 0.058917631721522055
Trained batch 117 in epoch 1, gen_loss = 0.9373713628215304, disc_loss = 0.05844813264251324
Trained batch 118 in epoch 1, gen_loss = 0.9372847798992606, disc_loss = 0.057985973783119135
Trained batch 119 in epoch 1, gen_loss = 0.9370161024232705, disc_loss = 0.05752249842043966
Trained batch 120 in epoch 1, gen_loss = 0.9364646217547172, disc_loss = 0.05706501213164061
Trained batch 121 in epoch 1, gen_loss = 0.9363354104952734, disc_loss = 0.05662266578197052
Trained batch 122 in epoch 1, gen_loss = 0.9359102624703229, disc_loss = 0.05618218723419539
Trained batch 123 in epoch 1, gen_loss = 0.9353492507530797, disc_loss = 0.05575286916404542
Trained batch 124 in epoch 1, gen_loss = 0.9353059751987457, disc_loss = 0.055330849492922426
Trained batch 125 in epoch 1, gen_loss = 0.9354585231769652, disc_loss = 0.054911537164275256
Trained batch 126 in epoch 1, gen_loss = 0.9352619396889303, disc_loss = 0.054497164974766456
Trained batch 127 in epoch 1, gen_loss = 0.9350261811632663, disc_loss = 0.05409263424371602
Trained batch 128 in epoch 1, gen_loss = 0.9345654967681382, disc_loss = 0.05369840828384193
Trained batch 129 in epoch 1, gen_loss = 0.934135969556295, disc_loss = 0.053305132133671294
Trained batch 130 in epoch 1, gen_loss = 0.9341708269283062, disc_loss = 0.0529222788719304
Trained batch 131 in epoch 1, gen_loss = 0.9339419470140429, disc_loss = 0.052539212017136655
Trained batch 132 in epoch 1, gen_loss = 0.9336928023879689, disc_loss = 0.052159784612056795
Trained batch 133 in epoch 1, gen_loss = 0.9328481801855031, disc_loss = 0.05179297102010572
Trained batch 134 in epoch 1, gen_loss = 0.9327653582449312, disc_loss = 0.051443511090689786
Trained batch 135 in epoch 1, gen_loss = 0.9327099689227694, disc_loss = 0.05108778264462564
Trained batch 136 in epoch 1, gen_loss = 0.9330039988033962, disc_loss = 0.050749943688525444
Trained batch 137 in epoch 1, gen_loss = 0.9332400255877039, disc_loss = 0.05040787254034987
Trained batch 138 in epoch 1, gen_loss = 0.9333852355857547, disc_loss = 0.050069598854593125
Trained batch 139 in epoch 1, gen_loss = 0.9332991461668696, disc_loss = 0.049736414139624686
Trained batch 140 in epoch 1, gen_loss = 0.933221217376966, disc_loss = 0.04940593824391617
Trained batch 141 in epoch 1, gen_loss = 0.9329404383897781, disc_loss = 0.049080668805940995
Trained batch 142 in epoch 1, gen_loss = 0.9327948895784525, disc_loss = 0.04875594865973596
Trained batch 143 in epoch 1, gen_loss = 0.9326996395571364, disc_loss = 0.04843642909771814
Trained batch 144 in epoch 1, gen_loss = 0.9327266132009441, disc_loss = 0.04811810188573496
Trained batch 145 in epoch 1, gen_loss = 0.9323130019315301, disc_loss = 0.047808317973099854
Trained batch 146 in epoch 1, gen_loss = 0.9318238689380438, disc_loss = 0.04749896603661786
Trained batch 147 in epoch 1, gen_loss = 0.9317270326050552, disc_loss = 0.04719556167539259
Trained batch 148 in epoch 1, gen_loss = 0.9318635629727536, disc_loss = 0.04689636996840971
Trained batch 149 in epoch 1, gen_loss = 0.9315831691026688, disc_loss = 0.04659675696088622
Trained batch 150 in epoch 1, gen_loss = 0.9312373425392125, disc_loss = 0.04631035173287159
Trained batch 151 in epoch 1, gen_loss = 0.9310783420346285, disc_loss = 0.04602735305486835
Trained batch 152 in epoch 1, gen_loss = 0.9309645347735461, disc_loss = 0.045740715465417095
Trained batch 153 in epoch 1, gen_loss = 0.9309201412773752, disc_loss = 0.04545860115874123
Trained batch 154 in epoch 1, gen_loss = 0.9310682898567569, disc_loss = 0.045182731588401144
Trained batch 155 in epoch 1, gen_loss = 0.9306979784980799, disc_loss = 0.04490615756740459
Trained batch 156 in epoch 1, gen_loss = 0.9305499923077358, disc_loss = 0.044636624761424055
Trained batch 157 in epoch 1, gen_loss = 0.9306662295815311, disc_loss = 0.04437054249552326
Trained batch 158 in epoch 1, gen_loss = 0.9305957977501851, disc_loss = 0.04411077567042326
Trained batch 159 in epoch 1, gen_loss = 0.930431448854506, disc_loss = 0.04385257523099426
Trained batch 160 in epoch 1, gen_loss = 0.930368356267858, disc_loss = 0.04359178253021438
Trained batch 161 in epoch 1, gen_loss = 0.9299440978117931, disc_loss = 0.04333471455165749
Trained batch 162 in epoch 1, gen_loss = 0.9295304086676405, disc_loss = 0.04307985113593721
Trained batch 163 in epoch 1, gen_loss = 0.929054530110301, disc_loss = 0.04283022209533445
Trained batch 164 in epoch 1, gen_loss = 0.9292993774919799, disc_loss = 0.0425846885374719
Trained batch 165 in epoch 1, gen_loss = 0.9290231399866472, disc_loss = 0.042344896680344433
Trained batch 166 in epoch 1, gen_loss = 0.928937060925775, disc_loss = 0.04210490886955717
Trained batch 167 in epoch 1, gen_loss = 0.928904922058185, disc_loss = 0.041866721139827166
Trained batch 168 in epoch 1, gen_loss = 0.9286694017035015, disc_loss = 0.04163559543357379
Trained batch 169 in epoch 1, gen_loss = 0.9281175243503907, disc_loss = 0.04140240951263181
Trained batch 170 in epoch 1, gen_loss = 0.9280056271985261, disc_loss = 0.041174157712559556
Trained batch 171 in epoch 1, gen_loss = 0.9276805417828782, disc_loss = 0.040948228417153926
Trained batch 172 in epoch 1, gen_loss = 0.9277475378072331, disc_loss = 0.04072613769945705
Trained batch 173 in epoch 1, gen_loss = 0.9275917515329931, disc_loss = 0.0405061248865182
Trained batch 174 in epoch 1, gen_loss = 0.927287084545408, disc_loss = 0.04029017246927002
Trained batch 175 in epoch 1, gen_loss = 0.9272714350372553, disc_loss = 0.04007799327783604
Trained batch 176 in epoch 1, gen_loss = 0.9270190796946401, disc_loss = 0.039864786967009014
Trained batch 177 in epoch 1, gen_loss = 0.9267335987827751, disc_loss = 0.03966082921683307
Trained batch 178 in epoch 1, gen_loss = 0.9267938208646614, disc_loss = 0.03945471301177964
Trained batch 179 in epoch 1, gen_loss = 0.9268989832864867, disc_loss = 0.039260745941687165
Trained batch 180 in epoch 1, gen_loss = 0.9271257583936934, disc_loss = 0.03906233483624454
Trained batch 181 in epoch 1, gen_loss = 0.9267303542448924, disc_loss = 0.03886335918099036
Trained batch 182 in epoch 1, gen_loss = 0.9263028517121175, disc_loss = 0.03866676252292052
Trained batch 183 in epoch 1, gen_loss = 0.9262397929054239, disc_loss = 0.03846622326186069
Trained batch 184 in epoch 1, gen_loss = 0.9261391683204754, disc_loss = 0.038267598376055624
Trained batch 185 in epoch 1, gen_loss = 0.926039334106189, disc_loss = 0.038072492082988824
Trained batch 186 in epoch 1, gen_loss = 0.9261174264119908, disc_loss = 0.03788125922562265
Trained batch 187 in epoch 1, gen_loss = 0.9260628916164662, disc_loss = 0.03769255916407193
Trained batch 188 in epoch 1, gen_loss = 0.9258714184243843, disc_loss = 0.037503174031227236
Trained batch 189 in epoch 1, gen_loss = 0.9256641044428474, disc_loss = 0.03731511837043064
Trained batch 190 in epoch 1, gen_loss = 0.9256724841619661, disc_loss = 0.037128823661825655
Trained batch 191 in epoch 1, gen_loss = 0.9255779157392681, disc_loss = 0.03694565330685388
Trained batch 192 in epoch 1, gen_loss = 0.9254439731027179, disc_loss = 0.03676756764183043
Trained batch 193 in epoch 1, gen_loss = 0.9254255222598302, disc_loss = 0.03658943005823098
Trained batch 194 in epoch 1, gen_loss = 0.9251256137322157, disc_loss = 0.03641259827269002
Trained batch 195 in epoch 1, gen_loss = 0.9250411015688157, disc_loss = 0.036236588478478014
Trained batch 196 in epoch 1, gen_loss = 0.9252217779607337, disc_loss = 0.0360674419331596
Trained batch 197 in epoch 1, gen_loss = 0.925188631270871, disc_loss = 0.03589731643465583
Trained batch 198 in epoch 1, gen_loss = 0.9251250677072822, disc_loss = 0.03572674967049055
Trained batch 199 in epoch 1, gen_loss = 0.9250649453699589, disc_loss = 0.035557725732214746
Trained batch 200 in epoch 1, gen_loss = 0.9248555550231269, disc_loss = 0.035396463842367505
Trained batch 201 in epoch 1, gen_loss = 0.9250727430133536, disc_loss = 0.035231668670375894
Trained batch 202 in epoch 1, gen_loss = 0.9250035337333021, disc_loss = 0.035074764881007775
Trained batch 203 in epoch 1, gen_loss = 0.9251731919015155, disc_loss = 0.0349286104570709
Trained batch 204 in epoch 1, gen_loss = 0.9240097102595539, disc_loss = 0.03506235758342394
Trained batch 205 in epoch 1, gen_loss = 0.9248247735419319, disc_loss = 0.03547292819373237
Trained batch 206 in epoch 1, gen_loss = 0.9230878397750394, disc_loss = 0.036206705864644854
Trained batch 207 in epoch 1, gen_loss = 0.9240388507739856, disc_loss = 0.038665974100765124
Trained batch 208 in epoch 1, gen_loss = 0.9227420526543303, disc_loss = 0.03942646537172167
Trained batch 209 in epoch 1, gen_loss = 0.9206697405803771, disc_loss = 0.04134739114060288
Trained batch 210 in epoch 1, gen_loss = 0.9200437056227317, disc_loss = 0.04246068539283287
Trained batch 211 in epoch 1, gen_loss = 0.9190213240261348, disc_loss = 0.043376741561827796
Trained batch 212 in epoch 1, gen_loss = 0.9178528697557853, disc_loss = 0.04402864687669445
Trained batch 213 in epoch 1, gen_loss = 0.9159915348358243, disc_loss = 0.0448139837168366
Trained batch 214 in epoch 1, gen_loss = 0.9144139005694278, disc_loss = 0.045531358639168185
Trained batch 215 in epoch 1, gen_loss = 0.9132395650225656, disc_loss = 0.04605047475477612
Trained batch 216 in epoch 1, gen_loss = 0.9121393565483357, disc_loss = 0.04656991309353283
Trained batch 217 in epoch 1, gen_loss = 0.9105623792344277, disc_loss = 0.0472324882386201
Trained batch 218 in epoch 1, gen_loss = 0.9099719683601432, disc_loss = 0.04772538070877393
Trained batch 219 in epoch 1, gen_loss = 0.9084955021739006, disc_loss = 0.048114605129442434
Trained batch 220 in epoch 1, gen_loss = 0.908600364470374, disc_loss = 0.048386901128211174
Trained batch 221 in epoch 1, gen_loss = 0.9075598334138458, disc_loss = 0.04855269450392272
Trained batch 222 in epoch 1, gen_loss = 0.9066596869128702, disc_loss = 0.04879842927437192
Trained batch 223 in epoch 1, gen_loss = 0.9066924850589463, disc_loss = 0.049209856178744564
Trained batch 224 in epoch 1, gen_loss = 0.9053142138322194, disc_loss = 0.049593803965383106
Trained batch 225 in epoch 1, gen_loss = 0.9053976067663294, disc_loss = 0.049976999995059675
Trained batch 226 in epoch 1, gen_loss = 0.903983030681568, disc_loss = 0.0508226413722868
Trained batch 227 in epoch 1, gen_loss = 0.9038446016217533, disc_loss = 0.05125422914626829
Trained batch 228 in epoch 1, gen_loss = 0.90309927544219, disc_loss = 0.05132985064621576
Trained batch 229 in epoch 1, gen_loss = 0.9020068188076434, disc_loss = 0.05155383942891722
Trained batch 230 in epoch 1, gen_loss = 0.901463376108186, disc_loss = 0.05198508912286201
Trained batch 231 in epoch 1, gen_loss = 0.9003427574603722, disc_loss = 0.05220013261162516
Trained batch 232 in epoch 1, gen_loss = 0.9002982614633863, disc_loss = 0.05252709820099143
Trained batch 233 in epoch 1, gen_loss = 0.9004030315539776, disc_loss = 0.052445703034854345
Trained batch 234 in epoch 1, gen_loss = 0.9009072913768443, disc_loss = 0.05231039817345903
Trained batch 235 in epoch 1, gen_loss = 0.9013694531079066, disc_loss = 0.05214856959232208
Trained batch 236 in epoch 1, gen_loss = 0.9027232033542439, disc_loss = 0.05202680982979415
Trained batch 237 in epoch 1, gen_loss = 0.9037994583364294, disc_loss = 0.051857028160432056
Trained batch 238 in epoch 1, gen_loss = 0.90416407647492, disc_loss = 0.05166817850055305
Trained batch 239 in epoch 1, gen_loss = 0.9043808665126563, disc_loss = 0.05148328675810868
Trained batch 240 in epoch 1, gen_loss = 0.9047180628133512, disc_loss = 0.05128652139091516
Trained batch 241 in epoch 1, gen_loss = 0.904891727507607, disc_loss = 0.051097340396921
Trained batch 242 in epoch 1, gen_loss = 0.905025620887309, disc_loss = 0.050908179884707486
Trained batch 243 in epoch 1, gen_loss = 0.9050037488341331, disc_loss = 0.050720727136053266
Trained batch 244 in epoch 1, gen_loss = 0.9047597095674398, disc_loss = 0.05056456976703235
Trained batch 245 in epoch 1, gen_loss = 0.9044762560264851, disc_loss = 0.050418798247639965
Trained batch 246 in epoch 1, gen_loss = 0.9048084386205866, disc_loss = 0.05028588530279485
Trained batch 247 in epoch 1, gen_loss = 0.9040331555710684, disc_loss = 0.05032769654081353
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 1.0097154378890991, disc_loss = 0.3053761422634125
Trained batch 1 in epoch 2, gen_loss = 0.7634217441082001, disc_loss = 0.43831516802310944
Trained batch 2 in epoch 2, gen_loss = 0.7808358867963155, disc_loss = 0.3586015999317169
Trained batch 3 in epoch 2, gen_loss = 0.7629693895578384, disc_loss = 0.347429022192955
Trained batch 4 in epoch 2, gen_loss = 0.7287887811660767, disc_loss = 0.3262358784675598
Trained batch 5 in epoch 2, gen_loss = 0.7429332037766775, disc_loss = 0.2913999830683072
Trained batch 6 in epoch 2, gen_loss = 0.7445568697793143, disc_loss = 0.2658225808824812
Trained batch 7 in epoch 2, gen_loss = 0.7248973324894905, disc_loss = 0.24792328476905823
Trained batch 8 in epoch 2, gen_loss = 0.726478636264801, disc_loss = 0.23309285855955547
Trained batch 9 in epoch 2, gen_loss = 0.7297450780868531, disc_loss = 0.21542711108922957
Trained batch 10 in epoch 2, gen_loss = 0.7147283879193392, disc_loss = 0.20767768811095844
Trained batch 11 in epoch 2, gen_loss = 0.7431733508904775, disc_loss = 0.20679772645235062
Trained batch 12 in epoch 2, gen_loss = 0.7256849774947534, disc_loss = 0.2077150849195627
Trained batch 13 in epoch 2, gen_loss = 0.7228711460317884, disc_loss = 0.2024943424122674
Trained batch 14 in epoch 2, gen_loss = 0.7408293962478638, disc_loss = 0.2075881024201711
Trained batch 15 in epoch 2, gen_loss = 0.726957343518734, disc_loss = 0.20684292260557413
Trained batch 16 in epoch 2, gen_loss = 0.7370706761584562, disc_loss = 0.2014883248245015
Trained batch 17 in epoch 2, gen_loss = 0.7313732405503591, disc_loss = 0.19733447167608473
Trained batch 18 in epoch 2, gen_loss = 0.7294499529035467, disc_loss = 0.19343567757230057
Trained batch 19 in epoch 2, gen_loss = 0.7294278740882874, disc_loss = 0.18689511567354203
Trained batch 20 in epoch 2, gen_loss = 0.7233881780079433, disc_loss = 0.18490482795806157
Trained batch 21 in epoch 2, gen_loss = 0.736931253563274, disc_loss = 0.18296514045108447
Trained batch 22 in epoch 2, gen_loss = 0.7390388561331708, disc_loss = 0.1762383513800476
Trained batch 23 in epoch 2, gen_loss = 0.730165995657444, disc_loss = 0.1753575986561676
Trained batch 24 in epoch 2, gen_loss = 0.7446720290184021, disc_loss = 0.18218738898634912
Trained batch 25 in epoch 2, gen_loss = 0.7485725810894599, disc_loss = 0.17621254218885532
Trained batch 26 in epoch 2, gen_loss = 0.744430994545972, disc_loss = 0.17649213072878342
Trained batch 27 in epoch 2, gen_loss = 0.7480310052633286, disc_loss = 0.17323804713253463
Trained batch 28 in epoch 2, gen_loss = 0.7455764351219967, disc_loss = 0.17238792841290607
Trained batch 29 in epoch 2, gen_loss = 0.7494732598463695, disc_loss = 0.17170516215264797
Trained batch 30 in epoch 2, gen_loss = 0.7420826785026058, disc_loss = 0.1731379850497169
Trained batch 31 in epoch 2, gen_loss = 0.7422021087259054, disc_loss = 0.17355713120196015
Trained batch 32 in epoch 2, gen_loss = 0.7459318403041724, disc_loss = 0.17086110117309022
Trained batch 33 in epoch 2, gen_loss = 0.7472270218765035, disc_loss = 0.1675081089796389
Trained batch 34 in epoch 2, gen_loss = 0.7539652824401856, disc_loss = 0.16315961373703822
Trained batch 35 in epoch 2, gen_loss = 0.745983256234063, disc_loss = 0.16708662340210545
Trained batch 36 in epoch 2, gen_loss = 0.7574695574270712, disc_loss = 0.1746868400557621
Trained batch 37 in epoch 2, gen_loss = 0.7536508644882002, disc_loss = 0.17344144908221146
Trained batch 38 in epoch 2, gen_loss = 0.7490924214705442, disc_loss = 0.1723622074111914
Trained batch 39 in epoch 2, gen_loss = 0.749220834672451, disc_loss = 0.17105448786169292
Trained batch 40 in epoch 2, gen_loss = 0.7472789200340829, disc_loss = 0.17053029904278313
Trained batch 41 in epoch 2, gen_loss = 0.7456543814568293, disc_loss = 0.16925415591824622
Trained batch 42 in epoch 2, gen_loss = 0.7438031213228092, disc_loss = 0.16766688626172932
Trained batch 43 in epoch 2, gen_loss = 0.7452197643843564, disc_loss = 0.16533979976719076
Trained batch 44 in epoch 2, gen_loss = 0.7446637895372179, disc_loss = 0.16355180558231142
Trained batch 45 in epoch 2, gen_loss = 0.7477468848228455, disc_loss = 0.16061619280473047
Trained batch 46 in epoch 2, gen_loss = 0.7451825129224899, disc_loss = 0.15887267396171043
Trained batch 47 in epoch 2, gen_loss = 0.7521548854808012, disc_loss = 0.15829180475945273
Trained batch 48 in epoch 2, gen_loss = 0.7475480291308189, disc_loss = 0.15947271168840174
Trained batch 49 in epoch 2, gen_loss = 0.7537482464313507, disc_loss = 0.15934089735150336
Trained batch 50 in epoch 2, gen_loss = 0.7531512987379935, disc_loss = 0.15678919139592087
Trained batch 51 in epoch 2, gen_loss = 0.7484883895287147, disc_loss = 0.15842576027632907
Trained batch 52 in epoch 2, gen_loss = 0.7532372519655047, disc_loss = 0.15945818869151035
Trained batch 53 in epoch 2, gen_loss = 0.750502712196774, disc_loss = 0.15902495429057767
Trained batch 54 in epoch 2, gen_loss = 0.7497850027951327, disc_loss = 0.15712985034016044
Trained batch 55 in epoch 2, gen_loss = 0.7483950672405106, disc_loss = 0.15592759691311844
Trained batch 56 in epoch 2, gen_loss = 0.7479711154050994, disc_loss = 0.1554340004202044
Trained batch 57 in epoch 2, gen_loss = 0.7510885010505545, disc_loss = 0.15300471605411892
Trained batch 58 in epoch 2, gen_loss = 0.7516095951452093, disc_loss = 0.15072006972159369
Trained batch 59 in epoch 2, gen_loss = 0.748408513267835, disc_loss = 0.15066930130124093
Trained batch 60 in epoch 2, gen_loss = 0.7563893980667239, disc_loss = 0.15179888879666564
Trained batch 61 in epoch 2, gen_loss = 0.7536043918901875, disc_loss = 0.15142850601865399
Trained batch 62 in epoch 2, gen_loss = 0.751570445204538, disc_loss = 0.15046834165141695
Trained batch 63 in epoch 2, gen_loss = 0.7548997784033418, disc_loss = 0.15112147224135697
Trained batch 64 in epoch 2, gen_loss = 0.7508061436506418, disc_loss = 0.1513163685798645
Trained batch 65 in epoch 2, gen_loss = 0.7503423591454824, disc_loss = 0.14991572792782928
Trained batch 66 in epoch 2, gen_loss = 0.7571558498624545, disc_loss = 0.14960506202569648
Trained batch 67 in epoch 2, gen_loss = 0.7594213424360051, disc_loss = 0.147683155229863
Trained batch 68 in epoch 2, gen_loss = 0.7572003542513087, disc_loss = 0.14734458135090012
Trained batch 69 in epoch 2, gen_loss = 0.7577346784727914, disc_loss = 0.1454829478370292
Trained batch 70 in epoch 2, gen_loss = 0.7644069245163824, disc_loss = 0.14459192212408697
Trained batch 71 in epoch 2, gen_loss = 0.7682264529996448, disc_loss = 0.14274378219205472
Trained batch 72 in epoch 2, gen_loss = 0.7708876508556001, disc_loss = 0.14097166931486294
Trained batch 73 in epoch 2, gen_loss = 0.7734799183703758, disc_loss = 0.1392713517227487
Trained batch 74 in epoch 2, gen_loss = 0.7778568847974141, disc_loss = 0.13751230916008353
Trained batch 75 in epoch 2, gen_loss = 0.7818240264528676, disc_loss = 0.13587914002250487
Trained batch 76 in epoch 2, gen_loss = 0.785308107927248, disc_loss = 0.13421133340203337
Trained batch 77 in epoch 2, gen_loss = 0.7883756596308488, disc_loss = 0.13258553942283377
Trained batch 78 in epoch 2, gen_loss = 0.7911936927445328, disc_loss = 0.1309683388688519
Trained batch 79 in epoch 2, gen_loss = 0.7935845069587231, disc_loss = 0.12938900361186825
Trained batch 80 in epoch 2, gen_loss = 0.7955976687831643, disc_loss = 0.12786595806778397
Trained batch 81 in epoch 2, gen_loss = 0.7982882355771413, disc_loss = 0.12635363865836818
Trained batch 82 in epoch 2, gen_loss = 0.8006428903843983, disc_loss = 0.12488848830752793
Trained batch 83 in epoch 2, gen_loss = 0.8023733390229089, disc_loss = 0.12343536479775571
Trained batch 84 in epoch 2, gen_loss = 0.8040948397973005, disc_loss = 0.12204084930503194
Trained batch 85 in epoch 2, gen_loss = 0.8061783306820448, disc_loss = 0.12066078242076951
Trained batch 86 in epoch 2, gen_loss = 0.8075955263499556, disc_loss = 0.11934462271834156
Trained batch 87 in epoch 2, gen_loss = 0.8090401474725116, disc_loss = 0.1180381086226341
Trained batch 88 in epoch 2, gen_loss = 0.8105380863286136, disc_loss = 0.11674150181777274
Trained batch 89 in epoch 2, gen_loss = 0.8121648828188578, disc_loss = 0.11548400699005773
Trained batch 90 in epoch 2, gen_loss = 0.8136407005917895, disc_loss = 0.11424684392001766
Trained batch 91 in epoch 2, gen_loss = 0.8152067518752554, disc_loss = 0.11303865651438094
Trained batch 92 in epoch 2, gen_loss = 0.8164913897873253, disc_loss = 0.11185971922892075
Trained batch 93 in epoch 2, gen_loss = 0.8179555725544057, disc_loss = 0.11070934673919877
Trained batch 94 in epoch 2, gen_loss = 0.8194662307438098, disc_loss = 0.1095788281631509
Trained batch 95 in epoch 2, gen_loss = 0.8207946829497814, disc_loss = 0.10852464438115324
Trained batch 96 in epoch 2, gen_loss = 0.8217574585344374, disc_loss = 0.10745913924447731
Trained batch 97 in epoch 2, gen_loss = 0.8226066274302346, disc_loss = 0.10641545947992756
Trained batch 98 in epoch 2, gen_loss = 0.8253105367072905, disc_loss = 0.10544867056534823
Trained batch 99 in epoch 2, gen_loss = 0.8272882145643234, disc_loss = 0.1044498805818148
Trained batch 100 in epoch 2, gen_loss = 0.8262590034173267, disc_loss = 0.10371643324419487
Trained batch 101 in epoch 2, gen_loss = 0.8276824425248539, disc_loss = 0.1027638635018329
Trained batch 102 in epoch 2, gen_loss = 0.8302598659274647, disc_loss = 0.10196286534158133
Trained batch 103 in epoch 2, gen_loss = 0.8317428569381053, disc_loss = 0.10101694207360896
Trained batch 104 in epoch 2, gen_loss = 0.8321177857262748, disc_loss = 0.10015760617818506
Trained batch 105 in epoch 2, gen_loss = 0.8321742572874393, disc_loss = 0.09933466445171397
Trained batch 106 in epoch 2, gen_loss = 0.831912920853802, disc_loss = 0.09857543490209103
Trained batch 107 in epoch 2, gen_loss = 0.8337493384325946, disc_loss = 0.09774604646911568
Trained batch 108 in epoch 2, gen_loss = 0.8348810432154105, disc_loss = 0.09692786365038279
Trained batch 109 in epoch 2, gen_loss = 0.8356229722499847, disc_loss = 0.09611681289335883
Trained batch 110 in epoch 2, gen_loss = 0.8345803908399634, disc_loss = 0.09549375246950165
Trained batch 111 in epoch 2, gen_loss = 0.8349565895540374, disc_loss = 0.09472865056886803
Trained batch 112 in epoch 2, gen_loss = 0.8350065566797172, disc_loss = 0.09396890945015557
Trained batch 113 in epoch 2, gen_loss = 0.836125621147323, disc_loss = 0.09321016088544734
Trained batch 114 in epoch 2, gen_loss = 0.8367231674816298, disc_loss = 0.0924357265578178
Trained batch 115 in epoch 2, gen_loss = 0.8384960124204899, disc_loss = 0.09170396474455002
Trained batch 116 in epoch 2, gen_loss = 0.8400877067166516, disc_loss = 0.09100155893148074
Trained batch 117 in epoch 2, gen_loss = 0.8411124909328203, disc_loss = 0.09027084001237369
Trained batch 118 in epoch 2, gen_loss = 0.8418867027058321, disc_loss = 0.08953963084921178
Trained batch 119 in epoch 2, gen_loss = 0.8427412460247675, disc_loss = 0.0890465930046048
Trained batch 120 in epoch 2, gen_loss = 0.8435838025463515, disc_loss = 0.0883579063056083
Trained batch 121 in epoch 2, gen_loss = 0.8444457200706982, disc_loss = 0.08766134691302527
Trained batch 122 in epoch 2, gen_loss = 0.8441428924963726, disc_loss = 0.08705873381937058
Trained batch 123 in epoch 2, gen_loss = 0.8457267207484092, disc_loss = 0.08641936115905523
Trained batch 124 in epoch 2, gen_loss = 0.8472545833587647, disc_loss = 0.0857846165932715
Trained batch 125 in epoch 2, gen_loss = 0.8483903005955711, disc_loss = 0.08512737916871196
Trained batch 126 in epoch 2, gen_loss = 0.8491454936387971, disc_loss = 0.0844749268437699
Trained batch 127 in epoch 2, gen_loss = 0.8500268901698291, disc_loss = 0.08383555236650864
Trained batch 128 in epoch 2, gen_loss = 0.8504077496454697, disc_loss = 0.0832041322195888
Trained batch 129 in epoch 2, gen_loss = 0.8510061273208032, disc_loss = 0.08258793704713194
Trained batch 130 in epoch 2, gen_loss = 0.8514656074174488, disc_loss = 0.08198736979135575
Trained batch 131 in epoch 2, gen_loss = 0.8524545006679766, disc_loss = 0.0813881984777805
Trained batch 132 in epoch 2, gen_loss = 0.8530085512569973, disc_loss = 0.08079759861321602
Trained batch 133 in epoch 2, gen_loss = 0.8539011349428945, disc_loss = 0.08021389212591379
Trained batch 134 in epoch 2, gen_loss = 0.85422790006355, disc_loss = 0.07964254172380876
Trained batch 135 in epoch 2, gen_loss = 0.8545726910233498, disc_loss = 0.07907548485501834
Trained batch 136 in epoch 2, gen_loss = 0.8549534382611296, disc_loss = 0.07851705980575542
Trained batch 137 in epoch 2, gen_loss = 0.8551309415395709, disc_loss = 0.07796213481544881
Trained batch 138 in epoch 2, gen_loss = 0.8553817688132361, disc_loss = 0.07741980799289568
Trained batch 139 in epoch 2, gen_loss = 0.8559868595429829, disc_loss = 0.07691281947024566
Trained batch 140 in epoch 2, gen_loss = 0.8548409630220832, disc_loss = 0.07666488478855224
Trained batch 141 in epoch 2, gen_loss = 0.8569291255003969, disc_loss = 0.07644953660939124
Trained batch 142 in epoch 2, gen_loss = 0.8589666035625484, disc_loss = 0.07596843190396765
Trained batch 143 in epoch 2, gen_loss = 0.8607775995300876, disc_loss = 0.07550355716618166
Trained batch 144 in epoch 2, gen_loss = 0.862799581577038, disc_loss = 0.07500828104495103
Trained batch 145 in epoch 2, gen_loss = 0.8646916375584799, disc_loss = 0.07451614018048044
Trained batch 146 in epoch 2, gen_loss = 0.8666666644771083, disc_loss = 0.07403275989658091
Trained batch 147 in epoch 2, gen_loss = 0.8686826523091342, disc_loss = 0.07363679630106089
Trained batch 148 in epoch 2, gen_loss = 0.8704140054299527, disc_loss = 0.07317891445139035
Trained batch 149 in epoch 2, gen_loss = 0.8717776985963186, disc_loss = 0.07274133453844116
Trained batch 150 in epoch 2, gen_loss = 0.8735559480079752, disc_loss = 0.07229232980903633
Trained batch 151 in epoch 2, gen_loss = 0.87503600630321, disc_loss = 0.07184326500818745
Trained batch 152 in epoch 2, gen_loss = 0.8763167752939112, disc_loss = 0.07142278906094897
Trained batch 153 in epoch 2, gen_loss = 0.877240863326308, disc_loss = 0.07098330652973216
Trained batch 154 in epoch 2, gen_loss = 0.8780948465870273, disc_loss = 0.07055320376905823
Trained batch 155 in epoch 2, gen_loss = 0.8783518385428649, disc_loss = 0.0701216545533568
Trained batch 156 in epoch 2, gen_loss = 0.8794126111990327, disc_loss = 0.06970069878868118
Trained batch 157 in epoch 2, gen_loss = 0.8807160005539278, disc_loss = 0.06927607773988849
Trained batch 158 in epoch 2, gen_loss = 0.8820923195694977, disc_loss = 0.06885502146448612
Trained batch 159 in epoch 2, gen_loss = 0.8836378958076239, disc_loss = 0.06846985156807932
Trained batch 160 in epoch 2, gen_loss = 0.8847054824325609, disc_loss = 0.06806239145966998
Trained batch 161 in epoch 2, gen_loss = 0.8856603867477841, disc_loss = 0.06765856817120364
Trained batch 162 in epoch 2, gen_loss = 0.8862142475104771, disc_loss = 0.06725581429621627
Trained batch 163 in epoch 2, gen_loss = 0.8869550388033797, disc_loss = 0.06686369353754833
Trained batch 164 in epoch 2, gen_loss = 0.8871898419929273, disc_loss = 0.06646840213727431
Trained batch 165 in epoch 2, gen_loss = 0.8874065951410547, disc_loss = 0.06607980328031356
Trained batch 166 in epoch 2, gen_loss = 0.8875971465053673, disc_loss = 0.065696726174618
Trained batch 167 in epoch 2, gen_loss = 0.8879654127217474, disc_loss = 0.06531699509165871
Trained batch 168 in epoch 2, gen_loss = 0.8885371928384318, disc_loss = 0.06493960002495097
Trained batch 169 in epoch 2, gen_loss = 0.8888526962083929, disc_loss = 0.06456753401674659
Trained batch 170 in epoch 2, gen_loss = 0.8890046261207402, disc_loss = 0.06419727919767583
Trained batch 171 in epoch 2, gen_loss = 0.8892328195100607, disc_loss = 0.06383402623793889
Trained batch 172 in epoch 2, gen_loss = 0.8892331164696313, disc_loss = 0.0634794091964625
Trained batch 173 in epoch 2, gen_loss = 0.8895335190597622, disc_loss = 0.06313898848321546
Trained batch 174 in epoch 2, gen_loss = 0.889486756324768, disc_loss = 0.06279750333965889
Trained batch 175 in epoch 2, gen_loss = 0.8892058814791116, disc_loss = 0.062458162488341754
Trained batch 176 in epoch 2, gen_loss = 0.8892545242094051, disc_loss = 0.062118299317277845
Trained batch 177 in epoch 2, gen_loss = 0.8889999228916811, disc_loss = 0.06177880837362301
Trained batch 178 in epoch 2, gen_loss = 0.8889271120785335, disc_loss = 0.06144320097681676
Trained batch 179 in epoch 2, gen_loss = 0.8890377011564042, disc_loss = 0.061110448237741366
Trained batch 180 in epoch 2, gen_loss = 0.8892405181299916, disc_loss = 0.06078877475547465
Trained batch 181 in epoch 2, gen_loss = 0.8893503215941754, disc_loss = 0.06047348482444739
Trained batch 182 in epoch 2, gen_loss = 0.8891016717165545, disc_loss = 0.060160774081726584
Trained batch 183 in epoch 2, gen_loss = 0.8891944046253744, disc_loss = 0.05987657085832958
Trained batch 184 in epoch 2, gen_loss = 0.8892621932802973, disc_loss = 0.059577852880859095
Trained batch 185 in epoch 2, gen_loss = 0.8894826878783524, disc_loss = 0.05926775974684685
Trained batch 186 in epoch 2, gen_loss = 0.8895220217857769, disc_loss = 0.058968380139020074
Trained batch 187 in epoch 2, gen_loss = 0.88948433354814, disc_loss = 0.058667121749207816
Trained batch 188 in epoch 2, gen_loss = 0.8893984420589669, disc_loss = 0.058373112644798185
Trained batch 189 in epoch 2, gen_loss = 0.889667798029749, disc_loss = 0.058076961422461625
Trained batch 190 in epoch 2, gen_loss = 0.8897313600435307, disc_loss = 0.057782345047922734
Trained batch 191 in epoch 2, gen_loss = 0.8891693310191234, disc_loss = 0.05754650638482417
Trained batch 192 in epoch 2, gen_loss = 0.8902359360857949, disc_loss = 0.05726533384216766
Trained batch 193 in epoch 2, gen_loss = 0.8906889195294724, disc_loss = 0.05698721314607591
Trained batch 194 in epoch 2, gen_loss = 0.8908092272587311, disc_loss = 0.05670447782852138
Trained batch 195 in epoch 2, gen_loss = 0.8908333687149749, disc_loss = 0.056433923866799365
Trained batch 196 in epoch 2, gen_loss = 0.8913540416562618, disc_loss = 0.05616650844186658
Trained batch 197 in epoch 2, gen_loss = 0.8919838149138172, disc_loss = 0.055901796384150104
Trained batch 198 in epoch 2, gen_loss = 0.8920445792639076, disc_loss = 0.055629119782441824
Trained batch 199 in epoch 2, gen_loss = 0.8920706269145012, disc_loss = 0.05536729769199155
Trained batch 200 in epoch 2, gen_loss = 0.8919816696228673, disc_loss = 0.05510131920460815
Trained batch 201 in epoch 2, gen_loss = 0.8924317362875042, disc_loss = 0.05484077824270445
Trained batch 202 in epoch 2, gen_loss = 0.8924152075950735, disc_loss = 0.05458080577962284
Trained batch 203 in epoch 2, gen_loss = 0.8928953987710616, disc_loss = 0.05432310184765169
Trained batch 204 in epoch 2, gen_loss = 0.8927415062741535, disc_loss = 0.054065607042369866
Trained batch 205 in epoch 2, gen_loss = 0.8930746166451463, disc_loss = 0.053810574077024546
Trained batch 206 in epoch 2, gen_loss = 0.892872909416899, disc_loss = 0.053565133874786
Trained batch 207 in epoch 2, gen_loss = 0.8929704496493707, disc_loss = 0.053316908191146255
Trained batch 208 in epoch 2, gen_loss = 0.8929759169879713, disc_loss = 0.05307273921984555
Trained batch 209 in epoch 2, gen_loss = 0.8933245156492505, disc_loss = 0.05282735074593109
Trained batch 210 in epoch 2, gen_loss = 0.8933707724250324, disc_loss = 0.052582944239604495
Trained batch 211 in epoch 2, gen_loss = 0.8932935781074021, disc_loss = 0.05234103031315893
Trained batch 212 in epoch 2, gen_loss = 0.8933389850065742, disc_loss = 0.05209986602410919
Trained batch 213 in epoch 2, gen_loss = 0.8933406079483923, disc_loss = 0.051862933666436614
Trained batch 214 in epoch 2, gen_loss = 0.8935741044754206, disc_loss = 0.05162766938271044
Trained batch 215 in epoch 2, gen_loss = 0.8936299358805021, disc_loss = 0.05139545284166363
Trained batch 216 in epoch 2, gen_loss = 0.893541220421066, disc_loss = 0.05116393600916704
Trained batch 217 in epoch 2, gen_loss = 0.8933322022267438, disc_loss = 0.05093355968897872
Trained batch 218 in epoch 2, gen_loss = 0.8932698096858857, disc_loss = 0.05070495732409293
Trained batch 219 in epoch 2, gen_loss = 0.8931859588081187, disc_loss = 0.05047805671373763
Trained batch 220 in epoch 2, gen_loss = 0.8931655659934514, disc_loss = 0.05025343755412872
Trained batch 221 in epoch 2, gen_loss = 0.8930960316378791, disc_loss = 0.050033117355285886
Trained batch 222 in epoch 2, gen_loss = 0.8926171318297963, disc_loss = 0.04981347952625869
Trained batch 223 in epoch 2, gen_loss = 0.8926687519997358, disc_loss = 0.049598478388621255
Trained batch 224 in epoch 2, gen_loss = 0.8926281118392945, disc_loss = 0.049382333719533766
Trained batch 225 in epoch 2, gen_loss = 0.8925353705355551, disc_loss = 0.04916900455507664
Trained batch 226 in epoch 2, gen_loss = 0.8925691422911992, disc_loss = 0.048959453009932596
Trained batch 227 in epoch 2, gen_loss = 0.8927021933752194, disc_loss = 0.04875058934665408
Trained batch 228 in epoch 2, gen_loss = 0.8929037399687622, disc_loss = 0.048550530359419426
Trained batch 229 in epoch 2, gen_loss = 0.8927838696085888, disc_loss = 0.04834809322137912
Trained batch 230 in epoch 2, gen_loss = 0.8928231086049762, disc_loss = 0.048145083999573714
Trained batch 231 in epoch 2, gen_loss = 0.8927723929799837, disc_loss = 0.047947270893802914
Trained batch 232 in epoch 2, gen_loss = 0.8926832527561761, disc_loss = 0.04774992944559786
Trained batch 233 in epoch 2, gen_loss = 0.8928720490035847, disc_loss = 0.04755230556748624
Trained batch 234 in epoch 2, gen_loss = 0.8928565530066794, disc_loss = 0.047359385041450645
Trained batch 235 in epoch 2, gen_loss = 0.8928868944867182, disc_loss = 0.04716377661457893
Trained batch 236 in epoch 2, gen_loss = 0.8928699644306038, disc_loss = 0.04697933100789731
Trained batch 237 in epoch 2, gen_loss = 0.8928075735809422, disc_loss = 0.04679377472831304
Trained batch 238 in epoch 2, gen_loss = 0.8925924463252143, disc_loss = 0.04660766596626296
Trained batch 239 in epoch 2, gen_loss = 0.8924405964712302, disc_loss = 0.04641799525149205
Trained batch 240 in epoch 2, gen_loss = 0.8924463732608621, disc_loss = 0.04623397142472735
Trained batch 241 in epoch 2, gen_loss = 0.8925196067853407, disc_loss = 0.046061563664664365
Trained batch 242 in epoch 2, gen_loss = 0.8923638823591633, disc_loss = 0.04588060786036407
Trained batch 243 in epoch 2, gen_loss = 0.8922620496300401, disc_loss = 0.04570334914763512
Trained batch 244 in epoch 2, gen_loss = 0.8922129628609637, disc_loss = 0.04552234205136988
Trained batch 245 in epoch 2, gen_loss = 0.8922554598591192, disc_loss = 0.04534231940103596
Trained batch 246 in epoch 2, gen_loss = 0.8921344622909299, disc_loss = 0.04516357839176326
Trained batch 247 in epoch 2, gen_loss = 0.8920045848334989, disc_loss = 0.04498547989280797
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 0.8722831010818481, disc_loss = 0.0008984630112536252
Trained batch 1 in epoch 3, gen_loss = 0.8678756952285767, disc_loss = 0.0009047103521879762
Trained batch 2 in epoch 3, gen_loss = 0.8784354527791342, disc_loss = 0.0009757652684735755
Trained batch 3 in epoch 3, gen_loss = 0.8903343975543976, disc_loss = 0.0010006866214098409
Trained batch 4 in epoch 3, gen_loss = 0.8758134841918945, disc_loss = 0.0010126684443093835
Trained batch 5 in epoch 3, gen_loss = 0.8763133784135183, disc_loss = 0.0009814754109053563
Trained batch 6 in epoch 3, gen_loss = 0.8725396990776062, disc_loss = 0.000954906946779894
Trained batch 7 in epoch 3, gen_loss = 0.872328370809555, disc_loss = 0.000984474208962638
Trained batch 8 in epoch 3, gen_loss = 0.8670910596847534, disc_loss = 0.0009658971749660042
Trained batch 9 in epoch 3, gen_loss = 0.8670943856239319, disc_loss = 0.000982317072339356
Trained batch 10 in epoch 3, gen_loss = 0.8676957000385631, disc_loss = 0.0009820345387032087
Trained batch 11 in epoch 3, gen_loss = 0.8685926596323649, disc_loss = 0.0009705657284939662
Trained batch 12 in epoch 3, gen_loss = 0.8684297295717093, disc_loss = 0.0010103184076097722
Trained batch 13 in epoch 3, gen_loss = 0.8660301438399723, disc_loss = 0.0009994165198544838
Trained batch 14 in epoch 3, gen_loss = 0.8688607573509216, disc_loss = 0.000989977231559654
Trained batch 15 in epoch 3, gen_loss = 0.8678542338311672, disc_loss = 0.001070169084414374
Trained batch 16 in epoch 3, gen_loss = 0.8665982519879061, disc_loss = 0.0011064643656615825
Trained batch 17 in epoch 3, gen_loss = 0.8646815717220306, disc_loss = 0.0011052155039376682
Trained batch 18 in epoch 3, gen_loss = 0.8661424078439411, disc_loss = 0.001091411986731385
Trained batch 19 in epoch 3, gen_loss = 0.8678201586008072, disc_loss = 0.0010828317201230675
Trained batch 20 in epoch 3, gen_loss = 0.8687799345879328, disc_loss = 0.001075010070399869
Trained batch 21 in epoch 3, gen_loss = 0.8673517947847192, disc_loss = 0.0010818665191023188
Trained batch 22 in epoch 3, gen_loss = 0.8667188649592192, disc_loss = 0.001077848830786736
Trained batch 23 in epoch 3, gen_loss = 0.8665247435371081, disc_loss = 0.0010670939494351235
Trained batch 24 in epoch 3, gen_loss = 0.8675578474998474, disc_loss = 0.0010958698368631304
Trained batch 25 in epoch 3, gen_loss = 0.8674200154267825, disc_loss = 0.001107972578700775
Trained batch 26 in epoch 3, gen_loss = 0.8679881669856884, disc_loss = 0.0011205610978693046
Trained batch 27 in epoch 3, gen_loss = 0.8690694570541382, disc_loss = 0.0011399394362732501
Trained batch 28 in epoch 3, gen_loss = 0.8693708530787764, disc_loss = 0.0011295069005051307
Trained batch 29 in epoch 3, gen_loss = 0.8700770258903503, disc_loss = 0.0011198796234869709
Trained batch 30 in epoch 3, gen_loss = 0.8705101436184298, disc_loss = 0.0011293779281268438
Trained batch 31 in epoch 3, gen_loss = 0.870841957628727, disc_loss = 0.0011300362111796858
Trained batch 32 in epoch 3, gen_loss = 0.8725463260303844, disc_loss = 0.0011306937914482798
Trained batch 33 in epoch 3, gen_loss = 0.8740733616492328, disc_loss = 0.00112699533244321
Trained batch 34 in epoch 3, gen_loss = 0.8751955253737314, disc_loss = 0.0011396113999320992
Trained batch 35 in epoch 3, gen_loss = 0.8746630301078161, disc_loss = 0.0011573374908443333
Trained batch 36 in epoch 3, gen_loss = 0.8748184974129135, disc_loss = 0.001145738678845904
Trained batch 37 in epoch 3, gen_loss = 0.875649000469007, disc_loss = 0.001240259488297038
Trained batch 38 in epoch 3, gen_loss = 0.8736294538546832, disc_loss = 0.0012864791355334604
Trained batch 39 in epoch 3, gen_loss = 0.872573459148407, disc_loss = 0.0012832971915486269
Trained batch 40 in epoch 3, gen_loss = 0.8733900392927775, disc_loss = 0.0012774581313928272
Trained batch 41 in epoch 3, gen_loss = 0.8724934841905322, disc_loss = 0.001276675430181924
Trained batch 42 in epoch 3, gen_loss = 0.8719950346059577, disc_loss = 0.0012729923676721058
Trained batch 43 in epoch 3, gen_loss = 0.8717449537732385, disc_loss = 0.0012598174309294502
Trained batch 44 in epoch 3, gen_loss = 0.871739387512207, disc_loss = 0.00125665434041164
Trained batch 45 in epoch 3, gen_loss = 0.870080160058063, disc_loss = 0.0012449036648436247
Trained batch 46 in epoch 3, gen_loss = 0.8700189463635708, disc_loss = 0.0012402519734794313
Trained batch 47 in epoch 3, gen_loss = 0.8695134570201238, disc_loss = 0.0012299934460315853
Trained batch 48 in epoch 3, gen_loss = 0.8704583231283693, disc_loss = 0.0012260499595645436
Trained batch 49 in epoch 3, gen_loss = 0.870802776813507, disc_loss = 0.0012143506575375796
Trained batch 50 in epoch 3, gen_loss = 0.8710386823205387, disc_loss = 0.0012059957873277074
Trained batch 51 in epoch 3, gen_loss = 0.8709426591029534, disc_loss = 0.0011950802615431782
Trained batch 52 in epoch 3, gen_loss = 0.8722856292184794, disc_loss = 0.0011967620318140482
Trained batch 53 in epoch 3, gen_loss = 0.8728811321435151, disc_loss = 0.0011948250499295278
Trained batch 54 in epoch 3, gen_loss = 0.8731139443137429, disc_loss = 0.0011893580487759953
Trained batch 55 in epoch 3, gen_loss = 0.8728855858956065, disc_loss = 0.0011856990323784494
Trained batch 56 in epoch 3, gen_loss = 0.8734115184399119, disc_loss = 0.0011813004936189636
Trained batch 57 in epoch 3, gen_loss = 0.8739995781717629, disc_loss = 0.0011737283764824528
Trained batch 58 in epoch 3, gen_loss = 0.8739134022745035, disc_loss = 0.0011659030490791646
Trained batch 59 in epoch 3, gen_loss = 0.8730893929799398, disc_loss = 0.0011602021423944584
Trained batch 60 in epoch 3, gen_loss = 0.8730346003516776, disc_loss = 0.0011544818455567125
Trained batch 61 in epoch 3, gen_loss = 0.8736469428385457, disc_loss = 0.001151896277142148
Trained batch 62 in epoch 3, gen_loss = 0.8739580360669938, disc_loss = 0.0011462982640498215
Trained batch 63 in epoch 3, gen_loss = 0.873982759192586, disc_loss = 0.001142324750617263
Trained batch 64 in epoch 3, gen_loss = 0.8739843451059781, disc_loss = 0.001135819643520965
Trained batch 65 in epoch 3, gen_loss = 0.8739971961035873, disc_loss = 0.0011460788417466436
Trained batch 66 in epoch 3, gen_loss = 0.8737256242268121, disc_loss = 0.0011570621681496946
Trained batch 67 in epoch 3, gen_loss = 0.8734679704203325, disc_loss = 0.0011578428384382278
Trained batch 68 in epoch 3, gen_loss = 0.8736492835957071, disc_loss = 0.0011556398315841088
Trained batch 69 in epoch 3, gen_loss = 0.8747442185878753, disc_loss = 0.0011632694097767984
Trained batch 70 in epoch 3, gen_loss = 0.8741141507323359, disc_loss = 0.0011666295607246353
Trained batch 71 in epoch 3, gen_loss = 0.8740365530053774, disc_loss = 0.0011693807642182542
Trained batch 72 in epoch 3, gen_loss = 0.8743643213624823, disc_loss = 0.001168801814432524
Trained batch 73 in epoch 3, gen_loss = 0.8745872877739571, disc_loss = 0.001171728504846829
Trained batch 74 in epoch 3, gen_loss = 0.8753426146507263, disc_loss = 0.0011762373087306818
Trained batch 75 in epoch 3, gen_loss = 0.8748948001547864, disc_loss = 0.0011722794756918262
Trained batch 76 in epoch 3, gen_loss = 0.874878657328618, disc_loss = 0.001179488941984759
Trained batch 77 in epoch 3, gen_loss = 0.874448761726037, disc_loss = 0.001176206909197693
Trained batch 78 in epoch 3, gen_loss = 0.8743602633476257, disc_loss = 0.001171509472246553
Trained batch 79 in epoch 3, gen_loss = 0.8741184450685978, disc_loss = 0.001171036145387916
Trained batch 80 in epoch 3, gen_loss = 0.8735585529127239, disc_loss = 0.0011702801128217009
Trained batch 81 in epoch 3, gen_loss = 0.873621593161327, disc_loss = 0.0011691773507641855
Trained batch 82 in epoch 3, gen_loss = 0.8734334362558571, disc_loss = 0.0011641667245505713
Trained batch 83 in epoch 3, gen_loss = 0.8739128205038252, disc_loss = 0.0011623441858405602
Trained batch 84 in epoch 3, gen_loss = 0.8733227996265187, disc_loss = 0.0011756713837659096
Trained batch 85 in epoch 3, gen_loss = 0.8728391749914303, disc_loss = 0.001172390527519679
Trained batch 86 in epoch 3, gen_loss = 0.8725063321234166, disc_loss = 0.0011742427783226058
Trained batch 87 in epoch 3, gen_loss = 0.8725947981530969, disc_loss = 0.0011724248199078086
Trained batch 88 in epoch 3, gen_loss = 0.8728855212083023, disc_loss = 0.001173815627849211
Trained batch 89 in epoch 3, gen_loss = 0.8727293060885535, disc_loss = 0.001170454960083589
Trained batch 90 in epoch 3, gen_loss = 0.8728346831195957, disc_loss = 0.0011730642847276732
Trained batch 91 in epoch 3, gen_loss = 0.8728782716004745, disc_loss = 0.0011832826098923208
Trained batch 92 in epoch 3, gen_loss = 0.873618374588669, disc_loss = 0.0011898635352100497
Trained batch 93 in epoch 3, gen_loss = 0.8736846358218091, disc_loss = 0.0011877594620950441
Trained batch 94 in epoch 3, gen_loss = 0.873626202658603, disc_loss = 0.0011828620280874404
Trained batch 95 in epoch 3, gen_loss = 0.8738471337904533, disc_loss = 0.0011783606896642596
Trained batch 96 in epoch 3, gen_loss = 0.8737956605006739, disc_loss = 0.0011885641694798605
Trained batch 97 in epoch 3, gen_loss = 0.8737442967843037, disc_loss = 0.001187566290039341
Trained batch 98 in epoch 3, gen_loss = 0.8732973794744472, disc_loss = 0.0011866970712112056
Trained batch 99 in epoch 3, gen_loss = 0.873683769106865, disc_loss = 0.001182760871015489
Trained batch 100 in epoch 3, gen_loss = 0.8737362912385771, disc_loss = 0.0011787512777649825
Trained batch 101 in epoch 3, gen_loss = 0.873811359499015, disc_loss = 0.0011742854172446054
Trained batch 102 in epoch 3, gen_loss = 0.8740526808118357, disc_loss = 0.0011712934926956964
Trained batch 103 in epoch 3, gen_loss = 0.8738959569197434, disc_loss = 0.0011669134182739072
Trained batch 104 in epoch 3, gen_loss = 0.8737244549251738, disc_loss = 0.001161965740556341
Trained batch 105 in epoch 3, gen_loss = 0.8733515458286933, disc_loss = 0.0011623647368187964
Trained batch 106 in epoch 3, gen_loss = 0.8732049498602609, disc_loss = 0.0011597832748622887
Trained batch 107 in epoch 3, gen_loss = 0.8730535463050559, disc_loss = 0.0011555738046472132
Trained batch 108 in epoch 3, gen_loss = 0.8731161809842521, disc_loss = 0.0011523277594904424
Trained batch 109 in epoch 3, gen_loss = 0.8730319965969432, disc_loss = 0.0011495398950170388
Trained batch 110 in epoch 3, gen_loss = 0.8730052022246627, disc_loss = 0.0011453593185439975
Trained batch 111 in epoch 3, gen_loss = 0.8726790100336075, disc_loss = 0.0011422799533257993
Trained batch 112 in epoch 3, gen_loss = 0.8725336737337366, disc_loss = 0.0011408328551560046
Trained batch 113 in epoch 3, gen_loss = 0.8724435034551119, disc_loss = 0.0011404038028048123
Trained batch 114 in epoch 3, gen_loss = 0.8724733518517536, disc_loss = 0.0011376342285707916
Trained batch 115 in epoch 3, gen_loss = 0.8726062826041517, disc_loss = 0.0011349410031408329
Trained batch 116 in epoch 3, gen_loss = 0.8728354588533059, disc_loss = 0.001143029441213251
Trained batch 117 in epoch 3, gen_loss = 0.8727155782408633, disc_loss = 0.0011435668250561644
Trained batch 118 in epoch 3, gen_loss = 0.8729703947275627, disc_loss = 0.0011428077988905692
Trained batch 119 in epoch 3, gen_loss = 0.8730373660723368, disc_loss = 0.0011406889389036223
Trained batch 120 in epoch 3, gen_loss = 0.8732249337779588, disc_loss = 0.0011366641991733273
Trained batch 121 in epoch 3, gen_loss = 0.8728223584714483, disc_loss = 0.0011334820286958616
Trained batch 122 in epoch 3, gen_loss = 0.8727778898991221, disc_loss = 0.001130504598481414
Trained batch 123 in epoch 3, gen_loss = 0.8728282129572283, disc_loss = 0.0011272880773533197
Trained batch 124 in epoch 3, gen_loss = 0.8725845108032226, disc_loss = 0.0011242245617322623
Trained batch 125 in epoch 3, gen_loss = 0.8725199477067069, disc_loss = 0.001120465582177516
Trained batch 126 in epoch 3, gen_loss = 0.8724771048140338, disc_loss = 0.0011171942469517253
Trained batch 127 in epoch 3, gen_loss = 0.8725725873373449, disc_loss = 0.001113537668970821
Trained batch 128 in epoch 3, gen_loss = 0.8727203311846238, disc_loss = 0.001109705282223606
Trained batch 129 in epoch 3, gen_loss = 0.8729759986584004, disc_loss = 0.0011059708745541194
Trained batch 130 in epoch 3, gen_loss = 0.8725464389524387, disc_loss = 0.001103382568738871
Trained batch 131 in epoch 3, gen_loss = 0.872259160785964, disc_loss = 0.0011022569409705643
Trained batch 132 in epoch 3, gen_loss = 0.872325346882182, disc_loss = 0.0010988330551689224
Trained batch 133 in epoch 3, gen_loss = 0.872915227021744, disc_loss = 0.001096744507328788
Trained batch 134 in epoch 3, gen_loss = 0.872710848737646, disc_loss = 0.0010947590728324873
Trained batch 135 in epoch 3, gen_loss = 0.8725307496155009, disc_loss = 0.0010921914286240388
Trained batch 136 in epoch 3, gen_loss = 0.8725025627734887, disc_loss = 0.0010980589614406119
Trained batch 137 in epoch 3, gen_loss = 0.8721664854581805, disc_loss = 0.0011068935188856246
Trained batch 138 in epoch 3, gen_loss = 0.8725291902212788, disc_loss = 0.0011063069515533262
Trained batch 139 in epoch 3, gen_loss = 0.8725961940629142, disc_loss = 0.0011039648292353378
Trained batch 140 in epoch 3, gen_loss = 0.8723501829390831, disc_loss = 0.0011008863518153257
Trained batch 141 in epoch 3, gen_loss = 0.8720560699281558, disc_loss = 0.0010985654793535425
Trained batch 142 in epoch 3, gen_loss = 0.8720199123962776, disc_loss = 0.0011079224873451398
Trained batch 143 in epoch 3, gen_loss = 0.8719414253201749, disc_loss = 0.0011070249125219157
Trained batch 144 in epoch 3, gen_loss = 0.8715045431564594, disc_loss = 0.0011104023991281103
Trained batch 145 in epoch 3, gen_loss = 0.8716406467026228, disc_loss = 0.001109412272878578
Trained batch 146 in epoch 3, gen_loss = 0.8717788137546202, disc_loss = 0.0011100219424060058
Trained batch 147 in epoch 3, gen_loss = 0.8717200901057269, disc_loss = 0.0011075835850410717
Trained batch 148 in epoch 3, gen_loss = 0.8719760987582623, disc_loss = 0.0011055081568645852
Trained batch 149 in epoch 3, gen_loss = 0.8719969662030538, disc_loss = 0.001103583222332721
Trained batch 150 in epoch 3, gen_loss = 0.8720881765251918, disc_loss = 0.0011009431774851354
Trained batch 151 in epoch 3, gen_loss = 0.8719063322795065, disc_loss = 0.0010999081373723272
Trained batch 152 in epoch 3, gen_loss = 0.8717569151734994, disc_loss = 0.0010988770430950217
Trained batch 153 in epoch 3, gen_loss = 0.8719366827568451, disc_loss = 0.001102673510836389
Trained batch 154 in epoch 3, gen_loss = 0.8717282722073216, disc_loss = 0.0011020594437967145
Trained batch 155 in epoch 3, gen_loss = 0.8716052281550872, disc_loss = 0.001100537511191737
Trained batch 156 in epoch 3, gen_loss = 0.8715838782346932, disc_loss = 0.0010998637755075173
Trained batch 157 in epoch 3, gen_loss = 0.8712857241117502, disc_loss = 0.0010968979641123192
Trained batch 158 in epoch 3, gen_loss = 0.8711896017662384, disc_loss = 0.0010942820512320635
Trained batch 159 in epoch 3, gen_loss = 0.8711587157100439, disc_loss = 0.001092666398108122
Trained batch 160 in epoch 3, gen_loss = 0.871092673044027, disc_loss = 0.0010901418899949525
Trained batch 161 in epoch 3, gen_loss = 0.8711773447784377, disc_loss = 0.0010879455507232774
Trained batch 162 in epoch 3, gen_loss = 0.8713169492826871, disc_loss = 0.0010859753670130908
Trained batch 163 in epoch 3, gen_loss = 0.8713366127595669, disc_loss = 0.0010863786294244275
Trained batch 164 in epoch 3, gen_loss = 0.8711948864387743, disc_loss = 0.0010861680775909035
Trained batch 165 in epoch 3, gen_loss = 0.8713001267737653, disc_loss = 0.0010842554637999554
Trained batch 166 in epoch 3, gen_loss = 0.8714204337782488, disc_loss = 0.001082763389871082
Trained batch 167 in epoch 3, gen_loss = 0.8715172945743516, disc_loss = 0.0010827600452189689
Trained batch 168 in epoch 3, gen_loss = 0.8716281162211176, disc_loss = 0.0010804138642311449
Trained batch 169 in epoch 3, gen_loss = 0.8715060567154603, disc_loss = 0.0010789607086574987
Trained batch 170 in epoch 3, gen_loss = 0.8714534542713946, disc_loss = 0.0010756574212355615
Trained batch 171 in epoch 3, gen_loss = 0.8714020657677983, disc_loss = 0.0010731016041380678
Trained batch 172 in epoch 3, gen_loss = 0.8714546533678308, disc_loss = 0.00107000621521544
Trained batch 173 in epoch 3, gen_loss = 0.8713507470728337, disc_loss = 0.0010670031753406142
Trained batch 174 in epoch 3, gen_loss = 0.871225208895547, disc_loss = 0.0010642676098671343
Trained batch 175 in epoch 3, gen_loss = 0.8715251907706261, disc_loss = 0.0010624633548352656
Trained batch 176 in epoch 3, gen_loss = 0.8714845419603553, disc_loss = 0.001060270009454508
Trained batch 177 in epoch 3, gen_loss = 0.8714516387226876, disc_loss = 0.0010585237926871546
Trained batch 178 in epoch 3, gen_loss = 0.8715509958773352, disc_loss = 0.0010562634154732793
Trained batch 179 in epoch 3, gen_loss = 0.8717632436090046, disc_loss = 0.0010548747726716102
Trained batch 180 in epoch 3, gen_loss = 0.872090466444005, disc_loss = 0.0010542993402257767
Trained batch 181 in epoch 3, gen_loss = 0.8720247964937609, disc_loss = 0.001055221387714782
Trained batch 182 in epoch 3, gen_loss = 0.8720401600410378, disc_loss = 0.0010539892226930892
Trained batch 183 in epoch 3, gen_loss = 0.8719062212368717, disc_loss = 0.0010516498640873065
Trained batch 184 in epoch 3, gen_loss = 0.8717303743233552, disc_loss = 0.0010498114622424584
Trained batch 185 in epoch 3, gen_loss = 0.8718199034531912, disc_loss = 0.0010482326252586258
Trained batch 186 in epoch 3, gen_loss = 0.871811771775312, disc_loss = 0.001046130061087343
Trained batch 187 in epoch 3, gen_loss = 0.872155580748903, disc_loss = 0.0010442662692475232
Trained batch 188 in epoch 3, gen_loss = 0.8721035895524202, disc_loss = 0.001042609251160963
Trained batch 189 in epoch 3, gen_loss = 0.8720825264328405, disc_loss = 0.0010412735858392952
Trained batch 190 in epoch 3, gen_loss = 0.8721723372399495, disc_loss = 0.0010387574576075477
Trained batch 191 in epoch 3, gen_loss = 0.8720782743766904, disc_loss = 0.0010371577300247736
Trained batch 192 in epoch 3, gen_loss = 0.8720532473504852, disc_loss = 0.001034977809656315
Trained batch 193 in epoch 3, gen_loss = 0.8721111379947859, disc_loss = 0.0010335955675211304
Trained batch 194 in epoch 3, gen_loss = 0.872221967501518, disc_loss = 0.0010321954077181334
Trained batch 195 in epoch 3, gen_loss = 0.8721184770063478, disc_loss = 0.0010299070979402
Trained batch 196 in epoch 3, gen_loss = 0.8719508548073357, disc_loss = 0.0010285521875168693
Trained batch 197 in epoch 3, gen_loss = 0.8720405869411699, disc_loss = 0.0010281095940930147
Trained batch 198 in epoch 3, gen_loss = 0.872226366146126, disc_loss = 0.001029019587411166
Trained batch 199 in epoch 3, gen_loss = 0.8720357483625412, disc_loss = 0.0010300937556894495
Trained batch 200 in epoch 3, gen_loss = 0.87200034020552, disc_loss = 0.001029554584795674
Trained batch 201 in epoch 3, gen_loss = 0.8720543965844825, disc_loss = 0.0010281609484261954
Trained batch 202 in epoch 3, gen_loss = 0.8720871653462866, disc_loss = 0.0010260068126174214
Trained batch 203 in epoch 3, gen_loss = 0.872218959179579, disc_loss = 0.0010240288778304068
Trained batch 204 in epoch 3, gen_loss = 0.8722061584635479, disc_loss = 0.0010226901495692933
Trained batch 205 in epoch 3, gen_loss = 0.8724131804068112, disc_loss = 0.0010237462436599495
Trained batch 206 in epoch 3, gen_loss = 0.872392669967983, disc_loss = 0.001023900623721237
Trained batch 207 in epoch 3, gen_loss = 0.8724519189160603, disc_loss = 0.0010248534140723327
Trained batch 208 in epoch 3, gen_loss = 0.8724783556313036, disc_loss = 0.0010230148480714935
Trained batch 209 in epoch 3, gen_loss = 0.8724932974293118, disc_loss = 0.0010209836944427696
Trained batch 210 in epoch 3, gen_loss = 0.8725884068068734, disc_loss = 0.0010197649202839212
Trained batch 211 in epoch 3, gen_loss = 0.8725994780378522, disc_loss = 0.001017669703150256
Trained batch 212 in epoch 3, gen_loss = 0.8724492410538902, disc_loss = 0.001015797937059329
Trained batch 213 in epoch 3, gen_loss = 0.8722530115987653, disc_loss = 0.0010140647825558678
Trained batch 214 in epoch 3, gen_loss = 0.8725238658661066, disc_loss = 0.0010122140374056302
Trained batch 215 in epoch 3, gen_loss = 0.8725093357540943, disc_loss = 0.0010110897163502631
Trained batch 216 in epoch 3, gen_loss = 0.8724144425260306, disc_loss = 0.0010097113165420733
Trained batch 217 in epoch 3, gen_loss = 0.8723238323806622, disc_loss = 0.0010074549624290523
Trained batch 218 in epoch 3, gen_loss = 0.8721871155582063, disc_loss = 0.0010065427690544527
Trained batch 219 in epoch 3, gen_loss = 0.8722090783444318, disc_loss = 0.0010061690306015821
Trained batch 220 in epoch 3, gen_loss = 0.8723104828083676, disc_loss = 0.001004426296836195
Trained batch 221 in epoch 3, gen_loss = 0.8722853797513086, disc_loss = 0.0010024329863996288
Trained batch 222 in epoch 3, gen_loss = 0.872365955547367, disc_loss = 0.0010018379932829082
Trained batch 223 in epoch 3, gen_loss = 0.8722818251699209, disc_loss = 0.0010043248236927735
Trained batch 224 in epoch 3, gen_loss = 0.87251170290841, disc_loss = 0.0010042018288125595
Trained batch 225 in epoch 3, gen_loss = 0.8723319259892522, disc_loss = 0.0010085363688969375
Trained batch 226 in epoch 3, gen_loss = 0.8721981137859663, disc_loss = 0.0010075438647153521
Trained batch 227 in epoch 3, gen_loss = 0.8723168305137701, disc_loss = 0.00100851005322112
Trained batch 228 in epoch 3, gen_loss = 0.8723697540020838, disc_loss = 0.0010083171904522227
Trained batch 229 in epoch 3, gen_loss = 0.8722373534803806, disc_loss = 0.001007451267366338
Trained batch 230 in epoch 3, gen_loss = 0.8722275250401847, disc_loss = 0.0010079894113068134
Trained batch 231 in epoch 3, gen_loss = 0.8722138633501941, disc_loss = 0.0010078560133416463
Trained batch 232 in epoch 3, gen_loss = 0.8725260526837197, disc_loss = 0.0010075406291294251
Trained batch 233 in epoch 3, gen_loss = 0.8723864603755821, disc_loss = 0.0010058021881323084
Trained batch 234 in epoch 3, gen_loss = 0.872505137260924, disc_loss = 0.0010043651900908097
Trained batch 235 in epoch 3, gen_loss = 0.8724926775794918, disc_loss = 0.0010026462698726267
Trained batch 236 in epoch 3, gen_loss = 0.8724129225131328, disc_loss = 0.0010009939106424902
Trained batch 237 in epoch 3, gen_loss = 0.8723683339707992, disc_loss = 0.0009995605556896942
Trained batch 238 in epoch 3, gen_loss = 0.8723387890281039, disc_loss = 0.000997933224242991
Trained batch 239 in epoch 3, gen_loss = 0.8722081658740838, disc_loss = 0.0009971725640449828
Trained batch 240 in epoch 3, gen_loss = 0.8723459063229224, disc_loss = 0.000996154792659
Trained batch 241 in epoch 3, gen_loss = 0.8722937895246774, disc_loss = 0.0009953427763005394
Trained batch 242 in epoch 3, gen_loss = 0.8722897385373528, disc_loss = 0.0009941790332450482
Trained batch 243 in epoch 3, gen_loss = 0.872594453760835, disc_loss = 0.0009945844453721321
Trained batch 244 in epoch 3, gen_loss = 0.8726007661040949, disc_loss = 0.0009936316050494051
Trained batch 245 in epoch 3, gen_loss = 0.8723672705937208, disc_loss = 0.0009931049613013288
Trained batch 246 in epoch 3, gen_loss = 0.8723523389955281, disc_loss = 0.0009922017800519883
Trained batch 247 in epoch 3, gen_loss = 0.8724602564207969, disc_loss = 0.00099049767572245
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 0.8784775137901306, disc_loss = 0.0007483874214813113
Trained batch 1 in epoch 4, gen_loss = 0.8874552845954895, disc_loss = 0.0007910126005299389
Trained batch 2 in epoch 4, gen_loss = 0.8768071333567301, disc_loss = 0.0007102480158209801
Trained batch 3 in epoch 4, gen_loss = 0.8594486862421036, disc_loss = 0.000679818243952468
Trained batch 4 in epoch 4, gen_loss = 0.8570574879646301, disc_loss = 0.0007203886983916163
Trained batch 5 in epoch 4, gen_loss = 0.8549957176049551, disc_loss = 0.0007380891959959021
Trained batch 6 in epoch 4, gen_loss = 0.8541614413261414, disc_loss = 0.0008043200692294963
Trained batch 7 in epoch 4, gen_loss = 0.8608966693282127, disc_loss = 0.0007738320346106775
Trained batch 8 in epoch 4, gen_loss = 0.8608981834517585, disc_loss = 0.0007450360377940038
Trained batch 9 in epoch 4, gen_loss = 0.8616678416728973, disc_loss = 0.0007423554081469775
Trained batch 10 in epoch 4, gen_loss = 0.8636864857240156, disc_loss = 0.000738059234043414
Trained batch 11 in epoch 4, gen_loss = 0.8673702925443649, disc_loss = 0.0007410985029612979
Trained batch 12 in epoch 4, gen_loss = 0.8696575027245742, disc_loss = 0.0007654856532238997
Trained batch 13 in epoch 4, gen_loss = 0.8728887055601392, disc_loss = 0.0007773672030972582
Trained batch 14 in epoch 4, gen_loss = 0.8724637071291605, disc_loss = 0.000769968912936747
Trained batch 15 in epoch 4, gen_loss = 0.8717603199183941, disc_loss = 0.000752846484829206
Trained batch 16 in epoch 4, gen_loss = 0.8705209949437309, disc_loss = 0.0007537111831719385
Trained batch 17 in epoch 4, gen_loss = 0.8714833358923594, disc_loss = 0.000758314692777478
Trained batch 18 in epoch 4, gen_loss = 0.873923195035834, disc_loss = 0.000764803985427869
Trained batch 19 in epoch 4, gen_loss = 0.8763000428676605, disc_loss = 0.0007668864156585187
Trained batch 20 in epoch 4, gen_loss = 0.8783011862209865, disc_loss = 0.0007613809845809426
Trained batch 21 in epoch 4, gen_loss = 0.8788751282475211, disc_loss = 0.0007619584476659921
Trained batch 22 in epoch 4, gen_loss = 0.8784387163493944, disc_loss = 0.0007638787374953213
Trained batch 23 in epoch 4, gen_loss = 0.8783859113852183, disc_loss = 0.0007614278486774614
Trained batch 24 in epoch 4, gen_loss = 0.8782674741744995, disc_loss = 0.0007555127935484052
Trained batch 25 in epoch 4, gen_loss = 0.8777380585670471, disc_loss = 0.0007582553236996039
Trained batch 26 in epoch 4, gen_loss = 0.8799642545205576, disc_loss = 0.0007568584923218521
Trained batch 27 in epoch 4, gen_loss = 0.879537086401667, disc_loss = 0.0007535948887899784
Trained batch 28 in epoch 4, gen_loss = 0.8804874255739409, disc_loss = 0.0007506618015307548
Trained batch 29 in epoch 4, gen_loss = 0.87933509349823, disc_loss = 0.0007502069832601895
Trained batch 30 in epoch 4, gen_loss = 0.879938296733364, disc_loss = 0.0007508945812831723
Trained batch 31 in epoch 4, gen_loss = 0.8793747220188379, disc_loss = 0.0007462164448952535
Trained batch 32 in epoch 4, gen_loss = 0.8793704455549066, disc_loss = 0.0007418168260659459
Trained batch 33 in epoch 4, gen_loss = 0.8789967158261467, disc_loss = 0.0007462885336923029
Trained batch 34 in epoch 4, gen_loss = 0.8777825270380293, disc_loss = 0.0007441892770917288
Trained batch 35 in epoch 4, gen_loss = 0.8772408250305388, disc_loss = 0.0007500369053256387
Trained batch 36 in epoch 4, gen_loss = 0.8776897594735429, disc_loss = 0.0007527068389478971
Trained batch 37 in epoch 4, gen_loss = 0.8778257793501804, disc_loss = 0.0007529128036510787
Trained batch 38 in epoch 4, gen_loss = 0.8787504128920727, disc_loss = 0.0007539936057769526
Trained batch 39 in epoch 4, gen_loss = 0.8798058524727821, disc_loss = 0.0007540651902672834
Trained batch 40 in epoch 4, gen_loss = 0.8792139786045726, disc_loss = 0.0007500451898611174
Trained batch 41 in epoch 4, gen_loss = 0.8798380763757796, disc_loss = 0.0007461050187148864
Trained batch 42 in epoch 4, gen_loss = 0.8790707588195801, disc_loss = 0.0007422536755045659
Trained batch 43 in epoch 4, gen_loss = 0.8786320781165903, disc_loss = 0.0007403427946635268
Trained batch 44 in epoch 4, gen_loss = 0.87828582127889, disc_loss = 0.0007420875804705753
Trained batch 45 in epoch 4, gen_loss = 0.8773335322089817, disc_loss = 0.0007413309776102719
Trained batch 46 in epoch 4, gen_loss = 0.8767158490546206, disc_loss = 0.0007553212047415845
Trained batch 47 in epoch 4, gen_loss = 0.8769686780869961, disc_loss = 0.0007586561575105103
Trained batch 48 in epoch 4, gen_loss = 0.8771096626106574, disc_loss = 0.000782702488786712
Trained batch 49 in epoch 4, gen_loss = 0.8772408306598664, disc_loss = 0.0007805482647381723
Trained batch 50 in epoch 4, gen_loss = 0.8775997430670495, disc_loss = 0.0007822006705728377
Trained batch 51 in epoch 4, gen_loss = 0.8776364498413526, disc_loss = 0.0007805179350096016
Trained batch 52 in epoch 4, gen_loss = 0.8781063624148099, disc_loss = 0.0007764160586960332
Trained batch 53 in epoch 4, gen_loss = 0.8784840923768503, disc_loss = 0.000772436292781667
Trained batch 54 in epoch 4, gen_loss = 0.8787239150567488, disc_loss = 0.0007735713628459383
Trained batch 55 in epoch 4, gen_loss = 0.8782885851604598, disc_loss = 0.0007715558936719649
Trained batch 56 in epoch 4, gen_loss = 0.8779603546125847, disc_loss = 0.000770060166822779
Trained batch 57 in epoch 4, gen_loss = 0.8775854922574142, disc_loss = 0.0007680328653177953
Trained batch 58 in epoch 4, gen_loss = 0.8777548943535757, disc_loss = 0.0007638975778610399
Trained batch 59 in epoch 4, gen_loss = 0.8785527835289637, disc_loss = 0.0007701782965644573
Trained batch 60 in epoch 4, gen_loss = 0.8789180448797883, disc_loss = 0.0007669249650655833
Trained batch 61 in epoch 4, gen_loss = 0.87883466578299, disc_loss = 0.0007662692251840546
Trained batch 62 in epoch 4, gen_loss = 0.8783171933794779, disc_loss = 0.0007654211330523212
Trained batch 63 in epoch 4, gen_loss = 0.8784062704071403, disc_loss = 0.0007683422691115993
Trained batch 64 in epoch 4, gen_loss = 0.8784477756573603, disc_loss = 0.0007687950372481002
Trained batch 65 in epoch 4, gen_loss = 0.8783797106959603, disc_loss = 0.0007716667526189915
Trained batch 66 in epoch 4, gen_loss = 0.8778603317132637, disc_loss = 0.0007709945784881711
Trained batch 67 in epoch 4, gen_loss = 0.8780791917267967, disc_loss = 0.0007676718249807463
Trained batch 68 in epoch 4, gen_loss = 0.8778762782829396, disc_loss = 0.000764570588691403
Trained batch 69 in epoch 4, gen_loss = 0.8777634331158229, disc_loss = 0.0007646882457525603
Trained batch 70 in epoch 4, gen_loss = 0.8772427699935268, disc_loss = 0.0007618078986563208
Trained batch 71 in epoch 4, gen_loss = 0.8776681439744102, disc_loss = 0.0007604534314143368
Trained batch 72 in epoch 4, gen_loss = 0.8780707716941833, disc_loss = 0.0007579220811300592
Trained batch 73 in epoch 4, gen_loss = 0.8782221054708635, disc_loss = 0.0007547495258984634
Trained batch 74 in epoch 4, gen_loss = 0.8786498053868612, disc_loss = 0.0007520829575757185
Trained batch 75 in epoch 4, gen_loss = 0.8790355983533358, disc_loss = 0.0007488923874916509
Trained batch 76 in epoch 4, gen_loss = 0.8793052543293346, disc_loss = 0.0007468225342197368
Trained batch 77 in epoch 4, gen_loss = 0.8788373944086906, disc_loss = 0.0007435066225484777
Trained batch 78 in epoch 4, gen_loss = 0.878948718686647, disc_loss = 0.0007407084907570123
Trained batch 79 in epoch 4, gen_loss = 0.8794910907745361, disc_loss = 0.000740035133640049
Trained batch 80 in epoch 4, gen_loss = 0.8793868591755997, disc_loss = 0.000739115242915297
Trained batch 81 in epoch 4, gen_loss = 0.8790590079819284, disc_loss = 0.0007381141199957488
Trained batch 82 in epoch 4, gen_loss = 0.8791525866611895, disc_loss = 0.0007369732049417244
Trained batch 83 in epoch 4, gen_loss = 0.8789151296729133, disc_loss = 0.0007356042416566717
Trained batch 84 in epoch 4, gen_loss = 0.8791941046714783, disc_loss = 0.0007349017589791295
Trained batch 85 in epoch 4, gen_loss = 0.8792351955591247, disc_loss = 0.000732771210307472
Trained batch 86 in epoch 4, gen_loss = 0.8794676695746937, disc_loss = 0.0007306245615941355
Trained batch 87 in epoch 4, gen_loss = 0.8798193667422641, disc_loss = 0.0007294309497493404
Trained batch 88 in epoch 4, gen_loss = 0.8794196127505784, disc_loss = 0.0007279520563969619
Trained batch 89 in epoch 4, gen_loss = 0.8795265151394738, disc_loss = 0.0007262342687075336
Trained batch 90 in epoch 4, gen_loss = 0.879258312366821, disc_loss = 0.000724222287817111
Trained batch 91 in epoch 4, gen_loss = 0.8796110762202222, disc_loss = 0.0007225643171493531
Trained batch 92 in epoch 4, gen_loss = 0.8796330446838051, disc_loss = 0.0007207836093310948
Trained batch 93 in epoch 4, gen_loss = 0.8797495162233393, disc_loss = 0.000718546721668161
Trained batch 94 in epoch 4, gen_loss = 0.8800481030815526, disc_loss = 0.0007185970898717642
Trained batch 95 in epoch 4, gen_loss = 0.8802591233203808, disc_loss = 0.0007158053322200431
Trained batch 96 in epoch 4, gen_loss = 0.880282193729558, disc_loss = 0.0007135068629292253
Trained batch 97 in epoch 4, gen_loss = 0.8801177758343366, disc_loss = 0.0007119718826214345
Trained batch 98 in epoch 4, gen_loss = 0.8802288150546527, disc_loss = 0.0007112445974148659
Trained batch 99 in epoch 4, gen_loss = 0.8803187865018844, disc_loss = 0.0007119177660206333
Trained batch 100 in epoch 4, gen_loss = 0.8801305282233965, disc_loss = 0.0007134121825392957
Trained batch 101 in epoch 4, gen_loss = 0.8794944070133508, disc_loss = 0.0007117498465174553
Trained batch 102 in epoch 4, gen_loss = 0.8793461999846893, disc_loss = 0.0007090829437128404
Trained batch 103 in epoch 4, gen_loss = 0.8796655082931886, disc_loss = 0.0007121804206130597
Trained batch 104 in epoch 4, gen_loss = 0.8794938002313887, disc_loss = 0.0007238890576575484
Trained batch 105 in epoch 4, gen_loss = 0.8793300502705124, disc_loss = 0.000726524926063095
Trained batch 106 in epoch 4, gen_loss = 0.8790410601090048, disc_loss = 0.0007278960269971568
Trained batch 107 in epoch 4, gen_loss = 0.8793024553192986, disc_loss = 0.0007354531898508194
Trained batch 108 in epoch 4, gen_loss = 0.8793059193759883, disc_loss = 0.0007387765911792259
Trained batch 109 in epoch 4, gen_loss = 0.8793009627949108, disc_loss = 0.0007426820282655007
Trained batch 110 in epoch 4, gen_loss = 0.8792671555871362, disc_loss = 0.0007436026400584426
Trained batch 111 in epoch 4, gen_loss = 0.8794379191739219, disc_loss = 0.0007424350598219982
Trained batch 112 in epoch 4, gen_loss = 0.8795558715288618, disc_loss = 0.0007405341535897316
Trained batch 113 in epoch 4, gen_loss = 0.8793126349909264, disc_loss = 0.000738532185399284
Trained batch 114 in epoch 4, gen_loss = 0.8794770043829213, disc_loss = 0.0007382068388245028
Trained batch 115 in epoch 4, gen_loss = 0.8792724948504875, disc_loss = 0.0007407816713033565
Trained batch 116 in epoch 4, gen_loss = 0.8794971296929905, disc_loss = 0.0007418439003169282
Trained batch 117 in epoch 4, gen_loss = 0.8794975295915441, disc_loss = 0.0007409017520238471
Trained batch 118 in epoch 4, gen_loss = 0.8793067626592492, disc_loss = 0.0007432647584546201
Trained batch 119 in epoch 4, gen_loss = 0.8794284691413243, disc_loss = 0.0007446456627803854
Trained batch 120 in epoch 4, gen_loss = 0.8792417138076025, disc_loss = 0.0007445450977052847
Trained batch 121 in epoch 4, gen_loss = 0.8792204549078082, disc_loss = 0.0007430372872298248
Trained batch 122 in epoch 4, gen_loss = 0.879378129796284, disc_loss = 0.0007404947951076385
Trained batch 123 in epoch 4, gen_loss = 0.8797003035583804, disc_loss = 0.0007397133771108554
Trained batch 124 in epoch 4, gen_loss = 0.8796950459480286, disc_loss = 0.0007381751036737114
Trained batch 125 in epoch 4, gen_loss = 0.8800005349848006, disc_loss = 0.0007371223979308048
Trained batch 126 in epoch 4, gen_loss = 0.8798771664852233, disc_loss = 0.0007370180731334936
Trained batch 127 in epoch 4, gen_loss = 0.8802104201167822, disc_loss = 0.0007382719588804321
Trained batch 128 in epoch 4, gen_loss = 0.8804760196412257, disc_loss = 0.0007373324124767019
Trained batch 129 in epoch 4, gen_loss = 0.8805792707663316, disc_loss = 0.0007371172606676388
Trained batch 130 in epoch 4, gen_loss = 0.8803591455212076, disc_loss = 0.0007374126062895534
Trained batch 131 in epoch 4, gen_loss = 0.8800665921334064, disc_loss = 0.0007405983379805658
Trained batch 132 in epoch 4, gen_loss = 0.8801064567458361, disc_loss = 0.0007422700372465039
Trained batch 133 in epoch 4, gen_loss = 0.8797155640908142, disc_loss = 0.0007441878466912087
Trained batch 134 in epoch 4, gen_loss = 0.8796178151060033, disc_loss = 0.0007430068521191263
Trained batch 135 in epoch 4, gen_loss = 0.8795983138329843, disc_loss = 0.0007441597076916985
Trained batch 136 in epoch 4, gen_loss = 0.8799091399151043, disc_loss = 0.000744379036524503
Trained batch 137 in epoch 4, gen_loss = 0.8796894502812538, disc_loss = 0.0007444481629847913
Trained batch 138 in epoch 4, gen_loss = 0.8793645955675797, disc_loss = 0.0007430887427231257
Trained batch 139 in epoch 4, gen_loss = 0.8793078677994864, disc_loss = 0.0007417371253333321
Trained batch 140 in epoch 4, gen_loss = 0.8791923653994892, disc_loss = 0.0007406900773495303
Trained batch 141 in epoch 4, gen_loss = 0.8794346149538604, disc_loss = 0.0007409567882808607
Trained batch 142 in epoch 4, gen_loss = 0.879239112347156, disc_loss = 0.0007414088970769874
Trained batch 143 in epoch 4, gen_loss = 0.8791869009534518, disc_loss = 0.0007407397321609702
Trained batch 144 in epoch 4, gen_loss = 0.8791210569184402, disc_loss = 0.0007393633125847655
Trained batch 145 in epoch 4, gen_loss = 0.879045014512049, disc_loss = 0.0007376824180700829
Trained batch 146 in epoch 4, gen_loss = 0.8790231651189376, disc_loss = 0.0007397254256192645
Trained batch 147 in epoch 4, gen_loss = 0.8789577387474679, disc_loss = 0.0007421026744555707
Trained batch 148 in epoch 4, gen_loss = 0.8788168134305301, disc_loss = 0.0007433902439833212
Trained batch 149 in epoch 4, gen_loss = 0.8789262930552165, disc_loss = 0.0007430669900107508
Trained batch 150 in epoch 4, gen_loss = 0.8789939165904822, disc_loss = 0.0007429815266383133
Trained batch 151 in epoch 4, gen_loss = 0.878740412232123, disc_loss = 0.0007411312133052362
Trained batch 152 in epoch 4, gen_loss = 0.8788217715188569, disc_loss = 0.0007397871967815958
Trained batch 153 in epoch 4, gen_loss = 0.8788782431707753, disc_loss = 0.0007392431187138034
Trained batch 154 in epoch 4, gen_loss = 0.8789778590202332, disc_loss = 0.0007382103660699701
Trained batch 155 in epoch 4, gen_loss = 0.8789834066843375, disc_loss = 0.0007366790226884545
Trained batch 156 in epoch 4, gen_loss = 0.8790513094823071, disc_loss = 0.0007362593716873555
Trained batch 157 in epoch 4, gen_loss = 0.8790237639523759, disc_loss = 0.0007381590679685785
Trained batch 158 in epoch 4, gen_loss = 0.8789622978594318, disc_loss = 0.0007385653163578783
Trained batch 159 in epoch 4, gen_loss = 0.8789360545575619, disc_loss = 0.0007422837907142821
Trained batch 160 in epoch 4, gen_loss = 0.8789060826627364, disc_loss = 0.0007415912726891128
Trained batch 161 in epoch 4, gen_loss = 0.8789419369933046, disc_loss = 0.0007408920129010868
Trained batch 162 in epoch 4, gen_loss = 0.8791085463360043, disc_loss = 0.0007394827558427615
Trained batch 163 in epoch 4, gen_loss = 0.8791533007127482, disc_loss = 0.0007380447590016624
Trained batch 164 in epoch 4, gen_loss = 0.8792101072542595, disc_loss = 0.000737809497249228
Trained batch 165 in epoch 4, gen_loss = 0.8792116685085986, disc_loss = 0.000736910401505463
Trained batch 166 in epoch 4, gen_loss = 0.8794091975617552, disc_loss = 0.0007361222376062641
Trained batch 167 in epoch 4, gen_loss = 0.8794814188565526, disc_loss = 0.0007355496558635163
Trained batch 168 in epoch 4, gen_loss = 0.8795024565691073, disc_loss = 0.0007362230568945121
Trained batch 169 in epoch 4, gen_loss = 0.8795414002502666, disc_loss = 0.0007362972234499038
Trained batch 170 in epoch 4, gen_loss = 0.8793447826340882, disc_loss = 0.0007386800851087407
Trained batch 171 in epoch 4, gen_loss = 0.8793986089700876, disc_loss = 0.0007385210193988737
Trained batch 172 in epoch 4, gen_loss = 0.8795630101523647, disc_loss = 0.0007430300282414012
Trained batch 173 in epoch 4, gen_loss = 0.8793098498349903, disc_loss = 0.0007455608469297595
Trained batch 174 in epoch 4, gen_loss = 0.8792321351596287, disc_loss = 0.0007453397347126156
Trained batch 175 in epoch 4, gen_loss = 0.8794862692329016, disc_loss = 0.000746520804155311
Trained batch 176 in epoch 4, gen_loss = 0.8793300494635846, disc_loss = 0.0007514678161146677
Trained batch 177 in epoch 4, gen_loss = 0.8790913455271989, disc_loss = 0.0007553155966602747
Trained batch 178 in epoch 4, gen_loss = 0.8792114241163158, disc_loss = 0.0007569140703586456
Trained batch 179 in epoch 4, gen_loss = 0.8791584024826685, disc_loss = 0.000757073723394165
Trained batch 180 in epoch 4, gen_loss = 0.8790288254700972, disc_loss = 0.0007560045086297603
Trained batch 181 in epoch 4, gen_loss = 0.8792902404790396, disc_loss = 0.0007561032107332721
Trained batch 182 in epoch 4, gen_loss = 0.8791654898169262, disc_loss = 0.0007550526393483307
Trained batch 183 in epoch 4, gen_loss = 0.8791541172110516, disc_loss = 0.000754461213902054
Trained batch 184 in epoch 4, gen_loss = 0.8787965787423624, disc_loss = 0.0007678318191382631
Trained batch 185 in epoch 4, gen_loss = 0.8785316908872256, disc_loss = 0.0007748082431937038
Trained batch 186 in epoch 4, gen_loss = 0.8787071261813933, disc_loss = 0.0007756944208214169
Trained batch 187 in epoch 4, gen_loss = 0.8786644919755611, disc_loss = 0.0007771591352796717
Trained batch 188 in epoch 4, gen_loss = 0.8787137730411752, disc_loss = 0.0007784836508257305
Trained batch 189 in epoch 4, gen_loss = 0.8787394705571626, disc_loss = 0.000779418418900796
Trained batch 190 in epoch 4, gen_loss = 0.8786955834683323, disc_loss = 0.0007790428294046875
Trained batch 191 in epoch 4, gen_loss = 0.8786590645710627, disc_loss = 0.0007783518966183086
Trained batch 192 in epoch 4, gen_loss = 0.8788124631723592, disc_loss = 0.0007785791490489974
Trained batch 193 in epoch 4, gen_loss = 0.8787295065589786, disc_loss = 0.0007775555859552696
Trained batch 194 in epoch 4, gen_loss = 0.87881379983364, disc_loss = 0.0007782475370615243
Trained batch 195 in epoch 4, gen_loss = 0.8787446776214911, disc_loss = 0.0007780970316867307
Trained batch 196 in epoch 4, gen_loss = 0.8787071172356, disc_loss = 0.0007779855190405177
Trained batch 197 in epoch 4, gen_loss = 0.8786559848472325, disc_loss = 0.0007776896311428793
Trained batch 198 in epoch 4, gen_loss = 0.8786158654558, disc_loss = 0.0007781926020406579
Trained batch 199 in epoch 4, gen_loss = 0.8785088646411896, disc_loss = 0.0007779409729118925
Trained batch 200 in epoch 4, gen_loss = 0.8785053995711294, disc_loss = 0.0007764328639219927
Trained batch 201 in epoch 4, gen_loss = 0.8783889011581345, disc_loss = 0.0007749126581786347
Trained batch 202 in epoch 4, gen_loss = 0.8784333602548233, disc_loss = 0.0007735650997615782
Trained batch 203 in epoch 4, gen_loss = 0.8784319495453554, disc_loss = 0.0007725398878820295
Trained batch 204 in epoch 4, gen_loss = 0.8785570699994157, disc_loss = 0.0007784443553934646
Trained batch 205 in epoch 4, gen_loss = 0.8786569014914984, disc_loss = 0.000781559562101481
Trained batch 206 in epoch 4, gen_loss = 0.8787011481137668, disc_loss = 0.0007823725721117217
Trained batch 207 in epoch 4, gen_loss = 0.8786060835879582, disc_loss = 0.0007820426604806785
Trained batch 208 in epoch 4, gen_loss = 0.8786564814416986, disc_loss = 0.0007817352180309041
Trained batch 209 in epoch 4, gen_loss = 0.8787898026761555, disc_loss = 0.0007823905803629064
Trained batch 210 in epoch 4, gen_loss = 0.8787300227942625, disc_loss = 0.0007840223243223919
Trained batch 211 in epoch 4, gen_loss = 0.8788151167473703, disc_loss = 0.0007837575170890217
Trained batch 212 in epoch 4, gen_loss = 0.8788947966736806, disc_loss = 0.0007821472232971131
Trained batch 213 in epoch 4, gen_loss = 0.8787273472157594, disc_loss = 0.0007821371133937544
Trained batch 214 in epoch 4, gen_loss = 0.8786066390747248, disc_loss = 0.0007820783035428978
Trained batch 215 in epoch 4, gen_loss = 0.8786197906291043, disc_loss = 0.0007818875583998979
Trained batch 216 in epoch 4, gen_loss = 0.8785637746208824, disc_loss = 0.0007807565427842348
Trained batch 217 in epoch 4, gen_loss = 0.8786623956413444, disc_loss = 0.00077958214307661
Trained batch 218 in epoch 4, gen_loss = 0.8787056079738216, disc_loss = 0.0007788279628302459
Trained batch 219 in epoch 4, gen_loss = 0.8786068000576713, disc_loss = 0.0007775140533340163
Trained batch 220 in epoch 4, gen_loss = 0.8786252526675954, disc_loss = 0.0007768231827283185
Trained batch 221 in epoch 4, gen_loss = 0.878728304360364, disc_loss = 0.0007757999448405646
Trained batch 222 in epoch 4, gen_loss = 0.8788297924760211, disc_loss = 0.0007749062182638594
Trained batch 223 in epoch 4, gen_loss = 0.8789123131760529, disc_loss = 0.0007739690345260897
Trained batch 224 in epoch 4, gen_loss = 0.8789997222688463, disc_loss = 0.0007730580249335617
Trained batch 225 in epoch 4, gen_loss = 0.8790117009023649, disc_loss = 0.000774060442309159
Trained batch 226 in epoch 4, gen_loss = 0.8789698549829391, disc_loss = 0.0007735721951315697
Trained batch 227 in epoch 4, gen_loss = 0.8789791564146677, disc_loss = 0.0007727382595603878
Trained batch 228 in epoch 4, gen_loss = 0.878874624660442, disc_loss = 0.0007718733361135258
Trained batch 229 in epoch 4, gen_loss = 0.8789624359296716, disc_loss = 0.0007712583010763173
Trained batch 230 in epoch 4, gen_loss = 0.8790681645983741, disc_loss = 0.0007707742331358019
Trained batch 231 in epoch 4, gen_loss = 0.8789369928939589, disc_loss = 0.000769320814815101
Trained batch 232 in epoch 4, gen_loss = 0.878745187761446, disc_loss = 0.0007693161964346555
Trained batch 233 in epoch 4, gen_loss = 0.8787184518117171, disc_loss = 0.000771378788477184
Trained batch 234 in epoch 4, gen_loss = 0.8786815539319465, disc_loss = 0.0007734786428045482
Trained batch 235 in epoch 4, gen_loss = 0.8787824923204164, disc_loss = 0.0007755472972225477
Trained batch 236 in epoch 4, gen_loss = 0.8788820153047264, disc_loss = 0.0007803500390499594
Trained batch 237 in epoch 4, gen_loss = 0.8790606069965523, disc_loss = 0.0007819723732380133
Trained batch 238 in epoch 4, gen_loss = 0.8791522974748491, disc_loss = 0.0007814214562180854
Trained batch 239 in epoch 4, gen_loss = 0.8791850984096528, disc_loss = 0.000780717853558599
Trained batch 240 in epoch 4, gen_loss = 0.8791196385854507, disc_loss = 0.0007797141574638126
Trained batch 241 in epoch 4, gen_loss = 0.8793516245262682, disc_loss = 0.0007794519263648713
Trained batch 242 in epoch 4, gen_loss = 0.8794371456275751, disc_loss = 0.0007788256186093184
Trained batch 243 in epoch 4, gen_loss = 0.8793987810123162, disc_loss = 0.0007779397857404069
Trained batch 244 in epoch 4, gen_loss = 0.8794421840687188, disc_loss = 0.00077804508987263
Trained batch 245 in epoch 4, gen_loss = 0.8794769552665028, disc_loss = 0.0007779898581698885
Trained batch 246 in epoch 4, gen_loss = 0.8794993084934559, disc_loss = 0.0007775902378359651
Trained batch 247 in epoch 4, gen_loss = 0.8793786336337367, disc_loss = 0.0007769994846321717
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 0.8962228894233704, disc_loss = 0.000563876936212182
Trained batch 1 in epoch 5, gen_loss = 0.8833172619342804, disc_loss = 0.0005876327340956777
Trained batch 2 in epoch 5, gen_loss = 0.897783617178599, disc_loss = 0.0006504839014572402
Trained batch 3 in epoch 5, gen_loss = 0.894494041800499, disc_loss = 0.0006558480235980824
Trained batch 4 in epoch 5, gen_loss = 0.8920847296714782, disc_loss = 0.0006653774762526155
Trained batch 5 in epoch 5, gen_loss = 0.8943821688493093, disc_loss = 0.0006886521587148309
Trained batch 6 in epoch 5, gen_loss = 0.8946093576295036, disc_loss = 0.0007639766138579164
Trained batch 7 in epoch 5, gen_loss = 0.8943344578146935, disc_loss = 0.000777177068812307
Trained batch 8 in epoch 5, gen_loss = 0.8926380276679993, disc_loss = 0.000780459241165469
Trained batch 9 in epoch 5, gen_loss = 0.8904048144817353, disc_loss = 0.00079226364614442
Trained batch 10 in epoch 5, gen_loss = 0.8910750529982827, disc_loss = 0.000779435271397233
Trained batch 11 in epoch 5, gen_loss = 0.8914838433265686, disc_loss = 0.0007604288499957571
Trained batch 12 in epoch 5, gen_loss = 0.8910356301527756, disc_loss = 0.000748592599008519
Trained batch 13 in epoch 5, gen_loss = 0.8915454064096723, disc_loss = 0.0007419562524384153
Trained batch 14 in epoch 5, gen_loss = 0.8941473642985026, disc_loss = 0.0007642168280047675
Trained batch 15 in epoch 5, gen_loss = 0.8951722681522369, disc_loss = 0.0007757290186418686
Trained batch 16 in epoch 5, gen_loss = 0.8951948355225956, disc_loss = 0.0007777686045943376
Trained batch 17 in epoch 5, gen_loss = 0.8953811327616373, disc_loss = 0.000787411273146669
Trained batch 18 in epoch 5, gen_loss = 0.89426841233906, disc_loss = 0.0007993839313521197
Trained batch 19 in epoch 5, gen_loss = 0.8947699874639511, disc_loss = 0.0008400367863941937
Trained batch 20 in epoch 5, gen_loss = 0.8960227427028474, disc_loss = 0.0008702283957973123
Trained batch 21 in epoch 5, gen_loss = 0.8965882740237496, disc_loss = 0.000951695028396154
Trained batch 22 in epoch 5, gen_loss = 0.9017225478006445, disc_loss = 0.0009697463424147471
Trained batch 23 in epoch 5, gen_loss = 0.9034169887502989, disc_loss = 0.0009894290415104479
Trained batch 24 in epoch 5, gen_loss = 0.9042106604576111, disc_loss = 0.0010187454335391522
Trained batch 25 in epoch 5, gen_loss = 0.904986172914505, disc_loss = 0.0010972429210176836
Trained batch 26 in epoch 5, gen_loss = 0.9074500953709638, disc_loss = 0.0011756672799863198
Trained batch 27 in epoch 5, gen_loss = 0.9124710325683866, disc_loss = 0.001269099851404982
Trained batch 28 in epoch 5, gen_loss = 0.9151706222830147, disc_loss = 0.0013336994813690926
Trained batch 29 in epoch 5, gen_loss = 0.9155292054017384, disc_loss = 0.0014175117791940769
Trained batch 30 in epoch 5, gen_loss = 0.9165734744841053, disc_loss = 0.0014234924643871285
Trained batch 31 in epoch 5, gen_loss = 0.9182069059461355, disc_loss = 0.0015051949667395093
Trained batch 32 in epoch 5, gen_loss = 0.9200323657556013, disc_loss = 0.0015424536117775874
Trained batch 33 in epoch 5, gen_loss = 0.9245820588925305, disc_loss = 0.0016141766819226392
Trained batch 34 in epoch 5, gen_loss = 0.9258546846253531, disc_loss = 0.001646689185872674
Trained batch 35 in epoch 5, gen_loss = 0.9308749785025915, disc_loss = 0.0017274574105006952
Trained batch 36 in epoch 5, gen_loss = 0.93548759415343, disc_loss = 0.0018706975341145251
Trained batch 37 in epoch 5, gen_loss = 0.9380937893139688, disc_loss = 0.0019196880871037904
Trained batch 38 in epoch 5, gen_loss = 0.9384391598212414, disc_loss = 0.0019350752580719881
Trained batch 39 in epoch 5, gen_loss = 0.9376633986830711, disc_loss = 0.001947902573738247
Trained batch 40 in epoch 5, gen_loss = 0.9382445521470977, disc_loss = 0.00195374672596411
Trained batch 41 in epoch 5, gen_loss = 0.9362630531901405, disc_loss = 0.0019569830592012123
Trained batch 42 in epoch 5, gen_loss = 0.9351561416027158, disc_loss = 0.0019430134737820819
Trained batch 43 in epoch 5, gen_loss = 0.9358577308329669, disc_loss = 0.0019445164520716803
Trained batch 44 in epoch 5, gen_loss = 0.9318181236584981, disc_loss = 0.00249760569487181
Trained batch 45 in epoch 5, gen_loss = 0.9325511105682539, disc_loss = 0.002780433567038373
Trained batch 46 in epoch 5, gen_loss = 0.9337931744595791, disc_loss = 0.00283010562069397
Trained batch 47 in epoch 5, gen_loss = 0.9365420093139013, disc_loss = 0.0029005178997370726
Trained batch 48 in epoch 5, gen_loss = 0.9370125447000776, disc_loss = 0.0029633210506290197
Trained batch 49 in epoch 5, gen_loss = 0.9369933736324311, disc_loss = 0.0029547801287844776
Trained batch 50 in epoch 5, gen_loss = 0.9356219803585726, disc_loss = 0.002990648821544121
Trained batch 51 in epoch 5, gen_loss = 0.9358111172914505, disc_loss = 0.003038760995528159
Trained batch 52 in epoch 5, gen_loss = 0.9350182087916248, disc_loss = 0.0030359273758839888
Trained batch 53 in epoch 5, gen_loss = 0.9355695413218604, disc_loss = 0.003017744588389717
Trained batch 54 in epoch 5, gen_loss = 0.9347807483239607, disc_loss = 0.0029830485286021775
Trained batch 55 in epoch 5, gen_loss = 0.9339607996600015, disc_loss = 0.002942889844624525
Trained batch 56 in epoch 5, gen_loss = 0.9326772993071037, disc_loss = 0.002910669414089633
Trained batch 57 in epoch 5, gen_loss = 0.9312980606638152, disc_loss = 0.002879364184176164
Trained batch 58 in epoch 5, gen_loss = 0.9304725295406276, disc_loss = 0.0028591934084434504
Trained batch 59 in epoch 5, gen_loss = 0.9304742455482483, disc_loss = 0.0028389191885556404
Trained batch 60 in epoch 5, gen_loss = 0.9288107684401216, disc_loss = 0.0028928855718418833
Trained batch 61 in epoch 5, gen_loss = 0.9332750093552374, disc_loss = 0.0030344579258047405
Trained batch 62 in epoch 5, gen_loss = 0.9352784554163615, disc_loss = 0.0030882268754159293
Trained batch 63 in epoch 5, gen_loss = 0.9373881127685308, disc_loss = 0.003127400713310635
Trained batch 64 in epoch 5, gen_loss = 0.9407868880491991, disc_loss = 0.003175715594373357
Trained batch 65 in epoch 5, gen_loss = 0.9427810871239864, disc_loss = 0.0031683597595529686
Trained batch 66 in epoch 5, gen_loss = 0.9442699311384514, disc_loss = 0.003149021177990501
Trained batch 67 in epoch 5, gen_loss = 0.9442125839345595, disc_loss = 0.0031282443096107967
Trained batch 68 in epoch 5, gen_loss = 0.9439999936283499, disc_loss = 0.003103669537939941
Trained batch 69 in epoch 5, gen_loss = 0.9440031170845031, disc_loss = 0.003076831092559067
Trained batch 70 in epoch 5, gen_loss = 0.9442938549417845, disc_loss = 0.0030540592884841624
Trained batch 71 in epoch 5, gen_loss = 0.9435834222369723, disc_loss = 0.003029214888455398
Trained batch 72 in epoch 5, gen_loss = 0.9436052433431965, disc_loss = 0.0030114391048387816
Trained batch 73 in epoch 5, gen_loss = 0.9439612820341781, disc_loss = 0.0030000430564836576
Trained batch 74 in epoch 5, gen_loss = 0.943237320582072, disc_loss = 0.0029792222543619574
Trained batch 75 in epoch 5, gen_loss = 0.9427410536690762, disc_loss = 0.0029651952890593462
Trained batch 76 in epoch 5, gen_loss = 0.9421144476184597, disc_loss = 0.0029514288407290813
Trained batch 77 in epoch 5, gen_loss = 0.9417048830252427, disc_loss = 0.0029335469119429877
Trained batch 78 in epoch 5, gen_loss = 0.9409073960931995, disc_loss = 0.0029098925916065427
Trained batch 79 in epoch 5, gen_loss = 0.9401908166706562, disc_loss = 0.002909461655508494
Trained batch 80 in epoch 5, gen_loss = 0.9387434831372014, disc_loss = 0.002909588664166491
Trained batch 81 in epoch 5, gen_loss = 0.9376880119486553, disc_loss = 0.0028923983783631516
Trained batch 82 in epoch 5, gen_loss = 0.9373964459063059, disc_loss = 0.002870076798121389
Trained batch 83 in epoch 5, gen_loss = 0.9374492927676156, disc_loss = 0.002854669860902331
Trained batch 84 in epoch 5, gen_loss = 0.936735060635735, disc_loss = 0.0028364763848538347
Trained batch 85 in epoch 5, gen_loss = 0.9358473953812622, disc_loss = 0.0028118812810727072
Trained batch 86 in epoch 5, gen_loss = 0.9347323090180584, disc_loss = 0.002802090034900426
Trained batch 87 in epoch 5, gen_loss = 0.9337185289372097, disc_loss = 0.00278181854743955
Trained batch 88 in epoch 5, gen_loss = 0.9330683337168747, disc_loss = 0.0027650932675447274
Trained batch 89 in epoch 5, gen_loss = 0.933064517709944, disc_loss = 0.002744505192903388
Trained batch 90 in epoch 5, gen_loss = 0.9332141489773006, disc_loss = 0.002724288510552679
Trained batch 91 in epoch 5, gen_loss = 0.9328381943961849, disc_loss = 0.002703685237540175
Trained batch 92 in epoch 5, gen_loss = 0.9323552302134934, disc_loss = 0.002687014752037583
Trained batch 93 in epoch 5, gen_loss = 0.9316467858375387, disc_loss = 0.0026667636591307027
Trained batch 94 in epoch 5, gen_loss = 0.9310570158456501, disc_loss = 0.0026439950642126956
Trained batch 95 in epoch 5, gen_loss = 0.9301228548089663, disc_loss = 0.0026243541130194594
Trained batch 96 in epoch 5, gen_loss = 0.9292785095185349, disc_loss = 0.0026070424835629683
Trained batch 97 in epoch 5, gen_loss = 0.928795978122828, disc_loss = 0.002593779444637499
Trained batch 98 in epoch 5, gen_loss = 0.9284252247425041, disc_loss = 0.0025731257046572864
Trained batch 99 in epoch 5, gen_loss = 0.9280303138494491, disc_loss = 0.002554240478784777
Trained batch 100 in epoch 5, gen_loss = 0.9274882095875127, disc_loss = 0.002536313709143623
Trained batch 101 in epoch 5, gen_loss = 0.926800342167125, disc_loss = 0.0025213374990248577
Trained batch 102 in epoch 5, gen_loss = 0.9261201909444865, disc_loss = 0.002515530373643433
Trained batch 103 in epoch 5, gen_loss = 0.9256887137889862, disc_loss = 0.0024988725328092608
Trained batch 104 in epoch 5, gen_loss = 0.9255866936274937, disc_loss = 0.0024837037797884216
Trained batch 105 in epoch 5, gen_loss = 0.9251443619997997, disc_loss = 0.002466326038010489
Trained batch 106 in epoch 5, gen_loss = 0.9244732589365166, disc_loss = 0.002450877139083693
Trained batch 107 in epoch 5, gen_loss = 0.923897487145883, disc_loss = 0.0024341098927565057
Trained batch 108 in epoch 5, gen_loss = 0.923575998993095, disc_loss = 0.0024166953121952783
Trained batch 109 in epoch 5, gen_loss = 0.9230600590055639, disc_loss = 0.0023988951958017423
Trained batch 110 in epoch 5, gen_loss = 0.9228030534477921, disc_loss = 0.0023842036662736557
Trained batch 111 in epoch 5, gen_loss = 0.9224264424826417, disc_loss = 0.0023783193337294506
Trained batch 112 in epoch 5, gen_loss = 0.9218356635718219, disc_loss = 0.002371053565530502
Trained batch 113 in epoch 5, gen_loss = 0.9215036756113956, disc_loss = 0.0023607836324995254
Trained batch 114 in epoch 5, gen_loss = 0.92089734647585, disc_loss = 0.0023448781300153907
Trained batch 115 in epoch 5, gen_loss = 0.9205326134788578, disc_loss = 0.0023287226644681833
Trained batch 116 in epoch 5, gen_loss = 0.9201690243859576, disc_loss = 0.0023135015826560874
Trained batch 117 in epoch 5, gen_loss = 0.919737636032751, disc_loss = 0.002298459523136459
Trained batch 118 in epoch 5, gen_loss = 0.9193027099641431, disc_loss = 0.0022833080558270656
Trained batch 119 in epoch 5, gen_loss = 0.9190651148557663, disc_loss = 0.0022705743889673614
Trained batch 120 in epoch 5, gen_loss = 0.9190290033324691, disc_loss = 0.002260240853652512
Trained batch 121 in epoch 5, gen_loss = 0.9185706005721795, disc_loss = 0.002250859356908983
Trained batch 122 in epoch 5, gen_loss = 0.9182191035611843, disc_loss = 0.002237182310252352
Trained batch 123 in epoch 5, gen_loss = 0.9180962726954491, disc_loss = 0.0022250747077182057
Trained batch 124 in epoch 5, gen_loss = 0.9178899998664856, disc_loss = 0.0022153947949409484
Trained batch 125 in epoch 5, gen_loss = 0.9174269224916186, disc_loss = 0.002206558351486271
Trained batch 126 in epoch 5, gen_loss = 0.9169904110938545, disc_loss = 0.0021958168427364563
Trained batch 127 in epoch 5, gen_loss = 0.9165704934857786, disc_loss = 0.002185919384828594
Trained batch 128 in epoch 5, gen_loss = 0.9161859616752743, disc_loss = 0.0021724727854417823
Trained batch 129 in epoch 5, gen_loss = 0.915884220141631, disc_loss = 0.0021592898780139736
Trained batch 130 in epoch 5, gen_loss = 0.9153892971177138, disc_loss = 0.0021473829123948678
Trained batch 131 in epoch 5, gen_loss = 0.9152558662674644, disc_loss = 0.002137797047466985
Trained batch 132 in epoch 5, gen_loss = 0.9151148092477841, disc_loss = 0.002125576357103366
Trained batch 133 in epoch 5, gen_loss = 0.9147202657229865, disc_loss = 0.0021151264192477395
Trained batch 134 in epoch 5, gen_loss = 0.9143794620478595, disc_loss = 0.002102645543722988
Trained batch 135 in epoch 5, gen_loss = 0.914145343882196, disc_loss = 0.0020927078587513227
Trained batch 136 in epoch 5, gen_loss = 0.9137458762113195, disc_loss = 0.002080766237077446
Trained batch 137 in epoch 5, gen_loss = 0.9131686570851699, disc_loss = 0.002069438252795447
Trained batch 138 in epoch 5, gen_loss = 0.9130903272320041, disc_loss = 0.0020609025673006104
Trained batch 139 in epoch 5, gen_loss = 0.9126703070742743, disc_loss = 0.002054367370146792
Trained batch 140 in epoch 5, gen_loss = 0.9127452648277824, disc_loss = 0.0020473027861502074
Trained batch 141 in epoch 5, gen_loss = 0.9122811488702264, disc_loss = 0.0020371106169170135
Trained batch 142 in epoch 5, gen_loss = 0.9118341049114307, disc_loss = 0.002026571452388071
Trained batch 143 in epoch 5, gen_loss = 0.9112129625346925, disc_loss = 0.002019512475777042
Trained batch 144 in epoch 5, gen_loss = 0.9108853701887459, disc_loss = 0.002016188706680811
Trained batch 145 in epoch 5, gen_loss = 0.9106979006773805, disc_loss = 0.002009977320048078
Trained batch 146 in epoch 5, gen_loss = 0.9105856929506574, disc_loss = 0.002001102856751595
Trained batch 147 in epoch 5, gen_loss = 0.910499258621319, disc_loss = 0.001992759911297833
Trained batch 148 in epoch 5, gen_loss = 0.9100876634552975, disc_loss = 0.0019827317456236645
Trained batch 149 in epoch 5, gen_loss = 0.9098197801907857, disc_loss = 0.0019736047335512314
Trained batch 150 in epoch 5, gen_loss = 0.909846427424854, disc_loss = 0.001964380613656172
Trained batch 151 in epoch 5, gen_loss = 0.9095671086719161, disc_loss = 0.001954049648989703
Trained batch 152 in epoch 5, gen_loss = 0.909356867955401, disc_loss = 0.001943859787584812
Trained batch 153 in epoch 5, gen_loss = 0.9091670373817543, disc_loss = 0.0019342743760646115
Trained batch 154 in epoch 5, gen_loss = 0.908698695705783, disc_loss = 0.0019247253487382325
Trained batch 155 in epoch 5, gen_loss = 0.9085815067474659, disc_loss = 0.00191553411628448
Trained batch 156 in epoch 5, gen_loss = 0.9082287580344328, disc_loss = 0.0019079848371704173
Trained batch 157 in epoch 5, gen_loss = 0.9077702179739747, disc_loss = 0.0019064717297958022
Trained batch 158 in epoch 5, gen_loss = 0.9073648493994707, disc_loss = 0.0019008333202811696
Trained batch 159 in epoch 5, gen_loss = 0.9072872910648584, disc_loss = 0.0018942031352707999
Trained batch 160 in epoch 5, gen_loss = 0.9069268492438038, disc_loss = 0.0018855926296196485
Trained batch 161 in epoch 5, gen_loss = 0.9068850988959088, disc_loss = 0.0018819128797334952
Trained batch 162 in epoch 5, gen_loss = 0.9065045758259077, disc_loss = 0.001882779950660259
Trained batch 163 in epoch 5, gen_loss = 0.9062652838666264, disc_loss = 0.0018758456609226058
Trained batch 164 in epoch 5, gen_loss = 0.9060538281093944, disc_loss = 0.0018698058025840895
Trained batch 165 in epoch 5, gen_loss = 0.9062666932502424, disc_loss = 0.0018721883925426953
Trained batch 166 in epoch 5, gen_loss = 0.9060176346830265, disc_loss = 0.0018678562014020734
Trained batch 167 in epoch 5, gen_loss = 0.9056282653695061, disc_loss = 0.0018603092170711274
Trained batch 168 in epoch 5, gen_loss = 0.9053525854144576, disc_loss = 0.001854468243280646
Trained batch 169 in epoch 5, gen_loss = 0.9049599219770993, disc_loss = 0.0018498070327469202
Trained batch 170 in epoch 5, gen_loss = 0.9049312475829097, disc_loss = 0.0018459870107267705
Trained batch 171 in epoch 5, gen_loss = 0.9046293351539346, disc_loss = 0.0018390949463896822
Trained batch 172 in epoch 5, gen_loss = 0.9040769214575002, disc_loss = 0.0018312176999049207
Trained batch 173 in epoch 5, gen_loss = 0.9038722306147389, disc_loss = 0.0018240134315377894
Trained batch 174 in epoch 5, gen_loss = 0.9037930628231593, disc_loss = 0.0018202313378320209
Trained batch 175 in epoch 5, gen_loss = 0.9032482806254517, disc_loss = 0.0018166931453875309
Trained batch 176 in epoch 5, gen_loss = 0.9029994633911693, disc_loss = 0.001810760940043624
Trained batch 177 in epoch 5, gen_loss = 0.9027209412515833, disc_loss = 0.0018045023401539898
Trained batch 178 in epoch 5, gen_loss = 0.9024772384313232, disc_loss = 0.0017966824998642062
Trained batch 179 in epoch 5, gen_loss = 0.9021032134691874, disc_loss = 0.0017889240708124513
Trained batch 180 in epoch 5, gen_loss = 0.9019632046393926, disc_loss = 0.00178136403520607
Trained batch 181 in epoch 5, gen_loss = 0.9019491780590225, disc_loss = 0.0017747568893425453
Trained batch 182 in epoch 5, gen_loss = 0.9016097982724508, disc_loss = 0.0017688944417336965
Trained batch 183 in epoch 5, gen_loss = 0.9013513116085011, disc_loss = 0.0017623364195890683
Trained batch 184 in epoch 5, gen_loss = 0.90099762484834, disc_loss = 0.0017556730903232017
Trained batch 185 in epoch 5, gen_loss = 0.9008618122146975, disc_loss = 0.0017494985061417263
Trained batch 186 in epoch 5, gen_loss = 0.9006964207333039, disc_loss = 0.0017430037552650201
Trained batch 187 in epoch 5, gen_loss = 0.9005280244857707, disc_loss = 0.0017384144451538536
Trained batch 188 in epoch 5, gen_loss = 0.9002481389928747, disc_loss = 0.0017326056132482355
Trained batch 189 in epoch 5, gen_loss = 0.9000682630037007, disc_loss = 0.0017286673926527759
Trained batch 190 in epoch 5, gen_loss = 0.900103285050517, disc_loss = 0.0017262004612681714
Trained batch 191 in epoch 5, gen_loss = 0.8999147430683175, disc_loss = 0.0017264392102636823
Trained batch 192 in epoch 5, gen_loss = 0.8996116552945863, disc_loss = 0.0017254795644485387
Trained batch 193 in epoch 5, gen_loss = 0.8994257941688459, disc_loss = 0.001721666040578281
Trained batch 194 in epoch 5, gen_loss = 0.8992825526457566, disc_loss = 0.0017156435111059974
Trained batch 195 in epoch 5, gen_loss = 0.8991021240244106, disc_loss = 0.0017091722310192846
Trained batch 196 in epoch 5, gen_loss = 0.8990569659296026, disc_loss = 0.0017029582200746812
Trained batch 197 in epoch 5, gen_loss = 0.8991933416838598, disc_loss = 0.0016971532407691796
Trained batch 198 in epoch 5, gen_loss = 0.8989648447563899, disc_loss = 0.001690767177184061
Trained batch 199 in epoch 5, gen_loss = 0.8987866139411926, disc_loss = 0.0016858180510462262
Trained batch 200 in epoch 5, gen_loss = 0.8986710728104434, disc_loss = 0.0016805678857976932
Trained batch 201 in epoch 5, gen_loss = 0.8986720425067561, disc_loss = 0.0016786582404309607
Trained batch 202 in epoch 5, gen_loss = 0.8984355409744338, disc_loss = 0.0016739672021779779
Trained batch 203 in epoch 5, gen_loss = 0.8981379475079331, disc_loss = 0.0016708823132634565
Trained batch 204 in epoch 5, gen_loss = 0.8980752375067734, disc_loss = 0.0016661817026210994
Trained batch 205 in epoch 5, gen_loss = 0.8979143054739943, disc_loss = 0.0016609401870473714
Trained batch 206 in epoch 5, gen_loss = 0.8974295002250856, disc_loss = 0.0016556640655018282
Trained batch 207 in epoch 5, gen_loss = 0.8970608888910367, disc_loss = 0.00165455210998726
Trained batch 208 in epoch 5, gen_loss = 0.8971654595940878, disc_loss = 0.0016508936017537801
Trained batch 209 in epoch 5, gen_loss = 0.8968865122113909, disc_loss = 0.0016461216315205786
Trained batch 210 in epoch 5, gen_loss = 0.8968860998537869, disc_loss = 0.001641418798650081
Trained batch 211 in epoch 5, gen_loss = 0.8967530395624772, disc_loss = 0.0016360646649153973
Trained batch 212 in epoch 5, gen_loss = 0.8965798325381928, disc_loss = 0.001630874495776239
Trained batch 213 in epoch 5, gen_loss = 0.8965147045728202, disc_loss = 0.0016254949872762782
Trained batch 214 in epoch 5, gen_loss = 0.8964281301165736, disc_loss = 0.0016199068275962545
Trained batch 215 in epoch 5, gen_loss = 0.896123257500154, disc_loss = 0.0016148397333853172
Trained batch 216 in epoch 5, gen_loss = 0.8960356772769981, disc_loss = 0.0016110451895505412
Trained batch 217 in epoch 5, gen_loss = 0.8958499092574513, disc_loss = 0.0016076530762702448
Trained batch 218 in epoch 5, gen_loss = 0.8957567193192434, disc_loss = 0.0016035191592766763
Trained batch 219 in epoch 5, gen_loss = 0.8956579980525103, disc_loss = 0.0015990957349210724
Trained batch 220 in epoch 5, gen_loss = 0.8955502706954922, disc_loss = 0.0015946369038998018
Trained batch 221 in epoch 5, gen_loss = 0.8954238276760857, disc_loss = 0.0015893286050282637
Trained batch 222 in epoch 5, gen_loss = 0.895209337831078, disc_loss = 0.0015844036784543
Trained batch 223 in epoch 5, gen_loss = 0.8950872072683913, disc_loss = 0.001580558480392418
Trained batch 224 in epoch 5, gen_loss = 0.8948652911186218, disc_loss = 0.0015763640472303247
Trained batch 225 in epoch 5, gen_loss = 0.8946102873413964, disc_loss = 0.001571762815310488
Trained batch 226 in epoch 5, gen_loss = 0.8943709618194513, disc_loss = 0.0015670905387929605
Trained batch 227 in epoch 5, gen_loss = 0.8944107618248254, disc_loss = 0.0015633745437330696
Trained batch 228 in epoch 5, gen_loss = 0.8943270439664349, disc_loss = 0.001560451387499935
Trained batch 229 in epoch 5, gen_loss = 0.8940709546856258, disc_loss = 0.0015562542411751803
Trained batch 230 in epoch 5, gen_loss = 0.8938207654725938, disc_loss = 0.001552813430039567
Trained batch 231 in epoch 5, gen_loss = 0.8937839508570474, disc_loss = 0.001549618181813677
Trained batch 232 in epoch 5, gen_loss = 0.8937331673413387, disc_loss = 0.0015475442429430896
Trained batch 233 in epoch 5, gen_loss = 0.8934262858496772, disc_loss = 0.0015446863503595337
Trained batch 234 in epoch 5, gen_loss = 0.8931835210069697, disc_loss = 0.0015414008331990385
Trained batch 235 in epoch 5, gen_loss = 0.8930489031945245, disc_loss = 0.0015386955804434226
Trained batch 236 in epoch 5, gen_loss = 0.8930182059605917, disc_loss = 0.0015341791843519967
Trained batch 237 in epoch 5, gen_loss = 0.892888600084962, disc_loss = 0.0015300758153164932
Trained batch 238 in epoch 5, gen_loss = 0.8926337082016917, disc_loss = 0.0015268522674202233
Trained batch 239 in epoch 5, gen_loss = 0.8925630378226439, disc_loss = 0.0015222977289037468
Trained batch 240 in epoch 5, gen_loss = 0.8925201732093367, disc_loss = 0.0015182695037557808
Trained batch 241 in epoch 5, gen_loss = 0.8923171125660257, disc_loss = 0.001513539329277013
Trained batch 242 in epoch 5, gen_loss = 0.8920162994675185, disc_loss = 0.0015091030920018277
Trained batch 243 in epoch 5, gen_loss = 0.8916667172166167, disc_loss = 0.0015165013702229412
Trained batch 244 in epoch 5, gen_loss = 0.8914203702187051, disc_loss = 0.0015262022991046993
Trained batch 245 in epoch 5, gen_loss = 0.8912626761731094, disc_loss = 0.0015290556169101756
Trained batch 246 in epoch 5, gen_loss = 0.8912884204493843, disc_loss = 0.0015339792546060177
Trained batch 247 in epoch 5, gen_loss = 0.8913334420611781, disc_loss = 0.0015340948416597976
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 0.8714340925216675, disc_loss = 0.0010875058360397816
Trained batch 1 in epoch 6, gen_loss = 0.8429325222969055, disc_loss = 0.0011505153961479664
Trained batch 2 in epoch 6, gen_loss = 0.8351295193036398, disc_loss = 0.0026642770196000734
Trained batch 3 in epoch 6, gen_loss = 0.8162741512060165, disc_loss = 0.004086285596713424
Trained batch 4 in epoch 6, gen_loss = 0.8829326033592224, disc_loss = 0.007288824208080769
Trained batch 5 in epoch 6, gen_loss = 0.906652162472407, disc_loss = 0.0070258090272545815
Trained batch 6 in epoch 6, gen_loss = 0.9133126820836749, disc_loss = 0.007044593005308083
Trained batch 7 in epoch 6, gen_loss = 0.9160004183650017, disc_loss = 0.006549059093231335
Trained batch 8 in epoch 6, gen_loss = 0.9214016530248854, disc_loss = 0.006032900005165074
Trained batch 9 in epoch 6, gen_loss = 0.9238600134849548, disc_loss = 0.00558204686967656
Trained batch 10 in epoch 6, gen_loss = 0.9226984977722168, disc_loss = 0.005179067639718679
Trained batch 11 in epoch 6, gen_loss = 0.9221399426460266, disc_loss = 0.004933555833607291
Trained batch 12 in epoch 6, gen_loss = 0.9242272147765527, disc_loss = 0.004677837454857161
Trained batch 13 in epoch 6, gen_loss = 0.9205241969653538, disc_loss = 0.004462508642713406
Trained batch 14 in epoch 6, gen_loss = 0.9179299116134644, disc_loss = 0.0042708510144924125
Trained batch 15 in epoch 6, gen_loss = 0.9142828732728958, disc_loss = 0.004076696059200913
Trained batch 16 in epoch 6, gen_loss = 0.9131430808235618, disc_loss = 0.0038909742451163336
Trained batch 17 in epoch 6, gen_loss = 0.9099463290638394, disc_loss = 0.003712666612247833
Trained batch 18 in epoch 6, gen_loss = 0.9074611036401046, disc_loss = 0.003556994987823265
Trained batch 19 in epoch 6, gen_loss = 0.9048019826412201, disc_loss = 0.0034474923828383907
Trained batch 20 in epoch 6, gen_loss = 0.902219866003309, disc_loss = 0.003354805790530961
Trained batch 21 in epoch 6, gen_loss = 0.9032200737433, disc_loss = 0.0032683094587727364
Trained batch 22 in epoch 6, gen_loss = 0.9061494780623395, disc_loss = 0.003196729466055884
Trained batch 23 in epoch 6, gen_loss = 0.9076944068074226, disc_loss = 0.00315050871722633
Trained batch 24 in epoch 6, gen_loss = 0.9086749005317688, disc_loss = 0.0030826803366653622
Trained batch 25 in epoch 6, gen_loss = 0.9074443487020639, disc_loss = 0.0030014273383690473
Trained batch 26 in epoch 6, gen_loss = 0.9068548635200218, disc_loss = 0.002946586988400668
Trained batch 27 in epoch 6, gen_loss = 0.9050497157233102, disc_loss = 0.002866444053194885
Trained batch 28 in epoch 6, gen_loss = 0.9065298581945485, disc_loss = 0.002795513685198565
Trained batch 29 in epoch 6, gen_loss = 0.9052035888036092, disc_loss = 0.002742948563536629
Trained batch 30 in epoch 6, gen_loss = 0.9079956969907207, disc_loss = 0.0026794811297628667
Trained batch 31 in epoch 6, gen_loss = 0.9099184647202492, disc_loss = 0.0026155283812840935
Trained batch 32 in epoch 6, gen_loss = 0.909676831780058, disc_loss = 0.002551250413737514
Trained batch 33 in epoch 6, gen_loss = 0.90862197209807, disc_loss = 0.002497366287142915
Trained batch 34 in epoch 6, gen_loss = 0.9092772228377206, disc_loss = 0.0024457037465513815
Trained batch 35 in epoch 6, gen_loss = 0.9089493552843729, disc_loss = 0.0024099187592380783
Trained batch 36 in epoch 6, gen_loss = 0.9110138094103014, disc_loss = 0.002363052244323331
Trained batch 37 in epoch 6, gen_loss = 0.9115045666694641, disc_loss = 0.0023167400596369255
Trained batch 38 in epoch 6, gen_loss = 0.9126854141553243, disc_loss = 0.002288825242804029
Trained batch 39 in epoch 6, gen_loss = 0.9133858472108841, disc_loss = 0.002252834336832166
Trained batch 40 in epoch 6, gen_loss = 0.9130922061641041, disc_loss = 0.002207578369984176
Trained batch 41 in epoch 6, gen_loss = 0.9132891865003676, disc_loss = 0.0021638636681018397
Trained batch 42 in epoch 6, gen_loss = 0.9132626001224962, disc_loss = 0.0021369940253396975
Trained batch 43 in epoch 6, gen_loss = 0.9114021997560154, disc_loss = 0.0021088138237246312
Trained batch 44 in epoch 6, gen_loss = 0.9113728761672973, disc_loss = 0.0020715146784722393
Trained batch 45 in epoch 6, gen_loss = 0.9114832593047101, disc_loss = 0.00203863936590294
Trained batch 46 in epoch 6, gen_loss = 0.9107852996663844, disc_loss = 0.002012987609363181
Trained batch 47 in epoch 6, gen_loss = 0.9094761113325754, disc_loss = 0.0019981616090566
Trained batch 48 in epoch 6, gen_loss = 0.9086829156291728, disc_loss = 0.0019751212171193362
Trained batch 49 in epoch 6, gen_loss = 0.9078963017463684, disc_loss = 0.0019452717219246552
Trained batch 50 in epoch 6, gen_loss = 0.9076012700211769, disc_loss = 0.001925039073730837
Trained batch 51 in epoch 6, gen_loss = 0.9082564551096696, disc_loss = 0.0019137444127968943
Trained batch 52 in epoch 6, gen_loss = 0.9073520415234115, disc_loss = 0.001898477818786149
Trained batch 53 in epoch 6, gen_loss = 0.9061412402877101, disc_loss = 0.0018773384664975176
Trained batch 54 in epoch 6, gen_loss = 0.9052186879244718, disc_loss = 0.0018582651555665176
Trained batch 55 in epoch 6, gen_loss = 0.9049503558448383, disc_loss = 0.0018448844654942928
Trained batch 56 in epoch 6, gen_loss = 0.9046601036138702, disc_loss = 0.0018200545072383982
Trained batch 57 in epoch 6, gen_loss = 0.9039109842530613, disc_loss = 0.0018028669347304144
Trained batch 58 in epoch 6, gen_loss = 0.9042393262103453, disc_loss = 0.0017817772049812
Trained batch 59 in epoch 6, gen_loss = 0.9040272196133932, disc_loss = 0.0017616276614717207
Trained batch 60 in epoch 6, gen_loss = 0.9038124573035319, disc_loss = 0.0017425089346466312
Trained batch 61 in epoch 6, gen_loss = 0.9030632818898847, disc_loss = 0.001723301249101848
Trained batch 62 in epoch 6, gen_loss = 0.9030934600603013, disc_loss = 0.0017030299664290238
Trained batch 63 in epoch 6, gen_loss = 0.9025887018069625, disc_loss = 0.0016825234038151393
Trained batch 64 in epoch 6, gen_loss = 0.9017123552469107, disc_loss = 0.0016655257441855682
Trained batch 65 in epoch 6, gen_loss = 0.900831117774501, disc_loss = 0.0016504006418858119
Trained batch 66 in epoch 6, gen_loss = 0.9005196352503193, disc_loss = 0.001632780944772148
Trained batch 67 in epoch 6, gen_loss = 0.8999734038815779, disc_loss = 0.0016151732591371162
Trained batch 68 in epoch 6, gen_loss = 0.8998549874278082, disc_loss = 0.0016028845283722478
Trained batch 69 in epoch 6, gen_loss = 0.8987386567252023, disc_loss = 0.0016058586916187778
Trained batch 70 in epoch 6, gen_loss = 0.8985534335525942, disc_loss = 0.0015994178825615524
Trained batch 71 in epoch 6, gen_loss = 0.8980288455883662, disc_loss = 0.0015900931026003996
Trained batch 72 in epoch 6, gen_loss = 0.897257973070014, disc_loss = 0.001575729523846012
Trained batch 73 in epoch 6, gen_loss = 0.8964702551429337, disc_loss = 0.0015601311763905844
Trained batch 74 in epoch 6, gen_loss = 0.8953294976552327, disc_loss = 0.0015468003635760396
Trained batch 75 in epoch 6, gen_loss = 0.8952435678557346, disc_loss = 0.0015342609821297963
Trained batch 76 in epoch 6, gen_loss = 0.8948036207781209, disc_loss = 0.0015220864454447594
Trained batch 77 in epoch 6, gen_loss = 0.8943842809933883, disc_loss = 0.0015111898086242713
Trained batch 78 in epoch 6, gen_loss = 0.8942806056783169, disc_loss = 0.0015019849336947774
Trained batch 79 in epoch 6, gen_loss = 0.8939098536968231, disc_loss = 0.0014957190385757712
Trained batch 80 in epoch 6, gen_loss = 0.8933207407409762, disc_loss = 0.0014830790506819562
Trained batch 81 in epoch 6, gen_loss = 0.8932161163992998, disc_loss = 0.0014745307388493974
Trained batch 82 in epoch 6, gen_loss = 0.8928283689969994, disc_loss = 0.0014634136764854417
Trained batch 83 in epoch 6, gen_loss = 0.8922331836961565, disc_loss = 0.0014571321568967374
Trained batch 84 in epoch 6, gen_loss = 0.8919285009889042, disc_loss = 0.0014459091940593413
Trained batch 85 in epoch 6, gen_loss = 0.8919907926126968, disc_loss = 0.0014327495172078352
Trained batch 86 in epoch 6, gen_loss = 0.8918714502762104, disc_loss = 0.0014196415113997057
Trained batch 87 in epoch 6, gen_loss = 0.8919406214898283, disc_loss = 0.001407295273979385
Trained batch 88 in epoch 6, gen_loss = 0.8912166403920463, disc_loss = 0.001395851889039191
Trained batch 89 in epoch 6, gen_loss = 0.8913797802395291, disc_loss = 0.0013862985406174427
Trained batch 90 in epoch 6, gen_loss = 0.8912114474799607, disc_loss = 0.0013766352005384782
Trained batch 91 in epoch 6, gen_loss = 0.8908657762019531, disc_loss = 0.0013650449976051712
Trained batch 92 in epoch 6, gen_loss = 0.8909632005999165, disc_loss = 0.0013541415520262733
Trained batch 93 in epoch 6, gen_loss = 0.8901743394263247, disc_loss = 0.001345140517050242
Trained batch 94 in epoch 6, gen_loss = 0.8898186344849436, disc_loss = 0.0013362768700493403
Trained batch 95 in epoch 6, gen_loss = 0.8888810873031616, disc_loss = 0.0013274083181992562
Trained batch 96 in epoch 6, gen_loss = 0.8886480005746035, disc_loss = 0.0013182219789968324
Trained batch 97 in epoch 6, gen_loss = 0.8888249646644203, disc_loss = 0.0013090311781246671
Trained batch 98 in epoch 6, gen_loss = 0.8882099769332192, disc_loss = 0.0013025204734547497
Trained batch 99 in epoch 6, gen_loss = 0.8878729385137558, disc_loss = 0.0012975001649465413
Trained batch 100 in epoch 6, gen_loss = 0.887758203072123, disc_loss = 0.0012929761738488727
Trained batch 101 in epoch 6, gen_loss = 0.8875970910577213, disc_loss = 0.0012841484559056185
Trained batch 102 in epoch 6, gen_loss = 0.8870437133659437, disc_loss = 0.0012747471215705233
Trained batch 103 in epoch 6, gen_loss = 0.8867511221995721, disc_loss = 0.0012654305176581077
Trained batch 104 in epoch 6, gen_loss = 0.8865630007925488, disc_loss = 0.001255836715877411
Trained batch 105 in epoch 6, gen_loss = 0.8866299660700672, disc_loss = 0.0012468913249355162
Trained batch 106 in epoch 6, gen_loss = 0.8860678427687315, disc_loss = 0.0012376992990454294
Trained batch 107 in epoch 6, gen_loss = 0.8859552133966375, disc_loss = 0.0012295081046263309
Trained batch 108 in epoch 6, gen_loss = 0.8856574198521605, disc_loss = 0.0012227050717621016
Trained batch 109 in epoch 6, gen_loss = 0.8856874189593575, disc_loss = 0.0012173783970700408
Trained batch 110 in epoch 6, gen_loss = 0.8854218307916109, disc_loss = 0.0012123093448436677
Trained batch 111 in epoch 6, gen_loss = 0.8850601294210979, disc_loss = 0.0012058571056903539
Trained batch 112 in epoch 6, gen_loss = 0.8847793920905189, disc_loss = 0.0011989915003254186
Trained batch 113 in epoch 6, gen_loss = 0.8844301449625116, disc_loss = 0.0011907771751570532
Trained batch 114 in epoch 6, gen_loss = 0.8845134175342062, disc_loss = 0.0011845862470142058
Trained batch 115 in epoch 6, gen_loss = 0.884734873113961, disc_loss = 0.0011796415474863947
Trained batch 116 in epoch 6, gen_loss = 0.8842092818684049, disc_loss = 0.0011731168256702428
Trained batch 117 in epoch 6, gen_loss = 0.8840559508840916, disc_loss = 0.0011673604912160092
Trained batch 118 in epoch 6, gen_loss = 0.8838750098933693, disc_loss = 0.0011626654145593497
Trained batch 119 in epoch 6, gen_loss = 0.883605978389581, disc_loss = 0.0011608374545176048
Trained batch 120 in epoch 6, gen_loss = 0.883542247547591, disc_loss = 0.0011563601493277426
Trained batch 121 in epoch 6, gen_loss = 0.8833034766502068, disc_loss = 0.0011513885136857842
Trained batch 122 in epoch 6, gen_loss = 0.8827183677898189, disc_loss = 0.0011493939798934824
Trained batch 123 in epoch 6, gen_loss = 0.8825211568224814, disc_loss = 0.0011525747214627994
Trained batch 124 in epoch 6, gen_loss = 0.8824560117721557, disc_loss = 0.0011482836187351494
Trained batch 125 in epoch 6, gen_loss = 0.8827384085882277, disc_loss = 0.0011535942850593804
Trained batch 126 in epoch 6, gen_loss = 0.8824500183420857, disc_loss = 0.0011509138851070878
Trained batch 127 in epoch 6, gen_loss = 0.8821681523695588, disc_loss = 0.0011503715361413924
Trained batch 128 in epoch 6, gen_loss = 0.8822473980659662, disc_loss = 0.001146482235378434
Trained batch 129 in epoch 6, gen_loss = 0.8822213466350849, disc_loss = 0.0011411021282233729
Trained batch 130 in epoch 6, gen_loss = 0.8820459287585193, disc_loss = 0.0011381529769700248
Trained batch 131 in epoch 6, gen_loss = 0.8814562766840963, disc_loss = 0.0011348910892124738
Trained batch 132 in epoch 6, gen_loss = 0.8813721331438624, disc_loss = 0.0011287160634406302
Trained batch 133 in epoch 6, gen_loss = 0.8814335723421467, disc_loss = 0.0011226338131957924
Trained batch 134 in epoch 6, gen_loss = 0.8812570324650517, disc_loss = 0.0011174094914976093
Trained batch 135 in epoch 6, gen_loss = 0.8813245839932385, disc_loss = 0.0011122995330130354
Trained batch 136 in epoch 6, gen_loss = 0.8811806466457618, disc_loss = 0.0011084194589970483
Trained batch 137 in epoch 6, gen_loss = 0.8809522891390151, disc_loss = 0.001103936461309997
Trained batch 138 in epoch 6, gen_loss = 0.8804119589517443, disc_loss = 0.0011014753061500814
Trained batch 139 in epoch 6, gen_loss = 0.8803285960640226, disc_loss = 0.001097130447825683
Trained batch 140 in epoch 6, gen_loss = 0.8804751106187807, disc_loss = 0.0010929638796472751
Trained batch 141 in epoch 6, gen_loss = 0.8801640477818502, disc_loss = 0.0010876239520910813
Trained batch 142 in epoch 6, gen_loss = 0.8800810329563968, disc_loss = 0.0010834801319328795
Trained batch 143 in epoch 6, gen_loss = 0.8800228366421329, disc_loss = 0.0010806921745825093
Trained batch 144 in epoch 6, gen_loss = 0.8798899239507215, disc_loss = 0.0010764481646313878
Trained batch 145 in epoch 6, gen_loss = 0.8797290782405905, disc_loss = 0.0010713346070077346
Trained batch 146 in epoch 6, gen_loss = 0.8795956133985195, disc_loss = 0.0010662851265162787
Trained batch 147 in epoch 6, gen_loss = 0.8790982196459899, disc_loss = 0.0010623262360978344
Trained batch 148 in epoch 6, gen_loss = 0.8788043672606449, disc_loss = 0.0010575790342252903
Trained batch 149 in epoch 6, gen_loss = 0.8786426067352295, disc_loss = 0.0010534990961120153
Trained batch 150 in epoch 6, gen_loss = 0.8785043820640109, disc_loss = 0.0010488993541834049
Trained batch 151 in epoch 6, gen_loss = 0.8784365603014043, disc_loss = 0.0010459251909771027
Trained batch 152 in epoch 6, gen_loss = 0.8782396713892618, disc_loss = 0.0010435425250690576
Trained batch 153 in epoch 6, gen_loss = 0.8779000690231076, disc_loss = 0.0010389790996113888
Trained batch 154 in epoch 6, gen_loss = 0.8776810788339184, disc_loss = 0.0010341460230730234
Trained batch 155 in epoch 6, gen_loss = 0.8776271820832522, disc_loss = 0.0010303186386292323
Trained batch 156 in epoch 6, gen_loss = 0.8780020661414809, disc_loss = 0.0010401023352358514
Trained batch 157 in epoch 6, gen_loss = 0.8774974874303311, disc_loss = 0.0010526455622726367
Trained batch 158 in epoch 6, gen_loss = 0.8774860771197193, disc_loss = 0.00105067719441821
Trained batch 159 in epoch 6, gen_loss = 0.8776514824479819, disc_loss = 0.0010522808785026426
Trained batch 160 in epoch 6, gen_loss = 0.8775216241060577, disc_loss = 0.0010520723649815465
Trained batch 161 in epoch 6, gen_loss = 0.8773452415142531, disc_loss = 0.0010504443334978949
Trained batch 162 in epoch 6, gen_loss = 0.8773169023858989, disc_loss = 0.001047877463772093
Trained batch 163 in epoch 6, gen_loss = 0.8770603403085615, disc_loss = 0.0010468342956212327
Trained batch 164 in epoch 6, gen_loss = 0.8772228461323363, disc_loss = 0.0010496460994931333
Trained batch 165 in epoch 6, gen_loss = 0.8771875716117491, disc_loss = 0.001052556466170957
Trained batch 166 in epoch 6, gen_loss = 0.8767820318301994, disc_loss = 0.001051586001768463
Trained batch 167 in epoch 6, gen_loss = 0.8765436893417722, disc_loss = 0.0010499093567930338
Trained batch 168 in epoch 6, gen_loss = 0.8763129439579664, disc_loss = 0.0010490549711741992
Trained batch 169 in epoch 6, gen_loss = 0.8763962465174058, disc_loss = 0.0010481291539583574
Trained batch 170 in epoch 6, gen_loss = 0.8762831663527684, disc_loss = 0.001052432249665086
Trained batch 171 in epoch 6, gen_loss = 0.87597727706266, disc_loss = 0.001064295344444555
Trained batch 172 in epoch 6, gen_loss = 0.876056112650502, disc_loss = 0.0010738106029958738
Trained batch 173 in epoch 6, gen_loss = 0.8759344566142422, disc_loss = 0.001083146818196294
Trained batch 174 in epoch 6, gen_loss = 0.8759559978757586, disc_loss = 0.0010893078135060413
Trained batch 175 in epoch 6, gen_loss = 0.8755949071862481, disc_loss = 0.001092986277812584
Trained batch 176 in epoch 6, gen_loss = 0.8753090470524157, disc_loss = 0.001093217926126205
Trained batch 177 in epoch 6, gen_loss = 0.8752111363946722, disc_loss = 0.0010911839035747761
Trained batch 178 in epoch 6, gen_loss = 0.8751358133454562, disc_loss = 0.001088183364432888
Trained batch 179 in epoch 6, gen_loss = 0.8753192901611329, disc_loss = 0.0010872150641969508
Trained batch 180 in epoch 6, gen_loss = 0.875332892270378, disc_loss = 0.0010889762374495275
Trained batch 181 in epoch 6, gen_loss = 0.8752363389664954, disc_loss = 0.0010911119298415853
Trained batch 182 in epoch 6, gen_loss = 0.8751497447816401, disc_loss = 0.0010896983401865133
Trained batch 183 in epoch 6, gen_loss = 0.8750037165439647, disc_loss = 0.0010869868922821731
Trained batch 184 in epoch 6, gen_loss = 0.8749182088955029, disc_loss = 0.001084302133263869
Trained batch 185 in epoch 6, gen_loss = 0.8748272791985543, disc_loss = 0.001082755861833932
Trained batch 186 in epoch 6, gen_loss = 0.8746943661873353, disc_loss = 0.001078866536879693
Trained batch 187 in epoch 6, gen_loss = 0.8745031902130614, disc_loss = 0.0010750973355669053
Trained batch 188 in epoch 6, gen_loss = 0.8743918856615742, disc_loss = 0.0010728669471708596
Trained batch 189 in epoch 6, gen_loss = 0.8742378385443437, disc_loss = 0.0010703355934789502
Trained batch 190 in epoch 6, gen_loss = 0.8741834416439396, disc_loss = 0.001066922517347086
Trained batch 191 in epoch 6, gen_loss = 0.8741984923059741, disc_loss = 0.0010648652857222867
Trained batch 192 in epoch 6, gen_loss = 0.874049258664482, disc_loss = 0.001062134777827893
Trained batch 193 in epoch 6, gen_loss = 0.8740223729118859, disc_loss = 0.0010595880757858882
Trained batch 194 in epoch 6, gen_loss = 0.8737608469449557, disc_loss = 0.0010568494810006366
Trained batch 195 in epoch 6, gen_loss = 0.8736147321000391, disc_loss = 0.0010551814003538682
Trained batch 196 in epoch 6, gen_loss = 0.8736196393288936, disc_loss = 0.0010523750818438526
Trained batch 197 in epoch 6, gen_loss = 0.8734834362762143, disc_loss = 0.001048251487475801
Trained batch 198 in epoch 6, gen_loss = 0.8734416500407847, disc_loss = 0.0010444521984429422
Trained batch 199 in epoch 6, gen_loss = 0.8733701744675636, disc_loss = 0.001041049543855479
Trained batch 200 in epoch 6, gen_loss = 0.8733426670529949, disc_loss = 0.0010379784512020815
Trained batch 201 in epoch 6, gen_loss = 0.8733886934743069, disc_loss = 0.001034271308436464
Trained batch 202 in epoch 6, gen_loss = 0.8733001160504196, disc_loss = 0.0010305319414095576
Trained batch 203 in epoch 6, gen_loss = 0.8734315341594172, disc_loss = 0.0010284227240595547
Trained batch 204 in epoch 6, gen_loss = 0.8733063261683395, disc_loss = 0.0010278862303338672
Trained batch 205 in epoch 6, gen_loss = 0.8732662912711356, disc_loss = 0.0010290371944384144
Trained batch 206 in epoch 6, gen_loss = 0.8732222039342502, disc_loss = 0.0010300944231682264
Trained batch 207 in epoch 6, gen_loss = 0.8730961574384799, disc_loss = 0.001030141590000802
Trained batch 208 in epoch 6, gen_loss = 0.8730897036465731, disc_loss = 0.0010283967583389
Trained batch 209 in epoch 6, gen_loss = 0.8728696902592977, disc_loss = 0.0010256057765911377
Trained batch 210 in epoch 6, gen_loss = 0.8726204128061991, disc_loss = 0.0010227840930340432
Trained batch 211 in epoch 6, gen_loss = 0.8726695132143093, disc_loss = 0.0010198144307239244
Trained batch 212 in epoch 6, gen_loss = 0.8725754058976688, disc_loss = 0.001016619989644089
Trained batch 213 in epoch 6, gen_loss = 0.8726560726901081, disc_loss = 0.0010142450592976724
Trained batch 214 in epoch 6, gen_loss = 0.8728377059448597, disc_loss = 0.0010142541788301842
Trained batch 215 in epoch 6, gen_loss = 0.8730286889606051, disc_loss = 0.0010124712875781202
Trained batch 216 in epoch 6, gen_loss = 0.8726898920700846, disc_loss = 0.0010170116020078999
Trained batch 217 in epoch 6, gen_loss = 0.8728785235947425, disc_loss = 0.001016574732344085
Trained batch 218 in epoch 6, gen_loss = 0.8730868468545887, disc_loss = 0.0010178053877039994
Trained batch 219 in epoch 6, gen_loss = 0.8728275813839652, disc_loss = 0.0010167575684714724
Trained batch 220 in epoch 6, gen_loss = 0.872688951265758, disc_loss = 0.0010142145413437613
Trained batch 221 in epoch 6, gen_loss = 0.8726876423702584, disc_loss = 0.0010110053026929145
Trained batch 222 in epoch 6, gen_loss = 0.8725745664583728, disc_loss = 0.0010076314896071588
Trained batch 223 in epoch 6, gen_loss = 0.8724373376795224, disc_loss = 0.0010045628404051449
Trained batch 224 in epoch 6, gen_loss = 0.8723972447713216, disc_loss = 0.0010016201515423342
Trained batch 225 in epoch 6, gen_loss = 0.8725568747098467, disc_loss = 0.0009983065207148862
Trained batch 226 in epoch 6, gen_loss = 0.8725620484562172, disc_loss = 0.000995624670322927
Trained batch 227 in epoch 6, gen_loss = 0.8723968588992169, disc_loss = 0.0009936312632992652
Trained batch 228 in epoch 6, gen_loss = 0.8724062018519406, disc_loss = 0.0009912983623666762
Trained batch 229 in epoch 6, gen_loss = 0.8724850190722424, disc_loss = 0.0009935947760190491
Trained batch 230 in epoch 6, gen_loss = 0.8734380933113428, disc_loss = 0.0009928367451413885
Trained batch 231 in epoch 6, gen_loss = 0.8740504335226684, disc_loss = 0.0009946135587283764
Trained batch 232 in epoch 6, gen_loss = 0.874364903044803, disc_loss = 0.000993568271342585
Trained batch 233 in epoch 6, gen_loss = 0.8747515637650449, disc_loss = 0.0009929805115446385
Trained batch 234 in epoch 6, gen_loss = 0.875015576342319, disc_loss = 0.000991759097025274
Trained batch 235 in epoch 6, gen_loss = 0.875041798767397, disc_loss = 0.0009912658320992427
Trained batch 236 in epoch 6, gen_loss = 0.8754591338242157, disc_loss = 0.0009892147421475326
Trained batch 237 in epoch 6, gen_loss = 0.8757779971391213, disc_loss = 0.0009870194296104082
Trained batch 238 in epoch 6, gen_loss = 0.8759682682268789, disc_loss = 0.0009851391383624054
Trained batch 239 in epoch 6, gen_loss = 0.8760225673516592, disc_loss = 0.0009832773800250532
Trained batch 240 in epoch 6, gen_loss = 0.8760934247020864, disc_loss = 0.0009845513402420595
Trained batch 241 in epoch 6, gen_loss = 0.8761180112184572, disc_loss = 0.000988605012371559
Trained batch 242 in epoch 6, gen_loss = 0.8764276023754858, disc_loss = 0.0009916358740680272
Trained batch 243 in epoch 6, gen_loss = 0.8770238336969595, disc_loss = 0.0009957303768491417
Trained batch 244 in epoch 6, gen_loss = 0.8771806201156305, disc_loss = 0.0009962230679645603
Trained batch 245 in epoch 6, gen_loss = 0.8772775797339959, disc_loss = 0.000994429865741262
Trained batch 246 in epoch 6, gen_loss = 0.8774921645519704, disc_loss = 0.0009921970044315495
Trained batch 247 in epoch 6, gen_loss = 0.8776165304645416, disc_loss = 0.0009894446308364071
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 0.9061580896377563, disc_loss = 0.00032134688808582723
Trained batch 1 in epoch 7, gen_loss = 0.8954446315765381, disc_loss = 0.00037844151665922254
Trained batch 2 in epoch 7, gen_loss = 0.8874728679656982, disc_loss = 0.0004586532498554637
Trained batch 3 in epoch 7, gen_loss = 0.8930152058601379, disc_loss = 0.0004925710745737888
Trained batch 4 in epoch 7, gen_loss = 0.8934524893760681, disc_loss = 0.0005181848478969187
Trained batch 5 in epoch 7, gen_loss = 0.8839150468508402, disc_loss = 0.000535477568822292
Trained batch 6 in epoch 7, gen_loss = 0.8810207673481533, disc_loss = 0.0005433328707502889
Trained batch 7 in epoch 7, gen_loss = 0.8773270845413208, disc_loss = 0.0005653214284393471
Trained batch 8 in epoch 7, gen_loss = 0.8759230640199449, disc_loss = 0.0005751908724454956
Trained batch 9 in epoch 7, gen_loss = 0.8804897606372833, disc_loss = 0.0005817975703394041
Trained batch 10 in epoch 7, gen_loss = 0.8852367672053251, disc_loss = 0.0006008071650285274
Trained batch 11 in epoch 7, gen_loss = 0.883099709947904, disc_loss = 0.0005896467070366876
Trained batch 12 in epoch 7, gen_loss = 0.880471830184643, disc_loss = 0.0005820268169582749
Trained batch 13 in epoch 7, gen_loss = 0.8782767525741032, disc_loss = 0.0005736216012987175
Trained batch 14 in epoch 7, gen_loss = 0.8764649868011475, disc_loss = 0.0005836515959041814
Trained batch 15 in epoch 7, gen_loss = 0.8732736706733704, disc_loss = 0.0006803345131629612
Trained batch 16 in epoch 7, gen_loss = 0.8819895632126752, disc_loss = 0.0008440240087699803
Trained batch 17 in epoch 7, gen_loss = 0.8861468699243333, disc_loss = 0.0008924071153160185
Trained batch 18 in epoch 7, gen_loss = 0.8750175394509968, disc_loss = 0.004400282862326621
Trained batch 19 in epoch 7, gen_loss = 0.9009772807359695, disc_loss = 0.03837507195712533
Trained batch 20 in epoch 7, gen_loss = 0.8911342223485311, disc_loss = 0.05114231627556451
Trained batch 21 in epoch 7, gen_loss = 0.8866771405393427, disc_loss = 0.07382760108818977
Trained batch 22 in epoch 7, gen_loss = 0.8984796223433121, disc_loss = 0.09750494082286225
Trained batch 23 in epoch 7, gen_loss = 0.9059459169705709, disc_loss = 0.11140597096285394
Trained batch 24 in epoch 7, gen_loss = 0.9021615171432495, disc_loss = 0.11743690115166829
Trained batch 25 in epoch 7, gen_loss = 0.9022588569384354, disc_loss = 0.11518701750453776
Trained batch 26 in epoch 7, gen_loss = 0.9039253879476477, disc_loss = 0.1121401252565664
Trained batch 27 in epoch 7, gen_loss = 0.9047761325325284, disc_loss = 0.10882979588807627
Trained batch 28 in epoch 7, gen_loss = 0.9061281516634184, disc_loss = 0.10543916448910624
Trained batch 29 in epoch 7, gen_loss = 0.9052665193875631, disc_loss = 0.10229642953684864
Trained batch 30 in epoch 7, gen_loss = 0.9102947481216923, disc_loss = 0.09945296688989226
Trained batch 31 in epoch 7, gen_loss = 0.9195773489773273, disc_loss = 0.09664840496225224
Trained batch 32 in epoch 7, gen_loss = 0.9251933784195872, disc_loss = 0.09386922758263112
Trained batch 33 in epoch 7, gen_loss = 0.9292360333835378, disc_loss = 0.0911939261970795
Trained batch 34 in epoch 7, gen_loss = 0.9333716256277902, disc_loss = 0.0886618780155134
Trained batch 35 in epoch 7, gen_loss = 0.9361160695552826, disc_loss = 0.0862635040135097
Trained batch 36 in epoch 7, gen_loss = 0.939749585615622, disc_loss = 0.08397328041688967
Trained batch 37 in epoch 7, gen_loss = 0.9429033775078622, disc_loss = 0.08180190830362814
Trained batch 38 in epoch 7, gen_loss = 0.9465529032242603, disc_loss = 0.07973887170336615
Trained batch 39 in epoch 7, gen_loss = 0.9488407224416733, disc_loss = 0.0777896981642698
Trained batch 40 in epoch 7, gen_loss = 0.9508527866223964, disc_loss = 0.07592860020543789
Trained batch 41 in epoch 7, gen_loss = 0.9529572668529692, disc_loss = 0.07416482383268885
Trained batch 42 in epoch 7, gen_loss = 0.9549119555672934, disc_loss = 0.072486333628889
Trained batch 43 in epoch 7, gen_loss = 0.95684014396234, disc_loss = 0.07088639480670364
Trained batch 44 in epoch 7, gen_loss = 0.9580562035242717, disc_loss = 0.06937679295402227
Trained batch 45 in epoch 7, gen_loss = 0.9603160619735718, disc_loss = 0.0679058421835931
Trained batch 46 in epoch 7, gen_loss = 0.9625772263141389, disc_loss = 0.06655492596798873
Trained batch 47 in epoch 7, gen_loss = 0.9638985221584638, disc_loss = 0.06525702963578321
Trained batch 48 in epoch 7, gen_loss = 0.9660707322918639, disc_loss = 0.06396933126486648
Trained batch 49 in epoch 7, gen_loss = 0.9673266005516052, disc_loss = 0.06274511973722838
Trained batch 50 in epoch 7, gen_loss = 0.9679348270098368, disc_loss = 0.06156721618368893
Trained batch 51 in epoch 7, gen_loss = 0.9690012576488348, disc_loss = 0.06040514543621192
Trained batch 52 in epoch 7, gen_loss = 0.9698363643772198, disc_loss = 0.05928312915812229
Trained batch 53 in epoch 7, gen_loss = 0.9709172348181406, disc_loss = 0.058200081651901
Trained batch 54 in epoch 7, gen_loss = 0.9719922380013899, disc_loss = 0.057164115766698324
Trained batch 55 in epoch 7, gen_loss = 0.9729135089686939, disc_loss = 0.056163051152127864
Trained batch 56 in epoch 7, gen_loss = 0.9742441355136403, disc_loss = 0.05519511143517632
Trained batch 57 in epoch 7, gen_loss = 0.9751642007252266, disc_loss = 0.05425539946761625
Trained batch 58 in epoch 7, gen_loss = 0.9759364219035133, disc_loss = 0.05334646884407217
Trained batch 59 in epoch 7, gen_loss = 0.9759501149257024, disc_loss = 0.052483521318451194
Trained batch 60 in epoch 7, gen_loss = 0.976501323160578, disc_loss = 0.051654754609220706
Trained batch 61 in epoch 7, gen_loss = 0.976590794901694, disc_loss = 0.050837298872084505
Trained batch 62 in epoch 7, gen_loss = 0.9772610702211895, disc_loss = 0.05004501397747339
Trained batch 63 in epoch 7, gen_loss = 0.9774801507592201, disc_loss = 0.049281746149972605
Trained batch 64 in epoch 7, gen_loss = 0.977925285926232, disc_loss = 0.048535416656746884
Trained batch 65 in epoch 7, gen_loss = 0.9786612843022202, disc_loss = 0.047812593094545955
Trained batch 66 in epoch 7, gen_loss = 0.9787088027640954, disc_loss = 0.04711763483711949
Trained batch 67 in epoch 7, gen_loss = 0.979534280650756, disc_loss = 0.04644650273685864
Trained batch 68 in epoch 7, gen_loss = 0.9801588974137238, disc_loss = 0.0457874846828602
Trained batch 69 in epoch 7, gen_loss = 0.9805654968534198, disc_loss = 0.04514235669048503
Trained batch 70 in epoch 7, gen_loss = 0.9808749212345607, disc_loss = 0.044515136090717215
Trained batch 71 in epoch 7, gen_loss = 0.9811148229572508, disc_loss = 0.04390853281155513
Trained batch 72 in epoch 7, gen_loss = 0.9823120669142841, disc_loss = 0.04331787599470747
Trained batch 73 in epoch 7, gen_loss = 0.9829048965428326, disc_loss = 0.042771869613568776
Trained batch 74 in epoch 7, gen_loss = 0.983475325902303, disc_loss = 0.04223846135738616
Trained batch 75 in epoch 7, gen_loss = 0.9839437415725306, disc_loss = 0.04169881985274658
Trained batch 76 in epoch 7, gen_loss = 0.9843598000414959, disc_loss = 0.041166257940220656
Trained batch 77 in epoch 7, gen_loss = 0.9847517762428675, disc_loss = 0.04064746711250896
Trained batch 78 in epoch 7, gen_loss = 0.9855633174316792, disc_loss = 0.040141065224056145
Trained batch 79 in epoch 7, gen_loss = 0.9855609990656375, disc_loss = 0.039647573178081076
Trained batch 80 in epoch 7, gen_loss = 0.985926334504728, disc_loss = 0.039173494043535796
Trained batch 81 in epoch 7, gen_loss = 0.98546940815158, disc_loss = 0.03871105283586786
Trained batch 82 in epoch 7, gen_loss = 0.9861308968210795, disc_loss = 0.03825464208416798
Trained batch 83 in epoch 7, gen_loss = 0.9861281159378233, disc_loss = 0.037810969246146714
Trained batch 84 in epoch 7, gen_loss = 0.9862483150818768, disc_loss = 0.03738080349490595
Trained batch 85 in epoch 7, gen_loss = 0.9860307019810344, disc_loss = 0.036955869257812884
Trained batch 86 in epoch 7, gen_loss = 0.9868526006567067, disc_loss = 0.036540828666639054
Trained batch 87 in epoch 7, gen_loss = 0.9872714497826316, disc_loss = 0.03613452882498016
Trained batch 88 in epoch 7, gen_loss = 0.9870964991912413, disc_loss = 0.0357384016741266
Trained batch 89 in epoch 7, gen_loss = 0.9874064796500736, disc_loss = 0.035347040090063175
Trained batch 90 in epoch 7, gen_loss = 0.9874118808861617, disc_loss = 0.03496753032175967
Trained batch 91 in epoch 7, gen_loss = 0.9873939856238987, disc_loss = 0.03460034158247847
Trained batch 92 in epoch 7, gen_loss = 0.9879300914784913, disc_loss = 0.034238397491775374
Trained batch 93 in epoch 7, gen_loss = 0.9881135745251433, disc_loss = 0.033880668966609864
Trained batch 94 in epoch 7, gen_loss = 0.9886299748169748, disc_loss = 0.03353305824689175
Trained batch 95 in epoch 7, gen_loss = 0.988368384540081, disc_loss = 0.03319190322933233
Trained batch 96 in epoch 7, gen_loss = 0.9887973868969789, disc_loss = 0.03286231959961144
Trained batch 97 in epoch 7, gen_loss = 0.989359223112768, disc_loss = 0.03253604416861389
Trained batch 98 in epoch 7, gen_loss = 0.989470939443569, disc_loss = 0.032216392334602356
Trained batch 99 in epoch 7, gen_loss = 0.9894553518295288, disc_loss = 0.031902638569590636
Trained batch 100 in epoch 7, gen_loss = 0.9894312620162964, disc_loss = 0.03159397023345003
Trained batch 101 in epoch 7, gen_loss = 0.9891925237926782, disc_loss = 0.03128882292395586
Trained batch 102 in epoch 7, gen_loss = 0.9892843857552241, disc_loss = 0.030989371286761647
Trained batch 103 in epoch 7, gen_loss = 0.9898101435257838, disc_loss = 0.030697787687901067
Trained batch 104 in epoch 7, gen_loss = 0.9897614445005144, disc_loss = 0.03042531613443446
Trained batch 105 in epoch 7, gen_loss = 0.9896364307628488, disc_loss = 0.030150912662820873
Trained batch 106 in epoch 7, gen_loss = 0.9893840629363728, disc_loss = 0.029874176813766064
Trained batch 107 in epoch 7, gen_loss = 0.9894755272953598, disc_loss = 0.029604168575638648
Trained batch 108 in epoch 7, gen_loss = 0.989487457712856, disc_loss = 0.029338354730515083
Trained batch 109 in epoch 7, gen_loss = 0.989431940425526, disc_loss = 0.02908100594993977
Trained batch 110 in epoch 7, gen_loss = 0.9895086578420691, disc_loss = 0.028827445748574647
Trained batch 111 in epoch 7, gen_loss = 0.9894711061247757, disc_loss = 0.028576094407461432
Trained batch 112 in epoch 7, gen_loss = 0.989472380254121, disc_loss = 0.02833089380977321
Trained batch 113 in epoch 7, gen_loss = 0.989506242045185, disc_loss = 0.028087016375043038
Trained batch 114 in epoch 7, gen_loss = 0.9893574652464493, disc_loss = 0.027847954709558625
Trained batch 115 in epoch 7, gen_loss = 0.9895030701982563, disc_loss = 0.02761495552313763
Trained batch 116 in epoch 7, gen_loss = 0.9895990536763117, disc_loss = 0.027384993871703792
Trained batch 117 in epoch 7, gen_loss = 0.9897847610004877, disc_loss = 0.027157967290357625
Trained batch 118 in epoch 7, gen_loss = 0.9896185092565393, disc_loss = 0.026933458587497145
Trained batch 119 in epoch 7, gen_loss = 0.9899412656823794, disc_loss = 0.026713384028941314
Trained batch 120 in epoch 7, gen_loss = 0.9901582352386034, disc_loss = 0.026499139280433667
Trained batch 121 in epoch 7, gen_loss = 0.9902755906347369, disc_loss = 0.02628723525114884
Trained batch 122 in epoch 7, gen_loss = 0.9905504148180891, disc_loss = 0.02607840516843939
Trained batch 123 in epoch 7, gen_loss = 0.990690228919829, disc_loss = 0.02587387151194684
Trained batch 124 in epoch 7, gen_loss = 0.9905763669013977, disc_loss = 0.02566989791812375
Trained batch 125 in epoch 7, gen_loss = 0.9903795700224619, disc_loss = 0.025469131421044632
Trained batch 126 in epoch 7, gen_loss = 0.9904228345615658, disc_loss = 0.025271416197881088
Trained batch 127 in epoch 7, gen_loss = 0.9901902368292212, disc_loss = 0.02508187660873773
Trained batch 128 in epoch 7, gen_loss = 0.9898386556048726, disc_loss = 0.02489755220883598
Trained batch 129 in epoch 7, gen_loss = 0.9899814440653875, disc_loss = 0.024712854045971584
Trained batch 130 in epoch 7, gen_loss = 0.9898282680802672, disc_loss = 0.024529115130497454
Trained batch 131 in epoch 7, gen_loss = 0.9899504374374043, disc_loss = 0.024346293930703367
Trained batch 132 in epoch 7, gen_loss = 0.9904073907020396, disc_loss = 0.024166912824060784
Trained batch 133 in epoch 7, gen_loss = 0.9904276386125764, disc_loss = 0.023991347792942368
Trained batch 134 in epoch 7, gen_loss = 0.9902652144432068, disc_loss = 0.023817708482319074
Trained batch 135 in epoch 7, gen_loss = 0.9903001487255096, disc_loss = 0.023646186335099628
Trained batch 136 in epoch 7, gen_loss = 0.9902877172414404, disc_loss = 0.023478323793638647
Trained batch 137 in epoch 7, gen_loss = 0.9902999211048734, disc_loss = 0.023319720639214527
Trained batch 138 in epoch 7, gen_loss = 0.9906998426794148, disc_loss = 0.02315755724875933
Trained batch 139 in epoch 7, gen_loss = 0.9907294030700411, disc_loss = 0.02299681371348145
Trained batch 140 in epoch 7, gen_loss = 0.9905407547105288, disc_loss = 0.022839684490773313
Trained batch 141 in epoch 7, gen_loss = 0.9903158499321467, disc_loss = 0.02268368890406531
Trained batch 142 in epoch 7, gen_loss = 0.990096266036267, disc_loss = 0.022528627601010934
Trained batch 143 in epoch 7, gen_loss = 0.9898597883681456, disc_loss = 0.022375045464084704
Trained batch 144 in epoch 7, gen_loss = 0.9899289616223039, disc_loss = 0.02222346053358392
Trained batch 145 in epoch 7, gen_loss = 0.9899317728330012, disc_loss = 0.022073957902636086
Trained batch 146 in epoch 7, gen_loss = 0.9898028730535183, disc_loss = 0.021926152604619407
Trained batch 147 in epoch 7, gen_loss = 0.9897537336156175, disc_loss = 0.021781069536872737
Trained batch 148 in epoch 7, gen_loss = 0.989584540360726, disc_loss = 0.021638296312111862
Trained batch 149 in epoch 7, gen_loss = 0.9896343123912811, disc_loss = 0.02149619600813215
Trained batch 150 in epoch 7, gen_loss = 0.9897950260054986, disc_loss = 0.021359425470609192
Trained batch 151 in epoch 7, gen_loss = 0.989778813955031, disc_loss = 0.021229662754003106
Trained batch 152 in epoch 7, gen_loss = 0.9897570941183302, disc_loss = 0.0211008007522502
Trained batch 153 in epoch 7, gen_loss = 0.9900531973931697, disc_loss = 0.020968738077026972
Trained batch 154 in epoch 7, gen_loss = 0.9900223308993924, disc_loss = 0.020835606320460717
Trained batch 155 in epoch 7, gen_loss = 0.9900721376522993, disc_loss = 0.020707679289327457
Trained batch 156 in epoch 7, gen_loss = 0.9901898207178541, disc_loss = 0.020580100691595535
Trained batch 157 in epoch 7, gen_loss = 0.9900801136523862, disc_loss = 0.020453241603269206
Trained batch 158 in epoch 7, gen_loss = 0.9903300228358815, disc_loss = 0.020331348526458484
Trained batch 159 in epoch 7, gen_loss = 0.9903786793351174, disc_loss = 0.02020849505388469
Trained batch 160 in epoch 7, gen_loss = 0.9903474775900752, disc_loss = 0.020086174932748127
Trained batch 161 in epoch 7, gen_loss = 0.9903866096779153, disc_loss = 0.019968384242311902
Trained batch 162 in epoch 7, gen_loss = 0.9902280832360859, disc_loss = 0.019851089233069743
Trained batch 163 in epoch 7, gen_loss = 0.9899755207503714, disc_loss = 0.01973827311800361
Trained batch 164 in epoch 7, gen_loss = 0.9900991461493752, disc_loss = 0.019629970088488224
Trained batch 165 in epoch 7, gen_loss = 0.9899329094283552, disc_loss = 0.019516405518340642
Trained batch 166 in epoch 7, gen_loss = 0.9898626151199112, disc_loss = 0.01940170007469941
Trained batch 167 in epoch 7, gen_loss = 0.9898981888379369, disc_loss = 0.019288267996584875
Trained batch 168 in epoch 7, gen_loss = 0.9899718094859603, disc_loss = 0.019176833366888392
Trained batch 169 in epoch 7, gen_loss = 0.9898268271895015, disc_loss = 0.0190664006241337
Trained batch 170 in epoch 7, gen_loss = 0.9896385202630918, disc_loss = 0.018957385381789912
Trained batch 171 in epoch 7, gen_loss = 0.9895766574976056, disc_loss = 0.018849220656489325
Trained batch 172 in epoch 7, gen_loss = 0.9893592913026754, disc_loss = 0.018743224780820848
Trained batch 173 in epoch 7, gen_loss = 0.9891950508643841, disc_loss = 0.018637588818024995
Trained batch 174 in epoch 7, gen_loss = 0.9891352714811052, disc_loss = 0.018533993170130998
Trained batch 175 in epoch 7, gen_loss = 0.989232515746897, disc_loss = 0.018431231603740758
Trained batch 176 in epoch 7, gen_loss = 0.9890381818437307, disc_loss = 0.018329508620048583
Trained batch 177 in epoch 7, gen_loss = 0.9891355426123972, disc_loss = 0.018229412282830145
Trained batch 178 in epoch 7, gen_loss = 0.9890852107682042, disc_loss = 0.018130786460369055
Trained batch 179 in epoch 7, gen_loss = 0.9892276684443156, disc_loss = 0.018032531457720324
Trained batch 180 in epoch 7, gen_loss = 0.9891337762221447, disc_loss = 0.017934862032721786
Trained batch 181 in epoch 7, gen_loss = 0.9891275645612361, disc_loss = 0.017838141989509147
Trained batch 182 in epoch 7, gen_loss = 0.9890663767121529, disc_loss = 0.017743779773043998
Trained batch 183 in epoch 7, gen_loss = 0.9894503912200099, disc_loss = 0.017650959752443116
Trained batch 184 in epoch 7, gen_loss = 0.9892600748990034, disc_loss = 0.017558018830321678
Trained batch 185 in epoch 7, gen_loss = 0.9893030354412653, disc_loss = 0.017466274071804008
Trained batch 186 in epoch 7, gen_loss = 0.9894296303789883, disc_loss = 0.01737539192822259
Trained batch 187 in epoch 7, gen_loss = 0.9892399840532465, disc_loss = 0.01728493524445939
Trained batch 188 in epoch 7, gen_loss = 0.9892041165992697, disc_loss = 0.017195178240182855
Trained batch 189 in epoch 7, gen_loss = 0.9892714098880165, disc_loss = 0.017106978552060594
Trained batch 190 in epoch 7, gen_loss = 0.9894021562256738, disc_loss = 0.01701941601846718
Trained batch 191 in epoch 7, gen_loss = 0.9894614722579718, disc_loss = 0.016933122224751667
Trained batch 192 in epoch 7, gen_loss = 0.9896911530914702, disc_loss = 0.01684812311453436
Trained batch 193 in epoch 7, gen_loss = 0.9896520800197247, disc_loss = 0.016763138197441633
Trained batch 194 in epoch 7, gen_loss = 0.9897777991417127, disc_loss = 0.01667972658850396
Trained batch 195 in epoch 7, gen_loss = 0.9896586221091601, disc_loss = 0.01659673169906826
Trained batch 196 in epoch 7, gen_loss = 0.9898590079418899, disc_loss = 0.0165146580734172
Trained batch 197 in epoch 7, gen_loss = 0.9899303569938197, disc_loss = 0.016436707795211912
Trained batch 198 in epoch 7, gen_loss = 0.9898067020890701, disc_loss = 0.01635786870099024
Trained batch 199 in epoch 7, gen_loss = 0.989587415754795, disc_loss = 0.01628372129285708
Trained batch 200 in epoch 7, gen_loss = 0.9894997619870883, disc_loss = 0.01620814536260302
Trained batch 201 in epoch 7, gen_loss = 0.9893652982640975, disc_loss = 0.016130895396789056
Trained batch 202 in epoch 7, gen_loss = 0.9892154873298307, disc_loss = 0.016053213693317383
Trained batch 203 in epoch 7, gen_loss = 0.9892473735061347, disc_loss = 0.015977429794278863
Trained batch 204 in epoch 7, gen_loss = 0.9891752737324412, disc_loss = 0.015901959724241594
Trained batch 205 in epoch 7, gen_loss = 0.9890332453459212, disc_loss = 0.015826802203732372
Trained batch 206 in epoch 7, gen_loss = 0.9886985588188909, disc_loss = 0.015755589714820457
Trained batch 207 in epoch 7, gen_loss = 0.9886095182826886, disc_loss = 0.015685242667621842
Trained batch 208 in epoch 7, gen_loss = 0.9885682996950651, disc_loss = 0.015612185797759925
Trained batch 209 in epoch 7, gen_loss = 0.988644640218644, disc_loss = 0.015539391761385126
Trained batch 210 in epoch 7, gen_loss = 0.9885943986793265, disc_loss = 0.015467328979590713
Trained batch 211 in epoch 7, gen_loss = 0.988487036160703, disc_loss = 0.01539618147271883
Trained batch 212 in epoch 7, gen_loss = 0.9882848660151163, disc_loss = 0.015325203569231012
Trained batch 213 in epoch 7, gen_loss = 0.9882210055801356, disc_loss = 0.015254933222074054
Trained batch 214 in epoch 7, gen_loss = 0.9881956921067349, disc_loss = 0.015185280550585323
Trained batch 215 in epoch 7, gen_loss = 0.9880670960302707, disc_loss = 0.015116195060895902
Trained batch 216 in epoch 7, gen_loss = 0.9879756907713578, disc_loss = 0.015047892846042625
Trained batch 217 in epoch 7, gen_loss = 0.98790817741954, disc_loss = 0.014980352258068347
Trained batch 218 in epoch 7, gen_loss = 0.9881390001131519, disc_loss = 0.014914264176072783
Trained batch 219 in epoch 7, gen_loss = 0.9881224597042257, disc_loss = 0.014849196729747664
Trained batch 220 in epoch 7, gen_loss = 0.9880746238911313, disc_loss = 0.014785074553298616
Trained batch 221 in epoch 7, gen_loss = 0.988060778057253, disc_loss = 0.014720804526560797
Trained batch 222 in epoch 7, gen_loss = 0.9881797090774159, disc_loss = 0.01465795953333119
Trained batch 223 in epoch 7, gen_loss = 0.9881462712905237, disc_loss = 0.014596108523619478
Trained batch 224 in epoch 7, gen_loss = 0.988243698808882, disc_loss = 0.014534310899260971
Trained batch 225 in epoch 7, gen_loss = 0.9881398369253209, disc_loss = 0.014471644262522582
Trained batch 226 in epoch 7, gen_loss = 0.9879107372876306, disc_loss = 0.014409797166121327
Trained batch 227 in epoch 7, gen_loss = 0.987703561521413, disc_loss = 0.014348952675630388
Trained batch 228 in epoch 7, gen_loss = 0.987827292436075, disc_loss = 0.014287873314501409
Trained batch 229 in epoch 7, gen_loss = 0.9877317436363386, disc_loss = 0.014228675929885155
Trained batch 230 in epoch 7, gen_loss = 0.9875779448649584, disc_loss = 0.014170788729576458
Trained batch 231 in epoch 7, gen_loss = 0.9873764147532398, disc_loss = 0.014113464324101845
Trained batch 232 in epoch 7, gen_loss = 0.9873006730120581, disc_loss = 0.014055084520945917
Trained batch 233 in epoch 7, gen_loss = 0.9873691596027113, disc_loss = 0.013996199228722228
Trained batch 234 in epoch 7, gen_loss = 0.9875506149961594, disc_loss = 0.013938607807404937
Trained batch 235 in epoch 7, gen_loss = 0.9875135237382631, disc_loss = 0.013880949179588627
Trained batch 236 in epoch 7, gen_loss = 0.9874656889509048, disc_loss = 0.013825511697135504
Trained batch 237 in epoch 7, gen_loss = 0.9874881155350629, disc_loss = 0.013770684736591036
Trained batch 238 in epoch 7, gen_loss = 0.9873465010311813, disc_loss = 0.013715515808235448
Trained batch 239 in epoch 7, gen_loss = 0.9873810817797979, disc_loss = 0.013660428375684812
Trained batch 240 in epoch 7, gen_loss = 0.9874350945484589, disc_loss = 0.013605667335895195
Trained batch 241 in epoch 7, gen_loss = 0.9874227037114546, disc_loss = 0.013551695081588143
Trained batch 242 in epoch 7, gen_loss = 0.9873077111479677, disc_loss = 0.01349898407124596
Trained batch 243 in epoch 7, gen_loss = 0.9873572267958375, disc_loss = 0.013445386197179419
Trained batch 244 in epoch 7, gen_loss = 0.9872063736526333, disc_loss = 0.013392116916627263
Trained batch 245 in epoch 7, gen_loss = 0.9873382989468613, disc_loss = 0.013340237106189957
Trained batch 246 in epoch 7, gen_loss = 0.9871360920218804, disc_loss = 0.013288459309441818
Trained batch 247 in epoch 7, gen_loss = 0.9869699336348041, disc_loss = 0.013235847431309183
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 1.0095551013946533, disc_loss = 0.00044700736179947853
Trained batch 1 in epoch 8, gen_loss = 0.9717589914798737, disc_loss = 0.00043739193642977625
Trained batch 2 in epoch 8, gen_loss = 0.984440545241038, disc_loss = 0.0003997287421952933
Trained batch 3 in epoch 8, gen_loss = 0.9836573749780655, disc_loss = 0.0003546441475918982
Trained batch 4 in epoch 8, gen_loss = 0.9768076300621032, disc_loss = 0.00037329231563489886
Trained batch 5 in epoch 8, gen_loss = 0.9779932598272959, disc_loss = 0.00038634658994851634
Trained batch 6 in epoch 8, gen_loss = 0.9809334363256182, disc_loss = 0.0003658252805637728
Trained batch 7 in epoch 8, gen_loss = 0.983240395784378, disc_loss = 0.000353427725713118
Trained batch 8 in epoch 8, gen_loss = 0.986581457985772, disc_loss = 0.0003683154532660006
Trained batch 9 in epoch 8, gen_loss = 0.9844362914562226, disc_loss = 0.00035654883104143666
Trained batch 10 in epoch 8, gen_loss = 0.9852532365105369, disc_loss = 0.00034715810298538685
Trained batch 11 in epoch 8, gen_loss = 0.9830481112003326, disc_loss = 0.0003500856776857593
Trained batch 12 in epoch 8, gen_loss = 0.9835585355758667, disc_loss = 0.0003460250053859244
Trained batch 13 in epoch 8, gen_loss = 0.9855357749121529, disc_loss = 0.0003539892485215595
Trained batch 14 in epoch 8, gen_loss = 0.984183152516683, disc_loss = 0.0004096640807498867
Trained batch 15 in epoch 8, gen_loss = 0.9842256717383862, disc_loss = 0.0004416583460624679
Trained batch 16 in epoch 8, gen_loss = 0.9844776637413922, disc_loss = 0.0004395744069958763
Trained batch 17 in epoch 8, gen_loss = 0.9823718236552345, disc_loss = 0.00043582285919304314
Trained batch 18 in epoch 8, gen_loss = 0.9821132829314784, disc_loss = 0.00043680543297485103
Trained batch 19 in epoch 8, gen_loss = 0.9824821323156356, disc_loss = 0.0004310549884394277
Trained batch 20 in epoch 8, gen_loss = 0.9822782561892555, disc_loss = 0.00043396354955066706
Trained batch 21 in epoch 8, gen_loss = 0.9812444231726907, disc_loss = 0.0004346519503583708
Trained batch 22 in epoch 8, gen_loss = 0.9827498404876046, disc_loss = 0.00044420815095730614
Trained batch 23 in epoch 8, gen_loss = 0.9815608486533165, disc_loss = 0.0004460038295898509
Trained batch 24 in epoch 8, gen_loss = 0.9809128880500794, disc_loss = 0.0004594809765694663
Trained batch 25 in epoch 8, gen_loss = 0.9787214375459231, disc_loss = 0.00047304805607731955
Trained batch 26 in epoch 8, gen_loss = 0.9786427793679414, disc_loss = 0.00048412881410008087
Trained batch 27 in epoch 8, gen_loss = 0.9788771505866732, disc_loss = 0.00048168266169211293
Trained batch 28 in epoch 8, gen_loss = 0.9789530963733278, disc_loss = 0.0004779477919861353
Trained batch 29 in epoch 8, gen_loss = 0.9792307158311208, disc_loss = 0.00047360969037981706
Trained batch 30 in epoch 8, gen_loss = 0.9807131463481534, disc_loss = 0.0004668027916434972
Trained batch 31 in epoch 8, gen_loss = 0.9813616890460253, disc_loss = 0.0004662789829126268
Trained batch 32 in epoch 8, gen_loss = 0.9803817434744402, disc_loss = 0.0004636878751846256
Trained batch 33 in epoch 8, gen_loss = 0.9810444695108077, disc_loss = 0.0004586840603973114
Trained batch 34 in epoch 8, gen_loss = 0.9807472007615226, disc_loss = 0.00045740010474608947
Trained batch 35 in epoch 8, gen_loss = 0.9814956800805198, disc_loss = 0.00046218047686529136
Trained batch 36 in epoch 8, gen_loss = 0.9810172561052684, disc_loss = 0.00046371547717638815
Trained batch 37 in epoch 8, gen_loss = 0.9811748281905526, disc_loss = 0.00045824006902924
Trained batch 38 in epoch 8, gen_loss = 0.980961785866664, disc_loss = 0.00045234286666620907
Trained batch 39 in epoch 8, gen_loss = 0.9804148241877556, disc_loss = 0.00044804809185734485
Trained batch 40 in epoch 8, gen_loss = 0.9799827002897495, disc_loss = 0.00044122871108035123
Trained batch 41 in epoch 8, gen_loss = 0.9809738553705669, disc_loss = 0.0004394955758471042
Trained batch 42 in epoch 8, gen_loss = 0.9809083495029184, disc_loss = 0.00043540224392335253
Trained batch 43 in epoch 8, gen_loss = 0.9810991571708159, disc_loss = 0.0004309738439835862
Trained batch 44 in epoch 8, gen_loss = 0.9810138331519233, disc_loss = 0.00042701744500340687
Trained batch 45 in epoch 8, gen_loss = 0.9814152238161667, disc_loss = 0.0004223374632166942
Trained batch 46 in epoch 8, gen_loss = 0.9818596421404088, disc_loss = 0.00042177161370265357
Trained batch 47 in epoch 8, gen_loss = 0.9809974692761898, disc_loss = 0.00042190958750628244
Trained batch 48 in epoch 8, gen_loss = 0.9815964370357747, disc_loss = 0.0004209073976737124
Trained batch 49 in epoch 8, gen_loss = 0.9817470860481262, disc_loss = 0.0004174770490499213
Trained batch 50 in epoch 8, gen_loss = 0.9823022589964026, disc_loss = 0.0004148696984082241
Trained batch 51 in epoch 8, gen_loss = 0.9829824406367081, disc_loss = 0.00041629465760287043
Trained batch 52 in epoch 8, gen_loss = 0.9834612248078832, disc_loss = 0.0004149860546502443
Trained batch 53 in epoch 8, gen_loss = 0.983618602708534, disc_loss = 0.0004138681569774808
Trained batch 54 in epoch 8, gen_loss = 0.9830905697562478, disc_loss = 0.0004134958419440822
Trained batch 55 in epoch 8, gen_loss = 0.9836822897195816, disc_loss = 0.000414172733144369
Trained batch 56 in epoch 8, gen_loss = 0.9840742433280275, disc_loss = 0.0004127406455952217
Trained batch 57 in epoch 8, gen_loss = 0.9845795775281971, disc_loss = 0.00041086287920138445
Trained batch 58 in epoch 8, gen_loss = 0.9843801795426061, disc_loss = 0.0004089775656042147
Trained batch 59 in epoch 8, gen_loss = 0.9835379650195439, disc_loss = 0.0004115144280755582
Trained batch 60 in epoch 8, gen_loss = 0.9829468443745473, disc_loss = 0.0004120352358335904
Trained batch 61 in epoch 8, gen_loss = 0.9831936695883351, disc_loss = 0.00041140610119327903
Trained batch 62 in epoch 8, gen_loss = 0.983307333219619, disc_loss = 0.00041391371494336495
Trained batch 63 in epoch 8, gen_loss = 0.9829751718789339, disc_loss = 0.00041232548846892314
Trained batch 64 in epoch 8, gen_loss = 0.982252130141625, disc_loss = 0.0004116042651450978
Trained batch 65 in epoch 8, gen_loss = 0.9818543719522881, disc_loss = 0.000415121015535216
Trained batch 66 in epoch 8, gen_loss = 0.9819807072183979, disc_loss = 0.0004218192727638603
Trained batch 67 in epoch 8, gen_loss = 0.9818697387681288, disc_loss = 0.00042198367437402555
Trained batch 68 in epoch 8, gen_loss = 0.9812821495360222, disc_loss = 0.0004252902353587358
Trained batch 69 in epoch 8, gen_loss = 0.9811234303883144, disc_loss = 0.000432372247866754
Trained batch 70 in epoch 8, gen_loss = 0.9807568855688605, disc_loss = 0.0004336698756317123
Trained batch 71 in epoch 8, gen_loss = 0.9812258382638296, disc_loss = 0.0004332206861161265
Trained batch 72 in epoch 8, gen_loss = 0.9810293300511086, disc_loss = 0.00043188913267628887
Trained batch 73 in epoch 8, gen_loss = 0.9808572216613872, disc_loss = 0.0004337009973037434
Trained batch 74 in epoch 8, gen_loss = 0.9809695855776469, disc_loss = 0.000434730511236315
Trained batch 75 in epoch 8, gen_loss = 0.9808199860547718, disc_loss = 0.0004345219357147519
Trained batch 76 in epoch 8, gen_loss = 0.9809093506305249, disc_loss = 0.0004362175142840035
Trained batch 77 in epoch 8, gen_loss = 0.9806859699579386, disc_loss = 0.000435251628424829
Trained batch 78 in epoch 8, gen_loss = 0.9804863982562777, disc_loss = 0.00043239142680157543
Trained batch 79 in epoch 8, gen_loss = 0.9800069786608219, disc_loss = 0.00043039378015237163
Trained batch 80 in epoch 8, gen_loss = 0.9802302276646649, disc_loss = 0.0004287635518401792
Trained batch 81 in epoch 8, gen_loss = 0.9796525378052782, disc_loss = 0.00042850635260792175
Trained batch 82 in epoch 8, gen_loss = 0.97938309089247, disc_loss = 0.00042758501399201845
Trained batch 83 in epoch 8, gen_loss = 0.9794135093688965, disc_loss = 0.0004261462192863248
Trained batch 84 in epoch 8, gen_loss = 0.979555277263417, disc_loss = 0.00042408482729703847
Trained batch 85 in epoch 8, gen_loss = 0.9795701954253885, disc_loss = 0.00042123946467506547
Trained batch 86 in epoch 8, gen_loss = 0.9792965177831978, disc_loss = 0.0004186435519308173
Trained batch 87 in epoch 8, gen_loss = 0.9792009395631877, disc_loss = 0.00041565733359179416
Trained batch 88 in epoch 8, gen_loss = 0.979268619853459, disc_loss = 0.00041387682231901776
Trained batch 89 in epoch 8, gen_loss = 0.9794726292292277, disc_loss = 0.00041295542145639453
Trained batch 90 in epoch 8, gen_loss = 0.9795247499759381, disc_loss = 0.00041072454369386435
Trained batch 91 in epoch 8, gen_loss = 0.9792946266091388, disc_loss = 0.0004086852607977799
Trained batch 92 in epoch 8, gen_loss = 0.9787972223374152, disc_loss = 0.0004065116000254088
Trained batch 93 in epoch 8, gen_loss = 0.9781649169769693, disc_loss = 0.0004120401586368779
Trained batch 94 in epoch 8, gen_loss = 0.9780606847060355, disc_loss = 0.0004204445066677995
Trained batch 95 in epoch 8, gen_loss = 0.977996493379275, disc_loss = 0.00042462712872293196
Trained batch 96 in epoch 8, gen_loss = 0.9784526763503084, disc_loss = 0.000426888506236659
Trained batch 97 in epoch 8, gen_loss = 0.9783884627478463, disc_loss = 0.00042561655380045615
Trained batch 98 in epoch 8, gen_loss = 0.9786606581524165, disc_loss = 0.00042472331595931655
Trained batch 99 in epoch 8, gen_loss = 0.9783577442169189, disc_loss = 0.0004233453956840094
Trained batch 100 in epoch 8, gen_loss = 0.9784088294104775, disc_loss = 0.0004221436924630739
Trained batch 101 in epoch 8, gen_loss = 0.9781369385766048, disc_loss = 0.00042137852227931623
Trained batch 102 in epoch 8, gen_loss = 0.9779493189552455, disc_loss = 0.0004228028298968232
Trained batch 103 in epoch 8, gen_loss = 0.9781778655373133, disc_loss = 0.0004267941116827737
Trained batch 104 in epoch 8, gen_loss = 0.9784027025813148, disc_loss = 0.00042744310769540745
Trained batch 105 in epoch 8, gen_loss = 0.97812937734262, disc_loss = 0.00042830195751827524
Trained batch 106 in epoch 8, gen_loss = 0.9784991824738333, disc_loss = 0.00042992317437076785
Trained batch 107 in epoch 8, gen_loss = 0.9784845875369178, disc_loss = 0.00042977165395751836
Trained batch 108 in epoch 8, gen_loss = 0.9785481286705087, disc_loss = 0.0004294612184604801
Trained batch 109 in epoch 8, gen_loss = 0.9785154131325808, disc_loss = 0.00043037132669600063
Trained batch 110 in epoch 8, gen_loss = 0.9783989303820843, disc_loss = 0.0004323279362660623
Trained batch 111 in epoch 8, gen_loss = 0.97831133593406, disc_loss = 0.00043214436651136827
Trained batch 112 in epoch 8, gen_loss = 0.97814343882873, disc_loss = 0.00043073883092142147
Trained batch 113 in epoch 8, gen_loss = 0.978213658981156, disc_loss = 0.00042867819202161117
Trained batch 114 in epoch 8, gen_loss = 0.9780033194500467, disc_loss = 0.00042636714453059857
Trained batch 115 in epoch 8, gen_loss = 0.9776318073272705, disc_loss = 0.0004244093385029279
Trained batch 116 in epoch 8, gen_loss = 0.977493805763049, disc_loss = 0.0004231551457863126
Trained batch 117 in epoch 8, gen_loss = 0.977547717296471, disc_loss = 0.00042201296124958545
Trained batch 118 in epoch 8, gen_loss = 0.977524622648704, disc_loss = 0.00042033377455688326
Trained batch 119 in epoch 8, gen_loss = 0.977359780172507, disc_loss = 0.0004185582585099231
Trained batch 120 in epoch 8, gen_loss = 0.9772468105820585, disc_loss = 0.0004169447488230384
Trained batch 121 in epoch 8, gen_loss = 0.9775980525329465, disc_loss = 0.00041561488471982515
Trained batch 122 in epoch 8, gen_loss = 0.9776480454739517, disc_loss = 0.0004148393637752463
Trained batch 123 in epoch 8, gen_loss = 0.9775395551996846, disc_loss = 0.00041403403848826496
Trained batch 124 in epoch 8, gen_loss = 0.9775764331817627, disc_loss = 0.00041404376772698014
Trained batch 125 in epoch 8, gen_loss = 0.9776363268731132, disc_loss = 0.0004134988623610254
Trained batch 126 in epoch 8, gen_loss = 0.9776817100254569, disc_loss = 0.0004123303548599718
Trained batch 127 in epoch 8, gen_loss = 0.9778676126152277, disc_loss = 0.0004126724585375996
Trained batch 128 in epoch 8, gen_loss = 0.9779832871385323, disc_loss = 0.0004128844919659616
Trained batch 129 in epoch 8, gen_loss = 0.9778206816086402, disc_loss = 0.00041195405456864346
Trained batch 130 in epoch 8, gen_loss = 0.978165598316047, disc_loss = 0.00041358823119751567
Trained batch 131 in epoch 8, gen_loss = 0.9780185908982248, disc_loss = 0.0004136926324986923
Trained batch 132 in epoch 8, gen_loss = 0.9779455200173801, disc_loss = 0.0004120228614717638
Trained batch 133 in epoch 8, gen_loss = 0.9776005019892507, disc_loss = 0.00041157218176739483
Trained batch 134 in epoch 8, gen_loss = 0.9778245356347826, disc_loss = 0.0004117805424525782
Trained batch 135 in epoch 8, gen_loss = 0.9776608466225511, disc_loss = 0.0004128682823433979
Trained batch 136 in epoch 8, gen_loss = 0.9781360456543248, disc_loss = 0.0004151477100307217
Trained batch 137 in epoch 8, gen_loss = 0.9781462571759155, disc_loss = 0.00041674150860922384
Trained batch 138 in epoch 8, gen_loss = 0.97808066374964, disc_loss = 0.0004156863910695471
Trained batch 139 in epoch 8, gen_loss = 0.9780153866325106, disc_loss = 0.0004171292900407155
Trained batch 140 in epoch 8, gen_loss = 0.9781529036819512, disc_loss = 0.00041949462206664344
Trained batch 141 in epoch 8, gen_loss = 0.9781359224252297, disc_loss = 0.00041978919208804014
Trained batch 142 in epoch 8, gen_loss = 0.9780790330646755, disc_loss = 0.0004192366465434458
Trained batch 143 in epoch 8, gen_loss = 0.9780477599965202, disc_loss = 0.00042018274345739174
Trained batch 144 in epoch 8, gen_loss = 0.9785211875520904, disc_loss = 0.0004222117225912496
Trained batch 145 in epoch 8, gen_loss = 0.9784150923768135, disc_loss = 0.0004219483966502195
Trained batch 146 in epoch 8, gen_loss = 0.9785891917287087, disc_loss = 0.00042081463822246006
Trained batch 147 in epoch 8, gen_loss = 0.978569003778535, disc_loss = 0.0004199581713151388
Trained batch 148 in epoch 8, gen_loss = 0.9783621494402022, disc_loss = 0.0004204645215364911
Trained batch 149 in epoch 8, gen_loss = 0.978331847190857, disc_loss = 0.00042089597050411003
Trained batch 150 in epoch 8, gen_loss = 0.9784143034196058, disc_loss = 0.000420950587903649
Trained batch 151 in epoch 8, gen_loss = 0.9780775763486561, disc_loss = 0.00041974641010854514
Trained batch 152 in epoch 8, gen_loss = 0.9780063613567477, disc_loss = 0.00041914909244499785
Trained batch 153 in epoch 8, gen_loss = 0.9778573714293443, disc_loss = 0.0004196754508756113
Trained batch 154 in epoch 8, gen_loss = 0.9775951993080878, disc_loss = 0.00041904916222612826
Trained batch 155 in epoch 8, gen_loss = 0.9777781749382998, disc_loss = 0.00041812150457423204
Trained batch 156 in epoch 8, gen_loss = 0.9777501430481103, disc_loss = 0.00041666746293016633
Trained batch 157 in epoch 8, gen_loss = 0.9775779379319541, disc_loss = 0.0004149282013494934
Trained batch 158 in epoch 8, gen_loss = 0.9776053968465553, disc_loss = 0.00041341033839963304
Trained batch 159 in epoch 8, gen_loss = 0.9773788586258888, disc_loss = 0.00041195706062353566
Trained batch 160 in epoch 8, gen_loss = 0.977713097696719, disc_loss = 0.0004121544522338877
Trained batch 161 in epoch 8, gen_loss = 0.9777782099482454, disc_loss = 0.00041144528474017727
Trained batch 162 in epoch 8, gen_loss = 0.9776878122903087, disc_loss = 0.000410795927514105
Trained batch 163 in epoch 8, gen_loss = 0.9778265197102617, disc_loss = 0.0004103555495420573
Trained batch 164 in epoch 8, gen_loss = 0.9779313679897423, disc_loss = 0.00041070692038346984
Trained batch 165 in epoch 8, gen_loss = 0.9778361636472036, disc_loss = 0.0004126235751711472
Trained batch 166 in epoch 8, gen_loss = 0.9777716576696156, disc_loss = 0.00041404914141919823
Trained batch 167 in epoch 8, gen_loss = 0.9777857781875701, disc_loss = 0.0004143784229936067
Trained batch 168 in epoch 8, gen_loss = 0.9776211730121861, disc_loss = 0.00041334565493661207
Trained batch 169 in epoch 8, gen_loss = 0.9775808162548962, disc_loss = 0.0004122398903264719
Trained batch 170 in epoch 8, gen_loss = 0.977739727636527, disc_loss = 0.0004118167897699978
Trained batch 171 in epoch 8, gen_loss = 0.9776549290779025, disc_loss = 0.0004104657164134551
Trained batch 172 in epoch 8, gen_loss = 0.9774714584295461, disc_loss = 0.00041131765170849193
Trained batch 173 in epoch 8, gen_loss = 0.9774457349859434, disc_loss = 0.00041186149342817887
Trained batch 174 in epoch 8, gen_loss = 0.9774247598648071, disc_loss = 0.00041322597294181053
Trained batch 175 in epoch 8, gen_loss = 0.9776138602332636, disc_loss = 0.00041490717781429834
Trained batch 176 in epoch 8, gen_loss = 0.977747942094749, disc_loss = 0.00041626236395907754
Trained batch 177 in epoch 8, gen_loss = 0.9777366435259915, disc_loss = 0.0004157632919783139
Trained batch 178 in epoch 8, gen_loss = 0.9776464903820826, disc_loss = 0.00041456335122103924
Trained batch 179 in epoch 8, gen_loss = 0.9774450070328182, disc_loss = 0.0004138864921211886
Trained batch 180 in epoch 8, gen_loss = 0.9775179282077768, disc_loss = 0.0004138080089659178
Trained batch 181 in epoch 8, gen_loss = 0.9774221083620093, disc_loss = 0.00041294234896278273
Trained batch 182 in epoch 8, gen_loss = 0.9774405584960687, disc_loss = 0.00041211779306317
Trained batch 183 in epoch 8, gen_loss = 0.9774338956112447, disc_loss = 0.0004113632695288802
Trained batch 184 in epoch 8, gen_loss = 0.977494017175726, disc_loss = 0.0004103064473334549
Trained batch 185 in epoch 8, gen_loss = 0.9776476092876927, disc_loss = 0.0004099619183507848
Trained batch 186 in epoch 8, gen_loss = 0.9775972369520421, disc_loss = 0.0004103190020781339
Trained batch 187 in epoch 8, gen_loss = 0.9776838187207567, disc_loss = 0.0004110766649512485
Trained batch 188 in epoch 8, gen_loss = 0.9775983710137625, disc_loss = 0.00041241335543057336
Trained batch 189 in epoch 8, gen_loss = 0.9775293754903893, disc_loss = 0.0004125718908892993
Trained batch 190 in epoch 8, gen_loss = 0.9775441622858896, disc_loss = 0.0004120579978154914
Trained batch 191 in epoch 8, gen_loss = 0.9775325500716766, disc_loss = 0.0004110359641344985
Trained batch 192 in epoch 8, gen_loss = 0.977350537023396, disc_loss = 0.00041034935377634715
Trained batch 193 in epoch 8, gen_loss = 0.9774686177981269, disc_loss = 0.000409392818143068
Trained batch 194 in epoch 8, gen_loss = 0.9774194017434732, disc_loss = 0.00040855149354917023
Trained batch 195 in epoch 8, gen_loss = 0.9773705851058571, disc_loss = 0.0004077519760710634
Trained batch 196 in epoch 8, gen_loss = 0.9774819688143463, disc_loss = 0.00040830562175145173
Trained batch 197 in epoch 8, gen_loss = 0.9776483698926791, disc_loss = 0.00041111928272364435
Trained batch 198 in epoch 8, gen_loss = 0.9777475035370294, disc_loss = 0.0004155151494082541
Trained batch 199 in epoch 8, gen_loss = 0.9776814317703247, disc_loss = 0.00041976129992690405
Trained batch 200 in epoch 8, gen_loss = 0.9776055869178393, disc_loss = 0.00042265728737206766
Trained batch 201 in epoch 8, gen_loss = 0.9778007602337564, disc_loss = 0.00042432435912986074
Trained batch 202 in epoch 8, gen_loss = 0.9776938604603848, disc_loss = 0.0004242995569368898
Trained batch 203 in epoch 8, gen_loss = 0.9776115695051119, disc_loss = 0.0004234250746045362
Trained batch 204 in epoch 8, gen_loss = 0.9776388543408091, disc_loss = 0.0004223789128179594
Trained batch 205 in epoch 8, gen_loss = 0.9777207851988597, disc_loss = 0.00042156157808862085
Trained batch 206 in epoch 8, gen_loss = 0.9777743283677216, disc_loss = 0.00042116271029901355
Trained batch 207 in epoch 8, gen_loss = 0.9776627258039438, disc_loss = 0.0004210899910853746
Trained batch 208 in epoch 8, gen_loss = 0.9776275214966405, disc_loss = 0.00042115904515582406
Trained batch 209 in epoch 8, gen_loss = 0.977796897434053, disc_loss = 0.0004204116810190802
Trained batch 210 in epoch 8, gen_loss = 0.9776933588687843, disc_loss = 0.0004200485915108915
Trained batch 211 in epoch 8, gen_loss = 0.9777201830216173, disc_loss = 0.0004202059496475278
Trained batch 212 in epoch 8, gen_loss = 0.9776406819831598, disc_loss = 0.00041982392723641487
Trained batch 213 in epoch 8, gen_loss = 0.9776049891364909, disc_loss = 0.0004193271808413284
Trained batch 214 in epoch 8, gen_loss = 0.977266125346339, disc_loss = 0.0004203090298011206
Trained batch 215 in epoch 8, gen_loss = 0.9770921689492685, disc_loss = 0.0004219557007740217
Trained batch 216 in epoch 8, gen_loss = 0.9770817289704002, disc_loss = 0.0004234935815793715
Trained batch 217 in epoch 8, gen_loss = 0.9770495672838404, disc_loss = 0.0004244268769846904
Trained batch 218 in epoch 8, gen_loss = 0.9770464973362614, disc_loss = 0.0004246598017905928
Trained batch 219 in epoch 8, gen_loss = 0.9767968711527911, disc_loss = 0.00042580634035402907
Trained batch 220 in epoch 8, gen_loss = 0.976848080686854, disc_loss = 0.00042983068970276454
Trained batch 221 in epoch 8, gen_loss = 0.9771274763184625, disc_loss = 0.0004333634120108023
Trained batch 222 in epoch 8, gen_loss = 0.9773510528786835, disc_loss = 0.00043421255718528257
Trained batch 223 in epoch 8, gen_loss = 0.9773156523172345, disc_loss = 0.00043402461986780897
Trained batch 224 in epoch 8, gen_loss = 0.9773400515980191, disc_loss = 0.00043429792263648576
Trained batch 225 in epoch 8, gen_loss = 0.977406227746896, disc_loss = 0.0004342075215036511
Trained batch 226 in epoch 8, gen_loss = 0.9772474965334988, disc_loss = 0.0004338795719986232
Trained batch 227 in epoch 8, gen_loss = 0.9772519526774424, disc_loss = 0.00043315943414774284
Trained batch 228 in epoch 8, gen_loss = 0.9771541224296436, disc_loss = 0.0004321492883818037
Trained batch 229 in epoch 8, gen_loss = 0.9769983159459156, disc_loss = 0.00043097404388548887
Trained batch 230 in epoch 8, gen_loss = 0.9769088553659844, disc_loss = 0.0004304013245495125
Trained batch 231 in epoch 8, gen_loss = 0.9769980750721077, disc_loss = 0.0004301097314024007
Trained batch 232 in epoch 8, gen_loss = 0.976812333252297, disc_loss = 0.00043025345375657465
Trained batch 233 in epoch 8, gen_loss = 0.9766721320457947, disc_loss = 0.00043058084571757953
Trained batch 234 in epoch 8, gen_loss = 0.9766495973505872, disc_loss = 0.0004319937278001391
Trained batch 235 in epoch 8, gen_loss = 0.976775180990413, disc_loss = 0.00043222521726728685
Trained batch 236 in epoch 8, gen_loss = 0.9768933963172043, disc_loss = 0.0004316204207122153
Trained batch 237 in epoch 8, gen_loss = 0.9768295383253017, disc_loss = 0.00043161033039830406
Trained batch 238 in epoch 8, gen_loss = 0.9765655141495262, disc_loss = 0.000431286110070234
Trained batch 239 in epoch 8, gen_loss = 0.9765892590085665, disc_loss = 0.0004311948351338894
Trained batch 240 in epoch 8, gen_loss = 0.9764573554280388, disc_loss = 0.0004314816199654628
Trained batch 241 in epoch 8, gen_loss = 0.9763712390395235, disc_loss = 0.0004315406601435374
Trained batch 242 in epoch 8, gen_loss = 0.9763385869348, disc_loss = 0.00043142470962333456
Trained batch 243 in epoch 8, gen_loss = 0.9762741639965871, disc_loss = 0.0004312286681121551
Trained batch 244 in epoch 8, gen_loss = 0.9762902349841838, disc_loss = 0.00043063588091172276
Trained batch 245 in epoch 8, gen_loss = 0.9761550865037655, disc_loss = 0.0004305288950889939
Trained batch 246 in epoch 8, gen_loss = 0.9761088823499949, disc_loss = 0.00043104115406028656
Trained batch 247 in epoch 8, gen_loss = 0.9762581954559972, disc_loss = 0.00043078529368710495
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 1.0221153497695923, disc_loss = 0.0005275526782497764
Trained batch 1 in epoch 9, gen_loss = 0.975032776594162, disc_loss = 0.0004898771876469254
Trained batch 2 in epoch 9, gen_loss = 0.9795408447583517, disc_loss = 0.00047262142955635983
Trained batch 3 in epoch 9, gen_loss = 0.9808802157640457, disc_loss = 0.0004910835123155266
Trained batch 4 in epoch 9, gen_loss = 0.9863319993019104, disc_loss = 0.000506139814388007
Trained batch 5 in epoch 9, gen_loss = 0.9889075060685476, disc_loss = 0.0004891126445727423
Trained batch 6 in epoch 9, gen_loss = 0.9865665180342538, disc_loss = 0.0004656939875401024
Trained batch 7 in epoch 9, gen_loss = 0.9837521314620972, disc_loss = 0.00043819990605697967
Trained batch 8 in epoch 9, gen_loss = 0.9815599123636881, disc_loss = 0.00041993788585791155
Trained batch 9 in epoch 9, gen_loss = 0.9788400292396545, disc_loss = 0.0004028131806990132
Trained batch 10 in epoch 9, gen_loss = 0.9781446402723138, disc_loss = 0.0003902611073995517
Trained batch 11 in epoch 9, gen_loss = 0.9729364862044653, disc_loss = 0.0003786755817903516
Trained batch 12 in epoch 9, gen_loss = 0.9721819254068228, disc_loss = 0.0003781424960694634
Trained batch 13 in epoch 9, gen_loss = 0.9721789913518089, disc_loss = 0.00037187761751868365
Trained batch 14 in epoch 9, gen_loss = 0.9727391084035237, disc_loss = 0.0003644149343017489
Trained batch 15 in epoch 9, gen_loss = 0.972321167588234, disc_loss = 0.0003568553274817532
Trained batch 16 in epoch 9, gen_loss = 0.9722016839420095, disc_loss = 0.00034525505821768413
Trained batch 17 in epoch 9, gen_loss = 0.9717222617732154, disc_loss = 0.00033522208347373333
Trained batch 18 in epoch 9, gen_loss = 0.9754098245972082, disc_loss = 0.0003322600777640841
Trained batch 19 in epoch 9, gen_loss = 0.9746244192123413, disc_loss = 0.00032398759722127577
Trained batch 20 in epoch 9, gen_loss = 0.9742732956295922, disc_loss = 0.00032537683104497513
Trained batch 21 in epoch 9, gen_loss = 0.9756729927929965, disc_loss = 0.00034434207654240623
Trained batch 22 in epoch 9, gen_loss = 0.9748205464819203, disc_loss = 0.00036590021298489654
Trained batch 23 in epoch 9, gen_loss = 0.9742658957839012, disc_loss = 0.00036884304851506994
Trained batch 24 in epoch 9, gen_loss = 0.973462951183319, disc_loss = 0.00036434741865377874
Trained batch 25 in epoch 9, gen_loss = 0.9747662796423986, disc_loss = 0.0003610200986328821
Trained batch 26 in epoch 9, gen_loss = 0.9737182392014397, disc_loss = 0.000357103486075411
Trained batch 27 in epoch 9, gen_loss = 0.9734657428094319, disc_loss = 0.00035679668664150607
Trained batch 28 in epoch 9, gen_loss = 0.973683433286075, disc_loss = 0.0003585089404529346
Trained batch 29 in epoch 9, gen_loss = 0.9723600089550019, disc_loss = 0.0003608320611723078
Trained batch 30 in epoch 9, gen_loss = 0.9725577273676472, disc_loss = 0.0003606189139029612
Trained batch 31 in epoch 9, gen_loss = 0.9726266358047724, disc_loss = 0.00036371672604218475
Trained batch 32 in epoch 9, gen_loss = 0.9726720506494696, disc_loss = 0.00037129530744895226
Trained batch 33 in epoch 9, gen_loss = 0.9720068871974945, disc_loss = 0.0003696524205117706
Trained batch 34 in epoch 9, gen_loss = 0.9731825743402753, disc_loss = 0.0003676126806697409
Trained batch 35 in epoch 9, gen_loss = 0.9741961740785174, disc_loss = 0.00036947309167266614
Trained batch 36 in epoch 9, gen_loss = 0.9751106001235343, disc_loss = 0.0003755873590676315
Trained batch 37 in epoch 9, gen_loss = 0.9747691044681951, disc_loss = 0.0003791918168549034
Trained batch 38 in epoch 9, gen_loss = 0.974228880344293, disc_loss = 0.000377574520266185
Trained batch 39 in epoch 9, gen_loss = 0.9741108313202858, disc_loss = 0.0003720070355484495
Trained batch 40 in epoch 9, gen_loss = 0.9743273011068019, disc_loss = 0.00036625805482688566
Trained batch 41 in epoch 9, gen_loss = 0.9747398651781536, disc_loss = 0.00036328468316545087
Trained batch 42 in epoch 9, gen_loss = 0.9740490234175394, disc_loss = 0.00036093573286306375
Trained batch 43 in epoch 9, gen_loss = 0.9739584313197569, disc_loss = 0.000361561475570356
Trained batch 44 in epoch 9, gen_loss = 0.973153989844852, disc_loss = 0.00036064500907539494
Trained batch 45 in epoch 9, gen_loss = 0.9731302248395007, disc_loss = 0.0003576160034635509
Trained batch 46 in epoch 9, gen_loss = 0.9734344989695447, disc_loss = 0.0003609256351371593
Trained batch 47 in epoch 9, gen_loss = 0.9733480152984461, disc_loss = 0.00036104470412586426
Trained batch 48 in epoch 9, gen_loss = 0.9721784117270489, disc_loss = 0.00035819877295431736
Trained batch 49 in epoch 9, gen_loss = 0.9727427399158478, disc_loss = 0.0003577292710542679
Trained batch 50 in epoch 9, gen_loss = 0.9719853179127562, disc_loss = 0.00035744135875218346
Trained batch 51 in epoch 9, gen_loss = 0.9714021854675733, disc_loss = 0.0003553258144305661
Trained batch 52 in epoch 9, gen_loss = 0.9712916770071354, disc_loss = 0.00035253863832210454
Trained batch 53 in epoch 9, gen_loss = 0.9713632342992006, disc_loss = 0.000350291186973832
Trained batch 54 in epoch 9, gen_loss = 0.9711667559363625, disc_loss = 0.000350126276448877
Trained batch 55 in epoch 9, gen_loss = 0.9712889726672854, disc_loss = 0.00034950886973612275
Trained batch 56 in epoch 9, gen_loss = 0.971066951751709, disc_loss = 0.0003463064561385596
Trained batch 57 in epoch 9, gen_loss = 0.9707784015556862, disc_loss = 0.00034339670397959455
Trained batch 58 in epoch 9, gen_loss = 0.9709929642030748, disc_loss = 0.00034260861028056843
Trained batch 59 in epoch 9, gen_loss = 0.970290528734525, disc_loss = 0.0003416046303755138
Trained batch 60 in epoch 9, gen_loss = 0.9697042996766138, disc_loss = 0.0003396674585585925
Trained batch 61 in epoch 9, gen_loss = 0.969654752362159, disc_loss = 0.00034433042404294437
Trained batch 62 in epoch 9, gen_loss = 0.9694733534540448, disc_loss = 0.0003457626118601876
Trained batch 63 in epoch 9, gen_loss = 0.9692747248336673, disc_loss = 0.00034284843081877625
Trained batch 64 in epoch 9, gen_loss = 0.9696737674566416, disc_loss = 0.00034626705433206205
Trained batch 65 in epoch 9, gen_loss = 0.9694835453322439, disc_loss = 0.0003505424813766061
Trained batch 66 in epoch 9, gen_loss = 0.9696660993704155, disc_loss = 0.00035025550546854343
Trained batch 67 in epoch 9, gen_loss = 0.9695649436291527, disc_loss = 0.0003499951278225875
Trained batch 68 in epoch 9, gen_loss = 0.9698378357334413, disc_loss = 0.0003508857577495898
Trained batch 69 in epoch 9, gen_loss = 0.969283584186009, disc_loss = 0.0003507978143586245
Trained batch 70 in epoch 9, gen_loss = 0.9692346781072482, disc_loss = 0.0003487519185308
Trained batch 71 in epoch 9, gen_loss = 0.9697739879290262, disc_loss = 0.00034680023074745096
Trained batch 72 in epoch 9, gen_loss = 0.9697889669300759, disc_loss = 0.00034598513204948847
Trained batch 73 in epoch 9, gen_loss = 0.9695059423511093, disc_loss = 0.00034441893807820017
Trained batch 74 in epoch 9, gen_loss = 0.969977187315623, disc_loss = 0.0003435021590363855
Trained batch 75 in epoch 9, gen_loss = 0.9696549765373531, disc_loss = 0.00034537760438979603
Trained batch 76 in epoch 9, gen_loss = 0.9696522262189295, disc_loss = 0.0003475714185768013
Trained batch 77 in epoch 9, gen_loss = 0.9695769173976703, disc_loss = 0.0003465407687308004
Trained batch 78 in epoch 9, gen_loss = 0.9696783785578571, disc_loss = 0.0003438273301463032
Trained batch 79 in epoch 9, gen_loss = 0.9699044100940227, disc_loss = 0.0003415553108425229
Trained batch 80 in epoch 9, gen_loss = 0.9700217372105445, disc_loss = 0.00034009723422508457
Trained batch 81 in epoch 9, gen_loss = 0.9699932736594502, disc_loss = 0.0003391291712632221
Trained batch 82 in epoch 9, gen_loss = 0.9697009870804936, disc_loss = 0.0003373603303552078
Trained batch 83 in epoch 9, gen_loss = 0.9696928220135825, disc_loss = 0.0003359643149971297
Trained batch 84 in epoch 9, gen_loss = 0.9699851709253647, disc_loss = 0.0003342407166629153
Trained batch 85 in epoch 9, gen_loss = 0.9698733410169912, disc_loss = 0.00033327472750855567
Trained batch 86 in epoch 9, gen_loss = 0.9704123845045594, disc_loss = 0.00033416310271740647
Trained batch 87 in epoch 9, gen_loss = 0.9705656238577582, disc_loss = 0.00033350307322424754
Trained batch 88 in epoch 9, gen_loss = 0.9708850008718083, disc_loss = 0.00033222031606272324
Trained batch 89 in epoch 9, gen_loss = 0.9707682636049059, disc_loss = 0.00033142488634136194
Trained batch 90 in epoch 9, gen_loss = 0.9707207260551033, disc_loss = 0.00033163143450440325
Trained batch 91 in epoch 9, gen_loss = 0.9706810194513072, disc_loss = 0.00033224315800749616
Trained batch 92 in epoch 9, gen_loss = 0.9706050003728559, disc_loss = 0.0003337734818561203
Trained batch 93 in epoch 9, gen_loss = 0.9706277314652788, disc_loss = 0.00033416616853618837
Trained batch 94 in epoch 9, gen_loss = 0.9709257119580319, disc_loss = 0.0003332417015611243
Trained batch 95 in epoch 9, gen_loss = 0.9707944275190433, disc_loss = 0.00033229395194211975
Trained batch 96 in epoch 9, gen_loss = 0.97067955044127, disc_loss = 0.0003328334198683769
Trained batch 97 in epoch 9, gen_loss = 0.9705467516062211, disc_loss = 0.00033228017202084316
Trained batch 98 in epoch 9, gen_loss = 0.971237823216602, disc_loss = 0.0003326416005041789
Trained batch 99 in epoch 9, gen_loss = 0.9709963756799698, disc_loss = 0.00033406630565878
Trained batch 100 in epoch 9, gen_loss = 0.9709930744501624, disc_loss = 0.00033887246529119884
Trained batch 101 in epoch 9, gen_loss = 0.9708081647461536, disc_loss = 0.0003446412487320748
Trained batch 102 in epoch 9, gen_loss = 0.9709514171174429, disc_loss = 0.0003477706154582353
Trained batch 103 in epoch 9, gen_loss = 0.9708249695025958, disc_loss = 0.00034711315199204435
Trained batch 104 in epoch 9, gen_loss = 0.970615808169047, disc_loss = 0.0003456344609037929
Trained batch 105 in epoch 9, gen_loss = 0.9705290322033864, disc_loss = 0.00034495812312497774
Trained batch 106 in epoch 9, gen_loss = 0.9705712416461695, disc_loss = 0.0003450403447484894
Trained batch 107 in epoch 9, gen_loss = 0.9703174509384014, disc_loss = 0.00034494241710355573
Trained batch 108 in epoch 9, gen_loss = 0.9705904044142557, disc_loss = 0.0003460343241469439
Trained batch 109 in epoch 9, gen_loss = 0.9704422067512165, disc_loss = 0.00034713523054961113
Trained batch 110 in epoch 9, gen_loss = 0.9705797127775244, disc_loss = 0.00034727710550902665
Trained batch 111 in epoch 9, gen_loss = 0.9708275214901992, disc_loss = 0.00034679635116065456
Trained batch 112 in epoch 9, gen_loss = 0.9708858828629012, disc_loss = 0.0003451548969533822
Trained batch 113 in epoch 9, gen_loss = 0.9708920356474424, disc_loss = 0.00034380400131595436
Trained batch 114 in epoch 9, gen_loss = 0.9709441620370616, disc_loss = 0.0003424615095592225
Trained batch 115 in epoch 9, gen_loss = 0.9707545997767613, disc_loss = 0.00034056393821535084
Trained batch 116 in epoch 9, gen_loss = 0.9704311011183975, disc_loss = 0.00033905759775159386
Trained batch 117 in epoch 9, gen_loss = 0.9705964160167565, disc_loss = 0.00033812115898245343
Trained batch 118 in epoch 9, gen_loss = 0.9706920144938621, disc_loss = 0.0003368722524605457
Trained batch 119 in epoch 9, gen_loss = 0.9706938619414965, disc_loss = 0.00033644804098003077
Trained batch 120 in epoch 9, gen_loss = 0.9710373351396608, disc_loss = 0.0003357550555268641
Trained batch 121 in epoch 9, gen_loss = 0.971056486739487, disc_loss = 0.0003343316975438998
Trained batch 122 in epoch 9, gen_loss = 0.9710144797960917, disc_loss = 0.00033308708947057253
Trained batch 123 in epoch 9, gen_loss = 0.9706605725711391, disc_loss = 0.0003327316363509219
Trained batch 124 in epoch 9, gen_loss = 0.9709283690452576, disc_loss = 0.00033647954661864785
Trained batch 125 in epoch 9, gen_loss = 0.9709229450377207, disc_loss = 0.0003396750272793089
Trained batch 126 in epoch 9, gen_loss = 0.9710697564553088, disc_loss = 0.00033922240976335874
Trained batch 127 in epoch 9, gen_loss = 0.9708402622491121, disc_loss = 0.00033799684217683534
Trained batch 128 in epoch 9, gen_loss = 0.970945607322131, disc_loss = 0.0003368011898001974
Trained batch 129 in epoch 9, gen_loss = 0.9712428510189056, disc_loss = 0.00033625769887853844
Trained batch 130 in epoch 9, gen_loss = 0.9715805358559121, disc_loss = 0.00033592486112886855
Trained batch 131 in epoch 9, gen_loss = 0.9714927736556891, disc_loss = 0.00033544377341362025
Trained batch 132 in epoch 9, gen_loss = 0.9710966438279116, disc_loss = 0.00033499837007909257
Trained batch 133 in epoch 9, gen_loss = 0.9712361293052559, disc_loss = 0.00033454734251274964
Trained batch 134 in epoch 9, gen_loss = 0.9716338378411752, disc_loss = 0.00033421541048920953
Trained batch 135 in epoch 9, gen_loss = 0.9716647394439754, disc_loss = 0.00033364985949233146
Trained batch 136 in epoch 9, gen_loss = 0.9715194236623109, disc_loss = 0.00033327452866037643
Trained batch 137 in epoch 9, gen_loss = 0.9714521675006204, disc_loss = 0.00033293697133953884
Trained batch 138 in epoch 9, gen_loss = 0.9710044869416051, disc_loss = 0.00033452943469508274
Trained batch 139 in epoch 9, gen_loss = 0.9710012691361564, disc_loss = 0.00034012809451918917
Trained batch 140 in epoch 9, gen_loss = 0.9708813762833887, disc_loss = 0.00034520779032481453
Trained batch 141 in epoch 9, gen_loss = 0.971159214285058, disc_loss = 0.0003456543481533258
Trained batch 142 in epoch 9, gen_loss = 0.9711011698195985, disc_loss = 0.0003446917022314652
Trained batch 143 in epoch 9, gen_loss = 0.9710396263334486, disc_loss = 0.000345153234067968
Trained batch 144 in epoch 9, gen_loss = 0.9706978325186104, disc_loss = 0.0003462048556559302
Trained batch 145 in epoch 9, gen_loss = 0.9710442558543323, disc_loss = 0.00034680807156080046
Trained batch 146 in epoch 9, gen_loss = 0.9709684763635907, disc_loss = 0.0003461263771723246
Trained batch 147 in epoch 9, gen_loss = 0.9711100451044135, disc_loss = 0.00034653981050281356
Trained batch 148 in epoch 9, gen_loss = 0.9710919821022341, disc_loss = 0.00034818463531422785
Trained batch 149 in epoch 9, gen_loss = 0.9713029126326244, disc_loss = 0.00035076346267790844
Trained batch 150 in epoch 9, gen_loss = 0.9711659246722594, disc_loss = 0.0003535253192769943
Trained batch 151 in epoch 9, gen_loss = 0.9712578583704797, disc_loss = 0.0003554576207151465
Trained batch 152 in epoch 9, gen_loss = 0.9714532451691971, disc_loss = 0.0003565042334824825
Trained batch 153 in epoch 9, gen_loss = 0.9715912585908716, disc_loss = 0.00035633350432965325
Trained batch 154 in epoch 9, gen_loss = 0.9714654922485352, disc_loss = 0.000355822941468608
Trained batch 155 in epoch 9, gen_loss = 0.9714330939146189, disc_loss = 0.00035480449300032493
Trained batch 156 in epoch 9, gen_loss = 0.9714328422667874, disc_loss = 0.00035352854333984055
Trained batch 157 in epoch 9, gen_loss = 0.971419942152651, disc_loss = 0.00035270748886904573
Trained batch 158 in epoch 9, gen_loss = 0.9715174785200155, disc_loss = 0.00035208460264224206
Trained batch 159 in epoch 9, gen_loss = 0.9714337531477213, disc_loss = 0.0003515805959978024
Trained batch 160 in epoch 9, gen_loss = 0.9717360590555653, disc_loss = 0.000350725112800336
Trained batch 161 in epoch 9, gen_loss = 0.971919419956796, disc_loss = 0.00034962783495386785
Trained batch 162 in epoch 9, gen_loss = 0.9722563397664965, disc_loss = 0.0003506204596702067
Trained batch 163 in epoch 9, gen_loss = 0.9722103036758376, disc_loss = 0.0003537089135689468
Trained batch 164 in epoch 9, gen_loss = 0.9722814115610989, disc_loss = 0.00035573837345564795
Trained batch 165 in epoch 9, gen_loss = 0.9723217796130352, disc_loss = 0.000356748910794029
Trained batch 166 in epoch 9, gen_loss = 0.9721053092779514, disc_loss = 0.00035682886333168555
Trained batch 167 in epoch 9, gen_loss = 0.9720004296728543, disc_loss = 0.00035620084418042097
Trained batch 168 in epoch 9, gen_loss = 0.9720679073644107, disc_loss = 0.00035531710338718175
Trained batch 169 in epoch 9, gen_loss = 0.9723283778218662, disc_loss = 0.0003553700703538626
Trained batch 170 in epoch 9, gen_loss = 0.9722037754560772, disc_loss = 0.0003558528670504667
Trained batch 171 in epoch 9, gen_loss = 0.9723064726175263, disc_loss = 0.0003550718112058158
Trained batch 172 in epoch 9, gen_loss = 0.9723481367089156, disc_loss = 0.00035502175084514427
Trained batch 173 in epoch 9, gen_loss = 0.9724893220539751, disc_loss = 0.00035481866892031125
Trained batch 174 in epoch 9, gen_loss = 0.9725118643896921, disc_loss = 0.00035474328523767845
Trained batch 175 in epoch 9, gen_loss = 0.9726391952823509, disc_loss = 0.00035496673759057143
Trained batch 176 in epoch 9, gen_loss = 0.9729074923332128, disc_loss = 0.0003548158639528931
Trained batch 177 in epoch 9, gen_loss = 0.9731772270765198, disc_loss = 0.0003544739629024263
Trained batch 178 in epoch 9, gen_loss = 0.9730802704502084, disc_loss = 0.0003543661826995186
Trained batch 179 in epoch 9, gen_loss = 0.9731947193543117, disc_loss = 0.00035426264302158313
Trained batch 180 in epoch 9, gen_loss = 0.9734054477833911, disc_loss = 0.0003534732298032787
Trained batch 181 in epoch 9, gen_loss = 0.9733655665602002, disc_loss = 0.0003526041955510564
Trained batch 182 in epoch 9, gen_loss = 0.9731391111358267, disc_loss = 0.00035281645425447756
Trained batch 183 in epoch 9, gen_loss = 0.973100294885428, disc_loss = 0.0003533173237329997
Trained batch 184 in epoch 9, gen_loss = 0.9730125291927441, disc_loss = 0.0003535727414969556
Trained batch 185 in epoch 9, gen_loss = 0.9730177790887894, disc_loss = 0.0003533886464860951
Trained batch 186 in epoch 9, gen_loss = 0.973135011400131, disc_loss = 0.00035247619759993636
Trained batch 187 in epoch 9, gen_loss = 0.9730660335180608, disc_loss = 0.00035170157462608646
Trained batch 188 in epoch 9, gen_loss = 0.9731552995071209, disc_loss = 0.0003512722931133347
Trained batch 189 in epoch 9, gen_loss = 0.9731545558101252, disc_loss = 0.00035084744978169176
Trained batch 190 in epoch 9, gen_loss = 0.9732755350816936, disc_loss = 0.00035084097477648874
Trained batch 191 in epoch 9, gen_loss = 0.9734582028662165, disc_loss = 0.0003506728743711089
Trained batch 192 in epoch 9, gen_loss = 0.9734652672406923, disc_loss = 0.00035017955838039113
Trained batch 193 in epoch 9, gen_loss = 0.9733339735527629, disc_loss = 0.000349999573090733
Trained batch 194 in epoch 9, gen_loss = 0.973298915838584, disc_loss = 0.00034993269938963633
Trained batch 195 in epoch 9, gen_loss = 0.9731097336934538, disc_loss = 0.00034977865801252215
Trained batch 196 in epoch 9, gen_loss = 0.9732065736339782, disc_loss = 0.0003499304307689701
Trained batch 197 in epoch 9, gen_loss = 0.9731791961674738, disc_loss = 0.00035032657578627514
Trained batch 198 in epoch 9, gen_loss = 0.9728766089707763, disc_loss = 0.00035094402079065637
Trained batch 199 in epoch 9, gen_loss = 0.9726732787489891, disc_loss = 0.00035229539971624033
Trained batch 200 in epoch 9, gen_loss = 0.9725991585361424, disc_loss = 0.00035302360162465596
Trained batch 201 in epoch 9, gen_loss = 0.9723202299953687, disc_loss = 0.0003527147868460293
Trained batch 202 in epoch 9, gen_loss = 0.9725631678045676, disc_loss = 0.00035716271754228075
Trained batch 203 in epoch 9, gen_loss = 0.9725420886979383, disc_loss = 0.0003638844546895045
Trained batch 204 in epoch 9, gen_loss = 0.9726416520956086, disc_loss = 0.00036669588916105923
Trained batch 205 in epoch 9, gen_loss = 0.9724010573428812, disc_loss = 0.0003660746049859281
Trained batch 206 in epoch 9, gen_loss = 0.9724013445457974, disc_loss = 0.0003658987151218155
Trained batch 207 in epoch 9, gen_loss = 0.9723728382243559, disc_loss = 0.00036685095689720655
Trained batch 208 in epoch 9, gen_loss = 0.9723817560661352, disc_loss = 0.0003681809608835691
Trained batch 209 in epoch 9, gen_loss = 0.9724049721445356, disc_loss = 0.0003686452050238759
Trained batch 210 in epoch 9, gen_loss = 0.9724673552535722, disc_loss = 0.0003680138180023545
Trained batch 211 in epoch 9, gen_loss = 0.9725330455123253, disc_loss = 0.00036733750367036336
Trained batch 212 in epoch 9, gen_loss = 0.9727115256125938, disc_loss = 0.00036748899778180663
Trained batch 213 in epoch 9, gen_loss = 0.9725100381352078, disc_loss = 0.0003689320356243455
Trained batch 214 in epoch 9, gen_loss = 0.9725153823231542, disc_loss = 0.0003705116556036871
Trained batch 215 in epoch 9, gen_loss = 0.9726270572454842, disc_loss = 0.00037184086990978187
Trained batch 216 in epoch 9, gen_loss = 0.9724238459965051, disc_loss = 0.00037199468123898217
Trained batch 217 in epoch 9, gen_loss = 0.9722268152127572, disc_loss = 0.0003718849583400772
Trained batch 218 in epoch 9, gen_loss = 0.9723657018517795, disc_loss = 0.00037159052340964444
Trained batch 219 in epoch 9, gen_loss = 0.9723653080788526, disc_loss = 0.000371081915165467
Trained batch 220 in epoch 9, gen_loss = 0.9721546191975002, disc_loss = 0.0003707960418665706
Trained batch 221 in epoch 9, gen_loss = 0.9722225738538278, disc_loss = 0.0003706703004731402
Trained batch 222 in epoch 9, gen_loss = 0.9719011665994276, disc_loss = 0.0003712095674952166
Trained batch 223 in epoch 9, gen_loss = 0.9722354571734156, disc_loss = 0.0003710411944796631
Trained batch 224 in epoch 9, gen_loss = 0.972238146993849, disc_loss = 0.00037087395437993107
Trained batch 225 in epoch 9, gen_loss = 0.972337562689739, disc_loss = 0.00037225756644316643
Trained batch 226 in epoch 9, gen_loss = 0.9722733426724236, disc_loss = 0.0003735776781668632
Trained batch 227 in epoch 9, gen_loss = 0.972195749742943, disc_loss = 0.0003741456415522599
Trained batch 228 in epoch 9, gen_loss = 0.9724100245138443, disc_loss = 0.000373881470613328
Trained batch 229 in epoch 9, gen_loss = 0.9723664060882901, disc_loss = 0.00037406932147543713
Trained batch 230 in epoch 9, gen_loss = 0.9723757696358156, disc_loss = 0.0003740457418269893
Trained batch 231 in epoch 9, gen_loss = 0.972283149587697, disc_loss = 0.0003734402212260114
Trained batch 232 in epoch 9, gen_loss = 0.9722539762058995, disc_loss = 0.0003730495645946427
Trained batch 233 in epoch 9, gen_loss = 0.972146557437049, disc_loss = 0.00037265904374623625
Trained batch 234 in epoch 9, gen_loss = 0.9719958909014438, disc_loss = 0.00037389548552381073
Trained batch 235 in epoch 9, gen_loss = 0.9717998706688316, disc_loss = 0.00037626050285880565
Trained batch 236 in epoch 9, gen_loss = 0.9719486508188369, disc_loss = 0.0003764082031483656
Trained batch 237 in epoch 9, gen_loss = 0.9719038923748401, disc_loss = 0.0003764566419031784
Trained batch 238 in epoch 9, gen_loss = 0.9718459482971096, disc_loss = 0.0003763430143724036
Trained batch 239 in epoch 9, gen_loss = 0.9718397691845894, disc_loss = 0.000376546430804107
Trained batch 240 in epoch 9, gen_loss = 0.9716465992551622, disc_loss = 0.00037675400405129053
Trained batch 241 in epoch 9, gen_loss = 0.9717028052353662, disc_loss = 0.0003767933063680491
Trained batch 242 in epoch 9, gen_loss = 0.971634787296562, disc_loss = 0.00037747647562025907
Trained batch 243 in epoch 9, gen_loss = 0.9717545548423392, disc_loss = 0.00037893205659261705
Trained batch 244 in epoch 9, gen_loss = 0.9717955900698292, disc_loss = 0.0003786160343336131
Trained batch 245 in epoch 9, gen_loss = 0.9717162677912208, disc_loss = 0.00037761818562214057
Trained batch 246 in epoch 9, gen_loss = 0.9716200495538442, disc_loss = 0.0003780016410711263
Trained batch 247 in epoch 9, gen_loss = 0.9716196247646885, disc_loss = 0.0003792209730994317
Testing Epoch 9
wandb: WARNING Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 0.43864232301712036, disc_loss = 0.4414694905281067
Trained batch 1 in epoch 0, gen_loss = 0.5086597800254822, disc_loss = 0.5625723600387573
Trained batch 2 in epoch 0, gen_loss = 0.49262577295303345, disc_loss = 0.5759105285008749
Trained batch 3 in epoch 0, gen_loss = 0.4818585067987442, disc_loss = 0.529355376958847
Trained batch 4 in epoch 0, gen_loss = 0.46144323945045473, disc_loss = 0.465028715133667
Trained batch 5 in epoch 0, gen_loss = 0.46665801604588825, disc_loss = 0.4186503142118454
Trained batch 6 in epoch 0, gen_loss = 0.458325241293226, disc_loss = 0.3860968287502016
Trained batch 7 in epoch 0, gen_loss = 0.4647868871688843, disc_loss = 0.36911999620497227
Trained batch 8 in epoch 0, gen_loss = 0.4627974099583096, disc_loss = 0.3442840923865636
Trained batch 9 in epoch 0, gen_loss = 0.46398143768310546, disc_loss = 0.3205420359969139
Trained batch 10 in epoch 0, gen_loss = 0.46022566340186377, disc_loss = 0.299535869197412
Trained batch 11 in epoch 0, gen_loss = 0.4584064409136772, disc_loss = 0.28161929671963054
Trained batch 12 in epoch 0, gen_loss = 0.4585117216293628, disc_loss = 0.26619436878424424
Trained batch 13 in epoch 0, gen_loss = 0.4600416421890259, disc_loss = 0.25389971850173815
Trained batch 14 in epoch 0, gen_loss = 0.46272546450297036, disc_loss = 0.24284851799408594
Trained batch 15 in epoch 0, gen_loss = 0.45917103812098503, disc_loss = 0.23344812961295247
Trained batch 16 in epoch 0, gen_loss = 0.4559010705527137, disc_loss = 0.2289436376270126
Trained batch 17 in epoch 0, gen_loss = 0.45732057922416264, disc_loss = 0.22659895279341274
Trained batch 18 in epoch 0, gen_loss = 0.4544246149690528, disc_loss = 0.2215154731744214
Trained batch 19 in epoch 0, gen_loss = 0.4537441790103912, disc_loss = 0.22142576090991498
Trained batch 20 in epoch 0, gen_loss = 0.45708013432366507, disc_loss = 0.2181078539717765
Trained batch 21 in epoch 0, gen_loss = 0.4593938941305334, disc_loss = 0.21367124501954426
Trained batch 22 in epoch 0, gen_loss = 0.4575283877227617, disc_loss = 0.20852291260076605
Trained batch 23 in epoch 0, gen_loss = 0.45841633528470993, disc_loss = 0.2043854066481193
Trained batch 24 in epoch 0, gen_loss = 0.45830583572387695, disc_loss = 0.2010103976726532
Trained batch 25 in epoch 0, gen_loss = 0.46267106670599717, disc_loss = 0.1977490375821407
Trained batch 26 in epoch 0, gen_loss = 0.4631506535742018, disc_loss = 0.19283204387735436
Trained batch 27 in epoch 0, gen_loss = 0.4647497258016041, disc_loss = 0.18794120901397296
Trained batch 28 in epoch 0, gen_loss = 0.46443252727903167, disc_loss = 0.1830836831238763
Trained batch 29 in epoch 0, gen_loss = 0.46477187275886533, disc_loss = 0.17849250175058842
Trained batch 30 in epoch 0, gen_loss = 0.4649728392401049, disc_loss = 0.17421967692432866
Trained batch 31 in epoch 0, gen_loss = 0.4676654161885381, disc_loss = 0.17003864177968353
Trained batch 32 in epoch 0, gen_loss = 0.46751840006221423, disc_loss = 0.16623153176271555
Trained batch 33 in epoch 0, gen_loss = 0.468760667478337, disc_loss = 0.1624884493649006
Trained batch 34 in epoch 0, gen_loss = 0.46722804137638635, disc_loss = 0.1589096830359527
Trained batch 35 in epoch 0, gen_loss = 0.46748582853211296, disc_loss = 0.1555069221390618
Trained batch 36 in epoch 0, gen_loss = 0.46520202224319046, disc_loss = 0.1523370212195693
Trained batch 37 in epoch 0, gen_loss = 0.46574924180382177, disc_loss = 0.14929034021732054
Trained batch 38 in epoch 0, gen_loss = 0.4651355544726054, disc_loss = 0.14638271287847787
Trained batch 39 in epoch 0, gen_loss = 0.46539361625909803, disc_loss = 0.14399286657571791
Trained batch 40 in epoch 0, gen_loss = 0.46570465550190066, disc_loss = 0.14160723348216311
Trained batch 41 in epoch 0, gen_loss = 0.46560613101436976, disc_loss = 0.13983181420536267
Trained batch 42 in epoch 0, gen_loss = 0.468643668779107, disc_loss = 0.13785868094757545
Trained batch 43 in epoch 0, gen_loss = 0.46935612843795255, disc_loss = 0.13578625370494343
Trained batch 44 in epoch 0, gen_loss = 0.47032059099939133, disc_loss = 0.13353038935197725
Trained batch 45 in epoch 0, gen_loss = 0.4701390000789062, disc_loss = 0.13134544610005358
Trained batch 46 in epoch 0, gen_loss = 0.46971763131466315, disc_loss = 0.12937076366011133
Trained batch 47 in epoch 0, gen_loss = 0.4711756054311991, disc_loss = 0.12754988057228425
Trained batch 48 in epoch 0, gen_loss = 0.47161722426511804, disc_loss = 0.1255443864026848
Trained batch 49 in epoch 0, gen_loss = 0.47055544376373293, disc_loss = 0.12389258861541748
Trained batch 50 in epoch 0, gen_loss = 0.4704655829597922, disc_loss = 0.12261213106559772
Trained batch 51 in epoch 0, gen_loss = 0.4706928271513719, disc_loss = 0.12217161195495954
Trained batch 52 in epoch 0, gen_loss = 0.47009524196948643, disc_loss = 0.12260032058605608
Trained batch 53 in epoch 0, gen_loss = 0.4702212413152059, disc_loss = 0.12192639108333322
Trained batch 54 in epoch 0, gen_loss = 0.4710675282911821, disc_loss = 0.12043067792599851
Trained batch 55 in epoch 0, gen_loss = 0.47004601306148935, disc_loss = 0.11960397640775357
Trained batch 56 in epoch 0, gen_loss = 0.4673946630536464, disc_loss = 0.11878293040290214
Trained batch 57 in epoch 0, gen_loss = 0.4680605186470624, disc_loss = 0.11754668741647539
Trained batch 58 in epoch 0, gen_loss = 0.4673800251241458, disc_loss = 0.11654989048838615
Trained batch 59 in epoch 0, gen_loss = 0.4672721152504285, disc_loss = 0.1158248166864117
Trained batch 60 in epoch 0, gen_loss = 0.4669374808913372, disc_loss = 0.11455905724500047
Trained batch 61 in epoch 0, gen_loss = 0.467028118910328, disc_loss = 0.11318816755327486
Trained batch 62 in epoch 0, gen_loss = 0.4671562323494563, disc_loss = 0.11180908227014164
Trained batch 63 in epoch 0, gen_loss = 0.46857069712132215, disc_loss = 0.11043279484147206
Trained batch 64 in epoch 0, gen_loss = 0.46862988747083223, disc_loss = 0.10912566629166787
Trained batch 65 in epoch 0, gen_loss = 0.4688907635934425, disc_loss = 0.10794129914067911
Trained batch 66 in epoch 0, gen_loss = 0.4685899561910487, disc_loss = 0.10710722349806508
Trained batch 67 in epoch 0, gen_loss = 0.4688136485569617, disc_loss = 0.10687110460746814
Trained batch 68 in epoch 0, gen_loss = 0.46920784444048785, disc_loss = 0.10581939049281072
Trained batch 69 in epoch 0, gen_loss = 0.46892241707869936, disc_loss = 0.10477877059685332
Trained batch 70 in epoch 0, gen_loss = 0.46884692722642923, disc_loss = 0.10367919564981695
Trained batch 71 in epoch 0, gen_loss = 0.4685499837829007, disc_loss = 0.10266492166556418
Trained batch 72 in epoch 0, gen_loss = 0.4674844407055476, disc_loss = 0.10174523357761232
Trained batch 73 in epoch 0, gen_loss = 0.4675048090316154, disc_loss = 0.10094827989972122
Trained batch 74 in epoch 0, gen_loss = 0.46760606129964194, disc_loss = 0.10024419647951921
Trained batch 75 in epoch 0, gen_loss = 0.4677461377884212, disc_loss = 0.10020107994052141
Trained batch 76 in epoch 0, gen_loss = 0.4677767765212369, disc_loss = 0.10012967809550948
Trained batch 77 in epoch 0, gen_loss = 0.4682138680647581, disc_loss = 0.09927493594109248
Trained batch 78 in epoch 0, gen_loss = 0.46985329291488553, disc_loss = 0.0988622784284474
Trained batch 79 in epoch 0, gen_loss = 0.46971074379980565, disc_loss = 0.09807756675872951
Trained batch 80 in epoch 0, gen_loss = 0.4696189220304842, disc_loss = 0.0978715167047433
Trained batch 81 in epoch 0, gen_loss = 0.47093852373158057, disc_loss = 0.09806418611963348
Trained batch 82 in epoch 0, gen_loss = 0.47118757431765634, disc_loss = 0.09849702263901751
Trained batch 83 in epoch 0, gen_loss = 0.4709431174255553, disc_loss = 0.1048707673991365
Trained batch 84 in epoch 0, gen_loss = 0.47049736801315756, disc_loss = 0.10503391441615188
Trained batch 85 in epoch 0, gen_loss = 0.47176417188588965, disc_loss = 0.10587229295958613
Trained batch 86 in epoch 0, gen_loss = 0.4720620098470271, disc_loss = 0.10634584649969106
Trained batch 87 in epoch 0, gen_loss = 0.4718505252491344, disc_loss = 0.10669364282776686
Trained batch 88 in epoch 0, gen_loss = 0.47171558958760806, disc_loss = 0.1067816765999861
Trained batch 89 in epoch 0, gen_loss = 0.47080381711324054, disc_loss = 0.10708370972424745
Trained batch 90 in epoch 0, gen_loss = 0.4703829819029504, disc_loss = 0.10828552372589871
Trained batch 91 in epoch 0, gen_loss = 0.47035639117593353, disc_loss = 0.11075886891668905
Trained batch 92 in epoch 0, gen_loss = 0.46947029809797963, disc_loss = 0.11595019924464406
Trained batch 93 in epoch 0, gen_loss = 0.4689384572049405, disc_loss = 0.11743433077997983
Trained batch 94 in epoch 0, gen_loss = 0.469131453727421, disc_loss = 0.11842663399875164
Trained batch 95 in epoch 0, gen_loss = 0.4702082285657525, disc_loss = 0.11864482225306953
Trained batch 96 in epoch 0, gen_loss = 0.4693948408377539, disc_loss = 0.11909801891246408
Trained batch 97 in epoch 0, gen_loss = 0.46897544392517637, disc_loss = 0.11922372712240535
Trained batch 98 in epoch 0, gen_loss = 0.46915215645173586, disc_loss = 0.11938149626884195
Trained batch 99 in epoch 0, gen_loss = 0.4687002438306809, disc_loss = 0.12245532261207699
Trained batch 100 in epoch 0, gen_loss = 0.46734838763085923, disc_loss = 0.12535234387632055
Trained batch 101 in epoch 0, gen_loss = 0.46638667846427245, disc_loss = 0.12759861512584428
Trained batch 102 in epoch 0, gen_loss = 0.4659303640856326, disc_loss = 0.12837545908264164
Trained batch 103 in epoch 0, gen_loss = 0.4662601976440503, disc_loss = 0.12910591526171908
Trained batch 104 in epoch 0, gen_loss = 0.46612690971011206, disc_loss = 0.12958522823949656
Trained batch 105 in epoch 0, gen_loss = 0.4653177022371652, disc_loss = 0.13022056884431052
Trained batch 106 in epoch 0, gen_loss = 0.4654433604712798, disc_loss = 0.13062986329406778
Trained batch 107 in epoch 0, gen_loss = 0.46520348721080357, disc_loss = 0.1307974664873823
Trained batch 108 in epoch 0, gen_loss = 0.46558270924681916, disc_loss = 0.13064928115302815
Trained batch 109 in epoch 0, gen_loss = 0.46547915664586154, disc_loss = 0.13057240960611538
Trained batch 110 in epoch 0, gen_loss = 0.464986711203515, disc_loss = 0.13109017124919742
Trained batch 111 in epoch 0, gen_loss = 0.46474131170128075, disc_loss = 0.13235824962612242
Trained batch 112 in epoch 0, gen_loss = 0.46469654024174784, disc_loss = 0.1328318109323757
Trained batch 113 in epoch 0, gen_loss = 0.46439457776253684, disc_loss = 0.1334169497386667
Trained batch 114 in epoch 0, gen_loss = 0.46400957366694573, disc_loss = 0.13402875060944452
Trained batch 115 in epoch 0, gen_loss = 0.46422031675947123, disc_loss = 0.13418542743050332
Trained batch 116 in epoch 0, gen_loss = 0.46430092234896797, disc_loss = 0.13405116865586522
Trained batch 117 in epoch 0, gen_loss = 0.4635691183098292, disc_loss = 0.134438765329956
Trained batch 118 in epoch 0, gen_loss = 0.46331341802573006, disc_loss = 0.13552927728272787
Trained batch 119 in epoch 0, gen_loss = 0.46335100506742793, disc_loss = 0.1393402100385477
Trained batch 120 in epoch 0, gen_loss = 0.462535468261104, disc_loss = 0.14004494343722654
Trained batch 121 in epoch 0, gen_loss = 0.46217222658337137, disc_loss = 0.14012422896616283
Trained batch 122 in epoch 0, gen_loss = 0.46176637188205877, disc_loss = 0.13988191920627907
Trained batch 123 in epoch 0, gen_loss = 0.46117108339263546, disc_loss = 0.13969552548482053
Trained batch 124 in epoch 0, gen_loss = 0.46025198078155516, disc_loss = 0.1402131737023592
Trained batch 125 in epoch 0, gen_loss = 0.4598145480193789, disc_loss = 0.14082544209760806
Trained batch 126 in epoch 0, gen_loss = 0.45932961143846585, disc_loss = 0.1415188788458353
Trained batch 127 in epoch 0, gen_loss = 0.45903252251446247, disc_loss = 0.14157330508169252
Trained batch 128 in epoch 0, gen_loss = 0.45792212112005365, disc_loss = 0.14215524282393066
Trained batch 129 in epoch 0, gen_loss = 0.45732443034648895, disc_loss = 0.14207903956278012
Trained batch 130 in epoch 0, gen_loss = 0.45689053708360394, disc_loss = 0.14214490088172085
Trained batch 131 in epoch 0, gen_loss = 0.45640586135965405, disc_loss = 0.1420411354241272
Trained batch 132 in epoch 0, gen_loss = 0.4562336208676933, disc_loss = 0.14174288428647625
Trained batch 133 in epoch 0, gen_loss = 0.45619471237730624, disc_loss = 0.14221550342140357
Trained batch 134 in epoch 0, gen_loss = 0.45586182762075356, disc_loss = 0.1435740483717786
Trained batch 135 in epoch 0, gen_loss = 0.45561544816283617, disc_loss = 0.14401408280793795
Trained batch 136 in epoch 0, gen_loss = 0.4547274134454936, disc_loss = 0.14423939940540026
Trained batch 137 in epoch 0, gen_loss = 0.4537502164426057, disc_loss = 0.14421447988707517
Trained batch 138 in epoch 0, gen_loss = 0.45372232215867625, disc_loss = 0.1440185461354127
Trained batch 139 in epoch 0, gen_loss = 0.45323401093482973, disc_loss = 0.14419521163882953
Trained batch 140 in epoch 0, gen_loss = 0.4536419392477536, disc_loss = 0.14442190597930277
Trained batch 141 in epoch 0, gen_loss = 0.45430555016222135, disc_loss = 0.14425699828638577
Trained batch 142 in epoch 0, gen_loss = 0.45443848088071065, disc_loss = 0.14418534086561285
Trained batch 143 in epoch 0, gen_loss = 0.4539396208193567, disc_loss = 0.14410904397825813
Trained batch 144 in epoch 0, gen_loss = 0.45400938741092023, disc_loss = 0.14427708630161037
Trained batch 145 in epoch 0, gen_loss = 0.4534178606859625, disc_loss = 0.14484569528586652
Trained batch 146 in epoch 0, gen_loss = 0.4531960917167923, disc_loss = 0.14521859734490208
Trained batch 147 in epoch 0, gen_loss = 0.4534499323045885, disc_loss = 0.14576686612909306
Trained batch 148 in epoch 0, gen_loss = 0.45336375320517774, disc_loss = 0.1465164056585339
Trained batch 149 in epoch 0, gen_loss = 0.4530219397942225, disc_loss = 0.1464936440810561
Trained batch 150 in epoch 0, gen_loss = 0.45242039000751166, disc_loss = 0.1464227335959278
Trained batch 151 in epoch 0, gen_loss = 0.45174909147777054, disc_loss = 0.14631528099753746
Trained batch 152 in epoch 0, gen_loss = 0.4514552623617883, disc_loss = 0.14601136638107254
Trained batch 153 in epoch 0, gen_loss = 0.4511609089064908, disc_loss = 0.14567457372927434
Trained batch 154 in epoch 0, gen_loss = 0.451114752984816, disc_loss = 0.14564936316061405
Trained batch 155 in epoch 0, gen_loss = 0.45091941226751375, disc_loss = 0.14559829962224916
Trained batch 156 in epoch 0, gen_loss = 0.45137152702185757, disc_loss = 0.1461029752353384
Trained batch 157 in epoch 0, gen_loss = 0.4515002266138415, disc_loss = 0.14692077730322564
Trained batch 158 in epoch 0, gen_loss = 0.4513125417742339, disc_loss = 0.14779586116519738
Trained batch 159 in epoch 0, gen_loss = 0.45084126126021146, disc_loss = 0.1478080526110716
Trained batch 160 in epoch 0, gen_loss = 0.45121911871507303, disc_loss = 0.1478083178239024
Trained batch 161 in epoch 0, gen_loss = 0.45109500487645465, disc_loss = 0.14789276175706842
Trained batch 162 in epoch 0, gen_loss = 0.45061649555808925, disc_loss = 0.14787873005254504
Trained batch 163 in epoch 0, gen_loss = 0.450143575304892, disc_loss = 0.14774132939055562
Trained batch 164 in epoch 0, gen_loss = 0.45067597808259907, disc_loss = 0.14734836176715113
Trained batch 165 in epoch 0, gen_loss = 0.4506641252931342, disc_loss = 0.14720926578549376
Trained batch 166 in epoch 0, gen_loss = 0.45025242285100286, disc_loss = 0.14706218796977383
Trained batch 167 in epoch 0, gen_loss = 0.4506605024493876, disc_loss = 0.14680666890039684
Trained batch 168 in epoch 0, gen_loss = 0.4511470408481959, disc_loss = 0.14617685547109538
Trained batch 169 in epoch 0, gen_loss = 0.4510811328887939, disc_loss = 0.14624374891247818
Trained batch 170 in epoch 0, gen_loss = 0.45147656000148484, disc_loss = 0.14860429572300954
Trained batch 171 in epoch 0, gen_loss = 0.4512341344772383, disc_loss = 0.14866623954934088
Trained batch 172 in epoch 0, gen_loss = 0.4512713442992613, disc_loss = 0.1488688231225131
Trained batch 173 in epoch 0, gen_loss = 0.45159753557594345, disc_loss = 0.14929297340541392
Trained batch 174 in epoch 0, gen_loss = 0.4514627356188638, disc_loss = 0.1495147605985403
Trained batch 175 in epoch 0, gen_loss = 0.45135457475077023, disc_loss = 0.14971295012880795
Trained batch 176 in epoch 0, gen_loss = 0.45099265831338486, disc_loss = 0.14961272929558309
Trained batch 177 in epoch 0, gen_loss = 0.4507249232088582, disc_loss = 0.14947304967790842
Trained batch 178 in epoch 0, gen_loss = 0.45036078681492936, disc_loss = 0.1494855770955705
Trained batch 179 in epoch 0, gen_loss = 0.450074481467406, disc_loss = 0.14922286786345973
Trained batch 180 in epoch 0, gen_loss = 0.44970095865634263, disc_loss = 0.1492265528016492
Trained batch 181 in epoch 0, gen_loss = 0.4490018490251604, disc_loss = 0.14953797835611052
Trained batch 182 in epoch 0, gen_loss = 0.44916948073548696, disc_loss = 0.14965328306488979
Trained batch 183 in epoch 0, gen_loss = 0.44853476272976917, disc_loss = 0.1497705352148446
Trained batch 184 in epoch 0, gen_loss = 0.4475752363333831, disc_loss = 0.15113834095363682
Trained batch 185 in epoch 0, gen_loss = 0.44736812528102626, disc_loss = 0.15292295125583488
Trained batch 186 in epoch 0, gen_loss = 0.44712282820818894, disc_loss = 0.15350054324988058
Trained batch 187 in epoch 0, gen_loss = 0.4465254270967017, disc_loss = 0.15434782255559842
Trained batch 188 in epoch 0, gen_loss = 0.44615341699312605, disc_loss = 0.15490278350337158
Trained batch 189 in epoch 0, gen_loss = 0.44568332292531665, disc_loss = 0.1552902367652247
Trained batch 190 in epoch 0, gen_loss = 0.44543941482823557, disc_loss = 0.15568464254248518
Trained batch 191 in epoch 0, gen_loss = 0.44489727076143026, disc_loss = 0.1561044771321273
Trained batch 192 in epoch 0, gen_loss = 0.44461660295570454, disc_loss = 0.15653143638812508
Trained batch 193 in epoch 0, gen_loss = 0.4442146535693985, disc_loss = 0.15710681163197018
Trained batch 194 in epoch 0, gen_loss = 0.443642125527064, disc_loss = 0.15761696552045834
Trained batch 195 in epoch 0, gen_loss = 0.4433050245350721, disc_loss = 0.15790240140631795
Trained batch 196 in epoch 0, gen_loss = 0.4431045273233791, disc_loss = 0.15831788543252473
Trained batch 197 in epoch 0, gen_loss = 0.44278551201627714, disc_loss = 0.15862759722942354
Trained batch 198 in epoch 0, gen_loss = 0.44228457446074365, disc_loss = 0.15902898854683692
Trained batch 199 in epoch 0, gen_loss = 0.44197748199105263, disc_loss = 0.1592699417565018
Trained batch 200 in epoch 0, gen_loss = 0.4417235120315457, disc_loss = 0.1596012341683332
Trained batch 201 in epoch 0, gen_loss = 0.44165462801362027, disc_loss = 0.15992932789728487
Trained batch 202 in epoch 0, gen_loss = 0.441173097036155, disc_loss = 0.16033180213069975
Trained batch 203 in epoch 0, gen_loss = 0.4408501827833699, disc_loss = 0.16092018462607965
Trained batch 204 in epoch 0, gen_loss = 0.44079205640932406, disc_loss = 0.16119550605554406
Trained batch 205 in epoch 0, gen_loss = 0.4403637523211322, disc_loss = 0.1616746805771028
Trained batch 206 in epoch 0, gen_loss = 0.4401565664920254, disc_loss = 0.16202639490545948
Trained batch 207 in epoch 0, gen_loss = 0.4397875382923163, disc_loss = 0.16223119866425315
Trained batch 208 in epoch 0, gen_loss = 0.4395122472464183, disc_loss = 0.16239559907983078
Trained batch 209 in epoch 0, gen_loss = 0.43949795677548364, disc_loss = 0.16268749763036058
Trained batch 210 in epoch 0, gen_loss = 0.43921183847703077, disc_loss = 0.1632545648398699
Trained batch 211 in epoch 0, gen_loss = 0.4391805941485009, disc_loss = 0.16341131532845912
Trained batch 212 in epoch 0, gen_loss = 0.43922553529761765, disc_loss = 0.16358938772108914
Trained batch 213 in epoch 0, gen_loss = 0.4391775642321489, disc_loss = 0.1637734857205058
Trained batch 214 in epoch 0, gen_loss = 0.43884732362835904, disc_loss = 0.1639006049220645
Trained batch 215 in epoch 0, gen_loss = 0.43850629142037145, disc_loss = 0.16403522191534717
Trained batch 216 in epoch 0, gen_loss = 0.43865812731228665, disc_loss = 0.1640050437404401
Trained batch 217 in epoch 0, gen_loss = 0.4383017921119655, disc_loss = 0.16436365958508276
Trained batch 218 in epoch 0, gen_loss = 0.4378809568272334, disc_loss = 0.1645360938167055
Trained batch 219 in epoch 0, gen_loss = 0.43767537122423, disc_loss = 0.16461391510780563
Trained batch 220 in epoch 0, gen_loss = 0.437907633333724, disc_loss = 0.16460562501591525
Trained batch 221 in epoch 0, gen_loss = 0.43776636926440504, disc_loss = 0.16504562620140678
Trained batch 222 in epoch 0, gen_loss = 0.4373174073182948, disc_loss = 0.16543099772803185
Trained batch 223 in epoch 0, gen_loss = 0.4371120784697788, disc_loss = 0.16554161767375522
Trained batch 224 in epoch 0, gen_loss = 0.43689737452401056, disc_loss = 0.1657581275784307
Trained batch 225 in epoch 0, gen_loss = 0.4367315132269817, disc_loss = 0.1658661032623026
Trained batch 226 in epoch 0, gen_loss = 0.43635292331552716, disc_loss = 0.1663337351943034
Trained batch 227 in epoch 0, gen_loss = 0.4360457956790924, disc_loss = 0.16685572391571968
Trained batch 228 in epoch 0, gen_loss = 0.43598783224430665, disc_loss = 0.16715431084051144
Trained batch 229 in epoch 0, gen_loss = 0.43555501660575036, disc_loss = 0.16748055026097142
Trained batch 230 in epoch 0, gen_loss = 0.4351308916038249, disc_loss = 0.16785034873559104
Trained batch 231 in epoch 0, gen_loss = 0.4352333001021681, disc_loss = 0.16785961274732034
Trained batch 232 in epoch 0, gen_loss = 0.4349630894579089, disc_loss = 0.16813684629812006
Trained batch 233 in epoch 0, gen_loss = 0.4345773375696606, disc_loss = 0.16827003792342213
Trained batch 234 in epoch 0, gen_loss = 0.4339938085129921, disc_loss = 0.16840063683054549
Trained batch 235 in epoch 0, gen_loss = 0.43413586207365584, disc_loss = 0.16884009963911722
Trained batch 236 in epoch 0, gen_loss = 0.4339670473513221, disc_loss = 0.16933409342314373
Trained batch 237 in epoch 0, gen_loss = 0.4336922263898769, disc_loss = 0.16962202589082367
Trained batch 238 in epoch 0, gen_loss = 0.4331490888755192, disc_loss = 0.1698229109720331
Trained batch 239 in epoch 0, gen_loss = 0.4325831944743792, disc_loss = 0.16989480475119004
Trained batch 240 in epoch 0, gen_loss = 0.43267189862817157, disc_loss = 0.16990084254426333
Trained batch 241 in epoch 0, gen_loss = 0.43256365021398246, disc_loss = 0.1700644892186296
Trained batch 242 in epoch 0, gen_loss = 0.43266499214211607, disc_loss = 0.17005363315987734
Trained batch 243 in epoch 0, gen_loss = 0.4322959017313895, disc_loss = 0.17013967367744104
Trained batch 244 in epoch 0, gen_loss = 0.43195452592810807, disc_loss = 0.17032103387220782
Trained batch 245 in epoch 0, gen_loss = 0.4315093170578887, disc_loss = 0.17033199348857975
Trained batch 246 in epoch 0, gen_loss = 0.43119633885530323, disc_loss = 0.1704795104244098
Trained batch 247 in epoch 0, gen_loss = 0.4310462897823703, disc_loss = 0.17028766639921214
Trained batch 248 in epoch 0, gen_loss = 0.43095340953773287, disc_loss = 0.170277595497578
Trained batch 249 in epoch 0, gen_loss = 0.4305076483488083, disc_loss = 0.17037396923452616
Trained batch 250 in epoch 0, gen_loss = 0.43046109882958855, disc_loss = 0.17079491483648698
Trained batch 251 in epoch 0, gen_loss = 0.43102616107180003, disc_loss = 0.17194685047965438
Trained batch 252 in epoch 0, gen_loss = 0.4306579381816472, disc_loss = 0.17233962743090311
Trained batch 253 in epoch 0, gen_loss = 0.4301823245024118, disc_loss = 0.17291757397676313
Trained batch 254 in epoch 0, gen_loss = 0.43007771150738583, disc_loss = 0.17332777501467397
Trained batch 255 in epoch 0, gen_loss = 0.42982610792387277, disc_loss = 0.17395115717226872
Trained batch 256 in epoch 0, gen_loss = 0.42967941151054917, disc_loss = 0.17405487844133424
Trained batch 257 in epoch 0, gen_loss = 0.4291780644146971, disc_loss = 0.17421076265560795
Trained batch 258 in epoch 0, gen_loss = 0.42895535497591764, disc_loss = 0.17433085034396428
Trained batch 259 in epoch 0, gen_loss = 0.4289795286380328, disc_loss = 0.17432962699721638
Trained batch 260 in epoch 0, gen_loss = 0.42863963458729887, disc_loss = 0.1743767095722572
Trained batch 261 in epoch 0, gen_loss = 0.4285130923940935, disc_loss = 0.17433108546493845
Trained batch 262 in epoch 0, gen_loss = 0.428522231121027, disc_loss = 0.17427475414037025
Trained batch 263 in epoch 0, gen_loss = 0.4285863403118018, disc_loss = 0.17426432401760283
Trained batch 264 in epoch 0, gen_loss = 0.42841155585253016, disc_loss = 0.17429421592574074
Trained batch 265 in epoch 0, gen_loss = 0.4282035176691256, disc_loss = 0.17438832959650377
Trained batch 266 in epoch 0, gen_loss = 0.4280743899193596, disc_loss = 0.17437495277978285
Trained batch 267 in epoch 0, gen_loss = 0.4278387765386211, disc_loss = 0.1743791966087449
Trained batch 268 in epoch 0, gen_loss = 0.4274557752458579, disc_loss = 0.17452799463056057
Trained batch 269 in epoch 0, gen_loss = 0.42750765681266784, disc_loss = 0.17501033365864443
Trained batch 270 in epoch 0, gen_loss = 0.4273806281415299, disc_loss = 0.17529792020379178
Trained batch 271 in epoch 0, gen_loss = 0.42754331132506623, disc_loss = 0.17529386225129096
Trained batch 272 in epoch 0, gen_loss = 0.42755750902406464, disc_loss = 0.17543708064317048
Trained batch 273 in epoch 0, gen_loss = 0.42724791647744004, disc_loss = 0.17554431352220531
Trained batch 274 in epoch 0, gen_loss = 0.42666920445182105, disc_loss = 0.17581101789393208
Trained batch 275 in epoch 0, gen_loss = 0.4263019610358321, disc_loss = 0.17585055943767447
Trained batch 276 in epoch 0, gen_loss = 0.42613086082875085, disc_loss = 0.17585916062043677
Trained batch 277 in epoch 0, gen_loss = 0.42591575613553573, disc_loss = 0.17608756762962763
Trained batch 278 in epoch 0, gen_loss = 0.4257910656459015, disc_loss = 0.17597254013849628
Trained batch 279 in epoch 0, gen_loss = 0.4254464991390705, disc_loss = 0.17601909763179718
Trained batch 280 in epoch 0, gen_loss = 0.42529312709472356, disc_loss = 0.1760378509454986
Trained batch 281 in epoch 0, gen_loss = 0.42511965027937654, disc_loss = 0.17597656214200225
Trained batch 282 in epoch 0, gen_loss = 0.42513558963583553, disc_loss = 0.1758764593437472
Trained batch 283 in epoch 0, gen_loss = 0.42483788266987865, disc_loss = 0.17586913734385876
Trained batch 284 in epoch 0, gen_loss = 0.42465966375250563, disc_loss = 0.17586332149803638
Trained batch 285 in epoch 0, gen_loss = 0.4244221664600439, disc_loss = 0.17612301561512522
Trained batch 286 in epoch 0, gen_loss = 0.4242286843082215, disc_loss = 0.17620682600197685
Trained batch 287 in epoch 0, gen_loss = 0.4240956125367019, disc_loss = 0.1762205341947265
Trained batch 288 in epoch 0, gen_loss = 0.42391807614313276, disc_loss = 0.17620916322363495
Trained batch 289 in epoch 0, gen_loss = 0.4236901464133427, disc_loss = 0.17633034708299514
Trained batch 290 in epoch 0, gen_loss = 0.42337285509633854, disc_loss = 0.17628985006503017
Trained batch 291 in epoch 0, gen_loss = 0.42299035691643416, disc_loss = 0.17640422364339642
Trained batch 292 in epoch 0, gen_loss = 0.4226368214083206, disc_loss = 0.1764592190460642
Trained batch 293 in epoch 0, gen_loss = 0.4228213577448916, disc_loss = 0.17625333848377678
Trained batch 294 in epoch 0, gen_loss = 0.4228635138374264, disc_loss = 0.17601873564644385
Trained batch 295 in epoch 0, gen_loss = 0.4224886450211744, disc_loss = 0.17603762984603039
Trained batch 296 in epoch 0, gen_loss = 0.42235292238418504, disc_loss = 0.1760087294522861
Trained batch 297 in epoch 0, gen_loss = 0.4221183486632853, disc_loss = 0.1765482287991467
Trained batch 298 in epoch 0, gen_loss = 0.4219973895661408, disc_loss = 0.17735273845144936
Trained batch 299 in epoch 0, gen_loss = 0.42205252856016157, disc_loss = 0.17749988509342074
Trained batch 300 in epoch 0, gen_loss = 0.4219977484390981, disc_loss = 0.17750924873317397
Trained batch 301 in epoch 0, gen_loss = 0.4219985896388426, disc_loss = 0.17763796614618688
Trained batch 302 in epoch 0, gen_loss = 0.42191932470885046, disc_loss = 0.17765763114904218
Trained batch 303 in epoch 0, gen_loss = 0.4217319334612081, disc_loss = 0.17777689510196643
Trained batch 304 in epoch 0, gen_loss = 0.4215206579106753, disc_loss = 0.17782880427529577
Trained batch 305 in epoch 0, gen_loss = 0.42150649048534095, disc_loss = 0.17792030845713966
Trained batch 306 in epoch 0, gen_loss = 0.4215696177381646, disc_loss = 0.17810583433154545
Trained batch 307 in epoch 0, gen_loss = 0.42130592833091685, disc_loss = 0.17848152762230535
Trained batch 308 in epoch 0, gen_loss = 0.42150991248467207, disc_loss = 0.17853666189153797
Trained batch 309 in epoch 0, gen_loss = 0.4214657622960306, disc_loss = 0.17850608405687154
Trained batch 310 in epoch 0, gen_loss = 0.4211220095395275, disc_loss = 0.17845262709849324
Trained batch 311 in epoch 0, gen_loss = 0.4212409627552216, disc_loss = 0.17858277063649625
Trained batch 312 in epoch 0, gen_loss = 0.421191309397213, disc_loss = 0.17894510408869377
Trained batch 313 in epoch 0, gen_loss = 0.42096343484653787, disc_loss = 0.17887623772428485
Trained batch 314 in epoch 0, gen_loss = 0.4208930183970739, disc_loss = 0.17894417906682641
Trained batch 315 in epoch 0, gen_loss = 0.42073275620424294, disc_loss = 0.1789557190458703
Trained batch 316 in epoch 0, gen_loss = 0.4207387607932467, disc_loss = 0.17883425601390823
Trained batch 317 in epoch 0, gen_loss = 0.42086574350887873, disc_loss = 0.17868838930771974
Trained batch 318 in epoch 0, gen_loss = 0.42055626517179245, disc_loss = 0.1786902468231124
Trained batch 319 in epoch 0, gen_loss = 0.4204868270084262, disc_loss = 0.17863522044499405
Trained batch 320 in epoch 0, gen_loss = 0.4204851703666081, disc_loss = 0.17858327180727435
Trained batch 321 in epoch 0, gen_loss = 0.42026809043025376, disc_loss = 0.1785165668748643
Trained batch 322 in epoch 0, gen_loss = 0.42016972882828846, disc_loss = 0.17840774835378578
Trained batch 323 in epoch 0, gen_loss = 0.4199758302650334, disc_loss = 0.17820270640637587
Trained batch 324 in epoch 0, gen_loss = 0.41991540532845717, disc_loss = 0.178006634626251
Trained batch 325 in epoch 0, gen_loss = 0.41975601200311463, disc_loss = 0.17781284164088818
Trained batch 326 in epoch 0, gen_loss = 0.41953169388144024, disc_loss = 0.17756780561071106
Trained batch 327 in epoch 0, gen_loss = 0.4193116099369235, disc_loss = 0.1777784377166138
Trained batch 328 in epoch 0, gen_loss = 0.419387906518026, disc_loss = 0.17880961795459221
Trained batch 329 in epoch 0, gen_loss = 0.4190607620008064, disc_loss = 0.1787903017449108
Trained batch 330 in epoch 0, gen_loss = 0.4189956977828392, disc_loss = 0.17960707310395838
Trained batch 331 in epoch 0, gen_loss = 0.4189492159758706, disc_loss = 0.17979306977309556
Trained batch 332 in epoch 0, gen_loss = 0.4189028974409934, disc_loss = 0.18005004890442072
Trained batch 333 in epoch 0, gen_loss = 0.41903792375219084, disc_loss = 0.1800854931345689
Trained batch 334 in epoch 0, gen_loss = 0.41868746405217183, disc_loss = 0.18028779392922992
Trained batch 335 in epoch 0, gen_loss = 0.41861490479537417, disc_loss = 0.180265925142781
Trained batch 336 in epoch 0, gen_loss = 0.41841569958525526, disc_loss = 0.18015445625680312
Trained batch 337 in epoch 0, gen_loss = 0.41802418805085695, disc_loss = 0.18019780567874746
Trained batch 338 in epoch 0, gen_loss = 0.41782871679922123, disc_loss = 0.18030227714693475
Trained batch 339 in epoch 0, gen_loss = 0.4178876964484944, disc_loss = 0.18017970177290193
Trained batch 340 in epoch 0, gen_loss = 0.4176893936049554, disc_loss = 0.1802841302859556
Trained batch 341 in epoch 0, gen_loss = 0.41747052523127776, disc_loss = 0.18033485126011728
Trained batch 342 in epoch 0, gen_loss = 0.4171841478208759, disc_loss = 0.1803476039602614
Trained batch 343 in epoch 0, gen_loss = 0.4168492965400219, disc_loss = 0.18029989551774464
Trained batch 344 in epoch 0, gen_loss = 0.41682943347571555, disc_loss = 0.18025854150562182
Trained batch 345 in epoch 0, gen_loss = 0.4167815951598173, disc_loss = 0.18031568720269237
Trained batch 346 in epoch 0, gen_loss = 0.41672352299910115, disc_loss = 0.18014431288009589
Trained batch 347 in epoch 0, gen_loss = 0.41645504277327966, disc_loss = 0.18011912502798028
Trained batch 348 in epoch 0, gen_loss = 0.41641647486085537, disc_loss = 0.1800559941081485
Trained batch 349 in epoch 0, gen_loss = 0.4162412462915693, disc_loss = 0.17995355495916945
Trained batch 350 in epoch 0, gen_loss = 0.4161641302271786, disc_loss = 0.1800251972949148
Trained batch 351 in epoch 0, gen_loss = 0.4160285120491277, disc_loss = 0.18012813077075407
Trained batch 352 in epoch 0, gen_loss = 0.4160645447101539, disc_loss = 0.17990255265604843
Trained batch 353 in epoch 0, gen_loss = 0.4160174090983504, disc_loss = 0.17969123099925322
Trained batch 354 in epoch 0, gen_loss = 0.4156854677368218, disc_loss = 0.1796860150310775
Trained batch 355 in epoch 0, gen_loss = 0.41550150965706684, disc_loss = 0.18018944296211506
Trained batch 356 in epoch 0, gen_loss = 0.41540166994436784, disc_loss = 0.18037876627128832
Trained batch 357 in epoch 0, gen_loss = 0.41520279296283613, disc_loss = 0.1805198484636302
Trained batch 358 in epoch 0, gen_loss = 0.4149233189964029, disc_loss = 0.18054314562142892
Trained batch 359 in epoch 0, gen_loss = 0.41485983489288225, disc_loss = 0.18031811582235
Trained batch 360 in epoch 0, gen_loss = 0.41479098722545066, disc_loss = 0.18037213860311832
Trained batch 361 in epoch 0, gen_loss = 0.41460338992308515, disc_loss = 0.1804170773225677
Trained batch 362 in epoch 0, gen_loss = 0.41464392155326757, disc_loss = 0.18022597080850897
Trained batch 363 in epoch 0, gen_loss = 0.41446191645585573, disc_loss = 0.1803948477493947
Trained batch 364 in epoch 0, gen_loss = 0.4145959343812237, disc_loss = 0.18033995928931726
Trained batch 365 in epoch 0, gen_loss = 0.41446953767635786, disc_loss = 0.18004958321915462
Trained batch 366 in epoch 0, gen_loss = 0.41427127387608104, disc_loss = 0.17991340759766036
Trained batch 367 in epoch 0, gen_loss = 0.41438785608371964, disc_loss = 0.1798659477069083
Trained batch 368 in epoch 0, gen_loss = 0.4143070327395669, disc_loss = 0.1805759296679319
Trained batch 369 in epoch 0, gen_loss = 0.4140057099026603, disc_loss = 0.1807208530252447
Trained batch 370 in epoch 0, gen_loss = 0.41380313962617654, disc_loss = 0.18091188024257554
Trained batch 371 in epoch 0, gen_loss = 0.4138458539401331, disc_loss = 0.18094115943137196
Trained batch 372 in epoch 0, gen_loss = 0.4138219048126773, disc_loss = 0.18085889416889114
Trained batch 373 in epoch 0, gen_loss = 0.41379887072797766, disc_loss = 0.18084066483207087
Trained batch 374 in epoch 0, gen_loss = 0.4136745196978251, disc_loss = 0.18082734734316666
Trained batch 375 in epoch 0, gen_loss = 0.4137209491368304, disc_loss = 0.1808047143078627
Trained batch 376 in epoch 0, gen_loss = 0.4134658191659406, disc_loss = 0.18107567358495227
Trained batch 377 in epoch 0, gen_loss = 0.41349184379060433, disc_loss = 0.18102175721198951
Trained batch 378 in epoch 0, gen_loss = 0.41331411123590295, disc_loss = 0.18109035372517826
Trained batch 379 in epoch 0, gen_loss = 0.4131616237132173, disc_loss = 0.1809823948154716
Trained batch 380 in epoch 0, gen_loss = 0.41318203677029747, disc_loss = 0.1809336311401423
Trained batch 381 in epoch 0, gen_loss = 0.41277664002635717, disc_loss = 0.1809411031189155
Trained batch 382 in epoch 0, gen_loss = 0.4126953314552108, disc_loss = 0.1808724233992495
Trained batch 383 in epoch 0, gen_loss = 0.41286955688459176, disc_loss = 0.18077949219635533
Trained batch 384 in epoch 0, gen_loss = 0.4128770929652375, disc_loss = 0.1809690865071176
Trained batch 385 in epoch 0, gen_loss = 0.4126178938798954, disc_loss = 0.18088255670655112
Trained batch 386 in epoch 0, gen_loss = 0.41264758214778063, disc_loss = 0.18092662672144036
Trained batch 387 in epoch 0, gen_loss = 0.4124795165412205, disc_loss = 0.18121548679167615
Trained batch 388 in epoch 0, gen_loss = 0.41254956503147333, disc_loss = 0.18151518249055873
Trained batch 389 in epoch 0, gen_loss = 0.41261695394149195, disc_loss = 0.18133993237159954
Trained batch 390 in epoch 0, gen_loss = 0.41236868211070593, disc_loss = 0.18119948721774246
Trained batch 391 in epoch 0, gen_loss = 0.41210282936084025, disc_loss = 0.18138423037943335
Trained batch 392 in epoch 0, gen_loss = 0.4119273142050241, disc_loss = 0.18129402035539235
Trained batch 393 in epoch 0, gen_loss = 0.4117307911064419, disc_loss = 0.18162457887461494
Trained batch 394 in epoch 0, gen_loss = 0.411615729558317, disc_loss = 0.1816621771766038
Trained batch 395 in epoch 0, gen_loss = 0.41139236453807715, disc_loss = 0.1817278885000357
Trained batch 396 in epoch 0, gen_loss = 0.4111539418210911, disc_loss = 0.18181667629376017
Trained batch 397 in epoch 0, gen_loss = 0.41115389487252163, disc_loss = 0.18164239060508097
Trained batch 398 in epoch 0, gen_loss = 0.41112702099004184, disc_loss = 0.18165023808360548
Trained batch 399 in epoch 0, gen_loss = 0.411173580288887, disc_loss = 0.1815844099642709
Trained batch 400 in epoch 0, gen_loss = 0.41095721996633194, disc_loss = 0.18155962247819527
Trained batch 401 in epoch 0, gen_loss = 0.4107121547211462, disc_loss = 0.1814621176561387
Trained batch 402 in epoch 0, gen_loss = 0.4108200565756994, disc_loss = 0.18144172959251528
Trained batch 403 in epoch 0, gen_loss = 0.4107209977389562, disc_loss = 0.1813882260011638
Trained batch 404 in epoch 0, gen_loss = 0.41056615857430445, disc_loss = 0.18128417723432735
Trained batch 405 in epoch 0, gen_loss = 0.4107246865045848, disc_loss = 0.18124709748594192
Trained batch 406 in epoch 0, gen_loss = 0.41059610232967125, disc_loss = 0.1811314181674098
Trained batch 407 in epoch 0, gen_loss = 0.41056692023195474, disc_loss = 0.18084491879277514
Trained batch 408 in epoch 0, gen_loss = 0.4104814456552631, disc_loss = 0.18054483974384358
Trained batch 409 in epoch 0, gen_loss = 0.41033630596428383, disc_loss = 0.1806600538832022
Trained batch 410 in epoch 0, gen_loss = 0.4105459149301487, disc_loss = 0.18102449180055274
Trained batch 411 in epoch 0, gen_loss = 0.4107711778827084, disc_loss = 0.18081894292252013
Trained batch 412 in epoch 0, gen_loss = 0.4106232052709519, disc_loss = 0.18099854889688854
Trained batch 413 in epoch 0, gen_loss = 0.4106278665687727, disc_loss = 0.1808699162065047
Trained batch 414 in epoch 0, gen_loss = 0.41063022333455373, disc_loss = 0.18106683958995054
Trained batch 415 in epoch 0, gen_loss = 0.4104501069165193, disc_loss = 0.18105791981529015
Trained batch 416 in epoch 0, gen_loss = 0.4102769546228633, disc_loss = 0.18101863405383606
Trained batch 417 in epoch 0, gen_loss = 0.41031385993843444, disc_loss = 0.1809444983922052
Trained batch 418 in epoch 0, gen_loss = 0.41021222018398934, disc_loss = 0.18104767631783833
Trained batch 419 in epoch 0, gen_loss = 0.41002070839915955, disc_loss = 0.18138532577792094
Trained batch 420 in epoch 0, gen_loss = 0.4098764686997883, disc_loss = 0.18143266492087456
Trained batch 421 in epoch 0, gen_loss = 0.4096599228291715, disc_loss = 0.18154058763889763
Trained batch 422 in epoch 0, gen_loss = 0.4095600552451808, disc_loss = 0.1815603900630353
Trained batch 423 in epoch 0, gen_loss = 0.40943115963688437, disc_loss = 0.18148773381012087
Trained batch 424 in epoch 0, gen_loss = 0.40935499534887426, disc_loss = 0.1814398531659561
Trained batch 425 in epoch 0, gen_loss = 0.4091154872111871, disc_loss = 0.18165651022810753
Trained batch 426 in epoch 0, gen_loss = 0.40886446994138265, disc_loss = 0.18181395781525264
Trained batch 427 in epoch 0, gen_loss = 0.408697867713799, disc_loss = 0.18177221283299205
Trained batch 428 in epoch 0, gen_loss = 0.4086063006818989, disc_loss = 0.18172699757927643
Trained batch 429 in epoch 0, gen_loss = 0.4086957307749016, disc_loss = 0.18157336855263903
Trained batch 430 in epoch 0, gen_loss = 0.4085981128802156, disc_loss = 0.18148496582360804
Trained batch 431 in epoch 0, gen_loss = 0.408655473065597, disc_loss = 0.18126004778659316
Trained batch 432 in epoch 0, gen_loss = 0.40870585156643363, disc_loss = 0.1809921080491766
Trained batch 433 in epoch 0, gen_loss = 0.40881880218257555, disc_loss = 0.18087353745758672
Trained batch 434 in epoch 0, gen_loss = 0.40870099869267695, disc_loss = 0.1808210422895078
Trained batch 435 in epoch 0, gen_loss = 0.4085384514353691, disc_loss = 0.18071569905214763
Trained batch 436 in epoch 0, gen_loss = 0.40870743648956787, disc_loss = 0.18063170273172363
Trained batch 437 in epoch 0, gen_loss = 0.4086191044550508, disc_loss = 0.18067997424825005
Trained batch 438 in epoch 0, gen_loss = 0.40852835903406687, disc_loss = 0.1806020881250874
Trained batch 439 in epoch 0, gen_loss = 0.4084257186813788, disc_loss = 0.18065241605297408
Trained batch 440 in epoch 0, gen_loss = 0.40840673189855214, disc_loss = 0.18089126529860525
Trained batch 441 in epoch 0, gen_loss = 0.4083242696874282, disc_loss = 0.180827759336933
Trained batch 442 in epoch 0, gen_loss = 0.40812196183958116, disc_loss = 0.18103481505831395
Trained batch 443 in epoch 0, gen_loss = 0.4079060727008828, disc_loss = 0.1810281022938455
Trained batch 444 in epoch 0, gen_loss = 0.40792950358283653, disc_loss = 0.18099047889451633
Trained batch 445 in epoch 0, gen_loss = 0.4078548002670699, disc_loss = 0.1810334890103594
Trained batch 446 in epoch 0, gen_loss = 0.4076660750162948, disc_loss = 0.18102253933064222
Trained batch 447 in epoch 0, gen_loss = 0.4077911897828536, disc_loss = 0.1809514834437453
Trained batch 448 in epoch 0, gen_loss = 0.40775733217099197, disc_loss = 0.1811301873785284
Trained batch 449 in epoch 0, gen_loss = 0.4077066273821725, disc_loss = 0.18118422461466657
Trained batch 450 in epoch 0, gen_loss = 0.4077338686671331, disc_loss = 0.18104454393843458
Trained batch 451 in epoch 0, gen_loss = 0.4077165530978051, disc_loss = 0.18144379939834496
Trained batch 452 in epoch 0, gen_loss = 0.4076367992965328, disc_loss = 0.18148074630919275
Trained batch 453 in epoch 0, gen_loss = 0.4076432424888737, disc_loss = 0.18136805799350733
Trained batch 454 in epoch 0, gen_loss = 0.4075817430412376, disc_loss = 0.18137305913963817
Trained batch 455 in epoch 0, gen_loss = 0.40758080251122775, disc_loss = 0.1813404198466359
Trained batch 456 in epoch 0, gen_loss = 0.4077010842720841, disc_loss = 0.18116990882389786
Trained batch 457 in epoch 0, gen_loss = 0.4075534173234581, disc_loss = 0.1812401688149337
Trained batch 458 in epoch 0, gen_loss = 0.4072919440555157, disc_loss = 0.1815195104679446
Trained batch 459 in epoch 0, gen_loss = 0.4073238035906916, disc_loss = 0.18135171762222183
Trained batch 460 in epoch 0, gen_loss = 0.4074371493302302, disc_loss = 0.18120004789026983
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 0.3756481111049652, disc_loss = 0.11522749066352844
Trained batch 1 in epoch 1, gen_loss = 0.3656279444694519, disc_loss = 0.15011800825595856
Trained batch 2 in epoch 1, gen_loss = 0.37962761521339417, disc_loss = 0.17527892688910165
Trained batch 3 in epoch 1, gen_loss = 0.3824101686477661, disc_loss = 0.1758989430963993
Trained batch 4 in epoch 1, gen_loss = 0.3829432725906372, disc_loss = 0.19333275854587556
Trained batch 5 in epoch 1, gen_loss = 0.37621670961380005, disc_loss = 0.1811465509235859
Trained batch 6 in epoch 1, gen_loss = 0.398330705506461, disc_loss = 0.1730297463280814
Trained batch 7 in epoch 1, gen_loss = 0.41467858105897903, disc_loss = 0.15731930499896407
Trained batch 8 in epoch 1, gen_loss = 0.41387440429793465, disc_loss = 0.14484679202238718
Trained batch 9 in epoch 1, gen_loss = 0.4155005425214767, disc_loss = 0.1381387248635292
Trained batch 10 in epoch 1, gen_loss = 0.41883333162827924, disc_loss = 0.13724158162420447
Trained batch 11 in epoch 1, gen_loss = 0.41324906547864276, disc_loss = 0.13486628234386444
Trained batch 12 in epoch 1, gen_loss = 0.4137213642780597, disc_loss = 0.13297322507088
Trained batch 13 in epoch 1, gen_loss = 0.41152634578091757, disc_loss = 0.13119939980762346
Trained batch 14 in epoch 1, gen_loss = 0.41350956161816915, disc_loss = 0.13443352033694586
Trained batch 15 in epoch 1, gen_loss = 0.4087533690035343, disc_loss = 0.12962861731648445
Trained batch 16 in epoch 1, gen_loss = 0.4052627419724184, disc_loss = 0.1302049317780663
Trained batch 17 in epoch 1, gen_loss = 0.40714080300596023, disc_loss = 0.12644821322626537
Trained batch 18 in epoch 1, gen_loss = 0.4111646209892474, disc_loss = 0.13268068824943743
Trained batch 19 in epoch 1, gen_loss = 0.4101728141307831, disc_loss = 0.13590027168393135
Trained batch 20 in epoch 1, gen_loss = 0.41011413080351694, disc_loss = 0.13662704328695932
Trained batch 21 in epoch 1, gen_loss = 0.4121065139770508, disc_loss = 0.1342390477657318
Trained batch 22 in epoch 1, gen_loss = 0.40964513498803845, disc_loss = 0.13245651255483212
Trained batch 23 in epoch 1, gen_loss = 0.4129592292010784, disc_loss = 0.12948577431961894
Trained batch 24 in epoch 1, gen_loss = 0.41260928273200986, disc_loss = 0.1284351797401905
Trained batch 25 in epoch 1, gen_loss = 0.41415117795650774, disc_loss = 0.12816433450923517
Trained batch 26 in epoch 1, gen_loss = 0.4143152689492261, disc_loss = 0.12957313063519973
Trained batch 27 in epoch 1, gen_loss = 0.4140660507338388, disc_loss = 0.1294614626094699
Trained batch 28 in epoch 1, gen_loss = 0.41234013849291307, disc_loss = 0.13247286412736464
Trained batch 29 in epoch 1, gen_loss = 0.41179644664128623, disc_loss = 0.1332393513371547
Trained batch 30 in epoch 1, gen_loss = 0.4089843361608444, disc_loss = 0.1327126556106152
Trained batch 31 in epoch 1, gen_loss = 0.40678593795746565, disc_loss = 0.13210900768171996
Trained batch 32 in epoch 1, gen_loss = 0.4045218987898393, disc_loss = 0.13015851073644377
Trained batch 33 in epoch 1, gen_loss = 0.40608929097652435, disc_loss = 0.12726292145602844
Trained batch 34 in epoch 1, gen_loss = 0.40413774592535834, disc_loss = 0.12764172852039338
Trained batch 35 in epoch 1, gen_loss = 0.40390749606821275, disc_loss = 0.12815481134586865
Trained batch 36 in epoch 1, gen_loss = 0.4013984058354352, disc_loss = 0.12845110571062243
Trained batch 37 in epoch 1, gen_loss = 0.4042213072902278, disc_loss = 0.1298790283893284
Trained batch 38 in epoch 1, gen_loss = 0.4052803378838759, disc_loss = 0.13572745674695724
Trained batch 39 in epoch 1, gen_loss = 0.40934532731771467, disc_loss = 0.14151762351393699
Trained batch 40 in epoch 1, gen_loss = 0.40722174397329003, disc_loss = 0.14267366070572923
Trained batch 41 in epoch 1, gen_loss = 0.4070155109677996, disc_loss = 0.14395867607423238
Trained batch 42 in epoch 1, gen_loss = 0.40848312059114145, disc_loss = 0.14298583203276924
Trained batch 43 in epoch 1, gen_loss = 0.40612200647592545, disc_loss = 0.14481088061901656
Trained batch 44 in epoch 1, gen_loss = 0.4063841111130185, disc_loss = 0.14768527696530023
Trained batch 45 in epoch 1, gen_loss = 0.4070152828226919, disc_loss = 0.14862200957925423
Trained batch 46 in epoch 1, gen_loss = 0.40731748938560486, disc_loss = 0.14857876887346835
Trained batch 47 in epoch 1, gen_loss = 0.40791446156799793, disc_loss = 0.14980047677333155
Trained batch 48 in epoch 1, gen_loss = 0.4086177227448444, disc_loss = 0.1489092021876452
Trained batch 49 in epoch 1, gen_loss = 0.40747914254665374, disc_loss = 0.1483737276494503
Trained batch 50 in epoch 1, gen_loss = 0.4062712338625216, disc_loss = 0.14901888180597156
Trained batch 51 in epoch 1, gen_loss = 0.4059331319653071, disc_loss = 0.15014448919548437
Trained batch 52 in epoch 1, gen_loss = 0.40613400654972726, disc_loss = 0.15338635992891383
Trained batch 53 in epoch 1, gen_loss = 0.40460494215841647, disc_loss = 0.153287834453362
Trained batch 54 in epoch 1, gen_loss = 0.40290041620081124, disc_loss = 0.15417866584929554
Trained batch 55 in epoch 1, gen_loss = 0.4031847933573382, disc_loss = 0.1532190487320934
Trained batch 56 in epoch 1, gen_loss = 0.4038057797833493, disc_loss = 0.15243734680769735
Trained batch 57 in epoch 1, gen_loss = 0.40277042779429206, disc_loss = 0.15256600364528852
Trained batch 58 in epoch 1, gen_loss = 0.4044034971018969, disc_loss = 0.15236847784559607
Trained batch 59 in epoch 1, gen_loss = 0.4040476356943448, disc_loss = 0.15162683526674905
Trained batch 60 in epoch 1, gen_loss = 0.40484207038019526, disc_loss = 0.15076612155945573
Trained batch 61 in epoch 1, gen_loss = 0.4051147473435248, disc_loss = 0.14931881632055005
Trained batch 62 in epoch 1, gen_loss = 0.4040331007942321, disc_loss = 0.14916069935711604
Trained batch 63 in epoch 1, gen_loss = 0.40485456492751837, disc_loss = 0.1489643872482702
Trained batch 64 in epoch 1, gen_loss = 0.4050368125622089, disc_loss = 0.14851697350923831
Trained batch 65 in epoch 1, gen_loss = 0.40594797016996326, disc_loss = 0.14718517378875703
Trained batch 66 in epoch 1, gen_loss = 0.4057765469622256, disc_loss = 0.14631426345501372
Trained batch 67 in epoch 1, gen_loss = 0.405538615934989, disc_loss = 0.1452342559966971
Trained batch 68 in epoch 1, gen_loss = 0.4056934278080429, disc_loss = 0.14619844817165015
Trained batch 69 in epoch 1, gen_loss = 0.40423499303204674, disc_loss = 0.14568199291825296
Trained batch 70 in epoch 1, gen_loss = 0.4021133516036289, disc_loss = 0.14804429518924633
Trained batch 71 in epoch 1, gen_loss = 0.40199767756793237, disc_loss = 0.14885641417155662
Trained batch 72 in epoch 1, gen_loss = 0.401886522769928, disc_loss = 0.14747058161317486
Trained batch 73 in epoch 1, gen_loss = 0.4013169593102223, disc_loss = 0.14794278950304598
Trained batch 74 in epoch 1, gen_loss = 0.401765532096227, disc_loss = 0.1468486523628235
Trained batch 75 in epoch 1, gen_loss = 0.4025585380823989, disc_loss = 0.14881568284411179
Trained batch 76 in epoch 1, gen_loss = 0.40237277397861726, disc_loss = 0.14795859177391252
Trained batch 77 in epoch 1, gen_loss = 0.402288902646456, disc_loss = 0.1475800252877749
Trained batch 78 in epoch 1, gen_loss = 0.40171909709519976, disc_loss = 0.14676023368971258
Trained batch 79 in epoch 1, gen_loss = 0.4021132092922926, disc_loss = 0.14620887115597725
Trained batch 80 in epoch 1, gen_loss = 0.4015598245608954, disc_loss = 0.14595891185748724
Trained batch 81 in epoch 1, gen_loss = 0.4013921204136639, disc_loss = 0.14593900267670795
Trained batch 82 in epoch 1, gen_loss = 0.40239088039800347, disc_loss = 0.14665515846516713
Trained batch 83 in epoch 1, gen_loss = 0.40217094655547825, disc_loss = 0.1462778684993585
Trained batch 84 in epoch 1, gen_loss = 0.4008650460663964, disc_loss = 0.1453749078161576
Trained batch 85 in epoch 1, gen_loss = 0.4006292930869169, disc_loss = 0.145161124855973
Trained batch 86 in epoch 1, gen_loss = 0.40138169575011595, disc_loss = 0.14461905928863877
Trained batch 87 in epoch 1, gen_loss = 0.40139116685498843, disc_loss = 0.14452504349703138
Trained batch 88 in epoch 1, gen_loss = 0.4021755503804496, disc_loss = 0.14376432456997004
Trained batch 89 in epoch 1, gen_loss = 0.4015258875158098, disc_loss = 0.14320589270856646
Trained batch 90 in epoch 1, gen_loss = 0.4018342619413858, disc_loss = 0.14207523307957493
Trained batch 91 in epoch 1, gen_loss = 0.4023303992074469, disc_loss = 0.14103230789465748
Trained batch 92 in epoch 1, gen_loss = 0.4013840030598384, disc_loss = 0.14128638904101104
Trained batch 93 in epoch 1, gen_loss = 0.4016699489760906, disc_loss = 0.142973203489438
Trained batch 94 in epoch 1, gen_loss = 0.40116983683485735, disc_loss = 0.14282891001356277
Trained batch 95 in epoch 1, gen_loss = 0.40142767565945786, disc_loss = 0.1421441613153244
Trained batch 96 in epoch 1, gen_loss = 0.4018444299083395, disc_loss = 0.14158711770607024
Trained batch 97 in epoch 1, gen_loss = 0.40134981457068, disc_loss = 0.14105553001317442
Trained batch 98 in epoch 1, gen_loss = 0.40094102994360103, disc_loss = 0.1413427400543834
Trained batch 99 in epoch 1, gen_loss = 0.4010357028245926, disc_loss = 0.1409277592971921
Trained batch 100 in epoch 1, gen_loss = 0.40055769858974044, disc_loss = 0.14054017023432372
Trained batch 101 in epoch 1, gen_loss = 0.4009750409453523, disc_loss = 0.14017309880285872
Trained batch 102 in epoch 1, gen_loss = 0.40058309823563953, disc_loss = 0.14097751752988805
Trained batch 103 in epoch 1, gen_loss = 0.40086662196196043, disc_loss = 0.14415956320814216
Trained batch 104 in epoch 1, gen_loss = 0.40118471866562255, disc_loss = 0.14581779670857248
Trained batch 105 in epoch 1, gen_loss = 0.40083862025782746, disc_loss = 0.14699154392868843
Trained batch 106 in epoch 1, gen_loss = 0.40090283723635095, disc_loss = 0.1477655597448906
Trained batch 107 in epoch 1, gen_loss = 0.4006707825594478, disc_loss = 0.14760047518130806
Trained batch 108 in epoch 1, gen_loss = 0.40043554967696515, disc_loss = 0.147236839927938
Trained batch 109 in epoch 1, gen_loss = 0.39994333576072344, disc_loss = 0.14671034735034813
Trained batch 110 in epoch 1, gen_loss = 0.39923460231171, disc_loss = 0.1470733172520324
Trained batch 111 in epoch 1, gen_loss = 0.39964909239539076, disc_loss = 0.14714135565528913
Trained batch 112 in epoch 1, gen_loss = 0.39964410029681385, disc_loss = 0.1472080926517997
Trained batch 113 in epoch 1, gen_loss = 0.4002904716813773, disc_loss = 0.14680669414238973
Trained batch 114 in epoch 1, gen_loss = 0.4006991155769514, disc_loss = 0.14634416540679723
Trained batch 115 in epoch 1, gen_loss = 0.4002040082524563, disc_loss = 0.14618532292159467
Trained batch 116 in epoch 1, gen_loss = 0.3989325035841037, disc_loss = 0.14655083962357962
Trained batch 117 in epoch 1, gen_loss = 0.39804858701714013, disc_loss = 0.14697979437976572
Trained batch 118 in epoch 1, gen_loss = 0.39901756063228894, disc_loss = 0.14709328950828865
Trained batch 119 in epoch 1, gen_loss = 0.3989782539506753, disc_loss = 0.14830885675425332
Trained batch 120 in epoch 1, gen_loss = 0.39807945120433147, disc_loss = 0.152266659981702
Trained batch 121 in epoch 1, gen_loss = 0.39810881995763936, disc_loss = 0.15428599907604398
Trained batch 122 in epoch 1, gen_loss = 0.3986173916638382, disc_loss = 0.15515899194813357
Trained batch 123 in epoch 1, gen_loss = 0.3984017576421461, disc_loss = 0.15623607940130657
Trained batch 124 in epoch 1, gen_loss = 0.39833104753494264, disc_loss = 0.15662362322211265
Trained batch 125 in epoch 1, gen_loss = 0.3981012798964031, disc_loss = 0.15706075452977702
Trained batch 126 in epoch 1, gen_loss = 0.3975735353672598, disc_loss = 0.15758636274089025
Trained batch 127 in epoch 1, gen_loss = 0.39751003589481115, disc_loss = 0.15769174377783202
Trained batch 128 in epoch 1, gen_loss = 0.39716773624568025, disc_loss = 0.15793733388301015
Trained batch 129 in epoch 1, gen_loss = 0.3969919170324619, disc_loss = 0.15809166004451422
Trained batch 130 in epoch 1, gen_loss = 0.3965717893065387, disc_loss = 0.15872744985550413
Trained batch 131 in epoch 1, gen_loss = 0.3959625803611495, disc_loss = 0.15913102558503547
Trained batch 132 in epoch 1, gen_loss = 0.3953581338090108, disc_loss = 0.1593430183155644
Trained batch 133 in epoch 1, gen_loss = 0.3950805808626004, disc_loss = 0.15949912588876575
Trained batch 134 in epoch 1, gen_loss = 0.394601395395067, disc_loss = 0.15964893773198127
Trained batch 135 in epoch 1, gen_loss = 0.3938600771567401, disc_loss = 0.15958137489745722
Trained batch 136 in epoch 1, gen_loss = 0.39415759435535347, disc_loss = 0.15941145415179922
Trained batch 137 in epoch 1, gen_loss = 0.39466216577136, disc_loss = 0.16017474846887417
Trained batch 138 in epoch 1, gen_loss = 0.3939715898294243, disc_loss = 0.16055481776380712
Trained batch 139 in epoch 1, gen_loss = 0.39373380967548915, disc_loss = 0.15997540570263352
Trained batch 140 in epoch 1, gen_loss = 0.3935691401468101, disc_loss = 0.15968183235179448
Trained batch 141 in epoch 1, gen_loss = 0.3935580828659971, disc_loss = 0.1589757603606288
Trained batch 142 in epoch 1, gen_loss = 0.3941846575353529, disc_loss = 0.15803943870107193
Trained batch 143 in epoch 1, gen_loss = 0.394374149127139, disc_loss = 0.15725026288742405
Trained batch 144 in epoch 1, gen_loss = 0.3940077841281891, disc_loss = 0.15655466388782552
Trained batch 145 in epoch 1, gen_loss = 0.39358238324727096, disc_loss = 0.15584040921793818
Trained batch 146 in epoch 1, gen_loss = 0.39375698201510373, disc_loss = 0.15620683720272008
Trained batch 147 in epoch 1, gen_loss = 0.39458152369872945, disc_loss = 0.15701048527970105
Trained batch 148 in epoch 1, gen_loss = 0.39499519475354444, disc_loss = 0.15637821577889408
Trained batch 149 in epoch 1, gen_loss = 0.3949431351820628, disc_loss = 0.15562211179484925
Trained batch 150 in epoch 1, gen_loss = 0.39520817245079193, disc_loss = 0.15476559108702947
Trained batch 151 in epoch 1, gen_loss = 0.3948966894102724, disc_loss = 0.1563219794341804
Trained batch 152 in epoch 1, gen_loss = 0.3951246954646765, disc_loss = 0.1572030601182989
Trained batch 153 in epoch 1, gen_loss = 0.3945772930399164, disc_loss = 0.15735088294831576
Trained batch 154 in epoch 1, gen_loss = 0.39440641037879454, disc_loss = 0.15823729967157688
Trained batch 155 in epoch 1, gen_loss = 0.39414133265232426, disc_loss = 0.15796683304823744
Trained batch 156 in epoch 1, gen_loss = 0.39459232046346, disc_loss = 0.158102023717799
Trained batch 157 in epoch 1, gen_loss = 0.39400203337397754, disc_loss = 0.15810543276322417
Trained batch 158 in epoch 1, gen_loss = 0.39381508069968074, disc_loss = 0.1579174047581992
Trained batch 159 in epoch 1, gen_loss = 0.39396491516381504, disc_loss = 0.15767007680842654
Trained batch 160 in epoch 1, gen_loss = 0.3939278901363752, disc_loss = 0.15730409570593643
Trained batch 161 in epoch 1, gen_loss = 0.39439079349423634, disc_loss = 0.15680869407721876
Trained batch 162 in epoch 1, gen_loss = 0.3946900810200744, disc_loss = 0.15668442229414645
Trained batch 163 in epoch 1, gen_loss = 0.39475568965440844, disc_loss = 0.15826275750494948
Trained batch 164 in epoch 1, gen_loss = 0.3948472422180754, disc_loss = 0.1578515552322973
Trained batch 165 in epoch 1, gen_loss = 0.39477033410445755, disc_loss = 0.15804263187505035
Trained batch 166 in epoch 1, gen_loss = 0.3944258882613953, disc_loss = 0.15885311732079813
Trained batch 167 in epoch 1, gen_loss = 0.3951586956779162, disc_loss = 0.15846775424489307
Trained batch 168 in epoch 1, gen_loss = 0.3952993260332819, disc_loss = 0.15863503538865661
Trained batch 169 in epoch 1, gen_loss = 0.3947702484972337, disc_loss = 0.15851438401595636
Trained batch 170 in epoch 1, gen_loss = 0.394184768897051, disc_loss = 0.15899430046522478
Trained batch 171 in epoch 1, gen_loss = 0.39404487644517144, disc_loss = 0.15958066610619426
Trained batch 172 in epoch 1, gen_loss = 0.3937843285199535, disc_loss = 0.15989442054462227
Trained batch 173 in epoch 1, gen_loss = 0.3935085591571084, disc_loss = 0.16004844546189595
Trained batch 174 in epoch 1, gen_loss = 0.39372355103492734, disc_loss = 0.16053068762379033
Trained batch 175 in epoch 1, gen_loss = 0.3938089734451337, disc_loss = 0.1602850232209841
Trained batch 176 in epoch 1, gen_loss = 0.3933484581230724, disc_loss = 0.16026588829265812
Trained batch 177 in epoch 1, gen_loss = 0.39297636673691566, disc_loss = 0.1601152035899544
Trained batch 178 in epoch 1, gen_loss = 0.39260094375583715, disc_loss = 0.16010239413372299
Trained batch 179 in epoch 1, gen_loss = 0.3925842867957221, disc_loss = 0.1600200006634825
Trained batch 180 in epoch 1, gen_loss = 0.3925700111942397, disc_loss = 0.16066215916932947
Trained batch 181 in epoch 1, gen_loss = 0.3922577398818928, disc_loss = 0.16101305728143717
Trained batch 182 in epoch 1, gen_loss = 0.3919410596454078, disc_loss = 0.16070385542927218
Trained batch 183 in epoch 1, gen_loss = 0.3918075030264647, disc_loss = 0.16081004505774574
Trained batch 184 in epoch 1, gen_loss = 0.39186956399195905, disc_loss = 0.16063478908224685
Trained batch 185 in epoch 1, gen_loss = 0.39159675727608384, disc_loss = 0.16075991667927272
Trained batch 186 in epoch 1, gen_loss = 0.3915899168042576, disc_loss = 0.1611596619720287
Trained batch 187 in epoch 1, gen_loss = 0.3917216530188601, disc_loss = 0.16157701711586497
Trained batch 188 in epoch 1, gen_loss = 0.39175039860937333, disc_loss = 0.16155280879447384
Trained batch 189 in epoch 1, gen_loss = 0.39186554786406064, disc_loss = 0.1612218275372135
Trained batch 190 in epoch 1, gen_loss = 0.39179404633831605, disc_loss = 0.1610378971450148
Trained batch 191 in epoch 1, gen_loss = 0.391693448026975, disc_loss = 0.16106990613237335
Trained batch 192 in epoch 1, gen_loss = 0.3915789399122327, disc_loss = 0.16068509828125566
Trained batch 193 in epoch 1, gen_loss = 0.3913536572579256, disc_loss = 0.1605973019139822
Trained batch 194 in epoch 1, gen_loss = 0.39144699894464935, disc_loss = 0.16101349107921123
Trained batch 195 in epoch 1, gen_loss = 0.3913868373754073, disc_loss = 0.16057549668856116
Trained batch 196 in epoch 1, gen_loss = 0.3913511272311816, disc_loss = 0.16080752764899417
Trained batch 197 in epoch 1, gen_loss = 0.39132229110809286, disc_loss = 0.16147451592853876
Trained batch 198 in epoch 1, gen_loss = 0.3914225755923956, disc_loss = 0.16105212406933905
Trained batch 199 in epoch 1, gen_loss = 0.39098091766238213, disc_loss = 0.16092397072352468
Trained batch 200 in epoch 1, gen_loss = 0.39168879923535815, disc_loss = 0.16055403383847197
Trained batch 201 in epoch 1, gen_loss = 0.39168150059067375, disc_loss = 0.16035760445796912
Trained batch 202 in epoch 1, gen_loss = 0.3919947380796442, disc_loss = 0.16067593439202296
Trained batch 203 in epoch 1, gen_loss = 0.3921372583683799, disc_loss = 0.16096192767259246
Trained batch 204 in epoch 1, gen_loss = 0.392104083445014, disc_loss = 0.16037687260384967
Trained batch 205 in epoch 1, gen_loss = 0.39190059495203705, disc_loss = 0.1602879373573707
Trained batch 206 in epoch 1, gen_loss = 0.39170035230364775, disc_loss = 0.16060464437781036
Trained batch 207 in epoch 1, gen_loss = 0.39167286885472447, disc_loss = 0.16048039332068023
Trained batch 208 in epoch 1, gen_loss = 0.3917500470813952, disc_loss = 0.16059372150762516
Trained batch 209 in epoch 1, gen_loss = 0.39167677873656864, disc_loss = 0.16018179247954062
Trained batch 210 in epoch 1, gen_loss = 0.3920231232710924, disc_loss = 0.15961044787548448
Trained batch 211 in epoch 1, gen_loss = 0.39179788895373074, disc_loss = 0.1589778276107643
Trained batch 212 in epoch 1, gen_loss = 0.39183031841063165, disc_loss = 0.1584163918793901
Trained batch 213 in epoch 1, gen_loss = 0.3917763547919621, disc_loss = 0.15817254606773642
Trained batch 214 in epoch 1, gen_loss = 0.39233906047288764, disc_loss = 0.15811491115668486
Trained batch 215 in epoch 1, gen_loss = 0.3920999816446393, disc_loss = 0.15794009107371998
Trained batch 216 in epoch 1, gen_loss = 0.3919384261155458, disc_loss = 0.1578502613055404
Trained batch 217 in epoch 1, gen_loss = 0.39223930157652687, disc_loss = 0.15835408653653815
Trained batch 218 in epoch 1, gen_loss = 0.391934093955445, disc_loss = 0.1582686232156269
Trained batch 219 in epoch 1, gen_loss = 0.39162961380048233, disc_loss = 0.1578790401108563
Trained batch 220 in epoch 1, gen_loss = 0.3913567009554729, disc_loss = 0.1587152155326907
Trained batch 221 in epoch 1, gen_loss = 0.3915273054494514, disc_loss = 0.15862322007180066
Trained batch 222 in epoch 1, gen_loss = 0.39166825916200476, disc_loss = 0.15837980785945874
Trained batch 223 in epoch 1, gen_loss = 0.39178961369075943, disc_loss = 0.15847703328056792
Trained batch 224 in epoch 1, gen_loss = 0.39175031224886575, disc_loss = 0.1583791015462743
Trained batch 225 in epoch 1, gen_loss = 0.3920214231562825, disc_loss = 0.1580312157016808
Trained batch 226 in epoch 1, gen_loss = 0.39158661210589474, disc_loss = 0.1579146211810968
Trained batch 227 in epoch 1, gen_loss = 0.3915490676697932, disc_loss = 0.15739214880261243
Trained batch 228 in epoch 1, gen_loss = 0.39147229785481913, disc_loss = 0.15700897404427872
Trained batch 229 in epoch 1, gen_loss = 0.3915581135646157, disc_loss = 0.156850709012993
Trained batch 230 in epoch 1, gen_loss = 0.3918320701751874, disc_loss = 0.15700430167411572
Trained batch 231 in epoch 1, gen_loss = 0.39142472168494913, disc_loss = 0.157730733775052
Trained batch 232 in epoch 1, gen_loss = 0.39094609047721895, disc_loss = 0.16071298295560058
Trained batch 233 in epoch 1, gen_loss = 0.3907547949725746, disc_loss = 0.1617448087861268
Trained batch 234 in epoch 1, gen_loss = 0.390956723690033, disc_loss = 0.16462009687848547
Trained batch 235 in epoch 1, gen_loss = 0.39121997735257874, disc_loss = 0.1677689691137333
Trained batch 236 in epoch 1, gen_loss = 0.39130001870388725, disc_loss = 0.16870763834235789
Trained batch 237 in epoch 1, gen_loss = 0.3913143598983268, disc_loss = 0.16934778559326874
Trained batch 238 in epoch 1, gen_loss = 0.39096570201997477, disc_loss = 0.16961885002835275
Trained batch 239 in epoch 1, gen_loss = 0.39068495941658815, disc_loss = 0.16982594721484928
Trained batch 240 in epoch 1, gen_loss = 0.3904825209087356, disc_loss = 0.17015706910848372
Trained batch 241 in epoch 1, gen_loss = 0.3902727553913416, disc_loss = 0.17035514749740518
Trained batch 242 in epoch 1, gen_loss = 0.3903391184630217, disc_loss = 0.17059065038989846
Trained batch 243 in epoch 1, gen_loss = 0.3900566639714554, disc_loss = 0.17056881128734008
Trained batch 244 in epoch 1, gen_loss = 0.3899391004017421, disc_loss = 0.17031160093539832
Trained batch 245 in epoch 1, gen_loss = 0.3901407865247106, disc_loss = 0.1701983364177792
Trained batch 246 in epoch 1, gen_loss = 0.3899207402337418, disc_loss = 0.1700308622060879
Trained batch 247 in epoch 1, gen_loss = 0.3899480457748136, disc_loss = 0.17021489935746836
Trained batch 248 in epoch 1, gen_loss = 0.3899503223388549, disc_loss = 0.1699986600777112
Trained batch 249 in epoch 1, gen_loss = 0.38998244738578797, disc_loss = 0.17047931974381209
Trained batch 250 in epoch 1, gen_loss = 0.38974216995961164, disc_loss = 0.17060709313537734
Trained batch 251 in epoch 1, gen_loss = 0.3898070112816871, disc_loss = 0.17066418183671814
Trained batch 252 in epoch 1, gen_loss = 0.3897147133887521, disc_loss = 0.17079119006606194
Trained batch 253 in epoch 1, gen_loss = 0.3897198397578217, disc_loss = 0.1708772001113361
Trained batch 254 in epoch 1, gen_loss = 0.3896300083281947, disc_loss = 0.17071964868581763
Trained batch 255 in epoch 1, gen_loss = 0.38939021178521216, disc_loss = 0.1705271324244677
Trained batch 256 in epoch 1, gen_loss = 0.38914232286497774, disc_loss = 0.17032688724942477
Trained batch 257 in epoch 1, gen_loss = 0.3888006709342779, disc_loss = 0.1702271124290288
Trained batch 258 in epoch 1, gen_loss = 0.3888565373236608, disc_loss = 0.1703619253551983
Trained batch 259 in epoch 1, gen_loss = 0.389085126725527, disc_loss = 0.1709515461196693
Trained batch 260 in epoch 1, gen_loss = 0.38899909673522715, disc_loss = 0.17076592406407856
Trained batch 261 in epoch 1, gen_loss = 0.3889864100754716, disc_loss = 0.1709734658916829
Trained batch 262 in epoch 1, gen_loss = 0.3888936850734537, disc_loss = 0.17138561019284418
Trained batch 263 in epoch 1, gen_loss = 0.38883678434473096, disc_loss = 0.17119073028901988
Trained batch 264 in epoch 1, gen_loss = 0.38852757620361617, disc_loss = 0.1712514295541453
Trained batch 265 in epoch 1, gen_loss = 0.38829145922248526, disc_loss = 0.1716452757092683
Trained batch 266 in epoch 1, gen_loss = 0.38808637254693534, disc_loss = 0.17183189336140728
Trained batch 267 in epoch 1, gen_loss = 0.3882031255026362, disc_loss = 0.1717892912105282
Trained batch 268 in epoch 1, gen_loss = 0.3880067271592449, disc_loss = 0.17184047275620987
Trained batch 269 in epoch 1, gen_loss = 0.3880180596201508, disc_loss = 0.17189724513640006
Trained batch 270 in epoch 1, gen_loss = 0.3876976049694188, disc_loss = 0.17214697425518308
Trained batch 271 in epoch 1, gen_loss = 0.3877191724365248, disc_loss = 0.1720295802840744
Trained batch 272 in epoch 1, gen_loss = 0.38748466171624457, disc_loss = 0.17203327054806025
Trained batch 273 in epoch 1, gen_loss = 0.38727930296946617, disc_loss = 0.17232868023026382
Trained batch 274 in epoch 1, gen_loss = 0.3871839354254983, disc_loss = 0.1724646941843358
Trained batch 275 in epoch 1, gen_loss = 0.38751718207545904, disc_loss = 0.17258358543630745
Trained batch 276 in epoch 1, gen_loss = 0.38721388642968685, disc_loss = 0.17273384038802733
Trained batch 277 in epoch 1, gen_loss = 0.3872254387937861, disc_loss = 0.17250451608393474
Trained batch 278 in epoch 1, gen_loss = 0.38714387083566315, disc_loss = 0.17255830419613682
Trained batch 279 in epoch 1, gen_loss = 0.38725749009421895, disc_loss = 0.17273955086379178
Trained batch 280 in epoch 1, gen_loss = 0.3871921240434952, disc_loss = 0.17263399480155991
Trained batch 281 in epoch 1, gen_loss = 0.38717506530014334, disc_loss = 0.1728480355417792
Trained batch 282 in epoch 1, gen_loss = 0.38708427221951974, disc_loss = 0.17294082995306687
Trained batch 283 in epoch 1, gen_loss = 0.3873028569448162, disc_loss = 0.1726575836631089
Trained batch 284 in epoch 1, gen_loss = 0.38714145306955305, disc_loss = 0.17262104798696543
Trained batch 285 in epoch 1, gen_loss = 0.3868147737079567, disc_loss = 0.17258070843698053
Trained batch 286 in epoch 1, gen_loss = 0.38688654652455956, disc_loss = 0.17264283084365756
Trained batch 287 in epoch 1, gen_loss = 0.3866358173804151, disc_loss = 0.17245901020942256
Trained batch 288 in epoch 1, gen_loss = 0.38657502546442424, disc_loss = 0.17267494261342142
Trained batch 289 in epoch 1, gen_loss = 0.38657624259077267, disc_loss = 0.17311121032027335
Trained batch 290 in epoch 1, gen_loss = 0.38668269000921873, disc_loss = 0.17299766538351058
Trained batch 291 in epoch 1, gen_loss = 0.3865815333715857, disc_loss = 0.17309489919587154
Trained batch 292 in epoch 1, gen_loss = 0.38655158826515534, disc_loss = 0.17338850607923884
Trained batch 293 in epoch 1, gen_loss = 0.38649219973963134, disc_loss = 0.17310998114269405
Trained batch 294 in epoch 1, gen_loss = 0.3865685265953258, disc_loss = 0.1729633300170555
Trained batch 295 in epoch 1, gen_loss = 0.38649766278025266, disc_loss = 0.17286182327724592
Trained batch 296 in epoch 1, gen_loss = 0.3864335881339179, disc_loss = 0.17303194202833908
Trained batch 297 in epoch 1, gen_loss = 0.38626035297877037, disc_loss = 0.17305583148669676
Trained batch 298 in epoch 1, gen_loss = 0.3862491257015279, disc_loss = 0.1735036611046181
Trained batch 299 in epoch 1, gen_loss = 0.38606008936961494, disc_loss = 0.17401993619278072
Trained batch 300 in epoch 1, gen_loss = 0.38613569172117795, disc_loss = 0.17444706890744427
Trained batch 301 in epoch 1, gen_loss = 0.3863602712849118, disc_loss = 0.17425978434771694
Trained batch 302 in epoch 1, gen_loss = 0.3863562328783986, disc_loss = 0.17456956148122993
Trained batch 303 in epoch 1, gen_loss = 0.3863235598332004, disc_loss = 0.1747385900112261
Trained batch 304 in epoch 1, gen_loss = 0.38640011539224717, disc_loss = 0.17475558513867073
Trained batch 305 in epoch 1, gen_loss = 0.3861537419892604, disc_loss = 0.17477757010755002
Trained batch 306 in epoch 1, gen_loss = 0.38599407876741615, disc_loss = 0.17482993627385712
Trained batch 307 in epoch 1, gen_loss = 0.3856803882238153, disc_loss = 0.17495069860226728
Trained batch 308 in epoch 1, gen_loss = 0.3857947040144294, disc_loss = 0.17509615965621564
Trained batch 309 in epoch 1, gen_loss = 0.3855607037582705, disc_loss = 0.1751491706638086
Trained batch 310 in epoch 1, gen_loss = 0.3854405452584147, disc_loss = 0.17523950194023621
Trained batch 311 in epoch 1, gen_loss = 0.3852985276816747, disc_loss = 0.17549885503159693
Trained batch 312 in epoch 1, gen_loss = 0.3850810051726076, disc_loss = 0.1757540122900432
Trained batch 313 in epoch 1, gen_loss = 0.3848782426612392, disc_loss = 0.1757833851311522
Trained batch 314 in epoch 1, gen_loss = 0.3849361302360656, disc_loss = 0.17586715608716957
Trained batch 315 in epoch 1, gen_loss = 0.3848201219416872, disc_loss = 0.1759209348466483
Trained batch 316 in epoch 1, gen_loss = 0.3848442577225177, disc_loss = 0.1758869185467906
Trained batch 317 in epoch 1, gen_loss = 0.38483176197645796, disc_loss = 0.1757912135290556
Trained batch 318 in epoch 1, gen_loss = 0.38467859455784287, disc_loss = 0.17569022931065117
Trained batch 319 in epoch 1, gen_loss = 0.38431953368708494, disc_loss = 0.17573076718836092
Trained batch 320 in epoch 1, gen_loss = 0.3841153997869878, disc_loss = 0.17556914598376394
Trained batch 321 in epoch 1, gen_loss = 0.38443119879464926, disc_loss = 0.17543324346289688
Trained batch 322 in epoch 1, gen_loss = 0.3842582911160708, disc_loss = 0.17604012514577008
Trained batch 323 in epoch 1, gen_loss = 0.3842858907617169, disc_loss = 0.17590154113569928
Trained batch 324 in epoch 1, gen_loss = 0.3845882339660938, disc_loss = 0.17576484331144737
Trained batch 325 in epoch 1, gen_loss = 0.38459160366307005, disc_loss = 0.1755415792605537
Trained batch 326 in epoch 1, gen_loss = 0.3847058256831738, disc_loss = 0.17520762541949383
Trained batch 327 in epoch 1, gen_loss = 0.38476134109787824, disc_loss = 0.17495319507902535
Trained batch 328 in epoch 1, gen_loss = 0.3848934837568857, disc_loss = 0.17482521185102254
Trained batch 329 in epoch 1, gen_loss = 0.38478372674999817, disc_loss = 0.17462576148523526
Trained batch 330 in epoch 1, gen_loss = 0.3847144239798773, disc_loss = 0.17564402272491478
Trained batch 331 in epoch 1, gen_loss = 0.3846246646829398, disc_loss = 0.1756962204677423
Trained batch 332 in epoch 1, gen_loss = 0.38439712026813727, disc_loss = 0.17569001483823266
Trained batch 333 in epoch 1, gen_loss = 0.38459437050505313, disc_loss = 0.17555412622782107
Trained batch 334 in epoch 1, gen_loss = 0.38471929475442684, disc_loss = 0.17538189580525035
Trained batch 335 in epoch 1, gen_loss = 0.3848957810550928, disc_loss = 0.17571113484224216
Trained batch 336 in epoch 1, gen_loss = 0.38484295141449315, disc_loss = 0.17562717013061047
Trained batch 337 in epoch 1, gen_loss = 0.38534298918303656, disc_loss = 0.1755820495963714
Trained batch 338 in epoch 1, gen_loss = 0.3853698840535144, disc_loss = 0.17545999115701094
Trained batch 339 in epoch 1, gen_loss = 0.3853123532498584, disc_loss = 0.17545223625595954
Trained batch 340 in epoch 1, gen_loss = 0.38538722890563026, disc_loss = 0.1754283980135956
Trained batch 341 in epoch 1, gen_loss = 0.3852984556677746, disc_loss = 0.1753359135861198
Trained batch 342 in epoch 1, gen_loss = 0.3852553244234869, disc_loss = 0.17538155023953483
Trained batch 343 in epoch 1, gen_loss = 0.38543857443471286, disc_loss = 0.1751300884833083
Trained batch 344 in epoch 1, gen_loss = 0.3856112290983615, disc_loss = 0.1750479756867972
Trained batch 345 in epoch 1, gen_loss = 0.38547900534434126, disc_loss = 0.17508838893684175
Trained batch 346 in epoch 1, gen_loss = 0.38539189314979644, disc_loss = 0.17473765049849016
Trained batch 347 in epoch 1, gen_loss = 0.38522778905328664, disc_loss = 0.17502980218429504
Trained batch 348 in epoch 1, gen_loss = 0.3854307897794554, disc_loss = 0.175072908502894
Trained batch 349 in epoch 1, gen_loss = 0.3853059711626598, disc_loss = 0.17485841403582267
Trained batch 350 in epoch 1, gen_loss = 0.385123495108042, disc_loss = 0.1747236861621807
Trained batch 351 in epoch 1, gen_loss = 0.3851698839359663, disc_loss = 0.17488161818949843
Trained batch 352 in epoch 1, gen_loss = 0.38531808365168047, disc_loss = 0.17521701383248772
Trained batch 353 in epoch 1, gen_loss = 0.3851588369257706, disc_loss = 0.1751637417286382
Trained batch 354 in epoch 1, gen_loss = 0.3851544758803408, disc_loss = 0.1749671769131657
Trained batch 355 in epoch 1, gen_loss = 0.3852204763320055, disc_loss = 0.17472126639939928
Trained batch 356 in epoch 1, gen_loss = 0.385260274430283, disc_loss = 0.17455903650978868
Trained batch 357 in epoch 1, gen_loss = 0.38514102479266055, disc_loss = 0.17441892802361503
Trained batch 358 in epoch 1, gen_loss = 0.38510637935821723, disc_loss = 0.17441392371892764
Trained batch 359 in epoch 1, gen_loss = 0.38506143962343536, disc_loss = 0.17441815596798227
Trained batch 360 in epoch 1, gen_loss = 0.38511910019158657, disc_loss = 0.17438882064600567
Trained batch 361 in epoch 1, gen_loss = 0.38508802290120836, disc_loss = 0.17434216895300217
Trained batch 362 in epoch 1, gen_loss = 0.38517852164497063, disc_loss = 0.17435163833693532
Trained batch 363 in epoch 1, gen_loss = 0.3852377616605916, disc_loss = 0.17417194474754588
Trained batch 364 in epoch 1, gen_loss = 0.38517394890523937, disc_loss = 0.17420907830436752
Trained batch 365 in epoch 1, gen_loss = 0.38494247230675704, disc_loss = 0.17414251700186176
Trained batch 366 in epoch 1, gen_loss = 0.38482384184725604, disc_loss = 0.17451799043253755
Trained batch 367 in epoch 1, gen_loss = 0.3846547376850377, disc_loss = 0.17437365166741706
Trained batch 368 in epoch 1, gen_loss = 0.3847912486975755, disc_loss = 0.17454061890904335
Trained batch 369 in epoch 1, gen_loss = 0.38495029871528214, disc_loss = 0.17458579537735597
Trained batch 370 in epoch 1, gen_loss = 0.3846748747594273, disc_loss = 0.1748322556673918
Trained batch 371 in epoch 1, gen_loss = 0.38493253747301714, disc_loss = 0.17460530643321334
Trained batch 372 in epoch 1, gen_loss = 0.38524913540154937, disc_loss = 0.17448344582507022
Trained batch 373 in epoch 1, gen_loss = 0.38520878943848735, disc_loss = 0.17429924188032347
Trained batch 374 in epoch 1, gen_loss = 0.3850132433573405, disc_loss = 0.17466604369382063
Trained batch 375 in epoch 1, gen_loss = 0.38492536893550383, disc_loss = 0.17492112883445907
Trained batch 376 in epoch 1, gen_loss = 0.3851185509791741, disc_loss = 0.1749335323220776
Trained batch 377 in epoch 1, gen_loss = 0.3849887370905548, disc_loss = 0.17522113117335178
Trained batch 378 in epoch 1, gen_loss = 0.38484451662267416, disc_loss = 0.17514238144347252
Trained batch 379 in epoch 1, gen_loss = 0.38452583935699963, disc_loss = 0.17506306168966387
Trained batch 380 in epoch 1, gen_loss = 0.384381191311233, disc_loss = 0.17513765599529732
Trained batch 381 in epoch 1, gen_loss = 0.38435197383633457, disc_loss = 0.17494084820131825
Trained batch 382 in epoch 1, gen_loss = 0.38437840840523924, disc_loss = 0.17478210474644099
Trained batch 383 in epoch 1, gen_loss = 0.38438011201409, disc_loss = 0.17483164123162473
Trained batch 384 in epoch 1, gen_loss = 0.38429949152005183, disc_loss = 0.1748341720357731
Trained batch 385 in epoch 1, gen_loss = 0.38421499258187153, disc_loss = 0.17469869941530913
Trained batch 386 in epoch 1, gen_loss = 0.38400423180225285, disc_loss = 0.1746774235889508
Trained batch 387 in epoch 1, gen_loss = 0.38394562539058863, disc_loss = 0.174555356062219
Trained batch 388 in epoch 1, gen_loss = 0.38396715405361204, disc_loss = 0.17453604026345637
Trained batch 389 in epoch 1, gen_loss = 0.3840555134492043, disc_loss = 0.17436345727302324
Trained batch 390 in epoch 1, gen_loss = 0.3839692521430647, disc_loss = 0.17423115769291625
Trained batch 391 in epoch 1, gen_loss = 0.3840127376725479, disc_loss = 0.1741482132276026
Trained batch 392 in epoch 1, gen_loss = 0.38390588032380313, disc_loss = 0.17412787057345605
Trained batch 393 in epoch 1, gen_loss = 0.3839421844119348, disc_loss = 0.17448011853349238
Trained batch 394 in epoch 1, gen_loss = 0.3838512310498877, disc_loss = 0.1744998272036827
Trained batch 395 in epoch 1, gen_loss = 0.38378879111824615, disc_loss = 0.17446816964263115
Trained batch 396 in epoch 1, gen_loss = 0.3836163926484903, disc_loss = 0.17452888377949183
Trained batch 397 in epoch 1, gen_loss = 0.38353500885879577, disc_loss = 0.17451389343126786
Trained batch 398 in epoch 1, gen_loss = 0.38354817555661785, disc_loss = 0.17460776808996098
Trained batch 399 in epoch 1, gen_loss = 0.38353102520108223, disc_loss = 0.17482927716802807
Trained batch 400 in epoch 1, gen_loss = 0.383791633377646, disc_loss = 0.1746848127816309
Trained batch 401 in epoch 1, gen_loss = 0.3839088295822713, disc_loss = 0.17454954744108134
Trained batch 402 in epoch 1, gen_loss = 0.38377949380992954, disc_loss = 0.1744353540805596
Trained batch 403 in epoch 1, gen_loss = 0.3838694518302927, disc_loss = 0.17447399827052312
Trained batch 404 in epoch 1, gen_loss = 0.38353485612221705, disc_loss = 0.17433614872028064
Trained batch 405 in epoch 1, gen_loss = 0.38348322284632713, disc_loss = 0.17431073846396408
Trained batch 406 in epoch 1, gen_loss = 0.383599853632784, disc_loss = 0.17412983834359072
Trained batch 407 in epoch 1, gen_loss = 0.3834046553455147, disc_loss = 0.1739893194936289
Trained batch 408 in epoch 1, gen_loss = 0.38322410031169435, disc_loss = 0.17377689128746177
Trained batch 409 in epoch 1, gen_loss = 0.38332120260087454, disc_loss = 0.1737355849137757
Trained batch 410 in epoch 1, gen_loss = 0.3833774289800593, disc_loss = 0.1739258151773336
Trained batch 411 in epoch 1, gen_loss = 0.38342975137881863, disc_loss = 0.1738269359226004
Trained batch 412 in epoch 1, gen_loss = 0.3834104880005049, disc_loss = 0.1738763633917016
Trained batch 413 in epoch 1, gen_loss = 0.3833591065545013, disc_loss = 0.17392130157851798
Trained batch 414 in epoch 1, gen_loss = 0.38335256397006023, disc_loss = 0.17392682168767395
Trained batch 415 in epoch 1, gen_loss = 0.38347523394398964, disc_loss = 0.17376314047634459
Trained batch 416 in epoch 1, gen_loss = 0.383141558090274, disc_loss = 0.17390699171387464
Trained batch 417 in epoch 1, gen_loss = 0.38311628205924514, disc_loss = 0.17380548612121047
Trained batch 418 in epoch 1, gen_loss = 0.38328256854578535, disc_loss = 0.1739710261534037
Trained batch 419 in epoch 1, gen_loss = 0.3831940554437183, disc_loss = 0.17398532183308688
Trained batch 420 in epoch 1, gen_loss = 0.38306153401059945, disc_loss = 0.17424272876365593
Trained batch 421 in epoch 1, gen_loss = 0.3830616654236735, disc_loss = 0.1742732388704521
Trained batch 422 in epoch 1, gen_loss = 0.3829694591797272, disc_loss = 0.17419496592107817
Trained batch 423 in epoch 1, gen_loss = 0.3828143259545542, disc_loss = 0.17412951937876642
Trained batch 424 in epoch 1, gen_loss = 0.38272559137905343, disc_loss = 0.17391323348616852
Trained batch 425 in epoch 1, gen_loss = 0.3824906645106598, disc_loss = 0.17396041876395962
Trained batch 426 in epoch 1, gen_loss = 0.38259794638084305, disc_loss = 0.1737800268565394
Trained batch 427 in epoch 1, gen_loss = 0.38264605054788503, disc_loss = 0.17372151667461078
Trained batch 428 in epoch 1, gen_loss = 0.38237692870738066, disc_loss = 0.17369618679728957
Trained batch 429 in epoch 1, gen_loss = 0.38232529156429823, disc_loss = 0.17366250730444527
Trained batch 430 in epoch 1, gen_loss = 0.38256644919134347, disc_loss = 0.17358118940032413
Trained batch 431 in epoch 1, gen_loss = 0.38263205135310135, disc_loss = 0.17347683124157978
Trained batch 432 in epoch 1, gen_loss = 0.3826415843005544, disc_loss = 0.1737118688375446
Trained batch 433 in epoch 1, gen_loss = 0.3825104658230109, disc_loss = 0.17406311508886138
Trained batch 434 in epoch 1, gen_loss = 0.3822771855469408, disc_loss = 0.17406243556446727
Trained batch 435 in epoch 1, gen_loss = 0.3822089189646441, disc_loss = 0.17414770744860583
Trained batch 436 in epoch 1, gen_loss = 0.3820863530483071, disc_loss = 0.17436433484185343
Trained batch 437 in epoch 1, gen_loss = 0.38226853045698717, disc_loss = 0.1742253992919168
Trained batch 438 in epoch 1, gen_loss = 0.3823135551531929, disc_loss = 0.1741095440491932
Trained batch 439 in epoch 1, gen_loss = 0.38220833668654614, disc_loss = 0.17404589134437795
Trained batch 440 in epoch 1, gen_loss = 0.3823704814829794, disc_loss = 0.17442240192219108
Trained batch 441 in epoch 1, gen_loss = 0.3824901451352495, disc_loss = 0.1743568648874962
Trained batch 442 in epoch 1, gen_loss = 0.3824904655898936, disc_loss = 0.17418906936510287
Trained batch 443 in epoch 1, gen_loss = 0.38236554712057114, disc_loss = 0.1740522644365089
Trained batch 444 in epoch 1, gen_loss = 0.38240330199177347, disc_loss = 0.174029057611073
Trained batch 445 in epoch 1, gen_loss = 0.38228917990564765, disc_loss = 0.1741897540267206
Trained batch 446 in epoch 1, gen_loss = 0.38228848369862944, disc_loss = 0.1739682625995853
Trained batch 447 in epoch 1, gen_loss = 0.3823318351060152, disc_loss = 0.17384331203980505
Trained batch 448 in epoch 1, gen_loss = 0.3821549728877826, disc_loss = 0.17379594575572252
Trained batch 449 in epoch 1, gen_loss = 0.3820053731732898, disc_loss = 0.17428418261723386
Trained batch 450 in epoch 1, gen_loss = 0.3820248747083406, disc_loss = 0.17406916551853627
Trained batch 451 in epoch 1, gen_loss = 0.3821278124783946, disc_loss = 0.17429032664235056
Trained batch 452 in epoch 1, gen_loss = 0.3820533995859933, disc_loss = 0.17425491612725305
Trained batch 453 in epoch 1, gen_loss = 0.3820962076145122, disc_loss = 0.17428917867348975
Trained batch 454 in epoch 1, gen_loss = 0.38217989042565065, disc_loss = 0.1742024852965887
Trained batch 455 in epoch 1, gen_loss = 0.3823310198229656, disc_loss = 0.17397454967150433
Trained batch 456 in epoch 1, gen_loss = 0.3823375213459232, disc_loss = 0.17379862071306362
Trained batch 457 in epoch 1, gen_loss = 0.38228579008683367, disc_loss = 0.17357491052355697
Trained batch 458 in epoch 1, gen_loss = 0.38216529965140983, disc_loss = 0.17337519217339345
Trained batch 459 in epoch 1, gen_loss = 0.38229101844455887, disc_loss = 0.17317235305824358
Trained batch 460 in epoch 1, gen_loss = 0.3824775431006177, disc_loss = 0.173283557680288
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 0.33720657229423523, disc_loss = 0.10631401836872101
Trained batch 1 in epoch 2, gen_loss = 0.3579363375902176, disc_loss = 0.13365072011947632
Trained batch 2 in epoch 2, gen_loss = 0.38563353816668194, disc_loss = 0.12869415680567423
Trained batch 3 in epoch 2, gen_loss = 0.3998759910464287, disc_loss = 0.12484226189553738
Trained batch 4 in epoch 2, gen_loss = 0.39657759070396426, disc_loss = 0.1328762635588646
Trained batch 5 in epoch 2, gen_loss = 0.3893617441256841, disc_loss = 0.15532096599539122
Trained batch 6 in epoch 2, gen_loss = 0.3848905691078731, disc_loss = 0.1582214438489505
Trained batch 7 in epoch 2, gen_loss = 0.3900658003985882, disc_loss = 0.17440480273216963
Trained batch 8 in epoch 2, gen_loss = 0.394657207859887, disc_loss = 0.1888589652048217
Trained batch 9 in epoch 2, gen_loss = 0.3982270061969757, disc_loss = 0.19250852093100548
Trained batch 10 in epoch 2, gen_loss = 0.39082641222260217, disc_loss = 0.19501604343002493
Trained batch 11 in epoch 2, gen_loss = 0.3919033606847127, disc_loss = 0.19858359235028425
Trained batch 12 in epoch 2, gen_loss = 0.3879132591761075, disc_loss = 0.20359739833153212
Trained batch 13 in epoch 2, gen_loss = 0.38514733953135355, disc_loss = 0.1994133203157357
Trained batch 14 in epoch 2, gen_loss = 0.38181072076161704, disc_loss = 0.19577924956878026
Trained batch 15 in epoch 2, gen_loss = 0.37597233057022095, disc_loss = 0.19426209339872003
Trained batch 16 in epoch 2, gen_loss = 0.3736682166071499, disc_loss = 0.1933094223632532
Trained batch 17 in epoch 2, gen_loss = 0.37963542507754433, disc_loss = 0.19365479590164292
Trained batch 18 in epoch 2, gen_loss = 0.3774660464964415, disc_loss = 0.19406974119575401
Trained batch 19 in epoch 2, gen_loss = 0.3776561051607132, disc_loss = 0.1924858670681715
Trained batch 20 in epoch 2, gen_loss = 0.3792754752295358, disc_loss = 0.18850955899272645
Trained batch 21 in epoch 2, gen_loss = 0.3833577172322707, disc_loss = 0.18306208435784688
Trained batch 22 in epoch 2, gen_loss = 0.383222714714382, disc_loss = 0.18078160966220108
Trained batch 23 in epoch 2, gen_loss = 0.3829403631389141, disc_loss = 0.17799369525164366
Trained batch 24 in epoch 2, gen_loss = 0.3870818471908569, disc_loss = 0.17520704239606857
Trained batch 25 in epoch 2, gen_loss = 0.3871165089882337, disc_loss = 0.17221963606201685
Trained batch 26 in epoch 2, gen_loss = 0.38797242332387855, disc_loss = 0.1743205396665467
Trained batch 27 in epoch 2, gen_loss = 0.38837782187121256, disc_loss = 0.17056366614997387
Trained batch 28 in epoch 2, gen_loss = 0.38742247121087436, disc_loss = 0.17205954959680295
Trained batch 29 in epoch 2, gen_loss = 0.3864856610695521, disc_loss = 0.17704801683624585
Trained batch 30 in epoch 2, gen_loss = 0.38664050736734945, disc_loss = 0.17851038349251594
Trained batch 31 in epoch 2, gen_loss = 0.38597909454256296, disc_loss = 0.17640411294996738
Trained batch 32 in epoch 2, gen_loss = 0.3855290205189676, disc_loss = 0.17489547124414734
Trained batch 33 in epoch 2, gen_loss = 0.3853539693004945, disc_loss = 0.17219158766024253
Trained batch 34 in epoch 2, gen_loss = 0.3841345267636435, disc_loss = 0.17375697089093073
Trained batch 35 in epoch 2, gen_loss = 0.38405880166424644, disc_loss = 0.1760162870503134
Trained batch 36 in epoch 2, gen_loss = 0.3840366771092286, disc_loss = 0.17411691030940493
Trained batch 37 in epoch 2, gen_loss = 0.38430796249916677, disc_loss = 0.17660636494034215
Trained batch 38 in epoch 2, gen_loss = 0.38391612279109466, disc_loss = 0.17472261305038744
Trained batch 39 in epoch 2, gen_loss = 0.3831435516476631, disc_loss = 0.17426161803305149
Trained batch 40 in epoch 2, gen_loss = 0.38316518359067964, disc_loss = 0.17170103603019948
Trained batch 41 in epoch 2, gen_loss = 0.38297609772000996, disc_loss = 0.17094104577388083
Trained batch 42 in epoch 2, gen_loss = 0.38392157679380373, disc_loss = 0.17037746812715088
Trained batch 43 in epoch 2, gen_loss = 0.38285169208591635, disc_loss = 0.1694952996278351
Trained batch 44 in epoch 2, gen_loss = 0.38274951179822286, disc_loss = 0.17026803410715527
Trained batch 45 in epoch 2, gen_loss = 0.38198363197886426, disc_loss = 0.16974407029540642
Trained batch 46 in epoch 2, gen_loss = 0.38050536272373603, disc_loss = 0.16864354464601963
Trained batch 47 in epoch 2, gen_loss = 0.3803622753669818, disc_loss = 0.16646455647423863
Trained batch 48 in epoch 2, gen_loss = 0.38044311684005117, disc_loss = 0.16453218201593478
Trained batch 49 in epoch 2, gen_loss = 0.38106987953186033, disc_loss = 0.16327310398221015
Trained batch 50 in epoch 2, gen_loss = 0.38013259394496096, disc_loss = 0.16403275625962838
Trained batch 51 in epoch 2, gen_loss = 0.3801181035546156, disc_loss = 0.16441595540023768
Trained batch 52 in epoch 2, gen_loss = 0.37887532081244124, disc_loss = 0.16498299997370197
Trained batch 53 in epoch 2, gen_loss = 0.3788010831232424, disc_loss = 0.16625707858690508
Trained batch 54 in epoch 2, gen_loss = 0.3773154237053611, disc_loss = 0.167118785191666
Trained batch 55 in epoch 2, gen_loss = 0.37770163853253635, disc_loss = 0.16618491602795465
Trained batch 56 in epoch 2, gen_loss = 0.3773761992914635, disc_loss = 0.1650398607578194
Trained batch 57 in epoch 2, gen_loss = 0.3765925287172712, disc_loss = 0.16382504973945947
Trained batch 58 in epoch 2, gen_loss = 0.3762736042677346, disc_loss = 0.1624122147085303
Trained batch 59 in epoch 2, gen_loss = 0.37591475049654643, disc_loss = 0.16259412181874117
Trained batch 60 in epoch 2, gen_loss = 0.3770737535640842, disc_loss = 0.16342380728389397
Trained batch 61 in epoch 2, gen_loss = 0.37577241803369216, disc_loss = 0.16607705419582705
Trained batch 62 in epoch 2, gen_loss = 0.37619783197130474, disc_loss = 0.16511559238036475
Trained batch 63 in epoch 2, gen_loss = 0.377291280310601, disc_loss = 0.16747797501739115
Trained batch 64 in epoch 2, gen_loss = 0.3762237741396977, disc_loss = 0.16829239416580935
Trained batch 65 in epoch 2, gen_loss = 0.37510600144212897, disc_loss = 0.16810318793762813
Trained batch 66 in epoch 2, gen_loss = 0.3760613736821644, disc_loss = 0.16727271231252755
Trained batch 67 in epoch 2, gen_loss = 0.3761630860321662, disc_loss = 0.16599836003254442
Trained batch 68 in epoch 2, gen_loss = 0.3756162243476812, disc_loss = 0.1651852856511655
Trained batch 69 in epoch 2, gen_loss = 0.3759923700775419, disc_loss = 0.16378839824880873
Trained batch 70 in epoch 2, gen_loss = 0.37617022680564666, disc_loss = 0.1627581344104149
Trained batch 71 in epoch 2, gen_loss = 0.3765915023783843, disc_loss = 0.16133865439850423
Trained batch 72 in epoch 2, gen_loss = 0.3765485458178063, disc_loss = 0.1606551997159442
Trained batch 73 in epoch 2, gen_loss = 0.3765274656785501, disc_loss = 0.1594839970505721
Trained batch 74 in epoch 2, gen_loss = 0.3774296728769938, disc_loss = 0.1581001691520214
Trained batch 75 in epoch 2, gen_loss = 0.3785177916288376, disc_loss = 0.16019054546364045
Trained batch 76 in epoch 2, gen_loss = 0.3779599802060561, disc_loss = 0.16019932891834865
Trained batch 77 in epoch 2, gen_loss = 0.37730556115125996, disc_loss = 0.15984658863490972
Trained batch 78 in epoch 2, gen_loss = 0.37789230859732326, disc_loss = 0.16142039816779427
Trained batch 79 in epoch 2, gen_loss = 0.37727287225425243, disc_loss = 0.16094195251353086
Trained batch 80 in epoch 2, gen_loss = 0.37771875586038756, disc_loss = 0.16100403487130446
Trained batch 81 in epoch 2, gen_loss = 0.378475308054831, disc_loss = 0.16301002158079206
Trained batch 82 in epoch 2, gen_loss = 0.3780404135405299, disc_loss = 0.16285479701606623
Trained batch 83 in epoch 2, gen_loss = 0.37812922717559905, disc_loss = 0.16281365944693485
Trained batch 84 in epoch 2, gen_loss = 0.3773330355391783, disc_loss = 0.1630826617426732
Trained batch 85 in epoch 2, gen_loss = 0.3772188030010046, disc_loss = 0.163197441892915
Trained batch 86 in epoch 2, gen_loss = 0.37704052527745563, disc_loss = 0.1631049274456227
Trained batch 87 in epoch 2, gen_loss = 0.37617595730857417, disc_loss = 0.16318507784638892
Trained batch 88 in epoch 2, gen_loss = 0.37704107098365097, disc_loss = 0.16271188976557066
Trained batch 89 in epoch 2, gen_loss = 0.3770388642946879, disc_loss = 0.16258977589507898
Trained batch 90 in epoch 2, gen_loss = 0.3770892783835694, disc_loss = 0.16241853352595162
Trained batch 91 in epoch 2, gen_loss = 0.3772834837436676, disc_loss = 0.1616485487750691
Trained batch 92 in epoch 2, gen_loss = 0.3767371347514532, disc_loss = 0.16183247469285483
Trained batch 93 in epoch 2, gen_loss = 0.3772652310893891, disc_loss = 0.16118489637812403
Trained batch 94 in epoch 2, gen_loss = 0.37688128352165223, disc_loss = 0.16151033455604
Trained batch 95 in epoch 2, gen_loss = 0.3764973043774565, disc_loss = 0.16255507746245712
Trained batch 96 in epoch 2, gen_loss = 0.37668345607433124, disc_loss = 0.16322864027521045
Trained batch 97 in epoch 2, gen_loss = 0.37746666371822357, disc_loss = 0.1623057630673355
Trained batch 98 in epoch 2, gen_loss = 0.3772105026726771, disc_loss = 0.1625757481187883
Trained batch 99 in epoch 2, gen_loss = 0.37770086973905564, disc_loss = 0.16286354709416628
Trained batch 100 in epoch 2, gen_loss = 0.37766887704924784, disc_loss = 0.1620393476937667
Trained batch 101 in epoch 2, gen_loss = 0.37697159455103035, disc_loss = 0.1617337686247101
Trained batch 102 in epoch 2, gen_loss = 0.3776526772281499, disc_loss = 0.16088488860761077
Trained batch 103 in epoch 2, gen_loss = 0.37803260810100114, disc_loss = 0.1606264391269248
Trained batch 104 in epoch 2, gen_loss = 0.3788520103409177, disc_loss = 0.16088321907889275
Trained batch 105 in epoch 2, gen_loss = 0.37881953002146956, disc_loss = 0.16045382868428276
Trained batch 106 in epoch 2, gen_loss = 0.3785161133681502, disc_loss = 0.15974145400050643
Trained batch 107 in epoch 2, gen_loss = 0.3778979565810274, disc_loss = 0.15966399120925753
Trained batch 108 in epoch 2, gen_loss = 0.378211680355422, disc_loss = 0.16107377105759918
Trained batch 109 in epoch 2, gen_loss = 0.3780081350695003, disc_loss = 0.1625685439529744
Trained batch 110 in epoch 2, gen_loss = 0.37845481166968475, disc_loss = 0.16244067812153884
Trained batch 111 in epoch 2, gen_loss = 0.37813714811844484, disc_loss = 0.16212896453881903
Trained batch 112 in epoch 2, gen_loss = 0.3774171790717977, disc_loss = 0.16268577153044464
Trained batch 113 in epoch 2, gen_loss = 0.37798233748527993, disc_loss = 0.16244167295333586
Trained batch 114 in epoch 2, gen_loss = 0.37724606757578644, disc_loss = 0.1619677340530831
Trained batch 115 in epoch 2, gen_loss = 0.37747152869043676, disc_loss = 0.16166952820815916
Trained batch 116 in epoch 2, gen_loss = 0.37745253525228584, disc_loss = 0.1612597254033272
Trained batch 117 in epoch 2, gen_loss = 0.3774717972945359, disc_loss = 0.16079376268563633
Trained batch 118 in epoch 2, gen_loss = 0.37723825083059426, disc_loss = 0.16053777216237133
Trained batch 119 in epoch 2, gen_loss = 0.37749574283758797, disc_loss = 0.160087976573656
Trained batch 120 in epoch 2, gen_loss = 0.37765026067899277, disc_loss = 0.15977608304747865
Trained batch 121 in epoch 2, gen_loss = 0.377823503535302, disc_loss = 0.1595826087611132
Trained batch 122 in epoch 2, gen_loss = 0.37787983936022934, disc_loss = 0.1593837152591081
Trained batch 123 in epoch 2, gen_loss = 0.37835497769617266, disc_loss = 0.15945847689985268
Trained batch 124 in epoch 2, gen_loss = 0.3781112036705017, disc_loss = 0.1589412272274494
Trained batch 125 in epoch 2, gen_loss = 0.37797836273435564, disc_loss = 0.15877375175200759
Trained batch 126 in epoch 2, gen_loss = 0.3778805448783664, disc_loss = 0.15815618713423024
Trained batch 127 in epoch 2, gen_loss = 0.3778399017173797, disc_loss = 0.15757823656895198
Trained batch 128 in epoch 2, gen_loss = 0.378096786118293, disc_loss = 0.15799472790009292
Trained batch 129 in epoch 2, gen_loss = 0.3787169263913081, disc_loss = 0.15745758164960605
Trained batch 130 in epoch 2, gen_loss = 0.3790763716661293, disc_loss = 0.1568511955667543
Trained batch 131 in epoch 2, gen_loss = 0.37891615769176773, disc_loss = 0.15651673482110104
Trained batch 132 in epoch 2, gen_loss = 0.3781623313749643, disc_loss = 0.1566278826641409
Trained batch 133 in epoch 2, gen_loss = 0.37863486071131125, disc_loss = 0.1565294011926918
Trained batch 134 in epoch 2, gen_loss = 0.3788007444805569, disc_loss = 0.15587082756338297
Trained batch 135 in epoch 2, gen_loss = 0.3785388899200103, disc_loss = 0.1555618548163158
Trained batch 136 in epoch 2, gen_loss = 0.3780760123346844, disc_loss = 0.15617596948125068
Trained batch 137 in epoch 2, gen_loss = 0.37742168531901593, disc_loss = 0.15800790961129943
Trained batch 138 in epoch 2, gen_loss = 0.3779308362830457, disc_loss = 0.15776441313272757
Trained batch 139 in epoch 2, gen_loss = 0.37781086798225133, disc_loss = 0.15800130066594908
Trained batch 140 in epoch 2, gen_loss = 0.37776720756334614, disc_loss = 0.1574438859226433
Trained batch 141 in epoch 2, gen_loss = 0.37792093904925067, disc_loss = 0.15713594268850037
Trained batch 142 in epoch 2, gen_loss = 0.37765487382461976, disc_loss = 0.15753866870190714
Trained batch 143 in epoch 2, gen_loss = 0.3779478429092301, disc_loss = 0.15723132101508477
Trained batch 144 in epoch 2, gen_loss = 0.3776969262238207, disc_loss = 0.15673529585373813
Trained batch 145 in epoch 2, gen_loss = 0.37741626554156005, disc_loss = 0.15628558012006216
Trained batch 146 in epoch 2, gen_loss = 0.37745217705259515, disc_loss = 0.15582296558890213
Trained batch 147 in epoch 2, gen_loss = 0.3776051617554716, disc_loss = 0.15546735851849253
Trained batch 148 in epoch 2, gen_loss = 0.37811139725998744, disc_loss = 0.15482518971966416
Trained batch 149 in epoch 2, gen_loss = 0.3783277487754822, disc_loss = 0.15423302367329597
Trained batch 150 in epoch 2, gen_loss = 0.37814300423426345, disc_loss = 0.15509509739299485
Trained batch 151 in epoch 2, gen_loss = 0.37732354394699397, disc_loss = 0.1566319088696649
Trained batch 152 in epoch 2, gen_loss = 0.37735773788558113, disc_loss = 0.15614377317670125
Trained batch 153 in epoch 2, gen_loss = 0.3769128401945164, disc_loss = 0.15575325213275948
Trained batch 154 in epoch 2, gen_loss = 0.3768132298223434, disc_loss = 0.15539360666467297
Trained batch 155 in epoch 2, gen_loss = 0.37721388729719013, disc_loss = 0.15506424516057357
Trained batch 156 in epoch 2, gen_loss = 0.3779432187034826, disc_loss = 0.1550802025635531
Trained batch 157 in epoch 2, gen_loss = 0.3781273536667039, disc_loss = 0.15522571709714358
Trained batch 158 in epoch 2, gen_loss = 0.378419372645564, disc_loss = 0.15481921074525365
Trained batch 159 in epoch 2, gen_loss = 0.3786294344812632, disc_loss = 0.15615301243960858
Trained batch 160 in epoch 2, gen_loss = 0.37901186295177625, disc_loss = 0.15567615142335062
Trained batch 161 in epoch 2, gen_loss = 0.3794857162384339, disc_loss = 0.15571838695509935
Trained batch 162 in epoch 2, gen_loss = 0.37925974978991084, disc_loss = 0.15766161465388864
Trained batch 163 in epoch 2, gen_loss = 0.37901828510732183, disc_loss = 0.1577014068550453
Trained batch 164 in epoch 2, gen_loss = 0.3793911303534652, disc_loss = 0.1575359188697555
Trained batch 165 in epoch 2, gen_loss = 0.37969019380678615, disc_loss = 0.15825875134891773
Trained batch 166 in epoch 2, gen_loss = 0.37972392507655894, disc_loss = 0.1584921796432512
Trained batch 167 in epoch 2, gen_loss = 0.37995232588478495, disc_loss = 0.15819059613914715
Trained batch 168 in epoch 2, gen_loss = 0.37987452057691723, disc_loss = 0.15816821184384047
Trained batch 169 in epoch 2, gen_loss = 0.38049207294688503, disc_loss = 0.15812147364896886
Trained batch 170 in epoch 2, gen_loss = 0.38060961637580604, disc_loss = 0.1574942549984706
Trained batch 171 in epoch 2, gen_loss = 0.3806717551724855, disc_loss = 0.15795661112683457
Trained batch 172 in epoch 2, gen_loss = 0.3806784113363034, disc_loss = 0.15746126382078737
Trained batch 173 in epoch 2, gen_loss = 0.38070173612956343, disc_loss = 0.15720302853519205
Trained batch 174 in epoch 2, gen_loss = 0.38109655686787197, disc_loss = 0.15714277380279132
Trained batch 175 in epoch 2, gen_loss = 0.38083770481700246, disc_loss = 0.15756363356062633
Trained batch 176 in epoch 2, gen_loss = 0.380824207417709, disc_loss = 0.1573236895525186
Trained batch 177 in epoch 2, gen_loss = 0.38120011131415205, disc_loss = 0.1570814819692561
Trained batch 178 in epoch 2, gen_loss = 0.38083171794534393, disc_loss = 0.1571452788509137
Trained batch 179 in epoch 2, gen_loss = 0.38054032888677386, disc_loss = 0.15784744349204832
Trained batch 180 in epoch 2, gen_loss = 0.38040823732291795, disc_loss = 0.15751092298501762
Trained batch 181 in epoch 2, gen_loss = 0.3808935392688919, disc_loss = 0.15713216444211348
Trained batch 182 in epoch 2, gen_loss = 0.3809825564668478, disc_loss = 0.1574017327136355
Trained batch 183 in epoch 2, gen_loss = 0.3812955773395041, disc_loss = 0.1578365478300206
Trained batch 184 in epoch 2, gen_loss = 0.38184269425031303, disc_loss = 0.15782826331418914
Trained batch 185 in epoch 2, gen_loss = 0.3820798802439884, disc_loss = 0.1575035236735818
Trained batch 186 in epoch 2, gen_loss = 0.38246861594246034, disc_loss = 0.15710226775092237
Trained batch 187 in epoch 2, gen_loss = 0.38221730450366403, disc_loss = 0.15696358250731485
Trained batch 188 in epoch 2, gen_loss = 0.38165116546646, disc_loss = 0.15671743221935772
Trained batch 189 in epoch 2, gen_loss = 0.38207734431091106, disc_loss = 0.15616590802214647
Trained batch 190 in epoch 2, gen_loss = 0.3823854707922611, disc_loss = 0.15634374591614564
Trained batch 191 in epoch 2, gen_loss = 0.3824543009201686, disc_loss = 0.1563032068273363
Trained batch 192 in epoch 2, gen_loss = 0.3832266256599229, disc_loss = 0.1560798701034
Trained batch 193 in epoch 2, gen_loss = 0.383359701516702, disc_loss = 0.15565960572014764
Trained batch 194 in epoch 2, gen_loss = 0.3834573032000126, disc_loss = 0.15531734035183223
Trained batch 195 in epoch 2, gen_loss = 0.3838714426573442, disc_loss = 0.15527172574811443
Trained batch 196 in epoch 2, gen_loss = 0.3839884217317939, disc_loss = 0.15586376800981874
Trained batch 197 in epoch 2, gen_loss = 0.38357386745587746, disc_loss = 0.15644559013948897
Trained batch 198 in epoch 2, gen_loss = 0.3831879551985755, disc_loss = 0.15697515645443494
Trained batch 199 in epoch 2, gen_loss = 0.38348951235413553, disc_loss = 0.15686298621818423
Trained batch 200 in epoch 2, gen_loss = 0.3842394534331649, disc_loss = 0.15755085489569018
Trained batch 201 in epoch 2, gen_loss = 0.3843677279972794, disc_loss = 0.15770123941399675
Trained batch 202 in epoch 2, gen_loss = 0.38429528783107625, disc_loss = 0.1577118862548779
Trained batch 203 in epoch 2, gen_loss = 0.384421223664985, disc_loss = 0.157448798253694
Trained batch 204 in epoch 2, gen_loss = 0.38432073549526496, disc_loss = 0.15760785964567486
Trained batch 205 in epoch 2, gen_loss = 0.38416520368705676, disc_loss = 0.15741084101926356
Trained batch 206 in epoch 2, gen_loss = 0.38431551519799345, disc_loss = 0.1574843628646959
Trained batch 207 in epoch 2, gen_loss = 0.38465610476067436, disc_loss = 0.15709951314000556
Trained batch 208 in epoch 2, gen_loss = 0.38442916818783046, disc_loss = 0.1570386765569306
Trained batch 209 in epoch 2, gen_loss = 0.3848838185980206, disc_loss = 0.1570876177045561
Trained batch 210 in epoch 2, gen_loss = 0.38503973899294414, disc_loss = 0.15679282393147595
Trained batch 211 in epoch 2, gen_loss = 0.38516945110739403, disc_loss = 0.1565454100908817
Trained batch 212 in epoch 2, gen_loss = 0.38535556728851067, disc_loss = 0.15629383125845256
Trained batch 213 in epoch 2, gen_loss = 0.38558917360328065, disc_loss = 0.1569624227236643
Trained batch 214 in epoch 2, gen_loss = 0.3858010585917983, disc_loss = 0.1574721505648868
Trained batch 215 in epoch 2, gen_loss = 0.38576382577971174, disc_loss = 0.1570603313372919
Trained batch 216 in epoch 2, gen_loss = 0.3859099251334019, disc_loss = 0.1568027829691287
Trained batch 217 in epoch 2, gen_loss = 0.38534029197255404, disc_loss = 0.15746783624069954
Trained batch 218 in epoch 2, gen_loss = 0.38508544610515577, disc_loss = 0.15747465984257933
Trained batch 219 in epoch 2, gen_loss = 0.38519010692834854, disc_loss = 0.1571633924984119
Trained batch 220 in epoch 2, gen_loss = 0.3853293081484229, disc_loss = 0.1570077050831253
Trained batch 221 in epoch 2, gen_loss = 0.3853691674030579, disc_loss = 0.15714936003693053
Trained batch 222 in epoch 2, gen_loss = 0.3853782637236899, disc_loss = 0.15699008940781714
Trained batch 223 in epoch 2, gen_loss = 0.38537024706602097, disc_loss = 0.1566787721156808
Trained batch 224 in epoch 2, gen_loss = 0.38555745482444764, disc_loss = 0.15627146301998032
Trained batch 225 in epoch 2, gen_loss = 0.38547348435473655, disc_loss = 0.1558942038697743
Trained batch 226 in epoch 2, gen_loss = 0.38541881549725976, disc_loss = 0.1555379962113723
Trained batch 227 in epoch 2, gen_loss = 0.38533755352622584, disc_loss = 0.15570874343903965
Trained batch 228 in epoch 2, gen_loss = 0.38505261329584245, disc_loss = 0.157006379965221
Trained batch 229 in epoch 2, gen_loss = 0.3850921268048494, disc_loss = 0.15686994306743146
Trained batch 230 in epoch 2, gen_loss = 0.3855222402971028, disc_loss = 0.15653125382153502
Trained batch 231 in epoch 2, gen_loss = 0.3855537047673916, disc_loss = 0.15667425097640733
Trained batch 232 in epoch 2, gen_loss = 0.38543771264890747, disc_loss = 0.15638504597826067
Trained batch 233 in epoch 2, gen_loss = 0.38534470806773913, disc_loss = 0.15625337856765995
Trained batch 234 in epoch 2, gen_loss = 0.385695872915552, disc_loss = 0.1560098872381322
Trained batch 235 in epoch 2, gen_loss = 0.38579638744309797, disc_loss = 0.15569926058021138
Trained batch 236 in epoch 2, gen_loss = 0.38567652518739176, disc_loss = 0.15537924783202164
Trained batch 237 in epoch 2, gen_loss = 0.38539489076918915, disc_loss = 0.15513156309035145
Trained batch 238 in epoch 2, gen_loss = 0.38545079523050635, disc_loss = 0.15519536799404413
Trained batch 239 in epoch 2, gen_loss = 0.385522319500645, disc_loss = 0.15508806337602438
Trained batch 240 in epoch 2, gen_loss = 0.38579765147687983, disc_loss = 0.15465895625998372
Trained batch 241 in epoch 2, gen_loss = 0.3856986557895487, disc_loss = 0.15512670341047866
Trained batch 242 in epoch 2, gen_loss = 0.3857573982128881, disc_loss = 0.15509103243181735
Trained batch 243 in epoch 2, gen_loss = 0.38566408196433644, disc_loss = 0.1548343882972344
Trained batch 244 in epoch 2, gen_loss = 0.3855237622650302, disc_loss = 0.15498841424681703
Trained batch 245 in epoch 2, gen_loss = 0.38562963067031486, disc_loss = 0.15537277289582946
Trained batch 246 in epoch 2, gen_loss = 0.3857711195221797, disc_loss = 0.1552966315646162
Trained batch 247 in epoch 2, gen_loss = 0.3854101232943996, disc_loss = 0.1552484707396117
Trained batch 248 in epoch 2, gen_loss = 0.38526762537209386, disc_loss = 0.15529700540694366
Trained batch 249 in epoch 2, gen_loss = 0.3853532919883728, disc_loss = 0.15538681478798388
Trained batch 250 in epoch 2, gen_loss = 0.38572718114017013, disc_loss = 0.15529345321762134
Trained batch 251 in epoch 2, gen_loss = 0.3857330029445981, disc_loss = 0.1551294153674491
Trained batch 252 in epoch 2, gen_loss = 0.38587465246204333, disc_loss = 0.15478542657650035
Trained batch 253 in epoch 2, gen_loss = 0.386152791460668, disc_loss = 0.15442602232274577
Trained batch 254 in epoch 2, gen_loss = 0.3862157961901496, disc_loss = 0.1539795428076211
Trained batch 255 in epoch 2, gen_loss = 0.38627299503423274, disc_loss = 0.15388439282833133
Trained batch 256 in epoch 2, gen_loss = 0.38656468498103813, disc_loss = 0.15411903684531206
Trained batch 257 in epoch 2, gen_loss = 0.3864405487858972, disc_loss = 0.15377498777626558
Trained batch 258 in epoch 2, gen_loss = 0.3864607408240035, disc_loss = 0.15406901025461414
Trained batch 259 in epoch 2, gen_loss = 0.38640619825858336, disc_loss = 0.15447162608974255
Trained batch 260 in epoch 2, gen_loss = 0.3865207289827281, disc_loss = 0.1543076771286484
Trained batch 261 in epoch 2, gen_loss = 0.38660764933087444, disc_loss = 0.1540809545722854
Trained batch 262 in epoch 2, gen_loss = 0.38671512748805287, disc_loss = 0.15407524409459572
Trained batch 263 in epoch 2, gen_loss = 0.3863217312503945, disc_loss = 0.15410091040768858
Trained batch 264 in epoch 2, gen_loss = 0.3861122289918504, disc_loss = 0.15412883501289026
Trained batch 265 in epoch 2, gen_loss = 0.38660609397224915, disc_loss = 0.1544061783365065
Trained batch 266 in epoch 2, gen_loss = 0.38650275169686876, disc_loss = 0.15432217590203892
Trained batch 267 in epoch 2, gen_loss = 0.3866110905560095, disc_loss = 0.1541366477205015
Trained batch 268 in epoch 2, gen_loss = 0.38653579819601264, disc_loss = 0.15399931247958906
Trained batch 269 in epoch 2, gen_loss = 0.3862010466831702, disc_loss = 0.15399722190642798
Trained batch 270 in epoch 2, gen_loss = 0.38596821568109013, disc_loss = 0.15390405079480468
Trained batch 271 in epoch 2, gen_loss = 0.386159710586071, disc_loss = 0.15353368518545346
Trained batch 272 in epoch 2, gen_loss = 0.3864011063680544, disc_loss = 0.1531226505344604
Trained batch 273 in epoch 2, gen_loss = 0.386609732778403, disc_loss = 0.1529141224268144
Trained batch 274 in epoch 2, gen_loss = 0.3869551321593198, disc_loss = 0.1529542691328309
Trained batch 275 in epoch 2, gen_loss = 0.3867804924215096, disc_loss = 0.15263069288778133
Trained batch 276 in epoch 2, gen_loss = 0.38701289999786265, disc_loss = 0.1528078756876801
Trained batch 277 in epoch 2, gen_loss = 0.38684331663220906, disc_loss = 0.15376408936844455
Trained batch 278 in epoch 2, gen_loss = 0.38705308153210577, disc_loss = 0.15396547838244387
Trained batch 279 in epoch 2, gen_loss = 0.38680543516363414, disc_loss = 0.15428086931684187
Trained batch 280 in epoch 2, gen_loss = 0.3869037675899967, disc_loss = 0.15404605337839533
Trained batch 281 in epoch 2, gen_loss = 0.38709490550748, disc_loss = 0.15390600845323388
Trained batch 282 in epoch 2, gen_loss = 0.3870215449653329, disc_loss = 0.1541437723611353
Trained batch 283 in epoch 2, gen_loss = 0.3872062237539762, disc_loss = 0.153902580122083
Trained batch 284 in epoch 2, gen_loss = 0.3871897411973853, disc_loss = 0.15375821112017882
Trained batch 285 in epoch 2, gen_loss = 0.387318919380228, disc_loss = 0.1537369744708905
Trained batch 286 in epoch 2, gen_loss = 0.38745541844633813, disc_loss = 0.15363037510927546
Trained batch 287 in epoch 2, gen_loss = 0.3871610028048356, disc_loss = 0.15336719002678162
Trained batch 288 in epoch 2, gen_loss = 0.38706557932197017, disc_loss = 0.15299416378552938
Trained batch 289 in epoch 2, gen_loss = 0.38729338491785115, disc_loss = 0.1526857636483579
Trained batch 290 in epoch 2, gen_loss = 0.3875358415018652, disc_loss = 0.15278911430555112
Trained batch 291 in epoch 2, gen_loss = 0.3872258115100534, disc_loss = 0.15259532598548964
Trained batch 292 in epoch 2, gen_loss = 0.3873668768706989, disc_loss = 0.1521874739829794
Trained batch 293 in epoch 2, gen_loss = 0.38735719177187705, disc_loss = 0.15201716372097024
Trained batch 294 in epoch 2, gen_loss = 0.387594063807342, disc_loss = 0.15238008806008405
Trained batch 295 in epoch 2, gen_loss = 0.38751690160181074, disc_loss = 0.1521888880084294
Trained batch 296 in epoch 2, gen_loss = 0.38759774812544234, disc_loss = 0.15227255901252781
Trained batch 297 in epoch 2, gen_loss = 0.3877339115078817, disc_loss = 0.15208231511482057
Trained batch 298 in epoch 2, gen_loss = 0.3876083698559764, disc_loss = 0.15186099769130199
Trained batch 299 in epoch 2, gen_loss = 0.3874162178238233, disc_loss = 0.15182600673288107
Trained batch 300 in epoch 2, gen_loss = 0.3872180552379634, disc_loss = 0.15190002783835924
Trained batch 301 in epoch 2, gen_loss = 0.38683398186371026, disc_loss = 0.1519279587668496
Trained batch 302 in epoch 2, gen_loss = 0.3865960653465573, disc_loss = 0.15183445018264327
Trained batch 303 in epoch 2, gen_loss = 0.38638332182247387, disc_loss = 0.15177514961626576
Trained batch 304 in epoch 2, gen_loss = 0.38641699552536013, disc_loss = 0.15188006923579778
Trained batch 305 in epoch 2, gen_loss = 0.3864733491068572, disc_loss = 0.15198395385413
Trained batch 306 in epoch 2, gen_loss = 0.38634757789804414, disc_loss = 0.15266737107685024
Trained batch 307 in epoch 2, gen_loss = 0.386508830181964, disc_loss = 0.15254601186697747
Trained batch 308 in epoch 2, gen_loss = 0.3866520171991058, disc_loss = 0.1525674983979622
Trained batch 309 in epoch 2, gen_loss = 0.3866831218042681, disc_loss = 0.1524103394559314
Trained batch 310 in epoch 2, gen_loss = 0.38704786174167005, disc_loss = 0.15229854985496621
Trained batch 311 in epoch 2, gen_loss = 0.38716148432248676, disc_loss = 0.15248217105340117
Trained batch 312 in epoch 2, gen_loss = 0.38748352615216286, disc_loss = 0.153027592530361
Trained batch 313 in epoch 2, gen_loss = 0.38730190381123003, disc_loss = 0.15324201151301528
Trained batch 314 in epoch 2, gen_loss = 0.3874550719109793, disc_loss = 0.15314040189934156
Trained batch 315 in epoch 2, gen_loss = 0.3875452476211741, disc_loss = 0.15294863706855458
Trained batch 316 in epoch 2, gen_loss = 0.3875934410170426, disc_loss = 0.15291184242168435
Trained batch 317 in epoch 2, gen_loss = 0.38738844651471144, disc_loss = 0.153049263271427
Trained batch 318 in epoch 2, gen_loss = 0.3876354497241376, disc_loss = 0.15284423879274753
Trained batch 319 in epoch 2, gen_loss = 0.3877144455909729, disc_loss = 0.15323515449417754
Trained batch 320 in epoch 2, gen_loss = 0.3876650063233955, disc_loss = 0.15358107556760126
Trained batch 321 in epoch 2, gen_loss = 0.3878173805912089, disc_loss = 0.1534098289930117
Trained batch 322 in epoch 2, gen_loss = 0.3879162532626291, disc_loss = 0.15338574584008371
Trained batch 323 in epoch 2, gen_loss = 0.3879626982006026, disc_loss = 0.1532164639505891
Trained batch 324 in epoch 2, gen_loss = 0.3876772763178899, disc_loss = 0.15319199895629515
Trained batch 325 in epoch 2, gen_loss = 0.38767282180259566, disc_loss = 0.1532904203935452
Trained batch 326 in epoch 2, gen_loss = 0.38755227684610116, disc_loss = 0.15336214105060342
Trained batch 327 in epoch 2, gen_loss = 0.38725769601580573, disc_loss = 0.15337716355329242
Trained batch 328 in epoch 2, gen_loss = 0.3876261782682413, disc_loss = 0.15321234069017292
Trained batch 329 in epoch 2, gen_loss = 0.38739644171613635, disc_loss = 0.15324391949583183
Trained batch 330 in epoch 2, gen_loss = 0.3875090229547276, disc_loss = 0.15308587285732214
Trained batch 331 in epoch 2, gen_loss = 0.38751327165638105, disc_loss = 0.15290647533060198
Trained batch 332 in epoch 2, gen_loss = 0.3875728411538465, disc_loss = 0.1534123432685484
Trained batch 333 in epoch 2, gen_loss = 0.3877629184437369, disc_loss = 0.15320359624386903
Trained batch 334 in epoch 2, gen_loss = 0.3880049246460644, disc_loss = 0.15318891871998558
Trained batch 335 in epoch 2, gen_loss = 0.3878024524698655, disc_loss = 0.15306559461168945
Trained batch 336 in epoch 2, gen_loss = 0.3879468701890385, disc_loss = 0.15317481878912767
Trained batch 337 in epoch 2, gen_loss = 0.38772686284322005, disc_loss = 0.15318820068954364
Trained batch 338 in epoch 2, gen_loss = 0.3877733876395718, disc_loss = 0.1528901939217144
Trained batch 339 in epoch 2, gen_loss = 0.3881001213017632, disc_loss = 0.15290560732212136
Trained batch 340 in epoch 2, gen_loss = 0.38809383675849335, disc_loss = 0.15269723035329597
Trained batch 341 in epoch 2, gen_loss = 0.38805236924461456, disc_loss = 0.15251686235573905
Trained batch 342 in epoch 2, gen_loss = 0.38801229504037527, disc_loss = 0.15221657745170872
Trained batch 343 in epoch 2, gen_loss = 0.3877390142270299, disc_loss = 0.1521300136999682
Trained batch 344 in epoch 2, gen_loss = 0.3877158904421157, disc_loss = 0.15205089706873548
Trained batch 345 in epoch 2, gen_loss = 0.3878146869081982, disc_loss = 0.15188269183642603
Trained batch 346 in epoch 2, gen_loss = 0.38796980846512213, disc_loss = 0.15177627343695171
Trained batch 347 in epoch 2, gen_loss = 0.387978155893841, disc_loss = 0.15195197956743597
Trained batch 348 in epoch 2, gen_loss = 0.38795165610859933, disc_loss = 0.151821047345171
Trained batch 349 in epoch 2, gen_loss = 0.3882040993656431, disc_loss = 0.15154560693672725
Trained batch 350 in epoch 2, gen_loss = 0.38837302546215874, disc_loss = 0.1512947179313399
Trained batch 351 in epoch 2, gen_loss = 0.38839164681055327, disc_loss = 0.15106315510770815
Trained batch 352 in epoch 2, gen_loss = 0.38852354048331805, disc_loss = 0.15072345889830388
Trained batch 353 in epoch 2, gen_loss = 0.3884849676304618, disc_loss = 0.15034079177589235
Trained batch 354 in epoch 2, gen_loss = 0.38861693211004766, disc_loss = 0.15016516290185317
Trained batch 355 in epoch 2, gen_loss = 0.3885647122109874, disc_loss = 0.1503307555927738
Trained batch 356 in epoch 2, gen_loss = 0.3885714468501863, disc_loss = 0.15072735520575395
Trained batch 357 in epoch 2, gen_loss = 0.3883527821169219, disc_loss = 0.1507389149862711
Trained batch 358 in epoch 2, gen_loss = 0.3884602585044744, disc_loss = 0.1506453028472768
Trained batch 359 in epoch 2, gen_loss = 0.38819728998674286, disc_loss = 0.15065925757193732
Trained batch 360 in epoch 2, gen_loss = 0.3880209081555998, disc_loss = 0.15056533238997585
Trained batch 361 in epoch 2, gen_loss = 0.3881101175237097, disc_loss = 0.15026091941174388
Trained batch 362 in epoch 2, gen_loss = 0.3882363345012192, disc_loss = 0.1501101030924514
Trained batch 363 in epoch 2, gen_loss = 0.3881338948568145, disc_loss = 0.14995837052465305
Trained batch 364 in epoch 2, gen_loss = 0.3880973744882296, disc_loss = 0.14979923118977514
Trained batch 365 in epoch 2, gen_loss = 0.3882792716632124, disc_loss = 0.14964956906751367
Trained batch 366 in epoch 2, gen_loss = 0.38819404169714095, disc_loss = 0.14952265613836715
Trained batch 367 in epoch 2, gen_loss = 0.3884834054371585, disc_loss = 0.14961148983211783
Trained batch 368 in epoch 2, gen_loss = 0.38854001821864265, disc_loss = 0.14961188165900022
Trained batch 369 in epoch 2, gen_loss = 0.388623101969023, disc_loss = 0.14938135665111446
Trained batch 370 in epoch 2, gen_loss = 0.38868117412788206, disc_loss = 0.14949199828919213
Trained batch 371 in epoch 2, gen_loss = 0.38842076655998026, disc_loss = 0.14956538177405795
Trained batch 372 in epoch 2, gen_loss = 0.38862140400799605, disc_loss = 0.14934436755689315
Trained batch 373 in epoch 2, gen_loss = 0.38864181258461694, disc_loss = 0.14930380719967865
Trained batch 374 in epoch 2, gen_loss = 0.38862401445706685, disc_loss = 0.14936470419665177
Trained batch 375 in epoch 2, gen_loss = 0.38873343748298095, disc_loss = 0.14960425409012812
Trained batch 376 in epoch 2, gen_loss = 0.3886947400215766, disc_loss = 0.14978485143884265
Trained batch 377 in epoch 2, gen_loss = 0.3888948868033747, disc_loss = 0.149632782123431
Trained batch 378 in epoch 2, gen_loss = 0.38885978847191643, disc_loss = 0.14942277765938505
Trained batch 379 in epoch 2, gen_loss = 0.3891210366236536, disc_loss = 0.1491922157032317
Trained batch 380 in epoch 2, gen_loss = 0.3891797090765685, disc_loss = 0.14894666169278734
Trained batch 381 in epoch 2, gen_loss = 0.38901953024701924, disc_loss = 0.14904965468589704
Trained batch 382 in epoch 2, gen_loss = 0.38901527471081704, disc_loss = 0.14896088039536545
Trained batch 383 in epoch 2, gen_loss = 0.38912414487761754, disc_loss = 0.1486751440631148
Trained batch 384 in epoch 2, gen_loss = 0.3889783839900772, disc_loss = 0.1488759090325662
Trained batch 385 in epoch 2, gen_loss = 0.3888127845494858, disc_loss = 0.14876324296904814
Trained batch 386 in epoch 2, gen_loss = 0.3888786804768466, disc_loss = 0.14873981848840412
Trained batch 387 in epoch 2, gen_loss = 0.3888762905118392, disc_loss = 0.14872991289348178
Trained batch 388 in epoch 2, gen_loss = 0.3887546988716469, disc_loss = 0.14856836432950202
Trained batch 389 in epoch 2, gen_loss = 0.38894835443068776, disc_loss = 0.14829925800649785
Trained batch 390 in epoch 2, gen_loss = 0.3888731023387226, disc_loss = 0.14834021010419443
Trained batch 391 in epoch 2, gen_loss = 0.38865272335860196, disc_loss = 0.14878226768662584
Trained batch 392 in epoch 2, gen_loss = 0.3883532370623135, disc_loss = 0.14873394064377737
Trained batch 393 in epoch 2, gen_loss = 0.38861100035270457, disc_loss = 0.1487427051817327
Trained batch 394 in epoch 2, gen_loss = 0.3885189807113213, disc_loss = 0.1485819297453648
Trained batch 395 in epoch 2, gen_loss = 0.38839829464753467, disc_loss = 0.14835363055927434
Trained batch 396 in epoch 2, gen_loss = 0.3886061977379268, disc_loss = 0.14830436594596588
Trained batch 397 in epoch 2, gen_loss = 0.38851800987768415, disc_loss = 0.14812500253974942
Trained batch 398 in epoch 2, gen_loss = 0.3885480279014224, disc_loss = 0.14822754969255517
Trained batch 399 in epoch 2, gen_loss = 0.3886420848965645, disc_loss = 0.1482745211897418
Trained batch 400 in epoch 2, gen_loss = 0.38869095510080864, disc_loss = 0.14812415921387084
Trained batch 401 in epoch 2, gen_loss = 0.3886072327989844, disc_loss = 0.14806958811997034
Trained batch 402 in epoch 2, gen_loss = 0.38858227864388495, disc_loss = 0.147882990534452
Trained batch 403 in epoch 2, gen_loss = 0.38857449517391696, disc_loss = 0.14775551215164584
Trained batch 404 in epoch 2, gen_loss = 0.38881582529456526, disc_loss = 0.147666095762893
Trained batch 405 in epoch 2, gen_loss = 0.3889537339874089, disc_loss = 0.14740807489202967
Trained batch 406 in epoch 2, gen_loss = 0.38907890303714854, disc_loss = 0.14719835012986415
Trained batch 407 in epoch 2, gen_loss = 0.3892292588510934, disc_loss = 0.14694460831564285
Trained batch 408 in epoch 2, gen_loss = 0.3893674144972216, disc_loss = 0.14672932105735492
Trained batch 409 in epoch 2, gen_loss = 0.3892206990137333, disc_loss = 0.14679778018830025
Trained batch 410 in epoch 2, gen_loss = 0.38937026436311484, disc_loss = 0.14681309799226386
Trained batch 411 in epoch 2, gen_loss = 0.38937790359108193, disc_loss = 0.146664130804355
Trained batch 412 in epoch 2, gen_loss = 0.38935489321159106, disc_loss = 0.14648758652946994
Trained batch 413 in epoch 2, gen_loss = 0.38940313062518117, disc_loss = 0.1462058000365533
Trained batch 414 in epoch 2, gen_loss = 0.38929193594369543, disc_loss = 0.14595418689570513
Trained batch 415 in epoch 2, gen_loss = 0.3892665926653605, disc_loss = 0.14566874578863812
Trained batch 416 in epoch 2, gen_loss = 0.3895500486703228, disc_loss = 0.14537236036406717
Trained batch 417 in epoch 2, gen_loss = 0.38960755284893456, disc_loss = 0.1451043923826594
Trained batch 418 in epoch 2, gen_loss = 0.3896396086153381, disc_loss = 0.1448227759263965
Trained batch 419 in epoch 2, gen_loss = 0.38960589383329663, disc_loss = 0.14451820469417032
Trained batch 420 in epoch 2, gen_loss = 0.3896368242924117, disc_loss = 0.14435630739885527
Trained batch 421 in epoch 2, gen_loss = 0.38950738678046315, disc_loss = 0.1446031220477975
Trained batch 422 in epoch 2, gen_loss = 0.3896803816441385, disc_loss = 0.14456429856060948
Trained batch 423 in epoch 2, gen_loss = 0.3897942249083294, disc_loss = 0.14441348786711833
Trained batch 424 in epoch 2, gen_loss = 0.3895029767120586, disc_loss = 0.14491591676631393
Trained batch 425 in epoch 2, gen_loss = 0.3893880735680531, disc_loss = 0.1447146034322924
Trained batch 426 in epoch 2, gen_loss = 0.38938116824878183, disc_loss = 0.14466007110996465
Trained batch 427 in epoch 2, gen_loss = 0.3893856047609142, disc_loss = 0.1444891345965737
Trained batch 428 in epoch 2, gen_loss = 0.3894197015495567, disc_loss = 0.1442491351507413
Trained batch 429 in epoch 2, gen_loss = 0.3895704579214717, disc_loss = 0.14397615009788858
Trained batch 430 in epoch 2, gen_loss = 0.3896517518501547, disc_loss = 0.14375818524241724
Trained batch 431 in epoch 2, gen_loss = 0.38965345056796513, disc_loss = 0.1435181706264201
Trained batch 432 in epoch 2, gen_loss = 0.38973534960669676, disc_loss = 0.14331250937169474
Trained batch 433 in epoch 2, gen_loss = 0.3898778138896837, disc_loss = 0.14321937309020125
Trained batch 434 in epoch 2, gen_loss = 0.38990483297698797, disc_loss = 0.14304721461630415
Trained batch 435 in epoch 2, gen_loss = 0.38998731348766097, disc_loss = 0.14286625752686907
Trained batch 436 in epoch 2, gen_loss = 0.3898293980199085, disc_loss = 0.14275279690594642
Trained batch 437 in epoch 2, gen_loss = 0.38976424646704166, disc_loss = 0.14270261777182147
Trained batch 438 in epoch 2, gen_loss = 0.3895682401293231, disc_loss = 0.14250994598437822
Trained batch 439 in epoch 2, gen_loss = 0.38936721113595096, disc_loss = 0.14239573719995943
Trained batch 440 in epoch 2, gen_loss = 0.38948561964121536, disc_loss = 0.14212929312131303
Trained batch 441 in epoch 2, gen_loss = 0.3896544241257922, disc_loss = 0.1418437084933212
Trained batch 442 in epoch 2, gen_loss = 0.38984084169697814, disc_loss = 0.14161954193668225
Trained batch 443 in epoch 2, gen_loss = 0.38999969116202343, disc_loss = 0.14146519758579162
Trained batch 444 in epoch 2, gen_loss = 0.3898955773101764, disc_loss = 0.1413058003766483
Trained batch 445 in epoch 2, gen_loss = 0.3898591169327364, disc_loss = 0.1410951403391468
Trained batch 446 in epoch 2, gen_loss = 0.3900172677749489, disc_loss = 0.14103113071497123
Trained batch 447 in epoch 2, gen_loss = 0.39008233290431754, disc_loss = 0.14087695149438723
Trained batch 448 in epoch 2, gen_loss = 0.38990579369604456, disc_loss = 0.14064281078715102
Trained batch 449 in epoch 2, gen_loss = 0.3899998648299111, disc_loss = 0.14037278163350292
Trained batch 450 in epoch 2, gen_loss = 0.39007431618918864, disc_loss = 0.14014165013813787
Trained batch 451 in epoch 2, gen_loss = 0.39011368933504664, disc_loss = 0.14008541848197315
Trained batch 452 in epoch 2, gen_loss = 0.38995736988701307, disc_loss = 0.14046305721876506
Trained batch 453 in epoch 2, gen_loss = 0.3899837169746995, disc_loss = 0.1402306100763873
Trained batch 454 in epoch 2, gen_loss = 0.39057238475307005, disc_loss = 0.14031953608187345
Trained batch 455 in epoch 2, gen_loss = 0.3907132340889228, disc_loss = 0.14017283736335995
Trained batch 456 in epoch 2, gen_loss = 0.3907884909757117, disc_loss = 0.13993265708863606
Trained batch 457 in epoch 2, gen_loss = 0.39095086607610297, disc_loss = 0.1397111746340209
Trained batch 458 in epoch 2, gen_loss = 0.3911575101689316, disc_loss = 0.13947217851828517
Trained batch 459 in epoch 2, gen_loss = 0.3912901344506637, disc_loss = 0.13926840723775652
Trained batch 460 in epoch 2, gen_loss = 0.3910714905717109, disc_loss = 0.1393311554586228
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 0.45427632331848145, disc_loss = 0.07418537139892578
Trained batch 1 in epoch 3, gen_loss = 0.4571971148252487, disc_loss = 0.04531665798276663
Trained batch 2 in epoch 3, gen_loss = 0.4306179980436961, disc_loss = 0.052587744469443955
Trained batch 3 in epoch 3, gen_loss = 0.4217461347579956, disc_loss = 0.04572182660922408
Trained batch 4 in epoch 3, gen_loss = 0.4192744195461273, disc_loss = 0.04978843294084072
Trained batch 5 in epoch 3, gen_loss = 0.43029435475667316, disc_loss = 0.04425832908600569
Trained batch 6 in epoch 3, gen_loss = 0.4255849463599069, disc_loss = 0.06422346218356065
Trained batch 7 in epoch 3, gen_loss = 0.4189281761646271, disc_loss = 0.07850467064417899
Trained batch 8 in epoch 3, gen_loss = 0.41265692313512164, disc_loss = 0.07293838262557983
Trained batch 9 in epoch 3, gen_loss = 0.41749622821807864, disc_loss = 0.07485687434673309
Trained batch 10 in epoch 3, gen_loss = 0.4181427738883279, disc_loss = 0.07116472754966129
Trained batch 11 in epoch 3, gen_loss = 0.414482019841671, disc_loss = 0.06870043774445851
Trained batch 12 in epoch 3, gen_loss = 0.4147060513496399, disc_loss = 0.06478940566571859
Trained batch 13 in epoch 3, gen_loss = 0.4197160324880055, disc_loss = 0.061351604626647065
Trained batch 14 in epoch 3, gen_loss = 0.42196035782496133, disc_loss = 0.05947597237924735
Trained batch 15 in epoch 3, gen_loss = 0.4210119843482971, disc_loss = 0.05759035178925842
Trained batch 16 in epoch 3, gen_loss = 0.421559857971528, disc_loss = 0.05723101086914539
Trained batch 17 in epoch 3, gen_loss = 0.41981811159186894, disc_loss = 0.06134214345365763
Trained batch 18 in epoch 3, gen_loss = 0.42162832931468364, disc_loss = 0.07396783493459225
Trained batch 19 in epoch 3, gen_loss = 0.420294477045536, disc_loss = 0.07188124330714345
Trained batch 20 in epoch 3, gen_loss = 0.4190278422264826, disc_loss = 0.08061677900453408
Trained batch 21 in epoch 3, gen_loss = 0.4210457287051461, disc_loss = 0.0801783838224682
Trained batch 22 in epoch 3, gen_loss = 0.4242810775404391, disc_loss = 0.08514851955292017
Trained batch 23 in epoch 3, gen_loss = 0.4252306992808978, disc_loss = 0.0934326658801486
Trained batch 24 in epoch 3, gen_loss = 0.4240740239620209, disc_loss = 0.09227057255804538
Trained batch 25 in epoch 3, gen_loss = 0.42442305156817806, disc_loss = 0.0933938376748791
Trained batch 26 in epoch 3, gen_loss = 0.4241167582847454, disc_loss = 0.09114910337935996
Trained batch 27 in epoch 3, gen_loss = 0.42061302065849304, disc_loss = 0.08944329732496824
Trained batch 28 in epoch 3, gen_loss = 0.41880484901625536, disc_loss = 0.08732619855938287
Trained batch 29 in epoch 3, gen_loss = 0.4211146871248881, disc_loss = 0.0855924998720487
Trained batch 30 in epoch 3, gen_loss = 0.4216548002535297, disc_loss = 0.08359004046407438
Trained batch 31 in epoch 3, gen_loss = 0.4194613555446267, disc_loss = 0.08234808495035395
Trained batch 32 in epoch 3, gen_loss = 0.42056062727263477, disc_loss = 0.08271048234944994
Trained batch 33 in epoch 3, gen_loss = 0.42021308050436135, disc_loss = 0.08135706640999107
Trained batch 34 in epoch 3, gen_loss = 0.42059067147118706, disc_loss = 0.08058443511171
Trained batch 35 in epoch 3, gen_loss = 0.42140140136082965, disc_loss = 0.07922232311425938
Trained batch 36 in epoch 3, gen_loss = 0.4226171253500758, disc_loss = 0.07778525287033738
Trained batch 37 in epoch 3, gen_loss = 0.42284143833737625, disc_loss = 0.07747376842522308
Trained batch 38 in epoch 3, gen_loss = 0.4245981306601793, disc_loss = 0.07604225853887889
Trained batch 39 in epoch 3, gen_loss = 0.4256064064800739, disc_loss = 0.07607802129350602
Trained batch 40 in epoch 3, gen_loss = 0.4263536624792146, disc_loss = 0.07782013437188254
Trained batch 41 in epoch 3, gen_loss = 0.4242840338320959, disc_loss = 0.07693983521312475
Trained batch 42 in epoch 3, gen_loss = 0.42456533049428186, disc_loss = 0.0756238411765459
Trained batch 43 in epoch 3, gen_loss = 0.4252642806280743, disc_loss = 0.07428531107408079
Trained batch 44 in epoch 3, gen_loss = 0.4255713290638394, disc_loss = 0.07323233671486377
Trained batch 45 in epoch 3, gen_loss = 0.4248982609614082, disc_loss = 0.0719443041547809
Trained batch 46 in epoch 3, gen_loss = 0.4247977289747685, disc_loss = 0.07116616289428573
Trained batch 47 in epoch 3, gen_loss = 0.4247295930981636, disc_loss = 0.07015504142812763
Trained batch 48 in epoch 3, gen_loss = 0.4252407885327631, disc_loss = 0.07081816708479001
Trained batch 49 in epoch 3, gen_loss = 0.42374814689159396, disc_loss = 0.07513344062492251
Trained batch 50 in epoch 3, gen_loss = 0.42450687639853535, disc_loss = 0.07812735597219538
Trained batch 51 in epoch 3, gen_loss = 0.4239610427847275, disc_loss = 0.07739331800705539
Trained batch 52 in epoch 3, gen_loss = 0.42420938723492174, disc_loss = 0.0768748454152132
Trained batch 53 in epoch 3, gen_loss = 0.4248344782325957, disc_loss = 0.07640719715574826
Trained batch 54 in epoch 3, gen_loss = 0.42468139258298004, disc_loss = 0.0753773700276559
Trained batch 55 in epoch 3, gen_loss = 0.4247412628361157, disc_loss = 0.07445634583876069
Trained batch 56 in epoch 3, gen_loss = 0.42337842050351593, disc_loss = 0.0735591120789187
Trained batch 57 in epoch 3, gen_loss = 0.42545695654277144, disc_loss = 0.073443577994175
Trained batch 58 in epoch 3, gen_loss = 0.4254764783180366, disc_loss = 0.07472922894472288
Trained batch 59 in epoch 3, gen_loss = 0.42535416732231773, disc_loss = 0.07401480105084678
Trained batch 60 in epoch 3, gen_loss = 0.4237993242310696, disc_loss = 0.07369699923046788
Trained batch 61 in epoch 3, gen_loss = 0.42291832595102247, disc_loss = 0.07313546305522323
Trained batch 62 in epoch 3, gen_loss = 0.42369371841824244, disc_loss = 0.07227757385384942
Trained batch 63 in epoch 3, gen_loss = 0.42263853596523404, disc_loss = 0.07142476977605838
Trained batch 64 in epoch 3, gen_loss = 0.42279137693918667, disc_loss = 0.07171509250138815
Trained batch 65 in epoch 3, gen_loss = 0.4209259048555837, disc_loss = 0.072324348289068
Trained batch 66 in epoch 3, gen_loss = 0.42182512158778174, disc_loss = 0.07198582429772438
Trained batch 67 in epoch 3, gen_loss = 0.42223745891276526, disc_loss = 0.0711596246178755
Trained batch 68 in epoch 3, gen_loss = 0.4220742362996806, disc_loss = 0.07050302032165337
Trained batch 69 in epoch 3, gen_loss = 0.42194018661975863, disc_loss = 0.07060812159574457
Trained batch 70 in epoch 3, gen_loss = 0.42228417119509737, disc_loss = 0.0713675248921967
Trained batch 71 in epoch 3, gen_loss = 0.4224371802475717, disc_loss = 0.07053721640517728
Trained batch 72 in epoch 3, gen_loss = 0.4209793712178322, disc_loss = 0.0701371727970569
Trained batch 73 in epoch 3, gen_loss = 0.4226722954898267, disc_loss = 0.06978470113480816
Trained batch 74 in epoch 3, gen_loss = 0.42242484966913857, disc_loss = 0.0693906057998538
Trained batch 75 in epoch 3, gen_loss = 0.42123859493356003, disc_loss = 0.06903150188736618
Trained batch 76 in epoch 3, gen_loss = 0.4215211407704787, disc_loss = 0.06842164043337107
Trained batch 77 in epoch 3, gen_loss = 0.42077392492538845, disc_loss = 0.06794698886238994
Trained batch 78 in epoch 3, gen_loss = 0.42023263815083084, disc_loss = 0.0674523549578801
Trained batch 79 in epoch 3, gen_loss = 0.42127366699278357, disc_loss = 0.06677375041181222
Trained batch 80 in epoch 3, gen_loss = 0.42164790961477494, disc_loss = 0.06617509089640261
Trained batch 81 in epoch 3, gen_loss = 0.4219950942731485, disc_loss = 0.06573874247828271
Trained batch 82 in epoch 3, gen_loss = 0.42299669801470746, disc_loss = 0.06507123217929199
Trained batch 83 in epoch 3, gen_loss = 0.42386034272965933, disc_loss = 0.06438500831081044
Trained batch 84 in epoch 3, gen_loss = 0.4242476901587318, disc_loss = 0.06371556423494922
Trained batch 85 in epoch 3, gen_loss = 0.42473621770393016, disc_loss = 0.06311505718351623
Trained batch 86 in epoch 3, gen_loss = 0.42614005762955237, disc_loss = 0.06252601899570603
Trained batch 87 in epoch 3, gen_loss = 0.42618796398693864, disc_loss = 0.06193923074434596
Trained batch 88 in epoch 3, gen_loss = 0.426398967089278, disc_loss = 0.06131187016981539
Trained batch 89 in epoch 3, gen_loss = 0.4258237342039744, disc_loss = 0.06079236952484482
Trained batch 90 in epoch 3, gen_loss = 0.4268239703807202, disc_loss = 0.060223432641558265
Trained batch 91 in epoch 3, gen_loss = 0.42745914536973706, disc_loss = 0.059775291552321745
Trained batch 92 in epoch 3, gen_loss = 0.427304055101128, disc_loss = 0.05939354973354487
Trained batch 93 in epoch 3, gen_loss = 0.42779335538123514, disc_loss = 0.058851583905399164
Trained batch 94 in epoch 3, gen_loss = 0.42858722743235134, disc_loss = 0.0584600186906755
Trained batch 95 in epoch 3, gen_loss = 0.42892647503564757, disc_loss = 0.057971958580310456
Trained batch 96 in epoch 3, gen_loss = 0.428398372279, disc_loss = 0.05756679319863006
Trained batch 97 in epoch 3, gen_loss = 0.42819370542253765, disc_loss = 0.0572137154534231
Trained batch 98 in epoch 3, gen_loss = 0.4285681533693063, disc_loss = 0.056711722113606006
Trained batch 99 in epoch 3, gen_loss = 0.4285185793042183, disc_loss = 0.05628372157458216
Trained batch 100 in epoch 3, gen_loss = 0.4278930207290272, disc_loss = 0.05599079272331725
Trained batch 101 in epoch 3, gen_loss = 0.42698347977563444, disc_loss = 0.05652381960466942
Trained batch 102 in epoch 3, gen_loss = 0.42732558840686835, disc_loss = 0.05719646795661849
Trained batch 103 in epoch 3, gen_loss = 0.4274392262674295, disc_loss = 0.05706649544523456
Trained batch 104 in epoch 3, gen_loss = 0.4279665989535196, disc_loss = 0.056695747876628524
Trained batch 105 in epoch 3, gen_loss = 0.4279590847919572, disc_loss = 0.05636722651169688
Trained batch 106 in epoch 3, gen_loss = 0.42866534078232593, disc_loss = 0.05615131331120278
Trained batch 107 in epoch 3, gen_loss = 0.4286595834074197, disc_loss = 0.0558397929503203
Trained batch 108 in epoch 3, gen_loss = 0.42910314891316476, disc_loss = 0.0555714110484979
Trained batch 109 in epoch 3, gen_loss = 0.4278304013338956, disc_loss = 0.055736030777916314
Trained batch 110 in epoch 3, gen_loss = 0.42798363706013104, disc_loss = 0.05546689841074047
Trained batch 111 in epoch 3, gen_loss = 0.42801401631108354, disc_loss = 0.055382540536811575
Trained batch 112 in epoch 3, gen_loss = 0.4282591762268438, disc_loss = 0.05654532411671449
Trained batch 113 in epoch 3, gen_loss = 0.42779435060526194, disc_loss = 0.057221250400241265
Trained batch 114 in epoch 3, gen_loss = 0.42866418024768, disc_loss = 0.056967770069351664
Trained batch 115 in epoch 3, gen_loss = 0.42905815459530927, disc_loss = 0.056638603455965116
Trained batch 116 in epoch 3, gen_loss = 0.4283877771634322, disc_loss = 0.056283531953286156
Trained batch 117 in epoch 3, gen_loss = 0.4290817842140036, disc_loss = 0.055919864124192274
Trained batch 118 in epoch 3, gen_loss = 0.4281886943749019, disc_loss = 0.05592036856526211
Trained batch 119 in epoch 3, gen_loss = 0.4276405011614164, disc_loss = 0.05562629049721484
Trained batch 120 in epoch 3, gen_loss = 0.42774237335220844, disc_loss = 0.05539311972362074
Trained batch 121 in epoch 3, gen_loss = 0.42785051538318886, disc_loss = 0.055063800325189705
Trained batch 122 in epoch 3, gen_loss = 0.42747374327202153, disc_loss = 0.05512399394898032
Trained batch 123 in epoch 3, gen_loss = 0.42788064143350046, disc_loss = 0.055078680285312716
Trained batch 124 in epoch 3, gen_loss = 0.427566153049469, disc_loss = 0.05507920940592885
Trained batch 125 in epoch 3, gen_loss = 0.4271978418978434, disc_loss = 0.055266635126567314
Trained batch 126 in epoch 3, gen_loss = 0.42711232637795876, disc_loss = 0.055068058192759284
Trained batch 127 in epoch 3, gen_loss = 0.4274244939442724, disc_loss = 0.054718482486350695
Trained batch 128 in epoch 3, gen_loss = 0.42829009982966637, disc_loss = 0.05443926083732598
Trained batch 129 in epoch 3, gen_loss = 0.4291555906717594, disc_loss = 0.05410301931417332
Trained batch 130 in epoch 3, gen_loss = 0.42915077632620136, disc_loss = 0.053766998942258934
Trained batch 131 in epoch 3, gen_loss = 0.42912511188875546, disc_loss = 0.05345631185142944
Trained batch 132 in epoch 3, gen_loss = 0.4295408172266824, disc_loss = 0.05315189958809126
Trained batch 133 in epoch 3, gen_loss = 0.43007933804348336, disc_loss = 0.05289932944005661
Trained batch 134 in epoch 3, gen_loss = 0.4300233052836524, disc_loss = 0.05265047727152705
Trained batch 135 in epoch 3, gen_loss = 0.42968739393879385, disc_loss = 0.052448783990899646
Trained batch 136 in epoch 3, gen_loss = 0.42993588212632783, disc_loss = 0.052128014144535266
Trained batch 137 in epoch 3, gen_loss = 0.4297098249628924, disc_loss = 0.05185262676989795
Trained batch 138 in epoch 3, gen_loss = 0.42929274143932533, disc_loss = 0.05166813527843613
Trained batch 139 in epoch 3, gen_loss = 0.4296130299568176, disc_loss = 0.05147891366920833
Trained batch 140 in epoch 3, gen_loss = 0.42967408536173773, disc_loss = 0.051201130828245525
Trained batch 141 in epoch 3, gen_loss = 0.4298102704572006, disc_loss = 0.05093189027540806
Trained batch 142 in epoch 3, gen_loss = 0.42966223742578413, disc_loss = 0.050909243318923075
Trained batch 143 in epoch 3, gen_loss = 0.4300048365775082, disc_loss = 0.05080843194607749
Trained batch 144 in epoch 3, gen_loss = 0.430194648997537, disc_loss = 0.05055462605287803
Trained batch 145 in epoch 3, gen_loss = 0.4302902676879543, disc_loss = 0.05044269633530448
Trained batch 146 in epoch 3, gen_loss = 0.4302930967742894, disc_loss = 0.05017053968507518
Trained batch 147 in epoch 3, gen_loss = 0.4302574808935861, disc_loss = 0.04997551504434464
Trained batch 148 in epoch 3, gen_loss = 0.430127734105859, disc_loss = 0.04996048596893881
Trained batch 149 in epoch 3, gen_loss = 0.4306461594502131, disc_loss = 0.04970083130213122
Trained batch 150 in epoch 3, gen_loss = 0.43123763424671246, disc_loss = 0.049548579444677034
Trained batch 151 in epoch 3, gen_loss = 0.43130924415431526, disc_loss = 0.04944760869808593
Trained batch 152 in epoch 3, gen_loss = 0.4306748805482403, disc_loss = 0.049816270355816955
Trained batch 153 in epoch 3, gen_loss = 0.4300617018303314, disc_loss = 0.05046534526476322
Trained batch 154 in epoch 3, gen_loss = 0.42970509240704197, disc_loss = 0.050509478395143824
Trained batch 155 in epoch 3, gen_loss = 0.4295509065955113, disc_loss = 0.05041303896667579
Trained batch 156 in epoch 3, gen_loss = 0.4296193923919823, disc_loss = 0.05038171394722192
Trained batch 157 in epoch 3, gen_loss = 0.42991301832319817, disc_loss = 0.05016512851985289
Trained batch 158 in epoch 3, gen_loss = 0.42989331558815336, disc_loss = 0.04999912714398226
Trained batch 159 in epoch 3, gen_loss = 0.429805020801723, disc_loss = 0.0497427985566901
Trained batch 160 in epoch 3, gen_loss = 0.42904030850955416, disc_loss = 0.04999700466587399
Trained batch 161 in epoch 3, gen_loss = 0.42914312838772195, disc_loss = 0.050120787398981646
Trained batch 162 in epoch 3, gen_loss = 0.428946645530455, disc_loss = 0.05009355624863432
Trained batch 163 in epoch 3, gen_loss = 0.4290288067082079, disc_loss = 0.05035259588564769
Trained batch 164 in epoch 3, gen_loss = 0.42844593687490984, disc_loss = 0.050297108566332044
Trained batch 165 in epoch 3, gen_loss = 0.4287250898329608, disc_loss = 0.05022699868654361
Trained batch 166 in epoch 3, gen_loss = 0.42877623510217955, disc_loss = 0.05018355592828757
Trained batch 167 in epoch 3, gen_loss = 0.4287036499452023, disc_loss = 0.050077549140301665
Trained batch 168 in epoch 3, gen_loss = 0.42830805771449615, disc_loss = 0.0501175775446174
Trained batch 169 in epoch 3, gen_loss = 0.4283576339483261, disc_loss = 0.04996633585816359
Trained batch 170 in epoch 3, gen_loss = 0.4284779741401561, disc_loss = 0.049858024324786074
Trained batch 171 in epoch 3, gen_loss = 0.428355026037194, disc_loss = 0.0496566598384836
Trained batch 172 in epoch 3, gen_loss = 0.4282365329348283, disc_loss = 0.049578473916697195
Trained batch 173 in epoch 3, gen_loss = 0.4279108227326952, disc_loss = 0.04939418524535823
Trained batch 174 in epoch 3, gen_loss = 0.42737171871321544, disc_loss = 0.04928797722661069
Trained batch 175 in epoch 3, gen_loss = 0.4274321769110181, disc_loss = 0.049162574596597224
Trained batch 176 in epoch 3, gen_loss = 0.42736381679604957, disc_loss = 0.04901750408649697
Trained batch 177 in epoch 3, gen_loss = 0.4272145987226722, disc_loss = 0.048792235466934154
Trained batch 178 in epoch 3, gen_loss = 0.42655464024517126, disc_loss = 0.04889380057503641
Trained batch 179 in epoch 3, gen_loss = 0.42627668811215297, disc_loss = 0.048708736893927886
Trained batch 180 in epoch 3, gen_loss = 0.42663262117633505, disc_loss = 0.04852484451421634
Trained batch 181 in epoch 3, gen_loss = 0.42668538859912325, disc_loss = 0.04838348557445947
Trained batch 182 in epoch 3, gen_loss = 0.42603552520600824, disc_loss = 0.04854189967634818
Trained batch 183 in epoch 3, gen_loss = 0.42577105663392856, disc_loss = 0.04868832806317622
Trained batch 184 in epoch 3, gen_loss = 0.4255420939342396, disc_loss = 0.04854913755395525
Trained batch 185 in epoch 3, gen_loss = 0.42562106219671103, disc_loss = 0.04837500434919631
Trained batch 186 in epoch 3, gen_loss = 0.4263337837821022, disc_loss = 0.048305768686481176
Trained batch 187 in epoch 3, gen_loss = 0.42651255999473814, disc_loss = 0.048117339113192194
Trained batch 188 in epoch 3, gen_loss = 0.42603484158793453, disc_loss = 0.04831104774629234
Trained batch 189 in epoch 3, gen_loss = 0.42618845387508997, disc_loss = 0.04844422463670765
Trained batch 190 in epoch 3, gen_loss = 0.426497974164823, disc_loss = 0.048483029571093655
Trained batch 191 in epoch 3, gen_loss = 0.4262404541174571, disc_loss = 0.04834750268249385
Trained batch 192 in epoch 3, gen_loss = 0.42636460776156093, disc_loss = 0.048254487666885316
Trained batch 193 in epoch 3, gen_loss = 0.4263039787405545, disc_loss = 0.04810586985267852
Trained batch 194 in epoch 3, gen_loss = 0.4263551320785131, disc_loss = 0.04797676926574264
Trained batch 195 in epoch 3, gen_loss = 0.4262337499127096, disc_loss = 0.04817049109082365
Trained batch 196 in epoch 3, gen_loss = 0.4261979693688717, disc_loss = 0.04816636453302303
Trained batch 197 in epoch 3, gen_loss = 0.4266327300457039, disc_loss = 0.048035093703109655
Trained batch 198 in epoch 3, gen_loss = 0.42652917926634976, disc_loss = 0.04787024817003602
Trained batch 199 in epoch 3, gen_loss = 0.42636226028203966, disc_loss = 0.04769625920103863
Trained batch 200 in epoch 3, gen_loss = 0.42637621259214864, disc_loss = 0.04751381730957337
Trained batch 201 in epoch 3, gen_loss = 0.42605865149214717, disc_loss = 0.047393633889513884
Trained batch 202 in epoch 3, gen_loss = 0.4264635887052038, disc_loss = 0.04723559688602395
Trained batch 203 in epoch 3, gen_loss = 0.42676712777100356, disc_loss = 0.047078998300575596
Trained batch 204 in epoch 3, gen_loss = 0.4270567847461235, disc_loss = 0.046904410410490704
Trained batch 205 in epoch 3, gen_loss = 0.42690176176793365, disc_loss = 0.04675989262352797
Trained batch 206 in epoch 3, gen_loss = 0.4270534312379533, disc_loss = 0.04678905732560777
Trained batch 207 in epoch 3, gen_loss = 0.4274707096987046, disc_loss = 0.04661607528508354
Trained batch 208 in epoch 3, gen_loss = 0.4277109416763178, disc_loss = 0.04648966773782977
Trained batch 209 in epoch 3, gen_loss = 0.42776001876308806, disc_loss = 0.04632682486525958
Trained batch 210 in epoch 3, gen_loss = 0.42726296101701206, disc_loss = 0.0465790380291217
Trained batch 211 in epoch 3, gen_loss = 0.4275031105246184, disc_loss = 0.046470732922349475
Trained batch 212 in epoch 3, gen_loss = 0.4274750654126557, disc_loss = 0.0464361089133076
Trained batch 213 in epoch 3, gen_loss = 0.42764494644704265, disc_loss = 0.04631650341004481
Trained batch 214 in epoch 3, gen_loss = 0.427506358124489, disc_loss = 0.046233303561200235
Trained batch 215 in epoch 3, gen_loss = 0.42767256567323647, disc_loss = 0.04607927821861166
Trained batch 216 in epoch 3, gen_loss = 0.42744477676905795, disc_loss = 0.04638408040542001
Trained batch 217 in epoch 3, gen_loss = 0.4268735016978115, disc_loss = 0.04651991669473093
Trained batch 218 in epoch 3, gen_loss = 0.42697039763677064, disc_loss = 0.04643258894900005
Trained batch 219 in epoch 3, gen_loss = 0.4273392283103683, disc_loss = 0.04630038665649904
Trained batch 220 in epoch 3, gen_loss = 0.4273743451450745, disc_loss = 0.04642559593223136
Trained batch 221 in epoch 3, gen_loss = 0.42703408835170503, disc_loss = 0.046686691527783465
Trained batch 222 in epoch 3, gen_loss = 0.4269748343480542, disc_loss = 0.04653476882984887
Trained batch 223 in epoch 3, gen_loss = 0.42728945213769165, disc_loss = 0.04678143247604437
Trained batch 224 in epoch 3, gen_loss = 0.42702660666571723, disc_loss = 0.04701001196478804
Trained batch 225 in epoch 3, gen_loss = 0.4269952917784716, disc_loss = 0.04687162566377855
Trained batch 226 in epoch 3, gen_loss = 0.4269480648807492, disc_loss = 0.04781302801714923
Trained batch 227 in epoch 3, gen_loss = 0.42641162937670424, disc_loss = 0.04859344378775476
Trained batch 228 in epoch 3, gen_loss = 0.42650075757867906, disc_loss = 0.048741126573323294
Trained batch 229 in epoch 3, gen_loss = 0.42632685355518174, disc_loss = 0.048964250851017625
Trained batch 230 in epoch 3, gen_loss = 0.42653344707055524, disc_loss = 0.04901970571584322
Trained batch 231 in epoch 3, gen_loss = 0.42717244411850797, disc_loss = 0.048917550049674026
Trained batch 232 in epoch 3, gen_loss = 0.42734250950710967, disc_loss = 0.04883512343947532
Trained batch 233 in epoch 3, gen_loss = 0.4273113911477929, disc_loss = 0.048703318702566445
Trained batch 234 in epoch 3, gen_loss = 0.4272586719786867, disc_loss = 0.04853195201882974
Trained batch 235 in epoch 3, gen_loss = 0.4277732310406232, disc_loss = 0.04840419620820084
Trained batch 236 in epoch 3, gen_loss = 0.4277714546219709, disc_loss = 0.04826267226500916
Trained batch 237 in epoch 3, gen_loss = 0.4273572339981544, disc_loss = 0.04826099507925453
Trained batch 238 in epoch 3, gen_loss = 0.4272387613811254, disc_loss = 0.04847355739692826
Trained batch 239 in epoch 3, gen_loss = 0.42734254350264866, disc_loss = 0.048333471580796566
Trained batch 240 in epoch 3, gen_loss = 0.4273358589633372, disc_loss = 0.04824703200855505
Trained batch 241 in epoch 3, gen_loss = 0.42750468997915914, disc_loss = 0.0481156275803916
Trained batch 242 in epoch 3, gen_loss = 0.42720284322161733, disc_loss = 0.048008535626447864
Trained batch 243 in epoch 3, gen_loss = 0.42742220898632144, disc_loss = 0.04787113629167014
Trained batch 244 in epoch 3, gen_loss = 0.4272898217853235, disc_loss = 0.04772731961530386
Trained batch 245 in epoch 3, gen_loss = 0.427634266454999, disc_loss = 0.047571975807848624
Trained batch 246 in epoch 3, gen_loss = 0.42760061529966503, disc_loss = 0.04740454663186964
Trained batch 247 in epoch 3, gen_loss = 0.42762607324027246, disc_loss = 0.04726307392082808
Trained batch 248 in epoch 3, gen_loss = 0.4277513517912133, disc_loss = 0.04713370034052246
Trained batch 249 in epoch 3, gen_loss = 0.4280031621456146, disc_loss = 0.047018461609259245
Trained batch 250 in epoch 3, gen_loss = 0.42797363683047046, disc_loss = 0.04686524072454211
Trained batch 251 in epoch 3, gen_loss = 0.4280176855741985, disc_loss = 0.04672450574284922
Trained batch 252 in epoch 3, gen_loss = 0.4279385674376733, disc_loss = 0.04662966264941888
Trained batch 253 in epoch 3, gen_loss = 0.4278769562328894, disc_loss = 0.046565467379913905
Trained batch 254 in epoch 3, gen_loss = 0.42760841063424654, disc_loss = 0.04644703003669194
Trained batch 255 in epoch 3, gen_loss = 0.42737935832701623, disc_loss = 0.046497757348333835
Trained batch 256 in epoch 3, gen_loss = 0.4274561664937535, disc_loss = 0.04637853976462312
Trained batch 257 in epoch 3, gen_loss = 0.4271013882271079, disc_loss = 0.046238538099799394
Trained batch 258 in epoch 3, gen_loss = 0.4270608266348084, disc_loss = 0.046103135364410616
Trained batch 259 in epoch 3, gen_loss = 0.4269990727305412, disc_loss = 0.04595493242825167
Trained batch 260 in epoch 3, gen_loss = 0.42670920593985195, disc_loss = 0.045801080963163994
Trained batch 261 in epoch 3, gen_loss = 0.42651215616528315, disc_loss = 0.045648691020479415
Trained batch 262 in epoch 3, gen_loss = 0.42652805948438755, disc_loss = 0.04552019552501209
Trained batch 263 in epoch 3, gen_loss = 0.4267070784487508, disc_loss = 0.045406789744667934
Trained batch 264 in epoch 3, gen_loss = 0.4272085613799545, disc_loss = 0.045375695529411425
Trained batch 265 in epoch 3, gen_loss = 0.4270056586964686, disc_loss = 0.045468855719257115
Trained batch 266 in epoch 3, gen_loss = 0.4270424650849475, disc_loss = 0.04537433542115858
Trained batch 267 in epoch 3, gen_loss = 0.4270906297128592, disc_loss = 0.045272568115658725
Trained batch 268 in epoch 3, gen_loss = 0.4267972231354412, disc_loss = 0.0452463782659029
Trained batch 269 in epoch 3, gen_loss = 0.42684804223201894, disc_loss = 0.04510464671378334
Trained batch 270 in epoch 3, gen_loss = 0.42660631926737147, disc_loss = 0.04505462878868259
Trained batch 271 in epoch 3, gen_loss = 0.42640556077308517, disc_loss = 0.045050734643797004
Trained batch 272 in epoch 3, gen_loss = 0.42614580139572367, disc_loss = 0.04511118995796739
Trained batch 273 in epoch 3, gen_loss = 0.42628758384363497, disc_loss = 0.04535617458083443
Trained batch 274 in epoch 3, gen_loss = 0.42570501121607696, disc_loss = 0.04567288346249949
Trained batch 275 in epoch 3, gen_loss = 0.42556607032167737, disc_loss = 0.0457178941840117
Trained batch 276 in epoch 3, gen_loss = 0.4257852719148574, disc_loss = 0.04581546908856406
Trained batch 277 in epoch 3, gen_loss = 0.42596894888569126, disc_loss = 0.04569656310415418
Trained batch 278 in epoch 3, gen_loss = 0.42593933711342485, disc_loss = 0.04566882917570705
Trained batch 279 in epoch 3, gen_loss = 0.425746082088777, disc_loss = 0.04567971281108579
Trained batch 280 in epoch 3, gen_loss = 0.4256424902809048, disc_loss = 0.04563181180162256
Trained batch 281 in epoch 3, gen_loss = 0.42569886570703896, disc_loss = 0.045497691582439215
Trained batch 282 in epoch 3, gen_loss = 0.42574930622805135, disc_loss = 0.04544124376463174
Trained batch 283 in epoch 3, gen_loss = 0.425787832745364, disc_loss = 0.045332263991184216
Trained batch 284 in epoch 3, gen_loss = 0.42557857632637025, disc_loss = 0.045274655782339863
Trained batch 285 in epoch 3, gen_loss = 0.42554448159424574, disc_loss = 0.04517769827865637
Trained batch 286 in epoch 3, gen_loss = 0.42548339728278983, disc_loss = 0.045071230896258606
Trained batch 287 in epoch 3, gen_loss = 0.42530702747818494, disc_loss = 0.044981710580436304
Trained batch 288 in epoch 3, gen_loss = 0.4251437724461605, disc_loss = 0.044887157569552374
Trained batch 289 in epoch 3, gen_loss = 0.42503212371776844, disc_loss = 0.04477493270653589
Trained batch 290 in epoch 3, gen_loss = 0.42472077573287936, disc_loss = 0.04464411317719678
Trained batch 291 in epoch 3, gen_loss = 0.42472331746392056, disc_loss = 0.04453942839419852
Trained batch 292 in epoch 3, gen_loss = 0.4246905524372648, disc_loss = 0.04443995142355561
Trained batch 293 in epoch 3, gen_loss = 0.4247462292309521, disc_loss = 0.044346588703353895
Trained batch 294 in epoch 3, gen_loss = 0.42491656834796326, disc_loss = 0.0442493612688603
Trained batch 295 in epoch 3, gen_loss = 0.4250305446015822, disc_loss = 0.044130512864039455
Trained batch 296 in epoch 3, gen_loss = 0.4248650346942221, disc_loss = 0.044010734365883
Trained batch 297 in epoch 3, gen_loss = 0.42486201616741665, disc_loss = 0.04390415970404826
Trained batch 298 in epoch 3, gen_loss = 0.4250021830051639, disc_loss = 0.04377564827422534
Trained batch 299 in epoch 3, gen_loss = 0.4250589476029078, disc_loss = 0.04365110556129366
Trained batch 300 in epoch 3, gen_loss = 0.4251228773910738, disc_loss = 0.0435404195048014
Trained batch 301 in epoch 3, gen_loss = 0.42503756590631625, disc_loss = 0.043452487723433124
Trained batch 302 in epoch 3, gen_loss = 0.42526264473943426, disc_loss = 0.043335269219103724
Trained batch 303 in epoch 3, gen_loss = 0.4250450145061079, disc_loss = 0.043211816713569294
Trained batch 304 in epoch 3, gen_loss = 0.42483840350244867, disc_loss = 0.043116329822567155
Trained batch 305 in epoch 3, gen_loss = 0.4245387947832058, disc_loss = 0.04306923203456392
Trained batch 306 in epoch 3, gen_loss = 0.4247610296216772, disc_loss = 0.043029240825507756
Trained batch 307 in epoch 3, gen_loss = 0.4249109362627005, disc_loss = 0.042930736697835294
Trained batch 308 in epoch 3, gen_loss = 0.42487000551038573, disc_loss = 0.0428175785681263
Trained batch 309 in epoch 3, gen_loss = 0.4245846483015245, disc_loss = 0.042754398062524776
Trained batch 310 in epoch 3, gen_loss = 0.4244630080902308, disc_loss = 0.04265094478839224
Trained batch 311 in epoch 3, gen_loss = 0.4241927427550157, disc_loss = 0.04257676435055402
Trained batch 312 in epoch 3, gen_loss = 0.42410753062738776, disc_loss = 0.04251058257896061
Trained batch 313 in epoch 3, gen_loss = 0.42394939121926667, disc_loss = 0.04239541388437104
Trained batch 314 in epoch 3, gen_loss = 0.42401362827845984, disc_loss = 0.042291632461701596
Trained batch 315 in epoch 3, gen_loss = 0.4241446275499803, disc_loss = 0.04219885391354136
Trained batch 316 in epoch 3, gen_loss = 0.424158667446311, disc_loss = 0.04208654021750254
Trained batch 317 in epoch 3, gen_loss = 0.4242451769188515, disc_loss = 0.04200049315626095
Trained batch 318 in epoch 3, gen_loss = 0.4242727993797733, disc_loss = 0.0419072329627239
Trained batch 319 in epoch 3, gen_loss = 0.42436240734532477, disc_loss = 0.041803886934940235
Trained batch 320 in epoch 3, gen_loss = 0.42438842982889335, disc_loss = 0.04172617389248957
Trained batch 321 in epoch 3, gen_loss = 0.42418527649426313, disc_loss = 0.04162259452675487
Trained batch 322 in epoch 3, gen_loss = 0.4241844726605312, disc_loss = 0.041603311015460234
Trained batch 323 in epoch 3, gen_loss = 0.4239365275443336, disc_loss = 0.04166534988721258
Trained batch 324 in epoch 3, gen_loss = 0.4240637083236988, disc_loss = 0.041613058718637776
Trained batch 325 in epoch 3, gen_loss = 0.4239139114420838, disc_loss = 0.041573899599546396
Trained batch 326 in epoch 3, gen_loss = 0.42378698111674107, disc_loss = 0.04151069330883181
Trained batch 327 in epoch 3, gen_loss = 0.42372143731974976, disc_loss = 0.04147370828730168
Trained batch 328 in epoch 3, gen_loss = 0.4236226666118599, disc_loss = 0.04137348418341989
Trained batch 329 in epoch 3, gen_loss = 0.42343227429823443, disc_loss = 0.04136915681742583
Trained batch 330 in epoch 3, gen_loss = 0.42366817350474006, disc_loss = 0.041281709516437844
Trained batch 331 in epoch 3, gen_loss = 0.42380232821746044, disc_loss = 0.04119721914961351
Trained batch 332 in epoch 3, gen_loss = 0.42375186900118805, disc_loss = 0.041114882111560565
Trained batch 333 in epoch 3, gen_loss = 0.42377955167593356, disc_loss = 0.04107674136116521
Trained batch 334 in epoch 3, gen_loss = 0.42359317968140786, disc_loss = 0.04098195726774744
Trained batch 335 in epoch 3, gen_loss = 0.4238534096096243, disc_loss = 0.040932220058970244
Trained batch 336 in epoch 3, gen_loss = 0.42406531876555537, disc_loss = 0.04084508528501812
Trained batch 337 in epoch 3, gen_loss = 0.42394869532105484, disc_loss = 0.04075572451648231
Trained batch 338 in epoch 3, gen_loss = 0.4238347575551992, disc_loss = 0.04069233131196603
Trained batch 339 in epoch 3, gen_loss = 0.42369055371074116, disc_loss = 0.04060668346937746
Trained batch 340 in epoch 3, gen_loss = 0.42370320074369483, disc_loss = 0.040612697709198835
Trained batch 341 in epoch 3, gen_loss = 0.42327600856970626, disc_loss = 0.04053727948727707
Trained batch 342 in epoch 3, gen_loss = 0.42311331186628204, disc_loss = 0.04052268913146054
Trained batch 343 in epoch 3, gen_loss = 0.4231081721914369, disc_loss = 0.04043397008100265
Trained batch 344 in epoch 3, gen_loss = 0.423219895362854, disc_loss = 0.04034409666757869
Trained batch 345 in epoch 3, gen_loss = 0.4234338776569146, disc_loss = 0.04025762373813013
Trained batch 346 in epoch 3, gen_loss = 0.42332465461420393, disc_loss = 0.04017392491857368
Trained batch 347 in epoch 3, gen_loss = 0.4232277010364094, disc_loss = 0.04008443610362666
Trained batch 348 in epoch 3, gen_loss = 0.42335800181828803, disc_loss = 0.039992481263295715
Trained batch 349 in epoch 3, gen_loss = 0.42316688469478064, disc_loss = 0.03998625087551773
Trained batch 350 in epoch 3, gen_loss = 0.4230643183926911, disc_loss = 0.039913964538736815
Trained batch 351 in epoch 3, gen_loss = 0.4228811109099876, disc_loss = 0.03990232986159919
Trained batch 352 in epoch 3, gen_loss = 0.42296493399582236, disc_loss = 0.039834366519025215
Trained batch 353 in epoch 3, gen_loss = 0.4229692558279145, disc_loss = 0.03977186810935579
Trained batch 354 in epoch 3, gen_loss = 0.42317193738171754, disc_loss = 0.03968127034998066
Trained batch 355 in epoch 3, gen_loss = 0.42317353364791765, disc_loss = 0.03961052122824103
Trained batch 356 in epoch 3, gen_loss = 0.42290251854421046, disc_loss = 0.03952900187375875
Trained batch 357 in epoch 3, gen_loss = 0.4226902690846161, disc_loss = 0.03946268932722176
Trained batch 358 in epoch 3, gen_loss = 0.4225485827929462, disc_loss = 0.03937830349617225
Trained batch 359 in epoch 3, gen_loss = 0.4225391257140372, disc_loss = 0.0392853638351274
Trained batch 360 in epoch 3, gen_loss = 0.4223188647272844, disc_loss = 0.039222184438361604
Trained batch 361 in epoch 3, gen_loss = 0.4221544534132626, disc_loss = 0.039132542627765825
Trained batch 362 in epoch 3, gen_loss = 0.4221705433915141, disc_loss = 0.039194735149357764
Trained batch 363 in epoch 3, gen_loss = 0.42200134907449993, disc_loss = 0.039118793445055956
Trained batch 364 in epoch 3, gen_loss = 0.4219060719829716, disc_loss = 0.03907844878937283
Trained batch 365 in epoch 3, gen_loss = 0.42181540129940365, disc_loss = 0.03899101678872369
Trained batch 366 in epoch 3, gen_loss = 0.42184160410221005, disc_loss = 0.038900431319157665
Trained batch 367 in epoch 3, gen_loss = 0.421933950856328, disc_loss = 0.03882599905204109
Trained batch 368 in epoch 3, gen_loss = 0.42202557982791084, disc_loss = 0.03874074183858749
Trained batch 369 in epoch 3, gen_loss = 0.4220237447603329, disc_loss = 0.03866304696562725
Trained batch 370 in epoch 3, gen_loss = 0.42208594517566445, disc_loss = 0.03859118710841853
Trained batch 371 in epoch 3, gen_loss = 0.42203294045181683, disc_loss = 0.03852691910209595
Trained batch 372 in epoch 3, gen_loss = 0.42195746326574374, disc_loss = 0.038497435001421706
Trained batch 373 in epoch 3, gen_loss = 0.4221464995553787, disc_loss = 0.0385079418787145
Trained batch 374 in epoch 3, gen_loss = 0.4221099169254303, disc_loss = 0.038481480685373146
Trained batch 375 in epoch 3, gen_loss = 0.4218337261613379, disc_loss = 0.038702927220196644
Trained batch 376 in epoch 3, gen_loss = 0.421745778078742, disc_loss = 0.03956876723565141
Trained batch 377 in epoch 3, gen_loss = 0.4213920994883492, disc_loss = 0.03999132896334958
Trained batch 378 in epoch 3, gen_loss = 0.4211701517998386, disc_loss = 0.04048875490041317
Trained batch 379 in epoch 3, gen_loss = 0.4212397640472964, disc_loss = 0.041116052755693855
Trained batch 380 in epoch 3, gen_loss = 0.42120363541788314, disc_loss = 0.041486203638724295
Trained batch 381 in epoch 3, gen_loss = 0.42112600148036217, disc_loss = 0.0418937874943291
Trained batch 382 in epoch 3, gen_loss = 0.42114579109547967, disc_loss = 0.04220055211724485
Trained batch 383 in epoch 3, gen_loss = 0.4209420081072797, disc_loss = 0.042281976326194126
Trained batch 384 in epoch 3, gen_loss = 0.42095659112001393, disc_loss = 0.04237850249152292
Trained batch 385 in epoch 3, gen_loss = 0.420800224487028, disc_loss = 0.0426320016186279
Trained batch 386 in epoch 3, gen_loss = 0.42090426258338515, disc_loss = 0.04272089783795351
Trained batch 387 in epoch 3, gen_loss = 0.4209850478110854, disc_loss = 0.042940565036878604
Trained batch 388 in epoch 3, gen_loss = 0.4209962166979871, disc_loss = 0.043182897659205376
Trained batch 389 in epoch 3, gen_loss = 0.4208977622099412, disc_loss = 0.043294698045326346
Trained batch 390 in epoch 3, gen_loss = 0.420738287060462, disc_loss = 0.04359471356577199
Trained batch 391 in epoch 3, gen_loss = 0.4209253915718624, disc_loss = 0.04384222194048747
Trained batch 392 in epoch 3, gen_loss = 0.4208573717197389, disc_loss = 0.04394109538370037
Trained batch 393 in epoch 3, gen_loss = 0.4205788309652793, disc_loss = 0.04444565263524803
Trained batch 394 in epoch 3, gen_loss = 0.4204662631584119, disc_loss = 0.044496713887570025
Trained batch 395 in epoch 3, gen_loss = 0.42034893941999685, disc_loss = 0.04449776983161391
Trained batch 396 in epoch 3, gen_loss = 0.42036528461225686, disc_loss = 0.04452040382151865
Trained batch 397 in epoch 3, gen_loss = 0.42039660188420935, disc_loss = 0.04458667689597412
Trained batch 398 in epoch 3, gen_loss = 0.42042473757774906, disc_loss = 0.04456649475817319
Trained batch 399 in epoch 3, gen_loss = 0.4203343340009451, disc_loss = 0.04468537436565384
Trained batch 400 in epoch 3, gen_loss = 0.42002043157741614, disc_loss = 0.04515024742571419
Trained batch 401 in epoch 3, gen_loss = 0.42019361635642266, disc_loss = 0.045576102751311826
Trained batch 402 in epoch 3, gen_loss = 0.4204609332694013, disc_loss = 0.04564882746248254
Trained batch 403 in epoch 3, gen_loss = 0.42040208675483665, disc_loss = 0.0457388543786647
Trained batch 404 in epoch 3, gen_loss = 0.4203246926819837, disc_loss = 0.04588927981432205
Trained batch 405 in epoch 3, gen_loss = 0.4203427337807388, disc_loss = 0.0459045828320086
Trained batch 406 in epoch 3, gen_loss = 0.4202383552341555, disc_loss = 0.04587568112715383
Trained batch 407 in epoch 3, gen_loss = 0.42025645427844105, disc_loss = 0.045934977089785334
Trained batch 408 in epoch 3, gen_loss = 0.4201785840440205, disc_loss = 0.04608092916796945
Trained batch 409 in epoch 3, gen_loss = 0.4200625953150959, disc_loss = 0.04654285114303958
Trained batch 410 in epoch 3, gen_loss = 0.4203045994695956, disc_loss = 0.04698493430241399
Trained batch 411 in epoch 3, gen_loss = 0.42014650769025375, disc_loss = 0.047471315670053214
Trained batch 412 in epoch 3, gen_loss = 0.4200348394402003, disc_loss = 0.04754654533448505
Trained batch 413 in epoch 3, gen_loss = 0.42002358701494, disc_loss = 0.04782070396558026
Trained batch 414 in epoch 3, gen_loss = 0.4200055945350463, disc_loss = 0.04805917550237423
Trained batch 415 in epoch 3, gen_loss = 0.4197960368429239, disc_loss = 0.04823866745125717
Trained batch 416 in epoch 3, gen_loss = 0.41968199853702703, disc_loss = 0.04888242526690094
Trained batch 417 in epoch 3, gen_loss = 0.4194830109200409, disc_loss = 0.049875208285846635
Trained batch 418 in epoch 3, gen_loss = 0.41951210771938496, disc_loss = 0.04993046148677928
Trained batch 419 in epoch 3, gen_loss = 0.41956584056218466, disc_loss = 0.05016463545062357
Trained batch 420 in epoch 3, gen_loss = 0.4194260373393034, disc_loss = 0.050232347027971594
Trained batch 421 in epoch 3, gen_loss = 0.4194468208963837, disc_loss = 0.05035005032053985
Trained batch 422 in epoch 3, gen_loss = 0.41959556831535716, disc_loss = 0.05046754320488965
Trained batch 423 in epoch 3, gen_loss = 0.41959418201783916, disc_loss = 0.05051029061257207
Trained batch 424 in epoch 3, gen_loss = 0.4194993120782516, disc_loss = 0.05057249283746761
Trained batch 425 in epoch 3, gen_loss = 0.4196041054289106, disc_loss = 0.05055412456629352
Trained batch 426 in epoch 3, gen_loss = 0.41968138163486185, disc_loss = 0.05063217341577071
Trained batch 427 in epoch 3, gen_loss = 0.4195194730413294, disc_loss = 0.05082526385879892
Trained batch 428 in epoch 3, gen_loss = 0.41950699652269446, disc_loss = 0.050805582899365806
Trained batch 429 in epoch 3, gen_loss = 0.4194009997123896, disc_loss = 0.05078969644382596
Trained batch 430 in epoch 3, gen_loss = 0.4192888844594048, disc_loss = 0.05085856683353468
Trained batch 431 in epoch 3, gen_loss = 0.41916055956648457, disc_loss = 0.050845384242064834
Trained batch 432 in epoch 3, gen_loss = 0.4192888165456318, disc_loss = 0.05079914953163879
Trained batch 433 in epoch 3, gen_loss = 0.4192171444953312, disc_loss = 0.0507430019316345
Trained batch 434 in epoch 3, gen_loss = 0.4190089503924052, disc_loss = 0.05071867938399657
Trained batch 435 in epoch 3, gen_loss = 0.4190788655926328, disc_loss = 0.050665498640678756
Trained batch 436 in epoch 3, gen_loss = 0.4190088663957757, disc_loss = 0.05057861307503771
Trained batch 437 in epoch 3, gen_loss = 0.4191267190322484, disc_loss = 0.050777397243960944
Trained batch 438 in epoch 3, gen_loss = 0.4188390463115414, disc_loss = 0.05132775288075209
Trained batch 439 in epoch 3, gen_loss = 0.4188960926099257, disc_loss = 0.05125383726448159
Trained batch 440 in epoch 3, gen_loss = 0.41885837493569944, disc_loss = 0.05123371019528634
Trained batch 441 in epoch 3, gen_loss = 0.4188212185288986, disc_loss = 0.05121785217086991
Trained batch 442 in epoch 3, gen_loss = 0.4188788311879737, disc_loss = 0.05123530309983691
Trained batch 443 in epoch 3, gen_loss = 0.41888878964357545, disc_loss = 0.05117445292479887
Trained batch 444 in epoch 3, gen_loss = 0.4187215379114901, disc_loss = 0.05140560072836246
Trained batch 445 in epoch 3, gen_loss = 0.4188027213507169, disc_loss = 0.05188146972978663
Trained batch 446 in epoch 3, gen_loss = 0.41890433917376285, disc_loss = 0.051948023466205834
Trained batch 447 in epoch 3, gen_loss = 0.4187889486285193, disc_loss = 0.05188889157268152
Trained batch 448 in epoch 3, gen_loss = 0.4186856361699264, disc_loss = 0.0518038307911901
Trained batch 449 in epoch 3, gen_loss = 0.4185790506336424, disc_loss = 0.05180138513031933
Trained batch 450 in epoch 3, gen_loss = 0.4183184429837965, disc_loss = 0.051839294275496065
Trained batch 451 in epoch 3, gen_loss = 0.41834586443363037, disc_loss = 0.05179060581840773
Trained batch 452 in epoch 3, gen_loss = 0.4183337882522979, disc_loss = 0.051706232677396824
Trained batch 453 in epoch 3, gen_loss = 0.4183050741970802, disc_loss = 0.05168643080535045
Trained batch 454 in epoch 3, gen_loss = 0.41841612143830936, disc_loss = 0.05160433580832822
Trained batch 455 in epoch 3, gen_loss = 0.4183925940540799, disc_loss = 0.051542604313509766
Trained batch 456 in epoch 3, gen_loss = 0.41836636860730614, disc_loss = 0.0515947001548056
Trained batch 457 in epoch 3, gen_loss = 0.4185370885518961, disc_loss = 0.05178069759680845
Trained batch 458 in epoch 3, gen_loss = 0.41839455921925234, disc_loss = 0.05172296924301482
Trained batch 459 in epoch 3, gen_loss = 0.41825778490823246, disc_loss = 0.051643123267137485
Trained batch 460 in epoch 3, gen_loss = 0.4182168703017162, disc_loss = 0.05161876026177355
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 0.37377750873565674, disc_loss = 0.18342749774456024
Trained batch 1 in epoch 4, gen_loss = 0.39103296399116516, disc_loss = 0.17394747585058212
Trained batch 2 in epoch 4, gen_loss = 0.39966167012850445, disc_loss = 0.13039095203081766
Trained batch 3 in epoch 4, gen_loss = 0.4097340703010559, disc_loss = 0.11520040594041348
Trained batch 4 in epoch 4, gen_loss = 0.40307456254959106, disc_loss = 0.10551069974899292
Trained batch 5 in epoch 4, gen_loss = 0.39628341297308606, disc_loss = 0.091320157982409
Trained batch 6 in epoch 4, gen_loss = 0.3993644416332245, disc_loss = 0.07958899957260915
Trained batch 7 in epoch 4, gen_loss = 0.40524836257100105, disc_loss = 0.07500758429523557
Trained batch 8 in epoch 4, gen_loss = 0.40785038140085006, disc_loss = 0.06816716626700428
Trained batch 9 in epoch 4, gen_loss = 0.40464967787265776, disc_loss = 0.06571214543655515
Trained batch 10 in epoch 4, gen_loss = 0.4058272350918163, disc_loss = 0.06109822456809608
Trained batch 11 in epoch 4, gen_loss = 0.4007365753253301, disc_loss = 0.05717710933337609
Trained batch 12 in epoch 4, gen_loss = 0.4106383277819707, disc_loss = 0.054504054670150466
Trained batch 13 in epoch 4, gen_loss = 0.4079202541283199, disc_loss = 0.05126280231135232
Trained batch 14 in epoch 4, gen_loss = 0.4067071537176768, disc_loss = 0.04920181110501289
Trained batch 15 in epoch 4, gen_loss = 0.4124286528676748, disc_loss = 0.04753805056679994
Trained batch 16 in epoch 4, gen_loss = 0.4134901884724112, disc_loss = 0.04524636608274544
Trained batch 17 in epoch 4, gen_loss = 0.41165291104051804, disc_loss = 0.04377074105044206
Trained batch 18 in epoch 4, gen_loss = 0.41598202680286606, disc_loss = 0.04245431878064808
Trained batch 19 in epoch 4, gen_loss = 0.41772512048482896, disc_loss = 0.041449427418410775
Trained batch 20 in epoch 4, gen_loss = 0.4156424715405419, disc_loss = 0.04518229461141995
Trained batch 21 in epoch 4, gen_loss = 0.41304634782401, disc_loss = 0.05002512562681328
Trained batch 22 in epoch 4, gen_loss = 0.4110364071700884, disc_loss = 0.05173669901231061
Trained batch 23 in epoch 4, gen_loss = 0.41383739685018855, disc_loss = 0.05101059485847751
Trained batch 24 in epoch 4, gen_loss = 0.4112206363677979, disc_loss = 0.051629472225904464
Trained batch 25 in epoch 4, gen_loss = 0.41254910826683044, disc_loss = 0.05045153938520413
Trained batch 26 in epoch 4, gen_loss = 0.4145142998960283, disc_loss = 0.04985550880708076
Trained batch 27 in epoch 4, gen_loss = 0.41010079852172304, disc_loss = 0.05251189088448882
Trained batch 28 in epoch 4, gen_loss = 0.413600977124839, disc_loss = 0.05563819646064577
Trained batch 29 in epoch 4, gen_loss = 0.41193343003590904, disc_loss = 0.05610164161771536
Trained batch 30 in epoch 4, gen_loss = 0.41177671474795186, disc_loss = 0.05753260135890976
Trained batch 31 in epoch 4, gen_loss = 0.41449973452836275, disc_loss = 0.059874258062336594
Trained batch 32 in epoch 4, gen_loss = 0.4149894651138421, disc_loss = 0.05974714994204767
Trained batch 33 in epoch 4, gen_loss = 0.41514017739716697, disc_loss = 0.06156416516751051
Trained batch 34 in epoch 4, gen_loss = 0.4179471722670964, disc_loss = 0.0629067567310163
Trained batch 35 in epoch 4, gen_loss = 0.4179435819387436, disc_loss = 0.06188632273632619
Trained batch 36 in epoch 4, gen_loss = 0.4155905142023757, disc_loss = 0.061615201921479124
Trained batch 37 in epoch 4, gen_loss = 0.4151502965312255, disc_loss = 0.06052401411886278
Trained batch 38 in epoch 4, gen_loss = 0.41478816591776335, disc_loss = 0.05936399718316702
Trained batch 39 in epoch 4, gen_loss = 0.41589281633496283, disc_loss = 0.058572452235966924
Trained batch 40 in epoch 4, gen_loss = 0.4177994299225691, disc_loss = 0.05765399600311023
Trained batch 41 in epoch 4, gen_loss = 0.4197138100862503, disc_loss = 0.05694216835711684
Trained batch 42 in epoch 4, gen_loss = 0.42112193343251253, disc_loss = 0.05680136321935543
Trained batch 43 in epoch 4, gen_loss = 0.4219928973100402, disc_loss = 0.058225103484636005
Trained batch 44 in epoch 4, gen_loss = 0.4225864701800876, disc_loss = 0.06002925443980429
Trained batch 45 in epoch 4, gen_loss = 0.4218737392321877, disc_loss = 0.05921470394115085
Trained batch 46 in epoch 4, gen_loss = 0.4195290321999408, disc_loss = 0.06000755873924874
Trained batch 47 in epoch 4, gen_loss = 0.4211153027911981, disc_loss = 0.06201924899748216
Trained batch 48 in epoch 4, gen_loss = 0.4202680101200026, disc_loss = 0.06655746413280769
Trained batch 49 in epoch 4, gen_loss = 0.4199137657880783, disc_loss = 0.06627928372472525
Trained batch 50 in epoch 4, gen_loss = 0.4204394846570258, disc_loss = 0.06581576384019618
Trained batch 51 in epoch 4, gen_loss = 0.41965815596855605, disc_loss = 0.06632059250170222
Trained batch 52 in epoch 4, gen_loss = 0.4204956006329015, disc_loss = 0.06711699964724621
Trained batch 53 in epoch 4, gen_loss = 0.41991401546531254, disc_loss = 0.06773249166845172
Trained batch 54 in epoch 4, gen_loss = 0.4195882417938926, disc_loss = 0.06702830232679843
Trained batch 55 in epoch 4, gen_loss = 0.41978213510343004, disc_loss = 0.06927441922016442
Trained batch 56 in epoch 4, gen_loss = 0.4187088169549641, disc_loss = 0.07188919588531319
Trained batch 57 in epoch 4, gen_loss = 0.4188688942070665, disc_loss = 0.07155942483323402
Trained batch 58 in epoch 4, gen_loss = 0.41930541648703107, disc_loss = 0.07456796126976861
Trained batch 59 in epoch 4, gen_loss = 0.41938190907239914, disc_loss = 0.07584623026972016
Trained batch 60 in epoch 4, gen_loss = 0.4176182683374061, disc_loss = 0.07615597121661803
Trained batch 61 in epoch 4, gen_loss = 0.41719919346993967, disc_loss = 0.07667311440191922
Trained batch 62 in epoch 4, gen_loss = 0.41624918296223595, disc_loss = 0.0765646690473197
Trained batch 63 in epoch 4, gen_loss = 0.4157784152776003, disc_loss = 0.07641457256977446
Trained batch 64 in epoch 4, gen_loss = 0.4161334042365734, disc_loss = 0.07548904911829875
Trained batch 65 in epoch 4, gen_loss = 0.41598493989669916, disc_loss = 0.07476110776152575
Trained batch 66 in epoch 4, gen_loss = 0.41635358644955195, disc_loss = 0.0738750796264677
Trained batch 67 in epoch 4, gen_loss = 0.418067608247785, disc_loss = 0.0740543671828859
Trained batch 68 in epoch 4, gen_loss = 0.41657965900241467, disc_loss = 0.07751615561436916
Trained batch 69 in epoch 4, gen_loss = 0.41686039098671507, disc_loss = 0.07877127592052732
Trained batch 70 in epoch 4, gen_loss = 0.4155365619021402, disc_loss = 0.07880038789040605
Trained batch 71 in epoch 4, gen_loss = 0.41422202065587044, disc_loss = 0.0800757659599185
Trained batch 72 in epoch 4, gen_loss = 0.4150322859417902, disc_loss = 0.07954772888389353
Trained batch 73 in epoch 4, gen_loss = 0.41484880729301554, disc_loss = 0.07878969682732949
Trained batch 74 in epoch 4, gen_loss = 0.4144344468911489, disc_loss = 0.07822591769198577
Trained batch 75 in epoch 4, gen_loss = 0.41412458843306493, disc_loss = 0.07809846669337467
Trained batch 76 in epoch 4, gen_loss = 0.41523461488934305, disc_loss = 0.07804889964883203
Trained batch 77 in epoch 4, gen_loss = 0.4144859168774042, disc_loss = 0.0775923242028325
Trained batch 78 in epoch 4, gen_loss = 0.41386294478102575, disc_loss = 0.07810979857569254
Trained batch 79 in epoch 4, gen_loss = 0.41410636752843855, disc_loss = 0.0776092231972143
Trained batch 80 in epoch 4, gen_loss = 0.4132136647348051, disc_loss = 0.07695246370578254
Trained batch 81 in epoch 4, gen_loss = 0.41369427231753747, disc_loss = 0.076223295590863
Trained batch 82 in epoch 4, gen_loss = 0.4140142342412328, disc_loss = 0.07562008163476565
Trained batch 83 in epoch 4, gen_loss = 0.4139762921702294, disc_loss = 0.07500433198930252
Trained batch 84 in epoch 4, gen_loss = 0.41365643599454094, disc_loss = 0.07457778313580682
Trained batch 85 in epoch 4, gen_loss = 0.4132995872303497, disc_loss = 0.07418023491668146
Trained batch 86 in epoch 4, gen_loss = 0.4132430824055069, disc_loss = 0.0734368955245477
Trained batch 87 in epoch 4, gen_loss = 0.4125583388588645, disc_loss = 0.07279275098434565
Trained batch 88 in epoch 4, gen_loss = 0.412853009915084, disc_loss = 0.07223362616901652
Trained batch 89 in epoch 4, gen_loss = 0.41297757890489367, disc_loss = 0.07238658483450612
Trained batch 90 in epoch 4, gen_loss = 0.4131648989169152, disc_loss = 0.07260622607114223
Trained batch 91 in epoch 4, gen_loss = 0.41300560728363367, disc_loss = 0.07223166014148813
Trained batch 92 in epoch 4, gen_loss = 0.41310797936172894, disc_loss = 0.07172693663667287
Trained batch 93 in epoch 4, gen_loss = 0.41282773303224685, disc_loss = 0.071139012711083
Trained batch 94 in epoch 4, gen_loss = 0.41209148795981154, disc_loss = 0.0713930506357237
Trained batch 95 in epoch 4, gen_loss = 0.4120569583028555, disc_loss = 0.07242818610393442
Trained batch 96 in epoch 4, gen_loss = 0.4119445761454474, disc_loss = 0.07190342868687873
Trained batch 97 in epoch 4, gen_loss = 0.411916976680561, disc_loss = 0.07160194004334662
Trained batch 98 in epoch 4, gen_loss = 0.41151398781574133, disc_loss = 0.07123932128565179
Trained batch 99 in epoch 4, gen_loss = 0.4108642691373825, disc_loss = 0.07111036284826695
Trained batch 100 in epoch 4, gen_loss = 0.4116997237842862, disc_loss = 0.07063388500805243
Trained batch 101 in epoch 4, gen_loss = 0.41119232598473043, disc_loss = 0.07063659792765975
Trained batch 102 in epoch 4, gen_loss = 0.4110016657889468, disc_loss = 0.07032949843633811
Trained batch 103 in epoch 4, gen_loss = 0.4119176070850629, disc_loss = 0.07002774809594624
Trained batch 104 in epoch 4, gen_loss = 0.4122800077710833, disc_loss = 0.06945989586058117
Trained batch 105 in epoch 4, gen_loss = 0.4123199160368937, disc_loss = 0.06892315788581124
Trained batch 106 in epoch 4, gen_loss = 0.4117481463423399, disc_loss = 0.06879005266057554
Trained batch 107 in epoch 4, gen_loss = 0.41263234118620556, disc_loss = 0.06869358836707694
Trained batch 108 in epoch 4, gen_loss = 0.4130646389558775, disc_loss = 0.06817552953138264
Trained batch 109 in epoch 4, gen_loss = 0.4136298726905476, disc_loss = 0.06780204600231214
Trained batch 110 in epoch 4, gen_loss = 0.4142375566937902, disc_loss = 0.06731822465017841
Trained batch 111 in epoch 4, gen_loss = 0.41431419817464693, disc_loss = 0.0667995814666418
Trained batch 112 in epoch 4, gen_loss = 0.41402182642337493, disc_loss = 0.06641703011649372
Trained batch 113 in epoch 4, gen_loss = 0.41406736196133126, disc_loss = 0.06600877440028023
Trained batch 114 in epoch 4, gen_loss = 0.41369425395260684, disc_loss = 0.06558871920342031
Trained batch 115 in epoch 4, gen_loss = 0.4136145718652627, disc_loss = 0.06508268704156167
Trained batch 116 in epoch 4, gen_loss = 0.4140192848494929, disc_loss = 0.06524846803906381
Trained batch 117 in epoch 4, gen_loss = 0.41351450979709625, disc_loss = 0.0656897730541305
Trained batch 118 in epoch 4, gen_loss = 0.41427932792351024, disc_loss = 0.06529831772811022
Trained batch 119 in epoch 4, gen_loss = 0.41467792515953383, disc_loss = 0.0651483210346972
Trained batch 120 in epoch 4, gen_loss = 0.414630783244598, disc_loss = 0.06487701958707295
Trained batch 121 in epoch 4, gen_loss = 0.4144961479745927, disc_loss = 0.06465743038589593
Trained batch 122 in epoch 4, gen_loss = 0.4148013918865018, disc_loss = 0.06424539022117369
Trained batch 123 in epoch 4, gen_loss = 0.4141751953190373, disc_loss = 0.06411541010733814
Trained batch 124 in epoch 4, gen_loss = 0.4140294897556305, disc_loss = 0.06385102810710669
Trained batch 125 in epoch 4, gen_loss = 0.41397426644014934, disc_loss = 0.06341545327403952
Trained batch 126 in epoch 4, gen_loss = 0.4137877244648971, disc_loss = 0.06320230858620461
Trained batch 127 in epoch 4, gen_loss = 0.4141034730710089, disc_loss = 0.06347191266104346
Trained batch 128 in epoch 4, gen_loss = 0.41343858607055606, disc_loss = 0.06465126414487297
Trained batch 129 in epoch 4, gen_loss = 0.4137142857679954, disc_loss = 0.06461529083406696
Trained batch 130 in epoch 4, gen_loss = 0.41462537009297434, disc_loss = 0.06529030413544587
Trained batch 131 in epoch 4, gen_loss = 0.4140614993644483, disc_loss = 0.0696528224824843
Trained batch 132 in epoch 4, gen_loss = 0.41374094571386066, disc_loss = 0.06999594443022533
Trained batch 133 in epoch 4, gen_loss = 0.41404530383757693, disc_loss = 0.07029259615619458
Trained batch 134 in epoch 4, gen_loss = 0.4134197855437243, disc_loss = 0.07064512437554421
Trained batch 135 in epoch 4, gen_loss = 0.41349219508907376, disc_loss = 0.07121080794946893
Trained batch 136 in epoch 4, gen_loss = 0.414173920441718, disc_loss = 0.07242641330825804
Trained batch 137 in epoch 4, gen_loss = 0.41403459055700165, disc_loss = 0.07256142000762233
Trained batch 138 in epoch 4, gen_loss = 0.4136715250478374, disc_loss = 0.07275267679029875
Trained batch 139 in epoch 4, gen_loss = 0.4133511683770588, disc_loss = 0.07462745856360666
Trained batch 140 in epoch 4, gen_loss = 0.41318400151340673, disc_loss = 0.07452103304709737
Trained batch 141 in epoch 4, gen_loss = 0.4131877319493764, disc_loss = 0.07531217348591333
Trained batch 142 in epoch 4, gen_loss = 0.4125325886102823, disc_loss = 0.07587886126907346
Trained batch 143 in epoch 4, gen_loss = 0.41163259744644165, disc_loss = 0.07603950171809022
Trained batch 144 in epoch 4, gen_loss = 0.41160046602117606, disc_loss = 0.0759202448394278
Trained batch 145 in epoch 4, gen_loss = 0.4115209056906504, disc_loss = 0.07588818525793413
Trained batch 146 in epoch 4, gen_loss = 0.41139201667844033, disc_loss = 0.07576132752634838
Trained batch 147 in epoch 4, gen_loss = 0.41115761266366857, disc_loss = 0.07535320821193021
Trained batch 148 in epoch 4, gen_loss = 0.412078863222327, disc_loss = 0.07597839641041004
Trained batch 149 in epoch 4, gen_loss = 0.41112809379895526, disc_loss = 0.0783970795944333
Trained batch 150 in epoch 4, gen_loss = 0.4109386039885464, disc_loss = 0.07854140415442305
Trained batch 151 in epoch 4, gen_loss = 0.41086285561323166, disc_loss = 0.07877143427092385
Trained batch 152 in epoch 4, gen_loss = 0.4108245100071228, disc_loss = 0.07850364063641214
Trained batch 153 in epoch 4, gen_loss = 0.41037196075761473, disc_loss = 0.07835682366623895
Trained batch 154 in epoch 4, gen_loss = 0.4101830909329076, disc_loss = 0.07820251556413789
Trained batch 155 in epoch 4, gen_loss = 0.4104463580327156, disc_loss = 0.07838716402124518
Trained batch 156 in epoch 4, gen_loss = 0.4100007274348265, disc_loss = 0.07835433576374677
Trained batch 157 in epoch 4, gen_loss = 0.4102021319956719, disc_loss = 0.07804198458177757
Trained batch 158 in epoch 4, gen_loss = 0.40995296067411796, disc_loss = 0.0777401688783986
Trained batch 159 in epoch 4, gen_loss = 0.4099435655400157, disc_loss = 0.07744672190165147
Trained batch 160 in epoch 4, gen_loss = 0.41021667226501135, disc_loss = 0.07714401413426265
Trained batch 161 in epoch 4, gen_loss = 0.4105728958491926, disc_loss = 0.0767787521429084
Trained batch 162 in epoch 4, gen_loss = 0.41084340616969245, disc_loss = 0.07639977414206676
Trained batch 163 in epoch 4, gen_loss = 0.4108593731028278, disc_loss = 0.07606901006386955
Trained batch 164 in epoch 4, gen_loss = 0.410788112336939, disc_loss = 0.0756844111577128
Trained batch 165 in epoch 4, gen_loss = 0.41080456666917686, disc_loss = 0.07542937950242355
Trained batch 166 in epoch 4, gen_loss = 0.4110315590204593, disc_loss = 0.07508687996221873
Trained batch 167 in epoch 4, gen_loss = 0.4110683130011672, disc_loss = 0.07471005028734605
Trained batch 168 in epoch 4, gen_loss = 0.41059253095875126, disc_loss = 0.07468672083503396
Trained batch 169 in epoch 4, gen_loss = 0.41067894749781664, disc_loss = 0.07457661974956008
Trained batch 170 in epoch 4, gen_loss = 0.4106513167682447, disc_loss = 0.07423511654007853
Trained batch 171 in epoch 4, gen_loss = 0.4099564690922582, disc_loss = 0.07417198358276902
Trained batch 172 in epoch 4, gen_loss = 0.4101353718366237, disc_loss = 0.07379459212884049
Trained batch 173 in epoch 4, gen_loss = 0.41002524841105803, disc_loss = 0.07357955482071159
Trained batch 174 in epoch 4, gen_loss = 0.4095286723545619, disc_loss = 0.07330332183412143
Trained batch 175 in epoch 4, gen_loss = 0.40951791422610934, disc_loss = 0.07298999969762834
Trained batch 176 in epoch 4, gen_loss = 0.40904926832786387, disc_loss = 0.07282207615799823
Trained batch 177 in epoch 4, gen_loss = 0.4090553366401222, disc_loss = 0.07262937123939563
Trained batch 178 in epoch 4, gen_loss = 0.4092775686493133, disc_loss = 0.07228937236769073
Trained batch 179 in epoch 4, gen_loss = 0.40919631189770167, disc_loss = 0.07201158922269113
Trained batch 180 in epoch 4, gen_loss = 0.4091350996033263, disc_loss = 0.0717904860030304
Trained batch 181 in epoch 4, gen_loss = 0.4086446545936249, disc_loss = 0.07254394029707208
Trained batch 182 in epoch 4, gen_loss = 0.4087951885220783, disc_loss = 0.07270986159825749
Trained batch 183 in epoch 4, gen_loss = 0.4088263560248458, disc_loss = 0.07251768806726551
Trained batch 184 in epoch 4, gen_loss = 0.4087241217896745, disc_loss = 0.0723191804227394
Trained batch 185 in epoch 4, gen_loss = 0.40872085174565675, disc_loss = 0.07199309138901612
Trained batch 186 in epoch 4, gen_loss = 0.409029984219189, disc_loss = 0.0721956084826015
Trained batch 187 in epoch 4, gen_loss = 0.4088997858318877, disc_loss = 0.0731304218705268
Trained batch 188 in epoch 4, gen_loss = 0.4089992634518437, disc_loss = 0.0731344511732459
Trained batch 189 in epoch 4, gen_loss = 0.4089417179948405, disc_loss = 0.07295634826449188
Trained batch 190 in epoch 4, gen_loss = 0.4089221383264552, disc_loss = 0.07275133606787595
Trained batch 191 in epoch 4, gen_loss = 0.4092650944367051, disc_loss = 0.07312751995535412
Trained batch 192 in epoch 4, gen_loss = 0.4092864616547224, disc_loss = 0.07287631349377527
Trained batch 193 in epoch 4, gen_loss = 0.408992488666908, disc_loss = 0.07268096383219373
Trained batch 194 in epoch 4, gen_loss = 0.4092149467040331, disc_loss = 0.07247339906887366
Trained batch 195 in epoch 4, gen_loss = 0.40944705219293126, disc_loss = 0.07243005645803499
Trained batch 196 in epoch 4, gen_loss = 0.4094953490090249, disc_loss = 0.0721072647484199
Trained batch 197 in epoch 4, gen_loss = 0.4095306545495987, disc_loss = 0.0720712030259422
Trained batch 198 in epoch 4, gen_loss = 0.4093695332357033, disc_loss = 0.0723754442601123
Trained batch 199 in epoch 4, gen_loss = 0.4088648708164692, disc_loss = 0.07219157398212701
Trained batch 200 in epoch 4, gen_loss = 0.40881862168881433, disc_loss = 0.07204731420813064
Trained batch 201 in epoch 4, gen_loss = 0.408663605846981, disc_loss = 0.07174564852831092
Trained batch 202 in epoch 4, gen_loss = 0.40883668405669077, disc_loss = 0.07195916084636902
Trained batch 203 in epoch 4, gen_loss = 0.4084652283904599, disc_loss = 0.07243880946371778
Trained batch 204 in epoch 4, gen_loss = 0.40883381962776183, disc_loss = 0.07314896971532485
Trained batch 205 in epoch 4, gen_loss = 0.408364524251049, disc_loss = 0.07345881966819752
Trained batch 206 in epoch 4, gen_loss = 0.4081099656756949, disc_loss = 0.07344358255141888
Trained batch 207 in epoch 4, gen_loss = 0.4077708820024362, disc_loss = 0.07413880321949434
Trained batch 208 in epoch 4, gen_loss = 0.4075330947860006, disc_loss = 0.07483867540706003
Trained batch 209 in epoch 4, gen_loss = 0.40749347295079913, disc_loss = 0.07467815160219159
Trained batch 210 in epoch 4, gen_loss = 0.4076116395787605, disc_loss = 0.0747082125466158
Trained batch 211 in epoch 4, gen_loss = 0.40753940113310544, disc_loss = 0.07473519919791592
Trained batch 212 in epoch 4, gen_loss = 0.4075891288793143, disc_loss = 0.07449024949799961
Trained batch 213 in epoch 4, gen_loss = 0.40778780874804915, disc_loss = 0.07432984514597142
Trained batch 214 in epoch 4, gen_loss = 0.40759876689245533, disc_loss = 0.07412440104540004
Trained batch 215 in epoch 4, gen_loss = 0.40736070054548756, disc_loss = 0.07388955789307754
Trained batch 216 in epoch 4, gen_loss = 0.4076623911132461, disc_loss = 0.07375017512366519
Trained batch 217 in epoch 4, gen_loss = 0.4074259102344513, disc_loss = 0.07346623940735099
Trained batch 218 in epoch 4, gen_loss = 0.407521646861072, disc_loss = 0.07322674523188508
Trained batch 219 in epoch 4, gen_loss = 0.4075538602742282, disc_loss = 0.07296890149485659
Trained batch 220 in epoch 4, gen_loss = 0.4073055311026077, disc_loss = 0.07274269028166436
Trained batch 221 in epoch 4, gen_loss = 0.4078126759142489, disc_loss = 0.07245581271126866
Trained batch 222 in epoch 4, gen_loss = 0.40792367918074396, disc_loss = 0.07220756512703248
Trained batch 223 in epoch 4, gen_loss = 0.40803378474499497, disc_loss = 0.07201376056348506
Trained batch 224 in epoch 4, gen_loss = 0.4081309731801351, disc_loss = 0.07176900114036269
Trained batch 225 in epoch 4, gen_loss = 0.40820451687395043, disc_loss = 0.07148950599727377
Trained batch 226 in epoch 4, gen_loss = 0.4082459244171428, disc_loss = 0.07126396705728795
Trained batch 227 in epoch 4, gen_loss = 0.4084796096410668, disc_loss = 0.07097961172755611
Trained batch 228 in epoch 4, gen_loss = 0.40870741139853367, disc_loss = 0.07072649769663941
Trained batch 229 in epoch 4, gen_loss = 0.4083863457907801, disc_loss = 0.07081446793821194
Trained batch 230 in epoch 4, gen_loss = 0.40871242617631887, disc_loss = 0.07172319980426914
Trained batch 231 in epoch 4, gen_loss = 0.4084012915605101, disc_loss = 0.07175846183110543
Trained batch 232 in epoch 4, gen_loss = 0.40787573523275844, disc_loss = 0.07182111617081795
Trained batch 233 in epoch 4, gen_loss = 0.40771896525835377, disc_loss = 0.0722559916261488
Trained batch 234 in epoch 4, gen_loss = 0.40811459219202084, disc_loss = 0.0721517297062785
Trained batch 235 in epoch 4, gen_loss = 0.4079191877932872, disc_loss = 0.07260592773130511
Trained batch 236 in epoch 4, gen_loss = 0.4077765397130185, disc_loss = 0.07238423958310723
Trained batch 237 in epoch 4, gen_loss = 0.4077690347653477, disc_loss = 0.0728893397305505
Trained batch 238 in epoch 4, gen_loss = 0.40752564588850015, disc_loss = 0.07282622436365448
Trained batch 239 in epoch 4, gen_loss = 0.40740798053642113, disc_loss = 0.07274175268054629
Trained batch 240 in epoch 4, gen_loss = 0.4073561220990177, disc_loss = 0.07265838925413695
Trained batch 241 in epoch 4, gen_loss = 0.407261804485124, disc_loss = 0.07248745252539919
Trained batch 242 in epoch 4, gen_loss = 0.4069467883541751, disc_loss = 0.07258779059237046
Trained batch 243 in epoch 4, gen_loss = 0.4071689616949832, disc_loss = 0.0735671183468438
Trained batch 244 in epoch 4, gen_loss = 0.40709986844841317, disc_loss = 0.07366564170818547
Trained batch 245 in epoch 4, gen_loss = 0.4073416425929806, disc_loss = 0.07346404276833665
Trained batch 246 in epoch 4, gen_loss = 0.4074692810595277, disc_loss = 0.07323904593780577
Trained batch 247 in epoch 4, gen_loss = 0.4076607579425458, disc_loss = 0.0729938686464823
Trained batch 248 in epoch 4, gen_loss = 0.40789130796869116, disc_loss = 0.07278542436030974
Trained batch 249 in epoch 4, gen_loss = 0.4078736548423767, disc_loss = 0.07253362264856696
Trained batch 250 in epoch 4, gen_loss = 0.4075488972948842, disc_loss = 0.07250785295929447
Trained batch 251 in epoch 4, gen_loss = 0.4079470844968917, disc_loss = 0.07234124009615726
Trained batch 252 in epoch 4, gen_loss = 0.40797617312947754, disc_loss = 0.07209347344920215
Trained batch 253 in epoch 4, gen_loss = 0.407940664394634, disc_loss = 0.07186083969344774
Trained batch 254 in epoch 4, gen_loss = 0.407748349273906, disc_loss = 0.07163897491626295
Trained batch 255 in epoch 4, gen_loss = 0.4077266219537705, disc_loss = 0.07162734146186267
Trained batch 256 in epoch 4, gen_loss = 0.40739602221589144, disc_loss = 0.07196341688719357
Trained batch 257 in epoch 4, gen_loss = 0.4073670486840167, disc_loss = 0.07190004989230471
Trained batch 258 in epoch 4, gen_loss = 0.4074346610708126, disc_loss = 0.07173700858281501
Trained batch 259 in epoch 4, gen_loss = 0.40743857817007945, disc_loss = 0.07152141251314718
Trained batch 260 in epoch 4, gen_loss = 0.40736355144402076, disc_loss = 0.07148670760907547
Trained batch 261 in epoch 4, gen_loss = 0.4075513960978457, disc_loss = 0.07129912411452818
Trained batch 262 in epoch 4, gen_loss = 0.407699683999834, disc_loss = 0.07114328483310829
Trained batch 263 in epoch 4, gen_loss = 0.4079580234758782, disc_loss = 0.07090523974814762
Trained batch 264 in epoch 4, gen_loss = 0.40796444910877155, disc_loss = 0.07081546051392577
Trained batch 265 in epoch 4, gen_loss = 0.40831389059697776, disc_loss = 0.07060013239138893
Trained batch 266 in epoch 4, gen_loss = 0.40843535742063203, disc_loss = 0.07052359856623278
Trained batch 267 in epoch 4, gen_loss = 0.40822603742578134, disc_loss = 0.07029985969038263
Trained batch 268 in epoch 4, gen_loss = 0.40834424287413135, disc_loss = 0.07007254063598396
Trained batch 269 in epoch 4, gen_loss = 0.4087581738277718, disc_loss = 0.0698730262444803
Trained batch 270 in epoch 4, gen_loss = 0.40873521588385325, disc_loss = 0.0697388706550112
Trained batch 271 in epoch 4, gen_loss = 0.4085853492074153, disc_loss = 0.06950971795252853
Trained batch 272 in epoch 4, gen_loss = 0.40866764048080306, disc_loss = 0.0693685060568263
Trained batch 273 in epoch 4, gen_loss = 0.40903756772949745, disc_loss = 0.06915691219113876
Trained batch 274 in epoch 4, gen_loss = 0.4090903016653928, disc_loss = 0.06896683016453277
Trained batch 275 in epoch 4, gen_loss = 0.4090301287562951, disc_loss = 0.06879033444726003
Trained batch 276 in epoch 4, gen_loss = 0.4088394099624579, disc_loss = 0.06856956216086388
Trained batch 277 in epoch 4, gen_loss = 0.40903026530210923, disc_loss = 0.06835146362410871
Trained batch 278 in epoch 4, gen_loss = 0.4091572776490215, disc_loss = 0.06813887639078028
Trained batch 279 in epoch 4, gen_loss = 0.4091246650687286, disc_loss = 0.06800096200147111
Trained batch 280 in epoch 4, gen_loss = 0.4091883742936565, disc_loss = 0.06800609742360872
Trained batch 281 in epoch 4, gen_loss = 0.40924863527852595, disc_loss = 0.0679238292517418
Trained batch 282 in epoch 4, gen_loss = 0.40912422727359055, disc_loss = 0.06773710182239384
Trained batch 283 in epoch 4, gen_loss = 0.40932072604625996, disc_loss = 0.06759606441318937
Trained batch 284 in epoch 4, gen_loss = 0.40945912693676195, disc_loss = 0.06738713427299732
Trained batch 285 in epoch 4, gen_loss = 0.4099464073672995, disc_loss = 0.06721184494371128
Trained batch 286 in epoch 4, gen_loss = 0.4098895544166764, disc_loss = 0.06700669421298423
Trained batch 287 in epoch 4, gen_loss = 0.40965285721338457, disc_loss = 0.06680357140107339
Trained batch 288 in epoch 4, gen_loss = 0.4096008674289941, disc_loss = 0.06660707392101418
Trained batch 289 in epoch 4, gen_loss = 0.40948870973340395, disc_loss = 0.06639440672729036
Trained batch 290 in epoch 4, gen_loss = 0.40953490670603987, disc_loss = 0.06618641398501457
Trained batch 291 in epoch 4, gen_loss = 0.4096609573454073, disc_loss = 0.06600136015474899
Trained batch 292 in epoch 4, gen_loss = 0.4096472685450987, disc_loss = 0.06580231097962314
Trained batch 293 in epoch 4, gen_loss = 0.4095332900277611, disc_loss = 0.06561808616752882
Trained batch 294 in epoch 4, gen_loss = 0.4096708175489458, disc_loss = 0.06543941381150635
Trained batch 295 in epoch 4, gen_loss = 0.40959879836520635, disc_loss = 0.06523324159206823
Trained batch 296 in epoch 4, gen_loss = 0.41005954236695263, disc_loss = 0.06503418412667884
Trained batch 297 in epoch 4, gen_loss = 0.410401391903026, disc_loss = 0.06483679982496038
Trained batch 298 in epoch 4, gen_loss = 0.4105269588953675, disc_loss = 0.0646648441354143
Trained batch 299 in epoch 4, gen_loss = 0.41064547369877497, disc_loss = 0.06464441500448932
Trained batch 300 in epoch 4, gen_loss = 0.41054122966785367, disc_loss = 0.06461524612972655
Trained batch 301 in epoch 4, gen_loss = 0.41055640301957036, disc_loss = 0.06441600404106179
Trained batch 302 in epoch 4, gen_loss = 0.4105601666784129, disc_loss = 0.06429116182465709
Trained batch 303 in epoch 4, gen_loss = 0.4106451185714257, disc_loss = 0.06410320361733045
Trained batch 304 in epoch 4, gen_loss = 0.4110764180050522, disc_loss = 0.06392234212673101
Trained batch 305 in epoch 4, gen_loss = 0.4111591844387304, disc_loss = 0.06377310306442524
Trained batch 306 in epoch 4, gen_loss = 0.41129135493346847, disc_loss = 0.06359571399901318
Trained batch 307 in epoch 4, gen_loss = 0.4111905536287791, disc_loss = 0.06341602183370428
Trained batch 308 in epoch 4, gen_loss = 0.4112953730771457, disc_loss = 0.06323200824721731
Trained batch 309 in epoch 4, gen_loss = 0.4112330856823152, disc_loss = 0.06306536507402216
Trained batch 310 in epoch 4, gen_loss = 0.41141074838362324, disc_loss = 0.06289771812222299
Trained batch 311 in epoch 4, gen_loss = 0.4115046696403088, disc_loss = 0.0627311072879447
Trained batch 312 in epoch 4, gen_loss = 0.41185434919576674, disc_loss = 0.06255759533566123
Trained batch 313 in epoch 4, gen_loss = 0.4116865426871427, disc_loss = 0.06237441444603406
Trained batch 314 in epoch 4, gen_loss = 0.4120216231497507, disc_loss = 0.062195685619695316
Trained batch 315 in epoch 4, gen_loss = 0.4119496701073043, disc_loss = 0.06202067870976804
Trained batch 316 in epoch 4, gen_loss = 0.41189409759518475, disc_loss = 0.06185469404156746
Trained batch 317 in epoch 4, gen_loss = 0.4119460240662473, disc_loss = 0.06168321907555439
Trained batch 318 in epoch 4, gen_loss = 0.4118549856459459, disc_loss = 0.06165871937061459
Trained batch 319 in epoch 4, gen_loss = 0.41215077312663195, disc_loss = 0.06160214644332882
Trained batch 320 in epoch 4, gen_loss = 0.41229147489568524, disc_loss = 0.06145683049610192
Trained batch 321 in epoch 4, gen_loss = 0.41223024377911727, disc_loss = 0.06129621262864574
Trained batch 322 in epoch 4, gen_loss = 0.41233160565881166, disc_loss = 0.06112468006066263
Trained batch 323 in epoch 4, gen_loss = 0.4123470233178433, disc_loss = 0.06097163352971598
Trained batch 324 in epoch 4, gen_loss = 0.41232239979964036, disc_loss = 0.06081669067963958
Trained batch 325 in epoch 4, gen_loss = 0.4125704917073981, disc_loss = 0.06083053659984808
Trained batch 326 in epoch 4, gen_loss = 0.41252755271185426, disc_loss = 0.06069386310573519
Trained batch 327 in epoch 4, gen_loss = 0.41246321088657145, disc_loss = 0.06055317121904298
Trained batch 328 in epoch 4, gen_loss = 0.4123729173897972, disc_loss = 0.06041192137537167
Trained batch 329 in epoch 4, gen_loss = 0.41232307399764206, disc_loss = 0.06024626695381647
Trained batch 330 in epoch 4, gen_loss = 0.4123889666129455, disc_loss = 0.06011822114465055
Trained batch 331 in epoch 4, gen_loss = 0.41256888237703276, disc_loss = 0.060016813052604985
Trained batch 332 in epoch 4, gen_loss = 0.4124149553947621, disc_loss = 0.059857149053275494
Trained batch 333 in epoch 4, gen_loss = 0.41229529741281523, disc_loss = 0.06005408037816381
Trained batch 334 in epoch 4, gen_loss = 0.41234718561172484, disc_loss = 0.06026037360555423
Trained batch 335 in epoch 4, gen_loss = 0.4124728020812784, disc_loss = 0.06011667490210606
Trained batch 336 in epoch 4, gen_loss = 0.41244914703270097, disc_loss = 0.060132463201493555
Trained batch 337 in epoch 4, gen_loss = 0.4124198912163458, disc_loss = 0.060133487775580155
Trained batch 338 in epoch 4, gen_loss = 0.41236959270319756, disc_loss = 0.05998938361314678
Trained batch 339 in epoch 4, gen_loss = 0.4122641336391954, disc_loss = 0.059842191290055566
Trained batch 340 in epoch 4, gen_loss = 0.41214419381359807, disc_loss = 0.059725779443269164
Trained batch 341 in epoch 4, gen_loss = 0.41212078170818195, disc_loss = 0.059608707273901815
Trained batch 342 in epoch 4, gen_loss = 0.4119911393688302, disc_loss = 0.05947639429996078
Trained batch 343 in epoch 4, gen_loss = 0.41211977713676384, disc_loss = 0.059384143539043796
Trained batch 344 in epoch 4, gen_loss = 0.41215403745139856, disc_loss = 0.05924079067384203
Trained batch 345 in epoch 4, gen_loss = 0.41213486709691194, disc_loss = 0.05911655799550344
Trained batch 346 in epoch 4, gen_loss = 0.4122216396613492, disc_loss = 0.058961275044388486
Trained batch 347 in epoch 4, gen_loss = 0.41223948551663037, disc_loss = 0.058945301655230334
Trained batch 348 in epoch 4, gen_loss = 0.4121486484833638, disc_loss = 0.059039163760798194
Trained batch 349 in epoch 4, gen_loss = 0.4123727689470564, disc_loss = 0.05890308554417321
Trained batch 350 in epoch 4, gen_loss = 0.41216800567770956, disc_loss = 0.05891439055180193
Trained batch 351 in epoch 4, gen_loss = 0.4121597037565979, disc_loss = 0.058799935057653456
Trained batch 352 in epoch 4, gen_loss = 0.4120774563750194, disc_loss = 0.05873027630414149
Trained batch 353 in epoch 4, gen_loss = 0.4123531410754737, disc_loss = 0.05881975490947144
Trained batch 354 in epoch 4, gen_loss = 0.41213796088393306, disc_loss = 0.058840317444377385
Trained batch 355 in epoch 4, gen_loss = 0.4122331502397409, disc_loss = 0.05871880860486476
Trained batch 356 in epoch 4, gen_loss = 0.4123361790213598, disc_loss = 0.05884089982737096
Trained batch 357 in epoch 4, gen_loss = 0.4123271214229435, disc_loss = 0.059111517820215925
Trained batch 358 in epoch 4, gen_loss = 0.41237028968367406, disc_loss = 0.05920727003345001
Trained batch 359 in epoch 4, gen_loss = 0.41256913700037534, disc_loss = 0.059080628554026286
Trained batch 360 in epoch 4, gen_loss = 0.4126780655575591, disc_loss = 0.058949654333685576
Trained batch 361 in epoch 4, gen_loss = 0.4125677210520644, disc_loss = 0.058877649552379195
Trained batch 362 in epoch 4, gen_loss = 0.4127529683027714, disc_loss = 0.058789317016348694
Trained batch 363 in epoch 4, gen_loss = 0.4126367674587847, disc_loss = 0.05865748248134668
Trained batch 364 in epoch 4, gen_loss = 0.4127003590538077, disc_loss = 0.05852856671769325
Trained batch 365 in epoch 4, gen_loss = 0.4126546022181954, disc_loss = 0.058490155101881
Trained batch 366 in epoch 4, gen_loss = 0.4126316635420277, disc_loss = 0.058593310547703295
Trained batch 367 in epoch 4, gen_loss = 0.4127465510012015, disc_loss = 0.058481352454375315
Trained batch 368 in epoch 4, gen_loss = 0.41271946076455157, disc_loss = 0.05840339853875036
Trained batch 369 in epoch 4, gen_loss = 0.41269661590859696, disc_loss = 0.0582753384032765
Trained batch 370 in epoch 4, gen_loss = 0.41249478425619734, disc_loss = 0.058308469136609545
Trained batch 371 in epoch 4, gen_loss = 0.41265955327018616, disc_loss = 0.05867044493475909
Trained batch 372 in epoch 4, gen_loss = 0.4125367534064735, disc_loss = 0.058725757888910275
Trained batch 373 in epoch 4, gen_loss = 0.4124698733741587, disc_loss = 0.058626054163603857
Trained batch 374 in epoch 4, gen_loss = 0.41246002006530763, disc_loss = 0.05856567557652791
Trained batch 375 in epoch 4, gen_loss = 0.4123663883259956, disc_loss = 0.05849574580590459
Trained batch 376 in epoch 4, gen_loss = 0.4124055612308593, disc_loss = 0.05836774490091861
Trained batch 377 in epoch 4, gen_loss = 0.4124035662601864, disc_loss = 0.058254190538295364
Trained batch 378 in epoch 4, gen_loss = 0.4124143739331681, disc_loss = 0.0581749748674499
Trained batch 379 in epoch 4, gen_loss = 0.41254470826763856, disc_loss = 0.0580582710424144
Trained batch 380 in epoch 4, gen_loss = 0.412706444269716, disc_loss = 0.057922466557834715
Trained batch 381 in epoch 4, gen_loss = 0.4127867073600829, disc_loss = 0.05781656246222751
Trained batch 382 in epoch 4, gen_loss = 0.41257552207294396, disc_loss = 0.05773907294375311
Trained batch 383 in epoch 4, gen_loss = 0.4126878014455239, disc_loss = 0.057704642837052234
Trained batch 384 in epoch 4, gen_loss = 0.412558344819329, disc_loss = 0.05787916628087496
Trained batch 385 in epoch 4, gen_loss = 0.41262949493573736, disc_loss = 0.058127216410876245
Trained batch 386 in epoch 4, gen_loss = 0.41247212263040767, disc_loss = 0.058083503018554486
Trained batch 387 in epoch 4, gen_loss = 0.41243724440483703, disc_loss = 0.05799378098958393
Trained batch 388 in epoch 4, gen_loss = 0.4123529489978114, disc_loss = 0.05787934614752436
Trained batch 389 in epoch 4, gen_loss = 0.4123778534241212, disc_loss = 0.05781337824196388
Trained batch 390 in epoch 4, gen_loss = 0.41238195252845355, disc_loss = 0.05774939474661637
Trained batch 391 in epoch 4, gen_loss = 0.41233368620884664, disc_loss = 0.05765458616447084
Trained batch 392 in epoch 4, gen_loss = 0.412298345383797, disc_loss = 0.05754864404011167
Trained batch 393 in epoch 4, gen_loss = 0.41218892057535006, disc_loss = 0.05744392601158564
Trained batch 394 in epoch 4, gen_loss = 0.4120485557031028, disc_loss = 0.057354361351720895
Trained batch 395 in epoch 4, gen_loss = 0.4120541366212296, disc_loss = 0.05762045258994807
Trained batch 396 in epoch 4, gen_loss = 0.41209688204662026, disc_loss = 0.057544391963546465
Trained batch 397 in epoch 4, gen_loss = 0.4122476769452119, disc_loss = 0.05809128985988285
Trained batch 398 in epoch 4, gen_loss = 0.41257553515876444, disc_loss = 0.05912626825534461
Trained batch 399 in epoch 4, gen_loss = 0.41250364258885386, disc_loss = 0.059029028150252995
Trained batch 400 in epoch 4, gen_loss = 0.4124401921494643, disc_loss = 0.05919973273062498
Trained batch 401 in epoch 4, gen_loss = 0.4124116613645459, disc_loss = 0.0591417395588548
Trained batch 402 in epoch 4, gen_loss = 0.4124541393580567, disc_loss = 0.05911280097851238
Trained batch 403 in epoch 4, gen_loss = 0.4124766332973348, disc_loss = 0.05908037478214886
Trained batch 404 in epoch 4, gen_loss = 0.4121911536028356, disc_loss = 0.059731096245440436
Trained batch 405 in epoch 4, gen_loss = 0.41206529215345244, disc_loss = 0.05986459244483063
Trained batch 406 in epoch 4, gen_loss = 0.41217440579095693, disc_loss = 0.06068721164191824
Trained batch 407 in epoch 4, gen_loss = 0.41200625421661957, disc_loss = 0.06100467285232655
Trained batch 408 in epoch 4, gen_loss = 0.4119013082281593, disc_loss = 0.06136614120221517
Trained batch 409 in epoch 4, gen_loss = 0.4118809670209885, disc_loss = 0.06180117762215981
Trained batch 410 in epoch 4, gen_loss = 0.4118959546959313, disc_loss = 0.06212671474075521
Trained batch 411 in epoch 4, gen_loss = 0.41169480205450243, disc_loss = 0.06257595848382531
Trained batch 412 in epoch 4, gen_loss = 0.41148662891861315, disc_loss = 0.06285039499203604
Trained batch 413 in epoch 4, gen_loss = 0.4113037412725209, disc_loss = 0.06293363094887727
Trained batch 414 in epoch 4, gen_loss = 0.4112310003803437, disc_loss = 0.06305824765509152
Trained batch 415 in epoch 4, gen_loss = 0.4111212238382835, disc_loss = 0.06322903565328139
Trained batch 416 in epoch 4, gen_loss = 0.41082186543112464, disc_loss = 0.06405022904294715
Trained batch 417 in epoch 4, gen_loss = 0.41070011379330923, disc_loss = 0.06419999954072339
Trained batch 418 in epoch 4, gen_loss = 0.4106076331297936, disc_loss = 0.06437264428627378
Trained batch 419 in epoch 4, gen_loss = 0.4104927789597284, disc_loss = 0.06435830995351785
Trained batch 420 in epoch 4, gen_loss = 0.4105706874661661, disc_loss = 0.06427520479024731
Trained batch 421 in epoch 4, gen_loss = 0.4107643565719162, disc_loss = 0.06417476931383824
Trained batch 422 in epoch 4, gen_loss = 0.4106409788554442, disc_loss = 0.06411179465992513
Trained batch 423 in epoch 4, gen_loss = 0.4106325528953435, disc_loss = 0.06407474172038008
Trained batch 424 in epoch 4, gen_loss = 0.41069118289386525, disc_loss = 0.06402095280149404
Trained batch 425 in epoch 4, gen_loss = 0.41093885450855666, disc_loss = 0.06392457231686849
Trained batch 426 in epoch 4, gen_loss = 0.41098329578406356, disc_loss = 0.0638038023904978
Trained batch 427 in epoch 4, gen_loss = 0.4112869423822822, disc_loss = 0.06378237098873218
Trained batch 428 in epoch 4, gen_loss = 0.41114714825069987, disc_loss = 0.06383133530269414
Trained batch 429 in epoch 4, gen_loss = 0.41126008622868115, disc_loss = 0.06379666644646678
Trained batch 430 in epoch 4, gen_loss = 0.4112225486756477, disc_loss = 0.0638005348946683
Trained batch 431 in epoch 4, gen_loss = 0.41129774965897753, disc_loss = 0.06376080543527173
Trained batch 432 in epoch 4, gen_loss = 0.41129503053275324, disc_loss = 0.06370416542571081
Trained batch 433 in epoch 4, gen_loss = 0.4112081233806874, disc_loss = 0.06383608136549249
Trained batch 434 in epoch 4, gen_loss = 0.41130268971125283, disc_loss = 0.06437102247072363
Trained batch 435 in epoch 4, gen_loss = 0.4111293351978337, disc_loss = 0.06456481346672555
Trained batch 436 in epoch 4, gen_loss = 0.41105857130046297, disc_loss = 0.06446258777441367
Trained batch 437 in epoch 4, gen_loss = 0.41107897970774404, disc_loss = 0.06443590284686655
Trained batch 438 in epoch 4, gen_loss = 0.41126019353204, disc_loss = 0.06440303166628156
Trained batch 439 in epoch 4, gen_loss = 0.4112603695555167, disc_loss = 0.06429921789941463
Trained batch 440 in epoch 4, gen_loss = 0.4113437809776557, disc_loss = 0.06423834713002721
Trained batch 441 in epoch 4, gen_loss = 0.41130003805074217, disc_loss = 0.06423292904080849
Trained batch 442 in epoch 4, gen_loss = 0.41106608321650573, disc_loss = 0.06486851304904064
Trained batch 443 in epoch 4, gen_loss = 0.4111033999570855, disc_loss = 0.06525271468133002
Trained batch 444 in epoch 4, gen_loss = 0.4109299069040277, disc_loss = 0.06519616595312451
Trained batch 445 in epoch 4, gen_loss = 0.4110057614576656, disc_loss = 0.06515179930313286
Trained batch 446 in epoch 4, gen_loss = 0.41091737524508365, disc_loss = 0.06519637198522854
Trained batch 447 in epoch 4, gen_loss = 0.41090264324364917, disc_loss = 0.0651308315656414
Trained batch 448 in epoch 4, gen_loss = 0.41081111766978734, disc_loss = 0.06506424493473728
Trained batch 449 in epoch 4, gen_loss = 0.4107594461573495, disc_loss = 0.06498829767107964
Trained batch 450 in epoch 4, gen_loss = 0.4107191800542523, disc_loss = 0.06489324180652985
Trained batch 451 in epoch 4, gen_loss = 0.41086682044299305, disc_loss = 0.06479791169409203
Trained batch 452 in epoch 4, gen_loss = 0.41076299350782736, disc_loss = 0.06472198813166839
Trained batch 453 in epoch 4, gen_loss = 0.41076925521642627, disc_loss = 0.06463911519734607
Trained batch 454 in epoch 4, gen_loss = 0.4108213029064975, disc_loss = 0.06452693638729524
Trained batch 455 in epoch 4, gen_loss = 0.4107674426938358, disc_loss = 0.06442070643727978
Trained batch 456 in epoch 4, gen_loss = 0.410823108461284, disc_loss = 0.06430855128278291
Trained batch 457 in epoch 4, gen_loss = 0.41080657623740785, disc_loss = 0.06418737923872848
Trained batch 458 in epoch 4, gen_loss = 0.41087000464821694, disc_loss = 0.06411405723168634
Trained batch 459 in epoch 4, gen_loss = 0.41073434417662413, disc_loss = 0.06403500554961679
Trained batch 460 in epoch 4, gen_loss = 0.4107221062426453, disc_loss = 0.06391621654380493
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 0.431235134601593, disc_loss = 0.017911996692419052
Trained batch 1 in epoch 5, gen_loss = 0.42455583810806274, disc_loss = 0.023886081762611866
Trained batch 2 in epoch 5, gen_loss = 0.41334065794944763, disc_loss = 0.01994902951021989
Trained batch 3 in epoch 5, gen_loss = 0.41958922892808914, disc_loss = 0.018980756867676973
Trained batch 4 in epoch 5, gen_loss = 0.41327313184738157, disc_loss = 0.016978044435381888
Trained batch 5 in epoch 5, gen_loss = 0.39918117721875507, disc_loss = 0.02549195010215044
Trained batch 6 in epoch 5, gen_loss = 0.40192378418786184, disc_loss = 0.035938692678298266
Trained batch 7 in epoch 5, gen_loss = 0.407938152551651, disc_loss = 0.03270958480425179
Trained batch 8 in epoch 5, gen_loss = 0.41116271085209316, disc_loss = 0.031655380916264325
Trained batch 9 in epoch 5, gen_loss = 0.42045678794384, disc_loss = 0.02955389190465212
Trained batch 10 in epoch 5, gen_loss = 0.42090332779017364, disc_loss = 0.027431908825581722
Trained batch 11 in epoch 5, gen_loss = 0.4194122478365898, disc_loss = 0.027515871295084555
Trained batch 12 in epoch 5, gen_loss = 0.42515106384570783, disc_loss = 0.02872871306653206
Trained batch 13 in epoch 5, gen_loss = 0.42854781661714825, disc_loss = 0.02741283524249281
Trained batch 14 in epoch 5, gen_loss = 0.43893483877182005, disc_loss = 0.028170946488777795
Trained batch 15 in epoch 5, gen_loss = 0.44067735597491264, disc_loss = 0.028441440081223845
Trained batch 16 in epoch 5, gen_loss = 0.4396622110815609, disc_loss = 0.027962615165640328
Trained batch 17 in epoch 5, gen_loss = 0.43541502621438766, disc_loss = 0.028077711247735553
Trained batch 18 in epoch 5, gen_loss = 0.43695510688580963, disc_loss = 0.02752280568605975
Trained batch 19 in epoch 5, gen_loss = 0.43394020944833755, disc_loss = 0.027383549697697164
Trained batch 20 in epoch 5, gen_loss = 0.429841704311825, disc_loss = 0.029114430326791035
Trained batch 21 in epoch 5, gen_loss = 0.4295981526374817, disc_loss = 0.02808444354344498
Trained batch 22 in epoch 5, gen_loss = 0.4325467490631601, disc_loss = 0.02884002920726071
Trained batch 23 in epoch 5, gen_loss = 0.43032218391696614, disc_loss = 0.030692648297796648
Trained batch 24 in epoch 5, gen_loss = 0.43278116822242735, disc_loss = 0.031284040659666064
Trained batch 25 in epoch 5, gen_loss = 0.43070130623303926, disc_loss = 0.0304607804864645
Trained batch 26 in epoch 5, gen_loss = 0.4290558762020535, disc_loss = 0.029723542225029733
Trained batch 27 in epoch 5, gen_loss = 0.42795989555971964, disc_loss = 0.030235386919230223
Trained batch 28 in epoch 5, gen_loss = 0.4292101921706364, disc_loss = 0.02945691735708508
Trained batch 29 in epoch 5, gen_loss = 0.431407497326533, disc_loss = 0.02912665397549669
Trained batch 30 in epoch 5, gen_loss = 0.4295507573312329, disc_loss = 0.028766684264184966
Trained batch 31 in epoch 5, gen_loss = 0.42838403210043907, disc_loss = 0.0285808072949294
Trained batch 32 in epoch 5, gen_loss = 0.43151601697459363, disc_loss = 0.02794113059556394
Trained batch 33 in epoch 5, gen_loss = 0.4325377388912089, disc_loss = 0.027448647641850746
Trained batch 34 in epoch 5, gen_loss = 0.43190129058701654, disc_loss = 0.027377197186329534
Trained batch 35 in epoch 5, gen_loss = 0.4307846832606528, disc_loss = 0.026836860161792073
Trained batch 36 in epoch 5, gen_loss = 0.4290310925728566, disc_loss = 0.026260560516872117
Trained batch 37 in epoch 5, gen_loss = 0.42809956560009405, disc_loss = 0.026121505376833835
Trained batch 38 in epoch 5, gen_loss = 0.4270742871822455, disc_loss = 0.025699560184222765
Trained batch 39 in epoch 5, gen_loss = 0.4280779756605625, disc_loss = 0.025449258892331274
Trained batch 40 in epoch 5, gen_loss = 0.4268562939108872, disc_loss = 0.02524314022327705
Trained batch 41 in epoch 5, gen_loss = 0.42576823560964494, disc_loss = 0.025828976017822112
Trained batch 42 in epoch 5, gen_loss = 0.42637524216674094, disc_loss = 0.025355163073643695
Trained batch 43 in epoch 5, gen_loss = 0.427102655172348, disc_loss = 0.025125147309154272
Trained batch 44 in epoch 5, gen_loss = 0.4266636802090539, disc_loss = 0.024683305910891958
Trained batch 45 in epoch 5, gen_loss = 0.4274561392224353, disc_loss = 0.0248889474036253
Trained batch 46 in epoch 5, gen_loss = 0.42615814602121393, disc_loss = 0.024643340960462043
Trained batch 47 in epoch 5, gen_loss = 0.4238343524436156, disc_loss = 0.024990620790049434
Trained batch 48 in epoch 5, gen_loss = 0.424112259125223, disc_loss = 0.025141550266012853
Trained batch 49 in epoch 5, gen_loss = 0.4246955341100693, disc_loss = 0.024972275868058204
Trained batch 50 in epoch 5, gen_loss = 0.42523955889776643, disc_loss = 0.024934223834790437
Trained batch 51 in epoch 5, gen_loss = 0.42510880873753476, disc_loss = 0.024663512505447634
Trained batch 52 in epoch 5, gen_loss = 0.4259947184121834, disc_loss = 0.024732447018460283
Trained batch 53 in epoch 5, gen_loss = 0.4235871395579091, disc_loss = 0.025257666129618883
Trained batch 54 in epoch 5, gen_loss = 0.4249782383441925, disc_loss = 0.02540149422870441
Trained batch 55 in epoch 5, gen_loss = 0.4228435403534344, disc_loss = 0.026153146073089113
Trained batch 56 in epoch 5, gen_loss = 0.42213211143225954, disc_loss = 0.027928306525082963
Trained batch 57 in epoch 5, gen_loss = 0.4225630385094675, disc_loss = 0.027895992734180444
Trained batch 58 in epoch 5, gen_loss = 0.42306523706953403, disc_loss = 0.027895927287133065
Trained batch 59 in epoch 5, gen_loss = 0.42273624390363695, disc_loss = 0.0275996084480236
Trained batch 60 in epoch 5, gen_loss = 0.42094724344425516, disc_loss = 0.02749691425715802
Trained batch 61 in epoch 5, gen_loss = 0.42169649033777173, disc_loss = 0.02740782065196864
Trained batch 62 in epoch 5, gen_loss = 0.42129219382528277, disc_loss = 0.02727785598604925
Trained batch 63 in epoch 5, gen_loss = 0.42095207376405597, disc_loss = 0.027674198252498172
Trained batch 64 in epoch 5, gen_loss = 0.4214768914075998, disc_loss = 0.027516274455075082
Trained batch 65 in epoch 5, gen_loss = 0.42186199128627777, disc_loss = 0.027255412021821194
Trained batch 66 in epoch 5, gen_loss = 0.4224704219334161, disc_loss = 0.02692822897945767
Trained batch 67 in epoch 5, gen_loss = 0.4199877508422908, disc_loss = 0.027504309765337145
Trained batch 68 in epoch 5, gen_loss = 0.42071766222732654, disc_loss = 0.02936688667514186
Trained batch 69 in epoch 5, gen_loss = 0.4209226991449084, disc_loss = 0.02962289268949202
Trained batch 70 in epoch 5, gen_loss = 0.42064819453467783, disc_loss = 0.029660224468565324
Trained batch 71 in epoch 5, gen_loss = 0.4198319965766536, disc_loss = 0.03065898018475208
Trained batch 72 in epoch 5, gen_loss = 0.4188330075512194, disc_loss = 0.030819628719393522
Trained batch 73 in epoch 5, gen_loss = 0.4196397867557165, disc_loss = 0.030636453598334983
Trained batch 74 in epoch 5, gen_loss = 0.4202502695719401, disc_loss = 0.030313901603221893
Trained batch 75 in epoch 5, gen_loss = 0.4194671311660817, disc_loss = 0.02999163107137735
Trained batch 76 in epoch 5, gen_loss = 0.41927559344799487, disc_loss = 0.029852592803586226
Trained batch 77 in epoch 5, gen_loss = 0.4194228458098876, disc_loss = 0.029693696952353302
Trained batch 78 in epoch 5, gen_loss = 0.4189522455010233, disc_loss = 0.029705247328958555
Trained batch 79 in epoch 5, gen_loss = 0.4180101063102484, disc_loss = 0.029512914578663185
Trained batch 80 in epoch 5, gen_loss = 0.419151426465423, disc_loss = 0.029270193568304365
Trained batch 81 in epoch 5, gen_loss = 0.4203505134437142, disc_loss = 0.029071678924260706
Trained batch 82 in epoch 5, gen_loss = 0.42057607619159193, disc_loss = 0.02880536768787417
Trained batch 83 in epoch 5, gen_loss = 0.4204748035186813, disc_loss = 0.028583154908292704
Trained batch 84 in epoch 5, gen_loss = 0.4198337958139532, disc_loss = 0.02858800456913955
Trained batch 85 in epoch 5, gen_loss = 0.42010022595871327, disc_loss = 0.02913969554288616
Trained batch 86 in epoch 5, gen_loss = 0.4191086446416789, disc_loss = 0.02923663515576172
Trained batch 87 in epoch 5, gen_loss = 0.4191730527037924, disc_loss = 0.029246152151079678
Trained batch 88 in epoch 5, gen_loss = 0.41987790150588816, disc_loss = 0.0293593218162907
Trained batch 89 in epoch 5, gen_loss = 0.4202398379643758, disc_loss = 0.029294473331214654
Trained batch 90 in epoch 5, gen_loss = 0.4198517085431696, disc_loss = 0.02921927272557066
Trained batch 91 in epoch 5, gen_loss = 0.4199522234823393, disc_loss = 0.0291342197806048
Trained batch 92 in epoch 5, gen_loss = 0.4199822214982843, disc_loss = 0.028886243265362516
Trained batch 93 in epoch 5, gen_loss = 0.42004023777677657, disc_loss = 0.02918342711463412
Trained batch 94 in epoch 5, gen_loss = 0.41939956890909297, disc_loss = 0.02966684185850777
Trained batch 95 in epoch 5, gen_loss = 0.4193882194037239, disc_loss = 0.029475739424621377
Trained batch 96 in epoch 5, gen_loss = 0.4196651107871655, disc_loss = 0.02963758590775206
Trained batch 97 in epoch 5, gen_loss = 0.4198277014858869, disc_loss = 0.029492834207544824
Trained batch 98 in epoch 5, gen_loss = 0.419850610121332, disc_loss = 0.029260617008225784
Trained batch 99 in epoch 5, gen_loss = 0.41968937873840334, disc_loss = 0.02920715670567006
Trained batch 100 in epoch 5, gen_loss = 0.41989336509515746, disc_loss = 0.029032251267408084
Trained batch 101 in epoch 5, gen_loss = 0.4196876173510271, disc_loss = 0.028828308693882004
Trained batch 102 in epoch 5, gen_loss = 0.4192763306562183, disc_loss = 0.02872394683128856
Trained batch 103 in epoch 5, gen_loss = 0.41916561929079205, disc_loss = 0.029178797979301844
Trained batch 104 in epoch 5, gen_loss = 0.41860664657184055, disc_loss = 0.02909476866590835
Trained batch 105 in epoch 5, gen_loss = 0.4180634584067003, disc_loss = 0.029404441663503367
Trained batch 106 in epoch 5, gen_loss = 0.41861921660253937, disc_loss = 0.03201145291868075
Trained batch 107 in epoch 5, gen_loss = 0.4180846407457634, disc_loss = 0.03315208351705223
Trained batch 108 in epoch 5, gen_loss = 0.4177385005382223, disc_loss = 0.0330940892005664
Trained batch 109 in epoch 5, gen_loss = 0.4181433298371055, disc_loss = 0.03291013746691698
Trained batch 110 in epoch 5, gen_loss = 0.4184008474285538, disc_loss = 0.03281433881587676
Trained batch 111 in epoch 5, gen_loss = 0.41817942687443327, disc_loss = 0.03339428103312717
Trained batch 112 in epoch 5, gen_loss = 0.4187125611094247, disc_loss = 0.03396756163658162
Trained batch 113 in epoch 5, gen_loss = 0.41871035831016407, disc_loss = 0.03397884658995297
Trained batch 114 in epoch 5, gen_loss = 0.4186773709628893, disc_loss = 0.033839705695762584
Trained batch 115 in epoch 5, gen_loss = 0.4185335559063944, disc_loss = 0.033835773336187265
Trained batch 116 in epoch 5, gen_loss = 0.41875697837935555, disc_loss = 0.033779274095168225
Trained batch 117 in epoch 5, gen_loss = 0.41824700746495846, disc_loss = 0.03367941160054909
Trained batch 118 in epoch 5, gen_loss = 0.4189588259749052, disc_loss = 0.033463468575584035
Trained batch 119 in epoch 5, gen_loss = 0.41865969176093737, disc_loss = 0.03331251166528091
Trained batch 120 in epoch 5, gen_loss = 0.4188197200948542, disc_loss = 0.03308124892213497
Trained batch 121 in epoch 5, gen_loss = 0.41899668974954574, disc_loss = 0.03288780935643027
Trained batch 122 in epoch 5, gen_loss = 0.41930846615535455, disc_loss = 0.032698524317030256
Trained batch 123 in epoch 5, gen_loss = 0.4191950975406554, disc_loss = 0.03253987905073671
Trained batch 124 in epoch 5, gen_loss = 0.4190214326381683, disc_loss = 0.032384653266519306
Trained batch 125 in epoch 5, gen_loss = 0.41868311545205494, disc_loss = 0.03264486156625762
Trained batch 126 in epoch 5, gen_loss = 0.41895706799086624, disc_loss = 0.03270536825046178
Trained batch 127 in epoch 5, gen_loss = 0.41837167646735907, disc_loss = 0.0327060492381861
Trained batch 128 in epoch 5, gen_loss = 0.4185808019120564, disc_loss = 0.032941234171708196
Trained batch 129 in epoch 5, gen_loss = 0.4185283463734847, disc_loss = 0.032792872430470126
Trained batch 130 in epoch 5, gen_loss = 0.41841681290218846, disc_loss = 0.03277134137114382
Trained batch 131 in epoch 5, gen_loss = 0.4184603537573959, disc_loss = 0.03257101652508771
Trained batch 132 in epoch 5, gen_loss = 0.41837319037071746, disc_loss = 0.03252727903523728
Trained batch 133 in epoch 5, gen_loss = 0.4183036202370231, disc_loss = 0.032432696542271704
Trained batch 134 in epoch 5, gen_loss = 0.41906955396687545, disc_loss = 0.032267299235832915
Trained batch 135 in epoch 5, gen_loss = 0.4196869522771415, disc_loss = 0.032093038450351316
Trained batch 136 in epoch 5, gen_loss = 0.4193776441316535, disc_loss = 0.03191352641400303
Trained batch 137 in epoch 5, gen_loss = 0.4191951598378195, disc_loss = 0.03173143131847399
Trained batch 138 in epoch 5, gen_loss = 0.41920445784390403, disc_loss = 0.031690151236361735
Trained batch 139 in epoch 5, gen_loss = 0.41887642187731605, disc_loss = 0.03157089031301439
Trained batch 140 in epoch 5, gen_loss = 0.4190461927271904, disc_loss = 0.031425392255187035
Trained batch 141 in epoch 5, gen_loss = 0.41955242400438014, disc_loss = 0.03126588621189896
Trained batch 142 in epoch 5, gen_loss = 0.4192334901202809, disc_loss = 0.031087141034642718
Trained batch 143 in epoch 5, gen_loss = 0.4187207685576545, disc_loss = 0.03127271826249651
Trained batch 144 in epoch 5, gen_loss = 0.4190679833806794, disc_loss = 0.031860809895242086
Trained batch 145 in epoch 5, gen_loss = 0.4190901550528121, disc_loss = 0.03173134693467658
Trained batch 146 in epoch 5, gen_loss = 0.4189515075310558, disc_loss = 0.031956094393164526
Trained batch 147 in epoch 5, gen_loss = 0.4192143422929016, disc_loss = 0.032420031304748076
Trained batch 148 in epoch 5, gen_loss = 0.4189655306755296, disc_loss = 0.032372941963074595
Trained batch 149 in epoch 5, gen_loss = 0.4190330386161804, disc_loss = 0.032266799503316484
Trained batch 150 in epoch 5, gen_loss = 0.4187558334789529, disc_loss = 0.032135619831252966
Trained batch 151 in epoch 5, gen_loss = 0.4186843996377368, disc_loss = 0.03202932671717319
Trained batch 152 in epoch 5, gen_loss = 0.4189486937974793, disc_loss = 0.031886097737679295
Trained batch 153 in epoch 5, gen_loss = 0.41822595120250405, disc_loss = 0.03180137853585668
Trained batch 154 in epoch 5, gen_loss = 0.41803737667299085, disc_loss = 0.031708428419886095
Trained batch 155 in epoch 5, gen_loss = 0.4174406794019235, disc_loss = 0.03158844170423272
Trained batch 156 in epoch 5, gen_loss = 0.4173229460123998, disc_loss = 0.03185482127414008
Trained batch 157 in epoch 5, gen_loss = 0.4176264803243589, disc_loss = 0.03266179253924874
Trained batch 158 in epoch 5, gen_loss = 0.4170841486573969, disc_loss = 0.03325227234489138
Trained batch 159 in epoch 5, gen_loss = 0.41718419939279555, disc_loss = 0.03462692400207743
Trained batch 160 in epoch 5, gen_loss = 0.41642211220279246, disc_loss = 0.03493785380345324
Trained batch 161 in epoch 5, gen_loss = 0.4160727523727181, disc_loss = 0.035004036880477714
Trained batch 162 in epoch 5, gen_loss = 0.4159152196960215, disc_loss = 0.034903212924676436
Trained batch 163 in epoch 5, gen_loss = 0.41623825961496774, disc_loss = 0.03478443111497455
Trained batch 164 in epoch 5, gen_loss = 0.41601349873976273, disc_loss = 0.03466229146402894
Trained batch 165 in epoch 5, gen_loss = 0.41600662218519, disc_loss = 0.034662944556449554
Trained batch 166 in epoch 5, gen_loss = 0.41607037597073765, disc_loss = 0.0347015131264925
Trained batch 167 in epoch 5, gen_loss = 0.4159969999676659, disc_loss = 0.03465053047763095
Trained batch 168 in epoch 5, gen_loss = 0.4158490003918755, disc_loss = 0.0345480397740412
Trained batch 169 in epoch 5, gen_loss = 0.4153924773721134, disc_loss = 0.03440172414788428
Trained batch 170 in epoch 5, gen_loss = 0.4154229429033067, disc_loss = 0.034310934063025385
Trained batch 171 in epoch 5, gen_loss = 0.4157527879227039, disc_loss = 0.03414605185118785
Trained batch 172 in epoch 5, gen_loss = 0.4162399796392187, disc_loss = 0.03428751970722065
Trained batch 173 in epoch 5, gen_loss = 0.4158400120748871, disc_loss = 0.03508617608786571
Trained batch 174 in epoch 5, gen_loss = 0.4160448694229126, disc_loss = 0.035243710702551265
Trained batch 175 in epoch 5, gen_loss = 0.4158047891475938, disc_loss = 0.035164569671244615
Trained batch 176 in epoch 5, gen_loss = 0.4154952176883396, disc_loss = 0.035533474239989024
Trained batch 177 in epoch 5, gen_loss = 0.41567185303468385, disc_loss = 0.03567478102317938
Trained batch 178 in epoch 5, gen_loss = 0.4161756196834522, disc_loss = 0.03555767837256276
Trained batch 179 in epoch 5, gen_loss = 0.4161006813247999, disc_loss = 0.03543652111095273
Trained batch 180 in epoch 5, gen_loss = 0.41624266683067407, disc_loss = 0.03537214789488121
Trained batch 181 in epoch 5, gen_loss = 0.41611570103482887, disc_loss = 0.035246702251382746
Trained batch 182 in epoch 5, gen_loss = 0.4160625589349882, disc_loss = 0.03511946976866797
Trained batch 183 in epoch 5, gen_loss = 0.41587590264237445, disc_loss = 0.03495433053467423
Trained batch 184 in epoch 5, gen_loss = 0.4154176399514482, disc_loss = 0.034857695937358046
Trained batch 185 in epoch 5, gen_loss = 0.4150966559686968, disc_loss = 0.0350674196166457
Trained batch 186 in epoch 5, gen_loss = 0.4152828278069828, disc_loss = 0.03495948436485733
Trained batch 187 in epoch 5, gen_loss = 0.41537844801836826, disc_loss = 0.034841572870797616
Trained batch 188 in epoch 5, gen_loss = 0.4155454364403215, disc_loss = 0.0347109916693871
Trained batch 189 in epoch 5, gen_loss = 0.41519999002155505, disc_loss = 0.03458884727503908
Trained batch 190 in epoch 5, gen_loss = 0.4149960828701239, disc_loss = 0.03449021083307672
Trained batch 191 in epoch 5, gen_loss = 0.41459412810703117, disc_loss = 0.03441320037139425
Trained batch 192 in epoch 5, gen_loss = 0.41485918587353565, disc_loss = 0.03511813703268149
Trained batch 193 in epoch 5, gen_loss = 0.4148519039154053, disc_loss = 0.035499511262613165
Trained batch 194 in epoch 5, gen_loss = 0.4149744663483057, disc_loss = 0.03542312182581578
Trained batch 195 in epoch 5, gen_loss = 0.4151741743695979, disc_loss = 0.03535230302403928
Trained batch 196 in epoch 5, gen_loss = 0.4153372194561256, disc_loss = 0.03524429449423921
Trained batch 197 in epoch 5, gen_loss = 0.41506011678714944, disc_loss = 0.035095500962037326
Trained batch 198 in epoch 5, gen_loss = 0.41492053626769754, disc_loss = 0.034948543757761845
Trained batch 199 in epoch 5, gen_loss = 0.4149847570061684, disc_loss = 0.03484506551641971
Trained batch 200 in epoch 5, gen_loss = 0.41491496029184827, disc_loss = 0.03471107365313306
Trained batch 201 in epoch 5, gen_loss = 0.4147287251630632, disc_loss = 0.034711042949284364
Trained batch 202 in epoch 5, gen_loss = 0.4146285930584217, disc_loss = 0.03499351687307282
Trained batch 203 in epoch 5, gen_loss = 0.41500651164382113, disc_loss = 0.03489936842108328
Trained batch 204 in epoch 5, gen_loss = 0.4149510755771544, disc_loss = 0.03535878190816176
Trained batch 205 in epoch 5, gen_loss = 0.4152034940650162, disc_loss = 0.03538359285250885
Trained batch 206 in epoch 5, gen_loss = 0.41551181083716054, disc_loss = 0.03529866617892819
Trained batch 207 in epoch 5, gen_loss = 0.41550235063410723, disc_loss = 0.03517525887582451
Trained batch 208 in epoch 5, gen_loss = 0.415789639550533, disc_loss = 0.035100774278053255
Trained batch 209 in epoch 5, gen_loss = 0.41601283025173913, disc_loss = 0.035060805304064635
Trained batch 210 in epoch 5, gen_loss = 0.41576125525750257, disc_loss = 0.03495463817181745
Trained batch 211 in epoch 5, gen_loss = 0.4156996600751607, disc_loss = 0.03484606489380997
Trained batch 212 in epoch 5, gen_loss = 0.4159339992373202, disc_loss = 0.03473885430399101
Trained batch 213 in epoch 5, gen_loss = 0.415578364768875, disc_loss = 0.0346406889235096
Trained batch 214 in epoch 5, gen_loss = 0.41611767175585723, disc_loss = 0.03467026171382777
Trained batch 215 in epoch 5, gen_loss = 0.41592259263550796, disc_loss = 0.03453877944223307
Trained batch 216 in epoch 5, gen_loss = 0.41611471827129065, disc_loss = 0.03448781370258276
Trained batch 217 in epoch 5, gen_loss = 0.41598545247261676, disc_loss = 0.03442856332782759
Trained batch 218 in epoch 5, gen_loss = 0.4160812207280773, disc_loss = 0.03430469860599193
Trained batch 219 in epoch 5, gen_loss = 0.4156230996955525, disc_loss = 0.03416797622022304
Trained batch 220 in epoch 5, gen_loss = 0.41537992096594556, disc_loss = 0.034052435401405685
Trained batch 221 in epoch 5, gen_loss = 0.4158310060565536, disc_loss = 0.03405717504420527
Trained batch 222 in epoch 5, gen_loss = 0.4159603252539186, disc_loss = 0.033973867478759565
Trained batch 223 in epoch 5, gen_loss = 0.4159906743360417, disc_loss = 0.03384459124520488
Trained batch 224 in epoch 5, gen_loss = 0.4162865686416626, disc_loss = 0.03374013943597674
Trained batch 225 in epoch 5, gen_loss = 0.4160770945316922, disc_loss = 0.03363858829087586
Trained batch 226 in epoch 5, gen_loss = 0.4159862680057072, disc_loss = 0.03370634503949778
Trained batch 227 in epoch 5, gen_loss = 0.41596439193215284, disc_loss = 0.03361719723570308
Trained batch 228 in epoch 5, gen_loss = 0.4160450849210331, disc_loss = 0.033569608593367724
Trained batch 229 in epoch 5, gen_loss = 0.41596300951812576, disc_loss = 0.03345325139310697
Trained batch 230 in epoch 5, gen_loss = 0.41594499388298434, disc_loss = 0.03334780424849425
Trained batch 231 in epoch 5, gen_loss = 0.4162198062343844, disc_loss = 0.03323136163466
Trained batch 232 in epoch 5, gen_loss = 0.4162747935419942, disc_loss = 0.033115350975067445
Trained batch 233 in epoch 5, gen_loss = 0.41625840350603444, disc_loss = 0.03301303842280092
Trained batch 234 in epoch 5, gen_loss = 0.4162376935177661, disc_loss = 0.03289098324888247
Trained batch 235 in epoch 5, gen_loss = 0.41623831919189225, disc_loss = 0.0327673376196506
Trained batch 236 in epoch 5, gen_loss = 0.4163382638104354, disc_loss = 0.032673234873518094
Trained batch 237 in epoch 5, gen_loss = 0.4164149748677967, disc_loss = 0.03257755928441976
Trained batch 238 in epoch 5, gen_loss = 0.41608067611271365, disc_loss = 0.032486567978073054
Trained batch 239 in epoch 5, gen_loss = 0.41604466338952384, disc_loss = 0.032369474724206766
Trained batch 240 in epoch 5, gen_loss = 0.4162015402960085, disc_loss = 0.0322658909181388
Trained batch 241 in epoch 5, gen_loss = 0.4164312267599027, disc_loss = 0.03216312487882924
Trained batch 242 in epoch 5, gen_loss = 0.4165215533947258, disc_loss = 0.03205777185685442
Trained batch 243 in epoch 5, gen_loss = 0.41668284061502237, disc_loss = 0.03195153050349842
Trained batch 244 in epoch 5, gen_loss = 0.4166382293311917, disc_loss = 0.03185112765343974
Trained batch 245 in epoch 5, gen_loss = 0.4169091359386599, disc_loss = 0.03175392309752694
Trained batch 246 in epoch 5, gen_loss = 0.4167065835192136, disc_loss = 0.03166149383663437
Trained batch 247 in epoch 5, gen_loss = 0.4169242785822961, disc_loss = 0.03155208675795415
Trained batch 248 in epoch 5, gen_loss = 0.416777944828133, disc_loss = 0.03149517333924202
Trained batch 249 in epoch 5, gen_loss = 0.4166766319274902, disc_loss = 0.031387998820282516
Trained batch 250 in epoch 5, gen_loss = 0.4167379279773074, disc_loss = 0.031284595194988815
Trained batch 251 in epoch 5, gen_loss = 0.41713731097323553, disc_loss = 0.031247893803834265
Trained batch 252 in epoch 5, gen_loss = 0.4172892069863708, disc_loss = 0.031156143156090096
Trained batch 253 in epoch 5, gen_loss = 0.41723221868980587, disc_loss = 0.03104682081822658
Trained batch 254 in epoch 5, gen_loss = 0.4172632735149533, disc_loss = 0.030988912626772242
Trained batch 255 in epoch 5, gen_loss = 0.41720525070559233, disc_loss = 0.030892794772626075
Trained batch 256 in epoch 5, gen_loss = 0.41723992724826825, disc_loss = 0.030800868810520503
Trained batch 257 in epoch 5, gen_loss = 0.4173250470974649, disc_loss = 0.030694590655855777
Trained batch 258 in epoch 5, gen_loss = 0.4174571058004519, disc_loss = 0.03059581112526501
Trained batch 259 in epoch 5, gen_loss = 0.41758857575746683, disc_loss = 0.030496775505777736
Trained batch 260 in epoch 5, gen_loss = 0.4175303753080039, disc_loss = 0.03039233805968558
Trained batch 261 in epoch 5, gen_loss = 0.4175445444256295, disc_loss = 0.03031421817291727
Trained batch 262 in epoch 5, gen_loss = 0.41758070857805896, disc_loss = 0.030211006652408
Trained batch 263 in epoch 5, gen_loss = 0.4175062049744707, disc_loss = 0.03011842996277141
Trained batch 264 in epoch 5, gen_loss = 0.41725184962434586, disc_loss = 0.03002321175738888
Trained batch 265 in epoch 5, gen_loss = 0.4173939239261742, disc_loss = 0.029936735938422214
Trained batch 266 in epoch 5, gen_loss = 0.41734891716907085, disc_loss = 0.029848974234727998
Trained batch 267 in epoch 5, gen_loss = 0.4172970824944439, disc_loss = 0.029792480228065667
Trained batch 268 in epoch 5, gen_loss = 0.41719580173049275, disc_loss = 0.029702921988283282
Trained batch 269 in epoch 5, gen_loss = 0.4172344458323938, disc_loss = 0.029619685496652014
Trained batch 270 in epoch 5, gen_loss = 0.41745904230983494, disc_loss = 0.029563653459806834
Trained batch 271 in epoch 5, gen_loss = 0.417460021617658, disc_loss = 0.029511696421061915
Trained batch 272 in epoch 5, gen_loss = 0.41753782413818025, disc_loss = 0.029481637712922833
Trained batch 273 in epoch 5, gen_loss = 0.4177160450141795, disc_loss = 0.029404048265780518
Trained batch 274 in epoch 5, gen_loss = 0.4176639088717374, disc_loss = 0.029321246153929018
Trained batch 275 in epoch 5, gen_loss = 0.41763691139825876, disc_loss = 0.029234577938779326
Trained batch 276 in epoch 5, gen_loss = 0.41775195026225564, disc_loss = 0.029166766257438848
Trained batch 277 in epoch 5, gen_loss = 0.4177673300393194, disc_loss = 0.029085784569288866
Trained batch 278 in epoch 5, gen_loss = 0.4178947382289449, disc_loss = 0.028996343100209817
Trained batch 279 in epoch 5, gen_loss = 0.4179505659001214, disc_loss = 0.028916262020356954
Trained batch 280 in epoch 5, gen_loss = 0.4180384119210294, disc_loss = 0.028872318376929523
Trained batch 281 in epoch 5, gen_loss = 0.4180996471897085, disc_loss = 0.02878926118096033
Trained batch 282 in epoch 5, gen_loss = 0.41805805660810574, disc_loss = 0.028700700408183434
Trained batch 283 in epoch 5, gen_loss = 0.418018693445434, disc_loss = 0.028619776696334004
Trained batch 284 in epoch 5, gen_loss = 0.4180979208988056, disc_loss = 0.02853245835816651
Trained batch 285 in epoch 5, gen_loss = 0.41811719130386005, disc_loss = 0.028450649767345584
Trained batch 286 in epoch 5, gen_loss = 0.41825739629177267, disc_loss = 0.028366230364940827
Trained batch 287 in epoch 5, gen_loss = 0.4182481131412917, disc_loss = 0.028292619692769624
Trained batch 288 in epoch 5, gen_loss = 0.418359830717727, disc_loss = 0.02821012522548334
Trained batch 289 in epoch 5, gen_loss = 0.418313625352136, disc_loss = 0.028126245004863576
Trained batch 290 in epoch 5, gen_loss = 0.41825436275849226, disc_loss = 0.028043444894087787
Trained batch 291 in epoch 5, gen_loss = 0.41825792662901423, disc_loss = 0.02796665587532653
Trained batch 292 in epoch 5, gen_loss = 0.41833638890611435, disc_loss = 0.0278910045613735
Trained batch 293 in epoch 5, gen_loss = 0.41838987039870956, disc_loss = 0.027807919791627195
Trained batch 294 in epoch 5, gen_loss = 0.41841305362976206, disc_loss = 0.027727708067366127
Trained batch 295 in epoch 5, gen_loss = 0.41848904488457217, disc_loss = 0.027659963761343043
Trained batch 296 in epoch 5, gen_loss = 0.41827734170939385, disc_loss = 0.027604651764373888
Trained batch 297 in epoch 5, gen_loss = 0.4180426686602151, disc_loss = 0.02754747087367179
Trained batch 298 in epoch 5, gen_loss = 0.41799589393529607, disc_loss = 0.02750892799976827
Trained batch 299 in epoch 5, gen_loss = 0.4181025488177935, disc_loss = 0.027462179522650936
Trained batch 300 in epoch 5, gen_loss = 0.4182888548635565, disc_loss = 0.027386423112187176
Trained batch 301 in epoch 5, gen_loss = 0.4182728157927658, disc_loss = 0.02731753920747695
Trained batch 302 in epoch 5, gen_loss = 0.41822356693815477, disc_loss = 0.027245521768251367
Trained batch 303 in epoch 5, gen_loss = 0.4183340538293123, disc_loss = 0.02717428237787987
Trained batch 304 in epoch 5, gen_loss = 0.4183097230606392, disc_loss = 0.027100597199846487
Trained batch 305 in epoch 5, gen_loss = 0.4184967549213397, disc_loss = 0.027031378861626282
Trained batch 306 in epoch 5, gen_loss = 0.4185229251555589, disc_loss = 0.026965958930867503
Trained batch 307 in epoch 5, gen_loss = 0.41834352707320993, disc_loss = 0.02690516004653333
Trained batch 308 in epoch 5, gen_loss = 0.41864897141950413, disc_loss = 0.02685885357408269
Trained batch 309 in epoch 5, gen_loss = 0.4187370776168762, disc_loss = 0.026863343388803543
Trained batch 310 in epoch 5, gen_loss = 0.418682891552088, disc_loss = 0.026859530963458816
Trained batch 311 in epoch 5, gen_loss = 0.41871248414883244, disc_loss = 0.026823014919407282
Trained batch 312 in epoch 5, gen_loss = 0.41878223257323804, disc_loss = 0.026818111660881355
Trained batch 313 in epoch 5, gen_loss = 0.41889347325844367, disc_loss = 0.026766082891826606
Trained batch 314 in epoch 5, gen_loss = 0.41926155194403636, disc_loss = 0.026715327276005632
Trained batch 315 in epoch 5, gen_loss = 0.41910187013541594, disc_loss = 0.026667629902050655
Trained batch 316 in epoch 5, gen_loss = 0.41913558895279557, disc_loss = 0.026607225516852143
Trained batch 317 in epoch 5, gen_loss = 0.41921343865259636, disc_loss = 0.02654014743349087
Trained batch 318 in epoch 5, gen_loss = 0.4191239919968907, disc_loss = 0.0264721064504271
Trained batch 319 in epoch 5, gen_loss = 0.41920639518648384, disc_loss = 0.026404798332077917
Trained batch 320 in epoch 5, gen_loss = 0.4187778681980858, disc_loss = 0.026407429720695794
Trained batch 321 in epoch 5, gen_loss = 0.4186730832787034, disc_loss = 0.026353731634303556
Trained batch 322 in epoch 5, gen_loss = 0.41845428251629646, disc_loss = 0.026291552040114675
Trained batch 323 in epoch 5, gen_loss = 0.4188052264076692, disc_loss = 0.026263474639114222
Trained batch 324 in epoch 5, gen_loss = 0.4186648322068728, disc_loss = 0.026210732967234574
Trained batch 325 in epoch 5, gen_loss = 0.4188494392516423, disc_loss = 0.0261603479810699
Trained batch 326 in epoch 5, gen_loss = 0.4187097189441004, disc_loss = 0.026119646536533803
Trained batch 327 in epoch 5, gen_loss = 0.4186953700533727, disc_loss = 0.026058934787969765
Trained batch 328 in epoch 5, gen_loss = 0.41856472488594637, disc_loss = 0.025990729286734546
Trained batch 329 in epoch 5, gen_loss = 0.41862437165144717, disc_loss = 0.02593118163305476
Trained batch 330 in epoch 5, gen_loss = 0.41856058342579266, disc_loss = 0.02587382022567161
Trained batch 331 in epoch 5, gen_loss = 0.41850402735802067, disc_loss = 0.025815816468514323
Trained batch 332 in epoch 5, gen_loss = 0.4183838037220207, disc_loss = 0.02575437516231347
Trained batch 333 in epoch 5, gen_loss = 0.4184160527890314, disc_loss = 0.025700609598442645
Trained batch 334 in epoch 5, gen_loss = 0.4182999870670375, disc_loss = 0.025668352925732954
Trained batch 335 in epoch 5, gen_loss = 0.418528658204845, disc_loss = 0.025619261867610647
Trained batch 336 in epoch 5, gen_loss = 0.41849426390155486, disc_loss = 0.025555392705147274
Trained batch 337 in epoch 5, gen_loss = 0.418586376591547, disc_loss = 0.025493657742709626
Trained batch 338 in epoch 5, gen_loss = 0.4185709827593294, disc_loss = 0.025483624221191117
Trained batch 339 in epoch 5, gen_loss = 0.41847825041588615, disc_loss = 0.025570598504889536
Trained batch 340 in epoch 5, gen_loss = 0.4184394322357569, disc_loss = 0.025547749941890015
Trained batch 341 in epoch 5, gen_loss = 0.4182231305112616, disc_loss = 0.025600623707041928
Trained batch 342 in epoch 5, gen_loss = 0.41850341278679515, disc_loss = 0.026470856092131696
Trained batch 343 in epoch 5, gen_loss = 0.41825690051150877, disc_loss = 0.0271428772762721
Trained batch 344 in epoch 5, gen_loss = 0.4182215778724007, disc_loss = 0.027181720299025377
Trained batch 345 in epoch 5, gen_loss = 0.41813506935373207, disc_loss = 0.027179124390954056
Trained batch 346 in epoch 5, gen_loss = 0.4181799174042188, disc_loss = 0.027129567163843415
Trained batch 347 in epoch 5, gen_loss = 0.41797671252968666, disc_loss = 0.027083435906739586
Trained batch 348 in epoch 5, gen_loss = 0.41795743920741585, disc_loss = 0.02709551880077424
Trained batch 349 in epoch 5, gen_loss = 0.4180274625335421, disc_loss = 0.02726552559595023
Trained batch 350 in epoch 5, gen_loss = 0.41783556053441473, disc_loss = 0.028033396762469385
Trained batch 351 in epoch 5, gen_loss = 0.41797626221721823, disc_loss = 0.02812350468064489
Trained batch 352 in epoch 5, gen_loss = 0.4179243518846906, disc_loss = 0.028387808731675318
Trained batch 353 in epoch 5, gen_loss = 0.4176465570926666, disc_loss = 0.02927050672966124
Trained batch 354 in epoch 5, gen_loss = 0.4176055286971616, disc_loss = 0.029516858772807558
Trained batch 355 in epoch 5, gen_loss = 0.41773222956094846, disc_loss = 0.029764953003987002
Trained batch 356 in epoch 5, gen_loss = 0.41768397253100614, disc_loss = 0.02982184678806561
Trained batch 357 in epoch 5, gen_loss = 0.41736274749540087, disc_loss = 0.02986211248272874
Trained batch 358 in epoch 5, gen_loss = 0.4175616272810774, disc_loss = 0.029845924666644305
Trained batch 359 in epoch 5, gen_loss = 0.4174400019976828, disc_loss = 0.02999104965840363
Trained batch 360 in epoch 5, gen_loss = 0.4174354273691732, disc_loss = 0.030524249807763793
Trained batch 361 in epoch 5, gen_loss = 0.41772381006354126, disc_loss = 0.030673686505002046
Trained batch 362 in epoch 5, gen_loss = 0.4176594206945298, disc_loss = 0.030710648168032328
Trained batch 363 in epoch 5, gen_loss = 0.4176330333882636, disc_loss = 0.030792590688688906
Trained batch 364 in epoch 5, gen_loss = 0.41749513034951197, disc_loss = 0.030857461800620163
Trained batch 365 in epoch 5, gen_loss = 0.41732842861954633, disc_loss = 0.03102270451430333
Trained batch 366 in epoch 5, gen_loss = 0.4172336092924227, disc_loss = 0.031185794578565726
Trained batch 367 in epoch 5, gen_loss = 0.41715548997339996, disc_loss = 0.031210915395564844
Trained batch 368 in epoch 5, gen_loss = 0.4172668904469911, disc_loss = 0.031185899331135962
Trained batch 369 in epoch 5, gen_loss = 0.4173091508246757, disc_loss = 0.031147815913868112
Trained batch 370 in epoch 5, gen_loss = 0.417355137452925, disc_loss = 0.031094412284217915
Trained batch 371 in epoch 5, gen_loss = 0.41747728270548645, disc_loss = 0.031036811497723384
Trained batch 372 in epoch 5, gen_loss = 0.4175080117687143, disc_loss = 0.03097935162994002
Trained batch 373 in epoch 5, gen_loss = 0.41752242842778803, disc_loss = 0.030949494450348107
Trained batch 374 in epoch 5, gen_loss = 0.41736439474423725, disc_loss = 0.031299805514514445
Trained batch 375 in epoch 5, gen_loss = 0.4173338176246653, disc_loss = 0.03161407273233016
Trained batch 376 in epoch 5, gen_loss = 0.41731464862823486, disc_loss = 0.03154797791886274
Trained batch 377 in epoch 5, gen_loss = 0.41732019856177943, disc_loss = 0.031481911949369876
Trained batch 378 in epoch 5, gen_loss = 0.41708532982262586, disc_loss = 0.03152562541602116
Trained batch 379 in epoch 5, gen_loss = 0.4172666322243841, disc_loss = 0.031516624186923234
Trained batch 380 in epoch 5, gen_loss = 0.4172176904878591, disc_loss = 0.031469659377476124
Trained batch 381 in epoch 5, gen_loss = 0.4171925659111033, disc_loss = 0.031448368720603005
Trained batch 382 in epoch 5, gen_loss = 0.4169342944267213, disc_loss = 0.032209530449654744
Trained batch 383 in epoch 5, gen_loss = 0.41693578272437054, disc_loss = 0.03272458943562621
Trained batch 384 in epoch 5, gen_loss = 0.4170370100380538, disc_loss = 0.032682250726774525
Trained batch 385 in epoch 5, gen_loss = 0.41690787997270495, disc_loss = 0.03283164211683979
Trained batch 386 in epoch 5, gen_loss = 0.41700147750765776, disc_loss = 0.03284631802000163
Trained batch 387 in epoch 5, gen_loss = 0.4170549021092887, disc_loss = 0.03281321279709371
Trained batch 388 in epoch 5, gen_loss = 0.4170100921836794, disc_loss = 0.03278463618389323
Trained batch 389 in epoch 5, gen_loss = 0.41707269350687665, disc_loss = 0.032716723174477616
Trained batch 390 in epoch 5, gen_loss = 0.41700044350550913, disc_loss = 0.03270383272677317
Trained batch 391 in epoch 5, gen_loss = 0.4171375649772128, disc_loss = 0.03267910825777609
Trained batch 392 in epoch 5, gen_loss = 0.417324169977324, disc_loss = 0.032636068440243866
Trained batch 393 in epoch 5, gen_loss = 0.4174537210900166, disc_loss = 0.03257554393795881
Trained batch 394 in epoch 5, gen_loss = 0.4174179502680332, disc_loss = 0.032504140942864405
Trained batch 395 in epoch 5, gen_loss = 0.4174673825953946, disc_loss = 0.032441816434988544
Trained batch 396 in epoch 5, gen_loss = 0.41757483889233854, disc_loss = 0.03247279163464078
Trained batch 397 in epoch 5, gen_loss = 0.41760898482559916, disc_loss = 0.032550903702922275
Trained batch 398 in epoch 5, gen_loss = 0.4176438530734308, disc_loss = 0.032496011716764146
Trained batch 399 in epoch 5, gen_loss = 0.41771105594933033, disc_loss = 0.03253555924282409
Trained batch 400 in epoch 5, gen_loss = 0.4173649820752275, disc_loss = 0.03258292927543756
Trained batch 401 in epoch 5, gen_loss = 0.4172305014744327, disc_loss = 0.0325238801925837
Trained batch 402 in epoch 5, gen_loss = 0.41717724158213687, disc_loss = 0.032457326052400745
Trained batch 403 in epoch 5, gen_loss = 0.4172994653777321, disc_loss = 0.03239457766954225
Trained batch 404 in epoch 5, gen_loss = 0.41740886326189397, disc_loss = 0.03232794628467089
Trained batch 405 in epoch 5, gen_loss = 0.4173936624391913, disc_loss = 0.03228149297670117
Trained batch 406 in epoch 5, gen_loss = 0.4173550545729935, disc_loss = 0.0322144129073261
Trained batch 407 in epoch 5, gen_loss = 0.417268304409934, disc_loss = 0.032148076811412754
Trained batch 408 in epoch 5, gen_loss = 0.41725359401667905, disc_loss = 0.03208224531513591
Trained batch 409 in epoch 5, gen_loss = 0.41713072374099636, disc_loss = 0.03201777775453903
Trained batch 410 in epoch 5, gen_loss = 0.4171718332164189, disc_loss = 0.03194905270045111
Trained batch 411 in epoch 5, gen_loss = 0.41704442677567305, disc_loss = 0.0319161321741791
Trained batch 412 in epoch 5, gen_loss = 0.41699705054627206, disc_loss = 0.03186864082500808
Trained batch 413 in epoch 5, gen_loss = 0.41716417281523993, disc_loss = 0.03184814616623852
Trained batch 414 in epoch 5, gen_loss = 0.41717779744102296, disc_loss = 0.031795832474368166
Trained batch 415 in epoch 5, gen_loss = 0.41701740126770276, disc_loss = 0.03179139434359968
Trained batch 416 in epoch 5, gen_loss = 0.41694994367283883, disc_loss = 0.03174957041394153
Trained batch 417 in epoch 5, gen_loss = 0.4169048476589924, disc_loss = 0.03168368324387872
Trained batch 418 in epoch 5, gen_loss = 0.41689637872370444, disc_loss = 0.03163519641940164
Trained batch 419 in epoch 5, gen_loss = 0.4167368005428995, disc_loss = 0.031574422121047975
Trained batch 420 in epoch 5, gen_loss = 0.4167176811400615, disc_loss = 0.031545911749687724
Trained batch 421 in epoch 5, gen_loss = 0.4167925793836467, disc_loss = 0.031504914952415565
Trained batch 422 in epoch 5, gen_loss = 0.41662896954703277, disc_loss = 0.03145131186513895
Trained batch 423 in epoch 5, gen_loss = 0.41671274630528576, disc_loss = 0.03139842624714563
Trained batch 424 in epoch 5, gen_loss = 0.416811086991254, disc_loss = 0.03137254891807542
Trained batch 425 in epoch 5, gen_loss = 0.4167338783892108, disc_loss = 0.03131202043759956
Trained batch 426 in epoch 5, gen_loss = 0.41668422021128815, disc_loss = 0.03127619949010238
Trained batch 427 in epoch 5, gen_loss = 0.4167247207783093, disc_loss = 0.031221887178362183
Trained batch 428 in epoch 5, gen_loss = 0.4167472630530804, disc_loss = 0.03116817013762179
Trained batch 429 in epoch 5, gen_loss = 0.4165739491235378, disc_loss = 0.031155183659000104
Trained batch 430 in epoch 5, gen_loss = 0.4165898489564865, disc_loss = 0.03110792271883644
Trained batch 431 in epoch 5, gen_loss = 0.4164986548324426, disc_loss = 0.03107800805635095
Trained batch 432 in epoch 5, gen_loss = 0.4165184083491495, disc_loss = 0.031017134717814022
Trained batch 433 in epoch 5, gen_loss = 0.41665973867963535, disc_loss = 0.030961860867200017
Trained batch 434 in epoch 5, gen_loss = 0.4165697938409345, disc_loss = 0.030900553130041593
Trained batch 435 in epoch 5, gen_loss = 0.4165256215481583, disc_loss = 0.030853236773384547
Trained batch 436 in epoch 5, gen_loss = 0.41658960961368047, disc_loss = 0.03080310907376849
Trained batch 437 in epoch 5, gen_loss = 0.4166945721188637, disc_loss = 0.030749038368948316
Trained batch 438 in epoch 5, gen_loss = 0.416686980083483, disc_loss = 0.030693701957405495
Trained batch 439 in epoch 5, gen_loss = 0.41673175753517583, disc_loss = 0.030668496195523236
Trained batch 440 in epoch 5, gen_loss = 0.41646391545293554, disc_loss = 0.03066367311234208
Trained batch 441 in epoch 5, gen_loss = 0.4166007228027102, disc_loss = 0.030685729822312477
Trained batch 442 in epoch 5, gen_loss = 0.4166198951396124, disc_loss = 0.030639206386186
Trained batch 443 in epoch 5, gen_loss = 0.41649523525087684, disc_loss = 0.03060203556680364
Trained batch 444 in epoch 5, gen_loss = 0.41635841492856485, disc_loss = 0.030584713960003652
Trained batch 445 in epoch 5, gen_loss = 0.4164764180846278, disc_loss = 0.030570930764789072
Trained batch 446 in epoch 5, gen_loss = 0.41642791746180063, disc_loss = 0.03051214505682889
Trained batch 447 in epoch 5, gen_loss = 0.4165327589559768, disc_loss = 0.03047235529291876
Trained batch 448 in epoch 5, gen_loss = 0.4165533045617934, disc_loss = 0.030413564260352095
Trained batch 449 in epoch 5, gen_loss = 0.41653177850776246, disc_loss = 0.03037980577701496
Trained batch 450 in epoch 5, gen_loss = 0.4164883269703309, disc_loss = 0.0303265460903143
Trained batch 451 in epoch 5, gen_loss = 0.41642136977309674, disc_loss = 0.030280920673796362
Trained batch 452 in epoch 5, gen_loss = 0.4162543314708516, disc_loss = 0.03023241576790053
Trained batch 453 in epoch 5, gen_loss = 0.41626183458887006, disc_loss = 0.030209529530544177
Trained batch 454 in epoch 5, gen_loss = 0.4161898958814013, disc_loss = 0.030178821489092084
Trained batch 455 in epoch 5, gen_loss = 0.4163154491076344, disc_loss = 0.030156408535651536
Trained batch 456 in epoch 5, gen_loss = 0.4162720620501746, disc_loss = 0.030098816099692813
Trained batch 457 in epoch 5, gen_loss = 0.41613257484404803, disc_loss = 0.03005951231723757
Trained batch 458 in epoch 5, gen_loss = 0.41631619051131286, disc_loss = 0.030028063719706663
Trained batch 459 in epoch 5, gen_loss = 0.41634526155565094, disc_loss = 0.02997772442176938
Trained batch 460 in epoch 5, gen_loss = 0.4162590640744522, disc_loss = 0.029942766943069705
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 0.41130805015563965, disc_loss = 0.013216494582593441
Trained batch 1 in epoch 6, gen_loss = 0.4215349704027176, disc_loss = 0.008631071774289012
Trained batch 2 in epoch 6, gen_loss = 0.407227764527003, disc_loss = 0.0075955552359422045
Trained batch 3 in epoch 6, gen_loss = 0.41304708272218704, disc_loss = 0.01738464180380106
Trained batch 4 in epoch 6, gen_loss = 0.39629673957824707, disc_loss = 0.024949482828378677
Trained batch 5 in epoch 6, gen_loss = 0.39672789971033734, disc_loss = 0.024689932664235432
Trained batch 6 in epoch 6, gen_loss = 0.4137709566525051, disc_loss = 0.056956946849823
Trained batch 7 in epoch 6, gen_loss = 0.4092336371541023, disc_loss = 0.08136479929089546
Trained batch 8 in epoch 6, gen_loss = 0.40200358298089767, disc_loss = 0.08838858207066853
Trained batch 9 in epoch 6, gen_loss = 0.3996891379356384, disc_loss = 0.08909730166196823
Trained batch 10 in epoch 6, gen_loss = 0.39752945574847137, disc_loss = 0.09990754046223381
Trained batch 11 in epoch 6, gen_loss = 0.3989899307489395, disc_loss = 0.09752017570038636
Trained batch 12 in epoch 6, gen_loss = 0.40091994175544154, disc_loss = 0.09464011398645547
Trained batch 13 in epoch 6, gen_loss = 0.396740015063967, disc_loss = 0.09449732463274683
Trained batch 14 in epoch 6, gen_loss = 0.3977168599764506, disc_loss = 0.09022524617612362
Trained batch 15 in epoch 6, gen_loss = 0.39702507480978966, disc_loss = 0.08566561387851834
Trained batch 16 in epoch 6, gen_loss = 0.39977529294350567, disc_loss = 0.08152293331701965
Trained batch 17 in epoch 6, gen_loss = 0.4029902650250329, disc_loss = 0.07735481946211722
Trained batch 18 in epoch 6, gen_loss = 0.40569992441880076, disc_loss = 0.07370572983238258
Trained batch 19 in epoch 6, gen_loss = 0.4076665654778481, disc_loss = 0.07031239727512002
Trained batch 20 in epoch 6, gen_loss = 0.4091718182677314, disc_loss = 0.06716664379373902
Trained batch 21 in epoch 6, gen_loss = 0.407556180249561, disc_loss = 0.06448897952213883
Trained batch 22 in epoch 6, gen_loss = 0.40748826705891156, disc_loss = 0.062044130597749485
Trained batch 23 in epoch 6, gen_loss = 0.40596411749720573, disc_loss = 0.05965797354777654
Trained batch 24 in epoch 6, gen_loss = 0.4069627773761749, disc_loss = 0.05749686088413
Trained batch 25 in epoch 6, gen_loss = 0.40627614580667937, disc_loss = 0.05638805357739329
Trained batch 26 in epoch 6, gen_loss = 0.40773094031545853, disc_loss = 0.05465534864062512
Trained batch 27 in epoch 6, gen_loss = 0.40712990186044146, disc_loss = 0.053356720433969586
Trained batch 28 in epoch 6, gen_loss = 0.40758427772028694, disc_loss = 0.05171217348683497
Trained batch 29 in epoch 6, gen_loss = 0.4102680027484894, disc_loss = 0.05052442050849398
Trained batch 30 in epoch 6, gen_loss = 0.4091154875293855, disc_loss = 0.0493101617321372
Trained batch 31 in epoch 6, gen_loss = 0.41144558135420084, disc_loss = 0.04812844441039488
Trained batch 32 in epoch 6, gen_loss = 0.4131764290910779, disc_loss = 0.046977645632895554
Trained batch 33 in epoch 6, gen_loss = 0.4122391930397819, disc_loss = 0.04581933841109276
Trained batch 34 in epoch 6, gen_loss = 0.41590242300714764, disc_loss = 0.04490038095308202
Trained batch 35 in epoch 6, gen_loss = 0.4172807095779313, disc_loss = 0.04392993077635765
Trained batch 36 in epoch 6, gen_loss = 0.4148639658012906, disc_loss = 0.04303125750172783
Trained batch 37 in epoch 6, gen_loss = 0.41700361433782074, disc_loss = 0.04204928116431754
Trained batch 38 in epoch 6, gen_loss = 0.41896392748906064, disc_loss = 0.041340777781815864
Trained batch 39 in epoch 6, gen_loss = 0.41856551766395567, disc_loss = 0.04042056397302076
Trained batch 40 in epoch 6, gen_loss = 0.41758585412327837, disc_loss = 0.03995764636003026
Trained batch 41 in epoch 6, gen_loss = 0.41861006972335635, disc_loss = 0.03913052498717748
Trained batch 42 in epoch 6, gen_loss = 0.4195139276426892, disc_loss = 0.03840864600267175
Trained batch 43 in epoch 6, gen_loss = 0.4209713184020736, disc_loss = 0.03785660150672563
Trained batch 44 in epoch 6, gen_loss = 0.4212514321009318, disc_loss = 0.03710796521562669
Trained batch 45 in epoch 6, gen_loss = 0.42190740419470746, disc_loss = 0.036515272273074675
Trained batch 46 in epoch 6, gen_loss = 0.42227450203388295, disc_loss = 0.035873088559651
Trained batch 47 in epoch 6, gen_loss = 0.42177663805584115, disc_loss = 0.03523840210012471
Trained batch 48 in epoch 6, gen_loss = 0.42137267638225945, disc_loss = 0.034611517411409595
Trained batch 49 in epoch 6, gen_loss = 0.4211172568798065, disc_loss = 0.033984659435227514
Trained batch 50 in epoch 6, gen_loss = 0.41970182575431525, disc_loss = 0.03353540907047835
Trained batch 51 in epoch 6, gen_loss = 0.42173802107572556, disc_loss = 0.033358201142758705
Trained batch 52 in epoch 6, gen_loss = 0.42260163010291335, disc_loss = 0.03280700877625144
Trained batch 53 in epoch 6, gen_loss = 0.4232182243355998, disc_loss = 0.0323347740513445
Trained batch 54 in epoch 6, gen_loss = 0.42292087890885094, disc_loss = 0.03181848871436986
Trained batch 55 in epoch 6, gen_loss = 0.4219228838171278, disc_loss = 0.031302003522536585
Trained batch 56 in epoch 6, gen_loss = 0.42156408439602766, disc_loss = 0.0308218013184766
Trained batch 57 in epoch 6, gen_loss = 0.42043765146156836, disc_loss = 0.030367042781014382
Trained batch 58 in epoch 6, gen_loss = 0.4202135973057504, disc_loss = 0.029915000051575696
Trained batch 59 in epoch 6, gen_loss = 0.420714149872462, disc_loss = 0.02969253793514023
Trained batch 60 in epoch 6, gen_loss = 0.42205948907820906, disc_loss = 0.029341611133308194
Trained batch 61 in epoch 6, gen_loss = 0.42184252123678884, disc_loss = 0.028946976132330396
Trained batch 62 in epoch 6, gen_loss = 0.42189494106504655, disc_loss = 0.028528777298532308
Trained batch 63 in epoch 6, gen_loss = 0.42048629466444254, disc_loss = 0.02823478935897583
Trained batch 64 in epoch 6, gen_loss = 0.4204656591782203, disc_loss = 0.027875253214285925
Trained batch 65 in epoch 6, gen_loss = 0.41975956026351813, disc_loss = 0.02752668246852629
Trained batch 66 in epoch 6, gen_loss = 0.4207644831778398, disc_loss = 0.027193615407641255
Trained batch 67 in epoch 6, gen_loss = 0.41964029170134487, disc_loss = 0.02684374018024434
Trained batch 68 in epoch 6, gen_loss = 0.4190682937269625, disc_loss = 0.02654004516754893
Trained batch 69 in epoch 6, gen_loss = 0.41866602386747087, disc_loss = 0.026364098928336587
Trained batch 70 in epoch 6, gen_loss = 0.4194954537170034, disc_loss = 0.02616729892947724
Trained batch 71 in epoch 6, gen_loss = 0.4191078796154923, disc_loss = 0.02587423028631343
Trained batch 72 in epoch 6, gen_loss = 0.41861137094563, disc_loss = 0.025660494291414954
Trained batch 73 in epoch 6, gen_loss = 0.4185207292840287, disc_loss = 0.025388968579873845
Trained batch 74 in epoch 6, gen_loss = 0.41804461359977724, disc_loss = 0.025116192040344078
Trained batch 75 in epoch 6, gen_loss = 0.41828459775761556, disc_loss = 0.02488741096672847
Trained batch 76 in epoch 6, gen_loss = 0.41778802368548007, disc_loss = 0.024778423655487887
Trained batch 77 in epoch 6, gen_loss = 0.4182355266350966, disc_loss = 0.024549255875918347
Trained batch 78 in epoch 6, gen_loss = 0.41902686900730374, disc_loss = 0.02432148203937502
Trained batch 79 in epoch 6, gen_loss = 0.41883997023105624, disc_loss = 0.024102013104129582
Trained batch 80 in epoch 6, gen_loss = 0.41948519702310916, disc_loss = 0.024028566688943057
Trained batch 81 in epoch 6, gen_loss = 0.4199159828627982, disc_loss = 0.02378054172731936
Trained batch 82 in epoch 6, gen_loss = 0.41964091809399157, disc_loss = 0.023652530381882406
Trained batch 83 in epoch 6, gen_loss = 0.4193934510861124, disc_loss = 0.02364874540805994
Trained batch 84 in epoch 6, gen_loss = 0.4202044378308689, disc_loss = 0.02369725115268546
Trained batch 85 in epoch 6, gen_loss = 0.4195208047018495, disc_loss = 0.024082570038952453
Trained batch 86 in epoch 6, gen_loss = 0.4182052667113556, disc_loss = 0.024467473555270625
Trained batch 87 in epoch 6, gen_loss = 0.4172008250924674, disc_loss = 0.0243512057244185
Trained batch 88 in epoch 6, gen_loss = 0.4174976543094335, disc_loss = 0.024143230269422358
Trained batch 89 in epoch 6, gen_loss = 0.4166357381476296, disc_loss = 0.02413293797419303
Trained batch 90 in epoch 6, gen_loss = 0.4164651606109116, disc_loss = 0.024343797502077217
Trained batch 91 in epoch 6, gen_loss = 0.41669742050378217, disc_loss = 0.02425074858246776
Trained batch 92 in epoch 6, gen_loss = 0.41540451203623124, disc_loss = 0.024322688394296233
Trained batch 93 in epoch 6, gen_loss = 0.41504780282365517, disc_loss = 0.028513300425789142
Trained batch 94 in epoch 6, gen_loss = 0.41374181446276215, disc_loss = 0.030250781906866715
Trained batch 95 in epoch 6, gen_loss = 0.4137127911671996, disc_loss = 0.030268394596835908
Trained batch 96 in epoch 6, gen_loss = 0.41334064873223453, disc_loss = 0.03043671979175247
Trained batch 97 in epoch 6, gen_loss = 0.41287341805136935, disc_loss = 0.03027420684372132
Trained batch 98 in epoch 6, gen_loss = 0.4121658221037701, disc_loss = 0.03015599325957774
Trained batch 99 in epoch 6, gen_loss = 0.4114749795198441, disc_loss = 0.030053260936401784
Trained batch 100 in epoch 6, gen_loss = 0.41077384087118773, disc_loss = 0.029950366433857397
Trained batch 101 in epoch 6, gen_loss = 0.41123515338289973, disc_loss = 0.030277009519255337
Trained batch 102 in epoch 6, gen_loss = 0.41082469699452223, disc_loss = 0.032532371196317154
Trained batch 103 in epoch 6, gen_loss = 0.4112195842541181, disc_loss = 0.0345540228434122
Trained batch 104 in epoch 6, gen_loss = 0.41116079205558415, disc_loss = 0.03436632078761856
Trained batch 105 in epoch 6, gen_loss = 0.4106921137503858, disc_loss = 0.03430381020583775
Trained batch 106 in epoch 6, gen_loss = 0.4106139718929184, disc_loss = 0.034130595802877826
Trained batch 107 in epoch 6, gen_loss = 0.41056964822389463, disc_loss = 0.033898481085930986
Trained batch 108 in epoch 6, gen_loss = 0.4112633130419145, disc_loss = 0.033862374385459984
Trained batch 109 in epoch 6, gen_loss = 0.41036604913798247, disc_loss = 0.0341820409394462
Trained batch 110 in epoch 6, gen_loss = 0.4102342867099487, disc_loss = 0.0372611723278087
Trained batch 111 in epoch 6, gen_loss = 0.4098723544073956, disc_loss = 0.038489679011815624
Trained batch 112 in epoch 6, gen_loss = 0.40951996698843696, disc_loss = 0.03842440149046283
Trained batch 113 in epoch 6, gen_loss = 0.40968562244323264, disc_loss = 0.03866713474864107
Trained batch 114 in epoch 6, gen_loss = 0.40874351885007776, disc_loss = 0.038879560910003344
Trained batch 115 in epoch 6, gen_loss = 0.4082081924224722, disc_loss = 0.038663699472290945
Trained batch 116 in epoch 6, gen_loss = 0.4069443154029357, disc_loss = 0.038579493462561794
Trained batch 117 in epoch 6, gen_loss = 0.40688147105402866, disc_loss = 0.03903315837053045
Trained batch 118 in epoch 6, gen_loss = 0.4066594473454131, disc_loss = 0.040357844313184
Trained batch 119 in epoch 6, gen_loss = 0.4062129298845927, disc_loss = 0.04139898110879585
Trained batch 120 in epoch 6, gen_loss = 0.40597379330761174, disc_loss = 0.04147658406656759
Trained batch 121 in epoch 6, gen_loss = 0.4064600365083726, disc_loss = 0.041288341506246905
Trained batch 122 in epoch 6, gen_loss = 0.4072963590544414, disc_loss = 0.04161954753297737
Trained batch 123 in epoch 6, gen_loss = 0.4064518069067309, disc_loss = 0.04341798327157214
Trained batch 124 in epoch 6, gen_loss = 0.4067544941902161, disc_loss = 0.04408732250705361
Trained batch 125 in epoch 6, gen_loss = 0.4065841710756695, disc_loss = 0.04387477478234186
Trained batch 126 in epoch 6, gen_loss = 0.40706530283755205, disc_loss = 0.04357488656152538
Trained batch 127 in epoch 6, gen_loss = 0.40678385458886623, disc_loss = 0.0432868022180628
Trained batch 128 in epoch 6, gen_loss = 0.40640395417693975, disc_loss = 0.04306454894443353
Trained batch 129 in epoch 6, gen_loss = 0.40583697786697975, disc_loss = 0.042764699917573194
Trained batch 130 in epoch 6, gen_loss = 0.4057179464183691, disc_loss = 0.042491605917688545
Trained batch 131 in epoch 6, gen_loss = 0.40555970573967154, disc_loss = 0.04219760089604692
Trained batch 132 in epoch 6, gen_loss = 0.4053637981414795, disc_loss = 0.0419054521419304
Trained batch 133 in epoch 6, gen_loss = 0.40500662197817616, disc_loss = 0.041638219859381556
Trained batch 134 in epoch 6, gen_loss = 0.4048297844551228, disc_loss = 0.04142483960388711
Trained batch 135 in epoch 6, gen_loss = 0.4050263902720283, disc_loss = 0.041190955971080044
Trained batch 136 in epoch 6, gen_loss = 0.4047229089876161, disc_loss = 0.04102887007081541
Trained batch 137 in epoch 6, gen_loss = 0.40456734468107636, disc_loss = 0.04095797862121971
Trained batch 138 in epoch 6, gen_loss = 0.4049019123152863, disc_loss = 0.041015524904598755
Trained batch 139 in epoch 6, gen_loss = 0.40473685626472744, disc_loss = 0.040754037338774654
Trained batch 140 in epoch 6, gen_loss = 0.4052154859329792, disc_loss = 0.040586476592373445
Trained batch 141 in epoch 6, gen_loss = 0.4052552127502334, disc_loss = 0.04033415834583395
Trained batch 142 in epoch 6, gen_loss = 0.40517172008961233, disc_loss = 0.040083007035464364
Trained batch 143 in epoch 6, gen_loss = 0.40518570008377236, disc_loss = 0.039845891463402144
Trained batch 144 in epoch 6, gen_loss = 0.4049430201793539, disc_loss = 0.03959828175700687
Trained batch 145 in epoch 6, gen_loss = 0.4053400538555563, disc_loss = 0.039418501567337914
Trained batch 146 in epoch 6, gen_loss = 0.4047892649157518, disc_loss = 0.039183308064722186
Trained batch 147 in epoch 6, gen_loss = 0.4047355607554719, disc_loss = 0.038972389121300764
Trained batch 148 in epoch 6, gen_loss = 0.4049322349113106, disc_loss = 0.038742401088656696
Trained batch 149 in epoch 6, gen_loss = 0.4046814761559169, disc_loss = 0.03852803471342971
Trained batch 150 in epoch 6, gen_loss = 0.40491552226590793, disc_loss = 0.03836274363674125
Trained batch 151 in epoch 6, gen_loss = 0.4047986116064222, disc_loss = 0.03866950402459081
Trained batch 152 in epoch 6, gen_loss = 0.4052168637319328, disc_loss = 0.03917290230914707
Trained batch 153 in epoch 6, gen_loss = 0.40547557117102984, disc_loss = 0.03951760690641142
Trained batch 154 in epoch 6, gen_loss = 0.4046149722991451, disc_loss = 0.04095836098666393
Trained batch 155 in epoch 6, gen_loss = 0.40454197006347853, disc_loss = 0.04084178443120506
Trained batch 156 in epoch 6, gen_loss = 0.40436598772455934, disc_loss = 0.041284340352211506
Trained batch 157 in epoch 6, gen_loss = 0.40429299862324436, disc_loss = 0.041102055190543677
Trained batch 158 in epoch 6, gen_loss = 0.40437589482691305, disc_loss = 0.04089019153671304
Trained batch 159 in epoch 6, gen_loss = 0.4044513827189803, disc_loss = 0.04070354616997065
Trained batch 160 in epoch 6, gen_loss = 0.4041817837990589, disc_loss = 0.04082153516138979
Trained batch 161 in epoch 6, gen_loss = 0.4044588287303477, disc_loss = 0.04081293644619255
Trained batch 162 in epoch 6, gen_loss = 0.404477953545155, disc_loss = 0.041085536478864364
Trained batch 163 in epoch 6, gen_loss = 0.40403686990825144, disc_loss = 0.04226879201539815
Trained batch 164 in epoch 6, gen_loss = 0.4044635037581126, disc_loss = 0.04400155949124107
Trained batch 165 in epoch 6, gen_loss = 0.4044764675648816, disc_loss = 0.044417275167743575
Trained batch 166 in epoch 6, gen_loss = 0.40429052621304634, disc_loss = 0.04461934081345663
Trained batch 167 in epoch 6, gen_loss = 0.4040992284814517, disc_loss = 0.04535117105253795
Trained batch 168 in epoch 6, gen_loss = 0.40374343687966024, disc_loss = 0.04703914024316039
Trained batch 169 in epoch 6, gen_loss = 0.4033698031130959, disc_loss = 0.04736812227159081
Trained batch 170 in epoch 6, gen_loss = 0.40350889148767927, disc_loss = 0.0473949932370727
Trained batch 171 in epoch 6, gen_loss = 0.40308746591556904, disc_loss = 0.04751457027728171
Trained batch 172 in epoch 6, gen_loss = 0.40306444423047105, disc_loss = 0.047468628848746766
Trained batch 173 in epoch 6, gen_loss = 0.40296369311453284, disc_loss = 0.0475579573914687
Trained batch 174 in epoch 6, gen_loss = 0.40287179929869515, disc_loss = 0.04734721506945789
Trained batch 175 in epoch 6, gen_loss = 0.402933400801637, disc_loss = 0.04714648369091182
Trained batch 176 in epoch 6, gen_loss = 0.4030849942043003, disc_loss = 0.04695405601260731
Trained batch 177 in epoch 6, gen_loss = 0.40272671670726173, disc_loss = 0.04676358524338457
Trained batch 178 in epoch 6, gen_loss = 0.40284273960736877, disc_loss = 0.04706761870642489
Trained batch 179 in epoch 6, gen_loss = 0.40246677663591174, disc_loss = 0.048033469637286746
Trained batch 180 in epoch 6, gen_loss = 0.4022827481038004, disc_loss = 0.04783890474695733
Trained batch 181 in epoch 6, gen_loss = 0.40207238577224397, disc_loss = 0.04774916464856897
Trained batch 182 in epoch 6, gen_loss = 0.4016853707735656, disc_loss = 0.047650421599353676
Trained batch 183 in epoch 6, gen_loss = 0.4015492662463499, disc_loss = 0.04758525712785068
Trained batch 184 in epoch 6, gen_loss = 0.4010120763971999, disc_loss = 0.04752686323874907
Trained batch 185 in epoch 6, gen_loss = 0.4014816484464112, disc_loss = 0.04753794935807305
Trained batch 186 in epoch 6, gen_loss = 0.40117234119119494, disc_loss = 0.04765269903461125
Trained batch 187 in epoch 6, gen_loss = 0.4015446936196469, disc_loss = 0.04819991402055553
Trained batch 188 in epoch 6, gen_loss = 0.40137587006760655, disc_loss = 0.04827610973056859
Trained batch 189 in epoch 6, gen_loss = 0.40121655244576304, disc_loss = 0.04815352574897636
Trained batch 190 in epoch 6, gen_loss = 0.40102621476063555, disc_loss = 0.04799424046626149
Trained batch 191 in epoch 6, gen_loss = 0.40096376463770866, disc_loss = 0.047819906492804876
Trained batch 192 in epoch 6, gen_loss = 0.4009654074135222, disc_loss = 0.04769327383068598
Trained batch 193 in epoch 6, gen_loss = 0.4011255289168702, disc_loss = 0.04774461396292966
Trained batch 194 in epoch 6, gen_loss = 0.4010116716225942, disc_loss = 0.04867380866661477
Trained batch 195 in epoch 6, gen_loss = 0.40157496609858107, disc_loss = 0.050739944528797834
Trained batch 196 in epoch 6, gen_loss = 0.401770164518792, disc_loss = 0.050744630449550784
Trained batch 197 in epoch 6, gen_loss = 0.4016443370568632, disc_loss = 0.0506252049705992
Trained batch 198 in epoch 6, gen_loss = 0.4022771015239121, disc_loss = 0.05041021481741351
Trained batch 199 in epoch 6, gen_loss = 0.40266114369034767, disc_loss = 0.050221871888497846
Trained batch 200 in epoch 6, gen_loss = 0.40278989966235945, disc_loss = 0.050018445107928335
Trained batch 201 in epoch 6, gen_loss = 0.4027765294407854, disc_loss = 0.04985168879266164
Trained batch 202 in epoch 6, gen_loss = 0.40268502021070773, disc_loss = 0.04970402952875447
Trained batch 203 in epoch 6, gen_loss = 0.40280483122549804, disc_loss = 0.049556304569420055
Trained batch 204 in epoch 6, gen_loss = 0.4027510208327596, disc_loss = 0.04935642455522789
Trained batch 205 in epoch 6, gen_loss = 0.40278047294292635, disc_loss = 0.049149363992274604
Trained batch 206 in epoch 6, gen_loss = 0.40288211844393595, disc_loss = 0.04893202549139047
Trained batch 207 in epoch 6, gen_loss = 0.40282695253308004, disc_loss = 0.04871814348175226
Trained batch 208 in epoch 6, gen_loss = 0.4027492689173758, disc_loss = 0.048516680084338244
Trained batch 209 in epoch 6, gen_loss = 0.4026361258257003, disc_loss = 0.04838593361256201
Trained batch 210 in epoch 6, gen_loss = 0.4025298030738017, disc_loss = 0.04821127110549306
Trained batch 211 in epoch 6, gen_loss = 0.4022576932637197, disc_loss = 0.04842819489059829
Trained batch 212 in epoch 6, gen_loss = 0.4024417156904516, disc_loss = 0.04877571409520094
Trained batch 213 in epoch 6, gen_loss = 0.40246860780448557, disc_loss = 0.04862935306117043
Trained batch 214 in epoch 6, gen_loss = 0.40224122474359914, disc_loss = 0.04848734372901882
Trained batch 215 in epoch 6, gen_loss = 0.40220774889544203, disc_loss = 0.048354601620101474
Trained batch 216 in epoch 6, gen_loss = 0.4025986926621556, disc_loss = 0.04818539355649754
Trained batch 217 in epoch 6, gen_loss = 0.4025325415604705, disc_loss = 0.048024697510158185
Trained batch 218 in epoch 6, gen_loss = 0.40292613174273, disc_loss = 0.0478998023291548
Trained batch 219 in epoch 6, gen_loss = 0.4026788798245517, disc_loss = 0.047906854654535314
Trained batch 220 in epoch 6, gen_loss = 0.40323982950788817, disc_loss = 0.048206073538573015
Trained batch 221 in epoch 6, gen_loss = 0.40302225692315147, disc_loss = 0.04807357362425374
Trained batch 222 in epoch 6, gen_loss = 0.4035504290608547, disc_loss = 0.04812177364096346
Trained batch 223 in epoch 6, gen_loss = 0.4035801338031888, disc_loss = 0.04833401386921261
Trained batch 224 in epoch 6, gen_loss = 0.40352083457840815, disc_loss = 0.04814943978666431
Trained batch 225 in epoch 6, gen_loss = 0.4033496706886629, disc_loss = 0.04813118319674107
Trained batch 226 in epoch 6, gen_loss = 0.4032963971209421, disc_loss = 0.047957824156434986
Trained batch 227 in epoch 6, gen_loss = 0.4032599387461679, disc_loss = 0.04791856050519926
Trained batch 228 in epoch 6, gen_loss = 0.40351643494643497, disc_loss = 0.04775644064368477
Trained batch 229 in epoch 6, gen_loss = 0.40341184450232465, disc_loss = 0.047640867392613515
Trained batch 230 in epoch 6, gen_loss = 0.40324718250340713, disc_loss = 0.047452645353142385
Trained batch 231 in epoch 6, gen_loss = 0.4030977608314876, disc_loss = 0.047398533560696926
Trained batch 232 in epoch 6, gen_loss = 0.40301147717263053, disc_loss = 0.04789592877386114
Trained batch 233 in epoch 6, gen_loss = 0.40284639456842697, disc_loss = 0.049128254080533534
Trained batch 234 in epoch 6, gen_loss = 0.4030200481414795, disc_loss = 0.04896828243806166
Trained batch 235 in epoch 6, gen_loss = 0.40266968600325664, disc_loss = 0.048851382919642444
Trained batch 236 in epoch 6, gen_loss = 0.40258546569679354, disc_loss = 0.04868107916343219
Trained batch 237 in epoch 6, gen_loss = 0.4027052660699652, disc_loss = 0.04849511790069744
Trained batch 238 in epoch 6, gen_loss = 0.40255445865407646, disc_loss = 0.04837893081778294
Trained batch 239 in epoch 6, gen_loss = 0.402486082042257, disc_loss = 0.04825055330390266
Trained batch 240 in epoch 6, gen_loss = 0.4024160265675224, disc_loss = 0.04815612102402722
Trained batch 241 in epoch 6, gen_loss = 0.40203487762242307, disc_loss = 0.0484993954060199
Trained batch 242 in epoch 6, gen_loss = 0.40222533973156177, disc_loss = 0.04952483743509668
Trained batch 243 in epoch 6, gen_loss = 0.40181379496562675, disc_loss = 0.05001559297527477
Trained batch 244 in epoch 6, gen_loss = 0.4018669241545152, disc_loss = 0.05002477561047643
Trained batch 245 in epoch 6, gen_loss = 0.40199312095235035, disc_loss = 0.05018588179453632
Trained batch 246 in epoch 6, gen_loss = 0.40180964942885794, disc_loss = 0.05001133256441035
Trained batch 247 in epoch 6, gen_loss = 0.40174733919482075, disc_loss = 0.04983817614641251
Trained batch 248 in epoch 6, gen_loss = 0.40180665793189085, disc_loss = 0.049685898576358176
Trained batch 249 in epoch 6, gen_loss = 0.4019232335090637, disc_loss = 0.04952977121528238
Trained batch 250 in epoch 6, gen_loss = 0.40221293882069836, disc_loss = 0.049377848166950136
Trained batch 251 in epoch 6, gen_loss = 0.40181577252963235, disc_loss = 0.049286531571794065
Trained batch 252 in epoch 6, gen_loss = 0.40199055348931567, disc_loss = 0.049140411888326525
Trained batch 253 in epoch 6, gen_loss = 0.40210253446120914, disc_loss = 0.049046803976218474
Trained batch 254 in epoch 6, gen_loss = 0.4021071625690834, disc_loss = 0.04891692201935632
Trained batch 255 in epoch 6, gen_loss = 0.4023335910169408, disc_loss = 0.04880194007910177
Trained batch 256 in epoch 6, gen_loss = 0.4024791948294361, disc_loss = 0.0486281076437116
Trained batch 257 in epoch 6, gen_loss = 0.40292322323765867, disc_loss = 0.04850643372448349
Trained batch 258 in epoch 6, gen_loss = 0.40293118150538, disc_loss = 0.04836829522585057
Trained batch 259 in epoch 6, gen_loss = 0.4029385642363475, disc_loss = 0.048199273055741704
Trained batch 260 in epoch 6, gen_loss = 0.4030750662202579, disc_loss = 0.04802916750536654
Trained batch 261 in epoch 6, gen_loss = 0.40316565084548395, disc_loss = 0.04786745108617825
Trained batch 262 in epoch 6, gen_loss = 0.40325086776294633, disc_loss = 0.047709431466487144
Trained batch 263 in epoch 6, gen_loss = 0.40351019833575597, disc_loss = 0.04755710491427277
Trained batch 264 in epoch 6, gen_loss = 0.40337410265544676, disc_loss = 0.04742009960167672
Trained batch 265 in epoch 6, gen_loss = 0.40374724398878287, disc_loss = 0.047275096149169804
Trained batch 266 in epoch 6, gen_loss = 0.40364077073357973, disc_loss = 0.04714028585670788
Trained batch 267 in epoch 6, gen_loss = 0.4036095421483268, disc_loss = 0.04701311801779153
Trained batch 268 in epoch 6, gen_loss = 0.40377941439586057, disc_loss = 0.04687016556596861
Trained batch 269 in epoch 6, gen_loss = 0.40378143897763, disc_loss = 0.046723956838077695
Trained batch 270 in epoch 6, gen_loss = 0.4035787650579896, disc_loss = 0.046565953681650965
Trained batch 271 in epoch 6, gen_loss = 0.40363734116887345, disc_loss = 0.04646509007023483
Trained batch 272 in epoch 6, gen_loss = 0.4035256949318198, disc_loss = 0.04640003801886361
Trained batch 273 in epoch 6, gen_loss = 0.4033599971202168, disc_loss = 0.04632121027977525
Trained batch 274 in epoch 6, gen_loss = 0.4034356694871729, disc_loss = 0.046241048769178714
Trained batch 275 in epoch 6, gen_loss = 0.40353491178889206, disc_loss = 0.04615549391398773
Trained batch 276 in epoch 6, gen_loss = 0.40354792047493726, disc_loss = 0.04605503781574244
Trained batch 277 in epoch 6, gen_loss = 0.4036979941155413, disc_loss = 0.04592935065738857
Trained batch 278 in epoch 6, gen_loss = 0.4040384467784649, disc_loss = 0.0457920465888756
Trained batch 279 in epoch 6, gen_loss = 0.4041785258267607, disc_loss = 0.045648577448446304
Trained batch 280 in epoch 6, gen_loss = 0.4043693086430696, disc_loss = 0.04550644675157036
Trained batch 281 in epoch 6, gen_loss = 0.40438285956146025, disc_loss = 0.045364442899004154
Trained batch 282 in epoch 6, gen_loss = 0.40442491462289654, disc_loss = 0.04521686721481251
Trained batch 283 in epoch 6, gen_loss = 0.4044503719663956, disc_loss = 0.04509029167041865
Trained batch 284 in epoch 6, gen_loss = 0.4045180443086122, disc_loss = 0.04494803896043123
Trained batch 285 in epoch 6, gen_loss = 0.404622416500445, disc_loss = 0.044806843260433396
Trained batch 286 in epoch 6, gen_loss = 0.4046444368487036, disc_loss = 0.04466177497257053
Trained batch 287 in epoch 6, gen_loss = 0.40458949375897646, disc_loss = 0.04455115021442503
Trained batch 288 in epoch 6, gen_loss = 0.4045016952245706, disc_loss = 0.04442829885971201
Trained batch 289 in epoch 6, gen_loss = 0.40460519574839493, disc_loss = 0.04431352767338655
Trained batch 290 in epoch 6, gen_loss = 0.40469021301498936, disc_loss = 0.04418968473388285
Trained batch 291 in epoch 6, gen_loss = 0.40476196300085276, disc_loss = 0.0440542293267567
Trained batch 292 in epoch 6, gen_loss = 0.40482130412762485, disc_loss = 0.043930389709395605
Trained batch 293 in epoch 6, gen_loss = 0.4049042930611137, disc_loss = 0.043801782352590087
Trained batch 294 in epoch 6, gen_loss = 0.4048647590612961, disc_loss = 0.0436700652219292
Trained batch 295 in epoch 6, gen_loss = 0.4050105338966524, disc_loss = 0.04354189358403075
Trained batch 296 in epoch 6, gen_loss = 0.4049972149258109, disc_loss = 0.04340430271658131
Trained batch 297 in epoch 6, gen_loss = 0.40504145212221465, disc_loss = 0.04326997489837192
Trained batch 298 in epoch 6, gen_loss = 0.4049528726566595, disc_loss = 0.04314642578649979
Trained batch 299 in epoch 6, gen_loss = 0.4051352259516716, disc_loss = 0.04301626205444336
Trained batch 300 in epoch 6, gen_loss = 0.40513886694496254, disc_loss = 0.04288260573428434
Trained batch 301 in epoch 6, gen_loss = 0.405149149480245, disc_loss = 0.04275521311279855
Trained batch 302 in epoch 6, gen_loss = 0.40510119483022405, disc_loss = 0.042625263078205855
Trained batch 303 in epoch 6, gen_loss = 0.4052516414146674, disc_loss = 0.042498430022724756
Trained batch 304 in epoch 6, gen_loss = 0.40542605841746093, disc_loss = 0.04237052900869338
Trained batch 305 in epoch 6, gen_loss = 0.4053692469020295, disc_loss = 0.04225347102832755
Trained batch 306 in epoch 6, gen_loss = 0.40523134458336846, disc_loss = 0.042126723918578426
Trained batch 307 in epoch 6, gen_loss = 0.4051158782336619, disc_loss = 0.042004344904759
Trained batch 308 in epoch 6, gen_loss = 0.405043515283313, disc_loss = 0.04187513906116866
Trained batch 309 in epoch 6, gen_loss = 0.4049730026914227, disc_loss = 0.0417498595862379
Trained batch 310 in epoch 6, gen_loss = 0.40491764443863626, disc_loss = 0.04162202989442987
Trained batch 311 in epoch 6, gen_loss = 0.40502085278813654, disc_loss = 0.041497277545903884
Trained batch 312 in epoch 6, gen_loss = 0.40503464329737826, disc_loss = 0.04137932926568146
Trained batch 313 in epoch 6, gen_loss = 0.4050113949806068, disc_loss = 0.0412556625714312
Trained batch 314 in epoch 6, gen_loss = 0.404975408221048, disc_loss = 0.04114134305836781
Trained batch 315 in epoch 6, gen_loss = 0.4050482072973553, disc_loss = 0.04102201914176038
Trained batch 316 in epoch 6, gen_loss = 0.405020092658064, disc_loss = 0.04089961833928709
Trained batch 317 in epoch 6, gen_loss = 0.4050697707717524, disc_loss = 0.04077809945674344
Trained batch 318 in epoch 6, gen_loss = 0.40509099244697716, disc_loss = 0.04066669582433088
Trained batch 319 in epoch 6, gen_loss = 0.4049041956663132, disc_loss = 0.0405582143474021
Trained batch 320 in epoch 6, gen_loss = 0.4048163486975376, disc_loss = 0.040451369219317426
Trained batch 321 in epoch 6, gen_loss = 0.40471452502360256, disc_loss = 0.04033421069204298
Trained batch 322 in epoch 6, gen_loss = 0.4046795650532371, disc_loss = 0.04021653467385623
Trained batch 323 in epoch 6, gen_loss = 0.4047375343464039, disc_loss = 0.04010166382750519
Trained batch 324 in epoch 6, gen_loss = 0.40481714808023894, disc_loss = 0.03998607988684223
Trained batch 325 in epoch 6, gen_loss = 0.40475352218180344, disc_loss = 0.03986979203235838
Trained batch 326 in epoch 6, gen_loss = 0.40470788256473134, disc_loss = 0.0397552676151424
Trained batch 327 in epoch 6, gen_loss = 0.40455977546005717, disc_loss = 0.0396449944492793
Trained batch 328 in epoch 6, gen_loss = 0.4047283767566855, disc_loss = 0.0395528427424266
Trained batch 329 in epoch 6, gen_loss = 0.4046920799847805, disc_loss = 0.03944629493846812
Trained batch 330 in epoch 6, gen_loss = 0.4045400658222844, disc_loss = 0.03934449405800495
Trained batch 331 in epoch 6, gen_loss = 0.40474648019635534, disc_loss = 0.0392370931832232
Trained batch 332 in epoch 6, gen_loss = 0.404390319868609, disc_loss = 0.03914582520141616
Trained batch 333 in epoch 6, gen_loss = 0.4043166874768491, disc_loss = 0.0390380667717737
Trained batch 334 in epoch 6, gen_loss = 0.4045652281882158, disc_loss = 0.038930780106960834
Trained batch 335 in epoch 6, gen_loss = 0.40452214765052, disc_loss = 0.03883043586254297
Trained batch 336 in epoch 6, gen_loss = 0.4047251613451395, disc_loss = 0.03872740906124343
Trained batch 337 in epoch 6, gen_loss = 0.4048162677584315, disc_loss = 0.03863339833832572
Trained batch 338 in epoch 6, gen_loss = 0.4046943002218342, disc_loss = 0.038532132001258546
Trained batch 339 in epoch 6, gen_loss = 0.4049045352374806, disc_loss = 0.03844549805610715
Trained batch 340 in epoch 6, gen_loss = 0.405012130562511, disc_loss = 0.03834732994164103
Trained batch 341 in epoch 6, gen_loss = 0.4048943326138614, disc_loss = 0.03825241986019482
Trained batch 342 in epoch 6, gen_loss = 0.40476453808236745, disc_loss = 0.03814971368385169
Trained batch 343 in epoch 6, gen_loss = 0.4048180661575739, disc_loss = 0.03806996418753379
Trained batch 344 in epoch 6, gen_loss = 0.4048738485661106, disc_loss = 0.038005755076427825
Trained batch 345 in epoch 6, gen_loss = 0.405030242969535, disc_loss = 0.03792781950609834
Trained batch 346 in epoch 6, gen_loss = 0.40481668178217556, disc_loss = 0.0379043035464152
Trained batch 347 in epoch 6, gen_loss = 0.40511783614925956, disc_loss = 0.037959091465695406
Trained batch 348 in epoch 6, gen_loss = 0.4051382087363213, disc_loss = 0.03786753245994961
Trained batch 349 in epoch 6, gen_loss = 0.40489930272102354, disc_loss = 0.03777643927506038
Trained batch 350 in epoch 6, gen_loss = 0.4050721285010335, disc_loss = 0.03774262713719467
Trained batch 351 in epoch 6, gen_loss = 0.4052916777066209, disc_loss = 0.037648679349910126
Trained batch 352 in epoch 6, gen_loss = 0.4053040475244225, disc_loss = 0.03760498741551938
Trained batch 353 in epoch 6, gen_loss = 0.4054279681821327, disc_loss = 0.03752517848575519
Trained batch 354 in epoch 6, gen_loss = 0.40549613925772654, disc_loss = 0.037431439523860605
Trained batch 355 in epoch 6, gen_loss = 0.4055344025405605, disc_loss = 0.03734484704452033
Trained batch 356 in epoch 6, gen_loss = 0.4057120323515072, disc_loss = 0.0372573403884195
Trained batch 357 in epoch 6, gen_loss = 0.405873991424145, disc_loss = 0.03718091580917923
Trained batch 358 in epoch 6, gen_loss = 0.4061645601453223, disc_loss = 0.03717531963357894
Trained batch 359 in epoch 6, gen_loss = 0.4062671221792698, disc_loss = 0.037085677002970545
Trained batch 360 in epoch 6, gen_loss = 0.40636425062890197, disc_loss = 0.037062206955683366
Trained batch 361 in epoch 6, gen_loss = 0.40666355703087803, disc_loss = 0.03701251458366355
Trained batch 362 in epoch 6, gen_loss = 0.40668508935894193, disc_loss = 0.03697972130235644
Trained batch 363 in epoch 6, gen_loss = 0.4068482979968354, disc_loss = 0.03694367105560889
Trained batch 364 in epoch 6, gen_loss = 0.40686550524136794, disc_loss = 0.036878703988782346
Trained batch 365 in epoch 6, gen_loss = 0.40681873082788916, disc_loss = 0.03682496572228892
Trained batch 366 in epoch 6, gen_loss = 0.4068463997717449, disc_loss = 0.03674602228133084
Trained batch 367 in epoch 6, gen_loss = 0.4068663670155017, disc_loss = 0.03666834162457077
Trained batch 368 in epoch 6, gen_loss = 0.4069836042760833, disc_loss = 0.03658998741195373
Trained batch 369 in epoch 6, gen_loss = 0.4071931665008133, disc_loss = 0.03650380124816218
Trained batch 370 in epoch 6, gen_loss = 0.4070781862960671, disc_loss = 0.03642123718080776
Trained batch 371 in epoch 6, gen_loss = 0.40716816340723344, disc_loss = 0.03633746546217471
Trained batch 372 in epoch 6, gen_loss = 0.40708686167688857, disc_loss = 0.03631172070389579
Trained batch 373 in epoch 6, gen_loss = 0.40743085933241613, disc_loss = 0.036249292383149744
Trained batch 374 in epoch 6, gen_loss = 0.4072115284601847, disc_loss = 0.03621935449664791
Trained batch 375 in epoch 6, gen_loss = 0.4071406742676775, disc_loss = 0.036150015619375364
Trained batch 376 in epoch 6, gen_loss = 0.4072928582009333, disc_loss = 0.03607394885696688
Trained batch 377 in epoch 6, gen_loss = 0.4072216120819566, disc_loss = 0.03600469804196446
Trained batch 378 in epoch 6, gen_loss = 0.4072488036822518, disc_loss = 0.03592818459166622
Trained batch 379 in epoch 6, gen_loss = 0.4070667238611924, disc_loss = 0.03584571066435034
Trained batch 380 in epoch 6, gen_loss = 0.40710821912044615, disc_loss = 0.03576634779787596
Trained batch 381 in epoch 6, gen_loss = 0.4070733873787975, disc_loss = 0.035681528531146575
Trained batch 382 in epoch 6, gen_loss = 0.407008422183617, disc_loss = 0.035601550046301035
Trained batch 383 in epoch 6, gen_loss = 0.4072630060060571, disc_loss = 0.03552046522660627
Trained batch 384 in epoch 6, gen_loss = 0.4073946561906245, disc_loss = 0.03544061688113619
Trained batch 385 in epoch 6, gen_loss = 0.4073911855103438, disc_loss = 0.035357402876463426
Trained batch 386 in epoch 6, gen_loss = 0.4074299142188188, disc_loss = 0.0352760622162343
Trained batch 387 in epoch 6, gen_loss = 0.4074543693784586, disc_loss = 0.035196220181815174
Trained batch 388 in epoch 6, gen_loss = 0.40755833903744165, disc_loss = 0.035115807859471264
Trained batch 389 in epoch 6, gen_loss = 0.40780921830580785, disc_loss = 0.03504503515835565
Trained batch 390 in epoch 6, gen_loss = 0.407677337717827, disc_loss = 0.03497264324508779
Trained batch 391 in epoch 6, gen_loss = 0.40774246715769474, disc_loss = 0.034890585789238385
Trained batch 392 in epoch 6, gen_loss = 0.40778542330853507, disc_loss = 0.03481374014259029
Trained batch 393 in epoch 6, gen_loss = 0.40780714290396214, disc_loss = 0.034741825385132645
Trained batch 394 in epoch 6, gen_loss = 0.40782159408436547, disc_loss = 0.03466193940714473
Trained batch 395 in epoch 6, gen_loss = 0.4077876769382544, disc_loss = 0.034583667489568315
Trained batch 396 in epoch 6, gen_loss = 0.407600669251281, disc_loss = 0.034508883581269224
Trained batch 397 in epoch 6, gen_loss = 0.4076343470781892, disc_loss = 0.034451767506227644
Trained batch 398 in epoch 6, gen_loss = 0.4075649576378347, disc_loss = 0.03437776392195047
Trained batch 399 in epoch 6, gen_loss = 0.4076530386507511, disc_loss = 0.03430086543608923
Trained batch 400 in epoch 6, gen_loss = 0.4077320714989803, disc_loss = 0.03422903779376196
Trained batch 401 in epoch 6, gen_loss = 0.407557521071007, disc_loss = 0.03434037052810804
Trained batch 402 in epoch 6, gen_loss = 0.4076930663130124, disc_loss = 0.03550521466273251
Trained batch 403 in epoch 6, gen_loss = 0.4074095766438116, disc_loss = 0.03584894606910443
Trained batch 404 in epoch 6, gen_loss = 0.4073172444914594, disc_loss = 0.03635167081058485
Trained batch 405 in epoch 6, gen_loss = 0.40737064880103313, disc_loss = 0.03682353390493141
Trained batch 406 in epoch 6, gen_loss = 0.40744327363862454, disc_loss = 0.03878492324530657
Trained batch 407 in epoch 6, gen_loss = 0.40746678448483054, disc_loss = 0.03927488445005307
Trained batch 408 in epoch 6, gen_loss = 0.4072143526561103, disc_loss = 0.03959641599069033
Trained batch 409 in epoch 6, gen_loss = 0.40716570608499575, disc_loss = 0.039985001330809074
Trained batch 410 in epoch 6, gen_loss = 0.40709974875995425, disc_loss = 0.04014996401886308
Trained batch 411 in epoch 6, gen_loss = 0.4071576988812789, disc_loss = 0.04041170687652058
Trained batch 412 in epoch 6, gen_loss = 0.40687837107129593, disc_loss = 0.04073020214041285
Trained batch 413 in epoch 6, gen_loss = 0.4068116709086054, disc_loss = 0.04077022541415594
Trained batch 414 in epoch 6, gen_loss = 0.40671655765498976, disc_loss = 0.0409182158113648
Trained batch 415 in epoch 6, gen_loss = 0.4065502957225992, disc_loss = 0.04154019053105283
Trained batch 416 in epoch 6, gen_loss = 0.40647393465042114, disc_loss = 0.04170744364793084
Trained batch 417 in epoch 6, gen_loss = 0.40653044791027687, disc_loss = 0.04174703832673417
Trained batch 418 in epoch 6, gen_loss = 0.40643748825944975, disc_loss = 0.041765089898630266
Trained batch 419 in epoch 6, gen_loss = 0.4064977874358495, disc_loss = 0.04174101011040399
Trained batch 420 in epoch 6, gen_loss = 0.4066366491011939, disc_loss = 0.041718774294312554
Trained batch 421 in epoch 6, gen_loss = 0.4067323539776825, disc_loss = 0.04172179891045925
Trained batch 422 in epoch 6, gen_loss = 0.4068166402214808, disc_loss = 0.041889158342293425
Trained batch 423 in epoch 6, gen_loss = 0.40673364270127044, disc_loss = 0.04220112122184562
Trained batch 424 in epoch 6, gen_loss = 0.4067443842747632, disc_loss = 0.04241844595190795
Trained batch 425 in epoch 6, gen_loss = 0.40664627413514637, disc_loss = 0.0423771017455133
Trained batch 426 in epoch 6, gen_loss = 0.4065648997137083, disc_loss = 0.042349178987976153
Trained batch 427 in epoch 6, gen_loss = 0.40660023863349004, disc_loss = 0.04230764556391095
Trained batch 428 in epoch 6, gen_loss = 0.40629165649136184, disc_loss = 0.042269275598076014
Trained batch 429 in epoch 6, gen_loss = 0.406206173120543, disc_loss = 0.042213700415544904
Trained batch 430 in epoch 6, gen_loss = 0.4061313108335792, disc_loss = 0.04225136505455004
Trained batch 431 in epoch 6, gen_loss = 0.40627655669770857, disc_loss = 0.042304617144206226
Trained batch 432 in epoch 6, gen_loss = 0.40622627480476065, disc_loss = 0.042450333300732744
Trained batch 433 in epoch 6, gen_loss = 0.40629404144627707, disc_loss = 0.042799006751094715
Trained batch 434 in epoch 6, gen_loss = 0.4061155508304464, disc_loss = 0.04320351289446069
Trained batch 435 in epoch 6, gen_loss = 0.40637148684317914, disc_loss = 0.04339212865980957
Trained batch 436 in epoch 6, gen_loss = 0.4066124457516441, disc_loss = 0.04332173084019677
Trained batch 437 in epoch 6, gen_loss = 0.4067836834551537, disc_loss = 0.043275250745490705
Trained batch 438 in epoch 6, gen_loss = 0.40672512057158833, disc_loss = 0.04319783307427375
Trained batch 439 in epoch 6, gen_loss = 0.406698722934181, disc_loss = 0.04312431485106406
Trained batch 440 in epoch 6, gen_loss = 0.40676635314547827, disc_loss = 0.043040410965541696
Trained batch 441 in epoch 6, gen_loss = 0.4069338270307127, disc_loss = 0.042965951893474415
Trained batch 442 in epoch 6, gen_loss = 0.4069410050561143, disc_loss = 0.042899391493543514
Trained batch 443 in epoch 6, gen_loss = 0.4069247525017541, disc_loss = 0.04283436542945318
Trained batch 444 in epoch 6, gen_loss = 0.4069609457187438, disc_loss = 0.04274717638363246
Trained batch 445 in epoch 6, gen_loss = 0.4068540901346592, disc_loss = 0.04268044780160931
Trained batch 446 in epoch 6, gen_loss = 0.4068571317115886, disc_loss = 0.04261078201057244
Trained batch 447 in epoch 6, gen_loss = 0.4068619578943721, disc_loss = 0.042530672656409606
Trained batch 448 in epoch 6, gen_loss = 0.40688293913424944, disc_loss = 0.042446920710962205
Trained batch 449 in epoch 6, gen_loss = 0.4069023495250278, disc_loss = 0.04236874265130609
Trained batch 450 in epoch 6, gen_loss = 0.4068092701176053, disc_loss = 0.04229232510231733
Trained batch 451 in epoch 6, gen_loss = 0.4068013597114951, disc_loss = 0.0422103516278434
Trained batch 452 in epoch 6, gen_loss = 0.4066932004019125, disc_loss = 0.04212667288980292
Trained batch 453 in epoch 6, gen_loss = 0.4065895636570086, disc_loss = 0.042040332283061574
Trained batch 454 in epoch 6, gen_loss = 0.4065440675714514, disc_loss = 0.04196156175233997
Trained batch 455 in epoch 6, gen_loss = 0.4064923179123485, disc_loss = 0.041883227762586454
Trained batch 456 in epoch 6, gen_loss = 0.40643547296002347, disc_loss = 0.04180297462974779
Trained batch 457 in epoch 6, gen_loss = 0.4064626227169578, disc_loss = 0.041717848966231645
Trained batch 458 in epoch 6, gen_loss = 0.40637646183728654, disc_loss = 0.04163291236925424
Trained batch 459 in epoch 6, gen_loss = 0.40635368739781175, disc_loss = 0.04156045007478932
Trained batch 460 in epoch 6, gen_loss = 0.40623549738830184, disc_loss = 0.04149081066266963
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 0.37460649013519287, disc_loss = 0.006768935360014439
Trained batch 1 in epoch 7, gen_loss = 0.38389891386032104, disc_loss = 0.00818481994792819
Trained batch 2 in epoch 7, gen_loss = 0.3752545913060506, disc_loss = 0.006781509146094322
Trained batch 3 in epoch 7, gen_loss = 0.37791019678115845, disc_loss = 0.0060165830655023456
Trained batch 4 in epoch 7, gen_loss = 0.38621639609336855, disc_loss = 0.00657782731577754
Trained batch 5 in epoch 7, gen_loss = 0.3903882106145223, disc_loss = 0.0063639730991174774
Trained batch 6 in epoch 7, gen_loss = 0.38911389453070505, disc_loss = 0.00622233994571226
Trained batch 7 in epoch 7, gen_loss = 0.38927967846393585, disc_loss = 0.005863916303496808
Trained batch 8 in epoch 7, gen_loss = 0.3879576159848107, disc_loss = 0.005448242545955711
Trained batch 9 in epoch 7, gen_loss = 0.39255169928073885, disc_loss = 0.005249027418904007
Trained batch 10 in epoch 7, gen_loss = 0.3914003209634261, disc_loss = 0.005145691652697596
Trained batch 11 in epoch 7, gen_loss = 0.38534846901893616, disc_loss = 0.005194403289351612
Trained batch 12 in epoch 7, gen_loss = 0.38959436920972973, disc_loss = 0.005627514346717642
Trained batch 13 in epoch 7, gen_loss = 0.3933667072228023, disc_loss = 0.005527465388045779
Trained batch 14 in epoch 7, gen_loss = 0.3924737175305684, disc_loss = 0.005350977461785078
Trained batch 15 in epoch 7, gen_loss = 0.39502968452870846, disc_loss = 0.0053092668240424246
Trained batch 16 in epoch 7, gen_loss = 0.3932099920861861, disc_loss = 0.0051435961059349425
Trained batch 17 in epoch 7, gen_loss = 0.3955186472998725, disc_loss = 0.005105084480924739
Trained batch 18 in epoch 7, gen_loss = 0.39507928176930074, disc_loss = 0.0050492133258988985
Trained batch 19 in epoch 7, gen_loss = 0.3964701026678085, disc_loss = 0.00495378648629412
Trained batch 20 in epoch 7, gen_loss = 0.3942036713872637, disc_loss = 0.005060187263769053
Trained batch 21 in epoch 7, gen_loss = 0.3946581076491963, disc_loss = 0.004947339967739853
Trained batch 22 in epoch 7, gen_loss = 0.3929840896440589, disc_loss = 0.004847009868725487
Trained batch 23 in epoch 7, gen_loss = 0.3880956048766772, disc_loss = 0.005018710585621496
Trained batch 24 in epoch 7, gen_loss = 0.3863962459564209, disc_loss = 0.00492323499172926
Trained batch 25 in epoch 7, gen_loss = 0.38718424852077776, disc_loss = 0.00497738322099814
Trained batch 26 in epoch 7, gen_loss = 0.3909139511761842, disc_loss = 0.0049168444928471685
Trained batch 27 in epoch 7, gen_loss = 0.392592511006764, disc_loss = 0.0049742302923862424
Trained batch 28 in epoch 7, gen_loss = 0.39277778308967065, disc_loss = 0.00490726871769233
Trained batch 29 in epoch 7, gen_loss = 0.3919317275285721, disc_loss = 0.004858469877702495
Trained batch 30 in epoch 7, gen_loss = 0.39227697830046376, disc_loss = 0.004769969513759979
Trained batch 31 in epoch 7, gen_loss = 0.3920117197558284, disc_loss = 0.004722084217064548
Trained batch 32 in epoch 7, gen_loss = 0.3910514721364686, disc_loss = 0.004645481698610114
Trained batch 33 in epoch 7, gen_loss = 0.39151715706376466, disc_loss = 0.004629489274092895
Trained batch 34 in epoch 7, gen_loss = 0.39236809185573035, disc_loss = 0.004561021538185221
Trained batch 35 in epoch 7, gen_loss = 0.39448948038948906, disc_loss = 0.004538458603848185
Trained batch 36 in epoch 7, gen_loss = 0.39246172598890355, disc_loss = 0.004696436037586347
Trained batch 37 in epoch 7, gen_loss = 0.3940027614957408, disc_loss = 0.004782544608276926
Trained batch 38 in epoch 7, gen_loss = 0.394340313397921, disc_loss = 0.004757248736822452
Trained batch 39 in epoch 7, gen_loss = 0.3941199317574501, disc_loss = 0.004712638352066279
Trained batch 40 in epoch 7, gen_loss = 0.39459363352961657, disc_loss = 0.00465497542626974
Trained batch 41 in epoch 7, gen_loss = 0.39583441615104675, disc_loss = 0.004604924769539919
Trained batch 42 in epoch 7, gen_loss = 0.39574632810991867, disc_loss = 0.0045604220006701555
Trained batch 43 in epoch 7, gen_loss = 0.3948414095423438, disc_loss = 0.004511769522320141
Trained batch 44 in epoch 7, gen_loss = 0.3954998473326365, disc_loss = 0.004503477178514004
Trained batch 45 in epoch 7, gen_loss = 0.3948654545390088, disc_loss = 0.004457559912344036
Trained batch 46 in epoch 7, gen_loss = 0.39522305955278114, disc_loss = 0.0044002851218658875
Trained batch 47 in epoch 7, gen_loss = 0.39557475596666336, disc_loss = 0.004374737620916373
Trained batch 48 in epoch 7, gen_loss = 0.39495388099125456, disc_loss = 0.004363640660553106
Trained batch 49 in epoch 7, gen_loss = 0.3952663791179657, disc_loss = 0.004401750315446406
Trained batch 50 in epoch 7, gen_loss = 0.39491895717733044, disc_loss = 0.004374892736200755
Trained batch 51 in epoch 7, gen_loss = 0.39556024911311954, disc_loss = 0.004335200344660104
Trained batch 52 in epoch 7, gen_loss = 0.39538156930005774, disc_loss = 0.0042910983166569525
Trained batch 53 in epoch 7, gen_loss = 0.3942573136753506, disc_loss = 0.0042490057918863995
Trained batch 54 in epoch 7, gen_loss = 0.39433910900896246, disc_loss = 0.0042384692954576825
Trained batch 55 in epoch 7, gen_loss = 0.3956476098724774, disc_loss = 0.004224933274339752
Trained batch 56 in epoch 7, gen_loss = 0.3964205347655112, disc_loss = 0.004216441282136529
Trained batch 57 in epoch 7, gen_loss = 0.3976580752380963, disc_loss = 0.004242511275465247
Trained batch 58 in epoch 7, gen_loss = 0.3973935726335493, disc_loss = 0.004208900099541298
Trained batch 59 in epoch 7, gen_loss = 0.39682907859484357, disc_loss = 0.00419718284974806
Trained batch 60 in epoch 7, gen_loss = 0.39826469440929224, disc_loss = 0.004171564764740159
Trained batch 61 in epoch 7, gen_loss = 0.39799078385676107, disc_loss = 0.004134779482433993
Trained batch 62 in epoch 7, gen_loss = 0.397255575846112, disc_loss = 0.004096803211030506
Trained batch 63 in epoch 7, gen_loss = 0.3973778304643929, disc_loss = 0.004057771217048867
Trained batch 64 in epoch 7, gen_loss = 0.3964418227855976, disc_loss = 0.0040439512114971874
Trained batch 65 in epoch 7, gen_loss = 0.3967588589046941, disc_loss = 0.00403080474246632
Trained batch 66 in epoch 7, gen_loss = 0.3966239539544974, disc_loss = 0.003996075589710207
Trained batch 67 in epoch 7, gen_loss = 0.39515040990184336, disc_loss = 0.0039819531717940285
Trained batch 68 in epoch 7, gen_loss = 0.39549563933109894, disc_loss = 0.00397619615862335
Trained batch 69 in epoch 7, gen_loss = 0.3953804629189627, disc_loss = 0.003949346449891371
Trained batch 70 in epoch 7, gen_loss = 0.394440556915713, disc_loss = 0.003934254522212375
Trained batch 71 in epoch 7, gen_loss = 0.3945128164357609, disc_loss = 0.003910811071465205
Trained batch 72 in epoch 7, gen_loss = 0.3949724856304796, disc_loss = 0.003911614689133959
Trained batch 73 in epoch 7, gen_loss = 0.3950975231222204, disc_loss = 0.0039028253853069365
Trained batch 74 in epoch 7, gen_loss = 0.39447980960210166, disc_loss = 0.003903291681781411
Trained batch 75 in epoch 7, gen_loss = 0.39476697656669113, disc_loss = 0.003900650616024474
Trained batch 76 in epoch 7, gen_loss = 0.39444217472881465, disc_loss = 0.003871136663977492
Trained batch 77 in epoch 7, gen_loss = 0.39408361988189894, disc_loss = 0.00385054884902321
Trained batch 78 in epoch 7, gen_loss = 0.3937382566023476, disc_loss = 0.0038528773518090574
Trained batch 79 in epoch 7, gen_loss = 0.3934849314391613, disc_loss = 0.0038239763482124543
Trained batch 80 in epoch 7, gen_loss = 0.39342672736556444, disc_loss = 0.003799920424497054
Trained batch 81 in epoch 7, gen_loss = 0.393932349798156, disc_loss = 0.003787549456763195
Trained batch 82 in epoch 7, gen_loss = 0.3935401493526367, disc_loss = 0.0037590026861079127
Trained batch 83 in epoch 7, gen_loss = 0.3936965022058714, disc_loss = 0.0037382864310140057
Trained batch 84 in epoch 7, gen_loss = 0.39367348376442407, disc_loss = 0.0037233129006755705
Trained batch 85 in epoch 7, gen_loss = 0.39387029929216516, disc_loss = 0.0037134203404664647
Trained batch 86 in epoch 7, gen_loss = 0.3939091292606003, disc_loss = 0.003690762073336833
Trained batch 87 in epoch 7, gen_loss = 0.39381151646375656, disc_loss = 0.0036715198154772884
Trained batch 88 in epoch 7, gen_loss = 0.39451404635825854, disc_loss = 0.0036948825666953005
Trained batch 89 in epoch 7, gen_loss = 0.3941240327225791, disc_loss = 0.003707234445028007
Trained batch 90 in epoch 7, gen_loss = 0.39423622502075445, disc_loss = 0.0036916703390018953
Trained batch 91 in epoch 7, gen_loss = 0.3945287002817444, disc_loss = 0.0036894532284982825
Trained batch 92 in epoch 7, gen_loss = 0.3948571877453917, disc_loss = 0.0036975272821002107
Trained batch 93 in epoch 7, gen_loss = 0.39473553604268014, disc_loss = 0.0036797026603264693
Trained batch 94 in epoch 7, gen_loss = 0.3943995729873055, disc_loss = 0.003670271608586374
Trained batch 95 in epoch 7, gen_loss = 0.39402955832580727, disc_loss = 0.0036527405657883114
Trained batch 96 in epoch 7, gen_loss = 0.3942886812170756, disc_loss = 0.003634890128579951
Trained batch 97 in epoch 7, gen_loss = 0.39414992624399614, disc_loss = 0.003619765337765673
Trained batch 98 in epoch 7, gen_loss = 0.3946314219272498, disc_loss = 0.003602854219603945
Trained batch 99 in epoch 7, gen_loss = 0.3945465415716171, disc_loss = 0.003587690474232659
Trained batch 100 in epoch 7, gen_loss = 0.3947350763448394, disc_loss = 0.0035668071993340805
Trained batch 101 in epoch 7, gen_loss = 0.3945417161665711, disc_loss = 0.003564420116234425
Trained batch 102 in epoch 7, gen_loss = 0.394777815318802, disc_loss = 0.0035714524700894085
Trained batch 103 in epoch 7, gen_loss = 0.39491190761327744, disc_loss = 0.003558644045439835
Trained batch 104 in epoch 7, gen_loss = 0.3948585825307029, disc_loss = 0.0035510386262709898
Trained batch 105 in epoch 7, gen_loss = 0.3944570278784014, disc_loss = 0.0035430165809438616
Trained batch 106 in epoch 7, gen_loss = 0.39378867973791104, disc_loss = 0.003544583040829226
Trained batch 107 in epoch 7, gen_loss = 0.39374781124017855, disc_loss = 0.0035404167515311943
Trained batch 108 in epoch 7, gen_loss = 0.39349494942831337, disc_loss = 0.0035348120391146716
Trained batch 109 in epoch 7, gen_loss = 0.3932342358610847, disc_loss = 0.003551365654195913
Trained batch 110 in epoch 7, gen_loss = 0.39318333203728134, disc_loss = 0.0035386620905367774
Trained batch 111 in epoch 7, gen_loss = 0.3934759585452931, disc_loss = 0.0035505451180922265
Trained batch 112 in epoch 7, gen_loss = 0.39436311057183593, disc_loss = 0.0035839122977618753
Trained batch 113 in epoch 7, gen_loss = 0.3944250489013237, disc_loss = 0.0035751300849625025
Trained batch 114 in epoch 7, gen_loss = 0.39433436989784243, disc_loss = 0.00356456707737854
Trained batch 115 in epoch 7, gen_loss = 0.3942818520911809, disc_loss = 0.003551118460218904
Trained batch 116 in epoch 7, gen_loss = 0.39456067737351114, disc_loss = 0.0035738144935562443
Trained batch 117 in epoch 7, gen_loss = 0.39416969529653, disc_loss = 0.0035745975930417365
Trained batch 118 in epoch 7, gen_loss = 0.39395966850408987, disc_loss = 0.0036660281054972975
Trained batch 119 in epoch 7, gen_loss = 0.39366510113080344, disc_loss = 0.003788299648052392
Trained batch 120 in epoch 7, gen_loss = 0.3941347286228306, disc_loss = 0.00398796845192844
Trained batch 121 in epoch 7, gen_loss = 0.39461084443037625, disc_loss = 0.005260991259882624
Trained batch 122 in epoch 7, gen_loss = 0.39420371617728134, disc_loss = 0.006055651269512388
Trained batch 123 in epoch 7, gen_loss = 0.3949315439789526, disc_loss = 0.006195267894297778
Trained batch 124 in epoch 7, gen_loss = 0.39569786834716797, disc_loss = 0.00622806445416063
Trained batch 125 in epoch 7, gen_loss = 0.3961080336381519, disc_loss = 0.0062924337357149595
Trained batch 126 in epoch 7, gen_loss = 0.3968172153150003, disc_loss = 0.00632385181274089
Trained batch 127 in epoch 7, gen_loss = 0.3965145426336676, disc_loss = 0.006338668775242695
Trained batch 128 in epoch 7, gen_loss = 0.39705228990362595, disc_loss = 0.006340967475927557
Trained batch 129 in epoch 7, gen_loss = 0.39723270168671243, disc_loss = 0.006313242115832579
Trained batch 130 in epoch 7, gen_loss = 0.3973422070950952, disc_loss = 0.006310317161464566
Trained batch 131 in epoch 7, gen_loss = 0.3976231199322325, disc_loss = 0.006312347663686413
Trained batch 132 in epoch 7, gen_loss = 0.39777546560853944, disc_loss = 0.0063102131865260406
Trained batch 133 in epoch 7, gen_loss = 0.3977266994874869, disc_loss = 0.0062850477815077485
Trained batch 134 in epoch 7, gen_loss = 0.39832470505325884, disc_loss = 0.006263728449293585
Trained batch 135 in epoch 7, gen_loss = 0.3989733010530472, disc_loss = 0.006247262418208479
Trained batch 136 in epoch 7, gen_loss = 0.3990423514025055, disc_loss = 0.006229454565650518
Trained batch 137 in epoch 7, gen_loss = 0.399210654091144, disc_loss = 0.006227972747697292
Trained batch 138 in epoch 7, gen_loss = 0.3987770112727186, disc_loss = 0.006240810990407259
Trained batch 139 in epoch 7, gen_loss = 0.3979218548962048, disc_loss = 0.006257710498591353
Trained batch 140 in epoch 7, gen_loss = 0.3976130684216817, disc_loss = 0.006373288796005889
Trained batch 141 in epoch 7, gen_loss = 0.39759450962006204, disc_loss = 0.0063755071589159185
Trained batch 142 in epoch 7, gen_loss = 0.39768417836069225, disc_loss = 0.006366747131056667
Trained batch 143 in epoch 7, gen_loss = 0.3974787764665153, disc_loss = 0.0066268688719396274
Trained batch 144 in epoch 7, gen_loss = 0.3982330994359378, disc_loss = 0.006978199032841828
Trained batch 145 in epoch 7, gen_loss = 0.398326258340927, disc_loss = 0.0071297636413500225
Trained batch 146 in epoch 7, gen_loss = 0.39815182304706703, disc_loss = 0.007817943833077795
Trained batch 147 in epoch 7, gen_loss = 0.3989843701994097, disc_loss = 0.007930920729130457
Trained batch 148 in epoch 7, gen_loss = 0.3993906548759281, disc_loss = 0.008129993109063764
Trained batch 149 in epoch 7, gen_loss = 0.3989631986618042, disc_loss = 0.008142671354580671
Trained batch 150 in epoch 7, gen_loss = 0.3989053962641204, disc_loss = 0.00817294973827627
Trained batch 151 in epoch 7, gen_loss = 0.3985411763975495, disc_loss = 0.008148163069180507
Trained batch 152 in epoch 7, gen_loss = 0.3983030802284191, disc_loss = 0.008389827231511328
Trained batch 153 in epoch 7, gen_loss = 0.3990833798012176, disc_loss = 0.008537284802349115
Trained batch 154 in epoch 7, gen_loss = 0.39912206915117077, disc_loss = 0.008587566380869717
Trained batch 155 in epoch 7, gen_loss = 0.39922014566568226, disc_loss = 0.008588271134216577
Trained batch 156 in epoch 7, gen_loss = 0.3989040077112283, disc_loss = 0.008669634108657053
Trained batch 157 in epoch 7, gen_loss = 0.39895153158827673, disc_loss = 0.00871135642430804
Trained batch 158 in epoch 7, gen_loss = 0.3987170733370871, disc_loss = 0.008734363584439474
Trained batch 159 in epoch 7, gen_loss = 0.3987203503027558, disc_loss = 0.00873883305102936
Trained batch 160 in epoch 7, gen_loss = 0.39870924349897396, disc_loss = 0.008727100257680791
Trained batch 161 in epoch 7, gen_loss = 0.39854073414096125, disc_loss = 0.008841982918337309
Trained batch 162 in epoch 7, gen_loss = 0.3979573789184079, disc_loss = 0.009145060362025776
Trained batch 163 in epoch 7, gen_loss = 0.39815973018000766, disc_loss = 0.010066410733199475
Trained batch 164 in epoch 7, gen_loss = 0.3979381516124263, disc_loss = 0.010225455487626746
Trained batch 165 in epoch 7, gen_loss = 0.3973881110369441, disc_loss = 0.010279039102634528
Trained batch 166 in epoch 7, gen_loss = 0.397297124305885, disc_loss = 0.010256430108384592
Trained batch 167 in epoch 7, gen_loss = 0.397586726361797, disc_loss = 0.010395759435985903
Trained batch 168 in epoch 7, gen_loss = 0.3977806592834066, disc_loss = 0.010502184666114578
Trained batch 169 in epoch 7, gen_loss = 0.39769116289475387, disc_loss = 0.010504325793590397
Trained batch 170 in epoch 7, gen_loss = 0.39771222371106957, disc_loss = 0.010608154732314598
Trained batch 171 in epoch 7, gen_loss = 0.3981089484553004, disc_loss = 0.010664758550647517
Trained batch 172 in epoch 7, gen_loss = 0.3978924661702503, disc_loss = 0.010746243110362635
Trained batch 173 in epoch 7, gen_loss = 0.39843852800884466, disc_loss = 0.010808492611274766
Trained batch 174 in epoch 7, gen_loss = 0.3987892826965877, disc_loss = 0.010784694235106664
Trained batch 175 in epoch 7, gen_loss = 0.39882598394020036, disc_loss = 0.010829179338047239
Trained batch 176 in epoch 7, gen_loss = 0.3990252497842756, disc_loss = 0.010798969444829318
Trained batch 177 in epoch 7, gen_loss = 0.39927309634310476, disc_loss = 0.010765887338411733
Trained batch 178 in epoch 7, gen_loss = 0.3993454478972451, disc_loss = 0.01083023130422843
Trained batch 179 in epoch 7, gen_loss = 0.39877481559912364, disc_loss = 0.010914473506596146
Trained batch 180 in epoch 7, gen_loss = 0.3981035098186514, disc_loss = 0.013298264958700217
Trained batch 181 in epoch 7, gen_loss = 0.39821245070997174, disc_loss = 0.01392678140885207
Trained batch 182 in epoch 7, gen_loss = 0.3982078227840486, disc_loss = 0.014086047993448711
Trained batch 183 in epoch 7, gen_loss = 0.39823152303047804, disc_loss = 0.014207772102647299
Trained batch 184 in epoch 7, gen_loss = 0.39824090761107367, disc_loss = 0.014264454754900086
Trained batch 185 in epoch 7, gen_loss = 0.39829696971242146, disc_loss = 0.014257429830444555
Trained batch 186 in epoch 7, gen_loss = 0.39825740902819096, disc_loss = 0.014276142099518628
Trained batch 187 in epoch 7, gen_loss = 0.3980418911322634, disc_loss = 0.014669226989660293
Trained batch 188 in epoch 7, gen_loss = 0.39790250447692066, disc_loss = 0.01556202807899801
Trained batch 189 in epoch 7, gen_loss = 0.3981348351428383, disc_loss = 0.016426106416742855
Trained batch 190 in epoch 7, gen_loss = 0.39809683776650756, disc_loss = 0.01640201342616386
Trained batch 191 in epoch 7, gen_loss = 0.398005330003798, disc_loss = 0.01705299785620203
Trained batch 192 in epoch 7, gen_loss = 0.3984130911258836, disc_loss = 0.017286385531981183
Trained batch 193 in epoch 7, gen_loss = 0.3983041421347058, disc_loss = 0.017238546063830674
Trained batch 194 in epoch 7, gen_loss = 0.3980032233091501, disc_loss = 0.017352245916994528
Trained batch 195 in epoch 7, gen_loss = 0.39792495996368177, disc_loss = 0.018088089470271667
Trained batch 196 in epoch 7, gen_loss = 0.39712907215060317, disc_loss = 0.01860725960687162
Trained batch 197 in epoch 7, gen_loss = 0.397316752058087, disc_loss = 0.01858215569459711
Trained batch 198 in epoch 7, gen_loss = 0.3972553616792113, disc_loss = 0.01877748729583887
Trained batch 199 in epoch 7, gen_loss = 0.3967813378572464, disc_loss = 0.01895297295588534
Trained batch 200 in epoch 7, gen_loss = 0.39660903544568304, disc_loss = 0.01904154052918508
Trained batch 201 in epoch 7, gen_loss = 0.3967456113879043, disc_loss = 0.0195038964767885
Trained batch 202 in epoch 7, gen_loss = 0.3963362507044975, disc_loss = 0.020995872794292648
Trained batch 203 in epoch 7, gen_loss = 0.39690397299972235, disc_loss = 0.021485855722430107
Trained batch 204 in epoch 7, gen_loss = 0.3971348952956316, disc_loss = 0.021613149410227267
Trained batch 205 in epoch 7, gen_loss = 0.3970811610082978, disc_loss = 0.021593152348164613
Trained batch 206 in epoch 7, gen_loss = 0.39689572450619387, disc_loss = 0.021530598754643637
Trained batch 207 in epoch 7, gen_loss = 0.39677375913239443, disc_loss = 0.02160308649035869
Trained batch 208 in epoch 7, gen_loss = 0.3967604818241448, disc_loss = 0.021525956999452596
Trained batch 209 in epoch 7, gen_loss = 0.39718044229916166, disc_loss = 0.021492505230430867
Trained batch 210 in epoch 7, gen_loss = 0.39713338398820414, disc_loss = 0.02146448635207092
Trained batch 211 in epoch 7, gen_loss = 0.3969273710588239, disc_loss = 0.021637162972869845
Trained batch 212 in epoch 7, gen_loss = 0.39745496864050206, disc_loss = 0.021884630374641032
Trained batch 213 in epoch 7, gen_loss = 0.3975462466478348, disc_loss = 0.021817275263678073
Trained batch 214 in epoch 7, gen_loss = 0.3979715207288432, disc_loss = 0.021761241803747104
Trained batch 215 in epoch 7, gen_loss = 0.39763317477923854, disc_loss = 0.021687990198390454
Trained batch 216 in epoch 7, gen_loss = 0.397722645976027, disc_loss = 0.021630939883222882
Trained batch 217 in epoch 7, gen_loss = 0.39778114171749956, disc_loss = 0.02155643701072731
Trained batch 218 in epoch 7, gen_loss = 0.3980576389184281, disc_loss = 0.02148541771927976
Trained batch 219 in epoch 7, gen_loss = 0.39768603376366873, disc_loss = 0.02150652854311788
Trained batch 220 in epoch 7, gen_loss = 0.3975726507637835, disc_loss = 0.021490116695856584
Trained batch 221 in epoch 7, gen_loss = 0.39753321121941815, disc_loss = 0.02146039934994586
Trained batch 222 in epoch 7, gen_loss = 0.3978592959220099, disc_loss = 0.021384484522491528
Trained batch 223 in epoch 7, gen_loss = 0.39805647132119965, disc_loss = 0.02142543958481318
Trained batch 224 in epoch 7, gen_loss = 0.39808571947945487, disc_loss = 0.021388429899493026
Trained batch 225 in epoch 7, gen_loss = 0.3982873659218307, disc_loss = 0.021347495842111024
Trained batch 226 in epoch 7, gen_loss = 0.3983793114250452, disc_loss = 0.0212704473926936
Trained batch 227 in epoch 7, gen_loss = 0.398477166891098, disc_loss = 0.021215867372168424
Trained batch 228 in epoch 7, gen_loss = 0.39861597478650024, disc_loss = 0.02115634391663848
Trained batch 229 in epoch 7, gen_loss = 0.3987504771222239, disc_loss = 0.02112188349407085
Trained batch 230 in epoch 7, gen_loss = 0.39876545688290616, disc_loss = 0.021071402610529585
Trained batch 231 in epoch 7, gen_loss = 0.399027272031225, disc_loss = 0.021029148841425295
Trained batch 232 in epoch 7, gen_loss = 0.3993769777946718, disc_loss = 0.021023575716667964
Trained batch 233 in epoch 7, gen_loss = 0.3994855367475086, disc_loss = 0.021508351609640174
Trained batch 234 in epoch 7, gen_loss = 0.3996261865534681, disc_loss = 0.0227062529750525
Trained batch 235 in epoch 7, gen_loss = 0.3997473678851532, disc_loss = 0.0227841155932056
Trained batch 236 in epoch 7, gen_loss = 0.4001804544955869, disc_loss = 0.022860155771447163
Trained batch 237 in epoch 7, gen_loss = 0.400105635283374, disc_loss = 0.02283357019279888
Trained batch 238 in epoch 7, gen_loss = 0.40035132920392885, disc_loss = 0.022776407965607006
Trained batch 239 in epoch 7, gen_loss = 0.40060283107062183, disc_loss = 0.022716751493377766
Trained batch 240 in epoch 7, gen_loss = 0.40047231328932575, disc_loss = 0.022725185580818267
Trained batch 241 in epoch 7, gen_loss = 0.4003767949983108, disc_loss = 0.02267154337008953
Trained batch 242 in epoch 7, gen_loss = 0.40021938441221605, disc_loss = 0.022617417894047014
Trained batch 243 in epoch 7, gen_loss = 0.39992507351715056, disc_loss = 0.02265268483735453
Trained batch 244 in epoch 7, gen_loss = 0.3996940088515379, disc_loss = 0.02302923082820691
Trained batch 245 in epoch 7, gen_loss = 0.40020849004509, disc_loss = 0.023939455507750947
Trained batch 246 in epoch 7, gen_loss = 0.3999993845760098, disc_loss = 0.02401186711756279
Trained batch 247 in epoch 7, gen_loss = 0.39993452316811007, disc_loss = 0.02406243909753093
Trained batch 248 in epoch 7, gen_loss = 0.3999581291493642, disc_loss = 0.0239903862222498
Trained batch 249 in epoch 7, gen_loss = 0.3998916519880295, disc_loss = 0.023994580768514424
Trained batch 250 in epoch 7, gen_loss = 0.39972346819254506, disc_loss = 0.02393848327335445
Trained batch 251 in epoch 7, gen_loss = 0.3998245820403099, disc_loss = 0.0238988558352474
Trained batch 252 in epoch 7, gen_loss = 0.39980901430246857, disc_loss = 0.023904283446804602
Trained batch 253 in epoch 7, gen_loss = 0.399810647518616, disc_loss = 0.02424083049564923
Trained batch 254 in epoch 7, gen_loss = 0.3999482842052684, disc_loss = 0.025124057112535573
Trained batch 255 in epoch 7, gen_loss = 0.40026957215741277, disc_loss = 0.02514075339468036
Trained batch 256 in epoch 7, gen_loss = 0.40059943932039727, disc_loss = 0.025264071380802892
Trained batch 257 in epoch 7, gen_loss = 0.40019540858361147, disc_loss = 0.025317871726980766
Trained batch 258 in epoch 7, gen_loss = 0.40022881599466775, disc_loss = 0.02526049382137818
Trained batch 259 in epoch 7, gen_loss = 0.4002882925363687, disc_loss = 0.025204659461563167
Trained batch 260 in epoch 7, gen_loss = 0.4001359973830738, disc_loss = 0.025124389214808713
Trained batch 261 in epoch 7, gen_loss = 0.4001624223612647, disc_loss = 0.025058934753423003
Trained batch 262 in epoch 7, gen_loss = 0.4002915372640008, disc_loss = 0.02502528305064547
Trained batch 263 in epoch 7, gen_loss = 0.4004868118826187, disc_loss = 0.02494629389812789
Trained batch 264 in epoch 7, gen_loss = 0.4005096731320867, disc_loss = 0.02515952490700655
Trained batch 265 in epoch 7, gen_loss = 0.3999772690292588, disc_loss = 0.02632100212683593
Trained batch 266 in epoch 7, gen_loss = 0.4002875638811776, disc_loss = 0.02645951346799466
Trained batch 267 in epoch 7, gen_loss = 0.400638438872437, disc_loss = 0.026589198363336747
Trained batch 268 in epoch 7, gen_loss = 0.40036488842343754, disc_loss = 0.026751165432755086
Trained batch 269 in epoch 7, gen_loss = 0.40034321701085124, disc_loss = 0.026748497679363936
Trained batch 270 in epoch 7, gen_loss = 0.40072581688856285, disc_loss = 0.02670978516816227
Trained batch 271 in epoch 7, gen_loss = 0.400897324523505, disc_loss = 0.026677619657729176
Trained batch 272 in epoch 7, gen_loss = 0.400814733116618, disc_loss = 0.026748099189077678
Trained batch 273 in epoch 7, gen_loss = 0.4008689110514021, disc_loss = 0.02683228135226213
Trained batch 274 in epoch 7, gen_loss = 0.40096172831275245, disc_loss = 0.026804476507770066
Trained batch 275 in epoch 7, gen_loss = 0.4007848275528438, disc_loss = 0.02683927702415478
Trained batch 276 in epoch 7, gen_loss = 0.4011967475879063, disc_loss = 0.028194734556449153
Trained batch 277 in epoch 7, gen_loss = 0.40118894238266156, disc_loss = 0.02828081327920994
Trained batch 278 in epoch 7, gen_loss = 0.4009513094433747, disc_loss = 0.02840186551915929
Trained batch 279 in epoch 7, gen_loss = 0.4009322954075677, disc_loss = 0.02919033353890492
Trained batch 280 in epoch 7, gen_loss = 0.4006313551151031, disc_loss = 0.03064090706071621
Trained batch 281 in epoch 7, gen_loss = 0.40085972792713354, disc_loss = 0.030731856934016186
Trained batch 282 in epoch 7, gen_loss = 0.4008528876641614, disc_loss = 0.030933736680756743
Trained batch 283 in epoch 7, gen_loss = 0.4005677103996277, disc_loss = 0.03144369440187674
Trained batch 284 in epoch 7, gen_loss = 0.4002829976249159, disc_loss = 0.03176428616055075
Trained batch 285 in epoch 7, gen_loss = 0.40006178742522125, disc_loss = 0.03253206426246821
Trained batch 286 in epoch 7, gen_loss = 0.3999575466852155, disc_loss = 0.03296230658637327
Trained batch 287 in epoch 7, gen_loss = 0.3997141926859816, disc_loss = 0.033120603357626045
Trained batch 288 in epoch 7, gen_loss = 0.39957759671145243, disc_loss = 0.033461797407628474
Trained batch 289 in epoch 7, gen_loss = 0.3993226634017352, disc_loss = 0.03375640894840311
Trained batch 290 in epoch 7, gen_loss = 0.3994401074766703, disc_loss = 0.03393088089649428
Trained batch 291 in epoch 7, gen_loss = 0.39945397025918306, disc_loss = 0.03392589605638234
Trained batch 292 in epoch 7, gen_loss = 0.39943673118389506, disc_loss = 0.03399836287774947
Trained batch 293 in epoch 7, gen_loss = 0.3993159313591159, disc_loss = 0.033909453540410035
Trained batch 294 in epoch 7, gen_loss = 0.39938733810085364, disc_loss = 0.03389616817496401
Trained batch 295 in epoch 7, gen_loss = 0.39940051613627253, disc_loss = 0.03382436698499274
Trained batch 296 in epoch 7, gen_loss = 0.39954583341826494, disc_loss = 0.03376160888354096
Trained batch 297 in epoch 7, gen_loss = 0.39943868011836237, disc_loss = 0.03366370442918746
Trained batch 298 in epoch 7, gen_loss = 0.3995163594201257, disc_loss = 0.03357119435782429
Trained batch 299 in epoch 7, gen_loss = 0.39936693002780277, disc_loss = 0.0335405175810835
Trained batch 300 in epoch 7, gen_loss = 0.39915827530563075, disc_loss = 0.033485083261031376
Trained batch 301 in epoch 7, gen_loss = 0.39937080975794637, disc_loss = 0.033396118643172455
Trained batch 302 in epoch 7, gen_loss = 0.3993424907966022, disc_loss = 0.033325864769373915
Trained batch 303 in epoch 7, gen_loss = 0.39925978097476456, disc_loss = 0.0333164237477161
Trained batch 304 in epoch 7, gen_loss = 0.3995241722122568, disc_loss = 0.033227623872779555
Trained batch 305 in epoch 7, gen_loss = 0.399531022882929, disc_loss = 0.03313460115996171
Trained batch 306 in epoch 7, gen_loss = 0.3996375951588348, disc_loss = 0.03305863696021553
Trained batch 307 in epoch 7, gen_loss = 0.400037323402894, disc_loss = 0.033048997000056354
Trained batch 308 in epoch 7, gen_loss = 0.3999014344416004, disc_loss = 0.03303042776516449
Trained batch 309 in epoch 7, gen_loss = 0.4000688703790788, disc_loss = 0.032987315329768126
Trained batch 310 in epoch 7, gen_loss = 0.4002734786827848, disc_loss = 0.03293205130062219
Trained batch 311 in epoch 7, gen_loss = 0.40035705211070866, disc_loss = 0.03285349391659017
Trained batch 312 in epoch 7, gen_loss = 0.40025783889590744, disc_loss = 0.03280041714536604
Trained batch 313 in epoch 7, gen_loss = 0.40021029940456343, disc_loss = 0.03276792994535759
Trained batch 314 in epoch 7, gen_loss = 0.400269529554579, disc_loss = 0.03269339938433693
Trained batch 315 in epoch 7, gen_loss = 0.4003698763590825, disc_loss = 0.03261722971669021
Trained batch 316 in epoch 7, gen_loss = 0.4004582213678571, disc_loss = 0.03253214598790528
Trained batch 317 in epoch 7, gen_loss = 0.4007023644147429, disc_loss = 0.03245721457404547
Trained batch 318 in epoch 7, gen_loss = 0.40067549400195057, disc_loss = 0.032383367879430074
Trained batch 319 in epoch 7, gen_loss = 0.40055410461500285, disc_loss = 0.0323378139455599
Trained batch 320 in epoch 7, gen_loss = 0.4005266735301211, disc_loss = 0.032254740867453315
Trained batch 321 in epoch 7, gen_loss = 0.4005478143877124, disc_loss = 0.032172185879689494
Trained batch 322 in epoch 7, gen_loss = 0.4007018777792668, disc_loss = 0.032102678959033
Trained batch 323 in epoch 7, gen_loss = 0.40073271417691386, disc_loss = 0.032045911982106504
Trained batch 324 in epoch 7, gen_loss = 0.40095892291802626, disc_loss = 0.03198355172868245
Trained batch 325 in epoch 7, gen_loss = 0.4009157027020776, disc_loss = 0.03199863012350147
Trained batch 326 in epoch 7, gen_loss = 0.4007809223202755, disc_loss = 0.031942030069253065
Trained batch 327 in epoch 7, gen_loss = 0.40051022971548683, disc_loss = 0.03203920052541567
Trained batch 328 in epoch 7, gen_loss = 0.4003215395027381, disc_loss = 0.03239842234950762
Trained batch 329 in epoch 7, gen_loss = 0.40016646629030056, disc_loss = 0.03258641305922841
Trained batch 330 in epoch 7, gen_loss = 0.4002467101254132, disc_loss = 0.03251019997973828
Trained batch 331 in epoch 7, gen_loss = 0.4003518578338336, disc_loss = 0.03243430329420806
Trained batch 332 in epoch 7, gen_loss = 0.4004077999978452, disc_loss = 0.03240627588252551
Trained batch 333 in epoch 7, gen_loss = 0.4004765835529316, disc_loss = 0.032498962650546796
Trained batch 334 in epoch 7, gen_loss = 0.400268538763274, disc_loss = 0.03300319439418781
Trained batch 335 in epoch 7, gen_loss = 0.400554578840023, disc_loss = 0.033053363903794285
Trained batch 336 in epoch 7, gen_loss = 0.4004450096397796, disc_loss = 0.033067673530763994
Trained batch 337 in epoch 7, gen_loss = 0.40038654869477425, disc_loss = 0.03312013822658671
Trained batch 338 in epoch 7, gen_loss = 0.40059119840990476, disc_loss = 0.0330693585537841
Trained batch 339 in epoch 7, gen_loss = 0.4007993097690975, disc_loss = 0.03321306637851248
Trained batch 340 in epoch 7, gen_loss = 0.4006811701132755, disc_loss = 0.03337526538025566
Trained batch 341 in epoch 7, gen_loss = 0.40063997257871237, disc_loss = 0.033543294767116615
Trained batch 342 in epoch 7, gen_loss = 0.40058449075798946, disc_loss = 0.033474059819254706
Trained batch 343 in epoch 7, gen_loss = 0.40045918948775117, disc_loss = 0.03342207593249081
Trained batch 344 in epoch 7, gen_loss = 0.40054786801338194, disc_loss = 0.03334109077020886
Trained batch 345 in epoch 7, gen_loss = 0.40075707702622937, disc_loss = 0.033266430657768804
Trained batch 346 in epoch 7, gen_loss = 0.40076204825203426, disc_loss = 0.03319725989174871
Trained batch 347 in epoch 7, gen_loss = 0.4007667178052595, disc_loss = 0.03312572974600594
Trained batch 348 in epoch 7, gen_loss = 0.4006307409451821, disc_loss = 0.03311083590335621
Trained batch 349 in epoch 7, gen_loss = 0.4006046339443752, disc_loss = 0.033129070791349344
Trained batch 350 in epoch 7, gen_loss = 0.4007067688000508, disc_loss = 0.033053338102149936
Trained batch 351 in epoch 7, gen_loss = 0.4007701116868041, disc_loss = 0.03298758870865144
Trained batch 352 in epoch 7, gen_loss = 0.4007448565014361, disc_loss = 0.03291767657432367
Trained batch 353 in epoch 7, gen_loss = 0.4007422821333179, disc_loss = 0.03294461110171383
Trained batch 354 in epoch 7, gen_loss = 0.4007674690703271, disc_loss = 0.032874864409677684
Trained batch 355 in epoch 7, gen_loss = 0.40082490310240326, disc_loss = 0.032835698076013706
Trained batch 356 in epoch 7, gen_loss = 0.401042834299953, disc_loss = 0.03283071423670752
Trained batch 357 in epoch 7, gen_loss = 0.4009899043337593, disc_loss = 0.032752106185058166
Trained batch 358 in epoch 7, gen_loss = 0.4007649126989264, disc_loss = 0.03283095370211527
Trained batch 359 in epoch 7, gen_loss = 0.4008510009282165, disc_loss = 0.032894572750471224
Trained batch 360 in epoch 7, gen_loss = 0.4008911351087681, disc_loss = 0.03283097933483803
Trained batch 361 in epoch 7, gen_loss = 0.4011790172829812, disc_loss = 0.03278536233795004
Trained batch 362 in epoch 7, gen_loss = 0.40110081894010224, disc_loss = 0.032749490740904
Trained batch 363 in epoch 7, gen_loss = 0.40102021674533467, disc_loss = 0.032774356250449055
Trained batch 364 in epoch 7, gen_loss = 0.40113641480876977, disc_loss = 0.03270576878495463
Trained batch 365 in epoch 7, gen_loss = 0.40110324461603425, disc_loss = 0.032630410113135264
Trained batch 366 in epoch 7, gen_loss = 0.4010227258426292, disc_loss = 0.03260568346814265
Trained batch 367 in epoch 7, gen_loss = 0.40091454602130083, disc_loss = 0.03271223641280338
Trained batch 368 in epoch 7, gen_loss = 0.4009662373925289, disc_loss = 0.032785754985564707
Trained batch 369 in epoch 7, gen_loss = 0.40098697019589913, disc_loss = 0.03271148736821487
Trained batch 370 in epoch 7, gen_loss = 0.40110279912897195, disc_loss = 0.03263928089447751
Trained batch 371 in epoch 7, gen_loss = 0.4013592966942377, disc_loss = 0.032564610304493674
Trained batch 372 in epoch 7, gen_loss = 0.4013811123754639, disc_loss = 0.03248694234611292
Trained batch 373 in epoch 7, gen_loss = 0.4015200588314291, disc_loss = 0.032411628354522576
Trained batch 374 in epoch 7, gen_loss = 0.40160821604728697, disc_loss = 0.032332302514774106
Trained batch 375 in epoch 7, gen_loss = 0.4016743355450478, disc_loss = 0.0322545792296296
Trained batch 376 in epoch 7, gen_loss = 0.4016303919670753, disc_loss = 0.03219150055961965
Trained batch 377 in epoch 7, gen_loss = 0.40169397745498275, disc_loss = 0.0321192644002463
Trained batch 378 in epoch 7, gen_loss = 0.40195623150287013, disc_loss = 0.03210321848500658
Trained batch 379 in epoch 7, gen_loss = 0.402055724906294, disc_loss = 0.03204589795694981
Trained batch 380 in epoch 7, gen_loss = 0.4020207997538599, disc_loss = 0.03198047621044871
Trained batch 381 in epoch 7, gen_loss = 0.40200546009378285, disc_loss = 0.031907298977923194
Trained batch 382 in epoch 7, gen_loss = 0.40194140619770974, disc_loss = 0.03193014760972207
Trained batch 383 in epoch 7, gen_loss = 0.401713526652505, disc_loss = 0.03210203178878146
Trained batch 384 in epoch 7, gen_loss = 0.40181628194722263, disc_loss = 0.03275701318498604
Trained batch 385 in epoch 7, gen_loss = 0.4015956914795495, disc_loss = 0.03352866426063219
Trained batch 386 in epoch 7, gen_loss = 0.40145985932313194, disc_loss = 0.033764889825060866
Trained batch 387 in epoch 7, gen_loss = 0.40130809310478033, disc_loss = 0.034185400079352515
Trained batch 388 in epoch 7, gen_loss = 0.4008826472458925, disc_loss = 0.034862422985551464
Trained batch 389 in epoch 7, gen_loss = 0.40091237540428454, disc_loss = 0.035118560856267904
Trained batch 390 in epoch 7, gen_loss = 0.4009671196760729, disc_loss = 0.03524252699951277
Trained batch 391 in epoch 7, gen_loss = 0.4007376877172869, disc_loss = 0.03533639184856189
Trained batch 392 in epoch 7, gen_loss = 0.4006159405671913, disc_loss = 0.035426802307891046
Trained batch 393 in epoch 7, gen_loss = 0.40053968396283646, disc_loss = 0.03581864080482829
Trained batch 394 in epoch 7, gen_loss = 0.4003147091292128, disc_loss = 0.036485399324977415
Trained batch 395 in epoch 7, gen_loss = 0.40043400243075206, disc_loss = 0.036515209128000686
Trained batch 396 in epoch 7, gen_loss = 0.4003920260844963, disc_loss = 0.03653475313807512
Trained batch 397 in epoch 7, gen_loss = 0.40034603758073933, disc_loss = 0.036590953268889975
Trained batch 398 in epoch 7, gen_loss = 0.40043412556026814, disc_loss = 0.03657454747110279
Trained batch 399 in epoch 7, gen_loss = 0.40042062230408193, disc_loss = 0.03654149686015444
Trained batch 400 in epoch 7, gen_loss = 0.40050660672033217, disc_loss = 0.036515778753072714
Trained batch 401 in epoch 7, gen_loss = 0.4005583093237521, disc_loss = 0.036471338961470354
Trained batch 402 in epoch 7, gen_loss = 0.40047692039764254, disc_loss = 0.03651908752780001
Trained batch 403 in epoch 7, gen_loss = 0.4006636172237963, disc_loss = 0.03749942892988323
Trained batch 404 in epoch 7, gen_loss = 0.400615711197441, disc_loss = 0.03777028777561852
Trained batch 405 in epoch 7, gen_loss = 0.4005417016339419, disc_loss = 0.03777197569527255
Trained batch 406 in epoch 7, gen_loss = 0.40069604469165754, disc_loss = 0.03776984519973919
Trained batch 407 in epoch 7, gen_loss = 0.4005572659273942, disc_loss = 0.037716576606137954
Trained batch 408 in epoch 7, gen_loss = 0.40047106926481996, disc_loss = 0.03767386733293579
Trained batch 409 in epoch 7, gen_loss = 0.4004910916816897, disc_loss = 0.03760731763393822
Trained batch 410 in epoch 7, gen_loss = 0.400549023690885, disc_loss = 0.03753772691382807
Trained batch 411 in epoch 7, gen_loss = 0.4004505447392325, disc_loss = 0.03748982923486252
Trained batch 412 in epoch 7, gen_loss = 0.40041168059332893, disc_loss = 0.0375108468410002
Trained batch 413 in epoch 7, gen_loss = 0.40043218628219934, disc_loss = 0.03744756864807861
Trained batch 414 in epoch 7, gen_loss = 0.4005276412130838, disc_loss = 0.037416971324808354
Trained batch 415 in epoch 7, gen_loss = 0.40036422522881854, disc_loss = 0.037424043315975444
Trained batch 416 in epoch 7, gen_loss = 0.40039121211289785, disc_loss = 0.03753781321595872
Trained batch 417 in epoch 7, gen_loss = 0.40034181792199897, disc_loss = 0.037549952252569685
Trained batch 418 in epoch 7, gen_loss = 0.40031324821326497, disc_loss = 0.03748490861011335
Trained batch 419 in epoch 7, gen_loss = 0.40051095329579856, disc_loss = 0.03744163483497687
Trained batch 420 in epoch 7, gen_loss = 0.4005562084729201, disc_loss = 0.037362065385516084
Trained batch 421 in epoch 7, gen_loss = 0.40056972043209166, disc_loss = 0.03730575730654486
Trained batch 422 in epoch 7, gen_loss = 0.4005815083817105, disc_loss = 0.037299518819389775
Trained batch 423 in epoch 7, gen_loss = 0.4005600495158501, disc_loss = 0.03725441949434341
Trained batch 424 in epoch 7, gen_loss = 0.4006490006166346, disc_loss = 0.03719645810066996
Trained batch 425 in epoch 7, gen_loss = 0.40057357068352856, disc_loss = 0.03712271485601206
Trained batch 426 in epoch 7, gen_loss = 0.40070834253375925, disc_loss = 0.0370637894800561
Trained batch 427 in epoch 7, gen_loss = 0.40064921334525133, disc_loss = 0.03700562969321237
Trained batch 428 in epoch 7, gen_loss = 0.4007009528316818, disc_loss = 0.036937300822727975
Trained batch 429 in epoch 7, gen_loss = 0.4009078234434128, disc_loss = 0.03689009800125563
Trained batch 430 in epoch 7, gen_loss = 0.4010181657952665, disc_loss = 0.03693911283608664
Trained batch 431 in epoch 7, gen_loss = 0.40097863047763155, disc_loss = 0.037265422951518475
Trained batch 432 in epoch 7, gen_loss = 0.4008192765520021, disc_loss = 0.03745468734203264
Trained batch 433 in epoch 7, gen_loss = 0.40098412245649345, disc_loss = 0.03742482715682234
Trained batch 434 in epoch 7, gen_loss = 0.4009965763694939, disc_loss = 0.03739545443710796
Trained batch 435 in epoch 7, gen_loss = 0.40094431851981976, disc_loss = 0.03734612550267121
Trained batch 436 in epoch 7, gen_loss = 0.40093647001537086, disc_loss = 0.037296056307615705
Trained batch 437 in epoch 7, gen_loss = 0.40105099805958194, disc_loss = 0.037264116464839764
Trained batch 438 in epoch 7, gen_loss = 0.4009263256823555, disc_loss = 0.03724726179963644
Trained batch 439 in epoch 7, gen_loss = 0.40102531706744976, disc_loss = 0.037281972541611384
Trained batch 440 in epoch 7, gen_loss = 0.40115409846208533, disc_loss = 0.03740405522697645
Trained batch 441 in epoch 7, gen_loss = 0.4011153646858569, disc_loss = 0.037488900056810485
Trained batch 442 in epoch 7, gen_loss = 0.40092686632685953, disc_loss = 0.03794863604720783
Trained batch 443 in epoch 7, gen_loss = 0.40106498322508355, disc_loss = 0.03875161224041713
Trained batch 444 in epoch 7, gen_loss = 0.40101791184939695, disc_loss = 0.0388759710975096
Trained batch 445 in epoch 7, gen_loss = 0.4007615809216093, disc_loss = 0.0389339926523666
Trained batch 446 in epoch 7, gen_loss = 0.40063161737966857, disc_loss = 0.03897461930099225
Trained batch 447 in epoch 7, gen_loss = 0.40052036701568533, disc_loss = 0.03902885991270263
Trained batch 448 in epoch 7, gen_loss = 0.4003584901314801, disc_loss = 0.039080952614896365
Trained batch 449 in epoch 7, gen_loss = 0.4003360064824422, disc_loss = 0.03928167422534898
Trained batch 450 in epoch 7, gen_loss = 0.40019362233166156, disc_loss = 0.03967897052037222
Trained batch 451 in epoch 7, gen_loss = 0.40015953739659976, disc_loss = 0.039859813925721556
Trained batch 452 in epoch 7, gen_loss = 0.40004895768944526, disc_loss = 0.039973157377056284
Trained batch 453 in epoch 7, gen_loss = 0.39978246187323513, disc_loss = 0.04000452603854543
Trained batch 454 in epoch 7, gen_loss = 0.39976141177690944, disc_loss = 0.040005733579612124
Trained batch 455 in epoch 7, gen_loss = 0.3997299025456111, disc_loss = 0.040069229704003145
Trained batch 456 in epoch 7, gen_loss = 0.399648813632698, disc_loss = 0.04088051274701081
Trained batch 457 in epoch 7, gen_loss = 0.39950314639176865, disc_loss = 0.04134634520993751
Trained batch 458 in epoch 7, gen_loss = 0.39948996031466133, disc_loss = 0.041521896576977586
Trained batch 459 in epoch 7, gen_loss = 0.39955031813486763, disc_loss = 0.041516118609275586
Trained batch 460 in epoch 7, gen_loss = 0.3993319606574135, disc_loss = 0.041613168852078504
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 0.34047606587409973, disc_loss = 0.011666132137179375
Trained batch 1 in epoch 8, gen_loss = 0.36966629326343536, disc_loss = 0.020279170013964176
Trained batch 2 in epoch 8, gen_loss = 0.3911094069480896, disc_loss = 0.03358159027993679
Trained batch 3 in epoch 8, gen_loss = 0.36478428542613983, disc_loss = 0.07883747713640332
Trained batch 4 in epoch 8, gen_loss = 0.3894636511802673, disc_loss = 0.1414383713155985
Trained batch 5 in epoch 8, gen_loss = 0.38107654949029285, disc_loss = 0.13570222289611897
Trained batch 6 in epoch 8, gen_loss = 0.37583789229393005, disc_loss = 0.15560856062386716
Trained batch 7 in epoch 8, gen_loss = 0.38090716674923897, disc_loss = 0.14816159126348794
Trained batch 8 in epoch 8, gen_loss = 0.3778923584355248, disc_loss = 0.14516441048019463
Trained batch 9 in epoch 8, gen_loss = 0.3790030121803284, disc_loss = 0.1343795733526349
Trained batch 10 in epoch 8, gen_loss = 0.37945314699953253, disc_loss = 0.1236074199392037
Trained batch 11 in epoch 8, gen_loss = 0.3806008423368136, disc_loss = 0.11394108928895245
Trained batch 12 in epoch 8, gen_loss = 0.3801991962469541, disc_loss = 0.10567415913996789
Trained batch 13 in epoch 8, gen_loss = 0.37208221214158194, disc_loss = 0.1049470295464354
Trained batch 14 in epoch 8, gen_loss = 0.3766195774078369, disc_loss = 0.12320537474006414
Trained batch 15 in epoch 8, gen_loss = 0.37714347057044506, disc_loss = 0.11753452761331573
Trained batch 16 in epoch 8, gen_loss = 0.3724503271719989, disc_loss = 0.11557831094764612
Trained batch 17 in epoch 8, gen_loss = 0.37340538369284737, disc_loss = 0.11192174240325888
Trained batch 18 in epoch 8, gen_loss = 0.37362151240047653, disc_loss = 0.10872038321471528
Trained batch 19 in epoch 8, gen_loss = 0.37477657198905945, disc_loss = 0.10649541900493205
Trained batch 20 in epoch 8, gen_loss = 0.3746085379804884, disc_loss = 0.10379590417834975
Trained batch 21 in epoch 8, gen_loss = 0.37418304790150037, disc_loss = 0.10164228932593357
Trained batch 22 in epoch 8, gen_loss = 0.37728629682375037, disc_loss = 0.10007390967043846
Trained batch 23 in epoch 8, gen_loss = 0.3765571415424347, disc_loss = 0.0968936742671455
Trained batch 24 in epoch 8, gen_loss = 0.3781746053695679, disc_loss = 0.09334002900868654
Trained batch 25 in epoch 8, gen_loss = 0.3770402119709895, disc_loss = 0.09234496395891675
Trained batch 26 in epoch 8, gen_loss = 0.3762314363762184, disc_loss = 0.1011874015201573
Trained batch 27 in epoch 8, gen_loss = 0.37424332967826296, disc_loss = 0.1023911223414221
Trained batch 28 in epoch 8, gen_loss = 0.3807472936038313, disc_loss = 0.10164351905856667
Trained batch 29 in epoch 8, gen_loss = 0.37790094713370004, disc_loss = 0.10458677650118868
Trained batch 30 in epoch 8, gen_loss = 0.37766567257142836, disc_loss = 0.10213154869815035
Trained batch 31 in epoch 8, gen_loss = 0.37675100192427635, disc_loss = 0.09977611023350619
Trained batch 32 in epoch 8, gen_loss = 0.37906718615329626, disc_loss = 0.09792783797125924
Trained batch 33 in epoch 8, gen_loss = 0.3781605099930483, disc_loss = 0.09917337170747273
Trained batch 34 in epoch 8, gen_loss = 0.37887756313596455, disc_loss = 0.09807727728039026
Trained batch 35 in epoch 8, gen_loss = 0.3808060669236713, disc_loss = 0.10041801556427446
Trained batch 36 in epoch 8, gen_loss = 0.37936248489328334, disc_loss = 0.1100541217051245
Trained batch 37 in epoch 8, gen_loss = 0.38056126158488424, disc_loss = 0.1080603638516837
Trained batch 38 in epoch 8, gen_loss = 0.3821850067529923, disc_loss = 0.10762854357464956
Trained batch 39 in epoch 8, gen_loss = 0.38194257766008377, disc_loss = 0.10631438659038395
Trained batch 40 in epoch 8, gen_loss = 0.3809331837223797, disc_loss = 0.10511531733067297
Trained batch 41 in epoch 8, gen_loss = 0.38162621075198766, disc_loss = 0.10347397534531497
Trained batch 42 in epoch 8, gen_loss = 0.3820255315581033, disc_loss = 0.10129384055387142
Trained batch 43 in epoch 8, gen_loss = 0.38190485672517255, disc_loss = 0.09948965797031467
Trained batch 44 in epoch 8, gen_loss = 0.38253626690970527, disc_loss = 0.09777202780048053
Trained batch 45 in epoch 8, gen_loss = 0.38387925728507666, disc_loss = 0.09591432596030443
Trained batch 46 in epoch 8, gen_loss = 0.38512149136117163, disc_loss = 0.0950497992019704
Trained batch 47 in epoch 8, gen_loss = 0.38535723214348155, disc_loss = 0.09426722877348463
Trained batch 48 in epoch 8, gen_loss = 0.3855862209991533, disc_loss = 0.09503922520243392
Trained batch 49 in epoch 8, gen_loss = 0.3878288459777832, disc_loss = 0.09391962721943856
Trained batch 50 in epoch 8, gen_loss = 0.38863372393682893, disc_loss = 0.09254485306640466
Trained batch 51 in epoch 8, gen_loss = 0.38946010573552203, disc_loss = 0.09185740885396416
Trained batch 52 in epoch 8, gen_loss = 0.3880194813575385, disc_loss = 0.09084836052695536
Trained batch 53 in epoch 8, gen_loss = 0.38967268389684184, disc_loss = 0.08955670665535662
Trained batch 54 in epoch 8, gen_loss = 0.39096949859098956, disc_loss = 0.08805885612117974
Trained batch 55 in epoch 8, gen_loss = 0.3914781611944948, disc_loss = 0.08688676236696276
Trained batch 56 in epoch 8, gen_loss = 0.39137549358501766, disc_loss = 0.08705195574612733
Trained batch 57 in epoch 8, gen_loss = 0.3927502539651147, disc_loss = 0.0939386985345005
Trained batch 58 in epoch 8, gen_loss = 0.39378197870012055, disc_loss = 0.09312131053026197
Trained batch 59 in epoch 8, gen_loss = 0.3947579736510913, disc_loss = 0.09255647025226305
Trained batch 60 in epoch 8, gen_loss = 0.3942147234424216, disc_loss = 0.0920227640155764
Trained batch 61 in epoch 8, gen_loss = 0.3944016546010971, disc_loss = 0.09126071000261413
Trained batch 62 in epoch 8, gen_loss = 0.39475060455382815, disc_loss = 0.08997039790339177
Trained batch 63 in epoch 8, gen_loss = 0.3941812110133469, disc_loss = 0.08918920081487158
Trained batch 64 in epoch 8, gen_loss = 0.39385275061313924, disc_loss = 0.08850824956853802
Trained batch 65 in epoch 8, gen_loss = 0.3943725192185604, disc_loss = 0.08882830978484091
Trained batch 66 in epoch 8, gen_loss = 0.39514509377194873, disc_loss = 0.0880455885485593
Trained batch 67 in epoch 8, gen_loss = 0.39466021034647436, disc_loss = 0.08701914886478335
Trained batch 68 in epoch 8, gen_loss = 0.39538260819255444, disc_loss = 0.0889699170568391
Trained batch 69 in epoch 8, gen_loss = 0.3942537418433598, disc_loss = 0.09302914577004101
Trained batch 70 in epoch 8, gen_loss = 0.3943285190723312, disc_loss = 0.09258540465929349
Trained batch 71 in epoch 8, gen_loss = 0.39357058000233436, disc_loss = 0.09450192985564677
Trained batch 72 in epoch 8, gen_loss = 0.3934153722573633, disc_loss = 0.09403866838842426
Trained batch 73 in epoch 8, gen_loss = 0.3917302130847364, disc_loss = 0.09424211259151029
Trained batch 74 in epoch 8, gen_loss = 0.391978413661321, disc_loss = 0.09376718444749713
Trained batch 75 in epoch 8, gen_loss = 0.39155237259049164, disc_loss = 0.09318365463619366
Trained batch 76 in epoch 8, gen_loss = 0.3922096247022802, disc_loss = 0.09264127463223291
Trained batch 77 in epoch 8, gen_loss = 0.39355687376780385, disc_loss = 0.0923051737451878
Trained batch 78 in epoch 8, gen_loss = 0.39304471996766105, disc_loss = 0.09237667407156734
Trained batch 79 in epoch 8, gen_loss = 0.3933459982275963, disc_loss = 0.09277638893690891
Trained batch 80 in epoch 8, gen_loss = 0.3953852226704727, disc_loss = 0.09327378876530278
Trained batch 81 in epoch 8, gen_loss = 0.39471327458939903, disc_loss = 0.09253804824633025
Trained batch 82 in epoch 8, gen_loss = 0.3961664510060506, disc_loss = 0.09152766402967903
Trained batch 83 in epoch 8, gen_loss = 0.39666091473329634, disc_loss = 0.09059013510012023
Trained batch 84 in epoch 8, gen_loss = 0.3968702659887426, disc_loss = 0.08963503926882849
Trained batch 85 in epoch 8, gen_loss = 0.39801576421704404, disc_loss = 0.0886696329676048
Trained batch 86 in epoch 8, gen_loss = 0.39782063234811543, disc_loss = 0.08780581204905763
Trained batch 87 in epoch 8, gen_loss = 0.3979606824842366, disc_loss = 0.08689428944754499
Trained batch 88 in epoch 8, gen_loss = 0.39774788095709984, disc_loss = 0.08622088336145108
Trained batch 89 in epoch 8, gen_loss = 0.39790987935331135, disc_loss = 0.08646860754427811
Trained batch 90 in epoch 8, gen_loss = 0.3974135229875753, disc_loss = 0.08868421371105117
Trained batch 91 in epoch 8, gen_loss = 0.3987751324539599, disc_loss = 0.08957963698523362
Trained batch 92 in epoch 8, gen_loss = 0.39959534554071324, disc_loss = 0.08871767515196435
Trained batch 93 in epoch 8, gen_loss = 0.39969079164748494, disc_loss = 0.08793180706871158
Trained batch 94 in epoch 8, gen_loss = 0.39944640241171187, disc_loss = 0.08709187963977456
Trained batch 95 in epoch 8, gen_loss = 0.39927563971529406, disc_loss = 0.08623682382070304
Trained batch 96 in epoch 8, gen_loss = 0.39796364829712305, disc_loss = 0.08558820468882464
Trained batch 97 in epoch 8, gen_loss = 0.3972091045306653, disc_loss = 0.08512115619639504
Trained batch 98 in epoch 8, gen_loss = 0.39659874517508226, disc_loss = 0.08445100712524069
Trained batch 99 in epoch 8, gen_loss = 0.39693239092826843, disc_loss = 0.08394688472617418
Trained batch 100 in epoch 8, gen_loss = 0.3973552071221984, disc_loss = 0.0840090837855224
Trained batch 101 in epoch 8, gen_loss = 0.397416900770337, disc_loss = 0.08359372561487059
Trained batch 102 in epoch 8, gen_loss = 0.3972360610383228, disc_loss = 0.08310293312663737
Trained batch 103 in epoch 8, gen_loss = 0.3974737739906861, disc_loss = 0.08243956324160816
Trained batch 104 in epoch 8, gen_loss = 0.3977245719659896, disc_loss = 0.08172525396747958
Trained batch 105 in epoch 8, gen_loss = 0.39805646156365015, disc_loss = 0.08129522958682533
Trained batch 106 in epoch 8, gen_loss = 0.3973734765966362, disc_loss = 0.08260150026164462
Trained batch 107 in epoch 8, gen_loss = 0.3981712982058525, disc_loss = 0.08491737321795274
Trained batch 108 in epoch 8, gen_loss = 0.39811865752990094, disc_loss = 0.08428854478625666
Trained batch 109 in epoch 8, gen_loss = 0.39741540361534466, disc_loss = 0.08479066074995155
Trained batch 110 in epoch 8, gen_loss = 0.39663925686398066, disc_loss = 0.08414978319611233
Trained batch 111 in epoch 8, gen_loss = 0.3967872160886015, disc_loss = 0.0836957112062789
Trained batch 112 in epoch 8, gen_loss = 0.3966538729393377, disc_loss = 0.08311643560656008
Trained batch 113 in epoch 8, gen_loss = 0.39643418213777376, disc_loss = 0.08258677133881863
Trained batch 114 in epoch 8, gen_loss = 0.3956508366957955, disc_loss = 0.0823443235627011
Trained batch 115 in epoch 8, gen_loss = 0.3956139026017025, disc_loss = 0.08366839398613907
Trained batch 116 in epoch 8, gen_loss = 0.3954933866476401, disc_loss = 0.08556577044690394
Trained batch 117 in epoch 8, gen_loss = 0.3961015980122453, disc_loss = 0.08703429558535375
Trained batch 118 in epoch 8, gen_loss = 0.396363460717081, disc_loss = 0.08677779066478129
Trained batch 119 in epoch 8, gen_loss = 0.39581007982293764, disc_loss = 0.08700670938706026
Trained batch 120 in epoch 8, gen_loss = 0.39598716167379017, disc_loss = 0.08639062165613633
Trained batch 121 in epoch 8, gen_loss = 0.39635860553530394, disc_loss = 0.08598416106637995
Trained batch 122 in epoch 8, gen_loss = 0.39607937476499294, disc_loss = 0.08571881053181804
Trained batch 123 in epoch 8, gen_loss = 0.3957828021337909, disc_loss = 0.0853007901197059
Trained batch 124 in epoch 8, gen_loss = 0.39549776101112366, disc_loss = 0.084843710873276
Trained batch 125 in epoch 8, gen_loss = 0.39526987643468947, disc_loss = 0.0842746590995895
Trained batch 126 in epoch 8, gen_loss = 0.3954657032264499, disc_loss = 0.08416800883297962
Trained batch 127 in epoch 8, gen_loss = 0.39603242301382124, disc_loss = 0.08395352984734927
Trained batch 128 in epoch 8, gen_loss = 0.3960769608501316, disc_loss = 0.08353647640581395
Trained batch 129 in epoch 8, gen_loss = 0.39592357713442583, disc_loss = 0.0831948426946138
Trained batch 130 in epoch 8, gen_loss = 0.39521923865980774, disc_loss = 0.0827022143852904
Trained batch 131 in epoch 8, gen_loss = 0.3965976491118922, disc_loss = 0.08239455105186524
Trained batch 132 in epoch 8, gen_loss = 0.39686697945558935, disc_loss = 0.0819659056247009
Trained batch 133 in epoch 8, gen_loss = 0.39719381038822343, disc_loss = 0.08155449206329216
Trained batch 134 in epoch 8, gen_loss = 0.39752238746042606, disc_loss = 0.08119615409178314
Trained batch 135 in epoch 8, gen_loss = 0.3977515693096554, disc_loss = 0.08075147430645302
Trained batch 136 in epoch 8, gen_loss = 0.3978346623208401, disc_loss = 0.08044942415720463
Trained batch 137 in epoch 8, gen_loss = 0.3980072758335998, disc_loss = 0.08002872392872645
Trained batch 138 in epoch 8, gen_loss = 0.39803455587771297, disc_loss = 0.07955052980000703
Trained batch 139 in epoch 8, gen_loss = 0.3978574146117483, disc_loss = 0.07906377075040447
Trained batch 140 in epoch 8, gen_loss = 0.3978224743342569, disc_loss = 0.07860432566203018
Trained batch 141 in epoch 8, gen_loss = 0.3978153467178345, disc_loss = 0.0780945401474781
Trained batch 142 in epoch 8, gen_loss = 0.3981412682499919, disc_loss = 0.07832413886745389
Trained batch 143 in epoch 8, gen_loss = 0.39732667514019543, disc_loss = 0.07881015824710226
Trained batch 144 in epoch 8, gen_loss = 0.39787817371302636, disc_loss = 0.07833314016140226
Trained batch 145 in epoch 8, gen_loss = 0.3979848862102587, disc_loss = 0.07840574228791647
Trained batch 146 in epoch 8, gen_loss = 0.3977931399329179, disc_loss = 0.0781325056965203
Trained batch 147 in epoch 8, gen_loss = 0.3978279281306911, disc_loss = 0.07847442122717463
Trained batch 148 in epoch 8, gen_loss = 0.3985489502849195, disc_loss = 0.07863475024487648
Trained batch 149 in epoch 8, gen_loss = 0.3989924128850301, disc_loss = 0.07834338562873502
Trained batch 150 in epoch 8, gen_loss = 0.3987971380451657, disc_loss = 0.07784905140319012
Trained batch 151 in epoch 8, gen_loss = 0.3985527277384934, disc_loss = 0.07782316231168807
Trained batch 152 in epoch 8, gen_loss = 0.3986367690407373, disc_loss = 0.07749035717079453
Trained batch 153 in epoch 8, gen_loss = 0.3986742719040289, disc_loss = 0.0770594027473942
Trained batch 154 in epoch 8, gen_loss = 0.3985778206779111, disc_loss = 0.07664153757955759
Trained batch 155 in epoch 8, gen_loss = 0.39927208289886135, disc_loss = 0.07629248457483183
Trained batch 156 in epoch 8, gen_loss = 0.3994468105067113, disc_loss = 0.07592270073071597
Trained batch 157 in epoch 8, gen_loss = 0.40020934011362774, disc_loss = 0.07585022240712107
Trained batch 158 in epoch 8, gen_loss = 0.4001264122297179, disc_loss = 0.075910365999729
Trained batch 159 in epoch 8, gen_loss = 0.4006164507940412, disc_loss = 0.0767013267672155
Trained batch 160 in epoch 8, gen_loss = 0.4003386271666296, disc_loss = 0.0768492628201287
Trained batch 161 in epoch 8, gen_loss = 0.4009289180423007, disc_loss = 0.07645221086172962
Trained batch 162 in epoch 8, gen_loss = 0.40121085749813384, disc_loss = 0.07612468651353033
Trained batch 163 in epoch 8, gen_loss = 0.40130046845936196, disc_loss = 0.07573812864947974
Trained batch 164 in epoch 8, gen_loss = 0.4010441012454755, disc_loss = 0.07534692904940157
Trained batch 165 in epoch 8, gen_loss = 0.4007574289319027, disc_loss = 0.07496602191443903
Trained batch 166 in epoch 8, gen_loss = 0.4008534372209789, disc_loss = 0.07460876700362402
Trained batch 167 in epoch 8, gen_loss = 0.40095689786331995, disc_loss = 0.07418785767263866
Trained batch 168 in epoch 8, gen_loss = 0.4013557878471691, disc_loss = 0.07377232677308765
Trained batch 169 in epoch 8, gen_loss = 0.4012985257541432, disc_loss = 0.07343478205011171
Trained batch 170 in epoch 8, gen_loss = 0.4018244872316282, disc_loss = 0.07328483142089426
Trained batch 171 in epoch 8, gen_loss = 0.4017583291197932, disc_loss = 0.07400667972776086
Trained batch 172 in epoch 8, gen_loss = 0.40154489478623934, disc_loss = 0.07499494315313467
Trained batch 173 in epoch 8, gen_loss = 0.4012047663844865, disc_loss = 0.07459215769522834
Trained batch 174 in epoch 8, gen_loss = 0.40080251046589443, disc_loss = 0.07503092315580163
Trained batch 175 in epoch 8, gen_loss = 0.4007955628701232, disc_loss = 0.07693856540771032
Trained batch 176 in epoch 8, gen_loss = 0.4008911576984966, disc_loss = 0.07693912931796858
Trained batch 177 in epoch 8, gen_loss = 0.39993358503901555, disc_loss = 0.07720349064578166
Trained batch 178 in epoch 8, gen_loss = 0.39955871739534027, disc_loss = 0.07705405451274118
Trained batch 179 in epoch 8, gen_loss = 0.39948051414555974, disc_loss = 0.0767837568393184
Trained batch 180 in epoch 8, gen_loss = 0.39918874763981416, disc_loss = 0.07653744684439667
Trained batch 181 in epoch 8, gen_loss = 0.399051196873188, disc_loss = 0.07622724359056779
Trained batch 182 in epoch 8, gen_loss = 0.39914468264644914, disc_loss = 0.07590288762512103
Trained batch 183 in epoch 8, gen_loss = 0.3989983919360068, disc_loss = 0.07553883849987356
Trained batch 184 in epoch 8, gen_loss = 0.39914417758181286, disc_loss = 0.07531322341009572
Trained batch 185 in epoch 8, gen_loss = 0.3990046291421818, disc_loss = 0.07510375383219892
Trained batch 186 in epoch 8, gen_loss = 0.3985940806846568, disc_loss = 0.07524977719540743
Trained batch 187 in epoch 8, gen_loss = 0.39891404476254544, disc_loss = 0.07503679089069842
Trained batch 188 in epoch 8, gen_loss = 0.3984140407629114, disc_loss = 0.07483696944952484
Trained batch 189 in epoch 8, gen_loss = 0.3989099082978148, disc_loss = 0.07449295795277545
Trained batch 190 in epoch 8, gen_loss = 0.3994205944357118, disc_loss = 0.07422229964578651
Trained batch 191 in epoch 8, gen_loss = 0.3993559719529003, disc_loss = 0.07388726357021369
Trained batch 192 in epoch 8, gen_loss = 0.39928419316679703, disc_loss = 0.07366006445969633
Trained batch 193 in epoch 8, gen_loss = 0.3996721434685373, disc_loss = 0.0738238536263096
Trained batch 194 in epoch 8, gen_loss = 0.39973312073793166, disc_loss = 0.07354879678250888
Trained batch 195 in epoch 8, gen_loss = 0.39915098941751886, disc_loss = 0.0732214316697221
Trained batch 196 in epoch 8, gen_loss = 0.39935458152729847, disc_loss = 0.07299922731454452
Trained batch 197 in epoch 8, gen_loss = 0.39972862202410747, disc_loss = 0.07267286155767964
Trained batch 198 in epoch 8, gen_loss = 0.3995663326739067, disc_loss = 0.07275853887780677
Trained batch 199 in epoch 8, gen_loss = 0.3993897385150194, disc_loss = 0.07401996800210327
Trained batch 200 in epoch 8, gen_loss = 0.3991183820203762, disc_loss = 0.0739200422632976
Trained batch 201 in epoch 8, gen_loss = 0.3988833167027719, disc_loss = 0.07381820877423824
Trained batch 202 in epoch 8, gen_loss = 0.3990223854780197, disc_loss = 0.07416020157136793
Trained batch 203 in epoch 8, gen_loss = 0.3987326403605003, disc_loss = 0.07399820881055705
Trained batch 204 in epoch 8, gen_loss = 0.3988027257890236, disc_loss = 0.07374083746406364
Trained batch 205 in epoch 8, gen_loss = 0.39875952950091037, disc_loss = 0.07345498617720402
Trained batch 206 in epoch 8, gen_loss = 0.3986477043461684, disc_loss = 0.07334033738605786
Trained batch 207 in epoch 8, gen_loss = 0.39900413606888974, disc_loss = 0.07327907767522937
Trained batch 208 in epoch 8, gen_loss = 0.3984834559653935, disc_loss = 0.07323950431510165
Trained batch 209 in epoch 8, gen_loss = 0.3985858470911071, disc_loss = 0.07313367921770328
Trained batch 210 in epoch 8, gen_loss = 0.3985635966627519, disc_loss = 0.07284157754526743
Trained batch 211 in epoch 8, gen_loss = 0.3982299815793082, disc_loss = 0.07263391757963823
Trained batch 212 in epoch 8, gen_loss = 0.3985002980405736, disc_loss = 0.07235867948109555
Trained batch 213 in epoch 8, gen_loss = 0.39829233031128053, disc_loss = 0.07237707177681901
Trained batch 214 in epoch 8, gen_loss = 0.397826213406962, disc_loss = 0.07366285713952642
Trained batch 215 in epoch 8, gen_loss = 0.3980737658976405, disc_loss = 0.07367639428142596
Trained batch 216 in epoch 8, gen_loss = 0.39803785257350466, disc_loss = 0.07360027538191888
Trained batch 217 in epoch 8, gen_loss = 0.3976038319118526, disc_loss = 0.07348173544015907
Trained batch 218 in epoch 8, gen_loss = 0.39773588426853423, disc_loss = 0.07335468931081088
Trained batch 219 in epoch 8, gen_loss = 0.39763986190611667, disc_loss = 0.07318742055107247
Trained batch 220 in epoch 8, gen_loss = 0.3977332440841252, disc_loss = 0.07293986270364324
Trained batch 221 in epoch 8, gen_loss = 0.3975823612229244, disc_loss = 0.07269498419754945
Trained batch 222 in epoch 8, gen_loss = 0.3976068331655365, disc_loss = 0.072567494185182
Trained batch 223 in epoch 8, gen_loss = 0.39740251091175843, disc_loss = 0.07244615410620879
Trained batch 224 in epoch 8, gen_loss = 0.39748147123389777, disc_loss = 0.07240271396934986
Trained batch 225 in epoch 8, gen_loss = 0.39800477720203653, disc_loss = 0.07260912713652427
Trained batch 226 in epoch 8, gen_loss = 0.3978182913054454, disc_loss = 0.07344519767893831
Trained batch 227 in epoch 8, gen_loss = 0.3983311938742797, disc_loss = 0.0735084934797334
Trained batch 228 in epoch 8, gen_loss = 0.3983982151382355, disc_loss = 0.0735974591388062
Trained batch 229 in epoch 8, gen_loss = 0.39777013951021695, disc_loss = 0.07373400198538667
Trained batch 230 in epoch 8, gen_loss = 0.39765776745426706, disc_loss = 0.07346066912370068
Trained batch 231 in epoch 8, gen_loss = 0.3980043928042568, disc_loss = 0.07317310696917362
Trained batch 232 in epoch 8, gen_loss = 0.3979989041458384, disc_loss = 0.07304096919016777
Trained batch 233 in epoch 8, gen_loss = 0.3982567870591441, disc_loss = 0.07375518678345232
Trained batch 234 in epoch 8, gen_loss = 0.39853195731944224, disc_loss = 0.07450548289938176
Trained batch 235 in epoch 8, gen_loss = 0.3984717607371888, disc_loss = 0.07433092805667449
Trained batch 236 in epoch 8, gen_loss = 0.39813223135370746, disc_loss = 0.0743942433960327
Trained batch 237 in epoch 8, gen_loss = 0.3978455486793478, disc_loss = 0.07435502478179812
Trained batch 238 in epoch 8, gen_loss = 0.3978860532264829, disc_loss = 0.0740806386342358
Trained batch 239 in epoch 8, gen_loss = 0.3979732401048144, disc_loss = 0.0738506311783567
Trained batch 240 in epoch 8, gen_loss = 0.39795132933563215, disc_loss = 0.07379602383497592
Trained batch 241 in epoch 8, gen_loss = 0.39784479048872784, disc_loss = 0.07409417425274603
Trained batch 242 in epoch 8, gen_loss = 0.39767809837688634, disc_loss = 0.07464282747373414
Trained batch 243 in epoch 8, gen_loss = 0.39771453578208316, disc_loss = 0.0745468330874917
Trained batch 244 in epoch 8, gen_loss = 0.3979614022434974, disc_loss = 0.07466482344482626
Trained batch 245 in epoch 8, gen_loss = 0.3979824185977137, disc_loss = 0.07464971678800941
Trained batch 246 in epoch 8, gen_loss = 0.3974011512058467, disc_loss = 0.07446642557106278
Trained batch 247 in epoch 8, gen_loss = 0.3973878580596178, disc_loss = 0.07426383920134075
Trained batch 248 in epoch 8, gen_loss = 0.39758824206978444, disc_loss = 0.07400509865438364
Trained batch 249 in epoch 8, gen_loss = 0.39722108250856397, disc_loss = 0.07403571558743716
Trained batch 250 in epoch 8, gen_loss = 0.39738276464293204, disc_loss = 0.07411526916066251
Trained batch 251 in epoch 8, gen_loss = 0.3971459932388767, disc_loss = 0.07389479066200909
Trained batch 252 in epoch 8, gen_loss = 0.39694477170116815, disc_loss = 0.07387047279405264
Trained batch 253 in epoch 8, gen_loss = 0.39715830858532836, disc_loss = 0.0740770275565231
Trained batch 254 in epoch 8, gen_loss = 0.39686326589070114, disc_loss = 0.0741962829129953
Trained batch 255 in epoch 8, gen_loss = 0.3968561112997122, disc_loss = 0.0740890728411614
Trained batch 256 in epoch 8, gen_loss = 0.3970761705581316, disc_loss = 0.07386500416649687
Trained batch 257 in epoch 8, gen_loss = 0.39716835106297055, disc_loss = 0.07360122111344407
Trained batch 258 in epoch 8, gen_loss = 0.397096963290082, disc_loss = 0.0733816401860371
Trained batch 259 in epoch 8, gen_loss = 0.3972026666196493, disc_loss = 0.07312420589777713
Trained batch 260 in epoch 8, gen_loss = 0.39704810927882506, disc_loss = 0.07296933710817748
Trained batch 261 in epoch 8, gen_loss = 0.3967584027475073, disc_loss = 0.07286254230189983
Trained batch 262 in epoch 8, gen_loss = 0.39685422731669684, disc_loss = 0.07266184617853777
Trained batch 263 in epoch 8, gen_loss = 0.3973392515132825, disc_loss = 0.07294970421670852
Trained batch 264 in epoch 8, gen_loss = 0.3973676300836059, disc_loss = 0.07286530445980013
Trained batch 265 in epoch 8, gen_loss = 0.3971502728816262, disc_loss = 0.07263497157806628
Trained batch 266 in epoch 8, gen_loss = 0.3971714818857136, disc_loss = 0.07252690999346614
Trained batch 267 in epoch 8, gen_loss = 0.3970786285822961, disc_loss = 0.07242682584172198
Trained batch 268 in epoch 8, gen_loss = 0.3970975565090499, disc_loss = 0.07228829437125904
Trained batch 269 in epoch 8, gen_loss = 0.3971356428883694, disc_loss = 0.07212175227080782
Trained batch 270 in epoch 8, gen_loss = 0.3974058208540357, disc_loss = 0.07189746402767641
Trained batch 271 in epoch 8, gen_loss = 0.39731249766533866, disc_loss = 0.07169946501209565
Trained batch 272 in epoch 8, gen_loss = 0.3971396940640914, disc_loss = 0.07145512793827188
Trained batch 273 in epoch 8, gen_loss = 0.39699072238520117, disc_loss = 0.07136315419372634
Trained batch 274 in epoch 8, gen_loss = 0.3971024509451606, disc_loss = 0.07111459654586559
Trained batch 275 in epoch 8, gen_loss = 0.39712008515345876, disc_loss = 0.07126947722914022
Trained batch 276 in epoch 8, gen_loss = 0.3971361267760342, disc_loss = 0.07112785515926832
Trained batch 277 in epoch 8, gen_loss = 0.3969452456711865, disc_loss = 0.07172306357437357
Trained batch 278 in epoch 8, gen_loss = 0.3971175300925436, disc_loss = 0.0721912765750281
Trained batch 279 in epoch 8, gen_loss = 0.39714012449341163, disc_loss = 0.07197890693205408
Trained batch 280 in epoch 8, gen_loss = 0.3971379576946917, disc_loss = 0.07185351628946055
Trained batch 281 in epoch 8, gen_loss = 0.3971669951334913, disc_loss = 0.07163132113282378
Trained batch 282 in epoch 8, gen_loss = 0.39683051786448004, disc_loss = 0.07146079152207098
Trained batch 283 in epoch 8, gen_loss = 0.3967059113505021, disc_loss = 0.07123796425474493
Trained batch 284 in epoch 8, gen_loss = 0.39680579905970054, disc_loss = 0.0710928804984545
Trained batch 285 in epoch 8, gen_loss = 0.3964870991510945, disc_loss = 0.071139024760268
Trained batch 286 in epoch 8, gen_loss = 0.3967412721093108, disc_loss = 0.07174653107647619
Trained batch 287 in epoch 8, gen_loss = 0.39667150921498734, disc_loss = 0.07202640560717555
Trained batch 288 in epoch 8, gen_loss = 0.3967340422027251, disc_loss = 0.07214587990752064
Trained batch 289 in epoch 8, gen_loss = 0.3967310297591933, disc_loss = 0.07193418635328397
Trained batch 290 in epoch 8, gen_loss = 0.3967607935372087, disc_loss = 0.07172246319017793
Trained batch 291 in epoch 8, gen_loss = 0.3969701606627197, disc_loss = 0.07151465312568216
Trained batch 292 in epoch 8, gen_loss = 0.3969700186427543, disc_loss = 0.07128809627110565
Trained batch 293 in epoch 8, gen_loss = 0.39708898540864995, disc_loss = 0.07106070563935225
Trained batch 294 in epoch 8, gen_loss = 0.3972099463313313, disc_loss = 0.07084245992335096
Trained batch 295 in epoch 8, gen_loss = 0.39728563616203294, disc_loss = 0.07064986467358304
Trained batch 296 in epoch 8, gen_loss = 0.39710839734936404, disc_loss = 0.07047633992849853
Trained batch 297 in epoch 8, gen_loss = 0.39702388489206364, disc_loss = 0.07035317560017183
Trained batch 298 in epoch 8, gen_loss = 0.3973564443281263, disc_loss = 0.07033152539940259
Trained batch 299 in epoch 8, gen_loss = 0.3974665964146455, disc_loss = 0.07027855810321247
Trained batch 300 in epoch 8, gen_loss = 0.397605437327461, disc_loss = 0.07006868596987001
Trained batch 301 in epoch 8, gen_loss = 0.39757851047429027, disc_loss = 0.06984974945886123
Trained batch 302 in epoch 8, gen_loss = 0.39773683623708905, disc_loss = 0.06977154460747914
Trained batch 303 in epoch 8, gen_loss = 0.39745167971245554, disc_loss = 0.07017565218312054
Trained batch 304 in epoch 8, gen_loss = 0.3975148801432281, disc_loss = 0.07096187651813886
Trained batch 305 in epoch 8, gen_loss = 0.39757171706631295, disc_loss = 0.07110635776702753
Trained batch 306 in epoch 8, gen_loss = 0.3974997368717038, disc_loss = 0.07116616246630271
Trained batch 307 in epoch 8, gen_loss = 0.397427682123788, disc_loss = 0.07111773163294903
Trained batch 308 in epoch 8, gen_loss = 0.39735415206565056, disc_loss = 0.07093423412295968
Trained batch 309 in epoch 8, gen_loss = 0.3973231736210085, disc_loss = 0.07077866914276515
Trained batch 310 in epoch 8, gen_loss = 0.3975191782812597, disc_loss = 0.07061141230079115
Trained batch 311 in epoch 8, gen_loss = 0.39743182086982787, disc_loss = 0.0704876082637407
Trained batch 312 in epoch 8, gen_loss = 0.3975037500595513, disc_loss = 0.07038470341216999
Trained batch 313 in epoch 8, gen_loss = 0.3973272116795467, disc_loss = 0.0702743833064499
Trained batch 314 in epoch 8, gen_loss = 0.39754730638057467, disc_loss = 0.0701863216406237
Trained batch 315 in epoch 8, gen_loss = 0.39742716510273235, disc_loss = 0.07022234261304117
Trained batch 316 in epoch 8, gen_loss = 0.39778801643698, disc_loss = 0.07165959798466497
Trained batch 317 in epoch 8, gen_loss = 0.39766281829127725, disc_loss = 0.07157548082591204
Trained batch 318 in epoch 8, gen_loss = 0.39752585447880917, disc_loss = 0.07195418668096319
Trained batch 319 in epoch 8, gen_loss = 0.39726750147528944, disc_loss = 0.07177808618507697
Trained batch 320 in epoch 8, gen_loss = 0.3970527209318315, disc_loss = 0.07173242476461252
Trained batch 321 in epoch 8, gen_loss = 0.3968067224258962, disc_loss = 0.07154060154791736
Trained batch 322 in epoch 8, gen_loss = 0.39691768909570974, disc_loss = 0.07141256855077027
Trained batch 323 in epoch 8, gen_loss = 0.396728859041576, disc_loss = 0.07123619265908973
Trained batch 324 in epoch 8, gen_loss = 0.3966394070937083, disc_loss = 0.07105083794762881
Trained batch 325 in epoch 8, gen_loss = 0.39654968784082156, disc_loss = 0.07101307166211787
Trained batch 326 in epoch 8, gen_loss = 0.39637402506596453, disc_loss = 0.0709847424895608
Trained batch 327 in epoch 8, gen_loss = 0.39652066836815053, disc_loss = 0.0708790444449533
Trained batch 328 in epoch 8, gen_loss = 0.3962796709548376, disc_loss = 0.07156910652388171
Trained batch 329 in epoch 8, gen_loss = 0.39652274571584933, disc_loss = 0.07207817112617759
Trained batch 330 in epoch 8, gen_loss = 0.3967297372050876, disc_loss = 0.07191336518674075
Trained batch 331 in epoch 8, gen_loss = 0.3968720271375524, disc_loss = 0.07178929377647386
Trained batch 332 in epoch 8, gen_loss = 0.39687187021022086, disc_loss = 0.07162155207266119
Trained batch 333 in epoch 8, gen_loss = 0.39684520933977857, disc_loss = 0.07146331995466311
Trained batch 334 in epoch 8, gen_loss = 0.396884370606337, disc_loss = 0.07132347741219869
Trained batch 335 in epoch 8, gen_loss = 0.39685402575525497, disc_loss = 0.07127832409778853
Trained batch 336 in epoch 8, gen_loss = 0.39694963846609926, disc_loss = 0.07125903105775022
Trained batch 337 in epoch 8, gen_loss = 0.3970002550080683, disc_loss = 0.07106389975679499
Trained batch 338 in epoch 8, gen_loss = 0.3970153086920403, disc_loss = 0.07090150431048532
Trained batch 339 in epoch 8, gen_loss = 0.39689607931410564, disc_loss = 0.0707390594700187
Trained batch 340 in epoch 8, gen_loss = 0.3970700800855838, disc_loss = 0.0706580680244687
Trained batch 341 in epoch 8, gen_loss = 0.397219767826691, disc_loss = 0.07072180564234806
Trained batch 342 in epoch 8, gen_loss = 0.39718207530134275, disc_loss = 0.07069815602085659
Trained batch 343 in epoch 8, gen_loss = 0.39725664245008036, disc_loss = 0.07054342014571587
Trained batch 344 in epoch 8, gen_loss = 0.3975946784451388, disc_loss = 0.07061510961975201
Trained batch 345 in epoch 8, gen_loss = 0.39776259501373146, disc_loss = 0.07043585675631278
Trained batch 346 in epoch 8, gen_loss = 0.3977480384303788, disc_loss = 0.07030459225207288
Trained batch 347 in epoch 8, gen_loss = 0.3977722902835786, disc_loss = 0.07012106118597967
Trained batch 348 in epoch 8, gen_loss = 0.3977823945290721, disc_loss = 0.069966908827835
Trained batch 349 in epoch 8, gen_loss = 0.3977642232605389, disc_loss = 0.06979896638076752
Trained batch 350 in epoch 8, gen_loss = 0.3979027517076231, disc_loss = 0.0697589523969563
Trained batch 351 in epoch 8, gen_loss = 0.3981387081386691, disc_loss = 0.06966395783092594
Trained batch 352 in epoch 8, gen_loss = 0.3981491831730175, disc_loss = 0.06964987542852231
Trained batch 353 in epoch 8, gen_loss = 0.3984702614656949, disc_loss = 0.06966441660385453
Trained batch 354 in epoch 8, gen_loss = 0.3984409828840847, disc_loss = 0.0694862114888629
Trained batch 355 in epoch 8, gen_loss = 0.39840980815920934, disc_loss = 0.06962575828015616
Trained batch 356 in epoch 8, gen_loss = 0.39864646056953934, disc_loss = 0.06971360757328696
Trained batch 357 in epoch 8, gen_loss = 0.3985230510211524, disc_loss = 0.0695422694273033
Trained batch 358 in epoch 8, gen_loss = 0.3984424110325598, disc_loss = 0.06943590076923017
Trained batch 359 in epoch 8, gen_loss = 0.3985546781371037, disc_loss = 0.069287807066899
Trained batch 360 in epoch 8, gen_loss = 0.398457554610152, disc_loss = 0.0691756840267701
Trained batch 361 in epoch 8, gen_loss = 0.39840936409669686, disc_loss = 0.06900351430554437
Trained batch 362 in epoch 8, gen_loss = 0.3983535497723861, disc_loss = 0.06899502146642747
Trained batch 363 in epoch 8, gen_loss = 0.39848426201350085, disc_loss = 0.06966308852117815
Trained batch 364 in epoch 8, gen_loss = 0.39873003865758033, disc_loss = 0.06974338227564035
Trained batch 365 in epoch 8, gen_loss = 0.3987256525888469, disc_loss = 0.06965871888932981
Trained batch 366 in epoch 8, gen_loss = 0.39855172909410513, disc_loss = 0.06972465847684857
Trained batch 367 in epoch 8, gen_loss = 0.3985688017033365, disc_loss = 0.06979520897110215
Trained batch 368 in epoch 8, gen_loss = 0.3987814517121328, disc_loss = 0.06995323993742647
Trained batch 369 in epoch 8, gen_loss = 0.39871527741889695, disc_loss = 0.06982848613862754
Trained batch 370 in epoch 8, gen_loss = 0.39866064288063513, disc_loss = 0.0697515009409143
Trained batch 371 in epoch 8, gen_loss = 0.39862716041745677, disc_loss = 0.06959126926069799
Trained batch 372 in epoch 8, gen_loss = 0.39861821357270666, disc_loss = 0.06957288905691066
Trained batch 373 in epoch 8, gen_loss = 0.3987827497449788, disc_loss = 0.07016857478700399
Trained batch 374 in epoch 8, gen_loss = 0.39856576788425446, disc_loss = 0.07056825010292232
Trained batch 375 in epoch 8, gen_loss = 0.3984123131141384, disc_loss = 0.07116202019623163
Trained batch 376 in epoch 8, gen_loss = 0.39836562276677046, disc_loss = 0.07132317778278903
Trained batch 377 in epoch 8, gen_loss = 0.39822020531489105, disc_loss = 0.0714476747794333
Trained batch 378 in epoch 8, gen_loss = 0.3980385973695715, disc_loss = 0.07132115118552029
Trained batch 379 in epoch 8, gen_loss = 0.3981102315610961, disc_loss = 0.07119902434427977
Trained batch 380 in epoch 8, gen_loss = 0.39823735741961974, disc_loss = 0.07110479019711825
Trained batch 381 in epoch 8, gen_loss = 0.3982663412446751, disc_loss = 0.07104796889245374
Trained batch 382 in epoch 8, gen_loss = 0.3981419389692984, disc_loss = 0.07101066449751917
Trained batch 383 in epoch 8, gen_loss = 0.3980670046294108, disc_loss = 0.0717472536131633
Trained batch 384 in epoch 8, gen_loss = 0.3980269120498137, disc_loss = 0.07201035576509675
Trained batch 385 in epoch 8, gen_loss = 0.3979539477840606, disc_loss = 0.07231536280144238
Trained batch 386 in epoch 8, gen_loss = 0.3978173361191146, disc_loss = 0.07258843717487765
Trained batch 387 in epoch 8, gen_loss = 0.3979558572557169, disc_loss = 0.07254787757524683
Trained batch 388 in epoch 8, gen_loss = 0.39790610976727886, disc_loss = 0.07268956434137276
Trained batch 389 in epoch 8, gen_loss = 0.3982360967076742, disc_loss = 0.0729802450338283
Trained batch 390 in epoch 8, gen_loss = 0.39824311389490163, disc_loss = 0.0729835061457656
Trained batch 391 in epoch 8, gen_loss = 0.3986649919605377, disc_loss = 0.0728298092661283
Trained batch 392 in epoch 8, gen_loss = 0.39886627211673875, disc_loss = 0.07271139709807402
Trained batch 393 in epoch 8, gen_loss = 0.39906334979128716, disc_loss = 0.07257822224797048
Trained batch 394 in epoch 8, gen_loss = 0.39921126580691035, disc_loss = 0.07244200065932413
Trained batch 395 in epoch 8, gen_loss = 0.39924276360508165, disc_loss = 0.07233462931242574
Trained batch 396 in epoch 8, gen_loss = 0.39922010864809115, disc_loss = 0.07226536538210282
Trained batch 397 in epoch 8, gen_loss = 0.3993072039892326, disc_loss = 0.07224764660686422
Trained batch 398 in epoch 8, gen_loss = 0.39913589856528997, disc_loss = 0.07254028283724827
Trained batch 399 in epoch 8, gen_loss = 0.39924797881394625, disc_loss = 0.07292064362030942
Trained batch 400 in epoch 8, gen_loss = 0.39907724538497497, disc_loss = 0.07286253645656134
Trained batch 401 in epoch 8, gen_loss = 0.3993709404299508, disc_loss = 0.07284104807212004
Trained batch 402 in epoch 8, gen_loss = 0.399482102644059, disc_loss = 0.07273411000015736
Trained batch 403 in epoch 8, gen_loss = 0.39940135701015445, disc_loss = 0.07277722427872757
Trained batch 404 in epoch 8, gen_loss = 0.3997821001726904, disc_loss = 0.07332270733931642
Trained batch 405 in epoch 8, gen_loss = 0.39969186525186295, disc_loss = 0.07318479596956041
Trained batch 406 in epoch 8, gen_loss = 0.3994219259562598, disc_loss = 0.07310237450678478
Trained batch 407 in epoch 8, gen_loss = 0.3994547806168888, disc_loss = 0.07319212930251881
Trained batch 408 in epoch 8, gen_loss = 0.39935265102567186, disc_loss = 0.07388406451666286
Trained batch 409 in epoch 8, gen_loss = 0.39947087891945027, disc_loss = 0.07378229434181732
Trained batch 410 in epoch 8, gen_loss = 0.39928173928220195, disc_loss = 0.07374740858594014
Trained batch 411 in epoch 8, gen_loss = 0.39926263852750216, disc_loss = 0.07367574276902161
Trained batch 412 in epoch 8, gen_loss = 0.3990419832831722, disc_loss = 0.0736066305375101
Trained batch 413 in epoch 8, gen_loss = 0.39887840732716134, disc_loss = 0.07363192240228418
Trained batch 414 in epoch 8, gen_loss = 0.3990413386778659, disc_loss = 0.0735277580102928
Trained batch 415 in epoch 8, gen_loss = 0.3990984073696801, disc_loss = 0.07348231507225697
Trained batch 416 in epoch 8, gen_loss = 0.3991181028904103, disc_loss = 0.07341735887595807
Trained batch 417 in epoch 8, gen_loss = 0.39907679257638146, disc_loss = 0.07327966084403018
Trained batch 418 in epoch 8, gen_loss = 0.3990533470325083, disc_loss = 0.073166824208777
Trained batch 419 in epoch 8, gen_loss = 0.3992291935497806, disc_loss = 0.07312854633810709
Trained batch 420 in epoch 8, gen_loss = 0.39923564615413865, disc_loss = 0.07311196447208507
Trained batch 421 in epoch 8, gen_loss = 0.39922936906888024, disc_loss = 0.07306319250784797
Trained batch 422 in epoch 8, gen_loss = 0.39927842265466146, disc_loss = 0.07291149863935831
Trained batch 423 in epoch 8, gen_loss = 0.39937323982001477, disc_loss = 0.07284538471414533
Trained batch 424 in epoch 8, gen_loss = 0.39960034892839547, disc_loss = 0.0727230584780302
Trained batch 425 in epoch 8, gen_loss = 0.39960942242486935, disc_loss = 0.07262440137576066
Trained batch 426 in epoch 8, gen_loss = 0.39964169776830516, disc_loss = 0.07253434267211313
Trained batch 427 in epoch 8, gen_loss = 0.39950396903903684, disc_loss = 0.0723886490743999
Trained batch 428 in epoch 8, gen_loss = 0.3994843691309571, disc_loss = 0.07231719789338366
Trained batch 429 in epoch 8, gen_loss = 0.3994689667987269, disc_loss = 0.07226958139745389
Trained batch 430 in epoch 8, gen_loss = 0.3994449191400457, disc_loss = 0.07223010839399581
Trained batch 431 in epoch 8, gen_loss = 0.39943483213169706, disc_loss = 0.07208103218376723
Trained batch 432 in epoch 8, gen_loss = 0.3994321881967659, disc_loss = 0.07209680724177105
Trained batch 433 in epoch 8, gen_loss = 0.399415618091959, disc_loss = 0.07245974974923505
Trained batch 434 in epoch 8, gen_loss = 0.39959714909394584, disc_loss = 0.07256285257947942
Trained batch 435 in epoch 8, gen_loss = 0.3996166535268683, disc_loss = 0.07248400333775379
Trained batch 436 in epoch 8, gen_loss = 0.3997189349045197, disc_loss = 0.07240629243958545
Trained batch 437 in epoch 8, gen_loss = 0.39959925600246754, disc_loss = 0.07230997701828287
Trained batch 438 in epoch 8, gen_loss = 0.3995524144865114, disc_loss = 0.07230964581830032
Trained batch 439 in epoch 8, gen_loss = 0.39968231167982926, disc_loss = 0.07244277041543021
Trained batch 440 in epoch 8, gen_loss = 0.3997655388246588, disc_loss = 0.07232671789033021
Trained batch 441 in epoch 8, gen_loss = 0.39993000816031277, disc_loss = 0.07223636928863604
Trained batch 442 in epoch 8, gen_loss = 0.4000204402289057, disc_loss = 0.07214593757459006
Trained batch 443 in epoch 8, gen_loss = 0.3999296001552998, disc_loss = 0.0720838760282752
Trained batch 444 in epoch 8, gen_loss = 0.3999233409594954, disc_loss = 0.07193206515675934
Trained batch 445 in epoch 8, gen_loss = 0.399986920301957, disc_loss = 0.07179029371574805
Trained batch 446 in epoch 8, gen_loss = 0.3999918182890954, disc_loss = 0.07164549725536482
Trained batch 447 in epoch 8, gen_loss = 0.40026240459909396, disc_loss = 0.07151497288941755
Trained batch 448 in epoch 8, gen_loss = 0.4003392468250143, disc_loss = 0.07137074345517447
Trained batch 449 in epoch 8, gen_loss = 0.4003384460012118, disc_loss = 0.0712929501876028
Trained batch 450 in epoch 8, gen_loss = 0.40018786417274943, disc_loss = 0.0713623070675351
Trained batch 451 in epoch 8, gen_loss = 0.40026343610566273, disc_loss = 0.07135912667974352
Trained batch 452 in epoch 8, gen_loss = 0.4005247096944329, disc_loss = 0.0712281277307636
Trained batch 453 in epoch 8, gen_loss = 0.4004555327842414, disc_loss = 0.07108295596838572
Trained batch 454 in epoch 8, gen_loss = 0.4004428347715965, disc_loss = 0.07095889754665012
Trained batch 455 in epoch 8, gen_loss = 0.40059420920647026, disc_loss = 0.070842378173869
Trained batch 456 in epoch 8, gen_loss = 0.40049413567168446, disc_loss = 0.07069554195802503
Trained batch 457 in epoch 8, gen_loss = 0.400582726442918, disc_loss = 0.07055851515162916
Trained batch 458 in epoch 8, gen_loss = 0.4004933161738132, disc_loss = 0.07041128329762252
Trained batch 459 in epoch 8, gen_loss = 0.40040777037325115, disc_loss = 0.07027495688475345
Trained batch 460 in epoch 8, gen_loss = 0.40055403646703913, disc_loss = 0.07014209080544057
Testing Epoch 8

Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 0.40645402669906616, disc_loss = 0.013678395189344883
Trained batch 1 in epoch 9, gen_loss = 0.3884401470422745, disc_loss = 0.012917737942188978
Trained batch 2 in epoch 9, gen_loss = 0.4301113982995351, disc_loss = 0.01138978855063518
Trained batch 3 in epoch 9, gen_loss = 0.3987768217921257, disc_loss = 0.018515053438022733
Trained batch 4 in epoch 9, gen_loss = 0.4091684281826019, disc_loss = 0.018074692972004414
Trained batch 5 in epoch 9, gen_loss = 0.42307377358277637, disc_loss = 0.018132954370230436
Trained batch 6 in epoch 9, gen_loss = 0.41986915469169617, disc_loss = 0.02032015485955136
Trained batch 7 in epoch 9, gen_loss = 0.41831590607762337, disc_loss = 0.02790393412578851
Trained batch 8 in epoch 9, gen_loss = 0.42298579547140336, disc_loss = 0.037856869503027864
Trained batch 9 in epoch 9, gen_loss = 0.4228111684322357, disc_loss = 0.036784260626882316
Trained batch 10 in epoch 9, gen_loss = 0.4220988235690377, disc_loss = 0.041371036574921825
Trained batch 11 in epoch 9, gen_loss = 0.4240739420056343, disc_loss = 0.0406025597670426
Trained batch 12 in epoch 9, gen_loss = 0.42380030338580793, disc_loss = 0.0385506573634652
Trained batch 13 in epoch 9, gen_loss = 0.43052296127591816, disc_loss = 0.037320625236524005
Trained batch 14 in epoch 9, gen_loss = 0.4272451877593994, disc_loss = 0.043192270087699096
Trained batch 15 in epoch 9, gen_loss = 0.43041975796222687, disc_loss = 0.04706019180594012
Trained batch 16 in epoch 9, gen_loss = 0.42773014482329874, disc_loss = 0.05062465123174822
Trained batch 17 in epoch 9, gen_loss = 0.43410051696830326, disc_loss = 0.06038096728217271
Trained batch 18 in epoch 9, gen_loss = 0.43115114538293137, disc_loss = 0.06323360470368673
Trained batch 19 in epoch 9, gen_loss = 0.42862004041671753, disc_loss = 0.06385535351000726
Trained batch 20 in epoch 9, gen_loss = 0.4263471946829841, disc_loss = 0.061500621028244495
Trained batch 21 in epoch 9, gen_loss = 0.4243442876772447, disc_loss = 0.05949462522667917
Trained batch 22 in epoch 9, gen_loss = 0.4202737121478371, disc_loss = 0.057298106708280415
Trained batch 23 in epoch 9, gen_loss = 0.4180176593363285, disc_loss = 0.056446751773667835
Trained batch 24 in epoch 9, gen_loss = 0.41348792910575866, disc_loss = 0.05646172527223826
Trained batch 25 in epoch 9, gen_loss = 0.41379075554701, disc_loss = 0.05452121396620686
Trained batch 26 in epoch 9, gen_loss = 0.4128301916299043, disc_loss = 0.055275846997068986
Trained batch 27 in epoch 9, gen_loss = 0.40924231495176044, disc_loss = 0.05701634903172297
Trained batch 28 in epoch 9, gen_loss = 0.4100758371682003, disc_loss = 0.05663136254739145
Trained batch 29 in epoch 9, gen_loss = 0.4101387679576874, disc_loss = 0.056107554988314705
Trained batch 30 in epoch 9, gen_loss = 0.4073899830541303, disc_loss = 0.060449158141930255
Trained batch 31 in epoch 9, gen_loss = 0.4096220163628459, disc_loss = 0.06872862033196725
Trained batch 32 in epoch 9, gen_loss = 0.4099913528471282, disc_loss = 0.06721104904444831
Trained batch 33 in epoch 9, gen_loss = 0.4075621015885297, disc_loss = 0.06589065346976414
Trained batch 34 in epoch 9, gen_loss = 0.40527486375399996, disc_loss = 0.0643907432843532
Trained batch 35 in epoch 9, gen_loss = 0.40685679763555527, disc_loss = 0.06319060556900997
Trained batch 36 in epoch 9, gen_loss = 0.40696238665967377, disc_loss = 0.06165687693282962
Trained batch 37 in epoch 9, gen_loss = 0.4052348427082363, disc_loss = 0.06251982063986361
Trained batch 38 in epoch 9, gen_loss = 0.4036657642095517, disc_loss = 0.06274937335640574
Trained batch 39 in epoch 9, gen_loss = 0.40385925248265264, disc_loss = 0.06320055046817288
Trained batch 40 in epoch 9, gen_loss = 0.40485047058361334, disc_loss = 0.0683202503090043
Trained batch 41 in epoch 9, gen_loss = 0.40140679407687413, disc_loss = 0.06824837974272668
Trained batch 42 in epoch 9, gen_loss = 0.4009455179059228, disc_loss = 0.07036459787077336
Trained batch 43 in epoch 9, gen_loss = 0.40188720280473883, disc_loss = 0.07464310589288785
Trained batch 44 in epoch 9, gen_loss = 0.40098042686780294, disc_loss = 0.07349136309284303
Trained batch 45 in epoch 9, gen_loss = 0.4001163185938545, disc_loss = 0.07311590755884738
Trained batch 46 in epoch 9, gen_loss = 0.39911619462865466, disc_loss = 0.07300331565412752
Trained batch 47 in epoch 9, gen_loss = 0.40004727616906166, disc_loss = 0.07463419789564796
Trained batch 48 in epoch 9, gen_loss = 0.39994158975932065, disc_loss = 0.07701055472716689
Trained batch 49 in epoch 9, gen_loss = 0.4017717748880386, disc_loss = 0.08120444516651332
Trained batch 50 in epoch 9, gen_loss = 0.40330374182439316, disc_loss = 0.08027910319723043
Trained batch 51 in epoch 9, gen_loss = 0.40244471167142576, disc_loss = 0.0805653155548498
Trained batch 52 in epoch 9, gen_loss = 0.40272209666809944, disc_loss = 0.07964057091377535
Trained batch 53 in epoch 9, gen_loss = 0.4029331659829175, disc_loss = 0.07869369835868754
Trained batch 54 in epoch 9, gen_loss = 0.4018805856054479, disc_loss = 0.07767283905466849
Trained batch 55 in epoch 9, gen_loss = 0.4017322925584657, disc_loss = 0.07676309469388798
Trained batch 56 in epoch 9, gen_loss = 0.40169557876754225, disc_loss = 0.07629637625231817
Trained batch 57 in epoch 9, gen_loss = 0.40174039222043134, disc_loss = 0.07735684201731508
Trained batch 58 in epoch 9, gen_loss = 0.4021996380919117, disc_loss = 0.0786697194848399
Trained batch 59 in epoch 9, gen_loss = 0.40278122425079343, disc_loss = 0.07773682359450808
Trained batch 60 in epoch 9, gen_loss = 0.4021122890417693, disc_loss = 0.0769888463307966
Trained batch 61 in epoch 9, gen_loss = 0.4032621705724347, disc_loss = 0.07610346111769398
Trained batch 62 in epoch 9, gen_loss = 0.40328285145381143, disc_loss = 0.07515901932492852
Trained batch 63 in epoch 9, gen_loss = 0.4049995858222246, disc_loss = 0.07409340414596954
Trained batch 64 in epoch 9, gen_loss = 0.40391256121488717, disc_loss = 0.07319107446103142
Trained batch 65 in epoch 9, gen_loss = 0.4025550994909171, disc_loss = 0.07268827341525166
Trained batch 66 in epoch 9, gen_loss = 0.40293907985758426, disc_loss = 0.07177669868401404
Trained batch 67 in epoch 9, gen_loss = 0.40316226508687525, disc_loss = 0.07197899187175448
Trained batch 68 in epoch 9, gen_loss = 0.4026517064675041, disc_loss = 0.07185255165846235
Trained batch 69 in epoch 9, gen_loss = 0.4024264923163823, disc_loss = 0.07116789053460316
Trained batch 70 in epoch 9, gen_loss = 0.4022117395636062, disc_loss = 0.07071380319178734
Trained batch 71 in epoch 9, gen_loss = 0.402967869821522, disc_loss = 0.07275435475296238
Trained batch 72 in epoch 9, gen_loss = 0.40169718902404994, disc_loss = 0.07273553027962781
Trained batch 73 in epoch 9, gen_loss = 0.40239670872688293, disc_loss = 0.0724713746143656
Trained batch 74 in epoch 9, gen_loss = 0.4034987938404083, disc_loss = 0.07242247215782603
Trained batch 75 in epoch 9, gen_loss = 0.4030659983032628, disc_loss = 0.07201937440856311
Trained batch 76 in epoch 9, gen_loss = 0.40350552038712934, disc_loss = 0.07168639046684294
Trained batch 77 in epoch 9, gen_loss = 0.405272282851048, disc_loss = 0.07259039420228547
Trained batch 78 in epoch 9, gen_loss = 0.4048324691343911, disc_loss = 0.07215083807211699
Trained batch 79 in epoch 9, gen_loss = 0.4039035998284817, disc_loss = 0.07230867894249968
Trained batch 80 in epoch 9, gen_loss = 0.40414854185080823, disc_loss = 0.07278983554239442
Trained batch 81 in epoch 9, gen_loss = 0.40342900556762046, disc_loss = 0.07359003677123749
Trained batch 82 in epoch 9, gen_loss = 0.4047394161482891, disc_loss = 0.07346223422090511
Trained batch 83 in epoch 9, gen_loss = 0.4046067233596529, disc_loss = 0.07428131839593075
Trained batch 84 in epoch 9, gen_loss = 0.4036680754493265, disc_loss = 0.07476536659523844
Trained batch 85 in epoch 9, gen_loss = 0.40352106683476024, disc_loss = 0.07411628811576859
Trained batch 86 in epoch 9, gen_loss = 0.40366741706585063, disc_loss = 0.0734332026324995
Trained batch 87 in epoch 9, gen_loss = 0.4039134396748109, disc_loss = 0.07270263145487248
Trained batch 88 in epoch 9, gen_loss = 0.40385815501213074, disc_loss = 0.07207897564479976
Trained batch 89 in epoch 9, gen_loss = 0.4033696085214615, disc_loss = 0.07167912389979594
Trained batch 90 in epoch 9, gen_loss = 0.4044915552322681, disc_loss = 0.07320655063101715
Trained batch 91 in epoch 9, gen_loss = 0.404440313577652, disc_loss = 0.0756465716479832
Trained batch 92 in epoch 9, gen_loss = 0.40556000509569723, disc_loss = 0.07607708318078871
Trained batch 93 in epoch 9, gen_loss = 0.4056462601144263, disc_loss = 0.07542208995808788
Trained batch 94 in epoch 9, gen_loss = 0.4050447664762798, disc_loss = 0.07509644887851256
Trained batch 95 in epoch 9, gen_loss = 0.40488270825395983, disc_loss = 0.0749697149876738
Trained batch 96 in epoch 9, gen_loss = 0.4035242866609514, disc_loss = 0.07454394035943851
Trained batch 97 in epoch 9, gen_loss = 0.4030599417735119, disc_loss = 0.0740249061871472
Trained batch 98 in epoch 9, gen_loss = 0.4035012980904242, disc_loss = 0.07380311092775729
Trained batch 99 in epoch 9, gen_loss = 0.4032930243015289, disc_loss = 0.07324674423318356
Trained batch 100 in epoch 9, gen_loss = 0.4023989167543921, disc_loss = 0.07432333132399634
Trained batch 101 in epoch 9, gen_loss = 0.402486426280994, disc_loss = 0.07611484032617334
Trained batch 102 in epoch 9, gen_loss = 0.4027791396506782, disc_loss = 0.07561472558769063
Trained batch 103 in epoch 9, gen_loss = 0.40313415974378586, disc_loss = 0.07531933025725615
Trained batch 104 in epoch 9, gen_loss = 0.4023870757647923, disc_loss = 0.07515032079869083
Trained batch 105 in epoch 9, gen_loss = 0.40248101752883986, disc_loss = 0.07482708970805244
Trained batch 106 in epoch 9, gen_loss = 0.4030741542299217, disc_loss = 0.07421345899543055
Trained batch 107 in epoch 9, gen_loss = 0.403531443465639, disc_loss = 0.07389385000095461
Trained batch 108 in epoch 9, gen_loss = 0.4034876301201112, disc_loss = 0.07386625505590794
Trained batch 109 in epoch 9, gen_loss = 0.40334335592660037, disc_loss = 0.07336403350345791
Trained batch 110 in epoch 9, gen_loss = 0.40354219803938995, disc_loss = 0.07279698588876976
Trained batch 111 in epoch 9, gen_loss = 0.4029281871127231, disc_loss = 0.07235073372638519
Trained batch 112 in epoch 9, gen_loss = 0.40229306495295164, disc_loss = 0.07213645268116245
Trained batch 113 in epoch 9, gen_loss = 0.40211703249236996, disc_loss = 0.07226413747769568
Trained batch 114 in epoch 9, gen_loss = 0.40142204113628555, disc_loss = 0.0729892174632329
Trained batch 115 in epoch 9, gen_loss = 0.40230988094518927, disc_loss = 0.07321116750144624
Trained batch 116 in epoch 9, gen_loss = 0.40218551062111163, disc_loss = 0.07271365583754885
Trained batch 117 in epoch 9, gen_loss = 0.4018787789647862, disc_loss = 0.07253401512990437
Trained batch 118 in epoch 9, gen_loss = 0.4019996348549338, disc_loss = 0.07201148746848232
Trained batch 119 in epoch 9, gen_loss = 0.40195784668127693, disc_loss = 0.07175942841374004
Trained batch 120 in epoch 9, gen_loss = 0.40157015264526874, disc_loss = 0.07128647764498168
Trained batch 121 in epoch 9, gen_loss = 0.4016411534098328, disc_loss = 0.07091004505646645
Trained batch 122 in epoch 9, gen_loss = 0.4022013050753896, disc_loss = 0.07059866468974851
Trained batch 123 in epoch 9, gen_loss = 0.4021685524813591, disc_loss = 0.07068915407158315
Trained batch 124 in epoch 9, gen_loss = 0.40139187169075013, disc_loss = 0.07155419916287065
Trained batch 125 in epoch 9, gen_loss = 0.401512729506644, disc_loss = 0.07160432134488863
Trained batch 126 in epoch 9, gen_loss = 0.4019249496966835, disc_loss = 0.0714327793634372
Trained batch 127 in epoch 9, gen_loss = 0.401839206693694, disc_loss = 0.07121615231517353
Trained batch 128 in epoch 9, gen_loss = 0.4011811440767244, disc_loss = 0.07094803750298398
Trained batch 129 in epoch 9, gen_loss = 0.40108568553741164, disc_loss = 0.07090359012453029
Trained batch 130 in epoch 9, gen_loss = 0.40106256340296215, disc_loss = 0.07044061777032627
Trained batch 131 in epoch 9, gen_loss = 0.40130906890739093, disc_loss = 0.07010255532804877
Trained batch 132 in epoch 9, gen_loss = 0.40112273495896417, disc_loss = 0.07024357091509421
Trained batch 133 in epoch 9, gen_loss = 0.4009400265875147, disc_loss = 0.0717946367595456
Trained batch 134 in epoch 9, gen_loss = 0.4013469539306782, disc_loss = 0.0730588192085701
Trained batch 135 in epoch 9, gen_loss = 0.40127257433007746, disc_loss = 0.07287495341220432
Trained batch 136 in epoch 9, gen_loss = 0.40092817318700524, disc_loss = 0.07294202344763996
Trained batch 137 in epoch 9, gen_loss = 0.4007240330827409, disc_loss = 0.07280806356541597
Trained batch 138 in epoch 9, gen_loss = 0.40038980468571617, disc_loss = 0.07280191973776376
Trained batch 139 in epoch 9, gen_loss = 0.40047691570861, disc_loss = 0.07253626836796424
Trained batch 140 in epoch 9, gen_loss = 0.39987205634725853, disc_loss = 0.0731824945744312
Trained batch 141 in epoch 9, gen_loss = 0.39962063813713233, disc_loss = 0.07439057053145494
Trained batch 142 in epoch 9, gen_loss = 0.3993796497791797, disc_loss = 0.07416786869883642
Trained batch 143 in epoch 9, gen_loss = 0.3992759941352738, disc_loss = 0.07406935651023458
Trained batch 144 in epoch 9, gen_loss = 0.39810667264050453, disc_loss = 0.07595295059847934
Trained batch 145 in epoch 9, gen_loss = 0.39861317979146355, disc_loss = 0.07654836790776517
Trained batch 146 in epoch 9, gen_loss = 0.39886085841120505, disc_loss = 0.07636174054334866
Trained batch 147 in epoch 9, gen_loss = 0.39946250134223216, disc_loss = 0.0769154331930032
Trained batch 148 in epoch 9, gen_loss = 0.39949473198628266, disc_loss = 0.07694634971765164
Trained batch 149 in epoch 9, gen_loss = 0.39933976491292317, disc_loss = 0.07772390382053951
Trained batch 150 in epoch 9, gen_loss = 0.3991230343351301, disc_loss = 0.0786558201826418
Trained batch 151 in epoch 9, gen_loss = 0.3993291266654667, disc_loss = 0.07838249413946055
Trained batch 152 in epoch 9, gen_loss = 0.3990533885612986, disc_loss = 0.07839615128362198
Trained batch 153 in epoch 9, gen_loss = 0.39904088691457523, disc_loss = 0.07809696280300714
Trained batch 154 in epoch 9, gen_loss = 0.3986729814160255, disc_loss = 0.07783223204615135
Trained batch 155 in epoch 9, gen_loss = 0.39801186800767213, disc_loss = 0.07777129855448714
Trained batch 156 in epoch 9, gen_loss = 0.39851761262887603, disc_loss = 0.07793705347201722
Trained batch 157 in epoch 9, gen_loss = 0.3983960642090327, disc_loss = 0.07908262823166066
Trained batch 158 in epoch 9, gen_loss = 0.3983478846040162, disc_loss = 0.07898318455056669
Trained batch 159 in epoch 9, gen_loss = 0.3986971560865641, disc_loss = 0.07903467199357692
Trained batch 160 in epoch 9, gen_loss = 0.39812108411552005, disc_loss = 0.08005303520743984
Trained batch 161 in epoch 9, gen_loss = 0.39852903838510867, disc_loss = 0.07980867467510204
Trained batch 162 in epoch 9, gen_loss = 0.39890033957417026, disc_loss = 0.07951448054732813
Trained batch 163 in epoch 9, gen_loss = 0.3988466261000168, disc_loss = 0.07920479864484017
Trained batch 164 in epoch 9, gen_loss = 0.39911547194827685, disc_loss = 0.078908112760859
Trained batch 165 in epoch 9, gen_loss = 0.3991392831127328, disc_loss = 0.0784743897033384
Trained batch 166 in epoch 9, gen_loss = 0.39932974512705544, disc_loss = 0.07810245351698585
Trained batch 167 in epoch 9, gen_loss = 0.39998605102300644, disc_loss = 0.07786471028590486
Trained batch 168 in epoch 9, gen_loss = 0.400277647393695, disc_loss = 0.07755769958951064
Trained batch 169 in epoch 9, gen_loss = 0.40042421256794647, disc_loss = 0.07727557027383762
Trained batch 170 in epoch 9, gen_loss = 0.40027430479289494, disc_loss = 0.0769500438428936
Trained batch 171 in epoch 9, gen_loss = 0.4005157145303349, disc_loss = 0.07664298976576606
Trained batch 172 in epoch 9, gen_loss = 0.4001163297650442, disc_loss = 0.07687618505920289
Trained batch 173 in epoch 9, gen_loss = 0.4005803977963568, disc_loss = 0.07762516080134216
Trained batch 174 in epoch 9, gen_loss = 0.40048852034977506, disc_loss = 0.07741277611681394
Trained batch 175 in epoch 9, gen_loss = 0.400092242624272, disc_loss = 0.07700604586121203
Trained batch 176 in epoch 9, gen_loss = 0.3997530740196422, disc_loss = 0.07679292795874473
Trained batch 177 in epoch 9, gen_loss = 0.40003739012761064, disc_loss = 0.07649456554228502
Trained batch 178 in epoch 9, gen_loss = 0.39980827130418917, disc_loss = 0.07616896684380384
Trained batch 179 in epoch 9, gen_loss = 0.39921413792504207, disc_loss = 0.07612764672376215
Trained batch 180 in epoch 9, gen_loss = 0.3989722732022322, disc_loss = 0.07833659947844665
Trained batch 181 in epoch 9, gen_loss = 0.3992601344873617, disc_loss = 0.07805422545605145
Trained batch 182 in epoch 9, gen_loss = 0.39949168240437744, disc_loss = 0.07792297438743824
Trained batch 183 in epoch 9, gen_loss = 0.3991914260322633, disc_loss = 0.07788455807705126
Trained batch 184 in epoch 9, gen_loss = 0.3987702274644697, disc_loss = 0.07798863151488272
Trained batch 185 in epoch 9, gen_loss = 0.39931827383015744, disc_loss = 0.07802427737843445
Trained batch 186 in epoch 9, gen_loss = 0.3994917576325768, disc_loss = 0.07771555207331073
Trained batch 187 in epoch 9, gen_loss = 0.3996999839201887, disc_loss = 0.07754332943264633
Trained batch 188 in epoch 9, gen_loss = 0.39989318213765584, disc_loss = 0.07728842259064396
Trained batch 189 in epoch 9, gen_loss = 0.3999695489281102, disc_loss = 0.07707037666420403
Trained batch 190 in epoch 9, gen_loss = 0.40047917035237657, disc_loss = 0.0767230492875136
Trained batch 191 in epoch 9, gen_loss = 0.40008307667449117, disc_loss = 0.07648009876235544
Trained batch 192 in epoch 9, gen_loss = 0.40030361688816485, disc_loss = 0.07611413056349353
Trained batch 193 in epoch 9, gen_loss = 0.4004433291781809, disc_loss = 0.07587561402565886
Trained batch 194 in epoch 9, gen_loss = 0.4009879281887641, disc_loss = 0.07551318540070684
Trained batch 195 in epoch 9, gen_loss = 0.4009384389738647, disc_loss = 0.07522051178194507
Trained batch 196 in epoch 9, gen_loss = 0.4008725485220778, disc_loss = 0.07487677266764535
Trained batch 197 in epoch 9, gen_loss = 0.40081285873446804, disc_loss = 0.07463162828170967
Trained batch 198 in epoch 9, gen_loss = 0.4007051976481874, disc_loss = 0.0743119896754585
Trained batch 199 in epoch 9, gen_loss = 0.4007719898223877, disc_loss = 0.07427396107697859
Trained batch 200 in epoch 9, gen_loss = 0.4009041027050113, disc_loss = 0.07393191982551817
Trained batch 201 in epoch 9, gen_loss = 0.4012175897265425, disc_loss = 0.07379031981489077
Trained batch 202 in epoch 9, gen_loss = 0.4008559050231144, disc_loss = 0.07349454470006336
Trained batch 203 in epoch 9, gen_loss = 0.4008593291920774, disc_loss = 0.07321685785199424
Trained batch 204 in epoch 9, gen_loss = 0.40087698450902615, disc_loss = 0.07293946369346685
Trained batch 205 in epoch 9, gen_loss = 0.40101182909266464, disc_loss = 0.07283127876405504
Trained batch 206 in epoch 9, gen_loss = 0.40109139536889854, disc_loss = 0.07262409140765307
Trained batch 207 in epoch 9, gen_loss = 0.40111979856514013, disc_loss = 0.07231706669867541
Trained batch 208 in epoch 9, gen_loss = 0.40144937132534225, disc_loss = 0.07201906999252274
Trained batch 209 in epoch 9, gen_loss = 0.40131153279826753, disc_loss = 0.07181867414952389
Trained batch 210 in epoch 9, gen_loss = 0.4015895248306871, disc_loss = 0.07255785460959042
Trained batch 211 in epoch 9, gen_loss = 0.40169682438081167, disc_loss = 0.07341342198636101
Trained batch 212 in epoch 9, gen_loss = 0.40189227084038964, disc_loss = 0.07333646958449007
Trained batch 213 in epoch 9, gen_loss = 0.40194486151231784, disc_loss = 0.07328597664023602
Trained batch 214 in epoch 9, gen_loss = 0.401535078398017, disc_loss = 0.0735045604819302
Trained batch 215 in epoch 9, gen_loss = 0.4018862814539009, disc_loss = 0.07328720878663093
Trained batch 216 in epoch 9, gen_loss = 0.4016135034198585, disc_loss = 0.07316036015740394
Trained batch 217 in epoch 9, gen_loss = 0.4015715856344328, disc_loss = 0.07329227605945679
Trained batch 218 in epoch 9, gen_loss = 0.40128606380937304, disc_loss = 0.07402155594049728
Trained batch 219 in epoch 9, gen_loss = 0.40139902383089066, disc_loss = 0.07453339541627263
Trained batch 220 in epoch 9, gen_loss = 0.4014331002580634, disc_loss = 0.07449226180614052
Trained batch 221 in epoch 9, gen_loss = 0.40123318323680945, disc_loss = 0.07443423154512169
Trained batch 222 in epoch 9, gen_loss = 0.4006618767843118, disc_loss = 0.07423575832028226
Trained batch 223 in epoch 9, gen_loss = 0.4009665007303868, disc_loss = 0.07406146790890489
Trained batch 224 in epoch 9, gen_loss = 0.4008727779653337, disc_loss = 0.07543984618244899
Trained batch 225 in epoch 9, gen_loss = 0.4012643883449841, disc_loss = 0.07640231070850473
Trained batch 226 in epoch 9, gen_loss = 0.40135886516865127, disc_loss = 0.07637241580995366
Trained batch 227 in epoch 9, gen_loss = 0.4008761401239194, disc_loss = 0.0767682026070951
Trained batch 228 in epoch 9, gen_loss = 0.40065622329711914, disc_loss = 0.07683229202193138
Trained batch 229 in epoch 9, gen_loss = 0.4005759780821593, disc_loss = 0.07661471447664435
Trained batch 230 in epoch 9, gen_loss = 0.4001035570324241, disc_loss = 0.07658640617601477
Trained batch 231 in epoch 9, gen_loss = 0.39988539072460144, disc_loss = 0.0764769931657015
Trained batch 232 in epoch 9, gen_loss = 0.3996434537893713, disc_loss = 0.07636526986245114
Trained batch 233 in epoch 9, gen_loss = 0.3999326380654278, disc_loss = 0.07632065976524137
Trained batch 234 in epoch 9, gen_loss = 0.3996467667691251, disc_loss = 0.07609521320803052
Trained batch 235 in epoch 9, gen_loss = 0.3996518510630575, disc_loss = 0.07631022412669293
Trained batch 236 in epoch 9, gen_loss = 0.3993808007189996, disc_loss = 0.0760822004780079
Trained batch 237 in epoch 9, gen_loss = 0.39945852718934294, disc_loss = 0.07580744569628116
Trained batch 238 in epoch 9, gen_loss = 0.39918674971269263, disc_loss = 0.07567183399635316
Trained batch 239 in epoch 9, gen_loss = 0.39916553571820257, disc_loss = 0.0756631509148671
Trained batch 240 in epoch 9, gen_loss = 0.39892783748658367, disc_loss = 0.07565588195502944
Trained batch 241 in epoch 9, gen_loss = 0.3987748707867851, disc_loss = 0.07580243805923677
Trained batch 242 in epoch 9, gen_loss = 0.39902354108453286, disc_loss = 0.0756133454583524
Trained batch 243 in epoch 9, gen_loss = 0.39918586025472547, disc_loss = 0.07558871113855514
Trained batch 244 in epoch 9, gen_loss = 0.39985161533161084, disc_loss = 0.07661042254304096
Trained batch 245 in epoch 9, gen_loss = 0.399507356126134, disc_loss = 0.07657740196796149
Trained batch 246 in epoch 9, gen_loss = 0.39941166504191966, disc_loss = 0.07634815815572253
Trained batch 247 in epoch 9, gen_loss = 0.3993994198258846, disc_loss = 0.07608112550693594
Trained batch 248 in epoch 9, gen_loss = 0.39953758797971123, disc_loss = 0.07608052895752242
Trained batch 249 in epoch 9, gen_loss = 0.3992066056728363, disc_loss = 0.07621719463728369
Trained batch 250 in epoch 9, gen_loss = 0.39914968562316133, disc_loss = 0.07604511915353605
Trained batch 251 in epoch 9, gen_loss = 0.39895221318990465, disc_loss = 0.0759222221778824
Trained batch 252 in epoch 9, gen_loss = 0.3989124983666914, disc_loss = 0.07568688474764879
Trained batch 253 in epoch 9, gen_loss = 0.3989345311649202, disc_loss = 0.07567891345623382
Trained batch 254 in epoch 9, gen_loss = 0.39865939161356756, disc_loss = 0.07635408384798496
Trained batch 255 in epoch 9, gen_loss = 0.3990960455266759, disc_loss = 0.07668081643896585
Trained batch 256 in epoch 9, gen_loss = 0.3991144819018442, disc_loss = 0.07684256584865516
Trained batch 257 in epoch 9, gen_loss = 0.3989766642104748, disc_loss = 0.07695576102949332
Trained batch 258 in epoch 9, gen_loss = 0.39902723261288237, disc_loss = 0.07709437527273094
Trained batch 259 in epoch 9, gen_loss = 0.3993014137332256, disc_loss = 0.07709139375410114
Trained batch 260 in epoch 9, gen_loss = 0.399358281116376, disc_loss = 0.07687685733404138
Trained batch 261 in epoch 9, gen_loss = 0.39947755157037546, disc_loss = 0.07682580558249001
Trained batch 262 in epoch 9, gen_loss = 0.3994576711165134, disc_loss = 0.07747448941678545
Trained batch 263 in epoch 9, gen_loss = 0.3997955202604785, disc_loss = 0.07792945517135333
Trained batch 264 in epoch 9, gen_loss = 0.40012964280146474, disc_loss = 0.077825520052311
Trained batch 265 in epoch 9, gen_loss = 0.4002094496237604, disc_loss = 0.07777022463059459
Trained batch 266 in epoch 9, gen_loss = 0.4002566518408529, disc_loss = 0.07777453974859043
Trained batch 267 in epoch 9, gen_loss = 0.4003725418848778, disc_loss = 0.07766192566791076
Trained batch 268 in epoch 9, gen_loss = 0.4001918755277825, disc_loss = 0.07752293267124592
Trained batch 269 in epoch 9, gen_loss = 0.4005077949276677, disc_loss = 0.07756496451760608
Trained batch 270 in epoch 9, gen_loss = 0.40020040293461284, disc_loss = 0.07759191801537832
Trained batch 271 in epoch 9, gen_loss = 0.40074500912690864, disc_loss = 0.07740006036885247
Trained batch 272 in epoch 9, gen_loss = 0.400835279580001, disc_loss = 0.07721744991340862
Trained batch 273 in epoch 9, gen_loss = 0.4007505005511054, disc_loss = 0.07721156760689932
Trained batch 274 in epoch 9, gen_loss = 0.4006899681958285, disc_loss = 0.07726713806898756
Trained batch 275 in epoch 9, gen_loss = 0.40049417165742407, disc_loss = 0.07706542018011374
Trained batch 276 in epoch 9, gen_loss = 0.40027470450969377, disc_loss = 0.07688899287644653
Trained batch 277 in epoch 9, gen_loss = 0.399997869412676, disc_loss = 0.0769211294836358
Trained batch 278 in epoch 9, gen_loss = 0.40020093717028166, disc_loss = 0.07771366116787744
Trained batch 279 in epoch 9, gen_loss = 0.3999819052006517, disc_loss = 0.07779804314320375
Trained batch 280 in epoch 9, gen_loss = 0.3997594229479277, disc_loss = 0.077745963356978
Trained batch 281 in epoch 9, gen_loss = 0.39959681921816886, disc_loss = 0.07774042304281595
Trained batch 282 in epoch 9, gen_loss = 0.3994372908302415, disc_loss = 0.07757574326256718
Trained batch 283 in epoch 9, gen_loss = 0.3994978969575654, disc_loss = 0.07734722921683808
Trained batch 284 in epoch 9, gen_loss = 0.39948454927979854, disc_loss = 0.07719875445524067
Trained batch 285 in epoch 9, gen_loss = 0.39934215741557677, disc_loss = 0.07732527434233237
Trained batch 286 in epoch 9, gen_loss = 0.39943283422483383, disc_loss = 0.0774667977407341
Trained batch 287 in epoch 9, gen_loss = 0.39897318225767875, disc_loss = 0.07796031184423352
Trained batch 288 in epoch 9, gen_loss = 0.39894335162680866, disc_loss = 0.07857877005271897
Trained batch 289 in epoch 9, gen_loss = 0.3989697242605275, disc_loss = 0.0783895637021111
Trained batch 290 in epoch 9, gen_loss = 0.39887326238900933, disc_loss = 0.07815773259125061
Trained batch 291 in epoch 9, gen_loss = 0.3989154322914881, disc_loss = 0.07794175109003147
Trained batch 292 in epoch 9, gen_loss = 0.39896851493230046, disc_loss = 0.07775382161833372
Trained batch 293 in epoch 9, gen_loss = 0.39891490978854044, disc_loss = 0.07769592022238185
Trained batch 294 in epoch 9, gen_loss = 0.3990314455355628, disc_loss = 0.07782858993573967
Trained batch 295 in epoch 9, gen_loss = 0.3991681550805633, disc_loss = 0.07795973572206709
Trained batch 296 in epoch 9, gen_loss = 0.39900352015639795, disc_loss = 0.07801714983082028
Trained batch 297 in epoch 9, gen_loss = 0.39959214057698345, disc_loss = 0.07806158800384393
Trained batch 298 in epoch 9, gen_loss = 0.39950093367825384, disc_loss = 0.07786203492401685
Trained batch 299 in epoch 9, gen_loss = 0.39965565969546635, disc_loss = 0.07772063873863469
Trained batch 300 in epoch 9, gen_loss = 0.39987978527316226, disc_loss = 0.07760853784629128
Trained batch 301 in epoch 9, gen_loss = 0.400244572304732, disc_loss = 0.07773730347691635
Trained batch 302 in epoch 9, gen_loss = 0.39986114759649777, disc_loss = 0.07802513110368411
Trained batch 303 in epoch 9, gen_loss = 0.4000349094797122, disc_loss = 0.07807122272788547
Trained batch 304 in epoch 9, gen_loss = 0.40008660623284636, disc_loss = 0.07795759252745842
Trained batch 305 in epoch 9, gen_loss = 0.400053043186275, disc_loss = 0.07793222055040008
Trained batch 306 in epoch 9, gen_loss = 0.4000983249869331, disc_loss = 0.07774503681511415
Trained batch 307 in epoch 9, gen_loss = 0.40025663046867815, disc_loss = 0.07753504148545348
Trained batch 308 in epoch 9, gen_loss = 0.4002296116359797, disc_loss = 0.07733663513768212
Trained batch 309 in epoch 9, gen_loss = 0.40010862052440643, disc_loss = 0.07720422708549567
Trained batch 310 in epoch 9, gen_loss = 0.40001913742237155, disc_loss = 0.07724199285790612
Trained batch 311 in epoch 9, gen_loss = 0.39993833664518136, disc_loss = 0.07808936274914931
Trained batch 312 in epoch 9, gen_loss = 0.39994177955408067, disc_loss = 0.0780379767053591
Trained batch 313 in epoch 9, gen_loss = 0.40001077902544835, disc_loss = 0.07807235582138465
Trained batch 314 in epoch 9, gen_loss = 0.4001097750096094, disc_loss = 0.07809942181236924
Trained batch 315 in epoch 9, gen_loss = 0.4002879137479806, disc_loss = 0.07795543545308889
Trained batch 316 in epoch 9, gen_loss = 0.40019112844196403, disc_loss = 0.07818775796639947
Trained batch 317 in epoch 9, gen_loss = 0.4002450277220528, disc_loss = 0.07804386572965052
Trained batch 318 in epoch 9, gen_loss = 0.4002481009519212, disc_loss = 0.07787684533820957
Trained batch 319 in epoch 9, gen_loss = 0.4002585711888969, disc_loss = 0.07771221514994978
Trained batch 320 in epoch 9, gen_loss = 0.4003848016633423, disc_loss = 0.07763940726502616
Trained batch 321 in epoch 9, gen_loss = 0.40053090999215285, disc_loss = 0.07757224225126762
Trained batch 322 in epoch 9, gen_loss = 0.40052371045384244, disc_loss = 0.0773796962455907
Trained batch 323 in epoch 9, gen_loss = 0.4004138521390197, disc_loss = 0.07716442022708325
Trained batch 324 in epoch 9, gen_loss = 0.4003391321805807, disc_loss = 0.07706000374056972
Trained batch 325 in epoch 9, gen_loss = 0.4003286571041938, disc_loss = 0.07698862700426003
Trained batch 326 in epoch 9, gen_loss = 0.39997288183699325, disc_loss = 0.07695789849499543
Trained batch 327 in epoch 9, gen_loss = 0.4003302599417, disc_loss = 0.07683778154555844
Trained batch 328 in epoch 9, gen_loss = 0.4003320622589088, disc_loss = 0.07669908849601732
Trained batch 329 in epoch 9, gen_loss = 0.4000355678977388, disc_loss = 0.07685614471662451
Trained batch 330 in epoch 9, gen_loss = 0.400084321772584, disc_loss = 0.0768202526784668
Trained batch 331 in epoch 9, gen_loss = 0.3998941837484578, disc_loss = 0.07692756285717015
Trained batch 332 in epoch 9, gen_loss = 0.3996791771582297, disc_loss = 0.07728930061134894
Trained batch 333 in epoch 9, gen_loss = 0.399888197818916, disc_loss = 0.07720435385781893
Trained batch 334 in epoch 9, gen_loss = 0.39994473768703975, disc_loss = 0.07709771648966776
Trained batch 335 in epoch 9, gen_loss = 0.39981592703788055, disc_loss = 0.0769002418258294
Trained batch 336 in epoch 9, gen_loss = 0.3999465601380572, disc_loss = 0.07672944033341565
Trained batch 337 in epoch 9, gen_loss = 0.39978218272592897, disc_loss = 0.07658176160604864
Trained batch 338 in epoch 9, gen_loss = 0.39995559285172316, disc_loss = 0.07638257647284848
Trained batch 339 in epoch 9, gen_loss = 0.3999721215051763, disc_loss = 0.07617782476659427
Trained batch 340 in epoch 9, gen_loss = 0.40002601045317665, disc_loss = 0.07598789592199792
Trained batch 341 in epoch 9, gen_loss = 0.39990798170455016, disc_loss = 0.07592012178648416
Trained batch 342 in epoch 9, gen_loss = 0.3997715962697744, disc_loss = 0.07634248589803587
Trained batch 343 in epoch 9, gen_loss = 0.399518255317627, disc_loss = 0.07751329354589892
Trained batch 344 in epoch 9, gen_loss = 0.3994182606538137, disc_loss = 0.07760478654282464
Trained batch 345 in epoch 9, gen_loss = 0.39957919380912893, disc_loss = 0.0779029087316934
Trained batch 346 in epoch 9, gen_loss = 0.399619837573351, disc_loss = 0.07775075496268333
Trained batch 347 in epoch 9, gen_loss = 0.39960598782903844, disc_loss = 0.07772565946577052
Trained batch 348 in epoch 9, gen_loss = 0.3996470376721084, disc_loss = 0.07787453130095727
Trained batch 349 in epoch 9, gen_loss = 0.3996142286062241, disc_loss = 0.07804797880218498
Trained batch 350 in epoch 9, gen_loss = 0.3995228184763862, disc_loss = 0.07786505793929736
Trained batch 351 in epoch 9, gen_loss = 0.39964354266835883, disc_loss = 0.07798977496118327
Trained batch 352 in epoch 9, gen_loss = 0.39933100612913247, disc_loss = 0.07790598626150921
Trained batch 353 in epoch 9, gen_loss = 0.3992621860766815, disc_loss = 0.07792848128020384
Trained batch 354 in epoch 9, gen_loss = 0.39934552899548703, disc_loss = 0.07778200610396518
Trained batch 355 in epoch 9, gen_loss = 0.39954368954294184, disc_loss = 0.07759397915234852
Trained batch 356 in epoch 9, gen_loss = 0.39951203333563495, disc_loss = 0.07740163784187172
Trained batch 357 in epoch 9, gen_loss = 0.399633728425596, disc_loss = 0.07732328823403398
Trained batch 358 in epoch 9, gen_loss = 0.39967762842815896, disc_loss = 0.07741996970593223
Trained batch 359 in epoch 9, gen_loss = 0.399618930535184, disc_loss = 0.0774948455276899
Trained batch 360 in epoch 9, gen_loss = 0.3997833744475716, disc_loss = 0.07734495881619835
Trained batch 361 in epoch 9, gen_loss = 0.3997122503775918, disc_loss = 0.07729907868332256
Trained batch 362 in epoch 9, gen_loss = 0.39999719822045526, disc_loss = 0.07779435028729975
Trained batch 363 in epoch 9, gen_loss = 0.3998355303000618, disc_loss = 0.07763592080996054
Trained batch 364 in epoch 9, gen_loss = 0.39957136446482516, disc_loss = 0.0776625854396963
Trained batch 365 in epoch 9, gen_loss = 0.3996840376671546, disc_loss = 0.07748882807765788
Trained batch 366 in epoch 9, gen_loss = 0.3997030269547444, disc_loss = 0.07744909008223898
Trained batch 367 in epoch 9, gen_loss = 0.39983167029593303, disc_loss = 0.07726919751123364
Trained batch 368 in epoch 9, gen_loss = 0.3997102488831776, disc_loss = 0.07744553538675351
Trained batch 369 in epoch 9, gen_loss = 0.39988506194707507, disc_loss = 0.07757010458767213
Trained batch 370 in epoch 9, gen_loss = 0.39985649701398657, disc_loss = 0.07794257366748632
Trained batch 371 in epoch 9, gen_loss = 0.3999179366134828, disc_loss = 0.07896133170648408
Trained batch 372 in epoch 9, gen_loss = 0.39966777917846597, disc_loss = 0.07912190900566231
Trained batch 373 in epoch 9, gen_loss = 0.3996090554298564, disc_loss = 0.07907104050805344
Trained batch 374 in epoch 9, gen_loss = 0.3996459134419759, disc_loss = 0.07890479735905925
Trained batch 375 in epoch 9, gen_loss = 0.39955555330565634, disc_loss = 0.07877696156774232
Trained batch 376 in epoch 9, gen_loss = 0.3996041304078595, disc_loss = 0.0786613528690837
Trained batch 377 in epoch 9, gen_loss = 0.3993903859740212, disc_loss = 0.0786025559408935
Trained batch 378 in epoch 9, gen_loss = 0.3993518214112536, disc_loss = 0.07851824769750237
Trained batch 379 in epoch 9, gen_loss = 0.39943676394851585, disc_loss = 0.07859086990233903
Trained batch 380 in epoch 9, gen_loss = 0.39935252805707333, disc_loss = 0.07850316242043545
Trained batch 381 in epoch 9, gen_loss = 0.3993663302578851, disc_loss = 0.07842510348522343
Trained batch 382 in epoch 9, gen_loss = 0.39965033609001815, disc_loss = 0.07838506435284844
Trained batch 383 in epoch 9, gen_loss = 0.39972157271889347, disc_loss = 0.07821407388231212
Trained batch 384 in epoch 9, gen_loss = 0.39964522402007857, disc_loss = 0.07807295973497358
Trained batch 385 in epoch 9, gen_loss = 0.3995809845356126, disc_loss = 0.0779859762086287
Trained batch 386 in epoch 9, gen_loss = 0.39953036979803436, disc_loss = 0.07790634538424838
Trained batch 387 in epoch 9, gen_loss = 0.3997183353784158, disc_loss = 0.07783869518442367
Trained batch 388 in epoch 9, gen_loss = 0.40002239217794955, disc_loss = 0.07782082453939901
Trained batch 389 in epoch 9, gen_loss = 0.39981615444024404, disc_loss = 0.07780607845992422
Trained batch 390 in epoch 9, gen_loss = 0.40016745690189665, disc_loss = 0.07770094050504171
Trained batch 391 in epoch 9, gen_loss = 0.40022396638381236, disc_loss = 0.07759144353770595
Trained batch 392 in epoch 9, gen_loss = 0.40008882150698555, disc_loss = 0.07770120952415822
Trained batch 393 in epoch 9, gen_loss = 0.40026664817091173, disc_loss = 0.07761161909485945
Trained batch 394 in epoch 9, gen_loss = 0.4003638588174989, disc_loss = 0.07760899841101675
Trained batch 395 in epoch 9, gen_loss = 0.400332082326364, disc_loss = 0.07781033128420023
Trained batch 396 in epoch 9, gen_loss = 0.4006812019222029, disc_loss = 0.07771956918629763
Trained batch 397 in epoch 9, gen_loss = 0.40065841047308554, disc_loss = 0.07757906920753943
Trained batch 398 in epoch 9, gen_loss = 0.4007816391630579, disc_loss = 0.07744108567966666
Trained batch 399 in epoch 9, gen_loss = 0.4006646902859211, disc_loss = 0.077303975521354
Trained batch 400 in epoch 9, gen_loss = 0.4007458088552565, disc_loss = 0.07715959064174731
Trained batch 401 in epoch 9, gen_loss = 0.40076713946031695, disc_loss = 0.07703889687128587
Trained batch 402 in epoch 9, gen_loss = 0.4008742751317935, disc_loss = 0.07689586949994598
Trained batch 403 in epoch 9, gen_loss = 0.4009996117784245, disc_loss = 0.07692279754146601
Trained batch 404 in epoch 9, gen_loss = 0.40089341578660187, disc_loss = 0.07735652444240304
Trained batch 405 in epoch 9, gen_loss = 0.40096277306819783, disc_loss = 0.07757533755350693
Trained batch 406 in epoch 9, gen_loss = 0.4008997108338799, disc_loss = 0.07753529548713667
Trained batch 407 in epoch 9, gen_loss = 0.4007339032695574, disc_loss = 0.07806551687341805
Trained batch 408 in epoch 9, gen_loss = 0.40095116944942616, disc_loss = 0.07800783730546937
Trained batch 409 in epoch 9, gen_loss = 0.4010050877565291, disc_loss = 0.07791148215055284
Trained batch 410 in epoch 9, gen_loss = 0.4008020903652312, disc_loss = 0.07780090392138946
Trained batch 411 in epoch 9, gen_loss = 0.4008629018965277, disc_loss = 0.07779127551871126
Trained batch 412 in epoch 9, gen_loss = 0.40109101587288604, disc_loss = 0.07770006952031581
Trained batch 413 in epoch 9, gen_loss = 0.40109479528118447, disc_loss = 0.07759634213598562
Trained batch 414 in epoch 9, gen_loss = 0.40131402877439937, disc_loss = 0.0775055518968547
Trained batch 415 in epoch 9, gen_loss = 0.4013655943652758, disc_loss = 0.07734945797822618
Trained batch 416 in epoch 9, gen_loss = 0.4011814153308777, disc_loss = 0.07733188519406198
Trained batch 417 in epoch 9, gen_loss = 0.40133503500069156, disc_loss = 0.07748352636306872
Trained batch 418 in epoch 9, gen_loss = 0.4012052548386886, disc_loss = 0.07775901236542476
Trained batch 419 in epoch 9, gen_loss = 0.401388797447795, disc_loss = 0.07774858850697498
Trained batch 420 in epoch 9, gen_loss = 0.4013876973025306, disc_loss = 0.07759648203659546
Trained batch 421 in epoch 9, gen_loss = 0.40123050889415196, disc_loss = 0.07750637782185882
Trained batch 422 in epoch 9, gen_loss = 0.4013528905579948, disc_loss = 0.07759344051691129
Trained batch 423 in epoch 9, gen_loss = 0.4015191505258938, disc_loss = 0.07789414332639251
Trained batch 424 in epoch 9, gen_loss = 0.4015481765831218, disc_loss = 0.07773190450690248
Trained batch 425 in epoch 9, gen_loss = 0.4015564348356265, disc_loss = 0.07764845543121263
Trained batch 426 in epoch 9, gen_loss = 0.4015825450839148, disc_loss = 0.0775959314593055
Trained batch 427 in epoch 9, gen_loss = 0.4017017340270158, disc_loss = 0.07772604137263044
Trained batch 428 in epoch 9, gen_loss = 0.40176762873198324, disc_loss = 0.07761645140039511
Trained batch 429 in epoch 9, gen_loss = 0.401968189311582, disc_loss = 0.0775083094239668
Trained batch 430 in epoch 9, gen_loss = 0.40197186777044064, disc_loss = 0.07742993826729412
Trained batch 431 in epoch 9, gen_loss = 0.4019886525002895, disc_loss = 0.0775620848623846
Trained batch 432 in epoch 9, gen_loss = 0.40213769089267104, disc_loss = 0.07778354766122636
Trained batch 433 in epoch 9, gen_loss = 0.40202471648218446, disc_loss = 0.07787439925059642
Trained batch 434 in epoch 9, gen_loss = 0.4020820418308521, disc_loss = 0.07780337493074523
Trained batch 435 in epoch 9, gen_loss = 0.4021686071512896, disc_loss = 0.07763925692335694
Trained batch 436 in epoch 9, gen_loss = 0.40217898059764223, disc_loss = 0.07747947420281288
Trained batch 437 in epoch 9, gen_loss = 0.402017848472617, disc_loss = 0.07736258032587123
Trained batch 438 in epoch 9, gen_loss = 0.40204184310582886, disc_loss = 0.0772243423084039
Trained batch 439 in epoch 9, gen_loss = 0.4020597386766564, disc_loss = 0.07708914159606635
Trained batch 440 in epoch 9, gen_loss = 0.4020065391550259, disc_loss = 0.07698712857701982
Trained batch 441 in epoch 9, gen_loss = 0.40198857623797196, disc_loss = 0.07695955201473542
Trained batch 442 in epoch 9, gen_loss = 0.40194836124340516, disc_loss = 0.07724917996107153
Trained batch 443 in epoch 9, gen_loss = 0.4021579887684401, disc_loss = 0.07762943958204978
Trained batch 444 in epoch 9, gen_loss = 0.4021944424409545, disc_loss = 0.07754824256859301
Trained batch 445 in epoch 9, gen_loss = 0.40198245918536935, disc_loss = 0.07772715658580075
Trained batch 446 in epoch 9, gen_loss = 0.40201016180467286, disc_loss = 0.07801773425679179
Trained batch 447 in epoch 9, gen_loss = 0.4018993796115475, disc_loss = 0.07805233505184463
Trained batch 448 in epoch 9, gen_loss = 0.4019786876134724, disc_loss = 0.07790773606160137
Trained batch 449 in epoch 9, gen_loss = 0.4018550865517722, disc_loss = 0.07791062861991425
Trained batch 450 in epoch 9, gen_loss = 0.4017596363756979, disc_loss = 0.07805549993000083
Trained batch 451 in epoch 9, gen_loss = 0.40178116819763604, disc_loss = 0.07803662340836681
Trained batch 452 in epoch 9, gen_loss = 0.40159873996612516, disc_loss = 0.07790477165467133
Trained batch 453 in epoch 9, gen_loss = 0.40156279681537643, disc_loss = 0.07775732476391424
Trained batch 454 in epoch 9, gen_loss = 0.40159651800826357, disc_loss = 0.07766314242546866
Trained batch 455 in epoch 9, gen_loss = 0.4015008558176066, disc_loss = 0.07774960230361964
Trained batch 456 in epoch 9, gen_loss = 0.4013911473281535, disc_loss = 0.07794985436290275
Trained batch 457 in epoch 9, gen_loss = 0.40133095204049324, disc_loss = 0.0780803153248642
Trained batch 458 in epoch 9, gen_loss = 0.4012369466113629, disc_loss = 0.07811235889999403
Trained batch 459 in epoch 9, gen_loss = 0.40117658149936924, disc_loss = 0.07821292195610864
Trained batch 460 in epoch 9, gen_loss = 0.4012593840957981, disc_loss = 0.07934762681622276
Testing Epoch 9

Training Epoch 10
Trained batch 0 in epoch 10, gen_loss = 0.38286077976226807, disc_loss = 0.13978253304958344
Trained batch 1 in epoch 10, gen_loss = 0.38062043488025665, disc_loss = 0.1076907142996788
Trained batch 2 in epoch 10, gen_loss = 0.3743446966012319, disc_loss = 0.08088390156626701
Trained batch 3 in epoch 10, gen_loss = 0.3888768330216408, disc_loss = 0.065393534488976
Trained batch 4 in epoch 10, gen_loss = 0.3714580714702606, disc_loss = 0.0780475951731205
Trained batch 5 in epoch 10, gen_loss = 0.38111690680185956, disc_loss = 0.07700980392595132
Trained batch 6 in epoch 10, gen_loss = 0.37059966155460905, disc_loss = 0.07872622194034713
Trained batch 7 in epoch 10, gen_loss = 0.3825582228600979, disc_loss = 0.08051548944786191
Trained batch 8 in epoch 10, gen_loss = 0.3847137623363071, disc_loss = 0.0765655669901106
Trained batch 9 in epoch 10, gen_loss = 0.3835147589445114, disc_loss = 0.07198263742029667
Trained batch 10 in epoch 10, gen_loss = 0.38604421236298303, disc_loss = 0.072099450298331
Trained batch 11 in epoch 10, gen_loss = 0.38279444475968677, disc_loss = 0.07296858138094346
Trained batch 12 in epoch 10, gen_loss = 0.3846854796776405, disc_loss = 0.07644139545468184
Trained batch 13 in epoch 10, gen_loss = 0.3890408213649477, disc_loss = 0.08003863559237548
Trained batch 14 in epoch 10, gen_loss = 0.3852511405944824, disc_loss = 0.08379877880215644
Trained batch 15 in epoch 10, gen_loss = 0.381057795137167, disc_loss = 0.0808220652397722
Trained batch 16 in epoch 10, gen_loss = 0.378611320958418, disc_loss = 0.07881193301256965
Trained batch 17 in epoch 10, gen_loss = 0.3783208578824997, disc_loss = 0.07692770866884126
Trained batch 18 in epoch 10, gen_loss = 0.3750092857762387, disc_loss = 0.07370930047411668
Trained batch 19 in epoch 10, gen_loss = 0.37700760960578916, disc_loss = 0.07144526280462742
Trained batch 20 in epoch 10, gen_loss = 0.3783366878827413, disc_loss = 0.07619994204668772
Trained batch 21 in epoch 10, gen_loss = 0.3827023316513408, disc_loss = 0.08414741165258667
Trained batch 22 in epoch 10, gen_loss = 0.3801654253316962, disc_loss = 0.08389351452174394
Trained batch 23 in epoch 10, gen_loss = 0.38217880328496295, disc_loss = 0.08244663849473
Trained batch 24 in epoch 10, gen_loss = 0.37925376653671267, disc_loss = 0.08074997752904892
Trained batch 25 in epoch 10, gen_loss = 0.3826945745027982, disc_loss = 0.08365927837215938
Trained batch 26 in epoch 10, gen_loss = 0.38155378456468936, disc_loss = 0.08622594977970477
Trained batch 27 in epoch 10, gen_loss = 0.38001308164426256, disc_loss = 0.08421957918575831
Trained batch 28 in epoch 10, gen_loss = 0.3805961989123246, disc_loss = 0.08494271337985992
Trained batch 29 in epoch 10, gen_loss = 0.38007914324601494, disc_loss = 0.08393561442693075
Trained batch 30 in epoch 10, gen_loss = 0.38009255836086886, disc_loss = 0.0827440919895326
Trained batch 31 in epoch 10, gen_loss = 0.38208479154855013, disc_loss = 0.08087093330686912
Trained batch 32 in epoch 10, gen_loss = 0.3812061945597331, disc_loss = 0.07942691609037644
Trained batch 33 in epoch 10, gen_loss = 0.38526729099890766, disc_loss = 0.08356606111149578
Trained batch 34 in epoch 10, gen_loss = 0.38549932071140836, disc_loss = 0.08835125081241131
Trained batch 35 in epoch 10, gen_loss = 0.38484478493531543, disc_loss = 0.08950069945098625
Trained batch 36 in epoch 10, gen_loss = 0.38282796096157384, disc_loss = 0.08834549084909864
Trained batch 37 in epoch 10, gen_loss = 0.3845659580669905, disc_loss = 0.08659255244818173
Trained batch 38 in epoch 10, gen_loss = 0.3862653680336781, disc_loss = 0.0846952573897747
Trained batch 39 in epoch 10, gen_loss = 0.3858631655573845, disc_loss = 0.08336309087462723
Trained batch 40 in epoch 10, gen_loss = 0.385921753761245, disc_loss = 0.08231845102840807
Trained batch 41 in epoch 10, gen_loss = 0.38655597823006765, disc_loss = 0.08064510203188374
Trained batch 42 in epoch 10, gen_loss = 0.3876991770988287, disc_loss = 0.0795119172611902
Trained batch 43 in epoch 10, gen_loss = 0.38823166354136035, disc_loss = 0.07912424359131943
Trained batch 44 in epoch 10, gen_loss = 0.3896199511157142, disc_loss = 0.07815304208132956
Trained batch 45 in epoch 10, gen_loss = 0.3894173807424048, disc_loss = 0.07732282157825388
Trained batch 46 in epoch 10, gen_loss = 0.3915297103689072, disc_loss = 0.07754502017447289
Trained batch 47 in epoch 10, gen_loss = 0.3901409829656283, disc_loss = 0.0802939385175705
Trained batch 48 in epoch 10, gen_loss = 0.3925150596365637, disc_loss = 0.08450119106137023
Trained batch 49 in epoch 10, gen_loss = 0.3914322900772095, disc_loss = 0.08302107948809861
Trained batch 50 in epoch 10, gen_loss = 0.39143867936788823, disc_loss = 0.08171848981988196
Trained batch 51 in epoch 10, gen_loss = 0.3908511738364513, disc_loss = 0.08158763412099618
Trained batch 52 in epoch 10, gen_loss = 0.3904177867016702, disc_loss = 0.08035376801524523
Trained batch 53 in epoch 10, gen_loss = 0.3900018748309877, disc_loss = 0.07983169642587502
Trained batch 54 in epoch 10, gen_loss = 0.3901625351472334, disc_loss = 0.0787332435561852
Trained batch 55 in epoch 10, gen_loss = 0.38997023339782444, disc_loss = 0.07910976502379137
Trained batch 56 in epoch 10, gen_loss = 0.39093548320887384, disc_loss = 0.08209385026834513
Trained batch 57 in epoch 10, gen_loss = 0.39012170505934746, disc_loss = 0.08247557471923787
Trained batch 58 in epoch 10, gen_loss = 0.38950450794171476, disc_loss = 0.08176748950223801
Trained batch 59 in epoch 10, gen_loss = 0.388993401825428, disc_loss = 0.08124616260950764
Trained batch 60 in epoch 10, gen_loss = 0.38876596484027925, disc_loss = 0.081283783234778
Trained batch 61 in epoch 10, gen_loss = 0.3904021608252679, disc_loss = 0.08143062123488035
Trained batch 62 in epoch 10, gen_loss = 0.389426027498548, disc_loss = 0.08174335581087877
Trained batch 63 in epoch 10, gen_loss = 0.3903401088900864, disc_loss = 0.08135752993985079
Trained batch 64 in epoch 10, gen_loss = 0.3906859659231626, disc_loss = 0.0805234847160486
Trained batch 65 in epoch 10, gen_loss = 0.39096056286132697, disc_loss = 0.07946863815639958
Trained batch 66 in epoch 10, gen_loss = 0.3892200464632974, disc_loss = 0.08237401318194261
Trained batch 67 in epoch 10, gen_loss = 0.39026794714086194, disc_loss = 0.08927843237624448
Trained batch 68 in epoch 10, gen_loss = 0.39086784228034643, disc_loss = 0.09030468437982642
Trained batch 69 in epoch 10, gen_loss = 0.38950377234390804, disc_loss = 0.09269925568784987
Trained batch 70 in epoch 10, gen_loss = 0.3884903528320957, disc_loss = 0.09322339485228902
Trained batch 71 in epoch 10, gen_loss = 0.38730982318520546, disc_loss = 0.09360028906828827
Trained batch 72 in epoch 10, gen_loss = 0.385916532310721, disc_loss = 0.09467891634327091
Trained batch 73 in epoch 10, gen_loss = 0.3869846596105679, disc_loss = 0.09608156515939816
Trained batch 74 in epoch 10, gen_loss = 0.3867611209551493, disc_loss = 0.09532482152183851
Trained batch 75 in epoch 10, gen_loss = 0.3863599727812566, disc_loss = 0.09461207673149674
Trained batch 76 in epoch 10, gen_loss = 0.38558435594880736, disc_loss = 0.09465396225258901
Trained batch 77 in epoch 10, gen_loss = 0.3866855574724002, disc_loss = 0.09449175348839699
Trained batch 78 in epoch 10, gen_loss = 0.3866103008578095, disc_loss = 0.09345737285912037
Trained batch 79 in epoch 10, gen_loss = 0.3861195228993893, disc_loss = 0.09415911154355854
Trained batch 80 in epoch 10, gen_loss = 0.3872879176963995, disc_loss = 0.09561625856584237
Trained batch 81 in epoch 10, gen_loss = 0.38731470958488745, disc_loss = 0.09463620183580532
Trained batch 82 in epoch 10, gen_loss = 0.3874424412307969, disc_loss = 0.0954732097550688
Trained batch 83 in epoch 10, gen_loss = 0.38761627816018607, disc_loss = 0.09563719319357049
Trained batch 84 in epoch 10, gen_loss = 0.38738310056574204, disc_loss = 0.09514731933527133
Trained batch 85 in epoch 10, gen_loss = 0.3877353165731874, disc_loss = 0.09494041281124187
Trained batch 86 in epoch 10, gen_loss = 0.38673492306950447, disc_loss = 0.09434723145403397
Trained batch 87 in epoch 10, gen_loss = 0.3873888728293506, disc_loss = 0.09361494389701296
Trained batch 88 in epoch 10, gen_loss = 0.3870278935084182, disc_loss = 0.09299790287871709
Trained batch 89 in epoch 10, gen_loss = 0.3875331617063946, disc_loss = 0.09255816421161095
Trained batch 90 in epoch 10, gen_loss = 0.38705141039995045, disc_loss = 0.09208718750748661
Trained batch 91 in epoch 10, gen_loss = 0.3875774527373521, disc_loss = 0.09228157525396218
Trained batch 92 in epoch 10, gen_loss = 0.38765250739230905, disc_loss = 0.09162748751220523
Trained batch 93 in epoch 10, gen_loss = 0.3876080906137507, disc_loss = 0.09085566166074986
Trained batch 94 in epoch 10, gen_loss = 0.3870353134054887, disc_loss = 0.09077632925228069
Trained batch 95 in epoch 10, gen_loss = 0.38766509170333546, disc_loss = 0.09253333629264186
Trained batch 96 in epoch 10, gen_loss = 0.3888219625679488, disc_loss = 0.09166341261534962
Trained batch 97 in epoch 10, gen_loss = 0.38903894746790124, disc_loss = 0.09209262497951182
Trained batch 98 in epoch 10, gen_loss = 0.3887854883767138, disc_loss = 0.09396267202541683
Trained batch 99 in epoch 10, gen_loss = 0.38874217718839643, disc_loss = 0.09348434271290898
Trained batch 100 in epoch 10, gen_loss = 0.3871910983678138, disc_loss = 0.09322963280621732
Trained batch 101 in epoch 10, gen_loss = 0.3870310489745701, disc_loss = 0.09250274424751599
Trained batch 102 in epoch 10, gen_loss = 0.38644165827811344, disc_loss = 0.09213691646034278
Trained batch 103 in epoch 10, gen_loss = 0.3864723233362803, disc_loss = 0.09268823394981715
Trained batch 104 in epoch 10, gen_loss = 0.38719448120821087, disc_loss = 0.09269916982877822
Trained batch 105 in epoch 10, gen_loss = 0.38598289284503684, disc_loss = 0.09409974374861088
Trained batch 106 in epoch 10, gen_loss = 0.3866748563318609, disc_loss = 0.09640051772661298
Trained batch 107 in epoch 10, gen_loss = 0.3873886108674385, disc_loss = 0.09608232174758558
Trained batch 108 in epoch 10, gen_loss = 0.386913529639944, disc_loss = 0.09683044596549568
Trained batch 109 in epoch 10, gen_loss = 0.3875818435441364, disc_loss = 0.09689722223715348
Trained batch 110 in epoch 10, gen_loss = 0.386976700779554, disc_loss = 0.09647934984516453
Trained batch 111 in epoch 10, gen_loss = 0.38613189770174877, disc_loss = 0.09633147909439035
Trained batch 112 in epoch 10, gen_loss = 0.38718472394795544, disc_loss = 0.09769115372832897
Trained batch 113 in epoch 10, gen_loss = 0.38725419695440094, disc_loss = 0.09745390837391217
Trained batch 114 in epoch 10, gen_loss = 0.38720197068608325, disc_loss = 0.09711866812861485
Trained batch 115 in epoch 10, gen_loss = 0.3866037332035344, disc_loss = 0.09769063834743254
Trained batch 116 in epoch 10, gen_loss = 0.38635271673019117, disc_loss = 0.09755291216648541
Trained batch 117 in epoch 10, gen_loss = 0.38648207422535297, disc_loss = 0.09716880681403613
Trained batch 118 in epoch 10, gen_loss = 0.38596465219469633, disc_loss = 0.09675862248830434
Trained batch 119 in epoch 10, gen_loss = 0.3861981594314178, disc_loss = 0.09623307806129257
Trained batch 120 in epoch 10, gen_loss = 0.3860853236815161, disc_loss = 0.09585713173362835
Trained batch 121 in epoch 10, gen_loss = 0.38666086497365454, disc_loss = 0.09563793354957807
Trained batch 122 in epoch 10, gen_loss = 0.3862630995066185, disc_loss = 0.09577761520820904
Trained batch 123 in epoch 10, gen_loss = 0.386448230113714, disc_loss = 0.09597833980355532
Trained batch 124 in epoch 10, gen_loss = 0.38570002114772794, disc_loss = 0.0967359993159771
Trained batch 125 in epoch 10, gen_loss = 0.3857295951909489, disc_loss = 0.09634402867347475
Trained batch 126 in epoch 10, gen_loss = 0.38652847191010875, disc_loss = 0.09584791336472578
Trained batch 127 in epoch 10, gen_loss = 0.38712681212928146, disc_loss = 0.09562392090447247
Trained batch 128 in epoch 10, gen_loss = 0.3875704542842022, disc_loss = 0.09495361154364754
Trained batch 129 in epoch 10, gen_loss = 0.3878861364263755, disc_loss = 0.0942841596614856
Trained batch 130 in epoch 10, gen_loss = 0.38803426921367645, disc_loss = 0.09361236030591354
Trained batch 131 in epoch 10, gen_loss = 0.3883276641594641, disc_loss = 0.09296278730317047
Trained batch 132 in epoch 10, gen_loss = 0.3883240620668669, disc_loss = 0.09244648050656892
Trained batch 133 in epoch 10, gen_loss = 0.3886686013038479, disc_loss = 0.09241806234775195
Trained batch 134 in epoch 10, gen_loss = 0.3889918178319931, disc_loss = 0.09251824879535922
Trained batch 135 in epoch 10, gen_loss = 0.3889627001960488, disc_loss = 0.09243490166195176
Trained batch 136 in epoch 10, gen_loss = 0.38949349772756114, disc_loss = 0.0923587729624153
Trained batch 137 in epoch 10, gen_loss = 0.38920980724303617, disc_loss = 0.09402051975653655
Trained batch 138 in epoch 10, gen_loss = 0.38951919265359425, disc_loss = 0.09412486071316459
Trained batch 139 in epoch 10, gen_loss = 0.38949230877416474, disc_loss = 0.0942580049325313
Trained batch 140 in epoch 10, gen_loss = 0.38902705136343096, disc_loss = 0.09414069499846892
Trained batch 141 in epoch 10, gen_loss = 0.38905302707997846, disc_loss = 0.09383743468829443
Trained batch 142 in epoch 10, gen_loss = 0.38927475399487504, disc_loss = 0.0934747032091751
Trained batch 143 in epoch 10, gen_loss = 0.3896549001543058, disc_loss = 0.09288150805514306
Trained batch 144 in epoch 10, gen_loss = 0.3893506412876063, disc_loss = 0.09257367496089688
Trained batch 145 in epoch 10, gen_loss = 0.3898018832280211, disc_loss = 0.09296841691056751
Trained batch 146 in epoch 10, gen_loss = 0.3897341048839141, disc_loss = 0.09413881464322814
Trained batch 147 in epoch 10, gen_loss = 0.38980197936699196, disc_loss = 0.09389847596301823
Trained batch 148 in epoch 10, gen_loss = 0.3902341614433583, disc_loss = 0.09368097763383548
Trained batch 149 in epoch 10, gen_loss = 0.3899338556329409, disc_loss = 0.09353139699747165
Trained batch 150 in epoch 10, gen_loss = 0.3901942130548275, disc_loss = 0.09388230801467469
Trained batch 151 in epoch 10, gen_loss = 0.3901713407157283, disc_loss = 0.09545007457123383
Trained batch 152 in epoch 10, gen_loss = 0.38967708736852885, disc_loss = 0.09747903011252287
Trained batch 153 in epoch 10, gen_loss = 0.39022109367243657, disc_loss = 0.09801887393046121
Trained batch 154 in epoch 10, gen_loss = 0.39007110432271036, disc_loss = 0.09776893326592061
Trained batch 155 in epoch 10, gen_loss = 0.39009676921444064, disc_loss = 0.09782745551843292
Trained batch 156 in epoch 10, gen_loss = 0.38991672550417056, disc_loss = 0.09737396974614851
Trained batch 157 in epoch 10, gen_loss = 0.3896603002389775, disc_loss = 0.09713781248966727
Trained batch 158 in epoch 10, gen_loss = 0.3897809169764789, disc_loss = 0.0970144908781509
Trained batch 159 in epoch 10, gen_loss = 0.3900605236180127, disc_loss = 0.09649502045940608
Trained batch 160 in epoch 10, gen_loss = 0.39025470938371576, disc_loss = 0.09595218180499462
Trained batch 161 in epoch 10, gen_loss = 0.39006715874980996, disc_loss = 0.09569010221295887
Trained batch 162 in epoch 10, gen_loss = 0.3903822590785524, disc_loss = 0.0955063715302871
Trained batch 163 in epoch 10, gen_loss = 0.38999966268495817, disc_loss = 0.09548914087254827
Trained batch 164 in epoch 10, gen_loss = 0.3902346987615932, disc_loss = 0.0950994095567501
Trained batch 165 in epoch 10, gen_loss = 0.3904336199882519, disc_loss = 0.09469782993062792
Trained batch 166 in epoch 10, gen_loss = 0.390612600360088, disc_loss = 0.09424735207534479
Trained batch 167 in epoch 10, gen_loss = 0.39140433596358415, disc_loss = 0.09428346861109492
Trained batch 168 in epoch 10, gen_loss = 0.391437464299992, disc_loss = 0.09514298324181131
Trained batch 169 in epoch 10, gen_loss = 0.392001968359246, disc_loss = 0.09484344509375446
Trained batch 170 in epoch 10, gen_loss = 0.3925393106121766, disc_loss = 0.09441300785463107
Trained batch 171 in epoch 10, gen_loss = 0.39296411385023317, disc_loss = 0.09398140971613832
Trained batch 172 in epoch 10, gen_loss = 0.3931870597463123, disc_loss = 0.09361991425168652
Trained batch 173 in epoch 10, gen_loss = 0.39278677508406257, disc_loss = 0.0932589801692072
Trained batch 174 in epoch 10, gen_loss = 0.39262173218386515, disc_loss = 0.09327249946338789
Trained batch 175 in epoch 10, gen_loss = 0.3927628815343434, disc_loss = 0.09351645623841746
Trained batch 176 in epoch 10, gen_loss = 0.39284727339353936, disc_loss = 0.0930205803406609
Trained batch 177 in epoch 10, gen_loss = 0.3928885067279419, disc_loss = 0.09270736471530092
Trained batch 178 in epoch 10, gen_loss = 0.39280461557417606, disc_loss = 0.09224687951653364
Trained batch 179 in epoch 10, gen_loss = 0.39324701668487655, disc_loss = 0.09175920679440928
Trained batch 180 in epoch 10, gen_loss = 0.3932704040523392, disc_loss = 0.09134793406589091
Trained batch 181 in epoch 10, gen_loss = 0.3933761541496266, disc_loss = 0.09106712466474254
Trained batch 182 in epoch 10, gen_loss = 0.3931609248040152, disc_loss = 0.09083879777215055
Trained batch 183 in epoch 10, gen_loss = 0.39346520027712634, disc_loss = 0.09046552036180282
Trained batch 184 in epoch 10, gen_loss = 0.39334961345066893, disc_loss = 0.09052261518364822
Trained batch 185 in epoch 10, gen_loss = 0.39246664324434855, disc_loss = 0.09096601855270164
Trained batch 186 in epoch 10, gen_loss = 0.39250964157402835, disc_loss = 0.0911919100229992
Trained batch 187 in epoch 10, gen_loss = 0.39225466763402556, disc_loss = 0.0913416378427931
Trained batch 188 in epoch 10, gen_loss = 0.392418153308056, disc_loss = 0.09110119709715483
Trained batch 189 in epoch 10, gen_loss = 0.3925317957997322, disc_loss = 0.09071023108829793
Trained batch 190 in epoch 10, gen_loss = 0.3921815201406079, disc_loss = 0.09079622900045199
Trained batch 191 in epoch 10, gen_loss = 0.3924152209268262, disc_loss = 0.09152464535145555
Trained batch 192 in epoch 10, gen_loss = 0.39249559194621647, disc_loss = 0.09111197087720731
Trained batch 193 in epoch 10, gen_loss = 0.39192461637184794, disc_loss = 0.09148670198664684
Trained batch 194 in epoch 10, gen_loss = 0.3917918047079673, disc_loss = 0.09146889558491798
Trained batch 195 in epoch 10, gen_loss = 0.39246405395013945, disc_loss = 0.0911023305225357
Trained batch 196 in epoch 10, gen_loss = 0.39219386936141754, disc_loss = 0.09086391240415083
Trained batch 197 in epoch 10, gen_loss = 0.39200826478425904, disc_loss = 0.09052846216210964
Trained batch 198 in epoch 10, gen_loss = 0.39193483296051695, disc_loss = 0.09022321516938096
Trained batch 199 in epoch 10, gen_loss = 0.39190325774252416, disc_loss = 0.09012374761048704
Trained batch 200 in epoch 10, gen_loss = 0.39231639218271075, disc_loss = 0.08992367931433133
Trained batch 201 in epoch 10, gen_loss = 0.3917633515625897, disc_loss = 0.09011585339627201
Trained batch 202 in epoch 10, gen_loss = 0.392155858316445, disc_loss = 0.09018927493724477
Trained batch 203 in epoch 10, gen_loss = 0.3926956626568355, disc_loss = 0.08980252306141398
Trained batch 204 in epoch 10, gen_loss = 0.39253935937474416, disc_loss = 0.08966578204275631
Trained batch 205 in epoch 10, gen_loss = 0.3927064618294679, disc_loss = 0.08932192495219338
Trained batch 206 in epoch 10, gen_loss = 0.39302806167498877, disc_loss = 0.08929398013413817
Trained batch 207 in epoch 10, gen_loss = 0.39288783137901473, disc_loss = 0.08927556526703903
Trained batch 208 in epoch 10, gen_loss = 0.3928446298438396, disc_loss = 0.08919462395840855
Trained batch 209 in epoch 10, gen_loss = 0.3931728620614324, disc_loss = 0.08973091838970071
Trained batch 210 in epoch 10, gen_loss = 0.39330279424574704, disc_loss = 0.09007271564614151
Trained batch 211 in epoch 10, gen_loss = 0.3930354859890803, disc_loss = 0.09017513395410101
Trained batch 212 in epoch 10, gen_loss = 0.39327637151653216, disc_loss = 0.08983415522625748
Trained batch 213 in epoch 10, gen_loss = 0.3935395362917508, disc_loss = 0.08964926770357327
Trained batch 214 in epoch 10, gen_loss = 0.3937396822280662, disc_loss = 0.08937439329402391
Trained batch 215 in epoch 10, gen_loss = 0.3937848674616328, disc_loss = 0.08932995799652955
Trained batch 216 in epoch 10, gen_loss = 0.39373536188206915, disc_loss = 0.08898770888572052
Trained batch 217 in epoch 10, gen_loss = 0.3940207003316748, disc_loss = 0.08881031717131034
Trained batch 218 in epoch 10, gen_loss = 0.3935460945650867, disc_loss = 0.08865728457649685
Trained batch 219 in epoch 10, gen_loss = 0.39403335174376314, disc_loss = 0.08831149697388438
Trained batch 220 in epoch 10, gen_loss = 0.3941011684377808, disc_loss = 0.08805789402791413
Trained batch 221 in epoch 10, gen_loss = 0.3937549244041915, disc_loss = 0.08816954592947622
Trained batch 222 in epoch 10, gen_loss = 0.39352652838144603, disc_loss = 0.08985057826082936
Trained batch 223 in epoch 10, gen_loss = 0.3934548924943166, disc_loss = 0.08986536734820609
Trained batch 224 in epoch 10, gen_loss = 0.3937289496925142, disc_loss = 0.08984941898534696
Trained batch 225 in epoch 10, gen_loss = 0.39352090927088157, disc_loss = 0.08983841299829362
Trained batch 226 in epoch 10, gen_loss = 0.3932200056472014, disc_loss = 0.0898601004673324
Trained batch 227 in epoch 10, gen_loss = 0.39330877527071717, disc_loss = 0.0900332487408856
Trained batch 228 in epoch 10, gen_loss = 0.39278505963789845, disc_loss = 0.09101886639379649
Trained batch 229 in epoch 10, gen_loss = 0.3925367022985997, disc_loss = 0.09112312348721469
Trained batch 230 in epoch 10, gen_loss = 0.39242615089530036, disc_loss = 0.09098026371315057
Trained batch 231 in epoch 10, gen_loss = 0.3926483675965975, disc_loss = 0.09115938638770503
Trained batch 232 in epoch 10, gen_loss = 0.3922430318440491, disc_loss = 0.09153050908922765
Trained batch 233 in epoch 10, gen_loss = 0.39259376134882623, disc_loss = 0.09130478244768377
Trained batch 234 in epoch 10, gen_loss = 0.39268804794930395, disc_loss = 0.09118645418276812
Trained batch 235 in epoch 10, gen_loss = 0.39262541629752873, disc_loss = 0.09114227253328061
Trained batch 236 in epoch 10, gen_loss = 0.39239978783995794, disc_loss = 0.09094123129304577
Trained batch 237 in epoch 10, gen_loss = 0.3923907690063244, disc_loss = 0.09177590914837577
Trained batch 238 in epoch 10, gen_loss = 0.3925321211251255, disc_loss = 0.09239644450077078
Trained batch 239 in epoch 10, gen_loss = 0.3925987394526601, disc_loss = 0.09235086598200723
Trained batch 240 in epoch 10, gen_loss = 0.39265267229426454, disc_loss = 0.0921843369912619
Trained batch 241 in epoch 10, gen_loss = 0.3925838927961578, disc_loss = 0.09193872868599108
Trained batch 242 in epoch 10, gen_loss = 0.3925124259029396, disc_loss = 0.09165761822550998
Trained batch 243 in epoch 10, gen_loss = 0.39277351018591006, disc_loss = 0.09150184611942558
Trained batch 244 in epoch 10, gen_loss = 0.3925287834843811, disc_loss = 0.09138061894217925
Trained batch 245 in epoch 10, gen_loss = 0.39281513021001974, disc_loss = 0.09118239327553447
Trained batch 246 in epoch 10, gen_loss = 0.39269445715886864, disc_loss = 0.09097879442201573
Trained batch 247 in epoch 10, gen_loss = 0.3923934809262714, disc_loss = 0.09093291533645242
Trained batch 248 in epoch 10, gen_loss = 0.39231549694116813, disc_loss = 0.09068511524817431
Trained batch 249 in epoch 10, gen_loss = 0.3922614613175392, disc_loss = 0.09058520021662116
Trained batch 250 in epoch 10, gen_loss = 0.39217997754949974, disc_loss = 0.09042657052066577
Trained batch 251 in epoch 10, gen_loss = 0.39218676178937867, disc_loss = 0.09024986278428326
Trained batch 252 in epoch 10, gen_loss = 0.3921816384957242, disc_loss = 0.09014964704088896
Trained batch 253 in epoch 10, gen_loss = 0.392160007040801, disc_loss = 0.0899027793624211
Trained batch 254 in epoch 10, gen_loss = 0.3924892366516824, disc_loss = 0.09005991635004094
Trained batch 255 in epoch 10, gen_loss = 0.39235839672619477, disc_loss = 0.09133285941425129
Trained batch 256 in epoch 10, gen_loss = 0.3927956481504069, disc_loss = 0.0913235983749714
Trained batch 257 in epoch 10, gen_loss = 0.3927949426132579, disc_loss = 0.09129905524165478
Trained batch 258 in epoch 10, gen_loss = 0.39298106522863896, disc_loss = 0.09120443408309148
Trained batch 259 in epoch 10, gen_loss = 0.3930002108789407, disc_loss = 0.09094771504617082
Trained batch 260 in epoch 10, gen_loss = 0.39309746112631655, disc_loss = 0.0909655163763983
Trained batch 261 in epoch 10, gen_loss = 0.393319045484976, disc_loss = 0.09111146042692184
Trained batch 262 in epoch 10, gen_loss = 0.3931825957030851, disc_loss = 0.09086950622966421
Trained batch 263 in epoch 10, gen_loss = 0.39328971239879273, disc_loss = 0.09072649976676048
Trained batch 264 in epoch 10, gen_loss = 0.3933679013319735, disc_loss = 0.09052466596564594
Trained batch 265 in epoch 10, gen_loss = 0.3937604756171542, disc_loss = 0.09048649075938235
Trained batch 266 in epoch 10, gen_loss = 0.3934787131762237, disc_loss = 0.09111955729470159
Trained batch 267 in epoch 10, gen_loss = 0.39377572259573795, disc_loss = 0.09103212036790131
Trained batch 268 in epoch 10, gen_loss = 0.39400478106227504, disc_loss = 0.09100710826001535
Trained batch 269 in epoch 10, gen_loss = 0.39384090928015886, disc_loss = 0.09179912475455139
Trained batch 270 in epoch 10, gen_loss = 0.3939024080759485, disc_loss = 0.09187522537085294
Trained batch 271 in epoch 10, gen_loss = 0.3939769570989644, disc_loss = 0.09168774758890162
Trained batch 272 in epoch 10, gen_loss = 0.39421837675920773, disc_loss = 0.09168978415825318
Trained batch 273 in epoch 10, gen_loss = 0.39439702017681444, disc_loss = 0.0916940863380195
Trained batch 274 in epoch 10, gen_loss = 0.3941601235758175, disc_loss = 0.09151319450614127
Trained batch 275 in epoch 10, gen_loss = 0.394134934451701, disc_loss = 0.09159800476070655
Trained batch 276 in epoch 10, gen_loss = 0.3941589990355048, disc_loss = 0.091355129474579
Trained batch 277 in epoch 10, gen_loss = 0.39393357476956553, disc_loss = 0.09174202638845756
Trained batch 278 in epoch 10, gen_loss = 0.3935770245542663, disc_loss = 0.09207313813896696
Trained batch 279 in epoch 10, gen_loss = 0.3937307417924915, disc_loss = 0.09188425212632864
Trained batch 280 in epoch 10, gen_loss = 0.3937899019052125, disc_loss = 0.09212788204029468
Trained batch 281 in epoch 10, gen_loss = 0.3936484046544589, disc_loss = 0.09309665686021565
Trained batch 282 in epoch 10, gen_loss = 0.3935799798253568, disc_loss = 0.09324772299560241
Trained batch 283 in epoch 10, gen_loss = 0.39336765205986063, disc_loss = 0.09332718321410807
Trained batch 284 in epoch 10, gen_loss = 0.39339953362941743, disc_loss = 0.0933457794582896
Trained batch 285 in epoch 10, gen_loss = 0.3936199847530652, disc_loss = 0.09330396699699593
Trained batch 286 in epoch 10, gen_loss = 0.3936388982193811, disc_loss = 0.09322633922995695
Trained batch 287 in epoch 10, gen_loss = 0.3937274250201881, disc_loss = 0.09299199665029947
Trained batch 288 in epoch 10, gen_loss = 0.3938954847391089, disc_loss = 0.09298109700484362
Trained batch 289 in epoch 10, gen_loss = 0.3936791053619878, disc_loss = 0.09289030925017493
Trained batch 290 in epoch 10, gen_loss = 0.3935999224583308, disc_loss = 0.09267716919139181
Trained batch 291 in epoch 10, gen_loss = 0.39369399728227966, disc_loss = 0.0925411958508959
Trained batch 292 in epoch 10, gen_loss = 0.3937244800272248, disc_loss = 0.09323995368739546
Trained batch 293 in epoch 10, gen_loss = 0.39373436250856947, disc_loss = 0.0932978713397114
Trained batch 294 in epoch 10, gen_loss = 0.39382904964988513, disc_loss = 0.09312445269108324
Trained batch 295 in epoch 10, gen_loss = 0.394031238263926, disc_loss = 0.09317243789209405
Trained batch 296 in epoch 10, gen_loss = 0.3937964152908486, disc_loss = 0.09335506519597488
Trained batch 297 in epoch 10, gen_loss = 0.39365025759743366, disc_loss = 0.09332578767078535
Trained batch 298 in epoch 10, gen_loss = 0.3937819116191322, disc_loss = 0.09378155151749634
Trained batch 299 in epoch 10, gen_loss = 0.3937210149069627, disc_loss = 0.09389199816000958
Trained batch 300 in epoch 10, gen_loss = 0.39405985394387544, disc_loss = 0.09366879188006998
Trained batch 301 in epoch 10, gen_loss = 0.3941707197108016, disc_loss = 0.09353095414240332
Trained batch 302 in epoch 10, gen_loss = 0.39423387057513687, disc_loss = 0.09336175324807171
Trained batch 303 in epoch 10, gen_loss = 0.39419165640873344, disc_loss = 0.09318761157766475
Trained batch 304 in epoch 10, gen_loss = 0.394245132999342, disc_loss = 0.09293903717923849
Trained batch 305 in epoch 10, gen_loss = 0.39426671265581853, disc_loss = 0.09273761508109815
Trained batch 306 in epoch 10, gen_loss = 0.3945723313364998, disc_loss = 0.09248911076398257
Trained batch 307 in epoch 10, gen_loss = 0.3946463456498338, disc_loss = 0.09261559998894764
Trained batch 308 in epoch 10, gen_loss = 0.3949268435679593, disc_loss = 0.09278248775219937
Trained batch 309 in epoch 10, gen_loss = 0.3948125521502187, disc_loss = 0.09265576297297112
Trained batch 310 in epoch 10, gen_loss = 0.39483458891367224, disc_loss = 0.09261473070925934
Trained batch 311 in epoch 10, gen_loss = 0.394946836364957, disc_loss = 0.09267322825661932
Trained batch 312 in epoch 10, gen_loss = 0.3948824444232276, disc_loss = 0.09276578055557827
Trained batch 313 in epoch 10, gen_loss = 0.3948357961834616, disc_loss = 0.09313342014659837
Trained batch 314 in epoch 10, gen_loss = 0.3952733123586291, disc_loss = 0.09422299976918906
Trained batch 315 in epoch 10, gen_loss = 0.3953457826017579, disc_loss = 0.09452999172484668
Trained batch 316 in epoch 10, gen_loss = 0.39496064642062323, disc_loss = 0.09528833032183184
Trained batch 317 in epoch 10, gen_loss = 0.3947472598099109, disc_loss = 0.09539845531056605
Trained batch 318 in epoch 10, gen_loss = 0.39472204245930553, disc_loss = 0.09532766832698569
Trained batch 319 in epoch 10, gen_loss = 0.39460346451960504, disc_loss = 0.09527846320124808
Trained batch 320 in epoch 10, gen_loss = 0.39442900923367974, disc_loss = 0.09518621691627387
Trained batch 321 in epoch 10, gen_loss = 0.3943216734513733, disc_loss = 0.09513057145052907
Trained batch 322 in epoch 10, gen_loss = 0.3942076329014988, disc_loss = 0.09528038345404177
Trained batch 323 in epoch 10, gen_loss = 0.3943281936700697, disc_loss = 0.0951444501729889
Trained batch 324 in epoch 10, gen_loss = 0.39459744723943563, disc_loss = 0.09493406880073822
Trained batch 325 in epoch 10, gen_loss = 0.3947644451735941, disc_loss = 0.09471079145209646
Trained batch 326 in epoch 10, gen_loss = 0.39466720587069837, disc_loss = 0.0944492635046579
Trained batch 327 in epoch 10, gen_loss = 0.39460674405279683, disc_loss = 0.09422921988454352
Trained batch 328 in epoch 10, gen_loss = 0.39454202888403256, disc_loss = 0.09408300674002402
Trained batch 329 in epoch 10, gen_loss = 0.39463826422438475, disc_loss = 0.09398299262040492
Trained batch 330 in epoch 10, gen_loss = 0.3945169746425577, disc_loss = 0.09404136803777736
Trained batch 331 in epoch 10, gen_loss = 0.39487644226615687, disc_loss = 0.0940696359275425
Trained batch 332 in epoch 10, gen_loss = 0.394784918284273, disc_loss = 0.09396708558114979
Trained batch 333 in epoch 10, gen_loss = 0.39471661451155554, disc_loss = 0.09388833540396954
Trained batch 334 in epoch 10, gen_loss = 0.3947348067564751, disc_loss = 0.09403316577090257
Trained batch 335 in epoch 10, gen_loss = 0.3943534791026087, disc_loss = 0.09449617177181478
Trained batch 336 in epoch 10, gen_loss = 0.3945758140670793, disc_loss = 0.09460151322097558
Trained batch 337 in epoch 10, gen_loss = 0.39463680590221867, disc_loss = 0.094392609551064
Trained batch 338 in epoch 10, gen_loss = 0.3946207826380181, disc_loss = 0.0943585261427811
Trained batch 339 in epoch 10, gen_loss = 0.39464720781235135, disc_loss = 0.09411781125099343
Trained batch 340 in epoch 10, gen_loss = 0.3945973045752545, disc_loss = 0.09415462195239634
Trained batch 341 in epoch 10, gen_loss = 0.39481745167956717, disc_loss = 0.09401357650473627
Trained batch 342 in epoch 10, gen_loss = 0.39498989492567915, disc_loss = 0.09385027565366151
Trained batch 343 in epoch 10, gen_loss = 0.39518139706274796, disc_loss = 0.09379570743307299
Trained batch 344 in epoch 10, gen_loss = 0.39511114138623943, disc_loss = 0.0940528196539136
Trained batch 345 in epoch 10, gen_loss = 0.3953101240916748, disc_loss = 0.09486414714463356
Trained batch 346 in epoch 10, gen_loss = 0.3953789886978243, disc_loss = 0.0947380355943091
Trained batch 347 in epoch 10, gen_loss = 0.3950217239901252, disc_loss = 0.09472908156163905
Trained batch 348 in epoch 10, gen_loss = 0.39495402664202334, disc_loss = 0.09459841676739533
Trained batch 349 in epoch 10, gen_loss = 0.3951034960150719, disc_loss = 0.0944295647367835
Trained batch 350 in epoch 10, gen_loss = 0.39528531069599326, disc_loss = 0.09421584864499902
Trained batch 351 in epoch 10, gen_loss = 0.39529415808448737, disc_loss = 0.09416146217633715
Trained batch 352 in epoch 10, gen_loss = 0.3954405660078816, disc_loss = 0.09403269417140707
Trained batch 353 in epoch 10, gen_loss = 0.39554628725610885, disc_loss = 0.09396290170860155
Trained batch 354 in epoch 10, gen_loss = 0.395644943772907, disc_loss = 0.09392434121437476
Trained batch 355 in epoch 10, gen_loss = 0.3955411769951997, disc_loss = 0.09377370062127208
Trained batch 356 in epoch 10, gen_loss = 0.3956477840324076, disc_loss = 0.09365629033297718
Trained batch 357 in epoch 10, gen_loss = 0.39561964009560685, disc_loss = 0.09366564433917653
Trained batch 358 in epoch 10, gen_loss = 0.39565871780463246, disc_loss = 0.09384650836664986
Trained batch 359 in epoch 10, gen_loss = 0.3955713374333249, disc_loss = 0.09363598118329214
Trained batch 360 in epoch 10, gen_loss = 0.3956636759630531, disc_loss = 0.0934003705024678
Trained batch 361 in epoch 10, gen_loss = 0.395577403104437, disc_loss = 0.09338350869581433
Trained batch 362 in epoch 10, gen_loss = 0.39581229909228227, disc_loss = 0.0939753321140553
Trained batch 363 in epoch 10, gen_loss = 0.39569614733477215, disc_loss = 0.09384502722001584
Trained batch 364 in epoch 10, gen_loss = 0.39559352042740337, disc_loss = 0.0936521908064207
Trained batch 365 in epoch 10, gen_loss = 0.3957172326458608, disc_loss = 0.09357529130250297
Trained batch 366 in epoch 10, gen_loss = 0.39568509421329084, disc_loss = 0.09368623217329261
Trained batch 367 in epoch 10, gen_loss = 0.39586459978929034, disc_loss = 0.09398708861756502
Trained batch 368 in epoch 10, gen_loss = 0.39598790743971257, disc_loss = 0.09381847814240349
Trained batch 369 in epoch 10, gen_loss = 0.3959296777844429, disc_loss = 0.09384751865338233
Trained batch 370 in epoch 10, gen_loss = 0.3961084325599542, disc_loss = 0.09372667304297905
Trained batch 371 in epoch 10, gen_loss = 0.3964532267262218, disc_loss = 0.09378196141602452
Trained batch 372 in epoch 10, gen_loss = 0.39641025874154495, disc_loss = 0.09368582304327401
Trained batch 373 in epoch 10, gen_loss = 0.3962315202635877, disc_loss = 0.09391837545924565
Trained batch 374 in epoch 10, gen_loss = 0.39615161128838855, disc_loss = 0.09387484340618055
Trained batch 375 in epoch 10, gen_loss = 0.39601268892751096, disc_loss = 0.09382391434430362
Trained batch 376 in epoch 10, gen_loss = 0.39603320613938237, disc_loss = 0.09385136667816882
Trained batch 377 in epoch 10, gen_loss = 0.39592261979031185, disc_loss = 0.09412331166356881
Trained batch 378 in epoch 10, gen_loss = 0.3961358576383943, disc_loss = 0.09449817834662809
Trained batch 379 in epoch 10, gen_loss = 0.3962228521312538, disc_loss = 0.0943490041787491
Trained batch 380 in epoch 10, gen_loss = 0.3963011953383293, disc_loss = 0.09431223329547744
Trained batch 381 in epoch 10, gen_loss = 0.39615690891499294, disc_loss = 0.09418005765176803
Trained batch 382 in epoch 10, gen_loss = 0.3962253660119234, disc_loss = 0.09421886684368158
Trained batch 383 in epoch 10, gen_loss = 0.395932623767294, disc_loss = 0.09440869707759703
Trained batch 384 in epoch 10, gen_loss = 0.39573289175312243, disc_loss = 0.09444464175877246
Trained batch 385 in epoch 10, gen_loss = 0.3957364443747491, disc_loss = 0.09462370786941345
Trained batch 386 in epoch 10, gen_loss = 0.39586307023692807, disc_loss = 0.09468751723904557
Trained batch 387 in epoch 10, gen_loss = 0.3957668270570101, disc_loss = 0.09487859449426155
Trained batch 388 in epoch 10, gen_loss = 0.39576582549317024, disc_loss = 0.09467532836944631
Trained batch 389 in epoch 10, gen_loss = 0.39575424985243723, disc_loss = 0.09468941488661445
Trained batch 390 in epoch 10, gen_loss = 0.3957616440246782, disc_loss = 0.09535784054014003
Trained batch 391 in epoch 10, gen_loss = 0.395880346281492, disc_loss = 0.09573031622412785
Trained batch 392 in epoch 10, gen_loss = 0.39615252155232367, disc_loss = 0.0958504200849028
Trained batch 393 in epoch 10, gen_loss = 0.39610002477308215, disc_loss = 0.09583034539160314
Trained batch 394 in epoch 10, gen_loss = 0.39605346695531773, disc_loss = 0.0957264193699141
Trained batch 395 in epoch 10, gen_loss = 0.39584455010716363, disc_loss = 0.09569142198876826
Trained batch 396 in epoch 10, gen_loss = 0.3956816176548413, disc_loss = 0.09557109803514982
Trained batch 397 in epoch 10, gen_loss = 0.3955523478400767, disc_loss = 0.0957233745805994
Trained batch 398 in epoch 10, gen_loss = 0.395672979248795, disc_loss = 0.09598981664471683
Trained batch 399 in epoch 10, gen_loss = 0.39575568955391643, disc_loss = 0.09588258255040273
Trained batch 400 in epoch 10, gen_loss = 0.39585479733503964, disc_loss = 0.09598037760073036
Trained batch 401 in epoch 10, gen_loss = 0.39587129085366407, disc_loss = 0.09611798348183286
Trained batch 402 in epoch 10, gen_loss = 0.39601566600000887, disc_loss = 0.09600955738498836
Trained batch 403 in epoch 10, gen_loss = 0.3960544653236866, disc_loss = 0.09588557150500762
Trained batch 404 in epoch 10, gen_loss = 0.3961504896113902, disc_loss = 0.09574858735510965
Trained batch 405 in epoch 10, gen_loss = 0.39614063710561526, disc_loss = 0.09579691353020042
Trained batch 406 in epoch 10, gen_loss = 0.3962983962432172, disc_loss = 0.09631860918646876
Trained batch 407 in epoch 10, gen_loss = 0.39635521812620117, disc_loss = 0.09638989833411853
Trained batch 408 in epoch 10, gen_loss = 0.3963704177321898, disc_loss = 0.09640811350706664
Trained batch 409 in epoch 10, gen_loss = 0.3963315792563485, disc_loss = 0.09638129668764589
Trained batch 410 in epoch 10, gen_loss = 0.3963260463917052, disc_loss = 0.0962476351812772
Trained batch 411 in epoch 10, gen_loss = 0.39612898038862976, disc_loss = 0.09681966987402332
Trained batch 412 in epoch 10, gen_loss = 0.39631911827201705, disc_loss = 0.09686166847002925
Trained batch 413 in epoch 10, gen_loss = 0.39652105888738726, disc_loss = 0.09687127879987233
Trained batch 414 in epoch 10, gen_loss = 0.3964046511664448, disc_loss = 0.09682031594979836
Trained batch 415 in epoch 10, gen_loss = 0.39627688001984585, disc_loss = 0.09675414756146403
Trained batch 416 in epoch 10, gen_loss = 0.396468256195958, disc_loss = 0.09668057610010572
Trained batch 417 in epoch 10, gen_loss = 0.3964560341678168, disc_loss = 0.09651229828908041
Trained batch 418 in epoch 10, gen_loss = 0.39631503148266695, disc_loss = 0.09655775591010908
Trained batch 419 in epoch 10, gen_loss = 0.3962196392317613, disc_loss = 0.09660923313127742
Trained batch 420 in epoch 10, gen_loss = 0.3962889832229909, disc_loss = 0.09640863101991366
Trained batch 421 in epoch 10, gen_loss = 0.3962270204701695, disc_loss = 0.09660076741482268
Trained batch 422 in epoch 10, gen_loss = 0.3961223218387464, disc_loss = 0.09692803461624235
Trained batch 423 in epoch 10, gen_loss = 0.396035211020202, disc_loss = 0.09677638239578677
Trained batch 424 in epoch 10, gen_loss = 0.3961446484046824, disc_loss = 0.09677699307746747
Trained batch 425 in epoch 10, gen_loss = 0.3959814377583808, disc_loss = 0.09689040749198255
Trained batch 426 in epoch 10, gen_loss = 0.395987866529257, disc_loss = 0.09675777776371819
Trained batch 427 in epoch 10, gen_loss = 0.39592664093475477, disc_loss = 0.09662549968408508
Trained batch 428 in epoch 10, gen_loss = 0.3957965420884686, disc_loss = 0.096508446763897
Trained batch 429 in epoch 10, gen_loss = 0.39579360114280565, disc_loss = 0.09656990550371797
Trained batch 430 in epoch 10, gen_loss = 0.3961578401847118, disc_loss = 0.09649711816621352
Trained batch 431 in epoch 10, gen_loss = 0.3962236728726162, disc_loss = 0.09633855623003372
Trained batch 432 in epoch 10, gen_loss = 0.3962935122207461, disc_loss = 0.09652797727658484
Trained batch 433 in epoch 10, gen_loss = 0.39640077931403017, disc_loss = 0.09671486572100682
Trained batch 434 in epoch 10, gen_loss = 0.39638896937342893, disc_loss = 0.09658920082809597
Trained batch 435 in epoch 10, gen_loss = 0.3963417566355762, disc_loss = 0.09650706212301183
Trained batch 436 in epoch 10, gen_loss = 0.3961792368978876, disc_loss = 0.09634460607709819
Trained batch 437 in epoch 10, gen_loss = 0.3963451628067178, disc_loss = 0.0963058426942183
Trained batch 438 in epoch 10, gen_loss = 0.39633182224081426, disc_loss = 0.09616187924268849
Trained batch 439 in epoch 10, gen_loss = 0.39620938108048653, disc_loss = 0.09603552229025147
Trained batch 440 in epoch 10, gen_loss = 0.39612840589076753, disc_loss = 0.09588245095478164
Trained batch 441 in epoch 10, gen_loss = 0.3961596164970376, disc_loss = 0.09570961431241952
Trained batch 442 in epoch 10, gen_loss = 0.3961172052417329, disc_loss = 0.09575282885749777
Trained batch 443 in epoch 10, gen_loss = 0.39599244521410615, disc_loss = 0.09610405474532026
Trained batch 444 in epoch 10, gen_loss = 0.39603436163971933, disc_loss = 0.09628803801168216
Trained batch 445 in epoch 10, gen_loss = 0.39583189802185836, disc_loss = 0.09631385645023109
Trained batch 446 in epoch 10, gen_loss = 0.3957227924192778, disc_loss = 0.09620356368905213
Trained batch 447 in epoch 10, gen_loss = 0.39551556632587953, disc_loss = 0.09612576363308888
Trained batch 448 in epoch 10, gen_loss = 0.3955585301785267, disc_loss = 0.09596450746324917
Trained batch 449 in epoch 10, gen_loss = 0.3956708840197987, disc_loss = 0.09603216883209016
Trained batch 450 in epoch 10, gen_loss = 0.3959028995420346, disc_loss = 0.09622980938385965
Trained batch 451 in epoch 10, gen_loss = 0.395769574770094, disc_loss = 0.09621603210019854
Trained batch 452 in epoch 10, gen_loss = 0.395614544649261, disc_loss = 0.09606052334800724
Trained batch 453 in epoch 10, gen_loss = 0.39567453617697773, disc_loss = 0.09601444857695554
Trained batch 454 in epoch 10, gen_loss = 0.3958130632455532, disc_loss = 0.09588292939486084
Trained batch 455 in epoch 10, gen_loss = 0.39590153702649106, disc_loss = 0.09570032372057699
Trained batch 456 in epoch 10, gen_loss = 0.3958535115163227, disc_loss = 0.09556973611434648
Trained batch 457 in epoch 10, gen_loss = 0.39595035788924415, disc_loss = 0.09546214351877895
Trained batch 458 in epoch 10, gen_loss = 0.3959147811650191, disc_loss = 0.09538145265937631
Trained batch 459 in epoch 10, gen_loss = 0.3956791401233362, disc_loss = 0.09531046830765579
Trained batch 460 in epoch 10, gen_loss = 0.3955466900174375, disc_loss = 0.0953730335721742
Testing Epoch 10
Training Epoch 11
Trained batch 0 in epoch 11, gen_loss = 0.3335522413253784, disc_loss = 0.13182371854782104
Trained batch 1 in epoch 11, gen_loss = 0.3244181126356125, disc_loss = 0.08616461604833603
Trained batch 2 in epoch 11, gen_loss = 0.35398048162460327, disc_loss = 0.06938457985719045
Trained batch 3 in epoch 11, gen_loss = 0.35474929958581924, disc_loss = 0.07125603966414928
Trained batch 4 in epoch 11, gen_loss = 0.35691938996315004, disc_loss = 0.06167569532990456
Trained batch 5 in epoch 11, gen_loss = 0.36639825999736786, disc_loss = 0.06081813325484594
Trained batch 6 in epoch 11, gen_loss = 0.37840433205877033, disc_loss = 0.05360395434711661
Trained batch 7 in epoch 11, gen_loss = 0.39200159162282944, disc_loss = 0.056493018520995975
Trained batch 8 in epoch 11, gen_loss = 0.3968499501546224, disc_loss = 0.055421903936399355
Trained batch 9 in epoch 11, gen_loss = 0.39476734697818755, disc_loss = 0.05221692863851786
Trained batch 10 in epoch 11, gen_loss = 0.4043029411272569, disc_loss = 0.048423460430719635
Trained batch 11 in epoch 11, gen_loss = 0.4057008996605873, disc_loss = 0.04664509308834871
Trained batch 12 in epoch 11, gen_loss = 0.40267285246115464, disc_loss = 0.045126741322187275
Trained batch 13 in epoch 11, gen_loss = 0.41052089631557465, disc_loss = 0.04651324504188129
Trained batch 14 in epoch 11, gen_loss = 0.4122913181781769, disc_loss = 0.0541451429327329
Trained batch 15 in epoch 11, gen_loss = 0.41392224840819836, disc_loss = 0.06302028195932508
Trained batch 16 in epoch 11, gen_loss = 0.40809175722739277, disc_loss = 0.07345113377360736
Trained batch 17 in epoch 11, gen_loss = 0.40769000351428986, disc_loss = 0.07331344361106555
Trained batch 18 in epoch 11, gen_loss = 0.4052901675826625, disc_loss = 0.07268930501059483
Trained batch 19 in epoch 11, gen_loss = 0.40666657239198684, disc_loss = 0.07273757979273796
Trained batch 20 in epoch 11, gen_loss = 0.4046857271875654, disc_loss = 0.07103177426116807
Trained batch 21 in epoch 11, gen_loss = 0.40606949546120386, disc_loss = 0.07445132071998986
Trained batch 22 in epoch 11, gen_loss = 0.4064499087955641, disc_loss = 0.07420143760416818
Trained batch 23 in epoch 11, gen_loss = 0.4084397181868553, disc_loss = 0.07239285266647737
Trained batch 24 in epoch 11, gen_loss = 0.4065548419952393, disc_loss = 0.07253008604049682
Trained batch 25 in epoch 11, gen_loss = 0.4027185978797766, disc_loss = 0.07250636042310642
Trained batch 26 in epoch 11, gen_loss = 0.40356950075538073, disc_loss = 0.07067934878998333
Trained batch 27 in epoch 11, gen_loss = 0.4050836307661874, disc_loss = 0.06851550278120808
Trained batch 28 in epoch 11, gen_loss = 0.40567315857985925, disc_loss = 0.06692900759135854
Trained batch 29 in epoch 11, gen_loss = 0.40552199482917783, disc_loss = 0.06572643822679917
Trained batch 30 in epoch 11, gen_loss = 0.40600649099196157, disc_loss = 0.06427599099134246
Trained batch 31 in epoch 11, gen_loss = 0.40523799508810043, disc_loss = 0.06358522869413719
Trained batch 32 in epoch 11, gen_loss = 0.4077389086737777, disc_loss = 0.06411799873140725
Trained batch 33 in epoch 11, gen_loss = 0.40676288219059215, disc_loss = 0.07423417001743526
Trained batch 34 in epoch 11, gen_loss = 0.40697731120245795, disc_loss = 0.07420611823243754
Trained batch 35 in epoch 11, gen_loss = 0.40810394949383205, disc_loss = 0.0751417522939543
Trained batch 36 in epoch 11, gen_loss = 0.40599572416898366, disc_loss = 0.08031342596419759
Trained batch 37 in epoch 11, gen_loss = 0.40687433983150284, disc_loss = 0.07890683133155107
Trained batch 38 in epoch 11, gen_loss = 0.40613596026714033, disc_loss = 0.07943570570876965
Trained batch 39 in epoch 11, gen_loss = 0.40738860964775087, disc_loss = 0.07935752528719604
Trained batch 40 in epoch 11, gen_loss = 0.40575009293672515, disc_loss = 0.08014931198118663
Trained batch 41 in epoch 11, gen_loss = 0.4062064744177319, disc_loss = 0.08049478040387233
Trained batch 42 in epoch 11, gen_loss = 0.40791229869044104, disc_loss = 0.08002554629604484
Trained batch 43 in epoch 11, gen_loss = 0.40464457734064624, disc_loss = 0.08622549834068526
Trained batch 44 in epoch 11, gen_loss = 0.4058731456597646, disc_loss = 0.08573867997361553
Trained batch 45 in epoch 11, gen_loss = 0.4055512722419656, disc_loss = 0.08791922668561987
Trained batch 46 in epoch 11, gen_loss = 0.4048247990456033, disc_loss = 0.08770001414132879
Trained batch 47 in epoch 11, gen_loss = 0.4021959987779458, disc_loss = 0.08770396936840068
Trained batch 48 in epoch 11, gen_loss = 0.4036494663783482, disc_loss = 0.08672103890198835
Trained batch 49 in epoch 11, gen_loss = 0.40291469275951386, disc_loss = 0.08591382216662169
Trained batch 50 in epoch 11, gen_loss = 0.401759782258202, disc_loss = 0.08694370248008008
Trained batch 51 in epoch 11, gen_loss = 0.4031459196255757, disc_loss = 0.09197906300855371
Trained batch 52 in epoch 11, gen_loss = 0.4021525141203178, disc_loss = 0.09223520541387908
Trained batch 53 in epoch 11, gen_loss = 0.4013667465360076, disc_loss = 0.09146566292340005
Trained batch 54 in epoch 11, gen_loss = 0.402475814927708, disc_loss = 0.09200614043934778
Trained batch 55 in epoch 11, gen_loss = 0.40057305299810003, disc_loss = 0.09159923494527382
Trained batch 56 in epoch 11, gen_loss = 0.39976486459113003, disc_loss = 0.0921541946825751
Trained batch 57 in epoch 11, gen_loss = 0.4003393377723365, disc_loss = 0.09710185155914776
Trained batch 58 in epoch 11, gen_loss = 0.4006117016582166, disc_loss = 0.09705375769507077
Trained batch 59 in epoch 11, gen_loss = 0.3993977750341097, disc_loss = 0.09796731003249685
Trained batch 60 in epoch 11, gen_loss = 0.39969177470832573, disc_loss = 0.09719323198937002
Trained batch 61 in epoch 11, gen_loss = 0.3989006502013053, disc_loss = 0.0973212752911833
Trained batch 62 in epoch 11, gen_loss = 0.3979725000404176, disc_loss = 0.09827889481352435
Trained batch 63 in epoch 11, gen_loss = 0.3985118782147765, disc_loss = 0.09869981746305712
Trained batch 64 in epoch 11, gen_loss = 0.3972424768484556, disc_loss = 0.0996087427609242
Trained batch 65 in epoch 11, gen_loss = 0.39733810542207776, disc_loss = 0.10008859117938713
Trained batch 66 in epoch 11, gen_loss = 0.3980302726154897, disc_loss = 0.10057478990238994
Trained batch 67 in epoch 11, gen_loss = 0.3971465063445708, disc_loss = 0.1016395957866574
Trained batch 68 in epoch 11, gen_loss = 0.39869575828745746, disc_loss = 0.10242793009872886
Trained batch 69 in epoch 11, gen_loss = 0.3990230705056872, disc_loss = 0.1012733622853245
Trained batch 70 in epoch 11, gen_loss = 0.40003199182765586, disc_loss = 0.10030487777901367
Trained batch 71 in epoch 11, gen_loss = 0.40081607674558956, disc_loss = 0.09927203741648959
Trained batch 72 in epoch 11, gen_loss = 0.400892243401645, disc_loss = 0.09827506493726006
Trained batch 73 in epoch 11, gen_loss = 0.3998615955178802, disc_loss = 0.09719149725562012
Trained batch 74 in epoch 11, gen_loss = 0.3997301137447357, disc_loss = 0.09644496974845727
Trained batch 75 in epoch 11, gen_loss = 0.3993758410215378, disc_loss = 0.09549723514110635
Trained batch 76 in epoch 11, gen_loss = 0.3996884540303961, disc_loss = 0.09550939430180308
Trained batch 77 in epoch 11, gen_loss = 0.40006929139296216, disc_loss = 0.09540364363541205
Trained batch 78 in epoch 11, gen_loss = 0.3999621109871925, disc_loss = 0.09513988305779197
Trained batch 79 in epoch 11, gen_loss = 0.39977417029440404, disc_loss = 0.09616652771364897
Trained batch 80 in epoch 11, gen_loss = 0.4006978343298406, disc_loss = 0.0988012236531502
Trained batch 81 in epoch 11, gen_loss = 0.40103214324974434, disc_loss = 0.09790619201503875
Trained batch 82 in epoch 11, gen_loss = 0.4008052686610854, disc_loss = 0.09747592052332608
Trained batch 83 in epoch 11, gen_loss = 0.4007719740981147, disc_loss = 0.0969628738461151
Trained batch 84 in epoch 11, gen_loss = 0.4014723812832552, disc_loss = 0.09592094211017384
Trained batch 85 in epoch 11, gen_loss = 0.40131892402504765, disc_loss = 0.09557020941445994
Trained batch 86 in epoch 11, gen_loss = 0.40135463900949764, disc_loss = 0.09537985860958867
Trained batch 87 in epoch 11, gen_loss = 0.40011248805306177, disc_loss = 0.09509322233498096
Trained batch 88 in epoch 11, gen_loss = 0.3994030815162016, disc_loss = 0.09632859990168154
Trained batch 89 in epoch 11, gen_loss = 0.399598604771826, disc_loss = 0.09879385183254878
Trained batch 90 in epoch 11, gen_loss = 0.4000990515226846, disc_loss = 0.09854800131294754
Trained batch 91 in epoch 11, gen_loss = 0.40006968346626864, disc_loss = 0.09836338792482148
Trained batch 92 in epoch 11, gen_loss = 0.40002137390516135, disc_loss = 0.09806314214903822
Trained batch 93 in epoch 11, gen_loss = 0.40072631296959327, disc_loss = 0.0972834624984163
Trained batch 94 in epoch 11, gen_loss = 0.40114438596524693, disc_loss = 0.09648219309747219
Trained batch 95 in epoch 11, gen_loss = 0.40060246425370377, disc_loss = 0.09657340607373044
Trained batch 96 in epoch 11, gen_loss = 0.40146237642494675, disc_loss = 0.0959861420824663
Trained batch 97 in epoch 11, gen_loss = 0.4015689689894112, disc_loss = 0.09573392708766826
Trained batch 98 in epoch 11, gen_loss = 0.40113083401111643, disc_loss = 0.09517424864073594
Trained batch 99 in epoch 11, gen_loss = 0.40129929304122924, disc_loss = 0.09513527961447835
Trained batch 100 in epoch 11, gen_loss = 0.40297484988033183, disc_loss = 0.09752267541935539
Trained batch 101 in epoch 11, gen_loss = 0.40240758774327295, disc_loss = 0.09734840422649593
Trained batch 102 in epoch 11, gen_loss = 0.4018581182632631, disc_loss = 0.09699547809810893
Trained batch 103 in epoch 11, gen_loss = 0.40208377545842755, disc_loss = 0.09708173821966809
Trained batch 104 in epoch 11, gen_loss = 0.401834674960091, disc_loss = 0.09818678517781552
Trained batch 105 in epoch 11, gen_loss = 0.40273957713594977, disc_loss = 0.0979012920573916
Trained batch 106 in epoch 11, gen_loss = 0.4024376587890019, disc_loss = 0.09766354605068113
Trained batch 107 in epoch 11, gen_loss = 0.4023720886972215, disc_loss = 0.09701640826339523
Trained batch 108 in epoch 11, gen_loss = 0.4020042799481558, disc_loss = 0.09791939252765354
Trained batch 109 in epoch 11, gen_loss = 0.4022391825914383, disc_loss = 0.09907638395035809
Trained batch 110 in epoch 11, gen_loss = 0.40182167586979567, disc_loss = 0.098584201405043
Trained batch 111 in epoch 11, gen_loss = 0.40257008613220285, disc_loss = 0.09797745748489563
Trained batch 112 in epoch 11, gen_loss = 0.4012954213977915, disc_loss = 0.09754426195492259
Trained batch 113 in epoch 11, gen_loss = 0.4025713064168629, disc_loss = 0.09689880918972847
Trained batch 114 in epoch 11, gen_loss = 0.4032397231330042, disc_loss = 0.09650606048171935
Trained batch 115 in epoch 11, gen_loss = 0.40345161844944133, disc_loss = 0.09599036445584276
Trained batch 116 in epoch 11, gen_loss = 0.40323933500509995, disc_loss = 0.09574379451954976
Trained batch 117 in epoch 11, gen_loss = 0.4034141668323743, disc_loss = 0.09718128083810462
Trained batch 118 in epoch 11, gen_loss = 0.40244616806006234, disc_loss = 0.0974521568561552
Trained batch 119 in epoch 11, gen_loss = 0.4024970332781474, disc_loss = 0.09723638077266514
Trained batch 120 in epoch 11, gen_loss = 0.4021342051915886, disc_loss = 0.0969907271190862
Trained batch 121 in epoch 11, gen_loss = 0.4019252203527044, disc_loss = 0.09659636391662672
Trained batch 122 in epoch 11, gen_loss = 0.40168078643519706, disc_loss = 0.09630755112483734
Trained batch 123 in epoch 11, gen_loss = 0.40195078474860035, disc_loss = 0.09596348423210363
Trained batch 124 in epoch 11, gen_loss = 0.40134957218170164, disc_loss = 0.09637948383390904
Trained batch 125 in epoch 11, gen_loss = 0.40105741411920576, disc_loss = 0.0961804651463079
Trained batch 126 in epoch 11, gen_loss = 0.40068875241467333, disc_loss = 0.09604226617421222
Trained batch 127 in epoch 11, gen_loss = 0.40073662530630827, disc_loss = 0.09566205089504365
Trained batch 128 in epoch 11, gen_loss = 0.4014807611472847, disc_loss = 0.0951114116568667
Trained batch 129 in epoch 11, gen_loss = 0.4015009180857585, disc_loss = 0.09475285443835534
Trained batch 130 in epoch 11, gen_loss = 0.4014237097656454, disc_loss = 0.09435783638014593
Trained batch 131 in epoch 11, gen_loss = 0.40173798009301676, disc_loss = 0.09399650625489427
Trained batch 132 in epoch 11, gen_loss = 0.4013662795375164, disc_loss = 0.09400142349750924
Trained batch 133 in epoch 11, gen_loss = 0.40142027077390185, disc_loss = 0.09438045902539101
Trained batch 134 in epoch 11, gen_loss = 0.40145119031270343, disc_loss = 0.09415157929890686
Trained batch 135 in epoch 11, gen_loss = 0.40124977905960646, disc_loss = 0.09386815647046794
Trained batch 136 in epoch 11, gen_loss = 0.4008414501691387, disc_loss = 0.09338623302968314
Trained batch 137 in epoch 11, gen_loss = 0.40102762869302777, disc_loss = 0.0929346388556819
Trained batch 138 in epoch 11, gen_loss = 0.4007481079307392, disc_loss = 0.09237617760119464
Trained batch 139 in epoch 11, gen_loss = 0.40113520473241804, disc_loss = 0.09266111746297351
Trained batch 140 in epoch 11, gen_loss = 0.4002563839263104, disc_loss = 0.09304887068900444
Trained batch 141 in epoch 11, gen_loss = 0.40025836565125156, disc_loss = 0.09311994649863369
Trained batch 142 in epoch 11, gen_loss = 0.4006969903732513, disc_loss = 0.0927360177860706
Trained batch 143 in epoch 11, gen_loss = 0.40022802394297385, disc_loss = 0.09248585687924384
Trained batch 144 in epoch 11, gen_loss = 0.4006287153424888, disc_loss = 0.09236450395065135
Trained batch 145 in epoch 11, gen_loss = 0.40057381660970925, disc_loss = 0.09240830061344864
Trained batch 146 in epoch 11, gen_loss = 0.40014492776118166, disc_loss = 0.09226606684249072
Trained batch 147 in epoch 11, gen_loss = 0.400488811972979, disc_loss = 0.09188292466884328
Trained batch 148 in epoch 11, gen_loss = 0.4002545663974429, disc_loss = 0.09220844036555731
Trained batch 149 in epoch 11, gen_loss = 0.40092599829037984, disc_loss = 0.09300287603711088
Trained batch 150 in epoch 11, gen_loss = 0.4014992536298487, disc_loss = 0.0924587549814424
Trained batch 151 in epoch 11, gen_loss = 0.40145211353113774, disc_loss = 0.09208268400796346
Trained batch 152 in epoch 11, gen_loss = 0.4012826268189873, disc_loss = 0.09162460136671666
Trained batch 153 in epoch 11, gen_loss = 0.4011585170572454, disc_loss = 0.09118766219705923
Trained batch 154 in epoch 11, gen_loss = 0.40067701974222736, disc_loss = 0.09201119050023056
Trained batch 155 in epoch 11, gen_loss = 0.40126435955365497, disc_loss = 0.097056516738704
Trained batch 156 in epoch 11, gen_loss = 0.40140387377921183, disc_loss = 0.09831236566826226
Trained batch 157 in epoch 11, gen_loss = 0.400501476624344, disc_loss = 0.09871446179178885
Trained batch 158 in epoch 11, gen_loss = 0.4002149671128711, disc_loss = 0.09923912189408855
Trained batch 159 in epoch 11, gen_loss = 0.4002388115972281, disc_loss = 0.09967624571290798
Trained batch 160 in epoch 11, gen_loss = 0.3994568786265687, disc_loss = 0.09997450248540743
Trained batch 161 in epoch 11, gen_loss = 0.3989603309719651, disc_loss = 0.09973537216514901
Trained batch 162 in epoch 11, gen_loss = 0.3984086029003003, disc_loss = 0.09950349622183234
Trained batch 163 in epoch 11, gen_loss = 0.39824940445946483, disc_loss = 0.0995101010619958
Trained batch 164 in epoch 11, gen_loss = 0.39858263116894344, disc_loss = 0.09968284238129854
Trained batch 165 in epoch 11, gen_loss = 0.39822884622108506, disc_loss = 0.09966527038332389
Trained batch 166 in epoch 11, gen_loss = 0.3980172993894109, disc_loss = 0.1005515145294056
Trained batch 167 in epoch 11, gen_loss = 0.39821490627669154, disc_loss = 0.10059424175415188
Trained batch 168 in epoch 11, gen_loss = 0.39767913634960467, disc_loss = 0.10060077460934601
Trained batch 169 in epoch 11, gen_loss = 0.3968845388468574, disc_loss = 0.10324791718603057
Trained batch 170 in epoch 11, gen_loss = 0.3971788593900134, disc_loss = 0.10357924037182714
Trained batch 171 in epoch 11, gen_loss = 0.39718197164840474, disc_loss = 0.10356978869043984
Trained batch 172 in epoch 11, gen_loss = 0.39702390969833196, disc_loss = 0.10359054864680318
Trained batch 173 in epoch 11, gen_loss = 0.39667156749758226, disc_loss = 0.10409871215300484
Trained batch 174 in epoch 11, gen_loss = 0.3965852086884635, disc_loss = 0.10459344081048455
Trained batch 175 in epoch 11, gen_loss = 0.3973101330074397, disc_loss = 0.10448168798624961
Trained batch 176 in epoch 11, gen_loss = 0.39729107604861935, disc_loss = 0.10406321788596062
Trained batch 177 in epoch 11, gen_loss = 0.3970046549030904, disc_loss = 0.10436289042255349
Trained batch 178 in epoch 11, gen_loss = 0.3971569891082508, disc_loss = 0.10451420696774841
Trained batch 179 in epoch 11, gen_loss = 0.39701199862692094, disc_loss = 0.10463887805429598
Trained batch 180 in epoch 11, gen_loss = 0.3971442940814719, disc_loss = 0.10539492310760594
Trained batch 181 in epoch 11, gen_loss = 0.3970262254332448, disc_loss = 0.10500568577733177
Trained batch 182 in epoch 11, gen_loss = 0.39645162143342483, disc_loss = 0.10507927131152055
Trained batch 183 in epoch 11, gen_loss = 0.39633233505098714, disc_loss = 0.10471541019986667
Trained batch 184 in epoch 11, gen_loss = 0.3964653683675302, disc_loss = 0.10421660601387958
Trained batch 185 in epoch 11, gen_loss = 0.3964282376791841, disc_loss = 0.10381160238357161
Trained batch 186 in epoch 11, gen_loss = 0.3963987296596568, disc_loss = 0.10349892510629115
Trained batch 187 in epoch 11, gen_loss = 0.3962543544934151, disc_loss = 0.10332300340102867
Trained batch 188 in epoch 11, gen_loss = 0.39623619828905376, disc_loss = 0.10328433501519381
Trained batch 189 in epoch 11, gen_loss = 0.39603690144262815, disc_loss = 0.10310640653203193
Trained batch 190 in epoch 11, gen_loss = 0.3961224746329622, disc_loss = 0.10278626947288269
Trained batch 191 in epoch 11, gen_loss = 0.3962297461306055, disc_loss = 0.10261687355523463
Trained batch 192 in epoch 11, gen_loss = 0.3961007886908833, disc_loss = 0.10225269088878687
Trained batch 193 in epoch 11, gen_loss = 0.39581538368131697, disc_loss = 0.10276041631634857
Trained batch 194 in epoch 11, gen_loss = 0.39605872615789756, disc_loss = 0.10287155339446588
Trained batch 195 in epoch 11, gen_loss = 0.3966003889027907, disc_loss = 0.10240129947814407
Trained batch 196 in epoch 11, gen_loss = 0.3963162855145895, disc_loss = 0.10214145058000149
Trained batch 197 in epoch 11, gen_loss = 0.3970443388127317, disc_loss = 0.10170173240505685
Trained batch 198 in epoch 11, gen_loss = 0.3971268934520645, disc_loss = 0.10137128317026636
Trained batch 199 in epoch 11, gen_loss = 0.39701429232954977, disc_loss = 0.10092570233624429
Trained batch 200 in epoch 11, gen_loss = 0.3970010212404811, disc_loss = 0.10133712441748499
Trained batch 201 in epoch 11, gen_loss = 0.39706473214791554, disc_loss = 0.1022350117886937
Trained batch 202 in epoch 11, gen_loss = 0.39753797576932487, disc_loss = 0.10216571236020092
Trained batch 203 in epoch 11, gen_loss = 0.3982366682852016, disc_loss = 0.10201074489319295
Trained batch 204 in epoch 11, gen_loss = 0.39800736816917975, disc_loss = 0.10194309695010505
Trained batch 205 in epoch 11, gen_loss = 0.3979261374299966, disc_loss = 0.10177765677692098
Trained batch 206 in epoch 11, gen_loss = 0.3979196273474302, disc_loss = 0.10148819971037804
Trained batch 207 in epoch 11, gen_loss = 0.398218762416106, disc_loss = 0.1010383030336995
Trained batch 208 in epoch 11, gen_loss = 0.39878606653669807, disc_loss = 0.10064822133701812
Trained batch 209 in epoch 11, gen_loss = 0.39893831113974254, disc_loss = 0.1003906501324049
Trained batch 210 in epoch 11, gen_loss = 0.3987554663447972, disc_loss = 0.10007070574768205
Trained batch 211 in epoch 11, gen_loss = 0.3987270067885237, disc_loss = 0.10025202565088447
Trained batch 212 in epoch 11, gen_loss = 0.3985589325707843, disc_loss = 0.1001527509630216
Trained batch 213 in epoch 11, gen_loss = 0.3983654113851975, disc_loss = 0.099871949697453
Trained batch 214 in epoch 11, gen_loss = 0.3987202940985214, disc_loss = 0.1000249519034527
Trained batch 215 in epoch 11, gen_loss = 0.39828554913401604, disc_loss = 0.10049191153073614
Trained batch 216 in epoch 11, gen_loss = 0.3980621133806519, disc_loss = 0.10084890743743302
Trained batch 217 in epoch 11, gen_loss = 0.3977801196892327, disc_loss = 0.10063213832385906
Trained batch 218 in epoch 11, gen_loss = 0.39799919425080355, disc_loss = 0.10057815934476107
Trained batch 219 in epoch 11, gen_loss = 0.39780974008820275, disc_loss = 0.10093160533684899
Trained batch 220 in epoch 11, gen_loss = 0.39800452997242164, disc_loss = 0.10088001071513374
Trained batch 221 in epoch 11, gen_loss = 0.3977969909036482, disc_loss = 0.10055910756073154
Trained batch 222 in epoch 11, gen_loss = 0.39767386293197426, disc_loss = 0.10027053267715891
Trained batch 223 in epoch 11, gen_loss = 0.3973986404016614, disc_loss = 0.10035620620224758
Trained batch 224 in epoch 11, gen_loss = 0.3976302950912052, disc_loss = 0.10153985013978349
Trained batch 225 in epoch 11, gen_loss = 0.3975423886976411, disc_loss = 0.10146005455388037
Trained batch 226 in epoch 11, gen_loss = 0.39707846749196496, disc_loss = 0.10193675379412422
Trained batch 227 in epoch 11, gen_loss = 0.3972756197316605, disc_loss = 0.10193916577273947
Trained batch 228 in epoch 11, gen_loss = 0.39752564628051357, disc_loss = 0.10177820111222273
Trained batch 229 in epoch 11, gen_loss = 0.3974685381288114, disc_loss = 0.1016324577488653
Trained batch 230 in epoch 11, gen_loss = 0.39745346214864163, disc_loss = 0.10188019472815386
Trained batch 231 in epoch 11, gen_loss = 0.3975889768836827, disc_loss = 0.10185870435490305
Trained batch 232 in epoch 11, gen_loss = 0.3973619974989748, disc_loss = 0.10188859477719141
Trained batch 233 in epoch 11, gen_loss = 0.3973705003149489, disc_loss = 0.10150076099870424
Trained batch 234 in epoch 11, gen_loss = 0.3974674550776786, disc_loss = 0.10129868222915746
Trained batch 235 in epoch 11, gen_loss = 0.3972396065117949, disc_loss = 0.10096971713937819
Trained batch 236 in epoch 11, gen_loss = 0.39698797502095184, disc_loss = 0.10062781686379814
Trained batch 237 in epoch 11, gen_loss = 0.396904203070312, disc_loss = 0.10038300174358888
Trained batch 238 in epoch 11, gen_loss = 0.3970862117023149, disc_loss = 0.10016449191315278
Trained batch 239 in epoch 11, gen_loss = 0.39690550925831, disc_loss = 0.10019693784027671
Trained batch 240 in epoch 11, gen_loss = 0.3966463940272193, disc_loss = 0.10083600173460869
Trained batch 241 in epoch 11, gen_loss = 0.3971362815908164, disc_loss = 0.10073043839728907
Trained batch 242 in epoch 11, gen_loss = 0.3971177084455765, disc_loss = 0.10067133080796818
Trained batch 243 in epoch 11, gen_loss = 0.3972848282485712, disc_loss = 0.10064334571590555
Trained batch 244 in epoch 11, gen_loss = 0.3973386560167585, disc_loss = 0.10034792275377075
Trained batch 245 in epoch 11, gen_loss = 0.39709672901203963, disc_loss = 0.10002462199048662
Trained batch 246 in epoch 11, gen_loss = 0.39758173065629565, disc_loss = 0.09983271034245911
Trained batch 247 in epoch 11, gen_loss = 0.3975319473012801, disc_loss = 0.09964496032109545
Trained batch 248 in epoch 11, gen_loss = 0.39766911270628014, disc_loss = 0.09972377441240003
Trained batch 249 in epoch 11, gen_loss = 0.3978129849433899, disc_loss = 0.09982419320568442
Trained batch 250 in epoch 11, gen_loss = 0.39775003095072103, disc_loss = 0.09979245965684434
Trained batch 251 in epoch 11, gen_loss = 0.39797807579475736, disc_loss = 0.10013295103618432
Trained batch 252 in epoch 11, gen_loss = 0.3976672471983159, disc_loss = 0.10031508341829179
Trained batch 253 in epoch 11, gen_loss = 0.3977703080167921, disc_loss = 0.10020137055755013
Trained batch 254 in epoch 11, gen_loss = 0.39775625046561747, disc_loss = 0.10078431203888327
Trained batch 255 in epoch 11, gen_loss = 0.39768614806234837, disc_loss = 0.10049378832991351
Trained batch 256 in epoch 11, gen_loss = 0.3977622637952812, disc_loss = 0.10032958972561336
Trained batch 257 in epoch 11, gen_loss = 0.3974866219038187, disc_loss = 0.10031235925925448
Trained batch 258 in epoch 11, gen_loss = 0.39724675810475146, disc_loss = 0.10024615299877168
Trained batch 259 in epoch 11, gen_loss = 0.3975395345917115, disc_loss = 0.10001649236521469
Trained batch 260 in epoch 11, gen_loss = 0.39798493140958735, disc_loss = 0.09973452748709369
Trained batch 261 in epoch 11, gen_loss = 0.39767316325020247, disc_loss = 0.0998568148423299
Trained batch 262 in epoch 11, gen_loss = 0.397741750845891, disc_loss = 0.0997199700621201
Trained batch 263 in epoch 11, gen_loss = 0.39784347525600233, disc_loss = 0.09947558646584212
Trained batch 264 in epoch 11, gen_loss = 0.39807399095229384, disc_loss = 0.0991757801435185
Trained batch 265 in epoch 11, gen_loss = 0.3978354396452581, disc_loss = 0.09929277913476851
Trained batch 266 in epoch 11, gen_loss = 0.39842772517311437, disc_loss = 0.10002616039836563
Trained batch 267 in epoch 11, gen_loss = 0.3986705424847887, disc_loss = 0.09971401639241002
Trained batch 268 in epoch 11, gen_loss = 0.39851411700691874, disc_loss = 0.09970769185406679
Trained batch 269 in epoch 11, gen_loss = 0.3986981604938154, disc_loss = 0.09943632543845861
Trained batch 270 in epoch 11, gen_loss = 0.3986952375221956, disc_loss = 0.09933037923587094
Trained batch 271 in epoch 11, gen_loss = 0.3986969778642935, disc_loss = 0.09940153379198712
Trained batch 272 in epoch 11, gen_loss = 0.39856263525756724, disc_loss = 0.099600741684082
Trained batch 273 in epoch 11, gen_loss = 0.39828671504111185, disc_loss = 0.10038116647365646
Trained batch 274 in epoch 11, gen_loss = 0.39838844136758284, disc_loss = 0.100295096822083
Trained batch 275 in epoch 11, gen_loss = 0.3985844431579977, disc_loss = 0.1003663948284921
Trained batch 276 in epoch 11, gen_loss = 0.3985284335561608, disc_loss = 0.10034891150367281
Trained batch 277 in epoch 11, gen_loss = 0.3989753906460975, disc_loss = 0.10020003231617508
Trained batch 278 in epoch 11, gen_loss = 0.3990318075516745, disc_loss = 0.09995213196042084
Trained batch 279 in epoch 11, gen_loss = 0.398914526615824, disc_loss = 0.09992498276156507
Trained batch 280 in epoch 11, gen_loss = 0.3987816869151974, disc_loss = 0.09996684499787584
Trained batch 281 in epoch 11, gen_loss = 0.398480641926434, disc_loss = 0.09978298462121517
Trained batch 282 in epoch 11, gen_loss = 0.3983985913305316, disc_loss = 0.09945707912672008
Trained batch 283 in epoch 11, gen_loss = 0.3983995413906138, disc_loss = 0.09915735365652388
Trained batch 284 in epoch 11, gen_loss = 0.39840817357364455, disc_loss = 0.09901744841287534
Trained batch 285 in epoch 11, gen_loss = 0.398185034627681, disc_loss = 0.099202930904482
Trained batch 286 in epoch 11, gen_loss = 0.3988778974328722, disc_loss = 0.09956233128450992
Trained batch 287 in epoch 11, gen_loss = 0.3987485062744882, disc_loss = 0.09936917030265452
Trained batch 288 in epoch 11, gen_loss = 0.39843190902244674, disc_loss = 0.09974110333062064
Trained batch 289 in epoch 11, gen_loss = 0.3985853007127499, disc_loss = 0.0994751569365376
Trained batch 290 in epoch 11, gen_loss = 0.398694627371031, disc_loss = 0.09979379083321165
Trained batch 291 in epoch 11, gen_loss = 0.3986251794107973, disc_loss = 0.0999945814829728
Trained batch 292 in epoch 11, gen_loss = 0.3987347728766679, disc_loss = 0.09997523149774241
Trained batch 293 in epoch 11, gen_loss = 0.3985841605736285, disc_loss = 0.10000614257732114
Trained batch 294 in epoch 11, gen_loss = 0.3987555942292941, disc_loss = 0.10007666671111927
Trained batch 295 in epoch 11, gen_loss = 0.39871652978094846, disc_loss = 0.0998316280185119
Trained batch 296 in epoch 11, gen_loss = 0.3987783399294523, disc_loss = 0.09953925345619821
Trained batch 297 in epoch 11, gen_loss = 0.39878196744310773, disc_loss = 0.09923331335737001
Trained batch 298 in epoch 11, gen_loss = 0.3988318873887078, disc_loss = 0.09903005912999645
Trained batch 299 in epoch 11, gen_loss = 0.3989341191450755, disc_loss = 0.09887627881020307
Trained batch 300 in epoch 11, gen_loss = 0.3992505717119109, disc_loss = 0.0997967000345257
Trained batch 301 in epoch 11, gen_loss = 0.3988941193416419, disc_loss = 0.09982954129724708
Trained batch 302 in epoch 11, gen_loss = 0.39890048704525033, disc_loss = 0.09968144153997843
Trained batch 303 in epoch 11, gen_loss = 0.39921656780337034, disc_loss = 0.09948212272291512
Trained batch 304 in epoch 11, gen_loss = 0.3991064749780248, disc_loss = 0.09934532009675855
Trained batch 305 in epoch 11, gen_loss = 0.39883143897929224, disc_loss = 0.09956914885273946
Trained batch 306 in epoch 11, gen_loss = 0.3989113099411955, disc_loss = 0.0993765621091139
Trained batch 307 in epoch 11, gen_loss = 0.3990616411357731, disc_loss = 0.09909619279689603
Trained batch 308 in epoch 11, gen_loss = 0.3989507748856899, disc_loss = 0.098888722631152
Trained batch 309 in epoch 11, gen_loss = 0.39882003886084405, disc_loss = 0.09861174380526908
Trained batch 310 in epoch 11, gen_loss = 0.39870578711822485, disc_loss = 0.09842377005989433
Trained batch 311 in epoch 11, gen_loss = 0.39848695599879974, disc_loss = 0.09834661961306268
Trained batch 312 in epoch 11, gen_loss = 0.39877483753350595, disc_loss = 0.09822273473091685
Trained batch 313 in epoch 11, gen_loss = 0.39865716456607647, disc_loss = 0.09808201471841924
Trained batch 314 in epoch 11, gen_loss = 0.3986889017952813, disc_loss = 0.09795775517289128
Trained batch 315 in epoch 11, gen_loss = 0.3988554900205588, disc_loss = 0.09804392157747305
Trained batch 316 in epoch 11, gen_loss = 0.3986330093457496, disc_loss = 0.09781399108645762
Trained batch 317 in epoch 11, gen_loss = 0.39864909330254084, disc_loss = 0.09862111408392307
Trained batch 318 in epoch 11, gen_loss = 0.39869520469892733, disc_loss = 0.09902572494327182
Trained batch 319 in epoch 11, gen_loss = 0.39846022222191096, disc_loss = 0.09898019908287096
Trained batch 320 in epoch 11, gen_loss = 0.39822170194064344, disc_loss = 0.09890023547274022
Trained batch 321 in epoch 11, gen_loss = 0.39825292357376646, disc_loss = 0.09870155631443081
Trained batch 322 in epoch 11, gen_loss = 0.3985423515824711, disc_loss = 0.0986225466984944
Trained batch 323 in epoch 11, gen_loss = 0.3984433912016727, disc_loss = 0.09861485272887405
Trained batch 324 in epoch 11, gen_loss = 0.3982246165092175, disc_loss = 0.09842550984082314
Trained batch 325 in epoch 11, gen_loss = 0.3978202215001627, disc_loss = 0.09835444635603051
Trained batch 326 in epoch 11, gen_loss = 0.3978535717051328, disc_loss = 0.09838741730944188
Trained batch 327 in epoch 11, gen_loss = 0.3977885524310717, disc_loss = 0.09885474826243319
Trained batch 328 in epoch 11, gen_loss = 0.3978700466612552, disc_loss = 0.09889960008472386
Trained batch 329 in epoch 11, gen_loss = 0.3978353134610436, disc_loss = 0.09874421730919769
Trained batch 330 in epoch 11, gen_loss = 0.39801480501800146, disc_loss = 0.09853440871197741
Trained batch 331 in epoch 11, gen_loss = 0.3979981166411595, disc_loss = 0.09854053817296693
Trained batch 332 in epoch 11, gen_loss = 0.3983121976122126, disc_loss = 0.09984011598233436
Trained batch 333 in epoch 11, gen_loss = 0.3981781980234706, disc_loss = 0.09994673375653738
Trained batch 334 in epoch 11, gen_loss = 0.39816637475099137, disc_loss = 0.09986904949895037
Trained batch 335 in epoch 11, gen_loss = 0.3978351354598999, disc_loss = 0.09984884385873254
Trained batch 336 in epoch 11, gen_loss = 0.3978592259063211, disc_loss = 0.09965790287820893
Trained batch 337 in epoch 11, gen_loss = 0.3977316333168357, disc_loss = 0.09945103028216042
Trained batch 338 in epoch 11, gen_loss = 0.3979402894819029, disc_loss = 0.0993107750072284
Trained batch 339 in epoch 11, gen_loss = 0.39784470691400414, disc_loss = 0.09935749719083747
Trained batch 340 in epoch 11, gen_loss = 0.398116559838969, disc_loss = 0.09920883103604278
Trained batch 341 in epoch 11, gen_loss = 0.39801850984668175, disc_loss = 0.09904613976818863
Trained batch 342 in epoch 11, gen_loss = 0.3980274028402723, disc_loss = 0.09907377514792688
Trained batch 343 in epoch 11, gen_loss = 0.3979948763410712, disc_loss = 0.09883676847540449
Trained batch 344 in epoch 11, gen_loss = 0.3982810550841732, disc_loss = 0.09859019842646692
Trained batch 345 in epoch 11, gen_loss = 0.3982215692542192, disc_loss = 0.09848296040173814
Trained batch 346 in epoch 11, gen_loss = 0.3978963538102526, disc_loss = 0.09840777792004327
Trained batch 347 in epoch 11, gen_loss = 0.3981160706487195, disc_loss = 0.09817311591361703
Trained batch 348 in epoch 11, gen_loss = 0.39822169327121065, disc_loss = 0.098210349057222
Trained batch 349 in epoch 11, gen_loss = 0.3980170374257224, disc_loss = 0.09893249309222613
Trained batch 350 in epoch 11, gen_loss = 0.3982540462431405, disc_loss = 0.09956998874478445
Trained batch 351 in epoch 11, gen_loss = 0.3982174306769263, disc_loss = 0.09944626206098209
Trained batch 352 in epoch 11, gen_loss = 0.3981753759107238, disc_loss = 0.09933158249538866
Trained batch 353 in epoch 11, gen_loss = 0.39810545700418076, disc_loss = 0.09915249348265556
Trained batch 354 in epoch 11, gen_loss = 0.3980406787193997, disc_loss = 0.09894871686283552
Trained batch 355 in epoch 11, gen_loss = 0.3980647469504496, disc_loss = 0.09874895394758813
Trained batch 356 in epoch 11, gen_loss = 0.397935358082213, disc_loss = 0.09858443087921674
Trained batch 357 in epoch 11, gen_loss = 0.39776846300290286, disc_loss = 0.09841558494079629
Trained batch 358 in epoch 11, gen_loss = 0.3976747006759006, disc_loss = 0.09842446129665318
Trained batch 359 in epoch 11, gen_loss = 0.39782926614085834, disc_loss = 0.09849467971620875
Trained batch 360 in epoch 11, gen_loss = 0.3975638782713882, disc_loss = 0.0986365577556874
Trained batch 361 in epoch 11, gen_loss = 0.3976144740430031, disc_loss = 0.09860742885300386
Trained batch 362 in epoch 11, gen_loss = 0.39760129395923666, disc_loss = 0.09878493228429523
Trained batch 363 in epoch 11, gen_loss = 0.39737466820976236, disc_loss = 0.09983492473519029
Trained batch 364 in epoch 11, gen_loss = 0.3974642765032102, disc_loss = 0.10009087228968944
Trained batch 365 in epoch 11, gen_loss = 0.3973837441922537, disc_loss = 0.09986946773282736
Trained batch 366 in epoch 11, gen_loss = 0.39721478306630004, disc_loss = 0.09975544747716318
Trained batch 367 in epoch 11, gen_loss = 0.39707188049088354, disc_loss = 0.09956401761408652
Trained batch 368 in epoch 11, gen_loss = 0.39714929736080534, disc_loss = 0.09939298162686065
Trained batch 369 in epoch 11, gen_loss = 0.3971764305958877, disc_loss = 0.09934705366707734
Trained batch 370 in epoch 11, gen_loss = 0.3970462988329062, disc_loss = 0.09958014478329619
Trained batch 371 in epoch 11, gen_loss = 0.3971367295711271, disc_loss = 0.09957461932083211
Trained batch 372 in epoch 11, gen_loss = 0.3973263499724002, disc_loss = 0.09946318487848976
Trained batch 373 in epoch 11, gen_loss = 0.39731132163402233, disc_loss = 0.09935831980540712
Trained batch 374 in epoch 11, gen_loss = 0.3972829612096151, disc_loss = 0.0992519753947854
Trained batch 375 in epoch 11, gen_loss = 0.3969856507759145, disc_loss = 0.09930177371542742
Trained batch 376 in epoch 11, gen_loss = 0.3968481317913501, disc_loss = 0.09911426962835007
Trained batch 377 in epoch 11, gen_loss = 0.3968359993563758, disc_loss = 0.0988989715198321
Trained batch 378 in epoch 11, gen_loss = 0.39690077123981665, disc_loss = 0.09873384663633668
Trained batch 379 in epoch 11, gen_loss = 0.39673553140539874, disc_loss = 0.09870865858454062
Trained batch 380 in epoch 11, gen_loss = 0.3969162648587715, disc_loss = 0.09872164342337315
Trained batch 381 in epoch 11, gen_loss = 0.39704129123250853, disc_loss = 0.09858987666422706
Trained batch 382 in epoch 11, gen_loss = 0.3969449824981839, disc_loss = 0.09848832661728557
Trained batch 383 in epoch 11, gen_loss = 0.39696413263057667, disc_loss = 0.09845480312894021
Trained batch 384 in epoch 11, gen_loss = 0.39709610691318264, disc_loss = 0.09931098011552127
Trained batch 385 in epoch 11, gen_loss = 0.3971180424789073, disc_loss = 0.0993099349666715
Trained batch 386 in epoch 11, gen_loss = 0.3970569633236227, disc_loss = 0.09937191750488462
Trained batch 387 in epoch 11, gen_loss = 0.3973338434223047, disc_loss = 0.09941280485111643
Trained batch 388 in epoch 11, gen_loss = 0.39725269879044484, disc_loss = 0.09934829782388127
Trained batch 389 in epoch 11, gen_loss = 0.3973441536609943, disc_loss = 0.09933677970742186
Trained batch 390 in epoch 11, gen_loss = 0.397106243597577, disc_loss = 0.09925432794529687
Trained batch 391 in epoch 11, gen_loss = 0.39692175654428347, disc_loss = 0.09920954059723917
Trained batch 392 in epoch 11, gen_loss = 0.39689557424938404, disc_loss = 0.099268114822265
Trained batch 393 in epoch 11, gen_loss = 0.39689735122743597, disc_loss = 0.0994636696281129
Trained batch 394 in epoch 11, gen_loss = 0.3966828827616535, disc_loss = 0.09961770723656385
Trained batch 395 in epoch 11, gen_loss = 0.3967748519898665, disc_loss = 0.09946967733581785
Trained batch 396 in epoch 11, gen_loss = 0.3967344522926609, disc_loss = 0.09937802235588844
Trained batch 397 in epoch 11, gen_loss = 0.39662170889389575, disc_loss = 0.09918548559170946
Trained batch 398 in epoch 11, gen_loss = 0.39666441075485154, disc_loss = 0.09900385279787288
Trained batch 399 in epoch 11, gen_loss = 0.3966739635169506, disc_loss = 0.09885012270184233
Trained batch 400 in epoch 11, gen_loss = 0.39655935898088757, disc_loss = 0.09890060311884728
Trained batch 401 in epoch 11, gen_loss = 0.3967344184864813, disc_loss = 0.09870094101903822
Trained batch 402 in epoch 11, gen_loss = 0.3967880288661266, disc_loss = 0.09853738828541402
Trained batch 403 in epoch 11, gen_loss = 0.3968565895563305, disc_loss = 0.09838359448182775
Trained batch 404 in epoch 11, gen_loss = 0.3969329252655123, disc_loss = 0.09830229866697833
Trained batch 405 in epoch 11, gen_loss = 0.39669460726195366, disc_loss = 0.09826908641600329
Trained batch 406 in epoch 11, gen_loss = 0.3968813833792028, disc_loss = 0.09807226041913106
Trained batch 407 in epoch 11, gen_loss = 0.3970428330495077, disc_loss = 0.09817591366385493
Trained batch 408 in epoch 11, gen_loss = 0.3968656094412349, disc_loss = 0.0982598852398088
Trained batch 409 in epoch 11, gen_loss = 0.3969775021803088, disc_loss = 0.09808715004246772
Trained batch 410 in epoch 11, gen_loss = 0.39697938193079907, disc_loss = 0.09816240637343368
Trained batch 411 in epoch 11, gen_loss = 0.39685659812202734, disc_loss = 0.09852520257315951
Trained batch 412 in epoch 11, gen_loss = 0.3968075882580321, disc_loss = 0.09890898322736164
Trained batch 413 in epoch 11, gen_loss = 0.3966744121002114, disc_loss = 0.09879095028357013
Trained batch 414 in epoch 11, gen_loss = 0.39685540809688796, disc_loss = 0.0986714930890734
Trained batch 415 in epoch 11, gen_loss = 0.39710235581375086, disc_loss = 0.09853570708834852
Trained batch 416 in epoch 11, gen_loss = 0.3970570816553468, disc_loss = 0.09851609268035892
Trained batch 417 in epoch 11, gen_loss = 0.3970957441193065, disc_loss = 0.09835974516739186
Trained batch 418 in epoch 11, gen_loss = 0.3970304726131776, disc_loss = 0.09837907569834113
Trained batch 419 in epoch 11, gen_loss = 0.3972242811606044, disc_loss = 0.09918099786598412
Trained batch 420 in epoch 11, gen_loss = 0.39706669956658064, disc_loss = 0.09914984333941673
Trained batch 421 in epoch 11, gen_loss = 0.3967788118462992, disc_loss = 0.0994793345193904
Trained batch 422 in epoch 11, gen_loss = 0.3968145772638614, disc_loss = 0.09975148093871261
Trained batch 423 in epoch 11, gen_loss = 0.3969046527625255, disc_loss = 0.09973360033363174
Trained batch 424 in epoch 11, gen_loss = 0.39691488707766814, disc_loss = 0.09970165874370757
Trained batch 425 in epoch 11, gen_loss = 0.39675547623298535, disc_loss = 0.09972090614487378
Trained batch 426 in epoch 11, gen_loss = 0.396772102254336, disc_loss = 0.09959793207944487
Trained batch 427 in epoch 11, gen_loss = 0.39665614096360785, disc_loss = 0.0996226445210349
Trained batch 428 in epoch 11, gen_loss = 0.39663218437652764, disc_loss = 0.09970090074772948
Trained batch 429 in epoch 11, gen_loss = 0.39644881861154424, disc_loss = 0.0995692741840558
Trained batch 430 in epoch 11, gen_loss = 0.3965259407346597, disc_loss = 0.09938758406615243
Trained batch 431 in epoch 11, gen_loss = 0.3964836382203632, disc_loss = 0.09927985882515916
Trained batch 432 in epoch 11, gen_loss = 0.3962735416707486, disc_loss = 0.09930873409077078
Trained batch 433 in epoch 11, gen_loss = 0.39644020843890404, disc_loss = 0.09964328434120881
Trained batch 434 in epoch 11, gen_loss = 0.3963565497562803, disc_loss = 0.09954138511856055
Trained batch 435 in epoch 11, gen_loss = 0.39623054978224115, disc_loss = 0.09971594363408283
Trained batch 436 in epoch 11, gen_loss = 0.39626850054793283, disc_loss = 0.09969555728725697
Trained batch 437 in epoch 11, gen_loss = 0.3964721951038326, disc_loss = 0.09959822269496785
Trained batch 438 in epoch 11, gen_loss = 0.3964979296936261, disc_loss = 0.09948896667400295
Trained batch 439 in epoch 11, gen_loss = 0.3964936806397005, disc_loss = 0.0995001505869864
Trained batch 440 in epoch 11, gen_loss = 0.39657969809984134, disc_loss = 0.09988089931110879
Trained batch 441 in epoch 11, gen_loss = 0.39640046042554516, disc_loss = 0.09975684395194795
Trained batch 442 in epoch 11, gen_loss = 0.3964479579075195, disc_loss = 0.09978017057702114
Trained batch 443 in epoch 11, gen_loss = 0.39659817476530335, disc_loss = 0.09975073291701977
Trained batch 444 in epoch 11, gen_loss = 0.3965148546722498, disc_loss = 0.09987793608118643
Trained batch 445 in epoch 11, gen_loss = 0.3965036287703322, disc_loss = 0.09994483441573822
Trained batch 446 in epoch 11, gen_loss = 0.3963365596146125, disc_loss = 0.09980207998138879
Trained batch 447 in epoch 11, gen_loss = 0.3963154970136072, disc_loss = 0.0996564034950487
Trained batch 448 in epoch 11, gen_loss = 0.3963759200344638, disc_loss = 0.09947589212999511
Trained batch 449 in epoch 11, gen_loss = 0.39608912812338937, disc_loss = 0.09952043570371137
Trained batch 450 in epoch 11, gen_loss = 0.39617498579152144, disc_loss = 0.09966897548789658
Trained batch 451 in epoch 11, gen_loss = 0.3960589080125885, disc_loss = 0.09957426044455342
Trained batch 452 in epoch 11, gen_loss = 0.3961398932449602, disc_loss = 0.09942165941254916
Trained batch 453 in epoch 11, gen_loss = 0.3961273683850461, disc_loss = 0.09962097610991104
Trained batch 454 in epoch 11, gen_loss = 0.3959623138328175, disc_loss = 0.0996177930732841
Trained batch 455 in epoch 11, gen_loss = 0.3959824352018666, disc_loss = 0.09946989771101232
Trained batch 456 in epoch 11, gen_loss = 0.39583387220975347, disc_loss = 0.09947031829098578
Trained batch 457 in epoch 11, gen_loss = 0.39580956003811685, disc_loss = 0.09936639830657162
Trained batch 458 in epoch 11, gen_loss = 0.3959107330162281, disc_loss = 0.09919653280814683
Trained batch 459 in epoch 11, gen_loss = 0.3958346226940984, disc_loss = 0.09907679472564031
Trained batch 460 in epoch 11, gen_loss = 0.39584836441368965, disc_loss = 0.09924388949005762
Testing Epoch 11
Training Epoch 12
Trained batch 0 in epoch 12, gen_loss = 0.33963900804519653, disc_loss = 0.5302717685699463
Trained batch 1 in epoch 12, gen_loss = 0.49584612250328064, disc_loss = 0.3630959689617157
Trained batch 2 in epoch 12, gen_loss = 0.5047797759373983, disc_loss = 0.24615222960710526
Trained batch 3 in epoch 12, gen_loss = 0.4698513224720955, disc_loss = 0.2113544512540102
Trained batch 4 in epoch 12, gen_loss = 0.45762609243392943, disc_loss = 0.17538989782333375
Trained batch 5 in epoch 12, gen_loss = 0.451710507273674, disc_loss = 0.15915992110967636
Trained batch 6 in epoch 12, gen_loss = 0.4411847804273878, disc_loss = 0.14723576392446244
Trained batch 7 in epoch 12, gen_loss = 0.43426117300987244, disc_loss = 0.14097033347934484
Trained batch 8 in epoch 12, gen_loss = 0.4359541204240587, disc_loss = 0.1523622531029913
Trained batch 9 in epoch 12, gen_loss = 0.43171410262584686, disc_loss = 0.14522348567843438
Trained batch 10 in epoch 12, gen_loss = 0.4315372678366574, disc_loss = 0.13503663749857384
Trained batch 11 in epoch 12, gen_loss = 0.4268201142549515, disc_loss = 0.12898348085582256
Trained batch 12 in epoch 12, gen_loss = 0.4171131459566263, disc_loss = 0.1308997840835498
Trained batch 13 in epoch 12, gen_loss = 0.42131913134029936, disc_loss = 0.13029954529234342
Trained batch 14 in epoch 12, gen_loss = 0.41832547783851626, disc_loss = 0.12437648425499598
Trained batch 15 in epoch 12, gen_loss = 0.41832259483635426, disc_loss = 0.11949987104162574
Trained batch 16 in epoch 12, gen_loss = 0.42132001414018516, disc_loss = 0.1245307874153642
Trained batch 17 in epoch 12, gen_loss = 0.4175073769357469, disc_loss = 0.12051300932135847
Trained batch 18 in epoch 12, gen_loss = 0.40995056064505325, disc_loss = 0.126927369323216
Trained batch 19 in epoch 12, gen_loss = 0.41103532910346985, disc_loss = 0.12235894054174423
Trained batch 20 in epoch 12, gen_loss = 0.41470766209420706, disc_loss = 0.12176709302834102
Trained batch 21 in epoch 12, gen_loss = 0.4132285754789006, disc_loss = 0.119434654712677
Trained batch 22 in epoch 12, gen_loss = 0.41069189750629925, disc_loss = 0.11633995855632036
Trained batch 23 in epoch 12, gen_loss = 0.4082806259393692, disc_loss = 0.1151034723346432
Trained batch 24 in epoch 12, gen_loss = 0.4058780550956726, disc_loss = 0.11389068752527237
Trained batch 25 in epoch 12, gen_loss = 0.40731120109558105, disc_loss = 0.11071363163109009
Trained batch 26 in epoch 12, gen_loss = 0.405427979098426, disc_loss = 0.10856254798946557
Trained batch 27 in epoch 12, gen_loss = 0.4044135180967195, disc_loss = 0.11178092725042786
Trained batch 28 in epoch 12, gen_loss = 0.4039771166341058, disc_loss = 0.10877409898515406
Trained batch 29 in epoch 12, gen_loss = 0.40005417068799337, disc_loss = 0.1121415293465058
Trained batch 30 in epoch 12, gen_loss = 0.40148926165796095, disc_loss = 0.11089544827418943
Trained batch 31 in epoch 12, gen_loss = 0.39927404932677746, disc_loss = 0.10968099266756326
Trained batch 32 in epoch 12, gen_loss = 0.39634070522857434, disc_loss = 0.10895189744505016
Trained batch 33 in epoch 12, gen_loss = 0.3964673999477835, disc_loss = 0.10604011656387764
Trained batch 34 in epoch 12, gen_loss = 0.3974678201334817, disc_loss = 0.1059766664568867
Trained batch 35 in epoch 12, gen_loss = 0.3991970734463798, disc_loss = 0.10889146947819325
Trained batch 36 in epoch 12, gen_loss = 0.39525856842865814, disc_loss = 0.10993386216058924
Trained batch 37 in epoch 12, gen_loss = 0.39596787095069885, disc_loss = 0.11036554856323882
Trained batch 38 in epoch 12, gen_loss = 0.397597325918002, disc_loss = 0.11143845677948915
Trained batch 39 in epoch 12, gen_loss = 0.3967643789947033, disc_loss = 0.11063864971511066
Trained batch 40 in epoch 12, gen_loss = 0.3968177277867387, disc_loss = 0.11089148186147213
Trained batch 41 in epoch 12, gen_loss = 0.39672138080710456, disc_loss = 0.1127202884693231
Trained batch 42 in epoch 12, gen_loss = 0.3967165551906408, disc_loss = 0.11151030525391878
Trained batch 43 in epoch 12, gen_loss = 0.3965539397163825, disc_loss = 0.11214021699164402
Trained batch 44 in epoch 12, gen_loss = 0.3992877066135406, disc_loss = 0.11294483844604757
Trained batch 45 in epoch 12, gen_loss = 0.39996688003125397, disc_loss = 0.11097959352090307
Trained batch 46 in epoch 12, gen_loss = 0.39974569132987486, disc_loss = 0.1098547202554789
Trained batch 47 in epoch 12, gen_loss = 0.3986535432438056, disc_loss = 0.10825979387542854
Trained batch 48 in epoch 12, gen_loss = 0.3987968679593534, disc_loss = 0.1069553054641096
Trained batch 49 in epoch 12, gen_loss = 0.3991709864139557, disc_loss = 0.10499341037124395
Trained batch 50 in epoch 12, gen_loss = 0.39998441233354454, disc_loss = 0.10475362263912079
Trained batch 51 in epoch 12, gen_loss = 0.398879121702451, disc_loss = 0.10574011171523195
Trained batch 52 in epoch 12, gen_loss = 0.3980503616467962, disc_loss = 0.1060973094811417
Trained batch 53 in epoch 12, gen_loss = 0.39688050746917725, disc_loss = 0.10602414839107681
Trained batch 54 in epoch 12, gen_loss = 0.3970303530042822, disc_loss = 0.105709405886856
Trained batch 55 in epoch 12, gen_loss = 0.39574667545301573, disc_loss = 0.1082124566060624
Trained batch 56 in epoch 12, gen_loss = 0.39631706789920207, disc_loss = 0.10901353544179808
Trained batch 57 in epoch 12, gen_loss = 0.3964950740337372, disc_loss = 0.1073156794340446
Trained batch 58 in epoch 12, gen_loss = 0.39522070904909556, disc_loss = 0.10604078404731669
Trained batch 59 in epoch 12, gen_loss = 0.3949066951870918, disc_loss = 0.10498658791184426
Trained batch 60 in epoch 12, gen_loss = 0.39613529111518236, disc_loss = 0.10484983918608212
Trained batch 61 in epoch 12, gen_loss = 0.39567350908633203, disc_loss = 0.10520285307880371
Trained batch 62 in epoch 12, gen_loss = 0.3948562878464896, disc_loss = 0.10457273643641245
Trained batch 63 in epoch 12, gen_loss = 0.3954661125317216, disc_loss = 0.10535114153753966
Trained batch 64 in epoch 12, gen_loss = 0.3952362234775837, disc_loss = 0.10479618333853208
Trained batch 65 in epoch 12, gen_loss = 0.39535584413644037, disc_loss = 0.10373832934507818
Trained batch 66 in epoch 12, gen_loss = 0.3955412907386894, disc_loss = 0.10277109298465857
Trained batch 67 in epoch 12, gen_loss = 0.39504093676805496, disc_loss = 0.10281718242913485
Trained batch 68 in epoch 12, gen_loss = 0.3934342995070029, disc_loss = 0.10404742417344148
Trained batch 69 in epoch 12, gen_loss = 0.3947445149932589, disc_loss = 0.10738590194710664
Trained batch 70 in epoch 12, gen_loss = 0.39458474013167366, disc_loss = 0.10653812322818057
Trained batch 71 in epoch 12, gen_loss = 0.39348046026296085, disc_loss = 0.10566844009897775
Trained batch 72 in epoch 12, gen_loss = 0.3929151962064717, disc_loss = 0.10465370287021546
Trained batch 73 in epoch 12, gen_loss = 0.3924070898745511, disc_loss = 0.1041060356372917
Trained batch 74 in epoch 12, gen_loss = 0.39296979308128355, disc_loss = 0.10416572347283364
Trained batch 75 in epoch 12, gen_loss = 0.3934348241279, disc_loss = 0.10429037328025229
Trained batch 76 in epoch 12, gen_loss = 0.39356130671191525, disc_loss = 0.104009273522473
Trained batch 77 in epoch 12, gen_loss = 0.3929554120852397, disc_loss = 0.10329069894475815
Trained batch 78 in epoch 12, gen_loss = 0.39208000030698653, disc_loss = 0.10320559738180306
Trained batch 79 in epoch 12, gen_loss = 0.39233701340854166, disc_loss = 0.10331156048923731
Trained batch 80 in epoch 12, gen_loss = 0.39271489852740443, disc_loss = 0.10297185035399449
Trained batch 81 in epoch 12, gen_loss = 0.39124669025583964, disc_loss = 0.10247563120977181
Trained batch 82 in epoch 12, gen_loss = 0.39104292514812516, disc_loss = 0.10246738131685429
Trained batch 83 in epoch 12, gen_loss = 0.39273382545936675, disc_loss = 0.10428935382515192
Trained batch 84 in epoch 12, gen_loss = 0.39225072264671323, disc_loss = 0.10377651501227828
Trained batch 85 in epoch 12, gen_loss = 0.3910665040792421, disc_loss = 0.10511427697573983
Trained batch 86 in epoch 12, gen_loss = 0.39132731913150043, disc_loss = 0.10485538947342456
Trained batch 87 in epoch 12, gen_loss = 0.3913662840019573, disc_loss = 0.10386407481167804
Trained batch 88 in epoch 12, gen_loss = 0.39107458912924437, disc_loss = 0.10295922662853525
Trained batch 89 in epoch 12, gen_loss = 0.3907005783584383, disc_loss = 0.10299827168799108
Trained batch 90 in epoch 12, gen_loss = 0.39123037391966514, disc_loss = 0.10274553088123327
Trained batch 91 in epoch 12, gen_loss = 0.3918010828935582, disc_loss = 0.10237724886721243
Trained batch 92 in epoch 12, gen_loss = 0.39128599532188907, disc_loss = 0.10272416875006692
Trained batch 93 in epoch 12, gen_loss = 0.39214186877646345, disc_loss = 0.10364048486139546
Trained batch 94 in epoch 12, gen_loss = 0.3920975694530889, disc_loss = 0.10315024070441722
Trained batch 95 in epoch 12, gen_loss = 0.39094332326203585, disc_loss = 0.1031137615791522
Trained batch 96 in epoch 12, gen_loss = 0.39090980881268217, disc_loss = 0.10244165132417507
Trained batch 97 in epoch 12, gen_loss = 0.3908099997408536, disc_loss = 0.10300287849516893
Trained batch 98 in epoch 12, gen_loss = 0.39017768279470577, disc_loss = 0.1043607716194608
Trained batch 99 in epoch 12, gen_loss = 0.39034501850605013, disc_loss = 0.10447912501171232
Trained batch 100 in epoch 12, gen_loss = 0.390220575403459, disc_loss = 0.10386562327125876
Trained batch 101 in epoch 12, gen_loss = 0.3905211868239384, disc_loss = 0.10397629076432363
Trained batch 102 in epoch 12, gen_loss = 0.39151300909449754, disc_loss = 0.10615711407826363
Trained batch 103 in epoch 12, gen_loss = 0.3909689276837386, disc_loss = 0.10676293592685117
Trained batch 104 in epoch 12, gen_loss = 0.391388734181722, disc_loss = 0.10645584295548144
Trained batch 105 in epoch 12, gen_loss = 0.3918754610250581, disc_loss = 0.10626969825616984
Trained batch 106 in epoch 12, gen_loss = 0.3915694250124637, disc_loss = 0.1067729793036374
Trained batch 107 in epoch 12, gen_loss = 0.39110841712465994, disc_loss = 0.10956535076170608
Trained batch 108 in epoch 12, gen_loss = 0.39104109045562396, disc_loss = 0.10929638313112455
Trained batch 109 in epoch 12, gen_loss = 0.3908253336494619, disc_loss = 0.10905495348640463
Trained batch 110 in epoch 12, gen_loss = 0.39084257467372996, disc_loss = 0.10869842306249314
Trained batch 111 in epoch 12, gen_loss = 0.3908504894269364, disc_loss = 0.10827812763662743
Trained batch 112 in epoch 12, gen_loss = 0.3907414044426606, disc_loss = 0.10763894362721295
Trained batch 113 in epoch 12, gen_loss = 0.390545471195589, disc_loss = 0.10686586560322005
Trained batch 114 in epoch 12, gen_loss = 0.39114470766938253, disc_loss = 0.10671864577933499
Trained batch 115 in epoch 12, gen_loss = 0.3906279920504011, disc_loss = 0.10634283193162289
Trained batch 116 in epoch 12, gen_loss = 0.3908277337367718, disc_loss = 0.10601680571388485
Trained batch 117 in epoch 12, gen_loss = 0.3905915165856733, disc_loss = 0.10550988647076538
Trained batch 118 in epoch 12, gen_loss = 0.39069864855093117, disc_loss = 0.1052614628736462
Trained batch 119 in epoch 12, gen_loss = 0.3915960495670637, disc_loss = 0.10549606797285378
Trained batch 120 in epoch 12, gen_loss = 0.39127021830929215, disc_loss = 0.10549848962359684
Trained batch 121 in epoch 12, gen_loss = 0.39160160671492095, disc_loss = 0.10508242107500307
Trained batch 122 in epoch 12, gen_loss = 0.3916605146435218, disc_loss = 0.10468616038257998
Trained batch 123 in epoch 12, gen_loss = 0.39130173214981634, disc_loss = 0.10558764274502473
Trained batch 124 in epoch 12, gen_loss = 0.39190518093109133, disc_loss = 0.10566196356713772
Trained batch 125 in epoch 12, gen_loss = 0.39184696191833135, disc_loss = 0.10505733031424738
Trained batch 126 in epoch 12, gen_loss = 0.39224254779928314, disc_loss = 0.10484455404143164
Trained batch 127 in epoch 12, gen_loss = 0.3930363084655255, disc_loss = 0.1044535798864672
Trained batch 128 in epoch 12, gen_loss = 0.39328127660492596, disc_loss = 0.10404925182635008
Trained batch 129 in epoch 12, gen_loss = 0.39312684467205633, disc_loss = 0.10447658903610248
Trained batch 130 in epoch 12, gen_loss = 0.3927417024401308, disc_loss = 0.10428713462564326
Trained batch 131 in epoch 12, gen_loss = 0.3927249666867834, disc_loss = 0.1039647431903039
Trained batch 132 in epoch 12, gen_loss = 0.3922487015562846, disc_loss = 0.10426763709830611
Trained batch 133 in epoch 12, gen_loss = 0.39203641641495834, disc_loss = 0.10398411418575404
Trained batch 134 in epoch 12, gen_loss = 0.39185109911141575, disc_loss = 0.10365499044182123
Trained batch 135 in epoch 12, gen_loss = 0.39217129240141196, disc_loss = 0.10316429836401607
Trained batch 136 in epoch 12, gen_loss = 0.39130467763782417, disc_loss = 0.10303406337153738
Trained batch 137 in epoch 12, gen_loss = 0.3914050773002099, disc_loss = 0.10281884142508109
Trained batch 138 in epoch 12, gen_loss = 0.39196044099416666, disc_loss = 0.10345867063126547
Trained batch 139 in epoch 12, gen_loss = 0.39137457460165026, disc_loss = 0.1045597717298993
Trained batch 140 in epoch 12, gen_loss = 0.39152411577549384, disc_loss = 0.10416602862483644
Trained batch 141 in epoch 12, gen_loss = 0.39162286633337046, disc_loss = 0.10635687207514552
Trained batch 142 in epoch 12, gen_loss = 0.3910599961564257, disc_loss = 0.10680130411955444
Trained batch 143 in epoch 12, gen_loss = 0.39117827059494126, disc_loss = 0.10631032072059396
Trained batch 144 in epoch 12, gen_loss = 0.3912021536251594, disc_loss = 0.10585657883563947
Trained batch 145 in epoch 12, gen_loss = 0.39146822772613943, disc_loss = 0.10544397563303579
Trained batch 146 in epoch 12, gen_loss = 0.39088436129952775, disc_loss = 0.10520141408303563
Trained batch 147 in epoch 12, gen_loss = 0.3910859497012319, disc_loss = 0.10539447922712646
Trained batch 148 in epoch 12, gen_loss = 0.39108161498236177, disc_loss = 0.10589596472880584
Trained batch 149 in epoch 12, gen_loss = 0.3912894543011983, disc_loss = 0.1067089597756664
Trained batch 150 in epoch 12, gen_loss = 0.39108909163253985, disc_loss = 0.10715824616024432
Trained batch 151 in epoch 12, gen_loss = 0.3907510889203925, disc_loss = 0.10684475191182603
Trained batch 152 in epoch 12, gen_loss = 0.39055561649253945, disc_loss = 0.10664831590077846
Trained batch 153 in epoch 12, gen_loss = 0.39042137640637237, disc_loss = 0.10636899437658585
Trained batch 154 in epoch 12, gen_loss = 0.38944655493382485, disc_loss = 0.10621729042501218
Trained batch 155 in epoch 12, gen_loss = 0.3890936285830461, disc_loss = 0.10587851935997605
Trained batch 156 in epoch 12, gen_loss = 0.38829696339786435, disc_loss = 0.10614589410745034
Trained batch 157 in epoch 12, gen_loss = 0.38849644768464414, disc_loss = 0.10666035892606913
Trained batch 158 in epoch 12, gen_loss = 0.388486865650183, disc_loss = 0.10633359039963791
Trained batch 159 in epoch 12, gen_loss = 0.38799127088859675, disc_loss = 0.10654900089139119
Trained batch 160 in epoch 12, gen_loss = 0.3876683000266922, disc_loss = 0.10636653502396545
Trained batch 161 in epoch 12, gen_loss = 0.38789333633066697, disc_loss = 0.10595472418001772
Trained batch 162 in epoch 12, gen_loss = 0.3881137424999951, disc_loss = 0.10637478177304283
Trained batch 163 in epoch 12, gen_loss = 0.3877885338918465, disc_loss = 0.10734753277743371
Trained batch 164 in epoch 12, gen_loss = 0.38822135573083705, disc_loss = 0.10760294482337707
Trained batch 165 in epoch 12, gen_loss = 0.3880899563790804, disc_loss = 0.10728838942181992
Trained batch 166 in epoch 12, gen_loss = 0.38786482445137227, disc_loss = 0.10688675356705389
Trained batch 167 in epoch 12, gen_loss = 0.3874604408407495, disc_loss = 0.10676893012021624
Trained batch 168 in epoch 12, gen_loss = 0.3874920431149782, disc_loss = 0.10678637870890502
Trained batch 169 in epoch 12, gen_loss = 0.3877264840637936, disc_loss = 0.10696668235913795
Trained batch 170 in epoch 12, gen_loss = 0.387506727673854, disc_loss = 0.1080931851760163
Trained batch 171 in epoch 12, gen_loss = 0.38786876452870145, disc_loss = 0.10765766780173709
Trained batch 172 in epoch 12, gen_loss = 0.3883916757182579, disc_loss = 0.10743891373492045
Trained batch 173 in epoch 12, gen_loss = 0.3879562858706233, disc_loss = 0.1072431863446174
Trained batch 174 in epoch 12, gen_loss = 0.38804589484419144, disc_loss = 0.1071868008268731
Trained batch 175 in epoch 12, gen_loss = 0.38834525873376563, disc_loss = 0.10712063781366768
Trained batch 176 in epoch 12, gen_loss = 0.3885536682976168, disc_loss = 0.1066957786153097
Trained batch 177 in epoch 12, gen_loss = 0.38817490980531394, disc_loss = 0.10688495802368676
Trained batch 178 in epoch 12, gen_loss = 0.38835276879744823, disc_loss = 0.10812307485280423
Trained batch 179 in epoch 12, gen_loss = 0.3880921371281147, disc_loss = 0.10816250529347195
Trained batch 180 in epoch 12, gen_loss = 0.38832638268642006, disc_loss = 0.10788517304341108
Trained batch 181 in epoch 12, gen_loss = 0.3885776874619526, disc_loss = 0.10746764531870792
Trained batch 182 in epoch 12, gen_loss = 0.3885063279033359, disc_loss = 0.10767002079045512
Trained batch 183 in epoch 12, gen_loss = 0.3886478516556647, disc_loss = 0.10800504045682432
Trained batch 184 in epoch 12, gen_loss = 0.3885471505893243, disc_loss = 0.10757780559360981
Trained batch 185 in epoch 12, gen_loss = 0.38851796162705265, disc_loss = 0.10748218481619191
Trained batch 186 in epoch 12, gen_loss = 0.3885958381993248, disc_loss = 0.10729786164978927
Trained batch 187 in epoch 12, gen_loss = 0.38928789272904396, disc_loss = 0.10768466467592627
Trained batch 188 in epoch 12, gen_loss = 0.3892270669577614, disc_loss = 0.10721900517111102
Trained batch 189 in epoch 12, gen_loss = 0.3887015856410328, disc_loss = 0.10720186917797515
Trained batch 190 in epoch 12, gen_loss = 0.38870870154253473, disc_loss = 0.10713269606388676
Trained batch 191 in epoch 12, gen_loss = 0.38864909135736525, disc_loss = 0.10702970408601686
Trained batch 192 in epoch 12, gen_loss = 0.38845529341635926, disc_loss = 0.10684184423150794
Trained batch 193 in epoch 12, gen_loss = 0.38829199962087513, disc_loss = 0.10650580787320726
Trained batch 194 in epoch 12, gen_loss = 0.3881920748032056, disc_loss = 0.10645006883602876
Trained batch 195 in epoch 12, gen_loss = 0.3886047204082109, disc_loss = 0.10714750512674147
Trained batch 196 in epoch 12, gen_loss = 0.38848961375389, disc_loss = 0.10723873545524433
Trained batch 197 in epoch 12, gen_loss = 0.38872894486694626, disc_loss = 0.10702652348713441
Trained batch 198 in epoch 12, gen_loss = 0.388856325392148, disc_loss = 0.10665326818224773
Trained batch 199 in epoch 12, gen_loss = 0.3887422252446413, disc_loss = 0.10657636782154441
Trained batch 200 in epoch 12, gen_loss = 0.3886602543924578, disc_loss = 0.10723891355727443
Trained batch 201 in epoch 12, gen_loss = 0.38905144940213404, disc_loss = 0.10846433314577777
Trained batch 202 in epoch 12, gen_loss = 0.3893320404103237, disc_loss = 0.10803752475110769
Trained batch 203 in epoch 12, gen_loss = 0.38977460234480743, disc_loss = 0.107835946001989
Trained batch 204 in epoch 12, gen_loss = 0.38932859483288557, disc_loss = 0.10762889474266912
Trained batch 205 in epoch 12, gen_loss = 0.38945295618286413, disc_loss = 0.10732533402957962
Trained batch 206 in epoch 12, gen_loss = 0.38948278445840456, disc_loss = 0.10710830709352585
Trained batch 207 in epoch 12, gen_loss = 0.38936607346225244, disc_loss = 0.10672385884950367
Trained batch 208 in epoch 12, gen_loss = 0.3892064152294369, disc_loss = 0.10662224562615868
Trained batch 209 in epoch 12, gen_loss = 0.3890828664104144, disc_loss = 0.10717478169216996
Trained batch 210 in epoch 12, gen_loss = 0.38960099199089393, disc_loss = 0.1075957180376019
Trained batch 211 in epoch 12, gen_loss = 0.38962966997949583, disc_loss = 0.10731482753565288
Trained batch 212 in epoch 12, gen_loss = 0.38942214517806056, disc_loss = 0.10714056494999939
Trained batch 213 in epoch 12, gen_loss = 0.389837156598256, disc_loss = 0.10683011961665666
Trained batch 214 in epoch 12, gen_loss = 0.3897328789150992, disc_loss = 0.10660080686211586
Trained batch 215 in epoch 12, gen_loss = 0.3900210383451647, disc_loss = 0.10627179708400811
Trained batch 216 in epoch 12, gen_loss = 0.39009534042277094, disc_loss = 0.10648153631299871
Trained batch 217 in epoch 12, gen_loss = 0.3904544778783387, disc_loss = 0.10647508240552671
Trained batch 218 in epoch 12, gen_loss = 0.3903681115336614, disc_loss = 0.10645645565978468
Trained batch 219 in epoch 12, gen_loss = 0.39057565554976464, disc_loss = 0.10608575835146687
Trained batch 220 in epoch 12, gen_loss = 0.3904385141252932, disc_loss = 0.10586160677590521
Trained batch 221 in epoch 12, gen_loss = 0.3907855986072136, disc_loss = 0.10587367435564866
Trained batch 222 in epoch 12, gen_loss = 0.3910699865609541, disc_loss = 0.10555746524924654
Trained batch 223 in epoch 12, gen_loss = 0.39097445983705775, disc_loss = 0.10525771129011575
Trained batch 224 in epoch 12, gen_loss = 0.39095062461164265, disc_loss = 0.10509091561039288
Trained batch 225 in epoch 12, gen_loss = 0.39094732695184975, disc_loss = 0.10508675528772637
Trained batch 226 in epoch 12, gen_loss = 0.39088910194483095, disc_loss = 0.1047297642783709
Trained batch 227 in epoch 12, gen_loss = 0.3913003987256895, disc_loss = 0.10454484625931895
Trained batch 228 in epoch 12, gen_loss = 0.3914154007315115, disc_loss = 0.10421779249920855
Trained batch 229 in epoch 12, gen_loss = 0.3914502306476883, disc_loss = 0.10473253026442683
Trained batch 230 in epoch 12, gen_loss = 0.3914958294722941, disc_loss = 0.10514896288030333
Trained batch 231 in epoch 12, gen_loss = 0.3920998760210029, disc_loss = 0.10515618063348892
Trained batch 232 in epoch 12, gen_loss = 0.3919738579077782, disc_loss = 0.10507145123516286
Trained batch 233 in epoch 12, gen_loss = 0.39221868307417274, disc_loss = 0.10504298777375211
Trained batch 234 in epoch 12, gen_loss = 0.3922742183538193, disc_loss = 0.10531068303959167
Trained batch 235 in epoch 12, gen_loss = 0.39216393327056354, disc_loss = 0.10510639621386841
Trained batch 236 in epoch 12, gen_loss = 0.3919916605018865, disc_loss = 0.10564741997621985
Trained batch 237 in epoch 12, gen_loss = 0.39212733212889744, disc_loss = 0.10614844545440263
Trained batch 238 in epoch 12, gen_loss = 0.39199681692293, disc_loss = 0.10592614715162929
Trained batch 239 in epoch 12, gen_loss = 0.3919833591207862, disc_loss = 0.10590372395236045
Trained batch 240 in epoch 12, gen_loss = 0.3924627161248591, disc_loss = 0.10594924693131101
Trained batch 241 in epoch 12, gen_loss = 0.3923135282210082, disc_loss = 0.10584612525537733
Trained batch 242 in epoch 12, gen_loss = 0.39212104058805314, disc_loss = 0.10561871733286499
Trained batch 243 in epoch 12, gen_loss = 0.3923968167700728, disc_loss = 0.10546884572011281
Trained batch 244 in epoch 12, gen_loss = 0.39242468470213365, disc_loss = 0.10518338287211194
Trained batch 245 in epoch 12, gen_loss = 0.3921313939419219, disc_loss = 0.10514054107441892
Trained batch 246 in epoch 12, gen_loss = 0.3921468924534948, disc_loss = 0.10478883077530002
Trained batch 247 in epoch 12, gen_loss = 0.39237609415525393, disc_loss = 0.10452366484359148
Trained batch 248 in epoch 12, gen_loss = 0.39246237547282714, disc_loss = 0.10456812189495468
Trained batch 249 in epoch 12, gen_loss = 0.39237622994184496, disc_loss = 0.10519009935110807
Trained batch 250 in epoch 12, gen_loss = 0.39283298110344494, disc_loss = 0.1050546302782943
Trained batch 251 in epoch 12, gen_loss = 0.39283457723638365, disc_loss = 0.10472459518276746
Trained batch 252 in epoch 12, gen_loss = 0.3925593492424064, disc_loss = 0.1045441428059528
Trained batch 253 in epoch 12, gen_loss = 0.3925095963783152, disc_loss = 0.10429571851295984
Trained batch 254 in epoch 12, gen_loss = 0.39255571768564335, disc_loss = 0.10419219350259679
Trained batch 255 in epoch 12, gen_loss = 0.39269832643913105, disc_loss = 0.10405161619564751
Trained batch 256 in epoch 12, gen_loss = 0.3927449510371175, disc_loss = 0.10396588898847307
Trained batch 257 in epoch 12, gen_loss = 0.39264147324386495, disc_loss = 0.10380573146940433
Trained batch 258 in epoch 12, gen_loss = 0.39274835914488465, disc_loss = 0.10364948717237209
Trained batch 259 in epoch 12, gen_loss = 0.3928984908530345, disc_loss = 0.10349853744443793
Trained batch 260 in epoch 12, gen_loss = 0.39277963089075124, disc_loss = 0.10384048567906422
Trained batch 261 in epoch 12, gen_loss = 0.3931608047080404, disc_loss = 0.1043038708406664
Trained batch 262 in epoch 12, gen_loss = 0.39330766857123645, disc_loss = 0.10427115070757531
Trained batch 263 in epoch 12, gen_loss = 0.3936807764411876, disc_loss = 0.10406241171541765
Trained batch 264 in epoch 12, gen_loss = 0.39342008553585917, disc_loss = 0.10393130212038193
Trained batch 265 in epoch 12, gen_loss = 0.39320190715834613, disc_loss = 0.10394754351109714
Trained batch 266 in epoch 12, gen_loss = 0.39309234124667636, disc_loss = 0.10395963094458821
Trained batch 267 in epoch 12, gen_loss = 0.39272873442786843, disc_loss = 0.10401615253719154
Trained batch 268 in epoch 12, gen_loss = 0.3926862201836916, disc_loss = 0.10386380661957548
Trained batch 269 in epoch 12, gen_loss = 0.3924491090355096, disc_loss = 0.10386045059810083
Trained batch 270 in epoch 12, gen_loss = 0.3922889269476007, disc_loss = 0.10386814086996982
Trained batch 271 in epoch 12, gen_loss = 0.3925997217678848, disc_loss = 0.10479419813354444
Trained batch 272 in epoch 12, gen_loss = 0.39258925998822236, disc_loss = 0.10457222112505646
Trained batch 273 in epoch 12, gen_loss = 0.39246269489509344, disc_loss = 0.10443261755888697
Trained batch 274 in epoch 12, gen_loss = 0.39233589860525997, disc_loss = 0.10430969691412015
Trained batch 275 in epoch 12, gen_loss = 0.3924260547087676, disc_loss = 0.10412380342925157
Trained batch 276 in epoch 12, gen_loss = 0.39235271954579476, disc_loss = 0.1040206940824482
Trained batch 277 in epoch 12, gen_loss = 0.3921263611895575, disc_loss = 0.10390940252959514
Trained batch 278 in epoch 12, gen_loss = 0.39233044489523844, disc_loss = 0.10419658502717385
Trained batch 279 in epoch 12, gen_loss = 0.3921114618756941, disc_loss = 0.10411520906990128
Trained batch 280 in epoch 12, gen_loss = 0.39214298166202055, disc_loss = 0.10397410146839042
Trained batch 281 in epoch 12, gen_loss = 0.39202314535988136, disc_loss = 0.10470476216167635
Trained batch 282 in epoch 12, gen_loss = 0.3919074744407364, disc_loss = 0.10477614495574164
Trained batch 283 in epoch 12, gen_loss = 0.3920217166379304, disc_loss = 0.10464836702301679
Trained batch 284 in epoch 12, gen_loss = 0.3921380814230233, disc_loss = 0.1044762029132822
Trained batch 285 in epoch 12, gen_loss = 0.3918550253643856, disc_loss = 0.10441573487164882
Trained batch 286 in epoch 12, gen_loss = 0.39224786931837063, disc_loss = 0.10453934938312616
Trained batch 287 in epoch 12, gen_loss = 0.3918667043973174, disc_loss = 0.10456758576522891
Trained batch 288 in epoch 12, gen_loss = 0.39190635440877564, disc_loss = 0.10441538190733396
Trained batch 289 in epoch 12, gen_loss = 0.39165387354020414, disc_loss = 0.10424940981099318
Trained batch 290 in epoch 12, gen_loss = 0.39144843361017223, disc_loss = 0.10545633568770901
Trained batch 291 in epoch 12, gen_loss = 0.3918915410870559, disc_loss = 0.10563035859815674
Trained batch 292 in epoch 12, gen_loss = 0.39215174261416996, disc_loss = 0.10537598548463384
Trained batch 293 in epoch 12, gen_loss = 0.3920423164963722, disc_loss = 0.10534568130336448
Trained batch 294 in epoch 12, gen_loss = 0.3919733715764547, disc_loss = 0.10539076544849549
Trained batch 295 in epoch 12, gen_loss = 0.3920509930498697, disc_loss = 0.10536625369049206
Trained batch 296 in epoch 12, gen_loss = 0.39206100408276323, disc_loss = 0.10543750183224077
Trained batch 297 in epoch 12, gen_loss = 0.3923269409761333, disc_loss = 0.10537902835206497
Trained batch 298 in epoch 12, gen_loss = 0.3922280137455184, disc_loss = 0.10539279810237047
Trained batch 299 in epoch 12, gen_loss = 0.39235578442613284, disc_loss = 0.10579905780032277
Trained batch 300 in epoch 12, gen_loss = 0.3922064526631587, disc_loss = 0.10568935460599752
Trained batch 301 in epoch 12, gen_loss = 0.3919736005316507, disc_loss = 0.10560645495498219
Trained batch 302 in epoch 12, gen_loss = 0.3919294477000882, disc_loss = 0.10541932807970952
Trained batch 303 in epoch 12, gen_loss = 0.3918891634890123, disc_loss = 0.10545092109762329
Trained batch 304 in epoch 12, gen_loss = 0.39188627967091855, disc_loss = 0.10597381605843051
Trained batch 305 in epoch 12, gen_loss = 0.3919235238549756, disc_loss = 0.10637365836114471
Trained batch 306 in epoch 12, gen_loss = 0.39201485649576406, disc_loss = 0.10648489575408375
Trained batch 307 in epoch 12, gen_loss = 0.39230620275650707, disc_loss = 0.10653314898516257
Trained batch 308 in epoch 12, gen_loss = 0.39223006247123854, disc_loss = 0.10641474886209641
Trained batch 309 in epoch 12, gen_loss = 0.3921175998545462, disc_loss = 0.10638866395118736
Trained batch 310 in epoch 12, gen_loss = 0.3921218127778872, disc_loss = 0.10641443865355762
Trained batch 311 in epoch 12, gen_loss = 0.392371298554234, disc_loss = 0.10620700464679454
Trained batch 312 in epoch 12, gen_loss = 0.39225003204216213, disc_loss = 0.1061993643534355
Trained batch 313 in epoch 12, gen_loss = 0.3922968582267974, disc_loss = 0.10685447109329282
Trained batch 314 in epoch 12, gen_loss = 0.39208546843793657, disc_loss = 0.10689982922659033
Trained batch 315 in epoch 12, gen_loss = 0.3920768364037894, disc_loss = 0.10677471860087936
Trained batch 316 in epoch 12, gen_loss = 0.391882668769322, disc_loss = 0.10657834605393161
Trained batch 317 in epoch 12, gen_loss = 0.39195325881617626, disc_loss = 0.10646744206571167
Trained batch 318 in epoch 12, gen_loss = 0.39183438015768896, disc_loss = 0.10646219358291932
Trained batch 319 in epoch 12, gen_loss = 0.3916774536948651, disc_loss = 0.10644805310876108
Trained batch 320 in epoch 12, gen_loss = 0.3917813338687487, disc_loss = 0.10640607097090404
Trained batch 321 in epoch 12, gen_loss = 0.39186237923662115, disc_loss = 0.10643802685605258
Trained batch 322 in epoch 12, gen_loss = 0.3921547008464949, disc_loss = 0.10630708836572643
Trained batch 323 in epoch 12, gen_loss = 0.39237512376757316, disc_loss = 0.10611097761257379
Trained batch 324 in epoch 12, gen_loss = 0.39257125418919786, disc_loss = 0.10582105422249208
Trained batch 325 in epoch 12, gen_loss = 0.39261752828681395, disc_loss = 0.10554446166872612
Trained batch 326 in epoch 12, gen_loss = 0.39280391947027377, disc_loss = 0.10555654489620381
Trained batch 327 in epoch 12, gen_loss = 0.3924237470165258, disc_loss = 0.10642160992024512
Trained batch 328 in epoch 12, gen_loss = 0.39279389512756313, disc_loss = 0.1066710745921432
Trained batch 329 in epoch 12, gen_loss = 0.39306424716205307, disc_loss = 0.10651878469595404
Trained batch 330 in epoch 12, gen_loss = 0.3929943966811517, disc_loss = 0.1067825438640449
Trained batch 331 in epoch 12, gen_loss = 0.3929476596594575, disc_loss = 0.10669333596590412
Trained batch 332 in epoch 12, gen_loss = 0.3928359797498485, disc_loss = 0.10682366691059894
Trained batch 333 in epoch 12, gen_loss = 0.3928644445217298, disc_loss = 0.10668934506927422
Trained batch 334 in epoch 12, gen_loss = 0.39271859958100674, disc_loss = 0.10667232684235074
Trained batch 335 in epoch 12, gen_loss = 0.3926873674971007, disc_loss = 0.10683889265748717
Trained batch 336 in epoch 12, gen_loss = 0.3926051241796165, disc_loss = 0.10678922157259299
Trained batch 337 in epoch 12, gen_loss = 0.3923950202807167, disc_loss = 0.10665523587070273
Trained batch 338 in epoch 12, gen_loss = 0.3923054355523579, disc_loss = 0.10658577141684417
Trained batch 339 in epoch 12, gen_loss = 0.39236256782622897, disc_loss = 0.10732566911508055
Trained batch 340 in epoch 12, gen_loss = 0.3919248549906739, disc_loss = 0.1076064659965353
Trained batch 341 in epoch 12, gen_loss = 0.3917904110592708, disc_loss = 0.10755084736043946
Trained batch 342 in epoch 12, gen_loss = 0.3918804242642211, disc_loss = 0.10758020744031789
Trained batch 343 in epoch 12, gen_loss = 0.39188784789727177, disc_loss = 0.1074644036071245
Trained batch 344 in epoch 12, gen_loss = 0.3916421696327735, disc_loss = 0.10749815959429396
Trained batch 345 in epoch 12, gen_loss = 0.3915309063185846, disc_loss = 0.1074035201932309
Trained batch 346 in epoch 12, gen_loss = 0.39161013504785486, disc_loss = 0.10716509049280576
Trained batch 347 in epoch 12, gen_loss = 0.39163874830493983, disc_loss = 0.10697654950507414
Trained batch 348 in epoch 12, gen_loss = 0.3918722926460228, disc_loss = 0.10685106826930128
Trained batch 349 in epoch 12, gen_loss = 0.39158407096351894, disc_loss = 0.10665159375539848
Trained batch 350 in epoch 12, gen_loss = 0.39130215465682866, disc_loss = 0.1065594118268911
Trained batch 351 in epoch 12, gen_loss = 0.39158010436221957, disc_loss = 0.10667420342691582
Trained batch 352 in epoch 12, gen_loss = 0.3915737225296815, disc_loss = 0.10666781852797476
Trained batch 353 in epoch 12, gen_loss = 0.39159029044505567, disc_loss = 0.10662869091466659
Trained batch 354 in epoch 12, gen_loss = 0.39160078407173426, disc_loss = 0.10685338450359627
Trained batch 355 in epoch 12, gen_loss = 0.3916056574311819, disc_loss = 0.10727523808273372
Trained batch 356 in epoch 12, gen_loss = 0.39163568970702944, disc_loss = 0.10720114248181258
Trained batch 357 in epoch 12, gen_loss = 0.3917921690384769, disc_loss = 0.10724753173661299
Trained batch 358 in epoch 12, gen_loss = 0.39167364074493183, disc_loss = 0.10707884104429513
Trained batch 359 in epoch 12, gen_loss = 0.39154952462348674, disc_loss = 0.10697068552383118
Trained batch 360 in epoch 12, gen_loss = 0.39164229983933413, disc_loss = 0.10700718357828845
Trained batch 361 in epoch 12, gen_loss = 0.39153351453621743, disc_loss = 0.10690613812381063
Trained batch 362 in epoch 12, gen_loss = 0.39140050359501327, disc_loss = 0.10692753017810751
Trained batch 363 in epoch 12, gen_loss = 0.39154210527028355, disc_loss = 0.10707317956897257
Trained batch 364 in epoch 12, gen_loss = 0.39149002698186325, disc_loss = 0.10696254096006694
Trained batch 365 in epoch 12, gen_loss = 0.39143464706146003, disc_loss = 0.10709404465971423
Trained batch 366 in epoch 12, gen_loss = 0.39150004267530153, disc_loss = 0.10765559716551115
Trained batch 367 in epoch 12, gen_loss = 0.3912030359244217, disc_loss = 0.1076202045255543
Trained batch 368 in epoch 12, gen_loss = 0.39101208552597017, disc_loss = 0.10747651851718341
Trained batch 369 in epoch 12, gen_loss = 0.390821347244688, disc_loss = 0.10729813096491066
Trained batch 370 in epoch 12, gen_loss = 0.3904870903957886, disc_loss = 0.10717885941267014
Trained batch 371 in epoch 12, gen_loss = 0.3905895989668626, disc_loss = 0.10693666563239149
Trained batch 372 in epoch 12, gen_loss = 0.39058751407161796, disc_loss = 0.10671022202789623
Trained batch 373 in epoch 12, gen_loss = 0.39061646884616047, disc_loss = 0.10683390239183915
Trained batch 374 in epoch 12, gen_loss = 0.3906161429484685, disc_loss = 0.10686319537957509
Trained batch 375 in epoch 12, gen_loss = 0.3905014383428274, disc_loss = 0.10704720436417042
Trained batch 376 in epoch 12, gen_loss = 0.3906748076253608, disc_loss = 0.1068382439566702
Trained batch 377 in epoch 12, gen_loss = 0.3909665334713522, disc_loss = 0.10665880255006924
Trained batch 378 in epoch 12, gen_loss = 0.3909582731984851, disc_loss = 0.10651130848478202
Trained batch 379 in epoch 12, gen_loss = 0.39122432858536116, disc_loss = 0.10636044332855626
Trained batch 380 in epoch 12, gen_loss = 0.39128794550426366, disc_loss = 0.10628389299228748
Trained batch 381 in epoch 12, gen_loss = 0.39154036822899474, disc_loss = 0.106290313936965
Trained batch 382 in epoch 12, gen_loss = 0.39153217230546566, disc_loss = 0.10627116945720529
Trained batch 383 in epoch 12, gen_loss = 0.3915376727236435, disc_loss = 0.10622401409394418
Trained batch 384 in epoch 12, gen_loss = 0.3916016608476639, disc_loss = 0.10615613427642104
Trained batch 385 in epoch 12, gen_loss = 0.3916612367478677, disc_loss = 0.10599672180537732
Trained batch 386 in epoch 12, gen_loss = 0.3917953403960211, disc_loss = 0.10595685619023419
Trained batch 387 in epoch 12, gen_loss = 0.39159408292358683, disc_loss = 0.10592659971839988
Trained batch 388 in epoch 12, gen_loss = 0.3917232522391415, disc_loss = 0.10574445164831868
Trained batch 389 in epoch 12, gen_loss = 0.3918172185619672, disc_loss = 0.10596018275007224
Trained batch 390 in epoch 12, gen_loss = 0.39184966107920916, disc_loss = 0.10651192642614969
Trained batch 391 in epoch 12, gen_loss = 0.39191942886278336, disc_loss = 0.10661384704693848
Trained batch 392 in epoch 12, gen_loss = 0.39216728296140374, disc_loss = 0.1064310607621233
Trained batch 393 in epoch 12, gen_loss = 0.3921711613154653, disc_loss = 0.10687719201338171
Trained batch 394 in epoch 12, gen_loss = 0.39225215327136126, disc_loss = 0.10697374516461469
Trained batch 395 in epoch 12, gen_loss = 0.3921012936743221, disc_loss = 0.1067872295588857
Trained batch 396 in epoch 12, gen_loss = 0.3920698886178903, disc_loss = 0.10663831430095569
Trained batch 397 in epoch 12, gen_loss = 0.39200666258532796, disc_loss = 0.10645669404810397
Trained batch 398 in epoch 12, gen_loss = 0.3920334378504813, disc_loss = 0.10627972805186321
Trained batch 399 in epoch 12, gen_loss = 0.3918694556131959, disc_loss = 0.10617374148219824
Trained batch 400 in epoch 12, gen_loss = 0.39161540278026885, disc_loss = 0.10620498952648587
Trained batch 401 in epoch 12, gen_loss = 0.3916252160917467, disc_loss = 0.10607848569417178
Trained batch 402 in epoch 12, gen_loss = 0.3917695918021072, disc_loss = 0.10607856320721044
Trained batch 403 in epoch 12, gen_loss = 0.3916564939709583, disc_loss = 0.10667739248843772
Trained batch 404 in epoch 12, gen_loss = 0.39158186283376484, disc_loss = 0.10680089012524228
Trained batch 405 in epoch 12, gen_loss = 0.39162278457962235, disc_loss = 0.10672416507720654
Trained batch 406 in epoch 12, gen_loss = 0.39171827846282237, disc_loss = 0.10671134887112153
Trained batch 407 in epoch 12, gen_loss = 0.39182540792606624, disc_loss = 0.10660733719922456
Trained batch 408 in epoch 12, gen_loss = 0.3919038780233971, disc_loss = 0.10645856756562126
Trained batch 409 in epoch 12, gen_loss = 0.39182382309582175, disc_loss = 0.10641850664666513
Trained batch 410 in epoch 12, gen_loss = 0.3918096522127625, disc_loss = 0.1063430990452749
Trained batch 411 in epoch 12, gen_loss = 0.39171577726029655, disc_loss = 0.10629584919661283
Trained batch 412 in epoch 12, gen_loss = 0.3916683087698195, disc_loss = 0.10622251133905773
Trained batch 413 in epoch 12, gen_loss = 0.39185001319589247, disc_loss = 0.1061089421366004
Trained batch 414 in epoch 12, gen_loss = 0.3917385774563594, disc_loss = 0.10597242703997946
Trained batch 415 in epoch 12, gen_loss = 0.3915620667931552, disc_loss = 0.10587728091587241
Trained batch 416 in epoch 12, gen_loss = 0.3918445595948816, disc_loss = 0.10565401105393323
Trained batch 417 in epoch 12, gen_loss = 0.3921541987637584, disc_loss = 0.10560486587789356
Trained batch 418 in epoch 12, gen_loss = 0.39204126920079846, disc_loss = 0.10553494294069547
Trained batch 419 in epoch 12, gen_loss = 0.3921208514698914, disc_loss = 0.10538747437475693
Trained batch 420 in epoch 12, gen_loss = 0.3922462649200988, disc_loss = 0.10534820207472086
Trained batch 421 in epoch 12, gen_loss = 0.39232216023297106, disc_loss = 0.10529640729216885
Trained batch 422 in epoch 12, gen_loss = 0.3921853746012311, disc_loss = 0.10532105526497178
Trained batch 423 in epoch 12, gen_loss = 0.3922720150494913, disc_loss = 0.10537575270523722
Trained batch 424 in epoch 12, gen_loss = 0.39223878779832055, disc_loss = 0.10555156347506187
Trained batch 425 in epoch 12, gen_loss = 0.39233590658981476, disc_loss = 0.10577329060176449
Trained batch 426 in epoch 12, gen_loss = 0.3920559710375877, disc_loss = 0.10585487968085522
Trained batch 427 in epoch 12, gen_loss = 0.39216038539448633, disc_loss = 0.10566843352411116
Trained batch 428 in epoch 12, gen_loss = 0.3921598629865335, disc_loss = 0.10556843848182605
Trained batch 429 in epoch 12, gen_loss = 0.3920834403744964, disc_loss = 0.10569994982418626
Trained batch 430 in epoch 12, gen_loss = 0.3922644542085046, disc_loss = 0.1064801298323889
Trained batch 431 in epoch 12, gen_loss = 0.3921645054317735, disc_loss = 0.10656343216800855
Trained batch 432 in epoch 12, gen_loss = 0.39215558949711693, disc_loss = 0.10668096299913409
Trained batch 433 in epoch 12, gen_loss = 0.39249943165872503, disc_loss = 0.10727373530341458
Trained batch 434 in epoch 12, gen_loss = 0.3925200366768344, disc_loss = 0.10733049031475494
Trained batch 435 in epoch 12, gen_loss = 0.3924590475310426, disc_loss = 0.10730184456589845
Trained batch 436 in epoch 12, gen_loss = 0.3925092766227657, disc_loss = 0.10748865674473601
Trained batch 437 in epoch 12, gen_loss = 0.39264695771616887, disc_loss = 0.10764152797355772
Trained batch 438 in epoch 12, gen_loss = 0.3926753013783001, disc_loss = 0.10750747573878064
Trained batch 439 in epoch 12, gen_loss = 0.3926303988491947, disc_loss = 0.10738260879773985
Trained batch 440 in epoch 12, gen_loss = 0.3927379267083274, disc_loss = 0.10731858788839543
Trained batch 441 in epoch 12, gen_loss = 0.3927114966295963, disc_loss = 0.10728306710989767
Trained batch 442 in epoch 12, gen_loss = 0.3927941868926817, disc_loss = 0.10717371972298784
Trained batch 443 in epoch 12, gen_loss = 0.3926856135529978, disc_loss = 0.10719243817971097
Trained batch 444 in epoch 12, gen_loss = 0.3927169434475095, disc_loss = 0.10714256639560957
Trained batch 445 in epoch 12, gen_loss = 0.3927702482438943, disc_loss = 0.10711991875495076
Trained batch 446 in epoch 12, gen_loss = 0.3928054828838481, disc_loss = 0.10711995647257606
Trained batch 447 in epoch 12, gen_loss = 0.3929557774681598, disc_loss = 0.10700929188169539
Trained batch 448 in epoch 12, gen_loss = 0.39294832065402796, disc_loss = 0.10687870473366538
Trained batch 449 in epoch 12, gen_loss = 0.3931661559144656, disc_loss = 0.10696705674959553
Trained batch 450 in epoch 12, gen_loss = 0.3929078632143807, disc_loss = 0.10743585793082572
Trained batch 451 in epoch 12, gen_loss = 0.39302421878792543, disc_loss = 0.1072784584526599
Trained batch 452 in epoch 12, gen_loss = 0.3931492946992647, disc_loss = 0.10727596842986069
Trained batch 453 in epoch 12, gen_loss = 0.3930468430274909, disc_loss = 0.10714274681776369
Trained batch 454 in epoch 12, gen_loss = 0.39287336052774074, disc_loss = 0.10725767996448737
Trained batch 455 in epoch 12, gen_loss = 0.3928661440221364, disc_loss = 0.10713262826596436
Trained batch 456 in epoch 12, gen_loss = 0.39309121629211, disc_loss = 0.107049300842786
Trained batch 457 in epoch 12, gen_loss = 0.3930991099716274, disc_loss = 0.1069102642415132
Trained batch 458 in epoch 12, gen_loss = 0.39295798880991595, disc_loss = 0.10686042917839582
Trained batch 459 in epoch 12, gen_loss = 0.3927203080252461, disc_loss = 0.10688168260714283
Trained batch 460 in epoch 12, gen_loss = 0.3926886168516639, disc_loss = 0.10686807142097883
Testing Epoch 12
Training Epoch 13
Trained batch 0 in epoch 13, gen_loss = 0.42216163873672485, disc_loss = 0.18899863958358765
Trained batch 1 in epoch 13, gen_loss = 0.40474314987659454, disc_loss = 0.15212470293045044
Trained batch 2 in epoch 13, gen_loss = 0.40300851066907245, disc_loss = 0.11359694848457973
Trained batch 3 in epoch 13, gen_loss = 0.4110937640070915, disc_loss = 0.09512228146195412
Trained batch 4 in epoch 13, gen_loss = 0.4225686252117157, disc_loss = 0.10353902280330658
Trained batch 5 in epoch 13, gen_loss = 0.3973911851644516, disc_loss = 0.13864179203907648
Trained batch 6 in epoch 13, gen_loss = 0.38891269479479107, disc_loss = 0.14825153137956346
Trained batch 7 in epoch 13, gen_loss = 0.3926953114569187, disc_loss = 0.1401716247200966
Trained batch 8 in epoch 13, gen_loss = 0.39263007375929093, disc_loss = 0.1316553983423445
Trained batch 9 in epoch 13, gen_loss = 0.3994724154472351, disc_loss = 0.1237895779311657
Trained batch 10 in epoch 13, gen_loss = 0.3946276144547896, disc_loss = 0.11902228336442601
Trained batch 11 in epoch 13, gen_loss = 0.40008750061194104, disc_loss = 0.11747497195998828
Trained batch 12 in epoch 13, gen_loss = 0.40694387830220735, disc_loss = 0.11569739075807425
Trained batch 13 in epoch 13, gen_loss = 0.3998160660266876, disc_loss = 0.11516254182372775
Trained batch 14 in epoch 13, gen_loss = 0.39573217233022057, disc_loss = 0.12887736658255258
Trained batch 15 in epoch 13, gen_loss = 0.40030999295413494, disc_loss = 0.12608267413452268
Trained batch 16 in epoch 13, gen_loss = 0.40432392849641685, disc_loss = 0.12060280867359217
Trained batch 17 in epoch 13, gen_loss = 0.4082913299401601, disc_loss = 0.11881021844844024
Trained batch 18 in epoch 13, gen_loss = 0.4104199252630535, disc_loss = 0.1152712763532212
Trained batch 19 in epoch 13, gen_loss = 0.41048809289932253, disc_loss = 0.11218679379671812
Trained batch 20 in epoch 13, gen_loss = 0.40751413930030095, disc_loss = 0.11616316703813416
Trained batch 21 in epoch 13, gen_loss = 0.4059678600593047, disc_loss = 0.11629941331391985
Trained batch 22 in epoch 13, gen_loss = 0.407348087300425, disc_loss = 0.1144488620693269
Trained batch 23 in epoch 13, gen_loss = 0.4040540469189485, disc_loss = 0.11455509609853227
Trained batch 24 in epoch 13, gen_loss = 0.40313817977905275, disc_loss = 0.11426275029778481
Trained batch 25 in epoch 13, gen_loss = 0.40238915383815765, disc_loss = 0.11308448260220197
Trained batch 26 in epoch 13, gen_loss = 0.40243415920822706, disc_loss = 0.11191798981141161
Trained batch 27 in epoch 13, gen_loss = 0.4005256901894297, disc_loss = 0.11143825030220407
Trained batch 28 in epoch 13, gen_loss = 0.4021929553870497, disc_loss = 0.11316013683019013
Trained batch 29 in epoch 13, gen_loss = 0.39870474735895794, disc_loss = 0.11381957717239857
Trained batch 30 in epoch 13, gen_loss = 0.39502686454403785, disc_loss = 0.11325384135688504
Trained batch 31 in epoch 13, gen_loss = 0.39473557844758034, disc_loss = 0.11074614047538489
Trained batch 32 in epoch 13, gen_loss = 0.3969617856271339, disc_loss = 0.10861135353193138
Trained batch 33 in epoch 13, gen_loss = 0.39678699304075804, disc_loss = 0.1072277436580728
Trained batch 34 in epoch 13, gen_loss = 0.3966400240148817, disc_loss = 0.1069436608680657
Trained batch 35 in epoch 13, gen_loss = 0.39565330412652755, disc_loss = 0.10489543330752188
Trained batch 36 in epoch 13, gen_loss = 0.39679100626223796, disc_loss = 0.10236478929181357
Trained batch 37 in epoch 13, gen_loss = 0.3960637199251275, disc_loss = 0.10516716255561302
Trained batch 38 in epoch 13, gen_loss = 0.40029924190961397, disc_loss = 0.11082501776325397
Trained batch 39 in epoch 13, gen_loss = 0.400723372399807, disc_loss = 0.10902195610105991
Trained batch 40 in epoch 13, gen_loss = 0.3986718741858878, disc_loss = 0.10810252842379779
Trained batch 41 in epoch 13, gen_loss = 0.39781818858214785, disc_loss = 0.10628408849948928
Trained batch 42 in epoch 13, gen_loss = 0.39918042823325756, disc_loss = 0.10549858541682709
Trained batch 43 in epoch 13, gen_loss = 0.3993904949589209, disc_loss = 0.10942228460176424
Trained batch 44 in epoch 13, gen_loss = 0.3987415744198693, disc_loss = 0.1080721501674917
Trained batch 45 in epoch 13, gen_loss = 0.39665227156618366, disc_loss = 0.11012000857811907
Trained batch 46 in epoch 13, gen_loss = 0.39745749818517806, disc_loss = 0.11032719347388187
Trained batch 47 in epoch 13, gen_loss = 0.39876145869493484, disc_loss = 0.1088279637042433
Trained batch 48 in epoch 13, gen_loss = 0.39861961834284726, disc_loss = 0.10771825050517005
Trained batch 49 in epoch 13, gen_loss = 0.3970295482873917, disc_loss = 0.10617904119193554
Trained batch 50 in epoch 13, gen_loss = 0.39740818972681086, disc_loss = 0.10570231145795654
Trained batch 51 in epoch 13, gen_loss = 0.39759602626928914, disc_loss = 0.10728306731639001
Trained batch 52 in epoch 13, gen_loss = 0.39778625290348846, disc_loss = 0.10590251036128907
Trained batch 53 in epoch 13, gen_loss = 0.39831999992882766, disc_loss = 0.10498599956432979
Trained batch 54 in epoch 13, gen_loss = 0.39861906387589197, disc_loss = 0.10545390735973012
Trained batch 55 in epoch 13, gen_loss = 0.39736779779195786, disc_loss = 0.10546642967632838
Trained batch 56 in epoch 13, gen_loss = 0.39811188243983087, disc_loss = 0.10533863658967771
Trained batch 57 in epoch 13, gen_loss = 0.3971365561773037, disc_loss = 0.10476288816024518
Trained batch 58 in epoch 13, gen_loss = 0.39816529417442065, disc_loss = 0.10396607788437504
Trained batch 59 in epoch 13, gen_loss = 0.3984616289536158, disc_loss = 0.10425448591510454
Trained batch 60 in epoch 13, gen_loss = 0.3962460565762442, disc_loss = 0.10587605150019536
Trained batch 61 in epoch 13, gen_loss = 0.39798402642050096, disc_loss = 0.10526320073873766
Trained batch 62 in epoch 13, gen_loss = 0.39813696391998776, disc_loss = 0.10434572883541622
Trained batch 63 in epoch 13, gen_loss = 0.3979770354926586, disc_loss = 0.10498345026280731
Trained batch 64 in epoch 13, gen_loss = 0.397605162858963, disc_loss = 0.10794786707713054
Trained batch 65 in epoch 13, gen_loss = 0.3984618489489411, disc_loss = 0.10781996685898665
Trained batch 66 in epoch 13, gen_loss = 0.3991169569207661, disc_loss = 0.10666339772183504
Trained batch 67 in epoch 13, gen_loss = 0.3990325826932402, disc_loss = 0.10662220281494014
Trained batch 68 in epoch 13, gen_loss = 0.3994108205256255, disc_loss = 0.10742491219138754
Trained batch 69 in epoch 13, gen_loss = 0.39968264145510535, disc_loss = 0.10747785392616477
Trained batch 70 in epoch 13, gen_loss = 0.3994138610195106, disc_loss = 0.10678586856999868
Trained batch 71 in epoch 13, gen_loss = 0.39876259283887017, disc_loss = 0.1058735071370999
Trained batch 72 in epoch 13, gen_loss = 0.3983495839654583, disc_loss = 0.10517444175808396
Trained batch 73 in epoch 13, gen_loss = 0.3987270573506484, disc_loss = 0.10436110802598901
Trained batch 74 in epoch 13, gen_loss = 0.3989638463656108, disc_loss = 0.10369727258880933
Trained batch 75 in epoch 13, gen_loss = 0.3990714224545579, disc_loss = 0.10275911338823407
Trained batch 76 in epoch 13, gen_loss = 0.3995563569781068, disc_loss = 0.1015833585777066
Trained batch 77 in epoch 13, gen_loss = 0.39870224472803945, disc_loss = 0.1014553975695983
Trained batch 78 in epoch 13, gen_loss = 0.39931595136847675, disc_loss = 0.10157126145838183
Trained batch 79 in epoch 13, gen_loss = 0.3986048523336649, disc_loss = 0.10131936413235962
Trained batch 80 in epoch 13, gen_loss = 0.398972319232093, disc_loss = 0.10084488137084761
Trained batch 81 in epoch 13, gen_loss = 0.39983189142331843, disc_loss = 0.10105543388280927
Trained batch 82 in epoch 13, gen_loss = 0.40066750473286733, disc_loss = 0.10073080008108933
Trained batch 83 in epoch 13, gen_loss = 0.39954037290243877, disc_loss = 0.10026690270751715
Trained batch 84 in epoch 13, gen_loss = 0.3981512195923749, disc_loss = 0.10011006598086918
Trained batch 85 in epoch 13, gen_loss = 0.398046403430229, disc_loss = 0.09976963547253331
Trained batch 86 in epoch 13, gen_loss = 0.39764376789673994, disc_loss = 0.09922301456674762
Trained batch 87 in epoch 13, gen_loss = 0.39783542400056665, disc_loss = 0.09915542987767946
Trained batch 88 in epoch 13, gen_loss = 0.3975618977225229, disc_loss = 0.10028177880671586
Trained batch 89 in epoch 13, gen_loss = 0.39714494546254475, disc_loss = 0.10071671253277195
Trained batch 90 in epoch 13, gen_loss = 0.39756721814910134, disc_loss = 0.10021061822772026
Trained batch 91 in epoch 13, gen_loss = 0.3965993232053259, disc_loss = 0.09970759624696296
Trained batch 92 in epoch 13, gen_loss = 0.3965691283184995, disc_loss = 0.09913874529702689
Trained batch 93 in epoch 13, gen_loss = 0.39732907046663, disc_loss = 0.09817616023281787
Trained batch 94 in epoch 13, gen_loss = 0.39697687500401546, disc_loss = 0.09780619764014294
Trained batch 95 in epoch 13, gen_loss = 0.3975059970592459, disc_loss = 0.09767508638712268
Trained batch 96 in epoch 13, gen_loss = 0.39722994369329867, disc_loss = 0.09792337428355954
Trained batch 97 in epoch 13, gen_loss = 0.3971478203121497, disc_loss = 0.09743269046350402
Trained batch 98 in epoch 13, gen_loss = 0.3968439731332991, disc_loss = 0.0973521452961546
Trained batch 99 in epoch 13, gen_loss = 0.39656650632619855, disc_loss = 0.09787730798125267
Trained batch 100 in epoch 13, gen_loss = 0.39642314421068325, disc_loss = 0.09908290177878767
Trained batch 101 in epoch 13, gen_loss = 0.3962924503812603, disc_loss = 0.0998626694667573
Trained batch 102 in epoch 13, gen_loss = 0.3959478536277141, disc_loss = 0.10031525646019908
Trained batch 103 in epoch 13, gen_loss = 0.39571286709262776, disc_loss = 0.09978547993187721
Trained batch 104 in epoch 13, gen_loss = 0.3952120590777624, disc_loss = 0.09943396747112274
Trained batch 105 in epoch 13, gen_loss = 0.395617368086329, disc_loss = 0.09915146990767065
Trained batch 106 in epoch 13, gen_loss = 0.3956212276053206, disc_loss = 0.09872492757913108
Trained batch 107 in epoch 13, gen_loss = 0.3940080887189618, disc_loss = 0.09915349466933145
Trained batch 108 in epoch 13, gen_loss = 0.39461893745518606, disc_loss = 0.10108941109902268
Trained batch 109 in epoch 13, gen_loss = 0.39393921982158314, disc_loss = 0.10207344740629196
Trained batch 110 in epoch 13, gen_loss = 0.3939220789853517, disc_loss = 0.10160344882725596
Trained batch 111 in epoch 13, gen_loss = 0.39442980715206694, disc_loss = 0.10195460067396718
Trained batch 112 in epoch 13, gen_loss = 0.39337487294610624, disc_loss = 0.10185763895907234
Trained batch 113 in epoch 13, gen_loss = 0.3938163874442117, disc_loss = 0.10144874362046258
Trained batch 114 in epoch 13, gen_loss = 0.39362540815187536, disc_loss = 0.10179739633332129
Trained batch 115 in epoch 13, gen_loss = 0.3929149690887024, disc_loss = 0.1020391648956414
Trained batch 116 in epoch 13, gen_loss = 0.3926108347045051, disc_loss = 0.10161519884808451
Trained batch 117 in epoch 13, gen_loss = 0.39231464241520836, disc_loss = 0.10141692380026235
Trained batch 118 in epoch 13, gen_loss = 0.39209650218987663, disc_loss = 0.10187688551279676
Trained batch 119 in epoch 13, gen_loss = 0.39220175966620446, disc_loss = 0.10326743802676598
Trained batch 120 in epoch 13, gen_loss = 0.39255054085707863, disc_loss = 0.10281190306933458
Trained batch 121 in epoch 13, gen_loss = 0.39214960522338993, disc_loss = 0.10282388091331622
Trained batch 122 in epoch 13, gen_loss = 0.39253555953018066, disc_loss = 0.10267699643121503
Trained batch 123 in epoch 13, gen_loss = 0.3924857539034659, disc_loss = 0.10286447700233228
Trained batch 124 in epoch 13, gen_loss = 0.39212614369392396, disc_loss = 0.10323953753709793
Trained batch 125 in epoch 13, gen_loss = 0.39256353510750663, disc_loss = 0.10272596983446015
Trained batch 126 in epoch 13, gen_loss = 0.3919702223905428, disc_loss = 0.10213432551955613
Trained batch 127 in epoch 13, gen_loss = 0.39215918933041394, disc_loss = 0.10181149319396354
Trained batch 128 in epoch 13, gen_loss = 0.39212273257647373, disc_loss = 0.10175762565214505
Trained batch 129 in epoch 13, gen_loss = 0.39142311032001786, disc_loss = 0.10183423691644118
Trained batch 130 in epoch 13, gen_loss = 0.3918444978371831, disc_loss = 0.10194295550916942
Trained batch 131 in epoch 13, gen_loss = 0.39184750910058164, disc_loss = 0.10202156930145892
Trained batch 132 in epoch 13, gen_loss = 0.39185562864282075, disc_loss = 0.10158248968366393
Trained batch 133 in epoch 13, gen_loss = 0.3924488870065604, disc_loss = 0.10114747010616225
Trained batch 134 in epoch 13, gen_loss = 0.3926259720766986, disc_loss = 0.10091894867795485
Trained batch 135 in epoch 13, gen_loss = 0.3923865192953278, disc_loss = 0.10080381271922413
Trained batch 136 in epoch 13, gen_loss = 0.3924692725613169, disc_loss = 0.10052608402214781
Trained batch 137 in epoch 13, gen_loss = 0.39297813177108765, disc_loss = 0.10160908634787884
Trained batch 138 in epoch 13, gen_loss = 0.3924472868013725, disc_loss = 0.10303134082568635
Trained batch 139 in epoch 13, gen_loss = 0.3925671820129667, disc_loss = 0.10264332499355078
Trained batch 140 in epoch 13, gen_loss = 0.3928865703707891, disc_loss = 0.10270698857328571
Trained batch 141 in epoch 13, gen_loss = 0.39258539949504423, disc_loss = 0.10300156718093745
Trained batch 142 in epoch 13, gen_loss = 0.3925239179101024, disc_loss = 0.10293094696594285
Trained batch 143 in epoch 13, gen_loss = 0.3928643053190576, disc_loss = 0.10273432165073852
Trained batch 144 in epoch 13, gen_loss = 0.3925633675065534, disc_loss = 0.10318621913420743
Trained batch 145 in epoch 13, gen_loss = 0.39316517094226733, disc_loss = 0.10394196470000155
Trained batch 146 in epoch 13, gen_loss = 0.39264972295079914, disc_loss = 0.1046762748488358
Trained batch 147 in epoch 13, gen_loss = 0.3926809941594665, disc_loss = 0.10457154607551324
Trained batch 148 in epoch 13, gen_loss = 0.3927772417164489, disc_loss = 0.10436564896430746
Trained batch 149 in epoch 13, gen_loss = 0.3929716388384501, disc_loss = 0.10445935674011707
Trained batch 150 in epoch 13, gen_loss = 0.3931229349398455, disc_loss = 0.10429978915891111
Trained batch 151 in epoch 13, gen_loss = 0.3935483115676202, disc_loss = 0.1043791702066205
Trained batch 152 in epoch 13, gen_loss = 0.39388703890875276, disc_loss = 0.10435894606452362
Trained batch 153 in epoch 13, gen_loss = 0.39390623859770885, disc_loss = 0.1042934807815722
Trained batch 154 in epoch 13, gen_loss = 0.39376375944383685, disc_loss = 0.10441148567103571
Trained batch 155 in epoch 13, gen_loss = 0.39361499135310835, disc_loss = 0.10460014132639536
Trained batch 156 in epoch 13, gen_loss = 0.39364765954625075, disc_loss = 0.10486094157691973
Trained batch 157 in epoch 13, gen_loss = 0.39410597368886197, disc_loss = 0.10446400751795949
Trained batch 158 in epoch 13, gen_loss = 0.3940224233288435, disc_loss = 0.1041254977104049
Trained batch 159 in epoch 13, gen_loss = 0.3945009853690863, disc_loss = 0.10395365785807371
Trained batch 160 in epoch 13, gen_loss = 0.3946334293910435, disc_loss = 0.10387177098982082
Trained batch 161 in epoch 13, gen_loss = 0.39430917689093836, disc_loss = 0.10432210987732735
Trained batch 162 in epoch 13, gen_loss = 0.39458630713948445, disc_loss = 0.10397715807143897
Trained batch 163 in epoch 13, gen_loss = 0.3944661713591436, disc_loss = 0.10375021134571331
Trained batch 164 in epoch 13, gen_loss = 0.3941157017693375, disc_loss = 0.10344620647303986
Trained batch 165 in epoch 13, gen_loss = 0.39425461855997523, disc_loss = 0.10317548703267632
Trained batch 166 in epoch 13, gen_loss = 0.39459798739341917, disc_loss = 0.10276863761915418
Trained batch 167 in epoch 13, gen_loss = 0.39465154317163287, disc_loss = 0.10221026046755946
Trained batch 168 in epoch 13, gen_loss = 0.3944025723891851, disc_loss = 0.1020958898258368
Trained batch 169 in epoch 13, gen_loss = 0.395055274402394, disc_loss = 0.10279866003924433
Trained batch 170 in epoch 13, gen_loss = 0.3948549771169473, disc_loss = 0.10335770626797487
Trained batch 171 in epoch 13, gen_loss = 0.39510973646890285, disc_loss = 0.10315307501032082
Trained batch 172 in epoch 13, gen_loss = 0.3947271933789887, disc_loss = 0.10305506506170324
Trained batch 173 in epoch 13, gen_loss = 0.3948464895459427, disc_loss = 0.10290864395277424
Trained batch 174 in epoch 13, gen_loss = 0.394722330059324, disc_loss = 0.10303231403763805
Trained batch 175 in epoch 13, gen_loss = 0.39474754678932106, disc_loss = 0.10260620078770444
Trained batch 176 in epoch 13, gen_loss = 0.39479604060367, disc_loss = 0.10215263280722886
Trained batch 177 in epoch 13, gen_loss = 0.39475785932514107, disc_loss = 0.10201448505074623
Trained batch 178 in epoch 13, gen_loss = 0.3951843249398237, disc_loss = 0.10180282594334314
Trained batch 179 in epoch 13, gen_loss = 0.39552134126424787, disc_loss = 0.10227524209250179
Trained batch 180 in epoch 13, gen_loss = 0.3953237113702363, disc_loss = 0.10268519573345862
Trained batch 181 in epoch 13, gen_loss = 0.39509513384693273, disc_loss = 0.1025220189438007
Trained batch 182 in epoch 13, gen_loss = 0.39553295670311306, disc_loss = 0.10232146558112623
Trained batch 183 in epoch 13, gen_loss = 0.3956943811929744, disc_loss = 0.10211724165887774
Trained batch 184 in epoch 13, gen_loss = 0.395360110257123, disc_loss = 0.10294364829220481
Trained batch 185 in epoch 13, gen_loss = 0.39589931070804596, disc_loss = 0.10316050502782066
Trained batch 186 in epoch 13, gen_loss = 0.39600411647143846, disc_loss = 0.10297026897078371
Trained batch 187 in epoch 13, gen_loss = 0.39576360852794445, disc_loss = 0.10274046649066533
Trained batch 188 in epoch 13, gen_loss = 0.3960880670282576, disc_loss = 0.10287673808338624
Trained batch 189 in epoch 13, gen_loss = 0.39603681893725146, disc_loss = 0.10266313107292119
Trained batch 190 in epoch 13, gen_loss = 0.39584182413460695, disc_loss = 0.10270905051458412
Trained batch 191 in epoch 13, gen_loss = 0.3961173173350592, disc_loss = 0.10266003153810743
Trained batch 192 in epoch 13, gen_loss = 0.3962144813080526, disc_loss = 0.10251895845457526
Trained batch 193 in epoch 13, gen_loss = 0.3962102094569157, disc_loss = 0.1022562085382026
Trained batch 194 in epoch 13, gen_loss = 0.39595252321316643, disc_loss = 0.10246715464939674
Trained batch 195 in epoch 13, gen_loss = 0.3957677006113286, disc_loss = 0.10302813879062174
Trained batch 196 in epoch 13, gen_loss = 0.39568292625664453, disc_loss = 0.10288708475016549
Trained batch 197 in epoch 13, gen_loss = 0.3954635721565497, disc_loss = 0.10267413516218464
Trained batch 198 in epoch 13, gen_loss = 0.39530067812258274, disc_loss = 0.10257008517788134
Trained batch 199 in epoch 13, gen_loss = 0.39516535684466364, disc_loss = 0.10219870138447731
Trained batch 200 in epoch 13, gen_loss = 0.3951485606271829, disc_loss = 0.1019092739434607
Trained batch 201 in epoch 13, gen_loss = 0.39532249708576955, disc_loss = 0.1014761318830718
Trained batch 202 in epoch 13, gen_loss = 0.39497130213699905, disc_loss = 0.10106517798427878
Trained batch 203 in epoch 13, gen_loss = 0.3949415918950941, disc_loss = 0.10079983444701807
Trained batch 204 in epoch 13, gen_loss = 0.3948079924757888, disc_loss = 0.1005428379446995
Trained batch 205 in epoch 13, gen_loss = 0.39496472694920104, disc_loss = 0.1002407957193921
Trained batch 206 in epoch 13, gen_loss = 0.39559581875801086, disc_loss = 0.1003599362672815
Trained batch 207 in epoch 13, gen_loss = 0.39535354994810545, disc_loss = 0.10061038650858861
Trained batch 208 in epoch 13, gen_loss = 0.3954698941068786, disc_loss = 0.10019401539313166
Trained batch 209 in epoch 13, gen_loss = 0.396161643805958, disc_loss = 0.10063780947100548
Trained batch 210 in epoch 13, gen_loss = 0.39624412633231465, disc_loss = 0.10094204273127831
Trained batch 211 in epoch 13, gen_loss = 0.39617626242480186, disc_loss = 0.10069066217555753
Trained batch 212 in epoch 13, gen_loss = 0.3959619012516989, disc_loss = 0.1004659678839462
Trained batch 213 in epoch 13, gen_loss = 0.3959469859288118, disc_loss = 0.10020968274465789
Trained batch 214 in epoch 13, gen_loss = 0.39595622323280155, disc_loss = 0.09995412464405215
Trained batch 215 in epoch 13, gen_loss = 0.3958295752052908, disc_loss = 0.09997768318970446
Trained batch 216 in epoch 13, gen_loss = 0.39600817714968034, disc_loss = 0.10020277877488444
Trained batch 217 in epoch 13, gen_loss = 0.3958743649338364, disc_loss = 0.10015082634438616
Trained batch 218 in epoch 13, gen_loss = 0.39596923178733756, disc_loss = 0.0998127534305124
Trained batch 219 in epoch 13, gen_loss = 0.3958610186522657, disc_loss = 0.09963031207973307
Trained batch 220 in epoch 13, gen_loss = 0.3955905628959518, disc_loss = 0.09944905241218088
Trained batch 221 in epoch 13, gen_loss = 0.39536439942884016, disc_loss = 0.09940101624139257
Trained batch 222 in epoch 13, gen_loss = 0.39546681599766687, disc_loss = 0.09918652499938226
Trained batch 223 in epoch 13, gen_loss = 0.3957644916538681, disc_loss = 0.0990063946394782
Trained batch 224 in epoch 13, gen_loss = 0.3956599285867479, disc_loss = 0.09900425061583519
Trained batch 225 in epoch 13, gen_loss = 0.3956313853242756, disc_loss = 0.09915058240624128
Trained batch 226 in epoch 13, gen_loss = 0.39572827091301066, disc_loss = 0.09910073297073663
Trained batch 227 in epoch 13, gen_loss = 0.3964810350485015, disc_loss = 0.09888977219203585
Trained batch 228 in epoch 13, gen_loss = 0.396359352826031, disc_loss = 0.09872817430303607
Trained batch 229 in epoch 13, gen_loss = 0.3962115438088127, disc_loss = 0.09847080796633077
Trained batch 230 in epoch 13, gen_loss = 0.396446422323004, disc_loss = 0.09810534457059263
Trained batch 231 in epoch 13, gen_loss = 0.3969057549176545, disc_loss = 0.09788372708436359
Trained batch 232 in epoch 13, gen_loss = 0.39681825770840623, disc_loss = 0.0976482112112539
Trained batch 233 in epoch 13, gen_loss = 0.3967191284028893, disc_loss = 0.09753278289865862
Trained batch 234 in epoch 13, gen_loss = 0.39663761093261396, disc_loss = 0.09731423043586472
Trained batch 235 in epoch 13, gen_loss = 0.3968001865481926, disc_loss = 0.09710868221107807
Trained batch 236 in epoch 13, gen_loss = 0.39666929438647336, disc_loss = 0.09697140958002977
Trained batch 237 in epoch 13, gen_loss = 0.3966105574068903, disc_loss = 0.0971917344468544
Trained batch 238 in epoch 13, gen_loss = 0.39701776861146904, disc_loss = 0.09736482372359377
Trained batch 239 in epoch 13, gen_loss = 0.39744323765238126, disc_loss = 0.09704891709067548
Trained batch 240 in epoch 13, gen_loss = 0.3973720370486564, disc_loss = 0.09681439675251602
Trained batch 241 in epoch 13, gen_loss = 0.3977035830828769, disc_loss = 0.09659689739115598
Trained batch 242 in epoch 13, gen_loss = 0.39811908597808804, disc_loss = 0.0962722743650584
Trained batch 243 in epoch 13, gen_loss = 0.3981203800830685, disc_loss = 0.09610214767229484
Trained batch 244 in epoch 13, gen_loss = 0.39830652609163403, disc_loss = 0.09594917410262385
Trained batch 245 in epoch 13, gen_loss = 0.39842406860212, disc_loss = 0.09572703543126704
Trained batch 246 in epoch 13, gen_loss = 0.3983197603148487, disc_loss = 0.09581901806101263
Trained batch 247 in epoch 13, gen_loss = 0.39839119031544656, disc_loss = 0.0957612153180244
Trained batch 248 in epoch 13, gen_loss = 0.39820853773369846, disc_loss = 0.09558797795624738
Trained batch 249 in epoch 13, gen_loss = 0.3980217846632004, disc_loss = 0.09531088859960436
Trained batch 250 in epoch 13, gen_loss = 0.39785818144144763, disc_loss = 0.0953409760648689
Trained batch 251 in epoch 13, gen_loss = 0.39828933739946004, disc_loss = 0.0960645500444881
Trained batch 252 in epoch 13, gen_loss = 0.39831393238584045, disc_loss = 0.0961699216136996
Trained batch 253 in epoch 13, gen_loss = 0.39837826272164745, disc_loss = 0.09588675534235329
Trained batch 254 in epoch 13, gen_loss = 0.3986233514897964, disc_loss = 0.0957318562539477
Trained batch 255 in epoch 13, gen_loss = 0.3984380828915164, disc_loss = 0.09563069083742448
Trained batch 256 in epoch 13, gen_loss = 0.3986028558085401, disc_loss = 0.0953181938192144
Trained batch 257 in epoch 13, gen_loss = 0.39853927701018577, disc_loss = 0.09509993592176096
Trained batch 258 in epoch 13, gen_loss = 0.3985346730611499, disc_loss = 0.09526142362203147
Trained batch 259 in epoch 13, gen_loss = 0.39792609323675815, disc_loss = 0.09575279308483005
Trained batch 260 in epoch 13, gen_loss = 0.39804946811034764, disc_loss = 0.09593369682601356
Trained batch 261 in epoch 13, gen_loss = 0.39820151286953276, disc_loss = 0.0957550298038671
Trained batch 262 in epoch 13, gen_loss = 0.39815562878498106, disc_loss = 0.09565687249680209
Trained batch 263 in epoch 13, gen_loss = 0.3986138232390989, disc_loss = 0.09590131797206898
Trained batch 264 in epoch 13, gen_loss = 0.39871846949154477, disc_loss = 0.09636762133043891
Trained batch 265 in epoch 13, gen_loss = 0.3988554681042083, disc_loss = 0.09637704913861546
Trained batch 266 in epoch 13, gen_loss = 0.3991500227973702, disc_loss = 0.09671201355308852
Trained batch 267 in epoch 13, gen_loss = 0.39929467434091354, disc_loss = 0.09672595993546185
Trained batch 268 in epoch 13, gen_loss = 0.3994081789786931, disc_loss = 0.09654640854374405
Trained batch 269 in epoch 13, gen_loss = 0.39950014932288064, disc_loss = 0.09659158826840145
Trained batch 270 in epoch 13, gen_loss = 0.3991406785935933, disc_loss = 0.09658796372531304
Trained batch 271 in epoch 13, gen_loss = 0.3990458303185947, disc_loss = 0.09655062579686809
Trained batch 272 in epoch 13, gen_loss = 0.3989279874406018, disc_loss = 0.09653355423429291
Trained batch 273 in epoch 13, gen_loss = 0.3988345262669299, disc_loss = 0.0963242069416999
Trained batch 274 in epoch 13, gen_loss = 0.3988266195492311, disc_loss = 0.09615476511418819
Trained batch 275 in epoch 13, gen_loss = 0.39858987328150997, disc_loss = 0.0960854666132102
Trained batch 276 in epoch 13, gen_loss = 0.398474588559853, disc_loss = 0.09621817110919996
Trained batch 277 in epoch 13, gen_loss = 0.39840569186339275, disc_loss = 0.09626244923113275
Trained batch 278 in epoch 13, gen_loss = 0.39826687908728065, disc_loss = 0.09653698851264292
Trained batch 279 in epoch 13, gen_loss = 0.3981125272278275, disc_loss = 0.09691134806323265
Trained batch 280 in epoch 13, gen_loss = 0.39860628089234496, disc_loss = 0.09690756083621885
Trained batch 281 in epoch 13, gen_loss = 0.39825996465928165, disc_loss = 0.09707320186289702
Trained batch 282 in epoch 13, gen_loss = 0.39869273219639334, disc_loss = 0.09700035854726503
Trained batch 283 in epoch 13, gen_loss = 0.3984624939170522, disc_loss = 0.09688343097862433
Trained batch 284 in epoch 13, gen_loss = 0.39840867681461467, disc_loss = 0.0969361008586068
Trained batch 285 in epoch 13, gen_loss = 0.39846748504396917, disc_loss = 0.09697545567931204
Trained batch 286 in epoch 13, gen_loss = 0.39855140868171995, disc_loss = 0.09673621267313949
Trained batch 287 in epoch 13, gen_loss = 0.39851642022323275, disc_loss = 0.09660522939197512
Trained batch 288 in epoch 13, gen_loss = 0.39849206913507523, disc_loss = 0.09646107175848269
Trained batch 289 in epoch 13, gen_loss = 0.39829512346407464, disc_loss = 0.09653814151754667
Trained batch 290 in epoch 13, gen_loss = 0.3981060906476581, disc_loss = 0.0964502394135363
Trained batch 291 in epoch 13, gen_loss = 0.3981502685338667, disc_loss = 0.09624778932879029
Trained batch 292 in epoch 13, gen_loss = 0.39829096121796165, disc_loss = 0.09601466465779539
Trained batch 293 in epoch 13, gen_loss = 0.39811041104753003, disc_loss = 0.09629437014409879
Trained batch 294 in epoch 13, gen_loss = 0.3980856242321305, disc_loss = 0.09611134227302115
Trained batch 295 in epoch 13, gen_loss = 0.3979018914035043, disc_loss = 0.09600077933203932
Trained batch 296 in epoch 13, gen_loss = 0.39799716371277766, disc_loss = 0.09592365913770416
Trained batch 297 in epoch 13, gen_loss = 0.3978714007359223, disc_loss = 0.09574608828547417
Trained batch 298 in epoch 13, gen_loss = 0.3979183368160573, disc_loss = 0.09566528161981433
Trained batch 299 in epoch 13, gen_loss = 0.3979764307041963, disc_loss = 0.09543688922499617
Trained batch 300 in epoch 13, gen_loss = 0.39796566314673504, disc_loss = 0.09519711526055075
Trained batch 301 in epoch 13, gen_loss = 0.39804856079501033, disc_loss = 0.0952515887121195
Trained batch 302 in epoch 13, gen_loss = 0.39805128772069914, disc_loss = 0.09514741228874957
Trained batch 303 in epoch 13, gen_loss = 0.3984104426773755, disc_loss = 0.09526873976114746
Trained batch 304 in epoch 13, gen_loss = 0.3982496380317407, disc_loss = 0.09555517066819746
Trained batch 305 in epoch 13, gen_loss = 0.3982486342585165, disc_loss = 0.09642549631569315
Trained batch 306 in epoch 13, gen_loss = 0.3980534231526844, disc_loss = 0.09736934200487424
Trained batch 307 in epoch 13, gen_loss = 0.3981888462099936, disc_loss = 0.09785369883424469
Trained batch 308 in epoch 13, gen_loss = 0.39817520286465924, disc_loss = 0.097908019543321
Trained batch 309 in epoch 13, gen_loss = 0.39819123720930466, disc_loss = 0.09794459002272736
Trained batch 310 in epoch 13, gen_loss = 0.39803937034399944, disc_loss = 0.097886590023564
Trained batch 311 in epoch 13, gen_loss = 0.3978327713811245, disc_loss = 0.09801744429084162
Trained batch 312 in epoch 13, gen_loss = 0.3978280056113252, disc_loss = 0.09817553945361807
Trained batch 313 in epoch 13, gen_loss = 0.39784515364344714, disc_loss = 0.0981318531913837
Trained batch 314 in epoch 13, gen_loss = 0.39767622205000075, disc_loss = 0.09821923486888409
Trained batch 315 in epoch 13, gen_loss = 0.39763718216290955, disc_loss = 0.09818465371698706
Trained batch 316 in epoch 13, gen_loss = 0.397608611626956, disc_loss = 0.09803939038999261
Trained batch 317 in epoch 13, gen_loss = 0.39726207395956953, disc_loss = 0.0983853062216497
Trained batch 318 in epoch 13, gen_loss = 0.397482910453339, disc_loss = 0.09877831392504018
Trained batch 319 in epoch 13, gen_loss = 0.39735917109064756, disc_loss = 0.09865100751048886
Trained batch 320 in epoch 13, gen_loss = 0.3970519957419868, disc_loss = 0.09872521652123453
Trained batch 321 in epoch 13, gen_loss = 0.3972280584044338, disc_loss = 0.09854562163514935
Trained batch 322 in epoch 13, gen_loss = 0.3973058349115561, disc_loss = 0.09845625211833615
Trained batch 323 in epoch 13, gen_loss = 0.39706284612601184, disc_loss = 0.09833668613300463
Trained batch 324 in epoch 13, gen_loss = 0.39695688701592957, disc_loss = 0.09856606748814767
Trained batch 325 in epoch 13, gen_loss = 0.3971023971409154, disc_loss = 0.09902034617069126
Trained batch 326 in epoch 13, gen_loss = 0.39719024113741125, disc_loss = 0.09901415881920116
Trained batch 327 in epoch 13, gen_loss = 0.3969880980780212, disc_loss = 0.0990566130125577
Trained batch 328 in epoch 13, gen_loss = 0.3969411310544492, disc_loss = 0.09914422700447696
Trained batch 329 in epoch 13, gen_loss = 0.3970693824417663, disc_loss = 0.09970360546739715
Trained batch 330 in epoch 13, gen_loss = 0.39722139917291543, disc_loss = 0.09979813327039297
Trained batch 331 in epoch 13, gen_loss = 0.39730348191167936, disc_loss = 0.0996855876565608
Trained batch 332 in epoch 13, gen_loss = 0.3970249750324198, disc_loss = 0.1001359684722828
Trained batch 333 in epoch 13, gen_loss = 0.39711763986391935, disc_loss = 0.10036831892870679
Trained batch 334 in epoch 13, gen_loss = 0.39698513101285965, disc_loss = 0.10030216963322305
Trained batch 335 in epoch 13, gen_loss = 0.3967808535145152, disc_loss = 0.10015381364307056
Trained batch 336 in epoch 13, gen_loss = 0.3969647748622413, disc_loss = 0.099908761188211
Trained batch 337 in epoch 13, gen_loss = 0.3970263895286611, disc_loss = 0.099883724086692
Trained batch 338 in epoch 13, gen_loss = 0.39676866810054556, disc_loss = 0.10004445604408561
Trained batch 339 in epoch 13, gen_loss = 0.396666871142738, disc_loss = 0.09985587735496024
Trained batch 340 in epoch 13, gen_loss = 0.39662313133565563, disc_loss = 0.09967649206409882
Trained batch 341 in epoch 13, gen_loss = 0.3966127233634218, disc_loss = 0.09945192471233724
Trained batch 342 in epoch 13, gen_loss = 0.3964967774145805, disc_loss = 0.09928514570562555
Trained batch 343 in epoch 13, gen_loss = 0.3965460477440163, disc_loss = 0.0990449421887481
Trained batch 344 in epoch 13, gen_loss = 0.3966364252826442, disc_loss = 0.09885808921594551
Trained batch 345 in epoch 13, gen_loss = 0.3965881765319433, disc_loss = 0.09870921712734795
Trained batch 346 in epoch 13, gen_loss = 0.3963744829728212, disc_loss = 0.09877673719046096
Trained batch 347 in epoch 13, gen_loss = 0.39638878263790034, disc_loss = 0.09858281496141491
Trained batch 348 in epoch 13, gen_loss = 0.3963796888774309, disc_loss = 0.09857776608414158
Trained batch 349 in epoch 13, gen_loss = 0.3960211738092559, disc_loss = 0.09882933460175991
Trained batch 350 in epoch 13, gen_loss = 0.39622264145276487, disc_loss = 0.0989282469655204
Trained batch 351 in epoch 13, gen_loss = 0.3963232625021853, disc_loss = 0.0989205049964684
Trained batch 352 in epoch 13, gen_loss = 0.3962751178245031, disc_loss = 0.0989840844429755
Trained batch 353 in epoch 13, gen_loss = 0.396353458827835, disc_loss = 0.09889386944725352
Trained batch 354 in epoch 13, gen_loss = 0.39622539294437625, disc_loss = 0.09889742783467534
Trained batch 355 in epoch 13, gen_loss = 0.39603724234392135, disc_loss = 0.09885661256907696
Trained batch 356 in epoch 13, gen_loss = 0.39633220797326385, disc_loss = 0.09892677681661453
Trained batch 357 in epoch 13, gen_loss = 0.39625263776026626, disc_loss = 0.09880364029642257
Trained batch 358 in epoch 13, gen_loss = 0.3961713773543456, disc_loss = 0.09876248752049749
Trained batch 359 in epoch 13, gen_loss = 0.39624333071211976, disc_loss = 0.09925907756098443
Trained batch 360 in epoch 13, gen_loss = 0.3960057063198486, disc_loss = 0.09917633418107297
Trained batch 361 in epoch 13, gen_loss = 0.39588927568157734, disc_loss = 0.09912422158400327
Trained batch 362 in epoch 13, gen_loss = 0.3960545053577292, disc_loss = 0.0991816178641536
Trained batch 363 in epoch 13, gen_loss = 0.39587156183935784, disc_loss = 0.09909835761760945
Trained batch 364 in epoch 13, gen_loss = 0.39577530283633977, disc_loss = 0.09888604384885259
Trained batch 365 in epoch 13, gen_loss = 0.3958641199873445, disc_loss = 0.09864177942387964
Trained batch 366 in epoch 13, gen_loss = 0.3957118022100802, disc_loss = 0.09865040442467304
Trained batch 367 in epoch 13, gen_loss = 0.39585096101560024, disc_loss = 0.09845235511286023
Trained batch 368 in epoch 13, gen_loss = 0.395701419572197, disc_loss = 0.0983548532732255
Trained batch 369 in epoch 13, gen_loss = 0.3954966006649507, disc_loss = 0.09826303461465884
Trained batch 370 in epoch 13, gen_loss = 0.395437155571588, disc_loss = 0.09824871959420789
Trained batch 371 in epoch 13, gen_loss = 0.39571712730873015, disc_loss = 0.09842139701559259
Trained batch 372 in epoch 13, gen_loss = 0.3956077779186315, disc_loss = 0.09835056292177764
Trained batch 373 in epoch 13, gen_loss = 0.39572020165901134, disc_loss = 0.0984287918445699
Trained batch 374 in epoch 13, gen_loss = 0.395584818482399, disc_loss = 0.09870180069158474
Trained batch 375 in epoch 13, gen_loss = 0.3955798856517736, disc_loss = 0.0987636237578625
Trained batch 376 in epoch 13, gen_loss = 0.3956595776647092, disc_loss = 0.09867689530031672
Trained batch 377 in epoch 13, gen_loss = 0.3956853450527267, disc_loss = 0.09856094218662413
Trained batch 378 in epoch 13, gen_loss = 0.39590656501793925, disc_loss = 0.09845314037035119
Trained batch 379 in epoch 13, gen_loss = 0.3960241608321667, disc_loss = 0.09869796988358231
Trained batch 380 in epoch 13, gen_loss = 0.3959387006174548, disc_loss = 0.09924334195488942
Trained batch 381 in epoch 13, gen_loss = 0.3961223961873204, disc_loss = 0.09930558666265057
Trained batch 382 in epoch 13, gen_loss = 0.395921951835834, disc_loss = 0.09944481081414394
Trained batch 383 in epoch 13, gen_loss = 0.3958653932980572, disc_loss = 0.09953711410586645
Trained batch 384 in epoch 13, gen_loss = 0.3956010276233995, disc_loss = 0.09978865578335214
Trained batch 385 in epoch 13, gen_loss = 0.3958064715710946, disc_loss = 0.10026670065636076
Trained batch 386 in epoch 13, gen_loss = 0.39569625239193595, disc_loss = 0.10071218483275145
Trained batch 387 in epoch 13, gen_loss = 0.3957907473380418, disc_loss = 0.10071493341280244
Trained batch 388 in epoch 13, gen_loss = 0.3958634886229866, disc_loss = 0.10071286558865505
Trained batch 389 in epoch 13, gen_loss = 0.3959477578600248, disc_loss = 0.10094460218141858
Trained batch 390 in epoch 13, gen_loss = 0.3961041487010239, disc_loss = 0.10084359275172357
Trained batch 391 in epoch 13, gen_loss = 0.3961778113960612, disc_loss = 0.1007602753245975
Trained batch 392 in epoch 13, gen_loss = 0.3961209304080968, disc_loss = 0.10058470539341068
Trained batch 393 in epoch 13, gen_loss = 0.3959712903133504, disc_loss = 0.10045893675397118
Trained batch 394 in epoch 13, gen_loss = 0.39601993217498443, disc_loss = 0.10033930578516631
Trained batch 395 in epoch 13, gen_loss = 0.3961572785946456, disc_loss = 0.10016193049207255
Trained batch 396 in epoch 13, gen_loss = 0.3961277616489444, disc_loss = 0.10009371421959073
Trained batch 397 in epoch 13, gen_loss = 0.3964345145540022, disc_loss = 0.10013909883394688
Trained batch 398 in epoch 13, gen_loss = 0.3962577895487759, disc_loss = 0.10016698312051688
Trained batch 399 in epoch 13, gen_loss = 0.39601402666419744, disc_loss = 0.1003650431917049
Trained batch 400 in epoch 13, gen_loss = 0.3960810785653288, disc_loss = 0.10017000057239857
Trained batch 401 in epoch 13, gen_loss = 0.39633513034427936, disc_loss = 0.10011194683657727
Trained batch 402 in epoch 13, gen_loss = 0.39634972245018774, disc_loss = 0.10001417754388994
Trained batch 403 in epoch 13, gen_loss = 0.3961829795769536, disc_loss = 0.09991324809379876
Trained batch 404 in epoch 13, gen_loss = 0.39596444173359574, disc_loss = 0.09993284679719328
Trained batch 405 in epoch 13, gen_loss = 0.39594792604005985, disc_loss = 0.10004216359396066
Trained batch 406 in epoch 13, gen_loss = 0.396120562343984, disc_loss = 0.10006254578480629
Trained batch 407 in epoch 13, gen_loss = 0.3961725727673255, disc_loss = 0.09995465320489351
Trained batch 408 in epoch 13, gen_loss = 0.39665773040945196, disc_loss = 0.10018798046059961
Trained batch 409 in epoch 13, gen_loss = 0.3966466774664274, disc_loss = 0.10016240161593731
Trained batch 410 in epoch 13, gen_loss = 0.39663741735791347, disc_loss = 0.10009259094513609
Trained batch 411 in epoch 13, gen_loss = 0.39682157080873703, disc_loss = 0.10023846018164265
Trained batch 412 in epoch 13, gen_loss = 0.3967106979854459, disc_loss = 0.10007793189547325
Trained batch 413 in epoch 13, gen_loss = 0.39662203174714306, disc_loss = 0.09989471428753169
Trained batch 414 in epoch 13, gen_loss = 0.3965595717530653, disc_loss = 0.09979520405317287
Trained batch 415 in epoch 13, gen_loss = 0.3967052113193159, disc_loss = 0.10015822983964776
Trained batch 416 in epoch 13, gen_loss = 0.39649878199294886, disc_loss = 0.10053978493432704
Trained batch 417 in epoch 13, gen_loss = 0.39658217042969746, disc_loss = 0.100335694693528
Trained batch 418 in epoch 13, gen_loss = 0.39658630189434724, disc_loss = 0.10037296212462793
Trained batch 419 in epoch 13, gen_loss = 0.39645955814492134, disc_loss = 0.10043949149992494
Trained batch 420 in epoch 13, gen_loss = 0.39640547873147025, disc_loss = 0.10042177567661091
Trained batch 421 in epoch 13, gen_loss = 0.3964621256948647, disc_loss = 0.10080889727637807
Trained batch 422 in epoch 13, gen_loss = 0.39626573899818085, disc_loss = 0.10091429531803227
Trained batch 423 in epoch 13, gen_loss = 0.3962748570473127, disc_loss = 0.10093176184345107
Trained batch 424 in epoch 13, gen_loss = 0.3962844556570053, disc_loss = 0.10094638235867023
Trained batch 425 in epoch 13, gen_loss = 0.3962823097624689, disc_loss = 0.10092444408754928
Trained batch 426 in epoch 13, gen_loss = 0.3962609729177779, disc_loss = 0.10090948592880152
Trained batch 427 in epoch 13, gen_loss = 0.3962525974297635, disc_loss = 0.10084111229995284
Trained batch 428 in epoch 13, gen_loss = 0.3961935931499744, disc_loss = 0.1007340309407675
Trained batch 429 in epoch 13, gen_loss = 0.39624521881341934, disc_loss = 0.10079166903485393
Trained batch 430 in epoch 13, gen_loss = 0.3962535921423728, disc_loss = 0.10100421921853538
Trained batch 431 in epoch 13, gen_loss = 0.396497483710172, disc_loss = 0.10102563910617458
Trained batch 432 in epoch 13, gen_loss = 0.396464946879801, disc_loss = 0.10091057454620855
Trained batch 433 in epoch 13, gen_loss = 0.3963971564091296, disc_loss = 0.10075492889530235
Trained batch 434 in epoch 13, gen_loss = 0.39616145810176584, disc_loss = 0.10069620907734865
Trained batch 435 in epoch 13, gen_loss = 0.39625041470478434, disc_loss = 0.10058413988081824
Trained batch 436 in epoch 13, gen_loss = 0.39624692806526507, disc_loss = 0.10046106425606277
Trained batch 437 in epoch 13, gen_loss = 0.3961409278996459, disc_loss = 0.10033058310905683
Trained batch 438 in epoch 13, gen_loss = 0.39603107560061107, disc_loss = 0.10032863915390876
Trained batch 439 in epoch 13, gen_loss = 0.39632934077896853, disc_loss = 0.10022095802070742
Trained batch 440 in epoch 13, gen_loss = 0.39627747129556, disc_loss = 0.10004034023858657
Trained batch 441 in epoch 13, gen_loss = 0.39623267763205783, disc_loss = 0.1000582338500414
Trained batch 442 in epoch 13, gen_loss = 0.3962498462967087, disc_loss = 0.10035566437745605
Trained batch 443 in epoch 13, gen_loss = 0.3962740552787845, disc_loss = 0.1003739751313251
Trained batch 444 in epoch 13, gen_loss = 0.3963824253068881, disc_loss = 0.10029813419985638
Trained batch 445 in epoch 13, gen_loss = 0.3962940616792093, disc_loss = 0.10014857373079243
Trained batch 446 in epoch 13, gen_loss = 0.39636645877787996, disc_loss = 0.10004421103103982
Trained batch 447 in epoch 13, gen_loss = 0.3961770017963967, disc_loss = 0.10020331051782705
Trained batch 448 in epoch 13, gen_loss = 0.396432096914353, disc_loss = 0.10048178012144725
Trained batch 449 in epoch 13, gen_loss = 0.39648120519187713, disc_loss = 0.10036457146621412
Trained batch 450 in epoch 13, gen_loss = 0.39651127807184755, disc_loss = 0.10018966702575033
Trained batch 451 in epoch 13, gen_loss = 0.39641946900339253, disc_loss = 0.10006460987971025
Trained batch 452 in epoch 13, gen_loss = 0.39625187099769416, disc_loss = 0.10031426040492705
Trained batch 453 in epoch 13, gen_loss = 0.3963075675693903, disc_loss = 0.10027317970679327
Trained batch 454 in epoch 13, gen_loss = 0.39626754925146207, disc_loss = 0.10016679060082515
Trained batch 455 in epoch 13, gen_loss = 0.3962486620600286, disc_loss = 0.10014957382768523
Trained batch 456 in epoch 13, gen_loss = 0.3962996667597435, disc_loss = 0.10002657557945674
Trained batch 457 in epoch 13, gen_loss = 0.39625204855568025, disc_loss = 0.09988370144487599
Trained batch 458 in epoch 13, gen_loss = 0.39640958477339194, disc_loss = 0.09973983245461465
Trained batch 459 in epoch 13, gen_loss = 0.39642542850064194, disc_loss = 0.0997499849282853
Trained batch 460 in epoch 13, gen_loss = 0.39619858032839933, disc_loss = 0.09966363849566841
Testing Epoch 13
Training Epoch 14
Trained batch 0 in epoch 14, gen_loss = 0.3567750155925751, disc_loss = 0.06363820284605026
Trained batch 1 in epoch 14, gen_loss = 0.4067663103342056, disc_loss = 0.15348808094859123
Trained batch 2 in epoch 14, gen_loss = 0.39188237984975177, disc_loss = 0.146783413986365
Trained batch 3 in epoch 14, gen_loss = 0.3944661617279053, disc_loss = 0.11363611719571054
Trained batch 4 in epoch 14, gen_loss = 0.41000574827194214, disc_loss = 0.10520293544977903
Trained batch 5 in epoch 14, gen_loss = 0.39890269935131073, disc_loss = 0.09814239153638482
Trained batch 6 in epoch 14, gen_loss = 0.3983425625732967, disc_loss = 0.0910022087129099
Trained batch 7 in epoch 14, gen_loss = 0.40566737577319145, disc_loss = 0.08740094571840018
Trained batch 8 in epoch 14, gen_loss = 0.4113757179843055, disc_loss = 0.0842706456573473
Trained batch 9 in epoch 14, gen_loss = 0.406963112950325, disc_loss = 0.08237028000876308
Trained batch 10 in epoch 14, gen_loss = 0.40256778489459644, disc_loss = 0.0812041342089122
Trained batch 11 in epoch 14, gen_loss = 0.40263022234042484, disc_loss = 0.08215377999780078
Trained batch 12 in epoch 14, gen_loss = 0.3964802599870242, disc_loss = 0.09101366215886977
Trained batch 13 in epoch 14, gen_loss = 0.4056030660867691, disc_loss = 0.08863534665267382
Trained batch 14 in epoch 14, gen_loss = 0.40715160171190895, disc_loss = 0.09767083519448837
Trained batch 15 in epoch 14, gen_loss = 0.40936530753970146, disc_loss = 0.09521191654494032
Trained batch 16 in epoch 14, gen_loss = 0.41072436641244325, disc_loss = 0.09555544479585745
Trained batch 17 in epoch 14, gen_loss = 0.41177622973918915, disc_loss = 0.09445256776072913
Trained batch 18 in epoch 14, gen_loss = 0.41090918057843256, disc_loss = 0.09216550615076956
Trained batch 19 in epoch 14, gen_loss = 0.41317655295133593, disc_loss = 0.08876204839907587
Trained batch 20 in epoch 14, gen_loss = 0.4113091400691441, disc_loss = 0.09185616720822595
Trained batch 21 in epoch 14, gen_loss = 0.41028798574751074, disc_loss = 0.09090218333188783
Trained batch 22 in epoch 14, gen_loss = 0.4062035342921381, disc_loss = 0.09221440630600504
Trained batch 23 in epoch 14, gen_loss = 0.4134139244755109, disc_loss = 0.09337962585656594
Trained batch 24 in epoch 14, gen_loss = 0.41383679866790773, disc_loss = 0.09095517259091139
Trained batch 25 in epoch 14, gen_loss = 0.4099095773238402, disc_loss = 0.09252848916758712
Trained batch 26 in epoch 14, gen_loss = 0.410273144642512, disc_loss = 0.09156822037227728
Trained batch 27 in epoch 14, gen_loss = 0.4087911258850779, disc_loss = 0.090544468689976
Trained batch 28 in epoch 14, gen_loss = 0.40778068119081956, disc_loss = 0.08902749377463398
Trained batch 29 in epoch 14, gen_loss = 0.40663892130057017, disc_loss = 0.09067275732134779
Trained batch 30 in epoch 14, gen_loss = 0.4083456733534413, disc_loss = 0.09003244109091259
Trained batch 31 in epoch 14, gen_loss = 0.40637444518506527, disc_loss = 0.08832927941693924
Trained batch 32 in epoch 14, gen_loss = 0.4062979600646279, disc_loss = 0.08635780178574902
Trained batch 33 in epoch 14, gen_loss = 0.40558138226761536, disc_loss = 0.08510566949296523
Trained batch 34 in epoch 14, gen_loss = 0.4088702057089124, disc_loss = 0.08511682203305619
Trained batch 35 in epoch 14, gen_loss = 0.4104749626583523, disc_loss = 0.0867104841551433
Trained batch 36 in epoch 14, gen_loss = 0.4107599089274535, disc_loss = 0.08947774171325806
Trained batch 37 in epoch 14, gen_loss = 0.41155003795498296, disc_loss = 0.08998182482135139
Trained batch 38 in epoch 14, gen_loss = 0.4102626771498949, disc_loss = 0.09162135219249205
Trained batch 39 in epoch 14, gen_loss = 0.41178962737321856, disc_loss = 0.0904989626025781
Trained batch 40 in epoch 14, gen_loss = 0.4114119694000337, disc_loss = 0.08906333109863647
Trained batch 41 in epoch 14, gen_loss = 0.41131817939735593, disc_loss = 0.08770607179030776
Trained batch 42 in epoch 14, gen_loss = 0.40891366296036297, disc_loss = 0.08697114510158467
Trained batch 43 in epoch 14, gen_loss = 0.408134669742801, disc_loss = 0.08590627789751372
Trained batch 44 in epoch 14, gen_loss = 0.4091840618186527, disc_loss = 0.08436499608473645
Trained batch 45 in epoch 14, gen_loss = 0.40890642417513806, disc_loss = 0.08425245326741235
Trained batch 46 in epoch 14, gen_loss = 0.4096178475846636, disc_loss = 0.08551153625817375
Trained batch 47 in epoch 14, gen_loss = 0.40962461568415165, disc_loss = 0.08940889521424349
Trained batch 48 in epoch 14, gen_loss = 0.41062600332863475, disc_loss = 0.0897122064073171
Trained batch 49 in epoch 14, gen_loss = 0.4095929503440857, disc_loss = 0.0900673352740705
Trained batch 50 in epoch 14, gen_loss = 0.4090040559862174, disc_loss = 0.08911457743641793
Trained batch 51 in epoch 14, gen_loss = 0.40892860236076206, disc_loss = 0.08829875797248231
Trained batch 52 in epoch 14, gen_loss = 0.40741691668078583, disc_loss = 0.08748283390096336
Trained batch 53 in epoch 14, gen_loss = 0.4067425909969542, disc_loss = 0.0871995407225633
Trained batch 54 in epoch 14, gen_loss = 0.4074359422380274, disc_loss = 0.08664483311162753
Trained batch 55 in epoch 14, gen_loss = 0.4092655282999788, disc_loss = 0.0863282720924222
Trained batch 56 in epoch 14, gen_loss = 0.40747175823178206, disc_loss = 0.08635930839533869
Trained batch 57 in epoch 14, gen_loss = 0.40799880592987453, disc_loss = 0.08640991772749815
Trained batch 58 in epoch 14, gen_loss = 0.40818564619048164, disc_loss = 0.0870698380236656
Trained batch 59 in epoch 14, gen_loss = 0.406903970738252, disc_loss = 0.08629666074799995
Trained batch 60 in epoch 14, gen_loss = 0.4054740212979864, disc_loss = 0.08742821514301125
Trained batch 61 in epoch 14, gen_loss = 0.4070602612149331, disc_loss = 0.08674880944853348
Trained batch 62 in epoch 14, gen_loss = 0.4071812511436523, disc_loss = 0.08816741843013064
Trained batch 63 in epoch 14, gen_loss = 0.40481952717527747, disc_loss = 0.09161917479650583
Trained batch 64 in epoch 14, gen_loss = 0.40431251434179455, disc_loss = 0.09105463525137077
Trained batch 65 in epoch 14, gen_loss = 0.4043818630955436, disc_loss = 0.09012837763029066
Trained batch 66 in epoch 14, gen_loss = 0.4051855237626318, disc_loss = 0.08948666956831715
Trained batch 67 in epoch 14, gen_loss = 0.4056380215813132, disc_loss = 0.0890432964763878
Trained batch 68 in epoch 14, gen_loss = 0.4052596532780191, disc_loss = 0.08986255379420692
Trained batch 69 in epoch 14, gen_loss = 0.4058983836855207, disc_loss = 0.09322175621720297
Trained batch 70 in epoch 14, gen_loss = 0.40486949346434903, disc_loss = 0.09455504765550435
Trained batch 71 in epoch 14, gen_loss = 0.40433639991614556, disc_loss = 0.09426843658244859
Trained batch 72 in epoch 14, gen_loss = 0.4042207463963391, disc_loss = 0.09497170307201473
Trained batch 73 in epoch 14, gen_loss = 0.4033845570441839, disc_loss = 0.09608290841601588
Trained batch 74 in epoch 14, gen_loss = 0.4026206636428833, disc_loss = 0.09586945239454508
Trained batch 75 in epoch 14, gen_loss = 0.40274580960211, disc_loss = 0.09507513079351108
Trained batch 76 in epoch 14, gen_loss = 0.40280956262117856, disc_loss = 0.09470782326171537
Trained batch 77 in epoch 14, gen_loss = 0.4030142842959135, disc_loss = 0.09410786393504494
Trained batch 78 in epoch 14, gen_loss = 0.40284329313266126, disc_loss = 0.09409940378339607
Trained batch 79 in epoch 14, gen_loss = 0.40269445478916166, disc_loss = 0.093382979684975
Trained batch 80 in epoch 14, gen_loss = 0.4036872872599849, disc_loss = 0.0934248052790393
Trained batch 81 in epoch 14, gen_loss = 0.4024149866365805, disc_loss = 0.09420630221096117
Trained batch 82 in epoch 14, gen_loss = 0.4023777350603816, disc_loss = 0.09384554241929786
Trained batch 83 in epoch 14, gen_loss = 0.40242865149463924, disc_loss = 0.09300090202928654
Trained batch 84 in epoch 14, gen_loss = 0.40245992926990287, disc_loss = 0.09237681069575689
Trained batch 85 in epoch 14, gen_loss = 0.40161866018938464, disc_loss = 0.09230679710027437
Trained batch 86 in epoch 14, gen_loss = 0.4009552601425127, disc_loss = 0.09261765993660552
Trained batch 87 in epoch 14, gen_loss = 0.40152025324377144, disc_loss = 0.09221320577092808
Trained batch 88 in epoch 14, gen_loss = 0.4020944997835695, disc_loss = 0.09262639998845505
Trained batch 89 in epoch 14, gen_loss = 0.4020193937751982, disc_loss = 0.09364441379697787
Trained batch 90 in epoch 14, gen_loss = 0.4011966707287254, disc_loss = 0.10077260691508814
Trained batch 91 in epoch 14, gen_loss = 0.4008256067400393, disc_loss = 0.10148915481429709
Trained batch 92 in epoch 14, gen_loss = 0.40049246498333513, disc_loss = 0.10272167714172474
Trained batch 93 in epoch 14, gen_loss = 0.4006018876395327, disc_loss = 0.10256675364291097
Trained batch 94 in epoch 14, gen_loss = 0.4001067999162172, disc_loss = 0.10256888179206534
Trained batch 95 in epoch 14, gen_loss = 0.39932647968331975, disc_loss = 0.10252199775034872
Trained batch 96 in epoch 14, gen_loss = 0.3987531723435392, disc_loss = 0.10224157298156589
Trained batch 97 in epoch 14, gen_loss = 0.39917684574516454, disc_loss = 0.10203500155701625
Trained batch 98 in epoch 14, gen_loss = 0.3981153534518348, disc_loss = 0.10187200978962761
Trained batch 99 in epoch 14, gen_loss = 0.39804415076971056, disc_loss = 0.10145593012683093
Trained batch 100 in epoch 14, gen_loss = 0.3984319036549861, disc_loss = 0.10098432921942803
Trained batch 101 in epoch 14, gen_loss = 0.3984914147386364, disc_loss = 0.10068435136995771
Trained batch 102 in epoch 14, gen_loss = 0.39863533707498344, disc_loss = 0.10007665280108023
Trained batch 103 in epoch 14, gen_loss = 0.39886770569361174, disc_loss = 0.09968824164332965
Trained batch 104 in epoch 14, gen_loss = 0.3994743244988578, disc_loss = 0.09896377769431898
Trained batch 105 in epoch 14, gen_loss = 0.3994782842555136, disc_loss = 0.09927396944565874
Trained batch 106 in epoch 14, gen_loss = 0.39877739409419977, disc_loss = 0.0994844552669152
Trained batch 107 in epoch 14, gen_loss = 0.3994515736897786, disc_loss = 0.09898519685871347
Trained batch 108 in epoch 14, gen_loss = 0.3991824391238186, disc_loss = 0.09906361434061867
Trained batch 109 in epoch 14, gen_loss = 0.3991662467067892, disc_loss = 0.09859624685380947
Trained batch 110 in epoch 14, gen_loss = 0.3995000107868298, disc_loss = 0.09807006669910373
Trained batch 111 in epoch 14, gen_loss = 0.40000960417091846, disc_loss = 0.09812334250558966
Trained batch 112 in epoch 14, gen_loss = 0.39950277531041506, disc_loss = 0.0981718739989189
Trained batch 113 in epoch 14, gen_loss = 0.3990596224341476, disc_loss = 0.09761770387392557
Trained batch 114 in epoch 14, gen_loss = 0.3985657671223516, disc_loss = 0.09741091959016479
Trained batch 115 in epoch 14, gen_loss = 0.3986196728615925, disc_loss = 0.09780752592206259
Trained batch 116 in epoch 14, gen_loss = 0.39835909900502264, disc_loss = 0.09894644714987431
Trained batch 117 in epoch 14, gen_loss = 0.3984666183843451, disc_loss = 0.09996384139946204
Trained batch 118 in epoch 14, gen_loss = 0.39767648342276823, disc_loss = 0.10065527596049198
Trained batch 119 in epoch 14, gen_loss = 0.3986353228489558, disc_loss = 0.10014788766857237
Trained batch 120 in epoch 14, gen_loss = 0.3983546859961896, disc_loss = 0.09952038321028317
Trained batch 121 in epoch 14, gen_loss = 0.3982550885345115, disc_loss = 0.09911208118113582
Trained batch 122 in epoch 14, gen_loss = 0.3979263199054129, disc_loss = 0.09871267525070324
Trained batch 123 in epoch 14, gen_loss = 0.3981017470359802, disc_loss = 0.09833516995422542
Trained batch 124 in epoch 14, gen_loss = 0.3976317949295044, disc_loss = 0.09799239955097437
Trained batch 125 in epoch 14, gen_loss = 0.39805372272218975, disc_loss = 0.09759929643884774
Trained batch 126 in epoch 14, gen_loss = 0.397676222906338, disc_loss = 0.0976184630385182
Trained batch 127 in epoch 14, gen_loss = 0.3970919370185584, disc_loss = 0.09718760912801372
Trained batch 128 in epoch 14, gen_loss = 0.39743277961893597, disc_loss = 0.09691680209032556
Trained batch 129 in epoch 14, gen_loss = 0.39794290570112373, disc_loss = 0.09664022229755154
Trained batch 130 in epoch 14, gen_loss = 0.3978681514281353, disc_loss = 0.09643452143197069
Trained batch 131 in epoch 14, gen_loss = 0.39882067523219367, disc_loss = 0.09668787942042179
Trained batch 132 in epoch 14, gen_loss = 0.398845967045404, disc_loss = 0.09683222901356175
Trained batch 133 in epoch 14, gen_loss = 0.3992763010423575, disc_loss = 0.0965067672598829
Trained batch 134 in epoch 14, gen_loss = 0.3996782770863286, disc_loss = 0.09600359497384893
Trained batch 135 in epoch 14, gen_loss = 0.39888449517243046, disc_loss = 0.09708143779597081
Trained batch 136 in epoch 14, gen_loss = 0.39945870616140156, disc_loss = 0.10063018903380981
Trained batch 137 in epoch 14, gen_loss = 0.40007431977900904, disc_loss = 0.10049992705951782
Trained batch 138 in epoch 14, gen_loss = 0.3998069450152006, disc_loss = 0.10224237923490272
Trained batch 139 in epoch 14, gen_loss = 0.4006530714886529, disc_loss = 0.10274553557724825
Trained batch 140 in epoch 14, gen_loss = 0.4005653145888173, disc_loss = 0.10221463992055638
Trained batch 141 in epoch 14, gen_loss = 0.400397926149234, disc_loss = 0.1017447776738292
Trained batch 142 in epoch 14, gen_loss = 0.400528808365335, disc_loss = 0.10134605149627773
Trained batch 143 in epoch 14, gen_loss = 0.4002322297957208, disc_loss = 0.10107438391100408
Trained batch 144 in epoch 14, gen_loss = 0.4003490700803954, disc_loss = 0.10068668176516377
Trained batch 145 in epoch 14, gen_loss = 0.3999690135864362, disc_loss = 0.10091297346971011
Trained batch 146 in epoch 14, gen_loss = 0.400204042796375, disc_loss = 0.10106064453340914
Trained batch 147 in epoch 14, gen_loss = 0.400352539645659, disc_loss = 0.1007263943414531
Trained batch 148 in epoch 14, gen_loss = 0.40064324508577387, disc_loss = 0.10034820368050928
Trained batch 149 in epoch 14, gen_loss = 0.400494892001152, disc_loss = 0.09996615345900257
Trained batch 150 in epoch 14, gen_loss = 0.40053454515160314, disc_loss = 0.0994688712911594
Trained batch 151 in epoch 14, gen_loss = 0.400639961032491, disc_loss = 0.09920985173850663
Trained batch 152 in epoch 14, gen_loss = 0.400453105666279, disc_loss = 0.09891504765749952
Trained batch 153 in epoch 14, gen_loss = 0.40051454073422915, disc_loss = 0.0996224868183883
Trained batch 154 in epoch 14, gen_loss = 0.4004480108138054, disc_loss = 0.10054549859055588
Trained batch 155 in epoch 14, gen_loss = 0.4006787481216284, disc_loss = 0.10148334613619134
Trained batch 156 in epoch 14, gen_loss = 0.4007020488286474, disc_loss = 0.10170591509289992
Trained batch 157 in epoch 14, gen_loss = 0.40103361406658267, disc_loss = 0.1015690859890531
Trained batch 158 in epoch 14, gen_loss = 0.4013657588628853, disc_loss = 0.10127943342422727
Trained batch 159 in epoch 14, gen_loss = 0.40128745306283237, disc_loss = 0.10106575736426748
Trained batch 160 in epoch 14, gen_loss = 0.4013874986156914, disc_loss = 0.1007719575629934
Trained batch 161 in epoch 14, gen_loss = 0.401142668760853, disc_loss = 0.10087993100032579
Trained batch 162 in epoch 14, gen_loss = 0.40092416756723553, disc_loss = 0.10063423351756086
Trained batch 163 in epoch 14, gen_loss = 0.40091604594050384, disc_loss = 0.10062625838966086
Trained batch 164 in epoch 14, gen_loss = 0.40075575962211146, disc_loss = 0.10034474089854595
Trained batch 165 in epoch 14, gen_loss = 0.40051668451493044, disc_loss = 0.1000389057346227
Trained batch 166 in epoch 14, gen_loss = 0.400411237142757, disc_loss = 0.09962110281057522
Trained batch 167 in epoch 14, gen_loss = 0.4005650274810337, disc_loss = 0.10013611186184876
Trained batch 168 in epoch 14, gen_loss = 0.40097082948543616, disc_loss = 0.099929772995236
Trained batch 169 in epoch 14, gen_loss = 0.4003954645465402, disc_loss = 0.09988545395762605
Trained batch 170 in epoch 14, gen_loss = 0.4009295918090999, disc_loss = 0.09996374506416203
Trained batch 171 in epoch 14, gen_loss = 0.40112470662177996, disc_loss = 0.09968622318512305
Trained batch 172 in epoch 14, gen_loss = 0.4010096052823039, disc_loss = 0.09932440921470437
Trained batch 173 in epoch 14, gen_loss = 0.40102374399530477, disc_loss = 0.0996108830735173
Trained batch 174 in epoch 14, gen_loss = 0.400732250554221, disc_loss = 0.0992873744613358
Trained batch 175 in epoch 14, gen_loss = 0.40062558820301836, disc_loss = 0.09895713103998621
Trained batch 176 in epoch 14, gen_loss = 0.40045331932057093, disc_loss = 0.09870953653218215
Trained batch 177 in epoch 14, gen_loss = 0.4011685516727105, disc_loss = 0.09886232283740734
Trained batch 178 in epoch 14, gen_loss = 0.4011099118760178, disc_loss = 0.09899443064883934
Trained batch 179 in epoch 14, gen_loss = 0.40114717533191047, disc_loss = 0.09918788118391401
Trained batch 180 in epoch 14, gen_loss = 0.4012644877091297, disc_loss = 0.09881130168060077
Trained batch 181 in epoch 14, gen_loss = 0.4010148151562764, disc_loss = 0.09854953662891473
Trained batch 182 in epoch 14, gen_loss = 0.40125679953502175, disc_loss = 0.09892202042999977
Trained batch 183 in epoch 14, gen_loss = 0.4011247561353704, disc_loss = 0.09958477092036248
Trained batch 184 in epoch 14, gen_loss = 0.4013242402592221, disc_loss = 0.09916913251115664
Trained batch 185 in epoch 14, gen_loss = 0.4016360172661402, disc_loss = 0.0994062927571596
Trained batch 186 in epoch 14, gen_loss = 0.4020015680216213, disc_loss = 0.09905896096286129
Trained batch 187 in epoch 14, gen_loss = 0.40203752321131686, disc_loss = 0.09859677387817585
Trained batch 188 in epoch 14, gen_loss = 0.40189480529260385, disc_loss = 0.09821875269707075
Trained batch 189 in epoch 14, gen_loss = 0.40201194647111393, disc_loss = 0.0977582112199774
Trained batch 190 in epoch 14, gen_loss = 0.4019746235839984, disc_loss = 0.09743121565265961
Trained batch 191 in epoch 14, gen_loss = 0.40235376730561256, disc_loss = 0.09710751883782602
Trained batch 192 in epoch 14, gen_loss = 0.4027263452660852, disc_loss = 0.0970143173806794
Trained batch 193 in epoch 14, gen_loss = 0.4024393421780203, disc_loss = 0.09674341929116353
Trained batch 194 in epoch 14, gen_loss = 0.40186728544724293, disc_loss = 0.09721769650872701
Trained batch 195 in epoch 14, gen_loss = 0.4022581841872663, disc_loss = 0.09694469916368169
Trained batch 196 in epoch 14, gen_loss = 0.40219784267057623, disc_loss = 0.09653015467834654
Trained batch 197 in epoch 14, gen_loss = 0.40232821320644535, disc_loss = 0.0962607871195433
Trained batch 198 in epoch 14, gen_loss = 0.4021802996870261, disc_loss = 0.09602803928805656
Trained batch 199 in epoch 14, gen_loss = 0.40203110083937643, disc_loss = 0.0958715354744345
Trained batch 200 in epoch 14, gen_loss = 0.4020328257807452, disc_loss = 0.09594222577983763
Trained batch 201 in epoch 14, gen_loss = 0.4018377073035382, disc_loss = 0.0957485662478179
Trained batch 202 in epoch 14, gen_loss = 0.4014187094026011, disc_loss = 0.09683245252542601
Trained batch 203 in epoch 14, gen_loss = 0.4009734421384101, disc_loss = 0.09736312568808596
Trained batch 204 in epoch 14, gen_loss = 0.40105305168686844, disc_loss = 0.09711098043111767
Trained batch 205 in epoch 14, gen_loss = 0.4008041610127514, disc_loss = 0.09700598763934906
Trained batch 206 in epoch 14, gen_loss = 0.40056575251662213, disc_loss = 0.09683703767036758
Trained batch 207 in epoch 14, gen_loss = 0.4008093715573733, disc_loss = 0.09739554597315593
Trained batch 208 in epoch 14, gen_loss = 0.40071578787274337, disc_loss = 0.09736815151094534
Trained batch 209 in epoch 14, gen_loss = 0.4004914242596853, disc_loss = 0.09717413407883474
Trained batch 210 in epoch 14, gen_loss = 0.40056936718276326, disc_loss = 0.09684372364026958
Trained batch 211 in epoch 14, gen_loss = 0.4004027858938811, disc_loss = 0.09671906641034304
Trained batch 212 in epoch 14, gen_loss = 0.40021746455223906, disc_loss = 0.0971410121209045
Trained batch 213 in epoch 14, gen_loss = 0.400080122262518, disc_loss = 0.09760643109226617
Trained batch 214 in epoch 14, gen_loss = 0.4000380425952202, disc_loss = 0.09750412296243878
Trained batch 215 in epoch 14, gen_loss = 0.4003298369546731, disc_loss = 0.09721449206376241
Trained batch 216 in epoch 14, gen_loss = 0.4004547427052177, disc_loss = 0.09703776612019484
Trained batch 217 in epoch 14, gen_loss = 0.4000878679916399, disc_loss = 0.09685850048591511
Trained batch 218 in epoch 14, gen_loss = 0.4004180669512379, disc_loss = 0.09669693220049551
Trained batch 219 in epoch 14, gen_loss = 0.3998667513782328, disc_loss = 0.09657194523818113
Trained batch 220 in epoch 14, gen_loss = 0.4000023509042835, disc_loss = 0.09668880742363531
Trained batch 221 in epoch 14, gen_loss = 0.3999083899968379, disc_loss = 0.09638211840914714
Trained batch 222 in epoch 14, gen_loss = 0.3998056608732506, disc_loss = 0.09635217846976801
Trained batch 223 in epoch 14, gen_loss = 0.39977187250873875, disc_loss = 0.09615221963862755
Trained batch 224 in epoch 14, gen_loss = 0.39938023302290176, disc_loss = 0.09598526681462924
Trained batch 225 in epoch 14, gen_loss = 0.39894207534009374, disc_loss = 0.09589961182688718
Trained batch 226 in epoch 14, gen_loss = 0.3992062484115231, disc_loss = 0.0959968846701578
Trained batch 227 in epoch 14, gen_loss = 0.3988470218160696, disc_loss = 0.0960230212168474
Trained batch 228 in epoch 14, gen_loss = 0.3990706718124156, disc_loss = 0.09578576272426734
Trained batch 229 in epoch 14, gen_loss = 0.39920362104540286, disc_loss = 0.0955213395635719
Trained batch 230 in epoch 14, gen_loss = 0.3993498729420947, disc_loss = 0.09542501184008854
Trained batch 231 in epoch 14, gen_loss = 0.3990258562924533, disc_loss = 0.09552374358513746
Trained batch 232 in epoch 14, gen_loss = 0.39935371573902506, disc_loss = 0.0954405953667962
Trained batch 233 in epoch 14, gen_loss = 0.3994258396391176, disc_loss = 0.09515445333165236
Trained batch 234 in epoch 14, gen_loss = 0.39933728334751534, disc_loss = 0.09490193966379826
Trained batch 235 in epoch 14, gen_loss = 0.39965698880664374, disc_loss = 0.09494525722180636
Trained batch 236 in epoch 14, gen_loss = 0.39965952675050825, disc_loss = 0.0955162278852005
Trained batch 237 in epoch 14, gen_loss = 0.39971257057510506, disc_loss = 0.09638521517431285
Trained batch 238 in epoch 14, gen_loss = 0.39960824034204045, disc_loss = 0.0964732995358097
Trained batch 239 in epoch 14, gen_loss = 0.39933698512613774, disc_loss = 0.09652614588073144
Trained batch 240 in epoch 14, gen_loss = 0.39913641281147716, disc_loss = 0.0966644289659885
Trained batch 241 in epoch 14, gen_loss = 0.3993232671386939, disc_loss = 0.09653519547336605
Trained batch 242 in epoch 14, gen_loss = 0.3991318259219574, disc_loss = 0.09634023339874705
Trained batch 243 in epoch 14, gen_loss = 0.39921876043081284, disc_loss = 0.09608995681628585
Trained batch 244 in epoch 14, gen_loss = 0.39910584457066595, disc_loss = 0.09591386989519304
Trained batch 245 in epoch 14, gen_loss = 0.3987708009355436, disc_loss = 0.09581613112846768
Trained batch 246 in epoch 14, gen_loss = 0.3992792001137367, disc_loss = 0.09619169482425881
Trained batch 247 in epoch 14, gen_loss = 0.399036732652495, disc_loss = 0.09591261117208388
Trained batch 248 in epoch 14, gen_loss = 0.3986688223947962, disc_loss = 0.09607186404816118
Trained batch 249 in epoch 14, gen_loss = 0.39867896234989164, disc_loss = 0.09610373491048813
Trained batch 250 in epoch 14, gen_loss = 0.3986643101589613, disc_loss = 0.0962167718258512
Trained batch 251 in epoch 14, gen_loss = 0.39858878699560013, disc_loss = 0.09642078035644122
Trained batch 252 in epoch 14, gen_loss = 0.3983983901649596, disc_loss = 0.09642562258384915
Trained batch 253 in epoch 14, gen_loss = 0.39884226458279165, disc_loss = 0.09616090667500037
Trained batch 254 in epoch 14, gen_loss = 0.3986816017066731, disc_loss = 0.09602218145395026
Trained batch 255 in epoch 14, gen_loss = 0.3985067728208378, disc_loss = 0.09572107160784071
Trained batch 256 in epoch 14, gen_loss = 0.39885777513340753, disc_loss = 0.09557828109291044
Trained batch 257 in epoch 14, gen_loss = 0.39842697827852974, disc_loss = 0.0956747875469484
Trained batch 258 in epoch 14, gen_loss = 0.39842162675378867, disc_loss = 0.09556642145234875
Trained batch 259 in epoch 14, gen_loss = 0.3983632540473571, disc_loss = 0.0955911776695687
Trained batch 260 in epoch 14, gen_loss = 0.39806676390527307, disc_loss = 0.09545353602375335
Trained batch 261 in epoch 14, gen_loss = 0.3980299267377562, disc_loss = 0.09543893272270455
Trained batch 262 in epoch 14, gen_loss = 0.39828326323639757, disc_loss = 0.096336356891822
Trained batch 263 in epoch 14, gen_loss = 0.3985012149946256, disc_loss = 0.096299943450669
Trained batch 264 in epoch 14, gen_loss = 0.3987404268867565, disc_loss = 0.09607549848843296
Trained batch 265 in epoch 14, gen_loss = 0.3988583067754157, disc_loss = 0.09611332665120524
Trained batch 266 in epoch 14, gen_loss = 0.3985915874943751, disc_loss = 0.09617195978118909
Trained batch 267 in epoch 14, gen_loss = 0.3984328903146644, disc_loss = 0.09637707821441008
Trained batch 268 in epoch 14, gen_loss = 0.398475886720707, disc_loss = 0.09629761972585797
Trained batch 269 in epoch 14, gen_loss = 0.39854085114267135, disc_loss = 0.09619944315679647
Trained batch 270 in epoch 14, gen_loss = 0.3988915273844096, disc_loss = 0.09605755933948769
Trained batch 271 in epoch 14, gen_loss = 0.3986288122832775, disc_loss = 0.09654575574677438
Trained batch 272 in epoch 14, gen_loss = 0.3989817989178193, disc_loss = 0.09655292519801484
Trained batch 273 in epoch 14, gen_loss = 0.39941248406458946, disc_loss = 0.09633389209825409
Trained batch 274 in epoch 14, gen_loss = 0.39934669852256777, disc_loss = 0.0962861753526059
Trained batch 275 in epoch 14, gen_loss = 0.3994316468420236, disc_loss = 0.09637733154079836
Trained batch 276 in epoch 14, gen_loss = 0.39919014969027, disc_loss = 0.09656664550923053
Trained batch 277 in epoch 14, gen_loss = 0.3993930504690829, disc_loss = 0.09645938325887747
Trained batch 278 in epoch 14, gen_loss = 0.3994032301569498, disc_loss = 0.09619813397072763
Trained batch 279 in epoch 14, gen_loss = 0.39922490960785323, disc_loss = 0.09616615275320198
Trained batch 280 in epoch 14, gen_loss = 0.39929694138812, disc_loss = 0.09620602453439049
Trained batch 281 in epoch 14, gen_loss = 0.3990508514515897, disc_loss = 0.09625976826625725
Trained batch 282 in epoch 14, gen_loss = 0.39873061510783625, disc_loss = 0.09614510558440281
Trained batch 283 in epoch 14, gen_loss = 0.3987785809686486, disc_loss = 0.09586852720059769
Trained batch 284 in epoch 14, gen_loss = 0.39891665389663294, disc_loss = 0.09561192416831067
Trained batch 285 in epoch 14, gen_loss = 0.3989166190157403, disc_loss = 0.09537842262119471
Trained batch 286 in epoch 14, gen_loss = 0.39911999789679925, disc_loss = 0.09525028762216144
Trained batch 287 in epoch 14, gen_loss = 0.39947804332607323, disc_loss = 0.09550133340397021
Trained batch 288 in epoch 14, gen_loss = 0.3994059000666991, disc_loss = 0.09535527333075819
Trained batch 289 in epoch 14, gen_loss = 0.3993138643174336, disc_loss = 0.09519561313991917
Trained batch 290 in epoch 14, gen_loss = 0.39923808716007114, disc_loss = 0.0953698763079762
Trained batch 291 in epoch 14, gen_loss = 0.39924994304980316, disc_loss = 0.0956080741733823
Trained batch 292 in epoch 14, gen_loss = 0.39922816954781987, disc_loss = 0.0954085534228705
Trained batch 293 in epoch 14, gen_loss = 0.3992185939331444, disc_loss = 0.09514980025741519
Trained batch 294 in epoch 14, gen_loss = 0.399241515135361, disc_loss = 0.09495752777083445
Trained batch 295 in epoch 14, gen_loss = 0.39927812313308586, disc_loss = 0.09470431064884807
Trained batch 296 in epoch 14, gen_loss = 0.399181801863391, disc_loss = 0.09447406374720813
Trained batch 297 in epoch 14, gen_loss = 0.39908990803980987, disc_loss = 0.09430744130814435
Trained batch 298 in epoch 14, gen_loss = 0.39918534861360505, disc_loss = 0.09451620457039828
Trained batch 299 in epoch 14, gen_loss = 0.39873711476723356, disc_loss = 0.09446752075726787
Trained batch 300 in epoch 14, gen_loss = 0.39874939872972986, disc_loss = 0.094410915676492
Trained batch 301 in epoch 14, gen_loss = 0.3989154902712399, disc_loss = 0.0944847192627606
Trained batch 302 in epoch 14, gen_loss = 0.39886206319623263, disc_loss = 0.09483753247401698
Trained batch 303 in epoch 14, gen_loss = 0.39908449145916264, disc_loss = 0.09484113237550973
Trained batch 304 in epoch 14, gen_loss = 0.39920448807419323, disc_loss = 0.0945823750962488
Trained batch 305 in epoch 14, gen_loss = 0.39883123825188554, disc_loss = 0.09444653405351382
Trained batch 306 in epoch 14, gen_loss = 0.39879387500620045, disc_loss = 0.09465648667698769
Trained batch 307 in epoch 14, gen_loss = 0.3988042505724089, disc_loss = 0.09441890190778808
Trained batch 308 in epoch 14, gen_loss = 0.3988825452173412, disc_loss = 0.09521776110440203
Trained batch 309 in epoch 14, gen_loss = 0.39866282747637843, disc_loss = 0.09575760941952467
Trained batch 310 in epoch 14, gen_loss = 0.39882041585790384, disc_loss = 0.09566028627575977
Trained batch 311 in epoch 14, gen_loss = 0.39907966248500043, disc_loss = 0.09580135326951933
Trained batch 312 in epoch 14, gen_loss = 0.3989295998510842, disc_loss = 0.09611825897885017
Trained batch 313 in epoch 14, gen_loss = 0.39886025372584155, disc_loss = 0.09608940673980174
Trained batch 314 in epoch 14, gen_loss = 0.39904744606169446, disc_loss = 0.09603296019846484
Trained batch 315 in epoch 14, gen_loss = 0.3988979632341409, disc_loss = 0.09582078991504976
Trained batch 316 in epoch 14, gen_loss = 0.39879795645689736, disc_loss = 0.09576226199157419
Trained batch 317 in epoch 14, gen_loss = 0.39867866170481314, disc_loss = 0.095566459099686
Trained batch 318 in epoch 14, gen_loss = 0.3988056948005593, disc_loss = 0.09553072471346788
Trained batch 319 in epoch 14, gen_loss = 0.3987135736271739, disc_loss = 0.0953969746187795
Trained batch 320 in epoch 14, gen_loss = 0.3986060514442646, disc_loss = 0.09535409206657952
Trained batch 321 in epoch 14, gen_loss = 0.39852521647207484, disc_loss = 0.09520256561545297
Trained batch 322 in epoch 14, gen_loss = 0.3985902947538039, disc_loss = 0.09531758472484886
Trained batch 323 in epoch 14, gen_loss = 0.39881539473563066, disc_loss = 0.09524901168144963
Trained batch 324 in epoch 14, gen_loss = 0.3985515101139362, disc_loss = 0.09507495730542219
Trained batch 325 in epoch 14, gen_loss = 0.3984720706939697, disc_loss = 0.09502010478815236
Trained batch 326 in epoch 14, gen_loss = 0.3986793193248434, disc_loss = 0.09577024841413403
Trained batch 327 in epoch 14, gen_loss = 0.3985445972804616, disc_loss = 0.09572011704284061
Trained batch 328 in epoch 14, gen_loss = 0.3984292995603614, disc_loss = 0.09582047566975323
Trained batch 329 in epoch 14, gen_loss = 0.3983546004150853, disc_loss = 0.09715388814043818
Trained batch 330 in epoch 14, gen_loss = 0.39825465527906156, disc_loss = 0.09712946090250757
Trained batch 331 in epoch 14, gen_loss = 0.39804756551621906, disc_loss = 0.09714089138208921
Trained batch 332 in epoch 14, gen_loss = 0.39812966993263177, disc_loss = 0.09725739278302
Trained batch 333 in epoch 14, gen_loss = 0.39797204375980855, disc_loss = 0.09710748164083607
Trained batch 334 in epoch 14, gen_loss = 0.39776784252764574, disc_loss = 0.09687200145823742
Trained batch 335 in epoch 14, gen_loss = 0.3976906924730256, disc_loss = 0.09676308274113883
Trained batch 336 in epoch 14, gen_loss = 0.3978822146395901, disc_loss = 0.09658154001243921
Trained batch 337 in epoch 14, gen_loss = 0.3978927632760719, disc_loss = 0.09641087000649533
Trained batch 338 in epoch 14, gen_loss = 0.3977992130240156, disc_loss = 0.09627704843768856
Trained batch 339 in epoch 14, gen_loss = 0.3978837117552757, disc_loss = 0.09631061061449787
Trained batch 340 in epoch 14, gen_loss = 0.3977709337413486, disc_loss = 0.09636797918187033
Trained batch 341 in epoch 14, gen_loss = 0.3979995895547476, disc_loss = 0.09623092972286786
Trained batch 342 in epoch 14, gen_loss = 0.3979282207113661, disc_loss = 0.09615094696358932
Trained batch 343 in epoch 14, gen_loss = 0.39783083716797274, disc_loss = 0.09622274947266073
Trained batch 344 in epoch 14, gen_loss = 0.39813583450040957, disc_loss = 0.09630610998449982
Trained batch 345 in epoch 14, gen_loss = 0.3980594367822471, disc_loss = 0.09634913415298124
Trained batch 346 in epoch 14, gen_loss = 0.39787783557468603, disc_loss = 0.09627105211382812
Trained batch 347 in epoch 14, gen_loss = 0.39786406349519204, disc_loss = 0.09615948728296435
Trained batch 348 in epoch 14, gen_loss = 0.3979555528963193, disc_loss = 0.09607217337583915
Trained batch 349 in epoch 14, gen_loss = 0.39800343436854224, disc_loss = 0.09594794048262494
Trained batch 350 in epoch 14, gen_loss = 0.3981084239448917, disc_loss = 0.09601194885402833
Trained batch 351 in epoch 14, gen_loss = 0.39781701243059203, disc_loss = 0.09627315821655263
Trained batch 352 in epoch 14, gen_loss = 0.3978889493361411, disc_loss = 0.0964548521577552
Trained batch 353 in epoch 14, gen_loss = 0.3977030034961, disc_loss = 0.09632765916886471
Trained batch 354 in epoch 14, gen_loss = 0.39764954489721377, disc_loss = 0.09614636417950542
Trained batch 355 in epoch 14, gen_loss = 0.3976168110129539, disc_loss = 0.09592123509102156
Trained batch 356 in epoch 14, gen_loss = 0.397811617503981, disc_loss = 0.09569816725427698
Trained batch 357 in epoch 14, gen_loss = 0.39774257152773146, disc_loss = 0.09559245112055507
Trained batch 358 in epoch 14, gen_loss = 0.3979379947305058, disc_loss = 0.09580470248019131
Trained batch 359 in epoch 14, gen_loss = 0.3975366741418839, disc_loss = 0.09573937575850222
Trained batch 360 in epoch 14, gen_loss = 0.39757199878507704, disc_loss = 0.09573604575154523
Trained batch 361 in epoch 14, gen_loss = 0.3977641391655358, disc_loss = 0.09602631410347164
Trained batch 362 in epoch 14, gen_loss = 0.39792592827610407, disc_loss = 0.09591448830425246
Trained batch 363 in epoch 14, gen_loss = 0.3982369026967457, disc_loss = 0.09574631255652223
Trained batch 364 in epoch 14, gen_loss = 0.39836631221314, disc_loss = 0.09585203416135213
Trained batch 365 in epoch 14, gen_loss = 0.3983589268284417, disc_loss = 0.09573701381316928
Trained batch 366 in epoch 14, gen_loss = 0.39839198811827303, disc_loss = 0.09561415376999398
Trained batch 367 in epoch 14, gen_loss = 0.39856568391880265, disc_loss = 0.09543771191965789
Trained batch 368 in epoch 14, gen_loss = 0.3985325808770611, disc_loss = 0.09541966175019417
Trained batch 369 in epoch 14, gen_loss = 0.3985707535937026, disc_loss = 0.09576032915328805
Trained batch 370 in epoch 14, gen_loss = 0.3985752816791483, disc_loss = 0.09581254338820508
Trained batch 371 in epoch 14, gen_loss = 0.3984684501123685, disc_loss = 0.09562551130550684
Trained batch 372 in epoch 14, gen_loss = 0.39840772100811667, disc_loss = 0.09554523485775128
Trained batch 373 in epoch 14, gen_loss = 0.3982345011623148, disc_loss = 0.09544526495258598
Trained batch 374 in epoch 14, gen_loss = 0.3986716819604238, disc_loss = 0.09560154549777508
Trained batch 375 in epoch 14, gen_loss = 0.3985053178002226, disc_loss = 0.09547998683348774
Trained batch 376 in epoch 14, gen_loss = 0.39840228812131706, disc_loss = 0.09545140263355222
Trained batch 377 in epoch 14, gen_loss = 0.39842849662379615, disc_loss = 0.09537436681548281
Trained batch 378 in epoch 14, gen_loss = 0.3981601466918684, disc_loss = 0.09525724176543526
Trained batch 379 in epoch 14, gen_loss = 0.39816101099315443, disc_loss = 0.09534453291347937
Trained batch 380 in epoch 14, gen_loss = 0.39823337599361347, disc_loss = 0.09516526771381771
Trained batch 381 in epoch 14, gen_loss = 0.3984754612152489, disc_loss = 0.0951118545987063
Trained batch 382 in epoch 14, gen_loss = 0.398386195340916, disc_loss = 0.09524287045118703
Trained batch 383 in epoch 14, gen_loss = 0.39831865128750604, disc_loss = 0.09508427121909335
Trained batch 384 in epoch 14, gen_loss = 0.3981927432023086, disc_loss = 0.09529782063388205
Trained batch 385 in epoch 14, gen_loss = 0.3979006865944887, disc_loss = 0.09544947834135337
Trained batch 386 in epoch 14, gen_loss = 0.39802383044277356, disc_loss = 0.0955941971073779
Trained batch 387 in epoch 14, gen_loss = 0.3982409280292767, disc_loss = 0.09541707053857366
Trained batch 388 in epoch 14, gen_loss = 0.39821329314481935, disc_loss = 0.09554606838903575
Trained batch 389 in epoch 14, gen_loss = 0.3983549279280198, disc_loss = 0.09587275987634292
Trained batch 390 in epoch 14, gen_loss = 0.39835375097706494, disc_loss = 0.09572153809049246
Trained batch 391 in epoch 14, gen_loss = 0.3985214989860447, disc_loss = 0.09565714780925488
Trained batch 392 in epoch 14, gen_loss = 0.3983069825111758, disc_loss = 0.09552471728346124
Trained batch 393 in epoch 14, gen_loss = 0.3982632511914684, disc_loss = 0.09540013083951727
Trained batch 394 in epoch 14, gen_loss = 0.3982851192166534, disc_loss = 0.09529201367610618
Trained batch 395 in epoch 14, gen_loss = 0.39832854451555194, disc_loss = 0.09509616089288635
Trained batch 396 in epoch 14, gen_loss = 0.3981179398313277, disc_loss = 0.09496569549031462
Trained batch 397 in epoch 14, gen_loss = 0.39827863025904897, disc_loss = 0.09480072074948843
Trained batch 398 in epoch 14, gen_loss = 0.39839942428402436, disc_loss = 0.09466674145227089
Trained batch 399 in epoch 14, gen_loss = 0.39815555572509764, disc_loss = 0.0945591903384775
Trained batch 400 in epoch 14, gen_loss = 0.3981840805222566, disc_loss = 0.09454840539659645
Trained batch 401 in epoch 14, gen_loss = 0.3983292173390365, disc_loss = 0.0945139379328608
Trained batch 402 in epoch 14, gen_loss = 0.39830981265226606, disc_loss = 0.09461494702522276
Trained batch 403 in epoch 14, gen_loss = 0.3983802580007232, disc_loss = 0.0948308196822458
Trained batch 404 in epoch 14, gen_loss = 0.3984068720429032, disc_loss = 0.0947276590782919
Trained batch 405 in epoch 14, gen_loss = 0.3983046498351496, disc_loss = 0.09465257911552936
Trained batch 406 in epoch 14, gen_loss = 0.3984877880140956, disc_loss = 0.09453953359578107
Trained batch 407 in epoch 14, gen_loss = 0.39839894645938684, disc_loss = 0.09442956090959556
Trained batch 408 in epoch 14, gen_loss = 0.39842642752640406, disc_loss = 0.09434707245099515
Trained batch 409 in epoch 14, gen_loss = 0.39832361340522765, disc_loss = 0.094166771595071
Trained batch 410 in epoch 14, gen_loss = 0.39827080712701285, disc_loss = 0.09397409943333507
Trained batch 411 in epoch 14, gen_loss = 0.39823313571006347, disc_loss = 0.09387781141886434
Trained batch 412 in epoch 14, gen_loss = 0.3981894273446201, disc_loss = 0.0938275394731226
Trained batch 413 in epoch 14, gen_loss = 0.39805469377605235, disc_loss = 0.09379372931117021
Trained batch 414 in epoch 14, gen_loss = 0.398211485219289, disc_loss = 0.0941322474774108
Trained batch 415 in epoch 14, gen_loss = 0.3980085067451, disc_loss = 0.09434817242436111
Trained batch 416 in epoch 14, gen_loss = 0.39817919240866917, disc_loss = 0.09445161186605334
Trained batch 417 in epoch 14, gen_loss = 0.39803865323796794, disc_loss = 0.09433882433974572
Trained batch 418 in epoch 14, gen_loss = 0.3978568161871098, disc_loss = 0.09423182598873084
Trained batch 419 in epoch 14, gen_loss = 0.3979582066337268, disc_loss = 0.09408801009967213
Trained batch 420 in epoch 14, gen_loss = 0.3977408438142292, disc_loss = 0.0939515705204916
Trained batch 421 in epoch 14, gen_loss = 0.3977225371305411, disc_loss = 0.09386621924090724
Trained batch 422 in epoch 14, gen_loss = 0.39776435832605295, disc_loss = 0.09368203575095387
Trained batch 423 in epoch 14, gen_loss = 0.39763613509119683, disc_loss = 0.09374491937177361
Trained batch 424 in epoch 14, gen_loss = 0.39755941412028145, disc_loss = 0.09417026418096879
Trained batch 425 in epoch 14, gen_loss = 0.3973612702088737, disc_loss = 0.09400671102246488
Trained batch 426 in epoch 14, gen_loss = 0.3971036434592352, disc_loss = 0.09413463143365723
Trained batch 427 in epoch 14, gen_loss = 0.3972278316026536, disc_loss = 0.09406592314801762
Trained batch 428 in epoch 14, gen_loss = 0.39720865722858545, disc_loss = 0.09400021233585053
Trained batch 429 in epoch 14, gen_loss = 0.39711877800697504, disc_loss = 0.09387645229350688
Trained batch 430 in epoch 14, gen_loss = 0.39696500887726965, disc_loss = 0.09371024590599288
Trained batch 431 in epoch 14, gen_loss = 0.39677348132762646, disc_loss = 0.09356163429199821
Trained batch 432 in epoch 14, gen_loss = 0.3968820615260761, disc_loss = 0.09344014010927694
Trained batch 433 in epoch 14, gen_loss = 0.3973058458709497, disc_loss = 0.09336183956622528
Trained batch 434 in epoch 14, gen_loss = 0.39733747278136766, disc_loss = 0.09338213981225572
Trained batch 435 in epoch 14, gen_loss = 0.39706237477446915, disc_loss = 0.09372775620618544
Trained batch 436 in epoch 14, gen_loss = 0.3971584333571471, disc_loss = 0.0937158017498132
Trained batch 437 in epoch 14, gen_loss = 0.39702865066321474, disc_loss = 0.09430817819145172
Trained batch 438 in epoch 14, gen_loss = 0.3968717424636007, disc_loss = 0.09475334530064076
Trained batch 439 in epoch 14, gen_loss = 0.3967649687420238, disc_loss = 0.09488101718439297
Trained batch 440 in epoch 14, gen_loss = 0.3967727857922751, disc_loss = 0.09485917021425402
Trained batch 441 in epoch 14, gen_loss = 0.39666181971314807, disc_loss = 0.09480262443220994
Trained batch 442 in epoch 14, gen_loss = 0.39683439823090355, disc_loss = 0.09482387942735013
Trained batch 443 in epoch 14, gen_loss = 0.3966700881719589, disc_loss = 0.09504897422618694
Trained batch 444 in epoch 14, gen_loss = 0.39661870136689603, disc_loss = 0.09509726998846182
Trained batch 445 in epoch 14, gen_loss = 0.39660035594963705, disc_loss = 0.095239260087767
Trained batch 446 in epoch 14, gen_loss = 0.3963677607793403, disc_loss = 0.09553050916533609
Trained batch 447 in epoch 14, gen_loss = 0.39640978730416726, disc_loss = 0.09577437997463026
Trained batch 448 in epoch 14, gen_loss = 0.3962985727861358, disc_loss = 0.09571595262644816
Trained batch 449 in epoch 14, gen_loss = 0.396063316265742, disc_loss = 0.09591660838988092
Trained batch 450 in epoch 14, gen_loss = 0.3959932281014132, disc_loss = 0.09579252958826374
Trained batch 451 in epoch 14, gen_loss = 0.3962040120917084, disc_loss = 0.09562766483564557
Trained batch 452 in epoch 14, gen_loss = 0.3961492060430792, disc_loss = 0.09555976105150797
Trained batch 453 in epoch 14, gen_loss = 0.39619999887659685, disc_loss = 0.09543989551979802
Trained batch 454 in epoch 14, gen_loss = 0.39636532742898545, disc_loss = 0.09541922307440213
Trained batch 455 in epoch 14, gen_loss = 0.3962738472772272, disc_loss = 0.09536910263756126
Trained batch 456 in epoch 14, gen_loss = 0.3962204172652973, disc_loss = 0.09528132262323825
Trained batch 457 in epoch 14, gen_loss = 0.3961455915041886, disc_loss = 0.09515179675804475
Trained batch 458 in epoch 14, gen_loss = 0.39629792745077014, disc_loss = 0.09501374351400435
Trained batch 459 in epoch 14, gen_loss = 0.39626337834026504, disc_loss = 0.09500937848149435
Trained batch 460 in epoch 14, gen_loss = 0.39636285535166943, disc_loss = 0.09499315060109483
Testing Epoch 14
Training Epoch 15
Trained batch 0 in epoch 15, gen_loss = 0.41932031512260437, disc_loss = 0.05895061790943146
Trained batch 1 in epoch 15, gen_loss = 0.43092180788517, disc_loss = 0.0713111013174057
Trained batch 2 in epoch 15, gen_loss = 0.43574902415275574, disc_loss = 0.06877085814873378
Trained batch 3 in epoch 15, gen_loss = 0.4516388401389122, disc_loss = 0.09311601333320141
Trained batch 4 in epoch 15, gen_loss = 0.42978299856185914, disc_loss = 0.08190603703260421
Trained batch 5 in epoch 15, gen_loss = 0.42811469237009686, disc_loss = 0.08268323416511218
Trained batch 6 in epoch 15, gen_loss = 0.4401810680116926, disc_loss = 0.09010152838059834
Trained batch 7 in epoch 15, gen_loss = 0.4386117309331894, disc_loss = 0.08803348336368799
Trained batch 8 in epoch 15, gen_loss = 0.44664139217800564, disc_loss = 0.08320864248606893
Trained batch 9 in epoch 15, gen_loss = 0.44031186401844025, disc_loss = 0.07740723434835672
Trained batch 10 in epoch 15, gen_loss = 0.43000725182619964, disc_loss = 0.07651825740256092
Trained batch 11 in epoch 15, gen_loss = 0.4289633284012477, disc_loss = 0.07688559483115871
Trained batch 12 in epoch 15, gen_loss = 0.4231481895996974, disc_loss = 0.0803171036621699
Trained batch 13 in epoch 15, gen_loss = 0.4253950608628137, disc_loss = 0.08785652329346963
Trained batch 14 in epoch 15, gen_loss = 0.4250465015570323, disc_loss = 0.08838174355526765
Trained batch 15 in epoch 15, gen_loss = 0.42152431048452854, disc_loss = 0.08444328152108938
Trained batch 16 in epoch 15, gen_loss = 0.419274966506397, disc_loss = 0.08386220662471126
Trained batch 17 in epoch 15, gen_loss = 0.41688135928577846, disc_loss = 0.08271485577440923
Trained batch 18 in epoch 15, gen_loss = 0.4155467717271102, disc_loss = 0.07976548001170158
Trained batch 19 in epoch 15, gen_loss = 0.41519196033477784, disc_loss = 0.07691613575443626
Trained batch 20 in epoch 15, gen_loss = 0.41772018160138813, disc_loss = 0.07537153443055493
Trained batch 21 in epoch 15, gen_loss = 0.4129721237854524, disc_loss = 0.07721281500363891
Trained batch 22 in epoch 15, gen_loss = 0.4089810083741727, disc_loss = 0.07676858657404133
Trained batch 23 in epoch 15, gen_loss = 0.41158820564548176, disc_loss = 0.07694750814698637
Trained batch 24 in epoch 15, gen_loss = 0.40660755515098573, disc_loss = 0.0767302817851305
Trained batch 25 in epoch 15, gen_loss = 0.405963910313753, disc_loss = 0.07943247838948782
Trained batch 26 in epoch 15, gen_loss = 0.4028121343365422, disc_loss = 0.08348740037116739
Trained batch 27 in epoch 15, gen_loss = 0.40434349860463825, disc_loss = 0.08392616341422711
Trained batch 28 in epoch 15, gen_loss = 0.4048228212471666, disc_loss = 0.08299126302630737
Trained batch 29 in epoch 15, gen_loss = 0.40355617900689444, disc_loss = 0.08119343674431244
Trained batch 30 in epoch 15, gen_loss = 0.40285290152795855, disc_loss = 0.07972515789010833
Trained batch 31 in epoch 15, gen_loss = 0.4047557897865772, disc_loss = 0.07832046673865989
Trained batch 32 in epoch 15, gen_loss = 0.4029654029643897, disc_loss = 0.07657649339825819
Trained batch 33 in epoch 15, gen_loss = 0.40305296200163226, disc_loss = 0.0779053848784636
Trained batch 34 in epoch 15, gen_loss = 0.4027854825769152, disc_loss = 0.08158811793795653
Trained batch 35 in epoch 15, gen_loss = 0.40101829916238785, disc_loss = 0.08307483869915207
Trained batch 36 in epoch 15, gen_loss = 0.400349157082068, disc_loss = 0.08358538649170785
Trained batch 37 in epoch 15, gen_loss = 0.40109797763197047, disc_loss = 0.08284457189668167
Trained batch 38 in epoch 15, gen_loss = 0.40027271937101316, disc_loss = 0.08934144107386088
Trained batch 39 in epoch 15, gen_loss = 0.4037740096449852, disc_loss = 0.08979562730528415
Trained batch 41 in epoch 15, gen_loss = 0.40424209904103053, disc_loss = 0.09033136544305653
Trained batch 42 in epoch 15, gen_loss = 0.40375892852627954, disc_loss = 0.08894282930292362
Trained batch 43 in epoch 15, gen_loss = 0.4047391245310957, disc_loss = 0.08800588781014085
Trained batch 44 in epoch 15, gen_loss = 0.4038991120126512, disc_loss = 0.0867260716855526
Trained batch 45 in epoch 15, gen_loss = 0.4047514556542687, disc_loss = 0.08686724831552609
Trained batch 46 in epoch 15, gen_loss = 0.40497625635025347, disc_loss = 0.08670796049719161
Trained batch 47 in epoch 15, gen_loss = 0.40489593086143333, disc_loss = 0.08525561704300344
Trained batch 48 in epoch 15, gen_loss = 0.4037595020264995, disc_loss = 0.0866105292676663
Trained batch 49 in epoch 15, gen_loss = 0.4013544011116028, disc_loss = 0.08955844528973103
Trained batch 50 in epoch 15, gen_loss = 0.40180135240741804, disc_loss = 0.0904089207304459
Trained batch 51 in epoch 15, gen_loss = 0.4018258125736163, disc_loss = 0.09109072852879763
Trained batch 52 in epoch 15, gen_loss = 0.4011176571531116, disc_loss = 0.09049876814462104
Trained batch 53 in epoch 15, gen_loss = 0.4014870728607531, disc_loss = 0.089743469738298
Trained batch 54 in epoch 15, gen_loss = 0.4007705477151004, disc_loss = 0.08910420814698393
Trained batch 55 in epoch 15, gen_loss = 0.4011362822992461, disc_loss = 0.08836546181035894
Trained batch 56 in epoch 15, gen_loss = 0.4023738147919638, disc_loss = 0.09145728184988625
Trained batch 57 in epoch 15, gen_loss = 0.401743041544125, disc_loss = 0.09173264701304765
Trained batch 58 in epoch 15, gen_loss = 0.4014544436487101, disc_loss = 0.09151487582820957
Trained batch 59 in epoch 15, gen_loss = 0.40233941475550333, disc_loss = 0.09431600819031398
Trained batch 60 in epoch 15, gen_loss = 0.4022360839804665, disc_loss = 0.09319119295868718
Trained batch 61 in epoch 15, gen_loss = 0.40157481499256625, disc_loss = 0.09235709947684119
Trained batch 62 in epoch 15, gen_loss = 0.40174379187916953, disc_loss = 0.0912981407036857
Trained batch 63 in epoch 15, gen_loss = 0.4038228332065046, disc_loss = 0.090173586999299
Trained batch 64 in epoch 15, gen_loss = 0.40274048034961407, disc_loss = 0.08948796142179233
Trained batch 65 in epoch 15, gen_loss = 0.40203455451763037, disc_loss = 0.08857225420687234
Trained batch 66 in epoch 15, gen_loss = 0.4010984123642765, disc_loss = 0.0875435576899283
Trained batch 67 in epoch 15, gen_loss = 0.40019271829549, disc_loss = 0.08653375706361498
Trained batch 68 in epoch 15, gen_loss = 0.3997841978418654, disc_loss = 0.08580967354709687
Trained batch 69 in epoch 15, gen_loss = 0.3989139978374754, disc_loss = 0.08582486182983433
Trained batch 70 in epoch 15, gen_loss = 0.3990800703915072, disc_loss = 0.08666014264691883
Trained batch 71 in epoch 15, gen_loss = 0.39727672479218906, disc_loss = 0.08691603796453112
Trained batch 72 in epoch 15, gen_loss = 0.3970408843804712, disc_loss = 0.0867282377989733
Trained batch 73 in epoch 15, gen_loss = 0.3962153578932221, disc_loss = 0.08584855416336575
Trained batch 74 in epoch 15, gen_loss = 0.39557812412579857, disc_loss = 0.08628229826688766
Trained batch 75 in epoch 15, gen_loss = 0.3964703102645121, disc_loss = 0.08943271215416883
Trained batch 76 in epoch 15, gen_loss = 0.39671122485941107, disc_loss = 0.08862576116021577
Trained batch 77 in epoch 15, gen_loss = 0.39644247331680393, disc_loss = 0.08836806235978237
Trained batch 78 in epoch 15, gen_loss = 0.39698912410796444, disc_loss = 0.08779080094227308
Trained batch 79 in epoch 15, gen_loss = 0.39779677242040634, disc_loss = 0.08834923594258726
Trained batch 80 in epoch 15, gen_loss = 0.39809032060481886, disc_loss = 0.0881425312915702
Trained batch 81 in epoch 15, gen_loss = 0.3982238555099906, disc_loss = 0.08754103957879834
Trained batch 82 in epoch 15, gen_loss = 0.39815287381769665, disc_loss = 0.08677773985518031
Trained batch 83 in epoch 15, gen_loss = 0.3984846362755412, disc_loss = 0.08645014651119709
Trained batch 84 in epoch 15, gen_loss = 0.3974965330432443, disc_loss = 0.08864459334050907
Trained batch 85 in epoch 15, gen_loss = 0.3982557893492455, disc_loss = 0.09071488929695862
Trained batch 86 in epoch 15, gen_loss = 0.3993655981003553, disc_loss = 0.0905921700699576
Trained batch 87 in epoch 15, gen_loss = 0.3975943242284385, disc_loss = 0.0917928357693282
Trained batch 88 in epoch 15, gen_loss = 0.3980994900960601, disc_loss = 0.09110321765870191
Trained batch 89 in epoch 15, gen_loss = 0.39874370594819386, disc_loss = 0.09171484981973967
Trained batch 90 in epoch 15, gen_loss = 0.3979566513182043, disc_loss = 0.09132963521303711
Trained batch 91 in epoch 15, gen_loss = 0.39705718405868695, disc_loss = 0.09129726987979982
Trained batch 92 in epoch 15, gen_loss = 0.3969161939877336, disc_loss = 0.09194684417177272
Trained batch 93 in epoch 15, gen_loss = 0.39647924995168726, disc_loss = 0.09136965962007959
Trained batch 94 in epoch 15, gen_loss = 0.3972560581408049, disc_loss = 0.09154534186971815
Trained batch 95 in epoch 15, gen_loss = 0.3973510644088189, disc_loss = 0.09113874736552437
Trained batch 96 in epoch 15, gen_loss = 0.3974809268700708, disc_loss = 0.09080824616950811
Trained batch 97 in epoch 15, gen_loss = 0.3975962658925932, disc_loss = 0.09077368988370409
Trained batch 98 in epoch 15, gen_loss = 0.3977585326541554, disc_loss = 0.09049994438284575
Trained batch 99 in epoch 15, gen_loss = 0.3969224178791046, disc_loss = 0.09066870979964733
Trained batch 100 in epoch 15, gen_loss = 0.39775163879488956, disc_loss = 0.09044471346210725
Trained batch 101 in epoch 15, gen_loss = 0.3980226864417394, disc_loss = 0.08988633204032392
Trained batch 102 in epoch 15, gen_loss = 0.3988007431470075, disc_loss = 0.08922798363763151
Trained batch 103 in epoch 15, gen_loss = 0.3986901380121708, disc_loss = 0.08859334320116502
Trained batch 104 in epoch 15, gen_loss = 0.39864932468959263, disc_loss = 0.08848670962310973
Trained batch 105 in epoch 15, gen_loss = 0.3983823314027966, disc_loss = 0.08833627754224921
Trained batch 106 in epoch 15, gen_loss = 0.39806604385375977, disc_loss = 0.08800690137198038
Trained batch 107 in epoch 15, gen_loss = 0.3979894405713788, disc_loss = 0.08753121937452643
Trained batch 108 in epoch 15, gen_loss = 0.39789851023516526, disc_loss = 0.08708735090603523
Trained batch 109 in epoch 15, gen_loss = 0.39772868020968005, disc_loss = 0.08695986304770817
Trained batch 110 in epoch 15, gen_loss = 0.3974730600644876, disc_loss = 0.08702737676936227
Trained batch 111 in epoch 15, gen_loss = 0.3975996755595718, disc_loss = 0.08738095280049103
Trained batch 112 in epoch 15, gen_loss = 0.39806769062987474, disc_loss = 0.08747185667795418
Trained batch 113 in epoch 15, gen_loss = 0.39765412687209617, disc_loss = 0.08698278064267677
Trained batch 114 in epoch 15, gen_loss = 0.3977805824383445, disc_loss = 0.08668707567064658
Trained batch 115 in epoch 15, gen_loss = 0.39797336505404834, disc_loss = 0.08630940411239862
Trained batch 116 in epoch 15, gen_loss = 0.3980641039008768, disc_loss = 0.08582900439062689
Trained batch 117 in epoch 15, gen_loss = 0.3969441975577403, disc_loss = 0.08574182104508755
Trained batch 118 in epoch 15, gen_loss = 0.39686106583651376, disc_loss = 0.08542223703585752
Trained batch 119 in epoch 15, gen_loss = 0.39715202872951827, disc_loss = 0.08499341976518432
Trained batch 120 in epoch 15, gen_loss = 0.3974066359445083, disc_loss = 0.08474292024231155
Trained batch 121 in epoch 15, gen_loss = 0.39706223592406414, disc_loss = 0.08489070762498457
Trained batch 122 in epoch 15, gen_loss = 0.39798156589996525, disc_loss = 0.08561509087439476
Trained batch 123 in epoch 15, gen_loss = 0.397171153656898, disc_loss = 0.08597088680272141
Trained batch 124 in epoch 15, gen_loss = 0.39735906863212583, disc_loss = 0.08586615452170372
Trained batch 125 in epoch 15, gen_loss = 0.39808684516520726, disc_loss = 0.0867275973811509
Trained batch 126 in epoch 15, gen_loss = 0.3978211011473588, disc_loss = 0.08677583935809886
Trained batch 127 in epoch 15, gen_loss = 0.396568677155301, disc_loss = 0.08776533885975368
Trained batch 128 in epoch 15, gen_loss = 0.39685328870780706, disc_loss = 0.08742338124402733
Trained batch 129 in epoch 15, gen_loss = 0.3969138493904701, disc_loss = 0.08721105467814666
Trained batch 130 in epoch 15, gen_loss = 0.3969586075262259, disc_loss = 0.08682272150998807
Trained batch 131 in epoch 15, gen_loss = 0.3968722273906072, disc_loss = 0.08676237200923038
Trained batch 132 in epoch 15, gen_loss = 0.3964799057720299, disc_loss = 0.08651644714120635
Trained batch 133 in epoch 15, gen_loss = 0.39695296959200904, disc_loss = 0.0861644727636629
Trained batch 134 in epoch 15, gen_loss = 0.3973234803588302, disc_loss = 0.08590509041591927
Trained batch 135 in epoch 15, gen_loss = 0.39816661179065704, disc_loss = 0.08602242122459061
Trained batch 136 in epoch 15, gen_loss = 0.3979339229799535, disc_loss = 0.08613069768804703
Trained batch 137 in epoch 15, gen_loss = 0.39720017430575, disc_loss = 0.0880330197405124
Trained batch 138 in epoch 15, gen_loss = 0.39814830748297325, disc_loss = 0.08768957772915312
Trained batch 139 in epoch 15, gen_loss = 0.3988393491932324, disc_loss = 0.08733853628592832
Trained batch 140 in epoch 15, gen_loss = 0.39875110751348186, disc_loss = 0.08711683766004887
Trained batch 141 in epoch 15, gen_loss = 0.39904297132727123, disc_loss = 0.08861891080586004
Trained batch 142 in epoch 15, gen_loss = 0.3991854274189556, disc_loss = 0.08831135905184946
Trained batch 143 in epoch 15, gen_loss = 0.3993210705618064, disc_loss = 0.08786325125644605
Trained batch 144 in epoch 15, gen_loss = 0.399642040811736, disc_loss = 0.08786345185904668
Trained batch 145 in epoch 15, gen_loss = 0.39925419222818664, disc_loss = 0.08777140254435474
Trained batch 146 in epoch 15, gen_loss = 0.399585616426403, disc_loss = 0.08802306986584955
Trained batch 147 in epoch 15, gen_loss = 0.3993609485191268, disc_loss = 0.08975755211872023
Trained batch 148 in epoch 15, gen_loss = 0.3992993309593841, disc_loss = 0.08936642437873271
Trained batch 149 in epoch 15, gen_loss = 0.4000518351793289, disc_loss = 0.08988421209156514
Trained batch 150 in epoch 15, gen_loss = 0.39991884989454257, disc_loss = 0.089900897458097
Trained batch 151 in epoch 15, gen_loss = 0.3993823936111049, disc_loss = 0.08961775038685453
Trained batch 152 in epoch 15, gen_loss = 0.3989941088202732, disc_loss = 0.0893730255562106
Trained batch 153 in epoch 15, gen_loss = 0.39893988336061503, disc_loss = 0.0889628239145333
Trained batch 154 in epoch 15, gen_loss = 0.3986624413920987, disc_loss = 0.088803084711394
Trained batch 155 in epoch 15, gen_loss = 0.3987573752036461, disc_loss = 0.08857001811982347
Trained batch 156 in epoch 15, gen_loss = 0.3988745584609402, disc_loss = 0.08817603346553578
Trained batch 157 in epoch 15, gen_loss = 0.3985613460027719, disc_loss = 0.08796893590707568
Trained batch 158 in epoch 15, gen_loss = 0.3985357498222927, disc_loss = 0.08771374189066437
Trained batch 159 in epoch 15, gen_loss = 0.3988990610465407, disc_loss = 0.08760333345271647
Trained batch 160 in epoch 15, gen_loss = 0.39879253932407926, disc_loss = 0.08724501705873086
Trained batch 161 in epoch 15, gen_loss = 0.3982644228287685, disc_loss = 0.08688851926521754
Trained batch 162 in epoch 15, gen_loss = 0.3977658776052159, disc_loss = 0.08685079964300606
Trained batch 163 in epoch 15, gen_loss = 0.3982497466410079, disc_loss = 0.08673781753949276
Trained batch 164 in epoch 15, gen_loss = 0.39783643538301644, disc_loss = 0.08633856678550894
Trained batch 165 in epoch 15, gen_loss = 0.39727694891303417, disc_loss = 0.08611812487424138
Trained batch 166 in epoch 15, gen_loss = 0.3972797085068183, disc_loss = 0.08582265909292741
Trained batch 167 in epoch 15, gen_loss = 0.39744799459973973, disc_loss = 0.08545506271045833
Trained batch 168 in epoch 15, gen_loss = 0.39755154079234106, disc_loss = 0.08518578738150512
Trained batch 169 in epoch 15, gen_loss = 0.39812379374223594, disc_loss = 0.08500701009350664
Trained batch 170 in epoch 15, gen_loss = 0.39837465509336595, disc_loss = 0.08529755590777648
Trained batch 171 in epoch 15, gen_loss = 0.3986445795311484, disc_loss = 0.08660358775320441
Trained batch 172 in epoch 15, gen_loss = 0.3985797609552483, disc_loss = 0.08696300760342207
Trained batch 173 in epoch 15, gen_loss = 0.39897046983242035, disc_loss = 0.08668617827111277
Trained batch 174 in epoch 15, gen_loss = 0.39881719504083907, disc_loss = 0.08668989990438734
Trained batch 175 in epoch 15, gen_loss = 0.399397850883278, disc_loss = 0.0862963619557294
Trained batch 176 in epoch 15, gen_loss = 0.3999325683561422, disc_loss = 0.085957143234752
Trained batch 177 in epoch 15, gen_loss = 0.3998922024215205, disc_loss = 0.08568179916088166
Trained batch 178 in epoch 15, gen_loss = 0.4000154377361916, disc_loss = 0.08559110867868922
Trained batch 179 in epoch 15, gen_loss = 0.3998784747388628, disc_loss = 0.0857423098033501
Trained batch 180 in epoch 15, gen_loss = 0.40003944365359145, disc_loss = 0.0856735562566071
Trained batch 181 in epoch 15, gen_loss = 0.39985266900979555, disc_loss = 0.08553474051570827
Trained batch 182 in epoch 15, gen_loss = 0.40017857040212457, disc_loss = 0.0853575464908054
Trained batch 183 in epoch 15, gen_loss = 0.39992863134197565, disc_loss = 0.08539799650442666
Trained batch 184 in epoch 15, gen_loss = 0.40007419715056547, disc_loss = 0.08519593234601859
Trained batch 185 in epoch 15, gen_loss = 0.3998961954988459, disc_loss = 0.08516384227581883
Trained batch 186 in epoch 15, gen_loss = 0.39983629080701, disc_loss = 0.08519520450204132
Trained batch 187 in epoch 15, gen_loss = 0.3990119637009945, disc_loss = 0.08521311939198603
Trained batch 188 in epoch 15, gen_loss = 0.39912220536085663, disc_loss = 0.08503767052694919
Trained batch 189 in epoch 15, gen_loss = 0.39899035143224815, disc_loss = 0.08493238304202494
Trained batch 190 in epoch 15, gen_loss = 0.3984708314790776, disc_loss = 0.08497342530696492
Trained batch 191 in epoch 15, gen_loss = 0.3986742994748056, disc_loss = 0.0846294135262724
Trained batch 192 in epoch 15, gen_loss = 0.39863990949843214, disc_loss = 0.08499628808252861
Trained batch 193 in epoch 15, gen_loss = 0.39841026021647696, disc_loss = 0.08553224080962311
Trained batch 194 in epoch 15, gen_loss = 0.3986723282398322, disc_loss = 0.08528247547264282
Trained batch 195 in epoch 15, gen_loss = 0.39882370920813814, disc_loss = 0.08516964075934826
Trained batch 196 in epoch 15, gen_loss = 0.3991969143073571, disc_loss = 0.08507670343943356
Trained batch 197 in epoch 15, gen_loss = 0.3994810508959221, disc_loss = 0.08479325623825343
Trained batch 198 in epoch 15, gen_loss = 0.39993803195617905, disc_loss = 0.08460470345152084
Trained batch 199 in epoch 15, gen_loss = 0.3996789382398129, disc_loss = 0.08431146148592233
Trained batch 200 in epoch 15, gen_loss = 0.39960439050968605, disc_loss = 0.08424948026143496
Trained batch 201 in epoch 15, gen_loss = 0.40008967672244156, disc_loss = 0.08484855150379757
Trained batch 202 in epoch 15, gen_loss = 0.3999186293244949, disc_loss = 0.0846026541270646
Trained batch 203 in epoch 15, gen_loss = 0.40025361963346895, disc_loss = 0.08459004354389275
Trained batch 204 in epoch 15, gen_loss = 0.40003689382134416, disc_loss = 0.08468402140751118
Trained batch 205 in epoch 15, gen_loss = 0.39990998254817667, disc_loss = 0.08437476123601777
Trained batch 206 in epoch 15, gen_loss = 0.40001522573296, disc_loss = 0.08432125822969393
Trained batch 207 in epoch 15, gen_loss = 0.3997261760613093, disc_loss = 0.08434036425135744
Trained batch 208 in epoch 15, gen_loss = 0.40015811997167233, disc_loss = 0.08434877855676498
Trained batch 209 in epoch 15, gen_loss = 0.4001451519273576, disc_loss = 0.08420594273401158
Trained batch 210 in epoch 15, gen_loss = 0.40006465411864184, disc_loss = 0.08401853163060136
Trained batch 211 in epoch 15, gen_loss = 0.3999197873866783, disc_loss = 0.08393396654183853
Trained batch 212 in epoch 15, gen_loss = 0.40039098934388495, disc_loss = 0.08387352280458654
Trained batch 213 in epoch 15, gen_loss = 0.40043513811080256, disc_loss = 0.08359922916045255
Trained batch 214 in epoch 15, gen_loss = 0.4000920869583307, disc_loss = 0.08362360352347063
Trained batch 215 in epoch 15, gen_loss = 0.4001805798874961, disc_loss = 0.08378771756327262
Trained batch 216 in epoch 15, gen_loss = 0.40014561090601203, disc_loss = 0.08368453378295569
Trained batch 217 in epoch 15, gen_loss = 0.40001267372468197, disc_loss = 0.08385128109211769
Trained batch 218 in epoch 15, gen_loss = 0.39929315304919466, disc_loss = 0.0839380449934365
Trained batch 219 in epoch 15, gen_loss = 0.39927942434495145, disc_loss = 0.08361554970456796
Trained batch 220 in epoch 15, gen_loss = 0.3995705954224815, disc_loss = 0.08360736707554144
Trained batch 221 in epoch 15, gen_loss = 0.3994587131582939, disc_loss = 0.08350533426546299
Trained batch 222 in epoch 15, gen_loss = 0.3991776734857816, disc_loss = 0.08329539047762952
Trained batch 223 in epoch 15, gen_loss = 0.39920047065243125, disc_loss = 0.0832245745030897
Trained batch 224 in epoch 15, gen_loss = 0.39920511106650036, disc_loss = 0.08337822000185649
Trained batch 225 in epoch 15, gen_loss = 0.3993689822016564, disc_loss = 0.08321116356986814
Trained batch 226 in epoch 15, gen_loss = 0.39939371742603536, disc_loss = 0.08317466700523435
Trained batch 227 in epoch 15, gen_loss = 0.39964657113478896, disc_loss = 0.0833332313780199
Trained batch 228 in epoch 15, gen_loss = 0.39980194864054436, disc_loss = 0.08326720524432878
Trained batch 229 in epoch 15, gen_loss = 0.3994907960295677, disc_loss = 0.08358165527815405
Trained batch 230 in epoch 15, gen_loss = 0.39978422082605813, disc_loss = 0.08464473882665882
Trained batch 231 in epoch 15, gen_loss = 0.3993714339388856, disc_loss = 0.0846446421768131
Trained batch 232 in epoch 15, gen_loss = 0.3993302965496743, disc_loss = 0.08455161283456204
Trained batch 233 in epoch 15, gen_loss = 0.3993866029076087, disc_loss = 0.08437554009704508
Trained batch 234 in epoch 15, gen_loss = 0.3990648355255736, disc_loss = 0.08439859025021818
Trained batch 235 in epoch 15, gen_loss = 0.39893589162472953, disc_loss = 0.08441492122740059
Trained batch 236 in epoch 15, gen_loss = 0.3987026102054974, disc_loss = 0.08465120450982565
Trained batch 237 in epoch 15, gen_loss = 0.398946324629443, disc_loss = 0.08446623522694371
Trained batch 238 in epoch 15, gen_loss = 0.39902508477037424, disc_loss = 0.08428404417870933
Trained batch 239 in epoch 15, gen_loss = 0.39908548512806497, disc_loss = 0.08428172317023079
Trained batch 240 in epoch 15, gen_loss = 0.3994007929850416, disc_loss = 0.08485907362580794
Trained batch 241 in epoch 15, gen_loss = 0.39917331755407587, disc_loss = 0.08620004636073901
Trained batch 242 in epoch 15, gen_loss = 0.3991305517193712, disc_loss = 0.08607630284480107
Trained batch 243 in epoch 15, gen_loss = 0.39926920519744763, disc_loss = 0.0869061000889442
Trained batch 244 in epoch 15, gen_loss = 0.3992625859927158, disc_loss = 0.08691934578272761
Trained batch 245 in epoch 15, gen_loss = 0.39919978652785465, disc_loss = 0.08703115773273677
Trained batch 246 in epoch 15, gen_loss = 0.39922504175288476, disc_loss = 0.08686224687919926
Trained batch 247 in epoch 15, gen_loss = 0.3993386936884734, disc_loss = 0.08666683006430825
Trained batch 248 in epoch 15, gen_loss = 0.3993533087901801, disc_loss = 0.08647457706222093
Trained batch 249 in epoch 15, gen_loss = 0.3995254662632942, disc_loss = 0.08628782729804516
Trained batch 250 in epoch 15, gen_loss = 0.39934358481629434, disc_loss = 0.08628052430027035
Trained batch 251 in epoch 15, gen_loss = 0.3993206036587556, disc_loss = 0.08621546015557316
Trained batch 252 in epoch 15, gen_loss = 0.3992482226474483, disc_loss = 0.08619665470813574
Trained batch 253 in epoch 15, gen_loss = 0.3993395803364243, disc_loss = 0.08600198159243648
Trained batch 254 in epoch 15, gen_loss = 0.39931826141535065, disc_loss = 0.08608559897425128
Trained batch 255 in epoch 15, gen_loss = 0.3995563072967343, disc_loss = 0.0858378559933044
Trained batch 256 in epoch 15, gen_loss = 0.3993215641506915, disc_loss = 0.0856284827921641
Trained batch 257 in epoch 15, gen_loss = 0.3991006108564, disc_loss = 0.0854601504266724
Trained batch 258 in epoch 15, gen_loss = 0.3991436729905228, disc_loss = 0.08563085487220277
Trained batch 259 in epoch 15, gen_loss = 0.3989114077618489, disc_loss = 0.08605908390421134
Trained batch 260 in epoch 15, gen_loss = 0.39952090411122276, disc_loss = 0.08618949704814231
Trained batch 261 in epoch 15, gen_loss = 0.3996946452796914, disc_loss = 0.08598831768026789
Trained batch 262 in epoch 15, gen_loss = 0.39998457419328365, disc_loss = 0.08578588404186326
Trained batch 263 in epoch 15, gen_loss = 0.3998848536813801, disc_loss = 0.08593218354508281
Trained batch 264 in epoch 15, gen_loss = 0.3999988345042714, disc_loss = 0.08581038830134104
Trained batch 265 in epoch 15, gen_loss = 0.4000476240775639, disc_loss = 0.08567008007793947
Trained batch 266 in epoch 15, gen_loss = 0.39998595494679295, disc_loss = 0.0857766078792038
Trained batch 267 in epoch 15, gen_loss = 0.40009397663064855, disc_loss = 0.08571534774808297
Trained batch 268 in epoch 15, gen_loss = 0.39978220654464564, disc_loss = 0.08566762657912247
Trained batch 269 in epoch 15, gen_loss = 0.39954600979884464, disc_loss = 0.08565336701770623
Trained batch 270 in epoch 15, gen_loss = 0.3992469989835556, disc_loss = 0.08618900530397672
Trained batch 271 in epoch 15, gen_loss = 0.3993334530797951, disc_loss = 0.08630174254615079
Trained batch 272 in epoch 15, gen_loss = 0.39911631355573846, disc_loss = 0.08650782140783775
Trained batch 273 in epoch 15, gen_loss = 0.3991130366921425, disc_loss = 0.08669462793227965
Trained batch 274 in epoch 15, gen_loss = 0.39916537832130083, disc_loss = 0.08657287429679524
Trained batch 275 in epoch 15, gen_loss = 0.39916164476586424, disc_loss = 0.08654742841811283
Trained batch 276 in epoch 15, gen_loss = 0.3992443611367945, disc_loss = 0.08650784326266726
Trained batch 277 in epoch 15, gen_loss = 0.39937846839642355, disc_loss = 0.08654336741180729
Trained batch 278 in epoch 15, gen_loss = 0.39903594681652643, disc_loss = 0.08707352631515072
Trained batch 279 in epoch 15, gen_loss = 0.39937503758285725, disc_loss = 0.08703967127949
Trained batch 280 in epoch 15, gen_loss = 0.3991201070810128, disc_loss = 0.08705357276566088
Trained batch 281 in epoch 15, gen_loss = 0.3988208864280518, disc_loss = 0.08717773210072348
Trained batch 282 in epoch 15, gen_loss = 0.3987560832984877, disc_loss = 0.08736145886010079
Trained batch 283 in epoch 15, gen_loss = 0.3989041693718501, disc_loss = 0.08726302222151991
Trained batch 284 in epoch 15, gen_loss = 0.3986673278243918, disc_loss = 0.08712029897591524
Trained batch 285 in epoch 15, gen_loss = 0.3987747925249013, disc_loss = 0.08697023428976536
Trained batch 286 in epoch 15, gen_loss = 0.3987175850814228, disc_loss = 0.08690162559886842
Trained batch 287 in epoch 15, gen_loss = 0.39846781532590586, disc_loss = 0.08701116758553933
Trained batch 288 in epoch 15, gen_loss = 0.39861121531382565, disc_loss = 0.08689265506129364
Trained batch 289 in epoch 15, gen_loss = 0.39893589918983396, disc_loss = 0.08686611201485683
Trained batch 290 in epoch 15, gen_loss = 0.39894836644331616, disc_loss = 0.08689072550213624
Trained batch 291 in epoch 15, gen_loss = 0.3987169479568527, disc_loss = 0.08710061816166934
Trained batch 292 in epoch 15, gen_loss = 0.3983563391726985, disc_loss = 0.08751604898034916
Trained batch 293 in epoch 15, gen_loss = 0.3987277778131621, disc_loss = 0.08787570935578978
Trained batch 294 in epoch 15, gen_loss = 0.3988847273386131, disc_loss = 0.0878287304382203
Trained batch 295 in epoch 15, gen_loss = 0.39899890542634436, disc_loss = 0.08761027133142626
Trained batch 296 in epoch 15, gen_loss = 0.3990544224728639, disc_loss = 0.08749681200694155
Trained batch 297 in epoch 15, gen_loss = 0.3994806716406105, disc_loss = 0.08729034936018037
Trained batch 298 in epoch 15, gen_loss = 0.3993997328157808, disc_loss = 0.0874624426124686
Trained batch 299 in epoch 15, gen_loss = 0.39932759140928586, disc_loss = 0.08746717260529598
Trained batch 300 in epoch 15, gen_loss = 0.39930802301513, disc_loss = 0.08732791290776278
Trained batch 301 in epoch 15, gen_loss = 0.3993009383611332, disc_loss = 0.08728870558274897
Trained batch 302 in epoch 15, gen_loss = 0.39941383317948964, disc_loss = 0.08720840905906738
Trained batch 303 in epoch 15, gen_loss = 0.3994635647947067, disc_loss = 0.0869796309669159
Trained batch 304 in epoch 15, gen_loss = 0.3993009281451585, disc_loss = 0.08696729445555171
Trained batch 305 in epoch 15, gen_loss = 0.399482819720421, disc_loss = 0.08711769526787833
Trained batch 306 in epoch 15, gen_loss = 0.3994050405021599, disc_loss = 0.08697839705000483
Trained batch 307 in epoch 15, gen_loss = 0.3994494951874405, disc_loss = 0.08676835989531179
Trained batch 308 in epoch 15, gen_loss = 0.3994400193100994, disc_loss = 0.08659439849212139
Trained batch 309 in epoch 15, gen_loss = 0.39926912193336794, disc_loss = 0.0870390415131565
Trained batch 310 in epoch 15, gen_loss = 0.39960596554723965, disc_loss = 0.08763723424560962
Trained batch 311 in epoch 15, gen_loss = 0.3994679014938764, disc_loss = 0.08742155935854101
Trained batch 312 in epoch 15, gen_loss = 0.3992417572310176, disc_loss = 0.08732067444882453
Trained batch 313 in epoch 15, gen_loss = 0.3991289721078174, disc_loss = 0.08717761472294665
Trained batch 314 in epoch 15, gen_loss = 0.39928876961034443, disc_loss = 0.08760123469290279
Trained batch 315 in epoch 15, gen_loss = 0.398965786388026, disc_loss = 0.08758213829626388
Trained batch 316 in epoch 15, gen_loss = 0.39886402402202414, disc_loss = 0.08799766433022752
Trained batch 317 in epoch 15, gen_loss = 0.39911166953403243, disc_loss = 0.08853261923686888
Trained batch 318 in epoch 15, gen_loss = 0.39908408431984416, disc_loss = 0.08848343860813443
Trained batch 319 in epoch 15, gen_loss = 0.3990830218885094, disc_loss = 0.08866415038937703
Trained batch 320 in epoch 15, gen_loss = 0.39920023199739485, disc_loss = 0.08877804138439467
Trained batch 321 in epoch 15, gen_loss = 0.39918212152971244, disc_loss = 0.08871181106761745
Trained batch 322 in epoch 15, gen_loss = 0.39914927583176285, disc_loss = 0.08868601937827311
Trained batch 323 in epoch 15, gen_loss = 0.3990602302422494, disc_loss = 0.08852989463434544
Trained batch 324 in epoch 15, gen_loss = 0.3990397849908242, disc_loss = 0.08875620546249242
Trained batch 325 in epoch 15, gen_loss = 0.39910432207255275, disc_loss = 0.08926762720467123
Trained batch 326 in epoch 15, gen_loss = 0.399015314307417, disc_loss = 0.08913942360367615
Trained batch 327 in epoch 15, gen_loss = 0.39893230118947787, disc_loss = 0.08922660866434254
Trained batch 328 in epoch 15, gen_loss = 0.398722342671232, disc_loss = 0.08910912396471189
Trained batch 329 in epoch 15, gen_loss = 0.39897091221628767, disc_loss = 0.08955915216920954
Trained batch 330 in epoch 15, gen_loss = 0.39901540804305463, disc_loss = 0.08947304754413866
Trained batch 331 in epoch 15, gen_loss = 0.398903239518404, disc_loss = 0.08946438345788832
Trained batch 332 in epoch 15, gen_loss = 0.39886497059562903, disc_loss = 0.08953488402225233
Trained batch 333 in epoch 15, gen_loss = 0.39883221779576317, disc_loss = 0.08950711348411923
Trained batch 334 in epoch 15, gen_loss = 0.3985326316374451, disc_loss = 0.08958845860255299
Trained batch 335 in epoch 15, gen_loss = 0.3987463459461218, disc_loss = 0.08963143977425284
Trained batch 336 in epoch 15, gen_loss = 0.3988791213810267, disc_loss = 0.0896927730597622
Trained batch 337 in epoch 15, gen_loss = 0.3989464121721905, disc_loss = 0.08971879859427376
Trained batch 338 in epoch 15, gen_loss = 0.39906249070062044, disc_loss = 0.08979610691072315
Trained batch 339 in epoch 15, gen_loss = 0.3991839953643434, disc_loss = 0.08965525475933271
Trained batch 340 in epoch 15, gen_loss = 0.3989628465556679, disc_loss = 0.0895864713139548
Trained batch 341 in epoch 15, gen_loss = 0.39872000871868857, disc_loss = 0.08956654875250587
Trained batch 342 in epoch 15, gen_loss = 0.3990133177521625, disc_loss = 0.08955324439022354
Trained batch 343 in epoch 15, gen_loss = 0.3986891658413549, disc_loss = 0.08962672641284244
Trained batch 344 in epoch 15, gen_loss = 0.39859819278336955, disc_loss = 0.08950638339139413
Trained batch 345 in epoch 15, gen_loss = 0.3986474114949304, disc_loss = 0.08937692558231382
Trained batch 346 in epoch 15, gen_loss = 0.39852504698446917, disc_loss = 0.08923556476359065
Trained batch 347 in epoch 15, gen_loss = 0.3985762182066495, disc_loss = 0.08907083296698742
Trained batch 348 in epoch 15, gen_loss = 0.39861277194111944, disc_loss = 0.08906632393897433
Trained batch 349 in epoch 15, gen_loss = 0.39876839369535444, disc_loss = 0.08920266118432794
Trained batch 350 in epoch 15, gen_loss = 0.39866657122078103, disc_loss = 0.08913434716074216
Trained batch 351 in epoch 15, gen_loss = 0.3987092194147408, disc_loss = 0.08890929136065427
Trained batch 352 in epoch 15, gen_loss = 0.3985417305832206, disc_loss = 0.08925380382064213
Trained batch 353 in epoch 15, gen_loss = 0.3984082991541442, disc_loss = 0.08963686631371577
Trained batch 354 in epoch 15, gen_loss = 0.3985047376071903, disc_loss = 0.08942532595509374
Trained batch 355 in epoch 15, gen_loss = 0.39885255480917653, disc_loss = 0.08940048021358553
Trained batch 356 in epoch 15, gen_loss = 0.39911386449964775, disc_loss = 0.08927560417654634
Trained batch 357 in epoch 15, gen_loss = 0.3992621871595942, disc_loss = 0.08922274653700976
Trained batch 358 in epoch 15, gen_loss = 0.3993647534784168, disc_loss = 0.0892125378443255
Trained batch 359 in epoch 15, gen_loss = 0.39933869503438474, disc_loss = 0.08944070988541676
Trained batch 360 in epoch 15, gen_loss = 0.3994248543667331, disc_loss = 0.08931401676893069
Trained batch 361 in epoch 15, gen_loss = 0.3993775406183459, disc_loss = 0.08926567173362272
Trained batch 362 in epoch 15, gen_loss = 0.399422588796655, disc_loss = 0.08922633154641006
Trained batch 363 in epoch 15, gen_loss = 0.39938790600869684, disc_loss = 0.08912526341769231
Trained batch 364 in epoch 15, gen_loss = 0.39941272372252323, disc_loss = 0.08926085920060334
Trained batch 365 in epoch 15, gen_loss = 0.3991937571780278, disc_loss = 0.08927316027769788
Trained batch 366 in epoch 15, gen_loss = 0.3991066082215764, disc_loss = 0.08926289579869129
Trained batch 367 in epoch 15, gen_loss = 0.39914788091150316, disc_loss = 0.08917820942081997
Trained batch 368 in epoch 15, gen_loss = 0.39903000800751737, disc_loss = 0.08930234593367027
Trained batch 369 in epoch 15, gen_loss = 0.3990555613024815, disc_loss = 0.0891222780117312
Trained batch 370 in epoch 15, gen_loss = 0.399078603984532, disc_loss = 0.08891287381256205
Trained batch 371 in epoch 15, gen_loss = 0.39886202202529036, disc_loss = 0.08886008186426053
Trained batch 372 in epoch 15, gen_loss = 0.39878586130391497, disc_loss = 0.08883971502709805
Trained batch 373 in epoch 15, gen_loss = 0.39876320420261374, disc_loss = 0.08866058755666018
Trained batch 374 in epoch 15, gen_loss = 0.3989791062275569, disc_loss = 0.08845754529784124
Trained batch 375 in epoch 15, gen_loss = 0.3989202519284284, disc_loss = 0.08842832913889767
Trained batch 376 in epoch 15, gen_loss = 0.3989172673114731, disc_loss = 0.08830016378846899
Trained batch 377 in epoch 15, gen_loss = 0.39869486509019103, disc_loss = 0.0882158488720143
Trained batch 378 in epoch 15, gen_loss = 0.39893974017813844, disc_loss = 0.08850073967482845
Trained batch 379 in epoch 15, gen_loss = 0.39885052187662373, disc_loss = 0.08854957340334199
Trained batch 380 in epoch 15, gen_loss = 0.39867174840505354, disc_loss = 0.08888787140439111
Trained batch 381 in epoch 15, gen_loss = 0.39878529633995125, disc_loss = 0.08943163966077394
Trained batch 382 in epoch 15, gen_loss = 0.3988090076972548, disc_loss = 0.08932415792577494
Trained batch 383 in epoch 15, gen_loss = 0.398685842868872, disc_loss = 0.08926626156850641
Trained batch 384 in epoch 15, gen_loss = 0.3988599740452581, disc_loss = 0.089119407619265
Trained batch 385 in epoch 15, gen_loss = 0.39876982836062425, disc_loss = 0.0890391324598516
Trained batch 386 in epoch 15, gen_loss = 0.3986211753707832, disc_loss = 0.08886364732630724
Trained batch 387 in epoch 15, gen_loss = 0.3984586460151009, disc_loss = 0.08874218639936875
Trained batch 388 in epoch 15, gen_loss = 0.3984157176817597, disc_loss = 0.0885653530240327
Trained batch 389 in epoch 15, gen_loss = 0.3985457316805155, disc_loss = 0.08842512855115227
Trained batch 390 in epoch 15, gen_loss = 0.3984553587939733, disc_loss = 0.0883968383564478
Trained batch 391 in epoch 15, gen_loss = 0.3985284480589385, disc_loss = 0.08837162736299618
Trained batch 392 in epoch 15, gen_loss = 0.39865728374807585, disc_loss = 0.0882419337691507
Trained batch 393 in epoch 15, gen_loss = 0.3985598173162659, disc_loss = 0.08813675615681231
Trained batch 394 in epoch 15, gen_loss = 0.3986617776034754, disc_loss = 0.0879475839129543
Trained batch 395 in epoch 15, gen_loss = 0.39884777912738345, disc_loss = 0.08783247499406864
Trained batch 396 in epoch 15, gen_loss = 0.39882735570221767, disc_loss = 0.08785232844098614
Trained batch 397 in epoch 15, gen_loss = 0.3988357154493356, disc_loss = 0.0881608233637359
Trained batch 398 in epoch 15, gen_loss = 0.3987508782542738, disc_loss = 0.08811385752889969
Trained batch 399 in epoch 15, gen_loss = 0.3987016872689128, disc_loss = 0.08802180898142979
Trained batch 400 in epoch 15, gen_loss = 0.39873755806848, disc_loss = 0.08813225484204634
Trained batch 401 in epoch 15, gen_loss = 0.3987582762961957, disc_loss = 0.08799365681563666
Trained batch 402 in epoch 15, gen_loss = 0.398897458653592, disc_loss = 0.08798074025069144
Trained batch 403 in epoch 15, gen_loss = 0.3986812815586529, disc_loss = 0.08830088216322704
Trained batch 404 in epoch 15, gen_loss = 0.3987395110321634, disc_loss = 0.08824609917025139
Trained batch 405 in epoch 15, gen_loss = 0.3986395677102023, disc_loss = 0.08816775100379082
Trained batch 406 in epoch 15, gen_loss = 0.39847678843089346, disc_loss = 0.08832239380440417
Trained batch 407 in epoch 15, gen_loss = 0.3984318639644805, disc_loss = 0.08829250183714298
Trained batch 408 in epoch 15, gen_loss = 0.3981032165673659, disc_loss = 0.08853192482380456
Trained batch 409 in epoch 15, gen_loss = 0.39818022625475397, disc_loss = 0.08854212054710199
Trained batch 410 in epoch 15, gen_loss = 0.39802533043707083, disc_loss = 0.08852382035758301
Trained batch 411 in epoch 15, gen_loss = 0.3978646280768427, disc_loss = 0.08851950169649446
Trained batch 412 in epoch 15, gen_loss = 0.39808520772122297, disc_loss = 0.08861253339093693
Trained batch 413 in epoch 15, gen_loss = 0.39817544144852723, disc_loss = 0.08853241101870142
Trained batch 414 in epoch 15, gen_loss = 0.39810059239347295, disc_loss = 0.08842911262244704
Trained batch 415 in epoch 15, gen_loss = 0.3983099400782241, disc_loss = 0.0883937539474573
Trained batch 416 in epoch 15, gen_loss = 0.3980724911252372, disc_loss = 0.08873653992322637
Trained batch 417 in epoch 15, gen_loss = 0.3980351740307215, disc_loss = 0.0888501955931516
Trained batch 418 in epoch 15, gen_loss = 0.3979594350074527, disc_loss = 0.08904167957968459
Trained batch 419 in epoch 15, gen_loss = 0.39806443435095606, disc_loss = 0.08893207975751942
Trained batch 420 in epoch 15, gen_loss = 0.3979662397341037, disc_loss = 0.08894547525209302
Trained batch 421 in epoch 15, gen_loss = 0.3981872261347364, disc_loss = 0.08906139562930471
Trained batch 422 in epoch 15, gen_loss = 0.3979603317401088, disc_loss = 0.08922027106711698
Trained batch 423 in epoch 15, gen_loss = 0.3982199336630556, disc_loss = 0.08936315956569435
Trained batch 424 in epoch 15, gen_loss = 0.39832001570393055, disc_loss = 0.08925295651616419
Trained batch 425 in epoch 15, gen_loss = 0.398111723293441, disc_loss = 0.08923861477742663
Trained batch 426 in epoch 15, gen_loss = 0.3980559989007351, disc_loss = 0.08916878495016407
Trained batch 427 in epoch 15, gen_loss = 0.3980211241988935, disc_loss = 0.08904501322926692
Trained batch 428 in epoch 15, gen_loss = 0.39812582804189695, disc_loss = 0.08885882632038393
Trained batch 429 in epoch 15, gen_loss = 0.39804261545109193, disc_loss = 0.08873208874273439
Trained batch 430 in epoch 15, gen_loss = 0.3979414927917954, disc_loss = 0.08861738816335832
Trained batch 431 in epoch 15, gen_loss = 0.3980892601043538, disc_loss = 0.08854132546198175
Trained batch 432 in epoch 15, gen_loss = 0.39792454308092456, disc_loss = 0.08851401716487925
Trained batch 433 in epoch 15, gen_loss = 0.3979076783983938, disc_loss = 0.08889689092623061
Trained batch 434 in epoch 15, gen_loss = 0.3980625630452715, disc_loss = 0.08877027841049365
Trained batch 435 in epoch 15, gen_loss = 0.39824733852383193, disc_loss = 0.08866595113308194
Trained batch 436 in epoch 15, gen_loss = 0.3981027438452369, disc_loss = 0.08862705916183355
Trained batch 437 in epoch 15, gen_loss = 0.3981451353730132, disc_loss = 0.0885555028753806
Trained batch 438 in epoch 15, gen_loss = 0.3982705604582007, disc_loss = 0.08853359485219035
Trained batch 439 in epoch 15, gen_loss = 0.39804974371059376, disc_loss = 0.08862854596650736
Trained batch 440 in epoch 15, gen_loss = 0.39813669823329734, disc_loss = 0.08849821504534913
Trained batch 441 in epoch 15, gen_loss = 0.3980908337559096, disc_loss = 0.08840560506422461
Trained batch 442 in epoch 15, gen_loss = 0.39796104828740886, disc_loss = 0.08831364251505038
Trained batch 443 in epoch 15, gen_loss = 0.3981186275345248, disc_loss = 0.08816678486009305
Trained batch 444 in epoch 15, gen_loss = 0.39823813274335323, disc_loss = 0.08808072302699758
Trained batch 445 in epoch 15, gen_loss = 0.39823991798632885, disc_loss = 0.08802345321167077
Trained batch 446 in epoch 15, gen_loss = 0.39818456032265487, disc_loss = 0.0880293211539253
Trained batch 447 in epoch 15, gen_loss = 0.3983114425957735, disc_loss = 0.08843394310263518
Trained batch 448 in epoch 15, gen_loss = 0.39834667264353196, disc_loss = 0.08835272175282705
Trained batch 449 in epoch 15, gen_loss = 0.39815362178617053, disc_loss = 0.08861987928135527
Trained batch 450 in epoch 15, gen_loss = 0.39835533866464695, disc_loss = 0.08858937820927663
Trained batch 451 in epoch 15, gen_loss = 0.39849427589668635, disc_loss = 0.08859841844924124
Trained batch 452 in epoch 15, gen_loss = 0.3984090899986937, disc_loss = 0.08879243304118284
Trained batch 453 in epoch 15, gen_loss = 0.3984162394236363, disc_loss = 0.08863544864128733
Trained batch 454 in epoch 15, gen_loss = 0.3985624907108454, disc_loss = 0.08847006457642867
Trained batch 455 in epoch 15, gen_loss = 0.39864701245045453, disc_loss = 0.08852104579400794
Trained batch 456 in epoch 15, gen_loss = 0.39858389843084097, disc_loss = 0.0885981204257198
Trained batch 457 in epoch 15, gen_loss = 0.3986304223081951, disc_loss = 0.0885069971745549
Trained batch 458 in epoch 15, gen_loss = 0.39848060977355065, disc_loss = 0.08847360691757698
Trained batch 459 in epoch 15, gen_loss = 0.3985532974743325, disc_loss = 0.08831249706690078
Trained batch 460 in epoch 15, gen_loss = 0.3983841523237187, disc_loss = 0.08839680165165546
Testing Epoch 15
Training Epoch 16
Trained batch 0 in epoch 16, gen_loss = 0.43866080045700073, disc_loss = 0.06008896231651306
Trained batch 1 in epoch 16, gen_loss = 0.4080428034067154, disc_loss = 0.07636290043592453
Trained batch 2 in epoch 16, gen_loss = 0.4356013834476471, disc_loss = 0.06625751530130704
Trained batch 3 in epoch 16, gen_loss = 0.4572005644440651, disc_loss = 0.09051944594830275
Trained batch 4 in epoch 16, gen_loss = 0.4494422674179077, disc_loss = 0.08281846269965172
Trained batch 5 in epoch 16, gen_loss = 0.4373777856429418, disc_loss = 0.07734798702100913
Trained batch 6 in epoch 16, gen_loss = 0.4279232067721231, disc_loss = 0.07684749737381935
Trained batch 7 in epoch 16, gen_loss = 0.4268585033714771, disc_loss = 0.08009430719539523
Trained batch 8 in epoch 16, gen_loss = 0.42419366041819256, disc_loss = 0.07873018375701374
Trained batch 9 in epoch 16, gen_loss = 0.4205833226442337, disc_loss = 0.07568679489195347
Trained batch 10 in epoch 16, gen_loss = 0.41041405363516376, disc_loss = 0.08160230957648971
Trained batch 11 in epoch 16, gen_loss = 0.41312825431426364, disc_loss = 0.0976529037579894
Trained batch 12 in epoch 16, gen_loss = 0.41158652993348926, disc_loss = 0.09433084525741063
Trained batch 13 in epoch 16, gen_loss = 0.411411994269916, disc_loss = 0.0929627948041473
Trained batch 14 in epoch 16, gen_loss = 0.40578869183858235, disc_loss = 0.09440004403392474
Trained batch 15 in epoch 16, gen_loss = 0.4008717555552721, disc_loss = 0.09409028408117592
Trained batch 16 in epoch 16, gen_loss = 0.39830390846028046, disc_loss = 0.09056221606100306
Trained batch 17 in epoch 16, gen_loss = 0.39906033873558044, disc_loss = 0.10029428079724312
Trained batch 18 in epoch 16, gen_loss = 0.39654453804618434, disc_loss = 0.098307424469998
Trained batch 19 in epoch 16, gen_loss = 0.39555917382240297, disc_loss = 0.09641521591693163
Trained batch 20 in epoch 16, gen_loss = 0.3953668347426823, disc_loss = 0.09339377798494838
Trained batch 21 in epoch 16, gen_loss = 0.39545847340063617, disc_loss = 0.09436246769672091
Trained batch 22 in epoch 16, gen_loss = 0.39404331212458404, disc_loss = 0.09298245365852895
Trained batch 23 in epoch 16, gen_loss = 0.39331725612282753, disc_loss = 0.0898738323400418
Trained batch 24 in epoch 16, gen_loss = 0.3916216945648193, disc_loss = 0.08743172563612461
Trained batch 25 in epoch 16, gen_loss = 0.39361534783473384, disc_loss = 0.08537055200968797
Trained batch 26 in epoch 16, gen_loss = 0.39211427834298873, disc_loss = 0.08278156734175152
Trained batch 27 in epoch 16, gen_loss = 0.3915339836052486, disc_loss = 0.08302155057234424
Trained batch 28 in epoch 16, gen_loss = 0.3929367281239608, disc_loss = 0.08556439316478269
Trained batch 29 in epoch 16, gen_loss = 0.3913271059592565, disc_loss = 0.08345982357859612
Trained batch 30 in epoch 16, gen_loss = 0.38920858790797574, disc_loss = 0.08294775985902356
Trained batch 31 in epoch 16, gen_loss = 0.3878902057185769, disc_loss = 0.08172859577462077
Trained batch 32 in epoch 16, gen_loss = 0.3898176984353499, disc_loss = 0.0800847616611105
Trained batch 33 in epoch 16, gen_loss = 0.38899406966041117, disc_loss = 0.07907875057529001
Trained batch 34 in epoch 16, gen_loss = 0.3895959096295493, disc_loss = 0.08290913658482688
Trained batch 35 in epoch 16, gen_loss = 0.3927728889716996, disc_loss = 0.08763782473074065
Trained batch 36 in epoch 16, gen_loss = 0.3923565036541707, disc_loss = 0.08675818608419315
Trained batch 37 in epoch 16, gen_loss = 0.3905911131909019, disc_loss = 0.08634146067656968
Trained batch 38 in epoch 16, gen_loss = 0.3898684649895399, disc_loss = 0.08525795680590165
Trained batch 39 in epoch 16, gen_loss = 0.3918805725872517, disc_loss = 0.08345531290397049
Trained batch 40 in epoch 16, gen_loss = 0.3908094138633914, disc_loss = 0.08360093077871858
Trained batch 41 in epoch 16, gen_loss = 0.3904052653482982, disc_loss = 0.08439999472882066
Trained batch 42 in epoch 16, gen_loss = 0.3902664337047311, disc_loss = 0.08304874720268471
Trained batch 43 in epoch 16, gen_loss = 0.38992846283045685, disc_loss = 0.0832981343635104
Trained batch 44 in epoch 16, gen_loss = 0.38948355846934846, disc_loss = 0.0839332789182663
Trained batch 45 in epoch 16, gen_loss = 0.39180649169113324, disc_loss = 0.08504448409961618
Trained batch 46 in epoch 16, gen_loss = 0.39096839313811443, disc_loss = 0.0880257655331429
Trained batch 47 in epoch 16, gen_loss = 0.3933331885685523, disc_loss = 0.08812777108202378
Trained batch 48 in epoch 16, gen_loss = 0.39307696113781054, disc_loss = 0.0871648766404512
Trained batch 49 in epoch 16, gen_loss = 0.39323784232139586, disc_loss = 0.0865960155427456
Trained batch 50 in epoch 16, gen_loss = 0.3946572255854513, disc_loss = 0.08641334009521148
Trained batch 51 in epoch 16, gen_loss = 0.39410632160993725, disc_loss = 0.08519548256523334
Trained batch 52 in epoch 16, gen_loss = 0.3931499168557941, disc_loss = 0.08458687126074198
Trained batch 53 in epoch 16, gen_loss = 0.39325479831960464, disc_loss = 0.08367505421241124
Trained batch 54 in epoch 16, gen_loss = 0.39486739852211694, disc_loss = 0.08264173875478181
Trained batch 55 in epoch 16, gen_loss = 0.3959979047732694, disc_loss = 0.08285666280426085
Trained batch 56 in epoch 16, gen_loss = 0.3954790250251168, disc_loss = 0.08269563457814225
Trained batch 57 in epoch 16, gen_loss = 0.39563454893128625, disc_loss = 0.08229571243683839
Trained batch 58 in epoch 16, gen_loss = 0.3960719371246079, disc_loss = 0.08129929615405657
Trained batch 59 in epoch 16, gen_loss = 0.3951335370540619, disc_loss = 0.08058727473641435
Trained batch 60 in epoch 16, gen_loss = 0.3964168732283545, disc_loss = 0.08035135699710885
Trained batch 61 in epoch 16, gen_loss = 0.3980059897707355, disc_loss = 0.07967239597271528
Trained batch 62 in epoch 16, gen_loss = 0.3985289354172964, disc_loss = 0.07893421521617307
Trained batch 63 in epoch 16, gen_loss = 0.39909443352371454, disc_loss = 0.07797840060084127
Trained batch 64 in epoch 16, gen_loss = 0.40005241128114555, disc_loss = 0.07730909365300949
Trained batch 65 in epoch 16, gen_loss = 0.39911457670457434, disc_loss = 0.07664996010223121
Trained batch 66 in epoch 16, gen_loss = 0.3978261920943189, disc_loss = 0.07656597410008978
Trained batch 67 in epoch 16, gen_loss = 0.3975556729470982, disc_loss = 0.07642801541506368
Trained batch 68 in epoch 16, gen_loss = 0.3979182571604632, disc_loss = 0.0755871281945619
Trained batch 69 in epoch 16, gen_loss = 0.3986440816095897, disc_loss = 0.07538187932223081
Trained batch 70 in epoch 16, gen_loss = 0.3985876369644219, disc_loss = 0.07479109030059526
Trained batch 71 in epoch 16, gen_loss = 0.39839889150526786, disc_loss = 0.07547085765852696
Trained batch 72 in epoch 16, gen_loss = 0.39752935179292337, disc_loss = 0.07598678964151911
Trained batch 73 in epoch 16, gen_loss = 0.3963443427472501, disc_loss = 0.07564672276478361
Trained batch 74 in epoch 16, gen_loss = 0.3962801663080851, disc_loss = 0.07500385118027528
Trained batch 75 in epoch 16, gen_loss = 0.3960122175906834, disc_loss = 0.07421152850024794
Trained batch 76 in epoch 16, gen_loss = 0.3953497231780709, disc_loss = 0.07487056885737103
Trained batch 77 in epoch 16, gen_loss = 0.3956923652917911, disc_loss = 0.07566477613857923
Trained batch 78 in epoch 16, gen_loss = 0.3934912557088876, disc_loss = 0.07744278077366232
Trained batch 79 in epoch 16, gen_loss = 0.39408864490687845, disc_loss = 0.07923504307400435
Trained batch 80 in epoch 16, gen_loss = 0.3936087397145636, disc_loss = 0.07890236559381456
Trained batch 81 in epoch 16, gen_loss = 0.39394807597485987, disc_loss = 0.07820093250129281
Trained batch 82 in epoch 16, gen_loss = 0.3939160934413772, disc_loss = 0.07835387097424772
Trained batch 83 in epoch 16, gen_loss = 0.3929587531657446, disc_loss = 0.07896129760359015
Trained batch 84 in epoch 16, gen_loss = 0.3938153666608474, disc_loss = 0.0786654540721108
Trained batch 85 in epoch 16, gen_loss = 0.39344724874163783, disc_loss = 0.07873193261235259
Trained batch 86 in epoch 16, gen_loss = 0.393380470659541, disc_loss = 0.07799195490734673
Trained batch 87 in epoch 16, gen_loss = 0.3928862237794833, disc_loss = 0.07788499073252421
Trained batch 88 in epoch 16, gen_loss = 0.3916435787517033, disc_loss = 0.07818159436953537
Trained batch 89 in epoch 16, gen_loss = 0.3927510662211312, disc_loss = 0.07863702112808824
Trained batch 90 in epoch 16, gen_loss = 0.39183432289532255, disc_loss = 0.07863832323474217
Trained batch 91 in epoch 16, gen_loss = 0.3918179425856341, disc_loss = 0.07952142329684095
Trained batch 92 in epoch 16, gen_loss = 0.392614794354285, disc_loss = 0.0834190279986429
Trained batch 93 in epoch 16, gen_loss = 0.3920412726224737, disc_loss = 0.08341167535276171
Trained batch 94 in epoch 16, gen_loss = 0.39219857517041656, disc_loss = 0.08309835863152618
Trained batch 95 in epoch 16, gen_loss = 0.39163086966921884, disc_loss = 0.08382662735918227
Trained batch 96 in epoch 16, gen_loss = 0.3927324466484109, disc_loss = 0.08402799739089516
Trained batch 97 in epoch 16, gen_loss = 0.3926762281631937, disc_loss = 0.08371539384468782
Trained batch 98 in epoch 16, gen_loss = 0.3923880954583486, disc_loss = 0.08343513596878209
Trained batch 99 in epoch 16, gen_loss = 0.3915028840303421, disc_loss = 0.08329709098674357
Trained batch 100 in epoch 16, gen_loss = 0.39102906401794735, disc_loss = 0.08717336263138764
Trained batch 101 in epoch 16, gen_loss = 0.39032620746715396, disc_loss = 0.08702733989476281
Trained batch 102 in epoch 16, gen_loss = 0.39098048730961327, disc_loss = 0.08703520316268923
Trained batch 103 in epoch 16, gen_loss = 0.39080114003557426, disc_loss = 0.08692168251862033
Trained batch 104 in epoch 16, gen_loss = 0.39106821389425367, disc_loss = 0.08672765018861918
Trained batch 105 in epoch 16, gen_loss = 0.39116486316581944, disc_loss = 0.08645123574566448
Trained batch 106 in epoch 16, gen_loss = 0.3906442035581464, disc_loss = 0.08693711718143983
Trained batch 107 in epoch 16, gen_loss = 0.39068966800415955, disc_loss = 0.08726511275637205
Trained batch 108 in epoch 16, gen_loss = 0.39127991396352785, disc_loss = 0.0867216464285867
Trained batch 109 in epoch 16, gen_loss = 0.3914299062707207, disc_loss = 0.0864954655058682
Trained batch 110 in epoch 16, gen_loss = 0.3917065499065159, disc_loss = 0.08648313232068275
Trained batch 111 in epoch 16, gen_loss = 0.3923872049365725, disc_loss = 0.08832428856320414
Trained batch 112 in epoch 16, gen_loss = 0.391894604252503, disc_loss = 0.08947735351502104
Trained batch 113 in epoch 16, gen_loss = 0.3920465728692841, disc_loss = 0.08931761489070036
Trained batch 114 in epoch 16, gen_loss = 0.39300035393756366, disc_loss = 0.0890688134195364
Trained batch 115 in epoch 16, gen_loss = 0.3932037314978139, disc_loss = 0.08925985845994076
Trained batch 116 in epoch 16, gen_loss = 0.3935232944468148, disc_loss = 0.08884408607537675
Trained batch 117 in epoch 16, gen_loss = 0.3932215750722562, disc_loss = 0.08831658663417576
Trained batch 118 in epoch 16, gen_loss = 0.3933522227932425, disc_loss = 0.08792409858815059
Trained batch 119 in epoch 16, gen_loss = 0.393787299344937, disc_loss = 0.08754764969926328
Trained batch 120 in epoch 16, gen_loss = 0.3938118862219093, disc_loss = 0.08737994706612234
Trained batch 121 in epoch 16, gen_loss = 0.39360147861183664, disc_loss = 0.08721140070558815
Trained batch 122 in epoch 16, gen_loss = 0.39397344841220516, disc_loss = 0.08683552993537207
Trained batch 123 in epoch 16, gen_loss = 0.39389011720495837, disc_loss = 0.08680989209472412
Trained batch 124 in epoch 16, gen_loss = 0.3940183210372925, disc_loss = 0.08772710717469454
Trained batch 125 in epoch 16, gen_loss = 0.3940391299270448, disc_loss = 0.08771944259633384
Trained batch 126 in epoch 16, gen_loss = 0.39363909448225665, disc_loss = 0.0873686578931419
Trained batch 127 in epoch 16, gen_loss = 0.3943289932794869, disc_loss = 0.0880085555036203
Trained batch 128 in epoch 16, gen_loss = 0.3938629597194435, disc_loss = 0.08761783793944028
Trained batch 129 in epoch 16, gen_loss = 0.3939889424122297, disc_loss = 0.08766347153398853
Trained batch 130 in epoch 16, gen_loss = 0.3937943671040863, disc_loss = 0.08768577720856166
Trained batch 131 in epoch 16, gen_loss = 0.39345073067780695, disc_loss = 0.08747681312855672
Trained batch 132 in epoch 16, gen_loss = 0.3933951207121512, disc_loss = 0.0872409686628253
Trained batch 133 in epoch 16, gen_loss = 0.393212234128767, disc_loss = 0.0869186657703301
Trained batch 134 in epoch 16, gen_loss = 0.3940796540843116, disc_loss = 0.08769107078098588
Trained batch 135 in epoch 16, gen_loss = 0.39438339739161377, disc_loss = 0.0874257796402911
Trained batch 136 in epoch 16, gen_loss = 0.3945827632054795, disc_loss = 0.08722936974525669
Trained batch 137 in epoch 16, gen_loss = 0.3956258560436359, disc_loss = 0.08754677150695436
Trained batch 138 in epoch 16, gen_loss = 0.39545778983788527, disc_loss = 0.08729197961954976
Trained batch 139 in epoch 16, gen_loss = 0.39522522666624615, disc_loss = 0.08713931710725384
Trained batch 140 in epoch 16, gen_loss = 0.3952616079056517, disc_loss = 0.08705597844450398
Trained batch 141 in epoch 16, gen_loss = 0.395126320736509, disc_loss = 0.08686405449817089
Trained batch 142 in epoch 16, gen_loss = 0.39455205514714436, disc_loss = 0.08700943944676147
Trained batch 143 in epoch 16, gen_loss = 0.3955263356781668, disc_loss = 0.08656480412335238
Trained batch 144 in epoch 16, gen_loss = 0.3959622231023065, disc_loss = 0.08693112577472267
Trained batch 145 in epoch 16, gen_loss = 0.39593630253452144, disc_loss = 0.08759368048368456
Trained batch 146 in epoch 16, gen_loss = 0.3962889779992655, disc_loss = 0.087461025694854
Trained batch 147 in epoch 16, gen_loss = 0.3960730622749071, disc_loss = 0.0876909116396328
Trained batch 148 in epoch 16, gen_loss = 0.3961614976393296, disc_loss = 0.08755732148310683
Trained batch 149 in epoch 16, gen_loss = 0.39651599208513894, disc_loss = 0.08729713082934419
Trained batch 150 in epoch 16, gen_loss = 0.39662474847787266, disc_loss = 0.08732451030380087
Trained batch 151 in epoch 16, gen_loss = 0.39677890468584864, disc_loss = 0.0869725992180113
Trained batch 152 in epoch 16, gen_loss = 0.3969915955284842, disc_loss = 0.08723556864519719
Trained batch 153 in epoch 16, gen_loss = 0.39671839812359255, disc_loss = 0.087563611331166
Trained batch 154 in epoch 16, gen_loss = 0.3967136394593023, disc_loss = 0.08774767624394547
Trained batch 155 in epoch 16, gen_loss = 0.3970590468782645, disc_loss = 0.0874845548473203
Trained batch 156 in epoch 16, gen_loss = 0.39730235763416166, disc_loss = 0.08762322172261537
Trained batch 157 in epoch 16, gen_loss = 0.3984969978845572, disc_loss = 0.08777468854891537
Trained batch 158 in epoch 16, gen_loss = 0.39779520690816006, disc_loss = 0.08836640760232255
Trained batch 159 in epoch 16, gen_loss = 0.39783414993435146, disc_loss = 0.0887366680020932
Trained batch 160 in epoch 16, gen_loss = 0.3976866428896507, disc_loss = 0.0886930107017574
Trained batch 161 in epoch 16, gen_loss = 0.39711160405918405, disc_loss = 0.08892063521147694
Trained batch 162 in epoch 16, gen_loss = 0.3970511685485489, disc_loss = 0.08963005885230435
Trained batch 163 in epoch 16, gen_loss = 0.39693754402602593, disc_loss = 0.08933317973051311
Trained batch 164 in epoch 16, gen_loss = 0.39693077820720096, disc_loss = 0.08906588308851827
Trained batch 165 in epoch 16, gen_loss = 0.3970462502126234, disc_loss = 0.08870688451633575
Trained batch 166 in epoch 16, gen_loss = 0.39705127656102895, disc_loss = 0.08837157709267504
Trained batch 167 in epoch 16, gen_loss = 0.3972678397383009, disc_loss = 0.08821679401721451
Trained batch 168 in epoch 16, gen_loss = 0.3976014152433745, disc_loss = 0.08795216091572357
Trained batch 169 in epoch 16, gen_loss = 0.3981917858123779, disc_loss = 0.08752096512847964
Trained batch 170 in epoch 16, gen_loss = 0.3984914889112551, disc_loss = 0.08715841037422767
Trained batch 171 in epoch 16, gen_loss = 0.39876079992499464, disc_loss = 0.08707601861313505
Trained batch 172 in epoch 16, gen_loss = 0.3980457515730334, disc_loss = 0.08839215870645177
Trained batch 173 in epoch 16, gen_loss = 0.3980359034291629, disc_loss = 0.08807201061033826
Trained batch 174 in epoch 16, gen_loss = 0.3984900266783578, disc_loss = 0.0883972398138472
Trained batch 175 in epoch 16, gen_loss = 0.3984360611912879, disc_loss = 0.08826886289435523
Trained batch 176 in epoch 16, gen_loss = 0.3978125594430051, disc_loss = 0.08926287009828003
Trained batch 177 in epoch 16, gen_loss = 0.3978162749429767, disc_loss = 0.08903288109269872
Trained batch 178 in epoch 16, gen_loss = 0.39773785918118565, disc_loss = 0.0892195664606364
Trained batch 179 in epoch 16, gen_loss = 0.3978397481971317, disc_loss = 0.08936020066030323
Trained batch 180 in epoch 16, gen_loss = 0.3976280845660531, disc_loss = 0.08896787394126311
Trained batch 181 in epoch 16, gen_loss = 0.39830824912904383, disc_loss = 0.0886508151223617
Trained batch 182 in epoch 16, gen_loss = 0.3983257709305143, disc_loss = 0.08863489807690264
Trained batch 183 in epoch 16, gen_loss = 0.3981313438195249, disc_loss = 0.08850834896767755
Trained batch 184 in epoch 16, gen_loss = 0.3980950914524697, disc_loss = 0.08837692408847647
Trained batch 185 in epoch 16, gen_loss = 0.3983397653666876, disc_loss = 0.08798404890663361
Trained batch 186 in epoch 16, gen_loss = 0.3983952951303778, disc_loss = 0.08792549040527108
Trained batch 187 in epoch 16, gen_loss = 0.39874714391028626, disc_loss = 0.08769368403591216
Trained batch 188 in epoch 16, gen_loss = 0.39874338961782907, disc_loss = 0.08763842520713018
Trained batch 189 in epoch 16, gen_loss = 0.3987526568927263, disc_loss = 0.08765258172919091
Trained batch 190 in epoch 16, gen_loss = 0.39858963477049825, disc_loss = 0.08737277621354576
Trained batch 191 in epoch 16, gen_loss = 0.3987163423250119, disc_loss = 0.08702744646870997
Trained batch 192 in epoch 16, gen_loss = 0.39931791063417427, disc_loss = 0.08671467613737663
Trained batch 193 in epoch 16, gen_loss = 0.39945365073754613, disc_loss = 0.08660340372031343
Trained batch 194 in epoch 16, gen_loss = 0.3997819724755409, disc_loss = 0.0865548072478328
Trained batch 195 in epoch 16, gen_loss = 0.39974515869909405, disc_loss = 0.0861825648676224
Trained batch 196 in epoch 16, gen_loss = 0.39989470225300283, disc_loss = 0.08640872304171777
Trained batch 197 in epoch 16, gen_loss = 0.39972127477327984, disc_loss = 0.0864237453130008
Trained batch 198 in epoch 16, gen_loss = 0.3996390620967252, disc_loss = 0.08614818219226508
Trained batch 199 in epoch 16, gen_loss = 0.3996027697622776, disc_loss = 0.08604503753595054
Trained batch 200 in epoch 16, gen_loss = 0.3992545038313415, disc_loss = 0.08614545811282757
Trained batch 201 in epoch 16, gen_loss = 0.399444849774389, disc_loss = 0.08581993791579019
Trained batch 202 in epoch 16, gen_loss = 0.39978232686155535, disc_loss = 0.08592773093084984
Trained batch 203 in epoch 16, gen_loss = 0.3992135020739892, disc_loss = 0.08728652104151015
Trained batch 204 in epoch 16, gen_loss = 0.399104773562129, disc_loss = 0.08733082675352329
Trained batch 205 in epoch 16, gen_loss = 0.3993093034306776, disc_loss = 0.08709742219268697
Trained batch 206 in epoch 16, gen_loss = 0.3989257946394492, disc_loss = 0.08725564379766944
Trained batch 207 in epoch 16, gen_loss = 0.39900305294073546, disc_loss = 0.0870761234814731
Trained batch 208 in epoch 16, gen_loss = 0.3989054751738407, disc_loss = 0.08694330946894353
Trained batch 209 in epoch 16, gen_loss = 0.3984085186606362, disc_loss = 0.08694624998384998
Trained batch 210 in epoch 16, gen_loss = 0.39839696559295834, disc_loss = 0.08684686806176511
Trained batch 211 in epoch 16, gen_loss = 0.39828174701839125, disc_loss = 0.08675218930573396
Trained batch 212 in epoch 16, gen_loss = 0.39862710559312164, disc_loss = 0.08653370441405427
Trained batch 213 in epoch 16, gen_loss = 0.39847564516223477, disc_loss = 0.08636815269764896
Trained batch 214 in epoch 16, gen_loss = 0.3986207575299019, disc_loss = 0.08607111675448195
Trained batch 215 in epoch 16, gen_loss = 0.3989937505512326, disc_loss = 0.08610622831447809
Trained batch 216 in epoch 16, gen_loss = 0.3992300768327054, disc_loss = 0.0863021956713793
Trained batch 217 in epoch 16, gen_loss = 0.39893960118840593, disc_loss = 0.08609199233421493
Trained batch 218 in epoch 16, gen_loss = 0.39894759967991206, disc_loss = 0.0864052877646603
Trained batch 219 in epoch 16, gen_loss = 0.3984503491358323, disc_loss = 0.08616128651933237
Trained batch 220 in epoch 16, gen_loss = 0.39835653787824366, disc_loss = 0.08595349491316809
Trained batch 221 in epoch 16, gen_loss = 0.3984369588596327, disc_loss = 0.08600443232435363
Trained batch 222 in epoch 16, gen_loss = 0.39848404828743017, disc_loss = 0.08577756962901809
Trained batch 223 in epoch 16, gen_loss = 0.3984257146450026, disc_loss = 0.08567546815278806
Trained batch 224 in epoch 16, gen_loss = 0.39832169228129916, disc_loss = 0.0854072533465094
Trained batch 225 in epoch 16, gen_loss = 0.39848219794509687, disc_loss = 0.08546608700458191
Trained batch 226 in epoch 16, gen_loss = 0.39806535774390606, disc_loss = 0.08642225158667512
Trained batch 227 in epoch 16, gen_loss = 0.39812505349778293, disc_loss = 0.08635465739490955
Trained batch 228 in epoch 16, gen_loss = 0.39853784038510387, disc_loss = 0.08670789449918999
Trained batch 229 in epoch 16, gen_loss = 0.39807896691819894, disc_loss = 0.08724662076033976
Trained batch 230 in epoch 16, gen_loss = 0.398031341307091, disc_loss = 0.0872463992357383
Trained batch 231 in epoch 16, gen_loss = 0.39783736909257955, disc_loss = 0.08728125560547001
Trained batch 232 in epoch 16, gen_loss = 0.3981091372444906, disc_loss = 0.0872311339885508
Trained batch 233 in epoch 16, gen_loss = 0.39771541099772495, disc_loss = 0.08722736209662807
Trained batch 234 in epoch 16, gen_loss = 0.3973930427368651, disc_loss = 0.08713418623392886
Trained batch 235 in epoch 16, gen_loss = 0.3973282776394133, disc_loss = 0.08757318276122718
Trained batch 236 in epoch 16, gen_loss = 0.396975794044728, disc_loss = 0.08786160619104211
Trained batch 237 in epoch 16, gen_loss = 0.39683547616004944, disc_loss = 0.08783534310852029
Trained batch 238 in epoch 16, gen_loss = 0.39669877153560207, disc_loss = 0.08799998229174684
Trained batch 239 in epoch 16, gen_loss = 0.3964550342410803, disc_loss = 0.08776310381945222
Trained batch 240 in epoch 16, gen_loss = 0.39651403177328626, disc_loss = 0.08780190605994824
Trained batch 241 in epoch 16, gen_loss = 0.3961061975680107, disc_loss = 0.08818852788314593
Trained batch 242 in epoch 16, gen_loss = 0.39620171064212, disc_loss = 0.08808623386907234
Trained batch 243 in epoch 16, gen_loss = 0.39642116940412364, disc_loss = 0.0878521636296369
Trained batch 244 in epoch 16, gen_loss = 0.396130986724581, disc_loss = 0.08780838341585227
Trained batch 245 in epoch 16, gen_loss = 0.39604607830202676, disc_loss = 0.08763477520456886
Trained batch 246 in epoch 16, gen_loss = 0.3961734645038481, disc_loss = 0.08731990833559379
Trained batch 247 in epoch 16, gen_loss = 0.39631650308447497, disc_loss = 0.08711093874092424
Trained batch 248 in epoch 16, gen_loss = 0.3963735431552412, disc_loss = 0.08694452778567152
Trained batch 249 in epoch 16, gen_loss = 0.39642155158519743, disc_loss = 0.08693379146978258
Trained batch 250 in epoch 16, gen_loss = 0.39694595989952997, disc_loss = 0.08749094636242584
Trained batch 251 in epoch 16, gen_loss = 0.39701553623354624, disc_loss = 0.0875228488603459
Trained batch 252 in epoch 16, gen_loss = 0.39691937558735785, disc_loss = 0.08722275568783401
Trained batch 253 in epoch 16, gen_loss = 0.39694430004424, disc_loss = 0.08709572132046181
Trained batch 254 in epoch 16, gen_loss = 0.3968312439965267, disc_loss = 0.08686527533493206
Trained batch 255 in epoch 16, gen_loss = 0.39660798176191747, disc_loss = 0.0869469704302901
Trained batch 256 in epoch 16, gen_loss = 0.39672124293063865, disc_loss = 0.08681694997641247
Trained batch 257 in epoch 16, gen_loss = 0.3966339991767277, disc_loss = 0.086641796478323
Trained batch 258 in epoch 16, gen_loss = 0.3969326015835103, disc_loss = 0.0864147981844526
Trained batch 259 in epoch 16, gen_loss = 0.39724196321689165, disc_loss = 0.08624481022572861
Trained batch 260 in epoch 16, gen_loss = 0.3972121954420974, disc_loss = 0.08634109826137622
Trained batch 261 in epoch 16, gen_loss = 0.39737118473489774, disc_loss = 0.08623733874481485
Trained batch 262 in epoch 16, gen_loss = 0.39735235959404774, disc_loss = 0.08604882324305664
Trained batch 263 in epoch 16, gen_loss = 0.3973108980466019, disc_loss = 0.08586666276890108
Trained batch 264 in epoch 16, gen_loss = 0.39711815647359167, disc_loss = 0.08575750463905762
Trained batch 265 in epoch 16, gen_loss = 0.3968852398763026, disc_loss = 0.08555824221006798
Trained batch 266 in epoch 16, gen_loss = 0.39702138594920267, disc_loss = 0.08530416343472759
Trained batch 267 in epoch 16, gen_loss = 0.3969425468969701, disc_loss = 0.08514317348529932
Trained batch 268 in epoch 16, gen_loss = 0.3968436174011585, disc_loss = 0.08508646882530371
Trained batch 269 in epoch 16, gen_loss = 0.3973083854825408, disc_loss = 0.08482125118650773
Trained batch 270 in epoch 16, gen_loss = 0.3972325626334581, disc_loss = 0.08495263281068678
Trained batch 271 in epoch 16, gen_loss = 0.3977017481537426, disc_loss = 0.08604735633194008
Trained batch 272 in epoch 16, gen_loss = 0.3974772101138538, disc_loss = 0.08632251657136195
Trained batch 273 in epoch 16, gen_loss = 0.3975641258659154, disc_loss = 0.08610146303056147
Trained batch 274 in epoch 16, gen_loss = 0.3975890017639507, disc_loss = 0.08640349199148742
Trained batch 275 in epoch 16, gen_loss = 0.39741796319899353, disc_loss = 0.08648984034991135
Trained batch 276 in epoch 16, gen_loss = 0.3972680982915073, disc_loss = 0.08639527310613906
Trained batch 277 in epoch 16, gen_loss = 0.39748321248473023, disc_loss = 0.08630999683556582
Trained batch 278 in epoch 16, gen_loss = 0.39744358122562423, disc_loss = 0.08611008024183653
Trained batch 279 in epoch 16, gen_loss = 0.39742917461054666, disc_loss = 0.0860737425275147
Trained batch 280 in epoch 16, gen_loss = 0.3978678285015011, disc_loss = 0.08589152222850568
Trained batch 281 in epoch 16, gen_loss = 0.3981021931196781, disc_loss = 0.08584361185207434
Trained batch 282 in epoch 16, gen_loss = 0.3982285907748731, disc_loss = 0.08614300975951204
Trained batch 283 in epoch 16, gen_loss = 0.3981059333178359, disc_loss = 0.08665321914243027
Trained batch 284 in epoch 16, gen_loss = 0.39808083762202345, disc_loss = 0.08644577138648744
Trained batch 285 in epoch 16, gen_loss = 0.3980075945178946, disc_loss = 0.08632500766014511
Trained batch 286 in epoch 16, gen_loss = 0.39804574161871803, disc_loss = 0.08619523351486344
Trained batch 287 in epoch 16, gen_loss = 0.39811891555372214, disc_loss = 0.08596259990008548
Trained batch 288 in epoch 16, gen_loss = 0.39804567628665777, disc_loss = 0.08603764565784007
Trained batch 289 in epoch 16, gen_loss = 0.39785568457225273, disc_loss = 0.08590112758222325
Trained batch 290 in epoch 16, gen_loss = 0.3978010084211212, disc_loss = 0.08573689819329589
Trained batch 291 in epoch 16, gen_loss = 0.39821680380056984, disc_loss = 0.08549500040531363
Trained batch 292 in epoch 16, gen_loss = 0.39822156722228275, disc_loss = 0.08536216674480625
Trained batch 293 in epoch 16, gen_loss = 0.3982486107519695, disc_loss = 0.08533500539785137
Trained batch 294 in epoch 16, gen_loss = 0.3983043779761104, disc_loss = 0.0851871573887134
Trained batch 295 in epoch 16, gen_loss = 0.39852616462755847, disc_loss = 0.08507299274080307
Trained batch 296 in epoch 16, gen_loss = 0.39849130603600835, disc_loss = 0.08505467575683136
Trained batch 297 in epoch 16, gen_loss = 0.39858440344765683, disc_loss = 0.0849287073071671
Trained batch 298 in epoch 16, gen_loss = 0.3987858007384782, disc_loss = 0.0847281610350246
Trained batch 299 in epoch 16, gen_loss = 0.3988401207327843, disc_loss = 0.08457621561363339
Trained batch 300 in epoch 16, gen_loss = 0.3987236197208645, disc_loss = 0.08446667336571058
Trained batch 301 in epoch 16, gen_loss = 0.3986450977475438, disc_loss = 0.08429513863651761
Trained batch 302 in epoch 16, gen_loss = 0.39870189882741114, disc_loss = 0.08417236921146955
Trained batch 303 in epoch 16, gen_loss = 0.3988166636738338, disc_loss = 0.08416392448921933
Trained batch 304 in epoch 16, gen_loss = 0.39863561987876894, disc_loss = 0.08395161085197184
Trained batch 305 in epoch 16, gen_loss = 0.3988503793291017, disc_loss = 0.08377071937509611
Trained batch 306 in epoch 16, gen_loss = 0.39870541423850414, disc_loss = 0.08382071748812735
Trained batch 307 in epoch 16, gen_loss = 0.39901842554281286, disc_loss = 0.0840142017544864
Trained batch 308 in epoch 16, gen_loss = 0.3986755482201437, disc_loss = 0.08450837317600991
Trained batch 309 in epoch 16, gen_loss = 0.3987930719890902, disc_loss = 0.08459131181720764
Trained batch 310 in epoch 16, gen_loss = 0.39860468135002725, disc_loss = 0.08454082556476164
Trained batch 311 in epoch 16, gen_loss = 0.39852658697427845, disc_loss = 0.08458186590518707
Trained batch 312 in epoch 16, gen_loss = 0.3987876239676064, disc_loss = 0.084456715720911
Trained batch 313 in epoch 16, gen_loss = 0.39861974015737034, disc_loss = 0.08440720510615665
Trained batch 314 in epoch 16, gen_loss = 0.3985466047884926, disc_loss = 0.08458100687416772
Trained batch 315 in epoch 16, gen_loss = 0.39856375612412825, disc_loss = 0.08468772973157937
Trained batch 316 in epoch 16, gen_loss = 0.3986728940664406, disc_loss = 0.0846026426868672
Trained batch 317 in epoch 16, gen_loss = 0.39887143090461036, disc_loss = 0.08442100659364236
Trained batch 318 in epoch 16, gen_loss = 0.39865030390341827, disc_loss = 0.08439429612906188
Trained batch 319 in epoch 16, gen_loss = 0.3986233718693256, disc_loss = 0.08430627013440244
Trained batch 320 in epoch 16, gen_loss = 0.39883865216439385, disc_loss = 0.08417579994139456
Trained batch 321 in epoch 16, gen_loss = 0.39891451532426087, disc_loss = 0.08414989305509729
Trained batch 322 in epoch 16, gen_loss = 0.39930692370461973, disc_loss = 0.08395453181475308
Trained batch 323 in epoch 16, gen_loss = 0.39951355047064063, disc_loss = 0.08401831459070061
Trained batch 324 in epoch 16, gen_loss = 0.3991982457270989, disc_loss = 0.08498293417004439
Trained batch 325 in epoch 16, gen_loss = 0.3993156211324996, disc_loss = 0.08495687870480166
Trained batch 326 in epoch 16, gen_loss = 0.3991925060202222, disc_loss = 0.08487097423421133
Trained batch 327 in epoch 16, gen_loss = 0.3991679571023801, disc_loss = 0.0849242586438067
Trained batch 328 in epoch 16, gen_loss = 0.3991010337615086, disc_loss = 0.08492738263268239
Trained batch 329 in epoch 16, gen_loss = 0.39904279763048345, disc_loss = 0.0849059803580696
Trained batch 330 in epoch 16, gen_loss = 0.3990368792657766, disc_loss = 0.08479610205912158
Trained batch 331 in epoch 16, gen_loss = 0.3989638325320669, disc_loss = 0.08459493446062846
Trained batch 332 in epoch 16, gen_loss = 0.39919149499755724, disc_loss = 0.08457944501896163
Trained batch 333 in epoch 16, gen_loss = 0.399007947323565, disc_loss = 0.08482685839076956
Trained batch 334 in epoch 16, gen_loss = 0.39907716530472487, disc_loss = 0.08475423508615636
Trained batch 335 in epoch 16, gen_loss = 0.3993105517611617, disc_loss = 0.08478112341392607
Trained batch 336 in epoch 16, gen_loss = 0.3993238435300946, disc_loss = 0.08478843071428888
Trained batch 337 in epoch 16, gen_loss = 0.3993158523853009, disc_loss = 0.0847906159931386
Trained batch 338 in epoch 16, gen_loss = 0.3995317138050158, disc_loss = 0.08551064828152502
Trained batch 339 in epoch 16, gen_loss = 0.39945012786809136, disc_loss = 0.08555867251227883
Trained batch 340 in epoch 16, gen_loss = 0.3994305943114317, disc_loss = 0.08540257463051427
Trained batch 341 in epoch 16, gen_loss = 0.3993474475124426, disc_loss = 0.08565439036584388
Trained batch 342 in epoch 16, gen_loss = 0.3991705544140874, disc_loss = 0.08603746912091884
Trained batch 343 in epoch 16, gen_loss = 0.3994855362662049, disc_loss = 0.08630733110747019
Trained batch 344 in epoch 16, gen_loss = 0.3996869893177696, disc_loss = 0.08621547028854273
Trained batch 345 in epoch 16, gen_loss = 0.3996458231885998, disc_loss = 0.08622238945452809
Trained batch 346 in epoch 16, gen_loss = 0.3996211584088438, disc_loss = 0.08615728878880441
Trained batch 347 in epoch 16, gen_loss = 0.39946555842955905, disc_loss = 0.08608522477035208
Trained batch 348 in epoch 16, gen_loss = 0.3992745625255443, disc_loss = 0.08599250730564738
Trained batch 349 in epoch 16, gen_loss = 0.39930205753871373, disc_loss = 0.08604398566697324
Trained batch 350 in epoch 16, gen_loss = 0.3992847953087244, disc_loss = 0.08614476824290732
Trained batch 351 in epoch 16, gen_loss = 0.3994631387970664, disc_loss = 0.08604028154249219
Trained batch 352 in epoch 16, gen_loss = 0.3995643905640999, disc_loss = 0.08590523999912543
Trained batch 353 in epoch 16, gen_loss = 0.3996125989209461, disc_loss = 0.08579474946452399
Trained batch 354 in epoch 16, gen_loss = 0.39971556067466735, disc_loss = 0.08569989757428706
Trained batch 355 in epoch 16, gen_loss = 0.3993402695220508, disc_loss = 0.08559106943312655
Trained batch 356 in epoch 16, gen_loss = 0.3991823772422406, disc_loss = 0.08552649024487878
Trained batch 357 in epoch 16, gen_loss = 0.3993355275532387, disc_loss = 0.085376719689236
Trained batch 358 in epoch 16, gen_loss = 0.399416410989416, disc_loss = 0.08516803745201122
Trained batch 359 in epoch 16, gen_loss = 0.3994905165500111, disc_loss = 0.08497163902243807
Trained batch 360 in epoch 16, gen_loss = 0.39950514549693905, disc_loss = 0.08493086919085306
Trained batch 361 in epoch 16, gen_loss = 0.39944929666611373, disc_loss = 0.08517361770368577
Trained batch 362 in epoch 16, gen_loss = 0.39960145219626836, disc_loss = 0.0856179253098147
Trained batch 363 in epoch 16, gen_loss = 0.3994148097686715, disc_loss = 0.08556276703621823
Trained batch 364 in epoch 16, gen_loss = 0.39931913255012197, disc_loss = 0.08555319550613018
Trained batch 365 in epoch 16, gen_loss = 0.39946591805239196, disc_loss = 0.08568082335074254
Trained batch 366 in epoch 16, gen_loss = 0.39956457527197026, disc_loss = 0.08553307918116085
Trained batch 367 in epoch 16, gen_loss = 0.39937029471215996, disc_loss = 0.08549537410979847
Trained batch 368 in epoch 16, gen_loss = 0.39949799771231365, disc_loss = 0.08540571830803301
Trained batch 369 in epoch 16, gen_loss = 0.3993915344412262, disc_loss = 0.08540249843955845
Trained batch 370 in epoch 16, gen_loss = 0.3992331867430088, disc_loss = 0.08553261053309126
Trained batch 371 in epoch 16, gen_loss = 0.3990794831225949, disc_loss = 0.08561807633027115
Trained batch 372 in epoch 16, gen_loss = 0.39919468968227784, disc_loss = 0.08555475257377043
Trained batch 373 in epoch 16, gen_loss = 0.3993094572249581, disc_loss = 0.08553842624978107
Trained batch 374 in epoch 16, gen_loss = 0.3991696116924286, disc_loss = 0.08539775953193506
Trained batch 375 in epoch 16, gen_loss = 0.3993556901336984, disc_loss = 0.08554810421798933
Trained batch 376 in epoch 16, gen_loss = 0.399367179968629, disc_loss = 0.08539932198941075
Trained batch 377 in epoch 16, gen_loss = 0.39912162216567487, disc_loss = 0.08532247906698594
Trained batch 378 in epoch 16, gen_loss = 0.3991395775277885, disc_loss = 0.08527361471353388
Trained batch 379 in epoch 16, gen_loss = 0.3991334341858563, disc_loss = 0.08509248599508092
Trained batch 380 in epoch 16, gen_loss = 0.3993008621721443, disc_loss = 0.08493831747375291
Trained batch 381 in epoch 16, gen_loss = 0.39909173002105736, disc_loss = 0.08485697247380518
Trained batch 382 in epoch 16, gen_loss = 0.3993029389773585, disc_loss = 0.08480668809585876
Trained batch 383 in epoch 16, gen_loss = 0.39929618360474706, disc_loss = 0.084639581371448
Trained batch 384 in epoch 16, gen_loss = 0.39919988853590826, disc_loss = 0.0846321330683959
Trained batch 385 in epoch 16, gen_loss = 0.3992316746804381, disc_loss = 0.08489311963725121
Trained batch 386 in epoch 16, gen_loss = 0.399199224257654, disc_loss = 0.0848710885661286
Trained batch 387 in epoch 16, gen_loss = 0.39912891226638225, disc_loss = 0.08472308141573034
Trained batch 388 in epoch 16, gen_loss = 0.3989952988060704, disc_loss = 0.08456076201827177
Trained batch 389 in epoch 16, gen_loss = 0.3990445823241503, disc_loss = 0.08524076387477227
Trained batch 390 in epoch 16, gen_loss = 0.39891284506034363, disc_loss = 0.08547669530029187
Trained batch 391 in epoch 16, gen_loss = 0.3989069248188515, disc_loss = 0.08534586276592952
Trained batch 392 in epoch 16, gen_loss = 0.39898854759509933, disc_loss = 0.08582634824794971
Trained batch 393 in epoch 16, gen_loss = 0.39872657269390704, disc_loss = 0.08639482509931029
Trained batch 394 in epoch 16, gen_loss = 0.398710753646078, disc_loss = 0.08646483873076077
Trained batch 395 in epoch 16, gen_loss = 0.3985081412876495, disc_loss = 0.08639149743160515
Trained batch 396 in epoch 16, gen_loss = 0.3987257861970954, disc_loss = 0.08624524152567915
Trained batch 397 in epoch 16, gen_loss = 0.3985270868294203, disc_loss = 0.08626457364134603
Trained batch 398 in epoch 16, gen_loss = 0.3984490758494327, disc_loss = 0.08612532320346002
Trained batch 399 in epoch 16, gen_loss = 0.39855105623602866, disc_loss = 0.0860713028954342
Trained batch 400 in epoch 16, gen_loss = 0.39861617458431503, disc_loss = 0.08602953180577838
Trained batch 401 in epoch 16, gen_loss = 0.39859312135188735, disc_loss = 0.08588998357010125
Trained batch 402 in epoch 16, gen_loss = 0.39855944126770454, disc_loss = 0.08573156499093579
Trained batch 403 in epoch 16, gen_loss = 0.398773236513728, disc_loss = 0.08573235374054697
Trained batch 404 in epoch 16, gen_loss = 0.39858297411306404, disc_loss = 0.08572110491402356
Trained batch 405 in epoch 16, gen_loss = 0.3986679124714706, disc_loss = 0.0856304110894943
Trained batch 406 in epoch 16, gen_loss = 0.3986567962521124, disc_loss = 0.08549059857900371
Trained batch 407 in epoch 16, gen_loss = 0.3986366541654456, disc_loss = 0.08547256034159777
Trained batch 408 in epoch 16, gen_loss = 0.3987283632341399, disc_loss = 0.08532096461044547
Trained batch 409 in epoch 16, gen_loss = 0.3987987354034331, disc_loss = 0.08520279974653953
Trained batch 410 in epoch 16, gen_loss = 0.3989088565038649, disc_loss = 0.08522488489529512
Trained batch 411 in epoch 16, gen_loss = 0.3986496895696353, disc_loss = 0.08514783538660957
Trained batch 412 in epoch 16, gen_loss = 0.3987283971494393, disc_loss = 0.08507397842140232
Trained batch 413 in epoch 16, gen_loss = 0.39874257982353084, disc_loss = 0.08500587658569721
Trained batch 414 in epoch 16, gen_loss = 0.3990061334098678, disc_loss = 0.08519251898649227
Trained batch 415 in epoch 16, gen_loss = 0.3987723540944549, disc_loss = 0.0854446028914446
Trained batch 416 in epoch 16, gen_loss = 0.399047809467613, disc_loss = 0.08540747846237762
Trained batch 417 in epoch 16, gen_loss = 0.39917400543484394, disc_loss = 0.0852516264249192
Trained batch 418 in epoch 16, gen_loss = 0.39907096785122, disc_loss = 0.0851213785292923
Trained batch 419 in epoch 16, gen_loss = 0.3991650587746075, disc_loss = 0.08503672801224249
Trained batch 420 in epoch 16, gen_loss = 0.3992923975981896, disc_loss = 0.08496175679398121
Trained batch 421 in epoch 16, gen_loss = 0.3992720127670686, disc_loss = 0.0848887917228149
Trained batch 422 in epoch 16, gen_loss = 0.3991937975511483, disc_loss = 0.08509499933262384
Trained batch 423 in epoch 16, gen_loss = 0.3993678791624195, disc_loss = 0.08513524184302199
Trained batch 424 in epoch 16, gen_loss = 0.39943108677864075, disc_loss = 0.08496316067874432
Trained batch 425 in epoch 16, gen_loss = 0.39927970740436947, disc_loss = 0.08491520670640497
Trained batch 426 in epoch 16, gen_loss = 0.3993531513688715, disc_loss = 0.0847951103420601
Trained batch 427 in epoch 16, gen_loss = 0.39942618146120945, disc_loss = 0.08478918806954383
Trained batch 428 in epoch 16, gen_loss = 0.3993957149676787, disc_loss = 0.08485049654953268
Trained batch 429 in epoch 16, gen_loss = 0.39952431951844414, disc_loss = 0.08496356006538452
Trained batch 430 in epoch 16, gen_loss = 0.3995597251883239, disc_loss = 0.08485207747745818
Trained batch 431 in epoch 16, gen_loss = 0.39944052247813455, disc_loss = 0.08514581687524225
Trained batch 432 in epoch 16, gen_loss = 0.39947732856312196, disc_loss = 0.08509745489694093
Trained batch 433 in epoch 16, gen_loss = 0.3995842312887517, disc_loss = 0.0849758287342394
Trained batch 434 in epoch 16, gen_loss = 0.39936603184404046, disc_loss = 0.08494553911531794
Trained batch 435 in epoch 16, gen_loss = 0.3993936559749306, disc_loss = 0.0847775536854196
Trained batch 436 in epoch 16, gen_loss = 0.39931855485422935, disc_loss = 0.08463973347822235
Trained batch 437 in epoch 16, gen_loss = 0.3996692785661515, disc_loss = 0.08452953213238962
Trained batch 438 in epoch 16, gen_loss = 0.3995647902233454, disc_loss = 0.0845694501071761
Trained batch 439 in epoch 16, gen_loss = 0.39960262748328124, disc_loss = 0.08476174526678568
Trained batch 440 in epoch 16, gen_loss = 0.3995868386595157, disc_loss = 0.08466157845544572
Trained batch 441 in epoch 16, gen_loss = 0.39979931691922754, disc_loss = 0.08454386252336778
Trained batch 442 in epoch 16, gen_loss = 0.39993215643256297, disc_loss = 0.08458732744220551
Trained batch 443 in epoch 16, gen_loss = 0.39978017543887234, disc_loss = 0.08443847679541455
Trained batch 444 in epoch 16, gen_loss = 0.39989643237564, disc_loss = 0.08445860827237033
Trained batch 445 in epoch 16, gen_loss = 0.3997403617129732, disc_loss = 0.08454627167817723
Trained batch 446 in epoch 16, gen_loss = 0.3997525015400027, disc_loss = 0.08450878491537683
Trained batch 447 in epoch 16, gen_loss = 0.39952301300529924, disc_loss = 0.08449282901295062
Trained batch 448 in epoch 16, gen_loss = 0.3997093397949745, disc_loss = 0.08443886829842968
Trained batch 449 in epoch 16, gen_loss = 0.39956088609165613, disc_loss = 0.08436656315293577
Trained batch 450 in epoch 16, gen_loss = 0.3995581645262479, disc_loss = 0.08432161531301666
Trained batch 451 in epoch 16, gen_loss = 0.3994532305978041, disc_loss = 0.08429410292940066
Trained batch 452 in epoch 16, gen_loss = 0.3996277931773373, disc_loss = 0.08418389831651125
Trained batch 453 in epoch 16, gen_loss = 0.39963228908666953, disc_loss = 0.08405407045102198
Trained batch 454 in epoch 16, gen_loss = 0.3998371277536665, disc_loss = 0.08406208889088133
Trained batch 455 in epoch 16, gen_loss = 0.39976179005022633, disc_loss = 0.08401309361828393
Trained batch 456 in epoch 16, gen_loss = 0.39977784895010016, disc_loss = 0.08393488656036573
Trained batch 457 in epoch 16, gen_loss = 0.3998455869839181, disc_loss = 0.08385244165201505
Trained batch 458 in epoch 16, gen_loss = 0.39983177847332424, disc_loss = 0.08385290439628178
Trained batch 459 in epoch 16, gen_loss = 0.39982794827741125, disc_loss = 0.08411077183630804
Trained batch 460 in epoch 16, gen_loss = 0.39999219639440936, disc_loss = 0.08415805202971441
Testing Epoch 16
Training Epoch 17
Trained batch 0 in epoch 17, gen_loss = 0.3833576440811157, disc_loss = 0.010732833296060562
Trained batch 1 in epoch 17, gen_loss = 0.3962087035179138, disc_loss = 0.04239966534078121
Trained batch 2 in epoch 17, gen_loss = 0.4294402599334717, disc_loss = 0.03760166342059771
Trained batch 3 in epoch 17, gen_loss = 0.4340578764677048, disc_loss = 0.06121272500604391
Trained batch 4 in epoch 17, gen_loss = 0.4127023756504059, disc_loss = 0.08115429207682609
Trained batch 5 in epoch 17, gen_loss = 0.41326436897118884, disc_loss = 0.07287632736066978
Trained batch 6 in epoch 17, gen_loss = 0.4042235399995531, disc_loss = 0.06929997886930193
Trained batch 7 in epoch 17, gen_loss = 0.4201822988688946, disc_loss = 0.06680151540786028
Trained batch 8 in epoch 17, gen_loss = 0.41572675108909607, disc_loss = 0.06572385380665462
Trained batch 9 in epoch 17, gen_loss = 0.4146709620952606, disc_loss = 0.06675762459635734
Trained batch 10 in epoch 17, gen_loss = 0.4185471372170882, disc_loss = 0.06477242064746944
Trained batch 11 in epoch 17, gen_loss = 0.410760723054409, disc_loss = 0.06407065565387408
Trained batch 12 in epoch 17, gen_loss = 0.4149037760037642, disc_loss = 0.06280877956977257
Trained batch 13 in epoch 17, gen_loss = 0.4138124031679971, disc_loss = 0.06823851593903132
Trained batch 14 in epoch 17, gen_loss = 0.4099417467912038, disc_loss = 0.0756792038679123
Trained batch 15 in epoch 17, gen_loss = 0.41273107565939426, disc_loss = 0.07500485284253955
Trained batch 16 in epoch 17, gen_loss = 0.41630711800911846, disc_loss = 0.07135573122650385
Trained batch 17 in epoch 17, gen_loss = 0.41757989260885453, disc_loss = 0.06983721861615777
Trained batch 18 in epoch 17, gen_loss = 0.4177686838727248, disc_loss = 0.0686268557941443
Trained batch 19 in epoch 17, gen_loss = 0.4170037269592285, disc_loss = 0.06727396161295474
Trained batch 20 in epoch 17, gen_loss = 0.415684468689419, disc_loss = 0.06702577948038067
Trained batch 21 in epoch 17, gen_loss = 0.41840696741234173, disc_loss = 0.0663167589174753
Trained batch 22 in epoch 17, gen_loss = 0.4177748470202736, disc_loss = 0.06589940712665734
Trained batch 23 in epoch 17, gen_loss = 0.4159969240427017, disc_loss = 0.07043697875148307
Trained batch 24 in epoch 17, gen_loss = 0.41822466135025027, disc_loss = 0.07202011290937663
Trained batch 25 in epoch 17, gen_loss = 0.416080762560551, disc_loss = 0.07243559283849138
Trained batch 26 in epoch 17, gen_loss = 0.4141979692158876, disc_loss = 0.0714487574511656
Trained batch 27 in epoch 17, gen_loss = 0.41639311079468044, disc_loss = 0.06998370704241097
Trained batch 28 in epoch 17, gen_loss = 0.4170303385833214, disc_loss = 0.06882167874096796
Trained batch 29 in epoch 17, gen_loss = 0.41607694526513417, disc_loss = 0.06726855346933007
Trained batch 30 in epoch 17, gen_loss = 0.4181609182588516, disc_loss = 0.06896662480768657
Trained batch 31 in epoch 17, gen_loss = 0.41715467628091574, disc_loss = 0.06815334488055669
Trained batch 32 in epoch 17, gen_loss = 0.41563992789297394, disc_loss = 0.0673186390406706
Trained batch 33 in epoch 17, gen_loss = 0.4137007269789191, disc_loss = 0.06667042312705342
Trained batch 34 in epoch 17, gen_loss = 0.41566644821848187, disc_loss = 0.07441881562450102
Trained batch 35 in epoch 17, gen_loss = 0.4141199191411336, disc_loss = 0.07431644726441139
Trained batch 36 in epoch 17, gen_loss = 0.4121762006669431, disc_loss = 0.07359394448733814
Trained batch 37 in epoch 17, gen_loss = 0.41188138723373413, disc_loss = 0.07631299426583082
Trained batch 38 in epoch 17, gen_loss = 0.4077911025438553, disc_loss = 0.08238053453178742
Trained batch 39 in epoch 17, gen_loss = 0.4072868078947067, disc_loss = 0.08262978566344828
Trained batch 40 in epoch 17, gen_loss = 0.4093969835013878, disc_loss = 0.08252439718330051
Trained batch 41 in epoch 17, gen_loss = 0.4099849249635424, disc_loss = 0.08199169404716009
Trained batch 42 in epoch 17, gen_loss = 0.410024457199629, disc_loss = 0.08122539232203434
Trained batch 43 in epoch 17, gen_loss = 0.40994779697873374, disc_loss = 0.08041385643776845
Trained batch 44 in epoch 17, gen_loss = 0.4102035257551405, disc_loss = 0.07969922007371982
Trained batch 45 in epoch 17, gen_loss = 0.41142232975234155, disc_loss = 0.07975375634091704
Trained batch 46 in epoch 17, gen_loss = 0.41315368515379886, disc_loss = 0.0786913530504767
Trained batch 47 in epoch 17, gen_loss = 0.41313643753528595, disc_loss = 0.07789939193753526
Trained batch 48 in epoch 17, gen_loss = 0.4122955148317376, disc_loss = 0.07763054968827234
Trained batch 49 in epoch 17, gen_loss = 0.4114921188354492, disc_loss = 0.07971147062256932
Trained batch 50 in epoch 17, gen_loss = 0.4117928159003164, disc_loss = 0.07908975941074245
Trained batch 51 in epoch 17, gen_loss = 0.4115303067060617, disc_loss = 0.07814490001720305
Trained batch 52 in epoch 17, gen_loss = 0.41101891702076176, disc_loss = 0.0769950480569365
Trained batch 53 in epoch 17, gen_loss = 0.4097649891067434, disc_loss = 0.0766043573514455
Trained batch 54 in epoch 17, gen_loss = 0.40949117107824845, disc_loss = 0.07571448326449502
Trained batch 55 in epoch 17, gen_loss = 0.4091544821858406, disc_loss = 0.07505606469099543
Trained batch 56 in epoch 17, gen_loss = 0.4101936906053309, disc_loss = 0.07420817914565928
Trained batch 57 in epoch 17, gen_loss = 0.4083831222920582, disc_loss = 0.07419204283184533
Trained batch 58 in epoch 17, gen_loss = 0.40679633970988, disc_loss = 0.07374299502284345
Trained batch 59 in epoch 17, gen_loss = 0.4063299720486005, disc_loss = 0.07469062129966915
Trained batch 60 in epoch 17, gen_loss = 0.40518598820342394, disc_loss = 0.0759226730642993
Trained batch 61 in epoch 17, gen_loss = 0.40830580794042154, disc_loss = 0.07710239358787094
Trained batch 62 in epoch 17, gen_loss = 0.4102477965846894, disc_loss = 0.07632138469212112
Trained batch 63 in epoch 17, gen_loss = 0.41029704362154007, disc_loss = 0.07538028854469303
Trained batch 64 in epoch 17, gen_loss = 0.40971892521931574, disc_loss = 0.07439281050688945
Trained batch 65 in epoch 17, gen_loss = 0.41162067561438587, disc_loss = 0.07373165814770442
Trained batch 66 in epoch 17, gen_loss = 0.4110482432949009, disc_loss = 0.07353140114903894
Trained batch 67 in epoch 17, gen_loss = 0.4105396840502234, disc_loss = 0.07273399634012843
Trained batch 68 in epoch 17, gen_loss = 0.4106518915597943, disc_loss = 0.07270169842556334
Trained batch 69 in epoch 17, gen_loss = 0.409414233480181, disc_loss = 0.07278553291356989
Trained batch 70 in epoch 17, gen_loss = 0.40948760257640354, disc_loss = 0.07252467404001615
Trained batch 71 in epoch 17, gen_loss = 0.4086819216609001, disc_loss = 0.07226646972251022
Trained batch 72 in epoch 17, gen_loss = 0.40778842813348115, disc_loss = 0.07193862158192756
Trained batch 73 in epoch 17, gen_loss = 0.4076949829185331, disc_loss = 0.07113644051541751
Trained batch 74 in epoch 17, gen_loss = 0.40787092645963036, disc_loss = 0.07093841586261988
Trained batch 75 in epoch 17, gen_loss = 0.4084974735190994, disc_loss = 0.07068866230302344
Trained batch 76 in epoch 17, gen_loss = 0.4089144913407115, disc_loss = 0.07007461523806507
Trained batch 77 in epoch 17, gen_loss = 0.4081954593077684, disc_loss = 0.06960923624678682
Trained batch 78 in epoch 17, gen_loss = 0.4083016046994849, disc_loss = 0.0694747373721079
Trained batch 79 in epoch 17, gen_loss = 0.4070381697267294, disc_loss = 0.07043143146438524
Trained batch 80 in epoch 17, gen_loss = 0.4075300388130141, disc_loss = 0.07095858177607074
Trained batch 81 in epoch 17, gen_loss = 0.40636535643077476, disc_loss = 0.07084550053199254
Trained batch 82 in epoch 17, gen_loss = 0.4052196726741561, disc_loss = 0.07308043035712228
Trained batch 83 in epoch 17, gen_loss = 0.4065478912421635, disc_loss = 0.07389801225092794
Trained batch 84 in epoch 17, gen_loss = 0.4082546437487883, disc_loss = 0.07330907823189217
Trained batch 85 in epoch 17, gen_loss = 0.4076173381749974, disc_loss = 0.07319467951175432
Trained batch 86 in epoch 17, gen_loss = 0.4073653258811468, disc_loss = 0.07271617778373518
Trained batch 87 in epoch 17, gen_loss = 0.4068756398152221, disc_loss = 0.07215902800883421
Trained batch 88 in epoch 17, gen_loss = 0.4062508903862385, disc_loss = 0.07232037302776334
Trained batch 89 in epoch 17, gen_loss = 0.4048957649204466, disc_loss = 0.07224860761521591
Trained batch 90 in epoch 17, gen_loss = 0.40426912412538635, disc_loss = 0.0727804714895703
Trained batch 91 in epoch 17, gen_loss = 0.4043242241377416, disc_loss = 0.07349424281805429
Trained batch 92 in epoch 17, gen_loss = 0.404370391561139, disc_loss = 0.07293411411385062
Trained batch 93 in epoch 17, gen_loss = 0.40435665719052577, disc_loss = 0.07267152659713905
Trained batch 94 in epoch 17, gen_loss = 0.404800977518684, disc_loss = 0.07294134057470059
Trained batch 95 in epoch 17, gen_loss = 0.40370600794752437, disc_loss = 0.0725948262164214
Trained batch 96 in epoch 17, gen_loss = 0.4036395906173077, disc_loss = 0.07318955163481002
Trained batch 97 in epoch 17, gen_loss = 0.40361220283167704, disc_loss = 0.07300392537358769
Trained batch 98 in epoch 17, gen_loss = 0.40382352531558335, disc_loss = 0.07253315816210075
Trained batch 99 in epoch 17, gen_loss = 0.4035796019434929, disc_loss = 0.07231731404550373
Trained batch 100 in epoch 17, gen_loss = 0.40356936814761396, disc_loss = 0.07229318880097996
Trained batch 101 in epoch 17, gen_loss = 0.4038793205046186, disc_loss = 0.07205540088790596
Trained batch 102 in epoch 17, gen_loss = 0.4039893370230221, disc_loss = 0.07161038042525354
Trained batch 103 in epoch 17, gen_loss = 0.40467871954807866, disc_loss = 0.07141636103355828
Trained batch 104 in epoch 17, gen_loss = 0.4046495341119312, disc_loss = 0.07104643454686517
Trained batch 105 in epoch 17, gen_loss = 0.4044934156930672, disc_loss = 0.0707793836306148
Trained batch 106 in epoch 17, gen_loss = 0.40509822212647056, disc_loss = 0.07057924679193263
Trained batch 107 in epoch 17, gen_loss = 0.40484412400810804, disc_loss = 0.07047176187754506
Trained batch 108 in epoch 17, gen_loss = 0.40527586926014053, disc_loss = 0.07035355539052585
Trained batch 109 in epoch 17, gen_loss = 0.4052529023452239, disc_loss = 0.07001253287731246
Trained batch 110 in epoch 17, gen_loss = 0.4057104429146191, disc_loss = 0.06956961266864259
Trained batch 111 in epoch 17, gen_loss = 0.4057246648839542, disc_loss = 0.06925062538357452
Trained batch 112 in epoch 17, gen_loss = 0.4064540456881565, disc_loss = 0.06943459844266155
Trained batch 113 in epoch 17, gen_loss = 0.40652108767576384, disc_loss = 0.06921070810047943
Trained batch 114 in epoch 17, gen_loss = 0.40712340137232905, disc_loss = 0.06874001088511685
Trained batch 115 in epoch 17, gen_loss = 0.4069147616110999, disc_loss = 0.06839944721713405
Trained batch 116 in epoch 17, gen_loss = 0.40763625731834996, disc_loss = 0.06803774815371148
Trained batch 117 in epoch 17, gen_loss = 0.4072711813752934, disc_loss = 0.06787261178211892
Trained batch 118 in epoch 17, gen_loss = 0.4073452283354366, disc_loss = 0.06754540958042655
Trained batch 119 in epoch 17, gen_loss = 0.40786620378494265, disc_loss = 0.06742711634530375
Trained batch 120 in epoch 17, gen_loss = 0.40792804611615896, disc_loss = 0.06705287760046642
Trained batch 121 in epoch 17, gen_loss = 0.4075294413038942, disc_loss = 0.06692944988455685
Trained batch 122 in epoch 17, gen_loss = 0.40716479900406627, disc_loss = 0.0671876588594017
Trained batch 123 in epoch 17, gen_loss = 0.40719629415581304, disc_loss = 0.06686427282740272
Trained batch 124 in epoch 17, gen_loss = 0.4073857355117798, disc_loss = 0.06668354410678148
Trained batch 125 in epoch 17, gen_loss = 0.4073002615145275, disc_loss = 0.06662341923497263
Trained batch 126 in epoch 17, gen_loss = 0.40834487305851436, disc_loss = 0.06713649836610856
Trained batch 127 in epoch 17, gen_loss = 0.40781409852206707, disc_loss = 0.06688464136823313
Trained batch 128 in epoch 17, gen_loss = 0.4076663549094237, disc_loss = 0.067534992233092
Trained batch 129 in epoch 17, gen_loss = 0.40848924357157484, disc_loss = 0.07002733470872044
Trained batch 130 in epoch 17, gen_loss = 0.40850534648385667, disc_loss = 0.06993481838890842
Trained batch 131 in epoch 17, gen_loss = 0.40812643007798627, disc_loss = 0.07019501374893342
Trained batch 132 in epoch 17, gen_loss = 0.4080017437612204, disc_loss = 0.0701365795588695
Trained batch 133 in epoch 17, gen_loss = 0.40768140643390255, disc_loss = 0.06976947786786886
Trained batch 134 in epoch 17, gen_loss = 0.40741192036204865, disc_loss = 0.06931274468424144
Trained batch 135 in epoch 17, gen_loss = 0.40700849320958643, disc_loss = 0.0689692844855873
Trained batch 136 in epoch 17, gen_loss = 0.4066268486263108, disc_loss = 0.06871209913579217
Trained batch 137 in epoch 17, gen_loss = 0.40692971754765167, disc_loss = 0.0685071136424507
Trained batch 138 in epoch 17, gen_loss = 0.40663354838494775, disc_loss = 0.06829186928250806
Trained batch 139 in epoch 17, gen_loss = 0.40698822907039095, disc_loss = 0.06803261927728142
Trained batch 140 in epoch 17, gen_loss = 0.4073615983022866, disc_loss = 0.06794297972575147
Trained batch 141 in epoch 17, gen_loss = 0.4070784034023822, disc_loss = 0.06830703548457422
Trained batch 142 in epoch 17, gen_loss = 0.40685631032590264, disc_loss = 0.06819814636365518
Trained batch 143 in epoch 17, gen_loss = 0.40611157814661664, disc_loss = 0.06800273259998196
Trained batch 144 in epoch 17, gen_loss = 0.40536833631581276, disc_loss = 0.06812262321854459
Trained batch 145 in epoch 17, gen_loss = 0.40556065962739185, disc_loss = 0.06785469823708273
Trained batch 146 in epoch 17, gen_loss = 0.4054697506687268, disc_loss = 0.06756737164291395
Trained batch 147 in epoch 17, gen_loss = 0.40510225416840734, disc_loss = 0.06833935403139205
Trained batch 148 in epoch 17, gen_loss = 0.4051708481055778, disc_loss = 0.06873837148383159
Trained batch 149 in epoch 17, gen_loss = 0.4052710078159968, disc_loss = 0.06840535302956899
Trained batch 150 in epoch 17, gen_loss = 0.4051393803381762, disc_loss = 0.06823914804008623
Trained batch 151 in epoch 17, gen_loss = 0.40481110426940414, disc_loss = 0.06813936778589298
Trained batch 152 in epoch 17, gen_loss = 0.4051470004655177, disc_loss = 0.06890418161364163
Trained batch 153 in epoch 17, gen_loss = 0.4045416434089859, disc_loss = 0.06883797676048496
Trained batch 154 in epoch 17, gen_loss = 0.4042547245179453, disc_loss = 0.06934678792472809
Trained batch 155 in epoch 17, gen_loss = 0.4041499411448454, disc_loss = 0.06918485601169941
Trained batch 156 in epoch 17, gen_loss = 0.40427094982687833, disc_loss = 0.06897448347347557
Trained batch 157 in epoch 17, gen_loss = 0.40391385875925234, disc_loss = 0.06920159784959087
Trained batch 158 in epoch 17, gen_loss = 0.4041651309286273, disc_loss = 0.06938824697204356
Trained batch 159 in epoch 17, gen_loss = 0.4046193728223443, disc_loss = 0.07005916323978453
Trained batch 160 in epoch 17, gen_loss = 0.4045328810718489, disc_loss = 0.0709104727004996
Trained batch 161 in epoch 17, gen_loss = 0.4048180333626123, disc_loss = 0.07090543318585849
Trained batch 162 in epoch 17, gen_loss = 0.40517326037576595, disc_loss = 0.07112777569085542
Trained batch 163 in epoch 17, gen_loss = 0.40487203256386084, disc_loss = 0.07158331307241829
Trained batch 164 in epoch 17, gen_loss = 0.404319915265748, disc_loss = 0.07163093914136742
Trained batch 165 in epoch 17, gen_loss = 0.4045507503920291, disc_loss = 0.07144174186221089
Trained batch 166 in epoch 17, gen_loss = 0.40468422435000984, disc_loss = 0.07113343994774504
Trained batch 167 in epoch 17, gen_loss = 0.4046669847198895, disc_loss = 0.0709393905874874
Trained batch 168 in epoch 17, gen_loss = 0.40477063352539694, disc_loss = 0.07091619768703478
Trained batch 169 in epoch 17, gen_loss = 0.4043083460891948, disc_loss = 0.07091272633303614
Trained batch 170 in epoch 17, gen_loss = 0.40494376525544284, disc_loss = 0.07070906279467003
Trained batch 171 in epoch 17, gen_loss = 0.4051852281703505, disc_loss = 0.07041500755694023
Trained batch 172 in epoch 17, gen_loss = 0.4051042767618433, disc_loss = 0.07009199166918076
Trained batch 173 in epoch 17, gen_loss = 0.40453817618304283, disc_loss = 0.06997005301045961
Trained batch 174 in epoch 17, gen_loss = 0.40523595775876725, disc_loss = 0.06973257470343794
Trained batch 175 in epoch 17, gen_loss = 0.40511253594674845, disc_loss = 0.0695816203422675
Trained batch 176 in epoch 17, gen_loss = 0.4046696532244063, disc_loss = 0.0694890259159992
Trained batch 177 in epoch 17, gen_loss = 0.40466781881418123, disc_loss = 0.06921160275514206
Trained batch 178 in epoch 17, gen_loss = 0.40468473074822453, disc_loss = 0.0689587391725632
Trained batch 179 in epoch 17, gen_loss = 0.40474275797605513, disc_loss = 0.06881801797490981
Trained batch 180 in epoch 17, gen_loss = 0.4051522497314116, disc_loss = 0.06854591421906461
Trained batch 181 in epoch 17, gen_loss = 0.40524809111605636, disc_loss = 0.06832098138037619
Trained batch 182 in epoch 17, gen_loss = 0.4055686930163962, disc_loss = 0.06808813556499495
Trained batch 183 in epoch 17, gen_loss = 0.40542283751394437, disc_loss = 0.06795092990986355
Trained batch 184 in epoch 17, gen_loss = 0.40524449171246707, disc_loss = 0.06782499558820917
Trained batch 185 in epoch 17, gen_loss = 0.40506605387374917, disc_loss = 0.0678743920238909
Trained batch 186 in epoch 17, gen_loss = 0.40504814070813794, disc_loss = 0.06758541383725755
Trained batch 187 in epoch 17, gen_loss = 0.40474997857149614, disc_loss = 0.06743677339932704
Trained batch 188 in epoch 17, gen_loss = 0.40476730639341646, disc_loss = 0.06761062518747711
Trained batch 189 in epoch 17, gen_loss = 0.40509550445958187, disc_loss = 0.0682102576976544
Trained batch 190 in epoch 17, gen_loss = 0.40471655816932, disc_loss = 0.06884986118301359
Trained batch 191 in epoch 17, gen_loss = 0.4050580800200502, disc_loss = 0.06888648203069654
Trained batch 192 in epoch 17, gen_loss = 0.4046255011941485, disc_loss = 0.06906319702034479
Trained batch 193 in epoch 17, gen_loss = 0.40442100904651523, disc_loss = 0.06897453140928266
Trained batch 194 in epoch 17, gen_loss = 0.40474897225697837, disc_loss = 0.06945726679494747
Trained batch 195 in epoch 17, gen_loss = 0.4043039671924649, disc_loss = 0.06940249320385712
Trained batch 196 in epoch 17, gen_loss = 0.4040649617989051, disc_loss = 0.06965269058526773
Trained batch 197 in epoch 17, gen_loss = 0.40421473106952627, disc_loss = 0.0722682952523382
Trained batch 198 in epoch 17, gen_loss = 0.40379601147905664, disc_loss = 0.07264387054396934
Trained batch 199 in epoch 17, gen_loss = 0.4037090492248535, disc_loss = 0.07268893987871707
Trained batch 200 in epoch 17, gen_loss = 0.40339193089091363, disc_loss = 0.07268433840899029
Trained batch 201 in epoch 17, gen_loss = 0.40320721076856747, disc_loss = 0.0725866710804034
Trained batch 202 in epoch 17, gen_loss = 0.40332962712043613, disc_loss = 0.07277374238399743
Trained batch 203 in epoch 17, gen_loss = 0.4026536180400381, disc_loss = 0.07301719425538299
Trained batch 204 in epoch 17, gen_loss = 0.4032135063555182, disc_loss = 0.07302325096253942
Trained batch 205 in epoch 17, gen_loss = 0.4027909455658163, disc_loss = 0.07279844728560703
Trained batch 206 in epoch 17, gen_loss = 0.4028737101577906, disc_loss = 0.07272567007924624
Trained batch 207 in epoch 17, gen_loss = 0.40294239670038223, disc_loss = 0.07294455813602187
Trained batch 208 in epoch 17, gen_loss = 0.40258492308370236, disc_loss = 0.07273224340172475
Trained batch 209 in epoch 17, gen_loss = 0.40303903151126136, disc_loss = 0.0726258945429609
Trained batch 210 in epoch 17, gen_loss = 0.4031132171504305, disc_loss = 0.07252699865902204
Trained batch 211 in epoch 17, gen_loss = 0.4032813513054038, disc_loss = 0.07229883949500772
Trained batch 212 in epoch 17, gen_loss = 0.40310622828667153, disc_loss = 0.07238289106969542
Trained batch 213 in epoch 17, gen_loss = 0.4034288928051975, disc_loss = 0.07290012767172863
Trained batch 214 in epoch 17, gen_loss = 0.40323886386183805, disc_loss = 0.07281859023279921
Trained batch 215 in epoch 17, gen_loss = 0.4027224268626284, disc_loss = 0.07271389778772439
Trained batch 216 in epoch 17, gen_loss = 0.40229170759152705, disc_loss = 0.07339352710936475
Trained batch 217 in epoch 17, gen_loss = 0.4022987959308362, disc_loss = 0.0736044356001353
Trained batch 218 in epoch 17, gen_loss = 0.4025310288825536, disc_loss = 0.07345592489117357
Trained batch 219 in epoch 17, gen_loss = 0.40242574309760876, disc_loss = 0.0732148456048559
Trained batch 220 in epoch 17, gen_loss = 0.4021986477515277, disc_loss = 0.07299228514043185
Trained batch 221 in epoch 17, gen_loss = 0.4023752987116307, disc_loss = 0.0727310133846225
Trained batch 222 in epoch 17, gen_loss = 0.4023839601486788, disc_loss = 0.07259349120705652
Trained batch 223 in epoch 17, gen_loss = 0.40236326227230684, disc_loss = 0.07236897056489917
Trained batch 224 in epoch 17, gen_loss = 0.40243552247683206, disc_loss = 0.07220685275892416
Trained batch 225 in epoch 17, gen_loss = 0.4027239325563465, disc_loss = 0.0721211778164833
Trained batch 226 in epoch 17, gen_loss = 0.40260839567310486, disc_loss = 0.07195613146780083
Trained batch 227 in epoch 17, gen_loss = 0.4023239152473316, disc_loss = 0.07182874106556962
Trained batch 228 in epoch 17, gen_loss = 0.40243943094166085, disc_loss = 0.07157426533252652
Trained batch 229 in epoch 17, gen_loss = 0.40235575942889507, disc_loss = 0.07143483979060598
Trained batch 230 in epoch 17, gen_loss = 0.40270707114434345, disc_loss = 0.07151029546829787
Trained batch 231 in epoch 17, gen_loss = 0.4026831227900653, disc_loss = 0.07127421916912086
Trained batch 232 in epoch 17, gen_loss = 0.4023878227743468, disc_loss = 0.07122583616157202
Trained batch 233 in epoch 17, gen_loss = 0.40241173839467204, disc_loss = 0.07121447288295907
Trained batch 234 in epoch 17, gen_loss = 0.4020643787181124, disc_loss = 0.07100363036895052
Trained batch 235 in epoch 17, gen_loss = 0.401955386844732, disc_loss = 0.07105794753405754
Trained batch 236 in epoch 17, gen_loss = 0.40189575645994036, disc_loss = 0.0719262954036269
Trained batch 237 in epoch 17, gen_loss = 0.4015535478081022, disc_loss = 0.0720333747424874
Trained batch 238 in epoch 17, gen_loss = 0.4015341883673329, disc_loss = 0.07181609129712423
Trained batch 239 in epoch 17, gen_loss = 0.40173881463706496, disc_loss = 0.07177405982123067
Trained batch 240 in epoch 17, gen_loss = 0.40153657932499137, disc_loss = 0.07160745874140025
Trained batch 241 in epoch 17, gen_loss = 0.4018358830824371, disc_loss = 0.07154503631721104
Trained batch 242 in epoch 17, gen_loss = 0.40211531801969425, disc_loss = 0.07134806209937535
Trained batch 243 in epoch 17, gen_loss = 0.40229802200051606, disc_loss = 0.0711761681271381
Trained batch 244 in epoch 17, gen_loss = 0.40220982237738007, disc_loss = 0.07105617176513282
Trained batch 245 in epoch 17, gen_loss = 0.40224208349619456, disc_loss = 0.07104770324336804
Trained batch 246 in epoch 17, gen_loss = 0.4024928396771311, disc_loss = 0.0710987407668882
Trained batch 247 in epoch 17, gen_loss = 0.40241762346798376, disc_loss = 0.0709512532358208
Trained batch 248 in epoch 17, gen_loss = 0.4022163578784131, disc_loss = 0.07080616529686863
Trained batch 249 in epoch 17, gen_loss = 0.402366489648819, disc_loss = 0.07070731964707375
Trained batch 250 in epoch 17, gen_loss = 0.402397550672174, disc_loss = 0.07055017182907736
Trained batch 251 in epoch 17, gen_loss = 0.4019456020896397, disc_loss = 0.07084281432131927
Trained batch 252 in epoch 17, gen_loss = 0.40163838509985583, disc_loss = 0.07208363361391626
Trained batch 253 in epoch 17, gen_loss = 0.4016320466056583, disc_loss = 0.0719791850969782
Trained batch 254 in epoch 17, gen_loss = 0.40148524782236883, disc_loss = 0.07233628912591467
Trained batch 255 in epoch 17, gen_loss = 0.4014258028473705, disc_loss = 0.0725358877243707
Trained batch 256 in epoch 17, gen_loss = 0.4016538472259091, disc_loss = 0.07241305866883886
Trained batch 257 in epoch 17, gen_loss = 0.4020249045403429, disc_loss = 0.07256718267246272
Trained batch 258 in epoch 17, gen_loss = 0.40169011338337046, disc_loss = 0.07282371063892906
Trained batch 259 in epoch 17, gen_loss = 0.401568972491301, disc_loss = 0.07273300632547874
Trained batch 260 in epoch 17, gen_loss = 0.4013384144424935, disc_loss = 0.0728041008543009
Trained batch 261 in epoch 17, gen_loss = 0.4013572387567913, disc_loss = 0.07276824996842228
Trained batch 262 in epoch 17, gen_loss = 0.40115178843868093, disc_loss = 0.07288362529171284
Trained batch 263 in epoch 17, gen_loss = 0.4013427261150245, disc_loss = 0.07297567025560772
Trained batch 264 in epoch 17, gen_loss = 0.4012372777147113, disc_loss = 0.07290249189959382
Trained batch 265 in epoch 17, gen_loss = 0.40119167691782903, disc_loss = 0.07276286062945549
Trained batch 266 in epoch 17, gen_loss = 0.4010962070374007, disc_loss = 0.07256813048758311
Trained batch 267 in epoch 17, gen_loss = 0.4015599492548117, disc_loss = 0.07292785926430083
Trained batch 268 in epoch 17, gen_loss = 0.40125581533492277, disc_loss = 0.0732590596859783
Trained batch 269 in epoch 17, gen_loss = 0.4013320521072105, disc_loss = 0.0731482771259767
Trained batch 270 in epoch 17, gen_loss = 0.4015417789621107, disc_loss = 0.07360796652376872
Trained batch 271 in epoch 17, gen_loss = 0.40136070067391677, disc_loss = 0.0742749411284047
Trained batch 272 in epoch 17, gen_loss = 0.401532191496629, disc_loss = 0.07441148336553749
Trained batch 273 in epoch 17, gen_loss = 0.40143097621681045, disc_loss = 0.07430131317381442
Trained batch 274 in epoch 17, gen_loss = 0.4017697274684906, disc_loss = 0.07466426136818799
Trained batch 275 in epoch 17, gen_loss = 0.4023314909874529, disc_loss = 0.07516893730971261
Trained batch 276 in epoch 17, gen_loss = 0.40242132738178815, disc_loss = 0.07498413208024812
Trained batch 277 in epoch 17, gen_loss = 0.4022756356129543, disc_loss = 0.07479369253080954
Trained batch 278 in epoch 17, gen_loss = 0.4020568112105024, disc_loss = 0.07473529066129397
Trained batch 279 in epoch 17, gen_loss = 0.40172242021986415, disc_loss = 0.07458270484847682
Trained batch 280 in epoch 17, gen_loss = 0.4016164148829586, disc_loss = 0.0745760471265087
Trained batch 281 in epoch 17, gen_loss = 0.4016550729672114, disc_loss = 0.07444554086483962
Trained batch 282 in epoch 17, gen_loss = 0.401782322266919, disc_loss = 0.07450929078744073
Trained batch 283 in epoch 17, gen_loss = 0.40152894233314085, disc_loss = 0.07470463987597277
Trained batch 284 in epoch 17, gen_loss = 0.4017479453170509, disc_loss = 0.07480087269816482
Trained batch 285 in epoch 17, gen_loss = 0.4013924236064191, disc_loss = 0.07491287500499845
Trained batch 286 in epoch 17, gen_loss = 0.40174630356997976, disc_loss = 0.07474296974855434
Trained batch 287 in epoch 17, gen_loss = 0.4020141659097539, disc_loss = 0.0745566420826233
Trained batch 288 in epoch 17, gen_loss = 0.4018633968896107, disc_loss = 0.07456255588152004
Trained batch 289 in epoch 17, gen_loss = 0.4019443054651392, disc_loss = 0.07451160823733642
Trained batch 290 in epoch 17, gen_loss = 0.4019377811258191, disc_loss = 0.07436647711648155
Trained batch 291 in epoch 17, gen_loss = 0.40195140763096615, disc_loss = 0.0743320949171504
Trained batch 292 in epoch 17, gen_loss = 0.40214110041234274, disc_loss = 0.07423534900356885
Trained batch 293 in epoch 17, gen_loss = 0.40220855237269887, disc_loss = 0.07413410387781201
Trained batch 294 in epoch 17, gen_loss = 0.40213896692809414, disc_loss = 0.07433923677367679
Trained batch 295 in epoch 17, gen_loss = 0.40214467159396894, disc_loss = 0.07418541145838194
Trained batch 296 in epoch 17, gen_loss = 0.40190701181639726, disc_loss = 0.07409455319897895
Trained batch 297 in epoch 17, gen_loss = 0.4017136327972348, disc_loss = 0.07412134217185862
Trained batch 298 in epoch 17, gen_loss = 0.40150150038725557, disc_loss = 0.07412286617335269
Trained batch 299 in epoch 17, gen_loss = 0.4018172678351402, disc_loss = 0.07405157784620921
Trained batch 300 in epoch 17, gen_loss = 0.40163161687280646, disc_loss = 0.07392182944967501
Trained batch 301 in epoch 17, gen_loss = 0.4015205414682035, disc_loss = 0.07377081788730937
Trained batch 302 in epoch 17, gen_loss = 0.4014679471848428, disc_loss = 0.07359945099100028
Trained batch 303 in epoch 17, gen_loss = 0.4014803962291856, disc_loss = 0.07365171668904
Trained batch 304 in epoch 17, gen_loss = 0.40164548578809517, disc_loss = 0.07403611060781556
Trained batch 305 in epoch 17, gen_loss = 0.40169962013469024, disc_loss = 0.07406465785906595
Trained batch 306 in epoch 17, gen_loss = 0.4016873148248716, disc_loss = 0.07385987014864671
Trained batch 307 in epoch 17, gen_loss = 0.40158250057078027, disc_loss = 0.07380764869150597
Trained batch 308 in epoch 17, gen_loss = 0.401700546151226, disc_loss = 0.07377012760580358
Trained batch 309 in epoch 17, gen_loss = 0.40158242612115796, disc_loss = 0.0737108216590939
Trained batch 310 in epoch 17, gen_loss = 0.40178663717205504, disc_loss = 0.07353191624524318
Trained batch 311 in epoch 17, gen_loss = 0.40194789444406825, disc_loss = 0.07355616046473958
Trained batch 312 in epoch 17, gen_loss = 0.40164276186269693, disc_loss = 0.07339016753382767
Trained batch 313 in epoch 17, gen_loss = 0.4013657231999051, disc_loss = 0.07361512596179155
Trained batch 314 in epoch 17, gen_loss = 0.4014983277472239, disc_loss = 0.07369208357755154
Trained batch 315 in epoch 17, gen_loss = 0.40155491015956374, disc_loss = 0.0735806109961358
Trained batch 316 in epoch 17, gen_loss = 0.4018477657427923, disc_loss = 0.07341060798603466
Trained batch 317 in epoch 17, gen_loss = 0.40197840098689935, disc_loss = 0.07350426295526186
Trained batch 318 in epoch 17, gen_loss = 0.40165162637689644, disc_loss = 0.07384523517542685
Trained batch 319 in epoch 17, gen_loss = 0.40166464326903223, disc_loss = 0.07366504675010219
Trained batch 320 in epoch 17, gen_loss = 0.4016366901798783, disc_loss = 0.07378686995846089
Trained batch 321 in epoch 17, gen_loss = 0.4011964778537336, disc_loss = 0.07423764771509984
Trained batch 322 in epoch 17, gen_loss = 0.40122863871763365, disc_loss = 0.07437904288663584
Trained batch 323 in epoch 17, gen_loss = 0.401125718689995, disc_loss = 0.07427340394092931
Trained batch 324 in epoch 17, gen_loss = 0.4010044140082139, disc_loss = 0.07435392221579185
Trained batch 325 in epoch 17, gen_loss = 0.4011185359369758, disc_loss = 0.07420404360521059
Trained batch 326 in epoch 17, gen_loss = 0.40117498949762515, disc_loss = 0.07402023098884372
Trained batch 327 in epoch 17, gen_loss = 0.4009270678933074, disc_loss = 0.07387942660645377
Trained batch 328 in epoch 17, gen_loss = 0.40082128386729393, disc_loss = 0.07386277524307144
Trained batch 329 in epoch 17, gen_loss = 0.400853521715511, disc_loss = 0.07387828525494446
Trained batch 330 in epoch 17, gen_loss = 0.40093583597877597, disc_loss = 0.07386716818746483
Trained batch 331 in epoch 17, gen_loss = 0.4009033977446786, disc_loss = 0.07395181855388794
Trained batch 332 in epoch 17, gen_loss = 0.4010753358627583, disc_loss = 0.07427810795896046
Trained batch 333 in epoch 17, gen_loss = 0.4010208372227446, disc_loss = 0.07415229626401455
Trained batch 334 in epoch 17, gen_loss = 0.4010982017908523, disc_loss = 0.07397128196794596
Trained batch 335 in epoch 17, gen_loss = 0.4010184902165617, disc_loss = 0.07404623681768066
Trained batch 336 in epoch 17, gen_loss = 0.40102806820006326, disc_loss = 0.07396940835019247
Trained batch 337 in epoch 17, gen_loss = 0.4007457813920354, disc_loss = 0.07393461193602818
Trained batch 338 in epoch 17, gen_loss = 0.4007196774524925, disc_loss = 0.07378318167365758
Trained batch 339 in epoch 17, gen_loss = 0.4008419171852224, disc_loss = 0.07359715083559208
Trained batch 340 in epoch 17, gen_loss = 0.400846751554271, disc_loss = 0.07341020874121934
Trained batch 341 in epoch 17, gen_loss = 0.40104839850587454, disc_loss = 0.07333973643495238
Trained batch 342 in epoch 17, gen_loss = 0.40100493514503055, disc_loss = 0.0733610351730149
Trained batch 343 in epoch 17, gen_loss = 0.4010028670173745, disc_loss = 0.07328104254583893
Trained batch 344 in epoch 17, gen_loss = 0.4010303689085919, disc_loss = 0.07311931469788154
Trained batch 345 in epoch 17, gen_loss = 0.4010780381329487, disc_loss = 0.07296377454609798
Trained batch 346 in epoch 17, gen_loss = 0.4011510080665951, disc_loss = 0.07286372689277965
Trained batch 347 in epoch 17, gen_loss = 0.40095641386920006, disc_loss = 0.07278775169792447
Trained batch 348 in epoch 17, gen_loss = 0.4009182912572407, disc_loss = 0.07271315042932856
Trained batch 349 in epoch 17, gen_loss = 0.40098305182797567, disc_loss = 0.07254256270559771
Trained batch 350 in epoch 17, gen_loss = 0.4012406039611566, disc_loss = 0.07245467519095736
Trained batch 351 in epoch 17, gen_loss = 0.40109346993267536, disc_loss = 0.07278636687128297
Trained batch 352 in epoch 17, gen_loss = 0.4015184480475299, disc_loss = 0.0727391362417141
Trained batch 353 in epoch 17, gen_loss = 0.4017449028916278, disc_loss = 0.0726198059096301
Trained batch 354 in epoch 17, gen_loss = 0.4016033380803928, disc_loss = 0.07250935205219078
Trained batch 355 in epoch 17, gen_loss = 0.401441757431191, disc_loss = 0.07250150861061608
Trained batch 356 in epoch 17, gen_loss = 0.4014897908316273, disc_loss = 0.07247291209765759
Trained batch 357 in epoch 17, gen_loss = 0.40163145593091765, disc_loss = 0.07234299267959578
Trained batch 358 in epoch 17, gen_loss = 0.4015749448853283, disc_loss = 0.07228842985486834
Trained batch 359 in epoch 17, gen_loss = 0.4014492946366469, disc_loss = 0.07229333103686157
Trained batch 360 in epoch 17, gen_loss = 0.4013156705120594, disc_loss = 0.07228644707928981
Trained batch 361 in epoch 17, gen_loss = 0.4013162399359171, disc_loss = 0.07247105162354052
Trained batch 362 in epoch 17, gen_loss = 0.40145916296759254, disc_loss = 0.07242701693948553
Trained batch 363 in epoch 17, gen_loss = 0.40148498641920616, disc_loss = 0.07227979048544152
Trained batch 364 in epoch 17, gen_loss = 0.4017149074436867, disc_loss = 0.07230727697837434
Trained batch 365 in epoch 17, gen_loss = 0.4016389057773059, disc_loss = 0.07259344705253269
Trained batch 366 in epoch 17, gen_loss = 0.4020413466467844, disc_loss = 0.07253657593785173
Trained batch 367 in epoch 17, gen_loss = 0.4020340105761652, disc_loss = 0.07245252086811335
Trained batch 368 in epoch 17, gen_loss = 0.40196281534223377, disc_loss = 0.07242132230411942
Trained batch 369 in epoch 17, gen_loss = 0.4021028687825074, disc_loss = 0.07231392974940104
Trained batch 370 in epoch 17, gen_loss = 0.4021950299849086, disc_loss = 0.07222192135772534
Trained batch 371 in epoch 17, gen_loss = 0.4022067202034817, disc_loss = 0.07205543238218994
Trained batch 372 in epoch 17, gen_loss = 0.40238144602277004, disc_loss = 0.07196515215056432
Trained batch 373 in epoch 17, gen_loss = 0.4023697043166441, disc_loss = 0.07184224752808877
Trained batch 374 in epoch 17, gen_loss = 0.4020646132628123, disc_loss = 0.07224532466878493
Trained batch 375 in epoch 17, gen_loss = 0.4020236855808725, disc_loss = 0.07222652637171856
Trained batch 376 in epoch 17, gen_loss = 0.4021743329671713, disc_loss = 0.07218393709866296
Trained batch 377 in epoch 17, gen_loss = 0.40204547109111904, disc_loss = 0.07252441112829185
Trained batch 378 in epoch 17, gen_loss = 0.4021896464371744, disc_loss = 0.07289717201693942
Trained batch 379 in epoch 17, gen_loss = 0.4022034976827471, disc_loss = 0.072843469186735
Trained batch 380 in epoch 17, gen_loss = 0.4018729051423511, disc_loss = 0.0732073604136588
Trained batch 381 in epoch 17, gen_loss = 0.4018277635905131, disc_loss = 0.07313044290960381
Trained batch 382 in epoch 17, gen_loss = 0.4018980128491205, disc_loss = 0.07320707295012147
Trained batch 383 in epoch 17, gen_loss = 0.4018899571771423, disc_loss = 0.0735249450832877
Trained batch 384 in epoch 17, gen_loss = 0.40184355594895105, disc_loss = 0.07397650238126516
Trained batch 385 in epoch 17, gen_loss = 0.40200056081608787, disc_loss = 0.07420676488940811
Trained batch 386 in epoch 17, gen_loss = 0.4019463466581448, disc_loss = 0.07492643607977671
Trained batch 387 in epoch 17, gen_loss = 0.4022024692487471, disc_loss = 0.07533937410125029
Trained batch 388 in epoch 17, gen_loss = 0.402194167087501, disc_loss = 0.07538235719749048
Trained batch 389 in epoch 17, gen_loss = 0.4021458748823557, disc_loss = 0.0752967379676799
Trained batch 390 in epoch 17, gen_loss = 0.4018408479288106, disc_loss = 0.07544070183802062
Trained batch 391 in epoch 17, gen_loss = 0.40175255912603164, disc_loss = 0.07542567744575517
Trained batch 392 in epoch 17, gen_loss = 0.40164929408456834, disc_loss = 0.07537600746657937
Trained batch 393 in epoch 17, gen_loss = 0.40152643953785677, disc_loss = 0.07528055990398459
Trained batch 394 in epoch 17, gen_loss = 0.4017262105700336, disc_loss = 0.07518516470312694
Trained batch 395 in epoch 17, gen_loss = 0.4018224279838379, disc_loss = 0.07505962806471596
Trained batch 396 in epoch 17, gen_loss = 0.4020464926282465, disc_loss = 0.07498025442579156
Trained batch 397 in epoch 17, gen_loss = 0.40200735980541863, disc_loss = 0.07488034227301353
Trained batch 398 in epoch 17, gen_loss = 0.4021368594396682, disc_loss = 0.07487389971653845
Trained batch 399 in epoch 17, gen_loss = 0.40222888298332693, disc_loss = 0.07496643533697352
Trained batch 400 in epoch 17, gen_loss = 0.4022370481728913, disc_loss = 0.07519593208498714
Trained batch 401 in epoch 17, gen_loss = 0.40236292208605146, disc_loss = 0.07506002024492592
Trained batch 402 in epoch 17, gen_loss = 0.4023924100191954, disc_loss = 0.07491074395007812
Trained batch 403 in epoch 17, gen_loss = 0.40229133369013814, disc_loss = 0.07476173816156564
Trained batch 404 in epoch 17, gen_loss = 0.40239203388308303, disc_loss = 0.07464655347076463
Trained batch 405 in epoch 17, gen_loss = 0.402467604634797, disc_loss = 0.07462262031920437
Trained batch 406 in epoch 17, gen_loss = 0.40240620307313135, disc_loss = 0.0745269428911168
Trained batch 407 in epoch 17, gen_loss = 0.40239207453879655, disc_loss = 0.07453125489729584
Trained batch 408 in epoch 17, gen_loss = 0.4025489018278192, disc_loss = 0.07449942983887306
Trained batch 409 in epoch 17, gen_loss = 0.4024929072071866, disc_loss = 0.07440368594919763
Trained batch 410 in epoch 17, gen_loss = 0.4024748805085528, disc_loss = 0.07454149298134222
Trained batch 411 in epoch 17, gen_loss = 0.4023331771921186, disc_loss = 0.07497098586223658
Trained batch 412 in epoch 17, gen_loss = 0.40213314102867903, disc_loss = 0.07488401025786239
Trained batch 413 in epoch 17, gen_loss = 0.4021254435253604, disc_loss = 0.07485523208939798
Trained batch 414 in epoch 17, gen_loss = 0.4020024130861443, disc_loss = 0.07493803060377936
Trained batch 415 in epoch 17, gen_loss = 0.4022694624817142, disc_loss = 0.07492446832251377
Trained batch 416 in epoch 17, gen_loss = 0.40199914710413065, disc_loss = 0.07491691482903289
Trained batch 417 in epoch 17, gen_loss = 0.4020768468174638, disc_loss = 0.07489942189787278
Trained batch 418 in epoch 17, gen_loss = 0.4020381384220214, disc_loss = 0.07496986517722681
Trained batch 419 in epoch 17, gen_loss = 0.4021151058021046, disc_loss = 0.07485694269694033
Trained batch 420 in epoch 17, gen_loss = 0.4020296200012651, disc_loss = 0.07481682675751258
Trained batch 421 in epoch 17, gen_loss = 0.40207318650885215, disc_loss = 0.07472929319640471
Trained batch 422 in epoch 17, gen_loss = 0.4021000419666299, disc_loss = 0.07463476669492451
Trained batch 423 in epoch 17, gen_loss = 0.40209362747253113, disc_loss = 0.07452357222132806
Trained batch 424 in epoch 17, gen_loss = 0.4021132488110486, disc_loss = 0.07443131404764512
Trained batch 425 in epoch 17, gen_loss = 0.40214161784716057, disc_loss = 0.07441187527537906
Trained batch 426 in epoch 17, gen_loss = 0.4021922202663064, disc_loss = 0.07438510466166347
Trained batch 427 in epoch 17, gen_loss = 0.40238382764787317, disc_loss = 0.07441494314470024
Trained batch 428 in epoch 17, gen_loss = 0.40212756207772904, disc_loss = 0.07510933592602924
Trained batch 429 in epoch 17, gen_loss = 0.4021390697983808, disc_loss = 0.07508119067480398
Trained batch 430 in epoch 17, gen_loss = 0.40207347958381107, disc_loss = 0.07515988478182087
Trained batch 431 in epoch 17, gen_loss = 0.4019326718731059, disc_loss = 0.07526575879159349
Trained batch 432 in epoch 17, gen_loss = 0.40184267749687264, disc_loss = 0.07524134032858437
Trained batch 433 in epoch 17, gen_loss = 0.40187694496273446, disc_loss = 0.07512009116790948
Trained batch 434 in epoch 17, gen_loss = 0.4019048629135921, disc_loss = 0.07500649049621204
Trained batch 435 in epoch 17, gen_loss = 0.40184007687579604, disc_loss = 0.07501053090267089
Trained batch 436 in epoch 17, gen_loss = 0.401917884156142, disc_loss = 0.07487029079944578
Trained batch 437 in epoch 17, gen_loss = 0.40200968712704366, disc_loss = 0.0747355253129483
Trained batch 438 in epoch 17, gen_loss = 0.40229933211635077, disc_loss = 0.07473534676363025
Trained batch 439 in epoch 17, gen_loss = 0.4022569688883695, disc_loss = 0.07483535549307073
Trained batch 440 in epoch 17, gen_loss = 0.40231290209590714, disc_loss = 0.07487944150111235
Trained batch 441 in epoch 17, gen_loss = 0.40233616598321303, disc_loss = 0.0751335258781067
Trained batch 442 in epoch 17, gen_loss = 0.4025580676495356, disc_loss = 0.07544917520556103
Trained batch 443 in epoch 17, gen_loss = 0.40254998401747094, disc_loss = 0.07537612515115724
Trained batch 444 in epoch 17, gen_loss = 0.40262136024035766, disc_loss = 0.07525027364785417
Trained batch 445 in epoch 17, gen_loss = 0.4025477873236609, disc_loss = 0.07514693906463916
Trained batch 446 in epoch 17, gen_loss = 0.40260910941183703, disc_loss = 0.07533255167163792
Trained batch 447 in epoch 17, gen_loss = 0.402585889013218, disc_loss = 0.07541607687224834
Trained batch 448 in epoch 17, gen_loss = 0.40269674656120336, disc_loss = 0.07535664503460539
Trained batch 449 in epoch 17, gen_loss = 0.4028392017549939, disc_loss = 0.07527344034156866
Trained batch 450 in epoch 17, gen_loss = 0.40284580857949354, disc_loss = 0.07516294618461389
Trained batch 451 in epoch 17, gen_loss = 0.40279268822838776, disc_loss = 0.07503650940138748
Trained batch 452 in epoch 17, gen_loss = 0.40260987802846543, disc_loss = 0.07501694980482458
Trained batch 453 in epoch 17, gen_loss = 0.40264636908333734, disc_loss = 0.07501856222264633
Trained batch 454 in epoch 17, gen_loss = 0.4028259672306396, disc_loss = 0.07494135850446892
Trained batch 455 in epoch 17, gen_loss = 0.402885265648365, disc_loss = 0.07481054093876625
Trained batch 456 in epoch 17, gen_loss = 0.402847953711349, disc_loss = 0.07483339141565222
Trained batch 457 in epoch 17, gen_loss = 0.40288994471058576, disc_loss = 0.07490281993116549
Trained batch 458 in epoch 17, gen_loss = 0.4028420937866427, disc_loss = 0.07478129865159332
Trained batch 459 in epoch 17, gen_loss = 0.4030531397332316, disc_loss = 0.07478089602866575
Trained batch 460 in epoch 17, gen_loss = 0.4027327606191863, disc_loss = 0.07537282978885539
Testing Epoch 17
Training Epoch 18
Trained batch 0 in epoch 18, gen_loss = 0.5058091282844543, disc_loss = 0.030544649809598923
Trained batch 1 in epoch 18, gen_loss = 0.45224352180957794, disc_loss = 0.10979350470006466
Trained batch 2 in epoch 18, gen_loss = 0.4119750459988912, disc_loss = 0.1236363984644413
Trained batch 3 in epoch 18, gen_loss = 0.39071985334157944, disc_loss = 0.10354059841483831
Trained batch 4 in epoch 18, gen_loss = 0.4054692804813385, disc_loss = 0.08641304560005665
Trained batch 5 in epoch 18, gen_loss = 0.4141033540169398, disc_loss = 0.07774597872048616
Trained batch 6 in epoch 18, gen_loss = 0.4115326191697802, disc_loss = 0.08271389747304576
Trained batch 7 in epoch 18, gen_loss = 0.4187379591166973, disc_loss = 0.07549318065866828
Trained batch 8 in epoch 18, gen_loss = 0.4170893000231849, disc_loss = 0.07327821892168787
Trained batch 9 in epoch 18, gen_loss = 0.41056948602199556, disc_loss = 0.07295269705355167
Trained batch 10 in epoch 18, gen_loss = 0.4075244285843589, disc_loss = 0.07141622867096555
Trained batch 11 in epoch 18, gen_loss = 0.41103020558754605, disc_loss = 0.06980085155616204
Trained batch 12 in epoch 18, gen_loss = 0.41777827648016125, disc_loss = 0.06633634234850223
Trained batch 13 in epoch 18, gen_loss = 0.41813926824501585, disc_loss = 0.063056794660432
Trained batch 14 in epoch 18, gen_loss = 0.4151064952214559, disc_loss = 0.06860974232355753
Trained batch 15 in epoch 18, gen_loss = 0.4118231814354658, disc_loss = 0.06740924529731274
Trained batch 16 in epoch 18, gen_loss = 0.4085494928500232, disc_loss = 0.06875830888748169
Trained batch 17 in epoch 18, gen_loss = 0.40501881308025783, disc_loss = 0.06962954956624243
Trained batch 18 in epoch 18, gen_loss = 0.4084394103602359, disc_loss = 0.06675659708286587
Trained batch 19 in epoch 18, gen_loss = 0.4080574125051498, disc_loss = 0.06741463616490365
Trained batch 20 in epoch 18, gen_loss = 0.4078411701179686, disc_loss = 0.06739712400095803
Trained batch 21 in epoch 18, gen_loss = 0.4094844474033876, disc_loss = 0.06519301193342968
Trained batch 22 in epoch 18, gen_loss = 0.4097277716450069, disc_loss = 0.06609843760404897
Trained batch 23 in epoch 18, gen_loss = 0.40651626015702885, disc_loss = 0.06633563052552442
Trained batch 24 in epoch 18, gen_loss = 0.40702893495559694, disc_loss = 0.06530763410031795
Trained batch 25 in epoch 18, gen_loss = 0.40994520714649785, disc_loss = 0.06533144636509511
Trained batch 26 in epoch 18, gen_loss = 0.40478863208382215, disc_loss = 0.06975877719620864
Trained batch 27 in epoch 18, gen_loss = 0.40296521144253866, disc_loss = 0.06818082403125507
Trained batch 28 in epoch 18, gen_loss = 0.40864791335730716, disc_loss = 0.0677143788157866
Trained batch 29 in epoch 18, gen_loss = 0.4087691088517507, disc_loss = 0.0664196082080404
Trained batch 30 in epoch 18, gen_loss = 0.40894404918916766, disc_loss = 0.06527215608906362
Trained batch 31 in epoch 18, gen_loss = 0.4111214457079768, disc_loss = 0.06372260762145743
Trained batch 32 in epoch 18, gen_loss = 0.41458572311834857, disc_loss = 0.06256155489069043
Trained batch 33 in epoch 18, gen_loss = 0.41459716242902417, disc_loss = 0.06126960312180659
Trained batch 34 in epoch 18, gen_loss = 0.4154573082923889, disc_loss = 0.060387060578380315
Trained batch 35 in epoch 18, gen_loss = 0.4152182266116142, disc_loss = 0.05918181532373031
Trained batch 36 in epoch 18, gen_loss = 0.41578509275977676, disc_loss = 0.05831016338354832
Trained batch 37 in epoch 18, gen_loss = 0.41689594403693553, disc_loss = 0.05920373609191493
Trained batch 38 in epoch 18, gen_loss = 0.4153088858494392, disc_loss = 0.05976624939686213
Trained batch 39 in epoch 18, gen_loss = 0.4146624132990837, disc_loss = 0.058502615848556164
Trained batch 40 in epoch 18, gen_loss = 0.41729437141883663, disc_loss = 0.059580483859995516
Trained batch 41 in epoch 18, gen_loss = 0.4165500317301069, disc_loss = 0.05900831356467236
Trained batch 42 in epoch 18, gen_loss = 0.41504828042762226, disc_loss = 0.058220507447109666
Trained batch 43 in epoch 18, gen_loss = 0.41366549649021844, disc_loss = 0.05981041118502617
Trained batch 44 in epoch 18, gen_loss = 0.4130050705538856, disc_loss = 0.06153520411915249
Trained batch 45 in epoch 18, gen_loss = 0.4114391687123672, disc_loss = 0.062094159262335816
Trained batch 46 in epoch 18, gen_loss = 0.4099331130372717, disc_loss = 0.061877028739198724
Trained batch 47 in epoch 18, gen_loss = 0.4104599443574746, disc_loss = 0.06288692789773147
Trained batch 48 in epoch 18, gen_loss = 0.4109381048046813, disc_loss = 0.06359717219459768
Trained batch 49 in epoch 18, gen_loss = 0.41020906567573545, disc_loss = 0.06258921433240175
Trained batch 50 in epoch 18, gen_loss = 0.4108363950953764, disc_loss = 0.061897094818014725
Trained batch 51 in epoch 18, gen_loss = 0.4100157314768204, disc_loss = 0.061472446048775546
Trained batch 52 in epoch 18, gen_loss = 0.41015663743019104, disc_loss = 0.06097019193166832
Trained batch 53 in epoch 18, gen_loss = 0.4104536065348872, disc_loss = 0.06084845211632826
Trained batch 54 in epoch 18, gen_loss = 0.41020260453224183, disc_loss = 0.06003774733028629
Trained batch 55 in epoch 18, gen_loss = 0.41006682174546377, disc_loss = 0.05960533937572369
Trained batch 56 in epoch 18, gen_loss = 0.4089526309255968, disc_loss = 0.05960512164522681
Trained batch 57 in epoch 18, gen_loss = 0.41034157060343646, disc_loss = 0.059166203509887744
Trained batch 58 in epoch 18, gen_loss = 0.4102563469086663, disc_loss = 0.058514889077109805
Trained batch 59 in epoch 18, gen_loss = 0.41029407183329264, disc_loss = 0.05802212320268154
Trained batch 60 in epoch 18, gen_loss = 0.40993717312812805, disc_loss = 0.058708103831674234
Trained batch 61 in epoch 18, gen_loss = 0.4111217837179861, disc_loss = 0.05833664668663856
Trained batch 62 in epoch 18, gen_loss = 0.41077398875403026, disc_loss = 0.05836751134622665
Trained batch 63 in epoch 18, gen_loss = 0.41038200818002224, disc_loss = 0.05918189324438572
Trained batch 64 in epoch 18, gen_loss = 0.4102186835729159, disc_loss = 0.059589095413684845
Trained batch 65 in epoch 18, gen_loss = 0.409366074385065, disc_loss = 0.05924096257623398
Trained batch 66 in epoch 18, gen_loss = 0.4091837557394113, disc_loss = 0.05952573806714656
Trained batch 67 in epoch 18, gen_loss = 0.40961873180725994, disc_loss = 0.05926139943082543
Trained batch 68 in epoch 18, gen_loss = 0.40822740352672077, disc_loss = 0.05871771205810533
Trained batch 69 in epoch 18, gen_loss = 0.4085436659199851, disc_loss = 0.05825041069516114
Trained batch 70 in epoch 18, gen_loss = 0.4075522523530772, disc_loss = 0.05902858020764001
Trained batch 71 in epoch 18, gen_loss = 0.4089871355228954, disc_loss = 0.060596134358396135
Trained batch 72 in epoch 18, gen_loss = 0.4099220217090763, disc_loss = 0.05993357959063086
Trained batch 73 in epoch 18, gen_loss = 0.40922850612047557, disc_loss = 0.059445236633355554
Trained batch 74 in epoch 18, gen_loss = 0.40801343123118083, disc_loss = 0.060142874568700794
Trained batch 75 in epoch 18, gen_loss = 0.4098909175709674, disc_loss = 0.060095928364286295
Trained batch 76 in epoch 18, gen_loss = 0.4094156870594272, disc_loss = 0.06014777124895678
Trained batch 77 in epoch 18, gen_loss = 0.4083265226620894, disc_loss = 0.05986647331752838
Trained batch 78 in epoch 18, gen_loss = 0.40780898664571064, disc_loss = 0.05948289471996736
Trained batch 79 in epoch 18, gen_loss = 0.40762848891317843, disc_loss = 0.05892135020112619
Trained batch 80 in epoch 18, gen_loss = 0.40757867105213214, disc_loss = 0.05881839796302863
Trained batch 81 in epoch 18, gen_loss = 0.4079934762018483, disc_loss = 0.05887920026690131
Trained batch 82 in epoch 18, gen_loss = 0.40682447997920484, disc_loss = 0.058640078372176156
Trained batch 83 in epoch 18, gen_loss = 0.40783423788490747, disc_loss = 0.05856267570163168
Trained batch 84 in epoch 18, gen_loss = 0.4069977269453161, disc_loss = 0.0581051986774101
Trained batch 85 in epoch 18, gen_loss = 0.4072774797677994, disc_loss = 0.0593644667221883
Trained batch 86 in epoch 18, gen_loss = 0.407605704219862, disc_loss = 0.060677519549840485
Trained batch 87 in epoch 18, gen_loss = 0.40786061537536705, disc_loss = 0.06010321461045268
Trained batch 88 in epoch 18, gen_loss = 0.40825861658942836, disc_loss = 0.06011847771829768
Trained batch 89 in epoch 18, gen_loss = 0.4080912732415729, disc_loss = 0.05999449033083187
Trained batch 90 in epoch 18, gen_loss = 0.4088791379561791, disc_loss = 0.05954933099980865
Trained batch 91 in epoch 18, gen_loss = 0.4084407674229663, disc_loss = 0.05916910963740362
Trained batch 92 in epoch 18, gen_loss = 0.40862702842681636, disc_loss = 0.05910002100732057
Trained batch 93 in epoch 18, gen_loss = 0.407680887491145, disc_loss = 0.06026417719438038
Trained batch 94 in epoch 18, gen_loss = 0.40732778248034024, disc_loss = 0.06048126962820166
Trained batch 95 in epoch 18, gen_loss = 0.4071621758242448, disc_loss = 0.06060656778087529
Trained batch 96 in epoch 18, gen_loss = 0.40606681710665987, disc_loss = 0.06061164125531297
Trained batch 97 in epoch 18, gen_loss = 0.40482860408267196, disc_loss = 0.060396526778610994
Trained batch 98 in epoch 18, gen_loss = 0.40537489574364943, disc_loss = 0.060080990392827625
Trained batch 99 in epoch 18, gen_loss = 0.4048673665523529, disc_loss = 0.0596899929177016
Trained batch 100 in epoch 18, gen_loss = 0.4044222043882502, disc_loss = 0.059578605392708046
Trained batch 101 in epoch 18, gen_loss = 0.4049752228984646, disc_loss = 0.05938405345431438
Trained batch 102 in epoch 18, gen_loss = 0.4045097500953859, disc_loss = 0.05949915206801255
Trained batch 103 in epoch 18, gen_loss = 0.4046523871903236, disc_loss = 0.059092033752956644
Trained batch 104 in epoch 18, gen_loss = 0.40428663350286936, disc_loss = 0.059211050213447636
Trained batch 105 in epoch 18, gen_loss = 0.4046459046174895, disc_loss = 0.05972327315687852
Trained batch 106 in epoch 18, gen_loss = 0.40381895103187204, disc_loss = 0.05968032825181139
Trained batch 107 in epoch 18, gen_loss = 0.40386573749559895, disc_loss = 0.059431009675824535
Trained batch 108 in epoch 18, gen_loss = 0.40491560128850673, disc_loss = 0.059072081845492945
Trained batch 109 in epoch 18, gen_loss = 0.4052676168355075, disc_loss = 0.05880884530700066
Trained batch 110 in epoch 18, gen_loss = 0.4049401030884133, disc_loss = 0.05880010677585462
Trained batch 111 in epoch 18, gen_loss = 0.40565373801759314, disc_loss = 0.05838766913594944
Trained batch 112 in epoch 18, gen_loss = 0.4062216500792883, disc_loss = 0.05806681311038216
Trained batch 113 in epoch 18, gen_loss = 0.4058113749089994, disc_loss = 0.05802349244620193
Trained batch 114 in epoch 18, gen_loss = 0.4062237604804661, disc_loss = 0.05840348797323911
Trained batch 115 in epoch 18, gen_loss = 0.40625997581358614, disc_loss = 0.05811966042002213
Trained batch 116 in epoch 18, gen_loss = 0.4056218159504426, disc_loss = 0.05855418370766008
Trained batch 117 in epoch 18, gen_loss = 0.405809219105769, disc_loss = 0.05924220810944246
Trained batch 118 in epoch 18, gen_loss = 0.4057680899355592, disc_loss = 0.05885444244197687
Trained batch 119 in epoch 18, gen_loss = 0.4049577790002028, disc_loss = 0.0603863356091703
Trained batch 120 in epoch 18, gen_loss = 0.4051804653376587, disc_loss = 0.060272101474510245
Trained batch 121 in epoch 18, gen_loss = 0.40567936980333485, disc_loss = 0.06077497819682858
Trained batch 122 in epoch 18, gen_loss = 0.40512708023311644, disc_loss = 0.06054025204715932
Trained batch 123 in epoch 18, gen_loss = 0.4043607719002231, disc_loss = 0.06056764536356974
Trained batch 124 in epoch 18, gen_loss = 0.40431758666038514, disc_loss = 0.06018388193845749
Trained batch 125 in epoch 18, gen_loss = 0.40446295009719, disc_loss = 0.06045264969505961
Trained batch 126 in epoch 18, gen_loss = 0.4041735213103257, disc_loss = 0.06028730325459495
Trained batch 127 in epoch 18, gen_loss = 0.4041303703561425, disc_loss = 0.060300102893961594
Trained batch 128 in epoch 18, gen_loss = 0.4044867144074551, disc_loss = 0.0599405239588877
Trained batch 129 in epoch 18, gen_loss = 0.4042969226837158, disc_loss = 0.06064060498745395
Trained batch 130 in epoch 18, gen_loss = 0.40310296780280486, disc_loss = 0.06079888522255284
Trained batch 131 in epoch 18, gen_loss = 0.4030558823636084, disc_loss = 0.060489311779030795
Trained batch 132 in epoch 18, gen_loss = 0.40285721936620267, disc_loss = 0.060236456369827114
Trained batch 133 in epoch 18, gen_loss = 0.4029828390078758, disc_loss = 0.05989213242654258
Trained batch 134 in epoch 18, gen_loss = 0.4029173221853044, disc_loss = 0.059615017521988466
Trained batch 135 in epoch 18, gen_loss = 0.4035167661221588, disc_loss = 0.059594390660469586
Trained batch 136 in epoch 18, gen_loss = 0.40338047751545036, disc_loss = 0.05975257155968108
Trained batch 137 in epoch 18, gen_loss = 0.40391359553820844, disc_loss = 0.05948460708790715
Trained batch 138 in epoch 18, gen_loss = 0.4040081140806349, disc_loss = 0.059325661021117256
Trained batch 139 in epoch 18, gen_loss = 0.4036595866084099, disc_loss = 0.05977718007218625
Trained batch 140 in epoch 18, gen_loss = 0.403497984434696, disc_loss = 0.062354221695650976
Trained batch 141 in epoch 18, gen_loss = 0.4038059138496157, disc_loss = 0.06211922907362312
Trained batch 142 in epoch 18, gen_loss = 0.4046865774618162, disc_loss = 0.06230270770749637
Trained batch 143 in epoch 18, gen_loss = 0.40411920597155887, disc_loss = 0.06265882358032589
Trained batch 144 in epoch 18, gen_loss = 0.4035164378840348, disc_loss = 0.06320455841848563
Trained batch 145 in epoch 18, gen_loss = 0.4037030631140487, disc_loss = 0.06303429322266212
Trained batch 146 in epoch 18, gen_loss = 0.40427264206263486, disc_loss = 0.06304534787603584
Trained batch 147 in epoch 18, gen_loss = 0.4038753066513989, disc_loss = 0.06287695630453527
Trained batch 148 in epoch 18, gen_loss = 0.4036414669264083, disc_loss = 0.06287590656179509
Trained batch 149 in epoch 18, gen_loss = 0.4042287455002467, disc_loss = 0.06264035031820336
Trained batch 150 in epoch 18, gen_loss = 0.4047221069699092, disc_loss = 0.06266000063238752
Trained batch 151 in epoch 18, gen_loss = 0.40464603998943377, disc_loss = 0.06252898793594029
Trained batch 152 in epoch 18, gen_loss = 0.40438302065811904, disc_loss = 0.06270264588856424
Trained batch 153 in epoch 18, gen_loss = 0.4044428624503024, disc_loss = 0.06269570271327317
Trained batch 154 in epoch 18, gen_loss = 0.4041924991915303, disc_loss = 0.06254987782167812
Trained batch 155 in epoch 18, gen_loss = 0.40432518548690355, disc_loss = 0.062251302383792326
Trained batch 156 in epoch 18, gen_loss = 0.40386600042604337, disc_loss = 0.06197489500876255
Trained batch 157 in epoch 18, gen_loss = 0.4040675598986541, disc_loss = 0.06178725578621784
Trained batch 158 in epoch 18, gen_loss = 0.4040245861752228, disc_loss = 0.06161553946282691
Trained batch 159 in epoch 18, gen_loss = 0.40373452585190533, disc_loss = 0.061530903534730896
Trained batch 160 in epoch 18, gen_loss = 0.4036719066015682, disc_loss = 0.06130425700836856
Trained batch 161 in epoch 18, gen_loss = 0.4038460574768208, disc_loss = 0.06104591007654866
Trained batch 162 in epoch 18, gen_loss = 0.4037707184721356, disc_loss = 0.06073635939988622
Trained batch 163 in epoch 18, gen_loss = 0.4038998798989668, disc_loss = 0.06046552906130872
Trained batch 164 in epoch 18, gen_loss = 0.4034054837443612, disc_loss = 0.06037505492568016
Trained batch 165 in epoch 18, gen_loss = 0.4035017743527171, disc_loss = 0.06023573047335608
Trained batch 166 in epoch 18, gen_loss = 0.4029975492440298, disc_loss = 0.06055622782089753
Trained batch 167 in epoch 18, gen_loss = 0.4027675115281627, disc_loss = 0.06091888344270133
Trained batch 168 in epoch 18, gen_loss = 0.40267244915990436, disc_loss = 0.06077328758567748
Trained batch 169 in epoch 18, gen_loss = 0.4029025459990782, disc_loss = 0.06066250038497588
Trained batch 170 in epoch 18, gen_loss = 0.40259330122791537, disc_loss = 0.06073271931960569
Trained batch 171 in epoch 18, gen_loss = 0.40285908915968827, disc_loss = 0.06143040296643279
Trained batch 172 in epoch 18, gen_loss = 0.40235611382936465, disc_loss = 0.06257495077359194
Trained batch 173 in epoch 18, gen_loss = 0.40304607444110957, disc_loss = 0.06243618821789478
Trained batch 174 in epoch 18, gen_loss = 0.40326239160129, disc_loss = 0.06235200639281954
Trained batch 175 in epoch 18, gen_loss = 0.4030624260617928, disc_loss = 0.06227374186908657
Trained batch 176 in epoch 18, gen_loss = 0.40298650325354884, disc_loss = 0.06230225990721061
Trained batch 177 in epoch 18, gen_loss = 0.40317216515541077, disc_loss = 0.06221890395109573
Trained batch 178 in epoch 18, gen_loss = 0.4028089201317153, disc_loss = 0.06235036886604139
Trained batch 179 in epoch 18, gen_loss = 0.4029556233021948, disc_loss = 0.06342554423544142
Trained batch 180 in epoch 18, gen_loss = 0.4024463001206435, disc_loss = 0.06373376531001612
Trained batch 181 in epoch 18, gen_loss = 0.4022708615431419, disc_loss = 0.06353494033708677
Trained batch 182 in epoch 18, gen_loss = 0.4022387202645912, disc_loss = 0.06345459049353834
Trained batch 183 in epoch 18, gen_loss = 0.40204455071817274, disc_loss = 0.06336781961600417
Trained batch 184 in epoch 18, gen_loss = 0.402325018515458, disc_loss = 0.06318626685722455
Trained batch 185 in epoch 18, gen_loss = 0.4026524403723337, disc_loss = 0.06305625393826475
Trained batch 186 in epoch 18, gen_loss = 0.40259083595505374, disc_loss = 0.06306764061119467
Trained batch 187 in epoch 18, gen_loss = 0.40239298359510745, disc_loss = 0.06287895089530564
Trained batch 188 in epoch 18, gen_loss = 0.40276884591137924, disc_loss = 0.06295260193723219
Trained batch 189 in epoch 18, gen_loss = 0.4025594883843472, disc_loss = 0.06346176100012503
Trained batch 190 in epoch 18, gen_loss = 0.4027881291524278, disc_loss = 0.06396730070572873
Trained batch 191 in epoch 18, gen_loss = 0.40274907508865, disc_loss = 0.06434130100145315
Trained batch 192 in epoch 18, gen_loss = 0.4025934509971599, disc_loss = 0.06482664899118824
Trained batch 193 in epoch 18, gen_loss = 0.4029665801328482, disc_loss = 0.06466904779915343
Trained batch 194 in epoch 18, gen_loss = 0.40302204336875525, disc_loss = 0.06483609494872582
Trained batch 195 in epoch 18, gen_loss = 0.4036707231888966, disc_loss = 0.06570178850040752
Trained batch 196 in epoch 18, gen_loss = 0.4033348566384485, disc_loss = 0.06562753613603296
Trained batch 197 in epoch 18, gen_loss = 0.40285392797956565, disc_loss = 0.0656738927531423
Trained batch 198 in epoch 18, gen_loss = 0.40305916807759345, disc_loss = 0.0656850239701906
Trained batch 199 in epoch 18, gen_loss = 0.4028004704415798, disc_loss = 0.06557931406423449
Trained batch 200 in epoch 18, gen_loss = 0.4025673262812012, disc_loss = 0.06539282782828036
Trained batch 201 in epoch 18, gen_loss = 0.4023380987715013, disc_loss = 0.06580922348738306
Trained batch 202 in epoch 18, gen_loss = 0.4023890098914724, disc_loss = 0.06613940083114385
Trained batch 203 in epoch 18, gen_loss = 0.4024934477958025, disc_loss = 0.06608870565233861
Trained batch 204 in epoch 18, gen_loss = 0.4020989609927666, disc_loss = 0.06636498884820356
Trained batch 205 in epoch 18, gen_loss = 0.40235734087170905, disc_loss = 0.0662174506962878
Trained batch 206 in epoch 18, gen_loss = 0.40227318976236426, disc_loss = 0.06612159074216649
Trained batch 207 in epoch 18, gen_loss = 0.40200508973346305, disc_loss = 0.06617720973176452
Trained batch 208 in epoch 18, gen_loss = 0.401948320951188, disc_loss = 0.06606026724622581
Trained batch 209 in epoch 18, gen_loss = 0.4017418737922396, disc_loss = 0.06589936151036195
Trained batch 210 in epoch 18, gen_loss = 0.40146169800893955, disc_loss = 0.06582340592809763
Trained batch 211 in epoch 18, gen_loss = 0.40111035291316377, disc_loss = 0.06592392417127793
Trained batch 212 in epoch 18, gen_loss = 0.40092980204053885, disc_loss = 0.06587484522674565
Trained batch 213 in epoch 18, gen_loss = 0.4010070793539564, disc_loss = 0.0657992364890943
Trained batch 214 in epoch 18, gen_loss = 0.4007048336572425, disc_loss = 0.06572941079042678
Trained batch 215 in epoch 18, gen_loss = 0.4008749985584506, disc_loss = 0.06558083341008535
Trained batch 216 in epoch 18, gen_loss = 0.4009863661456218, disc_loss = 0.065463090049369
Trained batch 217 in epoch 18, gen_loss = 0.40108419790727284, disc_loss = 0.0652765542901027
Trained batch 218 in epoch 18, gen_loss = 0.4011219425560677, disc_loss = 0.06577548637271743
Trained batch 219 in epoch 18, gen_loss = 0.4008405447006226, disc_loss = 0.06651709060269323
Trained batch 220 in epoch 18, gen_loss = 0.4008707557868095, disc_loss = 0.06647288594479205
Trained batch 221 in epoch 18, gen_loss = 0.40118913258518185, disc_loss = 0.06705487577395665
Trained batch 222 in epoch 18, gen_loss = 0.4015443727307256, disc_loss = 0.06693644568557963
Trained batch 223 in epoch 18, gen_loss = 0.40163830095635994, disc_loss = 0.06703224446391687
Trained batch 224 in epoch 18, gen_loss = 0.4016052700413598, disc_loss = 0.06695554182761246
Trained batch 225 in epoch 18, gen_loss = 0.40175841827835657, disc_loss = 0.066946487700715
Trained batch 226 in epoch 18, gen_loss = 0.4017896327940903, disc_loss = 0.0672533783142656
Trained batch 227 in epoch 18, gen_loss = 0.4016068878403881, disc_loss = 0.06711934035513223
Trained batch 228 in epoch 18, gen_loss = 0.40177005997911813, disc_loss = 0.06736465051412321
Trained batch 229 in epoch 18, gen_loss = 0.40156996016917024, disc_loss = 0.0675445385520225
Trained batch 230 in epoch 18, gen_loss = 0.40173765462198296, disc_loss = 0.06736685147758945
Trained batch 231 in epoch 18, gen_loss = 0.40190579151285105, disc_loss = 0.06718875320853088
Trained batch 232 in epoch 18, gen_loss = 0.4017985355700546, disc_loss = 0.06709519125393276
Trained batch 233 in epoch 18, gen_loss = 0.4018427358988004, disc_loss = 0.06692795059842686
Trained batch 234 in epoch 18, gen_loss = 0.4019193111582005, disc_loss = 0.0670272328038799
Trained batch 235 in epoch 18, gen_loss = 0.4013937186386626, disc_loss = 0.06756280368130843
Trained batch 236 in epoch 18, gen_loss = 0.40151662087138695, disc_loss = 0.067637642562578
Trained batch 237 in epoch 18, gen_loss = 0.4017120125163503, disc_loss = 0.06746674684353736
Trained batch 238 in epoch 18, gen_loss = 0.4013888113917666, disc_loss = 0.06735042209842215
Trained batch 239 in epoch 18, gen_loss = 0.4012028137842814, disc_loss = 0.06733152200467885
Trained batch 240 in epoch 18, gen_loss = 0.40157383395923124, disc_loss = 0.06776356479129851
Trained batch 241 in epoch 18, gen_loss = 0.4014981837312052, disc_loss = 0.06774835447080371
Trained batch 242 in epoch 18, gen_loss = 0.40159923157083643, disc_loss = 0.06771410613822838
Trained batch 243 in epoch 18, gen_loss = 0.4016414296920182, disc_loss = 0.06831653952048938
Trained batch 244 in epoch 18, gen_loss = 0.40180777724908323, disc_loss = 0.06818738944676457
Trained batch 245 in epoch 18, gen_loss = 0.4015506491428468, disc_loss = 0.06823787644384353
Trained batch 246 in epoch 18, gen_loss = 0.40158305525297094, disc_loss = 0.06814004078145453
Trained batch 247 in epoch 18, gen_loss = 0.4014983167571406, disc_loss = 0.067970868688257
Trained batch 248 in epoch 18, gen_loss = 0.4013519820918041, disc_loss = 0.06785521818601702
Trained batch 249 in epoch 18, gen_loss = 0.40166321098804475, disc_loss = 0.0676638498827815
Trained batch 250 in epoch 18, gen_loss = 0.4017060865681485, disc_loss = 0.06765672424251577
Trained batch 251 in epoch 18, gen_loss = 0.4017259765948568, disc_loss = 0.06776189262283937
Trained batch 252 in epoch 18, gen_loss = 0.4018227849082042, disc_loss = 0.06753968197498986
Trained batch 253 in epoch 18, gen_loss = 0.40170350870278876, disc_loss = 0.06731604028302501
Trained batch 254 in epoch 18, gen_loss = 0.40190062324206033, disc_loss = 0.06715400409245607
Trained batch 255 in epoch 18, gen_loss = 0.40201280650217086, disc_loss = 0.067021029364696
Trained batch 256 in epoch 18, gen_loss = 0.4017699007162324, disc_loss = 0.06729756986019328
Trained batch 257 in epoch 18, gen_loss = 0.40220832304899085, disc_loss = 0.06840125073195082
Trained batch 258 in epoch 18, gen_loss = 0.40185139181531077, disc_loss = 0.06830524886566354
Trained batch 259 in epoch 18, gen_loss = 0.4018178598238872, disc_loss = 0.06837321202127407
Trained batch 260 in epoch 18, gen_loss = 0.40181781528553284, disc_loss = 0.06834981168381213
Trained batch 261 in epoch 18, gen_loss = 0.4016309780928925, disc_loss = 0.06821219893598943
Trained batch 262 in epoch 18, gen_loss = 0.40156855997930463, disc_loss = 0.06823531396956158
Trained batch 263 in epoch 18, gen_loss = 0.40173784936919354, disc_loss = 0.06808937476087136
Trained batch 264 in epoch 18, gen_loss = 0.40181010545424695, disc_loss = 0.06793208421330969
Trained batch 265 in epoch 18, gen_loss = 0.40204572083806633, disc_loss = 0.06786257890928396
Trained batch 266 in epoch 18, gen_loss = 0.40168267042002875, disc_loss = 0.0677282034841537
Trained batch 267 in epoch 18, gen_loss = 0.40173407543951006, disc_loss = 0.06795205696791744
Trained batch 268 in epoch 18, gen_loss = 0.40194690404771427, disc_loss = 0.06817386721409718
Trained batch 269 in epoch 18, gen_loss = 0.4020893627846682, disc_loss = 0.06813736800449315
Trained batch 270 in epoch 18, gen_loss = 0.4022877082173675, disc_loss = 0.06821358747904041
Trained batch 271 in epoch 18, gen_loss = 0.4021494743578574, disc_loss = 0.06806479073608951
Trained batch 272 in epoch 18, gen_loss = 0.40212303007042016, disc_loss = 0.0678802774877939
Trained batch 273 in epoch 18, gen_loss = 0.4024117438897599, disc_loss = 0.06772451689058956
Trained batch 274 in epoch 18, gen_loss = 0.40226292740214953, disc_loss = 0.06759875450960615
Trained batch 275 in epoch 18, gen_loss = 0.4022093490845915, disc_loss = 0.06745163753858187
Trained batch 276 in epoch 18, gen_loss = 0.4022634308045522, disc_loss = 0.06729637371167702
Trained batch 277 in epoch 18, gen_loss = 0.4024932603184268, disc_loss = 0.06749229679527365
Trained batch 278 in epoch 18, gen_loss = 0.4021004209808979, disc_loss = 0.06760707235557951
Trained batch 279 in epoch 18, gen_loss = 0.4020398714712688, disc_loss = 0.06760897255569165
Trained batch 280 in epoch 18, gen_loss = 0.4023164763145175, disc_loss = 0.06806460788864577
Trained batch 281 in epoch 18, gen_loss = 0.40229789468836274, disc_loss = 0.06805462566871487
Trained batch 282 in epoch 18, gen_loss = 0.4022534988794226, disc_loss = 0.0680524076799148
Trained batch 283 in epoch 18, gen_loss = 0.4020745963068076, disc_loss = 0.06798414187833772
Trained batch 284 in epoch 18, gen_loss = 0.40177516665375024, disc_loss = 0.06793677400013334
Trained batch 285 in epoch 18, gen_loss = 0.4019479886009977, disc_loss = 0.06774281992713783
Trained batch 286 in epoch 18, gen_loss = 0.4019087310036716, disc_loss = 0.06767652131526208
Trained batch 287 in epoch 18, gen_loss = 0.4017413936348425, disc_loss = 0.06766727757834208
Trained batch 288 in epoch 18, gen_loss = 0.40194273974656236, disc_loss = 0.06751906321058533
Trained batch 289 in epoch 18, gen_loss = 0.40183203168984116, disc_loss = 0.06744285745803139
Trained batch 290 in epoch 18, gen_loss = 0.40177141688124013, disc_loss = 0.06728308872860629
Trained batch 291 in epoch 18, gen_loss = 0.4016861314438794, disc_loss = 0.06743707946399609
Trained batch 292 in epoch 18, gen_loss = 0.4014498368668475, disc_loss = 0.06786060846591871
Trained batch 293 in epoch 18, gen_loss = 0.40146216881923935, disc_loss = 0.06779264222488415
Trained batch 294 in epoch 18, gen_loss = 0.40141741795054936, disc_loss = 0.06760094869187323
Trained batch 295 in epoch 18, gen_loss = 0.4013847107621464, disc_loss = 0.06741271139676305
Trained batch 296 in epoch 18, gen_loss = 0.40118628369035947, disc_loss = 0.06737080213272009
Trained batch 297 in epoch 18, gen_loss = 0.4008639731863201, disc_loss = 0.06728027362826487
Trained batch 298 in epoch 18, gen_loss = 0.40065731631473556, disc_loss = 0.06717463313013215
Trained batch 299 in epoch 18, gen_loss = 0.40073349157969157, disc_loss = 0.06714320857698719
Trained batch 300 in epoch 18, gen_loss = 0.401043726360283, disc_loss = 0.06715371981386925
Trained batch 301 in epoch 18, gen_loss = 0.4013512415799084, disc_loss = 0.06700253340458831
Trained batch 302 in epoch 18, gen_loss = 0.4012524137402525, disc_loss = 0.06687917626730286
Trained batch 303 in epoch 18, gen_loss = 0.4010905266592377, disc_loss = 0.06671762082872815
Trained batch 304 in epoch 18, gen_loss = 0.4011726502512322, disc_loss = 0.06656728418635541
Trained batch 305 in epoch 18, gen_loss = 0.4010937361935385, disc_loss = 0.06650615673439175
Trained batch 306 in epoch 18, gen_loss = 0.4009893874392059, disc_loss = 0.06638427837129914
Trained batch 307 in epoch 18, gen_loss = 0.40081789276816626, disc_loss = 0.06622641162293685
Trained batch 308 in epoch 18, gen_loss = 0.40102164509998556, disc_loss = 0.06604703384056736
Trained batch 309 in epoch 18, gen_loss = 0.4014275010555021, disc_loss = 0.06602663206417234
Trained batch 310 in epoch 18, gen_loss = 0.40142914767817284, disc_loss = 0.06637840572792522
Trained batch 311 in epoch 18, gen_loss = 0.4015226378463782, disc_loss = 0.06644675079195832
Trained batch 312 in epoch 18, gen_loss = 0.40153682469940793, disc_loss = 0.06634534075082586
Trained batch 313 in epoch 18, gen_loss = 0.4016759922360159, disc_loss = 0.06621837810832698
Trained batch 314 in epoch 18, gen_loss = 0.4016581953517974, disc_loss = 0.06611458330696064
Trained batch 315 in epoch 18, gen_loss = 0.40167503926572923, disc_loss = 0.06601723147072841
Trained batch 316 in epoch 18, gen_loss = 0.40164737708937104, disc_loss = 0.06589886527038429
Trained batch 317 in epoch 18, gen_loss = 0.40130754883559244, disc_loss = 0.0660144014711603
Trained batch 318 in epoch 18, gen_loss = 0.4014106689015152, disc_loss = 0.06595300945824123
Trained batch 319 in epoch 18, gen_loss = 0.4011742199771106, disc_loss = 0.0658444673725171
Trained batch 320 in epoch 18, gen_loss = 0.401379709024667, disc_loss = 0.06568458304679561
Trained batch 321 in epoch 18, gen_loss = 0.4014827828414692, disc_loss = 0.065548461517724
Trained batch 322 in epoch 18, gen_loss = 0.40162054082557513, disc_loss = 0.06549952870909552
Trained batch 323 in epoch 18, gen_loss = 0.4014565771744575, disc_loss = 0.06554409665814429
Trained batch 324 in epoch 18, gen_loss = 0.4014306609447186, disc_loss = 0.06568590918126015
Trained batch 325 in epoch 18, gen_loss = 0.4012841893120046, disc_loss = 0.06574489235409472
Trained batch 326 in epoch 18, gen_loss = 0.40140776304294573, disc_loss = 0.06584953824029695
Trained batch 327 in epoch 18, gen_loss = 0.4014074587967338, disc_loss = 0.06584257112032302
Trained batch 328 in epoch 18, gen_loss = 0.401680945444252, disc_loss = 0.0657450615380265
Trained batch 329 in epoch 18, gen_loss = 0.40152730562470174, disc_loss = 0.0656339321370152
Trained batch 330 in epoch 18, gen_loss = 0.40154625641975517, disc_loss = 0.06553486662317529
Trained batch 331 in epoch 18, gen_loss = 0.40140928624265165, disc_loss = 0.06542087151915822
Trained batch 332 in epoch 18, gen_loss = 0.4013613250341501, disc_loss = 0.06535991391743178
Trained batch 333 in epoch 18, gen_loss = 0.40132815207906825, disc_loss = 0.06521012367189911
Trained batch 334 in epoch 18, gen_loss = 0.4016173568234515, disc_loss = 0.06528935973713203
Trained batch 335 in epoch 18, gen_loss = 0.40174364183275474, disc_loss = 0.06530730557971678
Trained batch 336 in epoch 18, gen_loss = 0.40180146260855815, disc_loss = 0.06526255302230664
Trained batch 337 in epoch 18, gen_loss = 0.40191091403100615, disc_loss = 0.06516952978821813
Trained batch 338 in epoch 18, gen_loss = 0.4018970428139059, disc_loss = 0.06504800612145381
Trained batch 339 in epoch 18, gen_loss = 0.4016885155264069, disc_loss = 0.06502323931576136
Trained batch 340 in epoch 18, gen_loss = 0.4016234625644348, disc_loss = 0.0648945221360609
Trained batch 341 in epoch 18, gen_loss = 0.40182252942818647, disc_loss = 0.06484403787725414
Trained batch 342 in epoch 18, gen_loss = 0.4017341852014336, disc_loss = 0.06483691587294764
Trained batch 343 in epoch 18, gen_loss = 0.40183855454589046, disc_loss = 0.06467821906039188
Trained batch 344 in epoch 18, gen_loss = 0.40171946710434514, disc_loss = 0.06461599324492441
Trained batch 345 in epoch 18, gen_loss = 0.4018086995175808, disc_loss = 0.06451214686832848
Trained batch 346 in epoch 18, gen_loss = 0.4016433824551552, disc_loss = 0.06460871459964544
Trained batch 347 in epoch 18, gen_loss = 0.40184273091198386, disc_loss = 0.06516767310877812
Trained batch 348 in epoch 18, gen_loss = 0.40176809619695886, disc_loss = 0.06512606570385077
Trained batch 349 in epoch 18, gen_loss = 0.40153332335608344, disc_loss = 0.06529011091483491
Trained batch 350 in epoch 18, gen_loss = 0.4015235299738044, disc_loss = 0.06516157678113534
Trained batch 351 in epoch 18, gen_loss = 0.40152539837766776, disc_loss = 0.06566453735153614
Trained batch 352 in epoch 18, gen_loss = 0.4013417605468977, disc_loss = 0.0655980086476455
Trained batch 353 in epoch 18, gen_loss = 0.4012997031716977, disc_loss = 0.06561432670970253
Trained batch 354 in epoch 18, gen_loss = 0.40122004697020625, disc_loss = 0.06551263305083127
Trained batch 355 in epoch 18, gen_loss = 0.4014105619339461, disc_loss = 0.06550316202841448
Trained batch 356 in epoch 18, gen_loss = 0.40140116398407966, disc_loss = 0.0654426421187505
Trained batch 357 in epoch 18, gen_loss = 0.4014017746768184, disc_loss = 0.06560126916822774
Trained batch 358 in epoch 18, gen_loss = 0.4013944147024978, disc_loss = 0.06552463062211332
Trained batch 359 in epoch 18, gen_loss = 0.40159973742233385, disc_loss = 0.06557511941840251
Trained batch 360 in epoch 18, gen_loss = 0.40140083927527026, disc_loss = 0.0656053390240405
Trained batch 361 in epoch 18, gen_loss = 0.40141185097272886, disc_loss = 0.06563118653814437
Trained batch 362 in epoch 18, gen_loss = 0.40131381022700263, disc_loss = 0.0655868582776427
Trained batch 363 in epoch 18, gen_loss = 0.4012776949739718, disc_loss = 0.06546257508427396
Trained batch 364 in epoch 18, gen_loss = 0.4013274405917076, disc_loss = 0.06538302199787473
Trained batch 365 in epoch 18, gen_loss = 0.40132202541893297, disc_loss = 0.06527757762213711
Trained batch 366 in epoch 18, gen_loss = 0.40133641306970685, disc_loss = 0.06525226147992572
Trained batch 367 in epoch 18, gen_loss = 0.40129728445216367, disc_loss = 0.06512262770379691
Trained batch 368 in epoch 18, gen_loss = 0.40126605384395053, disc_loss = 0.06502100276107065
Trained batch 369 in epoch 18, gen_loss = 0.40123263686089905, disc_loss = 0.06500630432085411
Trained batch 370 in epoch 18, gen_loss = 0.40129858191122586, disc_loss = 0.06495909587633256
Trained batch 371 in epoch 18, gen_loss = 0.40156476536104757, disc_loss = 0.0648281689012243
Trained batch 372 in epoch 18, gen_loss = 0.4013937790815696, disc_loss = 0.06475590190403263
Trained batch 373 in epoch 18, gen_loss = 0.401532547677902, disc_loss = 0.0648827707683817
Trained batch 374 in epoch 18, gen_loss = 0.40136981844902037, disc_loss = 0.0649627147614956
Trained batch 375 in epoch 18, gen_loss = 0.40126897656220073, disc_loss = 0.06489022610154241
Trained batch 376 in epoch 18, gen_loss = 0.4011938473115865, disc_loss = 0.0649867157701314
Trained batch 377 in epoch 18, gen_loss = 0.4012398461973856, disc_loss = 0.06498636781341499
Trained batch 378 in epoch 18, gen_loss = 0.40145669724192656, disc_loss = 0.06486038695087061
Trained batch 379 in epoch 18, gen_loss = 0.4016238701186682, disc_loss = 0.06495769722387194
Trained batch 380 in epoch 18, gen_loss = 0.40181926643754556, disc_loss = 0.0649938586160658
Trained batch 381 in epoch 18, gen_loss = 0.40165087003358374, disc_loss = 0.06489488658987727
Trained batch 382 in epoch 18, gen_loss = 0.4017614496594621, disc_loss = 0.06480834581560939
Trained batch 383 in epoch 18, gen_loss = 0.4018188995930056, disc_loss = 0.0648063224410483
Trained batch 384 in epoch 18, gen_loss = 0.40177604099372766, disc_loss = 0.06499886805941532
Trained batch 385 in epoch 18, gen_loss = 0.40181225306629514, disc_loss = 0.06497923854178715
Trained batch 386 in epoch 18, gen_loss = 0.4019295931324478, disc_loss = 0.06489083631017104
Trained batch 387 in epoch 18, gen_loss = 0.40190920072425274, disc_loss = 0.06492608810592558
Trained batch 388 in epoch 18, gen_loss = 0.40195435913792, disc_loss = 0.06478761314177421
Trained batch 389 in epoch 18, gen_loss = 0.40204609571359096, disc_loss = 0.0646597163966642
Trained batch 390 in epoch 18, gen_loss = 0.402033522991878, disc_loss = 0.06464866666680635
Trained batch 391 in epoch 18, gen_loss = 0.4018611320275433, disc_loss = 0.06471118262294223
Trained batch 392 in epoch 18, gen_loss = 0.4018168333377547, disc_loss = 0.06461645200440978
Trained batch 393 in epoch 18, gen_loss = 0.4018084499890429, disc_loss = 0.06460357065251107
Trained batch 394 in epoch 18, gen_loss = 0.40163087580777423, disc_loss = 0.06468067517433362
Trained batch 395 in epoch 18, gen_loss = 0.40147068261197116, disc_loss = 0.06489716806317294
Trained batch 396 in epoch 18, gen_loss = 0.4014255044892693, disc_loss = 0.06490024944218416
Trained batch 397 in epoch 18, gen_loss = 0.40155206268756233, disc_loss = 0.06486021271724272
Trained batch 398 in epoch 18, gen_loss = 0.4015003022245297, disc_loss = 0.06482510253983109
Trained batch 399 in epoch 18, gen_loss = 0.4016917036473751, disc_loss = 0.06471193827921524
Trained batch 400 in epoch 18, gen_loss = 0.40160307466537876, disc_loss = 0.0647395646914914
Trained batch 401 in epoch 18, gen_loss = 0.401681882899199, disc_loss = 0.0646133977961518
Trained batch 402 in epoch 18, gen_loss = 0.4016300649855924, disc_loss = 0.06449254453598195
Trained batch 403 in epoch 18, gen_loss = 0.4017520011356561, disc_loss = 0.06436883115283407
Trained batch 404 in epoch 18, gen_loss = 0.40181247614048143, disc_loss = 0.06429063861062866
Trained batch 405 in epoch 18, gen_loss = 0.4016230996019147, disc_loss = 0.06455030754034229
Trained batch 406 in epoch 18, gen_loss = 0.4019474012260062, disc_loss = 0.06473138898437161
Trained batch 407 in epoch 18, gen_loss = 0.40185528774471846, disc_loss = 0.06470136027828809
Trained batch 408 in epoch 18, gen_loss = 0.40214877227699264, disc_loss = 0.06458324592214415
Trained batch 409 in epoch 18, gen_loss = 0.402152963527819, disc_loss = 0.06457316357778703
Trained batch 410 in epoch 18, gen_loss = 0.40220769645233806, disc_loss = 0.06446810094118481
Trained batch 411 in epoch 18, gen_loss = 0.40193151400505917, disc_loss = 0.06478567662178675
Trained batch 412 in epoch 18, gen_loss = 0.402274978507229, disc_loss = 0.06515980970348992
Trained batch 413 in epoch 18, gen_loss = 0.4022942880789439, disc_loss = 0.06518047524544136
Trained batch 414 in epoch 18, gen_loss = 0.40209041237831117, disc_loss = 0.06558738697589521
Trained batch 415 in epoch 18, gen_loss = 0.40207489794836593, disc_loss = 0.0655130893283058
Trained batch 416 in epoch 18, gen_loss = 0.40202104223432017, disc_loss = 0.06550697945907033
Trained batch 417 in epoch 18, gen_loss = 0.4019464123192016, disc_loss = 0.0655211529061733
Trained batch 418 in epoch 18, gen_loss = 0.4018847344883302, disc_loss = 0.06549403230773022
Trained batch 419 in epoch 18, gen_loss = 0.4020301750728062, disc_loss = 0.06562204546561198
Trained batch 420 in epoch 18, gen_loss = 0.4019290154308718, disc_loss = 0.06564875571123566
Trained batch 421 in epoch 18, gen_loss = 0.4018760274795559, disc_loss = 0.06584447072554045
Trained batch 422 in epoch 18, gen_loss = 0.40208271991276573, disc_loss = 0.06597116354623937
Trained batch 423 in epoch 18, gen_loss = 0.40226069619914273, disc_loss = 0.0658719842783439
Trained batch 424 in epoch 18, gen_loss = 0.40204128012937657, disc_loss = 0.0658105756013709
Trained batch 425 in epoch 18, gen_loss = 0.4021005501069933, disc_loss = 0.06593007144207756
Trained batch 426 in epoch 18, gen_loss = 0.40213737275617184, disc_loss = 0.06621423347327483
Trained batch 427 in epoch 18, gen_loss = 0.4023836901254743, disc_loss = 0.06630575739795987
Trained batch 428 in epoch 18, gen_loss = 0.4022337050982566, disc_loss = 0.06632288768757265
Trained batch 429 in epoch 18, gen_loss = 0.4021018152320108, disc_loss = 0.06632281075080121
Trained batch 430 in epoch 18, gen_loss = 0.4021766692607419, disc_loss = 0.06627545375463373
Trained batch 431 in epoch 18, gen_loss = 0.40208241543560114, disc_loss = 0.06615800515714067
Trained batch 432 in epoch 18, gen_loss = 0.4022362648614835, disc_loss = 0.06608362626671516
Trained batch 433 in epoch 18, gen_loss = 0.40232062525188866, disc_loss = 0.06605560722232964
Trained batch 434 in epoch 18, gen_loss = 0.4026929527178578, disc_loss = 0.06603995415157285
Trained batch 435 in epoch 18, gen_loss = 0.40253893026244747, disc_loss = 0.0659766870576444
Trained batch 436 in epoch 18, gen_loss = 0.4022415588594956, disc_loss = 0.06597702732859542
Trained batch 437 in epoch 18, gen_loss = 0.40228220582280527, disc_loss = 0.06589710220405365
Trained batch 438 in epoch 18, gen_loss = 0.40245308725328816, disc_loss = 0.06579668313723083
Trained batch 439 in epoch 18, gen_loss = 0.4024352154271169, disc_loss = 0.0657144653653218
Trained batch 440 in epoch 18, gen_loss = 0.4022309744979789, disc_loss = 0.06562327815730826
Trained batch 441 in epoch 18, gen_loss = 0.4020401655413986, disc_loss = 0.06557337635479092
Trained batch 442 in epoch 18, gen_loss = 0.4019759493810598, disc_loss = 0.06559114248132329
Trained batch 443 in epoch 18, gen_loss = 0.4021113025578293, disc_loss = 0.06604877898788399
Trained batch 444 in epoch 18, gen_loss = 0.4020527286475964, disc_loss = 0.066289258463664
Trained batch 445 in epoch 18, gen_loss = 0.4021384095263588, disc_loss = 0.06616686982407564
Trained batch 446 in epoch 18, gen_loss = 0.4022163022684571, disc_loss = 0.06612611876621476
Trained batch 447 in epoch 18, gen_loss = 0.4021545102420662, disc_loss = 0.06605071301289302
Trained batch 448 in epoch 18, gen_loss = 0.40221382468474204, disc_loss = 0.0660089848475958
Trained batch 449 in epoch 18, gen_loss = 0.4021215211682849, disc_loss = 0.06594087963716852
Trained batch 450 in epoch 18, gen_loss = 0.4022068360824543, disc_loss = 0.06588357893911143
Trained batch 451 in epoch 18, gen_loss = 0.40246491509992466, disc_loss = 0.0660359709012627
Trained batch 452 in epoch 18, gen_loss = 0.40247882813807356, disc_loss = 0.06595309278938023
Trained batch 453 in epoch 18, gen_loss = 0.40240108763331356, disc_loss = 0.06601788608628091
Trained batch 454 in epoch 18, gen_loss = 0.40261511953322443, disc_loss = 0.06631922131956934
Trained batch 455 in epoch 18, gen_loss = 0.40249845856114436, disc_loss = 0.06637722179865498
Trained batch 456 in epoch 18, gen_loss = 0.4024500235165235, disc_loss = 0.06626702423250258
Trained batch 457 in epoch 18, gen_loss = 0.4025406332515733, disc_loss = 0.06627566262054782
Trained batch 458 in epoch 18, gen_loss = 0.4024518602943628, disc_loss = 0.0662384430445682
Trained batch 459 in epoch 18, gen_loss = 0.40249459685190864, disc_loss = 0.06612130004264738
Trained batch 460 in epoch 18, gen_loss = 0.40261600093831207, disc_loss = 0.06612716397824102
Testing Epoch 18
Training Epoch 19
Trained batch 0 in epoch 19, gen_loss = 0.369261771440506, disc_loss = 0.04592154175043106
Trained batch 1 in epoch 19, gen_loss = 0.3431249111890793, disc_loss = 0.06497695669531822
Trained batch 2 in epoch 19, gen_loss = 0.38695229093233746, disc_loss = 0.05277830424408118
Trained batch 3 in epoch 19, gen_loss = 0.40948497503995895, disc_loss = 0.04702023509889841
Trained batch 4 in epoch 19, gen_loss = 0.4132287323474884, disc_loss = 0.04966411665081978
Trained batch 5 in epoch 19, gen_loss = 0.4047576387723287, disc_loss = 0.046140846175452076
Trained batch 6 in epoch 19, gen_loss = 0.39740531359400066, disc_loss = 0.0411286356725863
Trained batch 7 in epoch 19, gen_loss = 0.39650734141469, disc_loss = 0.04053321504034102
Trained batch 8 in epoch 19, gen_loss = 0.4111942880683475, disc_loss = 0.0380770628237062
Trained batch 9 in epoch 19, gen_loss = 0.41040085554122924, disc_loss = 0.035854027792811397
Trained batch 10 in epoch 19, gen_loss = 0.40782669999382715, disc_loss = 0.03538931753825058
Trained batch 11 in epoch 19, gen_loss = 0.4030764152606328, disc_loss = 0.036540952045470476
Trained batch 12 in epoch 19, gen_loss = 0.3993636919901921, disc_loss = 0.03576013861367336
Trained batch 13 in epoch 19, gen_loss = 0.3965770091329302, disc_loss = 0.035014280517186434
Trained batch 14 in epoch 19, gen_loss = 0.40017176071802774, disc_loss = 0.03413008054097493
Trained batch 15 in epoch 19, gen_loss = 0.40076315589249134, disc_loss = 0.03551286458969116
Trained batch 16 in epoch 19, gen_loss = 0.4051995996166678, disc_loss = 0.03544718355816953
Trained batch 17 in epoch 19, gen_loss = 0.40730374389224583, disc_loss = 0.0345598298849331
Trained batch 18 in epoch 19, gen_loss = 0.4037604488824543, disc_loss = 0.033275199759947624
Trained batch 19 in epoch 19, gen_loss = 0.40179706960916517, disc_loss = 0.037121344543993476
Trained batch 20 in epoch 19, gen_loss = 0.40446198128518607, disc_loss = 0.047950085607312974
Trained batch 21 in epoch 19, gen_loss = 0.4086376035755331, disc_loss = 0.048158111558719116
Trained batch 22 in epoch 19, gen_loss = 0.4050154517526212, disc_loss = 0.05395389866569768
Trained batch 23 in epoch 19, gen_loss = 0.4021076063315074, disc_loss = 0.05557506189992031
Trained batch 24 in epoch 19, gen_loss = 0.403388067483902, disc_loss = 0.05388910077512264
Trained batch 25 in epoch 19, gen_loss = 0.4041363000869751, disc_loss = 0.05256773982770168
Trained batch 26 in epoch 19, gen_loss = 0.3998349893976141, disc_loss = 0.052469908018355015
Trained batch 27 in epoch 19, gen_loss = 0.4001717045903206, disc_loss = 0.05177828609677298
Trained batch 28 in epoch 19, gen_loss = 0.3970608700966013, disc_loss = 0.05051359582435468
Trained batch 29 in epoch 19, gen_loss = 0.3975012004375458, disc_loss = 0.049648604014267524
Trained batch 30 in epoch 19, gen_loss = 0.4008248698326849, disc_loss = 0.04905841099999605
Trained batch 31 in epoch 19, gen_loss = 0.3990294160321355, disc_loss = 0.04864051108597778
Trained batch 32 in epoch 19, gen_loss = 0.40068188761219836, disc_loss = 0.047784784328982685
Trained batch 33 in epoch 19, gen_loss = 0.4020178142715903, disc_loss = 0.047242229612653744
Trained batch 34 in epoch 19, gen_loss = 0.402086478471756, disc_loss = 0.04731158169784716
Trained batch 35 in epoch 19, gen_loss = 0.40129660815000534, disc_loss = 0.04624937492836681
Trained batch 36 in epoch 19, gen_loss = 0.403011180259086, disc_loss = 0.0456608360431887
Trained batch 37 in epoch 19, gen_loss = 0.4026442523065366, disc_loss = 0.04603190599989734
Trained batch 38 in epoch 19, gen_loss = 0.4031337109895853, disc_loss = 0.04712187057026686
Trained batch 39 in epoch 19, gen_loss = 0.4038777269423008, disc_loss = 0.04695078998338431
Trained batch 40 in epoch 19, gen_loss = 0.4051575159154287, disc_loss = 0.04603061518382009
Trained batch 41 in epoch 19, gen_loss = 0.4058713480120614, disc_loss = 0.04550079373820197
Trained batch 42 in epoch 19, gen_loss = 0.40556457014971004, disc_loss = 0.044721987704898034
Trained batch 43 in epoch 19, gen_loss = 0.4053839492526921, disc_loss = 0.04417220333760435
Trained batch 44 in epoch 19, gen_loss = 0.40679429504606457, disc_loss = 0.04371211764713128
Trained batch 45 in epoch 19, gen_loss = 0.40629440546035767, disc_loss = 0.0440654095829181
Trained batch 46 in epoch 19, gen_loss = 0.40662366405446476, disc_loss = 0.04477218685156487
Trained batch 47 in epoch 19, gen_loss = 0.4061807381610076, disc_loss = 0.045295223322076104
Trained batch 48 in epoch 19, gen_loss = 0.40655299960350505, disc_loss = 0.04629515388942495
Trained batch 49 in epoch 19, gen_loss = 0.4071675992012024, disc_loss = 0.04610105711966753
Trained batch 50 in epoch 19, gen_loss = 0.40561915378944546, disc_loss = 0.04716287352436898
Trained batch 51 in epoch 19, gen_loss = 0.40678381060178465, disc_loss = 0.0500233772640618
Trained batch 52 in epoch 19, gen_loss = 0.4077051096367386, disc_loss = 0.04965457717343321
Trained batch 53 in epoch 19, gen_loss = 0.40772738059361774, disc_loss = 0.050641688242278715
Trained batch 54 in epoch 19, gen_loss = 0.40822189829566263, disc_loss = 0.04987872117622332
Trained batch 55 in epoch 19, gen_loss = 0.4091091070856367, disc_loss = 0.04950019540930433
Trained batch 56 in epoch 19, gen_loss = 0.40896158051072506, disc_loss = 0.0494173734791969
Trained batch 57 in epoch 19, gen_loss = 0.40798797895168437, disc_loss = 0.04991943129049293
Trained batch 58 in epoch 19, gen_loss = 0.40815129623574725, disc_loss = 0.049402258500961936
Trained batch 59 in epoch 19, gen_loss = 0.40863761653502784, disc_loss = 0.04884219110632936
Trained batch 60 in epoch 19, gen_loss = 0.40876172409682976, disc_loss = 0.04853412994473684
Trained batch 61 in epoch 19, gen_loss = 0.40826761914837745, disc_loss = 0.048274134285748005
Trained batch 62 in epoch 19, gen_loss = 0.40960158431340776, disc_loss = 0.04791999821152006
Trained batch 63 in epoch 19, gen_loss = 0.4087318079546094, disc_loss = 0.04741166277381126
Trained batch 64 in epoch 19, gen_loss = 0.40872739553451537, disc_loss = 0.04741014495778542
Trained batch 65 in epoch 19, gen_loss = 0.40830515957239905, disc_loss = 0.04806181349594033
Trained batch 66 in epoch 19, gen_loss = 0.4087769664935212, disc_loss = 0.04749894777396277
Trained batch 67 in epoch 19, gen_loss = 0.4083101959789501, disc_loss = 0.04965249176465852
Trained batch 68 in epoch 19, gen_loss = 0.4077043930689494, disc_loss = 0.05000606126597394
Trained batch 69 in epoch 19, gen_loss = 0.40698039531707764, disc_loss = 0.051337239265974076
Trained batch 70 in epoch 19, gen_loss = 0.4058781178064749, disc_loss = 0.05348507924871126
Trained batch 71 in epoch 19, gen_loss = 0.4055392009516557, disc_loss = 0.0534328791545704
Trained batch 72 in epoch 19, gen_loss = 0.4062781852402099, disc_loss = 0.05356330762630048
Trained batch 73 in epoch 19, gen_loss = 0.40467442209656174, disc_loss = 0.0550318585985617
Trained batch 74 in epoch 19, gen_loss = 0.40497642596562705, disc_loss = 0.05515339355915785
Trained batch 75 in epoch 19, gen_loss = 0.404734264471029, disc_loss = 0.05487059307970891
Trained batch 76 in epoch 19, gen_loss = 0.40486248166530164, disc_loss = 0.054453772492706776
Trained batch 77 in epoch 19, gen_loss = 0.403693913267209, disc_loss = 0.05500722878302137
Trained batch 78 in epoch 19, gen_loss = 0.4043459009520615, disc_loss = 0.0553717164417045
Trained batch 79 in epoch 19, gen_loss = 0.4044576361775398, disc_loss = 0.05592595759080723
Trained batch 80 in epoch 19, gen_loss = 0.40331226734467496, disc_loss = 0.056752290910132876
Trained batch 81 in epoch 19, gen_loss = 0.40258172045393686, disc_loss = 0.05699764583941277
Trained batch 82 in epoch 19, gen_loss = 0.40415670821465643, disc_loss = 0.0583507338852947
Trained batch 83 in epoch 19, gen_loss = 0.4044167881920224, disc_loss = 0.05791261099234578
Trained batch 84 in epoch 19, gen_loss = 0.40385444549953237, disc_loss = 0.05902027977520929
Trained batch 85 in epoch 19, gen_loss = 0.4042316948951677, disc_loss = 0.05979580846940016
Trained batch 86 in epoch 19, gen_loss = 0.4039992220785426, disc_loss = 0.06003596555527257
Trained batch 87 in epoch 19, gen_loss = 0.40457089617848396, disc_loss = 0.05958830140827393
Trained batch 88 in epoch 19, gen_loss = 0.40483155310823676, disc_loss = 0.05946194479932611
Trained batch 89 in epoch 19, gen_loss = 0.40526254408889345, disc_loss = 0.05946179403819972
Trained batch 90 in epoch 19, gen_loss = 0.4050214274243994, disc_loss = 0.059393341960078415
Trained batch 91 in epoch 19, gen_loss = 0.40630459040403366, disc_loss = 0.059191232132118035
Trained batch 92 in epoch 19, gen_loss = 0.4059831535303465, disc_loss = 0.058948249536095766
Trained batch 93 in epoch 19, gen_loss = 0.40555925001489357, disc_loss = 0.05906072634450616
Trained batch 94 in epoch 19, gen_loss = 0.4065697011194731, disc_loss = 0.06024804329989772
Trained batch 95 in epoch 19, gen_loss = 0.40652624766031903, disc_loss = 0.05992521220468916
Trained batch 96 in epoch 19, gen_loss = 0.40650912658455446, disc_loss = 0.05981105111885009
Trained batch 97 in epoch 19, gen_loss = 0.40556240507534574, disc_loss = 0.059609974858027936
Trained batch 98 in epoch 19, gen_loss = 0.4057501933791421, disc_loss = 0.059396034341794676
Trained batch 99 in epoch 19, gen_loss = 0.4064351224899292, disc_loss = 0.059061685306951404
Trained batch 100 in epoch 19, gen_loss = 0.4064939145994659, disc_loss = 0.05883920165977561
Trained batch 101 in epoch 19, gen_loss = 0.4077026925834955, disc_loss = 0.05878310960114879
Trained batch 102 in epoch 19, gen_loss = 0.4072984711637775, disc_loss = 0.05835382297671246
Trained batch 103 in epoch 19, gen_loss = 0.4072707209449548, disc_loss = 0.058144212243720315
Trained batch 104 in epoch 19, gen_loss = 0.40686760970524377, disc_loss = 0.05803586341263283
Trained batch 105 in epoch 19, gen_loss = 0.4072460374742184, disc_loss = 0.058906897454399545
Trained batch 106 in epoch 19, gen_loss = 0.40562515476039634, disc_loss = 0.060755125386205235
Trained batch 107 in epoch 19, gen_loss = 0.405951241100276, disc_loss = 0.060739573617293326
Trained batch 108 in epoch 19, gen_loss = 0.40607621855692033, disc_loss = 0.06031241358488525
Trained batch 109 in epoch 19, gen_loss = 0.406196530027823, disc_loss = 0.05992811759087172
Trained batch 110 in epoch 19, gen_loss = 0.405383101991705, disc_loss = 0.060554880850218436
Trained batch 111 in epoch 19, gen_loss = 0.4055726980524404, disc_loss = 0.06117489697810795
Trained batch 112 in epoch 19, gen_loss = 0.40554391150980923, disc_loss = 0.06135364282315811
Trained batch 113 in epoch 19, gen_loss = 0.40454177296998206, disc_loss = 0.06389014053632293
Trained batch 114 in epoch 19, gen_loss = 0.40516841048779695, disc_loss = 0.06426057611470637
Trained batch 115 in epoch 19, gen_loss = 0.4056963586601718, disc_loss = 0.0639153703372797
Trained batch 116 in epoch 19, gen_loss = 0.4060796354061518, disc_loss = 0.06432127855463415
Trained batch 117 in epoch 19, gen_loss = 0.40569678024720335, disc_loss = 0.06411558309159542
Trained batch 118 in epoch 19, gen_loss = 0.40517146572345447, disc_loss = 0.06384353876552161
Trained batch 119 in epoch 19, gen_loss = 0.40462478399276736, disc_loss = 0.06421622235017518
Trained batch 120 in epoch 19, gen_loss = 0.4048235426264361, disc_loss = 0.06416110735971572
Trained batch 121 in epoch 19, gen_loss = 0.4051250661494302, disc_loss = 0.0640265968032792
Trained batch 122 in epoch 19, gen_loss = 0.4051895592270828, disc_loss = 0.0641122236999312
Trained batch 123 in epoch 19, gen_loss = 0.40458510719960733, disc_loss = 0.06386104678254455
Trained batch 124 in epoch 19, gen_loss = 0.40397698307037355, disc_loss = 0.06388866110146045
Trained batch 125 in epoch 19, gen_loss = 0.4032595112683281, disc_loss = 0.06386267892011101
Trained batch 126 in epoch 19, gen_loss = 0.4027982243872064, disc_loss = 0.06368020266353146
Trained batch 127 in epoch 19, gen_loss = 0.4028393211774528, disc_loss = 0.06347379386716057
Trained batch 128 in epoch 19, gen_loss = 0.4026236700457196, disc_loss = 0.06374965667320315
Trained batch 129 in epoch 19, gen_loss = 0.4027034046558233, disc_loss = 0.06393470593656485
Trained batch 130 in epoch 19, gen_loss = 0.40265910657307574, disc_loss = 0.0638134581470535
Trained batch 131 in epoch 19, gen_loss = 0.40283141285181046, disc_loss = 0.06360385590938455
Trained batch 132 in epoch 19, gen_loss = 0.40307687301384776, disc_loss = 0.06332241477710861
Trained batch 133 in epoch 19, gen_loss = 0.40290769956894773, disc_loss = 0.06337037129299854
Trained batch 134 in epoch 19, gen_loss = 0.4032119947451132, disc_loss = 0.06370037046295625
Trained batch 135 in epoch 19, gen_loss = 0.40312858955825076, disc_loss = 0.06345050165648847
Trained batch 136 in epoch 19, gen_loss = 0.40256183034312115, disc_loss = 0.06331508119937278
Trained batch 137 in epoch 19, gen_loss = 0.4022053966055746, disc_loss = 0.06308271937018288
Trained batch 138 in epoch 19, gen_loss = 0.40288630492395633, disc_loss = 0.06270467574379855
Trained batch 139 in epoch 19, gen_loss = 0.40307684860059195, disc_loss = 0.062457303556480576
Trained batch 140 in epoch 19, gen_loss = 0.40289339972725996, disc_loss = 0.062117074517176504
Trained batch 141 in epoch 19, gen_loss = 0.4029187801438318, disc_loss = 0.061957439945512255
Trained batch 142 in epoch 19, gen_loss = 0.4020098695805023, disc_loss = 0.06262912850019399
Trained batch 143 in epoch 19, gen_loss = 0.40223420390652287, disc_loss = 0.06461765807277213
Trained batch 144 in epoch 19, gen_loss = 0.4020990914311902, disc_loss = 0.06431185660948013
Trained batch 145 in epoch 19, gen_loss = 0.40193312359999306, disc_loss = 0.06428807255595106
Trained batch 146 in epoch 19, gen_loss = 0.4011063496677243, disc_loss = 0.06506045260244891
Trained batch 147 in epoch 19, gen_loss = 0.4011907051946666, disc_loss = 0.06678182054059328
Trained batch 148 in epoch 19, gen_loss = 0.4016286424742449, disc_loss = 0.06647768052882397
Trained batch 149 in epoch 19, gen_loss = 0.40152724981307986, disc_loss = 0.06628100393960873
Trained batch 150 in epoch 19, gen_loss = 0.40156288277234464, disc_loss = 0.06653262160422392
Trained batch 151 in epoch 19, gen_loss = 0.4020198824766435, disc_loss = 0.06632912696927394
Trained batch 152 in epoch 19, gen_loss = 0.40214721400753345, disc_loss = 0.06674910973440977
Trained batch 153 in epoch 19, gen_loss = 0.4013905890963294, disc_loss = 0.0675530672532978
Trained batch 154 in epoch 19, gen_loss = 0.40157399600551974, disc_loss = 0.06732761651998566
Trained batch 155 in epoch 19, gen_loss = 0.401403967386637, disc_loss = 0.06782880237994668
Trained batch 156 in epoch 19, gen_loss = 0.4019222762554314, disc_loss = 0.06762458503863235
Trained batch 157 in epoch 19, gen_loss = 0.40159688399562354, disc_loss = 0.06787609550630368
Trained batch 158 in epoch 19, gen_loss = 0.402051827442721, disc_loss = 0.06862238317774902
Trained batch 159 in epoch 19, gen_loss = 0.4016621347516775, disc_loss = 0.06837751501007006
Trained batch 160 in epoch 19, gen_loss = 0.40189919171866423, disc_loss = 0.06812065654659863
Trained batch 161 in epoch 19, gen_loss = 0.40185819989369237, disc_loss = 0.06802682137047802
Trained batch 162 in epoch 19, gen_loss = 0.40151136455360364, disc_loss = 0.067855422619296
Trained batch 163 in epoch 19, gen_loss = 0.4013785123825073, disc_loss = 0.06761988135418151
Trained batch 164 in epoch 19, gen_loss = 0.4010537991018006, disc_loss = 0.06737447195883953
Trained batch 165 in epoch 19, gen_loss = 0.40129920696637716, disc_loss = 0.06713422686310418
Trained batch 166 in epoch 19, gen_loss = 0.40121543907119844, disc_loss = 0.06685719951362668
Trained batch 167 in epoch 19, gen_loss = 0.4010016435668582, disc_loss = 0.06665214587978664
Trained batch 168 in epoch 19, gen_loss = 0.401169955377748, disc_loss = 0.06644270176718221
Trained batch 169 in epoch 19, gen_loss = 0.4013815222417607, disc_loss = 0.06642621225293945
Trained batch 170 in epoch 19, gen_loss = 0.4008779241676219, disc_loss = 0.06723067630627001
Trained batch 171 in epoch 19, gen_loss = 0.4015101452552995, disc_loss = 0.06762243153224158
Trained batch 172 in epoch 19, gen_loss = 0.4016529152848128, disc_loss = 0.06735852451165976
Trained batch 173 in epoch 19, gen_loss = 0.40158731122126523, disc_loss = 0.06715766338353184
Trained batch 174 in epoch 19, gen_loss = 0.40133144923618863, disc_loss = 0.06692160071006843
Trained batch 175 in epoch 19, gen_loss = 0.4015746485780586, disc_loss = 0.06675556279845875
Trained batch 176 in epoch 19, gen_loss = 0.40171185337891013, disc_loss = 0.0665114264156522
Trained batch 177 in epoch 19, gen_loss = 0.4018792724341489, disc_loss = 0.06622479195717011
Trained batch 178 in epoch 19, gen_loss = 0.40156850202123545, disc_loss = 0.06632924738584617
Trained batch 179 in epoch 19, gen_loss = 0.40138873060544333, disc_loss = 0.06699986251898937
Trained batch 180 in epoch 19, gen_loss = 0.40203989309500593, disc_loss = 0.06698410181091964
Trained batch 181 in epoch 19, gen_loss = 0.40186766510481364, disc_loss = 0.0667312622152187
Trained batch 182 in epoch 19, gen_loss = 0.4015447026719161, disc_loss = 0.06651257267578052
Trained batch 183 in epoch 19, gen_loss = 0.40146359768898593, disc_loss = 0.06632127815290638
Trained batch 184 in epoch 19, gen_loss = 0.401492738240474, disc_loss = 0.0662000134990022
Trained batch 185 in epoch 19, gen_loss = 0.40143932690543516, disc_loss = 0.06611804724220306
Trained batch 186 in epoch 19, gen_loss = 0.4018887563504, disc_loss = 0.06613164012604218
Trained batch 187 in epoch 19, gen_loss = 0.40163015907115124, disc_loss = 0.06600296118871328
Trained batch 188 in epoch 19, gen_loss = 0.4016139780087446, disc_loss = 0.0658167413775883
Trained batch 189 in epoch 19, gen_loss = 0.4018313465934051, disc_loss = 0.06558179018136702
Trained batch 190 in epoch 19, gen_loss = 0.4022987063642572, disc_loss = 0.06529835400937116
Trained batch 191 in epoch 19, gen_loss = 0.40218928068255383, disc_loss = 0.06507373634182538
Trained batch 192 in epoch 19, gen_loss = 0.40208174728358964, disc_loss = 0.06499923935517128
Trained batch 193 in epoch 19, gen_loss = 0.4020517193472263, disc_loss = 0.06491474684366245
Trained batch 194 in epoch 19, gen_loss = 0.40234044163655014, disc_loss = 0.06471371910510919
Trained batch 195 in epoch 19, gen_loss = 0.4025078282064321, disc_loss = 0.06446754455338327
Trained batch 196 in epoch 19, gen_loss = 0.4025897138614945, disc_loss = 0.06418387178180333
Trained batch 197 in epoch 19, gen_loss = 0.4024615018355726, disc_loss = 0.06401483896611766
Trained batch 198 in epoch 19, gen_loss = 0.4027893646578094, disc_loss = 0.06392138855222931
Trained batch 199 in epoch 19, gen_loss = 0.4024427518248558, disc_loss = 0.06398948132526129
Trained batch 200 in epoch 19, gen_loss = 0.40221084068663676, disc_loss = 0.06387694312991639
Trained batch 201 in epoch 19, gen_loss = 0.40280811931237137, disc_loss = 0.06441452825847681
Trained batch 202 in epoch 19, gen_loss = 0.40241016043818056, disc_loss = 0.06452240214540894
Trained batch 203 in epoch 19, gen_loss = 0.40257806170220467, disc_loss = 0.06431096238449362
Trained batch 204 in epoch 19, gen_loss = 0.4023500044171403, disc_loss = 0.0644362096879177
Trained batch 205 in epoch 19, gen_loss = 0.40245953086510444, disc_loss = 0.06434672782920951
Trained batch 206 in epoch 19, gen_loss = 0.4024977969086688, disc_loss = 0.06428995260131964
Trained batch 207 in epoch 19, gen_loss = 0.40252669986623985, disc_loss = 0.06416889906484777
Trained batch 208 in epoch 19, gen_loss = 0.402201248127878, disc_loss = 0.06433009380768788
Trained batch 209 in epoch 19, gen_loss = 0.4024011539561408, disc_loss = 0.06438557537095178
Trained batch 210 in epoch 19, gen_loss = 0.4022681194741579, disc_loss = 0.06435189980095456
Trained batch 211 in epoch 19, gen_loss = 0.402197094880185, disc_loss = 0.0640955890994519
Trained batch 212 in epoch 19, gen_loss = 0.40220851615561004, disc_loss = 0.06388246567543823
Trained batch 213 in epoch 19, gen_loss = 0.402143975980928, disc_loss = 0.06383723384813866
Trained batch 214 in epoch 19, gen_loss = 0.40184095432591993, disc_loss = 0.06363964638304571
Trained batch 215 in epoch 19, gen_loss = 0.4019018675166148, disc_loss = 0.06360855553281942
Trained batch 216 in epoch 19, gen_loss = 0.4017697640003697, disc_loss = 0.0637988944576564
Trained batch 217 in epoch 19, gen_loss = 0.40201831028002116, disc_loss = 0.0637253104504027
Trained batch 218 in epoch 19, gen_loss = 0.4017235382234669, disc_loss = 0.06386900315120748
Trained batch 219 in epoch 19, gen_loss = 0.40128323571248486, disc_loss = 0.06453429162078961
Trained batch 220 in epoch 19, gen_loss = 0.4010863395837637, disc_loss = 0.06441161845182806
Trained batch 221 in epoch 19, gen_loss = 0.4014313529740583, disc_loss = 0.06528339004311878
Trained batch 222 in epoch 19, gen_loss = 0.4010676045321563, disc_loss = 0.06534962315580102
Trained batch 223 in epoch 19, gen_loss = 0.40128986151622875, disc_loss = 0.06511565837925966
Trained batch 224 in epoch 19, gen_loss = 0.40156544155544704, disc_loss = 0.06498893576777644
Trained batch 225 in epoch 19, gen_loss = 0.4014088465312941, disc_loss = 0.0647694854378964
Trained batch 226 in epoch 19, gen_loss = 0.4018900758106803, disc_loss = 0.06454487390291061
Trained batch 227 in epoch 19, gen_loss = 0.40195929076065096, disc_loss = 0.06437423216636505
Trained batch 228 in epoch 19, gen_loss = 0.40186818497149707, disc_loss = 0.06434542710961993
Trained batch 229 in epoch 19, gen_loss = 0.4016732824885327, disc_loss = 0.06473889158957678
Trained batch 230 in epoch 19, gen_loss = 0.40213203249555646, disc_loss = 0.06465655312877455
Trained batch 231 in epoch 19, gen_loss = 0.40211029941665716, disc_loss = 0.0646523910911818
Trained batch 232 in epoch 19, gen_loss = 0.4021870667842325, disc_loss = 0.0646199980279023
Trained batch 233 in epoch 19, gen_loss = 0.40240046178173816, disc_loss = 0.06438959822950201
Trained batch 234 in epoch 19, gen_loss = 0.4023527405363448, disc_loss = 0.06415078108535802
Trained batch 235 in epoch 19, gen_loss = 0.4022489118121438, disc_loss = 0.06421192894468747
Trained batch 236 in epoch 19, gen_loss = 0.402009081362672, disc_loss = 0.06403604466939651
Trained batch 237 in epoch 19, gen_loss = 0.40186602891493245, disc_loss = 0.06389656416023103
Trained batch 238 in epoch 19, gen_loss = 0.40169017983280964, disc_loss = 0.06385693351921302
Trained batch 239 in epoch 19, gen_loss = 0.40176794218520323, disc_loss = 0.06380490789888427
Trained batch 240 in epoch 19, gen_loss = 0.4016064657709905, disc_loss = 0.06387139422842204
Trained batch 241 in epoch 19, gen_loss = 0.40133373353106916, disc_loss = 0.063844656144569
Trained batch 242 in epoch 19, gen_loss = 0.40124076249177565, disc_loss = 0.06372570680691995
Trained batch 243 in epoch 19, gen_loss = 0.4010711253666487, disc_loss = 0.06359157861271476
Trained batch 244 in epoch 19, gen_loss = 0.4009750694644694, disc_loss = 0.06346728195417292
Trained batch 245 in epoch 19, gen_loss = 0.4008804204745021, disc_loss = 0.06329760127663006
Trained batch 246 in epoch 19, gen_loss = 0.4007562219131331, disc_loss = 0.06326578780330024
Trained batch 247 in epoch 19, gen_loss = 0.40128580949479536, disc_loss = 0.06362877389220821
Trained batch 248 in epoch 19, gen_loss = 0.4012920582390215, disc_loss = 0.0636936029658679
Trained batch 249 in epoch 19, gen_loss = 0.4012070471048355, disc_loss = 0.06348177932575345
Trained batch 250 in epoch 19, gen_loss = 0.40116890600003097, disc_loss = 0.0634171755732115
Trained batch 251 in epoch 19, gen_loss = 0.40127436887650264, disc_loss = 0.06324896949993832
Trained batch 252 in epoch 19, gen_loss = 0.40138132770070917, disc_loss = 0.06316280365358345
Trained batch 253 in epoch 19, gen_loss = 0.40136094086282836, disc_loss = 0.06300835949772103
Trained batch 254 in epoch 19, gen_loss = 0.40151787972917746, disc_loss = 0.06285302249312985
Trained batch 255 in epoch 19, gen_loss = 0.4013593408744782, disc_loss = 0.06294732324386132
Trained batch 256 in epoch 19, gen_loss = 0.40176590662522077, disc_loss = 0.06379172129462317
Trained batch 257 in epoch 19, gen_loss = 0.4019489018029945, disc_loss = 0.06361522925151296
Trained batch 258 in epoch 19, gen_loss = 0.4020844895867307, disc_loss = 0.06411485806553405
Trained batch 259 in epoch 19, gen_loss = 0.4021733467395489, disc_loss = 0.06423668386772848
Trained batch 260 in epoch 19, gen_loss = 0.4021115279060671, disc_loss = 0.06405578534051033
Trained batch 261 in epoch 19, gen_loss = 0.40206951414810793, disc_loss = 0.06389923958562826
Trained batch 262 in epoch 19, gen_loss = 0.40206492627074963, disc_loss = 0.06383546208431626
Trained batch 263 in epoch 19, gen_loss = 0.4019857785015395, disc_loss = 0.06365660509221595
Trained batch 264 in epoch 19, gen_loss = 0.4022821569217826, disc_loss = 0.06353718839796646
Trained batch 265 in epoch 19, gen_loss = 0.4020659227792482, disc_loss = 0.06378902998031642
Trained batch 266 in epoch 19, gen_loss = 0.40205412879865265, disc_loss = 0.06376474600787578
Trained batch 267 in epoch 19, gen_loss = 0.4019313820484859, disc_loss = 0.06376374345064274
Trained batch 268 in epoch 19, gen_loss = 0.40207992732303294, disc_loss = 0.06369623418925088
Trained batch 269 in epoch 19, gen_loss = 0.40196794657795515, disc_loss = 0.06358243602638443
Trained batch 270 in epoch 19, gen_loss = 0.4017087246439114, disc_loss = 0.06345144425934642
Trained batch 271 in epoch 19, gen_loss = 0.40175967729266954, disc_loss = 0.06350225405014284
Trained batch 272 in epoch 19, gen_loss = 0.4018479814896217, disc_loss = 0.06330931717154635
Trained batch 273 in epoch 19, gen_loss = 0.40180571986375935, disc_loss = 0.06328206691197562
Trained batch 274 in epoch 19, gen_loss = 0.4019262241233479, disc_loss = 0.06307787972587076
Trained batch 275 in epoch 19, gen_loss = 0.40187273325695505, disc_loss = 0.06328305252658986
Trained batch 276 in epoch 19, gen_loss = 0.402080860701709, disc_loss = 0.06344684021251565
Trained batch 277 in epoch 19, gen_loss = 0.4019480496644974, disc_loss = 0.06329213537898906
Trained batch 278 in epoch 19, gen_loss = 0.4019178290948218, disc_loss = 0.06319808086220136
Trained batch 279 in epoch 19, gen_loss = 0.40185470964227404, disc_loss = 0.06303396493229749
Trained batch 280 in epoch 19, gen_loss = 0.4015359178556666, disc_loss = 0.06287504875290065
Trained batch 281 in epoch 19, gen_loss = 0.4016907148538752, disc_loss = 0.06282018684676406
Trained batch 282 in epoch 19, gen_loss = 0.4012842391068017, disc_loss = 0.06286011999078069
Trained batch 283 in epoch 19, gen_loss = 0.4011071958172489, disc_loss = 0.06273220958430845
Trained batch 284 in epoch 19, gen_loss = 0.4015510954354939, disc_loss = 0.06262787317922502
Trained batch 285 in epoch 19, gen_loss = 0.40149059850019175, disc_loss = 0.06246041556839812
Trained batch 286 in epoch 19, gen_loss = 0.4011995174535891, disc_loss = 0.06249332880497446
Trained batch 287 in epoch 19, gen_loss = 0.4011799582383699, disc_loss = 0.06261960172075003
Trained batch 288 in epoch 19, gen_loss = 0.4010404784580415, disc_loss = 0.06255628666953283
Trained batch 289 in epoch 19, gen_loss = 0.40101428350497936, disc_loss = 0.062468842630563626
Trained batch 290 in epoch 19, gen_loss = 0.4010294553954986, disc_loss = 0.06241895394924631
Trained batch 291 in epoch 19, gen_loss = 0.401081393332514, disc_loss = 0.06225172610321937
Trained batch 292 in epoch 19, gen_loss = 0.4011134086208539, disc_loss = 0.06214809594612327
Trained batch 293 in epoch 19, gen_loss = 0.4009218873823581, disc_loss = 0.06201912623792127
Trained batch 294 in epoch 19, gen_loss = 0.4010528676590677, disc_loss = 0.061913580082798916
Trained batch 295 in epoch 19, gen_loss = 0.4013443930527648, disc_loss = 0.06194847054634797
Trained batch 296 in epoch 19, gen_loss = 0.40111928124620455, disc_loss = 0.06185382736457969
Trained batch 297 in epoch 19, gen_loss = 0.4012723370086427, disc_loss = 0.0617124332793232
Trained batch 298 in epoch 19, gen_loss = 0.40128977621678125, disc_loss = 0.061556066777307954
Trained batch 299 in epoch 19, gen_loss = 0.4009870824217796, disc_loss = 0.061445776840361455
Trained batch 300 in epoch 19, gen_loss = 0.4011002022562629, disc_loss = 0.06163496229073583
Trained batch 301 in epoch 19, gen_loss = 0.4007994674688933, disc_loss = 0.06196985393300011
Trained batch 302 in epoch 19, gen_loss = 0.4008348772037934, disc_loss = 0.061809056633683815
Trained batch 303 in epoch 19, gen_loss = 0.40089646422941433, disc_loss = 0.061891787729875525
Trained batch 304 in epoch 19, gen_loss = 0.4005980956749838, disc_loss = 0.06208393707657691
Trained batch 305 in epoch 19, gen_loss = 0.4007561133772719, disc_loss = 0.0622259887754065
Trained batch 306 in epoch 19, gen_loss = 0.4005855311205799, disc_loss = 0.062151900448621
Trained batch 307 in epoch 19, gen_loss = 0.4006593617332446, disc_loss = 0.062093917638752855
Trained batch 308 in epoch 19, gen_loss = 0.4004035682739949, disc_loss = 0.06206315793971076
Trained batch 309 in epoch 19, gen_loss = 0.4003859741072501, disc_loss = 0.06196512414833471
Trained batch 310 in epoch 19, gen_loss = 0.40056725311125974, disc_loss = 0.0618266614642102
Trained batch 311 in epoch 19, gen_loss = 0.40074222735487497, disc_loss = 0.061668660499167464
Trained batch 312 in epoch 19, gen_loss = 0.40081200508263926, disc_loss = 0.06158715613430348
Trained batch 313 in epoch 19, gen_loss = 0.4006647215147687, disc_loss = 0.06164093150247102
Trained batch 314 in epoch 19, gen_loss = 0.40063651147342866, disc_loss = 0.06158216506508844
Trained batch 315 in epoch 19, gen_loss = 0.40063224968653693, disc_loss = 0.06142896920283431
Trained batch 316 in epoch 19, gen_loss = 0.4008077790120423, disc_loss = 0.06134572133498284
Trained batch 317 in epoch 19, gen_loss = 0.4008289205390702, disc_loss = 0.061243607781229996
Trained batch 318 in epoch 19, gen_loss = 0.40088384614842815, disc_loss = 0.061182435796096876
Trained batch 319 in epoch 19, gen_loss = 0.40105933817103506, disc_loss = 0.061067857716989235
Trained batch 320 in epoch 19, gen_loss = 0.40109275165376634, disc_loss = 0.06102118073205385
Trained batch 321 in epoch 19, gen_loss = 0.40131918947148765, disc_loss = 0.060937932867452686
Trained batch 322 in epoch 19, gen_loss = 0.401182527973925, disc_loss = 0.06079295900543638
Trained batch 323 in epoch 19, gen_loss = 0.4013872543050919, disc_loss = 0.0606513539067596
Trained batch 324 in epoch 19, gen_loss = 0.40136666380442104, disc_loss = 0.06053409282547923
Trained batch 325 in epoch 19, gen_loss = 0.4011881633038901, disc_loss = 0.06046838656873471
Trained batch 326 in epoch 19, gen_loss = 0.4012861942661647, disc_loss = 0.06044653159016544
Trained batch 327 in epoch 19, gen_loss = 0.401228585530345, disc_loss = 0.06038738322222787
Trained batch 328 in epoch 19, gen_loss = 0.4011712376832237, disc_loss = 0.060301568683259484
Trained batch 329 in epoch 19, gen_loss = 0.4009704249374794, disc_loss = 0.06029532613430285
Trained batch 330 in epoch 19, gen_loss = 0.40116751905294346, disc_loss = 0.06041326207950081
Trained batch 331 in epoch 19, gen_loss = 0.40109155874654473, disc_loss = 0.060340727764989686
Trained batch 332 in epoch 19, gen_loss = 0.40118179629156897, disc_loss = 0.06023404049874471
Trained batch 333 in epoch 19, gen_loss = 0.4012518705365187, disc_loss = 0.060405831277916974
Trained batch 334 in epoch 19, gen_loss = 0.4011043377776644, disc_loss = 0.06038629672448359
Trained batch 335 in epoch 19, gen_loss = 0.40106160575080485, disc_loss = 0.060281397332714516
Trained batch 336 in epoch 19, gen_loss = 0.4011399844103114, disc_loss = 0.06034399648763527
Trained batch 337 in epoch 19, gen_loss = 0.40102760308592983, disc_loss = 0.06022206207974291
Trained batch 338 in epoch 19, gen_loss = 0.4011079352513879, disc_loss = 0.06023557740332323
Trained batch 339 in epoch 19, gen_loss = 0.4014090431087157, disc_loss = 0.0601100092055276
Trained batch 340 in epoch 19, gen_loss = 0.4013353724283906, disc_loss = 0.06014786757490546
Trained batch 341 in epoch 19, gen_loss = 0.4010587436588187, disc_loss = 0.060493448941167774
Trained batch 342 in epoch 19, gen_loss = 0.40134794467044643, disc_loss = 0.06049625324248269
Trained batch 343 in epoch 19, gen_loss = 0.4014111047740592, disc_loss = 0.060461704734290495
Trained batch 344 in epoch 19, gen_loss = 0.401379305469817, disc_loss = 0.060523320849229026
Trained batch 345 in epoch 19, gen_loss = 0.4014036202361818, disc_loss = 0.06039914565909159
Trained batch 346 in epoch 19, gen_loss = 0.40163720779185336, disc_loss = 0.06032333458218219
Trained batch 347 in epoch 19, gen_loss = 0.4015855685561553, disc_loss = 0.06021335267799039
Trained batch 348 in epoch 19, gen_loss = 0.40155173159260465, disc_loss = 0.060183659672235434
Trained batch 349 in epoch 19, gen_loss = 0.40182770277772634, disc_loss = 0.060062526726563065
Trained batch 350 in epoch 19, gen_loss = 0.40196682389645155, disc_loss = 0.059922808013124086
Trained batch 351 in epoch 19, gen_loss = 0.401949933137406, disc_loss = 0.059844036016412167
Trained batch 352 in epoch 19, gen_loss = 0.4021483505244971, disc_loss = 0.05972785796711575
Trained batch 353 in epoch 19, gen_loss = 0.4022738544617669, disc_loss = 0.05973943853934985
Trained batch 354 in epoch 19, gen_loss = 0.4021838355232292, disc_loss = 0.05988952379647485
Trained batch 355 in epoch 19, gen_loss = 0.4023580610584677, disc_loss = 0.05994716377306227
Trained batch 356 in epoch 19, gen_loss = 0.4022285356408074, disc_loss = 0.0598393106475702
Trained batch 357 in epoch 19, gen_loss = 0.40215297792543914, disc_loss = 0.059754643325210036
Trained batch 358 in epoch 19, gen_loss = 0.4022042718936474, disc_loss = 0.05964146692093078
Trained batch 359 in epoch 19, gen_loss = 0.4023992075688309, disc_loss = 0.05971091551732065
Trained batch 360 in epoch 19, gen_loss = 0.4024060027586126, disc_loss = 0.059895126036835264
Trained batch 361 in epoch 19, gen_loss = 0.40254321537953053, disc_loss = 0.05977254382139123
Trained batch 362 in epoch 19, gen_loss = 0.4028303692984515, disc_loss = 0.059827606915945276
Trained batch 363 in epoch 19, gen_loss = 0.40274840683399976, disc_loss = 0.05982165522284929
Trained batch 364 in epoch 19, gen_loss = 0.40264070197327495, disc_loss = 0.059812056902183657
Trained batch 365 in epoch 19, gen_loss = 0.4026574155346292, disc_loss = 0.05970586935704564
Trained batch 366 in epoch 19, gen_loss = 0.4028753597664898, disc_loss = 0.059576015141653026
Trained batch 367 in epoch 19, gen_loss = 0.4028166302520296, disc_loss = 0.05952358917388863
Trained batch 368 in epoch 19, gen_loss = 0.4028457175425398, disc_loss = 0.05939150475303776
Trained batch 369 in epoch 19, gen_loss = 0.403134827678268, disc_loss = 0.059453228346349016
Trained batch 370 in epoch 19, gen_loss = 0.4030966480787231, disc_loss = 0.05950300247757382
Trained batch 371 in epoch 19, gen_loss = 0.4032427380161901, disc_loss = 0.059370108981496625
Trained batch 372 in epoch 19, gen_loss = 0.40348313768811267, disc_loss = 0.059531063132297654
Trained batch 373 in epoch 19, gen_loss = 0.40334083554260236, disc_loss = 0.05946378782516056
Trained batch 374 in epoch 19, gen_loss = 0.4033122554620107, disc_loss = 0.059397739411642156
Trained batch 375 in epoch 19, gen_loss = 0.40346358748192485, disc_loss = 0.05930269800963752
Trained batch 376 in epoch 19, gen_loss = 0.40343600116294637, disc_loss = 0.05917631324988343
Trained batch 377 in epoch 19, gen_loss = 0.4034892772398298, disc_loss = 0.05918070841605268
Trained batch 378 in epoch 19, gen_loss = 0.4034714223055223, disc_loss = 0.05908155200590126
Trained batch 379 in epoch 19, gen_loss = 0.4035514638612145, disc_loss = 0.059003114270193405
Trained batch 380 in epoch 19, gen_loss = 0.40347453083578994, disc_loss = 0.058993072374882737
Trained batch 381 in epoch 19, gen_loss = 0.40330974141340603, disc_loss = 0.05919429152857766
Trained batch 382 in epoch 19, gen_loss = 0.4033180033257985, disc_loss = 0.05905884406201094
Trained batch 383 in epoch 19, gen_loss = 0.40384057257324457, disc_loss = 0.05930246144149957
Trained batch 384 in epoch 19, gen_loss = 0.40369643855404547, disc_loss = 0.05921034125079002
Trained batch 385 in epoch 19, gen_loss = 0.40350419993227626, disc_loss = 0.05916991244176393
Trained batch 386 in epoch 19, gen_loss = 0.4034527460117981, disc_loss = 0.059082520477117574
Trained batch 387 in epoch 19, gen_loss = 0.40357508694695443, disc_loss = 0.058955384179536906
Trained batch 388 in epoch 19, gen_loss = 0.4036155933739287, disc_loss = 0.058822432926743454
Trained batch 389 in epoch 19, gen_loss = 0.40381317688868595, disc_loss = 0.05875131409639158
Trained batch 390 in epoch 19, gen_loss = 0.4041341328255051, disc_loss = 0.05869941921342555
Trained batch 391 in epoch 19, gen_loss = 0.40424891508051325, disc_loss = 0.05863100765581832
Trained batch 392 in epoch 19, gen_loss = 0.40419239033269516, disc_loss = 0.058800114627984415
Trained batch 393 in epoch 19, gen_loss = 0.4042195071121158, disc_loss = 0.0588412956927955
Trained batch 394 in epoch 19, gen_loss = 0.4040729033041604, disc_loss = 0.05874940824777454
Trained batch 395 in epoch 19, gen_loss = 0.4041708314208069, disc_loss = 0.058733011079679306
Trained batch 396 in epoch 19, gen_loss = 0.40426991470814955, disc_loss = 0.05862074421943923
Trained batch 397 in epoch 19, gen_loss = 0.4043253583824215, disc_loss = 0.05854142859376892
Trained batch 398 in epoch 19, gen_loss = 0.4044816213144097, disc_loss = 0.05847017212717194
Trained batch 399 in epoch 19, gen_loss = 0.4042610839754343, disc_loss = 0.05855420356267132
Trained batch 400 in epoch 19, gen_loss = 0.40435532723876305, disc_loss = 0.05874045365640982
Trained batch 401 in epoch 19, gen_loss = 0.4040823657417772, disc_loss = 0.058655407758133105
Trained batch 402 in epoch 19, gen_loss = 0.40402525848253784, disc_loss = 0.05868769630849842
Trained batch 403 in epoch 19, gen_loss = 0.4042048007249832, disc_loss = 0.058685646785450823
Trained batch 404 in epoch 19, gen_loss = 0.40419768955972457, disc_loss = 0.05856744489391093
Trained batch 405 in epoch 19, gen_loss = 0.4041065265392435, disc_loss = 0.05848148824495672
Trained batch 406 in epoch 19, gen_loss = 0.4043951110699253, disc_loss = 0.05837020905532803
Trained batch 407 in epoch 19, gen_loss = 0.40449945351072386, disc_loss = 0.05824491099280981
Trained batch 408 in epoch 19, gen_loss = 0.40463930390283354, disc_loss = 0.058126935673863935
Trained batch 409 in epoch 19, gen_loss = 0.40460869175631825, disc_loss = 0.058067572805121905
Trained batch 410 in epoch 19, gen_loss = 0.4045235531318507, disc_loss = 0.058161425200311374
Trained batch 411 in epoch 19, gen_loss = 0.40466500341313555, disc_loss = 0.058325017809198756
Trained batch 412 in epoch 19, gen_loss = 0.40464736272290025, disc_loss = 0.05821011658333981
Trained batch 413 in epoch 19, gen_loss = 0.40444951652040806, disc_loss = 0.05819903275420988
Trained batch 414 in epoch 19, gen_loss = 0.4043841423758541, disc_loss = 0.058142664579741925
Trained batch 415 in epoch 19, gen_loss = 0.4045142269191834, disc_loss = 0.05802779518014107
Trained batch 416 in epoch 19, gen_loss = 0.4044364229094782, disc_loss = 0.057980781215593684
Trained batch 417 in epoch 19, gen_loss = 0.4047177371225859, disc_loss = 0.0582044167248042
Trained batch 418 in epoch 19, gen_loss = 0.40449439874696846, disc_loss = 0.05828349980879086
Trained batch 419 in epoch 19, gen_loss = 0.4043907232937359, disc_loss = 0.05819888577929565
Trained batch 420 in epoch 19, gen_loss = 0.40412491482114, disc_loss = 0.058291843306989964
Trained batch 421 in epoch 19, gen_loss = 0.40417646295368953, disc_loss = 0.058322109582158624
Trained batch 422 in epoch 19, gen_loss = 0.404144521371129, disc_loss = 0.05821939220048716
Trained batch 423 in epoch 19, gen_loss = 0.40409149693430596, disc_loss = 0.05820300869801837
Trained batch 424 in epoch 19, gen_loss = 0.40411740639630483, disc_loss = 0.058152687597800706
Trained batch 425 in epoch 19, gen_loss = 0.40418799697233476, disc_loss = 0.05810930753485278
Trained batch 426 in epoch 19, gen_loss = 0.40426075395711414, disc_loss = 0.058109299591644306
Trained batch 427 in epoch 19, gen_loss = 0.40429906317285286, disc_loss = 0.05835589013175569
Trained batch 428 in epoch 19, gen_loss = 0.40433143819128714, disc_loss = 0.058666706975280265
Trained batch 429 in epoch 19, gen_loss = 0.4043833530226419, disc_loss = 0.05874793219791595
Trained batch 430 in epoch 19, gen_loss = 0.40438554493014606, disc_loss = 0.05870520566825662
Trained batch 431 in epoch 19, gen_loss = 0.4042724853174554, disc_loss = 0.0586418455802939
Trained batch 432 in epoch 19, gen_loss = 0.4043754673719957, disc_loss = 0.05854307767649033
Trained batch 433 in epoch 19, gen_loss = 0.4045809555438257, disc_loss = 0.05845660765651047
Trained batch 434 in epoch 19, gen_loss = 0.40449846181376226, disc_loss = 0.05853891238655852
Trained batch 435 in epoch 19, gen_loss = 0.4047647638741983, disc_loss = 0.058839740141918624
Trained batch 436 in epoch 19, gen_loss = 0.4048574129012957, disc_loss = 0.0591071933738086
Trained batch 437 in epoch 19, gen_loss = 0.4048916611769428, disc_loss = 0.059068926303864344
Trained batch 438 in epoch 19, gen_loss = 0.40504956869981285, disc_loss = 0.05897764780119503
Trained batch 439 in epoch 19, gen_loss = 0.40497578788887373, disc_loss = 0.05893829342993823
Trained batch 440 in epoch 19, gen_loss = 0.4050758654703629, disc_loss = 0.05887167152786066
Trained batch 441 in epoch 19, gen_loss = 0.4051687286585165, disc_loss = 0.058777963805825735
Trained batch 442 in epoch 19, gen_loss = 0.4050876206253775, disc_loss = 0.05871820015492208
Trained batch 443 in epoch 19, gen_loss = 0.4051448224901079, disc_loss = 0.05873536153671306
Trained batch 444 in epoch 19, gen_loss = 0.40498485250419447, disc_loss = 0.05883544311345963
Trained batch 445 in epoch 19, gen_loss = 0.4050301211163602, disc_loss = 0.05888644002394692
Trained batch 446 in epoch 19, gen_loss = 0.4049961487585533, disc_loss = 0.058790156455247995
Trained batch 447 in epoch 19, gen_loss = 0.4050948826729187, disc_loss = 0.05869819229701534
Trained batch 448 in epoch 19, gen_loss = 0.40498475674000506, disc_loss = 0.05861445368663771
Trained batch 449 in epoch 19, gen_loss = 0.4050411847564909, disc_loss = 0.05858905498352316
Trained batch 450 in epoch 19, gen_loss = 0.4051459367550133, disc_loss = 0.05851481917279126
Trained batch 451 in epoch 19, gen_loss = 0.4050034461955054, disc_loss = 0.05840624596478533
Trained batch 452 in epoch 19, gen_loss = 0.40495379778986207, disc_loss = 0.05833262032017145
Trained batch 453 in epoch 19, gen_loss = 0.40490492292175206, disc_loss = 0.05827489058335316
Trained batch 454 in epoch 19, gen_loss = 0.4047799217831958, disc_loss = 0.05836711017885706
Trained batch 455 in epoch 19, gen_loss = 0.4048845092194122, disc_loss = 0.05853350865327867
Trained batch 456 in epoch 19, gen_loss = 0.4048275153929086, disc_loss = 0.05842075667484649
Trained batch 457 in epoch 19, gen_loss = 0.40477018396666997, disc_loss = 0.058367286180451054
Trained batch 458 in epoch 19, gen_loss = 0.4046678259351934, disc_loss = 0.0582654738194088
Trained batch 459 in epoch 19, gen_loss = 0.40472693417383276, disc_loss = 0.05816406758866556
Trained batch 460 in epoch 19, gen_loss = 0.40468343924286565, disc_loss = 0.05808733159841852
Testing Epoch 19
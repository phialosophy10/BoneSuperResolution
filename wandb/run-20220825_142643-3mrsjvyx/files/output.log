wandb: WARNING Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 0.6640885472297668, disc_loss = 0.6806713938713074
Trained batch 1 in epoch 0, gen_loss = 0.602548360824585, disc_loss = 0.6832165718078613
Trained batch 2 in epoch 0, gen_loss = 0.5563964148362478, disc_loss = 0.6892370780309042
Trained batch 3 in epoch 0, gen_loss = 0.5187733694911003, disc_loss = 0.6165150478482246
Trained batch 4 in epoch 0, gen_loss = 0.49483644366264345, disc_loss = 0.5411029398441315
Trained batch 5 in epoch 0, gen_loss = 0.47382403413454693, disc_loss = 0.4932275861501694
Trained batch 6 in epoch 0, gen_loss = 0.46873349802834646, disc_loss = 0.44809840832437786
Trained batch 7 in epoch 0, gen_loss = 0.45814941078424454, disc_loss = 0.41436418518424034
Trained batch 8 in epoch 0, gen_loss = 0.45065749684969586, disc_loss = 0.395968668990665
Trained batch 9 in epoch 0, gen_loss = 0.4468909323215485, disc_loss = 0.3785119324922562
Trained batch 10 in epoch 0, gen_loss = 0.4494716091589494, disc_loss = 0.3573216985572468
Trained batch 11 in epoch 0, gen_loss = 0.4466673384110133, disc_loss = 0.33760512930651504
Trained batch 12 in epoch 0, gen_loss = 0.44129179074214053, disc_loss = 0.32209266321017194
Trained batch 13 in epoch 0, gen_loss = 0.44077203954969135, disc_loss = 0.30524672833936556
Trained batch 14 in epoch 0, gen_loss = 0.44444500605265297, disc_loss = 0.29053201228380204
Trained batch 15 in epoch 0, gen_loss = 0.44845836982131004, disc_loss = 0.27809336595237255
Trained batch 16 in epoch 0, gen_loss = 0.4475429408690509, disc_loss = 0.2672221577342819
Trained batch 17 in epoch 0, gen_loss = 0.4496561669641071, disc_loss = 0.2592004785935084
Trained batch 18 in epoch 0, gen_loss = 0.452496527056945, disc_loss = 0.2502276446474226
Trained batch 19 in epoch 0, gen_loss = 0.4518079414963722, disc_loss = 0.24309560470283031
Trained batch 20 in epoch 0, gen_loss = 0.4522087219215575, disc_loss = 0.24096059479883739
Trained batch 21 in epoch 0, gen_loss = 0.45426016504114325, disc_loss = 0.2365214726464315
Trained batch 22 in epoch 0, gen_loss = 0.4518881414247596, disc_loss = 0.2356642461989237
Trained batch 23 in epoch 0, gen_loss = 0.4541509946187337, disc_loss = 0.235435395501554
Trained batch 24 in epoch 0, gen_loss = 0.4520970702171326, disc_loss = 0.2309765002131462
Trained batch 25 in epoch 0, gen_loss = 0.4519525239100823, disc_loss = 0.2262865657416674
Trained batch 26 in epoch 0, gen_loss = 0.4506142183586403, disc_loss = 0.22046873966852823
Trained batch 27 in epoch 0, gen_loss = 0.4501140309231622, disc_loss = 0.21568278702242033
Trained batch 28 in epoch 0, gen_loss = 0.44937450104746324, disc_loss = 0.21050218184446468
Trained batch 29 in epoch 0, gen_loss = 0.45079032679398856, disc_loss = 0.205520723387599
Trained batch 30 in epoch 0, gen_loss = 0.4504137010343613, disc_loss = 0.20055153833762293
Trained batch 31 in epoch 0, gen_loss = 0.4516783142462373, disc_loss = 0.19574936397839338
Trained batch 32 in epoch 0, gen_loss = 0.4525837347362981, disc_loss = 0.19106951863928276
Trained batch 33 in epoch 0, gen_loss = 0.45359380630885854, disc_loss = 0.1865739574765458
Trained batch 34 in epoch 0, gen_loss = 0.45337616545813425, disc_loss = 0.1823323890566826
Trained batch 35 in epoch 0, gen_loss = 0.4539438775844044, disc_loss = 0.17829768297572932
Trained batch 36 in epoch 0, gen_loss = 0.45321998966706767, disc_loss = 0.17492439728733655
Trained batch 37 in epoch 0, gen_loss = 0.4542653152817174, disc_loss = 0.1719564350419923
Trained batch 38 in epoch 0, gen_loss = 0.4552247508978232, disc_loss = 0.16872121861729866
Trained batch 39 in epoch 0, gen_loss = 0.45697415322065355, disc_loss = 0.16557613303884863
Trained batch 40 in epoch 0, gen_loss = 0.45861490906738656, disc_loss = 0.16262380279055455
Trained batch 41 in epoch 0, gen_loss = 0.45787419591631207, disc_loss = 0.15992295404984838
Trained batch 42 in epoch 0, gen_loss = 0.458369140015092, disc_loss = 0.1580754454399264
Trained batch 43 in epoch 0, gen_loss = 0.458357841453769, disc_loss = 0.15603550235656174
Trained batch 44 in epoch 0, gen_loss = 0.45863947007391187, disc_loss = 0.15362947632869084
Trained batch 45 in epoch 0, gen_loss = 0.45932229705478833, disc_loss = 0.1510734912817893
Trained batch 46 in epoch 0, gen_loss = 0.4613686533684426, disc_loss = 0.14863384483342476
Trained batch 47 in epoch 0, gen_loss = 0.46152549237012863, disc_loss = 0.14639686637868485
Trained batch 48 in epoch 0, gen_loss = 0.46387190721472915, disc_loss = 0.14429120050401104
Trained batch 49 in epoch 0, gen_loss = 0.4635584992170334, disc_loss = 0.14226946912705898
Trained batch 50 in epoch 0, gen_loss = 0.4654342526314305, disc_loss = 0.14006063641578542
Trained batch 51 in epoch 0, gen_loss = 0.4647760660602496, disc_loss = 0.13981992185402375
Trained batch 52 in epoch 0, gen_loss = 0.4667604436289589, disc_loss = 0.14080598198299138
Trained batch 53 in epoch 0, gen_loss = 0.4675296837532962, disc_loss = 0.1393494069300316
Trained batch 54 in epoch 0, gen_loss = 0.46985497853972696, disc_loss = 0.13843554732474414
Trained batch 55 in epoch 0, gen_loss = 0.4706378627036299, disc_loss = 0.13681807475430624
Trained batch 56 in epoch 0, gen_loss = 0.4705958758529864, disc_loss = 0.13540157584244744
Trained batch 57 in epoch 0, gen_loss = 0.4717389802480566, disc_loss = 0.1337806644110844
Trained batch 58 in epoch 0, gen_loss = 0.47231564531892034, disc_loss = 0.1321073964995853
Trained batch 59 in epoch 0, gen_loss = 0.47241767595211664, disc_loss = 0.13050536140799524
Trained batch 60 in epoch 0, gen_loss = 0.4714685712681442, disc_loss = 0.12886330082279737
Trained batch 61 in epoch 0, gen_loss = 0.46954232694641235, disc_loss = 0.12789733503614703
Trained batch 62 in epoch 0, gen_loss = 0.470298386282391, disc_loss = 0.1265432056453493
Trained batch 63 in epoch 0, gen_loss = 0.47185812471434474, disc_loss = 0.1251079592620954
Trained batch 64 in epoch 0, gen_loss = 0.471112290254006, disc_loss = 0.12386991502000735
Trained batch 65 in epoch 0, gen_loss = 0.4716636822982268, disc_loss = 0.12428196570412679
Trained batch 66 in epoch 0, gen_loss = 0.47322764903751774, disc_loss = 0.12329478873245751
Trained batch 67 in epoch 0, gen_loss = 0.4736857541343745, disc_loss = 0.12261706327690798
Trained batch 68 in epoch 0, gen_loss = 0.47318222686864325, disc_loss = 0.12244210964527683
Trained batch 69 in epoch 0, gen_loss = 0.4735764848334449, disc_loss = 0.12129716133432729
Trained batch 70 in epoch 0, gen_loss = 0.4740686613908956, disc_loss = 0.12013950214629442
Trained batch 71 in epoch 0, gen_loss = 0.4754231708745162, disc_loss = 0.11879551858227286
Trained batch 72 in epoch 0, gen_loss = 0.4754557299287352, disc_loss = 0.11750281048453834
Trained batch 73 in epoch 0, gen_loss = 0.47490180706655655, disc_loss = 0.11621662126098936
Trained batch 74 in epoch 0, gen_loss = 0.47489586353302005, disc_loss = 0.11497806501885255
Trained batch 75 in epoch 0, gen_loss = 0.4750709380758436, disc_loss = 0.11369869639900954
Trained batch 76 in epoch 0, gen_loss = 0.4738626932943022, disc_loss = 0.11268081731320202
Trained batch 77 in epoch 0, gen_loss = 0.47312932709852856, disc_loss = 0.11156182855558701
Trained batch 78 in epoch 0, gen_loss = 0.47290100477918795, disc_loss = 0.1105209001446072
Trained batch 79 in epoch 0, gen_loss = 0.4720307901501656, disc_loss = 0.10941483757924289
Trained batch 80 in epoch 0, gen_loss = 0.4726036220421026, disc_loss = 0.10840376588389461
Trained batch 81 in epoch 0, gen_loss = 0.4731421899504778, disc_loss = 0.1073899986903842
Trained batch 82 in epoch 0, gen_loss = 0.47247422567333086, disc_loss = 0.10649936314088752
Trained batch 83 in epoch 0, gen_loss = 0.4726173569049154, disc_loss = 0.10559188410462368
Trained batch 84 in epoch 0, gen_loss = 0.47209165061221403, disc_loss = 0.10499344814349623
Trained batch 85 in epoch 0, gen_loss = 0.4721969664096832, disc_loss = 0.10450437695307788
Trained batch 86 in epoch 0, gen_loss = 0.47244614842294275, disc_loss = 0.10437535584486764
Trained batch 87 in epoch 0, gen_loss = 0.4719240330159664, disc_loss = 0.10413493668999184
Trained batch 88 in epoch 0, gen_loss = 0.47205691123276616, disc_loss = 0.10370891721228535
Trained batch 89 in epoch 0, gen_loss = 0.4721293720934126, disc_loss = 0.10311352192527717
Trained batch 90 in epoch 0, gen_loss = 0.4726366230419704, disc_loss = 0.1027389919937967
Trained batch 91 in epoch 0, gen_loss = 0.47375938685044, disc_loss = 0.1023309764087848
Trained batch 92 in epoch 0, gen_loss = 0.4749904223667678, disc_loss = 0.1016629982379175
Trained batch 93 in epoch 0, gen_loss = 0.47562345101478254, disc_loss = 0.10095596539371825
Trained batch 94 in epoch 0, gen_loss = 0.4756530137438523, disc_loss = 0.10074468651100209
Trained batch 95 in epoch 0, gen_loss = 0.4752413956448436, disc_loss = 0.10355847472480188
Trained batch 96 in epoch 0, gen_loss = 0.47489664019997585, disc_loss = 0.10404386444343734
Trained batch 97 in epoch 0, gen_loss = 0.47470548292812037, disc_loss = 0.10360463822678644
Trained batch 98 in epoch 0, gen_loss = 0.4738452091361537, disc_loss = 0.10371816940981933
Trained batch 99 in epoch 0, gen_loss = 0.4738544651865959, disc_loss = 0.10380777463316918
Trained batch 100 in epoch 0, gen_loss = 0.47516396818774764, disc_loss = 0.1035717761162484
Trained batch 101 in epoch 0, gen_loss = 0.4761130076413061, disc_loss = 0.10301682133884991
Trained batch 102 in epoch 0, gen_loss = 0.47630195739199815, disc_loss = 0.10255301241012453
Trained batch 103 in epoch 0, gen_loss = 0.4770519117323252, disc_loss = 0.10252472883663498
Trained batch 104 in epoch 0, gen_loss = 0.47742049949509757, disc_loss = 0.10281530927334513
Trained batch 105 in epoch 0, gen_loss = 0.4773047299317594, disc_loss = 0.10601696480979335
Trained batch 106 in epoch 0, gen_loss = 0.4780558757135801, disc_loss = 0.10620172917146549
Trained batch 107 in epoch 0, gen_loss = 0.47818107019971917, disc_loss = 0.1061890565065874
Trained batch 108 in epoch 0, gen_loss = 0.47826517694587006, disc_loss = 0.10774585724287077
Trained batch 109 in epoch 0, gen_loss = 0.4781973716887561, disc_loss = 0.10772227194498886
Trained batch 110 in epoch 0, gen_loss = 0.47795342781522254, disc_loss = 0.10790442329672006
Trained batch 111 in epoch 0, gen_loss = 0.47782203262405737, disc_loss = 0.10857922354313944
Trained batch 112 in epoch 0, gen_loss = 0.47707721406379633, disc_loss = 0.10999445798518383
Trained batch 113 in epoch 0, gen_loss = 0.47696868840016815, disc_loss = 0.1118668512228811
Trained batch 114 in epoch 0, gen_loss = 0.4768605094888936, disc_loss = 0.11341278303576552
Trained batch 115 in epoch 0, gen_loss = 0.47688581100825606, disc_loss = 0.11368959432403589
Trained batch 116 in epoch 0, gen_loss = 0.47737222196709395, disc_loss = 0.11404355058175886
Trained batch 117 in epoch 0, gen_loss = 0.4771709634085833, disc_loss = 0.11402579242268861
Trained batch 118 in epoch 0, gen_loss = 0.4764171776150455, disc_loss = 0.11407283809380371
Trained batch 119 in epoch 0, gen_loss = 0.4761053445438544, disc_loss = 0.11416064541166028
Trained batch 120 in epoch 0, gen_loss = 0.4753660769009393, disc_loss = 0.1147645678956154
Trained batch 121 in epoch 0, gen_loss = 0.47584565276982355, disc_loss = 0.11503358860118468
Trained batch 122 in epoch 0, gen_loss = 0.4757268111395642, disc_loss = 0.11500824167112994
Trained batch 123 in epoch 0, gen_loss = 0.47588489204645157, disc_loss = 0.11513142531076746
Trained batch 124 in epoch 0, gen_loss = 0.47542379903793336, disc_loss = 0.11574647572636604
Trained batch 125 in epoch 0, gen_loss = 0.4752532581961344, disc_loss = 0.11782060732089338
Trained batch 126 in epoch 0, gen_loss = 0.47478990690914663, disc_loss = 0.11902393696932342
Trained batch 127 in epoch 0, gen_loss = 0.47495616553351283, disc_loss = 0.11923226740327664
Trained batch 128 in epoch 0, gen_loss = 0.474767408167669, disc_loss = 0.11929486868108889
Trained batch 129 in epoch 0, gen_loss = 0.47426943251719844, disc_loss = 0.11935446884196538
Trained batch 130 in epoch 0, gen_loss = 0.47370540799985406, disc_loss = 0.11926131345729792
Trained batch 131 in epoch 0, gen_loss = 0.47334968614758866, disc_loss = 0.1194760985390255
Trained batch 132 in epoch 0, gen_loss = 0.4735615004722337, disc_loss = 0.11901962042863208
Trained batch 133 in epoch 0, gen_loss = 0.4736616778284756, disc_loss = 0.11856841137493725
Trained batch 134 in epoch 0, gen_loss = 0.47345353254565486, disc_loss = 0.11897592232735069
Trained batch 135 in epoch 0, gen_loss = 0.47277917471878667, disc_loss = 0.12253631473354556
Trained batch 136 in epoch 0, gen_loss = 0.4728946829364248, disc_loss = 0.12271665904099924
Trained batch 137 in epoch 0, gen_loss = 0.4726958866568579, disc_loss = 0.12320686334177204
Trained batch 138 in epoch 0, gen_loss = 0.47201824145351384, disc_loss = 0.12337338878846854
Trained batch 139 in epoch 0, gen_loss = 0.4715485998562404, disc_loss = 0.12340616889830147
Trained batch 140 in epoch 0, gen_loss = 0.47143578825267496, disc_loss = 0.1233037530266224
Trained batch 141 in epoch 0, gen_loss = 0.4709344588115182, disc_loss = 0.12303612735384786
Trained batch 142 in epoch 0, gen_loss = 0.471540394154462, disc_loss = 0.12268285950893289
Trained batch 143 in epoch 0, gen_loss = 0.4723390491886271, disc_loss = 0.1223140673763636
Trained batch 144 in epoch 0, gen_loss = 0.4717674224541105, disc_loss = 0.12279235517670369
Trained batch 145 in epoch 0, gen_loss = 0.4718197326954097, disc_loss = 0.12634585024661396
Trained batch 146 in epoch 0, gen_loss = 0.4716573965792753, disc_loss = 0.12632837792744442
Trained batch 147 in epoch 0, gen_loss = 0.47200150425369675, disc_loss = 0.12823532745745536
Trained batch 148 in epoch 0, gen_loss = 0.4717455952359526, disc_loss = 0.12852974698547548
Trained batch 149 in epoch 0, gen_loss = 0.4714255545536677, disc_loss = 0.12921499135593573
Trained batch 150 in epoch 0, gen_loss = 0.4710805948996386, disc_loss = 0.1292351105601977
Trained batch 151 in epoch 0, gen_loss = 0.4712411275035457, disc_loss = 0.12936260249759807
Trained batch 152 in epoch 0, gen_loss = 0.471207475740146, disc_loss = 0.12935824003192334
Trained batch 153 in epoch 0, gen_loss = 0.47082252297308536, disc_loss = 0.12920046348560166
Trained batch 154 in epoch 0, gen_loss = 0.47050267227234377, disc_loss = 0.12907975803940527
Trained batch 155 in epoch 0, gen_loss = 0.4701763846171208, disc_loss = 0.1290546165397152
Trained batch 156 in epoch 0, gen_loss = 0.4702198881252556, disc_loss = 0.13040199142637526
Trained batch 157 in epoch 0, gen_loss = 0.4699506699284421, disc_loss = 0.13164426450016378
Trained batch 158 in epoch 0, gen_loss = 0.4700587315004577, disc_loss = 0.13165057274811673
Trained batch 159 in epoch 0, gen_loss = 0.470056988671422, disc_loss = 0.13224093408789486
Trained batch 160 in epoch 0, gen_loss = 0.46937109631781254, disc_loss = 0.13256097578021311
Trained batch 161 in epoch 0, gen_loss = 0.46892923263855923, disc_loss = 0.132880006192459
Trained batch 162 in epoch 0, gen_loss = 0.4685364919571789, disc_loss = 0.13374985916757146
Trained batch 163 in epoch 0, gen_loss = 0.4679839471127929, disc_loss = 0.13373536559775834
Trained batch 164 in epoch 0, gen_loss = 0.46744460355151785, disc_loss = 0.13390181712580448
Trained batch 165 in epoch 0, gen_loss = 0.4673941894827119, disc_loss = 0.13386824114405246
Trained batch 166 in epoch 0, gen_loss = 0.4670853580900295, disc_loss = 0.13429269281600764
Trained batch 167 in epoch 0, gen_loss = 0.46640010000694365, disc_loss = 0.13481429367814035
Trained batch 168 in epoch 0, gen_loss = 0.46608689691893446, disc_loss = 0.1352522555496213
Trained batch 169 in epoch 0, gen_loss = 0.4658349256305134, disc_loss = 0.13551089480957565
Trained batch 170 in epoch 0, gen_loss = 0.46571825261701616, disc_loss = 0.1362070920305294
Trained batch 171 in epoch 0, gen_loss = 0.46572211471407915, disc_loss = 0.1365579776249306
Trained batch 172 in epoch 0, gen_loss = 0.4651691508775502, disc_loss = 0.13691984829788953
Trained batch 173 in epoch 0, gen_loss = 0.4646036931495557, disc_loss = 0.13690648114458584
Trained batch 174 in epoch 0, gen_loss = 0.4641349450179509, disc_loss = 0.13694652138011795
Trained batch 175 in epoch 0, gen_loss = 0.46404056572778657, disc_loss = 0.13701188350519675
Trained batch 176 in epoch 0, gen_loss = 0.46384584146030877, disc_loss = 0.13671470069363292
Trained batch 177 in epoch 0, gen_loss = 0.4638393080971214, disc_loss = 0.1366092171101423
Trained batch 178 in epoch 0, gen_loss = 0.4637974265900404, disc_loss = 0.13702290602985706
Trained batch 179 in epoch 0, gen_loss = 0.4635769905315505, disc_loss = 0.13787301813976632
Trained batch 180 in epoch 0, gen_loss = 0.46340762054064, disc_loss = 0.13791657681705544
Trained batch 181 in epoch 0, gen_loss = 0.4632719060876867, disc_loss = 0.13796674142908918
Trained batch 182 in epoch 0, gen_loss = 0.46293870135734644, disc_loss = 0.137823319439191
Trained batch 183 in epoch 0, gen_loss = 0.46290320514336875, disc_loss = 0.13766694018293335
Trained batch 184 in epoch 0, gen_loss = 0.4627556800842285, disc_loss = 0.13757511391430288
Trained batch 185 in epoch 0, gen_loss = 0.4626884157619169, disc_loss = 0.13763385015710067
Trained batch 186 in epoch 0, gen_loss = 0.4623143226705133, disc_loss = 0.13903580213533365
Trained batch 187 in epoch 0, gen_loss = 0.46212576583344883, disc_loss = 0.14052237061030687
Trained batch 188 in epoch 0, gen_loss = 0.46202376137965573, disc_loss = 0.1407985100473361
Trained batch 189 in epoch 0, gen_loss = 0.46190980908117796, disc_loss = 0.1412043860672336
Trained batch 190 in epoch 0, gen_loss = 0.4617972740640191, disc_loss = 0.14150345971056927
Trained batch 191 in epoch 0, gen_loss = 0.461595536985745, disc_loss = 0.1418147367076017
Trained batch 192 in epoch 0, gen_loss = 0.4614155328026707, disc_loss = 0.1420775894944223
Trained batch 193 in epoch 0, gen_loss = 0.4611494124857421, disc_loss = 0.1421399248437476
Trained batch 194 in epoch 0, gen_loss = 0.4608226560629331, disc_loss = 0.14254675643184248
Trained batch 195 in epoch 0, gen_loss = 0.4603277846258514, disc_loss = 0.1429934472567877
Trained batch 196 in epoch 0, gen_loss = 0.459724413561942, disc_loss = 0.14321106503987072
Trained batch 197 in epoch 0, gen_loss = 0.459308852601533, disc_loss = 0.14354736800070364
Trained batch 198 in epoch 0, gen_loss = 0.45952115900552454, disc_loss = 0.14349991388281985
Trained batch 199 in epoch 0, gen_loss = 0.45927507281303404, disc_loss = 0.14352878933772445
Trained batch 200 in epoch 0, gen_loss = 0.45864830903746, disc_loss = 0.14370102155490302
Trained batch 201 in epoch 0, gen_loss = 0.4588862346245511, disc_loss = 0.14364896793988083
Trained batch 202 in epoch 0, gen_loss = 0.4582686073380738, disc_loss = 0.14435605820396852
Trained batch 203 in epoch 0, gen_loss = 0.4578924912448023, disc_loss = 0.14549744295358075
Trained batch 204 in epoch 0, gen_loss = 0.45766658332289717, disc_loss = 0.14577152836250096
Trained batch 205 in epoch 0, gen_loss = 0.4575567887824716, disc_loss = 0.14594025510245734
Trained batch 206 in epoch 0, gen_loss = 0.45730153402844487, disc_loss = 0.14602542173675293
Trained batch 207 in epoch 0, gen_loss = 0.45670531847729134, disc_loss = 0.14640575760187438
Trained batch 208 in epoch 0, gen_loss = 0.45623689533420725, disc_loss = 0.14686181177006383
Trained batch 209 in epoch 0, gen_loss = 0.45587874693529945, disc_loss = 0.14731627480969542
Trained batch 210 in epoch 0, gen_loss = 0.45584467321775535, disc_loss = 0.14804646900691693
Trained batch 211 in epoch 0, gen_loss = 0.45595786425302615, disc_loss = 0.1483116677593229
Trained batch 212 in epoch 0, gen_loss = 0.4556514270988429, disc_loss = 0.14852967947511606
Trained batch 213 in epoch 0, gen_loss = 0.45537098169883833, disc_loss = 0.14876447442187885
Trained batch 214 in epoch 0, gen_loss = 0.4550774531308995, disc_loss = 0.14903345425115075
Trained batch 215 in epoch 0, gen_loss = 0.4548466961692881, disc_loss = 0.14916999753633584
Trained batch 216 in epoch 0, gen_loss = 0.4541161376210402, disc_loss = 0.14948194709172996
Trained batch 217 in epoch 0, gen_loss = 0.45359984135955844, disc_loss = 0.14972907651660092
Trained batch 218 in epoch 0, gen_loss = 0.45304380391286386, disc_loss = 0.14988840822147453
Trained batch 219 in epoch 0, gen_loss = 0.45276045866987924, disc_loss = 0.15006100493059918
Trained batch 220 in epoch 0, gen_loss = 0.4525492528445041, disc_loss = 0.15026245908432417
Trained batch 221 in epoch 0, gen_loss = 0.4525234841548645, disc_loss = 0.15073902607970946
Trained batch 222 in epoch 0, gen_loss = 0.4520532716015529, disc_loss = 0.1513783880780898
Trained batch 223 in epoch 0, gen_loss = 0.45208717603236437, disc_loss = 0.15143309505323746
Trained batch 224 in epoch 0, gen_loss = 0.4519172081682417, disc_loss = 0.15146193251013756
Trained batch 225 in epoch 0, gen_loss = 0.45144980842560795, disc_loss = 0.15165078770204454
Trained batch 226 in epoch 0, gen_loss = 0.4511710855666761, disc_loss = 0.15182204017752068
Trained batch 227 in epoch 0, gen_loss = 0.45102677481216297, disc_loss = 0.15226457455898063
Trained batch 228 in epoch 0, gen_loss = 0.45083420050196255, disc_loss = 0.15250653963877644
Trained batch 229 in epoch 0, gen_loss = 0.4506398933089298, disc_loss = 0.15248196032708106
Trained batch 230 in epoch 0, gen_loss = 0.45029307959915754, disc_loss = 0.15246875885696637
Trained batch 231 in epoch 0, gen_loss = 0.4499404826040926, disc_loss = 0.15266254664687762
Trained batch 232 in epoch 0, gen_loss = 0.4490699512892015, disc_loss = 0.1528832004145747
Trained batch 233 in epoch 0, gen_loss = 0.44872514438680094, disc_loss = 0.1529742004111027
Trained batch 234 in epoch 0, gen_loss = 0.4488329025659155, disc_loss = 0.15329521588505582
Trained batch 235 in epoch 0, gen_loss = 0.44845718707321053, disc_loss = 0.15394308744787666
Trained batch 236 in epoch 0, gen_loss = 0.44815460696250575, disc_loss = 0.15497665061666493
Trained batch 237 in epoch 0, gen_loss = 0.44769603258171004, disc_loss = 0.15598172348524844
Trained batch 238 in epoch 0, gen_loss = 0.4475219456097072, disc_loss = 0.15643226338168567
Trained batch 239 in epoch 0, gen_loss = 0.44740319966028136, disc_loss = 0.1569865152084579
Trained batch 240 in epoch 0, gen_loss = 0.44711707421110874, disc_loss = 0.15725778950633348
Trained batch 241 in epoch 0, gen_loss = 0.44653014807908004, disc_loss = 0.15755585899715088
Trained batch 242 in epoch 0, gen_loss = 0.44601372074443124, disc_loss = 0.1578922422426473
Trained batch 243 in epoch 0, gen_loss = 0.4459305237673345, disc_loss = 0.1580917507135233
Trained batch 244 in epoch 0, gen_loss = 0.4454772022913913, disc_loss = 0.1582546055773083
Trained batch 245 in epoch 0, gen_loss = 0.4452324828844729, disc_loss = 0.15838633888075507
Trained batch 246 in epoch 0, gen_loss = 0.4453196537036162, disc_loss = 0.15846156481246235
Trained batch 247 in epoch 0, gen_loss = 0.44494229885599307, disc_loss = 0.15882758091714594
Trained batch 248 in epoch 0, gen_loss = 0.44468584351510887, disc_loss = 0.15927633659607435
Trained batch 249 in epoch 0, gen_loss = 0.44466223555803297, disc_loss = 0.15922026662528516
Trained batch 250 in epoch 0, gen_loss = 0.44451715111495016, disc_loss = 0.1592338424012718
Trained batch 251 in epoch 0, gen_loss = 0.44406992474955226, disc_loss = 0.15939752158841916
Trained batch 252 in epoch 0, gen_loss = 0.44355018154198944, disc_loss = 0.15952335791331035
Trained batch 253 in epoch 0, gen_loss = 0.4435826629752249, disc_loss = 0.15946038752266273
Trained batch 254 in epoch 0, gen_loss = 0.44306148670467677, disc_loss = 0.16011371137756927
Trained batch 255 in epoch 0, gen_loss = 0.44251621601870283, disc_loss = 0.1617126771452604
Trained batch 256 in epoch 0, gen_loss = 0.44220404547244196, disc_loss = 0.16213282274538904
Trained batch 257 in epoch 0, gen_loss = 0.44210219423669256, disc_loss = 0.1624494715225558
Trained batch 258 in epoch 0, gen_loss = 0.4419621550783688, disc_loss = 0.16260572087062833
Trained batch 259 in epoch 0, gen_loss = 0.4418523247998494, disc_loss = 0.1627498624846339
Trained batch 260 in epoch 0, gen_loss = 0.44157512394632875, disc_loss = 0.16283441947280675
Trained batch 261 in epoch 0, gen_loss = 0.44141440383578073, disc_loss = 0.1628245652034765
Trained batch 262 in epoch 0, gen_loss = 0.4413992351792158, disc_loss = 0.16275570837660433
Trained batch 263 in epoch 0, gen_loss = 0.44121102678279084, disc_loss = 0.16284238895627134
Trained batch 264 in epoch 0, gen_loss = 0.4409990644117571, disc_loss = 0.16305206366023928
Trained batch 265 in epoch 0, gen_loss = 0.4409408788371803, disc_loss = 0.1629545856547311
Trained batch 266 in epoch 0, gen_loss = 0.4409374004781023, disc_loss = 0.16321307307716165
Trained batch 267 in epoch 0, gen_loss = 0.44115568058037047, disc_loss = 0.1632802002548949
Trained batch 268 in epoch 0, gen_loss = 0.44116443279285855, disc_loss = 0.16322849839094847
Trained batch 269 in epoch 0, gen_loss = 0.44088908042068836, disc_loss = 0.16325252032666296
Trained batch 270 in epoch 0, gen_loss = 0.44082879167861166, disc_loss = 0.16345138544031174
Trained batch 271 in epoch 0, gen_loss = 0.44058951982023087, disc_loss = 0.16453260927022817
Trained batch 272 in epoch 0, gen_loss = 0.4404478643512551, disc_loss = 0.1647905005285373
Trained batch 273 in epoch 0, gen_loss = 0.44006307961514396, disc_loss = 0.16485013534063406
Trained batch 274 in epoch 0, gen_loss = 0.4398751469633796, disc_loss = 0.16493236258625985
Trained batch 275 in epoch 0, gen_loss = 0.4397893768829712, disc_loss = 0.1649675577528019
Trained batch 276 in epoch 0, gen_loss = 0.43928389434134485, disc_loss = 0.16507512205935987
Trained batch 277 in epoch 0, gen_loss = 0.4388801140858115, disc_loss = 0.16510103636240359
Trained batch 278 in epoch 0, gen_loss = 0.43865931648293705, disc_loss = 0.1650024094755718
Trained batch 279 in epoch 0, gen_loss = 0.4383811586137329, disc_loss = 0.16499176396589194
Trained batch 280 in epoch 0, gen_loss = 0.43833334998516, disc_loss = 0.1648741749867638
Trained batch 281 in epoch 0, gen_loss = 0.4381391571451586, disc_loss = 0.16503941446067172
Trained batch 282 in epoch 0, gen_loss = 0.437962427419403, disc_loss = 0.16519384442864796
Trained batch 283 in epoch 0, gen_loss = 0.437766736714353, disc_loss = 0.16516521671445858
Trained batch 284 in epoch 0, gen_loss = 0.43756030604504703, disc_loss = 0.16536971078368656
Trained batch 285 in epoch 0, gen_loss = 0.4374334706397323, disc_loss = 0.16555594672429394
Trained batch 286 in epoch 0, gen_loss = 0.43753844068648506, disc_loss = 0.16588179713913373
Trained batch 287 in epoch 0, gen_loss = 0.43748351046815515, disc_loss = 0.16587983205034915
Trained batch 288 in epoch 0, gen_loss = 0.43700922489372507, disc_loss = 0.1658160043912569
Trained batch 289 in epoch 0, gen_loss = 0.43688386416640773, disc_loss = 0.16592201722850058
Trained batch 290 in epoch 0, gen_loss = 0.4369910528876937, disc_loss = 0.16647124258462095
Trained batch 291 in epoch 0, gen_loss = 0.43662540272694744, disc_loss = 0.16653587453526586
Trained batch 292 in epoch 0, gen_loss = 0.4365929026957665, disc_loss = 0.1669001205865637
Trained batch 293 in epoch 0, gen_loss = 0.43659464715897633, disc_loss = 0.16715658703172692
Trained batch 294 in epoch 0, gen_loss = 0.43613783368619824, disc_loss = 0.16720664833309287
Trained batch 295 in epoch 0, gen_loss = 0.4359589102803855, disc_loss = 0.16733047566250772
Trained batch 296 in epoch 0, gen_loss = 0.43558665874229135, disc_loss = 0.16744570889406735
Trained batch 297 in epoch 0, gen_loss = 0.43526274820902205, disc_loss = 0.16751178507786868
Trained batch 298 in epoch 0, gen_loss = 0.43515385418233266, disc_loss = 0.16752409166267085
Trained batch 299 in epoch 0, gen_loss = 0.43513981824119885, disc_loss = 0.16753065142780543
Trained batch 300 in epoch 0, gen_loss = 0.43495274149500257, disc_loss = 0.1675045665885721
Trained batch 301 in epoch 0, gen_loss = 0.43467571389004095, disc_loss = 0.16731497570132184
Trained batch 302 in epoch 0, gen_loss = 0.4346160844902788, disc_loss = 0.16723299949820286
Trained batch 303 in epoch 0, gen_loss = 0.434295783456611, disc_loss = 0.16726888773815804
Trained batch 304 in epoch 0, gen_loss = 0.4342735504029227, disc_loss = 0.16708433941983786
Trained batch 305 in epoch 0, gen_loss = 0.43423284049711974, disc_loss = 0.16698498421293848
Trained batch 306 in epoch 0, gen_loss = 0.4339953097438968, disc_loss = 0.16753903362620925
Trained batch 307 in epoch 0, gen_loss = 0.4339539924902575, disc_loss = 0.1683395661824903
Trained batch 308 in epoch 0, gen_loss = 0.43358323831581375, disc_loss = 0.16851671475278135
Trained batch 309 in epoch 0, gen_loss = 0.43358319281570373, disc_loss = 0.1686996082745252
Trained batch 310 in epoch 0, gen_loss = 0.43347251966260253, disc_loss = 0.16881796579891845
Trained batch 311 in epoch 0, gen_loss = 0.43322162277614457, disc_loss = 0.16881939488200423
Trained batch 312 in epoch 0, gen_loss = 0.43302524399262265, disc_loss = 0.1688355425128731
Trained batch 313 in epoch 0, gen_loss = 0.43272811027279323, disc_loss = 0.16893570596103075
Trained batch 314 in epoch 0, gen_loss = 0.4325884672857466, disc_loss = 0.16892391468087833
Trained batch 315 in epoch 0, gen_loss = 0.4324117459922652, disc_loss = 0.16902187878053776
Trained batch 316 in epoch 0, gen_loss = 0.4320829649358894, disc_loss = 0.16908235971342878
Trained batch 317 in epoch 0, gen_loss = 0.4320620802119843, disc_loss = 0.16898600364677935
Trained batch 318 in epoch 0, gen_loss = 0.4319946162846395, disc_loss = 0.169053589954365
Trained batch 319 in epoch 0, gen_loss = 0.4315685998182744, disc_loss = 0.16910858700284734
Trained batch 320 in epoch 0, gen_loss = 0.4312815784572441, disc_loss = 0.16946362043699
Trained batch 321 in epoch 0, gen_loss = 0.4309786608593064, disc_loss = 0.169677456956565
Trained batch 322 in epoch 0, gen_loss = 0.43095451856360717, disc_loss = 0.16982690746616283
Trained batch 323 in epoch 0, gen_loss = 0.43083704368751724, disc_loss = 0.16974781339781153
Trained batch 324 in epoch 0, gen_loss = 0.430523546062983, disc_loss = 0.16969748676969454
Trained batch 325 in epoch 0, gen_loss = 0.4302218481898308, disc_loss = 0.16958958112800415
Trained batch 326 in epoch 0, gen_loss = 0.4299715738686582, disc_loss = 0.1694914190161301
Trained batch 327 in epoch 0, gen_loss = 0.4297575954711292, disc_loss = 0.1694497859627917
Trained batch 328 in epoch 0, gen_loss = 0.429404820216463, disc_loss = 0.16979163940599623
Trained batch 329 in epoch 0, gen_loss = 0.42948354694879415, disc_loss = 0.17018572553766495
Trained batch 330 in epoch 0, gen_loss = 0.42934333778400074, disc_loss = 0.17019275336152118
Trained batch 331 in epoch 0, gen_loss = 0.42929724132619707, disc_loss = 0.1700662943725306
Trained batch 332 in epoch 0, gen_loss = 0.42929034239358016, disc_loss = 0.17041326850070967
Trained batch 333 in epoch 0, gen_loss = 0.429099680376267, disc_loss = 0.17052950416719484
Trained batch 334 in epoch 0, gen_loss = 0.4289236312926705, disc_loss = 0.1704705011599989
Trained batch 335 in epoch 0, gen_loss = 0.42880220493922633, disc_loss = 0.17031701905874624
Trained batch 336 in epoch 0, gen_loss = 0.42863040547873216, disc_loss = 0.1702526151050623
Trained batch 337 in epoch 0, gen_loss = 0.4285412065288019, disc_loss = 0.17021186847085432
Trained batch 338 in epoch 0, gen_loss = 0.4283895917610433, disc_loss = 0.1706174884024447
Trained batch 339 in epoch 0, gen_loss = 0.42838605523985973, disc_loss = 0.17089365794159034
Trained batch 340 in epoch 0, gen_loss = 0.4281441020913138, disc_loss = 0.17089369647270425
Trained batch 341 in epoch 0, gen_loss = 0.42797095459281354, disc_loss = 0.17081163778944672
Trained batch 342 in epoch 0, gen_loss = 0.4277722813384526, disc_loss = 0.17074669992046176
Trained batch 343 in epoch 0, gen_loss = 0.4276757030206364, disc_loss = 0.1708639272661923
Trained batch 344 in epoch 0, gen_loss = 0.4276146120351294, disc_loss = 0.17079710069557894
Trained batch 345 in epoch 0, gen_loss = 0.42755387598551764, disc_loss = 0.17073177248024182
Trained batch 346 in epoch 0, gen_loss = 0.4274837878406563, disc_loss = 0.17061151653227613
Trained batch 347 in epoch 0, gen_loss = 0.4273673180790468, disc_loss = 0.17048827283641046
Trained batch 348 in epoch 0, gen_loss = 0.42712688091662004, disc_loss = 0.17040071885146862
Trained batch 349 in epoch 0, gen_loss = 0.4272010481783322, disc_loss = 0.17042671666613646
Trained batch 350 in epoch 0, gen_loss = 0.42702708077057133, disc_loss = 0.17049859811225507
Trained batch 351 in epoch 0, gen_loss = 0.4269682175310498, disc_loss = 0.17077695158183237
Trained batch 352 in epoch 0, gen_loss = 0.4265421346547583, disc_loss = 0.17074155557383558
Trained batch 353 in epoch 0, gen_loss = 0.42614028636513457, disc_loss = 0.1707793222371973
Trained batch 354 in epoch 0, gen_loss = 0.42603165444353935, disc_loss = 0.17078882324653613
Trained batch 355 in epoch 0, gen_loss = 0.42620600806025977, disc_loss = 0.17070391693602452
Trained batch 356 in epoch 0, gen_loss = 0.4262713276955928, disc_loss = 0.17122866746549512
Trained batch 357 in epoch 0, gen_loss = 0.42619893458468955, disc_loss = 0.17114152716649644
Trained batch 358 in epoch 0, gen_loss = 0.4258612978342184, disc_loss = 0.17115678850945323
Trained batch 359 in epoch 0, gen_loss = 0.425688145433863, disc_loss = 0.1713687553898328
Trained batch 360 in epoch 0, gen_loss = 0.42559766426806306, disc_loss = 0.17148533103332295
Trained batch 361 in epoch 0, gen_loss = 0.42537051081163446, disc_loss = 0.17151472411885116
Trained batch 362 in epoch 0, gen_loss = 0.42528837553889953, disc_loss = 0.17155314980911157
Trained batch 363 in epoch 0, gen_loss = 0.4251063295363725, disc_loss = 0.1714467997304522
Trained batch 364 in epoch 0, gen_loss = 0.42510739658793356, disc_loss = 0.17143857967976023
Trained batch 365 in epoch 0, gen_loss = 0.4248901732225236, disc_loss = 0.17170843684567455
Trained batch 366 in epoch 0, gen_loss = 0.42498958423449495, disc_loss = 0.17214640519234076
Trained batch 367 in epoch 0, gen_loss = 0.4248249741757046, disc_loss = 0.17219059767565972
Trained batch 368 in epoch 0, gen_loss = 0.42457700813527355, disc_loss = 0.17233737656054135
Trained batch 369 in epoch 0, gen_loss = 0.4245981659035425, disc_loss = 0.17219540236165395
Trained batch 370 in epoch 0, gen_loss = 0.424632284719989, disc_loss = 0.1723119398112085
Trained batch 371 in epoch 0, gen_loss = 0.4246717995453265, disc_loss = 0.17210212755467622
Trained batch 372 in epoch 0, gen_loss = 0.4246829997039033, disc_loss = 0.17204726122859015
Trained batch 373 in epoch 0, gen_loss = 0.42460842944562116, disc_loss = 0.17190583557249073
Trained batch 374 in epoch 0, gen_loss = 0.424485161503156, disc_loss = 0.17183461571733158
Trained batch 375 in epoch 0, gen_loss = 0.424498083941797, disc_loss = 0.17179119013289504
Trained batch 376 in epoch 0, gen_loss = 0.42444533271719986, disc_loss = 0.17202599489918122
Trained batch 377 in epoch 0, gen_loss = 0.424305159302931, disc_loss = 0.17197585899244855
Trained batch 378 in epoch 0, gen_loss = 0.4239342673865975, disc_loss = 0.17196261494526133
Trained batch 379 in epoch 0, gen_loss = 0.42402400590087236, disc_loss = 0.17174872337399344
Trained batch 380 in epoch 0, gen_loss = 0.42426274544767195, disc_loss = 0.17159138703009902
Trained batch 381 in epoch 0, gen_loss = 0.42419280599393144, disc_loss = 0.17139179560877577
Trained batch 382 in epoch 0, gen_loss = 0.4240362301429943, disc_loss = 0.17126511939006125
Trained batch 383 in epoch 0, gen_loss = 0.42365110366760445, disc_loss = 0.171478403606064
Trained batch 384 in epoch 0, gen_loss = 0.4237362632116714, disc_loss = 0.17161840358144276
Trained batch 385 in epoch 0, gen_loss = 0.4235162949237799, disc_loss = 0.17163992567962624
Trained batch 386 in epoch 0, gen_loss = 0.4233294576406479, disc_loss = 0.17211586336102289
Trained batch 387 in epoch 0, gen_loss = 0.4233259014478049, disc_loss = 0.17284348560017102
Trained batch 388 in epoch 0, gen_loss = 0.42301476036215196, disc_loss = 0.17301459598012633
Trained batch 389 in epoch 0, gen_loss = 0.42291338997773636, disc_loss = 0.1732917495167408
Trained batch 390 in epoch 0, gen_loss = 0.42260828351273255, disc_loss = 0.17344532208636287
Trained batch 391 in epoch 0, gen_loss = 0.42241757990298223, disc_loss = 0.17358314917821968
Trained batch 392 in epoch 0, gen_loss = 0.4221582424473823, disc_loss = 0.1736029334480071
Trained batch 393 in epoch 0, gen_loss = 0.42211265086673844, disc_loss = 0.17358843633328294
Trained batch 394 in epoch 0, gen_loss = 0.4219975136880633, disc_loss = 0.1735538381470155
Trained batch 395 in epoch 0, gen_loss = 0.4220652270572956, disc_loss = 0.1735059983859008
Trained batch 396 in epoch 0, gen_loss = 0.4218388668611008, disc_loss = 0.17355021368008416
Trained batch 397 in epoch 0, gen_loss = 0.4217421147766425, disc_loss = 0.17374168320479405
Trained batch 398 in epoch 0, gen_loss = 0.4216291803241075, disc_loss = 0.17376811136689999
Trained batch 399 in epoch 0, gen_loss = 0.4215594629570842, disc_loss = 0.17361298504285513
Trained batch 400 in epoch 0, gen_loss = 0.42135288928660963, disc_loss = 0.17362057771580178
Trained batch 401 in epoch 0, gen_loss = 0.4212023660688851, disc_loss = 0.17362254341851122
Trained batch 402 in epoch 0, gen_loss = 0.42098157521956614, disc_loss = 0.17387948677905143
Trained batch 403 in epoch 0, gen_loss = 0.4210500863592814, disc_loss = 0.1736891300943081
Trained batch 404 in epoch 0, gen_loss = 0.42066630901377877, disc_loss = 0.17366989044311607
Trained batch 405 in epoch 0, gen_loss = 0.4204401206867448, disc_loss = 0.17359928631687105
Trained batch 406 in epoch 0, gen_loss = 0.4204135117205707, disc_loss = 0.17353157116059004
Trained batch 407 in epoch 0, gen_loss = 0.42032094164660166, disc_loss = 0.17342151992716917
Trained batch 408 in epoch 0, gen_loss = 0.42038262630004464, disc_loss = 0.17325739818454372
Trained batch 409 in epoch 0, gen_loss = 0.4203278355845591, disc_loss = 0.17329449389220739
Trained batch 410 in epoch 0, gen_loss = 0.4201537186864519, disc_loss = 0.1736157421666195
Trained batch 411 in epoch 0, gen_loss = 0.41997553013916156, disc_loss = 0.17410213729023066
Trained batch 412 in epoch 0, gen_loss = 0.41968009803110407, disc_loss = 0.17407972967256646
Trained batch 413 in epoch 0, gen_loss = 0.41948797150654493, disc_loss = 0.1741865397237493
Trained batch 414 in epoch 0, gen_loss = 0.41938895680100086, disc_loss = 0.1741590265857886
Trained batch 415 in epoch 0, gen_loss = 0.41934991610021544, disc_loss = 0.17407642449073207
Trained batch 416 in epoch 0, gen_loss = 0.41928026591130585, disc_loss = 0.17404999425835746
Trained batch 417 in epoch 0, gen_loss = 0.419334286387172, disc_loss = 0.17394100144755043
Trained batch 418 in epoch 0, gen_loss = 0.4192718417874953, disc_loss = 0.17399165020957766
Trained batch 419 in epoch 0, gen_loss = 0.4190628622614202, disc_loss = 0.1741073480762896
Trained batch 420 in epoch 0, gen_loss = 0.41888829028663044, disc_loss = 0.1740113574737183
Trained batch 421 in epoch 0, gen_loss = 0.41866904818474965, disc_loss = 0.17393874028318018
Trained batch 422 in epoch 0, gen_loss = 0.41858884554805487, disc_loss = 0.1740113681811954
Trained batch 423 in epoch 0, gen_loss = 0.4185273088866247, disc_loss = 0.17427181267126832
Trained batch 424 in epoch 0, gen_loss = 0.41824761001502764, disc_loss = 0.17428197465398731
Trained batch 425 in epoch 0, gen_loss = 0.41798766667434306, disc_loss = 0.17424980223073927
Trained batch 426 in epoch 0, gen_loss = 0.4180285783715773, disc_loss = 0.17419322216294408
Trained batch 427 in epoch 0, gen_loss = 0.417891295887878, disc_loss = 0.17405789858165466
Trained batch 428 in epoch 0, gen_loss = 0.4178580094675918, disc_loss = 0.17381640053886077
Trained batch 429 in epoch 0, gen_loss = 0.4178464740861294, disc_loss = 0.17370470877476904
Trained batch 430 in epoch 0, gen_loss = 0.4178123352076781, disc_loss = 0.17361436906138872
Trained batch 431 in epoch 0, gen_loss = 0.41775176649982176, disc_loss = 0.17359562312183832
Trained batch 432 in epoch 0, gen_loss = 0.41767285647210567, disc_loss = 0.17378923493947224
Trained batch 433 in epoch 0, gen_loss = 0.417583477421565, disc_loss = 0.17384316944753245
Trained batch 434 in epoch 0, gen_loss = 0.417615806679616, disc_loss = 0.1737217047176827
Trained batch 435 in epoch 0, gen_loss = 0.4174830000676693, disc_loss = 0.17353704680235835
Trained batch 436 in epoch 0, gen_loss = 0.4175288167439009, disc_loss = 0.17349377410055844
Trained batch 437 in epoch 0, gen_loss = 0.4173919964394613, disc_loss = 0.1735814716156623
Trained batch 438 in epoch 0, gen_loss = 0.4173724776587888, disc_loss = 0.17395035901312675
Trained batch 439 in epoch 0, gen_loss = 0.41732344854284414, disc_loss = 0.17384219995107164
Trained batch 440 in epoch 0, gen_loss = 0.4171426642576313, disc_loss = 0.17422897318830025
Trained batch 441 in epoch 0, gen_loss = 0.4170914432244603, disc_loss = 0.1743260162431595
Trained batch 442 in epoch 0, gen_loss = 0.41675799987520645, disc_loss = 0.17445183660557523
Trained batch 443 in epoch 0, gen_loss = 0.41659596746972016, disc_loss = 0.17452926577177938
Trained batch 444 in epoch 0, gen_loss = 0.41630377424566933, disc_loss = 0.17458561289678798
Trained batch 445 in epoch 0, gen_loss = 0.4162770697153737, disc_loss = 0.17458325947714226
Trained batch 446 in epoch 0, gen_loss = 0.416386161241222, disc_loss = 0.1744068495562546
Trained batch 447 in epoch 0, gen_loss = 0.41627599807855276, disc_loss = 0.1742535748968034
Trained batch 448 in epoch 0, gen_loss = 0.4161509251209569, disc_loss = 0.1741958518983394
Trained batch 449 in epoch 0, gen_loss = 0.4161501470870442, disc_loss = 0.17424431127806506
Trained batch 450 in epoch 0, gen_loss = 0.4158427909908696, disc_loss = 0.1742079207330876
Trained batch 451 in epoch 0, gen_loss = 0.41582351649361377, disc_loss = 0.17420528940361948
Trained batch 452 in epoch 0, gen_loss = 0.41579785327906116, disc_loss = 0.1742485715508066
Trained batch 453 in epoch 0, gen_loss = 0.41562062800587013, disc_loss = 0.17418878006088315
Trained batch 454 in epoch 0, gen_loss = 0.41575932584621095, disc_loss = 0.17409899777599744
Trained batch 455 in epoch 0, gen_loss = 0.4156294905891021, disc_loss = 0.17399887602547542
Trained batch 456 in epoch 0, gen_loss = 0.4154174281223076, disc_loss = 0.17412472347559763
Trained batch 457 in epoch 0, gen_loss = 0.4154053293656574, disc_loss = 0.17394398999559046
Trained batch 458 in epoch 0, gen_loss = 0.4154717151181111, disc_loss = 0.17389793198125555
Trained batch 459 in epoch 0, gen_loss = 0.4153014751556127, disc_loss = 0.17389352610739678
Trained batch 460 in epoch 0, gen_loss = 0.4152346859461832, disc_loss = 0.1737813731804975
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 0.31659725308418274, disc_loss = 0.1221766471862793
Trained batch 1 in epoch 1, gen_loss = 0.3356883227825165, disc_loss = 0.13037098944187164
Trained batch 2 in epoch 1, gen_loss = 0.35629231731096905, disc_loss = 0.1370268315076828
Trained batch 3 in epoch 1, gen_loss = 0.37025874108076096, disc_loss = 0.16931481286883354
Trained batch 4 in epoch 1, gen_loss = 0.37547693252563474, disc_loss = 0.17910422384738922
Trained batch 5 in epoch 1, gen_loss = 0.3813731521368027, disc_loss = 0.1797285626331965
Trained batch 6 in epoch 1, gen_loss = 0.3819580248423985, disc_loss = 0.16822707865919387
Trained batch 7 in epoch 1, gen_loss = 0.3823082521557808, disc_loss = 0.16900798678398132
Trained batch 8 in epoch 1, gen_loss = 0.3808966345257229, disc_loss = 0.17805063062243992
Trained batch 9 in epoch 1, gen_loss = 0.3789166986942291, disc_loss = 0.17962161600589752
Trained batch 10 in epoch 1, gen_loss = 0.37381808866154065, disc_loss = 0.18634787472811612
Trained batch 11 in epoch 1, gen_loss = 0.3782198776801427, disc_loss = 0.2026605283220609
Trained batch 12 in epoch 1, gen_loss = 0.37529810804587144, disc_loss = 0.20592630482636964
Trained batch 13 in epoch 1, gen_loss = 0.3672765280519213, disc_loss = 0.21310817237411225
Trained batch 14 in epoch 1, gen_loss = 0.375580902894338, disc_loss = 0.2117094228665034
Trained batch 15 in epoch 1, gen_loss = 0.3773945551365614, disc_loss = 0.21055974438786507
Trained batch 16 in epoch 1, gen_loss = 0.3782791618038626, disc_loss = 0.20619665787500494
Trained batch 17 in epoch 1, gen_loss = 0.37894435889191097, disc_loss = 0.20436061090893215
Trained batch 18 in epoch 1, gen_loss = 0.38090554507155167, disc_loss = 0.20018258063416733
Trained batch 19 in epoch 1, gen_loss = 0.37972732782363894, disc_loss = 0.19314724765717983
Trained batch 20 in epoch 1, gen_loss = 0.3764459717841375, disc_loss = 0.19453982760508856
Trained batch 21 in epoch 1, gen_loss = 0.37964950095523486, disc_loss = 0.1900575872172009
Trained batch 22 in epoch 1, gen_loss = 0.3843524326448855, disc_loss = 0.1876493653525477
Trained batch 23 in epoch 1, gen_loss = 0.38246364519000053, disc_loss = 0.1844729483127594
Trained batch 24 in epoch 1, gen_loss = 0.3836109232902527, disc_loss = 0.18204880475997925
Trained batch 25 in epoch 1, gen_loss = 0.3847768467206221, disc_loss = 0.1787986675134072
Trained batch 26 in epoch 1, gen_loss = 0.38377064245718495, disc_loss = 0.17882454450483676
Trained batch 27 in epoch 1, gen_loss = 0.38040406150477274, disc_loss = 0.19132241234183311
Trained batch 28 in epoch 1, gen_loss = 0.3824590701481392, disc_loss = 0.1906403380221334
Trained batch 29 in epoch 1, gen_loss = 0.3835616707801819, disc_loss = 0.18846215605735778
Trained batch 30 in epoch 1, gen_loss = 0.38329954974112973, disc_loss = 0.1867637009389939
Trained batch 31 in epoch 1, gen_loss = 0.38355648797005415, disc_loss = 0.18450044933706522
Trained batch 32 in epoch 1, gen_loss = 0.38523344560102984, disc_loss = 0.18266214452909701
Trained batch 33 in epoch 1, gen_loss = 0.38474153858773846, disc_loss = 0.18058121357770526
Trained batch 34 in epoch 1, gen_loss = 0.3864851142678942, disc_loss = 0.1808764915381159
Trained batch 35 in epoch 1, gen_loss = 0.38622766236464184, disc_loss = 0.18249994537068737
Trained batch 36 in epoch 1, gen_loss = 0.3862076619186917, disc_loss = 0.18107746360269752
Trained batch 37 in epoch 1, gen_loss = 0.3840776870125218, disc_loss = 0.18241182459812416
Trained batch 38 in epoch 1, gen_loss = 0.3839111106517987, disc_loss = 0.18299273859996062
Trained batch 39 in epoch 1, gen_loss = 0.3857294872403145, disc_loss = 0.18085659760981798
Trained batch 40 in epoch 1, gen_loss = 0.38552128759826104, disc_loss = 0.1804870267103358
Trained batch 41 in epoch 1, gen_loss = 0.3846678315174012, disc_loss = 0.17959572392560186
Trained batch 42 in epoch 1, gen_loss = 0.384506716284641, disc_loss = 0.1788060673794081
Trained batch 43 in epoch 1, gen_loss = 0.38535216450691223, disc_loss = 0.17887160063467242
Trained batch 44 in epoch 1, gen_loss = 0.3849304623074002, disc_loss = 0.17745604465405146
Trained batch 45 in epoch 1, gen_loss = 0.38605617116326874, disc_loss = 0.17562383818237678
Trained batch 46 in epoch 1, gen_loss = 0.3856502765036644, disc_loss = 0.17445546689819783
Trained batch 47 in epoch 1, gen_loss = 0.385432127242287, disc_loss = 0.17582217153782645
Trained batch 48 in epoch 1, gen_loss = 0.385637102686629, disc_loss = 0.17691945558299824
Trained batch 49 in epoch 1, gen_loss = 0.38630642294883727, disc_loss = 0.17577938005328178
Trained batch 50 in epoch 1, gen_loss = 0.38726648980495976, disc_loss = 0.17564449284006567
Trained batch 51 in epoch 1, gen_loss = 0.3878008396579669, disc_loss = 0.17362069381544223
Trained batch 52 in epoch 1, gen_loss = 0.38540645815291497, disc_loss = 0.17275672968266145
Trained batch 53 in epoch 1, gen_loss = 0.3849923930786274, disc_loss = 0.1719411350786686
Trained batch 54 in epoch 1, gen_loss = 0.38554826162078165, disc_loss = 0.1700893053954298
Trained batch 55 in epoch 1, gen_loss = 0.38555885425635744, disc_loss = 0.16949488581823452
Trained batch 56 in epoch 1, gen_loss = 0.3861120405950044, disc_loss = 0.17062539476574512
Trained batch 57 in epoch 1, gen_loss = 0.38686254620552063, disc_loss = 0.1687693583040402
Trained batch 58 in epoch 1, gen_loss = 0.3862453542523465, disc_loss = 0.16781250450570703
Trained batch 59 in epoch 1, gen_loss = 0.38624824583530426, disc_loss = 0.16593776879211267
Trained batch 60 in epoch 1, gen_loss = 0.38567411362147724, disc_loss = 0.16496706045553333
Trained batch 61 in epoch 1, gen_loss = 0.3849388509988785, disc_loss = 0.16413986622806517
Trained batch 62 in epoch 1, gen_loss = 0.3868924507072994, disc_loss = 0.16408597583335544
Trained batch 63 in epoch 1, gen_loss = 0.3874095380306244, disc_loss = 0.16269682778511196
Trained batch 64 in epoch 1, gen_loss = 0.38816173718525815, disc_loss = 0.16670614629983901
Trained batch 65 in epoch 1, gen_loss = 0.3884148665449836, disc_loss = 0.16835588363535475
Trained batch 66 in epoch 1, gen_loss = 0.3890196107216735, disc_loss = 0.16789556205717485
Trained batch 67 in epoch 1, gen_loss = 0.38756003099329334, disc_loss = 0.16921713323715856
Trained batch 68 in epoch 1, gen_loss = 0.38734610529913416, disc_loss = 0.16854500846154447
Trained batch 69 in epoch 1, gen_loss = 0.38661547090326037, disc_loss = 0.16865480148366518
Trained batch 70 in epoch 1, gen_loss = 0.387244764767902, disc_loss = 0.16752333550805776
Trained batch 71 in epoch 1, gen_loss = 0.3866680868797832, disc_loss = 0.16755271941009495
Trained batch 72 in epoch 1, gen_loss = 0.386441416119876, disc_loss = 0.1693250229709769
Trained batch 73 in epoch 1, gen_loss = 0.3861347569807156, disc_loss = 0.1691452215450841
Trained batch 74 in epoch 1, gen_loss = 0.3863188827037811, disc_loss = 0.16772843877474466
Trained batch 75 in epoch 1, gen_loss = 0.3866653767855544, disc_loss = 0.16795683730589717
Trained batch 76 in epoch 1, gen_loss = 0.38621976855513335, disc_loss = 0.16742492844532061
Trained batch 77 in epoch 1, gen_loss = 0.3861735829940209, disc_loss = 0.16692626514495948
Trained batch 78 in epoch 1, gen_loss = 0.38576260322256933, disc_loss = 0.16627613879457304
Trained batch 79 in epoch 1, gen_loss = 0.38529130779206755, disc_loss = 0.16650626435875893
Trained batch 80 in epoch 1, gen_loss = 0.3863862822821111, disc_loss = 0.16641500058733386
Trained batch 81 in epoch 1, gen_loss = 0.3866081466762031, disc_loss = 0.1651897565802423
Trained batch 82 in epoch 1, gen_loss = 0.38625597127948896, disc_loss = 0.1645842889346272
Trained batch 83 in epoch 1, gen_loss = 0.3864268685380618, disc_loss = 0.16377317603854907
Trained batch 84 in epoch 1, gen_loss = 0.3863747856196235, disc_loss = 0.162915901927387
Trained batch 85 in epoch 1, gen_loss = 0.3859321637902149, disc_loss = 0.16228568250703257
Trained batch 86 in epoch 1, gen_loss = 0.3844897462718788, disc_loss = 0.16169675379648976
Trained batch 87 in epoch 1, gen_loss = 0.3844165602190928, disc_loss = 0.16148042424835943
Trained batch 88 in epoch 1, gen_loss = 0.3835433651222272, disc_loss = 0.16147835602921046
Trained batch 89 in epoch 1, gen_loss = 0.3839490595791075, disc_loss = 0.1627922770049837
Trained batch 90 in epoch 1, gen_loss = 0.3842675027611491, disc_loss = 0.16516127723913926
Trained batch 91 in epoch 1, gen_loss = 0.384907819006754, disc_loss = 0.16715382331091425
Trained batch 92 in epoch 1, gen_loss = 0.38492665944560883, disc_loss = 0.1663412453346355
Trained batch 93 in epoch 1, gen_loss = 0.38562095609117064, disc_loss = 0.16618462239808224
Trained batch 94 in epoch 1, gen_loss = 0.3855185693816135, disc_loss = 0.16566264597993147
Trained batch 95 in epoch 1, gen_loss = 0.385584215944012, disc_loss = 0.165257448485742
Trained batch 96 in epoch 1, gen_loss = 0.3858064191857564, disc_loss = 0.16451823235172586
Trained batch 97 in epoch 1, gen_loss = 0.38593751769893025, disc_loss = 0.16408923306331344
Trained batch 98 in epoch 1, gen_loss = 0.38662534651130137, disc_loss = 0.16347611078409233
Trained batch 99 in epoch 1, gen_loss = 0.3868018391728401, disc_loss = 0.16390348114073278
Trained batch 100 in epoch 1, gen_loss = 0.385960315713788, disc_loss = 0.16403327210999952
Trained batch 101 in epoch 1, gen_loss = 0.3864370531895581, disc_loss = 0.16510365340931743
Trained batch 102 in epoch 1, gen_loss = 0.38582669646994583, disc_loss = 0.16520923339915508
Trained batch 103 in epoch 1, gen_loss = 0.38498611003160477, disc_loss = 0.1650033497896332
Trained batch 104 in epoch 1, gen_loss = 0.38453268181710015, disc_loss = 0.16580839235158193
Trained batch 105 in epoch 1, gen_loss = 0.38532112566929944, disc_loss = 0.16604216516299067
Trained batch 106 in epoch 1, gen_loss = 0.38553096145112936, disc_loss = 0.16519139038625164
Trained batch 107 in epoch 1, gen_loss = 0.385462484701916, disc_loss = 0.16482578148996388
Trained batch 108 in epoch 1, gen_loss = 0.38496621869025976, disc_loss = 0.16532692340535854
Trained batch 109 in epoch 1, gen_loss = 0.3850551057945598, disc_loss = 0.1652137902649966
Trained batch 110 in epoch 1, gen_loss = 0.38621066658346503, disc_loss = 0.16502853060090864
Trained batch 111 in epoch 1, gen_loss = 0.3862203383552177, disc_loss = 0.1646049817624901
Trained batch 112 in epoch 1, gen_loss = 0.3864240846802703, disc_loss = 0.16467627863177156
Trained batch 113 in epoch 1, gen_loss = 0.3865163875253577, disc_loss = 0.1639616054793199
Trained batch 114 in epoch 1, gen_loss = 0.3861422033413597, disc_loss = 0.16339336957620537
Trained batch 115 in epoch 1, gen_loss = 0.38600044337839917, disc_loss = 0.16229951522987465
Trained batch 116 in epoch 1, gen_loss = 0.38622414811044675, disc_loss = 0.16212559828900883
Trained batch 117 in epoch 1, gen_loss = 0.3863170677322452, disc_loss = 0.16250357877905086
Trained batch 118 in epoch 1, gen_loss = 0.38652114056739484, disc_loss = 0.16284134620878876
Trained batch 119 in epoch 1, gen_loss = 0.38703441669543587, disc_loss = 0.16236692182719709
Trained batch 120 in epoch 1, gen_loss = 0.3870032754811374, disc_loss = 0.16161685061356254
Trained batch 121 in epoch 1, gen_loss = 0.38718588259376463, disc_loss = 0.16124890274444564
Trained batch 122 in epoch 1, gen_loss = 0.3886929811016331, disc_loss = 0.16141307796162319
Trained batch 123 in epoch 1, gen_loss = 0.3886133865002663, disc_loss = 0.1623962000613251
Trained batch 124 in epoch 1, gen_loss = 0.3887106292247772, disc_loss = 0.162524123609066
Trained batch 125 in epoch 1, gen_loss = 0.38828455029972014, disc_loss = 0.16292252492100473
Trained batch 126 in epoch 1, gen_loss = 0.38820464310683606, disc_loss = 0.16366368972175704
Trained batch 127 in epoch 1, gen_loss = 0.3874682988971472, disc_loss = 0.16476334229810163
Trained batch 128 in epoch 1, gen_loss = 0.3873997268288635, disc_loss = 0.16474472500326098
Trained batch 129 in epoch 1, gen_loss = 0.38746234912138716, disc_loss = 0.1640242749108718
Trained batch 130 in epoch 1, gen_loss = 0.3870159285214111, disc_loss = 0.1634989755640503
Trained batch 131 in epoch 1, gen_loss = 0.3869571828029372, disc_loss = 0.16311053581761592
Trained batch 132 in epoch 1, gen_loss = 0.3871148723856847, disc_loss = 0.16308710931387163
Trained batch 133 in epoch 1, gen_loss = 0.3867797337806047, disc_loss = 0.16452697998107368
Trained batch 134 in epoch 1, gen_loss = 0.38679962908780136, disc_loss = 0.16494238056518412
Trained batch 135 in epoch 1, gen_loss = 0.38660422208554607, disc_loss = 0.16477140970528126
Trained batch 136 in epoch 1, gen_loss = 0.38593558477659295, disc_loss = 0.16507941299546375
Trained batch 137 in epoch 1, gen_loss = 0.38622470459212427, disc_loss = 0.16461832054715225
Trained batch 138 in epoch 1, gen_loss = 0.3859363513455974, disc_loss = 0.1652016690094694
Trained batch 139 in epoch 1, gen_loss = 0.3852704825145858, disc_loss = 0.1656521691807679
Trained batch 140 in epoch 1, gen_loss = 0.38531514769750286, disc_loss = 0.1659439579180792
Trained batch 141 in epoch 1, gen_loss = 0.38518395096483365, disc_loss = 0.16609599672152964
Trained batch 142 in epoch 1, gen_loss = 0.3847431732224418, disc_loss = 0.1663857806812633
Trained batch 143 in epoch 1, gen_loss = 0.38437554157442516, disc_loss = 0.16607238497171137
Trained batch 144 in epoch 1, gen_loss = 0.3844899148776613, disc_loss = 0.16585201477182324
Trained batch 145 in epoch 1, gen_loss = 0.3840527979478444, disc_loss = 0.1656985114494415
Trained batch 146 in epoch 1, gen_loss = 0.38419342851963173, disc_loss = 0.16521288160564138
Trained batch 147 in epoch 1, gen_loss = 0.384127387323895, disc_loss = 0.16539194001942067
Trained batch 148 in epoch 1, gen_loss = 0.3841211603791922, disc_loss = 0.16502316826141922
Trained batch 149 in epoch 1, gen_loss = 0.3843084752559662, disc_loss = 0.16584879418214163
Trained batch 150 in epoch 1, gen_loss = 0.384425855630281, disc_loss = 0.16637568481710574
Trained batch 151 in epoch 1, gen_loss = 0.3838296295388749, disc_loss = 0.16639704139609085
Trained batch 152 in epoch 1, gen_loss = 0.3840393238987019, disc_loss = 0.16626348088379778
Trained batch 153 in epoch 1, gen_loss = 0.38403966984191495, disc_loss = 0.1662369260153213
Trained batch 154 in epoch 1, gen_loss = 0.38338073588186694, disc_loss = 0.16679146059097782
Trained batch 155 in epoch 1, gen_loss = 0.38291306010423565, disc_loss = 0.16673463907761452
Trained batch 156 in epoch 1, gen_loss = 0.38294705520769595, disc_loss = 0.16630260352116483
Trained batch 157 in epoch 1, gen_loss = 0.38297275878206083, disc_loss = 0.16570722330597382
Trained batch 158 in epoch 1, gen_loss = 0.38337816269892566, disc_loss = 0.16518331009824322
Trained batch 159 in epoch 1, gen_loss = 0.38375704232603314, disc_loss = 0.1647258570883423
Trained batch 160 in epoch 1, gen_loss = 0.3835179442944734, disc_loss = 0.1644430527498263
Trained batch 161 in epoch 1, gen_loss = 0.3834228957140887, disc_loss = 0.16466425465028964
Trained batch 162 in epoch 1, gen_loss = 0.3837653354633074, disc_loss = 0.16520199997841947
Trained batch 163 in epoch 1, gen_loss = 0.38409873243512177, disc_loss = 0.16512334578466126
Trained batch 164 in epoch 1, gen_loss = 0.3833859503269196, disc_loss = 0.16500778139540642
Trained batch 165 in epoch 1, gen_loss = 0.3835671258619033, disc_loss = 0.16458545710487538
Trained batch 166 in epoch 1, gen_loss = 0.38385669949525847, disc_loss = 0.1643302381752494
Trained batch 167 in epoch 1, gen_loss = 0.3839410013031392, disc_loss = 0.16350991207928883
Trained batch 168 in epoch 1, gen_loss = 0.3835221336790796, disc_loss = 0.16304112168458793
Trained batch 169 in epoch 1, gen_loss = 0.3836435326758553, disc_loss = 0.16267497355447097
Trained batch 170 in epoch 1, gen_loss = 0.3835173627437904, disc_loss = 0.16228796951254906
Trained batch 171 in epoch 1, gen_loss = 0.3843241685698199, disc_loss = 0.16195752692603788
Trained batch 172 in epoch 1, gen_loss = 0.3840269703051947, disc_loss = 0.162261374897695
Trained batch 173 in epoch 1, gen_loss = 0.384274490434548, disc_loss = 0.1643371758019102
Trained batch 174 in epoch 1, gen_loss = 0.3840162926060813, disc_loss = 0.16457913573299135
Trained batch 175 in epoch 1, gen_loss = 0.38374135846441443, disc_loss = 0.16484726639464498
Trained batch 176 in epoch 1, gen_loss = 0.3836819362842431, disc_loss = 0.16488636891215536
Trained batch 177 in epoch 1, gen_loss = 0.38323543982559377, disc_loss = 0.16461672638072056
Trained batch 178 in epoch 1, gen_loss = 0.3829188463408188, disc_loss = 0.16425623511635393
Trained batch 179 in epoch 1, gen_loss = 0.38235499097241293, disc_loss = 0.16402400773432518
Trained batch 180 in epoch 1, gen_loss = 0.38238527531123295, disc_loss = 0.16380608773363228
Trained batch 181 in epoch 1, gen_loss = 0.38196400348301773, disc_loss = 0.16413661993139392
Trained batch 182 in epoch 1, gen_loss = 0.382398132580877, disc_loss = 0.16445819650842844
Trained batch 183 in epoch 1, gen_loss = 0.38225155858241994, disc_loss = 0.16460627236444017
Trained batch 184 in epoch 1, gen_loss = 0.3822753530901832, disc_loss = 0.16446187375365076
Trained batch 185 in epoch 1, gen_loss = 0.38230653892281236, disc_loss = 0.16487105415072492
Trained batch 186 in epoch 1, gen_loss = 0.3822809045008797, disc_loss = 0.16480826247822156
Trained batch 187 in epoch 1, gen_loss = 0.3822252851851443, disc_loss = 0.1642859039550766
Trained batch 188 in epoch 1, gen_loss = 0.3820508865136949, disc_loss = 0.16423233306754834
Trained batch 189 in epoch 1, gen_loss = 0.38192382266646935, disc_loss = 0.16388255581259728
Trained batch 190 in epoch 1, gen_loss = 0.38181220299286367, disc_loss = 0.1640505993943564
Trained batch 191 in epoch 1, gen_loss = 0.38205063063651323, disc_loss = 0.16411382056927928
Trained batch 192 in epoch 1, gen_loss = 0.3816353618480999, disc_loss = 0.16440235143961685
Trained batch 193 in epoch 1, gen_loss = 0.38180355451156184, disc_loss = 0.16426495297514287
Trained batch 194 in epoch 1, gen_loss = 0.381438309718401, disc_loss = 0.16386802804011566
Trained batch 195 in epoch 1, gen_loss = 0.3818350607643322, disc_loss = 0.16378426129872703
Trained batch 196 in epoch 1, gen_loss = 0.38179992071263075, disc_loss = 0.16436820348658537
Trained batch 197 in epoch 1, gen_loss = 0.3818876698161616, disc_loss = 0.16394723165366384
Trained batch 198 in epoch 1, gen_loss = 0.38179478678272, disc_loss = 0.16338109782892257
Trained batch 199 in epoch 1, gen_loss = 0.38160193428397177, disc_loss = 0.16306702870875597
Trained batch 200 in epoch 1, gen_loss = 0.3817442935794147, disc_loss = 0.1628574734525894
Trained batch 201 in epoch 1, gen_loss = 0.38161548175434074, disc_loss = 0.1635421353327756
Trained batch 202 in epoch 1, gen_loss = 0.38221757370850135, disc_loss = 0.16486272637920427
Trained batch 203 in epoch 1, gen_loss = 0.3823721899705775, disc_loss = 0.16452212335870547
Trained batch 204 in epoch 1, gen_loss = 0.3821717650425143, disc_loss = 0.16427659530465197
Trained batch 205 in epoch 1, gen_loss = 0.38202609729419634, disc_loss = 0.16400628016122337
Trained batch 206 in epoch 1, gen_loss = 0.38175050935883453, disc_loss = 0.1644311772596433
Trained batch 207 in epoch 1, gen_loss = 0.38164490604629886, disc_loss = 0.16461373442927232
Trained batch 208 in epoch 1, gen_loss = 0.3818098687384117, disc_loss = 0.16466501868512642
Trained batch 209 in epoch 1, gen_loss = 0.38158284269628073, disc_loss = 0.16454476181949887
Trained batch 210 in epoch 1, gen_loss = 0.3811532590909027, disc_loss = 0.16435226946362952
Trained batch 211 in epoch 1, gen_loss = 0.38111340943372474, disc_loss = 0.1643272027513891
Trained batch 212 in epoch 1, gen_loss = 0.38132421399506045, disc_loss = 0.16403601787319766
Trained batch 213 in epoch 1, gen_loss = 0.3812698649468823, disc_loss = 0.16409843697029852
Trained batch 214 in epoch 1, gen_loss = 0.38139502683351206, disc_loss = 0.1639511063694954
Trained batch 215 in epoch 1, gen_loss = 0.3813104999286157, disc_loss = 0.16485046136572404
Trained batch 216 in epoch 1, gen_loss = 0.38196888689621256, disc_loss = 0.1655730224356124
Trained batch 217 in epoch 1, gen_loss = 0.3822474005298877, disc_loss = 0.16541792783852016
Trained batch 218 in epoch 1, gen_loss = 0.38198627619982856, disc_loss = 0.1659789661362291
Trained batch 219 in epoch 1, gen_loss = 0.3816988545385274, disc_loss = 0.16582260826094583
Trained batch 220 in epoch 1, gen_loss = 0.38174124244111696, disc_loss = 0.16600394495067552
Trained batch 221 in epoch 1, gen_loss = 0.3816639188979123, disc_loss = 0.1659685822019169
Trained batch 222 in epoch 1, gen_loss = 0.3816611043808172, disc_loss = 0.1660516716105521
Trained batch 223 in epoch 1, gen_loss = 0.381860108114779, disc_loss = 0.16596943303011358
Trained batch 224 in epoch 1, gen_loss = 0.3819357563389672, disc_loss = 0.16610471662547854
Trained batch 225 in epoch 1, gen_loss = 0.3815585784943758, disc_loss = 0.16631159618233157
Trained batch 226 in epoch 1, gen_loss = 0.381307992115945, disc_loss = 0.16703782493191144
Trained batch 227 in epoch 1, gen_loss = 0.38104090251420675, disc_loss = 0.16686391376220344
Trained batch 228 in epoch 1, gen_loss = 0.3811110695376667, disc_loss = 0.16670618551136626
Trained batch 229 in epoch 1, gen_loss = 0.38101135686687804, disc_loss = 0.16630256610072178
Trained batch 230 in epoch 1, gen_loss = 0.3809866262720777, disc_loss = 0.1660358921596498
Trained batch 231 in epoch 1, gen_loss = 0.3808842256408313, disc_loss = 0.16653065489412383
Trained batch 232 in epoch 1, gen_loss = 0.38087109485920917, disc_loss = 0.16627950464323354
Trained batch 233 in epoch 1, gen_loss = 0.38036509902558774, disc_loss = 0.16635343868635658
Trained batch 234 in epoch 1, gen_loss = 0.3805680022594777, disc_loss = 0.16626664022815987
Trained batch 235 in epoch 1, gen_loss = 0.38039084864875017, disc_loss = 0.16666061232276894
Trained batch 236 in epoch 1, gen_loss = 0.3807764450709025, disc_loss = 0.16656498513518506
Trained batch 237 in epoch 1, gen_loss = 0.3807096199578598, disc_loss = 0.1666237882518468
Trained batch 238 in epoch 1, gen_loss = 0.3807279062320997, disc_loss = 0.16687622133283933
Trained batch 239 in epoch 1, gen_loss = 0.3806469009568294, disc_loss = 0.16665674904361366
Trained batch 240 in epoch 1, gen_loss = 0.3805868297938984, disc_loss = 0.16679232561365698
Trained batch 241 in epoch 1, gen_loss = 0.3805722946470434, disc_loss = 0.16662550702198478
Trained batch 242 in epoch 1, gen_loss = 0.38049207180125233, disc_loss = 0.1667963471493603
Trained batch 243 in epoch 1, gen_loss = 0.38050275393685357, disc_loss = 0.16667733881927904
Trained batch 244 in epoch 1, gen_loss = 0.3803982061999185, disc_loss = 0.1664951766327936
Trained batch 245 in epoch 1, gen_loss = 0.38025205188650424, disc_loss = 0.16672387691896137
Trained batch 246 in epoch 1, gen_loss = 0.38042252568098217, disc_loss = 0.16687398470244427
Trained batch 247 in epoch 1, gen_loss = 0.38090564274499494, disc_loss = 0.16696254653675902
Trained batch 248 in epoch 1, gen_loss = 0.3806620783595196, disc_loss = 0.16703252988048348
Trained batch 249 in epoch 1, gen_loss = 0.3807537569999695, disc_loss = 0.16708721742033958
Trained batch 250 in epoch 1, gen_loss = 0.38075755079428986, disc_loss = 0.16696156659330505
Trained batch 251 in epoch 1, gen_loss = 0.3807298321099508, disc_loss = 0.16663855125033666
Trained batch 252 in epoch 1, gen_loss = 0.38057436290465796, disc_loss = 0.16634873869155237
Trained batch 253 in epoch 1, gen_loss = 0.3805386553129812, disc_loss = 0.16627875222699848
Trained batch 254 in epoch 1, gen_loss = 0.3802306385601268, disc_loss = 0.16645580226299808
Trained batch 255 in epoch 1, gen_loss = 0.3806572040775791, disc_loss = 0.16633795574307442
Trained batch 256 in epoch 1, gen_loss = 0.38063757579614216, disc_loss = 0.1662231750409427
Trained batch 257 in epoch 1, gen_loss = 0.3806021863868994, disc_loss = 0.16695754489926404
Trained batch 258 in epoch 1, gen_loss = 0.3809500908529436, disc_loss = 0.16704142582692694
Trained batch 259 in epoch 1, gen_loss = 0.38104772384350116, disc_loss = 0.16678765513575994
Trained batch 260 in epoch 1, gen_loss = 0.38113231962668026, disc_loss = 0.16652039509851813
Trained batch 261 in epoch 1, gen_loss = 0.38085678890916225, disc_loss = 0.1666680176294487
Trained batch 262 in epoch 1, gen_loss = 0.38103199764349616, disc_loss = 0.1668919407029569
Trained batch 263 in epoch 1, gen_loss = 0.38099848479032516, disc_loss = 0.16666076182754655
Trained batch 264 in epoch 1, gen_loss = 0.38095773829604096, disc_loss = 0.16655529346668496
Trained batch 265 in epoch 1, gen_loss = 0.3812008194233242, disc_loss = 0.1664792133733294
Trained batch 266 in epoch 1, gen_loss = 0.3813853971520613, disc_loss = 0.1669822632429305
Trained batch 267 in epoch 1, gen_loss = 0.38113890454840305, disc_loss = 0.16697070033136588
Trained batch 268 in epoch 1, gen_loss = 0.381137275341275, disc_loss = 0.16663155516394895
Trained batch 269 in epoch 1, gen_loss = 0.38136282673588506, disc_loss = 0.1662159550521109
Trained batch 270 in epoch 1, gen_loss = 0.38118464337503777, disc_loss = 0.16625471710059037
Trained batch 271 in epoch 1, gen_loss = 0.38081874873708277, disc_loss = 0.16634609057184527
Trained batch 272 in epoch 1, gen_loss = 0.3807001047300332, disc_loss = 0.16624423141007896
Trained batch 273 in epoch 1, gen_loss = 0.3808327371621654, disc_loss = 0.16630644400189393
Trained batch 274 in epoch 1, gen_loss = 0.3807858331636949, disc_loss = 0.16627475104548714
Trained batch 275 in epoch 1, gen_loss = 0.38038212913965835, disc_loss = 0.16639103108774062
Trained batch 276 in epoch 1, gen_loss = 0.38037055096040995, disc_loss = 0.1664313753051448
Trained batch 277 in epoch 1, gen_loss = 0.3803077788232899, disc_loss = 0.16629096785252043
Trained batch 278 in epoch 1, gen_loss = 0.38055030771908366, disc_loss = 0.16611249355005106
Trained batch 279 in epoch 1, gen_loss = 0.380532236716577, disc_loss = 0.16610445209911892
Trained batch 280 in epoch 1, gen_loss = 0.38041349566704014, disc_loss = 0.16591110003588463
Trained batch 281 in epoch 1, gen_loss = 0.38053198623741774, disc_loss = 0.16572915995163276
Trained batch 282 in epoch 1, gen_loss = 0.3807516918376141, disc_loss = 0.16565828941525504
Trained batch 283 in epoch 1, gen_loss = 0.38106582754514584, disc_loss = 0.16589578697589083
Trained batch 284 in epoch 1, gen_loss = 0.38096566461680226, disc_loss = 0.1659820002944846
Trained batch 285 in epoch 1, gen_loss = 0.38103359176979196, disc_loss = 0.16597286710789153
Trained batch 286 in epoch 1, gen_loss = 0.38142362164288035, disc_loss = 0.16582918572093552
Trained batch 287 in epoch 1, gen_loss = 0.3814898398187425, disc_loss = 0.16571889957413077
Trained batch 288 in epoch 1, gen_loss = 0.3813272210347199, disc_loss = 0.1654532404558469
Trained batch 289 in epoch 1, gen_loss = 0.38135472618300337, disc_loss = 0.16576906897384544
Trained batch 290 in epoch 1, gen_loss = 0.3816596786795613, disc_loss = 0.16598195910351382
Trained batch 291 in epoch 1, gen_loss = 0.3817931140122348, disc_loss = 0.16597324341841757
Trained batch 292 in epoch 1, gen_loss = 0.3818616828413954, disc_loss = 0.16622498725563187
Trained batch 293 in epoch 1, gen_loss = 0.3819339125334811, disc_loss = 0.1664285191214409
Trained batch 294 in epoch 1, gen_loss = 0.38175227440009685, disc_loss = 0.1665052037875531
Trained batch 295 in epoch 1, gen_loss = 0.3819210899842752, disc_loss = 0.16618045177814122
Trained batch 296 in epoch 1, gen_loss = 0.3819774800679499, disc_loss = 0.1660394333930128
Trained batch 297 in epoch 1, gen_loss = 0.381785932803314, disc_loss = 0.16573915345556783
Trained batch 298 in epoch 1, gen_loss = 0.3818398150911299, disc_loss = 0.1653666676934746
Trained batch 299 in epoch 1, gen_loss = 0.3819454867641131, disc_loss = 0.16519652642309665
Trained batch 300 in epoch 1, gen_loss = 0.38197093132722415, disc_loss = 0.1648254665078911
Trained batch 301 in epoch 1, gen_loss = 0.3814404286098796, disc_loss = 0.165106252205885
Trained batch 302 in epoch 1, gen_loss = 0.38151506258316165, disc_loss = 0.16616163373288542
Trained batch 303 in epoch 1, gen_loss = 0.3814015334570094, disc_loss = 0.16603127006735457
Trained batch 304 in epoch 1, gen_loss = 0.38132469351174403, disc_loss = 0.1663079131089273
Trained batch 305 in epoch 1, gen_loss = 0.38148118828246796, disc_loss = 0.1660205772743116
Trained batch 306 in epoch 1, gen_loss = 0.38153932614901165, disc_loss = 0.16595301184960995
Trained batch 307 in epoch 1, gen_loss = 0.3815787196546406, disc_loss = 0.16623895429074764
Trained batch 308 in epoch 1, gen_loss = 0.38156648853064357, disc_loss = 0.166295998570024
Trained batch 309 in epoch 1, gen_loss = 0.381425491167653, disc_loss = 0.16626853430944105
Trained batch 310 in epoch 1, gen_loss = 0.38144084600390343, disc_loss = 0.1661949487121542
Trained batch 311 in epoch 1, gen_loss = 0.3812354485002848, disc_loss = 0.1660842640707508
Trained batch 312 in epoch 1, gen_loss = 0.38103883563520047, disc_loss = 0.16599414811823696
Trained batch 313 in epoch 1, gen_loss = 0.3810926235405503, disc_loss = 0.1661170263816217
Trained batch 314 in epoch 1, gen_loss = 0.38119935535249255, disc_loss = 0.16611494873724286
Trained batch 315 in epoch 1, gen_loss = 0.38103743755741964, disc_loss = 0.16588661880998673
Trained batch 316 in epoch 1, gen_loss = 0.3810393112691043, disc_loss = 0.16576628203647745
Trained batch 317 in epoch 1, gen_loss = 0.3810036744711534, disc_loss = 0.16575835813891213
Trained batch 318 in epoch 1, gen_loss = 0.38096123270480237, disc_loss = 0.16595340807422948
Trained batch 319 in epoch 1, gen_loss = 0.38075109431520104, disc_loss = 0.1663907811511308
Trained batch 320 in epoch 1, gen_loss = 0.3805383250720776, disc_loss = 0.16645119299769773
Trained batch 321 in epoch 1, gen_loss = 0.3806118621774342, disc_loss = 0.1663374979951367
Trained batch 322 in epoch 1, gen_loss = 0.3803954655910055, disc_loss = 0.16641506197467307
Trained batch 323 in epoch 1, gen_loss = 0.3806438779021487, disc_loss = 0.16626349666420323
Trained batch 324 in epoch 1, gen_loss = 0.38053045547925507, disc_loss = 0.1662989714053961
Trained batch 325 in epoch 1, gen_loss = 0.3803068901315057, disc_loss = 0.16634293316514945
Trained batch 326 in epoch 1, gen_loss = 0.3804428447094897, disc_loss = 0.16615952307569143
Trained batch 327 in epoch 1, gen_loss = 0.38064901794238787, disc_loss = 0.1660992884099847
Trained batch 328 in epoch 1, gen_loss = 0.38037939926773584, disc_loss = 0.16616407469322617
Trained batch 329 in epoch 1, gen_loss = 0.38023016913370655, disc_loss = 0.16664630723270504
Trained batch 330 in epoch 1, gen_loss = 0.3802065958249245, disc_loss = 0.167117069832688
Trained batch 331 in epoch 1, gen_loss = 0.38030376159642115, disc_loss = 0.16709257327917829
Trained batch 332 in epoch 1, gen_loss = 0.3803721711979256, disc_loss = 0.16728116408572183
Trained batch 333 in epoch 1, gen_loss = 0.3800594992266444, disc_loss = 0.1672826610327124
Trained batch 334 in epoch 1, gen_loss = 0.38021635101802315, disc_loss = 0.1680358225062712
Trained batch 335 in epoch 1, gen_loss = 0.3801314787318309, disc_loss = 0.16806464990423547
Trained batch 336 in epoch 1, gen_loss = 0.3799893004427324, disc_loss = 0.16811837306804403
Trained batch 337 in epoch 1, gen_loss = 0.3800150746777213, disc_loss = 0.16787484228699165
Trained batch 338 in epoch 1, gen_loss = 0.37996948688431126, disc_loss = 0.16778839902628137
Trained batch 339 in epoch 1, gen_loss = 0.3800081367878353, disc_loss = 0.16765653846018455
Trained batch 340 in epoch 1, gen_loss = 0.3799142085037623, disc_loss = 0.1676023353404663
Trained batch 341 in epoch 1, gen_loss = 0.37981663478745353, disc_loss = 0.16730546942579816
Trained batch 342 in epoch 1, gen_loss = 0.3800642806656507, disc_loss = 0.16698162583498496
Trained batch 343 in epoch 1, gen_loss = 0.3798813028910825, disc_loss = 0.1672006970228151
Trained batch 344 in epoch 1, gen_loss = 0.3798682627470597, disc_loss = 0.16801223132921303
Trained batch 345 in epoch 1, gen_loss = 0.3798675690427681, disc_loss = 0.16825925253030194
Trained batch 346 in epoch 1, gen_loss = 0.379737206511951, disc_loss = 0.1683157469422398
Trained batch 347 in epoch 1, gen_loss = 0.37954922534268476, disc_loss = 0.1681663152044532
Trained batch 348 in epoch 1, gen_loss = 0.37953706200963105, disc_loss = 0.16805109411563435
Trained batch 349 in epoch 1, gen_loss = 0.37932661516325816, disc_loss = 0.16782139471599034
Trained batch 350 in epoch 1, gen_loss = 0.3793647063423765, disc_loss = 0.16774885004062598
Trained batch 351 in epoch 1, gen_loss = 0.3794148884374987, disc_loss = 0.16790307385169648
Trained batch 352 in epoch 1, gen_loss = 0.37928338361529385, disc_loss = 0.16769682044010326
Trained batch 353 in epoch 1, gen_loss = 0.37942117326340435, disc_loss = 0.16744624280323417
Trained batch 354 in epoch 1, gen_loss = 0.3794580623297624, disc_loss = 0.16723317281461098
Trained batch 355 in epoch 1, gen_loss = 0.3794443418135804, disc_loss = 0.1671273120249925
Trained batch 356 in epoch 1, gen_loss = 0.37931402248828683, disc_loss = 0.16715593623513936
Trained batch 357 in epoch 1, gen_loss = 0.3795708152335449, disc_loss = 0.16691343246974757
Trained batch 358 in epoch 1, gen_loss = 0.37979265150917607, disc_loss = 0.1666957304338227
Trained batch 359 in epoch 1, gen_loss = 0.37957688089874053, disc_loss = 0.16669896273977228
Trained batch 360 in epoch 1, gen_loss = 0.37968849822094564, disc_loss = 0.16669112633800243
Trained batch 361 in epoch 1, gen_loss = 0.3798291927707788, disc_loss = 0.1668689424655714
Trained batch 362 in epoch 1, gen_loss = 0.37988995052566216, disc_loss = 0.16682258424844296
Trained batch 363 in epoch 1, gen_loss = 0.3798581857930173, disc_loss = 0.16672998359733884
Trained batch 364 in epoch 1, gen_loss = 0.37989719730533966, disc_loss = 0.16680956699260294
Trained batch 365 in epoch 1, gen_loss = 0.3799871564562855, disc_loss = 0.16678883741950729
Trained batch 366 in epoch 1, gen_loss = 0.3801806967005093, disc_loss = 0.16644945577274226
Trained batch 367 in epoch 1, gen_loss = 0.38032935154826747, disc_loss = 0.16616725827486295
Trained batch 368 in epoch 1, gen_loss = 0.38023348770490506, disc_loss = 0.16632728624917303
Trained batch 369 in epoch 1, gen_loss = 0.38024935819007255, disc_loss = 0.16707851527309095
Trained batch 370 in epoch 1, gen_loss = 0.38038931501843537, disc_loss = 0.16723731492528054
Trained batch 371 in epoch 1, gen_loss = 0.38043208780788607, disc_loss = 0.16808536419424638
Trained batch 372 in epoch 1, gen_loss = 0.3804491183872837, disc_loss = 0.16804121673386793
Trained batch 373 in epoch 1, gen_loss = 0.38038543049983164, disc_loss = 0.16788149588208467
Trained batch 374 in epoch 1, gen_loss = 0.3803858640193939, disc_loss = 0.16769964217146238
Trained batch 375 in epoch 1, gen_loss = 0.38047915372125646, disc_loss = 0.16758104614873834
Trained batch 376 in epoch 1, gen_loss = 0.38069431969910783, disc_loss = 0.16740036306196246
Trained batch 377 in epoch 1, gen_loss = 0.38060046874341513, disc_loss = 0.16745537143969347
Trained batch 378 in epoch 1, gen_loss = 0.3806657875276178, disc_loss = 0.16770714398542305
Trained batch 379 in epoch 1, gen_loss = 0.38047707653359364, disc_loss = 0.16766757795489148
Trained batch 380 in epoch 1, gen_loss = 0.3805366425220109, disc_loss = 0.16801696408569344
Trained batch 381 in epoch 1, gen_loss = 0.3803709598735989, disc_loss = 0.16823002737971188
Trained batch 382 in epoch 1, gen_loss = 0.38059110741079943, disc_loss = 0.168264401050445
Trained batch 383 in epoch 1, gen_loss = 0.38068045148005086, disc_loss = 0.16819758976149993
Trained batch 384 in epoch 1, gen_loss = 0.38069615782081306, disc_loss = 0.1681443098593842
Trained batch 385 in epoch 1, gen_loss = 0.3808453527756923, disc_loss = 0.16847984047867165
Trained batch 386 in epoch 1, gen_loss = 0.38076028866977346, disc_loss = 0.16855088753255146
Trained batch 387 in epoch 1, gen_loss = 0.3806748377140035, disc_loss = 0.16855196431087158
Trained batch 388 in epoch 1, gen_loss = 0.3805241280625596, disc_loss = 0.16872883202139394
Trained batch 389 in epoch 1, gen_loss = 0.38042119878989, disc_loss = 0.16865105287959942
Trained batch 390 in epoch 1, gen_loss = 0.3803832276397959, disc_loss = 0.16854856522453715
Trained batch 391 in epoch 1, gen_loss = 0.3802402088684695, disc_loss = 0.16839528299525988
Trained batch 392 in epoch 1, gen_loss = 0.38018110637143065, disc_loss = 0.16822955659744698
Trained batch 393 in epoch 1, gen_loss = 0.38050510140542454, disc_loss = 0.16820222686806002
Trained batch 394 in epoch 1, gen_loss = 0.3803947452502915, disc_loss = 0.1684553188896632
Trained batch 395 in epoch 1, gen_loss = 0.38053219042944186, disc_loss = 0.16880557417982456
Trained batch 396 in epoch 1, gen_loss = 0.3805577589072268, disc_loss = 0.16866615725216696
Trained batch 397 in epoch 1, gen_loss = 0.380613249899754, disc_loss = 0.16858142295187742
Trained batch 398 in epoch 1, gen_loss = 0.380656557722498, disc_loss = 0.16854520604238474
Trained batch 399 in epoch 1, gen_loss = 0.38088372856378555, disc_loss = 0.1684672812651843
Trained batch 400 in epoch 1, gen_loss = 0.3808398112245926, disc_loss = 0.16835290928396798
Trained batch 401 in epoch 1, gen_loss = 0.38097307627177357, disc_loss = 0.16810651200438909
Trained batch 402 in epoch 1, gen_loss = 0.38093922836313177, disc_loss = 0.16827361613844818
Trained batch 403 in epoch 1, gen_loss = 0.3809664714897033, disc_loss = 0.16873885439432199
Trained batch 404 in epoch 1, gen_loss = 0.3810611797703637, disc_loss = 0.16877308718768166
Trained batch 405 in epoch 1, gen_loss = 0.3810972150029807, disc_loss = 0.16878611288891343
Trained batch 406 in epoch 1, gen_loss = 0.3811055377894596, disc_loss = 0.16892139825063782
Trained batch 407 in epoch 1, gen_loss = 0.3808404529357658, disc_loss = 0.16884021989672499
Trained batch 408 in epoch 1, gen_loss = 0.3809968487411956, disc_loss = 0.16916168802634138
Trained batch 409 in epoch 1, gen_loss = 0.3809877666758328, disc_loss = 0.16925952902472602
Trained batch 410 in epoch 1, gen_loss = 0.3810689345618524, disc_loss = 0.16925038954746113
Trained batch 411 in epoch 1, gen_loss = 0.38110543852581563, disc_loss = 0.16920190835281193
Trained batch 412 in epoch 1, gen_loss = 0.3809834704993712, disc_loss = 0.1690943296953639
Trained batch 413 in epoch 1, gen_loss = 0.381153744559933, disc_loss = 0.16890639807255084
Trained batch 414 in epoch 1, gen_loss = 0.3809945785137544, disc_loss = 0.16889630235641837
Trained batch 415 in epoch 1, gen_loss = 0.38088043600034255, disc_loss = 0.168860268053742
Trained batch 416 in epoch 1, gen_loss = 0.38104452853866044, disc_loss = 0.16883620997663024
Trained batch 417 in epoch 1, gen_loss = 0.38096418720113034, disc_loss = 0.1687173313198335
Trained batch 418 in epoch 1, gen_loss = 0.3810190854322939, disc_loss = 0.16912960397137378
Trained batch 419 in epoch 1, gen_loss = 0.3808584018122582, disc_loss = 0.16942755575513557
Trained batch 420 in epoch 1, gen_loss = 0.3808597534399418, disc_loss = 0.16930555351379364
Trained batch 421 in epoch 1, gen_loss = 0.38108659073074846, disc_loss = 0.16920126235704003
Trained batch 422 in epoch 1, gen_loss = 0.3811262314764884, disc_loss = 0.16906180393928333
Trained batch 423 in epoch 1, gen_loss = 0.38126599584829135, disc_loss = 0.16902898607845857
Trained batch 424 in epoch 1, gen_loss = 0.3812998625110177, disc_loss = 0.16924171346951933
Trained batch 425 in epoch 1, gen_loss = 0.3813109276859973, disc_loss = 0.16930036464522422
Trained batch 426 in epoch 1, gen_loss = 0.38139731592260984, disc_loss = 0.1692919652708381
Trained batch 427 in epoch 1, gen_loss = 0.38126507450208486, disc_loss = 0.16915791658423493
Trained batch 428 in epoch 1, gen_loss = 0.38115376727286476, disc_loss = 0.1690635814793877
Trained batch 429 in epoch 1, gen_loss = 0.3811798476895621, disc_loss = 0.16890614156632922
Trained batch 430 in epoch 1, gen_loss = 0.3811125792649395, disc_loss = 0.16880868820434658
Trained batch 431 in epoch 1, gen_loss = 0.3812646794098395, disc_loss = 0.16859057998388177
Trained batch 432 in epoch 1, gen_loss = 0.381615554350353, disc_loss = 0.16829177628832656
Trained batch 433 in epoch 1, gen_loss = 0.38174459104713754, disc_loss = 0.16807997027575144
Trained batch 434 in epoch 1, gen_loss = 0.38172234536587507, disc_loss = 0.16785059650053924
Trained batch 435 in epoch 1, gen_loss = 0.38178985777798047, disc_loss = 0.1679764839760754
Trained batch 436 in epoch 1, gen_loss = 0.38215784691018423, disc_loss = 0.16826443466223623
Trained batch 437 in epoch 1, gen_loss = 0.3820640529127426, disc_loss = 0.1681210636820423
Trained batch 438 in epoch 1, gen_loss = 0.382087423141562, disc_loss = 0.16803397024411004
Trained batch 439 in epoch 1, gen_loss = 0.38221896595575594, disc_loss = 0.16799036443910814
Trained batch 440 in epoch 1, gen_loss = 0.38233745713082573, disc_loss = 0.1686669412721582
Trained batch 441 in epoch 1, gen_loss = 0.3825675660398751, disc_loss = 0.16867965058638498
Trained batch 442 in epoch 1, gen_loss = 0.38258488082724285, disc_loss = 0.16913638739903408
Trained batch 443 in epoch 1, gen_loss = 0.38265066889223753, disc_loss = 0.16902940867988914
Trained batch 444 in epoch 1, gen_loss = 0.3825855505600404, disc_loss = 0.16897124370162406
Trained batch 445 in epoch 1, gen_loss = 0.3826200631969178, disc_loss = 0.16906923042284533
Trained batch 446 in epoch 1, gen_loss = 0.3824805101958964, disc_loss = 0.16960859472052897
Trained batch 447 in epoch 1, gen_loss = 0.382387305809451, disc_loss = 0.16949944138260825
Trained batch 448 in epoch 1, gen_loss = 0.38232975640647393, disc_loss = 0.16943018944863486
Trained batch 449 in epoch 1, gen_loss = 0.38233941786819037, disc_loss = 0.1692618305153317
Trained batch 450 in epoch 1, gen_loss = 0.3823335026690278, disc_loss = 0.1691351257875859
Trained batch 451 in epoch 1, gen_loss = 0.38245657910551645, disc_loss = 0.16897043208303178
Trained batch 452 in epoch 1, gen_loss = 0.3824607914120419, disc_loss = 0.16874502551542475
Trained batch 453 in epoch 1, gen_loss = 0.3825526240113548, disc_loss = 0.168571833357018
Trained batch 454 in epoch 1, gen_loss = 0.3823553844467624, disc_loss = 0.16856372823099514
Trained batch 455 in epoch 1, gen_loss = 0.38245973716440956, disc_loss = 0.168371245297685
Trained batch 456 in epoch 1, gen_loss = 0.38256811280480096, disc_loss = 0.1681651433265444
Trained batch 457 in epoch 1, gen_loss = 0.38266071267263335, disc_loss = 0.16825488073076222
Trained batch 458 in epoch 1, gen_loss = 0.3828085623925028, disc_loss = 0.1681771824757258
Trained batch 459 in epoch 1, gen_loss = 0.38260609028132064, disc_loss = 0.16870903181640998
Trained batch 460 in epoch 1, gen_loss = 0.3826907521473353, disc_loss = 0.16853405279864975
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 0.3928471803665161, disc_loss = 0.09274711459875107
Trained batch 1 in epoch 2, gen_loss = 0.3638843446969986, disc_loss = 0.1381247378885746
Trained batch 2 in epoch 2, gen_loss = 0.373019943634669, disc_loss = 0.1397899016737938
Trained batch 3 in epoch 2, gen_loss = 0.3787265345454216, disc_loss = 0.15966730006039143
Trained batch 4 in epoch 2, gen_loss = 0.3634710073471069, disc_loss = 0.17149472385644912
Trained batch 5 in epoch 2, gen_loss = 0.3594529132048289, disc_loss = 0.163872379809618
Trained batch 6 in epoch 2, gen_loss = 0.3700666981084006, disc_loss = 0.15893251448869705
Trained batch 7 in epoch 2, gen_loss = 0.3723379857838154, disc_loss = 0.15760332252830267
Trained batch 8 in epoch 2, gen_loss = 0.3634004460440742, disc_loss = 0.15683089279466206
Trained batch 9 in epoch 2, gen_loss = 0.3619071513414383, disc_loss = 0.1609204612672329
Trained batch 10 in epoch 2, gen_loss = 0.371336890892549, disc_loss = 0.15680882063778964
Trained batch 11 in epoch 2, gen_loss = 0.37134067217508954, disc_loss = 0.15482116118073463
Trained batch 12 in epoch 2, gen_loss = 0.3630537253159743, disc_loss = 0.16593659955721635
Trained batch 13 in epoch 2, gen_loss = 0.3661098224776132, disc_loss = 0.16221645793744496
Trained batch 14 in epoch 2, gen_loss = 0.36853615641593934, disc_loss = 0.16081496278444926
Trained batch 15 in epoch 2, gen_loss = 0.36939631402492523, disc_loss = 0.1573199643753469
Trained batch 16 in epoch 2, gen_loss = 0.3738046639105853, disc_loss = 0.15854275621035518
Trained batch 17 in epoch 2, gen_loss = 0.37486206657356685, disc_loss = 0.15866715667976272
Trained batch 18 in epoch 2, gen_loss = 0.37456026673316956, disc_loss = 0.15589744205537595
Trained batch 19 in epoch 2, gen_loss = 0.37467743903398515, disc_loss = 0.15714373104274273
Trained batch 20 in epoch 2, gen_loss = 0.37969339035806204, disc_loss = 0.16558640450239182
Trained batch 21 in epoch 2, gen_loss = 0.3799360909245231, disc_loss = 0.16090017320080238
Trained batch 22 in epoch 2, gen_loss = 0.3793038168679113, disc_loss = 0.16308536898830664
Trained batch 23 in epoch 2, gen_loss = 0.38300463805596036, disc_loss = 0.16211700160056353
Trained batch 24 in epoch 2, gen_loss = 0.38255383133888243, disc_loss = 0.1599266281723976
Trained batch 25 in epoch 2, gen_loss = 0.3815761667031508, disc_loss = 0.15719400546871698
Trained batch 26 in epoch 2, gen_loss = 0.38197368052270675, disc_loss = 0.15479436268409094
Trained batch 27 in epoch 2, gen_loss = 0.3815999999642372, disc_loss = 0.15752195274191244
Trained batch 28 in epoch 2, gen_loss = 0.38206317198687584, disc_loss = 0.16265621395974322
Trained batch 29 in epoch 2, gen_loss = 0.3828458776076635, disc_loss = 0.15895332669218382
Trained batch 30 in epoch 2, gen_loss = 0.3848841805611887, disc_loss = 0.15743460121654695
Trained batch 31 in epoch 2, gen_loss = 0.3827901743352413, disc_loss = 0.15670400741510093
Trained batch 32 in epoch 2, gen_loss = 0.3823277272961356, disc_loss = 0.15548018569296057
Trained batch 33 in epoch 2, gen_loss = 0.38383954412796917, disc_loss = 0.15382713912164464
Trained batch 34 in epoch 2, gen_loss = 0.38477490970066613, disc_loss = 0.15366440968854087
Trained batch 35 in epoch 2, gen_loss = 0.38462141735686195, disc_loss = 0.1523596261524492
Trained batch 36 in epoch 2, gen_loss = 0.38457696018992243, disc_loss = 0.15295922937425407
Trained batch 37 in epoch 2, gen_loss = 0.38387243841823776, disc_loss = 0.15206395266087433
Trained batch 38 in epoch 2, gen_loss = 0.3824786092990484, disc_loss = 0.15285180528194475
Trained batch 39 in epoch 2, gen_loss = 0.38319220915436747, disc_loss = 0.15124431643635033
Trained batch 40 in epoch 2, gen_loss = 0.3833679331511986, disc_loss = 0.15086492041989072
Trained batch 41 in epoch 2, gen_loss = 0.38410177188260214, disc_loss = 0.15159154488217264
Trained batch 42 in epoch 2, gen_loss = 0.38584718316100364, disc_loss = 0.15135703305172366
Trained batch 43 in epoch 2, gen_loss = 0.3878431787545031, disc_loss = 0.1502885175022212
Trained batch 44 in epoch 2, gen_loss = 0.38694931202464633, disc_loss = 0.15606277386347453
Trained batch 45 in epoch 2, gen_loss = 0.3873943919720857, disc_loss = 0.15570516106875046
Trained batch 46 in epoch 2, gen_loss = 0.38730283113236125, disc_loss = 0.15474561570172615
Trained batch 47 in epoch 2, gen_loss = 0.3864067656298478, disc_loss = 0.15355275695522627
Trained batch 48 in epoch 2, gen_loss = 0.38733319968593366, disc_loss = 0.15241884379362575
Trained batch 49 in epoch 2, gen_loss = 0.3882551157474518, disc_loss = 0.1518450377881527
Trained batch 50 in epoch 2, gen_loss = 0.38911329005278794, disc_loss = 0.152383110248575
Trained batch 51 in epoch 2, gen_loss = 0.39159799481813723, disc_loss = 0.15196660834436232
Trained batch 52 in epoch 2, gen_loss = 0.39175045040418516, disc_loss = 0.15186394708898832
Trained batch 53 in epoch 2, gen_loss = 0.39228887690438163, disc_loss = 0.15221711593093695
Trained batch 54 in epoch 2, gen_loss = 0.39330813667990944, disc_loss = 0.15165558050979266
Trained batch 55 in epoch 2, gen_loss = 0.39384980872273445, disc_loss = 0.151394520221012
Trained batch 56 in epoch 2, gen_loss = 0.391928257649405, disc_loss = 0.1525883324313582
Trained batch 57 in epoch 2, gen_loss = 0.39186040337743433, disc_loss = 0.15377919478663082
Trained batch 58 in epoch 2, gen_loss = 0.3917186376401934, disc_loss = 0.15479765074738003
Trained batch 59 in epoch 2, gen_loss = 0.39097303450107573, disc_loss = 0.15377645219365757
Trained batch 60 in epoch 2, gen_loss = 0.3916260375351202, disc_loss = 0.152276908826144
Trained batch 61 in epoch 2, gen_loss = 0.39080156818512946, disc_loss = 0.15214323402652818
Trained batch 62 in epoch 2, gen_loss = 0.38948510137815323, disc_loss = 0.15308259220586884
Trained batch 63 in epoch 2, gen_loss = 0.38927999464794993, disc_loss = 0.15272060252027586
Trained batch 64 in epoch 2, gen_loss = 0.3889564197797042, disc_loss = 0.1515053645349466
Trained batch 65 in epoch 2, gen_loss = 0.388570635156198, disc_loss = 0.15195160647007552
Trained batch 66 in epoch 2, gen_loss = 0.38783100870118214, disc_loss = 0.15290632371359797
Trained batch 67 in epoch 2, gen_loss = 0.38869666483472376, disc_loss = 0.15193263150970726
Trained batch 68 in epoch 2, gen_loss = 0.3887979738090349, disc_loss = 0.15087570266231246
Trained batch 69 in epoch 2, gen_loss = 0.38857478031090326, disc_loss = 0.15129026765269893
Trained batch 70 in epoch 2, gen_loss = 0.3886290423467126, disc_loss = 0.15142102429354695
Trained batch 71 in epoch 2, gen_loss = 0.3877278438044919, disc_loss = 0.15068501932546496
Trained batch 72 in epoch 2, gen_loss = 0.38781721461309143, disc_loss = 0.15166049169963353
Trained batch 73 in epoch 2, gen_loss = 0.3869963409127416, disc_loss = 0.1520203842806655
Trained batch 74 in epoch 2, gen_loss = 0.38688411712646487, disc_loss = 0.1508529012898604
Trained batch 75 in epoch 2, gen_loss = 0.3871211903659921, disc_loss = 0.14991937778694064
Trained batch 76 in epoch 2, gen_loss = 0.3866979278527297, disc_loss = 0.1491811845887017
Trained batch 77 in epoch 2, gen_loss = 0.3878821069613481, disc_loss = 0.14943511760196623
Trained batch 78 in epoch 2, gen_loss = 0.3866146817992005, disc_loss = 0.15020294614796398
Trained batch 79 in epoch 2, gen_loss = 0.3863324798643589, disc_loss = 0.14915346228517593
Trained batch 80 in epoch 2, gen_loss = 0.3869592948460285, disc_loss = 0.14968213259621901
Trained batch 81 in epoch 2, gen_loss = 0.3869194243012405, disc_loss = 0.14974128986458954
Trained batch 82 in epoch 2, gen_loss = 0.3873696399022298, disc_loss = 0.14973645455327378
Trained batch 83 in epoch 2, gen_loss = 0.3879999791582425, disc_loss = 0.15051204272146737
Trained batch 84 in epoch 2, gen_loss = 0.38805935558150795, disc_loss = 0.15021903677021756
Trained batch 85 in epoch 2, gen_loss = 0.38918571174144745, disc_loss = 0.1496804093638825
Trained batch 86 in epoch 2, gen_loss = 0.38906005812787464, disc_loss = 0.14872162065458025
Trained batch 87 in epoch 2, gen_loss = 0.3891942518001253, disc_loss = 0.14882879945534197
Trained batch 88 in epoch 2, gen_loss = 0.38994827163353396, disc_loss = 0.148339519381858
Trained batch 89 in epoch 2, gen_loss = 0.38997683657540216, disc_loss = 0.1477356937610441
Trained batch 90 in epoch 2, gen_loss = 0.38903706872856225, disc_loss = 0.14778467984153673
Trained batch 91 in epoch 2, gen_loss = 0.38942466287509253, disc_loss = 0.14760624556599752
Trained batch 92 in epoch 2, gen_loss = 0.38939350074337375, disc_loss = 0.1486788600763326
Trained batch 93 in epoch 2, gen_loss = 0.3893667646545045, disc_loss = 0.1481777263527855
Trained batch 94 in epoch 2, gen_loss = 0.3896821323194002, disc_loss = 0.14830442733670535
Trained batch 95 in epoch 2, gen_loss = 0.390276827228566, disc_loss = 0.1478534754132852
Trained batch 96 in epoch 2, gen_loss = 0.3895700896523662, disc_loss = 0.1471013001636746
Trained batch 97 in epoch 2, gen_loss = 0.39039539226463865, disc_loss = 0.14597666385222455
Trained batch 98 in epoch 2, gen_loss = 0.3910112778345744, disc_loss = 0.14482663105232546
Trained batch 99 in epoch 2, gen_loss = 0.39117031067609787, disc_loss = 0.14360515400767326
Trained batch 100 in epoch 2, gen_loss = 0.3908005645959684, disc_loss = 0.14278269507507285
Trained batch 101 in epoch 2, gen_loss = 0.39253316089218737, disc_loss = 0.14228141906799055
Trained batch 102 in epoch 2, gen_loss = 0.3922902704442589, disc_loss = 0.14190373982040627
Trained batch 103 in epoch 2, gen_loss = 0.3928906052158429, disc_loss = 0.14148265553208497
Trained batch 104 in epoch 2, gen_loss = 0.39349567322503953, disc_loss = 0.1408262626046226
Trained batch 105 in epoch 2, gen_loss = 0.3934749660064589, disc_loss = 0.14077750930808625
Trained batch 106 in epoch 2, gen_loss = 0.39366769261449297, disc_loss = 0.1400585195450025
Trained batch 107 in epoch 2, gen_loss = 0.39414290449133627, disc_loss = 0.14024652802833804
Trained batch 108 in epoch 2, gen_loss = 0.39363522649905003, disc_loss = 0.14140590546874826
Trained batch 109 in epoch 2, gen_loss = 0.39398678541183474, disc_loss = 0.14128840850158172
Trained batch 110 in epoch 2, gen_loss = 0.39382612839475406, disc_loss = 0.14057377571458216
Trained batch 111 in epoch 2, gen_loss = 0.3939418005091803, disc_loss = 0.14031085199011223
Trained batch 112 in epoch 2, gen_loss = 0.3936134946029798, disc_loss = 0.14005554975134082
Trained batch 113 in epoch 2, gen_loss = 0.3934992201495589, disc_loss = 0.13920524285027855
Trained batch 114 in epoch 2, gen_loss = 0.39366406642872354, disc_loss = 0.13831984452579332
Trained batch 115 in epoch 2, gen_loss = 0.3936904363077262, disc_loss = 0.1389407524517898
Trained batch 116 in epoch 2, gen_loss = 0.39304280917868656, disc_loss = 0.14141946381483322
Trained batch 117 in epoch 2, gen_loss = 0.3935178298566301, disc_loss = 0.14223707985069792
Trained batch 118 in epoch 2, gen_loss = 0.39357832550000743, disc_loss = 0.1420956226457067
Trained batch 119 in epoch 2, gen_loss = 0.3937915657957395, disc_loss = 0.14229871357480686
Trained batch 120 in epoch 2, gen_loss = 0.3939362488502313, disc_loss = 0.14211867146255555
Trained batch 121 in epoch 2, gen_loss = 0.39415613476370204, disc_loss = 0.14169202280826257
Trained batch 122 in epoch 2, gen_loss = 0.39428953038967723, disc_loss = 0.1416075855978136
Trained batch 123 in epoch 2, gen_loss = 0.39335152939442664, disc_loss = 0.14209263218987372
Trained batch 124 in epoch 2, gen_loss = 0.3935797905921936, disc_loss = 0.14186631393432617
Trained batch 125 in epoch 2, gen_loss = 0.3936053171517357, disc_loss = 0.14118854246205753
Trained batch 126 in epoch 2, gen_loss = 0.39292279918362777, disc_loss = 0.1412257279350063
Trained batch 127 in epoch 2, gen_loss = 0.3924363791011274, disc_loss = 0.14122382301138714
Trained batch 128 in epoch 2, gen_loss = 0.3929562596387641, disc_loss = 0.1409311081434405
Trained batch 129 in epoch 2, gen_loss = 0.39314655638658086, disc_loss = 0.1404606346327525
Trained batch 130 in epoch 2, gen_loss = 0.3927473111917044, disc_loss = 0.13980330196955731
Trained batch 131 in epoch 2, gen_loss = 0.3935283083807338, disc_loss = 0.13891109790314327
Trained batch 132 in epoch 2, gen_loss = 0.3933382811851071, disc_loss = 0.13801079086567225
Trained batch 133 in epoch 2, gen_loss = 0.39351203570615, disc_loss = 0.13751465643742192
Trained batch 134 in epoch 2, gen_loss = 0.3932329391991651, disc_loss = 0.1381710555266451
Trained batch 135 in epoch 2, gen_loss = 0.39366133971249356, disc_loss = 0.13928150730755398
Trained batch 136 in epoch 2, gen_loss = 0.39365097771595864, disc_loss = 0.1390252521764623
Trained batch 137 in epoch 2, gen_loss = 0.39441906326058984, disc_loss = 0.14027386898363847
Trained batch 138 in epoch 2, gen_loss = 0.39415964162606987, disc_loss = 0.14182848011632618
Trained batch 139 in epoch 2, gen_loss = 0.39432730568306784, disc_loss = 0.14141489368464266
Trained batch 140 in epoch 2, gen_loss = 0.39519192584862944, disc_loss = 0.14095558511449935
Trained batch 141 in epoch 2, gen_loss = 0.39503601319353343, disc_loss = 0.1407967898207651
Trained batch 142 in epoch 2, gen_loss = 0.39482499711163394, disc_loss = 0.1403563479547734
Trained batch 143 in epoch 2, gen_loss = 0.3944485342750947, disc_loss = 0.14068086626422074
Trained batch 144 in epoch 2, gen_loss = 0.39431634154813044, disc_loss = 0.1421358794487756
Trained batch 145 in epoch 2, gen_loss = 0.3934926043634545, disc_loss = 0.14196625275358762
Trained batch 146 in epoch 2, gen_loss = 0.39319836059395147, disc_loss = 0.141895720899916
Trained batch 147 in epoch 2, gen_loss = 0.3934613184348957, disc_loss = 0.14252183188659115
Trained batch 148 in epoch 2, gen_loss = 0.39362157151203025, disc_loss = 0.14220572142993043
Trained batch 149 in epoch 2, gen_loss = 0.39353766242663063, disc_loss = 0.141992976218462
Trained batch 150 in epoch 2, gen_loss = 0.39389035243861725, disc_loss = 0.1417450916194758
Trained batch 151 in epoch 2, gen_loss = 0.39319077094918803, disc_loss = 0.14178466860597072
Trained batch 152 in epoch 2, gen_loss = 0.3930767593430538, disc_loss = 0.14149502177838408
Trained batch 153 in epoch 2, gen_loss = 0.3934128234138736, disc_loss = 0.14118228228641794
Trained batch 154 in epoch 2, gen_loss = 0.3934856697436302, disc_loss = 0.14075017210937316
Trained batch 155 in epoch 2, gen_loss = 0.39295200048348844, disc_loss = 0.14034623896273282
Trained batch 156 in epoch 2, gen_loss = 0.39266175126573843, disc_loss = 0.14059359295542834
Trained batch 157 in epoch 2, gen_loss = 0.3927448061825354, disc_loss = 0.14260826651242714
Trained batch 158 in epoch 2, gen_loss = 0.392381100347207, disc_loss = 0.14214479309395425
Trained batch 159 in epoch 2, gen_loss = 0.39170820247381927, disc_loss = 0.14182187621481718
Trained batch 160 in epoch 2, gen_loss = 0.3913062118595431, disc_loss = 0.14122869680572
Trained batch 161 in epoch 2, gen_loss = 0.3908151826004923, disc_loss = 0.14079434585608083
Trained batch 162 in epoch 2, gen_loss = 0.39088871672840936, disc_loss = 0.140762641705984
Trained batch 163 in epoch 2, gen_loss = 0.39053663720444937, disc_loss = 0.14099036088985642
Trained batch 164 in epoch 2, gen_loss = 0.39098463401649936, disc_loss = 0.14104354476386852
Trained batch 165 in epoch 2, gen_loss = 0.3910481299621513, disc_loss = 0.1408583233245166
Trained batch 166 in epoch 2, gen_loss = 0.3910111586847705, disc_loss = 0.14070001936065937
Trained batch 167 in epoch 2, gen_loss = 0.3907785804143974, disc_loss = 0.14022636444618305
Trained batch 168 in epoch 2, gen_loss = 0.3908925592546632, disc_loss = 0.13962251188222474
Trained batch 169 in epoch 2, gen_loss = 0.3908310318694395, disc_loss = 0.139463895888013
Trained batch 170 in epoch 2, gen_loss = 0.39087192322078507, disc_loss = 0.13937907650718215
Trained batch 171 in epoch 2, gen_loss = 0.3912292486706445, disc_loss = 0.13882739601526842
Trained batch 172 in epoch 2, gen_loss = 0.391309429972158, disc_loss = 0.1386080809971156
Trained batch 173 in epoch 2, gen_loss = 0.39099083977869187, disc_loss = 0.13837248868383895
Trained batch 174 in epoch 2, gen_loss = 0.39156237636293684, disc_loss = 0.13790374451449938
Trained batch 175 in epoch 2, gen_loss = 0.39229094169356604, disc_loss = 0.13748304310932077
Trained batch 176 in epoch 2, gen_loss = 0.3928349649502059, disc_loss = 0.13753817312545696
Trained batch 177 in epoch 2, gen_loss = 0.3924598752447728, disc_loss = 0.1376134580147735
Trained batch 178 in epoch 2, gen_loss = 0.39280809387148424, disc_loss = 0.13701784903152361
Trained batch 179 in epoch 2, gen_loss = 0.39305433862739136, disc_loss = 0.13668286966987783
Trained batch 180 in epoch 2, gen_loss = 0.3931712809517897, disc_loss = 0.13639276306973308
Trained batch 181 in epoch 2, gen_loss = 0.39285914812769207, disc_loss = 0.13654049863568046
Trained batch 182 in epoch 2, gen_loss = 0.3927164527236438, disc_loss = 0.1373085538485174
Trained batch 183 in epoch 2, gen_loss = 0.3924767891673938, disc_loss = 0.13736168433831114
Trained batch 184 in epoch 2, gen_loss = 0.39216223133576883, disc_loss = 0.13741050283046993
Trained batch 185 in epoch 2, gen_loss = 0.39222117761770886, disc_loss = 0.13742894960707555
Trained batch 186 in epoch 2, gen_loss = 0.392323711976648, disc_loss = 0.1368761993247398
Trained batch 187 in epoch 2, gen_loss = 0.39269468648002503, disc_loss = 0.13628025496616325
Trained batch 188 in epoch 2, gen_loss = 0.39270037775317196, disc_loss = 0.13599544027376742
Trained batch 189 in epoch 2, gen_loss = 0.393003690085913, disc_loss = 0.136012238391528
Trained batch 190 in epoch 2, gen_loss = 0.3928798599392956, disc_loss = 0.13635699799118553
Trained batch 191 in epoch 2, gen_loss = 0.39310832290599745, disc_loss = 0.136621033976553
Trained batch 192 in epoch 2, gen_loss = 0.39327347958026154, disc_loss = 0.13625218874625283
Trained batch 193 in epoch 2, gen_loss = 0.39297227776542154, disc_loss = 0.13618567103001566
Trained batch 194 in epoch 2, gen_loss = 0.39337111100172384, disc_loss = 0.1362353325749819
Trained batch 195 in epoch 2, gen_loss = 0.39338446347689143, disc_loss = 0.13589124504134667
Trained batch 196 in epoch 2, gen_loss = 0.39357036851384314, disc_loss = 0.1354906309471669
Trained batch 197 in epoch 2, gen_loss = 0.3936178419325087, disc_loss = 0.13517558188036535
Trained batch 198 in epoch 2, gen_loss = 0.3936031643469729, disc_loss = 0.13469958785528213
Trained batch 199 in epoch 2, gen_loss = 0.3934322607517242, disc_loss = 0.1341580388508737
Trained batch 200 in epoch 2, gen_loss = 0.39354445299698937, disc_loss = 0.13360427357997764
Trained batch 201 in epoch 2, gen_loss = 0.39354538651976256, disc_loss = 0.13321760393642257
Trained batch 202 in epoch 2, gen_loss = 0.39339239550341526, disc_loss = 0.13343788427415446
Trained batch 203 in epoch 2, gen_loss = 0.3939686213053909, disc_loss = 0.13486786421351865
Trained batch 204 in epoch 2, gen_loss = 0.3938217450932759, disc_loss = 0.13496221682829102
Trained batch 205 in epoch 2, gen_loss = 0.39366495580349153, disc_loss = 0.1357019303583549
Trained batch 206 in epoch 2, gen_loss = 0.39371942235651797, disc_loss = 0.136064020268943
Trained batch 207 in epoch 2, gen_loss = 0.39340668658797556, disc_loss = 0.13598021790564346
Trained batch 208 in epoch 2, gen_loss = 0.39334774573453873, disc_loss = 0.13591597518888102
Trained batch 209 in epoch 2, gen_loss = 0.3930502089716139, disc_loss = 0.13599031320107835
Trained batch 210 in epoch 2, gen_loss = 0.3930258814474983, disc_loss = 0.13594983935673938
Trained batch 211 in epoch 2, gen_loss = 0.3927628483693555, disc_loss = 0.13596325284221544
Trained batch 212 in epoch 2, gen_loss = 0.3930684987088324, disc_loss = 0.13582636766625403
Trained batch 213 in epoch 2, gen_loss = 0.3929618010732615, disc_loss = 0.1356870902911107
Trained batch 214 in epoch 2, gen_loss = 0.3932018716667974, disc_loss = 0.13613154247922954
Trained batch 215 in epoch 2, gen_loss = 0.3926145635821201, disc_loss = 0.13685076170669938
Trained batch 216 in epoch 2, gen_loss = 0.3926970513734949, disc_loss = 0.13678519535071565
Trained batch 217 in epoch 2, gen_loss = 0.39268406719789595, disc_loss = 0.13646390888019713
Trained batch 218 in epoch 2, gen_loss = 0.39235662842450075, disc_loss = 0.13656207685226993
Trained batch 219 in epoch 2, gen_loss = 0.39228941134431144, disc_loss = 0.1362061807631769
Trained batch 220 in epoch 2, gen_loss = 0.39224641625158385, disc_loss = 0.13575569451765507
Trained batch 221 in epoch 2, gen_loss = 0.39224606215416846, disc_loss = 0.13537078453983004
Trained batch 222 in epoch 2, gen_loss = 0.39220746376054705, disc_loss = 0.13487834977027813
Trained batch 223 in epoch 2, gen_loss = 0.3922570471518806, disc_loss = 0.13450209619311085
Trained batch 224 in epoch 2, gen_loss = 0.3923557345072428, disc_loss = 0.13398396597968207
Trained batch 225 in epoch 2, gen_loss = 0.39229635511879374, disc_loss = 0.13362261850749496
Trained batch 226 in epoch 2, gen_loss = 0.3923017629442761, disc_loss = 0.1334113010947925
Trained batch 227 in epoch 2, gen_loss = 0.39217710429639147, disc_loss = 0.13293008833077916
Trained batch 228 in epoch 2, gen_loss = 0.3918335937516658, disc_loss = 0.1326833378084362
Trained batch 229 in epoch 2, gen_loss = 0.39169712623824243, disc_loss = 0.13234833580968172
Trained batch 230 in epoch 2, gen_loss = 0.39172915707934985, disc_loss = 0.13198254017151279
Trained batch 231 in epoch 2, gen_loss = 0.391696457847439, disc_loss = 0.13149736243589172
Trained batch 232 in epoch 2, gen_loss = 0.3917188904060315, disc_loss = 0.13113624020579548
Trained batch 233 in epoch 2, gen_loss = 0.39184896940858954, disc_loss = 0.13085292419816694
Trained batch 234 in epoch 2, gen_loss = 0.39166753241356383, disc_loss = 0.13071349989226524
Trained batch 235 in epoch 2, gen_loss = 0.3917319487969754, disc_loss = 0.1306891787355229
Trained batch 236 in epoch 2, gen_loss = 0.3918164393821346, disc_loss = 0.13039464726729735
Trained batch 237 in epoch 2, gen_loss = 0.39191036264435586, disc_loss = 0.1301261910370418
Trained batch 238 in epoch 2, gen_loss = 0.3922680602662234, disc_loss = 0.12969833582047388
Trained batch 239 in epoch 2, gen_loss = 0.39245187615354854, disc_loss = 0.12930285732727498
Trained batch 240 in epoch 2, gen_loss = 0.3925665348644573, disc_loss = 0.1288435712333042
Trained batch 241 in epoch 2, gen_loss = 0.3924692699239274, disc_loss = 0.1286428234547623
Trained batch 242 in epoch 2, gen_loss = 0.39237518541116284, disc_loss = 0.1294136030193219
Trained batch 243 in epoch 2, gen_loss = 0.39291638526760164, disc_loss = 0.13024253227183077
Trained batch 244 in epoch 2, gen_loss = 0.39229589135062937, disc_loss = 0.13059286353539448
Trained batch 245 in epoch 2, gen_loss = 0.39268197876408817, disc_loss = 0.1302352921083206
Trained batch 246 in epoch 2, gen_loss = 0.3929094870684118, disc_loss = 0.13007125370053627
Trained batch 247 in epoch 2, gen_loss = 0.3929727778679902, disc_loss = 0.13010517366590998
Trained batch 248 in epoch 2, gen_loss = 0.39328638706580704, disc_loss = 0.13003028432528177
Trained batch 249 in epoch 2, gen_loss = 0.3935781995654106, disc_loss = 0.12975879053771497
Trained batch 250 in epoch 2, gen_loss = 0.3933713547143328, disc_loss = 0.1296154059825903
Trained batch 251 in epoch 2, gen_loss = 0.3933465366680471, disc_loss = 0.12944144842820982
Trained batch 252 in epoch 2, gen_loss = 0.3932296896993878, disc_loss = 0.12946295024083537
Trained batch 253 in epoch 2, gen_loss = 0.3936635414798429, disc_loss = 0.1295053445418754
Trained batch 254 in epoch 2, gen_loss = 0.3934440450925453, disc_loss = 0.1293092817798549
Trained batch 255 in epoch 2, gen_loss = 0.3933654492138885, disc_loss = 0.12894305273948703
Trained batch 256 in epoch 2, gen_loss = 0.39333278248050335, disc_loss = 0.128561182520153
Trained batch 257 in epoch 2, gen_loss = 0.3932223157711731, disc_loss = 0.12819245684343253
Trained batch 258 in epoch 2, gen_loss = 0.3935556688479015, disc_loss = 0.1280725679313584
Trained batch 259 in epoch 2, gen_loss = 0.3937601798428939, disc_loss = 0.12910010922127046
Trained batch 260 in epoch 2, gen_loss = 0.39354433404759886, disc_loss = 0.12877229305690732
Trained batch 261 in epoch 2, gen_loss = 0.3932907780959406, disc_loss = 0.12871054606867655
Trained batch 262 in epoch 2, gen_loss = 0.3934791632591545, disc_loss = 0.12851132170612367
Trained batch 263 in epoch 2, gen_loss = 0.39336659177912003, disc_loss = 0.12825109894302758
Trained batch 264 in epoch 2, gen_loss = 0.3930614432636297, disc_loss = 0.12794947795710473
Trained batch 265 in epoch 2, gen_loss = 0.3929975268648083, disc_loss = 0.1276004802491656
Trained batch 266 in epoch 2, gen_loss = 0.3931421930535456, disc_loss = 0.12726461640402173
Trained batch 267 in epoch 2, gen_loss = 0.3931206410834149, disc_loss = 0.12685534204425875
Trained batch 268 in epoch 2, gen_loss = 0.39305533790012276, disc_loss = 0.1264623773170005
Trained batch 269 in epoch 2, gen_loss = 0.3930798738642975, disc_loss = 0.12603525073026065
Trained batch 270 in epoch 2, gen_loss = 0.3935286220699219, disc_loss = 0.12563621815005352
Trained batch 271 in epoch 2, gen_loss = 0.3936119774794754, disc_loss = 0.12521160778466284
Trained batch 272 in epoch 2, gen_loss = 0.39374735683966905, disc_loss = 0.12478238481673457
Trained batch 273 in epoch 2, gen_loss = 0.3937089680863993, disc_loss = 0.12437028344720602
Trained batch 274 in epoch 2, gen_loss = 0.39366437939080323, disc_loss = 0.12397193063389171
Trained batch 275 in epoch 2, gen_loss = 0.39389211787045864, disc_loss = 0.12361129492089368
Trained batch 276 in epoch 2, gen_loss = 0.3941050128278319, disc_loss = 0.12320004342063347
Trained batch 277 in epoch 2, gen_loss = 0.3939492885264561, disc_loss = 0.12284134997376542
Trained batch 278 in epoch 2, gen_loss = 0.3939176668082514, disc_loss = 0.12243882073656953
Trained batch 279 in epoch 2, gen_loss = 0.3940354484000376, disc_loss = 0.12203724721247064
Trained batch 280 in epoch 2, gen_loss = 0.39414915394740596, disc_loss = 0.12165745672872588
Trained batch 281 in epoch 2, gen_loss = 0.3941725309119157, disc_loss = 0.12128933063041128
Trained batch 282 in epoch 2, gen_loss = 0.39420533101255395, disc_loss = 0.12089189326607823
Trained batch 283 in epoch 2, gen_loss = 0.3938900228642242, disc_loss = 0.12057246697712427
Trained batch 284 in epoch 2, gen_loss = 0.3939328076023805, disc_loss = 0.12020764060383826
Trained batch 285 in epoch 2, gen_loss = 0.39429254585004353, disc_loss = 0.1198585637766946
Trained batch 286 in epoch 2, gen_loss = 0.3943263347867474, disc_loss = 0.11951112563848391
Trained batch 287 in epoch 2, gen_loss = 0.39457054493120974, disc_loss = 0.11924406580510549
Trained batch 288 in epoch 2, gen_loss = 0.39484914142161504, disc_loss = 0.11891059921313218
Trained batch 289 in epoch 2, gen_loss = 0.3949552793441148, disc_loss = 0.11856804819906067
Trained batch 290 in epoch 2, gen_loss = 0.3948564742951049, disc_loss = 0.11824612120723295
Trained batch 291 in epoch 2, gen_loss = 0.39496996299657106, disc_loss = 0.11789027654106589
Trained batch 292 in epoch 2, gen_loss = 0.3951414211719923, disc_loss = 0.11752597370690351
Trained batch 293 in epoch 2, gen_loss = 0.39527683705091476, disc_loss = 0.11722099113588531
Trained batch 294 in epoch 2, gen_loss = 0.39519210503262986, disc_loss = 0.11688183167538906
Trained batch 295 in epoch 2, gen_loss = 0.3952294258350456, disc_loss = 0.11651658829666574
Trained batch 296 in epoch 2, gen_loss = 0.39517738236120653, disc_loss = 0.11615669616005737
Trained batch 297 in epoch 2, gen_loss = 0.3954122709047874, disc_loss = 0.11581234534539832
Trained batch 298 in epoch 2, gen_loss = 0.3953972569975167, disc_loss = 0.11555472340895778
Trained batch 299 in epoch 2, gen_loss = 0.3956007289389769, disc_loss = 0.11529082793121537
Trained batch 300 in epoch 2, gen_loss = 0.3955847060066521, disc_loss = 0.11502555638328937
Trained batch 301 in epoch 2, gen_loss = 0.3958020940028279, disc_loss = 0.11488857452714482
Trained batch 302 in epoch 2, gen_loss = 0.3959888438678811, disc_loss = 0.11478739791847889
Trained batch 303 in epoch 2, gen_loss = 0.39617296136719615, disc_loss = 0.1146277446532622
Trained batch 304 in epoch 2, gen_loss = 0.39616077742615685, disc_loss = 0.11446300370649236
Trained batch 305 in epoch 2, gen_loss = 0.3964047557096076, disc_loss = 0.11418813554070939
Trained batch 306 in epoch 2, gen_loss = 0.39656665071796515, disc_loss = 0.11386137069218127
Trained batch 307 in epoch 2, gen_loss = 0.3965592852176784, disc_loss = 0.11359175296451945
Trained batch 308 in epoch 2, gen_loss = 0.39681667528299064, disc_loss = 0.11329465079751215
Trained batch 309 in epoch 2, gen_loss = 0.39694797276489197, disc_loss = 0.11304382602533987
Trained batch 310 in epoch 2, gen_loss = 0.3968266789648694, disc_loss = 0.11274989045126262
Trained batch 311 in epoch 2, gen_loss = 0.39675259871933705, disc_loss = 0.11261064048187855
Trained batch 312 in epoch 2, gen_loss = 0.39688711515821207, disc_loss = 0.1123850649704758
Trained batch 313 in epoch 2, gen_loss = 0.3966552850072551, disc_loss = 0.11223703647732355
Trained batch 314 in epoch 2, gen_loss = 0.396727673354603, disc_loss = 0.11236736666825083
Trained batch 315 in epoch 2, gen_loss = 0.39659865544755246, disc_loss = 0.11214129168162995
Trained batch 316 in epoch 2, gen_loss = 0.3964790742762081, disc_loss = 0.11198960194123281
Trained batch 317 in epoch 2, gen_loss = 0.39668367732808274, disc_loss = 0.11195290117940437
Trained batch 318 in epoch 2, gen_loss = 0.39668763940424007, disc_loss = 0.11165219763159565
Trained batch 319 in epoch 2, gen_loss = 0.39673075410537423, disc_loss = 0.11161456318222918
Trained batch 320 in epoch 2, gen_loss = 0.3970206379426231, disc_loss = 0.11134785385309165
Trained batch 321 in epoch 2, gen_loss = 0.3971659020514962, disc_loss = 0.11106421121668002
Trained batch 322 in epoch 2, gen_loss = 0.39724417685908797, disc_loss = 0.11079256027798534
Trained batch 323 in epoch 2, gen_loss = 0.3971547420470067, disc_loss = 0.11079246356485435
Trained batch 324 in epoch 2, gen_loss = 0.3972951087126365, disc_loss = 0.1105117001842994
Trained batch 325 in epoch 2, gen_loss = 0.3972781450927623, disc_loss = 0.11021291082610656
Trained batch 326 in epoch 2, gen_loss = 0.3971296903828233, disc_loss = 0.10994857294194468
Trained batch 327 in epoch 2, gen_loss = 0.39731048179290646, disc_loss = 0.10973148461056464
Trained batch 328 in epoch 2, gen_loss = 0.39751793208636776, disc_loss = 0.1095591816445388
Trained batch 329 in epoch 2, gen_loss = 0.3976145083705584, disc_loss = 0.10947870118543505
Trained batch 330 in epoch 2, gen_loss = 0.3980006597643532, disc_loss = 0.11004895839299951
Trained batch 331 in epoch 2, gen_loss = 0.397908289703619, disc_loss = 0.11043595857862158
Trained batch 332 in epoch 2, gen_loss = 0.39792305432461406, disc_loss = 0.11023292854685594
Trained batch 333 in epoch 2, gen_loss = 0.3980317936239842, disc_loss = 0.10999179378006897
Trained batch 334 in epoch 2, gen_loss = 0.39818088665826995, disc_loss = 0.10984309372116825
Trained batch 335 in epoch 2, gen_loss = 0.39819886273748817, disc_loss = 0.10981133922524307
Trained batch 336 in epoch 2, gen_loss = 0.39805528994660705, disc_loss = 0.10973163025083368
Trained batch 337 in epoch 2, gen_loss = 0.39815619072088826, disc_loss = 0.11057747610343191
Trained batch 338 in epoch 2, gen_loss = 0.39806884135995996, disc_loss = 0.11081440395958568
Trained batch 339 in epoch 2, gen_loss = 0.3982984810629312, disc_loss = 0.11076948636978426
Trained batch 340 in epoch 2, gen_loss = 0.39802412225528894, disc_loss = 0.11061545392318119
Trained batch 341 in epoch 2, gen_loss = 0.39796361287957743, disc_loss = 0.1106848745792015
Trained batch 342 in epoch 2, gen_loss = 0.39841730771016104, disc_loss = 0.11088009702948631
Trained batch 343 in epoch 2, gen_loss = 0.39838536503876365, disc_loss = 0.11082195831451912
Trained batch 344 in epoch 2, gen_loss = 0.39805557861708213, disc_loss = 0.11107479928574268
Trained batch 345 in epoch 2, gen_loss = 0.39803395739008235, disc_loss = 0.11107552584228401
Trained batch 346 in epoch 2, gen_loss = 0.39823275671396885, disc_loss = 0.11092670131689447
Trained batch 347 in epoch 2, gen_loss = 0.39838541594558746, disc_loss = 0.11077705362608292
Trained batch 348 in epoch 2, gen_loss = 0.3983492621121912, disc_loss = 0.11075955273631566
Trained batch 349 in epoch 2, gen_loss = 0.3984889013000897, disc_loss = 0.11059621374255844
Trained batch 350 in epoch 2, gen_loss = 0.3984252360896168, disc_loss = 0.11049006955480559
Trained batch 351 in epoch 2, gen_loss = 0.39857323827560653, disc_loss = 0.11106395395208066
Trained batch 352 in epoch 2, gen_loss = 0.39855674622585685, disc_loss = 0.11170629759928576
Trained batch 353 in epoch 2, gen_loss = 0.3985503655621561, disc_loss = 0.1115810326616264
Trained batch 354 in epoch 2, gen_loss = 0.39835590925854697, disc_loss = 0.1116297699379879
Trained batch 355 in epoch 2, gen_loss = 0.3980740654920594, disc_loss = 0.1122388416309998
Trained batch 356 in epoch 2, gen_loss = 0.3981936943380773, disc_loss = 0.11214995676135066
Trained batch 357 in epoch 2, gen_loss = 0.39840593288897136, disc_loss = 0.11204543370264453
Trained batch 358 in epoch 2, gen_loss = 0.39824010929855463, disc_loss = 0.11206294718382667
Trained batch 359 in epoch 2, gen_loss = 0.3982002656079001, disc_loss = 0.1122179861051134
Trained batch 360 in epoch 2, gen_loss = 0.3979002956785984, disc_loss = 0.11275683572242381
Trained batch 361 in epoch 2, gen_loss = 0.39785574495957043, disc_loss = 0.11263607831116128
Trained batch 362 in epoch 2, gen_loss = 0.3978630694722341, disc_loss = 0.11253675947494333
Trained batch 363 in epoch 2, gen_loss = 0.39823149042306366, disc_loss = 0.11234415442027806
Trained batch 364 in epoch 2, gen_loss = 0.3981357662236854, disc_loss = 0.11217488404363393
Trained batch 365 in epoch 2, gen_loss = 0.39817566237325874, disc_loss = 0.11191018155007496
Trained batch 366 in epoch 2, gen_loss = 0.3981647473995952, disc_loss = 0.11166293050951707
Trained batch 367 in epoch 2, gen_loss = 0.3979790503483104, disc_loss = 0.1115217570331879
Trained batch 368 in epoch 2, gen_loss = 0.39799651766049504, disc_loss = 0.11143218433903404
Trained batch 369 in epoch 2, gen_loss = 0.398153854020544, disc_loss = 0.11140571770988203
Trained batch 370 in epoch 2, gen_loss = 0.3980214895022847, disc_loss = 0.11115009070316334
Trained batch 371 in epoch 2, gen_loss = 0.3978411175150384, disc_loss = 0.11097528090229838
Trained batch 372 in epoch 2, gen_loss = 0.3978839191051335, disc_loss = 0.11071571660035817
Trained batch 373 in epoch 2, gen_loss = 0.39802894398649746, disc_loss = 0.11054971697864766
Trained batch 374 in epoch 2, gen_loss = 0.3979887806971868, disc_loss = 0.11033421213676532
Trained batch 375 in epoch 2, gen_loss = 0.39804148495672864, disc_loss = 0.11009276388064423
Trained batch 376 in epoch 2, gen_loss = 0.3982134315553331, disc_loss = 0.11052114924845788
Trained batch 377 in epoch 2, gen_loss = 0.39790303843519675, disc_loss = 0.11082233535125852
Trained batch 378 in epoch 2, gen_loss = 0.3979335274340924, disc_loss = 0.11057267078790706
Trained batch 379 in epoch 2, gen_loss = 0.3978688962757587, disc_loss = 0.11062816591492217
Trained batch 380 in epoch 2, gen_loss = 0.39763519907091543, disc_loss = 0.11068946688516637
Trained batch 381 in epoch 2, gen_loss = 0.3976611442356834, disc_loss = 0.11086304164223412
Trained batch 382 in epoch 2, gen_loss = 0.3974431386270971, disc_loss = 0.1108816294291351
Trained batch 383 in epoch 2, gen_loss = 0.39755767952495563, disc_loss = 0.11069212948253455
Trained batch 384 in epoch 2, gen_loss = 0.3974994886618156, disc_loss = 0.11054107321595603
Trained batch 385 in epoch 2, gen_loss = 0.39758158637297586, disc_loss = 0.11066191507638505
Trained batch 386 in epoch 2, gen_loss = 0.3978075524864271, disc_loss = 0.11066974136612596
Trained batch 387 in epoch 2, gen_loss = 0.39754967587356715, disc_loss = 0.11053590293368805
Trained batch 388 in epoch 2, gen_loss = 0.39745738615873233, disc_loss = 0.1103090047908128
Trained batch 389 in epoch 2, gen_loss = 0.39740570489412697, disc_loss = 0.11005314541025421
Trained batch 390 in epoch 2, gen_loss = 0.3974057158164661, disc_loss = 0.10983663386024554
Trained batch 391 in epoch 2, gen_loss = 0.39766497921426686, disc_loss = 0.10960617265901623
Trained batch 392 in epoch 2, gen_loss = 0.3978266445659196, disc_loss = 0.10948797703765654
Trained batch 393 in epoch 2, gen_loss = 0.3978413316577219, disc_loss = 0.10925696482692802
Trained batch 394 in epoch 2, gen_loss = 0.39782458562639694, disc_loss = 0.10911557710953529
Trained batch 395 in epoch 2, gen_loss = 0.39827383486459955, disc_loss = 0.10899249571281476
Trained batch 396 in epoch 2, gen_loss = 0.39833861360471856, disc_loss = 0.10874166154309695
Trained batch 397 in epoch 2, gen_loss = 0.398529558437853, disc_loss = 0.10849876862824262
Trained batch 398 in epoch 2, gen_loss = 0.3986358617556125, disc_loss = 0.10828540502186108
Trained batch 399 in epoch 2, gen_loss = 0.39879063356667754, disc_loss = 0.10806877517141401
Trained batch 400 in epoch 2, gen_loss = 0.3987351323378056, disc_loss = 0.10788620227107086
Trained batch 401 in epoch 2, gen_loss = 0.3985718929426587, disc_loss = 0.10803822045265442
Trained batch 402 in epoch 2, gen_loss = 0.398739897546638, disc_loss = 0.10813758848581657
Trained batch 403 in epoch 2, gen_loss = 0.3987968561451624, disc_loss = 0.10806244135013607
Trained batch 404 in epoch 2, gen_loss = 0.39895794792675676, disc_loss = 0.10783100071374649
Trained batch 405 in epoch 2, gen_loss = 0.39902045401593145, disc_loss = 0.10775767751450976
Trained batch 406 in epoch 2, gen_loss = 0.39900427108461206, disc_loss = 0.10760209370971971
Trained batch 407 in epoch 2, gen_loss = 0.39912752898446485, disc_loss = 0.10739597901199743
Trained batch 408 in epoch 2, gen_loss = 0.3990360065238109, disc_loss = 0.10727289016870896
Trained batch 409 in epoch 2, gen_loss = 0.39909270751040155, disc_loss = 0.10705050236613649
Trained batch 410 in epoch 2, gen_loss = 0.3990171673886677, disc_loss = 0.10685310688848695
Trained batch 411 in epoch 2, gen_loss = 0.3989417658919848, disc_loss = 0.10663121766682027
Trained batch 412 in epoch 2, gen_loss = 0.39921017510694684, disc_loss = 0.10679291702635568
Trained batch 413 in epoch 2, gen_loss = 0.39925037011288217, disc_loss = 0.10657278680724007
Trained batch 414 in epoch 2, gen_loss = 0.39905578655650814, disc_loss = 0.10681862592562494
Trained batch 415 in epoch 2, gen_loss = 0.39907535513003284, disc_loss = 0.1066047727116921
Trained batch 416 in epoch 2, gen_loss = 0.3992416714664272, disc_loss = 0.10639600929909115
Trained batch 417 in epoch 2, gen_loss = 0.39922892594594134, disc_loss = 0.10650513041987303
Trained batch 418 in epoch 2, gen_loss = 0.3992812784659834, disc_loss = 0.10679347666207177
Trained batch 419 in epoch 2, gen_loss = 0.39919403085396404, disc_loss = 0.10658370072598614
Trained batch 420 in epoch 2, gen_loss = 0.39942184115390594, disc_loss = 0.1064372491556045
Trained batch 421 in epoch 2, gen_loss = 0.3996145720659839, disc_loss = 0.106266988651006
Trained batch 422 in epoch 2, gen_loss = 0.3995509044427962, disc_loss = 0.1060770998156275
Trained batch 423 in epoch 2, gen_loss = 0.3995491360085753, disc_loss = 0.10591069680313527
Trained batch 424 in epoch 2, gen_loss = 0.39951195657253263, disc_loss = 0.10572623408235171
Trained batch 425 in epoch 2, gen_loss = 0.3994571641787117, disc_loss = 0.1055897230680315
Trained batch 426 in epoch 2, gen_loss = 0.3995818862521397, disc_loss = 0.10537995051034231
Trained batch 427 in epoch 2, gen_loss = 0.39973250257773935, disc_loss = 0.10517069751997347
Trained batch 428 in epoch 2, gen_loss = 0.3998757149581309, disc_loss = 0.10506903462433245
Trained batch 429 in epoch 2, gen_loss = 0.40005380923664846, disc_loss = 0.10491211927864094
Trained batch 430 in epoch 2, gen_loss = 0.40007145861876814, disc_loss = 0.10471140169117193
Trained batch 431 in epoch 2, gen_loss = 0.40008897048041775, disc_loss = 0.10453965610833149
Trained batch 432 in epoch 2, gen_loss = 0.4002303400229637, disc_loss = 0.10433506717642997
Trained batch 433 in epoch 2, gen_loss = 0.40047485820846074, disc_loss = 0.1041609488989866
Trained batch 434 in epoch 2, gen_loss = 0.4004743501030166, disc_loss = 0.10393736871366185
Trained batch 435 in epoch 2, gen_loss = 0.4004912533276125, disc_loss = 0.10377473415114806
Trained batch 436 in epoch 2, gen_loss = 0.4005512251802113, disc_loss = 0.10355646852020269
Trained batch 437 in epoch 2, gen_loss = 0.40067448501037134, disc_loss = 0.10334740632711208
Trained batch 438 in epoch 2, gen_loss = 0.40075490153596177, disc_loss = 0.10323767306321302
Trained batch 439 in epoch 2, gen_loss = 0.4009439573707906, disc_loss = 0.1032304837283763
Trained batch 440 in epoch 2, gen_loss = 0.4008887063821697, disc_loss = 0.10328901695961855
Trained batch 441 in epoch 2, gen_loss = 0.4011416762595263, disc_loss = 0.10310317997344479
Trained batch 442 in epoch 2, gen_loss = 0.4011838644339322, disc_loss = 0.10294685402620189
Trained batch 443 in epoch 2, gen_loss = 0.40118431632180473, disc_loss = 0.10280919361121214
Trained batch 444 in epoch 2, gen_loss = 0.40122910741339907, disc_loss = 0.10260409706512864
Trained batch 445 in epoch 2, gen_loss = 0.401369266679736, disc_loss = 0.10263091586780788
Trained batch 446 in epoch 2, gen_loss = 0.4011956227639111, disc_loss = 0.10244735322425963
Trained batch 447 in epoch 2, gen_loss = 0.4010985744784453, disc_loss = 0.10261911094338368
Trained batch 448 in epoch 2, gen_loss = 0.40124302588087946, disc_loss = 0.1030845781518582
Trained batch 449 in epoch 2, gen_loss = 0.40136341237359574, disc_loss = 0.10302128471020196
Trained batch 450 in epoch 2, gen_loss = 0.40124092586421123, disc_loss = 0.1032025624776957
Trained batch 451 in epoch 2, gen_loss = 0.40125083089270425, disc_loss = 0.10329461266261945
Trained batch 452 in epoch 2, gen_loss = 0.4012226364667842, disc_loss = 0.10330494269975368
Trained batch 453 in epoch 2, gen_loss = 0.4011032051911438, disc_loss = 0.10355374635923408
Trained batch 454 in epoch 2, gen_loss = 0.4014266324239773, disc_loss = 0.10349820444953965
Trained batch 455 in epoch 2, gen_loss = 0.40141630300173636, disc_loss = 0.10341637822178502
Trained batch 456 in epoch 2, gen_loss = 0.40145543462207595, disc_loss = 0.1033910733873852
Trained batch 457 in epoch 2, gen_loss = 0.4015629733038261, disc_loss = 0.10323725623286056
Trained batch 458 in epoch 2, gen_loss = 0.4015488679437596, disc_loss = 0.10303430768513082
Trained batch 459 in epoch 2, gen_loss = 0.4014996532836686, disc_loss = 0.10284670347590809
Trained batch 460 in epoch 2, gen_loss = 0.4017810071949845, disc_loss = 0.10266598230005604
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 0.4414631128311157, disc_loss = 0.007717246189713478
Trained batch 1 in epoch 3, gen_loss = 0.45037417113780975, disc_loss = 0.016904196701943874
Trained batch 2 in epoch 3, gen_loss = 0.4304145872592926, disc_loss = 0.017041336745023727
Trained batch 3 in epoch 3, gen_loss = 0.4315178915858269, disc_loss = 0.01803905889391899
Trained batch 4 in epoch 3, gen_loss = 0.4440875291824341, disc_loss = 0.015928598679602148
Trained batch 5 in epoch 3, gen_loss = 0.4385088582833608, disc_loss = 0.028932742308825254
Trained batch 6 in epoch 3, gen_loss = 0.43573373556137085, disc_loss = 0.037084746174514294
Trained batch 7 in epoch 3, gen_loss = 0.41780658438801765, disc_loss = 0.03749134542886168
Trained batch 8 in epoch 3, gen_loss = 0.4218262864483727, disc_loss = 0.04435279437651237
Trained batch 9 in epoch 3, gen_loss = 0.4201041579246521, disc_loss = 0.041838994901627305
Trained batch 10 in epoch 3, gen_loss = 0.4174099293622104, disc_loss = 0.04208201567896388
Trained batch 11 in epoch 3, gen_loss = 0.42501991987228394, disc_loss = 0.039988139256214104
Trained batch 12 in epoch 3, gen_loss = 0.4247808273021991, disc_loss = 0.04137454633242809
Trained batch 13 in epoch 3, gen_loss = 0.41981866317135946, disc_loss = 0.0405954890884459
Trained batch 14 in epoch 3, gen_loss = 0.4188706497351328, disc_loss = 0.039821869569520156
Trained batch 15 in epoch 3, gen_loss = 0.4135418515652418, disc_loss = 0.038370476046111435
Trained batch 16 in epoch 3, gen_loss = 0.4185832335668452, disc_loss = 0.03884516913882073
Trained batch 17 in epoch 3, gen_loss = 0.42250680095619625, disc_loss = 0.038410450176646314
Trained batch 18 in epoch 3, gen_loss = 0.42220897737302276, disc_loss = 0.0377775457638659
Trained batch 19 in epoch 3, gen_loss = 0.4265511929988861, disc_loss = 0.038010836904868485
Trained batch 20 in epoch 3, gen_loss = 0.4246918388775417, disc_loss = 0.03673552646346036
Trained batch 21 in epoch 3, gen_loss = 0.42460649663751776, disc_loss = 0.03589911246672273
Trained batch 22 in epoch 3, gen_loss = 0.4260577740876571, disc_loss = 0.034877829942042415
Trained batch 23 in epoch 3, gen_loss = 0.4287147472302119, disc_loss = 0.03387908521108329
Trained batch 24 in epoch 3, gen_loss = 0.4300768041610718, disc_loss = 0.03300216689705849
Trained batch 25 in epoch 3, gen_loss = 0.42938920167776257, disc_loss = 0.03270294732199265
Trained batch 26 in epoch 3, gen_loss = 0.42978368423603197, disc_loss = 0.03267631127878472
Trained batch 27 in epoch 3, gen_loss = 0.43069271211113247, disc_loss = 0.03205461171455681
Trained batch 28 in epoch 3, gen_loss = 0.4280621183329615, disc_loss = 0.03168895413521035
Trained batch 29 in epoch 3, gen_loss = 0.42649943232536314, disc_loss = 0.0316353392166396
Trained batch 30 in epoch 3, gen_loss = 0.42512036811920906, disc_loss = 0.031090412258861527
Trained batch 31 in epoch 3, gen_loss = 0.42566596809774637, disc_loss = 0.03079792278003879
Trained batch 32 in epoch 3, gen_loss = 0.426116353634632, disc_loss = 0.03188657989217476
Trained batch 33 in epoch 3, gen_loss = 0.4270094256190693, disc_loss = 0.03246925708235187
Trained batch 34 in epoch 3, gen_loss = 0.4277209026472909, disc_loss = 0.03321724408971412
Trained batch 35 in epoch 3, gen_loss = 0.42474659118387437, disc_loss = 0.03494573987296058
Trained batch 36 in epoch 3, gen_loss = 0.427742152600675, disc_loss = 0.034422830451984666
Trained batch 37 in epoch 3, gen_loss = 0.429275548771808, disc_loss = 0.03407225164731866
Trained batch 38 in epoch 3, gen_loss = 0.4290188138301556, disc_loss = 0.034287674161486134
Trained batch 39 in epoch 3, gen_loss = 0.4264607928693295, disc_loss = 0.035473810182884334
Trained batch 40 in epoch 3, gen_loss = 0.4247854461030262, disc_loss = 0.03615242356389034
Trained batch 41 in epoch 3, gen_loss = 0.4237009634574254, disc_loss = 0.03642275756491082
Trained batch 42 in epoch 3, gen_loss = 0.42500313284785246, disc_loss = 0.03595514248969943
Trained batch 43 in epoch 3, gen_loss = 0.42469140684062784, disc_loss = 0.038382269103418694
Trained batch 44 in epoch 3, gen_loss = 0.4226704365677304, disc_loss = 0.043103556831677756
Trained batch 45 in epoch 3, gen_loss = 0.4217705603526986, disc_loss = 0.04284126983712549
Trained batch 46 in epoch 3, gen_loss = 0.4217399428499506, disc_loss = 0.042505531512359356
Trained batch 47 in epoch 3, gen_loss = 0.4224346100042264, disc_loss = 0.042264644793855645
Trained batch 48 in epoch 3, gen_loss = 0.42201255231487506, disc_loss = 0.042514516420814455
Trained batch 49 in epoch 3, gen_loss = 0.42292106986045835, disc_loss = 0.042139744535088536
Trained batch 50 in epoch 3, gen_loss = 0.42368847774524315, disc_loss = 0.04145566279105112
Trained batch 51 in epoch 3, gen_loss = 0.42419237758104616, disc_loss = 0.04096398266175619
Trained batch 52 in epoch 3, gen_loss = 0.42289187379603116, disc_loss = 0.04063306808612257
Trained batch 53 in epoch 3, gen_loss = 0.4229909915615011, disc_loss = 0.04049049410969019
Trained batch 54 in epoch 3, gen_loss = 0.423047615181316, disc_loss = 0.040026141330599785
Trained batch 55 in epoch 3, gen_loss = 0.4222621050264154, disc_loss = 0.039926132486600964
Trained batch 56 in epoch 3, gen_loss = 0.4214765858231929, disc_loss = 0.04044470233483273
Trained batch 57 in epoch 3, gen_loss = 0.4212925747550767, disc_loss = 0.04072377076051358
Trained batch 58 in epoch 3, gen_loss = 0.4205719939732956, disc_loss = 0.040283944615620675
Trained batch 59 in epoch 3, gen_loss = 0.42176753282546997, disc_loss = 0.040138469108690816
Trained batch 60 in epoch 3, gen_loss = 0.4223162937359732, disc_loss = 0.040047183541245146
Trained batch 61 in epoch 3, gen_loss = 0.42215990972134376, disc_loss = 0.03979663295491088
Trained batch 62 in epoch 3, gen_loss = 0.42322251579118153, disc_loss = 0.039692881236237196
Trained batch 63 in epoch 3, gen_loss = 0.42391651729121804, disc_loss = 0.03922725383017678
Trained batch 64 in epoch 3, gen_loss = 0.42275594427035407, disc_loss = 0.03878063950687647
Trained batch 65 in epoch 3, gen_loss = 0.4230216308073564, disc_loss = 0.03834504734329654
Trained batch 66 in epoch 3, gen_loss = 0.42244736605615757, disc_loss = 0.03847476249254907
Trained batch 67 in epoch 3, gen_loss = 0.42022839583018246, disc_loss = 0.03940712253782241
Trained batch 68 in epoch 3, gen_loss = 0.421100040708763, disc_loss = 0.038994259929851345
Trained batch 69 in epoch 3, gen_loss = 0.42223431851182663, disc_loss = 0.03857525082837258
Trained batch 70 in epoch 3, gen_loss = 0.42223437990940793, disc_loss = 0.03835565346280034
Trained batch 71 in epoch 3, gen_loss = 0.4218979345427619, disc_loss = 0.03819558354249845
Trained batch 72 in epoch 3, gen_loss = 0.42246925790015966, disc_loss = 0.03883176101754381
Trained batch 73 in epoch 3, gen_loss = 0.42154213182024053, disc_loss = 0.039959765656070935
Trained batch 74 in epoch 3, gen_loss = 0.42168211221694946, disc_loss = 0.03964383146415154
Trained batch 75 in epoch 3, gen_loss = 0.4213995447284297, disc_loss = 0.040200411109253764
Trained batch 76 in epoch 3, gen_loss = 0.42172140928057883, disc_loss = 0.04057565884205041
Trained batch 77 in epoch 3, gen_loss = 0.421580922909272, disc_loss = 0.04024631569448572
Trained batch 78 in epoch 3, gen_loss = 0.42150658859482293, disc_loss = 0.039898261227468146
Trained batch 79 in epoch 3, gen_loss = 0.42038653008639815, disc_loss = 0.03974624424008653
Trained batch 80 in epoch 3, gen_loss = 0.420327373124935, disc_loss = 0.039361709303418056
Trained batch 81 in epoch 3, gen_loss = 0.4211701074751412, disc_loss = 0.03916556979870287
Trained batch 82 in epoch 3, gen_loss = 0.42093118845698346, disc_loss = 0.038845874447689714
Trained batch 83 in epoch 3, gen_loss = 0.421382660312312, disc_loss = 0.03864007404384514
Trained batch 84 in epoch 3, gen_loss = 0.4212638556957245, disc_loss = 0.040521826255409156
Trained batch 85 in epoch 3, gen_loss = 0.41992840898591416, disc_loss = 0.045023856262221586
Trained batch 86 in epoch 3, gen_loss = 0.4210087290440483, disc_loss = 0.045963257690356384
Trained batch 87 in epoch 3, gen_loss = 0.4198898574845357, disc_loss = 0.04725678922312165
Trained batch 88 in epoch 3, gen_loss = 0.4187250750118427, disc_loss = 0.04856843188446894
Trained batch 89 in epoch 3, gen_loss = 0.41834064490265316, disc_loss = 0.049953612819727926
Trained batch 90 in epoch 3, gen_loss = 0.41741717680469975, disc_loss = 0.051209669816051864
Trained batch 91 in epoch 3, gen_loss = 0.41665217798689136, disc_loss = 0.05149325798265636
Trained batch 92 in epoch 3, gen_loss = 0.416783566756915, disc_loss = 0.05205305454431362
Trained batch 93 in epoch 3, gen_loss = 0.4162678357134474, disc_loss = 0.05314108116076665
Trained batch 94 in epoch 3, gen_loss = 0.4160518345079924, disc_loss = 0.053532070911636476
Trained batch 95 in epoch 3, gen_loss = 0.41440886693696183, disc_loss = 0.0537852208459905
Trained batch 96 in epoch 3, gen_loss = 0.4150744857861824, disc_loss = 0.05369829656268211
Trained batch 97 in epoch 3, gen_loss = 0.4147825508701558, disc_loss = 0.05351464633772872
Trained batch 98 in epoch 3, gen_loss = 0.4149312659947559, disc_loss = 0.05322366746876276
Trained batch 99 in epoch 3, gen_loss = 0.41446437627077104, disc_loss = 0.053393190773203966
Trained batch 100 in epoch 3, gen_loss = 0.41373062310832565, disc_loss = 0.054121008723752924
Trained batch 101 in epoch 3, gen_loss = 0.4142953373637854, disc_loss = 0.05451377829098526
Trained batch 102 in epoch 3, gen_loss = 0.4138135904247321, disc_loss = 0.05461537864203881
Trained batch 103 in epoch 3, gen_loss = 0.4147824134964209, disc_loss = 0.05423684173729271
Trained batch 104 in epoch 3, gen_loss = 0.4153756720679147, disc_loss = 0.05385419349407866
Trained batch 105 in epoch 3, gen_loss = 0.4159970058585113, disc_loss = 0.053471978938312466
Trained batch 106 in epoch 3, gen_loss = 0.4155784151821493, disc_loss = 0.05334809301508086
Trained batch 107 in epoch 3, gen_loss = 0.4158720037451497, disc_loss = 0.05316019966267049
Trained batch 108 in epoch 3, gen_loss = 0.4151841700077057, disc_loss = 0.05285575385248169
Trained batch 109 in epoch 3, gen_loss = 0.41398043605414303, disc_loss = 0.05345759324898774
Trained batch 110 in epoch 3, gen_loss = 0.4138826260695586, disc_loss = 0.055319555045046785
Trained batch 111 in epoch 3, gen_loss = 0.4145864514367921, disc_loss = 0.05567261577484065
Trained batch 112 in epoch 3, gen_loss = 0.4146835060246223, disc_loss = 0.05532727084757216
Trained batch 113 in epoch 3, gen_loss = 0.4146359298835721, disc_loss = 0.055131687447755484
Trained batch 114 in epoch 3, gen_loss = 0.4145373328872349, disc_loss = 0.05488418255649183
Trained batch 115 in epoch 3, gen_loss = 0.41360585931046256, disc_loss = 0.0548387926055825
Trained batch 116 in epoch 3, gen_loss = 0.4142998765167008, disc_loss = 0.05474477929150701
Trained batch 117 in epoch 3, gen_loss = 0.41430730738882293, disc_loss = 0.05458658894965962
Trained batch 118 in epoch 3, gen_loss = 0.4137525896565253, disc_loss = 0.054274536755342946
Trained batch 119 in epoch 3, gen_loss = 0.41402348056435584, disc_loss = 0.05402321648628761
Trained batch 120 in epoch 3, gen_loss = 0.41433665550444737, disc_loss = 0.05403839545093538
Trained batch 121 in epoch 3, gen_loss = 0.41535708430360574, disc_loss = 0.054127122115221665
Trained batch 122 in epoch 3, gen_loss = 0.4154721970965223, disc_loss = 0.054034374631577876
Trained batch 123 in epoch 3, gen_loss = 0.4150061953452326, disc_loss = 0.05438341540584882
Trained batch 124 in epoch 3, gen_loss = 0.41539529991149904, disc_loss = 0.05406600783765316
Trained batch 125 in epoch 3, gen_loss = 0.41550985924781314, disc_loss = 0.05370027436653063
Trained batch 126 in epoch 3, gen_loss = 0.41571547806732295, disc_loss = 0.05357208725534321
Trained batch 127 in epoch 3, gen_loss = 0.41497570322826505, disc_loss = 0.05348068790772231
Trained batch 128 in epoch 3, gen_loss = 0.41457584754441135, disc_loss = 0.053334017775144224
Trained batch 129 in epoch 3, gen_loss = 0.41503271254209373, disc_loss = 0.053076683880331425
Trained batch 130 in epoch 3, gen_loss = 0.41513217155259985, disc_loss = 0.05273334562550974
Trained batch 131 in epoch 3, gen_loss = 0.4148997495120222, disc_loss = 0.05249689073499405
Trained batch 132 in epoch 3, gen_loss = 0.4150174125692898, disc_loss = 0.05227414732868958
Trained batch 133 in epoch 3, gen_loss = 0.41551029059424327, disc_loss = 0.05194053320742365
Trained batch 134 in epoch 3, gen_loss = 0.41584559546576605, disc_loss = 0.051718260499614255
Trained batch 135 in epoch 3, gen_loss = 0.41515078483258977, disc_loss = 0.051507590544026566
Trained batch 136 in epoch 3, gen_loss = 0.415940512270823, disc_loss = 0.05131137513820708
Trained batch 137 in epoch 3, gen_loss = 0.41654781889224396, disc_loss = 0.051004386425990124
Trained batch 138 in epoch 3, gen_loss = 0.41692694764343097, disc_loss = 0.05070212055935705
Trained batch 139 in epoch 3, gen_loss = 0.4168451447572027, disc_loss = 0.050390624328117285
Trained batch 140 in epoch 3, gen_loss = 0.4172410956511261, disc_loss = 0.05013755608534982
Trained batch 141 in epoch 3, gen_loss = 0.41736107728850674, disc_loss = 0.049887546115148236
Trained batch 142 in epoch 3, gen_loss = 0.41769570299795455, disc_loss = 0.049621832303025505
Trained batch 143 in epoch 3, gen_loss = 0.41800226353936726, disc_loss = 0.049352891296924405
Trained batch 144 in epoch 3, gen_loss = 0.4184097462686999, disc_loss = 0.04905776340064817
Trained batch 145 in epoch 3, gen_loss = 0.4184841174785405, disc_loss = 0.04898595904025619
Trained batch 146 in epoch 3, gen_loss = 0.4181497656569189, disc_loss = 0.049038108080296086
Trained batch 147 in epoch 3, gen_loss = 0.4191220736986882, disc_loss = 0.04881858766217389
Trained batch 148 in epoch 3, gen_loss = 0.41918021520512216, disc_loss = 0.04860374389916358
Trained batch 149 in epoch 3, gen_loss = 0.41882940848668415, disc_loss = 0.048691359270984926
Trained batch 150 in epoch 3, gen_loss = 0.4188681197482229, disc_loss = 0.04980702176135009
Trained batch 151 in epoch 3, gen_loss = 0.4188853078766873, disc_loss = 0.05149290437111631
Trained batch 152 in epoch 3, gen_loss = 0.4192851076718249, disc_loss = 0.05141915406216106
Trained batch 153 in epoch 3, gen_loss = 0.4194543936422893, disc_loss = 0.05159488495427196
Trained batch 154 in epoch 3, gen_loss = 0.41895669987124784, disc_loss = 0.052028045067263225
Trained batch 155 in epoch 3, gen_loss = 0.41941629407497555, disc_loss = 0.05344097078359949
Trained batch 156 in epoch 3, gen_loss = 0.4193683855093209, disc_loss = 0.05373056675159153
Trained batch 157 in epoch 3, gen_loss = 0.41929840079591246, disc_loss = 0.05400485315218662
Trained batch 158 in epoch 3, gen_loss = 0.4193259533846153, disc_loss = 0.05403794960628422
Trained batch 159 in epoch 3, gen_loss = 0.41968579329550265, disc_loss = 0.05450477631238755
Trained batch 160 in epoch 3, gen_loss = 0.41926307078474057, disc_loss = 0.05522528914040568
Trained batch 161 in epoch 3, gen_loss = 0.4196259406981645, disc_loss = 0.05520787373771546
Trained batch 162 in epoch 3, gen_loss = 0.419939240977808, disc_loss = 0.055510189255665233
Trained batch 163 in epoch 3, gen_loss = 0.41978539853561214, disc_loss = 0.05613442954164362
Trained batch 164 in epoch 3, gen_loss = 0.4198117622823426, disc_loss = 0.056093142257834024
Trained batch 165 in epoch 3, gen_loss = 0.4194945748670992, disc_loss = 0.056046898743272365
Trained batch 166 in epoch 3, gen_loss = 0.4194928848457907, disc_loss = 0.05582995668979373
Trained batch 167 in epoch 3, gen_loss = 0.4197393050860791, disc_loss = 0.055598705438786145
Trained batch 168 in epoch 3, gen_loss = 0.4193602199032462, disc_loss = 0.05548253740024196
Trained batch 169 in epoch 3, gen_loss = 0.4196552716633853, disc_loss = 0.055415214978925445
Trained batch 170 in epoch 3, gen_loss = 0.41940742487098737, disc_loss = 0.05532423756221495
Trained batch 171 in epoch 3, gen_loss = 0.4195174481286559, disc_loss = 0.055205687195560786
Trained batch 172 in epoch 3, gen_loss = 0.4194782310827619, disc_loss = 0.055044755487665104
Trained batch 173 in epoch 3, gen_loss = 0.4195159464731984, disc_loss = 0.05517251440323889
Trained batch 174 in epoch 3, gen_loss = 0.4193369599751064, disc_loss = 0.05597107037635786
Trained batch 175 in epoch 3, gen_loss = 0.41942250745540316, disc_loss = 0.05612134114066562
Trained batch 176 in epoch 3, gen_loss = 0.4192955987264881, disc_loss = 0.055860952929314756
Trained batch 177 in epoch 3, gen_loss = 0.41902866306599607, disc_loss = 0.05565092837950738
Trained batch 178 in epoch 3, gen_loss = 0.4190884182573031, disc_loss = 0.055444213064834894
Trained batch 179 in epoch 3, gen_loss = 0.4185375561316808, disc_loss = 0.055243341808414295
Trained batch 180 in epoch 3, gen_loss = 0.41862546245037524, disc_loss = 0.05503102848615024
Trained batch 181 in epoch 3, gen_loss = 0.41875516664195844, disc_loss = 0.05484507297124755
Trained batch 182 in epoch 3, gen_loss = 0.41898461997183295, disc_loss = 0.05461715471986783
Trained batch 183 in epoch 3, gen_loss = 0.41906559775057045, disc_loss = 0.054387161034948964
Trained batch 184 in epoch 3, gen_loss = 0.4189329329374674, disc_loss = 0.05419332788048967
Trained batch 185 in epoch 3, gen_loss = 0.41930978753233467, disc_loss = 0.053945505873911004
Trained batch 186 in epoch 3, gen_loss = 0.419422367996073, disc_loss = 0.05369911504471127
Trained batch 187 in epoch 3, gen_loss = 0.4193351595325673, disc_loss = 0.05358703238542806
Trained batch 188 in epoch 3, gen_loss = 0.41963272766461446, disc_loss = 0.05377729239297055
Trained batch 189 in epoch 3, gen_loss = 0.41918502528416485, disc_loss = 0.054593682311181176
Trained batch 190 in epoch 3, gen_loss = 0.41907656489242434, disc_loss = 0.054654717740373615
Trained batch 191 in epoch 3, gen_loss = 0.41934464359655976, disc_loss = 0.054535859751922544
Trained batch 192 in epoch 3, gen_loss = 0.41927476744577674, disc_loss = 0.05457723054098728
Trained batch 193 in epoch 3, gen_loss = 0.4191264101524943, disc_loss = 0.05438502049601646
Trained batch 194 in epoch 3, gen_loss = 0.4192395100226769, disc_loss = 0.05458143740558089
Trained batch 195 in epoch 3, gen_loss = 0.419205833150416, disc_loss = 0.05463780593174529
Trained batch 196 in epoch 3, gen_loss = 0.4193779700601161, disc_loss = 0.05447132338244978
Trained batch 197 in epoch 3, gen_loss = 0.4190188048764913, disc_loss = 0.05439693258012259
Trained batch 198 in epoch 3, gen_loss = 0.41904207734606375, disc_loss = 0.05555414040830342
Trained batch 199 in epoch 3, gen_loss = 0.41881674468517305, disc_loss = 0.05645027774618939
Trained batch 200 in epoch 3, gen_loss = 0.4189771765203618, disc_loss = 0.057459772404616895
Trained batch 201 in epoch 3, gen_loss = 0.4192425472901599, disc_loss = 0.0576863636626945
Trained batch 202 in epoch 3, gen_loss = 0.41915978865670456, disc_loss = 0.05820232493289072
Trained batch 203 in epoch 3, gen_loss = 0.4189746466045286, disc_loss = 0.05890048393185305
Trained batch 204 in epoch 3, gen_loss = 0.4187827928764064, disc_loss = 0.058896909029472894
Trained batch 205 in epoch 3, gen_loss = 0.4190330642808988, disc_loss = 0.05883567211742612
Trained batch 206 in epoch 3, gen_loss = 0.4188373702159826, disc_loss = 0.05881860018325385
Trained batch 207 in epoch 3, gen_loss = 0.41838808372043645, disc_loss = 0.05882631714428918
Trained batch 208 in epoch 3, gen_loss = 0.4187944934984143, disc_loss = 0.060935453358039474
Trained batch 209 in epoch 3, gen_loss = 0.41854143398148674, disc_loss = 0.061462780046055
Trained batch 210 in epoch 3, gen_loss = 0.41851411738666877, disc_loss = 0.061465423423973445
Trained batch 211 in epoch 3, gen_loss = 0.41866802564769423, disc_loss = 0.061283490385526336
Trained batch 212 in epoch 3, gen_loss = 0.41817009476988526, disc_loss = 0.06127987280181946
Trained batch 213 in epoch 3, gen_loss = 0.41773995924218793, disc_loss = 0.06132381488830199
Trained batch 214 in epoch 3, gen_loss = 0.4178396518840346, disc_loss = 0.06162032252177596
Trained batch 215 in epoch 3, gen_loss = 0.41754258548219997, disc_loss = 0.06157197450779171
Trained batch 216 in epoch 3, gen_loss = 0.4173492098458901, disc_loss = 0.06147172397500428
Trained batch 217 in epoch 3, gen_loss = 0.417498457185719, disc_loss = 0.06137417628720335
Trained batch 218 in epoch 3, gen_loss = 0.417126311967362, disc_loss = 0.061254962421868626
Trained batch 219 in epoch 3, gen_loss = 0.4169270699674433, disc_loss = 0.06120162158569491
Trained batch 220 in epoch 3, gen_loss = 0.41700875516390906, disc_loss = 0.06117197612671359
Trained batch 221 in epoch 3, gen_loss = 0.4166407054877496, disc_loss = 0.061358217026216084
Trained batch 222 in epoch 3, gen_loss = 0.41663142971928346, disc_loss = 0.06112359127764812
Trained batch 223 in epoch 3, gen_loss = 0.41694323984639986, disc_loss = 0.06107128746849152
Trained batch 224 in epoch 3, gen_loss = 0.41696025848388674, disc_loss = 0.06090038829586572
Trained batch 225 in epoch 3, gen_loss = 0.4171137712170592, disc_loss = 0.06107656802957367
Trained batch 226 in epoch 3, gen_loss = 0.4172711466902678, disc_loss = 0.06090570994681527
Trained batch 227 in epoch 3, gen_loss = 0.41722080255286736, disc_loss = 0.060739569613105504
Trained batch 228 in epoch 3, gen_loss = 0.41695669072163677, disc_loss = 0.06064302391498695
Trained batch 229 in epoch 3, gen_loss = 0.4165140820586163, disc_loss = 0.06111722114171995
Trained batch 230 in epoch 3, gen_loss = 0.41586438066515574, disc_loss = 0.06250076704090099
Trained batch 231 in epoch 3, gen_loss = 0.4155964733197771, disc_loss = 0.06281448147813629
Trained batch 232 in epoch 3, gen_loss = 0.41549374131174044, disc_loss = 0.06307565147664734
Trained batch 233 in epoch 3, gen_loss = 0.41538235494214243, disc_loss = 0.06308614598133434
Trained batch 234 in epoch 3, gen_loss = 0.41501131488921794, disc_loss = 0.06302742086390549
Trained batch 235 in epoch 3, gen_loss = 0.4153524411179252, disc_loss = 0.06296171312875477
Trained batch 236 in epoch 3, gen_loss = 0.4153964654051302, disc_loss = 0.06280013425511462
Trained batch 237 in epoch 3, gen_loss = 0.4152594780972024, disc_loss = 0.06278607875554815
Trained batch 238 in epoch 3, gen_loss = 0.4149004542677971, disc_loss = 0.06375858848758634
Trained batch 239 in epoch 3, gen_loss = 0.41472978790601095, disc_loss = 0.0636176051280927
Trained batch 240 in epoch 3, gen_loss = 0.41513565269248615, disc_loss = 0.06364600607908923
Trained batch 241 in epoch 3, gen_loss = 0.41518907236658836, disc_loss = 0.06347689177448407
Trained batch 242 in epoch 3, gen_loss = 0.4148434962264795, disc_loss = 0.06330863339826465
Trained batch 243 in epoch 3, gen_loss = 0.4151270619181336, disc_loss = 0.06315673592492754
Trained batch 244 in epoch 3, gen_loss = 0.41519430364881244, disc_loss = 0.06312583345273623
Trained batch 245 in epoch 3, gen_loss = 0.41549973456355616, disc_loss = 0.06294263987347665
Trained batch 246 in epoch 3, gen_loss = 0.41567100542276975, disc_loss = 0.06280792901398018
Trained batch 247 in epoch 3, gen_loss = 0.4155323359995119, disc_loss = 0.06271881924288708
Trained batch 248 in epoch 3, gen_loss = 0.41564458979660246, disc_loss = 0.06256739086243343
Trained batch 249 in epoch 3, gen_loss = 0.41550794088840487, disc_loss = 0.06239653585292399
Trained batch 250 in epoch 3, gen_loss = 0.41570548137345636, disc_loss = 0.062182715932552916
Trained batch 251 in epoch 3, gen_loss = 0.4158016573342066, disc_loss = 0.06202967444043015
Trained batch 252 in epoch 3, gen_loss = 0.41570369092372095, disc_loss = 0.061855251357886984
Trained batch 253 in epoch 3, gen_loss = 0.4159158868348505, disc_loss = 0.061636335779289446
Trained batch 254 in epoch 3, gen_loss = 0.4160996791194467, disc_loss = 0.06146783071807494
Trained batch 255 in epoch 3, gen_loss = 0.4161510687554255, disc_loss = 0.061379609656796674
Trained batch 256 in epoch 3, gen_loss = 0.41638645935615215, disc_loss = 0.061273932527634765
Trained batch 257 in epoch 3, gen_loss = 0.416312430140584, disc_loss = 0.06110636151193591
Trained batch 258 in epoch 3, gen_loss = 0.416329087552877, disc_loss = 0.06090401123281439
Trained batch 259 in epoch 3, gen_loss = 0.4165382956083004, disc_loss = 0.060729837376409426
Trained batch 260 in epoch 3, gen_loss = 0.41632400013477866, disc_loss = 0.060599524857854595
Trained batch 261 in epoch 3, gen_loss = 0.41653868010025896, disc_loss = 0.06042089265813866
Trained batch 262 in epoch 3, gen_loss = 0.4165305384211667, disc_loss = 0.060240791715724044
Trained batch 263 in epoch 3, gen_loss = 0.4166009345966758, disc_loss = 0.06005230843562238
Trained batch 264 in epoch 3, gen_loss = 0.4167516281019967, disc_loss = 0.059874857285604724
Trained batch 265 in epoch 3, gen_loss = 0.41683423900066463, disc_loss = 0.059697844989639814
Trained batch 266 in epoch 3, gen_loss = 0.41725973690047247, disc_loss = 0.05954519118450945
Trained batch 267 in epoch 3, gen_loss = 0.4173317157955312, disc_loss = 0.05939216471673337
Trained batch 268 in epoch 3, gen_loss = 0.41712889507357515, disc_loss = 0.05921090027095826
Trained batch 269 in epoch 3, gen_loss = 0.41751421005637557, disc_loss = 0.05901921334572964
Trained batch 270 in epoch 3, gen_loss = 0.4177316153401378, disc_loss = 0.058876388376351875
Trained batch 271 in epoch 3, gen_loss = 0.41751798121806455, disc_loss = 0.05881146422025802
Trained batch 272 in epoch 3, gen_loss = 0.4177828901634985, disc_loss = 0.05888896395585367
Trained batch 273 in epoch 3, gen_loss = 0.4175241963706747, disc_loss = 0.05891829792641266
Trained batch 274 in epoch 3, gen_loss = 0.4175744764371352, disc_loss = 0.05900619217956608
Trained batch 275 in epoch 3, gen_loss = 0.4175408723345701, disc_loss = 0.05914653895382324
Trained batch 276 in epoch 3, gen_loss = 0.41753859199341453, disc_loss = 0.059159566870208034
Trained batch 277 in epoch 3, gen_loss = 0.4175237762413437, disc_loss = 0.05912600091504429
Trained batch 278 in epoch 3, gen_loss = 0.41739559291084183, disc_loss = 0.05907326399625736
Trained batch 279 in epoch 3, gen_loss = 0.4172269757304873, disc_loss = 0.05912795761001429
Trained batch 280 in epoch 3, gen_loss = 0.41710421114205465, disc_loss = 0.059428478445314216
Trained batch 281 in epoch 3, gen_loss = 0.41696799287559294, disc_loss = 0.05964855778077287
Trained batch 282 in epoch 3, gen_loss = 0.4170235615526408, disc_loss = 0.0598425499193186
Trained batch 283 in epoch 3, gen_loss = 0.4169429369585615, disc_loss = 0.06057326091309144
Trained batch 284 in epoch 3, gen_loss = 0.416988417035655, disc_loss = 0.060649246418554535
Trained batch 285 in epoch 3, gen_loss = 0.41694191848481454, disc_loss = 0.060630251995411576
Trained batch 286 in epoch 3, gen_loss = 0.41672641288112683, disc_loss = 0.060610545750460765
Trained batch 287 in epoch 3, gen_loss = 0.4170440855539507, disc_loss = 0.06137682053506271
Trained batch 288 in epoch 3, gen_loss = 0.41691458173689133, disc_loss = 0.061778863676047034
Trained batch 289 in epoch 3, gen_loss = 0.4166846846712047, disc_loss = 0.062153074463251336
Trained batch 290 in epoch 3, gen_loss = 0.416461352732583, disc_loss = 0.06256568765658181
Trained batch 291 in epoch 3, gen_loss = 0.41657801574631914, disc_loss = 0.06266480118788983
Trained batch 292 in epoch 3, gen_loss = 0.41638685961225336, disc_loss = 0.06265063167775349
Trained batch 293 in epoch 3, gen_loss = 0.4160319849544642, disc_loss = 0.06249850768862026
Trained batch 294 in epoch 3, gen_loss = 0.4154095223394491, disc_loss = 0.06273199525361849
Trained batch 295 in epoch 3, gen_loss = 0.4156233499179015, disc_loss = 0.06321516797588383
Trained batch 296 in epoch 3, gen_loss = 0.41577505573680507, disc_loss = 0.063369346421952
Trained batch 297 in epoch 3, gen_loss = 0.4154933164983788, disc_loss = 0.0633800622394571
Trained batch 298 in epoch 3, gen_loss = 0.41567788694215857, disc_loss = 0.06349417224314599
Trained batch 299 in epoch 3, gen_loss = 0.4155700831611951, disc_loss = 0.06356290694015722
Trained batch 300 in epoch 3, gen_loss = 0.41560936241450896, disc_loss = 0.06341948609279338
Trained batch 301 in epoch 3, gen_loss = 0.41566362098747534, disc_loss = 0.06331840753616975
Trained batch 302 in epoch 3, gen_loss = 0.415671312474575, disc_loss = 0.06318152854803076
Trained batch 303 in epoch 3, gen_loss = 0.4156482786332306, disc_loss = 0.06304229905301902
Trained batch 304 in epoch 3, gen_loss = 0.415792619204912, disc_loss = 0.06286826709315914
Trained batch 305 in epoch 3, gen_loss = 0.415629851857042, disc_loss = 0.06276439066696303
Trained batch 306 in epoch 3, gen_loss = 0.4156987467107245, disc_loss = 0.06262976690483694
Trained batch 307 in epoch 3, gen_loss = 0.41537533110225355, disc_loss = 0.06277019273816281
Trained batch 308 in epoch 3, gen_loss = 0.415576840777999, disc_loss = 0.06357302398249073
Trained batch 309 in epoch 3, gen_loss = 0.4153347632577342, disc_loss = 0.06358722190883372
Trained batch 310 in epoch 3, gen_loss = 0.41527047187952365, disc_loss = 0.06362622034499403
Trained batch 311 in epoch 3, gen_loss = 0.4153334855651244, disc_loss = 0.06362405435767216
Trained batch 312 in epoch 3, gen_loss = 0.4150866144381392, disc_loss = 0.06368927281207075
Trained batch 313 in epoch 3, gen_loss = 0.4150637814383598, disc_loss = 0.06358606389361866
Trained batch 314 in epoch 3, gen_loss = 0.4151247025482238, disc_loss = 0.06372064659224143
Trained batch 315 in epoch 3, gen_loss = 0.4149080842167516, disc_loss = 0.06430184241985501
Trained batch 316 in epoch 3, gen_loss = 0.4150884308461511, disc_loss = 0.06446816440530662
Trained batch 317 in epoch 3, gen_loss = 0.4147587700647378, disc_loss = 0.06444612370054208
Trained batch 318 in epoch 3, gen_loss = 0.4145276943531156, disc_loss = 0.06479365955220774
Trained batch 319 in epoch 3, gen_loss = 0.4145534474402666, disc_loss = 0.06477274414792192
Trained batch 320 in epoch 3, gen_loss = 0.4143239559599915, disc_loss = 0.06463539643021667
Trained batch 321 in epoch 3, gen_loss = 0.41393210910121847, disc_loss = 0.06469131592857819
Trained batch 322 in epoch 3, gen_loss = 0.41391341374385465, disc_loss = 0.06464932040937084
Trained batch 323 in epoch 3, gen_loss = 0.4137355150815881, disc_loss = 0.0645437183485217
Trained batch 324 in epoch 3, gen_loss = 0.4136937397259932, disc_loss = 0.06464793064559882
Trained batch 325 in epoch 3, gen_loss = 0.4134884165839915, disc_loss = 0.06495863680607794
Trained batch 326 in epoch 3, gen_loss = 0.4137493807606012, disc_loss = 0.06505073852187723
Trained batch 327 in epoch 3, gen_loss = 0.4137989722374009, disc_loss = 0.0649346341123441
Trained batch 328 in epoch 3, gen_loss = 0.41409251519611906, disc_loss = 0.06477894624383797
Trained batch 329 in epoch 3, gen_loss = 0.41434353707414684, disc_loss = 0.06460261533714154
Trained batch 330 in epoch 3, gen_loss = 0.4143746881506594, disc_loss = 0.06447700401796225
Trained batch 331 in epoch 3, gen_loss = 0.4143553298999028, disc_loss = 0.06430486761067197
Trained batch 332 in epoch 3, gen_loss = 0.4141958156326512, disc_loss = 0.06428049011127995
Trained batch 333 in epoch 3, gen_loss = 0.4144090430108373, disc_loss = 0.0642273960841407
Trained batch 334 in epoch 3, gen_loss = 0.4144295067039888, disc_loss = 0.06414153109679915
Trained batch 335 in epoch 3, gen_loss = 0.4142191944909947, disc_loss = 0.06402850448475442
Trained batch 336 in epoch 3, gen_loss = 0.414431089109766, disc_loss = 0.06422508059439833
Trained batch 337 in epoch 3, gen_loss = 0.4143970437656493, disc_loss = 0.06437021976932002
Trained batch 338 in epoch 3, gen_loss = 0.4146397963913493, disc_loss = 0.06454150044911466
Trained batch 339 in epoch 3, gen_loss = 0.4145517536822487, disc_loss = 0.06483504189561834
Trained batch 340 in epoch 3, gen_loss = 0.41460249920394765, disc_loss = 0.06505704315275478
Trained batch 341 in epoch 3, gen_loss = 0.41420659213735345, disc_loss = 0.06508225457721024
Trained batch 342 in epoch 3, gen_loss = 0.41394406948075696, disc_loss = 0.06520999012563823
Trained batch 343 in epoch 3, gen_loss = 0.41392905628958415, disc_loss = 0.06511494203546453
Trained batch 344 in epoch 3, gen_loss = 0.41392568159794463, disc_loss = 0.06498109925322343
Trained batch 345 in epoch 3, gen_loss = 0.413759053787055, disc_loss = 0.0649323244471469
Trained batch 346 in epoch 3, gen_loss = 0.4135792667652757, disc_loss = 0.06519268288059692
Trained batch 347 in epoch 3, gen_loss = 0.41374141543075954, disc_loss = 0.06514897831480136
Trained batch 348 in epoch 3, gen_loss = 0.4137828321033358, disc_loss = 0.06505563596055382
Trained batch 349 in epoch 3, gen_loss = 0.4135400399991444, disc_loss = 0.06495755830247488
Trained batch 350 in epoch 3, gen_loss = 0.4136779686154803, disc_loss = 0.06481976619526277
Trained batch 351 in epoch 3, gen_loss = 0.4137126264924353, disc_loss = 0.06470117640988478
Trained batch 352 in epoch 3, gen_loss = 0.4138818454134566, disc_loss = 0.0645954802067734
Trained batch 353 in epoch 3, gen_loss = 0.41394590843195295, disc_loss = 0.06445996646143201
Trained batch 354 in epoch 3, gen_loss = 0.41388166496451473, disc_loss = 0.06430229382248412
Trained batch 355 in epoch 3, gen_loss = 0.41397150605916977, disc_loss = 0.06416886753214293
Trained batch 356 in epoch 3, gen_loss = 0.413773197503317, disc_loss = 0.06405486923274624
Trained batch 357 in epoch 3, gen_loss = 0.4140788583948625, disc_loss = 0.06399154186758665
Trained batch 358 in epoch 3, gen_loss = 0.41400291004884876, disc_loss = 0.06384819416811788
Trained batch 359 in epoch 3, gen_loss = 0.41406856916017004, disc_loss = 0.06370508262318456
Trained batch 360 in epoch 3, gen_loss = 0.41419906208389684, disc_loss = 0.06355210346198148
Trained batch 361 in epoch 3, gen_loss = 0.4142645933351464, disc_loss = 0.06339369216182614
Trained batch 362 in epoch 3, gen_loss = 0.4145392161427122, disc_loss = 0.06333480769198788
Trained batch 363 in epoch 3, gen_loss = 0.4145612197590398, disc_loss = 0.0637247681331176
Trained batch 364 in epoch 3, gen_loss = 0.4146439891155452, disc_loss = 0.06404504014612877
Trained batch 365 in epoch 3, gen_loss = 0.4146231419401742, disc_loss = 0.06403971215089162
Trained batch 366 in epoch 3, gen_loss = 0.41453051396546636, disc_loss = 0.0639399910289845
Trained batch 367 in epoch 3, gen_loss = 0.41430993054224097, disc_loss = 0.06389070350838744
Trained batch 368 in epoch 3, gen_loss = 0.41434006493912157, disc_loss = 0.06377604895531323
Trained batch 369 in epoch 3, gen_loss = 0.4141818362313348, disc_loss = 0.06369905020739582
Trained batch 370 in epoch 3, gen_loss = 0.41421571558697845, disc_loss = 0.0642268503451283
Trained batch 371 in epoch 3, gen_loss = 0.41422707162877564, disc_loss = 0.06434987531474201
Trained batch 372 in epoch 3, gen_loss = 0.4140683351029659, disc_loss = 0.06429557532231865
Trained batch 373 in epoch 3, gen_loss = 0.4140757288046699, disc_loss = 0.06420220691152913
Trained batch 374 in epoch 3, gen_loss = 0.41420542073249816, disc_loss = 0.06409631479283173
Trained batch 375 in epoch 3, gen_loss = 0.41415502265729803, disc_loss = 0.06401685481157868
Trained batch 376 in epoch 3, gen_loss = 0.41412701333233154, disc_loss = 0.06386195182978158
Trained batch 377 in epoch 3, gen_loss = 0.4140332108609891, disc_loss = 0.06378984291145884
Trained batch 378 in epoch 3, gen_loss = 0.41422868639938437, disc_loss = 0.06371738632408641
Trained batch 379 in epoch 3, gen_loss = 0.41401052506346453, disc_loss = 0.06363642596590675
Trained batch 380 in epoch 3, gen_loss = 0.4140430955592729, disc_loss = 0.0635107772136376
Trained batch 381 in epoch 3, gen_loss = 0.41415641062858843, disc_loss = 0.06336062092514445
Trained batch 382 in epoch 3, gen_loss = 0.4142383571237559, disc_loss = 0.06322177245789852
Trained batch 383 in epoch 3, gen_loss = 0.413967587131386, disc_loss = 0.06308638378808003
Trained batch 384 in epoch 3, gen_loss = 0.4137875785301258, disc_loss = 0.06294099656719859
Trained batch 385 in epoch 3, gen_loss = 0.41371342146026036, disc_loss = 0.0628187210344917
Trained batch 386 in epoch 3, gen_loss = 0.4136862135672754, disc_loss = 0.06268512764319932
Trained batch 387 in epoch 3, gen_loss = 0.41376449521054925, disc_loss = 0.0625487857380613
Trained batch 388 in epoch 3, gen_loss = 0.4139177452935658, disc_loss = 0.062416859736048394
Trained batch 389 in epoch 3, gen_loss = 0.4140745147680625, disc_loss = 0.062279649813158006
Trained batch 390 in epoch 3, gen_loss = 0.4140795647640667, disc_loss = 0.06220232332220582
Trained batch 391 in epoch 3, gen_loss = 0.41399183177522253, disc_loss = 0.06214281371960949
Trained batch 392 in epoch 3, gen_loss = 0.41416999409520294, disc_loss = 0.062008404164662724
Trained batch 393 in epoch 3, gen_loss = 0.41422635838767596, disc_loss = 0.06188911596090925
Trained batch 394 in epoch 3, gen_loss = 0.4142040648037874, disc_loss = 0.061754432859347216
Trained batch 395 in epoch 3, gen_loss = 0.41421947861560665, disc_loss = 0.06161438888691441
Trained batch 396 in epoch 3, gen_loss = 0.4142519809136763, disc_loss = 0.06148103082913821
Trained batch 397 in epoch 3, gen_loss = 0.4143854094360342, disc_loss = 0.06135832585497343
Trained batch 398 in epoch 3, gen_loss = 0.414301559067609, disc_loss = 0.061220785161774406
Trained batch 399 in epoch 3, gen_loss = 0.41432303316891195, disc_loss = 0.06107992561999708
Trained batch 400 in epoch 3, gen_loss = 0.4143044174906619, disc_loss = 0.06095249851250515
Trained batch 401 in epoch 3, gen_loss = 0.4141714259314893, disc_loss = 0.06081488871812561
Trained batch 402 in epoch 3, gen_loss = 0.41419710429667245, disc_loss = 0.060679637828134646
Trained batch 403 in epoch 3, gen_loss = 0.4141415574468008, disc_loss = 0.06054589218842696
Trained batch 404 in epoch 3, gen_loss = 0.4141443702909682, disc_loss = 0.06041089975976466
Trained batch 405 in epoch 3, gen_loss = 0.41421568320302543, disc_loss = 0.0602752095216821
Trained batch 406 in epoch 3, gen_loss = 0.41415779904007033, disc_loss = 0.06013692650001231
Trained batch 407 in epoch 3, gen_loss = 0.41428371694158106, disc_loss = 0.060002100722426004
Trained batch 408 in epoch 3, gen_loss = 0.41421677175827304, disc_loss = 0.05986959083474863
Trained batch 409 in epoch 3, gen_loss = 0.41419653420041247, disc_loss = 0.05973514960965187
Trained batch 410 in epoch 3, gen_loss = 0.4142257669111238, disc_loss = 0.05960614689333487
Trained batch 411 in epoch 3, gen_loss = 0.4143023663064809, disc_loss = 0.05948041849294949
Trained batch 412 in epoch 3, gen_loss = 0.41429046590160806, disc_loss = 0.05935060399072583
Trained batch 413 in epoch 3, gen_loss = 0.4143354922964953, disc_loss = 0.059225218679872904
Trained batch 414 in epoch 3, gen_loss = 0.414280844237431, disc_loss = 0.05910744331664888
Trained batch 415 in epoch 3, gen_loss = 0.4141712117796907, disc_loss = 0.0589851278849752
Trained batch 416 in epoch 3, gen_loss = 0.4141508064967551, disc_loss = 0.05886458463596104
Trained batch 417 in epoch 3, gen_loss = 0.4141086811226521, disc_loss = 0.05875021728027487
Trained batch 418 in epoch 3, gen_loss = 0.4140701436911107, disc_loss = 0.058631427553849105
Trained batch 419 in epoch 3, gen_loss = 0.41394981493552524, disc_loss = 0.05850512511872997
Trained batch 420 in epoch 3, gen_loss = 0.41386617086562294, disc_loss = 0.058388470042709285
Trained batch 421 in epoch 3, gen_loss = 0.41387600758911874, disc_loss = 0.05827334294232465
Trained batch 422 in epoch 3, gen_loss = 0.41400747645831276, disc_loss = 0.058148218465233596
Trained batch 423 in epoch 3, gen_loss = 0.4139916793495979, disc_loss = 0.05802564911504786
Trained batch 424 in epoch 3, gen_loss = 0.4140215616366443, disc_loss = 0.05790473823709523
Trained batch 425 in epoch 3, gen_loss = 0.4141921696248749, disc_loss = 0.05778288619238621
Trained batch 426 in epoch 3, gen_loss = 0.4141234400959149, disc_loss = 0.0576626741473478
Trained batch 427 in epoch 3, gen_loss = 0.4142028517394422, disc_loss = 0.05755443085272248
Trained batch 428 in epoch 3, gen_loss = 0.41415520988422116, disc_loss = 0.05745976131913059
Trained batch 429 in epoch 3, gen_loss = 0.4143178858036219, disc_loss = 0.05734321686850731
Trained batch 430 in epoch 3, gen_loss = 0.41447521922483244, disc_loss = 0.057247043472742815
Trained batch 431 in epoch 3, gen_loss = 0.41443599118954605, disc_loss = 0.05714060718202273
Trained batch 432 in epoch 3, gen_loss = 0.4144499150489825, disc_loss = 0.0570232817595588
Trained batch 433 in epoch 3, gen_loss = 0.41457232420894957, disc_loss = 0.056940202265419924
Trained batch 434 in epoch 3, gen_loss = 0.41472274715873014, disc_loss = 0.05682718034127149
Trained batch 435 in epoch 3, gen_loss = 0.4147111476151221, disc_loss = 0.0567204592452564
Trained batch 436 in epoch 3, gen_loss = 0.41468411561280694, disc_loss = 0.05660824358433451
Trained batch 437 in epoch 3, gen_loss = 0.4146466017721995, disc_loss = 0.05649383881950079
Trained batch 438 in epoch 3, gen_loss = 0.41479807107758143, disc_loss = 0.05638145361358728
Trained batch 439 in epoch 3, gen_loss = 0.414863879639994, disc_loss = 0.056268797860353846
Trained batch 440 in epoch 3, gen_loss = 0.41510144416707445, disc_loss = 0.05616897924395612
Trained batch 441 in epoch 3, gen_loss = 0.4148970546361008, disc_loss = 0.056063010151881504
Trained batch 442 in epoch 3, gen_loss = 0.4147952262892411, disc_loss = 0.05600871907706892
Trained batch 443 in epoch 3, gen_loss = 0.41468790522566784, disc_loss = 0.055910175713408436
Trained batch 444 in epoch 3, gen_loss = 0.41485834804813515, disc_loss = 0.0558664025937657
Trained batch 445 in epoch 3, gen_loss = 0.4149214887298276, disc_loss = 0.05582006633670107
Trained batch 446 in epoch 3, gen_loss = 0.4148824112260635, disc_loss = 0.0557345561901945
Trained batch 447 in epoch 3, gen_loss = 0.4147836556658149, disc_loss = 0.055678703153846855
Trained batch 448 in epoch 3, gen_loss = 0.4148740985478484, disc_loss = 0.05560341060580582
Trained batch 449 in epoch 3, gen_loss = 0.4150244135989083, disc_loss = 0.05550101431811021
Trained batch 450 in epoch 3, gen_loss = 0.41510705520995705, disc_loss = 0.055415544337789197
Trained batch 451 in epoch 3, gen_loss = 0.41501693777014725, disc_loss = 0.05533217380865914
Trained batch 452 in epoch 3, gen_loss = 0.41496881138673153, disc_loss = 0.0552368241950261
Trained batch 453 in epoch 3, gen_loss = 0.4149021722277881, disc_loss = 0.05517134023727726
Trained batch 454 in epoch 3, gen_loss = 0.4149037818987291, disc_loss = 0.055066016962199094
Trained batch 455 in epoch 3, gen_loss = 0.41493372802148787, disc_loss = 0.054969611462295516
Trained batch 456 in epoch 3, gen_loss = 0.4150496738875199, disc_loss = 0.05490300794492763
Trained batch 457 in epoch 3, gen_loss = 0.4149353732578619, disc_loss = 0.05484107454657132
Trained batch 458 in epoch 3, gen_loss = 0.4148931646139274, disc_loss = 0.05473464416859424
Trained batch 459 in epoch 3, gen_loss = 0.4149547798478085, disc_loss = 0.054635756044729575
Trained batch 460 in epoch 3, gen_loss = 0.41517188880035005, disc_loss = 0.05454178689322445
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 0.40794074535369873, disc_loss = 0.037841517478227615
Trained batch 1 in epoch 4, gen_loss = 0.3960980772972107, disc_loss = 0.08631708659231663
Trained batch 2 in epoch 4, gen_loss = 0.4113805294036865, disc_loss = 0.09326308344801267
Trained batch 3 in epoch 4, gen_loss = 0.4081847444176674, disc_loss = 0.07271517813205719
Trained batch 4 in epoch 4, gen_loss = 0.4137892425060272, disc_loss = 0.09982399940490723
Trained batch 5 in epoch 4, gen_loss = 0.38998596370220184, disc_loss = 0.16253672043482462
Trained batch 6 in epoch 4, gen_loss = 0.37262921248163494, disc_loss = 0.16184067726135254
Trained batch 7 in epoch 4, gen_loss = 0.3751342110335827, disc_loss = 0.16407279297709465
Trained batch 8 in epoch 4, gen_loss = 0.37586742970678544, disc_loss = 0.15924398766623604
Trained batch 9 in epoch 4, gen_loss = 0.3710559070110321, disc_loss = 0.15217450335621835
Trained batch 10 in epoch 4, gen_loss = 0.3738566149364818, disc_loss = 0.14213486964052374
Trained batch 11 in epoch 4, gen_loss = 0.3738199820121129, disc_loss = 0.13386698284496865
Trained batch 12 in epoch 4, gen_loss = 0.38061256133593047, disc_loss = 0.126033980685931
Trained batch 13 in epoch 4, gen_loss = 0.3847062715462276, disc_loss = 0.11934461896972996
Trained batch 14 in epoch 4, gen_loss = 0.37795177300771077, disc_loss = 0.11884996021787325
Trained batch 15 in epoch 4, gen_loss = 0.38148305751383305, disc_loss = 0.11677404283545911
Trained batch 16 in epoch 4, gen_loss = 0.3836195170879364, disc_loss = 0.1110440998831216
Trained batch 17 in epoch 4, gen_loss = 0.38526423275470734, disc_loss = 0.10641794838011265
Trained batch 18 in epoch 4, gen_loss = 0.3846853532289204, disc_loss = 0.1016644086492689
Trained batch 19 in epoch 4, gen_loss = 0.386173740029335, disc_loss = 0.09746764553710818
Trained batch 20 in epoch 4, gen_loss = 0.38707408167067026, disc_loss = 0.09571293661636966
Trained batch 21 in epoch 4, gen_loss = 0.38557100566950714, disc_loss = 0.0924170400778001
Trained batch 22 in epoch 4, gen_loss = 0.3855819326380025, disc_loss = 0.08973411770294541
Trained batch 23 in epoch 4, gen_loss = 0.38708290085196495, disc_loss = 0.08743389672599733
Trained batch 24 in epoch 4, gen_loss = 0.3884970498085022, disc_loss = 0.08419374272227287
Trained batch 25 in epoch 4, gen_loss = 0.39214821045215315, disc_loss = 0.08160606427834584
Trained batch 26 in epoch 4, gen_loss = 0.3939016064008077, disc_loss = 0.0789251026387016
Trained batch 27 in epoch 4, gen_loss = 0.39701063079493387, disc_loss = 0.07635896263777145
Trained batch 28 in epoch 4, gen_loss = 0.39743301786225416, disc_loss = 0.07481038194663565
Trained batch 29 in epoch 4, gen_loss = 0.3978970984617869, disc_loss = 0.0731106009023885
Trained batch 30 in epoch 4, gen_loss = 0.3978556923327907, disc_loss = 0.07108313833633738
Trained batch 31 in epoch 4, gen_loss = 0.39944163151085377, disc_loss = 0.06908709008712322
Trained batch 32 in epoch 4, gen_loss = 0.40051405718832306, disc_loss = 0.06716584744439884
Trained batch 33 in epoch 4, gen_loss = 0.40180594956173615, disc_loss = 0.06544773825718199
Trained batch 34 in epoch 4, gen_loss = 0.4016894008432116, disc_loss = 0.06380544541669743
Trained batch 35 in epoch 4, gen_loss = 0.4040277856919501, disc_loss = 0.06219777023781919
Trained batch 36 in epoch 4, gen_loss = 0.403179295159675, disc_loss = 0.06190098493636863
Trained batch 37 in epoch 4, gen_loss = 0.40500778038250773, disc_loss = 0.060615326388199865
Trained batch 38 in epoch 4, gen_loss = 0.4074214337727962, disc_loss = 0.06162923742802097
Trained batch 39 in epoch 4, gen_loss = 0.40610146820545195, disc_loss = 0.06312535643810406
Trained batch 40 in epoch 4, gen_loss = 0.40669456705814455, disc_loss = 0.06216126222663173
Trained batch 41 in epoch 4, gen_loss = 0.4074321985244751, disc_loss = 0.060896807649571984
Trained batch 42 in epoch 4, gen_loss = 0.4075934873070828, disc_loss = 0.05989142683832798
Trained batch 43 in epoch 4, gen_loss = 0.40708177062598144, disc_loss = 0.059101160732097924
Trained batch 44 in epoch 4, gen_loss = 0.4059717092249129, disc_loss = 0.058751887776371504
Trained batch 45 in epoch 4, gen_loss = 0.4088525156611982, disc_loss = 0.0576962296668764
Trained batch 46 in epoch 4, gen_loss = 0.40923909303989814, disc_loss = 0.05788395134732127
Trained batch 47 in epoch 4, gen_loss = 0.410136337702473, disc_loss = 0.05825212280615233
Trained batch 48 in epoch 4, gen_loss = 0.40935248258162515, disc_loss = 0.05723331905711366
Trained batch 49 in epoch 4, gen_loss = 0.40895277976989747, disc_loss = 0.05627344842068851
Trained batch 50 in epoch 4, gen_loss = 0.4089482029279073, disc_loss = 0.05555267401003078
Trained batch 51 in epoch 4, gen_loss = 0.4059832606178064, disc_loss = 0.055557433471012004
Trained batch 52 in epoch 4, gen_loss = 0.4063842240369545, disc_loss = 0.05547342241196981
Trained batch 53 in epoch 4, gen_loss = 0.40746319901060174, disc_loss = 0.05510876081987388
Trained batch 54 in epoch 4, gen_loss = 0.4083254705775868, disc_loss = 0.054445078249343415
Trained batch 55 in epoch 4, gen_loss = 0.4078367788876806, disc_loss = 0.053650382498744875
Trained batch 56 in epoch 4, gen_loss = 0.40836963737220094, disc_loss = 0.05290878091105505
Trained batch 57 in epoch 4, gen_loss = 0.4094652626021155, disc_loss = 0.05237410118771267
Trained batch 58 in epoch 4, gen_loss = 0.40998710767697477, disc_loss = 0.05164741346675713
Trained batch 59 in epoch 4, gen_loss = 0.4101786146561305, disc_loss = 0.050889949888611834
Trained batch 60 in epoch 4, gen_loss = 0.4099652249304975, disc_loss = 0.050530787328349765
Trained batch 61 in epoch 4, gen_loss = 0.40996220611756845, disc_loss = 0.049977615640889254
Trained batch 62 in epoch 4, gen_loss = 0.41191346872420537, disc_loss = 0.04934340205398344
Trained batch 63 in epoch 4, gen_loss = 0.41151999961584806, disc_loss = 0.048728033565566875
Trained batch 64 in epoch 4, gen_loss = 0.41109958382753226, disc_loss = 0.04812135832527509
Trained batch 65 in epoch 4, gen_loss = 0.4109950557802663, disc_loss = 0.047983860526459685
Trained batch 66 in epoch 4, gen_loss = 0.4105013875818964, disc_loss = 0.04762479044330209
Trained batch 67 in epoch 4, gen_loss = 0.4122778825900134, disc_loss = 0.048404264578814894
Trained batch 68 in epoch 4, gen_loss = 0.411557137966156, disc_loss = 0.04915599237479593
Trained batch 69 in epoch 4, gen_loss = 0.4118180602788925, disc_loss = 0.04899421412763851
Trained batch 70 in epoch 4, gen_loss = 0.41116954617097345, disc_loss = 0.050540882451328595
Trained batch 71 in epoch 4, gen_loss = 0.41071495455172324, disc_loss = 0.05303549242671579
Trained batch 72 in epoch 4, gen_loss = 0.4100861173786529, disc_loss = 0.052743622892829654
Trained batch 73 in epoch 4, gen_loss = 0.4096357218317083, disc_loss = 0.05305905598593322
Trained batch 74 in epoch 4, gen_loss = 0.40985456546147664, disc_loss = 0.053248966125150524
Trained batch 75 in epoch 4, gen_loss = 0.4088869173275797, disc_loss = 0.05558373581765121
Trained batch 76 in epoch 4, gen_loss = 0.4086312171700713, disc_loss = 0.05660028019073335
Trained batch 77 in epoch 4, gen_loss = 0.4085052571235559, disc_loss = 0.05675120077406367
Trained batch 78 in epoch 4, gen_loss = 0.40809005876130694, disc_loss = 0.057040969204581994
Trained batch 79 in epoch 4, gen_loss = 0.4089922647923231, disc_loss = 0.057151420682203025
Trained batch 80 in epoch 4, gen_loss = 0.40937988036944545, disc_loss = 0.056805504175523915
Trained batch 81 in epoch 4, gen_loss = 0.4087148890262697, disc_loss = 0.05668856138817784
Trained batch 82 in epoch 4, gen_loss = 0.4084281181714621, disc_loss = 0.056435680387160146
Trained batch 83 in epoch 4, gen_loss = 0.40899662602515446, disc_loss = 0.05599623336456716
Trained batch 84 in epoch 4, gen_loss = 0.40757489730330076, disc_loss = 0.05632857482003815
Trained batch 85 in epoch 4, gen_loss = 0.40875827191874037, disc_loss = 0.06155856104221109
Trained batch 86 in epoch 4, gen_loss = 0.40807477496136196, disc_loss = 0.06260653280107112
Trained batch 87 in epoch 4, gen_loss = 0.407723547721451, disc_loss = 0.06309706526173448
Trained batch 88 in epoch 4, gen_loss = 0.40749657890769875, disc_loss = 0.06278829622930021
Trained batch 89 in epoch 4, gen_loss = 0.40701676739586723, disc_loss = 0.06253484635510378
Trained batch 90 in epoch 4, gen_loss = 0.40784543457922046, disc_loss = 0.06206804807656086
Trained batch 91 in epoch 4, gen_loss = 0.40783415669980255, disc_loss = 0.06154116477979266
Trained batch 92 in epoch 4, gen_loss = 0.4081948040634073, disc_loss = 0.06100185620047713
Trained batch 93 in epoch 4, gen_loss = 0.40834547357356293, disc_loss = 0.06044212740628009
Trained batch 94 in epoch 4, gen_loss = 0.40794307307193156, disc_loss = 0.06012457262136434
Trained batch 95 in epoch 4, gen_loss = 0.40828035088876885, disc_loss = 0.060720541417443506
Trained batch 96 in epoch 4, gen_loss = 0.40753676934340566, disc_loss = 0.0645664176644431
Trained batch 97 in epoch 4, gen_loss = 0.4074402211271987, disc_loss = 0.06489697834286763
Trained batch 98 in epoch 4, gen_loss = 0.4082704213532535, disc_loss = 0.06466767596400748
Trained batch 99 in epoch 4, gen_loss = 0.408009772002697, disc_loss = 0.06499179845675826
Trained batch 100 in epoch 4, gen_loss = 0.40876293093851296, disc_loss = 0.06500974074374921
Trained batch 101 in epoch 4, gen_loss = 0.40879855085821715, disc_loss = 0.06476314868047542
Trained batch 102 in epoch 4, gen_loss = 0.40867722092322933, disc_loss = 0.06432158487297378
Trained batch 103 in epoch 4, gen_loss = 0.4097171528981282, disc_loss = 0.06389868554945749
Trained batch 104 in epoch 4, gen_loss = 0.4095291711035229, disc_loss = 0.0639264289999292
Trained batch 105 in epoch 4, gen_loss = 0.4098449248187947, disc_loss = 0.06574491075819956
Trained batch 106 in epoch 4, gen_loss = 0.4092155012571923, disc_loss = 0.06634081762597382
Trained batch 107 in epoch 4, gen_loss = 0.4091708662885207, disc_loss = 0.06712988876151266
Trained batch 108 in epoch 4, gen_loss = 0.4088237971887676, disc_loss = 0.0670563622523065
Trained batch 109 in epoch 4, gen_loss = 0.4098836300047961, disc_loss = 0.06655518639494072
Trained batch 110 in epoch 4, gen_loss = 0.4099746075299409, disc_loss = 0.06602455965486599
Trained batch 111 in epoch 4, gen_loss = 0.41018157532172544, disc_loss = 0.06563650295720436
Trained batch 112 in epoch 4, gen_loss = 0.40979389121047166, disc_loss = 0.06541671826034388
Trained batch 113 in epoch 4, gen_loss = 0.4102427269283094, disc_loss = 0.06507092481887523
Trained batch 114 in epoch 4, gen_loss = 0.410304538063381, disc_loss = 0.0647396567520564
Trained batch 115 in epoch 4, gen_loss = 0.41048722714185715, disc_loss = 0.06478103479482876
Trained batch 116 in epoch 4, gen_loss = 0.41041637918887997, disc_loss = 0.06429946470735037
Trained batch 117 in epoch 4, gen_loss = 0.4107864966331902, disc_loss = 0.06389202509406891
Trained batch 118 in epoch 4, gen_loss = 0.4109788499459499, disc_loss = 0.0636849549927694
Trained batch 119 in epoch 4, gen_loss = 0.4109002267320951, disc_loss = 0.0633718080081356
Trained batch 120 in epoch 4, gen_loss = 0.41093186381434604, disc_loss = 0.06305762508514622
Trained batch 121 in epoch 4, gen_loss = 0.4102160217332058, disc_loss = 0.06397484498266436
Trained batch 122 in epoch 4, gen_loss = 0.41135280015991954, disc_loss = 0.06780637218049024
Trained batch 123 in epoch 4, gen_loss = 0.41113749891519547, disc_loss = 0.06771484412808693
Trained batch 124 in epoch 4, gen_loss = 0.41059030532836915, disc_loss = 0.06769023304060101
Trained batch 125 in epoch 4, gen_loss = 0.41156168352989925, disc_loss = 0.06738347186529565
Trained batch 126 in epoch 4, gen_loss = 0.41144499370432275, disc_loss = 0.06712482613328052
Trained batch 127 in epoch 4, gen_loss = 0.411058017751202, disc_loss = 0.06739350089992513
Trained batch 128 in epoch 4, gen_loss = 0.4112769617128742, disc_loss = 0.06926001049939168
Trained batch 129 in epoch 4, gen_loss = 0.4107507662131236, disc_loss = 0.06901854725482945
Trained batch 130 in epoch 4, gen_loss = 0.41060204292071684, disc_loss = 0.0688958125835896
Trained batch 131 in epoch 4, gen_loss = 0.41088830769965146, disc_loss = 0.06862927574283359
Trained batch 132 in epoch 4, gen_loss = 0.41091719650684444, disc_loss = 0.06825590676004838
Trained batch 133 in epoch 4, gen_loss = 0.41103961885865054, disc_loss = 0.0682641606840458
Trained batch 134 in epoch 4, gen_loss = 0.4108113993097235, disc_loss = 0.06810942989325634
Trained batch 135 in epoch 4, gen_loss = 0.4112236523891197, disc_loss = 0.06777041623546906
Trained batch 136 in epoch 4, gen_loss = 0.4111528233455045, disc_loss = 0.0674573806603949
Trained batch 137 in epoch 4, gen_loss = 0.41104804260143335, disc_loss = 0.06708322824788807
Trained batch 138 in epoch 4, gen_loss = 0.41102999320133127, disc_loss = 0.06729108392991287
Trained batch 139 in epoch 4, gen_loss = 0.41008122201476777, disc_loss = 0.06794493025767484
Trained batch 140 in epoch 4, gen_loss = 0.41019359822814344, disc_loss = 0.06824341958309425
Trained batch 141 in epoch 4, gen_loss = 0.40995744626287006, disc_loss = 0.06826744131861963
Trained batch 142 in epoch 4, gen_loss = 0.41006537021456896, disc_loss = 0.06790367826832445
Trained batch 143 in epoch 4, gen_loss = 0.41034961036509937, disc_loss = 0.06813781160356787
Trained batch 144 in epoch 4, gen_loss = 0.40997439499559074, disc_loss = 0.06820170114073774
Trained batch 145 in epoch 4, gen_loss = 0.41102597607325203, disc_loss = 0.06801926816992257
Trained batch 146 in epoch 4, gen_loss = 0.4111322484859804, disc_loss = 0.06764749456893931
Trained batch 147 in epoch 4, gen_loss = 0.4117403614359933, disc_loss = 0.067273369691385
Trained batch 148 in epoch 4, gen_loss = 0.41160224868147166, disc_loss = 0.06688570417776304
Trained batch 149 in epoch 4, gen_loss = 0.41150212069352465, disc_loss = 0.06650688436813652
Trained batch 150 in epoch 4, gen_loss = 0.4115226470082011, disc_loss = 0.06653493457467646
Trained batch 151 in epoch 4, gen_loss = 0.41080564534977865, disc_loss = 0.06729556181112696
Trained batch 152 in epoch 4, gen_loss = 0.4112333589129978, disc_loss = 0.06757003553150819
Trained batch 153 in epoch 4, gen_loss = 0.4117338429023693, disc_loss = 0.06735419092228176
Trained batch 154 in epoch 4, gen_loss = 0.41191028664189, disc_loss = 0.06696650949156573
Trained batch 155 in epoch 4, gen_loss = 0.41230468662121356, disc_loss = 0.0665793718638806
Trained batch 156 in epoch 4, gen_loss = 0.4123531929246939, disc_loss = 0.06626206400928794
Trained batch 157 in epoch 4, gen_loss = 0.4124386521834361, disc_loss = 0.06589480326805688
Trained batch 158 in epoch 4, gen_loss = 0.41230957912948896, disc_loss = 0.06556639315431598
Trained batch 159 in epoch 4, gen_loss = 0.4127118971198797, disc_loss = 0.0651948714745231
Trained batch 160 in epoch 4, gen_loss = 0.41258740184469994, disc_loss = 0.06483659359643826
Trained batch 161 in epoch 4, gen_loss = 0.41228254912076173, disc_loss = 0.06455418069410011
Trained batch 162 in epoch 4, gen_loss = 0.4125456568653598, disc_loss = 0.06422243608116097
Trained batch 163 in epoch 4, gen_loss = 0.41234811704333235, disc_loss = 0.06394454039826353
Trained batch 164 in epoch 4, gen_loss = 0.4123685444846298, disc_loss = 0.06367468323953676
Trained batch 165 in epoch 4, gen_loss = 0.41227427735386124, disc_loss = 0.0633727984688054
Trained batch 166 in epoch 4, gen_loss = 0.41239091468428424, disc_loss = 0.06305318942828896
Trained batch 167 in epoch 4, gen_loss = 0.4124012795232591, disc_loss = 0.06278268384492203
Trained batch 168 in epoch 4, gen_loss = 0.41319252189094496, disc_loss = 0.06257174414521932
Trained batch 169 in epoch 4, gen_loss = 0.4129850924015045, disc_loss = 0.06226468954837936
Trained batch 170 in epoch 4, gen_loss = 0.4126476882493984, disc_loss = 0.06195687469672303
Trained batch 171 in epoch 4, gen_loss = 0.4125471641851026, disc_loss = 0.061778628004736505
Trained batch 172 in epoch 4, gen_loss = 0.41247371493736446, disc_loss = 0.06146101023452733
Trained batch 173 in epoch 4, gen_loss = 0.41238390799911545, disc_loss = 0.061248887841450585
Trained batch 174 in epoch 4, gen_loss = 0.4117300406524113, disc_loss = 0.06102479589570846
Trained batch 175 in epoch 4, gen_loss = 0.41204401799900964, disc_loss = 0.060771990416634995
Trained batch 176 in epoch 4, gen_loss = 0.4117511406456683, disc_loss = 0.0605524266480684
Trained batch 177 in epoch 4, gen_loss = 0.4123163903027438, disc_loss = 0.060351637199918706
Trained batch 178 in epoch 4, gen_loss = 0.41253505106078847, disc_loss = 0.06016738148531018
Trained batch 179 in epoch 4, gen_loss = 0.41247386634349825, disc_loss = 0.05999575853089078
Trained batch 180 in epoch 4, gen_loss = 0.4123578820768641, disc_loss = 0.05973139185283477
Trained batch 181 in epoch 4, gen_loss = 0.41236510496218126, disc_loss = 0.059444553372296656
Trained batch 182 in epoch 4, gen_loss = 0.412501819961058, disc_loss = 0.05915207464166515
Trained batch 183 in epoch 4, gen_loss = 0.4128770241918771, disc_loss = 0.05888508586719146
Trained batch 184 in epoch 4, gen_loss = 0.41293728963748827, disc_loss = 0.05860644510972339
Trained batch 185 in epoch 4, gen_loss = 0.41281242428287385, disc_loss = 0.05832306620594795
Trained batch 186 in epoch 4, gen_loss = 0.41303400033935506, disc_loss = 0.05806594677667885
Trained batch 187 in epoch 4, gen_loss = 0.4132507563905513, disc_loss = 0.05782225999505596
Trained batch 188 in epoch 4, gen_loss = 0.413984392055128, disc_loss = 0.057569851162572384
Trained batch 189 in epoch 4, gen_loss = 0.4140359848737717, disc_loss = 0.05736738762965328
Trained batch 190 in epoch 4, gen_loss = 0.4136919149865655, disc_loss = 0.057204312913080785
Trained batch 191 in epoch 4, gen_loss = 0.41342988951752585, disc_loss = 0.05696182449658712
Trained batch 192 in epoch 4, gen_loss = 0.41364181072600764, disc_loss = 0.05670022993671848
Trained batch 193 in epoch 4, gen_loss = 0.4137711193143707, disc_loss = 0.05644223889691237
Trained batch 194 in epoch 4, gen_loss = 0.41366861569575775, disc_loss = 0.056187690670291585
Trained batch 195 in epoch 4, gen_loss = 0.4138065789427076, disc_loss = 0.05599877773308937
Trained batch 196 in epoch 4, gen_loss = 0.41414524486222243, disc_loss = 0.05590383009748713
Trained batch 197 in epoch 4, gen_loss = 0.413996591863006, disc_loss = 0.05567340250832565
Trained batch 198 in epoch 4, gen_loss = 0.41397756517832, disc_loss = 0.055431325206224194
Trained batch 199 in epoch 4, gen_loss = 0.41386051788926126, disc_loss = 0.055222074186895044
Trained batch 200 in epoch 4, gen_loss = 0.4138359022674276, disc_loss = 0.05509973748526837
Trained batch 201 in epoch 4, gen_loss = 0.41414012811561624, disc_loss = 0.05490441083917302
Trained batch 202 in epoch 4, gen_loss = 0.4143324043656805, disc_loss = 0.05468023517237875
Trained batch 203 in epoch 4, gen_loss = 0.41467978980611353, disc_loss = 0.05446289882164303
Trained batch 204 in epoch 4, gen_loss = 0.4145846651821602, disc_loss = 0.05429647453810747
Trained batch 205 in epoch 4, gen_loss = 0.4145929809044866, disc_loss = 0.054292852852439275
Trained batch 206 in epoch 4, gen_loss = 0.41489940521797697, disc_loss = 0.05406995594798439
Trained batch 207 in epoch 4, gen_loss = 0.4151253796254213, disc_loss = 0.05388456357132572
Trained batch 208 in epoch 4, gen_loss = 0.41525851311295797, disc_loss = 0.05366467850942289
Trained batch 209 in epoch 4, gen_loss = 0.4152366619734537, disc_loss = 0.053444134248864086
Trained batch 210 in epoch 4, gen_loss = 0.41516361092504167, disc_loss = 0.05325960947015274
Trained batch 211 in epoch 4, gen_loss = 0.41496119971545237, disc_loss = 0.053074814735050754
Trained batch 212 in epoch 4, gen_loss = 0.4149164011780645, disc_loss = 0.052861159920972275
Trained batch 213 in epoch 4, gen_loss = 0.4153827481737761, disc_loss = 0.05266863360966199
Trained batch 214 in epoch 4, gen_loss = 0.41561331721239314, disc_loss = 0.05248117747521678
Trained batch 215 in epoch 4, gen_loss = 0.41560515940741255, disc_loss = 0.052302265906258034
Trained batch 216 in epoch 4, gen_loss = 0.41564147249894207, disc_loss = 0.05209964130520134
Trained batch 217 in epoch 4, gen_loss = 0.41541441441129107, disc_loss = 0.05189666885096546
Trained batch 218 in epoch 4, gen_loss = 0.41547706995380523, disc_loss = 0.05168341882059087
Trained batch 219 in epoch 4, gen_loss = 0.41521152298558844, disc_loss = 0.05146822695070031
Trained batch 220 in epoch 4, gen_loss = 0.4151111700955559, disc_loss = 0.051269308223528154
Trained batch 221 in epoch 4, gen_loss = 0.41524482820485087, disc_loss = 0.051131662788909966
Trained batch 222 in epoch 4, gen_loss = 0.41522188023601414, disc_loss = 0.05092287808030242
Trained batch 223 in epoch 4, gen_loss = 0.41557208967528175, disc_loss = 0.05072382066490328
Trained batch 224 in epoch 4, gen_loss = 0.4155797587500678, disc_loss = 0.05052140643406246
Trained batch 225 in epoch 4, gen_loss = 0.41569462946030944, disc_loss = 0.050316535191923646
Trained batch 226 in epoch 4, gen_loss = 0.4157116927764489, disc_loss = 0.050140883941777736
Trained batch 227 in epoch 4, gen_loss = 0.41560448052590354, disc_loss = 0.04993839192678008
Trained batch 228 in epoch 4, gen_loss = 0.41572051732821236, disc_loss = 0.04979651962207655
Trained batch 229 in epoch 4, gen_loss = 0.4159053015968074, disc_loss = 0.049610410701564474
Trained batch 230 in epoch 4, gen_loss = 0.41601836952296173, disc_loss = 0.04944411658952053
Trained batch 231 in epoch 4, gen_loss = 0.4162840836777769, disc_loss = 0.049272261140466636
Trained batch 232 in epoch 4, gen_loss = 0.41609156374767614, disc_loss = 0.0490788522240398
Trained batch 233 in epoch 4, gen_loss = 0.41622717602130693, disc_loss = 0.04892972811984901
Trained batch 234 in epoch 4, gen_loss = 0.4160793622757526, disc_loss = 0.04874133197987016
Trained batch 235 in epoch 4, gen_loss = 0.41566950550018733, disc_loss = 0.04855750931892544
Trained batch 236 in epoch 4, gen_loss = 0.41573599823416535, disc_loss = 0.048412381343244874
Trained batch 237 in epoch 4, gen_loss = 0.4156006254067942, disc_loss = 0.04825627948392276
Trained batch 238 in epoch 4, gen_loss = 0.41559980728636225, disc_loss = 0.048130372069604604
Trained batch 239 in epoch 4, gen_loss = 0.4155375455816587, disc_loss = 0.04794854102074168
Trained batch 240 in epoch 4, gen_loss = 0.4156383351418982, disc_loss = 0.04778524040905334
Trained batch 241 in epoch 4, gen_loss = 0.4157668535620713, disc_loss = 0.0476103015994453
Trained batch 242 in epoch 4, gen_loss = 0.4154636745835528, disc_loss = 0.04743194945900099
Trained batch 243 in epoch 4, gen_loss = 0.4156107280830868, disc_loss = 0.04726086103273403
Trained batch 244 in epoch 4, gen_loss = 0.4157567740703116, disc_loss = 0.04710507316286771
Trained batch 245 in epoch 4, gen_loss = 0.4157117407738678, disc_loss = 0.046997033621797836
Trained batch 246 in epoch 4, gen_loss = 0.4157281335790148, disc_loss = 0.04717649952489657
Trained batch 247 in epoch 4, gen_loss = 0.41544139901957206, disc_loss = 0.047078665227614225
Trained batch 248 in epoch 4, gen_loss = 0.4154864277944986, disc_loss = 0.04692728908164015
Trained batch 249 in epoch 4, gen_loss = 0.4155867196321487, disc_loss = 0.046791566783562305
Trained batch 250 in epoch 4, gen_loss = 0.4156202005437646, disc_loss = 0.046626809453851434
Trained batch 251 in epoch 4, gen_loss = 0.41567954633917126, disc_loss = 0.04648619466682985
Trained batch 252 in epoch 4, gen_loss = 0.4159814040415843, disc_loss = 0.046349094396552784
Trained batch 253 in epoch 4, gen_loss = 0.4161094948062746, disc_loss = 0.04619754296837477
Trained batch 254 in epoch 4, gen_loss = 0.4160790144228468, disc_loss = 0.046063979612846
Trained batch 255 in epoch 4, gen_loss = 0.4162626932375133, disc_loss = 0.04607824463164434
Trained batch 256 in epoch 4, gen_loss = 0.4162314748717653, disc_loss = 0.04616146105620648
Trained batch 257 in epoch 4, gen_loss = 0.4162867021884105, disc_loss = 0.04605856275027113
Trained batch 258 in epoch 4, gen_loss = 0.41612644119612496, disc_loss = 0.04609278599555428
Trained batch 259 in epoch 4, gen_loss = 0.41599994829067816, disc_loss = 0.046053247483303916
Trained batch 260 in epoch 4, gen_loss = 0.4160033061358207, disc_loss = 0.04591577797699934
Trained batch 261 in epoch 4, gen_loss = 0.4158973672235285, disc_loss = 0.045788573406864215
Trained batch 262 in epoch 4, gen_loss = 0.4159275594772948, disc_loss = 0.04577549398936926
Trained batch 263 in epoch 4, gen_loss = 0.41566823490641336, disc_loss = 0.046279369056168376
Trained batch 264 in epoch 4, gen_loss = 0.4160835805928932, disc_loss = 0.04746028619976538
Trained batch 265 in epoch 4, gen_loss = 0.41576022245830163, disc_loss = 0.048106084157593716
Trained batch 266 in epoch 4, gen_loss = 0.4156644395674659, disc_loss = 0.0489970561368077
Trained batch 267 in epoch 4, gen_loss = 0.4154901341048639, disc_loss = 0.050221574694307436
Trained batch 268 in epoch 4, gen_loss = 0.41552109689517536, disc_loss = 0.05134784894888064
Trained batch 269 in epoch 4, gen_loss = 0.4155309106464739, disc_loss = 0.051895127880076566
Trained batch 270 in epoch 4, gen_loss = 0.41553320304054175, disc_loss = 0.05187040404502536
Trained batch 271 in epoch 4, gen_loss = 0.41528713933246975, disc_loss = 0.052023244960069215
Trained batch 272 in epoch 4, gen_loss = 0.41542706679511854, disc_loss = 0.05236882259966908
Trained batch 273 in epoch 4, gen_loss = 0.41549789405217136, disc_loss = 0.0522972645754688
Trained batch 274 in epoch 4, gen_loss = 0.4153294889493422, disc_loss = 0.052517960904674095
Trained batch 275 in epoch 4, gen_loss = 0.414835792304813, disc_loss = 0.05297402456483763
Trained batch 276 in epoch 4, gen_loss = 0.41509386047129165, disc_loss = 0.053558310359339854
Trained batch 277 in epoch 4, gen_loss = 0.41472613479164866, disc_loss = 0.05381841964939301
Trained batch 278 in epoch 4, gen_loss = 0.41479431909899556, disc_loss = 0.05386040222874466
Trained batch 279 in epoch 4, gen_loss = 0.4145315490663052, disc_loss = 0.05397183540543275
Trained batch 280 in epoch 4, gen_loss = 0.4148562178280854, disc_loss = 0.05392135525274743
Trained batch 281 in epoch 4, gen_loss = 0.4148815503568514, disc_loss = 0.05379542397295541
Trained batch 282 in epoch 4, gen_loss = 0.4148571593390758, disc_loss = 0.05376946296240121
Trained batch 283 in epoch 4, gen_loss = 0.41489621535153454, disc_loss = 0.0537348483610426
Trained batch 284 in epoch 4, gen_loss = 0.4147854336521082, disc_loss = 0.053602109574957896
Trained batch 285 in epoch 4, gen_loss = 0.41466834922353707, disc_loss = 0.053516131845283345
Trained batch 286 in epoch 4, gen_loss = 0.414825974544997, disc_loss = 0.053360006564300025
Trained batch 287 in epoch 4, gen_loss = 0.4151191617258721, disc_loss = 0.05324596190217158
Trained batch 288 in epoch 4, gen_loss = 0.4150344313840965, disc_loss = 0.053093881868341596
Trained batch 289 in epoch 4, gen_loss = 0.4149899611185337, disc_loss = 0.052953786576359435
Trained batch 290 in epoch 4, gen_loss = 0.4148625134397618, disc_loss = 0.05291785921299785
Trained batch 291 in epoch 4, gen_loss = 0.4150322534858364, disc_loss = 0.05281181129537625
Trained batch 292 in epoch 4, gen_loss = 0.4148305799977364, disc_loss = 0.05268261207858857
Trained batch 293 in epoch 4, gen_loss = 0.41493897890152576, disc_loss = 0.05252862277877878
Trained batch 294 in epoch 4, gen_loss = 0.41494521165298204, disc_loss = 0.05236954692340756
Trained batch 295 in epoch 4, gen_loss = 0.4148636957680857, disc_loss = 0.05251600616768858
Trained batch 296 in epoch 4, gen_loss = 0.4148590719258344, disc_loss = 0.05485378053534763
Trained batch 297 in epoch 4, gen_loss = 0.4147521421413294, disc_loss = 0.0552327756741828
Trained batch 298 in epoch 4, gen_loss = 0.4144878947615225, disc_loss = 0.055760250524944786
Trained batch 299 in epoch 4, gen_loss = 0.41428845743338266, disc_loss = 0.05581373660049091
Trained batch 300 in epoch 4, gen_loss = 0.41433563234402093, disc_loss = 0.05606324394756427
Trained batch 301 in epoch 4, gen_loss = 0.4143123289212486, disc_loss = 0.05602590545598689
Trained batch 302 in epoch 4, gen_loss = 0.41424670510559586, disc_loss = 0.05593777255680744
Trained batch 303 in epoch 4, gen_loss = 0.4144143007303539, disc_loss = 0.05587230962976862
Trained batch 304 in epoch 4, gen_loss = 0.41423656285786237, disc_loss = 0.05585743665970007
Trained batch 305 in epoch 4, gen_loss = 0.4139486471422357, disc_loss = 0.056030115838546085
Trained batch 306 in epoch 4, gen_loss = 0.4140666101965143, disc_loss = 0.05588838070819112
Trained batch 307 in epoch 4, gen_loss = 0.41414215986604813, disc_loss = 0.05576887800412664
Trained batch 308 in epoch 4, gen_loss = 0.41439236136316093, disc_loss = 0.05563010981692224
Trained batch 309 in epoch 4, gen_loss = 0.4138983647669515, disc_loss = 0.05578761175124636
Trained batch 310 in epoch 4, gen_loss = 0.4141330118156323, disc_loss = 0.05568234534287328
Trained batch 311 in epoch 4, gen_loss = 0.4139997684038602, disc_loss = 0.055531123687381834
Trained batch 312 in epoch 4, gen_loss = 0.41400115139568194, disc_loss = 0.0554171355765539
Trained batch 313 in epoch 4, gen_loss = 0.414021046108501, disc_loss = 0.055310932289109015
Trained batch 314 in epoch 4, gen_loss = 0.4141069497380938, disc_loss = 0.05518055071995135
Trained batch 315 in epoch 4, gen_loss = 0.41434257005966163, disc_loss = 0.05507971814250031
Trained batch 316 in epoch 4, gen_loss = 0.41415487018293384, disc_loss = 0.05497664083764897
Trained batch 317 in epoch 4, gen_loss = 0.41403823425559877, disc_loss = 0.05483768908336243
Trained batch 318 in epoch 4, gen_loss = 0.41396898507698204, disc_loss = 0.05470713491764702
Trained batch 319 in epoch 4, gen_loss = 0.41403158018365505, disc_loss = 0.05456134388659848
Trained batch 320 in epoch 4, gen_loss = 0.41396891393022744, disc_loss = 0.054439665603152596
Trained batch 321 in epoch 4, gen_loss = 0.4139039883887546, disc_loss = 0.054306355725846585
Trained batch 322 in epoch 4, gen_loss = 0.41403104129590484, disc_loss = 0.05416370110713153
Trained batch 323 in epoch 4, gen_loss = 0.41397511729119735, disc_loss = 0.05406163876767006
Trained batch 324 in epoch 4, gen_loss = 0.41391177516717176, disc_loss = 0.054522735798874726
Trained batch 325 in epoch 4, gen_loss = 0.4140383594789388, disc_loss = 0.055935918097812794
Trained batch 326 in epoch 4, gen_loss = 0.413741323288063, disc_loss = 0.0560295523503163
Trained batch 327 in epoch 4, gen_loss = 0.41371538989791057, disc_loss = 0.05599376333383389
Trained batch 328 in epoch 4, gen_loss = 0.4136077710016883, disc_loss = 0.05588071958776167
Trained batch 329 in epoch 4, gen_loss = 0.41348752496820507, disc_loss = 0.055742766447083064
Trained batch 330 in epoch 4, gen_loss = 0.4134230183330547, disc_loss = 0.055598513846457275
Trained batch 331 in epoch 4, gen_loss = 0.4133421820868929, disc_loss = 0.05544813696704581
Trained batch 332 in epoch 4, gen_loss = 0.4132581877636838, disc_loss = 0.05530064377805089
Trained batch 333 in epoch 4, gen_loss = 0.4133417581369777, disc_loss = 0.05514917500222291
Trained batch 334 in epoch 4, gen_loss = 0.41342549626506975, disc_loss = 0.05500553911273826
Trained batch 335 in epoch 4, gen_loss = 0.4133708571926469, disc_loss = 0.05487338471686512
Trained batch 336 in epoch 4, gen_loss = 0.41353438171151835, disc_loss = 0.05474140585016028
Trained batch 337 in epoch 4, gen_loss = 0.4131526909989013, disc_loss = 0.05472985663197758
Trained batch 338 in epoch 4, gen_loss = 0.4134229592165764, disc_loss = 0.054711921996324374
Trained batch 339 in epoch 4, gen_loss = 0.41362245249397617, disc_loss = 0.05462408863309333
Trained batch 340 in epoch 4, gen_loss = 0.4135314285580364, disc_loss = 0.05451163544546256
Trained batch 341 in epoch 4, gen_loss = 0.41364776391034935, disc_loss = 0.054496629369221845
Trained batch 342 in epoch 4, gen_loss = 0.4134504829829358, disc_loss = 0.05474618051076205
Trained batch 343 in epoch 4, gen_loss = 0.4133268066270407, disc_loss = 0.05519582538968385
Trained batch 344 in epoch 4, gen_loss = 0.41343596828156626, disc_loss = 0.055629823171952066
Trained batch 345 in epoch 4, gen_loss = 0.4133715650249768, disc_loss = 0.055619290441737614
Trained batch 346 in epoch 4, gen_loss = 0.413241768175312, disc_loss = 0.055551298315601925
Trained batch 347 in epoch 4, gen_loss = 0.41332003345777246, disc_loss = 0.05543061330962669
Trained batch 348 in epoch 4, gen_loss = 0.41316568911246376, disc_loss = 0.05531392724021074
Trained batch 349 in epoch 4, gen_loss = 0.41315222076007296, disc_loss = 0.055172552531585095
Trained batch 350 in epoch 4, gen_loss = 0.41299650616455624, disc_loss = 0.05504334633214734
Trained batch 351 in epoch 4, gen_loss = 0.4132336668500846, disc_loss = 0.0549200593787563
Trained batch 352 in epoch 4, gen_loss = 0.41317711867624235, disc_loss = 0.05478829915157754
Trained batch 353 in epoch 4, gen_loss = 0.4131305326344603, disc_loss = 0.05474840042886382
Trained batch 354 in epoch 4, gen_loss = 0.4134264802429038, disc_loss = 0.054715725195817126
Trained batch 355 in epoch 4, gen_loss = 0.41333297506142197, disc_loss = 0.05457851111894118
Trained batch 356 in epoch 4, gen_loss = 0.41324396986587375, disc_loss = 0.05446358542779789
Trained batch 357 in epoch 4, gen_loss = 0.4129813517438633, disc_loss = 0.05433277144908447
Trained batch 358 in epoch 4, gen_loss = 0.4129121106813213, disc_loss = 0.05421944736557543
Trained batch 359 in epoch 4, gen_loss = 0.4127387552625603, disc_loss = 0.054096744334997816
Trained batch 360 in epoch 4, gen_loss = 0.4127807995288986, disc_loss = 0.053957122396755125
Trained batch 361 in epoch 4, gen_loss = 0.4126661329308926, disc_loss = 0.053828041445469044
Trained batch 362 in epoch 4, gen_loss = 0.4126458581814096, disc_loss = 0.05369464652907852
Trained batch 363 in epoch 4, gen_loss = 0.41284560559542627, disc_loss = 0.05356272686193544
Trained batch 364 in epoch 4, gen_loss = 0.4128155000405769, disc_loss = 0.053462537781858485
Trained batch 365 in epoch 4, gen_loss = 0.41279776117515043, disc_loss = 0.0533953447644268
Trained batch 366 in epoch 4, gen_loss = 0.41294898941341474, disc_loss = 0.0532953710090978
Trained batch 367 in epoch 4, gen_loss = 0.41297927369242127, disc_loss = 0.053447497943441544
Trained batch 368 in epoch 4, gen_loss = 0.4127834116217244, disc_loss = 0.05339542503322305
Trained batch 369 in epoch 4, gen_loss = 0.41274278558589317, disc_loss = 0.053356359069034257
Trained batch 370 in epoch 4, gen_loss = 0.4129774948818022, disc_loss = 0.05329893410489505
Trained batch 371 in epoch 4, gen_loss = 0.41310969932425406, disc_loss = 0.053168014915514816
Trained batch 372 in epoch 4, gen_loss = 0.41308772348207057, disc_loss = 0.053056618942187515
Trained batch 373 in epoch 4, gen_loss = 0.412901688227679, disc_loss = 0.05292794790136364
Trained batch 374 in epoch 4, gen_loss = 0.41300477234522504, disc_loss = 0.0528095573776712
Trained batch 375 in epoch 4, gen_loss = 0.4128108798981981, disc_loss = 0.05269383999675096
Trained batch 376 in epoch 4, gen_loss = 0.4128104981123927, disc_loss = 0.0525850401493407
Trained batch 377 in epoch 4, gen_loss = 0.4127783324352648, disc_loss = 0.05251784338529601
Trained batch 378 in epoch 4, gen_loss = 0.41281397408734527, disc_loss = 0.052442246057107886
Trained batch 379 in epoch 4, gen_loss = 0.41281599982788686, disc_loss = 0.052314783274318634
Trained batch 380 in epoch 4, gen_loss = 0.41272968953362915, disc_loss = 0.05221095995481304
Trained batch 381 in epoch 4, gen_loss = 0.41256404164885974, disc_loss = 0.0521016066585526
Trained batch 382 in epoch 4, gen_loss = 0.4127422130761508, disc_loss = 0.05220340418887103
Trained batch 383 in epoch 4, gen_loss = 0.4126075961006184, disc_loss = 0.052359414664654956
Trained batch 384 in epoch 4, gen_loss = 0.4125386569407079, disc_loss = 0.052348524418526464
Trained batch 385 in epoch 4, gen_loss = 0.4124843965385862, disc_loss = 0.05222618663647342
Trained batch 386 in epoch 4, gen_loss = 0.4124085054533118, disc_loss = 0.05213866353778587
Trained batch 387 in epoch 4, gen_loss = 0.4123409972670152, disc_loss = 0.05201701112583606
Trained batch 388 in epoch 4, gen_loss = 0.41229920537428866, disc_loss = 0.05190643724018186
Trained batch 389 in epoch 4, gen_loss = 0.4124152808617323, disc_loss = 0.051798463068926374
Trained batch 390 in epoch 4, gen_loss = 0.41249851070706495, disc_loss = 0.05168731513080637
Trained batch 391 in epoch 4, gen_loss = 0.412629633229606, disc_loss = 0.051585442099686976
Trained batch 392 in epoch 4, gen_loss = 0.41271089855344545, disc_loss = 0.051471438773720506
Trained batch 393 in epoch 4, gen_loss = 0.4126411613625318, disc_loss = 0.05136530281477111
Trained batch 394 in epoch 4, gen_loss = 0.41269899757602546, disc_loss = 0.05130560235474023
Trained batch 395 in epoch 4, gen_loss = 0.41270268685889966, disc_loss = 0.05119722122573435
Trained batch 396 in epoch 4, gen_loss = 0.41284899447366635, disc_loss = 0.05107905731714736
Trained batch 397 in epoch 4, gen_loss = 0.41316881191790406, disc_loss = 0.05096427070962069
Trained batch 398 in epoch 4, gen_loss = 0.41307231664358823, disc_loss = 0.05087169979227459
Trained batch 399 in epoch 4, gen_loss = 0.4130749597400427, disc_loss = 0.05077875241928268
Trained batch 400 in epoch 4, gen_loss = 0.41318047879045444, disc_loss = 0.05068175302890415
Trained batch 401 in epoch 4, gen_loss = 0.41313403481571237, disc_loss = 0.0505681238154561
Trained batch 402 in epoch 4, gen_loss = 0.4131806851468666, disc_loss = 0.05046791032536727
Trained batch 403 in epoch 4, gen_loss = 0.412881957643693, disc_loss = 0.050353062336245494
Trained batch 404 in epoch 4, gen_loss = 0.412689647483237, disc_loss = 0.050242953149049925
Trained batch 405 in epoch 4, gen_loss = 0.41281493903674515, disc_loss = 0.050137709635264
Trained batch 406 in epoch 4, gen_loss = 0.41284533793276007, disc_loss = 0.05002274543918779
Trained batch 407 in epoch 4, gen_loss = 0.41288256842423887, disc_loss = 0.04993526851039325
Trained batch 408 in epoch 4, gen_loss = 0.41257074176536507, disc_loss = 0.04992178528601518
Trained batch 409 in epoch 4, gen_loss = 0.4125899917468792, disc_loss = 0.05005928895652022
Trained batch 410 in epoch 4, gen_loss = 0.4124185936729403, disc_loss = 0.05005218961316902
Trained batch 411 in epoch 4, gen_loss = 0.4123704840691344, disc_loss = 0.04994424627200945
Trained batch 412 in epoch 4, gen_loss = 0.412316142430317, disc_loss = 0.04985544987791838
Trained batch 413 in epoch 4, gen_loss = 0.412365870775232, disc_loss = 0.0497520664377264
Trained batch 414 in epoch 4, gen_loss = 0.41233131662908806, disc_loss = 0.0497222290379949
Trained batch 415 in epoch 4, gen_loss = 0.41231091119922125, disc_loss = 0.04966545623420433
Trained batch 416 in epoch 4, gen_loss = 0.4122994839430427, disc_loss = 0.04955821382094005
Trained batch 417 in epoch 4, gen_loss = 0.4122240160498323, disc_loss = 0.04947262577340453
Trained batch 418 in epoch 4, gen_loss = 0.4122837515178899, disc_loss = 0.04936389531773517
Trained batch 419 in epoch 4, gen_loss = 0.4122552889443579, disc_loss = 0.0493089502106332
Trained batch 420 in epoch 4, gen_loss = 0.41228512410879703, disc_loss = 0.0492526386292638
Trained batch 421 in epoch 4, gen_loss = 0.4123895789068457, disc_loss = 0.04915609580224106
Trained batch 422 in epoch 4, gen_loss = 0.4125097590558072, disc_loss = 0.04905753537415842
Trained batch 423 in epoch 4, gen_loss = 0.4126022538908248, disc_loss = 0.04896078150080218
Trained batch 424 in epoch 4, gen_loss = 0.41245531299534965, disc_loss = 0.04887225624447798
Trained batch 425 in epoch 4, gen_loss = 0.4121625799108559, disc_loss = 0.048925055392598074
Trained batch 426 in epoch 4, gen_loss = 0.41224878265651105, disc_loss = 0.04969745485354171
Trained batch 427 in epoch 4, gen_loss = 0.4121539309342331, disc_loss = 0.04962120992925766
Trained batch 428 in epoch 4, gen_loss = 0.4119853391236081, disc_loss = 0.04958756486038593
Trained batch 429 in epoch 4, gen_loss = 0.41186969273312146, disc_loss = 0.04956500642922122
Trained batch 430 in epoch 4, gen_loss = 0.4118560630733065, disc_loss = 0.049486353985312675
Trained batch 431 in epoch 4, gen_loss = 0.4117284460614125, disc_loss = 0.04947917374698187
Trained batch 432 in epoch 4, gen_loss = 0.41150350307757527, disc_loss = 0.04976945521049718
Trained batch 433 in epoch 4, gen_loss = 0.4115766867102566, disc_loss = 0.05016432270839004
Trained batch 434 in epoch 4, gen_loss = 0.4114156007766724, disc_loss = 0.05021502522098693
Trained batch 435 in epoch 4, gen_loss = 0.4112811824734058, disc_loss = 0.050161348810150296
Trained batch 436 in epoch 4, gen_loss = 0.4114450620704712, disc_loss = 0.05027438635464749
Trained batch 437 in epoch 4, gen_loss = 0.41137225993964227, disc_loss = 0.050276208252722575
Trained batch 438 in epoch 4, gen_loss = 0.4114996505761201, disc_loss = 0.050194051624265136
Trained batch 439 in epoch 4, gen_loss = 0.411433417011391, disc_loss = 0.05038836477165618
Trained batch 440 in epoch 4, gen_loss = 0.41113051643717585, disc_loss = 0.050944281280011175
Trained batch 441 in epoch 4, gen_loss = 0.4111915192992439, disc_loss = 0.05099857420548881
Trained batch 442 in epoch 4, gen_loss = 0.4111251903710462, disc_loss = 0.05136905241238361
Trained batch 443 in epoch 4, gen_loss = 0.4111365677939879, disc_loss = 0.05160137642487497
Trained batch 444 in epoch 4, gen_loss = 0.41100114034802726, disc_loss = 0.05164634865666792
Trained batch 445 in epoch 4, gen_loss = 0.41091598583711103, disc_loss = 0.05165626528629023
Trained batch 446 in epoch 4, gen_loss = 0.41078778007953226, disc_loss = 0.05173377998400338
Trained batch 447 in epoch 4, gen_loss = 0.41086874276931795, disc_loss = 0.051743245648789786
Trained batch 448 in epoch 4, gen_loss = 0.4110916582141528, disc_loss = 0.05173609579004812
Trained batch 449 in epoch 4, gen_loss = 0.41113463832272423, disc_loss = 0.05165909779827214
Trained batch 450 in epoch 4, gen_loss = 0.4111426830159587, disc_loss = 0.05159887774153602
Trained batch 451 in epoch 4, gen_loss = 0.4111187667709536, disc_loss = 0.05166294684775784
Trained batch 452 in epoch 4, gen_loss = 0.41101231111859116, disc_loss = 0.05160652139947789
Trained batch 453 in epoch 4, gen_loss = 0.41098070236554757, disc_loss = 0.05152189556462075
Trained batch 454 in epoch 4, gen_loss = 0.4111106307951959, disc_loss = 0.05145436673588887
Trained batch 455 in epoch 4, gen_loss = 0.4111566726575818, disc_loss = 0.051378349957910054
Trained batch 456 in epoch 4, gen_loss = 0.4112433663995313, disc_loss = 0.05128077347864778
Trained batch 457 in epoch 4, gen_loss = 0.41118538841670255, disc_loss = 0.05118298649484918
Trained batch 458 in epoch 4, gen_loss = 0.41121415699748953, disc_loss = 0.051125742033963986
Trained batch 459 in epoch 4, gen_loss = 0.41125974097977513, disc_loss = 0.05102526941286076
Trained batch 460 in epoch 4, gen_loss = 0.4113428282375708, disc_loss = 0.05092585637080614
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 0.438992977142334, disc_loss = 0.005796720739454031
Trained batch 1 in epoch 5, gen_loss = 0.4916873276233673, disc_loss = 0.009465536335483193
Trained batch 2 in epoch 5, gen_loss = 0.43615901470184326, disc_loss = 0.009021674127628406
Trained batch 3 in epoch 5, gen_loss = 0.4450688585639, disc_loss = 0.008504441939294338
Trained batch 4 in epoch 5, gen_loss = 0.44601746201515197, disc_loss = 0.011534465104341507
Trained batch 5 in epoch 5, gen_loss = 0.4389855166276296, disc_loss = 0.011475575466950735
Trained batch 6 in epoch 5, gen_loss = 0.43585708311625887, disc_loss = 0.013546145920242583
Trained batch 7 in epoch 5, gen_loss = 0.4339783787727356, disc_loss = 0.01671129371970892
Trained batch 8 in epoch 5, gen_loss = 0.42131178908877903, disc_loss = 0.018191173672676086
Trained batch 9 in epoch 5, gen_loss = 0.4284699857234955, disc_loss = 0.018090040981769563
Trained batch 10 in epoch 5, gen_loss = 0.43996419689872046, disc_loss = 0.01895896294577555
Trained batch 11 in epoch 5, gen_loss = 0.4409540593624115, disc_loss = 0.01793959635930757
Trained batch 12 in epoch 5, gen_loss = 0.43941890276395357, disc_loss = 0.01696015751132598
Trained batch 13 in epoch 5, gen_loss = 0.4331483989953995, disc_loss = 0.016864362571920668
Trained batch 14 in epoch 5, gen_loss = 0.43185757994651797, disc_loss = 0.016107956723620493
Trained batch 15 in epoch 5, gen_loss = 0.43484789319336414, disc_loss = 0.015485191863263026
Trained batch 16 in epoch 5, gen_loss = 0.4337746080230264, disc_loss = 0.01481575976290247
Trained batch 17 in epoch 5, gen_loss = 0.43830684158537125, disc_loss = 0.01426867284398112
Trained batch 18 in epoch 5, gen_loss = 0.43231651343797384, disc_loss = 0.015148651369504239
Trained batch 19 in epoch 5, gen_loss = 0.43065045177936556, disc_loss = 0.018994682584889233
Trained batch 20 in epoch 5, gen_loss = 0.4301778361910865, disc_loss = 0.019443296184319826
Trained batch 21 in epoch 5, gen_loss = 0.4287029965357347, disc_loss = 0.019647572041404517
Trained batch 22 in epoch 5, gen_loss = 0.42735801961110986, disc_loss = 0.01976939924466221
Trained batch 23 in epoch 5, gen_loss = 0.42718998591105145, disc_loss = 0.020344659239829827
Trained batch 24 in epoch 5, gen_loss = 0.4247518754005432, disc_loss = 0.019880400877445935
Trained batch 25 in epoch 5, gen_loss = 0.4239372576658542, disc_loss = 0.019541457062587142
Trained batch 26 in epoch 5, gen_loss = 0.4210422226676234, disc_loss = 0.020630264223587734
Trained batch 27 in epoch 5, gen_loss = 0.4230704467211451, disc_loss = 0.020169531144866987
Trained batch 28 in epoch 5, gen_loss = 0.42394632409358846, disc_loss = 0.02067002257460664
Trained batch 29 in epoch 5, gen_loss = 0.42315004070599876, disc_loss = 0.020156962253774207
Trained batch 30 in epoch 5, gen_loss = 0.4211561054952683, disc_loss = 0.019936064874092416
Trained batch 31 in epoch 5, gen_loss = 0.41933586448431015, disc_loss = 0.019505279502482153
Trained batch 32 in epoch 5, gen_loss = 0.4200317525502407, disc_loss = 0.019074551888148893
Trained batch 33 in epoch 5, gen_loss = 0.4187636664685081, disc_loss = 0.018701316980535492
Trained batch 34 in epoch 5, gen_loss = 0.4197957949978965, disc_loss = 0.01851434853992292
Trained batch 35 in epoch 5, gen_loss = 0.4200432441300816, disc_loss = 0.018149173663308222
Trained batch 36 in epoch 5, gen_loss = 0.41956883588352717, disc_loss = 0.018072680041596696
Trained batch 37 in epoch 5, gen_loss = 0.42180509237866654, disc_loss = 0.01787760113611033
Trained batch 38 in epoch 5, gen_loss = 0.42037228513986635, disc_loss = 0.01766958087682724
Trained batch 39 in epoch 5, gen_loss = 0.4183810673654079, disc_loss = 0.017366061103530228
Trained batch 40 in epoch 5, gen_loss = 0.4193976296157372, disc_loss = 0.01703864681284602
Trained batch 41 in epoch 5, gen_loss = 0.42061218264557065, disc_loss = 0.016777924916130445
Trained batch 42 in epoch 5, gen_loss = 0.421210928018703, disc_loss = 0.01654610879242767
Trained batch 43 in epoch 5, gen_loss = 0.42293954166499054, disc_loss = 0.016494521458463914
Trained batch 44 in epoch 5, gen_loss = 0.42211963136990865, disc_loss = 0.016401123721152544
Trained batch 45 in epoch 5, gen_loss = 0.4233801040960395, disc_loss = 0.016444743418580165
Trained batch 46 in epoch 5, gen_loss = 0.4225685786693654, disc_loss = 0.01638260449064856
Trained batch 47 in epoch 5, gen_loss = 0.422656840334336, disc_loss = 0.01637127363937907
Trained batch 48 in epoch 5, gen_loss = 0.4222573844753966, disc_loss = 0.016232354918076675
Trained batch 49 in epoch 5, gen_loss = 0.4220585948228836, disc_loss = 0.016162021150812507
Trained batch 50 in epoch 5, gen_loss = 0.42320804794629413, disc_loss = 0.016975925093991498
Trained batch 51 in epoch 5, gen_loss = 0.42232033667656094, disc_loss = 0.016751318301360767
Trained batch 52 in epoch 5, gen_loss = 0.4239286774734281, disc_loss = 0.016967595247376076
Trained batch 53 in epoch 5, gen_loss = 0.42463145929354207, disc_loss = 0.016795901055620226
Trained batch 54 in epoch 5, gen_loss = 0.42478444359519263, disc_loss = 0.016601140500808305
Trained batch 55 in epoch 5, gen_loss = 0.4234686642885208, disc_loss = 0.016746428104982312
Trained batch 56 in epoch 5, gen_loss = 0.42261972291427746, disc_loss = 0.016694479662794293
Trained batch 57 in epoch 5, gen_loss = 0.4233784742396453, disc_loss = 0.016521086073319972
Trained batch 58 in epoch 5, gen_loss = 0.4236832922798092, disc_loss = 0.016380756106859042
Trained batch 59 in epoch 5, gen_loss = 0.42355002065499625, disc_loss = 0.016225645993836225
Trained batch 60 in epoch 5, gen_loss = 0.4233265802508495, disc_loss = 0.016152769747022233
Trained batch 61 in epoch 5, gen_loss = 0.42417204476171927, disc_loss = 0.01596725094432552
Trained batch 62 in epoch 5, gen_loss = 0.4237218229543595, disc_loss = 0.01580894584693606
Trained batch 63 in epoch 5, gen_loss = 0.424161029048264, disc_loss = 0.01568686027894728
Trained batch 64 in epoch 5, gen_loss = 0.424905329484206, disc_loss = 0.01564939685452443
Trained batch 65 in epoch 5, gen_loss = 0.423879218823982, disc_loss = 0.015895236495204947
Trained batch 66 in epoch 5, gen_loss = 0.4235490182442452, disc_loss = 0.015788923017680645
Trained batch 67 in epoch 5, gen_loss = 0.4236195731688948, disc_loss = 0.015618795364656868
Trained batch 68 in epoch 5, gen_loss = 0.42321134995723114, disc_loss = 0.0157244059972573
Trained batch 69 in epoch 5, gen_loss = 0.42235353887081145, disc_loss = 0.015729640450860772
Trained batch 70 in epoch 5, gen_loss = 0.4226184919686385, disc_loss = 0.015676543942954337
Trained batch 71 in epoch 5, gen_loss = 0.4222520767814583, disc_loss = 0.015779503349525232
Trained batch 72 in epoch 5, gen_loss = 0.423546653496076, disc_loss = 0.01563921551641128
Trained batch 73 in epoch 5, gen_loss = 0.42331251622857274, disc_loss = 0.016382924822234624
Trained batch 74 in epoch 5, gen_loss = 0.42259198387463887, disc_loss = 0.0179504756256938
Trained batch 75 in epoch 5, gen_loss = 0.4226096554806358, disc_loss = 0.017837369091514694
Trained batch 76 in epoch 5, gen_loss = 0.4228870535825754, disc_loss = 0.017929618053331778
Trained batch 77 in epoch 5, gen_loss = 0.4226525532893645, disc_loss = 0.017822763369156
Trained batch 78 in epoch 5, gen_loss = 0.42338160925273655, disc_loss = 0.017887280581966987
Trained batch 79 in epoch 5, gen_loss = 0.42316382229328153, disc_loss = 0.01785753577714786
Trained batch 80 in epoch 5, gen_loss = 0.42317483896090663, disc_loss = 0.017732685104150464
Trained batch 81 in epoch 5, gen_loss = 0.4225802974003117, disc_loss = 0.017604107792466517
Trained batch 82 in epoch 5, gen_loss = 0.4223161702414593, disc_loss = 0.01763273084940142
Trained batch 83 in epoch 5, gen_loss = 0.4214684626176244, disc_loss = 0.018142768675239666
Trained batch 84 in epoch 5, gen_loss = 0.42241515727604134, disc_loss = 0.01923197648652336
Trained batch 85 in epoch 5, gen_loss = 0.42229121819485066, disc_loss = 0.019255609733464067
Trained batch 86 in epoch 5, gen_loss = 0.42118266361883316, disc_loss = 0.019888907697736876
Trained batch 87 in epoch 5, gen_loss = 0.42161900854923506, disc_loss = 0.020366799282121727
Trained batch 88 in epoch 5, gen_loss = 0.4219255644953653, disc_loss = 0.020214452219896772
Trained batch 89 in epoch 5, gen_loss = 0.42129026783837215, disc_loss = 0.02070953867708643
Trained batch 90 in epoch 5, gen_loss = 0.42106523192845857, disc_loss = 0.020872381986579397
Trained batch 91 in epoch 5, gen_loss = 0.42099422507959866, disc_loss = 0.02084066325029277
Trained batch 92 in epoch 5, gen_loss = 0.42139622440902136, disc_loss = 0.021035620752441628
Trained batch 93 in epoch 5, gen_loss = 0.4196951925120455, disc_loss = 0.021711454974447795
Trained batch 94 in epoch 5, gen_loss = 0.41955199963168094, disc_loss = 0.022965800360237296
Trained batch 95 in epoch 5, gen_loss = 0.4188566030934453, disc_loss = 0.022945801601357136
Trained batch 96 in epoch 5, gen_loss = 0.418349032549514, disc_loss = 0.02301341317325216
Trained batch 97 in epoch 5, gen_loss = 0.4180546643174424, disc_loss = 0.022948929840432748
Trained batch 98 in epoch 5, gen_loss = 0.41786369621151626, disc_loss = 0.023343234304150546
Trained batch 99 in epoch 5, gen_loss = 0.4182229098677635, disc_loss = 0.02776170219294727
Trained batch 100 in epoch 5, gen_loss = 0.417549462011545, disc_loss = 0.02800294730148398
Trained batch 101 in epoch 5, gen_loss = 0.4176360932635326, disc_loss = 0.028740632429938105
Trained batch 102 in epoch 5, gen_loss = 0.4178419356207246, disc_loss = 0.02875313512727763
Trained batch 103 in epoch 5, gen_loss = 0.41709760347237956, disc_loss = 0.029195441031613603
Trained batch 104 in epoch 5, gen_loss = 0.4165166684559413, disc_loss = 0.029243809330676284
Trained batch 105 in epoch 5, gen_loss = 0.41608521707777707, disc_loss = 0.029115275479853153
Trained batch 106 in epoch 5, gen_loss = 0.4158693457318244, disc_loss = 0.029047300046849474
Trained batch 107 in epoch 5, gen_loss = 0.4163064010165356, disc_loss = 0.029031230481686415
Trained batch 108 in epoch 5, gen_loss = 0.4157330855863904, disc_loss = 0.029416131453776577
Trained batch 109 in epoch 5, gen_loss = 0.4158098686825145, disc_loss = 0.03080607232722369
Trained batch 110 in epoch 5, gen_loss = 0.41529699703594586, disc_loss = 0.031216408084104728
Trained batch 111 in epoch 5, gen_loss = 0.41535371941115173, disc_loss = 0.03133350427794669
Trained batch 112 in epoch 5, gen_loss = 0.4158846654195701, disc_loss = 0.031210360504620897
Trained batch 113 in epoch 5, gen_loss = 0.4157239852244394, disc_loss = 0.031087787772871946
Trained batch 114 in epoch 5, gen_loss = 0.41560794762943104, disc_loss = 0.030957347624327825
Trained batch 115 in epoch 5, gen_loss = 0.415285246125583, disc_loss = 0.030809116437388904
Trained batch 116 in epoch 5, gen_loss = 0.41514736566788113, disc_loss = 0.03058021726946418
Trained batch 117 in epoch 5, gen_loss = 0.4151890325849339, disc_loss = 0.030358196780780108
Trained batch 118 in epoch 5, gen_loss = 0.41549263331068664, disc_loss = 0.030156839095024753
Trained batch 119 in epoch 5, gen_loss = 0.4154530790944894, disc_loss = 0.02995865682993705
Trained batch 120 in epoch 5, gen_loss = 0.4159832577074855, disc_loss = 0.02984125571602509
Trained batch 121 in epoch 5, gen_loss = 0.4162055933084644, disc_loss = 0.029639692232776127
Trained batch 122 in epoch 5, gen_loss = 0.416226437421349, disc_loss = 0.02944936336404303
Trained batch 123 in epoch 5, gen_loss = 0.4165566868839725, disc_loss = 0.029405415174551308
Trained batch 124 in epoch 5, gen_loss = 0.4167021958827972, disc_loss = 0.02923777473345399
Trained batch 125 in epoch 5, gen_loss = 0.41714395700939116, disc_loss = 0.029131449363563978
Trained batch 126 in epoch 5, gen_loss = 0.41692147808750785, disc_loss = 0.0293140450573167
Trained batch 127 in epoch 5, gen_loss = 0.4176542838104069, disc_loss = 0.029698501679376932
Trained batch 128 in epoch 5, gen_loss = 0.4167367109032564, disc_loss = 0.030921491992825918
Trained batch 129 in epoch 5, gen_loss = 0.41732814610004426, disc_loss = 0.03320843438761165
Trained batch 130 in epoch 5, gen_loss = 0.4169954509680508, disc_loss = 0.03328635491331229
Trained batch 131 in epoch 5, gen_loss = 0.4164111564556758, disc_loss = 0.03394105154527069
Trained batch 132 in epoch 5, gen_loss = 0.4160052616345255, disc_loss = 0.03436840016436868
Trained batch 133 in epoch 5, gen_loss = 0.4153836293896632, disc_loss = 0.03420747531258237
Trained batch 134 in epoch 5, gen_loss = 0.41529975511409617, disc_loss = 0.03410203931163307
Trained batch 135 in epoch 5, gen_loss = 0.41585419962511344, disc_loss = 0.033924909311976725
Trained batch 136 in epoch 5, gen_loss = 0.41620055928717564, disc_loss = 0.03376539772457994
Trained batch 137 in epoch 5, gen_loss = 0.416614107247712, disc_loss = 0.03357479831986669
Trained batch 138 in epoch 5, gen_loss = 0.41636045094874263, disc_loss = 0.03339948060942425
Trained batch 139 in epoch 5, gen_loss = 0.41611543468066625, disc_loss = 0.03330227368777352
Trained batch 140 in epoch 5, gen_loss = 0.41660517665511326, disc_loss = 0.03322745968607512
Trained batch 141 in epoch 5, gen_loss = 0.41659352750005857, disc_loss = 0.033045669919220914
Trained batch 142 in epoch 5, gen_loss = 0.41618548740040173, disc_loss = 0.032889448666385004
Trained batch 143 in epoch 5, gen_loss = 0.41615773199333084, disc_loss = 0.03272189687575317
Trained batch 144 in epoch 5, gen_loss = 0.4164135725333773, disc_loss = 0.03273882705332904
Trained batch 145 in epoch 5, gen_loss = 0.41611079463403516, disc_loss = 0.033369440164366
Trained batch 146 in epoch 5, gen_loss = 0.4153932144447249, disc_loss = 0.03476073206434039
Trained batch 147 in epoch 5, gen_loss = 0.4158527593354921, disc_loss = 0.03519183531957301
Trained batch 148 in epoch 5, gen_loss = 0.4160421964706191, disc_loss = 0.035011369659996676
Trained batch 149 in epoch 5, gen_loss = 0.41589780946572624, disc_loss = 0.03486976420506835
Trained batch 150 in epoch 5, gen_loss = 0.41619320144716476, disc_loss = 0.034761623578109094
Trained batch 151 in epoch 5, gen_loss = 0.4161903440560165, disc_loss = 0.03457714118810959
Trained batch 152 in epoch 5, gen_loss = 0.4161289270017661, disc_loss = 0.03438851750741889
Trained batch 153 in epoch 5, gen_loss = 0.4161273217820502, disc_loss = 0.034247181568802756
Trained batch 154 in epoch 5, gen_loss = 0.4155535190336166, disc_loss = 0.03440272131213738
Trained batch 155 in epoch 5, gen_loss = 0.41602469216554594, disc_loss = 0.03510835906192183
Trained batch 156 in epoch 5, gen_loss = 0.41607420896268954, disc_loss = 0.03524103287049824
Trained batch 157 in epoch 5, gen_loss = 0.4158589532480964, disc_loss = 0.03526285562746793
Trained batch 158 in epoch 5, gen_loss = 0.4157993441107888, disc_loss = 0.03547300401571318
Trained batch 159 in epoch 5, gen_loss = 0.4161025196313858, disc_loss = 0.03573713273217436
Trained batch 160 in epoch 5, gen_loss = 0.41602610190462624, disc_loss = 0.03572695765655881
Trained batch 161 in epoch 5, gen_loss = 0.41613876948386064, disc_loss = 0.03558009426270462
Trained batch 162 in epoch 5, gen_loss = 0.41624586914945966, disc_loss = 0.03552001989246603
Trained batch 163 in epoch 5, gen_loss = 0.41650545597076416, disc_loss = 0.0354822674317558
Trained batch 164 in epoch 5, gen_loss = 0.416556715965271, disc_loss = 0.03533394745635715
Trained batch 165 in epoch 5, gen_loss = 0.4166134100362479, disc_loss = 0.03518482957158731
Trained batch 166 in epoch 5, gen_loss = 0.4166555101286151, disc_loss = 0.03502479051434976
Trained batch 167 in epoch 5, gen_loss = 0.4165673702955246, disc_loss = 0.0350102440625917
Trained batch 168 in epoch 5, gen_loss = 0.41624055529487203, disc_loss = 0.034882345691477586
Trained batch 169 in epoch 5, gen_loss = 0.4163846790790558, disc_loss = 0.035009643871008474
Trained batch 170 in epoch 5, gen_loss = 0.4168258682329055, disc_loss = 0.03506460524169586
Trained batch 171 in epoch 5, gen_loss = 0.41706848421762155, disc_loss = 0.034933510883494695
Trained batch 172 in epoch 5, gen_loss = 0.417240923884287, disc_loss = 0.03481434595453515
Trained batch 173 in epoch 5, gen_loss = 0.41705984767826126, disc_loss = 0.03465030045548304
Trained batch 174 in epoch 5, gen_loss = 0.4167421507835388, disc_loss = 0.03450093372325812
Trained batch 175 in epoch 5, gen_loss = 0.41686145825819537, disc_loss = 0.034345061430940405
Trained batch 176 in epoch 5, gen_loss = 0.4168661634127299, disc_loss = 0.03417529828983259
Trained batch 177 in epoch 5, gen_loss = 0.41700411696782275, disc_loss = 0.03400864878805417
Trained batch 178 in epoch 5, gen_loss = 0.4171379023757061, disc_loss = 0.03392707862157645
Trained batch 179 in epoch 5, gen_loss = 0.4175050988793373, disc_loss = 0.03379746318225645
Trained batch 180 in epoch 5, gen_loss = 0.41756680920637773, disc_loss = 0.033657902386039495
Trained batch 181 in epoch 5, gen_loss = 0.4179133129316372, disc_loss = 0.03349860597166468
Trained batch 182 in epoch 5, gen_loss = 0.4178096181382247, disc_loss = 0.03334688601883057
Trained batch 183 in epoch 5, gen_loss = 0.41774498817065486, disc_loss = 0.03320525524348183
Trained batch 184 in epoch 5, gen_loss = 0.41744836923238393, disc_loss = 0.03305577647847098
Trained batch 185 in epoch 5, gen_loss = 0.4175292247085161, disc_loss = 0.03296588065843749
Trained batch 186 in epoch 5, gen_loss = 0.4170504021134606, disc_loss = 0.032844013106177516
Trained batch 187 in epoch 5, gen_loss = 0.41702154183641393, disc_loss = 0.033015368342835534
Trained batch 188 in epoch 5, gen_loss = 0.41726306948081526, disc_loss = 0.033589842886954706
Trained batch 189 in epoch 5, gen_loss = 0.4167550289317181, disc_loss = 0.033556572176319986
Trained batch 190 in epoch 5, gen_loss = 0.41677285270541126, disc_loss = 0.03344172064253953
Trained batch 191 in epoch 5, gen_loss = 0.41681139667828876, disc_loss = 0.03342293971703233
Trained batch 192 in epoch 5, gen_loss = 0.41702993268176064, disc_loss = 0.03344263436050767
Trained batch 193 in epoch 5, gen_loss = 0.4167545835689171, disc_loss = 0.033415915660521725
Trained batch 194 in epoch 5, gen_loss = 0.41702626729622866, disc_loss = 0.03347889326799374
Trained batch 195 in epoch 5, gen_loss = 0.416911424726856, disc_loss = 0.03367469874590787
Trained batch 196 in epoch 5, gen_loss = 0.41739578234967845, disc_loss = 0.03354580610574502
Trained batch 197 in epoch 5, gen_loss = 0.4174870758345633, disc_loss = 0.034362727879650064
Trained batch 198 in epoch 5, gen_loss = 0.417368847071825, disc_loss = 0.0349944603896171
Trained batch 199 in epoch 5, gen_loss = 0.4173214758932591, disc_loss = 0.03520262707956135
Trained batch 200 in epoch 5, gen_loss = 0.4172113763159187, disc_loss = 0.03511952967452469
Trained batch 201 in epoch 5, gen_loss = 0.4171828006458755, disc_loss = 0.03500259922134994
Trained batch 202 in epoch 5, gen_loss = 0.4165837701611918, disc_loss = 0.035107099308902996
Trained batch 203 in epoch 5, gen_loss = 0.416798996136469, disc_loss = 0.03507909956662094
Trained batch 204 in epoch 5, gen_loss = 0.416489503151033, disc_loss = 0.03496008902879023
Trained batch 205 in epoch 5, gen_loss = 0.41618030236184017, disc_loss = 0.03505499516749411
Trained batch 206 in epoch 5, gen_loss = 0.41646280740770164, disc_loss = 0.03515754359805785
Trained batch 207 in epoch 5, gen_loss = 0.4158830131189181, disc_loss = 0.03551665500540716
Trained batch 208 in epoch 5, gen_loss = 0.41597460930427294, disc_loss = 0.03687223100936726
Trained batch 209 in epoch 5, gen_loss = 0.41566384576615834, disc_loss = 0.03836457098257683
Trained batch 210 in epoch 5, gen_loss = 0.41529352094324845, disc_loss = 0.039548046291051034
Trained batch 211 in epoch 5, gen_loss = 0.41501771897639866, disc_loss = 0.03995057817917528
Trained batch 212 in epoch 5, gen_loss = 0.4145803693594507, disc_loss = 0.04023699686718239
Trained batch 213 in epoch 5, gen_loss = 0.4144728268696883, disc_loss = 0.04014994371595366
Trained batch 214 in epoch 5, gen_loss = 0.4144833902980006, disc_loss = 0.040081871712450375
Trained batch 215 in epoch 5, gen_loss = 0.41425228946738774, disc_loss = 0.04000217744787396
Trained batch 216 in epoch 5, gen_loss = 0.41429360286431377, disc_loss = 0.03989292209547374
Trained batch 217 in epoch 5, gen_loss = 0.41440825095964134, disc_loss = 0.03983777339800919
Trained batch 218 in epoch 5, gen_loss = 0.41427526789713126, disc_loss = 0.03972876819964821
Trained batch 219 in epoch 5, gen_loss = 0.41423542689193377, disc_loss = 0.03960247914391485
Trained batch 220 in epoch 5, gen_loss = 0.4141535102242258, disc_loss = 0.03985833293206282
Trained batch 221 in epoch 5, gen_loss = 0.4144934461460457, disc_loss = 0.041645399697527695
Trained batch 222 in epoch 5, gen_loss = 0.41399659049350584, disc_loss = 0.04214453437436589
Trained batch 223 in epoch 5, gen_loss = 0.4137143564543554, disc_loss = 0.042244151509034315
Trained batch 224 in epoch 5, gen_loss = 0.41370343738132054, disc_loss = 0.042451175062192814
Trained batch 225 in epoch 5, gen_loss = 0.4134230808874147, disc_loss = 0.04252947139166362
Trained batch 226 in epoch 5, gen_loss = 0.4132139930903649, disc_loss = 0.0425079965529069
Trained batch 227 in epoch 5, gen_loss = 0.4133465265234311, disc_loss = 0.04246548961096427
Trained batch 228 in epoch 5, gen_loss = 0.41348103053184576, disc_loss = 0.042325636868133294
Trained batch 229 in epoch 5, gen_loss = 0.41343540484490604, disc_loss = 0.042198594781043736
Trained batch 230 in epoch 5, gen_loss = 0.4132492028789603, disc_loss = 0.04213006071165785
Trained batch 231 in epoch 5, gen_loss = 0.4133775172562435, disc_loss = 0.04209178010933101
Trained batch 232 in epoch 5, gen_loss = 0.4134649153431086, disc_loss = 0.04207321497024129
Trained batch 233 in epoch 5, gen_loss = 0.4132674978329585, disc_loss = 0.04255132059542797
Trained batch 234 in epoch 5, gen_loss = 0.4137153465697106, disc_loss = 0.043544017008327426
Trained batch 235 in epoch 5, gen_loss = 0.41378934264688166, disc_loss = 0.043556949652542
Trained batch 236 in epoch 5, gen_loss = 0.4137498017101851, disc_loss = 0.04353587969917537
Trained batch 237 in epoch 5, gen_loss = 0.41374331374629203, disc_loss = 0.04343801671873872
Trained batch 238 in epoch 5, gen_loss = 0.41404753287467, disc_loss = 0.04350837553114821
Trained batch 239 in epoch 5, gen_loss = 0.4135387673974037, disc_loss = 0.04457476088621964
Trained batch 240 in epoch 5, gen_loss = 0.4140088701643884, disc_loss = 0.04473991307943936
Trained batch 241 in epoch 5, gen_loss = 0.41404210314277773, disc_loss = 0.044759839226699565
Trained batch 242 in epoch 5, gen_loss = 0.4136244334556438, disc_loss = 0.04481139543769046
Trained batch 243 in epoch 5, gen_loss = 0.41342569484573893, disc_loss = 0.0446704926740256
Trained batch 244 in epoch 5, gen_loss = 0.4134918188562199, disc_loss = 0.04452755667497309
Trained batch 245 in epoch 5, gen_loss = 0.41363048686729215, disc_loss = 0.04437829684693276
Trained batch 246 in epoch 5, gen_loss = 0.4137850110588769, disc_loss = 0.044225600103165216
Trained batch 247 in epoch 5, gen_loss = 0.41401699593951624, disc_loss = 0.044152521164036326
Trained batch 248 in epoch 5, gen_loss = 0.4141466891669844, disc_loss = 0.04402317644197898
Trained batch 249 in epoch 5, gen_loss = 0.414084602355957, disc_loss = 0.04402533457055688
Trained batch 250 in epoch 5, gen_loss = 0.41394332704316095, disc_loss = 0.044006172037011834
Trained batch 251 in epoch 5, gen_loss = 0.41374638783080236, disc_loss = 0.04388746934839421
Trained batch 252 in epoch 5, gen_loss = 0.41367761301900086, disc_loss = 0.04380669834997814
Trained batch 253 in epoch 5, gen_loss = 0.41383850081699103, disc_loss = 0.04366509169046804
Trained batch 254 in epoch 5, gen_loss = 0.41377892260457955, disc_loss = 0.04352128633170151
Trained batch 255 in epoch 5, gen_loss = 0.41350153577513993, disc_loss = 0.04339250434350106
Trained batch 256 in epoch 5, gen_loss = 0.4136457240303203, disc_loss = 0.04324521185967941
Trained batch 257 in epoch 5, gen_loss = 0.4136006574529086, disc_loss = 0.04313540439908357
Trained batch 258 in epoch 5, gen_loss = 0.41363444026832874, disc_loss = 0.0435709411774593
Trained batch 259 in epoch 5, gen_loss = 0.41329945486325487, disc_loss = 0.044138813520280214
Trained batch 260 in epoch 5, gen_loss = 0.41307099523215457, disc_loss = 0.04414595236780543
Trained batch 261 in epoch 5, gen_loss = 0.4130740403446532, disc_loss = 0.044022542449382654
Trained batch 262 in epoch 5, gen_loss = 0.4132613654145723, disc_loss = 0.043877498607926724
Trained batch 263 in epoch 5, gen_loss = 0.41338528433080873, disc_loss = 0.04376104080019462
Trained batch 264 in epoch 5, gen_loss = 0.41344911264923384, disc_loss = 0.04362023731447616
Trained batch 265 in epoch 5, gen_loss = 0.4132727204184783, disc_loss = 0.043489262790776285
Trained batch 266 in epoch 5, gen_loss = 0.41322010922967717, disc_loss = 0.043391791161861315
Trained batch 267 in epoch 5, gen_loss = 0.41306007052980254, disc_loss = 0.04376078078717883
Trained batch 268 in epoch 5, gen_loss = 0.41316123112869974, disc_loss = 0.04460085650081971
Trained batch 269 in epoch 5, gen_loss = 0.4133120749835615, disc_loss = 0.04446373615862319
Trained batch 270 in epoch 5, gen_loss = 0.4131854904533752, disc_loss = 0.04437683258253765
Trained batch 271 in epoch 5, gen_loss = 0.41335191731067267, disc_loss = 0.04423394513843745
Trained batch 272 in epoch 5, gen_loss = 0.41310506196685765, disc_loss = 0.04409352543119054
Trained batch 273 in epoch 5, gen_loss = 0.41297564541336396, disc_loss = 0.04395385702432942
Trained batch 274 in epoch 5, gen_loss = 0.41312216476960617, disc_loss = 0.04382265234874053
Trained batch 275 in epoch 5, gen_loss = 0.41327826451996097, disc_loss = 0.0437267088311036
Trained batch 276 in epoch 5, gen_loss = 0.4132077004289799, disc_loss = 0.04359675606793391
Trained batch 277 in epoch 5, gen_loss = 0.41288002382079475, disc_loss = 0.043478162297576985
Trained batch 278 in epoch 5, gen_loss = 0.4127873084023862, disc_loss = 0.04339208763166194
Trained batch 279 in epoch 5, gen_loss = 0.4127796496663775, disc_loss = 0.04327334566873365
Trained batch 280 in epoch 5, gen_loss = 0.41284398623208557, disc_loss = 0.04332859789806806
Trained batch 281 in epoch 5, gen_loss = 0.4127974507022411, disc_loss = 0.04358837258975609
Trained batch 282 in epoch 5, gen_loss = 0.4132188037301121, disc_loss = 0.04381640178608863
Trained batch 283 in epoch 5, gen_loss = 0.41303871907818485, disc_loss = 0.04371354347390031
Trained batch 284 in epoch 5, gen_loss = 0.412953953261961, disc_loss = 0.04368288216524218
Trained batch 285 in epoch 5, gen_loss = 0.41289084868414416, disc_loss = 0.04361568811557979
Trained batch 286 in epoch 5, gen_loss = 0.4130243715093526, disc_loss = 0.0434893472136391
Trained batch 287 in epoch 5, gen_loss = 0.4131527494432198, disc_loss = 0.04336455524996078
Trained batch 288 in epoch 5, gen_loss = 0.41286446097400364, disc_loss = 0.04328170285808328
Trained batch 289 in epoch 5, gen_loss = 0.4128280147396285, disc_loss = 0.043162935183801016
Trained batch 290 in epoch 5, gen_loss = 0.41277568334156706, disc_loss = 0.043043922359296646
Trained batch 291 in epoch 5, gen_loss = 0.41267529915865153, disc_loss = 0.042969776089430776
Trained batch 292 in epoch 5, gen_loss = 0.4126607772636739, disc_loss = 0.042854235165851004
Trained batch 293 in epoch 5, gen_loss = 0.4126051978594592, disc_loss = 0.04275235182884447
Trained batch 294 in epoch 5, gen_loss = 0.4125656984620175, disc_loss = 0.042663717568236385
Trained batch 295 in epoch 5, gen_loss = 0.41251400213789297, disc_loss = 0.042584538775987016
Trained batch 296 in epoch 5, gen_loss = 0.4125597892385541, disc_loss = 0.04246015041934872
Trained batch 297 in epoch 5, gen_loss = 0.4127696215506368, disc_loss = 0.04234395053506448
Trained batch 298 in epoch 5, gen_loss = 0.41275551356998175, disc_loss = 0.04242327378090957
Trained batch 299 in epoch 5, gen_loss = 0.41235378781954446, disc_loss = 0.04293987857643515
Trained batch 300 in epoch 5, gen_loss = 0.4122839637372977, disc_loss = 0.04315873774919547
Trained batch 301 in epoch 5, gen_loss = 0.4123303373128373, disc_loss = 0.043052993756441386
Trained batch 302 in epoch 5, gen_loss = 0.41216055473478713, disc_loss = 0.04295149671909685
Trained batch 303 in epoch 5, gen_loss = 0.412120192654823, disc_loss = 0.04287653339959338
Trained batch 304 in epoch 5, gen_loss = 0.4121609919383878, disc_loss = 0.04278120228593223
Trained batch 305 in epoch 5, gen_loss = 0.4124617119824964, disc_loss = 0.042678687178219356
Trained batch 306 in epoch 5, gen_loss = 0.4124953258503532, disc_loss = 0.04255899214200942
Trained batch 307 in epoch 5, gen_loss = 0.41243323538597526, disc_loss = 0.04245548886730783
Trained batch 308 in epoch 5, gen_loss = 0.4122947874964248, disc_loss = 0.042386951084733976
Trained batch 309 in epoch 5, gen_loss = 0.4122481813353877, disc_loss = 0.04229476292647662
Trained batch 310 in epoch 5, gen_loss = 0.4118289773103892, disc_loss = 0.04219741943528894
Trained batch 311 in epoch 5, gen_loss = 0.411814499550905, disc_loss = 0.042082209031109534
Trained batch 312 in epoch 5, gen_loss = 0.4117533312247584, disc_loss = 0.04196410157685034
Trained batch 313 in epoch 5, gen_loss = 0.411702374648896, disc_loss = 0.04184337061604449
Trained batch 314 in epoch 5, gen_loss = 0.4114266307581039, disc_loss = 0.04182525009123816
Trained batch 315 in epoch 5, gen_loss = 0.41142314823367926, disc_loss = 0.041887593530766855
Trained batch 316 in epoch 5, gen_loss = 0.41133133056411986, disc_loss = 0.04182497539325421
Trained batch 317 in epoch 5, gen_loss = 0.41118067099988087, disc_loss = 0.04191257345853315
Trained batch 318 in epoch 5, gen_loss = 0.4114221935175056, disc_loss = 0.041856981964262206
Trained batch 319 in epoch 5, gen_loss = 0.41158912014216187, disc_loss = 0.04204422874463489
Trained batch 320 in epoch 5, gen_loss = 0.41153678056606996, disc_loss = 0.04201705343992307
Trained batch 321 in epoch 5, gen_loss = 0.4114934746523081, disc_loss = 0.04193513452144837
Trained batch 322 in epoch 5, gen_loss = 0.4115942360446918, disc_loss = 0.041823117084074594
Trained batch 323 in epoch 5, gen_loss = 0.4115029708654792, disc_loss = 0.041708882971390804
Trained batch 324 in epoch 5, gen_loss = 0.41131504563184884, disc_loss = 0.04169911703667962
Trained batch 325 in epoch 5, gen_loss = 0.41154278092589114, disc_loss = 0.04164596842859009
Trained batch 326 in epoch 5, gen_loss = 0.4117654051620297, disc_loss = 0.041774990217936785
Trained batch 327 in epoch 5, gen_loss = 0.41161490831433273, disc_loss = 0.041701185061289676
Trained batch 328 in epoch 5, gen_loss = 0.4114470567022051, disc_loss = 0.041727868866990675
Trained batch 329 in epoch 5, gen_loss = 0.41159889517408427, disc_loss = 0.041672384777021676
Trained batch 330 in epoch 5, gen_loss = 0.41177211211167075, disc_loss = 0.04160195623251561
Trained batch 331 in epoch 5, gen_loss = 0.4119241987186742, disc_loss = 0.04150655504220715
Trained batch 332 in epoch 5, gen_loss = 0.4120293663249717, disc_loss = 0.04144749639264948
Trained batch 333 in epoch 5, gen_loss = 0.41221373630854896, disc_loss = 0.04133452472561402
Trained batch 334 in epoch 5, gen_loss = 0.4123902690944387, disc_loss = 0.04124710180921786
Trained batch 335 in epoch 5, gen_loss = 0.4125365720440944, disc_loss = 0.04114301807047533
Trained batch 336 in epoch 5, gen_loss = 0.41247439234122324, disc_loss = 0.041032477436747504
Trained batch 337 in epoch 5, gen_loss = 0.41250877937621616, disc_loss = 0.04093576036118103
Trained batch 338 in epoch 5, gen_loss = 0.4124238947323993, disc_loss = 0.04083741865612588
Trained batch 339 in epoch 5, gen_loss = 0.41238016345921685, disc_loss = 0.04072802570675883
Trained batch 340 in epoch 5, gen_loss = 0.4123816726144807, disc_loss = 0.04064062235964315
Trained batch 341 in epoch 5, gen_loss = 0.4122915498868764, disc_loss = 0.04053787026848448
Trained batch 342 in epoch 5, gen_loss = 0.41220755453707525, disc_loss = 0.04044590772566747
Trained batch 343 in epoch 5, gen_loss = 0.41207949531286264, disc_loss = 0.040342794817894004
Trained batch 344 in epoch 5, gen_loss = 0.41194380461305813, disc_loss = 0.040243363508657704
Trained batch 345 in epoch 5, gen_loss = 0.4120793202192108, disc_loss = 0.0401673853179343
Trained batch 346 in epoch 5, gen_loss = 0.41197983650034375, disc_loss = 0.04006609054931818
Trained batch 347 in epoch 5, gen_loss = 0.4121384103407805, disc_loss = 0.03996882557162437
Trained batch 348 in epoch 5, gen_loss = 0.41217861809156686, disc_loss = 0.03986735216590088
Trained batch 349 in epoch 5, gen_loss = 0.41233723214694434, disc_loss = 0.03976372908002564
Trained batch 350 in epoch 5, gen_loss = 0.412461464136754, disc_loss = 0.03966924297939084
Trained batch 351 in epoch 5, gen_loss = 0.4124473888765682, disc_loss = 0.039570601053789935
Trained batch 352 in epoch 5, gen_loss = 0.4125310639315219, disc_loss = 0.0395160402216165
Trained batch 353 in epoch 5, gen_loss = 0.4125536952146703, disc_loss = 0.03948307249400407
Trained batch 354 in epoch 5, gen_loss = 0.4125237452312255, disc_loss = 0.03938516186104274
Trained batch 355 in epoch 5, gen_loss = 0.41255650250764375, disc_loss = 0.03931886704083992
Trained batch 356 in epoch 5, gen_loss = 0.41242956505770106, disc_loss = 0.039244574682489666
Trained batch 357 in epoch 5, gen_loss = 0.4123990245205064, disc_loss = 0.039151002650341674
Trained batch 358 in epoch 5, gen_loss = 0.4123713219730303, disc_loss = 0.039055593121111974
Trained batch 359 in epoch 5, gen_loss = 0.4124990522861481, disc_loss = 0.03901501396386367
Trained batch 360 in epoch 5, gen_loss = 0.41257388192200595, disc_loss = 0.03894834062652121
Trained batch 361 in epoch 5, gen_loss = 0.4125162643786952, disc_loss = 0.03886918654248571
Trained batch 362 in epoch 5, gen_loss = 0.4126278000265442, disc_loss = 0.03878916596952754
Trained batch 363 in epoch 5, gen_loss = 0.41258979384060745, disc_loss = 0.038707671631997516
Trained batch 364 in epoch 5, gen_loss = 0.4123571805758019, disc_loss = 0.038628012438189904
Trained batch 365 in epoch 5, gen_loss = 0.41222560112593604, disc_loss = 0.03853657871708681
Trained batch 366 in epoch 5, gen_loss = 0.4121979845317248, disc_loss = 0.038443344491673505
Trained batch 367 in epoch 5, gen_loss = 0.4121644228048947, disc_loss = 0.03834955629755986
Trained batch 368 in epoch 5, gen_loss = 0.4121461046258932, disc_loss = 0.038253237362092914
Trained batch 369 in epoch 5, gen_loss = 0.4121316180841343, disc_loss = 0.03816841091658618
Trained batch 370 in epoch 5, gen_loss = 0.41223194841747335, disc_loss = 0.038076373322984844
Trained batch 371 in epoch 5, gen_loss = 0.41219089204265225, disc_loss = 0.03798371040067004
Trained batch 372 in epoch 5, gen_loss = 0.41231656849544107, disc_loss = 0.037891210391418385
Trained batch 373 in epoch 5, gen_loss = 0.41222127722227636, disc_loss = 0.037800158888231065
Trained batch 374 in epoch 5, gen_loss = 0.41227480896313984, disc_loss = 0.03773417245720823
Trained batch 375 in epoch 5, gen_loss = 0.41214458303565676, disc_loss = 0.03764924645409028
Trained batch 376 in epoch 5, gen_loss = 0.41230018456671536, disc_loss = 0.037558346328421914
Trained batch 377 in epoch 5, gen_loss = 0.4123075445966115, disc_loss = 0.03747485998264026
Trained batch 378 in epoch 5, gen_loss = 0.4121125558278177, disc_loss = 0.03739349759432013
Trained batch 379 in epoch 5, gen_loss = 0.41193985052798926, disc_loss = 0.03732167798658147
Trained batch 380 in epoch 5, gen_loss = 0.41193096695609605, disc_loss = 0.03726634696697977
Trained batch 381 in epoch 5, gen_loss = 0.4118292839583302, disc_loss = 0.03719450524978886
Trained batch 382 in epoch 5, gen_loss = 0.41177760029586113, disc_loss = 0.03710613322903842
Trained batch 383 in epoch 5, gen_loss = 0.41185130124601227, disc_loss = 0.03702745047970287
Trained batch 384 in epoch 5, gen_loss = 0.4117520148877974, disc_loss = 0.036945881830020386
Trained batch 385 in epoch 5, gen_loss = 0.41177974888388974, disc_loss = 0.03686473712595324
Trained batch 386 in epoch 5, gen_loss = 0.4117130432326048, disc_loss = 0.03678167625318356
Trained batch 387 in epoch 5, gen_loss = 0.4117278654858009, disc_loss = 0.03670948416657131
Trained batch 388 in epoch 5, gen_loss = 0.4117207198492359, disc_loss = 0.036676672330379946
Trained batch 389 in epoch 5, gen_loss = 0.4117204509484462, disc_loss = 0.036792583637035046
Trained batch 390 in epoch 5, gen_loss = 0.4117279181547482, disc_loss = 0.0367374316243755
Trained batch 391 in epoch 5, gen_loss = 0.411738035250075, disc_loss = 0.036763748650591135
Trained batch 392 in epoch 5, gen_loss = 0.4118015868518189, disc_loss = 0.036717394971153665
Trained batch 393 in epoch 5, gen_loss = 0.41180096286807566, disc_loss = 0.0366750416100063
Trained batch 394 in epoch 5, gen_loss = 0.41192227436017387, disc_loss = 0.036607653048785424
Trained batch 395 in epoch 5, gen_loss = 0.4119495940629882, disc_loss = 0.036539325382409976
Trained batch 396 in epoch 5, gen_loss = 0.411937098208843, disc_loss = 0.03645936268679704
Trained batch 397 in epoch 5, gen_loss = 0.411777045034883, disc_loss = 0.036379945311161815
Trained batch 398 in epoch 5, gen_loss = 0.4117811998179682, disc_loss = 0.03629636190677608
Trained batch 399 in epoch 5, gen_loss = 0.4118671350181103, disc_loss = 0.03621410552063026
Trained batch 400 in epoch 5, gen_loss = 0.41174225468290715, disc_loss = 0.036134794644751306
Trained batch 401 in epoch 5, gen_loss = 0.41174472001061513, disc_loss = 0.036055348567961165
Trained batch 402 in epoch 5, gen_loss = 0.41158555399987007, disc_loss = 0.03597222022635969
Trained batch 403 in epoch 5, gen_loss = 0.41155733050096155, disc_loss = 0.03589764725829539
Trained batch 404 in epoch 5, gen_loss = 0.4116442541281382, disc_loss = 0.03581873978672112
Trained batch 405 in epoch 5, gen_loss = 0.411752219784436, disc_loss = 0.035747925600087445
Trained batch 406 in epoch 5, gen_loss = 0.41142419771421745, disc_loss = 0.03584738344889985
Trained batch 407 in epoch 5, gen_loss = 0.41134702158617037, disc_loss = 0.03614365351534741
Trained batch 408 in epoch 5, gen_loss = 0.4112513345873443, disc_loss = 0.03650944195471449
Trained batch 409 in epoch 5, gen_loss = 0.41127630057858255, disc_loss = 0.03664684766369713
Trained batch 410 in epoch 5, gen_loss = 0.4113081356469732, disc_loss = 0.03661449562697026
Trained batch 411 in epoch 5, gen_loss = 0.4113327009440626, disc_loss = 0.03655278962162025
Trained batch 412 in epoch 5, gen_loss = 0.41117536307247154, disc_loss = 0.036501363024102035
Trained batch 413 in epoch 5, gen_loss = 0.41124865369520325, disc_loss = 0.03642757772636748
Trained batch 414 in epoch 5, gen_loss = 0.4113719518644264, disc_loss = 0.03635457875824208
Trained batch 415 in epoch 5, gen_loss = 0.41131182136730504, disc_loss = 0.03627686640482772
Trained batch 416 in epoch 5, gen_loss = 0.41141358117977206, disc_loss = 0.036204265400977265
Trained batch 417 in epoch 5, gen_loss = 0.41130132595317787, disc_loss = 0.036135890786803404
Trained batch 418 in epoch 5, gen_loss = 0.4112242640202825, disc_loss = 0.036064672338840746
Trained batch 419 in epoch 5, gen_loss = 0.41125452844869526, disc_loss = 0.03600201286940968
Trained batch 420 in epoch 5, gen_loss = 0.411055998323649, disc_loss = 0.03600517028971462
Trained batch 421 in epoch 5, gen_loss = 0.4110358455593552, disc_loss = 0.03602867418518334
Trained batch 422 in epoch 5, gen_loss = 0.4109041594303528, disc_loss = 0.03597959259086801
Trained batch 423 in epoch 5, gen_loss = 0.41098191427453507, disc_loss = 0.03591022988779136
Trained batch 424 in epoch 5, gen_loss = 0.41114319906515234, disc_loss = 0.03583752525258152
Trained batch 425 in epoch 5, gen_loss = 0.41105784112019156, disc_loss = 0.035812529722696496
Trained batch 426 in epoch 5, gen_loss = 0.4112412504485396, disc_loss = 0.03578351545409328
Trained batch 427 in epoch 5, gen_loss = 0.41130337529928884, disc_loss = 0.03603068463315003
Trained batch 428 in epoch 5, gen_loss = 0.41123924854196314, disc_loss = 0.03654353708812494
Trained batch 429 in epoch 5, gen_loss = 0.411270986809287, disc_loss = 0.03666631308286776
Trained batch 430 in epoch 5, gen_loss = 0.4112350508536098, disc_loss = 0.03675837004978616
Trained batch 431 in epoch 5, gen_loss = 0.4112767769644658, disc_loss = 0.03674857878973449
Trained batch 432 in epoch 5, gen_loss = 0.4111705432725558, disc_loss = 0.036710996792154865
Trained batch 433 in epoch 5, gen_loss = 0.41116163793796767, disc_loss = 0.03666567500339486
Trained batch 434 in epoch 5, gen_loss = 0.4111954997325766, disc_loss = 0.03659289233739777
Trained batch 435 in epoch 5, gen_loss = 0.4111929441537332, disc_loss = 0.03652103077203736
Trained batch 436 in epoch 5, gen_loss = 0.41092971124147115, disc_loss = 0.036466851189532225
Trained batch 437 in epoch 5, gen_loss = 0.4107878015602016, disc_loss = 0.03645024339181528
Trained batch 438 in epoch 5, gen_loss = 0.4107588143310677, disc_loss = 0.0364829421086886
Trained batch 439 in epoch 5, gen_loss = 0.4107673125510866, disc_loss = 0.03651952507577583
Trained batch 440 in epoch 5, gen_loss = 0.41072302198464095, disc_loss = 0.036546421364528424
Trained batch 441 in epoch 5, gen_loss = 0.4109024650910321, disc_loss = 0.03653472953853176
Trained batch 442 in epoch 5, gen_loss = 0.41102988994417555, disc_loss = 0.03648479112831804
Trained batch 443 in epoch 5, gen_loss = 0.41096646546780524, disc_loss = 0.0364367586129496
Trained batch 444 in epoch 5, gen_loss = 0.41103627092382883, disc_loss = 0.03648874282135806
Trained batch 445 in epoch 5, gen_loss = 0.4109816110187582, disc_loss = 0.0375364324367175
Trained batch 446 in epoch 5, gen_loss = 0.41073568968698215, disc_loss = 0.037744250653261605
Trained batch 447 in epoch 5, gen_loss = 0.41076532824497136, disc_loss = 0.038073193827066074
Trained batch 448 in epoch 5, gen_loss = 0.4106527786610652, disc_loss = 0.038103987556676856
Trained batch 449 in epoch 5, gen_loss = 0.41061785572104986, disc_loss = 0.03831472556261967
Trained batch 450 in epoch 5, gen_loss = 0.41058046597070547, disc_loss = 0.03826849918013352
Trained batch 451 in epoch 5, gen_loss = 0.41058334938984004, disc_loss = 0.03826326719924099
Trained batch 452 in epoch 5, gen_loss = 0.41058522054954344, disc_loss = 0.038409977292469304
Trained batch 453 in epoch 5, gen_loss = 0.4106693164104932, disc_loss = 0.03879452470150501
Trained batch 454 in epoch 5, gen_loss = 0.41062952725441904, disc_loss = 0.03913980224272134
Trained batch 455 in epoch 5, gen_loss = 0.4107406126302585, disc_loss = 0.03934709348342087
Trained batch 456 in epoch 5, gen_loss = 0.4104998409095948, disc_loss = 0.0394240465444152
Trained batch 457 in epoch 5, gen_loss = 0.41049501514590986, disc_loss = 0.039549534429194136
Trained batch 458 in epoch 5, gen_loss = 0.4103363517322831, disc_loss = 0.03959451903576896
Trained batch 459 in epoch 5, gen_loss = 0.41030698334393295, disc_loss = 0.039667202747406684
Trained batch 460 in epoch 5, gen_loss = 0.4102225439408855, disc_loss = 0.039608882635593444
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 0.3419651985168457, disc_loss = 0.10212893784046173
Trained batch 1 in epoch 6, gen_loss = 0.38972342014312744, disc_loss = 0.11581481248140335
Trained batch 2 in epoch 6, gen_loss = 0.39651207129160565, disc_loss = 0.0804944255699714
Trained batch 3 in epoch 6, gen_loss = 0.37882286310195923, disc_loss = 0.07240515621379018
Trained batch 4 in epoch 6, gen_loss = 0.37843949198722837, disc_loss = 0.06432491727173328
Trained batch 5 in epoch 6, gen_loss = 0.3834083179632823, disc_loss = 0.056440599573155247
Trained batch 6 in epoch 6, gen_loss = 0.39115228397505625, disc_loss = 0.04969602344291551
Trained batch 7 in epoch 6, gen_loss = 0.3909973241388798, disc_loss = 0.04488338576629758
Trained batch 8 in epoch 6, gen_loss = 0.384207288424174, disc_loss = 0.041098525954617396
Trained batch 9 in epoch 6, gen_loss = 0.3881611734628677, disc_loss = 0.04179994240403175
Trained batch 10 in epoch 6, gen_loss = 0.39297164570201526, disc_loss = 0.04300438409501856
Trained batch 11 in epoch 6, gen_loss = 0.39392030239105225, disc_loss = 0.044455526396632195
Trained batch 12 in epoch 6, gen_loss = 0.39104764278118426, disc_loss = 0.0626000423844044
Trained batch 13 in epoch 6, gen_loss = 0.3885543005807059, disc_loss = 0.061156430946929116
Trained batch 14 in epoch 6, gen_loss = 0.3905165414015452, disc_loss = 0.05970993290344874
Trained batch 15 in epoch 6, gen_loss = 0.3936809543520212, disc_loss = 0.05980963190086186
Trained batch 16 in epoch 6, gen_loss = 0.3940461540923399, disc_loss = 0.06120812169769231
Trained batch 17 in epoch 6, gen_loss = 0.3986186732848485, disc_loss = 0.059021735253433384
Trained batch 18 in epoch 6, gen_loss = 0.39893646302976105, disc_loss = 0.05724986613188919
Trained batch 19 in epoch 6, gen_loss = 0.4004028022289276, disc_loss = 0.05476888595148921
Trained batch 20 in epoch 6, gen_loss = 0.40228657779239474, disc_loss = 0.05255549631658055
Trained batch 21 in epoch 6, gen_loss = 0.4031782841140574, disc_loss = 0.050751447889276526
Trained batch 22 in epoch 6, gen_loss = 0.4007889265599458, disc_loss = 0.04926640317653832
Trained batch 23 in epoch 6, gen_loss = 0.40234658991297084, disc_loss = 0.047648627505016826
Trained batch 24 in epoch 6, gen_loss = 0.4056912100315094, disc_loss = 0.04621943656355142
Trained batch 25 in epoch 6, gen_loss = 0.40593148653323835, disc_loss = 0.04484224147521532
Trained batch 26 in epoch 6, gen_loss = 0.40741773115264046, disc_loss = 0.04367528686782828
Trained batch 27 in epoch 6, gen_loss = 0.4073122814297676, disc_loss = 0.042277648246714046
Trained batch 28 in epoch 6, gen_loss = 0.403458414406612, disc_loss = 0.042358415265535486
Trained batch 29 in epoch 6, gen_loss = 0.40507087806860603, disc_loss = 0.052396966392795244
Trained batch 30 in epoch 6, gen_loss = 0.40290380966278816, disc_loss = 0.057080923910102534
Trained batch 31 in epoch 6, gen_loss = 0.40287652611732483, disc_loss = 0.05779767071362585
Trained batch 32 in epoch 6, gen_loss = 0.40218710086562415, disc_loss = 0.0571093438475421
Trained batch 33 in epoch 6, gen_loss = 0.40198855978601117, disc_loss = 0.05644845579038648
Trained batch 34 in epoch 6, gen_loss = 0.40323286141668047, disc_loss = 0.055299606812851766
Trained batch 35 in epoch 6, gen_loss = 0.4008353344268269, disc_loss = 0.05661678241772784
Trained batch 36 in epoch 6, gen_loss = 0.4015511298501814, disc_loss = 0.05891802755964769
Trained batch 37 in epoch 6, gen_loss = 0.40089960553144155, disc_loss = 0.058746170938799254
Trained batch 38 in epoch 6, gen_loss = 0.4001312859547444, disc_loss = 0.05752390326979833
Trained batch 39 in epoch 6, gen_loss = 0.4003961257636547, disc_loss = 0.05624407604336738
Trained batch 40 in epoch 6, gen_loss = 0.40305489955878837, disc_loss = 0.055122796491515344
Trained batch 41 in epoch 6, gen_loss = 0.4024313347680228, disc_loss = 0.05402253878613313
Trained batch 42 in epoch 6, gen_loss = 0.4019674534021422, disc_loss = 0.0540422519972158
Trained batch 43 in epoch 6, gen_loss = 0.40086538615551864, disc_loss = 0.060535679486664856
Trained batch 44 in epoch 6, gen_loss = 0.4019402775499556, disc_loss = 0.06207933127880096
Trained batch 45 in epoch 6, gen_loss = 0.40166639050711755, disc_loss = 0.06184432542194491
Trained batch 46 in epoch 6, gen_loss = 0.4030770272650617, disc_loss = 0.06093667709129922
Trained batch 47 in epoch 6, gen_loss = 0.40286171312133473, disc_loss = 0.06017572021422287
Trained batch 48 in epoch 6, gen_loss = 0.4045887151542975, disc_loss = 0.05924855769440836
Trained batch 49 in epoch 6, gen_loss = 0.40362655580043794, disc_loss = 0.05858917709439993
Trained batch 50 in epoch 6, gen_loss = 0.4031298417671054, disc_loss = 0.058948763262699634
Trained batch 51 in epoch 6, gen_loss = 0.40294302770724666, disc_loss = 0.06200091179030446
Trained batch 52 in epoch 6, gen_loss = 0.4030956682169212, disc_loss = 0.062072542865040166
Trained batch 53 in epoch 6, gen_loss = 0.40385448932647705, disc_loss = 0.06138308749844631
Trained batch 54 in epoch 6, gen_loss = 0.40291624990376557, disc_loss = 0.062100514938885513
Trained batch 55 in epoch 6, gen_loss = 0.4034129748386996, disc_loss = 0.06187679096391158
Trained batch 56 in epoch 6, gen_loss = 0.4043957324404466, disc_loss = 0.061110321726453934
Trained batch 57 in epoch 6, gen_loss = 0.4047823692190236, disc_loss = 0.06102274766127611
Trained batch 58 in epoch 6, gen_loss = 0.4043852323192661, disc_loss = 0.06020765521137391
Trained batch 59 in epoch 6, gen_loss = 0.40281547605991364, disc_loss = 0.06105864665781458
Trained batch 60 in epoch 6, gen_loss = 0.40387393607467903, disc_loss = 0.06611961733977326
Trained batch 61 in epoch 6, gen_loss = 0.4031806395899865, disc_loss = 0.06544954969637817
Trained batch 62 in epoch 6, gen_loss = 0.40359976130818564, disc_loss = 0.06526678194484067
Trained batch 63 in epoch 6, gen_loss = 0.4032374294474721, disc_loss = 0.06494696470326744
Trained batch 64 in epoch 6, gen_loss = 0.40277997713822583, disc_loss = 0.06431473310177142
Trained batch 65 in epoch 6, gen_loss = 0.401109645764033, disc_loss = 0.06351746548192971
Trained batch 66 in epoch 6, gen_loss = 0.40179479122161865, disc_loss = 0.06267429145275434
Trained batch 67 in epoch 6, gen_loss = 0.4013795449453242, disc_loss = 0.062083827270030534
Trained batch 68 in epoch 6, gen_loss = 0.4009904494320137, disc_loss = 0.06125075612352162
Trained batch 69 in epoch 6, gen_loss = 0.40139543328966415, disc_loss = 0.060770145797037656
Trained batch 70 in epoch 6, gen_loss = 0.401055160542609, disc_loss = 0.06002758655198653
Trained batch 71 in epoch 6, gen_loss = 0.40083004617028767, disc_loss = 0.05946895637316629
Trained batch 72 in epoch 6, gen_loss = 0.39996290329384476, disc_loss = 0.05882047418479438
Trained batch 73 in epoch 6, gen_loss = 0.4006800136050662, disc_loss = 0.05833548876909992
Trained batch 74 in epoch 6, gen_loss = 0.3998743152618408, disc_loss = 0.057692802331099906
Trained batch 75 in epoch 6, gen_loss = 0.39877031821953624, disc_loss = 0.05717864510676775
Trained batch 76 in epoch 6, gen_loss = 0.3984446901005584, disc_loss = 0.05651153994772535
Trained batch 77 in epoch 6, gen_loss = 0.3993670111283278, disc_loss = 0.05585584067739546
Trained batch 78 in epoch 6, gen_loss = 0.4003404148771793, disc_loss = 0.05536229639090126
Trained batch 79 in epoch 6, gen_loss = 0.40040553621947766, disc_loss = 0.05492185719194822
Trained batch 80 in epoch 6, gen_loss = 0.40047190844276803, disc_loss = 0.054361018921352096
Trained batch 81 in epoch 6, gen_loss = 0.400901420814235, disc_loss = 0.05376922169404968
Trained batch 82 in epoch 6, gen_loss = 0.40189504192536135, disc_loss = 0.05319618265402604
Trained batch 83 in epoch 6, gen_loss = 0.4021398325761159, disc_loss = 0.05263159095886208
Trained batch 84 in epoch 6, gen_loss = 0.4030829717131222, disc_loss = 0.05209580868592157
Trained batch 85 in epoch 6, gen_loss = 0.4035329323175342, disc_loss = 0.05158283762352238
Trained batch 86 in epoch 6, gen_loss = 0.4036855625695196, disc_loss = 0.05103853535998998
Trained batch 87 in epoch 6, gen_loss = 0.40349861640821805, disc_loss = 0.05060049641178921
Trained batch 88 in epoch 6, gen_loss = 0.4034225398235107, disc_loss = 0.05007788641482926
Trained batch 89 in epoch 6, gen_loss = 0.4037993507252799, disc_loss = 0.049704109711779486
Trained batch 90 in epoch 6, gen_loss = 0.4032123468734406, disc_loss = 0.04922708272319901
Trained batch 91 in epoch 6, gen_loss = 0.40426293630962784, disc_loss = 0.0487380814080572
Trained batch 92 in epoch 6, gen_loss = 0.4040668843894876, disc_loss = 0.048268443879781554
Trained batch 93 in epoch 6, gen_loss = 0.4051373467800465, disc_loss = 0.04797135662545073
Trained batch 94 in epoch 6, gen_loss = 0.40426488801052696, disc_loss = 0.04856543012061401
Trained batch 95 in epoch 6, gen_loss = 0.40461814527710277, disc_loss = 0.04984574862464797
Trained batch 96 in epoch 6, gen_loss = 0.4048471208085719, disc_loss = 0.049500961571970245
Trained batch 97 in epoch 6, gen_loss = 0.4051956221157191, disc_loss = 0.049356040967704386
Trained batch 98 in epoch 6, gen_loss = 0.40521493403598513, disc_loss = 0.04899808455427939
Trained batch 99 in epoch 6, gen_loss = 0.40580915957689284, disc_loss = 0.04854999426286668
Trained batch 100 in epoch 6, gen_loss = 0.4051636062046089, disc_loss = 0.04827214976182521
Trained batch 101 in epoch 6, gen_loss = 0.40509457740129207, disc_loss = 0.04894962928294405
Trained batch 102 in epoch 6, gen_loss = 0.4038567285514572, disc_loss = 0.051057485334611345
Trained batch 103 in epoch 6, gen_loss = 0.4040852223451321, disc_loss = 0.05172651583024372
Trained batch 104 in epoch 6, gen_loss = 0.40411449216661, disc_loss = 0.051506148611328434
Trained batch 105 in epoch 6, gen_loss = 0.4036387877081925, disc_loss = 0.051443924297104184
Trained batch 106 in epoch 6, gen_loss = 0.4029222682257679, disc_loss = 0.05119630702658095
Trained batch 107 in epoch 6, gen_loss = 0.4036096331697923, disc_loss = 0.0508145740798985
Trained batch 108 in epoch 6, gen_loss = 0.40462257255107986, disc_loss = 0.05050269016620079
Trained batch 109 in epoch 6, gen_loss = 0.40446101996031675, disc_loss = 0.0503979793114757
Trained batch 110 in epoch 6, gen_loss = 0.40365294320089323, disc_loss = 0.0506813514533008
Trained batch 111 in epoch 6, gen_loss = 0.4032607802322933, disc_loss = 0.05034047316543625
Trained batch 112 in epoch 6, gen_loss = 0.40332083048018735, disc_loss = 0.05021917053077996
Trained batch 113 in epoch 6, gen_loss = 0.4032236865737982, disc_loss = 0.04985153004772177
Trained batch 114 in epoch 6, gen_loss = 0.40365241688230763, disc_loss = 0.04961294162127635
Trained batch 115 in epoch 6, gen_loss = 0.4036700466069682, disc_loss = 0.04967249460630761
Trained batch 116 in epoch 6, gen_loss = 0.40374200262575066, disc_loss = 0.04937908726417993
Trained batch 117 in epoch 6, gen_loss = 0.40339233410560477, disc_loss = 0.049077787101110916
Trained batch 118 in epoch 6, gen_loss = 0.4030464587091398, disc_loss = 0.04882021329342192
Trained batch 119 in epoch 6, gen_loss = 0.4025973707437515, disc_loss = 0.04859201896858091
Trained batch 120 in epoch 6, gen_loss = 0.4028909494561597, disc_loss = 0.048386091331774295
Trained batch 121 in epoch 6, gen_loss = 0.4029501815799807, disc_loss = 0.048098566968635216
Trained batch 122 in epoch 6, gen_loss = 0.40317614873250324, disc_loss = 0.048020593984794566
Trained batch 123 in epoch 6, gen_loss = 0.40316807238325, disc_loss = 0.047704430713859054
Trained batch 124 in epoch 6, gen_loss = 0.40301726603508, disc_loss = 0.04746120923385024
Trained batch 125 in epoch 6, gen_loss = 0.4032858797009029, disc_loss = 0.04718384496675479
Trained batch 126 in epoch 6, gen_loss = 0.40329886116380764, disc_loss = 0.04689149520044604
Trained batch 127 in epoch 6, gen_loss = 0.40267188963480294, disc_loss = 0.04663043567779823
Trained batch 128 in epoch 6, gen_loss = 0.40367931520292, disc_loss = 0.04649069237833222
Trained batch 129 in epoch 6, gen_loss = 0.40381311384531166, disc_loss = 0.04622491761110723
Trained batch 130 in epoch 6, gen_loss = 0.404505574293719, disc_loss = 0.04592066601928295
Trained batch 131 in epoch 6, gen_loss = 0.4046348848126151, disc_loss = 0.04582639444605306
Trained batch 132 in epoch 6, gen_loss = 0.40466149296975673, disc_loss = 0.04555116871483904
Trained batch 133 in epoch 6, gen_loss = 0.4045126489294109, disc_loss = 0.0455257344136098
Trained batch 134 in epoch 6, gen_loss = 0.4048559308052063, disc_loss = 0.04528794851223076
Trained batch 135 in epoch 6, gen_loss = 0.40477534186314135, disc_loss = 0.04504822517457582
Trained batch 136 in epoch 6, gen_loss = 0.4048737833534714, disc_loss = 0.04477000457105519
Trained batch 137 in epoch 6, gen_loss = 0.4045354531726975, disc_loss = 0.044473201702888786
Trained batch 138 in epoch 6, gen_loss = 0.40496752523689816, disc_loss = 0.044204643131870267
Trained batch 139 in epoch 6, gen_loss = 0.40546989845378056, disc_loss = 0.0440038727746079
Trained batch 140 in epoch 6, gen_loss = 0.4057988080572575, disc_loss = 0.04375807591713965
Trained batch 141 in epoch 6, gen_loss = 0.4057019231185107, disc_loss = 0.04353322985444323
Trained batch 142 in epoch 6, gen_loss = 0.40537641077608494, disc_loss = 0.043268343031575736
Trained batch 143 in epoch 6, gen_loss = 0.40556802973151207, disc_loss = 0.04308412943404013
Trained batch 144 in epoch 6, gen_loss = 0.40534928893220834, disc_loss = 0.04325373753552036
Trained batch 145 in epoch 6, gen_loss = 0.40476754960948474, disc_loss = 0.04302739426780696
Trained batch 146 in epoch 6, gen_loss = 0.40398675993997224, disc_loss = 0.04372868097235202
Trained batch 147 in epoch 6, gen_loss = 0.40424112190265915, disc_loss = 0.04410262947832864
Trained batch 148 in epoch 6, gen_loss = 0.40458435960264016, disc_loss = 0.043897074305033625
Trained batch 149 in epoch 6, gen_loss = 0.4044908301035563, disc_loss = 0.04368229136647036
Trained batch 150 in epoch 6, gen_loss = 0.4045609450892897, disc_loss = 0.04343638559710851
Trained batch 151 in epoch 6, gen_loss = 0.4043680998055558, disc_loss = 0.043245018507341706
Trained batch 152 in epoch 6, gen_loss = 0.4042624967550141, disc_loss = 0.04298820558576266
Trained batch 153 in epoch 6, gen_loss = 0.4042903186825963, disc_loss = 0.04272484567240122
Trained batch 154 in epoch 6, gen_loss = 0.4043210366079884, disc_loss = 0.04248637211088452
Trained batch 155 in epoch 6, gen_loss = 0.40481089036434126, disc_loss = 0.04224319144253595
Trained batch 156 in epoch 6, gen_loss = 0.4046315222409121, disc_loss = 0.042015858476530686
Trained batch 157 in epoch 6, gen_loss = 0.4047028501577015, disc_loss = 0.04178727541525577
Trained batch 158 in epoch 6, gen_loss = 0.40449602217794217, disc_loss = 0.04156164610729137
Trained batch 159 in epoch 6, gen_loss = 0.4048969393596053, disc_loss = 0.04133214839821449
Trained batch 160 in epoch 6, gen_loss = 0.40484386441870507, disc_loss = 0.04111821194445448
Trained batch 161 in epoch 6, gen_loss = 0.4047524200545417, disc_loss = 0.04088615058679824
Trained batch 162 in epoch 6, gen_loss = 0.40476543917977736, disc_loss = 0.04065370385712184
Trained batch 163 in epoch 6, gen_loss = 0.4048005585990301, disc_loss = 0.04042458053530625
Trained batch 164 in epoch 6, gen_loss = 0.40503636345718846, disc_loss = 0.04020762882392966
Trained batch 165 in epoch 6, gen_loss = 0.4048190280256501, disc_loss = 0.03999762261477131
Trained batch 166 in epoch 6, gen_loss = 0.4050192277945444, disc_loss = 0.03981010973576211
Trained batch 167 in epoch 6, gen_loss = 0.40482462215281667, disc_loss = 0.03960226251677211
Trained batch 168 in epoch 6, gen_loss = 0.4047876009221613, disc_loss = 0.03939931076185326
Trained batch 169 in epoch 6, gen_loss = 0.4043838048682493, disc_loss = 0.03959311298642527
Trained batch 170 in epoch 6, gen_loss = 0.4045254626469305, disc_loss = 0.04020808514327421
Trained batch 171 in epoch 6, gen_loss = 0.40478679243215293, disc_loss = 0.04012216340891237
Trained batch 172 in epoch 6, gen_loss = 0.4049484183678048, disc_loss = 0.04004717402084801
Trained batch 173 in epoch 6, gen_loss = 0.40477983859078637, disc_loss = 0.03985747964196335
Trained batch 174 in epoch 6, gen_loss = 0.4044745905058725, disc_loss = 0.039891701910112584
Trained batch 175 in epoch 6, gen_loss = 0.4046149148859761, disc_loss = 0.03985918987944553
Trained batch 176 in epoch 6, gen_loss = 0.4047956909500273, disc_loss = 0.03968118757830333
Trained batch 177 in epoch 6, gen_loss = 0.40492333237374767, disc_loss = 0.039573175094896156
Trained batch 178 in epoch 6, gen_loss = 0.4044751138660495, disc_loss = 0.04008922995947426
Trained batch 179 in epoch 6, gen_loss = 0.40492647058433956, disc_loss = 0.041267017021568285
Trained batch 180 in epoch 6, gen_loss = 0.40478723895483915, disc_loss = 0.04109509748751452
Trained batch 181 in epoch 6, gen_loss = 0.40469211651073705, disc_loss = 0.04096514231699345
Trained batch 182 in epoch 6, gen_loss = 0.40466395101912034, disc_loss = 0.04087270856860394
Trained batch 183 in epoch 6, gen_loss = 0.4045152401794558, disc_loss = 0.040723973196809704
Trained batch 184 in epoch 6, gen_loss = 0.4045785792776056, disc_loss = 0.040560653040537964
Trained batch 185 in epoch 6, gen_loss = 0.4048697929228506, disc_loss = 0.04053199797948842
Trained batch 186 in epoch 6, gen_loss = 0.40448440316526646, disc_loss = 0.04119984735859269
Trained batch 187 in epoch 6, gen_loss = 0.4044761488095243, disc_loss = 0.04218051600408681
Trained batch 188 in epoch 6, gen_loss = 0.40429889004697245, disc_loss = 0.04203159614865269
Trained batch 189 in epoch 6, gen_loss = 0.4043532652290244, disc_loss = 0.04190286820950477
Trained batch 190 in epoch 6, gen_loss = 0.40391099515385653, disc_loss = 0.04172879048374467
Trained batch 191 in epoch 6, gen_loss = 0.4040314505497615, disc_loss = 0.04152978219887397
Trained batch 192 in epoch 6, gen_loss = 0.4042803614250737, disc_loss = 0.04141519053168402
Trained batch 193 in epoch 6, gen_loss = 0.40389279468157857, disc_loss = 0.04137093697184908
Trained batch 194 in epoch 6, gen_loss = 0.40364493681834296, disc_loss = 0.041285288501053286
Trained batch 195 in epoch 6, gen_loss = 0.4039102920464107, disc_loss = 0.041790199081166365
Trained batch 196 in epoch 6, gen_loss = 0.4034607900580779, disc_loss = 0.04208416568805572
Trained batch 197 in epoch 6, gen_loss = 0.40308905129480843, disc_loss = 0.041932592342485385
Trained batch 198 in epoch 6, gen_loss = 0.40311610533963493, disc_loss = 0.04184022136313382
Trained batch 199 in epoch 6, gen_loss = 0.4035610218346119, disc_loss = 0.041773586277849974
Trained batch 200 in epoch 6, gen_loss = 0.4031970910171964, disc_loss = 0.04196997506275254
Trained batch 201 in epoch 6, gen_loss = 0.40278251262584536, disc_loss = 0.04352339578903105
Trained batch 202 in epoch 6, gen_loss = 0.4025040566921234, disc_loss = 0.043908625221788296
Trained batch 203 in epoch 6, gen_loss = 0.4028540724048428, disc_loss = 0.044244797028345516
Trained batch 204 in epoch 6, gen_loss = 0.402904178165808, disc_loss = 0.044230760674832795
Trained batch 205 in epoch 6, gen_loss = 0.40299472748075876, disc_loss = 0.04416979802772403
Trained batch 206 in epoch 6, gen_loss = 0.4026003478517855, disc_loss = 0.04416414478496797
Trained batch 207 in epoch 6, gen_loss = 0.40249896980822086, disc_loss = 0.04409254785143556
Trained batch 208 in epoch 6, gen_loss = 0.40284443443471735, disc_loss = 0.04427737816187896
Trained batch 209 in epoch 6, gen_loss = 0.40221884704771493, disc_loss = 0.044910412587757624
Trained batch 210 in epoch 6, gen_loss = 0.4025712020306791, disc_loss = 0.04509589254803143
Trained batch 211 in epoch 6, gen_loss = 0.40270691744561465, disc_loss = 0.04523490006016251
Trained batch 212 in epoch 6, gen_loss = 0.40251285649241414, disc_loss = 0.04508601386589763
Trained batch 213 in epoch 6, gen_loss = 0.40206872107826663, disc_loss = 0.04521873818327472
Trained batch 214 in epoch 6, gen_loss = 0.4023007191890894, disc_loss = 0.04510948907064144
Trained batch 215 in epoch 6, gen_loss = 0.40249656623712293, disc_loss = 0.044953175354748964
Trained batch 216 in epoch 6, gen_loss = 0.4027528552690409, disc_loss = 0.044907135262330006
Trained batch 217 in epoch 6, gen_loss = 0.40283483567587824, disc_loss = 0.044759964531954
Trained batch 218 in epoch 6, gen_loss = 0.4032376522887243, disc_loss = 0.044597296286629486
Trained batch 219 in epoch 6, gen_loss = 0.4033626901832494, disc_loss = 0.044624748229133815
Trained batch 220 in epoch 6, gen_loss = 0.40374613657796005, disc_loss = 0.045298662740416926
Trained batch 221 in epoch 6, gen_loss = 0.4039785829750267, disc_loss = 0.045801973033293676
Trained batch 222 in epoch 6, gen_loss = 0.404084847379693, disc_loss = 0.0457209429156553
Trained batch 223 in epoch 6, gen_loss = 0.40420848077961374, disc_loss = 0.04558674413627679
Trained batch 224 in epoch 6, gen_loss = 0.40437456197208826, disc_loss = 0.045582609354621835
Trained batch 225 in epoch 6, gen_loss = 0.4041520511418317, disc_loss = 0.04546076441348522
Trained batch 226 in epoch 6, gen_loss = 0.40431863345238606, disc_loss = 0.04529816057894067
Trained batch 227 in epoch 6, gen_loss = 0.4041648908403882, disc_loss = 0.04512424575442677
Trained batch 228 in epoch 6, gen_loss = 0.40413139506719, disc_loss = 0.044986915148339156
Trained batch 229 in epoch 6, gen_loss = 0.40442234433215596, disc_loss = 0.04483409098390004
Trained batch 230 in epoch 6, gen_loss = 0.4043114431750723, disc_loss = 0.04475046397948807
Trained batch 231 in epoch 6, gen_loss = 0.4046659969307225, disc_loss = 0.04461781046321166
Trained batch 232 in epoch 6, gen_loss = 0.4048073406894831, disc_loss = 0.044888151897509214
Trained batch 233 in epoch 6, gen_loss = 0.40473369222420913, disc_loss = 0.045508862258150026
Trained batch 234 in epoch 6, gen_loss = 0.4043682577762198, disc_loss = 0.04595026908085701
Trained batch 235 in epoch 6, gen_loss = 0.4046381806670609, disc_loss = 0.045822506328508004
Trained batch 236 in epoch 6, gen_loss = 0.4049019717968969, disc_loss = 0.04579175169332118
Trained batch 237 in epoch 6, gen_loss = 0.4047392718180889, disc_loss = 0.0456568916218684
Trained batch 238 in epoch 6, gen_loss = 0.404684044576589, disc_loss = 0.04549280167304011
Trained batch 239 in epoch 6, gen_loss = 0.404675675307711, disc_loss = 0.045328476722352205
Trained batch 240 in epoch 6, gen_loss = 0.4049456233305555, disc_loss = 0.04517956227218709
Trained batch 241 in epoch 6, gen_loss = 0.4048484749784154, disc_loss = 0.045011019145623464
Trained batch 242 in epoch 6, gen_loss = 0.40496510083292736, disc_loss = 0.04484363626918675
Trained batch 243 in epoch 6, gen_loss = 0.40510204690890234, disc_loss = 0.04469104497846155
Trained batch 244 in epoch 6, gen_loss = 0.40496580406111116, disc_loss = 0.04453163889939992
Trained batch 245 in epoch 6, gen_loss = 0.40490584838681104, disc_loss = 0.04438978806327332
Trained batch 246 in epoch 6, gen_loss = 0.4044875308328312, disc_loss = 0.04443326821882534
Trained batch 247 in epoch 6, gen_loss = 0.40468187485971757, disc_loss = 0.044431227126023584
Trained batch 248 in epoch 6, gen_loss = 0.4044394394958833, disc_loss = 0.044275532813226604
Trained batch 249 in epoch 6, gen_loss = 0.4045079045295715, disc_loss = 0.04413603667542338
Trained batch 250 in epoch 6, gen_loss = 0.4046144461726762, disc_loss = 0.04403705766194489
Trained batch 251 in epoch 6, gen_loss = 0.40463780304269187, disc_loss = 0.04396736518745976
Trained batch 252 in epoch 6, gen_loss = 0.4048471917276797, disc_loss = 0.04383622211856922
Trained batch 253 in epoch 6, gen_loss = 0.40494652221521993, disc_loss = 0.04374590753320986
Trained batch 254 in epoch 6, gen_loss = 0.40532780394834633, disc_loss = 0.043589315612745635
Trained batch 255 in epoch 6, gen_loss = 0.40566220018081367, disc_loss = 0.043443718594062375
Trained batch 256 in epoch 6, gen_loss = 0.4061631799208051, disc_loss = 0.043306386471519444
Trained batch 257 in epoch 6, gen_loss = 0.40612950077814647, disc_loss = 0.043232974874274445
Trained batch 258 in epoch 6, gen_loss = 0.4062663543408442, disc_loss = 0.04314471441446929
Trained batch 259 in epoch 6, gen_loss = 0.40639252272936016, disc_loss = 0.04300975241841605
Trained batch 260 in epoch 6, gen_loss = 0.40619767922551236, disc_loss = 0.04289706986597329
Trained batch 261 in epoch 6, gen_loss = 0.4066016962965026, disc_loss = 0.04275467327461784
Trained batch 262 in epoch 6, gen_loss = 0.4065021470245753, disc_loss = 0.042630201003765654
Trained batch 263 in epoch 6, gen_loss = 0.4064424659943942, disc_loss = 0.04249331597803217
Trained batch 264 in epoch 6, gen_loss = 0.40665575322115194, disc_loss = 0.042386404628742415
Trained batch 265 in epoch 6, gen_loss = 0.4066920226677916, disc_loss = 0.0423334201139615
Trained batch 266 in epoch 6, gen_loss = 0.40682035639937897, disc_loss = 0.04239764601717728
Trained batch 267 in epoch 6, gen_loss = 0.4066164698173751, disc_loss = 0.04236525160941615
Trained batch 268 in epoch 6, gen_loss = 0.4066101663839418, disc_loss = 0.042271983467014745
Trained batch 269 in epoch 6, gen_loss = 0.40678021676010556, disc_loss = 0.04216697438171616
Trained batch 270 in epoch 6, gen_loss = 0.4068477627755971, disc_loss = 0.04202525952755305
Trained batch 271 in epoch 6, gen_loss = 0.4071147687294904, disc_loss = 0.04189142433632001
Trained batch 272 in epoch 6, gen_loss = 0.4072496906304971, disc_loss = 0.0417605692251234
Trained batch 273 in epoch 6, gen_loss = 0.40710944350618516, disc_loss = 0.04163034066700642
Trained batch 274 in epoch 6, gen_loss = 0.4073521097139879, disc_loss = 0.041500137790360235
Trained batch 275 in epoch 6, gen_loss = 0.407275742702726, disc_loss = 0.041365009199395994
Trained batch 276 in epoch 6, gen_loss = 0.40743227480550964, disc_loss = 0.0412303498384647
Trained batch 277 in epoch 6, gen_loss = 0.40765874130691554, disc_loss = 0.041111712739300386
Trained batch 278 in epoch 6, gen_loss = 0.4076652516173633, disc_loss = 0.04097817794296316
Trained batch 279 in epoch 6, gen_loss = 0.40777641385793684, disc_loss = 0.04086152177603383
Trained batch 280 in epoch 6, gen_loss = 0.4076467332466641, disc_loss = 0.04073418123528255
Trained batch 281 in epoch 6, gen_loss = 0.40782970824140186, disc_loss = 0.04060060280731859
Trained batch 282 in epoch 6, gen_loss = 0.4076297892909168, disc_loss = 0.04047740343464506
Trained batch 283 in epoch 6, gen_loss = 0.4075800081793691, disc_loss = 0.04035800370932097
Trained batch 284 in epoch 6, gen_loss = 0.4073905653075168, disc_loss = 0.04023013632711873
Trained batch 285 in epoch 6, gen_loss = 0.4073690135370601, disc_loss = 0.040106534383135974
Trained batch 286 in epoch 6, gen_loss = 0.40745032685143606, disc_loss = 0.03998134354168374
Trained batch 287 in epoch 6, gen_loss = 0.4074273585445351, disc_loss = 0.03987412390900621
Trained batch 288 in epoch 6, gen_loss = 0.4073633551597595, disc_loss = 0.03976111560512115
Trained batch 289 in epoch 6, gen_loss = 0.4073046404739906, disc_loss = 0.03966953796013419
Trained batch 290 in epoch 6, gen_loss = 0.4073152712120633, disc_loss = 0.03956916190114167
Trained batch 291 in epoch 6, gen_loss = 0.40745036161109194, disc_loss = 0.039469227512137425
Trained batch 292 in epoch 6, gen_loss = 0.4074899597989821, disc_loss = 0.03938920149872073
Trained batch 293 in epoch 6, gen_loss = 0.4074853442761363, disc_loss = 0.03927863917636628
Trained batch 294 in epoch 6, gen_loss = 0.4075644105167712, disc_loss = 0.03916435091424796
Trained batch 295 in epoch 6, gen_loss = 0.407879846724304, disc_loss = 0.039062409230658936
Trained batch 296 in epoch 6, gen_loss = 0.4079361916190446, disc_loss = 0.038964021063538315
Trained batch 297 in epoch 6, gen_loss = 0.4079117467939454, disc_loss = 0.038842841712507924
Trained batch 298 in epoch 6, gen_loss = 0.40779687239972245, disc_loss = 0.03872593642090973
Trained batch 299 in epoch 6, gen_loss = 0.407759802043438, disc_loss = 0.038610878579008086
Trained batch 300 in epoch 6, gen_loss = 0.4078232513313674, disc_loss = 0.038537446092319155
Trained batch 301 in epoch 6, gen_loss = 0.40775071222655823, disc_loss = 0.038437657531609895
Trained batch 302 in epoch 6, gen_loss = 0.40782941449986826, disc_loss = 0.03832610998849812
Trained batch 303 in epoch 6, gen_loss = 0.40797360623745543, disc_loss = 0.03821432484025871
Trained batch 304 in epoch 6, gen_loss = 0.40805654398730545, disc_loss = 0.03809729388563848
Trained batch 305 in epoch 6, gen_loss = 0.4079209772589939, disc_loss = 0.037992154025880534
Trained batch 306 in epoch 6, gen_loss = 0.40830753466982017, disc_loss = 0.0378847775119281
Trained batch 307 in epoch 6, gen_loss = 0.4082838269797238, disc_loss = 0.03777407548940656
Trained batch 308 in epoch 6, gen_loss = 0.4085050529067956, disc_loss = 0.037670620057044676
Trained batch 309 in epoch 6, gen_loss = 0.40856073566021456, disc_loss = 0.03756265417943078
Trained batch 310 in epoch 6, gen_loss = 0.4086840353019751, disc_loss = 0.037504779719942254
Trained batch 311 in epoch 6, gen_loss = 0.4083041378702873, disc_loss = 0.037603342034018196
Trained batch 312 in epoch 6, gen_loss = 0.4087438499584746, disc_loss = 0.03759505304570396
Trained batch 313 in epoch 6, gen_loss = 0.40878600081440747, disc_loss = 0.037498658104758165
Trained batch 314 in epoch 6, gen_loss = 0.4089130943729764, disc_loss = 0.03739647940392532
Trained batch 315 in epoch 6, gen_loss = 0.4088822580591033, disc_loss = 0.03729023507065317
Trained batch 316 in epoch 6, gen_loss = 0.4087845567461068, disc_loss = 0.037190432307730524
Trained batch 317 in epoch 6, gen_loss = 0.40884287477289355, disc_loss = 0.03710434603088963
Trained batch 318 in epoch 6, gen_loss = 0.408859938196254, disc_loss = 0.03699704680918806
Trained batch 319 in epoch 6, gen_loss = 0.4089176217094064, disc_loss = 0.036908696571481416
Trained batch 320 in epoch 6, gen_loss = 0.4089883793365918, disc_loss = 0.0368131055450212
Trained batch 321 in epoch 6, gen_loss = 0.40913083131268896, disc_loss = 0.03673148402359961
Trained batch 322 in epoch 6, gen_loss = 0.4090678702936084, disc_loss = 0.036627135709527844
Trained batch 323 in epoch 6, gen_loss = 0.40908956509313465, disc_loss = 0.03652381841926893
Trained batch 324 in epoch 6, gen_loss = 0.4093552248294537, disc_loss = 0.036432596801851805
Trained batch 325 in epoch 6, gen_loss = 0.40953186574889106, disc_loss = 0.03633409342300033
Trained batch 326 in epoch 6, gen_loss = 0.4095264902902306, disc_loss = 0.03624337354521139
Trained batch 327 in epoch 6, gen_loss = 0.4093910426628299, disc_loss = 0.03614913680159101
Trained batch 328 in epoch 6, gen_loss = 0.40932758555586213, disc_loss = 0.036056028305351914
Trained batch 329 in epoch 6, gen_loss = 0.4093817070578084, disc_loss = 0.03595777672405044
Trained batch 330 in epoch 6, gen_loss = 0.4092525401324304, disc_loss = 0.03587697736716342
Trained batch 331 in epoch 6, gen_loss = 0.40918342086924125, disc_loss = 0.03578021780711161
Trained batch 332 in epoch 6, gen_loss = 0.40913026522587725, disc_loss = 0.03568072577409849
Trained batch 333 in epoch 6, gen_loss = 0.40893506316724654, disc_loss = 0.03558091859230047
Trained batch 334 in epoch 6, gen_loss = 0.4087263510298373, disc_loss = 0.03548726966368285
Trained batch 335 in epoch 6, gen_loss = 0.40872696565375444, disc_loss = 0.035390793490694794
Trained batch 336 in epoch 6, gen_loss = 0.40890615939740255, disc_loss = 0.03529748625470221
Trained batch 337 in epoch 6, gen_loss = 0.408755769126514, disc_loss = 0.03521919318615354
Trained batch 338 in epoch 6, gen_loss = 0.4086811482730517, disc_loss = 0.03515991033741704
Trained batch 339 in epoch 6, gen_loss = 0.40884779516388386, disc_loss = 0.03507675030200249
Trained batch 340 in epoch 6, gen_loss = 0.4089159530278874, disc_loss = 0.03498039688693791
Trained batch 341 in epoch 6, gen_loss = 0.4086887310122886, disc_loss = 0.03497369097455878
Trained batch 342 in epoch 6, gen_loss = 0.4085668007416906, disc_loss = 0.03504381044469122
Trained batch 343 in epoch 6, gen_loss = 0.40865938400113305, disc_loss = 0.03497532244736524
Trained batch 344 in epoch 6, gen_loss = 0.40887984909873076, disc_loss = 0.035307366008856804
Trained batch 345 in epoch 6, gen_loss = 0.4086647378226925, disc_loss = 0.03548613686660961
Trained batch 346 in epoch 6, gen_loss = 0.4084787635019945, disc_loss = 0.0353955092205148
Trained batch 347 in epoch 6, gen_loss = 0.4084878782260007, disc_loss = 0.03535224026103836
Trained batch 348 in epoch 6, gen_loss = 0.40854340151251217, disc_loss = 0.03533225001455058
Trained batch 349 in epoch 6, gen_loss = 0.4087318218605859, disc_loss = 0.03551177817596389
Trained batch 350 in epoch 6, gen_loss = 0.40855834677688074, disc_loss = 0.03581103301299285
Trained batch 351 in epoch 6, gen_loss = 0.40846495262601157, disc_loss = 0.03728483144037786
Trained batch 352 in epoch 6, gen_loss = 0.4082618672347947, disc_loss = 0.03779906195736155
Trained batch 353 in epoch 6, gen_loss = 0.4082844654719035, disc_loss = 0.03820252061576851
Trained batch 354 in epoch 6, gen_loss = 0.4080976579390781, disc_loss = 0.038344232284818106
Trained batch 355 in epoch 6, gen_loss = 0.40780893093749376, disc_loss = 0.03838917877580029
Trained batch 356 in epoch 6, gen_loss = 0.40773405422683523, disc_loss = 0.038366772962932366
Trained batch 357 in epoch 6, gen_loss = 0.4077172062083996, disc_loss = 0.038343742144470984
Trained batch 358 in epoch 6, gen_loss = 0.4076455348381425, disc_loss = 0.03825695019326897
Trained batch 359 in epoch 6, gen_loss = 0.40753198564052584, disc_loss = 0.03816765050416709
Trained batch 360 in epoch 6, gen_loss = 0.40748051708755073, disc_loss = 0.03811218940209174
Trained batch 361 in epoch 6, gen_loss = 0.40753273805860657, disc_loss = 0.03806138198979672
Trained batch 362 in epoch 6, gen_loss = 0.4074261465184288, disc_loss = 0.038095366084671095
Trained batch 363 in epoch 6, gen_loss = 0.4072823458975488, disc_loss = 0.03831567726632744
Trained batch 364 in epoch 6, gen_loss = 0.4073715850098492, disc_loss = 0.03899286549398038
Trained batch 365 in epoch 6, gen_loss = 0.40733499979712273, disc_loss = 0.03893178035543285
Trained batch 366 in epoch 6, gen_loss = 0.40704381815094387, disc_loss = 0.039028638205554446
Trained batch 367 in epoch 6, gen_loss = 0.4071847010079933, disc_loss = 0.03895002227268971
Trained batch 368 in epoch 6, gen_loss = 0.4074500166788334, disc_loss = 0.038916218125445615
Trained batch 369 in epoch 6, gen_loss = 0.40741832272426504, disc_loss = 0.038844625921794086
Trained batch 370 in epoch 6, gen_loss = 0.40707171613958004, disc_loss = 0.03896069784543284
Trained batch 371 in epoch 6, gen_loss = 0.40704117499051556, disc_loss = 0.03943794277579253
Trained batch 372 in epoch 6, gen_loss = 0.40679708243055573, disc_loss = 0.03970794911850893
Trained batch 373 in epoch 6, gen_loss = 0.40666159429652166, disc_loss = 0.03976454233992247
Trained batch 374 in epoch 6, gen_loss = 0.40674839226404824, disc_loss = 0.03971348001373311
Trained batch 375 in epoch 6, gen_loss = 0.4067141315404405, disc_loss = 0.03964359065867029
Trained batch 376 in epoch 6, gen_loss = 0.40670677458259724, disc_loss = 0.03956206527103816
Trained batch 377 in epoch 6, gen_loss = 0.4067577590387334, disc_loss = 0.03948559743665139
Trained batch 378 in epoch 6, gen_loss = 0.4067639886232039, disc_loss = 0.039400689373294134
Trained batch 379 in epoch 6, gen_loss = 0.40671698184389815, disc_loss = 0.03931483124983252
Trained batch 380 in epoch 6, gen_loss = 0.40681155921593115, disc_loss = 0.03923693323065466
Trained batch 381 in epoch 6, gen_loss = 0.406704306602478, disc_loss = 0.0391488064681448
Trained batch 382 in epoch 6, gen_loss = 0.40656760047061014, disc_loss = 0.03906767726900158
Trained batch 383 in epoch 6, gen_loss = 0.4066671264978747, disc_loss = 0.03897907579145491
Trained batch 384 in epoch 6, gen_loss = 0.4067114605532064, disc_loss = 0.038925309891074705
Trained batch 385 in epoch 6, gen_loss = 0.4065122602825955, disc_loss = 0.03902426501555088
Trained batch 386 in epoch 6, gen_loss = 0.4066680987059916, disc_loss = 0.03934020204986963
Trained batch 387 in epoch 6, gen_loss = 0.4065764040215728, disc_loss = 0.03930641380054684
Trained batch 388 in epoch 6, gen_loss = 0.40651825698604926, disc_loss = 0.03925183491606581
Trained batch 389 in epoch 6, gen_loss = 0.4065859373563375, disc_loss = 0.03918562874687501
Trained batch 390 in epoch 6, gen_loss = 0.4065906230903343, disc_loss = 0.039167976043189466
Trained batch 391 in epoch 6, gen_loss = 0.4065918850959564, disc_loss = 0.0391289368254009
Trained batch 392 in epoch 6, gen_loss = 0.406931091659245, disc_loss = 0.04008680998949623
Trained batch 393 in epoch 6, gen_loss = 0.4068133629820674, disc_loss = 0.040371950959838775
Trained batch 394 in epoch 6, gen_loss = 0.4068207135683374, disc_loss = 0.04052691859358191
Trained batch 395 in epoch 6, gen_loss = 0.4068959927318072, disc_loss = 0.040742031814215346
Trained batch 396 in epoch 6, gen_loss = 0.4069318026679589, disc_loss = 0.04067711183339151
Trained batch 397 in epoch 6, gen_loss = 0.40681696297535347, disc_loss = 0.0406133835326796
Trained batch 398 in epoch 6, gen_loss = 0.4068701725107685, disc_loss = 0.04057806848436314
Trained batch 399 in epoch 6, gen_loss = 0.406877055093646, disc_loss = 0.0405086778459372
Trained batch 400 in epoch 6, gen_loss = 0.40679604075198755, disc_loss = 0.040468221793341405
Trained batch 401 in epoch 6, gen_loss = 0.4065117280726409, disc_loss = 0.040502581243236455
Trained batch 402 in epoch 6, gen_loss = 0.4065873808511729, disc_loss = 0.04049895844126476
Trained batch 403 in epoch 6, gen_loss = 0.4064462475552417, disc_loss = 0.0404222147143907
Trained batch 404 in epoch 6, gen_loss = 0.40640957811732353, disc_loss = 0.04050258448014013
Trained batch 405 in epoch 6, gen_loss = 0.40638874750125586, disc_loss = 0.04079754927982416
Trained batch 406 in epoch 6, gen_loss = 0.4062025216053393, disc_loss = 0.040754247377271915
Trained batch 407 in epoch 6, gen_loss = 0.4062262752330771, disc_loss = 0.0407019994460165
Trained batch 408 in epoch 6, gen_loss = 0.4062482463992895, disc_loss = 0.04062293244304914
Trained batch 409 in epoch 6, gen_loss = 0.4062487096321292, disc_loss = 0.040568986669659794
Trained batch 410 in epoch 6, gen_loss = 0.4061285164524459, disc_loss = 0.04074401624892768
Trained batch 411 in epoch 6, gen_loss = 0.4060805679380315, disc_loss = 0.041641310407233074
Trained batch 412 in epoch 6, gen_loss = 0.40611074067489866, disc_loss = 0.04171750859411537
Trained batch 413 in epoch 6, gen_loss = 0.40611034638927757, disc_loss = 0.04181610896186858
Trained batch 414 in epoch 6, gen_loss = 0.4061881644180022, disc_loss = 0.04182535645843719
Trained batch 415 in epoch 6, gen_loss = 0.406301826166992, disc_loss = 0.04175193767262569
Trained batch 416 in epoch 6, gen_loss = 0.4063181346126026, disc_loss = 0.04167257006418594
Trained batch 417 in epoch 6, gen_loss = 0.4062361395672748, disc_loss = 0.041593992419242325
Trained batch 418 in epoch 6, gen_loss = 0.4063053412056197, disc_loss = 0.041524047601572404
Trained batch 419 in epoch 6, gen_loss = 0.4061536944338254, disc_loss = 0.04144540746929124
Trained batch 420 in epoch 6, gen_loss = 0.4060736074158811, disc_loss = 0.04137743042611612
Trained batch 421 in epoch 6, gen_loss = 0.40610704002504666, disc_loss = 0.0413495283910422
Trained batch 422 in epoch 6, gen_loss = 0.40605483882252486, disc_loss = 0.04137164285465916
Trained batch 423 in epoch 6, gen_loss = 0.40611064054493634, disc_loss = 0.04153946224646204
Trained batch 424 in epoch 6, gen_loss = 0.4062200453702141, disc_loss = 0.04151067227837356
Trained batch 425 in epoch 6, gen_loss = 0.4062482140993288, disc_loss = 0.04154146925990028
Trained batch 426 in epoch 6, gen_loss = 0.40622358900043387, disc_loss = 0.041539519866579486
Trained batch 427 in epoch 6, gen_loss = 0.4060129373569355, disc_loss = 0.04151528699282191
Trained batch 428 in epoch 6, gen_loss = 0.4060567391641212, disc_loss = 0.04158952090474571
Trained batch 429 in epoch 6, gen_loss = 0.4061970238768777, disc_loss = 0.04151185764660409
Trained batch 430 in epoch 6, gen_loss = 0.4061296562169378, disc_loss = 0.041442301840112994
Trained batch 431 in epoch 6, gen_loss = 0.40593340696284064, disc_loss = 0.04139201352814713
Trained batch 432 in epoch 6, gen_loss = 0.405840510928328, disc_loss = 0.04131179356110856
Trained batch 433 in epoch 6, gen_loss = 0.40591820154321906, disc_loss = 0.04137895829505652
Trained batch 434 in epoch 6, gen_loss = 0.40581479387721797, disc_loss = 0.04168609705989131
Trained batch 435 in epoch 6, gen_loss = 0.4059141808693562, disc_loss = 0.04164117188331748
Trained batch 436 in epoch 6, gen_loss = 0.4060906465730078, disc_loss = 0.04162841894476327
Trained batch 437 in epoch 6, gen_loss = 0.4061568997221995, disc_loss = 0.041581314110801
Trained batch 438 in epoch 6, gen_loss = 0.40615517349069374, disc_loss = 0.04159642796133961
Trained batch 439 in epoch 6, gen_loss = 0.40602732707153666, disc_loss = 0.041533181981966746
Trained batch 440 in epoch 6, gen_loss = 0.40608449797241053, disc_loss = 0.04145688561526235
Trained batch 441 in epoch 6, gen_loss = 0.40622624181784117, disc_loss = 0.04137143244328424
Trained batch 442 in epoch 6, gen_loss = 0.40621309577745995, disc_loss = 0.04129184336027311
Trained batch 443 in epoch 6, gen_loss = 0.4062486063386943, disc_loss = 0.041227930955911846
Trained batch 444 in epoch 6, gen_loss = 0.405993765324689, disc_loss = 0.04120256976182625
Trained batch 445 in epoch 6, gen_loss = 0.4060717215051565, disc_loss = 0.04114163065623626
Trained batch 446 in epoch 6, gen_loss = 0.40603987122542107, disc_loss = 0.041475618746177494
Trained batch 447 in epoch 6, gen_loss = 0.4058870864765985, disc_loss = 0.041751501184210484
Trained batch 448 in epoch 6, gen_loss = 0.40606798254832926, disc_loss = 0.0417472359735751
Trained batch 449 in epoch 6, gen_loss = 0.40619633628262414, disc_loss = 0.0416691517100359
Trained batch 450 in epoch 6, gen_loss = 0.40610316845107236, disc_loss = 0.04160093240380006
Trained batch 451 in epoch 6, gen_loss = 0.40620661217027004, disc_loss = 0.04152784595395793
Trained batch 452 in epoch 6, gen_loss = 0.4062097334440707, disc_loss = 0.041460880285507234
Trained batch 453 in epoch 6, gen_loss = 0.4061349020524172, disc_loss = 0.04141053093324461
Trained batch 454 in epoch 6, gen_loss = 0.40617782519413875, disc_loss = 0.04134936374816839
Trained batch 455 in epoch 6, gen_loss = 0.40609908025515706, disc_loss = 0.04127993076179879
Trained batch 456 in epoch 6, gen_loss = 0.40619195120600693, disc_loss = 0.0412862716050089
Trained batch 457 in epoch 6, gen_loss = 0.40605762210475305, disc_loss = 0.04161029495451372
Trained batch 458 in epoch 6, gen_loss = 0.40605395753139506, disc_loss = 0.041935408209432284
Trained batch 459 in epoch 6, gen_loss = 0.4061617399039476, disc_loss = 0.04186336412853764
Trained batch 460 in epoch 6, gen_loss = 0.40621089870655613, disc_loss = 0.04190133966317647
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 0.41234299540519714, disc_loss = 0.01883636973798275
Trained batch 1 in epoch 7, gen_loss = 0.4212094396352768, disc_loss = 0.03592499438673258
Trained batch 2 in epoch 7, gen_loss = 0.3802228967348735, disc_loss = 0.04743998311460018
Trained batch 3 in epoch 7, gen_loss = 0.379243902862072, disc_loss = 0.03786119865253568
Trained batch 4 in epoch 7, gen_loss = 0.392001610994339, disc_loss = 0.035903820767998695
Trained batch 5 in epoch 7, gen_loss = 0.4002576023340225, disc_loss = 0.03401806578040123
Trained batch 6 in epoch 7, gen_loss = 0.40117980326925007, disc_loss = 0.03774833732417652
Trained batch 7 in epoch 7, gen_loss = 0.3859701007604599, disc_loss = 0.04803757881745696
Trained batch 8 in epoch 7, gen_loss = 0.394619666867786, disc_loss = 0.05597847658726904
Trained batch 9 in epoch 7, gen_loss = 0.3960136860609055, disc_loss = 0.05439777374267578
Trained batch 10 in epoch 7, gen_loss = 0.3964442258531397, disc_loss = 0.0500360565175387
Trained batch 11 in epoch 7, gen_loss = 0.4016015628973643, disc_loss = 0.046822358815309904
Trained batch 12 in epoch 7, gen_loss = 0.40031999120345485, disc_loss = 0.04382094995190318
Trained batch 13 in epoch 7, gen_loss = 0.39937599854809896, disc_loss = 0.04376706371216902
Trained batch 14 in epoch 7, gen_loss = 0.3995022634665171, disc_loss = 0.043890735724320014
Trained batch 15 in epoch 7, gen_loss = 0.3991442508995533, disc_loss = 0.04271242776303552
Trained batch 16 in epoch 7, gen_loss = 0.39978788530125337, disc_loss = 0.04290718659210731
Trained batch 17 in epoch 7, gen_loss = 0.40161480837398106, disc_loss = 0.04251504262598852
Trained batch 18 in epoch 7, gen_loss = 0.4012473900067179, disc_loss = 0.040968891404765215
Trained batch 19 in epoch 7, gen_loss = 0.40121201127767564, disc_loss = 0.03936723966617137
Trained batch 20 in epoch 7, gen_loss = 0.3975106789952233, disc_loss = 0.03985222369166357
Trained batch 21 in epoch 7, gen_loss = 0.4010142399506135, disc_loss = 0.04291194010610608
Trained batch 22 in epoch 7, gen_loss = 0.39868858456611633, disc_loss = 0.04686978275118315
Trained batch 23 in epoch 7, gen_loss = 0.4012147958079974, disc_loss = 0.0462551720168752
Trained batch 24 in epoch 7, gen_loss = 0.39995830178260805, disc_loss = 0.04945058653131127
Trained batch 25 in epoch 7, gen_loss = 0.3964546471834183, disc_loss = 0.052089349671195335
Trained batch 26 in epoch 7, gen_loss = 0.3957245040822912, disc_loss = 0.05145391444158223
Trained batch 27 in epoch 7, gen_loss = 0.39796915650367737, disc_loss = 0.05050250882881561
Trained batch 28 in epoch 7, gen_loss = 0.39936479206742914, disc_loss = 0.04900329177878026
Trained batch 29 in epoch 7, gen_loss = 0.39976224104563396, disc_loss = 0.04762050779536366
Trained batch 30 in epoch 7, gen_loss = 0.4000124940949102, disc_loss = 0.046272658953262914
Trained batch 31 in epoch 7, gen_loss = 0.40153107326477766, disc_loss = 0.045172556885518134
Trained batch 32 in epoch 7, gen_loss = 0.40469518303871155, disc_loss = 0.043986616896070314
Trained batch 33 in epoch 7, gen_loss = 0.4063109378604328, disc_loss = 0.04290157477097476
Trained batch 34 in epoch 7, gen_loss = 0.40542916314942495, disc_loss = 0.04177794086613825
Trained batch 35 in epoch 7, gen_loss = 0.40459802995125455, disc_loss = 0.0409085921322306
Trained batch 36 in epoch 7, gen_loss = 0.4048125679428513, disc_loss = 0.040284887761683076
Trained batch 37 in epoch 7, gen_loss = 0.4025672352627704, disc_loss = 0.03962064409432443
Trained batch 38 in epoch 7, gen_loss = 0.40192877711393893, disc_loss = 0.038783383675110646
Trained batch 39 in epoch 7, gen_loss = 0.403686610609293, disc_loss = 0.03863651854917407
Trained batch 40 in epoch 7, gen_loss = 0.40427419543266296, disc_loss = 0.039323476665630575
Trained batch 41 in epoch 7, gen_loss = 0.40280909552460625, disc_loss = 0.04003836879772799
Trained batch 42 in epoch 7, gen_loss = 0.4039946177671122, disc_loss = 0.03955317370940086
Trained batch 43 in epoch 7, gen_loss = 0.4051640656861392, disc_loss = 0.038974223362112585
Trained batch 44 in epoch 7, gen_loss = 0.4066295292642381, disc_loss = 0.03837288460797734
Trained batch 45 in epoch 7, gen_loss = 0.40606491980345355, disc_loss = 0.03961502687762613
Trained batch 46 in epoch 7, gen_loss = 0.4051571082561574, disc_loss = 0.04075795007829971
Trained batch 47 in epoch 7, gen_loss = 0.40482470641533536, disc_loss = 0.04018624448993554
Trained batch 48 in epoch 7, gen_loss = 0.4053515895288818, disc_loss = 0.039485368022353064
Trained batch 49 in epoch 7, gen_loss = 0.4053516465425491, disc_loss = 0.038888596575707195
Trained batch 50 in epoch 7, gen_loss = 0.40586526721131566, disc_loss = 0.03849118248577796
Trained batch 51 in epoch 7, gen_loss = 0.40609976706596523, disc_loss = 0.03886601667349728
Trained batch 52 in epoch 7, gen_loss = 0.406674454796989, disc_loss = 0.038353960978675564
Trained batch 53 in epoch 7, gen_loss = 0.4070970725130152, disc_loss = 0.038252637083469716
Trained batch 54 in epoch 7, gen_loss = 0.4077164216475053, disc_loss = 0.03778510418805209
Trained batch 55 in epoch 7, gen_loss = 0.4085420295596123, disc_loss = 0.03732681281066367
Trained batch 56 in epoch 7, gen_loss = 0.4088970260661945, disc_loss = 0.03682253903529623
Trained batch 57 in epoch 7, gen_loss = 0.4079985495271354, disc_loss = 0.03627936115713212
Trained batch 58 in epoch 7, gen_loss = 0.4086068828227156, disc_loss = 0.035760819525221144
Trained batch 59 in epoch 7, gen_loss = 0.40758642653624216, disc_loss = 0.03525705999539544
Trained batch 60 in epoch 7, gen_loss = 0.4083168193942211, disc_loss = 0.03476793262496835
Trained batch 61 in epoch 7, gen_loss = 0.4086256589620344, disc_loss = 0.03467305639999047
Trained batch 62 in epoch 7, gen_loss = 0.40892501340972054, disc_loss = 0.03461972297361446
Trained batch 63 in epoch 7, gen_loss = 0.4100100132636726, disc_loss = 0.0372484421095578
Trained batch 64 in epoch 7, gen_loss = 0.40867648674891544, disc_loss = 0.03828035929741768
Trained batch 65 in epoch 7, gen_loss = 0.4086192485057946, disc_loss = 0.03782867449759082
Trained batch 66 in epoch 7, gen_loss = 0.40859534580316115, disc_loss = 0.03742483315238757
Trained batch 67 in epoch 7, gen_loss = 0.4084409659399706, disc_loss = 0.03723839148605133
Trained batch 68 in epoch 7, gen_loss = 0.4080415337845899, disc_loss = 0.03697414238653753
Trained batch 69 in epoch 7, gen_loss = 0.4086208185979298, disc_loss = 0.03658299907775862
Trained batch 70 in epoch 7, gen_loss = 0.40904484542322833, disc_loss = 0.0361271838421448
Trained batch 71 in epoch 7, gen_loss = 0.40889814413256115, disc_loss = 0.03570153231137536
Trained batch 72 in epoch 7, gen_loss = 0.4081140809679685, disc_loss = 0.03538283591528665
Trained batch 73 in epoch 7, gen_loss = 0.4076053999565743, disc_loss = 0.03501195556836555
Trained batch 74 in epoch 7, gen_loss = 0.40769005378087364, disc_loss = 0.034668273360778885
Trained batch 75 in epoch 7, gen_loss = 0.4084632275135894, disc_loss = 0.03425512930047453
Trained batch 76 in epoch 7, gen_loss = 0.4084703960976043, disc_loss = 0.03385575838967577
Trained batch 77 in epoch 7, gen_loss = 0.40850893197915494, disc_loss = 0.033466096594332695
Trained batch 78 in epoch 7, gen_loss = 0.4083451979522464, disc_loss = 0.03308748385185211
Trained batch 79 in epoch 7, gen_loss = 0.40849512852728365, disc_loss = 0.03270363656047266
Trained batch 80 in epoch 7, gen_loss = 0.4087827820100902, disc_loss = 0.032330873120507156
Trained batch 81 in epoch 7, gen_loss = 0.4094307880576064, disc_loss = 0.032002507018992994
Trained batch 82 in epoch 7, gen_loss = 0.4100020064646939, disc_loss = 0.031667250979983484
Trained batch 83 in epoch 7, gen_loss = 0.4100443777583894, disc_loss = 0.031399540356471245
Trained batch 84 in epoch 7, gen_loss = 0.409369216596379, disc_loss = 0.031093321299618656
Trained batch 85 in epoch 7, gen_loss = 0.40882558150346887, disc_loss = 0.03078322581199626
Trained batch 86 in epoch 7, gen_loss = 0.40862447023391724, disc_loss = 0.030471406424760646
Trained batch 87 in epoch 7, gen_loss = 0.4086226336658001, disc_loss = 0.030200728979914195
Trained batch 88 in epoch 7, gen_loss = 0.40775647290636985, disc_loss = 0.030428260985992096
Trained batch 89 in epoch 7, gen_loss = 0.4076981378926171, disc_loss = 0.030892370643818542
Trained batch 90 in epoch 7, gen_loss = 0.4083361609296484, disc_loss = 0.030789823857248648
Trained batch 91 in epoch 7, gen_loss = 0.4083004496667696, disc_loss = 0.03278529518739442
Trained batch 92 in epoch 7, gen_loss = 0.40851506302433627, disc_loss = 0.033374771037669754
Trained batch 93 in epoch 7, gen_loss = 0.40915253821839676, disc_loss = 0.03344756947642073
Trained batch 94 in epoch 7, gen_loss = 0.40921392378054167, disc_loss = 0.033854651257493776
Trained batch 95 in epoch 7, gen_loss = 0.40952784319718677, disc_loss = 0.03359310887996495
Trained batch 96 in epoch 7, gen_loss = 0.40984751176588313, disc_loss = 0.03372611094160562
Trained batch 97 in epoch 7, gen_loss = 0.40930175629197335, disc_loss = 0.03390214748309963
Trained batch 98 in epoch 7, gen_loss = 0.40953593663494997, disc_loss = 0.033674097114308466
Trained batch 99 in epoch 7, gen_loss = 0.4103254383802414, disc_loss = 0.033903774612117556
Trained batch 100 in epoch 7, gen_loss = 0.40942768826343046, disc_loss = 0.034430582475120035
Trained batch 101 in epoch 7, gen_loss = 0.4089941794381422, disc_loss = 0.03424895807927219
Trained batch 102 in epoch 7, gen_loss = 0.4088100634732293, disc_loss = 0.03458022547985237
Trained batch 103 in epoch 7, gen_loss = 0.408987446473195, disc_loss = 0.03436917094558549
Trained batch 104 in epoch 7, gen_loss = 0.40864933814321247, disc_loss = 0.03439818541962831
Trained batch 105 in epoch 7, gen_loss = 0.40901368490929874, disc_loss = 0.03414515052034678
Trained batch 106 in epoch 7, gen_loss = 0.4097198493012758, disc_loss = 0.033929396118255004
Trained batch 107 in epoch 7, gen_loss = 0.4102813082712668, disc_loss = 0.03369429987139517
Trained batch 108 in epoch 7, gen_loss = 0.41038674116134644, disc_loss = 0.03344094908984224
Trained batch 109 in epoch 7, gen_loss = 0.4096004738049074, disc_loss = 0.03319822997066446
Trained batch 110 in epoch 7, gen_loss = 0.4090526466434066, disc_loss = 0.03293890132870827
Trained batch 111 in epoch 7, gen_loss = 0.4088430854358843, disc_loss = 0.03331612838207677
Trained batch 112 in epoch 7, gen_loss = 0.40912736174279607, disc_loss = 0.03618252240492245
Trained batch 113 in epoch 7, gen_loss = 0.4086317289293858, disc_loss = 0.03633836551626589
Trained batch 114 in epoch 7, gen_loss = 0.40841841853183247, disc_loss = 0.0361380238916077
Trained batch 115 in epoch 7, gen_loss = 0.40816599130630493, disc_loss = 0.03591170842992142
Trained batch 116 in epoch 7, gen_loss = 0.40849722577975345, disc_loss = 0.035766786969322555
Trained batch 117 in epoch 7, gen_loss = 0.40778518556538274, disc_loss = 0.035618379272094346
Trained batch 118 in epoch 7, gen_loss = 0.40745948793507425, disc_loss = 0.035445512955257
Trained batch 119 in epoch 7, gen_loss = 0.40698763728141785, disc_loss = 0.03527491314841124
Trained batch 120 in epoch 7, gen_loss = 0.40670639153354426, disc_loss = 0.03511819780865792
Trained batch 121 in epoch 7, gen_loss = 0.40654310461927634, disc_loss = 0.0348875113766732
Trained batch 122 in epoch 7, gen_loss = 0.40599399441626016, disc_loss = 0.03499145006450514
Trained batch 123 in epoch 7, gen_loss = 0.40618456635744343, disc_loss = 0.036717960552778095
Trained batch 124 in epoch 7, gen_loss = 0.40630773949623106, disc_loss = 0.04003555548377335
Trained batch 125 in epoch 7, gen_loss = 0.4072540934596743, disc_loss = 0.040450970984123175
Trained batch 126 in epoch 7, gen_loss = 0.4078463224444802, disc_loss = 0.04048057631076145
Trained batch 127 in epoch 7, gen_loss = 0.4072511082049459, disc_loss = 0.04051230105869763
Trained batch 128 in epoch 7, gen_loss = 0.40676214644151143, disc_loss = 0.040909704053774476
Trained batch 129 in epoch 7, gen_loss = 0.40627018625919636, disc_loss = 0.04205780920680039
Trained batch 130 in epoch 7, gen_loss = 0.4056681217128084, disc_loss = 0.04200517542781095
Trained batch 131 in epoch 7, gen_loss = 0.4049891357620557, disc_loss = 0.04253642117273006
Trained batch 132 in epoch 7, gen_loss = 0.4057072291248723, disc_loss = 0.043395611158172996
Trained batch 133 in epoch 7, gen_loss = 0.4052217391444676, disc_loss = 0.043515429208263644
Trained batch 134 in epoch 7, gen_loss = 0.4047800419507203, disc_loss = 0.04328203900303278
Trained batch 135 in epoch 7, gen_loss = 0.4051414101439364, disc_loss = 0.04304836774826981
Trained batch 136 in epoch 7, gen_loss = 0.4050894640658024, disc_loss = 0.04282005544051691
Trained batch 137 in epoch 7, gen_loss = 0.4046855156404385, disc_loss = 0.04260717581559405
Trained batch 138 in epoch 7, gen_loss = 0.4038726310078189, disc_loss = 0.04300843855439813
Trained batch 139 in epoch 7, gen_loss = 0.4044777423143387, disc_loss = 0.042905671809733446
Trained batch 140 in epoch 7, gen_loss = 0.4045460883607256, disc_loss = 0.04309644203481152
Trained batch 141 in epoch 7, gen_loss = 0.4038462263177818, disc_loss = 0.043085941856294135
Trained batch 142 in epoch 7, gen_loss = 0.40425600476198265, disc_loss = 0.04290170805574349
Trained batch 143 in epoch 7, gen_loss = 0.40436912038260037, disc_loss = 0.042658430984981045
Trained batch 144 in epoch 7, gen_loss = 0.4045791056649438, disc_loss = 0.04240926353357218
Trained batch 145 in epoch 7, gen_loss = 0.4044202157895859, disc_loss = 0.04218980081360277
Trained batch 146 in epoch 7, gen_loss = 0.40427732001356526, disc_loss = 0.042115565219919396
Trained batch 147 in epoch 7, gen_loss = 0.40425294577269943, disc_loss = 0.04206644938283323
Trained batch 148 in epoch 7, gen_loss = 0.40421159515444866, disc_loss = 0.04218453909708
Trained batch 149 in epoch 7, gen_loss = 0.40467391987641654, disc_loss = 0.04302641531607757
Trained batch 150 in epoch 7, gen_loss = 0.40506657819874237, disc_loss = 0.042790252186468994
Trained batch 151 in epoch 7, gen_loss = 0.40479257369512006, disc_loss = 0.04335528017959165
Trained batch 152 in epoch 7, gen_loss = 0.4054430284920861, disc_loss = 0.043190270907312533
Trained batch 153 in epoch 7, gen_loss = 0.4052258695100809, disc_loss = 0.04391667725935627
Trained batch 154 in epoch 7, gen_loss = 0.40498519405241934, disc_loss = 0.04374326473672784
Trained batch 155 in epoch 7, gen_loss = 0.40471174663458115, disc_loss = 0.04374262849495818
Trained batch 156 in epoch 7, gen_loss = 0.40373163769958886, disc_loss = 0.04429523149878973
Trained batch 157 in epoch 7, gen_loss = 0.4034173343377777, disc_loss = 0.04432137943715848
Trained batch 158 in epoch 7, gen_loss = 0.40289690715711823, disc_loss = 0.04430131423404241
Trained batch 159 in epoch 7, gen_loss = 0.403240174241364, disc_loss = 0.04425395593425492
Trained batch 160 in epoch 7, gen_loss = 0.40303569402753936, disc_loss = 0.0443048755889932
Trained batch 161 in epoch 7, gen_loss = 0.4025962520160793, disc_loss = 0.0444697541900462
Trained batch 162 in epoch 7, gen_loss = 0.4018961320991165, disc_loss = 0.04526180295313657
Trained batch 163 in epoch 7, gen_loss = 0.4022957237391937, disc_loss = 0.047214306085995146
Trained batch 164 in epoch 7, gen_loss = 0.4020233847878196, disc_loss = 0.04718257348109601
Trained batch 165 in epoch 7, gen_loss = 0.4017811943608594, disc_loss = 0.047372784388408695
Trained batch 166 in epoch 7, gen_loss = 0.4021585779989551, disc_loss = 0.047859305093444125
Trained batch 167 in epoch 7, gen_loss = 0.4020684741082646, disc_loss = 0.04774046580756216
Trained batch 168 in epoch 7, gen_loss = 0.40162371231254035, disc_loss = 0.0477124684718961
Trained batch 169 in epoch 7, gen_loss = 0.40142817199230196, disc_loss = 0.04755273634595249
Trained batch 170 in epoch 7, gen_loss = 0.40171302637161566, disc_loss = 0.04733325287901213
Trained batch 171 in epoch 7, gen_loss = 0.4016707454656446, disc_loss = 0.04712029628396078
Trained batch 172 in epoch 7, gen_loss = 0.40139430606296295, disc_loss = 0.047181732496354364
Trained batch 173 in epoch 7, gen_loss = 0.4020375230874138, disc_loss = 0.04770236661063571
Trained batch 174 in epoch 7, gen_loss = 0.40218581131526404, disc_loss = 0.04746889454578715
Trained batch 175 in epoch 7, gen_loss = 0.40187896889719094, disc_loss = 0.047542582939389504
Trained batch 176 in epoch 7, gen_loss = 0.4020906289418538, disc_loss = 0.04731166744894101
Trained batch 177 in epoch 7, gen_loss = 0.40215044677927253, disc_loss = 0.04733356543727679
Trained batch 178 in epoch 7, gen_loss = 0.4019276489758625, disc_loss = 0.04722308374904929
Trained batch 179 in epoch 7, gen_loss = 0.40168852574295466, disc_loss = 0.04708939590103303
Trained batch 180 in epoch 7, gen_loss = 0.40207907063526344, disc_loss = 0.04693689576134045
Trained batch 181 in epoch 7, gen_loss = 0.4020055825566197, disc_loss = 0.046713121835357294
Trained batch 182 in epoch 7, gen_loss = 0.4016495259081731, disc_loss = 0.0467699215368271
Trained batch 183 in epoch 7, gen_loss = 0.4009663482075152, disc_loss = 0.04937827162591376
Trained batch 184 in epoch 7, gen_loss = 0.40130783545004356, disc_loss = 0.04940182035663039
Trained batch 185 in epoch 7, gen_loss = 0.40143255905438496, disc_loss = 0.04937890424988964
Trained batch 186 in epoch 7, gen_loss = 0.401051961961277, disc_loss = 0.04930745233174035
Trained batch 187 in epoch 7, gen_loss = 0.4010229473735424, disc_loss = 0.049299615956694284
Trained batch 188 in epoch 7, gen_loss = 0.4009019495948913, disc_loss = 0.04946929751156223
Trained batch 189 in epoch 7, gen_loss = 0.4008997876393168, disc_loss = 0.04986736396646225
Trained batch 190 in epoch 7, gen_loss = 0.400716601866078, disc_loss = 0.050295014642617854
Trained batch 191 in epoch 7, gen_loss = 0.40070117885867756, disc_loss = 0.05010772912282846
Trained batch 192 in epoch 7, gen_loss = 0.40046266524285234, disc_loss = 0.05004508934861985
Trained batch 193 in epoch 7, gen_loss = 0.40047970245179443, disc_loss = 0.0498155157007373
Trained batch 194 in epoch 7, gen_loss = 0.4000053312533941, disc_loss = 0.04959762835373672
Trained batch 195 in epoch 7, gen_loss = 0.3997623727333789, disc_loss = 0.04939241658501821
Trained batch 196 in epoch 7, gen_loss = 0.39960126556115705, disc_loss = 0.049171719148159404
Trained batch 197 in epoch 7, gen_loss = 0.39956399256532843, disc_loss = 0.04901692248302314
Trained batch 198 in epoch 7, gen_loss = 0.39949303071702547, disc_loss = 0.0488943369490511
Trained batch 199 in epoch 7, gen_loss = 0.3994792956113815, disc_loss = 0.049065927328774704
Trained batch 200 in epoch 7, gen_loss = 0.39959649141155074, disc_loss = 0.049762958379239955
Trained batch 201 in epoch 7, gen_loss = 0.39976800771633, disc_loss = 0.04969009032846419
Trained batch 202 in epoch 7, gen_loss = 0.39948354228376753, disc_loss = 0.04958811373532442
Trained batch 203 in epoch 7, gen_loss = 0.39963285537327037, disc_loss = 0.04939750021017686
Trained batch 204 in epoch 7, gen_loss = 0.3990323183013172, disc_loss = 0.04968406959300543
Trained batch 205 in epoch 7, gen_loss = 0.39882938231079323, disc_loss = 0.049966658290376144
Trained batch 206 in epoch 7, gen_loss = 0.3989444717692868, disc_loss = 0.049813923607062965
Trained batch 207 in epoch 7, gen_loss = 0.39881591269603145, disc_loss = 0.04964037675773188
Trained batch 208 in epoch 7, gen_loss = 0.3988540888403021, disc_loss = 0.049538344279617855
Trained batch 209 in epoch 7, gen_loss = 0.398751932098752, disc_loss = 0.04932353500210281
Trained batch 210 in epoch 7, gen_loss = 0.39832957576236455, disc_loss = 0.04915968372080457
Trained batch 211 in epoch 7, gen_loss = 0.39872027975770663, disc_loss = 0.049005725720835815
Trained batch 212 in epoch 7, gen_loss = 0.3990649969924783, disc_loss = 0.048898584337275425
Trained batch 213 in epoch 7, gen_loss = 0.3989378131717165, disc_loss = 0.04915332714221919
Trained batch 214 in epoch 7, gen_loss = 0.3991792958836223, disc_loss = 0.049061347467305005
Trained batch 215 in epoch 7, gen_loss = 0.3994689064997214, disc_loss = 0.04890871950084585
Trained batch 216 in epoch 7, gen_loss = 0.39963054286170113, disc_loss = 0.04877959724090787
Trained batch 217 in epoch 7, gen_loss = 0.39978825034351523, disc_loss = 0.04858438749135463
Trained batch 218 in epoch 7, gen_loss = 0.3997380888625367, disc_loss = 0.04840086145670957
Trained batch 219 in epoch 7, gen_loss = 0.39990197108550507, disc_loss = 0.04823713157728145
Trained batch 220 in epoch 7, gen_loss = 0.39988697047147276, disc_loss = 0.048181215957506685
Trained batch 221 in epoch 7, gen_loss = 0.3996507039478233, disc_loss = 0.048028073008256116
Trained batch 222 in epoch 7, gen_loss = 0.39936632238695974, disc_loss = 0.04787080902334787
Trained batch 223 in epoch 7, gen_loss = 0.39983488539499895, disc_loss = 0.0477509646391679
Trained batch 224 in epoch 7, gen_loss = 0.39969557219081453, disc_loss = 0.047808342752978204
Trained batch 225 in epoch 7, gen_loss = 0.3994802903812543, disc_loss = 0.04768218933625262
Trained batch 226 in epoch 7, gen_loss = 0.3992932492678386, disc_loss = 0.04756190326979737
Trained batch 227 in epoch 7, gen_loss = 0.39981254085636975, disc_loss = 0.04747383160365484
Trained batch 228 in epoch 7, gen_loss = 0.40005282556646254, disc_loss = 0.04731073791230317
Trained batch 229 in epoch 7, gen_loss = 0.40034955739974976, disc_loss = 0.0472053182301233
Trained batch 230 in epoch 7, gen_loss = 0.40022598303757706, disc_loss = 0.04708015419909674
Trained batch 231 in epoch 7, gen_loss = 0.40033130399112044, disc_loss = 0.047030298772934374
Trained batch 232 in epoch 7, gen_loss = 0.4002277609360576, disc_loss = 0.0468655628274103
Trained batch 233 in epoch 7, gen_loss = 0.4003248677039758, disc_loss = 0.04671920295386838
Trained batch 234 in epoch 7, gen_loss = 0.40038474100701354, disc_loss = 0.04654088823937197
Trained batch 235 in epoch 7, gen_loss = 0.40057442804514354, disc_loss = 0.04639590974656423
Trained batch 236 in epoch 7, gen_loss = 0.40084107415082587, disc_loss = 0.04622122803251043
Trained batch 237 in epoch 7, gen_loss = 0.4009947111877073, disc_loss = 0.04607627239810037
Trained batch 238 in epoch 7, gen_loss = 0.400834902559863, disc_loss = 0.04589824962125756
Trained batch 239 in epoch 7, gen_loss = 0.4008415311574936, disc_loss = 0.04573732058148986
Trained batch 240 in epoch 7, gen_loss = 0.4010062387128094, disc_loss = 0.04571935567807762
Trained batch 241 in epoch 7, gen_loss = 0.40057211818773886, disc_loss = 0.046305152526979663
Trained batch 242 in epoch 7, gen_loss = 0.4008602934119142, disc_loss = 0.04759163635690915
Trained batch 243 in epoch 7, gen_loss = 0.4007751365176967, disc_loss = 0.04751872478270537
Trained batch 244 in epoch 7, gen_loss = 0.40073768764126055, disc_loss = 0.04753945818912162
Trained batch 245 in epoch 7, gen_loss = 0.4007310297915606, disc_loss = 0.047392671217013724
Trained batch 246 in epoch 7, gen_loss = 0.400841337104558, disc_loss = 0.04732694314804064
Trained batch 247 in epoch 7, gen_loss = 0.4009709022939205, disc_loss = 0.04754605337380311
Trained batch 248 in epoch 7, gen_loss = 0.40080441420815555, disc_loss = 0.048884066480986144
Trained batch 249 in epoch 7, gen_loss = 0.40068993663787844, disc_loss = 0.04916098634246737
Trained batch 250 in epoch 7, gen_loss = 0.400939545902123, disc_loss = 0.04971394860890668
Trained batch 251 in epoch 7, gen_loss = 0.4008785195293881, disc_loss = 0.050248129538164314
Trained batch 252 in epoch 7, gen_loss = 0.401054581163429, disc_loss = 0.050478794778560994
Trained batch 253 in epoch 7, gen_loss = 0.40093234908862374, disc_loss = 0.05051288274978471
Trained batch 254 in epoch 7, gen_loss = 0.4009088633107204, disc_loss = 0.05054924836583143
Trained batch 255 in epoch 7, gen_loss = 0.4008957239566371, disc_loss = 0.05071114964903245
Trained batch 256 in epoch 7, gen_loss = 0.4010296585726831, disc_loss = 0.050755631476676936
Trained batch 257 in epoch 7, gen_loss = 0.4009318051412124, disc_loss = 0.050604292495688784
Trained batch 258 in epoch 7, gen_loss = 0.4005691954528043, disc_loss = 0.05050202664868856
Trained batch 259 in epoch 7, gen_loss = 0.4005270781425329, disc_loss = 0.05034276703462148
Trained batch 260 in epoch 7, gen_loss = 0.4009574201828675, disc_loss = 0.05025525025084929
Trained batch 261 in epoch 7, gen_loss = 0.4008590249159864, disc_loss = 0.05009884420046512
Trained batch 262 in epoch 7, gen_loss = 0.4007688299558009, disc_loss = 0.0499744190924762
Trained batch 263 in epoch 7, gen_loss = 0.40061750116221834, disc_loss = 0.04981612917265121
Trained batch 264 in epoch 7, gen_loss = 0.40035627135690655, disc_loss = 0.04991763369883147
Trained batch 265 in epoch 7, gen_loss = 0.40086454130653154, disc_loss = 0.05051405874301532
Trained batch 266 in epoch 7, gen_loss = 0.40065723177645535, disc_loss = 0.05065552441818354
Trained batch 267 in epoch 7, gen_loss = 0.400671061295182, disc_loss = 0.05050375797775394
Trained batch 268 in epoch 7, gen_loss = 0.40099630258340374, disc_loss = 0.05036004958587757
Trained batch 269 in epoch 7, gen_loss = 0.40117898958700676, disc_loss = 0.05025818014465686
Trained batch 270 in epoch 7, gen_loss = 0.40152490270973573, disc_loss = 0.0501160021103245
Trained batch 271 in epoch 7, gen_loss = 0.4016450345516205, disc_loss = 0.050063650867634674
Trained batch 272 in epoch 7, gen_loss = 0.4016031154564449, disc_loss = 0.05005111160940549
Trained batch 273 in epoch 7, gen_loss = 0.40178703261117865, disc_loss = 0.049887329920358194
Trained batch 274 in epoch 7, gen_loss = 0.40201543873006645, disc_loss = 0.04973438398658552
Trained batch 275 in epoch 7, gen_loss = 0.40186927078858664, disc_loss = 0.04967496501184001
Trained batch 276 in epoch 7, gen_loss = 0.40197379892483515, disc_loss = 0.049746694334947404
Trained batch 277 in epoch 7, gen_loss = 0.40171084665566037, disc_loss = 0.049608085608518544
Trained batch 278 in epoch 7, gen_loss = 0.4015478709692596, disc_loss = 0.0503284804694902
Trained batch 279 in epoch 7, gen_loss = 0.40099817748580663, disc_loss = 0.050923585847652116
Trained batch 280 in epoch 7, gen_loss = 0.4011824700543889, disc_loss = 0.051193894078504304
Trained batch 281 in epoch 7, gen_loss = 0.40154671912074935, disc_loss = 0.051100063351551005
Trained batch 282 in epoch 7, gen_loss = 0.401534007105305, disc_loss = 0.051048559530773086
Trained batch 283 in epoch 7, gen_loss = 0.4018893228240416, disc_loss = 0.05095229430606221
Trained batch 284 in epoch 7, gen_loss = 0.40218491836598047, disc_loss = 0.050898550989171655
Trained batch 285 in epoch 7, gen_loss = 0.4022241875633493, disc_loss = 0.0507802626442073
Trained batch 286 in epoch 7, gen_loss = 0.4021349849393559, disc_loss = 0.05090065430509063
Trained batch 287 in epoch 7, gen_loss = 0.4025379188565744, disc_loss = 0.05213433100774031
Trained batch 288 in epoch 7, gen_loss = 0.4023528127934281, disc_loss = 0.05223452537256103
Trained batch 289 in epoch 7, gen_loss = 0.4022796457183772, disc_loss = 0.05238573643908804
Trained batch 290 in epoch 7, gen_loss = 0.4023387580597933, disc_loss = 0.05226207599027844
Trained batch 291 in epoch 7, gen_loss = 0.40245334385600806, disc_loss = 0.05212299064461984
Trained batch 292 in epoch 7, gen_loss = 0.4023228406702699, disc_loss = 0.05197259687036657
Trained batch 293 in epoch 7, gen_loss = 0.40216008670070547, disc_loss = 0.05181085031565127
Trained batch 294 in epoch 7, gen_loss = 0.40210791856555617, disc_loss = 0.051662974200858656
Trained batch 295 in epoch 7, gen_loss = 0.4020614943190201, disc_loss = 0.05153231834599471
Trained batch 296 in epoch 7, gen_loss = 0.4023805822587575, disc_loss = 0.05139987269394501
Trained batch 297 in epoch 7, gen_loss = 0.40254385949381244, disc_loss = 0.05124600087808157
Trained batch 298 in epoch 7, gen_loss = 0.40272016379745507, disc_loss = 0.05110239503472221
Trained batch 299 in epoch 7, gen_loss = 0.4027565035223961, disc_loss = 0.05095274547347799
Trained batch 300 in epoch 7, gen_loss = 0.4027326466435214, disc_loss = 0.05083074530453554
Trained batch 301 in epoch 7, gen_loss = 0.40279809193105887, disc_loss = 0.0507151490556915
Trained batch 302 in epoch 7, gen_loss = 0.40286312058027035, disc_loss = 0.050579509955274535
Trained batch 303 in epoch 7, gen_loss = 0.4030666001337139, disc_loss = 0.05048517690049362
Trained batch 304 in epoch 7, gen_loss = 0.40313446101595146, disc_loss = 0.050355009101789264
Trained batch 305 in epoch 7, gen_loss = 0.4035025485395606, disc_loss = 0.05029240799869952
Trained batch 306 in epoch 7, gen_loss = 0.4035722354141819, disc_loss = 0.05017348337260224
Trained batch 307 in epoch 7, gen_loss = 0.40336294365780695, disc_loss = 0.05012539262178826
Trained batch 308 in epoch 7, gen_loss = 0.4033435597581771, disc_loss = 0.0501336661102642
Trained batch 309 in epoch 7, gen_loss = 0.4032273228130033, disc_loss = 0.050043846705117294
Trained batch 310 in epoch 7, gen_loss = 0.40313137871276145, disc_loss = 0.04991326071666344
Trained batch 311 in epoch 7, gen_loss = 0.4033218825665804, disc_loss = 0.04979596628123918
Trained batch 312 in epoch 7, gen_loss = 0.403301796307579, disc_loss = 0.049667945354076
Trained batch 313 in epoch 7, gen_loss = 0.40314951643442654, disc_loss = 0.049544711836767945
Trained batch 314 in epoch 7, gen_loss = 0.4028319621843005, disc_loss = 0.049465653426679114
Trained batch 315 in epoch 7, gen_loss = 0.40283572126792955, disc_loss = 0.049333591555699094
Trained batch 316 in epoch 7, gen_loss = 0.40291646160537886, disc_loss = 0.049197306808771726
Trained batch 317 in epoch 7, gen_loss = 0.4029303746965696, disc_loss = 0.04912646046221701
Trained batch 318 in epoch 7, gen_loss = 0.4029706112082849, disc_loss = 0.04907791702395019
Trained batch 319 in epoch 7, gen_loss = 0.403114874754101, disc_loss = 0.04895181206738926
Trained batch 320 in epoch 7, gen_loss = 0.40330223567389256, disc_loss = 0.04882896171862439
Trained batch 321 in epoch 7, gen_loss = 0.4032112663577062, disc_loss = 0.04870157747786862
Trained batch 322 in epoch 7, gen_loss = 0.40332269705486, disc_loss = 0.04856955396637159
Trained batch 323 in epoch 7, gen_loss = 0.40329229831695557, disc_loss = 0.04854613301605791
Trained batch 324 in epoch 7, gen_loss = 0.40361320128807654, disc_loss = 0.04874142594563846
Trained batch 325 in epoch 7, gen_loss = 0.4034383988087894, disc_loss = 0.04873125808687732
Trained batch 326 in epoch 7, gen_loss = 0.4033111507010387, disc_loss = 0.048846932936214844
Trained batch 327 in epoch 7, gen_loss = 0.40356541933809836, disc_loss = 0.048959613260216785
Trained batch 328 in epoch 7, gen_loss = 0.40353334629426973, disc_loss = 0.04884710227914924
Trained batch 329 in epoch 7, gen_loss = 0.4038179179935744, disc_loss = 0.04872835831307439
Trained batch 330 in epoch 7, gen_loss = 0.40391368142067485, disc_loss = 0.048605208990679
Trained batch 331 in epoch 7, gen_loss = 0.4040526022394019, disc_loss = 0.04847093387885602
Trained batch 332 in epoch 7, gen_loss = 0.40389329857296413, disc_loss = 0.04834053396840241
Trained batch 333 in epoch 7, gen_loss = 0.403741185268956, disc_loss = 0.04829525869426145
Trained batch 334 in epoch 7, gen_loss = 0.40392071595832485, disc_loss = 0.04829341108604932
Trained batch 335 in epoch 7, gen_loss = 0.40385024276162895, disc_loss = 0.04863102408056702
Trained batch 336 in epoch 7, gen_loss = 0.40383752013172525, disc_loss = 0.049774638821373667
Trained batch 337 in epoch 7, gen_loss = 0.4038424164762158, disc_loss = 0.04988107900755182
Trained batch 338 in epoch 7, gen_loss = 0.4036155302615996, disc_loss = 0.05015546694373201
Trained batch 339 in epoch 7, gen_loss = 0.4036400068332167, disc_loss = 0.05045722429298193
Trained batch 340 in epoch 7, gen_loss = 0.40354653283997366, disc_loss = 0.050449973184620835
Trained batch 341 in epoch 7, gen_loss = 0.40371080588179026, disc_loss = 0.05040785244309305
Trained batch 342 in epoch 7, gen_loss = 0.4036812601562144, disc_loss = 0.05035726603259042
Trained batch 343 in epoch 7, gen_loss = 0.403738112037265, disc_loss = 0.05026892181093328
Trained batch 344 in epoch 7, gen_loss = 0.4035596739554751, disc_loss = 0.05039578072011363
Trained batch 345 in epoch 7, gen_loss = 0.4037028741457559, disc_loss = 0.051736067662236276
Trained batch 346 in epoch 7, gen_loss = 0.4037769379292854, disc_loss = 0.05200879821642396
Trained batch 347 in epoch 7, gen_loss = 0.4036584845048258, disc_loss = 0.05300378303201441
Trained batch 348 in epoch 7, gen_loss = 0.403793079719844, disc_loss = 0.05347242490735364
Trained batch 349 in epoch 7, gen_loss = 0.4035049306494849, disc_loss = 0.05401808338971543
Trained batch 350 in epoch 7, gen_loss = 0.403622450567039, disc_loss = 0.05426868805303597
Trained batch 351 in epoch 7, gen_loss = 0.4034310955215584, disc_loss = 0.054392395715033424
Trained batch 352 in epoch 7, gen_loss = 0.4032240640846933, disc_loss = 0.054456895944812775
Trained batch 353 in epoch 7, gen_loss = 0.4032817418965916, disc_loss = 0.05437200137553473
Trained batch 354 in epoch 7, gen_loss = 0.4033498314064993, disc_loss = 0.05431166258640587
Trained batch 355 in epoch 7, gen_loss = 0.4031829716784231, disc_loss = 0.0542084765770954
Trained batch 356 in epoch 7, gen_loss = 0.4029039226326288, disc_loss = 0.05411044894248059
Trained batch 357 in epoch 7, gen_loss = 0.40269213207274174, disc_loss = 0.05400793212166774
Trained batch 358 in epoch 7, gen_loss = 0.4026585022885155, disc_loss = 0.05392485807654979
Trained batch 359 in epoch 7, gen_loss = 0.40279292406307327, disc_loss = 0.053828113716897656
Trained batch 360 in epoch 7, gen_loss = 0.40295131962715425, disc_loss = 0.053743028212880455
Trained batch 361 in epoch 7, gen_loss = 0.40307598128832506, disc_loss = 0.05363468023323202
Trained batch 362 in epoch 7, gen_loss = 0.4031287048309631, disc_loss = 0.053529632035976396
Trained batch 363 in epoch 7, gen_loss = 0.40328820377260777, disc_loss = 0.05365202146272718
Trained batch 364 in epoch 7, gen_loss = 0.4030127629025342, disc_loss = 0.053742815229454885
Trained batch 365 in epoch 7, gen_loss = 0.40282368212124037, disc_loss = 0.05364690502899409
Trained batch 366 in epoch 7, gen_loss = 0.4027896103644566, disc_loss = 0.05369858837265227
Trained batch 367 in epoch 7, gen_loss = 0.40277084797296836, disc_loss = 0.05362618205064158
Trained batch 368 in epoch 7, gen_loss = 0.40271174051574254, disc_loss = 0.05360245646790256
Trained batch 369 in epoch 7, gen_loss = 0.4027082128299249, disc_loss = 0.05351229884623978
Trained batch 370 in epoch 7, gen_loss = 0.40270574049486946, disc_loss = 0.053395727244544666
Trained batch 371 in epoch 7, gen_loss = 0.40270234323957915, disc_loss = 0.05327215927380127
Trained batch 372 in epoch 7, gen_loss = 0.4026402123172545, disc_loss = 0.05317566214671144
Trained batch 373 in epoch 7, gen_loss = 0.4026758327363009, disc_loss = 0.05306681924820803
Trained batch 374 in epoch 7, gen_loss = 0.40270319596926374, disc_loss = 0.052996395180001855
Trained batch 375 in epoch 7, gen_loss = 0.4028845143286472, disc_loss = 0.05289187953507706
Trained batch 376 in epoch 7, gen_loss = 0.40269794807193765, disc_loss = 0.0529816345471039
Trained batch 377 in epoch 7, gen_loss = 0.40282293003072184, disc_loss = 0.05320274281357391
Trained batch 378 in epoch 7, gen_loss = 0.4029623128493417, disc_loss = 0.05327632900826279
Trained batch 379 in epoch 7, gen_loss = 0.4030113431968187, disc_loss = 0.0531517167054852
Trained batch 380 in epoch 7, gen_loss = 0.40302890085485665, disc_loss = 0.05306019244062912
Trained batch 381 in epoch 7, gen_loss = 0.40303275316797627, disc_loss = 0.05296183506414509
Trained batch 382 in epoch 7, gen_loss = 0.4029144493002182, disc_loss = 0.05287497601710143
Trained batch 383 in epoch 7, gen_loss = 0.40311373335619766, disc_loss = 0.052905905120496755
Trained batch 384 in epoch 7, gen_loss = 0.40311092076363503, disc_loss = 0.053126995538228326
Trained batch 385 in epoch 7, gen_loss = 0.4032545312080976, disc_loss = 0.053314296173419165
Trained batch 386 in epoch 7, gen_loss = 0.40314428050080625, disc_loss = 0.053357453272588916
Trained batch 387 in epoch 7, gen_loss = 0.4031526494732837, disc_loss = 0.05324796971939408
Trained batch 388 in epoch 7, gen_loss = 0.4031547673410499, disc_loss = 0.05315419158821681
Trained batch 389 in epoch 7, gen_loss = 0.4031467820589359, disc_loss = 0.05304685820980618
Trained batch 390 in epoch 7, gen_loss = 0.4029015586199358, disc_loss = 0.05292259555731607
Trained batch 391 in epoch 7, gen_loss = 0.4028522182179957, disc_loss = 0.05280453071048084
Trained batch 392 in epoch 7, gen_loss = 0.4026918978484836, disc_loss = 0.05270506156568176
Trained batch 393 in epoch 7, gen_loss = 0.4028149970291835, disc_loss = 0.05258922685980135
Trained batch 394 in epoch 7, gen_loss = 0.40266570275342917, disc_loss = 0.05248314084048984
Trained batch 395 in epoch 7, gen_loss = 0.4028411957651678, disc_loss = 0.05238702815235357
Trained batch 396 in epoch 7, gen_loss = 0.4029352749775279, disc_loss = 0.052269037625862644
Trained batch 397 in epoch 7, gen_loss = 0.4029395940465544, disc_loss = 0.052195962051037305
Trained batch 398 in epoch 7, gen_loss = 0.403015219702159, disc_loss = 0.052186978407283514
Trained batch 399 in epoch 7, gen_loss = 0.4029986245185137, disc_loss = 0.05208059430879075
Trained batch 400 in epoch 7, gen_loss = 0.40300322232995545, disc_loss = 0.05202956403666025
Trained batch 401 in epoch 7, gen_loss = 0.403153463901572, disc_loss = 0.051981318008214865
Trained batch 402 in epoch 7, gen_loss = 0.40332376594578956, disc_loss = 0.05187044764300416
Trained batch 403 in epoch 7, gen_loss = 0.40352839519186773, disc_loss = 0.0517558240023958
Trained batch 404 in epoch 7, gen_loss = 0.40365845413855567, disc_loss = 0.051654909404546576
Trained batch 405 in epoch 7, gen_loss = 0.40375867684192845, disc_loss = 0.05155557811574488
Trained batch 406 in epoch 7, gen_loss = 0.4038255462921808, disc_loss = 0.05144914807648803
Trained batch 407 in epoch 7, gen_loss = 0.40389397806104493, disc_loss = 0.05134616873521522
Trained batch 408 in epoch 7, gen_loss = 0.4038961887505352, disc_loss = 0.051251108567446725
Trained batch 409 in epoch 7, gen_loss = 0.40388823086168707, disc_loss = 0.05113567987559136
Trained batch 410 in epoch 7, gen_loss = 0.403905643526365, disc_loss = 0.05104464055333568
Trained batch 411 in epoch 7, gen_loss = 0.4038340575920725, disc_loss = 0.050945342607113524
Trained batch 412 in epoch 7, gen_loss = 0.40385247777795674, disc_loss = 0.050879985998896544
Trained batch 413 in epoch 7, gen_loss = 0.40396366012845064, disc_loss = 0.05077829835587744
Trained batch 414 in epoch 7, gen_loss = 0.40395754159214986, disc_loss = 0.05067184935548309
Trained batch 415 in epoch 7, gen_loss = 0.40406309490880143, disc_loss = 0.05057142857213666
Trained batch 416 in epoch 7, gen_loss = 0.4039062544596281, disc_loss = 0.050622236471046966
Trained batch 417 in epoch 7, gen_loss = 0.4042018994189906, disc_loss = 0.051030115590377324
Trained batch 418 in epoch 7, gen_loss = 0.4042692688029251, disc_loss = 0.05103586242992102
Trained batch 419 in epoch 7, gen_loss = 0.404241177155858, disc_loss = 0.05124145940090308
Trained batch 420 in epoch 7, gen_loss = 0.4042609074195037, disc_loss = 0.05167058696516849
Trained batch 421 in epoch 7, gen_loss = 0.40414266154099415, disc_loss = 0.051575846401246274
Trained batch 422 in epoch 7, gen_loss = 0.40399689229103974, disc_loss = 0.051626633523014456
Trained batch 423 in epoch 7, gen_loss = 0.404056412993737, disc_loss = 0.05157982469766998
Trained batch 424 in epoch 7, gen_loss = 0.40391228262115925, disc_loss = 0.051594863556435
Trained batch 425 in epoch 7, gen_loss = 0.4037288869490646, disc_loss = 0.051621450352298856
Trained batch 426 in epoch 7, gen_loss = 0.4038151750380317, disc_loss = 0.05161806438129125
Trained batch 427 in epoch 7, gen_loss = 0.4037956004248601, disc_loss = 0.05157370707422721
Trained batch 428 in epoch 7, gen_loss = 0.40397057618016685, disc_loss = 0.05161411152438354
Trained batch 429 in epoch 7, gen_loss = 0.40402464797330456, disc_loss = 0.05161304817437519
Trained batch 430 in epoch 7, gen_loss = 0.40416961770046617, disc_loss = 0.05154390161664694
Trained batch 431 in epoch 7, gen_loss = 0.4044489526638278, disc_loss = 0.05144005067402894
Trained batch 432 in epoch 7, gen_loss = 0.4043983625071704, disc_loss = 0.05134579928120809
Trained batch 433 in epoch 7, gen_loss = 0.4044102003909476, disc_loss = 0.05129491819298401
Trained batch 434 in epoch 7, gen_loss = 0.404439511723902, disc_loss = 0.05120484338612991
Trained batch 435 in epoch 7, gen_loss = 0.4044394851961267, disc_loss = 0.05110690012999272
Trained batch 436 in epoch 7, gen_loss = 0.4045228432326895, disc_loss = 0.051025064192708046
Trained batch 437 in epoch 7, gen_loss = 0.4046700634912813, disc_loss = 0.05091994051815151
Trained batch 438 in epoch 7, gen_loss = 0.40474305901006036, disc_loss = 0.050858267960043155
Trained batch 439 in epoch 7, gen_loss = 0.4046997528184544, disc_loss = 0.05087835350317288
Trained batch 440 in epoch 7, gen_loss = 0.4048599256139223, disc_loss = 0.0509313583862915
Trained batch 441 in epoch 7, gen_loss = 0.40501041069829086, disc_loss = 0.050848672859164216
Trained batch 442 in epoch 7, gen_loss = 0.4048303100648368, disc_loss = 0.050807949308512006
Trained batch 443 in epoch 7, gen_loss = 0.4049480982997396, disc_loss = 0.050739870429236174
Trained batch 444 in epoch 7, gen_loss = 0.40517180970545563, disc_loss = 0.05063668274885734
Trained batch 445 in epoch 7, gen_loss = 0.40528839853312404, disc_loss = 0.05053289671639406
Trained batch 446 in epoch 7, gen_loss = 0.40525287263078713, disc_loss = 0.05057217798433298
Trained batch 447 in epoch 7, gen_loss = 0.4054210700227746, disc_loss = 0.0507844735501359
Trained batch 448 in epoch 7, gen_loss = 0.40542893639386096, disc_loss = 0.05074322803769435
Trained batch 449 in epoch 7, gen_loss = 0.4053394620286094, disc_loss = 0.05084120322588003
Trained batch 450 in epoch 7, gen_loss = 0.40551339925789254, disc_loss = 0.05100870356448986
Trained batch 451 in epoch 7, gen_loss = 0.4053475134140622, disc_loss = 0.05101394355121951
Trained batch 452 in epoch 7, gen_loss = 0.40545057441225113, disc_loss = 0.05093429741659356
Trained batch 453 in epoch 7, gen_loss = 0.4055606709046511, disc_loss = 0.05084166468976533
Trained batch 454 in epoch 7, gen_loss = 0.4053738679859664, disc_loss = 0.05089757180424755
Trained batch 455 in epoch 7, gen_loss = 0.40539373829960823, disc_loss = 0.05177304821789444
Trained batch 456 in epoch 7, gen_loss = 0.4054768316985742, disc_loss = 0.051909207286419144
Trained batch 457 in epoch 7, gen_loss = 0.40556237602598283, disc_loss = 0.05200399089082018
Trained batch 458 in epoch 7, gen_loss = 0.4054418628901438, disc_loss = 0.05190905970967657
Trained batch 459 in epoch 7, gen_loss = 0.4053913709262143, disc_loss = 0.051851184586690656
Trained batch 460 in epoch 7, gen_loss = 0.405262166597838, disc_loss = 0.05177574726922635
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 0.3812294900417328, disc_loss = 0.011732475832104683
Trained batch 1 in epoch 8, gen_loss = 0.32862500846385956, disc_loss = 0.02161321137100458
Trained batch 2 in epoch 8, gen_loss = 0.37818673253059387, disc_loss = 0.027022176111737888
Trained batch 3 in epoch 8, gen_loss = 0.38194359838962555, disc_loss = 0.02417866699397564
Trained batch 4 in epoch 8, gen_loss = 0.3733047187328339, disc_loss = 0.03379322737455368
Trained batch 5 in epoch 8, gen_loss = 0.3753031889597575, disc_loss = 0.09442936753233273
Trained batch 6 in epoch 8, gen_loss = 0.3846373898642404, disc_loss = 0.09652422474963325
Trained batch 7 in epoch 8, gen_loss = 0.384506955742836, disc_loss = 0.08871023962274194
Trained batch 8 in epoch 8, gen_loss = 0.38596051931381226, disc_loss = 0.08474931162264612
Trained batch 9 in epoch 8, gen_loss = 0.3882057636976242, disc_loss = 0.0791016735136509
Trained batch 10 in epoch 8, gen_loss = 0.38224131952632556, disc_loss = 0.07549710470167073
Trained batch 11 in epoch 8, gen_loss = 0.39380712310473126, disc_loss = 0.08425111478815477
Trained batch 12 in epoch 8, gen_loss = 0.38692118571354794, disc_loss = 0.11197944931112803
Trained batch 13 in epoch 8, gen_loss = 0.37812384750161854, disc_loss = 0.11297442258468696
Trained batch 14 in epoch 8, gen_loss = 0.38322585821151733, disc_loss = 0.11488225484887758
Trained batch 15 in epoch 8, gen_loss = 0.3852857965976, disc_loss = 0.11763223470188677
Trained batch 16 in epoch 8, gen_loss = 0.38404637399841757, disc_loss = 0.11664668974630973
Trained batch 17 in epoch 8, gen_loss = 0.3849416524171829, disc_loss = 0.11529327742755413
Trained batch 18 in epoch 8, gen_loss = 0.3886002694305621, disc_loss = 0.11433395410054609
Trained batch 19 in epoch 8, gen_loss = 0.3875031307339668, disc_loss = 0.11025308426469564
Trained batch 20 in epoch 8, gen_loss = 0.3825249487445468, disc_loss = 0.10826442479377701
Trained batch 21 in epoch 8, gen_loss = 0.3826632716438987, disc_loss = 0.10388128268955783
Trained batch 22 in epoch 8, gen_loss = 0.38128247338792554, disc_loss = 0.10064850662551496
Trained batch 23 in epoch 8, gen_loss = 0.38264111429452896, disc_loss = 0.09797277514978002
Trained batch 24 in epoch 8, gen_loss = 0.3837785243988037, disc_loss = 0.09649181004613638
Trained batch 25 in epoch 8, gen_loss = 0.38686826252020323, disc_loss = 0.10395197222868983
Trained batch 26 in epoch 8, gen_loss = 0.385627168196219, disc_loss = 0.10594638516367585
Trained batch 27 in epoch 8, gen_loss = 0.38857600731509073, disc_loss = 0.10462146781251899
Trained batch 28 in epoch 8, gen_loss = 0.3893862644146229, disc_loss = 0.10133539252625458
Trained batch 29 in epoch 8, gen_loss = 0.3877280126015345, disc_loss = 0.09917497408265868
Trained batch 30 in epoch 8, gen_loss = 0.3899029310672514, disc_loss = 0.09658818352486818
Trained batch 31 in epoch 8, gen_loss = 0.38986983243376017, disc_loss = 0.09399242597282864
Trained batch 32 in epoch 8, gen_loss = 0.3885471865986333, disc_loss = 0.09173035584954602
Trained batch 33 in epoch 8, gen_loss = 0.3872484363177243, disc_loss = 0.0900304150658057
Trained batch 34 in epoch 8, gen_loss = 0.3878639715058463, disc_loss = 0.09359175177024943
Trained batch 35 in epoch 8, gen_loss = 0.39066458079550004, disc_loss = 0.09740081302718157
Trained batch 36 in epoch 8, gen_loss = 0.3909650646351479, disc_loss = 0.09503188268659082
Trained batch 37 in epoch 8, gen_loss = 0.3897515213803241, disc_loss = 0.09338774612957709
Trained batch 38 in epoch 8, gen_loss = 0.3897213614903964, disc_loss = 0.09236334629643422
Trained batch 39 in epoch 8, gen_loss = 0.38937212750315664, disc_loss = 0.09017145631369203
Trained batch 40 in epoch 8, gen_loss = 0.3903187244403653, disc_loss = 0.08914633819878828
Trained batch 41 in epoch 8, gen_loss = 0.3893731896366392, disc_loss = 0.08721044134082538
Trained batch 42 in epoch 8, gen_loss = 0.3885725618794907, disc_loss = 0.08548818953162016
Trained batch 43 in epoch 8, gen_loss = 0.38905714858662, disc_loss = 0.08427699409763921
Trained batch 44 in epoch 8, gen_loss = 0.39015852477815416, disc_loss = 0.0827024163471328
Trained batch 45 in epoch 8, gen_loss = 0.3924781071103137, disc_loss = 0.08138089537944483
Trained batch 46 in epoch 8, gen_loss = 0.39484941578925925, disc_loss = 0.08164995678878845
Trained batch 47 in epoch 8, gen_loss = 0.3925363253802061, disc_loss = 0.08356925340679784
Trained batch 48 in epoch 8, gen_loss = 0.39328800293864036, disc_loss = 0.08515395885523484
Trained batch 49 in epoch 8, gen_loss = 0.3925008726119995, disc_loss = 0.0842831263691187
Trained batch 50 in epoch 8, gen_loss = 0.393764653042251, disc_loss = 0.08307066216480498
Trained batch 51 in epoch 8, gen_loss = 0.3940810819084828, disc_loss = 0.0854217353491829
Trained batch 52 in epoch 8, gen_loss = 0.3922247105049637, disc_loss = 0.0885666255259289
Trained batch 53 in epoch 8, gen_loss = 0.39224927844824614, disc_loss = 0.08790531623418685
Trained batch 54 in epoch 8, gen_loss = 0.39357602975585243, disc_loss = 0.08742894516749815
Trained batch 55 in epoch 8, gen_loss = 0.39307500049471855, disc_loss = 0.08681450883990952
Trained batch 56 in epoch 8, gen_loss = 0.39323197174490543, disc_loss = 0.08567013111161559
Trained batch 57 in epoch 8, gen_loss = 0.39303130322489244, disc_loss = 0.0848710266230949
Trained batch 58 in epoch 8, gen_loss = 0.3938463683855736, disc_loss = 0.0837727053943327
Trained batch 59 in epoch 8, gen_loss = 0.3944232414166133, disc_loss = 0.08324552215635776
Trained batch 60 in epoch 8, gen_loss = 0.3940217807644703, disc_loss = 0.08761429237049134
Trained batch 61 in epoch 8, gen_loss = 0.393350618981546, disc_loss = 0.08849074174800227
Trained batch 62 in epoch 8, gen_loss = 0.39457363079464625, disc_loss = 0.08853005724293846
Trained batch 63 in epoch 8, gen_loss = 0.39676758274435997, disc_loss = 0.08837466104887426
Trained batch 64 in epoch 8, gen_loss = 0.395311183654345, disc_loss = 0.08752074298950342
Trained batch 65 in epoch 8, gen_loss = 0.39534141439380066, disc_loss = 0.08644305798930652
Trained batch 66 in epoch 8, gen_loss = 0.3953415440089667, disc_loss = 0.08595915069219781
Trained batch 67 in epoch 8, gen_loss = 0.3957016573232763, disc_loss = 0.08606766687486977
Trained batch 68 in epoch 8, gen_loss = 0.3959181749302408, disc_loss = 0.09121185711220554
Trained batch 69 in epoch 8, gen_loss = 0.3957047155925206, disc_loss = 0.09239325925175633
Trained batch 70 in epoch 8, gen_loss = 0.39622341788990395, disc_loss = 0.09174674216815283
Trained batch 71 in epoch 8, gen_loss = 0.3972376158667935, disc_loss = 0.09102048344599704
Trained batch 72 in epoch 8, gen_loss = 0.396963068475462, disc_loss = 0.08995180175167648
Trained batch 73 in epoch 8, gen_loss = 0.3968886914285454, disc_loss = 0.08887048399176549
Trained batch 74 in epoch 8, gen_loss = 0.3961267403761546, disc_loss = 0.08785364470134178
Trained batch 75 in epoch 8, gen_loss = 0.3955928232324751, disc_loss = 0.08687839328654502
Trained batch 76 in epoch 8, gen_loss = 0.3965853181752292, disc_loss = 0.08583282297114272
Trained batch 77 in epoch 8, gen_loss = 0.3969718733659157, disc_loss = 0.08529082996149857
Trained batch 78 in epoch 8, gen_loss = 0.39842225139654136, disc_loss = 0.0847882420956334
Trained batch 79 in epoch 8, gen_loss = 0.39820251129567624, disc_loss = 0.08379873395897448
Trained batch 80 in epoch 8, gen_loss = 0.39792628310344835, disc_loss = 0.08285390140695705
Trained batch 81 in epoch 8, gen_loss = 0.3979490250349045, disc_loss = 0.08215256456694589
Trained batch 82 in epoch 8, gen_loss = 0.39884257855185545, disc_loss = 0.08129013872828829
Trained batch 83 in epoch 8, gen_loss = 0.39945893167030244, disc_loss = 0.08060000805805127
Trained batch 84 in epoch 8, gen_loss = 0.3994159642387839, disc_loss = 0.08003295177922529
Trained batch 85 in epoch 8, gen_loss = 0.40011768666810765, disc_loss = 0.0795919137552034
Trained batch 86 in epoch 8, gen_loss = 0.40074709434618894, disc_loss = 0.07882828465609372
Trained batch 87 in epoch 8, gen_loss = 0.4011819857088002, disc_loss = 0.07805344021074813
Trained batch 88 in epoch 8, gen_loss = 0.4008089605342136, disc_loss = 0.07804276131805074
Trained batch 89 in epoch 8, gen_loss = 0.40189230508274504, disc_loss = 0.0779432507749233
Trained batch 90 in epoch 8, gen_loss = 0.402857203404982, disc_loss = 0.07732018925618012
Trained batch 91 in epoch 8, gen_loss = 0.4031074079482452, disc_loss = 0.0770138078065508
Trained batch 92 in epoch 8, gen_loss = 0.40357391680440596, disc_loss = 0.07636171784652497
Trained batch 93 in epoch 8, gen_loss = 0.4034726356572293, disc_loss = 0.07562591407963253
Trained batch 94 in epoch 8, gen_loss = 0.40349657315956916, disc_loss = 0.07534344748250749
Trained batch 95 in epoch 8, gen_loss = 0.4038899131119251, disc_loss = 0.07486307534660834
Trained batch 96 in epoch 8, gen_loss = 0.4041931245130362, disc_loss = 0.07778134457190934
Trained batch 97 in epoch 8, gen_loss = 0.4039939897400992, disc_loss = 0.08046442763499763
Trained batch 98 in epoch 8, gen_loss = 0.40428156383109815, disc_loss = 0.08103924288856562
Trained batch 99 in epoch 8, gen_loss = 0.4040374606847763, disc_loss = 0.08139769217930734
Trained batch 100 in epoch 8, gen_loss = 0.40375428831223215, disc_loss = 0.08168082712863636
Trained batch 101 in epoch 8, gen_loss = 0.4033436211300831, disc_loss = 0.0819453527584818
Trained batch 102 in epoch 8, gen_loss = 0.4031836266077838, disc_loss = 0.0820880705056694
Trained batch 103 in epoch 8, gen_loss = 0.4027130239858077, disc_loss = 0.08193859679158777
Trained batch 104 in epoch 8, gen_loss = 0.40156433695838567, disc_loss = 0.08181479139519589
Trained batch 105 in epoch 8, gen_loss = 0.4014539274404634, disc_loss = 0.0822811068281672
Trained batch 106 in epoch 8, gen_loss = 0.40026077962367335, disc_loss = 0.08341988161310693
Trained batch 107 in epoch 8, gen_loss = 0.40009821151141767, disc_loss = 0.08539768383424315
Trained batch 108 in epoch 8, gen_loss = 0.40054727120136996, disc_loss = 0.08549777567899282
Trained batch 109 in epoch 8, gen_loss = 0.4002257404002276, disc_loss = 0.08542216175489804
Trained batch 110 in epoch 8, gen_loss = 0.4003821418092057, disc_loss = 0.08546877779100123
Trained batch 111 in epoch 8, gen_loss = 0.400215174470629, disc_loss = 0.08523499229756583
Trained batch 112 in epoch 8, gen_loss = 0.40007171931519975, disc_loss = 0.08567758546565223
Trained batch 113 in epoch 8, gen_loss = 0.3996354717957346, disc_loss = 0.08672452413297274
Trained batch 114 in epoch 8, gen_loss = 0.4002438058023867, disc_loss = 0.08608247678241004
Trained batch 115 in epoch 8, gen_loss = 0.4007171844613963, disc_loss = 0.08580325869843364
Trained batch 116 in epoch 8, gen_loss = 0.4004230776913146, disc_loss = 0.08544196285562128
Trained batch 117 in epoch 8, gen_loss = 0.4007415107246173, disc_loss = 0.0870373032639845
Trained batch 118 in epoch 8, gen_loss = 0.40032418911196604, disc_loss = 0.08742236097131957
Trained batch 119 in epoch 8, gen_loss = 0.4005896580715974, disc_loss = 0.08726152121089399
Trained batch 120 in epoch 8, gen_loss = 0.40027842048771123, disc_loss = 0.08688697472892025
Trained batch 121 in epoch 8, gen_loss = 0.399406976387149, disc_loss = 0.08714713078358623
Trained batch 122 in epoch 8, gen_loss = 0.3995865738488794, disc_loss = 0.08767334712532962
Trained batch 123 in epoch 8, gen_loss = 0.398740224059551, disc_loss = 0.08791588674930315
Trained batch 124 in epoch 8, gen_loss = 0.3990982382297516, disc_loss = 0.08745681071281433
Trained batch 125 in epoch 8, gen_loss = 0.3995193193356196, disc_loss = 0.08682738204619714
Trained batch 126 in epoch 8, gen_loss = 0.399937279346421, disc_loss = 0.08620499017259736
Trained batch 127 in epoch 8, gen_loss = 0.40005365922115743, disc_loss = 0.08577858704666141
Trained batch 128 in epoch 8, gen_loss = 0.3999604855396951, disc_loss = 0.08536398181215275
Trained batch 129 in epoch 8, gen_loss = 0.3999313531013636, disc_loss = 0.08502275137087474
Trained batch 130 in epoch 8, gen_loss = 0.4001222464419503, disc_loss = 0.08570327554324655
Trained batch 131 in epoch 8, gen_loss = 0.4001065914829572, disc_loss = 0.08666142433260877
Trained batch 132 in epoch 8, gen_loss = 0.40044802539330676, disc_loss = 0.0861298051431663
Trained batch 133 in epoch 8, gen_loss = 0.4008785123700526, disc_loss = 0.08565751832923782
Trained batch 134 in epoch 8, gen_loss = 0.4012660993470086, disc_loss = 0.08509367169743334
Trained batch 135 in epoch 8, gen_loss = 0.4011147337801316, disc_loss = 0.08544656257008147
Trained batch 136 in epoch 8, gen_loss = 0.4016057740162759, disc_loss = 0.0881829124256751
Trained batch 137 in epoch 8, gen_loss = 0.40096291251804517, disc_loss = 0.08796133142153638
Trained batch 138 in epoch 8, gen_loss = 0.4005757456631969, disc_loss = 0.08786151309584757
Trained batch 139 in epoch 8, gen_loss = 0.40067272186279296, disc_loss = 0.08784150175883301
Trained batch 140 in epoch 8, gen_loss = 0.40072099748232687, disc_loss = 0.08801116760661627
Trained batch 141 in epoch 8, gen_loss = 0.4004193901176184, disc_loss = 0.08752452866108694
Trained batch 142 in epoch 8, gen_loss = 0.40013650497356495, disc_loss = 0.0872117425087136
Trained batch 143 in epoch 8, gen_loss = 0.40019142917460865, disc_loss = 0.08673147640527329
Trained batch 144 in epoch 8, gen_loss = 0.39979339879134607, disc_loss = 0.08620529067542018
Trained batch 145 in epoch 8, gen_loss = 0.3998521625587385, disc_loss = 0.0856813669447111
Trained batch 146 in epoch 8, gen_loss = 0.39956302018392653, disc_loss = 0.08542191720611993
Trained batch 147 in epoch 8, gen_loss = 0.3995782251696329, disc_loss = 0.08555363830355173
Trained batch 148 in epoch 8, gen_loss = 0.39940292243189457, disc_loss = 0.08545676970716891
Trained batch 149 in epoch 8, gen_loss = 0.399754802385966, disc_loss = 0.08505090354010462
Trained batch 150 in epoch 8, gen_loss = 0.39971698435726544, disc_loss = 0.08477830734498651
Trained batch 151 in epoch 8, gen_loss = 0.3999049091025403, disc_loss = 0.08543101840922118
Trained batch 152 in epoch 8, gen_loss = 0.4000801751816195, disc_loss = 0.08598319392992196
Trained batch 153 in epoch 8, gen_loss = 0.39986110623780785, disc_loss = 0.08548597943690883
Trained batch 154 in epoch 8, gen_loss = 0.3998751348064792, disc_loss = 0.08518261011209219
Trained batch 155 in epoch 8, gen_loss = 0.3995591528140582, disc_loss = 0.08468893576914874
Trained batch 156 in epoch 8, gen_loss = 0.3995856699670196, disc_loss = 0.08432118671169136
Trained batch 157 in epoch 8, gen_loss = 0.39903980474683304, disc_loss = 0.08394255760844939
Trained batch 158 in epoch 8, gen_loss = 0.39933476789192585, disc_loss = 0.08405350146920613
Trained batch 159 in epoch 8, gen_loss = 0.3990505516529083, disc_loss = 0.08377859511529095
Trained batch 160 in epoch 8, gen_loss = 0.3987410708984233, disc_loss = 0.08406638648499798
Trained batch 161 in epoch 8, gen_loss = 0.3988194759981132, disc_loss = 0.08401836701496332
Trained batch 162 in epoch 8, gen_loss = 0.3994188469611794, disc_loss = 0.08384127851484195
Trained batch 163 in epoch 8, gen_loss = 0.39899960251116173, disc_loss = 0.08395420224405825
Trained batch 164 in epoch 8, gen_loss = 0.39954496983325843, disc_loss = 0.08355486079711806
Trained batch 165 in epoch 8, gen_loss = 0.39991323739649304, disc_loss = 0.08310012982215688
Trained batch 166 in epoch 8, gen_loss = 0.4001804094114703, disc_loss = 0.0827356071941956
Trained batch 167 in epoch 8, gen_loss = 0.399808111290137, disc_loss = 0.0827757173406315
Trained batch 168 in epoch 8, gen_loss = 0.3998368114409362, disc_loss = 0.08231643661195358
Trained batch 169 in epoch 8, gen_loss = 0.40042543271008657, disc_loss = 0.08207687230452018
Trained batch 170 in epoch 8, gen_loss = 0.4006322976092846, disc_loss = 0.08163227816248497
Trained batch 171 in epoch 8, gen_loss = 0.4003034651625988, disc_loss = 0.08136234891622565
Trained batch 172 in epoch 8, gen_loss = 0.40031037750960774, disc_loss = 0.08123413886810314
Trained batch 173 in epoch 8, gen_loss = 0.40020771855595466, disc_loss = 0.08138442651807577
Trained batch 174 in epoch 8, gen_loss = 0.4005255879674639, disc_loss = 0.08167594428573335
Trained batch 175 in epoch 8, gen_loss = 0.40042874962091446, disc_loss = 0.08130576393821022
Trained batch 176 in epoch 8, gen_loss = 0.4003891768091816, disc_loss = 0.08095884636718001
Trained batch 177 in epoch 8, gen_loss = 0.4004312664940116, disc_loss = 0.08055876508313284
Trained batch 178 in epoch 8, gen_loss = 0.4004692826524127, disc_loss = 0.08025325897186163
Trained batch 179 in epoch 8, gen_loss = 0.4007165956828329, disc_loss = 0.08016515519056056
Trained batch 180 in epoch 8, gen_loss = 0.40083440677237114, disc_loss = 0.07984033770324117
Trained batch 181 in epoch 8, gen_loss = 0.4006592888425995, disc_loss = 0.07971159321675589
Trained batch 182 in epoch 8, gen_loss = 0.4008673338290772, disc_loss = 0.07960480885183224
Trained batch 183 in epoch 8, gen_loss = 0.40071276899265207, disc_loss = 0.07922676704702494
Trained batch 184 in epoch 8, gen_loss = 0.400751791612522, disc_loss = 0.07884116271460379
Trained batch 185 in epoch 8, gen_loss = 0.4010686475423075, disc_loss = 0.07854383526950755
Trained batch 186 in epoch 8, gen_loss = 0.4011228605706424, disc_loss = 0.07819319157836271
Trained batch 187 in epoch 8, gen_loss = 0.4009486417821113, disc_loss = 0.0778321435357979
Trained batch 188 in epoch 8, gen_loss = 0.40103385420072646, disc_loss = 0.07746743758223833
Trained batch 189 in epoch 8, gen_loss = 0.40106359124183655, disc_loss = 0.07707970484993175
Trained batch 190 in epoch 8, gen_loss = 0.4010917332159911, disc_loss = 0.07689585066181047
Trained batch 191 in epoch 8, gen_loss = 0.4013712697972854, disc_loss = 0.07669064464183369
Trained batch 192 in epoch 8, gen_loss = 0.4015978417248306, disc_loss = 0.0765428374728931
Trained batch 193 in epoch 8, gen_loss = 0.401707547227132, disc_loss = 0.07650665262445193
Trained batch 194 in epoch 8, gen_loss = 0.4012861960973495, disc_loss = 0.07615569875312922
Trained batch 195 in epoch 8, gen_loss = 0.4015862786648225, disc_loss = 0.07580901391576139
Trained batch 196 in epoch 8, gen_loss = 0.40187907279445434, disc_loss = 0.07546396002759637
Trained batch 197 in epoch 8, gen_loss = 0.40171335712827816, disc_loss = 0.07514565312444713
Trained batch 198 in epoch 8, gen_loss = 0.401399319495388, disc_loss = 0.07479282518633497
Trained batch 199 in epoch 8, gen_loss = 0.40179156720638276, disc_loss = 0.07446998278144747
Trained batch 200 in epoch 8, gen_loss = 0.4019310550013585, disc_loss = 0.07416538953947932
Trained batch 201 in epoch 8, gen_loss = 0.401876763689636, disc_loss = 0.07388037895451825
Trained batch 202 in epoch 8, gen_loss = 0.4016605389529261, disc_loss = 0.0735915058012593
Trained batch 203 in epoch 8, gen_loss = 0.4019460716083938, disc_loss = 0.07353468985735055
Trained batch 204 in epoch 8, gen_loss = 0.4020758249410769, disc_loss = 0.07326542920001396
Trained batch 205 in epoch 8, gen_loss = 0.4023945401015791, disc_loss = 0.07295041866329255
Trained batch 206 in epoch 8, gen_loss = 0.4024819905919153, disc_loss = 0.07264947723867236
Trained batch 207 in epoch 8, gen_loss = 0.4027388703364592, disc_loss = 0.07233031092730996
Trained batch 208 in epoch 8, gen_loss = 0.40295536481022265, disc_loss = 0.07221682320246428
Trained batch 209 in epoch 8, gen_loss = 0.402951414670263, disc_loss = 0.07196978123503782
Trained batch 210 in epoch 8, gen_loss = 0.4028041012479231, disc_loss = 0.07172023346515205
Trained batch 211 in epoch 8, gen_loss = 0.40326123192625224, disc_loss = 0.07142292047007326
Trained batch 212 in epoch 8, gen_loss = 0.4033736145832169, disc_loss = 0.07129927503793312
Trained batch 213 in epoch 8, gen_loss = 0.4034161574651148, disc_loss = 0.07103912259460748
Trained batch 214 in epoch 8, gen_loss = 0.4034233328907989, disc_loss = 0.0709950830224295
Trained batch 215 in epoch 8, gen_loss = 0.4036370359913067, disc_loss = 0.07122815440460625
Trained batch 216 in epoch 8, gen_loss = 0.40349790783521766, disc_loss = 0.07105498335620362
Trained batch 217 in epoch 8, gen_loss = 0.40375186612299824, disc_loss = 0.07080369813094309
Trained batch 218 in epoch 8, gen_loss = 0.40357369361402784, disc_loss = 0.07054992053725812
Trained batch 219 in epoch 8, gen_loss = 0.4036423237486319, disc_loss = 0.07026768606156111
Trained batch 220 in epoch 8, gen_loss = 0.40357568617320166, disc_loss = 0.06998465743918832
Trained batch 221 in epoch 8, gen_loss = 0.40358542711348144, disc_loss = 0.06969421009768036
Trained batch 222 in epoch 8, gen_loss = 0.40337284864866146, disc_loss = 0.0695135088098724
Trained batch 223 in epoch 8, gen_loss = 0.40300471309040276, disc_loss = 0.06964426037198532
Trained batch 224 in epoch 8, gen_loss = 0.4033309430546231, disc_loss = 0.06996866380381915
Trained batch 225 in epoch 8, gen_loss = 0.40276859898482803, disc_loss = 0.06983854597129455
Trained batch 226 in epoch 8, gen_loss = 0.40283794812693996, disc_loss = 0.0697592730912901
Trained batch 227 in epoch 8, gen_loss = 0.40278002240678723, disc_loss = 0.06958295194342275
Trained batch 228 in epoch 8, gen_loss = 0.4028990919413004, disc_loss = 0.06939448169981613
Trained batch 229 in epoch 8, gen_loss = 0.40273508623890253, disc_loss = 0.06980550497486863
Trained batch 230 in epoch 8, gen_loss = 0.4028809391832971, disc_loss = 0.07026482061624076
Trained batch 231 in epoch 8, gen_loss = 0.40271743682437927, disc_loss = 0.07000789355591004
Trained batch 232 in epoch 8, gen_loss = 0.4027904191498081, disc_loss = 0.06976531831099944
Trained batch 233 in epoch 8, gen_loss = 0.4026128547823327, disc_loss = 0.0695499085013269
Trained batch 234 in epoch 8, gen_loss = 0.4025814343006053, disc_loss = 0.06927552699170848
Trained batch 235 in epoch 8, gen_loss = 0.40249156535176905, disc_loss = 0.06901216865280423
Trained batch 236 in epoch 8, gen_loss = 0.4024695438423237, disc_loss = 0.06909278533441104
Trained batch 237 in epoch 8, gen_loss = 0.4021292413984026, disc_loss = 0.07001523506052855
Trained batch 238 in epoch 8, gen_loss = 0.40186867279986455, disc_loss = 0.06982800073796984
Trained batch 239 in epoch 8, gen_loss = 0.4019037072857221, disc_loss = 0.06965058088923494
Trained batch 240 in epoch 8, gen_loss = 0.4021630483791541, disc_loss = 0.06948345021588179
Trained batch 241 in epoch 8, gen_loss = 0.4020974233377078, disc_loss = 0.06992033444160273
Trained batch 242 in epoch 8, gen_loss = 0.4023513353655858, disc_loss = 0.06971608032568247
Trained batch 243 in epoch 8, gen_loss = 0.40247592928468207, disc_loss = 0.06975776724303599
Trained batch 244 in epoch 8, gen_loss = 0.4025516435808065, disc_loss = 0.06952966039962306
Trained batch 245 in epoch 8, gen_loss = 0.4026982422039761, disc_loss = 0.06930741165741915
Trained batch 246 in epoch 8, gen_loss = 0.40265135895385434, disc_loss = 0.06907731352698224
Trained batch 247 in epoch 8, gen_loss = 0.4027607460175791, disc_loss = 0.06887942086905241
Trained batch 248 in epoch 8, gen_loss = 0.40243809816827736, disc_loss = 0.06870493533680716
Trained batch 249 in epoch 8, gen_loss = 0.4023357231616974, disc_loss = 0.06849629189819098
Trained batch 250 in epoch 8, gen_loss = 0.4020236731762905, disc_loss = 0.06833775172314321
Trained batch 251 in epoch 8, gen_loss = 0.40245304729730363, disc_loss = 0.06826351072994016
Trained batch 252 in epoch 8, gen_loss = 0.40224796568923316, disc_loss = 0.06820870681183612
Trained batch 253 in epoch 8, gen_loss = 0.4023290541697675, disc_loss = 0.06796766853869313
Trained batch 254 in epoch 8, gen_loss = 0.40248332269051496, disc_loss = 0.06777452570477537
Trained batch 255 in epoch 8, gen_loss = 0.40237884712405503, disc_loss = 0.06752433677866065
Trained batch 256 in epoch 8, gen_loss = 0.4024869917895543, disc_loss = 0.06727641793457131
Trained batch 257 in epoch 8, gen_loss = 0.4022931692212127, disc_loss = 0.06710138802990577
Trained batch 258 in epoch 8, gen_loss = 0.40243456308445874, disc_loss = 0.0669399493429666
Trained batch 259 in epoch 8, gen_loss = 0.4025085960443203, disc_loss = 0.0667261348831324
Trained batch 260 in epoch 8, gen_loss = 0.4025509038875843, disc_loss = 0.06660356060815868
Trained batch 261 in epoch 8, gen_loss = 0.4024726930465407, disc_loss = 0.06638343191176
Trained batch 262 in epoch 8, gen_loss = 0.4025334930011981, disc_loss = 0.06615624963589183
Trained batch 263 in epoch 8, gen_loss = 0.402648814586979, disc_loss = 0.06592187726302214
Trained batch 264 in epoch 8, gen_loss = 0.40257818170313564, disc_loss = 0.06568859827458717
Trained batch 265 in epoch 8, gen_loss = 0.4026863290403122, disc_loss = 0.0654577341856771
Trained batch 266 in epoch 8, gen_loss = 0.4028867162791977, disc_loss = 0.06523010234892619
Trained batch 267 in epoch 8, gen_loss = 0.4028363557004217, disc_loss = 0.0650757111916527
Trained batch 268 in epoch 8, gen_loss = 0.4028201995064335, disc_loss = 0.06540455411319866
Trained batch 269 in epoch 8, gen_loss = 0.40244519820919744, disc_loss = 0.06642372646558754
Trained batch 270 in epoch 8, gen_loss = 0.40300852060317993, disc_loss = 0.06649183682372237
Trained batch 271 in epoch 8, gen_loss = 0.40313104737330885, disc_loss = 0.06637292152342578
Trained batch 272 in epoch 8, gen_loss = 0.403374466922257, disc_loss = 0.06620818433597438
Trained batch 273 in epoch 8, gen_loss = 0.4030771492606532, disc_loss = 0.06605221237732356
Trained batch 274 in epoch 8, gen_loss = 0.402959660616788, disc_loss = 0.0658835028086535
Trained batch 275 in epoch 8, gen_loss = 0.40311155057903647, disc_loss = 0.06617595434637633
Trained batch 276 in epoch 8, gen_loss = 0.4026413166135657, disc_loss = 0.06650849860514571
Trained batch 277 in epoch 8, gen_loss = 0.4026115841145138, disc_loss = 0.06639717724057008
Trained batch 278 in epoch 8, gen_loss = 0.40271816896708634, disc_loss = 0.06618057435134753
Trained batch 279 in epoch 8, gen_loss = 0.40282361933163235, disc_loss = 0.06604040019696446
Trained batch 280 in epoch 8, gen_loss = 0.4023974582393823, disc_loss = 0.0661326391411965
Trained batch 281 in epoch 8, gen_loss = 0.4024429774664818, disc_loss = 0.06599145993699339
Trained batch 282 in epoch 8, gen_loss = 0.4025860288749735, disc_loss = 0.0658338770949917
Trained batch 283 in epoch 8, gen_loss = 0.40255335613455573, disc_loss = 0.06563750480409895
Trained batch 284 in epoch 8, gen_loss = 0.40232921734190824, disc_loss = 0.06556125470567821
Trained batch 285 in epoch 8, gen_loss = 0.4024377844550393, disc_loss = 0.06537472554791875
Trained batch 286 in epoch 8, gen_loss = 0.4029143895006346, disc_loss = 0.06538225880837009
Trained batch 287 in epoch 8, gen_loss = 0.4029699931335118, disc_loss = 0.06532610940323341
Trained batch 288 in epoch 8, gen_loss = 0.40293362963570856, disc_loss = 0.0651554224350422
Trained batch 289 in epoch 8, gen_loss = 0.4030774265527725, disc_loss = 0.06498573817842608
Trained batch 290 in epoch 8, gen_loss = 0.40310537712680516, disc_loss = 0.06485215553780217
Trained batch 291 in epoch 8, gen_loss = 0.40284763735859364, disc_loss = 0.06501883581960063
Trained batch 292 in epoch 8, gen_loss = 0.4033205284396943, disc_loss = 0.06549555101152192
Trained batch 293 in epoch 8, gen_loss = 0.4034323079042694, disc_loss = 0.06535664860707181
Trained batch 294 in epoch 8, gen_loss = 0.40323808284129126, disc_loss = 0.06544412193677815
Trained batch 295 in epoch 8, gen_loss = 0.4031441714111212, disc_loss = 0.06525560926309333
Trained batch 296 in epoch 8, gen_loss = 0.4029727244015896, disc_loss = 0.0652498849691127
Trained batch 297 in epoch 8, gen_loss = 0.40312439213263107, disc_loss = 0.06656392858498074
Trained batch 298 in epoch 8, gen_loss = 0.40298538503040837, disc_loss = 0.06771144131120656
Trained batch 299 in epoch 8, gen_loss = 0.403026001850764, disc_loss = 0.06783615487084414
Trained batch 300 in epoch 8, gen_loss = 0.40310429784150614, disc_loss = 0.06790646685185252
Trained batch 301 in epoch 8, gen_loss = 0.4029150162114213, disc_loss = 0.06790937024202592
Trained batch 302 in epoch 8, gen_loss = 0.40259536825390935, disc_loss = 0.06811331664734573
Trained batch 303 in epoch 8, gen_loss = 0.40246103949060563, disc_loss = 0.06879700803409305
Trained batch 304 in epoch 8, gen_loss = 0.402712926903709, disc_loss = 0.06947584000538241
Trained batch 305 in epoch 8, gen_loss = 0.4025520171994477, disc_loss = 0.06939271815331179
Trained batch 306 in epoch 8, gen_loss = 0.4022300895728195, disc_loss = 0.0694168696600143
Trained batch 307 in epoch 8, gen_loss = 0.40204154777449447, disc_loss = 0.06934335470795269
Trained batch 308 in epoch 8, gen_loss = 0.40187972562212776, disc_loss = 0.06926760608918096
Trained batch 309 in epoch 8, gen_loss = 0.40173921363969, disc_loss = 0.06921517169778986
Trained batch 310 in epoch 8, gen_loss = 0.4017908312500098, disc_loss = 0.0693102229687526
Trained batch 311 in epoch 8, gen_loss = 0.40159236677946186, disc_loss = 0.07005860998954934
Trained batch 312 in epoch 8, gen_loss = 0.40170072614194485, disc_loss = 0.07034075672934635
Trained batch 313 in epoch 8, gen_loss = 0.4018863769853191, disc_loss = 0.07015878898551343
Trained batch 314 in epoch 8, gen_loss = 0.40192479803448633, disc_loss = 0.07000776746103334
Trained batch 315 in epoch 8, gen_loss = 0.40214938576085657, disc_loss = 0.06984568592765121
Trained batch 316 in epoch 8, gen_loss = 0.4019199298571337, disc_loss = 0.06966774060819828
Trained batch 317 in epoch 8, gen_loss = 0.40177170313754174, disc_loss = 0.06951162554455464
Trained batch 318 in epoch 8, gen_loss = 0.40174175691455133, disc_loss = 0.06954051054748459
Trained batch 319 in epoch 8, gen_loss = 0.40149580389261247, disc_loss = 0.07024052106207819
Trained batch 320 in epoch 8, gen_loss = 0.40169490590645146, disc_loss = 0.07015474602896314
Trained batch 321 in epoch 8, gen_loss = 0.40191524165757697, disc_loss = 0.07015604424356882
Trained batch 322 in epoch 8, gen_loss = 0.4018927555150661, disc_loss = 0.07019625618353187
Trained batch 323 in epoch 8, gen_loss = 0.4019489372034132, disc_loss = 0.07005412890762666
Trained batch 324 in epoch 8, gen_loss = 0.4019531518679399, disc_loss = 0.06988617128549288
Trained batch 325 in epoch 8, gen_loss = 0.40158493323194466, disc_loss = 0.06971821944340721
Trained batch 326 in epoch 8, gen_loss = 0.401371026531272, disc_loss = 0.06962017234292349
Trained batch 327 in epoch 8, gen_loss = 0.4014816292357154, disc_loss = 0.06943736879918838
Trained batch 328 in epoch 8, gen_loss = 0.40152819875888185, disc_loss = 0.06941880383472154
Trained batch 329 in epoch 8, gen_loss = 0.40117876836747834, disc_loss = 0.06957800418039728
Trained batch 330 in epoch 8, gen_loss = 0.4012459736216104, disc_loss = 0.06945313981261521
Trained batch 331 in epoch 8, gen_loss = 0.4012281576014427, disc_loss = 0.06928832670575547
Trained batch 332 in epoch 8, gen_loss = 0.4010944864055416, disc_loss = 0.06914396375185577
Trained batch 333 in epoch 8, gen_loss = 0.40093954674854965, disc_loss = 0.06898496392905198
Trained batch 334 in epoch 8, gen_loss = 0.40081580743860845, disc_loss = 0.06884121201279114
Trained batch 335 in epoch 8, gen_loss = 0.4008446939821754, disc_loss = 0.06888186424164035
Trained batch 336 in epoch 8, gen_loss = 0.4007995745902245, disc_loss = 0.06907784260425286
Trained batch 337 in epoch 8, gen_loss = 0.40047245556433525, disc_loss = 0.06940130684758983
Trained batch 338 in epoch 8, gen_loss = 0.40077788877276194, disc_loss = 0.06943684603516177
Trained batch 339 in epoch 8, gen_loss = 0.40102343743338303, disc_loss = 0.06927493658149615
Trained batch 340 in epoch 8, gen_loss = 0.40095979158829387, disc_loss = 0.06910077464777725
Trained batch 341 in epoch 8, gen_loss = 0.4008585515252331, disc_loss = 0.06909301946530587
Trained batch 342 in epoch 8, gen_loss = 0.40103700487676236, disc_loss = 0.06944382147057085
Trained batch 343 in epoch 8, gen_loss = 0.40085322895022324, disc_loss = 0.06929056319140092
Trained batch 344 in epoch 8, gen_loss = 0.4006064088448234, disc_loss = 0.0698662013983003
Trained batch 345 in epoch 8, gen_loss = 0.4006532298002629, disc_loss = 0.07044842725988434
Trained batch 346 in epoch 8, gen_loss = 0.40070618324046176, disc_loss = 0.07034944771703129
Trained batch 347 in epoch 8, gen_loss = 0.40080885160928487, disc_loss = 0.07052114516852595
Trained batch 348 in epoch 8, gen_loss = 0.4008801104687688, disc_loss = 0.07041398888216341
Trained batch 349 in epoch 8, gen_loss = 0.40084566729409354, disc_loss = 0.07029886097048542
Trained batch 350 in epoch 8, gen_loss = 0.4007570876015557, disc_loss = 0.07012401870982536
Trained batch 351 in epoch 8, gen_loss = 0.4007525858892636, disc_loss = 0.0699672081768354
Trained batch 352 in epoch 8, gen_loss = 0.400736482133271, disc_loss = 0.06981743798359026
Trained batch 353 in epoch 8, gen_loss = 0.4007607052723567, disc_loss = 0.06964149469533398
Trained batch 354 in epoch 8, gen_loss = 0.4009629402362125, disc_loss = 0.06967188309104196
Trained batch 355 in epoch 8, gen_loss = 0.4008510676997431, disc_loss = 0.0698508426496037
Trained batch 356 in epoch 8, gen_loss = 0.40103960988902243, disc_loss = 0.06976722253170856
Trained batch 357 in epoch 8, gen_loss = 0.4012982787866166, disc_loss = 0.06963177254571783
Trained batch 358 in epoch 8, gen_loss = 0.4012666698285796, disc_loss = 0.06948631396192881
Trained batch 359 in epoch 8, gen_loss = 0.40117885122696556, disc_loss = 0.06939905756993944
Trained batch 360 in epoch 8, gen_loss = 0.4011975597806915, disc_loss = 0.06926398237050095
Trained batch 361 in epoch 8, gen_loss = 0.4012260156277135, disc_loss = 0.06910349410966306
Trained batch 362 in epoch 8, gen_loss = 0.40129503213669643, disc_loss = 0.06897977048200209
Trained batch 363 in epoch 8, gen_loss = 0.4012967275230439, disc_loss = 0.06908533376562255
Trained batch 364 in epoch 8, gen_loss = 0.40105983451621174, disc_loss = 0.06928270143099538
Trained batch 365 in epoch 8, gen_loss = 0.4010567919966953, disc_loss = 0.06923939263552448
Trained batch 366 in epoch 8, gen_loss = 0.40087002296538704, disc_loss = 0.06915116718493158
Trained batch 367 in epoch 8, gen_loss = 0.400859615482066, disc_loss = 0.06900430121775412
Trained batch 368 in epoch 8, gen_loss = 0.400815111511768, disc_loss = 0.06886033040754053
Trained batch 369 in epoch 8, gen_loss = 0.4007004401973776, disc_loss = 0.06883599523870224
Trained batch 370 in epoch 8, gen_loss = 0.4008017652278962, disc_loss = 0.06879172778708453
Trained batch 371 in epoch 8, gen_loss = 0.4009671441970333, disc_loss = 0.06865140413477396
Trained batch 372 in epoch 8, gen_loss = 0.401191079824284, disc_loss = 0.06848734838890545
Trained batch 373 in epoch 8, gen_loss = 0.40133116191083734, disc_loss = 0.0683162998747987
Trained batch 374 in epoch 8, gen_loss = 0.4012635680039724, disc_loss = 0.06820250220410526
Trained batch 375 in epoch 8, gen_loss = 0.4011792359041407, disc_loss = 0.06820500855386119
Trained batch 376 in epoch 8, gen_loss = 0.40105987409381716, disc_loss = 0.06838426645412864
Trained batch 377 in epoch 8, gen_loss = 0.40100104200146186, disc_loss = 0.06828073220803013
Trained batch 378 in epoch 8, gen_loss = 0.40130284452186726, disc_loss = 0.06839558627458885
Trained batch 379 in epoch 8, gen_loss = 0.4011342950557408, disc_loss = 0.06892656036713896
Trained batch 380 in epoch 8, gen_loss = 0.4011862118413129, disc_loss = 0.06887003527941998
Trained batch 381 in epoch 8, gen_loss = 0.4012748024850616, disc_loss = 0.0687393548621684
Trained batch 382 in epoch 8, gen_loss = 0.4011510539770749, disc_loss = 0.06872259763035407
Trained batch 383 in epoch 8, gen_loss = 0.40126588839727145, disc_loss = 0.06868116644727706
Trained batch 384 in epoch 8, gen_loss = 0.4014420860773557, disc_loss = 0.06853909678817666
Trained batch 385 in epoch 8, gen_loss = 0.4012357597215188, disc_loss = 0.06857607342421024
Trained batch 386 in epoch 8, gen_loss = 0.40150016838882013, disc_loss = 0.06869096063060603
Trained batch 387 in epoch 8, gen_loss = 0.4013812578062421, disc_loss = 0.06876289518610046
Trained batch 388 in epoch 8, gen_loss = 0.40135173932445695, disc_loss = 0.06907154896037992
Trained batch 389 in epoch 8, gen_loss = 0.40129701304130067, disc_loss = 0.06966810635804462
Trained batch 390 in epoch 8, gen_loss = 0.4013704281024006, disc_loss = 0.07006487959717184
Trained batch 391 in epoch 8, gen_loss = 0.4012960636494111, disc_loss = 0.07000482651198339
Trained batch 392 in epoch 8, gen_loss = 0.40114970706194714, disc_loss = 0.06999049922060363
Trained batch 393 in epoch 8, gen_loss = 0.40123969702248646, disc_loss = 0.07003498841892587
Trained batch 394 in epoch 8, gen_loss = 0.4011942053142982, disc_loss = 0.07009829517182764
Trained batch 395 in epoch 8, gen_loss = 0.40106589023513023, disc_loss = 0.0700733552673935
Trained batch 396 in epoch 8, gen_loss = 0.4010520793628933, disc_loss = 0.07014181205512539
Trained batch 397 in epoch 8, gen_loss = 0.40092584528216163, disc_loss = 0.07068772465704318
Trained batch 398 in epoch 8, gen_loss = 0.4010227506322072, disc_loss = 0.07099977118443969
Trained batch 399 in epoch 8, gen_loss = 0.40104962065815924, disc_loss = 0.07087932301743421
Trained batch 400 in epoch 8, gen_loss = 0.4009895535775848, disc_loss = 0.07075426012261346
Trained batch 401 in epoch 8, gen_loss = 0.4008367757002513, disc_loss = 0.07074215035220673
Trained batch 402 in epoch 8, gen_loss = 0.40113053931196035, disc_loss = 0.07062230230581765
Trained batch 403 in epoch 8, gen_loss = 0.40128707310350814, disc_loss = 0.07088967094642783
Trained batch 404 in epoch 8, gen_loss = 0.4009721795717875, disc_loss = 0.07117525485436213
Trained batch 405 in epoch 8, gen_loss = 0.40097679799707064, disc_loss = 0.07103622526795204
Trained batch 406 in epoch 8, gen_loss = 0.40108144803187773, disc_loss = 0.07096689555128116
Trained batch 407 in epoch 8, gen_loss = 0.40096259840271053, disc_loss = 0.07088444015871752
Trained batch 408 in epoch 8, gen_loss = 0.40089378117932084, disc_loss = 0.07079703974751596
Trained batch 409 in epoch 8, gen_loss = 0.4008693232042034, disc_loss = 0.0707956279565512
Trained batch 410 in epoch 8, gen_loss = 0.4007511302067416, disc_loss = 0.07093862105226666
Trained batch 411 in epoch 8, gen_loss = 0.400707688291096, disc_loss = 0.07209790989957768
Trained batch 412 in epoch 8, gen_loss = 0.4007242424436112, disc_loss = 0.07209134639520423
Trained batch 413 in epoch 8, gen_loss = 0.4005959744470707, disc_loss = 0.07233767582222837
Trained batch 414 in epoch 8, gen_loss = 0.4007459343197834, disc_loss = 0.07225308061061225
Trained batch 415 in epoch 8, gen_loss = 0.4008578246889206, disc_loss = 0.0722795900571957
Trained batch 416 in epoch 8, gen_loss = 0.40084275589000695, disc_loss = 0.07214692053697754
Trained batch 417 in epoch 8, gen_loss = 0.40080437670198926, disc_loss = 0.07219634247045857
Trained batch 418 in epoch 8, gen_loss = 0.4006519066547722, disc_loss = 0.07267265568647382
Trained batch 419 in epoch 8, gen_loss = 0.40052913448640276, disc_loss = 0.07283217381031828
Trained batch 420 in epoch 8, gen_loss = 0.4005641469338161, disc_loss = 0.07291572879957844
Trained batch 421 in epoch 8, gen_loss = 0.4005427583698978, disc_loss = 0.07298589837726346
Trained batch 422 in epoch 8, gen_loss = 0.4005772233291157, disc_loss = 0.07297273033989889
Trained batch 423 in epoch 8, gen_loss = 0.40049502450340196, disc_loss = 0.07291247851252644
Trained batch 424 in epoch 8, gen_loss = 0.4007009025882272, disc_loss = 0.07286991014254882
Trained batch 425 in epoch 8, gen_loss = 0.4006059310385879, disc_loss = 0.07298819283559096
Trained batch 426 in epoch 8, gen_loss = 0.40061578810633763, disc_loss = 0.07307030253637957
Trained batch 427 in epoch 8, gen_loss = 0.40064352172835965, disc_loss = 0.07292680705682088
Trained batch 428 in epoch 8, gen_loss = 0.40064158382671416, disc_loss = 0.072819104783415
Trained batch 429 in epoch 8, gen_loss = 0.40057727271734284, disc_loss = 0.07269345430148288
Trained batch 430 in epoch 8, gen_loss = 0.4006090368167983, disc_loss = 0.0725442156494917
Trained batch 431 in epoch 8, gen_loss = 0.4006503699002443, disc_loss = 0.0726253459045741
Trained batch 432 in epoch 8, gen_loss = 0.4008297584348683, disc_loss = 0.07316928273486296
Trained batch 433 in epoch 8, gen_loss = 0.400594615304525, disc_loss = 0.07308357565241012
Trained batch 434 in epoch 8, gen_loss = 0.4005063433071663, disc_loss = 0.07312680333049904
Trained batch 435 in epoch 8, gen_loss = 0.4005539382406331, disc_loss = 0.07313147249659352
Trained batch 436 in epoch 8, gen_loss = 0.4004081179402786, disc_loss = 0.07310968900932685
Trained batch 437 in epoch 8, gen_loss = 0.4005649434104902, disc_loss = 0.07295599683309101
Trained batch 438 in epoch 8, gen_loss = 0.40042466441156654, disc_loss = 0.07284409163895239
Trained batch 439 in epoch 8, gen_loss = 0.40042721222747457, disc_loss = 0.07277515901157379
Trained batch 440 in epoch 8, gen_loss = 0.4004192204972784, disc_loss = 0.07269580235394339
Trained batch 441 in epoch 8, gen_loss = 0.40079120071225577, disc_loss = 0.07278422376391692
Trained batch 442 in epoch 8, gen_loss = 0.4009377909971414, disc_loss = 0.07274129094280572
Trained batch 443 in epoch 8, gen_loss = 0.400997679714147, disc_loss = 0.07266467704536259
Trained batch 444 in epoch 8, gen_loss = 0.4011118575428309, disc_loss = 0.07267566779262145
Trained batch 445 in epoch 8, gen_loss = 0.40118567558682017, disc_loss = 0.07255776473498515
Trained batch 446 in epoch 8, gen_loss = 0.401239577289129, disc_loss = 0.07243220753690657
Trained batch 447 in epoch 8, gen_loss = 0.40105575629110846, disc_loss = 0.07231997762314027
Trained batch 448 in epoch 8, gen_loss = 0.4011873832524221, disc_loss = 0.07222090600699368
Trained batch 449 in epoch 8, gen_loss = 0.40138870226012335, disc_loss = 0.07210516929367763
Trained batch 450 in epoch 8, gen_loss = 0.4013517339055131, disc_loss = 0.072012016770147
Trained batch 451 in epoch 8, gen_loss = 0.4013050327786302, disc_loss = 0.07192371147880496
Trained batch 452 in epoch 8, gen_loss = 0.40136533554552933, disc_loss = 0.07183825769194424
Trained batch 453 in epoch 8, gen_loss = 0.40137755030577404, disc_loss = 0.07173441032241078
Trained batch 454 in epoch 8, gen_loss = 0.40154924870847347, disc_loss = 0.07170405890741437
Trained batch 455 in epoch 8, gen_loss = 0.40146736179788906, disc_loss = 0.07190474173566735
Trained batch 456 in epoch 8, gen_loss = 0.40158506973567104, disc_loss = 0.07226657702921761
Trained batch 457 in epoch 8, gen_loss = 0.4015480182316626, disc_loss = 0.07221304942644304
Trained batch 458 in epoch 8, gen_loss = 0.40152316129804955, disc_loss = 0.07208618530770257
Trained batch 459 in epoch 8, gen_loss = 0.40154564179804014, disc_loss = 0.07200246216152269
Trained batch 460 in epoch 8, gen_loss = 0.4014473534199266, disc_loss = 0.07199604786001146
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 0.3534250855445862, disc_loss = 0.022813081741333008
Trained batch 1 in epoch 9, gen_loss = 0.39497171342372894, disc_loss = 0.05433502793312073
Trained batch 2 in epoch 9, gen_loss = 0.4139065245787303, disc_loss = 0.15470153093338013
Trained batch 3 in epoch 9, gen_loss = 0.3851643577218056, disc_loss = 0.1498895063996315
Trained batch 4 in epoch 9, gen_loss = 0.37235239148139954, disc_loss = 0.14337366372346877
Trained batch 5 in epoch 9, gen_loss = 0.37186136345068616, disc_loss = 0.14221662655472755
Trained batch 6 in epoch 9, gen_loss = 0.3872845981802259, disc_loss = 0.16348236267055785
Trained batch 7 in epoch 9, gen_loss = 0.3828943260014057, disc_loss = 0.1501066703349352
Trained batch 8 in epoch 9, gen_loss = 0.3765506512588925, disc_loss = 0.14531677961349487
Trained batch 9 in epoch 9, gen_loss = 0.37361177802085876, disc_loss = 0.13235007654875516
Trained batch 10 in epoch 9, gen_loss = 0.3691613972187042, disc_loss = 0.12178012102165005
Trained batch 11 in epoch 9, gen_loss = 0.37428203225135803, disc_loss = 0.1133067097204427
Trained batch 12 in epoch 9, gen_loss = 0.37862719480807966, disc_loss = 0.10554153572481412
Trained batch 13 in epoch 9, gen_loss = 0.38072232263428823, disc_loss = 0.10261782564754997
Trained batch 14 in epoch 9, gen_loss = 0.37769468625386554, disc_loss = 0.09950780980288983
Trained batch 15 in epoch 9, gen_loss = 0.3798385038971901, disc_loss = 0.1180598969804123
Trained batch 16 in epoch 9, gen_loss = 0.3771059635807486, disc_loss = 0.13221056244390852
Trained batch 17 in epoch 9, gen_loss = 0.38021286494202083, disc_loss = 0.13457963212082782
Trained batch 18 in epoch 9, gen_loss = 0.3805764960615258, disc_loss = 0.1348381749305286
Trained batch 19 in epoch 9, gen_loss = 0.37653950303792955, disc_loss = 0.13134429017081856
Trained batch 20 in epoch 9, gen_loss = 0.3746940039453052, disc_loss = 0.12881308377143882
Trained batch 21 in epoch 9, gen_loss = 0.373067243532701, disc_loss = 0.1242679197510535
Trained batch 22 in epoch 9, gen_loss = 0.37648870245270105, disc_loss = 0.12033142773029597
Trained batch 23 in epoch 9, gen_loss = 0.3774312771856785, disc_loss = 0.11640873543607692
Trained batch 24 in epoch 9, gen_loss = 0.37449429631233216, disc_loss = 0.11272366188466548
Trained batch 25 in epoch 9, gen_loss = 0.37253103921046626, disc_loss = 0.11181217453514154
Trained batch 26 in epoch 9, gen_loss = 0.3738372634958338, disc_loss = 0.10886757317240592
Trained batch 27 in epoch 9, gen_loss = 0.3751082218119076, disc_loss = 0.10660616182056921
Trained batch 28 in epoch 9, gen_loss = 0.3761468005591425, disc_loss = 0.1054896972431191
Trained batch 29 in epoch 9, gen_loss = 0.3800984372695287, disc_loss = 0.10359313618391752
Trained batch 30 in epoch 9, gen_loss = 0.3835875026641353, disc_loss = 0.10072475064906382
Trained batch 31 in epoch 9, gen_loss = 0.38405338395386934, disc_loss = 0.09905343007994816
Trained batch 32 in epoch 9, gen_loss = 0.38386083642641705, disc_loss = 0.09656724113632333
Trained batch 33 in epoch 9, gen_loss = 0.3854716016965754, disc_loss = 0.09406285765854751
Trained batch 34 in epoch 9, gen_loss = 0.3874243003981454, disc_loss = 0.09262715546148163
Trained batch 35 in epoch 9, gen_loss = 0.39085156718889874, disc_loss = 0.09099314589467314
Trained batch 36 in epoch 9, gen_loss = 0.38977109177692515, disc_loss = 0.08907502637924375
Trained batch 37 in epoch 9, gen_loss = 0.3892584780329152, disc_loss = 0.0898742327760709
Trained batch 38 in epoch 9, gen_loss = 0.39242851657745165, disc_loss = 0.09710198994248341
Trained batch 39 in epoch 9, gen_loss = 0.3941882349550724, disc_loss = 0.09567010272294282
Trained batch 40 in epoch 9, gen_loss = 0.3923422963154025, disc_loss = 0.0961944357287593
Trained batch 41 in epoch 9, gen_loss = 0.3918691085917609, disc_loss = 0.0942581080432449
Trained batch 42 in epoch 9, gen_loss = 0.3932897427747416, disc_loss = 0.09296346611754838
Trained batch 43 in epoch 9, gen_loss = 0.39248781922188675, disc_loss = 0.09139755626463077
Trained batch 44 in epoch 9, gen_loss = 0.3917177114221785, disc_loss = 0.09135409250027604
Trained batch 45 in epoch 9, gen_loss = 0.3918325233718623, disc_loss = 0.08976795451472634
Trained batch 46 in epoch 9, gen_loss = 0.3930449124346388, disc_loss = 0.08819707657428498
Trained batch 47 in epoch 9, gen_loss = 0.3932253246506055, disc_loss = 0.08665884746005759
Trained batch 48 in epoch 9, gen_loss = 0.39297113309101184, disc_loss = 0.08586783389731938
Trained batch 49 in epoch 9, gen_loss = 0.3913819968700409, disc_loss = 0.09095163779333233
Trained batch 50 in epoch 9, gen_loss = 0.39246539216415555, disc_loss = 0.09671488186965387
Trained batch 51 in epoch 9, gen_loss = 0.392108077613207, disc_loss = 0.09531373510925242
Trained batch 52 in epoch 9, gen_loss = 0.3904905690337127, disc_loss = 0.09568890867719673
Trained batch 53 in epoch 9, gen_loss = 0.39105487752843787, disc_loss = 0.09438891700227503
Trained batch 54 in epoch 9, gen_loss = 0.3922388867898421, disc_loss = 0.0933907176791267
Trained batch 55 in epoch 9, gen_loss = 0.3919492693884032, disc_loss = 0.09196617492541138
Trained batch 56 in epoch 9, gen_loss = 0.3934914966424306, disc_loss = 0.09078204568083349
Trained batch 57 in epoch 9, gen_loss = 0.3942355441636053, disc_loss = 0.08951835791933639
Trained batch 58 in epoch 9, gen_loss = 0.39429145647307573, disc_loss = 0.08878184648199101
Trained batch 59 in epoch 9, gen_loss = 0.3938201720515887, disc_loss = 0.09046952247930069
Trained batch 60 in epoch 9, gen_loss = 0.39599379897117615, disc_loss = 0.09451193712102096
Trained batch 61 in epoch 9, gen_loss = 0.3964218578992351, disc_loss = 0.09403038501078563
Trained batch 62 in epoch 9, gen_loss = 0.3960560839327555, disc_loss = 0.09542041894284979
Trained batch 63 in epoch 9, gen_loss = 0.3963978784158826, disc_loss = 0.09421955082507338
Trained batch 64 in epoch 9, gen_loss = 0.3967248260974884, disc_loss = 0.09335927875855794
Trained batch 65 in epoch 9, gen_loss = 0.3970675856778116, disc_loss = 0.09248881147835743
Trained batch 66 in epoch 9, gen_loss = 0.39606237811828726, disc_loss = 0.09253209933582972
Trained batch 67 in epoch 9, gen_loss = 0.39649881159558015, disc_loss = 0.09142813364536885
Trained batch 68 in epoch 9, gen_loss = 0.3967292939407238, disc_loss = 0.09154394823733879
Trained batch 69 in epoch 9, gen_loss = 0.39584059374673025, disc_loss = 0.09084673527894276
Trained batch 70 in epoch 9, gen_loss = 0.3958060153773133, disc_loss = 0.08976316461208421
Trained batch 71 in epoch 9, gen_loss = 0.3964349706139829, disc_loss = 0.08905424931759222
Trained batch 72 in epoch 9, gen_loss = 0.39570297566178725, disc_loss = 0.0930005337354051
Trained batch 73 in epoch 9, gen_loss = 0.3958455138915294, disc_loss = 0.09526275469594307
Trained batch 74 in epoch 9, gen_loss = 0.3969302694002787, disc_loss = 0.09675467221687238
Trained batch 75 in epoch 9, gen_loss = 0.3972411481173415, disc_loss = 0.09682284127675782
Trained batch 76 in epoch 9, gen_loss = 0.3961959183216095, disc_loss = 0.09721384099503229
Trained batch 77 in epoch 9, gen_loss = 0.3962174164943206, disc_loss = 0.09703727743516748
Trained batch 78 in epoch 9, gen_loss = 0.39621767213072956, disc_loss = 0.09663687654641233
Trained batch 79 in epoch 9, gen_loss = 0.39652579203248023, disc_loss = 0.09587841996690258
Trained batch 80 in epoch 9, gen_loss = 0.39608951814380694, disc_loss = 0.09555516432234902
Trained batch 81 in epoch 9, gen_loss = 0.39611498393663547, disc_loss = 0.09559557317733401
Trained batch 82 in epoch 9, gen_loss = 0.39564845684063005, disc_loss = 0.09618257707635681
Trained batch 83 in epoch 9, gen_loss = 0.39606640345993493, disc_loss = 0.09516721714421042
Trained batch 84 in epoch 9, gen_loss = 0.39690633977160733, disc_loss = 0.09771476982928375
Trained batch 85 in epoch 9, gen_loss = 0.39569356275159256, disc_loss = 0.09731058662670643
Trained batch 86 in epoch 9, gen_loss = 0.3947683213085964, disc_loss = 0.09720556017268321
Trained batch 87 in epoch 9, gen_loss = 0.39519416066733276, disc_loss = 0.0974669927963987
Trained batch 88 in epoch 9, gen_loss = 0.39506239402160215, disc_loss = 0.09714892932496379
Trained batch 89 in epoch 9, gen_loss = 0.3946295377280977, disc_loss = 0.09906931642649902
Trained batch 90 in epoch 9, gen_loss = 0.3945389406366663, disc_loss = 0.09877269042676294
Trained batch 91 in epoch 9, gen_loss = 0.39460177751986875, disc_loss = 0.100766600706898
Trained batch 92 in epoch 9, gen_loss = 0.39450321915329145, disc_loss = 0.10099627797602005
Trained batch 93 in epoch 9, gen_loss = 0.39450092740515447, disc_loss = 0.10169379649921617
Trained batch 94 in epoch 9, gen_loss = 0.3951057609758879, disc_loss = 0.10194838626408263
Trained batch 95 in epoch 9, gen_loss = 0.39478114744027454, disc_loss = 0.10152507917761493
Trained batch 96 in epoch 9, gen_loss = 0.3955384904576331, disc_loss = 0.1009621565162982
Trained batch 97 in epoch 9, gen_loss = 0.39586229531132444, disc_loss = 0.10026775307155081
Trained batch 98 in epoch 9, gen_loss = 0.3947328979318792, disc_loss = 0.10043889682062647
Trained batch 99 in epoch 9, gen_loss = 0.3948909467458725, disc_loss = 0.10188391110859811
Trained batch 100 in epoch 9, gen_loss = 0.3948017695162556, disc_loss = 0.10185566831306361
Trained batch 101 in epoch 9, gen_loss = 0.3936954365641463, disc_loss = 0.10212697825558922
Trained batch 102 in epoch 9, gen_loss = 0.39282070606657604, disc_loss = 0.10161122107353893
Trained batch 103 in epoch 9, gen_loss = 0.39223302614230376, disc_loss = 0.1012378417295762
Trained batch 104 in epoch 9, gen_loss = 0.3915089102018447, disc_loss = 0.10064698052370832
Trained batch 105 in epoch 9, gen_loss = 0.391325296377236, disc_loss = 0.10014031260748799
Trained batch 106 in epoch 9, gen_loss = 0.3915868610422188, disc_loss = 0.09946920368472272
Trained batch 107 in epoch 9, gen_loss = 0.39177957480704345, disc_loss = 0.09861241384512848
Trained batch 108 in epoch 9, gen_loss = 0.39162831787669333, disc_loss = 0.0982445067632089
Trained batch 109 in epoch 9, gen_loss = 0.3922735235907815, disc_loss = 0.0984672952782024
Trained batch 110 in epoch 9, gen_loss = 0.391805924273826, disc_loss = 0.10018683392722327
Trained batch 111 in epoch 9, gen_loss = 0.39243779783802374, disc_loss = 0.10043246205896139
Trained batch 112 in epoch 9, gen_loss = 0.3932539691439772, disc_loss = 0.09985111172484086
Trained batch 113 in epoch 9, gen_loss = 0.39325961339892, disc_loss = 0.09940701817864911
Trained batch 114 in epoch 9, gen_loss = 0.3926148313543071, disc_loss = 0.09885520575487096
Trained batch 115 in epoch 9, gen_loss = 0.39345893289508493, disc_loss = 0.09809101435580644
Trained batch 116 in epoch 9, gen_loss = 0.3934401217688862, disc_loss = 0.09737183908239389
Trained batch 117 in epoch 9, gen_loss = 0.39354175910101097, disc_loss = 0.09665571998457535
Trained batch 118 in epoch 9, gen_loss = 0.39340496288628135, disc_loss = 0.095918427644094
Trained batch 119 in epoch 9, gen_loss = 0.393586449076732, disc_loss = 0.09575919939670711
Trained batch 120 in epoch 9, gen_loss = 0.39354688224713663, disc_loss = 0.09512566564958697
Trained batch 121 in epoch 9, gen_loss = 0.39345052252050305, disc_loss = 0.09481865539383448
Trained batch 122 in epoch 9, gen_loss = 0.39230283561760815, disc_loss = 0.09510500249793617
Trained batch 123 in epoch 9, gen_loss = 0.39228838009219014, disc_loss = 0.09485487242589795
Trained batch 124 in epoch 9, gen_loss = 0.3917772660255432, disc_loss = 0.09482201706618071
Trained batch 125 in epoch 9, gen_loss = 0.39191399869464694, disc_loss = 0.0956816339702715
Trained batch 126 in epoch 9, gen_loss = 0.3918703869571836, disc_loss = 0.09698428318461799
Trained batch 127 in epoch 9, gen_loss = 0.3930245926603675, disc_loss = 0.09701319724990753
Trained batch 128 in epoch 9, gen_loss = 0.39252130698788074, disc_loss = 0.09648356620626625
Trained batch 129 in epoch 9, gen_loss = 0.39237847970082207, disc_loss = 0.09586816101263348
Trained batch 130 in epoch 9, gen_loss = 0.3919862870496648, disc_loss = 0.09583705519361578
Trained batch 131 in epoch 9, gen_loss = 0.3926329172470353, disc_loss = 0.09584810441557431
Trained batch 132 in epoch 9, gen_loss = 0.39230770029519735, disc_loss = 0.09518495390079636
Trained batch 133 in epoch 9, gen_loss = 0.3921469478909649, disc_loss = 0.09469132125725163
Trained batch 134 in epoch 9, gen_loss = 0.392128770660471, disc_loss = 0.09409613702791157
Trained batch 135 in epoch 9, gen_loss = 0.39225145385545845, disc_loss = 0.09368666726753444
Trained batch 136 in epoch 9, gen_loss = 0.39220067184336865, disc_loss = 0.09362640693770165
Trained batch 137 in epoch 9, gen_loss = 0.3926947946133821, disc_loss = 0.09405673489285012
Trained batch 138 in epoch 9, gen_loss = 0.3918386155324017, disc_loss = 0.09470243269256015
Trained batch 139 in epoch 9, gen_loss = 0.3923428822840963, disc_loss = 0.0944449827041743
Trained batch 140 in epoch 9, gen_loss = 0.39225065644751206, disc_loss = 0.09411315772854162
Trained batch 141 in epoch 9, gen_loss = 0.39185718100675393, disc_loss = 0.09414838794553258
Trained batch 142 in epoch 9, gen_loss = 0.39216329376180686, disc_loss = 0.0935766776157478
Trained batch 143 in epoch 9, gen_loss = 0.39238742407825256, disc_loss = 0.09386397846780407
Trained batch 144 in epoch 9, gen_loss = 0.3919727345992779, disc_loss = 0.09533295477579894
Trained batch 145 in epoch 9, gen_loss = 0.39196184277534485, disc_loss = 0.09499318630128384
Trained batch 146 in epoch 9, gen_loss = 0.3918843889723019, disc_loss = 0.09484057845927928
Trained batch 147 in epoch 9, gen_loss = 0.39183207319394964, disc_loss = 0.09441150410566479
Trained batch 148 in epoch 9, gen_loss = 0.3917789957267326, disc_loss = 0.0940801307040223
Trained batch 149 in epoch 9, gen_loss = 0.3915575834115346, disc_loss = 0.09423044490627945
Trained batch 150 in epoch 9, gen_loss = 0.3923892674856628, disc_loss = 0.09549397908903609
Trained batch 151 in epoch 9, gen_loss = 0.39233461610580744, disc_loss = 0.09507885803529796
Trained batch 152 in epoch 9, gen_loss = 0.3918103887364755, disc_loss = 0.09544102694486188
Trained batch 153 in epoch 9, gen_loss = 0.39214563563272553, disc_loss = 0.09540654324878056
Trained batch 154 in epoch 9, gen_loss = 0.39237973151668426, disc_loss = 0.09493619493479209
Trained batch 155 in epoch 9, gen_loss = 0.3927061017125081, disc_loss = 0.09444768896672684
Trained batch 156 in epoch 9, gen_loss = 0.39283055275868456, disc_loss = 0.09393531504342226
Trained batch 157 in epoch 9, gen_loss = 0.3934794679472718, disc_loss = 0.09360538378558299
Trained batch 158 in epoch 9, gen_loss = 0.3934172324414523, disc_loss = 0.09336992875971603
Trained batch 159 in epoch 9, gen_loss = 0.39371521957218647, disc_loss = 0.09332890694786329
Trained batch 160 in epoch 9, gen_loss = 0.393689630379588, disc_loss = 0.09285359809128857
Trained batch 161 in epoch 9, gen_loss = 0.39352996996891354, disc_loss = 0.09286568909711032
Trained batch 162 in epoch 9, gen_loss = 0.3937863985453647, disc_loss = 0.09420063961697228
Trained batch 163 in epoch 9, gen_loss = 0.3937922243664904, disc_loss = 0.09373529660004395
Trained batch 164 in epoch 9, gen_loss = 0.39342852559956637, disc_loss = 0.0932818989890317
Trained batch 165 in epoch 9, gen_loss = 0.3932763813848955, disc_loss = 0.09284782109232283
Trained batch 166 in epoch 9, gen_loss = 0.3936558044599202, disc_loss = 0.0924176250216356
Trained batch 167 in epoch 9, gen_loss = 0.39376663310187204, disc_loss = 0.09194187317985952
Trained batch 168 in epoch 9, gen_loss = 0.39377820632866856, disc_loss = 0.09149660404011078
Trained batch 169 in epoch 9, gen_loss = 0.3936936383738237, disc_loss = 0.09106706164174658
Trained batch 170 in epoch 9, gen_loss = 0.3936063760553884, disc_loss = 0.091080173133867
Trained batch 171 in epoch 9, gen_loss = 0.39428970027108523, disc_loss = 0.09256199320919033
Trained batch 172 in epoch 9, gen_loss = 0.3946971752050984, disc_loss = 0.09216398842945006
Trained batch 173 in epoch 9, gen_loss = 0.39505759172741023, disc_loss = 0.09189171288644188
Trained batch 174 in epoch 9, gen_loss = 0.39487487060683113, disc_loss = 0.09145552571064659
Trained batch 175 in epoch 9, gen_loss = 0.39484932222826913, disc_loss = 0.09102730700396933
Trained batch 176 in epoch 9, gen_loss = 0.3948682763818967, disc_loss = 0.09054201665613273
Trained batch 177 in epoch 9, gen_loss = 0.3948945277527477, disc_loss = 0.09006289296438184
Trained batch 178 in epoch 9, gen_loss = 0.39512720004806307, disc_loss = 0.08964929729700089
Trained batch 179 in epoch 9, gen_loss = 0.39529789437850316, disc_loss = 0.08918620813637972
Trained batch 180 in epoch 9, gen_loss = 0.3955454398255322, disc_loss = 0.08871864016265582
Trained batch 181 in epoch 9, gen_loss = 0.3955976768181874, disc_loss = 0.08828171684693259
Trained batch 182 in epoch 9, gen_loss = 0.39541643825385087, disc_loss = 0.08785469455216996
Trained batch 183 in epoch 9, gen_loss = 0.3952254546077355, disc_loss = 0.08750787079486105
Trained batch 184 in epoch 9, gen_loss = 0.39552256754926735, disc_loss = 0.08719016397875305
Trained batch 185 in epoch 9, gen_loss = 0.39531088532299125, disc_loss = 0.08684170157748765
Trained batch 186 in epoch 9, gen_loss = 0.3948529260681275, disc_loss = 0.08837810851743116
Trained batch 187 in epoch 9, gen_loss = 0.3951067493316975, disc_loss = 0.08894838091293152
Trained batch 188 in epoch 9, gen_loss = 0.3952919370913632, disc_loss = 0.08862827481485154
Trained batch 189 in epoch 9, gen_loss = 0.39517197012901306, disc_loss = 0.08839530105408477
Trained batch 190 in epoch 9, gen_loss = 0.3954205449026917, disc_loss = 0.08798642024758677
Trained batch 191 in epoch 9, gen_loss = 0.3955202621097366, disc_loss = 0.08759857104693462
Trained batch 192 in epoch 9, gen_loss = 0.39561110935680605, disc_loss = 0.08731044878835736
Trained batch 193 in epoch 9, gen_loss = 0.39569857593664187, disc_loss = 0.08689866530632158
Trained batch 194 in epoch 9, gen_loss = 0.3960493876383855, disc_loss = 0.08659833707631781
Trained batch 195 in epoch 9, gen_loss = 0.3964586428233555, disc_loss = 0.08623212327638984
Trained batch 196 in epoch 9, gen_loss = 0.3966744136689278, disc_loss = 0.08582165267857425
Trained batch 197 in epoch 9, gen_loss = 0.39673571484257475, disc_loss = 0.08547671269766535
Trained batch 198 in epoch 9, gen_loss = 0.396832377766844, disc_loss = 0.08519014765522513
Trained batch 199 in epoch 9, gen_loss = 0.39655899375677106, disc_loss = 0.08549560596002266
Trained batch 200 in epoch 9, gen_loss = 0.39727348563682974, disc_loss = 0.08688202653015356
Trained batch 201 in epoch 9, gen_loss = 0.39740933669675693, disc_loss = 0.08658252821285461
Trained batch 202 in epoch 9, gen_loss = 0.3973340280537535, disc_loss = 0.08676748325259154
Trained batch 203 in epoch 9, gen_loss = 0.397353063027064, disc_loss = 0.08643865573229086
Trained batch 204 in epoch 9, gen_loss = 0.3976922570205316, disc_loss = 0.08622452788191234
Trained batch 205 in epoch 9, gen_loss = 0.3978559011683881, disc_loss = 0.08583379638815317
Trained batch 206 in epoch 9, gen_loss = 0.3977609020500367, disc_loss = 0.08545264537594673
Trained batch 207 in epoch 9, gen_loss = 0.39727836116575277, disc_loss = 0.08531493744409929
Trained batch 208 in epoch 9, gen_loss = 0.3972173353131308, disc_loss = 0.08499215976179145
Trained batch 209 in epoch 9, gen_loss = 0.39721061984697975, disc_loss = 0.08502945465124434
Trained batch 210 in epoch 9, gen_loss = 0.39700619417344224, disc_loss = 0.08630397567807993
Trained batch 211 in epoch 9, gen_loss = 0.39711941694313624, disc_loss = 0.08619535842444748
Trained batch 212 in epoch 9, gen_loss = 0.39739726406867515, disc_loss = 0.08599364143433355
Trained batch 213 in epoch 9, gen_loss = 0.3972471796463583, disc_loss = 0.08573156783017809
Trained batch 214 in epoch 9, gen_loss = 0.3972162878790567, disc_loss = 0.0854126209241533
Trained batch 215 in epoch 9, gen_loss = 0.39705139909077575, disc_loss = 0.08508379627407218
Trained batch 216 in epoch 9, gen_loss = 0.3968914718397202, disc_loss = 0.08474585466507462
Trained batch 217 in epoch 9, gen_loss = 0.396633042518152, disc_loss = 0.0847877668443247
Trained batch 218 in epoch 9, gen_loss = 0.39676117162181906, disc_loss = 0.08567157385394522
Trained batch 219 in epoch 9, gen_loss = 0.39682776873761955, disc_loss = 0.08539527958809313
Trained batch 220 in epoch 9, gen_loss = 0.39697551956543553, disc_loss = 0.08537995204439058
Trained batch 221 in epoch 9, gen_loss = 0.39728009767897493, disc_loss = 0.08534514826202245
Trained batch 222 in epoch 9, gen_loss = 0.39716525476075076, disc_loss = 0.08515255999513338
Trained batch 223 in epoch 9, gen_loss = 0.39685892978949205, disc_loss = 0.08514300711561061
Trained batch 224 in epoch 9, gen_loss = 0.39688998341560366, disc_loss = 0.08543553846784764
Trained batch 225 in epoch 9, gen_loss = 0.3964075840416208, disc_loss = 0.08553616387101995
Trained batch 226 in epoch 9, gen_loss = 0.3962642209120259, disc_loss = 0.08532016157554176
Trained batch 227 in epoch 9, gen_loss = 0.39654964888304994, disc_loss = 0.08505303111425683
Trained batch 228 in epoch 9, gen_loss = 0.39670372191474945, disc_loss = 0.0850815874459344
Trained batch 229 in epoch 9, gen_loss = 0.39649940495905667, disc_loss = 0.08497426638825108
Trained batch 230 in epoch 9, gen_loss = 0.396308379255848, disc_loss = 0.08477035183580471
Trained batch 231 in epoch 9, gen_loss = 0.3964434350872862, disc_loss = 0.08449909397890663
Trained batch 232 in epoch 9, gen_loss = 0.39655588151559296, disc_loss = 0.08427084389426485
Trained batch 233 in epoch 9, gen_loss = 0.3962677802540298, disc_loss = 0.08422742292292926
Trained batch 234 in epoch 9, gen_loss = 0.3958599038580631, disc_loss = 0.0840953519548032
Trained batch 235 in epoch 9, gen_loss = 0.3958463779950546, disc_loss = 0.08396707227556192
Trained batch 236 in epoch 9, gen_loss = 0.39617845805888435, disc_loss = 0.08449155851640593
Trained batch 237 in epoch 9, gen_loss = 0.3961717039346695, disc_loss = 0.0842326138219444
Trained batch 238 in epoch 9, gen_loss = 0.3960413531279464, disc_loss = 0.08396044720517604
Trained batch 239 in epoch 9, gen_loss = 0.3961162310093641, disc_loss = 0.08368252050325585
Trained batch 240 in epoch 9, gen_loss = 0.3964836094141996, disc_loss = 0.08344423177524536
Trained batch 241 in epoch 9, gen_loss = 0.39635224972874666, disc_loss = 0.0831568741358909
Trained batch 242 in epoch 9, gen_loss = 0.3964758802343298, disc_loss = 0.08302251777876123
Trained batch 243 in epoch 9, gen_loss = 0.3967150799075111, disc_loss = 0.08309123424820786
Trained batch 244 in epoch 9, gen_loss = 0.39632098565296253, disc_loss = 0.08319340996938396
Trained batch 245 in epoch 9, gen_loss = 0.3964913039188075, disc_loss = 0.0830533734155531
Trained batch 246 in epoch 9, gen_loss = 0.3964334077198013, disc_loss = 0.08277133409393883
Trained batch 247 in epoch 9, gen_loss = 0.3961908807677607, disc_loss = 0.08299881689092745
Trained batch 248 in epoch 9, gen_loss = 0.3962423672159034, disc_loss = 0.0838126529468201
Trained batch 249 in epoch 9, gen_loss = 0.39622349202632906, disc_loss = 0.08370951977930963
Trained batch 250 in epoch 9, gen_loss = 0.3957939058898455, disc_loss = 0.08423212993392847
Trained batch 251 in epoch 9, gen_loss = 0.3958819463612541, disc_loss = 0.08407469251052668
Trained batch 252 in epoch 9, gen_loss = 0.39607172002905444, disc_loss = 0.08396788679703834
Trained batch 253 in epoch 9, gen_loss = 0.3958779571093912, disc_loss = 0.08377492729039114
Trained batch 254 in epoch 9, gen_loss = 0.39581580933402566, disc_loss = 0.08352871737899441
Trained batch 255 in epoch 9, gen_loss = 0.3957347902469337, disc_loss = 0.08327119192654209
Trained batch 256 in epoch 9, gen_loss = 0.3956340623272996, disc_loss = 0.08351573313800219
Trained batch 257 in epoch 9, gen_loss = 0.3951578664687253, disc_loss = 0.08489901913770352
Trained batch 258 in epoch 9, gen_loss = 0.3947798670719029, disc_loss = 0.08552118704895198
Trained batch 259 in epoch 9, gen_loss = 0.39482824687774365, disc_loss = 0.08592641577661897
Trained batch 260 in epoch 9, gen_loss = 0.3947167594085708, disc_loss = 0.08629793437354809
Trained batch 261 in epoch 9, gen_loss = 0.39478670856879866, disc_loss = 0.08654540061118891
Trained batch 262 in epoch 9, gen_loss = 0.39427120898613005, disc_loss = 0.08681810191680213
Trained batch 263 in epoch 9, gen_loss = 0.39392321172988776, disc_loss = 0.08696275515390109
Trained batch 264 in epoch 9, gen_loss = 0.39390957782853325, disc_loss = 0.08716454062224278
Trained batch 265 in epoch 9, gen_loss = 0.3939584216901234, disc_loss = 0.08708768047189298
Trained batch 266 in epoch 9, gen_loss = 0.3941640031248443, disc_loss = 0.0869268073930583
Trained batch 267 in epoch 9, gen_loss = 0.3941872723734201, disc_loss = 0.08680614416744671
Trained batch 268 in epoch 9, gen_loss = 0.3941278250465606, disc_loss = 0.08691833167402663
Trained batch 269 in epoch 9, gen_loss = 0.3941462097344575, disc_loss = 0.08695898143471115
Trained batch 270 in epoch 9, gen_loss = 0.3939869245479907, disc_loss = 0.08722935610612326
Trained batch 271 in epoch 9, gen_loss = 0.39399026400026155, disc_loss = 0.08737993979080141
Trained batch 272 in epoch 9, gen_loss = 0.3937860812459673, disc_loss = 0.0873850329315133
Trained batch 273 in epoch 9, gen_loss = 0.39347831535078315, disc_loss = 0.08748187034146139
Trained batch 274 in epoch 9, gen_loss = 0.3933275657350367, disc_loss = 0.0876645488816906
Trained batch 275 in epoch 9, gen_loss = 0.3932425379753113, disc_loss = 0.08748874097110947
Trained batch 276 in epoch 9, gen_loss = 0.3934068396848892, disc_loss = 0.08745715088490061
Trained batch 277 in epoch 9, gen_loss = 0.39342671654207245, disc_loss = 0.0878855036286865
Trained batch 278 in epoch 9, gen_loss = 0.3933985945785345, disc_loss = 0.08921659795740973
Trained batch 279 in epoch 9, gen_loss = 0.39321976006031034, disc_loss = 0.08943573887559718
Trained batch 280 in epoch 9, gen_loss = 0.39334326070398623, disc_loss = 0.09079223151858962
Trained batch 281 in epoch 9, gen_loss = 0.3930551795460654, disc_loss = 0.09117760410671064
Trained batch 282 in epoch 9, gen_loss = 0.3926400541206131, disc_loss = 0.09130364089592133
Trained batch 283 in epoch 9, gen_loss = 0.3924066665726648, disc_loss = 0.09142522284806981
Trained batch 284 in epoch 9, gen_loss = 0.3924164021224306, disc_loss = 0.09134115353716832
Trained batch 285 in epoch 9, gen_loss = 0.3921471278775822, disc_loss = 0.09125436260690586
Trained batch 286 in epoch 9, gen_loss = 0.3924773921119211, disc_loss = 0.09148534428075164
Trained batch 287 in epoch 9, gen_loss = 0.3924374563826455, disc_loss = 0.0914930194638954
Trained batch 288 in epoch 9, gen_loss = 0.3924230715601502, disc_loss = 0.0912247524100475
Trained batch 289 in epoch 9, gen_loss = 0.39242929826522693, disc_loss = 0.09107795153937207
Trained batch 290 in epoch 9, gen_loss = 0.392115178181953, disc_loss = 0.0910488774094257
Trained batch 291 in epoch 9, gen_loss = 0.39223181425708614, disc_loss = 0.09088709526089314
Trained batch 292 in epoch 9, gen_loss = 0.39208189253107273, disc_loss = 0.09070562532349608
Trained batch 293 in epoch 9, gen_loss = 0.3920055249718582, disc_loss = 0.0905399221062128
Trained batch 294 in epoch 9, gen_loss = 0.3919338453624208, disc_loss = 0.09034872862463028
Trained batch 295 in epoch 9, gen_loss = 0.3918211741020551, disc_loss = 0.09023838585110482
Trained batch 296 in epoch 9, gen_loss = 0.391862637165821, disc_loss = 0.09055240416385058
Trained batch 297 in epoch 9, gen_loss = 0.391652413662648, disc_loss = 0.09121540378022865
Trained batch 298 in epoch 9, gen_loss = 0.3913834531570358, disc_loss = 0.091352340062912
Trained batch 299 in epoch 9, gen_loss = 0.39179505785306296, disc_loss = 0.09196595369993399
Trained batch 300 in epoch 9, gen_loss = 0.39156000885456504, disc_loss = 0.09196382923596276
Trained batch 301 in epoch 9, gen_loss = 0.3914344556481633, disc_loss = 0.09182549282038795
Trained batch 302 in epoch 9, gen_loss = 0.3913405249417812, disc_loss = 0.09158887575678651
Trained batch 303 in epoch 9, gen_loss = 0.3913369214064197, disc_loss = 0.09154943251020373
Trained batch 304 in epoch 9, gen_loss = 0.3912898256153357, disc_loss = 0.09180268930332339
Trained batch 305 in epoch 9, gen_loss = 0.39152807922534694, disc_loss = 0.09224804112645098
Trained batch 306 in epoch 9, gen_loss = 0.39145318848302385, disc_loss = 0.0921681701381621
Trained batch 307 in epoch 9, gen_loss = 0.3914340796408715, disc_loss = 0.09240510381679595
Trained batch 308 in epoch 9, gen_loss = 0.3917349295322949, disc_loss = 0.09238728132659516
Trained batch 309 in epoch 9, gen_loss = 0.39200493328032954, disc_loss = 0.09258973213183062
Trained batch 310 in epoch 9, gen_loss = 0.39182509659187587, disc_loss = 0.09273330320325647
Trained batch 311 in epoch 9, gen_loss = 0.3917136848545991, disc_loss = 0.09246905909654182
Trained batch 312 in epoch 9, gen_loss = 0.39162887647129097, disc_loss = 0.09221837863165397
Trained batch 313 in epoch 9, gen_loss = 0.39168111628787533, disc_loss = 0.09209392590679608
Trained batch 314 in epoch 9, gen_loss = 0.3916119298291585, disc_loss = 0.09237236329280431
Trained batch 315 in epoch 9, gen_loss = 0.3921060608346251, disc_loss = 0.09284041223817659
Trained batch 316 in epoch 9, gen_loss = 0.3919582637702629, disc_loss = 0.09269500706691518
Trained batch 317 in epoch 9, gen_loss = 0.3919881870911556, disc_loss = 0.09265768991449391
Trained batch 318 in epoch 9, gen_loss = 0.3919401815318762, disc_loss = 0.09295486861571296
Trained batch 319 in epoch 9, gen_loss = 0.3915972580201924, disc_loss = 0.09287427421222674
Trained batch 320 in epoch 9, gen_loss = 0.3914986388334233, disc_loss = 0.09262639216388173
Trained batch 321 in epoch 9, gen_loss = 0.39162667095661163, disc_loss = 0.09244946905943964
Trained batch 322 in epoch 9, gen_loss = 0.391581561174186, disc_loss = 0.09226305309492783
Trained batch 323 in epoch 9, gen_loss = 0.39145185080943284, disc_loss = 0.09210065617312298
Trained batch 324 in epoch 9, gen_loss = 0.3917271028115199, disc_loss = 0.09203455930289167
Trained batch 325 in epoch 9, gen_loss = 0.3916728177502111, disc_loss = 0.09189748749896838
Trained batch 326 in epoch 9, gen_loss = 0.39158835715474705, disc_loss = 0.09169464079458095
Trained batch 327 in epoch 9, gen_loss = 0.39158586112827787, disc_loss = 0.09144804044200744
Trained batch 328 in epoch 9, gen_loss = 0.391715595243912, disc_loss = 0.0912250125947717
Trained batch 329 in epoch 9, gen_loss = 0.3918419789184224, disc_loss = 0.09121831059596981
Trained batch 330 in epoch 9, gen_loss = 0.39238336511248906, disc_loss = 0.09132229512152219
Trained batch 331 in epoch 9, gen_loss = 0.39243218132171287, disc_loss = 0.09109435112254852
Trained batch 332 in epoch 9, gen_loss = 0.3922420890481622, disc_loss = 0.09102089954372328
Trained batch 333 in epoch 9, gen_loss = 0.39240576853295284, disc_loss = 0.0907858391640942
Trained batch 334 in epoch 9, gen_loss = 0.3927064993488255, disc_loss = 0.09060466810921902
Trained batch 335 in epoch 9, gen_loss = 0.39284428927515236, disc_loss = 0.09041578431719072
Trained batch 336 in epoch 9, gen_loss = 0.39273908132969093, disc_loss = 0.09035205770731636
Trained batch 337 in epoch 9, gen_loss = 0.3930751777435901, disc_loss = 0.09017299198732882
Trained batch 338 in epoch 9, gen_loss = 0.39325548932615634, disc_loss = 0.08999236883969214
Trained batch 339 in epoch 9, gen_loss = 0.39321760789436455, disc_loss = 0.09043014941271395
Trained batch 340 in epoch 9, gen_loss = 0.39340997843448716, disc_loss = 0.09141534643214949
Trained batch 341 in epoch 9, gen_loss = 0.39357730589414897, disc_loss = 0.09138329651571636
Trained batch 342 in epoch 9, gen_loss = 0.3934599788473924, disc_loss = 0.0913880563628895
Trained batch 343 in epoch 9, gen_loss = 0.39338571067119754, disc_loss = 0.09130391928903368
Trained batch 344 in epoch 9, gen_loss = 0.39331007133359497, disc_loss = 0.09108365947866569
Trained batch 345 in epoch 9, gen_loss = 0.393249162962671, disc_loss = 0.09087027969899335
Trained batch 346 in epoch 9, gen_loss = 0.3932386747526504, disc_loss = 0.09066930634267521
Trained batch 347 in epoch 9, gen_loss = 0.39312810887550487, disc_loss = 0.09071489768076003
Trained batch 348 in epoch 9, gen_loss = 0.39319003584733325, disc_loss = 0.09107469592142028
Trained batch 349 in epoch 9, gen_loss = 0.3930515262910298, disc_loss = 0.09170841670329018
Trained batch 350 in epoch 9, gen_loss = 0.39313848185063766, disc_loss = 0.09188894704488396
Trained batch 351 in epoch 9, gen_loss = 0.3931054849685593, disc_loss = 0.09191806580400391
Trained batch 352 in epoch 9, gen_loss = 0.39289025671083594, disc_loss = 0.09205657171834757
Trained batch 353 in epoch 9, gen_loss = 0.39287448956468013, disc_loss = 0.09235686594015251
Trained batch 354 in epoch 9, gen_loss = 0.39306466126106154, disc_loss = 0.09271490552764333
Trained batch 355 in epoch 9, gen_loss = 0.39297868554176907, disc_loss = 0.09251283937829724
Trained batch 356 in epoch 9, gen_loss = 0.3927584723765109, disc_loss = 0.0924972305765652
Trained batch 357 in epoch 9, gen_loss = 0.39260789868551926, disc_loss = 0.0923233184659094
Trained batch 358 in epoch 9, gen_loss = 0.3923807397360257, disc_loss = 0.09216785236731338
Trained batch 359 in epoch 9, gen_loss = 0.3923100526134173, disc_loss = 0.09198781182446207
Trained batch 360 in epoch 9, gen_loss = 0.3922762543871132, disc_loss = 0.09191973376219416
Trained batch 361 in epoch 9, gen_loss = 0.3920860195851458, disc_loss = 0.09216522755621011
Trained batch 362 in epoch 9, gen_loss = 0.39229039507135544, disc_loss = 0.09314956420457847
Trained batch 363 in epoch 9, gen_loss = 0.39228108942836193, disc_loss = 0.09345263902706882
Trained batch 364 in epoch 9, gen_loss = 0.3920961075449643, disc_loss = 0.09358314713463187
Trained batch 365 in epoch 9, gen_loss = 0.391994683387501, disc_loss = 0.09362987849143807
Trained batch 366 in epoch 9, gen_loss = 0.391911797205174, disc_loss = 0.09374302236759167
Trained batch 367 in epoch 9, gen_loss = 0.39198771378268366, disc_loss = 0.09373635153726513
Trained batch 368 in epoch 9, gen_loss = 0.3920070538675882, disc_loss = 0.0935696771603108
Trained batch 369 in epoch 9, gen_loss = 0.39201476630326865, disc_loss = 0.0934112450447739
Trained batch 370 in epoch 9, gen_loss = 0.39196725498955204, disc_loss = 0.09318492153779957
Trained batch 371 in epoch 9, gen_loss = 0.3919818137762367, disc_loss = 0.09295331134075319
Trained batch 372 in epoch 9, gen_loss = 0.3921106929913283, disc_loss = 0.09273320609883433
Trained batch 373 in epoch 9, gen_loss = 0.39217510014613044, disc_loss = 0.09255321869342763
Trained batch 374 in epoch 9, gen_loss = 0.39237187639872234, disc_loss = 0.09293560762827595
Trained batch 375 in epoch 9, gen_loss = 0.3922102849217171, disc_loss = 0.09375328645531207
Trained batch 376 in epoch 9, gen_loss = 0.39210976237327416, disc_loss = 0.09377145581070917
Trained batch 377 in epoch 9, gen_loss = 0.3923081914110789, disc_loss = 0.09395205177903845
Trained batch 378 in epoch 9, gen_loss = 0.3923139193913553, disc_loss = 0.09401147767021702
Trained batch 379 in epoch 9, gen_loss = 0.39238018973877553, disc_loss = 0.09400375249771108
Trained batch 380 in epoch 9, gen_loss = 0.39209535858762545, disc_loss = 0.09438353107772826
Trained batch 381 in epoch 9, gen_loss = 0.39225172044719075, disc_loss = 0.09426659859195156
Trained batch 382 in epoch 9, gen_loss = 0.3922217233062724, disc_loss = 0.09418992082133655
Trained batch 383 in epoch 9, gen_loss = 0.39209509431384504, disc_loss = 0.09440587277276791
Trained batch 384 in epoch 9, gen_loss = 0.39214210409622685, disc_loss = 0.09442486426877704
Trained batch 385 in epoch 9, gen_loss = 0.392097580386567, disc_loss = 0.09429119694905616
Trained batch 386 in epoch 9, gen_loss = 0.39199029144082576, disc_loss = 0.09415994157764378
Trained batch 387 in epoch 9, gen_loss = 0.39194830430229916, disc_loss = 0.0940212048938229
Trained batch 388 in epoch 9, gen_loss = 0.3920405715474126, disc_loss = 0.09381901996526244
Trained batch 389 in epoch 9, gen_loss = 0.39206819243920155, disc_loss = 0.0936382533922696
Trained batch 390 in epoch 9, gen_loss = 0.39209423048416975, disc_loss = 0.09341869572096545
Trained batch 391 in epoch 9, gen_loss = 0.3917778627756907, disc_loss = 0.09325818713915972
Trained batch 392 in epoch 9, gen_loss = 0.3917568749902206, disc_loss = 0.0932536615087217
Trained batch 393 in epoch 9, gen_loss = 0.39178185535566457, disc_loss = 0.0931879354257912
Trained batch 394 in epoch 9, gen_loss = 0.39195202717298194, disc_loss = 0.09343457097729928
Trained batch 395 in epoch 9, gen_loss = 0.39177853072231467, disc_loss = 0.09333939058470982
Trained batch 396 in epoch 9, gen_loss = 0.39181208700617254, disc_loss = 0.09319430975576568
Trained batch 397 in epoch 9, gen_loss = 0.39190185833815955, disc_loss = 0.09304405436453284
Trained batch 398 in epoch 9, gen_loss = 0.39189530270440237, disc_loss = 0.0929479324900753
Trained batch 399 in epoch 9, gen_loss = 0.39175257451832296, disc_loss = 0.09314378414535895
Trained batch 400 in epoch 9, gen_loss = 0.3918471320014345, disc_loss = 0.09324141344905569
Trained batch 401 in epoch 9, gen_loss = 0.391701795790919, disc_loss = 0.09309961723942142
Trained batch 402 in epoch 9, gen_loss = 0.3918909855723085, disc_loss = 0.0929323222566738
Trained batch 403 in epoch 9, gen_loss = 0.39219985068729607, disc_loss = 0.0927966871266576
Trained batch 404 in epoch 9, gen_loss = 0.39215586869804947, disc_loss = 0.09267198400870885
Trained batch 405 in epoch 9, gen_loss = 0.39204142136233194, disc_loss = 0.09282576114517348
Trained batch 406 in epoch 9, gen_loss = 0.3922192646918191, disc_loss = 0.09279752956332607
Trained batch 407 in epoch 9, gen_loss = 0.3922729376046097, disc_loss = 0.09260213288350724
Trained batch 408 in epoch 9, gen_loss = 0.39216707271585255, disc_loss = 0.09258491942126186
Trained batch 409 in epoch 9, gen_loss = 0.39240375946207745, disc_loss = 0.09239374694028278
Trained batch 410 in epoch 9, gen_loss = 0.39252840384949733, disc_loss = 0.09322061239676029
Trained batch 411 in epoch 9, gen_loss = 0.39226665810763256, disc_loss = 0.09352866517271376
Trained batch 412 in epoch 9, gen_loss = 0.39227998444300877, disc_loss = 0.09352560516798612
Trained batch 413 in epoch 9, gen_loss = 0.3921592867604776, disc_loss = 0.09339238447249655
Trained batch 414 in epoch 9, gen_loss = 0.39213412576411144, disc_loss = 0.09327934537397092
Trained batch 415 in epoch 9, gen_loss = 0.3922449800257499, disc_loss = 0.09310332278255373
Trained batch 416 in epoch 9, gen_loss = 0.3925027465648788, disc_loss = 0.09303172339173815
Trained batch 417 in epoch 9, gen_loss = 0.39239825743237183, disc_loss = 0.092851699797802
Trained batch 418 in epoch 9, gen_loss = 0.39249541459333925, disc_loss = 0.0930858126136881
Trained batch 419 in epoch 9, gen_loss = 0.3926521564523379, disc_loss = 0.09379384749169861
Trained batch 420 in epoch 9, gen_loss = 0.3927136942071756, disc_loss = 0.0939658003595974
Trained batch 421 in epoch 9, gen_loss = 0.3927864577815431, disc_loss = 0.09399571327130658
Trained batch 422 in epoch 9, gen_loss = 0.39273755269974964, disc_loss = 0.09397943095077296
Trained batch 423 in epoch 9, gen_loss = 0.3925731212322442, disc_loss = 0.09398849564165158
Trained batch 424 in epoch 9, gen_loss = 0.3924816008876352, disc_loss = 0.09394466602626969
Trained batch 425 in epoch 9, gen_loss = 0.3922778755566324, disc_loss = 0.09384849668423614
Trained batch 426 in epoch 9, gen_loss = 0.39227402391701727, disc_loss = 0.0936820415095088
Trained batch 427 in epoch 9, gen_loss = 0.3924487000592401, disc_loss = 0.09352318331094406
Trained batch 428 in epoch 9, gen_loss = 0.3927024206915102, disc_loss = 0.09351147066515225
Trained batch 429 in epoch 9, gen_loss = 0.39290804759014486, disc_loss = 0.09373853284172541
Trained batch 430 in epoch 9, gen_loss = 0.39292497549145516, disc_loss = 0.09405694101135444
Trained batch 431 in epoch 9, gen_loss = 0.3932565504478084, disc_loss = 0.09436502805652304
Trained batch 432 in epoch 9, gen_loss = 0.39336600266483035, disc_loss = 0.09420450833167958
Trained batch 433 in epoch 9, gen_loss = 0.3932719006791093, disc_loss = 0.09435500980093045
Trained batch 434 in epoch 9, gen_loss = 0.39336796382377887, disc_loss = 0.09425312495180245
Trained batch 435 in epoch 9, gen_loss = 0.3933546437856254, disc_loss = 0.09431044301530773
Trained batch 436 in epoch 9, gen_loss = 0.3931595395986221, disc_loss = 0.0944600735302989
Trained batch 437 in epoch 9, gen_loss = 0.3931522874935577, disc_loss = 0.09429220671097846
Trained batch 438 in epoch 9, gen_loss = 0.39317087350510793, disc_loss = 0.09411122618722549
Trained batch 439 in epoch 9, gen_loss = 0.393277957290411, disc_loss = 0.09400654257571495
Trained batch 440 in epoch 9, gen_loss = 0.3932572807989964, disc_loss = 0.09404568012820688
Trained batch 441 in epoch 9, gen_loss = 0.39327634392280925, disc_loss = 0.09402951942251077
Trained batch 442 in epoch 9, gen_loss = 0.39322484467960644, disc_loss = 0.09384753028851667
Trained batch 443 in epoch 9, gen_loss = 0.3931001716100418, disc_loss = 0.09376978740171604
Trained batch 444 in epoch 9, gen_loss = 0.3931770518254698, disc_loss = 0.09363888840536388
Trained batch 445 in epoch 9, gen_loss = 0.3930947661667127, disc_loss = 0.09351007262194705
Trained batch 446 in epoch 9, gen_loss = 0.3930003053656627, disc_loss = 0.09339003435959019
Trained batch 447 in epoch 9, gen_loss = 0.39290611006851706, disc_loss = 0.09370720949664246
Trained batch 448 in epoch 9, gen_loss = 0.39302801415490146, disc_loss = 0.09458854168296724
Trained batch 449 in epoch 9, gen_loss = 0.3931802986065547, disc_loss = 0.0945682325731549
Trained batch 450 in epoch 9, gen_loss = 0.3932012301723074, disc_loss = 0.09453748430263771
Trained batch 451 in epoch 9, gen_loss = 0.39337041209229323, disc_loss = 0.09439852615546403
Trained batch 452 in epoch 9, gen_loss = 0.39336887712510216, disc_loss = 0.0942366627244398
Trained batch 453 in epoch 9, gen_loss = 0.3933469691859468, disc_loss = 0.09412799151368144
Trained batch 454 in epoch 9, gen_loss = 0.39322972297668457, disc_loss = 0.09399608346828064
Trained batch 455 in epoch 9, gen_loss = 0.3934902461212978, disc_loss = 0.09408383368179529
Trained batch 456 in epoch 9, gen_loss = 0.393554535423379, disc_loss = 0.09417954650738111
Trained batch 457 in epoch 9, gen_loss = 0.39356898506655963, disc_loss = 0.09413826655328078
Trained batch 458 in epoch 9, gen_loss = 0.3935264624931194, disc_loss = 0.09401394022032132
Trained batch 459 in epoch 9, gen_loss = 0.39349003971918767, disc_loss = 0.09385201200721381
Trained batch 460 in epoch 9, gen_loss = 0.393444214686913, disc_loss = 0.0936800550907818
Testing Epoch 9
Training Epoch 10
Trained batch 0 in epoch 10, gen_loss = 0.45520299673080444, disc_loss = 0.09573005139827728
Trained batch 1 in epoch 10, gen_loss = 0.3884488493204117, disc_loss = 0.15926912426948547
Trained batch 2 in epoch 10, gen_loss = 0.40603355566660565, disc_loss = 0.12775148699680963
Trained batch 3 in epoch 10, gen_loss = 0.4243643805384636, disc_loss = 0.09891789546236396
Trained batch 4 in epoch 10, gen_loss = 0.40916637182235716, disc_loss = 0.10377926342189311
Trained batch 5 in epoch 10, gen_loss = 0.40781043966611225, disc_loss = 0.09726165079822142
Trained batch 6 in epoch 10, gen_loss = 0.3972511291503906, disc_loss = 0.08601222160671439
Trained batch 7 in epoch 10, gen_loss = 0.3965255208313465, disc_loss = 0.07842676877044141
Trained batch 8 in epoch 10, gen_loss = 0.4104742772049374, disc_loss = 0.0739332584457265
Trained batch 9 in epoch 10, gen_loss = 0.3941176265478134, disc_loss = 0.0711839972063899
Trained batch 10 in epoch 10, gen_loss = 0.38938749649307947, disc_loss = 0.07065644098276441
Trained batch 11 in epoch 10, gen_loss = 0.3927958905696869, disc_loss = 0.0689950065376858
Trained batch 12 in epoch 10, gen_loss = 0.39986578547037566, disc_loss = 0.06587326211424974
Trained batch 13 in epoch 10, gen_loss = 0.39425900152751375, disc_loss = 0.0670613053121737
Trained batch 14 in epoch 10, gen_loss = 0.3952627102533976, disc_loss = 0.06811234280467034
Trained batch 15 in epoch 10, gen_loss = 0.3925615884363651, disc_loss = 0.06766825052909553
Trained batch 16 in epoch 10, gen_loss = 0.3933713628965266, disc_loss = 0.06473487133488935
Trained batch 17 in epoch 10, gen_loss = 0.39549612833393943, disc_loss = 0.06733021429843372
Trained batch 18 in epoch 10, gen_loss = 0.39179909856695877, disc_loss = 0.07017784879395836
Trained batch 19 in epoch 10, gen_loss = 0.3959044173359871, disc_loss = 0.06806499511003494
Trained batch 20 in epoch 10, gen_loss = 0.39646162731306894, disc_loss = 0.06610550988642942
Trained batch 21 in epoch 10, gen_loss = 0.400436822663654, disc_loss = 0.06353838271884756
Trained batch 22 in epoch 10, gen_loss = 0.40231558680534363, disc_loss = 0.06186814496860556
Trained batch 23 in epoch 10, gen_loss = 0.39880915731191635, disc_loss = 0.060117742085518934
Trained batch 24 in epoch 10, gen_loss = 0.40199946403503417, disc_loss = 0.05795067438855767
Trained batch 25 in epoch 10, gen_loss = 0.40085303210295165, disc_loss = 0.05670597069323636
Trained batch 26 in epoch 10, gen_loss = 0.39770942484890975, disc_loss = 0.06476246381040525
Trained batch 27 in epoch 10, gen_loss = 0.3992670050689152, disc_loss = 0.067397391772829
Trained batch 28 in epoch 10, gen_loss = 0.39829031968938894, disc_loss = 0.06745377242372468
Trained batch 29 in epoch 10, gen_loss = 0.39545193711916604, disc_loss = 0.06731588724069297
Trained batch 30 in epoch 10, gen_loss = 0.3947916973021723, disc_loss = 0.06569603201182138
Trained batch 31 in epoch 10, gen_loss = 0.39467588625848293, disc_loss = 0.06818639086850453
Trained batch 32 in epoch 10, gen_loss = 0.39241235545187286, disc_loss = 0.07171688495542515
Trained batch 33 in epoch 10, gen_loss = 0.39359724083367514, disc_loss = 0.07058267532299985
Trained batch 34 in epoch 10, gen_loss = 0.39418560862541197, disc_loss = 0.07055672211572528
Trained batch 35 in epoch 10, gen_loss = 0.3925530148877038, disc_loss = 0.07035426046544065
Trained batch 36 in epoch 10, gen_loss = 0.39421287178993225, disc_loss = 0.06934709702240857
Trained batch 37 in epoch 10, gen_loss = 0.3936823214355268, disc_loss = 0.06793453516193519
Trained batch 38 in epoch 10, gen_loss = 0.39359031044519865, disc_loss = 0.06678765239671637
Trained batch 39 in epoch 10, gen_loss = 0.39404731467366216, disc_loss = 0.06564906138228252
Trained batch 40 in epoch 10, gen_loss = 0.3947900802623935, disc_loss = 0.06822381051620696
Trained batch 41 in epoch 10, gen_loss = 0.39239142054603215, disc_loss = 0.07274560888652645
Trained batch 42 in epoch 10, gen_loss = 0.39283841986988866, disc_loss = 0.07366361582738369
Trained batch 43 in epoch 10, gen_loss = 0.39208063754168426, disc_loss = 0.07319154735358263
Trained batch 44 in epoch 10, gen_loss = 0.39033515254656476, disc_loss = 0.07523228336746494
Trained batch 45 in epoch 10, gen_loss = 0.3883980694024459, disc_loss = 0.07991334351549007
Trained batch 46 in epoch 10, gen_loss = 0.388668547919456, disc_loss = 0.08025963438991854
Trained batch 47 in epoch 10, gen_loss = 0.38825476976732415, disc_loss = 0.07936372337280773
Trained batch 48 in epoch 10, gen_loss = 0.3872423311885522, disc_loss = 0.07810292914699839
Trained batch 49 in epoch 10, gen_loss = 0.3868114399909973, disc_loss = 0.07722842087037861
Trained batch 50 in epoch 10, gen_loss = 0.3865337173144023, disc_loss = 0.07680743805808472
Trained batch 51 in epoch 10, gen_loss = 0.3852433992119936, disc_loss = 0.0770358707343873
Trained batch 52 in epoch 10, gen_loss = 0.385122612399875, disc_loss = 0.07730499729689844
Trained batch 53 in epoch 10, gen_loss = 0.3836750040451686, disc_loss = 0.0784733271036573
Trained batch 54 in epoch 10, gen_loss = 0.3840655581517653, disc_loss = 0.07839493701573122
Trained batch 55 in epoch 10, gen_loss = 0.38556825848562376, disc_loss = 0.07926829828647897
Trained batch 56 in epoch 10, gen_loss = 0.3850463534656324, disc_loss = 0.07966220003895853
Trained batch 57 in epoch 10, gen_loss = 0.3863915667451661, disc_loss = 0.08008327262058597
Trained batch 58 in epoch 10, gen_loss = 0.38498180700560747, disc_loss = 0.08157050563022494
Trained batch 59 in epoch 10, gen_loss = 0.3865637441476186, disc_loss = 0.08437550146287928
Trained batch 60 in epoch 10, gen_loss = 0.38619227682957885, disc_loss = 0.08327514859160683
Trained batch 61 in epoch 10, gen_loss = 0.3849693642508599, disc_loss = 0.08611208678884132
Trained batch 62 in epoch 10, gen_loss = 0.3851731135731652, disc_loss = 0.08893533025143875
Trained batch 63 in epoch 10, gen_loss = 0.38580128364264965, disc_loss = 0.0880280224737362
Trained batch 64 in epoch 10, gen_loss = 0.3861484958575322, disc_loss = 0.08772407785201301
Trained batch 65 in epoch 10, gen_loss = 0.3858812053998311, disc_loss = 0.08754967585572916
Trained batch 66 in epoch 10, gen_loss = 0.3864864635823378, disc_loss = 0.08662979071959853
Trained batch 67 in epoch 10, gen_loss = 0.3864359066766851, disc_loss = 0.08682222281555262
Trained batch 68 in epoch 10, gen_loss = 0.3854731779167618, disc_loss = 0.08718242702087846
Trained batch 69 in epoch 10, gen_loss = 0.3853959828615189, disc_loss = 0.0870881519213851
Trained batch 70 in epoch 10, gen_loss = 0.38537885983225323, disc_loss = 0.08746755690458165
Trained batch 71 in epoch 10, gen_loss = 0.384504950294892, disc_loss = 0.09097649675095454
Trained batch 72 in epoch 10, gen_loss = 0.38494759553099334, disc_loss = 0.09083985976798281
Trained batch 73 in epoch 10, gen_loss = 0.3861116928023261, disc_loss = 0.09184932064994969
Trained batch 74 in epoch 10, gen_loss = 0.3866731770833333, disc_loss = 0.09263328711812695
Trained batch 75 in epoch 10, gen_loss = 0.38749766859569046, disc_loss = 0.09213381408297114
Trained batch 76 in epoch 10, gen_loss = 0.38730291228789787, disc_loss = 0.09124775345183232
Trained batch 77 in epoch 10, gen_loss = 0.3866727787714738, disc_loss = 0.0903678555578853
Trained batch 78 in epoch 10, gen_loss = 0.38761494280416753, disc_loss = 0.08938423988020307
Trained batch 79 in epoch 10, gen_loss = 0.38802683018147943, disc_loss = 0.08867281051934697
Trained batch 80 in epoch 10, gen_loss = 0.3866945015795437, disc_loss = 0.08865000059782172
Trained batch 81 in epoch 10, gen_loss = 0.38740296698198085, disc_loss = 0.08784135308957136
Trained batch 82 in epoch 10, gen_loss = 0.38801971903766497, disc_loss = 0.08703475230631519
Trained batch 83 in epoch 10, gen_loss = 0.38791772936071667, disc_loss = 0.08637441198585466
Trained batch 84 in epoch 10, gen_loss = 0.3881249561029322, disc_loss = 0.08573211953591775
Trained batch 85 in epoch 10, gen_loss = 0.38886133252188215, disc_loss = 0.08631046337811926
Trained batch 86 in epoch 10, gen_loss = 0.388860497323946, disc_loss = 0.08896673800980394
Trained batch 87 in epoch 10, gen_loss = 0.3901817917146466, disc_loss = 0.088563183454839
Trained batch 88 in epoch 10, gen_loss = 0.39036863807881816, disc_loss = 0.08921817192556651
Trained batch 89 in epoch 10, gen_loss = 0.39007680912812553, disc_loss = 0.09077268090202577
Trained batch 90 in epoch 10, gen_loss = 0.3911115792426434, disc_loss = 0.09064838761504698
Trained batch 91 in epoch 10, gen_loss = 0.39190768418104754, disc_loss = 0.09134356754973692
Trained batch 92 in epoch 10, gen_loss = 0.39082339341922473, disc_loss = 0.09168110319703657
Trained batch 93 in epoch 10, gen_loss = 0.39079945138160216, disc_loss = 0.09118693215435648
Trained batch 94 in epoch 10, gen_loss = 0.39111271343733134, disc_loss = 0.09073570939761243
Trained batch 95 in epoch 10, gen_loss = 0.3915893957018852, disc_loss = 0.08995521625911351
Trained batch 96 in epoch 10, gen_loss = 0.3911830229857533, disc_loss = 0.0896088460450704
Trained batch 97 in epoch 10, gen_loss = 0.3926735818386078, disc_loss = 0.08948469111144695
Trained batch 98 in epoch 10, gen_loss = 0.39264921106473366, disc_loss = 0.08876184301187444
Trained batch 99 in epoch 10, gen_loss = 0.3921514704823494, disc_loss = 0.08899164336267859
Trained batch 100 in epoch 10, gen_loss = 0.39236393570899963, disc_loss = 0.08832794254977662
Trained batch 101 in epoch 10, gen_loss = 0.39335038469118233, disc_loss = 0.08894263986297243
Trained batch 102 in epoch 10, gen_loss = 0.3932262615671436, disc_loss = 0.09058280495782066
Trained batch 103 in epoch 10, gen_loss = 0.3934954058092374, disc_loss = 0.09053828399359751
Trained batch 104 in epoch 10, gen_loss = 0.39363069647834414, disc_loss = 0.09028548694526156
Trained batch 105 in epoch 10, gen_loss = 0.3935877098789755, disc_loss = 0.08969311140706095
Trained batch 106 in epoch 10, gen_loss = 0.39332560094717506, disc_loss = 0.08946365882668679
Trained batch 107 in epoch 10, gen_loss = 0.393156240383784, disc_loss = 0.09068155108036956
Trained batch 108 in epoch 10, gen_loss = 0.3940128096199911, disc_loss = 0.09128104818882335
Trained batch 109 in epoch 10, gen_loss = 0.39385432628068057, disc_loss = 0.0907046152829108
Trained batch 110 in epoch 10, gen_loss = 0.3937053393136274, disc_loss = 0.09069504139542177
Trained batch 111 in epoch 10, gen_loss = 0.39415594323405195, disc_loss = 0.09008325347427412
Trained batch 112 in epoch 10, gen_loss = 0.3940959084877926, disc_loss = 0.08939194535440971
Trained batch 113 in epoch 10, gen_loss = 0.39381228230501475, disc_loss = 0.08881624714111942
Trained batch 114 in epoch 10, gen_loss = 0.39413868966309923, disc_loss = 0.0883749466996802
Trained batch 115 in epoch 10, gen_loss = 0.3941303381118281, disc_loss = 0.088164622425744
Trained batch 116 in epoch 10, gen_loss = 0.3944864402978848, disc_loss = 0.08805229668863691
Trained batch 117 in epoch 10, gen_loss = 0.39439682814024263, disc_loss = 0.08765050669011297
Trained batch 118 in epoch 10, gen_loss = 0.395525264890254, disc_loss = 0.08795486930209924
Trained batch 119 in epoch 10, gen_loss = 0.3946507414182027, disc_loss = 0.08890891337068751
Trained batch 120 in epoch 10, gen_loss = 0.39508072453096876, disc_loss = 0.0889497340333548
Trained batch 121 in epoch 10, gen_loss = 0.3949277557310511, disc_loss = 0.08873487588735755
Trained batch 122 in epoch 10, gen_loss = 0.39544091985477664, disc_loss = 0.08824046291940944
Trained batch 123 in epoch 10, gen_loss = 0.39583145778986717, disc_loss = 0.08770612840195216
Trained batch 124 in epoch 10, gen_loss = 0.39591797161102293, disc_loss = 0.08750186732038856
Trained batch 125 in epoch 10, gen_loss = 0.3959370908283052, disc_loss = 0.08692267275829282
Trained batch 126 in epoch 10, gen_loss = 0.39614217581711414, disc_loss = 0.0863507709201924
Trained batch 127 in epoch 10, gen_loss = 0.3965026456862688, disc_loss = 0.08608967133113765
Trained batch 128 in epoch 10, gen_loss = 0.39690600208533827, disc_loss = 0.08565076316757374
Trained batch 129 in epoch 10, gen_loss = 0.3967036659900959, disc_loss = 0.08508114501332434
Trained batch 130 in epoch 10, gen_loss = 0.39639068719084936, disc_loss = 0.0849290398191234
Trained batch 131 in epoch 10, gen_loss = 0.3969663121935093, disc_loss = 0.0846303446451202
Trained batch 132 in epoch 10, gen_loss = 0.3973664282856131, disc_loss = 0.08407244138433632
Trained batch 133 in epoch 10, gen_loss = 0.3972198518354501, disc_loss = 0.08372172770618613
Trained batch 134 in epoch 10, gen_loss = 0.39688373340500727, disc_loss = 0.08326890238526242
Trained batch 135 in epoch 10, gen_loss = 0.396479631171507, disc_loss = 0.08284262314726434
Trained batch 136 in epoch 10, gen_loss = 0.39572974321615956, disc_loss = 0.08345071937766498
Trained batch 137 in epoch 10, gen_loss = 0.39612460870673694, disc_loss = 0.08725095355707774
Trained batch 138 in epoch 10, gen_loss = 0.3958886051349503, disc_loss = 0.08723146617479569
Trained batch 139 in epoch 10, gen_loss = 0.39584918511765343, disc_loss = 0.08765269628659422
Trained batch 140 in epoch 10, gen_loss = 0.39582559931362776, disc_loss = 0.08790812053856381
Trained batch 141 in epoch 10, gen_loss = 0.39588037531980325, disc_loss = 0.08801767239543859
Trained batch 142 in epoch 10, gen_loss = 0.3957502706484361, disc_loss = 0.087735585155213
Trained batch 143 in epoch 10, gen_loss = 0.3957978509780433, disc_loss = 0.08730069090314727
Trained batch 144 in epoch 10, gen_loss = 0.3957138918597123, disc_loss = 0.08692306635002124
Trained batch 145 in epoch 10, gen_loss = 0.3959681259034431, disc_loss = 0.08649083977399318
Trained batch 146 in epoch 10, gen_loss = 0.39586603682057386, disc_loss = 0.08606351185019831
Trained batch 147 in epoch 10, gen_loss = 0.39581837726605906, disc_loss = 0.08558773623489951
Trained batch 148 in epoch 10, gen_loss = 0.39597720127777764, disc_loss = 0.0852690496506957
Trained batch 149 in epoch 10, gen_loss = 0.395577698747317, disc_loss = 0.08535837763609985
Trained batch 150 in epoch 10, gen_loss = 0.3957887246513998, disc_loss = 0.08615392203818982
Trained batch 151 in epoch 10, gen_loss = 0.3955973416174713, disc_loss = 0.08744001735651277
Trained batch 152 in epoch 10, gen_loss = 0.39651956569914726, disc_loss = 0.088623372305282
Trained batch 153 in epoch 10, gen_loss = 0.39670898233141216, disc_loss = 0.08852114425911628
Trained batch 154 in epoch 10, gen_loss = 0.3961264758340774, disc_loss = 0.08870127541463702
Trained batch 155 in epoch 10, gen_loss = 0.39605035537328476, disc_loss = 0.08841880498370394
Trained batch 156 in epoch 10, gen_loss = 0.3960768925915858, disc_loss = 0.0880080587764502
Trained batch 157 in epoch 10, gen_loss = 0.39649983523767207, disc_loss = 0.08759626729967945
Trained batch 158 in epoch 10, gen_loss = 0.39689552971402053, disc_loss = 0.08735777566842032
Trained batch 159 in epoch 10, gen_loss = 0.39689544048160313, disc_loss = 0.08740641388867516
Trained batch 160 in epoch 10, gen_loss = 0.39677641776777944, disc_loss = 0.08775075481371572
Trained batch 161 in epoch 10, gen_loss = 0.39699711310274804, disc_loss = 0.08900356943788076
Trained batch 162 in epoch 10, gen_loss = 0.397038814297483, disc_loss = 0.08876933196582402
Trained batch 163 in epoch 10, gen_loss = 0.39715222123919464, disc_loss = 0.08850812064994854
Trained batch 164 in epoch 10, gen_loss = 0.3975937935439023, disc_loss = 0.08804045580045292
Trained batch 165 in epoch 10, gen_loss = 0.39763632291052714, disc_loss = 0.08765140292234719
Trained batch 166 in epoch 10, gen_loss = 0.3979532866777774, disc_loss = 0.08735375369279952
Trained batch 167 in epoch 10, gen_loss = 0.39846284474645344, disc_loss = 0.0870872115732969
Trained batch 168 in epoch 10, gen_loss = 0.39871283254679846, disc_loss = 0.0867701250613397
Trained batch 169 in epoch 10, gen_loss = 0.3980665284044602, disc_loss = 0.08741190067273291
Trained batch 170 in epoch 10, gen_loss = 0.3988676060710037, disc_loss = 0.08829650058198654
Trained batch 171 in epoch 10, gen_loss = 0.3986506151945092, disc_loss = 0.0879076732252183
Trained batch 172 in epoch 10, gen_loss = 0.3983253088989699, disc_loss = 0.08843263561401322
Trained batch 173 in epoch 10, gen_loss = 0.39813107474782, disc_loss = 0.09053991674766715
Trained batch 174 in epoch 10, gen_loss = 0.3979470709392003, disc_loss = 0.09023948618077807
Trained batch 175 in epoch 10, gen_loss = 0.39728057621554896, disc_loss = 0.08996659724454564
Trained batch 176 in epoch 10, gen_loss = 0.3967036003783598, disc_loss = 0.08984986380910721
Trained batch 177 in epoch 10, gen_loss = 0.3964462276924862, disc_loss = 0.089730555293663
Trained batch 178 in epoch 10, gen_loss = 0.3959830616439521, disc_loss = 0.08998599935416653
Trained batch 179 in epoch 10, gen_loss = 0.39576445271571475, disc_loss = 0.09042712917499658
Trained batch 180 in epoch 10, gen_loss = 0.39586591078431566, disc_loss = 0.09008555331149072
Trained batch 181 in epoch 10, gen_loss = 0.39606807847599407, disc_loss = 0.08966732846706041
Trained batch 182 in epoch 10, gen_loss = 0.3959886407265898, disc_loss = 0.08943846598623799
Trained batch 183 in epoch 10, gen_loss = 0.39560706330382306, disc_loss = 0.08930501759649538
Trained batch 184 in epoch 10, gen_loss = 0.39514275273761235, disc_loss = 0.08919752599369432
Trained batch 185 in epoch 10, gen_loss = 0.3954029506252658, disc_loss = 0.0894044747911594
Trained batch 186 in epoch 10, gen_loss = 0.3950968706671567, disc_loss = 0.08941351471687942
Trained batch 187 in epoch 10, gen_loss = 0.39535412160640065, disc_loss = 0.08897946190158341
Trained batch 188 in epoch 10, gen_loss = 0.3954696115993318, disc_loss = 0.08868153406819575
Trained batch 189 in epoch 10, gen_loss = 0.39534947370228013, disc_loss = 0.08870850830632997
Trained batch 190 in epoch 10, gen_loss = 0.39511791604975754, disc_loss = 0.08879321994728052
Trained batch 191 in epoch 10, gen_loss = 0.39548260997980833, disc_loss = 0.08974601073956971
Trained batch 192 in epoch 10, gen_loss = 0.39543893485489284, disc_loss = 0.08998391072511905
Trained batch 193 in epoch 10, gen_loss = 0.3957654858372875, disc_loss = 0.08961776428683133
Trained batch 194 in epoch 10, gen_loss = 0.39564406122916784, disc_loss = 0.08966195628954432
Trained batch 195 in epoch 10, gen_loss = 0.3955232061597766, disc_loss = 0.08989896837916529
Trained batch 196 in epoch 10, gen_loss = 0.3955866405504004, disc_loss = 0.08954996060400369
Trained batch 197 in epoch 10, gen_loss = 0.395905147146697, disc_loss = 0.08928874805522612
Trained batch 198 in epoch 10, gen_loss = 0.39582681431243166, disc_loss = 0.08909790724019834
Trained batch 199 in epoch 10, gen_loss = 0.3956598910689354, disc_loss = 0.09008488659514115
Trained batch 200 in epoch 10, gen_loss = 0.39585347851710534, disc_loss = 0.09129956710055026
Trained batch 201 in epoch 10, gen_loss = 0.3960532422112946, disc_loss = 0.09111897183333219
Trained batch 202 in epoch 10, gen_loss = 0.39599802884562263, disc_loss = 0.09085228113145591
Trained batch 203 in epoch 10, gen_loss = 0.39551833052845564, disc_loss = 0.09096896201691718
Trained batch 204 in epoch 10, gen_loss = 0.3958723866358036, disc_loss = 0.09064866497703805
Trained batch 205 in epoch 10, gen_loss = 0.3959755802038804, disc_loss = 0.09039598921069748
Trained batch 206 in epoch 10, gen_loss = 0.395989158447238, disc_loss = 0.09023495667033653
Trained batch 207 in epoch 10, gen_loss = 0.39589765725227505, disc_loss = 0.09031029791311504
Trained batch 208 in epoch 10, gen_loss = 0.395527244327171, disc_loss = 0.09144550277383633
Trained batch 209 in epoch 10, gen_loss = 0.39539806856995535, disc_loss = 0.0915568891801827
Trained batch 210 in epoch 10, gen_loss = 0.3951450849031385, disc_loss = 0.09168615683657227
Trained batch 211 in epoch 10, gen_loss = 0.39477466581002724, disc_loss = 0.09175456491659202
Trained batch 212 in epoch 10, gen_loss = 0.3945961679930978, disc_loss = 0.09210218881593554
Trained batch 213 in epoch 10, gen_loss = 0.39434809411797567, disc_loss = 0.09228158847289596
Trained batch 214 in epoch 10, gen_loss = 0.39423785223517305, disc_loss = 0.09203257987622258
Trained batch 215 in epoch 10, gen_loss = 0.39456672138637966, disc_loss = 0.09215097995776753
Trained batch 216 in epoch 10, gen_loss = 0.39456722305117664, disc_loss = 0.09211595236937503
Trained batch 217 in epoch 10, gen_loss = 0.394649075942302, disc_loss = 0.09178289758050046
Trained batch 218 in epoch 10, gen_loss = 0.395065266519921, disc_loss = 0.0916397733907279
Trained batch 219 in epoch 10, gen_loss = 0.3947254275733774, disc_loss = 0.09187046347651631
Trained batch 220 in epoch 10, gen_loss = 0.3950568340482755, disc_loss = 0.09160864839279746
Trained batch 221 in epoch 10, gen_loss = 0.3949792308581842, disc_loss = 0.09151428529094938
Trained batch 222 in epoch 10, gen_loss = 0.3945334007119919, disc_loss = 0.09199137785868727
Trained batch 223 in epoch 10, gen_loss = 0.3951138621196151, disc_loss = 0.09208812285838316
Trained batch 224 in epoch 10, gen_loss = 0.3953455368677775, disc_loss = 0.09171716252755788
Trained batch 225 in epoch 10, gen_loss = 0.39518682091637, disc_loss = 0.09137885013504564
Trained batch 226 in epoch 10, gen_loss = 0.3949961280245088, disc_loss = 0.09132034395357783
Trained batch 227 in epoch 10, gen_loss = 0.3950987788930274, disc_loss = 0.09125544537438832
Trained batch 228 in epoch 10, gen_loss = 0.39523391510201333, disc_loss = 0.09096021924826711
Trained batch 229 in epoch 10, gen_loss = 0.39522389652936357, disc_loss = 0.09079929411046855
Trained batch 230 in epoch 10, gen_loss = 0.3951551778749986, disc_loss = 0.09111557741855066
Trained batch 231 in epoch 10, gen_loss = 0.39473665736872576, disc_loss = 0.09120596957128045
Trained batch 232 in epoch 10, gen_loss = 0.3946731388568878, disc_loss = 0.09103674453367427
Trained batch 233 in epoch 10, gen_loss = 0.3949234516192705, disc_loss = 0.09115195881503706
Trained batch 234 in epoch 10, gen_loss = 0.3949819667542234, disc_loss = 0.0913616197124282
Trained batch 235 in epoch 10, gen_loss = 0.3951394921642239, disc_loss = 0.0912540498075186
Trained batch 236 in epoch 10, gen_loss = 0.3952503508656337, disc_loss = 0.09092796691948792
Trained batch 237 in epoch 10, gen_loss = 0.3955165139015983, disc_loss = 0.09066097589968822
Trained batch 238 in epoch 10, gen_loss = 0.395814587880378, disc_loss = 0.09051083300893963
Trained batch 239 in epoch 10, gen_loss = 0.39581371545791627, disc_loss = 0.09093976348134068
Trained batch 240 in epoch 10, gen_loss = 0.3962744875072938, disc_loss = 0.09188197056774468
Trained batch 241 in epoch 10, gen_loss = 0.396555033350779, disc_loss = 0.09154363071415111
Trained batch 242 in epoch 10, gen_loss = 0.39657090990631666, disc_loss = 0.09129439111331424
Trained batch 243 in epoch 10, gen_loss = 0.39662688970565796, disc_loss = 0.09095329143389387
Trained batch 244 in epoch 10, gen_loss = 0.3969524968643578, disc_loss = 0.09064784332995816
Trained batch 245 in epoch 10, gen_loss = 0.39679003331234786, disc_loss = 0.0905015863860556
Trained batch 246 in epoch 10, gen_loss = 0.3965225345210025, disc_loss = 0.09024778887184585
Trained batch 247 in epoch 10, gen_loss = 0.39634494675743964, disc_loss = 0.08997467487877715
Trained batch 248 in epoch 10, gen_loss = 0.396612722710912, disc_loss = 0.08967463853376278
Trained batch 249 in epoch 10, gen_loss = 0.39686403727531433, disc_loss = 0.08940795563347638
Trained batch 250 in epoch 10, gen_loss = 0.39684883413086847, disc_loss = 0.08957970443838444
Trained batch 251 in epoch 10, gen_loss = 0.3965745591928089, disc_loss = 0.09058415255738451
Trained batch 252 in epoch 10, gen_loss = 0.3964000499766806, disc_loss = 0.0908377539723552
Trained batch 253 in epoch 10, gen_loss = 0.39646865509626433, disc_loss = 0.09089260024942575
Trained batch 254 in epoch 10, gen_loss = 0.39641878406206765, disc_loss = 0.09079174877272225
Trained batch 255 in epoch 10, gen_loss = 0.39612656424287707, disc_loss = 0.0910478122987115
Trained batch 256 in epoch 10, gen_loss = 0.39619015371753086, disc_loss = 0.09143573287983175
Trained batch 257 in epoch 10, gen_loss = 0.3959613757771115, disc_loss = 0.09131772745610034
Trained batch 258 in epoch 10, gen_loss = 0.3957376657305537, disc_loss = 0.09150440955146226
Trained batch 259 in epoch 10, gen_loss = 0.39612083778931545, disc_loss = 0.09201781169618838
Trained batch 260 in epoch 10, gen_loss = 0.39631871245373257, disc_loss = 0.09170804649655676
Trained batch 261 in epoch 10, gen_loss = 0.39620683916652477, disc_loss = 0.09190646468178292
Trained batch 262 in epoch 10, gen_loss = 0.3963522419276799, disc_loss = 0.09224054988069963
Trained batch 263 in epoch 10, gen_loss = 0.39632048107909434, disc_loss = 0.09193883055052014
Trained batch 264 in epoch 10, gen_loss = 0.39650254541972896, disc_loss = 0.09169658385041468
Trained batch 265 in epoch 10, gen_loss = 0.3961769990006784, disc_loss = 0.09138284847875566
Trained batch 266 in epoch 10, gen_loss = 0.3962765418634879, disc_loss = 0.0912984790444402
Trained batch 267 in epoch 10, gen_loss = 0.39616950745902846, disc_loss = 0.0913504311804479
Trained batch 268 in epoch 10, gen_loss = 0.3960980688772237, disc_loss = 0.091511343410204
Trained batch 269 in epoch 10, gen_loss = 0.39629568965346723, disc_loss = 0.09140811885569107
Trained batch 270 in epoch 10, gen_loss = 0.3963289597377566, disc_loss = 0.09112664046645769
Trained batch 271 in epoch 10, gen_loss = 0.3963969767312793, disc_loss = 0.09104784099926132
Trained batch 272 in epoch 10, gen_loss = 0.3964910222278846, disc_loss = 0.09130979728997572
Trained batch 273 in epoch 10, gen_loss = 0.39636795570815564, disc_loss = 0.09160501894500298
Trained batch 274 in epoch 10, gen_loss = 0.396539642052217, disc_loss = 0.09153403199362484
Trained batch 275 in epoch 10, gen_loss = 0.39652737132881, disc_loss = 0.09127173625249956
Trained batch 276 in epoch 10, gen_loss = 0.3965233659055689, disc_loss = 0.09113112094539759
Trained batch 277 in epoch 10, gen_loss = 0.39676355318628626, disc_loss = 0.09116587731417725
Trained batch 278 in epoch 10, gen_loss = 0.39678726059561564, disc_loss = 0.09111493633472524
Trained batch 279 in epoch 10, gen_loss = 0.39669068870799884, disc_loss = 0.0911806707652951
Trained batch 280 in epoch 10, gen_loss = 0.396994864070967, disc_loss = 0.09090862767373169
Trained batch 281 in epoch 10, gen_loss = 0.3969739063623104, disc_loss = 0.0907199402812023
Trained batch 282 in epoch 10, gen_loss = 0.3965759068832802, disc_loss = 0.09059251374449884
Trained batch 283 in epoch 10, gen_loss = 0.3965928462189688, disc_loss = 0.09061093697435892
Trained batch 284 in epoch 10, gen_loss = 0.3969106798632103, disc_loss = 0.09097243621455212
Trained batch 285 in epoch 10, gen_loss = 0.39704453830535597, disc_loss = 0.09150207554107415
Trained batch 286 in epoch 10, gen_loss = 0.3971747519247208, disc_loss = 0.09124541015425885
Trained batch 287 in epoch 10, gen_loss = 0.3971002074993319, disc_loss = 0.09129175631905026
Trained batch 288 in epoch 10, gen_loss = 0.3973965236472424, disc_loss = 0.0911654934535209
Trained batch 289 in epoch 10, gen_loss = 0.39782903954900545, disc_loss = 0.09092755347393967
Trained batch 290 in epoch 10, gen_loss = 0.3976496325940201, disc_loss = 0.09081574676788806
Trained batch 291 in epoch 10, gen_loss = 0.397385299614031, disc_loss = 0.09073133403212087
Trained batch 292 in epoch 10, gen_loss = 0.397352477897963, disc_loss = 0.09085742716197522
Trained batch 293 in epoch 10, gen_loss = 0.39717613667452417, disc_loss = 0.09092584304467198
Trained batch 294 in epoch 10, gen_loss = 0.397487614518505, disc_loss = 0.09098346002431491
Trained batch 295 in epoch 10, gen_loss = 0.397122878681969, disc_loss = 0.0909935254241793
Trained batch 296 in epoch 10, gen_loss = 0.39732673192265056, disc_loss = 0.09082137270413515
Trained batch 297 in epoch 10, gen_loss = 0.39731673666294787, disc_loss = 0.09078440281575008
Trained batch 298 in epoch 10, gen_loss = 0.39693374219148053, disc_loss = 0.09097900983089438
Trained batch 299 in epoch 10, gen_loss = 0.39673713783423104, disc_loss = 0.09085875261730204
Trained batch 300 in epoch 10, gen_loss = 0.3969545496064563, disc_loss = 0.09107595928588827
Trained batch 301 in epoch 10, gen_loss = 0.39666781944549634, disc_loss = 0.09109258312664137
Trained batch 302 in epoch 10, gen_loss = 0.39694414300100245, disc_loss = 0.09084937326985076
Trained batch 303 in epoch 10, gen_loss = 0.3972610252860345, disc_loss = 0.09057957359350678
Trained batch 304 in epoch 10, gen_loss = 0.39735469163441267, disc_loss = 0.09046473315168845
Trained batch 305 in epoch 10, gen_loss = 0.3971443514223971, disc_loss = 0.09066472132081543
Trained batch 306 in epoch 10, gen_loss = 0.39718064374566464, disc_loss = 0.09046115832561051
Trained batch 307 in epoch 10, gen_loss = 0.3972088306561693, disc_loss = 0.09026947192539304
Trained batch 308 in epoch 10, gen_loss = 0.3971125217317377, disc_loss = 0.09007022225578289
Trained batch 309 in epoch 10, gen_loss = 0.39711751332206113, disc_loss = 0.08990874571215
Trained batch 310 in epoch 10, gen_loss = 0.3970525486101292, disc_loss = 0.08985663616993851
Trained batch 311 in epoch 10, gen_loss = 0.3967916702803893, disc_loss = 0.09029767110209483
Trained batch 312 in epoch 10, gen_loss = 0.39685693126136123, disc_loss = 0.09139946476368906
Trained batch 313 in epoch 10, gen_loss = 0.3967665356055946, disc_loss = 0.0912992263844557
Trained batch 314 in epoch 10, gen_loss = 0.3969285533541725, disc_loss = 0.0911562991831156
Trained batch 315 in epoch 10, gen_loss = 0.3967645239980915, disc_loss = 0.0911249523419486
Trained batch 316 in epoch 10, gen_loss = 0.3966204023887682, disc_loss = 0.09091394945350402
Trained batch 317 in epoch 10, gen_loss = 0.3966532145281258, disc_loss = 0.09102611551383429
Trained batch 318 in epoch 10, gen_loss = 0.39637907722900656, disc_loss = 0.09122338511055586
Trained batch 319 in epoch 10, gen_loss = 0.39656596230342983, disc_loss = 0.09101572055515135
Trained batch 320 in epoch 10, gen_loss = 0.39677410175867167, disc_loss = 0.09075298355718221
Trained batch 321 in epoch 10, gen_loss = 0.39673790057993824, disc_loss = 0.0905515675574703
Trained batch 322 in epoch 10, gen_loss = 0.3967822546560329, disc_loss = 0.09033578632964577
Trained batch 323 in epoch 10, gen_loss = 0.396879365230784, disc_loss = 0.09023151278674005
Trained batch 324 in epoch 10, gen_loss = 0.39686997395295365, disc_loss = 0.0900539884988505
Trained batch 325 in epoch 10, gen_loss = 0.39671413938692013, disc_loss = 0.09025839230394209
Trained batch 326 in epoch 10, gen_loss = 0.39668444591924684, disc_loss = 0.09090340933662808
Trained batch 327 in epoch 10, gen_loss = 0.3968638050846937, disc_loss = 0.09148292928201533
Trained batch 328 in epoch 10, gen_loss = 0.3966114598023493, disc_loss = 0.09151997388762317
Trained batch 329 in epoch 10, gen_loss = 0.3965599702163176, disc_loss = 0.0913879889642086
Trained batch 330 in epoch 10, gen_loss = 0.3965005429849884, disc_loss = 0.09122102914569376
Trained batch 331 in epoch 10, gen_loss = 0.3965429406927293, disc_loss = 0.09104690035238458
Trained batch 332 in epoch 10, gen_loss = 0.3964052116190707, disc_loss = 0.0910191572964885
Trained batch 333 in epoch 10, gen_loss = 0.3962007814538693, disc_loss = 0.09127394577159273
Trained batch 334 in epoch 10, gen_loss = 0.3958725623230436, disc_loss = 0.09158941688460868
Trained batch 335 in epoch 10, gen_loss = 0.39596835373058203, disc_loss = 0.09205254507555981
Trained batch 336 in epoch 10, gen_loss = 0.39608586418168834, disc_loss = 0.09194646687150135
Trained batch 337 in epoch 10, gen_loss = 0.39573313190034154, disc_loss = 0.09193001306042649
Trained batch 338 in epoch 10, gen_loss = 0.3957022417083954, disc_loss = 0.0918501723862657
Trained batch 339 in epoch 10, gen_loss = 0.39580975113546146, disc_loss = 0.0916654943200924
Trained batch 340 in epoch 10, gen_loss = 0.3958090410029783, disc_loss = 0.09146678999279383
Trained batch 341 in epoch 10, gen_loss = 0.3957415980379484, disc_loss = 0.09150852812917043
Trained batch 342 in epoch 10, gen_loss = 0.3959557106474051, disc_loss = 0.09131542552376584
Trained batch 343 in epoch 10, gen_loss = 0.3959558496988097, disc_loss = 0.09113821197642273
Trained batch 344 in epoch 10, gen_loss = 0.3958542557730191, disc_loss = 0.09102662208800515
Trained batch 345 in epoch 10, gen_loss = 0.39627467948577305, disc_loss = 0.09130145974236546
Trained batch 346 in epoch 10, gen_loss = 0.396225714717887, disc_loss = 0.09134473184510121
Trained batch 347 in epoch 10, gen_loss = 0.39614325641900644, disc_loss = 0.09116796666258496
Trained batch 348 in epoch 10, gen_loss = 0.3960865613041088, disc_loss = 0.0911293061260657
Trained batch 349 in epoch 10, gen_loss = 0.3960012254544667, disc_loss = 0.09140940762923232
Trained batch 350 in epoch 10, gen_loss = 0.39606219249912816, disc_loss = 0.09139351108299829
Trained batch 351 in epoch 10, gen_loss = 0.3961213513023474, disc_loss = 0.09119526330058844
Trained batch 352 in epoch 10, gen_loss = 0.3962554274807571, disc_loss = 0.09095986170968616
Trained batch 353 in epoch 10, gen_loss = 0.3961504616979825, disc_loss = 0.09089099561485152
Trained batch 354 in epoch 10, gen_loss = 0.39593130148632427, disc_loss = 0.09078107372739576
Trained batch 355 in epoch 10, gen_loss = 0.39603714259822714, disc_loss = 0.0915418929993332
Trained batch 356 in epoch 10, gen_loss = 0.3960045004258303, disc_loss = 0.09131223530865976
Trained batch 357 in epoch 10, gen_loss = 0.3957696782643569, disc_loss = 0.09121270191481118
Trained batch 358 in epoch 10, gen_loss = 0.3959123540389505, disc_loss = 0.09101539730771463
Trained batch 359 in epoch 10, gen_loss = 0.3958805189364486, disc_loss = 0.09139636710363751
Trained batch 360 in epoch 10, gen_loss = 0.39577133255982333, disc_loss = 0.09164537102309084
Trained batch 361 in epoch 10, gen_loss = 0.3959082895220973, disc_loss = 0.09148635031804649
Trained batch 362 in epoch 10, gen_loss = 0.39597769299157726, disc_loss = 0.09138916657478151
Trained batch 363 in epoch 10, gen_loss = 0.3962021963773193, disc_loss = 0.09143628168641334
Trained batch 364 in epoch 10, gen_loss = 0.396262273723132, disc_loss = 0.0912099696504437
Trained batch 365 in epoch 10, gen_loss = 0.396210647264465, disc_loss = 0.09110036919967276
Trained batch 366 in epoch 10, gen_loss = 0.39631186048081524, disc_loss = 0.09097159195219341
Trained batch 367 in epoch 10, gen_loss = 0.39630866423249245, disc_loss = 0.09084694830665324
Trained batch 368 in epoch 10, gen_loss = 0.3962091780936492, disc_loss = 0.09083836671182012
Trained batch 369 in epoch 10, gen_loss = 0.3959303038345801, disc_loss = 0.09130827967908133
Trained batch 370 in epoch 10, gen_loss = 0.39615104325376754, disc_loss = 0.09218537885911582
Trained batch 371 in epoch 10, gen_loss = 0.3962614037977752, disc_loss = 0.09200171653747118
Trained batch 372 in epoch 10, gen_loss = 0.39608106472536964, disc_loss = 0.09183535035874385
Trained batch 373 in epoch 10, gen_loss = 0.3958820848860205, disc_loss = 0.09180925585414199
Trained batch 374 in epoch 10, gen_loss = 0.39579286257425944, disc_loss = 0.09161454558496673
Trained batch 375 in epoch 10, gen_loss = 0.3958691939553048, disc_loss = 0.0914372972651147
Trained batch 376 in epoch 10, gen_loss = 0.3956886796325208, disc_loss = 0.09125871591353962
Trained batch 377 in epoch 10, gen_loss = 0.395554802168614, disc_loss = 0.09107170067357993
Trained batch 378 in epoch 10, gen_loss = 0.39546273298817136, disc_loss = 0.09089279709639406
Trained batch 379 in epoch 10, gen_loss = 0.39527359353868585, disc_loss = 0.09087771298976517
Trained batch 380 in epoch 10, gen_loss = 0.3953273530237944, disc_loss = 0.09082780502800124
Trained batch 381 in epoch 10, gen_loss = 0.39532995512660263, disc_loss = 0.09083157212288163
Trained batch 382 in epoch 10, gen_loss = 0.39534888566318444, disc_loss = 0.09090908101392671
Trained batch 383 in epoch 10, gen_loss = 0.3953420149628073, disc_loss = 0.0910001182552757
Trained batch 384 in epoch 10, gen_loss = 0.3952185670276741, disc_loss = 0.0908237727201701
Trained batch 385 in epoch 10, gen_loss = 0.3949425720025838, disc_loss = 0.09133700491411736
Trained batch 386 in epoch 10, gen_loss = 0.39545131800094624, disc_loss = 0.09219275023764148
Trained batch 387 in epoch 10, gen_loss = 0.3956903521854853, disc_loss = 0.09210963519986182
Trained batch 388 in epoch 10, gen_loss = 0.3955368339862186, disc_loss = 0.09204714066902017
Trained batch 389 in epoch 10, gen_loss = 0.3954726184025789, disc_loss = 0.09187453676803181
Trained batch 390 in epoch 10, gen_loss = 0.3955579187406603, disc_loss = 0.09169466567852194
Trained batch 391 in epoch 10, gen_loss = 0.3955976129034344, disc_loss = 0.09153426772254349
Trained batch 392 in epoch 10, gen_loss = 0.3955296103584251, disc_loss = 0.09133598565908371
Trained batch 393 in epoch 10, gen_loss = 0.39541672200418365, disc_loss = 0.0911665569227378
Trained batch 394 in epoch 10, gen_loss = 0.3953865897051896, disc_loss = 0.09105004392965119
Trained batch 395 in epoch 10, gen_loss = 0.3955106949715903, disc_loss = 0.09085851225348171
Trained batch 396 in epoch 10, gen_loss = 0.3954670065145949, disc_loss = 0.0907506373222983
Trained batch 397 in epoch 10, gen_loss = 0.3952505766746387, disc_loss = 0.09094852964094274
Trained batch 398 in epoch 10, gen_loss = 0.39544506046108735, disc_loss = 0.09116294553017892
Trained batch 399 in epoch 10, gen_loss = 0.3954343359172344, disc_loss = 0.09105443346896208
Trained batch 400 in epoch 10, gen_loss = 0.39542472644934334, disc_loss = 0.09084247504511936
Trained batch 401 in epoch 10, gen_loss = 0.39551177220558054, disc_loss = 0.09064650440945368
Trained batch 402 in epoch 10, gen_loss = 0.39559108817547783, disc_loss = 0.09052369328419084
Trained batch 403 in epoch 10, gen_loss = 0.39575863268115735, disc_loss = 0.09051104089922944
Trained batch 404 in epoch 10, gen_loss = 0.3957254488527039, disc_loss = 0.09039817601327359
Trained batch 405 in epoch 10, gen_loss = 0.39570573361342765, disc_loss = 0.0902004390691173
Trained batch 406 in epoch 10, gen_loss = 0.3958394145204043, disc_loss = 0.09000538916873954
Trained batch 407 in epoch 10, gen_loss = 0.39585111947620616, disc_loss = 0.09000084612532244
Trained batch 408 in epoch 10, gen_loss = 0.3957457150398665, disc_loss = 0.09019224106477605
Trained batch 409 in epoch 10, gen_loss = 0.39584852275325033, disc_loss = 0.09009425746753993
Trained batch 410 in epoch 10, gen_loss = 0.39608070428354025, disc_loss = 0.08993022039038676
Trained batch 411 in epoch 10, gen_loss = 0.39600677289141034, disc_loss = 0.08983787163092927
Trained batch 412 in epoch 10, gen_loss = 0.39610994107498093, disc_loss = 0.08973998454969927
Trained batch 413 in epoch 10, gen_loss = 0.396113196576851, disc_loss = 0.08985157947478915
Trained batch 414 in epoch 10, gen_loss = 0.3962814298020788, disc_loss = 0.09001784237909569
Trained batch 415 in epoch 10, gen_loss = 0.39623466248695666, disc_loss = 0.08992485778491335
Trained batch 416 in epoch 10, gen_loss = 0.39638186923319774, disc_loss = 0.08977045678830654
Trained batch 417 in epoch 10, gen_loss = 0.39640065435872696, disc_loss = 0.08974450094843703
Trained batch 418 in epoch 10, gen_loss = 0.3965517125294715, disc_loss = 0.09000801925296253
Trained batch 419 in epoch 10, gen_loss = 0.39653998166322707, disc_loss = 0.09054683914208518
Trained batch 420 in epoch 10, gen_loss = 0.39681987800677426, disc_loss = 0.09056238294634393
Trained batch 421 in epoch 10, gen_loss = 0.39706758745191223, disc_loss = 0.09039636006936325
Trained batch 422 in epoch 10, gen_loss = 0.397026833490277, disc_loss = 0.09025740921475328
Trained batch 423 in epoch 10, gen_loss = 0.39696813937065734, disc_loss = 0.09010468248414087
Trained batch 424 in epoch 10, gen_loss = 0.3970174677932964, disc_loss = 0.08990845957990079
Trained batch 425 in epoch 10, gen_loss = 0.39707375412255946, disc_loss = 0.0897551672216155
Trained batch 426 in epoch 10, gen_loss = 0.39707787519874843, disc_loss = 0.0896193648500922
Trained batch 427 in epoch 10, gen_loss = 0.3970218059197764, disc_loss = 0.08952331075457874
Trained batch 428 in epoch 10, gen_loss = 0.39701451239608104, disc_loss = 0.08956392379347365
Trained batch 429 in epoch 10, gen_loss = 0.3968098492816437, disc_loss = 0.08974473270977479
Trained batch 430 in epoch 10, gen_loss = 0.3969270684464625, disc_loss = 0.09007780176853186
Trained batch 431 in epoch 10, gen_loss = 0.39682526500136767, disc_loss = 0.0899759513677391
Trained batch 432 in epoch 10, gen_loss = 0.3968101122500439, disc_loss = 0.08985617335167376
Trained batch 433 in epoch 10, gen_loss = 0.39660975728441494, disc_loss = 0.08969695101200265
Trained batch 434 in epoch 10, gen_loss = 0.39639173657044596, disc_loss = 0.08984097685001191
Trained batch 435 in epoch 10, gen_loss = 0.3965263936087626, disc_loss = 0.09038764263029048
Trained batch 436 in epoch 10, gen_loss = 0.39648320241159923, disc_loss = 0.0902917615172093
Trained batch 437 in epoch 10, gen_loss = 0.3963213716059515, disc_loss = 0.09035181421595179
Trained batch 438 in epoch 10, gen_loss = 0.39652563105411576, disc_loss = 0.09021703609857275
Trained batch 439 in epoch 10, gen_loss = 0.39670061855153604, disc_loss = 0.09003652653508736
Trained batch 440 in epoch 10, gen_loss = 0.3966634724956521, disc_loss = 0.08991490022433486
Trained batch 441 in epoch 10, gen_loss = 0.39665030361030973, disc_loss = 0.0898542617083152
Trained batch 442 in epoch 10, gen_loss = 0.3966504493497026, disc_loss = 0.08972958504888766
Trained batch 443 in epoch 10, gen_loss = 0.39656729841822974, disc_loss = 0.08964877657126635
Trained batch 444 in epoch 10, gen_loss = 0.39673937411790483, disc_loss = 0.08963383363476128
Trained batch 445 in epoch 10, gen_loss = 0.3966821306489508, disc_loss = 0.0895421443926797
Trained batch 446 in epoch 10, gen_loss = 0.3966270538517826, disc_loss = 0.09021465614608903
Trained batch 447 in epoch 10, gen_loss = 0.39688797135438236, disc_loss = 0.09008589664777641
Trained batch 448 in epoch 10, gen_loss = 0.39703056534839365, disc_loss = 0.09017887929006416
Trained batch 449 in epoch 10, gen_loss = 0.39699259731504655, disc_loss = 0.09015153310468628
Trained batch 450 in epoch 10, gen_loss = 0.3968740202106552, disc_loss = 0.090154164382969
Trained batch 451 in epoch 10, gen_loss = 0.3968770835647541, disc_loss = 0.09019763367271166
Trained batch 452 in epoch 10, gen_loss = 0.39676965605344205, disc_loss = 0.09002987052073443
Trained batch 453 in epoch 10, gen_loss = 0.39661791631828847, disc_loss = 0.0900357824305097
Trained batch 454 in epoch 10, gen_loss = 0.39666677189397287, disc_loss = 0.09011269413282746
Trained batch 455 in epoch 10, gen_loss = 0.39670502904214355, disc_loss = 0.09002148029251482
Trained batch 456 in epoch 10, gen_loss = 0.39655936468612707, disc_loss = 0.08988824938841702
Trained batch 457 in epoch 10, gen_loss = 0.39655979888668225, disc_loss = 0.08982285939860585
Trained batch 458 in epoch 10, gen_loss = 0.39663371242469175, disc_loss = 0.08973410993932152
Trained batch 459 in epoch 10, gen_loss = 0.3966434824725856, disc_loss = 0.08958702311830838
Trained batch 460 in epoch 10, gen_loss = 0.396750604382306, disc_loss = 0.08943015002946565
Testing Epoch 10
Training Epoch 11
Trained batch 0 in epoch 11, gen_loss = 0.32274454832077026, disc_loss = 0.032414212822914124
Trained batch 1 in epoch 11, gen_loss = 0.4313546419143677, disc_loss = 0.043241072446107864
Trained batch 2 in epoch 11, gen_loss = 0.42149266600608826, disc_loss = 0.0735851302742958
Trained batch 3 in epoch 11, gen_loss = 0.417437881231308, disc_loss = 0.09347028099000454
Trained batch 4 in epoch 11, gen_loss = 0.4089124023914337, disc_loss = 0.07651064563542605
Trained batch 5 in epoch 11, gen_loss = 0.3949362486600876, disc_loss = 0.06810714723542333
Trained batch 6 in epoch 11, gen_loss = 0.39336125765527996, disc_loss = 0.0628424258902669
Trained batch 7 in epoch 11, gen_loss = 0.4004095271229744, disc_loss = 0.057041140156798065
Trained batch 8 in epoch 11, gen_loss = 0.3954611685540941, disc_loss = 0.05635962045441071
Trained batch 9 in epoch 11, gen_loss = 0.3993162214756012, disc_loss = 0.05525793312117457
Trained batch 10 in epoch 11, gen_loss = 0.40358592705293134, disc_loss = 0.052283928729593754
Trained batch 11 in epoch 11, gen_loss = 0.4084002450108528, disc_loss = 0.05400118689673642
Trained batch 12 in epoch 11, gen_loss = 0.41287243136992824, disc_loss = 0.06513077328697993
Trained batch 13 in epoch 11, gen_loss = 0.40748222172260284, disc_loss = 0.07684126143742885
Trained batch 14 in epoch 11, gen_loss = 0.4138020654519399, disc_loss = 0.07556137833744288
Trained batch 15 in epoch 11, gen_loss = 0.41579742915928364, disc_loss = 0.07373219350120053
Trained batch 16 in epoch 11, gen_loss = 0.42194727413794575, disc_loss = 0.06987158461090397
Trained batch 17 in epoch 11, gen_loss = 0.4198871569501029, disc_loss = 0.06680243348495828
Trained batch 18 in epoch 11, gen_loss = 0.41866920025725113, disc_loss = 0.06451752242681227
Trained batch 19 in epoch 11, gen_loss = 0.41567213088274, disc_loss = 0.06164210955612361
Trained batch 20 in epoch 11, gen_loss = 0.41628617757842656, disc_loss = 0.0589540462408747
Trained batch 21 in epoch 11, gen_loss = 0.41330626336011017, disc_loss = 0.057664632627909836
Trained batch 22 in epoch 11, gen_loss = 0.411122423151265, disc_loss = 0.05655730531915375
Trained batch 23 in epoch 11, gen_loss = 0.40954358875751495, disc_loss = 0.056308814945320286
Trained batch 24 in epoch 11, gen_loss = 0.4083681666851044, disc_loss = 0.06056407004594803
Trained batch 25 in epoch 11, gen_loss = 0.40242321445391727, disc_loss = 0.06879547152381676
Trained batch 26 in epoch 11, gen_loss = 0.40182896344750013, disc_loss = 0.0727013826922134
Trained batch 27 in epoch 11, gen_loss = 0.4027984929936273, disc_loss = 0.071565625124744
Trained batch 28 in epoch 11, gen_loss = 0.400704143376186, disc_loss = 0.07022967896070974
Trained batch 29 in epoch 11, gen_loss = 0.3988079011440277, disc_loss = 0.07011873833835125
Trained batch 30 in epoch 11, gen_loss = 0.4017684767323156, disc_loss = 0.07274939035696368
Trained batch 31 in epoch 11, gen_loss = 0.4012916153296828, disc_loss = 0.07167801528703421
Trained batch 32 in epoch 11, gen_loss = 0.40046628587173694, disc_loss = 0.07001210043601917
Trained batch 33 in epoch 11, gen_loss = 0.40040173513047833, disc_loss = 0.06891673271927763
Trained batch 34 in epoch 11, gen_loss = 0.4006047827856881, disc_loss = 0.06918931896133082
Trained batch 35 in epoch 11, gen_loss = 0.3996010596553485, disc_loss = 0.07256176027779777
Trained batch 36 in epoch 11, gen_loss = 0.40337034254460724, disc_loss = 0.07567161115238795
Trained batch 37 in epoch 11, gen_loss = 0.4041793762068999, disc_loss = 0.07471718408755566
Trained batch 38 in epoch 11, gen_loss = 0.4026464338486011, disc_loss = 0.07516230169970256
Trained batch 39 in epoch 11, gen_loss = 0.4020640440285206, disc_loss = 0.07364198118448258
Trained batch 40 in epoch 11, gen_loss = 0.40364605915255664, disc_loss = 0.07213285847044573
Trained batch 41 in epoch 11, gen_loss = 0.4042160596166338, disc_loss = 0.0713753631072385
Trained batch 42 in epoch 11, gen_loss = 0.4022402486135793, disc_loss = 0.07287955821253532
Trained batch 43 in epoch 11, gen_loss = 0.4058225154876709, disc_loss = 0.07437731918286193
Trained batch 44 in epoch 11, gen_loss = 0.4062129722701179, disc_loss = 0.07383976040614976
Trained batch 45 in epoch 11, gen_loss = 0.4042614866857943, disc_loss = 0.07300318299752215
Trained batch 46 in epoch 11, gen_loss = 0.40161815349091873, disc_loss = 0.07345353629677853
Trained batch 47 in epoch 11, gen_loss = 0.4016781095415354, disc_loss = 0.07318651924530666
Trained batch 48 in epoch 11, gen_loss = 0.4004919571535928, disc_loss = 0.0743059555486757
Trained batch 49 in epoch 11, gen_loss = 0.4007550138235092, disc_loss = 0.07508423417806626
Trained batch 50 in epoch 11, gen_loss = 0.4010729152782291, disc_loss = 0.08196513471650142
Trained batch 51 in epoch 11, gen_loss = 0.399589859522306, disc_loss = 0.0854151865037588
Trained batch 52 in epoch 11, gen_loss = 0.3992587924003601, disc_loss = 0.08619872803957958
Trained batch 53 in epoch 11, gen_loss = 0.3984759858360997, disc_loss = 0.08530528995173949
Trained batch 54 in epoch 11, gen_loss = 0.3989050881429152, disc_loss = 0.08419919440692121
Trained batch 55 in epoch 11, gen_loss = 0.39786223641463686, disc_loss = 0.08368797407352499
Trained batch 56 in epoch 11, gen_loss = 0.3986008512346368, disc_loss = 0.08241447339063152
Trained batch 57 in epoch 11, gen_loss = 0.39811574282317325, disc_loss = 0.08138914297110048
Trained batch 58 in epoch 11, gen_loss = 0.39791817634792653, disc_loss = 0.08028151347475537
Trained batch 59 in epoch 11, gen_loss = 0.39749280661344527, disc_loss = 0.07944902280966441
Trained batch 60 in epoch 11, gen_loss = 0.3982435499058395, disc_loss = 0.078740586999987
Trained batch 61 in epoch 11, gen_loss = 0.3972421230808381, disc_loss = 0.07854530467621741
Trained batch 62 in epoch 11, gen_loss = 0.3970568326730577, disc_loss = 0.08094471089896701
Trained batch 63 in epoch 11, gen_loss = 0.3963272566907108, disc_loss = 0.08467037056107074
Trained batch 64 in epoch 11, gen_loss = 0.3974292704692254, disc_loss = 0.08402515007899358
Trained batch 65 in epoch 11, gen_loss = 0.39756447979898163, disc_loss = 0.0857355251456752
Trained batch 66 in epoch 11, gen_loss = 0.3965273904266642, disc_loss = 0.0881232092184807
Trained batch 67 in epoch 11, gen_loss = 0.39684877237852884, disc_loss = 0.08769702845636536
Trained batch 68 in epoch 11, gen_loss = 0.39774910522543866, disc_loss = 0.08972428739070892
Trained batch 69 in epoch 11, gen_loss = 0.3976374183382307, disc_loss = 0.08871736337563821
Trained batch 70 in epoch 11, gen_loss = 0.3974967489779835, disc_loss = 0.08890301453500567
Trained batch 71 in epoch 11, gen_loss = 0.39718741840786403, disc_loss = 0.08838121336884797
Trained batch 72 in epoch 11, gen_loss = 0.3967113927619098, disc_loss = 0.087455430284959
Trained batch 73 in epoch 11, gen_loss = 0.3967002803409422, disc_loss = 0.08698915400718515
Trained batch 74 in epoch 11, gen_loss = 0.3966557844479879, disc_loss = 0.0879290480663379
Trained batch 75 in epoch 11, gen_loss = 0.3971666874069917, disc_loss = 0.09275892918537322
Trained batch 76 in epoch 11, gen_loss = 0.39751757584608993, disc_loss = 0.09252841531166009
Trained batch 77 in epoch 11, gen_loss = 0.3968610488451444, disc_loss = 0.09404870077299002
Trained batch 78 in epoch 11, gen_loss = 0.39684240387964853, disc_loss = 0.09348499758428411
Trained batch 79 in epoch 11, gen_loss = 0.39579475708305834, disc_loss = 0.09274456219282001
Trained batch 80 in epoch 11, gen_loss = 0.3967058916150788, disc_loss = 0.09185976220041882
Trained batch 81 in epoch 11, gen_loss = 0.39643798296044513, disc_loss = 0.09163378022338559
Trained batch 82 in epoch 11, gen_loss = 0.39643113656216356, disc_loss = 0.09172625271940088
Trained batch 83 in epoch 11, gen_loss = 0.39605283666224705, disc_loss = 0.09300291048185456
Trained batch 84 in epoch 11, gen_loss = 0.3961369034122018, disc_loss = 0.09367670020198121
Trained batch 85 in epoch 11, gen_loss = 0.39460577070713043, disc_loss = 0.09397335097107083
Trained batch 86 in epoch 11, gen_loss = 0.39499504538788194, disc_loss = 0.09391587773530648
Trained batch 87 in epoch 11, gen_loss = 0.39423314414241095, disc_loss = 0.09444078606214713
Trained batch 88 in epoch 11, gen_loss = 0.395066106252456, disc_loss = 0.09468961186874449
Trained batch 89 in epoch 11, gen_loss = 0.39504262771871357, disc_loss = 0.0939298925921321
Trained batch 90 in epoch 11, gen_loss = 0.39478212201988305, disc_loss = 0.0931292118525112
Trained batch 91 in epoch 11, gen_loss = 0.3941175286536631, disc_loss = 0.09280957083177307
Trained batch 92 in epoch 11, gen_loss = 0.39363449811935425, disc_loss = 0.0921627135286408
Trained batch 93 in epoch 11, gen_loss = 0.39406491403884075, disc_loss = 0.09132846179319189
Trained batch 94 in epoch 11, gen_loss = 0.39407140738085694, disc_loss = 0.09109100899414012
Trained batch 95 in epoch 11, gen_loss = 0.3941641928007205, disc_loss = 0.0906831647735089
Trained batch 96 in epoch 11, gen_loss = 0.3941943264499153, disc_loss = 0.08999085599153313
Trained batch 97 in epoch 11, gen_loss = 0.39468933550678953, disc_loss = 0.08951014706066676
Trained batch 98 in epoch 11, gen_loss = 0.39464577701356673, disc_loss = 0.08916323500299694
Trained batch 99 in epoch 11, gen_loss = 0.39383910208940504, disc_loss = 0.08925911102443934
Trained batch 100 in epoch 11, gen_loss = 0.39484128769081417, disc_loss = 0.09078409828909553
Trained batch 101 in epoch 11, gen_loss = 0.39462155132901433, disc_loss = 0.0906640732770457
Trained batch 102 in epoch 11, gen_loss = 0.3939330126475362, disc_loss = 0.09121211701371137
Trained batch 103 in epoch 11, gen_loss = 0.39398417335290176, disc_loss = 0.091457736499321
Trained batch 104 in epoch 11, gen_loss = 0.3939875494866144, disc_loss = 0.09088150612300351
Trained batch 105 in epoch 11, gen_loss = 0.394006609635533, disc_loss = 0.09078144656388827
Trained batch 106 in epoch 11, gen_loss = 0.39490541035883897, disc_loss = 0.09053352407275517
Trained batch 107 in epoch 11, gen_loss = 0.3954978256865784, disc_loss = 0.08994842194779604
Trained batch 108 in epoch 11, gen_loss = 0.3957147171737951, disc_loss = 0.0893996750440346
Trained batch 109 in epoch 11, gen_loss = 0.39571043090386826, disc_loss = 0.08918310710313646
Trained batch 110 in epoch 11, gen_loss = 0.3948532485210144, disc_loss = 0.08949776733847889
Trained batch 111 in epoch 11, gen_loss = 0.3961924423596689, disc_loss = 0.09069922967215202
Trained batch 112 in epoch 11, gen_loss = 0.3954261016529218, disc_loss = 0.09075678675641528
Trained batch 113 in epoch 11, gen_loss = 0.39557047946411267, disc_loss = 0.09032121701002643
Trained batch 114 in epoch 11, gen_loss = 0.39612889004790264, disc_loss = 0.09039963491908883
Trained batch 115 in epoch 11, gen_loss = 0.39621427192770203, disc_loss = 0.08998296135265765
Trained batch 116 in epoch 11, gen_loss = 0.39639652998019487, disc_loss = 0.08983121864879742
Trained batch 117 in epoch 11, gen_loss = 0.3961115459264335, disc_loss = 0.08977043402965292
Trained batch 118 in epoch 11, gen_loss = 0.39625657731745423, disc_loss = 0.08949270645673034
Trained batch 119 in epoch 11, gen_loss = 0.3955825539926688, disc_loss = 0.08942128874671956
Trained batch 120 in epoch 11, gen_loss = 0.39575628677675545, disc_loss = 0.08944293205464675
Trained batch 121 in epoch 11, gen_loss = 0.3953395532291444, disc_loss = 0.08916492401393222
Trained batch 122 in epoch 11, gen_loss = 0.39473190709827394, disc_loss = 0.08877236948810457
Trained batch 123 in epoch 11, gen_loss = 0.394117433217264, disc_loss = 0.08877223401120113
Trained batch 124 in epoch 11, gen_loss = 0.39487543439865114, disc_loss = 0.08818632036447525
Trained batch 125 in epoch 11, gen_loss = 0.3950504187553648, disc_loss = 0.09092867451291235
Trained batch 126 in epoch 11, gen_loss = 0.3945974285208334, disc_loss = 0.09190892850554834
Trained batch 127 in epoch 11, gen_loss = 0.39541777269914746, disc_loss = 0.09180795977590606
Trained batch 128 in epoch 11, gen_loss = 0.39530190964077794, disc_loss = 0.0914373459626538
Trained batch 129 in epoch 11, gen_loss = 0.39487954194729147, disc_loss = 0.09096973902330949
Trained batch 130 in epoch 11, gen_loss = 0.39506675268857533, disc_loss = 0.09088064118764783
Trained batch 131 in epoch 11, gen_loss = 0.39477656488165713, disc_loss = 0.09101896696357113
Trained batch 132 in epoch 11, gen_loss = 0.3952204862931617, disc_loss = 0.09110686437864053
Trained batch 133 in epoch 11, gen_loss = 0.3949854629698084, disc_loss = 0.09064411959930588
Trained batch 134 in epoch 11, gen_loss = 0.39420266482565136, disc_loss = 0.0918691745372834
Trained batch 135 in epoch 11, gen_loss = 0.394976828028174, disc_loss = 0.0921534682103597
Trained batch 136 in epoch 11, gen_loss = 0.39495134919229213, disc_loss = 0.09174470939285999
Trained batch 137 in epoch 11, gen_loss = 0.3953434295844341, disc_loss = 0.0920306852195358
Trained batch 138 in epoch 11, gen_loss = 0.39567238371149244, disc_loss = 0.09354976525784825
Trained batch 139 in epoch 11, gen_loss = 0.39555670193263465, disc_loss = 0.09357735114172101
Trained batch 140 in epoch 11, gen_loss = 0.3951589549686892, disc_loss = 0.09336260086625603
Trained batch 141 in epoch 11, gen_loss = 0.39573806734152245, disc_loss = 0.09317825360774575
Trained batch 142 in epoch 11, gen_loss = 0.3959057049734609, disc_loss = 0.09287433601082205
Trained batch 143 in epoch 11, gen_loss = 0.3953587046513955, disc_loss = 0.09315286011486831
Trained batch 144 in epoch 11, gen_loss = 0.39536934947145397, disc_loss = 0.09320732230513261
Trained batch 145 in epoch 11, gen_loss = 0.3955365490831741, disc_loss = 0.09303918750063606
Trained batch 146 in epoch 11, gen_loss = 0.39542059590216394, disc_loss = 0.09251729035306544
Trained batch 147 in epoch 11, gen_loss = 0.3956517420105032, disc_loss = 0.09201895722464935
Trained batch 148 in epoch 11, gen_loss = 0.39541797669941947, disc_loss = 0.09184150992823928
Trained batch 149 in epoch 11, gen_loss = 0.3949302345514297, disc_loss = 0.09191034878293673
Trained batch 150 in epoch 11, gen_loss = 0.3954934594252252, disc_loss = 0.0914992606205656
Trained batch 151 in epoch 11, gen_loss = 0.3956023005670623, disc_loss = 0.09118217072988812
Trained batch 152 in epoch 11, gen_loss = 0.39581363594609925, disc_loss = 0.09119775535818798
Trained batch 153 in epoch 11, gen_loss = 0.3963739570085104, disc_loss = 0.09106818199544758
Trained batch 154 in epoch 11, gen_loss = 0.3964228189760639, disc_loss = 0.09056520181437654
Trained batch 155 in epoch 11, gen_loss = 0.3965186493901106, disc_loss = 0.09085174170561516
Trained batch 156 in epoch 11, gen_loss = 0.3970227072573012, disc_loss = 0.09118010415132069
Trained batch 157 in epoch 11, gen_loss = 0.3968812693146211, disc_loss = 0.09087469672218343
Trained batch 158 in epoch 11, gen_loss = 0.39628603229732634, disc_loss = 0.09135082296722527
Trained batch 159 in epoch 11, gen_loss = 0.396766366623342, disc_loss = 0.09085823810310104
Trained batch 160 in epoch 11, gen_loss = 0.3971984367933333, disc_loss = 0.09085774852645508
Trained batch 161 in epoch 11, gen_loss = 0.3972863854817402, disc_loss = 0.09112702949938399
Trained batch 162 in epoch 11, gen_loss = 0.397279860600372, disc_loss = 0.09125706266063305
Trained batch 163 in epoch 11, gen_loss = 0.3968183532720659, disc_loss = 0.09101543235365392
Trained batch 164 in epoch 11, gen_loss = 0.39729302868698585, disc_loss = 0.09060420843800812
Trained batch 165 in epoch 11, gen_loss = 0.3976181011243039, disc_loss = 0.0902140132061778
Trained batch 166 in epoch 11, gen_loss = 0.39796325707150076, disc_loss = 0.08989894368356752
Trained batch 167 in epoch 11, gen_loss = 0.3976972975901195, disc_loss = 0.08986259891008515
Trained batch 168 in epoch 11, gen_loss = 0.397872785139366, disc_loss = 0.08997798081178814
Trained batch 169 in epoch 11, gen_loss = 0.3974657125332776, disc_loss = 0.08961654521853608
Trained batch 170 in epoch 11, gen_loss = 0.3971376467866507, disc_loss = 0.0898968957048672
Trained batch 171 in epoch 11, gen_loss = 0.397625298867392, disc_loss = 0.09022602644142542
Trained batch 172 in epoch 11, gen_loss = 0.39777115814258596, disc_loss = 0.08984178970594799
Trained batch 173 in epoch 11, gen_loss = 0.39754363877334814, disc_loss = 0.08971483318734615
Trained batch 174 in epoch 11, gen_loss = 0.3974999592985426, disc_loss = 0.08991193399365459
Trained batch 175 in epoch 11, gen_loss = 0.397938389161771, disc_loss = 0.08968953575028783
Trained batch 176 in epoch 11, gen_loss = 0.3982183145264448, disc_loss = 0.08942246241863333
Trained batch 177 in epoch 11, gen_loss = 0.3985063711578926, disc_loss = 0.08977977343929115
Trained batch 178 in epoch 11, gen_loss = 0.3984034138018859, disc_loss = 0.08958786116736062
Trained batch 179 in epoch 11, gen_loss = 0.39795577890343137, disc_loss = 0.08960396339599457
Trained batch 180 in epoch 11, gen_loss = 0.3977929885545488, disc_loss = 0.09064194467947792
Trained batch 181 in epoch 11, gen_loss = 0.39803324246799554, disc_loss = 0.09171121222079619
Trained batch 182 in epoch 11, gen_loss = 0.39779208608663796, disc_loss = 0.09142321452518792
Trained batch 183 in epoch 11, gen_loss = 0.3977477500296157, disc_loss = 0.0913949515113769
Trained batch 184 in epoch 11, gen_loss = 0.39774442846710617, disc_loss = 0.09149416550691869
Trained batch 185 in epoch 11, gen_loss = 0.3977986139956341, disc_loss = 0.09127854992966017
Trained batch 186 in epoch 11, gen_loss = 0.3971824532842891, disc_loss = 0.09105962260382221
Trained batch 187 in epoch 11, gen_loss = 0.3969727313898979, disc_loss = 0.09076384685319314
Trained batch 188 in epoch 11, gen_loss = 0.3967326685549721, disc_loss = 0.09038424792960681
Trained batch 189 in epoch 11, gen_loss = 0.3968064518351304, disc_loss = 0.09032879888913349
Trained batch 190 in epoch 11, gen_loss = 0.39687448006649917, disc_loss = 0.09013928622690015
Trained batch 191 in epoch 11, gen_loss = 0.39704830028737587, disc_loss = 0.09035273270274047
Trained batch 192 in epoch 11, gen_loss = 0.39715422728518746, disc_loss = 0.09066572516596842
Trained batch 193 in epoch 11, gen_loss = 0.396912797363763, disc_loss = 0.09073030350960254
Trained batch 194 in epoch 11, gen_loss = 0.397353398341399, disc_loss = 0.09152477476745843
Trained batch 195 in epoch 11, gen_loss = 0.39734581949151293, disc_loss = 0.09123745261767537
Trained batch 196 in epoch 11, gen_loss = 0.39772651658445446, disc_loss = 0.09176976325907532
Trained batch 197 in epoch 11, gen_loss = 0.39807144665356836, disc_loss = 0.09285259161690118
Trained batch 198 in epoch 11, gen_loss = 0.39791084249414993, disc_loss = 0.0925773771517166
Trained batch 199 in epoch 11, gen_loss = 0.3972934573888779, disc_loss = 0.09303044497501105
Trained batch 200 in epoch 11, gen_loss = 0.39723404485787916, disc_loss = 0.09305266375695147
Trained batch 201 in epoch 11, gen_loss = 0.39764424155254174, disc_loss = 0.09281090607792877
Trained batch 202 in epoch 11, gen_loss = 0.3976216838864857, disc_loss = 0.09258654775565921
Trained batch 203 in epoch 11, gen_loss = 0.39723299575202603, disc_loss = 0.09249120062746692
Trained batch 204 in epoch 11, gen_loss = 0.39688673252012674, disc_loss = 0.09218976265500958
Trained batch 205 in epoch 11, gen_loss = 0.3967578169500944, disc_loss = 0.0918237698011245
Trained batch 206 in epoch 11, gen_loss = 0.39630650250232163, disc_loss = 0.09260884022277191
Trained batch 207 in epoch 11, gen_loss = 0.39609489776194096, disc_loss = 0.09398451183761398
Trained batch 208 in epoch 11, gen_loss = 0.3960826734891919, disc_loss = 0.09428367155501574
Trained batch 209 in epoch 11, gen_loss = 0.39604659591402325, disc_loss = 0.09439226567656511
Trained batch 210 in epoch 11, gen_loss = 0.39563294242343633, disc_loss = 0.09441055153977673
Trained batch 211 in epoch 11, gen_loss = 0.39556536008164567, disc_loss = 0.09414672710546204
Trained batch 212 in epoch 11, gen_loss = 0.395435286939424, disc_loss = 0.09378393462688571
Trained batch 213 in epoch 11, gen_loss = 0.3956611883417468, disc_loss = 0.09341867675865505
Trained batch 214 in epoch 11, gen_loss = 0.39526105342909346, disc_loss = 0.09313065822474485
Trained batch 215 in epoch 11, gen_loss = 0.3947111976643403, disc_loss = 0.09299723062819491
Trained batch 216 in epoch 11, gen_loss = 0.39429504228627077, disc_loss = 0.09287199642818232
Trained batch 217 in epoch 11, gen_loss = 0.39400588796226255, disc_loss = 0.09268352059955033
Trained batch 218 in epoch 11, gen_loss = 0.3939889255723997, disc_loss = 0.09235374218269707
Trained batch 219 in epoch 11, gen_loss = 0.39452527815645394, disc_loss = 0.09203167335468937
Trained batch 220 in epoch 11, gen_loss = 0.394111064224761, disc_loss = 0.09191182236781352
Trained batch 221 in epoch 11, gen_loss = 0.393924455116461, disc_loss = 0.09176660543475468
Trained batch 222 in epoch 11, gen_loss = 0.3941190054331125, disc_loss = 0.09242238411303993
Trained batch 223 in epoch 11, gen_loss = 0.3938149550397481, disc_loss = 0.09269032507186889
Trained batch 224 in epoch 11, gen_loss = 0.39422985752423606, disc_loss = 0.09243358585155673
Trained batch 225 in epoch 11, gen_loss = 0.39464729035322643, disc_loss = 0.0922461855225265
Trained batch 226 in epoch 11, gen_loss = 0.3945351097289686, disc_loss = 0.09211941210692544
Trained batch 227 in epoch 11, gen_loss = 0.3945724821665831, disc_loss = 0.09190315945613149
Trained batch 228 in epoch 11, gen_loss = 0.39481906430169483, disc_loss = 0.09167109274886971
Trained batch 229 in epoch 11, gen_loss = 0.3951313380313956, disc_loss = 0.09212278848028053
Trained batch 230 in epoch 11, gen_loss = 0.3950533475968745, disc_loss = 0.09290928288375015
Trained batch 231 in epoch 11, gen_loss = 0.39526570806729383, disc_loss = 0.09267776420516573
Trained batch 232 in epoch 11, gen_loss = 0.3950524395371711, disc_loss = 0.0926252886804836
Trained batch 233 in epoch 11, gen_loss = 0.39495336499988526, disc_loss = 0.09261204209576687
Trained batch 234 in epoch 11, gen_loss = 0.3954647918964954, disc_loss = 0.09316604844036888
Trained batch 235 in epoch 11, gen_loss = 0.39576067522925845, disc_loss = 0.09315090843918339
Trained batch 236 in epoch 11, gen_loss = 0.39586854735507243, disc_loss = 0.09296077915431955
Trained batch 237 in epoch 11, gen_loss = 0.3957248366430026, disc_loss = 0.09285807535600137
Trained batch 238 in epoch 11, gen_loss = 0.39540844918793716, disc_loss = 0.09274723123229074
Trained batch 239 in epoch 11, gen_loss = 0.3954009598741929, disc_loss = 0.09264249985960002
Trained batch 240 in epoch 11, gen_loss = 0.39507264702646566, disc_loss = 0.09258166349326798
Trained batch 241 in epoch 11, gen_loss = 0.39485297321288054, disc_loss = 0.09353733171655004
Trained batch 242 in epoch 11, gen_loss = 0.39425067769156563, disc_loss = 0.09369513905633992
Trained batch 243 in epoch 11, gen_loss = 0.39456207879254074, disc_loss = 0.09407291290747216
Trained batch 244 in epoch 11, gen_loss = 0.3947248607265706, disc_loss = 0.09414540676362053
Trained batch 245 in epoch 11, gen_loss = 0.3948232646637816, disc_loss = 0.09410314044983285
Trained batch 246 in epoch 11, gen_loss = 0.39483909821703367, disc_loss = 0.09389227718823714
Trained batch 247 in epoch 11, gen_loss = 0.3950083325466802, disc_loss = 0.09417553720319824
Trained batch 248 in epoch 11, gen_loss = 0.3948991921053354, disc_loss = 0.09463882553634274
Trained batch 249 in epoch 11, gen_loss = 0.3954404299259186, disc_loss = 0.09550513481721282
Trained batch 250 in epoch 11, gen_loss = 0.3951809348100685, disc_loss = 0.09552023621773222
Trained batch 251 in epoch 11, gen_loss = 0.3949507388567168, disc_loss = 0.09561231329904071
Trained batch 252 in epoch 11, gen_loss = 0.3946619469657717, disc_loss = 0.095434168769643
Trained batch 253 in epoch 11, gen_loss = 0.39478232635287785, disc_loss = 0.0951244766955946
Trained batch 254 in epoch 11, gen_loss = 0.39486071595958633, disc_loss = 0.09489668427656094
Trained batch 255 in epoch 11, gen_loss = 0.3947927341796458, disc_loss = 0.09474394654898788
Trained batch 256 in epoch 11, gen_loss = 0.39467550066194645, disc_loss = 0.09453749064906909
Trained batch 257 in epoch 11, gen_loss = 0.39446583713671957, disc_loss = 0.09439387140333537
Trained batch 258 in epoch 11, gen_loss = 0.39481023115080754, disc_loss = 0.09418017215465832
Trained batch 259 in epoch 11, gen_loss = 0.395116551220417, disc_loss = 0.09416137391772982
Trained batch 260 in epoch 11, gen_loss = 0.3951390465557347, disc_loss = 0.09404185705129557
Trained batch 261 in epoch 11, gen_loss = 0.39536521953480847, disc_loss = 0.09378334371913366
Trained batch 262 in epoch 11, gen_loss = 0.39556506276130676, disc_loss = 0.09350629525875297
Trained batch 263 in epoch 11, gen_loss = 0.3954987247107607, disc_loss = 0.09342174995055591
Trained batch 264 in epoch 11, gen_loss = 0.3958045835764903, disc_loss = 0.09319952375975982
Trained batch 265 in epoch 11, gen_loss = 0.39554778066344726, disc_loss = 0.09304442742307271
Trained batch 266 in epoch 11, gen_loss = 0.3957318748427687, disc_loss = 0.092803732994316
Trained batch 267 in epoch 11, gen_loss = 0.39623821493405015, disc_loss = 0.09271618210599382
Trained batch 268 in epoch 11, gen_loss = 0.3958666141813129, disc_loss = 0.09409018197065724
Trained batch 269 in epoch 11, gen_loss = 0.39550401292465354, disc_loss = 0.09440543539477167
Trained batch 270 in epoch 11, gen_loss = 0.3950906531177324, disc_loss = 0.09460048469271497
Trained batch 271 in epoch 11, gen_loss = 0.3948356772170347, disc_loss = 0.0945301059024025
Trained batch 272 in epoch 11, gen_loss = 0.3951521823694418, disc_loss = 0.09423957147632107
Trained batch 273 in epoch 11, gen_loss = 0.39513451296047575, disc_loss = 0.09395491276072325
Trained batch 274 in epoch 11, gen_loss = 0.39511939438906585, disc_loss = 0.09388939536430618
Trained batch 275 in epoch 11, gen_loss = 0.39533581995013833, disc_loss = 0.09426830399889445
Trained batch 276 in epoch 11, gen_loss = 0.39508211257655695, disc_loss = 0.09451576823953688
Trained batch 277 in epoch 11, gen_loss = 0.3952342967549674, disc_loss = 0.09440997016462062
Trained batch 278 in epoch 11, gen_loss = 0.3951873778228691, disc_loss = 0.0943036191699539
Trained batch 279 in epoch 11, gen_loss = 0.3951485688132899, disc_loss = 0.09427670372117843
Trained batch 280 in epoch 11, gen_loss = 0.3948413424220374, disc_loss = 0.09422238350073638
Trained batch 281 in epoch 11, gen_loss = 0.3950004700227832, disc_loss = 0.09397887700098626
Trained batch 282 in epoch 11, gen_loss = 0.3953848824484188, disc_loss = 0.09386057055196577
Trained batch 283 in epoch 11, gen_loss = 0.39539187821284144, disc_loss = 0.09365193446127462
Trained batch 284 in epoch 11, gen_loss = 0.39539226879153333, disc_loss = 0.0934276794982061
Trained batch 285 in epoch 11, gen_loss = 0.3955420499498194, disc_loss = 0.09319666462422876
Trained batch 286 in epoch 11, gen_loss = 0.3953585174025559, disc_loss = 0.09312005319635835
Trained batch 287 in epoch 11, gen_loss = 0.3947488069534302, disc_loss = 0.09416445628610542
Trained batch 288 in epoch 11, gen_loss = 0.39491672128129585, disc_loss = 0.09416454730742324
Trained batch 289 in epoch 11, gen_loss = 0.3948334101972909, disc_loss = 0.09425562712010638
Trained batch 290 in epoch 11, gen_loss = 0.3947396115543916, disc_loss = 0.09462550640285425
Trained batch 291 in epoch 11, gen_loss = 0.394576805503401, disc_loss = 0.09447036141988961
Trained batch 292 in epoch 11, gen_loss = 0.3947385749922678, disc_loss = 0.0942910063579526
Trained batch 293 in epoch 11, gen_loss = 0.3946130130769444, disc_loss = 0.09429505973623521
Trained batch 294 in epoch 11, gen_loss = 0.39492474461005905, disc_loss = 0.09416045596412682
Trained batch 295 in epoch 11, gen_loss = 0.3949922991765512, disc_loss = 0.09396286897134741
Trained batch 296 in epoch 11, gen_loss = 0.3951448264346781, disc_loss = 0.09435158937241292
Trained batch 297 in epoch 11, gen_loss = 0.3952504907478422, disc_loss = 0.09412662833053993
Trained batch 298 in epoch 11, gen_loss = 0.39566545691777233, disc_loss = 0.09399997850998389
Trained batch 299 in epoch 11, gen_loss = 0.3958373938004176, disc_loss = 0.09412448939556876
Trained batch 300 in epoch 11, gen_loss = 0.39618625058684237, disc_loss = 0.09415110308936862
Trained batch 301 in epoch 11, gen_loss = 0.39631336167553405, disc_loss = 0.0938798712399967
Trained batch 302 in epoch 11, gen_loss = 0.3961150705224217, disc_loss = 0.09378526310310407
Trained batch 303 in epoch 11, gen_loss = 0.3959958175883481, disc_loss = 0.09366933317352577
Trained batch 304 in epoch 11, gen_loss = 0.39628923457176957, disc_loss = 0.09354313218385958
Trained batch 305 in epoch 11, gen_loss = 0.3964957519878749, disc_loss = 0.09327072418276586
Trained batch 306 in epoch 11, gen_loss = 0.39630239143822016, disc_loss = 0.09319851940030578
Trained batch 307 in epoch 11, gen_loss = 0.39654537125841366, disc_loss = 0.0930302502381821
Trained batch 308 in epoch 11, gen_loss = 0.3968582853530217, disc_loss = 0.09276612047527986
Trained batch 309 in epoch 11, gen_loss = 0.3969982770181471, disc_loss = 0.09258435580038256
Trained batch 310 in epoch 11, gen_loss = 0.3972312090289554, disc_loss = 0.09252064145646295
Trained batch 311 in epoch 11, gen_loss = 0.39726207472192937, disc_loss = 0.09233200222922441
Trained batch 312 in epoch 11, gen_loss = 0.39717947503629203, disc_loss = 0.09210577388160145
Trained batch 313 in epoch 11, gen_loss = 0.39733406217994205, disc_loss = 0.09192660264670849
Trained batch 314 in epoch 11, gen_loss = 0.39710349837938946, disc_loss = 0.09191068253583379
Trained batch 315 in epoch 11, gen_loss = 0.39743435335687444, disc_loss = 0.09192348315227258
Trained batch 316 in epoch 11, gen_loss = 0.3973638663532606, disc_loss = 0.09188593770098236
Trained batch 317 in epoch 11, gen_loss = 0.39747994397796177, disc_loss = 0.09173450889593025
Trained batch 318 in epoch 11, gen_loss = 0.397700628049695, disc_loss = 0.09169336708501963
Trained batch 319 in epoch 11, gen_loss = 0.3977667692117393, disc_loss = 0.09218895960366354
Trained batch 320 in epoch 11, gen_loss = 0.39843064481595597, disc_loss = 0.09291589690656676
Trained batch 321 in epoch 11, gen_loss = 0.3985806250979441, disc_loss = 0.09267746996689842
Trained batch 322 in epoch 11, gen_loss = 0.39829184654696437, disc_loss = 0.09264054317200332
Trained batch 323 in epoch 11, gen_loss = 0.39844177203413883, disc_loss = 0.09243938620029776
Trained batch 324 in epoch 11, gen_loss = 0.3988235567166255, disc_loss = 0.09229699470675909
Trained batch 325 in epoch 11, gen_loss = 0.3989603963731988, disc_loss = 0.09216153663954486
Trained batch 326 in epoch 11, gen_loss = 0.39887142336332104, disc_loss = 0.09199612759714462
Trained batch 327 in epoch 11, gen_loss = 0.3986756224639532, disc_loss = 0.09274247407958638
Trained batch 328 in epoch 11, gen_loss = 0.3989660345855817, disc_loss = 0.09439670796135276
Trained batch 329 in epoch 11, gen_loss = 0.39882887692162483, disc_loss = 0.09518052801264054
Trained batch 330 in epoch 11, gen_loss = 0.39875100908682787, disc_loss = 0.09527996314121157
Trained batch 331 in epoch 11, gen_loss = 0.398566823228296, disc_loss = 0.09525130483804338
Trained batch 332 in epoch 11, gen_loss = 0.39832507454239213, disc_loss = 0.09513137255747756
Trained batch 333 in epoch 11, gen_loss = 0.3983040981128544, disc_loss = 0.09496898978145536
Trained batch 334 in epoch 11, gen_loss = 0.398119743991254, disc_loss = 0.09477593237117156
Trained batch 335 in epoch 11, gen_loss = 0.3980688373779967, disc_loss = 0.09462041917833544
Trained batch 336 in epoch 11, gen_loss = 0.39847927392413424, disc_loss = 0.09438752228233864
Trained batch 337 in epoch 11, gen_loss = 0.3984674404887758, disc_loss = 0.09421637491185285
Trained batch 338 in epoch 11, gen_loss = 0.39817076508274474, disc_loss = 0.0943993042967664
Trained batch 339 in epoch 11, gen_loss = 0.3981900312444743, disc_loss = 0.09452411339563482
Trained batch 340 in epoch 11, gen_loss = 0.39794135618070003, disc_loss = 0.09484784825106869
Trained batch 341 in epoch 11, gen_loss = 0.3979201221849486, disc_loss = 0.09580840902370319
Trained batch 342 in epoch 11, gen_loss = 0.3979307601646501, disc_loss = 0.09581430297638167
Trained batch 343 in epoch 11, gen_loss = 0.39794867277838464, disc_loss = 0.09625057206857343
Trained batch 344 in epoch 11, gen_loss = 0.39794733334278715, disc_loss = 0.09703971249037895
Trained batch 345 in epoch 11, gen_loss = 0.39789180552339276, disc_loss = 0.0972247850472872
Trained batch 346 in epoch 11, gen_loss = 0.39781291873035923, disc_loss = 0.09735355921282891
Trained batch 347 in epoch 11, gen_loss = 0.39733499352788104, disc_loss = 0.09757007390860169
Trained batch 348 in epoch 11, gen_loss = 0.397096939833253, disc_loss = 0.09762556778325734
Trained batch 349 in epoch 11, gen_loss = 0.3970944396512849, disc_loss = 0.0977247997692653
Trained batch 350 in epoch 11, gen_loss = 0.39693861864401064, disc_loss = 0.09778346520373624
Trained batch 351 in epoch 11, gen_loss = 0.3965788827785714, disc_loss = 0.0978086210617965
Trained batch 352 in epoch 11, gen_loss = 0.39645022917908246, disc_loss = 0.09787635906222183
Trained batch 353 in epoch 11, gen_loss = 0.396406030377089, disc_loss = 0.0980583636858369
Trained batch 354 in epoch 11, gen_loss = 0.39627873305703554, disc_loss = 0.09815407613633384
Trained batch 355 in epoch 11, gen_loss = 0.3960742133805591, disc_loss = 0.09840499894337708
Trained batch 356 in epoch 11, gen_loss = 0.3961583327929847, disc_loss = 0.09892054857993994
Trained batch 357 in epoch 11, gen_loss = 0.39618382344865266, disc_loss = 0.0990810257762504
Trained batch 358 in epoch 11, gen_loss = 0.3962022166979346, disc_loss = 0.09917793466520176
Trained batch 359 in epoch 11, gen_loss = 0.3960396191726128, disc_loss = 0.09908209962563383
Trained batch 360 in epoch 11, gen_loss = 0.39578606097486874, disc_loss = 0.09916501987591345
Trained batch 361 in epoch 11, gen_loss = 0.3960242605258747, disc_loss = 0.09913324089257756
Trained batch 362 in epoch 11, gen_loss = 0.39605592880859847, disc_loss = 0.09897221307739738
Trained batch 363 in epoch 11, gen_loss = 0.3959220689158518, disc_loss = 0.09879547758744313
Trained batch 364 in epoch 11, gen_loss = 0.3960296282621279, disc_loss = 0.09867187711882265
Trained batch 365 in epoch 11, gen_loss = 0.396145133413578, disc_loss = 0.09847930269163163
Trained batch 366 in epoch 11, gen_loss = 0.3962432088822695, disc_loss = 0.09825043428729845
Trained batch 367 in epoch 11, gen_loss = 0.3962359985174692, disc_loss = 0.09810993489151335
Trained batch 368 in epoch 11, gen_loss = 0.3964821484273042, disc_loss = 0.0979004997159367
Trained batch 369 in epoch 11, gen_loss = 0.3964395943122941, disc_loss = 0.09787535614812294
Trained batch 370 in epoch 11, gen_loss = 0.39632099573663626, disc_loss = 0.09837462425462881
Trained batch 371 in epoch 11, gen_loss = 0.3961645865872983, disc_loss = 0.09847585003452516
Trained batch 372 in epoch 11, gen_loss = 0.3959924249083363, disc_loss = 0.09831011271099223
Trained batch 373 in epoch 11, gen_loss = 0.39604512976612, disc_loss = 0.09823981919300986
Trained batch 374 in epoch 11, gen_loss = 0.3960545437733332, disc_loss = 0.09838016700496276
Trained batch 375 in epoch 11, gen_loss = 0.3958992130182525, disc_loss = 0.0989943152229163
Trained batch 376 in epoch 11, gen_loss = 0.396049573780371, disc_loss = 0.09900822142381172
Trained batch 377 in epoch 11, gen_loss = 0.3958410122012966, disc_loss = 0.09892547912846403
Trained batch 378 in epoch 11, gen_loss = 0.3956495998795869, disc_loss = 0.09906238287756107
Trained batch 379 in epoch 11, gen_loss = 0.3956837366678213, disc_loss = 0.09953476725587328
Trained batch 380 in epoch 11, gen_loss = 0.39554062552183006, disc_loss = 0.09946007791691487
Trained batch 381 in epoch 11, gen_loss = 0.3956151965478952, disc_loss = 0.09938916626157171
Trained batch 382 in epoch 11, gen_loss = 0.3955719549957828, disc_loss = 0.0993445318936329
Trained batch 383 in epoch 11, gen_loss = 0.39545884150235605, disc_loss = 0.09922253458595758
Trained batch 384 in epoch 11, gen_loss = 0.3955650948471837, disc_loss = 0.09914436371053581
Trained batch 385 in epoch 11, gen_loss = 0.3953551720692704, disc_loss = 0.0990625845890859
Trained batch 386 in epoch 11, gen_loss = 0.39528370600492146, disc_loss = 0.0988875722021673
Trained batch 387 in epoch 11, gen_loss = 0.3952583327659012, disc_loss = 0.0987510277875267
Trained batch 388 in epoch 11, gen_loss = 0.3951036863814283, disc_loss = 0.09852339879185881
Trained batch 389 in epoch 11, gen_loss = 0.39484612800371954, disc_loss = 0.09852236228732345
Trained batch 390 in epoch 11, gen_loss = 0.39508259246873734, disc_loss = 0.09868025286432804
Trained batch 391 in epoch 11, gen_loss = 0.3950804832714553, disc_loss = 0.09845249530887801
Trained batch 392 in epoch 11, gen_loss = 0.3948407151544367, disc_loss = 0.09850421679886319
Trained batch 393 in epoch 11, gen_loss = 0.39510596384705626, disc_loss = 0.09856565375363237
Trained batch 394 in epoch 11, gen_loss = 0.3950916757689247, disc_loss = 0.09842510815898452
Trained batch 395 in epoch 11, gen_loss = 0.3949653671471157, disc_loss = 0.09820404134907129
Trained batch 396 in epoch 11, gen_loss = 0.39492750494396056, disc_loss = 0.09802066876555345
Trained batch 397 in epoch 11, gen_loss = 0.3950375087521783, disc_loss = 0.09787985001311604
Trained batch 398 in epoch 11, gen_loss = 0.39486049638505566, disc_loss = 0.09826220777632673
Trained batch 399 in epoch 11, gen_loss = 0.39510591197758915, disc_loss = 0.09864642955595627
Trained batch 400 in epoch 11, gen_loss = 0.39510124152586645, disc_loss = 0.0985155514188278
Trained batch 401 in epoch 11, gen_loss = 0.39503196626901627, disc_loss = 0.09847458821040259
Trained batch 402 in epoch 11, gen_loss = 0.39489499795673505, disc_loss = 0.09854916102546395
Trained batch 403 in epoch 11, gen_loss = 0.39481186250796413, disc_loss = 0.09837984119652596
Trained batch 404 in epoch 11, gen_loss = 0.394693555103408, disc_loss = 0.0983087382129865
Trained batch 405 in epoch 11, gen_loss = 0.39491766298492553, disc_loss = 0.09846013860795372
Trained batch 406 in epoch 11, gen_loss = 0.3948432405911734, disc_loss = 0.09823859776816439
Trained batch 407 in epoch 11, gen_loss = 0.39473779663881836, disc_loss = 0.09849146610198944
Trained batch 408 in epoch 11, gen_loss = 0.39479226329361605, disc_loss = 0.09836555788780775
Trained batch 409 in epoch 11, gen_loss = 0.39499297727171967, disc_loss = 0.09819914172062787
Trained batch 410 in epoch 11, gen_loss = 0.39487881603177155, disc_loss = 0.09806393505212309
Trained batch 411 in epoch 11, gen_loss = 0.39486883598768596, disc_loss = 0.09841905050974303
Trained batch 412 in epoch 11, gen_loss = 0.3949799346072333, disc_loss = 0.09830740034201388
Trained batch 413 in epoch 11, gen_loss = 0.3950001180243953, disc_loss = 0.09815334506638816
Trained batch 414 in epoch 11, gen_loss = 0.39519318151904875, disc_loss = 0.09814998336495405
Trained batch 415 in epoch 11, gen_loss = 0.3952687691109112, disc_loss = 0.09830198237726179
Trained batch 416 in epoch 11, gen_loss = 0.3951287099854838, disc_loss = 0.09870002175317251
Trained batch 417 in epoch 11, gen_loss = 0.3952018223239474, disc_loss = 0.0988116240235821
Trained batch 418 in epoch 11, gen_loss = 0.39531034056924125, disc_loss = 0.09882668161715841
Trained batch 419 in epoch 11, gen_loss = 0.3954658920211451, disc_loss = 0.09869321341227208
Trained batch 420 in epoch 11, gen_loss = 0.39534965182285126, disc_loss = 0.09864252341597068
Trained batch 421 in epoch 11, gen_loss = 0.3950567584114052, disc_loss = 0.09868923159342666
Trained batch 422 in epoch 11, gen_loss = 0.3951134294553288, disc_loss = 0.09853149516767785
Trained batch 423 in epoch 11, gen_loss = 0.39518053024866673, disc_loss = 0.09853184549577253
Trained batch 424 in epoch 11, gen_loss = 0.3951860499031403, disc_loss = 0.09844691309420502
Trained batch 425 in epoch 11, gen_loss = 0.3949756416286661, disc_loss = 0.0983446702544748
Trained batch 426 in epoch 11, gen_loss = 0.39486716289849694, disc_loss = 0.09885601301958885
Trained batch 427 in epoch 11, gen_loss = 0.3950574848905345, disc_loss = 0.0988692870737863
Trained batch 428 in epoch 11, gen_loss = 0.39524701268939705, disc_loss = 0.09877184500140605
Trained batch 429 in epoch 11, gen_loss = 0.39533923950999283, disc_loss = 0.09877104781308146
Trained batch 430 in epoch 11, gen_loss = 0.39537504699141685, disc_loss = 0.09860886059476716
Trained batch 431 in epoch 11, gen_loss = 0.3954262594450955, disc_loss = 0.09842658620241478
Trained batch 432 in epoch 11, gen_loss = 0.3954971161849504, disc_loss = 0.09824023943385819
Trained batch 433 in epoch 11, gen_loss = 0.3955036153510419, disc_loss = 0.09817719820474836
Trained batch 434 in epoch 11, gen_loss = 0.39552974094604626, disc_loss = 0.09817727941634326
Trained batch 435 in epoch 11, gen_loss = 0.3956463553968373, disc_loss = 0.09797113268516548
Trained batch 436 in epoch 11, gen_loss = 0.39559886578973424, disc_loss = 0.09779946443153806
Trained batch 437 in epoch 11, gen_loss = 0.39539334433127754, disc_loss = 0.09808642398693586
Trained batch 438 in epoch 11, gen_loss = 0.3955225274815375, disc_loss = 0.0982795144051551
Trained batch 439 in epoch 11, gen_loss = 0.3957217983562838, disc_loss = 0.09811390476428311
Trained batch 440 in epoch 11, gen_loss = 0.39558497750434746, disc_loss = 0.0980225830759152
Trained batch 441 in epoch 11, gen_loss = 0.3955515640286299, disc_loss = 0.0978890995124178
Trained batch 442 in epoch 11, gen_loss = 0.3957585359063697, disc_loss = 0.09794524961842842
Trained batch 443 in epoch 11, gen_loss = 0.39563096190492314, disc_loss = 0.09796736314515206
Trained batch 444 in epoch 11, gen_loss = 0.3957029292757592, disc_loss = 0.09780113763395655
Trained batch 445 in epoch 11, gen_loss = 0.3957125465364734, disc_loss = 0.09769448900444959
Trained batch 446 in epoch 11, gen_loss = 0.395579935686967, disc_loss = 0.0975916773451688
Trained batch 447 in epoch 11, gen_loss = 0.3955758401259248, disc_loss = 0.09753276352213495
Trained batch 448 in epoch 11, gen_loss = 0.39561971520926215, disc_loss = 0.09778281927880372
Trained batch 449 in epoch 11, gen_loss = 0.3954036464624935, disc_loss = 0.09789486889416973
Trained batch 450 in epoch 11, gen_loss = 0.3954123903206341, disc_loss = 0.09775936247743748
Trained batch 451 in epoch 11, gen_loss = 0.3954100924980851, disc_loss = 0.09757294484818008
Trained batch 452 in epoch 11, gen_loss = 0.39537471707161953, disc_loss = 0.09743551615929893
Trained batch 453 in epoch 11, gen_loss = 0.3952567533708879, disc_loss = 0.0972931402641049
Trained batch 454 in epoch 11, gen_loss = 0.3953392728016927, disc_loss = 0.09715376070976912
Trained batch 455 in epoch 11, gen_loss = 0.39546254404673453, disc_loss = 0.09705054943384439
Trained batch 456 in epoch 11, gen_loss = 0.39554553757741623, disc_loss = 0.09688283974626784
Trained batch 457 in epoch 11, gen_loss = 0.3954564889640787, disc_loss = 0.09692067708657429
Trained batch 458 in epoch 11, gen_loss = 0.395565253554606, disc_loss = 0.09697584709262147
Trained batch 459 in epoch 11, gen_loss = 0.3953975322129934, disc_loss = 0.0969739583077962
Trained batch 460 in epoch 11, gen_loss = 0.3954098151265411, disc_loss = 0.09707441252460319
Testing Epoch 11
Training Epoch 12
Trained batch 0 in epoch 12, gen_loss = 0.333653062582016, disc_loss = 0.0823562741279602
Trained batch 1 in epoch 12, gen_loss = 0.36308275163173676, disc_loss = 0.06373897567391396
Trained batch 2 in epoch 12, gen_loss = 0.3647175431251526, disc_loss = 0.08053016414244969
Trained batch 3 in epoch 12, gen_loss = 0.353590190410614, disc_loss = 0.1099886279553175
Trained batch 4 in epoch 12, gen_loss = 0.3614874005317688, disc_loss = 0.10579353719949722
Trained batch 5 in epoch 12, gen_loss = 0.38367799917856854, disc_loss = 0.12815644219517708
Trained batch 6 in epoch 12, gen_loss = 0.3767646976879665, disc_loss = 0.1189609563776425
Trained batch 7 in epoch 12, gen_loss = 0.3743283078074455, disc_loss = 0.11111108167096972
Trained batch 8 in epoch 12, gen_loss = 0.37490175167719525, disc_loss = 0.10446864656276172
Trained batch 9 in epoch 12, gen_loss = 0.3738916516304016, disc_loss = 0.0990592535585165
Trained batch 10 in epoch 12, gen_loss = 0.3767652186480435, disc_loss = 0.10844745656306093
Trained batch 11 in epoch 12, gen_loss = 0.3742773657043775, disc_loss = 0.122145416525503
Trained batch 12 in epoch 12, gen_loss = 0.3772391860301678, disc_loss = 0.11860146172917806
Trained batch 13 in epoch 12, gen_loss = 0.38677010791642324, disc_loss = 0.11450372450053692
Trained batch 14 in epoch 12, gen_loss = 0.3850770513216654, disc_loss = 0.11144700472553572
Trained batch 15 in epoch 12, gen_loss = 0.3852008655667305, disc_loss = 0.10605227877385914
Trained batch 16 in epoch 12, gen_loss = 0.38254211404744315, disc_loss = 0.1017842755159911
Trained batch 17 in epoch 12, gen_loss = 0.37982501089572906, disc_loss = 0.10124887422555023
Trained batch 18 in epoch 12, gen_loss = 0.3828042165229195, disc_loss = 0.10003088904838812
Trained batch 19 in epoch 12, gen_loss = 0.38299722224473953, disc_loss = 0.09600309245288371
Trained batch 20 in epoch 12, gen_loss = 0.3820774455865224, disc_loss = 0.09825899168139413
Trained batch 21 in epoch 12, gen_loss = 0.3863852579485286, disc_loss = 0.09717511453411797
Trained batch 22 in epoch 12, gen_loss = 0.3879317213659701, disc_loss = 0.09496686267464058
Trained batch 23 in epoch 12, gen_loss = 0.38665268073479336, disc_loss = 0.0964235789142549
Trained batch 24 in epoch 12, gen_loss = 0.38963818550109863, disc_loss = 0.09337895050644875
Trained batch 25 in epoch 12, gen_loss = 0.39072943192261916, disc_loss = 0.09839816864293355
Trained batch 26 in epoch 12, gen_loss = 0.3866738224471057, disc_loss = 0.10131553049992632
Trained batch 27 in epoch 12, gen_loss = 0.38648659203733715, disc_loss = 0.09972631545471293
Trained batch 28 in epoch 12, gen_loss = 0.3875429465852935, disc_loss = 0.09760930723157422
Trained batch 29 in epoch 12, gen_loss = 0.389716370900472, disc_loss = 0.09547200029095014
Trained batch 30 in epoch 12, gen_loss = 0.3906125291701286, disc_loss = 0.09320048651387615
Trained batch 31 in epoch 12, gen_loss = 0.3907642029225826, disc_loss = 0.09170270850881934
Trained batch 32 in epoch 12, gen_loss = 0.3906105034279101, disc_loss = 0.09169877139907895
Trained batch 33 in epoch 12, gen_loss = 0.39271918114493876, disc_loss = 0.09229153811055071
Trained batch 34 in epoch 12, gen_loss = 0.3908399701118469, disc_loss = 0.09243526756763458
Trained batch 35 in epoch 12, gen_loss = 0.3923109496633212, disc_loss = 0.09037213120609522
Trained batch 36 in epoch 12, gen_loss = 0.3920682265951827, disc_loss = 0.09031922944091461
Trained batch 37 in epoch 12, gen_loss = 0.39042994850560236, disc_loss = 0.09151787928452618
Trained batch 38 in epoch 12, gen_loss = 0.39209778645099735, disc_loss = 0.0974010743964941
Trained batch 39 in epoch 12, gen_loss = 0.39210600703954696, disc_loss = 0.09703336926177145
Trained batch 40 in epoch 12, gen_loss = 0.3937068341708765, disc_loss = 0.0952731874748701
Trained batch 41 in epoch 12, gen_loss = 0.39212500765210107, disc_loss = 0.0951735203908313
Trained batch 42 in epoch 12, gen_loss = 0.3920364580875219, disc_loss = 0.09980068966573061
Trained batch 43 in epoch 12, gen_loss = 0.3911362899975343, disc_loss = 0.10121606294573708
Trained batch 44 in epoch 12, gen_loss = 0.3905877735879686, disc_loss = 0.09996736674673028
Trained batch 45 in epoch 12, gen_loss = 0.38763007392054016, disc_loss = 0.10074467758607605
Trained batch 46 in epoch 12, gen_loss = 0.3900541422214914, disc_loss = 0.10118592003400022
Trained batch 47 in epoch 12, gen_loss = 0.38987818236152333, disc_loss = 0.10219342909598102
Trained batch 48 in epoch 12, gen_loss = 0.39123809824184497, disc_loss = 0.10089529484358369
Trained batch 49 in epoch 12, gen_loss = 0.3911406493186951, disc_loss = 0.09953084822744131
Trained batch 50 in epoch 12, gen_loss = 0.3912333366917629, disc_loss = 0.0983626741331582
Trained batch 51 in epoch 12, gen_loss = 0.39159641758753705, disc_loss = 0.09746875760790247
Trained batch 52 in epoch 12, gen_loss = 0.3907648617366575, disc_loss = 0.09627448524928318
Trained batch 53 in epoch 12, gen_loss = 0.3902356078227361, disc_loss = 0.09616690015213357
Trained batch 54 in epoch 12, gen_loss = 0.3889209069988944, disc_loss = 0.09625041237608953
Trained batch 55 in epoch 12, gen_loss = 0.38884727603622843, disc_loss = 0.09487859708523112
Trained batch 56 in epoch 12, gen_loss = 0.3905261064830579, disc_loss = 0.09421303786598799
Trained batch 57 in epoch 12, gen_loss = 0.39043878070239363, disc_loss = 0.09403417808613901
Trained batch 58 in epoch 12, gen_loss = 0.38965683821904457, disc_loss = 0.09264463899751842
Trained batch 59 in epoch 12, gen_loss = 0.39095236112674076, disc_loss = 0.09130972647108138
Trained batch 60 in epoch 12, gen_loss = 0.39052362715611694, disc_loss = 0.09084825753616016
Trained batch 61 in epoch 12, gen_loss = 0.39056505503193023, disc_loss = 0.09088699121568952
Trained batch 62 in epoch 12, gen_loss = 0.3918287120168171, disc_loss = 0.09217062933991353
Trained batch 63 in epoch 12, gen_loss = 0.3910631285980344, disc_loss = 0.09174378505849745
Trained batch 64 in epoch 12, gen_loss = 0.39027439310000495, disc_loss = 0.09092582176224544
Trained batch 65 in epoch 12, gen_loss = 0.39127826329433557, disc_loss = 0.09109604695924756
Trained batch 66 in epoch 12, gen_loss = 0.3922814197504698, disc_loss = 0.09096327378178265
Trained batch 67 in epoch 12, gen_loss = 0.39341489444760713, disc_loss = 0.0902800918693709
Trained batch 68 in epoch 12, gen_loss = 0.3936824893605882, disc_loss = 0.08937200945734546
Trained batch 69 in epoch 12, gen_loss = 0.39228703039033075, disc_loss = 0.08972827652469277
Trained batch 70 in epoch 12, gen_loss = 0.392957221454298, disc_loss = 0.08887720138201831
Trained batch 71 in epoch 12, gen_loss = 0.39252424074543846, disc_loss = 0.08834346843003812
Trained batch 72 in epoch 12, gen_loss = 0.39123671879507094, disc_loss = 0.08846197291341139
Trained batch 73 in epoch 12, gen_loss = 0.39159206764118093, disc_loss = 0.08744627982378006
Trained batch 74 in epoch 12, gen_loss = 0.39260412057240807, disc_loss = 0.0871168147524198
Trained batch 75 in epoch 12, gen_loss = 0.3923447814426924, disc_loss = 0.08679599716867271
Trained batch 76 in epoch 12, gen_loss = 0.39190570177969997, disc_loss = 0.08773800469451136
Trained batch 77 in epoch 12, gen_loss = 0.39245132567026675, disc_loss = 0.08778972694507012
Trained batch 78 in epoch 12, gen_loss = 0.39289827776860586, disc_loss = 0.08723392912858649
Trained batch 79 in epoch 12, gen_loss = 0.39306690990924836, disc_loss = 0.08823413532227278
Trained batch 80 in epoch 12, gen_loss = 0.3948173890879125, disc_loss = 0.08814299741276989
Trained batch 81 in epoch 12, gen_loss = 0.3945979432361882, disc_loss = 0.08909507050383382
Trained batch 82 in epoch 12, gen_loss = 0.39385606115122873, disc_loss = 0.09221982623798301
Trained batch 83 in epoch 12, gen_loss = 0.3943137650688489, disc_loss = 0.09329788608565218
Trained batch 84 in epoch 12, gen_loss = 0.3939990099738626, disc_loss = 0.0923401285729864
Trained batch 85 in epoch 12, gen_loss = 0.3923506411009057, disc_loss = 0.09204145496018058
Trained batch 86 in epoch 12, gen_loss = 0.39241012485548, disc_loss = 0.09120258570102782
Trained batch 87 in epoch 12, gen_loss = 0.3926772126419978, disc_loss = 0.09063037308144638
Trained batch 88 in epoch 12, gen_loss = 0.3919826729244061, disc_loss = 0.09021115032014217
Trained batch 89 in epoch 12, gen_loss = 0.3916297001971139, disc_loss = 0.09180152313783765
Trained batch 90 in epoch 12, gen_loss = 0.39265465900138186, disc_loss = 0.09227025735058955
Trained batch 91 in epoch 12, gen_loss = 0.39341474907553714, disc_loss = 0.09157666356464766
Trained batch 92 in epoch 12, gen_loss = 0.39335393777457617, disc_loss = 0.09117222540280832
Trained batch 93 in epoch 12, gen_loss = 0.393481674346518, disc_loss = 0.09054976974197841
Trained batch 94 in epoch 12, gen_loss = 0.3930226266384125, disc_loss = 0.0899860191796171
Trained batch 95 in epoch 12, gen_loss = 0.3924444808314244, disc_loss = 0.08976409928679156
Trained batch 96 in epoch 12, gen_loss = 0.39302225764264764, disc_loss = 0.09192610435072601
Trained batch 97 in epoch 12, gen_loss = 0.39301957676605304, disc_loss = 0.09177507675842059
Trained batch 98 in epoch 12, gen_loss = 0.3927657393494038, disc_loss = 0.0910584084181623
Trained batch 99 in epoch 12, gen_loss = 0.3936913573741913, disc_loss = 0.09171379436738789
Trained batch 100 in epoch 12, gen_loss = 0.3926911787821515, disc_loss = 0.09190067660874955
Trained batch 101 in epoch 12, gen_loss = 0.39279839951618045, disc_loss = 0.09175716783376593
Trained batch 102 in epoch 12, gen_loss = 0.3927282569477859, disc_loss = 0.09156667286512053
Trained batch 103 in epoch 12, gen_loss = 0.39265665526573473, disc_loss = 0.09110221955387925
Trained batch 104 in epoch 12, gen_loss = 0.3919568862233843, disc_loss = 0.09037422630935907
Trained batch 105 in epoch 12, gen_loss = 0.39187050624838415, disc_loss = 0.08980755276872583
Trained batch 106 in epoch 12, gen_loss = 0.39174970733785186, disc_loss = 0.08933721772595266
Trained batch 107 in epoch 12, gen_loss = 0.39255833349846025, disc_loss = 0.08882553638303997
Trained batch 108 in epoch 12, gen_loss = 0.3926751542528835, disc_loss = 0.08887160129400842
Trained batch 109 in epoch 12, gen_loss = 0.392819747057828, disc_loss = 0.09109368789094416
Trained batch 110 in epoch 12, gen_loss = 0.3924811656947608, disc_loss = 0.0906991368025407
Trained batch 111 in epoch 12, gen_loss = 0.39255683603031294, disc_loss = 0.09034180023341573
Trained batch 112 in epoch 12, gen_loss = 0.392348240434596, disc_loss = 0.09077295536521525
Trained batch 113 in epoch 12, gen_loss = 0.39269507428010303, disc_loss = 0.09059682626505955
Trained batch 114 in epoch 12, gen_loss = 0.39343643473542256, disc_loss = 0.08992052075007688
Trained batch 115 in epoch 12, gen_loss = 0.39386188829767294, disc_loss = 0.08947459081637449
Trained batch 116 in epoch 12, gen_loss = 0.3944222147648151, disc_loss = 0.08893792433107
Trained batch 117 in epoch 12, gen_loss = 0.3948462547387107, disc_loss = 0.0889810072415966
Trained batch 118 in epoch 12, gen_loss = 0.394645984683718, disc_loss = 0.08935807006699699
Trained batch 119 in epoch 12, gen_loss = 0.39380136504769325, disc_loss = 0.0902508445084095
Trained batch 120 in epoch 12, gen_loss = 0.3937867185301032, disc_loss = 0.0903124904090708
Trained batch 121 in epoch 12, gen_loss = 0.3940745272108766, disc_loss = 0.0899445229194692
Trained batch 122 in epoch 12, gen_loss = 0.3936299865807944, disc_loss = 0.08971861964924549
Trained batch 123 in epoch 12, gen_loss = 0.3939977283439329, disc_loss = 0.08926394500679546
Trained batch 124 in epoch 12, gen_loss = 0.39427145767211913, disc_loss = 0.08915035036206245
Trained batch 125 in epoch 12, gen_loss = 0.3936674306316981, disc_loss = 0.08925860786130504
Trained batch 126 in epoch 12, gen_loss = 0.3938838832491026, disc_loss = 0.0892793145177402
Trained batch 127 in epoch 12, gen_loss = 0.3935579734388739, disc_loss = 0.08882754153455608
Trained batch 128 in epoch 12, gen_loss = 0.39389806777931924, disc_loss = 0.08831920035818751
Trained batch 129 in epoch 12, gen_loss = 0.3940421480398912, disc_loss = 0.08838553566199082
Trained batch 130 in epoch 12, gen_loss = 0.3937742373415532, disc_loss = 0.08865495532296086
Trained batch 131 in epoch 12, gen_loss = 0.39440217930259125, disc_loss = 0.08810420458515485
Trained batch 132 in epoch 12, gen_loss = 0.39471274928042765, disc_loss = 0.08767688296791307
Trained batch 133 in epoch 12, gen_loss = 0.3948284930257655, disc_loss = 0.0871799689397883
Trained batch 134 in epoch 12, gen_loss = 0.3947632337058032, disc_loss = 0.08695003553121178
Trained batch 135 in epoch 12, gen_loss = 0.3951076670166324, disc_loss = 0.08690868923440576
Trained batch 136 in epoch 12, gen_loss = 0.3944002331173333, disc_loss = 0.08652156324934786
Trained batch 137 in epoch 12, gen_loss = 0.3943352217691532, disc_loss = 0.08633557798853819
Trained batch 138 in epoch 12, gen_loss = 0.394476777572426, disc_loss = 0.08685002132928629
Trained batch 139 in epoch 12, gen_loss = 0.39417327514716555, disc_loss = 0.08672205576939242
Trained batch 140 in epoch 12, gen_loss = 0.3946372460811696, disc_loss = 0.08636631798131246
Trained batch 141 in epoch 12, gen_loss = 0.39478265000900753, disc_loss = 0.08584753031724356
Trained batch 142 in epoch 12, gen_loss = 0.3949488780715249, disc_loss = 0.08547536842525005
Trained batch 143 in epoch 12, gen_loss = 0.39521708339452744, disc_loss = 0.08523126175471891
Trained batch 144 in epoch 12, gen_loss = 0.3957126921620862, disc_loss = 0.08486432611685375
Trained batch 145 in epoch 12, gen_loss = 0.39499637137537136, disc_loss = 0.08491376025780831
Trained batch 146 in epoch 12, gen_loss = 0.3954289362949579, disc_loss = 0.08622297749784934
Trained batch 147 in epoch 12, gen_loss = 0.39478473606947306, disc_loss = 0.08591524726786726
Trained batch 148 in epoch 12, gen_loss = 0.3942862673093809, disc_loss = 0.08619434635261161
Trained batch 149 in epoch 12, gen_loss = 0.3943225093682607, disc_loss = 0.08640637386590243
Trained batch 150 in epoch 12, gen_loss = 0.3940252470259635, disc_loss = 0.0865617540375089
Trained batch 151 in epoch 12, gen_loss = 0.39391523383949933, disc_loss = 0.08614452190599159
Trained batch 152 in epoch 12, gen_loss = 0.39369453928049875, disc_loss = 0.08601398408120754
Trained batch 153 in epoch 12, gen_loss = 0.394236617080577, disc_loss = 0.08595345074964034
Trained batch 154 in epoch 12, gen_loss = 0.39435098055870305, disc_loss = 0.08603464016510594
Trained batch 155 in epoch 12, gen_loss = 0.39467062247105134, disc_loss = 0.08736983359528658
Trained batch 156 in epoch 12, gen_loss = 0.394808225760794, disc_loss = 0.08793945029188113
Trained batch 157 in epoch 12, gen_loss = 0.394592441901376, disc_loss = 0.0878071686653774
Trained batch 158 in epoch 12, gen_loss = 0.39486614000872244, disc_loss = 0.08735209810049654
Trained batch 159 in epoch 12, gen_loss = 0.3949978485703468, disc_loss = 0.08692459594458342
Trained batch 160 in epoch 12, gen_loss = 0.39469094824346695, disc_loss = 0.0866707222570914
Trained batch 161 in epoch 12, gen_loss = 0.39413687660370345, disc_loss = 0.08649805700981322
Trained batch 162 in epoch 12, gen_loss = 0.39469700503203037, disc_loss = 0.08830915782257823
Trained batch 163 in epoch 12, gen_loss = 0.39458083724830206, disc_loss = 0.08827195909419437
Trained batch 164 in epoch 12, gen_loss = 0.39420317176616554, disc_loss = 0.08848353762066725
Trained batch 165 in epoch 12, gen_loss = 0.3944618518812111, disc_loss = 0.08854345773088645
Trained batch 166 in epoch 12, gen_loss = 0.3947170325025113, disc_loss = 0.0883980712624724
Trained batch 167 in epoch 12, gen_loss = 0.39445719459936734, disc_loss = 0.0880739158241167
Trained batch 168 in epoch 12, gen_loss = 0.39409421199172207, disc_loss = 0.08772710478208827
Trained batch 169 in epoch 12, gen_loss = 0.3938197176246082, disc_loss = 0.08813691192909198
Trained batch 170 in epoch 12, gen_loss = 0.39350128975528026, disc_loss = 0.08876652702994166
Trained batch 171 in epoch 12, gen_loss = 0.39372505351554515, disc_loss = 0.08851139196519588
Trained batch 172 in epoch 12, gen_loss = 0.39341627173341076, disc_loss = 0.08861177975602577
Trained batch 173 in epoch 12, gen_loss = 0.39313826341738645, disc_loss = 0.08840287008975771
Trained batch 174 in epoch 12, gen_loss = 0.3933788309778486, disc_loss = 0.08802915614630495
Trained batch 175 in epoch 12, gen_loss = 0.39302424917166884, disc_loss = 0.08769959045193074
Trained batch 176 in epoch 12, gen_loss = 0.3926632789905462, disc_loss = 0.08740947699689933
Trained batch 177 in epoch 12, gen_loss = 0.3928525335668178, disc_loss = 0.08711325742429897
Trained batch 178 in epoch 12, gen_loss = 0.3934094855905245, disc_loss = 0.08676426449801003
Trained batch 179 in epoch 12, gen_loss = 0.39384115454223423, disc_loss = 0.08648800340791543
Trained batch 180 in epoch 12, gen_loss = 0.39342867916460195, disc_loss = 0.0863303179487339
Trained batch 181 in epoch 12, gen_loss = 0.39338361496453755, disc_loss = 0.08611828670069412
Trained batch 182 in epoch 12, gen_loss = 0.393410967021692, disc_loss = 0.08597563809710122
Trained batch 183 in epoch 12, gen_loss = 0.39411207353291305, disc_loss = 0.0859063819212758
Trained batch 184 in epoch 12, gen_loss = 0.39374265912416817, disc_loss = 0.08577349830318141
Trained batch 185 in epoch 12, gen_loss = 0.39403618615801617, disc_loss = 0.08594033486580335
Trained batch 186 in epoch 12, gen_loss = 0.39374141466808826, disc_loss = 0.08604295312720824
Trained batch 187 in epoch 12, gen_loss = 0.39386494917438386, disc_loss = 0.08564341191618526
Trained batch 188 in epoch 12, gen_loss = 0.39402785897254944, disc_loss = 0.08531362484036772
Trained batch 189 in epoch 12, gen_loss = 0.39403642463056665, disc_loss = 0.08493252328940128
Trained batch 190 in epoch 12, gen_loss = 0.3937475745278503, disc_loss = 0.08475525672328098
Trained batch 191 in epoch 12, gen_loss = 0.39354670342678827, disc_loss = 0.08493275885120966
Trained batch 192 in epoch 12, gen_loss = 0.39280285226866374, disc_loss = 0.0852214483148539
Trained batch 193 in epoch 12, gen_loss = 0.39297370658707376, disc_loss = 0.08511549728855337
Trained batch 194 in epoch 12, gen_loss = 0.3932161590991876, disc_loss = 0.08492573674481649
Trained batch 195 in epoch 12, gen_loss = 0.3934858909675053, disc_loss = 0.08480061743674534
Trained batch 196 in epoch 12, gen_loss = 0.3937112823658183, disc_loss = 0.08507501043681868
Trained batch 197 in epoch 12, gen_loss = 0.39430381568393325, disc_loss = 0.08572966719253196
Trained batch 198 in epoch 12, gen_loss = 0.39416208788378154, disc_loss = 0.08538272629618346
Trained batch 199 in epoch 12, gen_loss = 0.39423986986279486, disc_loss = 0.08501356433145701
Trained batch 200 in epoch 12, gen_loss = 0.39429967261072413, disc_loss = 0.08511613975672876
Trained batch 201 in epoch 12, gen_loss = 0.39490075748745757, disc_loss = 0.0850433237242079
Trained batch 202 in epoch 12, gen_loss = 0.39456507314014905, disc_loss = 0.08496975332608657
Trained batch 203 in epoch 12, gen_loss = 0.3942791623812096, disc_loss = 0.08473237873255915
Trained batch 204 in epoch 12, gen_loss = 0.3941807104320061, disc_loss = 0.08479062710411665
Trained batch 205 in epoch 12, gen_loss = 0.3943911353939945, disc_loss = 0.08518512878856323
Trained batch 206 in epoch 12, gen_loss = 0.39427271067808217, disc_loss = 0.08482847552620558
Trained batch 207 in epoch 12, gen_loss = 0.3944570737389418, disc_loss = 0.08495112765544596
Trained batch 208 in epoch 12, gen_loss = 0.39479833784285917, disc_loss = 0.0848090745170008
Trained batch 209 in epoch 12, gen_loss = 0.3949249051866077, disc_loss = 0.08450725201872133
Trained batch 210 in epoch 12, gen_loss = 0.39479069941416733, disc_loss = 0.08418765687052672
Trained batch 211 in epoch 12, gen_loss = 0.39506365583752684, disc_loss = 0.08383380002693606
Trained batch 212 in epoch 12, gen_loss = 0.3955014972059939, disc_loss = 0.08350070954645883
Trained batch 213 in epoch 12, gen_loss = 0.39542551491862143, disc_loss = 0.08318865352754141
Trained batch 214 in epoch 12, gen_loss = 0.3956675024919732, disc_loss = 0.08304674623230862
Trained batch 215 in epoch 12, gen_loss = 0.3955401569880821, disc_loss = 0.08288335511719601
Trained batch 216 in epoch 12, gen_loss = 0.3955849564295211, disc_loss = 0.08273204396723464
Trained batch 217 in epoch 12, gen_loss = 0.3952548413648518, disc_loss = 0.08296346416218428
Trained batch 218 in epoch 12, gen_loss = 0.3956365481903564, disc_loss = 0.08315886384871317
Trained batch 219 in epoch 12, gen_loss = 0.39552456492727456, disc_loss = 0.08282715956341814
Trained batch 220 in epoch 12, gen_loss = 0.3954059144490445, disc_loss = 0.08257723659091541
Trained batch 221 in epoch 12, gen_loss = 0.3957119008173814, disc_loss = 0.08232561266049743
Trained batch 222 in epoch 12, gen_loss = 0.3957555241916212, disc_loss = 0.08221988256753426
Trained batch 223 in epoch 12, gen_loss = 0.3959775934261935, disc_loss = 0.08190181240622353
Trained batch 224 in epoch 12, gen_loss = 0.39583496623569064, disc_loss = 0.0817593688228064
Trained batch 225 in epoch 12, gen_loss = 0.3961350377154561, disc_loss = 0.08156005427884185
Trained batch 226 in epoch 12, gen_loss = 0.3959912726007369, disc_loss = 0.08130620727274518
Trained batch 227 in epoch 12, gen_loss = 0.39618428744244993, disc_loss = 0.08104593472212161
Trained batch 228 in epoch 12, gen_loss = 0.39621113260240015, disc_loss = 0.08076008114817361
Trained batch 229 in epoch 12, gen_loss = 0.3961134795261466, disc_loss = 0.08086186901706716
Trained batch 230 in epoch 12, gen_loss = 0.3963360220064849, disc_loss = 0.08099621003775885
Trained batch 231 in epoch 12, gen_loss = 0.3965711182561414, disc_loss = 0.08075557645924132
Trained batch 232 in epoch 12, gen_loss = 0.39680883659313676, disc_loss = 0.08049873066786277
Trained batch 233 in epoch 12, gen_loss = 0.3969011208695224, disc_loss = 0.08018639707802516
Trained batch 234 in epoch 12, gen_loss = 0.39691768669067545, disc_loss = 0.08000960836900359
Trained batch 235 in epoch 12, gen_loss = 0.396774107621888, disc_loss = 0.07990245780141993
Trained batch 236 in epoch 12, gen_loss = 0.39673373379787813, disc_loss = 0.07961035416685516
Trained batch 237 in epoch 12, gen_loss = 0.39698612877801687, disc_loss = 0.07935235092705976
Trained batch 238 in epoch 12, gen_loss = 0.3969906703198804, disc_loss = 0.07916699484512833
Trained batch 239 in epoch 12, gen_loss = 0.3971676590541999, disc_loss = 0.07908703624852934
Trained batch 240 in epoch 12, gen_loss = 0.3972250242945564, disc_loss = 0.07885962661889022
Trained batch 241 in epoch 12, gen_loss = 0.3973709229102805, disc_loss = 0.07859792676369452
Trained batch 242 in epoch 12, gen_loss = 0.3970573318838583, disc_loss = 0.07842802968251791
Trained batch 243 in epoch 12, gen_loss = 0.3973731220257087, disc_loss = 0.07857227570293318
Trained batch 244 in epoch 12, gen_loss = 0.39722005068039407, disc_loss = 0.07939983667729765
Trained batch 245 in epoch 12, gen_loss = 0.3973041987273751, disc_loss = 0.07946489564127977
Trained batch 246 in epoch 12, gen_loss = 0.3973611191458065, disc_loss = 0.07939760610725173
Trained batch 247 in epoch 12, gen_loss = 0.39723995460137246, disc_loss = 0.0797254296015918
Trained batch 248 in epoch 12, gen_loss = 0.3978043276382737, disc_loss = 0.07971780864432094
Trained batch 249 in epoch 12, gen_loss = 0.3977230389118195, disc_loss = 0.07957463782094419
Trained batch 250 in epoch 12, gen_loss = 0.39759099554730604, disc_loss = 0.07963440863163289
Trained batch 251 in epoch 12, gen_loss = 0.3984302379309185, disc_loss = 0.0798407569730891
Trained batch 252 in epoch 12, gen_loss = 0.398100825991084, disc_loss = 0.07980168026802038
Trained batch 253 in epoch 12, gen_loss = 0.397812954201473, disc_loss = 0.07985574874374282
Trained batch 254 in epoch 12, gen_loss = 0.3976290585947972, disc_loss = 0.08111247758326286
Trained batch 255 in epoch 12, gen_loss = 0.3978562268894166, disc_loss = 0.08092742172266298
Trained batch 256 in epoch 12, gen_loss = 0.39779628459581606, disc_loss = 0.08091886437784315
Trained batch 257 in epoch 12, gen_loss = 0.3975742005331572, disc_loss = 0.08078032087123152
Trained batch 258 in epoch 12, gen_loss = 0.39755293519800694, disc_loss = 0.08064709008854731
Trained batch 259 in epoch 12, gen_loss = 0.3976023667133771, disc_loss = 0.08051530556001056
Trained batch 260 in epoch 12, gen_loss = 0.3975476726489962, disc_loss = 0.08029048268101624
Trained batch 261 in epoch 12, gen_loss = 0.3974356768467954, disc_loss = 0.08011845023485029
Trained batch 262 in epoch 12, gen_loss = 0.39753242035329117, disc_loss = 0.08005992798205508
Trained batch 263 in epoch 12, gen_loss = 0.3975329112374421, disc_loss = 0.08009194042780578
Trained batch 264 in epoch 12, gen_loss = 0.3978897576062184, disc_loss = 0.07990757192326885
Trained batch 265 in epoch 12, gen_loss = 0.3980154262897663, disc_loss = 0.07985283710811764
Trained batch 266 in epoch 12, gen_loss = 0.39795418602696964, disc_loss = 0.07995820039018207
Trained batch 267 in epoch 12, gen_loss = 0.3980361105345968, disc_loss = 0.0800016933770628
Trained batch 268 in epoch 12, gen_loss = 0.39793250297081956, disc_loss = 0.07983138038842597
Trained batch 269 in epoch 12, gen_loss = 0.3978752564500879, disc_loss = 0.07962431399738071
Trained batch 270 in epoch 12, gen_loss = 0.39796709563459415, disc_loss = 0.07939910269909405
Trained batch 271 in epoch 12, gen_loss = 0.3979647880529656, disc_loss = 0.07918475144234595
Trained batch 272 in epoch 12, gen_loss = 0.39796942734456325, disc_loss = 0.0790572678209743
Trained batch 273 in epoch 12, gen_loss = 0.3984644832837321, disc_loss = 0.07906584629795793
Trained batch 274 in epoch 12, gen_loss = 0.39821071082895454, disc_loss = 0.07898981325159019
Trained batch 275 in epoch 12, gen_loss = 0.39814650450927624, disc_loss = 0.07883388595486843
Trained batch 276 in epoch 12, gen_loss = 0.3982785653981922, disc_loss = 0.07857847118091228
Trained batch 277 in epoch 12, gen_loss = 0.39837302825004933, disc_loss = 0.07848373110231896
Trained batch 278 in epoch 12, gen_loss = 0.39819024732890523, disc_loss = 0.0788641930491026
Trained batch 279 in epoch 12, gen_loss = 0.3985577885593687, disc_loss = 0.07907700976190557
Trained batch 280 in epoch 12, gen_loss = 0.3985339222853718, disc_loss = 0.07881618008594231
Trained batch 281 in epoch 12, gen_loss = 0.39855279313757064, disc_loss = 0.07868731879061154
Trained batch 282 in epoch 12, gen_loss = 0.39839438972961777, disc_loss = 0.07849555247209887
Trained batch 283 in epoch 12, gen_loss = 0.3985529347834453, disc_loss = 0.07828106637224293
Trained batch 284 in epoch 12, gen_loss = 0.398486397245474, disc_loss = 0.07825457412390072
Trained batch 285 in epoch 12, gen_loss = 0.3983194895765998, disc_loss = 0.07858188664442957
Trained batch 286 in epoch 12, gen_loss = 0.3982043439710597, disc_loss = 0.07849647024750242
Trained batch 287 in epoch 12, gen_loss = 0.3982156713803609, disc_loss = 0.07826746298653436
Trained batch 288 in epoch 12, gen_loss = 0.39874099818892955, disc_loss = 0.078058507108165
Trained batch 289 in epoch 12, gen_loss = 0.3986116662107665, disc_loss = 0.0779710523350614
Trained batch 290 in epoch 12, gen_loss = 0.3981600820608565, disc_loss = 0.07809386874270655
Trained batch 291 in epoch 12, gen_loss = 0.39839400310222417, disc_loss = 0.07804113272609418
Trained batch 292 in epoch 12, gen_loss = 0.39863338791876524, disc_loss = 0.07780199019085782
Trained batch 293 in epoch 12, gen_loss = 0.3985931795267832, disc_loss = 0.07757187102997333
Trained batch 294 in epoch 12, gen_loss = 0.3984889851788343, disc_loss = 0.07735116923291047
Trained batch 295 in epoch 12, gen_loss = 0.3984612764136211, disc_loss = 0.07714590376299629
Trained batch 296 in epoch 12, gen_loss = 0.39842118879761357, disc_loss = 0.07716302921280566
Trained batch 297 in epoch 12, gen_loss = 0.3980413283277678, disc_loss = 0.07769271617774046
Trained batch 298 in epoch 12, gen_loss = 0.39806674445751916, disc_loss = 0.07783828652230244
Trained batch 299 in epoch 12, gen_loss = 0.3978040206432343, disc_loss = 0.0776665918668732
Trained batch 300 in epoch 12, gen_loss = 0.3976418904687875, disc_loss = 0.077473707467726
Trained batch 301 in epoch 12, gen_loss = 0.39749983801747, disc_loss = 0.07731203290954577
Trained batch 302 in epoch 12, gen_loss = 0.3972951277057723, disc_loss = 0.07714775839218065
Trained batch 303 in epoch 12, gen_loss = 0.39734205476155404, disc_loss = 0.07708540621464827
Trained batch 304 in epoch 12, gen_loss = 0.3976607678366489, disc_loss = 0.0769497201839065
Trained batch 305 in epoch 12, gen_loss = 0.3976771811059877, disc_loss = 0.07691234559752047
Trained batch 306 in epoch 12, gen_loss = 0.3977062663348568, disc_loss = 0.07689550443907368
Trained batch 307 in epoch 12, gen_loss = 0.3977387219473913, disc_loss = 0.07690890479451892
Trained batch 308 in epoch 12, gen_loss = 0.3978368783652975, disc_loss = 0.07672680871151268
Trained batch 309 in epoch 12, gen_loss = 0.398327646813085, disc_loss = 0.07704187098199562
Trained batch 310 in epoch 12, gen_loss = 0.398289263344271, disc_loss = 0.07780072538757103
Trained batch 311 in epoch 12, gen_loss = 0.3984472647500344, disc_loss = 0.07767223774676378
Trained batch 312 in epoch 12, gen_loss = 0.39841095298623885, disc_loss = 0.07770398206943378
Trained batch 313 in epoch 12, gen_loss = 0.39830270893634506, disc_loss = 0.07761742764413594
Trained batch 314 in epoch 12, gen_loss = 0.39832884792297607, disc_loss = 0.07741590171963686
Trained batch 315 in epoch 12, gen_loss = 0.3982247613087485, disc_loss = 0.07740162658546403
Trained batch 316 in epoch 12, gen_loss = 0.39805680795422865, disc_loss = 0.07796725759000667
Trained batch 317 in epoch 12, gen_loss = 0.3984835571463003, disc_loss = 0.07789987143064679
Trained batch 318 in epoch 12, gen_loss = 0.39865221900626036, disc_loss = 0.07779623502807044
Trained batch 319 in epoch 12, gen_loss = 0.3986262559890747, disc_loss = 0.07769552178360754
Trained batch 320 in epoch 12, gen_loss = 0.3985517543052959, disc_loss = 0.0780091421501682
Trained batch 321 in epoch 12, gen_loss = 0.39858497096144635, disc_loss = 0.07897992379043645
Trained batch 322 in epoch 12, gen_loss = 0.39878821539066894, disc_loss = 0.07926375276031371
Trained batch 323 in epoch 12, gen_loss = 0.39900403911316834, disc_loss = 0.07934559378226828
Trained batch 324 in epoch 12, gen_loss = 0.39909941599919246, disc_loss = 0.07933066196309832
Trained batch 325 in epoch 12, gen_loss = 0.3991311030702357, disc_loss = 0.07923264331984237
Trained batch 326 in epoch 12, gen_loss = 0.3991155696389143, disc_loss = 0.07905280906906414
Trained batch 327 in epoch 12, gen_loss = 0.3992798223001201, disc_loss = 0.07885079725969174
Trained batch 328 in epoch 12, gen_loss = 0.3988779140098479, disc_loss = 0.07869239342413095
Trained batch 329 in epoch 12, gen_loss = 0.3988424418550549, disc_loss = 0.0785382068363216
Trained batch 330 in epoch 12, gen_loss = 0.39908278429616256, disc_loss = 0.07837792316710526
Trained batch 331 in epoch 12, gen_loss = 0.3991886845913278, disc_loss = 0.07829912533809666
Trained batch 332 in epoch 12, gen_loss = 0.39914743007124365, disc_loss = 0.07837946381414304
Trained batch 333 in epoch 12, gen_loss = 0.39936554601449453, disc_loss = 0.07849319463924778
Trained batch 334 in epoch 12, gen_loss = 0.39937107634188523, disc_loss = 0.07851998916785441
Trained batch 335 in epoch 12, gen_loss = 0.3995059875860101, disc_loss = 0.07837204301003589
Trained batch 336 in epoch 12, gen_loss = 0.3997699358343017, disc_loss = 0.07829122170833566
Trained batch 337 in epoch 12, gen_loss = 0.3999361233598382, disc_loss = 0.07809829041940441
Trained batch 338 in epoch 12, gen_loss = 0.4000396082359078, disc_loss = 0.07796653503123506
Trained batch 339 in epoch 12, gen_loss = 0.40001178471481097, disc_loss = 0.07776496855624239
Trained batch 340 in epoch 12, gen_loss = 0.4002002137672167, disc_loss = 0.07766426710106017
Trained batch 341 in epoch 12, gen_loss = 0.4002868920041804, disc_loss = 0.07766280649366042
Trained batch 342 in epoch 12, gen_loss = 0.40033737858947444, disc_loss = 0.07762971156990867
Trained batch 343 in epoch 12, gen_loss = 0.40055096773214116, disc_loss = 0.07760034550690677
Trained batch 344 in epoch 12, gen_loss = 0.40030653373054836, disc_loss = 0.07769234289914585
Trained batch 345 in epoch 12, gen_loss = 0.40029459140893353, disc_loss = 0.07769678233089088
Trained batch 346 in epoch 12, gen_loss = 0.4002528314288137, disc_loss = 0.07751623137856724
Trained batch 347 in epoch 12, gen_loss = 0.40036069944329644, disc_loss = 0.07745799810181361
Trained batch 348 in epoch 12, gen_loss = 0.40033232064165153, disc_loss = 0.0773214653046284
Trained batch 349 in epoch 12, gen_loss = 0.4003017847027097, disc_loss = 0.07714450882880815
Trained batch 350 in epoch 12, gen_loss = 0.4005177706225306, disc_loss = 0.07695019035401125
Trained batch 351 in epoch 12, gen_loss = 0.4005230716006322, disc_loss = 0.07679909854381219
Trained batch 352 in epoch 12, gen_loss = 0.4004245341330682, disc_loss = 0.07697603466759619
Trained batch 353 in epoch 12, gen_loss = 0.4003656011516765, disc_loss = 0.07681051033843667
Trained batch 354 in epoch 12, gen_loss = 0.40033228464529547, disc_loss = 0.0766334793136888
Trained batch 355 in epoch 12, gen_loss = 0.4004370003436389, disc_loss = 0.07647270574679159
Trained batch 356 in epoch 12, gen_loss = 0.40041939342389254, disc_loss = 0.07630174602734066
Trained batch 357 in epoch 12, gen_loss = 0.4003084888837857, disc_loss = 0.07624609027364858
Trained batch 358 in epoch 12, gen_loss = 0.4005282307899762, disc_loss = 0.0772717722100115
Trained batch 359 in epoch 12, gen_loss = 0.4005677448378669, disc_loss = 0.07721989767289617
Trained batch 360 in epoch 12, gen_loss = 0.40062938387043917, disc_loss = 0.07704480689333705
Trained batch 361 in epoch 12, gen_loss = 0.4006790343404475, disc_loss = 0.0769895587196234
Trained batch 362 in epoch 12, gen_loss = 0.4006635343897113, disc_loss = 0.07739570728033658
Trained batch 363 in epoch 12, gen_loss = 0.4005819647521763, disc_loss = 0.07810689557400011
Trained batch 364 in epoch 12, gen_loss = 0.4006502729572662, disc_loss = 0.07845845217752742
Trained batch 365 in epoch 12, gen_loss = 0.40063260585232513, disc_loss = 0.07843811245497744
Trained batch 366 in epoch 12, gen_loss = 0.4006119129280953, disc_loss = 0.07842199233733625
Trained batch 367 in epoch 12, gen_loss = 0.40040473672358884, disc_loss = 0.07829301920086752
Trained batch 368 in epoch 12, gen_loss = 0.40034988716365844, disc_loss = 0.07834154632331193
Trained batch 369 in epoch 12, gen_loss = 0.4003399876323906, disc_loss = 0.07828072099443022
Trained batch 370 in epoch 12, gen_loss = 0.3999832507895652, disc_loss = 0.07828201909205623
Trained batch 371 in epoch 12, gen_loss = 0.3999880414496186, disc_loss = 0.07842326874629424
Trained batch 372 in epoch 12, gen_loss = 0.3999347371166577, disc_loss = 0.07841446541684202
Trained batch 373 in epoch 12, gen_loss = 0.3998031894312823, disc_loss = 0.07847679822137928
Trained batch 374 in epoch 12, gen_loss = 0.3995686512788137, disc_loss = 0.07846436668808261
Trained batch 375 in epoch 12, gen_loss = 0.3995774416847432, disc_loss = 0.07856541314593299
Trained batch 376 in epoch 12, gen_loss = 0.3995336747928387, disc_loss = 0.07879949482997746
Trained batch 377 in epoch 12, gen_loss = 0.3996512613914631, disc_loss = 0.07906806387534493
Trained batch 378 in epoch 12, gen_loss = 0.399713044823946, disc_loss = 0.07889401100915033
Trained batch 379 in epoch 12, gen_loss = 0.3997134647087047, disc_loss = 0.07875290816086099
Trained batch 380 in epoch 12, gen_loss = 0.3996852276519215, disc_loss = 0.07865038345105888
Trained batch 381 in epoch 12, gen_loss = 0.39961045559164116, disc_loss = 0.07849758369628711
Trained batch 382 in epoch 12, gen_loss = 0.3997136589441225, disc_loss = 0.07836649288343114
Trained batch 383 in epoch 12, gen_loss = 0.3997099033246438, disc_loss = 0.07824497981952543
Trained batch 384 in epoch 12, gen_loss = 0.3996547328187274, disc_loss = 0.07824094240952816
Trained batch 385 in epoch 12, gen_loss = 0.39986310806607955, disc_loss = 0.07822147161950757
Trained batch 386 in epoch 12, gen_loss = 0.39986845450499875, disc_loss = 0.07810549499245616
Trained batch 387 in epoch 12, gen_loss = 0.3998600455749895, disc_loss = 0.07802247235517872
Trained batch 388 in epoch 12, gen_loss = 0.3997393517077429, disc_loss = 0.07791651621255018
Trained batch 389 in epoch 12, gen_loss = 0.39986378321280847, disc_loss = 0.07797972969352626
Trained batch 390 in epoch 12, gen_loss = 0.3996295021927875, disc_loss = 0.07835702419571598
Trained batch 391 in epoch 12, gen_loss = 0.3997947631441817, disc_loss = 0.07825978423055376
Trained batch 392 in epoch 12, gen_loss = 0.39986496261361293, disc_loss = 0.07821049550358614
Trained batch 393 in epoch 12, gen_loss = 0.3998739152087778, disc_loss = 0.07824857112819206
Trained batch 394 in epoch 12, gen_loss = 0.39998456345328803, disc_loss = 0.07811131058732354
Trained batch 395 in epoch 12, gen_loss = 0.4001982118746247, disc_loss = 0.0780758358963831
Trained batch 396 in epoch 12, gen_loss = 0.4001068731098992, disc_loss = 0.07830051336582909
Trained batch 397 in epoch 12, gen_loss = 0.4003103529688102, disc_loss = 0.07875683512562072
Trained batch 398 in epoch 12, gen_loss = 0.4001405093454777, disc_loss = 0.07869314698427729
Trained batch 399 in epoch 12, gen_loss = 0.39975902892649173, disc_loss = 0.07869147024233826
Trained batch 400 in epoch 12, gen_loss = 0.399739558337038, disc_loss = 0.07862314382252142
Trained batch 401 in epoch 12, gen_loss = 0.39972901811350636, disc_loss = 0.07855240110219897
Trained batch 402 in epoch 12, gen_loss = 0.39973817103849746, disc_loss = 0.07841290216592531
Trained batch 403 in epoch 12, gen_loss = 0.3997413696038841, disc_loss = 0.07826575178694496
Trained batch 404 in epoch 12, gen_loss = 0.3996575655024729, disc_loss = 0.07812382670027422
Trained batch 405 in epoch 12, gen_loss = 0.3998058913229722, disc_loss = 0.07797327599708413
Trained batch 406 in epoch 12, gen_loss = 0.3996561016585376, disc_loss = 0.07801249012447144
Trained batch 407 in epoch 12, gen_loss = 0.39978410069848974, disc_loss = 0.07856523366667804
Trained batch 408 in epoch 12, gen_loss = 0.40000754186751497, disc_loss = 0.07853194015228114
Trained batch 409 in epoch 12, gen_loss = 0.3999813970996112, disc_loss = 0.07849673742042264
Trained batch 410 in epoch 12, gen_loss = 0.3999759371408291, disc_loss = 0.07852170687653759
Trained batch 411 in epoch 12, gen_loss = 0.40006206481202133, disc_loss = 0.07842597126332337
Trained batch 412 in epoch 12, gen_loss = 0.40022944639150515, disc_loss = 0.07834012158436038
Trained batch 413 in epoch 12, gen_loss = 0.40030422461205634, disc_loss = 0.0782092390143299
Trained batch 414 in epoch 12, gen_loss = 0.4002740411155195, disc_loss = 0.07810096480064543
Trained batch 415 in epoch 12, gen_loss = 0.40043734723272234, disc_loss = 0.07818169552998509
Trained batch 416 in epoch 12, gen_loss = 0.40050222376267686, disc_loss = 0.0784782525520477
Trained batch 417 in epoch 12, gen_loss = 0.4006156852228219, disc_loss = 0.07834212732073544
Trained batch 418 in epoch 12, gen_loss = 0.40060808742530024, disc_loss = 0.07825558860775146
Trained batch 419 in epoch 12, gen_loss = 0.40067289776745296, disc_loss = 0.07817206024968376
Trained batch 420 in epoch 12, gen_loss = 0.4006334424302017, disc_loss = 0.07811218337874833
Trained batch 421 in epoch 12, gen_loss = 0.4006390295463716, disc_loss = 0.07797786601933858
Trained batch 422 in epoch 12, gen_loss = 0.40051556176045827, disc_loss = 0.07785359538549967
Trained batch 423 in epoch 12, gen_loss = 0.4005138438265279, disc_loss = 0.07775030265021894
Trained batch 424 in epoch 12, gen_loss = 0.40076497610877543, disc_loss = 0.07779315996805534
Trained batch 425 in epoch 12, gen_loss = 0.4004711881629738, disc_loss = 0.07815696669090977
Trained batch 426 in epoch 12, gen_loss = 0.40058857411913906, disc_loss = 0.07804053485397887
Trained batch 427 in epoch 12, gen_loss = 0.40056187144228234, disc_loss = 0.07788651523062802
Trained batch 428 in epoch 12, gen_loss = 0.4006834671352849, disc_loss = 0.07775496665740034
Trained batch 429 in epoch 12, gen_loss = 0.400686016193656, disc_loss = 0.07779552181424616
Trained batch 430 in epoch 12, gen_loss = 0.4009223707590745, disc_loss = 0.07842077076620921
Trained batch 431 in epoch 12, gen_loss = 0.40083475645493577, disc_loss = 0.07832897770438446
Trained batch 432 in epoch 12, gen_loss = 0.4007844704678648, disc_loss = 0.0782560202525391
Trained batch 433 in epoch 12, gen_loss = 0.4006611281138961, disc_loss = 0.07842184244740909
Trained batch 434 in epoch 12, gen_loss = 0.40056645006969055, disc_loss = 0.07842482748366464
Trained batch 435 in epoch 12, gen_loss = 0.4006444069497082, disc_loss = 0.07845462787225671
Trained batch 436 in epoch 12, gen_loss = 0.4005925276868676, disc_loss = 0.07840792071266053
Trained batch 437 in epoch 12, gen_loss = 0.40054718789444665, disc_loss = 0.07832146524749356
Trained batch 438 in epoch 12, gen_loss = 0.40070950536901695, disc_loss = 0.0782171252018142
Trained batch 439 in epoch 12, gen_loss = 0.400863069770011, disc_loss = 0.07805986160052601
Trained batch 440 in epoch 12, gen_loss = 0.40103285801924277, disc_loss = 0.07799222154221803
Trained batch 441 in epoch 12, gen_loss = 0.40123610124329095, disc_loss = 0.0779935069228375
Trained batch 442 in epoch 12, gen_loss = 0.400994662372038, disc_loss = 0.07798923263914934
Trained batch 443 in epoch 12, gen_loss = 0.40102308746930715, disc_loss = 0.07790853598612352
Trained batch 444 in epoch 12, gen_loss = 0.40107740137014497, disc_loss = 0.07777298463173629
Trained batch 445 in epoch 12, gen_loss = 0.40118178504732155, disc_loss = 0.07767519398567355
Trained batch 446 in epoch 12, gen_loss = 0.4011458629196389, disc_loss = 0.07760600435966314
Trained batch 447 in epoch 12, gen_loss = 0.40136829750346287, disc_loss = 0.07748400405294628
Trained batch 448 in epoch 12, gen_loss = 0.4014270514714426, disc_loss = 0.0773847970918634
Trained batch 449 in epoch 12, gen_loss = 0.40130717032485536, disc_loss = 0.07731100077740848
Trained batch 450 in epoch 12, gen_loss = 0.4014206806862698, disc_loss = 0.07722051070276194
Trained batch 451 in epoch 12, gen_loss = 0.4014295968597969, disc_loss = 0.07713718101922093
Trained batch 452 in epoch 12, gen_loss = 0.4016150959806463, disc_loss = 0.07702484209949838
Trained batch 453 in epoch 12, gen_loss = 0.40152651714858506, disc_loss = 0.07689851910872836
Trained batch 454 in epoch 12, gen_loss = 0.4014686635562352, disc_loss = 0.07696147432837348
Trained batch 455 in epoch 12, gen_loss = 0.4011733459406777, disc_loss = 0.07751173973226462
Trained batch 456 in epoch 12, gen_loss = 0.40119209657351873, disc_loss = 0.0774066392322126
Trained batch 457 in epoch 12, gen_loss = 0.40117363794401745, disc_loss = 0.07736018043332712
Trained batch 458 in epoch 12, gen_loss = 0.4011530850188145, disc_loss = 0.07741400762106046
Trained batch 459 in epoch 12, gen_loss = 0.40119769612084266, disc_loss = 0.07757899288553745
Trained batch 460 in epoch 12, gen_loss = 0.40099005882755534, disc_loss = 0.07764149711259243
Testing Epoch 12
Training Epoch 13
Trained batch 0 in epoch 13, gen_loss = 0.39967969059944153, disc_loss = 0.008898470550775528
Trained batch 1 in epoch 13, gen_loss = 0.4212709963321686, disc_loss = 0.021818310022354126
Trained batch 2 in epoch 13, gen_loss = 0.406302531560262, disc_loss = 0.029787659645080566
Trained batch 3 in epoch 13, gen_loss = 0.3895336389541626, disc_loss = 0.053067417815327644
Trained batch 4 in epoch 13, gen_loss = 0.39655667543411255, disc_loss = 0.07165519148111343
Trained batch 5 in epoch 13, gen_loss = 0.41543429096539813, disc_loss = 0.0666898141304652
Trained batch 6 in epoch 13, gen_loss = 0.4068561451775687, disc_loss = 0.06081251321094377
Trained batch 7 in epoch 13, gen_loss = 0.41906628757715225, disc_loss = 0.05688495561480522
Trained batch 8 in epoch 13, gen_loss = 0.41332583626111347, disc_loss = 0.05725166201591492
Trained batch 9 in epoch 13, gen_loss = 0.41757234632968904, disc_loss = 0.059971942007541655
Trained batch 10 in epoch 13, gen_loss = 0.4161185188726945, disc_loss = 0.05959350141611966
Trained batch 11 in epoch 13, gen_loss = 0.4106920287013054, disc_loss = 0.056337787924955286
Trained batch 12 in epoch 13, gen_loss = 0.41349467176657456, disc_loss = 0.059180641833406225
Trained batch 13 in epoch 13, gen_loss = 0.40858447551727295, disc_loss = 0.07392708039177316
Trained batch 14 in epoch 13, gen_loss = 0.40738939444224037, disc_loss = 0.0734570740411679
Trained batch 15 in epoch 13, gen_loss = 0.4099308252334595, disc_loss = 0.0696295308880508
Trained batch 16 in epoch 13, gen_loss = 0.4145876204266268, disc_loss = 0.06698139450129341
Trained batch 17 in epoch 13, gen_loss = 0.4119723223977619, disc_loss = 0.06705465995603138
Trained batch 18 in epoch 13, gen_loss = 0.416675992702183, disc_loss = 0.07187751406117489
Trained batch 19 in epoch 13, gen_loss = 0.4105878159403801, disc_loss = 0.07474595978856087
Trained batch 20 in epoch 13, gen_loss = 0.4084474103791373, disc_loss = 0.07446275332144328
Trained batch 21 in epoch 13, gen_loss = 0.40625393661585724, disc_loss = 0.07215052961625835
Trained batch 22 in epoch 13, gen_loss = 0.40781089145204297, disc_loss = 0.07279027917462846
Trained batch 23 in epoch 13, gen_loss = 0.40765126918752986, disc_loss = 0.07237877619142334
Trained batch 24 in epoch 13, gen_loss = 0.40654953718185427, disc_loss = 0.07056663416326046
Trained batch 25 in epoch 13, gen_loss = 0.40518591151787686, disc_loss = 0.07226101416521348
Trained batch 26 in epoch 13, gen_loss = 0.40733207707051877, disc_loss = 0.07502759103145865
Trained batch 27 in epoch 13, gen_loss = 0.4048434091465814, disc_loss = 0.07323986977072698
Trained batch 28 in epoch 13, gen_loss = 0.4040111375266108, disc_loss = 0.07361638616642048
Trained batch 29 in epoch 13, gen_loss = 0.40511092444260915, disc_loss = 0.07209425121545791
Trained batch 30 in epoch 13, gen_loss = 0.4056103479477667, disc_loss = 0.07059563444026055
Trained batch 31 in epoch 13, gen_loss = 0.4053309941664338, disc_loss = 0.07086943497415632
Trained batch 32 in epoch 13, gen_loss = 0.4083734994584864, disc_loss = 0.07544442954840082
Trained batch 33 in epoch 13, gen_loss = 0.40850019104340496, disc_loss = 0.07474551404661992
Trained batch 34 in epoch 13, gen_loss = 0.411240371635982, disc_loss = 0.07357108273676463
Trained batch 35 in epoch 13, gen_loss = 0.41129065304994583, disc_loss = 0.0749348337865538
Trained batch 36 in epoch 13, gen_loss = 0.40910524452054825, disc_loss = 0.0760749540216214
Trained batch 37 in epoch 13, gen_loss = 0.408917541566648, disc_loss = 0.07450927117545354
Trained batch 38 in epoch 13, gen_loss = 0.40847628850203294, disc_loss = 0.07432974808109112
Trained batch 39 in epoch 13, gen_loss = 0.4089125692844391, disc_loss = 0.0730541015509516
Trained batch 40 in epoch 13, gen_loss = 0.4085959719448555, disc_loss = 0.07271905138906909
Trained batch 41 in epoch 13, gen_loss = 0.4092711621806735, disc_loss = 0.07207140490590107
Trained batch 42 in epoch 13, gen_loss = 0.4118682437164839, disc_loss = 0.07145411568845428
Trained batch 43 in epoch 13, gen_loss = 0.41185457801276987, disc_loss = 0.07029745003885844
Trained batch 44 in epoch 13, gen_loss = 0.4101453390386369, disc_loss = 0.06935146239896615
Trained batch 45 in epoch 13, gen_loss = 0.4119728103927944, disc_loss = 0.06828335000445014
Trained batch 46 in epoch 13, gen_loss = 0.41251719124773717, disc_loss = 0.06802385419290116
Trained batch 47 in epoch 13, gen_loss = 0.4128764079262813, disc_loss = 0.07018693047575653
Trained batch 48 in epoch 13, gen_loss = 0.4147126461778368, disc_loss = 0.07630609865395391
Trained batch 49 in epoch 13, gen_loss = 0.4155602324008942, disc_loss = 0.07527209751307964
Trained batch 50 in epoch 13, gen_loss = 0.4143020417176041, disc_loss = 0.07530612695743055
Trained batch 51 in epoch 13, gen_loss = 0.4129471028080353, disc_loss = 0.07490894828851406
Trained batch 52 in epoch 13, gen_loss = 0.4129554826133656, disc_loss = 0.07421565140193363
Trained batch 53 in epoch 13, gen_loss = 0.41229285575725416, disc_loss = 0.07320522613547466
Trained batch 54 in epoch 13, gen_loss = 0.4119127642024647, disc_loss = 0.07267483046109026
Trained batch 55 in epoch 13, gen_loss = 0.41252094879746437, disc_loss = 0.07202820885660392
Trained batch 56 in epoch 13, gen_loss = 0.4128360434582359, disc_loss = 0.07151753827929497
Trained batch 57 in epoch 13, gen_loss = 0.4117864740305933, disc_loss = 0.07148142794853654
Trained batch 58 in epoch 13, gen_loss = 0.4100466804989314, disc_loss = 0.0713787429287272
Trained batch 59 in epoch 13, gen_loss = 0.4103442107637723, disc_loss = 0.0712251424168547
Trained batch 60 in epoch 13, gen_loss = 0.40906194047849687, disc_loss = 0.07144178785994405
Trained batch 61 in epoch 13, gen_loss = 0.4101912499435486, disc_loss = 0.07081936918679745
Trained batch 62 in epoch 13, gen_loss = 0.4098053163006192, disc_loss = 0.07112916115494002
Trained batch 63 in epoch 13, gen_loss = 0.40883561270311475, disc_loss = 0.07254429924068972
Trained batch 64 in epoch 13, gen_loss = 0.4090908041367164, disc_loss = 0.07167312388236706
Trained batch 65 in epoch 13, gen_loss = 0.40949085806355334, disc_loss = 0.07140431496681589
Trained batch 66 in epoch 13, gen_loss = 0.4099828276171613, disc_loss = 0.07066314005807264
Trained batch 67 in epoch 13, gen_loss = 0.4090210159911829, disc_loss = 0.06985154460348628
Trained batch 68 in epoch 13, gen_loss = 0.40726878332055133, disc_loss = 0.06922359443337157
Trained batch 69 in epoch 13, gen_loss = 0.40757161464009967, disc_loss = 0.06913180513573544
Trained batch 70 in epoch 13, gen_loss = 0.4073759527273581, disc_loss = 0.06916258581192561
Trained batch 71 in epoch 13, gen_loss = 0.40752512878841823, disc_loss = 0.0690227573375321
Trained batch 72 in epoch 13, gen_loss = 0.40724143426712245, disc_loss = 0.06827231675182303
Trained batch 73 in epoch 13, gen_loss = 0.40777433724016754, disc_loss = 0.06781615578644984
Trained batch 74 in epoch 13, gen_loss = 0.40758065223693846, disc_loss = 0.06739779676000278
Trained batch 75 in epoch 13, gen_loss = 0.40830432505984054, disc_loss = 0.06713470316639072
Trained batch 76 in epoch 13, gen_loss = 0.40893239363447415, disc_loss = 0.0670309370601332
Trained batch 77 in epoch 13, gen_loss = 0.4091306596230238, disc_loss = 0.06660772248720512
Trained batch 78 in epoch 13, gen_loss = 0.40943572377856774, disc_loss = 0.06614466209577609
Trained batch 79 in epoch 13, gen_loss = 0.40902927331626415, disc_loss = 0.06549013773910702
Trained batch 80 in epoch 13, gen_loss = 0.4093855067535683, disc_loss = 0.06480274563310323
Trained batch 81 in epoch 13, gen_loss = 0.40850006443698234, disc_loss = 0.06437326879126996
Trained batch 82 in epoch 13, gen_loss = 0.409650258271091, disc_loss = 0.06563068641327231
Trained batch 83 in epoch 13, gen_loss = 0.4087680507273901, disc_loss = 0.0681542749073179
Trained batch 84 in epoch 13, gen_loss = 0.40890700782046596, disc_loss = 0.06861642846728072
Trained batch 85 in epoch 13, gen_loss = 0.40875187654827916, disc_loss = 0.0682267427314506
Trained batch 86 in epoch 13, gen_loss = 0.4087005853652954, disc_loss = 0.0677260949180044
Trained batch 87 in epoch 13, gen_loss = 0.4092508283528415, disc_loss = 0.06706723507324402
Trained batch 88 in epoch 13, gen_loss = 0.4086118209897802, disc_loss = 0.06688670257336637
Trained batch 89 in epoch 13, gen_loss = 0.40779217117362554, disc_loss = 0.06685025828580062
Trained batch 90 in epoch 13, gen_loss = 0.4068766197005471, disc_loss = 0.06628300315076179
Trained batch 91 in epoch 13, gen_loss = 0.4067296223795932, disc_loss = 0.0657914402368276
Trained batch 92 in epoch 13, gen_loss = 0.40663529660112113, disc_loss = 0.06575897392085804
Trained batch 93 in epoch 13, gen_loss = 0.4059021897772525, disc_loss = 0.06577632298811953
Trained batch 94 in epoch 13, gen_loss = 0.4058634485069074, disc_loss = 0.06558770262881329
Trained batch 95 in epoch 13, gen_loss = 0.4059620291615526, disc_loss = 0.06703211359369259
Trained batch 96 in epoch 13, gen_loss = 0.4051757712954098, disc_loss = 0.06882575684294258
Trained batch 97 in epoch 13, gen_loss = 0.4043317446295096, disc_loss = 0.07014131705675807
Trained batch 98 in epoch 13, gen_loss = 0.4044430677336876, disc_loss = 0.06958429283942237
Trained batch 99 in epoch 13, gen_loss = 0.4038454574346542, disc_loss = 0.07004347683861852
Trained batch 100 in epoch 13, gen_loss = 0.4038879177948036, disc_loss = 0.0696173837168677
Trained batch 101 in epoch 13, gen_loss = 0.40462813657872815, disc_loss = 0.0691276414173783
Trained batch 102 in epoch 13, gen_loss = 0.403291512172199, disc_loss = 0.07009822009040893
Trained batch 103 in epoch 13, gen_loss = 0.4035508715762542, disc_loss = 0.07294674527544814
Trained batch 104 in epoch 13, gen_loss = 0.402875489564169, disc_loss = 0.07374166358439695
Trained batch 105 in epoch 13, gen_loss = 0.40220808195617963, disc_loss = 0.0750510006053549
Trained batch 106 in epoch 13, gen_loss = 0.4024692484151537, disc_loss = 0.07577369628456708
Trained batch 107 in epoch 13, gen_loss = 0.4029455946551429, disc_loss = 0.07641181772298834
Trained batch 108 in epoch 13, gen_loss = 0.40269259903409066, disc_loss = 0.0769350783848161
Trained batch 109 in epoch 13, gen_loss = 0.40285188203508204, disc_loss = 0.07672083772380243
Trained batch 110 in epoch 13, gen_loss = 0.4031346190620113, disc_loss = 0.07638353725207282
Trained batch 111 in epoch 13, gen_loss = 0.4032649153045246, disc_loss = 0.0763849000546283
Trained batch 112 in epoch 13, gen_loss = 0.4028040816826103, disc_loss = 0.07692857065229816
Trained batch 113 in epoch 13, gen_loss = 0.4023203266817227, disc_loss = 0.07675131830272444
Trained batch 114 in epoch 13, gen_loss = 0.40259510641512664, disc_loss = 0.07656706958685232
Trained batch 115 in epoch 13, gen_loss = 0.4026700247978342, disc_loss = 0.07621001045958235
Trained batch 116 in epoch 13, gen_loss = 0.40267124721127695, disc_loss = 0.07589869575304353
Trained batch 117 in epoch 13, gen_loss = 0.40274709740937764, disc_loss = 0.07601439124131101
Trained batch 118 in epoch 13, gen_loss = 0.4030920933274662, disc_loss = 0.0766906886510238
Trained batch 119 in epoch 13, gen_loss = 0.4027911697824796, disc_loss = 0.07782502129363517
Trained batch 120 in epoch 13, gen_loss = 0.40335911758675064, disc_loss = 0.07969995500319753
Trained batch 121 in epoch 13, gen_loss = 0.403310412021934, disc_loss = 0.07938975219416325
Trained batch 122 in epoch 13, gen_loss = 0.40309310201706927, disc_loss = 0.07958971068444776
Trained batch 123 in epoch 13, gen_loss = 0.4025959783504086, disc_loss = 0.07965827452379369
Trained batch 124 in epoch 13, gen_loss = 0.40246704626083374, disc_loss = 0.0793588065057993
Trained batch 125 in epoch 13, gen_loss = 0.40266946241969154, disc_loss = 0.07906416323154218
Trained batch 126 in epoch 13, gen_loss = 0.40374017137242113, disc_loss = 0.0788925003671036
Trained batch 127 in epoch 13, gen_loss = 0.40324902068823576, disc_loss = 0.08006692559865769
Trained batch 128 in epoch 13, gen_loss = 0.4036139164322106, disc_loss = 0.07965433815595253
Trained batch 129 in epoch 13, gen_loss = 0.4038706362247467, disc_loss = 0.07947957158948367
Trained batch 130 in epoch 13, gen_loss = 0.4036398179658497, disc_loss = 0.07913093500635551
Trained batch 131 in epoch 13, gen_loss = 0.40375985701878864, disc_loss = 0.07900320548056201
Trained batch 132 in epoch 13, gen_loss = 0.4040579488851074, disc_loss = 0.07875559889340311
Trained batch 133 in epoch 13, gen_loss = 0.40362840023503377, disc_loss = 0.07856230314042587
Trained batch 134 in epoch 13, gen_loss = 0.40418142411443925, disc_loss = 0.07841410406485752
Trained batch 135 in epoch 13, gen_loss = 0.40390776338822704, disc_loss = 0.07863666113082539
Trained batch 136 in epoch 13, gen_loss = 0.404357996082654, disc_loss = 0.07843715715201667
Trained batch 137 in epoch 13, gen_loss = 0.40473075405411096, disc_loss = 0.07793843006526215
Trained batch 138 in epoch 13, gen_loss = 0.40463018395917877, disc_loss = 0.07746148502065552
Trained batch 139 in epoch 13, gen_loss = 0.404588797049863, disc_loss = 0.07719040945438402
Trained batch 140 in epoch 13, gen_loss = 0.40455398682161425, disc_loss = 0.07676709175162705
Trained batch 141 in epoch 13, gen_loss = 0.4046832176161484, disc_loss = 0.07628630076758039
Trained batch 142 in epoch 13, gen_loss = 0.40455377435350753, disc_loss = 0.07589019587510949
Trained batch 143 in epoch 13, gen_loss = 0.40462641707724994, disc_loss = 0.07624429115094244
Trained batch 144 in epoch 13, gen_loss = 0.40545464260824793, disc_loss = 0.07676429042014582
Trained batch 145 in epoch 13, gen_loss = 0.405239926421479, disc_loss = 0.07651610736263124
Trained batch 146 in epoch 13, gen_loss = 0.40539850568284796, disc_loss = 0.07607920915775356
Trained batch 147 in epoch 13, gen_loss = 0.40527186784389857, disc_loss = 0.07588011093714551
Trained batch 148 in epoch 13, gen_loss = 0.40500966534518557, disc_loss = 0.07570922599117828
Trained batch 149 in epoch 13, gen_loss = 0.4048655911286672, disc_loss = 0.07580080185706417
Trained batch 150 in epoch 13, gen_loss = 0.40505635343640056, disc_loss = 0.07608356686395328
Trained batch 151 in epoch 13, gen_loss = 0.405161247833779, disc_loss = 0.07567508931051155
Trained batch 152 in epoch 13, gen_loss = 0.404819503523945, disc_loss = 0.07531149248939518
Trained batch 153 in epoch 13, gen_loss = 0.40438934599424337, disc_loss = 0.07518372863119879
Trained batch 154 in epoch 13, gen_loss = 0.4042221027035867, disc_loss = 0.07526595240999615
Trained batch 155 in epoch 13, gen_loss = 0.40462494851687014, disc_loss = 0.07632309078382185
Trained batch 156 in epoch 13, gen_loss = 0.40450407251430925, disc_loss = 0.0763688397765824
Trained batch 157 in epoch 13, gen_loss = 0.4045751287212855, disc_loss = 0.07604512007011077
Trained batch 158 in epoch 13, gen_loss = 0.40513526793545895, disc_loss = 0.07566106356914688
Trained batch 159 in epoch 13, gen_loss = 0.40509382672607896, disc_loss = 0.07553304655011743
Trained batch 160 in epoch 13, gen_loss = 0.4048934967621513, disc_loss = 0.075462766570149
Trained batch 161 in epoch 13, gen_loss = 0.40490442900745954, disc_loss = 0.07509457942006396
Trained batch 162 in epoch 13, gen_loss = 0.40433919118957284, disc_loss = 0.07497830379274359
Trained batch 163 in epoch 13, gen_loss = 0.4045217386106165, disc_loss = 0.07500403816243861
Trained batch 164 in epoch 13, gen_loss = 0.40406393228155196, disc_loss = 0.0746356969304157
Trained batch 165 in epoch 13, gen_loss = 0.4047711586736771, disc_loss = 0.07431577037212002
Trained batch 166 in epoch 13, gen_loss = 0.40442231868555445, disc_loss = 0.07410386872818013
Trained batch 167 in epoch 13, gen_loss = 0.404923022148155, disc_loss = 0.07440450538082846
Trained batch 168 in epoch 13, gen_loss = 0.4045162564198646, disc_loss = 0.07418365548392372
Trained batch 169 in epoch 13, gen_loss = 0.40446166378610277, disc_loss = 0.07388504310784971
Trained batch 170 in epoch 13, gen_loss = 0.40480343065066643, disc_loss = 0.0735174739809587
Trained batch 171 in epoch 13, gen_loss = 0.40478196878765904, disc_loss = 0.07322002498996119
Trained batch 172 in epoch 13, gen_loss = 0.4050467431200722, disc_loss = 0.07315777311090789
Trained batch 173 in epoch 13, gen_loss = 0.40465639891295596, disc_loss = 0.07302999605649504
Trained batch 174 in epoch 13, gen_loss = 0.4045200530120305, disc_loss = 0.07293908855744771
Trained batch 175 in epoch 13, gen_loss = 0.4049843654713847, disc_loss = 0.07285929249006916
Trained batch 176 in epoch 13, gen_loss = 0.40489271636736596, disc_loss = 0.07251031629446536
Trained batch 177 in epoch 13, gen_loss = 0.4051359346073665, disc_loss = 0.07221683462181788
Trained batch 178 in epoch 13, gen_loss = 0.4049264683736769, disc_loss = 0.07191552307102933
Trained batch 179 in epoch 13, gen_loss = 0.4048301489816772, disc_loss = 0.07158815725706517
Trained batch 180 in epoch 13, gen_loss = 0.40460951074710866, disc_loss = 0.07167562839796365
Trained batch 181 in epoch 13, gen_loss = 0.4042305854650644, disc_loss = 0.07275952445343137
Trained batch 182 in epoch 13, gen_loss = 0.4048465786735868, disc_loss = 0.0728437379969518
Trained batch 183 in epoch 13, gen_loss = 0.4049465746983238, disc_loss = 0.07265093575899853
Trained batch 184 in epoch 13, gen_loss = 0.40489313795759874, disc_loss = 0.0723703410929522
Trained batch 185 in epoch 13, gen_loss = 0.40493748777656147, disc_loss = 0.072279017193303
Trained batch 186 in epoch 13, gen_loss = 0.40539640825699996, disc_loss = 0.0720169145544184
Trained batch 187 in epoch 13, gen_loss = 0.4051836288355766, disc_loss = 0.07174100072440157
Trained batch 188 in epoch 13, gen_loss = 0.4053931983690413, disc_loss = 0.07143049474766172
Trained batch 189 in epoch 13, gen_loss = 0.4052197483025099, disc_loss = 0.07138091965431445
Trained batch 190 in epoch 13, gen_loss = 0.4053163542485362, disc_loss = 0.07123896002242859
Trained batch 191 in epoch 13, gen_loss = 0.4052438017291327, disc_loss = 0.07113547123056681
Trained batch 192 in epoch 13, gen_loss = 0.40483156973833867, disc_loss = 0.0710388284051125
Trained batch 193 in epoch 13, gen_loss = 0.4050471707410419, disc_loss = 0.07096865618140581
Trained batch 194 in epoch 13, gen_loss = 0.4048815491871956, disc_loss = 0.0707222753085005
Trained batch 195 in epoch 13, gen_loss = 0.4047979353641977, disc_loss = 0.07062948792127474
Trained batch 196 in epoch 13, gen_loss = 0.40536915196985157, disc_loss = 0.0712414433858192
Trained batch 197 in epoch 13, gen_loss = 0.4051348317151118, disc_loss = 0.07101415818782919
Trained batch 198 in epoch 13, gen_loss = 0.40481571591080134, disc_loss = 0.07129401603629391
Trained batch 199 in epoch 13, gen_loss = 0.40510074481368064, disc_loss = 0.07144152207765728
Trained batch 200 in epoch 13, gen_loss = 0.4051011734044374, disc_loss = 0.07116404580258166
Trained batch 201 in epoch 13, gen_loss = 0.40500518532082586, disc_loss = 0.07088687139480274
Trained batch 202 in epoch 13, gen_loss = 0.40463035212361753, disc_loss = 0.07069992495636487
Trained batch 203 in epoch 13, gen_loss = 0.4049977660179138, disc_loss = 0.07043386305061479
Trained batch 204 in epoch 13, gen_loss = 0.4048713333723022, disc_loss = 0.07024157191286
Trained batch 205 in epoch 13, gen_loss = 0.40460707912745986, disc_loss = 0.07009279684986448
Trained batch 206 in epoch 13, gen_loss = 0.40416585088927964, disc_loss = 0.06996178557277445
Trained batch 207 in epoch 13, gen_loss = 0.40438193183105725, disc_loss = 0.06981390861955543
Trained batch 208 in epoch 13, gen_loss = 0.4042123750066073, disc_loss = 0.06974976517384845
Trained batch 209 in epoch 13, gen_loss = 0.40452026270684743, disc_loss = 0.0696367497644609
Trained batch 210 in epoch 13, gen_loss = 0.40493896419968084, disc_loss = 0.06943651926549266
Trained batch 211 in epoch 13, gen_loss = 0.40509897076858664, disc_loss = 0.0692321160447977
Trained batch 212 in epoch 13, gen_loss = 0.4050751564928064, disc_loss = 0.06902779503659882
Trained batch 213 in epoch 13, gen_loss = 0.4050337470301958, disc_loss = 0.0687843283472983
Trained batch 214 in epoch 13, gen_loss = 0.4051624519880428, disc_loss = 0.06855317295723876
Trained batch 215 in epoch 13, gen_loss = 0.4050119121869405, disc_loss = 0.06832218227511341
Trained batch 216 in epoch 13, gen_loss = 0.4051974461100618, disc_loss = 0.06816111490010254
Trained batch 217 in epoch 13, gen_loss = 0.4051054141937046, disc_loss = 0.06864654367208617
Trained batch 218 in epoch 13, gen_loss = 0.4044413374711389, disc_loss = 0.06974255350167484
Trained batch 219 in epoch 13, gen_loss = 0.404217996516011, disc_loss = 0.06960696214386686
Trained batch 220 in epoch 13, gen_loss = 0.4043371829781597, disc_loss = 0.06974528313981057
Trained batch 221 in epoch 13, gen_loss = 0.40429094957338796, disc_loss = 0.06950299289530597
Trained batch 222 in epoch 13, gen_loss = 0.404532674315799, disc_loss = 0.06924896376132297
Trained batch 223 in epoch 13, gen_loss = 0.40492808619248016, disc_loss = 0.0691242468767866
Trained batch 224 in epoch 13, gen_loss = 0.40490417970551384, disc_loss = 0.06922548604922162
Trained batch 225 in epoch 13, gen_loss = 0.40453056292196293, disc_loss = 0.06936559772976073
Trained batch 226 in epoch 13, gen_loss = 0.40459844115547144, disc_loss = 0.06938714077409013
Trained batch 227 in epoch 13, gen_loss = 0.40441207365508663, disc_loss = 0.06927503641743801
Trained batch 228 in epoch 13, gen_loss = 0.4044376285055319, disc_loss = 0.06906721639694996
Trained batch 229 in epoch 13, gen_loss = 0.40436071507308796, disc_loss = 0.06896703811362385
Trained batch 230 in epoch 13, gen_loss = 0.4047150940864117, disc_loss = 0.06871162577899116
Trained batch 231 in epoch 13, gen_loss = 0.40435458449967976, disc_loss = 0.06886953109441775
Trained batch 232 in epoch 13, gen_loss = 0.40447823709684383, disc_loss = 0.06966807588119492
Trained batch 233 in epoch 13, gen_loss = 0.40462548037370044, disc_loss = 0.069848722885721
Trained batch 234 in epoch 13, gen_loss = 0.4047877367506636, disc_loss = 0.06968101634386371
Trained batch 235 in epoch 13, gen_loss = 0.4048143189589856, disc_loss = 0.06971870435764856
Trained batch 236 in epoch 13, gen_loss = 0.4044276713570462, disc_loss = 0.06994546912531938
Trained batch 237 in epoch 13, gen_loss = 0.4044043709750937, disc_loss = 0.07012322727011658
Trained batch 238 in epoch 13, gen_loss = 0.40404736634078886, disc_loss = 0.07000687743720276
Trained batch 239 in epoch 13, gen_loss = 0.4040810130536556, disc_loss = 0.06990184222425645
Trained batch 240 in epoch 13, gen_loss = 0.40423914567563546, disc_loss = 0.06972525584515324
Trained batch 241 in epoch 13, gen_loss = 0.40410828627338097, disc_loss = 0.0695453195694126
Trained batch 242 in epoch 13, gen_loss = 0.4038380435955377, disc_loss = 0.06947430651328323
Trained batch 243 in epoch 13, gen_loss = 0.40386657392392394, disc_loss = 0.0693775392862678
Trained batch 244 in epoch 13, gen_loss = 0.40372375675610134, disc_loss = 0.06918571717961101
Trained batch 245 in epoch 13, gen_loss = 0.4036445136719603, disc_loss = 0.0691227758628869
Trained batch 246 in epoch 13, gen_loss = 0.40404389008336705, disc_loss = 0.06933105410065366
Trained batch 247 in epoch 13, gen_loss = 0.40363929300538953, disc_loss = 0.0696519602638399
Trained batch 248 in epoch 13, gen_loss = 0.4038912789170522, disc_loss = 0.06966874346391384
Trained batch 249 in epoch 13, gen_loss = 0.4041823692321777, disc_loss = 0.06944859593734146
Trained batch 250 in epoch 13, gen_loss = 0.4040507899812493, disc_loss = 0.06940982469628412
Trained batch 251 in epoch 13, gen_loss = 0.40411828813098727, disc_loss = 0.06929269512479622
Trained batch 252 in epoch 13, gen_loss = 0.403925851635311, disc_loss = 0.0692938165371067
Trained batch 253 in epoch 13, gen_loss = 0.403899057878284, disc_loss = 0.06934513811271374
Trained batch 254 in epoch 13, gen_loss = 0.4036078174908956, disc_loss = 0.06921378131225413
Trained batch 255 in epoch 13, gen_loss = 0.4036291145021096, disc_loss = 0.06914719564883853
Trained batch 256 in epoch 13, gen_loss = 0.40395508167344774, disc_loss = 0.06902204418794075
Trained batch 257 in epoch 13, gen_loss = 0.403856734088225, disc_loss = 0.06892812254571522
Trained batch 258 in epoch 13, gen_loss = 0.4037543306249449, disc_loss = 0.068898505293926
Trained batch 259 in epoch 13, gen_loss = 0.4036497027828143, disc_loss = 0.06902465953205067
Trained batch 260 in epoch 13, gen_loss = 0.40364907299421754, disc_loss = 0.06907487299179095
Trained batch 261 in epoch 13, gen_loss = 0.40388828356757417, disc_loss = 0.06889835193056527
Trained batch 262 in epoch 13, gen_loss = 0.4036427592369993, disc_loss = 0.06887859760114336
Trained batch 263 in epoch 13, gen_loss = 0.4039940099147233, disc_loss = 0.0692230572211415
Trained batch 264 in epoch 13, gen_loss = 0.4038233787383673, disc_loss = 0.06928845241595552
Trained batch 265 in epoch 13, gen_loss = 0.40407586624299674, disc_loss = 0.06911192932061123
Trained batch 266 in epoch 13, gen_loss = 0.40408732170022826, disc_loss = 0.06893282282874268
Trained batch 267 in epoch 13, gen_loss = 0.4044159240464666, disc_loss = 0.06878513207228215
Trained batch 268 in epoch 13, gen_loss = 0.4041664141704602, disc_loss = 0.06884453283297418
Trained batch 269 in epoch 13, gen_loss = 0.4041344517910922, disc_loss = 0.06880369384738583
Trained batch 270 in epoch 13, gen_loss = 0.4042598565566144, disc_loss = 0.06898710626174052
Trained batch 271 in epoch 13, gen_loss = 0.40394576671807203, disc_loss = 0.06958968882270924
Trained batch 272 in epoch 13, gen_loss = 0.40390855827174343, disc_loss = 0.06969409995122161
Trained batch 273 in epoch 13, gen_loss = 0.4042271574700836, disc_loss = 0.06953731864133347
Trained batch 274 in epoch 13, gen_loss = 0.40431286822665824, disc_loss = 0.06950813230804422
Trained batch 275 in epoch 13, gen_loss = 0.4040574701367945, disc_loss = 0.06947146220794083
Trained batch 276 in epoch 13, gen_loss = 0.4041914180297714, disc_loss = 0.06973363055312999
Trained batch 277 in epoch 13, gen_loss = 0.40391404197799213, disc_loss = 0.07000664749899678
Trained batch 278 in epoch 13, gen_loss = 0.4037896748298385, disc_loss = 0.06995194421006252
Trained batch 279 in epoch 13, gen_loss = 0.4037374413439206, disc_loss = 0.06974906391530697
Trained batch 280 in epoch 13, gen_loss = 0.403439503759676, disc_loss = 0.06958901360829849
Trained batch 281 in epoch 13, gen_loss = 0.40321244605889556, disc_loss = 0.06945026246830821
Trained batch 282 in epoch 13, gen_loss = 0.40332683489095195, disc_loss = 0.06927801451115957
Trained batch 283 in epoch 13, gen_loss = 0.40349393327471234, disc_loss = 0.06921331871392757
Trained batch 284 in epoch 13, gen_loss = 0.4032832534689652, disc_loss = 0.06917432815555417
Trained batch 285 in epoch 13, gen_loss = 0.4035623343466045, disc_loss = 0.06923978507088926
Trained batch 286 in epoch 13, gen_loss = 0.4034665923708407, disc_loss = 0.06916196290922809
Trained batch 287 in epoch 13, gen_loss = 0.40356984744883245, disc_loss = 0.06902118197629331
Trained batch 288 in epoch 13, gen_loss = 0.40390250499273256, disc_loss = 0.06884802942032117
Trained batch 289 in epoch 13, gen_loss = 0.4038653004786064, disc_loss = 0.06873168268016186
Trained batch 290 in epoch 13, gen_loss = 0.4038677526913148, disc_loss = 0.06860429963538635
Trained batch 291 in epoch 13, gen_loss = 0.40396358981116176, disc_loss = 0.06869161834187601
Trained batch 292 in epoch 13, gen_loss = 0.4044874435602195, disc_loss = 0.06935685223012959
Trained batch 293 in epoch 13, gen_loss = 0.404742390221479, disc_loss = 0.06919115410205356
Trained batch 294 in epoch 13, gen_loss = 0.40447197132191415, disc_loss = 0.06913861717902503
Trained batch 295 in epoch 13, gen_loss = 0.40433592560726245, disc_loss = 0.06922648008598166
Trained batch 296 in epoch 13, gen_loss = 0.40417205735489176, disc_loss = 0.06961792077467799
Trained batch 297 in epoch 13, gen_loss = 0.4040942343089404, disc_loss = 0.06969889520586237
Trained batch 298 in epoch 13, gen_loss = 0.403987917214333, disc_loss = 0.0695532200185202
Trained batch 299 in epoch 13, gen_loss = 0.4039085027575493, disc_loss = 0.06954035869799555
Trained batch 300 in epoch 13, gen_loss = 0.4039832388245782, disc_loss = 0.06953919447797577
Trained batch 301 in epoch 13, gen_loss = 0.4038395044819409, disc_loss = 0.06938553591943439
Trained batch 302 in epoch 13, gen_loss = 0.40371994452901405, disc_loss = 0.06932933603047636
Trained batch 303 in epoch 13, gen_loss = 0.403599445757113, disc_loss = 0.06918968997074683
Trained batch 304 in epoch 13, gen_loss = 0.403324526255248, disc_loss = 0.06930850384237824
Trained batch 305 in epoch 13, gen_loss = 0.40344977057447623, disc_loss = 0.06924179793195495
Trained batch 306 in epoch 13, gen_loss = 0.40366171305265025, disc_loss = 0.06931654352039487
Trained batch 307 in epoch 13, gen_loss = 0.4035434075570726, disc_loss = 0.0695876164222741
Trained batch 308 in epoch 13, gen_loss = 0.40378480117683657, disc_loss = 0.06968692008068357
Trained batch 309 in epoch 13, gen_loss = 0.40394786990457965, disc_loss = 0.06949492512390978
Trained batch 310 in epoch 13, gen_loss = 0.4040067195892334, disc_loss = 0.06929853352810889
Trained batch 311 in epoch 13, gen_loss = 0.40394289581439435, disc_loss = 0.06932286168627727
Trained batch 312 in epoch 13, gen_loss = 0.4041887714078251, disc_loss = 0.06948619462347354
Trained batch 313 in epoch 13, gen_loss = 0.40401167854381975, disc_loss = 0.06961088172296524
Trained batch 314 in epoch 13, gen_loss = 0.4041099434807187, disc_loss = 0.06951637116985189
Trained batch 315 in epoch 13, gen_loss = 0.4040938591278052, disc_loss = 0.06933117133294102
Trained batch 316 in epoch 13, gen_loss = 0.4042025878790425, disc_loss = 0.06924358291157788
Trained batch 317 in epoch 13, gen_loss = 0.40407466569786554, disc_loss = 0.06932485767833467
Trained batch 318 in epoch 13, gen_loss = 0.4040058240247744, disc_loss = 0.06919006291531657
Trained batch 319 in epoch 13, gen_loss = 0.40412450348958373, disc_loss = 0.06902173332637176
Trained batch 320 in epoch 13, gen_loss = 0.4044249056841354, disc_loss = 0.06885527537967372
Trained batch 321 in epoch 13, gen_loss = 0.40460550831341596, disc_loss = 0.06883744297907775
Trained batch 322 in epoch 13, gen_loss = 0.40434651810318323, disc_loss = 0.0693686938449602
Trained batch 323 in epoch 13, gen_loss = 0.40442976705086087, disc_loss = 0.06966758178501034
Trained batch 324 in epoch 13, gen_loss = 0.4045538523563972, disc_loss = 0.06953764980229048
Trained batch 325 in epoch 13, gen_loss = 0.40448436726090364, disc_loss = 0.069612165815854
Trained batch 326 in epoch 13, gen_loss = 0.4045705980299445, disc_loss = 0.06946780001716148
Trained batch 327 in epoch 13, gen_loss = 0.40448061967404875, disc_loss = 0.0693825248901437
Trained batch 328 in epoch 13, gen_loss = 0.4044625477406754, disc_loss = 0.06924989776499003
Trained batch 330 in epoch 13, gen_loss = 0.40442773600719484, disc_loss = 0.06906235348602076
Trained batch 331 in epoch 13, gen_loss = 0.40443449880344323, disc_loss = 0.06896854755300355
Trained batch 332 in epoch 13, gen_loss = 0.404449081456697, disc_loss = 0.06880655852300269
Trained batch 333 in epoch 13, gen_loss = 0.4046256534175245, disc_loss = 0.06865432294096775
Trained batch 334 in epoch 13, gen_loss = 0.4047270971447674, disc_loss = 0.06861438975850148
Trained batch 335 in epoch 13, gen_loss = 0.40441660166141535, disc_loss = 0.06880100539308928
Trained batch 336 in epoch 13, gen_loss = 0.4044687124494275, disc_loss = 0.0690370317692219
Trained batch 337 in epoch 13, gen_loss = 0.4043360075654363, disc_loss = 0.06885642676542585
Trained batch 338 in epoch 13, gen_loss = 0.4045425322027685, disc_loss = 0.06878669244844389
Trained batch 339 in epoch 13, gen_loss = 0.40446746112669213, disc_loss = 0.06869226125726367
Trained batch 340 in epoch 13, gen_loss = 0.404421181622838, disc_loss = 0.06861376844597789
Trained batch 341 in epoch 13, gen_loss = 0.40453257930209063, disc_loss = 0.06844855130688228
Trained batch 342 in epoch 13, gen_loss = 0.4044179017967802, disc_loss = 0.06866819418304256
Trained batch 343 in epoch 13, gen_loss = 0.4046477907618811, disc_loss = 0.06925938404327649
Trained batch 344 in epoch 13, gen_loss = 0.40488803317581396, disc_loss = 0.06911436064789693
Trained batch 345 in epoch 13, gen_loss = 0.4047829295169411, disc_loss = 0.06906187636885426
Trained batch 346 in epoch 13, gen_loss = 0.40500063700359906, disc_loss = 0.06893044088830264
Trained batch 347 in epoch 13, gen_loss = 0.40513540256297453, disc_loss = 0.06879195601186962
Trained batch 348 in epoch 13, gen_loss = 0.4052156297047022, disc_loss = 0.06864583740186982
Trained batch 349 in epoch 13, gen_loss = 0.4050587751184191, disc_loss = 0.0685247460193932
Trained batch 350 in epoch 13, gen_loss = 0.40524083503291136, disc_loss = 0.06836831823065664
Trained batch 351 in epoch 13, gen_loss = 0.4056741718033498, disc_loss = 0.06835931466246786
Trained batch 352 in epoch 13, gen_loss = 0.4055286492234249, disc_loss = 0.06837288955907224
Trained batch 353 in epoch 13, gen_loss = 0.4056768653082982, disc_loss = 0.0682681927399573
Trained batch 354 in epoch 13, gen_loss = 0.4058596853639039, disc_loss = 0.06858881183860588
Trained batch 355 in epoch 13, gen_loss = 0.40561716660354913, disc_loss = 0.06888394372464482
Trained batch 356 in epoch 13, gen_loss = 0.40584943867197226, disc_loss = 0.06874385256716768
Trained batch 357 in epoch 13, gen_loss = 0.4059775099574521, disc_loss = 0.06884307029017107
Trained batch 358 in epoch 13, gen_loss = 0.40594444517305633, disc_loss = 0.06872109812749212
Trained batch 359 in epoch 13, gen_loss = 0.40594835289650494, disc_loss = 0.06861110565821743
Trained batch 360 in epoch 13, gen_loss = 0.4058992161810233, disc_loss = 0.0685955269953592
Trained batch 361 in epoch 13, gen_loss = 0.40589720710535737, disc_loss = 0.0686545430075439
Trained batch 362 in epoch 13, gen_loss = 0.40583960642170974, disc_loss = 0.0685011768744381
Trained batch 363 in epoch 13, gen_loss = 0.40592851972841953, disc_loss = 0.06841340563055333
Trained batch 364 in epoch 13, gen_loss = 0.40616995602437894, disc_loss = 0.06870416794992881
Trained batch 365 in epoch 13, gen_loss = 0.40613970339623956, disc_loss = 0.0692386771348697
Trained batch 366 in epoch 13, gen_loss = 0.405990211288026, disc_loss = 0.06916461312732271
Trained batch 367 in epoch 13, gen_loss = 0.4061168388504049, disc_loss = 0.06909920404027418
Trained batch 368 in epoch 13, gen_loss = 0.4061297691126826, disc_loss = 0.06899292023251777
Trained batch 369 in epoch 13, gen_loss = 0.40583070887101663, disc_loss = 0.06901197360224418
Trained batch 370 in epoch 13, gen_loss = 0.40580428972077176, disc_loss = 0.06895057444593736
Trained batch 371 in epoch 13, gen_loss = 0.4056953534644137, disc_loss = 0.06942423406277373
Trained batch 372 in epoch 13, gen_loss = 0.4058005741070806, disc_loss = 0.06949766259141087
Trained batch 373 in epoch 13, gen_loss = 0.40604189428734905, disc_loss = 0.06938583384651471
Trained batch 374 in epoch 13, gen_loss = 0.4059782269001007, disc_loss = 0.06935050675024589
Trained batch 375 in epoch 13, gen_loss = 0.40596993441911455, disc_loss = 0.06921061180145578
Trained batch 376 in epoch 13, gen_loss = 0.40608878540423565, disc_loss = 0.06909668936940103
Trained batch 377 in epoch 13, gen_loss = 0.4061920213951636, disc_loss = 0.06895154273314845
Trained batch 378 in epoch 13, gen_loss = 0.40612685279355515, disc_loss = 0.06892033719696046
Trained batch 379 in epoch 13, gen_loss = 0.40620275649585225, disc_loss = 0.06896469959940173
Trained batch 380 in epoch 13, gen_loss = 0.406246755536147, disc_loss = 0.06899366827236778
Trained batch 381 in epoch 13, gen_loss = 0.40620134794275176, disc_loss = 0.06912779792684925
Trained batch 382 in epoch 13, gen_loss = 0.4059699899067144, disc_loss = 0.06946175594330223
Trained batch 383 in epoch 13, gen_loss = 0.40601147687993944, disc_loss = 0.069470660026127
Trained batch 384 in epoch 13, gen_loss = 0.4059195855221191, disc_loss = 0.06943981818032342
Trained batch 385 in epoch 13, gen_loss = 0.4059028860972953, disc_loss = 0.06933256673235735
Trained batch 386 in epoch 13, gen_loss = 0.40571143907477997, disc_loss = 0.0693156941209075
Trained batch 387 in epoch 13, gen_loss = 0.405973346423857, disc_loss = 0.0694774150987607
Trained batch 388 in epoch 13, gen_loss = 0.4060797977876541, disc_loss = 0.06933811560014602
Trained batch 389 in epoch 13, gen_loss = 0.4060907050585135, disc_loss = 0.06946987769781397
Trained batch 390 in epoch 13, gen_loss = 0.40627627009930817, disc_loss = 0.06933638555667056
Trained batch 391 in epoch 13, gen_loss = 0.40642767232291555, disc_loss = 0.06936850951157739
Trained batch 392 in epoch 13, gen_loss = 0.4062501395325018, disc_loss = 0.06923647646960487
Trained batch 393 in epoch 13, gen_loss = 0.40593271048238433, disc_loss = 0.06917028595471215
Trained batch 394 in epoch 13, gen_loss = 0.4059084783626508, disc_loss = 0.06913023575244448
Trained batch 395 in epoch 13, gen_loss = 0.40609849537863874, disc_loss = 0.06956118547752725
Trained batch 396 in epoch 13, gen_loss = 0.4059514315512679, disc_loss = 0.06980008467966198
Trained batch 397 in epoch 13, gen_loss = 0.40593988669278036, disc_loss = 0.06968462348555275
Trained batch 398 in epoch 13, gen_loss = 0.4059133045655444, disc_loss = 0.06979983558826952
Trained batch 399 in epoch 13, gen_loss = 0.4058285178989172, disc_loss = 0.06977817834587768
Trained batch 400 in epoch 13, gen_loss = 0.40565722705122836, disc_loss = 0.06984798107853628
Trained batch 401 in epoch 13, gen_loss = 0.40578150823341674, disc_loss = 0.06977916836265975
Trained batch 402 in epoch 13, gen_loss = 0.4056514097798255, disc_loss = 0.06968003969232808
Trained batch 403 in epoch 13, gen_loss = 0.4057628060921584, disc_loss = 0.06960840273583953
Trained batch 404 in epoch 13, gen_loss = 0.40564956473715513, disc_loss = 0.06990985341692045
Trained batch 405 in epoch 13, gen_loss = 0.4058227036974113, disc_loss = 0.07045955538722168
Trained batch 406 in epoch 13, gen_loss = 0.4059439282452445, disc_loss = 0.07039422097247487
Trained batch 407 in epoch 13, gen_loss = 0.40588798717248675, disc_loss = 0.0706047562211204
Trained batch 408 in epoch 13, gen_loss = 0.4058344057399078, disc_loss = 0.07055124554163743
Trained batch 409 in epoch 13, gen_loss = 0.40582083885262654, disc_loss = 0.070403068433175
Trained batch 410 in epoch 13, gen_loss = 0.4057707160058683, disc_loss = 0.07024800521604843
Trained batch 411 in epoch 13, gen_loss = 0.4058261030507319, disc_loss = 0.07013474060086877
Trained batch 412 in epoch 13, gen_loss = 0.4056059018174326, disc_loss = 0.07000801783758633
Trained batch 413 in epoch 13, gen_loss = 0.40551921408533476, disc_loss = 0.069902788490003
Trained batch 414 in epoch 13, gen_loss = 0.40546380518430686, disc_loss = 0.06988556464258806
Trained batch 415 in epoch 13, gen_loss = 0.4054571634445053, disc_loss = 0.07005293782164629
Trained batch 416 in epoch 13, gen_loss = 0.40535334939007567, disc_loss = 0.07015089344286876
Trained batch 417 in epoch 13, gen_loss = 0.40545165103873565, disc_loss = 0.07003536135288017
Trained batch 418 in epoch 13, gen_loss = 0.4055396334794939, disc_loss = 0.06999485089992638
Trained batch 419 in epoch 13, gen_loss = 0.4054687253066472, disc_loss = 0.06991738416476263
Trained batch 420 in epoch 13, gen_loss = 0.4054421310328531, disc_loss = 0.07033080321176956
Trained batch 421 in epoch 13, gen_loss = 0.4057005564042177, disc_loss = 0.07068696418794763
Trained batch 422 in epoch 13, gen_loss = 0.4056442217201206, disc_loss = 0.07059034940964998
Trained batch 423 in epoch 13, gen_loss = 0.40533202682744784, disc_loss = 0.07110725936945528
Trained batch 424 in epoch 13, gen_loss = 0.40543456757769863, disc_loss = 0.0722136353372651
Trained batch 425 in epoch 13, gen_loss = 0.4053334648340521, disc_loss = 0.07265715003494576
Trained batch 426 in epoch 13, gen_loss = 0.40513159966301304, disc_loss = 0.072869379742974
Trained batch 427 in epoch 13, gen_loss = 0.4049622390732587, disc_loss = 0.0732985813253359
Trained batch 428 in epoch 13, gen_loss = 0.4048494486125199, disc_loss = 0.07364640539264554
Trained batch 429 in epoch 13, gen_loss = 0.4049324012079904, disc_loss = 0.07374056913608382
Trained batch 430 in epoch 13, gen_loss = 0.4047579116030248, disc_loss = 0.0737445139220274
Trained batch 431 in epoch 13, gen_loss = 0.40457099717524314, disc_loss = 0.07372375565399933
Trained batch 432 in epoch 13, gen_loss = 0.4044246196609171, disc_loss = 0.07372295451898979
Trained batch 433 in epoch 13, gen_loss = 0.40425374630134775, disc_loss = 0.07376862117969152
Trained batch 434 in epoch 13, gen_loss = 0.4041726848174786, disc_loss = 0.07379796222152038
Trained batch 435 in epoch 13, gen_loss = 0.40401161250171314, disc_loss = 0.07369908018661407
Trained batch 436 in epoch 13, gen_loss = 0.4038945077758632, disc_loss = 0.07370607261450053
Trained batch 437 in epoch 13, gen_loss = 0.40365542328521, disc_loss = 0.07390311513240683
Trained batch 438 in epoch 13, gen_loss = 0.4037483308744322, disc_loss = 0.07457715798814299
Trained batch 439 in epoch 13, gen_loss = 0.4036518790505149, disc_loss = 0.0744983635482971
Trained batch 440 in epoch 13, gen_loss = 0.4035718488314795, disc_loss = 0.0744152475811558
Trained batch 441 in epoch 13, gen_loss = 0.4035640547717858, disc_loss = 0.07429231662615055
Trained batch 442 in epoch 13, gen_loss = 0.4034293070603709, disc_loss = 0.0742556248553955
Trained batch 443 in epoch 13, gen_loss = 0.4034364261739963, disc_loss = 0.07416178355505271
Trained batch 444 in epoch 13, gen_loss = 0.40340383541717956, disc_loss = 0.07410323868264977
Trained batch 445 in epoch 13, gen_loss = 0.4033583381250835, disc_loss = 0.07411474203941466
Trained batch 446 in epoch 13, gen_loss = 0.40330091285492214, disc_loss = 0.07403875497155209
Trained batch 447 in epoch 13, gen_loss = 0.40337077734459725, disc_loss = 0.07399080475650928
Trained batch 448 in epoch 13, gen_loss = 0.40338406822994716, disc_loss = 0.07392682222014746
Trained batch 449 in epoch 13, gen_loss = 0.4032035747501585, disc_loss = 0.07386623114140498
Trained batch 450 in epoch 13, gen_loss = 0.40325604633587164, disc_loss = 0.07389029569535654
Trained batch 451 in epoch 13, gen_loss = 0.4031650208398304, disc_loss = 0.07450467275364935
Trained batch 452 in epoch 13, gen_loss = 0.4034523189594151, disc_loss = 0.07509767548458664
Trained batch 453 in epoch 13, gen_loss = 0.40343082824204984, disc_loss = 0.07500010199377125
Trained batch 454 in epoch 13, gen_loss = 0.40332430312921713, disc_loss = 0.07493085495022299
Trained batch 455 in epoch 13, gen_loss = 0.40327845441929083, disc_loss = 0.07487574047940015
Trained batch 456 in epoch 13, gen_loss = 0.40320127126424526, disc_loss = 0.07476699490638153
Trained batch 457 in epoch 13, gen_loss = 0.40316028144682337, disc_loss = 0.0746610059451686
Trained batch 458 in epoch 13, gen_loss = 0.40285061523805255, disc_loss = 0.07464872784953167
Trained batch 459 in epoch 13, gen_loss = 0.4027495567565379, disc_loss = 0.07501371535877495
Trained batch 460 in epoch 13, gen_loss = 0.40291863356650265, disc_loss = 0.07601718020114297
Testing Epoch 13
Training Epoch 14
Trained batch 0 in epoch 14, gen_loss = 0.35628142952919006, disc_loss = 0.10081527382135391
Trained batch 1 in epoch 14, gen_loss = 0.3543083667755127, disc_loss = 0.127275500446558
Trained batch 2 in epoch 14, gen_loss = 0.3379842738310496, disc_loss = 0.10068849101662636
Trained batch 3 in epoch 14, gen_loss = 0.3559694364666939, disc_loss = 0.08874743618071079
Trained batch 4 in epoch 14, gen_loss = 0.3543505847454071, disc_loss = 0.08155419677495956
Trained batch 5 in epoch 14, gen_loss = 0.346975713968277, disc_loss = 0.07999672492345174
Trained batch 6 in epoch 14, gen_loss = 0.34586258019719807, disc_loss = 0.078708287860666
Trained batch 7 in epoch 14, gen_loss = 0.35472046211361885, disc_loss = 0.08550856914371252
Trained batch 8 in epoch 14, gen_loss = 0.35091174642244977, disc_loss = 0.08412960751189126
Trained batch 9 in epoch 14, gen_loss = 0.34780665934085847, disc_loss = 0.08891141340136528
Trained batch 10 in epoch 14, gen_loss = 0.35742137919772754, disc_loss = 0.08544519645246593
Trained batch 11 in epoch 14, gen_loss = 0.36084221055110294, disc_loss = 0.08368914915869634
Trained batch 12 in epoch 14, gen_loss = 0.36214518547058105, disc_loss = 0.08063194700158559
Trained batch 13 in epoch 14, gen_loss = 0.36071215144225527, disc_loss = 0.07722332887351513
Trained batch 14 in epoch 14, gen_loss = 0.35799426237742105, disc_loss = 0.07510179430246353
Trained batch 15 in epoch 14, gen_loss = 0.362750843167305, disc_loss = 0.07557547744363546
Trained batch 16 in epoch 14, gen_loss = 0.3682829422109267, disc_loss = 0.07549770702334012
Trained batch 17 in epoch 14, gen_loss = 0.3657853901386261, disc_loss = 0.07221429070664777
Trained batch 18 in epoch 14, gen_loss = 0.36364679744369105, disc_loss = 0.06969311617706951
Trained batch 19 in epoch 14, gen_loss = 0.36522382497787476, disc_loss = 0.06833916362375021
Trained batch 20 in epoch 14, gen_loss = 0.3616033253215608, disc_loss = 0.06612131017304602
Trained batch 21 in epoch 14, gen_loss = 0.360752135515213, disc_loss = 0.06379756750538945
Trained batch 22 in epoch 14, gen_loss = 0.36268793240837427, disc_loss = 0.068478147742217
Trained batch 23 in epoch 14, gen_loss = 0.35935275504986447, disc_loss = 0.07568910357076675
Trained batch 24 in epoch 14, gen_loss = 0.36045424580574037, disc_loss = 0.0786803413555026
Trained batch 25 in epoch 14, gen_loss = 0.3638130953678718, disc_loss = 0.08148236583488491
Trained batch 26 in epoch 14, gen_loss = 0.3652855544178574, disc_loss = 0.08303280847354068
Trained batch 27 in epoch 14, gen_loss = 0.3658446286405836, disc_loss = 0.08285274073880698
Trained batch 28 in epoch 14, gen_loss = 0.3638420731856905, disc_loss = 0.08326667839468553
Trained batch 29 in epoch 14, gen_loss = 0.36769205927848814, disc_loss = 0.08456623141343395
Trained batch 30 in epoch 14, gen_loss = 0.367005217459894, disc_loss = 0.09365144645374629
Trained batch 31 in epoch 14, gen_loss = 0.3684121295809746, disc_loss = 0.09675678782514296
Trained batch 32 in epoch 14, gen_loss = 0.36942470254320087, disc_loss = 0.09473442221342614
Trained batch 33 in epoch 14, gen_loss = 0.3691653416437261, disc_loss = 0.09259830407031319
Trained batch 34 in epoch 14, gen_loss = 0.3692610817296164, disc_loss = 0.09215366513069187
Trained batch 35 in epoch 14, gen_loss = 0.36735011637210846, disc_loss = 0.09078447771672574
Trained batch 36 in epoch 14, gen_loss = 0.3683330996616467, disc_loss = 0.0907586966263684
Trained batch 37 in epoch 14, gen_loss = 0.3675969564600995, disc_loss = 0.0894972015613396
Trained batch 38 in epoch 14, gen_loss = 0.3652987961585705, disc_loss = 0.09202869468105909
Trained batch 39 in epoch 14, gen_loss = 0.36827433556318284, disc_loss = 0.09597547689918429
Trained batch 40 in epoch 14, gen_loss = 0.3679523526168451, disc_loss = 0.09479516001827107
Trained batch 41 in epoch 14, gen_loss = 0.3685256441434224, disc_loss = 0.09525310285832911
Trained batch 42 in epoch 14, gen_loss = 0.36815338217934895, disc_loss = 0.09396360981343098
Trained batch 43 in epoch 14, gen_loss = 0.3692455711689862, disc_loss = 0.09218688040379096
Trained batch 44 in epoch 14, gen_loss = 0.37027783857451546, disc_loss = 0.09043053632809056
Trained batch 45 in epoch 14, gen_loss = 0.37155081461305206, disc_loss = 0.08971208394707544
Trained batch 46 in epoch 14, gen_loss = 0.3728423239068782, disc_loss = 0.08979152028072387
Trained batch 47 in epoch 14, gen_loss = 0.37444616109132767, disc_loss = 0.08855523149638127
Trained batch 48 in epoch 14, gen_loss = 0.3753981146277214, disc_loss = 0.08850969796125986
Trained batch 49 in epoch 14, gen_loss = 0.3757107537984848, disc_loss = 0.0872963434830308
Trained batch 50 in epoch 14, gen_loss = 0.37676099234936283, disc_loss = 0.08625202373984982
Trained batch 51 in epoch 14, gen_loss = 0.3780398792945422, disc_loss = 0.08492588606448127
Trained batch 52 in epoch 14, gen_loss = 0.3785324040448891, disc_loss = 0.08352019562262972
Trained batch 53 in epoch 14, gen_loss = 0.37911961089681695, disc_loss = 0.0830845475645253
Trained batch 54 in epoch 14, gen_loss = 0.3771779401735826, disc_loss = 0.08413120902736079
Trained batch 55 in epoch 14, gen_loss = 0.3801168368331024, disc_loss = 0.08529419599965747
Trained batch 56 in epoch 14, gen_loss = 0.3805873639750899, disc_loss = 0.08409424735592645
Trained batch 57 in epoch 14, gen_loss = 0.38024449810899535, disc_loss = 0.08422261972686854
Trained batch 58 in epoch 14, gen_loss = 0.3812781572341919, disc_loss = 0.08536026142221892
Trained batch 59 in epoch 14, gen_loss = 0.38050548483928043, disc_loss = 0.0845990130212158
Trained batch 60 in epoch 14, gen_loss = 0.3801411141137608, disc_loss = 0.0839369083434099
Trained batch 61 in epoch 14, gen_loss = 0.3810062071969432, disc_loss = 0.08382762897939931
Trained batch 62 in epoch 14, gen_loss = 0.3816316993463607, disc_loss = 0.08330910003906677
Trained batch 63 in epoch 14, gen_loss = 0.3829680262133479, disc_loss = 0.08332671645621303
Trained batch 64 in epoch 14, gen_loss = 0.3833634477395278, disc_loss = 0.08288907387222234
Trained batch 65 in epoch 14, gen_loss = 0.38284432165550464, disc_loss = 0.08214174449500261
Trained batch 66 in epoch 14, gen_loss = 0.38421354098106497, disc_loss = 0.08168036981360681
Trained batch 67 in epoch 14, gen_loss = 0.3850416790913133, disc_loss = 0.08071807228193126
Trained batch 68 in epoch 14, gen_loss = 0.38595472686532617, disc_loss = 0.07999921383579141
Trained batch 69 in epoch 14, gen_loss = 0.38750638238021307, disc_loss = 0.07924837223919375
Trained batch 70 in epoch 14, gen_loss = 0.38807652407968546, disc_loss = 0.07830803748220205
Trained batch 71 in epoch 14, gen_loss = 0.38798538140124744, disc_loss = 0.07786822009883407
Trained batch 72 in epoch 14, gen_loss = 0.3885519978118269, disc_loss = 0.07755460683256388
Trained batch 73 in epoch 14, gen_loss = 0.3901593193814561, disc_loss = 0.07819140623197765
Trained batch 74 in epoch 14, gen_loss = 0.39100711067517596, disc_loss = 0.07806963852296273
Trained batch 75 in epoch 14, gen_loss = 0.39194326455655853, disc_loss = 0.077408235900006
Trained batch 76 in epoch 14, gen_loss = 0.392416005784815, disc_loss = 0.07652168956815035
Trained batch 77 in epoch 14, gen_loss = 0.3926425366065441, disc_loss = 0.07569036420243673
Trained batch 78 in epoch 14, gen_loss = 0.3929967506776882, disc_loss = 0.07501198568298847
Trained batch 79 in epoch 14, gen_loss = 0.39322674460709095, disc_loss = 0.07556450413540006
Trained batch 80 in epoch 14, gen_loss = 0.3944342647805626, disc_loss = 0.07669130933505518
Trained batch 81 in epoch 14, gen_loss = 0.39523095764764926, disc_loss = 0.07636966410933471
Trained batch 82 in epoch 14, gen_loss = 0.39493931093847895, disc_loss = 0.0759755244635674
Trained batch 83 in epoch 14, gen_loss = 0.3956841553250949, disc_loss = 0.07558552424112956
Trained batch 84 in epoch 14, gen_loss = 0.3951606918783749, disc_loss = 0.07532866825075711
Trained batch 85 in epoch 14, gen_loss = 0.3957110612198364, disc_loss = 0.07472831983292519
Trained batch 86 in epoch 14, gen_loss = 0.39607568342110205, disc_loss = 0.07410274334680075
Trained batch 87 in epoch 14, gen_loss = 0.39580990238623187, disc_loss = 0.07391884207556193
Trained batch 88 in epoch 14, gen_loss = 0.39539627379245973, disc_loss = 0.07425565728813074
Trained batch 89 in epoch 14, gen_loss = 0.3956935816340976, disc_loss = 0.07597284809582763
Trained batch 90 in epoch 14, gen_loss = 0.39670232102111147, disc_loss = 0.0756524794294939
Trained batch 91 in epoch 14, gen_loss = 0.3968190298132274, disc_loss = 0.07666578771465499
Trained batch 92 in epoch 14, gen_loss = 0.3956551670387227, disc_loss = 0.07992146520685124
Trained batch 93 in epoch 14, gen_loss = 0.39582346982144295, disc_loss = 0.0793481678008399
Trained batch 94 in epoch 14, gen_loss = 0.39651525334308024, disc_loss = 0.07929121142155246
Trained batch 95 in epoch 14, gen_loss = 0.3964549864952763, disc_loss = 0.07877553155412897
Trained batch 96 in epoch 14, gen_loss = 0.39609092166743326, disc_loss = 0.07904120260062292
Trained batch 97 in epoch 14, gen_loss = 0.3963214441829798, disc_loss = 0.0789189183020166
Trained batch 98 in epoch 14, gen_loss = 0.3964893011131672, disc_loss = 0.07842066106997957
Trained batch 99 in epoch 14, gen_loss = 0.39709279030561445, disc_loss = 0.07785392181947827
Trained batch 100 in epoch 14, gen_loss = 0.397146073603394, disc_loss = 0.07765770543108483
Trained batch 101 in epoch 14, gen_loss = 0.3970169454228644, disc_loss = 0.07699915790455598
Trained batch 102 in epoch 14, gen_loss = 0.3978572071177288, disc_loss = 0.07802697808201452
Trained batch 103 in epoch 14, gen_loss = 0.3979116812921487, disc_loss = 0.07948387867341247
Trained batch 104 in epoch 14, gen_loss = 0.3975402159350259, disc_loss = 0.07962614746675604
Trained batch 105 in epoch 14, gen_loss = 0.3988138456951897, disc_loss = 0.08072796655502522
Trained batch 106 in epoch 14, gen_loss = 0.3984209446706504, disc_loss = 0.08024357281903798
Trained batch 107 in epoch 14, gen_loss = 0.3986939751991519, disc_loss = 0.07989177240610675
Trained batch 108 in epoch 14, gen_loss = 0.39840372221185527, disc_loss = 0.07955690676671102
Trained batch 109 in epoch 14, gen_loss = 0.3987474097446962, disc_loss = 0.07902252713049
Trained batch 110 in epoch 14, gen_loss = 0.3996195070915394, disc_loss = 0.07851509296813526
Trained batch 111 in epoch 14, gen_loss = 0.39976148307323456, disc_loss = 0.07831606697956366
Trained batch 112 in epoch 14, gen_loss = 0.3995560233571888, disc_loss = 0.0784858925746078
Trained batch 113 in epoch 14, gen_loss = 0.3991952117597848, disc_loss = 0.0784935343095608
Trained batch 114 in epoch 14, gen_loss = 0.3992567728395047, disc_loss = 0.07801809884283854
Trained batch 115 in epoch 14, gen_loss = 0.39967446440252763, disc_loss = 0.07754408858780718
Trained batch 116 in epoch 14, gen_loss = 0.4001015080855443, disc_loss = 0.07700849981962615
Trained batch 117 in epoch 14, gen_loss = 0.40024147902504875, disc_loss = 0.07668342742816371
Trained batch 118 in epoch 14, gen_loss = 0.4008030733641456, disc_loss = 0.07682441386292461
Trained batch 119 in epoch 14, gen_loss = 0.40080464258790016, disc_loss = 0.07667919774539769
Trained batch 120 in epoch 14, gen_loss = 0.4006592877640212, disc_loss = 0.07619428332925827
Trained batch 121 in epoch 14, gen_loss = 0.4011542909458035, disc_loss = 0.07598329091169795
Trained batch 122 in epoch 14, gen_loss = 0.40053487575151087, disc_loss = 0.07604559953135204
Trained batch 123 in epoch 14, gen_loss = 0.40112366719592, disc_loss = 0.07681555337002201
Trained batch 124 in epoch 14, gen_loss = 0.40120570349693296, disc_loss = 0.07678689306974411
Trained batch 125 in epoch 14, gen_loss = 0.40112026201354134, disc_loss = 0.07641799251238506
Trained batch 126 in epoch 14, gen_loss = 0.4020801768528195, disc_loss = 0.07695149554042366
Trained batch 127 in epoch 14, gen_loss = 0.4020064049400389, disc_loss = 0.07661189627833664
Trained batch 128 in epoch 14, gen_loss = 0.40130042844964553, disc_loss = 0.07639545138723167
Trained batch 129 in epoch 14, gen_loss = 0.40124466923566965, disc_loss = 0.07604137687728955
Trained batch 130 in epoch 14, gen_loss = 0.4008289702976023, disc_loss = 0.07599311572222309
Trained batch 131 in epoch 14, gen_loss = 0.4002861418958866, disc_loss = 0.07566332170796214
Trained batch 132 in epoch 14, gen_loss = 0.3995813648951681, disc_loss = 0.0761497292695637
Trained batch 133 in epoch 14, gen_loss = 0.39943386703284817, disc_loss = 0.07649442567420539
Trained batch 134 in epoch 14, gen_loss = 0.3996437425966616, disc_loss = 0.0760051616984937
Trained batch 135 in epoch 14, gen_loss = 0.3991265270639868, disc_loss = 0.07556111578528277
Trained batch 136 in epoch 14, gen_loss = 0.3989742846384536, disc_loss = 0.07521772480495002
Trained batch 137 in epoch 14, gen_loss = 0.39937701778135437, disc_loss = 0.07492543252832863
Trained batch 138 in epoch 14, gen_loss = 0.39897295618228773, disc_loss = 0.07456375803905639
Trained batch 139 in epoch 14, gen_loss = 0.39883171021938324, disc_loss = 0.07440332480972367
Trained batch 140 in epoch 14, gen_loss = 0.39827159195081563, disc_loss = 0.07486184615747514
Trained batch 141 in epoch 14, gen_loss = 0.39814456415847993, disc_loss = 0.07458926761575357
Trained batch 142 in epoch 14, gen_loss = 0.3986343941488466, disc_loss = 0.07454956659617332
Trained batch 143 in epoch 14, gen_loss = 0.39857446485095555, disc_loss = 0.07438990280368468
Trained batch 144 in epoch 14, gen_loss = 0.39783593642300574, disc_loss = 0.07422802525989969
Trained batch 145 in epoch 14, gen_loss = 0.3980958778155993, disc_loss = 0.07378518101057574
Trained batch 146 in epoch 14, gen_loss = 0.3985327634276176, disc_loss = 0.07349140804615759
Trained batch 147 in epoch 14, gen_loss = 0.39822268244382497, disc_loss = 0.07311829253150201
Trained batch 148 in epoch 14, gen_loss = 0.3981210769422902, disc_loss = 0.07302463590323725
Trained batch 149 in epoch 14, gen_loss = 0.3977517453829447, disc_loss = 0.0737017645003895
Trained batch 150 in epoch 14, gen_loss = 0.39844503347447374, disc_loss = 0.07429280290565152
Trained batch 151 in epoch 14, gen_loss = 0.3983758668366231, disc_loss = 0.07387846055146503
Trained batch 152 in epoch 14, gen_loss = 0.3982464291301428, disc_loss = 0.07361001785528036
Trained batch 153 in epoch 14, gen_loss = 0.39819652519442816, disc_loss = 0.0732580442949162
Trained batch 154 in epoch 14, gen_loss = 0.39748990343463037, disc_loss = 0.07318498725371976
Trained batch 155 in epoch 14, gen_loss = 0.3978829192809569, disc_loss = 0.07294097640671027
Trained batch 156 in epoch 14, gen_loss = 0.39772494678284714, disc_loss = 0.07321307772568836
Trained batch 157 in epoch 14, gen_loss = 0.3977699930532069, disc_loss = 0.07468077943577797
Trained batch 158 in epoch 14, gen_loss = 0.3979577693924214, disc_loss = 0.074400806612095
Trained batch 159 in epoch 14, gen_loss = 0.3981102131307125, disc_loss = 0.0741668674047105
Trained batch 160 in epoch 14, gen_loss = 0.39775645029470785, disc_loss = 0.07391154008298557
Trained batch 161 in epoch 14, gen_loss = 0.39770138999562205, disc_loss = 0.07353081361586113
Trained batch 162 in epoch 14, gen_loss = 0.39819896038324554, disc_loss = 0.07322472671583935
Trained batch 163 in epoch 14, gen_loss = 0.397883027428534, disc_loss = 0.0730436501922313
Trained batch 164 in epoch 14, gen_loss = 0.39751667253898854, disc_loss = 0.07281850532939037
Trained batch 165 in epoch 14, gen_loss = 0.39831510042569723, disc_loss = 0.07257448647911828
Trained batch 166 in epoch 14, gen_loss = 0.39791873846939224, disc_loss = 0.07246467495102904
Trained batch 167 in epoch 14, gen_loss = 0.3981401735828036, disc_loss = 0.07241235275952411
Trained batch 168 in epoch 14, gen_loss = 0.39842786097667626, disc_loss = 0.07209251001587458
Trained batch 169 in epoch 14, gen_loss = 0.3980625876609017, disc_loss = 0.07184444331180523
Trained batch 170 in epoch 14, gen_loss = 0.3983085293170304, disc_loss = 0.07150439649537119
Trained batch 171 in epoch 14, gen_loss = 0.39860426582569297, disc_loss = 0.07147809561493612
Trained batch 172 in epoch 14, gen_loss = 0.3985034757955915, disc_loss = 0.07195899934330255
Trained batch 173 in epoch 14, gen_loss = 0.3987415301046152, disc_loss = 0.0717108919199599
Trained batch 174 in epoch 14, gen_loss = 0.3987539722238268, disc_loss = 0.07135414910635778
Trained batch 175 in epoch 14, gen_loss = 0.39911534247750585, disc_loss = 0.0710116042649712
Trained batch 176 in epoch 14, gen_loss = 0.39930272035006076, disc_loss = 0.07066182953721217
Trained batch 177 in epoch 14, gen_loss = 0.3993124647086926, disc_loss = 0.07044441053601966
Trained batch 178 in epoch 14, gen_loss = 0.3991446341882205, disc_loss = 0.07036509718121596
Trained batch 179 in epoch 14, gen_loss = 0.39906156410773597, disc_loss = 0.07011418433135583
Trained batch 180 in epoch 14, gen_loss = 0.3991556468918837, disc_loss = 0.06996633741716489
Trained batch 181 in epoch 14, gen_loss = 0.39908837731722946, disc_loss = 0.06971317308105446
Trained batch 182 in epoch 14, gen_loss = 0.3992219920692548, disc_loss = 0.06954112762452963
Trained batch 183 in epoch 14, gen_loss = 0.3990212695106216, disc_loss = 0.06961707980878165
Trained batch 184 in epoch 14, gen_loss = 0.39934716949591764, disc_loss = 0.07108949293457978
Trained batch 185 in epoch 14, gen_loss = 0.3993748538596656, disc_loss = 0.07086204300304094
Trained batch 186 in epoch 14, gen_loss = 0.3993648225292165, disc_loss = 0.0705702679709875
Trained batch 187 in epoch 14, gen_loss = 0.39955901941086386, disc_loss = 0.07041417481873105
Trained batch 188 in epoch 14, gen_loss = 0.3995018905748135, disc_loss = 0.07026193716203567
Trained batch 189 in epoch 14, gen_loss = 0.39933830876099435, disc_loss = 0.0700019591684012
Trained batch 190 in epoch 14, gen_loss = 0.39919370943339083, disc_loss = 0.06986405848189019
Trained batch 191 in epoch 14, gen_loss = 0.3993557523936033, disc_loss = 0.06982313930348027
Trained batch 192 in epoch 14, gen_loss = 0.3992192391595692, disc_loss = 0.06967632417986894
Trained batch 193 in epoch 14, gen_loss = 0.39914126878546685, disc_loss = 0.06964972883597323
Trained batch 194 in epoch 14, gen_loss = 0.3992994630948091, disc_loss = 0.06938481401078976
Trained batch 195 in epoch 14, gen_loss = 0.3996329956821033, disc_loss = 0.06984996569000793
Trained batch 196 in epoch 14, gen_loss = 0.39900742085452007, disc_loss = 0.07071651897965198
Trained batch 197 in epoch 14, gen_loss = 0.39889411282057713, disc_loss = 0.07088886695735232
Trained batch 198 in epoch 14, gen_loss = 0.3991684378990576, disc_loss = 0.07105361252330505
Trained batch 199 in epoch 14, gen_loss = 0.3991940413415432, disc_loss = 0.07093942874576896
Trained batch 200 in epoch 14, gen_loss = 0.39851722328817074, disc_loss = 0.07095262750668165
Trained batch 201 in epoch 14, gen_loss = 0.3984838918884202, disc_loss = 0.0708123589128182
Trained batch 202 in epoch 14, gen_loss = 0.39821712988350777, disc_loss = 0.07068921120497834
Trained batch 203 in epoch 14, gen_loss = 0.398316370213733, disc_loss = 0.07050490607142303
Trained batch 204 in epoch 14, gen_loss = 0.3984133758196017, disc_loss = 0.07075303678014656
Trained batch 205 in epoch 14, gen_loss = 0.3982861055043137, disc_loss = 0.07091656733684025
Trained batch 206 in epoch 14, gen_loss = 0.39841388173149406, disc_loss = 0.07076185277172765
Trained batch 207 in epoch 14, gen_loss = 0.3986614919625796, disc_loss = 0.07063246723891307
Trained batch 208 in epoch 14, gen_loss = 0.39868053665571807, disc_loss = 0.07065390515181294
Trained batch 209 in epoch 14, gen_loss = 0.39866712575867064, disc_loss = 0.0709042997720341
Trained batch 210 in epoch 14, gen_loss = 0.39834793738279295, disc_loss = 0.07190044614005286
Trained batch 211 in epoch 14, gen_loss = 0.39878343523673293, disc_loss = 0.07180895951119656
Trained batch 212 in epoch 14, gen_loss = 0.3986140442006465, disc_loss = 0.07165420191371245
Trained batch 213 in epoch 14, gen_loss = 0.3984320272352094, disc_loss = 0.07145825703410763
Trained batch 214 in epoch 14, gen_loss = 0.39798491638760236, disc_loss = 0.07141741822192142
Trained batch 215 in epoch 14, gen_loss = 0.39847819645095756, disc_loss = 0.07152271277219471
Trained batch 216 in epoch 14, gen_loss = 0.3986893546196722, disc_loss = 0.07125093849281425
Trained batch 217 in epoch 14, gen_loss = 0.3982386405861706, disc_loss = 0.07105288977111014
Trained batch 218 in epoch 14, gen_loss = 0.3979557311698182, disc_loss = 0.07119526878662713
Trained batch 219 in epoch 14, gen_loss = 0.39835640977729453, disc_loss = 0.07173946727998555
Trained batch 220 in epoch 14, gen_loss = 0.39831112871342655, disc_loss = 0.07152250825060844
Trained batch 221 in epoch 14, gen_loss = 0.39835245759637505, disc_loss = 0.07150504108400899
Trained batch 222 in epoch 14, gen_loss = 0.39840325138494037, disc_loss = 0.0714111562459124
Trained batch 223 in epoch 14, gen_loss = 0.39805763667183264, disc_loss = 0.0713038919950902
Trained batch 224 in epoch 14, gen_loss = 0.39803663439220854, disc_loss = 0.07106812888135512
Trained batch 225 in epoch 14, gen_loss = 0.39808401386294745, disc_loss = 0.07104367687391629
Trained batch 226 in epoch 14, gen_loss = 0.3983988018813112, disc_loss = 0.07128106212317287
Trained batch 227 in epoch 14, gen_loss = 0.398466189440928, disc_loss = 0.0710174156671488
Trained batch 228 in epoch 14, gen_loss = 0.3986635459302294, disc_loss = 0.07100388622033414
Trained batch 229 in epoch 14, gen_loss = 0.39862857992234435, disc_loss = 0.07073668535879772
Trained batch 230 in epoch 14, gen_loss = 0.39861981319142625, disc_loss = 0.07051088688774156
Trained batch 231 in epoch 14, gen_loss = 0.3988922519673561, disc_loss = 0.0702526591806512
Trained batch 232 in epoch 14, gen_loss = 0.39887355312768996, disc_loss = 0.07008079741182117
Trained batch 233 in epoch 14, gen_loss = 0.3986404870565121, disc_loss = 0.07015698480730255
Trained batch 234 in epoch 14, gen_loss = 0.39825115140448225, disc_loss = 0.07083732467937343
Trained batch 235 in epoch 14, gen_loss = 0.39842736253799016, disc_loss = 0.07173574420276209
Trained batch 236 in epoch 14, gen_loss = 0.39865183440441826, disc_loss = 0.071477504175958
Trained batch 237 in epoch 14, gen_loss = 0.3982422658625771, disc_loss = 0.07148040285208772
Trained batch 238 in epoch 14, gen_loss = 0.39820408908393096, disc_loss = 0.07128837335636551
Trained batch 239 in epoch 14, gen_loss = 0.3983919865141312, disc_loss = 0.0712214502855204
Trained batch 240 in epoch 14, gen_loss = 0.39840398747396666, disc_loss = 0.07112424923068383
Trained batch 241 in epoch 14, gen_loss = 0.39866346908994943, disc_loss = 0.07088401240935503
Trained batch 242 in epoch 14, gen_loss = 0.3987554049295653, disc_loss = 0.07067441941840659
Trained batch 243 in epoch 14, gen_loss = 0.3986816299987621, disc_loss = 0.07047625951713225
Trained batch 244 in epoch 14, gen_loss = 0.39891808191124273, disc_loss = 0.07029420552509172
Trained batch 245 in epoch 14, gen_loss = 0.39866442990496875, disc_loss = 0.07011489676145034
Trained batch 246 in epoch 14, gen_loss = 0.39886794568073414, disc_loss = 0.06993660731957509
Trained batch 247 in epoch 14, gen_loss = 0.39910190937019163, disc_loss = 0.06971173154400481
Trained batch 248 in epoch 14, gen_loss = 0.39908230400468453, disc_loss = 0.07017878826752484
Trained batch 249 in epoch 14, gen_loss = 0.3985756733417511, disc_loss = 0.07142155388742685
Trained batch 250 in epoch 14, gen_loss = 0.39852448193675494, disc_loss = 0.07165729124618479
Trained batch 251 in epoch 14, gen_loss = 0.39868315072759747, disc_loss = 0.07178022657033234
Trained batch 252 in epoch 14, gen_loss = 0.3985055065437739, disc_loss = 0.07201159039416567
Trained batch 253 in epoch 14, gen_loss = 0.39842266700868534, disc_loss = 0.07216066817980347
Trained batch 254 in epoch 14, gen_loss = 0.3981314047878864, disc_loss = 0.07208824707743
Trained batch 255 in epoch 14, gen_loss = 0.39834846113808453, disc_loss = 0.07198543490812881
Trained batch 256 in epoch 14, gen_loss = 0.3977300878396758, disc_loss = 0.0722778559470339
Trained batch 257 in epoch 14, gen_loss = 0.3976858927066936, disc_loss = 0.07232711024495751
Trained batch 258 in epoch 14, gen_loss = 0.39768178110877517, disc_loss = 0.07237113974125459
Trained batch 259 in epoch 14, gen_loss = 0.3976273290239848, disc_loss = 0.07233833483635232
Trained batch 260 in epoch 14, gen_loss = 0.3976025424926217, disc_loss = 0.07211919506776264
Trained batch 261 in epoch 14, gen_loss = 0.39757267709906774, disc_loss = 0.07201542811581993
Trained batch 262 in epoch 14, gen_loss = 0.3978512477512142, disc_loss = 0.07189635592140965
Trained batch 263 in epoch 14, gen_loss = 0.3980882220873327, disc_loss = 0.07218420093131224
Trained batch 264 in epoch 14, gen_loss = 0.39790402380925305, disc_loss = 0.0724194952304352
Trained batch 265 in epoch 14, gen_loss = 0.39835658019646664, disc_loss = 0.07241021838613358
Trained batch 266 in epoch 14, gen_loss = 0.39823240052894704, disc_loss = 0.07228060928609376
Trained batch 267 in epoch 14, gen_loss = 0.39796981793731007, disc_loss = 0.07224194984535562
Trained batch 268 in epoch 14, gen_loss = 0.3976569448261899, disc_loss = 0.07232360121859827
Trained batch 269 in epoch 14, gen_loss = 0.39770224270997223, disc_loss = 0.07219735345009852
Trained batch 270 in epoch 14, gen_loss = 0.3976204442582007, disc_loss = 0.07215634856812958
Trained batch 271 in epoch 14, gen_loss = 0.3973630297490779, disc_loss = 0.0725550411563531
Trained batch 272 in epoch 14, gen_loss = 0.3976474127053341, disc_loss = 0.07239639633181659
Trained batch 273 in epoch 14, gen_loss = 0.39769801421322093, disc_loss = 0.07255016460022243
Trained batch 274 in epoch 14, gen_loss = 0.39751937541094695, disc_loss = 0.07251469836654988
Trained batch 275 in epoch 14, gen_loss = 0.39734292386666586, disc_loss = 0.07244106924390771
Trained batch 276 in epoch 14, gen_loss = 0.3974624028705087, disc_loss = 0.07242987874814642
Trained batch 277 in epoch 14, gen_loss = 0.39761607992134507, disc_loss = 0.07223126537789651
Trained batch 278 in epoch 14, gen_loss = 0.39745033011641556, disc_loss = 0.0721752840030845
Trained batch 279 in epoch 14, gen_loss = 0.3974979036620685, disc_loss = 0.07198272122934993
Trained batch 280 in epoch 14, gen_loss = 0.39781506513361403, disc_loss = 0.07203379808013656
Trained batch 281 in epoch 14, gen_loss = 0.39802044482095866, disc_loss = 0.07211429212599042
Trained batch 282 in epoch 14, gen_loss = 0.3983454289368943, disc_loss = 0.07218666750174213
Trained batch 283 in epoch 14, gen_loss = 0.3985325568158862, disc_loss = 0.07209507487779877
Trained batch 284 in epoch 14, gen_loss = 0.3984938142592447, disc_loss = 0.07193669964673749
Trained batch 285 in epoch 14, gen_loss = 0.3984578485255475, disc_loss = 0.07182859726106891
Trained batch 286 in epoch 14, gen_loss = 0.39875872054166495, disc_loss = 0.07161504121412902
Trained batch 287 in epoch 14, gen_loss = 0.39862732703073156, disc_loss = 0.07153161449888204
Trained batch 288 in epoch 14, gen_loss = 0.39869145538567674, disc_loss = 0.07142737452714192
Trained batch 289 in epoch 14, gen_loss = 0.39855667517103, disc_loss = 0.07130142626641639
Trained batch 290 in epoch 14, gen_loss = 0.39848197428221555, disc_loss = 0.07122186299003788
Trained batch 291 in epoch 14, gen_loss = 0.3985771493960733, disc_loss = 0.07106004776879635
Trained batch 292 in epoch 14, gen_loss = 0.39838443833813325, disc_loss = 0.07116637314405966
Trained batch 293 in epoch 14, gen_loss = 0.3985373950531694, disc_loss = 0.07148603495958002
Trained batch 294 in epoch 14, gen_loss = 0.3986198516215308, disc_loss = 0.07141610413347765
Trained batch 295 in epoch 14, gen_loss = 0.3981229099067482, disc_loss = 0.07144670288166585
Trained batch 296 in epoch 14, gen_loss = 0.3983534068772287, disc_loss = 0.07134609331097767
Trained batch 297 in epoch 14, gen_loss = 0.39844494588023066, disc_loss = 0.07117369511921033
Trained batch 298 in epoch 14, gen_loss = 0.3986218903575055, disc_loss = 0.0709703695870014
Trained batch 299 in epoch 14, gen_loss = 0.3984957626461983, disc_loss = 0.07103997410895924
Trained batch 300 in epoch 14, gen_loss = 0.39877438634336987, disc_loss = 0.07190881745326658
Trained batch 301 in epoch 14, gen_loss = 0.39862216140655493, disc_loss = 0.07172137259548864
Trained batch 302 in epoch 14, gen_loss = 0.3986781083121158, disc_loss = 0.07187869645679744
Trained batch 303 in epoch 14, gen_loss = 0.3987385608059795, disc_loss = 0.07167758920389276
Trained batch 304 in epoch 14, gen_loss = 0.3988216624885309, disc_loss = 0.07156533111863937
Trained batch 305 in epoch 14, gen_loss = 0.3986322392825208, disc_loss = 0.07143815162780336
Trained batch 306 in epoch 14, gen_loss = 0.3985286793801994, disc_loss = 0.07137973519521447
Trained batch 307 in epoch 14, gen_loss = 0.3982562707229094, disc_loss = 0.07126449386274757
Trained batch 308 in epoch 14, gen_loss = 0.398273783980064, disc_loss = 0.07110280528194407
Trained batch 309 in epoch 14, gen_loss = 0.3985008030168472, disc_loss = 0.07104309030898637
Trained batch 310 in epoch 14, gen_loss = 0.39826783854095116, disc_loss = 0.07144563501682791
Trained batch 311 in epoch 14, gen_loss = 0.3984337938137544, disc_loss = 0.07148393193701616
Trained batch 312 in epoch 14, gen_loss = 0.39849636920343956, disc_loss = 0.0713270160521324
Trained batch 313 in epoch 14, gen_loss = 0.39855562103022435, disc_loss = 0.07127716388422878
Trained batch 314 in epoch 14, gen_loss = 0.39871441494850884, disc_loss = 0.07110691715977968
Trained batch 315 in epoch 14, gen_loss = 0.3985828952510146, disc_loss = 0.07108888817255539
Trained batch 316 in epoch 14, gen_loss = 0.3985099882733559, disc_loss = 0.07103873716156095
Trained batch 317 in epoch 14, gen_loss = 0.3986457594723072, disc_loss = 0.07091878941165483
Trained batch 318 in epoch 14, gen_loss = 0.39878218721446573, disc_loss = 0.07073456897082094
Trained batch 319 in epoch 14, gen_loss = 0.3986746002919972, disc_loss = 0.07085621387523133
Trained batch 320 in epoch 14, gen_loss = 0.3989300306340987, disc_loss = 0.07077081094429222
Trained batch 321 in epoch 14, gen_loss = 0.39892469244714107, disc_loss = 0.07078364277721284
Trained batch 322 in epoch 14, gen_loss = 0.3987107976302274, disc_loss = 0.07098862135800138
Trained batch 323 in epoch 14, gen_loss = 0.39877716212728875, disc_loss = 0.07079797661805778
Trained batch 324 in epoch 14, gen_loss = 0.39878044898693377, disc_loss = 0.07061988496436522
Trained batch 325 in epoch 14, gen_loss = 0.3990743986668031, disc_loss = 0.07042821830972755
Trained batch 326 in epoch 14, gen_loss = 0.39897866515209185, disc_loss = 0.07035889286855491
Trained batch 327 in epoch 14, gen_loss = 0.3988021233278077, disc_loss = 0.07042651382138634
Trained batch 328 in epoch 14, gen_loss = 0.39873630596511633, disc_loss = 0.07026660196075504
Trained batch 329 in epoch 14, gen_loss = 0.3988512280312451, disc_loss = 0.07013228548069796
Trained batch 330 in epoch 14, gen_loss = 0.39885014808790203, disc_loss = 0.07004478628946935
Trained batch 331 in epoch 14, gen_loss = 0.398564533655902, disc_loss = 0.07024494631507669
Trained batch 332 in epoch 14, gen_loss = 0.3987010116870697, disc_loss = 0.07043434823821257
Trained batch 333 in epoch 14, gen_loss = 0.39879352880452207, disc_loss = 0.07029214120486718
Trained batch 334 in epoch 14, gen_loss = 0.39859130293575684, disc_loss = 0.07030063111946654
Trained batch 335 in epoch 14, gen_loss = 0.39871332865385783, disc_loss = 0.07025516258796588
Trained batch 336 in epoch 14, gen_loss = 0.3987213157404778, disc_loss = 0.07011116233596286
Trained batch 337 in epoch 14, gen_loss = 0.39898760026023233, disc_loss = 0.0699553482465931
Trained batch 338 in epoch 14, gen_loss = 0.3988997518664616, disc_loss = 0.06984702944425883
Trained batch 339 in epoch 14, gen_loss = 0.39878528056775825, disc_loss = 0.06980522211969775
Trained batch 340 in epoch 14, gen_loss = 0.39873997443232717, disc_loss = 0.06983704920148046
Trained batch 341 in epoch 14, gen_loss = 0.398859722136754, disc_loss = 0.06970280760692225
Trained batch 342 in epoch 14, gen_loss = 0.3987584826550053, disc_loss = 0.06957171137279046
Trained batch 343 in epoch 14, gen_loss = 0.3987914063902788, disc_loss = 0.0694448949693334
Trained batch 344 in epoch 14, gen_loss = 0.39907211635423745, disc_loss = 0.06952513841291269
Trained batch 345 in epoch 14, gen_loss = 0.3992130684025715, disc_loss = 0.06950023371424806
Trained batch 346 in epoch 14, gen_loss = 0.39923774002264834, disc_loss = 0.06942132543181995
Trained batch 347 in epoch 14, gen_loss = 0.39939822290820637, disc_loss = 0.06968130045516908
Trained batch 348 in epoch 14, gen_loss = 0.3996636063970604, disc_loss = 0.06953870247846689
Trained batch 349 in epoch 14, gen_loss = 0.39958490882601055, disc_loss = 0.06947786057634013
Trained batch 350 in epoch 14, gen_loss = 0.399428524437793, disc_loss = 0.06956607027992903
Trained batch 351 in epoch 14, gen_loss = 0.39958863392133603, disc_loss = 0.0696708938128061
Trained batch 352 in epoch 14, gen_loss = 0.3994489540965969, disc_loss = 0.06975988711285862
Trained batch 353 in epoch 14, gen_loss = 0.3995953438814077, disc_loss = 0.06968171162120367
Trained batch 354 in epoch 14, gen_loss = 0.39971694988264167, disc_loss = 0.06959599890339542
Trained batch 355 in epoch 14, gen_loss = 0.39970578772298404, disc_loss = 0.06946163423087322
Trained batch 356 in epoch 14, gen_loss = 0.39991543949151237, disc_loss = 0.0694014330652832
Trained batch 357 in epoch 14, gen_loss = 0.3996923669090484, disc_loss = 0.06955830286147707
Trained batch 358 in epoch 14, gen_loss = 0.3997744853118004, disc_loss = 0.0699219988778358
Trained batch 359 in epoch 14, gen_loss = 0.39967290071977507, disc_loss = 0.06999717468085388
Trained batch 360 in epoch 14, gen_loss = 0.3997523448638969, disc_loss = 0.06984988280631334
Trained batch 361 in epoch 14, gen_loss = 0.3997987973920548, disc_loss = 0.06993749026126789
Trained batch 362 in epoch 14, gen_loss = 0.399796308975246, disc_loss = 0.07003655242053766
Trained batch 363 in epoch 14, gen_loss = 0.3998352242531357, disc_loss = 0.06993330019822978
Trained batch 364 in epoch 14, gen_loss = 0.3997634674588295, disc_loss = 0.06977728488918854
Trained batch 365 in epoch 14, gen_loss = 0.39995557794479725, disc_loss = 0.06962654888222777
Trained batch 366 in epoch 14, gen_loss = 0.40015595233732737, disc_loss = 0.06948508795766967
Trained batch 367 in epoch 14, gen_loss = 0.39995140979147475, disc_loss = 0.06934888383029433
Trained batch 368 in epoch 14, gen_loss = 0.4000697574479793, disc_loss = 0.06939069427509456
Trained batch 369 in epoch 14, gen_loss = 0.40016005393621085, disc_loss = 0.06966354788054485
Trained batch 370 in epoch 14, gen_loss = 0.3998649550898056, disc_loss = 0.07017098031335603
Trained batch 371 in epoch 14, gen_loss = 0.39996118675316533, disc_loss = 0.07033166266797532
Trained batch 372 in epoch 14, gen_loss = 0.39987721655707575, disc_loss = 0.07036790576820878
Trained batch 373 in epoch 14, gen_loss = 0.4000180172410241, disc_loss = 0.07026606993899148
Trained batch 374 in epoch 14, gen_loss = 0.40006495889027915, disc_loss = 0.0701617019524177
Trained batch 375 in epoch 14, gen_loss = 0.39990795379940497, disc_loss = 0.07012225972349814
Trained batch 376 in epoch 14, gen_loss = 0.39989935956519856, disc_loss = 0.07008265731090418
Trained batch 377 in epoch 14, gen_loss = 0.3998658609768701, disc_loss = 0.06998098432209598
Trained batch 378 in epoch 14, gen_loss = 0.39982678841475133, disc_loss = 0.07003064563198108
Trained batch 379 in epoch 14, gen_loss = 0.39964974993153624, disc_loss = 0.07058727650560047
Trained batch 380 in epoch 14, gen_loss = 0.39965137972293563, disc_loss = 0.07050145014123184
Trained batch 381 in epoch 14, gen_loss = 0.3998603148298114, disc_loss = 0.07056088932346143
Trained batch 382 in epoch 14, gen_loss = 0.39983316851346984, disc_loss = 0.07055628867260626
Trained batch 383 in epoch 14, gen_loss = 0.39976211241446435, disc_loss = 0.07051448750523075
Trained batch 384 in epoch 14, gen_loss = 0.399951958037042, disc_loss = 0.07039217072744648
Trained batch 385 in epoch 14, gen_loss = 0.39987776802920305, disc_loss = 0.07046610362576852
Trained batch 386 in epoch 14, gen_loss = 0.40004121348531363, disc_loss = 0.07049374167328504
Trained batch 387 in epoch 14, gen_loss = 0.4000347394918658, disc_loss = 0.07036865175192811
Trained batch 388 in epoch 14, gen_loss = 0.40000447577253406, disc_loss = 0.07021381667693047
Trained batch 389 in epoch 14, gen_loss = 0.40000312267205657, disc_loss = 0.07014206804526157
Trained batch 390 in epoch 14, gen_loss = 0.39995456572688753, disc_loss = 0.070096811598829
Trained batch 391 in epoch 14, gen_loss = 0.4002048792127444, disc_loss = 0.06998027290920822
Trained batch 392 in epoch 14, gen_loss = 0.4004630515441943, disc_loss = 0.06983199488826608
Trained batch 393 in epoch 14, gen_loss = 0.4006077943719583, disc_loss = 0.06967635420127417
Trained batch 394 in epoch 14, gen_loss = 0.40046265321441843, disc_loss = 0.06961687365193156
Trained batch 395 in epoch 14, gen_loss = 0.4003468664607616, disc_loss = 0.069489888823356
Trained batch 396 in epoch 14, gen_loss = 0.40049452948330033, disc_loss = 0.06934520129996448
Trained batch 397 in epoch 14, gen_loss = 0.4005019770345496, disc_loss = 0.06918858441561648
Trained batch 398 in epoch 14, gen_loss = 0.40067879934059947, disc_loss = 0.06905911497440292
Trained batch 399 in epoch 14, gen_loss = 0.40086878068745135, disc_loss = 0.06893002260592766
Trained batch 400 in epoch 14, gen_loss = 0.40092812341050316, disc_loss = 0.0688614640442975
Trained batch 401 in epoch 14, gen_loss = 0.40080334846653154, disc_loss = 0.06882174943332833
Trained batch 402 in epoch 14, gen_loss = 0.40068214310901634, disc_loss = 0.068731890423986
Trained batch 403 in epoch 14, gen_loss = 0.4007700708242926, disc_loss = 0.068582217657413
Trained batch 404 in epoch 14, gen_loss = 0.4008189300696055, disc_loss = 0.06852538011347255
Trained batch 405 in epoch 14, gen_loss = 0.4009428987362115, disc_loss = 0.06839753138337266
Trained batch 406 in epoch 14, gen_loss = 0.40099409508177924, disc_loss = 0.06825537244498693
Trained batch 407 in epoch 14, gen_loss = 0.4010397350671245, disc_loss = 0.0681231648412387
Trained batch 408 in epoch 14, gen_loss = 0.401086693142329, disc_loss = 0.06803635892988819
Trained batch 409 in epoch 14, gen_loss = 0.40125397836289756, disc_loss = 0.06839478696333018
Trained batch 410 in epoch 14, gen_loss = 0.40092947216219565, disc_loss = 0.06896017565122305
Trained batch 411 in epoch 14, gen_loss = 0.40096811646396674, disc_loss = 0.06894042535382097
Trained batch 412 in epoch 14, gen_loss = 0.4008087955288968, disc_loss = 0.06883918737866364
Trained batch 413 in epoch 14, gen_loss = 0.40110453509766125, disc_loss = 0.0687632981883497
Trained batch 414 in epoch 14, gen_loss = 0.40113621842430297, disc_loss = 0.06868096123595374
Trained batch 415 in epoch 14, gen_loss = 0.4012521177243728, disc_loss = 0.06860832007973491
Trained batch 416 in epoch 14, gen_loss = 0.4016128944264327, disc_loss = 0.06847732798118207
Trained batch 417 in epoch 14, gen_loss = 0.40165469585138075, disc_loss = 0.06849993226947218
Trained batch 418 in epoch 14, gen_loss = 0.401480666208381, disc_loss = 0.06875651366986459
Trained batch 419 in epoch 14, gen_loss = 0.4016893386131241, disc_loss = 0.06907905304604875
Trained batch 420 in epoch 14, gen_loss = 0.40184608271739264, disc_loss = 0.06910453761447743
Trained batch 421 in epoch 14, gen_loss = 0.40185639989602057, disc_loss = 0.06905980019662442
Trained batch 422 in epoch 14, gen_loss = 0.40174445707183637, disc_loss = 0.06894519437108867
Trained batch 423 in epoch 14, gen_loss = 0.4017690233886242, disc_loss = 0.06880857023072236
Trained batch 424 in epoch 14, gen_loss = 0.4017358570239123, disc_loss = 0.06874868142144645
Trained batch 425 in epoch 14, gen_loss = 0.40180661176012156, disc_loss = 0.06897023052497474
Trained batch 426 in epoch 14, gen_loss = 0.40195785654791627, disc_loss = 0.06925053669322954
Trained batch 427 in epoch 14, gen_loss = 0.40203470061315555, disc_loss = 0.06924889248765344
Trained batch 428 in epoch 14, gen_loss = 0.40216310179872666, disc_loss = 0.06912038662299375
Trained batch 429 in epoch 14, gen_loss = 0.4023625033539395, disc_loss = 0.06900713727376316
Trained batch 430 in epoch 14, gen_loss = 0.4023776081349623, disc_loss = 0.06895055934212013
Trained batch 431 in epoch 14, gen_loss = 0.40252483001461736, disc_loss = 0.06899805978712349
Trained batch 432 in epoch 14, gen_loss = 0.4022883581509491, disc_loss = 0.06904631093742356
Trained batch 433 in epoch 14, gen_loss = 0.40225870509026784, disc_loss = 0.06902067002213735
Trained batch 434 in epoch 14, gen_loss = 0.4023330830979621, disc_loss = 0.06919443373857387
Trained batch 435 in epoch 14, gen_loss = 0.4021206833763954, disc_loss = 0.06921336054267925
Trained batch 436 in epoch 14, gen_loss = 0.4022753638997503, disc_loss = 0.06910190094385969
Trained batch 437 in epoch 14, gen_loss = 0.4021082549742912, disc_loss = 0.0690066740246379
Trained batch 438 in epoch 14, gen_loss = 0.4020609328171115, disc_loss = 0.06887359208701038
Trained batch 439 in epoch 14, gen_loss = 0.4019670592112975, disc_loss = 0.06891947115284645
Trained batch 440 in epoch 14, gen_loss = 0.4020938063695047, disc_loss = 0.06900643353834073
Trained batch 441 in epoch 14, gen_loss = 0.4018824490217062, disc_loss = 0.06889932003500134
Trained batch 442 in epoch 14, gen_loss = 0.4019093910404576, disc_loss = 0.06878315807166709
Trained batch 443 in epoch 14, gen_loss = 0.40178725217376743, disc_loss = 0.06874566136855162
Trained batch 444 in epoch 14, gen_loss = 0.4020039701729678, disc_loss = 0.06881635481324257
Trained batch 445 in epoch 14, gen_loss = 0.4018042070849594, disc_loss = 0.06883174653014694
Trained batch 446 in epoch 14, gen_loss = 0.4018007210170396, disc_loss = 0.06873191837783928
Trained batch 447 in epoch 14, gen_loss = 0.4018385535372155, disc_loss = 0.06862535814226638
Trained batch 448 in epoch 14, gen_loss = 0.40180701807240865, disc_loss = 0.06852077464272324
Trained batch 449 in epoch 14, gen_loss = 0.4020681987206141, disc_loss = 0.06855022127947046
Trained batch 450 in epoch 14, gen_loss = 0.4019803425293011, disc_loss = 0.0685939953906127
Trained batch 451 in epoch 14, gen_loss = 0.4021087707539575, disc_loss = 0.06850328774137868
Trained batch 452 in epoch 14, gen_loss = 0.40226933656149355, disc_loss = 0.06840970519021417
Trained batch 453 in epoch 14, gen_loss = 0.40242487717304987, disc_loss = 0.06829783411200122
Trained batch 454 in epoch 14, gen_loss = 0.40252140452573587, disc_loss = 0.06818888959996812
Trained batch 455 in epoch 14, gen_loss = 0.40256352199797046, disc_loss = 0.06824686183500218
Trained batch 456 in epoch 14, gen_loss = 0.40256925823912837, disc_loss = 0.06830897260176047
Trained batch 457 in epoch 14, gen_loss = 0.40265661347901455, disc_loss = 0.06870450149086918
Trained batch 458 in epoch 14, gen_loss = 0.40246442297964574, disc_loss = 0.06917339249783903
Trained batch 459 in epoch 14, gen_loss = 0.4022749846396239, disc_loss = 0.06920776326391521
Trained batch 460 in epoch 14, gen_loss = 0.4022193718499579, disc_loss = 0.06911577948282216
Testing Epoch 14
Training Epoch 15
Trained batch 0 in epoch 15, gen_loss = 0.34503716230392456, disc_loss = 0.07416775822639465
Trained batch 1 in epoch 15, gen_loss = 0.40447039902210236, disc_loss = 0.05118297599256039
Trained batch 2 in epoch 15, gen_loss = 0.3880964517593384, disc_loss = 0.0545514648159345
Trained batch 3 in epoch 15, gen_loss = 0.40022415667772293, disc_loss = 0.09955237619578838
Trained batch 4 in epoch 15, gen_loss = 0.37661526799201966, disc_loss = 0.09019163846969605
Trained batch 5 in epoch 15, gen_loss = 0.37107302248477936, disc_loss = 0.12810894350210825
Trained batch 6 in epoch 15, gen_loss = 0.3880316231931959, disc_loss = 0.16768223473003932
Trained batch 7 in epoch 15, gen_loss = 0.3969331979751587, disc_loss = 0.15509595815092325
Trained batch 8 in epoch 15, gen_loss = 0.3904985619915856, disc_loss = 0.14972350911961663
Trained batch 9 in epoch 15, gen_loss = 0.3978520542383194, disc_loss = 0.13793895281851293
Trained batch 10 in epoch 15, gen_loss = 0.39895471930503845, disc_loss = 0.12822539951990952
Trained batch 11 in epoch 15, gen_loss = 0.4079861914118131, disc_loss = 0.11951908189803362
Trained batch 12 in epoch 15, gen_loss = 0.405483963397833, disc_loss = 0.11097871153973617
Trained batch 13 in epoch 15, gen_loss = 0.40240757167339325, disc_loss = 0.10660537957612957
Trained batch 14 in epoch 15, gen_loss = 0.39898157517115274, disc_loss = 0.10522510396937529
Trained batch 15 in epoch 15, gen_loss = 0.4050976764410734, disc_loss = 0.1075442525325343
Trained batch 16 in epoch 15, gen_loss = 0.401823573252734, disc_loss = 0.10451222463127445
Trained batch 17 in epoch 15, gen_loss = 0.39941170314947766, disc_loss = 0.1000139353175958
Trained batch 18 in epoch 15, gen_loss = 0.3998889844668539, disc_loss = 0.09691867761706051
Trained batch 19 in epoch 15, gen_loss = 0.3991412132978439, disc_loss = 0.09798466768115759
Trained batch 20 in epoch 15, gen_loss = 0.40418554487682523, disc_loss = 0.09709115521538825
Trained batch 21 in epoch 15, gen_loss = 0.4013712541623549, disc_loss = 0.09637129662389105
Trained batch 22 in epoch 15, gen_loss = 0.39934220910072327, disc_loss = 0.1074885189857172
Trained batch 23 in epoch 15, gen_loss = 0.4004030115902424, disc_loss = 0.10497314560537536
Trained batch 24 in epoch 15, gen_loss = 0.40299070835113526, disc_loss = 0.10354469373822212
Trained batch 25 in epoch 15, gen_loss = 0.400838791177823, disc_loss = 0.10250219258551414
Trained batch 26 in epoch 15, gen_loss = 0.39603205190764534, disc_loss = 0.10307531955617445
Trained batch 27 in epoch 15, gen_loss = 0.3960419297218323, disc_loss = 0.10024504702804345
Trained batch 28 in epoch 15, gen_loss = 0.39427206228519307, disc_loss = 0.09792612460923605
Trained batch 29 in epoch 15, gen_loss = 0.3941449443499247, disc_loss = 0.09729163168619076
Trained batch 30 in epoch 15, gen_loss = 0.3946149791440656, disc_loss = 0.0971025679741175
Trained batch 31 in epoch 15, gen_loss = 0.3939538151025772, disc_loss = 0.09761339164106175
Trained batch 32 in epoch 15, gen_loss = 0.39429104599085724, disc_loss = 0.09701098496037902
Trained batch 33 in epoch 15, gen_loss = 0.3916028562714072, disc_loss = 0.09692161700085682
Trained batch 34 in epoch 15, gen_loss = 0.393685325554439, disc_loss = 0.09604402775210993
Trained batch 35 in epoch 15, gen_loss = 0.39585137863953906, disc_loss = 0.09427463982461227
Trained batch 36 in epoch 15, gen_loss = 0.3934157216871107, disc_loss = 0.09576604067272432
Trained batch 37 in epoch 15, gen_loss = 0.3954562654620723, disc_loss = 0.09951884706357592
Trained batch 38 in epoch 15, gen_loss = 0.39588059141085696, disc_loss = 0.09771480201146542
Trained batch 39 in epoch 15, gen_loss = 0.39639862105250356, disc_loss = 0.09711222108453513
Trained batch 40 in epoch 15, gen_loss = 0.3966620397276995, disc_loss = 0.09562252452824174
Trained batch 41 in epoch 15, gen_loss = 0.39641530386039187, disc_loss = 0.09377114590080012
Trained batch 42 in epoch 15, gen_loss = 0.394063146308411, disc_loss = 0.09303488807622777
Trained batch 43 in epoch 15, gen_loss = 0.3936248401349241, disc_loss = 0.09145187002352693
Trained batch 44 in epoch 15, gen_loss = 0.3940621362792121, disc_loss = 0.0923600891398059
Trained batch 45 in epoch 15, gen_loss = 0.39297045702519623, disc_loss = 0.0939258222832628
Trained batch 46 in epoch 15, gen_loss = 0.3955873365097858, disc_loss = 0.09490872911633329
Trained batch 47 in epoch 15, gen_loss = 0.3962890567878882, disc_loss = 0.09347700381961961
Trained batch 48 in epoch 15, gen_loss = 0.3972224526259364, disc_loss = 0.09266150218187547
Trained batch 49 in epoch 15, gen_loss = 0.39779259502887726, disc_loss = 0.09160101838409901
Trained batch 50 in epoch 15, gen_loss = 0.39814263523793686, disc_loss = 0.09024645187252876
Trained batch 51 in epoch 15, gen_loss = 0.39812067265693957, disc_loss = 0.08887595862436753
Trained batch 52 in epoch 15, gen_loss = 0.39695240754001543, disc_loss = 0.08894760224897906
Trained batch 53 in epoch 15, gen_loss = 0.3963845454984241, disc_loss = 0.09315613374389985
Trained batch 54 in epoch 15, gen_loss = 0.3983619370243766, disc_loss = 0.09225955307483673
Trained batch 55 in epoch 15, gen_loss = 0.3989341700715678, disc_loss = 0.09206143167934247
Trained batch 56 in epoch 15, gen_loss = 0.39872050442193685, disc_loss = 0.09062713739184435
Trained batch 57 in epoch 15, gen_loss = 0.3981162119528343, disc_loss = 0.08963061035771308
Trained batch 58 in epoch 15, gen_loss = 0.3976905467146534, disc_loss = 0.08904419986183866
Trained batch 59 in epoch 15, gen_loss = 0.396665221452713, disc_loss = 0.08812037217430771
Trained batch 60 in epoch 15, gen_loss = 0.3973081576042488, disc_loss = 0.08714195837068264
Trained batch 61 in epoch 15, gen_loss = 0.39641728372343127, disc_loss = 0.08658583493783109
Trained batch 62 in epoch 15, gen_loss = 0.39609271713665556, disc_loss = 0.08623836504384166
Trained batch 63 in epoch 15, gen_loss = 0.3964115190319717, disc_loss = 0.08659221972629894
Trained batch 64 in epoch 15, gen_loss = 0.39730986906931953, disc_loss = 0.08598648683669476
Trained batch 65 in epoch 15, gen_loss = 0.3976384216185772, disc_loss = 0.08490002128493154
Trained batch 66 in epoch 15, gen_loss = 0.39810369575201576, disc_loss = 0.08394059918320446
Trained batch 67 in epoch 15, gen_loss = 0.3985659195219769, disc_loss = 0.0831672397633905
Trained batch 68 in epoch 15, gen_loss = 0.3994882685550745, disc_loss = 0.08210371608805397
Trained batch 69 in epoch 15, gen_loss = 0.4004775311265673, disc_loss = 0.08135533954149911
Trained batch 70 in epoch 15, gen_loss = 0.3999418788392779, disc_loss = 0.08082268747802772
Trained batch 71 in epoch 15, gen_loss = 0.39906830754545, disc_loss = 0.08041701407637447
Trained batch 72 in epoch 15, gen_loss = 0.3992181118220499, disc_loss = 0.08088318711427385
Trained batch 73 in epoch 15, gen_loss = 0.3974731439674223, disc_loss = 0.08283573926451641
Trained batch 74 in epoch 15, gen_loss = 0.39800114432970685, disc_loss = 0.08209796206404765
Trained batch 75 in epoch 15, gen_loss = 0.3994002793180315, disc_loss = 0.08191130473278463
Trained batch 76 in epoch 15, gen_loss = 0.3985565478925581, disc_loss = 0.08135781201304167
Trained batch 77 in epoch 15, gen_loss = 0.39787286863877225, disc_loss = 0.0810209440234571
Trained batch 78 in epoch 15, gen_loss = 0.3981831699987001, disc_loss = 0.08012343683763395
Trained batch 79 in epoch 15, gen_loss = 0.39793076887726786, disc_loss = 0.08013705103658139
Trained batch 80 in epoch 15, gen_loss = 0.39687621777440296, disc_loss = 0.0801913961308238
Trained batch 81 in epoch 15, gen_loss = 0.3972466762472944, disc_loss = 0.07936623715227697
Trained batch 82 in epoch 15, gen_loss = 0.3981168797935348, disc_loss = 0.07854802024561956
Trained batch 83 in epoch 15, gen_loss = 0.3979693051604998, disc_loss = 0.07773529979888172
Trained batch 84 in epoch 15, gen_loss = 0.3975730804836049, disc_loss = 0.07733602149083334
Trained batch 85 in epoch 15, gen_loss = 0.39756315357463307, disc_loss = 0.07727937168593324
Trained batch 86 in epoch 15, gen_loss = 0.3978830839710674, disc_loss = 0.08150551932724728
Trained batch 87 in epoch 15, gen_loss = 0.39811034534465184, disc_loss = 0.08135886949656362
Trained batch 88 in epoch 15, gen_loss = 0.3990180365155252, disc_loss = 0.08098689996208368
Trained batch 89 in epoch 15, gen_loss = 0.39914572106467355, disc_loss = 0.08103818862388532
Trained batch 90 in epoch 15, gen_loss = 0.3990599103681334, disc_loss = 0.0805335407360242
Trained batch 91 in epoch 15, gen_loss = 0.39901591610649356, disc_loss = 0.07986100159747445
Trained batch 92 in epoch 15, gen_loss = 0.39874921306487054, disc_loss = 0.07927901462040922
Trained batch 93 in epoch 15, gen_loss = 0.3984729232306176, disc_loss = 0.07913260467033437
Trained batch 94 in epoch 15, gen_loss = 0.3983983272000363, disc_loss = 0.07886466862339722
Trained batch 95 in epoch 15, gen_loss = 0.3990217273434003, disc_loss = 0.07839055871590972
Trained batch 96 in epoch 15, gen_loss = 0.39888236203144506, disc_loss = 0.07859763149748143
Trained batch 97 in epoch 15, gen_loss = 0.40019697559123135, disc_loss = 0.08242648490229432
Trained batch 98 in epoch 15, gen_loss = 0.4002876871764058, disc_loss = 0.08285233935322424
Trained batch 99 in epoch 15, gen_loss = 0.39944004863500593, disc_loss = 0.08564606085419654
Trained batch 100 in epoch 15, gen_loss = 0.3993356410819705, disc_loss = 0.08505840103446256
Trained batch 101 in epoch 15, gen_loss = 0.3999827442800297, disc_loss = 0.08484810187170903
Trained batch 102 in epoch 15, gen_loss = 0.4001750237154729, disc_loss = 0.08418065291440603
Trained batch 103 in epoch 15, gen_loss = 0.399775783603008, disc_loss = 0.0837144938011009
Trained batch 104 in epoch 15, gen_loss = 0.3995566365264711, disc_loss = 0.08323903910460927
Trained batch 105 in epoch 15, gen_loss = 0.39964302840097893, disc_loss = 0.08293012273058577
Trained batch 106 in epoch 15, gen_loss = 0.39950641126276176, disc_loss = 0.08236240104676407
Trained batch 107 in epoch 15, gen_loss = 0.3992734689403463, disc_loss = 0.08273824045641555
Trained batch 108 in epoch 15, gen_loss = 0.39806105948369436, disc_loss = 0.08469650931998131
Trained batch 109 in epoch 15, gen_loss = 0.39816453944553026, disc_loss = 0.08442848023365844
Trained batch 110 in epoch 15, gen_loss = 0.39801458598257183, disc_loss = 0.08445550853738913
Trained batch 111 in epoch 15, gen_loss = 0.39749595363225254, disc_loss = 0.08392957616264798
Trained batch 112 in epoch 15, gen_loss = 0.39797316926770504, disc_loss = 0.0833772262640759
Trained batch 113 in epoch 15, gen_loss = 0.39781972609068217, disc_loss = 0.0830123289243171
Trained batch 114 in epoch 15, gen_loss = 0.39736591266549154, disc_loss = 0.08296828678120738
Trained batch 115 in epoch 15, gen_loss = 0.39727456764928226, disc_loss = 0.08245997167802577
Trained batch 116 in epoch 15, gen_loss = 0.3978646626839271, disc_loss = 0.0819341567878285
Trained batch 117 in epoch 15, gen_loss = 0.39753569258471666, disc_loss = 0.08144403500008886
Trained batch 118 in epoch 15, gen_loss = 0.39799338403870077, disc_loss = 0.08086184118756977
Trained batch 119 in epoch 15, gen_loss = 0.39827148492137593, disc_loss = 0.08063675103864322
Trained batch 120 in epoch 15, gen_loss = 0.3971901265057651, disc_loss = 0.08206273788540078
Trained batch 121 in epoch 15, gen_loss = 0.3976217957793689, disc_loss = 0.08318187651361843
Trained batch 122 in epoch 15, gen_loss = 0.3978034354806916, disc_loss = 0.08268648448846931
Trained batch 123 in epoch 15, gen_loss = 0.3977107537850257, disc_loss = 0.08259035288656671
Trained batch 124 in epoch 15, gen_loss = 0.39800457954406737, disc_loss = 0.08285344215482474
Trained batch 125 in epoch 15, gen_loss = 0.39774389777864727, disc_loss = 0.08239574195994508
Trained batch 126 in epoch 15, gen_loss = 0.39750242702604277, disc_loss = 0.08215650268573696
Trained batch 127 in epoch 15, gen_loss = 0.39807194331660867, disc_loss = 0.08176924903091276
Trained batch 128 in epoch 15, gen_loss = 0.39814937715382537, disc_loss = 0.08126869112570849
Trained batch 129 in epoch 15, gen_loss = 0.39830529873187726, disc_loss = 0.08080959724835478
Trained batch 130 in epoch 15, gen_loss = 0.3979004216558151, disc_loss = 0.08041783039038645
Trained batch 131 in epoch 15, gen_loss = 0.3974207296515956, disc_loss = 0.08051777233821199
Trained batch 132 in epoch 15, gen_loss = 0.3973121418988794, disc_loss = 0.08033042743493964
Trained batch 133 in epoch 15, gen_loss = 0.3978359419018475, disc_loss = 0.07978626414994473
Trained batch 134 in epoch 15, gen_loss = 0.3988250688270286, disc_loss = 0.07931523617632963
Trained batch 135 in epoch 15, gen_loss = 0.3990730454816538, disc_loss = 0.07882969290264608
Trained batch 136 in epoch 15, gen_loss = 0.39886193075319276, disc_loss = 0.07856323478240383
Trained batch 137 in epoch 15, gen_loss = 0.39894445823586505, disc_loss = 0.07824229085278037
Trained batch 138 in epoch 15, gen_loss = 0.3991024086801268, disc_loss = 0.07788817061231934
Trained batch 139 in epoch 15, gen_loss = 0.39966659545898436, disc_loss = 0.07773721132294407
Trained batch 140 in epoch 15, gen_loss = 0.39995342556466446, disc_loss = 0.07768203010980754
Trained batch 141 in epoch 15, gen_loss = 0.40021669549841277, disc_loss = 0.0775273602495206
Trained batch 142 in epoch 15, gen_loss = 0.4005261307412928, disc_loss = 0.07703976326628581
Trained batch 143 in epoch 15, gen_loss = 0.39986792020499706, disc_loss = 0.07700160863654067
Trained batch 144 in epoch 15, gen_loss = 0.39997481477671654, disc_loss = 0.07708608116312274
Trained batch 145 in epoch 15, gen_loss = 0.3999943292304261, disc_loss = 0.07711633273132451
Trained batch 146 in epoch 15, gen_loss = 0.4001133922411471, disc_loss = 0.0766422811224043
Trained batch 147 in epoch 15, gen_loss = 0.40040983904052424, disc_loss = 0.0764164731120439
Trained batch 148 in epoch 15, gen_loss = 0.39985546309675946, disc_loss = 0.07621830924970392
Trained batch 149 in epoch 15, gen_loss = 0.39989193896452585, disc_loss = 0.07584201021119952
Trained batch 150 in epoch 15, gen_loss = 0.39951211135119, disc_loss = 0.07563408950824808
Trained batch 151 in epoch 15, gen_loss = 0.39974871101348025, disc_loss = 0.07547580953809972
Trained batch 152 in epoch 15, gen_loss = 0.3997303827915316, disc_loss = 0.07509882880216526
Trained batch 153 in epoch 15, gen_loss = 0.39956093124755016, disc_loss = 0.07487542816595018
Trained batch 154 in epoch 15, gen_loss = 0.39890163598522066, disc_loss = 0.07481855654548253
Trained batch 155 in epoch 15, gen_loss = 0.3990418389439583, disc_loss = 0.0746471635483874
Trained batch 156 in epoch 15, gen_loss = 0.3989918332570677, disc_loss = 0.07423878176980148
Trained batch 157 in epoch 15, gen_loss = 0.3989053349706191, disc_loss = 0.07408056177694021
Trained batch 158 in epoch 15, gen_loss = 0.3990971423544974, disc_loss = 0.07420430707879974
Trained batch 159 in epoch 15, gen_loss = 0.39895017072558403, disc_loss = 0.07468930879258551
Trained batch 160 in epoch 15, gen_loss = 0.39940729885367876, disc_loss = 0.07503475448382753
Trained batch 161 in epoch 15, gen_loss = 0.3998360455404093, disc_loss = 0.07462904961020858
Trained batch 162 in epoch 15, gen_loss = 0.3995614635066752, disc_loss = 0.07433411421859923
Trained batch 163 in epoch 15, gen_loss = 0.3994913455553171, disc_loss = 0.07404587534824159
Trained batch 164 in epoch 15, gen_loss = 0.39934921752322805, disc_loss = 0.07370171519843015
Trained batch 165 in epoch 15, gen_loss = 0.3992289627890989, disc_loss = 0.07348193416753447
Trained batch 166 in epoch 15, gen_loss = 0.39952857462231983, disc_loss = 0.07317412433822355
Trained batch 167 in epoch 15, gen_loss = 0.39914373787386076, disc_loss = 0.07342177473141678
Trained batch 168 in epoch 15, gen_loss = 0.40004852131979, disc_loss = 0.07536959863052918
Trained batch 169 in epoch 15, gen_loss = 0.4008087808594984, disc_loss = 0.07588667531004724
Trained batch 170 in epoch 15, gen_loss = 0.4006235848741922, disc_loss = 0.07634231094162018
Trained batch 171 in epoch 15, gen_loss = 0.40049618326647335, disc_loss = 0.07634954214052753
Trained batch 172 in epoch 15, gen_loss = 0.40040237693428304, disc_loss = 0.0763698213254613
Trained batch 173 in epoch 15, gen_loss = 0.4000724994245617, disc_loss = 0.0759873865921607
Trained batch 174 in epoch 15, gen_loss = 0.3998070773056575, disc_loss = 0.07572886485074247
Trained batch 175 in epoch 15, gen_loss = 0.39971566962247546, disc_loss = 0.07550510612782091
Trained batch 176 in epoch 15, gen_loss = 0.400099204926841, disc_loss = 0.0751975830012964
Trained batch 177 in epoch 15, gen_loss = 0.4002368448490507, disc_loss = 0.07512952493022332
Trained batch 178 in epoch 15, gen_loss = 0.4000026591996241, disc_loss = 0.07587172254378902
Trained batch 179 in epoch 15, gen_loss = 0.4007706418633461, disc_loss = 0.07575997166956465
Trained batch 180 in epoch 15, gen_loss = 0.4006836304019169, disc_loss = 0.07599528227515971
Trained batch 181 in epoch 15, gen_loss = 0.40028991198146735, disc_loss = 0.07611339464578983
Trained batch 182 in epoch 15, gen_loss = 0.3999763559448263, disc_loss = 0.07576757135083441
Trained batch 183 in epoch 15, gen_loss = 0.4001230453343495, disc_loss = 0.07542033118965186
Trained batch 184 in epoch 15, gen_loss = 0.4000356216688414, disc_loss = 0.07507366369402892
Trained batch 185 in epoch 15, gen_loss = 0.39970156838816984, disc_loss = 0.07494089552651971
Trained batch 186 in epoch 15, gen_loss = 0.4001549421784712, disc_loss = 0.07472914848277434
Trained batch 187 in epoch 15, gen_loss = 0.4001112253742015, disc_loss = 0.0744667356249262
Trained batch 188 in epoch 15, gen_loss = 0.3997240925907458, disc_loss = 0.07445846161455232
Trained batch 189 in epoch 15, gen_loss = 0.3998959089580335, disc_loss = 0.07543160823713008
Trained batch 190 in epoch 15, gen_loss = 0.4003631951609207, disc_loss = 0.07516015305900604
Trained batch 191 in epoch 15, gen_loss = 0.40013737976551056, disc_loss = 0.07522268368726752
Trained batch 192 in epoch 15, gen_loss = 0.39962823434197225, disc_loss = 0.0753978595880724
Trained batch 193 in epoch 15, gen_loss = 0.39990138731051966, disc_loss = 0.07506499334344084
Trained batch 194 in epoch 15, gen_loss = 0.4001874219148587, disc_loss = 0.0747344747137947
Trained batch 195 in epoch 15, gen_loss = 0.40051592004542447, disc_loss = 0.07438962741241771
Trained batch 196 in epoch 15, gen_loss = 0.4008152445560785, disc_loss = 0.07405317993598239
Trained batch 197 in epoch 15, gen_loss = 0.4010860938014406, disc_loss = 0.07375616468771388
Trained batch 198 in epoch 15, gen_loss = 0.40096967349100354, disc_loss = 0.07342524316405231
Trained batch 199 in epoch 15, gen_loss = 0.40115347027778625, disc_loss = 0.07321415230631828
Trained batch 200 in epoch 15, gen_loss = 0.4010095944748589, disc_loss = 0.07313776236787364
Trained batch 201 in epoch 15, gen_loss = 0.40063580295236983, disc_loss = 0.07291645997452854
Trained batch 202 in epoch 15, gen_loss = 0.40052583226429417, disc_loss = 0.07301765351826922
Trained batch 203 in epoch 15, gen_loss = 0.40093295612171587, disc_loss = 0.07281131414221782
Trained batch 204 in epoch 15, gen_loss = 0.4011826877186938, disc_loss = 0.07262243368640178
Trained batch 205 in epoch 15, gen_loss = 0.40134788065859417, disc_loss = 0.07248595300881029
Trained batch 206 in epoch 15, gen_loss = 0.4011549488933766, disc_loss = 0.07245229913488678
Trained batch 207 in epoch 15, gen_loss = 0.4011612759473232, disc_loss = 0.07234420913916367
Trained batch 208 in epoch 15, gen_loss = 0.4010138031113091, disc_loss = 0.07219062538808613
Trained batch 209 in epoch 15, gen_loss = 0.40088628204095933, disc_loss = 0.0719520388437169
Trained batch 210 in epoch 15, gen_loss = 0.4008442772225746, disc_loss = 0.07172836866494603
Trained batch 211 in epoch 15, gen_loss = 0.4008476330705409, disc_loss = 0.07149053203328601
Trained batch 212 in epoch 15, gen_loss = 0.4008558231620162, disc_loss = 0.07144390448857921
Trained batch 213 in epoch 15, gen_loss = 0.40105133789165, disc_loss = 0.07141994556116167
Trained batch 214 in epoch 15, gen_loss = 0.4013557941414589, disc_loss = 0.07114034405108108
Trained batch 215 in epoch 15, gen_loss = 0.4011271015085556, disc_loss = 0.07105729833279771
Trained batch 216 in epoch 15, gen_loss = 0.4012603807833887, disc_loss = 0.07167826477043365
Trained batch 217 in epoch 15, gen_loss = 0.4011173089709851, disc_loss = 0.07175899608863877
Trained batch 218 in epoch 15, gen_loss = 0.4013791103341264, disc_loss = 0.07152262085955165
Trained batch 219 in epoch 15, gen_loss = 0.4012771191922101, disc_loss = 0.07124744859862733
Trained batch 220 in epoch 15, gen_loss = 0.4015063553104573, disc_loss = 0.07124071416120588
Trained batch 221 in epoch 15, gen_loss = 0.40120319673069965, disc_loss = 0.07125660142366279
Trained batch 222 in epoch 15, gen_loss = 0.40127220054912993, disc_loss = 0.07108507732622693
Trained batch 223 in epoch 15, gen_loss = 0.4012641874807222, disc_loss = 0.07092525611681465
Trained batch 224 in epoch 15, gen_loss = 0.4009695925977495, disc_loss = 0.07112345074199967
Trained batch 225 in epoch 15, gen_loss = 0.40107140683494835, disc_loss = 0.07101755855868744
Trained batch 226 in epoch 15, gen_loss = 0.4010185528431695, disc_loss = 0.07106514963924492
Trained batch 227 in epoch 15, gen_loss = 0.40074007500681963, disc_loss = 0.07195129166683999
Trained batch 228 in epoch 15, gen_loss = 0.40069497347398614, disc_loss = 0.0719797825278088
Trained batch 229 in epoch 15, gen_loss = 0.4008842558964439, disc_loss = 0.07182339688601053
Trained batch 230 in epoch 15, gen_loss = 0.40053255140007316, disc_loss = 0.07176956227573353
Trained batch 231 in epoch 15, gen_loss = 0.40035858634730864, disc_loss = 0.07167197989926127
Trained batch 232 in epoch 15, gen_loss = 0.4002184122161292, disc_loss = 0.07156093013692695
Trained batch 233 in epoch 15, gen_loss = 0.4000249459193303, disc_loss = 0.07138783546387513
Trained batch 234 in epoch 15, gen_loss = 0.40003134075631486, disc_loss = 0.07113388672946615
Trained batch 235 in epoch 15, gen_loss = 0.39996063734515236, disc_loss = 0.07089661581883744
Trained batch 236 in epoch 15, gen_loss = 0.3999736301506622, disc_loss = 0.07090310852204446
Trained batch 237 in epoch 15, gen_loss = 0.4000505682300119, disc_loss = 0.07153768135438196
Trained batch 238 in epoch 15, gen_loss = 0.3999185047139682, disc_loss = 0.07238161126658257
Trained batch 239 in epoch 15, gen_loss = 0.40016363325218357, disc_loss = 0.07226408576437583
Trained batch 240 in epoch 15, gen_loss = 0.4001679171912403, disc_loss = 0.07208553901815563
Trained batch 241 in epoch 15, gen_loss = 0.39981738287062685, disc_loss = 0.07203399835631621
Trained batch 242 in epoch 15, gen_loss = 0.39980010105749214, disc_loss = 0.07184095722105768
Trained batch 243 in epoch 15, gen_loss = 0.39987295462948375, disc_loss = 0.07176878587266461
Trained batch 244 in epoch 15, gen_loss = 0.40019136995685345, disc_loss = 0.07159208284348857
Trained batch 245 in epoch 15, gen_loss = 0.4001316577196121, disc_loss = 0.07145338926494606
Trained batch 246 in epoch 15, gen_loss = 0.4001959645555087, disc_loss = 0.07134473608874599
Trained batch 247 in epoch 15, gen_loss = 0.39981467336896925, disc_loss = 0.07129577254395812
Trained batch 248 in epoch 15, gen_loss = 0.3998352843355462, disc_loss = 0.07107586252043047
Trained batch 249 in epoch 15, gen_loss = 0.3999341517686844, disc_loss = 0.07082578772306443
Trained batch 250 in epoch 15, gen_loss = 0.3998094532356794, disc_loss = 0.07062616187381554
Trained batch 251 in epoch 15, gen_loss = 0.39998704561638454, disc_loss = 0.07064963300668058
Trained batch 252 in epoch 15, gen_loss = 0.3998153817512301, disc_loss = 0.07065058010722337
Trained batch 253 in epoch 15, gen_loss = 0.4001151462943535, disc_loss = 0.07042153568674378
Trained batch 254 in epoch 15, gen_loss = 0.4002235287544774, disc_loss = 0.07025580685585738
Trained batch 255 in epoch 15, gen_loss = 0.3999328095233068, disc_loss = 0.07033170971044456
Trained batch 256 in epoch 15, gen_loss = 0.40026540027982066, disc_loss = 0.07056732535550682
Trained batch 257 in epoch 15, gen_loss = 0.3998585244019826, disc_loss = 0.0707043445337015
Trained batch 258 in epoch 15, gen_loss = 0.40023436187317013, disc_loss = 0.07080751199016355
Trained batch 259 in epoch 15, gen_loss = 0.40033754775157343, disc_loss = 0.07065712097817316
Trained batch 260 in epoch 15, gen_loss = 0.4001354861761875, disc_loss = 0.07090877018283724
Trained batch 261 in epoch 15, gen_loss = 0.4001370562624385, disc_loss = 0.07092193370855605
Trained batch 262 in epoch 15, gen_loss = 0.40014172019614014, disc_loss = 0.07071328836319678
Trained batch 263 in epoch 15, gen_loss = 0.40009148159261904, disc_loss = 0.07055576371071352
Trained batch 264 in epoch 15, gen_loss = 0.40001984441055444, disc_loss = 0.07050149661119816
Trained batch 265 in epoch 15, gen_loss = 0.3997964734645714, disc_loss = 0.07072819781636722
Trained batch 266 in epoch 15, gen_loss = 0.39997918407122296, disc_loss = 0.07054285293842634
Trained batch 267 in epoch 15, gen_loss = 0.4001639933506055, disc_loss = 0.07053081431676314
Trained batch 268 in epoch 15, gen_loss = 0.40007048368897136, disc_loss = 0.07033355830784292
Trained batch 269 in epoch 15, gen_loss = 0.3999205888421447, disc_loss = 0.07026074835340734
Trained batch 270 in epoch 15, gen_loss = 0.3998039529772262, disc_loss = 0.0701024422587009
Trained batch 271 in epoch 15, gen_loss = 0.39990861100309033, disc_loss = 0.07003078049199436
Trained batch 272 in epoch 15, gen_loss = 0.39989960280966846, disc_loss = 0.06979877214141927
Trained batch 273 in epoch 15, gen_loss = 0.3997476319544507, disc_loss = 0.06976054708412202
Trained batch 274 in epoch 15, gen_loss = 0.40000008593906056, disc_loss = 0.06970488242466341
Trained batch 275 in epoch 15, gen_loss = 0.40002198906048486, disc_loss = 0.0695280317466814
Trained batch 276 in epoch 15, gen_loss = 0.4001284581659503, disc_loss = 0.06939179878278437
Trained batch 277 in epoch 15, gen_loss = 0.39999009036331723, disc_loss = 0.07043692877301745
Trained batch 278 in epoch 15, gen_loss = 0.39983792373356425, disc_loss = 0.07061515620652599
Trained batch 279 in epoch 15, gen_loss = 0.39991306151662553, disc_loss = 0.07066034597810358
Trained batch 280 in epoch 15, gen_loss = 0.40017388755740646, disc_loss = 0.07053667946231429
Trained batch 281 in epoch 15, gen_loss = 0.40025632136256983, disc_loss = 0.07045737174768926
Trained batch 282 in epoch 15, gen_loss = 0.39993891625438055, disc_loss = 0.0704366692865116
Trained batch 283 in epoch 15, gen_loss = 0.39979260918540016, disc_loss = 0.07023802453087984
Trained batch 284 in epoch 15, gen_loss = 0.3995435054887805, disc_loss = 0.07062879148217147
Trained batch 285 in epoch 15, gen_loss = 0.3992755503712834, disc_loss = 0.07093520390547135
Trained batch 286 in epoch 15, gen_loss = 0.39906272520587005, disc_loss = 0.07076273749189821
Trained batch 287 in epoch 15, gen_loss = 0.3992994874715805, disc_loss = 0.0713331475304181
Trained batch 288 in epoch 15, gen_loss = 0.3992051663695735, disc_loss = 0.07157958347582384
Trained batch 289 in epoch 15, gen_loss = 0.39906741760928055, disc_loss = 0.07144494801438574
Trained batch 290 in epoch 15, gen_loss = 0.39913947957078205, disc_loss = 0.07164944677303235
Trained batch 291 in epoch 15, gen_loss = 0.39926983018035755, disc_loss = 0.07152705676279554
Trained batch 292 in epoch 15, gen_loss = 0.3990863552475952, disc_loss = 0.0714311996767291
Trained batch 293 in epoch 15, gen_loss = 0.39901213064080193, disc_loss = 0.07127126267965452
Trained batch 294 in epoch 15, gen_loss = 0.3990316026291605, disc_loss = 0.07111748612596322
Trained batch 295 in epoch 15, gen_loss = 0.39932809739902214, disc_loss = 0.07095632339336884
Trained batch 296 in epoch 15, gen_loss = 0.39938217090436506, disc_loss = 0.07094609842444409
Trained batch 297 in epoch 15, gen_loss = 0.39918178849972336, disc_loss = 0.0707615734102992
Trained batch 298 in epoch 15, gen_loss = 0.39922607483273764, disc_loss = 0.07062207347710296
Trained batch 299 in epoch 15, gen_loss = 0.3993157547712326, disc_loss = 0.07063452647067607
Trained batch 300 in epoch 15, gen_loss = 0.3991309189519217, disc_loss = 0.07144903122722805
Trained batch 301 in epoch 15, gen_loss = 0.3992416252758329, disc_loss = 0.0714082780158431
Trained batch 302 in epoch 15, gen_loss = 0.3994261923402843, disc_loss = 0.07123475347525708
Trained batch 303 in epoch 15, gen_loss = 0.39955868160254077, disc_loss = 0.07114692539969263
Trained batch 304 in epoch 15, gen_loss = 0.39963968122591736, disc_loss = 0.07124799673491325
Trained batch 305 in epoch 15, gen_loss = 0.39958490236522326, disc_loss = 0.07145032713043631
Trained batch 306 in epoch 15, gen_loss = 0.39999182187384813, disc_loss = 0.0713769378905042
Trained batch 307 in epoch 15, gen_loss = 0.3999778280010471, disc_loss = 0.07133126382522478
Trained batch 308 in epoch 15, gen_loss = 0.40012534690906315, disc_loss = 0.07131105087830121
Trained batch 309 in epoch 15, gen_loss = 0.40019662774378256, disc_loss = 0.07126688851764607
Trained batch 310 in epoch 15, gen_loss = 0.4003443387352002, disc_loss = 0.07118105797630127
Trained batch 311 in epoch 15, gen_loss = 0.4005829729139805, disc_loss = 0.07158354101762271
Trained batch 312 in epoch 15, gen_loss = 0.4006721262162486, disc_loss = 0.07206968339784933
Trained batch 313 in epoch 15, gen_loss = 0.40074768842785224, disc_loss = 0.07186324002701718
Trained batch 314 in epoch 15, gen_loss = 0.4008922558928293, disc_loss = 0.07175725339394477
Trained batch 315 in epoch 15, gen_loss = 0.4010625422189507, disc_loss = 0.07155883556402795
Trained batch 316 in epoch 15, gen_loss = 0.4014139430191991, disc_loss = 0.07141415631598337
Trained batch 317 in epoch 15, gen_loss = 0.40112775011257557, disc_loss = 0.07135303487339344
Trained batch 318 in epoch 15, gen_loss = 0.4011785804664827, disc_loss = 0.07117576062311433
Trained batch 319 in epoch 15, gen_loss = 0.4009355836547911, disc_loss = 0.07127970069559524
Trained batch 320 in epoch 15, gen_loss = 0.40051228021535545, disc_loss = 0.07177771914698114
Trained batch 321 in epoch 15, gen_loss = 0.40076987871101927, disc_loss = 0.07167637199076668
Trained batch 322 in epoch 15, gen_loss = 0.40090189288275163, disc_loss = 0.07169013730057114
Trained batch 323 in epoch 15, gen_loss = 0.4007441070344713, disc_loss = 0.07178734814500964
Trained batch 324 in epoch 15, gen_loss = 0.4008379470385038, disc_loss = 0.07168817289890005
Trained batch 325 in epoch 15, gen_loss = 0.4011413858163576, disc_loss = 0.07168535523807938
Trained batch 326 in epoch 15, gen_loss = 0.40091679803457464, disc_loss = 0.07199077979328299
Trained batch 327 in epoch 15, gen_loss = 0.40103277264208326, disc_loss = 0.07196209715003511
Trained batch 328 in epoch 15, gen_loss = 0.4014217776549261, disc_loss = 0.0717786115560239
Trained batch 329 in epoch 15, gen_loss = 0.4013965295119719, disc_loss = 0.07169977811052267
Trained batch 330 in epoch 15, gen_loss = 0.4016059490309021, disc_loss = 0.07163354396127908
Trained batch 331 in epoch 15, gen_loss = 0.4017119288264987, disc_loss = 0.07145786982629987
Trained batch 332 in epoch 15, gen_loss = 0.40171839999365017, disc_loss = 0.07149378853981514
Trained batch 333 in epoch 15, gen_loss = 0.40175149665621224, disc_loss = 0.07178873427541269
Trained batch 334 in epoch 15, gen_loss = 0.40155261754989624, disc_loss = 0.07165434369261363
Trained batch 335 in epoch 15, gen_loss = 0.4015141586285262, disc_loss = 0.07160809859938343
Trained batch 336 in epoch 15, gen_loss = 0.40166158014659714, disc_loss = 0.07141973612863206
Trained batch 337 in epoch 15, gen_loss = 0.40182757465797064, disc_loss = 0.07130064135940867
Trained batch 338 in epoch 15, gen_loss = 0.40160352009235933, disc_loss = 0.07114766573445504
Trained batch 339 in epoch 15, gen_loss = 0.40143046712174135, disc_loss = 0.07100283103200662
Trained batch 340 in epoch 15, gen_loss = 0.4012870330614778, disc_loss = 0.07085516085968382
Trained batch 341 in epoch 15, gen_loss = 0.4013669505628229, disc_loss = 0.07073263841005838
Trained batch 342 in epoch 15, gen_loss = 0.4012344482167469, disc_loss = 0.07058320990722876
Trained batch 343 in epoch 15, gen_loss = 0.40133687204053237, disc_loss = 0.07040407485463981
Trained batch 344 in epoch 15, gen_loss = 0.4014528292676677, disc_loss = 0.07028418298459788
Trained batch 345 in epoch 15, gen_loss = 0.40152594326548496, disc_loss = 0.07023538671288575
Trained batch 346 in epoch 15, gen_loss = 0.4013120344805099, disc_loss = 0.07033619923001794
Trained batch 347 in epoch 15, gen_loss = 0.40153457070219106, disc_loss = 0.07044678792255749
Trained batch 348 in epoch 15, gen_loss = 0.401522524291943, disc_loss = 0.07034038913097329
Trained batch 349 in epoch 15, gen_loss = 0.40144788920879365, disc_loss = 0.07025996551582855
Trained batch 350 in epoch 15, gen_loss = 0.4014486671343149, disc_loss = 0.07023195208758752
Trained batch 351 in epoch 15, gen_loss = 0.40138223995877936, disc_loss = 0.07006715537466914
Trained batch 352 in epoch 15, gen_loss = 0.40138704108111245, disc_loss = 0.0699247608407171
Trained batch 353 in epoch 15, gen_loss = 0.4015811163153352, disc_loss = 0.06976148922990819
Trained batch 354 in epoch 15, gen_loss = 0.40147427177765, disc_loss = 0.06968174041707961
Trained batch 355 in epoch 15, gen_loss = 0.40149552868993094, disc_loss = 0.0697238547426617
Trained batch 356 in epoch 15, gen_loss = 0.40134008525132464, disc_loss = 0.06986705489399261
Trained batch 357 in epoch 15, gen_loss = 0.40128605800301004, disc_loss = 0.0703694369844239
Trained batch 358 in epoch 15, gen_loss = 0.4011953192501015, disc_loss = 0.07020647971551025
Trained batch 359 in epoch 15, gen_loss = 0.40109069761302735, disc_loss = 0.07006456565706887
Trained batch 360 in epoch 15, gen_loss = 0.4010759991622037, disc_loss = 0.06997192199432248
Trained batch 361 in epoch 15, gen_loss = 0.4012332779267875, disc_loss = 0.06982675335596403
Trained batch 362 in epoch 15, gen_loss = 0.4013852073141366, disc_loss = 0.0697002311329519
Trained batch 363 in epoch 15, gen_loss = 0.40095261263323356, disc_loss = 0.0700979910082194
Trained batch 364 in epoch 15, gen_loss = 0.401127399810373, disc_loss = 0.07099143668677504
Trained batch 365 in epoch 15, gen_loss = 0.4013252506653468, disc_loss = 0.07093780901908997
Trained batch 366 in epoch 15, gen_loss = 0.4013516994685503, disc_loss = 0.07121860987966123
Trained batch 367 in epoch 15, gen_loss = 0.40169370101521845, disc_loss = 0.07124907651830101
Trained batch 368 in epoch 15, gen_loss = 0.40197338700940616, disc_loss = 0.07129631991949952
Trained batch 369 in epoch 15, gen_loss = 0.40209255709841446, disc_loss = 0.07126300734518146
Trained batch 370 in epoch 15, gen_loss = 0.40198227377593354, disc_loss = 0.071453209402858
Trained batch 371 in epoch 15, gen_loss = 0.4018686074082569, disc_loss = 0.07230149222392669
Trained batch 372 in epoch 15, gen_loss = 0.4018581662996205, disc_loss = 0.07253437907617269
Trained batch 373 in epoch 15, gen_loss = 0.40174051258653243, disc_loss = 0.07253059685942442
Trained batch 374 in epoch 15, gen_loss = 0.40165671133995057, disc_loss = 0.07259638896460334
Trained batch 375 in epoch 15, gen_loss = 0.4018896124622923, disc_loss = 0.07254249242783346
Trained batch 376 in epoch 15, gen_loss = 0.4020213296622117, disc_loss = 0.07245346492610931
Trained batch 377 in epoch 15, gen_loss = 0.40185512610213464, disc_loss = 0.0723642146882537
Trained batch 378 in epoch 15, gen_loss = 0.40196166236671105, disc_loss = 0.07225339875327998
Trained batch 379 in epoch 15, gen_loss = 0.4019220731760326, disc_loss = 0.07252769268142353
Trained batch 380 in epoch 15, gen_loss = 0.401895562338391, disc_loss = 0.0733124899453046
Trained batch 381 in epoch 15, gen_loss = 0.4018477772542943, disc_loss = 0.073432000440482
Trained batch 382 in epoch 15, gen_loss = 0.40191547366408703, disc_loss = 0.073683677779817
Trained batch 383 in epoch 15, gen_loss = 0.40170653428261477, disc_loss = 0.07377711043106198
Trained batch 384 in epoch 15, gen_loss = 0.4015888624377065, disc_loss = 0.0736600427162628
Trained batch 385 in epoch 15, gen_loss = 0.40172664906076816, disc_loss = 0.07352319711920627
Trained batch 386 in epoch 15, gen_loss = 0.4016438962107173, disc_loss = 0.07346630541039799
Trained batch 387 in epoch 15, gen_loss = 0.40158986069799696, disc_loss = 0.073304652585648
Trained batch 388 in epoch 15, gen_loss = 0.401698249088155, disc_loss = 0.07381986824144396
Trained batch 389 in epoch 15, gen_loss = 0.4016128159486331, disc_loss = 0.07401739136697963
Trained batch 390 in epoch 15, gen_loss = 0.4016459283926298, disc_loss = 0.0739123421611593
Trained batch 391 in epoch 15, gen_loss = 0.4018049133675439, disc_loss = 0.07387987471408952
Trained batch 392 in epoch 15, gen_loss = 0.4018422233997714, disc_loss = 0.07372616596742707
Trained batch 393 in epoch 15, gen_loss = 0.40169808503032334, disc_loss = 0.0736249822042977
Trained batch 394 in epoch 15, gen_loss = 0.40152740478515625, disc_loss = 0.073504383761813
Trained batch 395 in epoch 15, gen_loss = 0.4015034523726714, disc_loss = 0.0733386747988242
Trained batch 396 in epoch 15, gen_loss = 0.40149896879040026, disc_loss = 0.07320327198095339
Trained batch 397 in epoch 15, gen_loss = 0.40139726530666925, disc_loss = 0.07318782108957557
Trained batch 398 in epoch 15, gen_loss = 0.4012890002482517, disc_loss = 0.07343057002335376
Trained batch 399 in epoch 15, gen_loss = 0.4015451781451702, disc_loss = 0.07342706621508115
Trained batch 400 in epoch 15, gen_loss = 0.40146743508051164, disc_loss = 0.07348414407253377
Trained batch 401 in epoch 15, gen_loss = 0.40129141450224826, disc_loss = 0.07349142772191904
Trained batch 402 in epoch 15, gen_loss = 0.40134932533387213, disc_loss = 0.07335904649997282
Trained batch 403 in epoch 15, gen_loss = 0.4011698727412979, disc_loss = 0.07323272042506661
Trained batch 404 in epoch 15, gen_loss = 0.40139963781392135, disc_loss = 0.0731153119665881
Trained batch 405 in epoch 15, gen_loss = 0.40129891324219447, disc_loss = 0.07305698389338852
Trained batch 406 in epoch 15, gen_loss = 0.40117058238467657, disc_loss = 0.07331940673488474
Trained batch 407 in epoch 15, gen_loss = 0.4013735833121281, disc_loss = 0.07341652145202947
Trained batch 408 in epoch 15, gen_loss = 0.4013526167146734, disc_loss = 0.07327286330618711
Trained batch 409 in epoch 15, gen_loss = 0.40116808785171043, disc_loss = 0.07323162392031674
Trained batch 410 in epoch 15, gen_loss = 0.4012412076448872, disc_loss = 0.07309480204865554
Trained batch 411 in epoch 15, gen_loss = 0.4013580646619056, disc_loss = 0.07308102655337527
Trained batch 412 in epoch 15, gen_loss = 0.4012071224015215, disc_loss = 0.0730611017823995
Trained batch 413 in epoch 15, gen_loss = 0.40116529224287484, disc_loss = 0.07293292353996009
Trained batch 414 in epoch 15, gen_loss = 0.4011961574295917, disc_loss = 0.07280972064416631
Trained batch 415 in epoch 15, gen_loss = 0.40108339273585725, disc_loss = 0.07271260340460756
Trained batch 416 in epoch 15, gen_loss = 0.4010004703518298, disc_loss = 0.07263046151420159
Trained batch 417 in epoch 15, gen_loss = 0.4009268868482854, disc_loss = 0.07247927953916909
Trained batch 418 in epoch 15, gen_loss = 0.40097927684431145, disc_loss = 0.07241614270168478
Trained batch 419 in epoch 15, gen_loss = 0.4007943107968285, disc_loss = 0.07260166229791053
Trained batch 420 in epoch 15, gen_loss = 0.4007429927941456, disc_loss = 0.07284763218799602
Trained batch 421 in epoch 15, gen_loss = 0.4006930802953187, disc_loss = 0.07290231415856259
Trained batch 422 in epoch 15, gen_loss = 0.4006378752119998, disc_loss = 0.07278730970065397
Trained batch 423 in epoch 15, gen_loss = 0.40067869242069853, disc_loss = 0.07263572053777335
Trained batch 424 in epoch 15, gen_loss = 0.400536724469241, disc_loss = 0.07250350032330435
Trained batch 425 in epoch 15, gen_loss = 0.40068155597073374, disc_loss = 0.07235227574751725
Trained batch 426 in epoch 15, gen_loss = 0.4006795982287137, disc_loss = 0.07222210356869693
Trained batch 427 in epoch 15, gen_loss = 0.4005110639835072, disc_loss = 0.07218686984873716
Trained batch 428 in epoch 15, gen_loss = 0.4004182824582765, disc_loss = 0.07287708722979769
Trained batch 429 in epoch 15, gen_loss = 0.40075403056865516, disc_loss = 0.07293455118291774
Trained batch 430 in epoch 15, gen_loss = 0.4010332068406789, disc_loss = 0.07295131872747344
Trained batch 431 in epoch 15, gen_loss = 0.40093779405234037, disc_loss = 0.07285265929035463
Trained batch 432 in epoch 15, gen_loss = 0.40071929609252455, disc_loss = 0.07295667646048423
Trained batch 433 in epoch 15, gen_loss = 0.40076010904279175, disc_loss = 0.07290688068777632
Trained batch 434 in epoch 15, gen_loss = 0.4007230461328879, disc_loss = 0.0727701119083012
Trained batch 435 in epoch 15, gen_loss = 0.4007679297836549, disc_loss = 0.0726356011390293
Trained batch 436 in epoch 15, gen_loss = 0.4008562746255294, disc_loss = 0.07249825268033337
Trained batch 437 in epoch 15, gen_loss = 0.40079640062976646, disc_loss = 0.07240407781773268
Trained batch 438 in epoch 15, gen_loss = 0.4007112671003798, disc_loss = 0.07246203507256434
Trained batch 439 in epoch 15, gen_loss = 0.4006681017577648, disc_loss = 0.07253558455056257
Trained batch 440 in epoch 15, gen_loss = 0.4007938429882197, disc_loss = 0.07249146590617542
Trained batch 441 in epoch 15, gen_loss = 0.40099449914235336, disc_loss = 0.07234952560356266
Trained batch 442 in epoch 15, gen_loss = 0.40100178324342045, disc_loss = 0.07220997950945125
Trained batch 443 in epoch 15, gen_loss = 0.400980250322604, disc_loss = 0.0722473728762067
Trained batch 444 in epoch 15, gen_loss = 0.4010382580623198, disc_loss = 0.07247692124206531
Trained batch 445 in epoch 15, gen_loss = 0.40091965083584125, disc_loss = 0.07252545914019672
Trained batch 446 in epoch 15, gen_loss = 0.40099191999008726, disc_loss = 0.07241700502462535
Trained batch 447 in epoch 15, gen_loss = 0.40109630108677913, disc_loss = 0.07226861812003856
Trained batch 448 in epoch 15, gen_loss = 0.4008878399773536, disc_loss = 0.07213767378472771
Trained batch 449 in epoch 15, gen_loss = 0.40079159061113995, disc_loss = 0.07200817849590546
Trained batch 450 in epoch 15, gen_loss = 0.4010030701260873, disc_loss = 0.07189053824551388
Trained batch 451 in epoch 15, gen_loss = 0.400859820631753, disc_loss = 0.07176491770320531
Trained batch 452 in epoch 15, gen_loss = 0.40098142110748797, disc_loss = 0.07165775633217647
Trained batch 453 in epoch 15, gen_loss = 0.4010512111339275, disc_loss = 0.07153840607651694
Trained batch 454 in epoch 15, gen_loss = 0.40114931261146464, disc_loss = 0.0715017632560825
Trained batch 455 in epoch 15, gen_loss = 0.40096255666331243, disc_loss = 0.0715912935628327
Trained batch 456 in epoch 15, gen_loss = 0.4010979625145768, disc_loss = 0.07162883909647424
Trained batch 457 in epoch 15, gen_loss = 0.4010053015431983, disc_loss = 0.07152802112520425
Trained batch 458 in epoch 15, gen_loss = 0.40078279518873344, disc_loss = 0.07159417496856164
Trained batch 459 in epoch 15, gen_loss = 0.40081609208946645, disc_loss = 0.07145781330865525
Trained batch 460 in epoch 15, gen_loss = 0.4007398305771925, disc_loss = 0.07149814229373722
Testing Epoch 15
Training Epoch 16
Trained batch 0 in epoch 16, gen_loss = 0.34070858359336853, disc_loss = 0.04052577167749405
Trained batch 1 in epoch 16, gen_loss = 0.3114105761051178, disc_loss = 0.055838100612163544
Trained batch 2 in epoch 16, gen_loss = 0.34683964649836224, disc_loss = 0.13182811439037323
Trained batch 3 in epoch 16, gen_loss = 0.3473607674241066, disc_loss = 0.10383794130757451
Trained batch 4 in epoch 16, gen_loss = 0.35232428908348085, disc_loss = 0.0894004937261343
Trained batch 5 in epoch 16, gen_loss = 0.36030598481496173, disc_loss = 0.07914233393967152
Trained batch 6 in epoch 16, gen_loss = 0.3587368556431362, disc_loss = 0.07365468463727406
Trained batch 7 in epoch 16, gen_loss = 0.35356855764985085, disc_loss = 0.09735045861452818
Trained batch 8 in epoch 16, gen_loss = 0.3683752649360233, disc_loss = 0.09759881595770518
Trained batch 9 in epoch 16, gen_loss = 0.3762813240289688, disc_loss = 0.0892577358521521
Trained batch 10 in epoch 16, gen_loss = 0.37554848194122314, disc_loss = 0.08350222786380486
Trained batch 11 in epoch 16, gen_loss = 0.3772355616092682, disc_loss = 0.07874212701184054
Trained batch 12 in epoch 16, gen_loss = 0.37781162903859067, disc_loss = 0.07459283756235471
Trained batch 13 in epoch 16, gen_loss = 0.3770964060510908, disc_loss = 0.06996459866474782
Trained batch 14 in epoch 16, gen_loss = 0.38108034133911134, disc_loss = 0.06699763940026363
Trained batch 15 in epoch 16, gen_loss = 0.3819127567112446, disc_loss = 0.06398846086813137
Trained batch 16 in epoch 16, gen_loss = 0.3839927473488976, disc_loss = 0.06252852909486084
Trained batch 17 in epoch 16, gen_loss = 0.3836740172571606, disc_loss = 0.06741317646164033
Trained batch 18 in epoch 16, gen_loss = 0.3894895032832497, disc_loss = 0.08013773939915393
Trained batch 19 in epoch 16, gen_loss = 0.39087592661380766, disc_loss = 0.07844582139514386
Trained batch 20 in epoch 16, gen_loss = 0.3869602055776687, disc_loss = 0.07804114810590233
Trained batch 21 in epoch 16, gen_loss = 0.38892135430466046, disc_loss = 0.07676758358932355
Trained batch 22 in epoch 16, gen_loss = 0.39097431690796564, disc_loss = 0.07629033967690624
Trained batch 23 in epoch 16, gen_loss = 0.39068131645520526, disc_loss = 0.07401161613718917
Trained batch 24 in epoch 16, gen_loss = 0.3912527906894684, disc_loss = 0.07240730304270983
Trained batch 25 in epoch 16, gen_loss = 0.39404728894050306, disc_loss = 0.07094354587248884
Trained batch 26 in epoch 16, gen_loss = 0.3943197970037107, disc_loss = 0.07122745920248606
Trained batch 27 in epoch 16, gen_loss = 0.3909747472831181, disc_loss = 0.07194873614103667
Trained batch 28 in epoch 16, gen_loss = 0.3946048041869854, disc_loss = 0.07128075333633299
Trained batch 29 in epoch 16, gen_loss = 0.3971481641133626, disc_loss = 0.07472273412471016
Trained batch 30 in epoch 16, gen_loss = 0.39796758947833893, disc_loss = 0.0781918048197704
Trained batch 31 in epoch 16, gen_loss = 0.3995241476222873, disc_loss = 0.07705949727096595
Trained batch 32 in epoch 16, gen_loss = 0.40008301355622033, disc_loss = 0.07524497414741552
Trained batch 33 in epoch 16, gen_loss = 0.40010853637667265, disc_loss = 0.07356953831827816
Trained batch 34 in epoch 16, gen_loss = 0.4005416895662035, disc_loss = 0.07395746572209257
Trained batch 35 in epoch 16, gen_loss = 0.39788752959834206, disc_loss = 0.07407068349938425
Trained batch 36 in epoch 16, gen_loss = 0.3967263175023569, disc_loss = 0.0724950266901303
Trained batch 37 in epoch 16, gen_loss = 0.39767861836834956, disc_loss = 0.07109584343178492
Trained batch 38 in epoch 16, gen_loss = 0.3967430347051376, disc_loss = 0.07077744868225776
Trained batch 39 in epoch 16, gen_loss = 0.39443831965327264, disc_loss = 0.07046779112424702
Trained batch 40 in epoch 16, gen_loss = 0.3954568556169184, disc_loss = 0.0695320751018277
Trained batch 41 in epoch 16, gen_loss = 0.39715386004675, disc_loss = 0.0682613085733638
Trained batch 42 in epoch 16, gen_loss = 0.39812770624493443, disc_loss = 0.06778497766530098
Trained batch 43 in epoch 16, gen_loss = 0.3975690400058573, disc_loss = 0.06661539222113788
Trained batch 44 in epoch 16, gen_loss = 0.39880353742175634, disc_loss = 0.06593718092060752
Trained batch 45 in epoch 16, gen_loss = 0.39978058441825537, disc_loss = 0.06470728031886012
Trained batch 46 in epoch 16, gen_loss = 0.3996573033485007, disc_loss = 0.06393717845624432
Trained batch 47 in epoch 16, gen_loss = 0.39887847440938157, disc_loss = 0.06301644846098498
Trained batch 48 in epoch 16, gen_loss = 0.3994017656968564, disc_loss = 0.0627238548037653
Trained batch 49 in epoch 16, gen_loss = 0.40136235594749453, disc_loss = 0.0618173867277801
Trained batch 50 in epoch 16, gen_loss = 0.40262038509051007, disc_loss = 0.062005999023277386
Trained batch 51 in epoch 16, gen_loss = 0.4025204089971689, disc_loss = 0.06263841944746673
Trained batch 52 in epoch 16, gen_loss = 0.40393432356276604, disc_loss = 0.061673111704020005
Trained batch 53 in epoch 16, gen_loss = 0.40332348368786, disc_loss = 0.06110610862917922
Trained batch 54 in epoch 16, gen_loss = 0.40336580384861337, disc_loss = 0.06024573836475611
Trained batch 55 in epoch 16, gen_loss = 0.4020044111779758, disc_loss = 0.059828811375025125
Trained batch 56 in epoch 16, gen_loss = 0.40212966736994293, disc_loss = 0.058953905625170784
Trained batch 57 in epoch 16, gen_loss = 0.4032882750034332, disc_loss = 0.05839188825660225
Trained batch 58 in epoch 16, gen_loss = 0.4021528893608158, disc_loss = 0.05804425602684082
Trained batch 59 in epoch 16, gen_loss = 0.4023098826408386, disc_loss = 0.057328722331052025
Trained batch 60 in epoch 16, gen_loss = 0.40185408269772765, disc_loss = 0.05985437158006625
Trained batch 61 in epoch 16, gen_loss = 0.4011006263955947, disc_loss = 0.06116944619063889
Trained batch 62 in epoch 16, gen_loss = 0.40136254401434035, disc_loss = 0.06190765053329487
Trained batch 63 in epoch 16, gen_loss = 0.40165475849062204, disc_loss = 0.061901598892291076
Trained batch 64 in epoch 16, gen_loss = 0.4027044653892517, disc_loss = 0.06114882308130081
Trained batch 65 in epoch 16, gen_loss = 0.4029271620692629, disc_loss = 0.06045032941708059
Trained batch 66 in epoch 16, gen_loss = 0.40303564516466056, disc_loss = 0.05978688753362912
Trained batch 67 in epoch 16, gen_loss = 0.40358898306594176, disc_loss = 0.05951098911464214
Trained batch 68 in epoch 16, gen_loss = 0.4025786544965661, disc_loss = 0.059836060132669365
Trained batch 69 in epoch 16, gen_loss = 0.40376597217151095, disc_loss = 0.06322661670190947
Trained batch 70 in epoch 16, gen_loss = 0.4043645124200364, disc_loss = 0.06268022471750287
Trained batch 71 in epoch 16, gen_loss = 0.40498942509293556, disc_loss = 0.06270961618671815
Trained batch 72 in epoch 16, gen_loss = 0.4041993548608806, disc_loss = 0.062171261298329866
Trained batch 73 in epoch 16, gen_loss = 0.4046680089589712, disc_loss = 0.0625216128254259
Trained batch 74 in epoch 16, gen_loss = 0.4040047605832418, disc_loss = 0.06203071018060048
Trained batch 75 in epoch 16, gen_loss = 0.4033475122169444, disc_loss = 0.06298613587492391
Trained batch 76 in epoch 16, gen_loss = 0.40389318706153277, disc_loss = 0.06431764267481767
Trained batch 77 in epoch 16, gen_loss = 0.40528918955570614, disc_loss = 0.06380638912415658
Trained batch 78 in epoch 16, gen_loss = 0.40439868011052094, disc_loss = 0.06380413503303559
Trained batch 79 in epoch 16, gen_loss = 0.40442662350833414, disc_loss = 0.06318096281029284
Trained batch 80 in epoch 16, gen_loss = 0.4043789899643557, disc_loss = 0.06281836059542349
Trained batch 81 in epoch 16, gen_loss = 0.4040332323894268, disc_loss = 0.06222851476745635
Trained batch 82 in epoch 16, gen_loss = 0.40357762108366174, disc_loss = 0.061657950663602495
Trained batch 83 in epoch 16, gen_loss = 0.4028268779317538, disc_loss = 0.06135536377717342
Trained batch 84 in epoch 16, gen_loss = 0.4023963777457967, disc_loss = 0.06075377391979975
Trained batch 85 in epoch 16, gen_loss = 0.40317831136459525, disc_loss = 0.06097593346913887
Trained batch 86 in epoch 16, gen_loss = 0.40289565167207825, disc_loss = 0.061470997209350266
Trained batch 87 in epoch 16, gen_loss = 0.40288095481016417, disc_loss = 0.060868535677648404
Trained batch 88 in epoch 16, gen_loss = 0.40365891342752436, disc_loss = 0.06090213322823637
Trained batch 89 in epoch 16, gen_loss = 0.4033732013569938, disc_loss = 0.06157822226070696
Trained batch 90 in epoch 16, gen_loss = 0.40363880140440805, disc_loss = 0.0616535167568005
Trained batch 91 in epoch 16, gen_loss = 0.40429702887068625, disc_loss = 0.06116506390516525
Trained batch 92 in epoch 16, gen_loss = 0.40401896385736363, disc_loss = 0.06081254389737883
Trained batch 93 in epoch 16, gen_loss = 0.4039180681426474, disc_loss = 0.060338576225207205
Trained batch 94 in epoch 16, gen_loss = 0.4038278485599317, disc_loss = 0.060076920884220224
Trained batch 95 in epoch 16, gen_loss = 0.40305006969720125, disc_loss = 0.0598639683254684
Trained batch 96 in epoch 16, gen_loss = 0.4029295868480328, disc_loss = 0.05944453905691806
Trained batch 97 in epoch 16, gen_loss = 0.40283575076229716, disc_loss = 0.05902005941131894
Trained batch 98 in epoch 16, gen_loss = 0.4029131525694722, disc_loss = 0.05859625648067455
Trained batch 99 in epoch 16, gen_loss = 0.40338466942310336, disc_loss = 0.05846851874142885
Trained batch 100 in epoch 16, gen_loss = 0.4044849642432562, disc_loss = 0.058048978300377876
Trained batch 101 in epoch 16, gen_loss = 0.404787122911098, disc_loss = 0.05840312711456243
Trained batch 102 in epoch 16, gen_loss = 0.4039288976238769, disc_loss = 0.059067797385951845
Trained batch 103 in epoch 16, gen_loss = 0.40395783403745067, disc_loss = 0.059085666631849915
Trained batch 104 in epoch 16, gen_loss = 0.40446609400567557, disc_loss = 0.05861042123287916
Trained batch 105 in epoch 16, gen_loss = 0.4041296825656351, disc_loss = 0.05813826876253171
Trained batch 106 in epoch 16, gen_loss = 0.4041604597434819, disc_loss = 0.057707159832189575
Trained batch 107 in epoch 16, gen_loss = 0.4048051654740616, disc_loss = 0.057275860441020794
Trained batch 108 in epoch 16, gen_loss = 0.40547732885824433, disc_loss = 0.056909570735323864
Trained batch 109 in epoch 16, gen_loss = 0.40545125712047925, disc_loss = 0.05693519631062042
Trained batch 110 in epoch 16, gen_loss = 0.4050932744064847, disc_loss = 0.058032993134950195
Trained batch 111 in epoch 16, gen_loss = 0.40453291604561464, disc_loss = 0.059832377234540345
Trained batch 112 in epoch 16, gen_loss = 0.40448405441984664, disc_loss = 0.05969902926610898
Trained batch 113 in epoch 16, gen_loss = 0.40529419586323856, disc_loss = 0.060326453241143836
Trained batch 114 in epoch 16, gen_loss = 0.40526218077410825, disc_loss = 0.059999101082591905
Trained batch 115 in epoch 16, gen_loss = 0.40504534028727435, disc_loss = 0.06014897561118264
Trained batch 116 in epoch 16, gen_loss = 0.4055924711064396, disc_loss = 0.059950000574637174
Trained batch 117 in epoch 16, gen_loss = 0.4056931398177551, disc_loss = 0.0600884584473225
Trained batch 118 in epoch 16, gen_loss = 0.404648748265595, disc_loss = 0.06150602917930409
Trained batch 119 in epoch 16, gen_loss = 0.40487906684478125, disc_loss = 0.06111637100111693
Trained batch 120 in epoch 16, gen_loss = 0.4054551112257745, disc_loss = 0.06074453440056113
Trained batch 121 in epoch 16, gen_loss = 0.40580503837984117, disc_loss = 0.060408665302408036
Trained batch 122 in epoch 16, gen_loss = 0.40558502102285865, disc_loss = 0.06047947381479227
Trained batch 123 in epoch 16, gen_loss = 0.4054507908801879, disc_loss = 0.06171020376496017
Trained batch 124 in epoch 16, gen_loss = 0.40464123129844665, disc_loss = 0.06301470462232828
Trained batch 125 in epoch 16, gen_loss = 0.40438145777535817, disc_loss = 0.06320423193068968
Trained batch 126 in epoch 16, gen_loss = 0.404828795297878, disc_loss = 0.06323098993354191
Trained batch 127 in epoch 16, gen_loss = 0.4047405489254743, disc_loss = 0.06371083649719367
Trained batch 128 in epoch 16, gen_loss = 0.404809822176778, disc_loss = 0.06341889175016058
Trained batch 129 in epoch 16, gen_loss = 0.40507775705594284, disc_loss = 0.06306256317318631
Trained batch 130 in epoch 16, gen_loss = 0.40417366446429537, disc_loss = 0.063287238220734
Trained batch 131 in epoch 16, gen_loss = 0.4050110090862621, disc_loss = 0.06426598332737657
Trained batch 132 in epoch 16, gen_loss = 0.40443053326212375, disc_loss = 0.06436341567511174
Trained batch 133 in epoch 16, gen_loss = 0.40437760993615907, disc_loss = 0.0640093288384378
Trained batch 134 in epoch 16, gen_loss = 0.40390832512466995, disc_loss = 0.06377019775272519
Trained batch 135 in epoch 16, gen_loss = 0.4035304854897892, disc_loss = 0.06368220737888752
Trained batch 136 in epoch 16, gen_loss = 0.40330546245957816, disc_loss = 0.06505276891572849
Trained batch 137 in epoch 16, gen_loss = 0.40274533154307934, disc_loss = 0.0665425039301424
Trained batch 138 in epoch 16, gen_loss = 0.4028680847703124, disc_loss = 0.06667631691013523
Trained batch 139 in epoch 16, gen_loss = 0.4033391690679959, disc_loss = 0.06637528446236891
Trained batch 140 in epoch 16, gen_loss = 0.40322153893768364, disc_loss = 0.06614293716187385
Trained batch 141 in epoch 16, gen_loss = 0.4030249578432298, disc_loss = 0.06580817723699228
Trained batch 142 in epoch 16, gen_loss = 0.40237898093003494, disc_loss = 0.06553621743186995
Trained batch 143 in epoch 16, gen_loss = 0.4021867985526721, disc_loss = 0.06515550269978121
Trained batch 144 in epoch 16, gen_loss = 0.4028815006387645, disc_loss = 0.06521737738030738
Trained batch 145 in epoch 16, gen_loss = 0.40250308668776735, disc_loss = 0.06692956406495547
Trained batch 146 in epoch 16, gen_loss = 0.4032275834862067, disc_loss = 0.06719532029285115
Trained batch 147 in epoch 16, gen_loss = 0.403434362765905, disc_loss = 0.0669870869999097
Trained batch 148 in epoch 16, gen_loss = 0.4036224852472344, disc_loss = 0.06686001909184176
Trained batch 149 in epoch 16, gen_loss = 0.40353880286216737, disc_loss = 0.06665291804199418
Trained batch 150 in epoch 16, gen_loss = 0.4038911692748796, disc_loss = 0.06645158750455309
Trained batch 151 in epoch 16, gen_loss = 0.40394125329820735, disc_loss = 0.06614756126471452
Trained batch 152 in epoch 16, gen_loss = 0.4037025169609419, disc_loss = 0.06584286679410273
Trained batch 153 in epoch 16, gen_loss = 0.4036031837587233, disc_loss = 0.06575421148959498
Trained batch 154 in epoch 16, gen_loss = 0.4038482158414779, disc_loss = 0.06540982559803993
Trained batch 155 in epoch 16, gen_loss = 0.4040577593140113, disc_loss = 0.06528920995501372
Trained batch 156 in epoch 16, gen_loss = 0.4038651019904264, disc_loss = 0.06528554064263205
Trained batch 157 in epoch 16, gen_loss = 0.4036767999582653, disc_loss = 0.06544055709544616
Trained batch 158 in epoch 16, gen_loss = 0.4037619540526432, disc_loss = 0.06515182882734814
Trained batch 159 in epoch 16, gen_loss = 0.4038548653945327, disc_loss = 0.06478406252572314
Trained batch 160 in epoch 16, gen_loss = 0.40428386878523026, disc_loss = 0.06452412074952392
Trained batch 161 in epoch 16, gen_loss = 0.4039785961310069, disc_loss = 0.06431287674256313
Trained batch 162 in epoch 16, gen_loss = 0.4042412682544966, disc_loss = 0.06404641612312911
Trained batch 163 in epoch 16, gen_loss = 0.4043904154039011, disc_loss = 0.06385101594894034
Trained batch 164 in epoch 16, gen_loss = 0.40475934960625387, disc_loss = 0.06366532750879274
Trained batch 165 in epoch 16, gen_loss = 0.40452291089368153, disc_loss = 0.06344459873500717
Trained batch 166 in epoch 16, gen_loss = 0.40504111144357097, disc_loss = 0.06410135233964392
Trained batch 167 in epoch 16, gen_loss = 0.40446675817171734, disc_loss = 0.06529868592596835
Trained batch 168 in epoch 16, gen_loss = 0.40453559865612954, disc_loss = 0.06515120120840312
Trained batch 169 in epoch 16, gen_loss = 0.40507660806179047, disc_loss = 0.0653423121856416
Trained batch 170 in epoch 16, gen_loss = 0.40568112856463384, disc_loss = 0.0650829784136418
Trained batch 171 in epoch 16, gen_loss = 0.4056165310186009, disc_loss = 0.06512126428356697
Trained batch 172 in epoch 16, gen_loss = 0.4059446202537228, disc_loss = 0.06502793287869134
Trained batch 173 in epoch 16, gen_loss = 0.4055942949549905, disc_loss = 0.06510078412448538
Trained batch 174 in epoch 16, gen_loss = 0.4052532652446202, disc_loss = 0.0663653835441385
Trained batch 175 in epoch 16, gen_loss = 0.40603471479632636, disc_loss = 0.06654207588342781
Trained batch 176 in epoch 16, gen_loss = 0.4061998320838152, disc_loss = 0.06641587951762529
Trained batch 177 in epoch 16, gen_loss = 0.40620406524518904, disc_loss = 0.06612164432999124
Trained batch 178 in epoch 16, gen_loss = 0.40586707029262736, disc_loss = 0.06597658352895155
Trained batch 179 in epoch 16, gen_loss = 0.4053283987773789, disc_loss = 0.06594538045012288
Trained batch 180 in epoch 16, gen_loss = 0.4055433510416779, disc_loss = 0.06593740494788022
Trained batch 181 in epoch 16, gen_loss = 0.40507754077623176, disc_loss = 0.06579674547026446
Trained batch 182 in epoch 16, gen_loss = 0.4047777584341706, disc_loss = 0.06644216778336978
Trained batch 183 in epoch 16, gen_loss = 0.40507314305590547, disc_loss = 0.06718533036663481
Trained batch 184 in epoch 16, gen_loss = 0.4051434782711235, disc_loss = 0.06696764330404836
Trained batch 185 in epoch 16, gen_loss = 0.404923279919932, disc_loss = 0.06701745616612576
Trained batch 186 in epoch 16, gen_loss = 0.40473903102033276, disc_loss = 0.06673839334697328
Trained batch 187 in epoch 16, gen_loss = 0.4049016346639775, disc_loss = 0.06650508063389583
Trained batch 188 in epoch 16, gen_loss = 0.4052594676219597, disc_loss = 0.0662316512710676
Trained batch 189 in epoch 16, gen_loss = 0.40532410364401966, disc_loss = 0.06598301883786917
Trained batch 190 in epoch 16, gen_loss = 0.40508261572628124, disc_loss = 0.06639684129174779
Trained batch 191 in epoch 16, gen_loss = 0.4047066255783041, disc_loss = 0.06818296893228155
Trained batch 192 in epoch 16, gen_loss = 0.4044893535307652, disc_loss = 0.06883104872248025
Trained batch 193 in epoch 16, gen_loss = 0.40446910246745826, disc_loss = 0.06934144663787686
Trained batch 194 in epoch 16, gen_loss = 0.4040695537359287, disc_loss = 0.06993611150254042
Trained batch 195 in epoch 16, gen_loss = 0.40361980911420314, disc_loss = 0.07040839863712994
Trained batch 196 in epoch 16, gen_loss = 0.4035028432528985, disc_loss = 0.07056757317014455
Trained batch 197 in epoch 16, gen_loss = 0.403352968921565, disc_loss = 0.07063914023603153
Trained batch 198 in epoch 16, gen_loss = 0.4031658997787303, disc_loss = 0.07079913161095962
Trained batch 199 in epoch 16, gen_loss = 0.4029596404731274, disc_loss = 0.07079901796765625
Trained batch 200 in epoch 16, gen_loss = 0.40283797822188383, disc_loss = 0.07095948815234561
Trained batch 201 in epoch 16, gen_loss = 0.4028183949170726, disc_loss = 0.07089363467317111
Trained batch 202 in epoch 16, gen_loss = 0.403052794962681, disc_loss = 0.07071559697279496
Trained batch 203 in epoch 16, gen_loss = 0.40327124487535626, disc_loss = 0.07048267784400605
Trained batch 204 in epoch 16, gen_loss = 0.4034290174158608, disc_loss = 0.07038976521935404
Trained batch 205 in epoch 16, gen_loss = 0.40316767585509034, disc_loss = 0.07036497603957224
Trained batch 206 in epoch 16, gen_loss = 0.4030850499436475, disc_loss = 0.07015573451124528
Trained batch 207 in epoch 16, gen_loss = 0.4027909223849957, disc_loss = 0.06997579714068426
Trained batch 208 in epoch 16, gen_loss = 0.4029164034784125, disc_loss = 0.06977992888058772
Trained batch 209 in epoch 16, gen_loss = 0.40320637410595306, disc_loss = 0.06949787595353665
Trained batch 210 in epoch 16, gen_loss = 0.40328427188769334, disc_loss = 0.06945544256612447
Trained batch 211 in epoch 16, gen_loss = 0.4038277416015571, disc_loss = 0.06966021103028841
Trained batch 212 in epoch 16, gen_loss = 0.4039910879213485, disc_loss = 0.07033637041409671
Trained batch 213 in epoch 16, gen_loss = 0.4044152326951517, disc_loss = 0.07019453114072714
Trained batch 214 in epoch 16, gen_loss = 0.40469397361888443, disc_loss = 0.0701982477853118
Trained batch 215 in epoch 16, gen_loss = 0.4049719704522027, disc_loss = 0.06992686676568594
Trained batch 216 in epoch 16, gen_loss = 0.4050061566763759, disc_loss = 0.06973458749718518
Trained batch 217 in epoch 16, gen_loss = 0.4050946057936467, disc_loss = 0.06955686162456597
Trained batch 218 in epoch 16, gen_loss = 0.4049249756826113, disc_loss = 0.0692820642186014
Trained batch 219 in epoch 16, gen_loss = 0.40450693721121006, disc_loss = 0.06906644205393439
Trained batch 220 in epoch 16, gen_loss = 0.40433946211413563, disc_loss = 0.0688509767015393
Trained batch 221 in epoch 16, gen_loss = 0.4042316473819114, disc_loss = 0.06878129801050097
Trained batch 222 in epoch 16, gen_loss = 0.4043511064063273, disc_loss = 0.06873828605769594
Trained batch 223 in epoch 16, gen_loss = 0.40407623244183405, disc_loss = 0.06887596438588973
Trained batch 224 in epoch 16, gen_loss = 0.4038368176089393, disc_loss = 0.06903757895446486
Trained batch 225 in epoch 16, gen_loss = 0.40387155616705395, disc_loss = 0.06978339621533466
Trained batch 226 in epoch 16, gen_loss = 0.40379645383305485, disc_loss = 0.06955496357581557
Trained batch 227 in epoch 16, gen_loss = 0.4035621332494836, disc_loss = 0.06969778845495168
Trained batch 228 in epoch 16, gen_loss = 0.4032548020500283, disc_loss = 0.06945406026959289
Trained batch 229 in epoch 16, gen_loss = 0.4031891724337702, disc_loss = 0.06918471673220072
Trained batch 230 in epoch 16, gen_loss = 0.40316072661123237, disc_loss = 0.0692407901406901
Trained batch 231 in epoch 16, gen_loss = 0.4033121967623974, disc_loss = 0.06913744085588781
Trained batch 232 in epoch 16, gen_loss = 0.4030749212007154, disc_loss = 0.06945357499484277
Trained batch 233 in epoch 16, gen_loss = 0.4034198583700718, disc_loss = 0.06981264104724376
Trained batch 234 in epoch 16, gen_loss = 0.4031138337673025, disc_loss = 0.06959742118029835
Trained batch 235 in epoch 16, gen_loss = 0.4033745654811293, disc_loss = 0.06934788294917887
Trained batch 236 in epoch 16, gen_loss = 0.40320345168375266, disc_loss = 0.06947198810983245
Trained batch 237 in epoch 16, gen_loss = 0.4033393156127769, disc_loss = 0.06970842081482108
Trained batch 238 in epoch 16, gen_loss = 0.403241040691671, disc_loss = 0.06962960309087918
Trained batch 239 in epoch 16, gen_loss = 0.4033486255755027, disc_loss = 0.06956482494521575
Trained batch 240 in epoch 16, gen_loss = 0.40309748770785037, disc_loss = 0.0694991323953935
Trained batch 241 in epoch 16, gen_loss = 0.4029659115332217, disc_loss = 0.069308083771905
Trained batch 242 in epoch 16, gen_loss = 0.40331312351756626, disc_loss = 0.06934770174255525
Trained batch 243 in epoch 16, gen_loss = 0.4031907118490485, disc_loss = 0.06956111015866465
Trained batch 244 in epoch 16, gen_loss = 0.40323722715280497, disc_loss = 0.06937893552097435
Trained batch 245 in epoch 16, gen_loss = 0.4033489744595396, disc_loss = 0.0691879625996287
Trained batch 246 in epoch 16, gen_loss = 0.4033948992669341, disc_loss = 0.0690101753177521
Trained batch 247 in epoch 16, gen_loss = 0.4034149047107466, disc_loss = 0.06880177251596545
Trained batch 248 in epoch 16, gen_loss = 0.40330013321585445, disc_loss = 0.0686952620800809
Trained batch 249 in epoch 16, gen_loss = 0.40351650738716127, disc_loss = 0.06869952503405512
Trained batch 250 in epoch 16, gen_loss = 0.403182544912475, disc_loss = 0.06884419808787594
Trained batch 251 in epoch 16, gen_loss = 0.4034655530537878, disc_loss = 0.06866468080977303
Trained batch 252 in epoch 16, gen_loss = 0.40346812059285614, disc_loss = 0.06876401888692509
Trained batch 253 in epoch 16, gen_loss = 0.4032758651521262, disc_loss = 0.06860783601392383
Trained batch 254 in epoch 16, gen_loss = 0.40319964628593596, disc_loss = 0.06862341468496358
Trained batch 255 in epoch 16, gen_loss = 0.4034555417019874, disc_loss = 0.06841720977354271
Trained batch 256 in epoch 16, gen_loss = 0.4036157036105946, disc_loss = 0.06820616478839679
Trained batch 257 in epoch 16, gen_loss = 0.40347675805868105, disc_loss = 0.06834698109454367
Trained batch 258 in epoch 16, gen_loss = 0.40334478296828546, disc_loss = 0.0690370601256698
Trained batch 259 in epoch 16, gen_loss = 0.40316883210952464, disc_loss = 0.06883254147027261
Trained batch 260 in epoch 16, gen_loss = 0.4034978481316475, disc_loss = 0.06921675028921716
Trained batch 261 in epoch 16, gen_loss = 0.40353606083920895, disc_loss = 0.06904984320840933
Trained batch 262 in epoch 16, gen_loss = 0.40333382190407, disc_loss = 0.0689166213860275
Trained batch 263 in epoch 16, gen_loss = 0.40321355708169215, disc_loss = 0.06871340090980414
Trained batch 264 in epoch 16, gen_loss = 0.40310934703305085, disc_loss = 0.06849599175401172
Trained batch 265 in epoch 16, gen_loss = 0.4030083936632128, disc_loss = 0.06828495985618267
Trained batch 266 in epoch 16, gen_loss = 0.40315512258015324, disc_loss = 0.06808977404762799
Trained batch 267 in epoch 16, gen_loss = 0.4032819136532385, disc_loss = 0.06790452791940865
Trained batch 268 in epoch 16, gen_loss = 0.40336761199851906, disc_loss = 0.06784413139540078
Trained batch 269 in epoch 16, gen_loss = 0.40317693761101475, disc_loss = 0.06768262200229974
Trained batch 270 in epoch 16, gen_loss = 0.4031313795225207, disc_loss = 0.06752393148818854
Trained batch 271 in epoch 16, gen_loss = 0.4031952869366197, disc_loss = 0.06732500732965384
Trained batch 272 in epoch 16, gen_loss = 0.40300063707016326, disc_loss = 0.0675976136614033
Trained batch 273 in epoch 16, gen_loss = 0.4030197643450577, disc_loss = 0.06850310061024978
Trained batch 274 in epoch 16, gen_loss = 0.4030583537708629, disc_loss = 0.06840823980386962
Trained batch 275 in epoch 16, gen_loss = 0.4032218007073886, disc_loss = 0.06825673674820396
Trained batch 276 in epoch 16, gen_loss = 0.4031385309214196, disc_loss = 0.06824855415137074
Trained batch 277 in epoch 16, gen_loss = 0.40317544973582675, disc_loss = 0.06838864173988055
Trained batch 278 in epoch 16, gen_loss = 0.4028934177318354, disc_loss = 0.06867490901267924
Trained batch 279 in epoch 16, gen_loss = 0.40308128307972635, disc_loss = 0.06849130951699668
Trained batch 280 in epoch 16, gen_loss = 0.40312803099163913, disc_loss = 0.06832678646041458
Trained batch 281 in epoch 16, gen_loss = 0.4031554829355673, disc_loss = 0.06813906961622654
Trained batch 282 in epoch 16, gen_loss = 0.40351264900116535, disc_loss = 0.06799189620174126
Trained batch 283 in epoch 16, gen_loss = 0.40319446474313736, disc_loss = 0.06817232214183297
Trained batch 284 in epoch 16, gen_loss = 0.40350025296211245, disc_loss = 0.06817005350042069
Trained batch 285 in epoch 16, gen_loss = 0.4035996647773089, disc_loss = 0.0679682122585787
Trained batch 286 in epoch 16, gen_loss = 0.4036238404308877, disc_loss = 0.06779878992321235
Trained batch 287 in epoch 16, gen_loss = 0.4038097471412685, disc_loss = 0.06763805824933418
Trained batch 288 in epoch 16, gen_loss = 0.4037727080414452, disc_loss = 0.06746659658778342
Trained batch 289 in epoch 16, gen_loss = 0.40372551340481333, disc_loss = 0.06732130325078194
Trained batch 290 in epoch 16, gen_loss = 0.40400790871213804, disc_loss = 0.06712297469063877
Trained batch 291 in epoch 16, gen_loss = 0.40369181845286123, disc_loss = 0.06697331951159269
Trained batch 292 in epoch 16, gen_loss = 0.40339908054664275, disc_loss = 0.06679940638656859
Trained batch 293 in epoch 16, gen_loss = 0.4035319014876878, disc_loss = 0.06670147097403449
Trained batch 294 in epoch 16, gen_loss = 0.4033151826616061, disc_loss = 0.06667368488259992
Trained batch 295 in epoch 16, gen_loss = 0.4034836737288011, disc_loss = 0.06663636088440497
Trained batch 296 in epoch 16, gen_loss = 0.4033782316578759, disc_loss = 0.0664657712882692
Trained batch 297 in epoch 16, gen_loss = 0.4033959429936121, disc_loss = 0.06632798979365136
Trained batch 298 in epoch 16, gen_loss = 0.4036517914721001, disc_loss = 0.06617060436845373
Trained batch 299 in epoch 16, gen_loss = 0.40367453575134277, disc_loss = 0.06596895935945213
Trained batch 300 in epoch 16, gen_loss = 0.40358111173211536, disc_loss = 0.06588893272663371
Trained batch 301 in epoch 16, gen_loss = 0.4034542761101628, disc_loss = 0.0659949152409685
Trained batch 302 in epoch 16, gen_loss = 0.40355865672083185, disc_loss = 0.06599905897890872
Trained batch 303 in epoch 16, gen_loss = 0.40362794442396416, disc_loss = 0.06583815755775983
Trained batch 304 in epoch 16, gen_loss = 0.40339533491212815, disc_loss = 0.0659938751826765
Trained batch 305 in epoch 16, gen_loss = 0.4036628661397236, disc_loss = 0.06609288977118197
Trained batch 306 in epoch 16, gen_loss = 0.4037495977715483, disc_loss = 0.0659376730390063
Trained batch 307 in epoch 16, gen_loss = 0.40382258342458055, disc_loss = 0.06579499291074643
Trained batch 308 in epoch 16, gen_loss = 0.40371213221627145, disc_loss = 0.06569936431184845
Trained batch 309 in epoch 16, gen_loss = 0.4036058792183476, disc_loss = 0.06552452904983394
Trained batch 310 in epoch 16, gen_loss = 0.4035660192322501, disc_loss = 0.06537875188424752
Trained batch 311 in epoch 16, gen_loss = 0.40335085768348133, disc_loss = 0.06533985067075357
Trained batch 312 in epoch 16, gen_loss = 0.4034321373834397, disc_loss = 0.06594570954969992
Trained batch 313 in epoch 16, gen_loss = 0.4032938412040662, disc_loss = 0.0658956845884158
Trained batch 314 in epoch 16, gen_loss = 0.4029674048461611, disc_loss = 0.0661160496994853
Trained batch 315 in epoch 16, gen_loss = 0.40319314589606053, disc_loss = 0.0671323171457205
Trained batch 316 in epoch 16, gen_loss = 0.40304594103846264, disc_loss = 0.0673326875820568
Trained batch 317 in epoch 16, gen_loss = 0.40287690155161254, disc_loss = 0.06757446828608711
Trained batch 318 in epoch 16, gen_loss = 0.40257357224401635, disc_loss = 0.06767046844242228
Trained batch 319 in epoch 16, gen_loss = 0.402683905698359, disc_loss = 0.06845783768512774
Trained batch 320 in epoch 16, gen_loss = 0.40257558105890623, disc_loss = 0.06861382690650002
Trained batch 321 in epoch 16, gen_loss = 0.40275432687738666, disc_loss = 0.06891871873370331
Trained batch 322 in epoch 16, gen_loss = 0.40256944833894265, disc_loss = 0.0691650066057641
Trained batch 323 in epoch 16, gen_loss = 0.40241470408660396, disc_loss = 0.06940778087606125
Trained batch 324 in epoch 16, gen_loss = 0.4022842154136071, disc_loss = 0.0695971480728342
Trained batch 325 in epoch 16, gen_loss = 0.401984298156083, disc_loss = 0.06952502651917149
Trained batch 326 in epoch 16, gen_loss = 0.4021016016648086, disc_loss = 0.06944326906314045
Trained batch 327 in epoch 16, gen_loss = 0.40192009908397025, disc_loss = 0.06939478754917751
Trained batch 328 in epoch 16, gen_loss = 0.40156107216982856, disc_loss = 0.06966971132994876
Trained batch 329 in epoch 16, gen_loss = 0.401693598429362, disc_loss = 0.0703704605076575
Trained batch 330 in epoch 16, gen_loss = 0.40155290530887616, disc_loss = 0.07023413550513839
Trained batch 331 in epoch 16, gen_loss = 0.4014950465545597, disc_loss = 0.0701518412146448
Trained batch 332 in epoch 16, gen_loss = 0.4013228220445616, disc_loss = 0.07019704201345418
Trained batch 333 in epoch 16, gen_loss = 0.4014359113877405, disc_loss = 0.07006304460427093
Trained batch 334 in epoch 16, gen_loss = 0.4013610672594896, disc_loss = 0.0699659494905552
Trained batch 335 in epoch 16, gen_loss = 0.401463485278544, disc_loss = 0.06985894746113834
Trained batch 336 in epoch 16, gen_loss = 0.4013031029559738, disc_loss = 0.06970756167949396
Trained batch 337 in epoch 16, gen_loss = 0.40149589773465894, disc_loss = 0.06952388487623994
Trained batch 338 in epoch 16, gen_loss = 0.4014069071385713, disc_loss = 0.06941296843740441
Trained batch 339 in epoch 16, gen_loss = 0.4014040520086008, disc_loss = 0.06928446943707325
Trained batch 340 in epoch 16, gen_loss = 0.4013786746784389, disc_loss = 0.06925895327259718
Trained batch 341 in epoch 16, gen_loss = 0.4012665557756759, disc_loss = 0.06943740549753284
Trained batch 342 in epoch 16, gen_loss = 0.4013098168998696, disc_loss = 0.06946863032030294
Trained batch 343 in epoch 16, gen_loss = 0.40133979344783827, disc_loss = 0.0693413172307056
Trained batch 344 in epoch 16, gen_loss = 0.4015071487081224, disc_loss = 0.06919603844483693
Trained batch 345 in epoch 16, gen_loss = 0.40127532046309783, disc_loss = 0.06915475279523459
Trained batch 346 in epoch 16, gen_loss = 0.401544003991641, disc_loss = 0.06899541622881243
Trained batch 347 in epoch 16, gen_loss = 0.40185363633536747, disc_loss = 0.06898822701782331
Trained batch 348 in epoch 16, gen_loss = 0.40169780968253455, disc_loss = 0.0689343071321191
Trained batch 349 in epoch 16, gen_loss = 0.4018141357387815, disc_loss = 0.06878291723451443
Trained batch 350 in epoch 16, gen_loss = 0.4019195200541081, disc_loss = 0.06862397726487231
Trained batch 351 in epoch 16, gen_loss = 0.4021443175151944, disc_loss = 0.06846860913686793
Trained batch 352 in epoch 16, gen_loss = 0.4019884157282097, disc_loss = 0.06834393762917423
Trained batch 353 in epoch 16, gen_loss = 0.4022254636563824, disc_loss = 0.06819858869253578
Trained batch 354 in epoch 16, gen_loss = 0.40234762312660755, disc_loss = 0.0681449986784391
Trained batch 355 in epoch 16, gen_loss = 0.4024304829621583, disc_loss = 0.06808249827139498
Trained batch 356 in epoch 16, gen_loss = 0.4027555287719107, disc_loss = 0.06798925475120879
Trained batch 357 in epoch 16, gen_loss = 0.4027831942342513, disc_loss = 0.06792598520535663
Trained batch 358 in epoch 16, gen_loss = 0.4028370088189425, disc_loss = 0.06778314890220637
Trained batch 359 in epoch 16, gen_loss = 0.4028199576669269, disc_loss = 0.0676534483054032
Trained batch 360 in epoch 16, gen_loss = 0.40273769955225597, disc_loss = 0.06750664763524096
Trained batch 361 in epoch 16, gen_loss = 0.4029335034650992, disc_loss = 0.06738186306037132
Trained batch 362 in epoch 16, gen_loss = 0.40312963477836167, disc_loss = 0.06728142149459068
Trained batch 363 in epoch 16, gen_loss = 0.40300409168332485, disc_loss = 0.06716410745610739
Trained batch 364 in epoch 16, gen_loss = 0.4029247857119939, disc_loss = 0.0673677806933857
Trained batch 365 in epoch 16, gen_loss = 0.4031504249312187, disc_loss = 0.06814042132225681
Trained batch 366 in epoch 16, gen_loss = 0.4031915148207537, disc_loss = 0.06798692812194047
Trained batch 367 in epoch 16, gen_loss = 0.4030438967696998, disc_loss = 0.06789043537877582
Trained batch 368 in epoch 16, gen_loss = 0.4029722636954248, disc_loss = 0.06777733470739791
Trained batch 369 in epoch 16, gen_loss = 0.40315586699021827, disc_loss = 0.06762415718136204
Trained batch 370 in epoch 16, gen_loss = 0.40315042432106407, disc_loss = 0.06749777255122955
Trained batch 371 in epoch 16, gen_loss = 0.40308706053803045, disc_loss = 0.067408242155247
Trained batch 372 in epoch 16, gen_loss = 0.4028685883926003, disc_loss = 0.06731746660610387
Trained batch 373 in epoch 16, gen_loss = 0.4026666982448037, disc_loss = 0.06738085801000981
Trained batch 374 in epoch 16, gen_loss = 0.40272489007314044, disc_loss = 0.06743257327129444
Trained batch 375 in epoch 16, gen_loss = 0.4027732089954488, disc_loss = 0.06728754031095416
Trained batch 376 in epoch 16, gen_loss = 0.4027044624485451, disc_loss = 0.0671523585223867
Trained batch 377 in epoch 16, gen_loss = 0.40257927199835497, disc_loss = 0.06704587465713895
Trained batch 378 in epoch 16, gen_loss = 0.4025652207296568, disc_loss = 0.06691475522195758
Trained batch 379 in epoch 16, gen_loss = 0.4022397129159225, disc_loss = 0.06725564005931742
Trained batch 380 in epoch 16, gen_loss = 0.4024589434070537, disc_loss = 0.06802315054720467
Trained batch 381 in epoch 16, gen_loss = 0.4024524026360187, disc_loss = 0.06788516216253111
Trained batch 382 in epoch 16, gen_loss = 0.40245525114841313, disc_loss = 0.0679404874850191
Trained batch 383 in epoch 16, gen_loss = 0.4024388644999514, disc_loss = 0.06786171334291187
Trained batch 384 in epoch 16, gen_loss = 0.402504601571467, disc_loss = 0.06787233423296507
Trained batch 385 in epoch 16, gen_loss = 0.4025585158038016, disc_loss = 0.06775615571809865
Trained batch 386 in epoch 16, gen_loss = 0.402669180348246, disc_loss = 0.06769922133101973
Trained batch 387 in epoch 16, gen_loss = 0.4027125765521502, disc_loss = 0.06758031775195573
Trained batch 388 in epoch 16, gen_loss = 0.40287414231459706, disc_loss = 0.06745907878335614
Trained batch 389 in epoch 16, gen_loss = 0.4029755033743687, disc_loss = 0.0673741402868659
Trained batch 390 in epoch 16, gen_loss = 0.4029593463139156, disc_loss = 0.06734031726084554
Trained batch 391 in epoch 16, gen_loss = 0.40310302361541867, disc_loss = 0.06726758992204404
Trained batch 392 in epoch 16, gen_loss = 0.40309362966595713, disc_loss = 0.06714105766276063
Trained batch 393 in epoch 16, gen_loss = 0.40309421339918516, disc_loss = 0.0671509511787728
Trained batch 394 in epoch 16, gen_loss = 0.40322872060763687, disc_loss = 0.06724442099279995
Trained batch 395 in epoch 16, gen_loss = 0.40326866183919136, disc_loss = 0.0672787989800175
Trained batch 396 in epoch 16, gen_loss = 0.4035051902685718, disc_loss = 0.06713523863526226
Trained batch 397 in epoch 16, gen_loss = 0.4036847741609842, disc_loss = 0.0669902336020865
Trained batch 398 in epoch 16, gen_loss = 0.40379003370017336, disc_loss = 0.06683653678726358
Trained batch 399 in epoch 16, gen_loss = 0.4037510950863361, disc_loss = 0.06671073787612841
Trained batch 400 in epoch 16, gen_loss = 0.4034538017098149, disc_loss = 0.06675188790337923
Trained batch 401 in epoch 16, gen_loss = 0.4031577023552425, disc_loss = 0.06732099819048053
Trained batch 402 in epoch 16, gen_loss = 0.40324920016541965, disc_loss = 0.06760984253156792
Trained batch 403 in epoch 16, gen_loss = 0.40313859018358855, disc_loss = 0.06754211152645548
Trained batch 404 in epoch 16, gen_loss = 0.402830649158101, disc_loss = 0.06755169045731978
Trained batch 405 in epoch 16, gen_loss = 0.40283026623314827, disc_loss = 0.06753212856495835
Trained batch 406 in epoch 16, gen_loss = 0.4028293844083603, disc_loss = 0.06751019061664325
Trained batch 407 in epoch 16, gen_loss = 0.40284131087508857, disc_loss = 0.06749860157815776
Trained batch 408 in epoch 16, gen_loss = 0.40277775721328474, disc_loss = 0.06741445955836321
Trained batch 409 in epoch 16, gen_loss = 0.4027456719700883, disc_loss = 0.06745343129945601
Trained batch 410 in epoch 16, gen_loss = 0.4025707624109412, disc_loss = 0.06766484382079684
Trained batch 411 in epoch 16, gen_loss = 0.40263455599835773, disc_loss = 0.06803424719458862
Trained batch 412 in epoch 16, gen_loss = 0.40272175428653745, disc_loss = 0.0680334171298305
Trained batch 413 in epoch 16, gen_loss = 0.4025738998023784, disc_loss = 0.06804899187254661
Trained batch 414 in epoch 16, gen_loss = 0.4025406244289444, disc_loss = 0.06804947991103652
Trained batch 415 in epoch 16, gen_loss = 0.40248083079663605, disc_loss = 0.06806288607409582
Trained batch 416 in epoch 16, gen_loss = 0.40272428506284025, disc_loss = 0.06805086703814692
Trained batch 417 in epoch 16, gen_loss = 0.40276388410461006, disc_loss = 0.06797385670057537
Trained batch 418 in epoch 16, gen_loss = 0.40260002792308325, disc_loss = 0.06787235253581639
Trained batch 419 in epoch 16, gen_loss = 0.4023445627519063, disc_loss = 0.06782869147802038
Trained batch 420 in epoch 16, gen_loss = 0.4021662685338788, disc_loss = 0.0677242902861886
Trained batch 421 in epoch 16, gen_loss = 0.40204908864758027, disc_loss = 0.06764936055855658
Trained batch 422 in epoch 16, gen_loss = 0.4018870449798891, disc_loss = 0.06759499818148272
Trained batch 423 in epoch 16, gen_loss = 0.40203014494113204, disc_loss = 0.06757649417114356
Trained batch 424 in epoch 16, gen_loss = 0.4019667565822601, disc_loss = 0.06754056474522632
Trained batch 425 in epoch 16, gen_loss = 0.4019047953713108, disc_loss = 0.06760542000044889
Trained batch 426 in epoch 16, gen_loss = 0.40192832279540336, disc_loss = 0.06765086850940971
Trained batch 427 in epoch 16, gen_loss = 0.40193494722664913, disc_loss = 0.06751661621921948
Trained batch 428 in epoch 16, gen_loss = 0.4021091440340856, disc_loss = 0.06744127434467798
Trained batch 429 in epoch 16, gen_loss = 0.4020751949659614, disc_loss = 0.06732424909985343
Trained batch 430 in epoch 16, gen_loss = 0.4019189521912356, disc_loss = 0.0673479577677709
Trained batch 431 in epoch 16, gen_loss = 0.40191338445853303, disc_loss = 0.0672873893097319
Trained batch 432 in epoch 16, gen_loss = 0.40201634767424427, disc_loss = 0.0671804688406321
Trained batch 433 in epoch 16, gen_loss = 0.4018757539685421, disc_loss = 0.06710983569892595
Trained batch 434 in epoch 16, gen_loss = 0.4019830709901349, disc_loss = 0.06698503765737873
Trained batch 435 in epoch 16, gen_loss = 0.4020791994322331, disc_loss = 0.06691036150372083
Trained batch 436 in epoch 16, gen_loss = 0.40192909276185373, disc_loss = 0.06681875790761319
Trained batch 437 in epoch 16, gen_loss = 0.4018727624661302, disc_loss = 0.06671858754128082
Trained batch 438 in epoch 16, gen_loss = 0.40191654497778767, disc_loss = 0.06658598559363353
Trained batch 439 in epoch 16, gen_loss = 0.4018190251155333, disc_loss = 0.06648290563501756
Trained batch 440 in epoch 16, gen_loss = 0.40183292589490377, disc_loss = 0.06640995915370937
Trained batch 441 in epoch 16, gen_loss = 0.4015872794039109, disc_loss = 0.0664357059019959
Trained batch 442 in epoch 16, gen_loss = 0.40184934440638626, disc_loss = 0.06650586269636119
Trained batch 443 in epoch 16, gen_loss = 0.40184833800738995, disc_loss = 0.06637408708742408
Trained batch 444 in epoch 16, gen_loss = 0.40173105115301155, disc_loss = 0.0663187083924252
Trained batch 445 in epoch 16, gen_loss = 0.4016887234198138, disc_loss = 0.06619319418077713
Trained batch 446 in epoch 16, gen_loss = 0.4016311618039005, disc_loss = 0.0660827509012965
Trained batch 447 in epoch 16, gen_loss = 0.4016526537016034, disc_loss = 0.06596227426156734
Trained batch 448 in epoch 16, gen_loss = 0.4015706285071001, disc_loss = 0.06589758953905119
Trained batch 449 in epoch 16, gen_loss = 0.4015746392144097, disc_loss = 0.06599285851129227
Trained batch 450 in epoch 16, gen_loss = 0.4015952648714746, disc_loss = 0.06605433463067345
Trained batch 451 in epoch 16, gen_loss = 0.40169079931436386, disc_loss = 0.06593645037052971
Trained batch 452 in epoch 16, gen_loss = 0.4017949995089314, disc_loss = 0.06593192325366319
Trained batch 453 in epoch 16, gen_loss = 0.40161997394939875, disc_loss = 0.06606363663696048
Trained batch 454 in epoch 16, gen_loss = 0.40172020085565335, disc_loss = 0.06607082768824402
Trained batch 455 in epoch 16, gen_loss = 0.4015355863069233, disc_loss = 0.0659754523627558
Trained batch 456 in epoch 16, gen_loss = 0.4014852280428947, disc_loss = 0.06591261991582957
Trained batch 457 in epoch 16, gen_loss = 0.4014503267394403, disc_loss = 0.06578948436402533
Trained batch 458 in epoch 16, gen_loss = 0.4014487898947107, disc_loss = 0.06574774117762941
Trained batch 459 in epoch 16, gen_loss = 0.40117917993794316, disc_loss = 0.06588652320003704
Trained batch 460 in epoch 16, gen_loss = 0.40112855228839883, disc_loss = 0.06607816636424972
Testing Epoch 16
Training Epoch 17
Trained batch 0 in epoch 17, gen_loss = 0.37735888361930847, disc_loss = 0.02242688462138176
Trained batch 1 in epoch 17, gen_loss = 0.36817945539951324, disc_loss = 0.06561030633747578
Trained batch 2 in epoch 17, gen_loss = 0.39635075132052106, disc_loss = 0.1113908402621746
Trained batch 3 in epoch 17, gen_loss = 0.4096798673272133, disc_loss = 0.09009676799178123
Trained batch 4 in epoch 17, gen_loss = 0.399453341960907, disc_loss = 0.09169225245714188
Trained batch 5 in epoch 17, gen_loss = 0.39811956882476807, disc_loss = 0.08698200186093648
Trained batch 6 in epoch 17, gen_loss = 0.39396627034459797, disc_loss = 0.07734446227550507
Trained batch 7 in epoch 17, gen_loss = 0.3906618170440197, disc_loss = 0.07074167765676975
Trained batch 8 in epoch 17, gen_loss = 0.40275999241405064, disc_loss = 0.06568388806449042
Trained batch 9 in epoch 17, gen_loss = 0.39871861338615416, disc_loss = 0.06063602566719055
Trained batch 10 in epoch 17, gen_loss = 0.39394373243505304, disc_loss = 0.05689365687695416
Trained batch 11 in epoch 17, gen_loss = 0.3875960359970729, disc_loss = 0.05582402025659879
Trained batch 12 in epoch 17, gen_loss = 0.38980291669185346, disc_loss = 0.058618203951762274
Trained batch 13 in epoch 17, gen_loss = 0.37723501452377867, disc_loss = 0.07189312257937022
Trained batch 14 in epoch 17, gen_loss = 0.38031538128852843, disc_loss = 0.07554535567760468
Trained batch 15 in epoch 17, gen_loss = 0.38156587444245815, disc_loss = 0.07198017928749323
Trained batch 16 in epoch 17, gen_loss = 0.382607556441251, disc_loss = 0.07005476820118287
Trained batch 17 in epoch 17, gen_loss = 0.3808559477329254, disc_loss = 0.06823252182867792
Trained batch 18 in epoch 17, gen_loss = 0.38337222996510956, disc_loss = 0.06612132617125385
Trained batch 19 in epoch 17, gen_loss = 0.38204377293586733, disc_loss = 0.06315369410440326
Trained batch 20 in epoch 17, gen_loss = 0.3821856578191121, disc_loss = 0.06083431777854761
Trained batch 21 in epoch 17, gen_loss = 0.3837986263361844, disc_loss = 0.06101650279015303
Trained batch 22 in epoch 17, gen_loss = 0.3844025627426479, disc_loss = 0.06227909749292809
Trained batch 23 in epoch 17, gen_loss = 0.38097675889730453, disc_loss = 0.061373841405535735
Trained batch 24 in epoch 17, gen_loss = 0.38530912160873415, disc_loss = 0.06002854086458683
Trained batch 25 in epoch 17, gen_loss = 0.3850089426224048, disc_loss = 0.05857803221218861
Trained batch 26 in epoch 17, gen_loss = 0.3866602381070455, disc_loss = 0.057699138574578146
Trained batch 27 in epoch 17, gen_loss = 0.3904395731432097, disc_loss = 0.05832021863066724
Trained batch 28 in epoch 17, gen_loss = 0.39131661632965353, disc_loss = 0.058554103084165476
Trained batch 29 in epoch 17, gen_loss = 0.39440322120984395, disc_loss = 0.05842509561528762
Trained batch 30 in epoch 17, gen_loss = 0.3969030476385547, disc_loss = 0.05708044280688609
Trained batch 31 in epoch 17, gen_loss = 0.3973905760794878, disc_loss = 0.056463175860699266
Trained batch 32 in epoch 17, gen_loss = 0.3977582734642607, disc_loss = 0.05662288398227908
Trained batch 33 in epoch 17, gen_loss = 0.39631748111809, disc_loss = 0.05860728502054425
Trained batch 34 in epoch 17, gen_loss = 0.39843844941684176, disc_loss = 0.057936383304851395
Trained batch 35 in epoch 17, gen_loss = 0.3983738364444839, disc_loss = 0.05707065548954739
Trained batch 36 in epoch 17, gen_loss = 0.3975078745468243, disc_loss = 0.05653677110535067
Trained batch 37 in epoch 17, gen_loss = 0.3971440431318785, disc_loss = 0.055760549920562064
Trained batch 38 in epoch 17, gen_loss = 0.3966128612175966, disc_loss = 0.055181024118493766
Trained batch 39 in epoch 17, gen_loss = 0.39842052161693575, disc_loss = 0.05402710670605302
Trained batch 40 in epoch 17, gen_loss = 0.3974931123780041, disc_loss = 0.05426689064720782
Trained batch 41 in epoch 17, gen_loss = 0.3957624023868924, disc_loss = 0.05693391701650052
Trained batch 42 in epoch 17, gen_loss = 0.3965192492618117, disc_loss = 0.05814233812135319
Trained batch 43 in epoch 17, gen_loss = 0.39624485847624863, disc_loss = 0.057162726086310366
Trained batch 44 in epoch 17, gen_loss = 0.3944860948456658, disc_loss = 0.05802825039459599
Trained batch 45 in epoch 17, gen_loss = 0.3955137638942055, disc_loss = 0.05708324261333631
Trained batch 46 in epoch 17, gen_loss = 0.396860974266174, disc_loss = 0.056111015438874985
Trained batch 47 in epoch 17, gen_loss = 0.39739973098039627, disc_loss = 0.055987200137072556
Trained batch 48 in epoch 17, gen_loss = 0.39781250150836245, disc_loss = 0.05577685431178127
Trained batch 49 in epoch 17, gen_loss = 0.39763989925384524, disc_loss = 0.054961883574724195
Trained batch 50 in epoch 17, gen_loss = 0.3988476004086289, disc_loss = 0.05534886583393695
Trained batch 51 in epoch 17, gen_loss = 0.39841752843214917, disc_loss = 0.055146379969440974
Trained batch 52 in epoch 17, gen_loss = 0.39991694745027795, disc_loss = 0.05423766825312994
Trained batch 53 in epoch 17, gen_loss = 0.4007819179031584, disc_loss = 0.05348431747579188
Trained batch 54 in epoch 17, gen_loss = 0.4001694511283528, disc_loss = 0.052921157474206254
Trained batch 55 in epoch 17, gen_loss = 0.399650869092771, disc_loss = 0.053361867097139894
Trained batch 56 in epoch 17, gen_loss = 0.3990593489847685, disc_loss = 0.052798685805643335
Trained batch 57 in epoch 17, gen_loss = 0.398762139780768, disc_loss = 0.052545887522463655
Trained batch 58 in epoch 17, gen_loss = 0.3996742064669981, disc_loss = 0.05480209309449893
Trained batch 59 in epoch 17, gen_loss = 0.3989025170604388, disc_loss = 0.060293902091992396
Trained batch 60 in epoch 17, gen_loss = 0.39993198142677056, disc_loss = 0.05974446231743596
Trained batch 61 in epoch 17, gen_loss = 0.40236054457003073, disc_loss = 0.05995521160413421
Trained batch 62 in epoch 17, gen_loss = 0.4036052321630811, disc_loss = 0.0601584161040447
Trained batch 63 in epoch 17, gen_loss = 0.4028454557992518, disc_loss = 0.059904057772655506
Trained batch 64 in epoch 17, gen_loss = 0.40157760427548334, disc_loss = 0.05937354826153471
Trained batch 65 in epoch 17, gen_loss = 0.40142655553239764, disc_loss = 0.05878345426313127
Trained batch 66 in epoch 17, gen_loss = 0.40279211926816116, disc_loss = 0.05816396004033845
Trained batch 67 in epoch 17, gen_loss = 0.4042348142932443, disc_loss = 0.05781431354390567
Trained batch 68 in epoch 17, gen_loss = 0.40357384128846985, disc_loss = 0.0576713590045878
Trained batch 69 in epoch 17, gen_loss = 0.40298565668719155, disc_loss = 0.05766314002685249
Trained batch 70 in epoch 17, gen_loss = 0.40360612054945716, disc_loss = 0.057246681492985556
Trained batch 71 in epoch 17, gen_loss = 0.4036790889998277, disc_loss = 0.056882516539189965
Trained batch 72 in epoch 17, gen_loss = 0.4035104023267145, disc_loss = 0.05669235949060076
Trained batch 73 in epoch 17, gen_loss = 0.4026735191409652, disc_loss = 0.05804304749000113
Trained batch 74 in epoch 17, gen_loss = 0.404009108543396, disc_loss = 0.06237105062231421
Trained batch 75 in epoch 17, gen_loss = 0.40463604581983464, disc_loss = 0.06183282771809517
Trained batch 76 in epoch 17, gen_loss = 0.40489990680248705, disc_loss = 0.06155037329012117
Trained batch 77 in epoch 17, gen_loss = 0.40356630392563647, disc_loss = 0.0611631489203622
Trained batch 78 in epoch 17, gen_loss = 0.4033998043476781, disc_loss = 0.06060603454921253
Trained batch 79 in epoch 17, gen_loss = 0.40297598727047446, disc_loss = 0.060026151238707824
Trained batch 80 in epoch 17, gen_loss = 0.4024276689246849, disc_loss = 0.05950094170201524
Trained batch 81 in epoch 17, gen_loss = 0.402830083922642, disc_loss = 0.05906613193247921
Trained batch 82 in epoch 17, gen_loss = 0.4016734239566757, disc_loss = 0.05884604456172471
Trained batch 83 in epoch 17, gen_loss = 0.4016612395644188, disc_loss = 0.058927345616255136
Trained batch 84 in epoch 17, gen_loss = 0.4016002595424652, disc_loss = 0.05918457669699017
Trained batch 85 in epoch 17, gen_loss = 0.4015184523061264, disc_loss = 0.05885207624347924
Trained batch 86 in epoch 17, gen_loss = 0.4015064311438593, disc_loss = 0.05832811752762431
Trained batch 87 in epoch 17, gen_loss = 0.4016773690554229, disc_loss = 0.05794597994430329
Trained batch 88 in epoch 17, gen_loss = 0.4015032381154178, disc_loss = 0.05756745292292385
Trained batch 89 in epoch 17, gen_loss = 0.4007096731000476, disc_loss = 0.05716040905875464
Trained batch 90 in epoch 17, gen_loss = 0.40082942784487546, disc_loss = 0.05697084821576437
Trained batch 91 in epoch 17, gen_loss = 0.4007774782569512, disc_loss = 0.057067830495171896
Trained batch 92 in epoch 17, gen_loss = 0.40256983842901006, disc_loss = 0.05662805506438818
Trained batch 93 in epoch 17, gen_loss = 0.40189786128541255, disc_loss = 0.05676164739131135
Trained batch 94 in epoch 17, gen_loss = 0.4012568094228443, disc_loss = 0.05928984370180651
Trained batch 95 in epoch 17, gen_loss = 0.4019166234259804, disc_loss = 0.05946969318029005
Trained batch 96 in epoch 17, gen_loss = 0.4027059391601798, disc_loss = 0.05962681931145873
Trained batch 97 in epoch 17, gen_loss = 0.40318733028003145, disc_loss = 0.05913536244414139
Trained batch 98 in epoch 17, gen_loss = 0.40306756502450114, disc_loss = 0.05892189254871372
Trained batch 99 in epoch 17, gen_loss = 0.4024120691418648, disc_loss = 0.058871992877684534
Trained batch 100 in epoch 17, gen_loss = 0.4020304240212582, disc_loss = 0.058489143622504305
Trained batch 101 in epoch 17, gen_loss = 0.4026002559591742, disc_loss = 0.05918870595575986
Trained batch 102 in epoch 17, gen_loss = 0.4026225750307435, disc_loss = 0.05927180621357074
Trained batch 103 in epoch 17, gen_loss = 0.4024833870621828, disc_loss = 0.0592259895011711
Trained batch 104 in epoch 17, gen_loss = 0.4032427498272487, disc_loss = 0.05962201952490778
Trained batch 105 in epoch 17, gen_loss = 0.4027225563548646, disc_loss = 0.05925590193057257
Trained batch 106 in epoch 17, gen_loss = 0.4034472166377807, disc_loss = 0.05883756086282502
Trained batch 107 in epoch 17, gen_loss = 0.40375092073723123, disc_loss = 0.058849978135657253
Trained batch 108 in epoch 17, gen_loss = 0.40321252214799236, disc_loss = 0.05902529956875455
Trained batch 109 in epoch 17, gen_loss = 0.4020071723244407, disc_loss = 0.059448828594759105
Trained batch 110 in epoch 17, gen_loss = 0.40171814636067227, disc_loss = 0.059530552824841695
Trained batch 111 in epoch 17, gen_loss = 0.40245422747518333, disc_loss = 0.05977919755553428
Trained batch 112 in epoch 17, gen_loss = 0.40154073433538456, disc_loss = 0.06290142150365013
Trained batch 113 in epoch 17, gen_loss = 0.40223127577388496, disc_loss = 0.06273192224060103
Trained batch 114 in epoch 17, gen_loss = 0.40257803745891735, disc_loss = 0.06283523885371245
Trained batch 115 in epoch 17, gen_loss = 0.4027132332838815, disc_loss = 0.062449809721799504
Trained batch 116 in epoch 17, gen_loss = 0.40225331345175064, disc_loss = 0.06227987881702108
Trained batch 117 in epoch 17, gen_loss = 0.40167163615509616, disc_loss = 0.06227749827223183
Trained batch 118 in epoch 17, gen_loss = 0.40121781600623574, disc_loss = 0.0654749450931216
Trained batch 119 in epoch 17, gen_loss = 0.4003710761666298, disc_loss = 0.06658262176982438
Trained batch 120 in epoch 17, gen_loss = 0.40028451444688906, disc_loss = 0.06691296602991864
Trained batch 121 in epoch 17, gen_loss = 0.3994062386575292, disc_loss = 0.06688935396292048
Trained batch 122 in epoch 17, gen_loss = 0.39946200377572844, disc_loss = 0.06695376652694209
Trained batch 123 in epoch 17, gen_loss = 0.39925850206805813, disc_loss = 0.06693715879678606
Trained batch 124 in epoch 17, gen_loss = 0.3996648156642914, disc_loss = 0.06660752178356051
Trained batch 125 in epoch 17, gen_loss = 0.39961975363511887, disc_loss = 0.0663928189499688
Trained batch 126 in epoch 17, gen_loss = 0.3993584558250397, disc_loss = 0.06626868275485522
Trained batch 127 in epoch 17, gen_loss = 0.3988500682171434, disc_loss = 0.06600844363492797
Trained batch 128 in epoch 17, gen_loss = 0.3989696389482927, disc_loss = 0.06560796390598019
Trained batch 129 in epoch 17, gen_loss = 0.39953586780107936, disc_loss = 0.06549134834382969
Trained batch 130 in epoch 17, gen_loss = 0.39942190824574186, disc_loss = 0.0663218452268145
Trained batch 131 in epoch 17, gen_loss = 0.399074848176855, disc_loss = 0.06852975279925334
Trained batch 132 in epoch 17, gen_loss = 0.3991644458663195, disc_loss = 0.06838872178310626
Trained batch 133 in epoch 17, gen_loss = 0.3981617644651612, disc_loss = 0.06874936403108955
Trained batch 134 in epoch 17, gen_loss = 0.39761584356979085, disc_loss = 0.06900106636393401
Trained batch 135 in epoch 17, gen_loss = 0.397031779455788, disc_loss = 0.06896120277986698
Trained batch 136 in epoch 17, gen_loss = 0.3970857129914917, disc_loss = 0.06871642942887045
Trained batch 137 in epoch 17, gen_loss = 0.39732265234857367, disc_loss = 0.06850856160272614
Trained batch 138 in epoch 17, gen_loss = 0.3967813973804172, disc_loss = 0.06842851232429095
Trained batch 139 in epoch 17, gen_loss = 0.39707265943288805, disc_loss = 0.06819536830631218
Trained batch 140 in epoch 17, gen_loss = 0.39690327475256953, disc_loss = 0.06784321897141371
Trained batch 141 in epoch 17, gen_loss = 0.39726566009118525, disc_loss = 0.06759517050584332
Trained batch 142 in epoch 17, gen_loss = 0.3966386774619976, disc_loss = 0.0676289956619429
Trained batch 143 in epoch 17, gen_loss = 0.3966753443496095, disc_loss = 0.06749025083910157
Trained batch 144 in epoch 17, gen_loss = 0.39668567673913363, disc_loss = 0.06710456638950213
Trained batch 145 in epoch 17, gen_loss = 0.3963162598952855, disc_loss = 0.06696881056278434
Trained batch 146 in epoch 17, gen_loss = 0.3963464070745066, disc_loss = 0.06704146788474552
Trained batch 147 in epoch 17, gen_loss = 0.396042241035281, disc_loss = 0.06670037733479026
Trained batch 148 in epoch 17, gen_loss = 0.395967753341534, disc_loss = 0.06641630488041564
Trained batch 149 in epoch 17, gen_loss = 0.396193874279658, disc_loss = 0.06605557971633971
Trained batch 150 in epoch 17, gen_loss = 0.3965483787438727, disc_loss = 0.0658131080790614
Trained batch 151 in epoch 17, gen_loss = 0.39666494511460004, disc_loss = 0.06567948748737476
Trained batch 152 in epoch 17, gen_loss = 0.3964214061989504, disc_loss = 0.06578193688643427
Trained batch 153 in epoch 17, gen_loss = 0.39608563927861, disc_loss = 0.06617614661657868
Trained batch 154 in epoch 17, gen_loss = 0.39674298551774795, disc_loss = 0.06608990568727735
Trained batch 155 in epoch 17, gen_loss = 0.3969590318126556, disc_loss = 0.0657524486245492
Trained batch 156 in epoch 17, gen_loss = 0.39718033079129117, disc_loss = 0.0654008405633081
Trained batch 157 in epoch 17, gen_loss = 0.3971944560733023, disc_loss = 0.06518917993194412
Trained batch 158 in epoch 17, gen_loss = 0.3972009060517797, disc_loss = 0.06485542602567647
Trained batch 159 in epoch 17, gen_loss = 0.3975641272962093, disc_loss = 0.06451118965924252
Trained batch 160 in epoch 17, gen_loss = 0.39745765905942976, disc_loss = 0.06426516239190046
Trained batch 161 in epoch 17, gen_loss = 0.3980806996057063, disc_loss = 0.06432129317653124
Trained batch 162 in epoch 17, gen_loss = 0.39757363781607225, disc_loss = 0.06517427130402323
Trained batch 163 in epoch 17, gen_loss = 0.3981837266828956, disc_loss = 0.06645734929877174
Trained batch 164 in epoch 17, gen_loss = 0.3978569769498074, disc_loss = 0.06657177890848481
Trained batch 165 in epoch 17, gen_loss = 0.39779956836298286, disc_loss = 0.06625506234445037
Trained batch 166 in epoch 17, gen_loss = 0.39785110379407507, disc_loss = 0.065900703886535
Trained batch 167 in epoch 17, gen_loss = 0.39748251704233034, disc_loss = 0.06555727437426824
Trained batch 168 in epoch 17, gen_loss = 0.39723542491359826, disc_loss = 0.06521381602550928
Trained batch 169 in epoch 17, gen_loss = 0.3972994513371412, disc_loss = 0.06500941104639102
Trained batch 170 in epoch 17, gen_loss = 0.3973496362828372, disc_loss = 0.06475149685985337
Trained batch 171 in epoch 17, gen_loss = 0.39751253207755644, disc_loss = 0.06458494141373004
Trained batch 172 in epoch 17, gen_loss = 0.3972115459814237, disc_loss = 0.06429223666732022
Trained batch 173 in epoch 17, gen_loss = 0.39722605015354595, disc_loss = 0.06422535426400859
Trained batch 174 in epoch 17, gen_loss = 0.39744335395949226, disc_loss = 0.06412288331559726
Trained batch 175 in epoch 17, gen_loss = 0.39760084196247836, disc_loss = 0.06400518265383487
Trained batch 176 in epoch 17, gen_loss = 0.3980973849525559, disc_loss = 0.06380115665158646
Trained batch 177 in epoch 17, gen_loss = 0.39826560790619153, disc_loss = 0.06348314150131903
Trained batch 178 in epoch 17, gen_loss = 0.3986669828771879, disc_loss = 0.0635363217885476
Trained batch 179 in epoch 17, gen_loss = 0.3986291825771332, disc_loss = 0.06334182424729483
Trained batch 180 in epoch 17, gen_loss = 0.3987071385699741, disc_loss = 0.06312575556842086
Trained batch 181 in epoch 17, gen_loss = 0.3987803696603565, disc_loss = 0.06284301123929793
Trained batch 182 in epoch 17, gen_loss = 0.39878146716805757, disc_loss = 0.06254741744662487
Trained batch 183 in epoch 17, gen_loss = 0.39905662040995515, disc_loss = 0.062341773606654584
Trained batch 184 in epoch 17, gen_loss = 0.3996491971853617, disc_loss = 0.062409760307117895
Trained batch 185 in epoch 17, gen_loss = 0.40027996881674693, disc_loss = 0.062313988571986556
Trained batch 186 in epoch 17, gen_loss = 0.4000874783266037, disc_loss = 0.06214388419829189
Trained batch 187 in epoch 17, gen_loss = 0.40060248812462423, disc_loss = 0.06269709072125322
Trained batch 188 in epoch 17, gen_loss = 0.40027422375149196, disc_loss = 0.06386845550751166
Trained batch 189 in epoch 17, gen_loss = 0.4007263679253428, disc_loss = 0.0638236509905638
Trained batch 190 in epoch 17, gen_loss = 0.4010123214172443, disc_loss = 0.0636319509093011
Trained batch 191 in epoch 17, gen_loss = 0.40101407018179697, disc_loss = 0.06335682378994534
Trained batch 192 in epoch 17, gen_loss = 0.4011749344168549, disc_loss = 0.06312503803453838
Trained batch 193 in epoch 17, gen_loss = 0.40141074113624614, disc_loss = 0.06286655183756705
Trained batch 194 in epoch 17, gen_loss = 0.4009106341080788, disc_loss = 0.0625930858656573
Trained batch 195 in epoch 17, gen_loss = 0.40096987297340314, disc_loss = 0.062320552868483474
Trained batch 196 in epoch 17, gen_loss = 0.40106191036059774, disc_loss = 0.06207515264572907
Trained batch 197 in epoch 17, gen_loss = 0.40102373078615977, disc_loss = 0.062012937910045786
Trained batch 198 in epoch 17, gen_loss = 0.4007315054610746, disc_loss = 0.06263571024062721
Trained batch 199 in epoch 17, gen_loss = 0.401149155497551, disc_loss = 0.062867803175468
Trained batch 200 in epoch 17, gen_loss = 0.4012416847309663, disc_loss = 0.06267709344560604
Trained batch 201 in epoch 17, gen_loss = 0.40081965333164327, disc_loss = 0.06250983651146513
Trained batch 202 in epoch 17, gen_loss = 0.4007046086153961, disc_loss = 0.062268532236826976
Trained batch 203 in epoch 17, gen_loss = 0.400736002507163, disc_loss = 0.06200130662068213
Trained batch 204 in epoch 17, gen_loss = 0.4006223854495258, disc_loss = 0.061874828671627656
Trained batch 205 in epoch 17, gen_loss = 0.40052848663723584, disc_loss = 0.0619511448267341
Trained batch 206 in epoch 17, gen_loss = 0.40060445248792714, disc_loss = 0.06198007575852643
Trained batch 207 in epoch 17, gen_loss = 0.4002841400125852, disc_loss = 0.06178287816314528
Trained batch 208 in epoch 17, gen_loss = 0.3999064470592298, disc_loss = 0.06203671671565997
Trained batch 209 in epoch 17, gen_loss = 0.40020652753966196, disc_loss = 0.06286038871898893
Trained batch 210 in epoch 17, gen_loss = 0.4005198266833879, disc_loss = 0.06264005483335582
Trained batch 211 in epoch 17, gen_loss = 0.40059187207019553, disc_loss = 0.062431952171466965
Trained batch 212 in epoch 17, gen_loss = 0.4003542142574776, disc_loss = 0.06229918626106471
Trained batch 213 in epoch 17, gen_loss = 0.40022612927115964, disc_loss = 0.06209489719063113
Trained batch 214 in epoch 17, gen_loss = 0.40031393724818565, disc_loss = 0.06184357656165958
Trained batch 215 in epoch 17, gen_loss = 0.4003970649231363, disc_loss = 0.061623562621038956
Trained batch 216 in epoch 17, gen_loss = 0.4007177307583769, disc_loss = 0.06139243376754602
Trained batch 217 in epoch 17, gen_loss = 0.4007361603712817, disc_loss = 0.061174511984247
Trained batch 218 in epoch 17, gen_loss = 0.4012096269762135, disc_loss = 0.06101435816476811
Trained batch 219 in epoch 17, gen_loss = 0.40112943175164134, disc_loss = 0.060941191328774125
Trained batch 220 in epoch 17, gen_loss = 0.4009119788715742, disc_loss = 0.06100800583493049
Trained batch 221 in epoch 17, gen_loss = 0.40097696931512505, disc_loss = 0.060964578248745016
Trained batch 222 in epoch 17, gen_loss = 0.40091827217773474, disc_loss = 0.06072257041321408
Trained batch 223 in epoch 17, gen_loss = 0.40060750275318113, disc_loss = 0.06066891647268286
Trained batch 224 in epoch 17, gen_loss = 0.40074291361702813, disc_loss = 0.06046649290248752
Trained batch 225 in epoch 17, gen_loss = 0.4012131015811346, disc_loss = 0.06033105314791664
Trained batch 226 in epoch 17, gen_loss = 0.40125587516944317, disc_loss = 0.060188471563242474
Trained batch 227 in epoch 17, gen_loss = 0.4013976842949265, disc_loss = 0.059964214964246934
Trained batch 228 in epoch 17, gen_loss = 0.40192753844386103, disc_loss = 0.05985790553531207
Trained batch 229 in epoch 17, gen_loss = 0.40205458830232205, disc_loss = 0.059683100796183164
Trained batch 230 in epoch 17, gen_loss = 0.4020640313367307, disc_loss = 0.0597445422126327
Trained batch 231 in epoch 17, gen_loss = 0.4022072706500004, disc_loss = 0.06064870367268229
Trained batch 232 in epoch 17, gen_loss = 0.40210902409492133, disc_loss = 0.060652495275927074
Trained batch 233 in epoch 17, gen_loss = 0.4020663150864789, disc_loss = 0.06043618625929404
Trained batch 234 in epoch 17, gen_loss = 0.40217493189142106, disc_loss = 0.06020650633194662
Trained batch 235 in epoch 17, gen_loss = 0.40217982952372505, disc_loss = 0.06024562817864057
Trained batch 236 in epoch 17, gen_loss = 0.4020011504239674, disc_loss = 0.06052994468143281
Trained batch 237 in epoch 17, gen_loss = 0.4022331792516869, disc_loss = 0.06048200195929145
Trained batch 238 in epoch 17, gen_loss = 0.4023374829082808, disc_loss = 0.06026621233617349
Trained batch 239 in epoch 17, gen_loss = 0.4024124508102735, disc_loss = 0.06009839917339074
Trained batch 240 in epoch 17, gen_loss = 0.4024210833167634, disc_loss = 0.059917263545606024
Trained batch 241 in epoch 17, gen_loss = 0.4024262782955958, disc_loss = 0.059713874464423576
Trained batch 242 in epoch 17, gen_loss = 0.4027956572089176, disc_loss = 0.059555531948912166
Trained batch 243 in epoch 17, gen_loss = 0.40291997313988015, disc_loss = 0.059756766689834415
Trained batch 244 in epoch 17, gen_loss = 0.4023916285865161, disc_loss = 0.06090872651726312
Trained batch 245 in epoch 17, gen_loss = 0.40244304843065215, disc_loss = 0.06099706345116644
Trained batch 246 in epoch 17, gen_loss = 0.4025285748335031, disc_loss = 0.06128339531835214
Trained batch 247 in epoch 17, gen_loss = 0.40229127207590687, disc_loss = 0.06143169506685808
Trained batch 248 in epoch 17, gen_loss = 0.40225783265738124, disc_loss = 0.061707457495726134
Trained batch 249 in epoch 17, gen_loss = 0.4019710103273392, disc_loss = 0.06159391768835485
Trained batch 250 in epoch 17, gen_loss = 0.4021694429842124, disc_loss = 0.06144623871543908
Trained batch 251 in epoch 17, gen_loss = 0.40210632069243324, disc_loss = 0.06128797270468481
Trained batch 252 in epoch 17, gen_loss = 0.40206126415211224, disc_loss = 0.061174015987576116
Trained batch 253 in epoch 17, gen_loss = 0.40200675108770684, disc_loss = 0.06113384913205807
Trained batch 254 in epoch 17, gen_loss = 0.4024176533315696, disc_loss = 0.061771842572545886
Trained batch 255 in epoch 17, gen_loss = 0.4023424128536135, disc_loss = 0.06186570192039653
Trained batch 256 in epoch 17, gen_loss = 0.4022438115646867, disc_loss = 0.06185930030753814
Trained batch 257 in epoch 17, gen_loss = 0.4018969427245532, disc_loss = 0.06186942010937446
Trained batch 258 in epoch 17, gen_loss = 0.4021073885866114, disc_loss = 0.06166755934299822
Trained batch 259 in epoch 17, gen_loss = 0.4024348889405911, disc_loss = 0.06146492255099404
Trained batch 260 in epoch 17, gen_loss = 0.4023584399186788, disc_loss = 0.061380634011194056
Trained batch 261 in epoch 17, gen_loss = 0.40219109636226685, disc_loss = 0.06124234200768059
Trained batch 262 in epoch 17, gen_loss = 0.4020481928899714, disc_loss = 0.061056120531853046
Trained batch 263 in epoch 17, gen_loss = 0.4018457100698442, disc_loss = 0.06087368529706234
Trained batch 264 in epoch 17, gen_loss = 0.4020320222062885, disc_loss = 0.060727634272133964
Trained batch 265 in epoch 17, gen_loss = 0.402325801831439, disc_loss = 0.06074198170677107
Trained batch 266 in epoch 17, gen_loss = 0.4019259824958187, disc_loss = 0.06099576849581095
Trained batch 267 in epoch 17, gen_loss = 0.40226529127181465, disc_loss = 0.0609045008166151
Trained batch 268 in epoch 17, gen_loss = 0.4025463405373371, disc_loss = 0.060996824652164286
Trained batch 269 in epoch 17, gen_loss = 0.4026992678642273, disc_loss = 0.061011595366936594
Trained batch 270 in epoch 17, gen_loss = 0.40260307375355403, disc_loss = 0.06090042524115351
Trained batch 271 in epoch 17, gen_loss = 0.4027118858169107, disc_loss = 0.060711089848636594
Trained batch 272 in epoch 17, gen_loss = 0.4026516682499058, disc_loss = 0.06061893300197664
Trained batch 273 in epoch 17, gen_loss = 0.40241602182823377, disc_loss = 0.06060499545479071
Trained batch 274 in epoch 17, gen_loss = 0.4026080136949366, disc_loss = 0.06053097457878969
Trained batch 275 in epoch 17, gen_loss = 0.4029198950831441, disc_loss = 0.06036788426454354
Trained batch 276 in epoch 17, gen_loss = 0.4027354556946118, disc_loss = 0.061064945300200464
Trained batch 277 in epoch 17, gen_loss = 0.4024531103724198, disc_loss = 0.06267452611346735
Trained batch 278 in epoch 17, gen_loss = 0.4023546445113356, disc_loss = 0.06300227153265188
Trained batch 279 in epoch 17, gen_loss = 0.4022930137813091, disc_loss = 0.0634497643198951
Trained batch 280 in epoch 17, gen_loss = 0.4020853876219101, disc_loss = 0.06359422163295417
Trained batch 281 in epoch 17, gen_loss = 0.40190186473072, disc_loss = 0.06389334606475705
Trained batch 282 in epoch 17, gen_loss = 0.4016969483016658, disc_loss = 0.06403904599252785
Trained batch 283 in epoch 17, gen_loss = 0.40140602087051097, disc_loss = 0.06415267990620047
Trained batch 284 in epoch 17, gen_loss = 0.4014232449364244, disc_loss = 0.06411214426584673
Trained batch 285 in epoch 17, gen_loss = 0.40128111089026175, disc_loss = 0.06406328769993376
Trained batch 286 in epoch 17, gen_loss = 0.4011347940782221, disc_loss = 0.0640821923690001
Trained batch 287 in epoch 17, gen_loss = 0.4009267759198944, disc_loss = 0.06409595159251087
Trained batch 288 in epoch 17, gen_loss = 0.40083158573064837, disc_loss = 0.0639717245368113
Trained batch 289 in epoch 17, gen_loss = 0.40079581316175134, disc_loss = 0.06399808752928571
Trained batch 290 in epoch 17, gen_loss = 0.40073864064675424, disc_loss = 0.06395940592230852
Trained batch 291 in epoch 17, gen_loss = 0.4006283454699059, disc_loss = 0.0640317663910786
Trained batch 292 in epoch 17, gen_loss = 0.4006011746442359, disc_loss = 0.06425680768908139
Trained batch 293 in epoch 17, gen_loss = 0.40054987928494307, disc_loss = 0.0644065174321663
Trained batch 294 in epoch 17, gen_loss = 0.4003094992395175, disc_loss = 0.06437010664840119
Trained batch 295 in epoch 17, gen_loss = 0.4002839824235117, disc_loss = 0.06443440617924254
Trained batch 296 in epoch 17, gen_loss = 0.4005629267756786, disc_loss = 0.06442458258615649
Trained batch 297 in epoch 17, gen_loss = 0.4005600274009192, disc_loss = 0.0644777566022646
Trained batch 298 in epoch 17, gen_loss = 0.40088251083590914, disc_loss = 0.0647696739881857
Trained batch 299 in epoch 17, gen_loss = 0.4005665621161461, disc_loss = 0.06518207925837487
Trained batch 300 in epoch 17, gen_loss = 0.4004236373592453, disc_loss = 0.06509567609836542
Trained batch 301 in epoch 17, gen_loss = 0.4003881642360561, disc_loss = 0.06499265611251903
Trained batch 302 in epoch 17, gen_loss = 0.40035773218661647, disc_loss = 0.06505196404615694
Trained batch 303 in epoch 17, gen_loss = 0.4005886960382524, disc_loss = 0.06494379245314601
Trained batch 304 in epoch 17, gen_loss = 0.40063369948355876, disc_loss = 0.0650584513611603
Trained batch 305 in epoch 17, gen_loss = 0.4000968488018497, disc_loss = 0.06581309462860957
Trained batch 306 in epoch 17, gen_loss = 0.400414681298725, disc_loss = 0.06578590631855087
Trained batch 307 in epoch 17, gen_loss = 0.40046525843344727, disc_loss = 0.0662078132275371
Trained batch 308 in epoch 17, gen_loss = 0.4001650946232879, disc_loss = 0.06623195669490205
Trained batch 309 in epoch 17, gen_loss = 0.40019011930111914, disc_loss = 0.0663381275705873
Trained batch 310 in epoch 17, gen_loss = 0.4003029315226331, disc_loss = 0.06648928497938912
Trained batch 311 in epoch 17, gen_loss = 0.4006993385652701, disc_loss = 0.06642577838516818
Trained batch 312 in epoch 17, gen_loss = 0.40068963865121715, disc_loss = 0.06626846337357696
Trained batch 313 in epoch 17, gen_loss = 0.4007867048880097, disc_loss = 0.06616039985381542
Trained batch 314 in epoch 17, gen_loss = 0.4007041625560276, disc_loss = 0.06603652419936326
Trained batch 315 in epoch 17, gen_loss = 0.40066277386644217, disc_loss = 0.06596289212149391
Trained batch 316 in epoch 17, gen_loss = 0.40059342256479835, disc_loss = 0.06597709752272592
Trained batch 317 in epoch 17, gen_loss = 0.40027969419581333, disc_loss = 0.06586261166980104
Trained batch 318 in epoch 17, gen_loss = 0.4000683706195377, disc_loss = 0.0658052671411685
Trained batch 319 in epoch 17, gen_loss = 0.4002197188325226, disc_loss = 0.06590766565204831
Trained batch 320 in epoch 17, gen_loss = 0.3999459668297634, disc_loss = 0.06588232126870305
Trained batch 321 in epoch 17, gen_loss = 0.39987965020703975, disc_loss = 0.06574395004087215
Trained batch 322 in epoch 17, gen_loss = 0.39988281769280093, disc_loss = 0.06559590091813505
Trained batch 323 in epoch 17, gen_loss = 0.4001085806959941, disc_loss = 0.06543371400272727
Trained batch 324 in epoch 17, gen_loss = 0.3999398461671976, disc_loss = 0.06537639641274627
Trained batch 325 in epoch 17, gen_loss = 0.3996538574710214, disc_loss = 0.06566286320580982
Trained batch 326 in epoch 17, gen_loss = 0.39976620017935377, disc_loss = 0.0655431515417583
Trained batch 327 in epoch 17, gen_loss = 0.39981262476705925, disc_loss = 0.06590992506883084
Trained batch 328 in epoch 17, gen_loss = 0.39952582392649083, disc_loss = 0.0658874819635507
Trained batch 329 in epoch 17, gen_loss = 0.3993421635844491, disc_loss = 0.06582254668500162
Trained batch 330 in epoch 17, gen_loss = 0.39924981893009287, disc_loss = 0.0656934378266312
Trained batch 331 in epoch 17, gen_loss = 0.39913181116782037, disc_loss = 0.06561671487891665
Trained batch 332 in epoch 17, gen_loss = 0.3990975829574081, disc_loss = 0.06548154928411047
Trained batch 333 in epoch 17, gen_loss = 0.3989306096723694, disc_loss = 0.06548640059870472
Trained batch 334 in epoch 17, gen_loss = 0.39926402026147984, disc_loss = 0.06562370450388808
Trained batch 335 in epoch 17, gen_loss = 0.39917021572944666, disc_loss = 0.06559763460037564
Trained batch 336 in epoch 17, gen_loss = 0.3992543075487946, disc_loss = 0.06544108638396205
Trained batch 337 in epoch 17, gen_loss = 0.39950453776579636, disc_loss = 0.06533665255059284
Trained batch 338 in epoch 17, gen_loss = 0.39988959327911555, disc_loss = 0.06525322874996999
Trained batch 339 in epoch 17, gen_loss = 0.39990765653988897, disc_loss = 0.0652830805944498
Trained batch 340 in epoch 17, gen_loss = 0.3998794364264983, disc_loss = 0.06563867642639801
Trained batch 341 in epoch 17, gen_loss = 0.4000024228242406, disc_loss = 0.0661600182549102
Trained batch 342 in epoch 17, gen_loss = 0.40003602358759666, disc_loss = 0.06599731456743602
Trained batch 343 in epoch 17, gen_loss = 0.3997708783420019, disc_loss = 0.06590940116845115
Trained batch 344 in epoch 17, gen_loss = 0.3995189518168353, disc_loss = 0.06619876150338762
Trained batch 345 in epoch 17, gen_loss = 0.39995253930202107, disc_loss = 0.06651881735669611
Trained batch 346 in epoch 17, gen_loss = 0.4000684567418497, disc_loss = 0.0663775913430759
Trained batch 347 in epoch 17, gen_loss = 0.3999604253076959, disc_loss = 0.06625103225380224
Trained batch 348 in epoch 17, gen_loss = 0.39984290049889026, disc_loss = 0.06617975533462228
Trained batch 349 in epoch 17, gen_loss = 0.3998550293275288, disc_loss = 0.06607334555925003
Trained batch 350 in epoch 17, gen_loss = 0.3997098423137284, disc_loss = 0.06595570833536338
Trained batch 351 in epoch 17, gen_loss = 0.3996647333895618, disc_loss = 0.06617080682322425
Trained batch 352 in epoch 17, gen_loss = 0.3996807597683104, disc_loss = 0.0665369258768772
Trained batch 353 in epoch 17, gen_loss = 0.39967625280894803, disc_loss = 0.06648866684533825
Trained batch 354 in epoch 17, gen_loss = 0.39964327325283644, disc_loss = 0.06651773305452416
Trained batch 355 in epoch 17, gen_loss = 0.399645705069049, disc_loss = 0.0663923953850806
Trained batch 356 in epoch 17, gen_loss = 0.39982648273142113, disc_loss = 0.06626530690901294
Trained batch 357 in epoch 17, gen_loss = 0.4000130112610716, disc_loss = 0.06613727362550711
Trained batch 358 in epoch 17, gen_loss = 0.4000545076008959, disc_loss = 0.06611314557186616
Trained batch 359 in epoch 17, gen_loss = 0.4001194334692425, disc_loss = 0.06643660234209771
Trained batch 360 in epoch 17, gen_loss = 0.39982208518770596, disc_loss = 0.0672749958718273
Trained batch 361 in epoch 17, gen_loss = 0.4000427821723137, disc_loss = 0.06734537483625196
Trained batch 362 in epoch 17, gen_loss = 0.39987618691665083, disc_loss = 0.06745469966420992
Trained batch 363 in epoch 17, gen_loss = 0.399690174303212, disc_loss = 0.06761726968445825
Trained batch 364 in epoch 17, gen_loss = 0.39963072081134743, disc_loss = 0.06751993238441135
Trained batch 365 in epoch 17, gen_loss = 0.39990412333949665, disc_loss = 0.06740070095850674
Trained batch 366 in epoch 17, gen_loss = 0.39996626997513735, disc_loss = 0.06728837401187428
Trained batch 367 in epoch 17, gen_loss = 0.39995203928455064, disc_loss = 0.06725009479787727
Trained batch 368 in epoch 17, gen_loss = 0.39984527674470816, disc_loss = 0.06719753320447515
Trained batch 369 in epoch 17, gen_loss = 0.3998672674636583, disc_loss = 0.06737311696507842
Trained batch 370 in epoch 17, gen_loss = 0.399684764866559, disc_loss = 0.06802834048892328
Trained batch 371 in epoch 17, gen_loss = 0.3997186907837468, disc_loss = 0.06793901821603418
Trained batch 372 in epoch 17, gen_loss = 0.3996869189809538, disc_loss = 0.06780994074898535
Trained batch 373 in epoch 17, gen_loss = 0.39966656164052017, disc_loss = 0.06769352835194671
Trained batch 374 in epoch 17, gen_loss = 0.39954668561617535, disc_loss = 0.06766310076539715
Trained batch 375 in epoch 17, gen_loss = 0.39962510582297406, disc_loss = 0.06756489381238699
Trained batch 376 in epoch 17, gen_loss = 0.39941824597136094, disc_loss = 0.06757407588143129
Trained batch 377 in epoch 17, gen_loss = 0.3991796263153591, disc_loss = 0.06769779917941719
Trained batch 378 in epoch 17, gen_loss = 0.3992484690803337, disc_loss = 0.06759545584590147
Trained batch 379 in epoch 17, gen_loss = 0.3995559873549562, disc_loss = 0.06748227655618011
Trained batch 380 in epoch 17, gen_loss = 0.3995708954615856, disc_loss = 0.06734912481838519
Trained batch 381 in epoch 17, gen_loss = 0.3996367619143731, disc_loss = 0.06720102623870587
Trained batch 382 in epoch 17, gen_loss = 0.3997576170583929, disc_loss = 0.067058546151285
Trained batch 383 in epoch 17, gen_loss = 0.399729780619964, disc_loss = 0.06693947083234282
Trained batch 384 in epoch 17, gen_loss = 0.39962655561310906, disc_loss = 0.06679738386860722
Trained batch 385 in epoch 17, gen_loss = 0.39957641366232244, disc_loss = 0.06669295113413097
Trained batch 386 in epoch 17, gen_loss = 0.3994762251389427, disc_loss = 0.06661054731084357
Trained batch 387 in epoch 17, gen_loss = 0.39944182344011425, disc_loss = 0.06659188413795698
Trained batch 388 in epoch 17, gen_loss = 0.3992614558392748, disc_loss = 0.06664922232392476
Trained batch 389 in epoch 17, gen_loss = 0.39955451771234857, disc_loss = 0.06665432623539788
Trained batch 390 in epoch 17, gen_loss = 0.3998690051648318, disc_loss = 0.06655312168871617
Trained batch 391 in epoch 17, gen_loss = 0.40002800835942737, disc_loss = 0.06643369717271619
Trained batch 392 in epoch 17, gen_loss = 0.40017269244630826, disc_loss = 0.06634091663010816
Trained batch 393 in epoch 17, gen_loss = 0.40019937124349136, disc_loss = 0.06619448838684576
Trained batch 394 in epoch 17, gen_loss = 0.399980175268801, disc_loss = 0.06609974475577474
Trained batch 395 in epoch 17, gen_loss = 0.400005789793501, disc_loss = 0.06598211120169685
Trained batch 396 in epoch 17, gen_loss = 0.39991774216707165, disc_loss = 0.0659086294085144
Trained batch 397 in epoch 17, gen_loss = 0.39997817598395613, disc_loss = 0.065824282518237
Trained batch 398 in epoch 17, gen_loss = 0.40002474898383733, disc_loss = 0.06575560353038118
Trained batch 399 in epoch 17, gen_loss = 0.40000218234956264, disc_loss = 0.06589730344596319
Trained batch 400 in epoch 17, gen_loss = 0.399837501774405, disc_loss = 0.06606255319234253
Trained batch 401 in epoch 17, gen_loss = 0.40022886970743016, disc_loss = 0.06600317871313895
Trained batch 402 in epoch 17, gen_loss = 0.40024543873429597, disc_loss = 0.06592071651557355
Trained batch 403 in epoch 17, gen_loss = 0.4003066687595726, disc_loss = 0.0657822109959411
Trained batch 404 in epoch 17, gen_loss = 0.400339506437749, disc_loss = 0.06570945683245857
Trained batch 405 in epoch 17, gen_loss = 0.40023855197018593, disc_loss = 0.06560093336830403
Trained batch 406 in epoch 17, gen_loss = 0.4002631176308859, disc_loss = 0.06548360586784213
Trained batch 407 in epoch 17, gen_loss = 0.40033648133862254, disc_loss = 0.06542513797895107
Trained batch 408 in epoch 17, gen_loss = 0.4002183308519769, disc_loss = 0.06537875492002787
Trained batch 409 in epoch 17, gen_loss = 0.40007991274682486, disc_loss = 0.06529711745565803
Trained batch 410 in epoch 17, gen_loss = 0.400244669830132, disc_loss = 0.06515506526949269
Trained batch 411 in epoch 17, gen_loss = 0.40034447444006077, disc_loss = 0.06502918210513528
Trained batch 412 in epoch 17, gen_loss = 0.40034111764182767, disc_loss = 0.0649616778501226
Trained batch 413 in epoch 17, gen_loss = 0.4004742842221606, disc_loss = 0.06485944616963754
Trained batch 414 in epoch 17, gen_loss = 0.4006493694092854, disc_loss = 0.06490780425269202
Trained batch 415 in epoch 17, gen_loss = 0.4004158520211394, disc_loss = 0.06563875266762736
Trained batch 416 in epoch 17, gen_loss = 0.4001375144477085, disc_loss = 0.06561535773285145
Trained batch 417 in epoch 17, gen_loss = 0.4001609244557659, disc_loss = 0.06563183071278927
Trained batch 418 in epoch 17, gen_loss = 0.40008391628401946, disc_loss = 0.06564515208056405
Trained batch 419 in epoch 17, gen_loss = 0.39996012818245663, disc_loss = 0.06560852427833846
Trained batch 420 in epoch 17, gen_loss = 0.3998732784864738, disc_loss = 0.06554598779353421
Trained batch 421 in epoch 17, gen_loss = 0.39970021889108054, disc_loss = 0.06554979942650734
Trained batch 422 in epoch 17, gen_loss = 0.3997575201745856, disc_loss = 0.06558770660407859
Trained batch 423 in epoch 17, gen_loss = 0.3996359190007426, disc_loss = 0.0655380430552265
Trained batch 424 in epoch 17, gen_loss = 0.39986051938113043, disc_loss = 0.06544163110939895
Trained batch 425 in epoch 17, gen_loss = 0.3997710502483475, disc_loss = 0.0654424283032616
Trained batch 426 in epoch 17, gen_loss = 0.39952326365321245, disc_loss = 0.06562039618591933
Trained batch 427 in epoch 17, gen_loss = 0.3998602117611983, disc_loss = 0.06550580433300027
Trained batch 428 in epoch 17, gen_loss = 0.3998475430450795, disc_loss = 0.06579015276770353
Trained batch 429 in epoch 17, gen_loss = 0.3998022089170855, disc_loss = 0.06602615803740053
Trained batch 430 in epoch 17, gen_loss = 0.3998154290452634, disc_loss = 0.0659158659273469
Trained batch 431 in epoch 17, gen_loss = 0.3999116104786043, disc_loss = 0.06578649673395341
Trained batch 432 in epoch 17, gen_loss = 0.400086337025116, disc_loss = 0.06566411257650505
Trained batch 433 in epoch 17, gen_loss = 0.4001471600087557, disc_loss = 0.06552757262917501
Trained batch 434 in epoch 17, gen_loss = 0.4002600556817548, disc_loss = 0.06540639457646115
Trained batch 435 in epoch 17, gen_loss = 0.40013603886606497, disc_loss = 0.06534647441537487
Trained batch 436 in epoch 17, gen_loss = 0.40009532101639894, disc_loss = 0.06533384606779236
Trained batch 437 in epoch 17, gen_loss = 0.4000414414629, disc_loss = 0.06526520584399502
Trained batch 438 in epoch 17, gen_loss = 0.4002505477713018, disc_loss = 0.0654188512139243
Trained batch 439 in epoch 17, gen_loss = 0.4000486002049663, disc_loss = 0.06580150535287843
Trained batch 440 in epoch 17, gen_loss = 0.39995248585331195, disc_loss = 0.06573318127255523
Trained batch 441 in epoch 17, gen_loss = 0.39999207490170163, disc_loss = 0.06570657060957805
Trained batch 442 in epoch 17, gen_loss = 0.4000241993915954, disc_loss = 0.06561541842595248
Trained batch 443 in epoch 17, gen_loss = 0.40000744680832095, disc_loss = 0.06557208923245403
Trained batch 444 in epoch 17, gen_loss = 0.4000124451149715, disc_loss = 0.0654693060732457
Trained batch 445 in epoch 17, gen_loss = 0.40003528469346566, disc_loss = 0.06540915932330917
Trained batch 446 in epoch 17, gen_loss = 0.4000720042376977, disc_loss = 0.06550222541303509
Trained batch 447 in epoch 17, gen_loss = 0.4002114573626646, disc_loss = 0.06563376631363228
Trained batch 448 in epoch 17, gen_loss = 0.4002114509819345, disc_loss = 0.06558702765177844
Trained batch 449 in epoch 17, gen_loss = 0.4001947704288695, disc_loss = 0.06548238780970375
Trained batch 450 in epoch 17, gen_loss = 0.40018971571636835, disc_loss = 0.06574053877547482
Trained batch 451 in epoch 17, gen_loss = 0.40012917318175323, disc_loss = 0.06616153057244302
Trained batch 452 in epoch 17, gen_loss = 0.4001564349954491, disc_loss = 0.06641664413764053
Trained batch 453 in epoch 17, gen_loss = 0.4000269545463738, disc_loss = 0.0663848360979905
Trained batch 454 in epoch 17, gen_loss = 0.40001914095092606, disc_loss = 0.06628367512967888
Trained batch 455 in epoch 17, gen_loss = 0.40001633671814935, disc_loss = 0.066226302419397
Trained batch 456 in epoch 17, gen_loss = 0.40011171791172656, disc_loss = 0.06622732011907015
Trained batch 457 in epoch 17, gen_loss = 0.40015578855593653, disc_loss = 0.06651202163264545
Trained batch 458 in epoch 17, gen_loss = 0.40026266213855455, disc_loss = 0.06680475162597847
Trained batch 459 in epoch 17, gen_loss = 0.4005439131156258, disc_loss = 0.06669413162921758
Trained batch 460 in epoch 17, gen_loss = 0.4003614182715302, disc_loss = 0.06680164493240594
Testing Epoch 17
Training Epoch 18
Trained batch 0 in epoch 18, gen_loss = 0.35186049342155457, disc_loss = 0.038752976804971695
Trained batch 1 in epoch 18, gen_loss = 0.4237493574619293, disc_loss = 0.02677814057096839
Trained batch 2 in epoch 18, gen_loss = 0.41161251068115234, disc_loss = 0.022325123039384682
Trained batch 3 in epoch 18, gen_loss = 0.42065463960170746, disc_loss = 0.020673048915341496
Trained batch 4 in epoch 18, gen_loss = 0.4116417169570923, disc_loss = 0.022223699651658536
Trained batch 5 in epoch 18, gen_loss = 0.4114905595779419, disc_loss = 0.022669169896592695
Trained batch 6 in epoch 18, gen_loss = 0.416867447750909, disc_loss = 0.022592010641736642
Trained batch 7 in epoch 18, gen_loss = 0.4122464768588543, disc_loss = 0.023921707994304597
Trained batch 8 in epoch 18, gen_loss = 0.4105510479874081, disc_loss = 0.02701788592255778
Trained batch 9 in epoch 18, gen_loss = 0.41386425495147705, disc_loss = 0.039099239837378265
Trained batch 10 in epoch 18, gen_loss = 0.4109942506660115, disc_loss = 0.042337780903008854
Trained batch 11 in epoch 18, gen_loss = 0.4075615083177884, disc_loss = 0.040390000600988664
Trained batch 12 in epoch 18, gen_loss = 0.4053288239699144, disc_loss = 0.03884171429448403
Trained batch 13 in epoch 18, gen_loss = 0.4011109471321106, disc_loss = 0.04296811796458704
Trained batch 14 in epoch 18, gen_loss = 0.4024646858374278, disc_loss = 0.04784895200282335
Trained batch 15 in epoch 18, gen_loss = 0.4070907421410084, disc_loss = 0.05060600693104789
Trained batch 16 in epoch 18, gen_loss = 0.40645315541940574, disc_loss = 0.048865011893212795
Trained batch 17 in epoch 18, gen_loss = 0.3975953799155023, disc_loss = 0.06176596088334918
Trained batch 18 in epoch 18, gen_loss = 0.3979363951243852, disc_loss = 0.06915382996789719
Trained batch 19 in epoch 18, gen_loss = 0.4015828721225262, disc_loss = 0.06927124219946564
Trained batch 20 in epoch 18, gen_loss = 0.4009096416689101, disc_loss = 0.06676561043908198
Trained batch 21 in epoch 18, gen_loss = 0.40199093046513473, disc_loss = 0.0650084121576087
Trained batch 22 in epoch 18, gen_loss = 0.4017440799785697, disc_loss = 0.06291280893365973
Trained batch 23 in epoch 18, gen_loss = 0.3971587462971608, disc_loss = 0.061671604053117335
Trained batch 24 in epoch 18, gen_loss = 0.398659970164299, disc_loss = 0.06015122700482607
Trained batch 25 in epoch 18, gen_loss = 0.3975754294257898, disc_loss = 0.06000966797224604
Trained batch 26 in epoch 18, gen_loss = 0.3934682039199052, disc_loss = 0.06141132078374977
Trained batch 27 in epoch 18, gen_loss = 0.3922049930053098, disc_loss = 0.0612802581662046
Trained batch 28 in epoch 18, gen_loss = 0.39321051743523827, disc_loss = 0.060488893457784736
Trained batch 29 in epoch 18, gen_loss = 0.3954996600747108, disc_loss = 0.059440077003091576
Trained batch 30 in epoch 18, gen_loss = 0.39402533779221194, disc_loss = 0.05888508131066637
Trained batch 31 in epoch 18, gen_loss = 0.3948366460390389, disc_loss = 0.06635709028341807
Trained batch 32 in epoch 18, gen_loss = 0.39343919763059326, disc_loss = 0.07620749343186617
Trained batch 33 in epoch 18, gen_loss = 0.39443548155181546, disc_loss = 0.07520498392884345
Trained batch 34 in epoch 18, gen_loss = 0.3959301935774939, disc_loss = 0.0753385015098112
Trained batch 35 in epoch 18, gen_loss = 0.39668671993745697, disc_loss = 0.07371368065165977
Trained batch 36 in epoch 18, gen_loss = 0.3957116511222479, disc_loss = 0.07208361056306072
Trained batch 37 in epoch 18, gen_loss = 0.39654946366423055, disc_loss = 0.07077036976912304
Trained batch 38 in epoch 18, gen_loss = 0.39599630580498624, disc_loss = 0.06919048065080857
Trained batch 39 in epoch 18, gen_loss = 0.3957598891109228, disc_loss = 0.06763173053041101
Trained batch 40 in epoch 18, gen_loss = 0.39870379283660795, disc_loss = 0.06621224546759594
Trained batch 41 in epoch 18, gen_loss = 0.39801301239501863, disc_loss = 0.06496873901536067
Trained batch 42 in epoch 18, gen_loss = 0.39919667153857474, disc_loss = 0.06379353748851044
Trained batch 43 in epoch 18, gen_loss = 0.4006210311569951, disc_loss = 0.06248542254748331
Trained batch 44 in epoch 18, gen_loss = 0.39953787492381204, disc_loss = 0.06177650142668022
Trained batch 45 in epoch 18, gen_loss = 0.39798292550055875, disc_loss = 0.06112429628189167
Trained batch 46 in epoch 18, gen_loss = 0.39979805559554, disc_loss = 0.06080268964448825
Trained batch 47 in epoch 18, gen_loss = 0.39736512769013643, disc_loss = 0.06136556488733428
Trained batch 48 in epoch 18, gen_loss = 0.3975758367047018, disc_loss = 0.06124155290842968
Trained batch 49 in epoch 18, gen_loss = 0.39828631669282916, disc_loss = 0.06047863609157503
Trained batch 50 in epoch 18, gen_loss = 0.39646262076555516, disc_loss = 0.060630351515012046
Trained batch 51 in epoch 18, gen_loss = 0.395334612005032, disc_loss = 0.05987050440699722
Trained batch 52 in epoch 18, gen_loss = 0.3974121047078438, disc_loss = 0.059066870082872654
Trained batch 53 in epoch 18, gen_loss = 0.39605382553957125, disc_loss = 0.058141960874544804
Trained batch 54 in epoch 18, gen_loss = 0.395628823204474, disc_loss = 0.057375599587844175
Trained batch 55 in epoch 18, gen_loss = 0.39561375895781176, disc_loss = 0.056655446341859976
Trained batch 56 in epoch 18, gen_loss = 0.3959004363992758, disc_loss = 0.055869579421388996
Trained batch 57 in epoch 18, gen_loss = 0.3951230899527155, disc_loss = 0.05558616806881438
Trained batch 58 in epoch 18, gen_loss = 0.3951028193962776, disc_loss = 0.05578307577771908
Trained batch 59 in epoch 18, gen_loss = 0.39589522952834766, disc_loss = 0.055801126585962875
Trained batch 60 in epoch 18, gen_loss = 0.3964323868028453, disc_loss = 0.0552539267027598
Trained batch 61 in epoch 18, gen_loss = 0.39775621242100195, disc_loss = 0.0546275413099436
Trained batch 62 in epoch 18, gen_loss = 0.39839724344866617, disc_loss = 0.05388677265820286
Trained batch 63 in epoch 18, gen_loss = 0.39790729410015047, disc_loss = 0.05347640772379236
Trained batch 64 in epoch 18, gen_loss = 0.39822656030838305, disc_loss = 0.052814835116553764
Trained batch 65 in epoch 18, gen_loss = 0.39845189474748843, disc_loss = 0.052460428165046105
Trained batch 66 in epoch 18, gen_loss = 0.3974081062114061, disc_loss = 0.05244449182038209
Trained batch 67 in epoch 18, gen_loss = 0.3969077965354218, disc_loss = 0.0519973345388494
Trained batch 68 in epoch 18, gen_loss = 0.3970844229494316, disc_loss = 0.05139475836135123
Trained batch 69 in epoch 18, gen_loss = 0.3972681865096092, disc_loss = 0.05096753550294254
Trained batch 70 in epoch 18, gen_loss = 0.3972404874126676, disc_loss = 0.05055969572481765
Trained batch 71 in epoch 18, gen_loss = 0.39628481016390854, disc_loss = 0.0504514149377226
Trained batch 72 in epoch 18, gen_loss = 0.3974336273457906, disc_loss = 0.04995371895676402
Trained batch 73 in epoch 18, gen_loss = 0.39746274275554194, disc_loss = 0.049579555816898074
Trained batch 74 in epoch 18, gen_loss = 0.3974489206075668, disc_loss = 0.05055367171143492
Trained batch 75 in epoch 18, gen_loss = 0.3986207836944806, disc_loss = 0.05419501132258263
Trained batch 76 in epoch 18, gen_loss = 0.39848623318331583, disc_loss = 0.05377819199816554
Trained batch 77 in epoch 18, gen_loss = 0.39739222270555985, disc_loss = 0.054502697464508504
Trained batch 78 in epoch 18, gen_loss = 0.39809729762469664, disc_loss = 0.055018940628093635
Trained batch 79 in epoch 18, gen_loss = 0.3982662020251155, disc_loss = 0.054480882425559686
Trained batch 80 in epoch 18, gen_loss = 0.398819465144181, disc_loss = 0.05399569563774599
Trained batch 81 in epoch 18, gen_loss = 0.3993261821749734, disc_loss = 0.05364767410338107
Trained batch 82 in epoch 18, gen_loss = 0.40002013563391675, disc_loss = 0.05318994344919022
Trained batch 83 in epoch 18, gen_loss = 0.4000812877146971, disc_loss = 0.05270503431979921
Trained batch 84 in epoch 18, gen_loss = 0.3997358748141457, disc_loss = 0.05314959696877529
Trained batch 85 in epoch 18, gen_loss = 0.4005400210965511, disc_loss = 0.055086221172322716
Trained batch 86 in epoch 18, gen_loss = 0.400361517893857, disc_loss = 0.05529448772705663
Trained batch 87 in epoch 18, gen_loss = 0.40057553808120167, disc_loss = 0.05484252737898549
Trained batch 88 in epoch 18, gen_loss = 0.4003865576527092, disc_loss = 0.054683978779220516
Trained batch 89 in epoch 18, gen_loss = 0.40004860046837065, disc_loss = 0.054261234045649566
Trained batch 90 in epoch 18, gen_loss = 0.40003247067823516, disc_loss = 0.05399388487829448
Trained batch 91 in epoch 18, gen_loss = 0.40003014696033107, disc_loss = 0.05353455204496403
Trained batch 92 in epoch 18, gen_loss = 0.40015369221087427, disc_loss = 0.05339058888675545
Trained batch 93 in epoch 18, gen_loss = 0.3993724338868831, disc_loss = 0.05392642334559338
Trained batch 94 in epoch 18, gen_loss = 0.40094865325250123, disc_loss = 0.0539768507164952
Trained batch 95 in epoch 18, gen_loss = 0.4010691231427093, disc_loss = 0.05358241610520054
Trained batch 96 in epoch 18, gen_loss = 0.4003114477568066, disc_loss = 0.053627420826479026
Trained batch 97 in epoch 18, gen_loss = 0.40025506746404027, disc_loss = 0.05319075683150821
Trained batch 98 in epoch 18, gen_loss = 0.4004018645394932, disc_loss = 0.053860091514923054
Trained batch 99 in epoch 18, gen_loss = 0.4001401098072529, disc_loss = 0.05401352943386883
Trained batch 100 in epoch 18, gen_loss = 0.4004163519285693, disc_loss = 0.05355939647588547
Trained batch 101 in epoch 18, gen_loss = 0.4009633696838921, disc_loss = 0.05314552820945049
Trained batch 102 in epoch 18, gen_loss = 0.4007862880102639, disc_loss = 0.05271830953639543
Trained batch 103 in epoch 18, gen_loss = 0.400803871309528, disc_loss = 0.052432337431058004
Trained batch 104 in epoch 18, gen_loss = 0.4009443190835771, disc_loss = 0.05215102442584577
Trained batch 105 in epoch 18, gen_loss = 0.4008490222523797, disc_loss = 0.051742733776885666
Trained batch 106 in epoch 18, gen_loss = 0.4010452086401877, disc_loss = 0.051326250505120116
Trained batch 107 in epoch 18, gen_loss = 0.400508812594193, disc_loss = 0.05119173063603402
Trained batch 108 in epoch 18, gen_loss = 0.4006037399036075, disc_loss = 0.05251189738665835
Trained batch 109 in epoch 18, gen_loss = 0.39961573549292306, disc_loss = 0.05346240022389049
Trained batch 110 in epoch 18, gen_loss = 0.3997067721845867, disc_loss = 0.0531454958600571
Trained batch 111 in epoch 18, gen_loss = 0.4008128849257316, disc_loss = 0.05353504356545662
Trained batch 112 in epoch 18, gen_loss = 0.4010291404164998, disc_loss = 0.053371851855839515
Trained batch 113 in epoch 18, gen_loss = 0.4014597225346063, disc_loss = 0.05340319767741388
Trained batch 114 in epoch 18, gen_loss = 0.4011848295512407, disc_loss = 0.053079991662145956
Trained batch 115 in epoch 18, gen_loss = 0.4016583087886202, disc_loss = 0.052704057949274005
Trained batch 116 in epoch 18, gen_loss = 0.4016070168497216, disc_loss = 0.0523169057793979
Trained batch 117 in epoch 18, gen_loss = 0.40159911687596367, disc_loss = 0.05205508361775744
Trained batch 118 in epoch 18, gen_loss = 0.40082318404642475, disc_loss = 0.052225121265637275
Trained batch 119 in epoch 18, gen_loss = 0.40103741399943826, disc_loss = 0.05449835666610549
Trained batch 120 in epoch 18, gen_loss = 0.40010825230562985, disc_loss = 0.054457739973055926
Trained batch 121 in epoch 18, gen_loss = 0.3995179715948027, disc_loss = 0.05441833500460279
Trained batch 122 in epoch 18, gen_loss = 0.39928260191184717, disc_loss = 0.054285424655469934
Trained batch 123 in epoch 18, gen_loss = 0.3995768068538558, disc_loss = 0.053941598507545645
Trained batch 124 in epoch 18, gen_loss = 0.40004680120944974, disc_loss = 0.05357253328710795
Trained batch 125 in epoch 18, gen_loss = 0.3998047076756992, disc_loss = 0.053208085349834865
Trained batch 126 in epoch 18, gen_loss = 0.40015047894218775, disc_loss = 0.05285335701384296
Trained batch 127 in epoch 18, gen_loss = 0.40006173320580274, disc_loss = 0.0525464548227319
Trained batch 128 in epoch 18, gen_loss = 0.4002751517434453, disc_loss = 0.05232695888280291
Trained batch 129 in epoch 18, gen_loss = 0.40091905811658274, disc_loss = 0.0521218681958719
Trained batch 130 in epoch 18, gen_loss = 0.40047139281989963, disc_loss = 0.05236925689133865
Trained batch 131 in epoch 18, gen_loss = 0.40031038190830837, disc_loss = 0.052196593316638784
Trained batch 132 in epoch 18, gen_loss = 0.40065551801283555, disc_loss = 0.052118527104279826
Trained batch 133 in epoch 18, gen_loss = 0.40034031234125594, disc_loss = 0.05199801339072856
Trained batch 134 in epoch 18, gen_loss = 0.40044976815029426, disc_loss = 0.0517897965558977
Trained batch 135 in epoch 18, gen_loss = 0.4007406869136235, disc_loss = 0.05175728001289398
Trained batch 136 in epoch 18, gen_loss = 0.40072222010497627, disc_loss = 0.051443374420033536
Trained batch 137 in epoch 18, gen_loss = 0.40024007802856143, disc_loss = 0.051336755783742534
Trained batch 138 in epoch 18, gen_loss = 0.4001911502304695, disc_loss = 0.05105257978689649
Trained batch 139 in epoch 18, gen_loss = 0.4003070683351585, disc_loss = 0.050762038401860214
Trained batch 140 in epoch 18, gen_loss = 0.40039159864821333, disc_loss = 0.05112696998151587
Trained batch 141 in epoch 18, gen_loss = 0.4000549837946892, disc_loss = 0.053107739481943805
Trained batch 142 in epoch 18, gen_loss = 0.3999773162853468, disc_loss = 0.053215754449601985
Trained batch 143 in epoch 18, gen_loss = 0.4003929525820745, disc_loss = 0.05345049375318922
Trained batch 144 in epoch 18, gen_loss = 0.40026349497252495, disc_loss = 0.05356214826541214
Trained batch 145 in epoch 18, gen_loss = 0.3997774035350917, disc_loss = 0.053837952385847904
Trained batch 146 in epoch 18, gen_loss = 0.3987589112552656, disc_loss = 0.05383135800623671
Trained batch 147 in epoch 18, gen_loss = 0.39869236654123746, disc_loss = 0.05380486852074092
Trained batch 148 in epoch 18, gen_loss = 0.39898512597452074, disc_loss = 0.05366894674343651
Trained batch 149 in epoch 18, gen_loss = 0.398725223839283, disc_loss = 0.05355347908101976
Trained batch 150 in epoch 18, gen_loss = 0.3988156442018534, disc_loss = 0.053317762087931896
Trained batch 151 in epoch 18, gen_loss = 0.3982860935165694, disc_loss = 0.05311361544973854
Trained batch 152 in epoch 18, gen_loss = 0.3983717594855751, disc_loss = 0.05294955674303221
Trained batch 153 in epoch 18, gen_loss = 0.3986553374629516, disc_loss = 0.05298178946877551
Trained batch 154 in epoch 18, gen_loss = 0.3981590070070759, disc_loss = 0.05352482145892516
Trained batch 155 in epoch 18, gen_loss = 0.3988406026783662, disc_loss = 0.05343215878252895
Trained batch 156 in epoch 18, gen_loss = 0.39930904585464744, disc_loss = 0.05357611852336177
Trained batch 157 in epoch 18, gen_loss = 0.39907136116224, disc_loss = 0.0539937272485157
Trained batch 158 in epoch 18, gen_loss = 0.39879085011077375, disc_loss = 0.05380642845488663
Trained batch 159 in epoch 18, gen_loss = 0.39901497652754186, disc_loss = 0.053752277189050804
Trained batch 160 in epoch 18, gen_loss = 0.39925130303972256, disc_loss = 0.05369222530030778
Trained batch 161 in epoch 18, gen_loss = 0.3995374353763498, disc_loss = 0.05344006255625483
Trained batch 162 in epoch 18, gen_loss = 0.3996474544511982, disc_loss = 0.05360445619897883
Trained batch 163 in epoch 18, gen_loss = 0.39935980401024584, disc_loss = 0.05373071867506951
Trained batch 164 in epoch 18, gen_loss = 0.39942469009847353, disc_loss = 0.053458935234018345
Trained batch 165 in epoch 18, gen_loss = 0.3997229083654392, disc_loss = 0.053276753173692216
Trained batch 166 in epoch 18, gen_loss = 0.39986071302862225, disc_loss = 0.053099461677790935
Trained batch 167 in epoch 18, gen_loss = 0.3999657532466309, disc_loss = 0.052898439354196726
Trained batch 168 in epoch 18, gen_loss = 0.400331268737302, disc_loss = 0.05268824330569636
Trained batch 169 in epoch 18, gen_loss = 0.4004400923848152, disc_loss = 0.05246364226400414
Trained batch 170 in epoch 18, gen_loss = 0.40093633924659927, disc_loss = 0.052227361549824824
Trained batch 171 in epoch 18, gen_loss = 0.40135259675078616, disc_loss = 0.05199005005090649
Trained batch 172 in epoch 18, gen_loss = 0.40095226828418024, disc_loss = 0.05203448673925562
Trained batch 173 in epoch 18, gen_loss = 0.40029849394642075, disc_loss = 0.053218717363010024
Trained batch 174 in epoch 18, gen_loss = 0.4004857212305069, disc_loss = 0.05412854244400348
Trained batch 175 in epoch 18, gen_loss = 0.4003595109520988, disc_loss = 0.05390178212440911
Trained batch 176 in epoch 18, gen_loss = 0.40055192720755345, disc_loss = 0.053741793208729245
Trained batch 177 in epoch 18, gen_loss = 0.40061621811617626, disc_loss = 0.05364759949956801
Trained batch 178 in epoch 18, gen_loss = 0.4004683750135273, disc_loss = 0.05347108623720497
Trained batch 179 in epoch 18, gen_loss = 0.4004927187330193, disc_loss = 0.05365558721176866
Trained batch 180 in epoch 18, gen_loss = 0.4000490642878232, disc_loss = 0.05518899248007335
Trained batch 181 in epoch 18, gen_loss = 0.4007658089746486, disc_loss = 0.055178588964966135
Trained batch 182 in epoch 18, gen_loss = 0.40136897881500055, disc_loss = 0.05500247253390039
Trained batch 183 in epoch 18, gen_loss = 0.401051060418072, disc_loss = 0.05502308946882334
Trained batch 184 in epoch 18, gen_loss = 0.401031154313603, disc_loss = 0.05508307739337151
Trained batch 185 in epoch 18, gen_loss = 0.4005659821052705, disc_loss = 0.05508957243704748
Trained batch 186 in epoch 18, gen_loss = 0.4005869664451018, disc_loss = 0.055012571294219256
Trained batch 187 in epoch 18, gen_loss = 0.4004927070692499, disc_loss = 0.05477270199867718
Trained batch 188 in epoch 18, gen_loss = 0.4005622038292506, disc_loss = 0.05462609352938161
Trained batch 189 in epoch 18, gen_loss = 0.4007718788165795, disc_loss = 0.05512791514445684
Trained batch 190 in epoch 18, gen_loss = 0.40034556349846706, disc_loss = 0.05587923459718443
Trained batch 191 in epoch 18, gen_loss = 0.40038240087839466, disc_loss = 0.056857489158574026
Trained batch 192 in epoch 18, gen_loss = 0.40040339452306223, disc_loss = 0.05664374495233974
Trained batch 193 in epoch 18, gen_loss = 0.4004747940553832, disc_loss = 0.056512322740091644
Trained batch 194 in epoch 18, gen_loss = 0.3999765199728501, disc_loss = 0.05639983958397538
Trained batch 195 in epoch 18, gen_loss = 0.3996344869386177, disc_loss = 0.05621207635897231
Trained batch 196 in epoch 18, gen_loss = 0.3998994460414509, disc_loss = 0.055965888039752616
Trained batch 197 in epoch 18, gen_loss = 0.3996938538521227, disc_loss = 0.05583468847672897
Trained batch 198 in epoch 18, gen_loss = 0.3995197980697431, disc_loss = 0.0557330620695074
Trained batch 199 in epoch 18, gen_loss = 0.39948843531310557, disc_loss = 0.05614892021287233
Trained batch 200 in epoch 18, gen_loss = 0.39916699123916344, disc_loss = 0.057291941860903854
Trained batch 201 in epoch 18, gen_loss = 0.3989559529293882, disc_loss = 0.05729860196922823
Trained batch 202 in epoch 18, gen_loss = 0.3988440664384165, disc_loss = 0.05721015325779545
Trained batch 203 in epoch 18, gen_loss = 0.3984518174593355, disc_loss = 0.057108259417445344
Trained batch 204 in epoch 18, gen_loss = 0.3984954913214939, disc_loss = 0.05702343140160892
Trained batch 205 in epoch 18, gen_loss = 0.39889163321372373, disc_loss = 0.05725724485621435
Trained batch 206 in epoch 18, gen_loss = 0.39856921021201186, disc_loss = 0.05728485007378934
Trained batch 207 in epoch 18, gen_loss = 0.39877608669205356, disc_loss = 0.057097823471010015
Trained batch 208 in epoch 18, gen_loss = 0.3989960765867142, disc_loss = 0.05706607372584668
Trained batch 209 in epoch 18, gen_loss = 0.39901774731420336, disc_loss = 0.056898724469577985
Trained batch 210 in epoch 18, gen_loss = 0.3988723807849025, disc_loss = 0.05680354642659708
Trained batch 211 in epoch 18, gen_loss = 0.399064976862579, disc_loss = 0.05666444505529724
Trained batch 212 in epoch 18, gen_loss = 0.3994238725710363, disc_loss = 0.056469536836788126
Trained batch 213 in epoch 18, gen_loss = 0.39931345591756784, disc_loss = 0.05629117347334869
Trained batch 214 in epoch 18, gen_loss = 0.39933763416700585, disc_loss = 0.056203540492542954
Trained batch 215 in epoch 18, gen_loss = 0.39917032579304995, disc_loss = 0.05669729828110172
Trained batch 216 in epoch 18, gen_loss = 0.3993272238200711, disc_loss = 0.058554474135629045
Trained batch 217 in epoch 18, gen_loss = 0.3993027508942359, disc_loss = 0.058388915374328235
Trained batch 218 in epoch 18, gen_loss = 0.39919144303014836, disc_loss = 0.05849262243604551
Trained batch 219 in epoch 18, gen_loss = 0.39913959577679636, disc_loss = 0.05834988867017356
Trained batch 220 in epoch 18, gen_loss = 0.3994493215467056, disc_loss = 0.058140584752300745
Trained batch 221 in epoch 18, gen_loss = 0.3995112965370084, disc_loss = 0.05793131370231643
Trained batch 222 in epoch 18, gen_loss = 0.39942413989471215, disc_loss = 0.05771259067271055
Trained batch 223 in epoch 18, gen_loss = 0.3995902373987649, disc_loss = 0.057524611632938365
Trained batch 224 in epoch 18, gen_loss = 0.39907700293593934, disc_loss = 0.05750025129152669
Trained batch 225 in epoch 18, gen_loss = 0.3988638592109216, disc_loss = 0.05736223890124697
Trained batch 226 in epoch 18, gen_loss = 0.3989254861807508, disc_loss = 0.05715481726871188
Trained batch 227 in epoch 18, gen_loss = 0.3988774423405789, disc_loss = 0.05705753908280218
Trained batch 228 in epoch 18, gen_loss = 0.3982449563700039, disc_loss = 0.058140544245206635
Trained batch 229 in epoch 18, gen_loss = 0.3984146962347238, disc_loss = 0.05830598368268946
Trained batch 230 in epoch 18, gen_loss = 0.3986823400764754, disc_loss = 0.058325651420272275
Trained batch 231 in epoch 18, gen_loss = 0.3982992057271045, disc_loss = 0.058524541733465316
Trained batch 232 in epoch 18, gen_loss = 0.3986390282284037, disc_loss = 0.0583027795520751
Trained batch 233 in epoch 18, gen_loss = 0.39900405341998124, disc_loss = 0.05809301596620462
Trained batch 234 in epoch 18, gen_loss = 0.3992138198715575, disc_loss = 0.05803920427099504
Trained batch 235 in epoch 18, gen_loss = 0.39917899712415067, disc_loss = 0.057898091469986084
Trained batch 236 in epoch 18, gen_loss = 0.3990357245951262, disc_loss = 0.05769027663269061
Trained batch 237 in epoch 18, gen_loss = 0.3989635714087166, disc_loss = 0.05753351044215012
Trained batch 238 in epoch 18, gen_loss = 0.3990418840527036, disc_loss = 0.05733973334375847
Trained batch 239 in epoch 18, gen_loss = 0.3990686383719246, disc_loss = 0.05730126969865523
Trained batch 240 in epoch 18, gen_loss = 0.39879537549998256, disc_loss = 0.05734644481850425
Trained batch 241 in epoch 18, gen_loss = 0.3987337866228474, disc_loss = 0.057265686450433756
Trained batch 242 in epoch 18, gen_loss = 0.3986930325320719, disc_loss = 0.0571288830493366
Trained batch 243 in epoch 18, gen_loss = 0.3985142149031162, disc_loss = 0.05710879531040116
Trained batch 244 in epoch 18, gen_loss = 0.3982181855002228, disc_loss = 0.057354982784588115
Trained batch 245 in epoch 18, gen_loss = 0.39830957504549647, disc_loss = 0.058084767593858326
Trained batch 246 in epoch 18, gen_loss = 0.39805252198506946, disc_loss = 0.058001414131795465
Trained batch 247 in epoch 18, gen_loss = 0.39802360480591176, disc_loss = 0.05829478182356745
Trained batch 248 in epoch 18, gen_loss = 0.3982985037038604, disc_loss = 0.05834289467575619
Trained batch 249 in epoch 18, gen_loss = 0.3983331748843193, disc_loss = 0.05814803480915725
Trained batch 250 in epoch 18, gen_loss = 0.3982650273705859, disc_loss = 0.05801015768563783
Trained batch 251 in epoch 18, gen_loss = 0.3982993758741825, disc_loss = 0.05794784108672055
Trained batch 252 in epoch 18, gen_loss = 0.39820502863335516, disc_loss = 0.05797651264146559
Trained batch 253 in epoch 18, gen_loss = 0.3984256727606293, disc_loss = 0.05803763841308184
Trained batch 254 in epoch 18, gen_loss = 0.3983775471355401, disc_loss = 0.05785693517685229
Trained batch 255 in epoch 18, gen_loss = 0.3986092238337733, disc_loss = 0.05782287151851051
Trained batch 256 in epoch 18, gen_loss = 0.3982640827792164, disc_loss = 0.05802097055763876
Trained batch 257 in epoch 18, gen_loss = 0.39851037551497304, disc_loss = 0.05832875673225973
Trained batch 258 in epoch 18, gen_loss = 0.3983476645813025, disc_loss = 0.05821781835795657
Trained batch 259 in epoch 18, gen_loss = 0.3985014228293529, disc_loss = 0.05811420525961484
Trained batch 260 in epoch 18, gen_loss = 0.3981979002326841, disc_loss = 0.058050664421884605
Trained batch 261 in epoch 18, gen_loss = 0.3980636921434002, disc_loss = 0.05822175630467823
Trained batch 262 in epoch 18, gen_loss = 0.3978817055547192, disc_loss = 0.0584071979170998
Trained batch 263 in epoch 18, gen_loss = 0.3981447428126227, disc_loss = 0.05846661871306203
Trained batch 264 in epoch 18, gen_loss = 0.3979895493331945, disc_loss = 0.05839358635844206
Trained batch 265 in epoch 18, gen_loss = 0.3980266200308513, disc_loss = 0.05835739292267402
Trained batch 266 in epoch 18, gen_loss = 0.3977082654666365, disc_loss = 0.058721357951296516
Trained batch 267 in epoch 18, gen_loss = 0.39750428759117623, disc_loss = 0.05955137066550052
Trained batch 268 in epoch 18, gen_loss = 0.3977187197780077, disc_loss = 0.059396075744348055
Trained batch 269 in epoch 18, gen_loss = 0.3979491823801288, disc_loss = 0.059227348089701044
Trained batch 270 in epoch 18, gen_loss = 0.39781001116736786, disc_loss = 0.05911975753806339
Trained batch 271 in epoch 18, gen_loss = 0.3978738055619247, disc_loss = 0.05899209371487172
Trained batch 272 in epoch 18, gen_loss = 0.39785956206557516, disc_loss = 0.05899390223309835
Trained batch 273 in epoch 18, gen_loss = 0.3974355042089511, disc_loss = 0.05953939019593607
Trained batch 274 in epoch 18, gen_loss = 0.397690433643081, disc_loss = 0.060480037925934246
Trained batch 275 in epoch 18, gen_loss = 0.39764030326319777, disc_loss = 0.060326449922285974
Trained batch 276 in epoch 18, gen_loss = 0.39755316100180793, disc_loss = 0.06020799085383542
Trained batch 277 in epoch 18, gen_loss = 0.39755061027600613, disc_loss = 0.06008330551512111
Trained batch 278 in epoch 18, gen_loss = 0.39776877663682436, disc_loss = 0.05990146173124192
Trained batch 279 in epoch 18, gen_loss = 0.397671088842409, disc_loss = 0.05973290416378794
Trained batch 280 in epoch 18, gen_loss = 0.3978454906002907, disc_loss = 0.05955376725451643
Trained batch 281 in epoch 18, gen_loss = 0.39788279101146873, disc_loss = 0.05938149818404188
Trained batch 282 in epoch 18, gen_loss = 0.39795159846017725, disc_loss = 0.05921729141846299
Trained batch 283 in epoch 18, gen_loss = 0.39797812023423085, disc_loss = 0.05913893841567751
Trained batch 284 in epoch 18, gen_loss = 0.39778893365148915, disc_loss = 0.0590059345735139
Trained batch 285 in epoch 18, gen_loss = 0.39752332079452235, disc_loss = 0.059328138878751366
Trained batch 286 in epoch 18, gen_loss = 0.39799645735204014, disc_loss = 0.05940711908269583
Trained batch 287 in epoch 18, gen_loss = 0.39801630062154597, disc_loss = 0.05941684034284359
Trained batch 288 in epoch 18, gen_loss = 0.397928371200512, disc_loss = 0.05925837528302131
Trained batch 289 in epoch 18, gen_loss = 0.3978316057858796, disc_loss = 0.05930700849838041
Trained batch 290 in epoch 18, gen_loss = 0.3976446006613499, disc_loss = 0.05914791006294057
Trained batch 291 in epoch 18, gen_loss = 0.39737136769172265, disc_loss = 0.05900260722998223
Trained batch 292 in epoch 18, gen_loss = 0.39711554297611573, disc_loss = 0.058867994242954885
Trained batch 293 in epoch 18, gen_loss = 0.39729772432118043, disc_loss = 0.05870866420881531
Trained batch 294 in epoch 18, gen_loss = 0.39738460430654426, disc_loss = 0.058566181022295
Trained batch 295 in epoch 18, gen_loss = 0.3973496239632368, disc_loss = 0.05855054602284941
Trained batch 296 in epoch 18, gen_loss = 0.39728744739434535, disc_loss = 0.058672870677089956
Trained batch 297 in epoch 18, gen_loss = 0.39702072254563336, disc_loss = 0.05927699496938328
Trained batch 298 in epoch 18, gen_loss = 0.3974908651615864, disc_loss = 0.059785461671538274
Trained batch 299 in epoch 18, gen_loss = 0.39796496187647185, disc_loss = 0.05965737733524293
Trained batch 300 in epoch 18, gen_loss = 0.39784310926432626, disc_loss = 0.059486205254888715
Trained batch 301 in epoch 18, gen_loss = 0.3976595332192269, disc_loss = 0.05949898370825346
Trained batch 302 in epoch 18, gen_loss = 0.3976585324546292, disc_loss = 0.059349875431507826
Trained batch 303 in epoch 18, gen_loss = 0.39784701202849027, disc_loss = 0.059199551642737595
Trained batch 304 in epoch 18, gen_loss = 0.39792650698638354, disc_loss = 0.059048445976232405
Trained batch 305 in epoch 18, gen_loss = 0.39785286272857706, disc_loss = 0.05905153372422396
Trained batch 306 in epoch 18, gen_loss = 0.3976162331791576, disc_loss = 0.059195059702006635
Trained batch 307 in epoch 18, gen_loss = 0.39810742839396773, disc_loss = 0.05906618718063918
Trained batch 308 in epoch 18, gen_loss = 0.3981707082114945, disc_loss = 0.059011887073287785
Trained batch 309 in epoch 18, gen_loss = 0.398215767500862, disc_loss = 0.058855321286847034
Trained batch 310 in epoch 18, gen_loss = 0.3981840561153038, disc_loss = 0.058700140456330645
Trained batch 311 in epoch 18, gen_loss = 0.3982507585046383, disc_loss = 0.058531503863214776
Trained batch 312 in epoch 18, gen_loss = 0.39836527683293094, disc_loss = 0.05837168057892507
Trained batch 313 in epoch 18, gen_loss = 0.3981261370573074, disc_loss = 0.05822103785107707
Trained batch 314 in epoch 18, gen_loss = 0.39818529131866637, disc_loss = 0.0580591634669829
Trained batch 315 in epoch 18, gen_loss = 0.3979217297385765, disc_loss = 0.05790227802935988
Trained batch 316 in epoch 18, gen_loss = 0.3979953573987311, disc_loss = 0.05775523397113764
Trained batch 317 in epoch 18, gen_loss = 0.39790231162834466, disc_loss = 0.05758745252570641
Trained batch 318 in epoch 18, gen_loss = 0.39779359349823296, disc_loss = 0.057430659266054444
Trained batch 319 in epoch 18, gen_loss = 0.39795292750932276, disc_loss = 0.05728489949833602
Trained batch 320 in epoch 18, gen_loss = 0.3980445928198526, disc_loss = 0.0571233084442738
Trained batch 321 in epoch 18, gen_loss = 0.3980770366069693, disc_loss = 0.05697301169568152
Trained batch 322 in epoch 18, gen_loss = 0.39820346932846695, disc_loss = 0.05682230974048745
Trained batch 323 in epoch 18, gen_loss = 0.39822234383519783, disc_loss = 0.05669110146477634
Trained batch 324 in epoch 18, gen_loss = 0.3981426124847852, disc_loss = 0.05656700435739297
Trained batch 325 in epoch 18, gen_loss = 0.3980301808268746, disc_loss = 0.05641164331256977
Trained batch 326 in epoch 18, gen_loss = 0.397953775269905, disc_loss = 0.056296546473552325
Trained batch 327 in epoch 18, gen_loss = 0.39782894452715795, disc_loss = 0.056339146109388734
Trained batch 328 in epoch 18, gen_loss = 0.3976147096479555, disc_loss = 0.05694554636883337
Trained batch 329 in epoch 18, gen_loss = 0.3976719055663456, disc_loss = 0.05695450422777371
Trained batch 330 in epoch 18, gen_loss = 0.3975827693489023, disc_loss = 0.05702096790502979
Trained batch 331 in epoch 18, gen_loss = 0.3977112798356866, disc_loss = 0.056882553689002274
Trained batch 332 in epoch 18, gen_loss = 0.39774976992929306, disc_loss = 0.05677256617393043
Trained batch 333 in epoch 18, gen_loss = 0.39747344720327926, disc_loss = 0.056761151910229714
Trained batch 334 in epoch 18, gen_loss = 0.3974056174950813, disc_loss = 0.05661984108277221
Trained batch 335 in epoch 18, gen_loss = 0.39738874656281303, disc_loss = 0.05647062488077652
Trained batch 336 in epoch 18, gen_loss = 0.39746245065322616, disc_loss = 0.05635012908996213
Trained batch 337 in epoch 18, gen_loss = 0.39744286719687594, disc_loss = 0.05625363670223387
Trained batch 338 in epoch 18, gen_loss = 0.39756352900579617, disc_loss = 0.05619049426662711
Trained batch 339 in epoch 18, gen_loss = 0.39786153150831954, disc_loss = 0.05611052876338363
Trained batch 340 in epoch 18, gen_loss = 0.39809704320696443, disc_loss = 0.05600487295527262
Trained batch 341 in epoch 18, gen_loss = 0.3981095572922662, disc_loss = 0.05598136239102361
Trained batch 342 in epoch 18, gen_loss = 0.3982451027666514, disc_loss = 0.05600884303711246
Trained batch 343 in epoch 18, gen_loss = 0.39826576701950195, disc_loss = 0.05670403488803395
Trained batch 344 in epoch 18, gen_loss = 0.39849756588970403, disc_loss = 0.05677266331470531
Trained batch 345 in epoch 18, gen_loss = 0.39870230108499527, disc_loss = 0.056976111842631606
Trained batch 346 in epoch 18, gen_loss = 0.39866806669778027, disc_loss = 0.05697676718707387
Trained batch 347 in epoch 18, gen_loss = 0.3986971938832738, disc_loss = 0.05700110300476181
Trained batch 348 in epoch 18, gen_loss = 0.39862073829829864, disc_loss = 0.05690488504261888
Trained batch 349 in epoch 18, gen_loss = 0.3988026117852756, disc_loss = 0.056846147126385145
Trained batch 350 in epoch 18, gen_loss = 0.39889360692596165, disc_loss = 0.05689063030387941
Trained batch 351 in epoch 18, gen_loss = 0.3990705928087912, disc_loss = 0.05685500107409263
Trained batch 352 in epoch 18, gen_loss = 0.39911706813165215, disc_loss = 0.05699726009461765
Trained batch 353 in epoch 18, gen_loss = 0.3990903335523471, disc_loss = 0.05691573983005716
Trained batch 354 in epoch 18, gen_loss = 0.3992485458162469, disc_loss = 0.05702044915040614
Trained batch 355 in epoch 18, gen_loss = 0.39925112152534925, disc_loss = 0.05705886599450801
Trained batch 356 in epoch 18, gen_loss = 0.3991004633052008, disc_loss = 0.05696051356484409
Trained batch 357 in epoch 18, gen_loss = 0.39930716452485354, disc_loss = 0.056852903034975075
Trained batch 358 in epoch 18, gen_loss = 0.39949071859748914, disc_loss = 0.05673190609430038
Trained batch 359 in epoch 18, gen_loss = 0.3996159746001164, disc_loss = 0.056630089935950104
Trained batch 360 in epoch 18, gen_loss = 0.39953076232668433, disc_loss = 0.05652544573155797
Trained batch 361 in epoch 18, gen_loss = 0.3998754938745367, disc_loss = 0.05645924512276333
Trained batch 362 in epoch 18, gen_loss = 0.3996588391952278, disc_loss = 0.0564430432173503
Trained batch 363 in epoch 18, gen_loss = 0.39994481300095935, disc_loss = 0.05633208264627463
Trained batch 364 in epoch 18, gen_loss = 0.4000465508601437, disc_loss = 0.05621783183760022
Trained batch 365 in epoch 18, gen_loss = 0.3999007895914583, disc_loss = 0.05614192003659049
Trained batch 366 in epoch 18, gen_loss = 0.4000828337198382, disc_loss = 0.05602806979379228
Trained batch 367 in epoch 18, gen_loss = 0.40015172776158736, disc_loss = 0.05593525501140191
Trained batch 368 in epoch 18, gen_loss = 0.4002597913913287, disc_loss = 0.05582618942802272
Trained batch 369 in epoch 18, gen_loss = 0.4001146898479075, disc_loss = 0.05585763125453849
Trained batch 370 in epoch 18, gen_loss = 0.3997893049469534, disc_loss = 0.05632381226787107
Trained batch 371 in epoch 18, gen_loss = 0.39990152622903546, disc_loss = 0.05675458180297527
Trained batch 372 in epoch 18, gen_loss = 0.40005537320238016, disc_loss = 0.05664029232558392
Trained batch 373 in epoch 18, gen_loss = 0.399695133182773, disc_loss = 0.05677083354283941
Trained batch 374 in epoch 18, gen_loss = 0.40006118921438855, disc_loss = 0.056664288838704426
Trained batch 375 in epoch 18, gen_loss = 0.39998671907852307, disc_loss = 0.05692765659632835
Trained batch 376 in epoch 18, gen_loss = 0.3998669726225678, disc_loss = 0.056934057974530786
Trained batch 377 in epoch 18, gen_loss = 0.3998203956812778, disc_loss = 0.05687435651345858
Trained batch 378 in epoch 18, gen_loss = 0.39984034080461334, disc_loss = 0.0567533807008279
Trained batch 379 in epoch 18, gen_loss = 0.39994142820176326, disc_loss = 0.05680147124160277
Trained batch 380 in epoch 18, gen_loss = 0.3998538504826428, disc_loss = 0.05729883421319989
Trained batch 381 in epoch 18, gen_loss = 0.3998639400638835, disc_loss = 0.05724740539389755
Trained batch 382 in epoch 18, gen_loss = 0.4000186147095329, disc_loss = 0.05729890976577764
Trained batch 383 in epoch 18, gen_loss = 0.39998120663221925, disc_loss = 0.05731619409440706
Trained batch 384 in epoch 18, gen_loss = 0.4001438686212936, disc_loss = 0.0572055179432228
Trained batch 385 in epoch 18, gen_loss = 0.40032200611780344, disc_loss = 0.057134555276348184
Trained batch 386 in epoch 18, gen_loss = 0.39995835374954136, disc_loss = 0.05753990255045952
Trained batch 387 in epoch 18, gen_loss = 0.40024083480238914, disc_loss = 0.057965789278297083
Trained batch 388 in epoch 18, gen_loss = 0.4002575882372942, disc_loss = 0.05784214037089851
Trained batch 389 in epoch 18, gen_loss = 0.4003436734661078, disc_loss = 0.05780729521543552
Trained batch 390 in epoch 18, gen_loss = 0.4004473723947545, disc_loss = 0.057701043736980394
Trained batch 391 in epoch 18, gen_loss = 0.4003964961715499, disc_loss = 0.05761020532239
Trained batch 392 in epoch 18, gen_loss = 0.4003714281714903, disc_loss = 0.057510557240846805
Trained batch 393 in epoch 18, gen_loss = 0.40035864033826113, disc_loss = 0.057456341903032684
Trained batch 394 in epoch 18, gen_loss = 0.4006644581314884, disc_loss = 0.05754029739035081
Trained batch 395 in epoch 18, gen_loss = 0.4005907256570127, disc_loss = 0.057478009803088925
Trained batch 396 in epoch 18, gen_loss = 0.40071042347464814, disc_loss = 0.05735433797448198
Trained batch 397 in epoch 18, gen_loss = 0.40085767610138984, disc_loss = 0.057237908688734226
Trained batch 398 in epoch 18, gen_loss = 0.40116048385774283, disc_loss = 0.05713317435664267
Trained batch 399 in epoch 18, gen_loss = 0.401145787127316, disc_loss = 0.05703202929580584
Trained batch 400 in epoch 18, gen_loss = 0.40128163049494536, disc_loss = 0.056903903660575794
Trained batch 401 in epoch 18, gen_loss = 0.40114292461628936, disc_loss = 0.05681923176138778
Trained batch 402 in epoch 18, gen_loss = 0.4011194800250879, disc_loss = 0.05675127743870464
Trained batch 403 in epoch 18, gen_loss = 0.4011162531626697, disc_loss = 0.05667457684164516
Trained batch 404 in epoch 18, gen_loss = 0.40117847628799486, disc_loss = 0.05659690879883222
Trained batch 405 in epoch 18, gen_loss = 0.40125927699757324, disc_loss = 0.056612623311817795
Trained batch 406 in epoch 18, gen_loss = 0.4011854720130307, disc_loss = 0.05718610981017058
Trained batch 407 in epoch 18, gen_loss = 0.40151226611844465, disc_loss = 0.05743463543545017
Trained batch 408 in epoch 18, gen_loss = 0.40154665172974463, disc_loss = 0.057343862966741356
Trained batch 409 in epoch 18, gen_loss = 0.40164468103065726, disc_loss = 0.05723752106608051
Trained batch 410 in epoch 18, gen_loss = 0.4015696289112968, disc_loss = 0.05713638405195481
Trained batch 411 in epoch 18, gen_loss = 0.40142939619502976, disc_loss = 0.05702575243720152
Trained batch 412 in epoch 18, gen_loss = 0.4013579169933213, disc_loss = 0.056919416626937884
Trained batch 413 in epoch 18, gen_loss = 0.4013060401531233, disc_loss = 0.05679765181247019
Trained batch 414 in epoch 18, gen_loss = 0.4013812778584928, disc_loss = 0.056673761928476486
Trained batch 415 in epoch 18, gen_loss = 0.40153748595800537, disc_loss = 0.05655504252354149
Trained batch 416 in epoch 18, gen_loss = 0.40149922247270314, disc_loss = 0.056439014445382844
Trained batch 417 in epoch 18, gen_loss = 0.4015286352004161, disc_loss = 0.056315964374147605
Trained batch 418 in epoch 18, gen_loss = 0.40137951765965163, disc_loss = 0.05621090591918491
Trained batch 419 in epoch 18, gen_loss = 0.4013810871967248, disc_loss = 0.056116040038787535
Trained batch 420 in epoch 18, gen_loss = 0.4013494451722736, disc_loss = 0.056001454966713514
Trained batch 421 in epoch 18, gen_loss = 0.40130945676452173, disc_loss = 0.05589496202091576
Trained batch 422 in epoch 18, gen_loss = 0.40115371652951476, disc_loss = 0.05581602668962122
Trained batch 423 in epoch 18, gen_loss = 0.4009582521569616, disc_loss = 0.05569667263365052
Trained batch 424 in epoch 18, gen_loss = 0.4011527713256724, disc_loss = 0.05560614340555142
Trained batch 425 in epoch 18, gen_loss = 0.40103190623118845, disc_loss = 0.05548649239069629
Trained batch 426 in epoch 18, gen_loss = 0.4011674175427167, disc_loss = 0.055370436527655054
Trained batch 427 in epoch 18, gen_loss = 0.4011330806136688, disc_loss = 0.05528814765998972
Trained batch 428 in epoch 18, gen_loss = 0.4012055453651157, disc_loss = 0.05518466975357566
Trained batch 429 in epoch 18, gen_loss = 0.4009912775352944, disc_loss = 0.05519579335787268
Trained batch 430 in epoch 18, gen_loss = 0.40101028017682433, disc_loss = 0.05530968417787358
Trained batch 431 in epoch 18, gen_loss = 0.4010509032135208, disc_loss = 0.05521735094522161
Trained batch 432 in epoch 18, gen_loss = 0.40114136590831, disc_loss = 0.05525891863962519
Trained batch 433 in epoch 18, gen_loss = 0.40103984637881207, disc_loss = 0.055215141491337855
Trained batch 434 in epoch 18, gen_loss = 0.4011605545364577, disc_loss = 0.05510775231081864
Trained batch 435 in epoch 18, gen_loss = 0.4010538106459543, disc_loss = 0.055038523501417504
Trained batch 436 in epoch 18, gen_loss = 0.4012220364481688, disc_loss = 0.05524525904785032
Trained batch 437 in epoch 18, gen_loss = 0.4011645601152285, disc_loss = 0.05570313265572672
Trained batch 438 in epoch 18, gen_loss = 0.40116435482860424, disc_loss = 0.05569570891745813
Trained batch 439 in epoch 18, gen_loss = 0.4012966612861915, disc_loss = 0.05576134501871738
Trained batch 440 in epoch 18, gen_loss = 0.40117017566617114, disc_loss = 0.055882420466870676
Trained batch 441 in epoch 18, gen_loss = 0.40128707282278875, disc_loss = 0.05580230537650272
Trained batch 442 in epoch 18, gen_loss = 0.40133696555687665, disc_loss = 0.05569954637993068
Trained batch 443 in epoch 18, gen_loss = 0.4013108387925066, disc_loss = 0.05560960728666737
Trained batch 444 in epoch 18, gen_loss = 0.4014235905382071, disc_loss = 0.055529317600924645
Trained batch 445 in epoch 18, gen_loss = 0.4013675342025778, disc_loss = 0.055441289962657764
Trained batch 446 in epoch 18, gen_loss = 0.40124573926930995, disc_loss = 0.055409881623849376
Trained batch 447 in epoch 18, gen_loss = 0.40135912547287134, disc_loss = 0.05535631344745135
Trained batch 448 in epoch 18, gen_loss = 0.4013119463732089, disc_loss = 0.055264356641517846
Trained batch 449 in epoch 18, gen_loss = 0.401333670715491, disc_loss = 0.05520341014489531
Trained batch 450 in epoch 18, gen_loss = 0.40131795627711353, disc_loss = 0.05519583855782472
Trained batch 451 in epoch 18, gen_loss = 0.40142814633724966, disc_loss = 0.05532183647938732
Trained batch 452 in epoch 18, gen_loss = 0.4017328154501273, disc_loss = 0.0553614983178889
Trained batch 453 in epoch 18, gen_loss = 0.40186129008226984, disc_loss = 0.05528453756575083
Trained batch 454 in epoch 18, gen_loss = 0.401696409530692, disc_loss = 0.05523454153316689
Trained batch 455 in epoch 18, gen_loss = 0.4017765826235215, disc_loss = 0.05519685473726049
Trained batch 456 in epoch 18, gen_loss = 0.40168140809045577, disc_loss = 0.05514756773743183
Trained batch 457 in epoch 18, gen_loss = 0.40171918471437357, disc_loss = 0.05505287338365439
Trained batch 458 in epoch 18, gen_loss = 0.40182656267239897, disc_loss = 0.055024663227851746
Trained batch 459 in epoch 18, gen_loss = 0.40177855520792627, disc_loss = 0.055242941992195406
Trained batch 460 in epoch 18, gen_loss = 0.4016863153257494, disc_loss = 0.05526195920058354
Testing Epoch 18
Training Epoch 19
Trained batch 0 in epoch 19, gen_loss = 0.46729856729507446, disc_loss = 0.031188327819108963
Trained batch 1 in epoch 19, gen_loss = 0.41210681200027466, disc_loss = 0.01952571189031005
Trained batch 2 in epoch 19, gen_loss = 0.4034779171148936, disc_loss = 0.019667251346011955
Trained batch 3 in epoch 19, gen_loss = 0.40538593381643295, disc_loss = 0.016482659266330302
Trained batch 4 in epoch 19, gen_loss = 0.4113863050937653, disc_loss = 0.014622595068067313
Trained batch 5 in epoch 19, gen_loss = 0.3991573452949524, disc_loss = 0.017007449253772695
Trained batch 6 in epoch 19, gen_loss = 0.3977945489542825, disc_loss = 0.017683777093355144
Trained batch 7 in epoch 19, gen_loss = 0.40041910484433174, disc_loss = 0.02696135704172775
Trained batch 8 in epoch 19, gen_loss = 0.4031636383798387, disc_loss = 0.029424252764632303
Trained batch 9 in epoch 19, gen_loss = 0.397456967830658, disc_loss = 0.032823481550440195
Trained batch 10 in epoch 19, gen_loss = 0.4098223772915927, disc_loss = 0.05605361352420666
Trained batch 11 in epoch 19, gen_loss = 0.41200454036394757, disc_loss = 0.05478711996693164
Trained batch 12 in epoch 19, gen_loss = 0.40704498841212344, disc_loss = 0.05216951807960868
Trained batch 13 in epoch 19, gen_loss = 0.40252360488687244, disc_loss = 0.05003601043219013
Trained batch 14 in epoch 19, gen_loss = 0.40315778652826945, disc_loss = 0.04730799940104286
Trained batch 15 in epoch 19, gen_loss = 0.40519012697041035, disc_loss = 0.045831875380827114
Trained batch 16 in epoch 19, gen_loss = 0.405150806202608, disc_loss = 0.04418217026464203
Trained batch 17 in epoch 19, gen_loss = 0.4044458385970857, disc_loss = 0.04225580350288914
Trained batch 18 in epoch 19, gen_loss = 0.39632751910310043, disc_loss = 0.04174738551342958
Trained batch 19 in epoch 19, gen_loss = 0.40176069289445876, disc_loss = 0.041360175772570076
Trained batch 20 in epoch 19, gen_loss = 0.40110133517356145, disc_loss = 0.040274225774088075
Trained batch 21 in epoch 19, gen_loss = 0.40085890889167786, disc_loss = 0.03906956152059138
Trained batch 22 in epoch 19, gen_loss = 0.39999898361123126, disc_loss = 0.03800613840070108
Trained batch 23 in epoch 19, gen_loss = 0.40239990626772243, disc_loss = 0.03711936151375994
Trained batch 24 in epoch 19, gen_loss = 0.4028629243373871, disc_loss = 0.03607965903356671
Trained batch 25 in epoch 19, gen_loss = 0.4065792044767967, disc_loss = 0.035066382869934805
Trained batch 26 in epoch 19, gen_loss = 0.40487297817512796, disc_loss = 0.034506742376834154
Trained batch 27 in epoch 19, gen_loss = 0.4045647286943027, disc_loss = 0.03380211510895086
Trained batch 28 in epoch 19, gen_loss = 0.40256075715196543, disc_loss = 0.03307203558305728
Trained batch 29 in epoch 19, gen_loss = 0.40262377162774404, disc_loss = 0.03250672986420492
Trained batch 30 in epoch 19, gen_loss = 0.40366104629731947, disc_loss = 0.0317632648943653
Trained batch 31 in epoch 19, gen_loss = 0.4039686555042863, disc_loss = 0.03210324169776868
Trained batch 32 in epoch 19, gen_loss = 0.4042267609726299, disc_loss = 0.03371670214233525
Trained batch 33 in epoch 19, gen_loss = 0.4055688425022013, disc_loss = 0.03443970327155993
Trained batch 34 in epoch 19, gen_loss = 0.40798836435590474, disc_loss = 0.03361913362251861
Trained batch 35 in epoch 19, gen_loss = 0.41056520740191144, disc_loss = 0.033232724009495646
Trained batch 36 in epoch 19, gen_loss = 0.4107760376221425, disc_loss = 0.032541793078888916
Trained batch 37 in epoch 19, gen_loss = 0.4098156957249892, disc_loss = 0.032248397541575526
Trained batch 38 in epoch 19, gen_loss = 0.410484451514024, disc_loss = 0.03180937794968486
Trained batch 39 in epoch 19, gen_loss = 0.4107337422668934, disc_loss = 0.03161223597126082
Trained batch 40 in epoch 19, gen_loss = 0.4103082331215463, disc_loss = 0.03129471403478486
Trained batch 41 in epoch 19, gen_loss = 0.40929608543713886, disc_loss = 0.030760990067695577
Trained batch 42 in epoch 19, gen_loss = 0.40962215495664017, disc_loss = 0.030202441469787858
Trained batch 43 in epoch 19, gen_loss = 0.41007284820079803, disc_loss = 0.029880885320546276
Trained batch 44 in epoch 19, gen_loss = 0.4101837946308984, disc_loss = 0.02937910586802496
Trained batch 45 in epoch 19, gen_loss = 0.40953721948291943, disc_loss = 0.028888592790083392
Trained batch 46 in epoch 19, gen_loss = 0.40791568920967425, disc_loss = 0.0285450508322646
Trained batch 47 in epoch 19, gen_loss = 0.4074626447012027, disc_loss = 0.031086204544408247
Trained batch 48 in epoch 19, gen_loss = 0.4059857446320203, disc_loss = 0.03793074339818286
Trained batch 49 in epoch 19, gen_loss = 0.40594770669937136, disc_loss = 0.03801644270308316
Trained batch 50 in epoch 19, gen_loss = 0.4037345040078257, disc_loss = 0.03924923000272875
Trained batch 51 in epoch 19, gen_loss = 0.40380302931253725, disc_loss = 0.03968170261046348
Trained batch 52 in epoch 19, gen_loss = 0.40183782689976244, disc_loss = 0.04008975116325156
Trained batch 53 in epoch 19, gen_loss = 0.40262875567983697, disc_loss = 0.040092152483002456
Trained batch 54 in epoch 19, gen_loss = 0.4022077343680642, disc_loss = 0.04077545273202387
Trained batch 55 in epoch 19, gen_loss = 0.4029000752738544, disc_loss = 0.04065317372026454
Trained batch 56 in epoch 19, gen_loss = 0.4015862272496809, disc_loss = 0.0406446497838356
Trained batch 57 in epoch 19, gen_loss = 0.40305439202949916, disc_loss = 0.04009440760449346
Trained batch 58 in epoch 19, gen_loss = 0.40224904175532067, disc_loss = 0.04147601797703212
Trained batch 59 in epoch 19, gen_loss = 0.4032767300804456, disc_loss = 0.04373275402467698
Trained batch 60 in epoch 19, gen_loss = 0.40233819064546805, disc_loss = 0.04409409877004438
Trained batch 61 in epoch 19, gen_loss = 0.40278310689233965, disc_loss = 0.043652504990478194
Trained batch 62 in epoch 19, gen_loss = 0.4033266954005711, disc_loss = 0.044330148418093955
Trained batch 63 in epoch 19, gen_loss = 0.4011740814894438, disc_loss = 0.04852344835671829
Trained batch 64 in epoch 19, gen_loss = 0.40175781479248635, disc_loss = 0.04827848450065805
Trained batch 65 in epoch 19, gen_loss = 0.4030946551850348, disc_loss = 0.048502568557689134
Trained batch 66 in epoch 19, gen_loss = 0.40272787391249815, disc_loss = 0.04887148054705849
Trained batch 67 in epoch 19, gen_loss = 0.4034833921229138, disc_loss = 0.048470203881151974
Trained batch 68 in epoch 19, gen_loss = 0.4037258987841399, disc_loss = 0.04817075102144609
Trained batch 69 in epoch 19, gen_loss = 0.40447537558419366, disc_loss = 0.04772192373472665
Trained batch 70 in epoch 19, gen_loss = 0.4037553714194768, disc_loss = 0.04736305264965959
Trained batch 71 in epoch 19, gen_loss = 0.4030935416618983, disc_loss = 0.047418623289559036
Trained batch 72 in epoch 19, gen_loss = 0.40237320898330375, disc_loss = 0.04744004902799856
Trained batch 73 in epoch 19, gen_loss = 0.40276662803984975, disc_loss = 0.047089512390713836
Trained batch 74 in epoch 19, gen_loss = 0.40219043334325155, disc_loss = 0.04665765767917037
Trained batch 75 in epoch 19, gen_loss = 0.40220904232640015, disc_loss = 0.046728693494132084
Trained batch 76 in epoch 19, gen_loss = 0.40290473575715896, disc_loss = 0.04699450117451223
Trained batch 77 in epoch 19, gen_loss = 0.40288745898466843, disc_loss = 0.046475814565872915
Trained batch 78 in epoch 19, gen_loss = 0.40201697055297564, disc_loss = 0.046643829285579766
Trained batch 79 in epoch 19, gen_loss = 0.40300214029848574, disc_loss = 0.04763730005943216
Trained batch 80 in epoch 19, gen_loss = 0.4029910520271019, disc_loss = 0.047674912965086136
Trained batch 81 in epoch 19, gen_loss = 0.4037512162836587, disc_loss = 0.04725377048683784
Trained batch 82 in epoch 19, gen_loss = 0.4035457868173898, disc_loss = 0.04733135780678636
Trained batch 83 in epoch 19, gen_loss = 0.4035360731539272, disc_loss = 0.04684391819561521
Trained batch 84 in epoch 19, gen_loss = 0.4035358106388765, disc_loss = 0.04655947135213544
Trained batch 85 in epoch 19, gen_loss = 0.40372229315513786, disc_loss = 0.0462328244087308
Trained batch 86 in epoch 19, gen_loss = 0.4030620952447255, disc_loss = 0.04592340700756544
Trained batch 87 in epoch 19, gen_loss = 0.40312461114742537, disc_loss = 0.04576459268785336
Trained batch 88 in epoch 19, gen_loss = 0.40286142772503114, disc_loss = 0.04544926095712051
Trained batch 89 in epoch 19, gen_loss = 0.4026716560125351, disc_loss = 0.045405727210972045
Trained batch 90 in epoch 19, gen_loss = 0.40366743423126555, disc_loss = 0.045079453551507255
Trained batch 91 in epoch 19, gen_loss = 0.403851647739825, disc_loss = 0.04471292589669642
Trained batch 92 in epoch 19, gen_loss = 0.40341272501535314, disc_loss = 0.04444234167295758
Trained batch 93 in epoch 19, gen_loss = 0.40268513750522694, disc_loss = 0.04420157234640198
Trained batch 94 in epoch 19, gen_loss = 0.4026962763384769, disc_loss = 0.04387184169731642
Trained batch 95 in epoch 19, gen_loss = 0.4029787698139747, disc_loss = 0.04347361876474073
Trained batch 96 in epoch 19, gen_loss = 0.4039669657490917, disc_loss = 0.043156856824595906
Trained batch 97 in epoch 19, gen_loss = 0.40407513355722235, disc_loss = 0.0429632176968212
Trained batch 98 in epoch 19, gen_loss = 0.4030465396365734, disc_loss = 0.04312718902347666
Trained batch 99 in epoch 19, gen_loss = 0.404044351875782, disc_loss = 0.04364521684125066
Trained batch 100 in epoch 19, gen_loss = 0.4043072621421059, disc_loss = 0.04344076157944037
Trained batch 101 in epoch 19, gen_loss = 0.4037042897121579, disc_loss = 0.04313647214725029
Trained batch 102 in epoch 19, gen_loss = 0.4035144708688977, disc_loss = 0.04289465718586179
Trained batch 103 in epoch 19, gen_loss = 0.40320920600340915, disc_loss = 0.042693925475200206
Trained batch 104 in epoch 19, gen_loss = 0.4034658866269248, disc_loss = 0.04241115263707581
Trained batch 105 in epoch 19, gen_loss = 0.40334000846125045, disc_loss = 0.042497736322781386
Trained batch 106 in epoch 19, gen_loss = 0.4036780907728962, disc_loss = 0.04412865604787508
Trained batch 107 in epoch 19, gen_loss = 0.40373135220121453, disc_loss = 0.043933741791449765
Trained batch 108 in epoch 19, gen_loss = 0.40370335983573846, disc_loss = 0.04412149717399013
Trained batch 109 in epoch 19, gen_loss = 0.4046103515408256, disc_loss = 0.044274291777136654
Trained batch 110 in epoch 19, gen_loss = 0.404397066649016, disc_loss = 0.0439656447568858
Trained batch 111 in epoch 19, gen_loss = 0.40430037065276075, disc_loss = 0.04407531863710444
Trained batch 112 in epoch 19, gen_loss = 0.40457895398139954, disc_loss = 0.0439869114898343
Trained batch 113 in epoch 19, gen_loss = 0.4040361765706748, disc_loss = 0.043964881474446306
Trained batch 114 in epoch 19, gen_loss = 0.40428782131360924, disc_loss = 0.043951147041566996
Trained batch 115 in epoch 19, gen_loss = 0.4043560703766757, disc_loss = 0.043778591749161995
Trained batch 116 in epoch 19, gen_loss = 0.40444129832789427, disc_loss = 0.0435484294883079
Trained batch 117 in epoch 19, gen_loss = 0.4049091571468418, disc_loss = 0.04377460718881023
Trained batch 118 in epoch 19, gen_loss = 0.4058751488934044, disc_loss = 0.044814291363190706
Trained batch 119 in epoch 19, gen_loss = 0.4051249772310257, disc_loss = 0.046968839061446485
Trained batch 120 in epoch 19, gen_loss = 0.4054990147263551, disc_loss = 0.046778612739352646
Trained batch 121 in epoch 19, gen_loss = 0.40546234098614237, disc_loss = 0.04896867505015164
Trained batch 122 in epoch 19, gen_loss = 0.4049129236519821, disc_loss = 0.04984591087341551
Trained batch 123 in epoch 19, gen_loss = 0.4046598994924176, disc_loss = 0.04959961970997674
Trained batch 124 in epoch 19, gen_loss = 0.40506643390655517, disc_loss = 0.04946948421746492
Trained batch 125 in epoch 19, gen_loss = 0.4039326901473696, disc_loss = 0.04976937908767944
Trained batch 126 in epoch 19, gen_loss = 0.40374919490551386, disc_loss = 0.04993804896939692
Trained batch 127 in epoch 19, gen_loss = 0.4046881904359907, disc_loss = 0.05048703699867474
Trained batch 128 in epoch 19, gen_loss = 0.40540666797364405, disc_loss = 0.05026057862871608
Trained batch 129 in epoch 19, gen_loss = 0.40555378863444697, disc_loss = 0.05010445958289963
Trained batch 130 in epoch 19, gen_loss = 0.4053116561347292, disc_loss = 0.0498139948747654
Trained batch 131 in epoch 19, gen_loss = 0.40521636740727857, disc_loss = 0.04971806573060652
Trained batch 132 in epoch 19, gen_loss = 0.4056823036276308, disc_loss = 0.05179800668073104
Trained batch 133 in epoch 19, gen_loss = 0.40517665712691064, disc_loss = 0.053285708435491394
Trained batch 134 in epoch 19, gen_loss = 0.4055344182032126, disc_loss = 0.05330716921361508
Trained batch 135 in epoch 19, gen_loss = 0.40596584909979033, disc_loss = 0.053084932945613915
Trained batch 136 in epoch 19, gen_loss = 0.40604794047174664, disc_loss = 0.052787314889694216
Trained batch 137 in epoch 19, gen_loss = 0.40618640875470813, disc_loss = 0.052608322966303946
Trained batch 138 in epoch 19, gen_loss = 0.40587826362616725, disc_loss = 0.05232980928430669
Trained batch 139 in epoch 19, gen_loss = 0.4054218394415719, disc_loss = 0.052085786505735344
Trained batch 140 in epoch 19, gen_loss = 0.40541725230555165, disc_loss = 0.05180467075357834
Trained batch 141 in epoch 19, gen_loss = 0.4056155478030863, disc_loss = 0.051625995772143066
Trained batch 142 in epoch 19, gen_loss = 0.4057826768685054, disc_loss = 0.05144126613630907
Trained batch 143 in epoch 19, gen_loss = 0.4059684125499593, disc_loss = 0.051551792091534786
Trained batch 144 in epoch 19, gen_loss = 0.40552286855105696, disc_loss = 0.05247545472892194
Trained batch 145 in epoch 19, gen_loss = 0.4059178749584172, disc_loss = 0.052696133561891643
Trained batch 146 in epoch 19, gen_loss = 0.4056984763972613, disc_loss = 0.05240052227615094
Trained batch 147 in epoch 19, gen_loss = 0.4057798613164876, disc_loss = 0.05212808197766945
Trained batch 148 in epoch 19, gen_loss = 0.4060291655911695, disc_loss = 0.051872691083324436
Trained batch 149 in epoch 19, gen_loss = 0.40642778793970746, disc_loss = 0.051575770014896986
Trained batch 150 in epoch 19, gen_loss = 0.4063718463016662, disc_loss = 0.05126785105464376
Trained batch 151 in epoch 19, gen_loss = 0.4063151192508246, disc_loss = 0.05096782973391543
Trained batch 152 in epoch 19, gen_loss = 0.4069959100554971, disc_loss = 0.0506771924187204
Trained batch 153 in epoch 19, gen_loss = 0.40672927785229374, disc_loss = 0.050375409862752275
Trained batch 154 in epoch 19, gen_loss = 0.406487298780872, disc_loss = 0.05010291084707264
Trained batch 155 in epoch 19, gen_loss = 0.40612862335565764, disc_loss = 0.04981606557833938
Trained batch 156 in epoch 19, gen_loss = 0.40641195379245054, disc_loss = 0.04953836351573752
Trained batch 157 in epoch 19, gen_loss = 0.40607072299794306, disc_loss = 0.049259293509081384
Trained batch 158 in epoch 19, gen_loss = 0.4059449683570262, disc_loss = 0.04899685236232929
Trained batch 159 in epoch 19, gen_loss = 0.4053768638521433, disc_loss = 0.04873473199841101
Trained batch 160 in epoch 19, gen_loss = 0.4057330568754895, disc_loss = 0.0484684102052117
Trained batch 161 in epoch 19, gen_loss = 0.40583225072901924, disc_loss = 0.04821361012377397
Trained batch 162 in epoch 19, gen_loss = 0.40571162671399263, disc_loss = 0.04795974038507035
Trained batch 163 in epoch 19, gen_loss = 0.4054984530297721, disc_loss = 0.047698710837810326
Trained batch 164 in epoch 19, gen_loss = 0.40447886622313295, disc_loss = 0.04773948212633982
Trained batch 165 in epoch 19, gen_loss = 0.40511051340993626, disc_loss = 0.04830316904965923
Trained batch 166 in epoch 19, gen_loss = 0.4048147108740435, disc_loss = 0.04839516847957662
Trained batch 167 in epoch 19, gen_loss = 0.4045836684249696, disc_loss = 0.04837917979706877
Trained batch 168 in epoch 19, gen_loss = 0.4042933043643568, disc_loss = 0.04821562620166402
Trained batch 169 in epoch 19, gen_loss = 0.4043006828602623, disc_loss = 0.048289229794788883
Trained batch 170 in epoch 19, gen_loss = 0.4043084534636715, disc_loss = 0.04819886452567421
Trained batch 171 in epoch 19, gen_loss = 0.4042971674786058, disc_loss = 0.048180686058151685
Trained batch 172 in epoch 19, gen_loss = 0.4038503547279821, disc_loss = 0.04904895827895558
Trained batch 173 in epoch 19, gen_loss = 0.40391288697719574, disc_loss = 0.05010581869450023
Trained batch 174 in epoch 19, gen_loss = 0.403546381848199, disc_loss = 0.05002784544602037
Trained batch 175 in epoch 19, gen_loss = 0.40360004556449974, disc_loss = 0.0506932049095419
Trained batch 176 in epoch 19, gen_loss = 0.40375273830473085, disc_loss = 0.051429364248836616
Trained batch 177 in epoch 19, gen_loss = 0.40336640430300424, disc_loss = 0.05246882218857076
Trained batch 178 in epoch 19, gen_loss = 0.40382609836882055, disc_loss = 0.05293336413623817
Trained batch 179 in epoch 19, gen_loss = 0.4039149209856987, disc_loss = 0.053384913201443854
Trained batch 180 in epoch 19, gen_loss = 0.40350835955604003, disc_loss = 0.053992928666942525
Trained batch 181 in epoch 19, gen_loss = 0.4035426723760563, disc_loss = 0.05428905722398598
Trained batch 182 in epoch 19, gen_loss = 0.4036248038049604, disc_loss = 0.054243865791871085
Trained batch 183 in epoch 19, gen_loss = 0.40316382585012395, disc_loss = 0.05428060738157238
Trained batch 184 in epoch 19, gen_loss = 0.4032292324143487, disc_loss = 0.05425399262709795
Trained batch 185 in epoch 19, gen_loss = 0.40333889873437984, disc_loss = 0.054276279932368665
Trained batch 186 in epoch 19, gen_loss = 0.40353063147335766, disc_loss = 0.05418551978929078
Trained batch 187 in epoch 19, gen_loss = 0.4030493090444423, disc_loss = 0.054647870270158855
Trained batch 188 in epoch 19, gen_loss = 0.40367430212005734, disc_loss = 0.05663621400744117
Trained batch 189 in epoch 19, gen_loss = 0.4037129395886471, disc_loss = 0.056474788621754236
Trained batch 190 in epoch 19, gen_loss = 0.40391403311834284, disc_loss = 0.056307278161488124
Trained batch 191 in epoch 19, gen_loss = 0.4038068735972047, disc_loss = 0.056184161083365325
Trained batch 192 in epoch 19, gen_loss = 0.4034087923524293, disc_loss = 0.05600277808075047
Trained batch 193 in epoch 19, gen_loss = 0.40367742021059255, disc_loss = 0.05582366320880648
Trained batch 194 in epoch 19, gen_loss = 0.4038428525129954, disc_loss = 0.05559872606864724
Trained batch 195 in epoch 19, gen_loss = 0.40390859529071926, disc_loss = 0.05543971856419301
Trained batch 196 in epoch 19, gen_loss = 0.404004519966048, disc_loss = 0.05526129767383794
Trained batch 197 in epoch 19, gen_loss = 0.4037996757813174, disc_loss = 0.055235200498083774
Trained batch 198 in epoch 19, gen_loss = 0.4034253493625315, disc_loss = 0.055178766801073476
Trained batch 199 in epoch 19, gen_loss = 0.404196951687336, disc_loss = 0.055076527188066396
Trained batch 200 in epoch 19, gen_loss = 0.4041961369229786, disc_loss = 0.05503237051240618
Trained batch 201 in epoch 19, gen_loss = 0.4036742357334288, disc_loss = 0.05516863024406283
Trained batch 202 in epoch 19, gen_loss = 0.40385079736192825, disc_loss = 0.05493650455348965
Trained batch 203 in epoch 19, gen_loss = 0.40395860344755885, disc_loss = 0.055163568563704544
Trained batch 204 in epoch 19, gen_loss = 0.40395914941299255, disc_loss = 0.05521677661823427
Trained batch 205 in epoch 19, gen_loss = 0.403849518125497, disc_loss = 0.05499916908204628
Trained batch 206 in epoch 19, gen_loss = 0.40397096601661275, disc_loss = 0.054774645281784634
Trained batch 207 in epoch 19, gen_loss = 0.4042027900711848, disc_loss = 0.05471787433131025
Trained batch 208 in epoch 19, gen_loss = 0.40354133864338887, disc_loss = 0.05458011154450797
Trained batch 209 in epoch 19, gen_loss = 0.4033042753026599, disc_loss = 0.05438782463426746
Trained batch 210 in epoch 19, gen_loss = 0.4034427863444197, disc_loss = 0.05419640316102672
Trained batch 211 in epoch 19, gen_loss = 0.403589129166783, disc_loss = 0.05406482911993802
Trained batch 212 in epoch 19, gen_loss = 0.4037102281767438, disc_loss = 0.0538719501499384
Trained batch 213 in epoch 19, gen_loss = 0.40380214140793985, disc_loss = 0.05394824090082999
Trained batch 214 in epoch 19, gen_loss = 0.4042128795801207, disc_loss = 0.054124089388913194
Trained batch 215 in epoch 19, gen_loss = 0.4047192128168212, disc_loss = 0.05390969617939037
Trained batch 216 in epoch 19, gen_loss = 0.4049122952920501, disc_loss = 0.05379641039537326
Trained batch 217 in epoch 19, gen_loss = 0.40480926810601436, disc_loss = 0.05358428570416269
Trained batch 218 in epoch 19, gen_loss = 0.40518801928110865, disc_loss = 0.05342722857651645
Trained batch 219 in epoch 19, gen_loss = 0.405091605945067, disc_loss = 0.053259690893305976
Trained batch 220 in epoch 19, gen_loss = 0.4053558072083676, disc_loss = 0.05309731521690054
Trained batch 221 in epoch 19, gen_loss = 0.40514620802960954, disc_loss = 0.05304149786631266
Trained batch 222 in epoch 19, gen_loss = 0.40524842666938166, disc_loss = 0.053032540937576596
Trained batch 223 in epoch 19, gen_loss = 0.40523430425673723, disc_loss = 0.05309887897289757
Trained batch 224 in epoch 19, gen_loss = 0.40486431585417854, disc_loss = 0.05352310957180129
Trained batch 225 in epoch 19, gen_loss = 0.404895853284186, disc_loss = 0.05350224141328208
Trained batch 226 in epoch 19, gen_loss = 0.4049838156427056, disc_loss = 0.053383212183737545
Trained batch 227 in epoch 19, gen_loss = 0.40532090044335317, disc_loss = 0.05319540932153662
Trained batch 228 in epoch 19, gen_loss = 0.4052597129449053, disc_loss = 0.05308614778596762
Trained batch 229 in epoch 19, gen_loss = 0.4051113689723222, disc_loss = 0.05298786041043375
Trained batch 230 in epoch 19, gen_loss = 0.4051145124229002, disc_loss = 0.05287170498853638
Trained batch 231 in epoch 19, gen_loss = 0.40508272113471194, disc_loss = 0.05268415622814591
Trained batch 232 in epoch 19, gen_loss = 0.40526372488476176, disc_loss = 0.052492709498644645
Trained batch 233 in epoch 19, gen_loss = 0.4049662734962936, disc_loss = 0.05228949043676894
Trained batch 234 in epoch 19, gen_loss = 0.40481707961001295, disc_loss = 0.05212378042175415
Trained batch 235 in epoch 19, gen_loss = 0.4045394378698478, disc_loss = 0.051976703951861394
Trained batch 236 in epoch 19, gen_loss = 0.4043211750843354, disc_loss = 0.05191021260927246
Trained batch 237 in epoch 19, gen_loss = 0.40457667798555197, disc_loss = 0.05199787539563009
Trained batch 238 in epoch 19, gen_loss = 0.4045947788898915, disc_loss = 0.051799746257521866
Trained batch 239 in epoch 19, gen_loss = 0.40446506688992184, disc_loss = 0.05163854075362906
Trained batch 240 in epoch 19, gen_loss = 0.40457246103227384, disc_loss = 0.0514575035786604
Trained batch 241 in epoch 19, gen_loss = 0.4043423865944886, disc_loss = 0.051364316174006164
Trained batch 242 in epoch 19, gen_loss = 0.4045150015089247, disc_loss = 0.051223340095499906
Trained batch 243 in epoch 19, gen_loss = 0.40459514128380136, disc_loss = 0.05106303904236096
Trained batch 244 in epoch 19, gen_loss = 0.404545559445206, disc_loss = 0.05095296886046322
Trained batch 245 in epoch 19, gen_loss = 0.4044040552968901, disc_loss = 0.05092851595756242
Trained batch 246 in epoch 19, gen_loss = 0.40444469801810107, disc_loss = 0.05074741293182257
Trained batch 247 in epoch 19, gen_loss = 0.40445985188407285, disc_loss = 0.050583248830310276
Trained batch 248 in epoch 19, gen_loss = 0.404792641540129, disc_loss = 0.05041105189102601
Trained batch 249 in epoch 19, gen_loss = 0.4046659746170044, disc_loss = 0.050261588864028456
Trained batch 250 in epoch 19, gen_loss = 0.4050499174699365, disc_loss = 0.05011097096886293
Trained batch 251 in epoch 19, gen_loss = 0.4053359507095246, disc_loss = 0.04993819627755632
Trained batch 252 in epoch 19, gen_loss = 0.40510564100129803, disc_loss = 0.04977450308688132
Trained batch 253 in epoch 19, gen_loss = 0.4052619638405447, disc_loss = 0.049599765046448335
Trained batch 254 in epoch 19, gen_loss = 0.4053501307964325, disc_loss = 0.04943105303408468
Trained batch 255 in epoch 19, gen_loss = 0.4052240246674046, disc_loss = 0.04928954169008648
Trained batch 256 in epoch 19, gen_loss = 0.4049430615939055, disc_loss = 0.04914968320918686
Trained batch 257 in epoch 19, gen_loss = 0.40474020510680914, disc_loss = 0.04900102419128945
Trained batch 258 in epoch 19, gen_loss = 0.4050985632255731, disc_loss = 0.048973366121930505
Trained batch 259 in epoch 19, gen_loss = 0.4047612890601158, disc_loss = 0.04904950300518137
Trained batch 260 in epoch 19, gen_loss = 0.40504587964079847, disc_loss = 0.04898122264878731
Trained batch 261 in epoch 19, gen_loss = 0.40485369055780746, disc_loss = 0.04885743145354604
Trained batch 262 in epoch 19, gen_loss = 0.4044992121453521, disc_loss = 0.04872207974965468
Trained batch 263 in epoch 19, gen_loss = 0.4042050172433709, disc_loss = 0.04889776943971149
Trained batch 264 in epoch 19, gen_loss = 0.40462647698960214, disc_loss = 0.049443020035495173
Trained batch 265 in epoch 19, gen_loss = 0.4047039478345025, disc_loss = 0.049300786958573234
Trained batch 266 in epoch 19, gen_loss = 0.40480904688549396, disc_loss = 0.04933050669352995
Trained batch 267 in epoch 19, gen_loss = 0.40490688361338717, disc_loss = 0.04918347121869673
Trained batch 268 in epoch 19, gen_loss = 0.4047560640870417, disc_loss = 0.04914985982818896
Trained batch 269 in epoch 19, gen_loss = 0.4045593086216185, disc_loss = 0.04928613234035395
Trained batch 270 in epoch 19, gen_loss = 0.40473737718874236, disc_loss = 0.049300456983191944
Trained batch 271 in epoch 19, gen_loss = 0.4045932300607948, disc_loss = 0.049152279488386255
Trained batch 272 in epoch 19, gen_loss = 0.4042846822476649, disc_loss = 0.04904953029770882
Trained batch 273 in epoch 19, gen_loss = 0.4042781918805881, disc_loss = 0.04895517358855501
Trained batch 274 in epoch 19, gen_loss = 0.4041177207773382, disc_loss = 0.04886993082748218
Trained batch 275 in epoch 19, gen_loss = 0.4044150264150854, disc_loss = 0.04885082304194246
Trained batch 276 in epoch 19, gen_loss = 0.40414525778285004, disc_loss = 0.04887212675387571
Trained batch 277 in epoch 19, gen_loss = 0.4043959151926658, disc_loss = 0.04885061998791296
Trained batch 278 in epoch 19, gen_loss = 0.404693318524241, disc_loss = 0.04883368668149769
Trained batch 279 in epoch 19, gen_loss = 0.4047624910516398, disc_loss = 0.048682008287869394
Trained batch 280 in epoch 19, gen_loss = 0.40461269360420116, disc_loss = 0.04865051029428999
Trained batch 281 in epoch 19, gen_loss = 0.40451285084511374, disc_loss = 0.048601153475093715
Trained batch 282 in epoch 19, gen_loss = 0.40416217861242937, disc_loss = 0.04887805526661473
Trained batch 283 in epoch 19, gen_loss = 0.4045846877803265, disc_loss = 0.04929913622720666
Trained batch 284 in epoch 19, gen_loss = 0.4046126540292773, disc_loss = 0.049156424399922814
Trained batch 285 in epoch 19, gen_loss = 0.40465047288607886, disc_loss = 0.049030345424983676
Trained batch 286 in epoch 19, gen_loss = 0.4045930709365353, disc_loss = 0.04892290100286543
Trained batch 287 in epoch 19, gen_loss = 0.40461743488493895, disc_loss = 0.048793048203353666
Trained batch 288 in epoch 19, gen_loss = 0.4045411550462452, disc_loss = 0.04867483400272457
Trained batch 289 in epoch 19, gen_loss = 0.4046107286009295, disc_loss = 0.04853985123657461
Trained batch 290 in epoch 19, gen_loss = 0.40476680846558405, disc_loss = 0.048403671206554394
Trained batch 291 in epoch 19, gen_loss = 0.40459541680469907, disc_loss = 0.04826982923119954
Trained batch 292 in epoch 19, gen_loss = 0.40461041618125837, disc_loss = 0.04816765357571759
Trained batch 293 in epoch 19, gen_loss = 0.4046672128495716, disc_loss = 0.04803673360103957
Trained batch 294 in epoch 19, gen_loss = 0.4047650161436049, disc_loss = 0.04810821128283012
Trained batch 295 in epoch 19, gen_loss = 0.4048916194084528, disc_loss = 0.04876798891928047
Trained batch 296 in epoch 19, gen_loss = 0.40476180176542265, disc_loss = 0.04888677047346076
Trained batch 297 in epoch 19, gen_loss = 0.40461042493381755, disc_loss = 0.04876210087060228
Trained batch 298 in epoch 19, gen_loss = 0.40451866926556845, disc_loss = 0.04866027646701172
Trained batch 299 in epoch 19, gen_loss = 0.4044540312886238, disc_loss = 0.048528750352561476
Trained batch 300 in epoch 19, gen_loss = 0.4046612675007792, disc_loss = 0.04839247053000222
Trained batch 301 in epoch 19, gen_loss = 0.40480394118669016, disc_loss = 0.04828691684227708
Trained batch 302 in epoch 19, gen_loss = 0.4047009431489623, disc_loss = 0.04820555956917431
Trained batch 303 in epoch 19, gen_loss = 0.40460130601729216, disc_loss = 0.04832083853819456
Trained batch 304 in epoch 19, gen_loss = 0.40437989840742017, disc_loss = 0.04838003400774276
Trained batch 305 in epoch 19, gen_loss = 0.4045807257586834, disc_loss = 0.04828154804562432
Trained batch 306 in epoch 19, gen_loss = 0.4044542904785479, disc_loss = 0.048260523024521745
Trained batch 307 in epoch 19, gen_loss = 0.40451792617896937, disc_loss = 0.04815123354496023
Trained batch 308 in epoch 19, gen_loss = 0.40450314478195215, disc_loss = 0.04807482221281355
Trained batch 309 in epoch 19, gen_loss = 0.4046103003524965, disc_loss = 0.04796119480123443
Trained batch 310 in epoch 19, gen_loss = 0.40471139396885203, disc_loss = 0.0478571574667834
Trained batch 311 in epoch 19, gen_loss = 0.4046473164015856, disc_loss = 0.0477773048556768
Trained batch 312 in epoch 19, gen_loss = 0.40477701716910536, disc_loss = 0.04777476191520691
Trained batch 313 in epoch 19, gen_loss = 0.40453640281394787, disc_loss = 0.048489277245132786
Trained batch 314 in epoch 19, gen_loss = 0.40450576685723805, disc_loss = 0.04851863792254811
Trained batch 315 in epoch 19, gen_loss = 0.40438204966013946, disc_loss = 0.04887095429710572
Trained batch 316 in epoch 19, gen_loss = 0.40424319227411165, disc_loss = 0.04898538298270304
Trained batch 317 in epoch 19, gen_loss = 0.40427928244542777, disc_loss = 0.04896768904144659
Trained batch 318 in epoch 19, gen_loss = 0.40438327090493564, disc_loss = 0.04900724834362541
Trained batch 319 in epoch 19, gen_loss = 0.4045173656195402, disc_loss = 0.04888652785739396
Trained batch 320 in epoch 19, gen_loss = 0.4041456053747195, disc_loss = 0.04893360715475502
Trained batch 321 in epoch 19, gen_loss = 0.40415511460778136, disc_loss = 0.04927427561444618
Trained batch 322 in epoch 19, gen_loss = 0.40438767298825384, disc_loss = 0.04917696584016085
Trained batch 323 in epoch 19, gen_loss = 0.4042555650259242, disc_loss = 0.04912807227595261
Trained batch 324 in epoch 19, gen_loss = 0.4042531514167786, disc_loss = 0.04909419081245477
Trained batch 325 in epoch 19, gen_loss = 0.40422671137411903, disc_loss = 0.04898647987712289
Trained batch 326 in epoch 19, gen_loss = 0.4043468965120636, disc_loss = 0.0489895886824173
Trained batch 327 in epoch 19, gen_loss = 0.40445489009342545, disc_loss = 0.04891649632226312
Trained batch 328 in epoch 19, gen_loss = 0.4042471479681125, disc_loss = 0.048913803684743164
Trained batch 329 in epoch 19, gen_loss = 0.4040858374400572, disc_loss = 0.04939131930639798
Trained batch 330 in epoch 19, gen_loss = 0.40431994289790035, disc_loss = 0.049551739295511266
Trained batch 331 in epoch 19, gen_loss = 0.40441059384001304, disc_loss = 0.0496006064223552
Trained batch 332 in epoch 19, gen_loss = 0.4045319878482246, disc_loss = 0.04948407980716891
Trained batch 333 in epoch 19, gen_loss = 0.40436502496996324, disc_loss = 0.049431247700808825
Trained batch 334 in epoch 19, gen_loss = 0.4042063286945001, disc_loss = 0.049309731455547595
Trained batch 335 in epoch 19, gen_loss = 0.4044437472309385, disc_loss = 0.04917866234817276
Trained batch 336 in epoch 19, gen_loss = 0.40446854468976706, disc_loss = 0.0490833384963167
Trained batch 337 in epoch 19, gen_loss = 0.40408300471729075, disc_loss = 0.048996958880238896
Trained batch 338 in epoch 19, gen_loss = 0.40414944001003705, disc_loss = 0.048881132467471305
Trained batch 339 in epoch 19, gen_loss = 0.40405339248040145, disc_loss = 0.048842347932376844
Trained batch 340 in epoch 19, gen_loss = 0.4038831422056271, disc_loss = 0.04905611260649352
Trained batch 341 in epoch 19, gen_loss = 0.403870025224853, disc_loss = 0.049035431755902734
Trained batch 342 in epoch 19, gen_loss = 0.40392504428287984, disc_loss = 0.04912493312079731
Trained batch 343 in epoch 19, gen_loss = 0.4041459831560767, disc_loss = 0.050105513369956944
Trained batch 344 in epoch 19, gen_loss = 0.4040280507094618, disc_loss = 0.050025456964267766
Trained batch 345 in epoch 19, gen_loss = 0.4037367848819391, disc_loss = 0.050011440695699495
Trained batch 346 in epoch 19, gen_loss = 0.403642729740665, disc_loss = 0.04993460888193346
Trained batch 347 in epoch 19, gen_loss = 0.40358260787766553, disc_loss = 0.049855667828774916
Trained batch 348 in epoch 19, gen_loss = 0.40381140524473436, disc_loss = 0.04978870781789665
Trained batch 349 in epoch 19, gen_loss = 0.4037892233473914, disc_loss = 0.04971065386464553
Trained batch 350 in epoch 19, gen_loss = 0.40370218816645803, disc_loss = 0.04962526480309092
Trained batch 351 in epoch 19, gen_loss = 0.40367966636338015, disc_loss = 0.049666898281429894
Trained batch 352 in epoch 19, gen_loss = 0.4031758661732795, disc_loss = 0.05006612073128816
Trained batch 353 in epoch 19, gen_loss = 0.40348146666409607, disc_loss = 0.05070281079128427
Trained batch 354 in epoch 19, gen_loss = 0.40366672785349295, disc_loss = 0.05062012719515134
Trained batch 355 in epoch 19, gen_loss = 0.40356771735830255, disc_loss = 0.050670952555786276
Trained batch 356 in epoch 19, gen_loss = 0.40348614384981096, disc_loss = 0.05068272025473103
Trained batch 357 in epoch 19, gen_loss = 0.4035660869665652, disc_loss = 0.05067068333061173
Trained batch 358 in epoch 19, gen_loss = 0.4035264624277529, disc_loss = 0.050568975530263856
Trained batch 359 in epoch 19, gen_loss = 0.4033580528779162, disc_loss = 0.05046816888498142
Trained batch 360 in epoch 19, gen_loss = 0.4033798389239985, disc_loss = 0.050410970912632275
Trained batch 361 in epoch 19, gen_loss = 0.4033681744123032, disc_loss = 0.05035320354126476
Trained batch 362 in epoch 19, gen_loss = 0.40317202964925897, disc_loss = 0.050283434019570264
Trained batch 363 in epoch 19, gen_loss = 0.4032119431092844, disc_loss = 0.05054375484386193
Trained batch 364 in epoch 19, gen_loss = 0.40357498244879997, disc_loss = 0.051208991915855095
Trained batch 365 in epoch 19, gen_loss = 0.40366875486132875, disc_loss = 0.05120877490144813
Trained batch 366 in epoch 19, gen_loss = 0.40349801574968186, disc_loss = 0.05119947430472161
Trained batch 367 in epoch 19, gen_loss = 0.40339036864916916, disc_loss = 0.05122919031545398
Trained batch 368 in epoch 19, gen_loss = 0.40329217761351166, disc_loss = 0.051127989442014514
Trained batch 369 in epoch 19, gen_loss = 0.4032351544982678, disc_loss = 0.05104403602135544
Trained batch 370 in epoch 19, gen_loss = 0.40316606302948976, disc_loss = 0.0509307943949742
Trained batch 371 in epoch 19, gen_loss = 0.4033513755327271, disc_loss = 0.050844244134452155
Trained batch 372 in epoch 19, gen_loss = 0.40316506553111703, disc_loss = 0.05075807078559221
Trained batch 373 in epoch 19, gen_loss = 0.4031973872034945, disc_loss = 0.050656061859821334
Trained batch 374 in epoch 19, gen_loss = 0.40299882026513417, disc_loss = 0.050682800512760875
Trained batch 375 in epoch 19, gen_loss = 0.4028896051756245, disc_loss = 0.05081680347830889
Trained batch 376 in epoch 19, gen_loss = 0.4030610888563986, disc_loss = 0.05122927232554049
Trained batch 377 in epoch 19, gen_loss = 0.40294433795112783, disc_loss = 0.051129832012559134
Trained batch 378 in epoch 19, gen_loss = 0.4028489502014145, disc_loss = 0.05107619617955076
Trained batch 379 in epoch 19, gen_loss = 0.40271320966513535, disc_loss = 0.05100554335298703
Trained batch 380 in epoch 19, gen_loss = 0.4026373270850169, disc_loss = 0.05093204532811061
Trained batch 381 in epoch 19, gen_loss = 0.4027049182987338, disc_loss = 0.05084202396293312
Trained batch 382 in epoch 19, gen_loss = 0.40263665885744765, disc_loss = 0.050745590202092114
Trained batch 383 in epoch 19, gen_loss = 0.4024796239488448, disc_loss = 0.05063961448104237
Trained batch 384 in epoch 19, gen_loss = 0.40247816091234034, disc_loss = 0.05054722567778323
Trained batch 385 in epoch 19, gen_loss = 0.40251197434305525, disc_loss = 0.05048904347069407
Trained batch 386 in epoch 19, gen_loss = 0.40254642477485253, disc_loss = 0.05037773662494635
Trained batch 387 in epoch 19, gen_loss = 0.4026601437824903, disc_loss = 0.05029865735589728
Trained batch 388 in epoch 19, gen_loss = 0.4027852986419722, disc_loss = 0.050294363312183815
Trained batch 389 in epoch 19, gen_loss = 0.4029388325718733, disc_loss = 0.05046668455888254
Trained batch 390 in epoch 19, gen_loss = 0.4028964184053109, disc_loss = 0.05039505897890157
Trained batch 391 in epoch 19, gen_loss = 0.40302404369778777, disc_loss = 0.050428011560365936
Trained batch 392 in epoch 19, gen_loss = 0.4031813542427301, disc_loss = 0.05055406245192082
Trained batch 393 in epoch 19, gen_loss = 0.4029924347996712, disc_loss = 0.05045766541899801
Trained batch 394 in epoch 19, gen_loss = 0.40275732637206213, disc_loss = 0.05040153177879468
Trained batch 395 in epoch 19, gen_loss = 0.4027394822074307, disc_loss = 0.05032811547286169
Trained batch 396 in epoch 19, gen_loss = 0.40288731339446243, disc_loss = 0.05022838525122186
Trained batch 397 in epoch 19, gen_loss = 0.40284671731779925, disc_loss = 0.05016622011989692
Trained batch 398 in epoch 19, gen_loss = 0.40296712274987595, disc_loss = 0.050161650074053
Trained batch 399 in epoch 19, gen_loss = 0.4030594975873828, disc_loss = 0.050121104448335244
Trained batch 400 in epoch 19, gen_loss = 0.40307862008747614, disc_loss = 0.05006946534257466
Trained batch 401 in epoch 19, gen_loss = 0.4032932519542044, disc_loss = 0.05008645302069313
Trained batch 402 in epoch 19, gen_loss = 0.40329997123175165, disc_loss = 0.050087749644901335
Trained batch 403 in epoch 19, gen_loss = 0.4034971820909788, disc_loss = 0.05003619107468478
Trained batch 404 in epoch 19, gen_loss = 0.4034928054353337, disc_loss = 0.049944774269551774
Trained batch 405 in epoch 19, gen_loss = 0.4035225279739338, disc_loss = 0.049859039110402244
Trained batch 406 in epoch 19, gen_loss = 0.40375348643676656, disc_loss = 0.04975929883416257
Trained batch 407 in epoch 19, gen_loss = 0.4037762386176516, disc_loss = 0.04966756426980354
Trained batch 408 in epoch 19, gen_loss = 0.4037265295577224, disc_loss = 0.049598217528531996
Trained batch 409 in epoch 19, gen_loss = 0.40385473999308374, disc_loss = 0.04979970583169744
Trained batch 410 in epoch 19, gen_loss = 0.4035443732120695, disc_loss = 0.05029150304200984
Trained batch 411 in epoch 19, gen_loss = 0.4034451244453203, disc_loss = 0.050273897948005755
Trained batch 412 in epoch 19, gen_loss = 0.40364642268087325, disc_loss = 0.05019876642206787
Trained batch 413 in epoch 19, gen_loss = 0.4037706790410954, disc_loss = 0.05010268420930322
Trained batch 414 in epoch 19, gen_loss = 0.4038710700101163, disc_loss = 0.04999945975099522
Trained batch 415 in epoch 19, gen_loss = 0.40387776218211424, disc_loss = 0.04990201518544032
Trained batch 416 in epoch 19, gen_loss = 0.40394079360029966, disc_loss = 0.049812436180872666
Trained batch 417 in epoch 19, gen_loss = 0.40394504821043836, disc_loss = 0.049726007003827316
Trained batch 418 in epoch 19, gen_loss = 0.40392482298513016, disc_loss = 0.04962114942635727
Trained batch 419 in epoch 19, gen_loss = 0.40388236624144375, disc_loss = 0.049530149319963086
Trained batch 420 in epoch 19, gen_loss = 0.4037321699415986, disc_loss = 0.04942694965488943
Trained batch 421 in epoch 19, gen_loss = 0.4036210375303906, disc_loss = 0.04933319484342719
Trained batch 422 in epoch 19, gen_loss = 0.403740818020018, disc_loss = 0.049232126674868044
Trained batch 423 in epoch 19, gen_loss = 0.40362203778382744, disc_loss = 0.04912551466973042
Trained batch 424 in epoch 19, gen_loss = 0.40345075526658225, disc_loss = 0.04902719041223035
Trained batch 425 in epoch 19, gen_loss = 0.40370713814463416, disc_loss = 0.048926554371038794
Trained batch 426 in epoch 19, gen_loss = 0.40384336597606785, disc_loss = 0.04882217504398186
Trained batch 427 in epoch 19, gen_loss = 0.4038505009331993, disc_loss = 0.04873284911867405
Trained batch 428 in epoch 19, gen_loss = 0.4040047698296033, disc_loss = 0.04863370760150757
Trained batch 429 in epoch 19, gen_loss = 0.40407393127679825, disc_loss = 0.04854772082140106
Trained batch 430 in epoch 19, gen_loss = 0.40418906281691414, disc_loss = 0.048447405036728994
Trained batch 431 in epoch 19, gen_loss = 0.4042875400778872, disc_loss = 0.048344358216531366
Trained batch 432 in epoch 19, gen_loss = 0.4042431651238206, disc_loss = 0.04825773988861169
Trained batch 433 in epoch 19, gen_loss = 0.40408387756155384, disc_loss = 0.04816255441969818
Trained batch 434 in epoch 19, gen_loss = 0.4038528189919461, disc_loss = 0.048080077449437875
Trained batch 435 in epoch 19, gen_loss = 0.40381501447580276, disc_loss = 0.04799642051044647
Trained batch 436 in epoch 19, gen_loss = 0.4036873048107466, disc_loss = 0.04793180160765756
Trained batch 437 in epoch 19, gen_loss = 0.4037706972053062, disc_loss = 0.04783692113102571
Trained batch 438 in epoch 19, gen_loss = 0.40370034957665246, disc_loss = 0.04775005828266739
Trained batch 439 in epoch 19, gen_loss = 0.40356671339408917, disc_loss = 0.047720026595264
Trained batch 440 in epoch 19, gen_loss = 0.40365633067765744, disc_loss = 0.04765172013611683
Trained batch 441 in epoch 19, gen_loss = 0.4037715772090994, disc_loss = 0.04755911774768987
Trained batch 442 in epoch 19, gen_loss = 0.40377098264731887, disc_loss = 0.047571132620733494
Trained batch 443 in epoch 19, gen_loss = 0.4034450815671736, disc_loss = 0.04785634189747643
Trained batch 444 in epoch 19, gen_loss = 0.40357164255018985, disc_loss = 0.04827626141709056
Trained batch 445 in epoch 19, gen_loss = 0.4035316508914858, disc_loss = 0.04818906133781467
Trained batch 446 in epoch 19, gen_loss = 0.40351199973749635, disc_loss = 0.0481056830474911
Trained batch 447 in epoch 19, gen_loss = 0.40345415882101016, disc_loss = 0.04812787620695807
Trained batch 448 in epoch 19, gen_loss = 0.4034217705904508, disc_loss = 0.04803275399714841
Trained batch 449 in epoch 19, gen_loss = 0.4035094756219122, disc_loss = 0.04794199587777257
Trained batch 450 in epoch 19, gen_loss = 0.40361457108261845, disc_loss = 0.04786275752392616
Trained batch 451 in epoch 19, gen_loss = 0.40353971386773396, disc_loss = 0.04795443936481874
Trained batch 452 in epoch 19, gen_loss = 0.40330334211685276, disc_loss = 0.04845951386330604
Trained batch 453 in epoch 19, gen_loss = 0.4031067357648837, disc_loss = 0.04858982586609569
Trained batch 454 in epoch 19, gen_loss = 0.4030541113117239, disc_loss = 0.04862050596460864
Trained batch 455 in epoch 19, gen_loss = 0.40307022889324445, disc_loss = 0.04860945079238726
Trained batch 456 in epoch 19, gen_loss = 0.4030590475714181, disc_loss = 0.0486336469189702
Trained batch 457 in epoch 19, gen_loss = 0.40306908220833565, disc_loss = 0.04863406976229434
Trained batch 458 in epoch 19, gen_loss = 0.40312224564858773, disc_loss = 0.048598736092399536
Trained batch 459 in epoch 19, gen_loss = 0.40298197829852933, disc_loss = 0.048548427282873056
Trained batch 460 in epoch 19, gen_loss = 0.40283883293512845, disc_loss = 0.04847988221438808
Testing Epoch 19
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 1.067917823791504, disc_loss = 0.5925700664520264
Trained batch 1 in epoch 0, gen_loss = 0.9215714335441589, disc_loss = 0.6764414608478546
Trained batch 2 in epoch 0, gen_loss = 0.9236652453740438, disc_loss = 0.6337080796559652
Trained batch 3 in epoch 0, gen_loss = 0.8877317756414413, disc_loss = 0.5625158250331879
Trained batch 4 in epoch 0, gen_loss = 0.842154347896576, disc_loss = 0.5165381550788879
Trained batch 5 in epoch 0, gen_loss = 0.8064464330673218, disc_loss = 0.48312628269195557
Trained batch 6 in epoch 0, gen_loss = 0.7933616808482579, disc_loss = 0.4465154494558062
Trained batch 7 in epoch 0, gen_loss = 0.7842995971441269, disc_loss = 0.41371022537350655
Trained batch 8 in epoch 0, gen_loss = 0.779504034254286, disc_loss = 0.3900984426339467
Trained batch 9 in epoch 0, gen_loss = 0.7687871217727661, disc_loss = 0.37441026270389555
Trained batch 10 in epoch 0, gen_loss = 0.7581069794568148, disc_loss = 0.3611531366001476
Trained batch 11 in epoch 0, gen_loss = 0.7456084489822388, disc_loss = 0.34553783386945724
Trained batch 12 in epoch 0, gen_loss = 0.7464736883456891, disc_loss = 0.3360567196057393
Trained batch 13 in epoch 0, gen_loss = 0.7318869062832424, disc_loss = 0.32546330030475346
Trained batch 14 in epoch 0, gen_loss = 0.7266695936520894, disc_loss = 0.31598177750905354
Trained batch 15 in epoch 0, gen_loss = 0.7212357483804226, disc_loss = 0.3066821862012148
Trained batch 16 in epoch 0, gen_loss = 0.7204857573789709, disc_loss = 0.2987542704624288
Trained batch 17 in epoch 0, gen_loss = 0.7174458669291602, disc_loss = 0.29119503994782764
Trained batch 18 in epoch 0, gen_loss = 0.7110971965287861, disc_loss = 0.28640030010750417
Trained batch 19 in epoch 0, gen_loss = 0.7026070654392242, disc_loss = 0.2870464093983173
Trained batch 20 in epoch 0, gen_loss = 0.7002541110629127, disc_loss = 0.28256223386242274
Trained batch 21 in epoch 0, gen_loss = 0.6997513581405986, disc_loss = 0.27854420041496103
Trained batch 22 in epoch 0, gen_loss = 0.6945660813995029, disc_loss = 0.2732462818207948
Trained batch 23 in epoch 0, gen_loss = 0.6928069368004799, disc_loss = 0.26712330244481564
Trained batch 24 in epoch 0, gen_loss = 0.6992458987236023, disc_loss = 0.26470233023166656
Trained batch 25 in epoch 0, gen_loss = 0.703243980040917, disc_loss = 0.2622576396052654
Trained batch 26 in epoch 0, gen_loss = 0.6994766968267935, disc_loss = 0.25699830055236816
Trained batch 27 in epoch 0, gen_loss = 0.6988109712089811, disc_loss = 0.25284450501203537
Trained batch 28 in epoch 0, gen_loss = 0.6987131669603545, disc_loss = 0.24877237143187686
Trained batch 29 in epoch 0, gen_loss = 0.699353297551473, disc_loss = 0.244963243107001
Trained batch 30 in epoch 0, gen_loss = 0.6947856910767094, disc_loss = 0.24229803392964025
Trained batch 31 in epoch 0, gen_loss = 0.6916944812983274, disc_loss = 0.23952165665104985
Trained batch 32 in epoch 0, gen_loss = 0.6907137090509589, disc_loss = 0.2353983431151419
Trained batch 33 in epoch 0, gen_loss = 0.6855407883139217, disc_loss = 0.23247424118659077
Trained batch 34 in epoch 0, gen_loss = 0.6824861764907837, disc_loss = 0.2297456864799772
Trained batch 35 in epoch 0, gen_loss = 0.6851895484659407, disc_loss = 0.22575022714833418
Trained batch 36 in epoch 0, gen_loss = 0.6878776389199335, disc_loss = 0.2218247432563756
Trained batch 37 in epoch 0, gen_loss = 0.687102662889581, disc_loss = 0.21760259627511627
Trained batch 38 in epoch 0, gen_loss = 0.6836673036599771, disc_loss = 0.21354181395891386
Trained batch 39 in epoch 0, gen_loss = 0.6817461743950843, disc_loss = 0.2098786709830165
Trained batch 40 in epoch 0, gen_loss = 0.682884098553076, disc_loss = 0.20686600411810527
Trained batch 41 in epoch 0, gen_loss = 0.6790687754040673, disc_loss = 0.20435708707996778
Trained batch 42 in epoch 0, gen_loss = 0.6754807524902876, disc_loss = 0.2014153121515762
Trained batch 43 in epoch 0, gen_loss = 0.6738317568193782, disc_loss = 0.19966938346624374
Trained batch 44 in epoch 0, gen_loss = 0.6718659652603998, disc_loss = 0.19696440564261541
Trained batch 45 in epoch 0, gen_loss = 0.6711743318516276, disc_loss = 0.19479282427093256
Trained batch 46 in epoch 0, gen_loss = 0.6701714713522728, disc_loss = 0.1918368580493521
Trained batch 47 in epoch 0, gen_loss = 0.6727293394505978, disc_loss = 0.18884818706040582
Trained batch 48 in epoch 0, gen_loss = 0.6721054510194429, disc_loss = 0.18702938620533263
Trained batch 49 in epoch 0, gen_loss = 0.6714377701282501, disc_loss = 0.18469840452075004
Trained batch 50 in epoch 0, gen_loss = 0.6708680917234982, disc_loss = 0.18211853664879704
Trained batch 51 in epoch 0, gen_loss = 0.6674161289746945, disc_loss = 0.17965566768096045
Trained batch 52 in epoch 0, gen_loss = 0.6658557473488573, disc_loss = 0.1777971937971295
Trained batch 53 in epoch 0, gen_loss = 0.6654901681122957, disc_loss = 0.1755019873380661
Trained batch 54 in epoch 0, gen_loss = 0.6632432211529125, disc_loss = 0.17353948314081538
Trained batch 55 in epoch 0, gen_loss = 0.6629288015621049, disc_loss = 0.17125494784808584
Trained batch 56 in epoch 0, gen_loss = 0.6625868542152539, disc_loss = 0.16900789306352013
Trained batch 57 in epoch 0, gen_loss = 0.6604940346602736, disc_loss = 0.16709604088602395
Trained batch 58 in epoch 0, gen_loss = 0.6605788802696486, disc_loss = 0.16484680607662364
Trained batch 59 in epoch 0, gen_loss = 0.6588165154059727, disc_loss = 0.16267239941904943
Trained batch 60 in epoch 0, gen_loss = 0.6566785652129377, disc_loss = 0.16089888649885772
Trained batch 61 in epoch 0, gen_loss = 0.6568356233258401, disc_loss = 0.1589450424597148
Trained batch 62 in epoch 0, gen_loss = 0.65531240285389, disc_loss = 0.15784708794856828
Trained batch 63 in epoch 0, gen_loss = 0.6570516908541322, disc_loss = 0.15602376672904938
Trained batch 64 in epoch 0, gen_loss = 0.656940129170051, disc_loss = 0.15414657902259093
Trained batch 65 in epoch 0, gen_loss = 0.6582549178239071, disc_loss = 0.15249778589967525
Trained batch 66 in epoch 0, gen_loss = 0.6567009669631275, disc_loss = 0.1508003672334685
Trained batch 67 in epoch 0, gen_loss = 0.6556474759298212, disc_loss = 0.14918690098120885
Trained batch 68 in epoch 0, gen_loss = 0.6566011404645615, disc_loss = 0.14751143942492595
Trained batch 69 in epoch 0, gen_loss = 0.6563133060932159, disc_loss = 0.14580425449780055
Trained batch 70 in epoch 0, gen_loss = 0.6555306265051936, disc_loss = 0.1441677640861189
Trained batch 71 in epoch 0, gen_loss = 0.6567191440198157, disc_loss = 0.14258994945945838
Trained batch 72 in epoch 0, gen_loss = 0.6562549602495481, disc_loss = 0.14117300176150996
Trained batch 73 in epoch 0, gen_loss = 0.6558438620051822, disc_loss = 0.13974307308829315
Trained batch 74 in epoch 0, gen_loss = 0.6544208598136901, disc_loss = 0.13856047632793586
Trained batch 75 in epoch 0, gen_loss = 0.6544635389980517, disc_loss = 0.13730467177045189
Trained batch 76 in epoch 0, gen_loss = 0.6536569997861787, disc_loss = 0.13593207335994614
Trained batch 77 in epoch 0, gen_loss = 0.6547569701304803, disc_loss = 0.13460869540293247
Trained batch 78 in epoch 0, gen_loss = 0.6539418584183802, disc_loss = 0.1332271338876667
Trained batch 79 in epoch 0, gen_loss = 0.6526744738221169, disc_loss = 0.13195271042641252
Trained batch 80 in epoch 0, gen_loss = 0.6521961240120876, disc_loss = 0.1306398134034725
Trained batch 81 in epoch 0, gen_loss = 0.6519472388232627, disc_loss = 0.12943398682173432
Trained batch 82 in epoch 0, gen_loss = 0.650772193828261, disc_loss = 0.12818749758403702
Trained batch 83 in epoch 0, gen_loss = 0.6489373310690835, disc_loss = 0.12710994071814985
Trained batch 84 in epoch 0, gen_loss = 0.6494023582514594, disc_loss = 0.12598861681626122
Trained batch 85 in epoch 0, gen_loss = 0.6487867333168207, disc_loss = 0.12480849497626688
Trained batch 86 in epoch 0, gen_loss = 0.6479832112104044, disc_loss = 0.12365379441401055
Trained batch 87 in epoch 0, gen_loss = 0.6485257243568247, disc_loss = 0.12257248374887487
Trained batch 88 in epoch 0, gen_loss = 0.6475186475207296, disc_loss = 0.12145122197153194
Trained batch 89 in epoch 0, gen_loss = 0.6463872810204824, disc_loss = 0.12031930192477173
Trained batch 90 in epoch 0, gen_loss = 0.6453615296017993, disc_loss = 0.11917367487490832
Trained batch 91 in epoch 0, gen_loss = 0.6445592946332434, disc_loss = 0.11817370622378329
Trained batch 92 in epoch 0, gen_loss = 0.6438608509238049, disc_loss = 0.11724600388157752
Trained batch 93 in epoch 0, gen_loss = 0.6422481448092359, disc_loss = 0.11619447599700157
Trained batch 94 in epoch 0, gen_loss = 0.640812411433772, disc_loss = 0.11528231217280814
Trained batch 95 in epoch 0, gen_loss = 0.6412027149150769, disc_loss = 0.11437126382952556
Trained batch 96 in epoch 0, gen_loss = 0.6399807389249507, disc_loss = 0.11345723075504155
Trained batch 97 in epoch 0, gen_loss = 0.6389828792640141, disc_loss = 0.11250633651352658
Trained batch 98 in epoch 0, gen_loss = 0.6383227483190671, disc_loss = 0.11160504084193346
Trained batch 99 in epoch 0, gen_loss = 0.6370796310901642, disc_loss = 0.11076606761664153
Trained batch 100 in epoch 0, gen_loss = 0.6369730965925915, disc_loss = 0.10993406289063468
Trained batch 101 in epoch 0, gen_loss = 0.6360781747920841, disc_loss = 0.10904809218995712
Trained batch 102 in epoch 0, gen_loss = 0.6349459186340999, disc_loss = 0.10824669902981485
Trained batch 103 in epoch 0, gen_loss = 0.634519633765404, disc_loss = 0.10739681807060081
Trained batch 104 in epoch 0, gen_loss = 0.6341914057731628, disc_loss = 0.10661115978090537
Trained batch 105 in epoch 0, gen_loss = 0.6333126167081436, disc_loss = 0.10577020602617061
Trained batch 106 in epoch 0, gen_loss = 0.6326941285177926, disc_loss = 0.105007910178365
Trained batch 107 in epoch 0, gen_loss = 0.6322160026541462, disc_loss = 0.10427040387703865
Trained batch 108 in epoch 0, gen_loss = 0.6330955334759634, disc_loss = 0.10357551931172883
Trained batch 109 in epoch 0, gen_loss = 0.6316823135722768, disc_loss = 0.10281031803989953
Trained batch 110 in epoch 0, gen_loss = 0.630711961436916, disc_loss = 0.10214911372744823
Trained batch 111 in epoch 0, gen_loss = 0.6303568200341293, disc_loss = 0.10137608254860554
Trained batch 112 in epoch 0, gen_loss = 0.629621059493681, disc_loss = 0.10061530590848586
Trained batch 113 in epoch 0, gen_loss = 0.6293691595395406, disc_loss = 0.09997293511568978
Trained batch 114 in epoch 0, gen_loss = 0.6285962778588999, disc_loss = 0.09925689277765544
Trained batch 115 in epoch 0, gen_loss = 0.6279768173036904, disc_loss = 0.09857623396312883
Trained batch 116 in epoch 0, gen_loss = 0.6270477817608759, disc_loss = 0.09795139129790995
Trained batch 117 in epoch 0, gen_loss = 0.6263487697657892, disc_loss = 0.09732203752244428
Trained batch 118 in epoch 0, gen_loss = 0.6269758809514406, disc_loss = 0.09669708617094185
Trained batch 119 in epoch 0, gen_loss = 0.6266188537081082, disc_loss = 0.0960711795836687
Trained batch 120 in epoch 0, gen_loss = 0.6271647480893726, disc_loss = 0.09551267838490403
Trained batch 121 in epoch 0, gen_loss = 0.6261015773796644, disc_loss = 0.09491180230054211
Trained batch 122 in epoch 0, gen_loss = 0.6265141842811088, disc_loss = 0.09437138473660481
Trained batch 123 in epoch 0, gen_loss = 0.6254028327042057, disc_loss = 0.0937342164106667
Trained batch 124 in epoch 0, gen_loss = 0.6246911182403564, disc_loss = 0.09312776486575604
Trained batch 125 in epoch 0, gen_loss = 0.6245375474294027, disc_loss = 0.09253841267514323
Trained batch 126 in epoch 0, gen_loss = 0.6252219827156368, disc_loss = 0.0919341154425867
Trained batch 127 in epoch 0, gen_loss = 0.6248675901442766, disc_loss = 0.0913247635908192
Trained batch 128 in epoch 0, gen_loss = 0.6241182592488075, disc_loss = 0.09075867641688318
Trained batch 129 in epoch 0, gen_loss = 0.6235018826448, disc_loss = 0.09016523397026154
Trained batch 130 in epoch 0, gen_loss = 0.6226716319113287, disc_loss = 0.08962491195904844
Trained batch 131 in epoch 0, gen_loss = 0.6215693950653076, disc_loss = 0.0890510703549918
Trained batch 132 in epoch 0, gen_loss = 0.6208824824569816, disc_loss = 0.08850715653900813
Trained batch 133 in epoch 0, gen_loss = 0.6205720861456288, disc_loss = 0.08793849258947728
Trained batch 134 in epoch 0, gen_loss = 0.6204617871178522, disc_loss = 0.08742383459100017
Trained batch 135 in epoch 0, gen_loss = 0.6189581817563843, disc_loss = 0.08705020778100281
Trained batch 136 in epoch 0, gen_loss = 0.6204353240284607, disc_loss = 0.08656901529018027
Trained batch 137 in epoch 0, gen_loss = 0.6214267792909042, disc_loss = 0.08606476145054119
Trained batch 138 in epoch 0, gen_loss = 0.620149626791906, disc_loss = 0.08559038747343228
Trained batch 139 in epoch 0, gen_loss = 0.6188376892890249, disc_loss = 0.08517976682633162
Trained batch 140 in epoch 0, gen_loss = 0.6189466767700006, disc_loss = 0.08471425144490621
Trained batch 141 in epoch 0, gen_loss = 0.6188977224306321, disc_loss = 0.08424872932562107
Trained batch 142 in epoch 0, gen_loss = 0.6186529779350841, disc_loss = 0.08375528282192829
Trained batch 143 in epoch 0, gen_loss = 0.6179967383957572, disc_loss = 0.08326268518835099
Trained batch 144 in epoch 0, gen_loss = 0.6177200845603286, disc_loss = 0.08277674226154541
Trained batch 145 in epoch 0, gen_loss = 0.6162522786284146, disc_loss = 0.08233141693707606
Trained batch 146 in epoch 0, gen_loss = 0.6164108948642705, disc_loss = 0.08188544465925823
Trained batch 147 in epoch 0, gen_loss = 0.616373733894245, disc_loss = 0.08143847004032216
Trained batch 148 in epoch 0, gen_loss = 0.6165926992493188, disc_loss = 0.08099323513623852
Trained batch 149 in epoch 0, gen_loss = 0.6166769321759542, disc_loss = 0.08052411250770092
Trained batch 150 in epoch 0, gen_loss = 0.615219637060797, disc_loss = 0.08022632770585698
Trained batch 151 in epoch 0, gen_loss = 0.6148255143902803, disc_loss = 0.07997597905954248
Trained batch 152 in epoch 0, gen_loss = 0.614231063065186, disc_loss = 0.07952767195411367
Trained batch 153 in epoch 0, gen_loss = 0.6142940372228622, disc_loss = 0.07910234628656468
Trained batch 154 in epoch 0, gen_loss = 0.6145043886476947, disc_loss = 0.07878224638200575
Trained batch 155 in epoch 0, gen_loss = 0.6139362314954783, disc_loss = 0.07900738591949145
Trained batch 156 in epoch 0, gen_loss = 0.6140188136298186, disc_loss = 0.0790919660572793
Trained batch 157 in epoch 0, gen_loss = 0.6133928406464902, disc_loss = 0.07875311028070842
Trained batch 158 in epoch 0, gen_loss = 0.6122052067855619, disc_loss = 0.07849945402089155
Trained batch 159 in epoch 0, gen_loss = 0.6110728124156595, disc_loss = 0.0781246056780219
Trained batch 160 in epoch 0, gen_loss = 0.6107415081181141, disc_loss = 0.07772971129750614
Trained batch 161 in epoch 0, gen_loss = 0.610235223615611, disc_loss = 0.07735672357411665
Trained batch 162 in epoch 0, gen_loss = 0.6093204825933726, disc_loss = 0.07705554998039833
Trained batch 163 in epoch 0, gen_loss = 0.6083347326735171, disc_loss = 0.07669343561978965
Trained batch 164 in epoch 0, gen_loss = 0.6077078286445502, disc_loss = 0.07637661383910613
Trained batch 165 in epoch 0, gen_loss = 0.6075407408447151, disc_loss = 0.07608106261096804
Trained batch 166 in epoch 0, gen_loss = 0.6080456206541576, disc_loss = 0.07574086840415073
Trained batch 167 in epoch 0, gen_loss = 0.6072958393820694, disc_loss = 0.07541691769091856
Trained batch 168 in epoch 0, gen_loss = 0.6079703176162652, disc_loss = 0.07506562350593375
Trained batch 169 in epoch 0, gen_loss = 0.6072880760711782, disc_loss = 0.07473369245143498
Trained batch 170 in epoch 0, gen_loss = 0.607003676089627, disc_loss = 0.07436945184803846
Trained batch 171 in epoch 0, gen_loss = 0.6064593454086503, disc_loss = 0.07399567496031523
Trained batch 172 in epoch 0, gen_loss = 0.6055494550335614, disc_loss = 0.07363650581201894
Trained batch 173 in epoch 0, gen_loss = 0.6046888287040009, disc_loss = 0.07329936414935637
Trained batch 174 in epoch 0, gen_loss = 0.6045307374000549, disc_loss = 0.07296292773314884
Trained batch 175 in epoch 0, gen_loss = 0.6036831790750677, disc_loss = 0.07260655928191474
Trained batch 176 in epoch 0, gen_loss = 0.6027620027294267, disc_loss = 0.07226783218188475
Trained batch 177 in epoch 0, gen_loss = 0.601888445153665, disc_loss = 0.0720090823394529
Trained batch 178 in epoch 0, gen_loss = 0.6010967904296001, disc_loss = 0.07169815460896359
Trained batch 179 in epoch 0, gen_loss = 0.6008411707149611, disc_loss = 0.07140356169806586
Trained batch 180 in epoch 0, gen_loss = 0.601144728904271, disc_loss = 0.07111422217435599
Trained batch 181 in epoch 0, gen_loss = 0.6004637614056304, disc_loss = 0.07086118259518356
Trained batch 182 in epoch 0, gen_loss = 0.600026691871914, disc_loss = 0.07057265181074052
Trained batch 183 in epoch 0, gen_loss = 0.5995676617907442, disc_loss = 0.07027976736223893
Trained batch 184 in epoch 0, gen_loss = 0.5989633355591748, disc_loss = 0.06997953940787026
Trained batch 185 in epoch 0, gen_loss = 0.5989855407707153, disc_loss = 0.06968939558212314
Trained batch 186 in epoch 0, gen_loss = 0.5991286184379762, disc_loss = 0.0693814073524931
Trained batch 187 in epoch 0, gen_loss = 0.598954235144118, disc_loss = 0.06907982163705882
Trained batch 188 in epoch 0, gen_loss = 0.5986073103846696, disc_loss = 0.068827539726737
Trained batch 189 in epoch 0, gen_loss = 0.5986129934850491, disc_loss = 0.06855650681904273
Trained batch 190 in epoch 0, gen_loss = 0.598238846238371, disc_loss = 0.06824970001072003
Trained batch 191 in epoch 0, gen_loss = 0.5983176136699816, disc_loss = 0.06799997021153104
Trained batch 192 in epoch 0, gen_loss = 0.5987697171114887, disc_loss = 0.06772878106413265
Trained batch 193 in epoch 0, gen_loss = 0.5986256324446079, disc_loss = 0.06742802718366236
Trained batch 194 in epoch 0, gen_loss = 0.5985572241819822, disc_loss = 0.06713590347805085
Trained batch 195 in epoch 0, gen_loss = 0.5988005513743478, disc_loss = 0.06684915097050216
Trained batch 196 in epoch 0, gen_loss = 0.5979275098306879, disc_loss = 0.06656692839856378
Trained batch 197 in epoch 0, gen_loss = 0.5980821905112026, disc_loss = 0.06629100049177956
Trained batch 198 in epoch 0, gen_loss = 0.5976622383199145, disc_loss = 0.06599953120583715
Trained batch 199 in epoch 0, gen_loss = 0.5970857843756676, disc_loss = 0.06573456954210996
Trained batch 200 in epoch 0, gen_loss = 0.597122114689196, disc_loss = 0.0654582457375986
Trained batch 201 in epoch 0, gen_loss = 0.5967600496098546, disc_loss = 0.06519513889354202
Trained batch 202 in epoch 0, gen_loss = 0.5965201147084166, disc_loss = 0.06491344071135585
Trained batch 203 in epoch 0, gen_loss = 0.5966870174104092, disc_loss = 0.06464201834637161
Trained batch 204 in epoch 0, gen_loss = 0.5959859307219343, disc_loss = 0.06436241575312324
Trained batch 205 in epoch 0, gen_loss = 0.5953632177947794, disc_loss = 0.06409286593710914
Trained batch 206 in epoch 0, gen_loss = 0.5956746200144579, disc_loss = 0.0638249790124991
Trained batch 207 in epoch 0, gen_loss = 0.5955315050310813, disc_loss = 0.06355818533875908
Trained batch 208 in epoch 0, gen_loss = 0.5956219227975635, disc_loss = 0.06328450661580386
Trained batch 209 in epoch 0, gen_loss = 0.5952682425578435, disc_loss = 0.06301505790269446
Trained batch 210 in epoch 0, gen_loss = 0.5946597430095854, disc_loss = 0.0627586988012761
Trained batch 211 in epoch 0, gen_loss = 0.5940323145884387, disc_loss = 0.062497763143290044
Trained batch 212 in epoch 0, gen_loss = 0.5932078025710414, disc_loss = 0.06223855137894971
Trained batch 213 in epoch 0, gen_loss = 0.5928652960563374, disc_loss = 0.06198042667705879
Trained batch 214 in epoch 0, gen_loss = 0.5928895032683085, disc_loss = 0.061722519612589545
Trained batch 215 in epoch 0, gen_loss = 0.5929005446809309, disc_loss = 0.061470902179954226
Trained batch 216 in epoch 0, gen_loss = 0.5931743767953688, disc_loss = 0.06122757497024701
Trained batch 217 in epoch 0, gen_loss = 0.5925299605918587, disc_loss = 0.06099634457789703
Trained batch 218 in epoch 0, gen_loss = 0.5926801462968191, disc_loss = 0.06075693114945605
Trained batch 219 in epoch 0, gen_loss = 0.5923271107402714, disc_loss = 0.06051560106941245
Trained batch 220 in epoch 0, gen_loss = 0.5922397246997281, disc_loss = 0.060272736767753625
Trained batch 221 in epoch 0, gen_loss = 0.591897986090935, disc_loss = 0.060028469294880156
Trained batch 222 in epoch 0, gen_loss = 0.5919820106350253, disc_loss = 0.059789752955193474
Trained batch 223 in epoch 0, gen_loss = 0.5914879551689539, disc_loss = 0.05955358958453871
Trained batch 224 in epoch 0, gen_loss = 0.5908980855676863, disc_loss = 0.059319810912840894
Trained batch 225 in epoch 0, gen_loss = 0.5906392363584148, disc_loss = 0.05908680212708701
Trained batch 226 in epoch 0, gen_loss = 0.5904212075445621, disc_loss = 0.058852036138955455
Trained batch 227 in epoch 0, gen_loss = 0.5905806219630074, disc_loss = 0.058629974579896056
Trained batch 228 in epoch 0, gen_loss = 0.5901728006950112, disc_loss = 0.05840374723963407
Trained batch 229 in epoch 0, gen_loss = 0.5894522871660149, disc_loss = 0.05820078904659528
Trained batch 230 in epoch 0, gen_loss = 0.5892256134516233, disc_loss = 0.057986089151384895
Trained batch 231 in epoch 0, gen_loss = 0.5893849067646881, disc_loss = 0.05776521407172148
Trained batch 232 in epoch 0, gen_loss = 0.5891952197439169, disc_loss = 0.05754946689661033
Trained batch 233 in epoch 0, gen_loss = 0.5889277030260135, disc_loss = 0.05733290968192184
Trained batch 234 in epoch 0, gen_loss = 0.5884163496342111, disc_loss = 0.05711666721493957
Trained batch 235 in epoch 0, gen_loss = 0.587906716991279, disc_loss = 0.05690709932438903
Trained batch 236 in epoch 0, gen_loss = 0.587591935562182, disc_loss = 0.05669205270330362
Trained batch 237 in epoch 0, gen_loss = 0.5870574618838414, disc_loss = 0.05647649890508409
Trained batch 238 in epoch 0, gen_loss = 0.586925511953721, disc_loss = 0.05626649079478061
Trained batch 239 in epoch 0, gen_loss = 0.5871729365239541, disc_loss = 0.05605943762542059
Trained batch 240 in epoch 0, gen_loss = 0.586987598184728, disc_loss = 0.05585142707691771
Trained batch 241 in epoch 0, gen_loss = 0.5873580428440709, disc_loss = 0.05565285415981303
Trained batch 242 in epoch 0, gen_loss = 0.5869115947941204, disc_loss = 0.05545041814001867
Trained batch 243 in epoch 0, gen_loss = 0.58652441533374, disc_loss = 0.05524827338770398
Trained batch 244 in epoch 0, gen_loss = 0.586292271346462, disc_loss = 0.055049106149877215
Trained batch 245 in epoch 0, gen_loss = 0.5860643923524919, disc_loss = 0.0548456601753104
Trained batch 246 in epoch 0, gen_loss = 0.5857971212883227, disc_loss = 0.05464700272359587
Trained batch 247 in epoch 0, gen_loss = 0.5852376068792036, disc_loss = 0.05445944320695895
Trained batch 248 in epoch 0, gen_loss = 0.585021608086475, disc_loss = 0.05426309366587056
Trained batch 249 in epoch 0, gen_loss = 0.5845732339620591, disc_loss = 0.0540674939788878
Trained batch 250 in epoch 0, gen_loss = 0.5849032740431478, disc_loss = 0.053881036162198304
Trained batch 251 in epoch 0, gen_loss = 0.5848053446601308, disc_loss = 0.05368991006010523
Trained batch 252 in epoch 0, gen_loss = 0.5844641734253276, disc_loss = 0.05349882323250705
Trained batch 253 in epoch 0, gen_loss = 0.5843239080483519, disc_loss = 0.05331138251202665
Trained batch 254 in epoch 0, gen_loss = 0.5837730016194138, disc_loss = 0.0531228566396178
Trained batch 255 in epoch 0, gen_loss = 0.5835531238699332, disc_loss = 0.052933889979613014
Trained batch 256 in epoch 0, gen_loss = 0.5832059109721203, disc_loss = 0.0527477616875465
Trained batch 257 in epoch 0, gen_loss = 0.5828335073798202, disc_loss = 0.05256031683552288
Trained batch 258 in epoch 0, gen_loss = 0.5827153100700452, disc_loss = 0.052376385616375906
Trained batch 259 in epoch 0, gen_loss = 0.5823697669001726, disc_loss = 0.05219647867175249
Trained batch 260 in epoch 0, gen_loss = 0.5814269334648761, disc_loss = 0.05220178320604266
Trained batch 261 in epoch 0, gen_loss = 0.581047869024386, disc_loss = 0.05239845081481315
Trained batch 262 in epoch 0, gen_loss = 0.5812926112245698, disc_loss = 0.05231195961624497
Trained batch 263 in epoch 0, gen_loss = 0.5810746533626859, disc_loss = 0.05249243233860894
Trained batch 264 in epoch 0, gen_loss = 0.5808799020524295, disc_loss = 0.05262633903690104
Trained batch 265 in epoch 0, gen_loss = 0.580474425079231, disc_loss = 0.05272267278479902
Trained batch 266 in epoch 0, gen_loss = 0.5809561639242851, disc_loss = 0.0527135669096802
Trained batch 267 in epoch 0, gen_loss = 0.5810461044311523, disc_loss = 0.05277274250150172
Trained batch 268 in epoch 0, gen_loss = 0.5806990028757145, disc_loss = 0.05262815651438826
Trained batch 269 in epoch 0, gen_loss = 0.5805302686161465, disc_loss = 0.05259676796073715
Trained batch 270 in epoch 0, gen_loss = 0.5804956581759717, disc_loss = 0.05244751425453108
Trained batch 271 in epoch 0, gen_loss = 0.5802647239145111, disc_loss = 0.05229300499537631
Trained batch 272 in epoch 0, gen_loss = 0.579972465396364, disc_loss = 0.0521518834747183
Trained batch 273 in epoch 0, gen_loss = 0.5801119451975301, disc_loss = 0.052001198172487696
Trained batch 274 in epoch 0, gen_loss = 0.5797549565271898, disc_loss = 0.05185887064784765
Trained batch 275 in epoch 0, gen_loss = 0.5797601757922034, disc_loss = 0.05170100100297967
Trained batch 276 in epoch 0, gen_loss = 0.5795925751274673, disc_loss = 0.05155179132825093
Trained batch 277 in epoch 0, gen_loss = 0.5799950791134251, disc_loss = 0.05140481849716936
Trained batch 278 in epoch 0, gen_loss = 0.5800236915388415, disc_loss = 0.051255445042791975
Trained batch 279 in epoch 0, gen_loss = 0.5801466397941113, disc_loss = 0.05109900755009481
Trained batch 280 in epoch 0, gen_loss = 0.5796301224902007, disc_loss = 0.05094189770035843
Trained batch 281 in epoch 0, gen_loss = 0.5793483212907263, disc_loss = 0.05078780317698863
Trained batch 282 in epoch 0, gen_loss = 0.5791736072449296, disc_loss = 0.05063314944861108
Trained batch 283 in epoch 0, gen_loss = 0.5797140306570161, disc_loss = 0.05049204897187965
Trained batch 284 in epoch 0, gen_loss = 0.5793796322847667, disc_loss = 0.05033739250022591
Trained batch 285 in epoch 0, gen_loss = 0.5788271043684099, disc_loss = 0.050186425149505894
Trained batch 286 in epoch 0, gen_loss = 0.5785951693298925, disc_loss = 0.050033401702741606
Trained batch 287 in epoch 0, gen_loss = 0.5786071525265774, disc_loss = 0.04987854392028465
Trained batch 288 in epoch 0, gen_loss = 0.5788605081168838, disc_loss = 0.04972715139756411
Trained batch 289 in epoch 0, gen_loss = 0.5787621298740651, disc_loss = 0.049575728279185195
Trained batch 290 in epoch 0, gen_loss = 0.5785654476008464, disc_loss = 0.04942224693366189
Trained batch 291 in epoch 0, gen_loss = 0.5783386369274087, disc_loss = 0.049273298027899676
Trained batch 292 in epoch 0, gen_loss = 0.5779062617354018, disc_loss = 0.04912341079824054
Trained batch 293 in epoch 0, gen_loss = 0.5772427689461481, disc_loss = 0.04898821918743656
Trained batch 294 in epoch 0, gen_loss = 0.576699481576176, disc_loss = 0.0488379379623901
Trained batch 295 in epoch 0, gen_loss = 0.576956457987025, disc_loss = 0.04869904273623802
Trained batch 296 in epoch 0, gen_loss = 0.5767255943230908, disc_loss = 0.04855478516080564
Trained batch 297 in epoch 0, gen_loss = 0.5762937468970382, disc_loss = 0.048406191404608875
Trained batch 298 in epoch 0, gen_loss = 0.5760354933930081, disc_loss = 0.04825882819546605
Trained batch 299 in epoch 0, gen_loss = 0.5757576005657514, disc_loss = 0.04811273102338116
Trained batch 300 in epoch 0, gen_loss = 0.5754443691220394, disc_loss = 0.04796808518382699
Trained batch 301 in epoch 0, gen_loss = 0.575202824954955, disc_loss = 0.04782372480720923
Trained batch 302 in epoch 0, gen_loss = 0.5752023984693458, disc_loss = 0.047679652550592776
Trained batch 303 in epoch 0, gen_loss = 0.5748354050477869, disc_loss = 0.047536378311250654
Trained batch 304 in epoch 0, gen_loss = 0.5745039592023755, disc_loss = 0.047397109574531436
Trained batch 305 in epoch 0, gen_loss = 0.5742335461713131, disc_loss = 0.04726131425659154
Trained batch 306 in epoch 0, gen_loss = 0.5741443824302102, disc_loss = 0.047125798756262764
Trained batch 307 in epoch 0, gen_loss = 0.574414006688378, disc_loss = 0.0469918846418815
Trained batch 308 in epoch 0, gen_loss = 0.5739690983565494, disc_loss = 0.046866113645503825
Trained batch 309 in epoch 0, gen_loss = 0.5739441556315268, disc_loss = 0.0467368608385685
Trained batch 310 in epoch 0, gen_loss = 0.573587613665406, disc_loss = 0.04660856446784313
Trained batch 311 in epoch 0, gen_loss = 0.5731905941397716, disc_loss = 0.04648126199399718
Trained batch 312 in epoch 0, gen_loss = 0.5730256501097268, disc_loss = 0.0463534456293899
Trained batch 313 in epoch 0, gen_loss = 0.5728590906045998, disc_loss = 0.046220894472875224
Trained batch 314 in epoch 0, gen_loss = 0.5724127982343946, disc_loss = 0.04609978211718419
Trained batch 315 in epoch 0, gen_loss = 0.5723100609228581, disc_loss = 0.04597186079820547
Trained batch 316 in epoch 0, gen_loss = 0.5718307278885826, disc_loss = 0.045848073624368255
Trained batch 317 in epoch 0, gen_loss = 0.5713478626695069, disc_loss = 0.04573016006751396
Trained batch 318 in epoch 0, gen_loss = 0.570961355789328, disc_loss = 0.04560470953437742
Trained batch 319 in epoch 0, gen_loss = 0.5705963656306267, disc_loss = 0.045476625813171266
Trained batch 320 in epoch 0, gen_loss = 0.5704318934883285, disc_loss = 0.045348449260565075
Trained batch 321 in epoch 0, gen_loss = 0.5699015401350045, disc_loss = 0.04521985164328669
Trained batch 322 in epoch 0, gen_loss = 0.5698176617777384, disc_loss = 0.04509789051614909
Trained batch 323 in epoch 0, gen_loss = 0.5694968645219449, disc_loss = 0.04497058557585043
Trained batch 324 in epoch 0, gen_loss = 0.5693114040448115, disc_loss = 0.04484785451267201
Trained batch 325 in epoch 0, gen_loss = 0.5692233423148196, disc_loss = 0.04472678506595477
Trained batch 326 in epoch 0, gen_loss = 0.5687330613989349, disc_loss = 0.0446022070655229
Trained batch 327 in epoch 0, gen_loss = 0.5686431898758179, disc_loss = 0.04448357099034006
Trained batch 328 in epoch 0, gen_loss = 0.5682801443030406, disc_loss = 0.0443645795038689
Trained batch 329 in epoch 0, gen_loss = 0.568490930037065, disc_loss = 0.044247506878508085
Trained batch 330 in epoch 0, gen_loss = 0.5681868415224588, disc_loss = 0.04412384503914938
Trained batch 331 in epoch 0, gen_loss = 0.567862647484584, disc_loss = 0.04400147612806948
Trained batch 332 in epoch 0, gen_loss = 0.5673938324680557, disc_loss = 0.043880589232240266
Trained batch 333 in epoch 0, gen_loss = 0.5667843120005316, disc_loss = 0.04378220601938665
Trained batch 334 in epoch 0, gen_loss = 0.5665751578202888, disc_loss = 0.04366498402834161
Trained batch 335 in epoch 0, gen_loss = 0.5665096232578868, disc_loss = 0.04354666396033108
Trained batch 336 in epoch 0, gen_loss = 0.5661809059738759, disc_loss = 0.04342813954207748
Trained batch 337 in epoch 0, gen_loss = 0.5664909983704076, disc_loss = 0.04331796727564803
Trained batch 338 in epoch 0, gen_loss = 0.5664485505724375, disc_loss = 0.043203758619104825
Trained batch 339 in epoch 0, gen_loss = 0.5666352158960174, disc_loss = 0.043089260925840145
Trained batch 340 in epoch 0, gen_loss = 0.566109712172813, disc_loss = 0.04297201695327601
Trained batch 341 in epoch 0, gen_loss = 0.5657575075563631, disc_loss = 0.04285975386816137
Trained batch 342 in epoch 0, gen_loss = 0.5655079285014127, disc_loss = 0.04274643492428776
Trained batch 343 in epoch 0, gen_loss = 0.5652026062787965, disc_loss = 0.042633540073523386
Trained batch 344 in epoch 0, gen_loss = 0.5651420772939488, disc_loss = 0.04252192171331009
Trained batch 345 in epoch 0, gen_loss = 0.5648729981197788, disc_loss = 0.042407630464315116
Trained batch 346 in epoch 0, gen_loss = 0.5645533136229006, disc_loss = 0.04229653798585881
Trained batch 347 in epoch 0, gen_loss = 0.5644217963362562, disc_loss = 0.04218881952993829
Trained batch 348 in epoch 0, gen_loss = 0.5642374703569877, disc_loss = 0.04208362038596867
Trained batch 349 in epoch 0, gen_loss = 0.5641590619938714, disc_loss = 0.041975878922800934
Trained batch 350 in epoch 0, gen_loss = 0.5639642199389955, disc_loss = 0.041867825170803785
Trained batch 351 in epoch 0, gen_loss = 0.563814709386365, disc_loss = 0.041760844619023955
Trained batch 352 in epoch 0, gen_loss = 0.5637523195054646, disc_loss = 0.041650106569767927
Trained batch 353 in epoch 0, gen_loss = 0.5638624915463776, disc_loss = 0.04154313542474966
Trained batch 354 in epoch 0, gen_loss = 0.5633613693882042, disc_loss = 0.04144002183038794
Trained batch 355 in epoch 0, gen_loss = 0.5633775461255834, disc_loss = 0.04133918707185749
Trained batch 356 in epoch 0, gen_loss = 0.5631478837057322, disc_loss = 0.041235236268417505
Trained batch 357 in epoch 0, gen_loss = 0.5632209324137458, disc_loss = 0.041130033628650885
Trained batch 358 in epoch 0, gen_loss = 0.5634548661602573, disc_loss = 0.04102770227311091
Trained batch 359 in epoch 0, gen_loss = 0.5633450492388672, disc_loss = 0.04092263257156851
Trained batch 360 in epoch 0, gen_loss = 0.5632414428976434, disc_loss = 0.04081864256883902
Trained batch 361 in epoch 0, gen_loss = 0.5628081900968077, disc_loss = 0.040714398681865334
Trained batch 362 in epoch 0, gen_loss = 0.5626652493621364, disc_loss = 0.04061377606323866
Trained batch 363 in epoch 0, gen_loss = 0.562295746917908, disc_loss = 0.04051345822741636
Trained batch 364 in epoch 0, gen_loss = 0.5620142000178768, disc_loss = 0.04041086970190581
Trained batch 365 in epoch 0, gen_loss = 0.5619573795893154, disc_loss = 0.04031350806831316
Trained batch 366 in epoch 0, gen_loss = 0.5619628240204637, disc_loss = 0.040213479524051986
Trained batch 367 in epoch 0, gen_loss = 0.5617640892286664, disc_loss = 0.04011402095594625
Trained batch 368 in epoch 0, gen_loss = 0.5616205009180033, disc_loss = 0.04001617086306719
Trained batch 369 in epoch 0, gen_loss = 0.5614424862571665, disc_loss = 0.03991605077832434
Trained batch 370 in epoch 0, gen_loss = 0.5612652648812677, disc_loss = 0.03981523061198788
Trained batch 371 in epoch 0, gen_loss = 0.5611037121665093, disc_loss = 0.03971693171150682
Trained batch 372 in epoch 0, gen_loss = 0.5610227829329769, disc_loss = 0.03962228698069205
Trained batch 373 in epoch 0, gen_loss = 0.5609274230857584, disc_loss = 0.039528090904596296
Trained batch 374 in epoch 0, gen_loss = 0.5604101500511169, disc_loss = 0.03943526592416068
Trained batch 375 in epoch 0, gen_loss = 0.5601550020436024, disc_loss = 0.03933842209455101
Trained batch 376 in epoch 0, gen_loss = 0.559474772183269, disc_loss = 0.03926431981782461
Trained batch 377 in epoch 0, gen_loss = 0.5592261879217058, disc_loss = 0.03917407715402386
Trained batch 378 in epoch 0, gen_loss = 0.5591057667946123, disc_loss = 0.03908050011678803
Trained batch 379 in epoch 0, gen_loss = 0.5586233749201424, disc_loss = 0.03898549107650883
Trained batch 380 in epoch 0, gen_loss = 0.5588385686473897, disc_loss = 0.038893765637289315
Trained batch 381 in epoch 0, gen_loss = 0.5586015429952382, disc_loss = 0.038798420899060035
Trained batch 382 in epoch 0, gen_loss = 0.5583148591667803, disc_loss = 0.03870525571770538
Trained batch 383 in epoch 0, gen_loss = 0.5579281650328388, disc_loss = 0.03861116399942451
Trained batch 384 in epoch 0, gen_loss = 0.5574508529978913, disc_loss = 0.03851721436873853
Trained batch 385 in epoch 0, gen_loss = 0.5573748542391574, disc_loss = 0.038440260057786356
Trained batch 386 in epoch 0, gen_loss = 0.5570466429842227, disc_loss = 0.038361203788180455
Trained batch 387 in epoch 0, gen_loss = 0.5568756478809819, disc_loss = 0.03827686116853057
Trained batch 388 in epoch 0, gen_loss = 0.5567434870645136, disc_loss = 0.038187019082844484
Trained batch 389 in epoch 0, gen_loss = 0.556555841748531, disc_loss = 0.038096207545067255
Trained batch 390 in epoch 0, gen_loss = 0.5565309316453422, disc_loss = 0.0380053505196672
Trained batch 391 in epoch 0, gen_loss = 0.556329036321567, disc_loss = 0.0379151653769255
Trained batch 392 in epoch 0, gen_loss = 0.5562213958826381, disc_loss = 0.037825458791490844
Trained batch 393 in epoch 0, gen_loss = 0.5562873304949194, disc_loss = 0.037737066710372524
Trained batch 394 in epoch 0, gen_loss = 0.5563768156721622, disc_loss = 0.03765084587355864
Trained batch 395 in epoch 0, gen_loss = 0.5563082698770244, disc_loss = 0.03756482775189039
Trained batch 396 in epoch 0, gen_loss = 0.5560786874228221, disc_loss = 0.03747936477122232
Trained batch 397 in epoch 0, gen_loss = 0.5559066372301111, disc_loss = 0.03739177668584164
Trained batch 398 in epoch 0, gen_loss = 0.5556635963438746, disc_loss = 0.03730504328553054
Trained batch 399 in epoch 0, gen_loss = 0.5556343317776918, disc_loss = 0.037219216829398646
Trained batch 400 in epoch 0, gen_loss = 0.5553320374274789, disc_loss = 0.03713219752070724
Trained batch 401 in epoch 0, gen_loss = 0.5550428330156933, disc_loss = 0.0370453559951069
Trained batch 402 in epoch 0, gen_loss = 0.5551511623871238, disc_loss = 0.03696313777027961
Trained batch 403 in epoch 0, gen_loss = 0.554811781143198, disc_loss = 0.03688191808414378
Trained batch 404 in epoch 0, gen_loss = 0.5544711165957981, disc_loss = 0.0368002027882562
Trained batch 405 in epoch 0, gen_loss = 0.5544199397411252, disc_loss = 0.03671788771549616
Trained batch 406 in epoch 0, gen_loss = 0.5541413574312477, disc_loss = 0.03663712352656139
Trained batch 407 in epoch 0, gen_loss = 0.5539995085667161, disc_loss = 0.036558155825261174
Trained batch 408 in epoch 0, gen_loss = 0.5539161313716823, disc_loss = 0.036476508180285215
Trained batch 409 in epoch 0, gen_loss = 0.553791074781883, disc_loss = 0.036395069127107355
Trained batch 410 in epoch 0, gen_loss = 0.5537297367469528, disc_loss = 0.036313181640489654
Trained batch 411 in epoch 0, gen_loss = 0.5535193030695313, disc_loss = 0.0362304643116376
Trained batch 412 in epoch 0, gen_loss = 0.5532803762767274, disc_loss = 0.036150075054386985
Trained batch 413 in epoch 0, gen_loss = 0.5531260926222455, disc_loss = 0.03607101669391068
Trained batch 414 in epoch 0, gen_loss = 0.553127051333347, disc_loss = 0.035993518562516175
Trained batch 415 in epoch 0, gen_loss = 0.5528858296859723, disc_loss = 0.03591512832813001
Trained batch 416 in epoch 0, gen_loss = 0.5527800930489739, disc_loss = 0.03583530644714225
Trained batch 417 in epoch 0, gen_loss = 0.5525824934529345, disc_loss = 0.03575568670533936
Trained batch 418 in epoch 0, gen_loss = 0.5523829419601504, disc_loss = 0.035675849272649475
Trained batch 419 in epoch 0, gen_loss = 0.5523156402366501, disc_loss = 0.0355963646722514
Trained batch 420 in epoch 0, gen_loss = 0.5521284464985627, disc_loss = 0.035516668252111576
Trained batch 421 in epoch 0, gen_loss = 0.5518503923551731, disc_loss = 0.03543747958045241
Trained batch 422 in epoch 0, gen_loss = 0.551886525700842, disc_loss = 0.035360512513574874
Trained batch 423 in epoch 0, gen_loss = 0.551809937745895, disc_loss = 0.03528364542498306
Trained batch 424 in epoch 0, gen_loss = 0.5516306797897115, disc_loss = 0.035204946038258425
Trained batch 425 in epoch 0, gen_loss = 0.5513770663542367, disc_loss = 0.03513527127035277
Trained batch 426 in epoch 0, gen_loss = 0.5513519603558391, disc_loss = 0.03506490433113148
Trained batch 427 in epoch 0, gen_loss = 0.551155424424421, disc_loss = 0.03499254726078013
Trained batch 428 in epoch 0, gen_loss = 0.5510168017207325, disc_loss = 0.03491677822749237
Trained batch 429 in epoch 0, gen_loss = 0.5506489515997642, disc_loss = 0.03484184164120707
Trained batch 430 in epoch 0, gen_loss = 0.5502828100302933, disc_loss = 0.03477522369102508
Trained batch 431 in epoch 0, gen_loss = 0.55015128650875, disc_loss = 0.03470635704838464
Trained batch 432 in epoch 0, gen_loss = 0.5501932823217494, disc_loss = 0.03463442225329681
Trained batch 433 in epoch 0, gen_loss = 0.5499283591036424, disc_loss = 0.034559858846478164
Trained batch 434 in epoch 0, gen_loss = 0.5496318410867932, disc_loss = 0.03448493298111034
Trained batch 435 in epoch 0, gen_loss = 0.5493189113539293, disc_loss = 0.03441120885310421
Trained batch 436 in epoch 0, gen_loss = 0.5493105133692787, disc_loss = 0.03433822883501888
Trained batch 437 in epoch 0, gen_loss = 0.5490432854520676, disc_loss = 0.03426543627674245
Trained batch 438 in epoch 0, gen_loss = 0.5486809371679954, disc_loss = 0.034193622345075114
Trained batch 439 in epoch 0, gen_loss = 0.5485791671682488, disc_loss = 0.0341207958990708
Trained batch 440 in epoch 0, gen_loss = 0.5485161586818782, disc_loss = 0.03404765785935751
Trained batch 441 in epoch 0, gen_loss = 0.5482547784148298, disc_loss = 0.033975140642526463
Trained batch 442 in epoch 0, gen_loss = 0.5480432640214536, disc_loss = 0.033904194871792005
Trained batch 443 in epoch 0, gen_loss = 0.5482168086879963, disc_loss = 0.033839064121649075
Trained batch 444 in epoch 0, gen_loss = 0.5479110208120239, disc_loss = 0.033771708968691944
Trained batch 445 in epoch 0, gen_loss = 0.5476798317624849, disc_loss = 0.03370348451922192
Trained batch 446 in epoch 0, gen_loss = 0.5474930273606473, disc_loss = 0.03363353607371883
Trained batch 447 in epoch 0, gen_loss = 0.5476587813879762, disc_loss = 0.03356531699630848
Trained batch 448 in epoch 0, gen_loss = 0.5473796060196806, disc_loss = 0.033496503323577925
Trained batch 449 in epoch 0, gen_loss = 0.5471507610215081, disc_loss = 0.03342999494168907
Trained batch 450 in epoch 0, gen_loss = 0.5472706050143273, disc_loss = 0.03336412098233953
Trained batch 451 in epoch 0, gen_loss = 0.5472489492555636, disc_loss = 0.03329594369845844
Trained batch 452 in epoch 0, gen_loss = 0.5469998602835547, disc_loss = 0.03322641118984694
Trained batch 453 in epoch 0, gen_loss = 0.5470097302602777, disc_loss = 0.03315888502940716
Trained batch 454 in epoch 0, gen_loss = 0.5467537448956417, disc_loss = 0.03309417771697454
Trained batch 455 in epoch 0, gen_loss = 0.5467056587599871, disc_loss = 0.03303359585289288
Trained batch 456 in epoch 0, gen_loss = 0.5463368065769354, disc_loss = 0.032976132514428026
Trained batch 457 in epoch 0, gen_loss = 0.5461450077300509, disc_loss = 0.032917352141629434
Trained batch 458 in epoch 0, gen_loss = 0.5457346141987637, disc_loss = 0.03285155375944633
Trained batch 459 in epoch 0, gen_loss = 0.5455883150515349, disc_loss = 0.032784818705556024
Trained batch 460 in epoch 0, gen_loss = 0.5456806008831281, disc_loss = 0.0327200754500174
Trained batch 461 in epoch 0, gen_loss = 0.5452134318294979, disc_loss = 0.032670722395943645
Trained batch 462 in epoch 0, gen_loss = 0.5451294055639024, disc_loss = 0.03261494616169249
Trained batch 463 in epoch 0, gen_loss = 0.5446615391892606, disc_loss = 0.03255112021699837
Trained batch 464 in epoch 0, gen_loss = 0.544544183438824, disc_loss = 0.032491815528802336
Trained batch 465 in epoch 0, gen_loss = 0.5442788364293749, disc_loss = 0.032437971048656644
Trained batch 466 in epoch 0, gen_loss = 0.5442921879204744, disc_loss = 0.03237809218382523
Trained batch 467 in epoch 0, gen_loss = 0.544245694947039, disc_loss = 0.03231532375017802
Trained batch 468 in epoch 0, gen_loss = 0.5440490966412559, disc_loss = 0.032252302602815155
Trained batch 469 in epoch 0, gen_loss = 0.5438299288140966, disc_loss = 0.03219154332913062
Trained batch 470 in epoch 0, gen_loss = 0.5436828951420551, disc_loss = 0.03213370262621457
Trained batch 471 in epoch 0, gen_loss = 0.5434920032019332, disc_loss = 0.03207453895188568
Trained batch 472 in epoch 0, gen_loss = 0.5431555760965286, disc_loss = 0.03201236033193909
Trained batch 473 in epoch 0, gen_loss = 0.5430854381011005, disc_loss = 0.031948985909170745
Trained batch 474 in epoch 0, gen_loss = 0.5431008867841017, disc_loss = 0.03188619856183466
Trained batch 475 in epoch 0, gen_loss = 0.5430432862970007, disc_loss = 0.03182301055170408
Trained batch 476 in epoch 0, gen_loss = 0.5430308079944467, disc_loss = 0.03176033018211555
Trained batch 477 in epoch 0, gen_loss = 0.5428763652945163, disc_loss = 0.03169787088413937
Trained batch 478 in epoch 0, gen_loss = 0.5424169254078994, disc_loss = 0.03163583557503512
Trained batch 479 in epoch 0, gen_loss = 0.542200187407434, disc_loss = 0.03157572794370935
Trained batch 480 in epoch 0, gen_loss = 0.5420606920724104, disc_loss = 0.031515875418589155
Trained batch 481 in epoch 0, gen_loss = 0.5422003768786355, disc_loss = 0.031456778185583144
Trained batch 482 in epoch 0, gen_loss = 0.5419276443697651, disc_loss = 0.03139810539144776
Trained batch 483 in epoch 0, gen_loss = 0.5418169713956266, disc_loss = 0.031339996383469626
Trained batch 484 in epoch 0, gen_loss = 0.5419689713065157, disc_loss = 0.03128466283417662
Trained batch 485 in epoch 0, gen_loss = 0.5417354177422975, disc_loss = 0.031229289416022554
Trained batch 486 in epoch 0, gen_loss = 0.541554481709028, disc_loss = 0.031172124657242558
Trained batch 487 in epoch 0, gen_loss = 0.5417185909435397, disc_loss = 0.031115523568348822
Trained batch 488 in epoch 0, gen_loss = 0.5415296331505103, disc_loss = 0.03105733148560332
Trained batch 489 in epoch 0, gen_loss = 0.5413430704146015, disc_loss = 0.030997678597828336
Trained batch 490 in epoch 0, gen_loss = 0.54150950192434, disc_loss = 0.030941584557456072
Trained batch 491 in epoch 0, gen_loss = 0.5413914935860208, disc_loss = 0.030883697757158594
Trained batch 492 in epoch 0, gen_loss = 0.5413264258638115, disc_loss = 0.030825866440369637
Trained batch 493 in epoch 0, gen_loss = 0.541305477078627, disc_loss = 0.030767097949712097
Trained batch 494 in epoch 0, gen_loss = 0.5410751316282484, disc_loss = 0.03070821412392149
Trained batch 495 in epoch 0, gen_loss = 0.5407988013279054, disc_loss = 0.03064971795468028
Trained batch 496 in epoch 0, gen_loss = 0.5406314160982129, disc_loss = 0.03059190916650792
Trained batch 497 in epoch 0, gen_loss = 0.5404718453625599, disc_loss = 0.03053371807519182
Trained batch 498 in epoch 0, gen_loss = 0.5403600767523588, disc_loss = 0.03047544408271384
Trained batch 499 in epoch 0, gen_loss = 0.5402124148607254, disc_loss = 0.030418659704970197
Trained batch 500 in epoch 0, gen_loss = 0.5402132213234664, disc_loss = 0.030362402579929317
Trained batch 501 in epoch 0, gen_loss = 0.5400749120816767, disc_loss = 0.030305661666912002
Trained batch 502 in epoch 0, gen_loss = 0.5402144275413119, disc_loss = 0.03025048520466013
Trained batch 503 in epoch 0, gen_loss = 0.5399983400508525, disc_loss = 0.030193722858149113
Trained batch 504 in epoch 0, gen_loss = 0.5400236823181115, disc_loss = 0.03013770407974019
Trained batch 505 in epoch 0, gen_loss = 0.5400199271120102, disc_loss = 0.030082646281809983
Trained batch 506 in epoch 0, gen_loss = 0.539615073735427, disc_loss = 0.03002795183602206
Trained batch 507 in epoch 0, gen_loss = 0.5394124770023692, disc_loss = 0.02997639229751236
Trained batch 508 in epoch 0, gen_loss = 0.5395106398052223, disc_loss = 0.029927375948482902
Trained batch 509 in epoch 0, gen_loss = 0.5393118936641543, disc_loss = 0.029877870754274886
Trained batch 510 in epoch 0, gen_loss = 0.5392519903976156, disc_loss = 0.029826125178127067
Trained batch 511 in epoch 0, gen_loss = 0.5392000208375975, disc_loss = 0.02977235068487971
Trained batch 512 in epoch 0, gen_loss = 0.5392666892466257, disc_loss = 0.029718838197534965
Trained batch 513 in epoch 0, gen_loss = 0.5390689008314786, disc_loss = 0.029666342337911128
Trained batch 514 in epoch 0, gen_loss = 0.5388790488243103, disc_loss = 0.029613931539233376
Trained batch 515 in epoch 0, gen_loss = 0.5387106809851735, disc_loss = 0.02956058886628634
Trained batch 516 in epoch 0, gen_loss = 0.5384799073697059, disc_loss = 0.02950782329677217
Trained batch 517 in epoch 0, gen_loss = 0.5382765707016912, disc_loss = 0.029456064048174652
Trained batch 518 in epoch 0, gen_loss = 0.5383524015574557, disc_loss = 0.029404253014076235
Trained batch 519 in epoch 0, gen_loss = 0.5381433809605929, disc_loss = 0.029351129585903926
Trained batch 520 in epoch 0, gen_loss = 0.5379478772977034, disc_loss = 0.029299523182447478
Trained batch 521 in epoch 0, gen_loss = 0.5378964960689289, disc_loss = 0.029247376023857744
Trained batch 522 in epoch 0, gen_loss = 0.5377688577138671, disc_loss = 0.029194559479919377
Trained batch 523 in epoch 0, gen_loss = 0.5375436109327177, disc_loss = 0.02914203096932966
Trained batch 524 in epoch 0, gen_loss = 0.537566500561578, disc_loss = 0.029093079554094445
Trained batch 525 in epoch 0, gen_loss = 0.5372565049295643, disc_loss = 0.029045471121705784
Trained batch 526 in epoch 0, gen_loss = 0.5371104066014516, disc_loss = 0.02899701065477514
Trained batch 527 in epoch 0, gen_loss = 0.5371360077776692, disc_loss = 0.028946597824070715
Trained batch 528 in epoch 0, gen_loss = 0.536876619988894, disc_loss = 0.02889593766204703
Trained batch 529 in epoch 0, gen_loss = 0.5369014362119279, disc_loss = 0.02884691454391083
Trained batch 530 in epoch 0, gen_loss = 0.5368449454478176, disc_loss = 0.028798899101619584
Trained batch 531 in epoch 0, gen_loss = 0.5367304913531569, disc_loss = 0.028749586901841054
Trained batch 532 in epoch 0, gen_loss = 0.5365623440908, disc_loss = 0.028699187860224837
Trained batch 533 in epoch 0, gen_loss = 0.5365955109118522, disc_loss = 0.028649762939933814
Trained batch 534 in epoch 0, gen_loss = 0.5362611660333437, disc_loss = 0.02859917226830654
Trained batch 535 in epoch 0, gen_loss = 0.5361219117445732, disc_loss = 0.028548788352706123
Trained batch 536 in epoch 0, gen_loss = 0.5359218047317846, disc_loss = 0.028499765998425457
Trained batch 537 in epoch 0, gen_loss = 0.5357927085630956, disc_loss = 0.02845146325996776
Trained batch 538 in epoch 0, gen_loss = 0.5356402341310965, disc_loss = 0.028402617421512646
Trained batch 539 in epoch 0, gen_loss = 0.5356018136496897, disc_loss = 0.028354132137502784
Trained batch 540 in epoch 0, gen_loss = 0.5355573519651198, disc_loss = 0.028309455453013648
Trained batch 541 in epoch 0, gen_loss = 0.5354361547865111, disc_loss = 0.02826239938703383
Trained batch 542 in epoch 0, gen_loss = 0.5353159051573737, disc_loss = 0.028213697832084602
Trained batch 543 in epoch 0, gen_loss = 0.5353848047773627, disc_loss = 0.028164931114802397
Trained batch 544 in epoch 0, gen_loss = 0.5355225998327273, disc_loss = 0.02811771131851155
Trained batch 545 in epoch 0, gen_loss = 0.5352973075576755, disc_loss = 0.02806950481791875
Trained batch 546 in epoch 0, gen_loss = 0.5351275670354065, disc_loss = 0.0280217337703002
Trained batch 547 in epoch 0, gen_loss = 0.5349451308920435, disc_loss = 0.027973514671197814
Trained batch 548 in epoch 0, gen_loss = 0.5347568110472952, disc_loss = 0.02792596183517924
Trained batch 549 in epoch 0, gen_loss = 0.5346911777691408, disc_loss = 0.027878195623316886
Trained batch 550 in epoch 0, gen_loss = 0.5346931915209644, disc_loss = 0.02783054036925802
Trained batch 551 in epoch 0, gen_loss = 0.5346167033565217, disc_loss = 0.027783206652215533
Trained batch 552 in epoch 0, gen_loss = 0.5344236792211722, disc_loss = 0.02773579089396261
Trained batch 553 in epoch 0, gen_loss = 0.5340433952395236, disc_loss = 0.027694855984981216
Trained batch 554 in epoch 0, gen_loss = 0.5340753587516578, disc_loss = 0.027653588966449705
Trained batch 555 in epoch 0, gen_loss = 0.5338775290430878, disc_loss = 0.027607911669024394
Trained batch 556 in epoch 0, gen_loss = 0.5336784343745165, disc_loss = 0.02756174817502405
Trained batch 557 in epoch 0, gen_loss = 0.5334836990709373, disc_loss = 0.02751533853309062
Trained batch 558 in epoch 0, gen_loss = 0.5333068142103594, disc_loss = 0.027469264797379857
Trained batch 559 in epoch 0, gen_loss = 0.5330829065825258, disc_loss = 0.027423318718501833
Trained batch 560 in epoch 0, gen_loss = 0.5331239685442783, disc_loss = 0.027378977513573266
Trained batch 561 in epoch 0, gen_loss = 0.5330901603045413, disc_loss = 0.027334408016562183
Trained batch 562 in epoch 0, gen_loss = 0.5328324015250638, disc_loss = 0.027288298059104352
Trained batch 563 in epoch 0, gen_loss = 0.532972496187856, disc_loss = 0.027245209812630854
Trained batch 564 in epoch 0, gen_loss = 0.5327659316822491, disc_loss = 0.027202250886980476
Trained batch 565 in epoch 0, gen_loss = 0.5324779978489286, disc_loss = 0.02715865436422247
Trained batch 566 in epoch 0, gen_loss = 0.5322769573336136, disc_loss = 0.027113682805803625
Trained batch 567 in epoch 0, gen_loss = 0.532186640872502, disc_loss = 0.027068999175574225
Trained batch 568 in epoch 0, gen_loss = 0.5322275219881262, disc_loss = 0.02702477895932989
Trained batch 569 in epoch 0, gen_loss = 0.5322360510888853, disc_loss = 0.026980696037910028
Trained batch 570 in epoch 0, gen_loss = 0.5321415453470735, disc_loss = 0.02693624156930903
Trained batch 571 in epoch 0, gen_loss = 0.5320611105306999, disc_loss = 0.02689268051095509
Trained batch 572 in epoch 0, gen_loss = 0.5318963471507527, disc_loss = 0.026849144714986856
Trained batch 573 in epoch 0, gen_loss = 0.5316756238920763, disc_loss = 0.026805120407934674
Trained batch 574 in epoch 0, gen_loss = 0.5317788061888321, disc_loss = 0.026763224359601736
Trained batch 575 in epoch 0, gen_loss = 0.5317518967721198, disc_loss = 0.02672155371894607
Trained batch 576 in epoch 0, gen_loss = 0.5315243978847457, disc_loss = 0.026679139206205307
Trained batch 577 in epoch 0, gen_loss = 0.531381144191567, disc_loss = 0.026637098284689614
Trained batch 578 in epoch 0, gen_loss = 0.5311977229175996, disc_loss = 0.026594863022277083
Trained batch 579 in epoch 0, gen_loss = 0.5311008614712748, disc_loss = 0.026551718046037672
Trained batch 580 in epoch 0, gen_loss = 0.5308807576892708, disc_loss = 0.026507810215231693
Trained batch 581 in epoch 0, gen_loss = 0.5312853228697663, disc_loss = 0.026469963083653375
Trained batch 582 in epoch 0, gen_loss = 0.53117789903186, disc_loss = 0.026427878590067448
Trained batch 583 in epoch 0, gen_loss = 0.5308531538060267, disc_loss = 0.02638590714454887
Trained batch 584 in epoch 0, gen_loss = 0.5306570833564823, disc_loss = 0.026344405881797848
Trained batch 585 in epoch 0, gen_loss = 0.5302520633354122, disc_loss = 0.026307419010592185
Trained batch 586 in epoch 0, gen_loss = 0.5303325370791824, disc_loss = 0.02626732737758059
Trained batch 587 in epoch 0, gen_loss = 0.5302224540892913, disc_loss = 0.026227092349998413
Trained batch 588 in epoch 0, gen_loss = 0.5302756624533487, disc_loss = 0.026187977753777264
Trained batch 589 in epoch 0, gen_loss = 0.5301648429389727, disc_loss = 0.02614726205257762
Trained batch 590 in epoch 0, gen_loss = 0.530218414092427, disc_loss = 0.026105508554960064
Trained batch 591 in epoch 0, gen_loss = 0.5301820672545079, disc_loss = 0.026063936676380125
Trained batch 592 in epoch 0, gen_loss = 0.5300892184395815, disc_loss = 0.026022719427814447
Trained batch 593 in epoch 0, gen_loss = 0.529989609714309, disc_loss = 0.025981226686297317
Trained batch 594 in epoch 0, gen_loss = 0.5297618249384295, disc_loss = 0.02593992139572794
Trained batch 595 in epoch 0, gen_loss = 0.5299797074606755, disc_loss = 0.025903169617710022
Trained batch 596 in epoch 0, gen_loss = 0.5297313410932295, disc_loss = 0.025863375758496385
Trained batch 597 in epoch 0, gen_loss = 0.5295349137739195, disc_loss = 0.025823459710168924
Trained batch 598 in epoch 0, gen_loss = 0.5295136496797825, disc_loss = 0.025783297944952342
Trained batch 599 in epoch 0, gen_loss = 0.5293902191023032, disc_loss = 0.025742513403917353
Trained batch 600 in epoch 0, gen_loss = 0.5292560851911142, disc_loss = 0.025702460465012133
Trained batch 601 in epoch 0, gen_loss = 0.529276480211372, disc_loss = 0.02566412988678085
Trained batch 602 in epoch 0, gen_loss = 0.5292271502674318, disc_loss = 0.025624908336784203
Trained batch 603 in epoch 0, gen_loss = 0.5292549108136568, disc_loss = 0.025585664202234036
Trained batch 604 in epoch 0, gen_loss = 0.5289126448394839, disc_loss = 0.02554554257961375
Trained batch 605 in epoch 0, gen_loss = 0.5287609066900247, disc_loss = 0.025505521225976595
Trained batch 606 in epoch 0, gen_loss = 0.5286156306353197, disc_loss = 0.02546616980638754
Trained batch 607 in epoch 0, gen_loss = 0.5284866600444442, disc_loss = 0.025427328830885113
Trained batch 608 in epoch 0, gen_loss = 0.5283811840615641, disc_loss = 0.02538888708937589
Trained batch 609 in epoch 0, gen_loss = 0.5282013194482834, disc_loss = 0.02534989611280044
Trained batch 610 in epoch 0, gen_loss = 0.528158378484011, disc_loss = 0.02531231246464131
Trained batch 611 in epoch 0, gen_loss = 0.5280892312818882, disc_loss = 0.02527662989469641
Trained batch 612 in epoch 0, gen_loss = 0.5281181319405555, disc_loss = 0.02524422382123823
Trained batch 613 in epoch 0, gen_loss = 0.5279883407905747, disc_loss = 0.025208753229350955
Trained batch 614 in epoch 0, gen_loss = 0.527822029057557, disc_loss = 0.025171199284410636
Trained batch 615 in epoch 0, gen_loss = 0.5277945851641042, disc_loss = 0.025133530459821817
Trained batch 616 in epoch 0, gen_loss = 0.5278050764743087, disc_loss = 0.02509601129052143
Trained batch 617 in epoch 0, gen_loss = 0.5277753831595665, disc_loss = 0.025058153125157575
Trained batch 618 in epoch 0, gen_loss = 0.5277521479784576, disc_loss = 0.025019926514201204
Trained batch 619 in epoch 0, gen_loss = 0.5278158983395945, disc_loss = 0.024982414444375243
Trained batch 620 in epoch 0, gen_loss = 0.5277267843724833, disc_loss = 0.024945623080333133
Trained batch 621 in epoch 0, gen_loss = 0.5276424343850452, disc_loss = 0.02490866627642238
Trained batch 622 in epoch 0, gen_loss = 0.52780455527872, disc_loss = 0.024872353434432625
Trained batch 623 in epoch 0, gen_loss = 0.5275851985773979, disc_loss = 0.024834585740627985
Trained batch 624 in epoch 0, gen_loss = 0.5274682752132416, disc_loss = 0.024797434996813535
Trained batch 625 in epoch 0, gen_loss = 0.5272909153859836, disc_loss = 0.024760747104124448
Trained batch 626 in epoch 0, gen_loss = 0.5271483654991101, disc_loss = 0.024723946436589057
Trained batch 627 in epoch 0, gen_loss = 0.5270776944175647, disc_loss = 0.02468703593002116
Trained batch 628 in epoch 0, gen_loss = 0.5268252404770905, disc_loss = 0.024649778788721276
Trained batch 629 in epoch 0, gen_loss = 0.5266753593607555, disc_loss = 0.02461324755623493
Trained batch 630 in epoch 0, gen_loss = 0.5267796208004566, disc_loss = 0.024578337423487164
Trained batch 631 in epoch 0, gen_loss = 0.5265093200097356, disc_loss = 0.024542118877848858
Trained batch 632 in epoch 0, gen_loss = 0.5263786386539586, disc_loss = 0.024508569753540484
Trained batch 633 in epoch 0, gen_loss = 0.5262819466530713, disc_loss = 0.024473995245935846
Trained batch 634 in epoch 0, gen_loss = 0.5261371299507112, disc_loss = 0.02443847635845236
Trained batch 635 in epoch 0, gen_loss = 0.5259053554831061, disc_loss = 0.024402251054346853
Trained batch 636 in epoch 0, gen_loss = 0.5259021506111139, disc_loss = 0.024366178932516386
Trained batch 637 in epoch 0, gen_loss = 0.5257488165903241, disc_loss = 0.024330432317292663
Trained batch 638 in epoch 0, gen_loss = 0.5256473538647981, disc_loss = 0.024295184630113587
Trained batch 639 in epoch 0, gen_loss = 0.5255408144555986, disc_loss = 0.024260070868695038
Trained batch 640 in epoch 0, gen_loss = 0.5252982191567116, disc_loss = 0.024223826228104844
Trained batch 641 in epoch 0, gen_loss = 0.5252587140256371, disc_loss = 0.024189506372004586
Trained batch 642 in epoch 0, gen_loss = 0.5249749195427398, disc_loss = 0.024156828852686132
Trained batch 643 in epoch 0, gen_loss = 0.5248204697825893, disc_loss = 0.02412359046848109
Trained batch 644 in epoch 0, gen_loss = 0.524749309979668, disc_loss = 0.02408856202147959
Trained batch 645 in epoch 0, gen_loss = 0.5244967087226755, disc_loss = 0.02405386467607715
Trained batch 646 in epoch 0, gen_loss = 0.5245000195374261, disc_loss = 0.02401952046042357
Trained batch 647 in epoch 0, gen_loss = 0.5244825778092131, disc_loss = 0.023984550877674024
Trained batch 648 in epoch 0, gen_loss = 0.5245773174637822, disc_loss = 0.02394972673333171
Trained batch 649 in epoch 0, gen_loss = 0.5244669432364978, disc_loss = 0.023914458275987552
Trained batch 650 in epoch 0, gen_loss = 0.5242854290385767, disc_loss = 0.023879827089255786
Trained batch 651 in epoch 0, gen_loss = 0.5242457419542447, disc_loss = 0.023844766649996085
Trained batch 652 in epoch 0, gen_loss = 0.5241357345493428, disc_loss = 0.02381062405904153
Trained batch 653 in epoch 0, gen_loss = 0.5242075327704077, disc_loss = 0.02377793951022698
Trained batch 654 in epoch 0, gen_loss = 0.5241949244309928, disc_loss = 0.023745505347890595
Trained batch 655 in epoch 0, gen_loss = 0.5242676193394312, disc_loss = 0.023712195561263177
Trained batch 656 in epoch 0, gen_loss = 0.5241873021176598, disc_loss = 0.02367802396720726
Trained batch 657 in epoch 0, gen_loss = 0.5239668307786293, disc_loss = 0.023644198966955646
Trained batch 658 in epoch 0, gen_loss = 0.5239505977207323, disc_loss = 0.02361039530251978
Trained batch 659 in epoch 0, gen_loss = 0.5240762040019036, disc_loss = 0.023577459461133307
Trained batch 660 in epoch 0, gen_loss = 0.5238946049999722, disc_loss = 0.02354354483555191
Trained batch 661 in epoch 0, gen_loss = 0.5239670182552942, disc_loss = 0.02351041071330059
Trained batch 662 in epoch 0, gen_loss = 0.52373963616912, disc_loss = 0.02347628825830877
Trained batch 663 in epoch 0, gen_loss = 0.5236911128263876, disc_loss = 0.023442483615271847
Trained batch 664 in epoch 0, gen_loss = 0.5237739106766264, disc_loss = 0.023410264846406653
Trained batch 665 in epoch 0, gen_loss = 0.5235851437927367, disc_loss = 0.02337703931613129
Trained batch 666 in epoch 0, gen_loss = 0.5236641035891365, disc_loss = 0.023345055693733983
Trained batch 667 in epoch 0, gen_loss = 0.523576065451799, disc_loss = 0.02331278071383957
Trained batch 668 in epoch 0, gen_loss = 0.5234475468128074, disc_loss = 0.023280768783836833
Trained batch 669 in epoch 0, gen_loss = 0.5233028452787827, disc_loss = 0.02324868515602994
Trained batch 670 in epoch 0, gen_loss = 0.5231435985572291, disc_loss = 0.02321736940828842
Trained batch 671 in epoch 0, gen_loss = 0.5231260102064836, disc_loss = 0.023185316801703135
Trained batch 672 in epoch 0, gen_loss = 0.5230307108757223, disc_loss = 0.023152675197347667
Trained batch 673 in epoch 0, gen_loss = 0.5230373481084049, disc_loss = 0.023120035927947223
Trained batch 674 in epoch 0, gen_loss = 0.5229339983728197, disc_loss = 0.02308879690348274
Trained batch 675 in epoch 0, gen_loss = 0.5228139134289245, disc_loss = 0.023058506472452306
Trained batch 676 in epoch 0, gen_loss = 0.5228006768878136, disc_loss = 0.023027797990672543
Trained batch 677 in epoch 0, gen_loss = 0.5225249458554924, disc_loss = 0.022995773402206147
Trained batch 678 in epoch 0, gen_loss = 0.5225751148934568, disc_loss = 0.022964627688595633
Trained batch 679 in epoch 0, gen_loss = 0.5225333148065735, disc_loss = 0.022934092987527358
Trained batch 680 in epoch 0, gen_loss = 0.5224760239957538, disc_loss = 0.02290250084457971
Trained batch 681 in epoch 0, gen_loss = 0.5222979681320554, disc_loss = 0.022871122565775934
Trained batch 682 in epoch 0, gen_loss = 0.5221146378300724, disc_loss = 0.022839663211408987
Trained batch 683 in epoch 0, gen_loss = 0.5220307762249868, disc_loss = 0.02280826210326853
Trained batch 684 in epoch 0, gen_loss = 0.5220650020742068, disc_loss = 0.022778047680562484
Trained batch 685 in epoch 0, gen_loss = 0.5219382923910986, disc_loss = 0.022746498500500634
Trained batch 686 in epoch 0, gen_loss = 0.5219944763652102, disc_loss = 0.02271574722678201
Trained batch 687 in epoch 0, gen_loss = 0.5218759672499673, disc_loss = 0.022685858914946736
Trained batch 688 in epoch 0, gen_loss = 0.5216184346700096, disc_loss = 0.022656176618911346
Trained batch 689 in epoch 0, gen_loss = 0.5215140929256661, disc_loss = 0.02262578026553535
Trained batch 690 in epoch 0, gen_loss = 0.5214927481155837, disc_loss = 0.022595185057668478
Trained batch 691 in epoch 0, gen_loss = 0.5212913506551285, disc_loss = 0.022564650304962724
Trained batch 692 in epoch 0, gen_loss = 0.5211670519125582, disc_loss = 0.022534575650984528
Trained batch 693 in epoch 0, gen_loss = 0.5212034583950592, disc_loss = 0.022504523573463425
Trained batch 694 in epoch 0, gen_loss = 0.521240163621285, disc_loss = 0.022474791432342243
Trained batch 695 in epoch 0, gen_loss = 0.5211538772216473, disc_loss = 0.022444407163748528
Trained batch 696 in epoch 0, gen_loss = 0.521206722497256, disc_loss = 0.0224150691678817
Trained batch 697 in epoch 0, gen_loss = 0.5212510036448694, disc_loss = 0.0223866281422178
Trained batch 698 in epoch 0, gen_loss = 0.5210878021045133, disc_loss = 0.022356875048442682
Trained batch 699 in epoch 0, gen_loss = 0.5208456566504069, disc_loss = 0.022327287324005737
Trained batch 700 in epoch 0, gen_loss = 0.5207261231418343, disc_loss = 0.022297205732432532
Trained batch 701 in epoch 0, gen_loss = 0.5207156544057732, disc_loss = 0.022267456340405858
Trained batch 702 in epoch 0, gen_loss = 0.520741158749267, disc_loss = 0.02223800672671942
Trained batch 703 in epoch 0, gen_loss = 0.520826887762682, disc_loss = 0.022209494603389016
Trained batch 704 in epoch 0, gen_loss = 0.5205904061067189, disc_loss = 0.022179450301275133
Trained batch 705 in epoch 0, gen_loss = 0.5204984845419444, disc_loss = 0.0221516695198413
Trained batch 706 in epoch 0, gen_loss = 0.5204274967586808, disc_loss = 0.022125940150291498
Trained batch 707 in epoch 0, gen_loss = 0.5202831828829932, disc_loss = 0.022099805356688682
Trained batch 708 in epoch 0, gen_loss = 0.5202215459770477, disc_loss = 0.022071751201563423
Trained batch 709 in epoch 0, gen_loss = 0.520270905906046, disc_loss = 0.022043248019541915
Trained batch 710 in epoch 0, gen_loss = 0.5202161370031274, disc_loss = 0.02201445483007899
Trained batch 711 in epoch 0, gen_loss = 0.5201451623121675, disc_loss = 0.021984985932116553
Trained batch 712 in epoch 0, gen_loss = 0.5200823419224497, disc_loss = 0.02195559498373299
Trained batch 713 in epoch 0, gen_loss = 0.51988910155303, disc_loss = 0.021926815089696617
Trained batch 714 in epoch 0, gen_loss = 0.519832111113555, disc_loss = 0.021899563524142636
Trained batch 715 in epoch 0, gen_loss = 0.5196715287406352, disc_loss = 0.021873890139701042
Trained batch 716 in epoch 0, gen_loss = 0.5194629041303983, disc_loss = 0.02185040106574746
Trained batch 717 in epoch 0, gen_loss = 0.5195237208458706, disc_loss = 0.021825639385416127
Trained batch 718 in epoch 0, gen_loss = 0.5193095994343844, disc_loss = 0.021798139653377163
Trained batch 719 in epoch 0, gen_loss = 0.5190897774779134, disc_loss = 0.02177286893743763
Trained batch 720 in epoch 0, gen_loss = 0.519018221786052, disc_loss = 0.021748104813119885
Trained batch 721 in epoch 0, gen_loss = 0.5190566924717948, disc_loss = 0.021721662143748408
Trained batch 722 in epoch 0, gen_loss = 0.5189252470209061, disc_loss = 0.02169464730314993
Trained batch 723 in epoch 0, gen_loss = 0.5188687072439089, disc_loss = 0.02166724016565768
Trained batch 724 in epoch 0, gen_loss = 0.5188599468921793, disc_loss = 0.021639543367100174
Trained batch 725 in epoch 0, gen_loss = 0.5187225895972292, disc_loss = 0.02161133080960146
Trained batch 726 in epoch 0, gen_loss = 0.5187620523871221, disc_loss = 0.0215842522768191
Trained batch 727 in epoch 0, gen_loss = 0.518783437190475, disc_loss = 0.02155757415991732
Trained batch 728 in epoch 0, gen_loss = 0.5188286330637781, disc_loss = 0.021530480301473927
Trained batch 729 in epoch 0, gen_loss = 0.5187451944775777, disc_loss = 0.021503062727414583
Trained batch 730 in epoch 0, gen_loss = 0.5187326029615754, disc_loss = 0.02147539552217082
Trained batch 731 in epoch 0, gen_loss = 0.518623223477374, disc_loss = 0.021447530177725948
Trained batch 732 in epoch 0, gen_loss = 0.5184811037364143, disc_loss = 0.021419596484935962
Trained batch 733 in epoch 0, gen_loss = 0.5185115422637326, disc_loss = 0.021391877649340536
Trained batch 734 in epoch 0, gen_loss = 0.5183917825724803, disc_loss = 0.02136448784873878
Trained batch 735 in epoch 0, gen_loss = 0.5183998231330643, disc_loss = 0.02133781310571383
Trained batch 736 in epoch 0, gen_loss = 0.5181572662118008, disc_loss = 0.02131111042452736
Trained batch 737 in epoch 0, gen_loss = 0.5181825029333109, disc_loss = 0.021285940606530687
Trained batch 738 in epoch 0, gen_loss = 0.5180239038635172, disc_loss = 0.021261323721013227
Trained batch 739 in epoch 0, gen_loss = 0.5178476289720149, disc_loss = 0.021236763941753355
Trained batch 740 in epoch 0, gen_loss = 0.5178563570284489, disc_loss = 0.02121218093406967
Trained batch 741 in epoch 0, gen_loss = 0.5178355033587253, disc_loss = 0.021187411205130166
Trained batch 742 in epoch 0, gen_loss = 0.5178952310560209, disc_loss = 0.021161130385681445
Trained batch 743 in epoch 0, gen_loss = 0.5177648526926836, disc_loss = 0.02113394897026811
Trained batch 744 in epoch 0, gen_loss = 0.5176544506677845, disc_loss = 0.021106997539833087
Trained batch 745 in epoch 0, gen_loss = 0.5176601207368176, disc_loss = 0.021080044748314004
Trained batch 746 in epoch 0, gen_loss = 0.5175609804460483, disc_loss = 0.02105321381549654
Trained batch 747 in epoch 0, gen_loss = 0.5176505954428152, disc_loss = 0.02102666435296956
Trained batch 748 in epoch 0, gen_loss = 0.5175164835714052, disc_loss = 0.021000005949993628
Trained batch 749 in epoch 0, gen_loss = 0.51738330300649, disc_loss = 0.020973586971871554
Trained batch 750 in epoch 0, gen_loss = 0.5172515030548512, disc_loss = 0.020947923964247873
Trained batch 751 in epoch 0, gen_loss = 0.5173013464726032, disc_loss = 0.020922786043306683
Trained batch 752 in epoch 0, gen_loss = 0.5171981063655331, disc_loss = 0.020897147177216434
Trained batch 753 in epoch 0, gen_loss = 0.5171368609056549, disc_loss = 0.020870976557643882
Trained batch 754 in epoch 0, gen_loss = 0.5171356815376029, disc_loss = 0.02084502292294302
Trained batch 755 in epoch 0, gen_loss = 0.5171506298439843, disc_loss = 0.02081901347957596
Trained batch 756 in epoch 0, gen_loss = 0.5170805984948081, disc_loss = 0.020793952519176196
Trained batch 757 in epoch 0, gen_loss = 0.5169530073696831, disc_loss = 0.020768991773020436
Trained batch 758 in epoch 0, gen_loss = 0.5168896987347107, disc_loss = 0.020743820913828055
Trained batch 759 in epoch 0, gen_loss = 0.5167449317480388, disc_loss = 0.020718298452495794
Trained batch 760 in epoch 0, gen_loss = 0.5166305656423706, disc_loss = 0.020692249325424697
Trained batch 761 in epoch 0, gen_loss = 0.5165508113351707, disc_loss = 0.02066620940426878
Trained batch 762 in epoch 0, gen_loss = 0.5163932270803739, disc_loss = 0.020640433155034388
Trained batch 763 in epoch 0, gen_loss = 0.5162972666284177, disc_loss = 0.02061489256265261
Trained batch 764 in epoch 0, gen_loss = 0.5162879354423947, disc_loss = 0.020589639985891292
Trained batch 765 in epoch 0, gen_loss = 0.516369110415872, disc_loss = 0.020565107348223043
Trained batch 766 in epoch 0, gen_loss = 0.5161808696921522, disc_loss = 0.020540018336764856
Trained batch 767 in epoch 0, gen_loss = 0.5160738732277727, disc_loss = 0.020515054824196948
Trained batch 768 in epoch 0, gen_loss = 0.5161450995502919, disc_loss = 0.02049025856500421
Trained batch 769 in epoch 0, gen_loss = 0.5160916263406927, disc_loss = 0.020465548190608765
Trained batch 770 in epoch 0, gen_loss = 0.5161199539551939, disc_loss = 0.0204411643587751
Trained batch 771 in epoch 0, gen_loss = 0.5159420768677262, disc_loss = 0.020417143744259705
Trained batch 772 in epoch 0, gen_loss = 0.5158623051365782, disc_loss = 0.020394018023210985
Trained batch 773 in epoch 0, gen_loss = 0.5159536905066912, disc_loss = 0.020370818231464183
Trained batch 774 in epoch 0, gen_loss = 0.5158654475981189, disc_loss = 0.020345933688353867
Trained batch 775 in epoch 0, gen_loss = 0.5157777353660348, disc_loss = 0.02032073769190639
Trained batch 776 in epoch 0, gen_loss = 0.5158125877073526, disc_loss = 0.02029587956979341
Trained batch 777 in epoch 0, gen_loss = 0.5156486400218733, disc_loss = 0.02027100671213216
Trained batch 778 in epoch 0, gen_loss = 0.5156009946310168, disc_loss = 0.020246041671534945
Trained batch 779 in epoch 0, gen_loss = 0.5153776681958101, disc_loss = 0.020222238716982806
Trained batch 780 in epoch 0, gen_loss = 0.5152911506450131, disc_loss = 0.02019955740924674
Trained batch 781 in epoch 0, gen_loss = 0.5151323200110585, disc_loss = 0.020177204173568594
Trained batch 782 in epoch 0, gen_loss = 0.5150440773364076, disc_loss = 0.02015473134406827
Trained batch 783 in epoch 0, gen_loss = 0.5147741819750897, disc_loss = 0.020132495397811742
Trained batch 784 in epoch 0, gen_loss = 0.5148934777754887, disc_loss = 0.020109414688095
Trained batch 785 in epoch 0, gen_loss = 0.5148932917503304, disc_loss = 0.020086471531460176
Trained batch 786 in epoch 0, gen_loss = 0.5150520476255817, disc_loss = 0.02006341675108564
Trained batch 787 in epoch 0, gen_loss = 0.5149607313465951, disc_loss = 0.020040043012985398
Trained batch 788 in epoch 0, gen_loss = 0.5147502947367341, disc_loss = 0.020016425333994455
Trained batch 789 in epoch 0, gen_loss = 0.5147288160988047, disc_loss = 0.01999326282323786
Trained batch 790 in epoch 0, gen_loss = 0.5147459351006711, disc_loss = 0.019970666648724083
Trained batch 791 in epoch 0, gen_loss = 0.5145729733536942, disc_loss = 0.01994732692783329
Trained batch 792 in epoch 0, gen_loss = 0.5145974742509378, disc_loss = 0.019925033458062857
Trained batch 793 in epoch 0, gen_loss = 0.5146659096932832, disc_loss = 0.019903503241582236
Trained batch 794 in epoch 0, gen_loss = 0.514460050497415, disc_loss = 0.019880735948491466
Trained batch 795 in epoch 0, gen_loss = 0.514380009779379, disc_loss = 0.019857674647060026
Trained batch 796 in epoch 0, gen_loss = 0.514258869768236, disc_loss = 0.01983559093652223
Trained batch 797 in epoch 0, gen_loss = 0.5143627392170125, disc_loss = 0.019813395246590853
Trained batch 798 in epoch 0, gen_loss = 0.5144183715532659, disc_loss = 0.019791858255392866
Trained batch 799 in epoch 0, gen_loss = 0.5144887387007475, disc_loss = 0.019769960452176747
Trained batch 800 in epoch 0, gen_loss = 0.5145656070608027, disc_loss = 0.019747543317651245
Trained batch 801 in epoch 0, gen_loss = 0.5144436982578767, disc_loss = 0.0197246820044482
Trained batch 802 in epoch 0, gen_loss = 0.5145320189028867, disc_loss = 0.019702027144521163
Trained batch 803 in epoch 0, gen_loss = 0.5144147717611707, disc_loss = 0.019679005373983448
Trained batch 804 in epoch 0, gen_loss = 0.514355675959439, disc_loss = 0.019656306646130862
Trained batch 805 in epoch 0, gen_loss = 0.5143798440694809, disc_loss = 0.019633599213008463
Trained batch 806 in epoch 0, gen_loss = 0.5143938946827341, disc_loss = 0.019611184200277156
Trained batch 807 in epoch 0, gen_loss = 0.5144490259930049, disc_loss = 0.019588705152633373
Trained batch 808 in epoch 0, gen_loss = 0.5142485703835529, disc_loss = 0.01956619363649701
Trained batch 809 in epoch 0, gen_loss = 0.5142320977684892, disc_loss = 0.019544595257985624
Trained batch 810 in epoch 0, gen_loss = 0.5141531809264135, disc_loss = 0.019524010118431814
Trained batch 811 in epoch 0, gen_loss = 0.5140256473216517, disc_loss = 0.019502855472256924
Trained batch 812 in epoch 0, gen_loss = 0.513948058913408, disc_loss = 0.019480935405515397
Trained batch 813 in epoch 0, gen_loss = 0.5139139494160763, disc_loss = 0.01945853598436732
Trained batch 814 in epoch 0, gen_loss = 0.5139135208963617, disc_loss = 0.019436756091583747
Trained batch 815 in epoch 0, gen_loss = 0.5140311252325773, disc_loss = 0.019416639310328915
Trained batch 816 in epoch 0, gen_loss = 0.5140204242495603, disc_loss = 0.01939583488837206
Trained batch 817 in epoch 0, gen_loss = 0.5140281765924398, disc_loss = 0.01937453863434414
Trained batch 818 in epoch 0, gen_loss = 0.5140108066964645, disc_loss = 0.019352941518471497
Trained batch 819 in epoch 0, gen_loss = 0.5138944501920444, disc_loss = 0.01933092612712133
Trained batch 820 in epoch 0, gen_loss = 0.5139206034765464, disc_loss = 0.019308755789040025
Trained batch 821 in epoch 0, gen_loss = 0.5139227517837446, disc_loss = 0.019286360590800262
Trained batch 822 in epoch 0, gen_loss = 0.5137527603497627, disc_loss = 0.019264077852247565
Trained batch 823 in epoch 0, gen_loss = 0.5137567175461829, disc_loss = 0.01924242734948899
Trained batch 824 in epoch 0, gen_loss = 0.5137400329835488, disc_loss = 0.019221573575667925
Trained batch 825 in epoch 0, gen_loss = 0.5135782194700426, disc_loss = 0.019199899197305206
Trained batch 826 in epoch 0, gen_loss = 0.5133782046089149, disc_loss = 0.019177854121938582
Trained batch 827 in epoch 0, gen_loss = 0.5133317444059584, disc_loss = 0.019156030653121065
Trained batch 828 in epoch 0, gen_loss = 0.5132570112858807, disc_loss = 0.019134068920022042
Trained batch 829 in epoch 0, gen_loss = 0.5133183079311646, disc_loss = 0.01911305605731231
Trained batch 830 in epoch 0, gen_loss = 0.5133074066555744, disc_loss = 0.019092624752628747
Trained batch 831 in epoch 0, gen_loss = 0.5132928616725482, disc_loss = 0.01907253934908882
Trained batch 832 in epoch 0, gen_loss = 0.513324184935777, disc_loss = 0.019051419284266263
Trained batch 833 in epoch 0, gen_loss = 0.5133242768635281, disc_loss = 0.019030362636613608
Trained batch 834 in epoch 0, gen_loss = 0.513315622321146, disc_loss = 0.01900920990999498
Trained batch 835 in epoch 0, gen_loss = 0.5134050418315321, disc_loss = 0.01898801497726269
Trained batch 836 in epoch 0, gen_loss = 0.513376304218846, disc_loss = 0.01896711084627287
Trained batch 837 in epoch 0, gen_loss = 0.5133394218785666, disc_loss = 0.01894758564799575
Trained batch 838 in epoch 0, gen_loss = 0.5132378179921865, disc_loss = 0.018928180989161072
Trained batch 839 in epoch 0, gen_loss = 0.5132438253788721, disc_loss = 0.01890852561738852
Trained batch 840 in epoch 0, gen_loss = 0.5133881639782228, disc_loss = 0.018889422100851275
Trained batch 841 in epoch 0, gen_loss = 0.5134533955195737, disc_loss = 0.01886906832342662
Trained batch 842 in epoch 0, gen_loss = 0.5133353792758457, disc_loss = 0.01884833678632449
Trained batch 843 in epoch 0, gen_loss = 0.5130857589403035, disc_loss = 0.0188283476305704
Trained batch 844 in epoch 0, gen_loss = 0.5130430900133574, disc_loss = 0.018810160030588816
Trained batch 845 in epoch 0, gen_loss = 0.5130487607162332, disc_loss = 0.018792640740502114
Trained batch 846 in epoch 0, gen_loss = 0.5130986515014766, disc_loss = 0.018773723518065756
Trained batch 847 in epoch 0, gen_loss = 0.512950935770037, disc_loss = 0.01875347544712054
Trained batch 848 in epoch 0, gen_loss = 0.5129323716509048, disc_loss = 0.01873306379649674
Trained batch 849 in epoch 0, gen_loss = 0.5128985818344004, disc_loss = 0.01871241663938717
Trained batch 850 in epoch 0, gen_loss = 0.5128303195068615, disc_loss = 0.018691659515825364
Trained batch 851 in epoch 0, gen_loss = 0.512859503393162, disc_loss = 0.018670840140832742
Trained batch 852 in epoch 0, gen_loss = 0.5129106896913066, disc_loss = 0.01865023475257431
Trained batch 853 in epoch 0, gen_loss = 0.5127828428630806, disc_loss = 0.018629906430856304
Trained batch 854 in epoch 0, gen_loss = 0.5126231346214026, disc_loss = 0.018609654937111038
Trained batch 855 in epoch 0, gen_loss = 0.51256009337501, disc_loss = 0.018589637640939273
Trained batch 856 in epoch 0, gen_loss = 0.512472212175505, disc_loss = 0.018569130780239987
Trained batch 857 in epoch 0, gen_loss = 0.5123594097949408, disc_loss = 0.018548551283188986
Trained batch 858 in epoch 0, gen_loss = 0.5123068887363074, disc_loss = 0.018527904376254782
Trained batch 859 in epoch 0, gen_loss = 0.5121610108503075, disc_loss = 0.018507828625923477
Trained batch 860 in epoch 0, gen_loss = 0.5121893282551383, disc_loss = 0.018488210757572905
Trained batch 861 in epoch 0, gen_loss = 0.512125202992676, disc_loss = 0.01846809237416166
Trained batch 862 in epoch 0, gen_loss = 0.5121069852336119, disc_loss = 0.018447700999544982
Trained batch 863 in epoch 0, gen_loss = 0.5120448971995049, disc_loss = 0.018427432121555926
Trained batch 864 in epoch 0, gen_loss = 0.5120042238276817, disc_loss = 0.018407497319495144
Trained batch 865 in epoch 0, gen_loss = 0.5120233743006307, disc_loss = 0.01838754122220754
Trained batch 866 in epoch 0, gen_loss = 0.5120260664267249, disc_loss = 0.018368043044540115
Trained batch 867 in epoch 0, gen_loss = 0.5119626419747481, disc_loss = 0.01834994196220653
Trained batch 868 in epoch 0, gen_loss = 0.5119127025881351, disc_loss = 0.018332739976466225
Trained batch 869 in epoch 0, gen_loss = 0.5117808812993696, disc_loss = 0.01831470766471399
Trained batch 870 in epoch 0, gen_loss = 0.5117564215725791, disc_loss = 0.01829704889842126
Trained batch 871 in epoch 0, gen_loss = 0.5116667543802786, disc_loss = 0.018279901845727774
Trained batch 872 in epoch 0, gen_loss = 0.5115123154234913, disc_loss = 0.01826322429084282
Trained batch 873 in epoch 0, gen_loss = 0.5114702271378558, disc_loss = 0.018246615053664945
Trained batch 874 in epoch 0, gen_loss = 0.5114290273530142, disc_loss = 0.018228991991840304
Trained batch 875 in epoch 0, gen_loss = 0.5114249952443658, disc_loss = 0.018210128643023717
Trained batch 876 in epoch 0, gen_loss = 0.5114464737398459, disc_loss = 0.01819077619811267
Trained batch 877 in epoch 0, gen_loss = 0.5114363588070272, disc_loss = 0.01817116261122309
Trained batch 878 in epoch 0, gen_loss = 0.5112946804473018, disc_loss = 0.018151685601141117
Trained batch 879 in epoch 0, gen_loss = 0.511233927919106, disc_loss = 0.018133337415069534
Trained batch 880 in epoch 0, gen_loss = 0.5112336608121398, disc_loss = 0.018114874016604027
Trained batch 881 in epoch 0, gen_loss = 0.5110532392720246, disc_loss = 0.018095854612459616
Trained batch 882 in epoch 0, gen_loss = 0.5110228356324128, disc_loss = 0.01807626000836772
Trained batch 883 in epoch 0, gen_loss = 0.5110785807756817, disc_loss = 0.0180574207355577
Trained batch 884 in epoch 0, gen_loss = 0.5110039664190368, disc_loss = 0.018039227758815755
Trained batch 885 in epoch 0, gen_loss = 0.5108812430844081, disc_loss = 0.01802130278262192
Trained batch 886 in epoch 0, gen_loss = 0.5109216854765827, disc_loss = 0.018003201756897784
Trained batch 887 in epoch 0, gen_loss = 0.5107853421689691, disc_loss = 0.017985114558934978
Trained batch 888 in epoch 0, gen_loss = 0.5107015752819177, disc_loss = 0.017969953955564423
Trained batch 889 in epoch 0, gen_loss = 0.5106548401077142, disc_loss = 0.017954089632454026
Trained batch 890 in epoch 0, gen_loss = 0.5106214575895958, disc_loss = 0.01793571347343306
Trained batch 891 in epoch 0, gen_loss = 0.5106480477770348, disc_loss = 0.01791672568058025
Trained batch 892 in epoch 0, gen_loss = 0.510632700709186, disc_loss = 0.017898009304874465
Trained batch 893 in epoch 0, gen_loss = 0.5105966903619318, disc_loss = 0.017879417619469495
Trained batch 894 in epoch 0, gen_loss = 0.5105200483146326, disc_loss = 0.017860603387345294
Trained batch 895 in epoch 0, gen_loss = 0.5104556580938931, disc_loss = 0.017841499915903114
Trained batch 896 in epoch 0, gen_loss = 0.5104865123130539, disc_loss = 0.01782246958276199
Trained batch 897 in epoch 0, gen_loss = 0.5105528795971371, disc_loss = 0.017803878805567438
Trained batch 898 in epoch 0, gen_loss = 0.5106026080413177, disc_loss = 0.017785461752422183
Trained batch 899 in epoch 0, gen_loss = 0.5105208379030227, disc_loss = 0.017767558019905764
Trained batch 900 in epoch 0, gen_loss = 0.5105290684133735, disc_loss = 0.01775003352338659
Trained batch 901 in epoch 0, gen_loss = 0.5104086044886689, disc_loss = 0.01773171420662123
Trained batch 902 in epoch 0, gen_loss = 0.5103566839317415, disc_loss = 0.017712836768627702
Trained batch 903 in epoch 0, gen_loss = 0.5102059210164357, disc_loss = 0.017694288902785692
Trained batch 904 in epoch 0, gen_loss = 0.5102200604275445, disc_loss = 0.01767595722886749
Trained batch 905 in epoch 0, gen_loss = 0.5101191431086585, disc_loss = 0.01765728431282756
Trained batch 906 in epoch 0, gen_loss = 0.5099504674808456, disc_loss = 0.017638715951320487
Trained batch 907 in epoch 0, gen_loss = 0.509815727594403, disc_loss = 0.01762002309773267
Trained batch 908 in epoch 0, gen_loss = 0.5099112948503169, disc_loss = 0.01760168406095231
Trained batch 909 in epoch 0, gen_loss = 0.5100100975442718, disc_loss = 0.017583638589105128
Trained batch 910 in epoch 0, gen_loss = 0.5100070360136084, disc_loss = 0.017565380948716847
Trained batch 911 in epoch 0, gen_loss = 0.509984992934685, disc_loss = 0.017546969016908213
Trained batch 912 in epoch 0, gen_loss = 0.5099653814799945, disc_loss = 0.017528371873879366
Trained batch 913 in epoch 0, gen_loss = 0.509752826565465, disc_loss = 0.01751027595924562
Trained batch 914 in epoch 0, gen_loss = 0.5097664648066453, disc_loss = 0.017492408096049836
Trained batch 915 in epoch 0, gen_loss = 0.5096887300628762, disc_loss = 0.01747402936309387
Testing Epoch 0
Traceback (most recent call last):
  File "esrgan_bones.py", line 359, in <module>
    imgs_lr = Variable(Tensor(imgs["lr"], requires_grad=False))
TypeError: new() received an invalid combination of arguments - got (Tensor, requires_grad=bool), but expected one of:
 * (*, torch.device device)
      didn't match because some of the keywords were incorrect: requires_grad
 * (torch.Storage storage)
 * (Tensor other)
 * (tuple of ints size, *, torch.device device)
 * (object data, *, torch.device device)
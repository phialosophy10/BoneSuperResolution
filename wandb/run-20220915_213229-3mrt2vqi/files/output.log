/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 1.5686529874801636, disc_loss = 1.247367262840271
Trained batch 1 in epoch 0, gen_loss = 1.3762941360473633, disc_loss = 1.1848230957984924
Trained batch 2 in epoch 0, gen_loss = 1.2057607571283977, disc_loss = 0.948663592338562
Trained batch 3 in epoch 0, gen_loss = 1.0640542954206467, disc_loss = 0.8117169439792633
Trained batch 4 in epoch 0, gen_loss = 0.9886877655982971, disc_loss = 0.7147955060005188
Trained batch 5 in epoch 0, gen_loss = 0.933903306722641, disc_loss = 0.645763764778773
Trained batch 6 in epoch 0, gen_loss = 0.8938578282083783, disc_loss = 0.6003170779773167
Trained batch 7 in epoch 0, gen_loss = 0.8827780485153198, disc_loss = 0.5611044764518738
Trained batch 8 in epoch 0, gen_loss = 0.875932408703698, disc_loss = 0.5224531888961792
Trained batch 9 in epoch 0, gen_loss = 0.8606552243232727, disc_loss = 0.4880941867828369
Trained batch 10 in epoch 0, gen_loss = 0.8464214368300005, disc_loss = 0.4600805369290439
Trained batch 11 in epoch 0, gen_loss = 0.8400288571914037, disc_loss = 0.4363827432195346
Trained batch 12 in epoch 0, gen_loss = 0.8378915007297809, disc_loss = 0.41564353154255795
Trained batch 13 in epoch 0, gen_loss = 0.8338154682091304, disc_loss = 0.3964953912155969
Trained batch 14 in epoch 0, gen_loss = 0.8314039826393127, disc_loss = 0.37914713422457375
Trained batch 15 in epoch 0, gen_loss = 0.8347440883517265, disc_loss = 0.36257309652864933
Trained batch 16 in epoch 0, gen_loss = 0.828701022793265, disc_loss = 0.3476896391195409
Trained batch 17 in epoch 0, gen_loss = 0.8266364832719167, disc_loss = 0.33470234937138027
Trained batch 18 in epoch 0, gen_loss = 0.8315238168365077, disc_loss = 0.3230401159901368
Trained batch 19 in epoch 0, gen_loss = 0.8302367627620697, disc_loss = 0.3151228778064251
Trained batch 20 in epoch 0, gen_loss = 0.844323544275193, disc_loss = 0.3084237107208797
Trained batch 21 in epoch 0, gen_loss = 0.8501581089063124, disc_loss = 0.3014053986831145
Trained batch 22 in epoch 0, gen_loss = 0.8582953551541204, disc_loss = 0.2924163037020227
Trained batch 23 in epoch 0, gen_loss = 0.8696046496431032, disc_loss = 0.28422302038719255
Trained batch 24 in epoch 0, gen_loss = 0.8825109791755676, disc_loss = 0.276667163670063
Trained batch 25 in epoch 0, gen_loss = 0.8920485170987936, disc_loss = 0.268515231517645
Trained batch 26 in epoch 0, gen_loss = 0.8995445282370956, disc_loss = 0.26030254308824186
Trained batch 27 in epoch 0, gen_loss = 0.9076448146786008, disc_loss = 0.25238589836018427
Trained batch 28 in epoch 0, gen_loss = 0.9153226305698526, disc_loss = 0.24486038320023437
Trained batch 29 in epoch 0, gen_loss = 0.9241908927758534, disc_loss = 0.2377983997265498
Trained batch 30 in epoch 0, gen_loss = 0.9299608718964362, disc_loss = 0.23106150088771696
Trained batch 31 in epoch 0, gen_loss = 0.9341875482350588, disc_loss = 0.22483732970431447
Trained batch 32 in epoch 0, gen_loss = 0.9385678677847891, disc_loss = 0.21887958924652953
Trained batch 33 in epoch 0, gen_loss = 0.9436891131541308, disc_loss = 0.21321032771511989
Trained batch 34 in epoch 0, gen_loss = 0.9505519645554679, disc_loss = 0.2079415863645928
Trained batch 35 in epoch 0, gen_loss = 0.953063804242346, disc_loss = 0.20283009546498457
Trained batch 36 in epoch 0, gen_loss = 0.9543597714321034, disc_loss = 0.19804384579529632
Trained batch 37 in epoch 0, gen_loss = 0.9579993282493792, disc_loss = 0.19351470764530332
Trained batch 38 in epoch 0, gen_loss = 0.9615589945744245, disc_loss = 0.18912528321529046
Trained batch 39 in epoch 0, gen_loss = 0.9640207722783088, disc_loss = 0.1849527157843113
Trained batch 40 in epoch 0, gen_loss = 0.9665979713928409, disc_loss = 0.1809882316738367
Trained batch 41 in epoch 0, gen_loss = 0.9684777415934063, disc_loss = 0.17717443845633948
Trained batch 42 in epoch 0, gen_loss = 0.9711858602457268, disc_loss = 0.17355580619254776
Trained batch 43 in epoch 0, gen_loss = 0.97246953709559, disc_loss = 0.17006689064543357
Trained batch 44 in epoch 0, gen_loss = 0.97459866338306, disc_loss = 0.16688448840545284
Trained batch 45 in epoch 0, gen_loss = 0.9767549491446951, disc_loss = 0.16392184753456843
Trained batch 46 in epoch 0, gen_loss = 0.9785038346939898, disc_loss = 0.161203588894073
Trained batch 47 in epoch 0, gen_loss = 0.9796033712724844, disc_loss = 0.1586835905133436
Trained batch 48 in epoch 0, gen_loss = 0.9811789709694532, disc_loss = 0.156243129272242
Trained batch 49 in epoch 0, gen_loss = 0.9826037180423737, disc_loss = 0.1538075952976942
Trained batch 50 in epoch 0, gen_loss = 0.9826530557052762, disc_loss = 0.15139497422120152
Trained batch 51 in epoch 0, gen_loss = 0.9831221252679825, disc_loss = 0.14900493489291805
Trained batch 52 in epoch 0, gen_loss = 0.983753502368927, disc_loss = 0.14651301162282251
Trained batch 53 in epoch 0, gen_loss = 0.9846618164468695, disc_loss = 0.14410866772824968
Trained batch 54 in epoch 0, gen_loss = 0.9854982907121832, disc_loss = 0.1417576278136535
Trained batch 55 in epoch 0, gen_loss = 0.9859931926642146, disc_loss = 0.13947306856113886
Trained batch 56 in epoch 0, gen_loss = 0.9861181984867966, disc_loss = 0.13736491418329247
Trained batch 57 in epoch 0, gen_loss = 0.9869448984491414, disc_loss = 0.1354205688333203
Trained batch 58 in epoch 0, gen_loss = 0.9880136362576889, disc_loss = 0.1336028817409681
Trained batch 59 in epoch 0, gen_loss = 0.9884576211373012, disc_loss = 0.13180414565528434
Trained batch 60 in epoch 0, gen_loss = 0.9884038987706919, disc_loss = 0.12995602144691787
Trained batch 61 in epoch 0, gen_loss = 0.9888541083182057, disc_loss = 0.12807915631621594
Trained batch 62 in epoch 0, gen_loss = 0.9898833168877496, disc_loss = 0.12624876691945017
Trained batch 63 in epoch 0, gen_loss = 0.9900470618158579, disc_loss = 0.12445980968186632
Trained batch 64 in epoch 0, gen_loss = 0.9900142999795767, disc_loss = 0.12272223956309831
Trained batch 65 in epoch 0, gen_loss = 0.9908711765751694, disc_loss = 0.12105756456201727
Trained batch 66 in epoch 0, gen_loss = 0.9915676668508729, disc_loss = 0.11945352137589188
Trained batch 67 in epoch 0, gen_loss = 0.9917450634872212, disc_loss = 0.11789802598821766
Trained batch 68 in epoch 0, gen_loss = 0.9919974095579507, disc_loss = 0.11641285534732151
Trained batch 69 in epoch 0, gen_loss = 0.9918843056474413, disc_loss = 0.11497559463605285
Trained batch 70 in epoch 0, gen_loss = 0.9919948703806165, disc_loss = 0.1136301143199835
Trained batch 71 in epoch 0, gen_loss = 0.9924198943707678, disc_loss = 0.11234904506192026
Trained batch 72 in epoch 0, gen_loss = 0.992370168640189, disc_loss = 0.11113407872362088
Trained batch 73 in epoch 0, gen_loss = 0.9932685856883591, disc_loss = 0.10993123080933818
Trained batch 74 in epoch 0, gen_loss = 0.9934699908892314, disc_loss = 0.1087028983856241
Trained batch 75 in epoch 0, gen_loss = 0.9938262442224904, disc_loss = 0.10743346598342453
Trained batch 76 in epoch 0, gen_loss = 0.9940830987769288, disc_loss = 0.10619919339509366
Trained batch 77 in epoch 0, gen_loss = 0.9944386596863086, disc_loss = 0.10499406278802034
Trained batch 78 in epoch 0, gen_loss = 0.9948117755636384, disc_loss = 0.10381123879806528
Trained batch 79 in epoch 0, gen_loss = 0.9949225880205631, disc_loss = 0.10270660173846409
Trained batch 80 in epoch 0, gen_loss = 0.9954453316735633, disc_loss = 0.10162529204454687
Trained batch 81 in epoch 0, gen_loss = 0.9957552428652601, disc_loss = 0.10052380976607887
Trained batch 82 in epoch 0, gen_loss = 0.9962269936699465, disc_loss = 0.09943276175847614
Trained batch 83 in epoch 0, gen_loss = 0.9960547252779915, disc_loss = 0.09834364370354229
Trained batch 84 in epoch 0, gen_loss = 0.9964304552358739, disc_loss = 0.09730103788349559
Trained batch 85 in epoch 0, gen_loss = 0.9964150737884433, disc_loss = 0.0962669889355988
Trained batch 86 in epoch 0, gen_loss = 0.9968211260335199, disc_loss = 0.09527208421636245
Trained batch 87 in epoch 0, gen_loss = 0.996989490633661, disc_loss = 0.09429748355283994
Trained batch 88 in epoch 0, gen_loss = 0.9973382219839632, disc_loss = 0.09334016335981615
Trained batch 89 in epoch 0, gen_loss = 0.9976640111870236, disc_loss = 0.0923912835928301
Trained batch 90 in epoch 0, gen_loss = 0.9971488236070989, disc_loss = 0.09146403939882805
Trained batch 91 in epoch 0, gen_loss = 0.9970125543034595, disc_loss = 0.09055607271907122
Trained batch 92 in epoch 0, gen_loss = 0.9972276674803867, disc_loss = 0.08966890579309836
Trained batch 93 in epoch 0, gen_loss = 0.9971681027970416, disc_loss = 0.08878773761952811
Trained batch 94 in epoch 0, gen_loss = 0.9967267362694991, disc_loss = 0.08792528632636133
Trained batch 95 in epoch 0, gen_loss = 0.9964848601569732, disc_loss = 0.08709130045220566
Trained batch 96 in epoch 0, gen_loss = 0.9961044880532727, disc_loss = 0.08626845917309221
Trained batch 97 in epoch 0, gen_loss = 0.9962585027120552, disc_loss = 0.08547396516446404
Trained batch 98 in epoch 0, gen_loss = 0.9962366464162113, disc_loss = 0.08468973211887659
Trained batch 99 in epoch 0, gen_loss = 0.9960826951265335, disc_loss = 0.08392506696749479
Trained batch 100 in epoch 0, gen_loss = 0.9961227786422956, disc_loss = 0.08318149169796321
Trained batch 101 in epoch 0, gen_loss = 0.9962598161370146, disc_loss = 0.08244806589723072
Trained batch 102 in epoch 0, gen_loss = 0.9964472663055346, disc_loss = 0.08172634909001802
Trained batch 103 in epoch 0, gen_loss = 0.9964651803557689, disc_loss = 0.08101583287889998
Trained batch 104 in epoch 0, gen_loss = 0.9964004516601562, disc_loss = 0.08030663699000365
Trained batch 105 in epoch 0, gen_loss = 0.9963650737168654, disc_loss = 0.07961679658993094
Trained batch 106 in epoch 0, gen_loss = 0.9962917349048864, disc_loss = 0.07893934190516995
Trained batch 107 in epoch 0, gen_loss = 0.9962757522309268, disc_loss = 0.07828612353963156
Trained batch 108 in epoch 0, gen_loss = 0.9964502781902979, disc_loss = 0.07763956057830551
Trained batch 109 in epoch 0, gen_loss = 0.9962591111660004, disc_loss = 0.07700699694370004
Trained batch 110 in epoch 0, gen_loss = 0.9962172288078446, disc_loss = 0.0763914614605407
Trained batch 111 in epoch 0, gen_loss = 0.9962786473333836, disc_loss = 0.07580020719823162
Trained batch 112 in epoch 0, gen_loss = 0.996267393626998, disc_loss = 0.07521361503667667
Trained batch 113 in epoch 0, gen_loss = 0.9963169484807733, disc_loss = 0.07464221826133628
Trained batch 114 in epoch 0, gen_loss = 0.9964543290760206, disc_loss = 0.07408848677397423
Trained batch 115 in epoch 0, gen_loss = 0.9960212995266092, disc_loss = 0.0735383442370221
Trained batch 116 in epoch 0, gen_loss = 0.9961903054490049, disc_loss = 0.07300475113587375
Trained batch 117 in epoch 0, gen_loss = 0.9962640303676411, disc_loss = 0.07245436667117401
Trained batch 118 in epoch 0, gen_loss = 0.9968927477588173, disc_loss = 0.07191490354955572
Trained batch 119 in epoch 0, gen_loss = 0.9970180004835129, disc_loss = 0.07137996526435017
Trained batch 120 in epoch 0, gen_loss = 0.9972202038961994, disc_loss = 0.07086519050327214
Trained batch 121 in epoch 0, gen_loss = 0.9974754726300474, disc_loss = 0.07036391602157326
Trained batch 122 in epoch 0, gen_loss = 0.9977718649840936, disc_loss = 0.06987325273969067
Trained batch 123 in epoch 0, gen_loss = 0.9978520399139773, disc_loss = 0.06939493511773405
Trained batch 124 in epoch 0, gen_loss = 0.9978377633094787, disc_loss = 0.06891567389667035
Trained batch 125 in epoch 0, gen_loss = 0.9973635091668084, disc_loss = 0.06843923804690204
Trained batch 126 in epoch 0, gen_loss = 0.9973338114933705, disc_loss = 0.06797080083684189
Trained batch 127 in epoch 0, gen_loss = 0.9970254879444838, disc_loss = 0.06750387186184525
Trained batch 128 in epoch 0, gen_loss = 0.9966538520746453, disc_loss = 0.06704616777656615
Trained batch 129 in epoch 0, gen_loss = 0.9965203684109908, disc_loss = 0.06659604528775583
Trained batch 130 in epoch 0, gen_loss = 0.996325584768339, disc_loss = 0.06614925530348115
Trained batch 131 in epoch 0, gen_loss = 0.9964228317593083, disc_loss = 0.06570830045155052
Trained batch 132 in epoch 0, gen_loss = 0.9963296176795673, disc_loss = 0.06526719484674304
Trained batch 133 in epoch 0, gen_loss = 0.9956111445355771, disc_loss = 0.06483078386578987
Trained batch 134 in epoch 0, gen_loss = 0.9959123540807653, disc_loss = 0.06442299968804474
Trained batch 135 in epoch 0, gen_loss = 0.995674164417912, disc_loss = 0.06403776844415594
Trained batch 136 in epoch 0, gen_loss = 0.9953500985229102, disc_loss = 0.06366106605388387
Trained batch 137 in epoch 0, gen_loss = 0.9957927642525106, disc_loss = 0.0632890944328645
Trained batch 138 in epoch 0, gen_loss = 0.9957813714905609, disc_loss = 0.0629074857737735
Trained batch 139 in epoch 0, gen_loss = 0.9957951865025929, disc_loss = 0.06252091612134661
Trained batch 140 in epoch 0, gen_loss = 0.9955540755961804, disc_loss = 0.06212290795850204
Trained batch 141 in epoch 0, gen_loss = 0.9957186810567346, disc_loss = 0.061732118693508316
Trained batch 142 in epoch 0, gen_loss = 0.9958448139103976, disc_loss = 0.06134815146117569
Trained batch 143 in epoch 0, gen_loss = 0.9957793607479997, disc_loss = 0.06096156700126206
Trained batch 144 in epoch 0, gen_loss = 0.9958781937073017, disc_loss = 0.060576374559053056
Trained batch 145 in epoch 0, gen_loss = 0.9958490529288985, disc_loss = 0.060197467979503004
Trained batch 146 in epoch 0, gen_loss = 0.9960616149869906, disc_loss = 0.05983286136824663
Trained batch 147 in epoch 0, gen_loss = 0.9959623664617538, disc_loss = 0.05947310709067293
Trained batch 148 in epoch 0, gen_loss = 0.9957457344804034, disc_loss = 0.059119155899240265
Trained batch 149 in epoch 0, gen_loss = 0.995569109916687, disc_loss = 0.05876429880037904
Trained batch 150 in epoch 0, gen_loss = 0.9953990195760664, disc_loss = 0.05840922176023785
Trained batch 151 in epoch 0, gen_loss = 0.99517746073635, disc_loss = 0.05805659222441088
Trained batch 152 in epoch 0, gen_loss = 0.9949409755226833, disc_loss = 0.057710083901541295
Trained batch 153 in epoch 0, gen_loss = 0.9948701494699949, disc_loss = 0.057370170600131734
Trained batch 154 in epoch 0, gen_loss = 0.9947085888155045, disc_loss = 0.05702856257257442
Trained batch 155 in epoch 0, gen_loss = 0.9944435247243979, disc_loss = 0.05669317646429707
Trained batch 156 in epoch 0, gen_loss = 0.9942398325652834, disc_loss = 0.05636123475873736
Trained batch 157 in epoch 0, gen_loss = 0.9940864632401285, disc_loss = 0.056036127071026
Trained batch 158 in epoch 0, gen_loss = 0.9937696588114373, disc_loss = 0.05571548431326852
Trained batch 159 in epoch 0, gen_loss = 0.9935475703328848, disc_loss = 0.05539843548031058
Trained batch 160 in epoch 0, gen_loss = 0.9935538180126167, disc_loss = 0.05508600787681915
Trained batch 161 in epoch 0, gen_loss = 0.9934792433991845, disc_loss = 0.05477538375172442
Trained batch 162 in epoch 0, gen_loss = 0.993411667873523, disc_loss = 0.05447034294391337
Trained batch 163 in epoch 0, gen_loss = 0.9931050233724641, disc_loss = 0.054171506224609006
Trained batch 164 in epoch 0, gen_loss = 0.9931804064548377, disc_loss = 0.05389092947271737
Trained batch 165 in epoch 0, gen_loss = 0.9930049382060407, disc_loss = 0.05361938743616443
Trained batch 166 in epoch 0, gen_loss = 0.9931404040959066, disc_loss = 0.053358555565069535
Trained batch 167 in epoch 0, gen_loss = 0.9926283189228603, disc_loss = 0.05309600873096358
Trained batch 168 in epoch 0, gen_loss = 0.9925099156311983, disc_loss = 0.052831881062386656
Trained batch 169 in epoch 0, gen_loss = 0.9925044364788953, disc_loss = 0.05256243459332515
Trained batch 170 in epoch 0, gen_loss = 0.9923543835941114, disc_loss = 0.05228938127197979
Trained batch 171 in epoch 0, gen_loss = 0.9923581664645394, disc_loss = 0.05201914173897442
Trained batch 172 in epoch 0, gen_loss = 0.9925303324798628, disc_loss = 0.05176535538381579
Trained batch 173 in epoch 0, gen_loss = 0.9925828147893665, disc_loss = 0.05150630207325535
Trained batch 174 in epoch 0, gen_loss = 0.9925621581077576, disc_loss = 0.05124892466036337
Trained batch 175 in epoch 0, gen_loss = 0.9924223389137875, disc_loss = 0.05098885263115252
Trained batch 176 in epoch 0, gen_loss = 0.9923955899173931, disc_loss = 0.05072622663357248
Trained batch 177 in epoch 0, gen_loss = 0.9920082728514511, disc_loss = 0.05046139259592452
Trained batch 178 in epoch 0, gen_loss = 0.991914201715139, disc_loss = 0.05020253016358481
Trained batch 179 in epoch 0, gen_loss = 0.9918220510085424, disc_loss = 0.04994936723831213
Trained batch 180 in epoch 0, gen_loss = 0.9917543148467554, disc_loss = 0.049700469835995804
Trained batch 181 in epoch 0, gen_loss = 0.9917210468224117, disc_loss = 0.049457362753206065
Trained batch 182 in epoch 0, gen_loss = 0.9914892472204615, disc_loss = 0.04921649432807265
Trained batch 183 in epoch 0, gen_loss = 0.991306002697219, disc_loss = 0.04898197905656517
Trained batch 184 in epoch 0, gen_loss = 0.991368533147348, disc_loss = 0.04875047166856962
Trained batch 185 in epoch 0, gen_loss = 0.9913961105449225, disc_loss = 0.048517383497348555
Trained batch 186 in epoch 0, gen_loss = 0.991301605089463, disc_loss = 0.048281240508577884
Trained batch 187 in epoch 0, gen_loss = 0.9910706424332679, disc_loss = 0.0480427136075029
Trained batch 188 in epoch 0, gen_loss = 0.9911816186375089, disc_loss = 0.04780795477039954
Trained batch 189 in epoch 0, gen_loss = 0.9911467354548605, disc_loss = 0.04757207846023927
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 0.9899832010269165, disc_loss = 0.003317574504762888
Trained batch 1 in epoch 1, gen_loss = 0.975451648235321, disc_loss = 0.003248172579333186
Trained batch 2 in epoch 1, gen_loss = 0.9823451638221741, disc_loss = 0.0031736277354260287
Trained batch 3 in epoch 1, gen_loss = 0.978286013007164, disc_loss = 0.0031078284373506904
Trained batch 4 in epoch 1, gen_loss = 0.980691385269165, disc_loss = 0.0030979137402027844
Trained batch 5 in epoch 1, gen_loss = 0.9787641962369283, disc_loss = 0.0030744102938721576
Trained batch 6 in epoch 1, gen_loss = 0.9790063670703343, disc_loss = 0.0030626152375979082
Trained batch 7 in epoch 1, gen_loss = 0.9754739254713058, disc_loss = 0.003030315274372697
Trained batch 8 in epoch 1, gen_loss = 0.9716625743442111, disc_loss = 0.003006305700788895
Trained batch 9 in epoch 1, gen_loss = 0.9732299864292144, disc_loss = 0.0031386222690343857
Trained batch 10 in epoch 1, gen_loss = 0.9802972782741893, disc_loss = 0.0033207101408730855
Trained batch 11 in epoch 1, gen_loss = 0.9835037738084793, disc_loss = 0.003463219152763486
Trained batch 12 in epoch 1, gen_loss = 0.9887595130847051, disc_loss = 0.003671002359344409
Trained batch 13 in epoch 1, gen_loss = 0.9918313494750431, disc_loss = 0.003901796215879066
Trained batch 14 in epoch 1, gen_loss = 0.9923749486605327, disc_loss = 0.004133535145471493
Trained batch 15 in epoch 1, gen_loss = 0.9920080713927746, disc_loss = 0.004379999561933801
Trained batch 16 in epoch 1, gen_loss = 0.9949831717154559, disc_loss = 0.004586251699091757
Trained batch 17 in epoch 1, gen_loss = 0.9976515803072188, disc_loss = 0.0047068090126332306
Trained batch 18 in epoch 1, gen_loss = 0.9992775446490237, disc_loss = 0.004794498219301826
Trained batch 19 in epoch 1, gen_loss = 0.9993180185556412, disc_loss = 0.004848650749772787
Trained batch 20 in epoch 1, gen_loss = 1.0003000072070531, disc_loss = 0.004862046844902493
Trained batch 21 in epoch 1, gen_loss = 1.0011579529805616, disc_loss = 0.004842287352816625
Trained batch 22 in epoch 1, gen_loss = 1.0022505910500237, disc_loss = 0.004784455684864003
Trained batch 23 in epoch 1, gen_loss = 1.001748266319434, disc_loss = 0.004717272415291518
Trained batch 24 in epoch 1, gen_loss = 0.9990914702415467, disc_loss = 0.004646004978567362
Trained batch 25 in epoch 1, gen_loss = 1.0001819661030402, disc_loss = 0.004603249182064946
Trained batch 26 in epoch 1, gen_loss = 0.9979686030635128, disc_loss = 0.004554549059658138
Trained batch 27 in epoch 1, gen_loss = 0.9963436701468059, disc_loss = 0.004505602701101452
Trained batch 28 in epoch 1, gen_loss = 0.9942868804109508, disc_loss = 0.00445878602853366
Trained batch 29 in epoch 1, gen_loss = 0.991561617453893, disc_loss = 0.004416783316992223
Trained batch 30 in epoch 1, gen_loss = 0.9900538940583506, disc_loss = 0.004390889162858648
Trained batch 31 in epoch 1, gen_loss = 0.9894521553069353, disc_loss = 0.004366600172943436
Trained batch 32 in epoch 1, gen_loss = 0.9870521931937246, disc_loss = 0.0043549471760563774
Trained batch 33 in epoch 1, gen_loss = 0.9850130589569316, disc_loss = 0.00434849231832606
Trained batch 34 in epoch 1, gen_loss = 0.9844007781573705, disc_loss = 0.00437817605478423
Trained batch 35 in epoch 1, gen_loss = 0.9841487358013788, disc_loss = 0.004434001412139171
Trained batch 36 in epoch 1, gen_loss = 0.9827926883826384, disc_loss = 0.004478916123106673
Trained batch 37 in epoch 1, gen_loss = 0.9836909723909277, disc_loss = 0.00452996341903743
Trained batch 38 in epoch 1, gen_loss = 0.9825752927706792, disc_loss = 0.004577780978228801
Trained batch 39 in epoch 1, gen_loss = 0.9811668410897255, disc_loss = 0.004626804916188121
Trained batch 40 in epoch 1, gen_loss = 0.9812387140785775, disc_loss = 0.004662167212766845
Trained batch 41 in epoch 1, gen_loss = 0.9812024718239194, disc_loss = 0.004678169209953575
Trained batch 42 in epoch 1, gen_loss = 0.9812119090279867, disc_loss = 0.004667498766942773
Trained batch 43 in epoch 1, gen_loss = 0.9806484634226019, disc_loss = 0.0046381905558519065
Trained batch 44 in epoch 1, gen_loss = 0.9809640937381321, disc_loss = 0.004611347450150384
Trained batch 45 in epoch 1, gen_loss = 0.9796842271867006, disc_loss = 0.004563639649068532
Trained batch 46 in epoch 1, gen_loss = 0.9787316056008034, disc_loss = 0.0045168032879604305
Trained batch 47 in epoch 1, gen_loss = 0.9779949088891348, disc_loss = 0.004471237606291349
Trained batch 48 in epoch 1, gen_loss = 0.9779763671816611, disc_loss = 0.004427474666843001
Trained batch 49 in epoch 1, gen_loss = 0.9778783810138703, disc_loss = 0.004391953125596046
Trained batch 50 in epoch 1, gen_loss = 0.9778118823088852, disc_loss = 0.004355944862004881
Trained batch 51 in epoch 1, gen_loss = 0.9773359814515481, disc_loss = 0.004323247721633659
Trained batch 52 in epoch 1, gen_loss = 0.9771993328940194, disc_loss = 0.004288867410307504
Trained batch 53 in epoch 1, gen_loss = 0.9755658098944912, disc_loss = 0.004263412047832928
Trained batch 54 in epoch 1, gen_loss = 0.9757586771791632, disc_loss = 0.004262777870859612
Trained batch 55 in epoch 1, gen_loss = 0.9758302984493119, disc_loss = 0.00427570750720666
Trained batch 56 in epoch 1, gen_loss = 0.9751837284941423, disc_loss = 0.004292747663464724
Trained batch 57 in epoch 1, gen_loss = 0.974425974591025, disc_loss = 0.004307592982137254
Trained batch 58 in epoch 1, gen_loss = 0.974063567185806, disc_loss = 0.004323406362022131
Trained batch 59 in epoch 1, gen_loss = 0.9729082355896632, disc_loss = 0.004345184040721506
Trained batch 60 in epoch 1, gen_loss = 0.9732729089064677, disc_loss = 0.004379576060646137
Trained batch 61 in epoch 1, gen_loss = 0.97313396200057, disc_loss = 0.00441103633267865
Trained batch 62 in epoch 1, gen_loss = 0.9728670621675158, disc_loss = 0.00443011643882427
Trained batch 63 in epoch 1, gen_loss = 0.9727197838947177, disc_loss = 0.004441559434781084
Trained batch 64 in epoch 1, gen_loss = 0.9721930384635925, disc_loss = 0.004455127398698376
Trained batch 65 in epoch 1, gen_loss = 0.9717282463203777, disc_loss = 0.004464597966888863
Trained batch 66 in epoch 1, gen_loss = 0.9709075893928756, disc_loss = 0.004482048657486465
Trained batch 67 in epoch 1, gen_loss = 0.970940087647999, disc_loss = 0.004494269306579714
Trained batch 68 in epoch 1, gen_loss = 0.9713104885557423, disc_loss = 0.004507221858543547
Trained batch 69 in epoch 1, gen_loss = 0.9708063645022256, disc_loss = 0.0045172019163146615
Trained batch 70 in epoch 1, gen_loss = 0.970795063065811, disc_loss = 0.004515311907006192
Trained batch 71 in epoch 1, gen_loss = 0.9702509774102105, disc_loss = 0.00450735956029449
Trained batch 72 in epoch 1, gen_loss = 0.9704643161329505, disc_loss = 0.004497696119296836
Trained batch 73 in epoch 1, gen_loss = 0.9700325373056773, disc_loss = 0.004477940078170315
Trained batch 74 in epoch 1, gen_loss = 0.9699252033233643, disc_loss = 0.004457263797521591
Trained batch 75 in epoch 1, gen_loss = 0.9695213272383338, disc_loss = 0.00443516712709281
Trained batch 76 in epoch 1, gen_loss = 0.9690452953437706, disc_loss = 0.004411518531428142
Trained batch 77 in epoch 1, gen_loss = 0.9691309806628104, disc_loss = 0.004391970954692135
Trained batch 78 in epoch 1, gen_loss = 0.9683289988131463, disc_loss = 0.004372276088717995
Trained batch 79 in epoch 1, gen_loss = 0.9687510944902897, disc_loss = 0.004355026115081273
Trained batch 80 in epoch 1, gen_loss = 0.968503662833461, disc_loss = 0.004333053626419034
Trained batch 81 in epoch 1, gen_loss = 0.9688149334453955, disc_loss = 0.004313511197546088
Trained batch 82 in epoch 1, gen_loss = 0.9686417529381901, disc_loss = 0.004289026722783245
Trained batch 83 in epoch 1, gen_loss = 0.9678265956186113, disc_loss = 0.0042644636954979175
Trained batch 84 in epoch 1, gen_loss = 0.9684929868754218, disc_loss = 0.004246953001026722
Trained batch 85 in epoch 1, gen_loss = 0.9689822481122128, disc_loss = 0.0042254985174770615
Trained batch 86 in epoch 1, gen_loss = 0.9689913405769173, disc_loss = 0.004202379569432688
Trained batch 87 in epoch 1, gen_loss = 0.9683774641968987, disc_loss = 0.004175843035971577
Trained batch 88 in epoch 1, gen_loss = 0.9678326831774765, disc_loss = 0.0041480944138752775
Trained batch 89 in epoch 1, gen_loss = 0.9680451353391012, disc_loss = 0.00412596786627546
Trained batch 90 in epoch 1, gen_loss = 0.9676766506918184, disc_loss = 0.0041074700420722365
Trained batch 91 in epoch 1, gen_loss = 0.9675532171259755, disc_loss = 0.004087852548210598
Trained batch 92 in epoch 1, gen_loss = 0.9675497976682519, disc_loss = 0.004071339477925131
Trained batch 93 in epoch 1, gen_loss = 0.9681143018793552, disc_loss = 0.004052209508100009
Trained batch 94 in epoch 1, gen_loss = 0.9682096186437105, disc_loss = 0.004028297381132449
Trained batch 95 in epoch 1, gen_loss = 0.9685662891715765, disc_loss = 0.004006178776762681
Trained batch 96 in epoch 1, gen_loss = 0.9680873198607534, disc_loss = 0.003984495103311216
Trained batch 97 in epoch 1, gen_loss = 0.9681311876189952, disc_loss = 0.003961565675052377
Trained batch 98 in epoch 1, gen_loss = 0.9679468539026048, disc_loss = 0.003939258500303358
Trained batch 99 in epoch 1, gen_loss = 0.967767384648323, disc_loss = 0.003918445367598906
Trained batch 100 in epoch 1, gen_loss = 0.9677948066503694, disc_loss = 0.003901597613809944
Trained batch 101 in epoch 1, gen_loss = 0.9675089220205942, disc_loss = 0.0038777017536773986
Trained batch 102 in epoch 1, gen_loss = 0.9671940982920452, disc_loss = 0.0038548325283398618
Trained batch 103 in epoch 1, gen_loss = 0.9671774581074715, disc_loss = 0.003831902091266014
Trained batch 104 in epoch 1, gen_loss = 0.9669582151231312, disc_loss = 0.003811183803537417
Trained batch 105 in epoch 1, gen_loss = 0.9668153940506701, disc_loss = 0.003791372986940913
Trained batch 106 in epoch 1, gen_loss = 0.9668988501914194, disc_loss = 0.0037734292101585
Trained batch 107 in epoch 1, gen_loss = 0.9669761260350546, disc_loss = 0.0037595253336433045
Trained batch 108 in epoch 1, gen_loss = 0.9672661188545577, disc_loss = 0.003747726227754915
Trained batch 109 in epoch 1, gen_loss = 0.9665366286581213, disc_loss = 0.003732923002363267
Trained batch 110 in epoch 1, gen_loss = 0.9663827215229068, disc_loss = 0.0037158590747748276
Trained batch 111 in epoch 1, gen_loss = 0.9664048036294324, disc_loss = 0.0036997947494715583
Trained batch 112 in epoch 1, gen_loss = 0.9659416765238331, disc_loss = 0.003687678767261054
Trained batch 113 in epoch 1, gen_loss = 0.9660174982589588, disc_loss = 0.003684113432220265
Trained batch 114 in epoch 1, gen_loss = 0.965994872217593, disc_loss = 0.003683267850631281
Trained batch 115 in epoch 1, gen_loss = 0.9660226769488434, disc_loss = 0.00368544257522946
Trained batch 116 in epoch 1, gen_loss = 0.9662004021497873, disc_loss = 0.0036872635131829186
Trained batch 117 in epoch 1, gen_loss = 0.9662710726261139, disc_loss = 0.0036836554724486324
Trained batch 118 in epoch 1, gen_loss = 0.9659844055897048, disc_loss = 0.0036759643958286705
Trained batch 119 in epoch 1, gen_loss = 0.9657433847586314, disc_loss = 0.00366611771848208
Trained batch 120 in epoch 1, gen_loss = 0.965533363425042, disc_loss = 0.003655560975624941
Trained batch 121 in epoch 1, gen_loss = 0.9657039295454495, disc_loss = 0.0036478959983901778
Trained batch 122 in epoch 1, gen_loss = 0.9654459856389984, disc_loss = 0.0036393799696011636
Trained batch 123 in epoch 1, gen_loss = 0.9654135386789998, disc_loss = 0.0036301736470176686
Trained batch 124 in epoch 1, gen_loss = 0.9652260522842407, disc_loss = 0.003620148819871247
Trained batch 125 in epoch 1, gen_loss = 0.9649607472949557, disc_loss = 0.0036105318521592942
Trained batch 126 in epoch 1, gen_loss = 0.9654516629346712, disc_loss = 0.0036030012324056405
Trained batch 127 in epoch 1, gen_loss = 0.9656297769397497, disc_loss = 0.003596864454266324
Trained batch 128 in epoch 1, gen_loss = 0.9652813682260439, disc_loss = 0.003594556003050922
Trained batch 129 in epoch 1, gen_loss = 0.9650942765749417, disc_loss = 0.003593755263584451
Trained batch 130 in epoch 1, gen_loss = 0.965135469691444, disc_loss = 0.00359355655537904
Trained batch 131 in epoch 1, gen_loss = 0.9653080412835786, disc_loss = 0.0035936277347376963
Trained batch 132 in epoch 1, gen_loss = 0.9650448574159378, disc_loss = 0.003594540739677062
Trained batch 133 in epoch 1, gen_loss = 0.9648918086913094, disc_loss = 0.003594376121599005
Trained batch 134 in epoch 1, gen_loss = 0.9647660414377849, disc_loss = 0.0035923570834307207
Trained batch 135 in epoch 1, gen_loss = 0.9651356479700874, disc_loss = 0.0035973824106964886
Trained batch 136 in epoch 1, gen_loss = 0.9651022270648149, disc_loss = 0.0036011927541902793
Trained batch 137 in epoch 1, gen_loss = 0.9653396429359049, disc_loss = 0.00360632545662288
Trained batch 138 in epoch 1, gen_loss = 0.9653926307348897, disc_loss = 0.0036137849519618875
Trained batch 139 in epoch 1, gen_loss = 0.9649993879454476, disc_loss = 0.00362246632492835
Trained batch 140 in epoch 1, gen_loss = 0.9652668837959885, disc_loss = 0.003635703529072727
Trained batch 141 in epoch 1, gen_loss = 0.9654909708130528, disc_loss = 0.0036483147258634194
Trained batch 142 in epoch 1, gen_loss = 0.9656497415129122, disc_loss = 0.0036603594027863414
Trained batch 143 in epoch 1, gen_loss = 0.9657869992984666, disc_loss = 0.0036707459067757656
Trained batch 144 in epoch 1, gen_loss = 0.9659081508373392, disc_loss = 0.003679811041641595
Trained batch 145 in epoch 1, gen_loss = 0.9659981964385673, disc_loss = 0.0036834552557182126
Trained batch 146 in epoch 1, gen_loss = 0.9657661886442275, disc_loss = 0.00368295375774076
Trained batch 147 in epoch 1, gen_loss = 0.9658490826149244, disc_loss = 0.0036832169587157565
Trained batch 148 in epoch 1, gen_loss = 0.9657458030937502, disc_loss = 0.0036800880174171304
Trained batch 149 in epoch 1, gen_loss = 0.9656961301962534, disc_loss = 0.003678116072745373
Trained batch 150 in epoch 1, gen_loss = 0.9657352748296119, disc_loss = 0.0036753900711492494
Trained batch 151 in epoch 1, gen_loss = 0.9654988485731577, disc_loss = 0.0036723754808343457
Trained batch 152 in epoch 1, gen_loss = 0.9655314274862701, disc_loss = 0.00366874612651741
Trained batch 153 in epoch 1, gen_loss = 0.9656431404027072, disc_loss = 0.003663121777822493
Trained batch 154 in epoch 1, gen_loss = 0.9655182553875831, disc_loss = 0.0036550422987690376
Trained batch 155 in epoch 1, gen_loss = 0.965379998469964, disc_loss = 0.0036448543654002538
Trained batch 156 in epoch 1, gen_loss = 0.9653505041341114, disc_loss = 0.003632677899922725
Trained batch 157 in epoch 1, gen_loss = 0.9652285926704165, disc_loss = 0.00361962700292138
Trained batch 158 in epoch 1, gen_loss = 0.9651306065373451, disc_loss = 0.003606072842266481
Trained batch 159 in epoch 1, gen_loss = 0.964693695679307, disc_loss = 0.0035958905427833088
Trained batch 160 in epoch 1, gen_loss = 0.9650174997608114, disc_loss = 0.0035987652835337827
Trained batch 161 in epoch 1, gen_loss = 0.9644925598009133, disc_loss = 0.003617517990750019
Trained batch 162 in epoch 1, gen_loss = 0.9645459619036482, disc_loss = 0.003644870121340536
Trained batch 163 in epoch 1, gen_loss = 0.9647293396112395, disc_loss = 0.0036768481183638113
Trained batch 164 in epoch 1, gen_loss = 0.9648209004691153, disc_loss = 0.00370045589480662
Trained batch 165 in epoch 1, gen_loss = 0.964811115020729, disc_loss = 0.003710058757597693
Trained batch 166 in epoch 1, gen_loss = 0.964731171816409, disc_loss = 0.003708490669660404
Trained batch 167 in epoch 1, gen_loss = 0.9647775292396545, disc_loss = 0.003701999416253308
Trained batch 168 in epoch 1, gen_loss = 0.9647720050529616, disc_loss = 0.0036925053190902846
Trained batch 169 in epoch 1, gen_loss = 0.9650240386233611, disc_loss = 0.003683539526537061
Trained batch 170 in epoch 1, gen_loss = 0.964849411046993, disc_loss = 0.003672663014169717
Trained batch 171 in epoch 1, gen_loss = 0.9647676525420921, disc_loss = 0.0036653758325819793
Trained batch 172 in epoch 1, gen_loss = 0.9646946553550014, disc_loss = 0.003658473594625604
Trained batch 173 in epoch 1, gen_loss = 0.964809253983114, disc_loss = 0.0036520260518641563
Trained batch 174 in epoch 1, gen_loss = 0.9647955778666905, disc_loss = 0.003642247355809169
Trained batch 175 in epoch 1, gen_loss = 0.9648043083196337, disc_loss = 0.0036325412266623143
Trained batch 176 in epoch 1, gen_loss = 0.9648657932793353, disc_loss = 0.0036219866922661916
Trained batch 177 in epoch 1, gen_loss = 0.9648490019058913, disc_loss = 0.0036105241762536965
Trained batch 178 in epoch 1, gen_loss = 0.9647234871400802, disc_loss = 0.003597771609722319
Trained batch 179 in epoch 1, gen_loss = 0.9644756330384149, disc_loss = 0.003584055809511079
Trained batch 180 in epoch 1, gen_loss = 0.964486166917158, disc_loss = 0.0035702465333620815
Trained batch 181 in epoch 1, gen_loss = 0.9644909930098188, disc_loss = 0.003557141886890999
Trained batch 182 in epoch 1, gen_loss = 0.9646152257919312, disc_loss = 0.0035438963079753795
Trained batch 183 in epoch 1, gen_loss = 0.9646965679915055, disc_loss = 0.003531730494654292
Trained batch 184 in epoch 1, gen_loss = 0.9644678164172817, disc_loss = 0.003520764771697892
Trained batch 185 in epoch 1, gen_loss = 0.9645139821754989, disc_loss = 0.003511267746122734
Trained batch 186 in epoch 1, gen_loss = 0.964533966811583, disc_loss = 0.003502614570178968
Trained batch 187 in epoch 1, gen_loss = 0.9641996511119477, disc_loss = 0.0034949532171285294
Trained batch 188 in epoch 1, gen_loss = 0.9640546787983526, disc_loss = 0.0034883372632234736
Trained batch 189 in epoch 1, gen_loss = 0.9638866979824869, disc_loss = 0.003481588342937788
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 0.9772845506668091, disc_loss = 0.002616767305880785
Trained batch 1 in epoch 2, gen_loss = 0.9664454758167267, disc_loss = 0.0024676829343661666
Trained batch 2 in epoch 2, gen_loss = 0.9646734595298767, disc_loss = 0.0023821103386580944
Trained batch 3 in epoch 2, gen_loss = 0.9586102068424225, disc_loss = 0.0023379846243187785
Trained batch 4 in epoch 2, gen_loss = 0.9529654026031494, disc_loss = 0.0023141751531511544
Trained batch 5 in epoch 2, gen_loss = 0.9640520215034485, disc_loss = 0.0023411449898655214
Trained batch 6 in epoch 2, gen_loss = 0.9581839527402606, disc_loss = 0.002315166838733213
Trained batch 7 in epoch 2, gen_loss = 0.9497680813074112, disc_loss = 0.002296039863722399
Trained batch 8 in epoch 2, gen_loss = 0.9503092964490255, disc_loss = 0.002299484150070283
Trained batch 9 in epoch 2, gen_loss = 0.9510619461536407, disc_loss = 0.002261045330669731
Trained batch 10 in epoch 2, gen_loss = 0.9531285708600824, disc_loss = 0.002200416511517357
Trained batch 11 in epoch 2, gen_loss = 0.9512059539556503, disc_loss = 0.002125944602691258
Trained batch 12 in epoch 2, gen_loss = 0.9551662894395682, disc_loss = 0.002085368435543317
Trained batch 13 in epoch 2, gen_loss = 0.9554055120263781, disc_loss = 0.002075745616041656
Trained batch 14 in epoch 2, gen_loss = 0.9538633545239766, disc_loss = 0.0020980439071233074
Trained batch 15 in epoch 2, gen_loss = 0.9537497274577618, disc_loss = 0.00211301014496712
Trained batch 16 in epoch 2, gen_loss = 0.955788114491631, disc_loss = 0.002134600976098548
Trained batch 17 in epoch 2, gen_loss = 0.9579997791184319, disc_loss = 0.0021469451086078254
Trained batch 18 in epoch 2, gen_loss = 0.9575305361496774, disc_loss = 0.0021395518407715777
Trained batch 19 in epoch 2, gen_loss = 0.9597330570220948, disc_loss = 0.0021448242652695624
Trained batch 20 in epoch 2, gen_loss = 0.9586119595028105, disc_loss = 0.002135200564572144
Trained batch 21 in epoch 2, gen_loss = 0.9559078975157305, disc_loss = 0.0021197633891874416
Trained batch 22 in epoch 2, gen_loss = 0.9545571130254994, disc_loss = 0.00209728321161769
Trained batch 23 in epoch 2, gen_loss = 0.9546295454104742, disc_loss = 0.0020733751540925973
Trained batch 24 in epoch 2, gen_loss = 0.9566099691390991, disc_loss = 0.0020494899759069085
Trained batch 25 in epoch 2, gen_loss = 0.9553892016410828, disc_loss = 0.002024596758509198
Trained batch 26 in epoch 2, gen_loss = 0.9532396219394825, disc_loss = 0.0020019501378690757
Trained batch 27 in epoch 2, gen_loss = 0.9536735543182918, disc_loss = 0.001991596010546865
Trained batch 28 in epoch 2, gen_loss = 0.9550346855459542, disc_loss = 0.001994182054627815
Trained batch 29 in epoch 2, gen_loss = 0.9552656908830007, disc_loss = 0.0019959028616237146
Trained batch 30 in epoch 2, gen_loss = 0.9535269198879119, disc_loss = 0.0020001735200264282
Trained batch 31 in epoch 2, gen_loss = 0.9545830637216568, disc_loss = 0.0020045517121616285
Trained batch 32 in epoch 2, gen_loss = 0.9551727067340504, disc_loss = 0.002006005894420951
Trained batch 33 in epoch 2, gen_loss = 0.9547579884529114, disc_loss = 0.002002330623594496
Trained batch 34 in epoch 2, gen_loss = 0.9550649830273219, disc_loss = 0.0020005316972466452
Trained batch 35 in epoch 2, gen_loss = 0.9555467913548151, disc_loss = 0.0020029829756822437
Trained batch 36 in epoch 2, gen_loss = 0.9558692671157218, disc_loss = 0.0020022882444381313
Trained batch 37 in epoch 2, gen_loss = 0.9554782243151414, disc_loss = 0.0019953419135785417
Trained batch 38 in epoch 2, gen_loss = 0.9559087569896991, disc_loss = 0.0019945748783170413
Trained batch 39 in epoch 2, gen_loss = 0.9555284708738327, disc_loss = 0.0020036560192238538
Trained batch 40 in epoch 2, gen_loss = 0.9563398186753436, disc_loss = 0.002020736559998335
Trained batch 41 in epoch 2, gen_loss = 0.9561952522822789, disc_loss = 0.0020302701907764587
Trained batch 42 in epoch 2, gen_loss = 0.9562607227369796, disc_loss = 0.0020370873200252306
Trained batch 43 in epoch 2, gen_loss = 0.9556526108221575, disc_loss = 0.002035597900182686
Trained batch 44 in epoch 2, gen_loss = 0.9553523672951593, disc_loss = 0.0020320766605436804
Trained batch 45 in epoch 2, gen_loss = 0.9554995505706124, disc_loss = 0.0020255989638035712
Trained batch 46 in epoch 2, gen_loss = 0.9551793717323466, disc_loss = 0.002009776554645059
Trained batch 47 in epoch 2, gen_loss = 0.9559367907543977, disc_loss = 0.00199196558969561
Trained batch 48 in epoch 2, gen_loss = 0.9564951208173013, disc_loss = 0.001976261378684062
Trained batch 49 in epoch 2, gen_loss = 0.9551888799667358, disc_loss = 0.0019615217274986207
Trained batch 50 in epoch 2, gen_loss = 0.9557743376376582, disc_loss = 0.0019572644001420807
Trained batch 51 in epoch 2, gen_loss = 0.9567722701109372, disc_loss = 0.001964314957149327
Trained batch 52 in epoch 2, gen_loss = 0.9570078568638496, disc_loss = 0.001975031051222446
Trained batch 53 in epoch 2, gen_loss = 0.9574689787847025, disc_loss = 0.001987885808813627
Trained batch 54 in epoch 2, gen_loss = 0.9585896394469521, disc_loss = 0.0020108796275136146
Trained batch 55 in epoch 2, gen_loss = 0.9588530915124076, disc_loss = 0.002041107941684978
Trained batch 56 in epoch 2, gen_loss = 0.9598221276935778, disc_loss = 0.002083092339729008
Trained batch 57 in epoch 2, gen_loss = 0.9598225951194763, disc_loss = 0.002137827534421251
Trained batch 58 in epoch 2, gen_loss = 0.9604724089978105, disc_loss = 0.0021983981606061177
Trained batch 59 in epoch 2, gen_loss = 0.9602427889903387, disc_loss = 0.0022482961183413865
Trained batch 60 in epoch 2, gen_loss = 0.9603156144501733, disc_loss = 0.0022816181137058577
Trained batch 61 in epoch 2, gen_loss = 0.9593539805181565, disc_loss = 0.0022998077930101463
Trained batch 62 in epoch 2, gen_loss = 0.9590563376744589, disc_loss = 0.0023098221965252405
Trained batch 63 in epoch 2, gen_loss = 0.9588779201731086, disc_loss = 0.002308023984369356
Trained batch 64 in epoch 2, gen_loss = 0.9600089210730333, disc_loss = 0.0023014028610375066
Trained batch 65 in epoch 2, gen_loss = 0.9595490061875546, disc_loss = 0.002291020549212893
Trained batch 66 in epoch 2, gen_loss = 0.9600776273812821, disc_loss = 0.0022826319431830475
Trained batch 67 in epoch 2, gen_loss = 0.9601692250546288, disc_loss = 0.0022739392571726486
Trained batch 68 in epoch 2, gen_loss = 0.959729602371437, disc_loss = 0.0022643658389890757
Trained batch 69 in epoch 2, gen_loss = 0.9596412301063537, disc_loss = 0.0022592753105397734
Trained batch 70 in epoch 2, gen_loss = 0.9591916933865614, disc_loss = 0.002254008399125871
Trained batch 71 in epoch 2, gen_loss = 0.9590439597765604, disc_loss = 0.002245383246594833
Trained batch 72 in epoch 2, gen_loss = 0.959218539603769, disc_loss = 0.002236647140681233
Trained batch 73 in epoch 2, gen_loss = 0.9589643937510413, disc_loss = 0.0022279429170806463
Trained batch 74 in epoch 2, gen_loss = 0.9588043189048767, disc_loss = 0.002222709075237314
Trained batch 75 in epoch 2, gen_loss = 0.9587961317677247, disc_loss = 0.0022181057551949237
Trained batch 76 in epoch 2, gen_loss = 0.9586939904596898, disc_loss = 0.002210632826854753
Trained batch 77 in epoch 2, gen_loss = 0.9588572382926941, disc_loss = 0.0022025839888299694
Trained batch 78 in epoch 2, gen_loss = 0.9592294542095329, disc_loss = 0.0021902155352143357
Trained batch 79 in epoch 2, gen_loss = 0.9589569866657257, disc_loss = 0.0021762763455626553
Trained batch 80 in epoch 2, gen_loss = 0.9587486393657731, disc_loss = 0.002167127451594965
Trained batch 81 in epoch 2, gen_loss = 0.959124761383708, disc_loss = 0.0021573339060812096
Trained batch 82 in epoch 2, gen_loss = 0.9599913215062704, disc_loss = 0.00214835489449282
Trained batch 83 in epoch 2, gen_loss = 0.9597813898608798, disc_loss = 0.0021373013247891017
Trained batch 84 in epoch 2, gen_loss = 0.9596862884128795, disc_loss = 0.002126355566467871
Trained batch 85 in epoch 2, gen_loss = 0.9595902326495148, disc_loss = 0.0021154965506866574
Trained batch 86 in epoch 2, gen_loss = 0.9597080103282271, disc_loss = 0.0021064584571654082
Trained batch 87 in epoch 2, gen_loss = 0.9595012691887942, disc_loss = 0.002102835467667319
Trained batch 88 in epoch 2, gen_loss = 0.9597438426499956, disc_loss = 0.0021044518340776644
Trained batch 89 in epoch 2, gen_loss = 0.9594863428009881, disc_loss = 0.0021079850784089
Trained batch 90 in epoch 2, gen_loss = 0.9599751954550272, disc_loss = 0.0021130469011060977
Trained batch 91 in epoch 2, gen_loss = 0.959841999022857, disc_loss = 0.0021162750439860088
Trained batch 92 in epoch 2, gen_loss = 0.9599692283138153, disc_loss = 0.0021181223546004584
Trained batch 93 in epoch 2, gen_loss = 0.9599680412322917, disc_loss = 0.0021192539356985783
Trained batch 94 in epoch 2, gen_loss = 0.9600954162447076, disc_loss = 0.0021196772993885373
Trained batch 95 in epoch 2, gen_loss = 0.960479000583291, disc_loss = 0.002119270923382525
Trained batch 96 in epoch 2, gen_loss = 0.9602431593482027, disc_loss = 0.0021159699913978424
Trained batch 97 in epoch 2, gen_loss = 0.9597744570702923, disc_loss = 0.0021125722263122394
Trained batch 98 in epoch 2, gen_loss = 0.9598942585665771, disc_loss = 0.002109317478225237
Trained batch 99 in epoch 2, gen_loss = 0.9601990574598313, disc_loss = 0.0021027001284528524
Trained batch 100 in epoch 2, gen_loss = 0.9601457018663387, disc_loss = 0.0020928134759058163
Trained batch 101 in epoch 2, gen_loss = 0.9599097540565565, disc_loss = 0.0020812419283103346
Trained batch 102 in epoch 2, gen_loss = 0.9596366864963642, disc_loss = 0.0020691212939179856
Trained batch 103 in epoch 2, gen_loss = 0.9597782641649246, disc_loss = 0.0020568377988708494
Trained batch 104 in epoch 2, gen_loss = 0.9595423062642415, disc_loss = 0.0020437972913939684
Trained batch 105 in epoch 2, gen_loss = 0.9593959608167972, disc_loss = 0.002031762301724158
Trained batch 106 in epoch 2, gen_loss = 0.9591854760579974, disc_loss = 0.002023315365604673
Trained batch 107 in epoch 2, gen_loss = 0.9590831845998764, disc_loss = 0.002019104301493994
Trained batch 108 in epoch 2, gen_loss = 0.9591155784939407, disc_loss = 0.0020163343346746073
Trained batch 109 in epoch 2, gen_loss = 0.959033320166848, disc_loss = 0.0020134636386170647
Trained batch 110 in epoch 2, gen_loss = 0.958907796992912, disc_loss = 0.0020102638502705944
Trained batch 111 in epoch 2, gen_loss = 0.9590969309210777, disc_loss = 0.0020076644032087643
Trained batch 112 in epoch 2, gen_loss = 0.9588034058039168, disc_loss = 0.0020050581794982133
Trained batch 113 in epoch 2, gen_loss = 0.9588268958685691, disc_loss = 0.0020012296526897046
Trained batch 114 in epoch 2, gen_loss = 0.9586063929226087, disc_loss = 0.001995528709528077
Trained batch 115 in epoch 2, gen_loss = 0.9584749618480946, disc_loss = 0.001987500800169073
Trained batch 116 in epoch 2, gen_loss = 0.9583189013676766, disc_loss = 0.001978817232187965
Trained batch 117 in epoch 2, gen_loss = 0.9578783345424523, disc_loss = 0.0019700673376249495
Trained batch 118 in epoch 2, gen_loss = 0.9575453395603084, disc_loss = 0.001961590607744493
Trained batch 119 in epoch 2, gen_loss = 0.9572457919518153, disc_loss = 0.0019544514720716204
Trained batch 120 in epoch 2, gen_loss = 0.9572647002117693, disc_loss = 0.0019509738613274102
Trained batch 121 in epoch 2, gen_loss = 0.9577334210520885, disc_loss = 0.0019538168705709766
Trained batch 122 in epoch 2, gen_loss = 0.9578795423352622, disc_loss = 0.0019549216849850566
Trained batch 123 in epoch 2, gen_loss = 0.9578408930570849, disc_loss = 0.001955460130815364
Trained batch 124 in epoch 2, gen_loss = 0.9575521898269653, disc_loss = 0.001953130473382771
Trained batch 125 in epoch 2, gen_loss = 0.9580062921085055, disc_loss = 0.0019501183830600763
Trained batch 126 in epoch 2, gen_loss = 0.9579003232670581, disc_loss = 0.001945789068328642
Trained batch 127 in epoch 2, gen_loss = 0.957915953360498, disc_loss = 0.001941892975992232
Trained batch 128 in epoch 2, gen_loss = 0.9576855860939322, disc_loss = 0.0019389000990204224
Trained batch 129 in epoch 2, gen_loss = 0.9577621588340173, disc_loss = 0.0019386885069812146
Trained batch 130 in epoch 2, gen_loss = 0.9577506143628186, disc_loss = 0.0019434867702239683
Trained batch 131 in epoch 2, gen_loss = 0.9576681978774794, disc_loss = 0.0019503264065309795
Trained batch 132 in epoch 2, gen_loss = 0.9576027034816885, disc_loss = 0.001961696902605096
Trained batch 133 in epoch 2, gen_loss = 0.957850505166979, disc_loss = 0.001978328273416177
Trained batch 134 in epoch 2, gen_loss = 0.9577057820779306, disc_loss = 0.0019993376357618857
Trained batch 135 in epoch 2, gen_loss = 0.9576524820397881, disc_loss = 0.002021936349646079
Trained batch 136 in epoch 2, gen_loss = 0.9573273702259482, disc_loss = 0.0020456218974746385
Trained batch 137 in epoch 2, gen_loss = 0.9577731006387351, disc_loss = 0.002071394216424475
Trained batch 138 in epoch 2, gen_loss = 0.9582277210496313, disc_loss = 0.002098017689611146
Trained batch 139 in epoch 2, gen_loss = 0.9581873284918921, disc_loss = 0.0021177906501439535
Trained batch 140 in epoch 2, gen_loss = 0.9580772443020598, disc_loss = 0.0021302368886544245
Trained batch 141 in epoch 2, gen_loss = 0.9579688096550149, disc_loss = 0.0021387099437612358
Trained batch 142 in epoch 2, gen_loss = 0.9576454496050214, disc_loss = 0.002148434645952201
Trained batch 143 in epoch 2, gen_loss = 0.957813948392868, disc_loss = 0.0021578697398783537
Trained batch 144 in epoch 2, gen_loss = 0.9578031819442223, disc_loss = 0.0021649563596744478
Trained batch 145 in epoch 2, gen_loss = 0.9572850465774536, disc_loss = 0.0021710052220342197
Trained batch 146 in epoch 2, gen_loss = 0.9575151464566082, disc_loss = 0.00217688307213616
Trained batch 147 in epoch 2, gen_loss = 0.9573351950258822, disc_loss = 0.0021854773300662134
Trained batch 148 in epoch 2, gen_loss = 0.9576248026534215, disc_loss = 0.0022065755778348586
Trained batch 149 in epoch 2, gen_loss = 0.9575426602363586, disc_loss = 0.002244013041102638
Trained batch 150 in epoch 2, gen_loss = 0.9574809279662884, disc_loss = 0.002286002807016947
Trained batch 151 in epoch 2, gen_loss = 0.9573995243561896, disc_loss = 0.0023175824309490914
Trained batch 152 in epoch 2, gen_loss = 0.9573632774789349, disc_loss = 0.002334291635087259
Trained batch 153 in epoch 2, gen_loss = 0.9574122730787699, disc_loss = 0.0023400615137251844
Trained batch 154 in epoch 2, gen_loss = 0.9571466392086398, disc_loss = 0.002335605001257312
Trained batch 155 in epoch 2, gen_loss = 0.9571316486749893, disc_loss = 0.002327467911154366
Trained batch 156 in epoch 2, gen_loss = 0.9569631431512772, disc_loss = 0.0023202567530356964
Trained batch 157 in epoch 2, gen_loss = 0.956867027131817, disc_loss = 0.0023139430227677657
Trained batch 158 in epoch 2, gen_loss = 0.9570204499382643, disc_loss = 0.0023062272764648654
Trained batch 159 in epoch 2, gen_loss = 0.957289720326662, disc_loss = 0.002297763535170816
Trained batch 160 in epoch 2, gen_loss = 0.9572745702281502, disc_loss = 0.0022894139520922294
Trained batch 161 in epoch 2, gen_loss = 0.9574643494906249, disc_loss = 0.002282693313454841
Trained batch 162 in epoch 2, gen_loss = 0.9573265972312974, disc_loss = 0.0022779488032598025
Trained batch 163 in epoch 2, gen_loss = 0.9573268883112, disc_loss = 0.002275264121680066
Trained batch 164 in epoch 2, gen_loss = 0.9571922930804166, disc_loss = 0.0022711671264418823
Trained batch 165 in epoch 2, gen_loss = 0.9575081862599016, disc_loss = 0.0022680598941592343
Trained batch 166 in epoch 2, gen_loss = 0.9573820950742253, disc_loss = 0.00226376469359973
Trained batch 167 in epoch 2, gen_loss = 0.9573641412314915, disc_loss = 0.002259769231992929
Trained batch 168 in epoch 2, gen_loss = 0.9572636396927241, disc_loss = 0.0022544610681227194
Trained batch 169 in epoch 2, gen_loss = 0.9574299163678113, disc_loss = 0.002248273911433952
Trained batch 170 in epoch 2, gen_loss = 0.9572646799143295, disc_loss = 0.0022402197300941187
Trained batch 171 in epoch 2, gen_loss = 0.9569323593100836, disc_loss = 0.0022321957702271986
Trained batch 172 in epoch 2, gen_loss = 0.9569328034544267, disc_loss = 0.00222376234206301
Trained batch 173 in epoch 2, gen_loss = 0.9569507885253292, disc_loss = 0.002214891333253412
Trained batch 174 in epoch 2, gen_loss = 0.9566362380981446, disc_loss = 0.002206496136329536
Trained batch 175 in epoch 2, gen_loss = 0.9565123153681104, disc_loss = 0.0021986315385385587
Trained batch 176 in epoch 2, gen_loss = 0.9561792979132657, disc_loss = 0.002191445580091706
Trained batch 177 in epoch 2, gen_loss = 0.9565057175213032, disc_loss = 0.0021859244459826667
Trained batch 178 in epoch 2, gen_loss = 0.9564371332109973, disc_loss = 0.002181055760804522
Trained batch 179 in epoch 2, gen_loss = 0.9565421233574549, disc_loss = 0.0021772491451378705
Trained batch 180 in epoch 2, gen_loss = 0.9565100686326211, disc_loss = 0.002172819246442793
Trained batch 181 in epoch 2, gen_loss = 0.9566898159273378, disc_loss = 0.0021687889101295885
Trained batch 182 in epoch 2, gen_loss = 0.9562610544142176, disc_loss = 0.0021662846187898085
Trained batch 183 in epoch 2, gen_loss = 0.9562447003048399, disc_loss = 0.002164414450817276
Trained batch 184 in epoch 2, gen_loss = 0.9564131047274615, disc_loss = 0.0021627278233928657
Trained batch 185 in epoch 2, gen_loss = 0.9564994221092552, disc_loss = 0.0021606618353861673
Trained batch 186 in epoch 2, gen_loss = 0.9563652391739708, disc_loss = 0.0021574245426519948
Trained batch 187 in epoch 2, gen_loss = 0.956355223313291, disc_loss = 0.0021538212576489696
Trained batch 188 in epoch 2, gen_loss = 0.9562087532073732, disc_loss = 0.0021503917074013282
Trained batch 189 in epoch 2, gen_loss = 0.9563444303838831, disc_loss = 0.0021479200158194688
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 0.932725727558136, disc_loss = 0.0015490701189264655
Trained batch 1 in epoch 3, gen_loss = 0.924474686384201, disc_loss = 0.0015865078894421458
Trained batch 2 in epoch 3, gen_loss = 0.9250232974688212, disc_loss = 0.0016643754206597805
Trained batch 3 in epoch 3, gen_loss = 0.9466985613107681, disc_loss = 0.0017501497059129179
Trained batch 4 in epoch 3, gen_loss = 0.9498843073844909, disc_loss = 0.001798095740377903
Trained batch 5 in epoch 3, gen_loss = 0.9466502368450165, disc_loss = 0.0017878282815217972
Trained batch 6 in epoch 3, gen_loss = 0.9450143490518842, disc_loss = 0.0017778760687048947
Trained batch 7 in epoch 3, gen_loss = 0.945230670273304, disc_loss = 0.0017649703077040613
Trained batch 8 in epoch 3, gen_loss = 0.9435390830039978, disc_loss = 0.0017479518428444862
Trained batch 9 in epoch 3, gen_loss = 0.9445405304431915, disc_loss = 0.0017202872200869023
Trained batch 10 in epoch 3, gen_loss = 0.9436312751336531, disc_loss = 0.001674271548505534
Trained batch 11 in epoch 3, gen_loss = 0.9455826232830683, disc_loss = 0.0016256090117773663
Trained batch 12 in epoch 3, gen_loss = 0.9430283720676715, disc_loss = 0.0015739295810747605
Trained batch 13 in epoch 3, gen_loss = 0.944380909204483, disc_loss = 0.0015250667555457248
Trained batch 14 in epoch 3, gen_loss = 0.9460004806518555, disc_loss = 0.0014826115725251536
Trained batch 15 in epoch 3, gen_loss = 0.9486498795449734, disc_loss = 0.0014483171617030166
Trained batch 16 in epoch 3, gen_loss = 0.9500024774495293, disc_loss = 0.0014117543982780155
Trained batch 17 in epoch 3, gen_loss = 0.9496084484789107, disc_loss = 0.0013750196149986652
Trained batch 18 in epoch 3, gen_loss = 0.949312570847963, disc_loss = 0.0013432924874666099
Trained batch 19 in epoch 3, gen_loss = 0.9467959076166153, disc_loss = 0.0013226192677393556
Trained batch 20 in epoch 3, gen_loss = 0.9436660238674709, disc_loss = 0.0013073285642479146
Trained batch 21 in epoch 3, gen_loss = 0.9425438723780892, disc_loss = 0.0012919415709223938
Trained batch 22 in epoch 3, gen_loss = 0.9436205729194309, disc_loss = 0.001281234096614239
Trained batch 23 in epoch 3, gen_loss = 0.9433555056651434, disc_loss = 0.0012754748313454911
Trained batch 24 in epoch 3, gen_loss = 0.9442872381210328, disc_loss = 0.0012744736671447753
Trained batch 25 in epoch 3, gen_loss = 0.9457691174287063, disc_loss = 0.001270948770420196
Trained batch 26 in epoch 3, gen_loss = 0.9439713579637034, disc_loss = 0.0012539817037543765
Trained batch 27 in epoch 3, gen_loss = 0.9453353051628385, disc_loss = 0.0012563729958076561
Trained batch 28 in epoch 3, gen_loss = 0.9454093082197781, disc_loss = 0.0012917768788234941
Trained batch 29 in epoch 3, gen_loss = 0.9454497079054515, disc_loss = 0.0013385117519646883
Trained batch 30 in epoch 3, gen_loss = 0.9462658724477214, disc_loss = 0.0013626079195209087
Trained batch 31 in epoch 3, gen_loss = 0.9464674349874258, disc_loss = 0.001363953429972753
Trained batch 32 in epoch 3, gen_loss = 0.9459669030073917, disc_loss = 0.00136296568918183
Trained batch 33 in epoch 3, gen_loss = 0.9470198487534243, disc_loss = 0.0013732941965024698
Trained batch 34 in epoch 3, gen_loss = 0.9472512142998831, disc_loss = 0.0013865544992898193
Trained batch 35 in epoch 3, gen_loss = 0.9473254432280859, disc_loss = 0.0013987865143766005
Trained batch 36 in epoch 3, gen_loss = 0.9467498450665861, disc_loss = 0.0014069346597770582
Trained batch 37 in epoch 3, gen_loss = 0.9481207430362701, disc_loss = 0.001423595454788914
Trained batch 38 in epoch 3, gen_loss = 0.9479089409877093, disc_loss = 0.0014421066137938164
Trained batch 39 in epoch 3, gen_loss = 0.9487205609679222, disc_loss = 0.0014620037574786693
Trained batch 40 in epoch 3, gen_loss = 0.9482561248104747, disc_loss = 0.001485482738466888
Trained batch 41 in epoch 3, gen_loss = 0.9477067547185081, disc_loss = 0.0015064141535688015
Trained batch 42 in epoch 3, gen_loss = 0.9472296418145646, disc_loss = 0.0015198353049886782
Trained batch 43 in epoch 3, gen_loss = 0.9480944587425753, disc_loss = 0.001527832514098422
Trained batch 44 in epoch 3, gen_loss = 0.9472298741340637, disc_loss = 0.0015315971518349316
Trained batch 45 in epoch 3, gen_loss = 0.9476328971593276, disc_loss = 0.001539128521234607
Trained batch 46 in epoch 3, gen_loss = 0.9484512476210899, disc_loss = 0.0015484632037461121
Trained batch 47 in epoch 3, gen_loss = 0.949230765302976, disc_loss = 0.0015569995424205747
Trained batch 48 in epoch 3, gen_loss = 0.9486548389707293, disc_loss = 0.0015639034955173122
Trained batch 49 in epoch 3, gen_loss = 0.9492211389541626, disc_loss = 0.0015764139173552393
Trained batch 50 in epoch 3, gen_loss = 0.9495808330236697, disc_loss = 0.0015873727206067712
Trained batch 51 in epoch 3, gen_loss = 0.9491260578999152, disc_loss = 0.0015899712743703276
Trained batch 52 in epoch 3, gen_loss = 0.9481758261626622, disc_loss = 0.0015870832886441418
Trained batch 53 in epoch 3, gen_loss = 0.9483965359352253, disc_loss = 0.0015796014232802445
Trained batch 54 in epoch 3, gen_loss = 0.9478305534882979, disc_loss = 0.0015681312652304769
Trained batch 55 in epoch 3, gen_loss = 0.947652630507946, disc_loss = 0.0015557610323802301
Trained batch 56 in epoch 3, gen_loss = 0.9477549195289612, disc_loss = 0.0015431454021222236
Trained batch 57 in epoch 3, gen_loss = 0.9475872578292057, disc_loss = 0.0015300014487804909
Trained batch 58 in epoch 3, gen_loss = 0.947264131853136, disc_loss = 0.0015191163313259387
Trained batch 59 in epoch 3, gen_loss = 0.9476849397023519, disc_loss = 0.0015107976165988173
Trained batch 60 in epoch 3, gen_loss = 0.9478264353314384, disc_loss = 0.0014997801502983346
Trained batch 61 in epoch 3, gen_loss = 0.9480222559744312, disc_loss = 0.0014866029856831677
Trained batch 62 in epoch 3, gen_loss = 0.9483754909227765, disc_loss = 0.001474194165821823
Trained batch 63 in epoch 3, gen_loss = 0.9488927479833364, disc_loss = 0.0014625382564190659
Trained batch 64 in epoch 3, gen_loss = 0.9489112276297349, disc_loss = 0.0014519584795030264
Trained batch 65 in epoch 3, gen_loss = 0.9493991606163256, disc_loss = 0.0014444047057733053
Trained batch 66 in epoch 3, gen_loss = 0.9492990374565125, disc_loss = 0.0014416626385246305
Trained batch 67 in epoch 3, gen_loss = 0.9497853929505629, disc_loss = 0.0014392073969836073
Trained batch 68 in epoch 3, gen_loss = 0.9499787394551263, disc_loss = 0.0014355154311540873
Trained batch 69 in epoch 3, gen_loss = 0.9502699971199036, disc_loss = 0.0014320368770443434
Trained batch 70 in epoch 3, gen_loss = 0.9500090815651585, disc_loss = 0.0014282019233370436
Trained batch 71 in epoch 3, gen_loss = 0.9502108949753973, disc_loss = 0.001423875257185298
Trained batch 72 in epoch 3, gen_loss = 0.9505075559224168, disc_loss = 0.0014214819394473039
Trained batch 73 in epoch 3, gen_loss = 0.9506503085832338, disc_loss = 0.0014207170626488388
Trained batch 74 in epoch 3, gen_loss = 0.9496217743555705, disc_loss = 0.0014191299793310463
Trained batch 75 in epoch 3, gen_loss = 0.9499553614541104, disc_loss = 0.0014145704863997373
Trained batch 76 in epoch 3, gen_loss = 0.9497725878443036, disc_loss = 0.0014090319867124902
Trained batch 77 in epoch 3, gen_loss = 0.9493500429850358, disc_loss = 0.001404968444825126
Trained batch 78 in epoch 3, gen_loss = 0.9494637628144855, disc_loss = 0.001401762642361271
Trained batch 79 in epoch 3, gen_loss = 0.9499694392085075, disc_loss = 0.0014019434100191574
Trained batch 80 in epoch 3, gen_loss = 0.9504858034628408, disc_loss = 0.0014032304141796941
Trained batch 81 in epoch 3, gen_loss = 0.9506069312735301, disc_loss = 0.0014061478723306209
Trained batch 82 in epoch 3, gen_loss = 0.9505272306591631, disc_loss = 0.0014119260342713132
Trained batch 83 in epoch 3, gen_loss = 0.9505973742121742, disc_loss = 0.0014223303428263449
Trained batch 84 in epoch 3, gen_loss = 0.9506962292334613, disc_loss = 0.0014342597295420572
Trained batch 85 in epoch 3, gen_loss = 0.9506004265574521, disc_loss = 0.0014478626740868962
Trained batch 86 in epoch 3, gen_loss = 0.9503394125521868, disc_loss = 0.0014628839656314545
Trained batch 87 in epoch 3, gen_loss = 0.9507694244384766, disc_loss = 0.0014796744131176224
Trained batch 88 in epoch 3, gen_loss = 0.9510960511946946, disc_loss = 0.001495416769940992
Trained batch 89 in epoch 3, gen_loss = 0.9512561937173207, disc_loss = 0.00150683079005426
Trained batch 90 in epoch 3, gen_loss = 0.9511571598576976, disc_loss = 0.0015106885943428747
Trained batch 91 in epoch 3, gen_loss = 0.9520644506682521, disc_loss = 0.0015164859303141661
Trained batch 92 in epoch 3, gen_loss = 0.9525503637970135, disc_loss = 0.0015197895631264215
Trained batch 93 in epoch 3, gen_loss = 0.9528494096816854, disc_loss = 0.001525536639630755
Trained batch 94 in epoch 3, gen_loss = 0.9532418106731616, disc_loss = 0.001531112710577681
Trained batch 95 in epoch 3, gen_loss = 0.9534376692026854, disc_loss = 0.0015356400999735342
Trained batch 96 in epoch 3, gen_loss = 0.9536460650335882, disc_loss = 0.001540186413510981
Trained batch 97 in epoch 3, gen_loss = 0.9534931985699401, disc_loss = 0.0015438382070730155
Trained batch 98 in epoch 3, gen_loss = 0.9539654447574808, disc_loss = 0.0015479933389349644
Trained batch 99 in epoch 3, gen_loss = 0.9537165611982346, disc_loss = 0.001551156576606445
Trained batch 100 in epoch 3, gen_loss = 0.9538637051487914, disc_loss = 0.0015547160090334565
Trained batch 101 in epoch 3, gen_loss = 0.9538116951783498, disc_loss = 0.0015579415639341973
Trained batch 102 in epoch 3, gen_loss = 0.9540090346799314, disc_loss = 0.001560981314769467
Trained batch 103 in epoch 3, gen_loss = 0.953991738649515, disc_loss = 0.0015640604268320692
Trained batch 104 in epoch 3, gen_loss = 0.9540049246379307, disc_loss = 0.0015656862491076546
Trained batch 105 in epoch 3, gen_loss = 0.9543939407141704, disc_loss = 0.0015670795016702406
Trained batch 106 in epoch 3, gen_loss = 0.9539097096318396, disc_loss = 0.0015652424663470657
Trained batch 107 in epoch 3, gen_loss = 0.9539141417653473, disc_loss = 0.0015621313699133073
Trained batch 108 in epoch 3, gen_loss = 0.9539117337366857, disc_loss = 0.0015606583718748746
Trained batch 109 in epoch 3, gen_loss = 0.9535688990896398, disc_loss = 0.0015603050192691047
Trained batch 110 in epoch 3, gen_loss = 0.9533117338343784, disc_loss = 0.0015600142829531284
Trained batch 111 in epoch 3, gen_loss = 0.9529971890151501, disc_loss = 0.0015591195681606354
Trained batch 112 in epoch 3, gen_loss = 0.9530973386975516, disc_loss = 0.001559357922750863
Trained batch 113 in epoch 3, gen_loss = 0.95295632251522, disc_loss = 0.0015605699803002114
Trained batch 114 in epoch 3, gen_loss = 0.9529090523719788, disc_loss = 0.0015640936736219927
Trained batch 115 in epoch 3, gen_loss = 0.9529989716307871, disc_loss = 0.0015689958241198148
Trained batch 116 in epoch 3, gen_loss = 0.9525008313676231, disc_loss = 0.001573574063109441
Trained batch 117 in epoch 3, gen_loss = 0.9522991554211762, disc_loss = 0.0015755035757615973
Trained batch 118 in epoch 3, gen_loss = 0.9522972282241372, disc_loss = 0.0015765951575609628
Trained batch 119 in epoch 3, gen_loss = 0.9524998625119527, disc_loss = 0.001575764496131645
Trained batch 120 in epoch 3, gen_loss = 0.9519974249453584, disc_loss = 0.0015726366531573358
Trained batch 121 in epoch 3, gen_loss = 0.9520426592865928, disc_loss = 0.0015677002098289181
Trained batch 122 in epoch 3, gen_loss = 0.9515857381549307, disc_loss = 0.0015627115745309407
Trained batch 123 in epoch 3, gen_loss = 0.951781710309367, disc_loss = 0.0015609383399057533
Trained batch 124 in epoch 3, gen_loss = 0.9520240025520325, disc_loss = 0.0015621690284460784
Trained batch 125 in epoch 3, gen_loss = 0.9521184961001078, disc_loss = 0.001563284353959182
Trained batch 126 in epoch 3, gen_loss = 0.9519075563573461, disc_loss = 0.0015641124002400814
Trained batch 127 in epoch 3, gen_loss = 0.9519740571267903, disc_loss = 0.0015672291156079154
Trained batch 128 in epoch 3, gen_loss = 0.9522460255511972, disc_loss = 0.0015698651712777656
Trained batch 129 in epoch 3, gen_loss = 0.9520110524617709, disc_loss = 0.001569190975995018
Trained batch 130 in epoch 3, gen_loss = 0.9520571049843126, disc_loss = 0.001565551094689499
Trained batch 131 in epoch 3, gen_loss = 0.9517485720641685, disc_loss = 0.001560393502145554
Trained batch 132 in epoch 3, gen_loss = 0.9516235702019885, disc_loss = 0.0015549980838348936
Trained batch 133 in epoch 3, gen_loss = 0.9515107363017637, disc_loss = 0.0015499236248086082
Trained batch 134 in epoch 3, gen_loss = 0.9512192425904451, disc_loss = 0.0015444193285441509
Trained batch 135 in epoch 3, gen_loss = 0.951072691118016, disc_loss = 0.001538361695351983
Trained batch 136 in epoch 3, gen_loss = 0.9510184830992762, disc_loss = 0.00153210115692082
Trained batch 137 in epoch 3, gen_loss = 0.9508195787236311, disc_loss = 0.0015250527193648336
Trained batch 138 in epoch 3, gen_loss = 0.9509421625583292, disc_loss = 0.001519374829539426
Trained batch 139 in epoch 3, gen_loss = 0.950935092994145, disc_loss = 0.001516169895434619
Trained batch 140 in epoch 3, gen_loss = 0.9509291708046663, disc_loss = 0.0015149784422188945
Trained batch 141 in epoch 3, gen_loss = 0.9506223739033014, disc_loss = 0.0015145487108589215
Trained batch 142 in epoch 3, gen_loss = 0.9506752666059908, disc_loss = 0.001514827050643133
Trained batch 143 in epoch 3, gen_loss = 0.9505341487626234, disc_loss = 0.0015147143789767546
Trained batch 144 in epoch 3, gen_loss = 0.9503631201283685, disc_loss = 0.0015147811504369923
Trained batch 145 in epoch 3, gen_loss = 0.9503475521525292, disc_loss = 0.0015144522093740382
Trained batch 146 in epoch 3, gen_loss = 0.950500818336902, disc_loss = 0.0015146551035236896
Trained batch 147 in epoch 3, gen_loss = 0.9505175932033642, disc_loss = 0.0015143172613288451
Trained batch 148 in epoch 3, gen_loss = 0.9504313716952433, disc_loss = 0.0015134479777868712
Trained batch 149 in epoch 3, gen_loss = 0.9503037667274475, disc_loss = 0.0015115855141387632
Trained batch 150 in epoch 3, gen_loss = 0.9503095082889329, disc_loss = 0.0015095700344089295
Trained batch 151 in epoch 3, gen_loss = 0.9501659627023497, disc_loss = 0.0015082872088992428
Trained batch 152 in epoch 3, gen_loss = 0.9499994337169173, disc_loss = 0.0015072116664050792
Trained batch 153 in epoch 3, gen_loss = 0.950560450553894, disc_loss = 0.0015072516077228326
Trained batch 154 in epoch 3, gen_loss = 0.9504845934529458, disc_loss = 0.0015035983824711894
Trained batch 155 in epoch 3, gen_loss = 0.9508051566588573, disc_loss = 0.0014987563515135732
Trained batch 156 in epoch 3, gen_loss = 0.950939571022228, disc_loss = 0.001493261597611627
Trained batch 157 in epoch 3, gen_loss = 0.9508517441115801, disc_loss = 0.0014879937406004514
Trained batch 158 in epoch 3, gen_loss = 0.9510085541497236, disc_loss = 0.0014823789788123056
Trained batch 159 in epoch 3, gen_loss = 0.9507613759487867, disc_loss = 0.0014766989868803648
Trained batch 160 in epoch 3, gen_loss = 0.9508132064564628, disc_loss = 0.001474739618885753
Trained batch 161 in epoch 3, gen_loss = 0.9511099608592045, disc_loss = 0.0014760703086295383
Trained batch 162 in epoch 3, gen_loss = 0.9509770157147039, disc_loss = 0.0014764639849637411
Trained batch 163 in epoch 3, gen_loss = 0.9512395771538339, disc_loss = 0.0014753864709679718
Trained batch 164 in epoch 3, gen_loss = 0.951373287041982, disc_loss = 0.0014726528943742089
Trained batch 165 in epoch 3, gen_loss = 0.9512202969516617, disc_loss = 0.0014697453417360827
Trained batch 166 in epoch 3, gen_loss = 0.9514119275315793, disc_loss = 0.001468100161556556
Trained batch 167 in epoch 3, gen_loss = 0.9513537727651142, disc_loss = 0.001466948231003092
Trained batch 168 in epoch 3, gen_loss = 0.9515282197816838, disc_loss = 0.0014675397170327339
Trained batch 169 in epoch 3, gen_loss = 0.9516136428889106, disc_loss = 0.001469757266493295
Trained batch 170 in epoch 3, gen_loss = 0.9513662182099638, disc_loss = 0.0014699234205777403
Trained batch 171 in epoch 3, gen_loss = 0.9516254299601843, disc_loss = 0.001467629507397908
Trained batch 172 in epoch 3, gen_loss = 0.9514118333083357, disc_loss = 0.0014636116512819607
Trained batch 173 in epoch 3, gen_loss = 0.9516807328695538, disc_loss = 0.0014589084800728865
Trained batch 174 in epoch 3, gen_loss = 0.9518526390620641, disc_loss = 0.0014549878642096052
Trained batch 175 in epoch 3, gen_loss = 0.9519752992147749, disc_loss = 0.0014516170046011791
Trained batch 176 in epoch 3, gen_loss = 0.951868937850672, disc_loss = 0.0014486292618495218
Trained batch 177 in epoch 3, gen_loss = 0.9520691335201263, disc_loss = 0.0014470639462671713
Trained batch 178 in epoch 3, gen_loss = 0.9519796388109303, disc_loss = 0.0014463914620076103
Trained batch 179 in epoch 3, gen_loss = 0.9518855628040102, disc_loss = 0.001447170615493734
Trained batch 180 in epoch 3, gen_loss = 0.9520099057677043, disc_loss = 0.0014487924424092702
Trained batch 181 in epoch 3, gen_loss = 0.952116058422969, disc_loss = 0.0014497599034227308
Trained batch 182 in epoch 3, gen_loss = 0.9522245187577003, disc_loss = 0.0014502934948032304
Trained batch 183 in epoch 3, gen_loss = 0.9522678942784019, disc_loss = 0.0014488623637589626
Trained batch 184 in epoch 3, gen_loss = 0.9520669228321798, disc_loss = 0.001446335209294449
Trained batch 185 in epoch 3, gen_loss = 0.9520073283103204, disc_loss = 0.0014443692675496262
Trained batch 186 in epoch 3, gen_loss = 0.9521792546950559, disc_loss = 0.0014445990181458307
Trained batch 187 in epoch 3, gen_loss = 0.9519696866578244, disc_loss = 0.0014475649925558135
Trained batch 188 in epoch 3, gen_loss = 0.9518942419814054, disc_loss = 0.001453224597585008
Trained batch 189 in epoch 3, gen_loss = 0.9519887230898204, disc_loss = 0.0014597256407509313
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 0.9704598188400269, disc_loss = 0.002742303302511573
Trained batch 1 in epoch 4, gen_loss = 0.9616336524486542, disc_loss = 0.002777374116703868
Trained batch 2 in epoch 4, gen_loss = 0.9456928571065267, disc_loss = 0.0027562810573726892
Trained batch 3 in epoch 4, gen_loss = 0.9445044100284576, disc_loss = 0.0026654660468921065
Trained batch 4 in epoch 4, gen_loss = 0.959946608543396, disc_loss = 0.002614558394998312
Trained batch 5 in epoch 4, gen_loss = 0.9598292112350464, disc_loss = 0.00254917168058455
Trained batch 6 in epoch 4, gen_loss = 0.9593913129397801, disc_loss = 0.002453795451271747
Trained batch 7 in epoch 4, gen_loss = 0.9581325426697731, disc_loss = 0.0023375226446660236
Trained batch 8 in epoch 4, gen_loss = 0.9614764451980591, disc_loss = 0.002225037418409354
Trained batch 9 in epoch 4, gen_loss = 0.9613175749778747, disc_loss = 0.0021177301998250185
Trained batch 10 in epoch 4, gen_loss = 0.958035561171445, disc_loss = 0.002008075286126272
Trained batch 11 in epoch 4, gen_loss = 0.9567337036132812, disc_loss = 0.0019070269287719082
Trained batch 12 in epoch 4, gen_loss = 0.9552187002622164, disc_loss = 0.0018168798683641048
Trained batch 13 in epoch 4, gen_loss = 0.9554050181593213, disc_loss = 0.0017395309239093746
Trained batch 14 in epoch 4, gen_loss = 0.9541157046953838, disc_loss = 0.0016698775774178405
Trained batch 15 in epoch 4, gen_loss = 0.954685602337122, disc_loss = 0.0016101083419925999
Trained batch 16 in epoch 4, gen_loss = 0.9545342396287357, disc_loss = 0.0015566486159942167
Trained batch 17 in epoch 4, gen_loss = 0.9558473295635648, disc_loss = 0.0015183775362351702
Trained batch 18 in epoch 4, gen_loss = 0.9550802393963462, disc_loss = 0.0014867718564346433
Trained batch 19 in epoch 4, gen_loss = 0.9560159653425216, disc_loss = 0.0014788220229092985
Trained batch 20 in epoch 4, gen_loss = 0.9549495350746882, disc_loss = 0.0014916207541578583
Trained batch 21 in epoch 4, gen_loss = 0.9550820805809714, disc_loss = 0.0015155942740172825
Trained batch 22 in epoch 4, gen_loss = 0.9546005985011226, disc_loss = 0.001544919578641977
Trained batch 23 in epoch 4, gen_loss = 0.9556849350531896, disc_loss = 0.0015710087657983725
Trained batch 24 in epoch 4, gen_loss = 0.9555795955657959, disc_loss = 0.0015928675839677452
Trained batch 25 in epoch 4, gen_loss = 0.9549218141115628, disc_loss = 0.00161086007182558
Trained batch 26 in epoch 4, gen_loss = 0.9526351248776471, disc_loss = 0.0016286015657156153
Trained batch 27 in epoch 4, gen_loss = 0.9496697740895408, disc_loss = 0.0016588276360250478
Trained batch 28 in epoch 4, gen_loss = 0.949289843953889, disc_loss = 0.0016960015656940382
Trained batch 29 in epoch 4, gen_loss = 0.9496612668037414, disc_loss = 0.0017297401286972065
Trained batch 30 in epoch 4, gen_loss = 0.9485644332824215, disc_loss = 0.0017573404944531859
Trained batch 31 in epoch 4, gen_loss = 0.9471675809472799, disc_loss = 0.001775552696926752
Trained batch 32 in epoch 4, gen_loss = 0.9484501192063997, disc_loss = 0.001783206455663524
Trained batch 33 in epoch 4, gen_loss = 0.9475748714278726, disc_loss = 0.0017783068812123554
Trained batch 34 in epoch 4, gen_loss = 0.94781322990145, disc_loss = 0.0017720668576657772
Trained batch 35 in epoch 4, gen_loss = 0.947839692234993, disc_loss = 0.0017786638216219014
Trained batch 36 in epoch 4, gen_loss = 0.9470741603825543, disc_loss = 0.001791708158782205
Trained batch 37 in epoch 4, gen_loss = 0.9475493415405876, disc_loss = 0.0017951293143835898
Trained batch 38 in epoch 4, gen_loss = 0.9478553976768103, disc_loss = 0.0017901390510348554
Trained batch 39 in epoch 4, gen_loss = 0.9480729967355728, disc_loss = 0.0017840956483269111
Trained batch 40 in epoch 4, gen_loss = 0.9468018761495265, disc_loss = 0.0017791999725443198
Trained batch 41 in epoch 4, gen_loss = 0.9479301444121769, disc_loss = 0.0017888214123169227
Trained batch 42 in epoch 4, gen_loss = 0.9480010950288107, disc_loss = 0.0018056834815070033
Trained batch 43 in epoch 4, gen_loss = 0.9480126242746006, disc_loss = 0.0018167104439767586
Trained batch 44 in epoch 4, gen_loss = 0.9481130613221063, disc_loss = 0.0018134996217365066
Trained batch 45 in epoch 4, gen_loss = 0.9490872453088346, disc_loss = 0.001804625860962045
Trained batch 46 in epoch 4, gen_loss = 0.9487461929625653, disc_loss = 0.001791923472836138
Trained batch 47 in epoch 4, gen_loss = 0.9483669313291708, disc_loss = 0.0017754155633156188
Trained batch 48 in epoch 4, gen_loss = 0.9491117012744047, disc_loss = 0.0017563236273863182
Trained batch 49 in epoch 4, gen_loss = 0.948440545797348, disc_loss = 0.0017339389503467828
Trained batch 50 in epoch 4, gen_loss = 0.9482831826397017, disc_loss = 0.0017106171809228173
Trained batch 51 in epoch 4, gen_loss = 0.9474012290055935, disc_loss = 0.0016910755892660325
Trained batch 52 in epoch 4, gen_loss = 0.9468810209688151, disc_loss = 0.001675792889590463
Trained batch 53 in epoch 4, gen_loss = 0.946910701416157, disc_loss = 0.0016601258324010781
Trained batch 54 in epoch 4, gen_loss = 0.9474261110479182, disc_loss = 0.001644533006897704
Trained batch 55 in epoch 4, gen_loss = 0.9475856497883797, disc_loss = 0.001631011438023831
Trained batch 56 in epoch 4, gen_loss = 0.9479074112155981, disc_loss = 0.0016157946328779584
Trained batch 57 in epoch 4, gen_loss = 0.9476140665596929, disc_loss = 0.0016019840499964253
Trained batch 58 in epoch 4, gen_loss = 0.9491534909959567, disc_loss = 0.0015969597083374354
Trained batch 59 in epoch 4, gen_loss = 0.9490945527950923, disc_loss = 0.0015929926788279165
Trained batch 60 in epoch 4, gen_loss = 0.9489507088895703, disc_loss = 0.0015904923355145777
Trained batch 61 in epoch 4, gen_loss = 0.9491295872196075, disc_loss = 0.001589221367236948
Trained batch 62 in epoch 4, gen_loss = 0.9493738100642249, disc_loss = 0.0015859399970236515
Trained batch 63 in epoch 4, gen_loss = 0.9481228878721595, disc_loss = 0.0015835821977816522
Trained batch 64 in epoch 4, gen_loss = 0.9474814956004803, disc_loss = 0.0015848359666191614
Trained batch 65 in epoch 4, gen_loss = 0.9474136748097159, disc_loss = 0.0015871906494298441
Trained batch 66 in epoch 4, gen_loss = 0.9474454735642048, disc_loss = 0.0015865498093832562
Trained batch 67 in epoch 4, gen_loss = 0.947239010649569, disc_loss = 0.001582350128207027
Trained batch 68 in epoch 4, gen_loss = 0.947910916114199, disc_loss = 0.0015774482702566445
Trained batch 69 in epoch 4, gen_loss = 0.9481265485286713, disc_loss = 0.001569603440085692
Trained batch 70 in epoch 4, gen_loss = 0.947674810046881, disc_loss = 0.0015596387060162363
Trained batch 71 in epoch 4, gen_loss = 0.9474152326583862, disc_loss = 0.0015481782433602752
Trained batch 72 in epoch 4, gen_loss = 0.9467020973767319, disc_loss = 0.001538356509353098
Trained batch 73 in epoch 4, gen_loss = 0.9467829570576951, disc_loss = 0.0015323730453068543
Trained batch 74 in epoch 4, gen_loss = 0.9466984629631042, disc_loss = 0.001528563640701274
Trained batch 75 in epoch 4, gen_loss = 0.9465050313033556, disc_loss = 0.0015244334093662665
Trained batch 76 in epoch 4, gen_loss = 0.9464440353505024, disc_loss = 0.0015200319194972709
Trained batch 77 in epoch 4, gen_loss = 0.9465179237035605, disc_loss = 0.0015163632267966676
Trained batch 78 in epoch 4, gen_loss = 0.9468870728830748, disc_loss = 0.0015114218503519705
Trained batch 79 in epoch 4, gen_loss = 0.9470818035304547, disc_loss = 0.0015049726483994164
Trained batch 80 in epoch 4, gen_loss = 0.9464027881622314, disc_loss = 0.0014986232466374834
Trained batch 81 in epoch 4, gen_loss = 0.9470551217474589, disc_loss = 0.0014967177568639561
Trained batch 82 in epoch 4, gen_loss = 0.9467945414853384, disc_loss = 0.0015005599272560823
Trained batch 83 in epoch 4, gen_loss = 0.947921701839992, disc_loss = 0.0015114415201380673
Trained batch 84 in epoch 4, gen_loss = 0.9479008253882913, disc_loss = 0.0015245329574955736
Trained batch 85 in epoch 4, gen_loss = 0.9480995619019796, disc_loss = 0.0015378630744444942
Trained batch 86 in epoch 4, gen_loss = 0.948748265189686, disc_loss = 0.0015503132017329335
Trained batch 87 in epoch 4, gen_loss = 0.9487320177934386, disc_loss = 0.001556911173710515
Trained batch 88 in epoch 4, gen_loss = 0.9483908033103086, disc_loss = 0.001560120894364343
Trained batch 89 in epoch 4, gen_loss = 0.948952262269126, disc_loss = 0.0015623566992063488
Trained batch 90 in epoch 4, gen_loss = 0.9491431149807605, disc_loss = 0.001562185469083488
Trained batch 91 in epoch 4, gen_loss = 0.9491702020168304, disc_loss = 0.001558013927221865
Trained batch 92 in epoch 4, gen_loss = 0.9494243808971938, disc_loss = 0.0015508232084954136
Trained batch 93 in epoch 4, gen_loss = 0.9493230441783337, disc_loss = 0.001541993147297267
Trained batch 94 in epoch 4, gen_loss = 0.9490235472980298, disc_loss = 0.001532212163836352
Trained batch 95 in epoch 4, gen_loss = 0.9487454822907845, disc_loss = 0.0015224742304174772
Trained batch 96 in epoch 4, gen_loss = 0.9484818442580626, disc_loss = 0.0015119361942009905
Trained batch 97 in epoch 4, gen_loss = 0.9487040517281513, disc_loss = 0.0015019018984665827
Trained batch 98 in epoch 4, gen_loss = 0.9483980765246381, disc_loss = 0.0014919509542071158
Trained batch 99 in epoch 4, gen_loss = 0.9483030128479004, disc_loss = 0.0014828721998492256
Trained batch 100 in epoch 4, gen_loss = 0.9483155932756934, disc_loss = 0.0014752736908734067
Trained batch 101 in epoch 4, gen_loss = 0.9482221416398591, disc_loss = 0.0014679770375711516
Trained batch 102 in epoch 4, gen_loss = 0.9484659769002673, disc_loss = 0.001460696363740248
Trained batch 103 in epoch 4, gen_loss = 0.9483131531339425, disc_loss = 0.0014532576690096622
Trained batch 104 in epoch 4, gen_loss = 0.9483106005759466, disc_loss = 0.0014452820970854235
Trained batch 105 in epoch 4, gen_loss = 0.9481823393758738, disc_loss = 0.0014369824642034353
Trained batch 106 in epoch 4, gen_loss = 0.9481284690794544, disc_loss = 0.0014288782541396392
Trained batch 107 in epoch 4, gen_loss = 0.9482897459356873, disc_loss = 0.0014213013400202962
Trained batch 108 in epoch 4, gen_loss = 0.9481691860277718, disc_loss = 0.0014140177811837729
Trained batch 109 in epoch 4, gen_loss = 0.9482695845040408, disc_loss = 0.0014074462111404334
Trained batch 110 in epoch 4, gen_loss = 0.9486562964078542, disc_loss = 0.0014001422646656833
Trained batch 111 in epoch 4, gen_loss = 0.9490241269980159, disc_loss = 0.0013930956956755836
Trained batch 112 in epoch 4, gen_loss = 0.94902045958865, disc_loss = 0.001385888928007664
Trained batch 113 in epoch 4, gen_loss = 0.949345096161491, disc_loss = 0.0013793064725560772
Trained batch 114 in epoch 4, gen_loss = 0.949687513579493, disc_loss = 0.0013742097896402297
Trained batch 115 in epoch 4, gen_loss = 0.9499621951374514, disc_loss = 0.0013692671621764272
Trained batch 116 in epoch 4, gen_loss = 0.9502094917827182, disc_loss = 0.001364219320826551
Trained batch 117 in epoch 4, gen_loss = 0.9504924209441169, disc_loss = 0.0013597140974617736
Trained batch 118 in epoch 4, gen_loss = 0.9504250137745833, disc_loss = 0.0013541422961397143
Trained batch 119 in epoch 4, gen_loss = 0.9502772058049838, disc_loss = 0.0013479552702240956
Trained batch 120 in epoch 4, gen_loss = 0.950236729846513, disc_loss = 0.0013413105207141336
Trained batch 121 in epoch 4, gen_loss = 0.9499573052906599, disc_loss = 0.0013356818392926248
Trained batch 122 in epoch 4, gen_loss = 0.950087982464612, disc_loss = 0.0013312434558037335
Trained batch 123 in epoch 4, gen_loss = 0.9497817572086088, disc_loss = 0.0013272370232434402
Trained batch 124 in epoch 4, gen_loss = 0.9497937178611755, disc_loss = 0.001323636496439576
Trained batch 125 in epoch 4, gen_loss = 0.9501635167333815, disc_loss = 0.001320429003080501
Trained batch 126 in epoch 4, gen_loss = 0.9498593075068917, disc_loss = 0.0013177462305330972
Trained batch 127 in epoch 4, gen_loss = 0.9500775961205363, disc_loss = 0.0013168320010663592
Trained batch 128 in epoch 4, gen_loss = 0.9500666681186173, disc_loss = 0.0013152171682580844
Trained batch 129 in epoch 4, gen_loss = 0.9503145763507256, disc_loss = 0.0013139458722434938
Trained batch 130 in epoch 4, gen_loss = 0.9501770989585469, disc_loss = 0.0013146021177650976
Trained batch 131 in epoch 4, gen_loss = 0.9502139606259086, disc_loss = 0.0013157506235240196
Trained batch 132 in epoch 4, gen_loss = 0.9507639650115394, disc_loss = 0.0013200436356386408
Trained batch 133 in epoch 4, gen_loss = 0.9508292884079378, disc_loss = 0.0013257777066414814
Trained batch 134 in epoch 4, gen_loss = 0.9509586687441225, disc_loss = 0.0013332868227735161
Trained batch 135 in epoch 4, gen_loss = 0.9510625548222486, disc_loss = 0.001341682400807793
Trained batch 136 in epoch 4, gen_loss = 0.9505539153614183, disc_loss = 0.0013524950626408205
Trained batch 137 in epoch 4, gen_loss = 0.9506544742895209, disc_loss = 0.0013641137165773282
Trained batch 138 in epoch 4, gen_loss = 0.950824430520586, disc_loss = 0.001374139679133517
Trained batch 139 in epoch 4, gen_loss = 0.9504970737865993, disc_loss = 0.0013794325283795063
Trained batch 140 in epoch 4, gen_loss = 0.9502692797505263, disc_loss = 0.0013811126861602385
Trained batch 141 in epoch 4, gen_loss = 0.9505611834391742, disc_loss = 0.0013831566640464458
Trained batch 142 in epoch 4, gen_loss = 0.9505001581632174, disc_loss = 0.0013860434748010932
Trained batch 143 in epoch 4, gen_loss = 0.9506378856798013, disc_loss = 0.0013908603100895158
Trained batch 144 in epoch 4, gen_loss = 0.9506102023453548, disc_loss = 0.0013968680896956859
Trained batch 145 in epoch 4, gen_loss = 0.9506575652997787, disc_loss = 0.0014024469052594513
Trained batch 146 in epoch 4, gen_loss = 0.9505952519624412, disc_loss = 0.001406982731942062
Trained batch 147 in epoch 4, gen_loss = 0.950320088782826, disc_loss = 0.0014098424903381415
Trained batch 148 in epoch 4, gen_loss = 0.9509002534335091, disc_loss = 0.0014174696293990784
Trained batch 149 in epoch 4, gen_loss = 0.9506784387429555, disc_loss = 0.001427488122911503
Trained batch 150 in epoch 4, gen_loss = 0.9504883514334824, disc_loss = 0.0014400809998654865
Trained batch 151 in epoch 4, gen_loss = 0.9504427145186224, disc_loss = 0.0014517998183452476
Trained batch 152 in epoch 4, gen_loss = 0.9505986699870989, disc_loss = 0.0014597323709441459
Trained batch 153 in epoch 4, gen_loss = 0.9506704458942661, disc_loss = 0.0014620464470527777
Trained batch 154 in epoch 4, gen_loss = 0.9506604017749909, disc_loss = 0.0014603614897256898
Trained batch 155 in epoch 4, gen_loss = 0.9505680734530474, disc_loss = 0.00145590952776659
Trained batch 156 in epoch 4, gen_loss = 0.9504514784569953, disc_loss = 0.001450170934123171
Trained batch 157 in epoch 4, gen_loss = 0.9503960017162033, disc_loss = 0.001444111479434503
Trained batch 158 in epoch 4, gen_loss = 0.9502275893523259, disc_loss = 0.001437834501903469
Trained batch 159 in epoch 4, gen_loss = 0.9501877631992102, disc_loss = 0.0014316829163362854
Trained batch 160 in epoch 4, gen_loss = 0.9499409091398583, disc_loss = 0.0014256767208054547
Trained batch 161 in epoch 4, gen_loss = 0.9500352578398622, disc_loss = 0.0014207225174709213
Trained batch 162 in epoch 4, gen_loss = 0.9502178445184157, disc_loss = 0.0014164746741469995
Trained batch 163 in epoch 4, gen_loss = 0.9501783462559305, disc_loss = 0.0014120595983624254
Trained batch 164 in epoch 4, gen_loss = 0.9499455791531187, disc_loss = 0.0014076930948773005
Trained batch 165 in epoch 4, gen_loss = 0.9497666570795588, disc_loss = 0.0014030522555014658
Trained batch 166 in epoch 4, gen_loss = 0.949741956002698, disc_loss = 0.0013978318501233185
Trained batch 167 in epoch 4, gen_loss = 0.9500319283633005, disc_loss = 0.001393391362528616
Trained batch 168 in epoch 4, gen_loss = 0.9501242045114732, disc_loss = 0.0013892309168097425
Trained batch 169 in epoch 4, gen_loss = 0.9503096934627084, disc_loss = 0.0013854913651491242
Trained batch 170 in epoch 4, gen_loss = 0.9502229251359638, disc_loss = 0.001381594565668421
Trained batch 171 in epoch 4, gen_loss = 0.9505064300326413, disc_loss = 0.001380485852572493
Trained batch 172 in epoch 4, gen_loss = 0.9500610346049931, disc_loss = 0.0013828553180977423
Trained batch 173 in epoch 4, gen_loss = 0.9501927895792599, disc_loss = 0.0013897289358408608
Trained batch 174 in epoch 4, gen_loss = 0.9499907725197928, disc_loss = 0.001398212250288842
Trained batch 175 in epoch 4, gen_loss = 0.9501661495728926, disc_loss = 0.0014061977753127312
Trained batch 176 in epoch 4, gen_loss = 0.9497194882840087, disc_loss = 0.001411760838059077
Trained batch 177 in epoch 4, gen_loss = 0.9496853961033768, disc_loss = 0.0014135342683535843
Trained batch 178 in epoch 4, gen_loss = 0.9497080495237639, disc_loss = 0.0014127382848284327
Trained batch 179 in epoch 4, gen_loss = 0.949996081325743, disc_loss = 0.0014103925643010168
Trained batch 180 in epoch 4, gen_loss = 0.9501103887241849, disc_loss = 0.001407233212054424
Trained batch 181 in epoch 4, gen_loss = 0.9502098095286023, disc_loss = 0.0014028792068999322
Trained batch 182 in epoch 4, gen_loss = 0.9505006583010565, disc_loss = 0.001398140627698708
Trained batch 183 in epoch 4, gen_loss = 0.9504526464835458, disc_loss = 0.0013930023123975843
Trained batch 184 in epoch 4, gen_loss = 0.9504804730415344, disc_loss = 0.0013876706043988265
Trained batch 185 in epoch 4, gen_loss = 0.9502798325272017, disc_loss = 0.0013826187616789974
Trained batch 186 in epoch 4, gen_loss = 0.9503844428189936, disc_loss = 0.0013785982080536054
Trained batch 187 in epoch 4, gen_loss = 0.9504576249325529, disc_loss = 0.0013742164010182023
Trained batch 188 in epoch 4, gen_loss = 0.9506528223002398, disc_loss = 0.0013699438509151892
Trained batch 189 in epoch 4, gen_loss = 0.9505994715188679, disc_loss = 0.0013658963281685782
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 0.9278491735458374, disc_loss = 0.0006081635365262628
Trained batch 1 in epoch 5, gen_loss = 0.9417619705200195, disc_loss = 0.0006102006882429123
Trained batch 2 in epoch 5, gen_loss = 0.9268223841985067, disc_loss = 0.0005873719734760622
Trained batch 3 in epoch 5, gen_loss = 0.9425967037677765, disc_loss = 0.0005722255882574245
Trained batch 4 in epoch 5, gen_loss = 0.9571740865707398, disc_loss = 0.0005612050648778677
Trained batch 5 in epoch 5, gen_loss = 0.9480867981910706, disc_loss = 0.0005389218519364173
Trained batch 6 in epoch 5, gen_loss = 0.950270278113229, disc_loss = 0.0005218149828059333
Trained batch 7 in epoch 5, gen_loss = 0.949866384267807, disc_loss = 0.0005173409881535918
Trained batch 8 in epoch 5, gen_loss = 0.9522194862365723, disc_loss = 0.0005269417177057929
Trained batch 9 in epoch 5, gen_loss = 0.9553134262561798, disc_loss = 0.0005364822805859149
Trained batch 10 in epoch 5, gen_loss = 0.9537318240512501, disc_loss = 0.0005381538172845136
Trained batch 11 in epoch 5, gen_loss = 0.9516775061686834, disc_loss = 0.0005361493288849791
Trained batch 12 in epoch 5, gen_loss = 0.9486252573820261, disc_loss = 0.0005272505133269498
Trained batch 13 in epoch 5, gen_loss = 0.9489467442035675, disc_loss = 0.0005165049037064559
Trained batch 14 in epoch 5, gen_loss = 0.944202450911204, disc_loss = 0.0005155788327101618
Trained batch 15 in epoch 5, gen_loss = 0.9466277696192265, disc_loss = 0.0005399538076744648
Trained batch 16 in epoch 5, gen_loss = 0.9497532178373898, disc_loss = 0.0006065067633137326
Trained batch 17 in epoch 5, gen_loss = 0.9489870303206973, disc_loss = 0.0007042811630526558
Trained batch 18 in epoch 5, gen_loss = 0.9508746015398126, disc_loss = 0.0007841559877545622
Trained batch 19 in epoch 5, gen_loss = 0.9495396345853806, disc_loss = 0.0008367891437956132
Trained batch 20 in epoch 5, gen_loss = 0.9531751899492173, disc_loss = 0.0008700807326628516
Trained batch 21 in epoch 5, gen_loss = 0.9534693170677532, disc_loss = 0.0008889571618055925
Trained batch 22 in epoch 5, gen_loss = 0.9547918646231942, disc_loss = 0.0009121568278794217
Trained batch 23 in epoch 5, gen_loss = 0.9537229860822359, disc_loss = 0.0009319277511773786
Trained batch 24 in epoch 5, gen_loss = 0.9562735342979432, disc_loss = 0.0009470524557400495
Trained batch 25 in epoch 5, gen_loss = 0.9560252565603989, disc_loss = 0.0009453433729224623
Trained batch 26 in epoch 5, gen_loss = 0.9561795592308044, disc_loss = 0.0009320762959153702
Trained batch 27 in epoch 5, gen_loss = 0.956191673874855, disc_loss = 0.0009177788794789064
Trained batch 28 in epoch 5, gen_loss = 0.9570421412073332, disc_loss = 0.0009073206145268191
Trained batch 29 in epoch 5, gen_loss = 0.9562079310417175, disc_loss = 0.0008917014017545929
Trained batch 30 in epoch 5, gen_loss = 0.956677213791878, disc_loss = 0.0008778502120666446
Trained batch 31 in epoch 5, gen_loss = 0.9556866176426411, disc_loss = 0.0008690648719493765
Trained batch 32 in epoch 5, gen_loss = 0.9549993384968151, disc_loss = 0.0008690895823140939
Trained batch 33 in epoch 5, gen_loss = 0.955558321055244, disc_loss = 0.0008758973289171563
Trained batch 34 in epoch 5, gen_loss = 0.9550715463502066, disc_loss = 0.0008852151488619192
Trained batch 35 in epoch 5, gen_loss = 0.9549572649929259, disc_loss = 0.0008950217064314833
Trained batch 36 in epoch 5, gen_loss = 0.9540842304358611, disc_loss = 0.0009014353288236905
Trained batch 37 in epoch 5, gen_loss = 0.953653313611683, disc_loss = 0.0008975025174502088
Trained batch 38 in epoch 5, gen_loss = 0.9529071740615063, disc_loss = 0.0008917142419168391
Trained batch 39 in epoch 5, gen_loss = 0.951084315776825, disc_loss = 0.0008876581487129442
Trained batch 40 in epoch 5, gen_loss = 0.9506904686369547, disc_loss = 0.0008948146146949289
Trained batch 41 in epoch 5, gen_loss = 0.9492762244883037, disc_loss = 0.0009248761191321094
Trained batch 42 in epoch 5, gen_loss = 0.9499959959540256, disc_loss = 0.000987971936579967
Trained batch 43 in epoch 5, gen_loss = 0.9504310800270601, disc_loss = 0.001073954953674481
Trained batch 44 in epoch 5, gen_loss = 0.9487324396769206, disc_loss = 0.0011476838016986019
Trained batch 45 in epoch 5, gen_loss = 0.9497955856115922, disc_loss = 0.0011879179978479995
Trained batch 46 in epoch 5, gen_loss = 0.9497611040764666, disc_loss = 0.001201321191322851
Trained batch 47 in epoch 5, gen_loss = 0.9497685929139456, disc_loss = 0.0012044976938341279
Trained batch 48 in epoch 5, gen_loss = 0.9503592143253404, disc_loss = 0.0012026803546623156
Trained batch 49 in epoch 5, gen_loss = 0.9510077250003814, disc_loss = 0.0011989970679860563
Trained batch 50 in epoch 5, gen_loss = 0.9511857266519584, disc_loss = 0.0011920908844901942
Trained batch 51 in epoch 5, gen_loss = 0.9525319062746488, disc_loss = 0.0011857887965071802
Trained batch 52 in epoch 5, gen_loss = 0.9524709031266986, disc_loss = 0.0011759405298914128
Trained batch 53 in epoch 5, gen_loss = 0.9521433843506707, disc_loss = 0.0011657157005242039
Trained batch 54 in epoch 5, gen_loss = 0.9523050546646118, disc_loss = 0.0011555793525820429
Trained batch 55 in epoch 5, gen_loss = 0.951959450330053, disc_loss = 0.0011457204236648977
Trained batch 56 in epoch 5, gen_loss = 0.9524065423430058, disc_loss = 0.0011376186984738237
Trained batch 57 in epoch 5, gen_loss = 0.9522647898772667, disc_loss = 0.0011331124044553344
Trained batch 58 in epoch 5, gen_loss = 0.9522855827363871, disc_loss = 0.001135925923166323
Trained batch 59 in epoch 5, gen_loss = 0.9526889244715373, disc_loss = 0.0011429129352715486
Trained batch 60 in epoch 5, gen_loss = 0.9522591037828414, disc_loss = 0.0011452179904034758
Trained batch 61 in epoch 5, gen_loss = 0.9523294346947824, disc_loss = 0.0011429325292532844
Trained batch 62 in epoch 5, gen_loss = 0.952395634991782, disc_loss = 0.0011413126439225698
Trained batch 63 in epoch 5, gen_loss = 0.9529121648520231, disc_loss = 0.0011444757046774612
Trained batch 64 in epoch 5, gen_loss = 0.9532327798696665, disc_loss = 0.001155019686736453
Trained batch 65 in epoch 5, gen_loss = 0.9536210280476194, disc_loss = 0.0011677116668910128
Trained batch 66 in epoch 5, gen_loss = 0.9536771356169857, disc_loss = 0.0011768724218553016
Trained batch 67 in epoch 5, gen_loss = 0.953882007914431, disc_loss = 0.00118221875249326
Trained batch 68 in epoch 5, gen_loss = 0.953390575837398, disc_loss = 0.001184817402711327
Trained batch 69 in epoch 5, gen_loss = 0.9531890324183873, disc_loss = 0.0011874272097234747
Trained batch 70 in epoch 5, gen_loss = 0.9528577923774719, disc_loss = 0.00119223969440881
Trained batch 71 in epoch 5, gen_loss = 0.953656442463398, disc_loss = 0.0012039092422734636
Trained batch 72 in epoch 5, gen_loss = 0.9540604459096308, disc_loss = 0.0012146026471770075
Trained batch 73 in epoch 5, gen_loss = 0.9539009340711542, disc_loss = 0.0012200872855877656
Trained batch 74 in epoch 5, gen_loss = 0.954286421140035, disc_loss = 0.001220778376640131
Trained batch 75 in epoch 5, gen_loss = 0.9537755078391025, disc_loss = 0.001218865214277206
Trained batch 76 in epoch 5, gen_loss = 0.953061046538415, disc_loss = 0.0012140495486424438
Trained batch 77 in epoch 5, gen_loss = 0.9528913352734003, disc_loss = 0.0012079610284835768
Trained batch 78 in epoch 5, gen_loss = 0.9532333748250068, disc_loss = 0.0012037208314124447
Trained batch 79 in epoch 5, gen_loss = 0.9525081187486648, disc_loss = 0.0012028919118165504
Trained batch 80 in epoch 5, gen_loss = 0.9528793184845535, disc_loss = 0.0012137928889937883
Trained batch 81 in epoch 5, gen_loss = 0.9526120904015332, disc_loss = 0.001237509396671113
Trained batch 82 in epoch 5, gen_loss = 0.9528696623193212, disc_loss = 0.001270130960444684
Trained batch 83 in epoch 5, gen_loss = 0.9529833445946375, disc_loss = 0.0013009904671759745
Trained batch 84 in epoch 5, gen_loss = 0.9525503509184894, disc_loss = 0.0013231656205949975
Trained batch 85 in epoch 5, gen_loss = 0.9521525259627852, disc_loss = 0.001336632867013429
Trained batch 86 in epoch 5, gen_loss = 0.9514027087167761, disc_loss = 0.0013418968642483755
Trained batch 87 in epoch 5, gen_loss = 0.9513246796347878, disc_loss = 0.0013396438358044675
Trained batch 88 in epoch 5, gen_loss = 0.9510374223248342, disc_loss = 0.0013336834512138215
Trained batch 89 in epoch 5, gen_loss = 0.9507413135634528, disc_loss = 0.0013249674598531176
Trained batch 90 in epoch 5, gen_loss = 0.9511045414012868, disc_loss = 0.0013146763529940661
Trained batch 91 in epoch 5, gen_loss = 0.9509564068006433, disc_loss = 0.0013047453713901948
Trained batch 92 in epoch 5, gen_loss = 0.9512207956724269, disc_loss = 0.001295330562761494
Trained batch 93 in epoch 5, gen_loss = 0.9511454016604322, disc_loss = 0.001285884193419677
Trained batch 94 in epoch 5, gen_loss = 0.9508739829063415, disc_loss = 0.0012756596389839328
Trained batch 95 in epoch 5, gen_loss = 0.9504791727910439, disc_loss = 0.0012653085574735694
Trained batch 96 in epoch 5, gen_loss = 0.9502013559193955, disc_loss = 0.0012550115445508745
Trained batch 97 in epoch 5, gen_loss = 0.9501640936549829, disc_loss = 0.0012451067058445544
Trained batch 98 in epoch 5, gen_loss = 0.9505477373046104, disc_loss = 0.0012363953065512834
Trained batch 99 in epoch 5, gen_loss = 0.9506101942062378, disc_loss = 0.0012291832169285045
Trained batch 100 in epoch 5, gen_loss = 0.951042639146937, disc_loss = 0.0012246610782348948
Trained batch 101 in epoch 5, gen_loss = 0.9505960286832323, disc_loss = 0.0012240899497341802
Trained batch 102 in epoch 5, gen_loss = 0.9507803442408738, disc_loss = 0.0012277649332389452
Trained batch 103 in epoch 5, gen_loss = 0.9506674087964572, disc_loss = 0.0012328952283356697
Trained batch 104 in epoch 5, gen_loss = 0.9504977663358053, disc_loss = 0.001235240529890039
Trained batch 105 in epoch 5, gen_loss = 0.9503483468631528, disc_loss = 0.0012330618958243714
Trained batch 106 in epoch 5, gen_loss = 0.9503784892715026, disc_loss = 0.00122845906570606
Trained batch 107 in epoch 5, gen_loss = 0.9500815349596518, disc_loss = 0.001222365385425898
Trained batch 108 in epoch 5, gen_loss = 0.9504555906724492, disc_loss = 0.0012160040264086235
Trained batch 109 in epoch 5, gen_loss = 0.9498675254258242, disc_loss = 0.0012096360881431875
Trained batch 110 in epoch 5, gen_loss = 0.9498501022656759, disc_loss = 0.00120440227774534
Trained batch 111 in epoch 5, gen_loss = 0.9499393031001091, disc_loss = 0.0012001525761401613
Trained batch 112 in epoch 5, gen_loss = 0.9494197832799591, disc_loss = 0.001196321422456706
Trained batch 113 in epoch 5, gen_loss = 0.9494335583427496, disc_loss = 0.001192209481367874
Trained batch 114 in epoch 5, gen_loss = 0.9495357487512671, disc_loss = 0.0011880496547192984
Trained batch 115 in epoch 5, gen_loss = 0.9498373773591272, disc_loss = 0.0011842630899928767
Trained batch 116 in epoch 5, gen_loss = 0.9493754638565911, disc_loss = 0.0011810594114960514
Trained batch 117 in epoch 5, gen_loss = 0.9496507715370696, disc_loss = 0.0011805701937715885
Trained batch 118 in epoch 5, gen_loss = 0.9499560970218242, disc_loss = 0.0011827744662902561
Trained batch 119 in epoch 5, gen_loss = 0.949863021572431, disc_loss = 0.0011847781531590348
Trained batch 120 in epoch 5, gen_loss = 0.9502862987439494, disc_loss = 0.0011864443634798335
Trained batch 121 in epoch 5, gen_loss = 0.9505779577083275, disc_loss = 0.0011893086475091147
Trained batch 122 in epoch 5, gen_loss = 0.9506339639182982, disc_loss = 0.0011943418123736614
Trained batch 123 in epoch 5, gen_loss = 0.9505709976919235, disc_loss = 0.0011989584064952309
Trained batch 124 in epoch 5, gen_loss = 0.9504430379867553, disc_loss = 0.0012017209529876709
Trained batch 125 in epoch 5, gen_loss = 0.9507184227307638, disc_loss = 0.001203493909939887
Trained batch 126 in epoch 5, gen_loss = 0.9506319249708821, disc_loss = 0.0012035956019608993
Trained batch 127 in epoch 5, gen_loss = 0.9505505175329745, disc_loss = 0.0012015780739602633
Trained batch 128 in epoch 5, gen_loss = 0.9504572259363278, disc_loss = 0.0011988964406484666
Trained batch 129 in epoch 5, gen_loss = 0.9502259084811577, disc_loss = 0.0011953791881051774
Trained batch 130 in epoch 5, gen_loss = 0.9500011110123787, disc_loss = 0.0011911432450736753
Trained batch 131 in epoch 5, gen_loss = 0.9501534587506092, disc_loss = 0.001187197662092689
Trained batch 132 in epoch 5, gen_loss = 0.9501499690507588, disc_loss = 0.0011830494832772678
Trained batch 133 in epoch 5, gen_loss = 0.9500218104960313, disc_loss = 0.0011784395488820024
Trained batch 134 in epoch 5, gen_loss = 0.9501290277198509, disc_loss = 0.0011735128251732223
Trained batch 135 in epoch 5, gen_loss = 0.9500224546474569, disc_loss = 0.0011684144269298378
Trained batch 136 in epoch 5, gen_loss = 0.9500356829949539, disc_loss = 0.0011628745227838003
Trained batch 137 in epoch 5, gen_loss = 0.9497417500917462, disc_loss = 0.0011573058771951448
Trained batch 138 in epoch 5, gen_loss = 0.9498691704633425, disc_loss = 0.0011519805480903617
Trained batch 139 in epoch 5, gen_loss = 0.9501123015369688, disc_loss = 0.001147657356133485
Trained batch 140 in epoch 5, gen_loss = 0.9500960094708923, disc_loss = 0.0011440209042469158
Trained batch 141 in epoch 5, gen_loss = 0.9502853297851455, disc_loss = 0.001140650293935733
Trained batch 142 in epoch 5, gen_loss = 0.9502342234958302, disc_loss = 0.0011374175964148025
Trained batch 143 in epoch 5, gen_loss = 0.9505034453339047, disc_loss = 0.0011347720818674942
Trained batch 144 in epoch 5, gen_loss = 0.950062685999377, disc_loss = 0.0011326685943239337
Trained batch 145 in epoch 5, gen_loss = 0.9500330898859729, disc_loss = 0.001131758490323778
Trained batch 146 in epoch 5, gen_loss = 0.9501360942717312, disc_loss = 0.0011322245013276051
Trained batch 147 in epoch 5, gen_loss = 0.9497568196541554, disc_loss = 0.0011326852138547503
Trained batch 148 in epoch 5, gen_loss = 0.9495135269709082, disc_loss = 0.0011342329001632339
Trained batch 149 in epoch 5, gen_loss = 0.9496123659610748, disc_loss = 0.0011354387297372644
Trained batch 150 in epoch 5, gen_loss = 0.9492795672637737, disc_loss = 0.0011364476115748113
Trained batch 151 in epoch 5, gen_loss = 0.9492388591170311, disc_loss = 0.0011360710657180263
Trained batch 152 in epoch 5, gen_loss = 0.9492839041099049, disc_loss = 0.0011344061644361324
Trained batch 153 in epoch 5, gen_loss = 0.9491944313049316, disc_loss = 0.0011315554572804529
Trained batch 154 in epoch 5, gen_loss = 0.9489151970032723, disc_loss = 0.001128311684888397
Trained batch 155 in epoch 5, gen_loss = 0.9487240333587695, disc_loss = 0.0011249950611948944
Trained batch 156 in epoch 5, gen_loss = 0.9488059544259575, disc_loss = 0.001121559149732481
Trained batch 157 in epoch 5, gen_loss = 0.9483691582196876, disc_loss = 0.0011184444557801713
Trained batch 158 in epoch 5, gen_loss = 0.9486289909050899, disc_loss = 0.0011191126528421545
Trained batch 159 in epoch 5, gen_loss = 0.9487262524664402, disc_loss = 0.0011242525220950482
Trained batch 160 in epoch 5, gen_loss = 0.9489413366554686, disc_loss = 0.0011332735152819674
Trained batch 161 in epoch 5, gen_loss = 0.9489897872194831, disc_loss = 0.001144512534036623
Trained batch 162 in epoch 5, gen_loss = 0.9489792142908997, disc_loss = 0.0011560396479508423
Trained batch 163 in epoch 5, gen_loss = 0.9490897622777195, disc_loss = 0.0011659537677343639
Trained batch 164 in epoch 5, gen_loss = 0.9491786729205739, disc_loss = 0.00117364778151651
Trained batch 165 in epoch 5, gen_loss = 0.9493685867412981, disc_loss = 0.0011802993226355974
Trained batch 166 in epoch 5, gen_loss = 0.9493741189648292, disc_loss = 0.0011862966510492326
Trained batch 167 in epoch 5, gen_loss = 0.9493661416428429, disc_loss = 0.0011906519570662308
Trained batch 168 in epoch 5, gen_loss = 0.9494364600209795, disc_loss = 0.0011937685099708676
Trained batch 169 in epoch 5, gen_loss = 0.9495119585710413, disc_loss = 0.0011950460151317255
Trained batch 170 in epoch 5, gen_loss = 0.9494932408918414, disc_loss = 0.0011945752451150019
Trained batch 171 in epoch 5, gen_loss = 0.9494891901348912, disc_loss = 0.0011925483432119214
Trained batch 172 in epoch 5, gen_loss = 0.9492057155322478, disc_loss = 0.001189560793451911
Trained batch 173 in epoch 5, gen_loss = 0.948942180337577, disc_loss = 0.0011859826394691314
Trained batch 174 in epoch 5, gen_loss = 0.9489808314187186, disc_loss = 0.0011820484373518932
Trained batch 175 in epoch 5, gen_loss = 0.9491589712825689, disc_loss = 0.001178591251697402
Trained batch 176 in epoch 5, gen_loss = 0.9493205486717871, disc_loss = 0.0011750120200324636
Trained batch 177 in epoch 5, gen_loss = 0.949242328659872, disc_loss = 0.001171647646729939
Trained batch 178 in epoch 5, gen_loss = 0.9493341895455089, disc_loss = 0.0011686983519277989
Trained batch 179 in epoch 5, gen_loss = 0.9494770735502243, disc_loss = 0.0011654097177799688
Trained batch 180 in epoch 5, gen_loss = 0.9494607089632783, disc_loss = 0.001161936640473165
Trained batch 181 in epoch 5, gen_loss = 0.949582101552041, disc_loss = 0.0011582850012608426
Trained batch 182 in epoch 5, gen_loss = 0.9497328915231215, disc_loss = 0.0011542901955608564
Trained batch 183 in epoch 5, gen_loss = 0.9492355024685031, disc_loss = 0.0011504329410419577
Trained batch 184 in epoch 5, gen_loss = 0.949304584876911, disc_loss = 0.0011480970898127133
Trained batch 185 in epoch 5, gen_loss = 0.9494724302522598, disc_loss = 0.0011481876490995668
Trained batch 186 in epoch 5, gen_loss = 0.9497452901008933, disc_loss = 0.0011497594583916532
Trained batch 187 in epoch 5, gen_loss = 0.9500133709070531, disc_loss = 0.0011501788999823397
Trained batch 188 in epoch 5, gen_loss = 0.9500620166460673, disc_loss = 0.0011496266457018142
Trained batch 189 in epoch 5, gen_loss = 0.949997752904892, disc_loss = 0.0011481668510609062
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 0.9272998571395874, disc_loss = 0.000685904233250767
Trained batch 1 in epoch 6, gen_loss = 0.9320755004882812, disc_loss = 0.0006634099700022489
Trained batch 2 in epoch 6, gen_loss = 0.9336068431536356, disc_loss = 0.000648253228670607
Trained batch 3 in epoch 6, gen_loss = 0.9405805915594101, disc_loss = 0.0006017566629452631
Trained batch 4 in epoch 6, gen_loss = 0.9602185368537903, disc_loss = 0.0005869047832675278
Trained batch 5 in epoch 6, gen_loss = 0.9599729279677073, disc_loss = 0.0005741274023118118
Trained batch 6 in epoch 6, gen_loss = 0.9633909378732953, disc_loss = 0.0005595348692233009
Trained batch 7 in epoch 6, gen_loss = 0.9620271995663643, disc_loss = 0.0005529830377781764
Trained batch 8 in epoch 6, gen_loss = 0.9585070212682089, disc_loss = 0.0005510133018510209
Trained batch 9 in epoch 6, gen_loss = 0.9596623778343201, disc_loss = 0.000546537316404283
Trained batch 10 in epoch 6, gen_loss = 0.9562270099466498, disc_loss = 0.0005434678380631588
Trained batch 11 in epoch 6, gen_loss = 0.9561925232410431, disc_loss = 0.00054755131714046
Trained batch 12 in epoch 6, gen_loss = 0.9576978316673865, disc_loss = 0.0005696114295950303
Trained batch 13 in epoch 6, gen_loss = 0.9578937632696969, disc_loss = 0.0006076073456954743
Trained batch 14 in epoch 6, gen_loss = 0.9558942159016927, disc_loss = 0.0006605311840151747
Trained batch 15 in epoch 6, gen_loss = 0.9536731876432896, disc_loss = 0.0007221159248729236
Trained batch 16 in epoch 6, gen_loss = 0.9525142802911646, disc_loss = 0.0007854633731767535
Trained batch 17 in epoch 6, gen_loss = 0.9513496458530426, disc_loss = 0.000832959912562122
Trained batch 18 in epoch 6, gen_loss = 0.953097497162066, disc_loss = 0.0008709570944407268
Trained batch 19 in epoch 6, gen_loss = 0.9529643505811691, disc_loss = 0.0009036104951519519
Trained batch 20 in epoch 6, gen_loss = 0.953958389304933, disc_loss = 0.0009291102122958927
Trained batch 21 in epoch 6, gen_loss = 0.9544635875658556, disc_loss = 0.0009463462311859158
Trained batch 22 in epoch 6, gen_loss = 0.9542912348457004, disc_loss = 0.0009600948542356491
Trained batch 23 in epoch 6, gen_loss = 0.9533805946509043, disc_loss = 0.0009705748040384302
Trained batch 24 in epoch 6, gen_loss = 0.9548910903930664, disc_loss = 0.0009802408050745726
Trained batch 25 in epoch 6, gen_loss = 0.9533562018321111, disc_loss = 0.00099027633237151
Trained batch 26 in epoch 6, gen_loss = 0.952818716013873, disc_loss = 0.0010012048857148599
Trained batch 27 in epoch 6, gen_loss = 0.9545554688998631, disc_loss = 0.0010172753287146666
Trained batch 28 in epoch 6, gen_loss = 0.9555103429432573, disc_loss = 0.0010319787262264512
Trained batch 29 in epoch 6, gen_loss = 0.9551090657711029, disc_loss = 0.0010505510532918076
Trained batch 30 in epoch 6, gen_loss = 0.9551247915913982, disc_loss = 0.001070101024402726
Trained batch 31 in epoch 6, gen_loss = 0.9535065684467554, disc_loss = 0.0010873447718040552
Trained batch 32 in epoch 6, gen_loss = 0.9513079289234045, disc_loss = 0.0011041042373769662
Trained batch 33 in epoch 6, gen_loss = 0.952236129957087, disc_loss = 0.001114676525021958
Trained batch 34 in epoch 6, gen_loss = 0.9522722550800868, disc_loss = 0.0011213512991421989
Trained batch 35 in epoch 6, gen_loss = 0.9520627872811424, disc_loss = 0.0011266395999377386
Trained batch 36 in epoch 6, gen_loss = 0.952240671660449, disc_loss = 0.0011295812500238015
Trained batch 37 in epoch 6, gen_loss = 0.952169584600549, disc_loss = 0.0011290768130780443
Trained batch 38 in epoch 6, gen_loss = 0.9532215075615125, disc_loss = 0.0011285619141581731
Trained batch 39 in epoch 6, gen_loss = 0.952215987443924, disc_loss = 0.0011281310464255512
Trained batch 40 in epoch 6, gen_loss = 0.9523218724785781, disc_loss = 0.0011283686617389321
Trained batch 41 in epoch 6, gen_loss = 0.9516801465125311, disc_loss = 0.001125696275959767
Trained batch 42 in epoch 6, gen_loss = 0.9522458952526713, disc_loss = 0.0011219609255339344
Trained batch 43 in epoch 6, gen_loss = 0.9517272927544334, disc_loss = 0.001116343166689727
Trained batch 44 in epoch 6, gen_loss = 0.9516740798950195, disc_loss = 0.0011084821592602465
Trained batch 45 in epoch 6, gen_loss = 0.9510101805562559, disc_loss = 0.001100357977481073
Trained batch 46 in epoch 6, gen_loss = 0.9508732050023181, disc_loss = 0.0010935556046922314
Trained batch 47 in epoch 6, gen_loss = 0.9510191194713116, disc_loss = 0.0010852217443850047
Trained batch 48 in epoch 6, gen_loss = 0.9512751528194973, disc_loss = 0.0010754371962357996
Trained batch 49 in epoch 6, gen_loss = 0.950777039527893, disc_loss = 0.0010669162648264318
Trained batch 50 in epoch 6, gen_loss = 0.9503952685524436, disc_loss = 0.0010580404755184609
Trained batch 51 in epoch 6, gen_loss = 0.9499475543315594, disc_loss = 0.0010500607929246214
Trained batch 52 in epoch 6, gen_loss = 0.9497641887304917, disc_loss = 0.0010421741457287011
Trained batch 53 in epoch 6, gen_loss = 0.9507082612426193, disc_loss = 0.0010340342134306276
Trained batch 54 in epoch 6, gen_loss = 0.9500309467315674, disc_loss = 0.001024852789388123
Trained batch 55 in epoch 6, gen_loss = 0.9499274268746376, disc_loss = 0.0010150148071781068
Trained batch 56 in epoch 6, gen_loss = 0.949108878771464, disc_loss = 0.0010052189959025239
Trained batch 57 in epoch 6, gen_loss = 0.9497649135260746, disc_loss = 0.0009994051948085364
Trained batch 58 in epoch 6, gen_loss = 0.9498353337837477, disc_loss = 0.0009981463875392673
Trained batch 59 in epoch 6, gen_loss = 0.949443859855334, disc_loss = 0.00099915029083301
Trained batch 60 in epoch 6, gen_loss = 0.9488696817491875, disc_loss = 0.0010009944170797397
Trained batch 61 in epoch 6, gen_loss = 0.9497022474965742, disc_loss = 0.0010032473829567371
Trained batch 62 in epoch 6, gen_loss = 0.9493427314455547, disc_loss = 0.0010016544140867948
Trained batch 63 in epoch 6, gen_loss = 0.9492661971598864, disc_loss = 0.000997833657947922
Trained batch 64 in epoch 6, gen_loss = 0.9493153040225689, disc_loss = 0.000992818273908387
Trained batch 65 in epoch 6, gen_loss = 0.948525734020002, disc_loss = 0.000987485817114992
Trained batch 66 in epoch 6, gen_loss = 0.9484644514411243, disc_loss = 0.0009813223154902626
Trained batch 67 in epoch 6, gen_loss = 0.9486734051914776, disc_loss = 0.0009744724884512834
Trained batch 68 in epoch 6, gen_loss = 0.9475751579671666, disc_loss = 0.0009661172267785161
Trained batch 69 in epoch 6, gen_loss = 0.9471859693527221, disc_loss = 0.0009571303418072473
Trained batch 70 in epoch 6, gen_loss = 0.9471191663137624, disc_loss = 0.0009482512865412299
Trained batch 71 in epoch 6, gen_loss = 0.9473634047640694, disc_loss = 0.0009392190044713465
Trained batch 72 in epoch 6, gen_loss = 0.9474088737409408, disc_loss = 0.0009303240720278341
Trained batch 73 in epoch 6, gen_loss = 0.9477499650942313, disc_loss = 0.0009217689209460357
Trained batch 74 in epoch 6, gen_loss = 0.9479106632868449, disc_loss = 0.0009130179482356956
Trained batch 75 in epoch 6, gen_loss = 0.947537539820922, disc_loss = 0.0009040290495154055
Trained batch 76 in epoch 6, gen_loss = 0.9478301614909977, disc_loss = 0.0008958462960624994
Trained batch 77 in epoch 6, gen_loss = 0.9471885370902526, disc_loss = 0.0008873341618872916
Trained batch 78 in epoch 6, gen_loss = 0.9473849286006976, disc_loss = 0.0008794145492462535
Trained batch 79 in epoch 6, gen_loss = 0.9475270234048366, disc_loss = 0.0008719701590962359
Trained batch 80 in epoch 6, gen_loss = 0.9479235638806849, disc_loss = 0.0008652424822449339
Trained batch 81 in epoch 6, gen_loss = 0.9475377238378292, disc_loss = 0.0008590974372587303
Trained batch 82 in epoch 6, gen_loss = 0.9477644605808947, disc_loss = 0.0008537711181848994
Trained batch 83 in epoch 6, gen_loss = 0.9475126003935224, disc_loss = 0.0008497199750785338
Trained batch 84 in epoch 6, gen_loss = 0.9477725547902724, disc_loss = 0.0008476244636660661
Trained batch 85 in epoch 6, gen_loss = 0.9473710974981618, disc_loss = 0.0008477989516862624
Trained batch 86 in epoch 6, gen_loss = 0.947010859675791, disc_loss = 0.0008490738927603474
Trained batch 87 in epoch 6, gen_loss = 0.9475527527657422, disc_loss = 0.0008515130593877984
Trained batch 88 in epoch 6, gen_loss = 0.9468936290633813, disc_loss = 0.0008547651547784236
Trained batch 89 in epoch 6, gen_loss = 0.946957959069146, disc_loss = 0.0008590823254457468
Trained batch 90 in epoch 6, gen_loss = 0.9468723083590413, disc_loss = 0.0008641523560112506
Trained batch 91 in epoch 6, gen_loss = 0.9463744604069254, disc_loss = 0.0008694728143303149
Trained batch 92 in epoch 6, gen_loss = 0.9466479773162514, disc_loss = 0.0008759934397887498
Trained batch 93 in epoch 6, gen_loss = 0.9471075617252512, disc_loss = 0.0008841358019011789
Trained batch 94 in epoch 6, gen_loss = 0.9472559157170748, disc_loss = 0.0008919091976407033
Trained batch 95 in epoch 6, gen_loss = 0.9473040470232567, disc_loss = 0.0008978204358148408
Trained batch 96 in epoch 6, gen_loss = 0.9476530533475974, disc_loss = 0.0009022045254373693
Trained batch 97 in epoch 6, gen_loss = 0.9479827205745541, disc_loss = 0.0009066953737471652
Trained batch 98 in epoch 6, gen_loss = 0.9472831987371348, disc_loss = 0.000912007314389374
Trained batch 99 in epoch 6, gen_loss = 0.9480301266908646, disc_loss = 0.0009161869653325994
Trained batch 100 in epoch 6, gen_loss = 0.9484684455512774, disc_loss = 0.0009168986869932125
Trained batch 101 in epoch 6, gen_loss = 0.9484904186398375, disc_loss = 0.0009164163044153932
Trained batch 102 in epoch 6, gen_loss = 0.9480507512694424, disc_loss = 0.0009143223887980799
Trained batch 103 in epoch 6, gen_loss = 0.9482772138256294, disc_loss = 0.0009103160433509261
Trained batch 104 in epoch 6, gen_loss = 0.9481916007541474, disc_loss = 0.0009052402080713017
Trained batch 105 in epoch 6, gen_loss = 0.9480112369330425, disc_loss = 0.0009001486201359856
Trained batch 106 in epoch 6, gen_loss = 0.9487737912998021, disc_loss = 0.0008980620046696739
Trained batch 107 in epoch 6, gen_loss = 0.9483735075703373, disc_loss = 0.0008996384795291642
Trained batch 108 in epoch 6, gen_loss = 0.948763658694171, disc_loss = 0.0009063057818529068
Trained batch 109 in epoch 6, gen_loss = 0.9488542540506884, disc_loss = 0.0009165015951359899
Trained batch 110 in epoch 6, gen_loss = 0.9489065086519396, disc_loss = 0.0009280108304763515
Trained batch 111 in epoch 6, gen_loss = 0.9492732829281262, disc_loss = 0.0009394793878527707
Trained batch 112 in epoch 6, gen_loss = 0.9493868772962452, disc_loss = 0.0009501205719399588
Trained batch 113 in epoch 6, gen_loss = 0.9491778748077259, disc_loss = 0.000960783302919784
Trained batch 114 in epoch 6, gen_loss = 0.9489647124124609, disc_loss = 0.0009726150580125091
Trained batch 115 in epoch 6, gen_loss = 0.9491901022606882, disc_loss = 0.000985539710106015
Trained batch 116 in epoch 6, gen_loss = 0.9490355176803393, disc_loss = 0.00099915265750924
Trained batch 117 in epoch 6, gen_loss = 0.9493460882518251, disc_loss = 0.001012466197869922
Trained batch 118 in epoch 6, gen_loss = 0.9492713864110097, disc_loss = 0.0010240192735663561
Trained batch 119 in epoch 6, gen_loss = 0.9493153189619382, disc_loss = 0.001034119216031589
Trained batch 120 in epoch 6, gen_loss = 0.949067490652573, disc_loss = 0.0010438488464665884
Trained batch 121 in epoch 6, gen_loss = 0.9491939603305254, disc_loss = 0.0010513749354581928
Trained batch 122 in epoch 6, gen_loss = 0.9490077931706499, disc_loss = 0.0010564536750893964
Trained batch 123 in epoch 6, gen_loss = 0.9489759562476989, disc_loss = 0.0010596059391607396
Trained batch 124 in epoch 6, gen_loss = 0.9493414626121521, disc_loss = 0.0010600183225469664
Trained batch 125 in epoch 6, gen_loss = 0.9496317548411233, disc_loss = 0.0010587042928645609
Trained batch 126 in epoch 6, gen_loss = 0.949496010157067, disc_loss = 0.0010576455384780704
Trained batch 127 in epoch 6, gen_loss = 0.9494453798979521, disc_loss = 0.0010576340606576196
Trained batch 128 in epoch 6, gen_loss = 0.9497109101724255, disc_loss = 0.0010569561269475408
Trained batch 129 in epoch 6, gen_loss = 0.9495758074980516, disc_loss = 0.001054604686550402
Trained batch 130 in epoch 6, gen_loss = 0.9492706137759085, disc_loss = 0.0010516311701623553
Trained batch 131 in epoch 6, gen_loss = 0.9489673281257803, disc_loss = 0.0010483741305396313
Trained batch 132 in epoch 6, gen_loss = 0.9488179056267989, disc_loss = 0.0010452354454857304
Trained batch 133 in epoch 6, gen_loss = 0.9487599997378108, disc_loss = 0.0010425766119637888
Trained batch 134 in epoch 6, gen_loss = 0.9487996017491376, disc_loss = 0.0010410143205835656
Trained batch 135 in epoch 6, gen_loss = 0.9487914670916164, disc_loss = 0.0010408442395761514
Trained batch 136 in epoch 6, gen_loss = 0.9486594861441285, disc_loss = 0.0010427793622378898
Trained batch 137 in epoch 6, gen_loss = 0.9489750862121582, disc_loss = 0.0010459474124481726
Trained batch 138 in epoch 6, gen_loss = 0.9489843909688991, disc_loss = 0.0010499287805588674
Trained batch 139 in epoch 6, gen_loss = 0.949139171413013, disc_loss = 0.0010561735183208449
Trained batch 140 in epoch 6, gen_loss = 0.949333094958718, disc_loss = 0.0010653420774380062
Trained batch 141 in epoch 6, gen_loss = 0.949146396677259, disc_loss = 0.0010763461252512134
Trained batch 142 in epoch 6, gen_loss = 0.9492546782626973, disc_loss = 0.0010874602579148617
Trained batch 143 in epoch 6, gen_loss = 0.949455778217978, disc_loss = 0.0010964778902133629
Trained batch 144 in epoch 6, gen_loss = 0.9495247203728249, disc_loss = 0.0011028138050560615
Trained batch 145 in epoch 6, gen_loss = 0.9494083695215721, disc_loss = 0.0011057871205880537
Trained batch 146 in epoch 6, gen_loss = 0.9491107844982017, disc_loss = 0.001105576531575885
Trained batch 147 in epoch 6, gen_loss = 0.9489525999571826, disc_loss = 0.001103274503858867
Trained batch 148 in epoch 6, gen_loss = 0.9490637031177547, disc_loss = 0.0010995773463580295
Trained batch 149 in epoch 6, gen_loss = 0.9492904778321584, disc_loss = 0.0010952907384489663
Trained batch 150 in epoch 6, gen_loss = 0.9489994420121047, disc_loss = 0.0010911951541001694
Trained batch 151 in epoch 6, gen_loss = 0.948617416384973, disc_loss = 0.0010879506820569269
Trained batch 152 in epoch 6, gen_loss = 0.948454277577743, disc_loss = 0.0010850341775450016
Trained batch 153 in epoch 6, gen_loss = 0.9486254774904871, disc_loss = 0.0010830178531226944
Trained batch 154 in epoch 6, gen_loss = 0.9486266432269927, disc_loss = 0.001083192259407482
Trained batch 155 in epoch 6, gen_loss = 0.94847244482774, disc_loss = 0.0010844562434962986
Trained batch 156 in epoch 6, gen_loss = 0.9485083643797856, disc_loss = 0.001085644851940696
Trained batch 157 in epoch 6, gen_loss = 0.9487795546839509, disc_loss = 0.0010870764035874495
Trained batch 158 in epoch 6, gen_loss = 0.9487896647843175, disc_loss = 0.0010885197652610746
Trained batch 159 in epoch 6, gen_loss = 0.9489460654556752, disc_loss = 0.0010893392508478429
Trained batch 160 in epoch 6, gen_loss = 0.9491261180883609, disc_loss = 0.0010887777183518704
Trained batch 161 in epoch 6, gen_loss = 0.9491913142027678, disc_loss = 0.0010872002297410178
Trained batch 162 in epoch 6, gen_loss = 0.9488840874718742, disc_loss = 0.0010853405864916434
Trained batch 163 in epoch 6, gen_loss = 0.9486327076830515, disc_loss = 0.0010838388674218127
Trained batch 164 in epoch 6, gen_loss = 0.9484483628562003, disc_loss = 0.0010826121279299541
Trained batch 165 in epoch 6, gen_loss = 0.948780676327556, disc_loss = 0.0010829170439455445
Trained batch 166 in epoch 6, gen_loss = 0.9489185378223122, disc_loss = 0.0010834421296248458
Trained batch 167 in epoch 6, gen_loss = 0.9491142974722953, disc_loss = 0.0010835764957543386
Trained batch 168 in epoch 6, gen_loss = 0.9491126752464023, disc_loss = 0.00108296261694263
Trained batch 169 in epoch 6, gen_loss = 0.9490883147015291, disc_loss = 0.0010811014427043334
Trained batch 170 in epoch 6, gen_loss = 0.9493210225077401, disc_loss = 0.0010786843612927627
Trained batch 171 in epoch 6, gen_loss = 0.9487970672374548, disc_loss = 0.0010759969588624975
Trained batch 172 in epoch 6, gen_loss = 0.9486768142336366, disc_loss = 0.0010738485837469653
Trained batch 173 in epoch 6, gen_loss = 0.9485412911437023, disc_loss = 0.0010724188001383491
Trained batch 174 in epoch 6, gen_loss = 0.9488001489639282, disc_loss = 0.001072740802691052
Trained batch 175 in epoch 6, gen_loss = 0.9489095563238318, disc_loss = 0.0010737359854663903
Trained batch 176 in epoch 6, gen_loss = 0.9490204086411471, disc_loss = 0.0010743668954194612
Trained batch 177 in epoch 6, gen_loss = 0.9491809469260527, disc_loss = 0.0010739682636157024
Trained batch 178 in epoch 6, gen_loss = 0.9491693970211391, disc_loss = 0.0010719725166417544
Trained batch 179 in epoch 6, gen_loss = 0.9489928166071574, disc_loss = 0.0010691826452481716
Trained batch 180 in epoch 6, gen_loss = 0.9489326957839629, disc_loss = 0.0010661378176271843
Trained batch 181 in epoch 6, gen_loss = 0.9489287537532848, disc_loss = 0.0010632445469177534
Trained batch 182 in epoch 6, gen_loss = 0.949046248946685, disc_loss = 0.0010602961122115585
Trained batch 183 in epoch 6, gen_loss = 0.9491159054248229, disc_loss = 0.0010568022870480174
Trained batch 184 in epoch 6, gen_loss = 0.9490891350282206, disc_loss = 0.0010528015675230857
Trained batch 185 in epoch 6, gen_loss = 0.9493840852732299, disc_loss = 0.00104889928237147
Trained batch 186 in epoch 6, gen_loss = 0.9493921768856558, disc_loss = 0.0010448352997608353
Trained batch 187 in epoch 6, gen_loss = 0.949434757549712, disc_loss = 0.0010409558375652117
Trained batch 188 in epoch 6, gen_loss = 0.9492034972029388, disc_loss = 0.001037281419340861
Trained batch 189 in epoch 6, gen_loss = 0.948883770327819, disc_loss = 0.0010341160131869592
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 0.9109060764312744, disc_loss = 0.0006065790075808764
Trained batch 1 in epoch 7, gen_loss = 0.9018477201461792, disc_loss = 0.0007699196867179126
Trained batch 2 in epoch 7, gen_loss = 0.9194286664326986, disc_loss = 0.0010118265442239742
Trained batch 3 in epoch 7, gen_loss = 0.9340070933103561, disc_loss = 0.0012231818254804239
Trained batch 4 in epoch 7, gen_loss = 0.9467868685722352, disc_loss = 0.001323237072210759
Trained batch 5 in epoch 7, gen_loss = 0.9475122690200806, disc_loss = 0.0013285909953992814
Trained batch 6 in epoch 7, gen_loss = 0.9496771352631705, disc_loss = 0.0012795780203305185
Trained batch 7 in epoch 7, gen_loss = 0.9547553434967995, disc_loss = 0.0012286693090572953
Trained batch 8 in epoch 7, gen_loss = 0.954596115483178, disc_loss = 0.0011918632662855089
Trained batch 9 in epoch 7, gen_loss = 0.9557335555553437, disc_loss = 0.0011709148937370628
Trained batch 10 in epoch 7, gen_loss = 0.9563830115578391, disc_loss = 0.0011515449467961762
Trained batch 11 in epoch 7, gen_loss = 0.9579453269640604, disc_loss = 0.001126555721081483
Trained batch 12 in epoch 7, gen_loss = 0.9569100554172809, disc_loss = 0.001090405226792567
Trained batch 13 in epoch 7, gen_loss = 0.9570043385028839, disc_loss = 0.0010495389537287078
Trained batch 14 in epoch 7, gen_loss = 0.9570546388626099, disc_loss = 0.001009045756654814
Trained batch 15 in epoch 7, gen_loss = 0.9534483626484871, disc_loss = 0.0009708735833555693
Trained batch 16 in epoch 7, gen_loss = 0.9523640871047974, disc_loss = 0.0009400337568128153
Trained batch 17 in epoch 7, gen_loss = 0.951678968138165, disc_loss = 0.000919005692897675
Trained batch 18 in epoch 7, gen_loss = 0.9512554752199274, disc_loss = 0.0009068370456684773
Trained batch 19 in epoch 7, gen_loss = 0.9518342703580857, disc_loss = 0.0009002206919831224
Trained batch 20 in epoch 7, gen_loss = 0.9504386300132388, disc_loss = 0.0008973387926484325
Trained batch 21 in epoch 7, gen_loss = 0.9498340677131306, disc_loss = 0.0008938086592190137
Trained batch 22 in epoch 7, gen_loss = 0.9498875581699869, disc_loss = 0.0008897671144475918
Trained batch 23 in epoch 7, gen_loss = 0.9509584531188011, disc_loss = 0.0008847663084452506
Trained batch 24 in epoch 7, gen_loss = 0.9517422008514405, disc_loss = 0.0008773889497388155
Trained batch 25 in epoch 7, gen_loss = 0.9529747114731715, disc_loss = 0.0008693151097619333
Trained batch 26 in epoch 7, gen_loss = 0.9522836539480422, disc_loss = 0.000862059814001744
Trained batch 27 in epoch 7, gen_loss = 0.9510713368654251, disc_loss = 0.0008579760646430909
Trained batch 28 in epoch 7, gen_loss = 0.9506422671778448, disc_loss = 0.0008578285291903363
Trained batch 29 in epoch 7, gen_loss = 0.9525067985057831, disc_loss = 0.0008630364657922959
Trained batch 30 in epoch 7, gen_loss = 0.9511790621665216, disc_loss = 0.0008686737884061351
Trained batch 31 in epoch 7, gen_loss = 0.9510593935847282, disc_loss = 0.0008755140215725987
Trained batch 32 in epoch 7, gen_loss = 0.9507457415262858, disc_loss = 0.0008770834723360498
Trained batch 33 in epoch 7, gen_loss = 0.9508165804778829, disc_loss = 0.0008748214707285276
Trained batch 34 in epoch 7, gen_loss = 0.9508622595242091, disc_loss = 0.0008715967024077795
Trained batch 35 in epoch 7, gen_loss = 0.9504012680715985, disc_loss = 0.0008689789141903424
Trained batch 36 in epoch 7, gen_loss = 0.9510162972115181, disc_loss = 0.0008671909116044943
Trained batch 37 in epoch 7, gen_loss = 0.9518594961417349, disc_loss = 0.0008649392180622703
Trained batch 38 in epoch 7, gen_loss = 0.9525313010582557, disc_loss = 0.0008617622489766338
Trained batch 39 in epoch 7, gen_loss = 0.9523985505104064, disc_loss = 0.000857817040377995
Trained batch 40 in epoch 7, gen_loss = 0.9524672816439372, disc_loss = 0.0008514289788208993
Trained batch 41 in epoch 7, gen_loss = 0.9516309925488063, disc_loss = 0.0008441338591399559
Trained batch 42 in epoch 7, gen_loss = 0.9505756816198659, disc_loss = 0.0008374479603358046
Trained batch 43 in epoch 7, gen_loss = 0.9510882686484944, disc_loss = 0.0008305375132212331
Trained batch 44 in epoch 7, gen_loss = 0.9521671268675063, disc_loss = 0.0008239506659770591
Trained batch 45 in epoch 7, gen_loss = 0.9518233978230021, disc_loss = 0.0008172629794622164
Trained batch 46 in epoch 7, gen_loss = 0.9512279135115603, disc_loss = 0.0008111924664959549
Trained batch 47 in epoch 7, gen_loss = 0.9514501417676607, disc_loss = 0.0008046597158681834
Trained batch 48 in epoch 7, gen_loss = 0.9513370321721447, disc_loss = 0.0007973276755810544
Trained batch 49 in epoch 7, gen_loss = 0.9517895424365997, disc_loss = 0.0007919964427128434
Trained batch 50 in epoch 7, gen_loss = 0.9518808699121662, disc_loss = 0.0007884825703085345
Trained batch 51 in epoch 7, gen_loss = 0.9514233149014987, disc_loss = 0.0007849309980743923
Trained batch 52 in epoch 7, gen_loss = 0.9513382821712854, disc_loss = 0.0007811234572041288
Trained batch 53 in epoch 7, gen_loss = 0.9509517605657931, disc_loss = 0.0007774644160505246
Trained batch 54 in epoch 7, gen_loss = 0.9499513030052185, disc_loss = 0.0007748052774166519
Trained batch 55 in epoch 7, gen_loss = 0.9503468051552773, disc_loss = 0.000774401574744843
Trained batch 56 in epoch 7, gen_loss = 0.9509112887215196, disc_loss = 0.0007761965583389004
Trained batch 57 in epoch 7, gen_loss = 0.9502577668633955, disc_loss = 0.000778137199412068
Trained batch 58 in epoch 7, gen_loss = 0.9497713052620322, disc_loss = 0.000781472710205905
Trained batch 59 in epoch 7, gen_loss = 0.949605193734169, disc_loss = 0.0007885770396872734
Trained batch 60 in epoch 7, gen_loss = 0.9496289296228377, disc_loss = 0.0007957767239069474
Trained batch 61 in epoch 7, gen_loss = 0.9498029697325922, disc_loss = 0.0008025952556636184
Trained batch 62 in epoch 7, gen_loss = 0.9501006414019872, disc_loss = 0.0008075345494222664
Trained batch 63 in epoch 7, gen_loss = 0.9504520483314991, disc_loss = 0.0008102636757030268
Trained batch 64 in epoch 7, gen_loss = 0.951132424061115, disc_loss = 0.0008092807999883707
Trained batch 65 in epoch 7, gen_loss = 0.9511537019050482, disc_loss = 0.000805883618974776
Trained batch 66 in epoch 7, gen_loss = 0.9512885969076583, disc_loss = 0.0008019953479628955
Trained batch 67 in epoch 7, gen_loss = 0.9515789484276491, disc_loss = 0.0007978185287142611
Trained batch 68 in epoch 7, gen_loss = 0.9513513938240383, disc_loss = 0.0007936157652284896
Trained batch 69 in epoch 7, gen_loss = 0.9511942071574074, disc_loss = 0.0007896661076561681
Trained batch 70 in epoch 7, gen_loss = 0.9505226973076941, disc_loss = 0.0007866148879541688
Trained batch 71 in epoch 7, gen_loss = 0.9505321126845148, disc_loss = 0.0007851858907896611
Trained batch 72 in epoch 7, gen_loss = 0.9506641659018111, disc_loss = 0.000785865765128744
Trained batch 73 in epoch 7, gen_loss = 0.9505639205107818, disc_loss = 0.0007895830660001249
Trained batch 74 in epoch 7, gen_loss = 0.9503424334526062, disc_loss = 0.0007938860465462009
Trained batch 75 in epoch 7, gen_loss = 0.9510255620667809, disc_loss = 0.0007964063766657522
Trained batch 76 in epoch 7, gen_loss = 0.9509829987179149, disc_loss = 0.0007958271398583983
Trained batch 77 in epoch 7, gen_loss = 0.9508210367117172, disc_loss = 0.0007935990086899927
Trained batch 78 in epoch 7, gen_loss = 0.9508235416834867, disc_loss = 0.0007907155977821426
Trained batch 79 in epoch 7, gen_loss = 0.9511754773557186, disc_loss = 0.0007880304954596795
Trained batch 80 in epoch 7, gen_loss = 0.9511685974803972, disc_loss = 0.0007856260104116375
Trained batch 81 in epoch 7, gen_loss = 0.9513762636882502, disc_loss = 0.0007846177102736674
Trained batch 82 in epoch 7, gen_loss = 0.9512388361505715, disc_loss = 0.0007830383543609586
Trained batch 83 in epoch 7, gen_loss = 0.9516977845203309, disc_loss = 0.0007828802938872416
Trained batch 84 in epoch 7, gen_loss = 0.951226446909063, disc_loss = 0.0007838917902999503
Trained batch 85 in epoch 7, gen_loss = 0.9512415237204973, disc_loss = 0.0007877233201302155
Trained batch 86 in epoch 7, gen_loss = 0.9517765743979092, disc_loss = 0.000794512457241058
Trained batch 87 in epoch 7, gen_loss = 0.9514987455172972, disc_loss = 0.000801158344653562
Trained batch 88 in epoch 7, gen_loss = 0.9515677991877781, disc_loss = 0.000806481779547764
Trained batch 89 in epoch 7, gen_loss = 0.9516143176290724, disc_loss = 0.0008100224212588121
Trained batch 90 in epoch 7, gen_loss = 0.9517691482554426, disc_loss = 0.000811445825492738
Trained batch 91 in epoch 7, gen_loss = 0.9517698592465856, disc_loss = 0.0008099618868942817
Trained batch 92 in epoch 7, gen_loss = 0.9515722015852569, disc_loss = 0.0008069208174723611
Trained batch 93 in epoch 7, gen_loss = 0.9515967128124643, disc_loss = 0.0008038769146685112
Trained batch 94 in epoch 7, gen_loss = 0.9517276989786249, disc_loss = 0.0008010368383685617
Trained batch 95 in epoch 7, gen_loss = 0.9514280930161476, disc_loss = 0.0007982599569610708
Trained batch 96 in epoch 7, gen_loss = 0.9517220424622604, disc_loss = 0.0007965248768198659
Trained batch 97 in epoch 7, gen_loss = 0.9518260706444176, disc_loss = 0.0007949177091418556
Trained batch 98 in epoch 7, gen_loss = 0.9519758483376166, disc_loss = 0.0007931700374959319
Trained batch 99 in epoch 7, gen_loss = 0.9519198220968247, disc_loss = 0.0007913459365954623
Trained batch 100 in epoch 7, gen_loss = 0.9517169807216909, disc_loss = 0.0007893092080830863
Trained batch 101 in epoch 7, gen_loss = 0.9515277083013572, disc_loss = 0.0007866821885245907
Trained batch 102 in epoch 7, gen_loss = 0.9515323505818265, disc_loss = 0.0007843016629848738
Trained batch 103 in epoch 7, gen_loss = 0.9514551099676353, disc_loss = 0.0007830191556982194
Trained batch 104 in epoch 7, gen_loss = 0.9514491018794832, disc_loss = 0.0007804790982932207
Trained batch 105 in epoch 7, gen_loss = 0.9515190315696428, disc_loss = 0.0007773917824587837
Trained batch 106 in epoch 7, gen_loss = 0.9515941404850683, disc_loss = 0.0007756641333178556
Trained batch 107 in epoch 7, gen_loss = 0.9516979969210095, disc_loss = 0.0007742586714340616
Trained batch 108 in epoch 7, gen_loss = 0.9517021972105044, disc_loss = 0.0007732309186895198
Trained batch 109 in epoch 7, gen_loss = 0.9512994034723802, disc_loss = 0.0007727113089376045
Trained batch 110 in epoch 7, gen_loss = 0.9512547571379859, disc_loss = 0.0007726345056571436
Trained batch 111 in epoch 7, gen_loss = 0.9512716728661742, disc_loss = 0.0007729702616156178
Trained batch 112 in epoch 7, gen_loss = 0.9516410152469061, disc_loss = 0.0007735719001312138
Trained batch 113 in epoch 7, gen_loss = 0.9514452051698116, disc_loss = 0.0007733799276665147
Trained batch 114 in epoch 7, gen_loss = 0.9509974308635878, disc_loss = 0.0007727708457462975
Trained batch 115 in epoch 7, gen_loss = 0.9505280723859524, disc_loss = 0.0007722630902647104
Trained batch 116 in epoch 7, gen_loss = 0.9501784265550792, disc_loss = 0.0007720534512116454
Trained batch 117 in epoch 7, gen_loss = 0.9502538690122507, disc_loss = 0.000773417510603302
Trained batch 118 in epoch 7, gen_loss = 0.9501451925069344, disc_loss = 0.0007768394540459262
Trained batch 119 in epoch 7, gen_loss = 0.9501282840967178, disc_loss = 0.0007806570955532758
Trained batch 120 in epoch 7, gen_loss = 0.9501159457135792, disc_loss = 0.0007848267379497786
Trained batch 121 in epoch 7, gen_loss = 0.9499982751783778, disc_loss = 0.0007894216150667549
Trained batch 122 in epoch 7, gen_loss = 0.9496600182075811, disc_loss = 0.000794676612121833
Trained batch 123 in epoch 7, gen_loss = 0.9497984739080552, disc_loss = 0.0008020190765701925
Trained batch 124 in epoch 7, gen_loss = 0.9495660462379456, disc_loss = 0.0008104975332971663
Trained batch 125 in epoch 7, gen_loss = 0.9492838926731594, disc_loss = 0.0008191621170789446
Trained batch 126 in epoch 7, gen_loss = 0.9493502786779028, disc_loss = 0.0008283018024077301
Trained batch 127 in epoch 7, gen_loss = 0.9492303277365863, disc_loss = 0.000837354093846443
Trained batch 128 in epoch 7, gen_loss = 0.9500801244447398, disc_loss = 0.0008466025846450799
Trained batch 129 in epoch 7, gen_loss = 0.9497474936338571, disc_loss = 0.0008519584346616355
Trained batch 130 in epoch 7, gen_loss = 0.9496595659328781, disc_loss = 0.0008539709798860158
Trained batch 131 in epoch 7, gen_loss = 0.949246321663712, disc_loss = 0.0008542654216977429
Trained batch 132 in epoch 7, gen_loss = 0.9493372453782791, disc_loss = 0.0008552297019781335
Trained batch 133 in epoch 7, gen_loss = 0.9493535765961035, disc_loss = 0.0008579890655072183
Trained batch 134 in epoch 7, gen_loss = 0.9491621922563623, disc_loss = 0.0008607593966492763
Trained batch 135 in epoch 7, gen_loss = 0.94930409464766, disc_loss = 0.0008634671623226228
Trained batch 136 in epoch 7, gen_loss = 0.949048901561403, disc_loss = 0.0008671646077359217
Trained batch 137 in epoch 7, gen_loss = 0.9489687128343444, disc_loss = 0.0008725767296762543
Trained batch 138 in epoch 7, gen_loss = 0.9485848310182421, disc_loss = 0.000880700471373811
Trained batch 139 in epoch 7, gen_loss = 0.9487664631434849, disc_loss = 0.0008930286847836604
Trained batch 140 in epoch 7, gen_loss = 0.9488679246699556, disc_loss = 0.000908119409759562
Trained batch 141 in epoch 7, gen_loss = 0.9488805574430547, disc_loss = 0.0009232670251972003
Trained batch 142 in epoch 7, gen_loss = 0.948911115422949, disc_loss = 0.000936650153912174
Trained batch 143 in epoch 7, gen_loss = 0.9490481279790401, disc_loss = 0.0009476845029389046
Trained batch 144 in epoch 7, gen_loss = 0.9490884858986427, disc_loss = 0.0009557314255226661
Trained batch 145 in epoch 7, gen_loss = 0.9491696545522507, disc_loss = 0.0009612908946870099
Trained batch 146 in epoch 7, gen_loss = 0.9491090596127673, disc_loss = 0.0009636090920690042
Trained batch 147 in epoch 7, gen_loss = 0.948780208423331, disc_loss = 0.0009637599670551592
Trained batch 148 in epoch 7, gen_loss = 0.9488783974775532, disc_loss = 0.0009642873666852388
Trained batch 149 in epoch 7, gen_loss = 0.9490440094470978, disc_loss = 0.0009656147299877679
Trained batch 150 in epoch 7, gen_loss = 0.949372995373429, disc_loss = 0.0009667745801783629
Trained batch 151 in epoch 7, gen_loss = 0.9489766010328343, disc_loss = 0.0009713013682094721
Trained batch 152 in epoch 7, gen_loss = 0.9485621748406903, disc_loss = 0.0009787884825046228
Trained batch 153 in epoch 7, gen_loss = 0.9484553561582194, disc_loss = 0.0009850653789124102
Trained batch 154 in epoch 7, gen_loss = 0.948478703729568, disc_loss = 0.0009880872238652721
Trained batch 155 in epoch 7, gen_loss = 0.9487441911911353, disc_loss = 0.0009879602747297701
Trained batch 156 in epoch 7, gen_loss = 0.9488200264371884, disc_loss = 0.0009856054299454662
Trained batch 157 in epoch 7, gen_loss = 0.9490102925632573, disc_loss = 0.0009829870915508982
Trained batch 158 in epoch 7, gen_loss = 0.9490165054423254, disc_loss = 0.0009808069080006004
Trained batch 159 in epoch 7, gen_loss = 0.9491132322698832, disc_loss = 0.0009791292557565611
Trained batch 160 in epoch 7, gen_loss = 0.9494522650789771, disc_loss = 0.0009780581521740912
Trained batch 161 in epoch 7, gen_loss = 0.9493551110779798, disc_loss = 0.0009768363895012572
Trained batch 162 in epoch 7, gen_loss = 0.9493500736593469, disc_loss = 0.0009756669488898336
Trained batch 163 in epoch 7, gen_loss = 0.9492270550349864, disc_loss = 0.000974031559386143
Trained batch 164 in epoch 7, gen_loss = 0.9494955803408768, disc_loss = 0.0009736587958424493
Trained batch 165 in epoch 7, gen_loss = 0.9494843522468245, disc_loss = 0.0009772963662342876
Trained batch 166 in epoch 7, gen_loss = 0.9492873909944546, disc_loss = 0.0009833468205482326
Trained batch 167 in epoch 7, gen_loss = 0.9490999554594358, disc_loss = 0.0009887432750561164
Trained batch 168 in epoch 7, gen_loss = 0.9492627332901814, disc_loss = 0.000994473080097053
Trained batch 169 in epoch 7, gen_loss = 0.9488863215726965, disc_loss = 0.0010022384540848983
Trained batch 170 in epoch 7, gen_loss = 0.9486656711812604, disc_loss = 0.0010104331050724423
Trained batch 171 in epoch 7, gen_loss = 0.9485930696476338, disc_loss = 0.0010165568120672022
Trained batch 172 in epoch 7, gen_loss = 0.9488331003685218, disc_loss = 0.001021033270194362
Trained batch 173 in epoch 7, gen_loss = 0.9484567522317514, disc_loss = 0.0010252407567653183
Trained batch 174 in epoch 7, gen_loss = 0.9484564025061472, disc_loss = 0.0010295264916827104
Trained batch 175 in epoch 7, gen_loss = 0.9483391920273955, disc_loss = 0.0010324161784493217
Trained batch 176 in epoch 7, gen_loss = 0.9483911661104968, disc_loss = 0.0010332567290084616
Trained batch 177 in epoch 7, gen_loss = 0.9481599371085007, disc_loss = 0.0010320585745248127
Trained batch 178 in epoch 7, gen_loss = 0.9483513435837942, disc_loss = 0.0010302794110953453
Trained batch 179 in epoch 7, gen_loss = 0.9480538954337437, disc_loss = 0.0010283974893455807
Trained batch 180 in epoch 7, gen_loss = 0.9480010560862926, disc_loss = 0.0010264056455922823
Trained batch 181 in epoch 7, gen_loss = 0.9481696915495527, disc_loss = 0.001024338276193293
Trained batch 182 in epoch 7, gen_loss = 0.9482504148952297, disc_loss = 0.001022022580912418
Trained batch 183 in epoch 7, gen_loss = 0.9481809923182363, disc_loss = 0.0010197211865844388
Trained batch 184 in epoch 7, gen_loss = 0.9483600693780023, disc_loss = 0.0010183417604846025
Trained batch 185 in epoch 7, gen_loss = 0.9485203328952995, disc_loss = 0.0010172673940761214
Trained batch 186 in epoch 7, gen_loss = 0.9482024962251837, disc_loss = 0.0010167733620775037
Trained batch 187 in epoch 7, gen_loss = 0.948134886774611, disc_loss = 0.0010174317379851151
Trained batch 188 in epoch 7, gen_loss = 0.9481589459868335, disc_loss = 0.0010190248822303065
Trained batch 189 in epoch 7, gen_loss = 0.9483146636109603, disc_loss = 0.0010215113431178524
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 0.9605560302734375, disc_loss = 0.0016677891835570335
Trained batch 1 in epoch 8, gen_loss = 0.9551985561847687, disc_loss = 0.001775973942130804
Trained batch 2 in epoch 8, gen_loss = 0.9485329985618591, disc_loss = 0.001875574855754773
Trained batch 3 in epoch 8, gen_loss = 0.9464872926473618, disc_loss = 0.0019695922383107245
Trained batch 4 in epoch 8, gen_loss = 0.9500653624534607, disc_loss = 0.0020044074393808843
Trained batch 5 in epoch 8, gen_loss = 0.9520517190297445, disc_loss = 0.0019937869316587844
Trained batch 6 in epoch 8, gen_loss = 0.953452638217381, disc_loss = 0.0019491886653538262
Trained batch 7 in epoch 8, gen_loss = 0.9561982974410057, disc_loss = 0.0018834581424016505
Trained batch 8 in epoch 8, gen_loss = 0.9568419787618849, disc_loss = 0.001794951864414745
Trained batch 9 in epoch 8, gen_loss = 0.9573912203311921, disc_loss = 0.0016876522859092802
Trained batch 10 in epoch 8, gen_loss = 0.956016334620389, disc_loss = 0.001576359336137433
Trained batch 11 in epoch 8, gen_loss = 0.9483118305603663, disc_loss = 0.0014803380909143016
Trained batch 12 in epoch 8, gen_loss = 0.9506367032344525, disc_loss = 0.0013980360325569143
Trained batch 13 in epoch 8, gen_loss = 0.9505497813224792, disc_loss = 0.0013273913355078548
Trained batch 14 in epoch 8, gen_loss = 0.9480511625607808, disc_loss = 0.0012627170071937144
Trained batch 15 in epoch 8, gen_loss = 0.9479617699980736, disc_loss = 0.0012001520681224065
Trained batch 16 in epoch 8, gen_loss = 0.949333534521215, disc_loss = 0.0011419510359273238
Trained batch 17 in epoch 8, gen_loss = 0.949366612566842, disc_loss = 0.0010885543613565257
Trained batch 18 in epoch 8, gen_loss = 0.9489253163337708, disc_loss = 0.0010451779526192695
Trained batch 19 in epoch 8, gen_loss = 0.9479232221841812, disc_loss = 0.0010081343745696359
Trained batch 20 in epoch 8, gen_loss = 0.9471689065297445, disc_loss = 0.0009739911821227343
Trained batch 21 in epoch 8, gen_loss = 0.9475411935286089, disc_loss = 0.0009428148358975621
Trained batch 22 in epoch 8, gen_loss = 0.9498164964758832, disc_loss = 0.0009142398776020855
Trained batch 23 in epoch 8, gen_loss = 0.9503164514899254, disc_loss = 0.0008884623675839975
Trained batch 24 in epoch 8, gen_loss = 0.9514122748374939, disc_loss = 0.0008692361158318817
Trained batch 25 in epoch 8, gen_loss = 0.9523241176055028, disc_loss = 0.0008523165933393801
Trained batch 26 in epoch 8, gen_loss = 0.9529493208284732, disc_loss = 0.00083586948824598
Trained batch 27 in epoch 8, gen_loss = 0.9533641998256955, disc_loss = 0.0008212036939637203
Trained batch 28 in epoch 8, gen_loss = 0.951039063519445, disc_loss = 0.0008091492616523314
Trained batch 29 in epoch 8, gen_loss = 0.9496358712514241, disc_loss = 0.0007976823049830273
Trained batch 30 in epoch 8, gen_loss = 0.9501448754341372, disc_loss = 0.0007867838806217356
Trained batch 31 in epoch 8, gen_loss = 0.9494620859622955, disc_loss = 0.0007754419220873388
Trained batch 32 in epoch 8, gen_loss = 0.9480953180428707, disc_loss = 0.00076442924292871
Trained batch 33 in epoch 8, gen_loss = 0.949999237761778, disc_loss = 0.0007539615497294375
Trained batch 34 in epoch 8, gen_loss = 0.9500377774238586, disc_loss = 0.0007458682621030935
Trained batch 35 in epoch 8, gen_loss = 0.9490339292420281, disc_loss = 0.0007404073112411425
Trained batch 36 in epoch 8, gen_loss = 0.9491864523372134, disc_loss = 0.0007342132236305121
Trained batch 37 in epoch 8, gen_loss = 0.9488324632770136, disc_loss = 0.0007243910743119685
Trained batch 38 in epoch 8, gen_loss = 0.9498652724119333, disc_loss = 0.0007134276719835515
Trained batch 39 in epoch 8, gen_loss = 0.949167899787426, disc_loss = 0.0007020637436653488
Trained batch 40 in epoch 8, gen_loss = 0.9492013309060073, disc_loss = 0.0006918699946254492
Trained batch 41 in epoch 8, gen_loss = 0.9483901588689714, disc_loss = 0.0006828820429897556
Trained batch 42 in epoch 8, gen_loss = 0.9479605347611183, disc_loss = 0.0006760954660590911
Trained batch 43 in epoch 8, gen_loss = 0.9473264434120872, disc_loss = 0.0006713769405244172
Trained batch 44 in epoch 8, gen_loss = 0.94723562002182, disc_loss = 0.0006674635890198665
Trained batch 45 in epoch 8, gen_loss = 0.9465850293636322, disc_loss = 0.0006640861082933438
Trained batch 46 in epoch 8, gen_loss = 0.9467460081932393, disc_loss = 0.0006633722662995074
Trained batch 47 in epoch 8, gen_loss = 0.9478471664090952, disc_loss = 0.000664757034125311
Trained batch 48 in epoch 8, gen_loss = 0.9480593070691946, disc_loss = 0.0006673032167244094
Trained batch 49 in epoch 8, gen_loss = 0.9487000548839569, disc_loss = 0.000673468858585693
Trained batch 50 in epoch 8, gen_loss = 0.9477063218752543, disc_loss = 0.0006829666586674969
Trained batch 51 in epoch 8, gen_loss = 0.9482047729767286, disc_loss = 0.0006945359441138302
Trained batch 52 in epoch 8, gen_loss = 0.9478406804912495, disc_loss = 0.0007055284755242954
Trained batch 53 in epoch 8, gen_loss = 0.9480221194249613, disc_loss = 0.0007144002641628807
Trained batch 54 in epoch 8, gen_loss = 0.947692935033278, disc_loss = 0.0007189769610042938
Trained batch 55 in epoch 8, gen_loss = 0.9469724978719439, disc_loss = 0.0007190967210460388
Trained batch 56 in epoch 8, gen_loss = 0.9463542532502559, disc_loss = 0.0007167442067599806
Trained batch 57 in epoch 8, gen_loss = 0.9470477371380247, disc_loss = 0.0007130318890317697
Trained batch 58 in epoch 8, gen_loss = 0.9467209678585247, disc_loss = 0.0007083466403794049
Trained batch 59 in epoch 8, gen_loss = 0.9466605047384898, disc_loss = 0.000705039390110566
Trained batch 60 in epoch 8, gen_loss = 0.9461668661383332, disc_loss = 0.0007028866518235414
Trained batch 61 in epoch 8, gen_loss = 0.9457344403189998, disc_loss = 0.0007008922970741086
Trained batch 62 in epoch 8, gen_loss = 0.9459785289234586, disc_loss = 0.0006986427788866596
Trained batch 63 in epoch 8, gen_loss = 0.9456706438213587, disc_loss = 0.0006943837261133012
Trained batch 64 in epoch 8, gen_loss = 0.9454532384872436, disc_loss = 0.0006891261893682755
Trained batch 65 in epoch 8, gen_loss = 0.9458032557458589, disc_loss = 0.000684490342268184
Trained batch 66 in epoch 8, gen_loss = 0.945470970068405, disc_loss = 0.0006797787239914065
Trained batch 67 in epoch 8, gen_loss = 0.9448254108428955, disc_loss = 0.0006752025574849755
Trained batch 68 in epoch 8, gen_loss = 0.9447765047999396, disc_loss = 0.0006708796376504166
Trained batch 69 in epoch 8, gen_loss = 0.9446473606995174, disc_loss = 0.00066700464272539
Trained batch 70 in epoch 8, gen_loss = 0.9441923465527279, disc_loss = 0.0006640918403667148
Trained batch 71 in epoch 8, gen_loss = 0.9436061200168397, disc_loss = 0.0006617747939243498
Trained batch 72 in epoch 8, gen_loss = 0.9441678801628008, disc_loss = 0.0006587903130136125
Trained batch 73 in epoch 8, gen_loss = 0.9438272835435094, disc_loss = 0.0006567064375377487
Trained batch 74 in epoch 8, gen_loss = 0.9438972568511963, disc_loss = 0.0006600533480135103
Trained batch 75 in epoch 8, gen_loss = 0.9447966798355705, disc_loss = 0.0006663306826100636
Trained batch 76 in epoch 8, gen_loss = 0.944827476879219, disc_loss = 0.0006716811882827866
Trained batch 77 in epoch 8, gen_loss = 0.9449960726958054, disc_loss = 0.0006771715117606502
Trained batch 78 in epoch 8, gen_loss = 0.9450095710875113, disc_loss = 0.0006822163608997966
Trained batch 79 in epoch 8, gen_loss = 0.9453757181763649, disc_loss = 0.0006846906799182761
Trained batch 80 in epoch 8, gen_loss = 0.9453409086039037, disc_loss = 0.000685708621016669
Trained batch 81 in epoch 8, gen_loss = 0.9461209425112096, disc_loss = 0.0006861424935334249
Trained batch 82 in epoch 8, gen_loss = 0.946112810847271, disc_loss = 0.0006867306417763144
Trained batch 83 in epoch 8, gen_loss = 0.9467496900331407, disc_loss = 0.0006889357616836648
Trained batch 84 in epoch 8, gen_loss = 0.9464151683975669, disc_loss = 0.000693140718538095
Trained batch 85 in epoch 8, gen_loss = 0.9467048416304034, disc_loss = 0.0007007976541793797
Trained batch 86 in epoch 8, gen_loss = 0.9467597494180175, disc_loss = 0.0007088122723474242
Trained batch 87 in epoch 8, gen_loss = 0.9466240616007284, disc_loss = 0.0007148729332997887
Trained batch 88 in epoch 8, gen_loss = 0.9469086782316144, disc_loss = 0.0007174593773199602
Trained batch 89 in epoch 8, gen_loss = 0.9469369643264347, disc_loss = 0.0007165093052511414
Trained batch 90 in epoch 8, gen_loss = 0.947057272706713, disc_loss = 0.0007144031933621391
Trained batch 91 in epoch 8, gen_loss = 0.9467188592838205, disc_loss = 0.0007124239845839127
Trained batch 92 in epoch 8, gen_loss = 0.9472091954241517, disc_loss = 0.0007144586096758083
Trained batch 93 in epoch 8, gen_loss = 0.9472751015044273, disc_loss = 0.0007235312189143943
Trained batch 94 in epoch 8, gen_loss = 0.9470504371743453, disc_loss = 0.000736269553951723
Trained batch 95 in epoch 8, gen_loss = 0.9466730318963528, disc_loss = 0.000751958411152979
Trained batch 96 in epoch 8, gen_loss = 0.9473379457119814, disc_loss = 0.0007773723348869567
Trained batch 97 in epoch 8, gen_loss = 0.9477885712166222, disc_loss = 0.0008125343408711179
Trained batch 98 in epoch 8, gen_loss = 0.9478405503311542, disc_loss = 0.0008510487239967768
Trained batch 99 in epoch 8, gen_loss = 0.9484177261590958, disc_loss = 0.0008873733348445967
Trained batch 100 in epoch 8, gen_loss = 0.9482982312098588, disc_loss = 0.0009146813922192864
Trained batch 101 in epoch 8, gen_loss = 0.9485823734133851, disc_loss = 0.0009310982291650612
Trained batch 102 in epoch 8, gen_loss = 0.9481202259804439, disc_loss = 0.0009382269769066094
Trained batch 103 in epoch 8, gen_loss = 0.9482175186276436, disc_loss = 0.0009411920702684886
Trained batch 104 in epoch 8, gen_loss = 0.9480272185234796, disc_loss = 0.0009417488633300222
Trained batch 105 in epoch 8, gen_loss = 0.9480872626574535, disc_loss = 0.0009402342344950533
Trained batch 106 in epoch 8, gen_loss = 0.9479850564047555, disc_loss = 0.0009369530886951311
Trained batch 107 in epoch 8, gen_loss = 0.9482341772980161, disc_loss = 0.0009334593207178706
Trained batch 108 in epoch 8, gen_loss = 0.9479356758091428, disc_loss = 0.0009317887688499936
Trained batch 109 in epoch 8, gen_loss = 0.9479386589743874, disc_loss = 0.0009335562110539865
Trained batch 110 in epoch 8, gen_loss = 0.9482334712604145, disc_loss = 0.0009358214845813744
Trained batch 111 in epoch 8, gen_loss = 0.9481261186301708, disc_loss = 0.0009359172940353996
Trained batch 112 in epoch 8, gen_loss = 0.9483076961694565, disc_loss = 0.0009337273731300261
Trained batch 113 in epoch 8, gen_loss = 0.9483747116306371, disc_loss = 0.000929968839045614
Trained batch 114 in epoch 8, gen_loss = 0.9483534128769584, disc_loss = 0.0009259025877564335
Trained batch 115 in epoch 8, gen_loss = 0.9483505502857011, disc_loss = 0.000922077923766257
Trained batch 116 in epoch 8, gen_loss = 0.9481176173585093, disc_loss = 0.0009188043328228956
Trained batch 117 in epoch 8, gen_loss = 0.9479981645689173, disc_loss = 0.0009163271907570977
Trained batch 118 in epoch 8, gen_loss = 0.9482037254742214, disc_loss = 0.0009143847114692184
Trained batch 119 in epoch 8, gen_loss = 0.9483905509114265, disc_loss = 0.0009127547869866248
Trained batch 120 in epoch 8, gen_loss = 0.9483590594007949, disc_loss = 0.0009113709273467163
Trained batch 121 in epoch 8, gen_loss = 0.9479210919044057, disc_loss = 0.0009096310038375286
Trained batch 122 in epoch 8, gen_loss = 0.9475102962517157, disc_loss = 0.000907676020680692
Trained batch 123 in epoch 8, gen_loss = 0.9476807386644425, disc_loss = 0.0009058724688422385
Trained batch 124 in epoch 8, gen_loss = 0.9475079655647278, disc_loss = 0.0009038151821587235
Trained batch 125 in epoch 8, gen_loss = 0.9474977079838042, disc_loss = 0.0009014414184974389
Trained batch 126 in epoch 8, gen_loss = 0.9475121207124605, disc_loss = 0.0008983111683202277
Trained batch 127 in epoch 8, gen_loss = 0.9473252505995333, disc_loss = 0.0008941025057538354
Trained batch 128 in epoch 8, gen_loss = 0.9476461290389069, disc_loss = 0.0008895977187266415
Trained batch 129 in epoch 8, gen_loss = 0.9480149269104003, disc_loss = 0.0008858194997838627
Trained batch 130 in epoch 8, gen_loss = 0.9478195223189493, disc_loss = 0.000881143645001291
Trained batch 131 in epoch 8, gen_loss = 0.9480262254223679, disc_loss = 0.0008765821017511895
Trained batch 132 in epoch 8, gen_loss = 0.947986372431418, disc_loss = 0.0008733192381284487
Trained batch 133 in epoch 8, gen_loss = 0.9479627449121049, disc_loss = 0.0008711146289368034
Trained batch 134 in epoch 8, gen_loss = 0.9478055035626447, disc_loss = 0.0008702741304188277
Trained batch 135 in epoch 8, gen_loss = 0.9478816254174008, disc_loss = 0.0008714958973595297
Trained batch 136 in epoch 8, gen_loss = 0.9480637281480497, disc_loss = 0.0008721719255898637
Trained batch 137 in epoch 8, gen_loss = 0.9477978175964908, disc_loss = 0.0008703378453914859
Trained batch 138 in epoch 8, gen_loss = 0.9476614826017147, disc_loss = 0.0008664700667886399
Trained batch 139 in epoch 8, gen_loss = 0.947411543556622, disc_loss = 0.0008622357573975543
Trained batch 140 in epoch 8, gen_loss = 0.9475317876389686, disc_loss = 0.0008588914556349528
Trained batch 141 in epoch 8, gen_loss = 0.9475784738298872, disc_loss = 0.0008569139643723119
Trained batch 142 in epoch 8, gen_loss = 0.9477732423302176, disc_loss = 0.0008564364231009218
Trained batch 143 in epoch 8, gen_loss = 0.9473644999994172, disc_loss = 0.0008600834816105715
Trained batch 144 in epoch 8, gen_loss = 0.9472920088932432, disc_loss = 0.000869539025608964
Trained batch 145 in epoch 8, gen_loss = 0.9470392375776212, disc_loss = 0.0008830271748194394
Trained batch 146 in epoch 8, gen_loss = 0.9471492045590667, disc_loss = 0.0008972844233273902
Trained batch 147 in epoch 8, gen_loss = 0.9472548329346889, disc_loss = 0.0009083200810080696
Trained batch 148 in epoch 8, gen_loss = 0.9474611542368895, disc_loss = 0.0009141114861516894
Trained batch 149 in epoch 8, gen_loss = 0.9474303758144379, disc_loss = 0.000916051766447102
Trained batch 150 in epoch 8, gen_loss = 0.9474020923999761, disc_loss = 0.0009159936969760583
Trained batch 151 in epoch 8, gen_loss = 0.9472048063027231, disc_loss = 0.0009157194186914957
Trained batch 152 in epoch 8, gen_loss = 0.9471868494756861, disc_loss = 0.0009150225916433033
Trained batch 153 in epoch 8, gen_loss = 0.9473079694555951, disc_loss = 0.0009135750894186801
Trained batch 154 in epoch 8, gen_loss = 0.9474852654241747, disc_loss = 0.0009113710227182075
Trained batch 155 in epoch 8, gen_loss = 0.9472972490848639, disc_loss = 0.0009085629057013788
Trained batch 156 in epoch 8, gen_loss = 0.9473473171519625, disc_loss = 0.0009054087130590134
Trained batch 157 in epoch 8, gen_loss = 0.9474695800225946, disc_loss = 0.0009018653930795579
Trained batch 158 in epoch 8, gen_loss = 0.9474792562940586, disc_loss = 0.0008979860293084416
Trained batch 159 in epoch 8, gen_loss = 0.9477694496512413, disc_loss = 0.0008943242337409174
Trained batch 160 in epoch 8, gen_loss = 0.9476081714126634, disc_loss = 0.0008906396351731527
Trained batch 161 in epoch 8, gen_loss = 0.9476141878116278, disc_loss = 0.0008872822230684652
Trained batch 162 in epoch 8, gen_loss = 0.9471073121380952, disc_loss = 0.0008842506582714458
Trained batch 163 in epoch 8, gen_loss = 0.9476298122871213, disc_loss = 0.0008815758279169818
Trained batch 164 in epoch 8, gen_loss = 0.947391439929153, disc_loss = 0.000878537366004435
Trained batch 165 in epoch 8, gen_loss = 0.9471863827791559, disc_loss = 0.0008756061070893207
Trained batch 166 in epoch 8, gen_loss = 0.9472094742123952, disc_loss = 0.0008725464315443651
Trained batch 167 in epoch 8, gen_loss = 0.9468794447325525, disc_loss = 0.0008694106285734701
Trained batch 168 in epoch 8, gen_loss = 0.9469989890882955, disc_loss = 0.000866774955768546
Trained batch 169 in epoch 8, gen_loss = 0.9470205436734592, disc_loss = 0.0008640702028060332
Trained batch 170 in epoch 8, gen_loss = 0.9472060018812704, disc_loss = 0.0008613339375788946
Trained batch 171 in epoch 8, gen_loss = 0.9472362859997638, disc_loss = 0.0008586684306528484
Trained batch 172 in epoch 8, gen_loss = 0.9471235209806806, disc_loss = 0.0008562360314862275
Trained batch 173 in epoch 8, gen_loss = 0.9468899122599898, disc_loss = 0.0008537612347622756
Trained batch 174 in epoch 8, gen_loss = 0.9468544687543596, disc_loss = 0.0008512971385581685
Trained batch 175 in epoch 8, gen_loss = 0.946949300440875, disc_loss = 0.0008487932516965719
Trained batch 176 in epoch 8, gen_loss = 0.947089476100469, disc_loss = 0.0008460707582025605
Trained batch 177 in epoch 8, gen_loss = 0.9471842867604802, disc_loss = 0.0008433892458985988
Trained batch 178 in epoch 8, gen_loss = 0.9469945067799957, disc_loss = 0.0008406516292337953
Trained batch 179 in epoch 8, gen_loss = 0.9471312357319726, disc_loss = 0.000837729946943
Trained batch 180 in epoch 8, gen_loss = 0.9474467822859959, disc_loss = 0.0008352899098079343
Trained batch 181 in epoch 8, gen_loss = 0.9472193531282656, disc_loss = 0.0008325155197251281
Trained batch 182 in epoch 8, gen_loss = 0.9470753285402809, disc_loss = 0.0008298968514580218
Trained batch 183 in epoch 8, gen_loss = 0.9471667998510859, disc_loss = 0.00082712208946443
Trained batch 184 in epoch 8, gen_loss = 0.9474849301415521, disc_loss = 0.0008242427832384065
Trained batch 185 in epoch 8, gen_loss = 0.9474984112606254, disc_loss = 0.0008213616091124614
Trained batch 186 in epoch 8, gen_loss = 0.9476465547786039, disc_loss = 0.0008183216912993155
Trained batch 187 in epoch 8, gen_loss = 0.9476869664293655, disc_loss = 0.0008151745840107051
Trained batch 188 in epoch 8, gen_loss = 0.9474390956459853, disc_loss = 0.0008122148655943829
Trained batch 189 in epoch 8, gen_loss = 0.9474437748130999, disc_loss = 0.0008094418590189889
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 0.977380633354187, disc_loss = 0.00030063308076933026
Trained batch 1 in epoch 9, gen_loss = 0.9545689225196838, disc_loss = 0.00030576050630770624
Trained batch 2 in epoch 9, gen_loss = 0.9307913780212402, disc_loss = 0.0003170774628718694
Trained batch 3 in epoch 9, gen_loss = 0.9377605617046356, disc_loss = 0.00030112225067568943
Trained batch 4 in epoch 9, gen_loss = 0.9376611351966858, disc_loss = 0.0002762198360869661
Trained batch 5 in epoch 9, gen_loss = 0.935501237710317, disc_loss = 0.00026386696360229206
Trained batch 6 in epoch 9, gen_loss = 0.9377346975462777, disc_loss = 0.0002551208765778158
Trained batch 7 in epoch 9, gen_loss = 0.9427671059966087, disc_loss = 0.00024843233040883206
Trained batch 8 in epoch 9, gen_loss = 0.9399587048424615, disc_loss = 0.0002444207897901328
Trained batch 9 in epoch 9, gen_loss = 0.9391750514507293, disc_loss = 0.00024913694214774297
Trained batch 10 in epoch 9, gen_loss = 0.9360919703136791, disc_loss = 0.0002590280425713652
Trained batch 11 in epoch 9, gen_loss = 0.9383978992700577, disc_loss = 0.00027363897364314954
Trained batch 12 in epoch 9, gen_loss = 0.9403089605844938, disc_loss = 0.00028687651166155073
Trained batch 13 in epoch 9, gen_loss = 0.9387793924127307, disc_loss = 0.0002955384271834711
Trained batch 14 in epoch 9, gen_loss = 0.9385205467542013, disc_loss = 0.0003017835833209877
Trained batch 15 in epoch 9, gen_loss = 0.9363006614148617, disc_loss = 0.000305447406390158
Trained batch 16 in epoch 9, gen_loss = 0.9393575997913585, disc_loss = 0.00030914415444439165
Trained batch 17 in epoch 9, gen_loss = 0.9411051770051321, disc_loss = 0.00030968846678863175
Trained batch 18 in epoch 9, gen_loss = 0.9415227833547091, disc_loss = 0.00030594945373626326
Trained batch 19 in epoch 9, gen_loss = 0.9395664155483245, disc_loss = 0.0003008730120200198
Trained batch 20 in epoch 9, gen_loss = 0.9414810424759275, disc_loss = 0.0002958904834009618
Trained batch 21 in epoch 9, gen_loss = 0.9429294304414229, disc_loss = 0.00029133325138404456
Trained batch 22 in epoch 9, gen_loss = 0.9434965330621471, disc_loss = 0.0002864911467717637
Trained batch 23 in epoch 9, gen_loss = 0.9453132500251135, disc_loss = 0.0002828646999356958
Trained batch 24 in epoch 9, gen_loss = 0.9463554191589355, disc_loss = 0.00028273672331124544
Trained batch 25 in epoch 9, gen_loss = 0.946501550766138, disc_loss = 0.00028910850456808333
Trained batch 26 in epoch 9, gen_loss = 0.944837283205103, disc_loss = 0.00029812771632956964
Trained batch 27 in epoch 9, gen_loss = 0.9472720112119403, disc_loss = 0.0003123303582209961
Trained batch 28 in epoch 9, gen_loss = 0.9483601101513567, disc_loss = 0.00032516299036395706
Trained batch 29 in epoch 9, gen_loss = 0.9491550127665201, disc_loss = 0.00033915149494229504
Trained batch 30 in epoch 9, gen_loss = 0.9513288774797993, disc_loss = 0.00035662941480686346
Trained batch 31 in epoch 9, gen_loss = 0.9517829231917858, disc_loss = 0.0003788240201174631
Trained batch 32 in epoch 9, gen_loss = 0.9513352278507117, disc_loss = 0.00040303877904079854
Trained batch 33 in epoch 9, gen_loss = 0.950541087809731, disc_loss = 0.0004273514316403581
Trained batch 34 in epoch 9, gen_loss = 0.9496542828423636, disc_loss = 0.00044730558043478856
Trained batch 35 in epoch 9, gen_loss = 0.9495962725745307, disc_loss = 0.00046556943481037807
Trained batch 36 in epoch 9, gen_loss = 0.9503475330971383, disc_loss = 0.0004856023973646901
Trained batch 37 in epoch 9, gen_loss = 0.9489070898608157, disc_loss = 0.0005098044478616334
Trained batch 38 in epoch 9, gen_loss = 0.9492563223227476, disc_loss = 0.000534090597797424
Trained batch 39 in epoch 9, gen_loss = 0.9479324281215668, disc_loss = 0.0005561669320741202
Trained batch 40 in epoch 9, gen_loss = 0.94820095271599, disc_loss = 0.00057682239027444
Trained batch 41 in epoch 9, gen_loss = 0.9489784780002776, disc_loss = 0.0005941252976689222
Trained batch 42 in epoch 9, gen_loss = 0.9481615036032921, disc_loss = 0.0006035867920091245
Trained batch 43 in epoch 9, gen_loss = 0.947518448938023, disc_loss = 0.0006071725663125769
Trained batch 44 in epoch 9, gen_loss = 0.9476039701037937, disc_loss = 0.0006061405842451172
Trained batch 45 in epoch 9, gen_loss = 0.9477506098539933, disc_loss = 0.0006021223171442018
Trained batch 46 in epoch 9, gen_loss = 0.9479662585765758, disc_loss = 0.0005969104686494362
Trained batch 47 in epoch 9, gen_loss = 0.948251393934091, disc_loss = 0.0005908624589210376
Trained batch 48 in epoch 9, gen_loss = 0.9483871995186319, disc_loss = 0.0005839890645987981
Trained batch 49 in epoch 9, gen_loss = 0.9490195178985595, disc_loss = 0.000576956124859862
Trained batch 50 in epoch 9, gen_loss = 0.9488500380048565, disc_loss = 0.0005694168035452272
Trained batch 51 in epoch 9, gen_loss = 0.9498175084590912, disc_loss = 0.0005636007722037343
Trained batch 52 in epoch 9, gen_loss = 0.9504761853308048, disc_loss = 0.0005594105223624281
Trained batch 53 in epoch 9, gen_loss = 0.9504966713764049, disc_loss = 0.000556288306985085
Trained batch 54 in epoch 9, gen_loss = 0.9499125664884394, disc_loss = 0.0005534589481116696
Trained batch 55 in epoch 9, gen_loss = 0.9505764448216983, disc_loss = 0.0005519427431863733
Trained batch 56 in epoch 9, gen_loss = 0.9498213184507269, disc_loss = 0.0005515404688929649
Trained batch 57 in epoch 9, gen_loss = 0.9498910061244307, disc_loss = 0.0005509836081383301
Trained batch 58 in epoch 9, gen_loss = 0.949868726528297, disc_loss = 0.000550420896615833
Trained batch 59 in epoch 9, gen_loss = 0.949899610877037, disc_loss = 0.0005509121333792185
Trained batch 60 in epoch 9, gen_loss = 0.9490429876280613, disc_loss = 0.0005531417994118739
Trained batch 61 in epoch 9, gen_loss = 0.9488594301285282, disc_loss = 0.0005565698112120792
Trained batch 62 in epoch 9, gen_loss = 0.9493601539778331, disc_loss = 0.0005604288317189212
Trained batch 63 in epoch 9, gen_loss = 0.9493271140381694, disc_loss = 0.0005637432241201168
Trained batch 64 in epoch 9, gen_loss = 0.94885397874392, disc_loss = 0.0005680761371667568
Trained batch 65 in epoch 9, gen_loss = 0.9496524153333722, disc_loss = 0.0005770809525115924
Trained batch 66 in epoch 9, gen_loss = 0.9495094729893243, disc_loss = 0.0005930419594271859
Trained batch 67 in epoch 9, gen_loss = 0.9490839716266183, disc_loss = 0.0006157160284655059
Trained batch 68 in epoch 9, gen_loss = 0.9501638066941414, disc_loss = 0.0006450930900493826
Trained batch 69 in epoch 9, gen_loss = 0.9502391006265368, disc_loss = 0.0006831659503015024
Trained batch 70 in epoch 9, gen_loss = 0.9511942468898397, disc_loss = 0.0007345641169592108
Trained batch 71 in epoch 9, gen_loss = 0.9507192100087801, disc_loss = 0.0007961044417849431
Trained batch 72 in epoch 9, gen_loss = 0.9510801140576193, disc_loss = 0.000859476578077429
Trained batch 73 in epoch 9, gen_loss = 0.9500374705404848, disc_loss = 0.000918316506982051
Trained batch 74 in epoch 9, gen_loss = 0.9510024269421895, disc_loss = 0.0009584119512389104
Trained batch 75 in epoch 9, gen_loss = 0.9498581329458639, disc_loss = 0.000976840597822478
Trained batch 76 in epoch 9, gen_loss = 0.9504512246553, disc_loss = 0.0009913870538645364
Trained batch 77 in epoch 9, gen_loss = 0.9503888067526695, disc_loss = 0.001017608076859361
Trained batch 78 in epoch 9, gen_loss = 0.950485469419745, disc_loss = 0.0010563308679604833
Trained batch 79 in epoch 9, gen_loss = 0.9505098894238472, disc_loss = 0.0010943253117147833
Trained batch 80 in epoch 9, gen_loss = 0.949968542581723, disc_loss = 0.0011138965973607551
Trained batch 81 in epoch 9, gen_loss = 0.9495347294865585, disc_loss = 0.0011157612018173606
Trained batch 82 in epoch 9, gen_loss = 0.9498783946037292, disc_loss = 0.001111847572225
Trained batch 83 in epoch 9, gen_loss = 0.9501009391886848, disc_loss = 0.0011074795842259413
Trained batch 84 in epoch 9, gen_loss = 0.9499998513390037, disc_loss = 0.001101657864637673
Trained batch 85 in epoch 9, gen_loss = 0.9495403461678084, disc_loss = 0.0010950723771265772
Trained batch 86 in epoch 9, gen_loss = 0.949371367350392, disc_loss = 0.0010916490834366915
Trained batch 87 in epoch 9, gen_loss = 0.9487015774304216, disc_loss = 0.0010992515288473276
Trained batch 88 in epoch 9, gen_loss = 0.9485567680905375, disc_loss = 0.0011285354410758598
Trained batch 89 in epoch 9, gen_loss = 0.9487546364466349, disc_loss = 0.0011742908824493902
Trained batch 90 in epoch 9, gen_loss = 0.9484627698803996, disc_loss = 0.0012170878030451854
Trained batch 91 in epoch 9, gen_loss = 0.9484409761169682, disc_loss = 0.001245489784987117
Trained batch 92 in epoch 9, gen_loss = 0.9482403442423831, disc_loss = 0.0012573549174703658
Trained batch 93 in epoch 9, gen_loss = 0.9485450279205403, disc_loss = 0.0012538411884885677
Trained batch 94 in epoch 9, gen_loss = 0.9480405249093709, disc_loss = 0.001242689762760787
Trained batch 95 in epoch 9, gen_loss = 0.9482638991127411, disc_loss = 0.0012367547292342351
Trained batch 96 in epoch 9, gen_loss = 0.9480244990476628, disc_loss = 0.0012414332939199048
Trained batch 97 in epoch 9, gen_loss = 0.9480875523722901, disc_loss = 0.001252946238495571
Trained batch 98 in epoch 9, gen_loss = 0.9483693525044605, disc_loss = 0.001261532947690358
Trained batch 99 in epoch 9, gen_loss = 0.9483131301403046, disc_loss = 0.0012624401356151793
Trained batch 100 in epoch 9, gen_loss = 0.9484230993997933, disc_loss = 0.0012572914487878229
Trained batch 101 in epoch 9, gen_loss = 0.9486860837422165, disc_loss = 0.001249445329663371
Trained batch 102 in epoch 9, gen_loss = 0.9486228163959911, disc_loss = 0.001240452101202094
Trained batch 103 in epoch 9, gen_loss = 0.9487013644897021, disc_loss = 0.0012316787549654972
Trained batch 104 in epoch 9, gen_loss = 0.9487409126190912, disc_loss = 0.0012227562013625477
Trained batch 105 in epoch 9, gen_loss = 0.9486748452456493, disc_loss = 0.0012135086014135388
Trained batch 106 in epoch 9, gen_loss = 0.9490272480750752, disc_loss = 0.0012049204771892193
Trained batch 107 in epoch 9, gen_loss = 0.9491775620866705, disc_loss = 0.0011966358699148124
Trained batch 108 in epoch 9, gen_loss = 0.9490544074172274, disc_loss = 0.0011883872819353116
Trained batch 109 in epoch 9, gen_loss = 0.949448885159059, disc_loss = 0.0011856863855924033
Trained batch 110 in epoch 9, gen_loss = 0.9497231728321797, disc_loss = 0.0011868301540694979
Trained batch 111 in epoch 9, gen_loss = 0.949563061020204, disc_loss = 0.0011882864459299267
Trained batch 112 in epoch 9, gen_loss = 0.9494609727268726, disc_loss = 0.0011862609647492572
Trained batch 113 in epoch 9, gen_loss = 0.9494776114037162, disc_loss = 0.001181518656825606
Trained batch 114 in epoch 9, gen_loss = 0.9495075085888738, disc_loss = 0.0011748241256851622
Trained batch 115 in epoch 9, gen_loss = 0.9494683316041683, disc_loss = 0.0011668718470900785
Trained batch 116 in epoch 9, gen_loss = 0.9493042602498307, disc_loss = 0.0011581896189112677
Trained batch 117 in epoch 9, gen_loss = 0.9491081758070801, disc_loss = 0.0011495856403706643
Trained batch 118 in epoch 9, gen_loss = 0.9492205231129622, disc_loss = 0.0011417869004732028
Trained batch 119 in epoch 9, gen_loss = 0.9491416787107786, disc_loss = 0.0011348072156882457
Trained batch 120 in epoch 9, gen_loss = 0.9493627779739947, disc_loss = 0.0011285235748139464
Trained batch 121 in epoch 9, gen_loss = 0.9492962111215122, disc_loss = 0.0011222583386564216
Trained batch 122 in epoch 9, gen_loss = 0.9495092296018833, disc_loss = 0.0011163312865835728
Trained batch 123 in epoch 9, gen_loss = 0.9496102347489326, disc_loss = 0.0011102421050318593
Trained batch 124 in epoch 9, gen_loss = 0.9493720149993896, disc_loss = 0.001103512679110281
Trained batch 125 in epoch 9, gen_loss = 0.9493576751814948, disc_loss = 0.001096278455940866
Trained batch 126 in epoch 9, gen_loss = 0.9493876460968979, disc_loss = 0.0010891106328239487
Trained batch 127 in epoch 9, gen_loss = 0.9497371474280953, disc_loss = 0.001081890872569602
Trained batch 128 in epoch 9, gen_loss = 0.9494664336359778, disc_loss = 0.001074621801209535
Trained batch 129 in epoch 9, gen_loss = 0.9492956051459679, disc_loss = 0.0010679944084796052
Trained batch 130 in epoch 9, gen_loss = 0.9497325784377469, disc_loss = 0.0010615984540661967
Trained batch 131 in epoch 9, gen_loss = 0.9497124615943793, disc_loss = 0.001054848369566378
Trained batch 132 in epoch 9, gen_loss = 0.9503101908174673, disc_loss = 0.0010501073078817821
Trained batch 133 in epoch 9, gen_loss = 0.9504597316037363, disc_loss = 0.0010464111161235818
Trained batch 134 in epoch 9, gen_loss = 0.950464493698544, disc_loss = 0.0010433525320237365
Trained batch 135 in epoch 9, gen_loss = 0.9507331300307723, disc_loss = 0.0010392171933584476
Trained batch 136 in epoch 9, gen_loss = 0.9506503556766649, disc_loss = 0.0010339611412381183
Trained batch 137 in epoch 9, gen_loss = 0.9507753810156947, disc_loss = 0.0010284417287988142
Trained batch 138 in epoch 9, gen_loss = 0.9509073148528449, disc_loss = 0.0010228647856525875
Trained batch 139 in epoch 9, gen_loss = 0.9506553143262864, disc_loss = 0.0010172975164355843
Trained batch 140 in epoch 9, gen_loss = 0.9504391923018382, disc_loss = 0.0010118077511994947
Trained batch 141 in epoch 9, gen_loss = 0.9500686270250401, disc_loss = 0.0010063822479987464
Trained batch 142 in epoch 9, gen_loss = 0.9499767097559842, disc_loss = 0.001001193274831777
Trained batch 143 in epoch 9, gen_loss = 0.9499565814104345, disc_loss = 0.0009959378389289163
Trained batch 144 in epoch 9, gen_loss = 0.9499531125200206, disc_loss = 0.0009905753275861258
Trained batch 145 in epoch 9, gen_loss = 0.9497259716465049, disc_loss = 0.0009851148037067678
Trained batch 146 in epoch 9, gen_loss = 0.9494124180605622, disc_loss = 0.000979852640714661
Trained batch 147 in epoch 9, gen_loss = 0.9495176020506266, disc_loss = 0.0009748741592645545
Trained batch 148 in epoch 9, gen_loss = 0.949293040189167, disc_loss = 0.0009696678009045142
Trained batch 149 in epoch 9, gen_loss = 0.9491990784804026, disc_loss = 0.0009642484530922957
Trained batch 150 in epoch 9, gen_loss = 0.9492393420232053, disc_loss = 0.0009587253538339664
Trained batch 151 in epoch 9, gen_loss = 0.949347206636479, disc_loss = 0.0009535195467354864
Trained batch 152 in epoch 9, gen_loss = 0.9491763570729423, disc_loss = 0.0009487425777954628
Trained batch 153 in epoch 9, gen_loss = 0.9491376667827754, disc_loss = 0.0009448144529332322
Trained batch 154 in epoch 9, gen_loss = 0.9493010097934353, disc_loss = 0.0009410294854352552
Trained batch 155 in epoch 9, gen_loss = 0.9494690016294137, disc_loss = 0.000937056538719051
Trained batch 156 in epoch 9, gen_loss = 0.9491977919438842, disc_loss = 0.0009333783196015462
Trained batch 157 in epoch 9, gen_loss = 0.9491293713261809, disc_loss = 0.0009306874680642298
Trained batch 158 in epoch 9, gen_loss = 0.9491774417319387, disc_loss = 0.0009286661312766022
Trained batch 159 in epoch 9, gen_loss = 0.9491779543459415, disc_loss = 0.0009272743371184333
Trained batch 160 in epoch 9, gen_loss = 0.9494463371934357, disc_loss = 0.0009332836447616241
Trained batch 161 in epoch 9, gen_loss = 0.9495797661351569, disc_loss = 0.0009384922922896452
Trained batch 162 in epoch 9, gen_loss = 0.9494010977949833, disc_loss = 0.0009451685700082775
Trained batch 163 in epoch 9, gen_loss = 0.9497458629491853, disc_loss = 0.0009550164287225571
Trained batch 164 in epoch 9, gen_loss = 0.9499703125520186, disc_loss = 0.000968340284607345
Trained batch 165 in epoch 9, gen_loss = 0.9501301904758775, disc_loss = 0.0009822834657255493
Trained batch 166 in epoch 9, gen_loss = 0.9498892776266543, disc_loss = 0.000991819498741241
Trained batch 167 in epoch 9, gen_loss = 0.9502672627568245, disc_loss = 0.0009973449575357205
Trained batch 168 in epoch 9, gen_loss = 0.9500732111507619, disc_loss = 0.0009992248852277097
Trained batch 169 in epoch 9, gen_loss = 0.949870554489248, disc_loss = 0.0010009271426550934
Trained batch 170 in epoch 9, gen_loss = 0.9498946670203181, disc_loss = 0.0010008464861124733
Trained batch 171 in epoch 9, gen_loss = 0.9496985632319783, disc_loss = 0.000998899523543768
Trained batch 172 in epoch 9, gen_loss = 0.9494331289578035, disc_loss = 0.000996141230338926
Trained batch 173 in epoch 9, gen_loss = 0.9494200396811825, disc_loss = 0.0009945704658240102
Trained batch 174 in epoch 9, gen_loss = 0.9492418316432408, disc_loss = 0.0009955825013042029
Trained batch 175 in epoch 9, gen_loss = 0.9493898085572503, disc_loss = 0.0009970862389640058
Trained batch 176 in epoch 9, gen_loss = 0.9495116034470036, disc_loss = 0.000996843855308453
Trained batch 177 in epoch 9, gen_loss = 0.9493876273712415, disc_loss = 0.0009949482776933569
Trained batch 178 in epoch 9, gen_loss = 0.9495550210915464, disc_loss = 0.0009953736387096949
Trained batch 179 in epoch 9, gen_loss = 0.9495450930462943, disc_loss = 0.0009983454350731336
Trained batch 180 in epoch 9, gen_loss = 0.9494336326477936, disc_loss = 0.0010012675818629583
Trained batch 181 in epoch 9, gen_loss = 0.9498677558296329, disc_loss = 0.0010036394186509815
Trained batch 182 in epoch 9, gen_loss = 0.9496478008442237, disc_loss = 0.0010070976096045103
Trained batch 183 in epoch 9, gen_loss = 0.9496848424491675, disc_loss = 0.0010128858562181806
Trained batch 184 in epoch 9, gen_loss = 0.9496399505718335, disc_loss = 0.0010182910666461228
Trained batch 185 in epoch 9, gen_loss = 0.9496769145611794, disc_loss = 0.0010221644424550456
Trained batch 186 in epoch 9, gen_loss = 0.9498572658727513, disc_loss = 0.0010244733818002385
Trained batch 187 in epoch 9, gen_loss = 0.9498666886319506, disc_loss = 0.0010248253342108504
Trained batch 188 in epoch 9, gen_loss = 0.9495159813335964, disc_loss = 0.0010231505109615643
Trained batch 189 in epoch 9, gen_loss = 0.9495085157846149, disc_loss = 0.0010200594859749177
Testing Epoch 9
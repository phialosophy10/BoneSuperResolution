/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 0.9377330541610718, disc_loss = 0.5155175924301147
Trained batch 1 in epoch 0, gen_loss = 0.952843964099884, disc_loss = 0.9049079418182373
Trained batch 2 in epoch 0, gen_loss = 0.9238881468772888, disc_loss = 0.8000872333844503
Trained batch 3 in epoch 0, gen_loss = 0.8844168037176132, disc_loss = 0.7063817232847214
Trained batch 4 in epoch 0, gen_loss = 0.8544052004814148, disc_loss = 0.6416713058948517
Trained batch 5 in epoch 0, gen_loss = 0.8334613541762034, disc_loss = 0.5860581894715627
Trained batch 6 in epoch 0, gen_loss = 0.8209799698420933, disc_loss = 0.5440192776066917
Trained batch 7 in epoch 0, gen_loss = 0.8111319467425346, disc_loss = 0.5054581165313721
Trained batch 8 in epoch 0, gen_loss = 0.80245883597268, disc_loss = 0.47340938614474404
Trained batch 9 in epoch 0, gen_loss = 0.7934407651424408, disc_loss = 0.44526262432336805
Trained batch 10 in epoch 0, gen_loss = 0.786254113370722, disc_loss = 0.42349161343141034
Trained batch 11 in epoch 0, gen_loss = 0.7776505053043365, disc_loss = 0.40342240532239276
Trained batch 12 in epoch 0, gen_loss = 0.7720118761062622, disc_loss = 0.38557443710473865
Trained batch 13 in epoch 0, gen_loss = 0.7691139238221305, disc_loss = 0.37053124819483074
Trained batch 14 in epoch 0, gen_loss = 0.7676377018292745, disc_loss = 0.35932607650756837
Trained batch 15 in epoch 0, gen_loss = 0.767073504626751, disc_loss = 0.3512373175472021
Trained batch 16 in epoch 0, gen_loss = 0.7668477892875671, disc_loss = 0.3431316771928002
Trained batch 17 in epoch 0, gen_loss = 0.766522208849589, disc_loss = 0.3327840508686172
Trained batch 18 in epoch 0, gen_loss = 0.7649618700930947, disc_loss = 0.3215016687386914
Trained batch 19 in epoch 0, gen_loss = 0.7632377982139588, disc_loss = 0.31170273162424567
Trained batch 20 in epoch 0, gen_loss = 0.7630145947138468, disc_loss = 0.3029055215773128
Trained batch 21 in epoch 0, gen_loss = 0.7615867500955408, disc_loss = 0.29403887858444994
Trained batch 22 in epoch 0, gen_loss = 0.7608770157979883, disc_loss = 0.28589604373859323
Trained batch 23 in epoch 0, gen_loss = 0.7596648087104162, disc_loss = 0.27774868874500197
Trained batch 24 in epoch 0, gen_loss = 0.7581722140312195, disc_loss = 0.27007202118635176
Trained batch 25 in epoch 0, gen_loss = 0.7574320687697484, disc_loss = 0.26262498503694165
Trained batch 26 in epoch 0, gen_loss = 0.7561345873055635, disc_loss = 0.2556842474473847
Trained batch 27 in epoch 0, gen_loss = 0.7561082520655223, disc_loss = 0.2494210848318679
Trained batch 28 in epoch 0, gen_loss = 0.7544038398512478, disc_loss = 0.2430485217221852
Trained batch 29 in epoch 0, gen_loss = 0.7545047998428345, disc_loss = 0.23670280526081722
Trained batch 30 in epoch 0, gen_loss = 0.7541850305372669, disc_loss = 0.23072372208679875
Trained batch 31 in epoch 0, gen_loss = 0.7541683800518513, disc_loss = 0.22587688523344696
Trained batch 32 in epoch 0, gen_loss = 0.7565668008544228, disc_loss = 0.22356023007270062
Trained batch 33 in epoch 0, gen_loss = 0.76121745039435, disc_loss = 0.22873883716323795
Trained batch 34 in epoch 0, gen_loss = 0.7676497408321925, disc_loss = 0.23672812644924437
Trained batch 35 in epoch 0, gen_loss = 0.7705117447508706, disc_loss = 0.23629897729390198
Trained batch 36 in epoch 0, gen_loss = 0.7735297373823218, disc_loss = 0.239328449440969
Trained batch 37 in epoch 0, gen_loss = 0.7695830103598142, disc_loss = 0.24071085903989642
Trained batch 38 in epoch 0, gen_loss = 0.7661299934754005, disc_loss = 0.23976693378809172
Trained batch 39 in epoch 0, gen_loss = 0.7664256796240807, disc_loss = 0.23683152943849564
Trained batch 40 in epoch 0, gen_loss = 0.7649479159494725, disc_loss = 0.2332941555395359
Trained batch 41 in epoch 0, gen_loss = 0.7620242238044739, disc_loss = 0.22941341144698008
Trained batch 42 in epoch 0, gen_loss = 0.7600683805554412, disc_loss = 0.2254548468735329
Trained batch 43 in epoch 0, gen_loss = 0.759533551606265, disc_loss = 0.2215709610926834
Trained batch 44 in epoch 0, gen_loss = 0.756578622923957, disc_loss = 0.21774409636855124
Trained batch 45 in epoch 0, gen_loss = 0.7581589610680289, disc_loss = 0.21393522142392138
Trained batch 46 in epoch 0, gen_loss = 0.7547295981265129, disc_loss = 0.21037954210918
Trained batch 47 in epoch 0, gen_loss = 0.7571159129341444, disc_loss = 0.2069980693825831
Trained batch 48 in epoch 0, gen_loss = 0.7557513056969156, disc_loss = 0.20373319568378584
Trained batch 49 in epoch 0, gen_loss = 0.751964693069458, disc_loss = 0.20050306230783463
Trained batch 50 in epoch 0, gen_loss = 0.7531916779630324, disc_loss = 0.19730466180572323
Trained batch 51 in epoch 0, gen_loss = 0.7530195369170263, disc_loss = 0.19405538237725312
Trained batch 52 in epoch 0, gen_loss = 0.7536226533493906, disc_loss = 0.19092306561486902
Trained batch 53 in epoch 0, gen_loss = 0.7524551782343123, disc_loss = 0.18788215866381372
Trained batch 54 in epoch 0, gen_loss = 0.751516195860776, disc_loss = 0.1848699153824286
Trained batch 55 in epoch 0, gen_loss = 0.7510171862585204, disc_loss = 0.1820495218437697
Trained batch 56 in epoch 0, gen_loss = 0.7495982322776527, disc_loss = 0.17926111513454662
Trained batch 57 in epoch 0, gen_loss = 0.748838242785684, disc_loss = 0.17654434755316067
Trained batch 58 in epoch 0, gen_loss = 0.7475045626446352, disc_loss = 0.1739910487716986
Trained batch 59 in epoch 0, gen_loss = 0.7464192807674408, disc_loss = 0.17144727120175957
Trained batch 60 in epoch 0, gen_loss = 0.74597909411446, disc_loss = 0.1689590118886506
Trained batch 61 in epoch 0, gen_loss = 0.7456069146433184, disc_loss = 0.16660280907226185
Trained batch 62 in epoch 0, gen_loss = 0.7440003317499918, disc_loss = 0.1643576460284373
Trained batch 63 in epoch 0, gen_loss = 0.7446272457018495, disc_loss = 0.163147577928612
Trained batch 64 in epoch 0, gen_loss = 0.739196660885444, disc_loss = 0.16289413700310085
Trained batch 65 in epoch 0, gen_loss = 0.7363365175146045, disc_loss = 0.16121371285143224
Trained batch 66 in epoch 0, gen_loss = 0.7373139413435068, disc_loss = 0.16023676255856878
Trained batch 67 in epoch 0, gen_loss = 0.7351105230696061, disc_loss = 0.15853478860877016
Trained batch 68 in epoch 0, gen_loss = 0.7341724737830784, disc_loss = 0.15666422129109286
Trained batch 69 in epoch 0, gen_loss = 0.733967741898128, disc_loss = 0.15483350061944554
Trained batch 70 in epoch 0, gen_loss = 0.7340770682818453, disc_loss = 0.1530297181346047
Trained batch 71 in epoch 0, gen_loss = 0.7328748595383432, disc_loss = 0.1512212302380552
Trained batch 72 in epoch 0, gen_loss = 0.7312996967198098, disc_loss = 0.14971961711265452
Trained batch 73 in epoch 0, gen_loss = 0.7309325426011473, disc_loss = 0.1480867261872501
Trained batch 74 in epoch 0, gen_loss = 0.73100346326828, disc_loss = 0.1464989364395539
Trained batch 75 in epoch 0, gen_loss = 0.7301545684274874, disc_loss = 0.14484235695808342
Trained batch 76 in epoch 0, gen_loss = 0.7288466328150266, disc_loss = 0.14330728129520046
Trained batch 77 in epoch 0, gen_loss = 0.7287373603918613, disc_loss = 0.14248371372620264
Trained batch 78 in epoch 0, gen_loss = 0.7231221089634714, disc_loss = 0.14291215131554422
Trained batch 79 in epoch 0, gen_loss = 0.7230068515986204, disc_loss = 0.14184606592170895
Trained batch 80 in epoch 0, gen_loss = 0.7232918978473286, disc_loss = 0.14120961380777536
Trained batch 81 in epoch 0, gen_loss = 0.7217347690971886, disc_loss = 0.13988141483831695
Trained batch 82 in epoch 0, gen_loss = 0.7211231370288206, disc_loss = 0.13847373574074492
Trained batch 83 in epoch 0, gen_loss = 0.7208063137673196, disc_loss = 0.13714508069235654
Trained batch 84 in epoch 0, gen_loss = 0.7191869662088506, disc_loss = 0.13580951375119826
Trained batch 85 in epoch 0, gen_loss = 0.7193502752586852, disc_loss = 0.13444841529654208
Trained batch 86 in epoch 0, gen_loss = 0.7181091291465979, disc_loss = 0.13318092620064473
Trained batch 87 in epoch 0, gen_loss = 0.7171933498572219, disc_loss = 0.13187901163473725
Trained batch 88 in epoch 0, gen_loss = 0.7165153371484092, disc_loss = 0.13055253067587533
Trained batch 89 in epoch 0, gen_loss = 0.7165200018220478, disc_loss = 0.1293248659517202
Trained batch 90 in epoch 0, gen_loss = 0.7151489817834162, disc_loss = 0.12812878427883753
Trained batch 91 in epoch 0, gen_loss = 0.7144152000546455, disc_loss = 0.12689330814527752
Trained batch 92 in epoch 0, gen_loss = 0.7140683714420565, disc_loss = 0.12569461853033112
Trained batch 93 in epoch 0, gen_loss = 0.7130665091123987, disc_loss = 0.12454022185758074
Trained batch 94 in epoch 0, gen_loss = 0.7114692948366467, disc_loss = 0.1234218915826396
Trained batch 95 in epoch 0, gen_loss = 0.7119809994474053, disc_loss = 0.12239165514862786
Trained batch 96 in epoch 0, gen_loss = 0.7105098357520152, disc_loss = 0.12135205237367719
Trained batch 97 in epoch 0, gen_loss = 0.7103664148218778, disc_loss = 0.12028166562394828
Trained batch 98 in epoch 0, gen_loss = 0.7101055639560776, disc_loss = 0.11921550633592738
Trained batch 99 in epoch 0, gen_loss = 0.7088767483830452, disc_loss = 0.11817277395166456
Trained batch 100 in epoch 0, gen_loss = 0.7086469256641841, disc_loss = 0.11715111631604999
Trained batch 101 in epoch 0, gen_loss = 0.7080365135973575, disc_loss = 0.11615086207166314
Trained batch 102 in epoch 0, gen_loss = 0.7069980088368203, disc_loss = 0.11515752793949785
Trained batch 103 in epoch 0, gen_loss = 0.7062255731568887, disc_loss = 0.11419581963071743
Trained batch 104 in epoch 0, gen_loss = 0.7059924480460938, disc_loss = 0.11331200002736988
Trained batch 105 in epoch 0, gen_loss = 0.7049010415684502, disc_loss = 0.1124171664991047
Trained batch 106 in epoch 0, gen_loss = 0.7047555599814264, disc_loss = 0.11155505566291998
Trained batch 107 in epoch 0, gen_loss = 0.7031388224826919, disc_loss = 0.11074317806331371
Trained batch 108 in epoch 0, gen_loss = 0.7032854488683403, disc_loss = 0.10992763168392104
Trained batch 109 in epoch 0, gen_loss = 0.7017968521876768, disc_loss = 0.10916163481941277
Trained batch 110 in epoch 0, gen_loss = 0.7022171393708065, disc_loss = 0.10863560264477053
Trained batch 111 in epoch 0, gen_loss = 0.6991131989551442, disc_loss = 0.10844365049186828
Trained batch 112 in epoch 0, gen_loss = 0.6993909475550187, disc_loss = 0.10811391420893174
Trained batch 113 in epoch 0, gen_loss = 0.6979443355087649, disc_loss = 0.10794478158973027
Trained batch 114 in epoch 0, gen_loss = 0.6977339322152345, disc_loss = 0.10741263408537792
Trained batch 115 in epoch 0, gen_loss = 0.6977722215755232, disc_loss = 0.10673660340975842
Trained batch 116 in epoch 0, gen_loss = 0.6962210777987782, disc_loss = 0.1061108962385955
Trained batch 117 in epoch 0, gen_loss = 0.6960602031420853, disc_loss = 0.10536057674878482
Trained batch 118 in epoch 0, gen_loss = 0.696251084073251, disc_loss = 0.10462160443714938
Trained batch 119 in epoch 0, gen_loss = 0.6950110293924808, disc_loss = 0.10391496897209436
Trained batch 120 in epoch 0, gen_loss = 0.694738934601634, disc_loss = 0.10320793223867486
Trained batch 121 in epoch 0, gen_loss = 0.6942366134436404, disc_loss = 0.10246384348414961
Trained batch 122 in epoch 0, gen_loss = 0.6934291945724953, disc_loss = 0.10173948776976365
Trained batch 123 in epoch 0, gen_loss = 0.693334328311105, disc_loss = 0.10103247117912097
Trained batch 124 in epoch 0, gen_loss = 0.6926606285572052, disc_loss = 0.10049887861311435
Trained batch 125 in epoch 0, gen_loss = 0.6902223420994622, disc_loss = 0.10015683794128043
Trained batch 126 in epoch 0, gen_loss = 0.6911081359611722, disc_loss = 0.09954110965660708
Trained batch 127 in epoch 0, gen_loss = 0.6915009331423789, disc_loss = 0.09903056283656042
Trained batch 128 in epoch 0, gen_loss = 0.6900870876256809, disc_loss = 0.09842034661781418
Trained batch 129 in epoch 0, gen_loss = 0.6891614797023626, disc_loss = 0.09776812680065632
Trained batch 130 in epoch 0, gen_loss = 0.6884180182264051, disc_loss = 0.0971199777261674
Trained batch 131 in epoch 0, gen_loss = 0.688285089126139, disc_loss = 0.09645696955902333
Trained batch 132 in epoch 0, gen_loss = 0.6876892969572455, disc_loss = 0.09581188127902665
Trained batch 133 in epoch 0, gen_loss = 0.6875862552603679, disc_loss = 0.09518514976683837
Trained batch 134 in epoch 0, gen_loss = 0.6863150113158756, disc_loss = 0.09461558174203943
Trained batch 135 in epoch 0, gen_loss = 0.6860015114002368, disc_loss = 0.09406624241348575
Trained batch 136 in epoch 0, gen_loss = 0.6856507965683067, disc_loss = 0.09361352613807594
Trained batch 137 in epoch 0, gen_loss = 0.6842442416194556, disc_loss = 0.09311942297263422
Trained batch 138 in epoch 0, gen_loss = 0.6832300645413159, disc_loss = 0.09254448482994553
Trained batch 139 in epoch 0, gen_loss = 0.683071177984987, disc_loss = 0.09197166684482778
Trained batch 140 in epoch 0, gen_loss = 0.6830575464042365, disc_loss = 0.0914067628773603
Trained batch 141 in epoch 0, gen_loss = 0.6823330653805129, disc_loss = 0.09084370861512045
Trained batch 142 in epoch 0, gen_loss = 0.6822552870620381, disc_loss = 0.09028347696900577
Trained batch 143 in epoch 0, gen_loss = 0.6815716262078948, disc_loss = 0.08972792064176044
Trained batch 144 in epoch 0, gen_loss = 0.6809953062698759, disc_loss = 0.08917647926457997
Trained batch 145 in epoch 0, gen_loss = 0.6806973339351889, disc_loss = 0.08864469560858322
Trained batch 146 in epoch 0, gen_loss = 0.6801885623915666, disc_loss = 0.08811472028139092
Trained batch 147 in epoch 0, gen_loss = 0.6794836833267599, disc_loss = 0.08762920485507394
Trained batch 148 in epoch 0, gen_loss = 0.679167157651594, disc_loss = 0.08715878448280312
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 0.586199164390564, disc_loss = 0.026083791628479958
Trained batch 1 in epoch 1, gen_loss = 0.5308700501918793, disc_loss = 0.027358331717550755
Trained batch 2 in epoch 1, gen_loss = 0.6025384068489075, disc_loss = 0.024367903048793476
Trained batch 3 in epoch 1, gen_loss = 0.6251082569360733, disc_loss = 0.021931782364845276
Trained batch 4 in epoch 1, gen_loss = 0.6017991304397583, disc_loss = 0.02213701531291008
Trained batch 5 in epoch 1, gen_loss = 0.6074134012063345, disc_loss = 0.020133725988368194
Trained batch 6 in epoch 1, gen_loss = 0.6079949906894139, disc_loss = 0.01867961511015892
Trained batch 7 in epoch 1, gen_loss = 0.6069226935505867, disc_loss = 0.017936029005795717
Trained batch 8 in epoch 1, gen_loss = 0.6067161758740743, disc_loss = 0.017334748369952042
Trained batch 9 in epoch 1, gen_loss = 0.6041648685932159, disc_loss = 0.016545835044234992
Trained batch 10 in epoch 1, gen_loss = 0.6070000746033408, disc_loss = 0.015891966240649872
Trained batch 11 in epoch 1, gen_loss = 0.6003139267365137, disc_loss = 0.015868277056142688
Trained batch 12 in epoch 1, gen_loss = 0.6012918857427744, disc_loss = 0.01538839449103062
Trained batch 13 in epoch 1, gen_loss = 0.6015640241759164, disc_loss = 0.015073917140918118
Trained batch 14 in epoch 1, gen_loss = 0.6053086956342061, disc_loss = 0.014910395815968513
Trained batch 15 in epoch 1, gen_loss = 0.6027692630887032, disc_loss = 0.014492305694147944
Trained batch 16 in epoch 1, gen_loss = 0.6047285058919121, disc_loss = 0.014133356456809184
Trained batch 17 in epoch 1, gen_loss = 0.5985684196154276, disc_loss = 0.014426377653661702
Trained batch 18 in epoch 1, gen_loss = 0.6058996037433022, disc_loss = 0.016117201186716557
Trained batch 19 in epoch 1, gen_loss = 0.5905496805906296, disc_loss = 0.020189368491992356
Trained batch 20 in epoch 1, gen_loss = 0.5914820035298666, disc_loss = 0.022178151910858496
Trained batch 21 in epoch 1, gen_loss = 0.5878493162718686, disc_loss = 0.02262283501807939
Trained batch 22 in epoch 1, gen_loss = 0.5877486156380695, disc_loss = 0.02284643325306799
Trained batch 23 in epoch 1, gen_loss = 0.5865185956160227, disc_loss = 0.023501277707206707
Trained batch 24 in epoch 1, gen_loss = 0.5890335035324097, disc_loss = 0.02378400560468435
Trained batch 25 in epoch 1, gen_loss = 0.5873963145109323, disc_loss = 0.02346898751476636
Trained batch 26 in epoch 1, gen_loss = 0.5858010009483055, disc_loss = 0.023049718803829618
Trained batch 27 in epoch 1, gen_loss = 0.5840094025645938, disc_loss = 0.02264205945123519
Trained batch 28 in epoch 1, gen_loss = 0.5842982222293985, disc_loss = 0.02283024408950888
Trained batch 29 in epoch 1, gen_loss = 0.5788980573415756, disc_loss = 0.023122846397260824
Trained batch 30 in epoch 1, gen_loss = 0.5811194287192437, disc_loss = 0.022817860327420697
Trained batch 31 in epoch 1, gen_loss = 0.5827462682500482, disc_loss = 0.0224575896281749
Trained batch 32 in epoch 1, gen_loss = 0.5821907980875536, disc_loss = 0.02206602861935442
Trained batch 33 in epoch 1, gen_loss = 0.5792286036645665, disc_loss = 0.02188271234798081
Trained batch 34 in epoch 1, gen_loss = 0.5774424765791212, disc_loss = 0.0216546718031168
Trained batch 35 in epoch 1, gen_loss = 0.5803126734164026, disc_loss = 0.021521725743595097
Trained batch 36 in epoch 1, gen_loss = 0.578578788686443, disc_loss = 0.021384629748157552
Trained batch 37 in epoch 1, gen_loss = 0.5784972176740044, disc_loss = 0.02106910598415293
Trained batch 38 in epoch 1, gen_loss = 0.5788776118021745, disc_loss = 0.020864513798210867
Trained batch 39 in epoch 1, gen_loss = 0.5767615579068661, disc_loss = 0.02066335764247924
Trained batch 40 in epoch 1, gen_loss = 0.5762513229032842, disc_loss = 0.020312178141732768
Trained batch 41 in epoch 1, gen_loss = 0.5767859085684731, disc_loss = 0.019999393694368855
Trained batch 42 in epoch 1, gen_loss = 0.5773269721241885, disc_loss = 0.019751376115045575
Trained batch 43 in epoch 1, gen_loss = 0.5760898556221615, disc_loss = 0.019544290262274444
Trained batch 44 in epoch 1, gen_loss = 0.5767628663116031, disc_loss = 0.01937953983950946
Trained batch 45 in epoch 1, gen_loss = 0.5765000393857127, disc_loss = 0.020776280293079173
Trained batch 46 in epoch 1, gen_loss = 0.5676917528852503, disc_loss = 0.024751324018344602
Trained batch 47 in epoch 1, gen_loss = 0.5669488466034333, disc_loss = 0.025759130764830235
Trained batch 48 in epoch 1, gen_loss = 0.5668156822117008, disc_loss = 0.02669449641882461
Trained batch 49 in epoch 1, gen_loss = 0.5666748541593551, disc_loss = 0.02784179617650807
Trained batch 50 in epoch 1, gen_loss = 0.5654174854942396, disc_loss = 0.02956941626125983
Trained batch 51 in epoch 1, gen_loss = 0.564676199394923, disc_loss = 0.030437558504322972
Trained batch 52 in epoch 1, gen_loss = 0.5625205855324583, disc_loss = 0.030632372638034932
Trained batch 53 in epoch 1, gen_loss = 0.5628811987461867, disc_loss = 0.03113099067747869
Trained batch 54 in epoch 1, gen_loss = 0.5642862303690477, disc_loss = 0.03148962534456091
Trained batch 55 in epoch 1, gen_loss = 0.5612185773040567, disc_loss = 0.03174527312928278
Trained batch 56 in epoch 1, gen_loss = 0.5611354651158316, disc_loss = 0.03137491490659222
Trained batch 57 in epoch 1, gen_loss = 0.5618049415021107, disc_loss = 0.031012447045088327
Trained batch 58 in epoch 1, gen_loss = 0.5609747196658182, disc_loss = 0.030632657275172108
Trained batch 59 in epoch 1, gen_loss = 0.5597379148006439, disc_loss = 0.030246981318729618
Trained batch 60 in epoch 1, gen_loss = 0.5584410902906637, disc_loss = 0.02989462437108159
Trained batch 61 in epoch 1, gen_loss = 0.558296398289742, disc_loss = 0.029528681737100406
Trained batch 62 in epoch 1, gen_loss = 0.5581727458371056, disc_loss = 0.029218233419611814
Trained batch 63 in epoch 1, gen_loss = 0.5570017118006945, disc_loss = 0.02893281963042682
Trained batch 64 in epoch 1, gen_loss = 0.5571002217439505, disc_loss = 0.028586939278130347
Trained batch 65 in epoch 1, gen_loss = 0.5572138672525232, disc_loss = 0.028256186778008036
Trained batch 66 in epoch 1, gen_loss = 0.5560814649311464, disc_loss = 0.02795496067282424
Trained batch 67 in epoch 1, gen_loss = 0.5556404765914468, disc_loss = 0.027662635082378983
Trained batch 68 in epoch 1, gen_loss = 0.5558610316635906, disc_loss = 0.027362590729920328
Trained batch 69 in epoch 1, gen_loss = 0.5560009224074227, disc_loss = 0.027070319592686635
Trained batch 70 in epoch 1, gen_loss = 0.5559271523650263, disc_loss = 0.026814531921868175
Trained batch 71 in epoch 1, gen_loss = 0.5554926751388444, disc_loss = 0.026517441580330744
Trained batch 72 in epoch 1, gen_loss = 0.5549255911618063, disc_loss = 0.026247249826890966
Trained batch 73 in epoch 1, gen_loss = 0.5546093639489766, disc_loss = 0.02602098004993152
Trained batch 74 in epoch 1, gen_loss = 0.5555261198679606, disc_loss = 0.02577909001459678
Trained batch 75 in epoch 1, gen_loss = 0.555426161540182, disc_loss = 0.025545976602619414
Trained batch 76 in epoch 1, gen_loss = 0.5547958140249376, disc_loss = 0.025358477050994897
Trained batch 77 in epoch 1, gen_loss = 0.5552627642949423, disc_loss = 0.025120932113331478
Trained batch 78 in epoch 1, gen_loss = 0.5552317862269245, disc_loss = 0.024898425351734026
Trained batch 79 in epoch 1, gen_loss = 0.5544676914811134, disc_loss = 0.024695837328908964
Trained batch 80 in epoch 1, gen_loss = 0.5546060572435827, disc_loss = 0.024464658628229375
Trained batch 81 in epoch 1, gen_loss = 0.5559278588469435, disc_loss = 0.024457875247363273
Trained batch 82 in epoch 1, gen_loss = 0.5531708878206919, disc_loss = 0.024835438989327257
Trained batch 83 in epoch 1, gen_loss = 0.5544814531292234, disc_loss = 0.02469226816070399
Trained batch 84 in epoch 1, gen_loss = 0.555770310233621, disc_loss = 0.024551279015619966
Trained batch 85 in epoch 1, gen_loss = 0.5555302486863247, disc_loss = 0.024379373815040604
Trained batch 86 in epoch 1, gen_loss = 0.5546006735028892, disc_loss = 0.02425317670186532
Trained batch 87 in epoch 1, gen_loss = 0.5547931245104833, disc_loss = 0.024065971887797456
Trained batch 88 in epoch 1, gen_loss = 0.5550831847646264, disc_loss = 0.023914645943958104
Trained batch 89 in epoch 1, gen_loss = 0.5546201391352548, disc_loss = 0.023730940019918812
Trained batch 90 in epoch 1, gen_loss = 0.5544708721585326, disc_loss = 0.023553114005743146
Trained batch 91 in epoch 1, gen_loss = 0.5546878560081773, disc_loss = 0.023681677584333913
Trained batch 92 in epoch 1, gen_loss = 0.551901860262758, disc_loss = 0.02398288425218354
Trained batch 93 in epoch 1, gen_loss = 0.5520785013411907, disc_loss = 0.023891074008288535
Trained batch 94 in epoch 1, gen_loss = 0.5520445867588646, disc_loss = 0.023723213158940014
Trained batch 95 in epoch 1, gen_loss = 0.5516100854923328, disc_loss = 0.02363768137486962
Trained batch 96 in epoch 1, gen_loss = 0.5509643769755805, disc_loss = 0.023612596776298025
Trained batch 97 in epoch 1, gen_loss = 0.5507292346078523, disc_loss = 0.023438380403938343
Trained batch 98 in epoch 1, gen_loss = 0.5514979735769406, disc_loss = 0.02334394959751705
Trained batch 99 in epoch 1, gen_loss = 0.5511648172140121, disc_loss = 0.02324223006144166
Trained batch 100 in epoch 1, gen_loss = 0.5514112864390458, disc_loss = 0.023112900942416473
Trained batch 101 in epoch 1, gen_loss = 0.5515035402541067, disc_loss = 0.02295104052652331
Trained batch 102 in epoch 1, gen_loss = 0.5506228549966534, disc_loss = 0.02285775054897209
Trained batch 103 in epoch 1, gen_loss = 0.5496907580930454, disc_loss = 0.022777804057113826
Trained batch 104 in epoch 1, gen_loss = 0.5499983591692789, disc_loss = 0.022629441405158667
Trained batch 105 in epoch 1, gen_loss = 0.5503858111377032, disc_loss = 0.02250458029942271
Trained batch 106 in epoch 1, gen_loss = 0.5492714846802649, disc_loss = 0.022386754545270005
Trained batch 107 in epoch 1, gen_loss = 0.5488535786668459, disc_loss = 0.022260400850360317
Trained batch 108 in epoch 1, gen_loss = 0.54938298491163, disc_loss = 0.022249206221329237
Trained batch 109 in epoch 1, gen_loss = 0.548545261404731, disc_loss = 0.022145746246149595
Trained batch 110 in epoch 1, gen_loss = 0.5480731833088506, disc_loss = 0.022042911571056187
Trained batch 111 in epoch 1, gen_loss = 0.5482262777430671, disc_loss = 0.021943564347956062
Trained batch 112 in epoch 1, gen_loss = 0.5474552222057781, disc_loss = 0.021836448349553134
Trained batch 113 in epoch 1, gen_loss = 0.5479432506519452, disc_loss = 0.021711608717675534
Trained batch 114 in epoch 1, gen_loss = 0.5477528147075488, disc_loss = 0.021571526117622853
Trained batch 115 in epoch 1, gen_loss = 0.5471625453953085, disc_loss = 0.0214400245559177
Trained batch 116 in epoch 1, gen_loss = 0.5474243334725372, disc_loss = 0.021304739663043082
Trained batch 117 in epoch 1, gen_loss = 0.5479020852658708, disc_loss = 0.021222212209792462
Trained batch 118 in epoch 1, gen_loss = 0.5464136870969244, disc_loss = 0.021253163824562264
Trained batch 119 in epoch 1, gen_loss = 0.5476449231306711, disc_loss = 0.021235853293910624
Trained batch 120 in epoch 1, gen_loss = 0.5476602995691221, disc_loss = 0.021173107176095492
Trained batch 121 in epoch 1, gen_loss = 0.5474774661611338, disc_loss = 0.02107493196934706
Trained batch 122 in epoch 1, gen_loss = 0.5471275846163431, disc_loss = 0.021754095005250076
Trained batch 123 in epoch 1, gen_loss = 0.5437653550217229, disc_loss = 0.023352683334040544
Trained batch 124 in epoch 1, gen_loss = 0.5431755373477936, disc_loss = 0.025166951201856136
Trained batch 125 in epoch 1, gen_loss = 0.5451588798609991, disc_loss = 0.032196826427169735
Trained batch 126 in epoch 1, gen_loss = 0.5446224046035075, disc_loss = 0.037473763089891025
Trained batch 127 in epoch 1, gen_loss = 0.5454274790827185, disc_loss = 0.04302910624392098
Trained batch 128 in epoch 1, gen_loss = 0.5448602292426797, disc_loss = 0.04647914201107829
Trained batch 129 in epoch 1, gen_loss = 0.5421491941580405, disc_loss = 0.04762949315257944
Trained batch 130 in epoch 1, gen_loss = 0.5389866489945477, disc_loss = 0.04899986829779303
Trained batch 131 in epoch 1, gen_loss = 0.5361192547010653, disc_loss = 0.04973775805256358
Trained batch 132 in epoch 1, gen_loss = 0.5340428031924972, disc_loss = 0.0504677573751126
Trained batch 133 in epoch 1, gen_loss = 0.5318413267829525, disc_loss = 0.05082676439448746
Trained batch 134 in epoch 1, gen_loss = 0.5297393041628379, disc_loss = 0.051035641320049764
Trained batch 135 in epoch 1, gen_loss = 0.5280846107531997, disc_loss = 0.05111756555818241
Trained batch 136 in epoch 1, gen_loss = 0.5263231588106085, disc_loss = 0.051064329609329245
Trained batch 137 in epoch 1, gen_loss = 0.5251165829274965, disc_loss = 0.05098845239431746
Trained batch 138 in epoch 1, gen_loss = 0.5237196261505429, disc_loss = 0.05086413124348405
Trained batch 139 in epoch 1, gen_loss = 0.5228589011090142, disc_loss = 0.050706942905006665
Trained batch 140 in epoch 1, gen_loss = 0.5218137868329988, disc_loss = 0.050615446542964335
Trained batch 141 in epoch 1, gen_loss = 0.5205072340830951, disc_loss = 0.05049963048200162
Trained batch 142 in epoch 1, gen_loss = 0.5201873233268312, disc_loss = 0.05034186734681154
Trained batch 143 in epoch 1, gen_loss = 0.5196738849497504, disc_loss = 0.05013831587792891
Trained batch 144 in epoch 1, gen_loss = 0.5192413073161553, disc_loss = 0.04991132102521329
Trained batch 145 in epoch 1, gen_loss = 0.5192071140220721, disc_loss = 0.04967695925614401
Trained batch 146 in epoch 1, gen_loss = 0.5190143575068233, disc_loss = 0.04947056169589969
Trained batch 147 in epoch 1, gen_loss = 0.518366776608132, disc_loss = 0.049276861645331654
Trained batch 148 in epoch 1, gen_loss = 0.5182812921952882, disc_loss = 0.04903524849663845
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 0.4584107995033264, disc_loss = 0.012959213927388191
Trained batch 1 in epoch 2, gen_loss = 0.44635990262031555, disc_loss = 0.01358900684863329
Trained batch 2 in epoch 2, gen_loss = 0.460581640402476, disc_loss = 0.013807928810516993
Trained batch 3 in epoch 2, gen_loss = 0.4579828381538391, disc_loss = 0.012930914293974638
Trained batch 4 in epoch 2, gen_loss = 0.45991456508636475, disc_loss = 0.01224689930677414
Trained batch 5 in epoch 2, gen_loss = 0.47207250197728473, disc_loss = 0.012066336814314127
Trained batch 6 in epoch 2, gen_loss = 0.46158806341035025, disc_loss = 0.012283437087067537
Trained batch 7 in epoch 2, gen_loss = 0.4757937528192997, disc_loss = 0.016055017826147377
Trained batch 8 in epoch 2, gen_loss = 0.43470399081707, disc_loss = 0.03441779656956593
Trained batch 9 in epoch 2, gen_loss = 0.46334014981985094, disc_loss = 0.057867319975048306
Trained batch 10 in epoch 2, gen_loss = 0.44858152893456543, disc_loss = 0.05635613550178029
Trained batch 11 in epoch 2, gen_loss = 0.42910881464680034, disc_loss = 0.05638564882489542
Trained batch 12 in epoch 2, gen_loss = 0.4150062214869719, disc_loss = 0.056255495390639856
Trained batch 13 in epoch 2, gen_loss = 0.41154327243566513, disc_loss = 0.054602061065712144
Trained batch 14 in epoch 2, gen_loss = 0.40976677437623343, disc_loss = 0.052895442210137845
Trained batch 15 in epoch 2, gen_loss = 0.40575492288917303, disc_loss = 0.05070396751398221
Trained batch 16 in epoch 2, gen_loss = 0.4049399346113205, disc_loss = 0.04834139588124612
Trained batch 17 in epoch 2, gen_loss = 0.4100705161690712, disc_loss = 0.04820801276299688
Trained batch 18 in epoch 2, gen_loss = 0.39706726372241974, disc_loss = 0.04968019418026272
Trained batch 19 in epoch 2, gen_loss = 0.40671113058924674, disc_loss = 0.048621068522334096
Trained batch 20 in epoch 2, gen_loss = 0.41398621386005763, disc_loss = 0.04756628739691916
Trained batch 21 in epoch 2, gen_loss = 0.41429563476280734, disc_loss = 0.04581874100999399
Trained batch 22 in epoch 2, gen_loss = 0.4126907127059024, disc_loss = 0.04468927977849608
Trained batch 23 in epoch 2, gen_loss = 0.41123286448419094, disc_loss = 0.04340050485916436
Trained batch 24 in epoch 2, gen_loss = 0.41309804379940035, disc_loss = 0.04208746999502182
Trained batch 25 in epoch 2, gen_loss = 0.4141095274916062, disc_loss = 0.04086748861636107
Trained batch 26 in epoch 2, gen_loss = 0.4151199807723363, disc_loss = 0.04026915912550909
Trained batch 27 in epoch 2, gen_loss = 0.4093272563602243, disc_loss = 0.04084547216604863
Trained batch 28 in epoch 2, gen_loss = 0.4157345300090724, disc_loss = 0.03984493505338143
Trained batch 29 in epoch 2, gen_loss = 0.4216109956304232, disc_loss = 0.038942038733512166
Trained batch 30 in epoch 2, gen_loss = 0.4262628963878078, disc_loss = 0.04494063481087646
Trained batch 31 in epoch 2, gen_loss = 0.4155466705560684, disc_loss = 0.0499564066703897
Trained batch 32 in epoch 2, gen_loss = 0.4096924089121096, disc_loss = 0.05022780086393609
Trained batch 33 in epoch 2, gen_loss = 0.409367680987891, disc_loss = 0.050523685264017654
Trained batch 34 in epoch 2, gen_loss = 0.4090250726257052, disc_loss = 0.05013133572148425
Trained batch 35 in epoch 2, gen_loss = 0.40616708290245795, disc_loss = 0.04981766348808176
Trained batch 36 in epoch 2, gen_loss = 0.4027613864557163, disc_loss = 0.049226772921109524
Trained batch 37 in epoch 2, gen_loss = 0.40406960601869385, disc_loss = 0.048169408753318224
Trained batch 38 in epoch 2, gen_loss = 0.4048616156364099, disc_loss = 0.047209395024065785
Trained batch 39 in epoch 2, gen_loss = 0.4057053718715906, disc_loss = 0.04620373916113749
Trained batch 40 in epoch 2, gen_loss = 0.4070628550721378, disc_loss = 0.04535089643308666
Trained batch 41 in epoch 2, gen_loss = 0.4070801263054212, disc_loss = 0.044578682886259186
Trained batch 42 in epoch 2, gen_loss = 0.40921595588672993, disc_loss = 0.043826576658026424
Trained batch 43 in epoch 2, gen_loss = 0.41002039780670946, disc_loss = 0.04301201648459854
Trained batch 44 in epoch 2, gen_loss = 0.41039504177040526, disc_loss = 0.04282103995275166
Trained batch 45 in epoch 2, gen_loss = 0.4064847111054089, disc_loss = 0.04287124468702013
Trained batch 46 in epoch 2, gen_loss = 0.4119249743984101, disc_loss = 0.04269759066680327
Trained batch 47 in epoch 2, gen_loss = 0.4126022330795725, disc_loss = 0.04218360877712257
Trained batch 48 in epoch 2, gen_loss = 0.4123957975178349, disc_loss = 0.04152674131969712
Trained batch 49 in epoch 2, gen_loss = 0.41281291395425795, disc_loss = 0.04087884631939232
Trained batch 50 in epoch 2, gen_loss = 0.41349973661058087, disc_loss = 0.04018758565150932
Trained batch 51 in epoch 2, gen_loss = 0.4148133841271584, disc_loss = 0.03956787059835803
Trained batch 52 in epoch 2, gen_loss = 0.41569686076551116, disc_loss = 0.03958693323305474
Trained batch 53 in epoch 2, gen_loss = 0.4115718487236235, disc_loss = 0.040115599494634405
Trained batch 54 in epoch 2, gen_loss = 0.41512010368433866, disc_loss = 0.04001527564938773
Trained batch 55 in epoch 2, gen_loss = 0.4182318752365453, disc_loss = 0.039707499697604884
Trained batch 56 in epoch 2, gen_loss = 0.4192596271372678, disc_loss = 0.039162301728011745
Trained batch 57 in epoch 2, gen_loss = 0.4193505911991514, disc_loss = 0.03870120304957803
Trained batch 58 in epoch 2, gen_loss = 0.41977169857186786, disc_loss = 0.03816824721298733
Trained batch 59 in epoch 2, gen_loss = 0.4199938784042994, disc_loss = 0.037647472019307314
Trained batch 60 in epoch 2, gen_loss = 0.42069860462282527, disc_loss = 0.03718060005425674
Trained batch 61 in epoch 2, gen_loss = 0.42075393613307704, disc_loss = 0.03669451482804312
Trained batch 62 in epoch 2, gen_loss = 0.4205936444184137, disc_loss = 0.036190731776139094
Trained batch 63 in epoch 2, gen_loss = 0.4209279571659863, disc_loss = 0.03570135181507794
Trained batch 64 in epoch 2, gen_loss = 0.421647382241029, disc_loss = 0.03522040914887419
Trained batch 65 in epoch 2, gen_loss = 0.4229514494989858, disc_loss = 0.034789894382949126
Trained batch 66 in epoch 2, gen_loss = 0.42312259682968484, disc_loss = 0.034465227150983775
Trained batch 67 in epoch 2, gen_loss = 0.42331811654217105, disc_loss = 0.03403137136689004
Trained batch 68 in epoch 2, gen_loss = 0.4242801100447558, disc_loss = 0.033613788260929825
Trained batch 69 in epoch 2, gen_loss = 0.4246111959218979, disc_loss = 0.033194438055423756
Trained batch 70 in epoch 2, gen_loss = 0.42512108322600245, disc_loss = 0.03279074040753111
Trained batch 71 in epoch 2, gen_loss = 0.424719658990701, disc_loss = 0.03241984082463508
Trained batch 72 in epoch 2, gen_loss = 0.42493000299963235, disc_loss = 0.03204881898063707
Trained batch 73 in epoch 2, gen_loss = 0.4255941844469792, disc_loss = 0.03167075069772231
Trained batch 74 in epoch 2, gen_loss = 0.42546643455823263, disc_loss = 0.03133144481728474
Trained batch 75 in epoch 2, gen_loss = 0.4258883662129703, disc_loss = 0.030975426694280224
Trained batch 76 in epoch 2, gen_loss = 0.4265483133978658, disc_loss = 0.030637078477045547
Trained batch 77 in epoch 2, gen_loss = 0.42656793808325744, disc_loss = 0.030323305668739173
Trained batch 78 in epoch 2, gen_loss = 0.42697388612771336, disc_loss = 0.03000351977004092
Trained batch 79 in epoch 2, gen_loss = 0.4272413682192564, disc_loss = 0.029685907426755875
Trained batch 80 in epoch 2, gen_loss = 0.42704281284485335, disc_loss = 0.0294164614751935
Trained batch 81 in epoch 2, gen_loss = 0.4276773315377352, disc_loss = 0.02912626434799011
Trained batch 82 in epoch 2, gen_loss = 0.42760270726249877, disc_loss = 0.02884522195995213
Trained batch 83 in epoch 2, gen_loss = 0.4274074885816801, disc_loss = 0.028592929848292398
Trained batch 84 in epoch 2, gen_loss = 0.42778219054726996, disc_loss = 0.02832024572964977
Trained batch 85 in epoch 2, gen_loss = 0.429347789564798, disc_loss = 0.028151965959993905
Trained batch 86 in epoch 2, gen_loss = 0.42926350441472283, disc_loss = 0.027934090159405237
Trained batch 87 in epoch 2, gen_loss = 0.4296819726851853, disc_loss = 0.02772126178553497
Trained batch 88 in epoch 2, gen_loss = 0.4296533093693551, disc_loss = 0.0274790242010874
Trained batch 89 in epoch 2, gen_loss = 0.43012980851862165, disc_loss = 0.027220518452425797
Trained batch 90 in epoch 2, gen_loss = 0.43125307985714506, disc_loss = 0.026980926999105856
Trained batch 91 in epoch 2, gen_loss = 0.4317183983714684, disc_loss = 0.026760635624194274
Trained batch 92 in epoch 2, gen_loss = 0.4320163810124961, disc_loss = 0.026575244963169098
Trained batch 93 in epoch 2, gen_loss = 0.4313013150970987, disc_loss = 0.02638610815034902
Trained batch 94 in epoch 2, gen_loss = 0.4316169183505209, disc_loss = 0.026141685678770666
Trained batch 95 in epoch 2, gen_loss = 0.4325786478196581, disc_loss = 0.025921634330491845
Trained batch 96 in epoch 2, gen_loss = 0.43298317384474055, disc_loss = 0.025689821762330447
Trained batch 97 in epoch 2, gen_loss = 0.43289395284895993, disc_loss = 0.02550334432542476
Trained batch 98 in epoch 2, gen_loss = 0.4337308843328495, disc_loss = 0.02529966104493448
Trained batch 99 in epoch 2, gen_loss = 0.4342136526107788, disc_loss = 0.025298270243220032
Trained batch 100 in epoch 2, gen_loss = 0.4318609037021599, disc_loss = 0.02576122369783202
Trained batch 101 in epoch 2, gen_loss = 0.43421631233364927, disc_loss = 0.025916259840824733
Trained batch 102 in epoch 2, gen_loss = 0.43566753389765916, disc_loss = 0.02583172920530716
Trained batch 103 in epoch 2, gen_loss = 0.43547960857932383, disc_loss = 0.025655506178736687
Trained batch 104 in epoch 2, gen_loss = 0.4351518029258365, disc_loss = 0.025506745367532686
Trained batch 105 in epoch 2, gen_loss = 0.43510470187888955, disc_loss = 0.025313908673541725
Trained batch 106 in epoch 2, gen_loss = 0.4352074705551718, disc_loss = 0.025119715557372736
Trained batch 107 in epoch 2, gen_loss = 0.4356944078096637, disc_loss = 0.024928350549156743
Trained batch 108 in epoch 2, gen_loss = 0.4361261659805928, disc_loss = 0.025153782658723242
Trained batch 109 in epoch 2, gen_loss = 0.4337904683568261, disc_loss = 0.0255240096244961
Trained batch 110 in epoch 2, gen_loss = 0.4332630599404241, disc_loss = 0.02542652196024318
Trained batch 111 in epoch 2, gen_loss = 0.43360792020601885, disc_loss = 0.025279894467010827
Trained batch 112 in epoch 2, gen_loss = 0.4337367710814012, disc_loss = 0.02511349581264421
Trained batch 113 in epoch 2, gen_loss = 0.43293982979498413, disc_loss = 0.024967303242240297
Trained batch 114 in epoch 2, gen_loss = 0.43368064968482306, disc_loss = 0.02489290182762172
Trained batch 115 in epoch 2, gen_loss = 0.4320609875280282, disc_loss = 0.024878818674237822
Trained batch 116 in epoch 2, gen_loss = 0.43407632474206453, disc_loss = 0.024995331457441945
Trained batch 117 in epoch 2, gen_loss = 0.43439844579009684, disc_loss = 0.02486466233208144
Trained batch 118 in epoch 2, gen_loss = 0.4335832533215274, disc_loss = 0.024743298017772055
Trained batch 119 in epoch 2, gen_loss = 0.4337951593101025, disc_loss = 0.024577307239330062
Trained batch 120 in epoch 2, gen_loss = 0.4337766961125303, disc_loss = 0.024399589304619832
Trained batch 121 in epoch 2, gen_loss = 0.4336809332742066, disc_loss = 0.024350190874891448
Trained batch 122 in epoch 2, gen_loss = 0.431742320215799, disc_loss = 0.02437945769160865
Trained batch 123 in epoch 2, gen_loss = 0.4320963510582524, disc_loss = 0.02423277374492177
Trained batch 124 in epoch 2, gen_loss = 0.4325301077365875, disc_loss = 0.024231549356132746
Trained batch 125 in epoch 2, gen_loss = 0.43219430602732156, disc_loss = 0.02410480335340022
Trained batch 126 in epoch 2, gen_loss = 0.4314749236181965, disc_loss = 0.02397680018229161
Trained batch 127 in epoch 2, gen_loss = 0.4315548022277653, disc_loss = 0.023826167689549038
Trained batch 128 in epoch 2, gen_loss = 0.4315577572168306, disc_loss = 0.023672320511798527
Trained batch 129 in epoch 2, gen_loss = 0.4314193734755883, disc_loss = 0.023533769521432428
Trained batch 130 in epoch 2, gen_loss = 0.4311373488593648, disc_loss = 0.02338024361578051
Trained batch 131 in epoch 2, gen_loss = 0.4309570753213131, disc_loss = 0.02324855637517899
Trained batch 132 in epoch 2, gen_loss = 0.4307401307991573, disc_loss = 0.02309941936501379
Trained batch 133 in epoch 2, gen_loss = 0.43066645024427724, disc_loss = 0.022962165556834148
Trained batch 134 in epoch 2, gen_loss = 0.4303235199716356, disc_loss = 0.022832328386397826
Trained batch 135 in epoch 2, gen_loss = 0.43003413891967607, disc_loss = 0.02270976415842169
Trained batch 136 in epoch 2, gen_loss = 0.4302033725446158, disc_loss = 0.022575202100590743
Trained batch 137 in epoch 2, gen_loss = 0.4301682660977046, disc_loss = 0.0224555089438766
Trained batch 138 in epoch 2, gen_loss = 0.43010849103653176, disc_loss = 0.02232367148549169
Trained batch 139 in epoch 2, gen_loss = 0.42989153606551034, disc_loss = 0.02219175199445869
Trained batch 140 in epoch 2, gen_loss = 0.42993998886845636, disc_loss = 0.022435020979044706
Trained batch 141 in epoch 2, gen_loss = 0.4276509534725001, disc_loss = 0.022995865975939472
Trained batch 142 in epoch 2, gen_loss = 0.4271594804900509, disc_loss = 0.022905994962145397
Trained batch 143 in epoch 2, gen_loss = 0.4277693631334437, disc_loss = 0.022958992359538872
Trained batch 144 in epoch 2, gen_loss = 0.426830505502635, disc_loss = 0.0229429771931007
Trained batch 145 in epoch 2, gen_loss = 0.42674759887669184, disc_loss = 0.02286137645579364
Trained batch 146 in epoch 2, gen_loss = 0.426971778172214, disc_loss = 0.022745776313300034
Trained batch 147 in epoch 2, gen_loss = 0.4260935892124434, disc_loss = 0.022666050718996574
Trained batch 148 in epoch 2, gen_loss = 0.42592381550961694, disc_loss = 0.022544840769529742
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 0.3928256332874298, disc_loss = 0.010868895798921585
Trained batch 1 in epoch 3, gen_loss = 0.36816324293613434, disc_loss = 0.009584594517946243
Trained batch 2 in epoch 3, gen_loss = 0.3749946653842926, disc_loss = 0.008153460609416166
Trained batch 3 in epoch 3, gen_loss = 0.38506652414798737, disc_loss = 0.007770246127620339
Trained batch 4 in epoch 3, gen_loss = 0.40034504532814025, disc_loss = 0.00744882170110941
Trained batch 5 in epoch 3, gen_loss = 0.3984326769908269, disc_loss = 0.00694184269135197
Trained batch 6 in epoch 3, gen_loss = 0.40304907730647493, disc_loss = 0.006694476984973464
Trained batch 7 in epoch 3, gen_loss = 0.4019668772816658, disc_loss = 0.00634402027935721
Trained batch 8 in epoch 3, gen_loss = 0.4049175414774153, disc_loss = 0.005929852137342095
Trained batch 9 in epoch 3, gen_loss = 0.40388359129428864, disc_loss = 0.0069824496516957876
Trained batch 10 in epoch 3, gen_loss = 0.3910189541903409, disc_loss = 0.008341466182504188
Trained batch 11 in epoch 3, gen_loss = 0.40524859229723614, disc_loss = 0.009549345530103892
Trained batch 12 in epoch 3, gen_loss = 0.4045089345711928, disc_loss = 0.00919123704975041
Trained batch 13 in epoch 3, gen_loss = 0.399778168116297, disc_loss = 0.009432648923913283
Trained batch 14 in epoch 3, gen_loss = 0.4012249926726023, disc_loss = 0.009183068030203382
Trained batch 15 in epoch 3, gen_loss = 0.4033879842609167, disc_loss = 0.008823583906632848
Trained batch 16 in epoch 3, gen_loss = 0.40513309310464296, disc_loss = 0.008536824970232212
Trained batch 17 in epoch 3, gen_loss = 0.4030004557636049, disc_loss = 0.008417433968538212
Trained batch 18 in epoch 3, gen_loss = 0.4054619152294962, disc_loss = 0.008140699533549579
Trained batch 19 in epoch 3, gen_loss = 0.40796697288751604, disc_loss = 0.007961851393338293
Trained batch 20 in epoch 3, gen_loss = 0.4057093177522932, disc_loss = 0.007804606253990815
Trained batch 21 in epoch 3, gen_loss = 0.40437275442210113, disc_loss = 0.0077348069647665725
Trained batch 22 in epoch 3, gen_loss = 0.40625754646632983, disc_loss = 0.0075960095830099736
Trained batch 23 in epoch 3, gen_loss = 0.4069193626443545, disc_loss = 0.007600665936479345
Trained batch 24 in epoch 3, gen_loss = 0.4075118100643158, disc_loss = 0.007541849492117763
Trained batch 25 in epoch 3, gen_loss = 0.4084550062051186, disc_loss = 0.007508372180522061
Trained batch 26 in epoch 3, gen_loss = 0.4056527437987151, disc_loss = 0.007527236559393781
Trained batch 27 in epoch 3, gen_loss = 0.4041199322257723, disc_loss = 0.007543226080347917
Trained batch 28 in epoch 3, gen_loss = 0.4072613500315568, disc_loss = 0.007685121638571908
Trained batch 29 in epoch 3, gen_loss = 0.40808765788873036, disc_loss = 0.007573665531041721
Trained batch 30 in epoch 3, gen_loss = 0.4067500147127336, disc_loss = 0.0075118204113096
Trained batch 31 in epoch 3, gen_loss = 0.4080637423321605, disc_loss = 0.007405555261357222
Trained batch 32 in epoch 3, gen_loss = 0.40817062601898657, disc_loss = 0.007254937078070008
Trained batch 33 in epoch 3, gen_loss = 0.408118651193731, disc_loss = 0.007100719746257014
Trained batch 34 in epoch 3, gen_loss = 0.40743385553359984, disc_loss = 0.007070901065266558
Trained batch 35 in epoch 3, gen_loss = 0.40667015065749484, disc_loss = 0.0069993703639031285
Trained batch 36 in epoch 3, gen_loss = 0.4068711263102454, disc_loss = 0.006898719647496536
Trained batch 37 in epoch 3, gen_loss = 0.4082977497263959, disc_loss = 0.006837225782586948
Trained batch 38 in epoch 3, gen_loss = 0.40825178837164855, disc_loss = 0.006714181419318685
Trained batch 39 in epoch 3, gen_loss = 0.40815942734479904, disc_loss = 0.006596666143741459
Trained batch 40 in epoch 3, gen_loss = 0.40729542403686336, disc_loss = 0.0065220377532901564
Trained batch 41 in epoch 3, gen_loss = 0.40818839768568677, disc_loss = 0.006536046104017822
Trained batch 42 in epoch 3, gen_loss = 0.40671171906382536, disc_loss = 0.006557736421263841
Trained batch 43 in epoch 3, gen_loss = 0.40698910640044644, disc_loss = 0.006473010368856855
Trained batch 44 in epoch 3, gen_loss = 0.4072523746225569, disc_loss = 0.006391017765013708
Trained batch 45 in epoch 3, gen_loss = 0.4074471340231273, disc_loss = 0.006319287410208389
Trained batch 46 in epoch 3, gen_loss = 0.40818157665272975, disc_loss = 0.006232860775545556
Trained batch 47 in epoch 3, gen_loss = 0.4082635312030713, disc_loss = 0.006158691345869253
Trained batch 48 in epoch 3, gen_loss = 0.4088194680457212, disc_loss = 0.006105501608618972
Trained batch 49 in epoch 3, gen_loss = 0.4087753182649612, disc_loss = 0.006078029558993876
Trained batch 50 in epoch 3, gen_loss = 0.4082377488706626, disc_loss = 0.006033249112649583
Trained batch 51 in epoch 3, gen_loss = 0.4092131039270988, disc_loss = 0.006003642942792235
Trained batch 52 in epoch 3, gen_loss = 0.4097210506223283, disc_loss = 0.005983119887598562
Trained batch 53 in epoch 3, gen_loss = 0.4098449239024409, disc_loss = 0.00591698186730759
Trained batch 54 in epoch 3, gen_loss = 0.4101578669114546, disc_loss = 0.005850560044531118
Trained batch 55 in epoch 3, gen_loss = 0.4105694613286427, disc_loss = 0.005794615671870166
Trained batch 56 in epoch 3, gen_loss = 0.4107747287080999, disc_loss = 0.0057343747425955115
Trained batch 57 in epoch 3, gen_loss = 0.41115662815241977, disc_loss = 0.0056839285273875655
Trained batch 58 in epoch 3, gen_loss = 0.4112290416733693, disc_loss = 0.005638603507777897
Trained batch 59 in epoch 3, gen_loss = 0.4118146002292633, disc_loss = 0.005583927167269091
Trained batch 60 in epoch 3, gen_loss = 0.4124169383869796, disc_loss = 0.005583682288339392
Trained batch 61 in epoch 3, gen_loss = 0.41207637373478184, disc_loss = 0.0055533411477001445
Trained batch 62 in epoch 3, gen_loss = 0.41217536774892655, disc_loss = 0.005542384549265816
Trained batch 63 in epoch 3, gen_loss = 0.41283996496349573, disc_loss = 0.005499621776834829
Trained batch 64 in epoch 3, gen_loss = 0.41373655154154854, disc_loss = 0.006209201863608681
Trained batch 65 in epoch 3, gen_loss = 0.40691732530566777, disc_loss = 0.009639656548670522
Trained batch 66 in epoch 3, gen_loss = 0.40955941873922275, disc_loss = 0.014219855733299211
Trained batch 67 in epoch 3, gen_loss = 0.40883476533653107, disc_loss = 0.014780228721279213
Trained batch 68 in epoch 3, gen_loss = 0.4063407345202522, disc_loss = 0.015158705936366881
Trained batch 69 in epoch 3, gen_loss = 0.4043596955814532, disc_loss = 0.015397499538292843
Trained batch 70 in epoch 3, gen_loss = 0.4027984044186666, disc_loss = 0.015688608895698692
Trained batch 71 in epoch 3, gen_loss = 0.399755133367661, disc_loss = 0.015961538104521524
Trained batch 72 in epoch 3, gen_loss = 0.39983800119937285, disc_loss = 0.016103881101876702
Trained batch 73 in epoch 3, gen_loss = 0.3985917635161329, disc_loss = 0.01612113371831239
Trained batch 74 in epoch 3, gen_loss = 0.39788454279303553, disc_loss = 0.01691638237175842
Trained batch 75 in epoch 3, gen_loss = 0.39277856645027276, disc_loss = 0.01869697404081786
Trained batch 76 in epoch 3, gen_loss = 0.39305574558191486, disc_loss = 0.018611983743846996
Trained batch 77 in epoch 3, gen_loss = 0.39418987132226807, disc_loss = 0.018663003989972938
Trained batch 78 in epoch 3, gen_loss = 0.39414161146630217, disc_loss = 0.018564797439789282
Trained batch 79 in epoch 3, gen_loss = 0.3930041987914592, disc_loss = 0.01849632879893761
Trained batch 80 in epoch 3, gen_loss = 0.3922410824876509, disc_loss = 0.0183426783632855
Trained batch 81 in epoch 3, gen_loss = 0.3927820681526167, disc_loss = 0.018185547675096954
Trained batch 82 in epoch 3, gen_loss = 0.3926519622734512, disc_loss = 0.018879416216366803
Trained batch 83 in epoch 3, gen_loss = 0.3879651075583838, disc_loss = 0.02062416671764194
Trained batch 84 in epoch 3, gen_loss = 0.38593476007089894, disc_loss = 0.020814004110391526
Trained batch 85 in epoch 3, gen_loss = 0.38688589264313844, disc_loss = 0.021358267433919706
Trained batch 86 in epoch 3, gen_loss = 0.3857403501611331, disc_loss = 0.02134499335715055
Trained batch 87 in epoch 3, gen_loss = 0.3853975735520097, disc_loss = 0.021262144910658455
Trained batch 88 in epoch 3, gen_loss = 0.38567550107836723, disc_loss = 0.021156019434395632
Trained batch 89 in epoch 3, gen_loss = 0.38660247934361297, disc_loss = 0.021054641206541824
Trained batch 90 in epoch 3, gen_loss = 0.3859066315977783, disc_loss = 0.020930875059483305
Trained batch 91 in epoch 3, gen_loss = 0.386182118166724, disc_loss = 0.02078212005764489
Trained batch 92 in epoch 3, gen_loss = 0.3865525156499878, disc_loss = 0.020641324888934852
Trained batch 93 in epoch 3, gen_loss = 0.3871550998709937, disc_loss = 0.020488706831027693
Trained batch 94 in epoch 3, gen_loss = 0.38788955537112135, disc_loss = 0.02034696725589272
Trained batch 95 in epoch 3, gen_loss = 0.3873618193514024, disc_loss = 0.020221045257737085
Trained batch 96 in epoch 3, gen_loss = 0.38805560702362013, disc_loss = 0.02006513581457596
Trained batch 97 in epoch 3, gen_loss = 0.38932894850719946, disc_loss = 0.019935747344826102
Trained batch 98 in epoch 3, gen_loss = 0.38947640054605226, disc_loss = 0.019821640144036423
Trained batch 99 in epoch 3, gen_loss = 0.38923681151121853, disc_loss = 0.01980509208748117
Trained batch 100 in epoch 3, gen_loss = 0.3900813579485558, disc_loss = 0.019679677785641635
Trained batch 101 in epoch 3, gen_loss = 0.39076405219441535, disc_loss = 0.019529174632100643
Trained batch 102 in epoch 3, gen_loss = 0.3909522732991038, disc_loss = 0.019376803318364094
Trained batch 103 in epoch 3, gen_loss = 0.3913974376180424, disc_loss = 0.019238555967324197
Trained batch 104 in epoch 3, gen_loss = 0.3918537089867251, disc_loss = 0.01915430804670212
Trained batch 105 in epoch 3, gen_loss = 0.39252622436099455, disc_loss = 0.019068826053660573
Trained batch 106 in epoch 3, gen_loss = 0.3914417427764318, disc_loss = 0.019107236685753565
Trained batch 107 in epoch 3, gen_loss = 0.3925754249578825, disc_loss = 0.019009222580482148
Trained batch 108 in epoch 3, gen_loss = 0.3931684213425588, disc_loss = 0.018875233647456274
Trained batch 109 in epoch 3, gen_loss = 0.3929477402771061, disc_loss = 0.01875568833413788
Trained batch 110 in epoch 3, gen_loss = 0.39304422107231507, disc_loss = 0.018626866180466505
Trained batch 111 in epoch 3, gen_loss = 0.3935671470992799, disc_loss = 0.01849749775595098
Trained batch 112 in epoch 3, gen_loss = 0.3941297500468461, disc_loss = 0.018406423812204625
Trained batch 113 in epoch 3, gen_loss = 0.39487502511525363, disc_loss = 0.018764664792749835
Trained batch 114 in epoch 3, gen_loss = 0.39195488999071326, disc_loss = 0.02006595698185265
Trained batch 115 in epoch 3, gen_loss = 0.3912921157055374, disc_loss = 0.020120873627782768
Trained batch 116 in epoch 3, gen_loss = 0.39261814006246054, disc_loss = 0.020442975603410195
Trained batch 117 in epoch 3, gen_loss = 0.3920447123947285, disc_loss = 0.02040877077783758
Trained batch 118 in epoch 3, gen_loss = 0.3910680212581358, disc_loss = 0.02037457806966072
Trained batch 119 in epoch 3, gen_loss = 0.39206179277971387, disc_loss = 0.020353896463833128
Trained batch 120 in epoch 3, gen_loss = 0.391723585492077, disc_loss = 0.02024041122972411
Trained batch 121 in epoch 3, gen_loss = 0.39125505917262837, disc_loss = 0.020123917657164397
Trained batch 122 in epoch 3, gen_loss = 0.3911623060400408, disc_loss = 0.0200031258760217
Trained batch 123 in epoch 3, gen_loss = 0.39163936767727137, disc_loss = 0.01989384827151474
Trained batch 124 in epoch 3, gen_loss = 0.3912229354083538, disc_loss = 0.019787082323804498
Trained batch 125 in epoch 3, gen_loss = 0.3914943852772315, disc_loss = 0.01967799349961477
Trained batch 126 in epoch 3, gen_loss = 0.39127224094168406, disc_loss = 0.019576360968374243
Trained batch 127 in epoch 3, gen_loss = 0.3909175961453002, disc_loss = 0.01948657681896293
Trained batch 128 in epoch 3, gen_loss = 0.39074621410217397, disc_loss = 0.019367409294268997
Trained batch 129 in epoch 3, gen_loss = 0.3908429228055936, disc_loss = 0.019251675497239027
Trained batch 130 in epoch 3, gen_loss = 0.39072605350431594, disc_loss = 0.019172944137400002
Trained batch 131 in epoch 3, gen_loss = 0.39095349336099444, disc_loss = 0.019053178858788062
Trained batch 132 in epoch 3, gen_loss = 0.39108727723920256, disc_loss = 0.018946174260831082
Trained batch 133 in epoch 3, gen_loss = 0.3907262813855908, disc_loss = 0.018875692604429353
Trained batch 134 in epoch 3, gen_loss = 0.3906528801553779, disc_loss = 0.018776334889440072
Trained batch 135 in epoch 3, gen_loss = 0.39088112244601636, disc_loss = 0.018665648418177357
Trained batch 136 in epoch 3, gen_loss = 0.39155132924444486, disc_loss = 0.018571787853691266
Trained batch 137 in epoch 3, gen_loss = 0.3910334941431664, disc_loss = 0.01848461259615378
Trained batch 138 in epoch 3, gen_loss = 0.3913929284208541, disc_loss = 0.0184003756575876
Trained batch 139 in epoch 3, gen_loss = 0.3913952437628593, disc_loss = 0.018309377742532107
Trained batch 140 in epoch 3, gen_loss = 0.3907574780602404, disc_loss = 0.018244088320259717
Trained batch 141 in epoch 3, gen_loss = 0.39178376316919294, disc_loss = 0.01820794363427435
Trained batch 142 in epoch 3, gen_loss = 0.39200845566558673, disc_loss = 0.01811417178543923
Trained batch 143 in epoch 3, gen_loss = 0.39179562960958314, disc_loss = 0.018052580695237137
Trained batch 144 in epoch 3, gen_loss = 0.3930287819227268, disc_loss = 0.01802544519305229
Trained batch 145 in epoch 3, gen_loss = 0.3930282539445652, disc_loss = 0.018080699002395752
Trained batch 146 in epoch 3, gen_loss = 0.3916609607332823, disc_loss = 0.018276046289980006
Trained batch 147 in epoch 3, gen_loss = 0.3930902392225894, disc_loss = 0.01839058565579959
Trained batch 148 in epoch 3, gen_loss = 0.3936545524571166, disc_loss = 0.018331282653364558
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 0.3844185471534729, disc_loss = 0.004842906259000301
Trained batch 1 in epoch 4, gen_loss = 0.3725598156452179, disc_loss = 0.006063987268134952
Trained batch 2 in epoch 4, gen_loss = 0.38304917017618817, disc_loss = 0.0070297263252238435
Trained batch 3 in epoch 4, gen_loss = 0.378248393535614, disc_loss = 0.006270617595873773
Trained batch 4 in epoch 4, gen_loss = 0.37693860530853274, disc_loss = 0.005731250671669841
Trained batch 5 in epoch 4, gen_loss = 0.37436074018478394, disc_loss = 0.005367323950243493
Trained batch 6 in epoch 4, gen_loss = 0.38499867064612253, disc_loss = 0.005134033305304391
Trained batch 7 in epoch 4, gen_loss = 0.3878890797495842, disc_loss = 0.005145080212969333
Trained batch 8 in epoch 4, gen_loss = 0.3814475437005361, disc_loss = 0.004989424409965674
Trained batch 9 in epoch 4, gen_loss = 0.3807403087615967, disc_loss = 0.004782913764938712
Trained batch 10 in epoch 4, gen_loss = 0.3827027515931563, disc_loss = 0.00494218444113027
Trained batch 11 in epoch 4, gen_loss = 0.385882668197155, disc_loss = 0.004730459496689339
Trained batch 12 in epoch 4, gen_loss = 0.38421758550864, disc_loss = 0.004619075486866327
Trained batch 13 in epoch 4, gen_loss = 0.38442908014569965, disc_loss = 0.004487379038307283
Trained batch 14 in epoch 4, gen_loss = 0.38348389863967897, disc_loss = 0.004320584408318003
Trained batch 15 in epoch 4, gen_loss = 0.3811229355633259, disc_loss = 0.00423570912971627
Trained batch 16 in epoch 4, gen_loss = 0.3803218953749713, disc_loss = 0.0041022303322439686
Trained batch 17 in epoch 4, gen_loss = 0.3809325844049454, disc_loss = 0.004130208851873047
Trained batch 18 in epoch 4, gen_loss = 0.38300235491049917, disc_loss = 0.004070170432035076
Trained batch 19 in epoch 4, gen_loss = 0.383252839744091, disc_loss = 0.004114495555404574
Trained batch 20 in epoch 4, gen_loss = 0.38338179389635724, disc_loss = 0.0042051447533248435
Trained batch 21 in epoch 4, gen_loss = 0.382422226396474, disc_loss = 0.0042091264198957515
Trained batch 22 in epoch 4, gen_loss = 0.38325026760930603, disc_loss = 0.004123313534680916
Trained batch 23 in epoch 4, gen_loss = 0.38248412186900776, disc_loss = 0.004101482355811943
Trained batch 24 in epoch 4, gen_loss = 0.3837518775463104, disc_loss = 0.0040548901539295915
Trained batch 25 in epoch 4, gen_loss = 0.3837827111666019, disc_loss = 0.00403507670853287
Trained batch 26 in epoch 4, gen_loss = 0.38403164788528726, disc_loss = 0.004031993664318213
Trained batch 27 in epoch 4, gen_loss = 0.3827955275774002, disc_loss = 0.003969846052184168
Trained batch 28 in epoch 4, gen_loss = 0.38136089978546933, disc_loss = 0.00391805489900811
Trained batch 29 in epoch 4, gen_loss = 0.38279424409071605, disc_loss = 0.003867001373631259
Trained batch 30 in epoch 4, gen_loss = 0.38317882341723286, disc_loss = 0.003876857542162461
Trained batch 31 in epoch 4, gen_loss = 0.38233983516693115, disc_loss = 0.003889904408424627
Trained batch 32 in epoch 4, gen_loss = 0.3827243275714643, disc_loss = 0.0038604527344983635
Trained batch 33 in epoch 4, gen_loss = 0.38359508619588967, disc_loss = 0.003823351169772008
Trained batch 34 in epoch 4, gen_loss = 0.384149364062718, disc_loss = 0.0046959698732410154
Trained batch 35 in epoch 4, gen_loss = 0.3753647555907567, disc_loss = 0.006686919937945074
Trained batch 36 in epoch 4, gen_loss = 0.3839254798115911, disc_loss = 0.013528280010497247
Trained batch 37 in epoch 4, gen_loss = 0.3732260498953493, disc_loss = 0.020017404942528197
Trained batch 38 in epoch 4, gen_loss = 0.3711923637833351, disc_loss = 0.02146959978227432
Trained batch 39 in epoch 4, gen_loss = 0.3701807977631688, disc_loss = 0.02249249112792313
Trained batch 40 in epoch 4, gen_loss = 0.36736110089028756, disc_loss = 0.023436542736684402
Trained batch 41 in epoch 4, gen_loss = 0.36546144758661586, disc_loss = 0.023595883555355527
Trained batch 42 in epoch 4, gen_loss = 0.36513911863399107, disc_loss = 0.02340617373065893
Trained batch 43 in epoch 4, gen_loss = 0.3653302207927812, disc_loss = 0.023099382619627497
Trained batch 44 in epoch 4, gen_loss = 0.36622446791993246, disc_loss = 0.022756384933988252
Trained batch 45 in epoch 4, gen_loss = 0.36638092492585594, disc_loss = 0.02259380708489081
Trained batch 46 in epoch 4, gen_loss = 0.3646765530426451, disc_loss = 0.022377009503543377
Trained batch 47 in epoch 4, gen_loss = 0.36421570818250376, disc_loss = 0.022034733245770138
Trained batch 48 in epoch 4, gen_loss = 0.3644952063961905, disc_loss = 0.02168373240880212
Trained batch 49 in epoch 4, gen_loss = 0.36449722841382026, disc_loss = 0.021382903028279544
Trained batch 50 in epoch 4, gen_loss = 0.36484801433250014, disc_loss = 0.02114677918600101
Trained batch 51 in epoch 4, gen_loss = 0.3661519834915033, disc_loss = 0.02081258565438195
Trained batch 52 in epoch 4, gen_loss = 0.367135743065825, disc_loss = 0.02051527430039813
Trained batch 53 in epoch 4, gen_loss = 0.36726963699415877, disc_loss = 0.02020470065030235
Trained batch 54 in epoch 4, gen_loss = 0.36832391849972984, disc_loss = 0.0198905335188928
Trained batch 55 in epoch 4, gen_loss = 0.36916451808065176, disc_loss = 0.019597296370193362
Trained batch 56 in epoch 4, gen_loss = 0.3699728502777585, disc_loss = 0.019327599326508085
Trained batch 57 in epoch 4, gen_loss = 0.3699428080741701, disc_loss = 0.019094907052429586
Trained batch 58 in epoch 4, gen_loss = 0.37037271273843314, disc_loss = 0.01882845414328878
Trained batch 59 in epoch 4, gen_loss = 0.3722684613118569, disc_loss = 0.01858581358877321
Trained batch 60 in epoch 4, gen_loss = 0.37345169032694864, disc_loss = 0.018352695557548374
Trained batch 61 in epoch 4, gen_loss = 0.3740252209526877, disc_loss = 0.018133345082582485
Trained batch 62 in epoch 4, gen_loss = 0.3748155932814356, disc_loss = 0.017923481636754578
Trained batch 63 in epoch 4, gen_loss = 0.37639636744279414, disc_loss = 0.017696238137432374
Trained batch 64 in epoch 4, gen_loss = 0.3776979841865026, disc_loss = 0.017474428592966152
Trained batch 65 in epoch 4, gen_loss = 0.37780972784667305, disc_loss = 0.017262369662410383
Trained batch 66 in epoch 4, gen_loss = 0.3790757372530539, disc_loss = 0.01712971956316215
Trained batch 67 in epoch 4, gen_loss = 0.37896629346205907, disc_loss = 0.016972540220355287
Trained batch 68 in epoch 4, gen_loss = 0.3801749025781949, disc_loss = 0.016971810248450958
Trained batch 69 in epoch 4, gen_loss = 0.3793519927987031, disc_loss = 0.016948221025190183
Trained batch 70 in epoch 4, gen_loss = 0.38073467169429215, disc_loss = 0.01679131875313084
Trained batch 71 in epoch 4, gen_loss = 0.3821693982722031, disc_loss = 0.01663602120243013
Trained batch 72 in epoch 4, gen_loss = 0.38241143841041275, disc_loss = 0.016496536321938038
Trained batch 73 in epoch 4, gen_loss = 0.3829855678250661, disc_loss = 0.016313607386011328
Trained batch 74 in epoch 4, gen_loss = 0.3837906329830488, disc_loss = 0.016133424441019693
Trained batch 75 in epoch 4, gen_loss = 0.3844947380650985, disc_loss = 0.016039927784157425
Trained batch 76 in epoch 4, gen_loss = 0.3840991472462555, disc_loss = 0.015891377009790052
Trained batch 77 in epoch 4, gen_loss = 0.38424307690599024, disc_loss = 0.01573578070383519
Trained batch 78 in epoch 4, gen_loss = 0.3849486200303971, disc_loss = 0.01557451633653969
Trained batch 79 in epoch 4, gen_loss = 0.3859006558544934, disc_loss = 0.015424743731273338
Trained batch 80 in epoch 4, gen_loss = 0.38558937048102604, disc_loss = 0.015291119195566869
Trained batch 81 in epoch 4, gen_loss = 0.3853657333770903, disc_loss = 0.015320902457460761
Trained batch 82 in epoch 4, gen_loss = 0.38398876041173935, disc_loss = 0.015439621200897249
Trained batch 83 in epoch 4, gen_loss = 0.38518526236571016, disc_loss = 0.015340033874270461
Trained batch 84 in epoch 4, gen_loss = 0.3855993545230697, disc_loss = 0.015199389840092729
Trained batch 85 in epoch 4, gen_loss = 0.3861023964750212, disc_loss = 0.015072385331095998
Trained batch 86 in epoch 4, gen_loss = 0.3863413005895998, disc_loss = 0.014971389194372398
Trained batch 87 in epoch 4, gen_loss = 0.38582975595173513, disc_loss = 0.014843132717280903
Trained batch 88 in epoch 4, gen_loss = 0.3857666171166334, disc_loss = 0.014771825550228691
Trained batch 89 in epoch 4, gen_loss = 0.38676069155335424, disc_loss = 0.01479923426070147
Trained batch 90 in epoch 4, gen_loss = 0.38676778963961445, disc_loss = 0.01469427071368465
Trained batch 91 in epoch 4, gen_loss = 0.3866522591561079, disc_loss = 0.014599458901616543
Trained batch 92 in epoch 4, gen_loss = 0.3866940840117393, disc_loss = 0.014498981977662733
Trained batch 93 in epoch 4, gen_loss = 0.38748004596601143, disc_loss = 0.014424602823094167
Trained batch 94 in epoch 4, gen_loss = 0.38795138197509865, disc_loss = 0.014351644415996576
Trained batch 95 in epoch 4, gen_loss = 0.3879343861869226, disc_loss = 0.014227338889516735
Trained batch 96 in epoch 4, gen_loss = 0.38842008170700565, disc_loss = 0.014125755145550542
Trained batch 97 in epoch 4, gen_loss = 0.3874287767221733, disc_loss = 0.014052962145425988
Trained batch 98 in epoch 4, gen_loss = 0.3872891156510873, disc_loss = 0.013951365970018687
Trained batch 99 in epoch 4, gen_loss = 0.38756114222109317, disc_loss = 0.01384497515624389
Trained batch 100 in epoch 4, gen_loss = 0.3876896209203371, disc_loss = 0.013753513752547379
Trained batch 101 in epoch 4, gen_loss = 0.387491151763528, disc_loss = 0.013705032450767854
Trained batch 102 in epoch 4, gen_loss = 0.38674661032493834, disc_loss = 0.01369352453587197
Trained batch 103 in epoch 4, gen_loss = 0.3862606425268146, disc_loss = 0.013631113520554768
Trained batch 104 in epoch 4, gen_loss = 0.38733581936075573, disc_loss = 0.014366955134928937
Trained batch 105 in epoch 4, gen_loss = 0.3828676098360206, disc_loss = 0.017801316281481874
Trained batch 106 in epoch 4, gen_loss = 0.38033902004500414, disc_loss = 0.01899934051967461
Trained batch 107 in epoch 4, gen_loss = 0.3798152166936133, disc_loss = 0.02116027957526967
Trained batch 108 in epoch 4, gen_loss = 0.37779825584057275, disc_loss = 0.022466582034654712
Trained batch 109 in epoch 4, gen_loss = 0.376421812989495, disc_loss = 0.02300426567354324
Trained batch 110 in epoch 4, gen_loss = 0.37590807193034403, disc_loss = 0.02321094298223453
Trained batch 111 in epoch 4, gen_loss = 0.375248126153435, disc_loss = 0.02335279052619756
Trained batch 112 in epoch 4, gen_loss = 0.37462576327070723, disc_loss = 0.023515929000254357
Trained batch 113 in epoch 4, gen_loss = 0.37341824356924025, disc_loss = 0.023544276037188082
Trained batch 114 in epoch 4, gen_loss = 0.3746753969918127, disc_loss = 0.02344881126292698
Trained batch 115 in epoch 4, gen_loss = 0.3753356021539918, disc_loss = 0.02333951597944994
Trained batch 116 in epoch 4, gen_loss = 0.37567788999304813, disc_loss = 0.02322518422156891
Trained batch 117 in epoch 4, gen_loss = 0.37516640379267224, disc_loss = 0.023114607024195967
Trained batch 118 in epoch 4, gen_loss = 0.37526183894702364, disc_loss = 0.022971875310147636
Trained batch 119 in epoch 4, gen_loss = 0.3754549500842889, disc_loss = 0.022817425509371485
Trained batch 120 in epoch 4, gen_loss = 0.37577844725167453, disc_loss = 0.022659219695593823
Trained batch 121 in epoch 4, gen_loss = 0.3759114300129843, disc_loss = 0.022515886789569478
Trained batch 122 in epoch 4, gen_loss = 0.3759438143513067, disc_loss = 0.022372049557771986
Trained batch 123 in epoch 4, gen_loss = 0.37637450954606455, disc_loss = 0.022227585786998634
Trained batch 124 in epoch 4, gen_loss = 0.37662452030181887, disc_loss = 0.022095201609656216
Trained batch 125 in epoch 4, gen_loss = 0.37700429771627697, disc_loss = 0.02196697195777522
Trained batch 126 in epoch 4, gen_loss = 0.3771530122268857, disc_loss = 0.021832084296065875
Trained batch 127 in epoch 4, gen_loss = 0.37737200199626386, disc_loss = 0.02169415631396987
Trained batch 128 in epoch 4, gen_loss = 0.37763494368671446, disc_loss = 0.021554352968295876
Trained batch 129 in epoch 4, gen_loss = 0.37764928730634545, disc_loss = 0.021411622856528714
Trained batch 130 in epoch 4, gen_loss = 0.37778162774238877, disc_loss = 0.02127294503294557
Trained batch 131 in epoch 4, gen_loss = 0.37821209114609344, disc_loss = 0.021175038887921608
Trained batch 132 in epoch 4, gen_loss = 0.3775959893276817, disc_loss = 0.021116597507905243
Trained batch 133 in epoch 4, gen_loss = 0.3779258639065187, disc_loss = 0.02099506849589855
Trained batch 134 in epoch 4, gen_loss = 0.3785268520867383, disc_loss = 0.020918155592624787
Trained batch 135 in epoch 4, gen_loss = 0.37828464477377777, disc_loss = 0.02080503633410177
Trained batch 136 in epoch 4, gen_loss = 0.3783049546454075, disc_loss = 0.020677992390863
Trained batch 137 in epoch 4, gen_loss = 0.37807982317779376, disc_loss = 0.02055984911630335
Trained batch 138 in epoch 4, gen_loss = 0.3780767160782711, disc_loss = 0.020438742018204264
Trained batch 139 in epoch 4, gen_loss = 0.3785170663680349, disc_loss = 0.02032380480419046
Trained batch 140 in epoch 4, gen_loss = 0.37824628517982806, disc_loss = 0.020221741703266266
Trained batch 141 in epoch 4, gen_loss = 0.3789503020299992, disc_loss = 0.020189479969009022
Trained batch 142 in epoch 4, gen_loss = 0.37807649353167394, disc_loss = 0.02014444194493125
Trained batch 143 in epoch 4, gen_loss = 0.37861690173546475, disc_loss = 0.020060332516247097
Trained batch 144 in epoch 4, gen_loss = 0.37881631727876336, disc_loss = 0.01995410295363901
Trained batch 145 in epoch 4, gen_loss = 0.3788047445147005, disc_loss = 0.019869315768081746
Trained batch 146 in epoch 4, gen_loss = 0.379079465152455, disc_loss = 0.019812060252376865
Trained batch 147 in epoch 4, gen_loss = 0.3791524743711626, disc_loss = 0.019728964111276878
Trained batch 148 in epoch 4, gen_loss = 0.37924111009444167, disc_loss = 0.01965925903622086
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 0.3159806430339813, disc_loss = 0.0078584598377347
Trained batch 1 in epoch 5, gen_loss = 0.35624025762081146, disc_loss = 0.0059186420403420925
Trained batch 2 in epoch 5, gen_loss = 0.3780154089132945, disc_loss = 0.005170879963164528
Trained batch 3 in epoch 5, gen_loss = 0.3837880790233612, disc_loss = 0.0046420160797424614
Trained batch 4 in epoch 5, gen_loss = 0.38903456926345825, disc_loss = 0.00472161234356463
Trained batch 5 in epoch 5, gen_loss = 0.3736771047115326, disc_loss = 0.004867985417755942
Trained batch 6 in epoch 5, gen_loss = 0.3814807193619864, disc_loss = 0.008394192538357206
Trained batch 7 in epoch 5, gen_loss = 0.34851980675011873, disc_loss = 0.014350306388223544
Trained batch 8 in epoch 5, gen_loss = 0.3740004872282346, disc_loss = 0.015869646772949234
Trained batch 9 in epoch 5, gen_loss = 0.37875424399971963, disc_loss = 0.015248044510371983
Trained batch 10 in epoch 5, gen_loss = 0.37316150082783267, disc_loss = 0.01495171501301229
Trained batch 11 in epoch 5, gen_loss = 0.37357101899882156, disc_loss = 0.014601728587877005
Trained batch 12 in epoch 5, gen_loss = 0.37129321293188977, disc_loss = 0.014005771641118022
Trained batch 13 in epoch 5, gen_loss = 0.3702515943774155, disc_loss = 0.013360735045612923
Trained batch 14 in epoch 5, gen_loss = 0.3697672292590141, disc_loss = 0.012871472832436363
Trained batch 15 in epoch 5, gen_loss = 0.3700366918928921, disc_loss = 0.013161397117073648
Trained batch 16 in epoch 5, gen_loss = 0.36857767534606595, disc_loss = 0.013303126304355614
Trained batch 17 in epoch 5, gen_loss = 0.36239121564560467, disc_loss = 0.013900885086817047
Trained batch 18 in epoch 5, gen_loss = 0.36208749954637726, disc_loss = 0.014038562811420937
Trained batch 19 in epoch 5, gen_loss = 0.35958259291946887, disc_loss = 0.013927532581146807
Trained batch 20 in epoch 5, gen_loss = 0.3560240485128902, disc_loss = 0.013527607755912911
Trained batch 21 in epoch 5, gen_loss = 0.36632833595980296, disc_loss = 0.014309715850024739
Trained batch 22 in epoch 5, gen_loss = 0.35413216540346976, disc_loss = 0.01594583790384881
Trained batch 23 in epoch 5, gen_loss = 0.3562028386319677, disc_loss = 0.015806271180432912
Trained batch 24 in epoch 5, gen_loss = 0.3561844900250435, disc_loss = 0.01580314922146499
Trained batch 25 in epoch 5, gen_loss = 0.35127640716158426, disc_loss = 0.015646773309876714
Trained batch 26 in epoch 5, gen_loss = 0.35022557250879427, disc_loss = 0.015269325658058127
Trained batch 27 in epoch 5, gen_loss = 0.35583887595151154, disc_loss = 0.015304729433929814
Trained batch 28 in epoch 5, gen_loss = 0.35133530636285915, disc_loss = 0.015224757243012046
Trained batch 29 in epoch 5, gen_loss = 0.34896785095334054, disc_loss = 0.014900051344496509
Trained batch 30 in epoch 5, gen_loss = 0.3512714627769686, disc_loss = 0.014623284152138137
Trained batch 31 in epoch 5, gen_loss = 0.3503382762428373, disc_loss = 0.014324839234177489
Trained batch 32 in epoch 5, gen_loss = 0.34813897334264987, disc_loss = 0.014036990892650052
Trained batch 33 in epoch 5, gen_loss = 0.3512149012702353, disc_loss = 0.014280932044665165
Trained batch 34 in epoch 5, gen_loss = 0.3449476005775588, disc_loss = 0.014978759649342725
Trained batch 35 in epoch 5, gen_loss = 0.3492711817638742, disc_loss = 0.014977784484573122
Trained batch 36 in epoch 5, gen_loss = 0.34972225028920817, disc_loss = 0.014669965493266244
Trained batch 37 in epoch 5, gen_loss = 0.34815662491478416, disc_loss = 0.014434570391466351
Trained batch 38 in epoch 5, gen_loss = 0.3512917468563104, disc_loss = 0.014212346414868265
Trained batch 39 in epoch 5, gen_loss = 0.3514412285760045, disc_loss = 0.014022779354127124
Trained batch 40 in epoch 5, gen_loss = 0.34966118397509177, disc_loss = 0.013875362264537594
Trained batch 41 in epoch 5, gen_loss = 0.350884275244815, disc_loss = 0.013696141757204064
Trained batch 42 in epoch 5, gen_loss = 0.35257959452479387, disc_loss = 0.0134396227022503
Trained batch 43 in epoch 5, gen_loss = 0.35389439507641574, disc_loss = 0.013213028872004625
Trained batch 44 in epoch 5, gen_loss = 0.35428261905908587, disc_loss = 0.013023014609805412
Trained batch 45 in epoch 5, gen_loss = 0.3549713325565276, disc_loss = 0.012794888957970492
Trained batch 46 in epoch 5, gen_loss = 0.3560765805713674, disc_loss = 0.012676532454590531
Trained batch 47 in epoch 5, gen_loss = 0.3561498927883804, disc_loss = 0.013016524506383575
Trained batch 48 in epoch 5, gen_loss = 0.3519141660357008, disc_loss = 0.013452131011314233
Trained batch 49 in epoch 5, gen_loss = 0.3547107903659344, disc_loss = 0.013394245221279561
Trained batch 50 in epoch 5, gen_loss = 0.35697344398381664, disc_loss = 0.013315306697953857
Trained batch 51 in epoch 5, gen_loss = 0.35750687910387147, disc_loss = 0.013109256191035876
Trained batch 52 in epoch 5, gen_loss = 0.35650401281298333, disc_loss = 0.012941256218220828
Trained batch 53 in epoch 5, gen_loss = 0.3567303340468142, disc_loss = 0.012733944068680069
Trained batch 54 in epoch 5, gen_loss = 0.35712836533784864, disc_loss = 0.012643930813382295
Trained batch 55 in epoch 5, gen_loss = 0.3565664923350726, disc_loss = 0.012504380003000344
Trained batch 56 in epoch 5, gen_loss = 0.3570420939409942, disc_loss = 0.012331132068331436
Trained batch 57 in epoch 5, gen_loss = 0.3571694327582573, disc_loss = 0.012161233127197444
Trained batch 58 in epoch 5, gen_loss = 0.3579234863489361, disc_loss = 0.012818913040603747
Trained batch 59 in epoch 5, gen_loss = 0.35282911534110706, disc_loss = 0.014260218992906934
Trained batch 60 in epoch 5, gen_loss = 0.35657239522113177, disc_loss = 0.015275274588512714
Trained batch 61 in epoch 5, gen_loss = 0.35379821711009546, disc_loss = 0.01539570028750947
Trained batch 62 in epoch 5, gen_loss = 0.3541259053680632, disc_loss = 0.015382299659818056
Trained batch 63 in epoch 5, gen_loss = 0.3540067260619253, disc_loss = 0.015303127454899368
Trained batch 64 in epoch 5, gen_loss = 0.35428428168480214, disc_loss = 0.015237300515246506
Trained batch 65 in epoch 5, gen_loss = 0.3533726910298521, disc_loss = 0.015185442994786144
Trained batch 66 in epoch 5, gen_loss = 0.35316649813260603, disc_loss = 0.015044173401252213
Trained batch 67 in epoch 5, gen_loss = 0.35478543994181294, disc_loss = 0.015046469190993401
Trained batch 68 in epoch 5, gen_loss = 0.35378926668478095, disc_loss = 0.015040854472950425
Trained batch 69 in epoch 5, gen_loss = 0.35440245802913395, disc_loss = 0.014907620123787118
Trained batch 70 in epoch 5, gen_loss = 0.3557015961744416, disc_loss = 0.014781742010750927
Trained batch 71 in epoch 5, gen_loss = 0.35516478473113644, disc_loss = 0.014636357103073452
Trained batch 72 in epoch 5, gen_loss = 0.35601257849229523, disc_loss = 0.014476771869900802
Trained batch 73 in epoch 5, gen_loss = 0.35692199682061737, disc_loss = 0.014318639898634944
Trained batch 74 in epoch 5, gen_loss = 0.3568975108861923, disc_loss = 0.01417051211775591
Trained batch 75 in epoch 5, gen_loss = 0.3564113878497952, disc_loss = 0.01408907666489923
Trained batch 76 in epoch 5, gen_loss = 0.3571145621600089, disc_loss = 0.013943640063153942
Trained batch 77 in epoch 5, gen_loss = 0.35738117362444216, disc_loss = 0.013928386605141733
Trained batch 78 in epoch 5, gen_loss = 0.3561318993945665, disc_loss = 0.014030930864671835
Trained batch 79 in epoch 5, gen_loss = 0.35701528247445824, disc_loss = 0.013936128026398365
Trained batch 80 in epoch 5, gen_loss = 0.3581090155575011, disc_loss = 0.013816543275570888
Trained batch 81 in epoch 5, gen_loss = 0.35837180930666807, disc_loss = 0.013714900928856124
Trained batch 82 in epoch 5, gen_loss = 0.3584350205688591, disc_loss = 0.013603444077938526
Trained batch 83 in epoch 5, gen_loss = 0.3591053015774205, disc_loss = 0.013535768105482151
Trained batch 84 in epoch 5, gen_loss = 0.3589084556874107, disc_loss = 0.013477469653384212
Trained batch 85 in epoch 5, gen_loss = 0.3594865800682889, disc_loss = 0.01337058708033806
Trained batch 86 in epoch 5, gen_loss = 0.3599490090005699, disc_loss = 0.013280413221921129
Trained batch 87 in epoch 5, gen_loss = 0.35934782078997657, disc_loss = 0.013184266531342555
Trained batch 88 in epoch 5, gen_loss = 0.3599009321311886, disc_loss = 0.013069759231594423
Trained batch 89 in epoch 5, gen_loss = 0.3604375251465374, disc_loss = 0.012987148165444119
Trained batch 90 in epoch 5, gen_loss = 0.3598848681200992, disc_loss = 0.012891189465145734
Trained batch 91 in epoch 5, gen_loss = 0.36043281739820604, disc_loss = 0.01278320608189856
Trained batch 92 in epoch 5, gen_loss = 0.3608607914178602, disc_loss = 0.01267982437400528
Trained batch 93 in epoch 5, gen_loss = 0.36095738236574415, disc_loss = 0.01257468607311355
Trained batch 94 in epoch 5, gen_loss = 0.3611345964042764, disc_loss = 0.01249701174735827
Trained batch 95 in epoch 5, gen_loss = 0.3616592506878078, disc_loss = 0.01239592438772282
Trained batch 96 in epoch 5, gen_loss = 0.36199666068111497, disc_loss = 0.012311659046429564
Trained batch 97 in epoch 5, gen_loss = 0.3620536338005747, disc_loss = 0.012223233177792281
Trained batch 98 in epoch 5, gen_loss = 0.36223672029345927, disc_loss = 0.012141195505697543
Trained batch 99 in epoch 5, gen_loss = 0.362753015011549, disc_loss = 0.012049881549319252
Trained batch 100 in epoch 5, gen_loss = 0.3631000198645167, disc_loss = 0.011968076320152989
Trained batch 101 in epoch 5, gen_loss = 0.36324529159887164, disc_loss = 0.011900236828973992
Trained batch 102 in epoch 5, gen_loss = 0.3636346787792965, disc_loss = 0.011836451025073896
Trained batch 103 in epoch 5, gen_loss = 0.36381223124380296, disc_loss = 0.011807897243460711
Trained batch 104 in epoch 5, gen_loss = 0.3643885579847154, disc_loss = 0.011784433501417793
Trained batch 105 in epoch 5, gen_loss = 0.3646105132856459, disc_loss = 0.011719210744387348
Trained batch 106 in epoch 5, gen_loss = 0.3646479487140602, disc_loss = 0.011664056527062762
Trained batch 107 in epoch 5, gen_loss = 0.36424360106940623, disc_loss = 0.011618288025837737
Trained batch 108 in epoch 5, gen_loss = 0.36427820289353713, disc_loss = 0.011561189050820373
Trained batch 109 in epoch 5, gen_loss = 0.3649361183697527, disc_loss = 0.011529178018893369
Trained batch 110 in epoch 5, gen_loss = 0.3650006825054014, disc_loss = 0.011480962437040566
Trained batch 111 in epoch 5, gen_loss = 0.3654111492048417, disc_loss = 0.011424727786756452
Trained batch 112 in epoch 5, gen_loss = 0.3661723296462962, disc_loss = 0.0113557929706768
Trained batch 113 in epoch 5, gen_loss = 0.36653355038479757, disc_loss = 0.011315998334331405
Trained batch 114 in epoch 5, gen_loss = 0.3665815256212069, disc_loss = 0.011258073579317525
Trained batch 115 in epoch 5, gen_loss = 0.3664231142350312, disc_loss = 0.01120137932192502
Trained batch 116 in epoch 5, gen_loss = 0.36735994145910966, disc_loss = 0.011126530558690747
Trained batch 117 in epoch 5, gen_loss = 0.36792674648054574, disc_loss = 0.011060266280980875
Trained batch 118 in epoch 5, gen_loss = 0.368058764759232, disc_loss = 0.010984828279885863
Trained batch 119 in epoch 5, gen_loss = 0.3681077861537536, disc_loss = 0.010925610806831779
Trained batch 120 in epoch 5, gen_loss = 0.368763733870727, disc_loss = 0.01085167992494477
Trained batch 121 in epoch 5, gen_loss = 0.3691387556371142, disc_loss = 0.010781905612885402
Trained batch 122 in epoch 5, gen_loss = 0.3696046816866572, disc_loss = 0.010760694695825924
Trained batch 123 in epoch 5, gen_loss = 0.3698394744386596, disc_loss = 0.010701550207393724
Trained batch 124 in epoch 5, gen_loss = 0.3699531549215317, disc_loss = 0.010679889178834856
Trained batch 125 in epoch 5, gen_loss = 0.3701198440459039, disc_loss = 0.010640569388799901
Trained batch 126 in epoch 5, gen_loss = 0.3705962906906924, disc_loss = 0.010587578275475622
Trained batch 127 in epoch 5, gen_loss = 0.3714416566072032, disc_loss = 0.0105372891512161
Trained batch 128 in epoch 5, gen_loss = 0.37189214763253237, disc_loss = 0.010518012982576565
Trained batch 129 in epoch 5, gen_loss = 0.37158521860837934, disc_loss = 0.010500730949346549
Trained batch 130 in epoch 5, gen_loss = 0.3717224735567588, disc_loss = 0.010448600148661275
Trained batch 131 in epoch 5, gen_loss = 0.3721500410500801, disc_loss = 0.01039403133626999
Trained batch 132 in epoch 5, gen_loss = 0.37232574137081775, disc_loss = 0.010333351464416916
Trained batch 133 in epoch 5, gen_loss = 0.3723579592891593, disc_loss = 0.010273449198488813
Trained batch 134 in epoch 5, gen_loss = 0.37213495671749114, disc_loss = 0.010234918948090463
Trained batch 135 in epoch 5, gen_loss = 0.3719291959834449, disc_loss = 0.010177279883304009
Trained batch 136 in epoch 5, gen_loss = 0.3734051568882309, disc_loss = 0.010190980494477834
Trained batch 137 in epoch 5, gen_loss = 0.3727683795319087, disc_loss = 0.010185853786516827
Trained batch 138 in epoch 5, gen_loss = 0.37289546923242883, disc_loss = 0.010189758646368927
Trained batch 139 in epoch 5, gen_loss = 0.3725501866212913, disc_loss = 0.01015181077361506
Trained batch 140 in epoch 5, gen_loss = 0.37253717338362485, disc_loss = 0.010102657322996422
Trained batch 141 in epoch 5, gen_loss = 0.37347889376778, disc_loss = 0.010127229838218855
Trained batch 142 in epoch 5, gen_loss = 0.37261285419230694, disc_loss = 0.010143130932205155
Trained batch 143 in epoch 5, gen_loss = 0.37368386921783286, disc_loss = 0.010164759017546507
Trained batch 144 in epoch 5, gen_loss = 0.3735717660394208, disc_loss = 0.010117966090007846
Trained batch 145 in epoch 5, gen_loss = 0.3730646712731009, disc_loss = 0.010116140695435493
Trained batch 146 in epoch 5, gen_loss = 0.37343702794743233, disc_loss = 0.010081998635634628
Trained batch 147 in epoch 5, gen_loss = 0.3733543499901488, disc_loss = 0.01005112419669466
Trained batch 148 in epoch 5, gen_loss = 0.3728796193663706, disc_loss = 0.010016392643763465
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 0.39274510741233826, disc_loss = 0.002043772954493761
Trained batch 1 in epoch 6, gen_loss = 0.4119761437177658, disc_loss = 0.0028451563557609916
Trained batch 2 in epoch 6, gen_loss = 0.39754897356033325, disc_loss = 0.002791980824743708
Trained batch 3 in epoch 6, gen_loss = 0.3848807215690613, disc_loss = 0.0025509580736979842
Trained batch 4 in epoch 6, gen_loss = 0.3754307866096497, disc_loss = 0.0023732258938252925
Trained batch 5 in epoch 6, gen_loss = 0.38372140129407245, disc_loss = 0.002401015915287038
Trained batch 6 in epoch 6, gen_loss = 0.37707676206316265, disc_loss = 0.0023469351830759217
Trained batch 7 in epoch 6, gen_loss = 0.37559114396572113, disc_loss = 0.002339837054023519
Trained batch 8 in epoch 6, gen_loss = 0.37497475412156844, disc_loss = 0.0023810940846386883
Trained batch 9 in epoch 6, gen_loss = 0.3794830322265625, disc_loss = 0.002582437568344176
Trained batch 10 in epoch 6, gen_loss = 0.37544171647592023, disc_loss = 0.0025636539159511976
Trained batch 11 in epoch 6, gen_loss = 0.37229179839293164, disc_loss = 0.002798080774179349
Trained batch 12 in epoch 6, gen_loss = 0.36737293692735523, disc_loss = 0.0031001234892755747
Trained batch 13 in epoch 6, gen_loss = 0.3720338238137109, disc_loss = 0.0032335085561499
Trained batch 14 in epoch 6, gen_loss = 0.37323488195737203, disc_loss = 0.003192135210459431
Trained batch 15 in epoch 6, gen_loss = 0.36968265660107136, disc_loss = 0.003165210029692389
Trained batch 16 in epoch 6, gen_loss = 0.3680711476241841, disc_loss = 0.0031299306052353453
Trained batch 17 in epoch 6, gen_loss = 0.3702352311876085, disc_loss = 0.003175094245105154
Trained batch 18 in epoch 6, gen_loss = 0.3677339522462142, disc_loss = 0.0031871241394822534
Trained batch 19 in epoch 6, gen_loss = 0.36687979102134705, disc_loss = 0.003150280797854066
Trained batch 20 in epoch 6, gen_loss = 0.3675959621156965, disc_loss = 0.0031436169298277015
Trained batch 21 in epoch 6, gen_loss = 0.3684095374562524, disc_loss = 0.0031023440586233682
Trained batch 22 in epoch 6, gen_loss = 0.36832190466963727, disc_loss = 0.003155670351470294
Trained batch 23 in epoch 6, gen_loss = 0.36563997467358905, disc_loss = 0.003145514327722291
Trained batch 24 in epoch 6, gen_loss = 0.3643336975574493, disc_loss = 0.004040083102881909
Trained batch 25 in epoch 6, gen_loss = 0.3568780439404341, disc_loss = 0.005122015646730478
Trained batch 26 in epoch 6, gen_loss = 0.3601827174425125, disc_loss = 0.005269927110660959
Trained batch 27 in epoch 6, gen_loss = 0.36495863060866085, disc_loss = 0.0054766210128686255
Trained batch 28 in epoch 6, gen_loss = 0.3644087052550809, disc_loss = 0.005356425194647805
Trained batch 29 in epoch 6, gen_loss = 0.36189376066128415, disc_loss = 0.005454406887292862
Trained batch 30 in epoch 6, gen_loss = 0.3624854159931983, disc_loss = 0.005388934841199267
Trained batch 31 in epoch 6, gen_loss = 0.36313791340216994, disc_loss = 0.005284136736008804
Trained batch 32 in epoch 6, gen_loss = 0.36263380673798645, disc_loss = 0.005172100165068652
Trained batch 33 in epoch 6, gen_loss = 0.3638302784632234, disc_loss = 0.005103479214834378
Trained batch 34 in epoch 6, gen_loss = 0.3637527461562838, disc_loss = 0.005011068600496011
Trained batch 35 in epoch 6, gen_loss = 0.36114296192924183, disc_loss = 0.005067479728798692
Trained batch 36 in epoch 6, gen_loss = 0.3634911457429061, disc_loss = 0.005166572880478123
Trained batch 37 in epoch 6, gen_loss = 0.36393927861201136, disc_loss = 0.005087392395484801
Trained batch 38 in epoch 6, gen_loss = 0.3645132913803443, disc_loss = 0.005005564854050485
Trained batch 39 in epoch 6, gen_loss = 0.36424702890217303, disc_loss = 0.004924006608780474
Trained batch 40 in epoch 6, gen_loss = 0.36271559501566536, disc_loss = 0.004849908470244306
Trained batch 41 in epoch 6, gen_loss = 0.36247256078890394, disc_loss = 0.004770492541692441
Trained batch 42 in epoch 6, gen_loss = 0.36247972104438514, disc_loss = 0.004699079590568016
Trained batch 43 in epoch 6, gen_loss = 0.361047105694359, disc_loss = 0.004636396304704249
Trained batch 44 in epoch 6, gen_loss = 0.36110860539807216, disc_loss = 0.004572384693245921
Trained batch 45 in epoch 6, gen_loss = 0.3619131047440612, disc_loss = 0.004505662730915229
Trained batch 46 in epoch 6, gen_loss = 0.3616715729870695, disc_loss = 0.004436494884120816
Trained batch 47 in epoch 6, gen_loss = 0.3613512705390652, disc_loss = 0.0043784446849410115
Trained batch 48 in epoch 6, gen_loss = 0.3607953382389886, disc_loss = 0.004324124722114327
Trained batch 49 in epoch 6, gen_loss = 0.3607626840472221, disc_loss = 0.004264717972837388
Trained batch 50 in epoch 6, gen_loss = 0.3603496776491988, disc_loss = 0.004224790045626315
Trained batch 51 in epoch 6, gen_loss = 0.3596259387066731, disc_loss = 0.004187855909829243
Trained batch 52 in epoch 6, gen_loss = 0.3591725637890258, disc_loss = 0.004150458677443412
Trained batch 53 in epoch 6, gen_loss = 0.35909369339545566, disc_loss = 0.004104765860743269
Trained batch 54 in epoch 6, gen_loss = 0.359463735873049, disc_loss = 0.004065244852311232
Trained batch 55 in epoch 6, gen_loss = 0.35895126073488165, disc_loss = 0.004026176000479609
Trained batch 56 in epoch 6, gen_loss = 0.3582859151718909, disc_loss = 0.003993429594852945
Trained batch 57 in epoch 6, gen_loss = 0.3579953032834777, disc_loss = 0.003961685025293766
Trained batch 58 in epoch 6, gen_loss = 0.3582087363732063, disc_loss = 0.003953254071332641
Trained batch 59 in epoch 6, gen_loss = 0.35811023935675623, disc_loss = 0.00392568272848924
Trained batch 60 in epoch 6, gen_loss = 0.3584723895201918, disc_loss = 0.0038995571724581915
Trained batch 61 in epoch 6, gen_loss = 0.3579710705145713, disc_loss = 0.0038698851281116086
Trained batch 62 in epoch 6, gen_loss = 0.35723644329441917, disc_loss = 0.003828979806885833
Trained batch 63 in epoch 6, gen_loss = 0.3570692224893719, disc_loss = 0.003795188677031547
Trained batch 64 in epoch 6, gen_loss = 0.35636871067377235, disc_loss = 0.00378081020182715
Trained batch 65 in epoch 6, gen_loss = 0.3558841467355237, disc_loss = 0.003913478371969452
Trained batch 66 in epoch 6, gen_loss = 0.3537553350872068, disc_loss = 0.003996896665237511
Trained batch 67 in epoch 6, gen_loss = 0.3545026005629231, disc_loss = 0.00416771782329306
Trained batch 68 in epoch 6, gen_loss = 0.35123753007771313, disc_loss = 0.00463763019407465
Trained batch 69 in epoch 6, gen_loss = 0.3532425529190472, disc_loss = 0.00517780477114554
Trained batch 70 in epoch 6, gen_loss = 0.35056673871799254, disc_loss = 0.005406935027026585
Trained batch 71 in epoch 6, gen_loss = 0.35218133011625874, disc_loss = 0.005507001326703984
Trained batch 72 in epoch 6, gen_loss = 0.35272433925164887, disc_loss = 0.005516296485438943
Trained batch 73 in epoch 6, gen_loss = 0.3522736033475077, disc_loss = 0.0054813627109585985
Trained batch 74 in epoch 6, gen_loss = 0.3522504582007726, disc_loss = 0.005449912715703249
Trained batch 75 in epoch 6, gen_loss = 0.35174143177114037, disc_loss = 0.005449326341285517
Trained batch 76 in epoch 6, gen_loss = 0.35088952117926114, disc_loss = 0.005472005901301836
Trained batch 77 in epoch 6, gen_loss = 0.35109091359071243, disc_loss = 0.005471203995582003
Trained batch 78 in epoch 6, gen_loss = 0.3509444830161107, disc_loss = 0.00546271435892846
Trained batch 79 in epoch 6, gen_loss = 0.3502473445609212, disc_loss = 0.0054699664528016
Trained batch 80 in epoch 6, gen_loss = 0.34979854266584653, disc_loss = 0.005552751845737666
Trained batch 81 in epoch 6, gen_loss = 0.3502159974560505, disc_loss = 0.005537691866842712
Trained batch 82 in epoch 6, gen_loss = 0.35072153932358846, disc_loss = 0.005510971724358668
Trained batch 83 in epoch 6, gen_loss = 0.35043321461195037, disc_loss = 0.005478884722660517
Trained batch 84 in epoch 6, gen_loss = 0.3500152039177277, disc_loss = 0.005434376458801768
Trained batch 85 in epoch 6, gen_loss = 0.3494319633342499, disc_loss = 0.00541389434392629
Trained batch 86 in epoch 6, gen_loss = 0.34925518450380744, disc_loss = 0.0053691505802388505
Trained batch 87 in epoch 6, gen_loss = 0.34881574677472765, disc_loss = 0.005327352731414562
Trained batch 88 in epoch 6, gen_loss = 0.34865509141027257, disc_loss = 0.005283698389892665
Trained batch 89 in epoch 6, gen_loss = 0.3486588122116195, disc_loss = 0.0052412567427381875
Trained batch 90 in epoch 6, gen_loss = 0.34851570361918144, disc_loss = 0.005201896422307242
Trained batch 91 in epoch 6, gen_loss = 0.348834162335033, disc_loss = 0.005163209226853011
Trained batch 92 in epoch 6, gen_loss = 0.3488646824193257, disc_loss = 0.005129941321048204
Trained batch 93 in epoch 6, gen_loss = 0.3489284627932183, disc_loss = 0.005091812592891461
Trained batch 94 in epoch 6, gen_loss = 0.34915938047986284, disc_loss = 0.005072498980811552
Trained batch 95 in epoch 6, gen_loss = 0.3494110975104074, disc_loss = 0.005040454258657216
Trained batch 96 in epoch 6, gen_loss = 0.3497662235473849, disc_loss = 0.005009436787864596
Trained batch 97 in epoch 6, gen_loss = 0.34910098615349555, disc_loss = 0.004983835703959423
Trained batch 98 in epoch 6, gen_loss = 0.34889482082140566, disc_loss = 0.004952555663432136
Trained batch 99 in epoch 6, gen_loss = 0.34941825434565543, disc_loss = 0.004923221666831523
Trained batch 100 in epoch 6, gen_loss = 0.3490162330983889, disc_loss = 0.004900676488765691
Trained batch 101 in epoch 6, gen_loss = 0.34897507683319207, disc_loss = 0.004873156054493259
Trained batch 102 in epoch 6, gen_loss = 0.34921893318301267, disc_loss = 0.0048433223036253486
Trained batch 103 in epoch 6, gen_loss = 0.34918679683827436, disc_loss = 0.004821570331562095
Trained batch 104 in epoch 6, gen_loss = 0.349093213109743, disc_loss = 0.004807212989821675
Trained batch 105 in epoch 6, gen_loss = 0.348895197628804, disc_loss = 0.004780592889973086
Trained batch 106 in epoch 6, gen_loss = 0.34890706113008696, disc_loss = 0.0047697276823553385
Trained batch 107 in epoch 6, gen_loss = 0.34844977008523764, disc_loss = 0.004745436046505347
Trained batch 108 in epoch 6, gen_loss = 0.3482000594018796, disc_loss = 0.004721176950474603
Trained batch 109 in epoch 6, gen_loss = 0.34819755080071363, disc_loss = 0.004690482138275084
Trained batch 110 in epoch 6, gen_loss = 0.3475367122136795, disc_loss = 0.004670672289616017
Trained batch 111 in epoch 6, gen_loss = 0.34726730747414486, disc_loss = 0.004641591015180373
Trained batch 112 in epoch 6, gen_loss = 0.34715443941871676, disc_loss = 0.0046233409671607405
Trained batch 113 in epoch 6, gen_loss = 0.3475939533428142, disc_loss = 0.004605883324984461
Trained batch 114 in epoch 6, gen_loss = 0.3478130689133769, disc_loss = 0.004576017101214308
Trained batch 115 in epoch 6, gen_loss = 0.34760200913096295, disc_loss = 0.004569410776984396
Trained batch 116 in epoch 6, gen_loss = 0.347632302560358, disc_loss = 0.004542661060650761
Trained batch 117 in epoch 6, gen_loss = 0.34788902141785216, disc_loss = 0.004516034215388788
Trained batch 118 in epoch 6, gen_loss = 0.3480385570716457, disc_loss = 0.004491870213268685
Trained batch 119 in epoch 6, gen_loss = 0.34755480475723743, disc_loss = 0.004479844324911634
Trained batch 120 in epoch 6, gen_loss = 0.3474137508425831, disc_loss = 0.004465388330392355
Trained batch 121 in epoch 6, gen_loss = 0.34751026613301916, disc_loss = 0.004455025762044748
Trained batch 122 in epoch 6, gen_loss = 0.3473652011253, disc_loss = 0.004435279932842265
Trained batch 123 in epoch 6, gen_loss = 0.3474693518252142, disc_loss = 0.004412629230383543
Trained batch 124 in epoch 6, gen_loss = 0.3474074867963791, disc_loss = 0.004385289431549609
Trained batch 125 in epoch 6, gen_loss = 0.3473693828970667, disc_loss = 0.004361453431931931
Trained batch 126 in epoch 6, gen_loss = 0.3473960138916031, disc_loss = 0.00433890610258645
Trained batch 127 in epoch 6, gen_loss = 0.3474171912530437, disc_loss = 0.0043225209483352955
Trained batch 128 in epoch 6, gen_loss = 0.3474400904058486, disc_loss = 0.004302050209921864
Trained batch 129 in epoch 6, gen_loss = 0.34767607416097934, disc_loss = 0.004343770264397161
Trained batch 130 in epoch 6, gen_loss = 0.34682689971141234, disc_loss = 0.0043900405538431905
Trained batch 131 in epoch 6, gen_loss = 0.34678762914104894, disc_loss = 0.004377089866796847
Trained batch 132 in epoch 6, gen_loss = 0.347206914447304, disc_loss = 0.004376032332805707
Trained batch 133 in epoch 6, gen_loss = 0.34700315712548013, disc_loss = 0.004365371379466143
Trained batch 134 in epoch 6, gen_loss = 0.34732311489405454, disc_loss = 0.004362855961166874
Trained batch 135 in epoch 6, gen_loss = 0.34755622650332313, disc_loss = 0.004346564084270914
Trained batch 136 in epoch 6, gen_loss = 0.34701781127139597, disc_loss = 0.0043554582920292545
Trained batch 137 in epoch 6, gen_loss = 0.3472817893261495, disc_loss = 0.004349752141169502
Trained batch 138 in epoch 6, gen_loss = 0.3474882799301216, disc_loss = 0.0043338605180958945
Trained batch 139 in epoch 6, gen_loss = 0.3467783824673721, disc_loss = 0.004364390554006344
Trained batch 140 in epoch 6, gen_loss = 0.3481406733287987, disc_loss = 0.004508996569776102
Trained batch 141 in epoch 6, gen_loss = 0.3483174372936638, disc_loss = 0.004510616486019809
Trained batch 142 in epoch 6, gen_loss = 0.3473728656560391, disc_loss = 0.004532854755773775
Trained batch 143 in epoch 6, gen_loss = 0.3476123235498865, disc_loss = 0.004530642914889743
Trained batch 144 in epoch 6, gen_loss = 0.34776983250831733, disc_loss = 0.004515968891791999
Trained batch 145 in epoch 6, gen_loss = 0.3481334373354912, disc_loss = 0.004500522369946264
Trained batch 146 in epoch 6, gen_loss = 0.3476995790288562, disc_loss = 0.004483655290709821
Trained batch 147 in epoch 6, gen_loss = 0.3476033642686702, disc_loss = 0.004470888244434939
Trained batch 148 in epoch 6, gen_loss = 0.34754995021644053, disc_loss = 0.004451349908142232
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 0.3651186227798462, disc_loss = 0.003371309954673052
Trained batch 1 in epoch 7, gen_loss = 0.34451448917388916, disc_loss = 0.0035112769110128284
Trained batch 2 in epoch 7, gen_loss = 0.3439788520336151, disc_loss = 0.0029283517505973577
Trained batch 3 in epoch 7, gen_loss = 0.33205486834049225, disc_loss = 0.0033167984220199287
Trained batch 4 in epoch 7, gen_loss = 0.3324288010597229, disc_loss = 0.00322545045055449
Trained batch 5 in epoch 7, gen_loss = 0.3356356869141261, disc_loss = 0.0029244787680606046
Trained batch 6 in epoch 7, gen_loss = 0.34007616128240314, disc_loss = 0.002707127282129867
Trained batch 7 in epoch 7, gen_loss = 0.33894044905900955, disc_loss = 0.0025324141315650195
Trained batch 8 in epoch 7, gen_loss = 0.33825353119108414, disc_loss = 0.0024269740614626142
Trained batch 9 in epoch 7, gen_loss = 0.3354261308908463, disc_loss = 0.0023951272014528513
Trained batch 10 in epoch 7, gen_loss = 0.33347703922878613, disc_loss = 0.002594834743914279
Trained batch 11 in epoch 7, gen_loss = 0.3261650614440441, disc_loss = 0.0026954138884320855
Trained batch 12 in epoch 7, gen_loss = 0.3275028341091596, disc_loss = 0.0027022855177235147
Trained batch 13 in epoch 7, gen_loss = 0.3280627354979515, disc_loss = 0.004362942301668227
Trained batch 14 in epoch 7, gen_loss = 0.31262800296147664, disc_loss = 0.00625376619088153
Trained batch 15 in epoch 7, gen_loss = 0.32126652263104916, disc_loss = 0.0073657157336128876
Trained batch 16 in epoch 7, gen_loss = 0.32222462752286124, disc_loss = 0.007154767730218523
Trained batch 17 in epoch 7, gen_loss = 0.3181551628642612, disc_loss = 0.0075212399371796185
Trained batch 18 in epoch 7, gen_loss = 0.32255405815024124, disc_loss = 0.007402322843278709
Trained batch 19 in epoch 7, gen_loss = 0.32589787542819976, disc_loss = 0.00725118238478899
Trained batch 20 in epoch 7, gen_loss = 0.3251695051079705, disc_loss = 0.007002919890163909
Trained batch 21 in epoch 7, gen_loss = 0.32656133852221747, disc_loss = 0.0067725292438725855
Trained batch 22 in epoch 7, gen_loss = 0.32501736283302307, disc_loss = 0.006584535631270189
Trained batch 23 in epoch 7, gen_loss = 0.32486846297979355, disc_loss = 0.006390446180982205
Trained batch 24 in epoch 7, gen_loss = 0.3255977344512939, disc_loss = 0.006246625077910722
Trained batch 25 in epoch 7, gen_loss = 0.32630732770149523, disc_loss = 0.006112299810271137
Trained batch 26 in epoch 7, gen_loss = 0.32823409636815387, disc_loss = 0.005953591131536221
Trained batch 27 in epoch 7, gen_loss = 0.32920922551836285, disc_loss = 0.00578193213108794
Trained batch 28 in epoch 7, gen_loss = 0.3281604318783201, disc_loss = 0.005678546105126111
Trained batch 29 in epoch 7, gen_loss = 0.3281238128741582, disc_loss = 0.00555654497584328
Trained batch 30 in epoch 7, gen_loss = 0.32745313548272653, disc_loss = 0.005424182952171372
Trained batch 31 in epoch 7, gen_loss = 0.32707362808287144, disc_loss = 0.005292912188451737
Trained batch 32 in epoch 7, gen_loss = 0.3273463718818896, disc_loss = 0.00635214200751348
Trained batch 33 in epoch 7, gen_loss = 0.31359347175149355, disc_loss = 0.014233000193010359
Trained batch 34 in epoch 7, gen_loss = 0.3166875319821494, disc_loss = 0.0149374679263149
Trained batch 35 in epoch 7, gen_loss = 0.31904303034146625, disc_loss = 0.01745917135849595
Trained batch 36 in epoch 7, gen_loss = 0.3138622718082892, disc_loss = 0.0180576547879625
Trained batch 37 in epoch 7, gen_loss = 0.31313386833981466, disc_loss = 0.01784435657196139
Trained batch 38 in epoch 7, gen_loss = 0.31443278185832196, disc_loss = 0.01752756306758294
Trained batch 39 in epoch 7, gen_loss = 0.31542597003281114, disc_loss = 0.01736677996814251
Trained batch 40 in epoch 7, gen_loss = 0.3135939396736098, disc_loss = 0.017206899253878652
Trained batch 41 in epoch 7, gen_loss = 0.312594829925469, disc_loss = 0.016876945127954797
Trained batch 42 in epoch 7, gen_loss = 0.3125826733749966, disc_loss = 0.01653188514674819
Trained batch 43 in epoch 7, gen_loss = 0.3132888921959834, disc_loss = 0.016217790469950574
Trained batch 44 in epoch 7, gen_loss = 0.3132324811485079, disc_loss = 0.01616134505925907
Trained batch 45 in epoch 7, gen_loss = 0.3118876073023547, disc_loss = 0.0159807409989931
Trained batch 46 in epoch 7, gen_loss = 0.3111150768843103, disc_loss = 0.015893260561960176
Trained batch 47 in epoch 7, gen_loss = 0.31276897620409727, disc_loss = 0.015614705655025318
Trained batch 48 in epoch 7, gen_loss = 0.3138664471251624, disc_loss = 0.015347556220557617
Trained batch 49 in epoch 7, gen_loss = 0.3140005233883858, disc_loss = 0.015071642771363258
Trained batch 50 in epoch 7, gen_loss = 0.31467364202527437, disc_loss = 0.014825132995040393
Trained batch 51 in epoch 7, gen_loss = 0.314432006329298, disc_loss = 0.014587903234104697
Trained batch 52 in epoch 7, gen_loss = 0.31365850595933087, disc_loss = 0.014352015325061555
Trained batch 53 in epoch 7, gen_loss = 0.3141576391127374, disc_loss = 0.014116312450453363
Trained batch 54 in epoch 7, gen_loss = 0.3151717313311317, disc_loss = 0.013909585316750137
Trained batch 55 in epoch 7, gen_loss = 0.3156386350414583, disc_loss = 0.013706603469992322
Trained batch 56 in epoch 7, gen_loss = 0.3164232532706177, disc_loss = 0.013510636119335367
Trained batch 57 in epoch 7, gen_loss = 0.3174198950672972, disc_loss = 0.013314694655930688
Trained batch 58 in epoch 7, gen_loss = 0.3177975590451289, disc_loss = 0.01311316469218582
Trained batch 59 in epoch 7, gen_loss = 0.31780981247623763, disc_loss = 0.012942567780070628
Trained batch 60 in epoch 7, gen_loss = 0.31797201638338995, disc_loss = 0.012761169975837235
Trained batch 61 in epoch 7, gen_loss = 0.31748829757974995, disc_loss = 0.01264008505630397
Trained batch 62 in epoch 7, gen_loss = 0.31779967674187254, disc_loss = 0.012501531738847022
Trained batch 63 in epoch 7, gen_loss = 0.31828199676238, disc_loss = 0.012349209311651066
Trained batch 64 in epoch 7, gen_loss = 0.3190759404347493, disc_loss = 0.012186586989376408
Trained batch 65 in epoch 7, gen_loss = 0.32015006040984934, disc_loss = 0.012027103681413626
Trained batch 66 in epoch 7, gen_loss = 0.3205908596960466, disc_loss = 0.011869936429117042
Trained batch 67 in epoch 7, gen_loss = 0.32177578592125106, disc_loss = 0.011719345435267314
Trained batch 68 in epoch 7, gen_loss = 0.3224403661662254, disc_loss = 0.011575601362299336
Trained batch 69 in epoch 7, gen_loss = 0.3224170933876719, disc_loss = 0.011426858570692795
Trained batch 70 in epoch 7, gen_loss = 0.3235612622868847, disc_loss = 0.011294247910485302
Trained batch 71 in epoch 7, gen_loss = 0.32437296563552487, disc_loss = 0.011168699679223614
Trained batch 72 in epoch 7, gen_loss = 0.3250863786837826, disc_loss = 0.011032328899464991
Trained batch 73 in epoch 7, gen_loss = 0.32583017868770137, disc_loss = 0.01090419343420984
Trained batch 74 in epoch 7, gen_loss = 0.32644823571046194, disc_loss = 0.010815111293147007
Trained batch 75 in epoch 7, gen_loss = 0.32648901660975654, disc_loss = 0.010714096467525355
Trained batch 76 in epoch 7, gen_loss = 0.3268518109213222, disc_loss = 0.010593980225710222
Trained batch 77 in epoch 7, gen_loss = 0.32779983354684633, disc_loss = 0.010476265016059654
Trained batch 78 in epoch 7, gen_loss = 0.32863105758081507, disc_loss = 0.010365447418504878
Trained batch 79 in epoch 7, gen_loss = 0.3299028595909476, disc_loss = 0.010273091460112483
Trained batch 80 in epoch 7, gen_loss = 0.33076870128696345, disc_loss = 0.010188035319133856
Trained batch 81 in epoch 7, gen_loss = 0.33059291050928397, disc_loss = 0.010114749209251164
Trained batch 82 in epoch 7, gen_loss = 0.33131456393075276, disc_loss = 0.010034663622346089
Trained batch 83 in epoch 7, gen_loss = 0.3323821778453532, disc_loss = 0.009955319043781077
Trained batch 84 in epoch 7, gen_loss = 0.33306645628284004, disc_loss = 0.00985584585543941
Trained batch 85 in epoch 7, gen_loss = 0.33362310934205386, disc_loss = 0.009763807411641316
Trained batch 86 in epoch 7, gen_loss = 0.33456976746005573, disc_loss = 0.009871054511656449
Trained batch 87 in epoch 7, gen_loss = 0.33357397009703244, disc_loss = 0.009879780188467439
Trained batch 88 in epoch 7, gen_loss = 0.33394241751579756, disc_loss = 0.009800467092093876
Trained batch 89 in epoch 7, gen_loss = 0.3355629803405868, disc_loss = 0.00973667495806391
Trained batch 90 in epoch 7, gen_loss = 0.33659084959999547, disc_loss = 0.00966155419387128
Trained batch 91 in epoch 7, gen_loss = 0.33704519838742586, disc_loss = 0.009575538561203639
Trained batch 92 in epoch 7, gen_loss = 0.33720535248197536, disc_loss = 0.00949846912220481
Trained batch 93 in epoch 7, gen_loss = 0.3375440501469247, disc_loss = 0.009417029948498894
Trained batch 94 in epoch 7, gen_loss = 0.33793726735993435, disc_loss = 0.009336469892265373
Trained batch 95 in epoch 7, gen_loss = 0.3384242143171529, disc_loss = 0.009267420683803115
Trained batch 96 in epoch 7, gen_loss = 0.33845784753253777, disc_loss = 0.009191012275213203
Trained batch 97 in epoch 7, gen_loss = 0.3391085603103346, disc_loss = 0.009121169261301734
Trained batch 98 in epoch 7, gen_loss = 0.3391502206072663, disc_loss = 0.009061316814922699
Trained batch 99 in epoch 7, gen_loss = 0.33937759086489677, disc_loss = 0.008987895556492731
Trained batch 100 in epoch 7, gen_loss = 0.33979352113634054, disc_loss = 0.008926739509328093
Trained batch 101 in epoch 7, gen_loss = 0.34036083095798303, disc_loss = 0.008873496007165122
Trained batch 102 in epoch 7, gen_loss = 0.3409488176547208, disc_loss = 0.008824758632877136
Trained batch 103 in epoch 7, gen_loss = 0.3412201331498531, disc_loss = 0.008769423251998467
Trained batch 104 in epoch 7, gen_loss = 0.3410636434952418, disc_loss = 0.008707718884882828
Trained batch 105 in epoch 7, gen_loss = 0.34117679565020326, disc_loss = 0.008671074294054634
Trained batch 106 in epoch 7, gen_loss = 0.3417896267688163, disc_loss = 0.008615708025389952
Trained batch 107 in epoch 7, gen_loss = 0.342086266450308, disc_loss = 0.008562553403424789
Trained batch 108 in epoch 7, gen_loss = 0.3425196894538512, disc_loss = 0.008501436388325116
Trained batch 109 in epoch 7, gen_loss = 0.3429531757127155, disc_loss = 0.008444691904481839
Trained batch 110 in epoch 7, gen_loss = 0.34348618943949005, disc_loss = 0.00838467171772274
Trained batch 111 in epoch 7, gen_loss = 0.34399802330881357, disc_loss = 0.008325219462026976
Trained batch 112 in epoch 7, gen_loss = 0.3443634825206436, disc_loss = 0.008265843233752963
Trained batch 113 in epoch 7, gen_loss = 0.3445607691741826, disc_loss = 0.008209088253543564
Trained batch 114 in epoch 7, gen_loss = 0.34540249821932417, disc_loss = 0.008148675109259785
Trained batch 115 in epoch 7, gen_loss = 0.34601218574519815, disc_loss = 0.008089079356005672
Trained batch 116 in epoch 7, gen_loss = 0.3464632083972295, disc_loss = 0.008056136165570436
Trained batch 117 in epoch 7, gen_loss = 0.34639104960833567, disc_loss = 0.008054578991535798
Trained batch 118 in epoch 7, gen_loss = 0.3471863982306809, disc_loss = 0.00800642982700511
Trained batch 119 in epoch 7, gen_loss = 0.3480493233849605, disc_loss = 0.007961273380594018
Trained batch 120 in epoch 7, gen_loss = 0.34846176551885844, disc_loss = 0.007907754819540015
Trained batch 121 in epoch 7, gen_loss = 0.34904738588899864, disc_loss = 0.007855069856006713
Trained batch 122 in epoch 7, gen_loss = 0.3498678925803037, disc_loss = 0.007806076885890064
Trained batch 123 in epoch 7, gen_loss = 0.35061357230428725, disc_loss = 0.007798049935034567
Trained batch 124 in epoch 7, gen_loss = 0.3505550836324692, disc_loss = 0.007788649262860417
Trained batch 125 in epoch 7, gen_loss = 0.3508055078841391, disc_loss = 0.007752392962131472
Trained batch 126 in epoch 7, gen_loss = 0.35154101053091485, disc_loss = 0.007709782104939222
Trained batch 127 in epoch 7, gen_loss = 0.35224935051519424, disc_loss = 0.007662865541533392
Trained batch 128 in epoch 7, gen_loss = 0.3527143307665522, disc_loss = 0.007614661628098855
Trained batch 129 in epoch 7, gen_loss = 0.3534256801009178, disc_loss = 0.007644319125057126
Trained batch 130 in epoch 7, gen_loss = 0.3534949812042804, disc_loss = 0.007625043938711343
Trained batch 131 in epoch 7, gen_loss = 0.3533991398007581, disc_loss = 0.007603250697050526
Trained batch 132 in epoch 7, gen_loss = 0.3539579794146961, disc_loss = 0.0075635752015698115
Trained batch 133 in epoch 7, gen_loss = 0.35460141935010453, disc_loss = 0.007529275087855144
Trained batch 134 in epoch 7, gen_loss = 0.3550596077133108, disc_loss = 0.007492675357153295
Trained batch 135 in epoch 7, gen_loss = 0.3554171224069946, disc_loss = 0.007498032112968811
Trained batch 136 in epoch 7, gen_loss = 0.35529760516037906, disc_loss = 0.007490697338069062
Trained batch 137 in epoch 7, gen_loss = 0.356173410039881, disc_loss = 0.007457078010201508
Trained batch 138 in epoch 7, gen_loss = 0.35696833586092475, disc_loss = 0.00742957855176127
Trained batch 139 in epoch 7, gen_loss = 0.3572611956724099, disc_loss = 0.007391634111991152
Trained batch 140 in epoch 7, gen_loss = 0.35783044000466663, disc_loss = 0.007354043850985666
Trained batch 141 in epoch 7, gen_loss = 0.3587004153031698, disc_loss = 0.007332338785103352
Trained batch 142 in epoch 7, gen_loss = 0.35901651088591224, disc_loss = 0.0073031707222319464
Trained batch 143 in epoch 7, gen_loss = 0.35927784391161466, disc_loss = 0.007285276931522983
Trained batch 144 in epoch 7, gen_loss = 0.3595670916910829, disc_loss = 0.007260811495080847
Trained batch 145 in epoch 7, gen_loss = 0.3601252631577727, disc_loss = 0.007234153104148652
Trained batch 146 in epoch 7, gen_loss = 0.36095396140400243, disc_loss = 0.007204541970570223
Trained batch 147 in epoch 7, gen_loss = 0.36176343252127235, disc_loss = 0.0071839986682076615
Trained batch 148 in epoch 7, gen_loss = 0.3624376415606313, disc_loss = 0.0071572964290631995
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 0.459121972322464, disc_loss = 0.0032213637605309486
Trained batch 1 in epoch 8, gen_loss = 0.4481987953186035, disc_loss = 0.004631004529073834
Trained batch 2 in epoch 8, gen_loss = 0.45912448565165204, disc_loss = 0.004082778313507636
Trained batch 3 in epoch 8, gen_loss = 0.4782652109861374, disc_loss = 0.003954232321120799
Trained batch 4 in epoch 8, gen_loss = 0.47981700897216795, disc_loss = 0.004407730419188738
Trained batch 5 in epoch 8, gen_loss = 0.48230324188868207, disc_loss = 0.004960361480092009
Trained batch 6 in epoch 8, gen_loss = 0.4768096719469343, disc_loss = 0.005430545857442277
Trained batch 7 in epoch 8, gen_loss = 0.48323600739240646, disc_loss = 0.005753044446464628
Trained batch 8 in epoch 8, gen_loss = 0.49937643607457477, disc_loss = 0.0075118621914751
Trained batch 9 in epoch 8, gen_loss = 0.4958471953868866, disc_loss = 0.007999179838225245
Trained batch 10 in epoch 8, gen_loss = 0.4933737245472995, disc_loss = 0.008415877353399992
Trained batch 11 in epoch 8, gen_loss = 0.5018499741951624, disc_loss = 0.00869274764166524
Trained batch 12 in epoch 8, gen_loss = 0.5160352083352896, disc_loss = 0.009505375682447966
Trained batch 13 in epoch 8, gen_loss = 0.5230253040790558, disc_loss = 0.009671577352232166
Trained batch 14 in epoch 8, gen_loss = 0.5178449094295502, disc_loss = 0.010734768553326527
Trained batch 15 in epoch 8, gen_loss = 0.5141748078167439, disc_loss = 0.011104630975751206
Trained batch 16 in epoch 8, gen_loss = 0.5133473452399758, disc_loss = 0.011086380246150144
Trained batch 17 in epoch 8, gen_loss = 0.5170094437069364, disc_loss = 0.011011931088028682
Trained batch 18 in epoch 8, gen_loss = 0.5371065139770508, disc_loss = 0.013481950362850176
Trained batch 19 in epoch 8, gen_loss = 0.5393915712833405, disc_loss = 0.013779779034666716
Trained batch 20 in epoch 8, gen_loss = 0.5366440798555102, disc_loss = 0.013707896273228385
Trained batch 21 in epoch 8, gen_loss = 0.5325804637237028, disc_loss = 0.013471270255236463
Trained batch 22 in epoch 8, gen_loss = 0.5267936989017155, disc_loss = 0.013075464708811563
Trained batch 23 in epoch 8, gen_loss = 0.5215309821069241, disc_loss = 0.012672419708299762
Trained batch 24 in epoch 8, gen_loss = 0.5155922329425812, disc_loss = 0.012333175847306848
Trained batch 25 in epoch 8, gen_loss = 0.5097882610100967, disc_loss = 0.011939311910492297
Trained batch 26 in epoch 8, gen_loss = 0.5037963666297771, disc_loss = 0.011573861594553347
Trained batch 27 in epoch 8, gen_loss = 0.49806720444134306, disc_loss = 0.011244067839080734
Trained batch 28 in epoch 8, gen_loss = 0.49423376856179074, disc_loss = 0.01096440422958855
Trained batch 29 in epoch 8, gen_loss = 0.48818505307038623, disc_loss = 0.01068510782594482
Trained batch 30 in epoch 8, gen_loss = 0.48276785016059875, disc_loss = 0.010540517888242198
Trained batch 31 in epoch 8, gen_loss = 0.4785060314461589, disc_loss = 0.010272905565216206
Trained batch 32 in epoch 8, gen_loss = 0.473922739426295, disc_loss = 0.010019784955533616
Trained batch 33 in epoch 8, gen_loss = 0.4699874905978932, disc_loss = 0.009767534581067808
Trained batch 34 in epoch 8, gen_loss = 0.4648430517741612, disc_loss = 0.009523214087156312
Trained batch 35 in epoch 8, gen_loss = 0.459509273370107, disc_loss = 0.009290183030922586
Trained batch 36 in epoch 8, gen_loss = 0.45370234186584885, disc_loss = 0.009070234477041743
Trained batch 37 in epoch 8, gen_loss = 0.4486004584713986, disc_loss = 0.00886914538109283
Trained batch 38 in epoch 8, gen_loss = 0.443585780950693, disc_loss = 0.008687746400634447
Trained batch 39 in epoch 8, gen_loss = 0.43817082718014716, disc_loss = 0.008505806446191855
Trained batch 40 in epoch 8, gen_loss = 0.43244704386083094, disc_loss = 0.008325153958938288
Trained batch 41 in epoch 8, gen_loss = 0.42764378161657424, disc_loss = 0.008152366033755243
Trained batch 42 in epoch 8, gen_loss = 0.4219417003698127, disc_loss = 0.00800534370517748
Trained batch 43 in epoch 8, gen_loss = 0.41622328555042093, disc_loss = 0.00785531637269411
Trained batch 44 in epoch 8, gen_loss = 0.4102705518404643, disc_loss = 0.007719400579420229
Trained batch 45 in epoch 8, gen_loss = 0.4045866617689962, disc_loss = 0.007606905259941097
Trained batch 46 in epoch 8, gen_loss = 0.39963334608585277, disc_loss = 0.0074944605411803155
Trained batch 47 in epoch 8, gen_loss = 0.3957324779282014, disc_loss = 0.007378924975152283
Trained batch 48 in epoch 8, gen_loss = 0.3913975923645253, disc_loss = 0.007258006796830011
Trained batch 49 in epoch 8, gen_loss = 0.38742693603038786, disc_loss = 0.007140768433455378
Trained batch 50 in epoch 8, gen_loss = 0.38249460856119794, disc_loss = 0.007026202965290377
Trained batch 51 in epoch 8, gen_loss = 0.3784860441317925, disc_loss = 0.006915719134177869
Trained batch 52 in epoch 8, gen_loss = 0.37505001223312234, disc_loss = 0.006813614633602073
Trained batch 53 in epoch 8, gen_loss = 0.3719160700285876, disc_loss = 0.006710976437682769
Trained batch 54 in epoch 8, gen_loss = 0.36788027557459746, disc_loss = 0.006610060421834615
Trained batch 55 in epoch 8, gen_loss = 0.36460621495332035, disc_loss = 0.006516765368620067
Trained batch 56 in epoch 8, gen_loss = 0.3606316562284503, disc_loss = 0.00642727576645516
Trained batch 57 in epoch 8, gen_loss = 0.3582588444496023, disc_loss = 0.006358710717779167
Trained batch 58 in epoch 8, gen_loss = 0.354739822573581, disc_loss = 0.00628215930290457
Trained batch 59 in epoch 8, gen_loss = 0.3523019929726919, disc_loss = 0.006197988135196889
Trained batch 60 in epoch 8, gen_loss = 0.3499770193803506, disc_loss = 0.006112718332528335
Trained batch 61 in epoch 8, gen_loss = 0.3471633989003397, disc_loss = 0.006033338580070244
Trained batch 62 in epoch 8, gen_loss = 0.3445952217730265, disc_loss = 0.005960927307901401
Trained batch 63 in epoch 8, gen_loss = 0.3421294502913952, disc_loss = 0.005885421969651361
Trained batch 64 in epoch 8, gen_loss = 0.3396178690286783, disc_loss = 0.005810199443322534
Trained batch 65 in epoch 8, gen_loss = 0.33652789213440637, disc_loss = 0.005735530171395195
Trained batch 66 in epoch 8, gen_loss = 0.33434986890251955, disc_loss = 0.00566833819620617
Trained batch 67 in epoch 8, gen_loss = 0.33187857927644954, disc_loss = 0.005600514750660616
Trained batch 68 in epoch 8, gen_loss = 0.33013113685276196, disc_loss = 0.005534379865360055
Trained batch 69 in epoch 8, gen_loss = 0.3282847847257342, disc_loss = 0.005466759639758883
Trained batch 70 in epoch 8, gen_loss = 0.32597008473436595, disc_loss = 0.00540615755221872
Trained batch 71 in epoch 8, gen_loss = 0.32374924918015796, disc_loss = 0.005341540072145613
Trained batch 72 in epoch 8, gen_loss = 0.3216491847822111, disc_loss = 0.005279677228727825
Trained batch 73 in epoch 8, gen_loss = 0.31892061314067327, disc_loss = 0.005220264216060625
Trained batch 74 in epoch 8, gen_loss = 0.31670366287231444, disc_loss = 0.005160625171847641
Trained batch 75 in epoch 8, gen_loss = 0.31517941230221797, disc_loss = 0.005107218119328057
Trained batch 76 in epoch 8, gen_loss = 0.313178633327608, disc_loss = 0.005053237416968959
Trained batch 77 in epoch 8, gen_loss = 0.3107926192191931, disc_loss = 0.005003013305563049
Trained batch 78 in epoch 8, gen_loss = 0.308731488034695, disc_loss = 0.004953622223390856
Trained batch 79 in epoch 8, gen_loss = 0.306430459395051, disc_loss = 0.004901856165815843
Trained batch 80 in epoch 8, gen_loss = 0.30467310658207647, disc_loss = 0.0048504839500377855
Trained batch 81 in epoch 8, gen_loss = 0.302690203233463, disc_loss = 0.004799983521679234
Trained batch 82 in epoch 8, gen_loss = 0.3013780170894531, disc_loss = 0.004752977017638643
Trained batch 83 in epoch 8, gen_loss = 0.2990134528705052, disc_loss = 0.004706864286812821
Trained batch 84 in epoch 8, gen_loss = 0.2972720447708579, disc_loss = 0.0046738841968095475
Trained batch 85 in epoch 8, gen_loss = 0.2953712593677432, disc_loss = 0.004631381404726917
Trained batch 86 in epoch 8, gen_loss = 0.2935938328162007, disc_loss = 0.004596839579967675
Trained batch 87 in epoch 8, gen_loss = 0.2922748720104044, disc_loss = 0.004560176064842381
Trained batch 88 in epoch 8, gen_loss = 0.29013382450918135, disc_loss = 0.00452195872484675
Trained batch 89 in epoch 8, gen_loss = 0.289153159989251, disc_loss = 0.004483928310219198
Trained batch 90 in epoch 8, gen_loss = 0.2874383815042265, disc_loss = 0.004442801878142815
Trained batch 91 in epoch 8, gen_loss = 0.28587148468131607, disc_loss = 0.0044047358008000356
Trained batch 92 in epoch 8, gen_loss = 0.2845710849249235, disc_loss = 0.004368012311608
Trained batch 93 in epoch 8, gen_loss = 0.2831960196824784, disc_loss = 0.004328434509126113
Trained batch 94 in epoch 8, gen_loss = 0.28181461095809934, disc_loss = 0.004294242548119081
Trained batch 95 in epoch 8, gen_loss = 0.28039042310168344, disc_loss = 0.004272437955175216
Trained batch 96 in epoch 8, gen_loss = 0.27936700570214656, disc_loss = 0.004248141855980779
Trained batch 97 in epoch 8, gen_loss = 0.27826361388576276, disc_loss = 0.004221191727176157
Trained batch 98 in epoch 8, gen_loss = 0.27727696149036135, disc_loss = 0.004189830661440889
Trained batch 99 in epoch 8, gen_loss = 0.27615280508995055, disc_loss = 0.004160278314957395
Trained batch 100 in epoch 8, gen_loss = 0.27473626160385584, disc_loss = 0.004132999817259831
Trained batch 101 in epoch 8, gen_loss = 0.2733789027905932, disc_loss = 0.00410034596251196
Trained batch 102 in epoch 8, gen_loss = 0.2724808254866924, disc_loss = 0.004070374973963729
Trained batch 103 in epoch 8, gen_loss = 0.2711617307594189, disc_loss = 0.004042637033517866
Trained batch 104 in epoch 8, gen_loss = 0.27033477084977287, disc_loss = 0.004011692523047151
Trained batch 105 in epoch 8, gen_loss = 0.26902164012755986, disc_loss = 0.003987991129693945
Trained batch 106 in epoch 8, gen_loss = 0.2676792253400678, disc_loss = 0.003956693090241681
Trained batch 107 in epoch 8, gen_loss = 0.26672335824480764, disc_loss = 0.003928843918536721
Trained batch 108 in epoch 8, gen_loss = 0.2657452545581608, disc_loss = 0.0039013642513346988
Trained batch 109 in epoch 8, gen_loss = 0.2641033327037638, disc_loss = 0.0038726208567492326
Trained batch 110 in epoch 8, gen_loss = 0.26305909253455495, disc_loss = 0.003845882527572145
Trained batch 111 in epoch 8, gen_loss = 0.26249643095902037, disc_loss = 0.003819278025600527
Trained batch 112 in epoch 8, gen_loss = 0.26111956639627437, disc_loss = 0.0037936633550644384
Trained batch 113 in epoch 8, gen_loss = 0.26033923578889745, disc_loss = 0.0037710734478630975
Trained batch 114 in epoch 8, gen_loss = 0.25965051106784653, disc_loss = 0.0037462202786548954
Trained batch 115 in epoch 8, gen_loss = 0.2583773647402895, disc_loss = 0.0037217352108764945
Trained batch 116 in epoch 8, gen_loss = 0.2576184020592616, disc_loss = 0.0036999651456737304
Trained batch 117 in epoch 8, gen_loss = 0.2568144987700349, disc_loss = 0.0036747131404916804
Trained batch 118 in epoch 8, gen_loss = 0.25577186110640776, disc_loss = 0.003650533379262955
Trained batch 119 in epoch 8, gen_loss = 0.2551526345312595, disc_loss = 0.003626013029618965
Trained batch 120 in epoch 8, gen_loss = 0.2540929822389745, disc_loss = 0.0036016862886603766
Trained batch 121 in epoch 8, gen_loss = 0.25351780482002945, disc_loss = 0.0035786157360369127
Trained batch 122 in epoch 8, gen_loss = 0.25263479158161134, disc_loss = 0.0035566284649672245
Trained batch 123 in epoch 8, gen_loss = 0.25161641571790944, disc_loss = 0.0035336499995244066
Trained batch 124 in epoch 8, gen_loss = 0.25098304438591, disc_loss = 0.0035121316690929234
Trained batch 125 in epoch 8, gen_loss = 0.25026258707992616, disc_loss = 0.003492310235280514
Trained batch 126 in epoch 8, gen_loss = 0.24934481448075901, disc_loss = 0.0034718209910609824
Trained batch 127 in epoch 8, gen_loss = 0.2487609777599573, disc_loss = 0.003461123609667993
Trained batch 128 in epoch 8, gen_loss = 0.24757311695305875, disc_loss = 0.003449294946243077
Trained batch 129 in epoch 8, gen_loss = 0.2467859896329733, disc_loss = 0.0034296665497374934
Trained batch 130 in epoch 8, gen_loss = 0.2458500161425758, disc_loss = 0.003409231649018568
Trained batch 131 in epoch 8, gen_loss = 0.24463431333953684, disc_loss = 0.0033907286865128713
Trained batch 132 in epoch 8, gen_loss = 0.24429700428381898, disc_loss = 0.0033752446717589648
Trained batch 133 in epoch 8, gen_loss = 0.24359619617462158, disc_loss = 0.003361904138782576
Trained batch 134 in epoch 8, gen_loss = 0.24272736487565216, disc_loss = 0.0033481938574739076
Trained batch 135 in epoch 8, gen_loss = 0.24198608188068166, disc_loss = 0.00333216690170743
Trained batch 136 in epoch 8, gen_loss = 0.24137286178386994, disc_loss = 0.0033126501557689133
Trained batch 137 in epoch 8, gen_loss = 0.24049947032893915, disc_loss = 0.0032957681759253846
Trained batch 138 in epoch 8, gen_loss = 0.2399842063728854, disc_loss = 0.0032763175968677075
Trained batch 139 in epoch 8, gen_loss = 0.23964702125106538, disc_loss = 0.0032611659066917906
Trained batch 140 in epoch 8, gen_loss = 0.23900827744328385, disc_loss = 0.003245249831907002
Trained batch 141 in epoch 8, gen_loss = 0.2386901424804204, disc_loss = 0.003229777099528599
Trained batch 142 in epoch 8, gen_loss = 0.23831834868117646, disc_loss = 0.003211510003384828
Trained batch 143 in epoch 8, gen_loss = 0.23786793711284795, disc_loss = 0.0031948306580792027
Trained batch 144 in epoch 8, gen_loss = 0.23717077251138358, disc_loss = 0.0031772297156717755
Trained batch 145 in epoch 8, gen_loss = 0.23659515584984872, disc_loss = 0.0031598082222108258
Trained batch 146 in epoch 8, gen_loss = 0.2358861640602553, disc_loss = 0.0031428698701372205
Trained batch 147 in epoch 8, gen_loss = 0.23547137166197235, disc_loss = 0.003126466800175557
Trained batch 148 in epoch 8, gen_loss = 0.2352072446538298, disc_loss = 0.0031112300055476543
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 0.1326524019241333, disc_loss = 0.0009718933724798262
Trained batch 1 in epoch 9, gen_loss = 0.1341763734817505, disc_loss = 0.0009946176141966134
Trained batch 2 in epoch 9, gen_loss = 0.14475159843762717, disc_loss = 0.0010496528702788055
Trained batch 3 in epoch 9, gen_loss = 0.13799912482500076, disc_loss = 0.0009992278646677732
Trained batch 4 in epoch 9, gen_loss = 0.14410145878791808, disc_loss = 0.0009489222429692745
Trained batch 5 in epoch 9, gen_loss = 0.13838452597459158, disc_loss = 0.0009563729399815202
Trained batch 6 in epoch 9, gen_loss = 0.13445726462772914, disc_loss = 0.0009653538498761398
Trained batch 7 in epoch 9, gen_loss = 0.14067521691322327, disc_loss = 0.0009559128593537025
Trained batch 8 in epoch 9, gen_loss = 0.14317549599541557, disc_loss = 0.0009277440646352867
Trained batch 9 in epoch 9, gen_loss = 0.14596427977085114, disc_loss = 0.0008989641035441309
Trained batch 10 in epoch 9, gen_loss = 0.1473208422010595, disc_loss = 0.0009607407528991727
Trained batch 11 in epoch 9, gen_loss = 0.1445211594303449, disc_loss = 0.0009593523330598449
Trained batch 12 in epoch 9, gen_loss = 0.14687000558926508, disc_loss = 0.0009472952985491317
Trained batch 13 in epoch 9, gen_loss = 0.14591915905475616, disc_loss = 0.0009362463481790785
Trained batch 14 in epoch 9, gen_loss = 0.14714420437812806, disc_loss = 0.0009191040104875962
Trained batch 15 in epoch 9, gen_loss = 0.1479384321719408, disc_loss = 0.0010695336386561394
Trained batch 16 in epoch 9, gen_loss = 0.14478848260991714, disc_loss = 0.0010902140809990028
Trained batch 17 in epoch 9, gen_loss = 0.14150556590822008, disc_loss = 0.001109224310817404
Trained batch 18 in epoch 9, gen_loss = 0.14135399303938212, disc_loss = 0.001108627668336818
Trained batch 19 in epoch 9, gen_loss = 0.1439259633421898, disc_loss = 0.0011069073807448149
Trained batch 20 in epoch 9, gen_loss = 0.14378005691937037, disc_loss = 0.0010856337557058958
Trained batch 21 in epoch 9, gen_loss = 0.14237796041098508, disc_loss = 0.0010837907691232183
Trained batch 22 in epoch 9, gen_loss = 0.14383970395378445, disc_loss = 0.0010714943080371165
Trained batch 23 in epoch 9, gen_loss = 0.1442808359861374, disc_loss = 0.0010595024553670858
Trained batch 24 in epoch 9, gen_loss = 0.14364344358444214, disc_loss = 0.0010417438321746887
Trained batch 25 in epoch 9, gen_loss = 0.14430904388427734, disc_loss = 0.001047293442892484
Trained batch 26 in epoch 9, gen_loss = 0.1426457541960257, disc_loss = 0.0010529730783740956
Trained batch 27 in epoch 9, gen_loss = 0.14039094852549688, disc_loss = 0.0010403193570839772
Trained batch 28 in epoch 9, gen_loss = 0.1414359674371522, disc_loss = 0.001028910997837525
Trained batch 29 in epoch 9, gen_loss = 0.14072848757108053, disc_loss = 0.0010327277705073357
Trained batch 30 in epoch 9, gen_loss = 0.14307527676705392, disc_loss = 0.0010274473799302454
Trained batch 31 in epoch 9, gen_loss = 0.14247409906238317, disc_loss = 0.0010271922783431364
Trained batch 32 in epoch 9, gen_loss = 0.1420191643816052, disc_loss = 0.0010152465441602874
Trained batch 33 in epoch 9, gen_loss = 0.14286536942510045, disc_loss = 0.0010043956435230724
Trained batch 34 in epoch 9, gen_loss = 0.14337558831487382, disc_loss = 0.0009998834924772383
Trained batch 35 in epoch 9, gen_loss = 0.14391840000947317, disc_loss = 0.0009966963763064188
Trained batch 36 in epoch 9, gen_loss = 0.14378617019266696, disc_loss = 0.0009903226478805613
Trained batch 37 in epoch 9, gen_loss = 0.14396417062533529, disc_loss = 0.0009835087004926447
Trained batch 38 in epoch 9, gen_loss = 0.14412916700045267, disc_loss = 0.0009730804908590821
Trained batch 39 in epoch 9, gen_loss = 0.14319226816296576, disc_loss = 0.0009665036937803962
Trained batch 40 in epoch 9, gen_loss = 0.14464446756897903, disc_loss = 0.0009665957399325945
Trained batch 41 in epoch 9, gen_loss = 0.1455747357436589, disc_loss = 0.0009626425966243481
Trained batch 42 in epoch 9, gen_loss = 0.14595275632170743, disc_loss = 0.0009546251981085989
Trained batch 43 in epoch 9, gen_loss = 0.1468803577802398, disc_loss = 0.0009528594025389546
Trained batch 44 in epoch 9, gen_loss = 0.1467534641424815, disc_loss = 0.0009460518602281808
Trained batch 45 in epoch 9, gen_loss = 0.14625986503518146, disc_loss = 0.0009382119004958836
Trained batch 46 in epoch 9, gen_loss = 0.14674578829014556, disc_loss = 0.000932647506062417
Trained batch 47 in epoch 9, gen_loss = 0.14679541562994322, disc_loss = 0.0009381129772615774
Trained batch 48 in epoch 9, gen_loss = 0.14720154660088675, disc_loss = 0.0009399939017199284
Trained batch 49 in epoch 9, gen_loss = 0.1470276868343353, disc_loss = 0.000934036432299763
Trained batch 50 in epoch 9, gen_loss = 0.14653569226171456, disc_loss = 0.0009281512934203242
Trained batch 51 in epoch 9, gen_loss = 0.14544824052315491, disc_loss = 0.0009234942766712406
Trained batch 52 in epoch 9, gen_loss = 0.14533609657917382, disc_loss = 0.0009167341994262248
Trained batch 53 in epoch 9, gen_loss = 0.14534807094821223, disc_loss = 0.0009104724039961757
Trained batch 54 in epoch 9, gen_loss = 0.14449558745731006, disc_loss = 0.0009043509966101159
Trained batch 55 in epoch 9, gen_loss = 0.14433562489492552, disc_loss = 0.0008967074105125253
Trained batch 56 in epoch 9, gen_loss = 0.1439343549703297, disc_loss = 0.0008906543110864923
Trained batch 57 in epoch 9, gen_loss = 0.1438554350672097, disc_loss = 0.0008858370364860406
Trained batch 58 in epoch 9, gen_loss = 0.1446228087958643, disc_loss = 0.0008843846464237609
Trained batch 59 in epoch 9, gen_loss = 0.14462967117627462, disc_loss = 0.0008907501542125829
Trained batch 60 in epoch 9, gen_loss = 0.14456959923759835, disc_loss = 0.0008920620822492742
Trained batch 61 in epoch 9, gen_loss = 0.14391081179341964, disc_loss = 0.0008923348368919124
Trained batch 62 in epoch 9, gen_loss = 0.14433487729420738, disc_loss = 0.0008902270896618979
Trained batch 63 in epoch 9, gen_loss = 0.14424733258783817, disc_loss = 0.0008886859745871334
Trained batch 64 in epoch 9, gen_loss = 0.14506601186899037, disc_loss = 0.0008880380178407694
Trained batch 65 in epoch 9, gen_loss = 0.14425886896523563, disc_loss = 0.0008888737431720294
Trained batch 66 in epoch 9, gen_loss = 0.14462789982112487, disc_loss = 0.0008886620213812801
Trained batch 67 in epoch 9, gen_loss = 0.14424821515293682, disc_loss = 0.0008892196068807286
Trained batch 68 in epoch 9, gen_loss = 0.1440135767494423, disc_loss = 0.0008862816144044147
Trained batch 69 in epoch 9, gen_loss = 0.1438277930021286, disc_loss = 0.0008909435339903992
Trained batch 70 in epoch 9, gen_loss = 0.14332104274924373, disc_loss = 0.0008925603859251182
Trained batch 71 in epoch 9, gen_loss = 0.1428411640226841, disc_loss = 0.0008923741063174222
Trained batch 72 in epoch 9, gen_loss = 0.14296899511389535, disc_loss = 0.0008895243673540703
Trained batch 73 in epoch 9, gen_loss = 0.14212886344742132, disc_loss = 0.0008873346625871302
Trained batch 74 in epoch 9, gen_loss = 0.1421611213684082, disc_loss = 0.0008925044874195009
Trained batch 75 in epoch 9, gen_loss = 0.14195465335720464, disc_loss = 0.0008931414168297412
Trained batch 76 in epoch 9, gen_loss = 0.14210735590426954, disc_loss = 0.0008909518308121131
Trained batch 77 in epoch 9, gen_loss = 0.14179779971257234, disc_loss = 0.000889776877906675
Trained batch 78 in epoch 9, gen_loss = 0.1420892873142339, disc_loss = 0.0008907427416695871
Trained batch 79 in epoch 9, gen_loss = 0.14152057580649852, disc_loss = 0.0008885544728400418
Trained batch 80 in epoch 9, gen_loss = 0.1416263473622593, disc_loss = 0.0008856163559234298
Trained batch 81 in epoch 9, gen_loss = 0.14173295076300457, disc_loss = 0.0008821873489068821
Trained batch 82 in epoch 9, gen_loss = 0.14172533405832496, disc_loss = 0.0008852109723269984
Trained batch 83 in epoch 9, gen_loss = 0.14220634280216127, disc_loss = 0.000883286594693172
Trained batch 84 in epoch 9, gen_loss = 0.1420641601085663, disc_loss = 0.0008835760578650105
Trained batch 85 in epoch 9, gen_loss = 0.14150834811288257, disc_loss = 0.0008830125947878154
Trained batch 86 in epoch 9, gen_loss = 0.14149839097055897, disc_loss = 0.0008826771227177233
Trained batch 87 in epoch 9, gen_loss = 0.14105684276331554, disc_loss = 0.0008797915139770008
Trained batch 88 in epoch 9, gen_loss = 0.14100496688585604, disc_loss = 0.0008768575632908078
Trained batch 89 in epoch 9, gen_loss = 0.14132802022827995, disc_loss = 0.0008750162420458057
Trained batch 90 in epoch 9, gen_loss = 0.14123110784279122, disc_loss = 0.000872306736470149
Trained batch 91 in epoch 9, gen_loss = 0.1416546226195667, disc_loss = 0.0008693616827772728
Trained batch 92 in epoch 9, gen_loss = 0.14176778607471016, disc_loss = 0.0008712607496593308
Trained batch 93 in epoch 9, gen_loss = 0.14105116623513242, disc_loss = 0.0008690087542685858
Trained batch 94 in epoch 9, gen_loss = 0.14130171098207173, disc_loss = 0.0008675687839154547
Trained batch 95 in epoch 9, gen_loss = 0.14136200460294882, disc_loss = 0.0008694968967877988
Trained batch 96 in epoch 9, gen_loss = 0.14145345233150364, disc_loss = 0.0008690829881462125
Trained batch 97 in epoch 9, gen_loss = 0.14127683183368372, disc_loss = 0.000867277921631229
Trained batch 98 in epoch 9, gen_loss = 0.14139580576106756, disc_loss = 0.0008647352385903812
Trained batch 99 in epoch 9, gen_loss = 0.1410685184597969, disc_loss = 0.0008634536681347526
Trained batch 100 in epoch 9, gen_loss = 0.1413470668957965, disc_loss = 0.000863742345245555
Trained batch 101 in epoch 9, gen_loss = 0.14106460704522975, disc_loss = 0.0008639940331740232
Trained batch 102 in epoch 9, gen_loss = 0.140572127207969, disc_loss = 0.0008653785128630155
Trained batch 103 in epoch 9, gen_loss = 0.14021248714281961, disc_loss = 0.0008647067182979439
Trained batch 104 in epoch 9, gen_loss = 0.1401525821004595, disc_loss = 0.0008623772902258982
Trained batch 105 in epoch 9, gen_loss = 0.14061633314726488, disc_loss = 0.0008616761179785859
Trained batch 106 in epoch 9, gen_loss = 0.14037577404040041, disc_loss = 0.0008598868542015727
Trained batch 107 in epoch 9, gen_loss = 0.14060737275414997, disc_loss = 0.0008571294981973349
Trained batch 108 in epoch 9, gen_loss = 0.1407817621296699, disc_loss = 0.0008545568046788044
Trained batch 109 in epoch 9, gen_loss = 0.14060304273258556, disc_loss = 0.0008529286987719719
Trained batch 110 in epoch 9, gen_loss = 0.1406501716858632, disc_loss = 0.0008529542453968814
Trained batch 111 in epoch 9, gen_loss = 0.1407022292592696, disc_loss = 0.0008542678278899984
Trained batch 112 in epoch 9, gen_loss = 0.14045585599620786, disc_loss = 0.000868168111171458
Trained batch 113 in epoch 9, gen_loss = 0.14000693120454488, disc_loss = 0.0008762033465788128
Trained batch 114 in epoch 9, gen_loss = 0.14000079787295797, disc_loss = 0.0008792716460606164
Trained batch 115 in epoch 9, gen_loss = 0.13985502103279376, disc_loss = 0.0008795957393635161
Trained batch 116 in epoch 9, gen_loss = 0.13964807961741063, disc_loss = 0.0008811926353288989
Trained batch 117 in epoch 9, gen_loss = 0.13951510367757183, disc_loss = 0.0008911184946339483
Trained batch 118 in epoch 9, gen_loss = 0.13950009731685414, disc_loss = 0.0008929136153917071
Trained batch 119 in epoch 9, gen_loss = 0.13937346612413723, disc_loss = 0.0008933617886214051
Trained batch 120 in epoch 9, gen_loss = 0.13912180681859165, disc_loss = 0.000892807593163149
Trained batch 121 in epoch 9, gen_loss = 0.1388661211631337, disc_loss = 0.0008918823639492001
Trained batch 122 in epoch 9, gen_loss = 0.13903740290703812, disc_loss = 0.0008909281944700828
Trained batch 123 in epoch 9, gen_loss = 0.13903013039981166, disc_loss = 0.0008935567389163489
Trained batch 124 in epoch 9, gen_loss = 0.13917219972610473, disc_loss = 0.0008929790093097835
Trained batch 125 in epoch 9, gen_loss = 0.13907865943416717, disc_loss = 0.0008995918945560882
Trained batch 126 in epoch 9, gen_loss = 0.13900778260756666, disc_loss = 0.0009008951819278153
Trained batch 127 in epoch 9, gen_loss = 0.13892054720781744, disc_loss = 0.0008996111694159481
Trained batch 128 in epoch 9, gen_loss = 0.13875888553700705, disc_loss = 0.0008973531470572677
Trained batch 129 in epoch 9, gen_loss = 0.13846051899286416, disc_loss = 0.0008974583548619053
Trained batch 130 in epoch 9, gen_loss = 0.13867045245097795, disc_loss = 0.0009002070045294169
Trained batch 131 in epoch 9, gen_loss = 0.13883242981903482, disc_loss = 0.0009010621497785023
Trained batch 132 in epoch 9, gen_loss = 0.13895373259271895, disc_loss = 0.0009013089441949908
Trained batch 133 in epoch 9, gen_loss = 0.1389171243158739, disc_loss = 0.0008986952174680808
Trained batch 134 in epoch 9, gen_loss = 0.1390403091907501, disc_loss = 0.0008974352224160814
Trained batch 135 in epoch 9, gen_loss = 0.13906549925313277, disc_loss = 0.0008957552728294532
Trained batch 136 in epoch 9, gen_loss = 0.1389973827087096, disc_loss = 0.000894927202399317
Trained batch 137 in epoch 9, gen_loss = 0.13849748498287753, disc_loss = 0.0008933848650380294
Trained batch 138 in epoch 9, gen_loss = 0.1381696653451851, disc_loss = 0.0008942864761141752
Trained batch 139 in epoch 9, gen_loss = 0.13817198255232402, disc_loss = 0.0008919151938503741
Trained batch 140 in epoch 9, gen_loss = 0.1379588506323226, disc_loss = 0.000892527550681831
Trained batch 141 in epoch 9, gen_loss = 0.13825537705085647, disc_loss = 0.0008907944735051067
Trained batch 142 in epoch 9, gen_loss = 0.1384285425806379, disc_loss = 0.0008889106470664924
Trained batch 143 in epoch 9, gen_loss = 0.13848282852106625, disc_loss = 0.0008868947319974217
Trained batch 144 in epoch 9, gen_loss = 0.13856721746510473, disc_loss = 0.0008868291755287169
Trained batch 145 in epoch 9, gen_loss = 0.13851776433317628, disc_loss = 0.0008875375192162696
Trained batch 146 in epoch 9, gen_loss = 0.138548914875303, disc_loss = 0.0008878156669092599
Trained batch 147 in epoch 9, gen_loss = 0.1382829599283837, disc_loss = 0.0008867777208718975
Trained batch 148 in epoch 9, gen_loss = 0.1383817861944237, disc_loss = 0.0008891705482582492
Testing Epoch 9
Training Epoch 10
Trained batch 0 in epoch 10, gen_loss = 0.13331639766693115, disc_loss = 0.0009680052753537893
Trained batch 1 in epoch 10, gen_loss = 0.12781190872192383, disc_loss = 0.0008903637062758207
Trained batch 2 in epoch 10, gen_loss = 0.13090731700261435, disc_loss = 0.0008488631380411485
Trained batch 3 in epoch 10, gen_loss = 0.1279793381690979, disc_loss = 0.000880222869454883
Trained batch 4 in epoch 10, gen_loss = 0.11344631910324096, disc_loss = 0.0008972927927970887
Trained batch 5 in epoch 10, gen_loss = 0.11574818690617879, disc_loss = 0.0008872292043330768
Trained batch 6 in epoch 10, gen_loss = 0.11801923172814506, disc_loss = 0.0008690736472739705
Trained batch 7 in epoch 10, gen_loss = 0.11887207627296448, disc_loss = 0.0008764348822296597
Trained batch 8 in epoch 10, gen_loss = 0.11639203627904256, disc_loss = 0.0008572393821345435
Trained batch 9 in epoch 10, gen_loss = 0.11842693090438842, disc_loss = 0.0008317697793245316
Trained batch 10 in epoch 10, gen_loss = 0.11889003623615611, disc_loss = 0.0008053814473731273
Trained batch 11 in epoch 10, gen_loss = 0.11838801701863606, disc_loss = 0.0007915582633965338
Trained batch 12 in epoch 10, gen_loss = 0.12192619305390578, disc_loss = 0.0009326415467792406
Trained batch 13 in epoch 10, gen_loss = 0.12358986479895455, disc_loss = 0.0009860799057475691
Trained batch 14 in epoch 10, gen_loss = 0.12723454634348552, disc_loss = 0.0009895182253482442
Trained batch 15 in epoch 10, gen_loss = 0.1273503415286541, disc_loss = 0.0009744576127559412
Trained batch 16 in epoch 10, gen_loss = 0.12809626144521377, disc_loss = 0.0009755041785812115
Trained batch 17 in epoch 10, gen_loss = 0.12828750742806327, disc_loss = 0.0009594909497536719
Trained batch 18 in epoch 10, gen_loss = 0.12932999039951124, disc_loss = 0.0009588688752908064
Trained batch 19 in epoch 10, gen_loss = 0.12991668432950973, disc_loss = 0.0009512409655144438
Trained batch 20 in epoch 10, gen_loss = 0.13210715992110117, disc_loss = 0.0009595619797307466
Trained batch 21 in epoch 10, gen_loss = 0.13065044988285412, disc_loss = 0.001006119511492381
Trained batch 22 in epoch 10, gen_loss = 0.13135700381320456, disc_loss = 0.0010040455280155268
Trained batch 23 in epoch 10, gen_loss = 0.13114474465449652, disc_loss = 0.0010009357235200393
Trained batch 24 in epoch 10, gen_loss = 0.1305181312561035, disc_loss = 0.0009897134290076791
Trained batch 25 in epoch 10, gen_loss = 0.13005201862408564, disc_loss = 0.0009902141061432373
Trained batch 26 in epoch 10, gen_loss = 0.130731048407378, disc_loss = 0.0009874265912609796
Trained batch 27 in epoch 10, gen_loss = 0.1297590093953269, disc_loss = 0.0009759784422515493
Trained batch 28 in epoch 10, gen_loss = 0.12975398425398202, disc_loss = 0.0009830633543656561
Trained batch 29 in epoch 10, gen_loss = 0.12958142161369324, disc_loss = 0.0009743739307547609
Trained batch 30 in epoch 10, gen_loss = 0.12901853265300875, disc_loss = 0.000965933465669232
Trained batch 31 in epoch 10, gen_loss = 0.12874075956642628, disc_loss = 0.0009662625107011991
Trained batch 32 in epoch 10, gen_loss = 0.12816167238986853, disc_loss = 0.000953170959484961
Trained batch 33 in epoch 10, gen_loss = 0.12678518803680644, disc_loss = 0.0009489081378834432
Trained batch 34 in epoch 10, gen_loss = 0.12585729786327907, disc_loss = 0.0009495994491901781
Trained batch 35 in epoch 10, gen_loss = 0.12510965516169867, disc_loss = 0.0009428179780823282
Trained batch 36 in epoch 10, gen_loss = 0.12570539439046705, disc_loss = 0.0009339729849425321
Trained batch 37 in epoch 10, gen_loss = 0.12636514949171165, disc_loss = 0.0009309445434298954
Trained batch 38 in epoch 10, gen_loss = 0.12611330243257377, disc_loss = 0.0009199120074462814
Trained batch 39 in epoch 10, gen_loss = 0.12728246226906775, disc_loss = 0.0009152859493042342
Trained batch 40 in epoch 10, gen_loss = 0.1270786051343127, disc_loss = 0.0009085256294006618
Trained batch 41 in epoch 10, gen_loss = 0.12765983385699137, disc_loss = 0.0009003403011731626
Trained batch 42 in epoch 10, gen_loss = 0.12721391126166942, disc_loss = 0.0009152313713309203
Trained batch 43 in epoch 10, gen_loss = 0.12732721052386545, disc_loss = 0.0009353428203295069
Trained batch 44 in epoch 10, gen_loss = 0.1271323866314358, disc_loss = 0.0009401842706008918
Trained batch 45 in epoch 10, gen_loss = 0.12735454543777133, disc_loss = 0.000943056268506157
Trained batch 46 in epoch 10, gen_loss = 0.12708552530471315, disc_loss = 0.0009426000426483756
Trained batch 47 in epoch 10, gen_loss = 0.12686231670280299, disc_loss = 0.0009401281240570825
Trained batch 48 in epoch 10, gen_loss = 0.12703303536590266, disc_loss = 0.0009319517531014066
Trained batch 49 in epoch 10, gen_loss = 0.12739779591560363, disc_loss = 0.0009244377282448113
Trained batch 50 in epoch 10, gen_loss = 0.12760687341877058, disc_loss = 0.0009165814662279159
Trained batch 51 in epoch 10, gen_loss = 0.1271149951678056, disc_loss = 0.0009158418319062688
Trained batch 52 in epoch 10, gen_loss = 0.1277070495317567, disc_loss = 0.0009142988326273999
Trained batch 53 in epoch 10, gen_loss = 0.12781067358122933, disc_loss = 0.0009139314211939496
Trained batch 54 in epoch 10, gen_loss = 0.12725518345832826, disc_loss = 0.0009085080713372339
Trained batch 55 in epoch 10, gen_loss = 0.12710659418787276, disc_loss = 0.0009013042519135135
Trained batch 56 in epoch 10, gen_loss = 0.12822594768122622, disc_loss = 0.0008970579467387053
Trained batch 57 in epoch 10, gen_loss = 0.12849500980870476, disc_loss = 0.0008927737493148266
Trained batch 58 in epoch 10, gen_loss = 0.1286059567483805, disc_loss = 0.0009015454581180998
Trained batch 59 in epoch 10, gen_loss = 0.1280979091922442, disc_loss = 0.0008996795659186319
Trained batch 60 in epoch 10, gen_loss = 0.1279641604814373, disc_loss = 0.0009010789131547218
Trained batch 61 in epoch 10, gen_loss = 0.12852482449623845, disc_loss = 0.0009008519804000013
Trained batch 62 in epoch 10, gen_loss = 0.12898559608156718, disc_loss = 0.0008964691309273125
Trained batch 63 in epoch 10, gen_loss = 0.12859597010537982, disc_loss = 0.0008917844161260291
Trained batch 64 in epoch 10, gen_loss = 0.12964686888914842, disc_loss = 0.0008899988543886978
Trained batch 65 in epoch 10, gen_loss = 0.1294226614814816, disc_loss = 0.0008959036424516164
Trained batch 66 in epoch 10, gen_loss = 0.1296282165975713, disc_loss = 0.0009067216184365549
Trained batch 67 in epoch 10, gen_loss = 0.12932245170368867, disc_loss = 0.0009073548392146168
Trained batch 68 in epoch 10, gen_loss = 0.12967637483624445, disc_loss = 0.0009016159658684679
Trained batch 69 in epoch 10, gen_loss = 0.1295202272278922, disc_loss = 0.0009016751361611698
Trained batch 70 in epoch 10, gen_loss = 0.12937937823819443, disc_loss = 0.0008966882555732425
Trained batch 71 in epoch 10, gen_loss = 0.12940587682856453, disc_loss = 0.0008971845632509536
Trained batch 72 in epoch 10, gen_loss = 0.12920981686409205, disc_loss = 0.0008961062691786824
Trained batch 73 in epoch 10, gen_loss = 0.12905835944253044, disc_loss = 0.0008946320937153556
Trained batch 74 in epoch 10, gen_loss = 0.12969162225723266, disc_loss = 0.0008952286629937589
Trained batch 75 in epoch 10, gen_loss = 0.13035940261263596, disc_loss = 0.0008952926268408957
Trained batch 76 in epoch 10, gen_loss = 0.13022831740317406, disc_loss = 0.0008904965679076585
Trained batch 77 in epoch 10, gen_loss = 0.12984474041523078, disc_loss = 0.0008900352180577242
Trained batch 78 in epoch 10, gen_loss = 0.12992539134206652, disc_loss = 0.0008869301159335654
Trained batch 79 in epoch 10, gen_loss = 0.13024002760648729, disc_loss = 0.0008836089313263073
Trained batch 80 in epoch 10, gen_loss = 0.12991522565300082, disc_loss = 0.0008847002345309765
Trained batch 81 in epoch 10, gen_loss = 0.12994781136512756, disc_loss = 0.000882871116784106
Trained batch 82 in epoch 10, gen_loss = 0.1294601731989757, disc_loss = 0.0008787554674725756
Trained batch 83 in epoch 10, gen_loss = 0.12900543000016892, disc_loss = 0.0008758588907464097
Trained batch 84 in epoch 10, gen_loss = 0.1282421210232903, disc_loss = 0.0008744620266096557
Trained batch 85 in epoch 10, gen_loss = 0.12819458960100663, disc_loss = 0.0008707760838618458
Trained batch 86 in epoch 10, gen_loss = 0.1281097085996606, disc_loss = 0.0008685099397218604
Trained batch 87 in epoch 10, gen_loss = 0.12811342830007727, disc_loss = 0.0008696941394274207
Trained batch 88 in epoch 10, gen_loss = 0.1278720467947842, disc_loss = 0.0008688881689829103
Trained batch 89 in epoch 10, gen_loss = 0.12734440763791402, disc_loss = 0.0008697570120501849
Trained batch 90 in epoch 10, gen_loss = 0.12688745738385798, disc_loss = 0.000867510279691727
Trained batch 91 in epoch 10, gen_loss = 0.1271046685135883, disc_loss = 0.0008648502369633998
Trained batch 92 in epoch 10, gen_loss = 0.12726679540449573, disc_loss = 0.0008622397010224641
Trained batch 93 in epoch 10, gen_loss = 0.1276175081729889, disc_loss = 0.0008599457623278524
Trained batch 94 in epoch 10, gen_loss = 0.1275110263573496, disc_loss = 0.0008575510049827005
Trained batch 95 in epoch 10, gen_loss = 0.12766584505637488, disc_loss = 0.0008575270633931117
Trained batch 96 in epoch 10, gen_loss = 0.12791460752487183, disc_loss = 0.000858329035480958
Trained batch 97 in epoch 10, gen_loss = 0.12820066937378474, disc_loss = 0.0008586795379322174
Trained batch 98 in epoch 10, gen_loss = 0.12778546021442222, disc_loss = 0.0008565839938584226
Trained batch 99 in epoch 10, gen_loss = 0.12795845329761504, disc_loss = 0.0008565174107206986
Trained batch 100 in epoch 10, gen_loss = 0.12834874297132587, disc_loss = 0.0008538118044910307
Trained batch 101 in epoch 10, gen_loss = 0.127994952248592, disc_loss = 0.0008523223137565176
Trained batch 102 in epoch 10, gen_loss = 0.12808326436477957, disc_loss = 0.0008497554769296452
Trained batch 103 in epoch 10, gen_loss = 0.12818418443202972, disc_loss = 0.0008463502325377284
Trained batch 104 in epoch 10, gen_loss = 0.12818590714817957, disc_loss = 0.0008431483121100991
Trained batch 105 in epoch 10, gen_loss = 0.12816302309621055, disc_loss = 0.0008396425647968602
Trained batch 106 in epoch 10, gen_loss = 0.12829402451203248, disc_loss = 0.0008380456928764339
Trained batch 107 in epoch 10, gen_loss = 0.1285970401432779, disc_loss = 0.0008351848368032801
Trained batch 108 in epoch 10, gen_loss = 0.1286439909300673, disc_loss = 0.0008325285375451481
Trained batch 109 in epoch 10, gen_loss = 0.1283670883287083, disc_loss = 0.000829469823193821
Trained batch 110 in epoch 10, gen_loss = 0.12808619748364697, disc_loss = 0.0008281881995457183
Trained batch 111 in epoch 10, gen_loss = 0.1281712885413851, disc_loss = 0.0008390348474287228
Trained batch 112 in epoch 10, gen_loss = 0.12754950243814855, disc_loss = 0.0008425342606223988
Trained batch 113 in epoch 10, gen_loss = 0.1273526217330966, disc_loss = 0.0008405972361000941
Trained batch 114 in epoch 10, gen_loss = 0.12728982334551603, disc_loss = 0.0008379405374517259
Trained batch 115 in epoch 10, gen_loss = 0.12739685794402814, disc_loss = 0.0008352867554439681
Trained batch 116 in epoch 10, gen_loss = 0.12697811972381723, disc_loss = 0.0008322990809877714
Trained batch 117 in epoch 10, gen_loss = 0.12718340173616247, disc_loss = 0.0008303008986423897
Trained batch 118 in epoch 10, gen_loss = 0.12698861681112722, disc_loss = 0.0008285262650309303
Trained batch 119 in epoch 10, gen_loss = 0.1269220436612765, disc_loss = 0.0008383284250157886
Trained batch 120 in epoch 10, gen_loss = 0.1265747859950893, disc_loss = 0.0008436705294634746
Trained batch 121 in epoch 10, gen_loss = 0.12650364515234214, disc_loss = 0.0008435605201664091
Trained batch 122 in epoch 10, gen_loss = 0.12630381332180365, disc_loss = 0.0008458678494207561
Trained batch 123 in epoch 10, gen_loss = 0.12636622714419518, disc_loss = 0.0008458780991326596
Trained batch 124 in epoch 10, gen_loss = 0.1262471082210541, disc_loss = 0.0008466167352162301
Trained batch 125 in epoch 10, gen_loss = 0.12670050656038617, disc_loss = 0.0008459253267141147
Trained batch 126 in epoch 10, gen_loss = 0.12681364801925, disc_loss = 0.0008446224062248889
Trained batch 127 in epoch 10, gen_loss = 0.12617622478865087, disc_loss = 0.0008439766443189001
Trained batch 128 in epoch 10, gen_loss = 0.1263442439164302, disc_loss = 0.000844267205526518
Trained batch 129 in epoch 10, gen_loss = 0.12640380492577186, disc_loss = 0.0008432815258856863
Trained batch 130 in epoch 10, gen_loss = 0.12644189778175063, disc_loss = 0.0008409985964086959
Trained batch 131 in epoch 10, gen_loss = 0.12667464397170328, disc_loss = 0.0008390898235092843
Trained batch 132 in epoch 10, gen_loss = 0.12685843495498025, disc_loss = 0.0008369320198277334
Trained batch 133 in epoch 10, gen_loss = 0.12680019616191066, disc_loss = 0.000834046195368908
Trained batch 134 in epoch 10, gen_loss = 0.12651156098754318, disc_loss = 0.0008338041060293714
Trained batch 135 in epoch 10, gen_loss = 0.12675520777702332, disc_loss = 0.0008329477440223427
Trained batch 136 in epoch 10, gen_loss = 0.1265367456596263, disc_loss = 0.0008313984505621458
Trained batch 137 in epoch 10, gen_loss = 0.1265855712303217, disc_loss = 0.0008349099430167859
Trained batch 138 in epoch 10, gen_loss = 0.1265554286593156, disc_loss = 0.0008406731029536923
Trained batch 139 in epoch 10, gen_loss = 0.12678641591753279, disc_loss = 0.0008453202296680372
Trained batch 140 in epoch 10, gen_loss = 0.1264378990687377, disc_loss = 0.0008472213211984552
Trained batch 141 in epoch 10, gen_loss = 0.12642328462130586, disc_loss = 0.00084794227248648
Trained batch 142 in epoch 10, gen_loss = 0.12627116054088086, disc_loss = 0.0008468400032448394
Trained batch 143 in epoch 10, gen_loss = 0.12637043495972952, disc_loss = 0.0008472967832252228
Trained batch 144 in epoch 10, gen_loss = 0.125889640224391, disc_loss = 0.0008503896581683436
Trained batch 145 in epoch 10, gen_loss = 0.12561025378638752, disc_loss = 0.0008514021034511954
Trained batch 146 in epoch 10, gen_loss = 0.12627029723050642, disc_loss = 0.0008534998660685406
Trained batch 147 in epoch 10, gen_loss = 0.1261905596868412, disc_loss = 0.0008544265209992945
Trained batch 148 in epoch 10, gen_loss = 0.12587240038302122, disc_loss = 0.000860790315399809
Testing Epoch 10
Training Epoch 11
Trained batch 0 in epoch 11, gen_loss = 0.11154922842979431, disc_loss = 0.0007473358418792486
Trained batch 1 in epoch 11, gen_loss = 0.11346670985221863, disc_loss = 0.000819489563582465
Trained batch 2 in epoch 11, gen_loss = 0.11375717322031657, disc_loss = 0.0007105289065899948
Trained batch 3 in epoch 11, gen_loss = 0.12009819597005844, disc_loss = 0.0007042114739306271
Trained batch 4 in epoch 11, gen_loss = 0.12314902544021607, disc_loss = 0.0007207710528746248
Trained batch 5 in epoch 11, gen_loss = 0.13336886962254843, disc_loss = 0.0008205134654417634
Trained batch 6 in epoch 11, gen_loss = 0.1278323701449803, disc_loss = 0.0009413838519581727
Trained batch 7 in epoch 11, gen_loss = 0.11978256329894066, disc_loss = 0.0010107492125825956
Trained batch 8 in epoch 11, gen_loss = 0.11790721284018622, disc_loss = 0.0009737175423651934
Trained batch 9 in epoch 11, gen_loss = 0.12143052816390991, disc_loss = 0.0009487653966061771
Trained batch 10 in epoch 11, gen_loss = 0.12263734232295644, disc_loss = 0.0009161375134929337
Trained batch 11 in epoch 11, gen_loss = 0.11943458517392476, disc_loss = 0.0008821898615375782
Trained batch 12 in epoch 11, gen_loss = 0.11860863520548894, disc_loss = 0.0008696525966605315
Trained batch 13 in epoch 11, gen_loss = 0.1191834786108562, disc_loss = 0.0008764346712268889
Trained batch 14 in epoch 11, gen_loss = 0.11981716553370157, disc_loss = 0.0008740436130513748
Trained batch 15 in epoch 11, gen_loss = 0.11866685375571251, disc_loss = 0.0008699892860022373
Trained batch 16 in epoch 11, gen_loss = 0.1156203939634211, disc_loss = 0.0008981536101440297
Trained batch 17 in epoch 11, gen_loss = 0.1149341066678365, disc_loss = 0.0008941916457843035
Trained batch 18 in epoch 11, gen_loss = 0.11492621428088139, disc_loss = 0.0008779019944516844
Trained batch 19 in epoch 11, gen_loss = 0.11501883417367935, disc_loss = 0.0008579262590501458
Trained batch 20 in epoch 11, gen_loss = 0.11326673343068078, disc_loss = 0.000848860111242781
Trained batch 21 in epoch 11, gen_loss = 0.1141130423003977, disc_loss = 0.0008327905009289018
Trained batch 22 in epoch 11, gen_loss = 0.11445639962735384, disc_loss = 0.0008255661510781425
Trained batch 23 in epoch 11, gen_loss = 0.113368126253287, disc_loss = 0.0008084542556995681
Trained batch 24 in epoch 11, gen_loss = 0.11267176389694214, disc_loss = 0.0007965789420995861
Trained batch 25 in epoch 11, gen_loss = 0.11497720846763024, disc_loss = 0.000789290704862931
Trained batch 26 in epoch 11, gen_loss = 0.11309727584874188, disc_loss = 0.0007931020626091157
Trained batch 27 in epoch 11, gen_loss = 0.11144064153943743, disc_loss = 0.0008048268282436766
Trained batch 28 in epoch 11, gen_loss = 0.10979489108611798, disc_loss = 0.0007962617844519816
Trained batch 29 in epoch 11, gen_loss = 0.11200790305932364, disc_loss = 0.0007909291452961043
Trained batch 30 in epoch 11, gen_loss = 0.1116296072160044, disc_loss = 0.0007848090280012618
Trained batch 31 in epoch 11, gen_loss = 0.11019314080476761, disc_loss = 0.0007838823757992941
Trained batch 32 in epoch 11, gen_loss = 0.10957360177329092, disc_loss = 0.0007825282421739151
Trained batch 33 in epoch 11, gen_loss = 0.1099011687671437, disc_loss = 0.0007866449998212321
Trained batch 34 in epoch 11, gen_loss = 0.11117427945137023, disc_loss = 0.0007813833113427141
Trained batch 35 in epoch 11, gen_loss = 0.11108513921499252, disc_loss = 0.0007733861736293571
Trained batch 36 in epoch 11, gen_loss = 0.11130194486798467, disc_loss = 0.000773688215869353
Trained batch 37 in epoch 11, gen_loss = 0.11168185739140761, disc_loss = 0.0007671935393438233
Trained batch 38 in epoch 11, gen_loss = 0.11230518496953525, disc_loss = 0.0007608119056572039
Trained batch 39 in epoch 11, gen_loss = 0.11272570192813873, disc_loss = 0.000754000688175438
Trained batch 40 in epoch 11, gen_loss = 0.11288330031604302, disc_loss = 0.0007514225726481527
Trained batch 41 in epoch 11, gen_loss = 0.1127544173172542, disc_loss = 0.0007485780245458175
Trained batch 42 in epoch 11, gen_loss = 0.11204341261885888, disc_loss = 0.0007410958554151707
Trained batch 43 in epoch 11, gen_loss = 0.11186500706455925, disc_loss = 0.0007362442920566536
Trained batch 44 in epoch 11, gen_loss = 0.11256428294711643, disc_loss = 0.0007310152771727493
Trained batch 45 in epoch 11, gen_loss = 0.11260267638641855, disc_loss = 0.0007241422509136812
Trained batch 46 in epoch 11, gen_loss = 0.11264410932013329, disc_loss = 0.0007174901739803163
Trained batch 47 in epoch 11, gen_loss = 0.1127451943854491, disc_loss = 0.0007146840574326537
Trained batch 48 in epoch 11, gen_loss = 0.11341078488194213, disc_loss = 0.0007134449332049686
Trained batch 49 in epoch 11, gen_loss = 0.11272561848163605, disc_loss = 0.0007094966660952196
Trained batch 50 in epoch 11, gen_loss = 0.11202138896081962, disc_loss = 0.0007074945726130596
Trained batch 51 in epoch 11, gen_loss = 0.11214767740322994, disc_loss = 0.0007026148215607883
Trained batch 52 in epoch 11, gen_loss = 0.11159524658940873, disc_loss = 0.0006995238940328149
Trained batch 53 in epoch 11, gen_loss = 0.11151051907627671, disc_loss = 0.0006983193156042102
Trained batch 54 in epoch 11, gen_loss = 0.11070492213422602, disc_loss = 0.0006947766253936359
Trained batch 55 in epoch 11, gen_loss = 0.10982476440923554, disc_loss = 0.000690000582835637
Trained batch 56 in epoch 11, gen_loss = 0.10995140985438698, disc_loss = 0.0006861979838280955
Trained batch 57 in epoch 11, gen_loss = 0.10946423791605851, disc_loss = 0.0006829825237971442
Trained batch 58 in epoch 11, gen_loss = 0.10966981720116178, disc_loss = 0.0006789455433983861
Trained batch 59 in epoch 11, gen_loss = 0.10933760652939478, disc_loss = 0.0006802024625358171
Trained batch 60 in epoch 11, gen_loss = 0.10905804839290556, disc_loss = 0.0006798619302333195
Trained batch 61 in epoch 11, gen_loss = 0.10950022262911643, disc_loss = 0.0006799922515300193
Trained batch 62 in epoch 11, gen_loss = 0.10957149428034586, disc_loss = 0.0006764554612648984
Trained batch 63 in epoch 11, gen_loss = 0.1089612478390336, disc_loss = 0.0006728516118528205
Trained batch 64 in epoch 11, gen_loss = 0.10888454730694111, disc_loss = 0.0006709369481541216
Trained batch 65 in epoch 11, gen_loss = 0.10884910054279096, disc_loss = 0.000673434451031922
Trained batch 66 in epoch 11, gen_loss = 0.10918388838198648, disc_loss = 0.0006698291364765323
Trained batch 67 in epoch 11, gen_loss = 0.10943019346279256, disc_loss = 0.000667558579794679
Trained batch 68 in epoch 11, gen_loss = 0.10902959324311519, disc_loss = 0.0006639584772410276
Trained batch 69 in epoch 11, gen_loss = 0.10910844717706952, disc_loss = 0.0006604672779628475
Trained batch 70 in epoch 11, gen_loss = 0.11002591210351863, disc_loss = 0.0006596359459545569
Trained batch 71 in epoch 11, gen_loss = 0.10919247940182686, disc_loss = 0.0006628481985697161
Trained batch 72 in epoch 11, gen_loss = 0.10875114594420342, disc_loss = 0.0006626655530241918
Trained batch 73 in epoch 11, gen_loss = 0.10857315804507281, disc_loss = 0.0006598582278112755
Trained batch 74 in epoch 11, gen_loss = 0.10895544489224752, disc_loss = 0.0006567323103081435
Trained batch 75 in epoch 11, gen_loss = 0.1091595656777683, disc_loss = 0.0006574431704632987
Trained batch 76 in epoch 11, gen_loss = 0.10963487354191867, disc_loss = 0.0006573175676560102
Trained batch 77 in epoch 11, gen_loss = 0.11051410856919411, disc_loss = 0.0006562880056056505
Trained batch 78 in epoch 11, gen_loss = 0.1111559388758261, disc_loss = 0.0006602731127368545
Trained batch 79 in epoch 11, gen_loss = 0.11068581268191338, disc_loss = 0.0006592667636141414
Trained batch 80 in epoch 11, gen_loss = 0.11082790148111037, disc_loss = 0.0006569037106129583
Trained batch 81 in epoch 11, gen_loss = 0.11111148065183221, disc_loss = 0.0006556703117051412
Trained batch 82 in epoch 11, gen_loss = 0.11078800781663642, disc_loss = 0.0006544728537583836
Trained batch 83 in epoch 11, gen_loss = 0.11134901926631019, disc_loss = 0.0006550185935338959
Trained batch 84 in epoch 11, gen_loss = 0.11110027397380155, disc_loss = 0.0006528655477963827
Trained batch 85 in epoch 11, gen_loss = 0.11057234746079113, disc_loss = 0.0006517186384583109
Trained batch 86 in epoch 11, gen_loss = 0.111202712374172, disc_loss = 0.0006507191186149915
Trained batch 87 in epoch 11, gen_loss = 0.11069182577458295, disc_loss = 0.0006482954618563367
Trained batch 88 in epoch 11, gen_loss = 0.11031885528832339, disc_loss = 0.0006465667478080965
Trained batch 89 in epoch 11, gen_loss = 0.11009125279055701, disc_loss = 0.0006454487337679085
Trained batch 90 in epoch 11, gen_loss = 0.10971596018298642, disc_loss = 0.0006449372772444654
Trained batch 91 in epoch 11, gen_loss = 0.1099158622648405, disc_loss = 0.000642888612397339
Trained batch 92 in epoch 11, gen_loss = 0.11004106139623991, disc_loss = 0.0006422604101219325
Trained batch 93 in epoch 11, gen_loss = 0.10982974222365846, disc_loss = 0.00064057283452712
Trained batch 94 in epoch 11, gen_loss = 0.1096683028497194, disc_loss = 0.0006380121946628941
Trained batch 95 in epoch 11, gen_loss = 0.10926873050630093, disc_loss = 0.0006359394907728225
Trained batch 96 in epoch 11, gen_loss = 0.10902514900128867, disc_loss = 0.0006354130959359103
Trained batch 97 in epoch 11, gen_loss = 0.10879915526935033, disc_loss = 0.0006347793868353249
Trained batch 98 in epoch 11, gen_loss = 0.10904239163254247, disc_loss = 0.0006333993820736956
Trained batch 99 in epoch 11, gen_loss = 0.10920704990625381, disc_loss = 0.0006480116525199264
Trained batch 100 in epoch 11, gen_loss = 0.10911061651635878, disc_loss = 0.0006540833711900776
Trained batch 101 in epoch 11, gen_loss = 0.10844576855500539, disc_loss = 0.0006569327670149505
Trained batch 102 in epoch 11, gen_loss = 0.10849397419725806, disc_loss = 0.0006583582828029339
Trained batch 103 in epoch 11, gen_loss = 0.10824591207962769, disc_loss = 0.000658393416625376
Trained batch 104 in epoch 11, gen_loss = 0.10813491486367725, disc_loss = 0.000657190130247424
Trained batch 105 in epoch 11, gen_loss = 0.10766879483213965, disc_loss = 0.0006556199250725221
Trained batch 106 in epoch 11, gen_loss = 0.10772499052163596, disc_loss = 0.0006546231865813242
Trained batch 107 in epoch 11, gen_loss = 0.108033855204229, disc_loss = 0.0006600638584199327
Trained batch 108 in epoch 11, gen_loss = 0.10747977134284623, disc_loss = 0.000659941016363168
Trained batch 109 in epoch 11, gen_loss = 0.10777199132875963, disc_loss = 0.0006655492417683655
Trained batch 110 in epoch 11, gen_loss = 0.10811763276924959, disc_loss = 0.0006710778783402733
Trained batch 111 in epoch 11, gen_loss = 0.10855651859726224, disc_loss = 0.0006741569419058838
Trained batch 112 in epoch 11, gen_loss = 0.10849346339175131, disc_loss = 0.0006750781486733957
Trained batch 113 in epoch 11, gen_loss = 0.10828890559966103, disc_loss = 0.0006749442535485223
Trained batch 114 in epoch 11, gen_loss = 0.10821531648221223, disc_loss = 0.0006779392006928506
Trained batch 115 in epoch 11, gen_loss = 0.1077923600015969, disc_loss = 0.0006782422890958922
Trained batch 116 in epoch 11, gen_loss = 0.10776846480165791, disc_loss = 0.0006768529708338026
Trained batch 117 in epoch 11, gen_loss = 0.10789275371422202, disc_loss = 0.0006778116334995286
Trained batch 118 in epoch 11, gen_loss = 0.10776914818948057, disc_loss = 0.0006775605045219868
Trained batch 119 in epoch 11, gen_loss = 0.10785625204443931, disc_loss = 0.0006764234087313526
Trained batch 120 in epoch 11, gen_loss = 0.1077373779017078, disc_loss = 0.0006759251551587166
Trained batch 121 in epoch 11, gen_loss = 0.10742653075788842, disc_loss = 0.0006739719428282353
Trained batch 122 in epoch 11, gen_loss = 0.10747142366277493, disc_loss = 0.0006717409367381587
Trained batch 123 in epoch 11, gen_loss = 0.10746233886288058, disc_loss = 0.0006702401111514548
Trained batch 124 in epoch 11, gen_loss = 0.10742825222015381, disc_loss = 0.0006690854018088431
Trained batch 125 in epoch 11, gen_loss = 0.10703183308480278, disc_loss = 0.0006679669038728914
Trained batch 126 in epoch 11, gen_loss = 0.10712889798982876, disc_loss = 0.0006753123733380032
Trained batch 127 in epoch 11, gen_loss = 0.10700277448631823, disc_loss = 0.0006806789176607708
Trained batch 128 in epoch 11, gen_loss = 0.10664112623347792, disc_loss = 0.0006810827223609324
Trained batch 129 in epoch 11, gen_loss = 0.1070313254228005, disc_loss = 0.0006854705107308781
Trained batch 130 in epoch 11, gen_loss = 0.10734983323184588, disc_loss = 0.0006877462446728707
Trained batch 131 in epoch 11, gen_loss = 0.10747584587696826, disc_loss = 0.0006876013444112191
Trained batch 132 in epoch 11, gen_loss = 0.10745977571136073, disc_loss = 0.0006906402197095769
Trained batch 133 in epoch 11, gen_loss = 0.10712290499637377, disc_loss = 0.0006953552206752321
Trained batch 134 in epoch 11, gen_loss = 0.10723638689076459, disc_loss = 0.0006953903437264402
Trained batch 135 in epoch 11, gen_loss = 0.10720894310404272, disc_loss = 0.0007009027859192643
Trained batch 136 in epoch 11, gen_loss = 0.10699024383169022, disc_loss = 0.0007038676419149214
Trained batch 137 in epoch 11, gen_loss = 0.10687588457612024, disc_loss = 0.0007030570782987617
Trained batch 138 in epoch 11, gen_loss = 0.10654176139145446, disc_loss = 0.0007020045729712482
Trained batch 139 in epoch 11, gen_loss = 0.1065889882189887, disc_loss = 0.000700126459871951
Trained batch 140 in epoch 11, gen_loss = 0.1066275898446428, disc_loss = 0.0006994690258115371
Trained batch 141 in epoch 11, gen_loss = 0.10659839149931787, disc_loss = 0.0007023240974940307
Trained batch 142 in epoch 11, gen_loss = 0.10657041097854401, disc_loss = 0.0007021978039170739
Trained batch 143 in epoch 11, gen_loss = 0.10653445000449817, disc_loss = 0.0007012586312258565
Trained batch 144 in epoch 11, gen_loss = 0.10626019157212356, disc_loss = 0.0007002507071492487
Trained batch 145 in epoch 11, gen_loss = 0.10695455621366631, disc_loss = 0.0007010456134743785
Trained batch 146 in epoch 11, gen_loss = 0.10688633821448501, disc_loss = 0.0007046097834106712
Trained batch 147 in epoch 11, gen_loss = 0.10662461374257062, disc_loss = 0.0007120822768696156
Trained batch 148 in epoch 11, gen_loss = 0.10632692287432267, disc_loss = 0.0007177147984617208
Testing Epoch 11
Training Epoch 12
Trained batch 0 in epoch 12, gen_loss = 0.07273563742637634, disc_loss = 0.0018766415305435658
Trained batch 1 in epoch 12, gen_loss = 0.07651975750923157, disc_loss = 0.0017869342118501663
Trained batch 2 in epoch 12, gen_loss = 0.0738611916700999, disc_loss = 0.0015257810009643435
Trained batch 3 in epoch 12, gen_loss = 0.08881095796823502, disc_loss = 0.0013372303801588714
Trained batch 4 in epoch 12, gen_loss = 0.08545403480529785, disc_loss = 0.0012296456843614578
Trained batch 5 in epoch 12, gen_loss = 0.08292206625143687, disc_loss = 0.0011257397030324985
Trained batch 6 in epoch 12, gen_loss = 0.08725004962512425, disc_loss = 0.0010590885815742826
Trained batch 7 in epoch 12, gen_loss = 0.08574480563402176, disc_loss = 0.000991488697763998
Trained batch 8 in epoch 12, gen_loss = 0.0891339017285241, disc_loss = 0.0009592901850636634
Trained batch 9 in epoch 12, gen_loss = 0.09648720920085907, disc_loss = 0.0009436601132620126
Trained batch 10 in epoch 12, gen_loss = 0.09475849704308943, disc_loss = 0.0009079346253367311
Trained batch 11 in epoch 12, gen_loss = 0.0958979402979215, disc_loss = 0.0008786173566477373
Trained batch 12 in epoch 12, gen_loss = 0.09488579172354478, disc_loss = 0.0008541351461854691
Trained batch 13 in epoch 12, gen_loss = 0.0964151258979525, disc_loss = 0.000841109427191051
Trained batch 14 in epoch 12, gen_loss = 0.0946332593758901, disc_loss = 0.0008113984969289352
Trained batch 15 in epoch 12, gen_loss = 0.09769237227737904, disc_loss = 0.0008050436645135051
Trained batch 16 in epoch 12, gen_loss = 0.09694396572954514, disc_loss = 0.0007902728171115194
Trained batch 17 in epoch 12, gen_loss = 0.09724194473690456, disc_loss = 0.0008523668948328122
Trained batch 18 in epoch 12, gen_loss = 0.09535903679697137, disc_loss = 0.0008854285283871976
Trained batch 19 in epoch 12, gen_loss = 0.09481270611286163, disc_loss = 0.0009005440268083475
Trained batch 20 in epoch 12, gen_loss = 0.09460987079711188, disc_loss = 0.0009014504127359638
Trained batch 21 in epoch 12, gen_loss = 0.09655253182757985, disc_loss = 0.0008973837076072497
Trained batch 22 in epoch 12, gen_loss = 0.09709849046624225, disc_loss = 0.0008977155021452547
Trained batch 23 in epoch 12, gen_loss = 0.09855543449521065, disc_loss = 0.0009072276892159911
Trained batch 24 in epoch 12, gen_loss = 0.09982572317123413, disc_loss = 0.000905037015909329
Trained batch 25 in epoch 12, gen_loss = 0.10210863558145669, disc_loss = 0.0009127355487390349
Trained batch 26 in epoch 12, gen_loss = 0.10276087897795218, disc_loss = 0.0009051968022335872
Trained batch 27 in epoch 12, gen_loss = 0.10305512696504593, disc_loss = 0.0008919648483112853
Trained batch 28 in epoch 12, gen_loss = 0.10268289364617446, disc_loss = 0.000881078527590003
Trained batch 29 in epoch 12, gen_loss = 0.10165759523709615, disc_loss = 0.0008734549793492382
Trained batch 30 in epoch 12, gen_loss = 0.101667954075721, disc_loss = 0.0008732698991098591
Trained batch 31 in epoch 12, gen_loss = 0.1011834442615509, disc_loss = 0.0008662241170895868
Trained batch 32 in epoch 12, gen_loss = 0.1011925104892615, disc_loss = 0.0008596277162503226
Trained batch 33 in epoch 12, gen_loss = 0.10083956315236933, disc_loss = 0.0008530455191195121
Trained batch 34 in epoch 12, gen_loss = 0.10124963096209935, disc_loss = 0.000846552212689338
Trained batch 35 in epoch 12, gen_loss = 0.10135711150036918, disc_loss = 0.0008468457761207699
Trained batch 36 in epoch 12, gen_loss = 0.10116020650477023, disc_loss = 0.0008483568601297668
Trained batch 37 in epoch 12, gen_loss = 0.10079450434760044, disc_loss = 0.0008377196722186023
Trained batch 38 in epoch 12, gen_loss = 0.0993949396487994, disc_loss = 0.0008844417222859099
Trained batch 39 in epoch 12, gen_loss = 0.09851671904325485, disc_loss = 0.0009044433223607484
Trained batch 40 in epoch 12, gen_loss = 0.09668085778631814, disc_loss = 0.0009231130264574526
Trained batch 41 in epoch 12, gen_loss = 0.0971642526842299, disc_loss = 0.0009309687281659405
Trained batch 42 in epoch 12, gen_loss = 0.09713968288066775, disc_loss = 0.0009406384867128678
Trained batch 43 in epoch 12, gen_loss = 0.09735423461957411, disc_loss = 0.0009419185549962673
Trained batch 44 in epoch 12, gen_loss = 0.09749794403711955, disc_loss = 0.0009377194807812985
Trained batch 45 in epoch 12, gen_loss = 0.09710808551829794, disc_loss = 0.0009349006115529767
Trained batch 46 in epoch 12, gen_loss = 0.0965490905528373, disc_loss = 0.000926202250411734
Trained batch 47 in epoch 12, gen_loss = 0.09621757889787357, disc_loss = 0.0009192190682369983
Trained batch 48 in epoch 12, gen_loss = 0.09747176267662827, disc_loss = 0.0009144985690779452
Trained batch 49 in epoch 12, gen_loss = 0.09715279340744018, disc_loss = 0.0009092669206438586
Trained batch 50 in epoch 12, gen_loss = 0.09656414681789922, disc_loss = 0.0009038108783344939
Trained batch 51 in epoch 12, gen_loss = 0.09734739477817829, disc_loss = 0.00089598125095318
Trained batch 52 in epoch 12, gen_loss = 0.09807847580819759, disc_loss = 0.0008883798689326659
Trained batch 53 in epoch 12, gen_loss = 0.09788017692389311, disc_loss = 0.0008828459243954125
Trained batch 54 in epoch 12, gen_loss = 0.09802725369280035, disc_loss = 0.0008770697353280742
Trained batch 55 in epoch 12, gen_loss = 0.09846241080335208, disc_loss = 0.0008737172159141794
Trained batch 56 in epoch 12, gen_loss = 0.09734918516978883, disc_loss = 0.0008739345270952439
Trained batch 57 in epoch 12, gen_loss = 0.09786003211448932, disc_loss = 0.0008780656804948853
Trained batch 58 in epoch 12, gen_loss = 0.09844493714429564, disc_loss = 0.0008744245135596306
Trained batch 59 in epoch 12, gen_loss = 0.09805397192637126, disc_loss = 0.0008727074906346388
Trained batch 60 in epoch 12, gen_loss = 0.09866750191469661, disc_loss = 0.0008680410716552898
Trained batch 61 in epoch 12, gen_loss = 0.09848843947533638, disc_loss = 0.0008622312757764912
Trained batch 62 in epoch 12, gen_loss = 0.09864699414798192, disc_loss = 0.0008829181781962573
Trained batch 63 in epoch 12, gen_loss = 0.09801246272400022, disc_loss = 0.0009048798315234308
Trained batch 64 in epoch 12, gen_loss = 0.09888726060207073, disc_loss = 0.0009030469411160224
Trained batch 65 in epoch 12, gen_loss = 0.09949075588674257, disc_loss = 0.0009022525420842805
Trained batch 66 in epoch 12, gen_loss = 0.09921137921845735, disc_loss = 0.0008981674410048317
Trained batch 67 in epoch 12, gen_loss = 0.09886076827259625, disc_loss = 0.0008958912611192585
Trained batch 68 in epoch 12, gen_loss = 0.09821340052977852, disc_loss = 0.0008928058749112045
Trained batch 69 in epoch 12, gen_loss = 0.09856003267424447, disc_loss = 0.0008902687026420608
Trained batch 70 in epoch 12, gen_loss = 0.09869041241390604, disc_loss = 0.0008853033039895949
Trained batch 71 in epoch 12, gen_loss = 0.09841662479771508, disc_loss = 0.0008808927325137322
Trained batch 72 in epoch 12, gen_loss = 0.09885274996496227, disc_loss = 0.000876024108274827
Trained batch 73 in epoch 12, gen_loss = 0.09841600181283178, disc_loss = 0.0008742724292804613
Trained batch 74 in epoch 12, gen_loss = 0.0985532828172048, disc_loss = 0.000868710617069155
Trained batch 75 in epoch 12, gen_loss = 0.09828492959863261, disc_loss = 0.00086887786701003
Trained batch 76 in epoch 12, gen_loss = 0.09832906761726776, disc_loss = 0.00086576710288812
Trained batch 77 in epoch 12, gen_loss = 0.09870734466956212, disc_loss = 0.0008645265203458854
Trained batch 78 in epoch 12, gen_loss = 0.09855996242052392, disc_loss = 0.0008619911195061912
Trained batch 79 in epoch 12, gen_loss = 0.09856828488409519, disc_loss = 0.0008609152326243929
Trained batch 80 in epoch 12, gen_loss = 0.0984835860169964, disc_loss = 0.0008592936540896326
Trained batch 81 in epoch 12, gen_loss = 0.09796734335945874, disc_loss = 0.0008601876183004096
Trained batch 82 in epoch 12, gen_loss = 0.09784057844116027, disc_loss = 0.0008576136848227266
Trained batch 83 in epoch 12, gen_loss = 0.09802503741922833, disc_loss = 0.000854272407845461
Trained batch 84 in epoch 12, gen_loss = 0.09822081011884352, disc_loss = 0.0008507141699630986
Trained batch 85 in epoch 12, gen_loss = 0.09919159183668536, disc_loss = 0.0008525523501935654
Trained batch 86 in epoch 12, gen_loss = 0.09926660067733677, disc_loss = 0.0008501992179562563
Trained batch 87 in epoch 12, gen_loss = 0.0999438887970014, disc_loss = 0.0008480993869439276
Trained batch 88 in epoch 12, gen_loss = 0.0994532469953044, disc_loss = 0.0008481015880288703
Trained batch 89 in epoch 12, gen_loss = 0.09927400218115913, disc_loss = 0.0008520855348453754
Trained batch 90 in epoch 12, gen_loss = 0.09944680365887316, disc_loss = 0.0008609318878030876
Trained batch 91 in epoch 12, gen_loss = 0.09896945305492567, disc_loss = 0.0008656491333132852
Trained batch 92 in epoch 12, gen_loss = 0.0989746368059548, disc_loss = 0.0008654933183714346
Trained batch 93 in epoch 12, gen_loss = 0.09884563437167634, disc_loss = 0.0008637737420863135
Trained batch 94 in epoch 12, gen_loss = 0.09831111211525767, disc_loss = 0.0008610972129788838
Trained batch 95 in epoch 12, gen_loss = 0.09815405402332544, disc_loss = 0.0008573239895971104
Trained batch 96 in epoch 12, gen_loss = 0.09865536210463219, disc_loss = 0.0008543788019769354
Trained batch 97 in epoch 12, gen_loss = 0.09850808704385952, disc_loss = 0.0008521974021426345
Trained batch 98 in epoch 12, gen_loss = 0.09856959033494044, disc_loss = 0.0008549815310739131
Trained batch 99 in epoch 12, gen_loss = 0.0983884060382843, disc_loss = 0.000858892805990763
Trained batch 100 in epoch 12, gen_loss = 0.0987259297087641, disc_loss = 0.0008604874549719441
Trained batch 101 in epoch 12, gen_loss = 0.09886469677382824, disc_loss = 0.0008583314780730242
Trained batch 102 in epoch 12, gen_loss = 0.09843116882935311, disc_loss = 0.0008557526738319582
Trained batch 103 in epoch 12, gen_loss = 0.09793615054625732, disc_loss = 0.0008517228967460911
Trained batch 104 in epoch 12, gen_loss = 0.09799000507309323, disc_loss = 0.0008481005342522015
Trained batch 105 in epoch 12, gen_loss = 0.09804213524989362, disc_loss = 0.0008453661084443085
Trained batch 106 in epoch 12, gen_loss = 0.09789339849882037, disc_loss = 0.0008414280598125829
Trained batch 107 in epoch 12, gen_loss = 0.09763832693850552, disc_loss = 0.000836886742844298
Trained batch 108 in epoch 12, gen_loss = 0.09752537815942677, disc_loss = 0.00083414047722568
Trained batch 109 in epoch 12, gen_loss = 0.0973926695910367, disc_loss = 0.00083462817419786
Trained batch 110 in epoch 12, gen_loss = 0.09750625571689091, disc_loss = 0.000844381347682478
Trained batch 111 in epoch 12, gen_loss = 0.09762124451143402, disc_loss = 0.0008509723938914249
Trained batch 112 in epoch 12, gen_loss = 0.09738975341341137, disc_loss = 0.0008481792357144466
Trained batch 113 in epoch 12, gen_loss = 0.09769803860731292, disc_loss = 0.0008491665978094955
Trained batch 114 in epoch 12, gen_loss = 0.09781955325085184, disc_loss = 0.0008522898836931942
Trained batch 115 in epoch 12, gen_loss = 0.09786119312047958, disc_loss = 0.0008580621524115799
Trained batch 116 in epoch 12, gen_loss = 0.09815333643530169, disc_loss = 0.000857486649024356
Trained batch 117 in epoch 12, gen_loss = 0.09805129544209626, disc_loss = 0.0008586991933012633
Trained batch 118 in epoch 12, gen_loss = 0.09817741172654289, disc_loss = 0.000861804375469982
Trained batch 119 in epoch 12, gen_loss = 0.09796680385867755, disc_loss = 0.0008623740322946105
Trained batch 120 in epoch 12, gen_loss = 0.09812521170978704, disc_loss = 0.0008637000186549699
Trained batch 121 in epoch 12, gen_loss = 0.09802601229949076, disc_loss = 0.0008649920906821937
Trained batch 122 in epoch 12, gen_loss = 0.09833089801354136, disc_loss = 0.0008657701662268368
Trained batch 123 in epoch 12, gen_loss = 0.09855247072635158, disc_loss = 0.0008648112512497803
Trained batch 124 in epoch 12, gen_loss = 0.09833043503761292, disc_loss = 0.0008631242767442018
Trained batch 125 in epoch 12, gen_loss = 0.09814672077459002, disc_loss = 0.0008602140673218177
Trained batch 126 in epoch 12, gen_loss = 0.09787517504429254, disc_loss = 0.0008581923584428095
Trained batch 127 in epoch 12, gen_loss = 0.09793670196086168, disc_loss = 0.0008569640078803786
Trained batch 128 in epoch 12, gen_loss = 0.09803644723670427, disc_loss = 0.0008561310338942955
Trained batch 129 in epoch 12, gen_loss = 0.09791818811343267, disc_loss = 0.0008555404548622811
Trained batch 130 in epoch 12, gen_loss = 0.09788253107143723, disc_loss = 0.0008534211409900281
Trained batch 131 in epoch 12, gen_loss = 0.0974821461872621, disc_loss = 0.0008518436562471007
Trained batch 132 in epoch 12, gen_loss = 0.09744306524893395, disc_loss = 0.0008498912121788983
Trained batch 133 in epoch 12, gen_loss = 0.09729813061543365, disc_loss = 0.000846681769098044
Trained batch 134 in epoch 12, gen_loss = 0.09730247833110668, disc_loss = 0.0008435002079716436
Trained batch 135 in epoch 12, gen_loss = 0.09740244356148384, disc_loss = 0.0008409636262941229
Trained batch 136 in epoch 12, gen_loss = 0.09769939136331099, disc_loss = 0.0008389089429873402
Trained batch 137 in epoch 12, gen_loss = 0.09737890526868295, disc_loss = 0.0008362266741207112
Trained batch 138 in epoch 12, gen_loss = 0.09753393140628183, disc_loss = 0.0008352489466946438
Trained batch 139 in epoch 12, gen_loss = 0.09777486281735556, disc_loss = 0.0008345847304943683
Trained batch 140 in epoch 12, gen_loss = 0.097701444059399, disc_loss = 0.0008328260910855804
Trained batch 141 in epoch 12, gen_loss = 0.09748910514401718, disc_loss = 0.0008360702961742301
Trained batch 142 in epoch 12, gen_loss = 0.09745326242246828, disc_loss = 0.000834856229147164
Trained batch 143 in epoch 12, gen_loss = 0.09799311558405559, disc_loss = 0.000834239060673604
Trained batch 144 in epoch 12, gen_loss = 0.09784292496483901, disc_loss = 0.0008338466114043418
Trained batch 145 in epoch 12, gen_loss = 0.09791682905530276, disc_loss = 0.0008313618530599044
Trained batch 146 in epoch 12, gen_loss = 0.09758510435519575, disc_loss = 0.0008298163430933163
Trained batch 147 in epoch 12, gen_loss = 0.09743187858446224, disc_loss = 0.0008272063449210789
Trained batch 148 in epoch 12, gen_loss = 0.0976572926812524, disc_loss = 0.0008246021135475787
Testing Epoch 12
Training Epoch 13
Trained batch 0 in epoch 13, gen_loss = 0.10619926452636719, disc_loss = 0.0004792135441675782
Trained batch 1 in epoch 13, gen_loss = 0.10188692808151245, disc_loss = 0.000582685723202303
Trained batch 2 in epoch 13, gen_loss = 0.10788798332214355, disc_loss = 0.0005830376176163554
Trained batch 3 in epoch 13, gen_loss = 0.09739366918802261, disc_loss = 0.0006381844432326034
Trained batch 4 in epoch 13, gen_loss = 0.09907343983650208, disc_loss = 0.0006999423028901219
Trained batch 5 in epoch 13, gen_loss = 0.10377211372057597, disc_loss = 0.0006807567163680991
Trained batch 6 in epoch 13, gen_loss = 0.10391594682421003, disc_loss = 0.0006565249641425908
Trained batch 7 in epoch 13, gen_loss = 0.10065099596977234, disc_loss = 0.0006591459896299057
Trained batch 8 in epoch 13, gen_loss = 0.0947760542233785, disc_loss = 0.0006846257278488742
Trained batch 9 in epoch 13, gen_loss = 0.09438489973545075, disc_loss = 0.0006797984009608626
Trained batch 10 in epoch 13, gen_loss = 0.09633216532793912, disc_loss = 0.0006676241755485535
Trained batch 11 in epoch 13, gen_loss = 0.0983104258775711, disc_loss = 0.0006456910074727299
Trained batch 12 in epoch 13, gen_loss = 0.09588304391274086, disc_loss = 0.0006277127272019592
Trained batch 13 in epoch 13, gen_loss = 0.09304391060556684, disc_loss = 0.00062041831136282
Trained batch 14 in epoch 13, gen_loss = 0.09067117770512899, disc_loss = 0.0006285223256175717
Trained batch 15 in epoch 13, gen_loss = 0.08852742239832878, disc_loss = 0.0006369180882757064
Trained batch 16 in epoch 13, gen_loss = 0.08822262988371007, disc_loss = 0.0006320826976340922
Trained batch 17 in epoch 13, gen_loss = 0.09134145577748616, disc_loss = 0.0006297007041414165
Trained batch 18 in epoch 13, gen_loss = 0.09250167482777645, disc_loss = 0.0006277859057789962
Trained batch 19 in epoch 13, gen_loss = 0.09350235760211945, disc_loss = 0.0006209186336491257
Trained batch 20 in epoch 13, gen_loss = 0.09591753993715559, disc_loss = 0.0006125057531919863
Trained batch 21 in epoch 13, gen_loss = 0.09585672210563313, disc_loss = 0.0006040906869615851
Trained batch 22 in epoch 13, gen_loss = 0.09559566041697627, disc_loss = 0.0005983527301830928
Trained batch 23 in epoch 13, gen_loss = 0.09435361499587695, disc_loss = 0.0005951729387258334
Trained batch 24 in epoch 13, gen_loss = 0.09508280634880066, disc_loss = 0.0005866846593562513
Trained batch 25 in epoch 13, gen_loss = 0.09824617207050323, disc_loss = 0.0005820041238061654
Trained batch 26 in epoch 13, gen_loss = 0.09696149274154946, disc_loss = 0.0005843745020683855
Trained batch 27 in epoch 13, gen_loss = 0.09837861252682549, disc_loss = 0.0005936185157874466
Trained batch 28 in epoch 13, gen_loss = 0.09716978360866678, disc_loss = 0.0006021919875036411
Trained batch 29 in epoch 13, gen_loss = 0.0985897829135259, disc_loss = 0.0006059828146438424
Trained batch 30 in epoch 13, gen_loss = 0.09797963692295936, disc_loss = 0.0005989909639597059
Trained batch 31 in epoch 13, gen_loss = 0.09719131700694561, disc_loss = 0.000596065475292562
Trained batch 32 in epoch 13, gen_loss = 0.09595183531443278, disc_loss = 0.0005911504038412011
Trained batch 33 in epoch 13, gen_loss = 0.09502426841679741, disc_loss = 0.0005955322395654066
Trained batch 34 in epoch 13, gen_loss = 0.09537498610360282, disc_loss = 0.0005926607542538217
Trained batch 35 in epoch 13, gen_loss = 0.09576395153999329, disc_loss = 0.0005897813728855302
Trained batch 36 in epoch 13, gen_loss = 0.09606282131091969, disc_loss = 0.0005941454453293134
Trained batch 37 in epoch 13, gen_loss = 0.09598218767266524, disc_loss = 0.0006056165561619166
Trained batch 38 in epoch 13, gen_loss = 0.09508810135034415, disc_loss = 0.0006236148019058582
Trained batch 39 in epoch 13, gen_loss = 0.0946686752140522, disc_loss = 0.0006288553078775295
Trained batch 40 in epoch 13, gen_loss = 0.09517752179285376, disc_loss = 0.0006385995117697592
Trained batch 41 in epoch 13, gen_loss = 0.0949329442921139, disc_loss = 0.0006462110669374288
Trained batch 42 in epoch 13, gen_loss = 0.09464795436970024, disc_loss = 0.000642847441689133
Trained batch 43 in epoch 13, gen_loss = 0.09399301287802783, disc_loss = 0.0006436431550272656
Trained batch 44 in epoch 13, gen_loss = 0.09494550095664131, disc_loss = 0.0006414000811572704
Trained batch 45 in epoch 13, gen_loss = 0.09479143049405969, disc_loss = 0.0006401236738462973
Trained batch 46 in epoch 13, gen_loss = 0.09435842962975198, disc_loss = 0.0006370750278175036
Trained batch 47 in epoch 13, gen_loss = 0.0940676045914491, disc_loss = 0.0006312935984169599
Trained batch 48 in epoch 13, gen_loss = 0.09436651273649566, disc_loss = 0.0006285501199736431
Trained batch 49 in epoch 13, gen_loss = 0.09492701292037964, disc_loss = 0.0006286235793959349
Trained batch 50 in epoch 13, gen_loss = 0.09432266389622408, disc_loss = 0.0006301480028139171
Trained batch 51 in epoch 13, gen_loss = 0.09471958589095336, disc_loss = 0.0006321244973850509
Trained batch 52 in epoch 13, gen_loss = 0.09503957291819015, disc_loss = 0.0006315095277661282
Trained batch 53 in epoch 13, gen_loss = 0.0946088273216177, disc_loss = 0.0006283557288245194
Trained batch 54 in epoch 13, gen_loss = 0.09492091373963789, disc_loss = 0.00062375004847788
Trained batch 55 in epoch 13, gen_loss = 0.0944136870758874, disc_loss = 0.0006192038028010367
Trained batch 56 in epoch 13, gen_loss = 0.0945601546973513, disc_loss = 0.0006164318224284471
Trained batch 57 in epoch 13, gen_loss = 0.09474029366312356, disc_loss = 0.0006158679055355104
Trained batch 58 in epoch 13, gen_loss = 0.09463257506742316, disc_loss = 0.0006130249742655304
Trained batch 59 in epoch 13, gen_loss = 0.09425760805606842, disc_loss = 0.0006164649656663338
Trained batch 60 in epoch 13, gen_loss = 0.0943331889441756, disc_loss = 0.0006215190085521365
Trained batch 61 in epoch 13, gen_loss = 0.0944377621335368, disc_loss = 0.0006242691221902328
Trained batch 62 in epoch 13, gen_loss = 0.0941632990799253, disc_loss = 0.0006224326891011544
Trained batch 63 in epoch 13, gen_loss = 0.09409151878207922, disc_loss = 0.0006206582156664808
Trained batch 64 in epoch 13, gen_loss = 0.09355570673942566, disc_loss = 0.0006174511504538644
Trained batch 65 in epoch 13, gen_loss = 0.09363467584956776, disc_loss = 0.0006130778576444948
Trained batch 66 in epoch 13, gen_loss = 0.09354411176781156, disc_loss = 0.0006095280257442882
Trained batch 67 in epoch 13, gen_loss = 0.09302556207951378, disc_loss = 0.0006083013756912859
Trained batch 68 in epoch 13, gen_loss = 0.09241853805555814, disc_loss = 0.0006070429125152853
Trained batch 69 in epoch 13, gen_loss = 0.09184005643640246, disc_loss = 0.0006053739634808153
Trained batch 70 in epoch 13, gen_loss = 0.09151543404015017, disc_loss = 0.0006035134146272034
Trained batch 71 in epoch 13, gen_loss = 0.09086280481682883, disc_loss = 0.0006024217028526538
Trained batch 72 in epoch 13, gen_loss = 0.09023348762564463, disc_loss = 0.000601366453737097
Trained batch 73 in epoch 13, gen_loss = 0.0897324487969682, disc_loss = 0.0005989780061960069
Trained batch 74 in epoch 13, gen_loss = 0.08974876046180726, disc_loss = 0.0005987428474084784
Trained batch 75 in epoch 13, gen_loss = 0.08967276741015284, disc_loss = 0.0005988598143295875
Trained batch 76 in epoch 13, gen_loss = 0.08983914070315176, disc_loss = 0.0006014151765523454
Trained batch 77 in epoch 13, gen_loss = 0.090221412670918, disc_loss = 0.0006067850377010659
Trained batch 78 in epoch 13, gen_loss = 0.08972506696664834, disc_loss = 0.0006104273006137271
Trained batch 79 in epoch 13, gen_loss = 0.08965235985815526, disc_loss = 0.0006145080787973711
Trained batch 80 in epoch 13, gen_loss = 0.0896455932546545, disc_loss = 0.0006145575880734135
Trained batch 81 in epoch 13, gen_loss = 0.08949511443696372, disc_loss = 0.0006144663035761701
Trained batch 82 in epoch 13, gen_loss = 0.089505127395492, disc_loss = 0.000615141971993361
Trained batch 83 in epoch 13, gen_loss = 0.08957149123861677, disc_loss = 0.0006138253128959886
Trained batch 84 in epoch 13, gen_loss = 0.0889444417813245, disc_loss = 0.0006197228414855678
Trained batch 85 in epoch 13, gen_loss = 0.08860583638035974, disc_loss = 0.0006187229953993242
Trained batch 86 in epoch 13, gen_loss = 0.08804315362853565, disc_loss = 0.0006188806725114627
Trained batch 87 in epoch 13, gen_loss = 0.0883425006812269, disc_loss = 0.0006201526031707709
Trained batch 88 in epoch 13, gen_loss = 0.0879982602730226, disc_loss = 0.0006244288671766983
Trained batch 89 in epoch 13, gen_loss = 0.08778898384835986, disc_loss = 0.0006264403491513804
Trained batch 90 in epoch 13, gen_loss = 0.08746611908241943, disc_loss = 0.0006244474504485849
Trained batch 91 in epoch 13, gen_loss = 0.0870448399497115, disc_loss = 0.0006214265509776811
Trained batch 92 in epoch 13, gen_loss = 0.08719477762458144, disc_loss = 0.0006190962568100702
Trained batch 93 in epoch 13, gen_loss = 0.08688673250218655, disc_loss = 0.0006167728551712997
Trained batch 94 in epoch 13, gen_loss = 0.08655948638916015, disc_loss = 0.0006137953237875512
Trained batch 95 in epoch 13, gen_loss = 0.08652229762325685, disc_loss = 0.0006135952353361063
Trained batch 96 in epoch 13, gen_loss = 0.08625268045159959, disc_loss = 0.0006403683771177666
Trained batch 97 in epoch 13, gen_loss = 0.08562312594481877, disc_loss = 0.0006584485337062149
Trained batch 98 in epoch 13, gen_loss = 0.08555700953560647, disc_loss = 0.0006676723644363158
Trained batch 99 in epoch 13, gen_loss = 0.08525288969278336, disc_loss = 0.0006723000749479979
Trained batch 100 in epoch 13, gen_loss = 0.08595651535704585, disc_loss = 0.0006903353144903436
Trained batch 101 in epoch 13, gen_loss = 0.08625441818845038, disc_loss = 0.0006943730667105638
Trained batch 102 in epoch 13, gen_loss = 0.08608568206574153, disc_loss = 0.0006937262092409565
Trained batch 103 in epoch 13, gen_loss = 0.0864160367502616, disc_loss = 0.0006956151885858092
Trained batch 104 in epoch 13, gen_loss = 0.08643850230035327, disc_loss = 0.0006989003901946403
Trained batch 105 in epoch 13, gen_loss = 0.08646503737512624, disc_loss = 0.0007005263875537323
Trained batch 106 in epoch 13, gen_loss = 0.08665325151425655, disc_loss = 0.0006990875362279329
Trained batch 107 in epoch 13, gen_loss = 0.0865734225070035, disc_loss = 0.0006990761989813849
Trained batch 108 in epoch 13, gen_loss = 0.08629906560302875, disc_loss = 0.0006971490642038781
Trained batch 109 in epoch 13, gen_loss = 0.08642627380111001, disc_loss = 0.0006987508894367652
Trained batch 110 in epoch 13, gen_loss = 0.08598877717782785, disc_loss = 0.0007038921419833157
Trained batch 111 in epoch 13, gen_loss = 0.08576117056821074, disc_loss = 0.0007030047023103439
Trained batch 112 in epoch 13, gen_loss = 0.08559401214650247, disc_loss = 0.0007016789477186657
Trained batch 113 in epoch 13, gen_loss = 0.08529051510911238, disc_loss = 0.00070196366409379
Trained batch 114 in epoch 13, gen_loss = 0.08530563427054363, disc_loss = 0.0007006418481266693
Trained batch 115 in epoch 13, gen_loss = 0.08543198735549531, disc_loss = 0.0006976457857647268
Trained batch 116 in epoch 13, gen_loss = 0.08505416043803223, disc_loss = 0.0006946567162417639
Trained batch 117 in epoch 13, gen_loss = 0.08500371747097726, disc_loss = 0.0006927677592503349
Trained batch 118 in epoch 13, gen_loss = 0.08534883601324898, disc_loss = 0.0006914833179545909
Trained batch 119 in epoch 13, gen_loss = 0.08541946982343991, disc_loss = 0.0006894960448941371
Trained batch 120 in epoch 13, gen_loss = 0.085607970056455, disc_loss = 0.0006871531320127758
Trained batch 121 in epoch 13, gen_loss = 0.0857518129661435, disc_loss = 0.000685275036585899
Trained batch 122 in epoch 13, gen_loss = 0.08553841613172515, disc_loss = 0.0006826774186901445
Trained batch 123 in epoch 13, gen_loss = 0.08519310215788503, disc_loss = 0.0006806566825910141
Trained batch 124 in epoch 13, gen_loss = 0.08540800499916076, disc_loss = 0.0006809636331163347
Trained batch 125 in epoch 13, gen_loss = 0.08531370475178673, disc_loss = 0.0006828697445425426
Trained batch 126 in epoch 13, gen_loss = 0.0850184822645713, disc_loss = 0.0006905209376682036
Trained batch 127 in epoch 13, gen_loss = 0.08529411652125418, disc_loss = 0.0007064534242999798
Trained batch 128 in epoch 13, gen_loss = 0.08530542000319606, disc_loss = 0.0007184576861336538
Trained batch 129 in epoch 13, gen_loss = 0.08497962126365075, disc_loss = 0.0007233296283699859
Trained batch 130 in epoch 13, gen_loss = 0.08463127785966597, disc_loss = 0.0007250363523503125
Trained batch 131 in epoch 13, gen_loss = 0.08475503009377104, disc_loss = 0.0007298514657040042
Trained batch 132 in epoch 13, gen_loss = 0.08471238075342394, disc_loss = 0.0007292166189465643
Trained batch 133 in epoch 13, gen_loss = 0.08470924131905855, disc_loss = 0.0007295764638667009
Trained batch 134 in epoch 13, gen_loss = 0.08457732288925736, disc_loss = 0.00073049853262664
Trained batch 135 in epoch 13, gen_loss = 0.08454683510696187, disc_loss = 0.0007310188405373244
Trained batch 136 in epoch 13, gen_loss = 0.0845019756442439, disc_loss = 0.0007311056328114856
Trained batch 137 in epoch 13, gen_loss = 0.08440997591917065, disc_loss = 0.0007313766455163072
Trained batch 138 in epoch 13, gen_loss = 0.0846359275227828, disc_loss = 0.0007309439887708093
Trained batch 139 in epoch 13, gen_loss = 0.0844143773828234, disc_loss = 0.0007321555150805839
Trained batch 140 in epoch 13, gen_loss = 0.08407372341933825, disc_loss = 0.0007346630202117541
Trained batch 141 in epoch 13, gen_loss = 0.08402187114870044, disc_loss = 0.000736533163253113
Trained batch 142 in epoch 13, gen_loss = 0.08403561853028678, disc_loss = 0.0007353215282978295
Trained batch 143 in epoch 13, gen_loss = 0.08413445225192441, disc_loss = 0.0007337096103583463
Trained batch 144 in epoch 13, gen_loss = 0.08405436996755929, disc_loss = 0.0007346271340542569
Trained batch 145 in epoch 13, gen_loss = 0.08384308586381886, disc_loss = 0.0007327836427888641
Trained batch 146 in epoch 13, gen_loss = 0.08369447949792252, disc_loss = 0.0007329869716029082
Trained batch 147 in epoch 13, gen_loss = 0.08353421273263725, disc_loss = 0.0007306942106633623
Trained batch 148 in epoch 13, gen_loss = 0.083525050406488, disc_loss = 0.0007295331620023705
Testing Epoch 13
Training Epoch 14
Trained batch 0 in epoch 14, gen_loss = 0.044655293226242065, disc_loss = 0.0006439383723773062
Trained batch 1 in epoch 14, gen_loss = 0.07985721528530121, disc_loss = 0.0006766434526070952
Trained batch 2 in epoch 14, gen_loss = 0.09303965171178182, disc_loss = 0.0006390031388339897
Trained batch 3 in epoch 14, gen_loss = 0.09201394766569138, disc_loss = 0.0006431242363760248
Trained batch 4 in epoch 14, gen_loss = 0.08598984479904175, disc_loss = 0.0007088821497745812
Trained batch 5 in epoch 14, gen_loss = 0.08363304535547893, disc_loss = 0.0007323694687026242
Trained batch 6 in epoch 14, gen_loss = 0.08101270028523036, disc_loss = 0.0007256036208543394
Trained batch 7 in epoch 14, gen_loss = 0.0842033214867115, disc_loss = 0.0006882854977448005
Trained batch 8 in epoch 14, gen_loss = 0.08045865760909186, disc_loss = 0.0007319301011092546
Trained batch 9 in epoch 14, gen_loss = 0.07703371047973633, disc_loss = 0.0007364306628005579
Trained batch 10 in epoch 14, gen_loss = 0.0772986737164584, disc_loss = 0.0007140479944858023
Trained batch 11 in epoch 14, gen_loss = 0.07757067183653514, disc_loss = 0.0007021047179781211
Trained batch 12 in epoch 14, gen_loss = 0.079827952843446, disc_loss = 0.0008113039053009393
Trained batch 13 in epoch 14, gen_loss = 0.07760325074195862, disc_loss = 0.000841347111937856
Trained batch 14 in epoch 14, gen_loss = 0.07637282411257426, disc_loss = 0.0008548604343862583
Trained batch 15 in epoch 14, gen_loss = 0.07493510097265244, disc_loss = 0.0008403838528465712
Trained batch 16 in epoch 14, gen_loss = 0.07580063448232763, disc_loss = 0.0008484654981122516
Trained batch 17 in epoch 14, gen_loss = 0.07586121890279982, disc_loss = 0.0008502802989419757
Trained batch 18 in epoch 14, gen_loss = 0.07631857144205194, disc_loss = 0.0008457008531733759
Trained batch 19 in epoch 14, gen_loss = 0.07429120987653733, disc_loss = 0.000844929066079203
Trained batch 20 in epoch 14, gen_loss = 0.07592052079382397, disc_loss = 0.000884378452264216
Trained batch 21 in epoch 14, gen_loss = 0.07410385391928932, disc_loss = 0.000902543274357661
Trained batch 22 in epoch 14, gen_loss = 0.07549918475358383, disc_loss = 0.0008919667110920115
Trained batch 23 in epoch 14, gen_loss = 0.07683691382408142, disc_loss = 0.000886059115146054
Trained batch 24 in epoch 14, gen_loss = 0.07830203890800476, disc_loss = 0.0008743173244874924
Trained batch 25 in epoch 14, gen_loss = 0.07588332432966965, disc_loss = 0.0008721610546882192
Trained batch 26 in epoch 14, gen_loss = 0.07451745315834328, disc_loss = 0.0008772332339840768
Trained batch 27 in epoch 14, gen_loss = 0.07431071464504514, disc_loss = 0.0008693946635633308
Trained batch 28 in epoch 14, gen_loss = 0.07389251733648367, disc_loss = 0.0008656956658875249
Trained batch 29 in epoch 14, gen_loss = 0.07399367392063141, disc_loss = 0.0008569247758714483
Trained batch 30 in epoch 14, gen_loss = 0.07463933287128326, disc_loss = 0.0008480705352755444
Trained batch 31 in epoch 14, gen_loss = 0.07467321958392859, disc_loss = 0.0008401543100262643
Trained batch 32 in epoch 14, gen_loss = 0.07566072543462117, disc_loss = 0.0008451021285233737
Trained batch 33 in epoch 14, gen_loss = 0.07582106660394107, disc_loss = 0.000848793370738242
Trained batch 34 in epoch 14, gen_loss = 0.07499442185674395, disc_loss = 0.0008415726587242846
Trained batch 35 in epoch 14, gen_loss = 0.07535091290871303, disc_loss = 0.0008350766947842203
Trained batch 36 in epoch 14, gen_loss = 0.07570998813654925, disc_loss = 0.0008344412852091262
Trained batch 37 in epoch 14, gen_loss = 0.07506457833867324, disc_loss = 0.000826930542213009
Trained batch 38 in epoch 14, gen_loss = 0.0759009191623101, disc_loss = 0.000818054755188477
Trained batch 39 in epoch 14, gen_loss = 0.0752126581966877, disc_loss = 0.000816558795486344
Trained batch 40 in epoch 14, gen_loss = 0.07400501937401004, disc_loss = 0.0008126921694805255
Trained batch 41 in epoch 14, gen_loss = 0.07374188232989538, disc_loss = 0.0008050194030926962
Trained batch 42 in epoch 14, gen_loss = 0.07326933949492699, disc_loss = 0.0007979560116858243
Trained batch 43 in epoch 14, gen_loss = 0.07275898145003752, disc_loss = 0.0007907417047218504
Trained batch 44 in epoch 14, gen_loss = 0.07262963387701246, disc_loss = 0.0007805596998271843
Trained batch 45 in epoch 14, gen_loss = 0.07182585998721745, disc_loss = 0.0007723162372080285
Trained batch 46 in epoch 14, gen_loss = 0.07187663430863238, disc_loss = 0.0007691690308150855
Trained batch 47 in epoch 14, gen_loss = 0.07155991656084855, disc_loss = 0.0007812960302544525
Trained batch 48 in epoch 14, gen_loss = 0.07151483333840662, disc_loss = 0.0007934418788455351
Trained batch 49 in epoch 14, gen_loss = 0.07069887280464172, disc_loss = 0.0008086704026209191
Trained batch 50 in epoch 14, gen_loss = 0.07069859960499932, disc_loss = 0.0008026261787688104
Trained batch 51 in epoch 14, gen_loss = 0.07173953434595695, disc_loss = 0.0008059098892352687
Trained batch 52 in epoch 14, gen_loss = 0.07136141466644574, disc_loss = 0.0008033688211998076
Trained batch 53 in epoch 14, gen_loss = 0.07164658606052399, disc_loss = 0.0008159484439400128
Trained batch 54 in epoch 14, gen_loss = 0.07194969058036804, disc_loss = 0.0008314236432356252
Trained batch 55 in epoch 14, gen_loss = 0.07274867221713066, disc_loss = 0.0008420297677470703
Trained batch 56 in epoch 14, gen_loss = 0.0718830264451211, disc_loss = 0.0008406305380304458
Trained batch 57 in epoch 14, gen_loss = 0.07181661550340981, disc_loss = 0.0008344933599362086
Trained batch 58 in epoch 14, gen_loss = 0.07099967235225742, disc_loss = 0.0008269463931170877
Trained batch 59 in epoch 14, gen_loss = 0.0712238813440005, disc_loss = 0.000819611215168455
Trained batch 60 in epoch 14, gen_loss = 0.07160249450167672, disc_loss = 0.0008133679254316405
Trained batch 61 in epoch 14, gen_loss = 0.07205303782416929, disc_loss = 0.0008082257531162711
Trained batch 62 in epoch 14, gen_loss = 0.07172936106485034, disc_loss = 0.0008027154424723001
Trained batch 63 in epoch 14, gen_loss = 0.07228189101442695, disc_loss = 0.0007996824474503228
Trained batch 64 in epoch 14, gen_loss = 0.07147442744328425, disc_loss = 0.0007968839038557444
Trained batch 65 in epoch 14, gen_loss = 0.07139102753364679, disc_loss = 0.0007955555378099565
Trained batch 66 in epoch 14, gen_loss = 0.07159478184002549, disc_loss = 0.0007946505180886711
Trained batch 67 in epoch 14, gen_loss = 0.07172857794691534, disc_loss = 0.0007952627908226158
Trained batch 68 in epoch 14, gen_loss = 0.0717726475086765, disc_loss = 0.0007928195093130773
Trained batch 69 in epoch 14, gen_loss = 0.07152715623378754, disc_loss = 0.0007893972917892305
Trained batch 70 in epoch 14, gen_loss = 0.07058922547689626, disc_loss = 0.000787101647059079
Trained batch 71 in epoch 14, gen_loss = 0.07061074963874286, disc_loss = 0.0007869648595967899
Trained batch 72 in epoch 14, gen_loss = 0.07026774630154649, disc_loss = 0.0007849802603556022
Trained batch 73 in epoch 14, gen_loss = 0.07043375558144338, disc_loss = 0.0007863373057507733
Trained batch 74 in epoch 14, gen_loss = 0.06974295655886333, disc_loss = 0.0007915151456836611
Trained batch 75 in epoch 14, gen_loss = 0.0699351935794479, disc_loss = 0.0007987972406370222
Trained batch 76 in epoch 14, gen_loss = 0.06925028639954406, disc_loss = 0.00080238756468193
Trained batch 77 in epoch 14, gen_loss = 0.0694440687314058, disc_loss = 0.0008014141546878725
Trained batch 78 in epoch 14, gen_loss = 0.06946707299993007, disc_loss = 0.0007985144123417337
Trained batch 79 in epoch 14, gen_loss = 0.06945228204131126, disc_loss = 0.0007965013883222127
Trained batch 80 in epoch 14, gen_loss = 0.06928087973300322, disc_loss = 0.0007943303937259142
Trained batch 81 in epoch 14, gen_loss = 0.06851448918261178, disc_loss = 0.0007914225993217992
Trained batch 82 in epoch 14, gen_loss = 0.06786596954586994, disc_loss = 0.0007944694234209741
Trained batch 83 in epoch 14, gen_loss = 0.06794961612849008, disc_loss = 0.0008058588521505174
Trained batch 84 in epoch 14, gen_loss = 0.0674268694484935, disc_loss = 0.0008146483762710191
Trained batch 85 in epoch 14, gen_loss = 0.06716870603173278, disc_loss = 0.0008181495233953302
Trained batch 86 in epoch 14, gen_loss = 0.06728523729861467, disc_loss = 0.0008174595687318936
Trained batch 87 in epoch 14, gen_loss = 0.0665486261925914, disc_loss = 0.0008135241206962911
Trained batch 88 in epoch 14, gen_loss = 0.06615105974540282, disc_loss = 0.000809892684056455
Trained batch 89 in epoch 14, gen_loss = 0.06653208037217458, disc_loss = 0.0008066133663911994
Trained batch 90 in epoch 14, gen_loss = 0.06706637635335817, disc_loss = 0.0008075876979561584
Trained batch 91 in epoch 14, gen_loss = 0.06685726020647131, disc_loss = 0.0008044986585129822
Trained batch 92 in epoch 14, gen_loss = 0.06657678914326494, disc_loss = 0.0008005337086781579
Trained batch 93 in epoch 14, gen_loss = 0.06627235260415584, disc_loss = 0.0008010613150582549
Trained batch 94 in epoch 14, gen_loss = 0.06590842541895414, disc_loss = 0.0008040970905169256
Trained batch 95 in epoch 14, gen_loss = 0.06573060154914856, disc_loss = 0.0008019640702817318
Trained batch 96 in epoch 14, gen_loss = 0.06552438944885411, disc_loss = 0.0007977430806519252
Trained batch 97 in epoch 14, gen_loss = 0.06572074062970219, disc_loss = 0.0007933441550133522
Trained batch 98 in epoch 14, gen_loss = 0.06541276218915226, disc_loss = 0.0007891320823950486
Trained batch 99 in epoch 14, gen_loss = 0.06514226734638214, disc_loss = 0.000785608719161246
Trained batch 100 in epoch 14, gen_loss = 0.06482866731020484, disc_loss = 0.0007816586838827681
Trained batch 101 in epoch 14, gen_loss = 0.06443124775793038, disc_loss = 0.0007781966588820569
Trained batch 102 in epoch 14, gen_loss = 0.06477748769000896, disc_loss = 0.0007760891387379249
Trained batch 103 in epoch 14, gen_loss = 0.06470089749648021, disc_loss = 0.0007737361825442909
Trained batch 104 in epoch 14, gen_loss = 0.064364150592259, disc_loss = 0.0007797784435318872
Trained batch 105 in epoch 14, gen_loss = 0.06400816030097457, disc_loss = 0.000789790544691847
Trained batch 106 in epoch 14, gen_loss = 0.06407148147297796, disc_loss = 0.0007923946998225716
Trained batch 107 in epoch 14, gen_loss = 0.06427928446619599, disc_loss = 0.0007893955806610864
Trained batch 108 in epoch 14, gen_loss = 0.06438768429493685, disc_loss = 0.0007885244443752043
Trained batch 109 in epoch 14, gen_loss = 0.06414394243197008, disc_loss = 0.0007877715437313203
Trained batch 110 in epoch 14, gen_loss = 0.06405022955155587, disc_loss = 0.0007885780800574434
Trained batch 111 in epoch 14, gen_loss = 0.0641048571893147, disc_loss = 0.0008042354313926937
Trained batch 112 in epoch 14, gen_loss = 0.06373067872714153, disc_loss = 0.0008112942324477388
Trained batch 113 in epoch 14, gen_loss = 0.06334457010553594, disc_loss = 0.0008119532265067264
Trained batch 114 in epoch 14, gen_loss = 0.06342202891474184, disc_loss = 0.00081144497532438
Trained batch 115 in epoch 14, gen_loss = 0.0633219418854549, disc_loss = 0.0008086768053732973
Trained batch 116 in epoch 14, gen_loss = 0.06283266778685088, disc_loss = 0.0008065526925413432
Trained batch 117 in epoch 14, gen_loss = 0.062491601806575967, disc_loss = 0.0008080659497833132
Trained batch 118 in epoch 14, gen_loss = 0.06234200361396084, disc_loss = 0.0008065303087629722
Trained batch 119 in epoch 14, gen_loss = 0.0625025970240434, disc_loss = 0.0008037999124402025
Trained batch 120 in epoch 14, gen_loss = 0.062384688410877194, disc_loss = 0.0008011212750926829
Trained batch 121 in epoch 14, gen_loss = 0.0622115504057681, disc_loss = 0.0007984703146665525
Trained batch 122 in epoch 14, gen_loss = 0.06210423121607401, disc_loss = 0.0007963244198931275
Trained batch 123 in epoch 14, gen_loss = 0.062349448521291054, disc_loss = 0.0007938224730277134
Trained batch 124 in epoch 14, gen_loss = 0.06194926333427429, disc_loss = 0.0007908527161926031
Trained batch 125 in epoch 14, gen_loss = 0.061999082801833985, disc_loss = 0.0007885978104443186
Trained batch 126 in epoch 14, gen_loss = 0.06192347712404146, disc_loss = 0.0007859891792484303
Trained batch 127 in epoch 14, gen_loss = 0.06202125642448664, disc_loss = 0.0007836103525278304
Trained batch 128 in epoch 14, gen_loss = 0.062053107707075374, disc_loss = 0.0007811407811304396
Trained batch 129 in epoch 14, gen_loss = 0.06202378662732931, disc_loss = 0.0007784350477427674
Trained batch 130 in epoch 14, gen_loss = 0.062162018686760474, disc_loss = 0.0007759403128120053
Trained batch 131 in epoch 14, gen_loss = 0.0617859781239972, disc_loss = 0.0007736863317955849
Trained batch 132 in epoch 14, gen_loss = 0.06176513276602093, disc_loss = 0.0007711293683930027
Trained batch 133 in epoch 14, gen_loss = 0.06172388858759581, disc_loss = 0.000768353297495033
Trained batch 134 in epoch 14, gen_loss = 0.06167949151109766, disc_loss = 0.0007659409007626689
Trained batch 135 in epoch 14, gen_loss = 0.06169839992242701, disc_loss = 0.0007652494072424495
Trained batch 136 in epoch 14, gen_loss = 0.061471519243978236, disc_loss = 0.0007632428146711803
Trained batch 137 in epoch 14, gen_loss = 0.06153988147127456, disc_loss = 0.0007601231313394923
Trained batch 138 in epoch 14, gen_loss = 0.061290381838091844, disc_loss = 0.0007586993451695889
Trained batch 139 in epoch 14, gen_loss = 0.061307290196418764, disc_loss = 0.0007563724236596109
Trained batch 140 in epoch 14, gen_loss = 0.06134236323918011, disc_loss = 0.0007539587243995133
Trained batch 141 in epoch 14, gen_loss = 0.0612420336881154, disc_loss = 0.0007525459005707271
Trained batch 142 in epoch 14, gen_loss = 0.06082551275099908, disc_loss = 0.0007507202990509413
Trained batch 143 in epoch 14, gen_loss = 0.06088360212743282, disc_loss = 0.0007485591817789504
Trained batch 144 in epoch 14, gen_loss = 0.06075093972271886, disc_loss = 0.0007547155086850297
Trained batch 145 in epoch 14, gen_loss = 0.0604266346725699, disc_loss = 0.0007599060996180426
Trained batch 146 in epoch 14, gen_loss = 0.06005992350124177, disc_loss = 0.0007606371532378047
Trained batch 147 in epoch 14, gen_loss = 0.06016142565656353, disc_loss = 0.000762250489158858
Trained batch 148 in epoch 14, gen_loss = 0.06000338824803397, disc_loss = 0.0007615557335779671
Testing Epoch 14

wandb: WARNING Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 1.0578501224517822, disc_loss = 0.7620019912719727
Trained batch 1 in epoch 0, gen_loss = 1.1245090961456299, disc_loss = 0.9111686944961548
Trained batch 2 in epoch 0, gen_loss = 1.1157010793685913, disc_loss = 0.8356731335322062
Trained batch 3 in epoch 0, gen_loss = 1.034069299697876, disc_loss = 0.7360613644123077
Trained batch 4 in epoch 0, gen_loss = 0.9899265050888062, disc_loss = 0.6556703388690949
Trained batch 5 in epoch 0, gen_loss = 0.9574144780635834, disc_loss = 0.5918226689100266
Trained batch 6 in epoch 0, gen_loss = 0.9296223861830575, disc_loss = 0.5392104110547474
Trained batch 7 in epoch 0, gen_loss = 0.9324041679501534, disc_loss = 0.49756347946822643
Trained batch 8 in epoch 0, gen_loss = 0.9101961056391398, disc_loss = 0.46014132930172813
Trained batch 9 in epoch 0, gen_loss = 0.9013413548469543, disc_loss = 0.4325972259044647
Trained batch 10 in epoch 0, gen_loss = 0.8963050571354952, disc_loss = 0.41254892403429205
Trained batch 11 in epoch 0, gen_loss = 0.8819056749343872, disc_loss = 0.39642487714687985
Trained batch 12 in epoch 0, gen_loss = 0.8765266858614408, disc_loss = 0.38034825256237614
Trained batch 13 in epoch 0, gen_loss = 0.8907610177993774, disc_loss = 0.367669124688421
Trained batch 14 in epoch 0, gen_loss = 0.875899092356364, disc_loss = 0.3569146772225698
Trained batch 15 in epoch 0, gen_loss = 0.8620422370731831, disc_loss = 0.3500936357304454
Trained batch 16 in epoch 0, gen_loss = 0.8570022337576922, disc_loss = 0.3441984837546068
Trained batch 17 in epoch 0, gen_loss = 0.8580567075146569, disc_loss = 0.33757687525616753
Trained batch 18 in epoch 0, gen_loss = 0.8573152548388431, disc_loss = 0.33510840174398926
Trained batch 19 in epoch 0, gen_loss = 0.8629664033651352, disc_loss = 0.3329127050936222
Trained batch 20 in epoch 0, gen_loss = 0.8544185672487531, disc_loss = 0.33357669980753035
Trained batch 21 in epoch 0, gen_loss = 0.8532499400052157, disc_loss = 0.33076482943513175
Trained batch 22 in epoch 0, gen_loss = 0.8529286410497583, disc_loss = 0.3259221516225649
Trained batch 23 in epoch 0, gen_loss = 0.8475733747084936, disc_loss = 0.3253665796170632
Trained batch 24 in epoch 0, gen_loss = 0.8438585042953491, disc_loss = 0.3234468013048172
Trained batch 25 in epoch 0, gen_loss = 0.8437754282584558, disc_loss = 0.3195308865262912
Trained batch 26 in epoch 0, gen_loss = 0.8482738159320973, disc_loss = 0.31606229422269044
Trained batch 27 in epoch 0, gen_loss = 0.8437545448541641, disc_loss = 0.31296947385583607
Trained batch 28 in epoch 0, gen_loss = 0.8463045749171026, disc_loss = 0.30989612022350577
Trained batch 29 in epoch 0, gen_loss = 0.8460496286551158, disc_loss = 0.3067703480521838
Trained batch 30 in epoch 0, gen_loss = 0.8455106327610631, disc_loss = 0.3042159287198897
Trained batch 31 in epoch 0, gen_loss = 0.8413984179496765, disc_loss = 0.30040640057995915
Trained batch 32 in epoch 0, gen_loss = 0.8449022155819517, disc_loss = 0.29712005682063825
Trained batch 33 in epoch 0, gen_loss = 0.8466395472778994, disc_loss = 0.29490232423824425
Trained batch 34 in epoch 0, gen_loss = 0.8456920198031834, disc_loss = 0.2913476471390043
Trained batch 35 in epoch 0, gen_loss = 0.844760904709498, disc_loss = 0.287848263565037
Trained batch 36 in epoch 0, gen_loss = 0.8436052444818858, disc_loss = 0.285191811017088
Trained batch 37 in epoch 0, gen_loss = 0.8458838572627619, disc_loss = 0.2813126476187455
Trained batch 38 in epoch 0, gen_loss = 0.849101355442634, disc_loss = 0.2774004592345311
Trained batch 39 in epoch 0, gen_loss = 0.8437118604779243, disc_loss = 0.2773046173155308
Trained batch 40 in epoch 0, gen_loss = 0.856454972813769, disc_loss = 0.2814560263622098
Trained batch 41 in epoch 0, gen_loss = 0.8564711880116236, disc_loss = 0.2784869220285189
Trained batch 42 in epoch 0, gen_loss = 0.8526127047316973, disc_loss = 0.27750187731066417
Trained batch 43 in epoch 0, gen_loss = 0.8532731356945905, disc_loss = 0.27568926357410173
Trained batch 44 in epoch 0, gen_loss = 0.8559215108553568, disc_loss = 0.2732892417245441
Trained batch 45 in epoch 0, gen_loss = 0.8545522625031678, disc_loss = 0.27098187123951706
Trained batch 46 in epoch 0, gen_loss = 0.853923074742581, disc_loss = 0.2691699814923266
Trained batch 47 in epoch 0, gen_loss = 0.8523993094762167, disc_loss = 0.26883042324334383
Trained batch 48 in epoch 0, gen_loss = 0.8511190280622366, disc_loss = 0.26694598946036124
Trained batch 49 in epoch 0, gen_loss = 0.8529718220233917, disc_loss = 0.2646003231406212
Trained batch 50 in epoch 0, gen_loss = 0.8542938232421875, disc_loss = 0.26318250976356805
Trained batch 51 in epoch 0, gen_loss = 0.8536545496720535, disc_loss = 0.26218628539488864
Trained batch 52 in epoch 0, gen_loss = 0.8528894534650838, disc_loss = 0.2618714885891609
Trained batch 53 in epoch 0, gen_loss = 0.8513319481302191, disc_loss = 0.2611586857173178
Trained batch 54 in epoch 0, gen_loss = 0.8498744910413568, disc_loss = 0.25991518036885697
Trained batch 55 in epoch 0, gen_loss = 0.8495157776134354, disc_loss = 0.2583650105765888
Trained batch 56 in epoch 0, gen_loss = 0.8489755371160674, disc_loss = 0.2574938985339382
Trained batch 57 in epoch 0, gen_loss = 0.849550933673464, disc_loss = 0.256641097880643
Trained batch 58 in epoch 0, gen_loss = 0.8500086291361664, disc_loss = 0.2552882637512886
Trained batch 59 in epoch 0, gen_loss = 0.8501327335834503, disc_loss = 0.25369900539517404
Trained batch 60 in epoch 0, gen_loss = 0.8507606221027062, disc_loss = 0.25291833794507823
Trained batch 61 in epoch 0, gen_loss = 0.8504642152017162, disc_loss = 0.25528560698993746
Trained batch 62 in epoch 0, gen_loss = 0.8496699248041425, disc_loss = 0.2593060511918295
Trained batch 63 in epoch 0, gen_loss = 0.847240031696856, disc_loss = 0.2579231890849769
Trained batch 64 in epoch 0, gen_loss = 0.8510802718309256, disc_loss = 0.25965147247681253
Trained batch 65 in epoch 0, gen_loss = 0.8496413863066471, disc_loss = 0.2589279119715546
Trained batch 66 in epoch 0, gen_loss = 0.847902036424893, disc_loss = 0.258802184862877
Trained batch 67 in epoch 0, gen_loss = 0.8431437147014281, disc_loss = 0.2580674812197685
Trained batch 68 in epoch 0, gen_loss = 0.8451140859852666, disc_loss = 0.2585017409013665
Trained batch 69 in epoch 0, gen_loss = 0.8436959198543004, disc_loss = 0.25784120772566116
Trained batch 70 in epoch 0, gen_loss = 0.8423489970220647, disc_loss = 0.257344341613877
Trained batch 71 in epoch 0, gen_loss = 0.8393674227926466, disc_loss = 0.2568702031340864
Trained batch 72 in epoch 0, gen_loss = 0.8387512140078087, disc_loss = 0.25616439687062614
Trained batch 73 in epoch 0, gen_loss = 0.8384645951760782, disc_loss = 0.25594271518088674
Trained batch 74 in epoch 0, gen_loss = 0.8346075948079427, disc_loss = 0.25622100671132403
Trained batch 75 in epoch 0, gen_loss = 0.836034786544348, disc_loss = 0.25565817109064054
Trained batch 76 in epoch 0, gen_loss = 0.8381985588507219, disc_loss = 0.25537142215611097
Trained batch 77 in epoch 0, gen_loss = 0.8360765996651772, disc_loss = 0.2546404330776288
Trained batch 78 in epoch 0, gen_loss = 0.8372713033157059, disc_loss = 0.253833029277717
Trained batch 79 in epoch 0, gen_loss = 0.8377589471638203, disc_loss = 0.25306435115635395
Trained batch 80 in epoch 0, gen_loss = 0.8363128804866179, disc_loss = 0.2523579715210714
Trained batch 81 in epoch 0, gen_loss = 0.8364057519086977, disc_loss = 0.25236529475305136
Trained batch 82 in epoch 0, gen_loss = 0.8346402286046959, disc_loss = 0.25273296596056005
Trained batch 83 in epoch 0, gen_loss = 0.8366636463574001, disc_loss = 0.2521551258507229
Trained batch 84 in epoch 0, gen_loss = 0.8357059773276834, disc_loss = 0.25150872381294476
Trained batch 85 in epoch 0, gen_loss = 0.8374874827473663, disc_loss = 0.2511216317151868
Trained batch 86 in epoch 0, gen_loss = 0.8347430551189116, disc_loss = 0.2511476680807684
Trained batch 87 in epoch 0, gen_loss = 0.8337683413516391, disc_loss = 0.25238526493988256
Trained batch 88 in epoch 0, gen_loss = 0.8313355271735888, disc_loss = 0.2543828063801433
Trained batch 89 in epoch 0, gen_loss = 0.8309785505135854, disc_loss = 0.2539171326491568
Trained batch 90 in epoch 0, gen_loss = 0.834747157909058, disc_loss = 0.25365054116144287
Trained batch 91 in epoch 0, gen_loss = 0.8326323997715245, disc_loss = 0.25331891603443935
Trained batch 92 in epoch 0, gen_loss = 0.8300062917893932, disc_loss = 0.2529444311575223
Trained batch 93 in epoch 0, gen_loss = 0.8298077247244247, disc_loss = 0.25255440318203987
Trained batch 94 in epoch 0, gen_loss = 0.829581976564307, disc_loss = 0.25201082762918975
Trained batch 95 in epoch 0, gen_loss = 0.8290621358901262, disc_loss = 0.25132185065497953
Trained batch 96 in epoch 0, gen_loss = 0.8270540987093424, disc_loss = 0.25145815358948465
Trained batch 97 in epoch 0, gen_loss = 0.8266995780322016, disc_loss = 0.25112156341878733
Trained batch 98 in epoch 0, gen_loss = 0.8245430835569748, disc_loss = 0.2508007063709124
Trained batch 99 in epoch 0, gen_loss = 0.824048466682434, disc_loss = 0.25069940105080607
Trained batch 100 in epoch 0, gen_loss = 0.8223637761455951, disc_loss = 0.25060196515947286
Trained batch 101 in epoch 0, gen_loss = 0.8209518679216796, disc_loss = 0.2507335822664055
Trained batch 102 in epoch 0, gen_loss = 0.8216644485019943, disc_loss = 0.25069583749886853
Trained batch 103 in epoch 0, gen_loss = 0.8213631505003343, disc_loss = 0.2503435770766093
Trained batch 104 in epoch 0, gen_loss = 0.8220554601578486, disc_loss = 0.2510222890547344
Trained batch 105 in epoch 0, gen_loss = 0.8203973320295226, disc_loss = 0.251961517024715
Trained batch 106 in epoch 0, gen_loss = 0.8184526462421239, disc_loss = 0.25181124644858816
Trained batch 107 in epoch 0, gen_loss = 0.8177657353657263, disc_loss = 0.2515863570626135
Trained batch 108 in epoch 0, gen_loss = 0.817249939529174, disc_loss = 0.25153393934079266
Trained batch 109 in epoch 0, gen_loss = 0.8184053529392589, disc_loss = 0.25128048739650033
Trained batch 110 in epoch 0, gen_loss = 0.8171215299013499, disc_loss = 0.2511518040487358
Trained batch 111 in epoch 0, gen_loss = 0.816781227609941, disc_loss = 0.2506815042080624
Trained batch 112 in epoch 0, gen_loss = 0.8161121733420718, disc_loss = 0.25062330304521374
Trained batch 113 in epoch 0, gen_loss = 0.8153341339345563, disc_loss = 0.2503635335648269
Trained batch 114 in epoch 0, gen_loss = 0.813217306137085, disc_loss = 0.2505162994498792
Trained batch 115 in epoch 0, gen_loss = 0.813678133076635, disc_loss = 0.2505887432088112
Trained batch 116 in epoch 0, gen_loss = 0.8127047867856474, disc_loss = 0.2505775523236674
Trained batch 117 in epoch 0, gen_loss = 0.8115655461610374, disc_loss = 0.2502825048010228
Trained batch 118 in epoch 0, gen_loss = 0.8113231488636562, disc_loss = 0.2501228290195225
Trained batch 119 in epoch 0, gen_loss = 0.8097261543075244, disc_loss = 0.2501774386813243
Trained batch 120 in epoch 0, gen_loss = 0.8095031011203104, disc_loss = 0.25030013290811176
Trained batch 121 in epoch 0, gen_loss = 0.8080286984560919, disc_loss = 0.2502592474710746
Trained batch 122 in epoch 0, gen_loss = 0.8085144370552001, disc_loss = 0.25031749116695995
Trained batch 123 in epoch 0, gen_loss = 0.8076116404225749, disc_loss = 0.2503888445996469
Trained batch 124 in epoch 0, gen_loss = 0.8071325950622559, disc_loss = 0.2500961505174637
Trained batch 125 in epoch 0, gen_loss = 0.8063388580367679, disc_loss = 0.24965211571682067
Trained batch 126 in epoch 0, gen_loss = 0.8046014036719255, disc_loss = 0.24940979023148693
Trained batch 127 in epoch 0, gen_loss = 0.803676369599998, disc_loss = 0.24893492937553674
Trained batch 128 in epoch 0, gen_loss = 0.8042521546053332, disc_loss = 0.24848180812920712
Trained batch 129 in epoch 0, gen_loss = 0.8020104023126455, disc_loss = 0.2484512638587218
Trained batch 130 in epoch 0, gen_loss = 0.8010772225510983, disc_loss = 0.248133922123727
Trained batch 131 in epoch 0, gen_loss = 0.8010513534148535, disc_loss = 0.2483305987535101
Trained batch 132 in epoch 0, gen_loss = 0.79974046954535, disc_loss = 0.24940576006595352
Trained batch 133 in epoch 0, gen_loss = 0.7985513650659305, disc_loss = 0.24936151738042261
Trained batch 134 in epoch 0, gen_loss = 0.7975756225762544, disc_loss = 0.24912923254348612
Trained batch 135 in epoch 0, gen_loss = 0.7966094323817421, disc_loss = 0.24898805403534105
Trained batch 136 in epoch 0, gen_loss = 0.7955405246602357, disc_loss = 0.24869878949040045
Trained batch 137 in epoch 0, gen_loss = 0.7946361635906108, disc_loss = 0.24854949829371079
Trained batch 138 in epoch 0, gen_loss = 0.793123331430147, disc_loss = 0.24862830501666172
Trained batch 139 in epoch 0, gen_loss = 0.7921859455960137, disc_loss = 0.24844625368714332
Trained batch 140 in epoch 0, gen_loss = 0.7904429507593737, disc_loss = 0.2482997196997311
Trained batch 141 in epoch 0, gen_loss = 0.7893846123151376, disc_loss = 0.24822053071898473
Trained batch 142 in epoch 0, gen_loss = 0.7902864584555993, disc_loss = 0.2483535332904829
Trained batch 143 in epoch 0, gen_loss = 0.7890342875487275, disc_loss = 0.24837004176030555
Trained batch 144 in epoch 0, gen_loss = 0.7869721879219187, disc_loss = 0.24840357170022767
Trained batch 145 in epoch 0, gen_loss = 0.7858448177576065, disc_loss = 0.24822977991545037
Trained batch 146 in epoch 0, gen_loss = 0.7859738430603832, disc_loss = 0.24809410265919302
Trained batch 147 in epoch 0, gen_loss = 0.7848982615648089, disc_loss = 0.24787765399024292
Trained batch 148 in epoch 0, gen_loss = 0.7843327780297938, disc_loss = 0.24773062535580373
Trained batch 149 in epoch 0, gen_loss = 0.7842919168869654, disc_loss = 0.24754320561885834
Trained batch 150 in epoch 0, gen_loss = 0.7833862630342017, disc_loss = 0.24727934934445564
Trained batch 151 in epoch 0, gen_loss = 0.782573789554207, disc_loss = 0.2470236603954905
Trained batch 152 in epoch 0, gen_loss = 0.7811703270946453, disc_loss = 0.2468887038675009
Trained batch 153 in epoch 0, gen_loss = 0.7805129972758231, disc_loss = 0.24676882262740815
Trained batch 154 in epoch 0, gen_loss = 0.7805111325556232, disc_loss = 0.24671899743618503
Trained batch 155 in epoch 0, gen_loss = 0.7785787062767224, disc_loss = 0.24711619002314714
Trained batch 156 in epoch 0, gen_loss = 0.778892281708444, disc_loss = 0.2473732839534237
Trained batch 157 in epoch 0, gen_loss = 0.776916004057172, disc_loss = 0.2473880785364139
Trained batch 158 in epoch 0, gen_loss = 0.776532178404946, disc_loss = 0.24726093049694156
Trained batch 159 in epoch 0, gen_loss = 0.7763316113501787, disc_loss = 0.24734264770522713
Trained batch 160 in epoch 0, gen_loss = 0.7760727879423532, disc_loss = 0.24723193336347615
Trained batch 161 in epoch 0, gen_loss = 0.7746543141058934, disc_loss = 0.24721555871728026
Trained batch 162 in epoch 0, gen_loss = 0.774938321186721, disc_loss = 0.2471412666187696
Trained batch 163 in epoch 0, gen_loss = 0.7741322252081662, disc_loss = 0.24692192010399772
Trained batch 164 in epoch 0, gen_loss = 0.7730298631119006, disc_loss = 0.24668883961258511
Trained batch 165 in epoch 0, gen_loss = 0.7725971445261713, disc_loss = 0.24653473792664976
Trained batch 166 in epoch 0, gen_loss = 0.7724450855198021, disc_loss = 0.24651952070033478
Trained batch 167 in epoch 0, gen_loss = 0.7713952926652772, disc_loss = 0.24648191770982175
Trained batch 168 in epoch 0, gen_loss = 0.7702541294887927, disc_loss = 0.24628121560141886
Trained batch 169 in epoch 0, gen_loss = 0.77037093464066, disc_loss = 0.2459982075235423
Trained batch 170 in epoch 0, gen_loss = 0.7692176107077571, disc_loss = 0.24551010602398923
Trained batch 171 in epoch 0, gen_loss = 0.7694928056971971, disc_loss = 0.24513229372542958
Trained batch 172 in epoch 0, gen_loss = 0.7703511935438034, disc_loss = 0.2448120903589822
Trained batch 173 in epoch 0, gen_loss = 0.7695655353452967, disc_loss = 0.2445920865083563
Trained batch 174 in epoch 0, gen_loss = 0.768312373161316, disc_loss = 0.2442959543636867
Trained batch 175 in epoch 0, gen_loss = 0.7680259323255583, disc_loss = 0.24453487839888444
Trained batch 176 in epoch 0, gen_loss = 0.7665073324394764, disc_loss = 0.245505548971521
Trained batch 177 in epoch 0, gen_loss = 0.7667982650271962, disc_loss = 0.24555911676267558
Trained batch 178 in epoch 0, gen_loss = 0.7664716674961858, disc_loss = 0.24558150734981346
Trained batch 179 in epoch 0, gen_loss = 0.7661029850443204, disc_loss = 0.24555323703421486
Trained batch 180 in epoch 0, gen_loss = 0.7653056292573391, disc_loss = 0.24560285454296935
Trained batch 181 in epoch 0, gen_loss = 0.7652519802143286, disc_loss = 0.24538007444077795
Trained batch 182 in epoch 0, gen_loss = 0.7653105908729991, disc_loss = 0.24518114124816623
Trained batch 183 in epoch 0, gen_loss = 0.7657824701265149, disc_loss = 0.24501730436864105
Trained batch 184 in epoch 0, gen_loss = 0.7653759722774093, disc_loss = 0.24463543650266287
Trained batch 185 in epoch 0, gen_loss = 0.7648938921510532, disc_loss = 0.24439259121815363
Trained batch 186 in epoch 0, gen_loss = 0.7650297610836233, disc_loss = 0.24428340099393364
Trained batch 187 in epoch 0, gen_loss = 0.7641557795887298, disc_loss = 0.24406401004562986
Trained batch 188 in epoch 0, gen_loss = 0.7656337544716224, disc_loss = 0.24377103157775112
Trained batch 189 in epoch 0, gen_loss = 0.7644728276290391, disc_loss = 0.2441649727131191
Trained batch 190 in epoch 0, gen_loss = 0.7646896887512107, disc_loss = 0.2440652089749331
Trained batch 191 in epoch 0, gen_loss = 0.7641633474268019, disc_loss = 0.24395586596801877
Trained batch 192 in epoch 0, gen_loss = 0.7640295542892397, disc_loss = 0.24420348242156864
Trained batch 193 in epoch 0, gen_loss = 0.7631960733956897, disc_loss = 0.24411242893061688
Trained batch 194 in epoch 0, gen_loss = 0.7630175378078069, disc_loss = 0.24395616818697025
Trained batch 195 in epoch 0, gen_loss = 0.7627939048166178, disc_loss = 0.2439144820126952
Trained batch 196 in epoch 0, gen_loss = 0.7623476081995795, disc_loss = 0.243721326671276
Trained batch 197 in epoch 0, gen_loss = 0.7609277945576292, disc_loss = 0.2436456164777881
Trained batch 198 in epoch 0, gen_loss = 0.7615306485238387, disc_loss = 0.24350632562409694
Trained batch 199 in epoch 0, gen_loss = 0.7613746219873428, disc_loss = 0.24367270044982434
Trained batch 200 in epoch 0, gen_loss = 0.7605595134977085, disc_loss = 0.2436594194292429
Trained batch 201 in epoch 0, gen_loss = 0.7604930574941163, disc_loss = 0.24353312878030361
Trained batch 202 in epoch 0, gen_loss = 0.7592148722098966, disc_loss = 0.24360302479689933
Trained batch 203 in epoch 0, gen_loss = 0.7592005349841773, disc_loss = 0.24355375160481416
Trained batch 204 in epoch 0, gen_loss = 0.7590238068161941, disc_loss = 0.243374910369152
Trained batch 205 in epoch 0, gen_loss = 0.7590005632164409, disc_loss = 0.2431442346243025
Trained batch 206 in epoch 0, gen_loss = 0.758887173185026, disc_loss = 0.24315746027778312
Trained batch 207 in epoch 0, gen_loss = 0.7586705555709509, disc_loss = 0.24308357724490073
Trained batch 208 in epoch 0, gen_loss = 0.7583652118746744, disc_loss = 0.24314953729011227
Trained batch 209 in epoch 0, gen_loss = 0.7570899233931587, disc_loss = 0.24318323795284544
Trained batch 210 in epoch 0, gen_loss = 0.7567139770747361, disc_loss = 0.2430528161508777
Trained batch 211 in epoch 0, gen_loss = 0.7559128935044667, disc_loss = 0.24272745341624855
Trained batch 212 in epoch 0, gen_loss = 0.7547950666275383, disc_loss = 0.242503145840806
Trained batch 213 in epoch 0, gen_loss = 0.754279346388077, disc_loss = 0.24225303669956244
Trained batch 214 in epoch 0, gen_loss = 0.7539708872174108, disc_loss = 0.24217493215272592
Trained batch 215 in epoch 0, gen_loss = 0.753388958396735, disc_loss = 0.24207153723195748
Trained batch 216 in epoch 0, gen_loss = 0.7528883020998696, disc_loss = 0.24180148315319816
Trained batch 217 in epoch 0, gen_loss = 0.7517915441902405, disc_loss = 0.24209842044825947
Trained batch 218 in epoch 0, gen_loss = 0.7523039854280481, disc_loss = 0.2420324725375328
Trained batch 219 in epoch 0, gen_loss = 0.7518243090672927, disc_loss = 0.24164074781266126
Trained batch 220 in epoch 0, gen_loss = 0.7517155441223766, disc_loss = 0.24151867533701038
Trained batch 221 in epoch 0, gen_loss = 0.7511930044169899, disc_loss = 0.24135917941997717
Trained batch 222 in epoch 0, gen_loss = 0.7507964674667392, disc_loss = 0.24134107448594988
Trained batch 223 in epoch 0, gen_loss = 0.7494360654215727, disc_loss = 0.24201896134763956
Trained batch 224 in epoch 0, gen_loss = 0.7494125356939104, disc_loss = 0.24239120483398438
Trained batch 225 in epoch 0, gen_loss = 0.7485638322819651, disc_loss = 0.24267576621697012
Trained batch 226 in epoch 0, gen_loss = 0.7478760684376772, disc_loss = 0.2426281283868042
Trained batch 227 in epoch 0, gen_loss = 0.7475843004751623, disc_loss = 0.24267222379383288
Trained batch 228 in epoch 0, gen_loss = 0.7480611987249299, disc_loss = 0.24264057240892187
Trained batch 229 in epoch 0, gen_loss = 0.7471506905296574, disc_loss = 0.24267179551331894
Trained batch 230 in epoch 0, gen_loss = 0.7465296172218405, disc_loss = 0.24253353315256374
Trained batch 231 in epoch 0, gen_loss = 0.74672054255317, disc_loss = 0.2424146195809389
Trained batch 232 in epoch 0, gen_loss = 0.7459325604940177, disc_loss = 0.24212001571072017
Trained batch 233 in epoch 0, gen_loss = 0.745577724952983, disc_loss = 0.24182192414489567
Trained batch 234 in epoch 0, gen_loss = 0.7450964644868323, disc_loss = 0.2416164665146077
Trained batch 235 in epoch 0, gen_loss = 0.7451523859369553, disc_loss = 0.2415442995221938
Trained batch 236 in epoch 0, gen_loss = 0.7459848554577002, disc_loss = 0.24136113931861106
Trained batch 237 in epoch 0, gen_loss = 0.7455760304416928, disc_loss = 0.24143469771918127
Trained batch 238 in epoch 0, gen_loss = 0.7460924789745937, disc_loss = 0.24146564024262848
Trained batch 239 in epoch 0, gen_loss = 0.7451496892919143, disc_loss = 0.24136800598353148
Trained batch 240 in epoch 0, gen_loss = 0.7446989502402263, disc_loss = 0.2412617473681438
Trained batch 241 in epoch 0, gen_loss = 0.7448644159007664, disc_loss = 0.24117657936308995
Trained batch 242 in epoch 0, gen_loss = 0.7444512246812812, disc_loss = 0.2409399520958402
Trained batch 243 in epoch 0, gen_loss = 0.7443124658015908, disc_loss = 0.24089092052862293
Trained batch 244 in epoch 0, gen_loss = 0.743949601479939, disc_loss = 0.24079442705426898
Trained batch 245 in epoch 0, gen_loss = 0.742910907278216, disc_loss = 0.24064101593765785
Trained batch 246 in epoch 0, gen_loss = 0.742751276686124, disc_loss = 0.24038373066587487
Trained batch 247 in epoch 0, gen_loss = 0.7434373541224387, disc_loss = 0.2402019593263826
Trained batch 248 in epoch 0, gen_loss = 0.742607338361472, disc_loss = 0.24009861596616874
Trained batch 249 in epoch 0, gen_loss = 0.7430505876541138, disc_loss = 0.24009184741973877
Trained batch 250 in epoch 0, gen_loss = 0.7426301630369696, disc_loss = 0.24035592240641315
Trained batch 251 in epoch 0, gen_loss = 0.7427797274930137, disc_loss = 0.24037057705341824
Trained batch 252 in epoch 0, gen_loss = 0.742400000689058, disc_loss = 0.24018995481517474
Trained batch 253 in epoch 0, gen_loss = 0.7414867525964272, disc_loss = 0.2398645510589044
Trained batch 254 in epoch 0, gen_loss = 0.740853936064477, disc_loss = 0.23980405365719515
Trained batch 255 in epoch 0, gen_loss = 0.7411593901924789, disc_loss = 0.2397669400088489
Trained batch 256 in epoch 0, gen_loss = 0.7407059822564923, disc_loss = 0.23947591662174997
Trained batch 257 in epoch 0, gen_loss = 0.7401628240134365, disc_loss = 0.23922914255035016
Trained batch 258 in epoch 0, gen_loss = 0.7399529147332239, disc_loss = 0.23879029294008453
Trained batch 259 in epoch 0, gen_loss = 0.7399548308207439, disc_loss = 0.23854018845237218
Trained batch 260 in epoch 0, gen_loss = 0.7405740780848653, disc_loss = 0.23853681581915567
Trained batch 261 in epoch 0, gen_loss = 0.7397631297584708, disc_loss = 0.23849483232461768
Trained batch 262 in epoch 0, gen_loss = 0.7390831527601177, disc_loss = 0.23837354886894443
Trained batch 263 in epoch 0, gen_loss = 0.7395072434887742, disc_loss = 0.23820487748492847
Trained batch 264 in epoch 0, gen_loss = 0.738827491256426, disc_loss = 0.23825287740185574
Trained batch 265 in epoch 0, gen_loss = 0.7390464172327429, disc_loss = 0.23795745986744873
Trained batch 266 in epoch 0, gen_loss = 0.7392554597908192, disc_loss = 0.23794498872221187
Trained batch 267 in epoch 0, gen_loss = 0.7392182674870562, disc_loss = 0.2379993989841262
Trained batch 268 in epoch 0, gen_loss = 0.738629119103726, disc_loss = 0.23781822372546427
Trained batch 269 in epoch 0, gen_loss = 0.7382471808680782, disc_loss = 0.23772083565040872
Trained batch 270 in epoch 0, gen_loss = 0.7393261669306738, disc_loss = 0.23763419374328698
Trained batch 271 in epoch 0, gen_loss = 0.7388175213161636, disc_loss = 0.23789579914334943
Trained batch 272 in epoch 0, gen_loss = 0.7383650453972729, disc_loss = 0.23759546668538245
Trained batch 273 in epoch 0, gen_loss = 0.7384616032134007, disc_loss = 0.23716146599528562
Trained batch 274 in epoch 0, gen_loss = 0.7380981349945068, disc_loss = 0.2370745801654729
Trained batch 275 in epoch 0, gen_loss = 0.7379022422044174, disc_loss = 0.23704574432601963
Trained batch 276 in epoch 0, gen_loss = 0.7378299890442446, disc_loss = 0.23675671340864057
Trained batch 277 in epoch 0, gen_loss = 0.7369417468849704, disc_loss = 0.23648622763349855
Trained batch 278 in epoch 0, gen_loss = 0.7368527969151842, disc_loss = 0.23630052017161496
Trained batch 279 in epoch 0, gen_loss = 0.736446804872581, disc_loss = 0.2360897564728345
Trained batch 280 in epoch 0, gen_loss = 0.7371420185761095, disc_loss = 0.23606520485517393
Trained batch 281 in epoch 0, gen_loss = 0.7370614508787791, disc_loss = 0.23565082748730978
Trained batch 282 in epoch 0, gen_loss = 0.736212272631406, disc_loss = 0.23534389687932422
Trained batch 283 in epoch 0, gen_loss = 0.736311850518408, disc_loss = 0.23497869908599786
Trained batch 284 in epoch 0, gen_loss = 0.7363415070793085, disc_loss = 0.23483535380739914
Trained batch 285 in epoch 0, gen_loss = 0.7358872378831143, disc_loss = 0.23470207209978905
Trained batch 286 in epoch 0, gen_loss = 0.7368224889351516, disc_loss = 0.2340414039011824
Trained batch 287 in epoch 0, gen_loss = 0.7376149490268694, disc_loss = 0.23341448663268238
Trained batch 288 in epoch 0, gen_loss = 0.7368550472812256, disc_loss = 0.23348193573137055
Trained batch 289 in epoch 0, gen_loss = 0.7378831332099849, disc_loss = 0.23364841307288614
Trained batch 290 in epoch 0, gen_loss = 0.7375353846148527, disc_loss = 0.23323928179456196
Trained batch 291 in epoch 0, gen_loss = 0.7377530078161253, disc_loss = 0.23294348898662687
Trained batch 292 in epoch 0, gen_loss = 0.7379889584848905, disc_loss = 0.23256026580929756
Trained batch 293 in epoch 0, gen_loss = 0.7386525489237844, disc_loss = 0.23208797460764038
Trained batch 294 in epoch 0, gen_loss = 0.7381257781537912, disc_loss = 0.2320497294224925
Trained batch 295 in epoch 0, gen_loss = 0.738698709957503, disc_loss = 0.2321718124345549
Trained batch 296 in epoch 0, gen_loss = 0.7381222483887014, disc_loss = 0.232573324946141
Trained batch 297 in epoch 0, gen_loss = 0.737567370069907, disc_loss = 0.23251455653483835
Trained batch 298 in epoch 0, gen_loss = 0.7373217680183143, disc_loss = 0.23237968479161678
Trained batch 299 in epoch 0, gen_loss = 0.7363129745920499, disc_loss = 0.2324264404301842
Trained batch 300 in epoch 0, gen_loss = 0.735820946008264, disc_loss = 0.2323285103265035
Trained batch 301 in epoch 0, gen_loss = 0.735774105254388, disc_loss = 0.23236553209358887
Trained batch 302 in epoch 0, gen_loss = 0.7353784688825261, disc_loss = 0.23206265045717211
Trained batch 303 in epoch 0, gen_loss = 0.7351841137401367, disc_loss = 0.23246017986859538
Trained batch 304 in epoch 0, gen_loss = 0.7351383855108355, disc_loss = 0.23302639631218597
Trained batch 305 in epoch 0, gen_loss = 0.7362012166797726, disc_loss = 0.23341633960166397
Trained batch 306 in epoch 0, gen_loss = 0.7363460835688277, disc_loss = 0.23344974609316366
Trained batch 307 in epoch 0, gen_loss = 0.7357916022082428, disc_loss = 0.23326626808273715
Trained batch 308 in epoch 0, gen_loss = 0.735304537232254, disc_loss = 0.23324914523746976
Trained batch 309 in epoch 0, gen_loss = 0.7352111486657973, disc_loss = 0.23320054509226354
Trained batch 310 in epoch 0, gen_loss = 0.7349199452392541, disc_loss = 0.23310510542279655
Trained batch 311 in epoch 0, gen_loss = 0.7346752676635216, disc_loss = 0.2329851323619294
Trained batch 312 in epoch 0, gen_loss = 0.7347576971442554, disc_loss = 0.23287964182587478
Trained batch 313 in epoch 0, gen_loss = 0.73427007712756, disc_loss = 0.23277841632960328
Trained batch 314 in epoch 0, gen_loss = 0.7339496021232907, disc_loss = 0.23259102963502445
Trained batch 315 in epoch 0, gen_loss = 0.7338037859601311, disc_loss = 0.2326251055361538
Trained batch 316 in epoch 0, gen_loss = 0.7335388245830776, disc_loss = 0.23236941192475402
Trained batch 317 in epoch 0, gen_loss = 0.7330913874525694, disc_loss = 0.23212449628648893
Trained batch 318 in epoch 0, gen_loss = 0.732557570766132, disc_loss = 0.23203094757883153
Trained batch 319 in epoch 0, gen_loss = 0.7327261638827622, disc_loss = 0.23207218340830876
Trained batch 320 in epoch 0, gen_loss = 0.7324204315834699, disc_loss = 0.23185145080878727
Trained batch 321 in epoch 0, gen_loss = 0.7321519450926632, disc_loss = 0.23156589414253367
Trained batch 322 in epoch 0, gen_loss = 0.7323947749086209, disc_loss = 0.23107289747787704
Trained batch 323 in epoch 0, gen_loss = 0.7317102890875604, disc_loss = 0.23094405189018558
Trained batch 324 in epoch 0, gen_loss = 0.731927773310588, disc_loss = 0.23087056770920752
Trained batch 325 in epoch 0, gen_loss = 0.7316808105429258, disc_loss = 0.23054090618767256
Trained batch 326 in epoch 0, gen_loss = 0.7324020847085784, disc_loss = 0.2307566472810525
Trained batch 327 in epoch 0, gen_loss = 0.7316431113314338, disc_loss = 0.23064010577821514
Trained batch 328 in epoch 0, gen_loss = 0.7311908735873851, disc_loss = 0.23057403926112008
Trained batch 329 in epoch 0, gen_loss = 0.7317420353492101, disc_loss = 0.23026844833159085
Trained batch 330 in epoch 0, gen_loss = 0.7311823876782847, disc_loss = 0.22988271502794816
Trained batch 331 in epoch 0, gen_loss = 0.7308444938207247, disc_loss = 0.22958271175129227
Trained batch 332 in epoch 0, gen_loss = 0.7304109344790289, disc_loss = 0.22943339607602842
Trained batch 333 in epoch 0, gen_loss = 0.7313832065123997, disc_loss = 0.2297517750635297
Trained batch 334 in epoch 0, gen_loss = 0.7310482262675442, disc_loss = 0.2299743680478032
Trained batch 335 in epoch 0, gen_loss = 0.7308064542178597, disc_loss = 0.22980489316839903
Trained batch 336 in epoch 0, gen_loss = 0.730696051428509, disc_loss = 0.22972205698003756
Trained batch 337 in epoch 0, gen_loss = 0.7300781463906609, disc_loss = 0.2296970475288714
Trained batch 338 in epoch 0, gen_loss = 0.7300119170572905, disc_loss = 0.22959199487327825
Trained batch 339 in epoch 0, gen_loss = 0.7308529007960768, disc_loss = 0.2290715254514533
Trained batch 340 in epoch 0, gen_loss = 0.732063404888002, disc_loss = 0.22850892889447227
Trained batch 341 in epoch 0, gen_loss = 0.7323709263613349, disc_loss = 0.2279552164438524
Trained batch 342 in epoch 0, gen_loss = 0.7333452097702304, disc_loss = 0.2274414717542882
Trained batch 343 in epoch 0, gen_loss = 0.7340476612538792, disc_loss = 0.22686804315010303
Trained batch 344 in epoch 0, gen_loss = 0.7352230102255725, disc_loss = 0.22626432642016722
Trained batch 345 in epoch 0, gen_loss = 0.7363010551026791, disc_loss = 0.22570377730931332
Trained batch 346 in epoch 0, gen_loss = 0.7370565300887875, disc_loss = 0.22510350349034458
Trained batch 347 in epoch 0, gen_loss = 0.7374337520236256, disc_loss = 0.22461155836802277
Trained batch 348 in epoch 0, gen_loss = 0.7377345298115366, disc_loss = 0.22418964588560997
Trained batch 349 in epoch 0, gen_loss = 0.7386723984139306, disc_loss = 0.22370445721383606
Trained batch 350 in epoch 0, gen_loss = 0.7403523486394149, disc_loss = 0.22343282831933595
Trained batch 351 in epoch 0, gen_loss = 0.7410959587009116, disc_loss = 0.22288116883084347
Trained batch 352 in epoch 0, gen_loss = 0.7415809199931601, disc_loss = 0.22236225881189023
Trained batch 353 in epoch 0, gen_loss = 0.7430901696621361, disc_loss = 0.2217924298171354
Trained batch 354 in epoch 0, gen_loss = 0.7440911256931197, disc_loss = 0.22121032348138767
Trained batch 355 in epoch 0, gen_loss = 0.7449096462197518, disc_loss = 0.2206523172907908
Trained batch 356 in epoch 0, gen_loss = 0.7458577904881549, disc_loss = 0.22008243534734853
Trained batch 357 in epoch 0, gen_loss = 0.7466825597279565, disc_loss = 0.2195337282717436
Trained batch 358 in epoch 0, gen_loss = 0.7467428612675839, disc_loss = 0.21920363882343832
Trained batch 359 in epoch 0, gen_loss = 0.747806814395719, disc_loss = 0.2188759950015487
Trained batch 360 in epoch 0, gen_loss = 0.7480436825190885, disc_loss = 0.2185176738003821
Trained batch 361 in epoch 0, gen_loss = 0.7480775475995975, disc_loss = 0.21815578704596966
Trained batch 362 in epoch 0, gen_loss = 0.7493529965890668, disc_loss = 0.21782973315566778
Trained batch 363 in epoch 0, gen_loss = 0.7487428318504449, disc_loss = 0.21793812256726017
Trained batch 364 in epoch 0, gen_loss = 0.7502088732098879, disc_loss = 0.21803123939986507
Trained batch 365 in epoch 0, gen_loss = 0.7501571651527791, disc_loss = 0.2176866501574837
Trained batch 366 in epoch 0, gen_loss = 0.7497533966637437, disc_loss = 0.21766390457840723
Trained batch 367 in epoch 0, gen_loss = 0.7500757621196301, disc_loss = 0.21749369062371957
Trained batch 368 in epoch 0, gen_loss = 0.7501307952856306, disc_loss = 0.217390447847424
Trained batch 369 in epoch 0, gen_loss = 0.7491766584886087, disc_loss = 0.2173210820963455
Trained batch 370 in epoch 0, gen_loss = 0.7493079505519404, disc_loss = 0.2170874647861422
Trained batch 371 in epoch 0, gen_loss = 0.7500488158836159, disc_loss = 0.21718773825885226
Trained batch 372 in epoch 0, gen_loss = 0.7500530564433449, disc_loss = 0.21677345080655716
Trained batch 373 in epoch 0, gen_loss = 0.7498235839573457, disc_loss = 0.21642065250668377
Trained batch 374 in epoch 0, gen_loss = 0.7499828494389852, disc_loss = 0.21605043470114468
Trained batch 375 in epoch 0, gen_loss = 0.7503312921270411, disc_loss = 0.2157181190609179
Trained batch 376 in epoch 0, gen_loss = 0.7502890316181537, disc_loss = 0.2152441353302459
Trained batch 377 in epoch 0, gen_loss = 0.7506680715651739, disc_loss = 0.21476324032942848
Trained batch 378 in epoch 0, gen_loss = 0.7514522135414989, disc_loss = 0.2142546217726411
Trained batch 379 in epoch 0, gen_loss = 0.7524062780957473, disc_loss = 0.21374771150172148
Trained batch 380 in epoch 0, gen_loss = 0.7529992717770454, disc_loss = 0.21323775843010723
Trained batch 381 in epoch 0, gen_loss = 0.7532627964831148, disc_loss = 0.21272883065171658
Trained batch 382 in epoch 0, gen_loss = 0.7531679618140736, disc_loss = 0.21228052363743125
Trained batch 383 in epoch 0, gen_loss = 0.7538591159197191, disc_loss = 0.21179402825509897
Trained batch 384 in epoch 0, gen_loss = 0.7541337843065138, disc_loss = 0.2113258341617592
Trained batch 385 in epoch 0, gen_loss = 0.7543263883170687, disc_loss = 0.21082456365777807
Trained batch 386 in epoch 0, gen_loss = 0.7537803258698732, disc_loss = 0.21086475236018884
Trained batch 387 in epoch 0, gen_loss = 0.7542910956844842, disc_loss = 0.21122872067336954
Trained batch 388 in epoch 0, gen_loss = 0.7549275984187972, disc_loss = 0.21084230986201136
Trained batch 389 in epoch 0, gen_loss = 0.7550038819129651, disc_loss = 0.2104427913084435
Trained batch 390 in epoch 0, gen_loss = 0.7550191682622865, disc_loss = 0.20996594474034008
Trained batch 391 in epoch 0, gen_loss = 0.755132502287018, disc_loss = 0.20952684701448876
Trained batch 392 in epoch 0, gen_loss = 0.7547676343347584, disc_loss = 0.2094274923020533
Trained batch 393 in epoch 0, gen_loss = 0.7558692746658615, disc_loss = 0.20960768670798635
Trained batch 394 in epoch 0, gen_loss = 0.7561786773838575, disc_loss = 0.20935923737485576
Trained batch 395 in epoch 0, gen_loss = 0.7555554099757262, disc_loss = 0.20939933539913835
Trained batch 396 in epoch 0, gen_loss = 0.7550727547866571, disc_loss = 0.20950377056192165
Trained batch 397 in epoch 0, gen_loss = 0.7553100007862302, disc_loss = 0.2095986154777508
Trained batch 398 in epoch 0, gen_loss = 0.7545964803014483, disc_loss = 0.2095370948580759
Trained batch 399 in epoch 0, gen_loss = 0.754860563725233, disc_loss = 0.20938116439851
Trained batch 400 in epoch 0, gen_loss = 0.7547047847226969, disc_loss = 0.2091550611242875
Trained batch 401 in epoch 0, gen_loss = 0.754290713451395, disc_loss = 0.20894284358489054
Trained batch 402 in epoch 0, gen_loss = 0.7542313282602182, disc_loss = 0.20897492042814308
Trained batch 403 in epoch 0, gen_loss = 0.7539461802433033, disc_loss = 0.20890782560719787
Trained batch 404 in epoch 0, gen_loss = 0.7541838049888611, disc_loss = 0.20881799387021197
Trained batch 405 in epoch 0, gen_loss = 0.7546342800697082, disc_loss = 0.20835858504769617
Trained batch 406 in epoch 0, gen_loss = 0.7542703172205707, disc_loss = 0.20816910880359224
Trained batch 407 in epoch 0, gen_loss = 0.7549068507026223, disc_loss = 0.20788201213330396
Trained batch 408 in epoch 0, gen_loss = 0.7550115897194972, disc_loss = 0.2075752905048521
Trained batch 409 in epoch 0, gen_loss = 0.7553805976379209, disc_loss = 0.2071139305943578
Trained batch 410 in epoch 0, gen_loss = 0.7556265850716843, disc_loss = 0.20665080112307685
Trained batch 411 in epoch 0, gen_loss = 0.7557059154637809, disc_loss = 0.2061918265190771
Trained batch 412 in epoch 0, gen_loss = 0.7559044056596825, disc_loss = 0.20578613584820568
Trained batch 413 in epoch 0, gen_loss = 0.7559928915638855, disc_loss = 0.20537630346005306
Trained batch 414 in epoch 0, gen_loss = 0.757128508550575, disc_loss = 0.20511602484452796
Trained batch 415 in epoch 0, gen_loss = 0.758208157781225, disc_loss = 0.20467107226543774
Trained batch 416 in epoch 0, gen_loss = 0.758704031828782, disc_loss = 0.20425187072513415
Trained batch 417 in epoch 0, gen_loss = 0.7578775197552722, disc_loss = 0.20497485656407105
Trained batch 418 in epoch 0, gen_loss = 0.7590619893944633, disc_loss = 0.20511893052963412
Trained batch 419 in epoch 0, gen_loss = 0.7596382972030412, disc_loss = 0.20491971022094643
Trained batch 420 in epoch 0, gen_loss = 0.7595540791254428, disc_loss = 0.2046832052566058
Trained batch 421 in epoch 0, gen_loss = 0.7594003822142479, disc_loss = 0.2046864102638693
Trained batch 422 in epoch 0, gen_loss = 0.7597977509876234, disc_loss = 0.2042878149033262
Trained batch 423 in epoch 0, gen_loss = 0.7602750195787763, disc_loss = 0.20388916870886636
Trained batch 424 in epoch 0, gen_loss = 0.7607246455725502, disc_loss = 0.20351163629880722
Trained batch 425 in epoch 0, gen_loss = 0.7605251957413176, disc_loss = 0.20335864258860128
Trained batch 426 in epoch 0, gen_loss = 0.7600830720096338, disc_loss = 0.20325256567186648
Trained batch 427 in epoch 0, gen_loss = 0.7611445087556526, disc_loss = 0.20340402557288306
Trained batch 428 in epoch 0, gen_loss = 0.760884041761185, disc_loss = 0.20348167024109956
Trained batch 429 in epoch 0, gen_loss = 0.7603940075913141, disc_loss = 0.20357914110212477
Trained batch 430 in epoch 0, gen_loss = 0.7601971730693587, disc_loss = 0.20351878438456084
Trained batch 431 in epoch 0, gen_loss = 0.759875474911597, disc_loss = 0.20350920744197168
Trained batch 432 in epoch 0, gen_loss = 0.7592827229659497, disc_loss = 0.20360153965763833
Trained batch 433 in epoch 0, gen_loss = 0.7588922160973747, disc_loss = 0.20364939167984
Trained batch 434 in epoch 0, gen_loss = 0.75867061662948, disc_loss = 0.2035967865273699
Trained batch 435 in epoch 0, gen_loss = 0.7584651541135726, disc_loss = 0.20370855183050104
Trained batch 436 in epoch 0, gen_loss = 0.7574784993034206, disc_loss = 0.20380220414529335
Trained batch 437 in epoch 0, gen_loss = 0.7570879170883736, disc_loss = 0.2039076473338521
Trained batch 438 in epoch 0, gen_loss = 0.7565063667188744, disc_loss = 0.20391831159006152
Trained batch 439 in epoch 0, gen_loss = 0.7562511320818555, disc_loss = 0.20388695185115052
Trained batch 440 in epoch 0, gen_loss = 0.7560679544937584, disc_loss = 0.20400919436420106
Trained batch 441 in epoch 0, gen_loss = 0.7558204251177171, disc_loss = 0.2040124578102243
Trained batch 442 in epoch 0, gen_loss = 0.7558751628307403, disc_loss = 0.20393570524936808
Trained batch 443 in epoch 0, gen_loss = 0.7556375598048305, disc_loss = 0.2036681876052171
Trained batch 444 in epoch 0, gen_loss = 0.7550485022952048, disc_loss = 0.2037947411680322
Trained batch 445 in epoch 0, gen_loss = 0.7552437401405899, disc_loss = 0.20376706100591027
Trained batch 446 in epoch 0, gen_loss = 0.7554600478818753, disc_loss = 0.20345241102021214
Trained batch 447 in epoch 0, gen_loss = 0.75529871002904, disc_loss = 0.20328760563487386
Trained batch 448 in epoch 0, gen_loss = 0.7546625109451651, disc_loss = 0.20336459109762928
Trained batch 449 in epoch 0, gen_loss = 0.7546880410777198, disc_loss = 0.2034487565420568
Trained batch 450 in epoch 0, gen_loss = 0.7547261104351137, disc_loss = 0.20339387751694463
Trained batch 451 in epoch 0, gen_loss = 0.7545044846766817, disc_loss = 0.20320714466825984
Trained batch 452 in epoch 0, gen_loss = 0.7542821471527975, disc_loss = 0.20288271744577235
Trained batch 453 in epoch 0, gen_loss = 0.75368157875958, disc_loss = 0.20334343126224197
Trained batch 454 in epoch 0, gen_loss = 0.753893146606592, disc_loss = 0.20342285053210926
Trained batch 455 in epoch 0, gen_loss = 0.7540621258841272, disc_loss = 0.20342064645394617
Trained batch 456 in epoch 0, gen_loss = 0.7544729199007773, disc_loss = 0.20305890138964097
Trained batch 457 in epoch 0, gen_loss = 0.7541574967870546, disc_loss = 0.202984578783449
Trained batch 458 in epoch 0, gen_loss = 0.7543621750828488, disc_loss = 0.20264266948935966
Trained batch 459 in epoch 0, gen_loss = 0.7546229869775151, disc_loss = 0.20239784226590848
Trained batch 460 in epoch 0, gen_loss = 0.7545721328568821, disc_loss = 0.2023023038662146
Trained batch 461 in epoch 0, gen_loss = 0.7540869023247715, disc_loss = 0.2024295693364204
Trained batch 462 in epoch 0, gen_loss = 0.7538042773309588, disc_loss = 0.20253106776109975
Trained batch 463 in epoch 0, gen_loss = 0.7544750657960259, disc_loss = 0.2021999090311824
Trained batch 464 in epoch 0, gen_loss = 0.7545866989961234, disc_loss = 0.2017984617761867
Trained batch 465 in epoch 0, gen_loss = 0.7547744271453358, disc_loss = 0.20142302229448897
Trained batch 466 in epoch 0, gen_loss = 0.7552000349925978, disc_loss = 0.20105542272640436
Trained batch 467 in epoch 0, gen_loss = 0.754964383939902, disc_loss = 0.20090538506698596
Trained batch 468 in epoch 0, gen_loss = 0.7547479768170476, disc_loss = 0.20083549261085196
Trained batch 469 in epoch 0, gen_loss = 0.7553580620821486, disc_loss = 0.20105048149943033
Trained batch 470 in epoch 0, gen_loss = 0.7559410120398122, disc_loss = 0.20071571075699574
Trained batch 471 in epoch 0, gen_loss = 0.7553451190686832, disc_loss = 0.20052843674093926
Trained batch 472 in epoch 0, gen_loss = 0.7549255711457694, disc_loss = 0.2008556178012906
Trained batch 473 in epoch 0, gen_loss = 0.7552333802990773, disc_loss = 0.20077707336130965
Trained batch 474 in epoch 0, gen_loss = 0.7559581211366152, disc_loss = 0.20088809506477495
Trained batch 475 in epoch 0, gen_loss = 0.7560304037037016, disc_loss = 0.20050955968987227
Trained batch 476 in epoch 0, gen_loss = 0.7557294820464632, disc_loss = 0.20024636089294148
Trained batch 477 in epoch 0, gen_loss = 0.7563098553708407, disc_loss = 0.1999586989078281
Trained batch 478 in epoch 0, gen_loss = 0.7560064616556705, disc_loss = 0.1996352215334462
Trained batch 479 in epoch 0, gen_loss = 0.7561712213481466, disc_loss = 0.19925434125082878
Trained batch 480 in epoch 0, gen_loss = 0.7563609949888161, disc_loss = 0.1988577639544673
Trained batch 481 in epoch 0, gen_loss = 0.7568419321567685, disc_loss = 0.19850635880418896
Trained batch 482 in epoch 0, gen_loss = 0.7570004821687505, disc_loss = 0.19812995116139606
Trained batch 483 in epoch 0, gen_loss = 0.7572168467089164, disc_loss = 0.19774809020979345
Trained batch 484 in epoch 0, gen_loss = 0.7575843922256195, disc_loss = 0.19735833814694095
Trained batch 485 in epoch 0, gen_loss = 0.7577108859157367, disc_loss = 0.19697587985407422
Trained batch 486 in epoch 0, gen_loss = 0.7574766833312213, disc_loss = 0.19668685580609516
Trained batch 487 in epoch 0, gen_loss = 0.7580603188300719, disc_loss = 0.19638351792255876
Trained batch 488 in epoch 0, gen_loss = 0.7587097864331399, disc_loss = 0.19615882883469263
Trained batch 489 in epoch 0, gen_loss = 0.7593114982454144, disc_loss = 0.19583837264502535
Trained batch 490 in epoch 0, gen_loss = 0.7596104106810816, disc_loss = 0.19553046231205498
Trained batch 491 in epoch 0, gen_loss = 0.7605534433955099, disc_loss = 0.1951638199275405
Trained batch 492 in epoch 0, gen_loss = 0.7612780248538475, disc_loss = 0.19480873832127749
Trained batch 493 in epoch 0, gen_loss = 0.7621255802360141, disc_loss = 0.1944334978117091
Trained batch 494 in epoch 0, gen_loss = 0.763542125502018, disc_loss = 0.19407071549859312
Trained batch 495 in epoch 0, gen_loss = 0.7641515268553649, disc_loss = 0.19370749037742854
Trained batch 496 in epoch 0, gen_loss = 0.7652497807858696, disc_loss = 0.19336659741968337
Trained batch 497 in epoch 0, gen_loss = 0.7660080920381239, disc_loss = 0.19299858849286194
Trained batch 498 in epoch 0, gen_loss = 0.7670979206571598, disc_loss = 0.1926296992350616
Trained batch 499 in epoch 0, gen_loss = 0.7680360038876534, disc_loss = 0.19229668303206562
Trained batch 500 in epoch 0, gen_loss = 0.7688655577852817, disc_loss = 0.1919434788951022
Trained batch 501 in epoch 0, gen_loss = 0.7696963340281491, disc_loss = 0.19158131306048526
Trained batch 502 in epoch 0, gen_loss = 0.7709116121054169, disc_loss = 0.1912336510682023
Trained batch 503 in epoch 0, gen_loss = 0.7719720098825674, disc_loss = 0.19087380379261004
Trained batch 504 in epoch 0, gen_loss = 0.772740788802062, disc_loss = 0.19051440406111209
Trained batch 505 in epoch 0, gen_loss = 0.773289306184991, disc_loss = 0.1901493645236338
Trained batch 506 in epoch 0, gen_loss = 0.7741641831938801, disc_loss = 0.1897957825746674
Trained batch 507 in epoch 0, gen_loss = 0.7749244275642192, disc_loss = 0.18944198794582287
Trained batch 508 in epoch 0, gen_loss = 0.7757855373304813, disc_loss = 0.1890854800398112
Trained batch 509 in epoch 0, gen_loss = 0.7767471783885769, disc_loss = 0.18873131417979797
Trained batch 510 in epoch 0, gen_loss = 0.7776610245326727, disc_loss = 0.1883753594885892
Trained batch 511 in epoch 0, gen_loss = 0.778479055094067, disc_loss = 0.18802989899813838
Trained batch 512 in epoch 0, gen_loss = 0.7795286076924025, disc_loss = 0.18767972103525207
Trained batch 513 in epoch 0, gen_loss = 0.7804265041411619, disc_loss = 0.1873315728744238
Trained batch 514 in epoch 0, gen_loss = 0.7812775323113191, disc_loss = 0.18698863330505136
Trained batch 515 in epoch 0, gen_loss = 0.7819636942919834, disc_loss = 0.18666379481676765
Trained batch 516 in epoch 0, gen_loss = 0.7828175081390477, disc_loss = 0.1863156429346024
Trained batch 517 in epoch 0, gen_loss = 0.7835681547184248, disc_loss = 0.18597486826796156
Trained batch 518 in epoch 0, gen_loss = 0.7843323510161714, disc_loss = 0.18563456688191102
Trained batch 519 in epoch 0, gen_loss = 0.7850915127648757, disc_loss = 0.185290386995229
Trained batch 520 in epoch 0, gen_loss = 0.7858889238504897, disc_loss = 0.1849486693318025
Trained batch 521 in epoch 0, gen_loss = 0.7866069300535539, disc_loss = 0.18460371349206714
Trained batch 522 in epoch 0, gen_loss = 0.7871944569834788, disc_loss = 0.18426644075020834
Trained batch 523 in epoch 0, gen_loss = 0.7876648971711406, disc_loss = 0.18392728730584743
Trained batch 524 in epoch 0, gen_loss = 0.7881839196454911, disc_loss = 0.18359270936765132
Trained batch 525 in epoch 0, gen_loss = 0.7887399711649681, disc_loss = 0.18325433799795127
Trained batch 526 in epoch 0, gen_loss = 0.7893439328308576, disc_loss = 0.18292247544730214
Trained batch 527 in epoch 0, gen_loss = 0.7898627224406509, disc_loss = 0.18259500028921827
Trained batch 528 in epoch 0, gen_loss = 0.7907756425595238, disc_loss = 0.18227245123169625
Trained batch 529 in epoch 0, gen_loss = 0.7912717293455915, disc_loss = 0.18195251094194936
Trained batch 530 in epoch 0, gen_loss = 0.7921749410094964, disc_loss = 0.18163906657373755
Trained batch 531 in epoch 0, gen_loss = 0.7930965695278089, disc_loss = 0.18137884595960072
Trained batch 532 in epoch 0, gen_loss = 0.793545863474064, disc_loss = 0.18107160663155325
Trained batch 533 in epoch 0, gen_loss = 0.7941833833295308, disc_loss = 0.18076257658895623
Trained batch 534 in epoch 0, gen_loss = 0.7948167052781471, disc_loss = 0.18044427855845505
Trained batch 535 in epoch 0, gen_loss = 0.795258476718593, disc_loss = 0.18012664837279677
Trained batch 536 in epoch 0, gen_loss = 0.7959561599366491, disc_loss = 0.1798089042286869
Trained batch 537 in epoch 0, gen_loss = 0.7964293119743411, disc_loss = 0.17948567477006425
Trained batch 538 in epoch 0, gen_loss = 0.7967385860343148, disc_loss = 0.1791848170291114
Trained batch 539 in epoch 0, gen_loss = 0.7972822100475982, disc_loss = 0.1788689924809323
Trained batch 540 in epoch 0, gen_loss = 0.7978621773600799, disc_loss = 0.17855019163591668
Trained batch 541 in epoch 0, gen_loss = 0.7978994670939181, disc_loss = 0.17823119656993866
Trained batch 542 in epoch 0, gen_loss = 0.7975335793490788, disc_loss = 0.17836654161807994
Trained batch 543 in epoch 0, gen_loss = 0.7973374282283818, disc_loss = 0.17825973803872544
Trained batch 544 in epoch 0, gen_loss = 0.7988304221848829, disc_loss = 0.17833193297489383
Trained batch 545 in epoch 0, gen_loss = 0.7995251531238521, disc_loss = 0.17808132667363974
Trained batch 546 in epoch 0, gen_loss = 0.8000749775108079, disc_loss = 0.1777781165235589
Trained batch 547 in epoch 0, gen_loss = 0.8004656643436773, disc_loss = 0.17748051779055765
Trained batch 548 in epoch 0, gen_loss = 0.8004281550700113, disc_loss = 0.1771816639475633
Trained batch 549 in epoch 0, gen_loss = 0.8003924193707379, disc_loss = 0.17692452770319175
Trained batch 550 in epoch 0, gen_loss = 0.7999033656938106, disc_loss = 0.1771088671809681
Trained batch 551 in epoch 0, gen_loss = 0.800503741517879, disc_loss = 0.1771571731584592
Trained batch 552 in epoch 0, gen_loss = 0.8007840368135497, disc_loss = 0.17702010654798872
Trained batch 553 in epoch 0, gen_loss = 0.8005006988448787, disc_loss = 0.1769539357830404
Trained batch 554 in epoch 0, gen_loss = 0.8002938059536187, disc_loss = 0.17699040588880846
Trained batch 555 in epoch 0, gen_loss = 0.8003076073184288, disc_loss = 0.1768690387160591
Trained batch 556 in epoch 0, gen_loss = 0.8008251676546607, disc_loss = 0.17675330177788862
Trained batch 557 in epoch 0, gen_loss = 0.8008211354948713, disc_loss = 0.17648679926227043
Trained batch 558 in epoch 0, gen_loss = 0.8007537012983094, disc_loss = 0.1762047581039769
Trained batch 559 in epoch 0, gen_loss = 0.8008245208965881, disc_loss = 0.17594626553473064
Trained batch 560 in epoch 0, gen_loss = 0.8010920446080533, disc_loss = 0.17567084006775907
Trained batch 561 in epoch 0, gen_loss = 0.8014260304037787, disc_loss = 0.17538755197074676
Trained batch 562 in epoch 0, gen_loss = 0.8020801701405967, disc_loss = 0.17513609507086408
Trained batch 563 in epoch 0, gen_loss = 0.8024077488915294, disc_loss = 0.1748430688150478
Trained batch 564 in epoch 0, gen_loss = 0.8026755984378072, disc_loss = 0.1745573039067728
Trained batch 565 in epoch 0, gen_loss = 0.8033129734516986, disc_loss = 0.17426632282442608
Trained batch 566 in epoch 0, gen_loss = 0.8039347824280855, disc_loss = 0.1739749553370268
Trained batch 567 in epoch 0, gen_loss = 0.8045168780839779, disc_loss = 0.17368456925852488
Trained batch 568 in epoch 0, gen_loss = 0.8048265242723254, disc_loss = 0.1733966757157107
Trained batch 569 in epoch 0, gen_loss = 0.8052016762787836, disc_loss = 0.17310588667741078
Trained batch 570 in epoch 0, gen_loss = 0.8058003596896257, disc_loss = 0.1728440748826126
Trained batch 571 in epoch 0, gen_loss = 0.806273228065534, disc_loss = 0.17256309939760037
Trained batch 572 in epoch 0, gen_loss = 0.8066386047354127, disc_loss = 0.1722733265546396
Trained batch 573 in epoch 0, gen_loss = 0.807189589022344, disc_loss = 0.1719931900721913
Trained batch 574 in epoch 0, gen_loss = 0.8077559446770212, disc_loss = 0.17171828980841067
Trained batch 575 in epoch 0, gen_loss = 0.8085027631475694, disc_loss = 0.1714521599076559
Trained batch 576 in epoch 0, gen_loss = 0.8088876096276725, disc_loss = 0.17117144094628364
Trained batch 577 in epoch 0, gen_loss = 0.8092836218412359, disc_loss = 0.1708902949193383
Trained batch 578 in epoch 0, gen_loss = 0.8097012951481116, disc_loss = 0.17061102482456464
Trained batch 579 in epoch 0, gen_loss = 0.8101622164763254, disc_loss = 0.17032695438728893
Trained batch 580 in epoch 0, gen_loss = 0.8103649182799761, disc_loss = 0.17005783102992864
Trained batch 581 in epoch 0, gen_loss = 0.8109249601147019, disc_loss = 0.1697830548597967
Trained batch 582 in epoch 0, gen_loss = 0.8113868170598358, disc_loss = 0.16950430963619725
Trained batch 583 in epoch 0, gen_loss = 0.8118225219212982, disc_loss = 0.16922610766678564
Trained batch 584 in epoch 0, gen_loss = 0.8123366159761054, disc_loss = 0.16895358961505386
Trained batch 585 in epoch 0, gen_loss = 0.8128538359045575, disc_loss = 0.16868454038877512
Trained batch 586 in epoch 0, gen_loss = 0.8133792417723641, disc_loss = 0.16840922230302502
Trained batch 587 in epoch 0, gen_loss = 0.8137717542498291, disc_loss = 0.1681367695944536
Trained batch 588 in epoch 0, gen_loss = 0.8141881048881745, disc_loss = 0.1678727690441967
Trained batch 589 in epoch 0, gen_loss = 0.8145190337451838, disc_loss = 0.16760064391656068
Trained batch 590 in epoch 0, gen_loss = 0.8148670296882816, disc_loss = 0.16733112404683947
Trained batch 591 in epoch 0, gen_loss = 0.8152100628594289, disc_loss = 0.1670599696926483
Trained batch 592 in epoch 0, gen_loss = 0.815778312504191, disc_loss = 0.1667888132669974
Trained batch 593 in epoch 0, gen_loss = 0.8160096629199757, disc_loss = 0.1665173136607214
Trained batch 594 in epoch 0, gen_loss = 0.8163847131388527, disc_loss = 0.1662608047602933
Trained batch 595 in epoch 0, gen_loss = 0.8167602077326519, disc_loss = 0.16599176426640017
Trained batch 596 in epoch 0, gen_loss = 0.8172986421053933, disc_loss = 0.16572969327984968
Trained batch 597 in epoch 0, gen_loss = 0.817704010318753, disc_loss = 0.1654638316011972
Trained batch 598 in epoch 0, gen_loss = 0.8180350687647104, disc_loss = 0.16520998185540928
Trained batch 599 in epoch 0, gen_loss = 0.8182270345588525, disc_loss = 0.16494416982789215
Trained batch 600 in epoch 0, gen_loss = 0.8185568077492833, disc_loss = 0.16468591707992597
Trained batch 601 in epoch 0, gen_loss = 0.818841962966808, disc_loss = 0.16442174071900892
Trained batch 602 in epoch 0, gen_loss = 0.8192128461490619, disc_loss = 0.16415837900187963
Trained batch 603 in epoch 0, gen_loss = 0.8196829338835565, disc_loss = 0.16389684628352943
Trained batch 604 in epoch 0, gen_loss = 0.8200484514729051, disc_loss = 0.16363475299709715
Trained batch 605 in epoch 0, gen_loss = 0.8202921380796054, disc_loss = 0.16337368174735764
Trained batch 606 in epoch 0, gen_loss = 0.8207396261479944, disc_loss = 0.16311397440762213
Trained batch 607 in epoch 0, gen_loss = 0.8208567543739551, disc_loss = 0.16285284653330515
Trained batch 608 in epoch 0, gen_loss = 0.821227001096619, disc_loss = 0.16259224491869825
Trained batch 609 in epoch 0, gen_loss = 0.8217200744836057, disc_loss = 0.16233471985906361
Trained batch 610 in epoch 0, gen_loss = 0.821953032537685, disc_loss = 0.16207888260264247
Trained batch 611 in epoch 0, gen_loss = 0.822210507698698, disc_loss = 0.1618248450362848
Trained batch 612 in epoch 0, gen_loss = 0.8225677715915257, disc_loss = 0.16156972507409886
Trained batch 613 in epoch 0, gen_loss = 0.8229126851119902, disc_loss = 0.16131387521279217
Trained batch 614 in epoch 0, gen_loss = 0.8235194507168561, disc_loss = 0.16107415913081752
Trained batch 615 in epoch 0, gen_loss = 0.8238810667066605, disc_loss = 0.1608213142668768
Trained batch 616 in epoch 0, gen_loss = 0.8243732955216202, disc_loss = 0.16056959189903264
Trained batch 617 in epoch 0, gen_loss = 0.8247021907838031, disc_loss = 0.16031803593829178
Trained batch 618 in epoch 0, gen_loss = 0.8251811121989144, disc_loss = 0.16008236206411977
Trained batch 619 in epoch 0, gen_loss = 0.8255967000319112, disc_loss = 0.15983407028590238
Trained batch 620 in epoch 0, gen_loss = 0.825939018993178, disc_loss = 0.15958420898999282
Trained batch 621 in epoch 0, gen_loss = 0.8265224410119164, disc_loss = 0.15933782907077065
Trained batch 622 in epoch 0, gen_loss = 0.8268931335373445, disc_loss = 0.1590910021471305
Trained batch 623 in epoch 0, gen_loss = 0.827265131024596, disc_loss = 0.15884440897095303
Trained batch 624 in epoch 0, gen_loss = 0.8277638960361481, disc_loss = 0.15859819700792432
Trained batch 625 in epoch 0, gen_loss = 0.8282029101738153, disc_loss = 0.15835233202007726
Trained batch 626 in epoch 0, gen_loss = 0.828625912538936, disc_loss = 0.15811411369490946
Trained batch 627 in epoch 0, gen_loss = 0.8289858577832295, disc_loss = 0.1578716102862956
Trained batch 628 in epoch 0, gen_loss = 0.8293385581958843, disc_loss = 0.15762916563111334
Trained batch 629 in epoch 0, gen_loss = 0.8294919303958378, disc_loss = 0.1573868890248594
Trained batch 630 in epoch 0, gen_loss = 0.8297865566946625, disc_loss = 0.15714811145884416
Trained batch 631 in epoch 0, gen_loss = 0.8300048237831532, disc_loss = 0.15690456447744142
Trained batch 632 in epoch 0, gen_loss = 0.8303637593560874, disc_loss = 0.15666733618559373
Trained batch 633 in epoch 0, gen_loss = 0.8308533560308372, disc_loss = 0.15642651177653366
Trained batch 634 in epoch 0, gen_loss = 0.8310058169946896, disc_loss = 0.15618622105341318
Trained batch 635 in epoch 0, gen_loss = 0.8314707793248525, disc_loss = 0.15594789785305155
Trained batch 636 in epoch 0, gen_loss = 0.8316174192087991, disc_loss = 0.15570903885188503
Trained batch 637 in epoch 0, gen_loss = 0.8321683779125303, disc_loss = 0.15547990708810433
Trained batch 638 in epoch 0, gen_loss = 0.8325714578557649, disc_loss = 0.15524564339183214
Trained batch 639 in epoch 0, gen_loss = 0.832754883216694, disc_loss = 0.15501037896174238
Trained batch 640 in epoch 0, gen_loss = 0.8329715796175315, disc_loss = 0.1547744587799694
Trained batch 641 in epoch 0, gen_loss = 0.83344480260696, disc_loss = 0.15454423811099552
Trained batch 642 in epoch 0, gen_loss = 0.8334895719543771, disc_loss = 0.1543121095265162
Trained batch 643 in epoch 0, gen_loss = 0.8338395061422579, disc_loss = 0.15408266460781872
Trained batch 644 in epoch 0, gen_loss = 0.8343813817168391, disc_loss = 0.15387335696994045
Trained batch 645 in epoch 0, gen_loss = 0.8346978053681252, disc_loss = 0.15364204926579186
Trained batch 646 in epoch 0, gen_loss = 0.8350452564691281, disc_loss = 0.1534135720906333
Trained batch 647 in epoch 0, gen_loss = 0.8354070998360346, disc_loss = 0.1531875687640557
Trained batch 648 in epoch 0, gen_loss = 0.8356673734489317, disc_loss = 0.1529577088026396
Trained batch 649 in epoch 0, gen_loss = 0.8358997440796632, disc_loss = 0.15272921681941415
Trained batch 650 in epoch 0, gen_loss = 0.8362692878817632, disc_loss = 0.15250898309920366
Trained batch 651 in epoch 0, gen_loss = 0.8366860864809685, disc_loss = 0.15228212398635452
Trained batch 652 in epoch 0, gen_loss = 0.8370805236227115, disc_loss = 0.15205676506692758
Trained batch 653 in epoch 0, gen_loss = 0.8374651802151211, disc_loss = 0.15183346330178246
Trained batch 654 in epoch 0, gen_loss = 0.8378138151332623, disc_loss = 0.15161056407471366
Trained batch 655 in epoch 0, gen_loss = 0.8380190599709749, disc_loss = 0.15139260684195394
Trained batch 656 in epoch 0, gen_loss = 0.8381701174845616, disc_loss = 0.1511787899980347
Trained batch 657 in epoch 0, gen_loss = 0.8384673367608282, disc_loss = 0.1509556178648257
Trained batch 658 in epoch 0, gen_loss = 0.8386627418047018, disc_loss = 0.15074367162754565
Trained batch 659 in epoch 0, gen_loss = 0.8389428820122372, disc_loss = 0.15052580371336785
Trained batch 660 in epoch 0, gen_loss = 0.8391713211918743, disc_loss = 0.1503065190219522
Trained batch 661 in epoch 0, gen_loss = 0.8397372326732042, disc_loss = 0.15009080591714263
Trained batch 662 in epoch 0, gen_loss = 0.8401041985187415, disc_loss = 0.14987071645221367
Trained batch 663 in epoch 0, gen_loss = 0.840453143354999, disc_loss = 0.1496517580084598
Trained batch 664 in epoch 0, gen_loss = 0.8407675823322812, disc_loss = 0.14943228576164272
Trained batch 665 in epoch 0, gen_loss = 0.8410286725730868, disc_loss = 0.14921420799462018
Trained batch 666 in epoch 0, gen_loss = 0.8414147073093026, disc_loss = 0.14899846395153715
Trained batch 667 in epoch 0, gen_loss = 0.841794466320983, disc_loss = 0.14878145687234684
Trained batch 668 in epoch 0, gen_loss = 0.8420874542808675, disc_loss = 0.14856507496209467
Trained batch 669 in epoch 0, gen_loss = 0.8424709620315637, disc_loss = 0.1483500195931254
Trained batch 670 in epoch 0, gen_loss = 0.8427879998207803, disc_loss = 0.1481340003217919
Trained batch 671 in epoch 0, gen_loss = 0.8430227697161692, disc_loss = 0.14791987460505748
Trained batch 672 in epoch 0, gen_loss = 0.8433165358487422, disc_loss = 0.14771038688578123
Trained batch 673 in epoch 0, gen_loss = 0.8436066513157032, disc_loss = 0.14749961788904264
Trained batch 674 in epoch 0, gen_loss = 0.8438637365676739, disc_loss = 0.14728750671087593
Trained batch 675 in epoch 0, gen_loss = 0.8440670356507132, disc_loss = 0.1470760678260769
Trained batch 676 in epoch 0, gen_loss = 0.8446077357983132, disc_loss = 0.14691029677505948
Trained batch 677 in epoch 0, gen_loss = 0.8448789068291672, disc_loss = 0.14671066772346564
Trained batch 678 in epoch 0, gen_loss = 0.8451760582000413, disc_loss = 0.1465020162658286
Trained batch 679 in epoch 0, gen_loss = 0.8455907763365437, disc_loss = 0.14629500289858482
Trained batch 680 in epoch 0, gen_loss = 0.8460109383961878, disc_loss = 0.14608909584931953
Trained batch 681 in epoch 0, gen_loss = 0.8463590083496312, disc_loss = 0.14588121275480323
Trained batch 682 in epoch 0, gen_loss = 0.8466556906089252, disc_loss = 0.14567276710947077
Trained batch 683 in epoch 0, gen_loss = 0.8468479007395388, disc_loss = 0.14546524147552095
Trained batch 684 in epoch 0, gen_loss = 0.8471775300746417, disc_loss = 0.1452628932641751
Trained batch 685 in epoch 0, gen_loss = 0.8474334675177888, disc_loss = 0.14505794130906507
Trained batch 686 in epoch 0, gen_loss = 0.8476714736075728, disc_loss = 0.1448529358726846
Trained batch 687 in epoch 0, gen_loss = 0.8478216032042752, disc_loss = 0.14464820624426614
Trained batch 688 in epoch 0, gen_loss = 0.848229470420818, disc_loss = 0.14444491153188233
Trained batch 689 in epoch 0, gen_loss = 0.8485663630392241, disc_loss = 0.14424315280672434
Trained batch 690 in epoch 0, gen_loss = 0.8486578116454885, disc_loss = 0.14403978872413487
Trained batch 691 in epoch 0, gen_loss = 0.8489533380707565, disc_loss = 0.14384193758674052
Trained batch 692 in epoch 0, gen_loss = 0.8492386706205673, disc_loss = 0.14364081288890815
Trained batch 693 in epoch 0, gen_loss = 0.8494981072563946, disc_loss = 0.1434392444185526
Trained batch 694 in epoch 0, gen_loss = 0.849836031009825, disc_loss = 0.14323965207599906
Trained batch 695 in epoch 0, gen_loss = 0.8500867046244528, disc_loss = 0.14303944241650263
Trained batch 696 in epoch 0, gen_loss = 0.8502667065244837, disc_loss = 0.14283804640767178
Trained batch 697 in epoch 0, gen_loss = 0.8504287681214105, disc_loss = 0.14263958500946383
Trained batch 698 in epoch 0, gen_loss = 0.8506234311665247, disc_loss = 0.14244047698174445
Trained batch 699 in epoch 0, gen_loss = 0.8508513091717448, disc_loss = 0.14224114639418467
Trained batch 700 in epoch 0, gen_loss = 0.8509978380335891, disc_loss = 0.14204211424459595
Trained batch 701 in epoch 0, gen_loss = 0.8512548909143165, disc_loss = 0.1418443961059701
Trained batch 702 in epoch 0, gen_loss = 0.8512816280338537, disc_loss = 0.1416616695217661
Trained batch 703 in epoch 0, gen_loss = 0.8515068198215555, disc_loss = 0.14146627938515105
Trained batch 704 in epoch 0, gen_loss = 0.8517686120584501, disc_loss = 0.14127154116393298
Trained batch 705 in epoch 0, gen_loss = 0.8520346524104181, disc_loss = 0.14108105575225235
Trained batch 706 in epoch 0, gen_loss = 0.852162263981861, disc_loss = 0.1408853893302634
Trained batch 707 in epoch 0, gen_loss = 0.852196266548445, disc_loss = 0.1406940636192159
Trained batch 708 in epoch 0, gen_loss = 0.8525471254783894, disc_loss = 0.14050372468691177
Trained batch 709 in epoch 0, gen_loss = 0.8529549843408692, disc_loss = 0.14032935391993484
Trained batch 710 in epoch 0, gen_loss = 0.8530117535306097, disc_loss = 0.14014088519575119
Trained batch 711 in epoch 0, gen_loss = 0.8531551572462815, disc_loss = 0.1399528762519234
Trained batch 712 in epoch 0, gen_loss = 0.8532646071442715, disc_loss = 0.13976150439943738
Trained batch 713 in epoch 0, gen_loss = 0.8532456776925496, disc_loss = 0.1395706395323177
Trained batch 714 in epoch 0, gen_loss = 0.853544325053275, disc_loss = 0.13938302394113392
Trained batch 715 in epoch 0, gen_loss = 0.8538127347993452, disc_loss = 0.1391938022671491
Trained batch 716 in epoch 0, gen_loss = 0.853890239735195, disc_loss = 0.13900605485920056
Trained batch 717 in epoch 0, gen_loss = 0.8541746610635502, disc_loss = 0.13881776074186217
Trained batch 718 in epoch 0, gen_loss = 0.8545651299482593, disc_loss = 0.13863270574991535
Trained batch 719 in epoch 0, gen_loss = 0.8547186091128323, disc_loss = 0.13844578574838426
Trained batch 720 in epoch 0, gen_loss = 0.8549205937349185, disc_loss = 0.1382584610118191
Trained batch 721 in epoch 0, gen_loss = 0.8551249115668506, disc_loss = 0.13807238011693174
Trained batch 722 in epoch 0, gen_loss = 0.8553490620183747, disc_loss = 0.13788566013017506
Trained batch 723 in epoch 0, gen_loss = 0.8554455896026522, disc_loss = 0.13770057158531795
Trained batch 724 in epoch 0, gen_loss = 0.8556582062408842, disc_loss = 0.13751489368556388
Trained batch 725 in epoch 0, gen_loss = 0.855684357856916, disc_loss = 0.13732959282938545
Trained batch 726 in epoch 0, gen_loss = 0.8558527968690681, disc_loss = 0.13714468919837328
Trained batch 727 in epoch 0, gen_loss = 0.8559754614892242, disc_loss = 0.13696050969052262
Trained batch 728 in epoch 0, gen_loss = 0.8561658212105107, disc_loss = 0.13677652018139616
Trained batch 729 in epoch 0, gen_loss = 0.856374495690816, disc_loss = 0.13659221689146625
Trained batch 730 in epoch 0, gen_loss = 0.8565913225573815, disc_loss = 0.13641071135003666
Trained batch 731 in epoch 0, gen_loss = 0.8567455206982425, disc_loss = 0.13622726294717147
Trained batch 732 in epoch 0, gen_loss = 0.8569627425761698, disc_loss = 0.13604384834756172
Trained batch 733 in epoch 0, gen_loss = 0.8571434426616258, disc_loss = 0.13586204207809363
Trained batch 734 in epoch 0, gen_loss = 0.8574472154484314, disc_loss = 0.1356854041037308
Trained batch 735 in epoch 0, gen_loss = 0.8575969010834461, disc_loss = 0.13550570363788764
Trained batch 736 in epoch 0, gen_loss = 0.8577257286014195, disc_loss = 0.1353269061282166
Trained batch 737 in epoch 0, gen_loss = 0.8579767276520328, disc_loss = 0.13514797973476836
Trained batch 738 in epoch 0, gen_loss = 0.8582256198010038, disc_loss = 0.13497011288080532
Trained batch 739 in epoch 0, gen_loss = 0.8584036452947437, disc_loss = 0.1347927511150546
Trained batch 740 in epoch 0, gen_loss = 0.8583893983872474, disc_loss = 0.13461428003507578
Trained batch 741 in epoch 0, gen_loss = 0.8586312791488241, disc_loss = 0.13443634937287652
Trained batch 742 in epoch 0, gen_loss = 0.8587532420097418, disc_loss = 0.13425929261425393
Trained batch 743 in epoch 0, gen_loss = 0.8588111892903364, disc_loss = 0.13408290659626995
Trained batch 744 in epoch 0, gen_loss = 0.8588134827629832, disc_loss = 0.13390674537466526
Trained batch 745 in epoch 0, gen_loss = 0.8590624534971912, disc_loss = 0.1337315656298437
Trained batch 746 in epoch 0, gen_loss = 0.859143282155914, disc_loss = 0.13355612311414986
Trained batch 747 in epoch 0, gen_loss = 0.8591707956424371, disc_loss = 0.13338138560333693
Trained batch 748 in epoch 0, gen_loss = 0.859313470618588, disc_loss = 0.13320870581797967
Trained batch 749 in epoch 0, gen_loss = 0.8595637262264888, disc_loss = 0.1330350456731394
Trained batch 750 in epoch 0, gen_loss = 0.8598383847232188, disc_loss = 0.13286217313151952
Trained batch 751 in epoch 0, gen_loss = 0.8597967132846726, disc_loss = 0.1326907442098092
Trained batch 752 in epoch 0, gen_loss = 0.8599884772443201, disc_loss = 0.1325337653760124
Trained batch 753 in epoch 0, gen_loss = 0.8602084259376602, disc_loss = 0.1323638405618122
Trained batch 754 in epoch 0, gen_loss = 0.8603978109280794, disc_loss = 0.13219383160447987
Trained batch 755 in epoch 0, gen_loss = 0.8602441521312194, disc_loss = 0.1320521680637578
Trained batch 756 in epoch 0, gen_loss = 0.8602641460681371, disc_loss = 0.13192443496577166
Trained batch 757 in epoch 0, gen_loss = 0.860142430128397, disc_loss = 0.13181581199851064
Trained batch 758 in epoch 0, gen_loss = 0.8605919054295863, disc_loss = 0.1317422990653448
Trained batch 759 in epoch 0, gen_loss = 0.8609805116920095, disc_loss = 0.13162230360658692
Trained batch 760 in epoch 0, gen_loss = 0.8607918483433993, disc_loss = 0.13152278729765854
Trained batch 761 in epoch 0, gen_loss = 0.860577269841054, disc_loss = 0.13148944974623944
Trained batch 762 in epoch 0, gen_loss = 0.86115166560538, disc_loss = 0.13148912282686237
Trained batch 763 in epoch 0, gen_loss = 0.8613989572016356, disc_loss = 0.1313481499396474
Trained batch 764 in epoch 0, gen_loss = 0.8616589677489661, disc_loss = 0.13119219122850184
Trained batch 765 in epoch 0, gen_loss = 0.8616843846463659, disc_loss = 0.13102945650340478
Trained batch 766 in epoch 0, gen_loss = 0.8618345550095087, disc_loss = 0.13086935381873752
Trained batch 767 in epoch 0, gen_loss = 0.8617379946711784, disc_loss = 0.13071064367341023
Trained batch 768 in epoch 0, gen_loss = 0.8617572611190563, disc_loss = 0.1305507208085625
Trained batch 769 in epoch 0, gen_loss = 0.861823583152387, disc_loss = 0.13039515841020538
Trained batch 770 in epoch 0, gen_loss = 0.8618426525871113, disc_loss = 0.13024509401814396
Trained batch 771 in epoch 0, gen_loss = 0.8614993889483146, disc_loss = 0.13020431681100636
Trained batch 772 in epoch 0, gen_loss = 0.8615554202960041, disc_loss = 0.13036962116003412
Trained batch 773 in epoch 0, gen_loss = 0.8619805892077528, disc_loss = 0.13023744534444814
Trained batch 774 in epoch 0, gen_loss = 0.8622758371983805, disc_loss = 0.13008194308337426
Trained batch 775 in epoch 0, gen_loss = 0.8623381073096978, disc_loss = 0.12993345265942818
Trained batch 776 in epoch 0, gen_loss = 0.8623435187754024, disc_loss = 0.1298088754010069
Trained batch 777 in epoch 0, gen_loss = 0.8630329835154403, disc_loss = 0.12965473312265682
Trained batch 778 in epoch 0, gen_loss = 0.8633960118572275, disc_loss = 0.1295017980141338
Trained batch 779 in epoch 0, gen_loss = 0.8637453533518009, disc_loss = 0.12935229231310913
Trained batch 780 in epoch 0, gen_loss = 0.864025899336677, disc_loss = 0.12919372647598854
Trained batch 781 in epoch 0, gen_loss = 0.8642364359648941, disc_loss = 0.1290372330132667
Trained batch 782 in epoch 0, gen_loss = 0.8643935427431251, disc_loss = 0.12887756668339279
Trained batch 783 in epoch 0, gen_loss = 0.8647769887608533, disc_loss = 0.12871992887604783
Trained batch 784 in epoch 0, gen_loss = 0.8648348494320158, disc_loss = 0.12856255782038495
Trained batch 785 in epoch 0, gen_loss = 0.8649970897812274, disc_loss = 0.12840587993859817
Trained batch 786 in epoch 0, gen_loss = 0.8652104378276738, disc_loss = 0.1282501831207557
Trained batch 787 in epoch 0, gen_loss = 0.8654258570014522, disc_loss = 0.12809451521689846
Trained batch 788 in epoch 0, gen_loss = 0.8654688789741772, disc_loss = 0.12793897214128444
Trained batch 789 in epoch 0, gen_loss = 0.8658014336341544, disc_loss = 0.12778212790925622
Trained batch 790 in epoch 0, gen_loss = 0.8660038692685958, disc_loss = 0.12762628098115014
Trained batch 791 in epoch 0, gen_loss = 0.8661577896111541, disc_loss = 0.12747913755792795
Trained batch 792 in epoch 0, gen_loss = 0.866492958004207, disc_loss = 0.1273258699255104
Trained batch 793 in epoch 0, gen_loss = 0.8667532465695134, disc_loss = 0.12717489172588395
Trained batch 794 in epoch 0, gen_loss = 0.8671477991455007, disc_loss = 0.12702392369432597
Trained batch 795 in epoch 0, gen_loss = 0.8673650294766954, disc_loss = 0.12687023425323832
Trained batch 796 in epoch 0, gen_loss = 0.867436774065683, disc_loss = 0.12671712847044422
Trained batch 797 in epoch 0, gen_loss = 0.8675666603453476, disc_loss = 0.1265658089108555
Trained batch 798 in epoch 0, gen_loss = 0.8671296498130946, disc_loss = 0.12675235321592582
Trained batch 799 in epoch 0, gen_loss = 0.8676185420528054, disc_loss = 0.12689597574033543
Trained batch 800 in epoch 0, gen_loss = 0.8676461691639099, disc_loss = 0.12686974545923316
Trained batch 801 in epoch 0, gen_loss = 0.867228989626404, disc_loss = 0.12692105744999052
Trained batch 802 in epoch 0, gen_loss = 0.8672389174680484, disc_loss = 0.12681075121951085
Trained batch 803 in epoch 0, gen_loss = 0.8670391840350569, disc_loss = 0.12672574166179545
Trained batch 804 in epoch 0, gen_loss = 0.8668509501477947, disc_loss = 0.12675336342484267
Trained batch 805 in epoch 0, gen_loss = 0.8669369973926331, disc_loss = 0.12665885089689788
Trained batch 806 in epoch 0, gen_loss = 0.8667152279888682, disc_loss = 0.12656627259796538
Trained batch 807 in epoch 0, gen_loss = 0.8669107813424993, disc_loss = 0.12646202411068058
Trained batch 808 in epoch 0, gen_loss = 0.8672209098769355, disc_loss = 0.12633147730252606
Trained batch 809 in epoch 0, gen_loss = 0.8670930508110258, disc_loss = 0.12621532169912286
Trained batch 810 in epoch 0, gen_loss = 0.8667150780319727, disc_loss = 0.12620664046159755
Trained batch 811 in epoch 0, gen_loss = 0.867044395303785, disc_loss = 0.12629697105722282
Trained batch 812 in epoch 0, gen_loss = 0.8672216938943734, disc_loss = 0.12618133587433944
Trained batch 813 in epoch 0, gen_loss = 0.8672009750065698, disc_loss = 0.12606577471748717
Trained batch 814 in epoch 0, gen_loss = 0.8671570449884684, disc_loss = 0.12594667886086722
Trained batch 815 in epoch 0, gen_loss = 0.8672979177870587, disc_loss = 0.1258068699489562
Trained batch 816 in epoch 0, gen_loss = 0.8673387494854711, disc_loss = 0.12570378413301925
Trained batch 817 in epoch 0, gen_loss = 0.8671922201705153, disc_loss = 0.12560701046524966
Trained batch 818 in epoch 0, gen_loss = 0.8674180716167003, disc_loss = 0.1255733404494481
Trained batch 819 in epoch 0, gen_loss = 0.8674904301035695, disc_loss = 0.12543204204241815
Trained batch 820 in epoch 0, gen_loss = 0.8674024052727383, disc_loss = 0.12529708961638578
Trained batch 821 in epoch 0, gen_loss = 0.8670490166204109, disc_loss = 0.12547879014589083
Trained batch 822 in epoch 0, gen_loss = 0.8673107371657616, disc_loss = 0.12603427648271592
Trained batch 823 in epoch 0, gen_loss = 0.8672313037355548, disc_loss = 0.12621643961360904
Trained batch 824 in epoch 0, gen_loss = 0.8668545512358348, disc_loss = 0.1263211787940765
Trained batch 825 in epoch 0, gen_loss = 0.8665712626231497, disc_loss = 0.12635903016435204
Trained batch 826 in epoch 0, gen_loss = 0.8666095637424681, disc_loss = 0.12628365871316316
Trained batch 827 in epoch 0, gen_loss = 0.8665055416992321, disc_loss = 0.12617257894506084
Trained batch 828 in epoch 0, gen_loss = 0.8662520333926842, disc_loss = 0.12608281562281198
Trained batch 829 in epoch 0, gen_loss = 0.8663373710520296, disc_loss = 0.12610198911700218
Trained batch 830 in epoch 0, gen_loss = 0.8657959989046792, disc_loss = 0.1263859062447189
Trained batch 831 in epoch 0, gen_loss = 0.8660863260738552, disc_loss = 0.12683045264762208
Trained batch 832 in epoch 0, gen_loss = 0.8658129770715698, disc_loss = 0.12700768352412403
Trained batch 833 in epoch 0, gen_loss = 0.8655427778296048, disc_loss = 0.12720962918203824
Trained batch 834 in epoch 0, gen_loss = 0.8652020151386718, disc_loss = 0.1275020623521065
Trained batch 835 in epoch 0, gen_loss = 0.8647704150474242, disc_loss = 0.12770720227910026
Trained batch 836 in epoch 0, gen_loss = 0.8646172052571993, disc_loss = 0.1278783927069089
Trained batch 837 in epoch 0, gen_loss = 0.8643117001844761, disc_loss = 0.12798703506979026
Trained batch 838 in epoch 0, gen_loss = 0.8639882039611757, disc_loss = 0.12808382945136346
Trained batch 839 in epoch 0, gen_loss = 0.8636893736109847, disc_loss = 0.12820046225401927
Trained batch 840 in epoch 0, gen_loss = 0.8635961970803854, disc_loss = 0.1283205905007298
Trained batch 841 in epoch 0, gen_loss = 0.8631393121922667, disc_loss = 0.1284984526533585
Trained batch 842 in epoch 0, gen_loss = 0.8627414128180784, disc_loss = 0.12863058018584295
Trained batch 843 in epoch 0, gen_loss = 0.862483490028935, disc_loss = 0.12875669603804302
Trained batch 844 in epoch 0, gen_loss = 0.8621407950770925, disc_loss = 0.12888477471734247
Trained batch 845 in epoch 0, gen_loss = 0.8619011585241796, disc_loss = 0.12895853816334546
Trained batch 846 in epoch 0, gen_loss = 0.8616251721362437, disc_loss = 0.12906529027567307
Trained batch 847 in epoch 0, gen_loss = 0.8612434526307965, disc_loss = 0.12917455024594432
Trained batch 848 in epoch 0, gen_loss = 0.8609184493937116, disc_loss = 0.12924975139863384
Trained batch 849 in epoch 0, gen_loss = 0.8606088049622143, disc_loss = 0.12931099138469163
Trained batch 850 in epoch 0, gen_loss = 0.8602710286052471, disc_loss = 0.12940843234119934
Trained batch 851 in epoch 0, gen_loss = 0.8599699212701668, disc_loss = 0.12951360785204505
Trained batch 852 in epoch 0, gen_loss = 0.8597026911388388, disc_loss = 0.1296150076319327
Trained batch 853 in epoch 0, gen_loss = 0.8593017173106553, disc_loss = 0.129763191655023
Trained batch 854 in epoch 0, gen_loss = 0.859113907082039, disc_loss = 0.12983214589168063
Trained batch 855 in epoch 0, gen_loss = 0.8587413420813663, disc_loss = 0.12994532536679365
Trained batch 856 in epoch 0, gen_loss = 0.8584245826218759, disc_loss = 0.13005812581527496
Trained batch 857 in epoch 0, gen_loss = 0.8583940975107514, disc_loss = 0.13018009668115163
Trained batch 858 in epoch 0, gen_loss = 0.8580932165122005, disc_loss = 0.13032947691201913
Trained batch 859 in epoch 0, gen_loss = 0.858099184306555, disc_loss = 0.1304853488948348
Trained batch 860 in epoch 0, gen_loss = 0.8577346696186288, disc_loss = 0.1305693891675522
Trained batch 861 in epoch 0, gen_loss = 0.8573601168089843, disc_loss = 0.13063002743119734
Trained batch 862 in epoch 0, gen_loss = 0.8571791200275908, disc_loss = 0.13075870150071056
Trained batch 863 in epoch 0, gen_loss = 0.8568326551122246, disc_loss = 0.13093105371350516
Trained batch 864 in epoch 0, gen_loss = 0.8565365786841839, disc_loss = 0.1310428278011975
Trained batch 865 in epoch 0, gen_loss = 0.8563516381912915, disc_loss = 0.13111877701848565
Trained batch 866 in epoch 0, gen_loss = 0.8560770522833145, disc_loss = 0.13120974693742754
Trained batch 867 in epoch 0, gen_loss = 0.8557889143236771, disc_loss = 0.13131927956976125
Trained batch 868 in epoch 0, gen_loss = 0.8553820590909798, disc_loss = 0.13141354603582503
Trained batch 869 in epoch 0, gen_loss = 0.8551193143101944, disc_loss = 0.13151096996835207
Trained batch 870 in epoch 0, gen_loss = 0.8547519783133344, disc_loss = 0.1315938116858011
Trained batch 871 in epoch 0, gen_loss = 0.8544939286460024, disc_loss = 0.13169878627864617
Trained batch 872 in epoch 0, gen_loss = 0.8541952850550993, disc_loss = 0.13180243867163557
Trained batch 873 in epoch 0, gen_loss = 0.853869175985967, disc_loss = 0.13191314031997614
Trained batch 874 in epoch 0, gen_loss = 0.8536946228912898, disc_loss = 0.13202210696014974
Trained batch 875 in epoch 0, gen_loss = 0.8534016199239857, disc_loss = 0.13210458530205596
Trained batch 876 in epoch 0, gen_loss = 0.8530224596692871, disc_loss = 0.13216845688416476
Trained batch 877 in epoch 0, gen_loss = 0.8529482436682477, disc_loss = 0.13229402226575168
Trained batch 878 in epoch 0, gen_loss = 0.8526750053358566, disc_loss = 0.13236997315296703
Trained batch 879 in epoch 0, gen_loss = 0.8524446330625902, disc_loss = 0.1323862988223978
Trained batch 880 in epoch 0, gen_loss = 0.852254361184853, disc_loss = 0.13243432248896042
Trained batch 881 in epoch 0, gen_loss = 0.8516463170043466, disc_loss = 0.13256974513837835
Trained batch 882 in epoch 0, gen_loss = 0.8511846045270511, disc_loss = 0.13264091036731793
Trained batch 883 in epoch 0, gen_loss = 0.8511763803694583, disc_loss = 0.13284871011431965
Trained batch 884 in epoch 0, gen_loss = 0.8510106523831685, disc_loss = 0.1329399548236828
Trained batch 885 in epoch 0, gen_loss = 0.8506239960075233, disc_loss = 0.13308338823220556
Trained batch 886 in epoch 0, gen_loss = 0.8504712916280667, disc_loss = 0.13316740489327544
Trained batch 887 in epoch 0, gen_loss = 0.8500343790059691, disc_loss = 0.13330015082616015
Trained batch 888 in epoch 0, gen_loss = 0.8497461317896977, disc_loss = 0.13339495178415775
Trained batch 889 in epoch 0, gen_loss = 0.8495828773868218, disc_loss = 0.1334687105283204
Trained batch 890 in epoch 0, gen_loss = 0.8492048619572161, disc_loss = 0.13360616791126864
Trained batch 891 in epoch 0, gen_loss = 0.8488484758031742, disc_loss = 0.1336632643639937
Trained batch 892 in epoch 0, gen_loss = 0.8485372936204993, disc_loss = 0.13368204296702124
Trained batch 893 in epoch 0, gen_loss = 0.8482758980869447, disc_loss = 0.13373020708626573
Trained batch 894 in epoch 0, gen_loss = 0.8481354925219573, disc_loss = 0.13382850609610492
Trained batch 895 in epoch 0, gen_loss = 0.8476786743849516, disc_loss = 0.13399511839062533
Trained batch 896 in epoch 0, gen_loss = 0.8476068217353013, disc_loss = 0.13413298645611216
Trained batch 897 in epoch 0, gen_loss = 0.8473402308860175, disc_loss = 0.13419634130921315
Trained batch 898 in epoch 0, gen_loss = 0.8470869933537832, disc_loss = 0.13432441486664182
Trained batch 899 in epoch 0, gen_loss = 0.8467771770556768, disc_loss = 0.1344014559414548
Trained batch 900 in epoch 0, gen_loss = 0.8466693914426153, disc_loss = 0.13448431904915592
Trained batch 901 in epoch 0, gen_loss = 0.8464914087181346, disc_loss = 0.1345986196306119
Trained batch 902 in epoch 0, gen_loss = 0.8460790266758316, disc_loss = 0.13471585276777984
Trained batch 903 in epoch 0, gen_loss = 0.8460463881492615, disc_loss = 0.1347925942450395
Trained batch 904 in epoch 0, gen_loss = 0.8460304440055763, disc_loss = 0.13482802240821168
Trained batch 905 in epoch 0, gen_loss = 0.8455387526592671, disc_loss = 0.13504795046501628
Trained batch 906 in epoch 0, gen_loss = 0.8453486244037106, disc_loss = 0.1351935362138877
Trained batch 907 in epoch 0, gen_loss = 0.8452517019691447, disc_loss = 0.13522836522251525
Trained batch 908 in epoch 0, gen_loss = 0.8449933697747187, disc_loss = 0.13537808927109032
Trained batch 909 in epoch 0, gen_loss = 0.8447272191008369, disc_loss = 0.13548357764049176
Trained batch 910 in epoch 0, gen_loss = 0.8444173518245228, disc_loss = 0.13549794806867765
Trained batch 911 in epoch 0, gen_loss = 0.8440095031666651, disc_loss = 0.13561714722202037
Trained batch 912 in epoch 0, gen_loss = 0.843791656041067, disc_loss = 0.1357393316403827
Trained batch 913 in epoch 0, gen_loss = 0.8435663756643396, disc_loss = 0.13577545098975685
Trained batch 914 in epoch 0, gen_loss = 0.8432496870476041, disc_loss = 0.1359082095831368
Trained batch 915 in epoch 0, gen_loss = 0.8430298468887025, disc_loss = 0.13598930369427134
Trained batch 916 in epoch 0, gen_loss = 0.8430076991913753, disc_loss = 0.1360953516073448
Trained batch 917 in epoch 0, gen_loss = 0.8427174000763425, disc_loss = 0.13617589005521724
Trained batch 918 in epoch 0, gen_loss = 0.84244086514749, disc_loss = 0.13622957580495865
Trained batch 919 in epoch 0, gen_loss = 0.8421647070218687, disc_loss = 0.13633189235950577
Trained batch 920 in epoch 0, gen_loss = 0.8417976467863098, disc_loss = 0.13643538839199926
Trained batch 921 in epoch 0, gen_loss = 0.8415963209826103, disc_loss = 0.1365116723828773
Trained batch 922 in epoch 0, gen_loss = 0.8412771251775074, disc_loss = 0.13655029772225877
Trained batch 923 in epoch 0, gen_loss = 0.8410602333548265, disc_loss = 0.13662162443065565
Trained batch 924 in epoch 0, gen_loss = 0.8410202194226755, disc_loss = 0.13667145517000273
Trained batch 925 in epoch 0, gen_loss = 0.8407384573319046, disc_loss = 0.13676481416170358
Trained batch 926 in epoch 0, gen_loss = 0.8403886899657491, disc_loss = 0.13686399397082594
Trained batch 927 in epoch 0, gen_loss = 0.8401467753574252, disc_loss = 0.13695616038001326
Trained batch 928 in epoch 0, gen_loss = 0.8400495552464886, disc_loss = 0.13705650598098462
Trained batch 929 in epoch 0, gen_loss = 0.8397194504417399, disc_loss = 0.1371391754695064
Trained batch 930 in epoch 0, gen_loss = 0.839503350530608, disc_loss = 0.137202253376877
Trained batch 931 in epoch 0, gen_loss = 0.8395696590962328, disc_loss = 0.1373354045995471
Trained batch 932 in epoch 0, gen_loss = 0.8391694989362841, disc_loss = 0.13746589585706503
Trained batch 933 in epoch 0, gen_loss = 0.838866340271666, disc_loss = 0.13752219876014216
Trained batch 934 in epoch 0, gen_loss = 0.8385254575606973, disc_loss = 0.13759899128821085
Trained batch 935 in epoch 0, gen_loss = 0.8383175982241957, disc_loss = 0.13766627830953704
Trained batch 936 in epoch 0, gen_loss = 0.8382707495826794, disc_loss = 0.137790525630027
Trained batch 937 in epoch 0, gen_loss = 0.8380326324942778, disc_loss = 0.1378022067162937
Trained batch 938 in epoch 0, gen_loss = 0.8377464029608697, disc_loss = 0.13787163866022295
Trained batch 939 in epoch 0, gen_loss = 0.8376062205497254, disc_loss = 0.13795914704430887
Trained batch 940 in epoch 0, gen_loss = 0.8376313248425564, disc_loss = 0.13799728276371345
Trained batch 941 in epoch 0, gen_loss = 0.8372859195539146, disc_loss = 0.1381134888384147
Trained batch 942 in epoch 0, gen_loss = 0.8372418383019853, disc_loss = 0.1381487514118023
Trained batch 943 in epoch 0, gen_loss = 0.8369787502086768, disc_loss = 0.13822289356361026
Trained batch 944 in epoch 0, gen_loss = 0.8366903518242811, disc_loss = 0.13834708035558896
Trained batch 945 in epoch 0, gen_loss = 0.836432292458875, disc_loss = 0.13845015314617343
Trained batch 946 in epoch 0, gen_loss = 0.8361996642639418, disc_loss = 0.13849101452980045
Trained batch 947 in epoch 0, gen_loss = 0.8360652323765091, disc_loss = 0.13855187985274886
Trained batch 948 in epoch 0, gen_loss = 0.8359194874009794, disc_loss = 0.13863190856823077
Trained batch 949 in epoch 0, gen_loss = 0.8357117379966535, disc_loss = 0.13864226316714562
Trained batch 950 in epoch 0, gen_loss = 0.835302041093383, disc_loss = 0.13884844643271457
Trained batch 951 in epoch 0, gen_loss = 0.8351143238549473, disc_loss = 0.1389154192241703
Trained batch 952 in epoch 0, gen_loss = 0.8350073830278323, disc_loss = 0.1389737311740389
Trained batch 953 in epoch 0, gen_loss = 0.8347051559129351, disc_loss = 0.13899825428016055
Trained batch 954 in epoch 0, gen_loss = 0.8344389331278377, disc_loss = 0.1390115944714973
Trained batch 955 in epoch 0, gen_loss = 0.8344079788509273, disc_loss = 0.1391410004855601
Trained batch 956 in epoch 0, gen_loss = 0.8344841746451838, disc_loss = 0.13913208021015483
Trained batch 957 in epoch 0, gen_loss = 0.8342619359119949, disc_loss = 0.1391964754406149
Trained batch 958 in epoch 0, gen_loss = 0.8341693513957751, disc_loss = 0.13918477833456513
Trained batch 959 in epoch 0, gen_loss = 0.8342582280437152, disc_loss = 0.1392176594020081
Trained batch 960 in epoch 0, gen_loss = 0.8340111333299254, disc_loss = 0.1392463032332124
Trained batch 961 in epoch 0, gen_loss = 0.8337077064102751, disc_loss = 0.1394314794796819
Trained batch 962 in epoch 0, gen_loss = 0.8336156698278425, disc_loss = 0.13962258920552226
Trained batch 963 in epoch 0, gen_loss = 0.833750329818963, disc_loss = 0.13959875411264158
Trained batch 964 in epoch 0, gen_loss = 0.8334361912055337, disc_loss = 0.13982634784272568
Trained batch 965 in epoch 0, gen_loss = 0.8331520545680083, disc_loss = 0.13987093146357255
Trained batch 966 in epoch 0, gen_loss = 0.8329521015733327, disc_loss = 0.13997048818151878
Trained batch 967 in epoch 0, gen_loss = 0.8326793140616299, disc_loss = 0.14004615497797504
Trained batch 968 in epoch 0, gen_loss = 0.832342198820183, disc_loss = 0.14014656314846433
Trained batch 969 in epoch 0, gen_loss = 0.8321126152559654, disc_loss = 0.1401978071872625
Trained batch 970 in epoch 0, gen_loss = 0.831906753207579, disc_loss = 0.14024798621722792
Trained batch 971 in epoch 0, gen_loss = 0.8318957837888733, disc_loss = 0.14019732164011103
Trained batch 972 in epoch 0, gen_loss = 0.8313918117690307, disc_loss = 0.14026253932119295
Trained batch 973 in epoch 0, gen_loss = 0.8313859848332356, disc_loss = 0.14026263347579246
Trained batch 974 in epoch 0, gen_loss = 0.8310157749286065, disc_loss = 0.1403185351133251
Trained batch 975 in epoch 0, gen_loss = 0.8308670753155087, disc_loss = 0.14034578077982707
Trained batch 976 in epoch 0, gen_loss = 0.8306052938271448, disc_loss = 0.14033971669485062
Trained batch 977 in epoch 0, gen_loss = 0.8302461603363112, disc_loss = 0.14039117142587618
Trained batch 978 in epoch 0, gen_loss = 0.8297804445789345, disc_loss = 0.14047372535007138
Trained batch 979 in epoch 0, gen_loss = 0.8295884441052165, disc_loss = 0.14054147393361913
Trained batch 980 in epoch 0, gen_loss = 0.8295351402657477, disc_loss = 0.14067330758018984
Trained batch 981 in epoch 0, gen_loss = 0.8295282951865323, disc_loss = 0.1406066314259908
Trained batch 982 in epoch 0, gen_loss = 0.8291420350542874, disc_loss = 0.14085270972786962
Trained batch 983 in epoch 0, gen_loss = 0.8290281422678533, disc_loss = 0.14097728820047264
Trained batch 984 in epoch 0, gen_loss = 0.8289220580292233, disc_loss = 0.14099967206431185
Trained batch 985 in epoch 0, gen_loss = 0.8287461518213667, disc_loss = 0.14106558371145414
Trained batch 986 in epoch 0, gen_loss = 0.8285287329672317, disc_loss = 0.14107273685653424
Trained batch 987 in epoch 0, gen_loss = 0.8284013695140117, disc_loss = 0.14115571739460314
Trained batch 988 in epoch 0, gen_loss = 0.8285600876603256, disc_loss = 0.14114135579644874
Trained batch 989 in epoch 0, gen_loss = 0.8283677648715299, disc_loss = 0.1411090485655204
Trained batch 990 in epoch 0, gen_loss = 0.8280974250929628, disc_loss = 0.14119545984369497
Trained batch 991 in epoch 0, gen_loss = 0.8282389675357169, disc_loss = 0.14130457963643317
Trained batch 992 in epoch 0, gen_loss = 0.828048698101399, disc_loss = 0.14133921714076605
Trained batch 993 in epoch 0, gen_loss = 0.8277949507027804, disc_loss = 0.1414179559513623
Trained batch 994 in epoch 0, gen_loss = 0.8277229465731424, disc_loss = 0.14138357114940694
Trained batch 995 in epoch 0, gen_loss = 0.8274942087420977, disc_loss = 0.1414474252754931
Trained batch 996 in epoch 0, gen_loss = 0.8275790893983698, disc_loss = 0.14165861678726357
Trained batch 997 in epoch 0, gen_loss = 0.8274584341204477, disc_loss = 0.14169046873826802
Trained batch 998 in epoch 0, gen_loss = 0.8272559585812332, disc_loss = 0.14170925090769054
Trained batch 999 in epoch 0, gen_loss = 0.8268992393910884, disc_loss = 0.14182411822467111
Trained batch 1000 in epoch 0, gen_loss = 0.8267326961447309, disc_loss = 0.14189533168588625
Trained batch 1001 in epoch 0, gen_loss = 0.8264636310810101, disc_loss = 0.14193765534819502
Trained batch 1002 in epoch 0, gen_loss = 0.8262026941372176, disc_loss = 0.14201004419671714
Trained batch 1003 in epoch 0, gen_loss = 0.8260271892663967, disc_loss = 0.1420642508403027
Trained batch 1004 in epoch 0, gen_loss = 0.8258223949676723, disc_loss = 0.14213833951029872
Trained batch 1005 in epoch 0, gen_loss = 0.8257987887615238, disc_loss = 0.14223674712698003
Trained batch 1006 in epoch 0, gen_loss = 0.8254759703811846, disc_loss = 0.14226200591930943
Trained batch 1007 in epoch 0, gen_loss = 0.8252130279406196, disc_loss = 0.14231643865475366
Trained batch 1008 in epoch 0, gen_loss = 0.8249725761156016, disc_loss = 0.1423839808257557
Trained batch 1009 in epoch 0, gen_loss = 0.8249833888641679, disc_loss = 0.14242769969364463
Trained batch 1010 in epoch 0, gen_loss = 0.8247895590098746, disc_loss = 0.14258940684246166
Trained batch 1011 in epoch 0, gen_loss = 0.8244731670370686, disc_loss = 0.14274714156601526
Trained batch 1012 in epoch 0, gen_loss = 0.824538388792407, disc_loss = 0.14294109063021662
Trained batch 1013 in epoch 0, gen_loss = 0.8244226357111564, disc_loss = 0.14305608773753745
Trained batch 1014 in epoch 0, gen_loss = 0.8242266106781702, disc_loss = 0.1431412552504025
Trained batch 1015 in epoch 0, gen_loss = 0.8241467608769578, disc_loss = 0.1432257195928695
Trained batch 1016 in epoch 0, gen_loss = 0.8239182724068884, disc_loss = 0.143265260998645
Trained batch 1017 in epoch 0, gen_loss = 0.8238558611431852, disc_loss = 0.14332260399089838
Trained batch 1018 in epoch 0, gen_loss = 0.8235676790184548, disc_loss = 0.1434251060204396
Trained batch 1019 in epoch 0, gen_loss = 0.823450951862569, disc_loss = 0.143540593556028
Trained batch 1020 in epoch 0, gen_loss = 0.8230851534006061, disc_loss = 0.14364260955928962
Trained batch 1021 in epoch 0, gen_loss = 0.8229209804896506, disc_loss = 0.143664594657433
Trained batch 1022 in epoch 0, gen_loss = 0.8226492100505418, disc_loss = 0.14372191014963648
Trained batch 1023 in epoch 0, gen_loss = 0.8222973558586091, disc_loss = 0.1437674652095211
Trained batch 1024 in epoch 0, gen_loss = 0.8219876829007777, disc_loss = 0.14381322937563243
Trained batch 1025 in epoch 0, gen_loss = 0.8219623011455202, disc_loss = 0.14385418868174352
Trained batch 1026 in epoch 0, gen_loss = 0.8217491262611419, disc_loss = 0.14388342327737552
Trained batch 1027 in epoch 0, gen_loss = 0.821431517050192, disc_loss = 0.1439716268585839
Trained batch 1028 in epoch 0, gen_loss = 0.8213812756063408, disc_loss = 0.1440081138748031
Trained batch 1029 in epoch 0, gen_loss = 0.8212567757344941, disc_loss = 0.14405866508141557
Trained batch 1030 in epoch 0, gen_loss = 0.821020456596443, disc_loss = 0.1442408232444267
Trained batch 1031 in epoch 0, gen_loss = 0.8209252974032893, disc_loss = 0.14440762375588817
Trained batch 1032 in epoch 0, gen_loss = 0.8207237997163531, disc_loss = 0.14450022054404302
Trained batch 1033 in epoch 0, gen_loss = 0.8204280963199974, disc_loss = 0.14461963825316007
Trained batch 1034 in epoch 0, gen_loss = 0.8203329705097825, disc_loss = 0.14470589706372775
Trained batch 1035 in epoch 0, gen_loss = 0.8200738111575598, disc_loss = 0.14471508980918366
Trained batch 1036 in epoch 0, gen_loss = 0.819878701332565, disc_loss = 0.14474018859109422
Trained batch 1037 in epoch 0, gen_loss = 0.8197583627666352, disc_loss = 0.14477805787341236
Trained batch 1038 in epoch 0, gen_loss = 0.8196246359816415, disc_loss = 0.1448345429264457
Trained batch 1039 in epoch 0, gen_loss = 0.8192851348565175, disc_loss = 0.14492893519681485
Trained batch 1040 in epoch 0, gen_loss = 0.8191124261513453, disc_loss = 0.14504123549782255
Trained batch 1041 in epoch 0, gen_loss = 0.8191128039657498, disc_loss = 0.14503747155964053
Trained batch 1042 in epoch 0, gen_loss = 0.8188096119710606, disc_loss = 0.14504421628589276
Trained batch 1043 in epoch 0, gen_loss = 0.8187145122623078, disc_loss = 0.14504969015630975
Trained batch 1044 in epoch 0, gen_loss = 0.8184794858882302, disc_loss = 0.14509319627198555
Trained batch 1045 in epoch 0, gen_loss = 0.818248099225429, disc_loss = 0.14514060617432561
Trained batch 1046 in epoch 0, gen_loss = 0.8181084410964361, disc_loss = 0.1452296387024825
Trained batch 1047 in epoch 0, gen_loss = 0.8179347125514773, disc_loss = 0.14530620595794846
Trained batch 1048 in epoch 0, gen_loss = 0.8177227305161373, disc_loss = 0.14538288376208847
Trained batch 1049 in epoch 0, gen_loss = 0.817306199669838, disc_loss = 0.14552174186223144
Trained batch 1050 in epoch 0, gen_loss = 0.8173842119614813, disc_loss = 0.1456474520735262
Trained batch 1051 in epoch 0, gen_loss = 0.8172982226589787, disc_loss = 0.14570554577946457
Trained batch 1052 in epoch 0, gen_loss = 0.8169978261843026, disc_loss = 0.14573586603882213
Trained batch 1053 in epoch 0, gen_loss = 0.8169730550254318, disc_loss = 0.1457528220133969
Trained batch 1054 in epoch 0, gen_loss = 0.8167343819593367, disc_loss = 0.1457516294641429
Trained batch 1055 in epoch 0, gen_loss = 0.8165046885666071, disc_loss = 0.14579035886223815
Trained batch 1056 in epoch 0, gen_loss = 0.816417747578084, disc_loss = 0.14590383714876448
Trained batch 1057 in epoch 0, gen_loss = 0.8162161417460396, disc_loss = 0.14594243128633475
Trained batch 1058 in epoch 0, gen_loss = 0.8158644365746531, disc_loss = 0.146113815960783
Trained batch 1059 in epoch 0, gen_loss = 0.8157371702621568, disc_loss = 0.14621890369815893
Trained batch 1060 in epoch 0, gen_loss = 0.8157833248910535, disc_loss = 0.14619827374239242
Trained batch 1061 in epoch 0, gen_loss = 0.8155149814660491, disc_loss = 0.14636284008901917
Trained batch 1062 in epoch 0, gen_loss = 0.8154337572692592, disc_loss = 0.14636040043487955
Trained batch 1063 in epoch 0, gen_loss = 0.815375646422232, disc_loss = 0.14636422591297046
Trained batch 1064 in epoch 0, gen_loss = 0.8151713891208452, disc_loss = 0.14640194991747782
Trained batch 1065 in epoch 0, gen_loss = 0.8149708354562577, disc_loss = 0.14644394325521404
Trained batch 1066 in epoch 0, gen_loss = 0.8147475185970782, disc_loss = 0.14644277524338353
Trained batch 1067 in epoch 0, gen_loss = 0.814535472667619, disc_loss = 0.14656071193068906
Trained batch 1068 in epoch 0, gen_loss = 0.8144462222357126, disc_loss = 0.14654611187492184
Trained batch 1069 in epoch 0, gen_loss = 0.8141854906193564, disc_loss = 0.14658452209550887
Trained batch 1070 in epoch 0, gen_loss = 0.8142295868234252, disc_loss = 0.14652867228237096
Trained batch 1071 in epoch 0, gen_loss = 0.813996893423262, disc_loss = 0.14660682909884803
Trained batch 1072 in epoch 0, gen_loss = 0.8141642376183352, disc_loss = 0.14657498691087797
Trained batch 1073 in epoch 0, gen_loss = 0.813920553725081, disc_loss = 0.14670804921807323
Trained batch 1074 in epoch 0, gen_loss = 0.8138447060695915, disc_loss = 0.14670661162996534
Trained batch 1075 in epoch 0, gen_loss = 0.813689345708567, disc_loss = 0.14676782662428908
Trained batch 1076 in epoch 0, gen_loss = 0.8137304242717633, disc_loss = 0.14676297433694224
Trained batch 1077 in epoch 0, gen_loss = 0.8135364449864637, disc_loss = 0.14674523760800479
Trained batch 1078 in epoch 0, gen_loss = 0.8133826580060866, disc_loss = 0.1467725279703443
Trained batch 1079 in epoch 0, gen_loss = 0.8134136035486504, disc_loss = 0.14672067103782427
Trained batch 1080 in epoch 0, gen_loss = 0.8134802753014436, disc_loss = 0.14680914887335672
Trained batch 1081 in epoch 0, gen_loss = 0.8132281528713522, disc_loss = 0.14687445289270296
Trained batch 1082 in epoch 0, gen_loss = 0.8132556038990355, disc_loss = 0.14694197670408693
Trained batch 1083 in epoch 0, gen_loss = 0.8132211479643614, disc_loss = 0.14703445132917164
Trained batch 1084 in epoch 0, gen_loss = 0.8128390349276055, disc_loss = 0.1472066250451613
Trained batch 1085 in epoch 0, gen_loss = 0.8127394256286639, disc_loss = 0.1471997601600556
Trained batch 1086 in epoch 0, gen_loss = 0.8125782651482313, disc_loss = 0.14734925668778304
Trained batch 1087 in epoch 0, gen_loss = 0.8124370627817424, disc_loss = 0.14737924460046892
Trained batch 1088 in epoch 0, gen_loss = 0.8122546640254688, disc_loss = 0.14742128834743276
Trained batch 1089 in epoch 0, gen_loss = 0.8123293743494454, disc_loss = 0.1474310533218342
Trained batch 1090 in epoch 0, gen_loss = 0.8122231284212782, disc_loss = 0.14746350760692875
Trained batch 1091 in epoch 0, gen_loss = 0.8121517086913298, disc_loss = 0.14750081025581677
Trained batch 1092 in epoch 0, gen_loss = 0.8119926170428085, disc_loss = 0.14751386794275267
Trained batch 1093 in epoch 0, gen_loss = 0.8119462242782443, disc_loss = 0.1474543310600968
Trained batch 1094 in epoch 0, gen_loss = 0.811830090306121, disc_loss = 0.14740354704338904
Trained batch 1095 in epoch 0, gen_loss = 0.8116252073460687, disc_loss = 0.1474283072316975
Trained batch 1096 in epoch 0, gen_loss = 0.8118060096188252, disc_loss = 0.14774018451176693
Trained batch 1097 in epoch 0, gen_loss = 0.8116200135542395, disc_loss = 0.14770922918217885
Trained batch 1098 in epoch 0, gen_loss = 0.8112243174204944, disc_loss = 0.14783685503030083
Trained batch 1099 in epoch 0, gen_loss = 0.8111017532782121, disc_loss = 0.14791021602884444
Trained batch 1100 in epoch 0, gen_loss = 0.8111910289466435, disc_loss = 0.14795218050614384
Trained batch 1101 in epoch 0, gen_loss = 0.8110513335563743, disc_loss = 0.14795629554212655
Trained batch 1102 in epoch 0, gen_loss = 0.8106743465578783, disc_loss = 0.1480855573344881
Trained batch 1103 in epoch 0, gen_loss = 0.8103933944164411, disc_loss = 0.14811068164345814
Trained batch 1104 in epoch 0, gen_loss = 0.8101911822325504, disc_loss = 0.1481505805666546
Trained batch 1105 in epoch 0, gen_loss = 0.8101606067492345, disc_loss = 0.14819409819315635
Trained batch 1106 in epoch 0, gen_loss = 0.8099425630786985, disc_loss = 0.14829069350226912
Trained batch 1107 in epoch 0, gen_loss = 0.8096749784445074, disc_loss = 0.14838405226299284
Trained batch 1108 in epoch 0, gen_loss = 0.8094150962810241, disc_loss = 0.14843615881298358
Trained batch 1109 in epoch 0, gen_loss = 0.8092341686959739, disc_loss = 0.14857026102117826
Trained batch 1110 in epoch 0, gen_loss = 0.8089682035731582, disc_loss = 0.1486284662652962
Trained batch 1111 in epoch 0, gen_loss = 0.8087665853794102, disc_loss = 0.14871390848466623
Trained batch 1112 in epoch 0, gen_loss = 0.8085481042221443, disc_loss = 0.14875090442014638
Trained batch 1113 in epoch 0, gen_loss = 0.808532707272783, disc_loss = 0.14883292930370406
Trained batch 1114 in epoch 0, gen_loss = 0.8081623004423664, disc_loss = 0.14892241281056318
Trained batch 1115 in epoch 0, gen_loss = 0.8079767784497643, disc_loss = 0.14900794155093738
Trained batch 1116 in epoch 0, gen_loss = 0.8077589291862429, disc_loss = 0.14906117087751194
Trained batch 1117 in epoch 0, gen_loss = 0.807516738079315, disc_loss = 0.14910672037060038
Trained batch 1118 in epoch 0, gen_loss = 0.8074478981908247, disc_loss = 0.14912131023709765
Trained batch 1119 in epoch 0, gen_loss = 0.8072708621887225, disc_loss = 0.1491741281782327
Trained batch 1120 in epoch 0, gen_loss = 0.8070081722566211, disc_loss = 0.14923141432621156
Trained batch 1121 in epoch 0, gen_loss = 0.8068790730361207, disc_loss = 0.14921919397039443
Trained batch 1122 in epoch 0, gen_loss = 0.8067102045590392, disc_loss = 0.14924072424295662
Trained batch 1123 in epoch 0, gen_loss = 0.8066398114549308, disc_loss = 0.1492521307177202
Trained batch 1124 in epoch 0, gen_loss = 0.8065124260849423, disc_loss = 0.1492828110570295
Trained batch 1125 in epoch 0, gen_loss = 0.8063860359613256, disc_loss = 0.1493858210657695
Trained batch 1126 in epoch 0, gen_loss = 0.8061522986630792, disc_loss = 0.14942686205350536
Trained batch 1127 in epoch 0, gen_loss = 0.8059936243750102, disc_loss = 0.14947747254016783
Trained batch 1128 in epoch 0, gen_loss = 0.805994487025233, disc_loss = 0.14945034995370696
Trained batch 1129 in epoch 0, gen_loss = 0.8057637251847614, disc_loss = 0.14948113089719936
Trained batch 1130 in epoch 0, gen_loss = 0.8056530745602835, disc_loss = 0.14949583083495768
Trained batch 1131 in epoch 0, gen_loss = 0.8055164541509463, disc_loss = 0.1494915573427852
Trained batch 1132 in epoch 0, gen_loss = 0.8054139130376444, disc_loss = 0.14954994546371986
Trained batch 1133 in epoch 0, gen_loss = 0.805130267164274, disc_loss = 0.14967324123311315
Trained batch 1134 in epoch 0, gen_loss = 0.805500503258558, disc_loss = 0.14992356704535692
Trained batch 1135 in epoch 0, gen_loss = 0.8052719570696354, disc_loss = 0.14998814151241135
Trained batch 1136 in epoch 0, gen_loss = 0.8049857973423357, disc_loss = 0.1500309506247333
Trained batch 1137 in epoch 0, gen_loss = 0.804983474720132, disc_loss = 0.15003011353221446
Trained batch 1138 in epoch 0, gen_loss = 0.8048620910054242, disc_loss = 0.15006664073314677
Trained batch 1139 in epoch 0, gen_loss = 0.804647677561693, disc_loss = 0.1501157324546703
Trained batch 1140 in epoch 0, gen_loss = 0.8045571132985048, disc_loss = 0.15013306846986643
Trained batch 1141 in epoch 0, gen_loss = 0.8045312294087351, disc_loss = 0.15012766642478864
Trained batch 1142 in epoch 0, gen_loss = 0.8044325743760337, disc_loss = 0.15017011796681606
Trained batch 1143 in epoch 0, gen_loss = 0.8040394791616843, disc_loss = 0.15026851439782601
Trained batch 1144 in epoch 0, gen_loss = 0.8039896332280605, disc_loss = 0.15023629980133318
Trained batch 1145 in epoch 0, gen_loss = 0.8039873629080272, disc_loss = 0.15023057501950832
Trained batch 1146 in epoch 0, gen_loss = 0.8037700396105842, disc_loss = 0.15023812198050893
Trained batch 1147 in epoch 0, gen_loss = 0.8035595615099116, disc_loss = 0.15032094111970304
Trained batch 1148 in epoch 0, gen_loss = 0.8034761909353307, disc_loss = 0.15038012796660336
Trained batch 1149 in epoch 0, gen_loss = 0.8034356380804726, disc_loss = 0.15043241433293114
Trained batch 1150 in epoch 0, gen_loss = 0.8031640104580505, disc_loss = 0.15054352473864877
Trained batch 1151 in epoch 0, gen_loss = 0.8030432032214271, disc_loss = 0.15052732678931433
Trained batch 1152 in epoch 0, gen_loss = 0.8030879037440185, disc_loss = 0.15072103632886225
Trained batch 1153 in epoch 0, gen_loss = 0.8030947341972662, disc_loss = 0.150670443929246
Trained batch 1154 in epoch 0, gen_loss = 0.80282265959364, disc_loss = 0.15075727837115882
Trained batch 1155 in epoch 0, gen_loss = 0.8027818133364911, disc_loss = 0.15079438791245345
Trained batch 1156 in epoch 0, gen_loss = 0.8026775997985306, disc_loss = 0.15083639638425175
Trained batch 1157 in epoch 0, gen_loss = 0.8024293290827559, disc_loss = 0.1509230062154416
Trained batch 1158 in epoch 0, gen_loss = 0.8023643424225018, disc_loss = 0.15092200970834055
Trained batch 1159 in epoch 0, gen_loss = 0.8023150365414291, disc_loss = 0.1509068863705234
Trained batch 1160 in epoch 0, gen_loss = 0.8021966182497634, disc_loss = 0.15091242723172557
Trained batch 1161 in epoch 0, gen_loss = 0.8020456844681101, disc_loss = 0.15097941356096353
Trained batch 1162 in epoch 0, gen_loss = 0.8020527225471424, disc_loss = 0.150992055371306
Trained batch 1163 in epoch 0, gen_loss = 0.8018276906505073, disc_loss = 0.15096615915905998
Trained batch 1164 in epoch 0, gen_loss = 0.8017200543645114, disc_loss = 0.15091772101671622
Trained batch 1165 in epoch 0, gen_loss = 0.8016280698019685, disc_loss = 0.15091773925575158
Trained batch 1166 in epoch 0, gen_loss = 0.8015538270185416, disc_loss = 0.15099055672263137
Trained batch 1167 in epoch 0, gen_loss = 0.801329038680008, disc_loss = 0.15101148982110515
Trained batch 1168 in epoch 0, gen_loss = 0.801288226611396, disc_loss = 0.15118563988913644
Trained batch 1169 in epoch 0, gen_loss = 0.8010527149734334, disc_loss = 0.1511825684726668
Trained batch 1170 in epoch 0, gen_loss = 0.801046698547448, disc_loss = 0.15118798457486132
Trained batch 1171 in epoch 0, gen_loss = 0.8007613621372411, disc_loss = 0.1512626158596023
Trained batch 1172 in epoch 0, gen_loss = 0.8007267860398777, disc_loss = 0.15136315042048992
Trained batch 1173 in epoch 0, gen_loss = 0.8006456382128408, disc_loss = 0.15145463125008354
Trained batch 1174 in epoch 0, gen_loss = 0.8002545004195355, disc_loss = 0.15158955282809095
Trained batch 1175 in epoch 0, gen_loss = 0.8001433700627211, disc_loss = 0.15162473532262727
Trained batch 1176 in epoch 0, gen_loss = 0.8000156720918219, disc_loss = 0.15166638983186484
Trained batch 1177 in epoch 0, gen_loss = 0.7999472771415483, disc_loss = 0.15164662981528396
Trained batch 1178 in epoch 0, gen_loss = 0.7998955305397156, disc_loss = 0.1516950950261515
Trained batch 1179 in epoch 0, gen_loss = 0.7998220046698037, disc_loss = 0.15163812890344977
Trained batch 1180 in epoch 0, gen_loss = 0.7998060658258669, disc_loss = 0.15162164607963774
Trained batch 1181 in epoch 0, gen_loss = 0.7995629854210339, disc_loss = 0.15173642533179688
Trained batch 1182 in epoch 0, gen_loss = 0.7995069477382799, disc_loss = 0.15175968574045898
Trained batch 1183 in epoch 0, gen_loss = 0.7993876615891585, disc_loss = 0.15175987170152586
Trained batch 1184 in epoch 0, gen_loss = 0.799369712821542, disc_loss = 0.15182143682869395
Trained batch 1185 in epoch 0, gen_loss = 0.7991383416455673, disc_loss = 0.15188025115713522
Trained batch 1186 in epoch 0, gen_loss = 0.7991166683235587, disc_loss = 0.1518703576759141
Trained batch 1187 in epoch 0, gen_loss = 0.7989662064345999, disc_loss = 0.1519602874984968
Trained batch 1188 in epoch 0, gen_loss = 0.7989760854847798, disc_loss = 0.15203402089710913
Trained batch 1189 in epoch 0, gen_loss = 0.7986825320400109, disc_loss = 0.15207984226290136
Trained batch 1190 in epoch 0, gen_loss = 0.7986354294892222, disc_loss = 0.15209573586580855
Trained batch 1191 in epoch 0, gen_loss = 0.7983350524766333, disc_loss = 0.15222446384645166
Trained batch 1192 in epoch 0, gen_loss = 0.79842194087947, disc_loss = 0.15238653416105227
Trained batch 1193 in epoch 0, gen_loss = 0.7982919385884475, disc_loss = 0.15241737861378926
Trained batch 1194 in epoch 0, gen_loss = 0.7982205441806107, disc_loss = 0.1524452584353373
Trained batch 1195 in epoch 0, gen_loss = 0.7980484915616919, disc_loss = 0.15249559612626234
Trained batch 1196 in epoch 0, gen_loss = 0.7977890454438097, disc_loss = 0.15255197088869013
Trained batch 1197 in epoch 0, gen_loss = 0.7977681577902206, disc_loss = 0.1525755968978411
Trained batch 1198 in epoch 0, gen_loss = 0.797593189687705, disc_loss = 0.15260769152610693
Trained batch 1199 in epoch 0, gen_loss = 0.7973708533247312, disc_loss = 0.15264295174876072
Trained batch 1200 in epoch 0, gen_loss = 0.7975821899037675, disc_loss = 0.15277219026312264
Trained batch 1201 in epoch 0, gen_loss = 0.7975352793783197, disc_loss = 0.15276120976678959
Trained batch 1202 in epoch 0, gen_loss = 0.7972458344841638, disc_loss = 0.15277865907298874
Trained batch 1203 in epoch 0, gen_loss = 0.7971383397068296, disc_loss = 0.1527719998720993
Trained batch 1204 in epoch 0, gen_loss = 0.796996988646717, disc_loss = 0.1527958070385923
Trained batch 1205 in epoch 0, gen_loss = 0.7968659126145725, disc_loss = 0.15283345653938832
Trained batch 1206 in epoch 0, gen_loss = 0.7969282060589984, disc_loss = 0.1528520254646262
Trained batch 1207 in epoch 0, gen_loss = 0.7966986653327153, disc_loss = 0.1529573215869801
Trained batch 1208 in epoch 0, gen_loss = 0.7967315622358109, disc_loss = 0.15300763378515253
Trained batch 1209 in epoch 0, gen_loss = 0.7967767997714114, disc_loss = 0.15303873028586934
Trained batch 1210 in epoch 0, gen_loss = 0.7966926515742239, disc_loss = 0.1530445686698769
Trained batch 1211 in epoch 0, gen_loss = 0.79656616310672, disc_loss = 0.15303454804291838
Trained batch 1212 in epoch 0, gen_loss = 0.7965356038310561, disc_loss = 0.1530398517178705
Trained batch 1213 in epoch 0, gen_loss = 0.7964226369311821, disc_loss = 0.15306998227582555
Trained batch 1214 in epoch 0, gen_loss = 0.7962946378645093, disc_loss = 0.15309974014463953
Trained batch 1215 in epoch 0, gen_loss = 0.7963300038521227, disc_loss = 0.15306099097219167
Trained batch 1216 in epoch 0, gen_loss = 0.7963185178126677, disc_loss = 0.15302750491958048
Trained batch 1217 in epoch 0, gen_loss = 0.7963173101688253, disc_loss = 0.15303956729926518
Trained batch 1218 in epoch 0, gen_loss = 0.7963130513696616, disc_loss = 0.15297305715190884
Trained batch 1219 in epoch 0, gen_loss = 0.7959954232466026, disc_loss = 0.15316507153529826
Trained batch 1220 in epoch 0, gen_loss = 0.7960261827507144, disc_loss = 0.15320897248022894
Trained batch 1221 in epoch 0, gen_loss = 0.7961307699668622, disc_loss = 0.15316212751446123
Trained batch 1222 in epoch 0, gen_loss = 0.7961925504057503, disc_loss = 0.1531445118638619
Trained batch 1223 in epoch 0, gen_loss = 0.7959095799163276, disc_loss = 0.15341774941390848
Trained batch 1224 in epoch 0, gen_loss = 0.7956311154852108, disc_loss = 0.15343591601093662
Trained batch 1225 in epoch 0, gen_loss = 0.7956545203194921, disc_loss = 0.15354733495858344
Trained batch 1226 in epoch 0, gen_loss = 0.7956624711152491, disc_loss = 0.15362501021580105
Trained batch 1227 in epoch 0, gen_loss = 0.7955070204960019, disc_loss = 0.1537328913475308
Trained batch 1228 in epoch 0, gen_loss = 0.7953073222332606, disc_loss = 0.15379670576193955
Trained batch 1229 in epoch 0, gen_loss = 0.7950605046942951, disc_loss = 0.15384211835652076
Trained batch 1230 in epoch 0, gen_loss = 0.7948643754014729, disc_loss = 0.1539015966525436
Trained batch 1231 in epoch 0, gen_loss = 0.7947922556528023, disc_loss = 0.15396904175955192
Trained batch 1232 in epoch 0, gen_loss = 0.7945690809085131, disc_loss = 0.1540186345221857
Trained batch 1233 in epoch 0, gen_loss = 0.7944253780660212, disc_loss = 0.15405826515543034
Trained batch 1234 in epoch 0, gen_loss = 0.7942854763525218, disc_loss = 0.15407996241451968
Trained batch 1235 in epoch 0, gen_loss = 0.794110350431362, disc_loss = 0.15412083686337713
Trained batch 1236 in epoch 0, gen_loss = 0.7939119213708679, disc_loss = 0.15415755374279558
Trained batch 1237 in epoch 0, gen_loss = 0.7936881254389521, disc_loss = 0.154201168751815
Trained batch 1238 in epoch 0, gen_loss = 0.7936233443728948, disc_loss = 0.154187821313142
Trained batch 1239 in epoch 0, gen_loss = 0.793479387077593, disc_loss = 0.15420388664520765
Trained batch 1240 in epoch 0, gen_loss = 0.7934411592679481, disc_loss = 0.15420613778131437
Trained batch 1241 in epoch 0, gen_loss = 0.7933309097892804, disc_loss = 0.15418995729510354
Trained batch 1242 in epoch 0, gen_loss = 0.7931043693161931, disc_loss = 0.15417410652505342
Trained batch 1243 in epoch 0, gen_loss = 0.7930458117144668, disc_loss = 0.15414967664447837
Trained batch 1244 in epoch 0, gen_loss = 0.7931028351726302, disc_loss = 0.15413390183615608
Trained batch 1245 in epoch 0, gen_loss = 0.7928585836822302, disc_loss = 0.1541949719245535
Trained batch 1246 in epoch 0, gen_loss = 0.7927958085810364, disc_loss = 0.15416036217448054
Trained batch 1247 in epoch 0, gen_loss = 0.792760608287958, disc_loss = 0.15412527125590714
Trained batch 1248 in epoch 0, gen_loss = 0.792661384165621, disc_loss = 0.15405769017264037
Trained batch 1249 in epoch 0, gen_loss = 0.7924424541473388, disc_loss = 0.15408072496484965
Trained batch 1250 in epoch 0, gen_loss = 0.7926242782248201, disc_loss = 0.1541135418193443
Trained batch 1251 in epoch 0, gen_loss = 0.7924581386696417, disc_loss = 0.15425745029870522
Trained batch 1252 in epoch 0, gen_loss = 0.7925145418189187, disc_loss = 0.15422806107916281
Trained batch 1253 in epoch 0, gen_loss = 0.7923399581198107, disc_loss = 0.15423250646182624
Trained batch 1254 in epoch 0, gen_loss = 0.7922816189636748, disc_loss = 0.15427381144409844
Trained batch 1255 in epoch 0, gen_loss = 0.792129851450586, disc_loss = 0.1542281036717138
Trained batch 1256 in epoch 0, gen_loss = 0.791836668905419, disc_loss = 0.15427854238541067
Trained batch 1257 in epoch 0, gen_loss = 0.7919983929452532, disc_loss = 0.1542693795249479
Trained batch 1258 in epoch 0, gen_loss = 0.7919421420625697, disc_loss = 0.15424601790921302
Trained batch 1259 in epoch 0, gen_loss = 0.7917777177123796, disc_loss = 0.15424715774115322
Trained batch 1260 in epoch 0, gen_loss = 0.7917171870546621, disc_loss = 0.15425776617995166
Trained batch 1261 in epoch 0, gen_loss = 0.791600579764877, disc_loss = 0.1542554044704545
Trained batch 1262 in epoch 0, gen_loss = 0.7915891700336505, disc_loss = 0.15433079851824444
Trained batch 1263 in epoch 0, gen_loss = 0.7913076449657166, disc_loss = 0.1543475795532444
Trained batch 1264 in epoch 0, gen_loss = 0.7915384641513523, disc_loss = 0.15447025937948508
Trained batch 1265 in epoch 0, gen_loss = 0.7914112007118891, disc_loss = 0.15449157238759154
Trained batch 1266 in epoch 0, gen_loss = 0.7914448328957185, disc_loss = 0.1545525288167788
Trained batch 1267 in epoch 0, gen_loss = 0.7912049926934934, disc_loss = 0.15471091367468115
Trained batch 1268 in epoch 0, gen_loss = 0.7911531753996586, disc_loss = 0.15471016973608603
Trained batch 1269 in epoch 0, gen_loss = 0.7910990258605461, disc_loss = 0.1547271411526787
Trained batch 1270 in epoch 0, gen_loss = 0.7909119489106674, disc_loss = 0.15482198020071816
Trained batch 1271 in epoch 0, gen_loss = 0.7907341130358992, disc_loss = 0.15480370896135504
Trained batch 1272 in epoch 0, gen_loss = 0.7906451158559145, disc_loss = 0.1548306799805756
Trained batch 1273 in epoch 0, gen_loss = 0.7904916656213802, disc_loss = 0.15484859818191335
Trained batch 1274 in epoch 0, gen_loss = 0.7904609748662687, disc_loss = 0.15487327462737904
Trained batch 1275 in epoch 0, gen_loss = 0.7903402006971799, disc_loss = 0.15494179578923523
Trained batch 1276 in epoch 0, gen_loss = 0.7900626826024933, disc_loss = 0.15497571608425792
Trained batch 1277 in epoch 0, gen_loss = 0.7899007397544963, disc_loss = 0.15503960289771584
Trained batch 1278 in epoch 0, gen_loss = 0.7897323676624551, disc_loss = 0.1550843806468035
Trained batch 1279 in epoch 0, gen_loss = 0.7896025667432696, disc_loss = 0.1551098941517921
Trained batch 1280 in epoch 0, gen_loss = 0.78957005495396, disc_loss = 0.15514447926078356
Trained batch 1281 in epoch 0, gen_loss = 0.7895021387920736, disc_loss = 0.15520297867691293
Trained batch 1282 in epoch 0, gen_loss = 0.7894076605095867, disc_loss = 0.15522571999070817
Trained batch 1283 in epoch 0, gen_loss = 0.7892727671753952, disc_loss = 0.15528526048468297
Trained batch 1284 in epoch 0, gen_loss = 0.7891550102122563, disc_loss = 0.15530784461005856
Trained batch 1285 in epoch 0, gen_loss = 0.7889479246703128, disc_loss = 0.15533972754448067
Trained batch 1286 in epoch 0, gen_loss = 0.7890755070580376, disc_loss = 0.1553345566256176
Trained batch 1287 in epoch 0, gen_loss = 0.7889246579190219, disc_loss = 0.15531012927082957
Trained batch 1288 in epoch 0, gen_loss = 0.7888702708589097, disc_loss = 0.15526363062108756
Trained batch 1289 in epoch 0, gen_loss = 0.7890767525794894, disc_loss = 0.15527618605221166
Trained batch 1290 in epoch 0, gen_loss = 0.788865291361288, disc_loss = 0.15539496291430968
Trained batch 1291 in epoch 0, gen_loss = 0.7890487642664659, disc_loss = 0.15548011835144787
Trained batch 1292 in epoch 0, gen_loss = 0.7889370345737431, disc_loss = 0.1554482687948587
Trained batch 1293 in epoch 0, gen_loss = 0.7887747155090756, disc_loss = 0.15542164848382561
Trained batch 1294 in epoch 0, gen_loss = 0.7887312082710414, disc_loss = 0.15535438630755086
Trained batch 1295 in epoch 0, gen_loss = 0.7886035927099946, disc_loss = 0.15536665784631265
Trained batch 1296 in epoch 0, gen_loss = 0.7883679934805323, disc_loss = 0.15549000573047253
Trained batch 1297 in epoch 0, gen_loss = 0.7883151809129583, disc_loss = 0.15553194768163583
Trained batch 1298 in epoch 0, gen_loss = 0.788439364961884, disc_loss = 0.1555844792267028
Trained batch 1299 in epoch 0, gen_loss = 0.7883143879817083, disc_loss = 0.15553762981936767
Trained batch 1300 in epoch 0, gen_loss = 0.788213924569959, disc_loss = 0.15554534363113687
Trained batch 1301 in epoch 0, gen_loss = 0.7882672568436958, disc_loss = 0.15556655749059875
Trained batch 1302 in epoch 0, gen_loss = 0.788200275127648, disc_loss = 0.15556156141658442
Trained batch 1303 in epoch 0, gen_loss = 0.7880727301346012, disc_loss = 0.15559851296336755
Trained batch 1304 in epoch 0, gen_loss = 0.7878850358656083, disc_loss = 0.155647837172059
Trained batch 1305 in epoch 0, gen_loss = 0.7878076884593204, disc_loss = 0.1557018082019492
Trained batch 1306 in epoch 0, gen_loss = 0.7876272969056197, disc_loss = 0.1557343033195474
Trained batch 1307 in epoch 0, gen_loss = 0.7875001944077489, disc_loss = 0.15573478245588634
Trained batch 1308 in epoch 0, gen_loss = 0.7875718104648081, disc_loss = 0.15573662566536906
Trained batch 1309 in epoch 0, gen_loss = 0.7874533593199635, disc_loss = 0.15576690525680298
Trained batch 1310 in epoch 0, gen_loss = 0.7873302910457032, disc_loss = 0.15575637942138124
Trained batch 1311 in epoch 0, gen_loss = 0.7872122452571625, disc_loss = 0.15575296545763948
Trained batch 1312 in epoch 0, gen_loss = 0.7872763587515135, disc_loss = 0.15582108482138962
Trained batch 1313 in epoch 0, gen_loss = 0.7869304029818176, disc_loss = 0.15595999403585237
Trained batch 1314 in epoch 0, gen_loss = 0.786779664360525, disc_loss = 0.1559987211449447
Trained batch 1315 in epoch 0, gen_loss = 0.786952849715314, disc_loss = 0.15594396595669752
Trained batch 1316 in epoch 0, gen_loss = 0.7868868586866803, disc_loss = 0.15596961327184955
Trained batch 1317 in epoch 0, gen_loss = 0.7868436304951293, disc_loss = 0.1559536598312947
Trained batch 1318 in epoch 0, gen_loss = 0.7867825697370331, disc_loss = 0.15592976714169482
Trained batch 1319 in epoch 0, gen_loss = 0.786688506603241, disc_loss = 0.15596210709190927
Trained batch 1320 in epoch 0, gen_loss = 0.7865686792031461, disc_loss = 0.15594518707905114
Trained batch 1321 in epoch 0, gen_loss = 0.7863862882403491, disc_loss = 0.15592104701361226
Trained batch 1322 in epoch 0, gen_loss = 0.7863889253238612, disc_loss = 0.15591416965648447
Trained batch 1323 in epoch 0, gen_loss = 0.7862917083988017, disc_loss = 0.15586288878113858
Trained batch 1324 in epoch 0, gen_loss = 0.786110711502579, disc_loss = 0.15591808705239224
Trained batch 1325 in epoch 0, gen_loss = 0.7860554251286059, disc_loss = 0.15601429609960396
Trained batch 1326 in epoch 0, gen_loss = 0.7860433542378072, disc_loss = 0.1560295924932795
Trained batch 1327 in epoch 0, gen_loss = 0.7857828640031168, disc_loss = 0.15612543789871144
Trained batch 1328 in epoch 0, gen_loss = 0.7857060704893237, disc_loss = 0.1562191030461526
Trained batch 1329 in epoch 0, gen_loss = 0.7855455021885105, disc_loss = 0.15621631904382652
Trained batch 1330 in epoch 0, gen_loss = 0.7855102439333316, disc_loss = 0.15620150427007942
Trained batch 1331 in epoch 0, gen_loss = 0.785641311995081, disc_loss = 0.1562059237116559
Trained batch 1332 in epoch 0, gen_loss = 0.7854783589331977, disc_loss = 0.15619834084172063
Trained batch 1333 in epoch 0, gen_loss = 0.7854346061709045, disc_loss = 0.15614850602808758
Trained batch 1334 in epoch 0, gen_loss = 0.785233385710234, disc_loss = 0.15614979786550703
Trained batch 1335 in epoch 0, gen_loss = 0.7853323551575224, disc_loss = 0.15615047238231078
Trained batch 1336 in epoch 0, gen_loss = 0.785017648916594, disc_loss = 0.15633984977082002
Trained batch 1337 in epoch 0, gen_loss = 0.7851337368178261, disc_loss = 0.15637750031968775
Trained batch 1338 in epoch 0, gen_loss = 0.7849649886216041, disc_loss = 0.15636921956522434
Trained batch 1339 in epoch 0, gen_loss = 0.7849273911607799, disc_loss = 0.15637986051012526
Trained batch 1340 in epoch 0, gen_loss = 0.7847985151452328, disc_loss = 0.15642277703455204
Trained batch 1341 in epoch 0, gen_loss = 0.7846335535077864, disc_loss = 0.15642763896732162
Trained batch 1342 in epoch 0, gen_loss = 0.7847771164382117, disc_loss = 0.15645070280099588
Trained batch 1343 in epoch 0, gen_loss = 0.7846877970511005, disc_loss = 0.15644976930603402
Trained batch 1344 in epoch 0, gen_loss = 0.7845371857008526, disc_loss = 0.1565143793196414
Trained batch 1345 in epoch 0, gen_loss = 0.7846818889586745, disc_loss = 0.15669150844636343
Trained batch 1346 in epoch 0, gen_loss = 0.784461142535376, disc_loss = 0.15672147912720016
Trained batch 1347 in epoch 0, gen_loss = 0.7842342701218249, disc_loss = 0.15675056192216266
Trained batch 1348 in epoch 0, gen_loss = 0.7842792754397735, disc_loss = 0.1567798117291337
Trained batch 1349 in epoch 0, gen_loss = 0.7842416388237918, disc_loss = 0.15676278507664662
Trained batch 1350 in epoch 0, gen_loss = 0.7841391741435322, disc_loss = 0.1567736914425159
Trained batch 1351 in epoch 0, gen_loss = 0.7839439047291081, disc_loss = 0.1567923531482842
Trained batch 1352 in epoch 0, gen_loss = 0.7839597262062149, disc_loss = 0.15676584084145173
Trained batch 1353 in epoch 0, gen_loss = 0.7838477477145159, disc_loss = 0.1567763085936181
Trained batch 1354 in epoch 0, gen_loss = 0.7837387909088628, disc_loss = 0.15677058318289636
Trained batch 1355 in epoch 0, gen_loss = 0.7837037327410901, disc_loss = 0.1567782064043686
Trained batch 1356 in epoch 0, gen_loss = 0.7836775534848738, disc_loss = 0.1567610399445825
Trained batch 1357 in epoch 0, gen_loss = 0.7834759443471639, disc_loss = 0.15677630023352543
Trained batch 1358 in epoch 0, gen_loss = 0.78352672491028, disc_loss = 0.1567792940027861
Trained batch 1359 in epoch 0, gen_loss = 0.7834772879805635, disc_loss = 0.15677044157003847
Trained batch 1360 in epoch 0, gen_loss = 0.7834669429313427, disc_loss = 0.1567093438229713
Trained batch 1361 in epoch 0, gen_loss = 0.7833393324007897, disc_loss = 0.15671244880000593
Trained batch 1362 in epoch 0, gen_loss = 0.7833799740582464, disc_loss = 0.15680490587619342
Trained batch 1363 in epoch 0, gen_loss = 0.7833197194853486, disc_loss = 0.15675204225779646
Trained batch 1364 in epoch 0, gen_loss = 0.7831399212608408, disc_loss = 0.15679066995953655
Trained batch 1365 in epoch 0, gen_loss = 0.7829642057375189, disc_loss = 0.15678835668247249
Trained batch 1366 in epoch 0, gen_loss = 0.7829943043564739, disc_loss = 0.15675462409973162
Trained batch 1367 in epoch 0, gen_loss = 0.7829619536056505, disc_loss = 0.15677194604878206
Trained batch 1368 in epoch 0, gen_loss = 0.7828135105316616, disc_loss = 0.15683097777486124
Trained batch 1369 in epoch 0, gen_loss = 0.7827367796297491, disc_loss = 0.15685440854825433
Trained batch 1370 in epoch 0, gen_loss = 0.7826987801243318, disc_loss = 0.15691200230609595
Trained batch 1371 in epoch 0, gen_loss = 0.7826285315976198, disc_loss = 0.15685729563365888
Trained batch 1372 in epoch 0, gen_loss = 0.7826212303141825, disc_loss = 0.15684882768338923
Trained batch 1373 in epoch 0, gen_loss = 0.7824866917239179, disc_loss = 0.1568257727602963
Trained batch 1374 in epoch 0, gen_loss = 0.782865981167013, disc_loss = 0.157063079317693
Trained batch 1375 in epoch 0, gen_loss = 0.7828058018024231, disc_loss = 0.15710196574066285
Trained batch 1376 in epoch 0, gen_loss = 0.782689982444892, disc_loss = 0.15709711991493322
Trained batch 1377 in epoch 0, gen_loss = 0.782584597068705, disc_loss = 0.15717404510225041
Trained batch 1378 in epoch 0, gen_loss = 0.7824752910617817, disc_loss = 0.15718197987206886
Trained batch 1379 in epoch 0, gen_loss = 0.7822354042659635, disc_loss = 0.1572610442012049
Trained batch 1380 in epoch 0, gen_loss = 0.7822439402751867, disc_loss = 0.1572800201229322
Trained batch 1381 in epoch 0, gen_loss = 0.7822272852386648, disc_loss = 0.15724921384310772
Trained batch 1382 in epoch 0, gen_loss = 0.7821005035248341, disc_loss = 0.15724051043250487
Trained batch 1383 in epoch 0, gen_loss = 0.781905514850265, disc_loss = 0.15724856933330542
Trained batch 1384 in epoch 0, gen_loss = 0.7817490214260047, disc_loss = 0.15723269604775209
Trained batch 1385 in epoch 0, gen_loss = 0.781839912910482, disc_loss = 0.1572782679527802
Trained batch 1386 in epoch 0, gen_loss = 0.7816477216613662, disc_loss = 0.15725256905893686
Trained batch 1387 in epoch 0, gen_loss = 0.7815735736265993, disc_loss = 0.15731473951328745
Trained batch 1388 in epoch 0, gen_loss = 0.7814308463926364, disc_loss = 0.15733340493459697
Trained batch 1389 in epoch 0, gen_loss = 0.7815496381023805, disc_loss = 0.1575010360076206
Trained batch 1390 in epoch 0, gen_loss = 0.7815299518540298, disc_loss = 0.15751805189527615
Trained batch 1391 in epoch 0, gen_loss = 0.7814019388123148, disc_loss = 0.157583529914926
Trained batch 1392 in epoch 0, gen_loss = 0.781503924151932, disc_loss = 0.15759656543921002
Trained batch 1393 in epoch 0, gen_loss = 0.7815157115416684, disc_loss = 0.15753358263516373
Trained batch 1394 in epoch 0, gen_loss = 0.7814508781851833, disc_loss = 0.15751653088099826
Trained batch 1395 in epoch 0, gen_loss = 0.7813260614402314, disc_loss = 0.15754800613146985
Trained batch 1396 in epoch 0, gen_loss = 0.7812640545576406, disc_loss = 0.15749940031198764
Trained batch 1397 in epoch 0, gen_loss = 0.7812925183849785, disc_loss = 0.15752860348793585
Trained batch 1398 in epoch 0, gen_loss = 0.7811175251407568, disc_loss = 0.1575379515580335
Trained batch 1399 in epoch 0, gen_loss = 0.780921903614487, disc_loss = 0.1575698961249353
Trained batch 1400 in epoch 0, gen_loss = 0.7809993795077347, disc_loss = 0.15757774977365124
Trained batch 1401 in epoch 0, gen_loss = 0.7810037947032659, disc_loss = 0.15766520341562662
Trained batch 1402 in epoch 0, gen_loss = 0.7808232862058913, disc_loss = 0.15770016691723143
Trained batch 1403 in epoch 0, gen_loss = 0.7806961583743068, disc_loss = 0.15772786980977102
Trained batch 1404 in epoch 0, gen_loss = 0.7805017079534904, disc_loss = 0.1577716044403838
Trained batch 1405 in epoch 0, gen_loss = 0.7805338596254799, disc_loss = 0.15777493939502496
Trained batch 1406 in epoch 0, gen_loss = 0.7802855493798693, disc_loss = 0.15782508298912892
Trained batch 1407 in epoch 0, gen_loss = 0.7801945708819072, disc_loss = 0.1578936622600767
Trained batch 1408 in epoch 0, gen_loss = 0.7800122767454178, disc_loss = 0.1578920332500427
Trained batch 1409 in epoch 0, gen_loss = 0.7800231191494786, disc_loss = 0.1578591534839811
Trained batch 1410 in epoch 0, gen_loss = 0.7798828361179708, disc_loss = 0.1578712480683619
Trained batch 1411 in epoch 0, gen_loss = 0.779791921145011, disc_loss = 0.15789047088167332
Trained batch 1412 in epoch 0, gen_loss = 0.779629291095214, disc_loss = 0.15787823191219091
Trained batch 1413 in epoch 0, gen_loss = 0.7795196397090397, disc_loss = 0.1578741763430928
Trained batch 1414 in epoch 0, gen_loss = 0.7793629808687068, disc_loss = 0.1579127126769903
Trained batch 1415 in epoch 0, gen_loss = 0.7792569170521815, disc_loss = 0.15796263294809465
Trained batch 1416 in epoch 0, gen_loss = 0.7790838870980324, disc_loss = 0.15805973927424688
Trained batch 1417 in epoch 0, gen_loss = 0.7790384081380155, disc_loss = 0.15803156784037456
Trained batch 1418 in epoch 0, gen_loss = 0.7792491088499899, disc_loss = 0.15816196756600845
Trained batch 1419 in epoch 0, gen_loss = 0.7789596545444408, disc_loss = 0.15821327588465195
Trained batch 1420 in epoch 0, gen_loss = 0.7787577703458838, disc_loss = 0.15830535135286966
Trained batch 1421 in epoch 0, gen_loss = 0.7788472273891317, disc_loss = 0.15832587619035068
Trained batch 1422 in epoch 0, gen_loss = 0.7788663271733429, disc_loss = 0.15836024785284097
Trained batch 1423 in epoch 0, gen_loss = 0.7787024865366434, disc_loss = 0.15840291698954428
Trained batch 1424 in epoch 0, gen_loss = 0.7786776988757284, disc_loss = 0.158417936985528
Trained batch 1425 in epoch 0, gen_loss = 0.7785420698044511, disc_loss = 0.15843122206261934
Trained batch 1426 in epoch 0, gen_loss = 0.778528163148209, disc_loss = 0.15846172472564524
Trained batch 1427 in epoch 0, gen_loss = 0.7783726491138381, disc_loss = 0.1584856737995617
Trained batch 1428 in epoch 0, gen_loss = 0.7782028219639796, disc_loss = 0.1585205857339918
Trained batch 1429 in epoch 0, gen_loss = 0.7781977189379139, disc_loss = 0.15855792237077743
Trained batch 1430 in epoch 0, gen_loss = 0.777999825510089, disc_loss = 0.1585610429504151
Trained batch 1431 in epoch 0, gen_loss = 0.7778818595467666, disc_loss = 0.15855478065972237
Trained batch 1432 in epoch 0, gen_loss = 0.7777313264990219, disc_loss = 0.15855711543967002
Trained batch 1433 in epoch 0, gen_loss = 0.7776500987333234, disc_loss = 0.15857562904244202
Trained batch 1434 in epoch 0, gen_loss = 0.7776242949198348, disc_loss = 0.15863910678121868
Trained batch 1435 in epoch 0, gen_loss = 0.7773800073476888, disc_loss = 0.15873435971214928
Trained batch 1436 in epoch 0, gen_loss = 0.7773025822705831, disc_loss = 0.1587351709641529
Trained batch 1437 in epoch 0, gen_loss = 0.7773523781246535, disc_loss = 0.1587149223274848
Trained batch 1438 in epoch 0, gen_loss = 0.777162095794585, disc_loss = 0.1587455186867003
Trained batch 1439 in epoch 0, gen_loss = 0.7770429070211119, disc_loss = 0.15872958195250247
Trained batch 1440 in epoch 0, gen_loss = 0.7770097441428407, disc_loss = 0.15877506770125716
Trained batch 1441 in epoch 0, gen_loss = 0.776780983652718, disc_loss = 0.15882180939475657
Trained batch 1442 in epoch 0, gen_loss = 0.7767273164092875, disc_loss = 0.15882467626037666
Trained batch 1443 in epoch 0, gen_loss = 0.7766905842643035, disc_loss = 0.15881613236797168
Trained batch 1444 in epoch 0, gen_loss = 0.7767258491895603, disc_loss = 0.1588671173640949
Trained batch 1445 in epoch 0, gen_loss = 0.7764896692947728, disc_loss = 0.15898477217426618
Trained batch 1446 in epoch 0, gen_loss = 0.7764674633761974, disc_loss = 0.15898475548688196
Trained batch 1447 in epoch 0, gen_loss = 0.7764382369980957, disc_loss = 0.15901562475161343
Trained batch 1448 in epoch 0, gen_loss = 0.7764405982300197, disc_loss = 0.15896359067381308
Trained batch 1449 in epoch 0, gen_loss = 0.7762986222834423, disc_loss = 0.1589772225850551
Trained batch 1450 in epoch 0, gen_loss = 0.7762998504978801, disc_loss = 0.15896726940209105
Trained batch 1451 in epoch 0, gen_loss = 0.7762796634772264, disc_loss = 0.15897529676781721
Trained batch 1452 in epoch 0, gen_loss = 0.7761027266752777, disc_loss = 0.15897605183959926
Trained batch 1453 in epoch 0, gen_loss = 0.775954954828324, disc_loss = 0.1589868605081466
Trained batch 1454 in epoch 0, gen_loss = 0.7759560361555762, disc_loss = 0.15898996605761861
Trained batch 1455 in epoch 0, gen_loss = 0.7759623731599077, disc_loss = 0.1589981762698409
Trained batch 1456 in epoch 0, gen_loss = 0.7759319405770089, disc_loss = 0.1590228502099468
Trained batch 1457 in epoch 0, gen_loss = 0.7758115710912908, disc_loss = 0.1590654866139766
Trained batch 1458 in epoch 0, gen_loss = 0.7758378878164324, disc_loss = 0.15899819884154973
Trained batch 1459 in epoch 0, gen_loss = 0.7756226805791463, disc_loss = 0.15905152642828324
Trained batch 1460 in epoch 0, gen_loss = 0.7755158907905333, disc_loss = 0.1591068555285082
Trained batch 1461 in epoch 0, gen_loss = 0.7753829513708316, disc_loss = 0.1590961498154516
Trained batch 1462 in epoch 0, gen_loss = 0.7754438289289025, disc_loss = 0.15910272995759278
Trained batch 1463 in epoch 0, gen_loss = 0.7755373073894469, disc_loss = 0.15905354389156814
Trained batch 1464 in epoch 0, gen_loss = 0.7752867547114961, disc_loss = 0.15921915329519162
Trained batch 1465 in epoch 0, gen_loss = 0.7754180981265572, disc_loss = 0.15931493689710755
Trained batch 1466 in epoch 0, gen_loss = 0.7754027010351114, disc_loss = 0.159290307655203
Trained batch 1467 in epoch 0, gen_loss = 0.7753847467355247, disc_loss = 0.1592990574628376
Trained batch 1468 in epoch 0, gen_loss = 0.7752671854645318, disc_loss = 0.1592394623249564
Trained batch 1469 in epoch 0, gen_loss = 0.7750963130573026, disc_loss = 0.1592202693817909
Trained batch 1470 in epoch 0, gen_loss = 0.7753393424562173, disc_loss = 0.15921441447746357
Trained batch 1471 in epoch 0, gen_loss = 0.7752087299469048, disc_loss = 0.15921568988842014
Trained batch 1472 in epoch 0, gen_loss = 0.7752391028104796, disc_loss = 0.15922571491947662
Trained batch 1473 in epoch 0, gen_loss = 0.7752513076953358, disc_loss = 0.15916980163455186
Trained batch 1474 in epoch 0, gen_loss = 0.7751092426857706, disc_loss = 0.15918932597879004
Trained batch 1475 in epoch 0, gen_loss = 0.7749775931804483, disc_loss = 0.15919683814451963
Trained batch 1476 in epoch 0, gen_loss = 0.7750504227732191, disc_loss = 0.15919479811844683
Trained batch 1477 in epoch 0, gen_loss = 0.774864588421801, disc_loss = 0.1592701306862439
Trained batch 1478 in epoch 0, gen_loss = 0.7749597881797845, disc_loss = 0.15923207170963463
Trained batch 1479 in epoch 0, gen_loss = 0.7749899038793268, disc_loss = 0.15921956856366926
Trained batch 1480 in epoch 0, gen_loss = 0.7748189874189597, disc_loss = 0.15924105223109172
Trained batch 1481 in epoch 0, gen_loss = 0.7747564420566546, disc_loss = 0.15922932964124353
Trained batch 1482 in epoch 0, gen_loss = 0.7748686729736289, disc_loss = 0.15924309427059927
Trained batch 1483 in epoch 0, gen_loss = 0.7748029638292655, disc_loss = 0.15922954251642674
Trained batch 1484 in epoch 0, gen_loss = 0.7747648911243336, disc_loss = 0.15923350191336463
Trained batch 1485 in epoch 0, gen_loss = 0.7746278950255139, disc_loss = 0.1592405176886657
Trained batch 1486 in epoch 0, gen_loss = 0.774542755722278, disc_loss = 0.15927021597103713
Trained batch 1487 in epoch 0, gen_loss = 0.7746074966565576, disc_loss = 0.1592191382427387
Trained batch 1488 in epoch 0, gen_loss = 0.774418776390775, disc_loss = 0.15923658317430953
Trained batch 1489 in epoch 0, gen_loss = 0.7745157589448378, disc_loss = 0.15926431600338836
Trained batch 1490 in epoch 0, gen_loss = 0.7743045650897291, disc_loss = 0.159339643049002
Trained batch 1491 in epoch 0, gen_loss = 0.774230046102892, disc_loss = 0.15939877266997482
Trained batch 1492 in epoch 0, gen_loss = 0.774110152828398, disc_loss = 0.15940335240107148
Trained batch 1493 in epoch 0, gen_loss = 0.7739619317862244, disc_loss = 0.1594154529229562
Trained batch 1494 in epoch 0, gen_loss = 0.7737578747663211, disc_loss = 0.15942067444981714
Trained batch 1495 in epoch 0, gen_loss = 0.7736583178773283, disc_loss = 0.1594168726978313
Trained batch 1496 in epoch 0, gen_loss = 0.7735568460577237, disc_loss = 0.15940518505885604
Trained batch 1497 in epoch 0, gen_loss = 0.7736572817027648, disc_loss = 0.1594311006164218
Trained batch 1498 in epoch 0, gen_loss = 0.7734953597675092, disc_loss = 0.1594805387322486
Trained batch 1499 in epoch 0, gen_loss = 0.7735411394437154, disc_loss = 0.15942996123293415
Trained batch 1500 in epoch 0, gen_loss = 0.7734695814356337, disc_loss = 0.15940872024230382
Trained batch 1501 in epoch 0, gen_loss = 0.7733905351114336, disc_loss = 0.1593889799922365
Trained batch 1502 in epoch 0, gen_loss = 0.7733343121851594, disc_loss = 0.15933160546157665
Trained batch 1503 in epoch 0, gen_loss = 0.773305024555389, disc_loss = 0.15930401750681106
Trained batch 1504 in epoch 0, gen_loss = 0.7732679459739761, disc_loss = 0.15930162132439202
Trained batch 1505 in epoch 0, gen_loss = 0.7734900394758856, disc_loss = 0.15930104845251078
Trained batch 1506 in epoch 0, gen_loss = 0.7733074491713802, disc_loss = 0.15944301919760115
Trained batch 1507 in epoch 0, gen_loss = 0.7733221655459556, disc_loss = 0.15938239330064569
Trained batch 1508 in epoch 0, gen_loss = 0.7732811598804631, disc_loss = 0.15935506881862715
Trained batch 1509 in epoch 0, gen_loss = 0.7731973214852099, disc_loss = 0.1593465997817439
Trained batch 1510 in epoch 0, gen_loss = 0.7731719475207465, disc_loss = 0.1593497745151256
Trained batch 1511 in epoch 0, gen_loss = 0.7732842665303636, disc_loss = 0.15928670385881405
Trained batch 1512 in epoch 0, gen_loss = 0.7730818410937705, disc_loss = 0.15930273405384576
Trained batch 1513 in epoch 0, gen_loss = 0.773199933405124, disc_loss = 0.1593372767021919
Trained batch 1514 in epoch 0, gen_loss = 0.7730542196692414, disc_loss = 0.1593644684529479
Trained batch 1515 in epoch 0, gen_loss = 0.7730629326957511, disc_loss = 0.15939276577339023
Trained batch 1516 in epoch 0, gen_loss = 0.7729318378862772, disc_loss = 0.1594261760780761
Trained batch 1517 in epoch 0, gen_loss = 0.7730069049340778, disc_loss = 0.1593592957688903
Trained batch 1518 in epoch 0, gen_loss = 0.7729039891838164, disc_loss = 0.15933498710138236
Trained batch 1519 in epoch 0, gen_loss = 0.7728035264501446, disc_loss = 0.159311033533978
Trained batch 1520 in epoch 0, gen_loss = 0.7727669424559238, disc_loss = 0.15927912379470505
Trained batch 1521 in epoch 0, gen_loss = 0.7726994878202481, disc_loss = 0.159269327994004
Trained batch 1522 in epoch 0, gen_loss = 0.7728277022167013, disc_loss = 0.1592542165173346
Trained batch 1523 in epoch 0, gen_loss = 0.7727920910113752, disc_loss = 0.1592400523323964
Trained batch 1524 in epoch 0, gen_loss = 0.7725926333763561, disc_loss = 0.159313416924236
Trained batch 1525 in epoch 0, gen_loss = 0.7728353108561367, disc_loss = 0.15974133797975557
Trained batch 1526 in epoch 0, gen_loss = 0.7728668044771958, disc_loss = 0.15975130505395715
Trained batch 1527 in epoch 0, gen_loss = 0.7726305897362257, disc_loss = 0.15989942627660905
Trained batch 1528 in epoch 0, gen_loss = 0.7726200676143676, disc_loss = 0.15990628061728995
Trained batch 1529 in epoch 0, gen_loss = 0.7726573900264853, disc_loss = 0.1599566081707713
Trained batch 1530 in epoch 0, gen_loss = 0.7724999327390198, disc_loss = 0.15995435623386978
Trained batch 1531 in epoch 0, gen_loss = 0.7724388078555425, disc_loss = 0.15996850672340282
Trained batch 1532 in epoch 0, gen_loss = 0.7723297797342724, disc_loss = 0.15995216024908937
Trained batch 1533 in epoch 0, gen_loss = 0.7722750062698491, disc_loss = 0.159941412337128
Trained batch 1534 in epoch 0, gen_loss = 0.7721240762973065, disc_loss = 0.15999083507681683
Trained batch 1535 in epoch 0, gen_loss = 0.7719571794732474, disc_loss = 0.16002729008672154
Trained batch 1536 in epoch 0, gen_loss = 0.7719658552514476, disc_loss = 0.16002090871876387
Trained batch 1537 in epoch 0, gen_loss = 0.7718620200112211, disc_loss = 0.16005755706477706
Trained batch 1538 in epoch 0, gen_loss = 0.7718006256844333, disc_loss = 0.16005615071245893
Trained batch 1539 in epoch 0, gen_loss = 0.7717950402722731, disc_loss = 0.16002877821356615
Trained batch 1540 in epoch 0, gen_loss = 0.7717775260953451, disc_loss = 0.1599842287165806
Trained batch 1541 in epoch 0, gen_loss = 0.7716982809756671, disc_loss = 0.15995080134515494
Trained batch 1542 in epoch 0, gen_loss = 0.7715765807007476, disc_loss = 0.15993113712798768
Trained batch 1543 in epoch 0, gen_loss = 0.7715372300171173, disc_loss = 0.15994054000264327
Trained batch 1544 in epoch 0, gen_loss = 0.7716904718706137, disc_loss = 0.15999746502371065
Trained batch 1545 in epoch 0, gen_loss = 0.771530542325079, disc_loss = 0.1600539205391936
Trained batch 1546 in epoch 0, gen_loss = 0.7714734787353794, disc_loss = 0.1600646148359014
Trained batch 1547 in epoch 0, gen_loss = 0.771400764141742, disc_loss = 0.16011058131352582
Trained batch 1548 in epoch 0, gen_loss = 0.7711860563117816, disc_loss = 0.16016160222350603
Trained batch 1549 in epoch 0, gen_loss = 0.7711038528526983, disc_loss = 0.1601751073075819
Trained batch 1550 in epoch 0, gen_loss = 0.7710597322764972, disc_loss = 0.1601702155043064
Trained batch 1551 in epoch 0, gen_loss = 0.7709911608319614, disc_loss = 0.16014364458120683
Trained batch 1552 in epoch 0, gen_loss = 0.7709964491326197, disc_loss = 0.16010895491720412
Trained batch 1553 in epoch 0, gen_loss = 0.770851579009336, disc_loss = 0.16009351434087216
Trained batch 1554 in epoch 0, gen_loss = 0.7708440524780482, disc_loss = 0.16008503283104497
Trained batch 1555 in epoch 0, gen_loss = 0.7707820436067324, disc_loss = 0.1600975725920404
Trained batch 1556 in epoch 0, gen_loss = 0.7707621275842688, disc_loss = 0.16008027410269257
Trained batch 1557 in epoch 0, gen_loss = 0.7706683961165273, disc_loss = 0.16005966688380177
Trained batch 1558 in epoch 0, gen_loss = 0.7706644751270127, disc_loss = 0.16009951508908657
Trained batch 1559 in epoch 0, gen_loss = 0.7707319272825351, disc_loss = 0.16003488129921234
Trained batch 1560 in epoch 0, gen_loss = 0.7707229222073759, disc_loss = 0.15995198908837097
Trained batch 1561 in epoch 0, gen_loss = 0.7708077689635159, disc_loss = 0.15987449776003837
Trained batch 1562 in epoch 0, gen_loss = 0.7707247722057372, disc_loss = 0.15979816771609326
Trained batch 1563 in epoch 0, gen_loss = 0.7706136368691464, disc_loss = 0.15974662388014532
Trained batch 1564 in epoch 0, gen_loss = 0.7708882835155098, disc_loss = 0.1596753501745399
Trained batch 1565 in epoch 0, gen_loss = 0.7710043087049767, disc_loss = 0.1595927369963713
Trained batch 1566 in epoch 0, gen_loss = 0.7707531151873486, disc_loss = 0.1596644976672294
Trained batch 1567 in epoch 0, gen_loss = 0.7709158418167915, disc_loss = 0.15972802799764654
Trained batch 1568 in epoch 0, gen_loss = 0.7709719812019074, disc_loss = 0.15965317436013135
Trained batch 1569 in epoch 0, gen_loss = 0.7708961957389382, disc_loss = 0.15961552063332407
Trained batch 1570 in epoch 0, gen_loss = 0.7709488945922451, disc_loss = 0.15953821430761156
Trained batch 1571 in epoch 0, gen_loss = 0.7709533306213129, disc_loss = 0.15948683608180556
Trained batch 1572 in epoch 0, gen_loss = 0.7708739946582707, disc_loss = 0.15943159780510063
Trained batch 1573 in epoch 0, gen_loss = 0.7709950945012299, disc_loss = 0.15936421446151336
Trained batch 1574 in epoch 0, gen_loss = 0.7709028320274656, disc_loss = 0.15935309944984813
Trained batch 1575 in epoch 0, gen_loss = 0.7708924030554174, disc_loss = 0.15933958497143652
Trained batch 1576 in epoch 0, gen_loss = 0.7707892628546069, disc_loss = 0.1593641607040928
Trained batch 1577 in epoch 0, gen_loss = 0.770851173724965, disc_loss = 0.1593761688229039
Trained batch 1578 in epoch 0, gen_loss = 0.7707152300389829, disc_loss = 0.1593400779921335
Trained batch 1579 in epoch 0, gen_loss = 0.7705499633392201, disc_loss = 0.15941318380926395
Trained batch 1580 in epoch 0, gen_loss = 0.7705855358446195, disc_loss = 0.1594626144230646
Testing Epoch 0

Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 0.6344691514968872, disc_loss = 0.12266238778829575
Trained batch 1 in epoch 1, gen_loss = 0.6539112627506256, disc_loss = 0.11760895326733589
Trained batch 2 in epoch 1, gen_loss = 0.7291297316551208, disc_loss = 0.1159628505508105
Trained batch 3 in epoch 1, gen_loss = 0.7407703548669815, disc_loss = 0.11184067465364933
Trained batch 4 in epoch 1, gen_loss = 0.7000283122062683, disc_loss = 0.12367292791604996
Trained batch 5 in epoch 1, gen_loss = 0.7073404689629873, disc_loss = 0.12195081884662311
Trained batch 6 in epoch 1, gen_loss = 0.7299645032201495, disc_loss = 0.1155583986214229
Trained batch 7 in epoch 1, gen_loss = 0.7056877389550209, disc_loss = 0.11223564110696316
Trained batch 8 in epoch 1, gen_loss = 0.7313584023051791, disc_loss = 0.10670363820261425
Trained batch 9 in epoch 1, gen_loss = 0.7096531093120575, disc_loss = 0.11989516690373421
Trained batch 10 in epoch 1, gen_loss = 0.7348745627836748, disc_loss = 0.13356292044574564
Trained batch 11 in epoch 1, gen_loss = 0.7831413447856903, disc_loss = 0.12959973203639188
Trained batch 12 in epoch 1, gen_loss = 0.7929429090940036, disc_loss = 0.12106125715833443
Trained batch 13 in epoch 1, gen_loss = 0.8001781616892133, disc_loss = 0.11544278796230044
Trained batch 14 in epoch 1, gen_loss = 0.8021901210149129, disc_loss = 0.10952004690965017
Trained batch 15 in epoch 1, gen_loss = 0.7965822480618954, disc_loss = 0.10337047191569582
Trained batch 16 in epoch 1, gen_loss = 0.8175148648374221, disc_loss = 0.09913907775326687
Trained batch 17 in epoch 1, gen_loss = 0.8205141921838125, disc_loss = 0.09425625370608436
Trained batch 18 in epoch 1, gen_loss = 0.8114560183725859, disc_loss = 0.09284566499684986
Trained batch 19 in epoch 1, gen_loss = 0.8222833305597306, disc_loss = 0.09071047604084015
Trained batch 20 in epoch 1, gen_loss = 0.8169079479717073, disc_loss = 0.09218451380729675
Trained batch 21 in epoch 1, gen_loss = 0.8233685412190177, disc_loss = 0.09109845181757753
Trained batch 22 in epoch 1, gen_loss = 0.8097383017125337, disc_loss = 0.09412700099789578
Trained batch 23 in epoch 1, gen_loss = 0.8171700462698936, disc_loss = 0.09584988746792078
Trained batch 24 in epoch 1, gen_loss = 0.8197541069984436, disc_loss = 0.09273270405828953
Trained batch 25 in epoch 1, gen_loss = 0.80754753947258, disc_loss = 0.09413558509773932
Trained batch 26 in epoch 1, gen_loss = 0.797862810117227, disc_loss = 0.09660142253118532
Trained batch 27 in epoch 1, gen_loss = 0.7993138794388089, disc_loss = 0.09663836185687355
Trained batch 28 in epoch 1, gen_loss = 0.7900707618943577, disc_loss = 0.10132472634572408
Trained batch 29 in epoch 1, gen_loss = 0.7968328138192494, disc_loss = 0.10488736784706514
Trained batch 30 in epoch 1, gen_loss = 0.7898838423913525, disc_loss = 0.10835569574227256
Trained batch 31 in epoch 1, gen_loss = 0.7849832829087973, disc_loss = 0.1083358601317741
Trained batch 32 in epoch 1, gen_loss = 0.7805901531017188, disc_loss = 0.1092331689979994
Trained batch 33 in epoch 1, gen_loss = 0.785424307865255, disc_loss = 0.10986458471811869
Trained batch 34 in epoch 1, gen_loss = 0.776980595929282, disc_loss = 0.10962895096412727
Trained batch 35 in epoch 1, gen_loss = 0.7709181822008557, disc_loss = 0.11061433107695645
Trained batch 36 in epoch 1, gen_loss = 0.7699724645227999, disc_loss = 0.10916959982667421
Trained batch 37 in epoch 1, gen_loss = 0.7666365723860892, disc_loss = 0.10868981191398282
Trained batch 38 in epoch 1, gen_loss = 0.7635540457872244, disc_loss = 0.10810985803031005
Trained batch 39 in epoch 1, gen_loss = 0.7741974398493767, disc_loss = 0.11088180192746222
Trained batch 40 in epoch 1, gen_loss = 0.7706612246792491, disc_loss = 0.11189730233717256
Trained batch 41 in epoch 1, gen_loss = 0.7699965380486988, disc_loss = 0.11292544845491648
Trained batch 42 in epoch 1, gen_loss = 0.7729393895282302, disc_loss = 0.11612896157731843
Trained batch 43 in epoch 1, gen_loss = 0.7670418308539824, disc_loss = 0.11906851070340384
Trained batch 44 in epoch 1, gen_loss = 0.769160434934828, disc_loss = 0.12042804811563756
Trained batch 45 in epoch 1, gen_loss = 0.7665960775769275, disc_loss = 0.11951052531114091
Trained batch 46 in epoch 1, gen_loss = 0.7609477055833694, disc_loss = 0.12332459305353621
Trained batch 47 in epoch 1, gen_loss = 0.7722537082930406, disc_loss = 0.13175188598688692
Trained batch 48 in epoch 1, gen_loss = 0.7722310983404821, disc_loss = 0.13221660929218848
Trained batch 49 in epoch 1, gen_loss = 0.7694229805469512, disc_loss = 0.1325843182578683
Trained batch 50 in epoch 1, gen_loss = 0.7669513611232534, disc_loss = 0.1342475528591404
Trained batch 51 in epoch 1, gen_loss = 0.7625979987474588, disc_loss = 0.13427982225011176
Trained batch 52 in epoch 1, gen_loss = 0.7598405716554174, disc_loss = 0.13376564831244495
Trained batch 53 in epoch 1, gen_loss = 0.7588536584818805, disc_loss = 0.13370441262506777
Trained batch 54 in epoch 1, gen_loss = 0.7577414046634328, disc_loss = 0.13370606496252796
Trained batch 55 in epoch 1, gen_loss = 0.7568225019744464, disc_loss = 0.13285823515616357
Trained batch 56 in epoch 1, gen_loss = 0.7538693620447527, disc_loss = 0.1333906107108321
Trained batch 57 in epoch 1, gen_loss = 0.7512358149577831, disc_loss = 0.1329772281299891
Trained batch 58 in epoch 1, gen_loss = 0.7491312804868666, disc_loss = 0.13373096303035648
Trained batch 59 in epoch 1, gen_loss = 0.7450949281454087, disc_loss = 0.13485168159628907
Trained batch 60 in epoch 1, gen_loss = 0.7463490484190769, disc_loss = 0.1348894772532045
Trained batch 61 in epoch 1, gen_loss = 0.7478533348729534, disc_loss = 0.13618836879369714
Trained batch 62 in epoch 1, gen_loss = 0.7446210128920419, disc_loss = 0.13753041923637427
Trained batch 63 in epoch 1, gen_loss = 0.7409782782196999, disc_loss = 0.13718222992611118
Trained batch 64 in epoch 1, gen_loss = 0.7463379896604098, disc_loss = 0.13776819846377922
Trained batch 65 in epoch 1, gen_loss = 0.7463786511710195, disc_loss = 0.13886778917389386
Trained batch 66 in epoch 1, gen_loss = 0.742902571585641, disc_loss = 0.1392086257518672
Trained batch 67 in epoch 1, gen_loss = 0.7411077259217992, disc_loss = 0.14033000853241367
Trained batch 68 in epoch 1, gen_loss = 0.7441210323485775, disc_loss = 0.1422195670235416
Trained batch 69 in epoch 1, gen_loss = 0.7409147500991822, disc_loss = 0.1432428430499775
Trained batch 70 in epoch 1, gen_loss = 0.7401303548208424, disc_loss = 0.14308633437563836
Trained batch 71 in epoch 1, gen_loss = 0.7379094950026936, disc_loss = 0.14403169439174235
Trained batch 72 in epoch 1, gen_loss = 0.7391928524187167, disc_loss = 0.1430862095104913
Trained batch 73 in epoch 1, gen_loss = 0.7398487740271801, disc_loss = 0.14374010126433662
Trained batch 74 in epoch 1, gen_loss = 0.7372720925013224, disc_loss = 0.14511274598538876
Trained batch 75 in epoch 1, gen_loss = 0.7372728225431944, disc_loss = 0.1482938832211259
Trained batch 76 in epoch 1, gen_loss = 0.7353762643677848, disc_loss = 0.14825161558563832
Trained batch 77 in epoch 1, gen_loss = 0.7339723927852435, disc_loss = 0.14800613624258682
Trained batch 78 in epoch 1, gen_loss = 0.7323455380488045, disc_loss = 0.1482110970618227
Trained batch 79 in epoch 1, gen_loss = 0.7306736268103122, disc_loss = 0.14875906298402697
Trained batch 80 in epoch 1, gen_loss = 0.7314157934836399, disc_loss = 0.14920518172467934
Trained batch 81 in epoch 1, gen_loss = 0.7294042786447014, disc_loss = 0.15002650606286963
Trained batch 82 in epoch 1, gen_loss = 0.7266505791480282, disc_loss = 0.150214997602694
Trained batch 83 in epoch 1, gen_loss = 0.7282221154088065, disc_loss = 0.15022309924963684
Trained batch 84 in epoch 1, gen_loss = 0.727589634586783, disc_loss = 0.15001751221716403
Trained batch 85 in epoch 1, gen_loss = 0.7252899373686591, disc_loss = 0.15031989354120437
Trained batch 86 in epoch 1, gen_loss = 0.7258018138764919, disc_loss = 0.15072686801097174
Trained batch 87 in epoch 1, gen_loss = 0.7243274247104471, disc_loss = 0.15060925028625538
Trained batch 88 in epoch 1, gen_loss = 0.723213761040334, disc_loss = 0.150879452925887
Trained batch 89 in epoch 1, gen_loss = 0.7262133426136441, disc_loss = 0.15195175510727696
Trained batch 90 in epoch 1, gen_loss = 0.7258791674624433, disc_loss = 0.15233344103690688
Trained batch 91 in epoch 1, gen_loss = 0.7246716275163319, disc_loss = 0.15268175338354448
Trained batch 92 in epoch 1, gen_loss = 0.7222370140014156, disc_loss = 0.1527877876394859
Trained batch 93 in epoch 1, gen_loss = 0.724346971892296, disc_loss = 0.15284035230015822
Trained batch 94 in epoch 1, gen_loss = 0.7241320892384178, disc_loss = 0.15242527693902191
Trained batch 95 in epoch 1, gen_loss = 0.7237623787174622, disc_loss = 0.15191613675172752
Trained batch 96 in epoch 1, gen_loss = 0.7234136714148767, disc_loss = 0.15137173721240355
Trained batch 97 in epoch 1, gen_loss = 0.7223230740245508, disc_loss = 0.1508772387834532
Trained batch 98 in epoch 1, gen_loss = 0.7214859164122379, disc_loss = 0.15044958695694052
Trained batch 99 in epoch 1, gen_loss = 0.7227519202232361, disc_loss = 0.1497067721374333
Trained batch 100 in epoch 1, gen_loss = 0.7196564633067292, disc_loss = 0.15180983978996773
Trained batch 101 in epoch 1, gen_loss = 0.722434924513686, disc_loss = 0.15267526740025655
Trained batch 102 in epoch 1, gen_loss = 0.7240410244580612, disc_loss = 0.15184987041629056
Trained batch 103 in epoch 1, gen_loss = 0.7229882610531954, disc_loss = 0.15300442323160285
Trained batch 104 in epoch 1, gen_loss = 0.7228448294457935, disc_loss = 0.1531645555049181
Trained batch 105 in epoch 1, gen_loss = 0.7228338038021663, disc_loss = 0.15237971614905685
Trained batch 106 in epoch 1, gen_loss = 0.723784409393774, disc_loss = 0.15216764760699786
Trained batch 107 in epoch 1, gen_loss = 0.7238326409348735, disc_loss = 0.15186511140523684
Trained batch 108 in epoch 1, gen_loss = 0.724168324142421, disc_loss = 0.15177133305152074
Trained batch 109 in epoch 1, gen_loss = 0.721463350274346, disc_loss = 0.15206529818136583
Trained batch 110 in epoch 1, gen_loss = 0.7241584959330859, disc_loss = 0.1524553082312818
Trained batch 111 in epoch 1, gen_loss = 0.7258358193295342, disc_loss = 0.15139930703610713
Trained batch 112 in epoch 1, gen_loss = 0.7250175855856026, disc_loss = 0.15120924450457096
Trained batch 113 in epoch 1, gen_loss = 0.7248931171601278, disc_loss = 0.15092320022941158
Trained batch 114 in epoch 1, gen_loss = 0.7253590335016665, disc_loss = 0.15085393567772015
Trained batch 115 in epoch 1, gen_loss = 0.7261217616755387, disc_loss = 0.15019040954588303
Trained batch 116 in epoch 1, gen_loss = 0.7274496045886961, disc_loss = 0.1495890104267587
Trained batch 117 in epoch 1, gen_loss = 0.7260372335627928, disc_loss = 0.15050951039450147
Trained batch 118 in epoch 1, gen_loss = 0.7267970608062103, disc_loss = 0.15022917149760642
Trained batch 119 in epoch 1, gen_loss = 0.729118334253629, disc_loss = 0.1500599891723444
Trained batch 120 in epoch 1, gen_loss = 0.726049841928088, disc_loss = 0.15229528534326178
Trained batch 121 in epoch 1, gen_loss = 0.7279096265308193, disc_loss = 0.1523371607095736
Trained batch 122 in epoch 1, gen_loss = 0.7272877005057606, disc_loss = 0.1524184219751174
Trained batch 123 in epoch 1, gen_loss = 0.7264552673985881, disc_loss = 0.1521392127709283
Trained batch 124 in epoch 1, gen_loss = 0.7254858951568603, disc_loss = 0.15233227749168873
Trained batch 125 in epoch 1, gen_loss = 0.72745842451141, disc_loss = 0.15202509571931191
Trained batch 126 in epoch 1, gen_loss = 0.7278437811558641, disc_loss = 0.15212897165847106
Trained batch 127 in epoch 1, gen_loss = 0.7260842435061932, disc_loss = 0.15358241666399408
Trained batch 128 in epoch 1, gen_loss = 0.7250550375428311, disc_loss = 0.15364637966592645
Trained batch 129 in epoch 1, gen_loss = 0.7277468883074247, disc_loss = 0.15434147264235296
Trained batch 130 in epoch 1, gen_loss = 0.7293330631183303, disc_loss = 0.15423846934417276
Trained batch 131 in epoch 1, gen_loss = 0.7286775879787676, disc_loss = 0.15493010341500243
Trained batch 132 in epoch 1, gen_loss = 0.7288923389033267, disc_loss = 0.15499088253573814
Trained batch 133 in epoch 1, gen_loss = 0.7295165480072818, disc_loss = 0.15536723971200078
Trained batch 134 in epoch 1, gen_loss = 0.7281960739029778, disc_loss = 0.15603695607019796
Trained batch 135 in epoch 1, gen_loss = 0.7281433584935525, disc_loss = 0.15582742044866524
Trained batch 136 in epoch 1, gen_loss = 0.7269677920063047, disc_loss = 0.15610295704083285
Trained batch 137 in epoch 1, gen_loss = 0.7284562138543613, disc_loss = 0.1561863575319665
Trained batch 138 in epoch 1, gen_loss = 0.7284619422267666, disc_loss = 0.15611826597625833
Trained batch 139 in epoch 1, gen_loss = 0.728186952642032, disc_loss = 0.1568069945089519
Trained batch 140 in epoch 1, gen_loss = 0.7278623995206035, disc_loss = 0.15664312736203906
Trained batch 141 in epoch 1, gen_loss = 0.7257534395641004, disc_loss = 0.15700128481684017
Trained batch 142 in epoch 1, gen_loss = 0.7265116489016926, disc_loss = 0.15751893105884116
Trained batch 143 in epoch 1, gen_loss = 0.7269220306641526, disc_loss = 0.1575693128656389
Trained batch 144 in epoch 1, gen_loss = 0.7247831782390332, disc_loss = 0.1583257889567778
Trained batch 145 in epoch 1, gen_loss = 0.7261591849670018, disc_loss = 0.15882500941061403
Trained batch 146 in epoch 1, gen_loss = 0.7266555669761839, disc_loss = 0.15853464031959472
Trained batch 147 in epoch 1, gen_loss = 0.7255935115185944, disc_loss = 0.15888658705847086
Trained batch 148 in epoch 1, gen_loss = 0.7246758667814651, disc_loss = 0.15917534312395842
Trained batch 149 in epoch 1, gen_loss = 0.7242150801420212, disc_loss = 0.1590277345602711
Trained batch 150 in epoch 1, gen_loss = 0.7233172917602867, disc_loss = 0.15923245731025737
Trained batch 151 in epoch 1, gen_loss = 0.7238442135092459, disc_loss = 0.1592789217462077
Trained batch 152 in epoch 1, gen_loss = 0.7234152650911044, disc_loss = 0.1592693213568209
Trained batch 153 in epoch 1, gen_loss = 0.7226361224016586, disc_loss = 0.15953494314491362
Trained batch 154 in epoch 1, gen_loss = 0.7227780290188328, disc_loss = 0.15898778790668133
Trained batch 155 in epoch 1, gen_loss = 0.7226722364624342, disc_loss = 0.15882116543033567
Trained batch 156 in epoch 1, gen_loss = 0.7230230928606288, disc_loss = 0.15870283521522002
Trained batch 157 in epoch 1, gen_loss = 0.7234549082909958, disc_loss = 0.15852816936949007
Trained batch 158 in epoch 1, gen_loss = 0.7234499700039437, disc_loss = 0.15781929406026998
Trained batch 159 in epoch 1, gen_loss = 0.7232963370159269, disc_loss = 0.15755222003208474
Trained batch 160 in epoch 1, gen_loss = 0.7228891940220542, disc_loss = 0.15754628339955895
Trained batch 161 in epoch 1, gen_loss = 0.7230054664391058, disc_loss = 0.15783946208057947
Trained batch 162 in epoch 1, gen_loss = 0.7218564874921108, disc_loss = 0.15811082539062923
Trained batch 163 in epoch 1, gen_loss = 0.7224578917389963, disc_loss = 0.15823391399050996
Trained batch 164 in epoch 1, gen_loss = 0.7232662881865646, disc_loss = 0.15802404719094434
Trained batch 165 in epoch 1, gen_loss = 0.7214874718562666, disc_loss = 0.1580702658989523
Trained batch 166 in epoch 1, gen_loss = 0.7241606084172597, disc_loss = 0.15924905857327812
Trained batch 167 in epoch 1, gen_loss = 0.7229545364777247, disc_loss = 0.15949406298542662
Trained batch 168 in epoch 1, gen_loss = 0.7240134375335197, disc_loss = 0.15959158858295375
Trained batch 169 in epoch 1, gen_loss = 0.7236243111245773, disc_loss = 0.15973590280422392
Trained batch 170 in epoch 1, gen_loss = 0.7235452295743932, disc_loss = 0.16001783007461773
Trained batch 171 in epoch 1, gen_loss = 0.7234307402788207, disc_loss = 0.16021685857802284
Trained batch 172 in epoch 1, gen_loss = 0.7232082375901283, disc_loss = 0.16045760678805712
Trained batch 173 in epoch 1, gen_loss = 0.7226094391154146, disc_loss = 0.16131169512739468
Trained batch 174 in epoch 1, gen_loss = 0.722061561175755, disc_loss = 0.16171540108110224
Trained batch 175 in epoch 1, gen_loss = 0.723200207745487, disc_loss = 0.16190656123217195
Trained batch 176 in epoch 1, gen_loss = 0.7236621851301462, disc_loss = 0.16226681411308422
Trained batch 177 in epoch 1, gen_loss = 0.7226378422104911, disc_loss = 0.16286857845784908
Trained batch 178 in epoch 1, gen_loss = 0.7224258956962457, disc_loss = 0.16256405772152227
Trained batch 179 in epoch 1, gen_loss = 0.7228076186445024, disc_loss = 0.1624472699335052
Trained batch 180 in epoch 1, gen_loss = 0.7221881309266907, disc_loss = 0.16274216047678533
Trained batch 181 in epoch 1, gen_loss = 0.7219144060061529, disc_loss = 0.1628549329956973
Trained batch 182 in epoch 1, gen_loss = 0.7218966933547474, disc_loss = 0.1629662222325639
Trained batch 183 in epoch 1, gen_loss = 0.7214647414891616, disc_loss = 0.16334137677862917
Trained batch 184 in epoch 1, gen_loss = 0.7202552495775996, disc_loss = 0.1637793021528302
Trained batch 185 in epoch 1, gen_loss = 0.7201989270666594, disc_loss = 0.16401592514888252
Trained batch 186 in epoch 1, gen_loss = 0.719581843697451, disc_loss = 0.16376004333204444
Trained batch 187 in epoch 1, gen_loss = 0.7193223136536618, disc_loss = 0.16339136252893097
Trained batch 188 in epoch 1, gen_loss = 0.719495607746972, disc_loss = 0.16356448432006848
Trained batch 189 in epoch 1, gen_loss = 0.7199583643361142, disc_loss = 0.16297844421902768
Trained batch 190 in epoch 1, gen_loss = 0.7188851234176397, disc_loss = 0.16303209212476982
Trained batch 191 in epoch 1, gen_loss = 0.7188196641703447, disc_loss = 0.162982741225278
Trained batch 192 in epoch 1, gen_loss = 0.7184383066207016, disc_loss = 0.16312344550816196
Trained batch 193 in epoch 1, gen_loss = 0.7191180457773897, disc_loss = 0.16312665055438721
Trained batch 194 in epoch 1, gen_loss = 0.7180740753809611, disc_loss = 0.16295686930609055
Trained batch 195 in epoch 1, gen_loss = 0.7192783906143538, disc_loss = 0.16308938773653034
Trained batch 196 in epoch 1, gen_loss = 0.7196896297072396, disc_loss = 0.16313898246640784
Trained batch 197 in epoch 1, gen_loss = 0.7183261387275927, disc_loss = 0.16348245183965474
Trained batch 198 in epoch 1, gen_loss = 0.7199973676671934, disc_loss = 0.16330310942876577
Trained batch 199 in epoch 1, gen_loss = 0.7201771268248558, disc_loss = 0.16324636683799326
Trained batch 200 in epoch 1, gen_loss = 0.7204361320728093, disc_loss = 0.16303232913623697
Trained batch 201 in epoch 1, gen_loss = 0.7203427272858006, disc_loss = 0.1629199667529452
Trained batch 202 in epoch 1, gen_loss = 0.7211393781483467, disc_loss = 0.16354123962666894
Trained batch 203 in epoch 1, gen_loss = 0.7212202280175453, disc_loss = 0.16325363499459392
Trained batch 204 in epoch 1, gen_loss = 0.7211734286168726, disc_loss = 0.1629789211491986
Trained batch 205 in epoch 1, gen_loss = 0.7212525010108948, disc_loss = 0.1628007522865551
Trained batch 206 in epoch 1, gen_loss = 0.7206977024170511, disc_loss = 0.1627961400140455
Trained batch 207 in epoch 1, gen_loss = 0.7209295166226534, disc_loss = 0.1631248209428472
Trained batch 208 in epoch 1, gen_loss = 0.7205628960896907, disc_loss = 0.16269126464055772
Trained batch 209 in epoch 1, gen_loss = 0.7214532046090989, disc_loss = 0.16216155465337492
Trained batch 210 in epoch 1, gen_loss = 0.7213721817703609, disc_loss = 0.16179947425297933
Trained batch 211 in epoch 1, gen_loss = 0.7208810906927541, disc_loss = 0.16130579822644028
Trained batch 212 in epoch 1, gen_loss = 0.7202059766496292, disc_loss = 0.16097643598039665
Trained batch 213 in epoch 1, gen_loss = 0.7216239178849158, disc_loss = 0.16124193444325824
Trained batch 214 in epoch 1, gen_loss = 0.7212212565333345, disc_loss = 0.16085843184832918
Trained batch 215 in epoch 1, gen_loss = 0.721081466310554, disc_loss = 0.1605444892430333
Trained batch 216 in epoch 1, gen_loss = 0.7210708128691818, disc_loss = 0.16051996465823892
Trained batch 217 in epoch 1, gen_loss = 0.7217901617015173, disc_loss = 0.1600192771335944
Trained batch 218 in epoch 1, gen_loss = 0.7212761501743369, disc_loss = 0.16002563374397688
Trained batch 219 in epoch 1, gen_loss = 0.7226356584917415, disc_loss = 0.1600583412176506
Trained batch 220 in epoch 1, gen_loss = 0.7213674286102277, disc_loss = 0.1606197127676253
Trained batch 221 in epoch 1, gen_loss = 0.7219936883932835, disc_loss = 0.1603978539120641
Trained batch 222 in epoch 1, gen_loss = 0.7214074232385832, disc_loss = 0.16072522268334044
Trained batch 223 in epoch 1, gen_loss = 0.721784276222544, disc_loss = 0.16045708416329166
Trained batch 224 in epoch 1, gen_loss = 0.7207328674528334, disc_loss = 0.1608847624146276
Trained batch 225 in epoch 1, gen_loss = 0.7200083537439329, disc_loss = 0.16084535480106035
Trained batch 226 in epoch 1, gen_loss = 0.7206585134178531, disc_loss = 0.1611502627526217
Trained batch 227 in epoch 1, gen_loss = 0.7197992344174469, disc_loss = 0.1612567840911971
Trained batch 228 in epoch 1, gen_loss = 0.7183672671234764, disc_loss = 0.16138529498536774
Trained batch 229 in epoch 1, gen_loss = 0.7196906107923259, disc_loss = 0.16170117408847032
Trained batch 230 in epoch 1, gen_loss = 0.7195444948229439, disc_loss = 0.16136013807575683
Trained batch 231 in epoch 1, gen_loss = 0.7195137217640877, disc_loss = 0.1610519400845956
Trained batch 232 in epoch 1, gen_loss = 0.7187497968837427, disc_loss = 0.16115647270604008
Trained batch 233 in epoch 1, gen_loss = 0.720001985374679, disc_loss = 0.16077059205685162
Trained batch 234 in epoch 1, gen_loss = 0.7199632601535066, disc_loss = 0.16044642269769882
Trained batch 235 in epoch 1, gen_loss = 0.7197186876151521, disc_loss = 0.16024685481373788
Trained batch 236 in epoch 1, gen_loss = 0.7209046913098686, disc_loss = 0.1601470759224917
Trained batch 237 in epoch 1, gen_loss = 0.7197059555714872, disc_loss = 0.15990624856203794
Trained batch 238 in epoch 1, gen_loss = 0.719336088980591, disc_loss = 0.15975338024979605
Trained batch 239 in epoch 1, gen_loss = 0.7203362909456094, disc_loss = 0.1595953934903567
Trained batch 240 in epoch 1, gen_loss = 0.7196182761944181, disc_loss = 0.1594869370545218
Trained batch 241 in epoch 1, gen_loss = 0.7191459154787142, disc_loss = 0.15926505746088984
Trained batch 242 in epoch 1, gen_loss = 0.71977624407521, disc_loss = 0.15905693201769772
Trained batch 243 in epoch 1, gen_loss = 0.7202942344497462, disc_loss = 0.15961745397386248
Trained batch 244 in epoch 1, gen_loss = 0.7193144117082868, disc_loss = 0.1609435186474299
Trained batch 245 in epoch 1, gen_loss = 0.7193951107622162, disc_loss = 0.16091509851649766
Trained batch 246 in epoch 1, gen_loss = 0.7183245462685944, disc_loss = 0.16088107624185471
Trained batch 247 in epoch 1, gen_loss = 0.7187446729550439, disc_loss = 0.1610065932731114
Trained batch 248 in epoch 1, gen_loss = 0.7191933622082554, disc_loss = 0.1613342339270206
Trained batch 249 in epoch 1, gen_loss = 0.7188036431074143, disc_loss = 0.1617411691918969
Trained batch 250 in epoch 1, gen_loss = 0.7180385835379718, disc_loss = 0.1615392835922094
Trained batch 251 in epoch 1, gen_loss = 0.7179286294276752, disc_loss = 0.16147349272958106
Trained batch 252 in epoch 1, gen_loss = 0.7186511734964348, disc_loss = 0.1613283489017265
Trained batch 253 in epoch 1, gen_loss = 0.7179837601156686, disc_loss = 0.16129249387868042
Trained batch 254 in epoch 1, gen_loss = 0.7176227685283212, disc_loss = 0.1614009707654808
Trained batch 255 in epoch 1, gen_loss = 0.7176895682932809, disc_loss = 0.16112473305111052
Trained batch 256 in epoch 1, gen_loss = 0.7172454554978975, disc_loss = 0.1613033861574148
Trained batch 257 in epoch 1, gen_loss = 0.7175479347622672, disc_loss = 0.16104356341728177
Trained batch 258 in epoch 1, gen_loss = 0.7179120458000875, disc_loss = 0.16092874153614276
Trained batch 259 in epoch 1, gen_loss = 0.7176486410773717, disc_loss = 0.1606201272816039
Trained batch 260 in epoch 1, gen_loss = 0.7175663514383908, disc_loss = 0.1605233037451789
Trained batch 261 in epoch 1, gen_loss = 0.7173742901050407, disc_loss = 0.16062944440014718
Trained batch 262 in epoch 1, gen_loss = 0.7171149114465533, disc_loss = 0.16087020860680382
Trained batch 263 in epoch 1, gen_loss = 0.7173930400926055, disc_loss = 0.16094542555087668
Trained batch 264 in epoch 1, gen_loss = 0.7176974288697513, disc_loss = 0.1606011121129652
Trained batch 265 in epoch 1, gen_loss = 0.7175166330167225, disc_loss = 0.16046749854362324
Trained batch 266 in epoch 1, gen_loss = 0.7183532778466686, disc_loss = 0.16029440411383963
Trained batch 267 in epoch 1, gen_loss = 0.7182416930349905, disc_loss = 0.16012263376571573
Trained batch 268 in epoch 1, gen_loss = 0.7178371002461388, disc_loss = 0.15976042461799644
Trained batch 269 in epoch 1, gen_loss = 0.7189322896577693, disc_loss = 0.15949180775356514
Trained batch 270 in epoch 1, gen_loss = 0.7190664028989433, disc_loss = 0.1591309880652221
Trained batch 271 in epoch 1, gen_loss = 0.7193653928663801, disc_loss = 0.15901052632013007
Trained batch 272 in epoch 1, gen_loss = 0.7191646156948565, disc_loss = 0.1590406442531845
Trained batch 273 in epoch 1, gen_loss = 0.7197562511602458, disc_loss = 0.15886987205322858
Trained batch 274 in epoch 1, gen_loss = 0.7205135162310167, disc_loss = 0.15854915960945867
Trained batch 275 in epoch 1, gen_loss = 0.72041648723509, disc_loss = 0.15877710375259968
Trained batch 276 in epoch 1, gen_loss = 0.7197857891824702, disc_loss = 0.15869161309775248
Trained batch 277 in epoch 1, gen_loss = 0.71955194736985, disc_loss = 0.15852558651014412
Trained batch 278 in epoch 1, gen_loss = 0.7185509028614209, disc_loss = 0.15856079346630522
Trained batch 279 in epoch 1, gen_loss = 0.7197511531412601, disc_loss = 0.15906000659534975
Trained batch 280 in epoch 1, gen_loss = 0.7203986877012083, disc_loss = 0.1586133857917213
Trained batch 281 in epoch 1, gen_loss = 0.7205625393077837, disc_loss = 0.15870897726202055
Trained batch 282 in epoch 1, gen_loss = 0.7199726160549865, disc_loss = 0.1585206299190913
Trained batch 283 in epoch 1, gen_loss = 0.7202724710526601, disc_loss = 0.15885391992083947
Trained batch 284 in epoch 1, gen_loss = 0.7204391748235937, disc_loss = 0.1584822026326468
Trained batch 285 in epoch 1, gen_loss = 0.7219612261840513, disc_loss = 0.15899130067026074
Trained batch 286 in epoch 1, gen_loss = 0.7211231228989591, disc_loss = 0.16071171576371385
Trained batch 287 in epoch 1, gen_loss = 0.7201374437039098, disc_loss = 0.16077474143174994
Trained batch 288 in epoch 1, gen_loss = 0.7209574218233564, disc_loss = 0.16120258696171033
Trained batch 289 in epoch 1, gen_loss = 0.7210020060169285, disc_loss = 0.1611916596583765
Trained batch 290 in epoch 1, gen_loss = 0.7206514896600926, disc_loss = 0.16143382400197467
Trained batch 291 in epoch 1, gen_loss = 0.7204222688323831, disc_loss = 0.16161080384116672
Trained batch 292 in epoch 1, gen_loss = 0.7206737536415712, disc_loss = 0.16170859352745903
Trained batch 293 in epoch 1, gen_loss = 0.7206234034835076, disc_loss = 0.16162445092713143
Trained batch 294 in epoch 1, gen_loss = 0.7203351229934369, disc_loss = 0.16169499023107148
Trained batch 295 in epoch 1, gen_loss = 0.7210831594829624, disc_loss = 0.16204938237756691
Trained batch 296 in epoch 1, gen_loss = 0.7209037280443943, disc_loss = 0.16191957475184793
Trained batch 297 in epoch 1, gen_loss = 0.7202235205261499, disc_loss = 0.16193980629237106
Trained batch 298 in epoch 1, gen_loss = 0.7209544788834243, disc_loss = 0.1617362875067769
Trained batch 299 in epoch 1, gen_loss = 0.7208836848537127, disc_loss = 0.16162405272945762
Trained batch 300 in epoch 1, gen_loss = 0.7202622398387554, disc_loss = 0.1615856505769531
Trained batch 301 in epoch 1, gen_loss = 0.7204472145300038, disc_loss = 0.161557013927558
Trained batch 302 in epoch 1, gen_loss = 0.719886707295679, disc_loss = 0.16147811096714865
Trained batch 303 in epoch 1, gen_loss = 0.720006147007409, disc_loss = 0.16112105433804622
Trained batch 304 in epoch 1, gen_loss = 0.7206637088392601, disc_loss = 0.16071629392929743
Trained batch 305 in epoch 1, gen_loss = 0.720235700603404, disc_loss = 0.1605400768918247
Trained batch 306 in epoch 1, gen_loss = 0.7195501625537872, disc_loss = 0.16046743760498222
Trained batch 307 in epoch 1, gen_loss = 0.7199258402764023, disc_loss = 0.16035221689441181
Trained batch 308 in epoch 1, gen_loss = 0.720302143625457, disc_loss = 0.16008306859501165
Trained batch 309 in epoch 1, gen_loss = 0.7202249597157201, disc_loss = 0.15991325249234514
Trained batch 310 in epoch 1, gen_loss = 0.7198072872169532, disc_loss = 0.15962231490413667
Trained batch 311 in epoch 1, gen_loss = 0.7192155784712388, disc_loss = 0.15948570431926504
Trained batch 312 in epoch 1, gen_loss = 0.7196065580692536, disc_loss = 0.15939837844726948
Trained batch 313 in epoch 1, gen_loss = 0.7191921948057831, disc_loss = 0.1592929562862227
Trained batch 314 in epoch 1, gen_loss = 0.7196660814777253, disc_loss = 0.1589385468276247
Trained batch 315 in epoch 1, gen_loss = 0.7199645714857911, disc_loss = 0.15868677735870965
Trained batch 316 in epoch 1, gen_loss = 0.7197652191205731, disc_loss = 0.15852300439041683
Trained batch 317 in epoch 1, gen_loss = 0.7202527119116213, disc_loss = 0.15887889722303586
Trained batch 318 in epoch 1, gen_loss = 0.7196911888249615, disc_loss = 0.15885698301922005
Trained batch 319 in epoch 1, gen_loss = 0.7198507181368768, disc_loss = 0.1587807970296126
Trained batch 320 in epoch 1, gen_loss = 0.7201396729158835, disc_loss = 0.15868234287982233
Trained batch 321 in epoch 1, gen_loss = 0.7196902289338734, disc_loss = 0.15848453890717362
Trained batch 322 in epoch 1, gen_loss = 0.7194561804226678, disc_loss = 0.15823527090482115
Trained batch 323 in epoch 1, gen_loss = 0.7202331345574355, disc_loss = 0.15802838089358476
Trained batch 324 in epoch 1, gen_loss = 0.7215402803971217, disc_loss = 0.15763402635661455
Trained batch 325 in epoch 1, gen_loss = 0.7212135491012795, disc_loss = 0.15742183064733364
Trained batch 326 in epoch 1, gen_loss = 0.7206836400228903, disc_loss = 0.15767809059983545
Trained batch 327 in epoch 1, gen_loss = 0.7220065431078759, disc_loss = 0.15755212817500094
Trained batch 328 in epoch 1, gen_loss = 0.7220467264710226, disc_loss = 0.1575943073682419
Trained batch 329 in epoch 1, gen_loss = 0.7209847475543166, disc_loss = 0.15809344664554703
Trained batch 330 in epoch 1, gen_loss = 0.7212107921655084, disc_loss = 0.15774144246341418
Trained batch 331 in epoch 1, gen_loss = 0.7218955839613834, disc_loss = 0.15773649693814568
Trained batch 332 in epoch 1, gen_loss = 0.7218311919464363, disc_loss = 0.1580372113600239
Trained batch 333 in epoch 1, gen_loss = 0.7213576195125808, disc_loss = 0.15830693666650328
Trained batch 334 in epoch 1, gen_loss = 0.7217710938026656, disc_loss = 0.15805085762334403
Trained batch 335 in epoch 1, gen_loss = 0.7214683501848153, disc_loss = 0.1580128624336794
Trained batch 336 in epoch 1, gen_loss = 0.7223990028972795, disc_loss = 0.15797304521792896
Trained batch 337 in epoch 1, gen_loss = 0.7218639393882639, disc_loss = 0.15808764834662337
Trained batch 338 in epoch 1, gen_loss = 0.721365463768838, disc_loss = 0.15813449898234685
Trained batch 339 in epoch 1, gen_loss = 0.7215572851545671, disc_loss = 0.15808916454039076
Trained batch 340 in epoch 1, gen_loss = 0.7224174559640745, disc_loss = 0.15812442509069646
Trained batch 341 in epoch 1, gen_loss = 0.7218495508035024, disc_loss = 0.1584444166983516
Trained batch 342 in epoch 1, gen_loss = 0.7218342232287104, disc_loss = 0.1583544869388592
Trained batch 343 in epoch 1, gen_loss = 0.7218174937852594, disc_loss = 0.15818423650574026
Trained batch 344 in epoch 1, gen_loss = 0.7225455842156341, disc_loss = 0.15828417309060477
Trained batch 345 in epoch 1, gen_loss = 0.7227255028451798, disc_loss = 0.15815599433367136
Trained batch 346 in epoch 1, gen_loss = 0.7219095077226073, disc_loss = 0.158612221291541
Trained batch 347 in epoch 1, gen_loss = 0.72248849495389, disc_loss = 0.1582641384200375
Trained batch 348 in epoch 1, gen_loss = 0.7229593809491243, disc_loss = 0.15808831583868638
Trained batch 349 in epoch 1, gen_loss = 0.723194706439972, disc_loss = 0.15785459681813205
Trained batch 350 in epoch 1, gen_loss = 0.7229872928385721, disc_loss = 0.1576756047843783
Trained batch 351 in epoch 1, gen_loss = 0.7234308076175776, disc_loss = 0.15760081536030734
Trained batch 352 in epoch 1, gen_loss = 0.72342780933164, disc_loss = 0.15740175325180755
Trained batch 353 in epoch 1, gen_loss = 0.7228908222273919, disc_loss = 0.15744643855713686
Trained batch 354 in epoch 1, gen_loss = 0.7235411266206015, disc_loss = 0.1572059932886295
Trained batch 355 in epoch 1, gen_loss = 0.7238858491182327, disc_loss = 0.1568758973401835
Trained batch 356 in epoch 1, gen_loss = 0.7236782898422048, disc_loss = 0.1568352710455656
Trained batch 357 in epoch 1, gen_loss = 0.7234484916292755, disc_loss = 0.15706059479742576
Trained batch 358 in epoch 1, gen_loss = 0.7237630322118987, disc_loss = 0.1567039486321732
Trained batch 359 in epoch 1, gen_loss = 0.7239762625760502, disc_loss = 0.15642851739087038
Trained batch 360 in epoch 1, gen_loss = 0.7239072547394814, disc_loss = 0.1565276794548345
Trained batch 361 in epoch 1, gen_loss = 0.7232227812814449, disc_loss = 0.1566383538880895
Trained batch 362 in epoch 1, gen_loss = 0.7236828250661698, disc_loss = 0.15649131830196736
Trained batch 363 in epoch 1, gen_loss = 0.7234589940571523, disc_loss = 0.1563319458349884
Trained batch 364 in epoch 1, gen_loss = 0.7234592632071613, disc_loss = 0.15624007608180177
Trained batch 365 in epoch 1, gen_loss = 0.7245305019323943, disc_loss = 0.15660439652538366
Trained batch 366 in epoch 1, gen_loss = 0.7244164250202335, disc_loss = 0.15644957377938223
Trained batch 367 in epoch 1, gen_loss = 0.7247203191661317, disc_loss = 0.15614664168906925
Trained batch 368 in epoch 1, gen_loss = 0.7254824291076764, disc_loss = 0.15597491219720544
Trained batch 369 in epoch 1, gen_loss = 0.7258714137850582, disc_loss = 0.15564804462766324
Trained batch 370 in epoch 1, gen_loss = 0.725598467167497, disc_loss = 0.15566127430999055
Trained batch 371 in epoch 1, gen_loss = 0.7262737281540389, disc_loss = 0.15538724853346744
Trained batch 372 in epoch 1, gen_loss = 0.7275878675182128, disc_loss = 0.15522190845563968
Trained batch 373 in epoch 1, gen_loss = 0.7271541729967862, disc_loss = 0.15531469057787228
Trained batch 374 in epoch 1, gen_loss = 0.7272676963806153, disc_loss = 0.1550504956841469
Trained batch 375 in epoch 1, gen_loss = 0.7269848899004308, disc_loss = 0.15502434114905747
Trained batch 376 in epoch 1, gen_loss = 0.72696852810503, disc_loss = 0.15502522919396192
Trained batch 377 in epoch 1, gen_loss = 0.7265911490198166, disc_loss = 0.1550234967951106
Trained batch 378 in epoch 1, gen_loss = 0.7265429853763933, disc_loss = 0.15497398056030903
Trained batch 379 in epoch 1, gen_loss = 0.7273842847660968, disc_loss = 0.15528455253102277
Trained batch 380 in epoch 1, gen_loss = 0.7270552372056356, disc_loss = 0.1550654377446087
Trained batch 381 in epoch 1, gen_loss = 0.7268397627076554, disc_loss = 0.15521361830971003
Trained batch 382 in epoch 1, gen_loss = 0.7268765660552381, disc_loss = 0.15505952339415138
Trained batch 383 in epoch 1, gen_loss = 0.7269261023029685, disc_loss = 0.15496285187934214
Trained batch 384 in epoch 1, gen_loss = 0.72642753805433, disc_loss = 0.15488699595262478
Trained batch 385 in epoch 1, gen_loss = 0.7270851956747975, disc_loss = 0.15537328668749395
Trained batch 386 in epoch 1, gen_loss = 0.7265466676509965, disc_loss = 0.15545526687874042
Trained batch 387 in epoch 1, gen_loss = 0.7266301927492791, disc_loss = 0.1554827625027944
Trained batch 388 in epoch 1, gen_loss = 0.7267252145512245, disc_loss = 0.15559452440790775
Trained batch 389 in epoch 1, gen_loss = 0.727370637960923, disc_loss = 0.15564104679685373
Trained batch 390 in epoch 1, gen_loss = 0.7274460559305937, disc_loss = 0.15535314948967352
Trained batch 391 in epoch 1, gen_loss = 0.7274889853231761, disc_loss = 0.1551517976485953
Trained batch 392 in epoch 1, gen_loss = 0.7275697491854505, disc_loss = 0.1550820845229025
Trained batch 393 in epoch 1, gen_loss = 0.727502377353949, disc_loss = 0.15501803900989783
Trained batch 394 in epoch 1, gen_loss = 0.7271757417087313, disc_loss = 0.15514209975924673
Trained batch 395 in epoch 1, gen_loss = 0.7268580737138035, disc_loss = 0.1551335155211314
Trained batch 396 in epoch 1, gen_loss = 0.7264245208024378, disc_loss = 0.15520929254272423
Trained batch 397 in epoch 1, gen_loss = 0.7266342725286532, disc_loss = 0.1555078612949381
Trained batch 398 in epoch 1, gen_loss = 0.7271584577130196, disc_loss = 0.1554741055370871
Trained batch 399 in epoch 1, gen_loss = 0.7260979941487312, disc_loss = 0.15630436915904283
Trained batch 400 in epoch 1, gen_loss = 0.7255963760421164, disc_loss = 0.1563427935440344
Trained batch 401 in epoch 1, gen_loss = 0.7259488262940402, disc_loss = 0.15642426811640536
Trained batch 402 in epoch 1, gen_loss = 0.7256929516496493, disc_loss = 0.15662870395272305
Trained batch 403 in epoch 1, gen_loss = 0.7255839411870088, disc_loss = 0.15658461147605782
Trained batch 404 in epoch 1, gen_loss = 0.7251852098806405, disc_loss = 0.15668002757025354
Trained batch 405 in epoch 1, gen_loss = 0.7253261629877419, disc_loss = 0.15656315882144303
Trained batch 406 in epoch 1, gen_loss = 0.7255839781620579, disc_loss = 0.1567700685205565
Trained batch 407 in epoch 1, gen_loss = 0.7251888902163973, disc_loss = 0.15669186648857944
Trained batch 408 in epoch 1, gen_loss = 0.7249035642899044, disc_loss = 0.1565108290147082
Trained batch 409 in epoch 1, gen_loss = 0.724912960500252, disc_loss = 0.15660316468012042
Trained batch 410 in epoch 1, gen_loss = 0.7246723250461031, disc_loss = 0.15675453562516076
Trained batch 411 in epoch 1, gen_loss = 0.7245814861024468, disc_loss = 0.15658435077198501
Trained batch 412 in epoch 1, gen_loss = 0.7240121094712911, disc_loss = 0.15653494837497683
Trained batch 413 in epoch 1, gen_loss = 0.7239092520757574, disc_loss = 0.15646151276890208
Trained batch 414 in epoch 1, gen_loss = 0.7241857692419764, disc_loss = 0.15629045503685274
Trained batch 415 in epoch 1, gen_loss = 0.7242685573605391, disc_loss = 0.1560219658108858
Trained batch 416 in epoch 1, gen_loss = 0.7239032452055019, disc_loss = 0.15600286284796624
Trained batch 417 in epoch 1, gen_loss = 0.7238967756620435, disc_loss = 0.15580627568173067
Trained batch 418 in epoch 1, gen_loss = 0.7240610575050045, disc_loss = 0.1560200559495457
Trained batch 419 in epoch 1, gen_loss = 0.723940543617521, disc_loss = 0.15607685386424974
Trained batch 420 in epoch 1, gen_loss = 0.7238351766400553, disc_loss = 0.1560328169205976
Trained batch 421 in epoch 1, gen_loss = 0.7238842918409556, disc_loss = 0.1560023947137792
Trained batch 422 in epoch 1, gen_loss = 0.724056147232687, disc_loss = 0.15626012824528607
Trained batch 423 in epoch 1, gen_loss = 0.7243702765905632, disc_loss = 0.15602659507883046
Trained batch 424 in epoch 1, gen_loss = 0.7243509563277749, disc_loss = 0.15596781380036298
Trained batch 425 in epoch 1, gen_loss = 0.7240697367930077, disc_loss = 0.1558597729729375
Trained batch 426 in epoch 1, gen_loss = 0.7248479028775485, disc_loss = 0.15570042315495378
Trained batch 427 in epoch 1, gen_loss = 0.7248279595764998, disc_loss = 0.1554524753782376
Trained batch 428 in epoch 1, gen_loss = 0.724557629832021, disc_loss = 0.1553510151074066
Trained batch 429 in epoch 1, gen_loss = 0.7244162904661755, disc_loss = 0.15528807685992052
Trained batch 430 in epoch 1, gen_loss = 0.7241769597591214, disc_loss = 0.15518479001667274
Trained batch 431 in epoch 1, gen_loss = 0.72417936888006, disc_loss = 0.15513468079303425
Trained batch 432 in epoch 1, gen_loss = 0.7251510388856672, disc_loss = 0.15562321146730737
Trained batch 433 in epoch 1, gen_loss = 0.7245888030886101, disc_loss = 0.15610568651989584
Trained batch 434 in epoch 1, gen_loss = 0.7244821279213346, disc_loss = 0.1560254053394685
Trained batch 435 in epoch 1, gen_loss = 0.7242952185349727, disc_loss = 0.15602489843656983
Trained batch 436 in epoch 1, gen_loss = 0.7244911199985434, disc_loss = 0.15585626822894172
Trained batch 437 in epoch 1, gen_loss = 0.7245381600372324, disc_loss = 0.1556871920126622
Trained batch 438 in epoch 1, gen_loss = 0.725082098826732, disc_loss = 0.1554775496601108
Trained batch 439 in epoch 1, gen_loss = 0.7246706055646593, disc_loss = 0.15556980191137304
Trained batch 440 in epoch 1, gen_loss = 0.7256459893147691, disc_loss = 0.1556206049139943
Trained batch 441 in epoch 1, gen_loss = 0.7253989599543998, disc_loss = 0.1555277317408388
Trained batch 442 in epoch 1, gen_loss = 0.7248929598396034, disc_loss = 0.155756093839154
Trained batch 443 in epoch 1, gen_loss = 0.7248365679705465, disc_loss = 0.15553756406413274
Trained batch 444 in epoch 1, gen_loss = 0.7252396483769578, disc_loss = 0.15579569030846102
Trained batch 445 in epoch 1, gen_loss = 0.7252727465645614, disc_loss = 0.15558132544293532
Trained batch 446 in epoch 1, gen_loss = 0.7249291603863905, disc_loss = 0.15570946706154737
Trained batch 447 in epoch 1, gen_loss = 0.7247889985862587, disc_loss = 0.15555190028888838
Trained batch 448 in epoch 1, gen_loss = 0.7251899031992745, disc_loss = 0.15537234329367533
Trained batch 449 in epoch 1, gen_loss = 0.7251209066311518, disc_loss = 0.15517018796669113
Trained batch 450 in epoch 1, gen_loss = 0.7250206894065747, disc_loss = 0.15506164623866325
Trained batch 451 in epoch 1, gen_loss = 0.7257225688184257, disc_loss = 0.15488934460862547
Trained batch 452 in epoch 1, gen_loss = 0.7257790646410935, disc_loss = 0.1546619184660596
Trained batch 453 in epoch 1, gen_loss = 0.7257919352879083, disc_loss = 0.15439085949556944
Trained batch 454 in epoch 1, gen_loss = 0.725515431034696, disc_loss = 0.15446143797138234
Trained batch 455 in epoch 1, gen_loss = 0.7256149871176795, disc_loss = 0.15431718016860255
Trained batch 456 in epoch 1, gen_loss = 0.7265392233428078, disc_loss = 0.1540566502338687
Trained batch 457 in epoch 1, gen_loss = 0.7266335948716085, disc_loss = 0.15387963492211817
Trained batch 458 in epoch 1, gen_loss = 0.7271153726219352, disc_loss = 0.15385155365163206
Trained batch 459 in epoch 1, gen_loss = 0.7270388910951822, disc_loss = 0.15372869694686453
Trained batch 460 in epoch 1, gen_loss = 0.726536603333376, disc_loss = 0.1537373285587077
Trained batch 461 in epoch 1, gen_loss = 0.727419054030856, disc_loss = 0.1535839502139267
Trained batch 462 in epoch 1, gen_loss = 0.7274633804999984, disc_loss = 0.15340505017382022
Trained batch 463 in epoch 1, gen_loss = 0.7271517470864386, disc_loss = 0.15333094794688554
Trained batch 464 in epoch 1, gen_loss = 0.72704161194063, disc_loss = 0.15331239392680507
Trained batch 465 in epoch 1, gen_loss = 0.7272444659676163, disc_loss = 0.1532713635924548
Trained batch 466 in epoch 1, gen_loss = 0.7272261060152115, disc_loss = 0.15334571345970513
Trained batch 467 in epoch 1, gen_loss = 0.7275125606574564, disc_loss = 0.15309396466542768
Trained batch 468 in epoch 1, gen_loss = 0.7285264644668554, disc_loss = 0.1530022461737778
Trained batch 469 in epoch 1, gen_loss = 0.7285638274664574, disc_loss = 0.15270816730731662
Trained batch 470 in epoch 1, gen_loss = 0.7279150061420068, disc_loss = 0.15260748132754853
Trained batch 471 in epoch 1, gen_loss = 0.7276435997652806, disc_loss = 0.1524761806703883
Trained batch 472 in epoch 1, gen_loss = 0.7288570833130569, disc_loss = 0.1526930742458013
Trained batch 473 in epoch 1, gen_loss = 0.7286695554412367, disc_loss = 0.15265307661326688
Trained batch 474 in epoch 1, gen_loss = 0.7284396521041268, disc_loss = 0.15255412819550226
Trained batch 475 in epoch 1, gen_loss = 0.7283878119177177, disc_loss = 0.15251099499247717
Trained batch 476 in epoch 1, gen_loss = 0.7281177713061279, disc_loss = 0.15232368918873793
Trained batch 477 in epoch 1, gen_loss = 0.7276118027989336, disc_loss = 0.15236682001555876
Trained batch 478 in epoch 1, gen_loss = 0.7285536392621058, disc_loss = 0.15261077472749546
Trained batch 479 in epoch 1, gen_loss = 0.7283994295323889, disc_loss = 0.15254067278195482
Trained batch 480 in epoch 1, gen_loss = 0.7287035163747546, disc_loss = 0.1524483898050479
Trained batch 481 in epoch 1, gen_loss = 0.7283882438765522, disc_loss = 0.1523989984143479
Trained batch 482 in epoch 1, gen_loss = 0.7283004780857213, disc_loss = 0.15241423506274296
Trained batch 483 in epoch 1, gen_loss = 0.7287128842936075, disc_loss = 0.1523322891848054
Trained batch 484 in epoch 1, gen_loss = 0.728776920271903, disc_loss = 0.15234852607755625
Trained batch 485 in epoch 1, gen_loss = 0.7287733342053959, disc_loss = 0.15214748348879778
Trained batch 486 in epoch 1, gen_loss = 0.7292681636873947, disc_loss = 0.15191230900945177
Trained batch 487 in epoch 1, gen_loss = 0.7290660500160007, disc_loss = 0.15195610820979918
Trained batch 488 in epoch 1, gen_loss = 0.7293861527262534, disc_loss = 0.15185088389467424
Trained batch 489 in epoch 1, gen_loss = 0.7298448250610001, disc_loss = 0.15167696481494575
Trained batch 490 in epoch 1, gen_loss = 0.7290931218996067, disc_loss = 0.15189661015234812
Trained batch 491 in epoch 1, gen_loss = 0.729182529497922, disc_loss = 0.15197667051901723
Trained batch 492 in epoch 1, gen_loss = 0.7295221118124213, disc_loss = 0.1517424183570861
Trained batch 493 in epoch 1, gen_loss = 0.7301836987497353, disc_loss = 0.15148383332416415
Trained batch 494 in epoch 1, gen_loss = 0.729762367166654, disc_loss = 0.15137191874097394
Trained batch 495 in epoch 1, gen_loss = 0.7295090706358033, disc_loss = 0.15138816579823353
Trained batch 496 in epoch 1, gen_loss = 0.7301762395461561, disc_loss = 0.15145844492641553
Trained batch 497 in epoch 1, gen_loss = 0.7301511132573507, disc_loss = 0.15134065825843726
Trained batch 498 in epoch 1, gen_loss = 0.7303793881842512, disc_loss = 0.15114977372201804
Trained batch 499 in epoch 1, gen_loss = 0.7299784774780274, disc_loss = 0.1512173955012113
Trained batch 500 in epoch 1, gen_loss = 0.7297061848307322, disc_loss = 0.15146819068055725
Trained batch 501 in epoch 1, gen_loss = 0.7305933386681089, disc_loss = 0.15182264952315574
Trained batch 502 in epoch 1, gen_loss = 0.7307613372328741, disc_loss = 0.1517284009957438
Trained batch 503 in epoch 1, gen_loss = 0.7302832435520868, disc_loss = 0.1519124405477048
Trained batch 504 in epoch 1, gen_loss = 0.7307121600254928, disc_loss = 0.1517927613607285
Trained batch 505 in epoch 1, gen_loss = 0.7305058935885372, disc_loss = 0.15185082971998176
Trained batch 506 in epoch 1, gen_loss = 0.7305673297340348, disc_loss = 0.15180517166037355
Trained batch 507 in epoch 1, gen_loss = 0.7303816141106012, disc_loss = 0.15165552727357434
Trained batch 508 in epoch 1, gen_loss = 0.7300286336357327, disc_loss = 0.15169780921147064
Trained batch 509 in epoch 1, gen_loss = 0.7304776064321107, disc_loss = 0.1515798927686524
Trained batch 510 in epoch 1, gen_loss = 0.7302359765989673, disc_loss = 0.15186553699403652
Trained batch 511 in epoch 1, gen_loss = 0.730137434671633, disc_loss = 0.15183564512881276
Trained batch 512 in epoch 1, gen_loss = 0.7299498657734074, disc_loss = 0.15168923806384582
Trained batch 513 in epoch 1, gen_loss = 0.7300570423964861, disc_loss = 0.15161907703503386
Trained batch 514 in epoch 1, gen_loss = 0.7298739382364218, disc_loss = 0.15151381476881723
Trained batch 515 in epoch 1, gen_loss = 0.7305539901866469, disc_loss = 0.1513969843373309
Trained batch 516 in epoch 1, gen_loss = 0.7300052348257725, disc_loss = 0.15168363121257125
Trained batch 517 in epoch 1, gen_loss = 0.7304348785099376, disc_loss = 0.1516275758869428
Trained batch 518 in epoch 1, gen_loss = 0.7300869672629186, disc_loss = 0.15171522450649497
Trained batch 519 in epoch 1, gen_loss = 0.7303315789080583, disc_loss = 0.1517035904716557
Trained batch 520 in epoch 1, gen_loss = 0.7298431144222874, disc_loss = 0.1518762822704472
Trained batch 521 in epoch 1, gen_loss = 0.7300439539197761, disc_loss = 0.15190441255775278
Trained batch 522 in epoch 1, gen_loss = 0.7302450377558203, disc_loss = 0.15172978916720098
Trained batch 523 in epoch 1, gen_loss = 0.730149985554109, disc_loss = 0.15158664253327056
Trained batch 524 in epoch 1, gen_loss = 0.7298430380934761, disc_loss = 0.1516863753415999
Trained batch 525 in epoch 1, gen_loss = 0.7296406827838702, disc_loss = 0.15165288800359508
Trained batch 526 in epoch 1, gen_loss = 0.7293935702579976, disc_loss = 0.15174614925262656
Trained batch 527 in epoch 1, gen_loss = 0.7294817244577588, disc_loss = 0.15190775554352018
Trained batch 528 in epoch 1, gen_loss = 0.7294848010873524, disc_loss = 0.15177339107143237
Trained batch 529 in epoch 1, gen_loss = 0.7295287027111593, disc_loss = 0.15166301368999313
Trained batch 530 in epoch 1, gen_loss = 0.7295792361549513, disc_loss = 0.15171182993448667
Trained batch 531 in epoch 1, gen_loss = 0.7294702536069361, disc_loss = 0.1516599902074392
Trained batch 532 in epoch 1, gen_loss = 0.7293655729763503, disc_loss = 0.15165250256524804
Trained batch 533 in epoch 1, gen_loss = 0.7295268454243627, disc_loss = 0.1516952379746188
Trained batch 534 in epoch 1, gen_loss = 0.7293319204700327, disc_loss = 0.15158701975107472
Trained batch 535 in epoch 1, gen_loss = 0.7296200501941034, disc_loss = 0.15143416132673676
Trained batch 536 in epoch 1, gen_loss = 0.7296134602535148, disc_loss = 0.1513063985337564
Trained batch 537 in epoch 1, gen_loss = 0.729894432270394, disc_loss = 0.15115545891038382
Trained batch 538 in epoch 1, gen_loss = 0.7297701216916206, disc_loss = 0.15103465076950628
Trained batch 539 in epoch 1, gen_loss = 0.7296189593496146, disc_loss = 0.15093978529071642
Trained batch 540 in epoch 1, gen_loss = 0.7298484448474348, disc_loss = 0.1507187755158698
Trained batch 541 in epoch 1, gen_loss = 0.729712735297935, disc_loss = 0.15076783811673522
Trained batch 542 in epoch 1, gen_loss = 0.7300249720695489, disc_loss = 0.1505655696560692
Trained batch 543 in epoch 1, gen_loss = 0.7312045141725856, disc_loss = 0.15093725544626496
Trained batch 544 in epoch 1, gen_loss = 0.7307247606439328, disc_loss = 0.1510904537718914
Trained batch 545 in epoch 1, gen_loss = 0.7306831751441781, disc_loss = 0.15115070040252454
Trained batch 546 in epoch 1, gen_loss = 0.7308602417517842, disc_loss = 0.15126221078248794
Trained batch 547 in epoch 1, gen_loss = 0.7302278216085295, disc_loss = 0.15137838034034048
Trained batch 548 in epoch 1, gen_loss = 0.730055411982406, disc_loss = 0.15126365230661326
Trained batch 549 in epoch 1, gen_loss = 0.73025836055929, disc_loss = 0.15111402048475364
Trained batch 550 in epoch 1, gen_loss = 0.7306917146416195, disc_loss = 0.15097382356549618
Trained batch 551 in epoch 1, gen_loss = 0.7306526880981266, disc_loss = 0.15089492088325485
Trained batch 552 in epoch 1, gen_loss = 0.7304694068367183, disc_loss = 0.15083206823739015
Trained batch 553 in epoch 1, gen_loss = 0.7308060029783834, disc_loss = 0.1507963118856161
Trained batch 554 in epoch 1, gen_loss = 0.7308404728099033, disc_loss = 0.15062774056149228
Trained batch 555 in epoch 1, gen_loss = 0.7308157801413707, disc_loss = 0.1504945140884747
Trained batch 556 in epoch 1, gen_loss = 0.7308484855203269, disc_loss = 0.15038109576259365
Trained batch 557 in epoch 1, gen_loss = 0.7304248112290563, disc_loss = 0.15044436076535814
Trained batch 558 in epoch 1, gen_loss = 0.7304537779316705, disc_loss = 0.15041945356382508
Trained batch 559 in epoch 1, gen_loss = 0.7306299645985875, disc_loss = 0.15032633491292863
Trained batch 560 in epoch 1, gen_loss = 0.7307541901627539, disc_loss = 0.15025807897362745
Trained batch 561 in epoch 1, gen_loss = 0.7310772913630746, disc_loss = 0.1501420082083615
Trained batch 562 in epoch 1, gen_loss = 0.7309807807895261, disc_loss = 0.14998537653537722
Trained batch 563 in epoch 1, gen_loss = 0.7314769642572876, disc_loss = 0.1500030526088828
Trained batch 564 in epoch 1, gen_loss = 0.7311792871593374, disc_loss = 0.1500230434408362
Trained batch 565 in epoch 1, gen_loss = 0.731686839577166, disc_loss = 0.1498331879825058
Trained batch 566 in epoch 1, gen_loss = 0.7317728413896376, disc_loss = 0.149671546275509
Trained batch 567 in epoch 1, gen_loss = 0.7318575966735961, disc_loss = 0.14950780172563408
Trained batch 568 in epoch 1, gen_loss = 0.7317439920034895, disc_loss = 0.14943714286176152
Trained batch 569 in epoch 1, gen_loss = 0.7323165405214879, disc_loss = 0.1495038177703687
Trained batch 570 in epoch 1, gen_loss = 0.732076092484536, disc_loss = 0.14943740061025956
Trained batch 571 in epoch 1, gen_loss = 0.7320246219218194, disc_loss = 0.14951417743150222
Trained batch 572 in epoch 1, gen_loss = 0.7323510043492076, disc_loss = 0.14943989843006586
Trained batch 573 in epoch 1, gen_loss = 0.7324123039893572, disc_loss = 0.14932206698339628
Trained batch 574 in epoch 1, gen_loss = 0.7322454182997994, disc_loss = 0.14916808321586122
Trained batch 575 in epoch 1, gen_loss = 0.7326313204442462, disc_loss = 0.14913435222277055
Trained batch 576 in epoch 1, gen_loss = 0.7332604258890995, disc_loss = 0.14890438723870178
Trained batch 577 in epoch 1, gen_loss = 0.7335355238518501, disc_loss = 0.14868923229452183
Trained batch 578 in epoch 1, gen_loss = 0.7337574980419534, disc_loss = 0.14845954250248344
Trained batch 579 in epoch 1, gen_loss = 0.7338491233258412, disc_loss = 0.14826202928730897
Trained batch 580 in epoch 1, gen_loss = 0.7336552220039236, disc_loss = 0.14819232741668947
Trained batch 581 in epoch 1, gen_loss = 0.7341265187845197, disc_loss = 0.14820323579006947
Trained batch 582 in epoch 1, gen_loss = 0.734313395685847, disc_loss = 0.1480150641490087
Trained batch 583 in epoch 1, gen_loss = 0.734102216281303, disc_loss = 0.14800631444205925
Trained batch 584 in epoch 1, gen_loss = 0.7340717827153002, disc_loss = 0.14784465063299634
Trained batch 585 in epoch 1, gen_loss = 0.734517870197524, disc_loss = 0.14775801657734014
Trained batch 586 in epoch 1, gen_loss = 0.7345540141734395, disc_loss = 0.1476054475698271
Trained batch 587 in epoch 1, gen_loss = 0.7340900148866939, disc_loss = 0.1477889507093473
Trained batch 588 in epoch 1, gen_loss = 0.7348831502407638, disc_loss = 0.1477590770285153
Trained batch 589 in epoch 1, gen_loss = 0.7353500573311822, disc_loss = 0.1475788245561643
Trained batch 590 in epoch 1, gen_loss = 0.735996297672517, disc_loss = 0.1473706375394653
Trained batch 591 in epoch 1, gen_loss = 0.7360792658417612, disc_loss = 0.14724934085215619
Trained batch 592 in epoch 1, gen_loss = 0.7362927890949668, disc_loss = 0.14721031667127527
Trained batch 593 in epoch 1, gen_loss = 0.7372467229864011, disc_loss = 0.14706543598932398
Trained batch 594 in epoch 1, gen_loss = 0.7373878193502666, disc_loss = 0.1468601493759691
Trained batch 595 in epoch 1, gen_loss = 0.7379956340429766, disc_loss = 0.14671524096399097
Trained batch 596 in epoch 1, gen_loss = 0.7378197450134623, disc_loss = 0.1466794014710253
Trained batch 597 in epoch 1, gen_loss = 0.7376767389949748, disc_loss = 0.14674333079148047
Trained batch 598 in epoch 1, gen_loss = 0.738275227144684, disc_loss = 0.1466335067525506
Trained batch 599 in epoch 1, gen_loss = 0.7383357823888461, disc_loss = 0.146474735114413
Trained batch 600 in epoch 1, gen_loss = 0.7391366503401327, disc_loss = 0.14633209684618848
Trained batch 601 in epoch 1, gen_loss = 0.7397006394657186, disc_loss = 0.14613229089394905
Trained batch 602 in epoch 1, gen_loss = 0.7392344192090516, disc_loss = 0.1463793182411968
Trained batch 603 in epoch 1, gen_loss = 0.7391278721046763, disc_loss = 0.14628601234424735
Trained batch 604 in epoch 1, gen_loss = 0.7391637554838638, disc_loss = 0.14625047422976287
Trained batch 605 in epoch 1, gen_loss = 0.7389904304896251, disc_loss = 0.14617155377811478
Trained batch 606 in epoch 1, gen_loss = 0.739410090191164, disc_loss = 0.14608189551837902
Trained batch 607 in epoch 1, gen_loss = 0.7393852331136402, disc_loss = 0.14599131622296563
Trained batch 608 in epoch 1, gen_loss = 0.7389705434612844, disc_loss = 0.14620617605678504
Trained batch 609 in epoch 1, gen_loss = 0.7397027507180073, disc_loss = 0.14612190238368072
Trained batch 610 in epoch 1, gen_loss = 0.7395319437239252, disc_loss = 0.14599011729756423
Trained batch 611 in epoch 1, gen_loss = 0.7395457674085705, disc_loss = 0.14583462969631297
Trained batch 612 in epoch 1, gen_loss = 0.74006953344454, disc_loss = 0.14575443337679056
Trained batch 613 in epoch 1, gen_loss = 0.7397266472978001, disc_loss = 0.14583908836736498
Trained batch 614 in epoch 1, gen_loss = 0.7399838602639796, disc_loss = 0.14565777272682606
Trained batch 615 in epoch 1, gen_loss = 0.7399345116762371, disc_loss = 0.1457684720101367
Trained batch 616 in epoch 1, gen_loss = 0.7397896355709341, disc_loss = 0.14579466043713366
Trained batch 617 in epoch 1, gen_loss = 0.7396587980217918, disc_loss = 0.14577639395142017
Trained batch 618 in epoch 1, gen_loss = 0.7404902468590436, disc_loss = 0.14582772447497422
Trained batch 619 in epoch 1, gen_loss = 0.740574154738457, disc_loss = 0.14565325564885093
Trained batch 620 in epoch 1, gen_loss = 0.7399526501431365, disc_loss = 0.14585631090439796
Trained batch 621 in epoch 1, gen_loss = 0.7400973713282987, disc_loss = 0.14572085360951506
Trained batch 622 in epoch 1, gen_loss = 0.740031772210931, disc_loss = 0.14566789100912322
Trained batch 623 in epoch 1, gen_loss = 0.7398550107310979, disc_loss = 0.14567354889676118
Trained batch 624 in epoch 1, gen_loss = 0.7397796779632568, disc_loss = 0.14564423825591802
Trained batch 625 in epoch 1, gen_loss = 0.7399747291692911, disc_loss = 0.14557775389551877
Trained batch 626 in epoch 1, gen_loss = 0.7399695963380439, disc_loss = 0.14544192082330323
Trained batch 627 in epoch 1, gen_loss = 0.739579924637345, disc_loss = 0.14546145289798212
Trained batch 628 in epoch 1, gen_loss = 0.7400936044645992, disc_loss = 0.14542656147701516
Trained batch 629 in epoch 1, gen_loss = 0.7400592665823679, disc_loss = 0.14529804649895856
Trained batch 630 in epoch 1, gen_loss = 0.7400337710811294, disc_loss = 0.14515128910464786
Trained batch 631 in epoch 1, gen_loss = 0.7404456668639485, disc_loss = 0.1450198421687996
Trained batch 632 in epoch 1, gen_loss = 0.740483818649304, disc_loss = 0.1448863298039277
Trained batch 633 in epoch 1, gen_loss = 0.7407895043633338, disc_loss = 0.14481029134061577
Trained batch 634 in epoch 1, gen_loss = 0.7405699345070547, disc_loss = 0.144715635958091
Trained batch 635 in epoch 1, gen_loss = 0.7403955322766455, disc_loss = 0.14475466666959882
Trained batch 636 in epoch 1, gen_loss = 0.740903497865099, disc_loss = 0.144721480222416
Trained batch 637 in epoch 1, gen_loss = 0.7410506104413992, disc_loss = 0.14462226856832733
Trained batch 638 in epoch 1, gen_loss = 0.740931081473361, disc_loss = 0.1446227709600973
Trained batch 639 in epoch 1, gen_loss = 0.740714391041547, disc_loss = 0.1446589239742025
Trained batch 640 in epoch 1, gen_loss = 0.7407965490858938, disc_loss = 0.14455439739493006
Trained batch 641 in epoch 1, gen_loss = 0.7413669015016883, disc_loss = 0.14443792512849252
Trained batch 642 in epoch 1, gen_loss = 0.7409617263551448, disc_loss = 0.14441098429083035
Trained batch 643 in epoch 1, gen_loss = 0.7410604361884342, disc_loss = 0.14430214229664587
Trained batch 644 in epoch 1, gen_loss = 0.7413717195507168, disc_loss = 0.14416628802094117
Trained batch 645 in epoch 1, gen_loss = 0.7416582739113285, disc_loss = 0.14397298472129016
Trained batch 646 in epoch 1, gen_loss = 0.7414335766476126, disc_loss = 0.14399171169340563
Trained batch 647 in epoch 1, gen_loss = 0.7412906096397359, disc_loss = 0.1439702608924428
Trained batch 648 in epoch 1, gen_loss = 0.7416487812353025, disc_loss = 0.14385622212999086
Trained batch 649 in epoch 1, gen_loss = 0.741631404023904, disc_loss = 0.1438770192073515
Trained batch 650 in epoch 1, gen_loss = 0.7413855475672562, disc_loss = 0.14399971039436427
Trained batch 651 in epoch 1, gen_loss = 0.7417051689299338, disc_loss = 0.14393178746247082
Trained batch 652 in epoch 1, gen_loss = 0.7414703852458533, disc_loss = 0.1439445002124307
Trained batch 653 in epoch 1, gen_loss = 0.7411722945966487, disc_loss = 0.1439322536478007
Trained batch 654 in epoch 1, gen_loss = 0.7415661191667309, disc_loss = 0.1438997476852236
Trained batch 655 in epoch 1, gen_loss = 0.7414658269958525, disc_loss = 0.14381561431857734
Trained batch 656 in epoch 1, gen_loss = 0.7412107093784182, disc_loss = 0.143704423679484
Trained batch 657 in epoch 1, gen_loss = 0.7415956408691261, disc_loss = 0.14358756561143646
Trained batch 658 in epoch 1, gen_loss = 0.741214733384267, disc_loss = 0.1436014424045662
Trained batch 659 in epoch 1, gen_loss = 0.7408595390392072, disc_loss = 0.143813466790104
Trained batch 660 in epoch 1, gen_loss = 0.7414496682595557, disc_loss = 0.14413100741550033
Trained batch 661 in epoch 1, gen_loss = 0.7415807338999838, disc_loss = 0.14408713460019212
Trained batch 662 in epoch 1, gen_loss = 0.7413098158519912, disc_loss = 0.14439126563877946
Trained batch 663 in epoch 1, gen_loss = 0.7414751969367624, disc_loss = 0.14426796832991517
Trained batch 664 in epoch 1, gen_loss = 0.7417888937139869, disc_loss = 0.14445821081701302
Trained batch 665 in epoch 1, gen_loss = 0.7414954832724264, disc_loss = 0.1446058196966556
Trained batch 666 in epoch 1, gen_loss = 0.7414133620226401, disc_loss = 0.14451957326605805
Trained batch 667 in epoch 1, gen_loss = 0.741486246892792, disc_loss = 0.14447449169032453
Trained batch 668 in epoch 1, gen_loss = 0.7419955771421994, disc_loss = 0.1443742845661281
Trained batch 669 in epoch 1, gen_loss = 0.7418631929070202, disc_loss = 0.1443293272906831
Trained batch 670 in epoch 1, gen_loss = 0.7419459055859356, disc_loss = 0.14427341605313176
Trained batch 671 in epoch 1, gen_loss = 0.7420410446467853, disc_loss = 0.14410476815482115
Trained batch 672 in epoch 1, gen_loss = 0.7421314050325845, disc_loss = 0.1439950590687534
Trained batch 673 in epoch 1, gen_loss = 0.7421552337241809, disc_loss = 0.1438342693416562
Trained batch 674 in epoch 1, gen_loss = 0.7421252987119886, disc_loss = 0.14370685161125882
Trained batch 675 in epoch 1, gen_loss = 0.7419019182758219, disc_loss = 0.14363996117904826
Trained batch 676 in epoch 1, gen_loss = 0.7420045413858253, disc_loss = 0.14363908800578495
Trained batch 677 in epoch 1, gen_loss = 0.7421064127159681, disc_loss = 0.14349089675393384
Trained batch 678 in epoch 1, gen_loss = 0.7418519151403907, disc_loss = 0.14351416777940096
Trained batch 679 in epoch 1, gen_loss = 0.7415324206737911, disc_loss = 0.1434465996633448
Trained batch 680 in epoch 1, gen_loss = 0.7420720064167409, disc_loss = 0.143495271487022
Trained batch 681 in epoch 1, gen_loss = 0.7417676063401958, disc_loss = 0.14363021800523934
Trained batch 682 in epoch 1, gen_loss = 0.7414445843040333, disc_loss = 0.1436609263582316
Trained batch 683 in epoch 1, gen_loss = 0.7418510789236827, disc_loss = 0.14366508407480144
Trained batch 684 in epoch 1, gen_loss = 0.7419255203574243, disc_loss = 0.14355416040541263
Trained batch 685 in epoch 1, gen_loss = 0.7417691615858162, disc_loss = 0.14362471317600883
Trained batch 686 in epoch 1, gen_loss = 0.7420119316123285, disc_loss = 0.14360405718758593
Trained batch 687 in epoch 1, gen_loss = 0.741948509372251, disc_loss = 0.14352688352918513
Trained batch 688 in epoch 1, gen_loss = 0.7418597511006371, disc_loss = 0.14342303958374072
Trained batch 689 in epoch 1, gen_loss = 0.7418695016183715, disc_loss = 0.1432579077631775
Trained batch 690 in epoch 1, gen_loss = 0.7417388853391932, disc_loss = 0.14311729901633327
Trained batch 691 in epoch 1, gen_loss = 0.74205809736872, disc_loss = 0.14314746300722175
Trained batch 692 in epoch 1, gen_loss = 0.7416720636737295, disc_loss = 0.1432018650260258
Trained batch 693 in epoch 1, gen_loss = 0.7413864331132053, disc_loss = 0.1432988539040196
Trained batch 694 in epoch 1, gen_loss = 0.7419411137378473, disc_loss = 0.14363884271504423
Trained batch 695 in epoch 1, gen_loss = 0.7418168204697384, disc_loss = 0.143621612828621
Trained batch 696 in epoch 1, gen_loss = 0.7416259379178243, disc_loss = 0.1437985605200809
Trained batch 697 in epoch 1, gen_loss = 0.7413583854293413, disc_loss = 0.14392509757218225
Trained batch 698 in epoch 1, gen_loss = 0.741095652182897, disc_loss = 0.14392521192528873
Trained batch 699 in epoch 1, gen_loss = 0.7409612360596657, disc_loss = 0.1439560281764716
Trained batch 700 in epoch 1, gen_loss = 0.7407739712151243, disc_loss = 0.14402894768863916
Trained batch 701 in epoch 1, gen_loss = 0.7403679389899273, disc_loss = 0.1440221223611374
Trained batch 702 in epoch 1, gen_loss = 0.7402688494617197, disc_loss = 0.14396963732325038
Trained batch 703 in epoch 1, gen_loss = 0.7405980626459826, disc_loss = 0.143859595416209
Trained batch 704 in epoch 1, gen_loss = 0.7403557674259159, disc_loss = 0.14388423403130568
Trained batch 705 in epoch 1, gen_loss = 0.7406223199354015, disc_loss = 0.1437943279387023
Trained batch 706 in epoch 1, gen_loss = 0.7403289756646757, disc_loss = 0.14372564367080554
Trained batch 707 in epoch 1, gen_loss = 0.7402492279218416, disc_loss = 0.1438082752257354
Trained batch 708 in epoch 1, gen_loss = 0.7402462867654765, disc_loss = 0.1437671775817976
Trained batch 709 in epoch 1, gen_loss = 0.7406051823790645, disc_loss = 0.14373673418484315
Trained batch 710 in epoch 1, gen_loss = 0.7406888853983873, disc_loss = 0.14358273899489188
Trained batch 711 in epoch 1, gen_loss = 0.7406214980429477, disc_loss = 0.1434752106355252
Trained batch 712 in epoch 1, gen_loss = 0.7407955266483034, disc_loss = 0.1434894610068344
Trained batch 713 in epoch 1, gen_loss = 0.7408966265973591, disc_loss = 0.14334770278086892
Trained batch 714 in epoch 1, gen_loss = 0.7411361261681243, disc_loss = 0.14318721513882593
Trained batch 715 in epoch 1, gen_loss = 0.7412087980595381, disc_loss = 0.14312465520778556
Trained batch 716 in epoch 1, gen_loss = 0.7412758901029451, disc_loss = 0.1429859014186421
Trained batch 717 in epoch 1, gen_loss = 0.7409746680087034, disc_loss = 0.14314988464205253
Trained batch 718 in epoch 1, gen_loss = 0.7417095393895772, disc_loss = 0.14321041873090165
Trained batch 719 in epoch 1, gen_loss = 0.7414469336469968, disc_loss = 0.14332229096778773
Trained batch 720 in epoch 1, gen_loss = 0.7417075066890532, disc_loss = 0.14344491642330168
Trained batch 721 in epoch 1, gen_loss = 0.7418281670422435, disc_loss = 0.1434550122615889
Trained batch 722 in epoch 1, gen_loss = 0.7418134039368373, disc_loss = 0.14344684737521954
Trained batch 723 in epoch 1, gen_loss = 0.7414576117752006, disc_loss = 0.14387131088351554
Trained batch 724 in epoch 1, gen_loss = 0.741334915613306, disc_loss = 0.14380525886113274
Trained batch 725 in epoch 1, gen_loss = 0.7414487337195841, disc_loss = 0.14397281832279787
Trained batch 726 in epoch 1, gen_loss = 0.7415212863003208, disc_loss = 0.14396937461147158
Trained batch 727 in epoch 1, gen_loss = 0.7415627796653208, disc_loss = 0.14389902507952815
Trained batch 728 in epoch 1, gen_loss = 0.7415295345874807, disc_loss = 0.14384441281220428
Trained batch 729 in epoch 1, gen_loss = 0.7418713784789386, disc_loss = 0.14388189255706454
Trained batch 730 in epoch 1, gen_loss = 0.741784823128365, disc_loss = 0.1439466889139912
Trained batch 731 in epoch 1, gen_loss = 0.7415567785094345, disc_loss = 0.14387203154632505
Trained batch 732 in epoch 1, gen_loss = 0.7415273999045685, disc_loss = 0.1438572014431694
Trained batch 733 in epoch 1, gen_loss = 0.7416252540551349, disc_loss = 0.1439734019493882
Trained batch 734 in epoch 1, gen_loss = 0.7416768425581407, disc_loss = 0.14387249668971414
Trained batch 735 in epoch 1, gen_loss = 0.7417805223604259, disc_loss = 0.14391086422762348
Trained batch 736 in epoch 1, gen_loss = 0.7416314678810021, disc_loss = 0.1439909061361382
Trained batch 737 in epoch 1, gen_loss = 0.7415597798620782, disc_loss = 0.14393369049000426
Trained batch 738 in epoch 1, gen_loss = 0.7413818304287081, disc_loss = 0.14392177366521788
Trained batch 739 in epoch 1, gen_loss = 0.7409920817291414, disc_loss = 0.14399902026320027
Trained batch 740 in epoch 1, gen_loss = 0.7412243270680972, disc_loss = 0.14402410362981632
Trained batch 741 in epoch 1, gen_loss = 0.7411941902014123, disc_loss = 0.1439876083166632
Trained batch 742 in epoch 1, gen_loss = 0.741047313364165, disc_loss = 0.14406945502377977
Trained batch 743 in epoch 1, gen_loss = 0.7410661848962948, disc_loss = 0.14402572026661528
Trained batch 744 in epoch 1, gen_loss = 0.7411793591992167, disc_loss = 0.1439635932558035
Trained batch 745 in epoch 1, gen_loss = 0.7409705043478242, disc_loss = 0.14400930510054843
Trained batch 746 in epoch 1, gen_loss = 0.7411137077224302, disc_loss = 0.14394116071657523
Trained batch 747 in epoch 1, gen_loss = 0.7409358305089614, disc_loss = 0.14384520875743248
Trained batch 748 in epoch 1, gen_loss = 0.7406684690228451, disc_loss = 0.14376156558425668
Trained batch 749 in epoch 1, gen_loss = 0.7408824679851532, disc_loss = 0.1436410688025256
Trained batch 750 in epoch 1, gen_loss = 0.7408657893836101, disc_loss = 0.1435408954795068
Trained batch 751 in epoch 1, gen_loss = 0.740893959444254, disc_loss = 0.14340149227435642
Trained batch 752 in epoch 1, gen_loss = 0.7409045032137735, disc_loss = 0.1432682240906247
Trained batch 753 in epoch 1, gen_loss = 0.7410974504144502, disc_loss = 0.14315924939356092
Trained batch 754 in epoch 1, gen_loss = 0.741027198011512, disc_loss = 0.14308952449987464
Trained batch 755 in epoch 1, gen_loss = 0.7408131868750961, disc_loss = 0.14314777251929242
Trained batch 756 in epoch 1, gen_loss = 0.7413582162466515, disc_loss = 0.14325560211687494
Trained batch 757 in epoch 1, gen_loss = 0.7412249403452811, disc_loss = 0.14329742561254188
Trained batch 758 in epoch 1, gen_loss = 0.741557134234387, disc_loss = 0.1433872923669706
Trained batch 759 in epoch 1, gen_loss = 0.7416722699999809, disc_loss = 0.14323311266611868
Trained batch 760 in epoch 1, gen_loss = 0.7416596726738357, disc_loss = 0.14308390021201775
Trained batch 761 in epoch 1, gen_loss = 0.7415687577148747, disc_loss = 0.14301127029015753
Trained batch 762 in epoch 1, gen_loss = 0.741759955570551, disc_loss = 0.1430283966089744
Trained batch 763 in epoch 1, gen_loss = 0.7417766789647298, disc_loss = 0.14291923769008544
Trained batch 764 in epoch 1, gen_loss = 0.7417795930812562, disc_loss = 0.14281308229136117
Trained batch 765 in epoch 1, gen_loss = 0.7417186951512768, disc_loss = 0.14274798614622214
Trained batch 766 in epoch 1, gen_loss = 0.7418147328624203, disc_loss = 0.14278598190825603
Trained batch 767 in epoch 1, gen_loss = 0.7420221599750221, disc_loss = 0.14268949979911363
Trained batch 768 in epoch 1, gen_loss = 0.7418211422599028, disc_loss = 0.14267344973249887
Trained batch 769 in epoch 1, gen_loss = 0.741834672627511, disc_loss = 0.14254668512103427
Trained batch 770 in epoch 1, gen_loss = 0.7423198298102996, disc_loss = 0.1425134085357943
Trained batch 771 in epoch 1, gen_loss = 0.7424099847597162, disc_loss = 0.14235623917117754
Trained batch 772 in epoch 1, gen_loss = 0.7424385287012196, disc_loss = 0.14223889283050348
Trained batch 773 in epoch 1, gen_loss = 0.742324340636108, disc_loss = 0.142361601630529
Trained batch 774 in epoch 1, gen_loss = 0.7428621262119662, disc_loss = 0.14259699176756604
Trained batch 775 in epoch 1, gen_loss = 0.7427709392972828, disc_loss = 0.1426908059043272
Trained batch 776 in epoch 1, gen_loss = 0.7425745891328024, disc_loss = 0.14271941237712574
Trained batch 777 in epoch 1, gen_loss = 0.7423216958738538, disc_loss = 0.14282186572011416
Trained batch 778 in epoch 1, gen_loss = 0.7421952730118846, disc_loss = 0.14285440155124443
Trained batch 779 in epoch 1, gen_loss = 0.7421635255599633, disc_loss = 0.14280007040629594
Trained batch 780 in epoch 1, gen_loss = 0.7419858811454186, disc_loss = 0.14293096347493758
Trained batch 781 in epoch 1, gen_loss = 0.7421896485873806, disc_loss = 0.14292573006918935
Trained batch 782 in epoch 1, gen_loss = 0.7422618671852054, disc_loss = 0.1428986295408273
Trained batch 783 in epoch 1, gen_loss = 0.7420065843177085, disc_loss = 0.14290134203311397
Trained batch 784 in epoch 1, gen_loss = 0.7423183106313086, disc_loss = 0.14294308827727273
Trained batch 785 in epoch 1, gen_loss = 0.742503154368801, disc_loss = 0.14281434804537635
Trained batch 786 in epoch 1, gen_loss = 0.7422981801451085, disc_loss = 0.1428170480967761
Trained batch 787 in epoch 1, gen_loss = 0.7428245017976325, disc_loss = 0.14273675171738764
Trained batch 788 in epoch 1, gen_loss = 0.7429044520144831, disc_loss = 0.1426213067320042
Trained batch 789 in epoch 1, gen_loss = 0.7426567101025883, disc_loss = 0.14264582882081217
Trained batch 790 in epoch 1, gen_loss = 0.7430875017278263, disc_loss = 0.14260201529963543
Trained batch 791 in epoch 1, gen_loss = 0.7430439095454987, disc_loss = 0.14260102715225645
Trained batch 792 in epoch 1, gen_loss = 0.7429665036189451, disc_loss = 0.1425108612793372
Trained batch 793 in epoch 1, gen_loss = 0.7429091124900943, disc_loss = 0.14240919811163164
Trained batch 794 in epoch 1, gen_loss = 0.7427330269753558, disc_loss = 0.14237021434958438
Trained batch 795 in epoch 1, gen_loss = 0.7433542475179212, disc_loss = 0.14247210019024734
Trained batch 796 in epoch 1, gen_loss = 0.743324528972956, disc_loss = 0.14238986812667498
Trained batch 797 in epoch 1, gen_loss = 0.7433586792838305, disc_loss = 0.14226360626420692
Trained batch 798 in epoch 1, gen_loss = 0.7434739197449332, disc_loss = 0.1421330599137611
Trained batch 799 in epoch 1, gen_loss = 0.7435438584536314, disc_loss = 0.14199338053236715
Trained batch 800 in epoch 1, gen_loss = 0.743416375063183, disc_loss = 0.1418787816739391
Trained batch 801 in epoch 1, gen_loss = 0.7432952405805897, disc_loss = 0.14183859768534948
Trained batch 802 in epoch 1, gen_loss = 0.7437407973397565, disc_loss = 0.1418771544276536
Trained batch 803 in epoch 1, gen_loss = 0.7437128992519568, disc_loss = 0.14188693417352044
Trained batch 804 in epoch 1, gen_loss = 0.744053698474576, disc_loss = 0.14182383825204203
Trained batch 805 in epoch 1, gen_loss = 0.7437801276040137, disc_loss = 0.14185940956687623
Trained batch 806 in epoch 1, gen_loss = 0.7437139519823823, disc_loss = 0.14182663724504993
Trained batch 807 in epoch 1, gen_loss = 0.7443845759671514, disc_loss = 0.1425443505580159
Trained batch 808 in epoch 1, gen_loss = 0.7440830522178867, disc_loss = 0.1426544083899396
Trained batch 809 in epoch 1, gen_loss = 0.7437955808492355, disc_loss = 0.14276359537386415
Trained batch 810 in epoch 1, gen_loss = 0.7438264602356569, disc_loss = 0.1427798193997707
Trained batch 811 in epoch 1, gen_loss = 0.7437657057651745, disc_loss = 0.14287125082397512
Trained batch 812 in epoch 1, gen_loss = 0.7435615954950433, disc_loss = 0.14304562814666594
Trained batch 813 in epoch 1, gen_loss = 0.7432405289619503, disc_loss = 0.1430447829065785
Trained batch 814 in epoch 1, gen_loss = 0.7428818981705999, disc_loss = 0.14305711587765282
Trained batch 815 in epoch 1, gen_loss = 0.7430804118002746, disc_loss = 0.14295275579549044
Trained batch 816 in epoch 1, gen_loss = 0.7428172003464133, disc_loss = 0.142958449989767
Trained batch 817 in epoch 1, gen_loss = 0.7429424538516182, disc_loss = 0.14296090405111025
Trained batch 818 in epoch 1, gen_loss = 0.7430499681113549, disc_loss = 0.14284568392217922
Trained batch 819 in epoch 1, gen_loss = 0.7428909708450481, disc_loss = 0.1427569689944659
Trained batch 820 in epoch 1, gen_loss = 0.7428361515397712, disc_loss = 0.14269856295812688
Trained batch 821 in epoch 1, gen_loss = 0.7429139986452975, disc_loss = 0.14269630359304467
Trained batch 822 in epoch 1, gen_loss = 0.7426620926413762, disc_loss = 0.14279104613858576
Trained batch 823 in epoch 1, gen_loss = 0.7429394812766209, disc_loss = 0.14270791060910606
Trained batch 824 in epoch 1, gen_loss = 0.7426909845164328, disc_loss = 0.14270251523703337
Trained batch 825 in epoch 1, gen_loss = 0.7425627995273392, disc_loss = 0.14262562430380296
Trained batch 826 in epoch 1, gen_loss = 0.7424912048726734, disc_loss = 0.14266416174049928
Trained batch 827 in epoch 1, gen_loss = 0.7422635577223151, disc_loss = 0.14270304542390297
Trained batch 828 in epoch 1, gen_loss = 0.7422824444112214, disc_loss = 0.14266361997533586
Trained batch 829 in epoch 1, gen_loss = 0.7423327052090541, disc_loss = 0.14267184797517327
Trained batch 830 in epoch 1, gen_loss = 0.7422848875700495, disc_loss = 0.14273311918944337
Trained batch 831 in epoch 1, gen_loss = 0.7424022407414248, disc_loss = 0.1426513589988015
Trained batch 832 in epoch 1, gen_loss = 0.7423375655694597, disc_loss = 0.14255009469825503
Trained batch 833 in epoch 1, gen_loss = 0.7422747472278791, disc_loss = 0.14257585716364587
Trained batch 834 in epoch 1, gen_loss = 0.7424259477389786, disc_loss = 0.1424592436687229
Trained batch 835 in epoch 1, gen_loss = 0.7425562400353012, disc_loss = 0.14242019494393904
Trained batch 836 in epoch 1, gen_loss = 0.7424620804749652, disc_loss = 0.14234466064641232
Trained batch 837 in epoch 1, gen_loss = 0.74261083114261, disc_loss = 0.14219378686547812
Trained batch 838 in epoch 1, gen_loss = 0.7429274886455809, disc_loss = 0.14231793200031048
Trained batch 839 in epoch 1, gen_loss = 0.7426845279123102, disc_loss = 0.14231755062383378
Trained batch 840 in epoch 1, gen_loss = 0.7426504027474933, disc_loss = 0.1422451795084351
Trained batch 841 in epoch 1, gen_loss = 0.7430974140657098, disc_loss = 0.14225168284935757
Trained batch 842 in epoch 1, gen_loss = 0.7431034551467194, disc_loss = 0.14213863104771854
Trained batch 843 in epoch 1, gen_loss = 0.7430474258500253, disc_loss = 0.14204328140283612
Trained batch 844 in epoch 1, gen_loss = 0.7432850059320235, disc_loss = 0.1421537339367722
Trained batch 845 in epoch 1, gen_loss = 0.7429567692057178, disc_loss = 0.14211485217309977
Trained batch 846 in epoch 1, gen_loss = 0.7427124751571218, disc_loss = 0.14217449502454282
Trained batch 847 in epoch 1, gen_loss = 0.7434373328919118, disc_loss = 0.14239852525236718
Trained batch 848 in epoch 1, gen_loss = 0.7434810893906301, disc_loss = 0.14231048126291435
Trained batch 849 in epoch 1, gen_loss = 0.7432792462671505, disc_loss = 0.14249036431641263
Trained batch 850 in epoch 1, gen_loss = 0.7431040946591194, disc_loss = 0.14256158804129174
Trained batch 851 in epoch 1, gen_loss = 0.7432729932413974, disc_loss = 0.14246613153982296
Trained batch 852 in epoch 1, gen_loss = 0.7434498278854321, disc_loss = 0.1423438618479325
Trained batch 853 in epoch 1, gen_loss = 0.743280824125511, disc_loss = 0.14233173790608097
Trained batch 854 in epoch 1, gen_loss = 0.7433908260705179, disc_loss = 0.1424426089547444
Trained batch 855 in epoch 1, gen_loss = 0.7433844661670868, disc_loss = 0.14241684932657736
Trained batch 856 in epoch 1, gen_loss = 0.7434900722606597, disc_loss = 0.14233625684011741
Trained batch 857 in epoch 1, gen_loss = 0.7435013327078942, disc_loss = 0.1422271796758341
Trained batch 858 in epoch 1, gen_loss = 0.7435395876173369, disc_loss = 0.14215144734369967
Trained batch 859 in epoch 1, gen_loss = 0.7436060390153597, disc_loss = 0.1420367833649263
Trained batch 860 in epoch 1, gen_loss = 0.7436734864728376, disc_loss = 0.1419087448054611
Trained batch 861 in epoch 1, gen_loss = 0.7438884044537135, disc_loss = 0.14184515344912485
Trained batch 862 in epoch 1, gen_loss = 0.7439301887296166, disc_loss = 0.14172761428773162
Trained batch 863 in epoch 1, gen_loss = 0.7437648693513539, disc_loss = 0.14178857460717187
Trained batch 864 in epoch 1, gen_loss = 0.7440586515589257, disc_loss = 0.14175117376631913
Trained batch 865 in epoch 1, gen_loss = 0.7444968465500561, disc_loss = 0.14170273149807616
Trained batch 866 in epoch 1, gen_loss = 0.7446095547117851, disc_loss = 0.1416221961299561
Trained batch 867 in epoch 1, gen_loss = 0.744515385186892, disc_loss = 0.14154070365019486
Trained batch 868 in epoch 1, gen_loss = 0.7446051339079788, disc_loss = 0.14146809792521187
Trained batch 869 in epoch 1, gen_loss = 0.7452789391251816, disc_loss = 0.14149695668990414
Trained batch 870 in epoch 1, gen_loss = 0.7453244125596691, disc_loss = 0.14143759107920764
Trained batch 871 in epoch 1, gen_loss = 0.7454511868092445, disc_loss = 0.14141626880662259
Trained batch 872 in epoch 1, gen_loss = 0.7452382466842219, disc_loss = 0.14137938324967986
Trained batch 873 in epoch 1, gen_loss = 0.7452060373274085, disc_loss = 0.14135678345124392
Trained batch 874 in epoch 1, gen_loss = 0.7451115502970559, disc_loss = 0.14136087193552938
Trained batch 875 in epoch 1, gen_loss = 0.7452684913391936, disc_loss = 0.14132296676602912
Trained batch 876 in epoch 1, gen_loss = 0.7455814366261798, disc_loss = 0.14138711084895253
Trained batch 877 in epoch 1, gen_loss = 0.7453545913405734, disc_loss = 0.1415041161516516
Trained batch 878 in epoch 1, gen_loss = 0.7454106713792434, disc_loss = 0.14146292503643462
Trained batch 879 in epoch 1, gen_loss = 0.7452137755738063, disc_loss = 0.14155120946869085
Trained batch 880 in epoch 1, gen_loss = 0.7452568147631699, disc_loss = 0.14164297826372502
Trained batch 881 in epoch 1, gen_loss = 0.7449076129398108, disc_loss = 0.14167815562477018
Trained batch 882 in epoch 1, gen_loss = 0.7447360556568456, disc_loss = 0.14167100178354156
Trained batch 883 in epoch 1, gen_loss = 0.7448071477032895, disc_loss = 0.14184744339920918
Trained batch 884 in epoch 1, gen_loss = 0.74451391377018, disc_loss = 0.1418916930491894
Trained batch 885 in epoch 1, gen_loss = 0.7442883386636157, disc_loss = 0.14194054616421764
Trained batch 886 in epoch 1, gen_loss = 0.7440417169382231, disc_loss = 0.14199033091338237
Trained batch 887 in epoch 1, gen_loss = 0.7439802161812246, disc_loss = 0.14205985607659058
Trained batch 888 in epoch 1, gen_loss = 0.7440263463689184, disc_loss = 0.14222147096057408
Trained batch 889 in epoch 1, gen_loss = 0.74400998015752, disc_loss = 0.14217165245496657
Trained batch 890 in epoch 1, gen_loss = 0.7438143487396732, disc_loss = 0.14220391985605962
Trained batch 891 in epoch 1, gen_loss = 0.743877940214001, disc_loss = 0.14222400111664138
Trained batch 892 in epoch 1, gen_loss = 0.7440634361506844, disc_loss = 0.14219200391581016
Trained batch 893 in epoch 1, gen_loss = 0.7439812598145782, disc_loss = 0.14215389757377556
Trained batch 894 in epoch 1, gen_loss = 0.7438872979006954, disc_loss = 0.14215213847788852
Trained batch 895 in epoch 1, gen_loss = 0.7440107809047082, disc_loss = 0.1420395488790486
Trained batch 896 in epoch 1, gen_loss = 0.7441666498697189, disc_loss = 0.14191274418741665
Trained batch 897 in epoch 1, gen_loss = 0.7440355743026414, disc_loss = 0.1418838668645739
Trained batch 898 in epoch 1, gen_loss = 0.7439603630838723, disc_loss = 0.14187916910153575
Trained batch 899 in epoch 1, gen_loss = 0.7442072405086624, disc_loss = 0.14192295469240182
Trained batch 900 in epoch 1, gen_loss = 0.7440180821172669, disc_loss = 0.14186056464244834
Trained batch 901 in epoch 1, gen_loss = 0.7440536063486615, disc_loss = 0.14179830727148843
Trained batch 902 in epoch 1, gen_loss = 0.7442501670828425, disc_loss = 0.14175982590030428
Trained batch 903 in epoch 1, gen_loss = 0.7440660930510643, disc_loss = 0.1416732921230038
Trained batch 904 in epoch 1, gen_loss = 0.7441303275896041, disc_loss = 0.14158787631753894
Trained batch 905 in epoch 1, gen_loss = 0.7438375577495061, disc_loss = 0.1415221990624784
Trained batch 906 in epoch 1, gen_loss = 0.7440655180217149, disc_loss = 0.141522335456407
Trained batch 907 in epoch 1, gen_loss = 0.7439215652611813, disc_loss = 0.1414499816593472
Trained batch 908 in epoch 1, gen_loss = 0.7438960967808798, disc_loss = 0.14136505662079396
Trained batch 909 in epoch 1, gen_loss = 0.7438337503553747, disc_loss = 0.14127800495640097
Trained batch 910 in epoch 1, gen_loss = 0.7440898039600067, disc_loss = 0.14131000489057843
Trained batch 911 in epoch 1, gen_loss = 0.7441883305447143, disc_loss = 0.14122988267193073
Trained batch 912 in epoch 1, gen_loss = 0.7441732229956661, disc_loss = 0.14115081133314808
Trained batch 913 in epoch 1, gen_loss = 0.7440572919026506, disc_loss = 0.1411030984980908
Trained batch 914 in epoch 1, gen_loss = 0.7441904714850128, disc_loss = 0.14104417686152165
Trained batch 915 in epoch 1, gen_loss = 0.7443449998917018, disc_loss = 0.14094953888754755
Trained batch 916 in epoch 1, gen_loss = 0.7445339041811819, disc_loss = 0.1408922092383778
Trained batch 917 in epoch 1, gen_loss = 0.744380426367903, disc_loss = 0.14085572257471599
Trained batch 918 in epoch 1, gen_loss = 0.7442556685150902, disc_loss = 0.14081857825190608
Trained batch 919 in epoch 1, gen_loss = 0.7449566819745561, disc_loss = 0.14125286665360404
Trained batch 920 in epoch 1, gen_loss = 0.7450942516844643, disc_loss = 0.1411377013843996
Trained batch 921 in epoch 1, gen_loss = 0.7450464572151416, disc_loss = 0.1410720385398934
Trained batch 922 in epoch 1, gen_loss = 0.7450463885475729, disc_loss = 0.14104600553728744
Trained batch 923 in epoch 1, gen_loss = 0.7454694488863924, disc_loss = 0.1409756868333834
Trained batch 924 in epoch 1, gen_loss = 0.745622172097902, disc_loss = 0.14091821470272703
Trained batch 925 in epoch 1, gen_loss = 0.7459386264016252, disc_loss = 0.14081048483801423
Trained batch 926 in epoch 1, gen_loss = 0.7464174697057072, disc_loss = 0.14069238746641233
Trained batch 927 in epoch 1, gen_loss = 0.7467527398518448, disc_loss = 0.1405861924657325
Trained batch 928 in epoch 1, gen_loss = 0.7470021418529383, disc_loss = 0.14046303379831612
Trained batch 929 in epoch 1, gen_loss = 0.7468386969258708, disc_loss = 0.1403715240989401
Trained batch 930 in epoch 1, gen_loss = 0.7472079361035667, disc_loss = 0.14033593828504792
Trained batch 931 in epoch 1, gen_loss = 0.7472180774027698, disc_loss = 0.14022141443705385
Trained batch 932 in epoch 1, gen_loss = 0.747310672478405, disc_loss = 0.14016421941495305
Trained batch 933 in epoch 1, gen_loss = 0.7472735305159199, disc_loss = 0.1401101217936222
Trained batch 934 in epoch 1, gen_loss = 0.7470879744718419, disc_loss = 0.14006460950196906
Trained batch 935 in epoch 1, gen_loss = 0.7472245891888937, disc_loss = 0.14001174125139818
Trained batch 936 in epoch 1, gen_loss = 0.7477661385225767, disc_loss = 0.14003551813098924
Trained batch 937 in epoch 1, gen_loss = 0.7474866289256225, disc_loss = 0.1402613562770061
Trained batch 938 in epoch 1, gen_loss = 0.747479651333552, disc_loss = 0.14016343468028547
Trained batch 939 in epoch 1, gen_loss = 0.7479147046487382, disc_loss = 0.14020969687485474
Trained batch 940 in epoch 1, gen_loss = 0.7477277197125868, disc_loss = 0.14017391591713893
Trained batch 941 in epoch 1, gen_loss = 0.7475682939630152, disc_loss = 0.14019008841852
Trained batch 942 in epoch 1, gen_loss = 0.7476479464535496, disc_loss = 0.14015826051669592
Trained batch 943 in epoch 1, gen_loss = 0.7476778057861632, disc_loss = 0.1402369906180696
Trained batch 944 in epoch 1, gen_loss = 0.7475405505409947, disc_loss = 0.140166469325346
Trained batch 945 in epoch 1, gen_loss = 0.7472339359133743, disc_loss = 0.1402063286630929
Trained batch 946 in epoch 1, gen_loss = 0.7472866573139884, disc_loss = 0.1401573544399618
Trained batch 947 in epoch 1, gen_loss = 0.747176724741479, disc_loss = 0.14010898090352772
Trained batch 948 in epoch 1, gen_loss = 0.7473071785633884, disc_loss = 0.14000009889130502
Trained batch 949 in epoch 1, gen_loss = 0.7473920897747341, disc_loss = 0.1399240894468599
Trained batch 950 in epoch 1, gen_loss = 0.7473248955641886, disc_loss = 0.1400090391854398
Trained batch 951 in epoch 1, gen_loss = 0.7470565525298359, disc_loss = 0.14021245920111058
Trained batch 952 in epoch 1, gen_loss = 0.7472537879178306, disc_loss = 0.14025767756663146
Trained batch 953 in epoch 1, gen_loss = 0.7471460817494983, disc_loss = 0.1402620049418034
Trained batch 954 in epoch 1, gen_loss = 0.7470939809739278, disc_loss = 0.14017638265013851
Trained batch 955 in epoch 1, gen_loss = 0.7473947681393085, disc_loss = 0.1401755073347429
Trained batch 956 in epoch 1, gen_loss = 0.7473133157164077, disc_loss = 0.14020658539493286
Trained batch 957 in epoch 1, gen_loss = 0.7473328746933031, disc_loss = 0.14026266436475585
Trained batch 958 in epoch 1, gen_loss = 0.7470063760146359, disc_loss = 0.14041052630211967
Trained batch 959 in epoch 1, gen_loss = 0.7472202900486687, disc_loss = 0.1403883046208648
Trained batch 960 in epoch 1, gen_loss = 0.7470460936318575, disc_loss = 0.140443083372754
Trained batch 961 in epoch 1, gen_loss = 0.7471675700246668, disc_loss = 0.14041212629120248
Trained batch 962 in epoch 1, gen_loss = 0.7470450438133529, disc_loss = 0.14032385130108238
Trained batch 963 in epoch 1, gen_loss = 0.7469753904646858, disc_loss = 0.14020897491054446
Trained batch 964 in epoch 1, gen_loss = 0.746488133644193, disc_loss = 0.140299227691878
Trained batch 965 in epoch 1, gen_loss = 0.7466068096597742, disc_loss = 0.14028161238612874
Trained batch 966 in epoch 1, gen_loss = 0.7466018297001642, disc_loss = 0.1402587537329178
Trained batch 967 in epoch 1, gen_loss = 0.7467476096589211, disc_loss = 0.14012588970921164
Trained batch 968 in epoch 1, gen_loss = 0.7464117285083322, disc_loss = 0.14030007306886194
Trained batch 969 in epoch 1, gen_loss = 0.7465686467197753, disc_loss = 0.14024337001010467
Trained batch 970 in epoch 1, gen_loss = 0.746905610778673, disc_loss = 0.14023759466309166
Trained batch 971 in epoch 1, gen_loss = 0.7466266319584944, disc_loss = 0.1402576426168666
Trained batch 972 in epoch 1, gen_loss = 0.7468474447910979, disc_loss = 0.14013882985344311
Trained batch 973 in epoch 1, gen_loss = 0.7469157623069732, disc_loss = 0.14004148902501568
Trained batch 974 in epoch 1, gen_loss = 0.7470338801237253, disc_loss = 0.13993147553637242
Trained batch 975 in epoch 1, gen_loss = 0.7469696033684934, disc_loss = 0.13994289136235985
Trained batch 976 in epoch 1, gen_loss = 0.7472444434736988, disc_loss = 0.14022213920756427
Trained batch 977 in epoch 1, gen_loss = 0.7472421517157604, disc_loss = 0.14018808925478646
Trained batch 978 in epoch 1, gen_loss = 0.7468638715997292, disc_loss = 0.1402762189927959
Trained batch 979 in epoch 1, gen_loss = 0.7465161335407471, disc_loss = 0.14042862162697223
Trained batch 980 in epoch 1, gen_loss = 0.7469632129482051, disc_loss = 0.14064300690742473
Trained batch 981 in epoch 1, gen_loss = 0.7471129303976377, disc_loss = 0.14060002541199873
Trained batch 982 in epoch 1, gen_loss = 0.7469227186357744, disc_loss = 0.14083472182377338
Trained batch 983 in epoch 1, gen_loss = 0.74701788570217, disc_loss = 0.14076514899583034
Trained batch 984 in epoch 1, gen_loss = 0.7472115183542223, disc_loss = 0.14072161899397367
Trained batch 985 in epoch 1, gen_loss = 0.7472811319221105, disc_loss = 0.1406606136628523
Trained batch 986 in epoch 1, gen_loss = 0.7471398271869382, disc_loss = 0.1406544165010163
Trained batch 987 in epoch 1, gen_loss = 0.7470591877575828, disc_loss = 0.14061857648438922
Trained batch 988 in epoch 1, gen_loss = 0.7471589103446571, disc_loss = 0.14063392807159825
Trained batch 989 in epoch 1, gen_loss = 0.7469721194770601, disc_loss = 0.14060388214302935
Trained batch 990 in epoch 1, gen_loss = 0.747025962524289, disc_loss = 0.14056567850830004
Trained batch 991 in epoch 1, gen_loss = 0.7470038954108473, disc_loss = 0.14052456589659765
Trained batch 992 in epoch 1, gen_loss = 0.7469861849257113, disc_loss = 0.14049882532640437
Trained batch 993 in epoch 1, gen_loss = 0.7471547488055719, disc_loss = 0.14046488557726713
Trained batch 994 in epoch 1, gen_loss = 0.7473187201885721, disc_loss = 0.14035456243191083
Trained batch 995 in epoch 1, gen_loss = 0.7473001397817011, disc_loss = 0.14028593517529467
Trained batch 996 in epoch 1, gen_loss = 0.7472017132111992, disc_loss = 0.1402359041268587
Trained batch 997 in epoch 1, gen_loss = 0.7470717259602461, disc_loss = 0.1401502579340491
Trained batch 998 in epoch 1, gen_loss = 0.7471421021777946, disc_loss = 0.14015509599952158
Trained batch 999 in epoch 1, gen_loss = 0.7473072822391987, disc_loss = 0.1400721993641928
Trained batch 1000 in epoch 1, gen_loss = 0.7472493101011861, disc_loss = 0.14000341208087844
Trained batch 1001 in epoch 1, gen_loss = 0.746911788801709, disc_loss = 0.1401401332397378
Trained batch 1002 in epoch 1, gen_loss = 0.7472221833818099, disc_loss = 0.14004024321441785
Trained batch 1003 in epoch 1, gen_loss = 0.747190325532064, disc_loss = 0.14008368290979342
Trained batch 1004 in epoch 1, gen_loss = 0.7472133855024974, disc_loss = 0.1400474053311778
Trained batch 1005 in epoch 1, gen_loss = 0.7469654274330462, disc_loss = 0.14031596341546232
Trained batch 1006 in epoch 1, gen_loss = 0.7472223049656755, disc_loss = 0.14028438489676973
Trained batch 1007 in epoch 1, gen_loss = 0.747196230653023, disc_loss = 0.1402362711877296
Trained batch 1008 in epoch 1, gen_loss = 0.7471584777824942, disc_loss = 0.1401972236938782
Trained batch 1009 in epoch 1, gen_loss = 0.7472847896342231, disc_loss = 0.1401741368908177
Trained batch 1010 in epoch 1, gen_loss = 0.747143232474577, disc_loss = 0.1401870167546129
Trained batch 1011 in epoch 1, gen_loss = 0.7470168346767369, disc_loss = 0.1401923418665312
Trained batch 1012 in epoch 1, gen_loss = 0.7473267133532484, disc_loss = 0.14028916305421987
Trained batch 1013 in epoch 1, gen_loss = 0.7472946081582376, disc_loss = 0.14028084396864093
Trained batch 1014 in epoch 1, gen_loss = 0.747267765746328, disc_loss = 0.14021874522065442
Trained batch 1015 in epoch 1, gen_loss = 0.7471575132446495, disc_loss = 0.14020924592540987
Trained batch 1016 in epoch 1, gen_loss = 0.7471484335884818, disc_loss = 0.14011648216448733
Trained batch 1017 in epoch 1, gen_loss = 0.7471886294471257, disc_loss = 0.14009638224071538
Trained batch 1018 in epoch 1, gen_loss = 0.747177488582759, disc_loss = 0.14001865525317758
Trained batch 1019 in epoch 1, gen_loss = 0.7470256340562128, disc_loss = 0.13998319387308084
Trained batch 1020 in epoch 1, gen_loss = 0.7468809483392231, disc_loss = 0.13994390300468676
Trained batch 1021 in epoch 1, gen_loss = 0.7470753846978021, disc_loss = 0.13997603824303836
Trained batch 1022 in epoch 1, gen_loss = 0.7471320831006573, disc_loss = 0.13990730241410806
Trained batch 1023 in epoch 1, gen_loss = 0.7473520758503582, disc_loss = 0.1398506948216891
Trained batch 1024 in epoch 1, gen_loss = 0.7470918268692203, disc_loss = 0.13992629557575395
Trained batch 1025 in epoch 1, gen_loss = 0.7471356556894254, disc_loss = 0.13989791397974766
Trained batch 1026 in epoch 1, gen_loss = 0.7469783331890534, disc_loss = 0.13991718458967553
Trained batch 1027 in epoch 1, gen_loss = 0.7468953733314336, disc_loss = 0.13990783126542802
Trained batch 1028 in epoch 1, gen_loss = 0.7470614809915785, disc_loss = 0.1399264265878164
Trained batch 1029 in epoch 1, gen_loss = 0.7469814924939164, disc_loss = 0.13986859912305927
Trained batch 1030 in epoch 1, gen_loss = 0.7468588808343667, disc_loss = 0.13987553159134494
Trained batch 1031 in epoch 1, gen_loss = 0.7469735641119092, disc_loss = 0.13993340858182501
Trained batch 1032 in epoch 1, gen_loss = 0.7472468501485213, disc_loss = 0.13983620483687892
Trained batch 1033 in epoch 1, gen_loss = 0.7472191809224437, disc_loss = 0.1397750993705998
Trained batch 1034 in epoch 1, gen_loss = 0.7469468364393078, disc_loss = 0.13974844918896753
Trained batch 1035 in epoch 1, gen_loss = 0.7472022577372297, disc_loss = 0.13973284188143795
Trained batch 1036 in epoch 1, gen_loss = 0.7469479770704084, disc_loss = 0.13985225320196457
Trained batch 1037 in epoch 1, gen_loss = 0.7468090125993038, disc_loss = 0.13987737466708572
Trained batch 1038 in epoch 1, gen_loss = 0.7465800190052239, disc_loss = 0.1398525641087346
Trained batch 1039 in epoch 1, gen_loss = 0.7464476573639192, disc_loss = 0.13982486745360523
Trained batch 1040 in epoch 1, gen_loss = 0.7462973446655915, disc_loss = 0.1397948985200064
Trained batch 1041 in epoch 1, gen_loss = 0.7462476250248998, disc_loss = 0.13983063189305667
Trained batch 1042 in epoch 1, gen_loss = 0.7465929732169538, disc_loss = 0.13991406733975573
Trained batch 1043 in epoch 1, gen_loss = 0.7464864893149142, disc_loss = 0.13988445478427255
Trained batch 1044 in epoch 1, gen_loss = 0.7464630966266377, disc_loss = 0.1398300469964386
Trained batch 1045 in epoch 1, gen_loss = 0.7465000224102067, disc_loss = 0.1398472463183219
Trained batch 1046 in epoch 1, gen_loss = 0.7463898111949564, disc_loss = 0.13988810963128134
Trained batch 1047 in epoch 1, gen_loss = 0.7465481131074537, disc_loss = 0.13983410130208715
Trained batch 1048 in epoch 1, gen_loss = 0.7463695399242998, disc_loss = 0.13981813328470272
Trained batch 1049 in epoch 1, gen_loss = 0.7463061239322026, disc_loss = 0.13986129942128345
Trained batch 1050 in epoch 1, gen_loss = 0.7464676729335205, disc_loss = 0.13976059834978816
Trained batch 1051 in epoch 1, gen_loss = 0.7465412022666332, disc_loss = 0.13969928443435395
Trained batch 1052 in epoch 1, gen_loss = 0.7469031776514714, disc_loss = 0.13959908040093588
Trained batch 1053 in epoch 1, gen_loss = 0.7468586678579591, disc_loss = 0.13954629762225432
Trained batch 1054 in epoch 1, gen_loss = 0.7468539718485556, disc_loss = 0.13947704174948672
Trained batch 1055 in epoch 1, gen_loss = 0.7468284279616042, disc_loss = 0.13948382024219344
Trained batch 1056 in epoch 1, gen_loss = 0.7470264296939944, disc_loss = 0.1394582096189472
Trained batch 1057 in epoch 1, gen_loss = 0.7471731562301207, disc_loss = 0.13934137217880055
Trained batch 1058 in epoch 1, gen_loss = 0.7469341501917223, disc_loss = 0.13941729515421578
Trained batch 1059 in epoch 1, gen_loss = 0.7470589134771869, disc_loss = 0.13936869736040397
Trained batch 1060 in epoch 1, gen_loss = 0.747359934980076, disc_loss = 0.13928999889002977
Trained batch 1061 in epoch 1, gen_loss = 0.7474393581659331, disc_loss = 0.1392190872863454
Trained batch 1062 in epoch 1, gen_loss = 0.7473484008298769, disc_loss = 0.1392702135797993
Trained batch 1063 in epoch 1, gen_loss = 0.7474096323594563, disc_loss = 0.13924576732403549
Trained batch 1064 in epoch 1, gen_loss = 0.7473955445166485, disc_loss = 0.13938994201538568
Trained batch 1065 in epoch 1, gen_loss = 0.7472729314726692, disc_loss = 0.13934082814927368
Trained batch 1066 in epoch 1, gen_loss = 0.7471526721815361, disc_loss = 0.13930251100471536
Trained batch 1067 in epoch 1, gen_loss = 0.7475594813736637, disc_loss = 0.13938577457379955
Trained batch 1068 in epoch 1, gen_loss = 0.7473950564192209, disc_loss = 0.1393878299026803
Trained batch 1069 in epoch 1, gen_loss = 0.7473193914812302, disc_loss = 0.139332841979949
Trained batch 1070 in epoch 1, gen_loss = 0.7472962173037614, disc_loss = 0.13945574671930933
Trained batch 1071 in epoch 1, gen_loss = 0.7471514154892804, disc_loss = 0.13943968466118173
Trained batch 1072 in epoch 1, gen_loss = 0.7473111265692217, disc_loss = 0.13939878257305707
Trained batch 1073 in epoch 1, gen_loss = 0.7471930393238085, disc_loss = 0.1393800823380425
Trained batch 1074 in epoch 1, gen_loss = 0.7469743528754212, disc_loss = 0.13942518981650126
Trained batch 1075 in epoch 1, gen_loss = 0.7470527530325833, disc_loss = 0.13940744465788252
Trained batch 1076 in epoch 1, gen_loss = 0.7470899167001082, disc_loss = 0.13935760555558854
Trained batch 1077 in epoch 1, gen_loss = 0.7468757613083428, disc_loss = 0.13947184583870262
Trained batch 1078 in epoch 1, gen_loss = 0.7470361664131684, disc_loss = 0.13944727123263564
Trained batch 1079 in epoch 1, gen_loss = 0.7472288412352402, disc_loss = 0.13943825273308902
Trained batch 1080 in epoch 1, gen_loss = 0.74713720079377, disc_loss = 0.13944566068149047
Trained batch 1081 in epoch 1, gen_loss = 0.7473018805938816, disc_loss = 0.13938741518404893
Trained batch 1082 in epoch 1, gen_loss = 0.7472038658977326, disc_loss = 0.13937825142274354
Trained batch 1083 in epoch 1, gen_loss = 0.7473777622479354, disc_loss = 0.139295611897401
Trained batch 1084 in epoch 1, gen_loss = 0.747590196709479, disc_loss = 0.13922987099187578
Trained batch 1085 in epoch 1, gen_loss = 0.7475597329616107, disc_loss = 0.13916887586737398
Trained batch 1086 in epoch 1, gen_loss = 0.7478611725069781, disc_loss = 0.13917321858716838
Trained batch 1087 in epoch 1, gen_loss = 0.7477508739239591, disc_loss = 0.1391906418438713
Trained batch 1088 in epoch 1, gen_loss = 0.7479095889462365, disc_loss = 0.13922640983241075
Trained batch 1089 in epoch 1, gen_loss = 0.7477414034648773, disc_loss = 0.1393104527068726
Trained batch 1090 in epoch 1, gen_loss = 0.7478715779309312, disc_loss = 0.13928661099613723
Trained batch 1091 in epoch 1, gen_loss = 0.7477989326957818, disc_loss = 0.13927047594191144
Trained batch 1092 in epoch 1, gen_loss = 0.7474878863904417, disc_loss = 0.1393145342252651
Trained batch 1093 in epoch 1, gen_loss = 0.747512589425012, disc_loss = 0.1392568034610253
Trained batch 1094 in epoch 1, gen_loss = 0.7475394891821631, disc_loss = 0.1393115874116211
Trained batch 1095 in epoch 1, gen_loss = 0.7474130054895025, disc_loss = 0.1392362021397541
Trained batch 1096 in epoch 1, gen_loss = 0.7472881759527932, disc_loss = 0.1392958183800878
Trained batch 1097 in epoch 1, gen_loss = 0.7472962123123023, disc_loss = 0.1392523270594007
Trained batch 1098 in epoch 1, gen_loss = 0.7472931133605221, disc_loss = 0.13919393447320147
Trained batch 1099 in epoch 1, gen_loss = 0.7471640136025168, disc_loss = 0.13919835010966794
Trained batch 1100 in epoch 1, gen_loss = 0.747003137469833, disc_loss = 0.13919452593647463
Trained batch 1101 in epoch 1, gen_loss = 0.7471642448227116, disc_loss = 0.1391012613127471
Trained batch 1102 in epoch 1, gen_loss = 0.7471883561755999, disc_loss = 0.138996459205119
Trained batch 1103 in epoch 1, gen_loss = 0.7470699223163335, disc_loss = 0.13906810585783957
Trained batch 1104 in epoch 1, gen_loss = 0.747034314908593, disc_loss = 0.13901458031232405
Trained batch 1105 in epoch 1, gen_loss = 0.7471315865059658, disc_loss = 0.13904809661354417
Trained batch 1106 in epoch 1, gen_loss = 0.7473434031063517, disc_loss = 0.13902173121228423
Trained batch 1107 in epoch 1, gen_loss = 0.7471393728191672, disc_loss = 0.1392197067965333
Trained batch 1108 in epoch 1, gen_loss = 0.7469145212762521, disc_loss = 0.13921923387788968
Trained batch 1109 in epoch 1, gen_loss = 0.747077328020388, disc_loss = 0.1392567891451354
Trained batch 1110 in epoch 1, gen_loss = 0.7472146267187049, disc_loss = 0.13919392463430078
Trained batch 1111 in epoch 1, gen_loss = 0.7471192438932631, disc_loss = 0.13917350473482054
Trained batch 1112 in epoch 1, gen_loss = 0.7470839267792406, disc_loss = 0.13910775286834168
Trained batch 1113 in epoch 1, gen_loss = 0.7472168523918576, disc_loss = 0.13907948916082402
Trained batch 1114 in epoch 1, gen_loss = 0.7470853028276041, disc_loss = 0.13905167852198463
Trained batch 1115 in epoch 1, gen_loss = 0.7471096791780978, disc_loss = 0.13895839624904682
Trained batch 1116 in epoch 1, gen_loss = 0.7469040282944429, disc_loss = 0.13890162794604805
Trained batch 1117 in epoch 1, gen_loss = 0.7469051976643223, disc_loss = 0.138983596495331
Trained batch 1118 in epoch 1, gen_loss = 0.7467269208199004, disc_loss = 0.13906973095609074
Trained batch 1119 in epoch 1, gen_loss = 0.7470475744988238, disc_loss = 0.13906835328172226
Trained batch 1120 in epoch 1, gen_loss = 0.7469588040667491, disc_loss = 0.13900060619308174
Trained batch 1121 in epoch 1, gen_loss = 0.7473657670930532, disc_loss = 0.13908897826295352
Trained batch 1122 in epoch 1, gen_loss = 0.747055955370515, disc_loss = 0.1392801855404663
Trained batch 1123 in epoch 1, gen_loss = 0.7467959600093101, disc_loss = 0.13932805327993564
Trained batch 1124 in epoch 1, gen_loss = 0.7466728232171801, disc_loss = 0.13930721788191133
Trained batch 1125 in epoch 1, gen_loss = 0.7467357295021071, disc_loss = 0.13930667024254667
Trained batch 1126 in epoch 1, gen_loss = 0.7467596228395613, disc_loss = 0.13932138921307877
Trained batch 1127 in epoch 1, gen_loss = 0.7467280256938427, disc_loss = 0.13932440631299656
Trained batch 1128 in epoch 1, gen_loss = 0.7465951535636287, disc_loss = 0.1393220537689418
Trained batch 1129 in epoch 1, gen_loss = 0.7466573130767957, disc_loss = 0.1393174237439788
Trained batch 1130 in epoch 1, gen_loss = 0.7464957738955604, disc_loss = 0.13927529642159148
Trained batch 1131 in epoch 1, gen_loss = 0.7464452041016871, disc_loss = 0.1392802672235249
Trained batch 1132 in epoch 1, gen_loss = 0.7464208488746333, disc_loss = 0.13935860723753551
Trained batch 1133 in epoch 1, gen_loss = 0.7462999313491573, disc_loss = 0.13944200449253594
Trained batch 1134 in epoch 1, gen_loss = 0.7462943407932567, disc_loss = 0.13946033346544673
Trained batch 1135 in epoch 1, gen_loss = 0.7461160196279976, disc_loss = 0.13952857770704546
Trained batch 1136 in epoch 1, gen_loss = 0.7461857678812642, disc_loss = 0.13953993664669462
Trained batch 1137 in epoch 1, gen_loss = 0.7463626109967123, disc_loss = 0.13950248986322217
Trained batch 1138 in epoch 1, gen_loss = 0.7462325034903475, disc_loss = 0.1394900202782231
Trained batch 1139 in epoch 1, gen_loss = 0.7461640251833096, disc_loss = 0.1395065049256868
Trained batch 1140 in epoch 1, gen_loss = 0.7461251484313417, disc_loss = 0.13950395408371344
Trained batch 1141 in epoch 1, gen_loss = 0.746087285923248, disc_loss = 0.13950320067627914
Trained batch 1142 in epoch 1, gen_loss = 0.7459432165662343, disc_loss = 0.13954500153201224
Trained batch 1143 in epoch 1, gen_loss = 0.7458276354245372, disc_loss = 0.13958796756456027
Trained batch 1144 in epoch 1, gen_loss = 0.7458443858738029, disc_loss = 0.13957081027084953
Trained batch 1145 in epoch 1, gen_loss = 0.7460982998732288, disc_loss = 0.13958988010958098
Trained batch 1146 in epoch 1, gen_loss = 0.7457810136527733, disc_loss = 0.13961791312654925
Trained batch 1147 in epoch 1, gen_loss = 0.7456753825840219, disc_loss = 0.1396590162203274
Trained batch 1148 in epoch 1, gen_loss = 0.7457434565373563, disc_loss = 0.1397373792362781
Trained batch 1149 in epoch 1, gen_loss = 0.7458046414800312, disc_loss = 0.13983028923606744
Trained batch 1150 in epoch 1, gen_loss = 0.7455682206371367, disc_loss = 0.13987297021567846
Trained batch 1151 in epoch 1, gen_loss = 0.7455591004497061, disc_loss = 0.139823047656844
Trained batch 1152 in epoch 1, gen_loss = 0.7456688221547259, disc_loss = 0.13987001246091782
Trained batch 1153 in epoch 1, gen_loss = 0.7454399415638873, disc_loss = 0.13981867961801808
Trained batch 1154 in epoch 1, gen_loss = 0.7451990082150414, disc_loss = 0.13983313899842045
Trained batch 1155 in epoch 1, gen_loss = 0.7450235212756688, disc_loss = 0.1398701293895079
Trained batch 1156 in epoch 1, gen_loss = 0.7448563782841148, disc_loss = 0.13996877536650942
Trained batch 1157 in epoch 1, gen_loss = 0.7446850038460088, disc_loss = 0.13998444812591082
Trained batch 1158 in epoch 1, gen_loss = 0.7447974207177052, disc_loss = 0.14010753406644047
Trained batch 1159 in epoch 1, gen_loss = 0.7446354320337032, disc_loss = 0.14010773552180236
Trained batch 1160 in epoch 1, gen_loss = 0.7444901199406534, disc_loss = 0.14010574455508557
Trained batch 1161 in epoch 1, gen_loss = 0.7443690020943673, disc_loss = 0.14004735614569047
Trained batch 1162 in epoch 1, gen_loss = 0.7443804052095422, disc_loss = 0.14005569020015535
Trained batch 1163 in epoch 1, gen_loss = 0.7444779835513368, disc_loss = 0.140087115772779
Trained batch 1164 in epoch 1, gen_loss = 0.7446178877814134, disc_loss = 0.14001171715445657
Trained batch 1165 in epoch 1, gen_loss = 0.7443197395390548, disc_loss = 0.140126234632126
Trained batch 1166 in epoch 1, gen_loss = 0.7443737214767943, disc_loss = 0.14006065694661532
Trained batch 1167 in epoch 1, gen_loss = 0.7443779415310654, disc_loss = 0.14006652525380534
Trained batch 1168 in epoch 1, gen_loss = 0.7444645532233987, disc_loss = 0.1400436663958726
Trained batch 1169 in epoch 1, gen_loss = 0.7446503319037266, disc_loss = 0.14007250095327567
Trained batch 1170 in epoch 1, gen_loss = 0.744566617334734, disc_loss = 0.1399769334577463
Trained batch 1171 in epoch 1, gen_loss = 0.7444149545384349, disc_loss = 0.1402266694307518
Trained batch 1172 in epoch 1, gen_loss = 0.7446253482388921, disc_loss = 0.14023266146983712
Trained batch 1173 in epoch 1, gen_loss = 0.7446057167177103, disc_loss = 0.14017814624296213
Trained batch 1174 in epoch 1, gen_loss = 0.7446932105054247, disc_loss = 0.14017054890619313
Trained batch 1175 in epoch 1, gen_loss = 0.7448668900851895, disc_loss = 0.14011106718581828
Trained batch 1176 in epoch 1, gen_loss = 0.7448299740620762, disc_loss = 0.14005686595842887
Trained batch 1177 in epoch 1, gen_loss = 0.7449700176361663, disc_loss = 0.1400376854105481
Trained batch 1178 in epoch 1, gen_loss = 0.7451769856450111, disc_loss = 0.13995814317974806
Trained batch 1179 in epoch 1, gen_loss = 0.7449334876011994, disc_loss = 0.13998888255791517
Trained batch 1180 in epoch 1, gen_loss = 0.7449935402635999, disc_loss = 0.13990703874538124
Trained batch 1181 in epoch 1, gen_loss = 0.7449357135949402, disc_loss = 0.13996721295696604
Trained batch 1182 in epoch 1, gen_loss = 0.7447201632788296, disc_loss = 0.14007852809930366
Trained batch 1183 in epoch 1, gen_loss = 0.74467355279705, disc_loss = 0.1401737476659725
Trained batch 1184 in epoch 1, gen_loss = 0.7448293338345073, disc_loss = 0.14026565247054215
Trained batch 1185 in epoch 1, gen_loss = 0.7447848069225556, disc_loss = 0.14019483796118257
Trained batch 1186 in epoch 1, gen_loss = 0.7447042472239995, disc_loss = 0.14022872162858854
Trained batch 1187 in epoch 1, gen_loss = 0.7448131014602353, disc_loss = 0.1402492411897176
Trained batch 1188 in epoch 1, gen_loss = 0.7448276227216344, disc_loss = 0.14021762383630212
Trained batch 1189 in epoch 1, gen_loss = 0.7446620609579968, disc_loss = 0.14019231890414316
Trained batch 1190 in epoch 1, gen_loss = 0.7445207239198244, disc_loss = 0.14016298487654236
Trained batch 1191 in epoch 1, gen_loss = 0.7445478792858604, disc_loss = 0.1401295870278443
Trained batch 1192 in epoch 1, gen_loss = 0.7446391319189367, disc_loss = 0.14005030881713418
Trained batch 1193 in epoch 1, gen_loss = 0.7447075741474752, disc_loss = 0.13994483838569205
Trained batch 1194 in epoch 1, gen_loss = 0.7449966677561963, disc_loss = 0.13987952220530314
Trained batch 1195 in epoch 1, gen_loss = 0.7450484387751009, disc_loss = 0.13979017277977066
Trained batch 1196 in epoch 1, gen_loss = 0.7449356586911227, disc_loss = 0.13975817190503442
Trained batch 1197 in epoch 1, gen_loss = 0.7448731250874387, disc_loss = 0.13975784085607015
Trained batch 1198 in epoch 1, gen_loss = 0.7451252589333147, disc_loss = 0.13982501143886333
Trained batch 1199 in epoch 1, gen_loss = 0.7449903117616972, disc_loss = 0.13975860198416437
Trained batch 1200 in epoch 1, gen_loss = 0.7447557356534255, disc_loss = 0.1400079136841514
Trained batch 1201 in epoch 1, gen_loss = 0.7448638020061613, disc_loss = 0.14001642328806332
Trained batch 1202 in epoch 1, gen_loss = 0.7450728905963977, disc_loss = 0.14004848294303823
Trained batch 1203 in epoch 1, gen_loss = 0.7450214929358904, disc_loss = 0.14000748185227405
Trained batch 1204 in epoch 1, gen_loss = 0.7449140968164468, disc_loss = 0.13994144441876794
Trained batch 1205 in epoch 1, gen_loss = 0.7449562995390315, disc_loss = 0.13985049307645975
Trained batch 1206 in epoch 1, gen_loss = 0.7451904576577326, disc_loss = 0.13986200764049972
Trained batch 1207 in epoch 1, gen_loss = 0.744957976684665, disc_loss = 0.1399100092339903
Trained batch 1208 in epoch 1, gen_loss = 0.7448892755090353, disc_loss = 0.13990810194967132
Trained batch 1209 in epoch 1, gen_loss = 0.7449543236208356, disc_loss = 0.1399121816808835
Trained batch 1210 in epoch 1, gen_loss = 0.7449683759647593, disc_loss = 0.1398820748743405
Trained batch 1211 in epoch 1, gen_loss = 0.7448082053326931, disc_loss = 0.1399608524308752
Trained batch 1212 in epoch 1, gen_loss = 0.7446388040607071, disc_loss = 0.13998473451072804
Trained batch 1213 in epoch 1, gen_loss = 0.7445841371718506, disc_loss = 0.13996047422955737
Trained batch 1214 in epoch 1, gen_loss = 0.7446518854839812, disc_loss = 0.13993233446675687
Trained batch 1215 in epoch 1, gen_loss = 0.7446770937623162, disc_loss = 0.139905651413229
Trained batch 1216 in epoch 1, gen_loss = 0.7445536963060045, disc_loss = 0.13993333076297526
Trained batch 1217 in epoch 1, gen_loss = 0.744360457647023, disc_loss = 0.13994305073826502
Trained batch 1218 in epoch 1, gen_loss = 0.7445230732891186, disc_loss = 0.13990118102819168
Trained batch 1219 in epoch 1, gen_loss = 0.744491944303278, disc_loss = 0.13987157609939696
Trained batch 1220 in epoch 1, gen_loss = 0.7442941907778028, disc_loss = 0.13990021878464437
Trained batch 1221 in epoch 1, gen_loss = 0.7442635391425775, disc_loss = 0.1399501225935469
Trained batch 1222 in epoch 1, gen_loss = 0.7443207472635894, disc_loss = 0.13992936047858642
Trained batch 1223 in epoch 1, gen_loss = 0.7443873276507932, disc_loss = 0.1398461714084108
Trained batch 1224 in epoch 1, gen_loss = 0.7443939864878751, disc_loss = 0.13981941311107
Trained batch 1225 in epoch 1, gen_loss = 0.7444191380581693, disc_loss = 0.13979519910724503
Trained batch 1226 in epoch 1, gen_loss = 0.74441634068765, disc_loss = 0.13974391175137973
Trained batch 1227 in epoch 1, gen_loss = 0.7445964996220623, disc_loss = 0.1397193434598161
Trained batch 1228 in epoch 1, gen_loss = 0.7445927670663504, disc_loss = 0.13970648563801152
Trained batch 1229 in epoch 1, gen_loss = 0.7444451460993387, disc_loss = 0.13972197534001576
Trained batch 1230 in epoch 1, gen_loss = 0.7446918413950891, disc_loss = 0.13983616453559902
Trained batch 1231 in epoch 1, gen_loss = 0.7445662760889376, disc_loss = 0.13980778827189844
Trained batch 1232 in epoch 1, gen_loss = 0.7444517524476373, disc_loss = 0.13986371989707128
Trained batch 1233 in epoch 1, gen_loss = 0.7442656881998578, disc_loss = 0.13992361219998334
Trained batch 1234 in epoch 1, gen_loss = 0.7445538623130273, disc_loss = 0.13995577595630276
Trained batch 1235 in epoch 1, gen_loss = 0.7445185890957762, disc_loss = 0.13989864052635012
Trained batch 1236 in epoch 1, gen_loss = 0.744445843039353, disc_loss = 0.13993481553642256
Trained batch 1237 in epoch 1, gen_loss = 0.7444885998530997, disc_loss = 0.13989194686357564
Trained batch 1238 in epoch 1, gen_loss = 0.7445922812403355, disc_loss = 0.1399350511526525
Trained batch 1239 in epoch 1, gen_loss = 0.7443796385680476, disc_loss = 0.13995393582304277
Trained batch 1240 in epoch 1, gen_loss = 0.7443731596736923, disc_loss = 0.13992318507181864
Trained batch 1241 in epoch 1, gen_loss = 0.7443722535446646, disc_loss = 0.1398720699377454
Trained batch 1242 in epoch 1, gen_loss = 0.7441475291647263, disc_loss = 0.14000547997734403
Trained batch 1243 in epoch 1, gen_loss = 0.744187719664773, disc_loss = 0.1400386810735455
Trained batch 1244 in epoch 1, gen_loss = 0.74448738423696, disc_loss = 0.14005449739580295
Trained batch 1245 in epoch 1, gen_loss = 0.7442920592585115, disc_loss = 0.14009442151468815
Trained batch 1246 in epoch 1, gen_loss = 0.7442971845579415, disc_loss = 0.14009928572833322
Trained batch 1247 in epoch 1, gen_loss = 0.7442079573296584, disc_loss = 0.14014168679251526
Trained batch 1248 in epoch 1, gen_loss = 0.7442336557768554, disc_loss = 0.1401322629784433
Trained batch 1249 in epoch 1, gen_loss = 0.7440155465364456, disc_loss = 0.1401836624123156
Trained batch 1250 in epoch 1, gen_loss = 0.7438609377323961, disc_loss = 0.14022447908301647
Trained batch 1251 in epoch 1, gen_loss = 0.7439661062420747, disc_loss = 0.14033589447616412
Trained batch 1252 in epoch 1, gen_loss = 0.7439850303571127, disc_loss = 0.14030354067234282
Trained batch 1253 in epoch 1, gen_loss = 0.7436634227752306, disc_loss = 0.14043229018401895
Trained batch 1254 in epoch 1, gen_loss = 0.7436041742444514, disc_loss = 0.1404336099108436
Trained batch 1255 in epoch 1, gen_loss = 0.7438458807671525, disc_loss = 0.14054653855043636
Trained batch 1256 in epoch 1, gen_loss = 0.7439348897529957, disc_loss = 0.1405329562778464
Trained batch 1257 in epoch 1, gen_loss = 0.7437793850093275, disc_loss = 0.14053216366103255
Trained batch 1258 in epoch 1, gen_loss = 0.7436428791810067, disc_loss = 0.14052155415429138
Trained batch 1259 in epoch 1, gen_loss = 0.7436325759405181, disc_loss = 0.1405968719805103
Trained batch 1260 in epoch 1, gen_loss = 0.7437442379703038, disc_loss = 0.14067334890687613
Trained batch 1261 in epoch 1, gen_loss = 0.7436503508436699, disc_loss = 0.14066865418339516
Trained batch 1262 in epoch 1, gen_loss = 0.7435941114042453, disc_loss = 0.1406400910396533
Trained batch 1263 in epoch 1, gen_loss = 0.7435512815048045, disc_loss = 0.1406433153403864
Trained batch 1264 in epoch 1, gen_loss = 0.7436009993901836, disc_loss = 0.1406713551779097
Trained batch 1265 in epoch 1, gen_loss = 0.7434815270311271, disc_loss = 0.1406885031323827
Trained batch 1266 in epoch 1, gen_loss = 0.743311946116382, disc_loss = 0.1407346916087295
Trained batch 1267 in epoch 1, gen_loss = 0.7432340859473692, disc_loss = 0.14069539663229103
Trained batch 1268 in epoch 1, gen_loss = 0.7432040705325755, disc_loss = 0.14071720145522398
Trained batch 1269 in epoch 1, gen_loss = 0.7433535519782014, disc_loss = 0.14070551968949635
Trained batch 1270 in epoch 1, gen_loss = 0.7432340624339931, disc_loss = 0.1407007100778675
Trained batch 1271 in epoch 1, gen_loss = 0.7433321447632972, disc_loss = 0.14064561756424396
Trained batch 1272 in epoch 1, gen_loss = 0.7433365963850074, disc_loss = 0.14057432533331796
Trained batch 1273 in epoch 1, gen_loss = 0.7433196439333202, disc_loss = 0.14060360256778412
Trained batch 1274 in epoch 1, gen_loss = 0.7432685444635504, disc_loss = 0.14063777816427103
Trained batch 1275 in epoch 1, gen_loss = 0.7432491686603866, disc_loss = 0.14056791881096423
Trained batch 1276 in epoch 1, gen_loss = 0.7431534808552069, disc_loss = 0.1405361642690555
Trained batch 1277 in epoch 1, gen_loss = 0.7433948075407547, disc_loss = 0.14047265194242758
Trained batch 1278 in epoch 1, gen_loss = 0.7432693286600105, disc_loss = 0.14046260123042809
Trained batch 1279 in epoch 1, gen_loss = 0.7434582172660157, disc_loss = 0.14039616747541003
Trained batch 1280 in epoch 1, gen_loss = 0.7435159345654004, disc_loss = 0.14031420583319817
Trained batch 1281 in epoch 1, gen_loss = 0.743738113462274, disc_loss = 0.140222043915566
Trained batch 1282 in epoch 1, gen_loss = 0.7438630617556865, disc_loss = 0.14013094736868553
Trained batch 1283 in epoch 1, gen_loss = 0.7436561284128379, disc_loss = 0.14020425510865483
Trained batch 1284 in epoch 1, gen_loss = 0.7436656930103376, disc_loss = 0.14015411456488797
Trained batch 1285 in epoch 1, gen_loss = 0.7435197468215533, disc_loss = 0.14022885044185013
Trained batch 1286 in epoch 1, gen_loss = 0.7439033420584233, disc_loss = 0.14030028974800932
Trained batch 1287 in epoch 1, gen_loss = 0.74382993546517, disc_loss = 0.14029484918060486
Trained batch 1288 in epoch 1, gen_loss = 0.7436253480480289, disc_loss = 0.1403107456566695
Trained batch 1289 in epoch 1, gen_loss = 0.743637932617535, disc_loss = 0.1403527681123783
Trained batch 1290 in epoch 1, gen_loss = 0.743945669957042, disc_loss = 0.14032834859696194
Trained batch 1291 in epoch 1, gen_loss = 0.7437993182624826, disc_loss = 0.1403793046047663
Trained batch 1292 in epoch 1, gen_loss = 0.7437892769854473, disc_loss = 0.14030234710070646
Trained batch 1293 in epoch 1, gen_loss = 0.7436721049698279, disc_loss = 0.14025360267174644
Trained batch 1294 in epoch 1, gen_loss = 0.7437366296195616, disc_loss = 0.1402347880002097
Trained batch 1295 in epoch 1, gen_loss = 0.7436283494081394, disc_loss = 0.14020595097279084
Trained batch 1296 in epoch 1, gen_loss = 0.7436703792101802, disc_loss = 0.14016192046452944
Trained batch 1297 in epoch 1, gen_loss = 0.7437438900325625, disc_loss = 0.14010740019515938
Trained batch 1298 in epoch 1, gen_loss = 0.7437225204646541, disc_loss = 0.14007223804938027
Trained batch 1299 in epoch 1, gen_loss = 0.7438716640151464, disc_loss = 0.13997529497871605
Trained batch 1300 in epoch 1, gen_loss = 0.7439771270083062, disc_loss = 0.13995905381217197
Trained batch 1301 in epoch 1, gen_loss = 0.744048358223039, disc_loss = 0.1399396748336378
Trained batch 1302 in epoch 1, gen_loss = 0.7439521700029453, disc_loss = 0.13993226524431
Trained batch 1303 in epoch 1, gen_loss = 0.7443379710194158, disc_loss = 0.13997388034387623
Trained batch 1304 in epoch 1, gen_loss = 0.7444572581413605, disc_loss = 0.13990001138442434
Trained batch 1305 in epoch 1, gen_loss = 0.7442661950316217, disc_loss = 0.1398621249500417
Trained batch 1306 in epoch 1, gen_loss = 0.744362505114343, disc_loss = 0.13987107807022178
Trained batch 1307 in epoch 1, gen_loss = 0.7441684867309504, disc_loss = 0.13983462730476728
Trained batch 1308 in epoch 1, gen_loss = 0.7441278160802275, disc_loss = 0.139758109119333
Trained batch 1309 in epoch 1, gen_loss = 0.7440428671718554, disc_loss = 0.139755347843872
Trained batch 1310 in epoch 1, gen_loss = 0.7439749854425726, disc_loss = 0.13978755778208954
Trained batch 1311 in epoch 1, gen_loss = 0.7438485464989776, disc_loss = 0.13979784002394144
Trained batch 1312 in epoch 1, gen_loss = 0.7438894455567263, disc_loss = 0.13975799004338052
Trained batch 1313 in epoch 1, gen_loss = 0.7438001439224821, disc_loss = 0.13978101974324844
Trained batch 1314 in epoch 1, gen_loss = 0.7439187540074265, disc_loss = 0.13975323782631766
Trained batch 1315 in epoch 1, gen_loss = 0.7440268945141404, disc_loss = 0.13974361481232778
Trained batch 1316 in epoch 1, gen_loss = 0.7440230211210505, disc_loss = 0.13970544226623183
Trained batch 1317 in epoch 1, gen_loss = 0.7439156079916383, disc_loss = 0.13970905988461624
Trained batch 1318 in epoch 1, gen_loss = 0.7439209986718158, disc_loss = 0.1397410137098709
Trained batch 1319 in epoch 1, gen_loss = 0.7440521580929106, disc_loss = 0.13965125771197068
Trained batch 1320 in epoch 1, gen_loss = 0.7441348824466746, disc_loss = 0.13956966744714686
Trained batch 1321 in epoch 1, gen_loss = 0.7440919230231359, disc_loss = 0.13953311594327103
Trained batch 1322 in epoch 1, gen_loss = 0.7441688041432915, disc_loss = 0.13950004817837694
Trained batch 1323 in epoch 1, gen_loss = 0.7441469298343644, disc_loss = 0.13944228515211843
Trained batch 1324 in epoch 1, gen_loss = 0.7442069568049233, disc_loss = 0.13939671472066417
Trained batch 1325 in epoch 1, gen_loss = 0.7442533626230954, disc_loss = 0.13937529639536192
Trained batch 1326 in epoch 1, gen_loss = 0.744205619014109, disc_loss = 0.13938394855966155
Trained batch 1327 in epoch 1, gen_loss = 0.7442497993224716, disc_loss = 0.13932497630313778
Trained batch 1328 in epoch 1, gen_loss = 0.7442341952103255, disc_loss = 0.13926059196361862
Trained batch 1329 in epoch 1, gen_loss = 0.7445958485056583, disc_loss = 0.1392580133442648
Trained batch 1330 in epoch 1, gen_loss = 0.7445352912441758, disc_loss = 0.1392525910672044
Trained batch 1331 in epoch 1, gen_loss = 0.7445593230851419, disc_loss = 0.1391567207779176
Trained batch 1332 in epoch 1, gen_loss = 0.7446036788412081, disc_loss = 0.13909586287115472
Trained batch 1333 in epoch 1, gen_loss = 0.7446738951343825, disc_loss = 0.13909240463620115
Trained batch 1334 in epoch 1, gen_loss = 0.7446885599848929, disc_loss = 0.1390411686480101
Trained batch 1335 in epoch 1, gen_loss = 0.7445198054129849, disc_loss = 0.13901013710388277
Trained batch 1336 in epoch 1, gen_loss = 0.7449842643497057, disc_loss = 0.13906006559676637
Trained batch 1337 in epoch 1, gen_loss = 0.744972981568231, disc_loss = 0.1390564392574176
Trained batch 1338 in epoch 1, gen_loss = 0.7450030266882502, disc_loss = 0.13903522463146767
Trained batch 1339 in epoch 1, gen_loss = 0.7450994230250814, disc_loss = 0.1389539594629974
Trained batch 1340 in epoch 1, gen_loss = 0.7450262539472089, disc_loss = 0.1389088148631761
Trained batch 1341 in epoch 1, gen_loss = 0.7452353838881153, disc_loss = 0.1388499971316786
Trained batch 1342 in epoch 1, gen_loss = 0.7452090757823399, disc_loss = 0.1388143178759308
Trained batch 1343 in epoch 1, gen_loss = 0.7451077285666197, disc_loss = 0.13881942732024027
Trained batch 1344 in epoch 1, gen_loss = 0.7450887509659764, disc_loss = 0.13878659697034879
Trained batch 1345 in epoch 1, gen_loss = 0.7453121396575959, disc_loss = 0.13876665107570976
Trained batch 1346 in epoch 1, gen_loss = 0.7451324774631325, disc_loss = 0.13878069835374132
Trained batch 1347 in epoch 1, gen_loss = 0.7450718421831682, disc_loss = 0.13870473658093957
Trained batch 1348 in epoch 1, gen_loss = 0.7452043674228985, disc_loss = 0.13863756790069562
Trained batch 1349 in epoch 1, gen_loss = 0.745340323249499, disc_loss = 0.13859157638624311
Trained batch 1350 in epoch 1, gen_loss = 0.7451621166738557, disc_loss = 0.13859133275886162
Trained batch 1351 in epoch 1, gen_loss = 0.7452276891108448, disc_loss = 0.13860680513599194
Trained batch 1352 in epoch 1, gen_loss = 0.7451932911553915, disc_loss = 0.13857210257571778
Trained batch 1353 in epoch 1, gen_loss = 0.7452117338270345, disc_loss = 0.1385010010425271
Trained batch 1354 in epoch 1, gen_loss = 0.7453934012083989, disc_loss = 0.13846486898902047
Trained batch 1355 in epoch 1, gen_loss = 0.7454543941184483, disc_loss = 0.13843118286400397
Trained batch 1356 in epoch 1, gen_loss = 0.7452522506148128, disc_loss = 0.1385061233465724
Trained batch 1357 in epoch 1, gen_loss = 0.7451871477275955, disc_loss = 0.1384775094785323
Trained batch 1358 in epoch 1, gen_loss = 0.7452354463169556, disc_loss = 0.13842039911324505
Trained batch 1359 in epoch 1, gen_loss = 0.7454389825025025, disc_loss = 0.1383893854662721
Trained batch 1360 in epoch 1, gen_loss = 0.7455965561695085, disc_loss = 0.1383062647121858
Trained batch 1361 in epoch 1, gen_loss = 0.7455231553482414, disc_loss = 0.13827352346059224
Trained batch 1362 in epoch 1, gen_loss = 0.7453771401921004, disc_loss = 0.13829406690240584
Trained batch 1363 in epoch 1, gen_loss = 0.7454123798528375, disc_loss = 0.13824153402506148
Trained batch 1364 in epoch 1, gen_loss = 0.7455029664895474, disc_loss = 0.1381691335806207
Trained batch 1365 in epoch 1, gen_loss = 0.7454153256569914, disc_loss = 0.13813518146380216
Trained batch 1366 in epoch 1, gen_loss = 0.7454935127396434, disc_loss = 0.13812624099483847
Trained batch 1367 in epoch 1, gen_loss = 0.7455813057764232, disc_loss = 0.1380509533912586
Trained batch 1368 in epoch 1, gen_loss = 0.7455341278244058, disc_loss = 0.1379920451563747
Trained batch 1369 in epoch 1, gen_loss = 0.7455933316780703, disc_loss = 0.13792506438360488
Trained batch 1370 in epoch 1, gen_loss = 0.7456322242359799, disc_loss = 0.1378824490419352
Trained batch 1371 in epoch 1, gen_loss = 0.74562233816778, disc_loss = 0.1378498715681157
Trained batch 1372 in epoch 1, gen_loss = 0.745932073811936, disc_loss = 0.1378191977472079
Trained batch 1373 in epoch 1, gen_loss = 0.745812895256359, disc_loss = 0.13780787256322638
Trained batch 1374 in epoch 1, gen_loss = 0.7457864612666043, disc_loss = 0.1379251966361295
Trained batch 1375 in epoch 1, gen_loss = 0.7457401585700207, disc_loss = 0.13794650198001046
Trained batch 1376 in epoch 1, gen_loss = 0.7457459173344493, disc_loss = 0.1378814922875644
Trained batch 1377 in epoch 1, gen_loss = 0.7456462084381951, disc_loss = 0.13785471394049822
Trained batch 1378 in epoch 1, gen_loss = 0.745767902645017, disc_loss = 0.13780257036602847
Trained batch 1379 in epoch 1, gen_loss = 0.745635065868281, disc_loss = 0.13779560169812455
Trained batch 1380 in epoch 1, gen_loss = 0.7457221835355323, disc_loss = 0.13774078802976442
Trained batch 1381 in epoch 1, gen_loss = 0.7458717149349439, disc_loss = 0.13781471938830187
Trained batch 1382 in epoch 1, gen_loss = 0.7457110561155704, disc_loss = 0.13786974588283812
Trained batch 1383 in epoch 1, gen_loss = 0.7457247448794414, disc_loss = 0.13783357375519448
Trained batch 1384 in epoch 1, gen_loss = 0.7458491341301681, disc_loss = 0.13789102733336953
Trained batch 1385 in epoch 1, gen_loss = 0.7459012921496387, disc_loss = 0.13789749714447802
Trained batch 1386 in epoch 1, gen_loss = 0.7457546328759141, disc_loss = 0.1378762189751436
Trained batch 1387 in epoch 1, gen_loss = 0.7456336153687249, disc_loss = 0.13794687830155947
Trained batch 1388 in epoch 1, gen_loss = 0.7460414340291802, disc_loss = 0.13802521774723664
Trained batch 1389 in epoch 1, gen_loss = 0.7461213011964619, disc_loss = 0.13804092688834388
Trained batch 1390 in epoch 1, gen_loss = 0.7460715697447573, disc_loss = 0.13812853412744192
Trained batch 1391 in epoch 1, gen_loss = 0.7461491912689017, disc_loss = 0.13810877605467156
Trained batch 1392 in epoch 1, gen_loss = 0.74604226870239, disc_loss = 0.13809506742956287
Trained batch 1393 in epoch 1, gen_loss = 0.74619229041692, disc_loss = 0.13809781648964226
Trained batch 1394 in epoch 1, gen_loss = 0.7460373953679129, disc_loss = 0.1380761996625946
Trained batch 1395 in epoch 1, gen_loss = 0.7459321436619007, disc_loss = 0.13809777069556659
Trained batch 1396 in epoch 1, gen_loss = 0.7460006078226531, disc_loss = 0.13809541025870323
Trained batch 1397 in epoch 1, gen_loss = 0.7461930244350979, disc_loss = 0.1381045946596891
Trained batch 1398 in epoch 1, gen_loss = 0.7463417275621689, disc_loss = 0.1380373010827259
Trained batch 1399 in epoch 1, gen_loss = 0.7462188225133078, disc_loss = 0.13804214022987124
Trained batch 1400 in epoch 1, gen_loss = 0.7461252923015184, disc_loss = 0.1379836257101754
Trained batch 1401 in epoch 1, gen_loss = 0.7461332310623517, disc_loss = 0.1380059662668271
Trained batch 1402 in epoch 1, gen_loss = 0.7462970564727348, disc_loss = 0.1380246926652678
Trained batch 1403 in epoch 1, gen_loss = 0.7461081343328851, disc_loss = 0.13811290600772236
Trained batch 1404 in epoch 1, gen_loss = 0.7460309574188286, disc_loss = 0.13815990269807205
Trained batch 1405 in epoch 1, gen_loss = 0.7462835176231851, disc_loss = 0.1382659035377141
Trained batch 1406 in epoch 1, gen_loss = 0.7460886664482068, disc_loss = 0.13830087724384701
Trained batch 1407 in epoch 1, gen_loss = 0.7459559211592105, disc_loss = 0.13829384968729838
Trained batch 1408 in epoch 1, gen_loss = 0.7459799966717375, disc_loss = 0.1382651724062749
Trained batch 1409 in epoch 1, gen_loss = 0.7459949003889206, disc_loss = 0.13832811338245762
Trained batch 1410 in epoch 1, gen_loss = 0.7459298589396866, disc_loss = 0.1383277503417146
Trained batch 1411 in epoch 1, gen_loss = 0.7458668362993018, disc_loss = 0.13831944687875045
Trained batch 1412 in epoch 1, gen_loss = 0.7458480283122323, disc_loss = 0.13832810187022881
Trained batch 1413 in epoch 1, gen_loss = 0.7459359322022515, disc_loss = 0.1385021686384025
Trained batch 1414 in epoch 1, gen_loss = 0.7458039266060603, disc_loss = 0.13856285655864453
Trained batch 1415 in epoch 1, gen_loss = 0.7456621500310925, disc_loss = 0.13853546203769176
Trained batch 1416 in epoch 1, gen_loss = 0.7458721590698312, disc_loss = 0.13856433375279142
Trained batch 1417 in epoch 1, gen_loss = 0.745893931691502, disc_loss = 0.13849069810655015
Trained batch 1418 in epoch 1, gen_loss = 0.7458572931235907, disc_loss = 0.13847147049008224
Trained batch 1419 in epoch 1, gen_loss = 0.745831482427221, disc_loss = 0.1384389968713562
Trained batch 1420 in epoch 1, gen_loss = 0.7460805467951893, disc_loss = 0.1383701270461911
Trained batch 1421 in epoch 1, gen_loss = 0.746184230437594, disc_loss = 0.13828467790092408
Trained batch 1422 in epoch 1, gen_loss = 0.7461011708829911, disc_loss = 0.13823927304028774
Trained batch 1423 in epoch 1, gen_loss = 0.7462227766014887, disc_loss = 0.13830812966772826
Trained batch 1424 in epoch 1, gen_loss = 0.7462370728609855, disc_loss = 0.1382542770937608
Trained batch 1425 in epoch 1, gen_loss = 0.7461421926091797, disc_loss = 0.13826282151490135
Trained batch 1426 in epoch 1, gen_loss = 0.7460902735496954, disc_loss = 0.13825876397271944
Trained batch 1427 in epoch 1, gen_loss = 0.7461039843846436, disc_loss = 0.13823808818280758
Trained batch 1428 in epoch 1, gen_loss = 0.7460457869890772, disc_loss = 0.13816323716772175
Trained batch 1429 in epoch 1, gen_loss = 0.7460473106040821, disc_loss = 0.13812053644821257
Trained batch 1430 in epoch 1, gen_loss = 0.7460719993029501, disc_loss = 0.13806981196045187
Trained batch 1431 in epoch 1, gen_loss = 0.7459819673992402, disc_loss = 0.13807726029095932
Trained batch 1432 in epoch 1, gen_loss = 0.7460109369786403, disc_loss = 0.13805127320050756
Trained batch 1433 in epoch 1, gen_loss = 0.7461083089540527, disc_loss = 0.13801309501107994
Trained batch 1434 in epoch 1, gen_loss = 0.7459643535082349, disc_loss = 0.13808381475884637
Trained batch 1435 in epoch 1, gen_loss = 0.7461731286932167, disc_loss = 0.13812033143504146
Trained batch 1436 in epoch 1, gen_loss = 0.7463954120521837, disc_loss = 0.13811859993941994
Trained batch 1437 in epoch 1, gen_loss = 0.7462807906187957, disc_loss = 0.13814705566170216
Trained batch 1438 in epoch 1, gen_loss = 0.7462495000847849, disc_loss = 0.13809019860910554
Trained batch 1439 in epoch 1, gen_loss = 0.7464337299681372, disc_loss = 0.13803112574063967
Trained batch 1440 in epoch 1, gen_loss = 0.7464487586147168, disc_loss = 0.13802153682743382
Trained batch 1441 in epoch 1, gen_loss = 0.7465683563655028, disc_loss = 0.13795085870253954
Trained batch 1442 in epoch 1, gen_loss = 0.7465176180428461, disc_loss = 0.13794229086101242
Trained batch 1443 in epoch 1, gen_loss = 0.7465923710873252, disc_loss = 0.13788475254563476
Trained batch 1444 in epoch 1, gen_loss = 0.7466212170759287, disc_loss = 0.13784863859041235
Trained batch 1445 in epoch 1, gen_loss = 0.7465010054955674, disc_loss = 0.13787874384599005
Trained batch 1446 in epoch 1, gen_loss = 0.7464705224933506, disc_loss = 0.13784526840416148
Trained batch 1447 in epoch 1, gen_loss = 0.7463861191387993, disc_loss = 0.13782605162412648
Trained batch 1448 in epoch 1, gen_loss = 0.7463513664988668, disc_loss = 0.13777218387237886
Trained batch 1449 in epoch 1, gen_loss = 0.7465234748248396, disc_loss = 0.13780315678117092
Trained batch 1450 in epoch 1, gen_loss = 0.7463821043728304, disc_loss = 0.13792525024841995
Trained batch 1451 in epoch 1, gen_loss = 0.7463061564881611, disc_loss = 0.1378751648814461
Trained batch 1452 in epoch 1, gen_loss = 0.746409891107865, disc_loss = 0.13795161484602866
Trained batch 1453 in epoch 1, gen_loss = 0.7465243269029641, disc_loss = 0.13793212262416538
Trained batch 1454 in epoch 1, gen_loss = 0.7463916643788315, disc_loss = 0.13795187901321454
Trained batch 1455 in epoch 1, gen_loss = 0.746371564997749, disc_loss = 0.13790684190238467
Trained batch 1456 in epoch 1, gen_loss = 0.7462863799800755, disc_loss = 0.1378660437503322
Trained batch 1457 in epoch 1, gen_loss = 0.7463648495033117, disc_loss = 0.1378713905835583
Trained batch 1458 in epoch 1, gen_loss = 0.7464228731626676, disc_loss = 0.1378489249546114
Trained batch 1459 in epoch 1, gen_loss = 0.7462162178673156, disc_loss = 0.1378728419842122
Trained batch 1460 in epoch 1, gen_loss = 0.7461602863263463, disc_loss = 0.13783090179601223
Trained batch 1461 in epoch 1, gen_loss = 0.7460899541788976, disc_loss = 0.13785790849703833
Trained batch 1462 in epoch 1, gen_loss = 0.7463154345852662, disc_loss = 0.1378856877180775
Trained batch 1463 in epoch 1, gen_loss = 0.74617047416545, disc_loss = 0.1379207001962124
Trained batch 1464 in epoch 1, gen_loss = 0.7461390160049595, disc_loss = 0.13790844162106006
Trained batch 1465 in epoch 1, gen_loss = 0.7460915905310382, disc_loss = 0.13784542247731782
Trained batch 1466 in epoch 1, gen_loss = 0.7463406240281883, disc_loss = 0.13785595971400244
Trained batch 1467 in epoch 1, gen_loss = 0.7462925565421419, disc_loss = 0.13783053982665391
Trained batch 1468 in epoch 1, gen_loss = 0.7462350050148467, disc_loss = 0.13785062425936603
Trained batch 1469 in epoch 1, gen_loss = 0.7462274449212211, disc_loss = 0.1378740725563649
Trained batch 1470 in epoch 1, gen_loss = 0.746376709010956, disc_loss = 0.13786886179570254
Trained batch 1471 in epoch 1, gen_loss = 0.7462012243821569, disc_loss = 0.1378718169460468
Trained batch 1472 in epoch 1, gen_loss = 0.7462596510513575, disc_loss = 0.13783558859133893
Trained batch 1473 in epoch 1, gen_loss = 0.7461885271272957, disc_loss = 0.1378002926660512
Trained batch 1474 in epoch 1, gen_loss = 0.7462840123499854, disc_loss = 0.1377448770271267
Trained batch 1475 in epoch 1, gen_loss = 0.7461303335622074, disc_loss = 0.13774051917224697
Trained batch 1476 in epoch 1, gen_loss = 0.7459406899937764, disc_loss = 0.13778440612093995
Trained batch 1477 in epoch 1, gen_loss = 0.7460851055924076, disc_loss = 0.13794196772304676
Trained batch 1478 in epoch 1, gen_loss = 0.7460097644762705, disc_loss = 0.13794859053102335
Trained batch 1479 in epoch 1, gen_loss = 0.7459310621425912, disc_loss = 0.13794495852198452
Trained batch 1480 in epoch 1, gen_loss = 0.7459525790349766, disc_loss = 0.13791208459375015
Trained batch 1481 in epoch 1, gen_loss = 0.7460649323206038, disc_loss = 0.13783976491402417
Trained batch 1482 in epoch 1, gen_loss = 0.7461544621738323, disc_loss = 0.13781686516482425
Trained batch 1483 in epoch 1, gen_loss = 0.7460232748577216, disc_loss = 0.13784314900312844
Trained batch 1484 in epoch 1, gen_loss = 0.7459421906407032, disc_loss = 0.13779030313483293
Trained batch 1485 in epoch 1, gen_loss = 0.7458406871693612, disc_loss = 0.1377524208662277
Trained batch 1486 in epoch 1, gen_loss = 0.745976681507267, disc_loss = 0.1377358315500012
Trained batch 1487 in epoch 1, gen_loss = 0.7461447270727286, disc_loss = 0.13766331107653576
Trained batch 1488 in epoch 1, gen_loss = 0.7460271190924481, disc_loss = 0.13763716256169664
Trained batch 1489 in epoch 1, gen_loss = 0.7459237300309559, disc_loss = 0.13763288218190506
Trained batch 1490 in epoch 1, gen_loss = 0.7459607277038032, disc_loss = 0.13757812384376084
Trained batch 1491 in epoch 1, gen_loss = 0.7458929288882672, disc_loss = 0.13755232327113343
Trained batch 1492 in epoch 1, gen_loss = 0.7457523849772193, disc_loss = 0.13759256265271513
Trained batch 1493 in epoch 1, gen_loss = 0.7456185872775005, disc_loss = 0.13758564369074772
Trained batch 1494 in epoch 1, gen_loss = 0.7456332188784877, disc_loss = 0.1375818067339302
Trained batch 1495 in epoch 1, gen_loss = 0.7455464436966468, disc_loss = 0.13761768488768727
Trained batch 1496 in epoch 1, gen_loss = 0.7455047400457985, disc_loss = 0.13763360472790445
Trained batch 1497 in epoch 1, gen_loss = 0.7453616426608591, disc_loss = 0.13761655130524322
Trained batch 1498 in epoch 1, gen_loss = 0.7456861235365381, disc_loss = 0.1377426822047887
Trained batch 1499 in epoch 1, gen_loss = 0.7457455072800319, disc_loss = 0.1376994562416027
Trained batch 1500 in epoch 1, gen_loss = 0.7454914586652048, disc_loss = 0.13778123299936845
Trained batch 1501 in epoch 1, gen_loss = 0.7454311799868127, disc_loss = 0.13778925711566833
Trained batch 1502 in epoch 1, gen_loss = 0.745430749036119, disc_loss = 0.13775328651544003
Trained batch 1503 in epoch 1, gen_loss = 0.7454240020324893, disc_loss = 0.13776140068744389
Trained batch 1504 in epoch 1, gen_loss = 0.7452886658055442, disc_loss = 0.13776357612724222
Trained batch 1505 in epoch 1, gen_loss = 0.7453224269319498, disc_loss = 0.13779610977415366
Trained batch 1506 in epoch 1, gen_loss = 0.7452427669519135, disc_loss = 0.13776023047355107
Trained batch 1507 in epoch 1, gen_loss = 0.7452179108318979, disc_loss = 0.13781578965492508
Trained batch 1508 in epoch 1, gen_loss = 0.7451061364473137, disc_loss = 0.1378259828679555
Trained batch 1509 in epoch 1, gen_loss = 0.744985357637437, disc_loss = 0.13787023796336048
Trained batch 1510 in epoch 1, gen_loss = 0.7450485591419795, disc_loss = 0.13785703832494411
Trained batch 1511 in epoch 1, gen_loss = 0.7451972863070233, disc_loss = 0.13783795626220544
Trained batch 1512 in epoch 1, gen_loss = 0.7450228445551998, disc_loss = 0.13788126535302486
Trained batch 1513 in epoch 1, gen_loss = 0.7451273654655233, disc_loss = 0.1378277980222993
Trained batch 1514 in epoch 1, gen_loss = 0.7450607051747073, disc_loss = 0.13780224472468738
Trained batch 1515 in epoch 1, gen_loss = 0.7450032475795154, disc_loss = 0.13777351811574895
Trained batch 1516 in epoch 1, gen_loss = 0.7450905908034204, disc_loss = 0.13773476692124093
Trained batch 1517 in epoch 1, gen_loss = 0.7449311507824067, disc_loss = 0.13775129923204327
Trained batch 1518 in epoch 1, gen_loss = 0.7453115640736631, disc_loss = 0.13783405956317418
Trained batch 1519 in epoch 1, gen_loss = 0.7451731491049653, disc_loss = 0.13782540578088773
Trained batch 1520 in epoch 1, gen_loss = 0.7450252052085483, disc_loss = 0.13782656628437667
Trained batch 1521 in epoch 1, gen_loss = 0.7450294929523505, disc_loss = 0.1377597286992519
Trained batch 1522 in epoch 1, gen_loss = 0.745007900387851, disc_loss = 0.13770621912694553
Trained batch 1523 in epoch 1, gen_loss = 0.7452068045891802, disc_loss = 0.1376792344446795
Trained batch 1524 in epoch 1, gen_loss = 0.7451697735903693, disc_loss = 0.13765049561552825
Trained batch 1525 in epoch 1, gen_loss = 0.7451509881183642, disc_loss = 0.13762576327272258
Trained batch 1526 in epoch 1, gen_loss = 0.7452422744437769, disc_loss = 0.13758998139216744
Trained batch 1527 in epoch 1, gen_loss = 0.745249011266138, disc_loss = 0.1375426403118824
Trained batch 1528 in epoch 1, gen_loss = 0.7453279449434511, disc_loss = 0.13748795389483437
Trained batch 1529 in epoch 1, gen_loss = 0.7452301920823802, disc_loss = 0.13751012230949367
Trained batch 1530 in epoch 1, gen_loss = 0.745312737316808, disc_loss = 0.13751955315711586
Trained batch 1531 in epoch 1, gen_loss = 0.7451255241939044, disc_loss = 0.13751980098141917
Trained batch 1532 in epoch 1, gen_loss = 0.7452060216521408, disc_loss = 0.13763852068450877
Trained batch 1533 in epoch 1, gen_loss = 0.7452140337990347, disc_loss = 0.13759218565233275
Trained batch 1534 in epoch 1, gen_loss = 0.7452813201502014, disc_loss = 0.1375496754325708
Trained batch 1535 in epoch 1, gen_loss = 0.7451079823464776, disc_loss = 0.1375471269608776
Trained batch 1536 in epoch 1, gen_loss = 0.7452749920186085, disc_loss = 0.13757820215037428
Trained batch 1537 in epoch 1, gen_loss = 0.7451444724756348, disc_loss = 0.1375833628269249
Trained batch 1538 in epoch 1, gen_loss = 0.7449961629604813, disc_loss = 0.13761321345284883
Trained batch 1539 in epoch 1, gen_loss = 0.7450636547881287, disc_loss = 0.13763208151190215
Trained batch 1540 in epoch 1, gen_loss = 0.7449105046616987, disc_loss = 0.13763828426635763
Trained batch 1541 in epoch 1, gen_loss = 0.7449144282306988, disc_loss = 0.13760255664603932
Trained batch 1542 in epoch 1, gen_loss = 0.7448129625731448, disc_loss = 0.1376070606281434
Trained batch 1543 in epoch 1, gen_loss = 0.7448509628522582, disc_loss = 0.137571685396767
Trained batch 1544 in epoch 1, gen_loss = 0.74500337985727, disc_loss = 0.13754972031816212
Trained batch 1545 in epoch 1, gen_loss = 0.7449072193821836, disc_loss = 0.13756853176695313
Trained batch 1546 in epoch 1, gen_loss = 0.7448377480565461, disc_loss = 0.1375444365518424
Trained batch 1547 in epoch 1, gen_loss = 0.7446957054988358, disc_loss = 0.13752728507574888
Trained batch 1548 in epoch 1, gen_loss = 0.744857868892751, disc_loss = 0.13752257395319262
Trained batch 1549 in epoch 1, gen_loss = 0.7447765124997785, disc_loss = 0.13758663306733773
Trained batch 1550 in epoch 1, gen_loss = 0.7446901586115706, disc_loss = 0.13760871146124057
Trained batch 1551 in epoch 1, gen_loss = 0.7446082763604283, disc_loss = 0.1375692941136802
Trained batch 1552 in epoch 1, gen_loss = 0.744560480962165, disc_loss = 0.13756205116057407
Trained batch 1553 in epoch 1, gen_loss = 0.7445441765981599, disc_loss = 0.137583780419465
Trained batch 1554 in epoch 1, gen_loss = 0.744565711527392, disc_loss = 0.13755535294041277
Trained batch 1555 in epoch 1, gen_loss = 0.7444007051174929, disc_loss = 0.13755768179776182
Trained batch 1556 in epoch 1, gen_loss = 0.7443204807714537, disc_loss = 0.137524674526926
Trained batch 1557 in epoch 1, gen_loss = 0.7443280975610516, disc_loss = 0.1375095961855746
Trained batch 1558 in epoch 1, gen_loss = 0.7444391401629176, disc_loss = 0.13758050702868305
Trained batch 1559 in epoch 1, gen_loss = 0.7443727732850955, disc_loss = 0.13756494667703428
Trained batch 1560 in epoch 1, gen_loss = 0.7443189100146981, disc_loss = 0.13755415320279485
Trained batch 1561 in epoch 1, gen_loss = 0.7444044097437597, disc_loss = 0.1375366476347739
Trained batch 1562 in epoch 1, gen_loss = 0.7443795992789631, disc_loss = 0.13751973973447726
Trained batch 1563 in epoch 1, gen_loss = 0.7442692467166335, disc_loss = 0.13751449551173697
Trained batch 1564 in epoch 1, gen_loss = 0.7442003830934104, disc_loss = 0.1374979900898406
Trained batch 1565 in epoch 1, gen_loss = 0.7441092367601577, disc_loss = 0.13751191131492285
Trained batch 1566 in epoch 1, gen_loss = 0.7440866024233995, disc_loss = 0.13748826131631156
Trained batch 1567 in epoch 1, gen_loss = 0.7440637664831414, disc_loss = 0.13744279692764394
Trained batch 1568 in epoch 1, gen_loss = 0.7443944796245519, disc_loss = 0.13748729735116638
Trained batch 1569 in epoch 1, gen_loss = 0.7442643970820555, disc_loss = 0.13753741669177913
Trained batch 1570 in epoch 1, gen_loss = 0.744210160173177, disc_loss = 0.13751537814193343
Trained batch 1571 in epoch 1, gen_loss = 0.7442916226371857, disc_loss = 0.13764990562793464
Trained batch 1572 in epoch 1, gen_loss = 0.7441574455595895, disc_loss = 0.13767235828841842
Trained batch 1573 in epoch 1, gen_loss = 0.7439931497981315, disc_loss = 0.13777006598274677
Trained batch 1574 in epoch 1, gen_loss = 0.7440604737637535, disc_loss = 0.1378281549606768
Trained batch 1575 in epoch 1, gen_loss = 0.7440929026508392, disc_loss = 0.13782103214032362
Trained batch 1576 in epoch 1, gen_loss = 0.7440613017062561, disc_loss = 0.13782768702629383
Trained batch 1577 in epoch 1, gen_loss = 0.7439752328569595, disc_loss = 0.13782499515226038
Trained batch 1578 in epoch 1, gen_loss = 0.7438607033368075, disc_loss = 0.13785986766452707
Trained batch 1579 in epoch 1, gen_loss = 0.7439074996340124, disc_loss = 0.13787000408407915
Trained batch 1580 in epoch 1, gen_loss = 0.7438293650397615, disc_loss = 0.13789945762547925
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 0.9762182235717773, disc_loss = 0.15189403295516968
Trained batch 1 in epoch 2, gen_loss = 0.6987599283456802, disc_loss = 0.22419065237045288
Trained batch 2 in epoch 2, gen_loss = 0.7027646402517954, disc_loss = 0.1970493644475937
Trained batch 3 in epoch 2, gen_loss = 0.7771227136254311, disc_loss = 0.2239002324640751
Trained batch 4 in epoch 2, gen_loss = 0.7463206350803375, disc_loss = 0.19850554168224335
Trained batch 5 in epoch 2, gen_loss = 0.7130030145247778, disc_loss = 0.1984398066997528
Trained batch 6 in epoch 2, gen_loss = 0.7185758054256439, disc_loss = 0.18856129476002284
Trained batch 7 in epoch 2, gen_loss = 0.7311459667980671, disc_loss = 0.19113627821207047
Trained batch 8 in epoch 2, gen_loss = 0.7195253802670373, disc_loss = 0.1855337553554111
Trained batch 9 in epoch 2, gen_loss = 0.7163529127836228, disc_loss = 0.1739941008388996
Trained batch 10 in epoch 2, gen_loss = 0.7154350470412861, disc_loss = 0.16196121647953987
Trained batch 11 in epoch 2, gen_loss = 0.7035194610555967, disc_loss = 0.15596355528881153
Trained batch 12 in epoch 2, gen_loss = 0.7203976443180671, disc_loss = 0.1578913230735522
Trained batch 13 in epoch 2, gen_loss = 0.7227785225425448, disc_loss = 0.15302113576659135
Trained batch 14 in epoch 2, gen_loss = 0.7170458932717642, disc_loss = 0.15030172343055406
Trained batch 15 in epoch 2, gen_loss = 0.7155983950942755, disc_loss = 0.14827431249432266
Trained batch 16 in epoch 2, gen_loss = 0.7089644232217003, disc_loss = 0.14707382877959924
Trained batch 17 in epoch 2, gen_loss = 0.7241345627440346, disc_loss = 0.14939315099683073
Trained batch 18 in epoch 2, gen_loss = 0.7338367590778753, disc_loss = 0.1450309022084663
Trained batch 19 in epoch 2, gen_loss = 0.7367752149701119, disc_loss = 0.1404058078303933
Trained batch 20 in epoch 2, gen_loss = 0.7394992694968269, disc_loss = 0.1362753196486405
Trained batch 21 in epoch 2, gen_loss = 0.7394823824817484, disc_loss = 0.13304457457905466
Trained batch 22 in epoch 2, gen_loss = 0.7400444940380428, disc_loss = 0.13114641461035478
Trained batch 23 in epoch 2, gen_loss = 0.7402901860574881, disc_loss = 0.12967385770753026
Trained batch 24 in epoch 2, gen_loss = 0.7409144651889801, disc_loss = 0.12765366598963737
Trained batch 25 in epoch 2, gen_loss = 0.7430805346140494, disc_loss = 0.1253776548860165
Trained batch 26 in epoch 2, gen_loss = 0.7421450316905975, disc_loss = 0.12541124983518212
Trained batch 27 in epoch 2, gen_loss = 0.7464804149099759, disc_loss = 0.122206084829356
Trained batch 28 in epoch 2, gen_loss = 0.7399198114871979, disc_loss = 0.12196534114151165
Trained batch 29 in epoch 2, gen_loss = 0.7593132664759954, disc_loss = 0.12001295474668344
Trained batch 30 in epoch 2, gen_loss = 0.7555930181857078, disc_loss = 0.11769585371498138
Trained batch 31 in epoch 2, gen_loss = 0.7607049373909831, disc_loss = 0.1148976176045835
Trained batch 32 in epoch 2, gen_loss = 0.7618288695812225, disc_loss = 0.11259119257782445
Trained batch 33 in epoch 2, gen_loss = 0.7671575432314592, disc_loss = 0.11069612917216386
Trained batch 34 in epoch 2, gen_loss = 0.7697140514850617, disc_loss = 0.11287430705768721
Trained batch 35 in epoch 2, gen_loss = 0.7683794589506255, disc_loss = 0.11106400471180677
Trained batch 36 in epoch 2, gen_loss = 0.7701015883200878, disc_loss = 0.10955286217299667
Trained batch 37 in epoch 2, gen_loss = 0.7714040334287443, disc_loss = 0.10830030570689
Trained batch 38 in epoch 2, gen_loss = 0.7757480870454739, disc_loss = 0.10615666879293247
Trained batch 39 in epoch 2, gen_loss = 0.7900667004287243, disc_loss = 0.1046551601961255
Trained batch 40 in epoch 2, gen_loss = 0.8038424507873815, disc_loss = 0.10288106323015399
Trained batch 41 in epoch 2, gen_loss = 0.8087107219866344, disc_loss = 0.10165016645831722
Trained batch 42 in epoch 2, gen_loss = 0.8039976337621378, disc_loss = 0.1021878307815208
Trained batch 43 in epoch 2, gen_loss = 0.8068726665594361, disc_loss = 0.10113104356622155
Trained batch 44 in epoch 2, gen_loss = 0.8150709794627296, disc_loss = 0.09933584982322322
Trained batch 45 in epoch 2, gen_loss = 0.8236235386651495, disc_loss = 0.09774040811411712
Trained batch 46 in epoch 2, gen_loss = 0.82646976696684, disc_loss = 0.09632403403520584
Trained batch 47 in epoch 2, gen_loss = 0.8297878025720516, disc_loss = 0.09486906843570371
Trained batch 48 in epoch 2, gen_loss = 0.8330214552733363, disc_loss = 0.0933733942481328
Trained batch 49 in epoch 2, gen_loss = 0.8387116187810898, disc_loss = 0.09201265599578619
Trained batch 50 in epoch 2, gen_loss = 0.8410108200475281, disc_loss = 0.09072656250175308
Trained batch 51 in epoch 2, gen_loss = 0.8378242626786232, disc_loss = 0.09077975719880599
Trained batch 52 in epoch 2, gen_loss = 0.8393644358751908, disc_loss = 0.09007034282077034
Trained batch 53 in epoch 2, gen_loss = 0.8499264821962074, disc_loss = 0.08973176680781224
Trained batch 54 in epoch 2, gen_loss = 0.8427294541488994, disc_loss = 0.09141903560269962
Trained batch 55 in epoch 2, gen_loss = 0.8425357815410409, disc_loss = 0.0909112413812961
Trained batch 56 in epoch 2, gen_loss = 0.8438229817047453, disc_loss = 0.08977697136109336
Trained batch 57 in epoch 2, gen_loss = 0.8419643460676588, disc_loss = 0.08902771038741901
Trained batch 58 in epoch 2, gen_loss = 0.8431339673066544, disc_loss = 0.08808679821885239
Trained batch 59 in epoch 2, gen_loss = 0.8409076775113742, disc_loss = 0.08809183668345213
Trained batch 60 in epoch 2, gen_loss = 0.8405669795685127, disc_loss = 0.08803097543413521
Trained batch 61 in epoch 2, gen_loss = 0.8420317966130472, disc_loss = 0.08708251508012894
Trained batch 62 in epoch 2, gen_loss = 0.8360901025552598, disc_loss = 0.08908152816787598
Trained batch 63 in epoch 2, gen_loss = 0.8386116730980575, disc_loss = 0.090668287826702
Trained batch 64 in epoch 2, gen_loss = 0.836527295754506, disc_loss = 0.08976808385207102
Trained batch 65 in epoch 2, gen_loss = 0.8343710262667049, disc_loss = 0.08965547326387781
Trained batch 66 in epoch 2, gen_loss = 0.834862132125826, disc_loss = 0.0902476371891463
Trained batch 67 in epoch 2, gen_loss = 0.8368654825231608, disc_loss = 0.09156740686910994
Trained batch 68 in epoch 2, gen_loss = 0.8311194146888844, disc_loss = 0.09394331567961237
Trained batch 69 in epoch 2, gen_loss = 0.8268368797642844, disc_loss = 0.09510406479239464
Trained batch 70 in epoch 2, gen_loss = 0.831920799235223, disc_loss = 0.09669840430289926
Trained batch 71 in epoch 2, gen_loss = 0.8317597831288973, disc_loss = 0.0961361067990462
Trained batch 72 in epoch 2, gen_loss = 0.8283167399772225, disc_loss = 0.09648640392577812
Trained batch 73 in epoch 2, gen_loss = 0.8265618891329378, disc_loss = 0.09693396816382537
Trained batch 74 in epoch 2, gen_loss = 0.823591050306956, disc_loss = 0.09764513969421387
Trained batch 75 in epoch 2, gen_loss = 0.8232196514543734, disc_loss = 0.09746100381016731
Trained batch 76 in epoch 2, gen_loss = 0.8221672595321358, disc_loss = 0.0990725624096858
Trained batch 77 in epoch 2, gen_loss = 0.8210002069289868, disc_loss = 0.09880405396987231
Trained batch 78 in epoch 2, gen_loss = 0.818251059779638, disc_loss = 0.09902667678609679
Trained batch 79 in epoch 2, gen_loss = 0.8176716834306716, disc_loss = 0.09979189988225698
Trained batch 80 in epoch 2, gen_loss = 0.8154304579452232, disc_loss = 0.0998287096987536
Trained batch 81 in epoch 2, gen_loss = 0.8181403170271617, disc_loss = 0.10331528679263301
Trained batch 82 in epoch 2, gen_loss = 0.8152334223310631, disc_loss = 0.10438123444117696
Trained batch 83 in epoch 2, gen_loss = 0.8139574889625821, disc_loss = 0.10430403381940864
Trained batch 84 in epoch 2, gen_loss = 0.813639540532056, disc_loss = 0.10436924424241571
Trained batch 85 in epoch 2, gen_loss = 0.8122098057769066, disc_loss = 0.10476645489418229
Trained batch 86 in epoch 2, gen_loss = 0.813680838579419, disc_loss = 0.10424974201054409
Trained batch 87 in epoch 2, gen_loss = 0.8145094954154708, disc_loss = 0.10381854156201537
Trained batch 88 in epoch 2, gen_loss = 0.8137051041206617, disc_loss = 0.10331888647561663
Trained batch 89 in epoch 2, gen_loss = 0.8117569009462993, disc_loss = 0.10310306780868106
Trained batch 90 in epoch 2, gen_loss = 0.8128567914386372, disc_loss = 0.104003356053279
Trained batch 91 in epoch 2, gen_loss = 0.8098092072683832, disc_loss = 0.10384237409933754
Trained batch 92 in epoch 2, gen_loss = 0.8062937560901847, disc_loss = 0.10481804593275952
Trained batch 93 in epoch 2, gen_loss = 0.8121981398856386, disc_loss = 0.10636264799123114
Trained batch 94 in epoch 2, gen_loss = 0.8090104423071208, disc_loss = 0.10708775567381006
Trained batch 95 in epoch 2, gen_loss = 0.8065713650236527, disc_loss = 0.10777921105424564
Trained batch 96 in epoch 2, gen_loss = 0.804585902961259, disc_loss = 0.10791180574709607
Trained batch 97 in epoch 2, gen_loss = 0.8037331700325012, disc_loss = 0.10804862414999884
Trained batch 98 in epoch 2, gen_loss = 0.8019407650437018, disc_loss = 0.10854432641556769
Trained batch 99 in epoch 2, gen_loss = 0.7989723950624465, disc_loss = 0.1091426170617342
Trained batch 100 in epoch 2, gen_loss = 0.7985125667978041, disc_loss = 0.10905607214363494
Trained batch 101 in epoch 2, gen_loss = 0.7991044515488195, disc_loss = 0.11201792378343788
Trained batch 102 in epoch 2, gen_loss = 0.7981738523372168, disc_loss = 0.11228791754511953
Trained batch 103 in epoch 2, gen_loss = 0.7972273752093315, disc_loss = 0.11232916351694328
Trained batch 104 in epoch 2, gen_loss = 0.79882356269019, disc_loss = 0.1125396667491822
Trained batch 105 in epoch 2, gen_loss = 0.7990222325864828, disc_loss = 0.11229623010698354
Trained batch 106 in epoch 2, gen_loss = 0.7983410570109002, disc_loss = 0.1122861510125276
Trained batch 107 in epoch 2, gen_loss = 0.7965225555278637, disc_loss = 0.11229956370812876
Trained batch 108 in epoch 2, gen_loss = 0.79466470337789, disc_loss = 0.1124713921218837
Trained batch 109 in epoch 2, gen_loss = 0.7940734332258051, disc_loss = 0.11222278408028863
Trained batch 110 in epoch 2, gen_loss = 0.7937082052230835, disc_loss = 0.11254128625801017
Trained batch 111 in epoch 2, gen_loss = 0.7920289098152092, disc_loss = 0.1125840177493436
Trained batch 112 in epoch 2, gen_loss = 0.7926033835495467, disc_loss = 0.11245915873915749
Trained batch 113 in epoch 2, gen_loss = 0.7919084701621741, disc_loss = 0.11292323888393871
Trained batch 114 in epoch 2, gen_loss = 0.7917146071143772, disc_loss = 0.11260614434014196
Trained batch 115 in epoch 2, gen_loss = 0.7917017104296848, disc_loss = 0.11318857094337201
Trained batch 116 in epoch 2, gen_loss = 0.790509842399858, disc_loss = 0.1136843888168661
Trained batch 117 in epoch 2, gen_loss = 0.7901409834118213, disc_loss = 0.11321546872919899
Trained batch 118 in epoch 2, gen_loss = 0.7913464167538811, disc_loss = 0.11323280948675982
Trained batch 119 in epoch 2, gen_loss = 0.7906363149483998, disc_loss = 0.11333949320639174
Trained batch 120 in epoch 2, gen_loss = 0.7918368262692916, disc_loss = 0.11304919929666953
Trained batch 121 in epoch 2, gen_loss = 0.7907124669825445, disc_loss = 0.11314894738378095
Trained batch 122 in epoch 2, gen_loss = 0.7918207747180287, disc_loss = 0.11279272163907687
Trained batch 123 in epoch 2, gen_loss = 0.7937619402523963, disc_loss = 0.1120938791953508
Trained batch 124 in epoch 2, gen_loss = 0.7929170160293579, disc_loss = 0.1120001823157072
Trained batch 125 in epoch 2, gen_loss = 0.7969233649117606, disc_loss = 0.11166906479509577
Trained batch 126 in epoch 2, gen_loss = 0.7985784641401036, disc_loss = 0.11106139613594126
Trained batch 127 in epoch 2, gen_loss = 0.7963278130628169, disc_loss = 0.11154942917346489
Trained batch 128 in epoch 2, gen_loss = 0.7967374218526737, disc_loss = 0.11085917763123217
Trained batch 129 in epoch 2, gen_loss = 0.7961489191422095, disc_loss = 0.11039682913285036
Trained batch 130 in epoch 2, gen_loss = 0.8009782337960396, disc_loss = 0.11128430750988821
Trained batch 131 in epoch 2, gen_loss = 0.7996903382467501, disc_loss = 0.1110369972884655
Trained batch 132 in epoch 2, gen_loss = 0.7990078536191381, disc_loss = 0.1109819930971117
Trained batch 133 in epoch 2, gen_loss = 0.7976674441970996, disc_loss = 0.11155233565551131
Trained batch 134 in epoch 2, gen_loss = 0.7981514109505548, disc_loss = 0.11162689085359927
Trained batch 135 in epoch 2, gen_loss = 0.7986709795453969, disc_loss = 0.11136358943493928
Trained batch 136 in epoch 2, gen_loss = 0.797135912588913, disc_loss = 0.11321720383028044
Trained batch 137 in epoch 2, gen_loss = 0.7999476133913234, disc_loss = 0.11382359244685242
Trained batch 138 in epoch 2, gen_loss = 0.7999155264106586, disc_loss = 0.11330189802449384
Trained batch 139 in epoch 2, gen_loss = 0.7980847086225237, disc_loss = 0.1133132774915014
Trained batch 140 in epoch 2, gen_loss = 0.7996236449437784, disc_loss = 0.1128178081138337
Trained batch 141 in epoch 2, gen_loss = 0.8004260571070121, disc_loss = 0.11245482021444281
Trained batch 142 in epoch 2, gen_loss = 0.7995462096654452, disc_loss = 0.11233813284368782
Trained batch 143 in epoch 2, gen_loss = 0.7986999199622207, disc_loss = 0.11233990924018952
Trained batch 144 in epoch 2, gen_loss = 0.7970842895836666, disc_loss = 0.11244574009344496
Trained batch 145 in epoch 2, gen_loss = 0.7990974473626646, disc_loss = 0.11258825440316984
Trained batch 146 in epoch 2, gen_loss = 0.7986867614343863, disc_loss = 0.11203166494006608
Trained batch 147 in epoch 2, gen_loss = 0.7978837494109128, disc_loss = 0.11165549473937701
Trained batch 148 in epoch 2, gen_loss = 0.7964658925197269, disc_loss = 0.11139569265280394
Trained batch 149 in epoch 2, gen_loss = 0.7964294489224751, disc_loss = 0.11136856405685346
Trained batch 150 in epoch 2, gen_loss = 0.796331304982798, disc_loss = 0.11146313552775525
Trained batch 151 in epoch 2, gen_loss = 0.7963082253148681, disc_loss = 0.1108744016873013
Trained batch 152 in epoch 2, gen_loss = 0.7942545567852219, disc_loss = 0.11116837840405555
Trained batch 153 in epoch 2, gen_loss = 0.7934598378933869, disc_loss = 0.11100991881851639
Trained batch 154 in epoch 2, gen_loss = 0.7962553760697765, disc_loss = 0.11136591125640177
Trained batch 155 in epoch 2, gen_loss = 0.7953590229153633, disc_loss = 0.11117846832777827
Trained batch 156 in epoch 2, gen_loss = 0.7940965418223362, disc_loss = 0.11120362407794804
Trained batch 157 in epoch 2, gen_loss = 0.7945587795369232, disc_loss = 0.11095039927270971
Trained batch 158 in epoch 2, gen_loss = 0.7961975442913344, disc_loss = 0.1117816584641641
Trained batch 159 in epoch 2, gen_loss = 0.7945503672584892, disc_loss = 0.11353068299358711
Trained batch 160 in epoch 2, gen_loss = 0.795959301431727, disc_loss = 0.11314954079965257
Trained batch 161 in epoch 2, gen_loss = 0.7961435312474215, disc_loss = 0.11337461822700722
Trained batch 162 in epoch 2, gen_loss = 0.794077230194595, disc_loss = 0.11448345460180491
Trained batch 163 in epoch 2, gen_loss = 0.7952734862522381, disc_loss = 0.1141989372738796
Trained batch 164 in epoch 2, gen_loss = 0.7954071129813339, disc_loss = 0.11452491634497136
Trained batch 165 in epoch 2, gen_loss = 0.7948849816997368, disc_loss = 0.11485930225890444
Trained batch 166 in epoch 2, gen_loss = 0.7942217322523722, disc_loss = 0.11529689883355966
Trained batch 167 in epoch 2, gen_loss = 0.7928938828408718, disc_loss = 0.11507240814777712
Trained batch 168 in epoch 2, gen_loss = 0.7945788532671844, disc_loss = 0.11521518925899232
Trained batch 169 in epoch 2, gen_loss = 0.7945335845736896, disc_loss = 0.11522727081661716
Trained batch 170 in epoch 2, gen_loss = 0.7934467240035186, disc_loss = 0.11518767274567607
Trained batch 171 in epoch 2, gen_loss = 0.7926621476924697, disc_loss = 0.11513860275709005
Trained batch 172 in epoch 2, gen_loss = 0.7919552472629988, disc_loss = 0.11502014741172335
Trained batch 173 in epoch 2, gen_loss = 0.7920356747405283, disc_loss = 0.11478132569370256
Trained batch 174 in epoch 2, gen_loss = 0.7908866628578731, disc_loss = 0.11440051950514317
Trained batch 175 in epoch 2, gen_loss = 0.7913392990488898, disc_loss = 0.1143532728839835
Trained batch 176 in epoch 2, gen_loss = 0.7909882730346615, disc_loss = 0.11400049088238659
Trained batch 177 in epoch 2, gen_loss = 0.7899757471312298, disc_loss = 0.1144011729407344
Trained batch 178 in epoch 2, gen_loss = 0.7899391356460209, disc_loss = 0.11407733237235573
Trained batch 179 in epoch 2, gen_loss = 0.7911398058136304, disc_loss = 0.11415356206190255
Trained batch 180 in epoch 2, gen_loss = 0.7905104929241686, disc_loss = 0.11541855078993252
Trained batch 181 in epoch 2, gen_loss = 0.7887144868190472, disc_loss = 0.1159804914412754
Trained batch 182 in epoch 2, gen_loss = 0.7889619437071795, disc_loss = 0.11566987408762747
Trained batch 183 in epoch 2, gen_loss = 0.7892851434324099, disc_loss = 0.11540723991904246
Trained batch 184 in epoch 2, gen_loss = 0.7896765277192399, disc_loss = 0.1151627212662149
Trained batch 185 in epoch 2, gen_loss = 0.7889478421339424, disc_loss = 0.11498129214610785
Trained batch 186 in epoch 2, gen_loss = 0.7901976806594726, disc_loss = 0.11491795014689632
Trained batch 187 in epoch 2, gen_loss = 0.7890879109184793, disc_loss = 0.11484540997944931
Trained batch 188 in epoch 2, gen_loss = 0.7894980308240053, disc_loss = 0.11461189569580177
Trained batch 189 in epoch 2, gen_loss = 0.788919733072582, disc_loss = 0.11432967345769468
Trained batch 190 in epoch 2, gen_loss = 0.7895332275260806, disc_loss = 0.11381606088648916
Trained batch 191 in epoch 2, gen_loss = 0.7885777341822783, disc_loss = 0.11370506589688982
Trained batch 192 in epoch 2, gen_loss = 0.7891005873680115, disc_loss = 0.11366256212555065
Trained batch 193 in epoch 2, gen_loss = 0.7886219912583066, disc_loss = 0.11347773016344026
Trained batch 194 in epoch 2, gen_loss = 0.7882175619785602, disc_loss = 0.11341021731495857
Trained batch 195 in epoch 2, gen_loss = 0.788097907998124, disc_loss = 0.11356365040172728
Trained batch 196 in epoch 2, gen_loss = 0.7862180398805493, disc_loss = 0.11432778122385746
Trained batch 197 in epoch 2, gen_loss = 0.7866795954078135, disc_loss = 0.1142776341487964
Trained batch 198 in epoch 2, gen_loss = 0.7855528233638361, disc_loss = 0.11451511573626767
Trained batch 199 in epoch 2, gen_loss = 0.7853040051460266, disc_loss = 0.11470376247540116
Trained batch 200 in epoch 2, gen_loss = 0.7843343298233564, disc_loss = 0.11488409208791767
Trained batch 201 in epoch 2, gen_loss = 0.7848874690509079, disc_loss = 0.11516962261261916
Trained batch 202 in epoch 2, gen_loss = 0.7834523615285094, disc_loss = 0.11551175235307275
Trained batch 203 in epoch 2, gen_loss = 0.7843202155302552, disc_loss = 0.11595165212729983
Trained batch 204 in epoch 2, gen_loss = 0.7831233107462162, disc_loss = 0.11595909677264167
Trained batch 205 in epoch 2, gen_loss = 0.7822745634803494, disc_loss = 0.11617583204603311
Trained batch 206 in epoch 2, gen_loss = 0.7825507635367666, disc_loss = 0.11674993958522156
Trained batch 207 in epoch 2, gen_loss = 0.780979113939863, disc_loss = 0.1172371014701919
Trained batch 208 in epoch 2, gen_loss = 0.7810905360434044, disc_loss = 0.11713463903970696
Trained batch 209 in epoch 2, gen_loss = 0.7817866261516299, disc_loss = 0.11684855939376922
Trained batch 210 in epoch 2, gen_loss = 0.7806303002540534, disc_loss = 0.11707277242888771
Trained batch 211 in epoch 2, gen_loss = 0.7816910961607717, disc_loss = 0.11701598208186761
Trained batch 212 in epoch 2, gen_loss = 0.7824993120952392, disc_loss = 0.11726594992646588
Trained batch 213 in epoch 2, gen_loss = 0.780720100085312, disc_loss = 0.11803553357859638
Trained batch 214 in epoch 2, gen_loss = 0.7806801073772963, disc_loss = 0.11800170533878859
Trained batch 215 in epoch 2, gen_loss = 0.7802510828607612, disc_loss = 0.11808957538946911
Trained batch 216 in epoch 2, gen_loss = 0.7800862433448914, disc_loss = 0.11777968716717535
Trained batch 217 in epoch 2, gen_loss = 0.7801060502955673, disc_loss = 0.11748308133026329
Trained batch 218 in epoch 2, gen_loss = 0.7807196235820039, disc_loss = 0.11733402837425062
Trained batch 219 in epoch 2, gen_loss = 0.780415518310937, disc_loss = 0.11723079954020002
Trained batch 220 in epoch 2, gen_loss = 0.780068675452228, disc_loss = 0.11701102542998564
Trained batch 221 in epoch 2, gen_loss = 0.7804042311670544, disc_loss = 0.1167450272184503
Trained batch 222 in epoch 2, gen_loss = 0.7801082723611139, disc_loss = 0.11651831145310616
Trained batch 223 in epoch 2, gen_loss = 0.7806739478505084, disc_loss = 0.11612802375540403
Trained batch 224 in epoch 2, gen_loss = 0.7801403608587053, disc_loss = 0.11597222064104346
Trained batch 225 in epoch 2, gen_loss = 0.780232134250413, disc_loss = 0.11619948168013212
Trained batch 226 in epoch 2, gen_loss = 0.7804693137234003, disc_loss = 0.11612957913740353
Trained batch 227 in epoch 2, gen_loss = 0.7792632136689989, disc_loss = 0.1169257855549324
Trained batch 228 in epoch 2, gen_loss = 0.7791344449249418, disc_loss = 0.11666561335357777
Trained batch 229 in epoch 2, gen_loss = 0.7799800184757814, disc_loss = 0.11692139801933714
Trained batch 230 in epoch 2, gen_loss = 0.7802804802661334, disc_loss = 0.11650488375649824
Trained batch 231 in epoch 2, gen_loss = 0.7795357204459864, disc_loss = 0.11636205372432697
Trained batch 232 in epoch 2, gen_loss = 0.7791864103257912, disc_loss = 0.11617354935139033
Trained batch 233 in epoch 2, gen_loss = 0.7789685612815058, disc_loss = 0.11616455609153988
Trained batch 234 in epoch 2, gen_loss = 0.7790695737016962, disc_loss = 0.11597717405950769
Trained batch 235 in epoch 2, gen_loss = 0.7793061194025864, disc_loss = 0.11565959410962917
Trained batch 236 in epoch 2, gen_loss = 0.7784550012666968, disc_loss = 0.11556663551222424
Trained batch 237 in epoch 2, gen_loss = 0.7778106285493915, disc_loss = 0.11556579562357995
Trained batch 238 in epoch 2, gen_loss = 0.7790884152366526, disc_loss = 0.11521415050807857
Trained batch 239 in epoch 2, gen_loss = 0.7791732804228862, disc_loss = 0.11525679423163335
Trained batch 240 in epoch 2, gen_loss = 0.7789979185058863, disc_loss = 0.11514426418483505
Trained batch 241 in epoch 2, gen_loss = 0.7780662271355795, disc_loss = 0.11526425302890707
Trained batch 242 in epoch 2, gen_loss = 0.7777264656598676, disc_loss = 0.11534517620203426
Trained batch 243 in epoch 2, gen_loss = 0.7778227076422973, disc_loss = 0.11559596978372237
Trained batch 244 in epoch 2, gen_loss = 0.777394267612574, disc_loss = 0.11542943281178572
Trained batch 245 in epoch 2, gen_loss = 0.7771700990151583, disc_loss = 0.11571944211193216
Trained batch 246 in epoch 2, gen_loss = 0.7763537618554073, disc_loss = 0.11599223572112288
Trained batch 247 in epoch 2, gen_loss = 0.7756968858020921, disc_loss = 0.11601086447556172
Trained batch 248 in epoch 2, gen_loss = 0.7754808833082039, disc_loss = 0.1159763804760324
Trained batch 249 in epoch 2, gen_loss = 0.7749204057455062, disc_loss = 0.11579381766915321
Trained batch 250 in epoch 2, gen_loss = 0.7755563029967456, disc_loss = 0.1159529033825692
Trained batch 251 in epoch 2, gen_loss = 0.7745437961485651, disc_loss = 0.11681644674686212
Trained batch 252 in epoch 2, gen_loss = 0.7763821856070884, disc_loss = 0.11675581068036113
Trained batch 253 in epoch 2, gen_loss = 0.7766733072170122, disc_loss = 0.11662300989970448
Trained batch 254 in epoch 2, gen_loss = 0.7756381454421025, disc_loss = 0.11659281294719846
Trained batch 255 in epoch 2, gen_loss = 0.7750130040803924, disc_loss = 0.11641499225515872
Trained batch 256 in epoch 2, gen_loss = 0.7761084037300213, disc_loss = 0.11636109824078557
Trained batch 257 in epoch 2, gen_loss = 0.775519993993663, disc_loss = 0.11629699216794598
Trained batch 258 in epoch 2, gen_loss = 0.774660416896739, disc_loss = 0.11609082597102897
Trained batch 259 in epoch 2, gen_loss = 0.7758495898200916, disc_loss = 0.1162770807169951
Trained batch 260 in epoch 2, gen_loss = 0.775416054602327, disc_loss = 0.11609524545541668
Trained batch 261 in epoch 2, gen_loss = 0.7748381432913641, disc_loss = 0.11596873399751786
Trained batch 262 in epoch 2, gen_loss = 0.774830914155612, disc_loss = 0.1161917423964
Trained batch 263 in epoch 2, gen_loss = 0.775603959844871, disc_loss = 0.1161619991233403
Trained batch 264 in epoch 2, gen_loss = 0.7756323250959505, disc_loss = 0.1159915138809186
Trained batch 265 in epoch 2, gen_loss = 0.7753583258928213, disc_loss = 0.11597271977846783
Trained batch 266 in epoch 2, gen_loss = 0.7750277210040932, disc_loss = 0.1160698811268985
Trained batch 267 in epoch 2, gen_loss = 0.7762056009760544, disc_loss = 0.11606944377408988
Trained batch 268 in epoch 2, gen_loss = 0.7764240214151078, disc_loss = 0.11580561275929767
Trained batch 269 in epoch 2, gen_loss = 0.7757154741772899, disc_loss = 0.11602569054122325
Trained batch 270 in epoch 2, gen_loss = 0.7762204675876786, disc_loss = 0.11579929661981735
Trained batch 271 in epoch 2, gen_loss = 0.7762039968853488, disc_loss = 0.11577542598687988
Trained batch 272 in epoch 2, gen_loss = 0.776382788961187, disc_loss = 0.11573904595805175
Trained batch 273 in epoch 2, gen_loss = 0.776154077509894, disc_loss = 0.11565245768177683
Trained batch 274 in epoch 2, gen_loss = 0.77678403951905, disc_loss = 0.11553458272056145
Trained batch 275 in epoch 2, gen_loss = 0.7766221805975058, disc_loss = 0.11555099885478831
Trained batch 276 in epoch 2, gen_loss = 0.7759892253023623, disc_loss = 0.11563437261252196
Trained batch 277 in epoch 2, gen_loss = 0.7748436809872552, disc_loss = 0.11576272481583434
Trained batch 278 in epoch 2, gen_loss = 0.776184168126848, disc_loss = 0.11715435115186544
Trained batch 279 in epoch 2, gen_loss = 0.775931052012103, disc_loss = 0.11702861302931394
Trained batch 280 in epoch 2, gen_loss = 0.775356644201109, disc_loss = 0.11687048221026876
Trained batch 281 in epoch 2, gen_loss = 0.7745423547342314, disc_loss = 0.11707864248636343
Trained batch 282 in epoch 2, gen_loss = 0.77564440283253, disc_loss = 0.11692720932010627
Trained batch 283 in epoch 2, gen_loss = 0.7763551891269819, disc_loss = 0.11660485333618774
Trained batch 284 in epoch 2, gen_loss = 0.7762010509507697, disc_loss = 0.11637768250677669
Trained batch 285 in epoch 2, gen_loss = 0.7753210365772247, disc_loss = 0.11649915452890254
Trained batch 286 in epoch 2, gen_loss = 0.7747400434175019, disc_loss = 0.11642693592566439
Trained batch 287 in epoch 2, gen_loss = 0.7752231284976006, disc_loss = 0.11708124470250267
Trained batch 288 in epoch 2, gen_loss = 0.7751388421933131, disc_loss = 0.11693400345020846
Trained batch 289 in epoch 2, gen_loss = 0.7747816803126499, disc_loss = 0.11687412572189651
Trained batch 290 in epoch 2, gen_loss = 0.7749858101209005, disc_loss = 0.11669968751569589
Trained batch 291 in epoch 2, gen_loss = 0.7737619976883066, disc_loss = 0.11686880842540158
Trained batch 292 in epoch 2, gen_loss = 0.7740721639512749, disc_loss = 0.11728475048960069
Trained batch 293 in epoch 2, gen_loss = 0.7739714191478937, disc_loss = 0.1169760612086678
Trained batch 294 in epoch 2, gen_loss = 0.7737680433160168, disc_loss = 0.11720910907675654
Trained batch 295 in epoch 2, gen_loss = 0.7742523355661212, disc_loss = 0.11700251398331209
Trained batch 296 in epoch 2, gen_loss = 0.773776787499386, disc_loss = 0.11702516210274864
Trained batch 297 in epoch 2, gen_loss = 0.7742287966629002, disc_loss = 0.11670839478380528
Trained batch 298 in epoch 2, gen_loss = 0.7751694501044359, disc_loss = 0.11718466999414175
Trained batch 299 in epoch 2, gen_loss = 0.7740974859396617, disc_loss = 0.11733127238228917
Trained batch 300 in epoch 2, gen_loss = 0.773785645383537, disc_loss = 0.11744359583033874
Trained batch 301 in epoch 2, gen_loss = 0.7734731335118906, disc_loss = 0.11724519918962623
Trained batch 302 in epoch 2, gen_loss = 0.7744540690195443, disc_loss = 0.11712869162680489
Trained batch 303 in epoch 2, gen_loss = 0.7749135911856827, disc_loss = 0.11697068040283691
Trained batch 304 in epoch 2, gen_loss = 0.774352117249223, disc_loss = 0.11680955070330472
Trained batch 305 in epoch 2, gen_loss = 0.773571710570965, disc_loss = 0.11696816756225684
Trained batch 306 in epoch 2, gen_loss = 0.7748686735327158, disc_loss = 0.11685545390004638
Trained batch 307 in epoch 2, gen_loss = 0.7745697498321533, disc_loss = 0.11713300550404887
Trained batch 308 in epoch 2, gen_loss = 0.774102306481704, disc_loss = 0.11713490591152394
Trained batch 309 in epoch 2, gen_loss = 0.7740856449450216, disc_loss = 0.11703195338167491
Trained batch 310 in epoch 2, gen_loss = 0.7745531419849089, disc_loss = 0.11691083269750766
Trained batch 311 in epoch 2, gen_loss = 0.7740200660549678, disc_loss = 0.11675425028452316
Trained batch 312 in epoch 2, gen_loss = 0.7744828675882504, disc_loss = 0.11730868920993309
Trained batch 313 in epoch 2, gen_loss = 0.7741146019309949, disc_loss = 0.11716850924714925
Trained batch 314 in epoch 2, gen_loss = 0.7738576062141903, disc_loss = 0.11716720156135067
Trained batch 315 in epoch 2, gen_loss = 0.772906467412846, disc_loss = 0.11724730601675715
Trained batch 316 in epoch 2, gen_loss = 0.7741919247321902, disc_loss = 0.1175906485363794
Trained batch 317 in epoch 2, gen_loss = 0.7736197990254037, disc_loss = 0.11752186333116307
Trained batch 318 in epoch 2, gen_loss = 0.7743284839634611, disc_loss = 0.11756320528359061
Trained batch 319 in epoch 2, gen_loss = 0.7741385999135673, disc_loss = 0.1176774391613435
Trained batch 320 in epoch 2, gen_loss = 0.7736946256175591, disc_loss = 0.11774797683633934
Trained batch 321 in epoch 2, gen_loss = 0.7736477486280181, disc_loss = 0.11769577723736904
Trained batch 322 in epoch 2, gen_loss = 0.7725408772012398, disc_loss = 0.11827430647477831
Trained batch 323 in epoch 2, gen_loss = 0.7725042977634772, disc_loss = 0.11810136110993263
Trained batch 324 in epoch 2, gen_loss = 0.7720733023606814, disc_loss = 0.11809609544391815
Trained batch 325 in epoch 2, gen_loss = 0.7717049142882868, disc_loss = 0.11803446756390158
Trained batch 326 in epoch 2, gen_loss = 0.7717388920280912, disc_loss = 0.11837409646891126
Trained batch 327 in epoch 2, gen_loss = 0.770742696232912, disc_loss = 0.1184663541399215
Trained batch 328 in epoch 2, gen_loss = 0.7706456372803105, disc_loss = 0.11827395485549894
Trained batch 329 in epoch 2, gen_loss = 0.7713090799071572, disc_loss = 0.11796919267173066
Trained batch 330 in epoch 2, gen_loss = 0.7714894174449033, disc_loss = 0.11776130555867248
Trained batch 331 in epoch 2, gen_loss = 0.7726546224341335, disc_loss = 0.11792861398152378
Trained batch 332 in epoch 2, gen_loss = 0.7725783287583887, disc_loss = 0.11788904939305496
Trained batch 333 in epoch 2, gen_loss = 0.7721294675044671, disc_loss = 0.11779379924413508
Trained batch 334 in epoch 2, gen_loss = 0.7720070707264232, disc_loss = 0.11753769495260359
Trained batch 335 in epoch 2, gen_loss = 0.7729514776950791, disc_loss = 0.11769633762915396
Trained batch 336 in epoch 2, gen_loss = 0.7725193343105938, disc_loss = 0.11777009777945828
Trained batch 337 in epoch 2, gen_loss = 0.7718795636701866, disc_loss = 0.11788473384642213
Trained batch 338 in epoch 2, gen_loss = 0.7720396114309981, disc_loss = 0.11798436425977928
Trained batch 339 in epoch 2, gen_loss = 0.7723483723752639, disc_loss = 0.11771424985764657
Trained batch 340 in epoch 2, gen_loss = 0.7714736210810474, disc_loss = 0.11789048376801776
Trained batch 341 in epoch 2, gen_loss = 0.7709833713825683, disc_loss = 0.11796504828795704
Trained batch 342 in epoch 2, gen_loss = 0.7705017532447337, disc_loss = 0.11799621454958666
Trained batch 343 in epoch 2, gen_loss = 0.7709484123733155, disc_loss = 0.11785464498842525
Trained batch 344 in epoch 2, gen_loss = 0.7723608859207319, disc_loss = 0.11806662327785424
Trained batch 345 in epoch 2, gen_loss = 0.7720352692927929, disc_loss = 0.11791440231908608
Trained batch 346 in epoch 2, gen_loss = 0.7715464317661197, disc_loss = 0.11797607871529349
Trained batch 347 in epoch 2, gen_loss = 0.7719555602505289, disc_loss = 0.11774168635622181
Trained batch 348 in epoch 2, gen_loss = 0.772748990096472, disc_loss = 0.1175308925310486
Trained batch 349 in epoch 2, gen_loss = 0.7740202647447586, disc_loss = 0.11810668673898493
Trained batch 350 in epoch 2, gen_loss = 0.7732859295487744, disc_loss = 0.11822201868789828
Trained batch 351 in epoch 2, gen_loss = 0.7725979874587872, disc_loss = 0.1183712584157051
Trained batch 352 in epoch 2, gen_loss = 0.773038814408921, disc_loss = 0.11826510152254496
Trained batch 353 in epoch 2, gen_loss = 0.7732966325882464, disc_loss = 0.11823126215929702
Trained batch 354 in epoch 2, gen_loss = 0.7729453465468447, disc_loss = 0.11825402472430552
Trained batch 355 in epoch 2, gen_loss = 0.7734066809663612, disc_loss = 0.11846744734793901
Trained batch 356 in epoch 2, gen_loss = 0.7733141296551007, disc_loss = 0.11844226796211314
Trained batch 357 in epoch 2, gen_loss = 0.7732023552642854, disc_loss = 0.11832095548385681
Trained batch 358 in epoch 2, gen_loss = 0.7734269718107739, disc_loss = 0.11820808699494617
Trained batch 359 in epoch 2, gen_loss = 0.773281646023194, disc_loss = 0.11833761412029466
Trained batch 360 in epoch 2, gen_loss = 0.7729466761413374, disc_loss = 0.11827096375030494
Trained batch 361 in epoch 2, gen_loss = 0.7726166947276553, disc_loss = 0.11820121688860885
Trained batch 362 in epoch 2, gen_loss = 0.7723804330530245, disc_loss = 0.11855893139791554
Trained batch 363 in epoch 2, gen_loss = 0.7730105901648711, disc_loss = 0.11867263895756268
Trained batch 364 in epoch 2, gen_loss = 0.7720803104034842, disc_loss = 0.11914376819582835
Trained batch 365 in epoch 2, gen_loss = 0.7718908075100738, disc_loss = 0.11892746909027868
Trained batch 366 in epoch 2, gen_loss = 0.7723259547425876, disc_loss = 0.1190828789705639
Trained batch 367 in epoch 2, gen_loss = 0.771821971334841, disc_loss = 0.11901787234186802
Trained batch 368 in epoch 2, gen_loss = 0.7714979417601898, disc_loss = 0.11876195361257245
Trained batch 369 in epoch 2, gen_loss = 0.771583969367517, disc_loss = 0.11879256153227509
Trained batch 370 in epoch 2, gen_loss = 0.7711558615100994, disc_loss = 0.11890956806646524
Trained batch 371 in epoch 2, gen_loss = 0.7722001399404259, disc_loss = 0.11915070153973116
Trained batch 372 in epoch 2, gen_loss = 0.7715553946533408, disc_loss = 0.1192839208281232
Trained batch 373 in epoch 2, gen_loss = 0.7717500635009399, disc_loss = 0.11922823274159496
Trained batch 374 in epoch 2, gen_loss = 0.7708205180168152, disc_loss = 0.11934259008367856
Trained batch 375 in epoch 2, gen_loss = 0.7707109408492737, disc_loss = 0.11939519825094241
Trained batch 376 in epoch 2, gen_loss = 0.7711362712263112, disc_loss = 0.11950738853540281
Trained batch 377 in epoch 2, gen_loss = 0.7702188452400228, disc_loss = 0.119931331811049
Trained batch 378 in epoch 2, gen_loss = 0.7707272324524328, disc_loss = 0.11995048788535878
Trained batch 379 in epoch 2, gen_loss = 0.7707919029813064, disc_loss = 0.11980130994986547
Trained batch 380 in epoch 2, gen_loss = 0.7708399866822511, disc_loss = 0.11960000465587368
Trained batch 381 in epoch 2, gen_loss = 0.7700933696243776, disc_loss = 0.11969170014310569
Trained batch 382 in epoch 2, gen_loss = 0.7717894163984542, disc_loss = 0.11966866049575121
Trained batch 383 in epoch 2, gen_loss = 0.7720636954375854, disc_loss = 0.11944752992712893
Trained batch 384 in epoch 2, gen_loss = 0.7716721499895121, disc_loss = 0.11962958468825786
Trained batch 385 in epoch 2, gen_loss = 0.7714419401217001, disc_loss = 0.11968419796405988
Trained batch 386 in epoch 2, gen_loss = 0.7712711318364747, disc_loss = 0.11960815269625157
Trained batch 387 in epoch 2, gen_loss = 0.7718417448634954, disc_loss = 0.11973146183089804
Trained batch 388 in epoch 2, gen_loss = 0.7718376567094063, disc_loss = 0.11966706941665597
Trained batch 389 in epoch 2, gen_loss = 0.7714416351837989, disc_loss = 0.11988940971593062
Trained batch 390 in epoch 2, gen_loss = 0.7710523686902907, disc_loss = 0.119990269727338
Trained batch 391 in epoch 2, gen_loss = 0.771671402439171, disc_loss = 0.11993236987072291
Trained batch 392 in epoch 2, gen_loss = 0.7718657833777615, disc_loss = 0.11978789563966162
Trained batch 393 in epoch 2, gen_loss = 0.7715344491797655, disc_loss = 0.1197088724900472
Trained batch 394 in epoch 2, gen_loss = 0.771204489620426, disc_loss = 0.11992601547626
Trained batch 395 in epoch 2, gen_loss = 0.7713448765753496, disc_loss = 0.11988062064417383
Trained batch 396 in epoch 2, gen_loss = 0.7712645596010559, disc_loss = 0.11986247116995398
Trained batch 397 in epoch 2, gen_loss = 0.7708868982654121, disc_loss = 0.119692820072848
Trained batch 398 in epoch 2, gen_loss = 0.7709313797622097, disc_loss = 0.11946036316977258
Trained batch 399 in epoch 2, gen_loss = 0.7705752081423998, disc_loss = 0.11966770156752318
Trained batch 400 in epoch 2, gen_loss = 0.7707307030286575, disc_loss = 0.11951346564898616
Trained batch 401 in epoch 2, gen_loss = 0.770088576781216, disc_loss = 0.11949097383211353
Trained batch 402 in epoch 2, gen_loss = 0.7701063704106116, disc_loss = 0.11934138315431682
Trained batch 403 in epoch 2, gen_loss = 0.7712322686715881, disc_loss = 0.11949075225943534
Trained batch 404 in epoch 2, gen_loss = 0.7711687915854983, disc_loss = 0.11936681274738577
Trained batch 405 in epoch 2, gen_loss = 0.7707135998116338, disc_loss = 0.11949804047663957
Trained batch 406 in epoch 2, gen_loss = 0.7705296003408455, disc_loss = 0.11931860502305869
Trained batch 407 in epoch 2, gen_loss = 0.7715449409888071, disc_loss = 0.11964027485444996
Trained batch 408 in epoch 2, gen_loss = 0.7711773852118653, disc_loss = 0.11961877151576843
Trained batch 409 in epoch 2, gen_loss = 0.7704970412138031, disc_loss = 0.11989322078028103
Trained batch 410 in epoch 2, gen_loss = 0.7705033879790573, disc_loss = 0.11996311702087993
Trained batch 411 in epoch 2, gen_loss = 0.7705276896363323, disc_loss = 0.12017049060374932
Trained batch 412 in epoch 2, gen_loss = 0.7698657111451932, disc_loss = 0.1202480690756736
Trained batch 413 in epoch 2, gen_loss = 0.769563519148435, disc_loss = 0.12022085158955216
Trained batch 414 in epoch 2, gen_loss = 0.7701411189803158, disc_loss = 0.120191348662757
Trained batch 415 in epoch 2, gen_loss = 0.7697927248305999, disc_loss = 0.12001680463212185
Trained batch 416 in epoch 2, gen_loss = 0.7691595441431737, disc_loss = 0.12013962406138007
Trained batch 417 in epoch 2, gen_loss = 0.7698156219064904, disc_loss = 0.11990249140909984
Trained batch 418 in epoch 2, gen_loss = 0.7696700911248783, disc_loss = 0.11979535172264445
Trained batch 419 in epoch 2, gen_loss = 0.770240169053986, disc_loss = 0.11986309587955475
Trained batch 420 in epoch 2, gen_loss = 0.7702961156317287, disc_loss = 0.11969165227900208
Trained batch 421 in epoch 2, gen_loss = 0.7692508390305731, disc_loss = 0.11996132580307423
Trained batch 422 in epoch 2, gen_loss = 0.7691610519626744, disc_loss = 0.1204288930194034
Trained batch 423 in epoch 2, gen_loss = 0.7692287573415153, disc_loss = 0.12039346766289112
Trained batch 424 in epoch 2, gen_loss = 0.7688491987480837, disc_loss = 0.12031238948597628
Trained batch 425 in epoch 2, gen_loss = 0.7693233188469085, disc_loss = 0.12023987425185145
Trained batch 426 in epoch 2, gen_loss = 0.7691557826845093, disc_loss = 0.12012323391660873
Trained batch 427 in epoch 2, gen_loss = 0.7693780334057095, disc_loss = 0.12013380628113991
Trained batch 428 in epoch 2, gen_loss = 0.7696467149646687, disc_loss = 0.12010678588163047
Trained batch 429 in epoch 2, gen_loss = 0.7698301515606947, disc_loss = 0.12001422229547833
Trained batch 430 in epoch 2, gen_loss = 0.7698024874358609, disc_loss = 0.12014549336203843
Trained batch 431 in epoch 2, gen_loss = 0.7696326192192458, disc_loss = 0.11999036649380017
Trained batch 432 in epoch 2, gen_loss = 0.7697493799426539, disc_loss = 0.11983337931283351
Trained batch 433 in epoch 2, gen_loss = 0.7704510200545535, disc_loss = 0.11980583856938072
Trained batch 434 in epoch 2, gen_loss = 0.7706550464547913, disc_loss = 0.1196930436224773
Trained batch 435 in epoch 2, gen_loss = 0.7699617262280315, disc_loss = 0.11983434541509785
Trained batch 436 in epoch 2, gen_loss = 0.7696204881100688, disc_loss = 0.12006729363849561
Trained batch 437 in epoch 2, gen_loss = 0.7695042060934789, disc_loss = 0.11995851954436737
Trained batch 438 in epoch 2, gen_loss = 0.7692924439228206, disc_loss = 0.11981775627762146
Trained batch 439 in epoch 2, gen_loss = 0.7700831497257407, disc_loss = 0.12022476552731612
Trained batch 440 in epoch 2, gen_loss = 0.7695834852940912, disc_loss = 0.12009449162079093
Trained batch 441 in epoch 2, gen_loss = 0.7692125596072339, disc_loss = 0.11993889902545586
Trained batch 442 in epoch 2, gen_loss = 0.7690592856224181, disc_loss = 0.11988792500330417
Trained batch 443 in epoch 2, gen_loss = 0.7693468125553818, disc_loss = 0.11994456550995777
Trained batch 444 in epoch 2, gen_loss = 0.7687023677183001, disc_loss = 0.11987418472934305
Trained batch 445 in epoch 2, gen_loss = 0.7681581225630414, disc_loss = 0.11990403254503894
Trained batch 446 in epoch 2, gen_loss = 0.767797303413118, disc_loss = 0.11991677982461799
Trained batch 447 in epoch 2, gen_loss = 0.7683070953935385, disc_loss = 0.1198119593235398
Trained batch 448 in epoch 2, gen_loss = 0.7687284284020319, disc_loss = 0.11966572009972846
Trained batch 449 in epoch 2, gen_loss = 0.7681174733241399, disc_loss = 0.11969870174924532
Trained batch 450 in epoch 2, gen_loss = 0.7686622615267591, disc_loss = 0.11951962359530434
Trained batch 451 in epoch 2, gen_loss = 0.7691451724519772, disc_loss = 0.11946877823994223
Trained batch 452 in epoch 2, gen_loss = 0.7688069188963236, disc_loss = 0.11931332615234994
Trained batch 453 in epoch 2, gen_loss = 0.7689518905552474, disc_loss = 0.11919521757028176
Trained batch 454 in epoch 2, gen_loss = 0.7684683979867579, disc_loss = 0.11918264625819175
Trained batch 455 in epoch 2, gen_loss = 0.7688351570906347, disc_loss = 0.11918376428647
Trained batch 456 in epoch 2, gen_loss = 0.7687384794655723, disc_loss = 0.1191230090559181
Trained batch 457 in epoch 2, gen_loss = 0.7682869303564838, disc_loss = 0.11912239033842711
Trained batch 458 in epoch 2, gen_loss = 0.7685583148776576, disc_loss = 0.11900964291656718
Trained batch 459 in epoch 2, gen_loss = 0.7683805304376975, disc_loss = 0.11893593124721362
Trained batch 460 in epoch 2, gen_loss = 0.768377022926823, disc_loss = 0.11892519626208861
Trained batch 461 in epoch 2, gen_loss = 0.7693518753046598, disc_loss = 0.1191737259943764
Trained batch 462 in epoch 2, gen_loss = 0.7688130755017695, disc_loss = 0.11945641031146823
Trained batch 463 in epoch 2, gen_loss = 0.7686367715098734, disc_loss = 0.11927931639365852
Trained batch 464 in epoch 2, gen_loss = 0.7689592113417963, disc_loss = 0.11908327703995089
Trained batch 465 in epoch 2, gen_loss = 0.769203174843297, disc_loss = 0.11903394693948424
Trained batch 466 in epoch 2, gen_loss = 0.7691856784151759, disc_loss = 0.11896660904015158
Trained batch 467 in epoch 2, gen_loss = 0.7688366017407842, disc_loss = 0.1189745397060218
Trained batch 468 in epoch 2, gen_loss = 0.7691903134017611, disc_loss = 0.1188959425239802
Trained batch 469 in epoch 2, gen_loss = 0.7690244695607652, disc_loss = 0.11876856008584195
Trained batch 470 in epoch 2, gen_loss = 0.7689995449945932, disc_loss = 0.11875053089420506
Trained batch 471 in epoch 2, gen_loss = 0.7688761053575297, disc_loss = 0.11857871284266397
Trained batch 472 in epoch 2, gen_loss = 0.7692245918524946, disc_loss = 0.11853515387495023
Trained batch 473 in epoch 2, gen_loss = 0.7688228885961484, disc_loss = 0.11858619920092041
Trained batch 474 in epoch 2, gen_loss = 0.7685806652746703, disc_loss = 0.11857327120084511
Trained batch 475 in epoch 2, gen_loss = 0.7689663879886395, disc_loss = 0.11871616148679447
Trained batch 476 in epoch 2, gen_loss = 0.7685609195592269, disc_loss = 0.11863821586379215
Trained batch 477 in epoch 2, gen_loss = 0.7693286981418043, disc_loss = 0.1185620577156419
Trained batch 478 in epoch 2, gen_loss = 0.7704968645950947, disc_loss = 0.11846466437915422
Trained batch 479 in epoch 2, gen_loss = 0.7703976914907495, disc_loss = 0.11840102173543225
Trained batch 480 in epoch 2, gen_loss = 0.7700060844545304, disc_loss = 0.11879697105152195
Trained batch 481 in epoch 2, gen_loss = 0.7703788610043862, disc_loss = 0.11870839396545749
Trained batch 482 in epoch 2, gen_loss = 0.7705676773443478, disc_loss = 0.11922041966153721
Trained batch 483 in epoch 2, gen_loss = 0.7705973446492321, disc_loss = 0.11904504260217602
Trained batch 484 in epoch 2, gen_loss = 0.7704576929205472, disc_loss = 0.11890655440307155
Trained batch 485 in epoch 2, gen_loss = 0.7701450685046828, disc_loss = 0.11885456356829331
Trained batch 486 in epoch 2, gen_loss = 0.7712932039947236, disc_loss = 0.119187747635085
Trained batch 487 in epoch 2, gen_loss = 0.771444883563968, disc_loss = 0.11907560588242333
Trained batch 488 in epoch 2, gen_loss = 0.7717696822615977, disc_loss = 0.1188879148855592
Trained batch 489 in epoch 2, gen_loss = 0.7715746571214832, disc_loss = 0.11869825414020796
Trained batch 490 in epoch 2, gen_loss = 0.7717745316854077, disc_loss = 0.11849981700800466
Trained batch 491 in epoch 2, gen_loss = 0.771953127066779, disc_loss = 0.11834597104130601
Trained batch 492 in epoch 2, gen_loss = 0.7715227921279884, disc_loss = 0.11837480428418934
Trained batch 493 in epoch 2, gen_loss = 0.7719707996377095, disc_loss = 0.11824771743418597
Trained batch 494 in epoch 2, gen_loss = 0.7715902628922703, disc_loss = 0.11812255601916048
Trained batch 495 in epoch 2, gen_loss = 0.7717737145121059, disc_loss = 0.11793118881271972
Trained batch 496 in epoch 2, gen_loss = 0.7719909624914288, disc_loss = 0.1178490079609561
Trained batch 497 in epoch 2, gen_loss = 0.772384234760181, disc_loss = 0.11767809530607908
Trained batch 498 in epoch 2, gen_loss = 0.7723352548951854, disc_loss = 0.11760052898992039
Trained batch 499 in epoch 2, gen_loss = 0.7725657281279564, disc_loss = 0.1174946112409234
Trained batch 500 in epoch 2, gen_loss = 0.7728438560001388, disc_loss = 0.11732081916116312
Trained batch 501 in epoch 2, gen_loss = 0.7728103591032712, disc_loss = 0.1171228636753749
Trained batch 502 in epoch 2, gen_loss = 0.7730884153255174, disc_loss = 0.11696768526884006
Trained batch 503 in epoch 2, gen_loss = 0.7736424072276032, disc_loss = 0.11680964272587545
Trained batch 504 in epoch 2, gen_loss = 0.7738948405969261, disc_loss = 0.11665125202276919
Trained batch 505 in epoch 2, gen_loss = 0.774583084015507, disc_loss = 0.1164576882430216
Trained batch 506 in epoch 2, gen_loss = 0.7748031345227296, disc_loss = 0.11628314785115583
Trained batch 507 in epoch 2, gen_loss = 0.7743657010160093, disc_loss = 0.11623012057439548
Trained batch 508 in epoch 2, gen_loss = 0.7743155655903058, disc_loss = 0.11606198393379306
Trained batch 509 in epoch 2, gen_loss = 0.7745523098052717, disc_loss = 0.11607586619462452
Trained batch 510 in epoch 2, gen_loss = 0.7748069745103907, disc_loss = 0.11596127963258562
Trained batch 511 in epoch 2, gen_loss = 0.7744294491712935, disc_loss = 0.11591696594405221
Trained batch 512 in epoch 2, gen_loss = 0.7748691834088189, disc_loss = 0.11572718704536877
Trained batch 513 in epoch 2, gen_loss = 0.7748841335453412, disc_loss = 0.11586087631924143
Trained batch 514 in epoch 2, gen_loss = 0.7747097226601203, disc_loss = 0.11584340021448228
Trained batch 515 in epoch 2, gen_loss = 0.7744271828569183, disc_loss = 0.11578585656518622
Trained batch 516 in epoch 2, gen_loss = 0.774457681513386, disc_loss = 0.11565644234937672
Trained batch 517 in epoch 2, gen_loss = 0.7749869558226647, disc_loss = 0.11548338904904928
Trained batch 518 in epoch 2, gen_loss = 0.7754040248476701, disc_loss = 0.11552445127885351
Trained batch 519 in epoch 2, gen_loss = 0.7751496818776314, disc_loss = 0.11557611831320592
Trained batch 520 in epoch 2, gen_loss = 0.7748601382272944, disc_loss = 0.11558585324737596
Trained batch 521 in epoch 2, gen_loss = 0.775420324384481, disc_loss = 0.11572227305536412
Trained batch 522 in epoch 2, gen_loss = 0.7757729782543037, disc_loss = 0.11573468032960796
Trained batch 523 in epoch 2, gen_loss = 0.7752792628780576, disc_loss = 0.11569261031566572
Trained batch 524 in epoch 2, gen_loss = 0.775008278858094, disc_loss = 0.11573140241915271
Trained batch 525 in epoch 2, gen_loss = 0.775169654094221, disc_loss = 0.11587442127286594
Trained batch 526 in epoch 2, gen_loss = 0.7749539555476331, disc_loss = 0.1159218394602216
Trained batch 527 in epoch 2, gen_loss = 0.7760523406958039, disc_loss = 0.11605196692769161
Trained batch 528 in epoch 2, gen_loss = 0.7758031260426419, disc_loss = 0.11602295470020835
Trained batch 529 in epoch 2, gen_loss = 0.7758443478705748, disc_loss = 0.11589510345585503
Trained batch 530 in epoch 2, gen_loss = 0.7754548888534252, disc_loss = 0.11602100087662987
Trained batch 531 in epoch 2, gen_loss = 0.7751034360967184, disc_loss = 0.11609252326932729
Trained batch 532 in epoch 2, gen_loss = 0.7750113949207607, disc_loss = 0.11619732709598027
Trained batch 533 in epoch 2, gen_loss = 0.7746362623092387, disc_loss = 0.11618634031855324
Trained batch 534 in epoch 2, gen_loss = 0.7744561770809031, disc_loss = 0.11611290847377799
Trained batch 535 in epoch 2, gen_loss = 0.7747059873124557, disc_loss = 0.11608617259675998
Trained batch 536 in epoch 2, gen_loss = 0.7749819891523827, disc_loss = 0.1159087524921035
Trained batch 537 in epoch 2, gen_loss = 0.77487951134882, disc_loss = 0.11604447598780288
Trained batch 538 in epoch 2, gen_loss = 0.7743706441655451, disc_loss = 0.1161253980027446
Trained batch 539 in epoch 2, gen_loss = 0.7747125585322027, disc_loss = 0.11619822804781574
Trained batch 540 in epoch 2, gen_loss = 0.7748042282798153, disc_loss = 0.1161478998005225
Trained batch 541 in epoch 2, gen_loss = 0.7748159877818449, disc_loss = 0.11605499841176606
Trained batch 542 in epoch 2, gen_loss = 0.7752441527325366, disc_loss = 0.11592631537679919
Trained batch 543 in epoch 2, gen_loss = 0.775318607523599, disc_loss = 0.11581959211445578
Trained batch 544 in epoch 2, gen_loss = 0.7754586992460654, disc_loss = 0.11569144746647515
Trained batch 545 in epoch 2, gen_loss = 0.7753814376426704, disc_loss = 0.11570887984332694
Trained batch 546 in epoch 2, gen_loss = 0.7753298995808666, disc_loss = 0.11564522764051309
Trained batch 547 in epoch 2, gen_loss = 0.775594129451435, disc_loss = 0.11569098938242907
Trained batch 548 in epoch 2, gen_loss = 0.7750590037561288, disc_loss = 0.1158740343271546
Trained batch 549 in epoch 2, gen_loss = 0.7756018004634163, disc_loss = 0.11633415051820603
Trained batch 550 in epoch 2, gen_loss = 0.7753164114839585, disc_loss = 0.11641913817725576
Trained batch 551 in epoch 2, gen_loss = 0.7751354872100595, disc_loss = 0.11654641422902004
Trained batch 552 in epoch 2, gen_loss = 0.7758281268650973, disc_loss = 0.1169757836853671
Trained batch 553 in epoch 2, gen_loss = 0.77580900065305, disc_loss = 0.11694105085496545
Trained batch 554 in epoch 2, gen_loss = 0.7755930888760197, disc_loss = 0.11692560487300963
Trained batch 555 in epoch 2, gen_loss = 0.7755320219041633, disc_loss = 0.11682954067766345
Trained batch 556 in epoch 2, gen_loss = 0.7754997591784013, disc_loss = 0.11671166548997003
Trained batch 557 in epoch 2, gen_loss = 0.7755348157925418, disc_loss = 0.11670957412570715
Trained batch 558 in epoch 2, gen_loss = 0.7757287395448292, disc_loss = 0.11687815368295462
Trained batch 559 in epoch 2, gen_loss = 0.7752918266824314, disc_loss = 0.11699193732347339
Trained batch 560 in epoch 2, gen_loss = 0.7748692331042094, disc_loss = 0.11701386269520629
Trained batch 561 in epoch 2, gen_loss = 0.7753368567317406, disc_loss = 0.11703186477219613
Trained batch 562 in epoch 2, gen_loss = 0.7754986628122482, disc_loss = 0.11705989050836059
Trained batch 563 in epoch 2, gen_loss = 0.7754624980561277, disc_loss = 0.11714284711497579
Trained batch 564 in epoch 2, gen_loss = 0.7757392357935947, disc_loss = 0.1171447437322509
Trained batch 565 in epoch 2, gen_loss = 0.7757310477667899, disc_loss = 0.117179332442529
Trained batch 566 in epoch 2, gen_loss = 0.7756928739514091, disc_loss = 0.11713228197653353
Trained batch 567 in epoch 2, gen_loss = 0.7761618732146813, disc_loss = 0.11717551013021926
Trained batch 568 in epoch 2, gen_loss = 0.7759360003764684, disc_loss = 0.11709244825888707
Trained batch 569 in epoch 2, gen_loss = 0.7755809210894401, disc_loss = 0.11702007094822954
Trained batch 570 in epoch 2, gen_loss = 0.775477992256552, disc_loss = 0.11694677855538925
Trained batch 571 in epoch 2, gen_loss = 0.7755834952101007, disc_loss = 0.11682791441639924
Trained batch 572 in epoch 2, gen_loss = 0.7755517639206758, disc_loss = 0.11667816451771826
Trained batch 573 in epoch 2, gen_loss = 0.77580190317556, disc_loss = 0.1165894294118684
Trained batch 574 in epoch 2, gen_loss = 0.7759965053848599, disc_loss = 0.11647070566273254
Trained batch 575 in epoch 2, gen_loss = 0.7761457565551003, disc_loss = 0.11653888124985518
Trained batch 576 in epoch 2, gen_loss = 0.7755596543721971, disc_loss = 0.11661553793817604
Trained batch 577 in epoch 2, gen_loss = 0.7755702980455643, disc_loss = 0.11661104677779967
Trained batch 578 in epoch 2, gen_loss = 0.7753455372260231, disc_loss = 0.11654175226359478
Trained batch 579 in epoch 2, gen_loss = 0.7758134682630671, disc_loss = 0.1165273556196741
Trained batch 580 in epoch 2, gen_loss = 0.77564892957625, disc_loss = 0.11649066743580384
Trained batch 581 in epoch 2, gen_loss = 0.7753563168941904, disc_loss = 0.11639602213163454
Trained batch 582 in epoch 2, gen_loss = 0.7756774374387686, disc_loss = 0.11632068839569545
Trained batch 583 in epoch 2, gen_loss = 0.7760344292611292, disc_loss = 0.11629091737447433
Trained batch 584 in epoch 2, gen_loss = 0.7761313657475333, disc_loss = 0.11614806114926807
Trained batch 585 in epoch 2, gen_loss = 0.7758161931111137, disc_loss = 0.1160714386552318
Trained batch 586 in epoch 2, gen_loss = 0.7758213172982458, disc_loss = 0.1159694897616996
Trained batch 587 in epoch 2, gen_loss = 0.7760753721809711, disc_loss = 0.11594099148816499
Trained batch 588 in epoch 2, gen_loss = 0.7762416116450558, disc_loss = 0.1158010049142791
Trained batch 589 in epoch 2, gen_loss = 0.7760834161507881, disc_loss = 0.11587429989003024
Trained batch 590 in epoch 2, gen_loss = 0.7764038758229483, disc_loss = 0.11579812714253283
Trained batch 591 in epoch 2, gen_loss = 0.7766138044362133, disc_loss = 0.11567752073657371
Trained batch 592 in epoch 2, gen_loss = 0.7774036096481207, disc_loss = 0.1157063856174381
Trained batch 593 in epoch 2, gen_loss = 0.7772731921488187, disc_loss = 0.11566192466414436
Trained batch 594 in epoch 2, gen_loss = 0.7767910505042357, disc_loss = 0.11578743896376686
Trained batch 595 in epoch 2, gen_loss = 0.7772224147947843, disc_loss = 0.11569735946933796
Trained batch 596 in epoch 2, gen_loss = 0.7779198659824167, disc_loss = 0.1156014717859489
Trained batch 597 in epoch 2, gen_loss = 0.7778648540228107, disc_loss = 0.11545690654599447
Trained batch 598 in epoch 2, gen_loss = 0.777813488483827, disc_loss = 0.11529369433667007
Trained batch 599 in epoch 2, gen_loss = 0.7778308023512364, disc_loss = 0.11523984387827416
Trained batch 600 in epoch 2, gen_loss = 0.7778784349535943, disc_loss = 0.11531837421241596
Trained batch 601 in epoch 2, gen_loss = 0.7782141482612224, disc_loss = 0.1152158139298277
Trained batch 602 in epoch 2, gen_loss = 0.7783643365598238, disc_loss = 0.11515167040154214
Trained batch 603 in epoch 2, gen_loss = 0.7783677847870928, disc_loss = 0.11504069373739377
Trained batch 604 in epoch 2, gen_loss = 0.7780853472957926, disc_loss = 0.11495550969107585
Trained batch 605 in epoch 2, gen_loss = 0.7786412933970442, disc_loss = 0.11509933083843772
Trained batch 606 in epoch 2, gen_loss = 0.7782358918492445, disc_loss = 0.11527251129083127
Trained batch 607 in epoch 2, gen_loss = 0.7784124797602233, disc_loss = 0.11523534134214156
Trained batch 608 in epoch 2, gen_loss = 0.7782439816076375, disc_loss = 0.11517224755376725
Trained batch 609 in epoch 2, gen_loss = 0.7784531154104921, disc_loss = 0.11512488358516673
Trained batch 610 in epoch 2, gen_loss = 0.7787518803207066, disc_loss = 0.11503398896739155
Trained batch 611 in epoch 2, gen_loss = 0.7788213518222952, disc_loss = 0.11518065850828695
Trained batch 612 in epoch 2, gen_loss = 0.7782800212672639, disc_loss = 0.1152763295748543
Trained batch 613 in epoch 2, gen_loss = 0.778121258371816, disc_loss = 0.11522297248402034
Trained batch 614 in epoch 2, gen_loss = 0.778499598183283, disc_loss = 0.11550889710888146
Trained batch 615 in epoch 2, gen_loss = 0.7785477155892105, disc_loss = 0.11540223001623405
Trained batch 616 in epoch 2, gen_loss = 0.7788114303804488, disc_loss = 0.11527432597014371
Trained batch 617 in epoch 2, gen_loss = 0.7786162572288976, disc_loss = 0.11523629033268945
Trained batch 618 in epoch 2, gen_loss = 0.7785833957988727, disc_loss = 0.11512684904833313
Trained batch 619 in epoch 2, gen_loss = 0.7787189005363372, disc_loss = 0.11528157027918966
Trained batch 620 in epoch 2, gen_loss = 0.7785849721439411, disc_loss = 0.11520941748363288
Trained batch 621 in epoch 2, gen_loss = 0.7785700787206171, disc_loss = 0.11515863435911883
Trained batch 622 in epoch 2, gen_loss = 0.7783223750790279, disc_loss = 0.115126892801727
Trained batch 623 in epoch 2, gen_loss = 0.7783125155151654, disc_loss = 0.11510315980129422
Trained batch 624 in epoch 2, gen_loss = 0.7779067058086395, disc_loss = 0.11506329942643642
Trained batch 625 in epoch 2, gen_loss = 0.7777471545690926, disc_loss = 0.11514058605300638
Trained batch 626 in epoch 2, gen_loss = 0.7774961336472769, disc_loss = 0.1152697066365009
Trained batch 627 in epoch 2, gen_loss = 0.7775188007267417, disc_loss = 0.11527535845792503
Trained batch 628 in epoch 2, gen_loss = 0.7776494668189596, disc_loss = 0.11526729538148367
Trained batch 629 in epoch 2, gen_loss = 0.7776103585012375, disc_loss = 0.11539969318620269
Trained batch 630 in epoch 2, gen_loss = 0.777152297188854, disc_loss = 0.11543800940120183
Trained batch 631 in epoch 2, gen_loss = 0.776964835303871, disc_loss = 0.11534084299803252
Trained batch 632 in epoch 2, gen_loss = 0.777025747591097, disc_loss = 0.11538075708959246
Trained batch 633 in epoch 2, gen_loss = 0.7768887616576456, disc_loss = 0.11531839743315328
Trained batch 634 in epoch 2, gen_loss = 0.7765819352912152, disc_loss = 0.11529517628135175
Trained batch 635 in epoch 2, gen_loss = 0.7765617185512429, disc_loss = 0.11520334804992911
Trained batch 636 in epoch 2, gen_loss = 0.7770897150507527, disc_loss = 0.11531836111127769
Trained batch 637 in epoch 2, gen_loss = 0.7772309383535086, disc_loss = 0.11530679587835335
Trained batch 638 in epoch 2, gen_loss = 0.7768827330245285, disc_loss = 0.11571677229389059
Trained batch 639 in epoch 2, gen_loss = 0.7772714065853507, disc_loss = 0.1156242956087226
Trained batch 640 in epoch 2, gen_loss = 0.7773940091293056, disc_loss = 0.11557195431228826
Trained batch 641 in epoch 2, gen_loss = 0.7773867474630985, disc_loss = 0.11579841318775282
Trained batch 642 in epoch 2, gen_loss = 0.7776038975311476, disc_loss = 0.11565505663399378
Trained batch 643 in epoch 2, gen_loss = 0.7773070783811327, disc_loss = 0.11573870181574585
Trained batch 644 in epoch 2, gen_loss = 0.7769614717295004, disc_loss = 0.11584443588589513
Trained batch 645 in epoch 2, gen_loss = 0.7772565144964785, disc_loss = 0.11582970208612389
Trained batch 646 in epoch 2, gen_loss = 0.7776860955417433, disc_loss = 0.11574258160715493
Trained batch 647 in epoch 2, gen_loss = 0.7775723634770623, disc_loss = 0.11565323711522384
Trained batch 648 in epoch 2, gen_loss = 0.7771000275718413, disc_loss = 0.1157563578951616
Trained batch 649 in epoch 2, gen_loss = 0.7780445056236708, disc_loss = 0.11578570954501628
Trained batch 650 in epoch 2, gen_loss = 0.7780028291836313, disc_loss = 0.11590720930018
Trained batch 651 in epoch 2, gen_loss = 0.7775316801539228, disc_loss = 0.11611372506120271
Trained batch 652 in epoch 2, gen_loss = 0.7773411634505069, disc_loss = 0.1161584756857677
Trained batch 653 in epoch 2, gen_loss = 0.7777729051740162, disc_loss = 0.11651542969048023
Trained batch 654 in epoch 2, gen_loss = 0.7780265859065165, disc_loss = 0.11647812306084705
Trained batch 655 in epoch 2, gen_loss = 0.7776120365029429, disc_loss = 0.11656014458276331
Trained batch 656 in epoch 2, gen_loss = 0.7773778678075364, disc_loss = 0.11657905284332358
Trained batch 657 in epoch 2, gen_loss = 0.777979450385259, disc_loss = 0.1167433508770897
Trained batch 658 in epoch 2, gen_loss = 0.7779119640633984, disc_loss = 0.116732384014609
Trained batch 659 in epoch 2, gen_loss = 0.7776330923492258, disc_loss = 0.11669975061421141
Trained batch 660 in epoch 2, gen_loss = 0.7776166261054023, disc_loss = 0.11667476605156185
Trained batch 661 in epoch 2, gen_loss = 0.7776759377599123, disc_loss = 0.11669489033970408
Trained batch 662 in epoch 2, gen_loss = 0.7778658091033026, disc_loss = 0.11654363202877893
Trained batch 663 in epoch 2, gen_loss = 0.7778694672756884, disc_loss = 0.11646923008767596
Trained batch 664 in epoch 2, gen_loss = 0.7778076846796768, disc_loss = 0.11643719014368559
Trained batch 665 in epoch 2, gen_loss = 0.7778158953060975, disc_loss = 0.11651137057277891
Trained batch 666 in epoch 2, gen_loss = 0.7780908672348491, disc_loss = 0.11649896311706331
Trained batch 667 in epoch 2, gen_loss = 0.7780580259190348, disc_loss = 0.11643032721818207
Trained batch 668 in epoch 2, gen_loss = 0.7780485592437254, disc_loss = 0.11645862557027371
Trained batch 669 in epoch 2, gen_loss = 0.777932592737141, disc_loss = 0.11641999850077416
Trained batch 670 in epoch 2, gen_loss = 0.7778918692500687, disc_loss = 0.11632633303609939
Trained batch 671 in epoch 2, gen_loss = 0.7786676937802917, disc_loss = 0.1163998906655858
Trained batch 672 in epoch 2, gen_loss = 0.7784756610687562, disc_loss = 0.1164363005031094
Trained batch 673 in epoch 2, gen_loss = 0.7784891185137921, disc_loss = 0.1163726400926665
Trained batch 674 in epoch 2, gen_loss = 0.7784626280819928, disc_loss = 0.1163316755824619
Trained batch 675 in epoch 2, gen_loss = 0.7786750103065954, disc_loss = 0.1165659909505816
Trained batch 676 in epoch 2, gen_loss = 0.7785909508672739, disc_loss = 0.11660367752283679
Trained batch 677 in epoch 2, gen_loss = 0.7782986092004804, disc_loss = 0.11653378230016843
Trained batch 678 in epoch 2, gen_loss = 0.778582717954498, disc_loss = 0.11644753880678115
Trained batch 679 in epoch 2, gen_loss = 0.778460701335879, disc_loss = 0.1163939547341536
Trained batch 680 in epoch 2, gen_loss = 0.7781417031120098, disc_loss = 0.11643004131868548
Trained batch 681 in epoch 2, gen_loss = 0.7781035392340327, disc_loss = 0.11649547664781819
Trained batch 682 in epoch 2, gen_loss = 0.7782451272185341, disc_loss = 0.11637120813916753
Trained batch 683 in epoch 2, gen_loss = 0.7779780218475744, disc_loss = 0.11637570692651104
Trained batch 684 in epoch 2, gen_loss = 0.7782602213595036, disc_loss = 0.11639072256584237
Trained batch 685 in epoch 2, gen_loss = 0.7782643417401495, disc_loss = 0.11626014896497434
Trained batch 686 in epoch 2, gen_loss = 0.7783041458463044, disc_loss = 0.1161842421131016
Trained batch 687 in epoch 2, gen_loss = 0.7789091216616852, disc_loss = 0.11613079942329678
Trained batch 688 in epoch 2, gen_loss = 0.7793988703989325, disc_loss = 0.11609585217709811
Trained batch 689 in epoch 2, gen_loss = 0.7790999136973118, disc_loss = 0.11610469517932422
Trained batch 690 in epoch 2, gen_loss = 0.7785932768012266, disc_loss = 0.11617452704095634
Trained batch 691 in epoch 2, gen_loss = 0.778518009607847, disc_loss = 0.11606800227259108
Trained batch 692 in epoch 2, gen_loss = 0.7789570853909716, disc_loss = 0.11609504734734435
Trained batch 693 in epoch 2, gen_loss = 0.7787888723852312, disc_loss = 0.11602718366433461
Trained batch 694 in epoch 2, gen_loss = 0.7786324674705807, disc_loss = 0.11607356818138266
Trained batch 695 in epoch 2, gen_loss = 0.7785482442156336, disc_loss = 0.1160482220276762
Trained batch 696 in epoch 2, gen_loss = 0.7790978287949282, disc_loss = 0.11625842083582236
Trained batch 697 in epoch 2, gen_loss = 0.7787885845646817, disc_loss = 0.11620622056197472
Trained batch 698 in epoch 2, gen_loss = 0.7784281592597607, disc_loss = 0.11630912935721005
Trained batch 699 in epoch 2, gen_loss = 0.7781722355314663, disc_loss = 0.11631852079182864
Trained batch 700 in epoch 2, gen_loss = 0.7784651142469317, disc_loss = 0.11627867874741214
Trained batch 701 in epoch 2, gen_loss = 0.7782125039572729, disc_loss = 0.11625687550339434
Trained batch 702 in epoch 2, gen_loss = 0.7780774956831382, disc_loss = 0.11622511739094091
Trained batch 703 in epoch 2, gen_loss = 0.7778238576667552, disc_loss = 0.11628618695117025
Trained batch 704 in epoch 2, gen_loss = 0.7780083359978723, disc_loss = 0.11644199848280731
Trained batch 705 in epoch 2, gen_loss = 0.7778076703842234, disc_loss = 0.11641263466317829
Trained batch 706 in epoch 2, gen_loss = 0.7774344477407329, disc_loss = 0.11638243924800037
Trained batch 707 in epoch 2, gen_loss = 0.7772246050716793, disc_loss = 0.11636373280195025
Trained batch 708 in epoch 2, gen_loss = 0.7771393341893706, disc_loss = 0.11628700150715447
Trained batch 709 in epoch 2, gen_loss = 0.777170290787455, disc_loss = 0.11627501959741955
Trained batch 710 in epoch 2, gen_loss = 0.7775421381080536, disc_loss = 0.1161701747710108
Trained batch 711 in epoch 2, gen_loss = 0.7771509429963117, disc_loss = 0.11614080479242996
Trained batch 712 in epoch 2, gen_loss = 0.7772071782452529, disc_loss = 0.11601749027009432
Trained batch 713 in epoch 2, gen_loss = 0.777341902214272, disc_loss = 0.11591187198789847
Trained batch 714 in epoch 2, gen_loss = 0.7774316155410314, disc_loss = 0.11582000252458599
Trained batch 715 in epoch 2, gen_loss = 0.7777619140024957, disc_loss = 0.11570069355910967
Trained batch 716 in epoch 2, gen_loss = 0.7773870722269912, disc_loss = 0.11597525428933828
Trained batch 717 in epoch 2, gen_loss = 0.7781245757029249, disc_loss = 0.1159946445899712
Trained batch 718 in epoch 2, gen_loss = 0.7782430060632703, disc_loss = 0.11594023860949551
Trained batch 719 in epoch 2, gen_loss = 0.7778287952558862, disc_loss = 0.11603923425233613
Trained batch 720 in epoch 2, gen_loss = 0.7778928243915516, disc_loss = 0.1159753103852892
Trained batch 721 in epoch 2, gen_loss = 0.7780332714319229, disc_loss = 0.11593097386174833
Trained batch 722 in epoch 2, gen_loss = 0.7779139232091389, disc_loss = 0.1159283178697442
Trained batch 723 in epoch 2, gen_loss = 0.7777218507880664, disc_loss = 0.11586426407129642
Trained batch 724 in epoch 2, gen_loss = 0.7780463355574114, disc_loss = 0.11601226725198072
Trained batch 725 in epoch 2, gen_loss = 0.778195258958609, disc_loss = 0.11595718138504865
Trained batch 726 in epoch 2, gen_loss = 0.7779000386329268, disc_loss = 0.11610324816852603
Trained batch 727 in epoch 2, gen_loss = 0.7777769938520678, disc_loss = 0.11626469709009833
Trained batch 728 in epoch 2, gen_loss = 0.7778769930612567, disc_loss = 0.11619948100845427
Trained batch 729 in epoch 2, gen_loss = 0.7777002578320569, disc_loss = 0.11612966696234191
Trained batch 730 in epoch 2, gen_loss = 0.7779585395808423, disc_loss = 0.11605293938454378
Trained batch 731 in epoch 2, gen_loss = 0.7777939452255358, disc_loss = 0.11594939831125199
Trained batch 732 in epoch 2, gen_loss = 0.7779655097532727, disc_loss = 0.11581511446878334
Trained batch 733 in epoch 2, gen_loss = 0.7775705841240506, disc_loss = 0.11582315518274619
Trained batch 734 in epoch 2, gen_loss = 0.7777972328014114, disc_loss = 0.11594494094654005
Trained batch 735 in epoch 2, gen_loss = 0.7773369402908112, disc_loss = 0.11604779972897275
Trained batch 736 in epoch 2, gen_loss = 0.7773546299504134, disc_loss = 0.11595931949455347
Trained batch 737 in epoch 2, gen_loss = 0.7767976797854674, disc_loss = 0.1161031919786439
Trained batch 738 in epoch 2, gen_loss = 0.7770033656986222, disc_loss = 0.1161545842018921
Trained batch 739 in epoch 2, gen_loss = 0.7773501686147741, disc_loss = 0.11607851992185052
Trained batch 740 in epoch 2, gen_loss = 0.7773074000148799, disc_loss = 0.11609944136116991
Trained batch 741 in epoch 2, gen_loss = 0.7771513189748934, disc_loss = 0.11609791188106704
Trained batch 742 in epoch 2, gen_loss = 0.7768953543652757, disc_loss = 0.11606134631712375
Trained batch 743 in epoch 2, gen_loss = 0.7769533286011348, disc_loss = 0.11602896952661135
Trained batch 744 in epoch 2, gen_loss = 0.7768756152799465, disc_loss = 0.11597509922197201
Trained batch 745 in epoch 2, gen_loss = 0.7769617355221398, disc_loss = 0.1159128843839143
Trained batch 746 in epoch 2, gen_loss = 0.7768704070942788, disc_loss = 0.11580930049300513
Trained batch 747 in epoch 2, gen_loss = 0.7767156670119035, disc_loss = 0.11578745230096069
Trained batch 748 in epoch 2, gen_loss = 0.7771977372417781, disc_loss = 0.11577488149258897
Trained batch 749 in epoch 2, gen_loss = 0.7770841150283814, disc_loss = 0.11568532748520374
Trained batch 750 in epoch 2, gen_loss = 0.7775405099325269, disc_loss = 0.11559027093605259
Trained batch 751 in epoch 2, gen_loss = 0.7771841439794986, disc_loss = 0.1156204209435097
Trained batch 752 in epoch 2, gen_loss = 0.777241447374007, disc_loss = 0.11579953881591598
Trained batch 753 in epoch 2, gen_loss = 0.7773497197925254, disc_loss = 0.11568929754513803
Trained batch 754 in epoch 2, gen_loss = 0.7771839610788206, disc_loss = 0.11558150451210951
Trained batch 755 in epoch 2, gen_loss = 0.7772398550043661, disc_loss = 0.11552416867817994
Trained batch 756 in epoch 2, gen_loss = 0.7769258061677335, disc_loss = 0.11552241264966709
Trained batch 757 in epoch 2, gen_loss = 0.7770996043424179, disc_loss = 0.11542637909622494
Trained batch 758 in epoch 2, gen_loss = 0.7771500020787336, disc_loss = 0.1153085080879754
Trained batch 759 in epoch 2, gen_loss = 0.777239038677592, disc_loss = 0.11523357655509914
Trained batch 760 in epoch 2, gen_loss = 0.7771855696898722, disc_loss = 0.11519076556956173
Trained batch 761 in epoch 2, gen_loss = 0.776763862981571, disc_loss = 0.1152092982841328
Trained batch 762 in epoch 2, gen_loss = 0.7769568826549175, disc_loss = 0.11513792932629195
Trained batch 763 in epoch 2, gen_loss = 0.7770621060388875, disc_loss = 0.11505284996371697
Trained batch 764 in epoch 2, gen_loss = 0.777186918258667, disc_loss = 0.11492869833277332
Trained batch 765 in epoch 2, gen_loss = 0.7776279480588032, disc_loss = 0.11510265545369984
Trained batch 766 in epoch 2, gen_loss = 0.7776497260532603, disc_loss = 0.1150501183606927
Trained batch 767 in epoch 2, gen_loss = 0.7777424529970934, disc_loss = 0.11493818279510985
Trained batch 768 in epoch 2, gen_loss = 0.7779269223870474, disc_loss = 0.11483160347250256
Trained batch 769 in epoch 2, gen_loss = 0.7776787483846986, disc_loss = 0.11489730786967588
Trained batch 770 in epoch 2, gen_loss = 0.7778233784491295, disc_loss = 0.11476683763644613
Trained batch 771 in epoch 2, gen_loss = 0.7788490435311214, disc_loss = 0.11484230020315112
Trained batch 772 in epoch 2, gen_loss = 0.7788677760731202, disc_loss = 0.11472923354514396
Trained batch 773 in epoch 2, gen_loss = 0.7792067542402628, disc_loss = 0.1146012682272771
Trained batch 774 in epoch 2, gen_loss = 0.7793199058501951, disc_loss = 0.11448560086830008
Trained batch 775 in epoch 2, gen_loss = 0.7795170944990572, disc_loss = 0.11436398650313123
Trained batch 776 in epoch 2, gen_loss = 0.7795593263713243, disc_loss = 0.11426236944937146
Trained batch 777 in epoch 2, gen_loss = 0.7795266344338885, disc_loss = 0.11418291916208854
Trained batch 778 in epoch 2, gen_loss = 0.7801698401130363, disc_loss = 0.11476598361887239
Trained batch 779 in epoch 2, gen_loss = 0.7800972992793108, disc_loss = 0.1147342055498694
Trained batch 780 in epoch 2, gen_loss = 0.7800258495743541, disc_loss = 0.11466411543502049
Trained batch 781 in epoch 2, gen_loss = 0.7799650738611246, disc_loss = 0.11456757290717548
Trained batch 782 in epoch 2, gen_loss = 0.7801704027643606, disc_loss = 0.11445026797281714
Trained batch 783 in epoch 2, gen_loss = 0.7799289294195418, disc_loss = 0.11447108707186404
Trained batch 784 in epoch 2, gen_loss = 0.7800463890573781, disc_loss = 0.11449972832587305
Trained batch 785 in epoch 2, gen_loss = 0.7802685531041095, disc_loss = 0.11443557702218189
Trained batch 786 in epoch 2, gen_loss = 0.78008451675369, disc_loss = 0.11453715777273137
Trained batch 787 in epoch 2, gen_loss = 0.7802171303989923, disc_loss = 0.11464752879130848
Trained batch 788 in epoch 2, gen_loss = 0.7805431083279115, disc_loss = 0.11458375334328912
Trained batch 789 in epoch 2, gen_loss = 0.7802257718919199, disc_loss = 0.11460004756462913
Trained batch 790 in epoch 2, gen_loss = 0.7803653761951721, disc_loss = 0.11447846440082668
Trained batch 791 in epoch 2, gen_loss = 0.7804592078683352, disc_loss = 0.11437151312352996
Trained batch 792 in epoch 2, gen_loss = 0.7802804943742547, disc_loss = 0.11432678768620327
Trained batch 793 in epoch 2, gen_loss = 0.7802684279322925, disc_loss = 0.11444292754587021
Trained batch 794 in epoch 2, gen_loss = 0.7800422805660175, disc_loss = 0.1144972993178094
Trained batch 795 in epoch 2, gen_loss = 0.7799157702443588, disc_loss = 0.11453297532435001
Trained batch 796 in epoch 2, gen_loss = 0.7801318268105855, disc_loss = 0.11460871748051313
Trained batch 797 in epoch 2, gen_loss = 0.7801261417997212, disc_loss = 0.11450826609507203
Trained batch 798 in epoch 2, gen_loss = 0.7798055547647392, disc_loss = 0.11452859046476169
Trained batch 799 in epoch 2, gen_loss = 0.779692714214325, disc_loss = 0.11448813371709549
Trained batch 800 in epoch 2, gen_loss = 0.7799123465345147, disc_loss = 0.11465290230065212
Trained batch 801 in epoch 2, gen_loss = 0.7796815135829763, disc_loss = 0.114642312210239
Trained batch 802 in epoch 2, gen_loss = 0.7795945898830371, disc_loss = 0.11457069804439621
Trained batch 803 in epoch 2, gen_loss = 0.7793831870478777, disc_loss = 0.11461078638641803
Trained batch 804 in epoch 2, gen_loss = 0.7795391505549413, disc_loss = 0.11455613236689234
Trained batch 805 in epoch 2, gen_loss = 0.7791002161301691, disc_loss = 0.11463537711358951
Trained batch 806 in epoch 2, gen_loss = 0.7795069237623959, disc_loss = 0.11464157652414532
Trained batch 807 in epoch 2, gen_loss = 0.7793792801180689, disc_loss = 0.11465571046055359
Trained batch 808 in epoch 2, gen_loss = 0.7791337277302783, disc_loss = 0.11470046655904635
Trained batch 809 in epoch 2, gen_loss = 0.7791412728804129, disc_loss = 0.11461725578424924
Trained batch 810 in epoch 2, gen_loss = 0.7792318129657082, disc_loss = 0.11463913412789932
Trained batch 811 in epoch 2, gen_loss = 0.7795443912885459, disc_loss = 0.11454056321615766
Trained batch 812 in epoch 2, gen_loss = 0.7794484892747793, disc_loss = 0.11453645999759876
Trained batch 813 in epoch 2, gen_loss = 0.7794129191657542, disc_loss = 0.11455137428944286
Trained batch 814 in epoch 2, gen_loss = 0.7793786957951411, disc_loss = 0.11446751473940041
Trained batch 815 in epoch 2, gen_loss = 0.779402442933882, disc_loss = 0.11457772665159485
Trained batch 816 in epoch 2, gen_loss = 0.7792370754181245, disc_loss = 0.11457230184327542
Trained batch 817 in epoch 2, gen_loss = 0.7801662529010353, disc_loss = 0.11466104377739696
Trained batch 818 in epoch 2, gen_loss = 0.7800029328454545, disc_loss = 0.1146917680360295
Trained batch 819 in epoch 2, gen_loss = 0.779743888756124, disc_loss = 0.11474482517848472
Trained batch 820 in epoch 2, gen_loss = 0.779736610408532, disc_loss = 0.1147732228737202
Trained batch 821 in epoch 2, gen_loss = 0.7799450857360868, disc_loss = 0.11504275753183195
Trained batch 822 in epoch 2, gen_loss = 0.7795804308077834, disc_loss = 0.11523320116577976
Trained batch 823 in epoch 2, gen_loss = 0.7793730647095198, disc_loss = 0.1152326826410802
Trained batch 824 in epoch 2, gen_loss = 0.779220151684501, disc_loss = 0.1152575619372003
Trained batch 825 in epoch 2, gen_loss = 0.7792075891904623, disc_loss = 0.11526568924791696
Trained batch 826 in epoch 2, gen_loss = 0.7788313338949718, disc_loss = 0.11536768894921876
Trained batch 827 in epoch 2, gen_loss = 0.7787160098840649, disc_loss = 0.11534931161440909
Trained batch 828 in epoch 2, gen_loss = 0.7787097938385746, disc_loss = 0.1153320717570272
Trained batch 829 in epoch 2, gen_loss = 0.7789677157459489, disc_loss = 0.11552879056186381
Trained batch 830 in epoch 2, gen_loss = 0.778514435252558, disc_loss = 0.11571178768977756
Trained batch 831 in epoch 2, gen_loss = 0.778536384459585, disc_loss = 0.11574306299511451
Trained batch 832 in epoch 2, gen_loss = 0.7783701857384228, disc_loss = 0.1158776890032557
Trained batch 833 in epoch 2, gen_loss = 0.7782019209161365, disc_loss = 0.11586550720442507
Trained batch 834 in epoch 2, gen_loss = 0.7780759451988928, disc_loss = 0.11581234116285682
Trained batch 835 in epoch 2, gen_loss = 0.7778658766709446, disc_loss = 0.11583813641590186
Trained batch 836 in epoch 2, gen_loss = 0.7777419994310382, disc_loss = 0.11589111606596013
Trained batch 837 in epoch 2, gen_loss = 0.7780161991822122, disc_loss = 0.1160424546214145
Trained batch 838 in epoch 2, gen_loss = 0.7777435634289652, disc_loss = 0.11600614078809131
Trained batch 839 in epoch 2, gen_loss = 0.7778726842786584, disc_loss = 0.11595199513359972
Trained batch 840 in epoch 2, gen_loss = 0.777610777851801, disc_loss = 0.11597935172234186
Trained batch 841 in epoch 2, gen_loss = 0.777531196874281, disc_loss = 0.11592880596524002
Trained batch 842 in epoch 2, gen_loss = 0.7775531458897098, disc_loss = 0.1158870449665302
Trained batch 843 in epoch 2, gen_loss = 0.777548209715511, disc_loss = 0.11587625863670561
Trained batch 844 in epoch 2, gen_loss = 0.7775355288615593, disc_loss = 0.11581678250198357
Trained batch 845 in epoch 2, gen_loss = 0.7773386260085072, disc_loss = 0.11578277693004578
Trained batch 846 in epoch 2, gen_loss = 0.7773671833162746, disc_loss = 0.11573326011400542
Trained batch 847 in epoch 2, gen_loss = 0.7772513855389267, disc_loss = 0.11577237893735005
Trained batch 848 in epoch 2, gen_loss = 0.7773803424428012, disc_loss = 0.11590726532204378
Trained batch 849 in epoch 2, gen_loss = 0.7772759361477459, disc_loss = 0.11602194481803214
Trained batch 850 in epoch 2, gen_loss = 0.7772820904658347, disc_loss = 0.11604158411220539
Trained batch 851 in epoch 2, gen_loss = 0.7771896575468247, disc_loss = 0.11597353480472077
Trained batch 852 in epoch 2, gen_loss = 0.7769904498268543, disc_loss = 0.11602409887875476
Trained batch 853 in epoch 2, gen_loss = 0.777443420237903, disc_loss = 0.11615514441063972
Trained batch 854 in epoch 2, gen_loss = 0.7773592359489865, disc_loss = 0.11614881898467129
Trained batch 855 in epoch 2, gen_loss = 0.7773461395822395, disc_loss = 0.11608859019192963
Trained batch 856 in epoch 2, gen_loss = 0.7775242156506698, disc_loss = 0.11602366425188274
Trained batch 857 in epoch 2, gen_loss = 0.777591593094639, disc_loss = 0.11596609793477507
Trained batch 858 in epoch 2, gen_loss = 0.7775683354096308, disc_loss = 0.11595612221285788
Trained batch 859 in epoch 2, gen_loss = 0.7772241230967433, disc_loss = 0.11602988495967936
Trained batch 860 in epoch 2, gen_loss = 0.7771193978747701, disc_loss = 0.11595431337420775
Trained batch 861 in epoch 2, gen_loss = 0.7772560924153317, disc_loss = 0.11591882027335586
Trained batch 862 in epoch 2, gen_loss = 0.7776431556303283, disc_loss = 0.11609392838826703
Trained batch 863 in epoch 2, gen_loss = 0.7772703795107426, disc_loss = 0.11628715133755813
Trained batch 864 in epoch 2, gen_loss = 0.7772145351922581, disc_loss = 0.11624220893368384
Trained batch 865 in epoch 2, gen_loss = 0.7774686951009561, disc_loss = 0.11623024446115449
Trained batch 866 in epoch 2, gen_loss = 0.7773643685322181, disc_loss = 0.11621812499324859
Trained batch 867 in epoch 2, gen_loss = 0.7770615320326546, disc_loss = 0.11619135867353649
Trained batch 868 in epoch 2, gen_loss = 0.7769787481656969, disc_loss = 0.1161662292697813
Trained batch 869 in epoch 2, gen_loss = 0.7764746695756912, disc_loss = 0.11635264660413752
Trained batch 870 in epoch 2, gen_loss = 0.7767413659908742, disc_loss = 0.11640730137850161
Trained batch 871 in epoch 2, gen_loss = 0.776593760305315, disc_loss = 0.11640908172110591
Trained batch 872 in epoch 2, gen_loss = 0.7767735907780209, disc_loss = 0.11635763426327317
Trained batch 873 in epoch 2, gen_loss = 0.7769220765654501, disc_loss = 0.11636887100638152
Trained batch 874 in epoch 2, gen_loss = 0.7768345563411713, disc_loss = 0.11634023441906487
Trained batch 875 in epoch 2, gen_loss = 0.776731430429574, disc_loss = 0.11628302015240845
Trained batch 876 in epoch 2, gen_loss = 0.7768226279160316, disc_loss = 0.11640891777999283
Trained batch 877 in epoch 2, gen_loss = 0.7769792554793977, disc_loss = 0.11632143846842416
Trained batch 878 in epoch 2, gen_loss = 0.776893317597718, disc_loss = 0.11635615948621561
Trained batch 879 in epoch 2, gen_loss = 0.7765211436897517, disc_loss = 0.11657404518495737
Trained batch 880 in epoch 2, gen_loss = 0.7769585586365452, disc_loss = 0.11646832593702938
Trained batch 881 in epoch 2, gen_loss = 0.7771028291408707, disc_loss = 0.11635642987728761
Trained batch 882 in epoch 2, gen_loss = 0.7773564103843131, disc_loss = 0.11637660787500956
Trained batch 883 in epoch 2, gen_loss = 0.7774169895781111, disc_loss = 0.11633784144303479
Trained batch 884 in epoch 2, gen_loss = 0.7772707770436497, disc_loss = 0.11630974965811955
Trained batch 885 in epoch 2, gen_loss = 0.7772512539851208, disc_loss = 0.11638357809746877
Trained batch 886 in epoch 2, gen_loss = 0.7774603404818689, disc_loss = 0.11647906218967248
Trained batch 887 in epoch 2, gen_loss = 0.7770480636070978, disc_loss = 0.11667844634566053
Trained batch 888 in epoch 2, gen_loss = 0.7773011886966242, disc_loss = 0.11679181667658657
Trained batch 889 in epoch 2, gen_loss = 0.7772058029857914, disc_loss = 0.11679252743448937
Trained batch 890 in epoch 2, gen_loss = 0.7767939440128377, disc_loss = 0.11688854844611468
Trained batch 891 in epoch 2, gen_loss = 0.7767994798419187, disc_loss = 0.11686127028018738
Trained batch 892 in epoch 2, gen_loss = 0.7770290983817879, disc_loss = 0.11678995497311984
Trained batch 893 in epoch 2, gen_loss = 0.7771763260532546, disc_loss = 0.11683485105162866
Trained batch 894 in epoch 2, gen_loss = 0.7769021429496105, disc_loss = 0.11681700650935566
Trained batch 895 in epoch 2, gen_loss = 0.7766810623995427, disc_loss = 0.11687914489032535
Trained batch 896 in epoch 2, gen_loss = 0.7766064558605951, disc_loss = 0.11683285527799274
Trained batch 897 in epoch 2, gen_loss = 0.776542594046529, disc_loss = 0.11680642816493234
Trained batch 898 in epoch 2, gen_loss = 0.7768356081707459, disc_loss = 0.11676223681218201
Trained batch 899 in epoch 2, gen_loss = 0.7767795076966286, disc_loss = 0.11681339882210724
Trained batch 900 in epoch 2, gen_loss = 0.776908056882854, disc_loss = 0.11677220187456937
Trained batch 901 in epoch 2, gen_loss = 0.7768346987449938, disc_loss = 0.11671935490945853
Trained batch 902 in epoch 2, gen_loss = 0.7769745963554445, disc_loss = 0.1166438404976051
Trained batch 903 in epoch 2, gen_loss = 0.7769178383184218, disc_loss = 0.11658997742141869
Trained batch 904 in epoch 2, gen_loss = 0.7772623872559373, disc_loss = 0.11701893622765719
Trained batch 905 in epoch 2, gen_loss = 0.7771533883894253, disc_loss = 0.11705150099051807
Trained batch 906 in epoch 2, gen_loss = 0.7773220200325714, disc_loss = 0.11696246714775821
Trained batch 907 in epoch 2, gen_loss = 0.7773310789255844, disc_loss = 0.11690127573361711
Trained batch 908 in epoch 2, gen_loss = 0.7773917031170118, disc_loss = 0.11689725126743283
Trained batch 909 in epoch 2, gen_loss = 0.7772208911049497, disc_loss = 0.11685779998897687
Trained batch 910 in epoch 2, gen_loss = 0.7771500498547119, disc_loss = 0.11685770233473551
Trained batch 911 in epoch 2, gen_loss = 0.7770561714771024, disc_loss = 0.11681626554427407
Trained batch 912 in epoch 2, gen_loss = 0.7771299230373441, disc_loss = 0.11676337765295136
Trained batch 913 in epoch 2, gen_loss = 0.776968830817377, disc_loss = 0.11670788752803624
Trained batch 914 in epoch 2, gen_loss = 0.7768627101932067, disc_loss = 0.11663246213310892
Trained batch 915 in epoch 2, gen_loss = 0.776972063991961, disc_loss = 0.11665236886375173
Trained batch 916 in epoch 2, gen_loss = 0.777142025749712, disc_loss = 0.11662190227851581
Trained batch 917 in epoch 2, gen_loss = 0.7769937547398549, disc_loss = 0.11669601840809117
Trained batch 918 in epoch 2, gen_loss = 0.7770757746190579, disc_loss = 0.11667456429946248
Trained batch 919 in epoch 2, gen_loss = 0.7770619830035645, disc_loss = 0.11666086737127246
Trained batch 920 in epoch 2, gen_loss = 0.7769251695867471, disc_loss = 0.11666608507867324
Trained batch 921 in epoch 2, gen_loss = 0.7770741714766641, disc_loss = 0.11664828658002932
Trained batch 922 in epoch 2, gen_loss = 0.7773326888179986, disc_loss = 0.11658024478235554
Trained batch 923 in epoch 2, gen_loss = 0.7770876614497854, disc_loss = 0.11652921065506706
Trained batch 924 in epoch 2, gen_loss = 0.7771941830338659, disc_loss = 0.11644927484260217
Trained batch 925 in epoch 2, gen_loss = 0.776997690807151, disc_loss = 0.1164215798670784
Trained batch 926 in epoch 2, gen_loss = 0.7769692105832866, disc_loss = 0.11634812124993776
Trained batch 927 in epoch 2, gen_loss = 0.7769943941705699, disc_loss = 0.1163044520924751
Trained batch 928 in epoch 2, gen_loss = 0.7769169613991667, disc_loss = 0.11630350698098396
Trained batch 929 in epoch 2, gen_loss = 0.7773333428047037, disc_loss = 0.11625007530674339
Trained batch 930 in epoch 2, gen_loss = 0.7770913657837344, disc_loss = 0.11624910137751145
Trained batch 931 in epoch 2, gen_loss = 0.7767389776432975, disc_loss = 0.11632596978282181
Trained batch 932 in epoch 2, gen_loss = 0.7771188147517774, disc_loss = 0.11631189572094817
Trained batch 933 in epoch 2, gen_loss = 0.7769971481291079, disc_loss = 0.11630342905838402
Trained batch 934 in epoch 2, gen_loss = 0.7772445077245885, disc_loss = 0.11626722146781848
Trained batch 935 in epoch 2, gen_loss = 0.7773476250979126, disc_loss = 0.11618293013371941
Trained batch 936 in epoch 2, gen_loss = 0.7772137077093888, disc_loss = 0.11611833247547948
Trained batch 937 in epoch 2, gen_loss = 0.7770993049020198, disc_loss = 0.11609545635130963
Trained batch 938 in epoch 2, gen_loss = 0.7767921903897652, disc_loss = 0.1160895000811948
Trained batch 939 in epoch 2, gen_loss = 0.7769774343739164, disc_loss = 0.11620613851663755
Trained batch 940 in epoch 2, gen_loss = 0.7772003861973567, disc_loss = 0.11617919484274135
Trained batch 941 in epoch 2, gen_loss = 0.7767469405242086, disc_loss = 0.11652369105856225
Trained batch 942 in epoch 2, gen_loss = 0.7768436157690758, disc_loss = 0.11644634668352843
Trained batch 943 in epoch 2, gen_loss = 0.7771532992058892, disc_loss = 0.11643639438829022
Trained batch 944 in epoch 2, gen_loss = 0.7773771475231837, disc_loss = 0.11647285757458241
Trained batch 945 in epoch 2, gen_loss = 0.777087717303262, disc_loss = 0.1164757508625046
Trained batch 946 in epoch 2, gen_loss = 0.7769150690518816, disc_loss = 0.116401983186044
Trained batch 947 in epoch 2, gen_loss = 0.7769946399997558, disc_loss = 0.11631025688207948
Trained batch 948 in epoch 2, gen_loss = 0.7773883286843938, disc_loss = 0.11623351580440779
Trained batch 949 in epoch 2, gen_loss = 0.7774632244361074, disc_loss = 0.11615194108043062
Trained batch 950 in epoch 2, gen_loss = 0.77748664414469, disc_loss = 0.11607624469648119
Trained batch 951 in epoch 2, gen_loss = 0.7775246896037534, disc_loss = 0.11600417940693461
Trained batch 952 in epoch 2, gen_loss = 0.7778430454753503, disc_loss = 0.11596107466785474
Trained batch 953 in epoch 2, gen_loss = 0.7780390734817497, disc_loss = 0.11587279091102991
Trained batch 954 in epoch 2, gen_loss = 0.7780403003642696, disc_loss = 0.11580005545871264
Trained batch 955 in epoch 2, gen_loss = 0.7778159262744951, disc_loss = 0.11596658674972794
Trained batch 956 in epoch 2, gen_loss = 0.7784469197411772, disc_loss = 0.11637825027882835
Trained batch 957 in epoch 2, gen_loss = 0.7783685965552957, disc_loss = 0.11633201870806749
Trained batch 958 in epoch 2, gen_loss = 0.778193068578917, disc_loss = 0.11640453122933012
Trained batch 959 in epoch 2, gen_loss = 0.7785882341365019, disc_loss = 0.11634589321814322
Trained batch 960 in epoch 2, gen_loss = 0.7787210850760294, disc_loss = 0.11636592762430395
Trained batch 961 in epoch 2, gen_loss = 0.7784090392802708, disc_loss = 0.11646663811030698
Trained batch 962 in epoch 2, gen_loss = 0.7781138814374542, disc_loss = 0.11646281380732453
Trained batch 963 in epoch 2, gen_loss = 0.7784744214838472, disc_loss = 0.1164975688933816
Trained batch 964 in epoch 2, gen_loss = 0.7788861741056097, disc_loss = 0.11647488941858315
Trained batch 965 in epoch 2, gen_loss = 0.7785513827087469, disc_loss = 0.11659280263855436
Trained batch 966 in epoch 2, gen_loss = 0.778409091399399, disc_loss = 0.11654916961100473
Trained batch 967 in epoch 2, gen_loss = 0.7783277004279874, disc_loss = 0.11648742717494495
Trained batch 968 in epoch 2, gen_loss = 0.7783891991380567, disc_loss = 0.11651189322222959
Trained batch 969 in epoch 2, gen_loss = 0.7782594445132718, disc_loss = 0.11648468959634913
Trained batch 970 in epoch 2, gen_loss = 0.7782077947372511, disc_loss = 0.11649132082497761
Trained batch 971 in epoch 2, gen_loss = 0.7782956154810058, disc_loss = 0.1164790566755773
Trained batch 972 in epoch 2, gen_loss = 0.7784193220939812, disc_loss = 0.11639250593522193
Trained batch 973 in epoch 2, gen_loss = 0.7783773572966304, disc_loss = 0.11635269813557027
Trained batch 974 in epoch 2, gen_loss = 0.7784115455395136, disc_loss = 0.11631180363492324
Trained batch 975 in epoch 2, gen_loss = 0.7784820662841934, disc_loss = 0.11629645869070969
Trained batch 976 in epoch 2, gen_loss = 0.7782736527090063, disc_loss = 0.11629068557775465
Trained batch 977 in epoch 2, gen_loss = 0.7788537423486358, disc_loss = 0.11637551269583511
Trained batch 978 in epoch 2, gen_loss = 0.7786218477403545, disc_loss = 0.11644371845440767
Trained batch 979 in epoch 2, gen_loss = 0.778670298475392, disc_loss = 0.11639956918507054
Trained batch 980 in epoch 2, gen_loss = 0.778522982054165, disc_loss = 0.1163578325005345
Trained batch 981 in epoch 2, gen_loss = 0.7787341317977536, disc_loss = 0.11636312118429849
Trained batch 982 in epoch 2, gen_loss = 0.7788728173909328, disc_loss = 0.11633116278858023
Trained batch 983 in epoch 2, gen_loss = 0.7787211857493815, disc_loss = 0.11630760796455197
Trained batch 984 in epoch 2, gen_loss = 0.778636742092026, disc_loss = 0.11629208673434663
Trained batch 985 in epoch 2, gen_loss = 0.7788456325659162, disc_loss = 0.11624413680258767
Trained batch 986 in epoch 2, gen_loss = 0.778879707737655, disc_loss = 0.11614970703304509
Trained batch 987 in epoch 2, gen_loss = 0.778724128086316, disc_loss = 0.11618289525379324
Trained batch 988 in epoch 2, gen_loss = 0.7785030488599057, disc_loss = 0.11624845382225435
Trained batch 989 in epoch 2, gen_loss = 0.7785878843430317, disc_loss = 0.1163702890624979
Trained batch 990 in epoch 2, gen_loss = 0.7787001728109346, disc_loss = 0.11639875838651456
Trained batch 991 in epoch 2, gen_loss = 0.7783268907017284, disc_loss = 0.11645965747283621
Trained batch 992 in epoch 2, gen_loss = 0.7782295770035289, disc_loss = 0.1163970432464645
Trained batch 993 in epoch 2, gen_loss = 0.7783581890930352, disc_loss = 0.11634058301886113
Trained batch 994 in epoch 2, gen_loss = 0.7782821625321354, disc_loss = 0.11630852032714903
Trained batch 995 in epoch 2, gen_loss = 0.7781178531158401, disc_loss = 0.11628897262673571
Trained batch 996 in epoch 2, gen_loss = 0.7780668174730261, disc_loss = 0.1162962928804809
Trained batch 997 in epoch 2, gen_loss = 0.7781531341329128, disc_loss = 0.11620900494500039
Trained batch 998 in epoch 2, gen_loss = 0.7780593805484943, disc_loss = 0.11617745361845563
Trained batch 999 in epoch 2, gen_loss = 0.7781272819042205, disc_loss = 0.11610068192053587
Trained batch 1000 in epoch 2, gen_loss = 0.7784817490306172, disc_loss = 0.11600293279844118
Trained batch 1001 in epoch 2, gen_loss = 0.7786216807222652, disc_loss = 0.11591574704430685
Trained batch 1002 in epoch 2, gen_loss = 0.7787172501964322, disc_loss = 0.11592863806256892
Trained batch 1003 in epoch 2, gen_loss = 0.7784669515027468, disc_loss = 0.11587790363520176
Trained batch 1004 in epoch 2, gen_loss = 0.778352307443002, disc_loss = 0.11586732189101515
Trained batch 1005 in epoch 2, gen_loss = 0.7783158267468628, disc_loss = 0.11583043270601814
Trained batch 1006 in epoch 2, gen_loss = 0.778327032376188, disc_loss = 0.11577741913552939
Trained batch 1007 in epoch 2, gen_loss = 0.7784856046949115, disc_loss = 0.11570280596765409
Trained batch 1008 in epoch 2, gen_loss = 0.7784541782704288, disc_loss = 0.11561502136633435
Trained batch 1009 in epoch 2, gen_loss = 0.778536857944904, disc_loss = 0.11552479611156453
Trained batch 1010 in epoch 2, gen_loss = 0.7783929085990914, disc_loss = 0.11543649897756816
Trained batch 1011 in epoch 2, gen_loss = 0.7783916264536823, disc_loss = 0.11539522519338832
Trained batch 1012 in epoch 2, gen_loss = 0.7786081186757742, disc_loss = 0.11529674076797902
Trained batch 1013 in epoch 2, gen_loss = 0.7784982256047589, disc_loss = 0.11526999844025078
Trained batch 1014 in epoch 2, gen_loss = 0.7787503421600229, disc_loss = 0.11519348426754104
Trained batch 1015 in epoch 2, gen_loss = 0.7788300950696149, disc_loss = 0.11516403051104221
Trained batch 1016 in epoch 2, gen_loss = 0.7787102001372106, disc_loss = 0.11516240816343587
Trained batch 1017 in epoch 2, gen_loss = 0.7784739626179978, disc_loss = 0.1151255194769261
Trained batch 1018 in epoch 2, gen_loss = 0.7782785877278321, disc_loss = 0.11536111091779978
Trained batch 1019 in epoch 2, gen_loss = 0.7780455713762956, disc_loss = 0.11533169762377499
Trained batch 1020 in epoch 2, gen_loss = 0.7781728328617032, disc_loss = 0.1152752642268926
Trained batch 1021 in epoch 2, gen_loss = 0.7781012083919547, disc_loss = 0.11520646942538845
Trained batch 1022 in epoch 2, gen_loss = 0.7779221438009835, disc_loss = 0.11516853562398711
Trained batch 1023 in epoch 2, gen_loss = 0.7783201452111825, disc_loss = 0.11510321115474653
Trained batch 1024 in epoch 2, gen_loss = 0.7785660185464999, disc_loss = 0.11502496711637189
Trained batch 1025 in epoch 2, gen_loss = 0.778411049998527, disc_loss = 0.11509967420602374
Trained batch 1026 in epoch 2, gen_loss = 0.7784536115846941, disc_loss = 0.11504666359520208
Trained batch 1027 in epoch 2, gen_loss = 0.7784370593291776, disc_loss = 0.11506197988852887
Trained batch 1028 in epoch 2, gen_loss = 0.7784791286994927, disc_loss = 0.11497441112571573
Trained batch 1029 in epoch 2, gen_loss = 0.7783605694770813, disc_loss = 0.11494007335107738
Trained batch 1030 in epoch 2, gen_loss = 0.7782358982167582, disc_loss = 0.11488779630533678
Trained batch 1031 in epoch 2, gen_loss = 0.7783445161442424, disc_loss = 0.1147880658945935
Trained batch 1032 in epoch 2, gen_loss = 0.7786095867083126, disc_loss = 0.11480610671886833
Trained batch 1033 in epoch 2, gen_loss = 0.7785229914654155, disc_loss = 0.11477905900147338
Trained batch 1034 in epoch 2, gen_loss = 0.7783591212281858, disc_loss = 0.11483427771965518
Trained batch 1035 in epoch 2, gen_loss = 0.7783559277711227, disc_loss = 0.1148898369303642
Trained batch 1036 in epoch 2, gen_loss = 0.7784492978134634, disc_loss = 0.11481376990887876
Trained batch 1037 in epoch 2, gen_loss = 0.7782506545384725, disc_loss = 0.11478321408486866
Trained batch 1038 in epoch 2, gen_loss = 0.7781672168512317, disc_loss = 0.11475099355638514
Trained batch 1039 in epoch 2, gen_loss = 0.7781230067977538, disc_loss = 0.1146805421440289
Trained batch 1040 in epoch 2, gen_loss = 0.7778596401672656, disc_loss = 0.11476764282503314
Trained batch 1041 in epoch 2, gen_loss = 0.7776391661212907, disc_loss = 0.11474824349186785
Trained batch 1042 in epoch 2, gen_loss = 0.7775490915443845, disc_loss = 0.11476252612962333
Trained batch 1043 in epoch 2, gen_loss = 0.7779835794278032, disc_loss = 0.11473537524680383
Trained batch 1044 in epoch 2, gen_loss = 0.7778295866610331, disc_loss = 0.11471971113626894
Trained batch 1045 in epoch 2, gen_loss = 0.7776411956970368, disc_loss = 0.11467335952880363
Trained batch 1046 in epoch 2, gen_loss = 0.7777613953054805, disc_loss = 0.1145975280761249
Trained batch 1047 in epoch 2, gen_loss = 0.7780786617907859, disc_loss = 0.11462106503002374
Trained batch 1048 in epoch 2, gen_loss = 0.7782559234602776, disc_loss = 0.11453629411078699
Trained batch 1049 in epoch 2, gen_loss = 0.778119991506849, disc_loss = 0.11448535525993932
Trained batch 1050 in epoch 2, gen_loss = 0.7779665701055845, disc_loss = 0.11449379588678466
Trained batch 1051 in epoch 2, gen_loss = 0.7779448625026094, disc_loss = 0.11440659190011086
Trained batch 1052 in epoch 2, gen_loss = 0.7781303801767507, disc_loss = 0.1146149400998427
Trained batch 1053 in epoch 2, gen_loss = 0.7779755605918407, disc_loss = 0.11463901137869516
Trained batch 1054 in epoch 2, gen_loss = 0.7781099139231641, disc_loss = 0.11456430748158015
Trained batch 1055 in epoch 2, gen_loss = 0.7780903828979442, disc_loss = 0.1145320012345275
Trained batch 1056 in epoch 2, gen_loss = 0.7783018114325452, disc_loss = 0.11463985842623542
Trained batch 1057 in epoch 2, gen_loss = 0.7783247783413907, disc_loss = 0.11463052586745646
Trained batch 1058 in epoch 2, gen_loss = 0.778118375115399, disc_loss = 0.11463438185077861
Trained batch 1059 in epoch 2, gen_loss = 0.7781796809637321, disc_loss = 0.11457198700375573
Trained batch 1060 in epoch 2, gen_loss = 0.7783462317005628, disc_loss = 0.1147122205271053
Trained batch 1061 in epoch 2, gen_loss = 0.7783000976576868, disc_loss = 0.11465112194541681
Trained batch 1062 in epoch 2, gen_loss = 0.7782418804132815, disc_loss = 0.11458592117796472
Trained batch 1063 in epoch 2, gen_loss = 0.7783778479000679, disc_loss = 0.11466323016684055
Trained batch 1064 in epoch 2, gen_loss = 0.778186560516626, disc_loss = 0.11481185220619182
Trained batch 1065 in epoch 2, gen_loss = 0.7782694708003783, disc_loss = 0.11482450517949842
Trained batch 1066 in epoch 2, gen_loss = 0.7781205211941505, disc_loss = 0.11478359869750253
Trained batch 1067 in epoch 2, gen_loss = 0.778065236431829, disc_loss = 0.11471503380989509
Trained batch 1068 in epoch 2, gen_loss = 0.778316110400422, disc_loss = 0.11472891574556494
Trained batch 1069 in epoch 2, gen_loss = 0.778297872743874, disc_loss = 0.11467071158776634
Trained batch 1070 in epoch 2, gen_loss = 0.777982355945028, disc_loss = 0.11473862636124804
Trained batch 1071 in epoch 2, gen_loss = 0.7780527648196292, disc_loss = 0.1147297083099595
Trained batch 1072 in epoch 2, gen_loss = 0.7780681095274385, disc_loss = 0.11474966606991462
Trained batch 1073 in epoch 2, gen_loss = 0.7778643892464026, disc_loss = 0.11480218761650848
Trained batch 1074 in epoch 2, gen_loss = 0.7779367668129678, disc_loss = 0.11484341093187415
Trained batch 1075 in epoch 2, gen_loss = 0.7778185401042598, disc_loss = 0.11497991533385638
Trained batch 1076 in epoch 2, gen_loss = 0.7780605916525328, disc_loss = 0.11494776558047964
Trained batch 1077 in epoch 2, gen_loss = 0.7782846240254192, disc_loss = 0.11501470954521993
Trained batch 1078 in epoch 2, gen_loss = 0.7781883975330385, disc_loss = 0.1151101663492903
Trained batch 1079 in epoch 2, gen_loss = 0.7779433221176818, disc_loss = 0.11520022551132435
Trained batch 1080 in epoch 2, gen_loss = 0.7779184662556891, disc_loss = 0.11513191233341695
Trained batch 1081 in epoch 2, gen_loss = 0.7781514124376716, disc_loss = 0.11513029278450526
Trained batch 1082 in epoch 2, gen_loss = 0.7783558658175411, disc_loss = 0.11504237563886774
Trained batch 1083 in epoch 2, gen_loss = 0.7783982463428455, disc_loss = 0.11497954629976784
Trained batch 1084 in epoch 2, gen_loss = 0.778184264321481, disc_loss = 0.11501545424268406
Trained batch 1085 in epoch 2, gen_loss = 0.778246134903769, disc_loss = 0.11494837584262148
Trained batch 1086 in epoch 2, gen_loss = 0.7784370863887292, disc_loss = 0.11497255476669725
Trained batch 1087 in epoch 2, gen_loss = 0.7784036408342859, disc_loss = 0.11490771915979327
Trained batch 1088 in epoch 2, gen_loss = 0.7785485004262163, disc_loss = 0.11484715786460646
Trained batch 1089 in epoch 2, gen_loss = 0.7784555640789347, disc_loss = 0.11482443353502986
Trained batch 1090 in epoch 2, gen_loss = 0.7785363569377651, disc_loss = 0.11475505520300265
Trained batch 1091 in epoch 2, gen_loss = 0.7785266851767515, disc_loss = 0.11475420971366922
Trained batch 1092 in epoch 2, gen_loss = 0.7785140885634916, disc_loss = 0.11475875766731437
Trained batch 1093 in epoch 2, gen_loss = 0.7782901625746564, disc_loss = 0.11477557572721754
Trained batch 1094 in epoch 2, gen_loss = 0.7783371924265334, disc_loss = 0.11494752183879756
Trained batch 1095 in epoch 2, gen_loss = 0.7783294126500179, disc_loss = 0.1148991644489545
Trained batch 1096 in epoch 2, gen_loss = 0.7781694323340653, disc_loss = 0.11489617402360536
Trained batch 1097 in epoch 2, gen_loss = 0.7782185495659736, disc_loss = 0.11483584109181454
Trained batch 1098 in epoch 2, gen_loss = 0.7782476551430783, disc_loss = 0.1150481224532923
Trained batch 1099 in epoch 2, gen_loss = 0.7780761804905805, disc_loss = 0.11509336155500602
Trained batch 1100 in epoch 2, gen_loss = 0.7780980262617757, disc_loss = 0.11503664283953154
Trained batch 1101 in epoch 2, gen_loss = 0.7782230212770659, disc_loss = 0.11495841780217693
Trained batch 1102 in epoch 2, gen_loss = 0.7782504502363023, disc_loss = 0.114888982456397
Trained batch 1103 in epoch 2, gen_loss = 0.7781508545512739, disc_loss = 0.11490426557999023
Trained batch 1104 in epoch 2, gen_loss = 0.7783830253247223, disc_loss = 0.11497741123046136
Trained batch 1105 in epoch 2, gen_loss = 0.7781875336148639, disc_loss = 0.11512489603313653
Trained batch 1106 in epoch 2, gen_loss = 0.7780353231481744, disc_loss = 0.11510307004535612
Trained batch 1107 in epoch 2, gen_loss = 0.7783851399748765, disc_loss = 0.11514098595219265
Trained batch 1108 in epoch 2, gen_loss = 0.7783686819110935, disc_loss = 0.11511039072051443
Trained batch 1109 in epoch 2, gen_loss = 0.7781320720105558, disc_loss = 0.11517613393816728
Trained batch 1110 in epoch 2, gen_loss = 0.7781440001366698, disc_loss = 0.11515765830213882
Trained batch 1111 in epoch 2, gen_loss = 0.7783387248679031, disc_loss = 0.11522958229929074
Trained batch 1112 in epoch 2, gen_loss = 0.7781322028651927, disc_loss = 0.1152676105397182
Trained batch 1113 in epoch 2, gen_loss = 0.7779649315231364, disc_loss = 0.11526059824053726
Trained batch 1114 in epoch 2, gen_loss = 0.7778896075193122, disc_loss = 0.11523276670280459
Trained batch 1115 in epoch 2, gen_loss = 0.7777554945065557, disc_loss = 0.11527074900068557
Trained batch 1116 in epoch 2, gen_loss = 0.7780741931288607, disc_loss = 0.11540042945736603
Trained batch 1117 in epoch 2, gen_loss = 0.7779936764875763, disc_loss = 0.11543487110933245
Trained batch 1118 in epoch 2, gen_loss = 0.7777637227291077, disc_loss = 0.11546702548392097
Trained batch 1119 in epoch 2, gen_loss = 0.7778906755149364, disc_loss = 0.1155063291604165
Trained batch 1120 in epoch 2, gen_loss = 0.7777509957844396, disc_loss = 0.11549034234747808
Trained batch 1121 in epoch 2, gen_loss = 0.7774799107283407, disc_loss = 0.1155834143139661
Trained batch 1122 in epoch 2, gen_loss = 0.7777205459634216, disc_loss = 0.11557878590937794
Trained batch 1123 in epoch 2, gen_loss = 0.7775568990467706, disc_loss = 0.11553721318727365
Trained batch 1124 in epoch 2, gen_loss = 0.7775850614706675, disc_loss = 0.11553709693004688
Trained batch 1125 in epoch 2, gen_loss = 0.7776974385362747, disc_loss = 0.1154545172924907
Trained batch 1126 in epoch 2, gen_loss = 0.7775470152457625, disc_loss = 0.11538284714974152
Trained batch 1127 in epoch 2, gen_loss = 0.7773752498658414, disc_loss = 0.11536162194105672
Trained batch 1128 in epoch 2, gen_loss = 0.7772847226861307, disc_loss = 0.11541731508516362
Trained batch 1129 in epoch 2, gen_loss = 0.7772081199736722, disc_loss = 0.11543211706922249
Trained batch 1130 in epoch 2, gen_loss = 0.7770767183719116, disc_loss = 0.11545670544440428
Trained batch 1131 in epoch 2, gen_loss = 0.7772444653795381, disc_loss = 0.11539708778949935
Trained batch 1132 in epoch 2, gen_loss = 0.7774560177683936, disc_loss = 0.115322628367564
Trained batch 1133 in epoch 2, gen_loss = 0.7773067560933885, disc_loss = 0.11538973257251123
Trained batch 1134 in epoch 2, gen_loss = 0.7775822537323451, disc_loss = 0.11533942842683734
Trained batch 1135 in epoch 2, gen_loss = 0.7774524962345899, disc_loss = 0.11530157583060635
Trained batch 1136 in epoch 2, gen_loss = 0.7776925249013759, disc_loss = 0.11533514551552981
Trained batch 1137 in epoch 2, gen_loss = 0.7775389122889624, disc_loss = 0.11534845389455216
Trained batch 1138 in epoch 2, gen_loss = 0.7772546092128418, disc_loss = 0.11543890347588183
Trained batch 1139 in epoch 2, gen_loss = 0.7773127894913942, disc_loss = 0.11546426832822984
Trained batch 1140 in epoch 2, gen_loss = 0.7771779075460826, disc_loss = 0.11545443898972897
Trained batch 1141 in epoch 2, gen_loss = 0.7772193824294987, disc_loss = 0.11547155598432948
Trained batch 1142 in epoch 2, gen_loss = 0.7770950740768736, disc_loss = 0.115522904695547
Trained batch 1143 in epoch 2, gen_loss = 0.776949254027405, disc_loss = 0.11557167677055731
Trained batch 1144 in epoch 2, gen_loss = 0.7769113904263776, disc_loss = 0.11564784211118799
Trained batch 1145 in epoch 2, gen_loss = 0.776813679782716, disc_loss = 0.11565064712074857
Trained batch 1146 in epoch 2, gen_loss = 0.7768664063062477, disc_loss = 0.11557459677857815
Trained batch 1147 in epoch 2, gen_loss = 0.7768925366864803, disc_loss = 0.11549900628493301
Trained batch 1148 in epoch 2, gen_loss = 0.7769081613050532, disc_loss = 0.1154656787990577
Trained batch 1149 in epoch 2, gen_loss = 0.7766059896479482, disc_loss = 0.1155151947028935
Trained batch 1150 in epoch 2, gen_loss = 0.7766049310344908, disc_loss = 0.11547065868595054
Trained batch 1151 in epoch 2, gen_loss = 0.776583741651848, disc_loss = 0.11552778362319158
Trained batch 1152 in epoch 2, gen_loss = 0.7766967171549487, disc_loss = 0.11545765888372377
Trained batch 1153 in epoch 2, gen_loss = 0.7765588604133299, disc_loss = 0.11543130629858973
Trained batch 1154 in epoch 2, gen_loss = 0.7763359844684601, disc_loss = 0.11552814272881458
Trained batch 1155 in epoch 2, gen_loss = 0.7766990069441729, disc_loss = 0.11550903008931726
Trained batch 1156 in epoch 2, gen_loss = 0.7768919746372961, disc_loss = 0.11550869063660181
Trained batch 1157 in epoch 2, gen_loss = 0.7766021774737535, disc_loss = 0.1156620164176639
Trained batch 1158 in epoch 2, gen_loss = 0.7767460835298863, disc_loss = 0.11560626586335064
Trained batch 1159 in epoch 2, gen_loss = 0.7766735985361296, disc_loss = 0.11558982675236747
Trained batch 1160 in epoch 2, gen_loss = 0.7767413959330675, disc_loss = 0.11554990421249038
Trained batch 1161 in epoch 2, gen_loss = 0.776582410844386, disc_loss = 0.11548845432041512
Trained batch 1162 in epoch 2, gen_loss = 0.7765205376945686, disc_loss = 0.11550135872633495
Trained batch 1163 in epoch 2, gen_loss = 0.7767075733425691, disc_loss = 0.1154313164713546
Trained batch 1164 in epoch 2, gen_loss = 0.7766378837593635, disc_loss = 0.11535868567570469
Trained batch 1165 in epoch 2, gen_loss = 0.7769085308904304, disc_loss = 0.11530119683801182
Trained batch 1166 in epoch 2, gen_loss = 0.7770240759890409, disc_loss = 0.11524810766738991
Trained batch 1167 in epoch 2, gen_loss = 0.7767045091939707, disc_loss = 0.11538135490223944
Trained batch 1168 in epoch 2, gen_loss = 0.7769931518338091, disc_loss = 0.11538132856511554
Trained batch 1169 in epoch 2, gen_loss = 0.7768801741365694, disc_loss = 0.11538851097082863
Trained batch 1170 in epoch 2, gen_loss = 0.7769514846811938, disc_loss = 0.11531955093371242
Trained batch 1171 in epoch 2, gen_loss = 0.776959707941415, disc_loss = 0.1152939829496991
Trained batch 1172 in epoch 2, gen_loss = 0.7770966622479838, disc_loss = 0.11522583253062366
Trained batch 1173 in epoch 2, gen_loss = 0.7770295079918086, disc_loss = 0.11516322181806019
Trained batch 1174 in epoch 2, gen_loss = 0.7773471633170513, disc_loss = 0.11509925830792239
Trained batch 1175 in epoch 2, gen_loss = 0.7773968248190929, disc_loss = 0.11508650161550843
Trained batch 1176 in epoch 2, gen_loss = 0.7775386846612445, disc_loss = 0.11501457818412715
Trained batch 1177 in epoch 2, gen_loss = 0.777495871501989, disc_loss = 0.11501977881353431
Trained batch 1178 in epoch 2, gen_loss = 0.7778052518537633, disc_loss = 0.11509441418385258
Trained batch 1179 in epoch 2, gen_loss = 0.7780095829044358, disc_loss = 0.11501169405104118
Trained batch 1180 in epoch 2, gen_loss = 0.7777128532011564, disc_loss = 0.114998699795174
Trained batch 1181 in epoch 2, gen_loss = 0.7777462563337206, disc_loss = 0.11490892454691849
Trained batch 1182 in epoch 2, gen_loss = 0.7777641771813116, disc_loss = 0.11486639625007887
Trained batch 1183 in epoch 2, gen_loss = 0.7775932279088207, disc_loss = 0.11486201451122258
Trained batch 1184 in epoch 2, gen_loss = 0.7777778510302934, disc_loss = 0.11478569827942406
Trained batch 1185 in epoch 2, gen_loss = 0.7780145539903721, disc_loss = 0.1147590506834435
Trained batch 1186 in epoch 2, gen_loss = 0.777872400617238, disc_loss = 0.11479428804400295
Trained batch 1187 in epoch 2, gen_loss = 0.777758433160557, disc_loss = 0.11472712665081325
Trained batch 1188 in epoch 2, gen_loss = 0.7780993585329882, disc_loss = 0.11471890127074828
Trained batch 1189 in epoch 2, gen_loss = 0.778246791422868, disc_loss = 0.11471530856768124
Trained batch 1190 in epoch 2, gen_loss = 0.7782003290507095, disc_loss = 0.11469983035818956
Trained batch 1191 in epoch 2, gen_loss = 0.7781922899736654, disc_loss = 0.11464583634355124
Trained batch 1192 in epoch 2, gen_loss = 0.7782651077571878, disc_loss = 0.1145598678549085
Trained batch 1193 in epoch 2, gen_loss = 0.7783894089598152, disc_loss = 0.11449993937393305
Trained batch 1194 in epoch 2, gen_loss = 0.7787459590943787, disc_loss = 0.11452492612908949
Trained batch 1195 in epoch 2, gen_loss = 0.7787510945047423, disc_loss = 0.11446859213729144
Trained batch 1196 in epoch 2, gen_loss = 0.7787347897551113, disc_loss = 0.11447194363274546
Trained batch 1197 in epoch 2, gen_loss = 0.778557398084408, disc_loss = 0.11445748429350518
Trained batch 1198 in epoch 2, gen_loss = 0.7789080049516361, disc_loss = 0.11448604562199419
Trained batch 1199 in epoch 2, gen_loss = 0.7786728781958421, disc_loss = 0.11451377757126466
Trained batch 1200 in epoch 2, gen_loss = 0.7785582783120955, disc_loss = 0.11455945380506642
Trained batch 1201 in epoch 2, gen_loss = 0.7785089236626808, disc_loss = 0.114618029317566
Trained batch 1202 in epoch 2, gen_loss = 0.7784194734724779, disc_loss = 0.11473658025893363
Trained batch 1203 in epoch 2, gen_loss = 0.7782977807066369, disc_loss = 0.11485340618497485
Trained batch 1204 in epoch 2, gen_loss = 0.7783331851741585, disc_loss = 0.11483265383717801
Trained batch 1205 in epoch 2, gen_loss = 0.7784288172203906, disc_loss = 0.11490751517114924
Trained batch 1206 in epoch 2, gen_loss = 0.7784324722440161, disc_loss = 0.11487899185717723
Trained batch 1207 in epoch 2, gen_loss = 0.7783520577956509, disc_loss = 0.11483522812259192
Trained batch 1208 in epoch 2, gen_loss = 0.7784333347386817, disc_loss = 0.11476582313161358
Trained batch 1209 in epoch 2, gen_loss = 0.7787123001311436, disc_loss = 0.11469410522186682
Trained batch 1210 in epoch 2, gen_loss = 0.7783852686673329, disc_loss = 0.11479709471301364
Trained batch 1211 in epoch 2, gen_loss = 0.7788010709749984, disc_loss = 0.11495403698092271
Trained batch 1212 in epoch 2, gen_loss = 0.7786441676300219, disc_loss = 0.11490924490012247
Trained batch 1213 in epoch 2, gen_loss = 0.7785026921570006, disc_loss = 0.11487856824672128
Trained batch 1214 in epoch 2, gen_loss = 0.778468837904832, disc_loss = 0.11483198111577902
Trained batch 1215 in epoch 2, gen_loss = 0.7785141661665157, disc_loss = 0.11480599204706347
Trained batch 1216 in epoch 2, gen_loss = 0.778383526629665, disc_loss = 0.11476149107654783
Trained batch 1217 in epoch 2, gen_loss = 0.7782533394389943, disc_loss = 0.11475810219651494
Trained batch 1218 in epoch 2, gen_loss = 0.7782934096330888, disc_loss = 0.11470957275272223
Trained batch 1219 in epoch 2, gen_loss = 0.7782975008741754, disc_loss = 0.11492418378179313
Trained batch 1220 in epoch 2, gen_loss = 0.7783989201892506, disc_loss = 0.11488282901481295
Trained batch 1221 in epoch 2, gen_loss = 0.778295768555955, disc_loss = 0.11487926297734222
Trained batch 1222 in epoch 2, gen_loss = 0.7783843107332681, disc_loss = 0.1148200585519802
Trained batch 1223 in epoch 2, gen_loss = 0.7784105232533287, disc_loss = 0.11488319091647985
Trained batch 1224 in epoch 2, gen_loss = 0.7783116456927085, disc_loss = 0.11484558988666656
Trained batch 1225 in epoch 2, gen_loss = 0.7783490011003628, disc_loss = 0.11478969593704062
Trained batch 1226 in epoch 2, gen_loss = 0.7781535856784022, disc_loss = 0.114770832140615
Trained batch 1227 in epoch 2, gen_loss = 0.7782236837117602, disc_loss = 0.11471984540688705
Trained batch 1228 in epoch 2, gen_loss = 0.7782804437824339, disc_loss = 0.11469299815204131
Trained batch 1229 in epoch 2, gen_loss = 0.7782398244714349, disc_loss = 0.1146532929320706
Trained batch 1230 in epoch 2, gen_loss = 0.7780051541512425, disc_loss = 0.11470817501946473
Trained batch 1231 in epoch 2, gen_loss = 0.7782319420585772, disc_loss = 0.11463447280497253
Trained batch 1232 in epoch 2, gen_loss = 0.7782955775634119, disc_loss = 0.11458920814710256
Trained batch 1233 in epoch 2, gen_loss = 0.7782696696840576, disc_loss = 0.11452281078160703
Trained batch 1234 in epoch 2, gen_loss = 0.7785377274399344, disc_loss = 0.11444096649857427
Trained batch 1235 in epoch 2, gen_loss = 0.7788545510288581, disc_loss = 0.11435965348628853
Trained batch 1236 in epoch 2, gen_loss = 0.778814489622702, disc_loss = 0.11433331708807014
Trained batch 1237 in epoch 2, gen_loss = 0.7789533920405562, disc_loss = 0.11429145822740838
Trained batch 1238 in epoch 2, gen_loss = 0.7792863219711836, disc_loss = 0.11427398145731006
Trained batch 1239 in epoch 2, gen_loss = 0.7790255455480468, disc_loss = 0.11432657867384653
Trained batch 1240 in epoch 2, gen_loss = 0.7789251825244652, disc_loss = 0.11429065112985136
Trained batch 1241 in epoch 2, gen_loss = 0.7790530960101052, disc_loss = 0.11426297277767038
Trained batch 1242 in epoch 2, gen_loss = 0.7792346671954912, disc_loss = 0.11419362178685223
Trained batch 1243 in epoch 2, gen_loss = 0.7792118615036608, disc_loss = 0.11421000498790186
Trained batch 1244 in epoch 2, gen_loss = 0.779078569876621, disc_loss = 0.11426533959791005
Trained batch 1245 in epoch 2, gen_loss = 0.7788848594955227, disc_loss = 0.11435050078492796
Trained batch 1246 in epoch 2, gen_loss = 0.7793533363481857, disc_loss = 0.11449596109040494
Trained batch 1247 in epoch 2, gen_loss = 0.7795621152155292, disc_loss = 0.11448701101023918
Trained batch 1248 in epoch 2, gen_loss = 0.7794830301602045, disc_loss = 0.11446912786002465
Trained batch 1249 in epoch 2, gen_loss = 0.7794337462663651, disc_loss = 0.11442787160351872
Trained batch 1250 in epoch 2, gen_loss = 0.7794681767717921, disc_loss = 0.1143719579981302
Trained batch 1251 in epoch 2, gen_loss = 0.7793984136785181, disc_loss = 0.11432591145902801
Trained batch 1252 in epoch 2, gen_loss = 0.7793419607286918, disc_loss = 0.11426414858924444
Trained batch 1253 in epoch 2, gen_loss = 0.7791787752171643, disc_loss = 0.11425821109195099
Trained batch 1254 in epoch 2, gen_loss = 0.7792764248838463, disc_loss = 0.11423224497259969
Trained batch 1255 in epoch 2, gen_loss = 0.779233161644761, disc_loss = 0.11421595187931897
Trained batch 1256 in epoch 2, gen_loss = 0.7796712147639494, disc_loss = 0.11428471861885788
Trained batch 1257 in epoch 2, gen_loss = 0.7794384687712538, disc_loss = 0.11441002225070979
Trained batch 1258 in epoch 2, gen_loss = 0.7795229281954958, disc_loss = 0.1143465678823773
Trained batch 1259 in epoch 2, gen_loss = 0.7795627023492541, disc_loss = 0.1143187969043437
Trained batch 1260 in epoch 2, gen_loss = 0.7795998717375354, disc_loss = 0.11424250887820614
Trained batch 1261 in epoch 2, gen_loss = 0.7797429534221414, disc_loss = 0.11418004861255007
Trained batch 1262 in epoch 2, gen_loss = 0.7798836541761034, disc_loss = 0.11412189348496833
Trained batch 1263 in epoch 2, gen_loss = 0.7798468003261693, disc_loss = 0.11410909324451173
Trained batch 1264 in epoch 2, gen_loss = 0.7798748003164299, disc_loss = 0.11405211925992499
Trained batch 1265 in epoch 2, gen_loss = 0.7798171524564613, disc_loss = 0.11402845061729894
Trained batch 1266 in epoch 2, gen_loss = 0.7799484530300631, disc_loss = 0.11396003516071904
Trained batch 1267 in epoch 2, gen_loss = 0.7798953982839825, disc_loss = 0.113928638073272
Trained batch 1268 in epoch 2, gen_loss = 0.7798754538580411, disc_loss = 0.11385517917394379
Trained batch 1269 in epoch 2, gen_loss = 0.7801913118737889, disc_loss = 0.1137968840979509
Trained batch 1270 in epoch 2, gen_loss = 0.7802452300121989, disc_loss = 0.1137737251362411
Trained batch 1271 in epoch 2, gen_loss = 0.7803319015967771, disc_loss = 0.11373914436235111
Trained batch 1272 in epoch 2, gen_loss = 0.7803893060264677, disc_loss = 0.11366485613299489
Trained batch 1273 in epoch 2, gen_loss = 0.7802397736013403, disc_loss = 0.1136333051947599
Trained batch 1274 in epoch 2, gen_loss = 0.7802112443774354, disc_loss = 0.11364032305119669
Trained batch 1275 in epoch 2, gen_loss = 0.780140822677403, disc_loss = 0.11361166011311441
Trained batch 1276 in epoch 2, gen_loss = 0.780476105987979, disc_loss = 0.11354577830229057
Trained batch 1277 in epoch 2, gen_loss = 0.7804823888113055, disc_loss = 0.11349907853889843
Trained batch 1278 in epoch 2, gen_loss = 0.7803991683485734, disc_loss = 0.11345276291947448
Trained batch 1279 in epoch 2, gen_loss = 0.7803278034087271, disc_loss = 0.11339687274085009
Trained batch 1280 in epoch 2, gen_loss = 0.7804964353198841, disc_loss = 0.11336906539649935
Trained batch 1281 in epoch 2, gen_loss = 0.7807099712713275, disc_loss = 0.11328857573251967
Trained batch 1282 in epoch 2, gen_loss = 0.7808207317153086, disc_loss = 0.11321989468510088
Trained batch 1283 in epoch 2, gen_loss = 0.7807828168445659, disc_loss = 0.11317766657261602
Trained batch 1284 in epoch 2, gen_loss = 0.7808846496422467, disc_loss = 0.11310636752977213
Trained batch 1285 in epoch 2, gen_loss = 0.7807661272689677, disc_loss = 0.11311529179192024
Trained batch 1286 in epoch 2, gen_loss = 0.780962097987521, disc_loss = 0.11333886994064873
Trained batch 1287 in epoch 2, gen_loss = 0.7810558693379349, disc_loss = 0.11330147100733998
Trained batch 1288 in epoch 2, gen_loss = 0.7810226707517685, disc_loss = 0.11328057515166867
Trained batch 1289 in epoch 2, gen_loss = 0.7807490559280381, disc_loss = 0.11329023236654294
Trained batch 1290 in epoch 2, gen_loss = 0.7809176351514369, disc_loss = 0.11324027566618693
Trained batch 1291 in epoch 2, gen_loss = 0.7809717591286813, disc_loss = 0.11322688302544202
Trained batch 1292 in epoch 2, gen_loss = 0.7808515177110509, disc_loss = 0.11326252112319234
Trained batch 1293 in epoch 2, gen_loss = 0.7808947694679317, disc_loss = 0.11323505374451831
Trained batch 1294 in epoch 2, gen_loss = 0.7810712070308596, disc_loss = 0.11318209399271426
Trained batch 1295 in epoch 2, gen_loss = 0.7810994751613449, disc_loss = 0.11314551703154718
Trained batch 1296 in epoch 2, gen_loss = 0.781043980037973, disc_loss = 0.11310777159618844
Trained batch 1297 in epoch 2, gen_loss = 0.7809642559528718, disc_loss = 0.11305609260913908
Trained batch 1298 in epoch 2, gen_loss = 0.7810577304432996, disc_loss = 0.11299312221254863
Trained batch 1299 in epoch 2, gen_loss = 0.7809602420834395, disc_loss = 0.1129540397785604
Trained batch 1300 in epoch 2, gen_loss = 0.7811285395470149, disc_loss = 0.11292262520099905
Trained batch 1301 in epoch 2, gen_loss = 0.7809727323082735, disc_loss = 0.11292486484327029
Trained batch 1302 in epoch 2, gen_loss = 0.7809191619489894, disc_loss = 0.1129179835042195
Trained batch 1303 in epoch 2, gen_loss = 0.7810151579052759, disc_loss = 0.11284503986504775
Trained batch 1304 in epoch 2, gen_loss = 0.7812083324024961, disc_loss = 0.11282081165675688
Trained batch 1305 in epoch 2, gen_loss = 0.7810983675407962, disc_loss = 0.1128110058425967
Trained batch 1306 in epoch 2, gen_loss = 0.7811357787344961, disc_loss = 0.11276939187652069
Trained batch 1307 in epoch 2, gen_loss = 0.7813122149682191, disc_loss = 0.11284035006936764
Trained batch 1308 in epoch 2, gen_loss = 0.7811374887653304, disc_loss = 0.11280711238949102
Trained batch 1309 in epoch 2, gen_loss = 0.7811736061600328, disc_loss = 0.11273670277721781
Trained batch 1310 in epoch 2, gen_loss = 0.7812257427963749, disc_loss = 0.1126814171100713
Trained batch 1311 in epoch 2, gen_loss = 0.7811264166971896, disc_loss = 0.11276916858439175
Trained batch 1312 in epoch 2, gen_loss = 0.7810188379118848, disc_loss = 0.1128254246125558
Trained batch 1313 in epoch 2, gen_loss = 0.7809857422403731, disc_loss = 0.11281654052578105
Trained batch 1314 in epoch 2, gen_loss = 0.7810557033399212, disc_loss = 0.11277098747912243
Trained batch 1315 in epoch 2, gen_loss = 0.7810335730210989, disc_loss = 0.11271517053331422
Trained batch 1316 in epoch 2, gen_loss = 0.7808963041144424, disc_loss = 0.11271963246313794
Trained batch 1317 in epoch 2, gen_loss = 0.7810718617734128, disc_loss = 0.1127015133013833
Trained batch 1318 in epoch 2, gen_loss = 0.7810364337786297, disc_loss = 0.11270176920788455
Trained batch 1319 in epoch 2, gen_loss = 0.7809367330462643, disc_loss = 0.11269644428129223
Trained batch 1320 in epoch 2, gen_loss = 0.7807579368781538, disc_loss = 0.11268985661044209
Trained batch 1321 in epoch 2, gen_loss = 0.7807417256072863, disc_loss = 0.11266241272074508
Trained batch 1322 in epoch 2, gen_loss = 0.7810388672153605, disc_loss = 0.11264751191396698
Trained batch 1323 in epoch 2, gen_loss = 0.7807894848804819, disc_loss = 0.11269529907629344
Trained batch 1324 in epoch 2, gen_loss = 0.7808911413516638, disc_loss = 0.11273443916917972
Trained batch 1325 in epoch 2, gen_loss = 0.7808674158553732, disc_loss = 0.11270880943436742
Trained batch 1326 in epoch 2, gen_loss = 0.7809077065603663, disc_loss = 0.11267451059210767
Trained batch 1327 in epoch 2, gen_loss = 0.7808728829385286, disc_loss = 0.11273086351392993
Trained batch 1328 in epoch 2, gen_loss = 0.7807587067644968, disc_loss = 0.11275216117305044
Trained batch 1329 in epoch 2, gen_loss = 0.7810168466173617, disc_loss = 0.11267906038328669
Trained batch 1330 in epoch 2, gen_loss = 0.7809729159639618, disc_loss = 0.11267054329782299
Trained batch 1331 in epoch 2, gen_loss = 0.7807197941316141, disc_loss = 0.11276837494559921
Trained batch 1332 in epoch 2, gen_loss = 0.7808588587155668, disc_loss = 0.11281710800792343
Trained batch 1333 in epoch 2, gen_loss = 0.7809097497448928, disc_loss = 0.11275810697234642
Trained batch 1334 in epoch 2, gen_loss = 0.7811424600497614, disc_loss = 0.11288675939601459
Trained batch 1335 in epoch 2, gen_loss = 0.7808446868094142, disc_loss = 0.11312721599685308
Trained batch 1336 in epoch 2, gen_loss = 0.7810694691665866, disc_loss = 0.11310805207872088
Trained batch 1337 in epoch 2, gen_loss = 0.781174357696499, disc_loss = 0.11309410301169383
Trained batch 1338 in epoch 2, gen_loss = 0.7810601451843866, disc_loss = 0.11310217141982688
Trained batch 1339 in epoch 2, gen_loss = 0.7808938361815552, disc_loss = 0.11320574881036335
Trained batch 1340 in epoch 2, gen_loss = 0.7809108774845143, disc_loss = 0.11320068285224777
Trained batch 1341 in epoch 2, gen_loss = 0.7809631247989467, disc_loss = 0.11317267318585146
Trained batch 1342 in epoch 2, gen_loss = 0.7808321462756914, disc_loss = 0.1132003664055025
Trained batch 1343 in epoch 2, gen_loss = 0.7806797379716521, disc_loss = 0.11322353591510494
Trained batch 1344 in epoch 2, gen_loss = 0.7810924891645581, disc_loss = 0.11326959728917668
Trained batch 1345 in epoch 2, gen_loss = 0.7811669597034114, disc_loss = 0.11321110791494907
Trained batch 1346 in epoch 2, gen_loss = 0.7810048472907867, disc_loss = 0.11327557573848596
Trained batch 1347 in epoch 2, gen_loss = 0.78115363220079, disc_loss = 0.11322042001383684
Trained batch 1348 in epoch 2, gen_loss = 0.7810931515923423, disc_loss = 0.11319552601388952
Trained batch 1349 in epoch 2, gen_loss = 0.7809849941288983, disc_loss = 0.11322361133440777
Trained batch 1350 in epoch 2, gen_loss = 0.7808879688437297, disc_loss = 0.11324389627152333
Trained batch 1351 in epoch 2, gen_loss = 0.7807703739439947, disc_loss = 0.1132064728402483
Trained batch 1352 in epoch 2, gen_loss = 0.7806100389821743, disc_loss = 0.1132219693233195
Trained batch 1353 in epoch 2, gen_loss = 0.7807830452390753, disc_loss = 0.11320513017761742
Trained batch 1354 in epoch 2, gen_loss = 0.7805727705524417, disc_loss = 0.1132290596644157
Trained batch 1355 in epoch 2, gen_loss = 0.7804526071500989, disc_loss = 0.11318449580706766
Trained batch 1356 in epoch 2, gen_loss = 0.7803661919246285, disc_loss = 0.11312711290746115
Trained batch 1357 in epoch 2, gen_loss = 0.7804357688846574, disc_loss = 0.11309725142993439
Trained batch 1358 in epoch 2, gen_loss = 0.780626443245553, disc_loss = 0.11310785944416647
Trained batch 1359 in epoch 2, gen_loss = 0.7804746905451312, disc_loss = 0.11313908202299738
Trained batch 1360 in epoch 2, gen_loss = 0.7803169378763083, disc_loss = 0.11317639587437467
Trained batch 1361 in epoch 2, gen_loss = 0.7803165678279516, disc_loss = 0.11313153044614672
Trained batch 1362 in epoch 2, gen_loss = 0.7804391177935541, disc_loss = 0.11313987649042469
Trained batch 1363 in epoch 2, gen_loss = 0.7804384265870642, disc_loss = 0.11313545271819812
Trained batch 1364 in epoch 2, gen_loss = 0.7805406713005387, disc_loss = 0.1130633023802887
Trained batch 1365 in epoch 2, gen_loss = 0.7802677203193416, disc_loss = 0.11312876250744848
Trained batch 1366 in epoch 2, gen_loss = 0.7803117290368111, disc_loss = 0.1131359614008096
Trained batch 1367 in epoch 2, gen_loss = 0.7803422615847044, disc_loss = 0.11311165424818119
Trained batch 1368 in epoch 2, gen_loss = 0.7801741940466655, disc_loss = 0.11307999954903818
Trained batch 1369 in epoch 2, gen_loss = 0.7801374887680486, disc_loss = 0.1130307459897858
Trained batch 1370 in epoch 2, gen_loss = 0.7803572674331484, disc_loss = 0.11306598589957348
Trained batch 1371 in epoch 2, gen_loss = 0.7803020060887838, disc_loss = 0.11305992556505079
Trained batch 1372 in epoch 2, gen_loss = 0.780133417962853, disc_loss = 0.11318791626009056
Trained batch 1373 in epoch 2, gen_loss = 0.7800610604895254, disc_loss = 0.11317331062797918
Trained batch 1374 in epoch 2, gen_loss = 0.7802985470294952, disc_loss = 0.11323406375335021
Trained batch 1375 in epoch 2, gen_loss = 0.7803898330907836, disc_loss = 0.11318196361508155
Trained batch 1376 in epoch 2, gen_loss = 0.7802375940066277, disc_loss = 0.11316235437948655
Trained batch 1377 in epoch 2, gen_loss = 0.7802168639330802, disc_loss = 0.11311073156062876
Trained batch 1378 in epoch 2, gen_loss = 0.7801495881033946, disc_loss = 0.11307903572962909
Trained batch 1379 in epoch 2, gen_loss = 0.7802737351560938, disc_loss = 0.11307867669122483
Trained batch 1380 in epoch 2, gen_loss = 0.7802789937016931, disc_loss = 0.11302080090716751
Trained batch 1381 in epoch 2, gen_loss = 0.7804432773339938, disc_loss = 0.11297371736141366
Trained batch 1382 in epoch 2, gen_loss = 0.7803325073622485, disc_loss = 0.112975505798845
Trained batch 1383 in epoch 2, gen_loss = 0.7802135458356039, disc_loss = 0.11296950991876488
Trained batch 1384 in epoch 2, gen_loss = 0.7803896600804174, disc_loss = 0.11295364008550716
Trained batch 1385 in epoch 2, gen_loss = 0.7804085432321994, disc_loss = 0.11292437600606212
Trained batch 1386 in epoch 2, gen_loss = 0.7802345911074475, disc_loss = 0.1130104834716109
Trained batch 1387 in epoch 2, gen_loss = 0.7803862303796006, disc_loss = 0.11297634078702361
Trained batch 1388 in epoch 2, gen_loss = 0.780593601918375, disc_loss = 0.11298049285892556
Trained batch 1389 in epoch 2, gen_loss = 0.7805124202434965, disc_loss = 0.11299086771704417
Trained batch 1390 in epoch 2, gen_loss = 0.7804674070615035, disc_loss = 0.11296613564839322
Trained batch 1391 in epoch 2, gen_loss = 0.7806953525106455, disc_loss = 0.11301624975180596
Trained batch 1392 in epoch 2, gen_loss = 0.7806379464103947, disc_loss = 0.11299231843200525
Trained batch 1393 in epoch 2, gen_loss = 0.7808497318279111, disc_loss = 0.11297760033242436
Trained batch 1394 in epoch 2, gen_loss = 0.7806855192962086, disc_loss = 0.11312099882738672
Trained batch 1395 in epoch 2, gen_loss = 0.7807292727097057, disc_loss = 0.11307028353675923
Trained batch 1396 in epoch 2, gen_loss = 0.7809161456167143, disc_loss = 0.11320334906858487
Trained batch 1397 in epoch 2, gen_loss = 0.7807895657373259, disc_loss = 0.11324048601157526
Trained batch 1398 in epoch 2, gen_loss = 0.7808691754223536, disc_loss = 0.113206240135492
Trained batch 1399 in epoch 2, gen_loss = 0.7808072195095676, disc_loss = 0.11315027897711843
Trained batch 1400 in epoch 2, gen_loss = 0.7808699742076569, disc_loss = 0.11318271283092221
Trained batch 1401 in epoch 2, gen_loss = 0.7808881752543715, disc_loss = 0.11313672114851833
Trained batch 1402 in epoch 2, gen_loss = 0.7807042289655377, disc_loss = 0.11318790773294882
Trained batch 1403 in epoch 2, gen_loss = 0.7808422636654642, disc_loss = 0.11318044826465307
Trained batch 1404 in epoch 2, gen_loss = 0.7808435843296323, disc_loss = 0.11316553426714236
Trained batch 1405 in epoch 2, gen_loss = 0.7807399361562594, disc_loss = 0.11319123134666134
Trained batch 1406 in epoch 2, gen_loss = 0.7806145867177927, disc_loss = 0.11319926168038838
Trained batch 1407 in epoch 2, gen_loss = 0.7805532823443752, disc_loss = 0.11322001748604552
Trained batch 1408 in epoch 2, gen_loss = 0.780875698673209, disc_loss = 0.11338899967064348
Trained batch 1409 in epoch 2, gen_loss = 0.7806488885313061, disc_loss = 0.1134558057722946
Trained batch 1410 in epoch 2, gen_loss = 0.7805256642702199, disc_loss = 0.11347599506898289
Trained batch 1411 in epoch 2, gen_loss = 0.7806982041122893, disc_loss = 0.11365991076071966
Trained batch 1412 in epoch 2, gen_loss = 0.7807634706751978, disc_loss = 0.11376784705825187
Trained batch 1413 in epoch 2, gen_loss = 0.7806295639765481, disc_loss = 0.11396132903621443
Trained batch 1414 in epoch 2, gen_loss = 0.7807856943287192, disc_loss = 0.11399432084598832
Trained batch 1415 in epoch 2, gen_loss = 0.7809376340085841, disc_loss = 0.11396445899394125
Trained batch 1416 in epoch 2, gen_loss = 0.7810460500466462, disc_loss = 0.11396904924165407
Trained batch 1417 in epoch 2, gen_loss = 0.7811216264542807, disc_loss = 0.11391374943331305
Trained batch 1418 in epoch 2, gen_loss = 0.7811157173090539, disc_loss = 0.1139118004021897
Trained batch 1419 in epoch 2, gen_loss = 0.7809721274904802, disc_loss = 0.11390100169310373
Trained batch 1420 in epoch 2, gen_loss = 0.7813215275661447, disc_loss = 0.11397652104195471
Trained batch 1421 in epoch 2, gen_loss = 0.7813418286468745, disc_loss = 0.11395658765960112
Trained batch 1422 in epoch 2, gen_loss = 0.7813411669377617, disc_loss = 0.11390052031128761
Trained batch 1423 in epoch 2, gen_loss = 0.7812302843615245, disc_loss = 0.11389463005673789
Trained batch 1424 in epoch 2, gen_loss = 0.781278649735869, disc_loss = 0.11383592799109848
Trained batch 1425 in epoch 2, gen_loss = 0.7812551117252668, disc_loss = 0.11377669888813711
Trained batch 1426 in epoch 2, gen_loss = 0.7814117052919312, disc_loss = 0.11371587976335581
Trained batch 1427 in epoch 2, gen_loss = 0.7814045809522396, disc_loss = 0.11369040456381352
Trained batch 1428 in epoch 2, gen_loss = 0.7815277506998154, disc_loss = 0.11362888481457535
Trained batch 1429 in epoch 2, gen_loss = 0.7817829691238337, disc_loss = 0.11357712732054866
Trained batch 1430 in epoch 2, gen_loss = 0.7817676961421967, disc_loss = 0.11354841400656372
Trained batch 1431 in epoch 2, gen_loss = 0.7817954199815262, disc_loss = 0.11351434836442473
Trained batch 1432 in epoch 2, gen_loss = 0.7816943506094766, disc_loss = 0.11349300272692585
Trained batch 1433 in epoch 2, gen_loss = 0.781811519792223, disc_loss = 0.11347282020053001
Trained batch 1434 in epoch 2, gen_loss = 0.7817526489807753, disc_loss = 0.11345540165628602
Trained batch 1435 in epoch 2, gen_loss = 0.7818381089644512, disc_loss = 0.11341136122384422
Trained batch 1436 in epoch 2, gen_loss = 0.7818062762336425, disc_loss = 0.11344483566503498
Trained batch 1437 in epoch 2, gen_loss = 0.7817239640526712, disc_loss = 0.11342125321946965
Trained batch 1438 in epoch 2, gen_loss = 0.781519117849912, disc_loss = 0.11345296231622058
Trained batch 1439 in epoch 2, gen_loss = 0.7815986305268274, disc_loss = 0.1134113832085859
Trained batch 1440 in epoch 2, gen_loss = 0.7815566271191914, disc_loss = 0.11337990178497176
Trained batch 1441 in epoch 2, gen_loss = 0.7816243335170653, disc_loss = 0.11341371014907997
Trained batch 1442 in epoch 2, gen_loss = 0.7815693557179808, disc_loss = 0.11338606377326504
Trained batch 1443 in epoch 2, gen_loss = 0.7814550323623369, disc_loss = 0.11337381289882323
Trained batch 1444 in epoch 2, gen_loss = 0.7815843176470496, disc_loss = 0.11340227662472886
Trained batch 1445 in epoch 2, gen_loss = 0.7815520890562037, disc_loss = 0.1134675995441589
Trained batch 1446 in epoch 2, gen_loss = 0.7815097615524416, disc_loss = 0.11343687548448217
Trained batch 1447 in epoch 2, gen_loss = 0.7813720367025605, disc_loss = 0.11347106330865964
Trained batch 1448 in epoch 2, gen_loss = 0.781258955155676, disc_loss = 0.11347393596093662
Trained batch 1449 in epoch 2, gen_loss = 0.7810838070203519, disc_loss = 0.113488837235832
Trained batch 1450 in epoch 2, gen_loss = 0.7810796081691179, disc_loss = 0.11350227496185585
Trained batch 1451 in epoch 2, gen_loss = 0.7809301374823923, disc_loss = 0.11348966012590823
Trained batch 1452 in epoch 2, gen_loss = 0.7809456936548433, disc_loss = 0.1134952044842607
Trained batch 1453 in epoch 2, gen_loss = 0.7809588200575384, disc_loss = 0.11344038508255982
Trained batch 1454 in epoch 2, gen_loss = 0.7808308624115187, disc_loss = 0.11348065181580913
Trained batch 1455 in epoch 2, gen_loss = 0.7806809447746683, disc_loss = 0.11354414026373179
Trained batch 1456 in epoch 2, gen_loss = 0.7807284770923358, disc_loss = 0.11369233148066389
Trained batch 1457 in epoch 2, gen_loss = 0.7809668376898733, disc_loss = 0.11367911575310985
Trained batch 1458 in epoch 2, gen_loss = 0.7810240998465856, disc_loss = 0.11362386750398208
Trained batch 1459 in epoch 2, gen_loss = 0.7809296801278036, disc_loss = 0.11361937115338873
Trained batch 1460 in epoch 2, gen_loss = 0.7809413339608667, disc_loss = 0.11357626277305731
Trained batch 1461 in epoch 2, gen_loss = 0.7808800874387517, disc_loss = 0.11352931762053013
Trained batch 1462 in epoch 2, gen_loss = 0.7811806460031482, disc_loss = 0.11364341525632127
Trained batch 1463 in epoch 2, gen_loss = 0.7809750739220387, disc_loss = 0.11374657572554984
Trained batch 1464 in epoch 2, gen_loss = 0.7808603747916303, disc_loss = 0.1137596184680232
Trained batch 1465 in epoch 2, gen_loss = 0.7808091579282105, disc_loss = 0.11375068763835104
Trained batch 1466 in epoch 2, gen_loss = 0.7808203488974321, disc_loss = 0.11369043223790941
Trained batch 1467 in epoch 2, gen_loss = 0.7809247807155513, disc_loss = 0.11373583243446735
Trained batch 1468 in epoch 2, gen_loss = 0.7805845493398774, disc_loss = 0.11381858365941182
Trained batch 1469 in epoch 2, gen_loss = 0.7806658502541431, disc_loss = 0.1137804729680271
Trained batch 1470 in epoch 2, gen_loss = 0.7806068477502572, disc_loss = 0.11375293449481619
Trained batch 1471 in epoch 2, gen_loss = 0.7805024721740704, disc_loss = 0.11373785009883526
Trained batch 1472 in epoch 2, gen_loss = 0.780514372119431, disc_loss = 0.11370374396688684
Trained batch 1473 in epoch 2, gen_loss = 0.7807816661075465, disc_loss = 0.11364795040437797
Trained batch 1474 in epoch 2, gen_loss = 0.78081517763057, disc_loss = 0.11367741618431726
Trained batch 1475 in epoch 2, gen_loss = 0.7807995992987783, disc_loss = 0.11364232875257832
Trained batch 1476 in epoch 2, gen_loss = 0.7806607212218063, disc_loss = 0.11365959553026576
Trained batch 1477 in epoch 2, gen_loss = 0.7807341992492121, disc_loss = 0.11368451727534039
Trained batch 1478 in epoch 2, gen_loss = 0.7807962852728536, disc_loss = 0.113687836790509
Trained batch 1479 in epoch 2, gen_loss = 0.7807077599739706, disc_loss = 0.1136745771928061
Trained batch 1480 in epoch 2, gen_loss = 0.7804595257968696, disc_loss = 0.11383252117309939
Trained batch 1481 in epoch 2, gen_loss = 0.7805611514329267, disc_loss = 0.11378480495844795
Trained batch 1482 in epoch 2, gen_loss = 0.7806032307832851, disc_loss = 0.11376110954487738
Trained batch 1483 in epoch 2, gen_loss = 0.7806458049265522, disc_loss = 0.1137077521383411
Trained batch 1484 in epoch 2, gen_loss = 0.7805224778475585, disc_loss = 0.11367714127920794
Trained batch 1485 in epoch 2, gen_loss = 0.7804623450557444, disc_loss = 0.11366279997635999
Trained batch 1486 in epoch 2, gen_loss = 0.7806124610033465, disc_loss = 0.11360974720395506
Trained batch 1487 in epoch 2, gen_loss = 0.7805521345386902, disc_loss = 0.11360024233531427
Trained batch 1488 in epoch 2, gen_loss = 0.7805286968330796, disc_loss = 0.11353177019902189
Trained batch 1489 in epoch 2, gen_loss = 0.7805401649851127, disc_loss = 0.11346539230392183
Trained batch 1490 in epoch 2, gen_loss = 0.7807086835484789, disc_loss = 0.11340955055882813
Trained batch 1491 in epoch 2, gen_loss = 0.7806517700127877, disc_loss = 0.11343595046168019
Trained batch 1492 in epoch 2, gen_loss = 0.780665769664058, disc_loss = 0.11340652277152947
Trained batch 1493 in epoch 2, gen_loss = 0.7806698428778603, disc_loss = 0.11336704722756502
Trained batch 1494 in epoch 2, gen_loss = 0.7808605739703545, disc_loss = 0.11333070879484398
Trained batch 1495 in epoch 2, gen_loss = 0.7810188705788895, disc_loss = 0.11327413797445775
Trained batch 1496 in epoch 2, gen_loss = 0.7808443821702866, disc_loss = 0.11332049239401966
Trained batch 1497 in epoch 2, gen_loss = 0.7808443405559766, disc_loss = 0.11327188957335853
Trained batch 1498 in epoch 2, gen_loss = 0.7810934914637598, disc_loss = 0.11331222291285292
Trained batch 1499 in epoch 2, gen_loss = 0.780883976538976, disc_loss = 0.11331019421853125
Trained batch 1500 in epoch 2, gen_loss = 0.7808029399880722, disc_loss = 0.11332932158716415
Trained batch 1501 in epoch 2, gen_loss = 0.7806892128346287, disc_loss = 0.1133025929315658
Trained batch 1502 in epoch 2, gen_loss = 0.7808228131539807, disc_loss = 0.11323485436216642
Trained batch 1503 in epoch 2, gen_loss = 0.781146702059406, disc_loss = 0.11326541105146579
Trained batch 1504 in epoch 2, gen_loss = 0.7809290394038457, disc_loss = 0.11333549760801848
Trained batch 1505 in epoch 2, gen_loss = 0.7807976939130431, disc_loss = 0.11332207464008218
Trained batch 1506 in epoch 2, gen_loss = 0.7809185973444599, disc_loss = 0.11337438627197478
Trained batch 1507 in epoch 2, gen_loss = 0.7807767262746548, disc_loss = 0.11337189605602851
Trained batch 1508 in epoch 2, gen_loss = 0.7806888865745171, disc_loss = 0.11335643067353604
Trained batch 1509 in epoch 2, gen_loss = 0.7807051381922716, disc_loss = 0.1133329170429154
Trained batch 1510 in epoch 2, gen_loss = 0.7806282761395175, disc_loss = 0.113354398991634
Trained batch 1511 in epoch 2, gen_loss = 0.7806864224729084, disc_loss = 0.11334712822088804
Trained batch 1512 in epoch 2, gen_loss = 0.7806226858144081, disc_loss = 0.11331587074532544
Trained batch 1513 in epoch 2, gen_loss = 0.7804642743289549, disc_loss = 0.11330662232724018
Trained batch 1514 in epoch 2, gen_loss = 0.7807750734165557, disc_loss = 0.11336058847384878
Trained batch 1515 in epoch 2, gen_loss = 0.7807354355786281, disc_loss = 0.1133222690510679
Trained batch 1516 in epoch 2, gen_loss = 0.7808079617386519, disc_loss = 0.1132616125852675
Trained batch 1517 in epoch 2, gen_loss = 0.780880294141405, disc_loss = 0.11323316079933732
Trained batch 1518 in epoch 2, gen_loss = 0.7808322984188147, disc_loss = 0.11318757516222223
Trained batch 1519 in epoch 2, gen_loss = 0.7807137560687567, disc_loss = 0.11317999909239772
Trained batch 1520 in epoch 2, gen_loss = 0.7809209891795171, disc_loss = 0.1131629906643738
Trained batch 1521 in epoch 2, gen_loss = 0.7809341988096726, disc_loss = 0.11315327289706383
Trained batch 1522 in epoch 2, gen_loss = 0.780956376170298, disc_loss = 0.11309388353173191
Trained batch 1523 in epoch 2, gen_loss = 0.7810302688850193, disc_loss = 0.11304653364201896
Trained batch 1524 in epoch 2, gen_loss = 0.7809332729167625, disc_loss = 0.11302757027818532
Trained batch 1525 in epoch 2, gen_loss = 0.7811138392822771, disc_loss = 0.11300299190800163
Trained batch 1526 in epoch 2, gen_loss = 0.7810879434411949, disc_loss = 0.11296852336636579
Trained batch 1527 in epoch 2, gen_loss = 0.7812031659234256, disc_loss = 0.11293910209367451
Trained batch 1528 in epoch 2, gen_loss = 0.7810379033232141, disc_loss = 0.11292337818330725
Trained batch 1529 in epoch 2, gen_loss = 0.7809637524333655, disc_loss = 0.11290274946250363
Trained batch 1530 in epoch 2, gen_loss = 0.7813238626909287, disc_loss = 0.11291334425372325
Trained batch 1531 in epoch 2, gen_loss = 0.7815514838337587, disc_loss = 0.11287182913217743
Trained batch 1532 in epoch 2, gen_loss = 0.781464123795877, disc_loss = 0.11285457166066103
Trained batch 1533 in epoch 2, gen_loss = 0.7812673674685081, disc_loss = 0.11287384803104548
Trained batch 1534 in epoch 2, gen_loss = 0.7813882437319243, disc_loss = 0.11283006414358507
Trained batch 1535 in epoch 2, gen_loss = 0.781679427503453, disc_loss = 0.11286415367915954
Trained batch 1536 in epoch 2, gen_loss = 0.7817107627705157, disc_loss = 0.1128193025762626
Trained batch 1537 in epoch 2, gen_loss = 0.7816882774679497, disc_loss = 0.1128116095443444
Trained batch 1538 in epoch 2, gen_loss = 0.7816812378814888, disc_loss = 0.11277784103475623
Trained batch 1539 in epoch 2, gen_loss = 0.7818577850987385, disc_loss = 0.1127513395779609
Trained batch 1540 in epoch 2, gen_loss = 0.7817326653204825, disc_loss = 0.11275761944255722
Trained batch 1541 in epoch 2, gen_loss = 0.7816010992080167, disc_loss = 0.1127716765935918
Trained batch 1542 in epoch 2, gen_loss = 0.7815297300639433, disc_loss = 0.11274881811470894
Trained batch 1543 in epoch 2, gen_loss = 0.7816945943074214, disc_loss = 0.1127145983956735
Trained batch 1544 in epoch 2, gen_loss = 0.7815532438384677, disc_loss = 0.11272608322064274
Trained batch 1545 in epoch 2, gen_loss = 0.7815176876403999, disc_loss = 0.11269019290751851
Trained batch 1546 in epoch 2, gen_loss = 0.7815121600492276, disc_loss = 0.11266309228673356
Trained batch 1547 in epoch 2, gen_loss = 0.7817946681103041, disc_loss = 0.11267059412002756
Trained batch 1548 in epoch 2, gen_loss = 0.7818922346026148, disc_loss = 0.11262913077487685
Trained batch 1549 in epoch 2, gen_loss = 0.7816721746613903, disc_loss = 0.11279990153327103
Trained batch 1550 in epoch 2, gen_loss = 0.7816196096704361, disc_loss = 0.11277879157171451
Trained batch 1551 in epoch 2, gen_loss = 0.7816892075016326, disc_loss = 0.11282043490611669
Trained batch 1552 in epoch 2, gen_loss = 0.781697619291405, disc_loss = 0.11278063289015161
Trained batch 1553 in epoch 2, gen_loss = 0.7815945656296522, disc_loss = 0.1127930057715706
Trained batch 1554 in epoch 2, gen_loss = 0.781664266118666, disc_loss = 0.11277014605844711
Trained batch 1555 in epoch 2, gen_loss = 0.7815805749062708, disc_loss = 0.11273765256915691
Trained batch 1556 in epoch 2, gen_loss = 0.781433922553874, disc_loss = 0.11280580992734462
Trained batch 1557 in epoch 2, gen_loss = 0.781487322588175, disc_loss = 0.11280852050636447
Trained batch 1558 in epoch 2, gen_loss = 0.781377100577486, disc_loss = 0.11282264692511713
Trained batch 1559 in epoch 2, gen_loss = 0.7813838582008313, disc_loss = 0.11277287256760667
Trained batch 1560 in epoch 2, gen_loss = 0.7816608386647618, disc_loss = 0.1127299453447466
Trained batch 1561 in epoch 2, gen_loss = 0.781571113078756, disc_loss = 0.11269656316557286
Trained batch 1562 in epoch 2, gen_loss = 0.7817578907967834, disc_loss = 0.11264504909024396
Trained batch 1563 in epoch 2, gen_loss = 0.7816742171183266, disc_loss = 0.11265298108810849
Trained batch 1564 in epoch 2, gen_loss = 0.7815897587008369, disc_loss = 0.1126162726741534
Trained batch 1565 in epoch 2, gen_loss = 0.7816890108554908, disc_loss = 0.11271520808581763
Trained batch 1566 in epoch 2, gen_loss = 0.7816802666076217, disc_loss = 0.11269466778062565
Trained batch 1567 in epoch 2, gen_loss = 0.7817001665125087, disc_loss = 0.11265377631786336
Trained batch 1568 in epoch 2, gen_loss = 0.781707693620272, disc_loss = 0.1126295849953946
Trained batch 1569 in epoch 2, gen_loss = 0.7818406127061054, disc_loss = 0.11258481903606729
Trained batch 1570 in epoch 2, gen_loss = 0.7818709731026109, disc_loss = 0.11256714159401073
Trained batch 1571 in epoch 2, gen_loss = 0.781966030446021, disc_loss = 0.11253744498743622
Trained batch 1572 in epoch 2, gen_loss = 0.7819426703892615, disc_loss = 0.11250719525990445
Trained batch 1573 in epoch 2, gen_loss = 0.7820989360803268, disc_loss = 0.11245580018395049
Trained batch 1574 in epoch 2, gen_loss = 0.7820897255246602, disc_loss = 0.11241952806119881
Trained batch 1575 in epoch 2, gen_loss = 0.7820161591629087, disc_loss = 0.11245426162013661
Trained batch 1576 in epoch 2, gen_loss = 0.7818498374467873, disc_loss = 0.1124860656706967
Trained batch 1577 in epoch 2, gen_loss = 0.7820727557359388, disc_loss = 0.11246586551698555
Trained batch 1578 in epoch 2, gen_loss = 0.7821461250315443, disc_loss = 0.1124120405011063
Trained batch 1579 in epoch 2, gen_loss = 0.7820398898064336, disc_loss = 0.11238009249319947
Trained batch 1580 in epoch 2, gen_loss = 0.7822238293574778, disc_loss = 0.11240182565919853
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 0.8488940596580505, disc_loss = 0.0395071804523468
Trained batch 1 in epoch 3, gen_loss = 0.7269323766231537, disc_loss = 0.08370517939329147
Trained batch 2 in epoch 3, gen_loss = 0.6677494247754415, disc_loss = 0.09416281680266063
Trained batch 3 in epoch 3, gen_loss = 0.7006131857633591, disc_loss = 0.12568049877882004
Trained batch 4 in epoch 3, gen_loss = 0.7674066662788391, disc_loss = 0.11899739652872085
Trained batch 5 in epoch 3, gen_loss = 0.7672284344832102, disc_loss = 0.11216612781087558
Trained batch 6 in epoch 3, gen_loss = 0.776012258870261, disc_loss = 0.10687890648841858
Trained batch 7 in epoch 3, gen_loss = 0.7507933005690575, disc_loss = 0.10918333567678928
Trained batch 8 in epoch 3, gen_loss = 0.7269959648450216, disc_loss = 0.10710503657658894
Trained batch 9 in epoch 3, gen_loss = 0.7429265320301056, disc_loss = 0.11688892394304276
Trained batch 10 in epoch 3, gen_loss = 0.7498728741299022, disc_loss = 0.1090554848990657
Trained batch 11 in epoch 3, gen_loss = 0.7787788758675257, disc_loss = 0.10646005316327016
Trained batch 12 in epoch 3, gen_loss = 0.760354954462785, disc_loss = 0.11023712817292947
Trained batch 13 in epoch 3, gen_loss = 0.7691664142268044, disc_loss = 0.10466494065310274
Trained batch 14 in epoch 3, gen_loss = 0.799983537197113, disc_loss = 0.10826542352636655
Trained batch 15 in epoch 3, gen_loss = 0.8065950982272625, disc_loss = 0.10370463598519564
Trained batch 16 in epoch 3, gen_loss = 0.811466700890485, disc_loss = 0.1009233436163734
Trained batch 17 in epoch 3, gen_loss = 0.8007167312833998, disc_loss = 0.09995713333288829
Trained batch 18 in epoch 3, gen_loss = 0.8184718207309121, disc_loss = 0.0972492257623296
Trained batch 19 in epoch 3, gen_loss = 0.8218634009361268, disc_loss = 0.09310208694078029
Trained batch 20 in epoch 3, gen_loss = 0.8285981587001255, disc_loss = 0.08934676997540962
Trained batch 21 in epoch 3, gen_loss = 0.8268659602512013, disc_loss = 0.0867263284850527
Trained batch 22 in epoch 3, gen_loss = 0.828224601952926, disc_loss = 0.0848519898870069
Trained batch 23 in epoch 3, gen_loss = 0.8242227286100388, disc_loss = 0.08622336383753766
Trained batch 24 in epoch 3, gen_loss = 0.8140936183929444, disc_loss = 0.08801971968263388
Trained batch 25 in epoch 3, gen_loss = 0.8234345271037176, disc_loss = 0.0887014137652631
Trained batch 26 in epoch 3, gen_loss = 0.8209848845446551, disc_loss = 0.08835156368850558
Trained batch 27 in epoch 3, gen_loss = 0.8208421213286263, disc_loss = 0.08996893728284963
Trained batch 28 in epoch 3, gen_loss = 0.8389066951028232, disc_loss = 0.08950287871191213
Trained batch 29 in epoch 3, gen_loss = 0.8345150947570801, disc_loss = 0.09049957664683461
Trained batch 30 in epoch 3, gen_loss = 0.8298169643648209, disc_loss = 0.08983092223324123
Trained batch 31 in epoch 3, gen_loss = 0.8313154969364405, disc_loss = 0.08902742268401198
Trained batch 32 in epoch 3, gen_loss = 0.8416424465901924, disc_loss = 0.08918400986515211
Trained batch 33 in epoch 3, gen_loss = 0.8373042520354775, disc_loss = 0.08862611517200575
Trained batch 34 in epoch 3, gen_loss = 0.836568626335689, disc_loss = 0.08644757119140455
Trained batch 35 in epoch 3, gen_loss = 0.828680126203431, disc_loss = 0.08748104710442324
Trained batch 36 in epoch 3, gen_loss = 0.8266581168045869, disc_loss = 0.08583460735610209
Trained batch 37 in epoch 3, gen_loss = 0.8274393630655188, disc_loss = 0.08409384473864186
Trained batch 38 in epoch 3, gen_loss = 0.8234772636340215, disc_loss = 0.08315205079718278
Trained batch 39 in epoch 3, gen_loss = 0.8302303954958916, disc_loss = 0.08391554004047067
Trained batch 40 in epoch 3, gen_loss = 0.8323060477652201, disc_loss = 0.08215338232495435
Trained batch 41 in epoch 3, gen_loss = 0.8274669931048438, disc_loss = 0.08328122916143565
Trained batch 42 in epoch 3, gen_loss = 0.8252700983091842, disc_loss = 0.08245511374674565
Trained batch 43 in epoch 3, gen_loss = 0.828927141698924, disc_loss = 0.08156998053362424
Trained batch 44 in epoch 3, gen_loss = 0.8246487551265292, disc_loss = 0.08177422752810849
Trained batch 45 in epoch 3, gen_loss = 0.8222585022449493, disc_loss = 0.08113684428288885
Trained batch 46 in epoch 3, gen_loss = 0.8228115540869693, disc_loss = 0.08327951317930475
Trained batch 47 in epoch 3, gen_loss = 0.8158238505323728, disc_loss = 0.08646786884249498
Trained batch 48 in epoch 3, gen_loss = 0.8214147163897144, disc_loss = 0.09051774643665673
Trained batch 49 in epoch 3, gen_loss = 0.822622092962265, disc_loss = 0.089378925524652
Trained batch 50 in epoch 3, gen_loss = 0.8213756610365475, disc_loss = 0.08827061290104016
Trained batch 51 in epoch 3, gen_loss = 0.818925005885271, disc_loss = 0.08783586147742775
Trained batch 52 in epoch 3, gen_loss = 0.814660907916303, disc_loss = 0.08731816072930705
Trained batch 53 in epoch 3, gen_loss = 0.8188170492649078, disc_loss = 0.0868827691991572
Trained batch 54 in epoch 3, gen_loss = 0.8162369001995433, disc_loss = 0.08689927563748577
Trained batch 55 in epoch 3, gen_loss = 0.8183940776756832, disc_loss = 0.08794359992524343
Trained batch 56 in epoch 3, gen_loss = 0.8166128815266124, disc_loss = 0.08693765129959374
Trained batch 57 in epoch 3, gen_loss = 0.8152803264815232, disc_loss = 0.08621122649517553
Trained batch 58 in epoch 3, gen_loss = 0.8220173524597943, disc_loss = 0.08603934299642757
Trained batch 59 in epoch 3, gen_loss = 0.8183233052492142, disc_loss = 0.08768091934422652
Trained batch 60 in epoch 3, gen_loss = 0.8145698123290891, disc_loss = 0.08792291667129172
Trained batch 61 in epoch 3, gen_loss = 0.8165765654656195, disc_loss = 0.08840378734373278
Trained batch 62 in epoch 3, gen_loss = 0.8147080077065362, disc_loss = 0.08817758624042783
Trained batch 63 in epoch 3, gen_loss = 0.8101142812520266, disc_loss = 0.08954829105641693
Trained batch 64 in epoch 3, gen_loss = 0.8124308907068692, disc_loss = 0.08972454426380304
Trained batch 65 in epoch 3, gen_loss = 0.8100804668484312, disc_loss = 0.08933746272867377
Trained batch 66 in epoch 3, gen_loss = 0.8112811419501234, disc_loss = 0.08920026514957201
Trained batch 67 in epoch 3, gen_loss = 0.8110995152417351, disc_loss = 0.08839792834923547
Trained batch 68 in epoch 3, gen_loss = 0.8103959992312003, disc_loss = 0.08780281413076581
Trained batch 69 in epoch 3, gen_loss = 0.8105860045978002, disc_loss = 0.08735013002795833
Trained batch 70 in epoch 3, gen_loss = 0.8071825479117918, disc_loss = 0.08788389864731842
Trained batch 71 in epoch 3, gen_loss = 0.8126758080389764, disc_loss = 0.0886869754952689
Trained batch 72 in epoch 3, gen_loss = 0.8089969329638024, disc_loss = 0.0891959999420055
Trained batch 73 in epoch 3, gen_loss = 0.806505500464826, disc_loss = 0.09093524248817482
Trained batch 74 in epoch 3, gen_loss = 0.8141473046938579, disc_loss = 0.09080584858854612
Trained batch 75 in epoch 3, gen_loss = 0.8171362665138746, disc_loss = 0.09028957926325108
Trained batch 76 in epoch 3, gen_loss = 0.8183275329602229, disc_loss = 0.08982961711945472
Trained batch 77 in epoch 3, gen_loss = 0.813714800736843, disc_loss = 0.09044465078757359
Trained batch 78 in epoch 3, gen_loss = 0.8121385861046707, disc_loss = 0.0901094263867487
Trained batch 79 in epoch 3, gen_loss = 0.8118275225162506, disc_loss = 0.08970847772434354
Trained batch 80 in epoch 3, gen_loss = 0.812156335807141, disc_loss = 0.08888241128973019
Trained batch 81 in epoch 3, gen_loss = 0.8131002187728882, disc_loss = 0.08840196734158004
Trained batch 82 in epoch 3, gen_loss = 0.8125366669103323, disc_loss = 0.08848526095410428
Trained batch 83 in epoch 3, gen_loss = 0.8088365005595344, disc_loss = 0.0897448267787695
Trained batch 84 in epoch 3, gen_loss = 0.8120966665885028, disc_loss = 0.08959489859202328
Trained batch 85 in epoch 3, gen_loss = 0.8109136750531751, disc_loss = 0.08937895765831304
Trained batch 86 in epoch 3, gen_loss = 0.8111352509465711, disc_loss = 0.08862770477245593
Trained batch 87 in epoch 3, gen_loss = 0.8096042343161323, disc_loss = 0.08864719691601666
Trained batch 88 in epoch 3, gen_loss = 0.8109855236632101, disc_loss = 0.08844635258899645
Trained batch 89 in epoch 3, gen_loss = 0.8074622564845615, disc_loss = 0.08877392278777228
Trained batch 90 in epoch 3, gen_loss = 0.8059962005405635, disc_loss = 0.0882736555822603
Trained batch 91 in epoch 3, gen_loss = 0.8066817923732426, disc_loss = 0.08797223631130613
Trained batch 92 in epoch 3, gen_loss = 0.8057091255341807, disc_loss = 0.08837146616430692
Trained batch 93 in epoch 3, gen_loss = 0.8049589871092045, disc_loss = 0.08880136011445776
Trained batch 94 in epoch 3, gen_loss = 0.8041648017732721, disc_loss = 0.08903170141734575
Trained batch 95 in epoch 3, gen_loss = 0.8054577602694432, disc_loss = 0.08854186829800408
Trained batch 96 in epoch 3, gen_loss = 0.8054256709580568, disc_loss = 0.08802860525926363
Trained batch 97 in epoch 3, gen_loss = 0.8071132740195917, disc_loss = 0.08816786646386798
Trained batch 98 in epoch 3, gen_loss = 0.8071877378405947, disc_loss = 0.08764496739163544
Trained batch 99 in epoch 3, gen_loss = 0.8037461030483246, disc_loss = 0.08901791624724865
Trained batch 100 in epoch 3, gen_loss = 0.8034529261069723, disc_loss = 0.0903088311010068
Trained batch 101 in epoch 3, gen_loss = 0.8049868129047693, disc_loss = 0.08989064651084881
Trained batch 102 in epoch 3, gen_loss = 0.8008880337465156, disc_loss = 0.09211701031738115
Trained batch 103 in epoch 3, gen_loss = 0.8050957780617934, disc_loss = 0.09165299662317221
Trained batch 104 in epoch 3, gen_loss = 0.8055504861332121, disc_loss = 0.09114444156487783
Trained batch 105 in epoch 3, gen_loss = 0.8057273811889145, disc_loss = 0.09090317139085734
Trained batch 106 in epoch 3, gen_loss = 0.8033581543191571, disc_loss = 0.09110486333336786
Trained batch 107 in epoch 3, gen_loss = 0.8015886804571858, disc_loss = 0.09143373418461394
Trained batch 108 in epoch 3, gen_loss = 0.8041726979640645, disc_loss = 0.09084883865413315
Trained batch 109 in epoch 3, gen_loss = 0.8073243385011499, disc_loss = 0.09047948115251281
Trained batch 110 in epoch 3, gen_loss = 0.8068428651706593, disc_loss = 0.09064338302558607
Trained batch 111 in epoch 3, gen_loss = 0.8054703282458442, disc_loss = 0.09065883493583117
Trained batch 112 in epoch 3, gen_loss = 0.8050563694101519, disc_loss = 0.09040577993192504
Trained batch 113 in epoch 3, gen_loss = 0.8057295465678499, disc_loss = 0.08998137215773265
Trained batch 114 in epoch 3, gen_loss = 0.8061505773793096, disc_loss = 0.08983825075885524
Trained batch 115 in epoch 3, gen_loss = 0.805318470145094, disc_loss = 0.0899106095834025
Trained batch 116 in epoch 3, gen_loss = 0.8054155834719666, disc_loss = 0.08967831463385852
Trained batch 117 in epoch 3, gen_loss = 0.8050077820228319, disc_loss = 0.0892198841576859
Trained batch 118 in epoch 3, gen_loss = 0.8043248533200817, disc_loss = 0.08932304219538424
Trained batch 119 in epoch 3, gen_loss = 0.8028787354628245, disc_loss = 0.089244679796199
Trained batch 120 in epoch 3, gen_loss = 0.8043588606779241, disc_loss = 0.08944017858790958
Trained batch 121 in epoch 3, gen_loss = 0.804030427190124, disc_loss = 0.08900435708585333
Trained batch 122 in epoch 3, gen_loss = 0.8019636350918592, disc_loss = 0.08933644154207493
Trained batch 123 in epoch 3, gen_loss = 0.8033430581131289, disc_loss = 0.08915124563199858
Trained batch 124 in epoch 3, gen_loss = 0.8062971529960632, disc_loss = 0.08894851350784302
Trained batch 125 in epoch 3, gen_loss = 0.8091547077610379, disc_loss = 0.08850561936814634
Trained batch 126 in epoch 3, gen_loss = 0.808028067660144, disc_loss = 0.09044819674271298
Trained batch 127 in epoch 3, gen_loss = 0.8100343351252377, disc_loss = 0.08988809387665242
Trained batch 128 in epoch 3, gen_loss = 0.812331688034442, disc_loss = 0.0894267347807339
Trained batch 129 in epoch 3, gen_loss = 0.8131423963950231, disc_loss = 0.08941566991404845
Trained batch 130 in epoch 3, gen_loss = 0.8129135447604056, disc_loss = 0.0890884674260862
Trained batch 131 in epoch 3, gen_loss = 0.8113340216152596, disc_loss = 0.08935569436994917
Trained batch 132 in epoch 3, gen_loss = 0.8098111112314955, disc_loss = 0.08946499207470202
Trained batch 133 in epoch 3, gen_loss = 0.8097933472982094, disc_loss = 0.08941326002632059
Trained batch 134 in epoch 3, gen_loss = 0.8089264697498746, disc_loss = 0.08953488073139279
Trained batch 135 in epoch 3, gen_loss = 0.8096952021998518, disc_loss = 0.08898849145043641
Trained batch 136 in epoch 3, gen_loss = 0.8135581925837663, disc_loss = 0.08872336046566276
Trained batch 137 in epoch 3, gen_loss = 0.8137434561183488, disc_loss = 0.0883894377604019
Trained batch 138 in epoch 3, gen_loss = 0.8132415336670635, disc_loss = 0.08830127517337637
Trained batch 139 in epoch 3, gen_loss = 0.8125025872673307, disc_loss = 0.08813154942888235
Trained batch 140 in epoch 3, gen_loss = 0.811727487026377, disc_loss = 0.08807675039118275
Trained batch 141 in epoch 3, gen_loss = 0.8158875347023279, disc_loss = 0.09125551828642336
Trained batch 142 in epoch 3, gen_loss = 0.8142135401705762, disc_loss = 0.09261074657649636
Trained batch 143 in epoch 3, gen_loss = 0.8135514797435867, disc_loss = 0.09283818744976695
Trained batch 144 in epoch 3, gen_loss = 0.8119752476955282, disc_loss = 0.09370970444047245
Trained batch 145 in epoch 3, gen_loss = 0.8086997805392906, disc_loss = 0.0946011096813193
Trained batch 146 in epoch 3, gen_loss = 0.8068817411961199, disc_loss = 0.09523912702313289
Trained batch 147 in epoch 3, gen_loss = 0.8056206385026107, disc_loss = 0.09547168223464207
Trained batch 148 in epoch 3, gen_loss = 0.806316660554617, disc_loss = 0.09553315606118248
Trained batch 149 in epoch 3, gen_loss = 0.8051699658234914, disc_loss = 0.09563119332616528
Trained batch 150 in epoch 3, gen_loss = 0.8044124743006876, disc_loss = 0.09588626718506316
Trained batch 151 in epoch 3, gen_loss = 0.8030131612169115, disc_loss = 0.09626156298174082
Trained batch 152 in epoch 3, gen_loss = 0.8046102660154205, disc_loss = 0.0961572754872488
Trained batch 153 in epoch 3, gen_loss = 0.8039189658381722, disc_loss = 0.09704929948844887
Trained batch 154 in epoch 3, gen_loss = 0.802592820121396, disc_loss = 0.0973955119869882
Trained batch 155 in epoch 3, gen_loss = 0.8009879405681903, disc_loss = 0.09757637557907937
Trained batch 156 in epoch 3, gen_loss = 0.8009970727240204, disc_loss = 0.09769875286324958
Trained batch 157 in epoch 3, gen_loss = 0.8004222957393791, disc_loss = 0.09751149602352252
Trained batch 158 in epoch 3, gen_loss = 0.7999405366069866, disc_loss = 0.09726346760355639
Trained batch 159 in epoch 3, gen_loss = 0.7998830139636993, disc_loss = 0.09769518462126144
Trained batch 160 in epoch 3, gen_loss = 0.7981126745295081, disc_loss = 0.0979976358169817
Trained batch 161 in epoch 3, gen_loss = 0.7972867444709495, disc_loss = 0.09830342530399377
Trained batch 162 in epoch 3, gen_loss = 0.7980675448669247, disc_loss = 0.09790845588420981
Trained batch 163 in epoch 3, gen_loss = 0.7979201187447804, disc_loss = 0.09752589982661714
Trained batch 164 in epoch 3, gen_loss = 0.7987258557117347, disc_loss = 0.09706268405936884
Trained batch 165 in epoch 3, gen_loss = 0.7982618851834032, disc_loss = 0.09665396281641471
Trained batch 166 in epoch 3, gen_loss = 0.7968531468671239, disc_loss = 0.09659970990621937
Trained batch 167 in epoch 3, gen_loss = 0.7960927227423304, disc_loss = 0.09627075891919612
Trained batch 168 in epoch 3, gen_loss = 0.7965571090314515, disc_loss = 0.09787779208272696
Trained batch 169 in epoch 3, gen_loss = 0.7961915934787077, disc_loss = 0.09765661428408588
Trained batch 170 in epoch 3, gen_loss = 0.7938897275088126, disc_loss = 0.09820455887316785
Trained batch 171 in epoch 3, gen_loss = 0.7946561110574145, disc_loss = 0.09804476961645103
Trained batch 172 in epoch 3, gen_loss = 0.7960962691059003, disc_loss = 0.09812055165863279
Trained batch 173 in epoch 3, gen_loss = 0.7945444594169485, disc_loss = 0.09953073685689048
Trained batch 174 in epoch 3, gen_loss = 0.7959912923404149, disc_loss = 0.09928237173706293
Trained batch 175 in epoch 3, gen_loss = 0.7972441400316629, disc_loss = 0.09963340269380504
Trained batch 176 in epoch 3, gen_loss = 0.7964563117188922, disc_loss = 0.09969735532304493
Trained batch 177 in epoch 3, gen_loss = 0.7958011828111798, disc_loss = 0.09975402123619163
Trained batch 178 in epoch 3, gen_loss = 0.7944036375876912, disc_loss = 0.09977648760499068
Trained batch 179 in epoch 3, gen_loss = 0.795256894826889, disc_loss = 0.09939461912856334
Trained batch 180 in epoch 3, gen_loss = 0.7968697277880505, disc_loss = 0.0993247466388246
Trained batch 181 in epoch 3, gen_loss = 0.7963691412747561, disc_loss = 0.09929620993968385
Trained batch 182 in epoch 3, gen_loss = 0.7952571048762629, disc_loss = 0.09954354862677432
Trained batch 183 in epoch 3, gen_loss = 0.7934204965181972, disc_loss = 0.09957873427977218
Trained batch 184 in epoch 3, gen_loss = 0.7945804045007036, disc_loss = 0.09973246200966673
Trained batch 185 in epoch 3, gen_loss = 0.7948347374957095, disc_loss = 0.09938336688003713
Trained batch 186 in epoch 3, gen_loss = 0.7952599168461274, disc_loss = 0.09911126120982164
Trained batch 187 in epoch 3, gen_loss = 0.7958270609378815, disc_loss = 0.09902437347819672
Trained batch 188 in epoch 3, gen_loss = 0.7954643220497818, disc_loss = 0.09913563546502874
Trained batch 189 in epoch 3, gen_loss = 0.7942576273491508, disc_loss = 0.0995908838304642
Trained batch 190 in epoch 3, gen_loss = 0.7940451434145424, disc_loss = 0.09944882138061742
Trained batch 191 in epoch 3, gen_loss = 0.7941435578589638, disc_loss = 0.09952533384299993
Trained batch 192 in epoch 3, gen_loss = 0.7936528868625818, disc_loss = 0.09920323377118055
Trained batch 193 in epoch 3, gen_loss = 0.7929895996432943, disc_loss = 0.0997192913752779
Trained batch 194 in epoch 3, gen_loss = 0.7922832406484164, disc_loss = 0.09953080613930256
Trained batch 195 in epoch 3, gen_loss = 0.7914458184826131, disc_loss = 0.0995890937546002
Trained batch 196 in epoch 3, gen_loss = 0.7923650720397833, disc_loss = 0.09929886045700251
Trained batch 197 in epoch 3, gen_loss = 0.7920811630860723, disc_loss = 0.09921039604685372
Trained batch 198 in epoch 3, gen_loss = 0.7915335654014319, disc_loss = 0.09906993650517722
Trained batch 199 in epoch 3, gen_loss = 0.7938607722520828, disc_loss = 0.09923348890151829
Trained batch 200 in epoch 3, gen_loss = 0.7925920201771295, disc_loss = 0.09912640050479873
Trained batch 201 in epoch 3, gen_loss = 0.791542524453437, disc_loss = 0.0993728701274215
Trained batch 202 in epoch 3, gen_loss = 0.793851775195211, disc_loss = 0.09944548286736159
Trained batch 203 in epoch 3, gen_loss = 0.7934272619439107, disc_loss = 0.09952220588685105
Trained batch 204 in epoch 3, gen_loss = 0.7940249632044536, disc_loss = 0.09928718686739846
Trained batch 205 in epoch 3, gen_loss = 0.7950132604941581, disc_loss = 0.09898602522602215
Trained batch 206 in epoch 3, gen_loss = 0.7936910520429197, disc_loss = 0.09957989043857596
Trained batch 207 in epoch 3, gen_loss = 0.792830464645074, disc_loss = 0.09961581084644422
Trained batch 208 in epoch 3, gen_loss = 0.7928357175662757, disc_loss = 0.09990334137828584
Trained batch 209 in epoch 3, gen_loss = 0.7922599676109495, disc_loss = 0.10034102511459163
Trained batch 210 in epoch 3, gen_loss = 0.7913532830527609, disc_loss = 0.1005857776612114
Trained batch 211 in epoch 3, gen_loss = 0.7910710154276974, disc_loss = 0.10074734003810247
Trained batch 212 in epoch 3, gen_loss = 0.792382945197289, disc_loss = 0.10091692717754645
Trained batch 213 in epoch 3, gen_loss = 0.7923862051183932, disc_loss = 0.10062106242229309
Trained batch 214 in epoch 3, gen_loss = 0.7922676568807557, disc_loss = 0.10045126780087865
Trained batch 215 in epoch 3, gen_loss = 0.7910524101720916, disc_loss = 0.10063452473237973
Trained batch 216 in epoch 3, gen_loss = 0.7923017534242797, disc_loss = 0.10079255411272636
Trained batch 217 in epoch 3, gen_loss = 0.7931405595683176, disc_loss = 0.10108546358575925
Trained batch 218 in epoch 3, gen_loss = 0.7925967408097498, disc_loss = 0.10098469763841122
Trained batch 219 in epoch 3, gen_loss = 0.7921142800287767, disc_loss = 0.10074290514246306
Trained batch 220 in epoch 3, gen_loss = 0.7913140441497527, disc_loss = 0.10139548167906601
Trained batch 221 in epoch 3, gen_loss = 0.7908002508653177, disc_loss = 0.10148431974471556
Trained batch 222 in epoch 3, gen_loss = 0.7907243779956492, disc_loss = 0.10122267143057467
Trained batch 223 in epoch 3, gen_loss = 0.7903279257672173, disc_loss = 0.10100285320991784
Trained batch 224 in epoch 3, gen_loss = 0.7901297669940525, disc_loss = 0.10105291659219398
Trained batch 225 in epoch 3, gen_loss = 0.789817340078607, disc_loss = 0.10106777724092908
Trained batch 226 in epoch 3, gen_loss = 0.7896211173565902, disc_loss = 0.10091655787966719
Trained batch 227 in epoch 3, gen_loss = 0.78950865331449, disc_loss = 0.10082689814449272
Trained batch 228 in epoch 3, gen_loss = 0.7891013455703269, disc_loss = 0.10067705010922065
Trained batch 229 in epoch 3, gen_loss = 0.7899407692577528, disc_loss = 0.10031154576446051
Trained batch 230 in epoch 3, gen_loss = 0.7895699685270136, disc_loss = 0.10039144492752496
Trained batch 231 in epoch 3, gen_loss = 0.7887989120750591, disc_loss = 0.10051163976032544
Trained batch 232 in epoch 3, gen_loss = 0.7894469663308925, disc_loss = 0.10139836744673135
Trained batch 233 in epoch 3, gen_loss = 0.7897418411368997, disc_loss = 0.10111124354661402
Trained batch 234 in epoch 3, gen_loss = 0.7913393253975726, disc_loss = 0.10085261674558228
Trained batch 235 in epoch 3, gen_loss = 0.7912286868539907, disc_loss = 0.10096539053039909
Trained batch 236 in epoch 3, gen_loss = 0.7912370321116869, disc_loss = 0.1013362735376265
Trained batch 237 in epoch 3, gen_loss = 0.7916985472210315, disc_loss = 0.10100406024432859
Trained batch 238 in epoch 3, gen_loss = 0.7908610591828573, disc_loss = 0.10093105816239467
Trained batch 239 in epoch 3, gen_loss = 0.7908279267450173, disc_loss = 0.10131293402907128
Trained batch 240 in epoch 3, gen_loss = 0.7918915543318784, disc_loss = 0.10114947908569545
Trained batch 241 in epoch 3, gen_loss = 0.7907569472454796, disc_loss = 0.10179154717648202
Trained batch 242 in epoch 3, gen_loss = 0.7903708042921843, disc_loss = 0.10163574108907593
Trained batch 243 in epoch 3, gen_loss = 0.7913973981239757, disc_loss = 0.10135266399698058
Trained batch 244 in epoch 3, gen_loss = 0.7917993618517506, disc_loss = 0.10125770895380755
Trained batch 245 in epoch 3, gen_loss = 0.7925641665129157, disc_loss = 0.10101651611957486
Trained batch 246 in epoch 3, gen_loss = 0.7919208704218691, disc_loss = 0.10101430784337796
Trained batch 247 in epoch 3, gen_loss = 0.7931091040372849, disc_loss = 0.10080511056472577
Trained batch 248 in epoch 3, gen_loss = 0.7924272269608984, disc_loss = 0.1008332711588367
Trained batch 249 in epoch 3, gen_loss = 0.7925799157619476, disc_loss = 0.10061558279022574
Trained batch 250 in epoch 3, gen_loss = 0.7921340662644679, disc_loss = 0.10089648027804149
Trained batch 251 in epoch 3, gen_loss = 0.7917532909011084, disc_loss = 0.1009828782352131
Trained batch 252 in epoch 3, gen_loss = 0.7927590888950664, disc_loss = 0.1007434618677723
Trained batch 253 in epoch 3, gen_loss = 0.7908800023747241, disc_loss = 0.10189141650999507
Trained batch 254 in epoch 3, gen_loss = 0.7920910718394261, disc_loss = 0.1016233615102429
Trained batch 255 in epoch 3, gen_loss = 0.7917383001185954, disc_loss = 0.10166369124999619
Trained batch 256 in epoch 3, gen_loss = 0.7914036067079477, disc_loss = 0.10149379080009252
Trained batch 257 in epoch 3, gen_loss = 0.7922512080318244, disc_loss = 0.10139679411686091
Trained batch 258 in epoch 3, gen_loss = 0.7925589632343601, disc_loss = 0.10155218896819243
Trained batch 259 in epoch 3, gen_loss = 0.791029134278114, disc_loss = 0.10202469378351592
Trained batch 260 in epoch 3, gen_loss = 0.7905666532415997, disc_loss = 0.10176446151445082
Trained batch 261 in epoch 3, gen_loss = 0.7913022738604145, disc_loss = 0.10157773677501401
Trained batch 262 in epoch 3, gen_loss = 0.7912549991798038, disc_loss = 0.10135030593128146
Trained batch 263 in epoch 3, gen_loss = 0.7918167180861487, disc_loss = 0.1011537866010754
Trained batch 264 in epoch 3, gen_loss = 0.7923536456980795, disc_loss = 0.10084140976574624
Trained batch 265 in epoch 3, gen_loss = 0.793781564087796, disc_loss = 0.10059532069047927
Trained batch 266 in epoch 3, gen_loss = 0.7929672053020992, disc_loss = 0.10076233861472611
Trained batch 267 in epoch 3, gen_loss = 0.7931984904319492, disc_loss = 0.10054353079341574
Trained batch 268 in epoch 3, gen_loss = 0.7944322063355641, disc_loss = 0.10032369661383801
Trained batch 269 in epoch 3, gen_loss = 0.7935628878849524, disc_loss = 0.1005833667151078
Trained batch 270 in epoch 3, gen_loss = 0.7940519061695606, disc_loss = 0.10125160750304091
Trained batch 271 in epoch 3, gen_loss = 0.7935651495833608, disc_loss = 0.10126587605747558
Trained batch 272 in epoch 3, gen_loss = 0.7949011167545459, disc_loss = 0.10094320947720563
Trained batch 273 in epoch 3, gen_loss = 0.7956607941075833, disc_loss = 0.10080731120708324
Trained batch 274 in epoch 3, gen_loss = 0.7946030177853324, disc_loss = 0.10119067061015151
Trained batch 275 in epoch 3, gen_loss = 0.7938473165251206, disc_loss = 0.10102912821752978
Trained batch 276 in epoch 3, gen_loss = 0.7944332026617622, disc_loss = 0.10073748940689362
Trained batch 277 in epoch 3, gen_loss = 0.7938623896820082, disc_loss = 0.10066952049504403
Trained batch 278 in epoch 3, gen_loss = 0.7942927132584288, disc_loss = 0.10077721502391561
Trained batch 279 in epoch 3, gen_loss = 0.7943152256309987, disc_loss = 0.10051379292604647
Trained batch 280 in epoch 3, gen_loss = 0.7944173336665401, disc_loss = 0.10028675004667553
Trained batch 281 in epoch 3, gen_loss = 0.7945649191631493, disc_loss = 0.10007500450014539
Trained batch 282 in epoch 3, gen_loss = 0.7944251196755117, disc_loss = 0.09992843105164834
Trained batch 283 in epoch 3, gen_loss = 0.7943656418315121, disc_loss = 0.0996862249809619
Trained batch 284 in epoch 3, gen_loss = 0.7946055528364684, disc_loss = 0.0994016711289684
Trained batch 285 in epoch 3, gen_loss = 0.7948263157289345, disc_loss = 0.09933175994864815
Trained batch 286 in epoch 3, gen_loss = 0.7952300344402367, disc_loss = 0.09911174968676804
Trained batch 287 in epoch 3, gen_loss = 0.7948396206936903, disc_loss = 0.09913439917080621
Trained batch 288 in epoch 3, gen_loss = 0.7950528650754051, disc_loss = 0.09900809082308958
Trained batch 289 in epoch 3, gen_loss = 0.7961844638503831, disc_loss = 0.0988527510604211
Trained batch 290 in epoch 3, gen_loss = 0.7959894260385192, disc_loss = 0.09862790767845932
Trained batch 291 in epoch 3, gen_loss = 0.7946898736161728, disc_loss = 0.09928817706731187
Trained batch 292 in epoch 3, gen_loss = 0.7958254141815694, disc_loss = 0.09923306963511397
Trained batch 293 in epoch 3, gen_loss = 0.7977787981025216, disc_loss = 0.09969333520311179
Trained batch 294 in epoch 3, gen_loss = 0.7972801088276557, disc_loss = 0.09971902892309226
Trained batch 295 in epoch 3, gen_loss = 0.7964771610458155, disc_loss = 0.10028771367993809
Trained batch 296 in epoch 3, gen_loss = 0.7970928414301439, disc_loss = 0.10005648779410004
Trained batch 297 in epoch 3, gen_loss = 0.7975035186781979, disc_loss = 0.10004838917641931
Trained batch 298 in epoch 3, gen_loss = 0.796801121637574, disc_loss = 0.10074421510810537
Trained batch 299 in epoch 3, gen_loss = 0.7959330873688062, disc_loss = 0.10068942237955829
Trained batch 300 in epoch 3, gen_loss = 0.7960549407821161, disc_loss = 0.1005113888129691
Trained batch 301 in epoch 3, gen_loss = 0.7953855416040547, disc_loss = 0.10061939138709414
Trained batch 302 in epoch 3, gen_loss = 0.7963325584879016, disc_loss = 0.10061528119673528
Trained batch 303 in epoch 3, gen_loss = 0.7965239324655972, disc_loss = 0.10062436618854438
Trained batch 304 in epoch 3, gen_loss = 0.7957320360863795, disc_loss = 0.10085066304404716
Trained batch 305 in epoch 3, gen_loss = 0.7952689056108201, disc_loss = 0.10090602054473718
Trained batch 306 in epoch 3, gen_loss = 0.7953098939567902, disc_loss = 0.10069737432020981
Trained batch 307 in epoch 3, gen_loss = 0.7956863422091905, disc_loss = 0.10077690997451254
Trained batch 308 in epoch 3, gen_loss = 0.7955080437621638, disc_loss = 0.10077079018113778
Trained batch 309 in epoch 3, gen_loss = 0.7953737965514583, disc_loss = 0.10079793994044585
Trained batch 310 in epoch 3, gen_loss = 0.7950940294089425, disc_loss = 0.10084636875059923
Trained batch 311 in epoch 3, gen_loss = 0.795261319535665, disc_loss = 0.10165386366693732
Trained batch 312 in epoch 3, gen_loss = 0.7950030819486125, disc_loss = 0.10157418807153218
Trained batch 313 in epoch 3, gen_loss = 0.7944822785011523, disc_loss = 0.10161650856173816
Trained batch 314 in epoch 3, gen_loss = 0.7948199524765923, disc_loss = 0.10147859946425472
Trained batch 315 in epoch 3, gen_loss = 0.7944566814016693, disc_loss = 0.1013111268447217
Trained batch 316 in epoch 3, gen_loss = 0.7953551047795955, disc_loss = 0.10134042186327631
Trained batch 317 in epoch 3, gen_loss = 0.7955494197846958, disc_loss = 0.10134663599478842
Trained batch 318 in epoch 3, gen_loss = 0.7954919623170154, disc_loss = 0.10117966961115599
Trained batch 319 in epoch 3, gen_loss = 0.7951810141094029, disc_loss = 0.10110945088381414
Trained batch 320 in epoch 3, gen_loss = 0.7957403489919467, disc_loss = 0.10083703861812658
Trained batch 321 in epoch 3, gen_loss = 0.7963709349032515, disc_loss = 0.10079425499595193
Trained batch 322 in epoch 3, gen_loss = 0.7963844994457883, disc_loss = 0.100681329477613
Trained batch 323 in epoch 3, gen_loss = 0.7957649053430852, disc_loss = 0.10056675825969397
Trained batch 324 in epoch 3, gen_loss = 0.7956761986475724, disc_loss = 0.1004613090507113
Trained batch 325 in epoch 3, gen_loss = 0.7954423402898883, disc_loss = 0.10030900890670397
Trained batch 326 in epoch 3, gen_loss = 0.7956028415704721, disc_loss = 0.10038866966518514
Trained batch 327 in epoch 3, gen_loss = 0.796594193886693, disc_loss = 0.10017120897508704
Trained batch 328 in epoch 3, gen_loss = 0.7970958891067099, disc_loss = 0.0999081021593742
Trained batch 329 in epoch 3, gen_loss = 0.7970869693792227, disc_loss = 0.09970774706170867
Trained batch 330 in epoch 3, gen_loss = 0.7978413736171953, disc_loss = 0.09959494560292931
Trained batch 331 in epoch 3, gen_loss = 0.7980202042374266, disc_loss = 0.09938077497610216
Trained batch 332 in epoch 3, gen_loss = 0.7981708829288368, disc_loss = 0.09919739802376376
Trained batch 333 in epoch 3, gen_loss = 0.7986886805581476, disc_loss = 0.09899675260816594
Trained batch 334 in epoch 3, gen_loss = 0.7989714570009886, disc_loss = 0.09925774984450927
Trained batch 335 in epoch 3, gen_loss = 0.7996426498783487, disc_loss = 0.09900227412193392
Trained batch 336 in epoch 3, gen_loss = 0.7993523912719873, disc_loss = 0.09899905977566183
Trained batch 337 in epoch 3, gen_loss = 0.7995804117099773, disc_loss = 0.09876511714107097
Trained batch 338 in epoch 3, gen_loss = 0.7992173126489364, disc_loss = 0.09868783559540292
Trained batch 339 in epoch 3, gen_loss = 0.8003684470758718, disc_loss = 0.09895459558979115
Trained batch 340 in epoch 3, gen_loss = 0.8001572347281616, disc_loss = 0.09883357867150624
Trained batch 341 in epoch 3, gen_loss = 0.7990710881718418, disc_loss = 0.09894499625760125
Trained batch 342 in epoch 3, gen_loss = 0.8001120326817904, disc_loss = 0.09876188469382748
Trained batch 343 in epoch 3, gen_loss = 0.8003198604944141, disc_loss = 0.09873011527139
Trained batch 344 in epoch 3, gen_loss = 0.8003939048103664, disc_loss = 0.09864836115714
Trained batch 345 in epoch 3, gen_loss = 0.7999141188715234, disc_loss = 0.0986344226086889
Trained batch 346 in epoch 3, gen_loss = 0.8000832804685367, disc_loss = 0.09844858571618624
Trained batch 347 in epoch 3, gen_loss = 0.8005042154898588, disc_loss = 0.09826951188934517
Trained batch 348 in epoch 3, gen_loss = 0.8015272542193831, disc_loss = 0.09837234137382327
Trained batch 349 in epoch 3, gen_loss = 0.8011199239322118, disc_loss = 0.09841934316658547
Trained batch 350 in epoch 3, gen_loss = 0.8008188311530654, disc_loss = 0.09844603879573594
Trained batch 351 in epoch 3, gen_loss = 0.8010732993822206, disc_loss = 0.09825386154856956
Trained batch 352 in epoch 3, gen_loss = 0.801880835642558, disc_loss = 0.09828211604841793
Trained batch 353 in epoch 3, gen_loss = 0.8013692914092608, disc_loss = 0.09860189365601893
Trained batch 354 in epoch 3, gen_loss = 0.8012585485485239, disc_loss = 0.09845812890783583
Trained batch 355 in epoch 3, gen_loss = 0.8008274350608333, disc_loss = 0.0984822692208285
Trained batch 356 in epoch 3, gen_loss = 0.8019743174397979, disc_loss = 0.09906306267254242
Trained batch 357 in epoch 3, gen_loss = 0.8013045118507727, disc_loss = 0.0993934750021045
Trained batch 358 in epoch 3, gen_loss = 0.8011489366090397, disc_loss = 0.09940173436724127
Trained batch 359 in epoch 3, gen_loss = 0.8021109309461382, disc_loss = 0.09936614230326894
Trained batch 360 in epoch 3, gen_loss = 0.8017285585073223, disc_loss = 0.09931743823229193
Trained batch 361 in epoch 3, gen_loss = 0.8017979601799454, disc_loss = 0.09931576500250572
Trained batch 362 in epoch 3, gen_loss = 0.8011816884532119, disc_loss = 0.09945331552109525
Trained batch 363 in epoch 3, gen_loss = 0.8017409230981555, disc_loss = 0.09956970406890653
Trained batch 364 in epoch 3, gen_loss = 0.8016509568854554, disc_loss = 0.09940769022509252
Trained batch 365 in epoch 3, gen_loss = 0.8013995846763986, disc_loss = 0.09931611529515823
Trained batch 366 in epoch 3, gen_loss = 0.8009272100815007, disc_loss = 0.09924629721689046
Trained batch 367 in epoch 3, gen_loss = 0.8011552124567654, disc_loss = 0.09923913108397518
Trained batch 368 in epoch 3, gen_loss = 0.8004757782954187, disc_loss = 0.09935587803330928
Trained batch 369 in epoch 3, gen_loss = 0.8002946003063305, disc_loss = 0.09933954883316481
Trained batch 370 in epoch 3, gen_loss = 0.7996509242250591, disc_loss = 0.09930033237997171
Trained batch 371 in epoch 3, gen_loss = 0.7988413811050435, disc_loss = 0.09925668437524589
Trained batch 372 in epoch 3, gen_loss = 0.8004800584616674, disc_loss = 0.0998076725346673
Trained batch 373 in epoch 3, gen_loss = 0.800151597847913, disc_loss = 0.09970096849592373
Trained batch 374 in epoch 3, gen_loss = 0.8007813045183818, disc_loss = 0.09983997277667125
Trained batch 375 in epoch 3, gen_loss = 0.8005134709020878, disc_loss = 0.09994519315907692
Trained batch 376 in epoch 3, gen_loss = 0.8005402026505306, disc_loss = 0.09978195083443699
Trained batch 377 in epoch 3, gen_loss = 0.8005996061065209, disc_loss = 0.09975515407751556
Trained batch 378 in epoch 3, gen_loss = 0.8001458382229063, disc_loss = 0.09968832889350628
Trained batch 379 in epoch 3, gen_loss = 0.8004387885332107, disc_loss = 0.09993824471817597
Trained batch 380 in epoch 3, gen_loss = 0.8006009403176195, disc_loss = 0.09972805158526019
Trained batch 381 in epoch 3, gen_loss = 0.800198312361203, disc_loss = 0.09976141720629877
Trained batch 382 in epoch 3, gen_loss = 0.800487218731066, disc_loss = 0.09957932882915511
Trained batch 383 in epoch 3, gen_loss = 0.8007199534525474, disc_loss = 0.09937377417372772
Trained batch 384 in epoch 3, gen_loss = 0.8011617256449415, disc_loss = 0.09915640222803726
Trained batch 385 in epoch 3, gen_loss = 0.8018163956817568, disc_loss = 0.09916224660969537
Trained batch 386 in epoch 3, gen_loss = 0.801428031089694, disc_loss = 0.09905999377418011
Trained batch 387 in epoch 3, gen_loss = 0.8006280540805502, disc_loss = 0.09920896926040272
Trained batch 388 in epoch 3, gen_loss = 0.801141103619475, disc_loss = 0.09918976378098016
Trained batch 389 in epoch 3, gen_loss = 0.8014850737192691, disc_loss = 0.09931391699430653
Trained batch 390 in epoch 3, gen_loss = 0.8012158701486904, disc_loss = 0.09933432990261128
Trained batch 391 in epoch 3, gen_loss = 0.8004096968441593, disc_loss = 0.09990500256048554
Trained batch 392 in epoch 3, gen_loss = 0.8008076208845046, disc_loss = 0.09980221404800661
Trained batch 393 in epoch 3, gen_loss = 0.8013394158806293, disc_loss = 0.09977757549953416
Trained batch 394 in epoch 3, gen_loss = 0.8010814585263216, disc_loss = 0.09962353774499667
Trained batch 395 in epoch 3, gen_loss = 0.8011729458365777, disc_loss = 0.09950137751957759
Trained batch 396 in epoch 3, gen_loss = 0.800629683946182, disc_loss = 0.09948072747869291
Trained batch 397 in epoch 3, gen_loss = 0.7998843383249925, disc_loss = 0.09952524123039452
Trained batch 398 in epoch 3, gen_loss = 0.8001756302097387, disc_loss = 0.0995826043566703
Trained batch 399 in epoch 3, gen_loss = 0.8009389258921147, disc_loss = 0.09967241974780336
Trained batch 400 in epoch 3, gen_loss = 0.8003670770925774, disc_loss = 0.09960140663424409
Trained batch 401 in epoch 3, gen_loss = 0.7998770573245946, disc_loss = 0.09954683490292128
Trained batch 402 in epoch 3, gen_loss = 0.800239671548602, disc_loss = 0.09933137130130905
Trained batch 403 in epoch 3, gen_loss = 0.800577817281874, disc_loss = 0.09920878124672293
Trained batch 404 in epoch 3, gen_loss = 0.8001570414613794, disc_loss = 0.09901434844474734
Trained batch 405 in epoch 3, gen_loss = 0.7999627914628372, disc_loss = 0.09892475255420936
Trained batch 406 in epoch 3, gen_loss = 0.8003700680170364, disc_loss = 0.09873734471326379
Trained batch 407 in epoch 3, gen_loss = 0.8008788834307708, disc_loss = 0.09890029581227139
Trained batch 408 in epoch 3, gen_loss = 0.8003633831124434, disc_loss = 0.09909012354454959
Trained batch 409 in epoch 3, gen_loss = 0.7999826905204028, disc_loss = 0.09915314620224441
Trained batch 410 in epoch 3, gen_loss = 0.8010597437837698, disc_loss = 0.09923567840435209
Trained batch 411 in epoch 3, gen_loss = 0.8008189338792875, disc_loss = 0.09906179350755602
Trained batch 412 in epoch 3, gen_loss = 0.8004405422014417, disc_loss = 0.09907632531738021
Trained batch 413 in epoch 3, gen_loss = 0.7998410120678409, disc_loss = 0.0994643786346207
Trained batch 414 in epoch 3, gen_loss = 0.799725208799523, disc_loss = 0.09926781989185207
Trained batch 415 in epoch 3, gen_loss = 0.8007453992389716, disc_loss = 0.09952130567174979
Trained batch 416 in epoch 3, gen_loss = 0.8006681949972249, disc_loss = 0.0995364681297212
Trained batch 417 in epoch 3, gen_loss = 0.7998374730491182, disc_loss = 0.09970424981101562
Trained batch 418 in epoch 3, gen_loss = 0.79978780999673, disc_loss = 0.09958890060002878
Trained batch 419 in epoch 3, gen_loss = 0.7994471020641781, disc_loss = 0.09946524993117367
Trained batch 420 in epoch 3, gen_loss = 0.8002911088302413, disc_loss = 0.09945297447384961
Trained batch 421 in epoch 3, gen_loss = 0.8001818887147858, disc_loss = 0.09930782832240606
Trained batch 422 in epoch 3, gen_loss = 0.7995831329489994, disc_loss = 0.0993254913400251
Trained batch 423 in epoch 3, gen_loss = 0.7993310306150958, disc_loss = 0.09916307855362319
Trained batch 424 in epoch 3, gen_loss = 0.799528482801774, disc_loss = 0.09914139077067376
Trained batch 425 in epoch 3, gen_loss = 0.798911474820034, disc_loss = 0.09931401928510744
Trained batch 426 in epoch 3, gen_loss = 0.798438878193393, disc_loss = 0.09930352289971199
Trained batch 427 in epoch 3, gen_loss = 0.7981035163469403, disc_loss = 0.09921850322388878
Trained batch 428 in epoch 3, gen_loss = 0.7987154716656203, disc_loss = 0.09905633492729603
Trained batch 429 in epoch 3, gen_loss = 0.7991926190464995, disc_loss = 0.09908596151616685
Trained batch 430 in epoch 3, gen_loss = 0.7985418795709543, disc_loss = 0.09922797942486551
Trained batch 431 in epoch 3, gen_loss = 0.7984866824139047, disc_loss = 0.09920563934267396
Trained batch 432 in epoch 3, gen_loss = 0.7983801234126366, disc_loss = 0.09914518977939119
Trained batch 433 in epoch 3, gen_loss = 0.7986819341710086, disc_loss = 0.09920343934356617
Trained batch 434 in epoch 3, gen_loss = 0.7983715025857947, disc_loss = 0.09943556013977391
Trained batch 435 in epoch 3, gen_loss = 0.7977967580797476, disc_loss = 0.09940408552150934
Trained batch 436 in epoch 3, gen_loss = 0.7978146459472534, disc_loss = 0.09932265990761106
Trained batch 437 in epoch 3, gen_loss = 0.7974464419769914, disc_loss = 0.0994868568616779
Trained batch 438 in epoch 3, gen_loss = 0.7976079850642176, disc_loss = 0.09929077976419334
Trained batch 439 in epoch 3, gen_loss = 0.7974220328710296, disc_loss = 0.09938886494968426
Trained batch 440 in epoch 3, gen_loss = 0.7968752858590107, disc_loss = 0.09940076647262995
Trained batch 441 in epoch 3, gen_loss = 0.7968835416692415, disc_loss = 0.09923152628932064
Trained batch 442 in epoch 3, gen_loss = 0.7977400187983201, disc_loss = 0.09933398630360718
Trained batch 443 in epoch 3, gen_loss = 0.7974957992901673, disc_loss = 0.09930018387600645
Trained batch 444 in epoch 3, gen_loss = 0.7964893458934312, disc_loss = 0.09971202864740672
Trained batch 445 in epoch 3, gen_loss = 0.798263937903092, disc_loss = 0.10078621497001883
Trained batch 446 in epoch 3, gen_loss = 0.7982292025947998, disc_loss = 0.10073844721786661
Trained batch 447 in epoch 3, gen_loss = 0.7978916291945747, disc_loss = 0.10074360261205584
Trained batch 448 in epoch 3, gen_loss = 0.7973577190348194, disc_loss = 0.10100779460041985
Trained batch 449 in epoch 3, gen_loss = 0.7980581646495395, disc_loss = 0.10136756842335065
Trained batch 450 in epoch 3, gen_loss = 0.7982157241478728, disc_loss = 0.1013544752797372
Trained batch 451 in epoch 3, gen_loss = 0.798338202380501, disc_loss = 0.1012288260446713
Trained batch 452 in epoch 3, gen_loss = 0.7977172283673655, disc_loss = 0.10142911490357212
Trained batch 453 in epoch 3, gen_loss = 0.7977365420778417, disc_loss = 0.10125832060671981
Trained batch 454 in epoch 3, gen_loss = 0.7979776297296797, disc_loss = 0.10115594759501599
Trained batch 455 in epoch 3, gen_loss = 0.7981359183526876, disc_loss = 0.10096067998746182
Trained batch 456 in epoch 3, gen_loss = 0.7980219917433006, disc_loss = 0.10095456574943643
Trained batch 457 in epoch 3, gen_loss = 0.7982360421309825, disc_loss = 0.10092250904979339
Trained batch 458 in epoch 3, gen_loss = 0.799097476701591, disc_loss = 0.10073874552159982
Trained batch 459 in epoch 3, gen_loss = 0.7990915557612543, disc_loss = 0.10066168990755535
Trained batch 460 in epoch 3, gen_loss = 0.7995361332779592, disc_loss = 0.10049226387745323
Trained batch 461 in epoch 3, gen_loss = 0.7991529368993008, disc_loss = 0.10047842690205097
Trained batch 462 in epoch 3, gen_loss = 0.7990793796903887, disc_loss = 0.10040993305208809
Trained batch 463 in epoch 3, gen_loss = 0.7992393752110416, disc_loss = 0.10035509817454771
Trained batch 464 in epoch 3, gen_loss = 0.7992278556669912, disc_loss = 0.10016630316974334
Trained batch 465 in epoch 3, gen_loss = 0.799440580504135, disc_loss = 0.10000747277365414
Trained batch 466 in epoch 3, gen_loss = 0.799749262455444, disc_loss = 0.0998559349637311
Trained batch 467 in epoch 3, gen_loss = 0.7993470355231538, disc_loss = 0.09988464547806762
Trained batch 468 in epoch 3, gen_loss = 0.7997296460147606, disc_loss = 0.09971931957796629
Trained batch 469 in epoch 3, gen_loss = 0.79938473232249, disc_loss = 0.09977542120527397
Trained batch 470 in epoch 3, gen_loss = 0.7996604975368313, disc_loss = 0.09960938229832617
Trained batch 471 in epoch 3, gen_loss = 0.8003466931187501, disc_loss = 0.09974833270653262
Trained batch 472 in epoch 3, gen_loss = 0.800379640834276, disc_loss = 0.09977039381916818
Trained batch 473 in epoch 3, gen_loss = 0.8003599711611301, disc_loss = 0.09974596681434834
Trained batch 474 in epoch 3, gen_loss = 0.7998153764323185, disc_loss = 0.100056980948307
Trained batch 475 in epoch 3, gen_loss = 0.7997444099237939, disc_loss = 0.0999318134380082
Trained batch 476 in epoch 3, gen_loss = 0.8001088215120183, disc_loss = 0.09982060376882741
Trained batch 477 in epoch 3, gen_loss = 0.8009147575460218, disc_loss = 0.09976863380809896
Trained batch 478 in epoch 3, gen_loss = 0.800522020067203, disc_loss = 0.09976206330819705
Trained batch 479 in epoch 3, gen_loss = 0.8005396458009879, disc_loss = 0.09959924007028652
Trained batch 480 in epoch 3, gen_loss = 0.8005628851000336, disc_loss = 0.09951860634435797
Trained batch 481 in epoch 3, gen_loss = 0.8008885718727508, disc_loss = 0.099389953865318
Trained batch 482 in epoch 3, gen_loss = 0.8012816137161808, disc_loss = 0.09921823421736127
Trained batch 483 in epoch 3, gen_loss = 0.8006935727990363, disc_loss = 0.09946901257119088
Trained batch 484 in epoch 3, gen_loss = 0.8009817848500517, disc_loss = 0.09956612867908073
Trained batch 485 in epoch 3, gen_loss = 0.8013467563032614, disc_loss = 0.09965642751481982
Trained batch 486 in epoch 3, gen_loss = 0.8010263034205662, disc_loss = 0.09972464274691543
Trained batch 487 in epoch 3, gen_loss = 0.8009415034387932, disc_loss = 0.09961738763949604
Trained batch 488 in epoch 3, gen_loss = 0.8011121323259818, disc_loss = 0.1000242378612207
Trained batch 489 in epoch 3, gen_loss = 0.8008386400281167, disc_loss = 0.1000773346222633
Trained batch 490 in epoch 3, gen_loss = 0.8003752196393528, disc_loss = 0.10019663488966567
Trained batch 491 in epoch 3, gen_loss = 0.8009051112382393, disc_loss = 0.10017338046629921
Trained batch 492 in epoch 3, gen_loss = 0.8009235727134147, disc_loss = 0.10003697167719293
Trained batch 493 in epoch 3, gen_loss = 0.8005846578341264, disc_loss = 0.10002036855522135
Trained batch 494 in epoch 3, gen_loss = 0.8007709957132436, disc_loss = 0.09994954219784098
Trained batch 495 in epoch 3, gen_loss = 0.8005415961867378, disc_loss = 0.09981788266562827
Trained batch 496 in epoch 3, gen_loss = 0.8009399529434066, disc_loss = 0.09966794621963916
Trained batch 497 in epoch 3, gen_loss = 0.8004973345252884, disc_loss = 0.09978307906470923
Trained batch 498 in epoch 3, gen_loss = 0.8004383879577468, disc_loss = 0.09967050193911624
Trained batch 499 in epoch 3, gen_loss = 0.801233724951744, disc_loss = 0.09963865259476005
Trained batch 500 in epoch 3, gen_loss = 0.8010761198883285, disc_loss = 0.09962429316108395
Trained batch 501 in epoch 3, gen_loss = 0.8012332243035989, disc_loss = 0.09956413121760425
Trained batch 502 in epoch 3, gen_loss = 0.8003559412942018, disc_loss = 0.09970528521495417
Trained batch 503 in epoch 3, gen_loss = 0.8007961790121737, disc_loss = 0.09964262219774167
Trained batch 504 in epoch 3, gen_loss = 0.8006959618318199, disc_loss = 0.09954503451722978
Trained batch 505 in epoch 3, gen_loss = 0.8003579484733198, disc_loss = 0.09966059908337097
Trained batch 506 in epoch 3, gen_loss = 0.8004167867012513, disc_loss = 0.09961021919523529
Trained batch 507 in epoch 3, gen_loss = 0.8000619771091018, disc_loss = 0.09953458164451923
Trained batch 508 in epoch 3, gen_loss = 0.8006600526203576, disc_loss = 0.09936822111551853
Trained batch 509 in epoch 3, gen_loss = 0.8010739553792804, disc_loss = 0.09937171164133093
Trained batch 510 in epoch 3, gen_loss = 0.8009517683324981, disc_loss = 0.09936167959692485
Trained batch 511 in epoch 3, gen_loss = 0.8013324870844372, disc_loss = 0.09928381502140837
Trained batch 512 in epoch 3, gen_loss = 0.8015987223003342, disc_loss = 0.09916110175024521
Trained batch 513 in epoch 3, gen_loss = 0.8012610456475024, disc_loss = 0.09916655125879185
Trained batch 514 in epoch 3, gen_loss = 0.8015209950868366, disc_loss = 0.09906729926508896
Trained batch 515 in epoch 3, gen_loss = 0.8019289065354555, disc_loss = 0.0989274707850242
Trained batch 516 in epoch 3, gen_loss = 0.8027524060967812, disc_loss = 0.09880887684043015
Trained batch 517 in epoch 3, gen_loss = 0.8029407829506517, disc_loss = 0.09867775000265033
Trained batch 518 in epoch 3, gen_loss = 0.8024036524268244, disc_loss = 0.09879605173669856
Trained batch 519 in epoch 3, gen_loss = 0.8026636400474951, disc_loss = 0.0986748759007941
Trained batch 520 in epoch 3, gen_loss = 0.8030193498976629, disc_loss = 0.09869065183087926
Trained batch 521 in epoch 3, gen_loss = 0.8032715490152096, disc_loss = 0.09873752520237675
Trained batch 522 in epoch 3, gen_loss = 0.8024493005148083, disc_loss = 0.09894844857053421
Trained batch 523 in epoch 3, gen_loss = 0.8025330630991295, disc_loss = 0.09886407932686044
Trained batch 524 in epoch 3, gen_loss = 0.8026823861826033, disc_loss = 0.09883270373834031
Trained batch 525 in epoch 3, gen_loss = 0.8027104720076681, disc_loss = 0.09886548833340802
Trained batch 526 in epoch 3, gen_loss = 0.8027646979864906, disc_loss = 0.09883480118428564
Trained batch 527 in epoch 3, gen_loss = 0.8023677509503834, disc_loss = 0.0990034852575539
Trained batch 528 in epoch 3, gen_loss = 0.8022471877600159, disc_loss = 0.09900954255344793
Trained batch 529 in epoch 3, gen_loss = 0.8032661077548873, disc_loss = 0.09912390699961557
Trained batch 530 in epoch 3, gen_loss = 0.8034932002172632, disc_loss = 0.09914073757230955
Trained batch 531 in epoch 3, gen_loss = 0.8037622455031352, disc_loss = 0.09901372596264389
Trained batch 532 in epoch 3, gen_loss = 0.8032371612583719, disc_loss = 0.09918592465730422
Trained batch 533 in epoch 3, gen_loss = 0.8029215137721893, disc_loss = 0.09910383771874764
Trained batch 534 in epoch 3, gen_loss = 0.8026639661499273, disc_loss = 0.09936154152083898
Trained batch 535 in epoch 3, gen_loss = 0.802031616555221, disc_loss = 0.09945080984112765
Trained batch 536 in epoch 3, gen_loss = 0.8020204115846303, disc_loss = 0.09932648378217963
Trained batch 537 in epoch 3, gen_loss = 0.8016946176170859, disc_loss = 0.09924546246448027
Trained batch 538 in epoch 3, gen_loss = 0.802294846810746, disc_loss = 0.09938056456833967
Trained batch 539 in epoch 3, gen_loss = 0.8017329441728416, disc_loss = 0.09962976704075656
Trained batch 540 in epoch 3, gen_loss = 0.801233163767954, disc_loss = 0.09977647482612051
Trained batch 541 in epoch 3, gen_loss = 0.8014313668232562, disc_loss = 0.09965524211615269
Trained batch 542 in epoch 3, gen_loss = 0.8016004083235619, disc_loss = 0.09966119483943418
Trained batch 543 in epoch 3, gen_loss = 0.8022126440944917, disc_loss = 0.09960786934757113
Trained batch 544 in epoch 3, gen_loss = 0.8017314249769263, disc_loss = 0.09953160966925938
Trained batch 545 in epoch 3, gen_loss = 0.8015359800049674, disc_loss = 0.09949467418674421
Trained batch 546 in epoch 3, gen_loss = 0.8014884400956156, disc_loss = 0.09951953867950922
Trained batch 547 in epoch 3, gen_loss = 0.8013550718009037, disc_loss = 0.09943874278377714
Trained batch 548 in epoch 3, gen_loss = 0.8012598532036571, disc_loss = 0.09934387358926738
Trained batch 549 in epoch 3, gen_loss = 0.8009963194348595, disc_loss = 0.09938796191222288
Trained batch 550 in epoch 3, gen_loss = 0.800707910595269, disc_loss = 0.09952487872436833
Trained batch 551 in epoch 3, gen_loss = 0.8012931299922259, disc_loss = 0.09939247659117362
Trained batch 552 in epoch 3, gen_loss = 0.8014609393870852, disc_loss = 0.09925433446166475
Trained batch 553 in epoch 3, gen_loss = 0.8018793739674324, disc_loss = 0.09916219226040941
Trained batch 554 in epoch 3, gen_loss = 0.8016371586838285, disc_loss = 0.0990282173813866
Trained batch 555 in epoch 3, gen_loss = 0.8019207325234687, disc_loss = 0.09891942648464988
Trained batch 556 in epoch 3, gen_loss = 0.8014154827466345, disc_loss = 0.09894514507722758
Trained batch 557 in epoch 3, gen_loss = 0.8021471115316542, disc_loss = 0.09884719618539389
Trained batch 558 in epoch 3, gen_loss = 0.8023392366701887, disc_loss = 0.09878122083316282
Trained batch 559 in epoch 3, gen_loss = 0.8019181672483683, disc_loss = 0.09877631389369657
Trained batch 560 in epoch 3, gen_loss = 0.8017588812930911, disc_loss = 0.0987366381916425
Trained batch 561 in epoch 3, gen_loss = 0.8015491602365656, disc_loss = 0.09873118201681674
Trained batch 562 in epoch 3, gen_loss = 0.8015328050189078, disc_loss = 0.0987437032146601
Trained batch 563 in epoch 3, gen_loss = 0.8016776554022275, disc_loss = 0.09865457334568896
Trained batch 564 in epoch 3, gen_loss = 0.8026634669409389, disc_loss = 0.09868066217090968
Trained batch 565 in epoch 3, gen_loss = 0.8024770421084583, disc_loss = 0.09866585482287059
Trained batch 566 in epoch 3, gen_loss = 0.8024002365649693, disc_loss = 0.09868811863118115
Trained batch 567 in epoch 3, gen_loss = 0.8025933892898997, disc_loss = 0.09854006660859507
Trained batch 568 in epoch 3, gen_loss = 0.8024240850040489, disc_loss = 0.09842572348627715
Trained batch 569 in epoch 3, gen_loss = 0.8024450640406525, disc_loss = 0.09830377850060662
Trained batch 570 in epoch 3, gen_loss = 0.802240648902235, disc_loss = 0.09833380162892064
Trained batch 571 in epoch 3, gen_loss = 0.8022518797250061, disc_loss = 0.09821195650187979
Trained batch 572 in epoch 3, gen_loss = 0.8021882932119553, disc_loss = 0.09812134390381566
Trained batch 573 in epoch 3, gen_loss = 0.8019625676945111, disc_loss = 0.09806604241264355
Trained batch 574 in epoch 3, gen_loss = 0.801603938859442, disc_loss = 0.09800525612643232
Trained batch 575 in epoch 3, gen_loss = 0.8021331759066217, disc_loss = 0.09785707137456888
Trained batch 576 in epoch 3, gen_loss = 0.8019424268339908, disc_loss = 0.0977585788532136
Trained batch 577 in epoch 3, gen_loss = 0.8018528331831665, disc_loss = 0.09763089411772762
Trained batch 578 in epoch 3, gen_loss = 0.8014775542912294, disc_loss = 0.09761101462024173
Trained batch 579 in epoch 3, gen_loss = 0.8026289476916708, disc_loss = 0.0986374866506406
Trained batch 580 in epoch 3, gen_loss = 0.8023975906499281, disc_loss = 0.09863729484174112
Trained batch 581 in epoch 3, gen_loss = 0.8021403132742623, disc_loss = 0.09870396038882204
Trained batch 582 in epoch 3, gen_loss = 0.8021887780564931, disc_loss = 0.09863488986053046
Trained batch 583 in epoch 3, gen_loss = 0.8022847157737164, disc_loss = 0.09853709440946273
Trained batch 584 in epoch 3, gen_loss = 0.80159873835042, disc_loss = 0.0987404433867106
Trained batch 585 in epoch 3, gen_loss = 0.8019998542989887, disc_loss = 0.09898855794322878
Trained batch 586 in epoch 3, gen_loss = 0.8024938887895879, disc_loss = 0.09906293322638414
Trained batch 587 in epoch 3, gen_loss = 0.8019125847285297, disc_loss = 0.09931726176228349
Trained batch 588 in epoch 3, gen_loss = 0.8021205671270756, disc_loss = 0.099251761074306
Trained batch 589 in epoch 3, gen_loss = 0.8022666037587797, disc_loss = 0.09911005699975511
Trained batch 590 in epoch 3, gen_loss = 0.8022695479760114, disc_loss = 0.09903011020027139
Trained batch 591 in epoch 3, gen_loss = 0.8023314969865857, disc_loss = 0.09900340530077449
Trained batch 592 in epoch 3, gen_loss = 0.802324996881099, disc_loss = 0.09894878176334636
Trained batch 593 in epoch 3, gen_loss = 0.801830680532889, disc_loss = 0.09918965975305548
Trained batch 594 in epoch 3, gen_loss = 0.801334762723506, disc_loss = 0.09944822687123503
Trained batch 595 in epoch 3, gen_loss = 0.8016289066048277, disc_loss = 0.09942345574010639
Trained batch 596 in epoch 3, gen_loss = 0.8012395226076819, disc_loss = 0.09992303079309275
Trained batch 597 in epoch 3, gen_loss = 0.8008059475035173, disc_loss = 0.10003449314625865
Trained batch 598 in epoch 3, gen_loss = 0.8006526873087844, disc_loss = 0.10002832333922684
Trained batch 599 in epoch 3, gen_loss = 0.8008001076678435, disc_loss = 0.10023195805959403
Trained batch 600 in epoch 3, gen_loss = 0.8008491355746042, disc_loss = 0.10021157679574165
Trained batch 601 in epoch 3, gen_loss = 0.8006637524627768, disc_loss = 0.10037267134150496
Trained batch 602 in epoch 3, gen_loss = 0.8008685305245085, disc_loss = 0.10034366570116572
Trained batch 603 in epoch 3, gen_loss = 0.8007299769299709, disc_loss = 0.10035384142006569
Trained batch 604 in epoch 3, gen_loss = 0.8005921925887589, disc_loss = 0.10032750827776006
Trained batch 605 in epoch 3, gen_loss = 0.8006656485127144, disc_loss = 0.10022855256515073
Trained batch 606 in epoch 3, gen_loss = 0.8003455618951819, disc_loss = 0.10015122229432843
Trained batch 607 in epoch 3, gen_loss = 0.8000521640734453, disc_loss = 0.10025759872453484
Trained batch 608 in epoch 3, gen_loss = 0.8008174141150194, disc_loss = 0.10049734650292909
Trained batch 609 in epoch 3, gen_loss = 0.8008530608454688, disc_loss = 0.10058778810513312
Trained batch 610 in epoch 3, gen_loss = 0.8003734984784197, disc_loss = 0.10098716038936191
Trained batch 611 in epoch 3, gen_loss = 0.8003977255201807, disc_loss = 0.10087482226720336
Trained batch 612 in epoch 3, gen_loss = 0.8002115408806388, disc_loss = 0.10083569036599181
Trained batch 613 in epoch 3, gen_loss = 0.8000953232911977, disc_loss = 0.10069867539908191
Trained batch 614 in epoch 3, gen_loss = 0.8002620277850608, disc_loss = 0.10057107371285678
Trained batch 615 in epoch 3, gen_loss = 0.8002105329621148, disc_loss = 0.10051768436398986
Trained batch 616 in epoch 3, gen_loss = 0.800121040118185, disc_loss = 0.10040186290029962
Trained batch 617 in epoch 3, gen_loss = 0.800593321522077, disc_loss = 0.10031522387295093
Trained batch 618 in epoch 3, gen_loss = 0.8003406643578617, disc_loss = 0.10032816564661236
Trained batch 619 in epoch 3, gen_loss = 0.8004061812835355, disc_loss = 0.10026078308301588
Trained batch 620 in epoch 3, gen_loss = 0.8009878504967344, disc_loss = 0.1002334989907277
Trained batch 621 in epoch 3, gen_loss = 0.8014754408137975, disc_loss = 0.10011220367631345
Trained batch 622 in epoch 3, gen_loss = 0.8009171883903001, disc_loss = 0.10046069385008483
Trained batch 623 in epoch 3, gen_loss = 0.8009344660318815, disc_loss = 0.10033959389114991
Trained batch 624 in epoch 3, gen_loss = 0.8016482181549073, disc_loss = 0.10037842712402344
Trained batch 625 in epoch 3, gen_loss = 0.8018835413570221, disc_loss = 0.10054463386154784
Trained batch 626 in epoch 3, gen_loss = 0.8015818535996396, disc_loss = 0.10066766697063781
Trained batch 627 in epoch 3, gen_loss = 0.801023564426003, disc_loss = 0.10081034027941667
Trained batch 628 in epoch 3, gen_loss = 0.801411615361849, disc_loss = 0.1007878088965325
Trained batch 629 in epoch 3, gen_loss = 0.8023333824816204, disc_loss = 0.10094172281641808
Trained batch 630 in epoch 3, gen_loss = 0.802256189699974, disc_loss = 0.10085915586366517
Trained batch 631 in epoch 3, gen_loss = 0.8020005822181702, disc_loss = 0.10098218222301972
Trained batch 632 in epoch 3, gen_loss = 0.801684214982188, disc_loss = 0.10103490802725722
Trained batch 633 in epoch 3, gen_loss = 0.8020688227674563, disc_loss = 0.10095518899123751
Trained batch 634 in epoch 3, gen_loss = 0.801919029922936, disc_loss = 0.10094377520516162
Trained batch 635 in epoch 3, gen_loss = 0.8021939458712092, disc_loss = 0.100818224919011
Trained batch 636 in epoch 3, gen_loss = 0.8028473811022341, disc_loss = 0.10074657632192974
Trained batch 637 in epoch 3, gen_loss = 0.8025591042721907, disc_loss = 0.10070800096917676
Trained batch 638 in epoch 3, gen_loss = 0.8030141370024106, disc_loss = 0.10058483232762985
Trained batch 639 in epoch 3, gen_loss = 0.8027413104660809, disc_loss = 0.10055281346139963
Trained batch 640 in epoch 3, gen_loss = 0.8030867592406905, disc_loss = 0.10046682516970147
Trained batch 641 in epoch 3, gen_loss = 0.8030531249499395, disc_loss = 0.10050196532229676
Trained batch 642 in epoch 3, gen_loss = 0.803417315286574, disc_loss = 0.10052663233554103
Trained batch 643 in epoch 3, gen_loss = 0.8032201796029665, disc_loss = 0.10045550980240754
Trained batch 644 in epoch 3, gen_loss = 0.8028138967447502, disc_loss = 0.10045987741025382
Trained batch 645 in epoch 3, gen_loss = 0.8025040815673745, disc_loss = 0.10045689280107387
Trained batch 646 in epoch 3, gen_loss = 0.8025134631434032, disc_loss = 0.10035857465837894
Trained batch 647 in epoch 3, gen_loss = 0.8030173864077639, disc_loss = 0.1004722408093742
Trained batch 648 in epoch 3, gen_loss = 0.8030309103119355, disc_loss = 0.10039266476978782
Trained batch 649 in epoch 3, gen_loss = 0.8030525742127346, disc_loss = 0.10029206385692725
Trained batch 650 in epoch 3, gen_loss = 0.8030496586669242, disc_loss = 0.10026468093665789
Trained batch 651 in epoch 3, gen_loss = 0.8034934330205976, disc_loss = 0.10015234062619553
Trained batch 652 in epoch 3, gen_loss = 0.8037227390371092, disc_loss = 0.1000600812320596
Trained batch 653 in epoch 3, gen_loss = 0.803677327042326, disc_loss = 0.0999761639897703
Trained batch 654 in epoch 3, gen_loss = 0.8036004763523131, disc_loss = 0.0998941334433683
Trained batch 655 in epoch 3, gen_loss = 0.8037506200191451, disc_loss = 0.0998300228881218
Trained batch 656 in epoch 3, gen_loss = 0.8036345082875256, disc_loss = 0.09973549662523618
Trained batch 657 in epoch 3, gen_loss = 0.803468062431979, disc_loss = 0.09966272632039426
Trained batch 658 in epoch 3, gen_loss = 0.8036921525399493, disc_loss = 0.09955133953907602
Trained batch 659 in epoch 3, gen_loss = 0.8034330010414124, disc_loss = 0.09965054200341304
Trained batch 660 in epoch 3, gen_loss = 0.8038700896564662, disc_loss = 0.09967722264139627
Trained batch 661 in epoch 3, gen_loss = 0.8037121935193272, disc_loss = 0.09968025999824626
Trained batch 662 in epoch 3, gen_loss = 0.8033868043850629, disc_loss = 0.09966688934112386
Trained batch 663 in epoch 3, gen_loss = 0.8035585684589592, disc_loss = 0.09959102410217185
Trained batch 664 in epoch 3, gen_loss = 0.8030216050327272, disc_loss = 0.09965761711162732
Trained batch 665 in epoch 3, gen_loss = 0.8027885741478687, disc_loss = 0.09964730285734565
Trained batch 666 in epoch 3, gen_loss = 0.8026305325385155, disc_loss = 0.099803334920258
Trained batch 667 in epoch 3, gen_loss = 0.8026629821090641, disc_loss = 0.09998987982618417
Trained batch 668 in epoch 3, gen_loss = 0.8026990891393881, disc_loss = 0.10001977714076526
Trained batch 669 in epoch 3, gen_loss = 0.8022924191916166, disc_loss = 0.10028652728382331
Trained batch 670 in epoch 3, gen_loss = 0.8024837320501154, disc_loss = 0.10017836301541719
Trained batch 671 in epoch 3, gen_loss = 0.8030980605454672, disc_loss = 0.10047714947722852
Trained batch 672 in epoch 3, gen_loss = 0.8027978393333628, disc_loss = 0.10055855172305724
Trained batch 673 in epoch 3, gen_loss = 0.8025307393569268, disc_loss = 0.10057996548380625
Trained batch 674 in epoch 3, gen_loss = 0.8022490338925962, disc_loss = 0.10077450733493876
Trained batch 675 in epoch 3, gen_loss = 0.8030111006731112, disc_loss = 0.10083610113688121
Trained batch 676 in epoch 3, gen_loss = 0.8029675182598909, disc_loss = 0.10084130614995956
Trained batch 677 in epoch 3, gen_loss = 0.8024876225399057, disc_loss = 0.10098864580985367
Trained batch 678 in epoch 3, gen_loss = 0.8027833962212255, disc_loss = 0.10087034239849303
Trained batch 679 in epoch 3, gen_loss = 0.8025763694416074, disc_loss = 0.1008217427194776
Trained batch 680 in epoch 3, gen_loss = 0.8023698347868198, disc_loss = 0.10084138523716146
Trained batch 681 in epoch 3, gen_loss = 0.8025999095869903, disc_loss = 0.10073030194065526
Trained batch 682 in epoch 3, gen_loss = 0.8027924214152955, disc_loss = 0.10079671728586993
Trained batch 683 in epoch 3, gen_loss = 0.8023459933567465, disc_loss = 0.1009487966592941
Trained batch 684 in epoch 3, gen_loss = 0.8020771396856239, disc_loss = 0.1009431499335235
Trained batch 685 in epoch 3, gen_loss = 0.8023723111468919, disc_loss = 0.10089630599109234
Trained batch 686 in epoch 3, gen_loss = 0.8027164678820009, disc_loss = 0.10081391052506983
Trained batch 687 in epoch 3, gen_loss = 0.80232892908849, disc_loss = 0.10083509116097851
Trained batch 688 in epoch 3, gen_loss = 0.8021231333904931, disc_loss = 0.10087246880075841
Trained batch 689 in epoch 3, gen_loss = 0.8022103452596112, disc_loss = 0.10085631695076608
Trained batch 690 in epoch 3, gen_loss = 0.8023417658036421, disc_loss = 0.10074742243243799
Trained batch 691 in epoch 3, gen_loss = 0.8019899465359015, disc_loss = 0.10078858469230677
Trained batch 692 in epoch 3, gen_loss = 0.8017803318314738, disc_loss = 0.10077178627951407
Trained batch 693 in epoch 3, gen_loss = 0.8018373638735037, disc_loss = 0.10068788745786769
Trained batch 694 in epoch 3, gen_loss = 0.8015868982393964, disc_loss = 0.10069787353545213
Trained batch 695 in epoch 3, gen_loss = 0.801564806537039, disc_loss = 0.100695422585604
Trained batch 696 in epoch 3, gen_loss = 0.8016668262662984, disc_loss = 0.10104112949494909
Trained batch 697 in epoch 3, gen_loss = 0.8011840833377701, disc_loss = 0.1012963679963376
Trained batch 698 in epoch 3, gen_loss = 0.8012142628644499, disc_loss = 0.10127708646542098
Trained batch 699 in epoch 3, gen_loss = 0.8009979222927774, disc_loss = 0.10122398029746754
Trained batch 700 in epoch 3, gen_loss = 0.8013120862879869, disc_loss = 0.10121768630360825
Trained batch 701 in epoch 3, gen_loss = 0.8013000553235029, disc_loss = 0.10112075414508581
Trained batch 702 in epoch 3, gen_loss = 0.8009498686149483, disc_loss = 0.10122107268492579
Trained batch 703 in epoch 3, gen_loss = 0.8008984298953279, disc_loss = 0.10121242284235037
Trained batch 704 in epoch 3, gen_loss = 0.8010877604602922, disc_loss = 0.1012105525306142
Trained batch 705 in epoch 3, gen_loss = 0.8007152129080748, disc_loss = 0.10130493261880391
Trained batch 706 in epoch 3, gen_loss = 0.8011819558821439, disc_loss = 0.10125988511344922
Trained batch 707 in epoch 3, gen_loss = 0.801664448348479, disc_loss = 0.10119721861977109
Trained batch 708 in epoch 3, gen_loss = 0.8013062228689073, disc_loss = 0.10128310650891831
Trained batch 709 in epoch 3, gen_loss = 0.8013061394573937, disc_loss = 0.10121387064089657
Trained batch 710 in epoch 3, gen_loss = 0.8009374641751773, disc_loss = 0.10140463396770626
Trained batch 711 in epoch 3, gen_loss = 0.8008989455241166, disc_loss = 0.10132669370485407
Trained batch 712 in epoch 3, gen_loss = 0.8011289637269345, disc_loss = 0.10131723159691645
Trained batch 713 in epoch 3, gen_loss = 0.8012992267598625, disc_loss = 0.10125588821064607
Trained batch 714 in epoch 3, gen_loss = 0.8012530715732308, disc_loss = 0.10118444830022909
Trained batch 715 in epoch 3, gen_loss = 0.8012500266705811, disc_loss = 0.10110556809543814
Trained batch 716 in epoch 3, gen_loss = 0.8019623719415572, disc_loss = 0.10119971037274707
Trained batch 717 in epoch 3, gen_loss = 0.801385480671872, disc_loss = 0.10133694721162734
Trained batch 718 in epoch 3, gen_loss = 0.8018103817656574, disc_loss = 0.1014544254917553
Trained batch 719 in epoch 3, gen_loss = 0.8015307149539391, disc_loss = 0.10149448051169101
Trained batch 720 in epoch 3, gen_loss = 0.8014637914262763, disc_loss = 0.10150221911686551
Trained batch 721 in epoch 3, gen_loss = 0.8018656260336535, disc_loss = 0.1013978199873357
Trained batch 722 in epoch 3, gen_loss = 0.8013437493378361, disc_loss = 0.10155473023467539
Trained batch 723 in epoch 3, gen_loss = 0.8013753411025633, disc_loss = 0.10158172049636834
Trained batch 724 in epoch 3, gen_loss = 0.800977066385335, disc_loss = 0.10168554065042529
Trained batch 725 in epoch 3, gen_loss = 0.8010156015883464, disc_loss = 0.10162679637594985
Trained batch 726 in epoch 3, gen_loss = 0.8013663348502273, disc_loss = 0.10173959728776179
Trained batch 727 in epoch 3, gen_loss = 0.8015365023370628, disc_loss = 0.10181653857804261
Trained batch 728 in epoch 3, gen_loss = 0.8012315292417267, disc_loss = 0.10196009190403058
Trained batch 729 in epoch 3, gen_loss = 0.8010870906588149, disc_loss = 0.10198708608338278
Trained batch 730 in epoch 3, gen_loss = 0.80103193490515, disc_loss = 0.1019560773175327
Trained batch 731 in epoch 3, gen_loss = 0.8008496948604376, disc_loss = 0.10190098233968833
Trained batch 732 in epoch 3, gen_loss = 0.8007628667240742, disc_loss = 0.10184648664513193
Trained batch 733 in epoch 3, gen_loss = 0.8008210831994257, disc_loss = 0.10175210252729033
Trained batch 734 in epoch 3, gen_loss = 0.8009039548789563, disc_loss = 0.10173203773847242
Trained batch 735 in epoch 3, gen_loss = 0.8005070411802634, disc_loss = 0.10178349417148401
Trained batch 736 in epoch 3, gen_loss = 0.8011174801246768, disc_loss = 0.1017583491561209
Trained batch 737 in epoch 3, gen_loss = 0.801247752375073, disc_loss = 0.10194532692351639
Trained batch 738 in epoch 3, gen_loss = 0.8008439419072761, disc_loss = 0.1021093652156435
Trained batch 739 in epoch 3, gen_loss = 0.8007194962050463, disc_loss = 0.1020634254692374
Trained batch 740 in epoch 3, gen_loss = 0.8007045375351642, disc_loss = 0.10200317440285535
Trained batch 741 in epoch 3, gen_loss = 0.8006917002869424, disc_loss = 0.10194468682988313
Trained batch 742 in epoch 3, gen_loss = 0.8007282379658675, disc_loss = 0.10185958675709259
Trained batch 743 in epoch 3, gen_loss = 0.800562542132152, disc_loss = 0.1018521737167111
Trained batch 744 in epoch 3, gen_loss = 0.8006006166438928, disc_loss = 0.1017601661734133
Trained batch 745 in epoch 3, gen_loss = 0.8006120062066148, disc_loss = 0.10173880100130396
Trained batch 746 in epoch 3, gen_loss = 0.8009414160586744, disc_loss = 0.10169441104334202
Trained batch 747 in epoch 3, gen_loss = 0.8006469946015965, disc_loss = 0.10167787098549905
Trained batch 748 in epoch 3, gen_loss = 0.8007994307694989, disc_loss = 0.10158242370799005
Trained batch 749 in epoch 3, gen_loss = 0.8011381290753683, disc_loss = 0.10149730436007182
Trained batch 750 in epoch 3, gen_loss = 0.8009980937612359, disc_loss = 0.10153181198116308
Trained batch 751 in epoch 3, gen_loss = 0.8008462391159636, disc_loss = 0.10142997889333662
Trained batch 752 in epoch 3, gen_loss = 0.8006902568210486, disc_loss = 0.10159182278649662
Trained batch 753 in epoch 3, gen_loss = 0.8002971968062677, disc_loss = 0.10168519488903904
Trained batch 754 in epoch 3, gen_loss = 0.8000523286939457, disc_loss = 0.10173222500806219
Trained batch 755 in epoch 3, gen_loss = 0.8000470950174584, disc_loss = 0.10167065851400217
Trained batch 756 in epoch 3, gen_loss = 0.8005737622159003, disc_loss = 0.10167754674022783
Trained batch 757 in epoch 3, gen_loss = 0.8005644121553779, disc_loss = 0.10166291595930553
Trained batch 758 in epoch 3, gen_loss = 0.800705081153764, disc_loss = 0.10160756642943707
Trained batch 759 in epoch 3, gen_loss = 0.8005854685839854, disc_loss = 0.10157387195596178
Trained batch 760 in epoch 3, gen_loss = 0.8009108998145756, disc_loss = 0.10160440104461609
Trained batch 761 in epoch 3, gen_loss = 0.8005593518416086, disc_loss = 0.10168199088385334
Trained batch 762 in epoch 3, gen_loss = 0.8004029836129705, disc_loss = 0.10163411468531092
Trained batch 763 in epoch 3, gen_loss = 0.8004479867001478, disc_loss = 0.10153337265486727
Trained batch 764 in epoch 3, gen_loss = 0.8003347258162654, disc_loss = 0.10145636136381844
Trained batch 765 in epoch 3, gen_loss = 0.8006054074272474, disc_loss = 0.10135201354299528
Trained batch 766 in epoch 3, gen_loss = 0.8008695122782223, disc_loss = 0.10147660398780523
Trained batch 767 in epoch 3, gen_loss = 0.8007224291407814, disc_loss = 0.10148931353129835
Trained batch 768 in epoch 3, gen_loss = 0.8007658717691201, disc_loss = 0.10140805260577422
Trained batch 769 in epoch 3, gen_loss = 0.8007393216157889, disc_loss = 0.10135052378059595
Trained batch 770 in epoch 3, gen_loss = 0.8008586673885004, disc_loss = 0.10124228986030887
Trained batch 771 in epoch 3, gen_loss = 0.800883663673475, disc_loss = 0.10116938489532687
Trained batch 772 in epoch 3, gen_loss = 0.8008730689890172, disc_loss = 0.1012304132951262
Trained batch 773 in epoch 3, gen_loss = 0.8008980439152829, disc_loss = 0.10118091415893046
Trained batch 774 in epoch 3, gen_loss = 0.8008598343018563, disc_loss = 0.10111066999454651
Trained batch 775 in epoch 3, gen_loss = 0.8009729775571331, disc_loss = 0.10114007960217669
Trained batch 776 in epoch 3, gen_loss = 0.8005714472119566, disc_loss = 0.10117279870035259
Trained batch 777 in epoch 3, gen_loss = 0.8003653274480359, disc_loss = 0.10111514118842417
Trained batch 778 in epoch 3, gen_loss = 0.8006050590143583, disc_loss = 0.10101950332158949
Trained batch 779 in epoch 3, gen_loss = 0.8007528342879735, disc_loss = 0.1010307051336918
Trained batch 780 in epoch 3, gen_loss = 0.8010227061645933, disc_loss = 0.10104432016153189
Trained batch 781 in epoch 3, gen_loss = 0.8005323402793206, disc_loss = 0.10123081875922126
Trained batch 782 in epoch 3, gen_loss = 0.8004295142750478, disc_loss = 0.1011867397684856
Trained batch 783 in epoch 3, gen_loss = 0.8007588123864665, disc_loss = 0.1014290514059973
Trained batch 784 in epoch 3, gen_loss = 0.8002905228715034, disc_loss = 0.10143096748810665
Trained batch 785 in epoch 3, gen_loss = 0.8000158021847407, disc_loss = 0.10161683327369107
Trained batch 786 in epoch 3, gen_loss = 0.7996771210257858, disc_loss = 0.10165745091862417
Trained batch 787 in epoch 3, gen_loss = 0.8001651540398598, disc_loss = 0.10173321834902473
Trained batch 788 in epoch 3, gen_loss = 0.8000776447044126, disc_loss = 0.1017837266618308
Trained batch 789 in epoch 3, gen_loss = 0.7998075379223764, disc_loss = 0.101821051820924
Trained batch 790 in epoch 3, gen_loss = 0.799682898067795, disc_loss = 0.10180206442376606
Trained batch 791 in epoch 3, gen_loss = 0.799423094914116, disc_loss = 0.10189475365585149
Trained batch 792 in epoch 3, gen_loss = 0.7990454504123101, disc_loss = 0.101957574411569
Trained batch 793 in epoch 3, gen_loss = 0.7993650545626504, disc_loss = 0.10192826431554271
Trained batch 794 in epoch 3, gen_loss = 0.7990857458339548, disc_loss = 0.10194266384127755
Trained batch 795 in epoch 3, gen_loss = 0.7991450373176954, disc_loss = 0.101843899457561
Trained batch 796 in epoch 3, gen_loss = 0.7990111571408275, disc_loss = 0.10178728874683979
Trained batch 797 in epoch 3, gen_loss = 0.7993462700816921, disc_loss = 0.10191065534239724
Trained batch 798 in epoch 3, gen_loss = 0.7994057613335205, disc_loss = 0.1019096774082906
Trained batch 799 in epoch 3, gen_loss = 0.7989805855602026, disc_loss = 0.10211782076396048
Trained batch 800 in epoch 3, gen_loss = 0.798797895473785, disc_loss = 0.10227606629722574
Trained batch 801 in epoch 3, gen_loss = 0.7989998264354363, disc_loss = 0.10218106627352815
Trained batch 802 in epoch 3, gen_loss = 0.798884356229718, disc_loss = 0.10215626672782459
Trained batch 803 in epoch 3, gen_loss = 0.7990614986093483, disc_loss = 0.10237014103699382
Trained batch 804 in epoch 3, gen_loss = 0.7993747223238027, disc_loss = 0.10232842055536945
Trained batch 805 in epoch 3, gen_loss = 0.7988714785049335, disc_loss = 0.10245186927966385
Trained batch 806 in epoch 3, gen_loss = 0.7986697770996756, disc_loss = 0.10263325519573585
Trained batch 807 in epoch 3, gen_loss = 0.798648878784463, disc_loss = 0.10295372803022365
Trained batch 808 in epoch 3, gen_loss = 0.7987021047193719, disc_loss = 0.10289997251978321
Trained batch 809 in epoch 3, gen_loss = 0.7984414798242074, disc_loss = 0.10288330612727153
Trained batch 810 in epoch 3, gen_loss = 0.7983330604327445, disc_loss = 0.10281953034617015
Trained batch 811 in epoch 3, gen_loss = 0.7985156181410615, disc_loss = 0.10271957601085673
Trained batch 812 in epoch 3, gen_loss = 0.7985227540556942, disc_loss = 0.10268078290778332
Trained batch 813 in epoch 3, gen_loss = 0.7983472776354384, disc_loss = 0.10263505095675478
Trained batch 814 in epoch 3, gen_loss = 0.798113370161115, disc_loss = 0.10277761386398888
Trained batch 815 in epoch 3, gen_loss = 0.7984343785427365, disc_loss = 0.1026949364071091
Trained batch 816 in epoch 3, gen_loss = 0.7986092116578848, disc_loss = 0.10283570086430745
Trained batch 817 in epoch 3, gen_loss = 0.798396371468938, disc_loss = 0.10281891645385467
Trained batch 818 in epoch 3, gen_loss = 0.7982771298387549, disc_loss = 0.10284000465030053
Trained batch 819 in epoch 3, gen_loss = 0.7981564233215844, disc_loss = 0.10276950791296435
Trained batch 820 in epoch 3, gen_loss = 0.7983691566754201, disc_loss = 0.1027100980417955
Trained batch 821 in epoch 3, gen_loss = 0.7982053552955897, disc_loss = 0.10267035064452901
Trained batch 822 in epoch 3, gen_loss = 0.7987390166354498, disc_loss = 0.10273357664086694
Trained batch 823 in epoch 3, gen_loss = 0.7985602077639219, disc_loss = 0.1028224080574961
Trained batch 824 in epoch 3, gen_loss = 0.7983729616800944, disc_loss = 0.10281549633903937
Trained batch 825 in epoch 3, gen_loss = 0.7984368060749322, disc_loss = 0.10273642032959704
Trained batch 826 in epoch 3, gen_loss = 0.7984446143008489, disc_loss = 0.1028864284731817
Trained batch 827 in epoch 3, gen_loss = 0.7983589227072858, disc_loss = 0.10283819085283988
Trained batch 828 in epoch 3, gen_loss = 0.7984013006684288, disc_loss = 0.10279052192738462
Trained batch 829 in epoch 3, gen_loss = 0.7985526131578239, disc_loss = 0.10269259720906077
Trained batch 830 in epoch 3, gen_loss = 0.7988116767719191, disc_loss = 0.10261573098492321
Trained batch 831 in epoch 3, gen_loss = 0.7988086289081436, disc_loss = 0.10252794867399363
Trained batch 832 in epoch 3, gen_loss = 0.7987066976019458, disc_loss = 0.10249029843657673
Trained batch 833 in epoch 3, gen_loss = 0.7989024437017006, disc_loss = 0.10245722060134228
Trained batch 834 in epoch 3, gen_loss = 0.799019189937386, disc_loss = 0.10239787865541652
Trained batch 835 in epoch 3, gen_loss = 0.798874685924019, disc_loss = 0.10238625585997219
Trained batch 836 in epoch 3, gen_loss = 0.7988656796292449, disc_loss = 0.10233313883148498
Trained batch 837 in epoch 3, gen_loss = 0.7986228899910228, disc_loss = 0.10252387012601752
Trained batch 838 in epoch 3, gen_loss = 0.7985786943384519, disc_loss = 0.10255767854376828
Trained batch 839 in epoch 3, gen_loss = 0.7990909432371457, disc_loss = 0.10293641466469992
Trained batch 840 in epoch 3, gen_loss = 0.7986442802493836, disc_loss = 0.10312680838082548
Trained batch 841 in epoch 3, gen_loss = 0.7984294773139183, disc_loss = 0.10336350548720416
Trained batch 842 in epoch 3, gen_loss = 0.7981596864132412, disc_loss = 0.10341197508580603
Trained batch 843 in epoch 3, gen_loss = 0.7984030835718905, disc_loss = 0.10351713084708458
Trained batch 844 in epoch 3, gen_loss = 0.7982987274785014, disc_loss = 0.10358466197400404
Trained batch 845 in epoch 3, gen_loss = 0.7982188141937797, disc_loss = 0.10351925728133667
Trained batch 846 in epoch 3, gen_loss = 0.7985052080053084, disc_loss = 0.10352968136035566
Trained batch 847 in epoch 3, gen_loss = 0.7980873142984116, disc_loss = 0.10368527720664751
Trained batch 848 in epoch 3, gen_loss = 0.7982262410530634, disc_loss = 0.10392024020529467
Trained batch 849 in epoch 3, gen_loss = 0.7980407106525758, disc_loss = 0.10388090486035627
Trained batch 850 in epoch 3, gen_loss = 0.7979295619716376, disc_loss = 0.10391022303479819
Trained batch 851 in epoch 3, gen_loss = 0.7979682303720237, disc_loss = 0.10382768042175702
Trained batch 852 in epoch 3, gen_loss = 0.7977560559093323, disc_loss = 0.10390432022625508
Trained batch 853 in epoch 3, gen_loss = 0.7976134244605585, disc_loss = 0.10388793831198222
Trained batch 854 in epoch 3, gen_loss = 0.797833180950399, disc_loss = 0.10389529325460133
Trained batch 855 in epoch 3, gen_loss = 0.7978246933040775, disc_loss = 0.10382340622578408
Trained batch 856 in epoch 3, gen_loss = 0.7979312639600894, disc_loss = 0.10372664865927908
Trained batch 857 in epoch 3, gen_loss = 0.7979495224905458, disc_loss = 0.10382545460232627
Trained batch 858 in epoch 3, gen_loss = 0.7978158263235903, disc_loss = 0.10380520484691033
Trained batch 859 in epoch 3, gen_loss = 0.7976568663882655, disc_loss = 0.10379737161186546
Trained batch 860 in epoch 3, gen_loss = 0.7978006580219313, disc_loss = 0.10390849237986835
Trained batch 861 in epoch 3, gen_loss = 0.7975238093159868, disc_loss = 0.10395554539136018
Trained batch 862 in epoch 3, gen_loss = 0.7977513763125498, disc_loss = 0.10386905649963978
Trained batch 863 in epoch 3, gen_loss = 0.7974735231104272, disc_loss = 0.10387239527578156
Trained batch 864 in epoch 3, gen_loss = 0.7975528874493748, disc_loss = 0.1037686144588569
Trained batch 865 in epoch 3, gen_loss = 0.7973808908779131, disc_loss = 0.10372241159608506
Trained batch 866 in epoch 3, gen_loss = 0.7976777839206907, disc_loss = 0.10367392020615843
Trained batch 867 in epoch 3, gen_loss = 0.7976248557185797, disc_loss = 0.10363645875538927
Trained batch 868 in epoch 3, gen_loss = 0.7974676785795544, disc_loss = 0.10362771802375005
Trained batch 869 in epoch 3, gen_loss = 0.7977504002979432, disc_loss = 0.10353430656330853
Trained batch 870 in epoch 3, gen_loss = 0.7977940204428203, disc_loss = 0.10363200140409129
Trained batch 871 in epoch 3, gen_loss = 0.7975205400736507, disc_loss = 0.10367347673756507
Trained batch 872 in epoch 3, gen_loss = 0.7974343733074739, disc_loss = 0.10361975231202573
Trained batch 873 in epoch 3, gen_loss = 0.7977692916205055, disc_loss = 0.10358894332812874
Trained batch 874 in epoch 3, gen_loss = 0.798028829063688, disc_loss = 0.10350033114318337
Trained batch 875 in epoch 3, gen_loss = 0.7980383898909778, disc_loss = 0.10341655365276452
Trained batch 876 in epoch 3, gen_loss = 0.7982149514600108, disc_loss = 0.10337558323400628
Trained batch 877 in epoch 3, gen_loss = 0.7981474072012652, disc_loss = 0.10333956655110646
Trained batch 878 in epoch 3, gen_loss = 0.7979159310748282, disc_loss = 0.10336588908927738
Trained batch 879 in epoch 3, gen_loss = 0.7982432402331721, disc_loss = 0.10326117992041293
Trained batch 880 in epoch 3, gen_loss = 0.798587730638556, disc_loss = 0.10324818527095536
Trained batch 881 in epoch 3, gen_loss = 0.7985883145983798, disc_loss = 0.1032113148830831
Trained batch 882 in epoch 3, gen_loss = 0.7988037007648839, disc_loss = 0.10319414791690094
Trained batch 883 in epoch 3, gen_loss = 0.7990608424689974, disc_loss = 0.10309702695802495
Trained batch 884 in epoch 3, gen_loss = 0.7989455500901755, disc_loss = 0.10308721722287816
Trained batch 885 in epoch 3, gen_loss = 0.798778923350317, disc_loss = 0.10307113838152913
Trained batch 886 in epoch 3, gen_loss = 0.7991359473417147, disc_loss = 0.1029904327767963
Trained batch 887 in epoch 3, gen_loss = 0.7990635337794686, disc_loss = 0.10295111723013457
Trained batch 888 in epoch 3, gen_loss = 0.7989053509970215, disc_loss = 0.10285682369576699
Trained batch 889 in epoch 3, gen_loss = 0.7989453133907211, disc_loss = 0.1027888792420455
Trained batch 890 in epoch 3, gen_loss = 0.7987933433484015, disc_loss = 0.10279420702733877
Trained batch 891 in epoch 3, gen_loss = 0.7990494861263331, disc_loss = 0.10280388563290874
Trained batch 892 in epoch 3, gen_loss = 0.7993306525276863, disc_loss = 0.10281081519883296
Trained batch 893 in epoch 3, gen_loss = 0.799242116094169, disc_loss = 0.10283629990118229
Trained batch 894 in epoch 3, gen_loss = 0.799168193173808, disc_loss = 0.10283973929290166
Trained batch 895 in epoch 3, gen_loss = 0.799430470680818, disc_loss = 0.10278943107134962
Trained batch 896 in epoch 3, gen_loss = 0.7991269655783174, disc_loss = 0.10281215178797908
Trained batch 897 in epoch 3, gen_loss = 0.799312137183474, disc_loss = 0.10275794064236145
Trained batch 898 in epoch 3, gen_loss = 0.7993892765747957, disc_loss = 0.10273300648850282
Trained batch 899 in epoch 3, gen_loss = 0.7993379954828156, disc_loss = 0.10270818162812954
Trained batch 900 in epoch 3, gen_loss = 0.7990931917176263, disc_loss = 0.10269798149564588
Trained batch 901 in epoch 3, gen_loss = 0.7992869765227227, disc_loss = 0.1027006357794673
Trained batch 902 in epoch 3, gen_loss = 0.7993072661120498, disc_loss = 0.10262179689570552
Trained batch 903 in epoch 3, gen_loss = 0.7991112573154732, disc_loss = 0.10256281588741668
Trained batch 904 in epoch 3, gen_loss = 0.7991659459817475, disc_loss = 0.10249874237101546
Trained batch 905 in epoch 3, gen_loss = 0.7992697316355526, disc_loss = 0.10242165332438041
Trained batch 906 in epoch 3, gen_loss = 0.7996932051607635, disc_loss = 0.10265196256992605
Trained batch 907 in epoch 3, gen_loss = 0.7994043276632935, disc_loss = 0.10272256376956167
Trained batch 908 in epoch 3, gen_loss = 0.7993829397544084, disc_loss = 0.10262441879488748
Trained batch 909 in epoch 3, gen_loss = 0.7993034562239281, disc_loss = 0.10255867090219488
Trained batch 910 in epoch 3, gen_loss = 0.7996263097395097, disc_loss = 0.10258744982235812
Trained batch 911 in epoch 3, gen_loss = 0.7995959734380768, disc_loss = 0.10253327063452289
Trained batch 912 in epoch 3, gen_loss = 0.7993737118071821, disc_loss = 0.1025195974348621
Trained batch 913 in epoch 3, gen_loss = 0.7991897228705804, disc_loss = 0.10256208823097124
Trained batch 914 in epoch 3, gen_loss = 0.7994236324328542, disc_loss = 0.10258394731870277
Trained batch 915 in epoch 3, gen_loss = 0.799529494774654, disc_loss = 0.10253855511729146
Trained batch 916 in epoch 3, gen_loss = 0.7993338036238172, disc_loss = 0.10256380639511242
Trained batch 917 in epoch 3, gen_loss = 0.7994659545959211, disc_loss = 0.10267658691248635
Trained batch 918 in epoch 3, gen_loss = 0.7992906011681562, disc_loss = 0.1025925365644502
Trained batch 919 in epoch 3, gen_loss = 0.7989991882896942, disc_loss = 0.10263980412349591
Trained batch 920 in epoch 3, gen_loss = 0.7991026431872195, disc_loss = 0.1025475786299112
Trained batch 921 in epoch 3, gen_loss = 0.799398695860147, disc_loss = 0.1025774672318355
Trained batch 922 in epoch 3, gen_loss = 0.7991606277672983, disc_loss = 0.10263188667131239
Trained batch 923 in epoch 3, gen_loss = 0.7987496874807201, disc_loss = 0.10276935082957052
Trained batch 924 in epoch 3, gen_loss = 0.7990031112206949, disc_loss = 0.10276543938126918
Trained batch 925 in epoch 3, gen_loss = 0.7989870706979451, disc_loss = 0.10270852964375465
Trained batch 926 in epoch 3, gen_loss = 0.7988337340735566, disc_loss = 0.10274192519152402
Trained batch 927 in epoch 3, gen_loss = 0.7988760071196432, disc_loss = 0.10269869657951922
Trained batch 928 in epoch 3, gen_loss = 0.7987143064982412, disc_loss = 0.10269642251055483
Trained batch 929 in epoch 3, gen_loss = 0.798620456008501, disc_loss = 0.10267708545390476
Trained batch 930 in epoch 3, gen_loss = 0.7987102464113532, disc_loss = 0.10260224124570762
Trained batch 931 in epoch 3, gen_loss = 0.7985442145827503, disc_loss = 0.10253622829654283
Trained batch 932 in epoch 3, gen_loss = 0.7983047769895065, disc_loss = 0.10254568889206085
Trained batch 933 in epoch 3, gen_loss = 0.7987776552456605, disc_loss = 0.10256603254779088
Trained batch 934 in epoch 3, gen_loss = 0.7989841465644021, disc_loss = 0.10254794462698506
Trained batch 935 in epoch 3, gen_loss = 0.7987652873763671, disc_loss = 0.10266686475967081
Trained batch 936 in epoch 3, gen_loss = 0.7989849857866701, disc_loss = 0.10257308587348417
Trained batch 937 in epoch 3, gen_loss = 0.7992396859853252, disc_loss = 0.10251743846765554
Trained batch 938 in epoch 3, gen_loss = 0.7993768767173044, disc_loss = 0.10242959664870724
Trained batch 939 in epoch 3, gen_loss = 0.7990836071207168, disc_loss = 0.10245174965226746
Trained batch 940 in epoch 3, gen_loss = 0.7993004128226058, disc_loss = 0.10250526968999414
Trained batch 941 in epoch 3, gen_loss = 0.7993045684005551, disc_loss = 0.10263629670446688
Trained batch 942 in epoch 3, gen_loss = 0.7992843967859464, disc_loss = 0.1026216840493954
Trained batch 943 in epoch 3, gen_loss = 0.7995283930104667, disc_loss = 0.10252417045373122
Trained batch 944 in epoch 3, gen_loss = 0.7996755596821901, disc_loss = 0.10243562081404937
Trained batch 945 in epoch 3, gen_loss = 0.7997852075553595, disc_loss = 0.10240247268249413
Trained batch 946 in epoch 3, gen_loss = 0.799547990247088, disc_loss = 0.10237717057982462
Trained batch 947 in epoch 3, gen_loss = 0.799813566328604, disc_loss = 0.10228649790807458
Trained batch 948 in epoch 3, gen_loss = 0.8001734867487869, disc_loss = 0.10222645147406233
Trained batch 949 in epoch 3, gen_loss = 0.800338229129189, disc_loss = 0.102159927168763
Trained batch 950 in epoch 3, gen_loss = 0.8003397713073546, disc_loss = 0.10209806821554837
Trained batch 951 in epoch 3, gen_loss = 0.8004616495816648, disc_loss = 0.10204167869000719
Trained batch 952 in epoch 3, gen_loss = 0.8006860728904308, disc_loss = 0.10196409114428326
Trained batch 953 in epoch 3, gen_loss = 0.8005967011491708, disc_loss = 0.10188822937442041
Trained batch 954 in epoch 3, gen_loss = 0.8004453490541867, disc_loss = 0.10185348424592411
Trained batch 955 in epoch 3, gen_loss = 0.8004092120849936, disc_loss = 0.10178049175540242
Trained batch 956 in epoch 3, gen_loss = 0.8006794423394318, disc_loss = 0.10173655339772643
Trained batch 957 in epoch 3, gen_loss = 0.8009076929167068, disc_loss = 0.101647382941377
Trained batch 958 in epoch 3, gen_loss = 0.8011675927014992, disc_loss = 0.10160989785223143
Trained batch 959 in epoch 3, gen_loss = 0.8011705723280708, disc_loss = 0.10160336640450017
Trained batch 960 in epoch 3, gen_loss = 0.8012683933036756, disc_loss = 0.10174558742086207
Trained batch 961 in epoch 3, gen_loss = 0.8009600628190625, disc_loss = 0.10184625407735083
Trained batch 962 in epoch 3, gen_loss = 0.8008892966331846, disc_loss = 0.10178142795406925
Trained batch 963 in epoch 3, gen_loss = 0.8007674322336047, disc_loss = 0.10172939140260745
Trained batch 964 in epoch 3, gen_loss = 0.8007589827547419, disc_loss = 0.10172701461501227
Trained batch 965 in epoch 3, gen_loss = 0.8009676859862562, disc_loss = 0.10164803964053097
Trained batch 966 in epoch 3, gen_loss = 0.8008307858361576, disc_loss = 0.10164267681789466
Trained batch 967 in epoch 3, gen_loss = 0.8009939122298533, disc_loss = 0.10159165043025932
Trained batch 968 in epoch 3, gen_loss = 0.8010467329015427, disc_loss = 0.10151346846434631
Trained batch 969 in epoch 3, gen_loss = 0.8011112281956624, disc_loss = 0.10142201606337864
Trained batch 970 in epoch 3, gen_loss = 0.8014154439114886, disc_loss = 0.10152500691554144
Trained batch 971 in epoch 3, gen_loss = 0.8012689675200623, disc_loss = 0.10155068587994685
Trained batch 972 in epoch 3, gen_loss = 0.8010677028167897, disc_loss = 0.10150937432995619
Trained batch 973 in epoch 3, gen_loss = 0.8009609039069691, disc_loss = 0.10144263138952503
Trained batch 974 in epoch 3, gen_loss = 0.8010947855924949, disc_loss = 0.10140786511202653
Trained batch 975 in epoch 3, gen_loss = 0.8009526381482843, disc_loss = 0.10142967740997488
Trained batch 976 in epoch 3, gen_loss = 0.8010080899650511, disc_loss = 0.10135024237497009
Trained batch 977 in epoch 3, gen_loss = 0.8009668394222338, disc_loss = 0.10128270444062164
Trained batch 978 in epoch 3, gen_loss = 0.8008371306025823, disc_loss = 0.10139500004438202
Trained batch 979 in epoch 3, gen_loss = 0.8008862573881539, disc_loss = 0.10133180770908995
Trained batch 980 in epoch 3, gen_loss = 0.8007189677638988, disc_loss = 0.10125829016449923
Trained batch 981 in epoch 3, gen_loss = 0.8009114808681783, disc_loss = 0.10123517299583087
Trained batch 982 in epoch 3, gen_loss = 0.8008870494571853, disc_loss = 0.10125835432215297
Trained batch 983 in epoch 3, gen_loss = 0.8007089669505755, disc_loss = 0.10130056902213491
Trained batch 984 in epoch 3, gen_loss = 0.8009337821587693, disc_loss = 0.10124041849397464
Trained batch 985 in epoch 3, gen_loss = 0.8008064530925867, disc_loss = 0.10119781068301406
Trained batch 986 in epoch 3, gen_loss = 0.8005947979750242, disc_loss = 0.10119143671336327
Trained batch 987 in epoch 3, gen_loss = 0.8004208205320574, disc_loss = 0.1011340196380158
Trained batch 988 in epoch 3, gen_loss = 0.8009029112763786, disc_loss = 0.10132802915321502
Trained batch 989 in epoch 3, gen_loss = 0.8009331691746759, disc_loss = 0.10127421314404769
Trained batch 990 in epoch 3, gen_loss = 0.8006349441742922, disc_loss = 0.10141351714722745
Trained batch 991 in epoch 3, gen_loss = 0.8005237328789888, disc_loss = 0.10135752525398388
Trained batch 992 in epoch 3, gen_loss = 0.8004707321899776, disc_loss = 0.10139044428437438
Trained batch 993 in epoch 3, gen_loss = 0.8007609356696936, disc_loss = 0.10148833615057005
Trained batch 994 in epoch 3, gen_loss = 0.8005426393082393, disc_loss = 0.1015559883367027
Trained batch 995 in epoch 3, gen_loss = 0.8001777647609213, disc_loss = 0.10166601316973448
Trained batch 996 in epoch 3, gen_loss = 0.8003806195622581, disc_loss = 0.10162308617656604
Trained batch 997 in epoch 3, gen_loss = 0.8002551662061879, disc_loss = 0.10160929983470567
Trained batch 998 in epoch 3, gen_loss = 0.8003643986221787, disc_loss = 0.10153784472551253
Trained batch 999 in epoch 3, gen_loss = 0.8003770549297333, disc_loss = 0.10145165770873428
Trained batch 1000 in epoch 3, gen_loss = 0.8002985506267338, disc_loss = 0.10138973497323223
Trained batch 1001 in epoch 3, gen_loss = 0.8002644870690481, disc_loss = 0.1013439090331336
Trained batch 1002 in epoch 3, gen_loss = 0.8001188784392025, disc_loss = 0.10134938476256217
Trained batch 1003 in epoch 3, gen_loss = 0.799999842308907, disc_loss = 0.10132855204754022
Trained batch 1004 in epoch 3, gen_loss = 0.7999388535817464, disc_loss = 0.10127880561040409
Trained batch 1005 in epoch 3, gen_loss = 0.8002192085353328, disc_loss = 0.10119762224983979
Trained batch 1006 in epoch 3, gen_loss = 0.8005977567163219, disc_loss = 0.10112604986073481
Trained batch 1007 in epoch 3, gen_loss = 0.8006246228303228, disc_loss = 0.10105732407435657
Trained batch 1008 in epoch 3, gen_loss = 0.8003825405898722, disc_loss = 0.10113611733550122
Trained batch 1009 in epoch 3, gen_loss = 0.8004585387093006, disc_loss = 0.10114299853765728
Trained batch 1010 in epoch 3, gen_loss = 0.8005906974880207, disc_loss = 0.10108391872794173
Trained batch 1011 in epoch 3, gen_loss = 0.8004166993934646, disc_loss = 0.10106710649349472
Trained batch 1012 in epoch 3, gen_loss = 0.800180776509928, disc_loss = 0.10105556445996124
Trained batch 1013 in epoch 3, gen_loss = 0.8007840802801196, disc_loss = 0.10105767439778975
Trained batch 1014 in epoch 3, gen_loss = 0.8007642677852086, disc_loss = 0.10100893269618744
Trained batch 1015 in epoch 3, gen_loss = 0.8006146799508981, disc_loss = 0.10099275539240499
Trained batch 1016 in epoch 3, gen_loss = 0.8004517405785642, disc_loss = 0.10099947718480344
Trained batch 1017 in epoch 3, gen_loss = 0.8005922492337367, disc_loss = 0.10095019919581873
Trained batch 1018 in epoch 3, gen_loss = 0.8005644092966928, disc_loss = 0.10089796152006071
Trained batch 1019 in epoch 3, gen_loss = 0.800313254664926, disc_loss = 0.1009603987648791
Trained batch 1020 in epoch 3, gen_loss = 0.8007902749955479, disc_loss = 0.10094173838558673
Trained batch 1021 in epoch 3, gen_loss = 0.8008894792041666, disc_loss = 0.10090598550765481
Trained batch 1022 in epoch 3, gen_loss = 0.8005560228668467, disc_loss = 0.10102296378809453
Trained batch 1023 in epoch 3, gen_loss = 0.8004257580614649, disc_loss = 0.10100251271069283
Trained batch 1024 in epoch 3, gen_loss = 0.8005982635079361, disc_loss = 0.10092704233599872
Trained batch 1025 in epoch 3, gen_loss = 0.8008674200747677, disc_loss = 0.10087267504042817
Trained batch 1026 in epoch 3, gen_loss = 0.800833424609499, disc_loss = 0.10083321713368175
Trained batch 1027 in epoch 3, gen_loss = 0.8007152853424911, disc_loss = 0.10080807274823522
Trained batch 1028 in epoch 3, gen_loss = 0.8007687089857949, disc_loss = 0.10078289166483866
Trained batch 1029 in epoch 3, gen_loss = 0.8008459943590812, disc_loss = 0.10080079631608667
Trained batch 1030 in epoch 3, gen_loss = 0.8007718148333256, disc_loss = 0.10077066587286014
Trained batch 1031 in epoch 3, gen_loss = 0.8008408577636231, disc_loss = 0.1007003531350877
Trained batch 1032 in epoch 3, gen_loss = 0.800713789659225, disc_loss = 0.10073369245215284
Trained batch 1033 in epoch 3, gen_loss = 0.8007317454026331, disc_loss = 0.10073252057573781
Trained batch 1034 in epoch 3, gen_loss = 0.8007248915335983, disc_loss = 0.10076713208559054
Trained batch 1035 in epoch 3, gen_loss = 0.8006608627707802, disc_loss = 0.10072096337611036
Trained batch 1036 in epoch 3, gen_loss = 0.8008349187808649, disc_loss = 0.10070623758113373
Trained batch 1037 in epoch 3, gen_loss = 0.8009886688809404, disc_loss = 0.10066179496905478
Trained batch 1038 in epoch 3, gen_loss = 0.8012523233488962, disc_loss = 0.10057402937829896
Trained batch 1039 in epoch 3, gen_loss = 0.8011835638147135, disc_loss = 0.10057447696677767
Trained batch 1040 in epoch 3, gen_loss = 0.8010141519716906, disc_loss = 0.10057735384426703
Trained batch 1041 in epoch 3, gen_loss = 0.8009669422645715, disc_loss = 0.1005262238457942
Trained batch 1042 in epoch 3, gen_loss = 0.8007809915798623, disc_loss = 0.10054790288252775
Trained batch 1043 in epoch 3, gen_loss = 0.8008489444338042, disc_loss = 0.10055850126148982
Trained batch 1044 in epoch 3, gen_loss = 0.800712428937118, disc_loss = 0.10052608421616006
Trained batch 1045 in epoch 3, gen_loss = 0.8011704507794937, disc_loss = 0.10064433266125605
Trained batch 1046 in epoch 3, gen_loss = 0.8011952081860649, disc_loss = 0.10061359496959757
Trained batch 1047 in epoch 3, gen_loss = 0.8010043720252641, disc_loss = 0.100580696667054
Trained batch 1048 in epoch 3, gen_loss = 0.8008982273825472, disc_loss = 0.10057713358784653
Trained batch 1049 in epoch 3, gen_loss = 0.8010920282772609, disc_loss = 0.10052948823642163
Trained batch 1050 in epoch 3, gen_loss = 0.801415109158016, disc_loss = 0.10047600438887454
Trained batch 1051 in epoch 3, gen_loss = 0.8012764850496793, disc_loss = 0.10057619833051025
Trained batch 1052 in epoch 3, gen_loss = 0.8011192442797981, disc_loss = 0.10060599815641713
Trained batch 1053 in epoch 3, gen_loss = 0.8013624819790842, disc_loss = 0.10071755111556804
Trained batch 1054 in epoch 3, gen_loss = 0.8013303923380883, disc_loss = 0.10068253196811223
Trained batch 1055 in epoch 3, gen_loss = 0.8012112661293058, disc_loss = 0.1006504839328541
Trained batch 1056 in epoch 3, gen_loss = 0.8012298608345024, disc_loss = 0.10059477562964132
Trained batch 1057 in epoch 3, gen_loss = 0.8010609561193642, disc_loss = 0.10061537708192782
Trained batch 1058 in epoch 3, gen_loss = 0.8014150535981536, disc_loss = 0.10065881664512065
Trained batch 1059 in epoch 3, gen_loss = 0.8011950831930592, disc_loss = 0.1006777472091171
Trained batch 1060 in epoch 3, gen_loss = 0.8012832076789971, disc_loss = 0.10059841041094171
Trained batch 1061 in epoch 3, gen_loss = 0.801453286981852, disc_loss = 0.10051970982576831
Trained batch 1062 in epoch 3, gen_loss = 0.8017289981680553, disc_loss = 0.10047384877868788
Trained batch 1063 in epoch 3, gen_loss = 0.8018580382703838, disc_loss = 0.10040923781847035
Trained batch 1064 in epoch 3, gen_loss = 0.8021138666940967, disc_loss = 0.10035286498181696
Trained batch 1065 in epoch 3, gen_loss = 0.8020436552407371, disc_loss = 0.10029913242871386
Trained batch 1066 in epoch 3, gen_loss = 0.802268508112978, disc_loss = 0.10021514596021276
Trained batch 1067 in epoch 3, gen_loss = 0.8024096375101069, disc_loss = 0.1001631146652645
Trained batch 1068 in epoch 3, gen_loss = 0.8026733198826062, disc_loss = 0.10017910099982992
Trained batch 1069 in epoch 3, gen_loss = 0.8028772292850174, disc_loss = 0.10011040598815568
Trained batch 1070 in epoch 3, gen_loss = 0.8027199855705603, disc_loss = 0.1002055561825647
Trained batch 1071 in epoch 3, gen_loss = 0.8028776820248632, disc_loss = 0.10013146824446688
Trained batch 1072 in epoch 3, gen_loss = 0.8028212928483115, disc_loss = 0.10006310261841533
Trained batch 1073 in epoch 3, gen_loss = 0.8028210833862951, disc_loss = 0.10005608575810544
Trained batch 1074 in epoch 3, gen_loss = 0.8029212951660156, disc_loss = 0.09998313001595265
Trained batch 1075 in epoch 3, gen_loss = 0.8027817041900521, disc_loss = 0.0999779552446339
Trained batch 1076 in epoch 3, gen_loss = 0.8026228689328321, disc_loss = 0.09994420443273244
Trained batch 1077 in epoch 3, gen_loss = 0.8027222149336714, disc_loss = 0.10003574131184528
Trained batch 1078 in epoch 3, gen_loss = 0.8028798743571475, disc_loss = 0.09996109268868876
Trained batch 1079 in epoch 3, gen_loss = 0.802680925031503, disc_loss = 0.09996919494846629
Trained batch 1080 in epoch 3, gen_loss = 0.8024492607306375, disc_loss = 0.1000211563436909
Trained batch 1081 in epoch 3, gen_loss = 0.8024494526236423, disc_loss = 0.09998181517203227
Trained batch 1082 in epoch 3, gen_loss = 0.8023302603516442, disc_loss = 0.09995907478185848
Trained batch 1083 in epoch 3, gen_loss = 0.8023468583712279, disc_loss = 0.09992510337224471
Trained batch 1084 in epoch 3, gen_loss = 0.8022538558678693, disc_loss = 0.0998785466007236
Trained batch 1085 in epoch 3, gen_loss = 0.8021086617947503, disc_loss = 0.09983341355549093
Trained batch 1086 in epoch 3, gen_loss = 0.8020297338793666, disc_loss = 0.09977842246892536
Trained batch 1087 in epoch 3, gen_loss = 0.8021328498006743, disc_loss = 0.09981106234515798
Trained batch 1088 in epoch 3, gen_loss = 0.8020196569086325, disc_loss = 0.09980363624394488
Trained batch 1089 in epoch 3, gen_loss = 0.8018416749774863, disc_loss = 0.09977068358160761
Trained batch 1090 in epoch 3, gen_loss = 0.8022893370563672, disc_loss = 0.09974460091909665
Trained batch 1091 in epoch 3, gen_loss = 0.8022547187931809, disc_loss = 0.09975636364796604
Trained batch 1092 in epoch 3, gen_loss = 0.8021300411071672, disc_loss = 0.09971071311936451
Trained batch 1093 in epoch 3, gen_loss = 0.8021016236959907, disc_loss = 0.09966251582172878
Trained batch 1094 in epoch 3, gen_loss = 0.8021779889929784, disc_loss = 0.09966843872411882
Trained batch 1095 in epoch 3, gen_loss = 0.8024655306426278, disc_loss = 0.09965810335214066
Trained batch 1096 in epoch 3, gen_loss = 0.8024594004630173, disc_loss = 0.09958479103335979
Trained batch 1097 in epoch 3, gen_loss = 0.8022032223221166, disc_loss = 0.09961263809814533
Trained batch 1098 in epoch 3, gen_loss = 0.802052687850185, disc_loss = 0.09960898937482905
Trained batch 1099 in epoch 3, gen_loss = 0.802459552992474, disc_loss = 0.09967558138919147
Trained batch 1100 in epoch 3, gen_loss = 0.8028985878535556, disc_loss = 0.09999864788846088
Trained batch 1101 in epoch 3, gen_loss = 0.8027490566192218, disc_loss = 0.10001174053058921
Trained batch 1102 in epoch 3, gen_loss = 0.8024784067708152, disc_loss = 0.10024518146942069
Trained batch 1103 in epoch 3, gen_loss = 0.8024296196366566, disc_loss = 0.10019165946784821
Trained batch 1104 in epoch 3, gen_loss = 0.8026919808862436, disc_loss = 0.10033273931373568
Trained batch 1105 in epoch 3, gen_loss = 0.8023091885000198, disc_loss = 0.10045359243098209
Trained batch 1106 in epoch 3, gen_loss = 0.8023022545170116, disc_loss = 0.10050359096246844
Trained batch 1107 in epoch 3, gen_loss = 0.8023433189852573, disc_loss = 0.10047899526695213
Trained batch 1108 in epoch 3, gen_loss = 0.80203336232734, disc_loss = 0.1005228714844442
Trained batch 1109 in epoch 3, gen_loss = 0.8022954853536847, disc_loss = 0.10048493145050498
Trained batch 1110 in epoch 3, gen_loss = 0.8021881820970994, disc_loss = 0.10047277110242339
Trained batch 1111 in epoch 3, gen_loss = 0.802154344968873, disc_loss = 0.10046124541562507
Trained batch 1112 in epoch 3, gen_loss = 0.8021919542299341, disc_loss = 0.10053160261975305
Trained batch 1113 in epoch 3, gen_loss = 0.8020520224444956, disc_loss = 0.1005589351797045
Trained batch 1114 in epoch 3, gen_loss = 0.8020309085001326, disc_loss = 0.10051130596130685
Trained batch 1115 in epoch 3, gen_loss = 0.8017743515872187, disc_loss = 0.10065636879807892
Trained batch 1116 in epoch 3, gen_loss = 0.8017965520772959, disc_loss = 0.1006264136945737
Trained batch 1117 in epoch 3, gen_loss = 0.8018428552929106, disc_loss = 0.10055414327688529
Trained batch 1118 in epoch 3, gen_loss = 0.8016843297473014, disc_loss = 0.10051343545077952
Trained batch 1119 in epoch 3, gen_loss = 0.8015757501391428, disc_loss = 0.10046425484386938
Trained batch 1120 in epoch 3, gen_loss = 0.8021811227996258, disc_loss = 0.10055413646797959
Trained batch 1121 in epoch 3, gen_loss = 0.8022134613491422, disc_loss = 0.10050053474179564
Trained batch 1122 in epoch 3, gen_loss = 0.8020208691075139, disc_loss = 0.10048142458351192
Trained batch 1123 in epoch 3, gen_loss = 0.8019693244341429, disc_loss = 0.10054984835251582
Trained batch 1124 in epoch 3, gen_loss = 0.801715500275294, disc_loss = 0.10064507693052292
Trained batch 1125 in epoch 3, gen_loss = 0.8016027872505239, disc_loss = 0.10062518751589486
Trained batch 1126 in epoch 3, gen_loss = 0.8017292279475753, disc_loss = 0.10061627485605078
Trained batch 1127 in epoch 3, gen_loss = 0.801850463719444, disc_loss = 0.1005697280518605
Trained batch 1128 in epoch 3, gen_loss = 0.8016315363116556, disc_loss = 0.10063501803470037
Trained batch 1129 in epoch 3, gen_loss = 0.8013907576293017, disc_loss = 0.10064337853902737
Trained batch 1130 in epoch 3, gen_loss = 0.8017103853581966, disc_loss = 0.1007129748827003
Trained batch 1131 in epoch 3, gen_loss = 0.8016060796885525, disc_loss = 0.1007025876632059
Trained batch 1132 in epoch 3, gen_loss = 0.8013068174274223, disc_loss = 0.10081749438042674
Trained batch 1133 in epoch 3, gen_loss = 0.8012522071915329, disc_loss = 0.10088515744546209
Trained batch 1134 in epoch 3, gen_loss = 0.8015542172912984, disc_loss = 0.10093597777942728
Trained batch 1135 in epoch 3, gen_loss = 0.8012959995687428, disc_loss = 0.10096482553807887
Trained batch 1136 in epoch 3, gen_loss = 0.8010597900276972, disc_loss = 0.1010859782464324
Trained batch 1137 in epoch 3, gen_loss = 0.8013133850007569, disc_loss = 0.10115038074867273
Trained batch 1138 in epoch 3, gen_loss = 0.8012247876026214, disc_loss = 0.10109969811666106
Trained batch 1139 in epoch 3, gen_loss = 0.8010682149153007, disc_loss = 0.10107917564414572
Trained batch 1140 in epoch 3, gen_loss = 0.8008930929965037, disc_loss = 0.10105788996026874
Trained batch 1141 in epoch 3, gen_loss = 0.8007315977912024, disc_loss = 0.10109748090772307
Trained batch 1142 in epoch 3, gen_loss = 0.8008552971943783, disc_loss = 0.10115640037159386
Trained batch 1143 in epoch 3, gen_loss = 0.800492489228507, disc_loss = 0.10128543396656225
Trained batch 1144 in epoch 3, gen_loss = 0.8005366374571771, disc_loss = 0.10122796677736216
Trained batch 1145 in epoch 3, gen_loss = 0.800641401561975, disc_loss = 0.10138863307565295
Trained batch 1146 in epoch 3, gen_loss = 0.8004831619489265, disc_loss = 0.10143135610802234
Trained batch 1147 in epoch 3, gen_loss = 0.8004080937454925, disc_loss = 0.10144198854625848
Trained batch 1148 in epoch 3, gen_loss = 0.8004109962438893, disc_loss = 0.10139315188242312
Trained batch 1149 in epoch 3, gen_loss = 0.8004563555769298, disc_loss = 0.10133506451287995
Trained batch 1150 in epoch 3, gen_loss = 0.8004266828635171, disc_loss = 0.10134301070839193
Trained batch 1151 in epoch 3, gen_loss = 0.8002213820970306, disc_loss = 0.10141212570468067
Trained batch 1152 in epoch 3, gen_loss = 0.8003092292641312, disc_loss = 0.1014482170983128
Trained batch 1153 in epoch 3, gen_loss = 0.8002155250393539, disc_loss = 0.10144821871749966
Trained batch 1154 in epoch 3, gen_loss = 0.79996393415835, disc_loss = 0.10146364858333683
Trained batch 1155 in epoch 3, gen_loss = 0.8001382518753049, disc_loss = 0.10141816154560622
Trained batch 1156 in epoch 3, gen_loss = 0.8001495320269437, disc_loss = 0.10135375519662246
Trained batch 1157 in epoch 3, gen_loss = 0.8001075936979992, disc_loss = 0.1012916582908372
Trained batch 1158 in epoch 3, gen_loss = 0.8000751404385817, disc_loss = 0.10130354195891063
Trained batch 1159 in epoch 3, gen_loss = 0.7998423096177907, disc_loss = 0.10138713704133086
Trained batch 1160 in epoch 3, gen_loss = 0.7999721049081653, disc_loss = 0.10132488447123565
Trained batch 1161 in epoch 3, gen_loss = 0.7998902819499296, disc_loss = 0.10132422039634749
Trained batch 1162 in epoch 3, gen_loss = 0.7999090476222624, disc_loss = 0.10139570018614506
Trained batch 1163 in epoch 3, gen_loss = 0.7996945541697679, disc_loss = 0.10140652522361514
Trained batch 1164 in epoch 3, gen_loss = 0.799641923152326, disc_loss = 0.10145486852098176
Trained batch 1165 in epoch 3, gen_loss = 0.799508608967117, disc_loss = 0.10143957788517657
Trained batch 1166 in epoch 3, gen_loss = 0.7993702818771254, disc_loss = 0.1014073111081772
Trained batch 1167 in epoch 3, gen_loss = 0.7991470033940795, disc_loss = 0.10148352033567092
Trained batch 1168 in epoch 3, gen_loss = 0.7991641262997105, disc_loss = 0.10143121261025362
Trained batch 1169 in epoch 3, gen_loss = 0.7990871500510436, disc_loss = 0.10138124226727802
Trained batch 1170 in epoch 3, gen_loss = 0.7991044442690305, disc_loss = 0.10131990897010322
Trained batch 1171 in epoch 3, gen_loss = 0.7990807181688299, disc_loss = 0.10127892887931787
Trained batch 1172 in epoch 3, gen_loss = 0.7990681023193239, disc_loss = 0.10128414434462608
Trained batch 1173 in epoch 3, gen_loss = 0.7989786304596945, disc_loss = 0.10122144834362161
Trained batch 1174 in epoch 3, gen_loss = 0.7991681259997347, disc_loss = 0.10116118524619873
Trained batch 1175 in epoch 3, gen_loss = 0.798963576073752, disc_loss = 0.10125481221685503
Trained batch 1176 in epoch 3, gen_loss = 0.7991729792691735, disc_loss = 0.10122274529875692
Trained batch 1177 in epoch 3, gen_loss = 0.7990788299533427, disc_loss = 0.10117168089529857
Trained batch 1178 in epoch 3, gen_loss = 0.799193835566871, disc_loss = 0.10109474191377359
Trained batch 1179 in epoch 3, gen_loss = 0.7989105781761267, disc_loss = 0.10123212295110827
Trained batch 1180 in epoch 3, gen_loss = 0.7989590389560987, disc_loss = 0.1011693834632345
Trained batch 1181 in epoch 3, gen_loss = 0.7992445351004399, disc_loss = 0.10133022318835261
Trained batch 1182 in epoch 3, gen_loss = 0.799055426683047, disc_loss = 0.10134292621203302
Trained batch 1183 in epoch 3, gen_loss = 0.7989275887407161, disc_loss = 0.10139644752505135
Trained batch 1184 in epoch 3, gen_loss = 0.7988175592342006, disc_loss = 0.10138172849242572
Trained batch 1185 in epoch 3, gen_loss = 0.7987429026206468, disc_loss = 0.10136118428750218
Trained batch 1186 in epoch 3, gen_loss = 0.798919575598025, disc_loss = 0.10132762151609451
Trained batch 1187 in epoch 3, gen_loss = 0.7990494007715071, disc_loss = 0.10127158431878772
Trained batch 1188 in epoch 3, gen_loss = 0.7989019257767648, disc_loss = 0.10130524483906486
Trained batch 1189 in epoch 3, gen_loss = 0.7991874426352877, disc_loss = 0.10126457336053503
Trained batch 1190 in epoch 3, gen_loss = 0.7991625649102289, disc_loss = 0.10123054239598644
Trained batch 1191 in epoch 3, gen_loss = 0.7991348403512232, disc_loss = 0.10118618904028538
Trained batch 1192 in epoch 3, gen_loss = 0.7990397649558771, disc_loss = 0.10115199351459991
Trained batch 1193 in epoch 3, gen_loss = 0.7993007754560691, disc_loss = 0.10119648478298106
Trained batch 1194 in epoch 3, gen_loss = 0.7990159695617325, disc_loss = 0.10128742682993037
Trained batch 1195 in epoch 3, gen_loss = 0.7988899266939099, disc_loss = 0.10129982224559679
Trained batch 1196 in epoch 3, gen_loss = 0.7991170539095089, disc_loss = 0.10136126745149879
Trained batch 1197 in epoch 3, gen_loss = 0.798940263029331, disc_loss = 0.1013984724977217
Trained batch 1198 in epoch 3, gen_loss = 0.7988191040681739, disc_loss = 0.10136785078793764
Trained batch 1199 in epoch 3, gen_loss = 0.7990577846765519, disc_loss = 0.10137057001624877
Trained batch 1200 in epoch 3, gen_loss = 0.7988412087406346, disc_loss = 0.10137094153660496
Trained batch 1201 in epoch 3, gen_loss = 0.7988430007721937, disc_loss = 0.10136277359614332
Trained batch 1202 in epoch 3, gen_loss = 0.7987910488795362, disc_loss = 0.10134906616798933
Trained batch 1203 in epoch 3, gen_loss = 0.798855334718362, disc_loss = 0.1014130376735733
Trained batch 1204 in epoch 3, gen_loss = 0.7987937364835462, disc_loss = 0.10137340923176143
Trained batch 1205 in epoch 3, gen_loss = 0.7987110610328504, disc_loss = 0.10140242072588349
Trained batch 1206 in epoch 3, gen_loss = 0.7986912122914489, disc_loss = 0.10136841896415226
Trained batch 1207 in epoch 3, gen_loss = 0.7987499943632164, disc_loss = 0.10130260083808977
Trained batch 1208 in epoch 3, gen_loss = 0.7988583427307722, disc_loss = 0.101239864031936
Trained batch 1209 in epoch 3, gen_loss = 0.7989312475377863, disc_loss = 0.10126958964084667
Trained batch 1210 in epoch 3, gen_loss = 0.7988467392697007, disc_loss = 0.10126771819627821
Trained batch 1211 in epoch 3, gen_loss = 0.7989935684617203, disc_loss = 0.10121045107553674
Trained batch 1212 in epoch 3, gen_loss = 0.7987071136649935, disc_loss = 0.10130887169249644
Trained batch 1213 in epoch 3, gen_loss = 0.7987806091002224, disc_loss = 0.10134112463858978
Trained batch 1214 in epoch 3, gen_loss = 0.7989287709503017, disc_loss = 0.10155273930633386
Trained batch 1215 in epoch 3, gen_loss = 0.7986339028728636, disc_loss = 0.10181936128662385
Trained batch 1216 in epoch 3, gen_loss = 0.7984860433646667, disc_loss = 0.1017924546912288
Trained batch 1217 in epoch 3, gen_loss = 0.7984176625074033, disc_loss = 0.10177984422268514
Trained batch 1218 in epoch 3, gen_loss = 0.7984699862623332, disc_loss = 0.10177693211254255
Trained batch 1219 in epoch 3, gen_loss = 0.7981875643866961, disc_loss = 0.10177917236416432
Trained batch 1220 in epoch 3, gen_loss = 0.7981021751838078, disc_loss = 0.10176137706263327
Trained batch 1221 in epoch 3, gen_loss = 0.798125842540432, disc_loss = 0.10178378952587856
Trained batch 1222 in epoch 3, gen_loss = 0.7981487334700559, disc_loss = 0.1017311052217446
Trained batch 1223 in epoch 3, gen_loss = 0.7981583825221249, disc_loss = 0.10173005612150103
Trained batch 1224 in epoch 3, gen_loss = 0.7982606790017108, disc_loss = 0.10168686404748231
Trained batch 1225 in epoch 3, gen_loss = 0.798521270224943, disc_loss = 0.10161391802384331
Trained batch 1226 in epoch 3, gen_loss = 0.7988775218028602, disc_loss = 0.10169908669021986
Trained batch 1227 in epoch 3, gen_loss = 0.7987037551034157, disc_loss = 0.10174128087920042
Trained batch 1228 in epoch 3, gen_loss = 0.7987557234950333, disc_loss = 0.10170640171019768
Trained batch 1229 in epoch 3, gen_loss = 0.7988565628606129, disc_loss = 0.10163448001977389
Trained batch 1230 in epoch 3, gen_loss = 0.7987678151707839, disc_loss = 0.10161279080470435
Trained batch 1231 in epoch 3, gen_loss = 0.7990139329975302, disc_loss = 0.10162149701424718
Trained batch 1232 in epoch 3, gen_loss = 0.7990750070035892, disc_loss = 0.10157580478517195
Trained batch 1233 in epoch 3, gen_loss = 0.7989441628297685, disc_loss = 0.10161002300909118
Trained batch 1234 in epoch 3, gen_loss = 0.7988608431719575, disc_loss = 0.10158789296019897
Trained batch 1235 in epoch 3, gen_loss = 0.7991358136281999, disc_loss = 0.1015467475707911
Trained batch 1236 in epoch 3, gen_loss = 0.7992031417166695, disc_loss = 0.10149446671276008
Trained batch 1237 in epoch 3, gen_loss = 0.7990932598445257, disc_loss = 0.10147364048801832
Trained batch 1238 in epoch 3, gen_loss = 0.7993160530479807, disc_loss = 0.10153255823930489
Trained batch 1239 in epoch 3, gen_loss = 0.7991228983767571, disc_loss = 0.10158007281922525
Trained batch 1240 in epoch 3, gen_loss = 0.7993396922621777, disc_loss = 0.10163921024125012
Trained batch 1241 in epoch 3, gen_loss = 0.7992594743600406, disc_loss = 0.10160236684200556
Trained batch 1242 in epoch 3, gen_loss = 0.7993178848575798, disc_loss = 0.10157735866051668
Trained batch 1243 in epoch 3, gen_loss = 0.79927928362437, disc_loss = 0.10154730505295026
Trained batch 1244 in epoch 3, gen_loss = 0.7992287538616533, disc_loss = 0.10151880328135797
Trained batch 1245 in epoch 3, gen_loss = 0.7996367293127468, disc_loss = 0.10147816636696769
Trained batch 1246 in epoch 3, gen_loss = 0.7997039899218054, disc_loss = 0.10149783644386072
Trained batch 1247 in epoch 3, gen_loss = 0.79943603484963, disc_loss = 0.10149272432467207
Trained batch 1248 in epoch 3, gen_loss = 0.7994907384542964, disc_loss = 0.10142109804362465
Trained batch 1249 in epoch 3, gen_loss = 0.7994452246904373, disc_loss = 0.10134699525535107
Trained batch 1250 in epoch 3, gen_loss = 0.7993435275783356, disc_loss = 0.10130074566645587
Trained batch 1251 in epoch 3, gen_loss = 0.7994928762507134, disc_loss = 0.10127633999878416
Trained batch 1252 in epoch 3, gen_loss = 0.7994596512671575, disc_loss = 0.10123144584898937
Trained batch 1253 in epoch 3, gen_loss = 0.7994649928104745, disc_loss = 0.10117331035494614
Trained batch 1254 in epoch 3, gen_loss = 0.7992720761384622, disc_loss = 0.10121070343659694
Trained batch 1255 in epoch 3, gen_loss = 0.7996383350888255, disc_loss = 0.1012054670032612
Trained batch 1256 in epoch 3, gen_loss = 0.7997479865308214, disc_loss = 0.10122445030115669
Trained batch 1257 in epoch 3, gen_loss = 0.7995838973736346, disc_loss = 0.10117410293621838
Trained batch 1258 in epoch 3, gen_loss = 0.7994301351552164, disc_loss = 0.10117378508682474
Trained batch 1259 in epoch 3, gen_loss = 0.7993295423331714, disc_loss = 0.1011947877439005
Trained batch 1260 in epoch 3, gen_loss = 0.7992701882837691, disc_loss = 0.10115428895798115
Trained batch 1261 in epoch 3, gen_loss = 0.7994679675191027, disc_loss = 0.10123437851454868
Trained batch 1262 in epoch 3, gen_loss = 0.7995909878826293, disc_loss = 0.10117132688326111
Trained batch 1263 in epoch 3, gen_loss = 0.799343742335899, disc_loss = 0.10127012376508475
Trained batch 1264 in epoch 3, gen_loss = 0.7994348454381166, disc_loss = 0.10126820914300062
Trained batch 1265 in epoch 3, gen_loss = 0.7995604031835499, disc_loss = 0.10123133953325274
Trained batch 1266 in epoch 3, gen_loss = 0.7996118338727161, disc_loss = 0.1011768513474534
Trained batch 1267 in epoch 3, gen_loss = 0.799586880987375, disc_loss = 0.10114895123753356
Trained batch 1268 in epoch 3, gen_loss = 0.7993860316614733, disc_loss = 0.10115113240572014
Trained batch 1269 in epoch 3, gen_loss = 0.7993814011727731, disc_loss = 0.10112635951753207
Trained batch 1270 in epoch 3, gen_loss = 0.7993877717681422, disc_loss = 0.10122828201678773
Trained batch 1271 in epoch 3, gen_loss = 0.7994498183142464, disc_loss = 0.10122936260857203
Trained batch 1272 in epoch 3, gen_loss = 0.7993162566062886, disc_loss = 0.10125662185959898
Trained batch 1273 in epoch 3, gen_loss = 0.7996324737741959, disc_loss = 0.10123739790703569
Trained batch 1274 in epoch 3, gen_loss = 0.799498035066268, disc_loss = 0.10124784765582459
Trained batch 1275 in epoch 3, gen_loss = 0.7993894275453023, disc_loss = 0.10121895526725577
Trained batch 1276 in epoch 3, gen_loss = 0.7994506022103055, disc_loss = 0.10116548507460506
Trained batch 1277 in epoch 3, gen_loss = 0.7995186452761129, disc_loss = 0.10115935388480274
Trained batch 1278 in epoch 3, gen_loss = 0.7993652382523311, disc_loss = 0.10114551029452781
Trained batch 1279 in epoch 3, gen_loss = 0.7994645386002958, disc_loss = 0.10107756747820532
Trained batch 1280 in epoch 3, gen_loss = 0.7993508356795657, disc_loss = 0.10102449546609536
Trained batch 1281 in epoch 3, gen_loss = 0.799584161286793, disc_loss = 0.10095546422119422
Trained batch 1282 in epoch 3, gen_loss = 0.7997279811072703, disc_loss = 0.10094565282839285
Trained batch 1283 in epoch 3, gen_loss = 0.799512416959923, disc_loss = 0.10104862957644477
Trained batch 1284 in epoch 3, gen_loss = 0.7994790267387717, disc_loss = 0.10101156358168631
Trained batch 1285 in epoch 3, gen_loss = 0.7996916785766697, disc_loss = 0.10112593161278226
Trained batch 1286 in epoch 3, gen_loss = 0.7997492759285181, disc_loss = 0.10118448436072078
Trained batch 1287 in epoch 3, gen_loss = 0.7994571252500419, disc_loss = 0.10135703171120367
Trained batch 1288 in epoch 3, gen_loss = 0.7992526650937423, disc_loss = 0.1014123057218267
Trained batch 1289 in epoch 3, gen_loss = 0.7994624226823334, disc_loss = 0.10189813559643866
Trained batch 1290 in epoch 3, gen_loss = 0.7994169611094258, disc_loss = 0.10191282579108299
Trained batch 1291 in epoch 3, gen_loss = 0.7993348088380722, disc_loss = 0.10198900899301995
Trained batch 1292 in epoch 3, gen_loss = 0.7990943335186854, disc_loss = 0.1022521235727275
Trained batch 1293 in epoch 3, gen_loss = 0.798763098175043, disc_loss = 0.10236435090990556
Trained batch 1294 in epoch 3, gen_loss = 0.7990285864207736, disc_loss = 0.10262190148335051
Trained batch 1295 in epoch 3, gen_loss = 0.7991447405498705, disc_loss = 0.10266781086605158
Trained batch 1296 in epoch 3, gen_loss = 0.7989248372355883, disc_loss = 0.10270787335418124
Trained batch 1297 in epoch 3, gen_loss = 0.7987949984558558, disc_loss = 0.10269514239896864
Trained batch 1298 in epoch 3, gen_loss = 0.7987321922189919, disc_loss = 0.10273271931508833
Trained batch 1299 in epoch 3, gen_loss = 0.7986730482945076, disc_loss = 0.10270196555827099
Trained batch 1300 in epoch 3, gen_loss = 0.7987333621363013, disc_loss = 0.10265962025802082
Trained batch 1301 in epoch 3, gen_loss = 0.7987101009364501, disc_loss = 0.10262924841835454
Trained batch 1302 in epoch 3, gen_loss = 0.7985159117536919, disc_loss = 0.10262657721910742
Trained batch 1303 in epoch 3, gen_loss = 0.7981965852661367, disc_loss = 0.10266039199895723
Trained batch 1304 in epoch 3, gen_loss = 0.7983905262417264, disc_loss = 0.10261017586179506
Trained batch 1305 in epoch 3, gen_loss = 0.7984224142560915, disc_loss = 0.10255615166096077
Trained batch 1306 in epoch 3, gen_loss = 0.7984182955020243, disc_loss = 0.10256473907549575
Trained batch 1307 in epoch 3, gen_loss = 0.7983846318102029, disc_loss = 0.10254945475479947
Trained batch 1308 in epoch 3, gen_loss = 0.7983986889250503, disc_loss = 0.10253443175000462
Trained batch 1309 in epoch 3, gen_loss = 0.7987012268477723, disc_loss = 0.10258599508852335
Trained batch 1310 in epoch 3, gen_loss = 0.7986917653036517, disc_loss = 0.10254376552910931
Trained batch 1311 in epoch 3, gen_loss = 0.7985450479133827, disc_loss = 0.10260204212362424
Trained batch 1312 in epoch 3, gen_loss = 0.7984263947331443, disc_loss = 0.10258652556613826
Trained batch 1313 in epoch 3, gen_loss = 0.7985795563486613, disc_loss = 0.10255742909619231
Trained batch 1314 in epoch 3, gen_loss = 0.7986053622267545, disc_loss = 0.1025209380781186
Trained batch 1315 in epoch 3, gen_loss = 0.798547339656795, disc_loss = 0.10249118836622086
Trained batch 1316 in epoch 3, gen_loss = 0.7983996181118733, disc_loss = 0.10253095525212942
Trained batch 1317 in epoch 3, gen_loss = 0.7985606088623834, disc_loss = 0.10249174482574933
Trained batch 1318 in epoch 3, gen_loss = 0.7983408720769875, disc_loss = 0.10254617351925649
Trained batch 1319 in epoch 3, gen_loss = 0.7984150919047269, disc_loss = 0.10261207778557119
Trained batch 1320 in epoch 3, gen_loss = 0.7984687517665716, disc_loss = 0.10254661959753196
Trained batch 1321 in epoch 3, gen_loss = 0.7984158545056197, disc_loss = 0.10250039158653856
Trained batch 1322 in epoch 3, gen_loss = 0.7983803695471829, disc_loss = 0.10246290636297459
Trained batch 1323 in epoch 3, gen_loss = 0.7982974411677738, disc_loss = 0.10243326142849542
Trained batch 1324 in epoch 3, gen_loss = 0.7985424073237293, disc_loss = 0.10237141963937935
Trained batch 1325 in epoch 3, gen_loss = 0.7985906397774928, disc_loss = 0.10231748097793932
Trained batch 1326 in epoch 3, gen_loss = 0.7983983218804642, disc_loss = 0.10237856743016477
Trained batch 1327 in epoch 3, gen_loss = 0.798375718026276, disc_loss = 0.10238426706419854
Trained batch 1328 in epoch 3, gen_loss = 0.7984834538535842, disc_loss = 0.10246925799707281
Trained batch 1329 in epoch 3, gen_loss = 0.7985545220679806, disc_loss = 0.10245398756718838
Trained batch 1330 in epoch 3, gen_loss = 0.7985430518368148, disc_loss = 0.10245194247833528
Trained batch 1331 in epoch 3, gen_loss = 0.7986447540847389, disc_loss = 0.10239213163399503
Trained batch 1332 in epoch 3, gen_loss = 0.7986034505902067, disc_loss = 0.10234317896204365
Trained batch 1333 in epoch 3, gen_loss = 0.7985910842086243, disc_loss = 0.10237126271945537
Trained batch 1334 in epoch 3, gen_loss = 0.7985955475421435, disc_loss = 0.10231609040110858
Trained batch 1335 in epoch 3, gen_loss = 0.7984682451822087, disc_loss = 0.10229624533805505
Trained batch 1336 in epoch 3, gen_loss = 0.7982743008420283, disc_loss = 0.10228522079902727
Trained batch 1337 in epoch 3, gen_loss = 0.798515619451155, disc_loss = 0.10248675589729518
Trained batch 1338 in epoch 3, gen_loss = 0.798433675883509, disc_loss = 0.10248187457331644
Trained batch 1339 in epoch 3, gen_loss = 0.7981678937798116, disc_loss = 0.10255930839982162
Trained batch 1340 in epoch 3, gen_loss = 0.79852536487366, disc_loss = 0.10252456863790661
Trained batch 1341 in epoch 3, gen_loss = 0.7986314223438012, disc_loss = 0.10248215484395401
Trained batch 1342 in epoch 3, gen_loss = 0.7986162914683015, disc_loss = 0.10245702298717298
Trained batch 1343 in epoch 3, gen_loss = 0.7985503002557726, disc_loss = 0.10243639544586629
Trained batch 1344 in epoch 3, gen_loss = 0.7983966373599595, disc_loss = 0.10242850021095636
Trained batch 1345 in epoch 3, gen_loss = 0.7982728746989507, disc_loss = 0.10240391117173288
Trained batch 1346 in epoch 3, gen_loss = 0.7982854375860473, disc_loss = 0.10238385800709195
Trained batch 1347 in epoch 3, gen_loss = 0.7984381542715191, disc_loss = 0.10235232697973906
Trained batch 1348 in epoch 3, gen_loss = 0.7984530916913869, disc_loss = 0.10231076002333608
Trained batch 1349 in epoch 3, gen_loss = 0.7982760490311517, disc_loss = 0.10231084512132738
Trained batch 1350 in epoch 3, gen_loss = 0.7983664076562991, disc_loss = 0.10226664169147599
Trained batch 1351 in epoch 3, gen_loss = 0.79837306945987, disc_loss = 0.10231191364389751
Trained batch 1352 in epoch 3, gen_loss = 0.7981743188760761, disc_loss = 0.10229442438560883
Trained batch 1353 in epoch 3, gen_loss = 0.7980496941940471, disc_loss = 0.10229201403899088
Trained batch 1354 in epoch 3, gen_loss = 0.797923192458839, disc_loss = 0.10225767786116288
Trained batch 1355 in epoch 3, gen_loss = 0.7982503752001618, disc_loss = 0.10236492451173212
Trained batch 1356 in epoch 3, gen_loss = 0.7980800315836553, disc_loss = 0.10241354840849481
Trained batch 1357 in epoch 3, gen_loss = 0.7981816460440191, disc_loss = 0.10236906846546306
Trained batch 1358 in epoch 3, gen_loss = 0.7981157450223337, disc_loss = 0.10235734291942111
Trained batch 1359 in epoch 3, gen_loss = 0.7982173410408637, disc_loss = 0.10244687602047206
Trained batch 1360 in epoch 3, gen_loss = 0.7982256117329538, disc_loss = 0.10242905942716313
Trained batch 1361 in epoch 3, gen_loss = 0.798181929689847, disc_loss = 0.10241121811130345
Trained batch 1362 in epoch 3, gen_loss = 0.7981778709484388, disc_loss = 0.10241624695793483
Trained batch 1363 in epoch 3, gen_loss = 0.7982346079041881, disc_loss = 0.10238579979174582
Trained batch 1364 in epoch 3, gen_loss = 0.7980020806684599, disc_loss = 0.10241302522069914
Trained batch 1365 in epoch 3, gen_loss = 0.7980929560970248, disc_loss = 0.10239721969449088
Trained batch 1366 in epoch 3, gen_loss = 0.7981068772517946, disc_loss = 0.10236845544901156
Trained batch 1367 in epoch 3, gen_loss = 0.7981900996065627, disc_loss = 0.10233443662897297
Trained batch 1368 in epoch 3, gen_loss = 0.7984172839635998, disc_loss = 0.10228877390311028
Trained batch 1369 in epoch 3, gen_loss = 0.7982718809895272, disc_loss = 0.1022744020440337
Trained batch 1370 in epoch 3, gen_loss = 0.7984847769652033, disc_loss = 0.10221590727967102
Trained batch 1371 in epoch 3, gen_loss = 0.7985002867030333, disc_loss = 0.10220259647075162
Trained batch 1372 in epoch 3, gen_loss = 0.7985426004967895, disc_loss = 0.10215002059792722
Trained batch 1373 in epoch 3, gen_loss = 0.7987067259338398, disc_loss = 0.10209189345816143
Trained batch 1374 in epoch 3, gen_loss = 0.7986181482185017, disc_loss = 0.10210092047872868
Trained batch 1375 in epoch 3, gen_loss = 0.7985701536933003, disc_loss = 0.10204761466593482
Trained batch 1376 in epoch 3, gen_loss = 0.7988313982126587, disc_loss = 0.10215892961361028
Trained batch 1377 in epoch 3, gen_loss = 0.7987951982566338, disc_loss = 0.10213875840249079
Trained batch 1378 in epoch 3, gen_loss = 0.7985923179385452, disc_loss = 0.10220795079317427
Trained batch 1379 in epoch 3, gen_loss = 0.7986947687423748, disc_loss = 0.10218870444830669
Trained batch 1380 in epoch 3, gen_loss = 0.798552427772678, disc_loss = 0.10220957545200761
Trained batch 1381 in epoch 3, gen_loss = 0.7985101698233319, disc_loss = 0.10215758626294011
Trained batch 1382 in epoch 3, gen_loss = 0.7988965606784268, disc_loss = 0.10232617143293761
Trained batch 1383 in epoch 3, gen_loss = 0.7989002546952294, disc_loss = 0.10228680105371174
Trained batch 1384 in epoch 3, gen_loss = 0.7988731741259675, disc_loss = 0.10228162850539069
Trained batch 1385 in epoch 3, gen_loss = 0.7987931663382793, disc_loss = 0.10227489818094505
Trained batch 1386 in epoch 3, gen_loss = 0.7988141915440645, disc_loss = 0.10231549020926452
Trained batch 1387 in epoch 3, gen_loss = 0.798807710387693, disc_loss = 0.10231514079080256
Trained batch 1388 in epoch 3, gen_loss = 0.7987252333723787, disc_loss = 0.10231345560927349
Trained batch 1389 in epoch 3, gen_loss = 0.7987616870686305, disc_loss = 0.10227499049920723
Trained batch 1390 in epoch 3, gen_loss = 0.7988897995885373, disc_loss = 0.10223215424116248
Trained batch 1391 in epoch 3, gen_loss = 0.7989241779921041, disc_loss = 0.10223117405374738
Trained batch 1392 in epoch 3, gen_loss = 0.7987220896847883, disc_loss = 0.10226650529575172
Trained batch 1393 in epoch 3, gen_loss = 0.7984122458198663, disc_loss = 0.10233150862913627
Trained batch 1394 in epoch 3, gen_loss = 0.7986193460802878, disc_loss = 0.10235891777915232
Trained batch 1395 in epoch 3, gen_loss = 0.7985906926728251, disc_loss = 0.10236586699659875
Trained batch 1396 in epoch 3, gen_loss = 0.7986411485573012, disc_loss = 0.10233000958633043
Trained batch 1397 in epoch 3, gen_loss = 0.7986008338576905, disc_loss = 0.10231488456986898
Trained batch 1398 in epoch 3, gen_loss = 0.798613040552896, disc_loss = 0.10227415069945694
Trained batch 1399 in epoch 3, gen_loss = 0.798507621543748, disc_loss = 0.10229762821258712
Trained batch 1400 in epoch 3, gen_loss = 0.7986875582728362, disc_loss = 0.10236877056143162
Trained batch 1401 in epoch 3, gen_loss = 0.7985734821386242, disc_loss = 0.10237826683230368
Trained batch 1402 in epoch 3, gen_loss = 0.7985147428954403, disc_loss = 0.10233199997809705
Trained batch 1403 in epoch 3, gen_loss = 0.7987670229371117, disc_loss = 0.10229526352644115
Trained batch 1404 in epoch 3, gen_loss = 0.7985869175174483, disc_loss = 0.10231176059746128
Trained batch 1405 in epoch 3, gen_loss = 0.7984848236121969, disc_loss = 0.10228354585255002
Trained batch 1406 in epoch 3, gen_loss = 0.7984976483814752, disc_loss = 0.10223869003114563
Trained batch 1407 in epoch 3, gen_loss = 0.7983610539443113, disc_loss = 0.10223844494149406
Trained batch 1408 in epoch 3, gen_loss = 0.7984194839313743, disc_loss = 0.10221309447165307
Trained batch 1409 in epoch 3, gen_loss = 0.7984180213711786, disc_loss = 0.10224714892328525
Trained batch 1410 in epoch 3, gen_loss = 0.7984631640280839, disc_loss = 0.10219665951195188
Trained batch 1411 in epoch 3, gen_loss = 0.7984254663287749, disc_loss = 0.10216569211056968
Trained batch 1412 in epoch 3, gen_loss = 0.798406751039428, disc_loss = 0.10212917799052307
Trained batch 1413 in epoch 3, gen_loss = 0.7983060627543437, disc_loss = 0.10215795084589083
Trained batch 1414 in epoch 3, gen_loss = 0.7983456773387249, disc_loss = 0.1021923140816838
Trained batch 1415 in epoch 3, gen_loss = 0.7984111917726064, disc_loss = 0.10213298552293372
Trained batch 1416 in epoch 3, gen_loss = 0.7985242204760361, disc_loss = 0.10208072711502635
Trained batch 1417 in epoch 3, gen_loss = 0.7984275614004713, disc_loss = 0.10217099169095813
Trained batch 1418 in epoch 3, gen_loss = 0.7984912603400475, disc_loss = 0.102134331193811
Trained batch 1419 in epoch 3, gen_loss = 0.798604233248133, disc_loss = 0.10207543628565757
Trained batch 1420 in epoch 3, gen_loss = 0.798521653646151, disc_loss = 0.10204473184978748
Trained batch 1421 in epoch 3, gen_loss = 0.7986774463442308, disc_loss = 0.10198517284079674
Trained batch 1422 in epoch 3, gen_loss = 0.7985847082593788, disc_loss = 0.10195837655181271
Trained batch 1423 in epoch 3, gen_loss = 0.7988144535194622, disc_loss = 0.10191420544124616
Trained batch 1424 in epoch 3, gen_loss = 0.7987770858563875, disc_loss = 0.10189965399668405
Trained batch 1425 in epoch 3, gen_loss = 0.7988077640366253, disc_loss = 0.10184869030098657
Trained batch 1426 in epoch 3, gen_loss = 0.7988425473191142, disc_loss = 0.10180092681220197
Trained batch 1427 in epoch 3, gen_loss = 0.7987875989338263, disc_loss = 0.10182326319836163
Trained batch 1428 in epoch 3, gen_loss = 0.798755839122935, disc_loss = 0.10178677672213966
Trained batch 1429 in epoch 3, gen_loss = 0.7986668767628969, disc_loss = 0.101789092675659
Trained batch 1430 in epoch 3, gen_loss = 0.7986980377586466, disc_loss = 0.10173448867338321
Trained batch 1431 in epoch 3, gen_loss = 0.7989974041890832, disc_loss = 0.10179128208751764
Trained batch 1432 in epoch 3, gen_loss = 0.7989658974137077, disc_loss = 0.10177177070352117
Trained batch 1433 in epoch 3, gen_loss = 0.798810695421413, disc_loss = 0.10176090029168308
Trained batch 1434 in epoch 3, gen_loss = 0.7986901673705735, disc_loss = 0.10174822191211301
Trained batch 1435 in epoch 3, gen_loss = 0.7989935902333857, disc_loss = 0.10173411038185373
Trained batch 1436 in epoch 3, gen_loss = 0.7989504489536989, disc_loss = 0.101733751275506
Trained batch 1437 in epoch 3, gen_loss = 0.799098187137877, disc_loss = 0.10167677958867667
Trained batch 1438 in epoch 3, gen_loss = 0.7991881653449037, disc_loss = 0.1016242534596579
Trained batch 1439 in epoch 3, gen_loss = 0.7992022808227274, disc_loss = 0.101567313308543
Trained batch 1440 in epoch 3, gen_loss = 0.7993426447854449, disc_loss = 0.10169960088487573
Trained batch 1441 in epoch 3, gen_loss = 0.7992234609494097, disc_loss = 0.10171131023506785
Trained batch 1442 in epoch 3, gen_loss = 0.7993226829123679, disc_loss = 0.10167390029175222
Trained batch 1443 in epoch 3, gen_loss = 0.7991583195832297, disc_loss = 0.10169911907322787
Trained batch 1444 in epoch 3, gen_loss = 0.799189793362337, disc_loss = 0.101726583415275
Trained batch 1445 in epoch 3, gen_loss = 0.799267781885498, disc_loss = 0.10169639702523088
Trained batch 1446 in epoch 3, gen_loss = 0.7991331595754986, disc_loss = 0.10167080723457218
Trained batch 1447 in epoch 3, gen_loss = 0.7993614606106478, disc_loss = 0.10163473287013293
Trained batch 1448 in epoch 3, gen_loss = 0.7994063706789616, disc_loss = 0.10160603893379597
Trained batch 1449 in epoch 3, gen_loss = 0.7992067761256777, disc_loss = 0.10167957836505154
Trained batch 1450 in epoch 3, gen_loss = 0.7993393952397951, disc_loss = 0.10164332362938079
Trained batch 1451 in epoch 3, gen_loss = 0.7994028345448255, disc_loss = 0.10165649007290048
Trained batch 1452 in epoch 3, gen_loss = 0.7993593672104564, disc_loss = 0.101626750738767
Trained batch 1453 in epoch 3, gen_loss = 0.799179535169549, disc_loss = 0.10178236143555917
Trained batch 1454 in epoch 3, gen_loss = 0.7993332319243257, disc_loss = 0.10175429005047812
Trained batch 1455 in epoch 3, gen_loss = 0.7996293205235686, disc_loss = 0.10172736046101469
Trained batch 1456 in epoch 3, gen_loss = 0.7995175740533932, disc_loss = 0.10169138595801903
Trained batch 1457 in epoch 3, gen_loss = 0.7997248170715955, disc_loss = 0.1016570863017585
Trained batch 1458 in epoch 3, gen_loss = 0.7997323797123329, disc_loss = 0.1016976461637921
Trained batch 1459 in epoch 3, gen_loss = 0.7995031187387361, disc_loss = 0.10180998265500857
Trained batch 1460 in epoch 3, gen_loss = 0.7993519190318938, disc_loss = 0.1018484140013859
Trained batch 1461 in epoch 3, gen_loss = 0.7994272339931102, disc_loss = 0.10182288545980112
Trained batch 1462 in epoch 3, gen_loss = 0.7993086102639496, disc_loss = 0.101823006841906
Trained batch 1463 in epoch 3, gen_loss = 0.7993419885716803, disc_loss = 0.1018439049436838
Trained batch 1464 in epoch 3, gen_loss = 0.7995846608799879, disc_loss = 0.10179750494239376
Trained batch 1465 in epoch 3, gen_loss = 0.7993770037024278, disc_loss = 0.10183723066650117
Trained batch 1466 in epoch 3, gen_loss = 0.799502815388463, disc_loss = 0.10177457195928227
Trained batch 1467 in epoch 3, gen_loss = 0.7995000867127398, disc_loss = 0.10174184030096987
Trained batch 1468 in epoch 3, gen_loss = 0.7996511494853693, disc_loss = 0.10173558363585732
Trained batch 1469 in epoch 3, gen_loss = 0.7998464992054466, disc_loss = 0.10174642738879842
Trained batch 1470 in epoch 3, gen_loss = 0.7995487149275541, disc_loss = 0.10182820074576795
Trained batch 1471 in epoch 3, gen_loss = 0.7996969038377637, disc_loss = 0.10176797247296908
Trained batch 1472 in epoch 3, gen_loss = 0.7996611074371882, disc_loss = 0.10174932128206675
Trained batch 1473 in epoch 3, gen_loss = 0.799663724253912, disc_loss = 0.1017192541065612
Trained batch 1474 in epoch 3, gen_loss = 0.7997569783663345, disc_loss = 0.10167619237139569
Trained batch 1475 in epoch 3, gen_loss = 0.7999335441405211, disc_loss = 0.10180242568302425
Trained batch 1476 in epoch 3, gen_loss = 0.7999025337503984, disc_loss = 0.10177511136383625
Trained batch 1477 in epoch 3, gen_loss = 0.799702975520907, disc_loss = 0.10184556163320663
Trained batch 1478 in epoch 3, gen_loss = 0.7996581946376855, disc_loss = 0.10181683008927421
Trained batch 1479 in epoch 3, gen_loss = 0.7998273235317823, disc_loss = 0.10184860736119082
Trained batch 1480 in epoch 3, gen_loss = 0.7996567568611568, disc_loss = 0.10191258452241582
Trained batch 1481 in epoch 3, gen_loss = 0.7996175704616928, disc_loss = 0.10185847167420865
Trained batch 1482 in epoch 3, gen_loss = 0.79956465794762, disc_loss = 0.10183812213078171
Trained batch 1483 in epoch 3, gen_loss = 0.799502713982307, disc_loss = 0.10180834201515986
Trained batch 1484 in epoch 3, gen_loss = 0.7994385289423394, disc_loss = 0.10180897301984856
Trained batch 1485 in epoch 3, gen_loss = 0.7994524236081587, disc_loss = 0.10175528102096867
Trained batch 1486 in epoch 3, gen_loss = 0.7995842736923382, disc_loss = 0.10172012496724595
Trained batch 1487 in epoch 3, gen_loss = 0.7994949889759864, disc_loss = 0.10170475571098367
Trained batch 1488 in epoch 3, gen_loss = 0.7993632688708078, disc_loss = 0.10172700357877965
Trained batch 1489 in epoch 3, gen_loss = 0.7993200922172341, disc_loss = 0.10171155094312842
Trained batch 1490 in epoch 3, gen_loss = 0.7993390471003026, disc_loss = 0.10167895050908018
Trained batch 1491 in epoch 3, gen_loss = 0.7993535160139482, disc_loss = 0.1016538812343191
Trained batch 1492 in epoch 3, gen_loss = 0.7994937457977648, disc_loss = 0.1016892874463694
Trained batch 1493 in epoch 3, gen_loss = 0.7993303288816608, disc_loss = 0.10176127310530587
Trained batch 1494 in epoch 3, gen_loss = 0.7993051218348602, disc_loss = 0.10179400093492158
Trained batch 1495 in epoch 3, gen_loss = 0.7991253710924623, disc_loss = 0.1018388341386419
Trained batch 1496 in epoch 3, gen_loss = 0.7991779161518864, disc_loss = 0.10178905251854627
Trained batch 1497 in epoch 3, gen_loss = 0.7993388844029766, disc_loss = 0.10174178923523733
Trained batch 1498 in epoch 3, gen_loss = 0.7993932252649151, disc_loss = 0.10172427700692073
Trained batch 1499 in epoch 3, gen_loss = 0.7993621952931086, disc_loss = 0.10170532403451701
Trained batch 1500 in epoch 3, gen_loss = 0.7992560157054747, disc_loss = 0.10168069418455207
Trained batch 1501 in epoch 3, gen_loss = 0.7992092357097706, disc_loss = 0.1016684883341104
Trained batch 1502 in epoch 3, gen_loss = 0.7992695976874071, disc_loss = 0.10161157142425468
Trained batch 1503 in epoch 3, gen_loss = 0.7994601947671556, disc_loss = 0.10157930941823771
Trained batch 1504 in epoch 3, gen_loss = 0.7995074162055488, disc_loss = 0.10154888055834957
Trained batch 1505 in epoch 3, gen_loss = 0.7993931982463416, disc_loss = 0.10165212828985071
Trained batch 1506 in epoch 3, gen_loss = 0.7996641589698209, disc_loss = 0.10167976195584703
Trained batch 1507 in epoch 3, gen_loss = 0.7997027855336825, disc_loss = 0.10173969409695335
Trained batch 1508 in epoch 3, gen_loss = 0.7995552268543332, disc_loss = 0.10179860715311813
Trained batch 1509 in epoch 3, gen_loss = 0.7993974935929506, disc_loss = 0.10180912095967014
Trained batch 1510 in epoch 3, gen_loss = 0.7995690299847676, disc_loss = 0.1017695058286338
Trained batch 1511 in epoch 3, gen_loss = 0.7997074321937309, disc_loss = 0.10181861901199987
Trained batch 1512 in epoch 3, gen_loss = 0.7994833357154496, disc_loss = 0.10187963354638276
Trained batch 1513 in epoch 3, gen_loss = 0.7995231119888777, disc_loss = 0.10184145562013654
Trained batch 1514 in epoch 3, gen_loss = 0.7995898601442281, disc_loss = 0.10183243948917085
Trained batch 1515 in epoch 3, gen_loss = 0.7997343877335337, disc_loss = 0.10178730352953726
Trained batch 1516 in epoch 3, gen_loss = 0.7995278333745351, disc_loss = 0.10184118383666581
Trained batch 1517 in epoch 3, gen_loss = 0.7995833002806338, disc_loss = 0.10184018580090838
Trained batch 1518 in epoch 3, gen_loss = 0.7994817746282016, disc_loss = 0.10180241848483751
Trained batch 1519 in epoch 3, gen_loss = 0.7996907641032809, disc_loss = 0.10177078226666995
Trained batch 1520 in epoch 3, gen_loss = 0.79956072692335, disc_loss = 0.10180244901150778
Trained batch 1521 in epoch 3, gen_loss = 0.7996058257470463, disc_loss = 0.10177200588822345
Trained batch 1522 in epoch 3, gen_loss = 0.7997874445181025, disc_loss = 0.10174713405772545
Trained batch 1523 in epoch 3, gen_loss = 0.7995946395389364, disc_loss = 0.10178680412087521
Trained batch 1524 in epoch 3, gen_loss = 0.7997222342842915, disc_loss = 0.10174135197564715
Trained batch 1525 in epoch 3, gen_loss = 0.7998984846461022, disc_loss = 0.10172686988712432
Trained batch 1526 in epoch 3, gen_loss = 0.7998930399099361, disc_loss = 0.10167871274300451
Trained batch 1527 in epoch 3, gen_loss = 0.799911921229506, disc_loss = 0.10162023966949121
Trained batch 1528 in epoch 3, gen_loss = 0.7999140667595686, disc_loss = 0.1015812810090114
Trained batch 1529 in epoch 3, gen_loss = 0.8000268195384468, disc_loss = 0.10154197283296121
Trained batch 1530 in epoch 3, gen_loss = 0.8000710023960049, disc_loss = 0.1015075275803424
Trained batch 1531 in epoch 3, gen_loss = 0.80008448825726, disc_loss = 0.10149846921733267
Trained batch 1532 in epoch 3, gen_loss = 0.7999848330129772, disc_loss = 0.10152621200127164
Trained batch 1533 in epoch 3, gen_loss = 0.799897452901364, disc_loss = 0.10151115410343162
Trained batch 1534 in epoch 3, gen_loss = 0.7999305488814749, disc_loss = 0.10146602217763274
Trained batch 1535 in epoch 3, gen_loss = 0.8000880845162707, disc_loss = 0.10143645031409203
Trained batch 1536 in epoch 3, gen_loss = 0.8000339250054233, disc_loss = 0.10139917833918419
Trained batch 1537 in epoch 3, gen_loss = 0.8003353765440235, disc_loss = 0.10148245153430321
Trained batch 1538 in epoch 3, gen_loss = 0.8001877527836471, disc_loss = 0.10159480570839105
Trained batch 1539 in epoch 3, gen_loss = 0.800189194218679, disc_loss = 0.10155790440750297
Trained batch 1540 in epoch 3, gen_loss = 0.8002323476352295, disc_loss = 0.10154440929710691
Trained batch 1541 in epoch 3, gen_loss = 0.8002481869725092, disc_loss = 0.10148696847871216
Trained batch 1542 in epoch 3, gen_loss = 0.800142465457465, disc_loss = 0.10147631730961572
Trained batch 1543 in epoch 3, gen_loss = 0.8003981755226078, disc_loss = 0.10150606096951398
Trained batch 1544 in epoch 3, gen_loss = 0.8003081433016891, disc_loss = 0.10149245343222298
Trained batch 1545 in epoch 3, gen_loss = 0.8002926582545234, disc_loss = 0.10147617612802755
Trained batch 1546 in epoch 3, gen_loss = 0.8003489421542105, disc_loss = 0.10144217753073691
Trained batch 1547 in epoch 3, gen_loss = 0.8003142528255165, disc_loss = 0.1014041202269177
Trained batch 1548 in epoch 3, gen_loss = 0.8003254396789223, disc_loss = 0.10137799111711375
Trained batch 1549 in epoch 3, gen_loss = 0.8002611201617026, disc_loss = 0.1013394079531633
Trained batch 1550 in epoch 3, gen_loss = 0.8003039365234412, disc_loss = 0.10134027345943056
Trained batch 1551 in epoch 3, gen_loss = 0.8002176445899243, disc_loss = 0.10134600279624718
Trained batch 1552 in epoch 3, gen_loss = 0.8001433224618166, disc_loss = 0.10133637545518794
Trained batch 1553 in epoch 3, gen_loss = 0.799966877587667, disc_loss = 0.10140862631428138
Trained batch 1554 in epoch 3, gen_loss = 0.8001284119592219, disc_loss = 0.10136474419409151
Trained batch 1555 in epoch 3, gen_loss = 0.8003168553688532, disc_loss = 0.10148185815789035
Trained batch 1556 in epoch 3, gen_loss = 0.8002764766960475, disc_loss = 0.10148359124603165
Trained batch 1557 in epoch 3, gen_loss = 0.8001090162487483, disc_loss = 0.10152788077264699
Trained batch 1558 in epoch 3, gen_loss = 0.8005231004674286, disc_loss = 0.1015540023959786
Trained batch 1559 in epoch 3, gen_loss = 0.8005550995660133, disc_loss = 0.10157301717807944
Trained batch 1560 in epoch 3, gen_loss = 0.8003613364803417, disc_loss = 0.10162477769508892
Trained batch 1561 in epoch 3, gen_loss = 0.8004333265650441, disc_loss = 0.10158466113249505
Trained batch 1562 in epoch 3, gen_loss = 0.8003591240520136, disc_loss = 0.10155263649727565
Trained batch 1563 in epoch 3, gen_loss = 0.8002958913402789, disc_loss = 0.10151948992584539
Trained batch 1564 in epoch 3, gen_loss = 0.8004080050098249, disc_loss = 0.10157515192672181
Trained batch 1565 in epoch 3, gen_loss = 0.8004829614669428, disc_loss = 0.10151904267003214
Trained batch 1566 in epoch 3, gen_loss = 0.800385581796612, disc_loss = 0.1015081445329324
Trained batch 1567 in epoch 3, gen_loss = 0.8003611876154129, disc_loss = 0.10148820614475491
Trained batch 1568 in epoch 3, gen_loss = 0.8003850561217034, disc_loss = 0.101454108900054
Trained batch 1569 in epoch 3, gen_loss = 0.8005646044851109, disc_loss = 0.10146907257022941
Trained batch 1570 in epoch 3, gen_loss = 0.8005691218687272, disc_loss = 0.10142053538882413
Trained batch 1571 in epoch 3, gen_loss = 0.8005241536874201, disc_loss = 0.10140894627217535
Trained batch 1572 in epoch 3, gen_loss = 0.8005026777269578, disc_loss = 0.1013893512624108
Trained batch 1573 in epoch 3, gen_loss = 0.8006512672466426, disc_loss = 0.10139004120146418
Trained batch 1574 in epoch 3, gen_loss = 0.8007799616881779, disc_loss = 0.10135439809707422
Trained batch 1575 in epoch 3, gen_loss = 0.8007210077254603, disc_loss = 0.10134920428109918
Trained batch 1576 in epoch 3, gen_loss = 0.800480156777853, disc_loss = 0.10142428086705614
Trained batch 1577 in epoch 3, gen_loss = 0.8005586671436392, disc_loss = 0.1013920120104052
Trained batch 1578 in epoch 3, gen_loss = 0.8008940769495128, disc_loss = 0.10142879212715152
Trained batch 1579 in epoch 3, gen_loss = 0.8009535409981692, disc_loss = 0.10137330189382633
Trained batch 1580 in epoch 3, gen_loss = 0.8008677666885502, disc_loss = 0.1013945808921629
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 0.7121388912200928, disc_loss = 0.09040388464927673
Trained batch 1 in epoch 4, gen_loss = 0.6891527473926544, disc_loss = 0.06085910275578499
Trained batch 2 in epoch 4, gen_loss = 0.7915674249331156, disc_loss = 0.052658667167027794
Trained batch 3 in epoch 4, gen_loss = 0.798040121793747, disc_loss = 0.0942889042198658
Trained batch 4 in epoch 4, gen_loss = 0.7239825367927551, disc_loss = 0.10883910059928895
Trained batch 5 in epoch 4, gen_loss = 0.7149798572063446, disc_loss = 0.10424754147728284
Trained batch 6 in epoch 4, gen_loss = 0.7406255517687116, disc_loss = 0.10148001994405474
Trained batch 7 in epoch 4, gen_loss = 0.7518172264099121, disc_loss = 0.10450945980846882
Trained batch 8 in epoch 4, gen_loss = 0.7530784010887146, disc_loss = 0.09841192637880643
Trained batch 9 in epoch 4, gen_loss = 0.749034184217453, disc_loss = 0.09131206907331943
Trained batch 10 in epoch 4, gen_loss = 0.741884551265023, disc_loss = 0.08956408466805112
Trained batch 11 in epoch 4, gen_loss = 0.7353740582863489, disc_loss = 0.0898179675762852
Trained batch 12 in epoch 4, gen_loss = 0.7504759660133948, disc_loss = 0.10737754891698177
Trained batch 13 in epoch 4, gen_loss = 0.7461575141974858, disc_loss = 0.10925066178398472
Trained batch 14 in epoch 4, gen_loss = 0.7379164576530457, disc_loss = 0.10567042802770933
Trained batch 15 in epoch 4, gen_loss = 0.741112407296896, disc_loss = 0.10172969871200621
Trained batch 16 in epoch 4, gen_loss = 0.7533457174020655, disc_loss = 0.0986680747831569
Trained batch 17 in epoch 4, gen_loss = 0.7524202466011047, disc_loss = 0.09584080386492941
Trained batch 18 in epoch 4, gen_loss = 0.7566509058600978, disc_loss = 0.0967248689971472
Trained batch 19 in epoch 4, gen_loss = 0.749474149942398, disc_loss = 0.09960190542042255
Trained batch 20 in epoch 4, gen_loss = 0.7471233067058382, disc_loss = 0.09685090450303895
Trained batch 21 in epoch 4, gen_loss = 0.7622597407210957, disc_loss = 0.10043492015789855
Trained batch 22 in epoch 4, gen_loss = 0.765563120012698, disc_loss = 0.09921532885535904
Trained batch 23 in epoch 4, gen_loss = 0.7577266444762548, disc_loss = 0.10117842707162102
Trained batch 24 in epoch 4, gen_loss = 0.7633337831497192, disc_loss = 0.09814195901155472
Trained batch 25 in epoch 4, gen_loss = 0.761323156265112, disc_loss = 0.09638303532623328
Trained batch 26 in epoch 4, gen_loss = 0.75846251072707, disc_loss = 0.09911490438712968
Trained batch 27 in epoch 4, gen_loss = 0.7722306485686984, disc_loss = 0.09654199292085
Trained batch 28 in epoch 4, gen_loss = 0.7721230058834471, disc_loss = 0.0957043236442681
Trained batch 29 in epoch 4, gen_loss = 0.7710188170274098, disc_loss = 0.09360213714341323
Trained batch 30 in epoch 4, gen_loss = 0.7754595337375518, disc_loss = 0.09193725331175712
Trained batch 31 in epoch 4, gen_loss = 0.7710108868777752, disc_loss = 0.09175190678797662
Trained batch 32 in epoch 4, gen_loss = 0.7877360943591956, disc_loss = 0.0931454858545101
Trained batch 33 in epoch 4, gen_loss = 0.7882410305387834, disc_loss = 0.09133243188261986
Trained batch 34 in epoch 4, gen_loss = 0.7917881659099034, disc_loss = 0.08971251951796667
Trained batch 35 in epoch 4, gen_loss = 0.7997761600547366, disc_loss = 0.08842346724122763
Trained batch 36 in epoch 4, gen_loss = 0.798254319139429, disc_loss = 0.08850076965786316
Trained batch 37 in epoch 4, gen_loss = 0.79596924154382, disc_loss = 0.08888633990366208
Trained batch 38 in epoch 4, gen_loss = 0.799035539993873, disc_loss = 0.08861083890765141
Trained batch 39 in epoch 4, gen_loss = 0.799740718305111, disc_loss = 0.08724025199189782
Trained batch 40 in epoch 4, gen_loss = 0.7967248326394616, disc_loss = 0.08629278611482644
Trained batch 41 in epoch 4, gen_loss = 0.7959855723948706, disc_loss = 0.08567427302755061
Trained batch 42 in epoch 4, gen_loss = 0.8017656595207924, disc_loss = 0.08556562185634015
Trained batch 43 in epoch 4, gen_loss = 0.8123606402765621, disc_loss = 0.08431200911714272
Trained batch 44 in epoch 4, gen_loss = 0.8102974348598057, disc_loss = 0.08416192655762036
Trained batch 45 in epoch 4, gen_loss = 0.8110383723093115, disc_loss = 0.0834452569808649
Trained batch 46 in epoch 4, gen_loss = 0.8105372089020749, disc_loss = 0.0821721446799471
Trained batch 47 in epoch 4, gen_loss = 0.8134386390447617, disc_loss = 0.08072700376699989
Trained batch 48 in epoch 4, gen_loss = 0.8145783105675055, disc_loss = 0.08155102748423815
Trained batch 49 in epoch 4, gen_loss = 0.8176724421977997, disc_loss = 0.08052576748654246
Trained batch 50 in epoch 4, gen_loss = 0.8132062671231288, disc_loss = 0.0815642215859364
Trained batch 51 in epoch 4, gen_loss = 0.8255311468472848, disc_loss = 0.0852335281490993
Trained batch 52 in epoch 4, gen_loss = 0.8193337051373608, disc_loss = 0.0883475932696799
Trained batch 53 in epoch 4, gen_loss = 0.8145936164591048, disc_loss = 0.087869502586761
Trained batch 54 in epoch 4, gen_loss = 0.8157831452109597, disc_loss = 0.08834789745848287
Trained batch 55 in epoch 4, gen_loss = 0.817837478859084, disc_loss = 0.08839825193198132
Trained batch 56 in epoch 4, gen_loss = 0.8146600137677109, disc_loss = 0.08782522646677599
Trained batch 57 in epoch 4, gen_loss = 0.8148914616683434, disc_loss = 0.08749080287164142
Trained batch 58 in epoch 4, gen_loss = 0.8137873390973624, disc_loss = 0.08628797977847064
Trained batch 59 in epoch 4, gen_loss = 0.8132477839787801, disc_loss = 0.085335459606722
Trained batch 60 in epoch 4, gen_loss = 0.8126803089360721, disc_loss = 0.08440043754326026
Trained batch 61 in epoch 4, gen_loss = 0.8151557897367785, disc_loss = 0.08330346378047139
Trained batch 62 in epoch 4, gen_loss = 0.8151404753563896, disc_loss = 0.08211834100444639
Trained batch 63 in epoch 4, gen_loss = 0.8147398447617888, disc_loss = 0.0814858586381888
Trained batch 64 in epoch 4, gen_loss = 0.8123883458284231, disc_loss = 0.08142473168957692
Trained batch 65 in epoch 4, gen_loss = 0.8141900671250892, disc_loss = 0.08067681401911558
Trained batch 66 in epoch 4, gen_loss = 0.8156824396617377, disc_loss = 0.08024015721044879
Trained batch 67 in epoch 4, gen_loss = 0.8181875628583571, disc_loss = 0.07924783091499087
Trained batch 68 in epoch 4, gen_loss = 0.8213094593822092, disc_loss = 0.07826341849252366
Trained batch 69 in epoch 4, gen_loss = 0.8264237063271659, disc_loss = 0.07755403017093028
Trained batch 70 in epoch 4, gen_loss = 0.8257998060172712, disc_loss = 0.07712553104411968
Trained batch 71 in epoch 4, gen_loss = 0.8260655154784521, disc_loss = 0.07712610695873284
Trained batch 72 in epoch 4, gen_loss = 0.8300245934969759, disc_loss = 0.07647383025502913
Trained batch 73 in epoch 4, gen_loss = 0.8282472781232886, disc_loss = 0.07624412701792412
Trained batch 74 in epoch 4, gen_loss = 0.8298686567942302, disc_loss = 0.07585245163490374
Trained batch 75 in epoch 4, gen_loss = 0.8276277192329106, disc_loss = 0.07603774505275253
Trained batch 76 in epoch 4, gen_loss = 0.8299143027949643, disc_loss = 0.0752628105148286
Trained batch 77 in epoch 4, gen_loss = 0.8353480398654938, disc_loss = 0.0757622361684648
Trained batch 78 in epoch 4, gen_loss = 0.8374367129953602, disc_loss = 0.0750220888235335
Trained batch 79 in epoch 4, gen_loss = 0.8348019890487194, disc_loss = 0.07509999187896028
Trained batch 80 in epoch 4, gen_loss = 0.8357569567951155, disc_loss = 0.07452333062013358
Trained batch 81 in epoch 4, gen_loss = 0.8356712504131037, disc_loss = 0.07405247690337824
Trained batch 82 in epoch 4, gen_loss = 0.8344592480774385, disc_loss = 0.07481609811131136
Trained batch 83 in epoch 4, gen_loss = 0.8361251808348156, disc_loss = 0.07496605189295397
Trained batch 84 in epoch 4, gen_loss = 0.8365127311033361, disc_loss = 0.07428936562774813
Trained batch 85 in epoch 4, gen_loss = 0.8355883692586145, disc_loss = 0.0752279220343849
Trained batch 86 in epoch 4, gen_loss = 0.8333587249120077, disc_loss = 0.07522181557470012
Trained batch 87 in epoch 4, gen_loss = 0.8332184241576628, disc_loss = 0.07458035970657048
Trained batch 88 in epoch 4, gen_loss = 0.8330841693985328, disc_loss = 0.07422926717469197
Trained batch 89 in epoch 4, gen_loss = 0.8308299395773145, disc_loss = 0.07409599962540799
Trained batch 90 in epoch 4, gen_loss = 0.8294339238942324, disc_loss = 0.07384617746408496
Trained batch 91 in epoch 4, gen_loss = 0.830267951540325, disc_loss = 0.0732387161469492
Trained batch 92 in epoch 4, gen_loss = 0.8259784572867936, disc_loss = 0.07418906237048808
Trained batch 93 in epoch 4, gen_loss = 0.8285791988068438, disc_loss = 0.07360673264818306
Trained batch 94 in epoch 4, gen_loss = 0.8308280756599025, disc_loss = 0.07374151620621744
Trained batch 95 in epoch 4, gen_loss = 0.8277892706294855, disc_loss = 0.07468624852481298
Trained batch 96 in epoch 4, gen_loss = 0.8278171119001723, disc_loss = 0.0746430479393331
Trained batch 97 in epoch 4, gen_loss = 0.828693939106805, disc_loss = 0.07406719489859379
Trained batch 98 in epoch 4, gen_loss = 0.8257413073019548, disc_loss = 0.0746526944385183
Trained batch 99 in epoch 4, gen_loss = 0.8292093604803086, disc_loss = 0.07532527794130146
Trained batch 100 in epoch 4, gen_loss = 0.8292960630785121, disc_loss = 0.07513443938465697
Trained batch 101 in epoch 4, gen_loss = 0.8288655964767232, disc_loss = 0.07488925160621018
Trained batch 102 in epoch 4, gen_loss = 0.8249737226847306, disc_loss = 0.07694658742837825
Trained batch 103 in epoch 4, gen_loss = 0.8284763963176653, disc_loss = 0.07775921622613588
Trained batch 104 in epoch 4, gen_loss = 0.8311398193949745, disc_loss = 0.0783169389214544
Trained batch 105 in epoch 4, gen_loss = 0.8305938153896691, disc_loss = 0.07927228528830521
Trained batch 106 in epoch 4, gen_loss = 0.8281704109405803, disc_loss = 0.07971977815902401
Trained batch 107 in epoch 4, gen_loss = 0.829579985804028, disc_loss = 0.08006940517333094
Trained batch 108 in epoch 4, gen_loss = 0.8350313464435962, disc_loss = 0.08032797096690181
Trained batch 109 in epoch 4, gen_loss = 0.8348106628114527, disc_loss = 0.08002459980039434
Trained batch 110 in epoch 4, gen_loss = 0.8336343384003854, disc_loss = 0.08008976848712107
Trained batch 111 in epoch 4, gen_loss = 0.8311709000595978, disc_loss = 0.0800767546669314
Trained batch 112 in epoch 4, gen_loss = 0.8329610639968804, disc_loss = 0.07963310088962317
Trained batch 113 in epoch 4, gen_loss = 0.8342647500205458, disc_loss = 0.0792533565361641
Trained batch 114 in epoch 4, gen_loss = 0.8330182091049526, disc_loss = 0.07895757260367922
Trained batch 115 in epoch 4, gen_loss = 0.8350664454287496, disc_loss = 0.07861417383437269
Trained batch 116 in epoch 4, gen_loss = 0.8356374986151345, disc_loss = 0.07844632512961443
Trained batch 117 in epoch 4, gen_loss = 0.8335828169927759, disc_loss = 0.07886192940522806
Trained batch 118 in epoch 4, gen_loss = 0.8335327536118131, disc_loss = 0.07847617953984427
Trained batch 119 in epoch 4, gen_loss = 0.8328648308912913, disc_loss = 0.07923071234642218
Trained batch 120 in epoch 4, gen_loss = 0.8340586896770257, disc_loss = 0.07870812072949715
Trained batch 121 in epoch 4, gen_loss = 0.8341795723946368, disc_loss = 0.07869469642364343
Trained batch 122 in epoch 4, gen_loss = 0.8334596438136527, disc_loss = 0.07862721873462443
Trained batch 123 in epoch 4, gen_loss = 0.8319697639634532, disc_loss = 0.07871784521417031
Trained batch 124 in epoch 4, gen_loss = 0.831630036354065, disc_loss = 0.07847166996449233
Trained batch 125 in epoch 4, gen_loss = 0.8316713089034671, disc_loss = 0.07815724252797072
Trained batch 126 in epoch 4, gen_loss = 0.8294267799910597, disc_loss = 0.07897703392856469
Trained batch 127 in epoch 4, gen_loss = 0.8295920970849693, disc_loss = 0.0788530437494046
Trained batch 128 in epoch 4, gen_loss = 0.8310754904451296, disc_loss = 0.07904913498074279
Trained batch 129 in epoch 4, gen_loss = 0.8318560513166281, disc_loss = 0.07938262014291607
Trained batch 130 in epoch 4, gen_loss = 0.8290284844755217, disc_loss = 0.08077168279107062
Trained batch 131 in epoch 4, gen_loss = 0.8272890015081926, disc_loss = 0.08095173963176255
Trained batch 132 in epoch 4, gen_loss = 0.8305265957251527, disc_loss = 0.08247229386177055
Trained batch 133 in epoch 4, gen_loss = 0.830098626328938, disc_loss = 0.08243686302022925
Trained batch 134 in epoch 4, gen_loss = 0.8281219513327988, disc_loss = 0.08342118844803836
Trained batch 135 in epoch 4, gen_loss = 0.8297994325266165, disc_loss = 0.08328716475379598
Trained batch 136 in epoch 4, gen_loss = 0.8293121109043595, disc_loss = 0.08407264270133129
Trained batch 137 in epoch 4, gen_loss = 0.8275584353916887, disc_loss = 0.0842695045824824
Trained batch 138 in epoch 4, gen_loss = 0.8279761839256012, disc_loss = 0.08382829580884829
Trained batch 139 in epoch 4, gen_loss = 0.8267796678202493, disc_loss = 0.08436611727811397
Trained batch 140 in epoch 4, gen_loss = 0.8285854919582394, disc_loss = 0.08448119114767363
Trained batch 141 in epoch 4, gen_loss = 0.8263550778509865, disc_loss = 0.08603518468681985
Trained batch 142 in epoch 4, gen_loss = 0.827075273006946, disc_loss = 0.08618255164734759
Trained batch 143 in epoch 4, gen_loss = 0.8281008634302351, disc_loss = 0.0857713447120558
Trained batch 144 in epoch 4, gen_loss = 0.8268736008940072, disc_loss = 0.0862404195463349
Trained batch 145 in epoch 4, gen_loss = 0.8278511146160021, disc_loss = 0.08610951309156133
Trained batch 146 in epoch 4, gen_loss = 0.8277103722500964, disc_loss = 0.08618605522704977
Trained batch 147 in epoch 4, gen_loss = 0.8265007524876982, disc_loss = 0.08614190452027361
Trained batch 148 in epoch 4, gen_loss = 0.8247730095914546, disc_loss = 0.08656685459958827
Trained batch 149 in epoch 4, gen_loss = 0.827835371096929, disc_loss = 0.08706498856966695
Trained batch 150 in epoch 4, gen_loss = 0.8279640157491166, disc_loss = 0.08703342421190036
Trained batch 151 in epoch 4, gen_loss = 0.828306574962641, disc_loss = 0.08672067197652436
Trained batch 152 in epoch 4, gen_loss = 0.827045605852713, disc_loss = 0.086501227563941
Trained batch 153 in epoch 4, gen_loss = 0.8260509720096341, disc_loss = 0.08669130453936659
Trained batch 154 in epoch 4, gen_loss = 0.8273213463444864, disc_loss = 0.08652745805560581
Trained batch 155 in epoch 4, gen_loss = 0.8285972598271493, disc_loss = 0.08641554380002885
Trained batch 156 in epoch 4, gen_loss = 0.828317998321193, disc_loss = 0.08631789701498428
Trained batch 157 in epoch 4, gen_loss = 0.8279813976981972, disc_loss = 0.08597414778498343
Trained batch 158 in epoch 4, gen_loss = 0.8288133879127743, disc_loss = 0.08579394196119136
Trained batch 159 in epoch 4, gen_loss = 0.8265884649008512, disc_loss = 0.08586591103230604
Trained batch 160 in epoch 4, gen_loss = 0.826459472964269, disc_loss = 0.0853988988070477
Trained batch 161 in epoch 4, gen_loss = 0.8270710232081236, disc_loss = 0.0851452248343439
Trained batch 162 in epoch 4, gen_loss = 0.8272010336624332, disc_loss = 0.08479120798888931
Trained batch 163 in epoch 4, gen_loss = 0.8269288147368082, disc_loss = 0.08462093504168457
Trained batch 164 in epoch 4, gen_loss = 0.8274743311332934, disc_loss = 0.08417894907408592
Trained batch 165 in epoch 4, gen_loss = 0.8277079197297613, disc_loss = 0.08396263731957739
Trained batch 166 in epoch 4, gen_loss = 0.8284725471884905, disc_loss = 0.083548739881528
Trained batch 167 in epoch 4, gen_loss = 0.8291264520514579, disc_loss = 0.0831285937068363
Trained batch 168 in epoch 4, gen_loss = 0.8281767329520727, disc_loss = 0.08306403720431779
Trained batch 169 in epoch 4, gen_loss = 0.8287404582780951, disc_loss = 0.08337711707195815
Trained batch 170 in epoch 4, gen_loss = 0.827776325027845, disc_loss = 0.08329667275150617
Trained batch 171 in epoch 4, gen_loss = 0.8285616407560747, disc_loss = 0.08470976242232461
Trained batch 172 in epoch 4, gen_loss = 0.8266277139241984, disc_loss = 0.08574298052171062
Trained batch 173 in epoch 4, gen_loss = 0.8269120048860024, disc_loss = 0.08567064985547257
Trained batch 174 in epoch 4, gen_loss = 0.8254155089173998, disc_loss = 0.08548852111612047
Trained batch 175 in epoch 4, gen_loss = 0.82641519182785, disc_loss = 0.08513198568570343
Trained batch 176 in epoch 4, gen_loss = 0.82623877010103, disc_loss = 0.08479484814708516
Trained batch 177 in epoch 4, gen_loss = 0.8265093191621009, disc_loss = 0.08480796314189944
Trained batch 178 in epoch 4, gen_loss = 0.8274808511054715, disc_loss = 0.08442787603376298
Trained batch 179 in epoch 4, gen_loss = 0.8258934635255072, disc_loss = 0.08467902741912338
Trained batch 180 in epoch 4, gen_loss = 0.8266652945984793, disc_loss = 0.08460800397050315
Trained batch 181 in epoch 4, gen_loss = 0.8266159281298354, disc_loss = 0.08483603791139283
Trained batch 182 in epoch 4, gen_loss = 0.8264619142957073, disc_loss = 0.08493131372690853
Trained batch 183 in epoch 4, gen_loss = 0.8264057845201181, disc_loss = 0.08457628370303175
Trained batch 184 in epoch 4, gen_loss = 0.8262903253774385, disc_loss = 0.08426187413971166
Trained batch 185 in epoch 4, gen_loss = 0.8259068511186107, disc_loss = 0.08399098772074907
Trained batch 186 in epoch 4, gen_loss = 0.8256024774064354, disc_loss = 0.08371390542762483
Trained batch 187 in epoch 4, gen_loss = 0.8272165537197539, disc_loss = 0.08336381640958976
Trained batch 188 in epoch 4, gen_loss = 0.8265257110356024, disc_loss = 0.08312087272486043
Trained batch 189 in epoch 4, gen_loss = 0.8286916627695686, disc_loss = 0.08285430304117893
Trained batch 190 in epoch 4, gen_loss = 0.8270141892720267, disc_loss = 0.08304033833141414
Trained batch 191 in epoch 4, gen_loss = 0.8265587530719737, disc_loss = 0.08285120204285097
Trained batch 192 in epoch 4, gen_loss = 0.8277394813268296, disc_loss = 0.08356650533646809
Trained batch 193 in epoch 4, gen_loss = 0.8272842843200743, disc_loss = 0.08332337827911389
Trained batch 194 in epoch 4, gen_loss = 0.8259381531140744, disc_loss = 0.08371264480818541
Trained batch 195 in epoch 4, gen_loss = 0.8258857762022894, disc_loss = 0.08342413306806465
Trained batch 196 in epoch 4, gen_loss = 0.8269773157417472, disc_loss = 0.0842146017130105
Trained batch 197 in epoch 4, gen_loss = 0.8259633973692403, disc_loss = 0.08454102502590177
Trained batch 198 in epoch 4, gen_loss = 0.8249847126666026, disc_loss = 0.08479104231312946
Trained batch 199 in epoch 4, gen_loss = 0.8257226018607616, disc_loss = 0.08502070522867143
Trained batch 200 in epoch 4, gen_loss = 0.824913687225598, disc_loss = 0.08510356043368134
Trained batch 201 in epoch 4, gen_loss = 0.8256543885068138, disc_loss = 0.08532826217942603
Trained batch 202 in epoch 4, gen_loss = 0.8252172298325694, disc_loss = 0.0853084598030216
Trained batch 203 in epoch 4, gen_loss = 0.8237224903468993, disc_loss = 0.08551166746217538
Trained batch 204 in epoch 4, gen_loss = 0.8229570875807506, disc_loss = 0.08533224324445898
Trained batch 205 in epoch 4, gen_loss = 0.8231562484525939, disc_loss = 0.08503685793975024
Trained batch 206 in epoch 4, gen_loss = 0.8228884185281928, disc_loss = 0.08504597036446926
Trained batch 207 in epoch 4, gen_loss = 0.8222135828378109, disc_loss = 0.08474881527945399
Trained batch 208 in epoch 4, gen_loss = 0.8227010732917694, disc_loss = 0.08445038879067418
Trained batch 209 in epoch 4, gen_loss = 0.8216322826487678, disc_loss = 0.08465216820616098
Trained batch 210 in epoch 4, gen_loss = 0.8213798475773979, disc_loss = 0.08494122927540569
Trained batch 211 in epoch 4, gen_loss = 0.8216831584302884, disc_loss = 0.0852045763442117
Trained batch 212 in epoch 4, gen_loss = 0.8209108012103139, disc_loss = 0.08533442678900671
Trained batch 213 in epoch 4, gen_loss = 0.8192902409306196, disc_loss = 0.08593327901108522
Trained batch 214 in epoch 4, gen_loss = 0.8196504317050757, disc_loss = 0.08559109048787937
Trained batch 215 in epoch 4, gen_loss = 0.8208074653866114, disc_loss = 0.08654831963832732
Trained batch 216 in epoch 4, gen_loss = 0.8202094851825644, disc_loss = 0.08651603401256597
Trained batch 217 in epoch 4, gen_loss = 0.8195163176967464, disc_loss = 0.08644010485448969
Trained batch 218 in epoch 4, gen_loss = 0.8192513023065106, disc_loss = 0.08630996792828112
Trained batch 219 in epoch 4, gen_loss = 0.8188901753588156, disc_loss = 0.08698777095838027
Trained batch 220 in epoch 4, gen_loss = 0.8173485460324524, disc_loss = 0.08722980360909285
Trained batch 221 in epoch 4, gen_loss = 0.816059163293323, disc_loss = 0.087110392161989
Trained batch 222 in epoch 4, gen_loss = 0.8170493934721156, disc_loss = 0.08700684473052153
Trained batch 223 in epoch 4, gen_loss = 0.8166445400565863, disc_loss = 0.08709406012868774
Trained batch 224 in epoch 4, gen_loss = 0.8178895841704474, disc_loss = 0.0868329911513461
Trained batch 225 in epoch 4, gen_loss = 0.8156941203416976, disc_loss = 0.08746569383625699
Trained batch 226 in epoch 4, gen_loss = 0.8153326991896273, disc_loss = 0.08723955526783865
Trained batch 227 in epoch 4, gen_loss = 0.8165672021476846, disc_loss = 0.0871562765045255
Trained batch 228 in epoch 4, gen_loss = 0.8179459152783889, disc_loss = 0.08778645242178024
Trained batch 229 in epoch 4, gen_loss = 0.8175473376460697, disc_loss = 0.08784341275206078
Trained batch 230 in epoch 4, gen_loss = 0.8173424340945817, disc_loss = 0.08792278900323235
Trained batch 231 in epoch 4, gen_loss = 0.8164290390137968, disc_loss = 0.08816149895850184
Trained batch 232 in epoch 4, gen_loss = 0.8182855926358137, disc_loss = 0.08846485935343437
Trained batch 233 in epoch 4, gen_loss = 0.817929480320368, disc_loss = 0.08845322439845046
Trained batch 234 in epoch 4, gen_loss = 0.8167780744268539, disc_loss = 0.08866339612038845
Trained batch 235 in epoch 4, gen_loss = 0.8173726923384909, disc_loss = 0.08850217052593322
Trained batch 236 in epoch 4, gen_loss = 0.817607216694184, disc_loss = 0.08890395165904413
Trained batch 237 in epoch 4, gen_loss = 0.8164869722198037, disc_loss = 0.08907813319795523
Trained batch 238 in epoch 4, gen_loss = 0.8154524587188305, disc_loss = 0.08913614732606889
Trained batch 239 in epoch 4, gen_loss = 0.8155916181703409, disc_loss = 0.088888193317689
Trained batch 240 in epoch 4, gen_loss = 0.8146110041012903, disc_loss = 0.08875055777303163
Trained batch 241 in epoch 4, gen_loss = 0.8146609580221255, disc_loss = 0.08866962303276643
Trained batch 242 in epoch 4, gen_loss = 0.8142141307332388, disc_loss = 0.08874397310179202
Trained batch 243 in epoch 4, gen_loss = 0.8136214604143237, disc_loss = 0.08868035783258374
Trained batch 244 in epoch 4, gen_loss = 0.8147302997355559, disc_loss = 0.08863337784245306
Trained batch 245 in epoch 4, gen_loss = 0.8142079817570322, disc_loss = 0.08836003264972592
Trained batch 246 in epoch 4, gen_loss = 0.8139779019934928, disc_loss = 0.08831599516877037
Trained batch 247 in epoch 4, gen_loss = 0.8160541059990083, disc_loss = 0.08807457227169746
Trained batch 248 in epoch 4, gen_loss = 0.8155913216521941, disc_loss = 0.0879566462179384
Trained batch 249 in epoch 4, gen_loss = 0.8161531429290771, disc_loss = 0.08801827485114336
Trained batch 250 in epoch 4, gen_loss = 0.8166088231531272, disc_loss = 0.08801044625382262
Trained batch 251 in epoch 4, gen_loss = 0.8152945365697618, disc_loss = 0.08842251196296678
Trained batch 252 in epoch 4, gen_loss = 0.8157088450292354, disc_loss = 0.08819059585129084
Trained batch 253 in epoch 4, gen_loss = 0.8157327144634067, disc_loss = 0.08805228735312937
Trained batch 254 in epoch 4, gen_loss = 0.8154064746464, disc_loss = 0.0879144574716395
Trained batch 255 in epoch 4, gen_loss = 0.8154742287006229, disc_loss = 0.08769331266375957
Trained batch 256 in epoch 4, gen_loss = 0.8150627587555911, disc_loss = 0.08789850092322678
Trained batch 257 in epoch 4, gen_loss = 0.8141543294570243, disc_loss = 0.08793255027614591
Trained batch 258 in epoch 4, gen_loss = 0.8137226818150995, disc_loss = 0.08811263440169653
Trained batch 259 in epoch 4, gen_loss = 0.8139546761145958, disc_loss = 0.08803766741632268
Trained batch 260 in epoch 4, gen_loss = 0.813713896548611, disc_loss = 0.08804450289014427
Trained batch 261 in epoch 4, gen_loss = 0.8135675599101846, disc_loss = 0.08778141222837317
Trained batch 262 in epoch 4, gen_loss = 0.8141469608694881, disc_loss = 0.08802643163349239
Trained batch 263 in epoch 4, gen_loss = 0.8127242985999945, disc_loss = 0.08809814297340134
Trained batch 264 in epoch 4, gen_loss = 0.8121431310221834, disc_loss = 0.08807846198104463
Trained batch 265 in epoch 4, gen_loss = 0.8115460366234744, disc_loss = 0.08799257042600696
Trained batch 266 in epoch 4, gen_loss = 0.8140136441041468, disc_loss = 0.0881172465753466
Trained batch 267 in epoch 4, gen_loss = 0.8140314136868092, disc_loss = 0.08787738636080454
Trained batch 268 in epoch 4, gen_loss = 0.814157437214621, disc_loss = 0.0879271309199608
Trained batch 269 in epoch 4, gen_loss = 0.8144877906198855, disc_loss = 0.08770638198626263
Trained batch 270 in epoch 4, gen_loss = 0.8147111202957885, disc_loss = 0.08755805350950063
Trained batch 271 in epoch 4, gen_loss = 0.8139185857246903, disc_loss = 0.08743853603407521
Trained batch 272 in epoch 4, gen_loss = 0.8144425909161132, disc_loss = 0.08751458684903579
Trained batch 273 in epoch 4, gen_loss = 0.8155353321646251, disc_loss = 0.0873818212549073
Trained batch 274 in epoch 4, gen_loss = 0.8146666054292159, disc_loss = 0.08730527579107068
Trained batch 275 in epoch 4, gen_loss = 0.813936789398608, disc_loss = 0.08764274660632879
Trained batch 276 in epoch 4, gen_loss = 0.8139291287329222, disc_loss = 0.08749655641561596
Trained batch 277 in epoch 4, gen_loss = 0.8150018149142643, disc_loss = 0.08764708062915279
Trained batch 278 in epoch 4, gen_loss = 0.8154330027146152, disc_loss = 0.08740007140970786
Trained batch 279 in epoch 4, gen_loss = 0.8162701261895043, disc_loss = 0.08714614137341933
Trained batch 280 in epoch 4, gen_loss = 0.8159591945889157, disc_loss = 0.08701518975410386
Trained batch 281 in epoch 4, gen_loss = 0.816139115509412, disc_loss = 0.08680264847287049
Trained batch 282 in epoch 4, gen_loss = 0.8159167867667262, disc_loss = 0.086648113591195
Trained batch 283 in epoch 4, gen_loss = 0.8158067582358777, disc_loss = 0.08646245532944588
Trained batch 284 in epoch 4, gen_loss = 0.8165325223353871, disc_loss = 0.08627152763176382
Trained batch 285 in epoch 4, gen_loss = 0.8164134830028027, disc_loss = 0.08606921531051606
Trained batch 286 in epoch 4, gen_loss = 0.8180224617183831, disc_loss = 0.08614719203488337
Trained batch 287 in epoch 4, gen_loss = 0.8171825357195404, disc_loss = 0.08635437249257746
Trained batch 288 in epoch 4, gen_loss = 0.81715229287692, disc_loss = 0.08628092114539708
Trained batch 289 in epoch 4, gen_loss = 0.8180778587686605, disc_loss = 0.08605892452700385
Trained batch 290 in epoch 4, gen_loss = 0.8195279781351384, disc_loss = 0.08656424637307826
Trained batch 291 in epoch 4, gen_loss = 0.8199880047611994, disc_loss = 0.08636055495079657
Trained batch 292 in epoch 4, gen_loss = 0.8195448759879675, disc_loss = 0.08627718746814711
Trained batch 293 in epoch 4, gen_loss = 0.820422193631023, disc_loss = 0.0861176398335671
Trained batch 294 in epoch 4, gen_loss = 0.8210378412473, disc_loss = 0.0859426918676344
Trained batch 295 in epoch 4, gen_loss = 0.8213477078321818, disc_loss = 0.0857326130105837
Trained batch 296 in epoch 4, gen_loss = 0.8213115412779529, disc_loss = 0.08555419828353908
Trained batch 297 in epoch 4, gen_loss = 0.8202711451773675, disc_loss = 0.08605267792540108
Trained batch 298 in epoch 4, gen_loss = 0.821394127348195, disc_loss = 0.08653810406010286
Trained batch 299 in epoch 4, gen_loss = 0.8220247801144918, disc_loss = 0.08729720051089923
Trained batch 300 in epoch 4, gen_loss = 0.8216659262330825, disc_loss = 0.08723258927613002
Trained batch 301 in epoch 4, gen_loss = 0.8210982636900137, disc_loss = 0.08715464404185876
Trained batch 302 in epoch 4, gen_loss = 0.8204142797504714, disc_loss = 0.08754264376442818
Trained batch 303 in epoch 4, gen_loss = 0.8210088204788534, disc_loss = 0.08799883176719672
Trained batch 304 in epoch 4, gen_loss = 0.8202825696741949, disc_loss = 0.08804394842171279
Trained batch 305 in epoch 4, gen_loss = 0.8196968582330966, disc_loss = 0.08823879871493072
Trained batch 306 in epoch 4, gen_loss = 0.8202479982609081, disc_loss = 0.08828433763223673
Trained batch 307 in epoch 4, gen_loss = 0.8213568533008749, disc_loss = 0.08828773436608253
Trained batch 308 in epoch 4, gen_loss = 0.8207454511648629, disc_loss = 0.08839708663113295
Trained batch 309 in epoch 4, gen_loss = 0.8198508014602046, disc_loss = 0.08863489858565791
Trained batch 310 in epoch 4, gen_loss = 0.8198637552200023, disc_loss = 0.08847654383282186
Trained batch 311 in epoch 4, gen_loss = 0.8207959345518014, disc_loss = 0.08839941559693752
Trained batch 312 in epoch 4, gen_loss = 0.8210401371264229, disc_loss = 0.08831666971738346
Trained batch 313 in epoch 4, gen_loss = 0.8202879083384375, disc_loss = 0.08863052369872476
Trained batch 314 in epoch 4, gen_loss = 0.8204866791528369, disc_loss = 0.08865130245685578
Trained batch 315 in epoch 4, gen_loss = 0.8204940508438062, disc_loss = 0.08861179838452159
Trained batch 316 in epoch 4, gen_loss = 0.8196774002881456, disc_loss = 0.08879482652110632
Trained batch 317 in epoch 4, gen_loss = 0.8198752219572008, disc_loss = 0.0886147548473856
Trained batch 318 in epoch 4, gen_loss = 0.8205400421327932, disc_loss = 0.08849898913764281
Trained batch 319 in epoch 4, gen_loss = 0.8198031989857555, disc_loss = 0.08854795208899305
Trained batch 320 in epoch 4, gen_loss = 0.8200473155930778, disc_loss = 0.08852288367174496
Trained batch 321 in epoch 4, gen_loss = 0.8202612672163092, disc_loss = 0.0886859915896047
Trained batch 322 in epoch 4, gen_loss = 0.8201446086629626, disc_loss = 0.0886850093978662
Trained batch 323 in epoch 4, gen_loss = 0.8192947492187406, disc_loss = 0.08920767488257017
Trained batch 324 in epoch 4, gen_loss = 0.8196239748367896, disc_loss = 0.08946191690289057
Trained batch 325 in epoch 4, gen_loss = 0.8196553121680862, disc_loss = 0.08939318005795494
Trained batch 326 in epoch 4, gen_loss = 0.8190454873469991, disc_loss = 0.08932019238123835
Trained batch 327 in epoch 4, gen_loss = 0.8200644888892407, disc_loss = 0.08986943806862323
Trained batch 328 in epoch 4, gen_loss = 0.81853874086609, disc_loss = 0.09035238833095889
Trained batch 329 in epoch 4, gen_loss = 0.8178937389092011, disc_loss = 0.09035088929037254
Trained batch 330 in epoch 4, gen_loss = 0.8187600216656653, disc_loss = 0.09077724862809988
Trained batch 331 in epoch 4, gen_loss = 0.8176955031343254, disc_loss = 0.09095715308359947
Trained batch 332 in epoch 4, gen_loss = 0.8175613602718433, disc_loss = 0.0909118300063295
Trained batch 333 in epoch 4, gen_loss = 0.8182623937815249, disc_loss = 0.09081788415725003
Trained batch 334 in epoch 4, gen_loss = 0.818803541873818, disc_loss = 0.09081255985952136
Trained batch 335 in epoch 4, gen_loss = 0.8189108744263649, disc_loss = 0.0907448145804838
Trained batch 336 in epoch 4, gen_loss = 0.8180300842760578, disc_loss = 0.09088949011279497
Trained batch 337 in epoch 4, gen_loss = 0.8180479802323516, disc_loss = 0.09081390761279848
Trained batch 338 in epoch 4, gen_loss = 0.81854965869656, disc_loss = 0.09070034681168278
Trained batch 339 in epoch 4, gen_loss = 0.8180265212760253, disc_loss = 0.09053957293577054
Trained batch 340 in epoch 4, gen_loss = 0.8167814997808674, disc_loss = 0.09103410393873618
Trained batch 341 in epoch 4, gen_loss = 0.8172573191903488, disc_loss = 0.09086150146628681
Trained batch 342 in epoch 4, gen_loss = 0.816901788854043, disc_loss = 0.09074673451939408
Trained batch 343 in epoch 4, gen_loss = 0.8169656956438408, disc_loss = 0.09063649512177636
Trained batch 344 in epoch 4, gen_loss = 0.8166372132474098, disc_loss = 0.09048468899251758
Trained batch 345 in epoch 4, gen_loss = 0.8167694096448105, disc_loss = 0.09031016756968864
Trained batch 346 in epoch 4, gen_loss = 0.8163256436500494, disc_loss = 0.0902615699552064
Trained batch 347 in epoch 4, gen_loss = 0.8165710000642414, disc_loss = 0.09005872405337534
Trained batch 348 in epoch 4, gen_loss = 0.8166118150624982, disc_loss = 0.09018050438396227
Trained batch 349 in epoch 4, gen_loss = 0.8157656036955969, disc_loss = 0.09070721397442477
Trained batch 350 in epoch 4, gen_loss = 0.8161306351508171, disc_loss = 0.0905023122476971
Trained batch 351 in epoch 4, gen_loss = 0.8177367886528373, disc_loss = 0.09082366631429811
Trained batch 352 in epoch 4, gen_loss = 0.817354294885657, disc_loss = 0.0908856384466711
Trained batch 353 in epoch 4, gen_loss = 0.81697528030576, disc_loss = 0.09101369347170753
Trained batch 354 in epoch 4, gen_loss = 0.8171265933715122, disc_loss = 0.09084795153581761
Trained batch 355 in epoch 4, gen_loss = 0.8174195660466559, disc_loss = 0.09072006425265683
Trained batch 356 in epoch 4, gen_loss = 0.8168492154413912, disc_loss = 0.09084146987928562
Trained batch 357 in epoch 4, gen_loss = 0.8160412382313659, disc_loss = 0.09077305611555969
Trained batch 358 in epoch 4, gen_loss = 0.8172527771640289, disc_loss = 0.09168063608986587
Trained batch 359 in epoch 4, gen_loss = 0.8171488554113441, disc_loss = 0.09159728954546154
Trained batch 360 in epoch 4, gen_loss = 0.8174170438107361, disc_loss = 0.09146748359864604
Trained batch 361 in epoch 4, gen_loss = 0.8166181814769355, disc_loss = 0.09176563290951166
Trained batch 362 in epoch 4, gen_loss = 0.8160520513688237, disc_loss = 0.09180688718975247
Trained batch 363 in epoch 4, gen_loss = 0.8158842645339913, disc_loss = 0.09179085532489878
Trained batch 364 in epoch 4, gen_loss = 0.8160237316399405, disc_loss = 0.09184241436217745
Trained batch 365 in epoch 4, gen_loss = 0.8165908697687212, disc_loss = 0.0916166021437715
Trained batch 366 in epoch 4, gen_loss = 0.8155507336520369, disc_loss = 0.09183252037170392
Trained batch 367 in epoch 4, gen_loss = 0.8154430894748025, disc_loss = 0.09167537546423062
Trained batch 368 in epoch 4, gen_loss = 0.8152398786893705, disc_loss = 0.09190688667652326
Trained batch 369 in epoch 4, gen_loss = 0.8147125584048194, disc_loss = 0.09203609691026646
Trained batch 370 in epoch 4, gen_loss = 0.8146566755045457, disc_loss = 0.09194375704873524
Trained batch 371 in epoch 4, gen_loss = 0.8145455554608376, disc_loss = 0.09183837166706961
Trained batch 372 in epoch 4, gen_loss = 0.814946452989655, disc_loss = 0.09178752913302056
Trained batch 373 in epoch 4, gen_loss = 0.8150199556095715, disc_loss = 0.09164361257036341
Trained batch 374 in epoch 4, gen_loss = 0.8148841250737509, disc_loss = 0.09145255455126365
Trained batch 375 in epoch 4, gen_loss = 0.815558855520918, disc_loss = 0.09157610229622731
Trained batch 376 in epoch 4, gen_loss = 0.8149126831353185, disc_loss = 0.09154392666966514
Trained batch 377 in epoch 4, gen_loss = 0.8149441389179735, disc_loss = 0.0914086067541527
Trained batch 378 in epoch 4, gen_loss = 0.8142464519490668, disc_loss = 0.09143110201264042
Trained batch 379 in epoch 4, gen_loss = 0.814738329774455, disc_loss = 0.09147813633623483
Trained batch 380 in epoch 4, gen_loss = 0.814660253487234, disc_loss = 0.09143343999776549
Trained batch 381 in epoch 4, gen_loss = 0.8141922549739558, disc_loss = 0.09154566897918026
Trained batch 382 in epoch 4, gen_loss = 0.8146863660675427, disc_loss = 0.09138632400141294
Trained batch 383 in epoch 4, gen_loss = 0.8144444284650186, disc_loss = 0.09140217790991301
Trained batch 384 in epoch 4, gen_loss = 0.8143475893255953, disc_loss = 0.09120296472320696
Trained batch 385 in epoch 4, gen_loss = 0.8141462177501442, disc_loss = 0.09113878459751683
Trained batch 386 in epoch 4, gen_loss = 0.8148244032564089, disc_loss = 0.09096991019299402
Trained batch 387 in epoch 4, gen_loss = 0.8142732738219586, disc_loss = 0.09093161650030807
Trained batch 388 in epoch 4, gen_loss = 0.8141996675101528, disc_loss = 0.09079106154691208
Trained batch 389 in epoch 4, gen_loss = 0.8147300040110563, disc_loss = 0.09106838751632051
Trained batch 390 in epoch 4, gen_loss = 0.8142640671461744, disc_loss = 0.09125967619850127
Trained batch 391 in epoch 4, gen_loss = 0.8141686499727016, disc_loss = 0.0910958031700848
Trained batch 392 in epoch 4, gen_loss = 0.8138159828938297, disc_loss = 0.0919189962508683
Trained batch 393 in epoch 4, gen_loss = 0.8131020911756506, disc_loss = 0.09208882159227269
Trained batch 394 in epoch 4, gen_loss = 0.8125711391243754, disc_loss = 0.0919948893611001
Trained batch 395 in epoch 4, gen_loss = 0.8125378837188085, disc_loss = 0.09207166813906621
Trained batch 396 in epoch 4, gen_loss = 0.8129395707428305, disc_loss = 0.09211102317343055
Trained batch 397 in epoch 4, gen_loss = 0.8128185408498774, disc_loss = 0.09201339588046598
Trained batch 398 in epoch 4, gen_loss = 0.8134907924740535, disc_loss = 0.0920286565752966
Trained batch 399 in epoch 4, gen_loss = 0.8133634673058987, disc_loss = 0.0920151315513067
Trained batch 400 in epoch 4, gen_loss = 0.8134100050700276, disc_loss = 0.09183239425181822
Trained batch 401 in epoch 4, gen_loss = 0.8131455627839956, disc_loss = 0.0917221842755318
Trained batch 402 in epoch 4, gen_loss = 0.8138380319841446, disc_loss = 0.09176895970122764
Trained batch 403 in epoch 4, gen_loss = 0.8134367706456987, disc_loss = 0.09191366404267305
Trained batch 404 in epoch 4, gen_loss = 0.8124067382312116, disc_loss = 0.09253686417446093
Trained batch 405 in epoch 4, gen_loss = 0.8122986059617526, disc_loss = 0.09287689392468686
Trained batch 406 in epoch 4, gen_loss = 0.8127717331088439, disc_loss = 0.09281666253988588
Trained batch 407 in epoch 4, gen_loss = 0.812523536164971, disc_loss = 0.09267060637848415
Trained batch 408 in epoch 4, gen_loss = 0.8124195867033634, disc_loss = 0.09262642781944685
Trained batch 409 in epoch 4, gen_loss = 0.8121002855097376, disc_loss = 0.0925915478774142
Trained batch 410 in epoch 4, gen_loss = 0.8118322879583586, disc_loss = 0.092577577745338
Trained batch 411 in epoch 4, gen_loss = 0.8120379677241288, disc_loss = 0.09290448556545651
Trained batch 412 in epoch 4, gen_loss = 0.8114892429791698, disc_loss = 0.09326866617511967
Trained batch 413 in epoch 4, gen_loss = 0.8115277596285954, disc_loss = 0.09355329972543362
Trained batch 414 in epoch 4, gen_loss = 0.8105540972158133, disc_loss = 0.09367284126893943
Trained batch 415 in epoch 4, gen_loss = 0.8104694565901389, disc_loss = 0.09373045933226912
Trained batch 416 in epoch 4, gen_loss = 0.81097941318576, disc_loss = 0.09385845045686411
Trained batch 417 in epoch 4, gen_loss = 0.8104881227872018, disc_loss = 0.09394219836986592
Trained batch 418 in epoch 4, gen_loss = 0.8102222831835326, disc_loss = 0.09399902269573157
Trained batch 419 in epoch 4, gen_loss = 0.8100332841986702, disc_loss = 0.09396882809565536
Trained batch 420 in epoch 4, gen_loss = 0.8113084912583267, disc_loss = 0.09423198022010278
Trained batch 421 in epoch 4, gen_loss = 0.811250533537842, disc_loss = 0.09411973662683255
Trained batch 422 in epoch 4, gen_loss = 0.8103878627713972, disc_loss = 0.09424360759829305
Trained batch 423 in epoch 4, gen_loss = 0.8106054289723342, disc_loss = 0.09411198003788672
Trained batch 424 in epoch 4, gen_loss = 0.8103613414483912, disc_loss = 0.09400334399631795
Trained batch 425 in epoch 4, gen_loss = 0.8104138780087932, disc_loss = 0.09400543828709094
Trained batch 426 in epoch 4, gen_loss = 0.811044203592966, disc_loss = 0.09409416639038844
Trained batch 427 in epoch 4, gen_loss = 0.8109741280569094, disc_loss = 0.09393822593901689
Trained batch 428 in epoch 4, gen_loss = 0.8103090385734896, disc_loss = 0.09408642334911303
Trained batch 429 in epoch 4, gen_loss = 0.8104096944942031, disc_loss = 0.09391908058030314
Trained batch 430 in epoch 4, gen_loss = 0.8108111532824221, disc_loss = 0.09379827690779678
Trained batch 431 in epoch 4, gen_loss = 0.8114839056851687, disc_loss = 0.09363250122879874
Trained batch 432 in epoch 4, gen_loss = 0.811123840390397, disc_loss = 0.09362485162337368
Trained batch 433 in epoch 4, gen_loss = 0.8107040112469054, disc_loss = 0.09350483799954096
Trained batch 434 in epoch 4, gen_loss = 0.8111420107983994, disc_loss = 0.0933610344862287
Trained batch 435 in epoch 4, gen_loss = 0.8106548318622309, disc_loss = 0.09328356317090673
Trained batch 436 in epoch 4, gen_loss = 0.8102076678308797, disc_loss = 0.09357455284366686
Trained batch 437 in epoch 4, gen_loss = 0.8096373660923684, disc_loss = 0.09370814638263354
Trained batch 438 in epoch 4, gen_loss = 0.8096261435869343, disc_loss = 0.09356960589129791
Trained batch 439 in epoch 4, gen_loss = 0.8101988379250873, disc_loss = 0.09403271691408008
Trained batch 440 in epoch 4, gen_loss = 0.8096661389279528, disc_loss = 0.09420860296246214
Trained batch 441 in epoch 4, gen_loss = 0.8098231327479781, disc_loss = 0.09410422003924913
Trained batch 442 in epoch 4, gen_loss = 0.8095459169781773, disc_loss = 0.09408619053216134
Trained batch 443 in epoch 4, gen_loss = 0.8097089812293783, disc_loss = 0.09393219690694399
Trained batch 444 in epoch 4, gen_loss = 0.8093366838573071, disc_loss = 0.09388891192927454
Trained batch 445 in epoch 4, gen_loss = 0.8093537069489604, disc_loss = 0.09395050851110319
Trained batch 446 in epoch 4, gen_loss = 0.8088362130276042, disc_loss = 0.09410098007353027
Trained batch 447 in epoch 4, gen_loss = 0.8089429713519556, disc_loss = 0.09398094181960914
Trained batch 448 in epoch 4, gen_loss = 0.8093302706567641, disc_loss = 0.09394737143683474
Trained batch 449 in epoch 4, gen_loss = 0.8091365465852949, disc_loss = 0.09385614179695646
Trained batch 450 in epoch 4, gen_loss = 0.8090875816186621, disc_loss = 0.09370042992231256
Trained batch 451 in epoch 4, gen_loss = 0.8085950329504182, disc_loss = 0.09371437790671742
Trained batch 452 in epoch 4, gen_loss = 0.8090646962982666, disc_loss = 0.0937870614144285
Trained batch 453 in epoch 4, gen_loss = 0.8091651743466634, disc_loss = 0.09399406994910427
Trained batch 454 in epoch 4, gen_loss = 0.8087291370381365, disc_loss = 0.09406911615118548
Trained batch 455 in epoch 4, gen_loss = 0.8082217295703135, disc_loss = 0.09420337288419862
Trained batch 456 in epoch 4, gen_loss = 0.8081221418777232, disc_loss = 0.0945405289917956
Trained batch 457 in epoch 4, gen_loss = 0.8090866726038237, disc_loss = 0.09462816189104227
Trained batch 458 in epoch 4, gen_loss = 0.8086122154929799, disc_loss = 0.09476384185132833
Trained batch 459 in epoch 4, gen_loss = 0.8078692363656086, disc_loss = 0.09491421984225187
Trained batch 460 in epoch 4, gen_loss = 0.8084314288389657, disc_loss = 0.0948643465617312
Trained batch 461 in epoch 4, gen_loss = 0.8084909377934096, disc_loss = 0.09489223647064396
Trained batch 462 in epoch 4, gen_loss = 0.8078804721585103, disc_loss = 0.09505854027856696
Trained batch 463 in epoch 4, gen_loss = 0.8080391876142601, disc_loss = 0.0949801761187324
Trained batch 464 in epoch 4, gen_loss = 0.8077931429750176, disc_loss = 0.09495651960493096
Trained batch 465 in epoch 4, gen_loss = 0.8082791331499943, disc_loss = 0.09494636975060909
Trained batch 466 in epoch 4, gen_loss = 0.8074774236699498, disc_loss = 0.09524607278478414
Trained batch 467 in epoch 4, gen_loss = 0.8070683443648183, disc_loss = 0.09533162004091482
Trained batch 468 in epoch 4, gen_loss = 0.8071815945954719, disc_loss = 0.09517709337182835
Trained batch 469 in epoch 4, gen_loss = 0.8073493243531978, disc_loss = 0.094994980705149
Trained batch 470 in epoch 4, gen_loss = 0.8080738017260396, disc_loss = 0.09490073550365975
Trained batch 471 in epoch 4, gen_loss = 0.8077973012449378, disc_loss = 0.09493328923541042
Trained batch 472 in epoch 4, gen_loss = 0.8081921022739773, disc_loss = 0.09481016717197464
Trained batch 473 in epoch 4, gen_loss = 0.8082227904333847, disc_loss = 0.09467986369709866
Trained batch 474 in epoch 4, gen_loss = 0.8082224500806708, disc_loss = 0.09454613303471553
Trained batch 475 in epoch 4, gen_loss = 0.808246375758107, disc_loss = 0.0943766253620793
Trained batch 476 in epoch 4, gen_loss = 0.8083084326870037, disc_loss = 0.09444446256677122
Trained batch 477 in epoch 4, gen_loss = 0.8077861603084469, disc_loss = 0.09448365607809385
Trained batch 478 in epoch 4, gen_loss = 0.8080746771647188, disc_loss = 0.09432039644164743
Trained batch 479 in epoch 4, gen_loss = 0.8083102557808161, disc_loss = 0.09434004391271932
Trained batch 480 in epoch 4, gen_loss = 0.8082809776625366, disc_loss = 0.09430796969991774
Trained batch 481 in epoch 4, gen_loss = 0.8080542426386315, disc_loss = 0.09431503143710282
Trained batch 482 in epoch 4, gen_loss = 0.8082363094602313, disc_loss = 0.09415055095463004
Trained batch 483 in epoch 4, gen_loss = 0.8085002676268255, disc_loss = 0.09410695141866372
Trained batch 484 in epoch 4, gen_loss = 0.8086189502293302, disc_loss = 0.09396006577677027
Trained batch 485 in epoch 4, gen_loss = 0.8083291716045804, disc_loss = 0.0938779127692091
Trained batch 486 in epoch 4, gen_loss = 0.8084384341259512, disc_loss = 0.09372392983904426
Trained batch 487 in epoch 4, gen_loss = 0.8080376735964759, disc_loss = 0.0937878965709328
Trained batch 488 in epoch 4, gen_loss = 0.8081063746430879, disc_loss = 0.09373512676896066
Trained batch 489 in epoch 4, gen_loss = 0.808062937429973, disc_loss = 0.09384692933372393
Trained batch 490 in epoch 4, gen_loss = 0.8074302605358986, disc_loss = 0.09393099795784156
Trained batch 491 in epoch 4, gen_loss = 0.8076662016593343, disc_loss = 0.09378015264164566
Trained batch 492 in epoch 4, gen_loss = 0.8077554029335114, disc_loss = 0.09363035007396951
Trained batch 493 in epoch 4, gen_loss = 0.8080751713712205, disc_loss = 0.09359014270118313
Trained batch 494 in epoch 4, gen_loss = 0.8079802348156168, disc_loss = 0.09351215816921357
Trained batch 495 in epoch 4, gen_loss = 0.807625976180838, disc_loss = 0.09354749180549275
Trained batch 496 in epoch 4, gen_loss = 0.8077132790621138, disc_loss = 0.09376195333785634
Trained batch 497 in epoch 4, gen_loss = 0.8081591873762598, disc_loss = 0.09367866917180429
Trained batch 498 in epoch 4, gen_loss = 0.8075223667229823, disc_loss = 0.09377488193619167
Trained batch 499 in epoch 4, gen_loss = 0.8070628119111061, disc_loss = 0.09375775055401027
Trained batch 500 in epoch 4, gen_loss = 0.8079722523094414, disc_loss = 0.09390873006710451
Trained batch 501 in epoch 4, gen_loss = 0.8073653360880704, disc_loss = 0.09393557105992598
Trained batch 502 in epoch 4, gen_loss = 0.8077638616737267, disc_loss = 0.09385729554270358
Trained batch 503 in epoch 4, gen_loss = 0.8076514829364088, disc_loss = 0.09374927947970314
Trained batch 504 in epoch 4, gen_loss = 0.8076669025539172, disc_loss = 0.09360154669289247
Trained batch 505 in epoch 4, gen_loss = 0.8077714116323607, disc_loss = 0.09349388344831794
Trained batch 506 in epoch 4, gen_loss = 0.8074949981545555, disc_loss = 0.09346324352169119
Trained batch 507 in epoch 4, gen_loss = 0.8076478167195019, disc_loss = 0.09330890783636765
Trained batch 508 in epoch 4, gen_loss = 0.8075507802555744, disc_loss = 0.09321378540862461
Trained batch 509 in epoch 4, gen_loss = 0.8080305815327401, disc_loss = 0.09314594659406472
Trained batch 510 in epoch 4, gen_loss = 0.8083603333703693, disc_loss = 0.093006000001122
Trained batch 511 in epoch 4, gen_loss = 0.8078633021214046, disc_loss = 0.09303245893352141
Trained batch 512 in epoch 4, gen_loss = 0.807988956483484, disc_loss = 0.09304547146304018
Trained batch 513 in epoch 4, gen_loss = 0.8080145626796359, disc_loss = 0.092964238713673
Trained batch 514 in epoch 4, gen_loss = 0.8080186397705263, disc_loss = 0.09286763819784505
Trained batch 515 in epoch 4, gen_loss = 0.8082546966598015, disc_loss = 0.09276599700331631
Trained batch 516 in epoch 4, gen_loss = 0.8083926393745946, disc_loss = 0.09279117118423116
Trained batch 517 in epoch 4, gen_loss = 0.8090680032738388, disc_loss = 0.09264762813771957
Trained batch 518 in epoch 4, gen_loss = 0.8085412093095466, disc_loss = 0.09296596927930796
Trained batch 519 in epoch 4, gen_loss = 0.8087257276933927, disc_loss = 0.09288037432035288
Trained batch 520 in epoch 4, gen_loss = 0.8090740894745041, disc_loss = 0.09290938737003165
Trained batch 521 in epoch 4, gen_loss = 0.8093216740651149, disc_loss = 0.09275810200349924
Trained batch 522 in epoch 4, gen_loss = 0.8089490430874761, disc_loss = 0.0927855184917867
Trained batch 523 in epoch 4, gen_loss = 0.8088148589466364, disc_loss = 0.0929942597947901
Trained batch 524 in epoch 4, gen_loss = 0.8093380833239783, disc_loss = 0.09288245852149668
Trained batch 525 in epoch 4, gen_loss = 0.8096752344088862, disc_loss = 0.09277765067230499
Trained batch 526 in epoch 4, gen_loss = 0.809634541707428, disc_loss = 0.09265104148614678
Trained batch 527 in epoch 4, gen_loss = 0.8091295286448617, disc_loss = 0.09269644756392209
Trained batch 528 in epoch 4, gen_loss = 0.8092326824403665, disc_loss = 0.0926169406918418
Trained batch 529 in epoch 4, gen_loss = 0.8096203612269096, disc_loss = 0.09249424330257582
Trained batch 530 in epoch 4, gen_loss = 0.8094343415649148, disc_loss = 0.09242723768194629
Trained batch 531 in epoch 4, gen_loss = 0.8097611230454946, disc_loss = 0.09234135987629231
Trained batch 532 in epoch 4, gen_loss = 0.8096822079194196, disc_loss = 0.09219300448300412
Trained batch 533 in epoch 4, gen_loss = 0.8098760383964031, disc_loss = 0.09216175026570757
Trained batch 534 in epoch 4, gen_loss = 0.8095340830700419, disc_loss = 0.09230629274464935
Trained batch 535 in epoch 4, gen_loss = 0.8096268848140737, disc_loss = 0.09226802941376983
Trained batch 536 in epoch 4, gen_loss = 0.8100660961100509, disc_loss = 0.09218726286168594
Trained batch 537 in epoch 4, gen_loss = 0.8107012086530601, disc_loss = 0.0924471789282023
Trained batch 538 in epoch 4, gen_loss = 0.8102488857806281, disc_loss = 0.0923736415620278
Trained batch 539 in epoch 4, gen_loss = 0.809701224775226, disc_loss = 0.09246019542182761
Trained batch 540 in epoch 4, gen_loss = 0.8096481752814295, disc_loss = 0.0923868672984227
Trained batch 541 in epoch 4, gen_loss = 0.8096318554504331, disc_loss = 0.09227706009274644
Trained batch 542 in epoch 4, gen_loss = 0.8100090212914166, disc_loss = 0.09218041245991958
Trained batch 543 in epoch 4, gen_loss = 0.810299391639145, disc_loss = 0.0921051685599035
Trained batch 544 in epoch 4, gen_loss = 0.8103704489152366, disc_loss = 0.09198295008391141
Trained batch 545 in epoch 4, gen_loss = 0.8104006256703492, disc_loss = 0.09198423375924811
Trained batch 546 in epoch 4, gen_loss = 0.8110205902151042, disc_loss = 0.09186090533902538
Trained batch 547 in epoch 4, gen_loss = 0.811602925460269, disc_loss = 0.09175708324539672
Trained batch 548 in epoch 4, gen_loss = 0.8108121750567563, disc_loss = 0.09194622893320678
Trained batch 549 in epoch 4, gen_loss = 0.8105526452714746, disc_loss = 0.091882180031389
Trained batch 550 in epoch 4, gen_loss = 0.8110981884322884, disc_loss = 0.09208616876836102
Trained batch 551 in epoch 4, gen_loss = 0.8105501432133757, disc_loss = 0.09226926521607337
Trained batch 552 in epoch 4, gen_loss = 0.8104459540968993, disc_loss = 0.09216943776123832
Trained batch 553 in epoch 4, gen_loss = 0.8105532600130846, disc_loss = 0.09232558688780945
Trained batch 554 in epoch 4, gen_loss = 0.810470834723464, disc_loss = 0.0925401319741263
Trained batch 555 in epoch 4, gen_loss = 0.8097296941945021, disc_loss = 0.09288853025834391
Trained batch 556 in epoch 4, gen_loss = 0.8098044058899905, disc_loss = 0.09285495526038605
Trained batch 557 in epoch 4, gen_loss = 0.8097908539049942, disc_loss = 0.09289196271976743
Trained batch 558 in epoch 4, gen_loss = 0.8093836980876854, disc_loss = 0.09300537641478406
Trained batch 559 in epoch 4, gen_loss = 0.8092398981430701, disc_loss = 0.09292105300119147
Trained batch 560 in epoch 4, gen_loss = 0.8092248242700376, disc_loss = 0.09284540731459856
Trained batch 561 in epoch 4, gen_loss = 0.8089482217390767, disc_loss = 0.09290845060614981
Trained batch 562 in epoch 4, gen_loss = 0.8091479809309619, disc_loss = 0.09337481236512082
Trained batch 563 in epoch 4, gen_loss = 0.8089561773635817, disc_loss = 0.09339020929153982
Trained batch 564 in epoch 4, gen_loss = 0.8087858797702114, disc_loss = 0.09331620260578605
Trained batch 565 in epoch 4, gen_loss = 0.8087960444259138, disc_loss = 0.09326689610218254
Trained batch 566 in epoch 4, gen_loss = 0.8088871237987774, disc_loss = 0.0931394721612965
Trained batch 567 in epoch 4, gen_loss = 0.8086015696991498, disc_loss = 0.09316500628032577
Trained batch 568 in epoch 4, gen_loss = 0.8089308679522864, disc_loss = 0.09301959836335037
Trained batch 569 in epoch 4, gen_loss = 0.8086164333841257, disc_loss = 0.09296897510393408
Trained batch 570 in epoch 4, gen_loss = 0.8091050415135098, disc_loss = 0.0932527831861596
Trained batch 571 in epoch 4, gen_loss = 0.8089332328913929, disc_loss = 0.09326955163362924
Trained batch 572 in epoch 4, gen_loss = 0.808588787991339, disc_loss = 0.09327821389822384
Trained batch 573 in epoch 4, gen_loss = 0.8086445976944335, disc_loss = 0.09319801444109879
Trained batch 574 in epoch 4, gen_loss = 0.8083644679836605, disc_loss = 0.09318581080793038
Trained batch 575 in epoch 4, gen_loss = 0.809152649042921, disc_loss = 0.0937778602803721
Trained batch 576 in epoch 4, gen_loss = 0.8092204988829185, disc_loss = 0.09369117568248635
Trained batch 577 in epoch 4, gen_loss = 0.8089024143544861, disc_loss = 0.0940285439435457
Trained batch 578 in epoch 4, gen_loss = 0.8084490957552493, disc_loss = 0.09433073437706743
Trained batch 579 in epoch 4, gen_loss = 0.8080226546217655, disc_loss = 0.0943262498231669
Trained batch 580 in epoch 4, gen_loss = 0.808180938745735, disc_loss = 0.09443665546382715
Trained batch 581 in epoch 4, gen_loss = 0.8083375674445195, disc_loss = 0.0943594441774759
Trained batch 582 in epoch 4, gen_loss = 0.8079214211086875, disc_loss = 0.09448994126004737
Trained batch 583 in epoch 4, gen_loss = 0.8079506157297794, disc_loss = 0.0943763597329364
Trained batch 584 in epoch 4, gen_loss = 0.8074448226354061, disc_loss = 0.0943539588736036
Trained batch 585 in epoch 4, gen_loss = 0.8080296463018392, disc_loss = 0.09446052752861137
Trained batch 586 in epoch 4, gen_loss = 0.8083535058636478, disc_loss = 0.0943709950770364
Trained batch 587 in epoch 4, gen_loss = 0.8078405177410768, disc_loss = 0.09456305481892611
Trained batch 588 in epoch 4, gen_loss = 0.8077072813373267, disc_loss = 0.09460860070676017
Trained batch 589 in epoch 4, gen_loss = 0.8074821641384545, disc_loss = 0.09452286873928319
Trained batch 590 in epoch 4, gen_loss = 0.8074397601552824, disc_loss = 0.09450244448303723
Trained batch 591 in epoch 4, gen_loss = 0.8075969483502008, disc_loss = 0.09475620044238009
Trained batch 592 in epoch 4, gen_loss = 0.8072320746028604, disc_loss = 0.09497824088712718
Trained batch 593 in epoch 4, gen_loss = 0.8071348012396784, disc_loss = 0.09491912253445597
Trained batch 594 in epoch 4, gen_loss = 0.8066610346822177, disc_loss = 0.09503312436942042
Trained batch 595 in epoch 4, gen_loss = 0.8070196869889362, disc_loss = 0.09508743795141228
Trained batch 596 in epoch 4, gen_loss = 0.8068935150776676, disc_loss = 0.09500384993283344
Trained batch 597 in epoch 4, gen_loss = 0.8070223728649593, disc_loss = 0.09490244206271592
Trained batch 598 in epoch 4, gen_loss = 0.8068191273284078, disc_loss = 0.09480187010007579
Trained batch 599 in epoch 4, gen_loss = 0.8075325751801332, disc_loss = 0.09505527354000758
Trained batch 600 in epoch 4, gen_loss = 0.8075936955838354, disc_loss = 0.09493695833129862
Trained batch 601 in epoch 4, gen_loss = 0.8079034781634213, disc_loss = 0.09482812993630668
Trained batch 602 in epoch 4, gen_loss = 0.8077591993223573, disc_loss = 0.0947825777271815
Trained batch 603 in epoch 4, gen_loss = 0.8076963325506015, disc_loss = 0.09468334165882837
Trained batch 604 in epoch 4, gen_loss = 0.8080480756345859, disc_loss = 0.09454506975098335
Trained batch 605 in epoch 4, gen_loss = 0.8087701120293966, disc_loss = 0.09447278518371112
Trained batch 606 in epoch 4, gen_loss = 0.8085840024802791, disc_loss = 0.09444179173092522
Trained batch 607 in epoch 4, gen_loss = 0.8084389308075371, disc_loss = 0.09437452161862318
Trained batch 608 in epoch 4, gen_loss = 0.8083195764149351, disc_loss = 0.09433899754551293
Trained batch 609 in epoch 4, gen_loss = 0.8081910425033726, disc_loss = 0.09433773589457889
Trained batch 610 in epoch 4, gen_loss = 0.8080320777264828, disc_loss = 0.09424641721846869
Trained batch 611 in epoch 4, gen_loss = 0.8082769771709162, disc_loss = 0.09412281249126334
Trained batch 612 in epoch 4, gen_loss = 0.8085925088523847, disc_loss = 0.09404870301187282
Trained batch 613 in epoch 4, gen_loss = 0.8085052304528046, disc_loss = 0.09398375876120471
Trained batch 614 in epoch 4, gen_loss = 0.8079985860402022, disc_loss = 0.09416201240496665
Trained batch 615 in epoch 4, gen_loss = 0.8080220093297494, disc_loss = 0.09408250143721264
Trained batch 616 in epoch 4, gen_loss = 0.8082483600662053, disc_loss = 0.09410464373451916
Trained batch 617 in epoch 4, gen_loss = 0.8086276509132971, disc_loss = 0.09415722234343392
Trained batch 618 in epoch 4, gen_loss = 0.8083962817858417, disc_loss = 0.09430661661360829
Trained batch 619 in epoch 4, gen_loss = 0.8088169968416614, disc_loss = 0.09425732922259598
Trained batch 620 in epoch 4, gen_loss = 0.8088546764351512, disc_loss = 0.09429113481541715
Trained batch 621 in epoch 4, gen_loss = 0.8090825300795472, disc_loss = 0.09430121791989234
Trained batch 622 in epoch 4, gen_loss = 0.8085436037895576, disc_loss = 0.09438210743573609
Trained batch 623 in epoch 4, gen_loss = 0.8085014570313387, disc_loss = 0.0943128540022418
Trained batch 624 in epoch 4, gen_loss = 0.8090480915546417, disc_loss = 0.09441133516877889
Trained batch 625 in epoch 4, gen_loss = 0.8091678479894663, disc_loss = 0.0943207621392898
Trained batch 626 in epoch 4, gen_loss = 0.8086370650851176, disc_loss = 0.09449873784886735
Trained batch 627 in epoch 4, gen_loss = 0.8085497422203137, disc_loss = 0.09463667358081954
Trained batch 628 in epoch 4, gen_loss = 0.8085040776073837, disc_loss = 0.09452760908811905
Trained batch 629 in epoch 4, gen_loss = 0.8086379811877296, disc_loss = 0.09447870035581882
Trained batch 630 in epoch 4, gen_loss = 0.8083279026102529, disc_loss = 0.09452302730162576
Trained batch 631 in epoch 4, gen_loss = 0.8089494983418078, disc_loss = 0.09451777783747102
Trained batch 632 in epoch 4, gen_loss = 0.8096042239647153, disc_loss = 0.09454039582985602
Trained batch 633 in epoch 4, gen_loss = 0.8095506295232743, disc_loss = 0.0944860603187339
Trained batch 634 in epoch 4, gen_loss = 0.8091735642726027, disc_loss = 0.09446914647595854
Trained batch 635 in epoch 4, gen_loss = 0.8096351524194082, disc_loss = 0.09436360127936885
Trained batch 636 in epoch 4, gen_loss = 0.8097211454689409, disc_loss = 0.09424532424026934
Trained batch 637 in epoch 4, gen_loss = 0.809750940825872, disc_loss = 0.09416649218934783
Trained batch 638 in epoch 4, gen_loss = 0.8095132040678988, disc_loss = 0.0940857741833083
Trained batch 639 in epoch 4, gen_loss = 0.8094002819620073, disc_loss = 0.09403871890244772
Trained batch 640 in epoch 4, gen_loss = 0.8096512459369606, disc_loss = 0.09393684286624193
Trained batch 641 in epoch 4, gen_loss = 0.8100925836236306, disc_loss = 0.09394025261371725
Trained batch 642 in epoch 4, gen_loss = 0.8099859674833425, disc_loss = 0.09399667365583671
Trained batch 643 in epoch 4, gen_loss = 0.8100954795846288, disc_loss = 0.09388975271671686
Trained batch 644 in epoch 4, gen_loss = 0.8108108193375344, disc_loss = 0.09378576624214419
Trained batch 645 in epoch 4, gen_loss = 0.8111572894887659, disc_loss = 0.09367529490974158
Trained batch 646 in epoch 4, gen_loss = 0.8113735448079648, disc_loss = 0.09355945287090964
Trained batch 647 in epoch 4, gen_loss = 0.8111833393757726, disc_loss = 0.09351583896348552
Trained batch 648 in epoch 4, gen_loss = 0.8115450495564148, disc_loss = 0.0933927930532761
Trained batch 649 in epoch 4, gen_loss = 0.8122330921429854, disc_loss = 0.09334520503735314
Trained batch 650 in epoch 4, gen_loss = 0.8122252752337771, disc_loss = 0.09327775672415754
Trained batch 651 in epoch 4, gen_loss = 0.8124703671668936, disc_loss = 0.09314972673188553
Trained batch 652 in epoch 4, gen_loss = 0.8125335837943995, disc_loss = 0.09309512197224004
Trained batch 653 in epoch 4, gen_loss = 0.8127086489754715, disc_loss = 0.09298250765684958
Trained batch 654 in epoch 4, gen_loss = 0.8127837904536998, disc_loss = 0.09286881308888889
Trained batch 655 in epoch 4, gen_loss = 0.8130063012969203, disc_loss = 0.09303746521387748
Trained batch 656 in epoch 4, gen_loss = 0.8132066847345419, disc_loss = 0.09298117062618426
Trained batch 657 in epoch 4, gen_loss = 0.8127392282239572, disc_loss = 0.09327283289459022
Trained batch 658 in epoch 4, gen_loss = 0.8130215908399301, disc_loss = 0.09315498534742635
Trained batch 659 in epoch 4, gen_loss = 0.8136583233421499, disc_loss = 0.09321093132267848
Trained batch 660 in epoch 4, gen_loss = 0.8136316022966705, disc_loss = 0.09330993279555472
Trained batch 661 in epoch 4, gen_loss = 0.8135542649877036, disc_loss = 0.09322597130041378
Trained batch 662 in epoch 4, gen_loss = 0.813799467022063, disc_loss = 0.09321072296173415
Trained batch 663 in epoch 4, gen_loss = 0.8138216803949999, disc_loss = 0.09327195381397853
Trained batch 664 in epoch 4, gen_loss = 0.813422970126446, disc_loss = 0.09346381496161894
Trained batch 665 in epoch 4, gen_loss = 0.8127358132028006, disc_loss = 0.0936844785510375
Trained batch 666 in epoch 4, gen_loss = 0.8132217495605863, disc_loss = 0.09371992537676395
Trained batch 667 in epoch 4, gen_loss = 0.8131393532820804, disc_loss = 0.093668790743268
Trained batch 668 in epoch 4, gen_loss = 0.8132857928450689, disc_loss = 0.09358721789702083
Trained batch 669 in epoch 4, gen_loss = 0.8133767485173781, disc_loss = 0.09349841200538091
Trained batch 670 in epoch 4, gen_loss = 0.8131558207126026, disc_loss = 0.09345452971312311
Trained batch 671 in epoch 4, gen_loss = 0.8131799885470953, disc_loss = 0.09340774722208846
Trained batch 672 in epoch 4, gen_loss = 0.8130130005715329, disc_loss = 0.09341434002708628
Trained batch 673 in epoch 4, gen_loss = 0.8132959349130664, disc_loss = 0.09346438963961089
Trained batch 674 in epoch 4, gen_loss = 0.8131165588785101, disc_loss = 0.09346469070900369
Trained batch 675 in epoch 4, gen_loss = 0.8135584088031357, disc_loss = 0.09337507772738853
Trained batch 676 in epoch 4, gen_loss = 0.8131578338815332, disc_loss = 0.09335232838889257
Trained batch 677 in epoch 4, gen_loss = 0.81267221711554, disc_loss = 0.09336249667953338
Trained batch 678 in epoch 4, gen_loss = 0.8131130736688802, disc_loss = 0.09337547328460287
Trained batch 679 in epoch 4, gen_loss = 0.8133170937352321, disc_loss = 0.09340964221833821
Trained batch 680 in epoch 4, gen_loss = 0.8134422237039838, disc_loss = 0.09330928866941586
Trained batch 681 in epoch 4, gen_loss = 0.8133082010966243, disc_loss = 0.09331268499007235
Trained batch 682 in epoch 4, gen_loss = 0.8129307319182428, disc_loss = 0.09340129492430788
Trained batch 683 in epoch 4, gen_loss = 0.8130125828218042, disc_loss = 0.09335321258503007
Trained batch 684 in epoch 4, gen_loss = 0.8127258982536566, disc_loss = 0.09328947574933515
Trained batch 685 in epoch 4, gen_loss = 0.8130233721813029, disc_loss = 0.09317206649745084
Trained batch 686 in epoch 4, gen_loss = 0.8128096065233195, disc_loss = 0.09311659964617597
Trained batch 687 in epoch 4, gen_loss = 0.8130112857406222, disc_loss = 0.09301914481262048
Trained batch 688 in epoch 4, gen_loss = 0.8129239741101839, disc_loss = 0.09293034681117673
Trained batch 689 in epoch 4, gen_loss = 0.8134995954192203, disc_loss = 0.09283787940993257
Trained batch 690 in epoch 4, gen_loss = 0.8134712754990016, disc_loss = 0.09272524421460462
Trained batch 691 in epoch 4, gen_loss = 0.8137565013559568, disc_loss = 0.09280230171946173
Trained batch 692 in epoch 4, gen_loss = 0.8133998573858501, disc_loss = 0.09283748844539018
Trained batch 693 in epoch 4, gen_loss = 0.8133777604580613, disc_loss = 0.09275892939719155
Trained batch 694 in epoch 4, gen_loss = 0.8133805147606692, disc_loss = 0.09267401193275297
Trained batch 695 in epoch 4, gen_loss = 0.8136149861946188, disc_loss = 0.0925558943946407
Trained batch 696 in epoch 4, gen_loss = 0.8134388119367137, disc_loss = 0.09249326325498702
Trained batch 697 in epoch 4, gen_loss = 0.8138303172195538, disc_loss = 0.0925235600306794
Trained batch 698 in epoch 4, gen_loss = 0.8135191827628746, disc_loss = 0.09254539511346382
Trained batch 699 in epoch 4, gen_loss = 0.8131229451298714, disc_loss = 0.09269225628913513
Trained batch 700 in epoch 4, gen_loss = 0.813294508700364, disc_loss = 0.09271215596043647
Trained batch 701 in epoch 4, gen_loss = 0.813004466500717, disc_loss = 0.09282346267884656
Trained batch 702 in epoch 4, gen_loss = 0.8132166494092087, disc_loss = 0.09273862946979902
Trained batch 703 in epoch 4, gen_loss = 0.8129879931749945, disc_loss = 0.09264812716256446
Trained batch 704 in epoch 4, gen_loss = 0.8128865250881682, disc_loss = 0.09270406655359564
Trained batch 705 in epoch 4, gen_loss = 0.812989951066525, disc_loss = 0.09264129450249224
Trained batch 706 in epoch 4, gen_loss = 0.8126688681785255, disc_loss = 0.0927244039895237
Trained batch 707 in epoch 4, gen_loss = 0.8125703880763323, disc_loss = 0.09273465373816421
Trained batch 708 in epoch 4, gen_loss = 0.8129945787035023, disc_loss = 0.09267053712022784
Trained batch 709 in epoch 4, gen_loss = 0.8128563258429649, disc_loss = 0.09262378884112121
Trained batch 710 in epoch 4, gen_loss = 0.8126562004267079, disc_loss = 0.09280645512908949
Trained batch 711 in epoch 4, gen_loss = 0.8126582889660691, disc_loss = 0.0927917339585282
Trained batch 712 in epoch 4, gen_loss = 0.8121447976140455, disc_loss = 0.09302010025494689
Trained batch 713 in epoch 4, gen_loss = 0.8121237381666648, disc_loss = 0.09300373841979716
Trained batch 714 in epoch 4, gen_loss = 0.8124829401503076, disc_loss = 0.09296668488532304
Trained batch 715 in epoch 4, gen_loss = 0.812531729067504, disc_loss = 0.09287941091506632
Trained batch 716 in epoch 4, gen_loss = 0.8122751397734074, disc_loss = 0.09289642013843215
Trained batch 717 in epoch 4, gen_loss = 0.8122540264906657, disc_loss = 0.09289342993974146
Trained batch 718 in epoch 4, gen_loss = 0.8122750902872258, disc_loss = 0.09284870903576324
Trained batch 719 in epoch 4, gen_loss = 0.8121289557052983, disc_loss = 0.09279595503143759
Trained batch 720 in epoch 4, gen_loss = 0.8119954516421409, disc_loss = 0.09272080203505355
Trained batch 721 in epoch 4, gen_loss = 0.8120688837320851, disc_loss = 0.09265108295997548
Trained batch 722 in epoch 4, gen_loss = 0.812099082835977, disc_loss = 0.09255842340628347
Trained batch 723 in epoch 4, gen_loss = 0.8120800159583434, disc_loss = 0.0925423801935777
Trained batch 724 in epoch 4, gen_loss = 0.8125075848349209, disc_loss = 0.09259082230642952
Trained batch 725 in epoch 4, gen_loss = 0.812454485203609, disc_loss = 0.09259754778129708
Trained batch 726 in epoch 4, gen_loss = 0.8124497577937466, disc_loss = 0.09250630697227778
Trained batch 727 in epoch 4, gen_loss = 0.8122492316332492, disc_loss = 0.09246245718555995
Trained batch 728 in epoch 4, gen_loss = 0.8124603700245359, disc_loss = 0.09239437937639419
Trained batch 729 in epoch 4, gen_loss = 0.812196781047403, disc_loss = 0.09236914939693597
Trained batch 730 in epoch 4, gen_loss = 0.8124233132021861, disc_loss = 0.09234415558988557
Trained batch 731 in epoch 4, gen_loss = 0.8120997349421183, disc_loss = 0.09239278338427141
Trained batch 732 in epoch 4, gen_loss = 0.8119369907886562, disc_loss = 0.09247257839634222
Trained batch 733 in epoch 4, gen_loss = 0.8123060227739713, disc_loss = 0.09252623681420567
Trained batch 734 in epoch 4, gen_loss = 0.812505055122635, disc_loss = 0.09246444343430858
Trained batch 735 in epoch 4, gen_loss = 0.8123889939616555, disc_loss = 0.09243965768584293
Trained batch 736 in epoch 4, gen_loss = 0.812329784015464, disc_loss = 0.09239188185040025
Trained batch 737 in epoch 4, gen_loss = 0.8125560203703438, disc_loss = 0.09230145389153584
Trained batch 738 in epoch 4, gen_loss = 0.812838465418964, disc_loss = 0.09220606129848384
Trained batch 739 in epoch 4, gen_loss = 0.8132159965263831, disc_loss = 0.0921886630645777
Trained batch 740 in epoch 4, gen_loss = 0.8129963516867273, disc_loss = 0.09212187087784211
Trained batch 741 in epoch 4, gen_loss = 0.8125016328620139, disc_loss = 0.09239931282464345
Trained batch 742 in epoch 4, gen_loss = 0.8125308435184638, disc_loss = 0.09238678242379492
Trained batch 743 in epoch 4, gen_loss = 0.8125989634984283, disc_loss = 0.09229532314679756
Trained batch 744 in epoch 4, gen_loss = 0.8127261621039986, disc_loss = 0.09232781445295019
Trained batch 745 in epoch 4, gen_loss = 0.812722617275913, disc_loss = 0.09223685956537604
Trained batch 746 in epoch 4, gen_loss = 0.8125891524305944, disc_loss = 0.09222896832603728
Trained batch 747 in epoch 4, gen_loss = 0.8129181990967714, disc_loss = 0.09243711614657572
Trained batch 748 in epoch 4, gen_loss = 0.8127708696077599, disc_loss = 0.0924062413711832
Trained batch 749 in epoch 4, gen_loss = 0.8126074693202973, disc_loss = 0.09246333121880888
Trained batch 750 in epoch 4, gen_loss = 0.812765681711875, disc_loss = 0.09240785269525532
Trained batch 751 in epoch 4, gen_loss = 0.8128669307111426, disc_loss = 0.09233355613925712
Trained batch 752 in epoch 4, gen_loss = 0.8130588685848799, disc_loss = 0.09225471148695327
Trained batch 753 in epoch 4, gen_loss = 0.8128388678205425, disc_loss = 0.0922339844680453
Trained batch 754 in epoch 4, gen_loss = 0.8128116302142869, disc_loss = 0.09231439979981311
Trained batch 755 in epoch 4, gen_loss = 0.8124497601437191, disc_loss = 0.09234451063139926
Trained batch 756 in epoch 4, gen_loss = 0.8128066455829727, disc_loss = 0.09232176374890097
Trained batch 757 in epoch 4, gen_loss = 0.8124626805725702, disc_loss = 0.09242715898011676
Trained batch 758 in epoch 4, gen_loss = 0.8120575169486648, disc_loss = 0.09248302455952241
Trained batch 759 in epoch 4, gen_loss = 0.812229107477163, disc_loss = 0.09241582321517758
Trained batch 760 in epoch 4, gen_loss = 0.8119479929257316, disc_loss = 0.09235417880680848
Trained batch 761 in epoch 4, gen_loss = 0.811940922981172, disc_loss = 0.09226764900013414
Trained batch 762 in epoch 4, gen_loss = 0.8118595330149599, disc_loss = 0.09231973849700796
Trained batch 763 in epoch 4, gen_loss = 0.8119080472366972, disc_loss = 0.09223238792860422
Trained batch 764 in epoch 4, gen_loss = 0.8123268202239392, disc_loss = 0.09227193727042356
Trained batch 765 in epoch 4, gen_loss = 0.8120351499894891, disc_loss = 0.0923594700782888
Trained batch 766 in epoch 4, gen_loss = 0.812077554217218, disc_loss = 0.09240650966146662
Trained batch 767 in epoch 4, gen_loss = 0.811893249473845, disc_loss = 0.0925276816378755
Trained batch 768 in epoch 4, gen_loss = 0.8124357596020395, disc_loss = 0.09265487830630553
Trained batch 769 in epoch 4, gen_loss = 0.8122567950131057, disc_loss = 0.09260791866350677
Trained batch 770 in epoch 4, gen_loss = 0.8122941826877272, disc_loss = 0.09257947634325765
Trained batch 771 in epoch 4, gen_loss = 0.8121207337923001, disc_loss = 0.09258768366953754
Trained batch 772 in epoch 4, gen_loss = 0.8120376590306824, disc_loss = 0.09253153023352174
Trained batch 773 in epoch 4, gen_loss = 0.812581496799331, disc_loss = 0.09250428059405481
Trained batch 774 in epoch 4, gen_loss = 0.8131097728975357, disc_loss = 0.09244433858341748
Trained batch 775 in epoch 4, gen_loss = 0.8127320937274658, disc_loss = 0.0927372762762951
Trained batch 776 in epoch 4, gen_loss = 0.8123880132284864, disc_loss = 0.09277189092080143
Trained batch 777 in epoch 4, gen_loss = 0.8129742612875519, disc_loss = 0.0929743056472841
Trained batch 778 in epoch 4, gen_loss = 0.8132571012585093, disc_loss = 0.09289906636019152
Trained batch 779 in epoch 4, gen_loss = 0.8128925784276082, disc_loss = 0.0929351898160978
Trained batch 780 in epoch 4, gen_loss = 0.8127292124471042, disc_loss = 0.09298001285213095
Trained batch 781 in epoch 4, gen_loss = 0.8127358420120786, disc_loss = 0.09291876724008899
Trained batch 782 in epoch 4, gen_loss = 0.8128438478533183, disc_loss = 0.09289815397826078
Trained batch 783 in epoch 4, gen_loss = 0.8130915129975397, disc_loss = 0.0929162595242889
Trained batch 784 in epoch 4, gen_loss = 0.8129902573907452, disc_loss = 0.09286699022765563
Trained batch 785 in epoch 4, gen_loss = 0.8127205070800151, disc_loss = 0.09286508736800185
Trained batch 786 in epoch 4, gen_loss = 0.8130871706572391, disc_loss = 0.09277311027206225
Trained batch 787 in epoch 4, gen_loss = 0.8133210828007781, disc_loss = 0.09267461707527148
Trained batch 788 in epoch 4, gen_loss = 0.8132084898924495, disc_loss = 0.0925836010159705
Trained batch 789 in epoch 4, gen_loss = 0.8138380618789528, disc_loss = 0.09254373268495443
Trained batch 790 in epoch 4, gen_loss = 0.8139879674887386, disc_loss = 0.09245583030375194
Trained batch 791 in epoch 4, gen_loss = 0.8140820970739981, disc_loss = 0.09240359185155331
Trained batch 792 in epoch 4, gen_loss = 0.8140033218178142, disc_loss = 0.09241613764127934
Trained batch 793 in epoch 4, gen_loss = 0.8138770476846912, disc_loss = 0.09235549427836345
Trained batch 794 in epoch 4, gen_loss = 0.8140611107244432, disc_loss = 0.09237574572856509
Trained batch 795 in epoch 4, gen_loss = 0.8140687064908857, disc_loss = 0.09227923451145952
Trained batch 796 in epoch 4, gen_loss = 0.8139339321978867, disc_loss = 0.0923358996713083
Trained batch 797 in epoch 4, gen_loss = 0.8137678350870472, disc_loss = 0.0923925813854693
Trained batch 798 in epoch 4, gen_loss = 0.8136484232802266, disc_loss = 0.09233624024552121
Trained batch 799 in epoch 4, gen_loss = 0.8138329123705625, disc_loss = 0.0922362460102886
Trained batch 800 in epoch 4, gen_loss = 0.8138900862799751, disc_loss = 0.09218234401405527
Trained batch 801 in epoch 4, gen_loss = 0.8140166730357524, disc_loss = 0.09211971127239992
Trained batch 802 in epoch 4, gen_loss = 0.813603339723751, disc_loss = 0.09232920743664205
Trained batch 803 in epoch 4, gen_loss = 0.8138776771464751, disc_loss = 0.09234165918749215
Trained batch 804 in epoch 4, gen_loss = 0.8139292468195376, disc_loss = 0.09224898502554582
Trained batch 805 in epoch 4, gen_loss = 0.8138346047910212, disc_loss = 0.0922139134955946
Trained batch 806 in epoch 4, gen_loss = 0.8136852446394192, disc_loss = 0.09216590162223526
Trained batch 807 in epoch 4, gen_loss = 0.8135530236038832, disc_loss = 0.0923714329520849
Trained batch 808 in epoch 4, gen_loss = 0.8134014708886778, disc_loss = 0.09245975721945206
Trained batch 809 in epoch 4, gen_loss = 0.8131954424911075, disc_loss = 0.09244697649767737
Trained batch 810 in epoch 4, gen_loss = 0.8129236906142182, disc_loss = 0.09243614452807221
Trained batch 811 in epoch 4, gen_loss = 0.8131950204742366, disc_loss = 0.09258282884927879
Trained batch 812 in epoch 4, gen_loss = 0.8132934743334593, disc_loss = 0.09254646115463232
Trained batch 813 in epoch 4, gen_loss = 0.8131513416913569, disc_loss = 0.09250556081487667
Trained batch 814 in epoch 4, gen_loss = 0.8126605315442466, disc_loss = 0.09262968613280474
Trained batch 815 in epoch 4, gen_loss = 0.8126283336211654, disc_loss = 0.09255124905429707
Trained batch 816 in epoch 4, gen_loss = 0.8127688359893229, disc_loss = 0.09253395363606394
Trained batch 817 in epoch 4, gen_loss = 0.8127196786018922, disc_loss = 0.09247201883568813
Trained batch 818 in epoch 4, gen_loss = 0.8128011514124561, disc_loss = 0.09238832121912813
Trained batch 819 in epoch 4, gen_loss = 0.8128053830164235, disc_loss = 0.09230779781710448
Trained batch 820 in epoch 4, gen_loss = 0.8129370587897213, disc_loss = 0.09225024229616617
Trained batch 821 in epoch 4, gen_loss = 0.8125647051926077, disc_loss = 0.0922140005065033
Trained batch 822 in epoch 4, gen_loss = 0.8128078798622002, disc_loss = 0.09221801528636986
Trained batch 823 in epoch 4, gen_loss = 0.8127253857052442, disc_loss = 0.09213002685240461
Trained batch 824 in epoch 4, gen_loss = 0.8124896653493245, disc_loss = 0.09213595257564025
Trained batch 825 in epoch 4, gen_loss = 0.8126030979953147, disc_loss = 0.09203643170264313
Trained batch 826 in epoch 4, gen_loss = 0.8125164601073444, disc_loss = 0.09198448642809057
Trained batch 827 in epoch 4, gen_loss = 0.8124164771918513, disc_loss = 0.09192644239848723
Trained batch 828 in epoch 4, gen_loss = 0.8125858247927216, disc_loss = 0.09185116774255389
Trained batch 829 in epoch 4, gen_loss = 0.812787998009877, disc_loss = 0.09211035287568727
Trained batch 830 in epoch 4, gen_loss = 0.8128863346418893, disc_loss = 0.09202558975151227
Trained batch 831 in epoch 4, gen_loss = 0.8126989987750466, disc_loss = 0.09205426268789989
Trained batch 832 in epoch 4, gen_loss = 0.8126948726277391, disc_loss = 0.09205311773141392
Trained batch 833 in epoch 4, gen_loss = 0.8122050444856822, disc_loss = 0.09225286990270126
Trained batch 834 in epoch 4, gen_loss = 0.8127602795640866, disc_loss = 0.09271833175893672
Trained batch 835 in epoch 4, gen_loss = 0.812725640940324, disc_loss = 0.09265444529995892
Trained batch 836 in epoch 4, gen_loss = 0.8126421172701472, disc_loss = 0.0926594153878901
Trained batch 837 in epoch 4, gen_loss = 0.8126566060829845, disc_loss = 0.09259010956962738
Trained batch 838 in epoch 4, gen_loss = 0.8130408188015116, disc_loss = 0.09269239749710594
Trained batch 839 in epoch 4, gen_loss = 0.8128576966268676, disc_loss = 0.09272355918683821
Trained batch 840 in epoch 4, gen_loss = 0.8127926819814938, disc_loss = 0.09285345853181216
Trained batch 841 in epoch 4, gen_loss = 0.8130790402232326, disc_loss = 0.09292968488884581
Trained batch 842 in epoch 4, gen_loss = 0.8129603039044644, disc_loss = 0.09298287286762312
Trained batch 843 in epoch 4, gen_loss = 0.8131696205427297, disc_loss = 0.09294153407207244
Trained batch 844 in epoch 4, gen_loss = 0.8129680900884098, disc_loss = 0.09297922329216667
Trained batch 845 in epoch 4, gen_loss = 0.8130691387551896, disc_loss = 0.09290714549389503
Trained batch 846 in epoch 4, gen_loss = 0.8133013485595496, disc_loss = 0.09288869105684082
Trained batch 847 in epoch 4, gen_loss = 0.8135088857193038, disc_loss = 0.09283631218307353
Trained batch 848 in epoch 4, gen_loss = 0.8134990279750353, disc_loss = 0.09284348001109065
Trained batch 849 in epoch 4, gen_loss = 0.8131630513948552, disc_loss = 0.09299322774962468
Trained batch 850 in epoch 4, gen_loss = 0.813123737533, disc_loss = 0.09293883083526101
Trained batch 851 in epoch 4, gen_loss = 0.8133751543614786, disc_loss = 0.09288196515580507
Trained batch 852 in epoch 4, gen_loss = 0.8133736327552572, disc_loss = 0.09283926482732732
Trained batch 853 in epoch 4, gen_loss = 0.8135820081418236, disc_loss = 0.09275865999532458
Trained batch 854 in epoch 4, gen_loss = 0.8139350808851901, disc_loss = 0.09266379527442636
Trained batch 855 in epoch 4, gen_loss = 0.8136337522730649, disc_loss = 0.09269807196579108
Trained batch 856 in epoch 4, gen_loss = 0.8136759276568124, disc_loss = 0.09262976900195158
Trained batch 857 in epoch 4, gen_loss = 0.8139059581817725, disc_loss = 0.09259717128649875
Trained batch 858 in epoch 4, gen_loss = 0.813706837655224, disc_loss = 0.09265077690462711
Trained batch 859 in epoch 4, gen_loss = 0.8140037472857985, disc_loss = 0.09273138516257669
Trained batch 860 in epoch 4, gen_loss = 0.8138046802544012, disc_loss = 0.09272915433387031
Trained batch 861 in epoch 4, gen_loss = 0.8137534883072094, disc_loss = 0.09269908992379143
Trained batch 862 in epoch 4, gen_loss = 0.8140597361402191, disc_loss = 0.09262710713445794
Trained batch 863 in epoch 4, gen_loss = 0.8142537997552642, disc_loss = 0.09274335813070475
Trained batch 864 in epoch 4, gen_loss = 0.8138866129638143, disc_loss = 0.09281393222812283
Trained batch 865 in epoch 4, gen_loss = 0.8136410892835666, disc_loss = 0.09283533309076593
Trained batch 866 in epoch 4, gen_loss = 0.8135297115561322, disc_loss = 0.09297191232631913
Trained batch 867 in epoch 4, gen_loss = 0.8131813292267136, disc_loss = 0.09308400288790739
Trained batch 868 in epoch 4, gen_loss = 0.8132075941055087, disc_loss = 0.0930061977961121
Trained batch 869 in epoch 4, gen_loss = 0.8133028803200557, disc_loss = 0.0932763265552877
Trained batch 870 in epoch 4, gen_loss = 0.8131331383292355, disc_loss = 0.09327311630774585
Trained batch 871 in epoch 4, gen_loss = 0.8130363618972105, disc_loss = 0.09325908015080549
Trained batch 872 in epoch 4, gen_loss = 0.8130850881372257, disc_loss = 0.09318505732165511
Trained batch 873 in epoch 4, gen_loss = 0.8134747486501864, disc_loss = 0.09313371094493558
Trained batch 874 in epoch 4, gen_loss = 0.81384881571361, disc_loss = 0.09313531668484211
Trained batch 875 in epoch 4, gen_loss = 0.8135919107557976, disc_loss = 0.09325511378265883
Trained batch 876 in epoch 4, gen_loss = 0.8133845658231624, disc_loss = 0.0932491513514974
Trained batch 877 in epoch 4, gen_loss = 0.8134144187516666, disc_loss = 0.0932798196618914
Trained batch 878 in epoch 4, gen_loss = 0.8133735141385267, disc_loss = 0.09324363390443607
Trained batch 879 in epoch 4, gen_loss = 0.813277254998684, disc_loss = 0.09319784888701343
Trained batch 880 in epoch 4, gen_loss = 0.8131021373523621, disc_loss = 0.09332032403808244
Trained batch 881 in epoch 4, gen_loss = 0.8129354757922036, disc_loss = 0.09327354988552072
Trained batch 882 in epoch 4, gen_loss = 0.8130480830693704, disc_loss = 0.09322839731293586
Trained batch 883 in epoch 4, gen_loss = 0.8128883994407783, disc_loss = 0.09318026688952859
Trained batch 884 in epoch 4, gen_loss = 0.8126039469982944, disc_loss = 0.09319252089970866
Trained batch 885 in epoch 4, gen_loss = 0.8126466749214964, disc_loss = 0.09324133659567911
Trained batch 886 in epoch 4, gen_loss = 0.8128667840022246, disc_loss = 0.09319207864564664
Trained batch 887 in epoch 4, gen_loss = 0.8129550485057874, disc_loss = 0.0931023755530315
Trained batch 888 in epoch 4, gen_loss = 0.8127242541956821, disc_loss = 0.09321958150534447
Trained batch 889 in epoch 4, gen_loss = 0.8129686796933078, disc_loss = 0.09320531584155024
Trained batch 890 in epoch 4, gen_loss = 0.812963980750738, disc_loss = 0.09315429792209506
Trained batch 891 in epoch 4, gen_loss = 0.8131554819008695, disc_loss = 0.09310675652555687
Trained batch 892 in epoch 4, gen_loss = 0.8134814157731589, disc_loss = 0.09304699312983142
Trained batch 893 in epoch 4, gen_loss = 0.8135708873170601, disc_loss = 0.09297951844247929
Trained batch 894 in epoch 4, gen_loss = 0.8132453143263663, disc_loss = 0.09318434421243614
Trained batch 895 in epoch 4, gen_loss = 0.8131642095478517, disc_loss = 0.09314678752811492
Trained batch 896 in epoch 4, gen_loss = 0.8131292144058806, disc_loss = 0.09307496123215227
Trained batch 897 in epoch 4, gen_loss = 0.813120488201855, disc_loss = 0.09305100847151802
Trained batch 898 in epoch 4, gen_loss = 0.8134997340542853, disc_loss = 0.09311617024706985
Trained batch 899 in epoch 4, gen_loss = 0.8132255105839835, disc_loss = 0.09312624694365594
Trained batch 900 in epoch 4, gen_loss = 0.8133208440755236, disc_loss = 0.09305888142945301
Trained batch 901 in epoch 4, gen_loss = 0.8130394178060629, disc_loss = 0.09306971236295222
Trained batch 902 in epoch 4, gen_loss = 0.8129855132974263, disc_loss = 0.09299744154271955
Trained batch 903 in epoch 4, gen_loss = 0.812993924636229, disc_loss = 0.09304431298607549
Trained batch 904 in epoch 4, gen_loss = 0.8126541831875375, disc_loss = 0.09315605936005958
Trained batch 905 in epoch 4, gen_loss = 0.8129534864794077, disc_loss = 0.09321595462158355
Trained batch 906 in epoch 4, gen_loss = 0.8127688926530646, disc_loss = 0.09325444961404131
Trained batch 907 in epoch 4, gen_loss = 0.8126669813620362, disc_loss = 0.09319453980847536
Trained batch 908 in epoch 4, gen_loss = 0.8126428161386084, disc_loss = 0.09313719486664034
Trained batch 909 in epoch 4, gen_loss = 0.812857750090924, disc_loss = 0.09324469977969324
Trained batch 910 in epoch 4, gen_loss = 0.8126709172021676, disc_loss = 0.09323986956459172
Trained batch 911 in epoch 4, gen_loss = 0.8130067426123118, disc_loss = 0.09343157728864371
Trained batch 912 in epoch 4, gen_loss = 0.8125803933477872, disc_loss = 0.09354218124714961
Trained batch 913 in epoch 4, gen_loss = 0.8123952838341569, disc_loss = 0.09354834236343201
Trained batch 914 in epoch 4, gen_loss = 0.8125701883451535, disc_loss = 0.09372960424121937
Trained batch 915 in epoch 4, gen_loss = 0.8123390342731143, disc_loss = 0.09380246938600746
Trained batch 916 in epoch 4, gen_loss = 0.8123003560298142, disc_loss = 0.09378044486590209
Trained batch 917 in epoch 4, gen_loss = 0.8123390025302994, disc_loss = 0.09375952736703853
Trained batch 918 in epoch 4, gen_loss = 0.812532173666264, disc_loss = 0.09382023230819306
Trained batch 919 in epoch 4, gen_loss = 0.8125851717980012, disc_loss = 0.0938056332970281
Trained batch 920 in epoch 4, gen_loss = 0.8123834423728926, disc_loss = 0.09392046374061533
Trained batch 921 in epoch 4, gen_loss = 0.8124121631174439, disc_loss = 0.09389638974090912
Trained batch 922 in epoch 4, gen_loss = 0.8127938925509592, disc_loss = 0.09402373102760973
Trained batch 923 in epoch 4, gen_loss = 0.8130035625520723, disc_loss = 0.09393660971104648
Trained batch 924 in epoch 4, gen_loss = 0.8129733675879401, disc_loss = 0.09388644488075296
Trained batch 925 in epoch 4, gen_loss = 0.8129009080499604, disc_loss = 0.09385049153425074
Trained batch 926 in epoch 4, gen_loss = 0.8127724131591368, disc_loss = 0.09380806774552007
Trained batch 927 in epoch 4, gen_loss = 0.8127574445358638, disc_loss = 0.09397485906234139
Trained batch 928 in epoch 4, gen_loss = 0.8125430829943318, disc_loss = 0.09398835349078134
Trained batch 929 in epoch 4, gen_loss = 0.8125171262089924, disc_loss = 0.09392879545408231
Trained batch 930 in epoch 4, gen_loss = 0.8123075886520484, disc_loss = 0.09388647483967877
Trained batch 931 in epoch 4, gen_loss = 0.8125002156511397, disc_loss = 0.09381360086000848
Trained batch 932 in epoch 4, gen_loss = 0.8124388459538852, disc_loss = 0.09383691128019926
Trained batch 933 in epoch 4, gen_loss = 0.812356970741611, disc_loss = 0.09380330122823825
Trained batch 934 in epoch 4, gen_loss = 0.8122430402964832, disc_loss = 0.09374348053280364
Trained batch 935 in epoch 4, gen_loss = 0.8124903374884882, disc_loss = 0.0936631883880617
Trained batch 936 in epoch 4, gen_loss = 0.8123960615222202, disc_loss = 0.09364840053339969
Trained batch 937 in epoch 4, gen_loss = 0.8125239746021563, disc_loss = 0.09363415828351972
Trained batch 938 in epoch 4, gen_loss = 0.8123157117694331, disc_loss = 0.09369050536633998
Trained batch 939 in epoch 4, gen_loss = 0.8125233686350761, disc_loss = 0.09367371118885089
Trained batch 940 in epoch 4, gen_loss = 0.8126369208635863, disc_loss = 0.09359868158814948
Trained batch 941 in epoch 4, gen_loss = 0.8125644474905261, disc_loss = 0.09353923027832733
Trained batch 942 in epoch 4, gen_loss = 0.8126790660689264, disc_loss = 0.093552955678118
Trained batch 943 in epoch 4, gen_loss = 0.8124754704156164, disc_loss = 0.09352537672137999
Trained batch 944 in epoch 4, gen_loss = 0.8124895757468289, disc_loss = 0.09349036782230966
Trained batch 945 in epoch 4, gen_loss = 0.8125195844102864, disc_loss = 0.09344543817297538
Trained batch 946 in epoch 4, gen_loss = 0.8124216028352473, disc_loss = 0.09339708068782765
Trained batch 947 in epoch 4, gen_loss = 0.8125645036687328, disc_loss = 0.09333787733327424
Trained batch 948 in epoch 4, gen_loss = 0.8125953763503546, disc_loss = 0.0932990484414632
Trained batch 949 in epoch 4, gen_loss = 0.8123952970379277, disc_loss = 0.0932813515925878
Trained batch 950 in epoch 4, gen_loss = 0.8122391826096143, disc_loss = 0.09328401383094795
Trained batch 951 in epoch 4, gen_loss = 0.8120151366881964, disc_loss = 0.09329945154041991
Trained batch 952 in epoch 4, gen_loss = 0.8121291719228498, disc_loss = 0.0932293731879525
Trained batch 953 in epoch 4, gen_loss = 0.8118403457745567, disc_loss = 0.0932189919624626
Trained batch 954 in epoch 4, gen_loss = 0.8120260085735022, disc_loss = 0.09317286477585114
Trained batch 955 in epoch 4, gen_loss = 0.8121020203479663, disc_loss = 0.09319671395012649
Trained batch 956 in epoch 4, gen_loss = 0.8121041140461666, disc_loss = 0.09317195524102469
Trained batch 957 in epoch 4, gen_loss = 0.811841065301278, disc_loss = 0.09320807624569392
Trained batch 958 in epoch 4, gen_loss = 0.8121408344682489, disc_loss = 0.09315977708996896
Trained batch 959 in epoch 4, gen_loss = 0.8126180353264014, disc_loss = 0.09315123203753804
Trained batch 960 in epoch 4, gen_loss = 0.8123696655438172, disc_loss = 0.09317216769046888
Trained batch 961 in epoch 4, gen_loss = 0.8125313882892197, disc_loss = 0.09311541585782214
Trained batch 962 in epoch 4, gen_loss = 0.8125274575635528, disc_loss = 0.09307989816211341
Trained batch 963 in epoch 4, gen_loss = 0.8122007395469302, disc_loss = 0.09316919407811156
Trained batch 964 in epoch 4, gen_loss = 0.8124374272292142, disc_loss = 0.09315653916622073
Trained batch 965 in epoch 4, gen_loss = 0.8125441195925324, disc_loss = 0.09308634065554379
Trained batch 966 in epoch 4, gen_loss = 0.8128900032995159, disc_loss = 0.09305996985984687
Trained batch 967 in epoch 4, gen_loss = 0.8129528486901079, disc_loss = 0.09299313491941545
Trained batch 968 in epoch 4, gen_loss = 0.8127708217922994, disc_loss = 0.09304345785318206
Trained batch 969 in epoch 4, gen_loss = 0.8126514871710354, disc_loss = 0.09303598420252812
Trained batch 970 in epoch 4, gen_loss = 0.8128067785384849, disc_loss = 0.09296179513123758
Trained batch 971 in epoch 4, gen_loss = 0.8124345711781165, disc_loss = 0.09299659595820946
Trained batch 972 in epoch 4, gen_loss = 0.81267141465783, disc_loss = 0.0929374309603167
Trained batch 973 in epoch 4, gen_loss = 0.8126171576107797, disc_loss = 0.09288988499739638
Trained batch 974 in epoch 4, gen_loss = 0.8124506150453519, disc_loss = 0.09283218789750185
Trained batch 975 in epoch 4, gen_loss = 0.8124232359047308, disc_loss = 0.09281667364860473
Trained batch 976 in epoch 4, gen_loss = 0.8123592507692784, disc_loss = 0.09274346400300153
Trained batch 977 in epoch 4, gen_loss = 0.8126959543225711, disc_loss = 0.09270535547149145
Trained batch 978 in epoch 4, gen_loss = 0.812455097519706, disc_loss = 0.09276283314533387
Trained batch 979 in epoch 4, gen_loss = 0.8123327373545997, disc_loss = 0.09273398973009721
Trained batch 980 in epoch 4, gen_loss = 0.812908279209205, disc_loss = 0.0928233614007237
Trained batch 981 in epoch 4, gen_loss = 0.8130578357126951, disc_loss = 0.09273916456939428
Trained batch 982 in epoch 4, gen_loss = 0.8130770865619364, disc_loss = 0.0926866264026593
Trained batch 983 in epoch 4, gen_loss = 0.8127801815365873, disc_loss = 0.09265375825409906
Trained batch 984 in epoch 4, gen_loss = 0.8127275988232666, disc_loss = 0.09261682355956075
Trained batch 985 in epoch 4, gen_loss = 0.8126950123428573, disc_loss = 0.09254714385483558
Trained batch 986 in epoch 4, gen_loss = 0.812566008339537, disc_loss = 0.09252879887690962
Trained batch 987 in epoch 4, gen_loss = 0.8126261551310177, disc_loss = 0.0925899940158282
Trained batch 988 in epoch 4, gen_loss = 0.8125099525593892, disc_loss = 0.09262020116590935
Trained batch 989 in epoch 4, gen_loss = 0.8123118161252051, disc_loss = 0.0926980496562942
Trained batch 990 in epoch 4, gen_loss = 0.8120462752194506, disc_loss = 0.09276683621604737
Trained batch 991 in epoch 4, gen_loss = 0.8123223949524183, disc_loss = 0.09272024740517561
Trained batch 992 in epoch 4, gen_loss = 0.8121719597749719, disc_loss = 0.09276422969846868
Trained batch 993 in epoch 4, gen_loss = 0.8122691489021543, disc_loss = 0.09272449841569187
Trained batch 994 in epoch 4, gen_loss = 0.8123677527784702, disc_loss = 0.09267133491759624
Trained batch 995 in epoch 4, gen_loss = 0.8125556654420244, disc_loss = 0.09285868874313422
Trained batch 996 in epoch 4, gen_loss = 0.8122796970779224, disc_loss = 0.09301915444403797
Trained batch 997 in epoch 4, gen_loss = 0.8122008847509453, disc_loss = 0.09297149885774315
Trained batch 998 in epoch 4, gen_loss = 0.8120250361519413, disc_loss = 0.09299304034072417
Trained batch 999 in epoch 4, gen_loss = 0.8123945520818233, disc_loss = 0.09304600308649241
Trained batch 1000 in epoch 4, gen_loss = 0.8123513057336702, disc_loss = 0.09305815605426228
Trained batch 1001 in epoch 4, gen_loss = 0.8123191528156132, disc_loss = 0.09302407807806236
Trained batch 1002 in epoch 4, gen_loss = 0.8120744364152283, disc_loss = 0.09308190371726054
Trained batch 1003 in epoch 4, gen_loss = 0.8118683687184911, disc_loss = 0.09305944428612214
Trained batch 1004 in epoch 4, gen_loss = 0.8117715817482317, disc_loss = 0.09308672474502627
Trained batch 1005 in epoch 4, gen_loss = 0.8119536359492637, disc_loss = 0.09301664758932815
Trained batch 1006 in epoch 4, gen_loss = 0.8115984376338649, disc_loss = 0.09308454313138805
Trained batch 1007 in epoch 4, gen_loss = 0.8121745439453257, disc_loss = 0.09323372459963024
Trained batch 1008 in epoch 4, gen_loss = 0.8121490863376141, disc_loss = 0.0931719269555494
Trained batch 1009 in epoch 4, gen_loss = 0.812083569818204, disc_loss = 0.09316054239205204
Trained batch 1010 in epoch 4, gen_loss = 0.8117462116580099, disc_loss = 0.09337674677150894
Trained batch 1011 in epoch 4, gen_loss = 0.8120028156890229, disc_loss = 0.09374133514041603
Trained batch 1012 in epoch 4, gen_loss = 0.8118850431108051, disc_loss = 0.09372095949396211
Trained batch 1013 in epoch 4, gen_loss = 0.8118734480243698, disc_loss = 0.09368034497755755
Trained batch 1014 in epoch 4, gen_loss = 0.8118340545687183, disc_loss = 0.0936990895515005
Trained batch 1015 in epoch 4, gen_loss = 0.8118528324201351, disc_loss = 0.09363450622002734
Trained batch 1016 in epoch 4, gen_loss = 0.8118773668916528, disc_loss = 0.0936166314882544
Trained batch 1017 in epoch 4, gen_loss = 0.8115242621285039, disc_loss = 0.09364938384840496
Trained batch 1018 in epoch 4, gen_loss = 0.8118907849617866, disc_loss = 0.09360602405379226
Trained batch 1019 in epoch 4, gen_loss = 0.8117753255016663, disc_loss = 0.0935662733774413
Trained batch 1020 in epoch 4, gen_loss = 0.8119700744850278, disc_loss = 0.09348889163181726
Trained batch 1021 in epoch 4, gen_loss = 0.8119293976203337, disc_loss = 0.09343278151617883
Trained batch 1022 in epoch 4, gen_loss = 0.8118201023439275, disc_loss = 0.0934951636641635
Trained batch 1023 in epoch 4, gen_loss = 0.811328572453931, disc_loss = 0.09364142033336975
Trained batch 1024 in epoch 4, gen_loss = 0.8114316550696768, disc_loss = 0.09361180424145082
Trained batch 1025 in epoch 4, gen_loss = 0.8114544666185249, disc_loss = 0.09356367790102087
Trained batch 1026 in epoch 4, gen_loss = 0.8114535819590382, disc_loss = 0.09355703962036384
Trained batch 1027 in epoch 4, gen_loss = 0.8114958552187055, disc_loss = 0.09352848818888054
Trained batch 1028 in epoch 4, gen_loss = 0.8112865052719042, disc_loss = 0.09358761283099304
Trained batch 1029 in epoch 4, gen_loss = 0.8109916181240266, disc_loss = 0.0936171729895241
Trained batch 1030 in epoch 4, gen_loss = 0.8112089174910729, disc_loss = 0.09375629699260546
Trained batch 1031 in epoch 4, gen_loss = 0.8111740789094637, disc_loss = 0.09370332790444814
Trained batch 1032 in epoch 4, gen_loss = 0.8110818701353563, disc_loss = 0.09371165828986701
Trained batch 1033 in epoch 4, gen_loss = 0.8110588142212402, disc_loss = 0.09383438104075494
Trained batch 1034 in epoch 4, gen_loss = 0.8107563069477174, disc_loss = 0.09392509679467494
Trained batch 1035 in epoch 4, gen_loss = 0.8106716442637462, disc_loss = 0.09391519213167224
Trained batch 1036 in epoch 4, gen_loss = 0.8107809317491323, disc_loss = 0.09398579791640879
Trained batch 1037 in epoch 4, gen_loss = 0.8106768808268399, disc_loss = 0.09403683849734205
Trained batch 1038 in epoch 4, gen_loss = 0.8102092775619294, disc_loss = 0.09416250711176061
Trained batch 1039 in epoch 4, gen_loss = 0.8104135286922638, disc_loss = 0.09426277290062549
Trained batch 1040 in epoch 4, gen_loss = 0.8102938947370715, disc_loss = 0.09426954299333173
Trained batch 1041 in epoch 4, gen_loss = 0.8104545077069478, disc_loss = 0.09419454733042079
Trained batch 1042 in epoch 4, gen_loss = 0.8103078045415284, disc_loss = 0.09418799351875815
Trained batch 1043 in epoch 4, gen_loss = 0.8105748965479862, disc_loss = 0.09423475704152294
Trained batch 1044 in epoch 4, gen_loss = 0.8104442613546928, disc_loss = 0.0942380137153362
Trained batch 1045 in epoch 4, gen_loss = 0.810199684041408, disc_loss = 0.09423797025058568
Trained batch 1046 in epoch 4, gen_loss = 0.8102464293909847, disc_loss = 0.09417179973712396
Trained batch 1047 in epoch 4, gen_loss = 0.8101373189164482, disc_loss = 0.09417154545049744
Trained batch 1048 in epoch 4, gen_loss = 0.8105070174479053, disc_loss = 0.09415987819021264
Trained batch 1049 in epoch 4, gen_loss = 0.8107422183241163, disc_loss = 0.09411067393209253
Trained batch 1050 in epoch 4, gen_loss = 0.810969543672538, disc_loss = 0.09402921387516353
Trained batch 1051 in epoch 4, gen_loss = 0.8109672832171727, disc_loss = 0.09399345027771513
Trained batch 1052 in epoch 4, gen_loss = 0.8106402174020425, disc_loss = 0.09401427841226147
Trained batch 1053 in epoch 4, gen_loss = 0.810691804428933, disc_loss = 0.09399410025472885
Trained batch 1054 in epoch 4, gen_loss = 0.8106123439508591, disc_loss = 0.09394787562684426
Trained batch 1055 in epoch 4, gen_loss = 0.8104768628536752, disc_loss = 0.09393943988040766
Trained batch 1056 in epoch 4, gen_loss = 0.8102144418511621, disc_loss = 0.09403425764535663
Trained batch 1057 in epoch 4, gen_loss = 0.8103147389645388, disc_loss = 0.09398725158438115
Trained batch 1058 in epoch 4, gen_loss = 0.8106291724669696, disc_loss = 0.09397108610842564
Trained batch 1059 in epoch 4, gen_loss = 0.8105377440744976, disc_loss = 0.09391618126757302
Trained batch 1060 in epoch 4, gen_loss = 0.8105373933672568, disc_loss = 0.093851922696121
Trained batch 1061 in epoch 4, gen_loss = 0.81027630094979, disc_loss = 0.09393817230203169
Trained batch 1062 in epoch 4, gen_loss = 0.8104595543075482, disc_loss = 0.0939222579806174
Trained batch 1063 in epoch 4, gen_loss = 0.8101065310936674, disc_loss = 0.09405473913451222
Trained batch 1064 in epoch 4, gen_loss = 0.8100396285874183, disc_loss = 0.09407598159052956
Trained batch 1065 in epoch 4, gen_loss = 0.809888833095835, disc_loss = 0.09403730955107686
Trained batch 1066 in epoch 4, gen_loss = 0.8097256806652012, disc_loss = 0.09404511697723023
Trained batch 1067 in epoch 4, gen_loss = 0.8100153253821845, disc_loss = 0.09411277201668489
Trained batch 1068 in epoch 4, gen_loss = 0.8099318496025646, disc_loss = 0.09413261935672435
Trained batch 1069 in epoch 4, gen_loss = 0.8097472968224053, disc_loss = 0.09424379812988723
Trained batch 1070 in epoch 4, gen_loss = 0.8095714970518784, disc_loss = 0.09426133643164465
Trained batch 1071 in epoch 4, gen_loss = 0.8093528045035565, disc_loss = 0.09428940995929957
Trained batch 1072 in epoch 4, gen_loss = 0.8093494733748654, disc_loss = 0.0943494931189734
Trained batch 1073 in epoch 4, gen_loss = 0.8094548614386962, disc_loss = 0.09427822594924568
Trained batch 1074 in epoch 4, gen_loss = 0.8095003246983816, disc_loss = 0.09422883836335914
Trained batch 1075 in epoch 4, gen_loss = 0.8096240046243686, disc_loss = 0.09415598500339958
Trained batch 1076 in epoch 4, gen_loss = 0.8095817398504737, disc_loss = 0.0941586303719239
Trained batch 1077 in epoch 4, gen_loss = 0.8094571431570018, disc_loss = 0.09411937375734379
Trained batch 1078 in epoch 4, gen_loss = 0.8098196686971397, disc_loss = 0.09424317686838392
Trained batch 1079 in epoch 4, gen_loss = 0.8097300178750798, disc_loss = 0.09418982629560763
Trained batch 1080 in epoch 4, gen_loss = 0.8094674967760074, disc_loss = 0.09422326733760543
Trained batch 1081 in epoch 4, gen_loss = 0.809250673089803, disc_loss = 0.09429733506825627
Trained batch 1082 in epoch 4, gen_loss = 0.8095555872633187, disc_loss = 0.09442201023534394
Trained batch 1083 in epoch 4, gen_loss = 0.8094045203935176, disc_loss = 0.09440495925388433
Trained batch 1084 in epoch 4, gen_loss = 0.8093984320141753, disc_loss = 0.09439641506441178
Trained batch 1085 in epoch 4, gen_loss = 0.809742244430449, disc_loss = 0.09442987371215504
Trained batch 1086 in epoch 4, gen_loss = 0.8097510252562595, disc_loss = 0.09443622043402565
Trained batch 1087 in epoch 4, gen_loss = 0.809602330904454, disc_loss = 0.09440944117822629
Trained batch 1088 in epoch 4, gen_loss = 0.8093983840515463, disc_loss = 0.09447878217401583
Trained batch 1089 in epoch 4, gen_loss = 0.8097277309096188, disc_loss = 0.09458813538791937
Trained batch 1090 in epoch 4, gen_loss = 0.8096009445070237, disc_loss = 0.09464546494479577
Trained batch 1091 in epoch 4, gen_loss = 0.8092713945787469, disc_loss = 0.09479681997399628
Trained batch 1092 in epoch 4, gen_loss = 0.8093471686063507, disc_loss = 0.09479966970997346
Trained batch 1093 in epoch 4, gen_loss = 0.8092923692582512, disc_loss = 0.09479014154598525
Trained batch 1094 in epoch 4, gen_loss = 0.8094494550467626, disc_loss = 0.09472586108056921
Trained batch 1095 in epoch 4, gen_loss = 0.8096349326091526, disc_loss = 0.09468498871573348
Trained batch 1096 in epoch 4, gen_loss = 0.8097439644384514, disc_loss = 0.09462671806066278
Trained batch 1097 in epoch 4, gen_loss = 0.8097780542024063, disc_loss = 0.09455551598254991
Trained batch 1098 in epoch 4, gen_loss = 0.8098575867936219, disc_loss = 0.09450234056156369
Trained batch 1099 in epoch 4, gen_loss = 0.8097098190947013, disc_loss = 0.0946239551867951
Trained batch 1100 in epoch 4, gen_loss = 0.8096843421134376, disc_loss = 0.09459768259706658
Trained batch 1101 in epoch 4, gen_loss = 0.8096724688303666, disc_loss = 0.09454486124596125
Trained batch 1102 in epoch 4, gen_loss = 0.8098104465094244, disc_loss = 0.09447558879588856
Trained batch 1103 in epoch 4, gen_loss = 0.8100461901799925, disc_loss = 0.09440526150443686
Trained batch 1104 in epoch 4, gen_loss = 0.8097965804969564, disc_loss = 0.09441473677046429
Trained batch 1105 in epoch 4, gen_loss = 0.8100520909425363, disc_loss = 0.09438089412514114
Trained batch 1106 in epoch 4, gen_loss = 0.8102571135344759, disc_loss = 0.09434532812126015
Trained batch 1107 in epoch 4, gen_loss = 0.8102405869842436, disc_loss = 0.0942854085661444
Trained batch 1108 in epoch 4, gen_loss = 0.8102490693680116, disc_loss = 0.09426194707534677
Trained batch 1109 in epoch 4, gen_loss = 0.8100283483395705, disc_loss = 0.09424859142384014
Trained batch 1110 in epoch 4, gen_loss = 0.8100820053117325, disc_loss = 0.09421467323033902
Trained batch 1111 in epoch 4, gen_loss = 0.8104952879035644, disc_loss = 0.09423354972261104
Trained batch 1112 in epoch 4, gen_loss = 0.8103735562336948, disc_loss = 0.0942113611509108
Trained batch 1113 in epoch 4, gen_loss = 0.8105296562935762, disc_loss = 0.09414874823493097
Trained batch 1114 in epoch 4, gen_loss = 0.8104271856391376, disc_loss = 0.09415386178501518
Trained batch 1115 in epoch 4, gen_loss = 0.8104198602525564, disc_loss = 0.09408989356243215
Trained batch 1116 in epoch 4, gen_loss = 0.8103429416032807, disc_loss = 0.09403883382151089
Trained batch 1117 in epoch 4, gen_loss = 0.8105054428144516, disc_loss = 0.09401440525624055
Trained batch 1118 in epoch 4, gen_loss = 0.8108981062356013, disc_loss = 0.09426777163175891
Trained batch 1119 in epoch 4, gen_loss = 0.810711397204016, disc_loss = 0.09430507244375934
Trained batch 1120 in epoch 4, gen_loss = 0.8106516851951351, disc_loss = 0.09430964488326758
Trained batch 1121 in epoch 4, gen_loss = 0.8105548980136181, disc_loss = 0.09427528131633678
Trained batch 1122 in epoch 4, gen_loss = 0.8109272919853988, disc_loss = 0.09440739552854484
Trained batch 1123 in epoch 4, gen_loss = 0.8108745736742783, disc_loss = 0.09437626452281328
Trained batch 1124 in epoch 4, gen_loss = 0.8108204889032575, disc_loss = 0.09436859885685973
Trained batch 1125 in epoch 4, gen_loss = 0.8108151212308166, disc_loss = 0.09432442910922939
Trained batch 1126 in epoch 4, gen_loss = 0.81095040455368, disc_loss = 0.09427456737734781
Trained batch 1127 in epoch 4, gen_loss = 0.8108829544949616, disc_loss = 0.0942316226354067
Trained batch 1128 in epoch 4, gen_loss = 0.8108775383133715, disc_loss = 0.09419727020388002
Trained batch 1129 in epoch 4, gen_loss = 0.8109546539794027, disc_loss = 0.09413494905704155
Trained batch 1130 in epoch 4, gen_loss = 0.8108370353382947, disc_loss = 0.09422030446970231
Trained batch 1131 in epoch 4, gen_loss = 0.8107181699821469, disc_loss = 0.09419564010456942
Trained batch 1132 in epoch 4, gen_loss = 0.8105931987251104, disc_loss = 0.09418345146236279
Trained batch 1133 in epoch 4, gen_loss = 0.8109272115287327, disc_loss = 0.09424184156479921
Trained batch 1134 in epoch 4, gen_loss = 0.8108201860593804, disc_loss = 0.0941820919776278
Trained batch 1135 in epoch 4, gen_loss = 0.8108443269689738, disc_loss = 0.09414514680196281
Trained batch 1136 in epoch 4, gen_loss = 0.810865633694247, disc_loss = 0.0940795221162031
Trained batch 1137 in epoch 4, gen_loss = 0.8107903279455768, disc_loss = 0.09406077449319651
Trained batch 1138 in epoch 4, gen_loss = 0.8108951174919808, disc_loss = 0.0940164239836744
Trained batch 1139 in epoch 4, gen_loss = 0.8107832125143001, disc_loss = 0.0940186755502956
Trained batch 1140 in epoch 4, gen_loss = 0.8108062368803751, disc_loss = 0.09398598606574964
Trained batch 1141 in epoch 4, gen_loss = 0.8106188966440863, disc_loss = 0.09409890781220329
Trained batch 1142 in epoch 4, gen_loss = 0.8106145153469092, disc_loss = 0.09403307560899753
Trained batch 1143 in epoch 4, gen_loss = 0.8104189915413206, disc_loss = 0.09398827365749365
Trained batch 1144 in epoch 4, gen_loss = 0.8104833279374385, disc_loss = 0.09394800060440879
Trained batch 1145 in epoch 4, gen_loss = 0.8105965415064577, disc_loss = 0.09388984886223993
Trained batch 1146 in epoch 4, gen_loss = 0.8104824058731016, disc_loss = 0.09390361570211578
Trained batch 1147 in epoch 4, gen_loss = 0.8107588147089041, disc_loss = 0.09393674132125354
Trained batch 1148 in epoch 4, gen_loss = 0.8109577132941744, disc_loss = 0.09389498652331045
Trained batch 1149 in epoch 4, gen_loss = 0.8105549145263174, disc_loss = 0.09410924195109502
Trained batch 1150 in epoch 4, gen_loss = 0.8107334062081643, disc_loss = 0.09408998984089371
Trained batch 1151 in epoch 4, gen_loss = 0.8108612586640649, disc_loss = 0.09403078830574588
Trained batch 1152 in epoch 4, gen_loss = 0.8109958569381098, disc_loss = 0.09398791415767109
Trained batch 1153 in epoch 4, gen_loss = 0.8109344831785669, disc_loss = 0.09396132848917974
Trained batch 1154 in epoch 4, gen_loss = 0.8107776547923232, disc_loss = 0.0940807045941358
Trained batch 1155 in epoch 4, gen_loss = 0.8105568877037834, disc_loss = 0.09419743429424698
Trained batch 1156 in epoch 4, gen_loss = 0.8105913091035577, disc_loss = 0.09438143104037902
Trained batch 1157 in epoch 4, gen_loss = 0.8106282382740257, disc_loss = 0.09433182654017663
Trained batch 1158 in epoch 4, gen_loss = 0.8107400814246473, disc_loss = 0.09428492940743748
Trained batch 1159 in epoch 4, gen_loss = 0.8105755882530377, disc_loss = 0.09429145610955511
Trained batch 1160 in epoch 4, gen_loss = 0.8104638418793987, disc_loss = 0.09426447658171487
Trained batch 1161 in epoch 4, gen_loss = 0.8108024139617683, disc_loss = 0.09421664170068071
Trained batch 1162 in epoch 4, gen_loss = 0.8109183540553342, disc_loss = 0.09420195378375945
Trained batch 1163 in epoch 4, gen_loss = 0.8108310685637071, disc_loss = 0.09415392187676837
Trained batch 1164 in epoch 4, gen_loss = 0.8111121447301218, disc_loss = 0.09420806034408158
Trained batch 1165 in epoch 4, gen_loss = 0.8109027275090357, disc_loss = 0.094276907441636
Trained batch 1166 in epoch 4, gen_loss = 0.8107810973508193, disc_loss = 0.09425577470727885
Trained batch 1167 in epoch 4, gen_loss = 0.81105761679068, disc_loss = 0.09421794870326117
Trained batch 1168 in epoch 4, gen_loss = 0.811269420757571, disc_loss = 0.09419266183416848
Trained batch 1169 in epoch 4, gen_loss = 0.8111516704926124, disc_loss = 0.0941859990851874
Trained batch 1170 in epoch 4, gen_loss = 0.8112034550291366, disc_loss = 0.09413458704534858
Trained batch 1171 in epoch 4, gen_loss = 0.8110019998440563, disc_loss = 0.09413163416538985
Trained batch 1172 in epoch 4, gen_loss = 0.8110032068392403, disc_loss = 0.09410307303750658
Trained batch 1173 in epoch 4, gen_loss = 0.8108091437633845, disc_loss = 0.09410625879749579
Trained batch 1174 in epoch 4, gen_loss = 0.8107829951225443, disc_loss = 0.09406355434117165
Trained batch 1175 in epoch 4, gen_loss = 0.8110284668450453, disc_loss = 0.09419105693438173
Trained batch 1176 in epoch 4, gen_loss = 0.810811893000072, disc_loss = 0.09415469836592422
Trained batch 1177 in epoch 4, gen_loss = 0.810736293450681, disc_loss = 0.09413294020584817
Trained batch 1178 in epoch 4, gen_loss = 0.8106767824891262, disc_loss = 0.09409243251221527
Trained batch 1179 in epoch 4, gen_loss = 0.810811067435701, disc_loss = 0.09404999125843584
Trained batch 1180 in epoch 4, gen_loss = 0.8106646771959891, disc_loss = 0.09407426601245836
Trained batch 1181 in epoch 4, gen_loss = 0.8108621414139388, disc_loss = 0.09408048039393628
Trained batch 1182 in epoch 4, gen_loss = 0.8106385993433523, disc_loss = 0.09413286898244214
Trained batch 1183 in epoch 4, gen_loss = 0.8106299958921768, disc_loss = 0.09407947582626916
Trained batch 1184 in epoch 4, gen_loss = 0.8108141160715482, disc_loss = 0.09419408772722326
Trained batch 1185 in epoch 4, gen_loss = 0.8107990706951984, disc_loss = 0.09419081225821632
Trained batch 1186 in epoch 4, gen_loss = 0.8106792992468933, disc_loss = 0.09415250924818387
Trained batch 1187 in epoch 4, gen_loss = 0.8106174301418793, disc_loss = 0.09413547535906687
Trained batch 1188 in epoch 4, gen_loss = 0.8106375541678991, disc_loss = 0.09407839348697933
Trained batch 1189 in epoch 4, gen_loss = 0.8106017809956013, disc_loss = 0.09407419520234611
Trained batch 1190 in epoch 4, gen_loss = 0.8105102537260849, disc_loss = 0.09406686248766034
Trained batch 1191 in epoch 4, gen_loss = 0.8104952641281505, disc_loss = 0.09404400971580622
Trained batch 1192 in epoch 4, gen_loss = 0.8103509727187849, disc_loss = 0.09415116678058402
Trained batch 1193 in epoch 4, gen_loss = 0.8107068363446087, disc_loss = 0.09434993404558106
Trained batch 1194 in epoch 4, gen_loss = 0.8107628198847112, disc_loss = 0.09432537593570962
Trained batch 1195 in epoch 4, gen_loss = 0.8106577618664323, disc_loss = 0.09429572788487658
Trained batch 1196 in epoch 4, gen_loss = 0.8103614972348798, disc_loss = 0.0943158078944947
Trained batch 1197 in epoch 4, gen_loss = 0.8107796439244871, disc_loss = 0.09428515593569496
Trained batch 1198 in epoch 4, gen_loss = 0.8105827432259408, disc_loss = 0.09434858795792933
Trained batch 1199 in epoch 4, gen_loss = 0.8106740953028202, disc_loss = 0.09428158529180412
Trained batch 1200 in epoch 4, gen_loss = 0.8104285121857375, disc_loss = 0.09433274771428847
Trained batch 1201 in epoch 4, gen_loss = 0.8103134836908584, disc_loss = 0.09432025194344748
Trained batch 1202 in epoch 4, gen_loss = 0.8108493463753267, disc_loss = 0.09447095905533578
Trained batch 1203 in epoch 4, gen_loss = 0.8108956394005455, disc_loss = 0.09444008313469045
Trained batch 1204 in epoch 4, gen_loss = 0.8108593591515949, disc_loss = 0.09438063245792236
Trained batch 1205 in epoch 4, gen_loss = 0.8106924328044872, disc_loss = 0.09439863083624647
Trained batch 1206 in epoch 4, gen_loss = 0.8109399803235893, disc_loss = 0.0943444016448962
Trained batch 1207 in epoch 4, gen_loss = 0.8110308653076753, disc_loss = 0.09434170970178228
Trained batch 1208 in epoch 4, gen_loss = 0.8111017642679837, disc_loss = 0.09444740292368914
Trained batch 1209 in epoch 4, gen_loss = 0.8108719349400071, disc_loss = 0.09462884525145011
Trained batch 1210 in epoch 4, gen_loss = 0.8110205671887669, disc_loss = 0.09457235015132007
Trained batch 1211 in epoch 4, gen_loss = 0.8111976695434489, disc_loss = 0.09463774743828025
Trained batch 1212 in epoch 4, gen_loss = 0.8111616306234173, disc_loss = 0.09459488939874716
Trained batch 1213 in epoch 4, gen_loss = 0.8110112807110468, disc_loss = 0.09464964564794542
Trained batch 1214 in epoch 4, gen_loss = 0.8110263588987751, disc_loss = 0.09460020183275143
Trained batch 1215 in epoch 4, gen_loss = 0.8110115582025365, disc_loss = 0.09454540594551393
Trained batch 1216 in epoch 4, gen_loss = 0.8111397784659387, disc_loss = 0.09450789777854351
Trained batch 1217 in epoch 4, gen_loss = 0.8112010648000025, disc_loss = 0.09446786386488473
Trained batch 1218 in epoch 4, gen_loss = 0.8110912506750512, disc_loss = 0.09447193151481993
Trained batch 1219 in epoch 4, gen_loss = 0.8110873170563432, disc_loss = 0.09441094405903314
Trained batch 1220 in epoch 4, gen_loss = 0.8109714513328796, disc_loss = 0.09435747791826114
Trained batch 1221 in epoch 4, gen_loss = 0.8109142926632871, disc_loss = 0.09437900970411013
Trained batch 1222 in epoch 4, gen_loss = 0.8108998493200819, disc_loss = 0.0943606181362627
Trained batch 1223 in epoch 4, gen_loss = 0.8109462880620769, disc_loss = 0.09430122148820802
Trained batch 1224 in epoch 4, gen_loss = 0.8112717371570821, disc_loss = 0.09425972443834252
Trained batch 1225 in epoch 4, gen_loss = 0.8117085022405155, disc_loss = 0.09431690285529266
Trained batch 1226 in epoch 4, gen_loss = 0.8116136631930662, disc_loss = 0.09437690068418866
Trained batch 1227 in epoch 4, gen_loss = 0.8116623716556288, disc_loss = 0.09431619777538319
Trained batch 1228 in epoch 4, gen_loss = 0.8116976788996486, disc_loss = 0.09425653278618518
Trained batch 1229 in epoch 4, gen_loss = 0.8120213554157474, disc_loss = 0.09421934747341566
Trained batch 1230 in epoch 4, gen_loss = 0.8121075942495022, disc_loss = 0.09415864985539094
Trained batch 1231 in epoch 4, gen_loss = 0.8122999304784583, disc_loss = 0.09409320369429354
Trained batch 1232 in epoch 4, gen_loss = 0.8124357688649341, disc_loss = 0.09405030960191436
Trained batch 1233 in epoch 4, gen_loss = 0.8125774555596579, disc_loss = 0.0939856059305865
Trained batch 1234 in epoch 4, gen_loss = 0.8126233867305493, disc_loss = 0.0939346349553058
Trained batch 1235 in epoch 4, gen_loss = 0.8127170684943307, disc_loss = 0.0938884426740188
Trained batch 1236 in epoch 4, gen_loss = 0.8125972954033842, disc_loss = 0.09387845583952717
Trained batch 1237 in epoch 4, gen_loss = 0.8129525270331079, disc_loss = 0.09388634184546925
Trained batch 1238 in epoch 4, gen_loss = 0.8129734375286333, disc_loss = 0.0938832328697671
Trained batch 1239 in epoch 4, gen_loss = 0.8129597280294665, disc_loss = 0.09387864573227782
Trained batch 1240 in epoch 4, gen_loss = 0.8129437925544696, disc_loss = 0.09384358976873824
Trained batch 1241 in epoch 4, gen_loss = 0.8130572718506658, disc_loss = 0.09378467757260837
Trained batch 1242 in epoch 4, gen_loss = 0.813167296487865, disc_loss = 0.09375316129093772
Trained batch 1243 in epoch 4, gen_loss = 0.8128512925034167, disc_loss = 0.09380418200261435
Trained batch 1244 in epoch 4, gen_loss = 0.8129630024413986, disc_loss = 0.09374509754788923
Trained batch 1245 in epoch 4, gen_loss = 0.8131419832356286, disc_loss = 0.09368152667979081
Trained batch 1246 in epoch 4, gen_loss = 0.8131293658026716, disc_loss = 0.0936619859299329
Trained batch 1247 in epoch 4, gen_loss = 0.8131872494585621, disc_loss = 0.09366045847761995
Trained batch 1248 in epoch 4, gen_loss = 0.8132684736417903, disc_loss = 0.09362295811311352
Trained batch 1249 in epoch 4, gen_loss = 0.8131508937120437, disc_loss = 0.0936188362210989
Trained batch 1250 in epoch 4, gen_loss = 0.8132335319459962, disc_loss = 0.09355490811267417
Trained batch 1251 in epoch 4, gen_loss = 0.813432549825682, disc_loss = 0.09349230756706442
Trained batch 1252 in epoch 4, gen_loss = 0.8136241777791847, disc_loss = 0.09343105978024001
Trained batch 1253 in epoch 4, gen_loss = 0.8138674116638479, disc_loss = 0.09336774759559018
Trained batch 1254 in epoch 4, gen_loss = 0.8139584372005615, disc_loss = 0.09331845703620122
Trained batch 1255 in epoch 4, gen_loss = 0.8137349866710271, disc_loss = 0.0934148487489623
Trained batch 1256 in epoch 4, gen_loss = 0.8136613474493475, disc_loss = 0.09338891062983323
Trained batch 1257 in epoch 4, gen_loss = 0.8138078845599118, disc_loss = 0.0935029628418611
Trained batch 1258 in epoch 4, gen_loss = 0.8139109749989059, disc_loss = 0.09343547931989926
Trained batch 1259 in epoch 4, gen_loss = 0.8138150005350038, disc_loss = 0.0934318546139236
Trained batch 1260 in epoch 4, gen_loss = 0.8137934653414893, disc_loss = 0.0934320944963314
Trained batch 1261 in epoch 4, gen_loss = 0.8135657400931874, disc_loss = 0.09342296649930665
Trained batch 1262 in epoch 4, gen_loss = 0.813699551947232, disc_loss = 0.09336274439691672
Trained batch 1263 in epoch 4, gen_loss = 0.813986872688313, disc_loss = 0.09343757501381886
Trained batch 1264 in epoch 4, gen_loss = 0.8137912130874136, disc_loss = 0.09344506549755693
Trained batch 1265 in epoch 4, gen_loss = 0.8136801169993941, disc_loss = 0.09354775528221922
Trained batch 1266 in epoch 4, gen_loss = 0.8134553988758936, disc_loss = 0.09351820573460637
Trained batch 1267 in epoch 4, gen_loss = 0.8135747756538707, disc_loss = 0.0934556118148006
Trained batch 1268 in epoch 4, gen_loss = 0.8137032377193818, disc_loss = 0.09339153489143455
Trained batch 1269 in epoch 4, gen_loss = 0.8137849562515423, disc_loss = 0.0933586696903478
Trained batch 1270 in epoch 4, gen_loss = 0.813796899409673, disc_loss = 0.09330609709502181
Trained batch 1271 in epoch 4, gen_loss = 0.813712745694057, disc_loss = 0.09328533851603081
Trained batch 1272 in epoch 4, gen_loss = 0.8136749168549199, disc_loss = 0.0933329965955836
Trained batch 1273 in epoch 4, gen_loss = 0.813657374195813, disc_loss = 0.09332262245891397
Trained batch 1274 in epoch 4, gen_loss = 0.8136034026099186, disc_loss = 0.09329380556867987
Trained batch 1275 in epoch 4, gen_loss = 0.8137304401463102, disc_loss = 0.09322763387067097
Trained batch 1276 in epoch 4, gen_loss = 0.8134977702013477, disc_loss = 0.09333361423601372
Trained batch 1277 in epoch 4, gen_loss = 0.8135578183920731, disc_loss = 0.09333248141750763
Trained batch 1278 in epoch 4, gen_loss = 0.8137340545887309, disc_loss = 0.09328627440149287
Trained batch 1279 in epoch 4, gen_loss = 0.813942069397308, disc_loss = 0.09331082809367217
Trained batch 1280 in epoch 4, gen_loss = 0.8137065106821098, disc_loss = 0.09338209661746007
Trained batch 1281 in epoch 4, gen_loss = 0.8135950825004236, disc_loss = 0.09338236961066258
Trained batch 1282 in epoch 4, gen_loss = 0.8138463620970422, disc_loss = 0.09335899350123766
Trained batch 1283 in epoch 4, gen_loss = 0.8138455227481614, disc_loss = 0.09333198232651685
Trained batch 1284 in epoch 4, gen_loss = 0.8139108403415531, disc_loss = 0.09327459886728094
Trained batch 1285 in epoch 4, gen_loss = 0.813818231827549, disc_loss = 0.09328715247717653
Trained batch 1286 in epoch 4, gen_loss = 0.8138272395732334, disc_loss = 0.09327208470747095
Trained batch 1287 in epoch 4, gen_loss = 0.813776418265904, disc_loss = 0.09322235264427821
Trained batch 1288 in epoch 4, gen_loss = 0.8141310507008233, disc_loss = 0.09316835517339737
Trained batch 1289 in epoch 4, gen_loss = 0.8140629829131356, disc_loss = 0.09312170389462118
Trained batch 1290 in epoch 4, gen_loss = 0.8140092163608574, disc_loss = 0.0930989778605683
Trained batch 1291 in epoch 4, gen_loss = 0.8140817627126218, disc_loss = 0.09315522143259737
Trained batch 1292 in epoch 4, gen_loss = 0.8143405586319752, disc_loss = 0.09312013162289906
Trained batch 1293 in epoch 4, gen_loss = 0.8141212199211489, disc_loss = 0.09314988399934962
Trained batch 1294 in epoch 4, gen_loss = 0.8140517756975756, disc_loss = 0.09315784968953565
Trained batch 1295 in epoch 4, gen_loss = 0.8139534720714078, disc_loss = 0.09327371657199376
Trained batch 1296 in epoch 4, gen_loss = 0.8138632952891227, disc_loss = 0.09327024797160026
Trained batch 1297 in epoch 4, gen_loss = 0.813979027749761, disc_loss = 0.09324165060398713
Trained batch 1298 in epoch 4, gen_loss = 0.813840764660024, disc_loss = 0.0932331705556249
Trained batch 1299 in epoch 4, gen_loss = 0.813968153664699, disc_loss = 0.09327221574548346
Trained batch 1300 in epoch 4, gen_loss = 0.8138623181945264, disc_loss = 0.09331354286828057
Trained batch 1301 in epoch 4, gen_loss = 0.8138887815623789, disc_loss = 0.09329360880146516
Trained batch 1302 in epoch 4, gen_loss = 0.8139191934308545, disc_loss = 0.09332318559248952
Trained batch 1303 in epoch 4, gen_loss = 0.8137898869538234, disc_loss = 0.09333819067362764
Trained batch 1304 in epoch 4, gen_loss = 0.8137298298293146, disc_loss = 0.09338272381645281
Trained batch 1305 in epoch 4, gen_loss = 0.8136843218600768, disc_loss = 0.09342040717002763
Trained batch 1306 in epoch 4, gen_loss = 0.8133366027677342, disc_loss = 0.093692244055475
Trained batch 1307 in epoch 4, gen_loss = 0.813530636307661, disc_loss = 0.09384375628203563
Trained batch 1308 in epoch 4, gen_loss = 0.8133069787251302, disc_loss = 0.09385577393332858
Trained batch 1309 in epoch 4, gen_loss = 0.8131829307279514, disc_loss = 0.09385384698149585
Trained batch 1310 in epoch 4, gen_loss = 0.8131234011151789, disc_loss = 0.09385702844700633
Trained batch 1311 in epoch 4, gen_loss = 0.813045030505192, disc_loss = 0.09397219275777433
Trained batch 1312 in epoch 4, gen_loss = 0.8129776110652741, disc_loss = 0.09396441852686656
Trained batch 1313 in epoch 4, gen_loss = 0.8129783170680477, disc_loss = 0.09391843334628522
Trained batch 1314 in epoch 4, gen_loss = 0.8128489372394837, disc_loss = 0.09391881583166439
Trained batch 1315 in epoch 4, gen_loss = 0.812877374760648, disc_loss = 0.09386244098766279
Trained batch 1316 in epoch 4, gen_loss = 0.8131035919341519, disc_loss = 0.09390980027468936
Trained batch 1317 in epoch 4, gen_loss = 0.8128018866269108, disc_loss = 0.09403570500175626
Trained batch 1318 in epoch 4, gen_loss = 0.812673141641812, disc_loss = 0.0939883422360694
Trained batch 1319 in epoch 4, gen_loss = 0.8125703639153278, disc_loss = 0.0939758584340752
Trained batch 1320 in epoch 4, gen_loss = 0.8128523031569719, disc_loss = 0.09394185924246896
Trained batch 1321 in epoch 4, gen_loss = 0.8127869095275694, disc_loss = 0.09398742564693206
Trained batch 1322 in epoch 4, gen_loss = 0.8126964377167544, disc_loss = 0.09400483608972324
Trained batch 1323 in epoch 4, gen_loss = 0.8126799245435306, disc_loss = 0.09398215381271034
Trained batch 1324 in epoch 4, gen_loss = 0.8128954735342062, disc_loss = 0.09400291464941682
Trained batch 1325 in epoch 4, gen_loss = 0.812691095457897, disc_loss = 0.09404736125299519
Trained batch 1326 in epoch 4, gen_loss = 0.8126534872155667, disc_loss = 0.09405779554603373
Trained batch 1327 in epoch 4, gen_loss = 0.8125867454043354, disc_loss = 0.09429410305463272
Trained batch 1328 in epoch 4, gen_loss = 0.812450562678754, disc_loss = 0.09430866728433772
Trained batch 1329 in epoch 4, gen_loss = 0.8123122323276405, disc_loss = 0.0943335234460638
Trained batch 1330 in epoch 4, gen_loss = 0.8125342946138533, disc_loss = 0.09440970785949437
Trained batch 1331 in epoch 4, gen_loss = 0.8125393509685814, disc_loss = 0.0943522839163718
Trained batch 1332 in epoch 4, gen_loss = 0.8124705316961393, disc_loss = 0.09435405160334669
Trained batch 1333 in epoch 4, gen_loss = 0.8124668458769883, disc_loss = 0.09437209976672277
Trained batch 1334 in epoch 4, gen_loss = 0.8123612763729882, disc_loss = 0.09434833611581432
Trained batch 1335 in epoch 4, gen_loss = 0.8124362067905014, disc_loss = 0.09430411138326421
Trained batch 1336 in epoch 4, gen_loss = 0.8124380195952211, disc_loss = 0.09429038255130656
Trained batch 1337 in epoch 4, gen_loss = 0.8126064797777053, disc_loss = 0.0942421878196622
Trained batch 1338 in epoch 4, gen_loss = 0.8124723698863171, disc_loss = 0.09424999084593512
Trained batch 1339 in epoch 4, gen_loss = 0.812440164587391, disc_loss = 0.09425005622402723
Trained batch 1340 in epoch 4, gen_loss = 0.812432206005947, disc_loss = 0.09422736738702195
Trained batch 1341 in epoch 4, gen_loss = 0.8125136871273934, disc_loss = 0.0942182431508261
Trained batch 1342 in epoch 4, gen_loss = 0.8124083569932143, disc_loss = 0.09424902303303832
Trained batch 1343 in epoch 4, gen_loss = 0.8124650303008301, disc_loss = 0.09423970819556243
Trained batch 1344 in epoch 4, gen_loss = 0.8124774842457257, disc_loss = 0.09418694369328731
Trained batch 1345 in epoch 4, gen_loss = 0.8123094107385553, disc_loss = 0.09419171722608592
Trained batch 1346 in epoch 4, gen_loss = 0.8125806919450483, disc_loss = 0.09417854931064465
Trained batch 1347 in epoch 4, gen_loss = 0.812417765974291, disc_loss = 0.09429219872649283
Trained batch 1348 in epoch 4, gen_loss = 0.8125769255601362, disc_loss = 0.09434270172941189
Trained batch 1349 in epoch 4, gen_loss = 0.8124543248282539, disc_loss = 0.09430677972044106
Trained batch 1350 in epoch 4, gen_loss = 0.8123804380238983, disc_loss = 0.09426143303441833
Trained batch 1351 in epoch 4, gen_loss = 0.8122873223392215, disc_loss = 0.09421931730566778
Trained batch 1352 in epoch 4, gen_loss = 0.812479828343247, disc_loss = 0.09423956059536182
Trained batch 1353 in epoch 4, gen_loss = 0.8122573815825419, disc_loss = 0.09432922891771732
Trained batch 1354 in epoch 4, gen_loss = 0.8124933083998761, disc_loss = 0.09428581937295265
Trained batch 1355 in epoch 4, gen_loss = 0.8124660680779313, disc_loss = 0.09428866008560347
Trained batch 1356 in epoch 4, gen_loss = 0.8123829497426595, disc_loss = 0.09434080076545982
Trained batch 1357 in epoch 4, gen_loss = 0.8121410902803531, disc_loss = 0.09446613552989726
Trained batch 1358 in epoch 4, gen_loss = 0.8119759443404483, disc_loss = 0.09463424123056106
Trained batch 1359 in epoch 4, gen_loss = 0.8119885631343897, disc_loss = 0.09459771196330514
Trained batch 1360 in epoch 4, gen_loss = 0.8121549372809674, disc_loss = 0.09466525544545872
Trained batch 1361 in epoch 4, gen_loss = 0.811972266820734, disc_loss = 0.09466494331150022
Trained batch 1362 in epoch 4, gen_loss = 0.8118151173553131, disc_loss = 0.09468942808611858
Trained batch 1363 in epoch 4, gen_loss = 0.8117749932661784, disc_loss = 0.09472463107490338
Trained batch 1364 in epoch 4, gen_loss = 0.8117946770164993, disc_loss = 0.09475265827725877
Trained batch 1365 in epoch 4, gen_loss = 0.8115792217750326, disc_loss = 0.09479955642853657
Trained batch 1366 in epoch 4, gen_loss = 0.8115000038052791, disc_loss = 0.09477913890499963
Trained batch 1367 in epoch 4, gen_loss = 0.8115401455794858, disc_loss = 0.09479549010992268
Trained batch 1368 in epoch 4, gen_loss = 0.8114325678461742, disc_loss = 0.09482334622905104
Trained batch 1369 in epoch 4, gen_loss = 0.811374306678772, disc_loss = 0.09480396727929367
Trained batch 1370 in epoch 4, gen_loss = 0.8112753367963105, disc_loss = 0.09475827979686094
Trained batch 1371 in epoch 4, gen_loss = 0.8113010455324768, disc_loss = 0.0947281374737251
Trained batch 1372 in epoch 4, gen_loss = 0.8112468747700207, disc_loss = 0.09471336214546079
Trained batch 1373 in epoch 4, gen_loss = 0.8110992230876217, disc_loss = 0.09470826633182372
Trained batch 1374 in epoch 4, gen_loss = 0.8110228121063926, disc_loss = 0.09469294931807301
Trained batch 1375 in epoch 4, gen_loss = 0.8112134273748758, disc_loss = 0.09468220682343641
Trained batch 1376 in epoch 4, gen_loss = 0.8111217389872045, disc_loss = 0.09465031381141863
Trained batch 1377 in epoch 4, gen_loss = 0.8113265118855004, disc_loss = 0.09459636953803988
Trained batch 1378 in epoch 4, gen_loss = 0.8114859256474672, disc_loss = 0.09453730176569673
Trained batch 1379 in epoch 4, gen_loss = 0.8112576600002206, disc_loss = 0.09458155172566572
Trained batch 1380 in epoch 4, gen_loss = 0.8113312054854386, disc_loss = 0.09454044796779999
Trained batch 1381 in epoch 4, gen_loss = 0.81130636549203, disc_loss = 0.09452691435943292
Trained batch 1382 in epoch 4, gen_loss = 0.8113878020236911, disc_loss = 0.09447547395269852
Trained batch 1383 in epoch 4, gen_loss = 0.8115649783628525, disc_loss = 0.09452912115055874
Trained batch 1384 in epoch 4, gen_loss = 0.8114049917524042, disc_loss = 0.09459176690247084
Trained batch 1385 in epoch 4, gen_loss = 0.8114724761307842, disc_loss = 0.09464295256296966
Trained batch 1386 in epoch 4, gen_loss = 0.8114129905229691, disc_loss = 0.09464842102019669
Trained batch 1387 in epoch 4, gen_loss = 0.8115685359287674, disc_loss = 0.09463704316756053
Trained batch 1388 in epoch 4, gen_loss = 0.8114520283891967, disc_loss = 0.09464109586008682
Trained batch 1389 in epoch 4, gen_loss = 0.8114603828183181, disc_loss = 0.09462049856460351
Trained batch 1390 in epoch 4, gen_loss = 0.8114729137578343, disc_loss = 0.09459114634437925
Trained batch 1391 in epoch 4, gen_loss = 0.8116711178558996, disc_loss = 0.09453761915612066
Trained batch 1392 in epoch 4, gen_loss = 0.8116330206180252, disc_loss = 0.0945009007028385
Trained batch 1393 in epoch 4, gen_loss = 0.8117475609697262, disc_loss = 0.09449036357659778
Trained batch 1394 in epoch 4, gen_loss = 0.8115930984524415, disc_loss = 0.09447082162811338
Trained batch 1395 in epoch 4, gen_loss = 0.8116720236816516, disc_loss = 0.09445926170518627
Trained batch 1396 in epoch 4, gen_loss = 0.8116741500842887, disc_loss = 0.0944160557989999
Trained batch 1397 in epoch 4, gen_loss = 0.811674940910121, disc_loss = 0.09440459740029725
Trained batch 1398 in epoch 4, gen_loss = 0.8117751539222167, disc_loss = 0.0943758666083973
Trained batch 1399 in epoch 4, gen_loss = 0.8117241404737745, disc_loss = 0.09434330822633845
Trained batch 1400 in epoch 4, gen_loss = 0.811822653242216, disc_loss = 0.09428846710983087
Trained batch 1401 in epoch 4, gen_loss = 0.8117940547462877, disc_loss = 0.09427140922964512
Trained batch 1402 in epoch 4, gen_loss = 0.8118338055128042, disc_loss = 0.09421407612849157
Trained batch 1403 in epoch 4, gen_loss = 0.8118380707638216, disc_loss = 0.09417566890162322
Trained batch 1404 in epoch 4, gen_loss = 0.8120593702665851, disc_loss = 0.0941281731972915
Trained batch 1405 in epoch 4, gen_loss = 0.8120896901039786, disc_loss = 0.09407621930097661
Trained batch 1406 in epoch 4, gen_loss = 0.8122893191434511, disc_loss = 0.09402290829765136
Trained batch 1407 in epoch 4, gen_loss = 0.812634792517532, disc_loss = 0.09403454400307965
Trained batch 1408 in epoch 4, gen_loss = 0.8125193393171214, disc_loss = 0.09402164324160964
Trained batch 1409 in epoch 4, gen_loss = 0.8124138083441038, disc_loss = 0.09399745030104058
Trained batch 1410 in epoch 4, gen_loss = 0.8124207191058375, disc_loss = 0.09394374920397174
Trained batch 1411 in epoch 4, gen_loss = 0.8124355126710519, disc_loss = 0.09394048432695545
Trained batch 1412 in epoch 4, gen_loss = 0.8123527425700523, disc_loss = 0.09401139943621215
Trained batch 1413 in epoch 4, gen_loss = 0.8122209905735, disc_loss = 0.09397388210643973
Trained batch 1414 in epoch 4, gen_loss = 0.812190963269965, disc_loss = 0.09392576775391827
Trained batch 1415 in epoch 4, gen_loss = 0.8121766388247915, disc_loss = 0.09387461320065635
Trained batch 1416 in epoch 4, gen_loss = 0.8122556640299257, disc_loss = 0.09382558485720473
Trained batch 1417 in epoch 4, gen_loss = 0.8123517296630337, disc_loss = 0.09376965331607229
Trained batch 1418 in epoch 4, gen_loss = 0.8124219875171035, disc_loss = 0.09371118445390438
Trained batch 1419 in epoch 4, gen_loss = 0.8124247745309078, disc_loss = 0.09368268143529938
Trained batch 1420 in epoch 4, gen_loss = 0.8126794674042495, disc_loss = 0.09385742876484707
Trained batch 1421 in epoch 4, gen_loss = 0.8126635581632203, disc_loss = 0.09383629945875702
Trained batch 1422 in epoch 4, gen_loss = 0.8125320272134042, disc_loss = 0.09382561462501343
Trained batch 1423 in epoch 4, gen_loss = 0.8126683623184648, disc_loss = 0.0937777115810359
Trained batch 1424 in epoch 4, gen_loss = 0.8127210726236043, disc_loss = 0.0937198877393415
Trained batch 1425 in epoch 4, gen_loss = 0.8125420651211812, disc_loss = 0.09373401823880734
Trained batch 1426 in epoch 4, gen_loss = 0.8127276456765387, disc_loss = 0.09369178877630452
Trained batch 1427 in epoch 4, gen_loss = 0.812937836728844, disc_loss = 0.09365175420311424
Trained batch 1428 in epoch 4, gen_loss = 0.8128702840327883, disc_loss = 0.09363310963001449
Trained batch 1429 in epoch 4, gen_loss = 0.8127349788909192, disc_loss = 0.09364353003162708
Trained batch 1430 in epoch 4, gen_loss = 0.8127034955471233, disc_loss = 0.09360985234080392
Trained batch 1431 in epoch 4, gen_loss = 0.8126192540346577, disc_loss = 0.09357927329174903
Trained batch 1432 in epoch 4, gen_loss = 0.8127764277498122, disc_loss = 0.09364650893530081
Trained batch 1433 in epoch 4, gen_loss = 0.8129775412328739, disc_loss = 0.09359309023552713
Trained batch 1434 in epoch 4, gen_loss = 0.8127354832684122, disc_loss = 0.09367561591951377
Trained batch 1435 in epoch 4, gen_loss = 0.812639249545784, disc_loss = 0.09363699635726848
Trained batch 1436 in epoch 4, gen_loss = 0.8126914452867701, disc_loss = 0.09374767326002599
Trained batch 1437 in epoch 4, gen_loss = 0.8126647531861888, disc_loss = 0.09373572015725543
Trained batch 1438 in epoch 4, gen_loss = 0.8124871215652972, disc_loss = 0.09378099967379322
Trained batch 1439 in epoch 4, gen_loss = 0.8124808544293046, disc_loss = 0.09373846804632599
Trained batch 1440 in epoch 4, gen_loss = 0.8125818210662362, disc_loss = 0.09373037580990133
Trained batch 1441 in epoch 4, gen_loss = 0.8126539176900905, disc_loss = 0.09367585233664566
Trained batch 1442 in epoch 4, gen_loss = 0.8126103267311141, disc_loss = 0.09362825752401818
Trained batch 1443 in epoch 4, gen_loss = 0.8122749912895655, disc_loss = 0.09380378515377043
Trained batch 1444 in epoch 4, gen_loss = 0.8123003511486582, disc_loss = 0.09375971030882176
Trained batch 1445 in epoch 4, gen_loss = 0.8125055897079233, disc_loss = 0.0937183082166848
Trained batch 1446 in epoch 4, gen_loss = 0.8125787794425229, disc_loss = 0.09366134090674752
Trained batch 1447 in epoch 4, gen_loss = 0.8124951852578155, disc_loss = 0.09370303346880954
Trained batch 1448 in epoch 4, gen_loss = 0.8123559921136636, disc_loss = 0.09370804859262302
Trained batch 1449 in epoch 4, gen_loss = 0.8121946800782762, disc_loss = 0.09376013724904123
Trained batch 1450 in epoch 4, gen_loss = 0.8121222571247122, disc_loss = 0.0937481689947862
Trained batch 1451 in epoch 4, gen_loss = 0.8121505396712582, disc_loss = 0.09371144011470466
Trained batch 1452 in epoch 4, gen_loss = 0.8122068858318959, disc_loss = 0.09367638947833162
Trained batch 1453 in epoch 4, gen_loss = 0.8122460568910452, disc_loss = 0.0936652413233756
Trained batch 1454 in epoch 4, gen_loss = 0.8121590140554094, disc_loss = 0.09366028044577623
Trained batch 1455 in epoch 4, gen_loss = 0.8120669326079744, disc_loss = 0.0936635058714783
Trained batch 1456 in epoch 4, gen_loss = 0.8119962296628265, disc_loss = 0.09361519655257504
Trained batch 1457 in epoch 4, gen_loss = 0.8120448901043343, disc_loss = 0.09359876678065897
Trained batch 1458 in epoch 4, gen_loss = 0.811894863925624, disc_loss = 0.0935851763301951
Trained batch 1459 in epoch 4, gen_loss = 0.8120226849227735, disc_loss = 0.09353411147460239
Trained batch 1460 in epoch 4, gen_loss = 0.8122262700749618, disc_loss = 0.0934921832739909
Trained batch 1461 in epoch 4, gen_loss = 0.8121353313021066, disc_loss = 0.09346167338634911
Trained batch 1462 in epoch 4, gen_loss = 0.812228620357898, disc_loss = 0.09341580925734684
Trained batch 1463 in epoch 4, gen_loss = 0.8121371575188442, disc_loss = 0.09338247906632946
Trained batch 1464 in epoch 4, gen_loss = 0.8120561944136441, disc_loss = 0.0933722683575017
Trained batch 1465 in epoch 4, gen_loss = 0.8124264793579771, disc_loss = 0.09353854508033736
Trained batch 1466 in epoch 4, gen_loss = 0.8123768080678535, disc_loss = 0.09352562774922484
Trained batch 1467 in epoch 4, gen_loss = 0.8121172061814275, disc_loss = 0.09368941363274584
Trained batch 1468 in epoch 4, gen_loss = 0.8121295488554251, disc_loss = 0.09366863884648005
Trained batch 1469 in epoch 4, gen_loss = 0.8122315107559671, disc_loss = 0.09382075762477558
Trained batch 1470 in epoch 4, gen_loss = 0.8122624152376083, disc_loss = 0.09380072877279538
Trained batch 1471 in epoch 4, gen_loss = 0.8119824133894366, disc_loss = 0.09394100269254642
Trained batch 1472 in epoch 4, gen_loss = 0.8120892288647618, disc_loss = 0.0939240789746528
Trained batch 1473 in epoch 4, gen_loss = 0.8120986719387033, disc_loss = 0.0938801906561906
Trained batch 1474 in epoch 4, gen_loss = 0.8119830147694733, disc_loss = 0.09391750879143759
Trained batch 1475 in epoch 4, gen_loss = 0.8117397985847662, disc_loss = 0.09401640173762048
Trained batch 1476 in epoch 4, gen_loss = 0.8116032404316867, disc_loss = 0.0939972725417528
Trained batch 1477 in epoch 4, gen_loss = 0.8116318411893225, disc_loss = 0.09396654428379844
Trained batch 1478 in epoch 4, gen_loss = 0.8116596361887947, disc_loss = 0.0940458240425762
Trained batch 1479 in epoch 4, gen_loss = 0.8114440912733207, disc_loss = 0.09409266776166152
Trained batch 1480 in epoch 4, gen_loss = 0.8112944904651938, disc_loss = 0.09408920442850242
Trained batch 1481 in epoch 4, gen_loss = 0.8112003968553505, disc_loss = 0.09419517085275408
Trained batch 1482 in epoch 4, gen_loss = 0.8113081498236087, disc_loss = 0.094169683186105
Trained batch 1483 in epoch 4, gen_loss = 0.8111117105840673, disc_loss = 0.0941581980311475
Trained batch 1484 in epoch 4, gen_loss = 0.8111550188626504, disc_loss = 0.09415040658818251
Trained batch 1485 in epoch 4, gen_loss = 0.8111155551744181, disc_loss = 0.09412201514973996
Trained batch 1486 in epoch 4, gen_loss = 0.8112885876237425, disc_loss = 0.09409430910593303
Trained batch 1487 in epoch 4, gen_loss = 0.811303888958308, disc_loss = 0.09406111559077036
Trained batch 1488 in epoch 4, gen_loss = 0.8111908409401745, disc_loss = 0.09405112212937879
Trained batch 1489 in epoch 4, gen_loss = 0.8112449336371966, disc_loss = 0.09401196107805876
Trained batch 1490 in epoch 4, gen_loss = 0.8115361193376128, disc_loss = 0.09405553897019503
Trained batch 1491 in epoch 4, gen_loss = 0.811414774557221, disc_loss = 0.09402048500596817
Trained batch 1492 in epoch 4, gen_loss = 0.811641411659946, disc_loss = 0.09401220333439966
Trained batch 1493 in epoch 4, gen_loss = 0.8115991771300953, disc_loss = 0.09400410162923306
Trained batch 1494 in epoch 4, gen_loss = 0.8114241785030302, disc_loss = 0.09397790862751944
Trained batch 1495 in epoch 4, gen_loss = 0.8114475407463344, disc_loss = 0.09397321046681148
Trained batch 1496 in epoch 4, gen_loss = 0.8115571162345494, disc_loss = 0.09394430390477639
Trained batch 1497 in epoch 4, gen_loss = 0.8114256756964608, disc_loss = 0.09393360651718659
Trained batch 1498 in epoch 4, gen_loss = 0.81132021277964, disc_loss = 0.09391174385829855
Trained batch 1499 in epoch 4, gen_loss = 0.811285708228747, disc_loss = 0.09386358612713715
Trained batch 1500 in epoch 4, gen_loss = 0.8112752962160079, disc_loss = 0.09382824633434306
Trained batch 1501 in epoch 4, gen_loss = 0.8111551130183051, disc_loss = 0.0938364199484226
Trained batch 1502 in epoch 4, gen_loss = 0.8113433694490495, disc_loss = 0.09387929010789293
Trained batch 1503 in epoch 4, gen_loss = 0.8113911758236428, disc_loss = 0.09383126573842712
Trained batch 1504 in epoch 4, gen_loss = 0.8113378354877333, disc_loss = 0.09379540028551785
Trained batch 1505 in epoch 4, gen_loss = 0.8112138537850829, disc_loss = 0.09380203860677076
Trained batch 1506 in epoch 4, gen_loss = 0.8109220764497771, disc_loss = 0.09405703878421992
Trained batch 1507 in epoch 4, gen_loss = 0.8111698005931447, disc_loss = 0.0942249605722419
Trained batch 1508 in epoch 4, gen_loss = 0.811205882813616, disc_loss = 0.0942044317879084
Trained batch 1509 in epoch 4, gen_loss = 0.8111158642350443, disc_loss = 0.09428465089248801
Trained batch 1510 in epoch 4, gen_loss = 0.8109366316064788, disc_loss = 0.09424843627239579
Trained batch 1511 in epoch 4, gen_loss = 0.8110843679852902, disc_loss = 0.09419285780109622
Trained batch 1512 in epoch 4, gen_loss = 0.8110764613430467, disc_loss = 0.09416732179113003
Trained batch 1513 in epoch 4, gen_loss = 0.8111902493269945, disc_loss = 0.09412078563581606
Trained batch 1514 in epoch 4, gen_loss = 0.8112382194193283, disc_loss = 0.09410887882113457
Trained batch 1515 in epoch 4, gen_loss = 0.8111626748241346, disc_loss = 0.09414693888394766
Trained batch 1516 in epoch 4, gen_loss = 0.8112276972676078, disc_loss = 0.09409384773497764
Trained batch 1517 in epoch 4, gen_loss = 0.8115028223226507, disc_loss = 0.09419379817451963
Trained batch 1518 in epoch 4, gen_loss = 0.8113763617441166, disc_loss = 0.09419068578113217
Trained batch 1519 in epoch 4, gen_loss = 0.8112286461615249, disc_loss = 0.09424118232717248
Trained batch 1520 in epoch 4, gen_loss = 0.8115192894517083, disc_loss = 0.09426283193439892
Trained batch 1521 in epoch 4, gen_loss = 0.8113426601565621, disc_loss = 0.09426335507511857
Trained batch 1522 in epoch 4, gen_loss = 0.8111989751937588, disc_loss = 0.09432178054516126
Trained batch 1523 in epoch 4, gen_loss = 0.8112877895395587, disc_loss = 0.09436401885902397
Trained batch 1524 in epoch 4, gen_loss = 0.8113323461227729, disc_loss = 0.09435580725796887
Trained batch 1525 in epoch 4, gen_loss = 0.8111978047679949, disc_loss = 0.09435952630328553
Trained batch 1526 in epoch 4, gen_loss = 0.8112225222798368, disc_loss = 0.09431313564262908
Trained batch 1527 in epoch 4, gen_loss = 0.8114741788835738, disc_loss = 0.09427825711101917
Trained batch 1528 in epoch 4, gen_loss = 0.8113660508897119, disc_loss = 0.09431277899141012
Trained batch 1529 in epoch 4, gen_loss = 0.8113508694117365, disc_loss = 0.09427851026549058
Trained batch 1530 in epoch 4, gen_loss = 0.8113350596675524, disc_loss = 0.09425425928288002
Trained batch 1531 in epoch 4, gen_loss = 0.8115075400424999, disc_loss = 0.09430376714333776
Trained batch 1532 in epoch 4, gen_loss = 0.8114400597973268, disc_loss = 0.09429695645550148
Trained batch 1533 in epoch 4, gen_loss = 0.8115660434557219, disc_loss = 0.09428575475405139
Trained batch 1534 in epoch 4, gen_loss = 0.8115590273169042, disc_loss = 0.09427689434990821
Trained batch 1535 in epoch 4, gen_loss = 0.8116135943952637, disc_loss = 0.0942234608016103
Trained batch 1536 in epoch 4, gen_loss = 0.8115001697197469, disc_loss = 0.09421598259117224
Trained batch 1537 in epoch 4, gen_loss = 0.8116449203502062, disc_loss = 0.09425170350788338
Trained batch 1538 in epoch 4, gen_loss = 0.8115654611951582, disc_loss = 0.09424196385377273
Trained batch 1539 in epoch 4, gen_loss = 0.8115956567518123, disc_loss = 0.0942103924767973
Trained batch 1540 in epoch 4, gen_loss = 0.811383939017575, disc_loss = 0.09423940043079339
Trained batch 1541 in epoch 4, gen_loss = 0.8113954923225594, disc_loss = 0.09419296996126823
Trained batch 1542 in epoch 4, gen_loss = 0.8114544689578046, disc_loss = 0.09413835385721359
Trained batch 1543 in epoch 4, gen_loss = 0.81152305437416, disc_loss = 0.09413108346595338
Trained batch 1544 in epoch 4, gen_loss = 0.8117392072206948, disc_loss = 0.09409775826477214
Trained batch 1545 in epoch 4, gen_loss = 0.8116043126945508, disc_loss = 0.09408901605265936
Trained batch 1546 in epoch 4, gen_loss = 0.8116340095294085, disc_loss = 0.09403814879109398
Trained batch 1547 in epoch 4, gen_loss = 0.8114663183650613, disc_loss = 0.09402872327876395
Trained batch 1548 in epoch 4, gen_loss = 0.8112417273439847, disc_loss = 0.09411746917113306
Trained batch 1549 in epoch 4, gen_loss = 0.8111946020010979, disc_loss = 0.09411214228058534
Trained batch 1550 in epoch 4, gen_loss = 0.811442943502441, disc_loss = 0.09410529560574614
Trained batch 1551 in epoch 4, gen_loss = 0.8112811033143518, disc_loss = 0.0941599847637261
Trained batch 1552 in epoch 4, gen_loss = 0.8111773424776462, disc_loss = 0.0941570522995271
Trained batch 1553 in epoch 4, gen_loss = 0.811325464949031, disc_loss = 0.09411258566129756
Trained batch 1554 in epoch 4, gen_loss = 0.8114490171912399, disc_loss = 0.0941202881701075
Trained batch 1555 in epoch 4, gen_loss = 0.8115972439282044, disc_loss = 0.09408064122350077
Trained batch 1556 in epoch 4, gen_loss = 0.8113382033185462, disc_loss = 0.09421071374708728
Trained batch 1557 in epoch 4, gen_loss = 0.8115607055336888, disc_loss = 0.09416865220470343
Trained batch 1558 in epoch 4, gen_loss = 0.8115925839155281, disc_loss = 0.09414407130297348
Trained batch 1559 in epoch 4, gen_loss = 0.8116281843529298, disc_loss = 0.09411230069788125
Trained batch 1560 in epoch 4, gen_loss = 0.8116243173303244, disc_loss = 0.09419518041625514
Trained batch 1561 in epoch 4, gen_loss = 0.8115166871976608, disc_loss = 0.09419329837143478
Trained batch 1562 in epoch 4, gen_loss = 0.8114283459924843, disc_loss = 0.09423584353908067
Trained batch 1563 in epoch 4, gen_loss = 0.811331909083192, disc_loss = 0.09426939836822336
Trained batch 1564 in epoch 4, gen_loss = 0.8113918093256295, disc_loss = 0.09422636953846049
Trained batch 1565 in epoch 4, gen_loss = 0.81145604997683, disc_loss = 0.09428351819765009
Trained batch 1566 in epoch 4, gen_loss = 0.8114199994206809, disc_loss = 0.09424272387442444
Trained batch 1567 in epoch 4, gen_loss = 0.8111990882768011, disc_loss = 0.09435288399536333
Trained batch 1568 in epoch 4, gen_loss = 0.8112406314483033, disc_loss = 0.09430480668222718
Trained batch 1569 in epoch 4, gen_loss = 0.8114170060226112, disc_loss = 0.09437612066472507
Trained batch 1570 in epoch 4, gen_loss = 0.8113939403766739, disc_loss = 0.09434305487661833
Trained batch 1571 in epoch 4, gen_loss = 0.8114470142406665, disc_loss = 0.09434761990954194
Trained batch 1572 in epoch 4, gen_loss = 0.811358265318237, disc_loss = 0.09440357425680546
Trained batch 1573 in epoch 4, gen_loss = 0.8112369475666117, disc_loss = 0.09443984160393837
Trained batch 1574 in epoch 4, gen_loss = 0.811274580028322, disc_loss = 0.09447349354920406
Trained batch 1575 in epoch 4, gen_loss = 0.8112625999536913, disc_loss = 0.09457619642888475
Trained batch 1576 in epoch 4, gen_loss = 0.811134508480811, disc_loss = 0.09461046611274827
Trained batch 1577 in epoch 4, gen_loss = 0.8110743758985147, disc_loss = 0.09461239522856546
Trained batch 1578 in epoch 4, gen_loss = 0.8109872240556653, disc_loss = 0.09459670138633217
Trained batch 1579 in epoch 4, gen_loss = 0.8109214922861208, disc_loss = 0.09459976442217166
Trained batch 1580 in epoch 4, gen_loss = 0.8108949826572003, disc_loss = 0.09456470518995602
Testing Epoch 4

  0%|          | 0/25 [00:00<?, ?it/s]
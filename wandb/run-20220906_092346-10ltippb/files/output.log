
wandb: WARNING Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 1.2902953624725342, disc_loss = 0.5281661748886108
Trained batch 1 in epoch 0, gen_loss = 1.383880853652954, disc_loss = 0.6709595322608948
Trained batch 2 in epoch 0, gen_loss = 1.280551830927531, disc_loss = 0.603569765885671
Trained batch 3 in epoch 0, gen_loss = 1.2196603417396545, disc_loss = 0.5365849211812019
Trained batch 4 in epoch 0, gen_loss = 1.1934740543365479, disc_loss = 0.48013477921485903
Trained batch 5 in epoch 0, gen_loss = 1.2002837657928467, disc_loss = 0.44172314802805585
Trained batch 6 in epoch 0, gen_loss = 1.186726553099496, disc_loss = 0.40536112444741385
Trained batch 7 in epoch 0, gen_loss = 1.1926277726888657, disc_loss = 0.37112308107316494
Trained batch 8 in epoch 0, gen_loss = 1.2010902563730876, disc_loss = 0.34333141562011504
Trained batch 9 in epoch 0, gen_loss = 1.2175305366516114, disc_loss = 0.3214729577302933
Trained batch 10 in epoch 0, gen_loss = 1.2415911501104182, disc_loss = 0.29905014823783527
Trained batch 11 in epoch 0, gen_loss = 1.263041267792384, disc_loss = 0.28004440913597745
Trained batch 12 in epoch 0, gen_loss = 1.2842984474622285, disc_loss = 0.264073504278293
Trained batch 13 in epoch 0, gen_loss = 1.3085679582187109, disc_loss = 0.24917532290731156
Trained batch 14 in epoch 0, gen_loss = 1.329236125946045, disc_loss = 0.23764723738034566
Trained batch 15 in epoch 0, gen_loss = 1.356416016817093, disc_loss = 0.22659130673855543
Trained batch 16 in epoch 0, gen_loss = 1.376720344319063, disc_loss = 0.21682445003705866
Trained batch 17 in epoch 0, gen_loss = 1.3927188250753615, disc_loss = 0.20706590906613404
Trained batch 18 in epoch 0, gen_loss = 1.409254933658399, disc_loss = 0.19830213271473585
Trained batch 19 in epoch 0, gen_loss = 1.4212997019290925, disc_loss = 0.1908601202070713
Trained batch 20 in epoch 0, gen_loss = 1.4337619656608218, disc_loss = 0.18472143759330115
Trained batch 21 in epoch 0, gen_loss = 1.4489003365690059, disc_loss = 0.180074311115525
Trained batch 22 in epoch 0, gen_loss = 1.4591829154802405, disc_loss = 0.17605307244736215
Trained batch 23 in epoch 0, gen_loss = 1.4691171844800313, disc_loss = 0.1717666561404864
Trained batch 24 in epoch 0, gen_loss = 1.4810079193115235, disc_loss = 0.16834933280944825
Trained batch 25 in epoch 0, gen_loss = 1.4883560675841112, disc_loss = 0.1649025844839903
Trained batch 26 in epoch 0, gen_loss = 1.493491009429649, disc_loss = 0.161140282396917
Trained batch 27 in epoch 0, gen_loss = 1.5005502913679396, disc_loss = 0.1572448035169925
Trained batch 28 in epoch 0, gen_loss = 1.5045258834444244, disc_loss = 0.15308644327110257
Trained batch 29 in epoch 0, gen_loss = 1.5110811988512676, disc_loss = 0.1490915438781182
Trained batch 30 in epoch 0, gen_loss = 1.515523249103177, disc_loss = 0.14541103258248297
Trained batch 31 in epoch 0, gen_loss = 1.5208066515624523, disc_loss = 0.14201428997330368
Trained batch 32 in epoch 0, gen_loss = 1.5247584798119285, disc_loss = 0.138944803991101
Trained batch 33 in epoch 0, gen_loss = 1.5298071643885445, disc_loss = 0.1359694966060274
Trained batch 34 in epoch 0, gen_loss = 1.5338783434459142, disc_loss = 0.13292304075189998
Trained batch 35 in epoch 0, gen_loss = 1.5354654093583424, disc_loss = 0.1303059289024936
Trained batch 36 in epoch 0, gen_loss = 1.539650862281387, disc_loss = 0.12778626825358416
Trained batch 37 in epoch 0, gen_loss = 1.541998370697624, disc_loss = 0.12543418013343685
Trained batch 38 in epoch 0, gen_loss = 1.5451979698278966, disc_loss = 0.12292656130515613
Trained batch 39 in epoch 0, gen_loss = 1.5472189247608186, disc_loss = 0.12044318364933133
Trained batch 40 in epoch 0, gen_loss = 1.54523130742515, disc_loss = 0.11798942325318731
Trained batch 41 in epoch 0, gen_loss = 1.5448394729977561, disc_loss = 0.11585359035858087
Trained batch 42 in epoch 0, gen_loss = 1.5469277903091077, disc_loss = 0.11370031856173693
Trained batch 43 in epoch 0, gen_loss = 1.5501121986996045, disc_loss = 0.11179766393351284
Trained batch 44 in epoch 0, gen_loss = 1.5495452642440797, disc_loss = 0.10998706639640861
Trained batch 45 in epoch 0, gen_loss = 1.5501521929450657, disc_loss = 0.10818012054685665
Trained batch 46 in epoch 0, gen_loss = 1.5510624190594287, disc_loss = 0.1064333355727982
Trained batch 47 in epoch 0, gen_loss = 1.5513375028967857, disc_loss = 0.10478842557252695
Trained batch 48 in epoch 0, gen_loss = 1.550395822038456, disc_loss = 0.10332369093536115
Trained batch 49 in epoch 0, gen_loss = 1.549448959827423, disc_loss = 0.10199081789702177
Trained batch 50 in epoch 0, gen_loss = 1.5495159602632709, disc_loss = 0.10059033235644593
Trained batch 51 in epoch 0, gen_loss = 1.551231514949065, disc_loss = 0.09906811328031696
Trained batch 52 in epoch 0, gen_loss = 1.5521443542444482, disc_loss = 0.0975037166181038
Trained batch 53 in epoch 0, gen_loss = 1.5525120430522494, disc_loss = 0.0960220027094086
Trained batch 54 in epoch 0, gen_loss = 1.5524175773967397, disc_loss = 0.09455701871351763
Trained batch 55 in epoch 0, gen_loss = 1.552658247096198, disc_loss = 0.09311344880344612
Trained batch 56 in epoch 0, gen_loss = 1.5524447361628215, disc_loss = 0.09174178468815067
Trained batch 57 in epoch 0, gen_loss = 1.5526872338919804, disc_loss = 0.09045740801455646
Trained batch 58 in epoch 0, gen_loss = 1.5529894343877242, disc_loss = 0.08916705186968132
Trained batch 59 in epoch 0, gen_loss = 1.554160968462626, disc_loss = 0.08797070123255253
Trained batch 60 in epoch 0, gen_loss = 1.5551852593656446, disc_loss = 0.08686534629859885
Trained batch 61 in epoch 0, gen_loss = 1.5568590318003008, disc_loss = 0.08571652620429954
Trained batch 62 in epoch 0, gen_loss = 1.5570222252891177, disc_loss = 0.08456929677003433
Trained batch 63 in epoch 0, gen_loss = 1.5566503535956144, disc_loss = 0.08346307085594162
Trained batch 64 in epoch 0, gen_loss = 1.5574339481500479, disc_loss = 0.08241285294867479
Trained batch 65 in epoch 0, gen_loss = 1.5579615686879014, disc_loss = 0.08145609783065139
Trained batch 66 in epoch 0, gen_loss = 1.5586508459119655, disc_loss = 0.08049530602657973
Trained batch 67 in epoch 0, gen_loss = 1.5603242323679083, disc_loss = 0.07955572833581005
Trained batch 68 in epoch 0, gen_loss = 1.560437962628793, disc_loss = 0.07863696680768677
Trained batch 69 in epoch 0, gen_loss = 1.5610528366906302, disc_loss = 0.07778028851108891
Trained batch 70 in epoch 0, gen_loss = 1.560589293359031, disc_loss = 0.07695923811218268
Trained batch 71 in epoch 0, gen_loss = 1.5611828648381763, disc_loss = 0.07620036643412378
Trained batch 72 in epoch 0, gen_loss = 1.5617758100979948, disc_loss = 0.07546225154440697
Trained batch 73 in epoch 0, gen_loss = 1.5619466675294411, disc_loss = 0.0747305355160623
Trained batch 74 in epoch 0, gen_loss = 1.5620848242441814, disc_loss = 0.07404286647836367
Trained batch 75 in epoch 0, gen_loss = 1.5622977771257098, disc_loss = 0.07333605584541433
Trained batch 76 in epoch 0, gen_loss = 1.5632321014032735, disc_loss = 0.07256462874931174
Trained batch 77 in epoch 0, gen_loss = 1.5631344455939074, disc_loss = 0.0717536026898485
Trained batch 78 in epoch 0, gen_loss = 1.5640780669224412, disc_loss = 0.07100957235958003
Trained batch 79 in epoch 0, gen_loss = 1.5645438522100448, disc_loss = 0.07029479686170817
Trained batch 80 in epoch 0, gen_loss = 1.564907686209973, disc_loss = 0.06957444711875768
Trained batch 81 in epoch 0, gen_loss = 1.5650299932898544, disc_loss = 0.06885867948621148
Trained batch 82 in epoch 0, gen_loss = 1.5647143498960747, disc_loss = 0.06815774580575974
Trained batch 83 in epoch 0, gen_loss = 1.565719219900313, disc_loss = 0.0675289500948219
Trained batch 84 in epoch 0, gen_loss = 1.565589695818284, disc_loss = 0.06692565657636698
Trained batch 85 in epoch 0, gen_loss = 1.5673258027365042, disc_loss = 0.06634739082479893
Trained batch 86 in epoch 0, gen_loss = 1.5678682546505982, disc_loss = 0.06571528986738674
Trained batch 87 in epoch 0, gen_loss = 1.5678061599081212, disc_loss = 0.06508217196361246
Trained batch 88 in epoch 0, gen_loss = 1.5676430423607988, disc_loss = 0.06445013409417667
Trained batch 89 in epoch 0, gen_loss = 1.567726985613505, disc_loss = 0.06386787359499269
Trained batch 90 in epoch 0, gen_loss = 1.5676613587599535, disc_loss = 0.06328185320228011
Trained batch 91 in epoch 0, gen_loss = 1.5681950190792913, disc_loss = 0.06274682726792019
Trained batch 92 in epoch 0, gen_loss = 1.5675031062095397, disc_loss = 0.06220522874425496
Trained batch 93 in epoch 0, gen_loss = 1.5683362395205396, disc_loss = 0.06168264545936217
Trained batch 94 in epoch 0, gen_loss = 1.567813569621036, disc_loss = 0.061126369512394856
Trained batch 95 in epoch 0, gen_loss = 1.5670625679194927, disc_loss = 0.060573348397156224
Trained batch 96 in epoch 0, gen_loss = 1.5660528473018371, disc_loss = 0.060066211219761786
Trained batch 97 in epoch 0, gen_loss = 1.5663680872138666, disc_loss = 0.05963290515070667
Trained batch 98 in epoch 0, gen_loss = 1.5659462406177713, disc_loss = 0.05927859369025688
Trained batch 99 in epoch 0, gen_loss = 1.566109937429428, disc_loss = 0.05890321595594287
Trained batch 100 in epoch 0, gen_loss = 1.5655233269870872, disc_loss = 0.05842277478647999
Trained batch 101 in epoch 0, gen_loss = 1.565614872119006, disc_loss = 0.05800511679776451
Trained batch 102 in epoch 0, gen_loss = 1.5646030439913852, disc_loss = 0.057659201134104755
Trained batch 103 in epoch 0, gen_loss = 1.5645585277905831, disc_loss = 0.05734356756931028
Trained batch 104 in epoch 0, gen_loss = 1.5650385095959618, disc_loss = 0.05700139416647809
Trained batch 105 in epoch 0, gen_loss = 1.5654392152462366, disc_loss = 0.05662882847289713
Trained batch 106 in epoch 0, gen_loss = 1.5659173192264877, disc_loss = 0.056257663198929525
Trained batch 107 in epoch 0, gen_loss = 1.5652334634904508, disc_loss = 0.05582807550241274
Trained batch 108 in epoch 0, gen_loss = 1.5651841951072762, disc_loss = 0.05538711667812746
Trained batch 109 in epoch 0, gen_loss = 1.5643338810313832, disc_loss = 0.05493559376759963
Trained batch 110 in epoch 0, gen_loss = 1.5648312804935214, disc_loss = 0.054514790809637795
Trained batch 111 in epoch 0, gen_loss = 1.564837125795228, disc_loss = 0.05410470632237515
Trained batch 112 in epoch 0, gen_loss = 1.5656327884809105, disc_loss = 0.053697587131003366
Trained batch 113 in epoch 0, gen_loss = 1.5661074717839558, disc_loss = 0.05328750254161525
Trained batch 114 in epoch 0, gen_loss = 1.5654572549073593, disc_loss = 0.05288150278932374
Trained batch 115 in epoch 0, gen_loss = 1.5646951044427937, disc_loss = 0.052501129379881356
Trained batch 116 in epoch 0, gen_loss = 1.5645495164088714, disc_loss = 0.052125324415536516
Trained batch 117 in epoch 0, gen_loss = 1.564446476556487, disc_loss = 0.05178901383463862
Trained batch 118 in epoch 0, gen_loss = 1.5628740236538798, disc_loss = 0.051490683179004355
Trained batch 119 in epoch 0, gen_loss = 1.5628744314114253, disc_loss = 0.05122091924616446
Trained batch 120 in epoch 0, gen_loss = 1.5625683256417267, disc_loss = 0.050923871746178996
Trained batch 121 in epoch 0, gen_loss = 1.5625810896764036, disc_loss = 0.05060495691160198
Trained batch 122 in epoch 0, gen_loss = 1.5624599718466037, disc_loss = 0.05027756355400008
Trained batch 123 in epoch 0, gen_loss = 1.562799636394747, disc_loss = 0.04994684626768914
Trained batch 124 in epoch 0, gen_loss = 1.5631655349731446, disc_loss = 0.049617297746241094
Trained batch 125 in epoch 0, gen_loss = 1.5627777879200284, disc_loss = 0.049271264697410284
Trained batch 126 in epoch 0, gen_loss = 1.5624491107745433, disc_loss = 0.04892794944081954
Trained batch 127 in epoch 0, gen_loss = 1.5620490349829197, disc_loss = 0.04859130911063403
Trained batch 128 in epoch 0, gen_loss = 1.5612630890321362, disc_loss = 0.048252086180385
Trained batch 129 in epoch 0, gen_loss = 1.5608038452955393, disc_loss = 0.04792203112648657
Trained batch 130 in epoch 0, gen_loss = 1.5602470690967472, disc_loss = 0.04759522759575994
Trained batch 131 in epoch 0, gen_loss = 1.560431055950396, disc_loss = 0.04727569715980666
Trained batch 132 in epoch 0, gen_loss = 1.5604866411452902, disc_loss = 0.04695981918813143
Trained batch 133 in epoch 0, gen_loss = 1.5606129916746225, disc_loss = 0.04665219199273791
Trained batch 134 in epoch 0, gen_loss = 1.5606347225330495, disc_loss = 0.04635119520265747
Trained batch 135 in epoch 0, gen_loss = 1.5605245302705204, disc_loss = 0.04605962590465103
Trained batch 136 in epoch 0, gen_loss = 1.5608396530151367, disc_loss = 0.045800920722013624
Trained batch 137 in epoch 0, gen_loss = 1.5606376554654993, disc_loss = 0.04553672324096703
Trained batch 138 in epoch 0, gen_loss = 1.5601968456515305, disc_loss = 0.04526175747176619
Trained batch 139 in epoch 0, gen_loss = 1.5599267976624624, disc_loss = 0.04498592506695007
Trained batch 140 in epoch 0, gen_loss = 1.5597592245602439, disc_loss = 0.04470884460453869
Trained batch 141 in epoch 0, gen_loss = 1.5595712905198755, disc_loss = 0.044436717815828364
Trained batch 142 in epoch 0, gen_loss = 1.559637755780787, disc_loss = 0.04416690405679645
Trained batch 143 in epoch 0, gen_loss = 1.5595341697335243, disc_loss = 0.043899463111301884
Trained batch 144 in epoch 0, gen_loss = 1.558938192499095, disc_loss = 0.04362972876827779
Trained batch 145 in epoch 0, gen_loss = 1.5585698395559233, disc_loss = 0.043374914790771595
Trained batch 146 in epoch 0, gen_loss = 1.5596087335729274, disc_loss = 0.04316248089632615
Trained batch 147 in epoch 0, gen_loss = 1.5602916076376632, disc_loss = 0.04295446505971454
Trained batch 148 in epoch 0, gen_loss = 1.5612468727483044, disc_loss = 0.04274301328415039
Trained batch 149 in epoch 0, gen_loss = 1.5614049084981283, disc_loss = 0.042495463204880554
Trained batch 150 in epoch 0, gen_loss = 1.5618898079095298, disc_loss = 0.042265712098520716
Trained batch 151 in epoch 0, gen_loss = 1.5619196891784668, disc_loss = 0.042042933704674636
Trained batch 152 in epoch 0, gen_loss = 1.5621312529433007, disc_loss = 0.04183237382448187
Trained batch 153 in epoch 0, gen_loss = 1.5623698520970035, disc_loss = 0.0416151840699377
Trained batch 154 in epoch 0, gen_loss = 1.5627053699185771, disc_loss = 0.041389690360595144
Trained batch 155 in epoch 0, gen_loss = 1.5621092197222588, disc_loss = 0.04116298150844299
Trained batch 156 in epoch 0, gen_loss = 1.5626840925520393, disc_loss = 0.04095413852601674
Trained batch 157 in epoch 0, gen_loss = 1.5626862448982046, disc_loss = 0.04075401179681096
Trained batch 158 in epoch 0, gen_loss = 1.5624529603142407, disc_loss = 0.04055542689777395
Trained batch 159 in epoch 0, gen_loss = 1.5625057272613048, disc_loss = 0.040350119216600436
Trained batch 160 in epoch 0, gen_loss = 1.5628635927757122, disc_loss = 0.04014862000780261
Trained batch 161 in epoch 0, gen_loss = 1.5629124494246494, disc_loss = 0.03995219957842319
Trained batch 162 in epoch 0, gen_loss = 1.5627860964441591, disc_loss = 0.03974841289119395
Trained batch 163 in epoch 0, gen_loss = 1.5623618880423105, disc_loss = 0.039529940777844406
Trained batch 164 in epoch 0, gen_loss = 1.562711635502902, disc_loss = 0.03932292444744345
Trained batch 165 in epoch 0, gen_loss = 1.5622408670115184, disc_loss = 0.039134894382679856
Trained batch 166 in epoch 0, gen_loss = 1.562158376870755, disc_loss = 0.038939787702311476
Trained batch 167 in epoch 0, gen_loss = 1.5618189239785785, disc_loss = 0.03873269239418386
Trained batch 168 in epoch 0, gen_loss = 1.5610847226261386, disc_loss = 0.03851928995349086
Trained batch 169 in epoch 0, gen_loss = 1.5610409463153165, disc_loss = 0.03831225274788106
Trained batch 170 in epoch 0, gen_loss = 1.5610420069499322, disc_loss = 0.03811466928615033
Trained batch 171 in epoch 0, gen_loss = 1.561196781175081, disc_loss = 0.03791844080808724
Trained batch 172 in epoch 0, gen_loss = 1.5604270648405043, disc_loss = 0.03773150721974025
Trained batch 173 in epoch 0, gen_loss = 1.560645458342015, disc_loss = 0.03754174398076346
Trained batch 174 in epoch 0, gen_loss = 1.561255351475307, disc_loss = 0.03735114917691265
Trained batch 175 in epoch 0, gen_loss = 1.560795436528596, disc_loss = 0.03715572362522256
Trained batch 176 in epoch 0, gen_loss = 1.5607010698587882, disc_loss = 0.03696626586192366
Trained batch 177 in epoch 0, gen_loss = 1.5605956061502522, disc_loss = 0.03678654197974947
Trained batch 178 in epoch 0, gen_loss = 1.560649341711119, disc_loss = 0.036607095041681685
Trained batch 179 in epoch 0, gen_loss = 1.560301751560635, disc_loss = 0.03643127061142069
Trained batch 180 in epoch 0, gen_loss = 1.5605273220420541, disc_loss = 0.03625751441751108
Trained batch 181 in epoch 0, gen_loss = 1.5605530267233376, disc_loss = 0.036086979702084354
Trained batch 182 in epoch 0, gen_loss = 1.5604205665692605, disc_loss = 0.03591236266908058
Trained batch 183 in epoch 0, gen_loss = 1.5601598685202391, disc_loss = 0.03573696183688615
Trained batch 184 in epoch 0, gen_loss = 1.5601350732751795, disc_loss = 0.03556221845131871
Trained batch 185 in epoch 0, gen_loss = 1.5603105252788914, disc_loss = 0.03539165962983163
Trained batch 186 in epoch 0, gen_loss = 1.5599807488089577, disc_loss = 0.03522428238570172
Trained batch 187 in epoch 0, gen_loss = 1.5596664262578843, disc_loss = 0.035056007078581274
Trained batch 188 in epoch 0, gen_loss = 1.560025860392858, disc_loss = 0.03489282857700591
Trained batch 189 in epoch 0, gen_loss = 1.55946387052536, disc_loss = 0.03472742999315654
Trained batch 190 in epoch 0, gen_loss = 1.5596343690812275, disc_loss = 0.0345643442916484
Trained batch 191 in epoch 0, gen_loss = 1.559737188120683, disc_loss = 0.03440166985213485
Trained batch 192 in epoch 0, gen_loss = 1.5596262173331463, disc_loss = 0.03423792396676895
Trained batch 193 in epoch 0, gen_loss = 1.5602803807897665, disc_loss = 0.03409753619818036
Trained batch 194 in epoch 0, gen_loss = 1.5603327366021964, disc_loss = 0.03394898839342671
Trained batch 195 in epoch 0, gen_loss = 1.560448282835435, disc_loss = 0.03380225170213653
Trained batch 196 in epoch 0, gen_loss = 1.560335776527521, disc_loss = 0.03366377694428269
Trained batch 197 in epoch 0, gen_loss = 1.5604327886995644, disc_loss = 0.03353116163664093
Trained batch 198 in epoch 0, gen_loss = 1.5600952431185162, disc_loss = 0.033397281512000304
Trained batch 199 in epoch 0, gen_loss = 1.5608396631479264, disc_loss = 0.03326550174271688
Trained batch 200 in epoch 0, gen_loss = 1.5605695111241507, disc_loss = 0.033133940972777
Trained batch 201 in epoch 0, gen_loss = 1.5603963591084622, disc_loss = 0.03302656901345616
Trained batch 202 in epoch 0, gen_loss = 1.560516230578493, disc_loss = 0.03293240098099183
Trained batch 203 in epoch 0, gen_loss = 1.5606003017986523, disc_loss = 0.03283626948912427
Trained batch 204 in epoch 0, gen_loss = 1.5602466687923524, disc_loss = 0.0327277295813873
Trained batch 205 in epoch 0, gen_loss = 1.560563704921204, disc_loss = 0.032615332965947035
Trained batch 206 in epoch 0, gen_loss = 1.5606693029403687, disc_loss = 0.032493211684415595
Trained batch 207 in epoch 0, gen_loss = 1.5602821209109747, disc_loss = 0.03236030795736811
Trained batch 208 in epoch 0, gen_loss = 1.5602759482187518, disc_loss = 0.032228098130611144
Trained batch 209 in epoch 0, gen_loss = 1.559803245181129, disc_loss = 0.03210916786144177
Trained batch 210 in epoch 0, gen_loss = 1.5595302683482237, disc_loss = 0.03199318788672016
Trained batch 211 in epoch 0, gen_loss = 1.5595433830090288, disc_loss = 0.031867614018133365
Trained batch 212 in epoch 0, gen_loss = 1.5596255008043818, disc_loss = 0.03173384462382662
Trained batch 213 in epoch 0, gen_loss = 1.5592157896434036, disc_loss = 0.03159860870365715
Trained batch 214 in epoch 0, gen_loss = 1.5590364433998285, disc_loss = 0.031466349442814324
Trained batch 215 in epoch 0, gen_loss = 1.55886999434895, disc_loss = 0.031335726687555306
Trained batch 216 in epoch 0, gen_loss = 1.558491201444705, disc_loss = 0.031209503262934667
Trained batch 217 in epoch 0, gen_loss = 1.5579601952789026, disc_loss = 0.031081525717836317
Trained batch 218 in epoch 0, gen_loss = 1.5575034672811152, disc_loss = 0.030953474496980302
Trained batch 219 in epoch 0, gen_loss = 1.5572563420642507, disc_loss = 0.030825653875415974
Trained batch 220 in epoch 0, gen_loss = 1.5569499121532182, disc_loss = 0.03069668822517256
Trained batch 221 in epoch 0, gen_loss = 1.5569442881120217, disc_loss = 0.030572731386626827
Trained batch 222 in epoch 0, gen_loss = 1.5570860844556527, disc_loss = 0.03045167953857626
Trained batch 223 in epoch 0, gen_loss = 1.5569305132542337, disc_loss = 0.03033139743014804
Trained batch 224 in epoch 0, gen_loss = 1.5568744574652778, disc_loss = 0.03021803350187838
Trained batch 225 in epoch 0, gen_loss = 1.5568541372771811, disc_loss = 0.0301006096940636
Trained batch 226 in epoch 0, gen_loss = 1.5568211320213283, disc_loss = 0.029980111610767992
Trained batch 227 in epoch 0, gen_loss = 1.5564798587246944, disc_loss = 0.029864352829590962
Trained batch 228 in epoch 0, gen_loss = 1.5564012985562654, disc_loss = 0.029750980126699963
Trained batch 229 in epoch 0, gen_loss = 1.5560035555259042, disc_loss = 0.029637495435409895
Trained batch 230 in epoch 0, gen_loss = 1.5556987266003828, disc_loss = 0.02952278898403984
Trained batch 231 in epoch 0, gen_loss = 1.5554763649044365, disc_loss = 0.029405796837166015
Trained batch 232 in epoch 0, gen_loss = 1.5552844085406847, disc_loss = 0.02928769742458451
Trained batch 233 in epoch 0, gen_loss = 1.5553206444805503, disc_loss = 0.02917093210694436
Trained batch 234 in epoch 0, gen_loss = 1.5552086109810688, disc_loss = 0.029056135475873313
Trained batch 235 in epoch 0, gen_loss = 1.5549077679545193, disc_loss = 0.02894461841393515
Trained batch 236 in epoch 0, gen_loss = 1.5553182655245945, disc_loss = 0.0288394768172207
Trained batch 237 in epoch 0, gen_loss = 1.5552924756242448, disc_loss = 0.02873467405604496
Trained batch 238 in epoch 0, gen_loss = 1.5554638482536731, disc_loss = 0.028640063618851443
Trained batch 239 in epoch 0, gen_loss = 1.555022527774175, disc_loss = 0.028550157409821017
Trained batch 240 in epoch 0, gen_loss = 1.5547800667553027, disc_loss = 0.028463646849710107
Trained batch 241 in epoch 0, gen_loss = 1.5550741848866803, disc_loss = 0.028373632777274456
Trained batch 242 in epoch 0, gen_loss = 1.5548467493842169, disc_loss = 0.02827301188831988
Trained batch 243 in epoch 0, gen_loss = 1.5546656656460685, disc_loss = 0.028171630631597926
Trained batch 244 in epoch 0, gen_loss = 1.5547579303079722, disc_loss = 0.028067504833167306
Trained batch 245 in epoch 0, gen_loss = 1.5544571668151919, disc_loss = 0.02796153824045739
Trained batch 246 in epoch 0, gen_loss = 1.5545386384855882, disc_loss = 0.027860182366684562
Trained batch 247 in epoch 0, gen_loss = 1.5542805276570781, disc_loss = 0.02776082731772124
Trained batch 248 in epoch 0, gen_loss = 1.5539901136873238, disc_loss = 0.02766112947787895
Trained batch 249 in epoch 0, gen_loss = 1.554020353794098, disc_loss = 0.027562771265394987
Trained batch 250 in epoch 0, gen_loss = 1.5539887977311335, disc_loss = 0.027463306234110578
Trained batch 251 in epoch 0, gen_loss = 1.5536403007923612, disc_loss = 0.02736235027652352
Trained batch 252 in epoch 0, gen_loss = 1.5533962155519268, disc_loss = 0.027261391657555527
Trained batch 253 in epoch 0, gen_loss = 1.5532608219957726, disc_loss = 0.027162275911404157
Trained batch 254 in epoch 0, gen_loss = 1.5530104440801284, disc_loss = 0.027068132572971724
Trained batch 255 in epoch 0, gen_loss = 1.5527792870998383, disc_loss = 0.026978233921909123
Trained batch 256 in epoch 0, gen_loss = 1.5524547095428645, disc_loss = 0.02688899584266752
Trained batch 257 in epoch 0, gen_loss = 1.551968561124432, disc_loss = 0.02679699708620996
Trained batch 258 in epoch 0, gen_loss = 1.5518716104242332, disc_loss = 0.02670479696208043
Trained batch 259 in epoch 0, gen_loss = 1.551852513735111, disc_loss = 0.026612585360327592
Trained batch 260 in epoch 0, gen_loss = 1.5516599818664492, disc_loss = 0.026518578299453262
Trained batch 261 in epoch 0, gen_loss = 1.5516148710068856, disc_loss = 0.026426925053748922
Trained batch 262 in epoch 0, gen_loss = 1.5513619769208784, disc_loss = 0.02634068355566252
Trained batch 263 in epoch 0, gen_loss = 1.551145179253636, disc_loss = 0.02626012183309561
Trained batch 264 in epoch 0, gen_loss = 1.5513028027876368, disc_loss = 0.02617431852948975
Trained batch 265 in epoch 0, gen_loss = 1.5508963264020763, disc_loss = 0.026085944027864003
Trained batch 266 in epoch 0, gen_loss = 1.5510495896643022, disc_loss = 0.026003959310530556
Trained batch 267 in epoch 0, gen_loss = 1.5507730868325305, disc_loss = 0.025925914829061713
Trained batch 268 in epoch 0, gen_loss = 1.5506171382492804, disc_loss = 0.02585378404253173
Trained batch 269 in epoch 0, gen_loss = 1.5505496625547055, disc_loss = 0.02578168461806382
Trained batch 270 in epoch 0, gen_loss = 1.550412673791836, disc_loss = 0.025704141153792447
Trained batch 271 in epoch 0, gen_loss = 1.5503922350266401, disc_loss = 0.02562075176170123
Trained batch 272 in epoch 0, gen_loss = 1.5500501197773022, disc_loss = 0.02553445266068473
Trained batch 273 in epoch 0, gen_loss = 1.5502381246455395, disc_loss = 0.025451672386656767
Trained batch 274 in epoch 0, gen_loss = 1.5499602166089144, disc_loss = 0.025369026287543502
Trained batch 275 in epoch 0, gen_loss = 1.549760840509249, disc_loss = 0.02528967064268806
Trained batch 276 in epoch 0, gen_loss = 1.5495583800202242, disc_loss = 0.025211642655150607
Trained batch 277 in epoch 0, gen_loss = 1.5493516587524963, disc_loss = 0.025133149833217423
Trained batch 278 in epoch 0, gen_loss = 1.5495834495858907, disc_loss = 0.025057339320613544
Trained batch 279 in epoch 0, gen_loss = 1.5493223169020245, disc_loss = 0.02497768182989343
Trained batch 280 in epoch 0, gen_loss = 1.5494238770305049, disc_loss = 0.024898550782213483
Trained batch 281 in epoch 0, gen_loss = 1.5493501822153728, disc_loss = 0.024821755973331576
Trained batch 282 in epoch 0, gen_loss = 1.5492326867875277, disc_loss = 0.024748038883936382
Trained batch 283 in epoch 0, gen_loss = 1.5492307728445027, disc_loss = 0.02467463661434496
Trained batch 284 in epoch 0, gen_loss = 1.5488882299055133, disc_loss = 0.024596538795811827
Trained batch 285 in epoch 0, gen_loss = 1.5485512018203735, disc_loss = 0.024517063268010952
Trained batch 286 in epoch 0, gen_loss = 1.5481319265498517, disc_loss = 0.024438357401723593
Trained batch 287 in epoch 0, gen_loss = 1.548270273125834, disc_loss = 0.024363168761839107
Trained batch 288 in epoch 0, gen_loss = 1.548254708105305, disc_loss = 0.024288127422783922
Trained batch 289 in epoch 0, gen_loss = 1.5480144373301803, disc_loss = 0.02421252097340365
Trained batch 290 in epoch 0, gen_loss = 1.5479525729143333, disc_loss = 0.024137613525185286
Trained batch 291 in epoch 0, gen_loss = 1.5480708483963797, disc_loss = 0.024065314903727746
Trained batch 292 in epoch 0, gen_loss = 1.5478245996371065, disc_loss = 0.02399398258620231
Trained batch 293 in epoch 0, gen_loss = 1.5475967940019102, disc_loss = 0.023924713269300558
Trained batch 294 in epoch 0, gen_loss = 1.5475737507060423, disc_loss = 0.0238593322895783
Trained batch 295 in epoch 0, gen_loss = 1.5476655525130194, disc_loss = 0.023793297400540748
Trained batch 296 in epoch 0, gen_loss = 1.5478513385310317, disc_loss = 0.023724428949538957
Trained batch 297 in epoch 0, gen_loss = 1.547668778656313, disc_loss = 0.02365280694606395
Trained batch 298 in epoch 0, gen_loss = 1.547599046126656, disc_loss = 0.02358217523853765
Trained batch 299 in epoch 0, gen_loss = 1.547689158519109, disc_loss = 0.023511834437958897
Trained batch 300 in epoch 0, gen_loss = 1.547591926647579, disc_loss = 0.02344629831574981
Trained batch 301 in epoch 0, gen_loss = 1.5474804221399572, disc_loss = 0.02338911501986795
Trained batch 302 in epoch 0, gen_loss = 1.5471834518728476, disc_loss = 0.023338223512441216
Trained batch 303 in epoch 0, gen_loss = 1.547610375049867, disc_loss = 0.02328352526590032
Trained batch 304 in epoch 0, gen_loss = 1.547777479203021, disc_loss = 0.023223040026963734
Trained batch 305 in epoch 0, gen_loss = 1.5479283675648807, disc_loss = 0.023163451670115097
Trained batch 306 in epoch 0, gen_loss = 1.5479498418223974, disc_loss = 0.023102638686336698
Trained batch 307 in epoch 0, gen_loss = 1.5479986357998539, disc_loss = 0.02304338486018506
Trained batch 308 in epoch 0, gen_loss = 1.5477542159626785, disc_loss = 0.022980499708223304
Trained batch 309 in epoch 0, gen_loss = 1.5476228329443162, disc_loss = 0.022917396729181132
Trained batch 310 in epoch 0, gen_loss = 1.5474890298015436, disc_loss = 0.022853632780971828
Trained batch 311 in epoch 0, gen_loss = 1.547453706845259, disc_loss = 0.022789233113424137
Trained batch 312 in epoch 0, gen_loss = 1.5475309733003855, disc_loss = 0.022722151631804795
Trained batch 313 in epoch 0, gen_loss = 1.5473055433315837, disc_loss = 0.022656161370716847
Trained batch 314 in epoch 0, gen_loss = 1.5473531378640069, disc_loss = 0.02259942905179092
Trained batch 315 in epoch 0, gen_loss = 1.5471863463709625, disc_loss = 0.022548797997186266
Trained batch 316 in epoch 0, gen_loss = 1.5469415221680602, disc_loss = 0.022495443459705975
Trained batch 317 in epoch 0, gen_loss = 1.5468844748892874, disc_loss = 0.022433846680822333
Trained batch 318 in epoch 0, gen_loss = 1.546857839841454, disc_loss = 0.022368629327624873
Trained batch 319 in epoch 0, gen_loss = 1.5465232968330382, disc_loss = 0.022303930613634292
Trained batch 320 in epoch 0, gen_loss = 1.5464995973206754, disc_loss = 0.022243212376477493
Trained batch 321 in epoch 0, gen_loss = 1.5466528560804285, disc_loss = 0.022184012192720835
Trained batch 322 in epoch 0, gen_loss = 1.5464051961898804, disc_loss = 0.022120793537098348
Trained batch 323 in epoch 0, gen_loss = 1.5463371140721403, disc_loss = 0.022060163634222713
Trained batch 324 in epoch 0, gen_loss = 1.5463910084504349, disc_loss = 0.022003711321964287
Trained batch 325 in epoch 0, gen_loss = 1.546230237542486, disc_loss = 0.021946894818062727
Trained batch 326 in epoch 0, gen_loss = 1.54588726062658, disc_loss = 0.0218871382612661
Trained batch 327 in epoch 0, gen_loss = 1.5456172558592587, disc_loss = 0.021826867216121884
Trained batch 328 in epoch 0, gen_loss = 1.5458505519617656, disc_loss = 0.021767489268518077
Trained batch 329 in epoch 0, gen_loss = 1.5456356850537387, disc_loss = 0.02170788960383189
Trained batch 330 in epoch 0, gen_loss = 1.5455884184361945, disc_loss = 0.021650652209468456
Trained batch 331 in epoch 0, gen_loss = 1.5454269920487003, disc_loss = 0.021592342499180708
Trained batch 332 in epoch 0, gen_loss = 1.5456368719135318, disc_loss = 0.021533574294033193
Trained batch 333 in epoch 0, gen_loss = 1.5456894300654977, disc_loss = 0.021473745737729515
Trained batch 334 in epoch 0, gen_loss = 1.5455506061440083, disc_loss = 0.02141321091391424
Trained batch 335 in epoch 0, gen_loss = 1.5453228833419936, disc_loss = 0.021354433617185958
Trained batch 336 in epoch 0, gen_loss = 1.544964924410472, disc_loss = 0.021296645313962873
Trained batch 337 in epoch 0, gen_loss = 1.5449217423884827, disc_loss = 0.021241594914322134
Trained batch 338 in epoch 0, gen_loss = 1.5447291554251252, disc_loss = 0.021188719873591312
Trained batch 339 in epoch 0, gen_loss = 1.544595913326039, disc_loss = 0.02113596130100846
Trained batch 340 in epoch 0, gen_loss = 1.5444760518339722, disc_loss = 0.02108007521932546
Trained batch 341 in epoch 0, gen_loss = 1.544696941710355, disc_loss = 0.021025756603768587
Trained batch 342 in epoch 0, gen_loss = 1.5444994772140903, disc_loss = 0.020970743026315578
Trained batch 343 in epoch 0, gen_loss = 1.544266181283219, disc_loss = 0.020916266247378336
Trained batch 344 in epoch 0, gen_loss = 1.5442062308822853, disc_loss = 0.02086298766147777
Trained batch 345 in epoch 0, gen_loss = 1.5439786273620033, disc_loss = 0.020808940006734944
Trained batch 346 in epoch 0, gen_loss = 1.543718677432805, disc_loss = 0.020753676153958296
Trained batch 347 in epoch 0, gen_loss = 1.5438070722009944, disc_loss = 0.020699356704008305
Trained batch 348 in epoch 0, gen_loss = 1.543550402523795, disc_loss = 0.020646007628150734
Trained batch 349 in epoch 0, gen_loss = 1.543683772087097, disc_loss = 0.020595381826029293
Trained batch 350 in epoch 0, gen_loss = 1.543563977605597, disc_loss = 0.020545647593024068
Trained batch 351 in epoch 0, gen_loss = 1.5433773212134838, disc_loss = 0.02049456078979843
Trained batch 352 in epoch 0, gen_loss = 1.5431438752004174, disc_loss = 0.020442479811133896
Trained batch 353 in epoch 0, gen_loss = 1.5432758671415727, disc_loss = 0.020391094608832212
Trained batch 354 in epoch 0, gen_loss = 1.5429882476027583, disc_loss = 0.020340850713177466
Trained batch 355 in epoch 0, gen_loss = 1.543109091145269, disc_loss = 0.020290704561774148
Trained batch 356 in epoch 0, gen_loss = 1.5432208763117217, disc_loss = 0.020239029020000594
Trained batch 357 in epoch 0, gen_loss = 1.5432516090030777, disc_loss = 0.020186540310715935
Trained batch 358 in epoch 0, gen_loss = 1.5430403848212408, disc_loss = 0.020133972317136015
Trained batch 359 in epoch 0, gen_loss = 1.5428652273284065, disc_loss = 0.020082260357836883
Trained batch 360 in epoch 0, gen_loss = 1.5428094523765374, disc_loss = 0.020030261546249536
Trained batch 361 in epoch 0, gen_loss = 1.5425040389292806, disc_loss = 0.019979723357114405
Trained batch 362 in epoch 0, gen_loss = 1.5425756227214802, disc_loss = 0.019933900887918847
Trained batch 363 in epoch 0, gen_loss = 1.5426280043282352, disc_loss = 0.019889401436647768
Trained batch 364 in epoch 0, gen_loss = 1.5422922516522342, disc_loss = 0.019843753832009658
Trained batch 365 in epoch 0, gen_loss = 1.5425641829850243, disc_loss = 0.019796042910158695
Trained batch 366 in epoch 0, gen_loss = 1.5425604234274466, disc_loss = 0.019747558567858217
Trained batch 367 in epoch 0, gen_loss = 1.5422061791886454, disc_loss = 0.019698337307921105
Trained batch 368 in epoch 0, gen_loss = 1.5420964875518468, disc_loss = 0.019648341552245867
Trained batch 369 in epoch 0, gen_loss = 1.542497350718524, disc_loss = 0.01960173155294379
Trained batch 370 in epoch 0, gen_loss = 1.5426393641294496, disc_loss = 0.01955447592232828
Trained batch 371 in epoch 0, gen_loss = 1.542342729786391, disc_loss = 0.019507805788038318
Trained batch 372 in epoch 0, gen_loss = 1.5422936000389325, disc_loss = 0.01946518881541075
Trained batch 373 in epoch 0, gen_loss = 1.5421443176779517, disc_loss = 0.019424178132060217
Trained batch 374 in epoch 0, gen_loss = 1.541992167154948, disc_loss = 0.019379786578317484
Trained batch 375 in epoch 0, gen_loss = 1.5418817007795294, disc_loss = 0.01933253764613294
Trained batch 376 in epoch 0, gen_loss = 1.541796713988408, disc_loss = 0.019287110957260236
Trained batch 377 in epoch 0, gen_loss = 1.5421465628992312, disc_loss = 0.019244242781679584
Trained batch 378 in epoch 0, gen_loss = 1.5422214065189412, disc_loss = 0.01920431062743795
Trained batch 379 in epoch 0, gen_loss = 1.5422239507499493, disc_loss = 0.01916518334458631
Trained batch 380 in epoch 0, gen_loss = 1.542109846443016, disc_loss = 0.01912456832941025
Trained batch 381 in epoch 0, gen_loss = 1.5421376250177155, disc_loss = 0.019085551370105935
Trained batch 382 in epoch 0, gen_loss = 1.5420078658559615, disc_loss = 0.019048293407486056
Trained batch 383 in epoch 0, gen_loss = 1.5417542181288202, disc_loss = 0.019011178863365785
Trained batch 384 in epoch 0, gen_loss = 1.541685396355468, disc_loss = 0.01897231494681305
Trained batch 385 in epoch 0, gen_loss = 1.5415532141151824, disc_loss = 0.018930499508272414
Trained batch 386 in epoch 0, gen_loss = 1.5417063821501817, disc_loss = 0.01888757548716102
Trained batch 387 in epoch 0, gen_loss = 1.541470029304937, disc_loss = 0.01884224034693409
Trained batch 388 in epoch 0, gen_loss = 1.5414007856177794, disc_loss = 0.01879704119888994
Trained batch 389 in epoch 0, gen_loss = 1.5411781528057196, disc_loss = 0.018751909254859082
Trained batch 390 in epoch 0, gen_loss = 1.5410775626102067, disc_loss = 0.018707930513829126
Trained batch 391 in epoch 0, gen_loss = 1.5408932019253165, disc_loss = 0.018663576422484916
Trained batch 392 in epoch 0, gen_loss = 1.5406615903965997, disc_loss = 0.01861915807447067
Trained batch 393 in epoch 0, gen_loss = 1.5405927412400997, disc_loss = 0.01857585884124835
Trained batch 394 in epoch 0, gen_loss = 1.5404030941709688, disc_loss = 0.018533068078959103
Trained batch 395 in epoch 0, gen_loss = 1.5401196061360716, disc_loss = 0.018490914983858325
Trained batch 396 in epoch 0, gen_loss = 1.5401339437859485, disc_loss = 0.01844772656204212
Trained batch 397 in epoch 0, gen_loss = 1.540123356047587, disc_loss = 0.018405062047327076
Trained batch 398 in epoch 0, gen_loss = 1.5401692934203566, disc_loss = 0.018364680517537233
Trained batch 399 in epoch 0, gen_loss = 1.5401678296923638, disc_loss = 0.018324914796685333
Trained batch 400 in epoch 0, gen_loss = 1.5401280969752933, disc_loss = 0.01828611240765205
Trained batch 401 in epoch 0, gen_loss = 1.5401449683886856, disc_loss = 0.01824836729039943
Trained batch 402 in epoch 0, gen_loss = 1.5400461168502164, disc_loss = 0.018208645188559316
Trained batch 403 in epoch 0, gen_loss = 1.5398703415204984, disc_loss = 0.018169833264500362
Trained batch 404 in epoch 0, gen_loss = 1.5398024550190679, disc_loss = 0.018132814426078565
Trained batch 405 in epoch 0, gen_loss = 1.5395911391732728, disc_loss = 0.018093694646881774
Trained batch 406 in epoch 0, gen_loss = 1.5394637599331156, disc_loss = 0.018051982491165033
Trained batch 407 in epoch 0, gen_loss = 1.5393972580923754, disc_loss = 0.018010022167479347
Trained batch 408 in epoch 0, gen_loss = 1.539297585090973, disc_loss = 0.017968957602447194
Trained batch 409 in epoch 0, gen_loss = 1.5393659373609032, disc_loss = 0.01792815637507862
Trained batch 410 in epoch 0, gen_loss = 1.5392964596875973, disc_loss = 0.01788721702496664
Trained batch 411 in epoch 0, gen_loss = 1.5392831277500079, disc_loss = 0.017846527344092852
Trained batch 412 in epoch 0, gen_loss = 1.5392553237679507, disc_loss = 0.01780538968927933
Trained batch 413 in epoch 0, gen_loss = 1.539351807412318, disc_loss = 0.017765119031537324
Trained batch 414 in epoch 0, gen_loss = 1.539280159214893, disc_loss = 0.017725730689904507
Trained batch 415 in epoch 0, gen_loss = 1.53921791481284, disc_loss = 0.017686778534250783
Trained batch 416 in epoch 0, gen_loss = 1.539114005559926, disc_loss = 0.017647693206710245
Trained batch 417 in epoch 0, gen_loss = 1.5395791154158742, disc_loss = 0.017612320430015333
Trained batch 418 in epoch 0, gen_loss = 1.5395568082895938, disc_loss = 0.017578090782230608
Trained batch 419 in epoch 0, gen_loss = 1.5393395372799465, disc_loss = 0.017547194670797104
Trained batch 420 in epoch 0, gen_loss = 1.5395407161350205, disc_loss = 0.01751744968378629
Trained batch 421 in epoch 0, gen_loss = 1.5395207365542227, disc_loss = 0.017485575584950747
Trained batch 422 in epoch 0, gen_loss = 1.5396270016406446, disc_loss = 0.01745153124494826
Trained batch 423 in epoch 0, gen_loss = 1.5394804705426377, disc_loss = 0.017413769581768098
Trained batch 424 in epoch 0, gen_loss = 1.5392205145779778, disc_loss = 0.01737591487410314
Trained batch 425 in epoch 0, gen_loss = 1.5391061308798095, disc_loss = 0.01733839301941173
Trained batch 426 in epoch 0, gen_loss = 1.5389677738417507, disc_loss = 0.017299843287510924
Trained batch 427 in epoch 0, gen_loss = 1.538796904766671, disc_loss = 0.017262271892254363
Trained batch 428 in epoch 0, gen_loss = 1.5388574136164916, disc_loss = 0.017225526966450907
Trained batch 429 in epoch 0, gen_loss = 1.5387399399003316, disc_loss = 0.017188904253728036
Trained batch 430 in epoch 0, gen_loss = 1.538553858024615, disc_loss = 0.01715200530133359
Trained batch 431 in epoch 0, gen_loss = 1.538265961187857, disc_loss = 0.017115530000241793
Trained batch 432 in epoch 0, gen_loss = 1.5384085784057546, disc_loss = 0.01708167059012037
Trained batch 433 in epoch 0, gen_loss = 1.5382436217250912, disc_loss = 0.017049125410870686
Trained batch 434 in epoch 0, gen_loss = 1.5380264156166163, disc_loss = 0.017018375922149668
Trained batch 435 in epoch 0, gen_loss = 1.5382002026116082, disc_loss = 0.0169866945517918
Trained batch 436 in epoch 0, gen_loss = 1.5380086623285674, disc_loss = 0.01695173107222409
Trained batch 437 in epoch 0, gen_loss = 1.5378102077741056, disc_loss = 0.016915606381717144
Trained batch 438 in epoch 0, gen_loss = 1.537732648143464, disc_loss = 0.016879080355078287
Trained batch 439 in epoch 0, gen_loss = 1.5378941029310227, disc_loss = 0.016844195358730343
Trained batch 440 in epoch 0, gen_loss = 1.5376417747700837, disc_loss = 0.016810177281855812
Trained batch 441 in epoch 0, gen_loss = 1.537457941344421, disc_loss = 0.016778014380352074
Trained batch 442 in epoch 0, gen_loss = 1.5372922242898703, disc_loss = 0.01674584339716541
Trained batch 443 in epoch 0, gen_loss = 1.537220183793489, disc_loss = 0.01671286965620721
Trained batch 444 in epoch 0, gen_loss = 1.5372360074118283, disc_loss = 0.01667976134242176
Trained batch 445 in epoch 0, gen_loss = 1.5370790071017004, disc_loss = 0.0166478129743281
Trained batch 446 in epoch 0, gen_loss = 1.537030216298114, disc_loss = 0.016619352362602032
Trained batch 447 in epoch 0, gen_loss = 1.5369877426752023, disc_loss = 0.016592182522799703
Trained batch 448 in epoch 0, gen_loss = 1.537084532739856, disc_loss = 0.016565219825081825
Trained batch 449 in epoch 0, gen_loss = 1.5369107802708943, disc_loss = 0.016536137136992896
Trained batch 450 in epoch 0, gen_loss = 1.5367427395611275, disc_loss = 0.01650627982981313
Trained batch 451 in epoch 0, gen_loss = 1.5370038977238984, disc_loss = 0.016477457409677203
Trained batch 452 in epoch 0, gen_loss = 1.5369421364718978, disc_loss = 0.016446952712434296
Trained batch 453 in epoch 0, gen_loss = 1.5368050444493735, disc_loss = 0.016417128240868106
Trained batch 454 in epoch 0, gen_loss = 1.5366881160945682, disc_loss = 0.01638873182518592
Trained batch 455 in epoch 0, gen_loss = 1.5367596118073714, disc_loss = 0.016363048207846044
Trained batch 456 in epoch 0, gen_loss = 1.5367186304255178, disc_loss = 0.016338106812104274
Trained batch 457 in epoch 0, gen_loss = 1.5364936678690682, disc_loss = 0.01631019695984265
Trained batch 458 in epoch 0, gen_loss = 1.5364992073158812, disc_loss = 0.01628094471708013
Trained batch 459 in epoch 0, gen_loss = 1.5363635174606158, disc_loss = 0.016250946153836
Trained batch 460 in epoch 0, gen_loss = 1.536285759828613, disc_loss = 0.016220399898521344
Trained batch 461 in epoch 0, gen_loss = 1.5361249485573212, disc_loss = 0.01619066767574961
Trained batch 462 in epoch 0, gen_loss = 1.5361792773458922, disc_loss = 0.01616356389463294
Trained batch 463 in epoch 0, gen_loss = 1.535971775650978, disc_loss = 0.016137524796720065
Trained batch 464 in epoch 0, gen_loss = 1.5358085647706063, disc_loss = 0.016109174377565344
Trained batch 465 in epoch 0, gen_loss = 1.535653663551347, disc_loss = 0.016078807282423432
Trained batch 466 in epoch 0, gen_loss = 1.5355932753397514, disc_loss = 0.016047039719117005
Trained batch 467 in epoch 0, gen_loss = 1.5354761837894082, disc_loss = 0.016015109543153282
Trained batch 468 in epoch 0, gen_loss = 1.5353245750419113, disc_loss = 0.015983966301316457
Trained batch 469 in epoch 0, gen_loss = 1.5353180583487165, disc_loss = 0.015952610537568305
Trained batch 470 in epoch 0, gen_loss = 1.5352528477423764, disc_loss = 0.015921035345007058
Trained batch 471 in epoch 0, gen_loss = 1.5352858517129542, disc_loss = 0.01588922575369213
Trained batch 472 in epoch 0, gen_loss = 1.5353956393913286, disc_loss = 0.0158576169888042
Trained batch 473 in epoch 0, gen_loss = 1.5352055790052133, disc_loss = 0.015826662612847105
Trained batch 474 in epoch 0, gen_loss = 1.5350198120819896, disc_loss = 0.01579631743609513
Trained batch 475 in epoch 0, gen_loss = 1.53490710959715, disc_loss = 0.015765846216319396
Trained batch 476 in epoch 0, gen_loss = 1.5349956358503745, disc_loss = 0.015735616257796903
Trained batch 477 in epoch 0, gen_loss = 1.534988838259645, disc_loss = 0.015705782859722565
Trained batch 478 in epoch 0, gen_loss = 1.535040391014115, disc_loss = 0.0156757176215984
Trained batch 479 in epoch 0, gen_loss = 1.5348931620518367, disc_loss = 0.015645929686919167
Trained batch 480 in epoch 0, gen_loss = 1.534730604433468, disc_loss = 0.015616820805189113
Trained batch 481 in epoch 0, gen_loss = 1.5346563218540177, disc_loss = 0.015587586177951614
Trained batch 482 in epoch 0, gen_loss = 1.5346198067161607, disc_loss = 0.015558046245162702
Trained batch 483 in epoch 0, gen_loss = 1.5344384765822041, disc_loss = 0.01552857793910883
Trained batch 484 in epoch 0, gen_loss = 1.5344913067276944, disc_loss = 0.015499695940615283
Trained batch 485 in epoch 0, gen_loss = 1.534334681897497, disc_loss = 0.015470626182401928
Trained batch 486 in epoch 0, gen_loss = 1.5342597307855343, disc_loss = 0.015441545493254397
Trained batch 487 in epoch 0, gen_loss = 1.5342274452330635, disc_loss = 0.01541214112238195
Trained batch 488 in epoch 0, gen_loss = 1.5341322999790403, disc_loss = 0.01538316641766616
Trained batch 489 in epoch 0, gen_loss = 1.5342081919008372, disc_loss = 0.015354452178842027
Trained batch 490 in epoch 0, gen_loss = 1.5340021151874799, disc_loss = 0.015326256205587668
Trained batch 491 in epoch 0, gen_loss = 1.5340491838571502, disc_loss = 0.015299616266057138
Trained batch 492 in epoch 0, gen_loss = 1.534129280831219, disc_loss = 0.015273315234593366
Trained batch 493 in epoch 0, gen_loss = 1.5341613338543818, disc_loss = 0.015246511880979545
Trained batch 494 in epoch 0, gen_loss = 1.5339819900917284, disc_loss = 0.01521861531696461
Trained batch 495 in epoch 0, gen_loss = 1.533883230099755, disc_loss = 0.01518984210715937
Trained batch 496 in epoch 0, gen_loss = 1.5337932543975246, disc_loss = 0.015160873300401528
Trained batch 497 in epoch 0, gen_loss = 1.5337934984739525, disc_loss = 0.015132987131663864
Trained batch 498 in epoch 0, gen_loss = 1.5337204586766764, disc_loss = 0.015105084397126444
Trained batch 499 in epoch 0, gen_loss = 1.533657399892807, disc_loss = 0.015077181514818221
Trained batch 500 in epoch 0, gen_loss = 1.5335118299472832, disc_loss = 0.015049012026288538
Trained batch 501 in epoch 0, gen_loss = 1.5333152223393263, disc_loss = 0.015020821599031899
Trained batch 502 in epoch 0, gen_loss = 1.5333436580585913, disc_loss = 0.014992600291014777
Trained batch 503 in epoch 0, gen_loss = 1.5334612656207312, disc_loss = 0.014964916899135995
Trained batch 504 in epoch 0, gen_loss = 1.5334941552417114, disc_loss = 0.014937611062443899
Trained batch 505 in epoch 0, gen_loss = 1.533437512137673, disc_loss = 0.014909949684087665
Trained batch 506 in epoch 0, gen_loss = 1.5333535760582315, disc_loss = 0.014882130848351292
Trained batch 507 in epoch 0, gen_loss = 1.5332184635748074, disc_loss = 0.014854130389578604
Trained batch 508 in epoch 0, gen_loss = 1.5329946806482342, disc_loss = 0.014826414528351336
Trained batch 509 in epoch 0, gen_loss = 1.5328991450515448, disc_loss = 0.014800079044653103
Trained batch 510 in epoch 0, gen_loss = 1.5328110580108403, disc_loss = 0.014773783664817788
Trained batch 511 in epoch 0, gen_loss = 1.5329412268474698, disc_loss = 0.014747870045880518
Trained batch 512 in epoch 0, gen_loss = 1.532903747484233, disc_loss = 0.014721475625896306
Trained batch 513 in epoch 0, gen_loss = 1.5327704912957514, disc_loss = 0.014695061807740835
Trained batch 514 in epoch 0, gen_loss = 1.532587809238619, disc_loss = 0.014668620044469508
Trained batch 515 in epoch 0, gen_loss = 1.5326472502346187, disc_loss = 0.014644075924049623
Trained batch 516 in epoch 0, gen_loss = 1.5326107941005862, disc_loss = 0.01462103444504204
Trained batch 517 in epoch 0, gen_loss = 1.5325110177275758, disc_loss = 0.014598189491637475
Trained batch 518 in epoch 0, gen_loss = 1.5327132186908023, disc_loss = 0.014575528320860879
Trained batch 519 in epoch 0, gen_loss = 1.5326319224559344, disc_loss = 0.014552996534957157
Trained batch 520 in epoch 0, gen_loss = 1.532590982094836, disc_loss = 0.014531833023496952
Trained batch 521 in epoch 0, gen_loss = 1.5325705637420275, disc_loss = 0.014512386887893617
Trained batch 522 in epoch 0, gen_loss = 1.532471298943514, disc_loss = 0.014493070080156045
Trained batch 523 in epoch 0, gen_loss = 1.532457545513415, disc_loss = 0.014471784756916134
Trained batch 524 in epoch 0, gen_loss = 1.5322772071475075, disc_loss = 0.014447468309552364
Trained batch 525 in epoch 0, gen_loss = 1.532138308644748, disc_loss = 0.01442337202710744
Trained batch 526 in epoch 0, gen_loss = 1.5319942242732763, disc_loss = 0.01439930615711169
Trained batch 527 in epoch 0, gen_loss = 1.532013325528665, disc_loss = 0.014375658483693383
Trained batch 528 in epoch 0, gen_loss = 1.5319890842996609, disc_loss = 0.014352251652875538
Trained batch 529 in epoch 0, gen_loss = 1.5320149709593576, disc_loss = 0.014329809475501226
Trained batch 530 in epoch 0, gen_loss = 1.5320766549101432, disc_loss = 0.014307699717073517
Trained batch 531 in epoch 0, gen_loss = 1.5321721580243648, disc_loss = 0.014285139082270129
Trained batch 532 in epoch 0, gen_loss = 1.5322212177638042, disc_loss = 0.014261335575814214
Trained batch 533 in epoch 0, gen_loss = 1.5322677126984472, disc_loss = 0.014236923447249401
Trained batch 534 in epoch 0, gen_loss = 1.5323563167982013, disc_loss = 0.014212560133734353
Trained batch 535 in epoch 0, gen_loss = 1.5324729051607757, disc_loss = 0.014189494034964348
Trained batch 536 in epoch 0, gen_loss = 1.532470825664158, disc_loss = 0.014167311976059362
Trained batch 537 in epoch 0, gen_loss = 1.5323280539211288, disc_loss = 0.01414468797145768
Trained batch 538 in epoch 0, gen_loss = 1.532328738573531, disc_loss = 0.014123413706710648
Trained batch 539 in epoch 0, gen_loss = 1.5325189219580757, disc_loss = 0.014103512796336199
Trained batch 540 in epoch 0, gen_loss = 1.532484081888816, disc_loss = 0.014080469376582295
Trained batch 541 in epoch 0, gen_loss = 1.5325164614568336, disc_loss = 0.014056872433963028
Trained batch 542 in epoch 0, gen_loss = 1.5323807271145984, disc_loss = 0.014033408294724298
Trained batch 543 in epoch 0, gen_loss = 1.5324506093473995, disc_loss = 0.014011276622969651
Trained batch 544 in epoch 0, gen_loss = 1.532426737864083, disc_loss = 0.01398957523532263
Trained batch 545 in epoch 0, gen_loss = 1.5325810123275925, disc_loss = 0.013970307291006914
Trained batch 546 in epoch 0, gen_loss = 1.5326394712249365, disc_loss = 0.013952114927378982
Trained batch 547 in epoch 0, gen_loss = 1.532558850998426, disc_loss = 0.01393218827253313
Trained batch 548 in epoch 0, gen_loss = 1.5325415075802413, disc_loss = 0.013909995807898833
Trained batch 549 in epoch 0, gen_loss = 1.532538868080486, disc_loss = 0.01388695142454129
Trained batch 550 in epoch 0, gen_loss = 1.532627406873201, disc_loss = 0.013864120913558757
Trained batch 551 in epoch 0, gen_loss = 1.5327429635369259, disc_loss = 0.013841198822774459
Trained batch 552 in epoch 0, gen_loss = 1.5325934548490086, disc_loss = 0.013817982529108977
Trained batch 553 in epoch 0, gen_loss = 1.532579253942097, disc_loss = 0.01379460020888923
Trained batch 554 in epoch 0, gen_loss = 1.5326484950813086, disc_loss = 0.01377235638923725
Trained batch 555 in epoch 0, gen_loss = 1.5326219792846296, disc_loss = 0.013750713228866987
Trained batch 556 in epoch 0, gen_loss = 1.532425816012028, disc_loss = 0.013729270065351283
Trained batch 557 in epoch 0, gen_loss = 1.5323627347587256, disc_loss = 0.013709813923976388
Trained batch 558 in epoch 0, gen_loss = 1.532590201161202, disc_loss = 0.013691445843092532
Trained batch 559 in epoch 0, gen_loss = 1.5327967882156373, disc_loss = 0.013670782856830295
Trained batch 560 in epoch 0, gen_loss = 1.5326993901036852, disc_loss = 0.013649166603684725
Trained batch 561 in epoch 0, gen_loss = 1.5326453962784221, disc_loss = 0.013627637025765128
Trained batch 562 in epoch 0, gen_loss = 1.5326513094334577, disc_loss = 0.01360517936160285
Trained batch 563 in epoch 0, gen_loss = 1.5324943304484617, disc_loss = 0.01358232839792184
Trained batch 564 in epoch 0, gen_loss = 1.5324515787901076, disc_loss = 0.013559862285073583
Trained batch 565 in epoch 0, gen_loss = 1.5323543125243575, disc_loss = 0.01353783198283054
Trained batch 566 in epoch 0, gen_loss = 1.5324283409370947, disc_loss = 0.013516666186046236
Trained batch 567 in epoch 0, gen_loss = 1.5322457447018423, disc_loss = 0.01349543812174373
Trained batch 568 in epoch 0, gen_loss = 1.5322306116352182, disc_loss = 0.013474510388996334
Trained batch 569 in epoch 0, gen_loss = 1.532197734347561, disc_loss = 0.01345342352114242
Trained batch 570 in epoch 0, gen_loss = 1.532072214236819, disc_loss = 0.013432135504255342
Trained batch 571 in epoch 0, gen_loss = 1.53216108721453, disc_loss = 0.013410804391585427
Trained batch 572 in epoch 0, gen_loss = 1.5321091201292907, disc_loss = 0.013389072323565
Trained batch 573 in epoch 0, gen_loss = 1.5320776752893932, disc_loss = 0.0133671246812588
Trained batch 574 in epoch 0, gen_loss = 1.5320762321223382, disc_loss = 0.013346127270234992
Trained batch 575 in epoch 0, gen_loss = 1.5318920233597357, disc_loss = 0.01332498409525821
Trained batch 576 in epoch 0, gen_loss = 1.5319671515162319, disc_loss = 0.013303553130706866
Trained batch 577 in epoch 0, gen_loss = 1.5318558517211862, disc_loss = 0.013281803168469209
Trained batch 578 in epoch 0, gen_loss = 1.5317644484096653, disc_loss = 0.013259861198260364
Trained batch 579 in epoch 0, gen_loss = 1.5317230489747278, disc_loss = 0.013238451492587297
Trained batch 580 in epoch 0, gen_loss = 1.5315351430807589, disc_loss = 0.01321736608191895
Trained batch 581 in epoch 0, gen_loss = 1.531529095574343, disc_loss = 0.013197006203659852
Trained batch 582 in epoch 0, gen_loss = 1.531482818809627, disc_loss = 0.01317626096653284
Trained batch 583 in epoch 0, gen_loss = 1.5315071636275068, disc_loss = 0.013155248586633818
Trained batch 584 in epoch 0, gen_loss = 1.531535601004576, disc_loss = 0.013134925689898495
Trained batch 585 in epoch 0, gen_loss = 1.531566756577215, disc_loss = 0.013114360828825142
Trained batch 586 in epoch 0, gen_loss = 1.531511272847957, disc_loss = 0.013093363736427725
Trained batch 587 in epoch 0, gen_loss = 1.531677967228857, disc_loss = 0.013074239110890902
Trained batch 588 in epoch 0, gen_loss = 1.531737859058866, disc_loss = 0.013056699062439855
Trained batch 589 in epoch 0, gen_loss = 1.5316101581363355, disc_loss = 0.013039195554141524
Trained batch 590 in epoch 0, gen_loss = 1.5315499263366468, disc_loss = 0.013021346246240607
Trained batch 591 in epoch 0, gen_loss = 1.5315349166457717, disc_loss = 0.013003817698886819
Trained batch 592 in epoch 0, gen_loss = 1.5314338609299813, disc_loss = 0.01298719642151455
Trained batch 593 in epoch 0, gen_loss = 1.5316263722249555, disc_loss = 0.012972504372068804
Trained batch 594 in epoch 0, gen_loss = 1.5317072617907483, disc_loss = 0.0129587182716443
Trained batch 595 in epoch 0, gen_loss = 1.5319692262467122, disc_loss = 0.012944772707895319
Trained batch 596 in epoch 0, gen_loss = 1.5320956812831426, disc_loss = 0.01292948133056325
Trained batch 597 in epoch 0, gen_loss = 1.5321177601016884, disc_loss = 0.012912676072006666
Trained batch 598 in epoch 0, gen_loss = 1.5321114312030237, disc_loss = 0.012894585788116256
Trained batch 599 in epoch 0, gen_loss = 1.532010438243548, disc_loss = 0.012875268354740304
Trained batch 600 in epoch 0, gen_loss = 1.5320536027137135, disc_loss = 0.012855896265044523
Trained batch 601 in epoch 0, gen_loss = 1.531934958755772, disc_loss = 0.012836326519916905
Trained batch 602 in epoch 0, gen_loss = 1.531955624496561, disc_loss = 0.012817730205666403
Trained batch 603 in epoch 0, gen_loss = 1.5319994344616568, disc_loss = 0.012799441421231786
Trained batch 604 in epoch 0, gen_loss = 1.5319567601542827, disc_loss = 0.012780711934362992
Trained batch 605 in epoch 0, gen_loss = 1.5318765667798888, disc_loss = 0.012761435835128926
Trained batch 606 in epoch 0, gen_loss = 1.5318661030670366, disc_loss = 0.012741914908884974
Trained batch 607 in epoch 0, gen_loss = 1.531770245809304, disc_loss = 0.01272236891494877
Trained batch 608 in epoch 0, gen_loss = 1.5316934446591657, disc_loss = 0.01270284209477261
Trained batch 609 in epoch 0, gen_loss = 1.53181910378034, disc_loss = 0.012684030292009874
Trained batch 610 in epoch 0, gen_loss = 1.5318669502161528, disc_loss = 0.01266510604944388
Trained batch 611 in epoch 0, gen_loss = 1.5317875086482053, disc_loss = 0.012646279754394854
Trained batch 612 in epoch 0, gen_loss = 1.5317204708376289, disc_loss = 0.012627905433436136
Trained batch 613 in epoch 0, gen_loss = 1.5317257271915772, disc_loss = 0.012610049689729343
Trained batch 614 in epoch 0, gen_loss = 1.531640450547381, disc_loss = 0.012592527572902268
Trained batch 615 in epoch 0, gen_loss = 1.5314981949019741, disc_loss = 0.01257523569036895
Trained batch 616 in epoch 0, gen_loss = 1.5314151338472166, disc_loss = 0.012558195674040987
Trained batch 617 in epoch 0, gen_loss = 1.5312289923525937, disc_loss = 0.012541108877450064
Trained batch 618 in epoch 0, gen_loss = 1.531134145710503, disc_loss = 0.012524056706223216
Trained batch 619 in epoch 0, gen_loss = 1.5309830054160087, disc_loss = 0.012507193719671529
Trained batch 620 in epoch 0, gen_loss = 1.5310003888011938, disc_loss = 0.012490173642528836
Trained batch 621 in epoch 0, gen_loss = 1.530892472750121, disc_loss = 0.012472816758397577
Trained batch 622 in epoch 0, gen_loss = 1.5307702828754775, disc_loss = 0.012454680683346164
Trained batch 623 in epoch 0, gen_loss = 1.5306518939443123, disc_loss = 0.01243661918450902
Trained batch 624 in epoch 0, gen_loss = 1.5306639890670777, disc_loss = 0.012419210844580085
Trained batch 625 in epoch 0, gen_loss = 1.5306394641010905, disc_loss = 0.012401777930790558
Trained batch 626 in epoch 0, gen_loss = 1.530547291468205, disc_loss = 0.012383582625902768
Trained batch 627 in epoch 0, gen_loss = 1.530401400699737, disc_loss = 0.012365128100882314
Trained batch 628 in epoch 0, gen_loss = 1.5304159458566735, disc_loss = 0.012346654594764825
Trained batch 629 in epoch 0, gen_loss = 1.5303651385837131, disc_loss = 0.01232819367857975
Trained batch 630 in epoch 0, gen_loss = 1.5303149710744384, disc_loss = 0.012309562640888956
Trained batch 631 in epoch 0, gen_loss = 1.5302857926374749, disc_loss = 0.012291046398705832
Trained batch 632 in epoch 0, gen_loss = 1.5301444334629777, disc_loss = 0.012272623136432143
Trained batch 633 in epoch 0, gen_loss = 1.5300921594682928, disc_loss = 0.0122543048272967
Trained batch 634 in epoch 0, gen_loss = 1.5299425994317362, disc_loss = 0.012236127904689628
Trained batch 635 in epoch 0, gen_loss = 1.5300704745001763, disc_loss = 0.012218853728018361
Trained batch 636 in epoch 0, gen_loss = 1.530007160626925, disc_loss = 0.012201401575547432
Trained batch 637 in epoch 0, gen_loss = 1.5300844634961932, disc_loss = 0.012184089154434218
Trained batch 638 in epoch 0, gen_loss = 1.5299330263257214, disc_loss = 0.012166503972701104
Trained batch 639 in epoch 0, gen_loss = 1.5297306502237915, disc_loss = 0.012149119879632053
Trained batch 640 in epoch 0, gen_loss = 1.5297841142380666, disc_loss = 0.012132722694174694
Trained batch 641 in epoch 0, gen_loss = 1.529752988681615, disc_loss = 0.01211731086967069
Trained batch 642 in epoch 0, gen_loss = 1.5297055689394938, disc_loss = 0.012102503396956682
Trained batch 643 in epoch 0, gen_loss = 1.529579059122512, disc_loss = 0.01208779142718684
Trained batch 644 in epoch 0, gen_loss = 1.5296383746834687, disc_loss = 0.012073149424598573
Trained batch 645 in epoch 0, gen_loss = 1.529629570411824, disc_loss = 0.012057175887290867
Trained batch 646 in epoch 0, gen_loss = 1.5295923561364457, disc_loss = 0.01204020979533899
Trained batch 647 in epoch 0, gen_loss = 1.5294646225225779, disc_loss = 0.012022943465261185
Trained batch 648 in epoch 0, gen_loss = 1.529517213258611, disc_loss = 0.01200588085899956
Trained batch 649 in epoch 0, gen_loss = 1.5294770407676697, disc_loss = 0.011989348172478808
Trained batch 650 in epoch 0, gen_loss = 1.5293699151359945, disc_loss = 0.011973155923055402
Trained batch 651 in epoch 0, gen_loss = 1.5295305189910842, disc_loss = 0.011957583177539782
Trained batch 652 in epoch 0, gen_loss = 1.5294200866547332, disc_loss = 0.01194143876820948
Trained batch 653 in epoch 0, gen_loss = 1.529319172605462, disc_loss = 0.0119246770779991
Trained batch 654 in epoch 0, gen_loss = 1.5292824683298591, disc_loss = 0.011908033139246538
Trained batch 655 in epoch 0, gen_loss = 1.5292148168494062, disc_loss = 0.011891570982786617
Trained batch 656 in epoch 0, gen_loss = 1.5291237000098148, disc_loss = 0.01187523349733666
Trained batch 657 in epoch 0, gen_loss = 1.5289735542242289, disc_loss = 0.011859152954808468
Trained batch 658 in epoch 0, gen_loss = 1.5289593616638995, disc_loss = 0.011843843298928165
Trained batch 659 in epoch 0, gen_loss = 1.5291146141110044, disc_loss = 0.011829550971301752
Trained batch 660 in epoch 0, gen_loss = 1.5290631697866812, disc_loss = 0.011815465983118207
Trained batch 661 in epoch 0, gen_loss = 1.5290001288641615, disc_loss = 0.011801707340538743
Trained batch 662 in epoch 0, gen_loss = 1.5288907503470397, disc_loss = 0.01178772700520311
Trained batch 663 in epoch 0, gen_loss = 1.5287792334355503, disc_loss = 0.011772505016012133
Trained batch 664 in epoch 0, gen_loss = 1.5288290948796093, disc_loss = 0.011756985173718234
Trained batch 665 in epoch 0, gen_loss = 1.528735416071551, disc_loss = 0.011741401611491002
Trained batch 666 in epoch 0, gen_loss = 1.5285609715703368, disc_loss = 0.011725542895377906
Trained batch 667 in epoch 0, gen_loss = 1.5285092196064796, disc_loss = 0.011709514110712306
Trained batch 668 in epoch 0, gen_loss = 1.5284566079198156, disc_loss = 0.01169341488101663
Trained batch 669 in epoch 0, gen_loss = 1.5285025021923122, disc_loss = 0.011677321197409461
Trained batch 670 in epoch 0, gen_loss = 1.5284664389273448, disc_loss = 0.011661214254405793
Trained batch 671 in epoch 0, gen_loss = 1.5284938285393375, disc_loss = 0.011645340672094747
Trained batch 672 in epoch 0, gen_loss = 1.5284089980118343, disc_loss = 0.011629103987638938
Trained batch 673 in epoch 0, gen_loss = 1.5283045791730683, disc_loss = 0.01161281988537699
Trained batch 674 in epoch 0, gen_loss = 1.5282957290720056, disc_loss = 0.011596774124730102
Trained batch 675 in epoch 0, gen_loss = 1.5282216585246768, disc_loss = 0.0115806791155059
Trained batch 676 in epoch 0, gen_loss = 1.5282019822248856, disc_loss = 0.011564633715313143
Trained batch 677 in epoch 0, gen_loss = 1.5281060401317292, disc_loss = 0.01154857458101014
Trained batch 678 in epoch 0, gen_loss = 1.528150210675505, disc_loss = 0.011532584496908197
Trained batch 679 in epoch 0, gen_loss = 1.5280158773941153, disc_loss = 0.011516669349957202
Trained batch 680 in epoch 0, gen_loss = 1.5280311319446425, disc_loss = 0.011501734349609964
Trained batch 681 in epoch 0, gen_loss = 1.5281318917302442, disc_loss = 0.01148684705826768
Trained batch 682 in epoch 0, gen_loss = 1.5281512124646635, disc_loss = 0.01147172680328495
Trained batch 683 in epoch 0, gen_loss = 1.5280559411522938, disc_loss = 0.01145651077457475
Trained batch 684 in epoch 0, gen_loss = 1.5280075139372888, disc_loss = 0.011441156273388242
Trained batch 685 in epoch 0, gen_loss = 1.5279525506253144, disc_loss = 0.011425710498062085
Trained batch 686 in epoch 0, gen_loss = 1.527842420851473, disc_loss = 0.01141026239059974
Trained batch 687 in epoch 0, gen_loss = 1.5277495399810548, disc_loss = 0.011394735323593459
Trained batch 688 in epoch 0, gen_loss = 1.527619816222281, disc_loss = 0.011379851033476537
Trained batch 689 in epoch 0, gen_loss = 1.527429381142492, disc_loss = 0.01136617472140537
Trained batch 690 in epoch 0, gen_loss = 1.5275361410270725, disc_loss = 0.01135329622514182
Trained batch 691 in epoch 0, gen_loss = 1.5273418436849737, disc_loss = 0.011340406919561051
Trained batch 692 in epoch 0, gen_loss = 1.5273964962401947, disc_loss = 0.011326996064029263
Trained batch 693 in epoch 0, gen_loss = 1.5273179660956524, disc_loss = 0.011312527732936376
Trained batch 694 in epoch 0, gen_loss = 1.5272017549267776, disc_loss = 0.011297630270852593
Trained batch 695 in epoch 0, gen_loss = 1.5272060915313919, disc_loss = 0.011283195674323728
Trained batch 696 in epoch 0, gen_loss = 1.5271668938687406, disc_loss = 0.011269320291984783
Trained batch 697 in epoch 0, gen_loss = 1.5271168827668986, disc_loss = 0.0112559994954361
Trained batch 698 in epoch 0, gen_loss = 1.5270436275670456, disc_loss = 0.01124234039621902
Trained batch 699 in epoch 0, gen_loss = 1.5271365668092456, disc_loss = 0.011228806379700213
Trained batch 700 in epoch 0, gen_loss = 1.5272293966608959, disc_loss = 0.011215258579446765
Trained batch 701 in epoch 0, gen_loss = 1.5272037388592363, disc_loss = 0.01120106525564277
Trained batch 702 in epoch 0, gen_loss = 1.5272126728576074, disc_loss = 0.011186287441548586
Trained batch 703 in epoch 0, gen_loss = 1.5270994385196404, disc_loss = 0.01117119935224764
Trained batch 704 in epoch 0, gen_loss = 1.5270608340594785, disc_loss = 0.011156272314115699
Trained batch 705 in epoch 0, gen_loss = 1.5269500625032204, disc_loss = 0.011142067469161125
Trained batch 706 in epoch 0, gen_loss = 1.5268757849130805, disc_loss = 0.011128659525183405
Trained batch 707 in epoch 0, gen_loss = 1.5269527719855982, disc_loss = 0.011115204813606684
Trained batch 708 in epoch 0, gen_loss = 1.5268061011399132, disc_loss = 0.011101141881262712
Trained batch 709 in epoch 0, gen_loss = 1.5268746802504634, disc_loss = 0.011087152251439221
Trained batch 710 in epoch 0, gen_loss = 1.5268929715565656, disc_loss = 0.011073090908633029
Trained batch 711 in epoch 0, gen_loss = 1.5267986484457938, disc_loss = 0.011058843643450325
Trained batch 712 in epoch 0, gen_loss = 1.5268550256860205, disc_loss = 0.011044859497410834
Trained batch 713 in epoch 0, gen_loss = 1.5267147755756432, disc_loss = 0.011030540740605266
Trained batch 714 in epoch 0, gen_loss = 1.5266795293434516, disc_loss = 0.011017935948081679
Trained batch 715 in epoch 0, gen_loss = 1.5267541080546778, disc_loss = 0.011007665799912482
Trained batch 716 in epoch 0, gen_loss = 1.5266272055720351, disc_loss = 0.010998251661203667
Trained batch 717 in epoch 0, gen_loss = 1.5266249086863484, disc_loss = 0.010988744044180928
Trained batch 718 in epoch 0, gen_loss = 1.5266292277562934, disc_loss = 0.010978675768963256
Trained batch 719 in epoch 0, gen_loss = 1.5265894840161005, disc_loss = 0.010968076995535132
Trained batch 720 in epoch 0, gen_loss = 1.5265081550476456, disc_loss = 0.010956917862613245
Trained batch 721 in epoch 0, gen_loss = 1.5265157341626872, disc_loss = 0.010944456655346373
Trained batch 722 in epoch 0, gen_loss = 1.526453170538938, disc_loss = 0.010930530871422433
Trained batch 723 in epoch 0, gen_loss = 1.526434711165191, disc_loss = 0.010917140200759222
Trained batch 724 in epoch 0, gen_loss = 1.5263416581318296, disc_loss = 0.01090505424975257
Trained batch 725 in epoch 0, gen_loss = 1.5263470018862364, disc_loss = 0.010893936267301578
Trained batch 726 in epoch 0, gen_loss = 1.5262806505743707, disc_loss = 0.010882588121588464
Trained batch 727 in epoch 0, gen_loss = 1.5263517533357327, disc_loss = 0.010870677363597609
Trained batch 728 in epoch 0, gen_loss = 1.52621568099625, disc_loss = 0.010858486867934563
Trained batch 729 in epoch 0, gen_loss = 1.5261182979361652, disc_loss = 0.010846625539164812
Trained batch 730 in epoch 0, gen_loss = 1.5261327972490386, disc_loss = 0.010834805525583883
Trained batch 731 in epoch 0, gen_loss = 1.5260152751630773, disc_loss = 0.010822455983757183
Trained batch 732 in epoch 0, gen_loss = 1.5259556020590976, disc_loss = 0.010809810794740636
Trained batch 733 in epoch 0, gen_loss = 1.5258803276664878, disc_loss = 0.010797062985886431
Trained batch 734 in epoch 0, gen_loss = 1.5258974576482967, disc_loss = 0.010784015326592818
Trained batch 735 in epoch 0, gen_loss = 1.5257645348167939, disc_loss = 0.010771062373390558
Trained batch 736 in epoch 0, gen_loss = 1.5256862700228129, disc_loss = 0.01075947908405025
Trained batch 737 in epoch 0, gen_loss = 1.5257367824474324, disc_loss = 0.010748605511001713
Trained batch 738 in epoch 0, gen_loss = 1.5256243266659273, disc_loss = 0.010736107445559534
Trained batch 739 in epoch 0, gen_loss = 1.5256632178216367, disc_loss = 0.010722588269257087
Trained batch 740 in epoch 0, gen_loss = 1.5256521463715917, disc_loss = 0.010709360147390877
Trained batch 741 in epoch 0, gen_loss = 1.525557096756372, disc_loss = 0.01069623644095331
Trained batch 742 in epoch 0, gen_loss = 1.5255162815386643, disc_loss = 0.010682862166604867
Trained batch 743 in epoch 0, gen_loss = 1.5255155739604787, disc_loss = 0.010669925652559526
Trained batch 744 in epoch 0, gen_loss = 1.5254577961544062, disc_loss = 0.010657756996884843
Trained batch 745 in epoch 0, gen_loss = 1.5254173155764152, disc_loss = 0.010646056374797134
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 1.476379632949829, disc_loss = 0.0014785191742703319
Trained batch 1 in epoch 1, gen_loss = 1.4529314637184143, disc_loss = 0.0013912453432567418
Trained batch 2 in epoch 1, gen_loss = 1.4507643779118855, disc_loss = 0.0013980437458182375
Trained batch 3 in epoch 1, gen_loss = 1.4633634984493256, disc_loss = 0.0013687466562259942
Trained batch 4 in epoch 1, gen_loss = 1.471614670753479, disc_loss = 0.0013902097707614303
Trained batch 5 in epoch 1, gen_loss = 1.48526527484258, disc_loss = 0.0014206609727504353
Trained batch 6 in epoch 1, gen_loss = 1.4833924600056239, disc_loss = 0.001345110874223922
Trained batch 7 in epoch 1, gen_loss = 1.4840789586305618, disc_loss = 0.0013250515185063705
Trained batch 8 in epoch 1, gen_loss = 1.4904503557417128, disc_loss = 0.0013120955813469158
Trained batch 9 in epoch 1, gen_loss = 1.4885594844818115, disc_loss = 0.0012482761463616042
Trained batch 10 in epoch 1, gen_loss = 1.4950042746283791, disc_loss = 0.001309319690335542
Trained batch 11 in epoch 1, gen_loss = 1.4929434259732564, disc_loss = 0.0015795659225356455
Trained batch 12 in epoch 1, gen_loss = 1.489925815508916, disc_loss = 0.0019173988526185544
Trained batch 13 in epoch 1, gen_loss = 1.4898016367639815, disc_loss = 0.0021434093650896102
Trained batch 14 in epoch 1, gen_loss = 1.485656476020813, disc_loss = 0.0021570207822757463
Trained batch 15 in epoch 1, gen_loss = 1.4843035861849785, disc_loss = 0.0020914629094477277
Trained batch 16 in epoch 1, gen_loss = 1.4836514276616715, disc_loss = 0.0020541117067777496
Trained batch 17 in epoch 1, gen_loss = 1.4823916885587904, disc_loss = 0.0020187083379520723
Trained batch 18 in epoch 1, gen_loss = 1.4866330309918052, disc_loss = 0.0019948478500162693
Trained batch 19 in epoch 1, gen_loss = 1.483716207742691, disc_loss = 0.002031124048517086
Trained batch 20 in epoch 1, gen_loss = 1.48699604897272, disc_loss = 0.002178753584822906
Trained batch 21 in epoch 1, gen_loss = 1.4849155816164883, disc_loss = 0.0023786648605230516
Trained batch 22 in epoch 1, gen_loss = 1.4864938103634378, disc_loss = 0.002517318649156748
Trained batch 23 in epoch 1, gen_loss = 1.4837753077348073, disc_loss = 0.0025439623398900344
Trained batch 24 in epoch 1, gen_loss = 1.4859748268127442, disc_loss = 0.0025187343382276593
Trained batch 25 in epoch 1, gen_loss = 1.4854432023488557, disc_loss = 0.0025576006267398884
Trained batch 26 in epoch 1, gen_loss = 1.488539457321167, disc_loss = 0.002672578029213818
Trained batch 27 in epoch 1, gen_loss = 1.490223262991224, disc_loss = 0.002763954982843383
Trained batch 28 in epoch 1, gen_loss = 1.4878528529200061, disc_loss = 0.0027567031893654375
Trained batch 29 in epoch 1, gen_loss = 1.4870207111040752, disc_loss = 0.0027337773023949313
Trained batch 30 in epoch 1, gen_loss = 1.4878358571760115, disc_loss = 0.002752228769578881
Trained batch 31 in epoch 1, gen_loss = 1.4867862574756145, disc_loss = 0.002755931907813647
Trained batch 32 in epoch 1, gen_loss = 1.4888273947166675, disc_loss = 0.0027318991822980797
Trained batch 33 in epoch 1, gen_loss = 1.4896086173899032, disc_loss = 0.0026951562664608527
Trained batch 34 in epoch 1, gen_loss = 1.4903289999280658, disc_loss = 0.002658903364291681
Trained batch 35 in epoch 1, gen_loss = 1.490877264075809, disc_loss = 0.0026137443993421686
Trained batch 36 in epoch 1, gen_loss = 1.4918034785502665, disc_loss = 0.002569853112642729
Trained batch 37 in epoch 1, gen_loss = 1.4910045768085278, disc_loss = 0.002521136337523594
Trained batch 38 in epoch 1, gen_loss = 1.491840090507116, disc_loss = 0.002472775877835468
Trained batch 39 in epoch 1, gen_loss = 1.4926475495100022, disc_loss = 0.002425631336518563
Trained batch 40 in epoch 1, gen_loss = 1.4940207760508468, disc_loss = 0.002378915868154386
Trained batch 41 in epoch 1, gen_loss = 1.4940424419584728, disc_loss = 0.002330331342472207
Trained batch 42 in epoch 1, gen_loss = 1.4937834933746692, disc_loss = 0.0022862516194690277
Trained batch 43 in epoch 1, gen_loss = 1.4960681118748405, disc_loss = 0.002254695791634731
Trained batch 44 in epoch 1, gen_loss = 1.4962891870074801, disc_loss = 0.002226127563820531
Trained batch 45 in epoch 1, gen_loss = 1.4952487090359563, disc_loss = 0.0021972197535670484
Trained batch 46 in epoch 1, gen_loss = 1.4966342576006626, disc_loss = 0.0021690600687895526
Trained batch 47 in epoch 1, gen_loss = 1.496162287890911, disc_loss = 0.002141990828628574
Trained batch 48 in epoch 1, gen_loss = 1.4970757158435122, disc_loss = 0.002124349138823015
Trained batch 49 in epoch 1, gen_loss = 1.4982165431976318, disc_loss = 0.002111993896542117
Trained batch 50 in epoch 1, gen_loss = 1.4968966198902505, disc_loss = 0.0020977438772188535
Trained batch 51 in epoch 1, gen_loss = 1.4982868616397564, disc_loss = 0.002085863302524488
Trained batch 52 in epoch 1, gen_loss = 1.4981348199664422, disc_loss = 0.0020721858874718957
Trained batch 53 in epoch 1, gen_loss = 1.499598968912054, disc_loss = 0.0020549269533215986
Trained batch 54 in epoch 1, gen_loss = 1.5006977514787154, disc_loss = 0.002030658162071962
Trained batch 55 in epoch 1, gen_loss = 1.4998688719102315, disc_loss = 0.002006064267854007
Trained batch 56 in epoch 1, gen_loss = 1.4996238695947748, disc_loss = 0.0019823544293135534
Trained batch 57 in epoch 1, gen_loss = 1.4992753904441307, disc_loss = 0.0019588488443144435
Trained batch 58 in epoch 1, gen_loss = 1.498610450049578, disc_loss = 0.001933963016322735
Trained batch 59 in epoch 1, gen_loss = 1.5000865439573923, disc_loss = 0.0019154167996020988
Trained batch 60 in epoch 1, gen_loss = 1.5004312894383416, disc_loss = 0.0019049590260752278
Trained batch 61 in epoch 1, gen_loss = 1.500401529573625, disc_loss = 0.0019034494452493927
Trained batch 62 in epoch 1, gen_loss = 1.5004559017363048, disc_loss = 0.0019057622624723803
Trained batch 63 in epoch 1, gen_loss = 1.4997839108109474, disc_loss = 0.0019071459219048847
Trained batch 64 in epoch 1, gen_loss = 1.4999685764312745, disc_loss = 0.0019029114798356135
Trained batch 65 in epoch 1, gen_loss = 1.5013068517049153, disc_loss = 0.0018964559765828942
Trained batch 66 in epoch 1, gen_loss = 1.5009661396937584, disc_loss = 0.001888155204820822
Trained batch 67 in epoch 1, gen_loss = 1.5010035967125612, disc_loss = 0.0018786048535463016
Trained batch 68 in epoch 1, gen_loss = 1.5006028793860173, disc_loss = 0.0018635871651433947
Trained batch 69 in epoch 1, gen_loss = 1.5008087805339267, disc_loss = 0.0018462984041044755
Trained batch 70 in epoch 1, gen_loss = 1.5011927963982166, disc_loss = 0.001828960249607097
Trained batch 71 in epoch 1, gen_loss = 1.5014246586296294, disc_loss = 0.001810247136745602
Trained batch 72 in epoch 1, gen_loss = 1.501419485431828, disc_loss = 0.0017910784613564355
Trained batch 73 in epoch 1, gen_loss = 1.5018354042156323, disc_loss = 0.0017721577330391753
Trained batch 74 in epoch 1, gen_loss = 1.5013265577952066, disc_loss = 0.0017528114452337225
Trained batch 75 in epoch 1, gen_loss = 1.5009401660216481, disc_loss = 0.0017348066712178192
Trained batch 76 in epoch 1, gen_loss = 1.5009228641336614, disc_loss = 0.0017182552716815723
Trained batch 77 in epoch 1, gen_loss = 1.501112944040543, disc_loss = 0.0017054608630505987
Trained batch 78 in epoch 1, gen_loss = 1.5000336683249171, disc_loss = 0.0016974657516089515
Trained batch 79 in epoch 1, gen_loss = 1.4989352971315384, disc_loss = 0.0016928148579609115
Trained batch 80 in epoch 1, gen_loss = 1.499793557473171, disc_loss = 0.0016946389309682505
Trained batch 81 in epoch 1, gen_loss = 1.500108449924283, disc_loss = 0.0016968191917928889
Trained batch 82 in epoch 1, gen_loss = 1.4997643203620452, disc_loss = 0.0016986736656076848
Trained batch 83 in epoch 1, gen_loss = 1.4992891933236803, disc_loss = 0.0017000275166494595
Trained batch 84 in epoch 1, gen_loss = 1.4991320006987627, disc_loss = 0.0016960071954492699
Trained batch 85 in epoch 1, gen_loss = 1.4994073219077533, disc_loss = 0.0016901560952118056
Trained batch 86 in epoch 1, gen_loss = 1.4988057846310494, disc_loss = 0.0016852787946051136
Trained batch 87 in epoch 1, gen_loss = 1.4986509504643353, disc_loss = 0.0016887697956090878
Trained batch 88 in epoch 1, gen_loss = 1.4995338488160894, disc_loss = 0.0017042391916496282
Trained batch 89 in epoch 1, gen_loss = 1.499770704905192, disc_loss = 0.001720141385966498
Trained batch 90 in epoch 1, gen_loss = 1.5006416996756753, disc_loss = 0.0017270590376958332
Trained batch 91 in epoch 1, gen_loss = 1.5003951217817224, disc_loss = 0.0017217797076623158
Trained batch 92 in epoch 1, gen_loss = 1.5004236749423447, disc_loss = 0.0017126902546082694
Trained batch 93 in epoch 1, gen_loss = 1.500563752143941, disc_loss = 0.0017028155704425212
Trained batch 94 in epoch 1, gen_loss = 1.500935979893333, disc_loss = 0.0016943317733852095
Trained batch 95 in epoch 1, gen_loss = 1.501620002090931, disc_loss = 0.0016845837823590652
Trained batch 96 in epoch 1, gen_loss = 1.5010454900485952, disc_loss = 0.001674579454648318
Trained batch 97 in epoch 1, gen_loss = 1.5012527533939906, disc_loss = 0.0016665182311601024
Trained batch 98 in epoch 1, gen_loss = 1.5007725123203162, disc_loss = 0.0016595925359676282
Trained batch 99 in epoch 1, gen_loss = 1.5005362677574157, disc_loss = 0.001650913447374478
Trained batch 100 in epoch 1, gen_loss = 1.5005821567950863, disc_loss = 0.0016421660836232772
Trained batch 101 in epoch 1, gen_loss = 1.50103169445898, disc_loss = 0.0016321141818337434
Trained batch 102 in epoch 1, gen_loss = 1.5005321930913091, disc_loss = 0.0016218696300446698
Trained batch 103 in epoch 1, gen_loss = 1.5001441469559302, disc_loss = 0.0016129338966073613
Trained batch 104 in epoch 1, gen_loss = 1.4998507261276246, disc_loss = 0.0016034159232817945
Trained batch 105 in epoch 1, gen_loss = 1.4995261127094053, disc_loss = 0.001592902713213643
Trained batch 106 in epoch 1, gen_loss = 1.4996594012340652, disc_loss = 0.0015824864793647184
Trained batch 107 in epoch 1, gen_loss = 1.4997717682962064, disc_loss = 0.0015717464487318433
Trained batch 108 in epoch 1, gen_loss = 1.5001335811177525, disc_loss = 0.0015627522167852234
Trained batch 109 in epoch 1, gen_loss = 1.5011766878041355, disc_loss = 0.0015541353765663438
Trained batch 110 in epoch 1, gen_loss = 1.5014090495066599, disc_loss = 0.0015444134205772734
Trained batch 111 in epoch 1, gen_loss = 1.5010013931563921, disc_loss = 0.0015349856127743675
Trained batch 112 in epoch 1, gen_loss = 1.500448252247498, disc_loss = 0.001525913403818664
Trained batch 113 in epoch 1, gen_loss = 1.5004241100528783, disc_loss = 0.001517599483792621
Trained batch 114 in epoch 1, gen_loss = 1.5001920617145041, disc_loss = 0.001508396422824539
Trained batch 115 in epoch 1, gen_loss = 1.5001241893603885, disc_loss = 0.0014996562097402257
Trained batch 116 in epoch 1, gen_loss = 1.50020659275544, disc_loss = 0.0014915019455345937
Trained batch 117 in epoch 1, gen_loss = 1.5006207348936695, disc_loss = 0.001484455839953764
Trained batch 118 in epoch 1, gen_loss = 1.5002605013486718, disc_loss = 0.0014790035238853429
Trained batch 119 in epoch 1, gen_loss = 1.5010630319515863, disc_loss = 0.001478112569748191
Trained batch 120 in epoch 1, gen_loss = 1.500696498500414, disc_loss = 0.001478800235733713
Trained batch 121 in epoch 1, gen_loss = 1.5002987502051182, disc_loss = 0.0014813045255904712
Trained batch 122 in epoch 1, gen_loss = 1.4998947740570316, disc_loss = 0.001484113365148641
Trained batch 123 in epoch 1, gen_loss = 1.4997516351361428, disc_loss = 0.0014862671155095731
Trained batch 124 in epoch 1, gen_loss = 1.5004941883087157, disc_loss = 0.0014878343634773046
Trained batch 125 in epoch 1, gen_loss = 1.499824569338844, disc_loss = 0.0014891458293219792
Trained batch 126 in epoch 1, gen_loss = 1.4997189777103934, disc_loss = 0.0014914645958695502
Trained batch 127 in epoch 1, gen_loss = 1.499465610831976, disc_loss = 0.0014937196376649808
Trained batch 128 in epoch 1, gen_loss = 1.499651168667993, disc_loss = 0.0014933695777070296
Trained batch 129 in epoch 1, gen_loss = 1.499033938921415, disc_loss = 0.0014888456111433557
Trained batch 130 in epoch 1, gen_loss = 1.498784828732032, disc_loss = 0.0014831182355405975
Trained batch 131 in epoch 1, gen_loss = 1.4989536332361626, disc_loss = 0.001477137728546619
Trained batch 132 in epoch 1, gen_loss = 1.4983814757569391, disc_loss = 0.0014704034720193875
Trained batch 133 in epoch 1, gen_loss = 1.497620589697539, disc_loss = 0.0014631381076360955
Trained batch 134 in epoch 1, gen_loss = 1.4980780707465278, disc_loss = 0.0014575380734944095
Trained batch 135 in epoch 1, gen_loss = 1.4978401853757746, disc_loss = 0.0014516456219151972
Trained batch 136 in epoch 1, gen_loss = 1.4971632409269793, disc_loss = 0.0014459486401989974
Trained batch 137 in epoch 1, gen_loss = 1.4970431241436282, disc_loss = 0.0014399505818036614
Trained batch 138 in epoch 1, gen_loss = 1.4966147975098314, disc_loss = 0.0014333270137154718
Trained batch 139 in epoch 1, gen_loss = 1.4961099650178638, disc_loss = 0.001426406975951977
Trained batch 140 in epoch 1, gen_loss = 1.495906338624075, disc_loss = 0.001418986119551201
Trained batch 141 in epoch 1, gen_loss = 1.4961642018506225, disc_loss = 0.0014116548655167694
Trained batch 142 in epoch 1, gen_loss = 1.4961676289151598, disc_loss = 0.0014050541532313829
Trained batch 143 in epoch 1, gen_loss = 1.4962438825103972, disc_loss = 0.001398232549440258
Trained batch 144 in epoch 1, gen_loss = 1.4962160422884185, disc_loss = 0.0013923408493704708
Trained batch 145 in epoch 1, gen_loss = 1.4963967457209548, disc_loss = 0.0013870819436293733
Trained batch 146 in epoch 1, gen_loss = 1.4960945577037579, disc_loss = 0.0013810597115820338
Trained batch 147 in epoch 1, gen_loss = 1.4957536322039526, disc_loss = 0.0013748343518346774
Trained batch 148 in epoch 1, gen_loss = 1.4957065870297834, disc_loss = 0.0013686771754209803
Trained batch 149 in epoch 1, gen_loss = 1.4960588343938193, disc_loss = 0.0013636160228634253
Trained batch 150 in epoch 1, gen_loss = 1.4958672831390079, disc_loss = 0.0013586097654797113
Trained batch 151 in epoch 1, gen_loss = 1.4961665484466051, disc_loss = 0.0013537692133181018
Trained batch 152 in epoch 1, gen_loss = 1.4962188301522747, disc_loss = 0.0013481166795447006
Trained batch 153 in epoch 1, gen_loss = 1.4958234003611974, disc_loss = 0.0013423748416433038
Trained batch 154 in epoch 1, gen_loss = 1.4955737067807104, disc_loss = 0.0013368617660636383
Trained batch 155 in epoch 1, gen_loss = 1.4951530580337231, disc_loss = 0.0013319276503096216
Trained batch 156 in epoch 1, gen_loss = 1.4955858569236318, disc_loss = 0.0013276878195654625
Trained batch 157 in epoch 1, gen_loss = 1.495937471148334, disc_loss = 0.001323203173468974
Trained batch 158 in epoch 1, gen_loss = 1.4954838737751703, disc_loss = 0.0013178882460730772
Trained batch 159 in epoch 1, gen_loss = 1.495330798625946, disc_loss = 0.0013127832782629412
Trained batch 160 in epoch 1, gen_loss = 1.4957085588703984, disc_loss = 0.0013082841366402202
Trained batch 161 in epoch 1, gen_loss = 1.4955289363861084, disc_loss = 0.001303575869741631
Trained batch 162 in epoch 1, gen_loss = 1.4954144428112754, disc_loss = 0.0012995253675588709
Trained batch 163 in epoch 1, gen_loss = 1.4955134973293398, disc_loss = 0.001296380534058255
Trained batch 164 in epoch 1, gen_loss = 1.4954269654823071, disc_loss = 0.00129295998591591
Trained batch 165 in epoch 1, gen_loss = 1.4955180854682464, disc_loss = 0.0012885274159362965
Trained batch 166 in epoch 1, gen_loss = 1.4949248429543958, disc_loss = 0.0012839327613031212
Trained batch 167 in epoch 1, gen_loss = 1.4945634255806606, disc_loss = 0.0012804097478649403
Trained batch 168 in epoch 1, gen_loss = 1.4951337660558126, disc_loss = 0.0012780578973008727
Trained batch 169 in epoch 1, gen_loss = 1.4947891130166895, disc_loss = 0.001275120224625639
Trained batch 170 in epoch 1, gen_loss = 1.4949339516678748, disc_loss = 0.0012721242842656608
Trained batch 171 in epoch 1, gen_loss = 1.494645045940266, disc_loss = 0.0012697482026090066
Trained batch 172 in epoch 1, gen_loss = 1.4947832078602963, disc_loss = 0.0012724430840650863
Trained batch 173 in epoch 1, gen_loss = 1.4945040002636525, disc_loss = 0.0012799687011183464
Trained batch 174 in epoch 1, gen_loss = 1.4945751878193447, disc_loss = 0.0012895018457701165
Trained batch 175 in epoch 1, gen_loss = 1.4946186461231925, disc_loss = 0.0012984605309611652
Trained batch 176 in epoch 1, gen_loss = 1.494305276601328, disc_loss = 0.001304081798660027
Trained batch 177 in epoch 1, gen_loss = 1.4941716314701552, disc_loss = 0.001306170512323027
Trained batch 178 in epoch 1, gen_loss = 1.4945104361912391, disc_loss = 0.0013051715893436786
Trained batch 179 in epoch 1, gen_loss = 1.4947592973709107, disc_loss = 0.0013032402348471805
Trained batch 180 in epoch 1, gen_loss = 1.4950145963805814, disc_loss = 0.0013015067976004141
Trained batch 181 in epoch 1, gen_loss = 1.4953769661568024, disc_loss = 0.0012997968629601278
Trained batch 182 in epoch 1, gen_loss = 1.4952391718254714, disc_loss = 0.0012988555598164313
Trained batch 183 in epoch 1, gen_loss = 1.4947949634945912, disc_loss = 0.001298223652828829
Trained batch 184 in epoch 1, gen_loss = 1.4950774360347439, disc_loss = 0.0012975141855988753
Trained batch 185 in epoch 1, gen_loss = 1.4953173315653236, disc_loss = 0.001298935287469317
Trained batch 186 in epoch 1, gen_loss = 1.4950113392131215, disc_loss = 0.001303325368298148
Trained batch 187 in epoch 1, gen_loss = 1.4947835720599967, disc_loss = 0.0013085034192277197
Trained batch 188 in epoch 1, gen_loss = 1.494378995012354, disc_loss = 0.001312671960688753
Trained batch 189 in epoch 1, gen_loss = 1.4941785216331482, disc_loss = 0.001315651736896191
Trained batch 190 in epoch 1, gen_loss = 1.4941422708371548, disc_loss = 0.0013170801660811519
Trained batch 191 in epoch 1, gen_loss = 1.4941214720408122, disc_loss = 0.0013166077026956675
Trained batch 192 in epoch 1, gen_loss = 1.4942748904845875, disc_loss = 0.001313524987847771
Trained batch 193 in epoch 1, gen_loss = 1.4944474525058393, disc_loss = 0.0013094882378186646
Trained batch 194 in epoch 1, gen_loss = 1.493952946173839, disc_loss = 0.0013068399296548123
Trained batch 195 in epoch 1, gen_loss = 1.4941016867452739, disc_loss = 0.0013076317418195611
Trained batch 196 in epoch 1, gen_loss = 1.493797648981743, disc_loss = 0.0013110682446282678
Trained batch 197 in epoch 1, gen_loss = 1.4937811487852926, disc_loss = 0.0013157501699158339
Trained batch 198 in epoch 1, gen_loss = 1.4935075733529863, disc_loss = 0.0013211074299249218
Trained batch 199 in epoch 1, gen_loss = 1.4932850539684295, disc_loss = 0.0013248303986620159
Trained batch 200 in epoch 1, gen_loss = 1.4933859412349872, disc_loss = 0.0013255475295142303
Trained batch 201 in epoch 1, gen_loss = 1.4933353509053144, disc_loss = 0.0013234393505753008
Trained batch 202 in epoch 1, gen_loss = 1.49314504773746, disc_loss = 0.0013199034711836924
Trained batch 203 in epoch 1, gen_loss = 1.493300115360933, disc_loss = 0.0013161508424102567
Trained batch 204 in epoch 1, gen_loss = 1.4934571330140276, disc_loss = 0.0013121330125325519
Trained batch 205 in epoch 1, gen_loss = 1.4937676729507816, disc_loss = 0.001307899089280326
Trained batch 206 in epoch 1, gen_loss = 1.4939035424863658, disc_loss = 0.0013038472775516105
Trained batch 207 in epoch 1, gen_loss = 1.4938860633052313, disc_loss = 0.0012999189016577124
Trained batch 208 in epoch 1, gen_loss = 1.493826900372665, disc_loss = 0.0012964140605705046
Trained batch 209 in epoch 1, gen_loss = 1.4934937772296724, disc_loss = 0.0012931522995045053
Trained batch 210 in epoch 1, gen_loss = 1.4933624256278666, disc_loss = 0.0012891143062471974
Trained batch 211 in epoch 1, gen_loss = 1.4932160473094795, disc_loss = 0.0012852460002353116
Trained batch 212 in epoch 1, gen_loss = 1.4934028857190844, disc_loss = 0.0012820485836942134
Trained batch 213 in epoch 1, gen_loss = 1.4930193608052262, disc_loss = 0.0012789070164234263
Trained batch 214 in epoch 1, gen_loss = 1.4930790618408558, disc_loss = 0.0012766534222972167
Trained batch 215 in epoch 1, gen_loss = 1.4933608715180997, disc_loss = 0.0012754645386950062
Trained batch 216 in epoch 1, gen_loss = 1.49297981602805, disc_loss = 0.0012738284184693998
Trained batch 217 in epoch 1, gen_loss = 1.493279432484863, disc_loss = 0.001271243221975581
Trained batch 218 in epoch 1, gen_loss = 1.493401388599448, disc_loss = 0.0012686952099907872
Trained batch 219 in epoch 1, gen_loss = 1.493434581973336, disc_loss = 0.0012661812116593037
Trained batch 220 in epoch 1, gen_loss = 1.4935579720665426, disc_loss = 0.0012648758188477925
Trained batch 221 in epoch 1, gen_loss = 1.493429737585085, disc_loss = 0.001264753549958596
Trained batch 222 in epoch 1, gen_loss = 1.4933855576365518, disc_loss = 0.0012637409970170563
Trained batch 223 in epoch 1, gen_loss = 1.492809942258256, disc_loss = 0.0012627782638706517
Trained batch 224 in epoch 1, gen_loss = 1.492937955326504, disc_loss = 0.001262793588426171
Trained batch 225 in epoch 1, gen_loss = 1.492924142200335, disc_loss = 0.0012636777842613101
Trained batch 226 in epoch 1, gen_loss = 1.4931999140373935, disc_loss = 0.0012632417819505796
Trained batch 227 in epoch 1, gen_loss = 1.4930021276599483, disc_loss = 0.00126139681468199
Trained batch 228 in epoch 1, gen_loss = 1.4930188093643522, disc_loss = 0.0012595540876693487
Trained batch 229 in epoch 1, gen_loss = 1.4926727699196858, disc_loss = 0.0012593833918166954
Trained batch 230 in epoch 1, gen_loss = 1.4928709892999559, disc_loss = 0.0012607641728016351
Trained batch 231 in epoch 1, gen_loss = 1.4928613474656796, disc_loss = 0.0012613352462659381
Trained batch 232 in epoch 1, gen_loss = 1.492766801379781, disc_loss = 0.0012616790145837458
Trained batch 233 in epoch 1, gen_loss = 1.4927746378458464, disc_loss = 0.0012604726024984948
Trained batch 234 in epoch 1, gen_loss = 1.4931684458509404, disc_loss = 0.001259082025338083
Trained batch 235 in epoch 1, gen_loss = 1.493204532033306, disc_loss = 0.0012573481430605416
Trained batch 236 in epoch 1, gen_loss = 1.493039578325135, disc_loss = 0.0012551649783802796
Trained batch 237 in epoch 1, gen_loss = 1.492792996037908, disc_loss = 0.0012523367451435393
Trained batch 238 in epoch 1, gen_loss = 1.4924584512431252, disc_loss = 0.0012490882172451888
Trained batch 239 in epoch 1, gen_loss = 1.4925575961669286, disc_loss = 0.001245728714275174
Trained batch 240 in epoch 1, gen_loss = 1.4923466483587051, disc_loss = 0.0012423800315642228
Trained batch 241 in epoch 1, gen_loss = 1.492571684447202, disc_loss = 0.0012401267578286573
Trained batch 242 in epoch 1, gen_loss = 1.4923556169855252, disc_loss = 0.0012397894754607246
Trained batch 243 in epoch 1, gen_loss = 1.4921017518786133, disc_loss = 0.0012416145936051596
Trained batch 244 in epoch 1, gen_loss = 1.49197572737324, disc_loss = 0.0012453131330180532
Trained batch 245 in epoch 1, gen_loss = 1.4917391611308586, disc_loss = 0.0012508233066466524
Trained batch 246 in epoch 1, gen_loss = 1.4917099722001235, disc_loss = 0.0012566879304947882
Trained batch 247 in epoch 1, gen_loss = 1.4918306719872259, disc_loss = 0.001260863481870582
Trained batch 248 in epoch 1, gen_loss = 1.4918114947506702, disc_loss = 0.0012617153545699444
Trained batch 249 in epoch 1, gen_loss = 1.4917379050254822, disc_loss = 0.001260335854953155
Trained batch 250 in epoch 1, gen_loss = 1.4915886048776694, disc_loss = 0.0012576554566102317
Trained batch 251 in epoch 1, gen_loss = 1.49184420941368, disc_loss = 0.0012545842709230435
Trained batch 252 in epoch 1, gen_loss = 1.4917569075648494, disc_loss = 0.0012511340823031874
Trained batch 253 in epoch 1, gen_loss = 1.4914760246990233, disc_loss = 0.00124822134623216
Trained batch 254 in epoch 1, gen_loss = 1.491318829386842, disc_loss = 0.0012473468508973134
Trained batch 255 in epoch 1, gen_loss = 1.4913509371690452, disc_loss = 0.0012473400429371395
Trained batch 256 in epoch 1, gen_loss = 1.4912412625806342, disc_loss = 0.0012462395098393761
Trained batch 257 in epoch 1, gen_loss = 1.491339812445086, disc_loss = 0.0012446128056644527
Trained batch 258 in epoch 1, gen_loss = 1.4910919914834748, disc_loss = 0.0012428166727269335
Trained batch 259 in epoch 1, gen_loss = 1.4909544738439413, disc_loss = 0.0012404398421774834
Trained batch 260 in epoch 1, gen_loss = 1.4910276301519167, disc_loss = 0.0012376518448158184
Trained batch 261 in epoch 1, gen_loss = 1.4907788192952862, disc_loss = 0.0012348579700044464
Trained batch 262 in epoch 1, gen_loss = 1.4907679036542942, disc_loss = 0.0012322724982742007
Trained batch 263 in epoch 1, gen_loss = 1.4907246986121843, disc_loss = 0.00123027245431193
Trained batch 264 in epoch 1, gen_loss = 1.490627208295858, disc_loss = 0.00122898765795706
Trained batch 265 in epoch 1, gen_loss = 1.490875148235407, disc_loss = 0.0012281592278846336
Trained batch 266 in epoch 1, gen_loss = 1.4908668713623219, disc_loss = 0.0012267256091952267
Trained batch 267 in epoch 1, gen_loss = 1.4908125111416204, disc_loss = 0.0012250432578252573
Trained batch 268 in epoch 1, gen_loss = 1.490970230900222, disc_loss = 0.0012230695059547222
Trained batch 269 in epoch 1, gen_loss = 1.490794993771447, disc_loss = 0.0012213993936138986
Trained batch 270 in epoch 1, gen_loss = 1.4909026108104804, disc_loss = 0.0012204272359372477
Trained batch 271 in epoch 1, gen_loss = 1.4907775280230187, disc_loss = 0.0012193657331569258
Trained batch 272 in epoch 1, gen_loss = 1.4907327846729712, disc_loss = 0.001218109447491993
Trained batch 273 in epoch 1, gen_loss = 1.4908351641501822, disc_loss = 0.0012165671673324639
Trained batch 274 in epoch 1, gen_loss = 1.4906434271552347, disc_loss = 0.0012147077827037059
Trained batch 275 in epoch 1, gen_loss = 1.4904377447522206, disc_loss = 0.0012131796462673938
Trained batch 276 in epoch 1, gen_loss = 1.4904546974368045, disc_loss = 0.0012117577044273111
Trained batch 277 in epoch 1, gen_loss = 1.490231508831326, disc_loss = 0.0012098680739877276
Trained batch 278 in epoch 1, gen_loss = 1.490179325090087, disc_loss = 0.0012075281656083506
Trained batch 279 in epoch 1, gen_loss = 1.4902981353657587, disc_loss = 0.0012051875166694767
Trained batch 280 in epoch 1, gen_loss = 1.4906242559813097, disc_loss = 0.0012037272542695188
Trained batch 281 in epoch 1, gen_loss = 1.490372951571823, disc_loss = 0.0012051756085055148
Trained batch 282 in epoch 1, gen_loss = 1.4905494283029133, disc_loss = 0.0012105995531657928
Trained batch 283 in epoch 1, gen_loss = 1.490442328469854, disc_loss = 0.001217567378697707
Trained batch 284 in epoch 1, gen_loss = 1.4905633754897536, disc_loss = 0.0012236011349351
Trained batch 285 in epoch 1, gen_loss = 1.4904359895866235, disc_loss = 0.0012275692896910949
Trained batch 286 in epoch 1, gen_loss = 1.4902389415049802, disc_loss = 0.0012300466069666092
Trained batch 287 in epoch 1, gen_loss = 1.4904031389289432, disc_loss = 0.0012309906996961217
Trained batch 288 in epoch 1, gen_loss = 1.4904091354059925, disc_loss = 0.0012304460006253633
Trained batch 289 in epoch 1, gen_loss = 1.4903318310606068, disc_loss = 0.0012289417556342508
Trained batch 290 in epoch 1, gen_loss = 1.4901228741681862, disc_loss = 0.0012272442663024432
Trained batch 291 in epoch 1, gen_loss = 1.4899927193987859, disc_loss = 0.0012252478232792235
Trained batch 292 in epoch 1, gen_loss = 1.4898971860319274, disc_loss = 0.0012228407647934306
Trained batch 293 in epoch 1, gen_loss = 1.4897874674829497, disc_loss = 0.0012198369521418029
Trained batch 294 in epoch 1, gen_loss = 1.4897304049992965, disc_loss = 0.001216810467353059
Trained batch 295 in epoch 1, gen_loss = 1.4897992699532896, disc_loss = 0.001214142404244961
Trained batch 296 in epoch 1, gen_loss = 1.4898591029523598, disc_loss = 0.0012119475353088995
Trained batch 297 in epoch 1, gen_loss = 1.490001757272938, disc_loss = 0.0012099796702191483
Trained batch 298 in epoch 1, gen_loss = 1.4900279443798257, disc_loss = 0.0012074562434393626
Trained batch 299 in epoch 1, gen_loss = 1.4898986546198527, disc_loss = 0.0012049167561538829
Trained batch 300 in epoch 1, gen_loss = 1.4897957897661531, disc_loss = 0.0012026028136182824
Trained batch 301 in epoch 1, gen_loss = 1.4896458537373323, disc_loss = 0.0012000448166644077
Trained batch 302 in epoch 1, gen_loss = 1.4894505310373338, disc_loss = 0.0011979858025027864
Trained batch 303 in epoch 1, gen_loss = 1.490011215209961, disc_loss = 0.0011983267432745044
Trained batch 304 in epoch 1, gen_loss = 1.489538083310987, disc_loss = 0.0012018335970752246
Trained batch 305 in epoch 1, gen_loss = 1.4895734841527501, disc_loss = 0.0012093492355798768
Trained batch 306 in epoch 1, gen_loss = 1.4895709679258762, disc_loss = 0.001219184205663339
Trained batch 307 in epoch 1, gen_loss = 1.4893615810902088, disc_loss = 0.0012276052952216417
Trained batch 308 in epoch 1, gen_loss = 1.4892798654469857, disc_loss = 0.0012336359294334842
Trained batch 309 in epoch 1, gen_loss = 1.4892624808895973, disc_loss = 0.0012357647097932414
Trained batch 310 in epoch 1, gen_loss = 1.4891694032877587, disc_loss = 0.0012357400304831001
Trained batch 311 in epoch 1, gen_loss = 1.4889505096735098, disc_loss = 0.0012376464996449589
Trained batch 312 in epoch 1, gen_loss = 1.4890572761956113, disc_loss = 0.0012413759859235653
Trained batch 313 in epoch 1, gen_loss = 1.4888778450382743, disc_loss = 0.0012446483143918204
Trained batch 314 in epoch 1, gen_loss = 1.4887577302872188, disc_loss = 0.0012461913449298
Trained batch 315 in epoch 1, gen_loss = 1.4886300114891198, disc_loss = 0.0012455464518869213
Trained batch 316 in epoch 1, gen_loss = 1.488424525652022, disc_loss = 0.0012443326133610357
Trained batch 317 in epoch 1, gen_loss = 1.488336795156107, disc_loss = 0.0012424735636296595
Trained batch 318 in epoch 1, gen_loss = 1.488260787108849, disc_loss = 0.0012402373995029055
Trained batch 319 in epoch 1, gen_loss = 1.4884088426828384, disc_loss = 0.00123821819679506
Trained batch 320 in epoch 1, gen_loss = 1.4886266279072033, disc_loss = 0.0012361553795541408
Trained batch 321 in epoch 1, gen_loss = 1.4887843935385994, disc_loss = 0.0012342075350721836
Trained batch 322 in epoch 1, gen_loss = 1.4886732389314257, disc_loss = 0.0012318375798831794
Trained batch 323 in epoch 1, gen_loss = 1.488733051367748, disc_loss = 0.001229834916838301
Trained batch 324 in epoch 1, gen_loss = 1.4887297091117273, disc_loss = 0.001228056847780513
Trained batch 325 in epoch 1, gen_loss = 1.4886997718752528, disc_loss = 0.0012263903867323351
Trained batch 326 in epoch 1, gen_loss = 1.48858026554096, disc_loss = 0.0012248050319479454
Trained batch 327 in epoch 1, gen_loss = 1.4885389012534445, disc_loss = 0.0012234545222493513
Trained batch 328 in epoch 1, gen_loss = 1.4887650882581809, disc_loss = 0.001221497672044539
Trained batch 329 in epoch 1, gen_loss = 1.4886195807745963, disc_loss = 0.0012194663788029699
Trained batch 330 in epoch 1, gen_loss = 1.488685628798793, disc_loss = 0.0012185290288581059
Trained batch 331 in epoch 1, gen_loss = 1.4888869186481797, disc_loss = 0.0012180163825375409
Trained batch 332 in epoch 1, gen_loss = 1.4889461228081413, disc_loss = 0.0012174353340686811
Trained batch 333 in epoch 1, gen_loss = 1.488947490375199, disc_loss = 0.0012163782294827073
Trained batch 334 in epoch 1, gen_loss = 1.4888049919213822, disc_loss = 0.0012150779511577992
Trained batch 335 in epoch 1, gen_loss = 1.4887401057141167, disc_loss = 0.0012137585093850724
Trained batch 336 in epoch 1, gen_loss = 1.4885992253923275, disc_loss = 0.0012123080604199807
Trained batch 337 in epoch 1, gen_loss = 1.4885384570917435, disc_loss = 0.0012107065603441487
Trained batch 338 in epoch 1, gen_loss = 1.4884521511100386, disc_loss = 0.0012086535966920784
Trained batch 339 in epoch 1, gen_loss = 1.4882320228744956, disc_loss = 0.0012068178724696148
Trained batch 340 in epoch 1, gen_loss = 1.4881302562277339, disc_loss = 0.0012055926218313435
Trained batch 341 in epoch 1, gen_loss = 1.488244378775881, disc_loss = 0.0012041234088093532
Trained batch 342 in epoch 1, gen_loss = 1.4883019402840394, disc_loss = 0.00120196192338316
Trained batch 343 in epoch 1, gen_loss = 1.488260886696882, disc_loss = 0.0011995353533441016
Trained batch 344 in epoch 1, gen_loss = 1.4882345745528953, disc_loss = 0.0011972051018518328
Trained batch 345 in epoch 1, gen_loss = 1.488423428094456, disc_loss = 0.001195023129973426
Trained batch 346 in epoch 1, gen_loss = 1.4883288863069386, disc_loss = 0.0011931147488600357
Trained batch 347 in epoch 1, gen_loss = 1.4884688628130947, disc_loss = 0.0011933825002018437
Trained batch 348 in epoch 1, gen_loss = 1.4884871305913843, disc_loss = 0.0011968747451654596
Trained batch 349 in epoch 1, gen_loss = 1.4885002177102225, disc_loss = 0.0012023884050514815
Trained batch 350 in epoch 1, gen_loss = 1.4885140789879694, disc_loss = 0.001205437412625444
Trained batch 351 in epoch 1, gen_loss = 1.4886962588537822, disc_loss = 0.0012053831433976566
Trained batch 352 in epoch 1, gen_loss = 1.4886877871100017, disc_loss = 0.0012039944301814464
Trained batch 353 in epoch 1, gen_loss = 1.4886944714912587, disc_loss = 0.001201962777311482
Trained batch 354 in epoch 1, gen_loss = 1.4886654796734662, disc_loss = 0.001199953719681706
Trained batch 355 in epoch 1, gen_loss = 1.4885597530375705, disc_loss = 0.001198082608435685
Trained batch 356 in epoch 1, gen_loss = 1.4886042654347353, disc_loss = 0.0011963525839007775
Trained batch 357 in epoch 1, gen_loss = 1.4886135612120175, disc_loss = 0.0011955112936371916
Trained batch 358 in epoch 1, gen_loss = 1.4884725045360894, disc_loss = 0.0011951084477174509
Trained batch 359 in epoch 1, gen_loss = 1.488547799653477, disc_loss = 0.0011944362711801659
Trained batch 360 in epoch 1, gen_loss = 1.4885119070967148, disc_loss = 0.001192941566348112
Trained batch 361 in epoch 1, gen_loss = 1.48842211553405, disc_loss = 0.0011918440594457511
Trained batch 362 in epoch 1, gen_loss = 1.4884655518308487, disc_loss = 0.0011922897439553934
Trained batch 363 in epoch 1, gen_loss = 1.4885025106288574, disc_loss = 0.0011945078195012583
Trained batch 364 in epoch 1, gen_loss = 1.4886595405944407, disc_loss = 0.001197620668234814
Trained batch 365 in epoch 1, gen_loss = 1.4885467580758809, disc_loss = 0.0012015228948073686
Trained batch 366 in epoch 1, gen_loss = 1.488610753896126, disc_loss = 0.0012052980929959504
Trained batch 367 in epoch 1, gen_loss = 1.4884591552874316, disc_loss = 0.0012080870618893127
Trained batch 368 in epoch 1, gen_loss = 1.4885124927613793, disc_loss = 0.0012103498107747385
Trained batch 369 in epoch 1, gen_loss = 1.4885209537841178, disc_loss = 0.001212330618196771
Trained batch 370 in epoch 1, gen_loss = 1.488631150150556, disc_loss = 0.0012132707539088572
Trained batch 371 in epoch 1, gen_loss = 1.4885555137229223, disc_loss = 0.0012133136421838846
Trained batch 372 in epoch 1, gen_loss = 1.4887562689768405, disc_loss = 0.0012132560821960434
Trained batch 373 in epoch 1, gen_loss = 1.4886633479658933, disc_loss = 0.001212569236345116
Trained batch 374 in epoch 1, gen_loss = 1.4886432123184203, disc_loss = 0.0012121192230066906
Trained batch 375 in epoch 1, gen_loss = 1.4885139306809039, disc_loss = 0.0012115857352910098
Trained batch 376 in epoch 1, gen_loss = 1.4885030368278767, disc_loss = 0.0012110859160750008
Trained batch 377 in epoch 1, gen_loss = 1.4884459215497214, disc_loss = 0.001210279896791911
Trained batch 378 in epoch 1, gen_loss = 1.4883449606027326, disc_loss = 0.0012087156108579302
Trained batch 379 in epoch 1, gen_loss = 1.4883981494527114, disc_loss = 0.001206829724450424
Trained batch 380 in epoch 1, gen_loss = 1.4883573590301153, disc_loss = 0.0012049164029181718
Trained batch 381 in epoch 1, gen_loss = 1.4883025703629897, disc_loss = 0.0012026876886954278
Trained batch 382 in epoch 1, gen_loss = 1.4883817499673708, disc_loss = 0.0012005280242660193
Trained batch 383 in epoch 1, gen_loss = 1.4885553233325481, disc_loss = 0.0011984610738030217
Trained batch 384 in epoch 1, gen_loss = 1.4884726895914449, disc_loss = 0.0011959830069968888
Trained batch 385 in epoch 1, gen_loss = 1.488589648138056, disc_loss = 0.0011936719715565085
Trained batch 386 in epoch 1, gen_loss = 1.488433110313514, disc_loss = 0.0011917741093706359
Trained batch 387 in epoch 1, gen_loss = 1.4883535805436754, disc_loss = 0.0011900707861959463
Trained batch 388 in epoch 1, gen_loss = 1.4883985078120292, disc_loss = 0.0011882793898532612
Trained batch 389 in epoch 1, gen_loss = 1.488406923184028, disc_loss = 0.0011861353332791717
Trained batch 390 in epoch 1, gen_loss = 1.488401429122671, disc_loss = 0.0011840211932429487
Trained batch 391 in epoch 1, gen_loss = 1.488441224913208, disc_loss = 0.0011825092199670712
Trained batch 392 in epoch 1, gen_loss = 1.488405271644204, disc_loss = 0.0011816748050450284
Trained batch 393 in epoch 1, gen_loss = 1.488353017017926, disc_loss = 0.0011812829713751963
Trained batch 394 in epoch 1, gen_loss = 1.4885317005688632, disc_loss = 0.0011808815529375466
Trained batch 395 in epoch 1, gen_loss = 1.4885654049088257, disc_loss = 0.0011807616847547269
Trained batch 396 in epoch 1, gen_loss = 1.488493635612411, disc_loss = 0.0011796588065678614
Trained batch 397 in epoch 1, gen_loss = 1.4887614951061843, disc_loss = 0.0011789812348828646
Trained batch 398 in epoch 1, gen_loss = 1.488758793749606, disc_loss = 0.0011781121744630732
Trained batch 399 in epoch 1, gen_loss = 1.488594157397747, disc_loss = 0.0011774926580983447
Trained batch 400 in epoch 1, gen_loss = 1.4886330544502657, disc_loss = 0.0011766789881820254
Trained batch 401 in epoch 1, gen_loss = 1.488617352881835, disc_loss = 0.0011757611311116111
Trained batch 402 in epoch 1, gen_loss = 1.4885489263250573, disc_loss = 0.0011752703769170626
Trained batch 403 in epoch 1, gen_loss = 1.4885567146362644, disc_loss = 0.0011752720388133163
Trained batch 404 in epoch 1, gen_loss = 1.4886484684767547, disc_loss = 0.001175468154668371
Trained batch 405 in epoch 1, gen_loss = 1.4885993784871594, disc_loss = 0.0011758558203958278
Trained batch 406 in epoch 1, gen_loss = 1.488566620344026, disc_loss = 0.0011755816444110456
Trained batch 407 in epoch 1, gen_loss = 1.4886094869351854, disc_loss = 0.0011746918708548252
Trained batch 408 in epoch 1, gen_loss = 1.488420935306689, disc_loss = 0.0011740889866901265
Trained batch 409 in epoch 1, gen_loss = 1.4885371865295782, disc_loss = 0.001173603639259321
Trained batch 410 in epoch 1, gen_loss = 1.488540652314532, disc_loss = 0.0011729713356708133
Trained batch 411 in epoch 1, gen_loss = 1.4883631441778349, disc_loss = 0.0011719667177689172
Trained batch 412 in epoch 1, gen_loss = 1.4885814735444927, disc_loss = 0.0011707804880762298
Trained batch 413 in epoch 1, gen_loss = 1.4885304190110469, disc_loss = 0.0011693350054747718
Trained batch 414 in epoch 1, gen_loss = 1.488602717813239, disc_loss = 0.0011678599311369863
Trained batch 415 in epoch 1, gen_loss = 1.4884968362748623, disc_loss = 0.0011665166921375203
Trained batch 416 in epoch 1, gen_loss = 1.4885500200646673, disc_loss = 0.001165974511900622
Trained batch 417 in epoch 1, gen_loss = 1.4884214917438452, disc_loss = 0.00116567667978916
Trained batch 418 in epoch 1, gen_loss = 1.4882358904385624, disc_loss = 0.0011650833588394698
Trained batch 419 in epoch 1, gen_loss = 1.4881209966682252, disc_loss = 0.001163893023303466
Trained batch 420 in epoch 1, gen_loss = 1.4882838292812792, disc_loss = 0.0011631728638977813
Trained batch 421 in epoch 1, gen_loss = 1.4884271666901936, disc_loss = 0.0011636566016100286
Trained batch 422 in epoch 1, gen_loss = 1.4884426269689068, disc_loss = 0.001164447973951825
Trained batch 423 in epoch 1, gen_loss = 1.4885444922267266, disc_loss = 0.001164232312115722
Trained batch 424 in epoch 1, gen_loss = 1.488494286817663, disc_loss = 0.0011633165690856165
Trained batch 425 in epoch 1, gen_loss = 1.488521032490081, disc_loss = 0.0011625599790120742
Trained batch 426 in epoch 1, gen_loss = 1.4884389055417349, disc_loss = 0.0011620069395252384
Trained batch 427 in epoch 1, gen_loss = 1.4884588306195268, disc_loss = 0.001161472893863477
Trained batch 428 in epoch 1, gen_loss = 1.4884466769256237, disc_loss = 0.0011608162814114103
Trained batch 429 in epoch 1, gen_loss = 1.4884213807970978, disc_loss = 0.0011600296071941727
Trained batch 430 in epoch 1, gen_loss = 1.488348406318169, disc_loss = 0.0011589339814227714
Trained batch 431 in epoch 1, gen_loss = 1.4882659616845626, disc_loss = 0.0011577067569440394
Trained batch 432 in epoch 1, gen_loss = 1.4879924265396787, disc_loss = 0.0011571047854621616
Trained batch 433 in epoch 1, gen_loss = 1.4880878760518017, disc_loss = 0.0011566128793804506
Trained batch 434 in epoch 1, gen_loss = 1.4878842079776458, disc_loss = 0.0011554489715758112
Trained batch 435 in epoch 1, gen_loss = 1.487864580449708, disc_loss = 0.001153516479345453
Trained batch 436 in epoch 1, gen_loss = 1.4878879259052757, disc_loss = 0.001151534443528304
Trained batch 437 in epoch 1, gen_loss = 1.4877521289538032, disc_loss = 0.0011496144838867173
Trained batch 438 in epoch 1, gen_loss = 1.4876781786221307, disc_loss = 0.0011477250498952874
Trained batch 439 in epoch 1, gen_loss = 1.4875076445666227, disc_loss = 0.0011460726818768308
Trained batch 440 in epoch 1, gen_loss = 1.4875367158124235, disc_loss = 0.0011462211989546342
Trained batch 441 in epoch 1, gen_loss = 1.4875546308124767, disc_loss = 0.0011483679361729904
Trained batch 442 in epoch 1, gen_loss = 1.4875633913022939, disc_loss = 0.0011511756578653747
Trained batch 443 in epoch 1, gen_loss = 1.4875727411325987, disc_loss = 0.001154185516333946
Trained batch 444 in epoch 1, gen_loss = 1.4873345814394148, disc_loss = 0.0011569352540595646
Trained batch 445 in epoch 1, gen_loss = 1.4873417190906713, disc_loss = 0.0011581113142266268
Trained batch 446 in epoch 1, gen_loss = 1.4871957848802775, disc_loss = 0.0011581415576147752
Trained batch 447 in epoch 1, gen_loss = 1.4871344571667058, disc_loss = 0.001157793886834822
Trained batch 448 in epoch 1, gen_loss = 1.4872550311226622, disc_loss = 0.001157254907162549
Trained batch 449 in epoch 1, gen_loss = 1.487128534581926, disc_loss = 0.0011569889017846436
Trained batch 450 in epoch 1, gen_loss = 1.487130285366676, disc_loss = 0.0011581554346792235
Trained batch 451 in epoch 1, gen_loss = 1.4872407559799936, disc_loss = 0.0011604891283039944
Trained batch 452 in epoch 1, gen_loss = 1.4871690715385588, disc_loss = 0.0011625716124278869
Trained batch 453 in epoch 1, gen_loss = 1.4872460851060136, disc_loss = 0.0011634975083281043
Trained batch 454 in epoch 1, gen_loss = 1.4873987155956225, disc_loss = 0.0011635909830527073
Trained batch 455 in epoch 1, gen_loss = 1.4872460514307022, disc_loss = 0.0011633139338779362
Trained batch 456 in epoch 1, gen_loss = 1.487163719776162, disc_loss = 0.0011632886303321783
Trained batch 457 in epoch 1, gen_loss = 1.4871904532461708, disc_loss = 0.0011629261315127175
Trained batch 458 in epoch 1, gen_loss = 1.4871519772835027, disc_loss = 0.0011620650455722898
Trained batch 459 in epoch 1, gen_loss = 1.4870746622914854, disc_loss = 0.0011610623323814134
Trained batch 460 in epoch 1, gen_loss = 1.4870543728164376, disc_loss = 0.0011598149959983833
Trained batch 461 in epoch 1, gen_loss = 1.487002029047384, disc_loss = 0.001158274508719393
Trained batch 462 in epoch 1, gen_loss = 1.4869482568736725, disc_loss = 0.001156483597404245
Trained batch 463 in epoch 1, gen_loss = 1.4868916242287076, disc_loss = 0.001154770240991011
Trained batch 464 in epoch 1, gen_loss = 1.486875666341474, disc_loss = 0.0011535724207523568
Trained batch 465 in epoch 1, gen_loss = 1.4868504284789121, disc_loss = 0.0011529443961545193
Trained batch 466 in epoch 1, gen_loss = 1.4868070333877008, disc_loss = 0.0011523769240715687
Trained batch 467 in epoch 1, gen_loss = 1.4867818251124814, disc_loss = 0.0011516138508893016
Trained batch 468 in epoch 1, gen_loss = 1.4867204043910955, disc_loss = 0.0011507049699980162
Trained batch 469 in epoch 1, gen_loss = 1.4865501236408314, disc_loss = 0.001150270070610667
Trained batch 470 in epoch 1, gen_loss = 1.4867072945694002, disc_loss = 0.0011502567306333944
Trained batch 471 in epoch 1, gen_loss = 1.486559934030145, disc_loss = 0.0011506519394199625
Trained batch 472 in epoch 1, gen_loss = 1.48644079970507, disc_loss = 0.0011523145907012112
Trained batch 473 in epoch 1, gen_loss = 1.4863844576767224, disc_loss = 0.0011545416450433488
Trained batch 474 in epoch 1, gen_loss = 1.4862791583412571, disc_loss = 0.001155764548978033
Trained batch 475 in epoch 1, gen_loss = 1.4860308067638333, disc_loss = 0.0011564834679143323
Trained batch 476 in epoch 1, gen_loss = 1.4860122323785938, disc_loss = 0.0011566772100157388
Trained batch 477 in epoch 1, gen_loss = 1.485832526843418, disc_loss = 0.001156540847104335
Trained batch 478 in epoch 1, gen_loss = 1.486026879641109, disc_loss = 0.0011563119458473075
Trained batch 479 in epoch 1, gen_loss = 1.4859615037838618, disc_loss = 0.0011555040025389947
Trained batch 480 in epoch 1, gen_loss = 1.4859599105533592, disc_loss = 0.0011543612868506693
Trained batch 481 in epoch 1, gen_loss = 1.4858992854094604, disc_loss = 0.0011533907558735174
Trained batch 482 in epoch 1, gen_loss = 1.4860497123212795, disc_loss = 0.0011526346079524083
Trained batch 483 in epoch 1, gen_loss = 1.4860870803683257, disc_loss = 0.001151868569184083
Trained batch 484 in epoch 1, gen_loss = 1.4860230952194056, disc_loss = 0.0011510278119287963
Trained batch 485 in epoch 1, gen_loss = 1.4859843955609042, disc_loss = 0.0011504758486534765
Trained batch 486 in epoch 1, gen_loss = 1.486034612636057, disc_loss = 0.0011504945321676935
Trained batch 487 in epoch 1, gen_loss = 1.485914857905419, disc_loss = 0.0011497773902207332
Trained batch 488 in epoch 1, gen_loss = 1.4857178760696286, disc_loss = 0.0011486518935368022
Trained batch 489 in epoch 1, gen_loss = 1.4857002168285602, disc_loss = 0.0011488400806544577
Trained batch 490 in epoch 1, gen_loss = 1.485808934068, disc_loss = 0.0011506271432983725
Trained batch 491 in epoch 1, gen_loss = 1.4859469288248357, disc_loss = 0.0011525319582651127
Trained batch 492 in epoch 1, gen_loss = 1.486224532610988, disc_loss = 0.0011544567823875695
Trained batch 493 in epoch 1, gen_loss = 1.4861583741087663, disc_loss = 0.0011562737794748512
Trained batch 494 in epoch 1, gen_loss = 1.4861282599092733, disc_loss = 0.0011571596040874908
Trained batch 495 in epoch 1, gen_loss = 1.4861984740822547, disc_loss = 0.001157314314109352
Trained batch 496 in epoch 1, gen_loss = 1.48632674461879, disc_loss = 0.0011571528963576928
Trained batch 497 in epoch 1, gen_loss = 1.486396341438753, disc_loss = 0.0011564586213981569
Trained batch 498 in epoch 1, gen_loss = 1.4862547145338956, disc_loss = 0.0011555308577924676
Trained batch 499 in epoch 1, gen_loss = 1.486323413848877, disc_loss = 0.001156259745650459
Trained batch 500 in epoch 1, gen_loss = 1.486334379561647, disc_loss = 0.0011575860441304527
Trained batch 501 in epoch 1, gen_loss = 1.4863500435988741, disc_loss = 0.0011579487909330055
Trained batch 502 in epoch 1, gen_loss = 1.4862390320533312, disc_loss = 0.0011575726749283811
Trained batch 503 in epoch 1, gen_loss = 1.4860972504294108, disc_loss = 0.001156966360703957
Trained batch 504 in epoch 1, gen_loss = 1.4859731072246438, disc_loss = 0.001156275408944152
Trained batch 505 in epoch 1, gen_loss = 1.4860095508956155, disc_loss = 0.0011552042170108402
Trained batch 506 in epoch 1, gen_loss = 1.4859185446884036, disc_loss = 0.0011545762202598677
Trained batch 507 in epoch 1, gen_loss = 1.4858126741225326, disc_loss = 0.0011541953356317832
Trained batch 508 in epoch 1, gen_loss = 1.4858119157536325, disc_loss = 0.0011534666697323608
Trained batch 509 in epoch 1, gen_loss = 1.485645722174177, disc_loss = 0.001153460640960154
Trained batch 510 in epoch 1, gen_loss = 1.4857753002013712, disc_loss = 0.0011574000107291212
Trained batch 511 in epoch 1, gen_loss = 1.4857123624533415, disc_loss = 0.0011644096377381175
Trained batch 512 in epoch 1, gen_loss = 1.4855792647913884, disc_loss = 0.001169467868805785
Trained batch 513 in epoch 1, gen_loss = 1.4858795627081904, disc_loss = 0.0011712873169625946
Trained batch 514 in epoch 1, gen_loss = 1.485942887796939, disc_loss = 0.0011715367772657135
Trained batch 515 in epoch 1, gen_loss = 1.4860085768755091, disc_loss = 0.0011709435828153743
Trained batch 516 in epoch 1, gen_loss = 1.4860265866008442, disc_loss = 0.0011699715833791227
Trained batch 517 in epoch 1, gen_loss = 1.4860351743845406, disc_loss = 0.0011688042938296636
Trained batch 518 in epoch 1, gen_loss = 1.485993137479058, disc_loss = 0.0011676417053914907
Trained batch 519 in epoch 1, gen_loss = 1.4861305881005067, disc_loss = 0.0011673792412553805
Trained batch 520 in epoch 1, gen_loss = 1.4862437486190943, disc_loss = 0.001167760824464215
Trained batch 521 in epoch 1, gen_loss = 1.486294316149306, disc_loss = 0.0011676164424574088
Trained batch 522 in epoch 1, gen_loss = 1.4863129174960048, disc_loss = 0.0011672739599618606
Trained batch 523 in epoch 1, gen_loss = 1.486388084770159, disc_loss = 0.0011671391543590123
Trained batch 524 in epoch 1, gen_loss = 1.4863470917656307, disc_loss = 0.0011667802738624493
Trained batch 525 in epoch 1, gen_loss = 1.4864273903034486, disc_loss = 0.001166778871072049
Trained batch 526 in epoch 1, gen_loss = 1.48643441557658, disc_loss = 0.0011669599240273767
Trained batch 527 in epoch 1, gen_loss = 1.4865259582346135, disc_loss = 0.0011667151038361199
Trained batch 528 in epoch 1, gen_loss = 1.4864836924468185, disc_loss = 0.0011660501499865415
Trained batch 529 in epoch 1, gen_loss = 1.4864895184085054, disc_loss = 0.00116496312026734
Trained batch 530 in epoch 1, gen_loss = 1.4863976810387074, disc_loss = 0.0011639204603578657
Trained batch 531 in epoch 1, gen_loss = 1.4863415925126326, disc_loss = 0.001163177198064741
Trained batch 532 in epoch 1, gen_loss = 1.4862420147400188, disc_loss = 0.0011623820195941685
Trained batch 533 in epoch 1, gen_loss = 1.486391439866484, disc_loss = 0.0011618332924824453
Trained batch 534 in epoch 1, gen_loss = 1.4863355346929248, disc_loss = 0.0011618032038024687
Trained batch 535 in epoch 1, gen_loss = 1.4863214523934607, disc_loss = 0.0011621005017047143
Trained batch 536 in epoch 1, gen_loss = 1.486510976510785, disc_loss = 0.0011620139773068795
Trained batch 537 in epoch 1, gen_loss = 1.4863965506890449, disc_loss = 0.0011612780624892403
Trained batch 538 in epoch 1, gen_loss = 1.486334432697473, disc_loss = 0.001159997639662702
Trained batch 539 in epoch 1, gen_loss = 1.4863497500066405, disc_loss = 0.0011585946159795167
Trained batch 540 in epoch 1, gen_loss = 1.4862266424182602, disc_loss = 0.0011572885253770507
Trained batch 541 in epoch 1, gen_loss = 1.4864621470335224, disc_loss = 0.0011563714813484856
Trained batch 542 in epoch 1, gen_loss = 1.4863820576536062, disc_loss = 0.0011560450938661476
Trained batch 543 in epoch 1, gen_loss = 1.486385247505763, disc_loss = 0.0011567658408667364
Trained batch 544 in epoch 1, gen_loss = 1.4864388853038122, disc_loss = 0.0011581768225686232
Trained batch 545 in epoch 1, gen_loss = 1.4865480499826509, disc_loss = 0.001160277518042493
Trained batch 546 in epoch 1, gen_loss = 1.4866640264852826, disc_loss = 0.0011628725053806376
Trained batch 547 in epoch 1, gen_loss = 1.4866863547885505, disc_loss = 0.0011652795687452958
Trained batch 548 in epoch 1, gen_loss = 1.4870489177808084, disc_loss = 0.0011674873165608993
Trained batch 549 in epoch 1, gen_loss = 1.4870173228870738, disc_loss = 0.0011683557160854848
Trained batch 550 in epoch 1, gen_loss = 1.487161594813186, disc_loss = 0.0011680776636499046
Trained batch 551 in epoch 1, gen_loss = 1.4871814736853475, disc_loss = 0.001166920614881404
Trained batch 552 in epoch 1, gen_loss = 1.4871414729527064, disc_loss = 0.0011655163716387583
Trained batch 553 in epoch 1, gen_loss = 1.487187016096356, disc_loss = 0.001164126583904159
Trained batch 554 in epoch 1, gen_loss = 1.487353134370065, disc_loss = 0.0011628043810052479
Trained batch 555 in epoch 1, gen_loss = 1.4873681548688051, disc_loss = 0.0011613566703024896
Trained batch 556 in epoch 1, gen_loss = 1.4876138063906768, disc_loss = 0.0011602091078694134
Trained batch 557 in epoch 1, gen_loss = 1.4876542420370178, disc_loss = 0.0011595285462243081
Trained batch 558 in epoch 1, gen_loss = 1.487682013477537, disc_loss = 0.0011591977777300245
Trained batch 559 in epoch 1, gen_loss = 1.487695681835924, disc_loss = 0.00115884411087401
Trained batch 560 in epoch 1, gen_loss = 1.4877213341667053, disc_loss = 0.0011579540551207635
Trained batch 561 in epoch 1, gen_loss = 1.4877368918093075, disc_loss = 0.0011566596360897041
Trained batch 562 in epoch 1, gen_loss = 1.4878386468701, disc_loss = 0.0011553120013404155
Trained batch 563 in epoch 1, gen_loss = 1.487782041654519, disc_loss = 0.001153981343348484
Trained batch 564 in epoch 1, gen_loss = 1.4877217845579165, disc_loss = 0.0011529857866606156
Trained batch 565 in epoch 1, gen_loss = 1.4876156792623836, disc_loss = 0.0011526171512722429
Trained batch 566 in epoch 1, gen_loss = 1.4878094604196161, disc_loss = 0.0011533423750069998
Trained batch 567 in epoch 1, gen_loss = 1.4878489593384971, disc_loss = 0.0011536752200287006
Trained batch 568 in epoch 1, gen_loss = 1.4878636764097297, disc_loss = 0.0011531802502776675
Trained batch 569 in epoch 1, gen_loss = 1.4878522797634728, disc_loss = 0.0011521378918060738
Trained batch 570 in epoch 1, gen_loss = 1.4879287270447419, disc_loss = 0.0011509691776186652
Trained batch 571 in epoch 1, gen_loss = 1.488052366079984, disc_loss = 0.0011496559473652542
Trained batch 572 in epoch 1, gen_loss = 1.488113911364091, disc_loss = 0.001148403578579676
Trained batch 573 in epoch 1, gen_loss = 1.4880205372069355, disc_loss = 0.0011473538314794654
Trained batch 574 in epoch 1, gen_loss = 1.4880964208685834, disc_loss = 0.0011464481127104196
Trained batch 575 in epoch 1, gen_loss = 1.4879304803907871, disc_loss = 0.0011457126671403886
Trained batch 576 in epoch 1, gen_loss = 1.4880167876000627, disc_loss = 0.0011450739763939409
Trained batch 577 in epoch 1, gen_loss = 1.4880546991387866, disc_loss = 0.0011444108697741251
Trained batch 578 in epoch 1, gen_loss = 1.4880144369622792, disc_loss = 0.001143540695097719
Trained batch 579 in epoch 1, gen_loss = 1.4880848354306715, disc_loss = 0.0011425847227279707
Trained batch 580 in epoch 1, gen_loss = 1.4881607579282146, disc_loss = 0.0011413890343754938
Trained batch 581 in epoch 1, gen_loss = 1.488236963134451, disc_loss = 0.0011400525961523312
Trained batch 582 in epoch 1, gen_loss = 1.4884380842359357, disc_loss = 0.001138732389346848
Trained batch 583 in epoch 1, gen_loss = 1.4883752118234765, disc_loss = 0.0011372943687865077
Trained batch 584 in epoch 1, gen_loss = 1.488342217909984, disc_loss = 0.0011358270118645847
Trained batch 585 in epoch 1, gen_loss = 1.4883095211136463, disc_loss = 0.0011341761726247936
Trained batch 586 in epoch 1, gen_loss = 1.4883209483180786, disc_loss = 0.0011325269903602107
Trained batch 587 in epoch 1, gen_loss = 1.4882937274417098, disc_loss = 0.0011309316211742773
Trained batch 588 in epoch 1, gen_loss = 1.4883536088244012, disc_loss = 0.0011293620981136891
Trained batch 589 in epoch 1, gen_loss = 1.4883768093788017, disc_loss = 0.001127980596788417
Trained batch 590 in epoch 1, gen_loss = 1.4884521652599276, disc_loss = 0.0011269008813074486
Trained batch 591 in epoch 1, gen_loss = 1.4884710768992837, disc_loss = 0.001126033786194229
Trained batch 592 in epoch 1, gen_loss = 1.4885095365935996, disc_loss = 0.0011252311938230268
Trained batch 593 in epoch 1, gen_loss = 1.4885498158859485, disc_loss = 0.001124424773451844
Trained batch 594 in epoch 1, gen_loss = 1.488483629507177, disc_loss = 0.0011238218767435422
Trained batch 595 in epoch 1, gen_loss = 1.4884945690231834, disc_loss = 0.0011236329240475987
Trained batch 596 in epoch 1, gen_loss = 1.4885772824087733, disc_loss = 0.001123393117196677
Trained batch 597 in epoch 1, gen_loss = 1.4885805000030874, disc_loss = 0.0011228910324367755
Trained batch 598 in epoch 1, gen_loss = 1.488676806722141, disc_loss = 0.0011224251306376331
Trained batch 599 in epoch 1, gen_loss = 1.4886257568995158, disc_loss = 0.00112222519654703
Trained batch 600 in epoch 1, gen_loss = 1.4886187340772885, disc_loss = 0.0011223176657532135
Trained batch 601 in epoch 1, gen_loss = 1.4885739929652293, disc_loss = 0.0011226403111386177
Trained batch 602 in epoch 1, gen_loss = 1.4885878940522177, disc_loss = 0.0011227507819730486
Trained batch 603 in epoch 1, gen_loss = 1.4885479047993162, disc_loss = 0.0011223011274493627
Trained batch 604 in epoch 1, gen_loss = 1.488473038831033, disc_loss = 0.0011215477934576694
Trained batch 605 in epoch 1, gen_loss = 1.4884196118553086, disc_loss = 0.001120751723358961
Trained batch 606 in epoch 1, gen_loss = 1.4884101558949252, disc_loss = 0.001120041182346771
Trained batch 607 in epoch 1, gen_loss = 1.488342832381788, disc_loss = 0.001119422604365115
Trained batch 608 in epoch 1, gen_loss = 1.4884004598767886, disc_loss = 0.0011186946894742597
Trained batch 609 in epoch 1, gen_loss = 1.4884266693083967, disc_loss = 0.0011178476846639494
Trained batch 610 in epoch 1, gen_loss = 1.488396685174171, disc_loss = 0.0011169985061512922
Trained batch 611 in epoch 1, gen_loss = 1.4883448927620657, disc_loss = 0.0011162410577336096
Trained batch 612 in epoch 1, gen_loss = 1.488361286883642, disc_loss = 0.001115456454704256
Trained batch 613 in epoch 1, gen_loss = 1.4882735627481913, disc_loss = 0.0011145435723002868
Trained batch 614 in epoch 1, gen_loss = 1.4881412157198277, disc_loss = 0.0011136269958773098
Trained batch 615 in epoch 1, gen_loss = 1.4881381404090237, disc_loss = 0.0011125605366009064
Trained batch 616 in epoch 1, gen_loss = 1.4880912993676851, disc_loss = 0.0011113192839415915
Trained batch 617 in epoch 1, gen_loss = 1.488099994975772, disc_loss = 0.0011099560955681756
Trained batch 618 in epoch 1, gen_loss = 1.4882168305709789, disc_loss = 0.0011088306693904108
Trained batch 619 in epoch 1, gen_loss = 1.4882996526456649, disc_loss = 0.001107748126237458
Trained batch 620 in epoch 1, gen_loss = 1.4883075562844146, disc_loss = 0.0011063772706887062
Trained batch 621 in epoch 1, gen_loss = 1.4882478692907228, disc_loss = 0.001105111598464289
Trained batch 622 in epoch 1, gen_loss = 1.4881969037829013, disc_loss = 0.001103957641098415
Trained batch 623 in epoch 1, gen_loss = 1.4881503931604898, disc_loss = 0.0011026186318000934
Trained batch 624 in epoch 1, gen_loss = 1.4880959478378295, disc_loss = 0.0011012127055088057
Trained batch 625 in epoch 1, gen_loss = 1.4881069505938327, disc_loss = 0.0010999016901569296
Trained batch 626 in epoch 1, gen_loss = 1.488239971074191, disc_loss = 0.0010986199281135711
Trained batch 627 in epoch 1, gen_loss = 1.4882233448468956, disc_loss = 0.0010975903440884145
Trained batch 628 in epoch 1, gen_loss = 1.4881948046919273, disc_loss = 0.0010966250922285474
Trained batch 629 in epoch 1, gen_loss = 1.4883162138954042, disc_loss = 0.0010959064049529843
Trained batch 630 in epoch 1, gen_loss = 1.4883336189620657, disc_loss = 0.0010950440425278542
Trained batch 631 in epoch 1, gen_loss = 1.4881873377893544, disc_loss = 0.0010940557200643248
Trained batch 632 in epoch 1, gen_loss = 1.4883370663129134, disc_loss = 0.001093231745092397
Trained batch 633 in epoch 1, gen_loss = 1.4882314009621316, disc_loss = 0.0010921753125075378
Trained batch 634 in epoch 1, gen_loss = 1.488228320512246, disc_loss = 0.0010914746258274
Trained batch 635 in epoch 1, gen_loss = 1.4882613898448225, disc_loss = 0.0010908571344977113
Trained batch 636 in epoch 1, gen_loss = 1.4882144387138883, disc_loss = 0.0010901361899558247
Trained batch 637 in epoch 1, gen_loss = 1.4881635909917585, disc_loss = 0.0010893179072849204
Trained batch 638 in epoch 1, gen_loss = 1.4881504949456277, disc_loss = 0.0010884326199426335
Trained batch 639 in epoch 1, gen_loss = 1.4880843440070748, disc_loss = 0.001087476534871712
Trained batch 640 in epoch 1, gen_loss = 1.4879891357258217, disc_loss = 0.0010866087247000415
Trained batch 641 in epoch 1, gen_loss = 1.4878956103621985, disc_loss = 0.0010856571685491244
Trained batch 642 in epoch 1, gen_loss = 1.4878546006942797, disc_loss = 0.001084780741580197
Trained batch 643 in epoch 1, gen_loss = 1.4878740653117992, disc_loss = 0.0010842012173197194
Trained batch 644 in epoch 1, gen_loss = 1.487864216353542, disc_loss = 0.0010838197067049658
Trained batch 645 in epoch 1, gen_loss = 1.4878168272160155, disc_loss = 0.0010834185441210937
Trained batch 646 in epoch 1, gen_loss = 1.4878457473271414, disc_loss = 0.0010828236729049498
Trained batch 647 in epoch 1, gen_loss = 1.4878090259469585, disc_loss = 0.0010819102145983323
Trained batch 648 in epoch 1, gen_loss = 1.4878277826382678, disc_loss = 0.0010809186334211956
Trained batch 649 in epoch 1, gen_loss = 1.487929963698754, disc_loss = 0.001079869012218506
Trained batch 650 in epoch 1, gen_loss = 1.4879133664701025, disc_loss = 0.0010786996001154886
Trained batch 651 in epoch 1, gen_loss = 1.487781796352995, disc_loss = 0.0010777574323895859
Trained batch 652 in epoch 1, gen_loss = 1.4877092091631925, disc_loss = 0.0010770764674092493
Trained batch 653 in epoch 1, gen_loss = 1.487665156887941, disc_loss = 0.0010764084783564634
Trained batch 654 in epoch 1, gen_loss = 1.487514642540735, disc_loss = 0.0010761347762620048
Trained batch 655 in epoch 1, gen_loss = 1.487615709806361, disc_loss = 0.0010765301607889564
Trained batch 656 in epoch 1, gen_loss = 1.4876415085393362, disc_loss = 0.0010769790306868446
Trained batch 657 in epoch 1, gen_loss = 1.4875871963051677, disc_loss = 0.001077063670565019
Trained batch 658 in epoch 1, gen_loss = 1.4876756221282101, disc_loss = 0.0010767178183125772
Trained batch 659 in epoch 1, gen_loss = 1.4875812391440073, disc_loss = 0.0010758210218530925
Trained batch 660 in epoch 1, gen_loss = 1.4875639839359924, disc_loss = 0.0010747706725883104
Trained batch 661 in epoch 1, gen_loss = 1.4875877279889547, disc_loss = 0.001073685666308647
Trained batch 662 in epoch 1, gen_loss = 1.4876958174942845, disc_loss = 0.0010727566192504285
Trained batch 663 in epoch 1, gen_loss = 1.487733419939696, disc_loss = 0.001071880093632099
Trained batch 664 in epoch 1, gen_loss = 1.487749389598244, disc_loss = 0.0010709580843891822
Trained batch 665 in epoch 1, gen_loss = 1.4877159076410014, disc_loss = 0.001070032889543796
Trained batch 666 in epoch 1, gen_loss = 1.4877515990158607, disc_loss = 0.0010691312713277312
Trained batch 667 in epoch 1, gen_loss = 1.4876923430822566, disc_loss = 0.0010684292429866769
Trained batch 668 in epoch 1, gen_loss = 1.4876701712430147, disc_loss = 0.0010680990072928845
Trained batch 669 in epoch 1, gen_loss = 1.4877566549315382, disc_loss = 0.0010679518350238438
Trained batch 670 in epoch 1, gen_loss = 1.4877203486182473, disc_loss = 0.0010678576811550924
Trained batch 671 in epoch 1, gen_loss = 1.4876724548992657, disc_loss = 0.0010678349530323992
Trained batch 672 in epoch 1, gen_loss = 1.4876086920898346, disc_loss = 0.0010677195127275364
Trained batch 673 in epoch 1, gen_loss = 1.4876112824731482, disc_loss = 0.0010676320249244822
Trained batch 674 in epoch 1, gen_loss = 1.487504537017257, disc_loss = 0.0010675276348289723
Trained batch 675 in epoch 1, gen_loss = 1.4874629494706555, disc_loss = 0.0010672132587726793
Trained batch 676 in epoch 1, gen_loss = 1.4874593908712819, disc_loss = 0.0010666415749241197
Trained batch 677 in epoch 1, gen_loss = 1.4875455199793024, disc_loss = 0.0010658277521776323
Trained batch 678 in epoch 1, gen_loss = 1.4875607274593414, disc_loss = 0.0010649710197325052
Trained batch 679 in epoch 1, gen_loss = 1.4876478824545356, disc_loss = 0.0010642230531041552
Trained batch 680 in epoch 1, gen_loss = 1.4876786164075093, disc_loss = 0.0010635947950979935
Trained batch 681 in epoch 1, gen_loss = 1.4875899158265233, disc_loss = 0.0010629487466952993
Trained batch 682 in epoch 1, gen_loss = 1.487583035431355, disc_loss = 0.0010622616714413044
Trained batch 683 in epoch 1, gen_loss = 1.487535338827044, disc_loss = 0.001061735478309303
Trained batch 684 in epoch 1, gen_loss = 1.4876045416741475, disc_loss = 0.0010614633239613657
Trained batch 685 in epoch 1, gen_loss = 1.4876053630436823, disc_loss = 0.0010612273567182056
Trained batch 686 in epoch 1, gen_loss = 1.4875749524850859, disc_loss = 0.0010608831811599701
Trained batch 687 in epoch 1, gen_loss = 1.4877662909931915, disc_loss = 0.0010603835259834617
Trained batch 688 in epoch 1, gen_loss = 1.4876506807842171, disc_loss = 0.001059651720662485
Trained batch 689 in epoch 1, gen_loss = 1.4876717588175898, disc_loss = 0.00105893962687148
Trained batch 690 in epoch 1, gen_loss = 1.4875855487265912, disc_loss = 0.001058279815214678
Trained batch 691 in epoch 1, gen_loss = 1.4875231212963258, disc_loss = 0.0010577372152779205
Trained batch 692 in epoch 1, gen_loss = 1.487525519354519, disc_loss = 0.00105708089467218
Trained batch 693 in epoch 1, gen_loss = 1.4875272426550257, disc_loss = 0.001056368165391649
Trained batch 694 in epoch 1, gen_loss = 1.4874652529791963, disc_loss = 0.0010555925472302819
Trained batch 695 in epoch 1, gen_loss = 1.4875607697785587, disc_loss = 0.0010549353362499648
Trained batch 696 in epoch 1, gen_loss = 1.4875490446514859, disc_loss = 0.0010541661935743183
Trained batch 697 in epoch 1, gen_loss = 1.487520363918348, disc_loss = 0.0010532030387640462
Trained batch 698 in epoch 1, gen_loss = 1.4874798918998293, disc_loss = 0.0010521204854058268
Trained batch 699 in epoch 1, gen_loss = 1.4874987656729561, disc_loss = 0.0010510962859552819
Trained batch 700 in epoch 1, gen_loss = 1.487388594004295, disc_loss = 0.0010501068329680033
Trained batch 701 in epoch 1, gen_loss = 1.48739292258211, disc_loss = 0.001049163517001731
Trained batch 702 in epoch 1, gen_loss = 1.4873947027228127, disc_loss = 0.001048180404597606
Trained batch 703 in epoch 1, gen_loss = 1.4873481784015894, disc_loss = 0.0010471552152880163
Trained batch 704 in epoch 1, gen_loss = 1.4873728577972305, disc_loss = 0.0010460860558896134
Trained batch 705 in epoch 1, gen_loss = 1.487417129382871, disc_loss = 0.0010449835879435675
Trained batch 706 in epoch 1, gen_loss = 1.4874081520582358, disc_loss = 0.0010439433323792767
Trained batch 707 in epoch 1, gen_loss = 1.4873574015784399, disc_loss = 0.0010431589089318555
Trained batch 708 in epoch 1, gen_loss = 1.4874467431069764, disc_loss = 0.0010426316112655903
Trained batch 709 in epoch 1, gen_loss = 1.4874057084741727, disc_loss = 0.0010423285554820659
Trained batch 710 in epoch 1, gen_loss = 1.4874847468444568, disc_loss = 0.0010424633462313738
Trained batch 711 in epoch 1, gen_loss = 1.487453724226255, disc_loss = 0.0010430980713495505
Trained batch 712 in epoch 1, gen_loss = 1.4874088988230574, disc_loss = 0.0010446140058392524
Trained batch 713 in epoch 1, gen_loss = 1.487431149856717, disc_loss = 0.0010475842592983732
Trained batch 714 in epoch 1, gen_loss = 1.4872455770319157, disc_loss = 0.0010510515224007838
Trained batch 715 in epoch 1, gen_loss = 1.4873109130220041, disc_loss = 0.0010535987446257942
Trained batch 716 in epoch 1, gen_loss = 1.4874518999993551, disc_loss = 0.0010565409591758229
Trained batch 717 in epoch 1, gen_loss = 1.4874154797503543, disc_loss = 0.001060475667061908
Trained batch 718 in epoch 1, gen_loss = 1.4874561005407978, disc_loss = 0.0010640242320016837
Trained batch 719 in epoch 1, gen_loss = 1.4872693611515893, disc_loss = 0.00106726877640742
Trained batch 720 in epoch 1, gen_loss = 1.4872337840962508, disc_loss = 0.0010707536671317444
Trained batch 721 in epoch 1, gen_loss = 1.4872886718475258, disc_loss = 0.0010736800755099703
Trained batch 722 in epoch 1, gen_loss = 1.48725152922534, disc_loss = 0.001075093104137091
Trained batch 723 in epoch 1, gen_loss = 1.487233934316846, disc_loss = 0.001075363146287977
Trained batch 724 in epoch 1, gen_loss = 1.4873440934871804, disc_loss = 0.0010755268339236298
Trained batch 725 in epoch 1, gen_loss = 1.4872485872142571, disc_loss = 0.0010759382789992066
Trained batch 726 in epoch 1, gen_loss = 1.4871532457894767, disc_loss = 0.0010764439419295288
Trained batch 727 in epoch 1, gen_loss = 1.4870349668211988, disc_loss = 0.0010775120606542638
Trained batch 728 in epoch 1, gen_loss = 1.4870800919657055, disc_loss = 0.0010794936087845143
Trained batch 729 in epoch 1, gen_loss = 1.4871210095000593, disc_loss = 0.0010821935295945429
Trained batch 730 in epoch 1, gen_loss = 1.4871291835396137, disc_loss = 0.0010843045417152195
Trained batch 731 in epoch 1, gen_loss = 1.4871070782343547, disc_loss = 0.0010856192782968143
Trained batch 732 in epoch 1, gen_loss = 1.4870368652096548, disc_loss = 0.0010862201407189974
Trained batch 733 in epoch 1, gen_loss = 1.4869593968183532, disc_loss = 0.0010896462395228001
Trained batch 734 in epoch 1, gen_loss = 1.4869486849324234, disc_loss = 0.0010963143428611777
Trained batch 735 in epoch 1, gen_loss = 1.486875493079424, disc_loss = 0.0011040533126027224
Trained batch 736 in epoch 1, gen_loss = 1.4869043987188766, disc_loss = 0.0011106668310620592
Trained batch 737 in epoch 1, gen_loss = 1.4869180899971546, disc_loss = 0.0011143334960821464
Trained batch 738 in epoch 1, gen_loss = 1.4869907937933853, disc_loss = 0.0011147240313888163
Trained batch 739 in epoch 1, gen_loss = 1.4869811834515752, disc_loss = 0.0011138647776041998
Trained batch 740 in epoch 1, gen_loss = 1.4869235478914702, disc_loss = 0.0011133536893483842
Trained batch 741 in epoch 1, gen_loss = 1.4870632247462106, disc_loss = 0.0011128027448369469
Trained batch 742 in epoch 1, gen_loss = 1.4869893133078738, disc_loss = 0.0011124339361161478
Trained batch 743 in epoch 1, gen_loss = 1.487010036104469, disc_loss = 0.0011136883793134926
Trained batch 744 in epoch 1, gen_loss = 1.4869336621073268, disc_loss = 0.0011163657991529673
Trained batch 745 in epoch 1, gen_loss = 1.4869505176595326, disc_loss = 0.0011190580209474025
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 1.4612371921539307, disc_loss = 0.0018986111972481012
Trained batch 1 in epoch 2, gen_loss = 1.4346330165863037, disc_loss = 0.001426319358870387
Trained batch 2 in epoch 2, gen_loss = 1.4370296398798625, disc_loss = 0.0011442425311543047
Trained batch 3 in epoch 2, gen_loss = 1.4760076701641083, disc_loss = 0.000997872164589353
Trained batch 4 in epoch 2, gen_loss = 1.4822579860687255, disc_loss = 0.0008816072600893676
Trained batch 5 in epoch 2, gen_loss = 1.4976415832837422, disc_loss = 0.0008001955284271389
Trained batch 6 in epoch 2, gen_loss = 1.5022080966404505, disc_loss = 0.0007749255497141608
Trained batch 7 in epoch 2, gen_loss = 1.4995075464248657, disc_loss = 0.0007775710109854117
Trained batch 8 in epoch 2, gen_loss = 1.4931608570946588, disc_loss = 0.0007821445793120398
Trained batch 9 in epoch 2, gen_loss = 1.4989723324775697, disc_loss = 0.0008001603302545846
Trained batch 10 in epoch 2, gen_loss = 1.5020813833583484, disc_loss = 0.0008151381467045708
Trained batch 11 in epoch 2, gen_loss = 1.4942144056161244, disc_loss = 0.0008043770309692869
Trained batch 12 in epoch 2, gen_loss = 1.4876353557293231, disc_loss = 0.0007991868590649504
Trained batch 13 in epoch 2, gen_loss = 1.4879174828529358, disc_loss = 0.0007916124304756522
Trained batch 14 in epoch 2, gen_loss = 1.4837088584899902, disc_loss = 0.0007677385273079077
Trained batch 15 in epoch 2, gen_loss = 1.4840995967388153, disc_loss = 0.0007509162242058665
Trained batch 16 in epoch 2, gen_loss = 1.483177241157083, disc_loss = 0.0007604022428174229
Trained batch 17 in epoch 2, gen_loss = 1.484256042374505, disc_loss = 0.0007956887905796369
Trained batch 18 in epoch 2, gen_loss = 1.487105369567871, disc_loss = 0.0008149002188522564
Trained batch 19 in epoch 2, gen_loss = 1.4858176589012146, disc_loss = 0.0008188179897842928
Trained batch 20 in epoch 2, gen_loss = 1.4831643672216506, disc_loss = 0.0008162608885738466
Trained batch 21 in epoch 2, gen_loss = 1.4854268919337879, disc_loss = 0.0008029090478719974
Trained batch 22 in epoch 2, gen_loss = 1.4847290567729785, disc_loss = 0.0007859537828430209
Trained batch 23 in epoch 2, gen_loss = 1.4838466097911198, disc_loss = 0.0007682383196273198
Trained batch 24 in epoch 2, gen_loss = 1.4859875631332398, disc_loss = 0.0007518485514447093
Trained batch 25 in epoch 2, gen_loss = 1.4852717472956731, disc_loss = 0.0007391648474507607
Trained batch 26 in epoch 2, gen_loss = 1.484204027387831, disc_loss = 0.0007302232595436551
Trained batch 27 in epoch 2, gen_loss = 1.484490922519139, disc_loss = 0.0007201671199124705
Trained batch 28 in epoch 2, gen_loss = 1.4846031830228608, disc_loss = 0.0007062362324334039
Trained batch 29 in epoch 2, gen_loss = 1.4840137481689453, disc_loss = 0.0006921196220597873
Trained batch 30 in epoch 2, gen_loss = 1.4864521141975158, disc_loss = 0.0006880448725555212
Trained batch 31 in epoch 2, gen_loss = 1.4863778613507748, disc_loss = 0.000695757424182375
Trained batch 32 in epoch 2, gen_loss = 1.4870271104754824, disc_loss = 0.0007011617205783048
Trained batch 33 in epoch 2, gen_loss = 1.4863332720363842, disc_loss = 0.000700823002262041
Trained batch 34 in epoch 2, gen_loss = 1.4895491259438651, disc_loss = 0.0006971301327991699
Trained batch 35 in epoch 2, gen_loss = 1.4896770649486117, disc_loss = 0.0006882686947291303
Trained batch 36 in epoch 2, gen_loss = 1.4889049143404574, disc_loss = 0.0006783762128671279
Trained batch 37 in epoch 2, gen_loss = 1.4872484238524186, disc_loss = 0.0006675019126544756
Trained batch 38 in epoch 2, gen_loss = 1.4887722852902534, disc_loss = 0.0006555606594655472
Trained batch 39 in epoch 2, gen_loss = 1.4884283512830734, disc_loss = 0.000650974886957556
Trained batch 40 in epoch 2, gen_loss = 1.4882439869206125, disc_loss = 0.0006536886567340755
Trained batch 41 in epoch 2, gen_loss = 1.4881562221617926, disc_loss = 0.0006529653037432581
Trained batch 42 in epoch 2, gen_loss = 1.4907427360845167, disc_loss = 0.0006556055186381347
Trained batch 43 in epoch 2, gen_loss = 1.48944982344454, disc_loss = 0.0006573767922501164
Trained batch 44 in epoch 2, gen_loss = 1.489305141237047, disc_loss = 0.0006547491622364356
Trained batch 45 in epoch 2, gen_loss = 1.4881975598957227, disc_loss = 0.0006455246880448059
Trained batch 46 in epoch 2, gen_loss = 1.4874578029551404, disc_loss = 0.0006406378326689864
Trained batch 47 in epoch 2, gen_loss = 1.487124261756738, disc_loss = 0.0006437665536698963
Trained batch 48 in epoch 2, gen_loss = 1.4868656299552139, disc_loss = 0.0006520859903076246
Trained batch 49 in epoch 2, gen_loss = 1.488520278930664, disc_loss = 0.0006570015737088397
Trained batch 50 in epoch 2, gen_loss = 1.4904323068319583, disc_loss = 0.0006586454698003317
Trained batch 51 in epoch 2, gen_loss = 1.4901932179927826, disc_loss = 0.0006562419500998937
Trained batch 52 in epoch 2, gen_loss = 1.4897022157345179, disc_loss = 0.0006547668473223963
Trained batch 53 in epoch 2, gen_loss = 1.4898526072502136, disc_loss = 0.0006572946068546218
Trained batch 54 in epoch 2, gen_loss = 1.4887342778119175, disc_loss = 0.0006652191593523391
Trained batch 55 in epoch 2, gen_loss = 1.4879990752254213, disc_loss = 0.0006742756538317605
Trained batch 56 in epoch 2, gen_loss = 1.488219376195941, disc_loss = 0.0006818499088311862
Trained batch 57 in epoch 2, gen_loss = 1.4902720328035026, disc_loss = 0.0006894781209070813
Trained batch 58 in epoch 2, gen_loss = 1.4898659253524522, disc_loss = 0.0006976544307505365
Trained batch 59 in epoch 2, gen_loss = 1.4895486036936443, disc_loss = 0.0007052041934609102
Trained batch 60 in epoch 2, gen_loss = 1.4888643045894434, disc_loss = 0.0007084991318196608
Trained batch 61 in epoch 2, gen_loss = 1.48693238535235, disc_loss = 0.0007071729290351693
Trained batch 62 in epoch 2, gen_loss = 1.4864017320057703, disc_loss = 0.0007063010924621411
Trained batch 63 in epoch 2, gen_loss = 1.4857382290065289, disc_loss = 0.0007050854551380326
Trained batch 64 in epoch 2, gen_loss = 1.4856798300376306, disc_loss = 0.0007006822624064695
Trained batch 65 in epoch 2, gen_loss = 1.4853537461974404, disc_loss = 0.0006962963741512574
Trained batch 66 in epoch 2, gen_loss = 1.48414181595418, disc_loss = 0.000695058224555939
Trained batch 67 in epoch 2, gen_loss = 1.484897858956281, disc_loss = 0.0006963088440790991
Trained batch 68 in epoch 2, gen_loss = 1.4849586711413618, disc_loss = 0.0006997245279532195
Trained batch 69 in epoch 2, gen_loss = 1.4844542060579573, disc_loss = 0.0007033469063961612
Trained batch 70 in epoch 2, gen_loss = 1.4843666318436743, disc_loss = 0.0007048070014283901
Trained batch 71 in epoch 2, gen_loss = 1.4844764471054077, disc_loss = 0.0007027741861141598
Trained batch 72 in epoch 2, gen_loss = 1.4841235402512223, disc_loss = 0.0006998594808838751
Trained batch 73 in epoch 2, gen_loss = 1.4835587482194643, disc_loss = 0.0006976823638684142
Trained batch 74 in epoch 2, gen_loss = 1.4835297362009685, disc_loss = 0.0006986872036941349
Trained batch 75 in epoch 2, gen_loss = 1.4832543448397988, disc_loss = 0.0007021339735825007
Trained batch 76 in epoch 2, gen_loss = 1.4841165263931473, disc_loss = 0.0007046754207377406
Trained batch 77 in epoch 2, gen_loss = 1.484137311959878, disc_loss = 0.0007023048514010719
Trained batch 78 in epoch 2, gen_loss = 1.4837383212922495, disc_loss = 0.0006972000767665479
Trained batch 79 in epoch 2, gen_loss = 1.4828735694289208, disc_loss = 0.0006912286778970155
Trained batch 80 in epoch 2, gen_loss = 1.4837630913581377, disc_loss = 0.0006859836450283542
Trained batch 81 in epoch 2, gen_loss = 1.4838660926353642, disc_loss = 0.0006828906984216102
Trained batch 82 in epoch 2, gen_loss = 1.4828563914241562, disc_loss = 0.0006791863563128309
Trained batch 83 in epoch 2, gen_loss = 1.4828890760739644, disc_loss = 0.0006739679090623256
Trained batch 84 in epoch 2, gen_loss = 1.48284831608043, disc_loss = 0.0006693295343532501
Trained batch 85 in epoch 2, gen_loss = 1.4827695696852927, disc_loss = 0.0006660909519184294
Trained batch 86 in epoch 2, gen_loss = 1.482386282120628, disc_loss = 0.0006629649102125831
Trained batch 87 in epoch 2, gen_loss = 1.483085961504416, disc_loss = 0.0006590276183983819
Trained batch 88 in epoch 2, gen_loss = 1.482843036062262, disc_loss = 0.0006553717372870972
Trained batch 89 in epoch 2, gen_loss = 1.4827969445122613, disc_loss = 0.0006551080832852879
Trained batch 90 in epoch 2, gen_loss = 1.4830490796120612, disc_loss = 0.0006583367450710304
Trained batch 91 in epoch 2, gen_loss = 1.483359358880831, disc_loss = 0.0006646050286413495
Trained batch 92 in epoch 2, gen_loss = 1.4839709099902902, disc_loss = 0.0006711812228620333
Trained batch 93 in epoch 2, gen_loss = 1.484234501706793, disc_loss = 0.0006766862213051819
Trained batch 94 in epoch 2, gen_loss = 1.4838871479034423, disc_loss = 0.0006838636641317096
Trained batch 95 in epoch 2, gen_loss = 1.4839146497348945, disc_loss = 0.0006917065411471413
Trained batch 96 in epoch 2, gen_loss = 1.4840766511012597, disc_loss = 0.0006976362864472472
Trained batch 97 in epoch 2, gen_loss = 1.4834600103144744, disc_loss = 0.0007006771638585559
Trained batch 98 in epoch 2, gen_loss = 1.4842321294726748, disc_loss = 0.0007020438303394864
Trained batch 99 in epoch 2, gen_loss = 1.4850819182395936, disc_loss = 0.0007027484182617627
Trained batch 100 in epoch 2, gen_loss = 1.4850038325432504, disc_loss = 0.0007028067366353762
Trained batch 101 in epoch 2, gen_loss = 1.486146230323642, disc_loss = 0.0007006352771342933
Trained batch 102 in epoch 2, gen_loss = 1.4863148615198227, disc_loss = 0.0006970136372137416
Trained batch 103 in epoch 2, gen_loss = 1.4859873491984148, disc_loss = 0.0006933250294353527
Trained batch 104 in epoch 2, gen_loss = 1.485889954794021, disc_loss = 0.0006890123299810858
Trained batch 105 in epoch 2, gen_loss = 1.4859788215385292, disc_loss = 0.0006843936186995498
Trained batch 106 in epoch 2, gen_loss = 1.4860367507578056, disc_loss = 0.0006815152262907615
Trained batch 107 in epoch 2, gen_loss = 1.486478586991628, disc_loss = 0.0006808593496788051
Trained batch 108 in epoch 2, gen_loss = 1.486814000190945, disc_loss = 0.0006824995520836545
Trained batch 109 in epoch 2, gen_loss = 1.487413594939492, disc_loss = 0.0006834641577866436
Trained batch 110 in epoch 2, gen_loss = 1.4870991137650635, disc_loss = 0.0006828657375031931
Trained batch 111 in epoch 2, gen_loss = 1.4878145913992609, disc_loss = 0.0006841416982622052
Trained batch 112 in epoch 2, gen_loss = 1.4878217066283774, disc_loss = 0.0006861757743069325
Trained batch 113 in epoch 2, gen_loss = 1.48803273523063, disc_loss = 0.0006878160957855646
Trained batch 114 in epoch 2, gen_loss = 1.4877267267393028, disc_loss = 0.0006883218517506738
Trained batch 115 in epoch 2, gen_loss = 1.4885099530220032, disc_loss = 0.000689158448196771
Trained batch 116 in epoch 2, gen_loss = 1.4881424883491972, disc_loss = 0.0006919290114723496
Trained batch 117 in epoch 2, gen_loss = 1.4874876646672266, disc_loss = 0.0006967462193303726
Trained batch 118 in epoch 2, gen_loss = 1.4868245755924898, disc_loss = 0.0007032439664902338
Trained batch 119 in epoch 2, gen_loss = 1.4870676348606746, disc_loss = 0.0007091232354772121
Trained batch 120 in epoch 2, gen_loss = 1.4867451151540456, disc_loss = 0.0007114247854294887
Trained batch 121 in epoch 2, gen_loss = 1.4858272036568063, disc_loss = 0.000712110679816134
Trained batch 122 in epoch 2, gen_loss = 1.4859698671635573, disc_loss = 0.0007121576262709904
Trained batch 123 in epoch 2, gen_loss = 1.486109180796531, disc_loss = 0.0007118900283521432
Trained batch 124 in epoch 2, gen_loss = 1.4864117403030395, disc_loss = 0.0007110210738610476
Trained batch 125 in epoch 2, gen_loss = 1.4858130869411288, disc_loss = 0.0007094867642514319
Trained batch 126 in epoch 2, gen_loss = 1.4856278361297968, disc_loss = 0.0007071014558786424
Trained batch 127 in epoch 2, gen_loss = 1.4850359484553337, disc_loss = 0.0007044709641377267
Trained batch 128 in epoch 2, gen_loss = 1.4848861186079276, disc_loss = 0.0007012664221313804
Trained batch 129 in epoch 2, gen_loss = 1.484820412672483, disc_loss = 0.0006975134250331814
Trained batch 130 in epoch 2, gen_loss = 1.4848338911551555, disc_loss = 0.0006941106756491487
Trained batch 131 in epoch 2, gen_loss = 1.4851095215840773, disc_loss = 0.0006907360364107951
Trained batch 132 in epoch 2, gen_loss = 1.484803645234359, disc_loss = 0.0006882193158258145
Trained batch 133 in epoch 2, gen_loss = 1.485417121381902, disc_loss = 0.0006866088157012336
Trained batch 134 in epoch 2, gen_loss = 1.485277161774812, disc_loss = 0.0006845990846933866
Trained batch 135 in epoch 2, gen_loss = 1.4852086340679842, disc_loss = 0.0006821838415977682
Trained batch 136 in epoch 2, gen_loss = 1.4850426137882426, disc_loss = 0.0006805050102263063
Trained batch 137 in epoch 2, gen_loss = 1.4849359600440315, disc_loss = 0.0006801076205970342
Trained batch 138 in epoch 2, gen_loss = 1.484871474101389, disc_loss = 0.0006800002480016204
Trained batch 139 in epoch 2, gen_loss = 1.4849986135959625, disc_loss = 0.0006788205985295853
Trained batch 140 in epoch 2, gen_loss = 1.4845305791137913, disc_loss = 0.0006768017557717146
Trained batch 141 in epoch 2, gen_loss = 1.4844629831717049, disc_loss = 0.0006746825976067708
Trained batch 142 in epoch 2, gen_loss = 1.4843928680553302, disc_loss = 0.0006731661702945854
Trained batch 143 in epoch 2, gen_loss = 1.4838494178321626, disc_loss = 0.0006725018847646425
Trained batch 144 in epoch 2, gen_loss = 1.4838890256552861, disc_loss = 0.0006714391684689527
Trained batch 145 in epoch 2, gen_loss = 1.4834174946562884, disc_loss = 0.000670549510986136
Trained batch 146 in epoch 2, gen_loss = 1.4828976441402824, disc_loss = 0.0006701538680187825
Trained batch 147 in epoch 2, gen_loss = 1.4823337833623629, disc_loss = 0.0006693344371711106
Trained batch 148 in epoch 2, gen_loss = 1.4820309541369445, disc_loss = 0.000668689299370131
Trained batch 149 in epoch 2, gen_loss = 1.4819716874758402, disc_loss = 0.0006681354035390541
Trained batch 150 in epoch 2, gen_loss = 1.482087567942032, disc_loss = 0.000668443481334553
Trained batch 151 in epoch 2, gen_loss = 1.4815861206305654, disc_loss = 0.0006692520268858827
Trained batch 152 in epoch 2, gen_loss = 1.4815626752142812, disc_loss = 0.0006694121842099098
Trained batch 153 in epoch 2, gen_loss = 1.4815801707181064, disc_loss = 0.0006687976334882029
Trained batch 154 in epoch 2, gen_loss = 1.481713879492975, disc_loss = 0.000668923704577009
Trained batch 155 in epoch 2, gen_loss = 1.4824054546845264, disc_loss = 0.0006710191334535081
Trained batch 156 in epoch 2, gen_loss = 1.4822965518684144, disc_loss = 0.0006746688468758444
Trained batch 157 in epoch 2, gen_loss = 1.4820390539833261, disc_loss = 0.0006804713525122645
Trained batch 158 in epoch 2, gen_loss = 1.482328142010191, disc_loss = 0.0006867482950369118
Trained batch 159 in epoch 2, gen_loss = 1.4821744464337825, disc_loss = 0.0006914359217262244
Trained batch 160 in epoch 2, gen_loss = 1.4820469247628443, disc_loss = 0.0006934986889047073
Trained batch 161 in epoch 2, gen_loss = 1.4817277480054785, disc_loss = 0.000694261682916858
Trained batch 162 in epoch 2, gen_loss = 1.4818220262878512, disc_loss = 0.0006941050925632036
Trained batch 163 in epoch 2, gen_loss = 1.48174459759782, disc_loss = 0.0006928703282383362
Trained batch 164 in epoch 2, gen_loss = 1.4818620414444894, disc_loss = 0.0006904457697546054
Trained batch 165 in epoch 2, gen_loss = 1.4818960363606373, disc_loss = 0.0006874128239031555
Trained batch 166 in epoch 2, gen_loss = 1.4818035035790085, disc_loss = 0.000684653343123936
Trained batch 167 in epoch 2, gen_loss = 1.4816733918019704, disc_loss = 0.0006823988582514825
Trained batch 168 in epoch 2, gen_loss = 1.4821214429020175, disc_loss = 0.0006807790058265446
Trained batch 169 in epoch 2, gen_loss = 1.4819569734966054, disc_loss = 0.0006796258532524328
Trained batch 170 in epoch 2, gen_loss = 1.4818136238912394, disc_loss = 0.0006791809760987193
Trained batch 171 in epoch 2, gen_loss = 1.481783819059993, disc_loss = 0.0006795107802581909
Trained batch 172 in epoch 2, gen_loss = 1.4813293315082616, disc_loss = 0.0006800162292360139
Trained batch 173 in epoch 2, gen_loss = 1.4811680474500546, disc_loss = 0.0006805346193509283
Trained batch 174 in epoch 2, gen_loss = 1.4815741682052612, disc_loss = 0.0006810939039236732
Trained batch 175 in epoch 2, gen_loss = 1.4811681048436598, disc_loss = 0.0006806378547811288
Trained batch 176 in epoch 2, gen_loss = 1.4810825458354195, disc_loss = 0.0006794759232187802
Trained batch 177 in epoch 2, gen_loss = 1.4814502918318417, disc_loss = 0.0006775186551483662
Trained batch 178 in epoch 2, gen_loss = 1.4811542094086803, disc_loss = 0.0006750604963253965
Trained batch 179 in epoch 2, gen_loss = 1.4809371213118234, disc_loss = 0.0006724657218405304
Trained batch 180 in epoch 2, gen_loss = 1.4810589064550663, disc_loss = 0.0006703805458668918
Trained batch 181 in epoch 2, gen_loss = 1.480766462100731, disc_loss = 0.0006684083729031864
Trained batch 182 in epoch 2, gen_loss = 1.4802763481609156, disc_loss = 0.0006663484011090976
Trained batch 183 in epoch 2, gen_loss = 1.4802668995183448, disc_loss = 0.0006647641418923107
Trained batch 184 in epoch 2, gen_loss = 1.4802009086351138, disc_loss = 0.0006642922149448832
Trained batch 185 in epoch 2, gen_loss = 1.480030180946473, disc_loss = 0.0006637546154501427
Trained batch 186 in epoch 2, gen_loss = 1.4798149418703375, disc_loss = 0.0006623399465869027
Trained batch 187 in epoch 2, gen_loss = 1.4797993093094928, disc_loss = 0.0006603068097629535
Trained batch 188 in epoch 2, gen_loss = 1.4796738000143141, disc_loss = 0.0006580460953979541
Trained batch 189 in epoch 2, gen_loss = 1.4798568731860111, disc_loss = 0.0006558751857435134
Trained batch 190 in epoch 2, gen_loss = 1.4800122801546027, disc_loss = 0.0006541965838036554
Trained batch 191 in epoch 2, gen_loss = 1.480200280745824, disc_loss = 0.0006532765448052184
Trained batch 192 in epoch 2, gen_loss = 1.480220165895057, disc_loss = 0.0006527790651654274
Trained batch 193 in epoch 2, gen_loss = 1.4801095207941901, disc_loss = 0.0006518407138820603
Trained batch 194 in epoch 2, gen_loss = 1.480371042398306, disc_loss = 0.0006510886642783403
Trained batch 195 in epoch 2, gen_loss = 1.4803261537941135, disc_loss = 0.0006502996086278379
Trained batch 196 in epoch 2, gen_loss = 1.4805742756364308, disc_loss = 0.0006494678243425046
Trained batch 197 in epoch 2, gen_loss = 1.480039651345725, disc_loss = 0.0006489872982704335
Trained batch 198 in epoch 2, gen_loss = 1.4799976360857787, disc_loss = 0.0006488734379764085
Trained batch 199 in epoch 2, gen_loss = 1.479696034193039, disc_loss = 0.0006486801338905934
Trained batch 200 in epoch 2, gen_loss = 1.4796321872454972, disc_loss = 0.0006484040744030449
Trained batch 201 in epoch 2, gen_loss = 1.4797371478364019, disc_loss = 0.0006480274053744621
Trained batch 202 in epoch 2, gen_loss = 1.480032643661123, disc_loss = 0.0006476586973902499
Trained batch 203 in epoch 2, gen_loss = 1.4800541728150611, disc_loss = 0.0006465740539259094
Trained batch 204 in epoch 2, gen_loss = 1.4801332101589295, disc_loss = 0.0006450598521396608
Trained batch 205 in epoch 2, gen_loss = 1.4802733636596828, disc_loss = 0.0006432128278708122
Trained batch 206 in epoch 2, gen_loss = 1.4806328090492653, disc_loss = 0.0006411490650624846
Trained batch 207 in epoch 2, gen_loss = 1.480336427115477, disc_loss = 0.000639168553579321
Trained batch 208 in epoch 2, gen_loss = 1.4805066283239703, disc_loss = 0.0006381471632449535
Trained batch 209 in epoch 2, gen_loss = 1.480710054011572, disc_loss = 0.0006374379769632859
Trained batch 210 in epoch 2, gen_loss = 1.4810887868935463, disc_loss = 0.0006371379280418723
Trained batch 211 in epoch 2, gen_loss = 1.4810153262795143, disc_loss = 0.0006372607840260245
Trained batch 212 in epoch 2, gen_loss = 1.4808293278788176, disc_loss = 0.0006374568025857
Trained batch 213 in epoch 2, gen_loss = 1.480860091815485, disc_loss = 0.0006373050273396075
Trained batch 214 in epoch 2, gen_loss = 1.480507413731065, disc_loss = 0.0006374708374117523
Trained batch 215 in epoch 2, gen_loss = 1.4804827846862652, disc_loss = 0.0006380617934930207
Trained batch 216 in epoch 2, gen_loss = 1.4805426498711933, disc_loss = 0.0006387099607049354
Trained batch 217 in epoch 2, gen_loss = 1.4802324996082061, disc_loss = 0.0006383510326236111
Trained batch 218 in epoch 2, gen_loss = 1.480221569265949, disc_loss = 0.0006373482315107908
Trained batch 219 in epoch 2, gen_loss = 1.480650849233974, disc_loss = 0.0006359875159846111
Trained batch 220 in epoch 2, gen_loss = 1.4805987706551185, disc_loss = 0.000634453257959867
Trained batch 221 in epoch 2, gen_loss = 1.480777889758617, disc_loss = 0.0006328326476127463
Trained batch 222 in epoch 2, gen_loss = 1.4805273672924983, disc_loss = 0.0006313191796235339
Trained batch 223 in epoch 2, gen_loss = 1.4805447741278581, disc_loss = 0.0006301352563501236
Trained batch 224 in epoch 2, gen_loss = 1.4803844091627334, disc_loss = 0.0006290225076696111
Trained batch 225 in epoch 2, gen_loss = 1.4807838576029888, disc_loss = 0.0006280670275260587
Trained batch 226 in epoch 2, gen_loss = 1.4806366980338412, disc_loss = 0.0006267828819401447
Trained batch 227 in epoch 2, gen_loss = 1.4806031469713177, disc_loss = 0.0006257474441346794
Trained batch 228 in epoch 2, gen_loss = 1.4807215080511102, disc_loss = 0.0006246844928825526
Trained batch 229 in epoch 2, gen_loss = 1.4806997148886971, disc_loss = 0.0006232762894006041
Trained batch 230 in epoch 2, gen_loss = 1.4807141255506706, disc_loss = 0.0006217456908313985
Trained batch 231 in epoch 2, gen_loss = 1.4808192073271191, disc_loss = 0.0006203070489422755
Trained batch 232 in epoch 2, gen_loss = 1.480398436984279, disc_loss = 0.0006184722591679176
Trained batch 233 in epoch 2, gen_loss = 1.4801065570268876, disc_loss = 0.0006168806516469863
Trained batch 234 in epoch 2, gen_loss = 1.4806127969254839, disc_loss = 0.0006154411656910831
Trained batch 235 in epoch 2, gen_loss = 1.4805920209925054, disc_loss = 0.0006138374328502785
Trained batch 236 in epoch 2, gen_loss = 1.4808316854484977, disc_loss = 0.000612463187480361
Trained batch 237 in epoch 2, gen_loss = 1.4809673899362068, disc_loss = 0.0006113830825926329
Trained batch 238 in epoch 2, gen_loss = 1.4807960972127556, disc_loss = 0.0006104455532595734
Trained batch 239 in epoch 2, gen_loss = 1.481087156633536, disc_loss = 0.0006098615340306424
Trained batch 240 in epoch 2, gen_loss = 1.4810834247541624, disc_loss = 0.00060998914542094
Trained batch 241 in epoch 2, gen_loss = 1.4809968629159218, disc_loss = 0.0006109578212653864
Trained batch 242 in epoch 2, gen_loss = 1.4812558717688415, disc_loss = 0.0006117060248272439
Trained batch 243 in epoch 2, gen_loss = 1.4811925809891497, disc_loss = 0.0006122907659909154
Trained batch 244 in epoch 2, gen_loss = 1.4810619889473429, disc_loss = 0.000613123187747765
Trained batch 245 in epoch 2, gen_loss = 1.4811042334006084, disc_loss = 0.0006141683694384084
Trained batch 246 in epoch 2, gen_loss = 1.4811096509941193, disc_loss = 0.000614777474140047
Trained batch 247 in epoch 2, gen_loss = 1.4809310171873338, disc_loss = 0.0006151325205498706
Trained batch 248 in epoch 2, gen_loss = 1.4808121479179965, disc_loss = 0.0006158347886773836
Trained batch 249 in epoch 2, gen_loss = 1.4805788259506225, disc_loss = 0.0006170457063708455
Trained batch 250 in epoch 2, gen_loss = 1.4805483162640576, disc_loss = 0.0006181655448872552
Trained batch 251 in epoch 2, gen_loss = 1.4804726058528537, disc_loss = 0.0006186306972744032
Trained batch 252 in epoch 2, gen_loss = 1.4805100548408718, disc_loss = 0.0006189845730605804
Trained batch 253 in epoch 2, gen_loss = 1.480187442828351, disc_loss = 0.0006192452996129566
Trained batch 254 in epoch 2, gen_loss = 1.4801656190086814, disc_loss = 0.000619119838081008
Trained batch 255 in epoch 2, gen_loss = 1.4799352437257767, disc_loss = 0.000618416780298503
Trained batch 256 in epoch 2, gen_loss = 1.4797764733607668, disc_loss = 0.0006175815618818024
Trained batch 257 in epoch 2, gen_loss = 1.4797543107077133, disc_loss = 0.0006171817117002468
Trained batch 258 in epoch 2, gen_loss = 1.4797446667917906, disc_loss = 0.0006170745711579458
Trained batch 259 in epoch 2, gen_loss = 1.4797968974480262, disc_loss = 0.0006169364541375006
Trained batch 260 in epoch 2, gen_loss = 1.4800090291947696, disc_loss = 0.0006169870364661703
Trained batch 261 in epoch 2, gen_loss = 1.4801103645608624, disc_loss = 0.0006172580209930378
Trained batch 262 in epoch 2, gen_loss = 1.4802263929816706, disc_loss = 0.0006176051546504345
Trained batch 263 in epoch 2, gen_loss = 1.4800581430846995, disc_loss = 0.0006186746243408627
Trained batch 264 in epoch 2, gen_loss = 1.480356531323127, disc_loss = 0.0006201668444774904
Trained batch 265 in epoch 2, gen_loss = 1.480104068168124, disc_loss = 0.000621401170912878
Trained batch 266 in epoch 2, gen_loss = 1.4799798526120989, disc_loss = 0.0006223945747206357
Trained batch 267 in epoch 2, gen_loss = 1.4797421400226765, disc_loss = 0.0006232050717929934
Trained batch 268 in epoch 2, gen_loss = 1.4797740390309615, disc_loss = 0.0006236705096390057
Trained batch 269 in epoch 2, gen_loss = 1.4795157114664714, disc_loss = 0.0006234898408702403
Trained batch 270 in epoch 2, gen_loss = 1.4795969447526545, disc_loss = 0.000623469283706354
Trained batch 271 in epoch 2, gen_loss = 1.479533248964478, disc_loss = 0.0006244592315103064
Trained batch 272 in epoch 2, gen_loss = 1.4794505319315872, disc_loss = 0.0006260778914860726
Trained batch 273 in epoch 2, gen_loss = 1.4792489426849533, disc_loss = 0.000627941511236607
Trained batch 274 in epoch 2, gen_loss = 1.4792081559788097, disc_loss = 0.0006298333391631869
Trained batch 275 in epoch 2, gen_loss = 1.4791478354861771, disc_loss = 0.0006311360644969576
Trained batch 276 in epoch 2, gen_loss = 1.4792681398804868, disc_loss = 0.0006323157967696982
Trained batch 277 in epoch 2, gen_loss = 1.4795180503412975, disc_loss = 0.0006339023419046144
Trained batch 278 in epoch 2, gen_loss = 1.4795748499559245, disc_loss = 0.000636086053562127
Trained batch 279 in epoch 2, gen_loss = 1.4796151276145662, disc_loss = 0.000639191155538096
Trained batch 280 in epoch 2, gen_loss = 1.4797649387787246, disc_loss = 0.0006439926038956886
Trained batch 281 in epoch 2, gen_loss = 1.4797670913080798, disc_loss = 0.000650063683427474
Trained batch 282 in epoch 2, gen_loss = 1.479525913619321, disc_loss = 0.000656272231620924
Trained batch 283 in epoch 2, gen_loss = 1.4797316059260301, disc_loss = 0.0006624054803978652
Trained batch 284 in epoch 2, gen_loss = 1.4796494910591527, disc_loss = 0.0006671958084201865
Trained batch 285 in epoch 2, gen_loss = 1.4799415348293063, disc_loss = 0.000670991488325351
Trained batch 286 in epoch 2, gen_loss = 1.4800331152274633, disc_loss = 0.0006757715983861467
Trained batch 287 in epoch 2, gen_loss = 1.480154063138697, disc_loss = 0.0006817971188866068
Trained batch 288 in epoch 2, gen_loss = 1.4797887356636021, disc_loss = 0.0006880433218888809
Trained batch 289 in epoch 2, gen_loss = 1.4799474592866568, disc_loss = 0.0006939556437608753
Trained batch 290 in epoch 2, gen_loss = 1.479704772483852, disc_loss = 0.0006988377688785445
Trained batch 291 in epoch 2, gen_loss = 1.4797420142448112, disc_loss = 0.0007027925437871265
Trained batch 292 in epoch 2, gen_loss = 1.4798142861180745, disc_loss = 0.0007056209640958865
Trained batch 293 in epoch 2, gen_loss = 1.4799175955811326, disc_loss = 0.0007075939282337773
Trained batch 294 in epoch 2, gen_loss = 1.4797659324387373, disc_loss = 0.0007091258478871846
Trained batch 295 in epoch 2, gen_loss = 1.4800355901589264, disc_loss = 0.0007103475241770817
Trained batch 296 in epoch 2, gen_loss = 1.4802156819237604, disc_loss = 0.0007107486889183346
Trained batch 297 in epoch 2, gen_loss = 1.4801437738757806, disc_loss = 0.0007106124420709683
Trained batch 298 in epoch 2, gen_loss = 1.480312680320995, disc_loss = 0.0007103634704243903
Trained batch 299 in epoch 2, gen_loss = 1.480367740392685, disc_loss = 0.0007099272828781977
Trained batch 300 in epoch 2, gen_loss = 1.480322456439072, disc_loss = 0.0007098790080645478
Trained batch 301 in epoch 2, gen_loss = 1.4802023551321977, disc_loss = 0.000709698996922951
Trained batch 302 in epoch 2, gen_loss = 1.4802143719330085, disc_loss = 0.0007090418272584111
Trained batch 303 in epoch 2, gen_loss = 1.4801673383304947, disc_loss = 0.0007078996824068446
Trained batch 304 in epoch 2, gen_loss = 1.4802536264794772, disc_loss = 0.0007068585602520797
Trained batch 305 in epoch 2, gen_loss = 1.4801299918710795, disc_loss = 0.0007064298306610071
Trained batch 306 in epoch 2, gen_loss = 1.4800351217437644, disc_loss = 0.0007068009107413092
Trained batch 307 in epoch 2, gen_loss = 1.4798394542235833, disc_loss = 0.0007080495997797698
Trained batch 308 in epoch 2, gen_loss = 1.4800392138533607, disc_loss = 0.0007099126481442052
Trained batch 309 in epoch 2, gen_loss = 1.4799904565657338, disc_loss = 0.0007115993536107483
Trained batch 310 in epoch 2, gen_loss = 1.4799091191153817, disc_loss = 0.0007126407190211045
Trained batch 311 in epoch 2, gen_loss = 1.4797102079177513, disc_loss = 0.0007127843433782124
Trained batch 312 in epoch 2, gen_loss = 1.479689734050641, disc_loss = 0.0007127508232459283
Trained batch 313 in epoch 2, gen_loss = 1.4794783531480533, disc_loss = 0.0007129876368685038
Trained batch 314 in epoch 2, gen_loss = 1.4793911245134141, disc_loss = 0.000712976512306976
Trained batch 315 in epoch 2, gen_loss = 1.4791945634008963, disc_loss = 0.0007122014131606261
Trained batch 316 in epoch 2, gen_loss = 1.4791355463984637, disc_loss = 0.0007110244333957048
Trained batch 317 in epoch 2, gen_loss = 1.4791943543362167, disc_loss = 0.0007098150076586226
Trained batch 318 in epoch 2, gen_loss = 1.4793036918281388, disc_loss = 0.0007084937016975987
Trained batch 319 in epoch 2, gen_loss = 1.479385033994913, disc_loss = 0.0007073551414578105
Trained batch 320 in epoch 2, gen_loss = 1.4791639077700558, disc_loss = 0.000706409761407253
Trained batch 321 in epoch 2, gen_loss = 1.4789735741496826, disc_loss = 0.0007057540126467378
Trained batch 322 in epoch 2, gen_loss = 1.479071255069768, disc_loss = 0.0007051710581267108
Trained batch 323 in epoch 2, gen_loss = 1.4789828341684224, disc_loss = 0.0007043651508686225
Trained batch 324 in epoch 2, gen_loss = 1.478746180167565, disc_loss = 0.0007032847320302748
Trained batch 325 in epoch 2, gen_loss = 1.478926268457635, disc_loss = 0.0007033010891515853
Trained batch 326 in epoch 2, gen_loss = 1.478896647418311, disc_loss = 0.0007044296106109994
Trained batch 327 in epoch 2, gen_loss = 1.4790591230479682, disc_loss = 0.0007057510784517679
Trained batch 328 in epoch 2, gen_loss = 1.479221113184665, disc_loss = 0.0007062425439197876
Trained batch 329 in epoch 2, gen_loss = 1.4792426232135658, disc_loss = 0.0007056092275447692
Trained batch 330 in epoch 2, gen_loss = 1.4793681306061068, disc_loss = 0.0007042333944785068
Trained batch 331 in epoch 2, gen_loss = 1.4795091320951301, disc_loss = 0.0007027393273664891
Trained batch 332 in epoch 2, gen_loss = 1.4795370313140366, disc_loss = 0.0007013129785761108
Trained batch 333 in epoch 2, gen_loss = 1.4795594675812178, disc_loss = 0.000700122939464901
Trained batch 334 in epoch 2, gen_loss = 1.4794361228373514, disc_loss = 0.0006990716594997655
Trained batch 335 in epoch 2, gen_loss = 1.4792657845786639, disc_loss = 0.0006978934698054218
Trained batch 336 in epoch 2, gen_loss = 1.4793064640254578, disc_loss = 0.0006966241693676198
Trained batch 337 in epoch 2, gen_loss = 1.4793985697644703, disc_loss = 0.0006954120063500551
Trained batch 338 in epoch 2, gen_loss = 1.4793517804075482, disc_loss = 0.0006942196051088083
Trained batch 339 in epoch 2, gen_loss = 1.47958183779436, disc_loss = 0.0006929865882043754
Trained batch 340 in epoch 2, gen_loss = 1.4794696384161448, disc_loss = 0.0006920542054426585
Trained batch 341 in epoch 2, gen_loss = 1.4791323898131388, disc_loss = 0.0006918795988469505
Trained batch 342 in epoch 2, gen_loss = 1.4789237499932157, disc_loss = 0.0006917741206259421
Trained batch 343 in epoch 2, gen_loss = 1.4788913418387257, disc_loss = 0.0006912700505910285
Trained batch 344 in epoch 2, gen_loss = 1.4786230844000112, disc_loss = 0.0006906049885783695
Trained batch 345 in epoch 2, gen_loss = 1.4787628488733588, disc_loss = 0.0006906014541685554
Trained batch 346 in epoch 2, gen_loss = 1.4788829122565321, disc_loss = 0.0006914818501324723
Trained batch 347 in epoch 2, gen_loss = 1.4790028025364053, disc_loss = 0.0006926628980024895
Trained batch 348 in epoch 2, gen_loss = 1.4790063871012034, disc_loss = 0.0006940165270012496
Trained batch 349 in epoch 2, gen_loss = 1.4791754937171937, disc_loss = 0.0006954877583692516
Trained batch 350 in epoch 2, gen_loss = 1.4790771136596332, disc_loss = 0.0006966180283097985
Trained batch 351 in epoch 2, gen_loss = 1.4793342609297147, disc_loss = 0.0006972706549855833
Trained batch 352 in epoch 2, gen_loss = 1.4792476983651224, disc_loss = 0.0006976541450887618
Trained batch 353 in epoch 2, gen_loss = 1.479110004874946, disc_loss = 0.0006986843626521985
Trained batch 354 in epoch 2, gen_loss = 1.4789489151726307, disc_loss = 0.0007005253739074581
Trained batch 355 in epoch 2, gen_loss = 1.4789398235551428, disc_loss = 0.0007021476452423945
Trained batch 356 in epoch 2, gen_loss = 1.4787854714219977, disc_loss = 0.0007030811411161002
Trained batch 357 in epoch 2, gen_loss = 1.4787558423740237, disc_loss = 0.000704730767358352
Trained batch 358 in epoch 2, gen_loss = 1.478664362663014, disc_loss = 0.0007066717810334098
Trained batch 359 in epoch 2, gen_loss = 1.4787669440110525, disc_loss = 0.0007077894333229374
Trained batch 360 in epoch 2, gen_loss = 1.4787341082195167, disc_loss = 0.0007078091744472172
Trained batch 361 in epoch 2, gen_loss = 1.478737478098158, disc_loss = 0.0007078561679642128
Trained batch 362 in epoch 2, gen_loss = 1.4786339676412998, disc_loss = 0.0007081740113990587
Trained batch 363 in epoch 2, gen_loss = 1.4786404819933923, disc_loss = 0.0007082196927592952
Trained batch 364 in epoch 2, gen_loss = 1.4787810851449836, disc_loss = 0.0007080522796046627
Trained batch 365 in epoch 2, gen_loss = 1.4788788869732716, disc_loss = 0.000707676156722658
Trained batch 366 in epoch 2, gen_loss = 1.4788667765885024, disc_loss = 0.0007069184470935078
Trained batch 367 in epoch 2, gen_loss = 1.4787750082171482, disc_loss = 0.0007058303622809193
Trained batch 368 in epoch 2, gen_loss = 1.478886813975285, disc_loss = 0.0007050036815759224
Trained batch 369 in epoch 2, gen_loss = 1.4787346997776547, disc_loss = 0.0007046937224741497
Trained batch 370 in epoch 2, gen_loss = 1.4788636213364306, disc_loss = 0.0007046395993959083
Trained batch 371 in epoch 2, gen_loss = 1.4789411419181413, disc_loss = 0.0007042892546607658
Trained batch 372 in epoch 2, gen_loss = 1.4790664032381278, disc_loss = 0.0007035597541569869
Trained batch 373 in epoch 2, gen_loss = 1.4790999503696667, disc_loss = 0.0007023951078016176
Trained batch 374 in epoch 2, gen_loss = 1.4791163136164347, disc_loss = 0.0007011271757461752
Trained batch 375 in epoch 2, gen_loss = 1.4793204627138503, disc_loss = 0.0007002792724651567
Trained batch 376 in epoch 2, gen_loss = 1.4793912115400603, disc_loss = 0.0006993943496112556
Trained batch 377 in epoch 2, gen_loss = 1.479337855936989, disc_loss = 0.0006982934007605307
Trained batch 378 in epoch 2, gen_loss = 1.479259708940511, disc_loss = 0.0006972047994309535
Trained batch 379 in epoch 2, gen_loss = 1.4791448979001296, disc_loss = 0.000696324122308349
Trained batch 380 in epoch 2, gen_loss = 1.4792127737535892, disc_loss = 0.000695482433904659
Trained batch 381 in epoch 2, gen_loss = 1.4793011795787911, disc_loss = 0.0006945488194057948
Trained batch 382 in epoch 2, gen_loss = 1.4793180719056889, disc_loss = 0.000693987262766266
Trained batch 383 in epoch 2, gen_loss = 1.4791075459991891, disc_loss = 0.0006933860898925559
Trained batch 384 in epoch 2, gen_loss = 1.4790186795321378, disc_loss = 0.0006926542054635001
Trained batch 385 in epoch 2, gen_loss = 1.478802120129679, disc_loss = 0.0006919626681959869
Trained batch 386 in epoch 2, gen_loss = 1.478892065757929, disc_loss = 0.0006918695583312053
Trained batch 387 in epoch 2, gen_loss = 1.4788708232112766, disc_loss = 0.0006921896400826037
Trained batch 388 in epoch 2, gen_loss = 1.478729028015333, disc_loss = 0.0006927408400763204
Trained batch 389 in epoch 2, gen_loss = 1.47881361246109, disc_loss = 0.0006933955931274865
Trained batch 390 in epoch 2, gen_loss = 1.4786979822856385, disc_loss = 0.0006939850432653566
Trained batch 391 in epoch 2, gen_loss = 1.4786976268705057, disc_loss = 0.000694746887960236
Trained batch 392 in epoch 2, gen_loss = 1.4785837268708013, disc_loss = 0.000695519979799382
Trained batch 393 in epoch 2, gen_loss = 1.478552336922757, disc_loss = 0.0006959609240651022
Trained batch 394 in epoch 2, gen_loss = 1.4783948451657838, disc_loss = 0.0006957419787288962
Trained batch 395 in epoch 2, gen_loss = 1.4783603019184537, disc_loss = 0.0006949281538769043
Trained batch 396 in epoch 2, gen_loss = 1.4784339092840777, disc_loss = 0.0006937827457942454
Trained batch 397 in epoch 2, gen_loss = 1.4784539258060743, disc_loss = 0.000692735487772456
Trained batch 398 in epoch 2, gen_loss = 1.4786898339900159, disc_loss = 0.0006921077330210444
Trained batch 399 in epoch 2, gen_loss = 1.4786444595456123, disc_loss = 0.0006921610398421763
Trained batch 400 in epoch 2, gen_loss = 1.4786812634836706, disc_loss = 0.0006927102563950347
Trained batch 401 in epoch 2, gen_loss = 1.4785894134744484, disc_loss = 0.0006933989654444575
Trained batch 402 in epoch 2, gen_loss = 1.4784669361398475, disc_loss = 0.0006942124867600344
Trained batch 403 in epoch 2, gen_loss = 1.4784842104014784, disc_loss = 0.00069486424950756
Trained batch 404 in epoch 2, gen_loss = 1.4784286628534764, disc_loss = 0.0006951999940397793
Trained batch 405 in epoch 2, gen_loss = 1.4784143223551107, disc_loss = 0.00069512975360026
Trained batch 406 in epoch 2, gen_loss = 1.4785565943331331, disc_loss = 0.0006950205532777872
Trained batch 407 in epoch 2, gen_loss = 1.4784132674628614, disc_loss = 0.0006950259644237995
Trained batch 408 in epoch 2, gen_loss = 1.478482850897866, disc_loss = 0.0006951696405495792
Trained batch 409 in epoch 2, gen_loss = 1.4785917875243397, disc_loss = 0.0006952226859738869
Trained batch 410 in epoch 2, gen_loss = 1.4786869586239186, disc_loss = 0.0006954672313980768
Trained batch 411 in epoch 2, gen_loss = 1.4786879185912678, disc_loss = 0.0006958594533995707
Trained batch 412 in epoch 2, gen_loss = 1.4787210812002927, disc_loss = 0.0006963615440318167
Trained batch 413 in epoch 2, gen_loss = 1.4786932946403246, disc_loss = 0.000696480514834284
Trained batch 414 in epoch 2, gen_loss = 1.4785686837621481, disc_loss = 0.0006961741937038275
Trained batch 415 in epoch 2, gen_loss = 1.4785089117403214, disc_loss = 0.0006956873184418117
Trained batch 416 in epoch 2, gen_loss = 1.4786016306431173, disc_loss = 0.0006951308221979473
Trained batch 417 in epoch 2, gen_loss = 1.4786474676223462, disc_loss = 0.0006943076447796513
Trained batch 418 in epoch 2, gen_loss = 1.4788517471145046, disc_loss = 0.0006933793503911121
Trained batch 419 in epoch 2, gen_loss = 1.478975507475081, disc_loss = 0.0006923645145087946
Trained batch 420 in epoch 2, gen_loss = 1.4787631558692371, disc_loss = 0.0006914042377310215
Trained batch 421 in epoch 2, gen_loss = 1.4788380333032654, disc_loss = 0.0006906515680737926
Trained batch 422 in epoch 2, gen_loss = 1.4788489116280918, disc_loss = 0.000690290772140876
Trained batch 423 in epoch 2, gen_loss = 1.4786503857599114, disc_loss = 0.0006900000461308013
Trained batch 424 in epoch 2, gen_loss = 1.478623267622555, disc_loss = 0.0006893611562383525
Trained batch 425 in epoch 2, gen_loss = 1.4783773377467768, disc_loss = 0.0006885386177036964
Trained batch 426 in epoch 2, gen_loss = 1.4784166938527128, disc_loss = 0.0006883120906116131
Trained batch 427 in epoch 2, gen_loss = 1.4785208362285223, disc_loss = 0.0006881523253145915
Trained batch 428 in epoch 2, gen_loss = 1.4784330627023479, disc_loss = 0.0006875864550034952
Trained batch 429 in epoch 2, gen_loss = 1.4786773914514586, disc_loss = 0.0006867128236186799
Trained batch 430 in epoch 2, gen_loss = 1.4787115704985616, disc_loss = 0.000686094550558489
Trained batch 431 in epoch 2, gen_loss = 1.478636464311017, disc_loss = 0.000686088954723716
Trained batch 432 in epoch 2, gen_loss = 1.4785821024870487, disc_loss = 0.000686833892000396
Trained batch 433 in epoch 2, gen_loss = 1.478684084481358, disc_loss = 0.0006878983142489594
Trained batch 434 in epoch 2, gen_loss = 1.478682522664125, disc_loss = 0.0006889531758196395
Trained batch 435 in epoch 2, gen_loss = 1.4786615861118386, disc_loss = 0.0006901880847973698
Trained batch 436 in epoch 2, gen_loss = 1.478784890414921, disc_loss = 0.0006913919224525275
Trained batch 437 in epoch 2, gen_loss = 1.4787524298990153, disc_loss = 0.0006918714431722618
Trained batch 438 in epoch 2, gen_loss = 1.4787400287484798, disc_loss = 0.0006917630834611036
Trained batch 439 in epoch 2, gen_loss = 1.4787533470175482, disc_loss = 0.0006912114832878367
Trained batch 440 in epoch 2, gen_loss = 1.4787638963214935, disc_loss = 0.0006904930215278248
Trained batch 441 in epoch 2, gen_loss = 1.4788245073271014, disc_loss = 0.0006900436655255835
Trained batch 442 in epoch 2, gen_loss = 1.4788454119830852, disc_loss = 0.0006897587015905311
Trained batch 443 in epoch 2, gen_loss = 1.4788052391361546, disc_loss = 0.0006890999295367012
Trained batch 444 in epoch 2, gen_loss = 1.4787318256463897, disc_loss = 0.0006880391721046017
Trained batch 445 in epoch 2, gen_loss = 1.4787769004903033, disc_loss = 0.0006869541476373644
Trained batch 446 in epoch 2, gen_loss = 1.4786773557364274, disc_loss = 0.000686023541604027
Trained batch 447 in epoch 2, gen_loss = 1.4787796674562352, disc_loss = 0.0006854418138898057
Trained batch 448 in epoch 2, gen_loss = 1.4787518595799571, disc_loss = 0.0006852589176803358
Trained batch 449 in epoch 2, gen_loss = 1.4787429963217842, disc_loss = 0.0006852429794445117
Trained batch 450 in epoch 2, gen_loss = 1.4787384435501436, disc_loss = 0.0006849779646434282
Trained batch 451 in epoch 2, gen_loss = 1.478573224713317, disc_loss = 0.0006843149715525086
Trained batch 452 in epoch 2, gen_loss = 1.4784999441100535, disc_loss = 0.000683786708029721
Trained batch 453 in epoch 2, gen_loss = 1.4785097485596914, disc_loss = 0.0006839692356905465
Trained batch 454 in epoch 2, gen_loss = 1.478519862300747, disc_loss = 0.0006848203214998408
Trained batch 455 in epoch 2, gen_loss = 1.4785753648009217, disc_loss = 0.0006854768021105229
Trained batch 456 in epoch 2, gen_loss = 1.4785151025137704, disc_loss = 0.0006852138303696633
Trained batch 457 in epoch 2, gen_loss = 1.478617927393018, disc_loss = 0.0006845986915589106
Trained batch 458 in epoch 2, gen_loss = 1.4786913929941348, disc_loss = 0.0006838189755337645
Trained batch 459 in epoch 2, gen_loss = 1.4786288380622863, disc_loss = 0.0006830783036686784
Trained batch 460 in epoch 2, gen_loss = 1.4786422260412684, disc_loss = 0.0006824987556963629
Trained batch 461 in epoch 2, gen_loss = 1.4787773010018583, disc_loss = 0.0006819429995531914
Trained batch 462 in epoch 2, gen_loss = 1.4787308183653565, disc_loss = 0.0006811655034171819
Trained batch 463 in epoch 2, gen_loss = 1.4788418345410248, disc_loss = 0.0006804556768311786
Trained batch 464 in epoch 2, gen_loss = 1.4787965313080818, disc_loss = 0.0006799928302268287
Trained batch 465 in epoch 2, gen_loss = 1.4787360908135836, disc_loss = 0.0006798408375495881
Trained batch 466 in epoch 2, gen_loss = 1.4787623022046794, disc_loss = 0.0006798948804766629
Trained batch 467 in epoch 2, gen_loss = 1.478838247875882, disc_loss = 0.0006797192032753916
Trained batch 468 in epoch 2, gen_loss = 1.4786544656956881, disc_loss = 0.0006793617425838421
Trained batch 469 in epoch 2, gen_loss = 1.478577746989879, disc_loss = 0.0006789825397526271
Trained batch 470 in epoch 2, gen_loss = 1.4785808719647158, disc_loss = 0.0006788541686005847
Trained batch 471 in epoch 2, gen_loss = 1.478655877002215, disc_loss = 0.0006790624681913977
Trained batch 472 in epoch 2, gen_loss = 1.478637077591636, disc_loss = 0.0006790214771541214
Trained batch 473 in epoch 2, gen_loss = 1.4786344195720014, disc_loss = 0.0006786737169391074
Trained batch 474 in epoch 2, gen_loss = 1.4784850943715948, disc_loss = 0.000678540995669257
Trained batch 475 in epoch 2, gen_loss = 1.4783879951769565, disc_loss = 0.0006787345594320027
Trained batch 476 in epoch 2, gen_loss = 1.478257971739619, disc_loss = 0.000679394525586358
Trained batch 477 in epoch 2, gen_loss = 1.4784852972090494, disc_loss = 0.0006811672526766804
Trained batch 478 in epoch 2, gen_loss = 1.4784549930150424, disc_loss = 0.0006834438543911102
Trained batch 479 in epoch 2, gen_loss = 1.4784394326309362, disc_loss = 0.0006856770167663248
Trained batch 480 in epoch 2, gen_loss = 1.47842667479525, disc_loss = 0.0006876503010708819
Trained batch 481 in epoch 2, gen_loss = 1.4782513511131414, disc_loss = 0.0006896789155572487
Trained batch 482 in epoch 2, gen_loss = 1.4782311827499675, disc_loss = 0.0006915730856926379
Trained batch 483 in epoch 2, gen_loss = 1.4784477680675254, disc_loss = 0.0006934738882313663
Trained batch 484 in epoch 2, gen_loss = 1.4783761697946136, disc_loss = 0.0006953050615566005
Trained batch 485 in epoch 2, gen_loss = 1.4783356714641116, disc_loss = 0.0006967551401471854
Trained batch 486 in epoch 2, gen_loss = 1.478265628432836, disc_loss = 0.0006978144165278112
Trained batch 487 in epoch 2, gen_loss = 1.4782000401469528, disc_loss = 0.0006985442737533928
Trained batch 488 in epoch 2, gen_loss = 1.4782381874408215, disc_loss = 0.0006987916466416715
Trained batch 489 in epoch 2, gen_loss = 1.4782708026924911, disc_loss = 0.0006985419522792728
Trained batch 490 in epoch 2, gen_loss = 1.4783056544674875, disc_loss = 0.0006980499059856677
Trained batch 491 in epoch 2, gen_loss = 1.4782890115326983, disc_loss = 0.0006973984161412203
Trained batch 492 in epoch 2, gen_loss = 1.4781643534286995, disc_loss = 0.000696731138386212
Trained batch 493 in epoch 2, gen_loss = 1.4781051632846416, disc_loss = 0.0006960562888619128
Trained batch 494 in epoch 2, gen_loss = 1.4781888041833435, disc_loss = 0.0006954384364735692
Trained batch 495 in epoch 2, gen_loss = 1.4780885377718556, disc_loss = 0.0006950064474538874
Trained batch 496 in epoch 2, gen_loss = 1.4783082586418934, disc_loss = 0.000695139237299376
Trained batch 497 in epoch 2, gen_loss = 1.4782179280457248, disc_loss = 0.000696074336924521
Trained batch 498 in epoch 2, gen_loss = 1.478299199459787, disc_loss = 0.0006974481898259637
Trained batch 499 in epoch 2, gen_loss = 1.4782188048362732, disc_loss = 0.0006989521220384632
Trained batch 500 in epoch 2, gen_loss = 1.4782163963584367, disc_loss = 0.0007009139909149202
Trained batch 501 in epoch 2, gen_loss = 1.4781842015653968, disc_loss = 0.0007027225844913155
Trained batch 502 in epoch 2, gen_loss = 1.4782830144965624, disc_loss = 0.00070389566465006
Trained batch 503 in epoch 2, gen_loss = 1.4782230932088125, disc_loss = 0.0007044491669061937
Trained batch 504 in epoch 2, gen_loss = 1.478214955802011, disc_loss = 0.0007044382112407319
Trained batch 505 in epoch 2, gen_loss = 1.478027273308147, disc_loss = 0.0007040390121373679
Trained batch 506 in epoch 2, gen_loss = 1.4781792516539083, disc_loss = 0.0007038606056418633
Trained batch 507 in epoch 2, gen_loss = 1.478069341323507, disc_loss = 0.0007042494138959873
Trained batch 508 in epoch 2, gen_loss = 1.4780210462675114, disc_loss = 0.0007051073485257631
Trained batch 509 in epoch 2, gen_loss = 1.4778781421044294, disc_loss = 0.0007056980088236742
Trained batch 510 in epoch 2, gen_loss = 1.4778052643087278, disc_loss = 0.0007058928737796409
Trained batch 511 in epoch 2, gen_loss = 1.4777636041399091, disc_loss = 0.0007056765767003981
Trained batch 512 in epoch 2, gen_loss = 1.4777472630346495, disc_loss = 0.0007051055401132022
Trained batch 513 in epoch 2, gen_loss = 1.4777287588045291, disc_loss = 0.0007044327592715922
Trained batch 514 in epoch 2, gen_loss = 1.4778657730343272, disc_loss = 0.0007041650461157313
Trained batch 515 in epoch 2, gen_loss = 1.477967965972516, disc_loss = 0.0007040858650415353
Trained batch 516 in epoch 2, gen_loss = 1.4780468977627488, disc_loss = 0.0007040620914278048
Trained batch 517 in epoch 2, gen_loss = 1.4780524458203996, disc_loss = 0.0007040798931252696
Trained batch 518 in epoch 2, gen_loss = 1.4780926185306555, disc_loss = 0.000703941252519312
Trained batch 519 in epoch 2, gen_loss = 1.4780860100801174, disc_loss = 0.0007035596457101817
Trained batch 520 in epoch 2, gen_loss = 1.4782092106777052, disc_loss = 0.0007029310049077554
Trained batch 521 in epoch 2, gen_loss = 1.478247213866062, disc_loss = 0.0007021693720817262
Trained batch 522 in epoch 2, gen_loss = 1.4782809342754502, disc_loss = 0.0007015733687101594
Trained batch 523 in epoch 2, gen_loss = 1.4782151124859584, disc_loss = 0.0007015254481760909
Trained batch 524 in epoch 2, gen_loss = 1.478086293992542, disc_loss = 0.0007017641453283085
Trained batch 525 in epoch 2, gen_loss = 1.478047267565709, disc_loss = 0.0007014958543546707
Trained batch 526 in epoch 2, gen_loss = 1.4780056797802108, disc_loss = 0.0007008104094432709
Trained batch 527 in epoch 2, gen_loss = 1.4779681195363854, disc_loss = 0.0007000052449009011
Trained batch 528 in epoch 2, gen_loss = 1.4780909404412108, disc_loss = 0.0006993808849335741
Trained batch 529 in epoch 2, gen_loss = 1.478107388964239, disc_loss = 0.0006988638820607689
Trained batch 530 in epoch 2, gen_loss = 1.4780628838332583, disc_loss = 0.0006983238710022554
Trained batch 531 in epoch 2, gen_loss = 1.4780172956617255, disc_loss = 0.0006977049107858088
Trained batch 532 in epoch 2, gen_loss = 1.477986043210772, disc_loss = 0.0006972548247332026
Trained batch 533 in epoch 2, gen_loss = 1.477957342224621, disc_loss = 0.0006970082507946194
Trained batch 534 in epoch 2, gen_loss = 1.4780261881997652, disc_loss = 0.0006973497854343345
Trained batch 535 in epoch 2, gen_loss = 1.4780101022168772, disc_loss = 0.0006980666253659718
Trained batch 536 in epoch 2, gen_loss = 1.4779701938842262, disc_loss = 0.000698554483575103
Trained batch 537 in epoch 2, gen_loss = 1.478016980518639, disc_loss = 0.0006987518897021733
Trained batch 538 in epoch 2, gen_loss = 1.4780420038386046, disc_loss = 0.000698767200902628
Trained batch 539 in epoch 2, gen_loss = 1.4779758232611198, disc_loss = 0.0006986985112167463
Trained batch 540 in epoch 2, gen_loss = 1.4779767719081942, disc_loss = 0.0006987925654338748
Trained batch 541 in epoch 2, gen_loss = 1.4779816604188447, disc_loss = 0.0006985866838782197
Trained batch 542 in epoch 2, gen_loss = 1.477970277626431, disc_loss = 0.0006980190910242454
Trained batch 543 in epoch 2, gen_loss = 1.4779309352092884, disc_loss = 0.00069744930621763
Trained batch 544 in epoch 2, gen_loss = 1.477913747796225, disc_loss = 0.0006968723469864526
Trained batch 545 in epoch 2, gen_loss = 1.4779094658491811, disc_loss = 0.0006963144936916527
Trained batch 546 in epoch 2, gen_loss = 1.4778191498472224, disc_loss = 0.0006956717749247566
Trained batch 547 in epoch 2, gen_loss = 1.477957459696888, disc_loss = 0.0006951589196957359
Trained batch 548 in epoch 2, gen_loss = 1.4779161351626036, disc_loss = 0.0006945979151820071
Trained batch 549 in epoch 2, gen_loss = 1.4778550598838112, disc_loss = 0.000694265691537029
Trained batch 550 in epoch 2, gen_loss = 1.4778048539983815, disc_loss = 0.0006940584745080195
Trained batch 551 in epoch 2, gen_loss = 1.4777969242869944, disc_loss = 0.0006937131496722915
Trained batch 552 in epoch 2, gen_loss = 1.477911059507194, disc_loss = 0.0006931660434298106
Trained batch 553 in epoch 2, gen_loss = 1.4778677920141805, disc_loss = 0.0006925127762300467
Trained batch 554 in epoch 2, gen_loss = 1.4779435000978074, disc_loss = 0.0006919032117710575
Trained batch 555 in epoch 2, gen_loss = 1.4778524163386804, disc_loss = 0.0006912270286939151
Trained batch 556 in epoch 2, gen_loss = 1.4776819674716175, disc_loss = 0.0006905899084408482
Trained batch 557 in epoch 2, gen_loss = 1.4778181532377839, disc_loss = 0.0006900554793099472
Trained batch 558 in epoch 2, gen_loss = 1.477768020681064, disc_loss = 0.0006897558432585961
Trained batch 559 in epoch 2, gen_loss = 1.4776898954595838, disc_loss = 0.0006894758131498487
Trained batch 560 in epoch 2, gen_loss = 1.4777351369194807, disc_loss = 0.0006891448034810686
Trained batch 561 in epoch 2, gen_loss = 1.4776136993937645, disc_loss = 0.0006890881266637567
Trained batch 562 in epoch 2, gen_loss = 1.4777884576502744, disc_loss = 0.0006896381557815283
Trained batch 563 in epoch 2, gen_loss = 1.4777497192646594, disc_loss = 0.0006903275345703537
Trained batch 564 in epoch 2, gen_loss = 1.4776106019990634, disc_loss = 0.000691196227274151
Trained batch 565 in epoch 2, gen_loss = 1.4775496727586215, disc_loss = 0.0006925863079990379
Trained batch 566 in epoch 2, gen_loss = 1.477587756025728, disc_loss = 0.0006944802086942006
Trained batch 567 in epoch 2, gen_loss = 1.47756776444509, disc_loss = 0.000696701472150662
Trained batch 568 in epoch 2, gen_loss = 1.477640948731367, disc_loss = 0.0006996586169036406
Trained batch 569 in epoch 2, gen_loss = 1.4776570240656535, disc_loss = 0.0007017005956170084
Trained batch 570 in epoch 2, gen_loss = 1.4777700005396026, disc_loss = 0.0007026953273911548
Trained batch 571 in epoch 2, gen_loss = 1.4776805489213316, disc_loss = 0.0007029659466313644
Trained batch 572 in epoch 2, gen_loss = 1.4776712581125229, disc_loss = 0.0007029778094132094
Trained batch 573 in epoch 2, gen_loss = 1.4777023553432904, disc_loss = 0.0007029358016536734
Trained batch 574 in epoch 2, gen_loss = 1.47763123076895, disc_loss = 0.0007027373316383962
Trained batch 575 in epoch 2, gen_loss = 1.4775803136742778, disc_loss = 0.000702458897169183
Trained batch 576 in epoch 2, gen_loss = 1.4776222784349782, disc_loss = 0.0007021379724124357
Trained batch 577 in epoch 2, gen_loss = 1.4776047833238093, disc_loss = 0.0007020116776478103
Trained batch 578 in epoch 2, gen_loss = 1.4775867338625261, disc_loss = 0.0007018684953684791
Trained batch 579 in epoch 2, gen_loss = 1.4775280755141686, disc_loss = 0.0007015188342283464
Trained batch 580 in epoch 2, gen_loss = 1.4774389316210854, disc_loss = 0.0007011231910663765
Trained batch 581 in epoch 2, gen_loss = 1.4776435127782659, disc_loss = 0.000700926302082691
Trained batch 582 in epoch 2, gen_loss = 1.4776105739649124, disc_loss = 0.000701093726866722
Trained batch 583 in epoch 2, gen_loss = 1.4777558650055977, disc_loss = 0.0007026162149660905
Trained batch 584 in epoch 2, gen_loss = 1.477747236765348, disc_loss = 0.0007055316559431088
Trained batch 585 in epoch 2, gen_loss = 1.477760769604823, disc_loss = 0.0007085998972161489
Trained batch 586 in epoch 2, gen_loss = 1.4776737669663698, disc_loss = 0.0007108045406800217
Trained batch 587 in epoch 2, gen_loss = 1.477716533099713, disc_loss = 0.0007119808025742473
Trained batch 588 in epoch 2, gen_loss = 1.4777135683037024, disc_loss = 0.000712370365295371
Trained batch 589 in epoch 2, gen_loss = 1.4777871645103067, disc_loss = 0.0007124286836804427
Trained batch 590 in epoch 2, gen_loss = 1.477691670157986, disc_loss = 0.0007123728195339671
Trained batch 591 in epoch 2, gen_loss = 1.4775966107845306, disc_loss = 0.0007123350208506028
Trained batch 592 in epoch 2, gen_loss = 1.4776316455001575, disc_loss = 0.0007120945926374421
Trained batch 593 in epoch 2, gen_loss = 1.477451756345704, disc_loss = 0.0007114002957788409
Trained batch 594 in epoch 2, gen_loss = 1.4774252154246097, disc_loss = 0.0007105033775496086
Trained batch 595 in epoch 2, gen_loss = 1.4775094551928092, disc_loss = 0.0007097558863822374
Trained batch 596 in epoch 2, gen_loss = 1.4774698260641177, disc_loss = 0.0007090454541509066
Trained batch 597 in epoch 2, gen_loss = 1.4773519565429176, disc_loss = 0.0007083835155945691
Trained batch 598 in epoch 2, gen_loss = 1.4773124124052528, disc_loss = 0.0007077777032685607
Trained batch 599 in epoch 2, gen_loss = 1.4773500378926594, disc_loss = 0.0007071833426743979
Trained batch 600 in epoch 2, gen_loss = 1.4774218002293946, disc_loss = 0.0007065103958857117
Trained batch 601 in epoch 2, gen_loss = 1.4773089663926946, disc_loss = 0.0007058744001106755
Trained batch 602 in epoch 2, gen_loss = 1.4772577787908552, disc_loss = 0.0007054998205056118
Trained batch 603 in epoch 2, gen_loss = 1.4772317666091666, disc_loss = 0.0007052387964777997
Trained batch 604 in epoch 2, gen_loss = 1.4772036609570842, disc_loss = 0.0007049796845203974
Trained batch 605 in epoch 2, gen_loss = 1.4771888381970597, disc_loss = 0.0007046769201809697
Trained batch 606 in epoch 2, gen_loss = 1.4771829829773753, disc_loss = 0.0007044120369368974
Trained batch 607 in epoch 2, gen_loss = 1.4771280488685559, disc_loss = 0.0007043210322607544
Trained batch 608 in epoch 2, gen_loss = 1.4771514209033234, disc_loss = 0.0007043530224650037
Trained batch 609 in epoch 2, gen_loss = 1.4771162439565189, disc_loss = 0.0007044641257380136
Trained batch 610 in epoch 2, gen_loss = 1.4772162780824152, disc_loss = 0.0007046019449479856
Trained batch 611 in epoch 2, gen_loss = 1.4772213494855595, disc_loss = 0.000704551847816903
Trained batch 612 in epoch 2, gen_loss = 1.4773337205121413, disc_loss = 0.0007042059899950825
Trained batch 613 in epoch 2, gen_loss = 1.4773747676358548, disc_loss = 0.0007036091467672398
Trained batch 614 in epoch 2, gen_loss = 1.4773764831263845, disc_loss = 0.0007028061283962438
Trained batch 615 in epoch 2, gen_loss = 1.4773594620939974, disc_loss = 0.0007018874471036902
Trained batch 616 in epoch 2, gen_loss = 1.477400127840583, disc_loss = 0.0007009596173403214
Trained batch 617 in epoch 2, gen_loss = 1.477378239137841, disc_loss = 0.0007001845368872092
Trained batch 618 in epoch 2, gen_loss = 1.4773404107147734, disc_loss = 0.0006996826280957096
Trained batch 619 in epoch 2, gen_loss = 1.4772851186413918, disc_loss = 0.0006997080611801076
Trained batch 620 in epoch 2, gen_loss = 1.4771339782002275, disc_loss = 0.0007001486962703139
Trained batch 621 in epoch 2, gen_loss = 1.4774837641470686, disc_loss = 0.0007001678786881364
Trained batch 622 in epoch 2, gen_loss = 1.4775607042481007, disc_loss = 0.0006996757668715096
Trained batch 623 in epoch 2, gen_loss = 1.4775731720221348, disc_loss = 0.0006990037200478419
Trained batch 624 in epoch 2, gen_loss = 1.4774593852996827, disc_loss = 0.0006983481842558831
Trained batch 625 in epoch 2, gen_loss = 1.4774130340963125, disc_loss = 0.000698207948941175
Trained batch 626 in epoch 2, gen_loss = 1.477390138916612, disc_loss = 0.0006982723363408554
Trained batch 627 in epoch 2, gen_loss = 1.4774346146613928, disc_loss = 0.0006981621680178406
Trained batch 628 in epoch 2, gen_loss = 1.477388377030438, disc_loss = 0.0006976866983958122
Trained batch 629 in epoch 2, gen_loss = 1.4774101030258906, disc_loss = 0.0006970050062851183
Trained batch 630 in epoch 2, gen_loss = 1.4773458350101476, disc_loss = 0.0006963794185889209
Trained batch 631 in epoch 2, gen_loss = 1.477316320319719, disc_loss = 0.0006961060808183142
Trained batch 632 in epoch 2, gen_loss = 1.4772535372307705, disc_loss = 0.0006968732534298646
Trained batch 633 in epoch 2, gen_loss = 1.4772561856248778, disc_loss = 0.0006985679851464445
Trained batch 634 in epoch 2, gen_loss = 1.4771553677836742, disc_loss = 0.0007008456237298825
Trained batch 635 in epoch 2, gen_loss = 1.4771913781106096, disc_loss = 0.0007034569032198849
Trained batch 636 in epoch 2, gen_loss = 1.4771535018549609, disc_loss = 0.0007061936028683309
Trained batch 637 in epoch 2, gen_loss = 1.4771970476850074, disc_loss = 0.0007088858752655957
Trained batch 638 in epoch 2, gen_loss = 1.4770968570395815, disc_loss = 0.0007112588845841959
Trained batch 639 in epoch 2, gen_loss = 1.477148967050016, disc_loss = 0.0007131910261705343
Trained batch 640 in epoch 2, gen_loss = 1.4770250859758969, disc_loss = 0.0007146030484463339
Trained batch 641 in epoch 2, gen_loss = 1.4769893730540884, disc_loss = 0.0007154678087572733
Trained batch 642 in epoch 2, gen_loss = 1.4769904730294021, disc_loss = 0.0007156369841764761
Trained batch 643 in epoch 2, gen_loss = 1.4770473388041028, disc_loss = 0.0007153015511626702
Trained batch 644 in epoch 2, gen_loss = 1.4770451362742933, disc_loss = 0.0007146198627387369
Trained batch 645 in epoch 2, gen_loss = 1.4770907276186043, disc_loss = 0.0007138712068411649
Trained batch 646 in epoch 2, gen_loss = 1.4771195042078056, disc_loss = 0.0007131670957614367
Trained batch 647 in epoch 2, gen_loss = 1.477072713735663, disc_loss = 0.0007126292909370134
Trained batch 648 in epoch 2, gen_loss = 1.476978294471012, disc_loss = 0.0007122866739187094
Trained batch 649 in epoch 2, gen_loss = 1.4769461780328017, disc_loss = 0.0007121162004365872
Trained batch 650 in epoch 2, gen_loss = 1.4768682919705884, disc_loss = 0.0007122813893820784
Trained batch 651 in epoch 2, gen_loss = 1.4767367417461301, disc_loss = 0.0007126848590787017
Trained batch 652 in epoch 2, gen_loss = 1.4767518585710393, disc_loss = 0.0007129394116404625
Trained batch 653 in epoch 2, gen_loss = 1.476700516286611, disc_loss = 0.0007127306211320754
Trained batch 654 in epoch 2, gen_loss = 1.4766526964784579, disc_loss = 0.0007124514415645119
Trained batch 655 in epoch 2, gen_loss = 1.4767439830593947, disc_loss = 0.0007124104304904638
Trained batch 656 in epoch 2, gen_loss = 1.4767226936973212, disc_loss = 0.0007127526172043761
Trained batch 657 in epoch 2, gen_loss = 1.476682477627844, disc_loss = 0.0007130404728658336
Trained batch 658 in epoch 2, gen_loss = 1.4766933818507448, disc_loss = 0.0007131067504539269
Trained batch 659 in epoch 2, gen_loss = 1.4765870339942702, disc_loss = 0.0007131306412867906
Trained batch 660 in epoch 2, gen_loss = 1.47656152107712, disc_loss = 0.0007129300169041944
Trained batch 661 in epoch 2, gen_loss = 1.476448933883736, disc_loss = 0.0007125983465372534
Trained batch 662 in epoch 2, gen_loss = 1.4764548840386116, disc_loss = 0.0007122617044728769
Trained batch 663 in epoch 2, gen_loss = 1.476501112063247, disc_loss = 0.0007119032787553565
Trained batch 664 in epoch 2, gen_loss = 1.4764663029434089, disc_loss = 0.0007114639050805157
Trained batch 665 in epoch 2, gen_loss = 1.4766522352401916, disc_loss = 0.0007111431918096136
Trained batch 666 in epoch 2, gen_loss = 1.4768063505550195, disc_loss = 0.0007109042873225249
Trained batch 667 in epoch 2, gen_loss = 1.4767554739635147, disc_loss = 0.000710744152761735
Trained batch 668 in epoch 2, gen_loss = 1.476745288824643, disc_loss = 0.0007107113536089862
Trained batch 669 in epoch 2, gen_loss = 1.4766976856473666, disc_loss = 0.0007106615965638602
Trained batch 670 in epoch 2, gen_loss = 1.4766972503790023, disc_loss = 0.0007105813174199344
Trained batch 671 in epoch 2, gen_loss = 1.4766453754689013, disc_loss = 0.0007105924549120703
Trained batch 672 in epoch 2, gen_loss = 1.4767104086160305, disc_loss = 0.0007106682755003571
Trained batch 673 in epoch 2, gen_loss = 1.4768816754443002, disc_loss = 0.0007108109165682563
Trained batch 674 in epoch 2, gen_loss = 1.4768333394439133, disc_loss = 0.0007107898239606854
Trained batch 675 in epoch 2, gen_loss = 1.476855923261868, disc_loss = 0.0007105763704240798
Trained batch 676 in epoch 2, gen_loss = 1.4768198378153001, disc_loss = 0.0007102777223844574
Trained batch 677 in epoch 2, gen_loss = 1.476928915949346, disc_loss = 0.0007104045032754686
Trained batch 678 in epoch 2, gen_loss = 1.4770525449856742, disc_loss = 0.0007111973306707645
Trained batch 679 in epoch 2, gen_loss = 1.4770215704160579, disc_loss = 0.0007122517089395414
Trained batch 680 in epoch 2, gen_loss = 1.4771179760780278, disc_loss = 0.0007128264733342996
Trained batch 681 in epoch 2, gen_loss = 1.477121114206454, disc_loss = 0.0007126017950437321
Trained batch 682 in epoch 2, gen_loss = 1.4771018129491178, disc_loss = 0.000711975844549172
Trained batch 683 in epoch 2, gen_loss = 1.477041949305618, disc_loss = 0.0007111898819389699
Trained batch 684 in epoch 2, gen_loss = 1.4769521953415696, disc_loss = 0.0007103897471840827
Trained batch 685 in epoch 2, gen_loss = 1.4771135369473227, disc_loss = 0.0007100054440064812
Trained batch 686 in epoch 2, gen_loss = 1.4770557299104494, disc_loss = 0.0007105573822098229
Trained batch 687 in epoch 2, gen_loss = 1.4770775629683983, disc_loss = 0.0007125095481294625
Trained batch 688 in epoch 2, gen_loss = 1.477039645995042, disc_loss = 0.0007144615873346357
Trained batch 689 in epoch 2, gen_loss = 1.4770679933437403, disc_loss = 0.0007157062914684766
Trained batch 690 in epoch 2, gen_loss = 1.4771921670902655, disc_loss = 0.0007163448173397082
Trained batch 691 in epoch 2, gen_loss = 1.4772102529602933, disc_loss = 0.0007161852923262934
Trained batch 692 in epoch 2, gen_loss = 1.477103458682524, disc_loss = 0.0007159357913081033
Trained batch 693 in epoch 2, gen_loss = 1.477160837189952, disc_loss = 0.0007159929351075298
Trained batch 694 in epoch 2, gen_loss = 1.4772220861997536, disc_loss = 0.0007160230880191135
Trained batch 695 in epoch 2, gen_loss = 1.4772263455322419, disc_loss = 0.0007159257148832066
Trained batch 696 in epoch 2, gen_loss = 1.4770858222819128, disc_loss = 0.0007158133318301001
Trained batch 697 in epoch 2, gen_loss = 1.477268596945656, disc_loss = 0.000716044684399365
Trained batch 698 in epoch 2, gen_loss = 1.47725991851441, disc_loss = 0.0007168604781733258
Trained batch 699 in epoch 2, gen_loss = 1.4772990221636635, disc_loss = 0.0007178707172611861
Trained batch 700 in epoch 2, gen_loss = 1.4771828989839757, disc_loss = 0.000718848625144532
Trained batch 701 in epoch 2, gen_loss = 1.4772138026704815, disc_loss = 0.0007199565211275826
Trained batch 702 in epoch 2, gen_loss = 1.477161434941407, disc_loss = 0.0007210034852801752
Trained batch 703 in epoch 2, gen_loss = 1.4771713572130962, disc_loss = 0.0007220340807262718
Trained batch 704 in epoch 2, gen_loss = 1.4772259253982112, disc_loss = 0.0007232256558581737
Trained batch 705 in epoch 2, gen_loss = 1.4771777997611264, disc_loss = 0.0007245447445003232
Trained batch 706 in epoch 2, gen_loss = 1.477091003678307, disc_loss = 0.0007257836396543144
Trained batch 707 in epoch 2, gen_loss = 1.4770718120922477, disc_loss = 0.0007268808719864521
Trained batch 708 in epoch 2, gen_loss = 1.4770855619473584, disc_loss = 0.0007274974720360125
Trained batch 709 in epoch 2, gen_loss = 1.4770178764638766, disc_loss = 0.0007275198876913506
Trained batch 710 in epoch 2, gen_loss = 1.477038713950145, disc_loss = 0.0007272885891536195
Trained batch 711 in epoch 2, gen_loss = 1.4770129773389087, disc_loss = 0.0007269877838307672
Trained batch 712 in epoch 2, gen_loss = 1.476989540946768, disc_loss = 0.0007266349314374335
Trained batch 713 in epoch 2, gen_loss = 1.4769358765177365, disc_loss = 0.0007261107186998791
Trained batch 714 in epoch 2, gen_loss = 1.4769411322120187, disc_loss = 0.0007256475913458849
Trained batch 715 in epoch 2, gen_loss = 1.4770007111839742, disc_loss = 0.0007253701981289088
Trained batch 716 in epoch 2, gen_loss = 1.4771049918822496, disc_loss = 0.0007250460927492213
Trained batch 717 in epoch 2, gen_loss = 1.477037177278471, disc_loss = 0.0007245159561795761
Trained batch 718 in epoch 2, gen_loss = 1.4769876028135192, disc_loss = 0.0007240166930952634
Trained batch 719 in epoch 2, gen_loss = 1.4769972751537959, disc_loss = 0.0007235959122934017
Trained batch 720 in epoch 2, gen_loss = 1.4770133306844555, disc_loss = 0.0007231086980158802
Trained batch 721 in epoch 2, gen_loss = 1.4769850465729626, disc_loss = 0.0007226651256218413
Trained batch 722 in epoch 2, gen_loss = 1.4769688267595706, disc_loss = 0.0007221786256439669
Trained batch 723 in epoch 2, gen_loss = 1.4769607704976646, disc_loss = 0.00072161270123334
Trained batch 724 in epoch 2, gen_loss = 1.47688967556789, disc_loss = 0.0007210757510319096
Trained batch 725 in epoch 2, gen_loss = 1.4769138992653734, disc_loss = 0.0007205967828339561
Trained batch 726 in epoch 2, gen_loss = 1.47687061567582, disc_loss = 0.0007200253818490308
Trained batch 727 in epoch 2, gen_loss = 1.4767952808639506, disc_loss = 0.0007194021313258058
Trained batch 728 in epoch 2, gen_loss = 1.476820355253128, disc_loss = 0.0007188123790499344
Trained batch 729 in epoch 2, gen_loss = 1.4769067545459695, disc_loss = 0.0007182096956418955
Trained batch 730 in epoch 2, gen_loss = 1.476783556096694, disc_loss = 0.0007175001531841601
Trained batch 731 in epoch 2, gen_loss = 1.4767896633982007, disc_loss = 0.0007169964726111925
Trained batch 732 in epoch 2, gen_loss = 1.4767859349634604, disc_loss = 0.000716742271131653
Trained batch 733 in epoch 2, gen_loss = 1.476746176016753, disc_loss = 0.0007167922202470758
Trained batch 734 in epoch 2, gen_loss = 1.476818720661864, disc_loss = 0.0007168831757299893
Trained batch 735 in epoch 2, gen_loss = 1.4768277461762014, disc_loss = 0.0007167658326303037
Trained batch 736 in epoch 2, gen_loss = 1.4767431256890782, disc_loss = 0.000716647526053895
Trained batch 737 in epoch 2, gen_loss = 1.4767802176759819, disc_loss = 0.0007167146122958549
Trained batch 738 in epoch 2, gen_loss = 1.4767994124124757, disc_loss = 0.000716935650234272
Trained batch 739 in epoch 2, gen_loss = 1.4767944078187685, disc_loss = 0.0007171438561518035
Trained batch 740 in epoch 2, gen_loss = 1.476941590045306, disc_loss = 0.0007171598232252896
Trained batch 741 in epoch 2, gen_loss = 1.4769592269090308, disc_loss = 0.0007170038982418446
Trained batch 742 in epoch 2, gen_loss = 1.476990956477169, disc_loss = 0.0007167454586421675
Trained batch 743 in epoch 2, gen_loss = 1.4769418758730735, disc_loss = 0.0007164173249068598
Trained batch 744 in epoch 2, gen_loss = 1.4769298473460561, disc_loss = 0.0007160215921607807
Trained batch 745 in epoch 2, gen_loss = 1.4769868230691863, disc_loss = 0.0007156175008237464
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 1.541590929031372, disc_loss = 0.0004972919123247266
Trained batch 1 in epoch 3, gen_loss = 1.5283635258674622, disc_loss = 0.000493476225528866
Trained batch 2 in epoch 3, gen_loss = 1.5172354777654011, disc_loss = 0.0004565172518293063
Trained batch 3 in epoch 3, gen_loss = 1.5063204169273376, disc_loss = 0.0004148013103986159
Trained batch 4 in epoch 3, gen_loss = 1.4956409215927124, disc_loss = 0.0003741320892004296
Trained batch 5 in epoch 3, gen_loss = 1.4936587015787761, disc_loss = 0.00033836580405477434
Trained batch 6 in epoch 3, gen_loss = 1.4965766157422746, disc_loss = 0.000317116134933063
Trained batch 7 in epoch 3, gen_loss = 1.494412362575531, disc_loss = 0.00031373217643704265
Trained batch 8 in epoch 3, gen_loss = 1.4961045980453491, disc_loss = 0.00031690609951814014
Trained batch 9 in epoch 3, gen_loss = 1.4953730821609497, disc_loss = 0.00032867867848835887
Trained batch 10 in epoch 3, gen_loss = 1.4897916533730247, disc_loss = 0.00033801952535709876
Trained batch 11 in epoch 3, gen_loss = 1.4909018973509471, disc_loss = 0.0003405304475260588
Trained batch 12 in epoch 3, gen_loss = 1.494391523874723, disc_loss = 0.0003443238965701312
Trained batch 13 in epoch 3, gen_loss = 1.494986891746521, disc_loss = 0.0003508970091518547
Trained batch 14 in epoch 3, gen_loss = 1.4936915397644044, disc_loss = 0.0003535743725175659
Trained batch 15 in epoch 3, gen_loss = 1.4924532920122147, disc_loss = 0.00035060702430200763
Trained batch 16 in epoch 3, gen_loss = 1.4906243927338545, disc_loss = 0.00034076744016013383
Trained batch 17 in epoch 3, gen_loss = 1.4886376195483737, disc_loss = 0.00033182465348444466
Trained batch 18 in epoch 3, gen_loss = 1.4890710931075246, disc_loss = 0.00032537380359013026
Trained batch 19 in epoch 3, gen_loss = 1.4878684639930726, disc_loss = 0.0003194201912265271
Trained batch 20 in epoch 3, gen_loss = 1.4890067463829404, disc_loss = 0.0003168776664616806
Trained batch 21 in epoch 3, gen_loss = 1.4913081526756287, disc_loss = 0.0003176121099386364
Trained batch 22 in epoch 3, gen_loss = 1.4910761221595432, disc_loss = 0.0003180637267296729
Trained batch 23 in epoch 3, gen_loss = 1.4883506447076797, disc_loss = 0.0003152974932163488
Trained batch 24 in epoch 3, gen_loss = 1.4875110054016114, disc_loss = 0.00031070107186678794
Trained batch 25 in epoch 3, gen_loss = 1.4877516398063073, disc_loss = 0.0003067548241233453
Trained batch 26 in epoch 3, gen_loss = 1.4838539759318035, disc_loss = 0.00030336888287112943
Trained batch 27 in epoch 3, gen_loss = 1.4814271245683943, disc_loss = 0.000300170875042178
Trained batch 28 in epoch 3, gen_loss = 1.4799825816318906, disc_loss = 0.00029601845920391
Trained batch 29 in epoch 3, gen_loss = 1.4809676806132, disc_loss = 0.0002912167760465915
Trained batch 30 in epoch 3, gen_loss = 1.4802534426412275, disc_loss = 0.00028797459690981815
Trained batch 31 in epoch 3, gen_loss = 1.4794150777161121, disc_loss = 0.00028562866646097973
Trained batch 32 in epoch 3, gen_loss = 1.480431105151321, disc_loss = 0.0002836529509460723
Trained batch 33 in epoch 3, gen_loss = 1.4820087061208838, disc_loss = 0.00028190293232910335
Trained batch 34 in epoch 3, gen_loss = 1.4825806719916208, disc_loss = 0.0002800932848393651
Trained batch 35 in epoch 3, gen_loss = 1.4805949363443587, disc_loss = 0.00027751915776106116
Trained batch 36 in epoch 3, gen_loss = 1.4800795091165078, disc_loss = 0.0002750345616683213
Trained batch 37 in epoch 3, gen_loss = 1.4796623117045353, disc_loss = 0.0002731664322996757
Trained batch 38 in epoch 3, gen_loss = 1.479237620647137, disc_loss = 0.00027326443971385463
Trained batch 39 in epoch 3, gen_loss = 1.4775315076112747, disc_loss = 0.00027669477967720015
Trained batch 40 in epoch 3, gen_loss = 1.4789572227291945, disc_loss = 0.0002867581486764432
Trained batch 41 in epoch 3, gen_loss = 1.4792924835568382, disc_loss = 0.00030248339802104357
Trained batch 42 in epoch 3, gen_loss = 1.4793336225110432, disc_loss = 0.00031898658401820115
Trained batch 43 in epoch 3, gen_loss = 1.4773998395963148, disc_loss = 0.0003329516551854216
Trained batch 44 in epoch 3, gen_loss = 1.4780936903423734, disc_loss = 0.0003447793744271621
Trained batch 45 in epoch 3, gen_loss = 1.4771687051524287, disc_loss = 0.00035570155792495075
Trained batch 46 in epoch 3, gen_loss = 1.4769951561664014, disc_loss = 0.0003664647696534806
Trained batch 47 in epoch 3, gen_loss = 1.4770809536178906, disc_loss = 0.00037684669799394516
Trained batch 48 in epoch 3, gen_loss = 1.4768589686374276, disc_loss = 0.00038563496313219394
Trained batch 49 in epoch 3, gen_loss = 1.4755752635002137, disc_loss = 0.0003918833643547259
Trained batch 50 in epoch 3, gen_loss = 1.4747147770488964, disc_loss = 0.0003966034613161658
Trained batch 51 in epoch 3, gen_loss = 1.47543298968902, disc_loss = 0.0004011125551747122
Trained batch 52 in epoch 3, gen_loss = 1.4742750829120852, disc_loss = 0.0004057739594982023
Trained batch 53 in epoch 3, gen_loss = 1.4741399177798518, disc_loss = 0.000412883158046666
Trained batch 54 in epoch 3, gen_loss = 1.4744515397331932, disc_loss = 0.0004226175165968016
Trained batch 55 in epoch 3, gen_loss = 1.474223479628563, disc_loss = 0.0004337659491803996
Trained batch 56 in epoch 3, gen_loss = 1.4739608534595423, disc_loss = 0.0004469369803126411
Trained batch 57 in epoch 3, gen_loss = 1.4741512680875843, disc_loss = 0.0004588392157215978
Trained batch 58 in epoch 3, gen_loss = 1.473867790173676, disc_loss = 0.0004667665814819067
Trained batch 59 in epoch 3, gen_loss = 1.4740308026472728, disc_loss = 0.0004690897774707992
Trained batch 60 in epoch 3, gen_loss = 1.4734499200445708, disc_loss = 0.000467710900950612
Trained batch 61 in epoch 3, gen_loss = 1.4728203031324572, disc_loss = 0.000466955610928351
Trained batch 62 in epoch 3, gen_loss = 1.4735571051400804, disc_loss = 0.00046626461502571133
Trained batch 63 in epoch 3, gen_loss = 1.473823320120573, disc_loss = 0.00046371080702556355
Trained batch 64 in epoch 3, gen_loss = 1.4728700711176945, disc_loss = 0.00046125418403579927
Trained batch 65 in epoch 3, gen_loss = 1.4743271054643574, disc_loss = 0.0004640424381112539
Trained batch 66 in epoch 3, gen_loss = 1.4732829492483566, disc_loss = 0.0004725575548294348
Trained batch 67 in epoch 3, gen_loss = 1.4740923643112183, disc_loss = 0.0004853120799987878
Trained batch 68 in epoch 3, gen_loss = 1.4731668786726135, disc_loss = 0.0005039788685162025
Trained batch 69 in epoch 3, gen_loss = 1.4730761323656354, disc_loss = 0.0005273564995150082
Trained batch 70 in epoch 3, gen_loss = 1.4722912865625302, disc_loss = 0.0005511688045963881
Trained batch 71 in epoch 3, gen_loss = 1.472908569706811, disc_loss = 0.0005715136174128727
Trained batch 72 in epoch 3, gen_loss = 1.4723963116946286, disc_loss = 0.0005864436662044657
Trained batch 73 in epoch 3, gen_loss = 1.4723092237034359, disc_loss = 0.0005950855157681037
Trained batch 74 in epoch 3, gen_loss = 1.4727285893758137, disc_loss = 0.0005970630594917262
Trained batch 75 in epoch 3, gen_loss = 1.4736290385848598, disc_loss = 0.0005953564692677709
Trained batch 76 in epoch 3, gen_loss = 1.4741407555419128, disc_loss = 0.0005919713110817209
Trained batch 77 in epoch 3, gen_loss = 1.4752227893242469, disc_loss = 0.0005884497246976631
Trained batch 78 in epoch 3, gen_loss = 1.4742367237429075, disc_loss = 0.0005853668179825727
Trained batch 79 in epoch 3, gen_loss = 1.4745071321725844, disc_loss = 0.0005834535129906726
Trained batch 80 in epoch 3, gen_loss = 1.4733477404088149, disc_loss = 0.0005828093065101262
Trained batch 81 in epoch 3, gen_loss = 1.473795754153554, disc_loss = 0.0005814628269191173
Trained batch 82 in epoch 3, gen_loss = 1.4728004932403564, disc_loss = 0.0005796436763562105
Trained batch 83 in epoch 3, gen_loss = 1.4718473837489174, disc_loss = 0.0005776451242646934
Trained batch 84 in epoch 3, gen_loss = 1.4719941153245815, disc_loss = 0.0005749844800448045
Trained batch 85 in epoch 3, gen_loss = 1.4718304927958998, disc_loss = 0.0005704959773940446
Trained batch 86 in epoch 3, gen_loss = 1.4718065398862992, disc_loss = 0.0005656706802172308
Trained batch 87 in epoch 3, gen_loss = 1.4722905375740745, disc_loss = 0.000562658384958261
Trained batch 88 in epoch 3, gen_loss = 1.4716841102985854, disc_loss = 0.0005603751224554615
Trained batch 89 in epoch 3, gen_loss = 1.4716260751088461, disc_loss = 0.0005579350571173967
Trained batch 90 in epoch 3, gen_loss = 1.4712486476688595, disc_loss = 0.0005542195036209055
Trained batch 91 in epoch 3, gen_loss = 1.4708668084248253, disc_loss = 0.000549639774481361
Trained batch 92 in epoch 3, gen_loss = 1.4706120914028538, disc_loss = 0.0005455435715585707
Trained batch 93 in epoch 3, gen_loss = 1.4706282907343926, disc_loss = 0.0005425437225989919
Trained batch 94 in epoch 3, gen_loss = 1.471222976634377, disc_loss = 0.0005413040831243913
Trained batch 95 in epoch 3, gen_loss = 1.4709279748300712, disc_loss = 0.0005390493670347496
Trained batch 96 in epoch 3, gen_loss = 1.471643782153572, disc_loss = 0.0005368186636784681
Trained batch 97 in epoch 3, gen_loss = 1.471889645469432, disc_loss = 0.0005347983105635575
Trained batch 98 in epoch 3, gen_loss = 1.4717546412439058, disc_loss = 0.0005333043162762704
Trained batch 99 in epoch 3, gen_loss = 1.4717186450958253, disc_loss = 0.0005329676371184178
Trained batch 100 in epoch 3, gen_loss = 1.4714863996694583, disc_loss = 0.0005336546164471656
Trained batch 101 in epoch 3, gen_loss = 1.4716832088489158, disc_loss = 0.000535948367221007
Trained batch 102 in epoch 3, gen_loss = 1.4721446164603371, disc_loss = 0.0005379941755819849
Trained batch 103 in epoch 3, gen_loss = 1.4717014615352337, disc_loss = 0.0005378026625504179
Trained batch 104 in epoch 3, gen_loss = 1.4716209298088436, disc_loss = 0.0005357764032115007
Trained batch 105 in epoch 3, gen_loss = 1.4721206055497222, disc_loss = 0.0005331255233613774
Trained batch 106 in epoch 3, gen_loss = 1.4726267919362148, disc_loss = 0.0005305572649546698
Trained batch 107 in epoch 3, gen_loss = 1.4720808377972356, disc_loss = 0.0005276179780830043
Trained batch 108 in epoch 3, gen_loss = 1.472222686907567, disc_loss = 0.0005247508193827619
Trained batch 109 in epoch 3, gen_loss = 1.4734676209363071, disc_loss = 0.0005223226159366525
Trained batch 110 in epoch 3, gen_loss = 1.473133944176339, disc_loss = 0.0005221754060282061
Trained batch 111 in epoch 3, gen_loss = 1.4732165464333125, disc_loss = 0.00052607620325164
Trained batch 112 in epoch 3, gen_loss = 1.4737106698804197, disc_loss = 0.0005301677030037298
Trained batch 113 in epoch 3, gen_loss = 1.4731228853526868, disc_loss = 0.0005311092212203923
Trained batch 114 in epoch 3, gen_loss = 1.4737011588138083, disc_loss = 0.0005314089183229953
Trained batch 115 in epoch 3, gen_loss = 1.473410881798843, disc_loss = 0.000535279432871652
Trained batch 116 in epoch 3, gen_loss = 1.4734011694916294, disc_loss = 0.0005426387674211023
Trained batch 117 in epoch 3, gen_loss = 1.472721041259119, disc_loss = 0.0005534026114234575
Trained batch 118 in epoch 3, gen_loss = 1.4725170215638745, disc_loss = 0.0005673012642890309
Trained batch 119 in epoch 3, gen_loss = 1.4724703162908555, disc_loss = 0.0005804169280357504
Trained batch 120 in epoch 3, gen_loss = 1.4722704660793966, disc_loss = 0.0005940220273996527
Trained batch 121 in epoch 3, gen_loss = 1.4722261624258073, disc_loss = 0.0006020465084698936
Trained batch 122 in epoch 3, gen_loss = 1.4717955376074565, disc_loss = 0.0006032710390002656
Trained batch 123 in epoch 3, gen_loss = 1.4711390214581643, disc_loss = 0.0006013927294031507
Trained batch 124 in epoch 3, gen_loss = 1.471279818534851, disc_loss = 0.0005985415414907038
Trained batch 125 in epoch 3, gen_loss = 1.4713399079110887, disc_loss = 0.0005963373112045081
Trained batch 126 in epoch 3, gen_loss = 1.4713516563881102, disc_loss = 0.000596420002751067
Trained batch 127 in epoch 3, gen_loss = 1.471157455816865, disc_loss = 0.0005988672839976061
Trained batch 128 in epoch 3, gen_loss = 1.4707316566807356, disc_loss = 0.0006041983469631234
Trained batch 129 in epoch 3, gen_loss = 1.4706731401956998, disc_loss = 0.0006107969534171458
Trained batch 130 in epoch 3, gen_loss = 1.4703514312059824, disc_loss = 0.0006168773009011679
Trained batch 131 in epoch 3, gen_loss = 1.4703391257560614, disc_loss = 0.0006217478351600496
Trained batch 132 in epoch 3, gen_loss = 1.4704471324619495, disc_loss = 0.0006260206895316706
Trained batch 133 in epoch 3, gen_loss = 1.4703186296704989, disc_loss = 0.0006297391315022094
Trained batch 134 in epoch 3, gen_loss = 1.47037544603701, disc_loss = 0.0006312442022910411
Trained batch 135 in epoch 3, gen_loss = 1.4701597751939999, disc_loss = 0.0006309227308734347
Trained batch 136 in epoch 3, gen_loss = 1.470305940530596, disc_loss = 0.0006295995825874436
Trained batch 137 in epoch 3, gen_loss = 1.4704686731532, disc_loss = 0.000629020324634874
Trained batch 138 in epoch 3, gen_loss = 1.470778866637525, disc_loss = 0.0006292819258214222
Trained batch 139 in epoch 3, gen_loss = 1.4711149164608546, disc_loss = 0.0006296797613945923
Trained batch 140 in epoch 3, gen_loss = 1.4707873890585934, disc_loss = 0.0006304446596269172
Trained batch 141 in epoch 3, gen_loss = 1.4705974459648132, disc_loss = 0.0006311561602403895
Trained batch 142 in epoch 3, gen_loss = 1.4711398403127711, disc_loss = 0.0006308511340782255
Trained batch 143 in epoch 3, gen_loss = 1.471089246372382, disc_loss = 0.0006291964940222291
Trained batch 144 in epoch 3, gen_loss = 1.4706260212536515, disc_loss = 0.0006276660219461111
Trained batch 145 in epoch 3, gen_loss = 1.47108393499296, disc_loss = 0.0006257664433788917
Trained batch 146 in epoch 3, gen_loss = 1.4708045453441387, disc_loss = 0.0006245453719233423
Trained batch 147 in epoch 3, gen_loss = 1.470629092003848, disc_loss = 0.0006243349351869845
Trained batch 148 in epoch 3, gen_loss = 1.4706899175707926, disc_loss = 0.0006245205353870488
Trained batch 149 in epoch 3, gen_loss = 1.4709917481740316, disc_loss = 0.0006247827123540144
Trained batch 150 in epoch 3, gen_loss = 1.4711541513733517, disc_loss = 0.0006246479133310549
Trained batch 151 in epoch 3, gen_loss = 1.4718851713757766, disc_loss = 0.0006254010904261744
Trained batch 152 in epoch 3, gen_loss = 1.471581334382101, disc_loss = 0.0006295051136559326
Trained batch 153 in epoch 3, gen_loss = 1.472165364723701, disc_loss = 0.0006371766582808712
Trained batch 154 in epoch 3, gen_loss = 1.4723916653663882, disc_loss = 0.0006452657635353746
Trained batch 155 in epoch 3, gen_loss = 1.4725261605702913, disc_loss = 0.0006510246036132463
Trained batch 156 in epoch 3, gen_loss = 1.4723207616502312, disc_loss = 0.0006543500808654887
Trained batch 157 in epoch 3, gen_loss = 1.472189962109433, disc_loss = 0.0006550882436052154
Trained batch 158 in epoch 3, gen_loss = 1.4720064094231564, disc_loss = 0.000653953691241595
Trained batch 159 in epoch 3, gen_loss = 1.472320031374693, disc_loss = 0.0006522706578834913
Trained batch 160 in epoch 3, gen_loss = 1.4728603000226228, disc_loss = 0.0006508023705136794
Trained batch 161 in epoch 3, gen_loss = 1.4730803149717826, disc_loss = 0.0006492805516672102
Trained batch 162 in epoch 3, gen_loss = 1.473234370442256, disc_loss = 0.0006477795289529407
Trained batch 163 in epoch 3, gen_loss = 1.4732855405749343, disc_loss = 0.0006460391111720195
Trained batch 164 in epoch 3, gen_loss = 1.4731874509291216, disc_loss = 0.0006446068446772794
Trained batch 165 in epoch 3, gen_loss = 1.4735283815717122, disc_loss = 0.0006436500754431788
Trained batch 166 in epoch 3, gen_loss = 1.4734576926259937, disc_loss = 0.0006429116948490996
Trained batch 167 in epoch 3, gen_loss = 1.4736620975392205, disc_loss = 0.0006423670291994876
Trained batch 168 in epoch 3, gen_loss = 1.4733545385168854, disc_loss = 0.0006418442050513079
Trained batch 169 in epoch 3, gen_loss = 1.4732281663838556, disc_loss = 0.0006405630645424347
Trained batch 170 in epoch 3, gen_loss = 1.47335161869986, disc_loss = 0.0006391525980662446
Trained batch 171 in epoch 3, gen_loss = 1.473609439855398, disc_loss = 0.0006382637193594345
Trained batch 172 in epoch 3, gen_loss = 1.473703908782474, disc_loss = 0.0006380420699015777
Trained batch 173 in epoch 3, gen_loss = 1.4738794298007571, disc_loss = 0.0006379468872308217
Trained batch 174 in epoch 3, gen_loss = 1.4735834523609705, disc_loss = 0.0006368313104446445
Trained batch 175 in epoch 3, gen_loss = 1.4734824875538999, disc_loss = 0.000634521541294155
Trained batch 176 in epoch 3, gen_loss = 1.473542995372061, disc_loss = 0.000631992628213839
Trained batch 177 in epoch 3, gen_loss = 1.4735784202479245, disc_loss = 0.0006294741966955238
Trained batch 178 in epoch 3, gen_loss = 1.4733161087142688, disc_loss = 0.0006269084031312524
Trained batch 179 in epoch 3, gen_loss = 1.4732738971710204, disc_loss = 0.0006243218586152782
Trained batch 180 in epoch 3, gen_loss = 1.4732226159691153, disc_loss = 0.0006218816829685801
Trained batch 181 in epoch 3, gen_loss = 1.4732446061385858, disc_loss = 0.000619484794887095
Trained batch 182 in epoch 3, gen_loss = 1.4731251164212253, disc_loss = 0.0006170717567870841
Trained batch 183 in epoch 3, gen_loss = 1.47276401973289, disc_loss = 0.0006148968997244399
Trained batch 184 in epoch 3, gen_loss = 1.4728414889928456, disc_loss = 0.0006128564744407462
Trained batch 185 in epoch 3, gen_loss = 1.4727684470915026, disc_loss = 0.0006104210081512749
Trained batch 186 in epoch 3, gen_loss = 1.4727767106683496, disc_loss = 0.0006078415637291759
Trained batch 187 in epoch 3, gen_loss = 1.4727461071724588, disc_loss = 0.0006052999690817817
Trained batch 188 in epoch 3, gen_loss = 1.4728733534535403, disc_loss = 0.0006027806625872722
Trained batch 189 in epoch 3, gen_loss = 1.4728949559362312, disc_loss = 0.0006002741998312749
Trained batch 190 in epoch 3, gen_loss = 1.4729056177339004, disc_loss = 0.0005979377028827326
Trained batch 191 in epoch 3, gen_loss = 1.472663492585222, disc_loss = 0.00059590624308233
Trained batch 192 in epoch 3, gen_loss = 1.472220133623311, disc_loss = 0.0005949657312968331
Trained batch 193 in epoch 3, gen_loss = 1.472186004378132, disc_loss = 0.0005943876939895323
Trained batch 194 in epoch 3, gen_loss = 1.4723226736753414, disc_loss = 0.0005940109397320507
Trained batch 195 in epoch 3, gen_loss = 1.4724466679047565, disc_loss = 0.0005933897584921452
Trained batch 196 in epoch 3, gen_loss = 1.472532094432618, disc_loss = 0.000592943007181999
Trained batch 197 in epoch 3, gen_loss = 1.4725380997465114, disc_loss = 0.0005920203927389318
Trained batch 198 in epoch 3, gen_loss = 1.472551680689481, disc_loss = 0.0005906106342255002
Trained batch 199 in epoch 3, gen_loss = 1.4724321395158768, disc_loss = 0.0005887862447707448
Trained batch 200 in epoch 3, gen_loss = 1.4730474225324184, disc_loss = 0.0005875627059357436
Trained batch 201 in epoch 3, gen_loss = 1.4732210317460617, disc_loss = 0.0005878374647028689
Trained batch 202 in epoch 3, gen_loss = 1.4734994032112836, disc_loss = 0.0005889269496082544
Trained batch 203 in epoch 3, gen_loss = 1.4735640754886703, disc_loss = 0.0005898138198045119
Trained batch 204 in epoch 3, gen_loss = 1.4735072612762452, disc_loss = 0.0005896546183687794
Trained batch 205 in epoch 3, gen_loss = 1.4735890812086827, disc_loss = 0.0005889309180823598
Trained batch 206 in epoch 3, gen_loss = 1.4742919690367104, disc_loss = 0.0005883049378160315
Trained batch 207 in epoch 3, gen_loss = 1.474107916538532, disc_loss = 0.0005874809895221216
Trained batch 208 in epoch 3, gen_loss = 1.4745286052877253, disc_loss = 0.0005868859572389551
Trained batch 209 in epoch 3, gen_loss = 1.4745777442341759, disc_loss = 0.0005861160242819183
Trained batch 210 in epoch 3, gen_loss = 1.475067901950312, disc_loss = 0.0005856005267198175
Trained batch 211 in epoch 3, gen_loss = 1.4748303339166462, disc_loss = 0.0005855252723295224
Trained batch 212 in epoch 3, gen_loss = 1.4749186464318647, disc_loss = 0.0005861706931981315
Trained batch 213 in epoch 3, gen_loss = 1.474978565612686, disc_loss = 0.0005873947761458928
Trained batch 214 in epoch 3, gen_loss = 1.4748741216437762, disc_loss = 0.0005882377521037449
Trained batch 215 in epoch 3, gen_loss = 1.4748804486460156, disc_loss = 0.000588294466137153
Trained batch 216 in epoch 3, gen_loss = 1.4750054915379818, disc_loss = 0.000587689453705905
Trained batch 217 in epoch 3, gen_loss = 1.4752107093093592, disc_loss = 0.0005871416980063183
Trained batch 218 in epoch 3, gen_loss = 1.4751161913893538, disc_loss = 0.000587079867499468
Trained batch 219 in epoch 3, gen_loss = 1.4749483877962286, disc_loss = 0.000587468659399416
Trained batch 220 in epoch 3, gen_loss = 1.475253637559813, disc_loss = 0.0005881332787600813
Trained batch 221 in epoch 3, gen_loss = 1.4754507842364613, disc_loss = 0.0005888374208216765
Trained batch 222 in epoch 3, gen_loss = 1.4754413467886203, disc_loss = 0.0005892121372431216
Trained batch 223 in epoch 3, gen_loss = 1.4755966471774238, disc_loss = 0.0005892696889142306
Trained batch 224 in epoch 3, gen_loss = 1.4754770930608114, disc_loss = 0.0005894317783208357
Trained batch 225 in epoch 3, gen_loss = 1.4754386259391246, disc_loss = 0.0005898428764050019
Trained batch 226 in epoch 3, gen_loss = 1.4752620815705624, disc_loss = 0.0005904892800552237
Trained batch 227 in epoch 3, gen_loss = 1.4755898259188, disc_loss = 0.0005912354839924854
Trained batch 228 in epoch 3, gen_loss = 1.4755323042515585, disc_loss = 0.0005915227585561639
Trained batch 229 in epoch 3, gen_loss = 1.4755748287491177, disc_loss = 0.000591204106129463
Trained batch 230 in epoch 3, gen_loss = 1.4752389481573394, disc_loss = 0.0005904333665966988
Trained batch 231 in epoch 3, gen_loss = 1.4753062647992168, disc_loss = 0.0005894646792198885
Trained batch 232 in epoch 3, gen_loss = 1.4751423796870677, disc_loss = 0.0005882867846024411
Trained batch 233 in epoch 3, gen_loss = 1.4751155534361162, disc_loss = 0.0005871267447250091
Trained batch 234 in epoch 3, gen_loss = 1.4751159373750078, disc_loss = 0.0005863903111411616
Trained batch 235 in epoch 3, gen_loss = 1.4748519704503529, disc_loss = 0.0005859164687581912
Trained batch 236 in epoch 3, gen_loss = 1.4746486698021868, disc_loss = 0.0005858424231400202
Trained batch 237 in epoch 3, gen_loss = 1.4747816023706388, disc_loss = 0.0005861413221221277
Trained batch 238 in epoch 3, gen_loss = 1.4748286318080694, disc_loss = 0.0005866794445830549
Trained batch 239 in epoch 3, gen_loss = 1.4750994910796484, disc_loss = 0.0005873850026546279
Trained batch 240 in epoch 3, gen_loss = 1.4750683040539754, disc_loss = 0.000587694196555091
Trained batch 241 in epoch 3, gen_loss = 1.4747922499317767, disc_loss = 0.0005877844200128967
Trained batch 242 in epoch 3, gen_loss = 1.4746165501237407, disc_loss = 0.0005876935347521854
Trained batch 243 in epoch 3, gen_loss = 1.474638361422742, disc_loss = 0.0005871553483779817
Trained batch 244 in epoch 3, gen_loss = 1.474642839723704, disc_loss = 0.0005866950817349157
Trained batch 245 in epoch 3, gen_loss = 1.474725592911728, disc_loss = 0.0005864503093506777
Trained batch 246 in epoch 3, gen_loss = 1.4748141336054936, disc_loss = 0.0005858753157896461
Trained batch 247 in epoch 3, gen_loss = 1.474761042864092, disc_loss = 0.0005848357501353378
Trained batch 248 in epoch 3, gen_loss = 1.4750980679768635, disc_loss = 0.000583656042922722
Trained batch 249 in epoch 3, gen_loss = 1.4749019904136658, disc_loss = 0.0005831391582032666
Trained batch 250 in epoch 3, gen_loss = 1.4743674784542555, disc_loss = 0.0005831169417875623
Trained batch 251 in epoch 3, gen_loss = 1.4743016059436496, disc_loss = 0.0005826054018273551
Trained batch 252 in epoch 3, gen_loss = 1.474204760766312, disc_loss = 0.0005821968984869291
Trained batch 253 in epoch 3, gen_loss = 1.4740567385681032, disc_loss = 0.0005820472006306536
Trained batch 254 in epoch 3, gen_loss = 1.4738810296152152, disc_loss = 0.000582722932278343
Trained batch 255 in epoch 3, gen_loss = 1.474001633003354, disc_loss = 0.0005842564941076489
Trained batch 256 in epoch 3, gen_loss = 1.4737358552472601, disc_loss = 0.000585114011601708
Trained batch 257 in epoch 3, gen_loss = 1.474076809347138, disc_loss = 0.0005851975729456171
Trained batch 258 in epoch 3, gen_loss = 1.4739113562815898, disc_loss = 0.0005841941757462056
Trained batch 259 in epoch 3, gen_loss = 1.474080295746143, disc_loss = 0.0005831182699274415
Trained batch 260 in epoch 3, gen_loss = 1.4741253122059321, disc_loss = 0.0005825705610178197
Trained batch 261 in epoch 3, gen_loss = 1.4739353069822296, disc_loss = 0.0005824940261575002
Trained batch 262 in epoch 3, gen_loss = 1.4735356424244637, disc_loss = 0.0005831045578649983
Trained batch 263 in epoch 3, gen_loss = 1.4736658108956886, disc_loss = 0.0005854850924427437
Trained batch 264 in epoch 3, gen_loss = 1.4734315120948935, disc_loss = 0.0005897824113248444
Trained batch 265 in epoch 3, gen_loss = 1.4735146595123119, disc_loss = 0.0005938928668199919
Trained batch 266 in epoch 3, gen_loss = 1.4733675512928195, disc_loss = 0.0005970148524236324
Trained batch 267 in epoch 3, gen_loss = 1.473349775840987, disc_loss = 0.0005991373385116805
Trained batch 268 in epoch 3, gen_loss = 1.473231168041442, disc_loss = 0.0006005458926936078
Trained batch 269 in epoch 3, gen_loss = 1.4733370908984431, disc_loss = 0.0006019611477515557
Trained batch 270 in epoch 3, gen_loss = 1.47339583806886, disc_loss = 0.0006038830818555135
Trained batch 271 in epoch 3, gen_loss = 1.4733305893400137, disc_loss = 0.0006070870060605504
Trained batch 272 in epoch 3, gen_loss = 1.473261134091751, disc_loss = 0.0006116579949639178
Trained batch 273 in epoch 3, gen_loss = 1.4735939920383647, disc_loss = 0.0006171408710350371
Trained batch 274 in epoch 3, gen_loss = 1.4733237561312589, disc_loss = 0.0006223287290512499
Trained batch 275 in epoch 3, gen_loss = 1.4735511040342026, disc_loss = 0.000627040103068609
Trained batch 276 in epoch 3, gen_loss = 1.4732473864882432, disc_loss = 0.0006311129912480188
Trained batch 277 in epoch 3, gen_loss = 1.4733026670895035, disc_loss = 0.0006352691533648671
Trained batch 278 in epoch 3, gen_loss = 1.4733018195757301, disc_loss = 0.000639468714478843
Trained batch 279 in epoch 3, gen_loss = 1.4731362904821124, disc_loss = 0.000644688285891399
Trained batch 280 in epoch 3, gen_loss = 1.4731178317629994, disc_loss = 0.0006512116179494949
Trained batch 281 in epoch 3, gen_loss = 1.4729370715770316, disc_loss = 0.0006576597993798778
Trained batch 282 in epoch 3, gen_loss = 1.4730708384261115, disc_loss = 0.0006631657921556094
Trained batch 283 in epoch 3, gen_loss = 1.4726487931231378, disc_loss = 0.0006669705769934193
Trained batch 284 in epoch 3, gen_loss = 1.4729351784053601, disc_loss = 0.0006686816671087096
Trained batch 285 in epoch 3, gen_loss = 1.4728909009820097, disc_loss = 0.0006698127446241898
Trained batch 286 in epoch 3, gen_loss = 1.4730750131274766, disc_loss = 0.0006707744221227367
Trained batch 287 in epoch 3, gen_loss = 1.473106881396638, disc_loss = 0.0006713049041435523
Trained batch 288 in epoch 3, gen_loss = 1.4730019400276528, disc_loss = 0.0006712328004739392
Trained batch 289 in epoch 3, gen_loss = 1.4727428296516683, disc_loss = 0.0006707711096106354
Trained batch 290 in epoch 3, gen_loss = 1.4727282884604334, disc_loss = 0.0006715674414355436
Trained batch 291 in epoch 3, gen_loss = 1.473254864346491, disc_loss = 0.0006726670533630754
Trained batch 292 in epoch 3, gen_loss = 1.4735489998254352, disc_loss = 0.0006715987758145194
Trained batch 293 in epoch 3, gen_loss = 1.473550660269601, disc_loss = 0.0006699608858151292
Trained batch 294 in epoch 3, gen_loss = 1.4736632108688354, disc_loss = 0.0006682551525616071
Trained batch 295 in epoch 3, gen_loss = 1.4736270304467227, disc_loss = 0.0006664948873918007
Trained batch 296 in epoch 3, gen_loss = 1.4736542175915908, disc_loss = 0.0006652083808908189
Trained batch 297 in epoch 3, gen_loss = 1.473565487253586, disc_loss = 0.0006649874343834473
Trained batch 298 in epoch 3, gen_loss = 1.4736193127456716, disc_loss = 0.0006662948272852103
Trained batch 299 in epoch 3, gen_loss = 1.4735747929414114, disc_loss = 0.0006686205989778197
Trained batch 300 in epoch 3, gen_loss = 1.4734114760972337, disc_loss = 0.0006720783965653613
Trained batch 301 in epoch 3, gen_loss = 1.4734115967687391, disc_loss = 0.0006760747705540767
Trained batch 302 in epoch 3, gen_loss = 1.473272425506768, disc_loss = 0.0006804432720041959
Trained batch 303 in epoch 3, gen_loss = 1.4733553030773212, disc_loss = 0.0006841481680997898
Trained batch 304 in epoch 3, gen_loss = 1.473070441699419, disc_loss = 0.00068717823906794
Trained batch 305 in epoch 3, gen_loss = 1.4733177291022406, disc_loss = 0.0006896870493150036
Trained batch 306 in epoch 3, gen_loss = 1.4730050940467014, disc_loss = 0.0006917617987657075
Trained batch 307 in epoch 3, gen_loss = 1.4729422276670283, disc_loss = 0.0006938830811122898
Trained batch 308 in epoch 3, gen_loss = 1.4729063460742, disc_loss = 0.000695092152831639
Trained batch 309 in epoch 3, gen_loss = 1.4727724217599438, disc_loss = 0.0006950535190445671
Trained batch 310 in epoch 3, gen_loss = 1.4725729142737924, disc_loss = 0.0006941826763758256
Trained batch 311 in epoch 3, gen_loss = 1.4723902279749894, disc_loss = 0.0006926463415882795
Trained batch 312 in epoch 3, gen_loss = 1.4725001029694043, disc_loss = 0.0006911126494957373
Trained batch 313 in epoch 3, gen_loss = 1.4724677394909464, disc_loss = 0.0006901235024464779
Trained batch 314 in epoch 3, gen_loss = 1.4722986792761181, disc_loss = 0.0006898482741754768
Trained batch 315 in epoch 3, gen_loss = 1.4723206464248368, disc_loss = 0.0006901075157887285
Trained batch 316 in epoch 3, gen_loss = 1.4721299466274513, disc_loss = 0.0006900555108529178
Trained batch 317 in epoch 3, gen_loss = 1.4722670301701288, disc_loss = 0.000689751716942377
Trained batch 318 in epoch 3, gen_loss = 1.472319660141924, disc_loss = 0.0006893580995385498
Trained batch 319 in epoch 3, gen_loss = 1.4723276507109404, disc_loss = 0.0006890968955758581
Trained batch 320 in epoch 3, gen_loss = 1.47231687080823, disc_loss = 0.0006890909227588275
Trained batch 321 in epoch 3, gen_loss = 1.4724205995198363, disc_loss = 0.0006890827386335597
Trained batch 322 in epoch 3, gen_loss = 1.4723769773270692, disc_loss = 0.000688628961024705
Trained batch 323 in epoch 3, gen_loss = 1.4724303406697732, disc_loss = 0.00068795626704045
Trained batch 324 in epoch 3, gen_loss = 1.4724064705922053, disc_loss = 0.0006869316480319517
Trained batch 325 in epoch 3, gen_loss = 1.4725081522040573, disc_loss = 0.0006858001285367588
Trained batch 326 in epoch 3, gen_loss = 1.4726115946375995, disc_loss = 0.0006849356158084694
Trained batch 327 in epoch 3, gen_loss = 1.4728538008724772, disc_loss = 0.0006841388208491347
Trained batch 328 in epoch 3, gen_loss = 1.4727995663790718, disc_loss = 0.0006836187508892081
Trained batch 329 in epoch 3, gen_loss = 1.4727682698856701, disc_loss = 0.0006830111998362664
Trained batch 330 in epoch 3, gen_loss = 1.4729225260973697, disc_loss = 0.0006824905446078487
Trained batch 331 in epoch 3, gen_loss = 1.4727999058114476, disc_loss = 0.0006821916092987346
Trained batch 332 in epoch 3, gen_loss = 1.4727944969772935, disc_loss = 0.0006823256434316889
Trained batch 333 in epoch 3, gen_loss = 1.4727730990170005, disc_loss = 0.0006821591313039566
Trained batch 334 in epoch 3, gen_loss = 1.4727630743339881, disc_loss = 0.000681574786222651
Trained batch 335 in epoch 3, gen_loss = 1.4728338250092097, disc_loss = 0.0006807124026246518
Trained batch 336 in epoch 3, gen_loss = 1.4728814890547393, disc_loss = 0.0006795375931677091
Trained batch 337 in epoch 3, gen_loss = 1.4729077336350842, disc_loss = 0.0006782647847668433
Trained batch 338 in epoch 3, gen_loss = 1.4729087792314963, disc_loss = 0.0006770091491478707
Trained batch 339 in epoch 3, gen_loss = 1.472733195739634, disc_loss = 0.000675938149652211
Trained batch 340 in epoch 3, gen_loss = 1.4728036944118064, disc_loss = 0.00067479373975773
Trained batch 341 in epoch 3, gen_loss = 1.4725280174037867, disc_loss = 0.0006734987621962185
Trained batch 342 in epoch 3, gen_loss = 1.4726447151979274, disc_loss = 0.0006721626749379647
Trained batch 343 in epoch 3, gen_loss = 1.472609625652779, disc_loss = 0.0006709525535180271
Trained batch 344 in epoch 3, gen_loss = 1.4723772774571957, disc_loss = 0.000669937581794026
Trained batch 345 in epoch 3, gen_loss = 1.4723521116151974, disc_loss = 0.0006690045533620354
Trained batch 346 in epoch 3, gen_loss = 1.4722554013777192, disc_loss = 0.0006679782987540717
Trained batch 347 in epoch 3, gen_loss = 1.4723970091891014, disc_loss = 0.0006668620120052211
Trained batch 348 in epoch 3, gen_loss = 1.4723158528265092, disc_loss = 0.0006657803226759347
Trained batch 349 in epoch 3, gen_loss = 1.4723801834242685, disc_loss = 0.0006647508911139864
Trained batch 350 in epoch 3, gen_loss = 1.4725945515510364, disc_loss = 0.0006636940496307041
Trained batch 351 in epoch 3, gen_loss = 1.4724978496405212, disc_loss = 0.0006623924871498523
Trained batch 352 in epoch 3, gen_loss = 1.4724892756081167, disc_loss = 0.0006610639814222126
Trained batch 353 in epoch 3, gen_loss = 1.4727896670837186, disc_loss = 0.0006600347164466498
Trained batch 354 in epoch 3, gen_loss = 1.4728018206609808, disc_loss = 0.0006590467240271146
Trained batch 355 in epoch 3, gen_loss = 1.4728847423966012, disc_loss = 0.0006579798007376749
Trained batch 356 in epoch 3, gen_loss = 1.4728510409844022, disc_loss = 0.0006567528077592963
Trained batch 357 in epoch 3, gen_loss = 1.472776871486749, disc_loss = 0.0006555702352594563
Trained batch 358 in epoch 3, gen_loss = 1.4728920908027372, disc_loss = 0.0006544810648771485
Trained batch 359 in epoch 3, gen_loss = 1.472984861003028, disc_loss = 0.0006535276908834931
Trained batch 360 in epoch 3, gen_loss = 1.4729370522697216, disc_loss = 0.0006527771865800694
Trained batch 361 in epoch 3, gen_loss = 1.4728589034870843, disc_loss = 0.00065221362086386
Trained batch 362 in epoch 3, gen_loss = 1.472775805751811, disc_loss = 0.000651843796215423
Trained batch 363 in epoch 3, gen_loss = 1.4727655835859068, disc_loss = 0.0006516877033940906
Trained batch 364 in epoch 3, gen_loss = 1.4728824880025158, disc_loss = 0.000651337050957197
Trained batch 365 in epoch 3, gen_loss = 1.4730351163389905, disc_loss = 0.0006505629758489232
Trained batch 366 in epoch 3, gen_loss = 1.4730551359763913, disc_loss = 0.0006496213143850025
Trained batch 367 in epoch 3, gen_loss = 1.473275363445282, disc_loss = 0.0006488979282079052
Trained batch 368 in epoch 3, gen_loss = 1.4732233159910373, disc_loss = 0.0006486660982122478
Trained batch 369 in epoch 3, gen_loss = 1.4730945925454835, disc_loss = 0.0006489833122326967
Trained batch 370 in epoch 3, gen_loss = 1.4733266788672887, disc_loss = 0.000649288874775337
Trained batch 371 in epoch 3, gen_loss = 1.4734342300122785, disc_loss = 0.0006496382941227777
Trained batch 372 in epoch 3, gen_loss = 1.473386966511008, disc_loss = 0.0006501000080708334
Trained batch 373 in epoch 3, gen_loss = 1.4732928881670702, disc_loss = 0.0006504068229712277
Trained batch 374 in epoch 3, gen_loss = 1.473239181836446, disc_loss = 0.0006503098756851008
Trained batch 375 in epoch 3, gen_loss = 1.4730577091587351, disc_loss = 0.0006498651556730112
Trained batch 376 in epoch 3, gen_loss = 1.4732235493014916, disc_loss = 0.0006492440936165498
Trained batch 377 in epoch 3, gen_loss = 1.4731938397442852, disc_loss = 0.0006486149962896619
Trained batch 378 in epoch 3, gen_loss = 1.4731965835616583, disc_loss = 0.000647954965295334
Trained batch 379 in epoch 3, gen_loss = 1.4732109336476578, disc_loss = 0.0006471422108772554
Trained batch 380 in epoch 3, gen_loss = 1.473399729553483, disc_loss = 0.0006462965741004364
Trained batch 381 in epoch 3, gen_loss = 1.4732414393524849, disc_loss = 0.0006456654956923914
Trained batch 382 in epoch 3, gen_loss = 1.4732098040941801, disc_loss = 0.0006451932214900812
Trained batch 383 in epoch 3, gen_loss = 1.4733775596444805, disc_loss = 0.000644701841792994
Trained batch 384 in epoch 3, gen_loss = 1.473259693926031, disc_loss = 0.0006443157908506691
Trained batch 385 in epoch 3, gen_loss = 1.4730471134803456, disc_loss = 0.0006441912345993549
Trained batch 386 in epoch 3, gen_loss = 1.4732215752589302, disc_loss = 0.0006440542355535951
Trained batch 387 in epoch 3, gen_loss = 1.4730631417220401, disc_loss = 0.0006438532199701006
Trained batch 388 in epoch 3, gen_loss = 1.4731305659889868, disc_loss = 0.0006436223673255956
Trained batch 389 in epoch 3, gen_loss = 1.4731105599647913, disc_loss = 0.0006434789918458615
Trained batch 390 in epoch 3, gen_loss = 1.4732631947988135, disc_loss = 0.0006433724724363698
Trained batch 391 in epoch 3, gen_loss = 1.4733191631278213, disc_loss = 0.0006428345812458488
Trained batch 392 in epoch 3, gen_loss = 1.4734718787457803, disc_loss = 0.0006419778414930835
Trained batch 393 in epoch 3, gen_loss = 1.4735302985622194, disc_loss = 0.0006409466241073893
Trained batch 394 in epoch 3, gen_loss = 1.4736210877382303, disc_loss = 0.0006397934587778453
Trained batch 395 in epoch 3, gen_loss = 1.4738352364963956, disc_loss = 0.0006386390858905441
Trained batch 396 in epoch 3, gen_loss = 1.4738000183922217, disc_loss = 0.0006373221266097494
Trained batch 397 in epoch 3, gen_loss = 1.4737989749740716, disc_loss = 0.0006361083856908997
Trained batch 398 in epoch 3, gen_loss = 1.4735818700981618, disc_loss = 0.0006351646409809991
Trained batch 399 in epoch 3, gen_loss = 1.4735954183340072, disc_loss = 0.0006346293801470892
Trained batch 400 in epoch 3, gen_loss = 1.473534906296956, disc_loss = 0.0006344621385444197
Trained batch 401 in epoch 3, gen_loss = 1.4735005008640574, disc_loss = 0.000634521545175653
Trained batch 402 in epoch 3, gen_loss = 1.4733701287664787, disc_loss = 0.0006346082019188647
Trained batch 403 in epoch 3, gen_loss = 1.473289189952435, disc_loss = 0.0006345934615646821
Trained batch 404 in epoch 3, gen_loss = 1.4732959614859686, disc_loss = 0.0006340866565652606
Trained batch 405 in epoch 3, gen_loss = 1.4731658700064485, disc_loss = 0.0006332051107433987
Trained batch 406 in epoch 3, gen_loss = 1.4730891988084123, disc_loss = 0.0006322457431643945
Trained batch 407 in epoch 3, gen_loss = 1.4733289854199279, disc_loss = 0.0006313015395540324
Trained batch 408 in epoch 3, gen_loss = 1.473268645025407, disc_loss = 0.0006303491598435776
Trained batch 409 in epoch 3, gen_loss = 1.473450669137443, disc_loss = 0.000629535493960536
Trained batch 410 in epoch 3, gen_loss = 1.4734966894135857, disc_loss = 0.0006288428035442357
Trained batch 411 in epoch 3, gen_loss = 1.4735384531391478, disc_loss = 0.0006282573581522882
Trained batch 412 in epoch 3, gen_loss = 1.4733593495648363, disc_loss = 0.0006278438394811438
Trained batch 413 in epoch 3, gen_loss = 1.4736681810899632, disc_loss = 0.0006275783007675422
Trained batch 414 in epoch 3, gen_loss = 1.4734868500606124, disc_loss = 0.0006275410551426327
Trained batch 415 in epoch 3, gen_loss = 1.4733439162373543, disc_loss = 0.000627904146243124
Trained batch 416 in epoch 3, gen_loss = 1.4733425678966714, disc_loss = 0.0006279818484324033
Trained batch 417 in epoch 3, gen_loss = 1.4732916973994679, disc_loss = 0.0006277254105430836
Trained batch 418 in epoch 3, gen_loss = 1.4732934737262406, disc_loss = 0.0006274021829246167
Trained batch 419 in epoch 3, gen_loss = 1.473324940318153, disc_loss = 0.0006271396384580016
Trained batch 420 in epoch 3, gen_loss = 1.473360193030568, disc_loss = 0.0006269774880982502
Trained batch 421 in epoch 3, gen_loss = 1.4732554944770595, disc_loss = 0.0006268008640924274
Trained batch 422 in epoch 3, gen_loss = 1.4735092539032018, disc_loss = 0.0006266668571426751
Trained batch 423 in epoch 3, gen_loss = 1.4735467740387287, disc_loss = 0.0006269327880905827
Trained batch 424 in epoch 3, gen_loss = 1.4734662086823407, disc_loss = 0.0006272570889525335
Trained batch 425 in epoch 3, gen_loss = 1.4734976940871405, disc_loss = 0.0006271435136818262
Trained batch 426 in epoch 3, gen_loss = 1.473646732906547, disc_loss = 0.0006268261211397523
Trained batch 427 in epoch 3, gen_loss = 1.473506773743674, disc_loss = 0.0006263879449166593
Trained batch 428 in epoch 3, gen_loss = 1.473730851442386, disc_loss = 0.0006268199015325174
Trained batch 429 in epoch 3, gen_loss = 1.4737298374952272, disc_loss = 0.0006293386450378484
Trained batch 430 in epoch 3, gen_loss = 1.473676627030782, disc_loss = 0.000632312297299742
Trained batch 431 in epoch 3, gen_loss = 1.4736405561367671, disc_loss = 0.0006336201188080142
Trained batch 432 in epoch 3, gen_loss = 1.4736957227935967, disc_loss = 0.0006337209663694772
Trained batch 433 in epoch 3, gen_loss = 1.4737338000728237, disc_loss = 0.0006334244531513866
Trained batch 434 in epoch 3, gen_loss = 1.473819950531269, disc_loss = 0.0006330772143140991
Trained batch 435 in epoch 3, gen_loss = 1.473703170588257, disc_loss = 0.0006326008688871014
Trained batch 436 in epoch 3, gen_loss = 1.473781897219695, disc_loss = 0.0006322202483033314
Trained batch 437 in epoch 3, gen_loss = 1.4738126778167133, disc_loss = 0.0006320344463716895
Trained batch 438 in epoch 3, gen_loss = 1.473858871058071, disc_loss = 0.0006317565165770904
Trained batch 439 in epoch 3, gen_loss = 1.4737761440602215, disc_loss = 0.0006312207216979005
Trained batch 440 in epoch 3, gen_loss = 1.4736518697673773, disc_loss = 0.0006304205411912075
Trained batch 441 in epoch 3, gen_loss = 1.4735454045809233, disc_loss = 0.0006294984416430395
Trained batch 442 in epoch 3, gen_loss = 1.4734841464066344, disc_loss = 0.000628630130388301
Trained batch 443 in epoch 3, gen_loss = 1.4733831866367444, disc_loss = 0.0006276891426668872
Trained batch 444 in epoch 3, gen_loss = 1.4734018719598148, disc_loss = 0.0006268839777599015
Trained batch 445 in epoch 3, gen_loss = 1.4734018984931467, disc_loss = 0.0006260713127769547
Trained batch 446 in epoch 3, gen_loss = 1.4732070297202808, disc_loss = 0.0006254845885070295
Trained batch 447 in epoch 3, gen_loss = 1.4730815437755413, disc_loss = 0.0006253534102143021
Trained batch 448 in epoch 3, gen_loss = 1.4729801469497001, disc_loss = 0.0006253972928556209
Trained batch 449 in epoch 3, gen_loss = 1.4728100895881653, disc_loss = 0.0006251922994852066
Trained batch 450 in epoch 3, gen_loss = 1.4727798055386596, disc_loss = 0.0006247752315381299
Trained batch 451 in epoch 3, gen_loss = 1.472963563636341, disc_loss = 0.0006243120825491986
Trained batch 452 in epoch 3, gen_loss = 1.4729262814090216, disc_loss = 0.0006250249845501051
Trained batch 453 in epoch 3, gen_loss = 1.4728018885667105, disc_loss = 0.0006261052949572524
Trained batch 454 in epoch 3, gen_loss = 1.472600798554473, disc_loss = 0.0006268442112691496
Trained batch 455 in epoch 3, gen_loss = 1.472649331939848, disc_loss = 0.000628902204960213
Trained batch 456 in epoch 3, gen_loss = 1.4725600700148869, disc_loss = 0.0006331722301107992
Trained batch 457 in epoch 3, gen_loss = 1.4724393231899977, disc_loss = 0.0006391003575530839
Trained batch 458 in epoch 3, gen_loss = 1.4724268970406393, disc_loss = 0.0006444229375218976
Trained batch 459 in epoch 3, gen_loss = 1.4723670420439348, disc_loss = 0.0006482912255982544
Trained batch 460 in epoch 3, gen_loss = 1.472390319158095, disc_loss = 0.0006503978474070712
Trained batch 461 in epoch 3, gen_loss = 1.4724679016447686, disc_loss = 0.0006514773220937595
Trained batch 462 in epoch 3, gen_loss = 1.4725596418133564, disc_loss = 0.0006520113095990131
Trained batch 463 in epoch 3, gen_loss = 1.4725956454359252, disc_loss = 0.0006522583511907904
Trained batch 464 in epoch 3, gen_loss = 1.472526772560612, disc_loss = 0.0006522155357449646
Trained batch 465 in epoch 3, gen_loss = 1.4726576835812417, disc_loss = 0.0006522329438846486
Trained batch 466 in epoch 3, gen_loss = 1.4726855678272452, disc_loss = 0.0006523586384482419
Trained batch 467 in epoch 3, gen_loss = 1.4726983306244907, disc_loss = 0.0006523417661779433
Trained batch 468 in epoch 3, gen_loss = 1.4726134492898546, disc_loss = 0.0006521608181439761
Trained batch 469 in epoch 3, gen_loss = 1.4727450530579749, disc_loss = 0.0006518572062982167
Trained batch 470 in epoch 3, gen_loss = 1.472679826104717, disc_loss = 0.0006513650157842825
Trained batch 471 in epoch 3, gen_loss = 1.4727066914408893, disc_loss = 0.0006507834238572425
Trained batch 472 in epoch 3, gen_loss = 1.4725174145265059, disc_loss = 0.0006503329802935561
Trained batch 473 in epoch 3, gen_loss = 1.472437890018592, disc_loss = 0.0006500512221164977
Trained batch 474 in epoch 3, gen_loss = 1.472301761978551, disc_loss = 0.0006498348598343957
Trained batch 475 in epoch 3, gen_loss = 1.4723971315792628, disc_loss = 0.0006497358324758497
Trained batch 476 in epoch 3, gen_loss = 1.4723704760929324, disc_loss = 0.0006497024778258134
Trained batch 477 in epoch 3, gen_loss = 1.4724039273281975, disc_loss = 0.0006497276515946393
Trained batch 478 in epoch 3, gen_loss = 1.4724051250545367, disc_loss = 0.0006496595231051088
Trained batch 479 in epoch 3, gen_loss = 1.472426132361094, disc_loss = 0.0006494070693709848
Trained batch 480 in epoch 3, gen_loss = 1.4725032008859076, disc_loss = 0.0006489957660521824
Trained batch 481 in epoch 3, gen_loss = 1.4724873163393424, disc_loss = 0.0006484118674512705
Trained batch 482 in epoch 3, gen_loss = 1.4726264395328783, disc_loss = 0.0006477666325099751
Trained batch 483 in epoch 3, gen_loss = 1.472558468580246, disc_loss = 0.0006470183177667378
Trained batch 484 in epoch 3, gen_loss = 1.472515267195161, disc_loss = 0.0006460888649111364
Trained batch 485 in epoch 3, gen_loss = 1.472573547696871, disc_loss = 0.0006450156434156468
Trained batch 486 in epoch 3, gen_loss = 1.4726077922805378, disc_loss = 0.0006439665340086028
Trained batch 487 in epoch 3, gen_loss = 1.472738750889653, disc_loss = 0.0006430354576460544
Trained batch 488 in epoch 3, gen_loss = 1.4726152463924664, disc_loss = 0.0006420931413473089
Trained batch 489 in epoch 3, gen_loss = 1.472631656393713, disc_loss = 0.000641119363688037
Trained batch 490 in epoch 3, gen_loss = 1.4725662112964388, disc_loss = 0.0006402432919437703
Trained batch 491 in epoch 3, gen_loss = 1.472570116926984, disc_loss = 0.0006394157071332391
Trained batch 492 in epoch 3, gen_loss = 1.4725742306235354, disc_loss = 0.0006385799766856795
Trained batch 493 in epoch 3, gen_loss = 1.4725116479252032, disc_loss = 0.0006377402975705645
Trained batch 494 in epoch 3, gen_loss = 1.4724146828506932, disc_loss = 0.0006370629604336702
Trained batch 495 in epoch 3, gen_loss = 1.472304144693959, disc_loss = 0.0006364970051377426
Trained batch 496 in epoch 3, gen_loss = 1.4723584920587673, disc_loss = 0.0006359418985523824
Trained batch 497 in epoch 3, gen_loss = 1.4724294344584148, disc_loss = 0.0006354334721520327
Trained batch 498 in epoch 3, gen_loss = 1.4722981486387388, disc_loss = 0.0006349816126212335
Trained batch 499 in epoch 3, gen_loss = 1.4722196438312531, disc_loss = 0.0006345127330278046
Trained batch 500 in epoch 3, gen_loss = 1.472152690211694, disc_loss = 0.0006341616677244876
Trained batch 501 in epoch 3, gen_loss = 1.4722390984634004, disc_loss = 0.0006337590951359352
Trained batch 502 in epoch 3, gen_loss = 1.472150204195891, disc_loss = 0.0006331330788771716
Trained batch 503 in epoch 3, gen_loss = 1.4721812447385183, disc_loss = 0.000632368650431523
Trained batch 504 in epoch 3, gen_loss = 1.472225823024712, disc_loss = 0.0006314540741789975
Trained batch 505 in epoch 3, gen_loss = 1.4719598552455073, disc_loss = 0.0006308267288174105
Trained batch 506 in epoch 3, gen_loss = 1.4720150568546393, disc_loss = 0.0006308514207277329
Trained batch 507 in epoch 3, gen_loss = 1.4720316074025912, disc_loss = 0.0006315197341770161
Trained batch 508 in epoch 3, gen_loss = 1.4721490812207954, disc_loss = 0.000632369881374615
Trained batch 509 in epoch 3, gen_loss = 1.4721934678507786, disc_loss = 0.0006327997930188133
Trained batch 510 in epoch 3, gen_loss = 1.472336764204992, disc_loss = 0.0006327639890806439
Trained batch 511 in epoch 3, gen_loss = 1.4724296305794269, disc_loss = 0.0006325999289060746
Trained batch 512 in epoch 3, gen_loss = 1.4724301531998039, disc_loss = 0.0006322972546830832
Trained batch 513 in epoch 3, gen_loss = 1.472447666444667, disc_loss = 0.0006318297262071607
Trained batch 514 in epoch 3, gen_loss = 1.4724628580426706, disc_loss = 0.0006313482931254486
Trained batch 515 in epoch 3, gen_loss = 1.472509918979896, disc_loss = 0.0006307788794366607
Trained batch 516 in epoch 3, gen_loss = 1.472386001387694, disc_loss = 0.0006300829950701157
Trained batch 517 in epoch 3, gen_loss = 1.4723508643367575, disc_loss = 0.0006293519392756127
Trained batch 518 in epoch 3, gen_loss = 1.4723079078229635, disc_loss = 0.0006286004312421233
Trained batch 519 in epoch 3, gen_loss = 1.4721794043595975, disc_loss = 0.0006278081282988961
Trained batch 520 in epoch 3, gen_loss = 1.472021901676156, disc_loss = 0.000627168788812159
Trained batch 521 in epoch 3, gen_loss = 1.4721008098445176, disc_loss = 0.0006266439825479723
Trained batch 522 in epoch 3, gen_loss = 1.4719913878814668, disc_loss = 0.0006260926508085169
Trained batch 523 in epoch 3, gen_loss = 1.4720050933706852, disc_loss = 0.0006255150505420237
Trained batch 524 in epoch 3, gen_loss = 1.4718524101802282, disc_loss = 0.0006248475383645633
Trained batch 525 in epoch 3, gen_loss = 1.471864924684677, disc_loss = 0.0006241068386899027
Trained batch 526 in epoch 3, gen_loss = 1.4716968307911331, disc_loss = 0.0006233780191488037
Trained batch 527 in epoch 3, gen_loss = 1.471626046932105, disc_loss = 0.0006228007811814402
Trained batch 528 in epoch 3, gen_loss = 1.4717630776655921, disc_loss = 0.000622226327800963
Trained batch 529 in epoch 3, gen_loss = 1.471689968963839, disc_loss = 0.0006214376287765467
Trained batch 530 in epoch 3, gen_loss = 1.4715838971111062, disc_loss = 0.0006206955408785762
Trained batch 531 in epoch 3, gen_loss = 1.4716297477707827, disc_loss = 0.0006201110525690002
Trained batch 532 in epoch 3, gen_loss = 1.4716628651234267, disc_loss = 0.0006196734093959176
Trained batch 533 in epoch 3, gen_loss = 1.47160944510042, disc_loss = 0.0006190556948618659
Trained batch 534 in epoch 3, gen_loss = 1.471441357158055, disc_loss = 0.000618337820203557
Trained batch 535 in epoch 3, gen_loss = 1.4712629618484583, disc_loss = 0.0006175913351751715
Trained batch 536 in epoch 3, gen_loss = 1.471188519254077, disc_loss = 0.0006168046013139504
Trained batch 537 in epoch 3, gen_loss = 1.4711916072217948, disc_loss = 0.0006159954943395996
Trained batch 538 in epoch 3, gen_loss = 1.4712615136976366, disc_loss = 0.0006151679401484219
Trained batch 539 in epoch 3, gen_loss = 1.4711995478029605, disc_loss = 0.0006142480657150305
Trained batch 540 in epoch 3, gen_loss = 1.471198897925851, disc_loss = 0.0006134447807175204
Trained batch 541 in epoch 3, gen_loss = 1.47106368295381, disc_loss = 0.0006132885671335202
Trained batch 542 in epoch 3, gen_loss = 1.47120444375068, disc_loss = 0.0006145961863327725
Trained batch 543 in epoch 3, gen_loss = 1.4712878741762216, disc_loss = 0.0006169562302736321
Trained batch 544 in epoch 3, gen_loss = 1.4711473058123108, disc_loss = 0.0006188054885870111
Trained batch 545 in epoch 3, gen_loss = 1.471127158556229, disc_loss = 0.0006197320192272139
Trained batch 546 in epoch 3, gen_loss = 1.4711582887325252, disc_loss = 0.0006204124219815411
Trained batch 547 in epoch 3, gen_loss = 1.4710855677615118, disc_loss = 0.0006210135237593586
Trained batch 548 in epoch 3, gen_loss = 1.4711340320566313, disc_loss = 0.0006216490130434923
Trained batch 549 in epoch 3, gen_loss = 1.471037701476704, disc_loss = 0.0006219908776719504
Trained batch 550 in epoch 3, gen_loss = 1.4711067016674257, disc_loss = 0.0006220436750932516
Trained batch 551 in epoch 3, gen_loss = 1.4710172103798909, disc_loss = 0.000622218866447983
Trained batch 552 in epoch 3, gen_loss = 1.4710775790550825, disc_loss = 0.0006226068561136508
Trained batch 553 in epoch 3, gen_loss = 1.4711446861067403, disc_loss = 0.0006229120746721633
Trained batch 554 in epoch 3, gen_loss = 1.4714989677205816, disc_loss = 0.0006231660605014956
Trained batch 555 in epoch 3, gen_loss = 1.4714557316234644, disc_loss = 0.0006241535468316149
Trained batch 556 in epoch 3, gen_loss = 1.4714537512250179, disc_loss = 0.0006255244837282351
Trained batch 557 in epoch 3, gen_loss = 1.471448303764439, disc_loss = 0.0006265699775209592
Trained batch 558 in epoch 3, gen_loss = 1.4716257372994328, disc_loss = 0.0006280233948817435
Trained batch 559 in epoch 3, gen_loss = 1.4715684694903237, disc_loss = 0.0006299267916542054
Trained batch 560 in epoch 3, gen_loss = 1.4716904822092856, disc_loss = 0.0006322032221081025
Trained batch 561 in epoch 3, gen_loss = 1.4715995046167611, disc_loss = 0.0006342368926903692
Trained batch 562 in epoch 3, gen_loss = 1.4715945436941793, disc_loss = 0.0006358247920094334
Trained batch 563 in epoch 3, gen_loss = 1.471486913608321, disc_loss = 0.0006367898380024902
Trained batch 564 in epoch 3, gen_loss = 1.4714589142166408, disc_loss = 0.0006371777466177915
Trained batch 565 in epoch 3, gen_loss = 1.4714556395375686, disc_loss = 0.000637213166150805
Trained batch 566 in epoch 3, gen_loss = 1.4713824550100525, disc_loss = 0.0006372934812418107
Trained batch 567 in epoch 3, gen_loss = 1.471279966369481, disc_loss = 0.0006381375496473506
Trained batch 568 in epoch 3, gen_loss = 1.4714000176880606, disc_loss = 0.0006395162409974503
Trained batch 569 in epoch 3, gen_loss = 1.4714233467453404, disc_loss = 0.0006405105776170865
Trained batch 570 in epoch 3, gen_loss = 1.4714594563753092, disc_loss = 0.000641148441841507
Trained batch 571 in epoch 3, gen_loss = 1.471417657770477, disc_loss = 0.0006415927807713567
Trained batch 572 in epoch 3, gen_loss = 1.4714457911762684, disc_loss = 0.0006419996602403245
Trained batch 573 in epoch 3, gen_loss = 1.4714188370139756, disc_loss = 0.0006425160568886727
Trained batch 574 in epoch 3, gen_loss = 1.4714237752168076, disc_loss = 0.0006427859789919634
Trained batch 575 in epoch 3, gen_loss = 1.4715053925497665, disc_loss = 0.0006427403066911413
Trained batch 576 in epoch 3, gen_loss = 1.4715681871467075, disc_loss = 0.0006424553747547336
Trained batch 577 in epoch 3, gen_loss = 1.4715956123642442, disc_loss = 0.0006419440223373171
Trained batch 578 in epoch 3, gen_loss = 1.4714918993091748, disc_loss = 0.0006413375826224577
Trained batch 579 in epoch 3, gen_loss = 1.4715813622392457, disc_loss = 0.000640971804600197
Trained batch 580 in epoch 3, gen_loss = 1.4715938730207039, disc_loss = 0.0006408876349446012
Trained batch 581 in epoch 3, gen_loss = 1.4715980107022315, disc_loss = 0.0006406298474432889
Trained batch 582 in epoch 3, gen_loss = 1.471599677005722, disc_loss = 0.0006402048195987232
Trained batch 583 in epoch 3, gen_loss = 1.4717360347101134, disc_loss = 0.0006398164207034638
Trained batch 584 in epoch 3, gen_loss = 1.471789814875676, disc_loss = 0.0006395373736338045
Trained batch 585 in epoch 3, gen_loss = 1.4716479334814963, disc_loss = 0.0006392139661168154
Trained batch 586 in epoch 3, gen_loss = 1.4717417675145035, disc_loss = 0.000638696085287316
Trained batch 587 in epoch 3, gen_loss = 1.4718087037809853, disc_loss = 0.000638337572009503
Trained batch 588 in epoch 3, gen_loss = 1.4719485335924831, disc_loss = 0.0006381219571974351
Trained batch 589 in epoch 3, gen_loss = 1.4719682335853577, disc_loss = 0.0006379325379508002
Trained batch 590 in epoch 3, gen_loss = 1.4719563095299322, disc_loss = 0.000637594538862646
Trained batch 591 in epoch 3, gen_loss = 1.4717919051244452, disc_loss = 0.0006371494857154863
Trained batch 592 in epoch 3, gen_loss = 1.4717454427812393, disc_loss = 0.0006367396117286391
Trained batch 593 in epoch 3, gen_loss = 1.4718595917778785, disc_loss = 0.000636455859060055
Trained batch 594 in epoch 3, gen_loss = 1.4718721836554904, disc_loss = 0.0006363884901589745
Trained batch 595 in epoch 3, gen_loss = 1.4719882397443655, disc_loss = 0.0006366665472750959
Trained batch 596 in epoch 3, gen_loss = 1.4721099441774326, disc_loss = 0.0006370220744033294
Trained batch 597 in epoch 3, gen_loss = 1.472077788517228, disc_loss = 0.0006370328535368848
Trained batch 598 in epoch 3, gen_loss = 1.4722098725068948, disc_loss = 0.0006370459625930665
Trained batch 599 in epoch 3, gen_loss = 1.4721601899464924, disc_loss = 0.0006374995316946297
Trained batch 600 in epoch 3, gen_loss = 1.472262125046995, disc_loss = 0.0006380968449038559
Trained batch 601 in epoch 3, gen_loss = 1.47217373673702, disc_loss = 0.0006386355048516785
Trained batch 602 in epoch 3, gen_loss = 1.472223476786321, disc_loss = 0.0006393057634193137
Trained batch 603 in epoch 3, gen_loss = 1.4723626643616632, disc_loss = 0.0006397730807932009
Trained batch 604 in epoch 3, gen_loss = 1.4723398527823204, disc_loss = 0.0006394471170901214
Trained batch 605 in epoch 3, gen_loss = 1.4723551656940195, disc_loss = 0.0006388916719437649
Trained batch 606 in epoch 3, gen_loss = 1.4723851384205324, disc_loss = 0.0006385251753327752
Trained batch 607 in epoch 3, gen_loss = 1.4722585046761913, disc_loss = 0.0006380449956874432
Trained batch 608 in epoch 3, gen_loss = 1.4722801041720537, disc_loss = 0.0006375799248342353
Trained batch 609 in epoch 3, gen_loss = 1.4721153509421427, disc_loss = 0.0006376102418933622
Trained batch 610 in epoch 3, gen_loss = 1.4721024926087274, disc_loss = 0.0006383508724986832
Trained batch 611 in epoch 3, gen_loss = 1.4721420605977376, disc_loss = 0.000638827497894846
Trained batch 612 in epoch 3, gen_loss = 1.4721828776899404, disc_loss = 0.0006387242052342696
Trained batch 613 in epoch 3, gen_loss = 1.4721352104643657, disc_loss = 0.0006385086757000665
Trained batch 614 in epoch 3, gen_loss = 1.4721027413034826, disc_loss = 0.0006381822221962607
Trained batch 615 in epoch 3, gen_loss = 1.472041343133171, disc_loss = 0.0006377062254023848
Trained batch 616 in epoch 3, gen_loss = 1.4719664032300828, disc_loss = 0.0006372647962822183
Trained batch 617 in epoch 3, gen_loss = 1.4720510487417573, disc_loss = 0.0006373884544232566
Trained batch 618 in epoch 3, gen_loss = 1.4719723927185109, disc_loss = 0.000638602967681051
Trained batch 619 in epoch 3, gen_loss = 1.4719315103946193, disc_loss = 0.0006405728670694272
Trained batch 620 in epoch 3, gen_loss = 1.4720286610813724, disc_loss = 0.0006421219024586194
Trained batch 621 in epoch 3, gen_loss = 1.4719765101981699, disc_loss = 0.0006426942233623033
Trained batch 622 in epoch 3, gen_loss = 1.4720597460411524, disc_loss = 0.0006425978809306032
Trained batch 623 in epoch 3, gen_loss = 1.47214263658493, disc_loss = 0.0006423702392077338
Trained batch 624 in epoch 3, gen_loss = 1.4722475082397461, disc_loss = 0.0006420554363750853
Trained batch 625 in epoch 3, gen_loss = 1.4722149113115792, disc_loss = 0.0006414696371344405
Trained batch 626 in epoch 3, gen_loss = 1.4721664549631366, disc_loss = 0.0006407440066055552
Trained batch 627 in epoch 3, gen_loss = 1.4721181696387613, disc_loss = 0.0006398965867510982
Trained batch 628 in epoch 3, gen_loss = 1.4722446440134216, disc_loss = 0.0006390605640074976
Trained batch 629 in epoch 3, gen_loss = 1.4722535825911023, disc_loss = 0.0006385559686884609
Trained batch 630 in epoch 3, gen_loss = 1.472256659705741, disc_loss = 0.0006385855075534988
Trained batch 631 in epoch 3, gen_loss = 1.4721822102990332, disc_loss = 0.0006388424095072153
Trained batch 632 in epoch 3, gen_loss = 1.4721298006850208, disc_loss = 0.0006387651348350449
Trained batch 633 in epoch 3, gen_loss = 1.4720202101517927, disc_loss = 0.0006385034113907188
Trained batch 634 in epoch 3, gen_loss = 1.4718294879582923, disc_loss = 0.0006383188621152016
Trained batch 635 in epoch 3, gen_loss = 1.4718481763353888, disc_loss = 0.0006380898981123033
Trained batch 636 in epoch 3, gen_loss = 1.4719097558145808, disc_loss = 0.0006377654177267573
Trained batch 637 in epoch 3, gen_loss = 1.4719071296688906, disc_loss = 0.0006374520117648349
Trained batch 638 in epoch 3, gen_loss = 1.4719470082687474, disc_loss = 0.0006372314865146334
Trained batch 639 in epoch 3, gen_loss = 1.472083326987922, disc_loss = 0.0006371390365984553
Trained batch 640 in epoch 3, gen_loss = 1.4721472611107431, disc_loss = 0.000637071524492818
Trained batch 641 in epoch 3, gen_loss = 1.4721897404141886, disc_loss = 0.0006369952804853594
Trained batch 642 in epoch 3, gen_loss = 1.4723222963917497, disc_loss = 0.0006369230327754778
Trained batch 643 in epoch 3, gen_loss = 1.472270957801653, disc_loss = 0.0006368502661146901
Trained batch 644 in epoch 3, gen_loss = 1.4724055585935134, disc_loss = 0.0006370455045126696
Trained batch 645 in epoch 3, gen_loss = 1.4723798985082668, disc_loss = 0.0006373947089910652
Trained batch 646 in epoch 3, gen_loss = 1.472432069100405, disc_loss = 0.0006377229094487317
Trained batch 647 in epoch 3, gen_loss = 1.4723232509913269, disc_loss = 0.0006379098066881179
Trained batch 648 in epoch 3, gen_loss = 1.4723072410180866, disc_loss = 0.0006379026318064393
Trained batch 649 in epoch 3, gen_loss = 1.4723077906095066, disc_loss = 0.0006378398506561867
Trained batch 650 in epoch 3, gen_loss = 1.4723596027186756, disc_loss = 0.00063786733207599
Trained batch 651 in epoch 3, gen_loss = 1.4722445393266854, disc_loss = 0.0006378508136594136
Trained batch 652 in epoch 3, gen_loss = 1.472334482403298, disc_loss = 0.0006380499962158929
Trained batch 653 in epoch 3, gen_loss = 1.4722617075348483, disc_loss = 0.0006385528766325837
Trained batch 654 in epoch 3, gen_loss = 1.4721904781938508, disc_loss = 0.0006393777096789786
Trained batch 655 in epoch 3, gen_loss = 1.4722206363590753, disc_loss = 0.000640193818404308
Trained batch 656 in epoch 3, gen_loss = 1.4723743993216272, disc_loss = 0.0006410293417959368
Trained batch 657 in epoch 3, gen_loss = 1.4722904102780536, disc_loss = 0.0006417967522843093
Trained batch 658 in epoch 3, gen_loss = 1.4722556255656056, disc_loss = 0.0006423456870723934
Trained batch 659 in epoch 3, gen_loss = 1.4723402899323088, disc_loss = 0.0006424554098471576
Trained batch 660 in epoch 3, gen_loss = 1.4723838753491054, disc_loss = 0.0006423022094060795
Trained batch 661 in epoch 3, gen_loss = 1.4723455958135898, disc_loss = 0.0006419678768733927
Trained batch 662 in epoch 3, gen_loss = 1.472346836625181, disc_loss = 0.000641532610858851
Trained batch 663 in epoch 3, gen_loss = 1.47231736348336, disc_loss = 0.000640902875514816
Trained batch 664 in epoch 3, gen_loss = 1.4724183702827396, disc_loss = 0.0006402125151887452
Trained batch 665 in epoch 3, gen_loss = 1.472415138293315, disc_loss = 0.0006395450286904921
Trained batch 666 in epoch 3, gen_loss = 1.4725155231655984, disc_loss = 0.0006389439743610149
Trained batch 667 in epoch 3, gen_loss = 1.472490887977406, disc_loss = 0.0006384819181237584
Trained batch 668 in epoch 3, gen_loss = 1.472587424899787, disc_loss = 0.0006383102961131323
Trained batch 669 in epoch 3, gen_loss = 1.4726024519151717, disc_loss = 0.0006383947124782908
Trained batch 670 in epoch 3, gen_loss = 1.4726350756942248, disc_loss = 0.0006384192319004276
Trained batch 671 in epoch 3, gen_loss = 1.4725787057763053, disc_loss = 0.0006383162085945688
Trained batch 672 in epoch 3, gen_loss = 1.4726844507021855, disc_loss = 0.0006380930318634467
Trained batch 673 in epoch 3, gen_loss = 1.4726779521042233, disc_loss = 0.0006377521758487666
Trained batch 674 in epoch 3, gen_loss = 1.4725795122429177, disc_loss = 0.0006372633420525947
Trained batch 675 in epoch 3, gen_loss = 1.4725614470490338, disc_loss = 0.0006366843544230893
Trained batch 676 in epoch 3, gen_loss = 1.4726618507235933, disc_loss = 0.0006360991238597492
Trained batch 677 in epoch 3, gen_loss = 1.472590177987529, disc_loss = 0.000635500672634088
Trained batch 678 in epoch 3, gen_loss = 1.472521867597577, disc_loss = 0.000634876328097164
Trained batch 679 in epoch 3, gen_loss = 1.4725202635807149, disc_loss = 0.0006342648959081784
Trained batch 680 in epoch 3, gen_loss = 1.4724935126899799, disc_loss = 0.0006339050999588898
Trained batch 681 in epoch 3, gen_loss = 1.4725673826209262, disc_loss = 0.0006340786124135113
Trained batch 682 in epoch 3, gen_loss = 1.4726255327506785, disc_loss = 0.0006348955572230297
Trained batch 683 in epoch 3, gen_loss = 1.4726168440099348, disc_loss = 0.0006357780394327489
Trained batch 684 in epoch 3, gen_loss = 1.4725946440313855, disc_loss = 0.0006364792546709442
Trained batch 685 in epoch 3, gen_loss = 1.4726699484680554, disc_loss = 0.0006371032796293068
Trained batch 686 in epoch 3, gen_loss = 1.4726291141829289, disc_loss = 0.0006378552003467409
Trained batch 687 in epoch 3, gen_loss = 1.472600685129332, disc_loss = 0.0006388542374753702
Trained batch 688 in epoch 3, gen_loss = 1.4726019796681509, disc_loss = 0.0006399680009190837
Trained batch 689 in epoch 3, gen_loss = 1.4725402039030324, disc_loss = 0.000640864381305131
Trained batch 690 in epoch 3, gen_loss = 1.4724990778134976, disc_loss = 0.0006412548547851221
Trained batch 691 in epoch 3, gen_loss = 1.472542758966457, disc_loss = 0.000641140907525416
Trained batch 692 in epoch 3, gen_loss = 1.4724414969591524, disc_loss = 0.0006406674735062631
Trained batch 693 in epoch 3, gen_loss = 1.4724524749459038, disc_loss = 0.0006401042516178234
Trained batch 694 in epoch 3, gen_loss = 1.472415035577129, disc_loss = 0.0006396855157297507
Trained batch 695 in epoch 3, gen_loss = 1.4724086896441448, disc_loss = 0.0006393490759950217
Trained batch 696 in epoch 3, gen_loss = 1.4723979715295297, disc_loss = 0.0006390119758063801
Trained batch 697 in epoch 3, gen_loss = 1.4724845206498416, disc_loss = 0.0006386181772009398
Trained batch 698 in epoch 3, gen_loss = 1.4725146706353271, disc_loss = 0.0006381635639822518
Trained batch 699 in epoch 3, gen_loss = 1.4725471356936863, disc_loss = 0.0006376897361561922
Trained batch 700 in epoch 3, gen_loss = 1.4724848539104816, disc_loss = 0.000637273783277396
Trained batch 701 in epoch 3, gen_loss = 1.4724376933527128, disc_loss = 0.0006368098037328672
Trained batch 702 in epoch 3, gen_loss = 1.472266541436251, disc_loss = 0.0006363537860289084
Trained batch 703 in epoch 3, gen_loss = 1.4723082614893264, disc_loss = 0.0006359367976074282
Trained batch 704 in epoch 3, gen_loss = 1.4722655965926799, disc_loss = 0.0006356851677063536
Trained batch 705 in epoch 3, gen_loss = 1.4723031134173148, disc_loss = 0.0006355110676012664
Trained batch 706 in epoch 3, gen_loss = 1.47228817791379, disc_loss = 0.0006353268327795448
Trained batch 707 in epoch 3, gen_loss = 1.4723870321518957, disc_loss = 0.0006350779104408923
Trained batch 708 in epoch 3, gen_loss = 1.4724092212819582, disc_loss = 0.0006348216733865687
Trained batch 709 in epoch 3, gen_loss = 1.4723711593050353, disc_loss = 0.000634574304411883
Trained batch 710 in epoch 3, gen_loss = 1.4723562220145545, disc_loss = 0.0006343752624117933
Trained batch 711 in epoch 3, gen_loss = 1.4722092662299617, disc_loss = 0.0006342932684173718
Trained batch 712 in epoch 3, gen_loss = 1.4721211776827028, disc_loss = 0.0006348263072865515
Trained batch 713 in epoch 3, gen_loss = 1.471975771819844, disc_loss = 0.0006360023925116766
Trained batch 714 in epoch 3, gen_loss = 1.472284292174386, disc_loss = 0.0006376503630935286
Trained batch 715 in epoch 3, gen_loss = 1.4720898477058837, disc_loss = 0.0006383292481622544
Trained batch 716 in epoch 3, gen_loss = 1.472090725785685, disc_loss = 0.0006389246798186035
Trained batch 717 in epoch 3, gen_loss = 1.4721277045672319, disc_loss = 0.0006396962442188225
Trained batch 718 in epoch 3, gen_loss = 1.4722196948047472, disc_loss = 0.0006404634884002285
Trained batch 719 in epoch 3, gen_loss = 1.472230815887451, disc_loss = 0.0006410013785272087
Trained batch 720 in epoch 3, gen_loss = 1.4722249865035906, disc_loss = 0.0006411438978592969
Trained batch 721 in epoch 3, gen_loss = 1.4722625730440557, disc_loss = 0.0006408150933203713
Trained batch 722 in epoch 3, gen_loss = 1.4722056372366836, disc_loss = 0.0006402980034332336
Trained batch 723 in epoch 3, gen_loss = 1.472202308270154, disc_loss = 0.0006399819601194686
Trained batch 724 in epoch 3, gen_loss = 1.4721789435682626, disc_loss = 0.0006399374150927982
Trained batch 725 in epoch 3, gen_loss = 1.4722018878978802, disc_loss = 0.0006404377889053604
Trained batch 726 in epoch 3, gen_loss = 1.4722592261667264, disc_loss = 0.0006411177897409496
Trained batch 727 in epoch 3, gen_loss = 1.4722459059167694, disc_loss = 0.0006412686786491546
Trained batch 728 in epoch 3, gen_loss = 1.4722091667609614, disc_loss = 0.000641357177128793
Trained batch 729 in epoch 3, gen_loss = 1.472185483044141, disc_loss = 0.0006415798147017621
Trained batch 730 in epoch 3, gen_loss = 1.4722623016211305, disc_loss = 0.0006415359540517594
Trained batch 731 in epoch 3, gen_loss = 1.4721722555616514, disc_loss = 0.0006413599136673535
Trained batch 732 in epoch 3, gen_loss = 1.4721786206611018, disc_loss = 0.0006419942755726042
Trained batch 733 in epoch 3, gen_loss = 1.4722476942662648, disc_loss = 0.0006430649906124067
Trained batch 734 in epoch 3, gen_loss = 1.4723209074565342, disc_loss = 0.000644243587533861
Trained batch 735 in epoch 3, gen_loss = 1.4723456458229085, disc_loss = 0.0006453508859008055
Trained batch 736 in epoch 3, gen_loss = 1.4724578212041868, disc_loss = 0.0006461372434571032
Trained batch 737 in epoch 3, gen_loss = 1.4724320943762617, disc_loss = 0.0006466927154331662
Trained batch 738 in epoch 3, gen_loss = 1.472549693510239, disc_loss = 0.0006476645766699457
Trained batch 739 in epoch 3, gen_loss = 1.4725433281950049, disc_loss = 0.0006492040147595863
Trained batch 740 in epoch 3, gen_loss = 1.4725630661414864, disc_loss = 0.000651082560572743
Trained batch 741 in epoch 3, gen_loss = 1.472515030851904, disc_loss = 0.0006522659625452655
Trained batch 742 in epoch 3, gen_loss = 1.4727059382930257, disc_loss = 0.0006542799955648827
Trained batch 743 in epoch 3, gen_loss = 1.4727778083855105, disc_loss = 0.0006557718713133175
Trained batch 744 in epoch 3, gen_loss = 1.472707526795816, disc_loss = 0.0006580900267272838
Trained batch 745 in epoch 3, gen_loss = 1.4726969216208676, disc_loss = 0.0006604662697029428
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 1.4206209182739258, disc_loss = 0.002171167405322194
Trained batch 1 in epoch 4, gen_loss = 1.4196362495422363, disc_loss = 0.0019355698022991419
Trained batch 2 in epoch 4, gen_loss = 1.4533780813217163, disc_loss = 0.0017584320933868487
Trained batch 3 in epoch 4, gen_loss = 1.4627799093723297, disc_loss = 0.0016265944868791848
Trained batch 4 in epoch 4, gen_loss = 1.4905353307723999, disc_loss = 0.0015005289809778334
Trained batch 5 in epoch 4, gen_loss = 1.4878424008687336, disc_loss = 0.0013777422039614369
Trained batch 6 in epoch 4, gen_loss = 1.4945027828216553, disc_loss = 0.0012639311774234688
Trained batch 7 in epoch 4, gen_loss = 1.5091822147369385, disc_loss = 0.0011603839811868966
Trained batch 8 in epoch 4, gen_loss = 1.5067422522438898, disc_loss = 0.0010759066046577776
Trained batch 9 in epoch 4, gen_loss = 1.5088064432144166, disc_loss = 0.0010105089546414091
Trained batch 10 in epoch 4, gen_loss = 1.50415668704293, disc_loss = 0.0009572575985327024
Trained batch 11 in epoch 4, gen_loss = 1.4994356135527294, disc_loss = 0.000904323535602695
Trained batch 12 in epoch 4, gen_loss = 1.4940903461896455, disc_loss = 0.0008517989100745091
Trained batch 13 in epoch 4, gen_loss = 1.4935457025255476, disc_loss = 0.0008072972913006586
Trained batch 14 in epoch 4, gen_loss = 1.4934571901957194, disc_loss = 0.0007710080360993743
Trained batch 15 in epoch 4, gen_loss = 1.4937517195940018, disc_loss = 0.0007412949889840093
Trained batch 16 in epoch 4, gen_loss = 1.4959902062135584, disc_loss = 0.0007197019226356026
Trained batch 17 in epoch 4, gen_loss = 1.4952061043845282, disc_loss = 0.0007029739095337896
Trained batch 18 in epoch 4, gen_loss = 1.488361960963199, disc_loss = 0.0006957007587372669
Trained batch 19 in epoch 4, gen_loss = 1.4871583580970764, disc_loss = 0.0007011127090663649
Trained batch 20 in epoch 4, gen_loss = 1.4897257316680181, disc_loss = 0.0007146116459764363
Trained batch 21 in epoch 4, gen_loss = 1.4883318651806225, disc_loss = 0.0007240087473870848
Trained batch 22 in epoch 4, gen_loss = 1.4901148080825806, disc_loss = 0.0007209720219100785
Trained batch 23 in epoch 4, gen_loss = 1.4905717819929123, disc_loss = 0.0007085283820439751
Trained batch 24 in epoch 4, gen_loss = 1.4881235456466675, disc_loss = 0.0006936615682207048
Trained batch 25 in epoch 4, gen_loss = 1.4867366414803724, disc_loss = 0.0006789996002156001
Trained batch 26 in epoch 4, gen_loss = 1.4874326255586412, disc_loss = 0.000661256813112198
Trained batch 27 in epoch 4, gen_loss = 1.484782384974616, disc_loss = 0.0006449229476856999
Trained batch 28 in epoch 4, gen_loss = 1.4823644448970925, disc_loss = 0.0006335704549263906
Trained batch 29 in epoch 4, gen_loss = 1.4834831873575847, disc_loss = 0.0006245881551876665
Trained batch 30 in epoch 4, gen_loss = 1.4806083286962202, disc_loss = 0.000622443798478813
Trained batch 31 in epoch 4, gen_loss = 1.4845840968191624, disc_loss = 0.0006336443620966747
Trained batch 32 in epoch 4, gen_loss = 1.4848401799346462, disc_loss = 0.0006486268883401698
Trained batch 33 in epoch 4, gen_loss = 1.4851466592620401, disc_loss = 0.0006551081982359071
Trained batch 34 in epoch 4, gen_loss = 1.4863317489624024, disc_loss = 0.0006506540696136654
Trained batch 35 in epoch 4, gen_loss = 1.4843055937025282, disc_loss = 0.0006400617599461435
Trained batch 36 in epoch 4, gen_loss = 1.483904471268525, disc_loss = 0.0006319598886310249
Trained batch 37 in epoch 4, gen_loss = 1.4848682880401611, disc_loss = 0.0006272544560488313
Trained batch 38 in epoch 4, gen_loss = 1.48251818999266, disc_loss = 0.0006220153061290964
Trained batch 39 in epoch 4, gen_loss = 1.4830225229263305, disc_loss = 0.0006181844248203561
Trained batch 40 in epoch 4, gen_loss = 1.4834506627989978, disc_loss = 0.0006145764470225336
Trained batch 41 in epoch 4, gen_loss = 1.4815311602183752, disc_loss = 0.0006087779267025846
Trained batch 42 in epoch 4, gen_loss = 1.4825149386428123, disc_loss = 0.0006038448015271231
Trained batch 43 in epoch 4, gen_loss = 1.4811375384980983, disc_loss = 0.0006014169564216652
Trained batch 44 in epoch 4, gen_loss = 1.4809214803907607, disc_loss = 0.0005987967105789317
Trained batch 45 in epoch 4, gen_loss = 1.4807622640029243, disc_loss = 0.0005923775265135033
Trained batch 46 in epoch 4, gen_loss = 1.4795485608121182, disc_loss = 0.0005843695166441512
Trained batch 47 in epoch 4, gen_loss = 1.4793576647837956, disc_loss = 0.000577640724562419
Trained batch 48 in epoch 4, gen_loss = 1.4800057070595878, disc_loss = 0.0005715884469040879
Trained batch 49 in epoch 4, gen_loss = 1.4803795671463014, disc_loss = 0.0005652866105083376
Trained batch 50 in epoch 4, gen_loss = 1.481669734506046, disc_loss = 0.000560451232755155
Trained batch 51 in epoch 4, gen_loss = 1.4813321003547082, disc_loss = 0.0005581927465615221
Trained batch 52 in epoch 4, gen_loss = 1.4807704349733748, disc_loss = 0.0005568013864762659
Trained batch 53 in epoch 4, gen_loss = 1.4806898258350514, disc_loss = 0.0005529109190252644
Trained batch 54 in epoch 4, gen_loss = 1.4786919658834283, disc_loss = 0.0005454283734169705
Trained batch 55 in epoch 4, gen_loss = 1.4784787872007914, disc_loss = 0.0005381737882999005
Trained batch 56 in epoch 4, gen_loss = 1.4782357194967437, disc_loss = 0.000532704574237741
Trained batch 57 in epoch 4, gen_loss = 1.4774195407998973, disc_loss = 0.0005275427460658428
Trained batch 58 in epoch 4, gen_loss = 1.4767462459661194, disc_loss = 0.0005234622614067522
Trained batch 59 in epoch 4, gen_loss = 1.476980197429657, disc_loss = 0.0005203841198332763
Trained batch 60 in epoch 4, gen_loss = 1.4769849366829044, disc_loss = 0.0005171532276540719
Trained batch 61 in epoch 4, gen_loss = 1.4754988474230613, disc_loss = 0.0005122165009285504
Trained batch 62 in epoch 4, gen_loss = 1.474072706131708, disc_loss = 0.0005069234674530369
Trained batch 63 in epoch 4, gen_loss = 1.4735438115894794, disc_loss = 0.0005020130454340688
Trained batch 64 in epoch 4, gen_loss = 1.4738474002251258, disc_loss = 0.0004969759665143031
Trained batch 65 in epoch 4, gen_loss = 1.4750181183670505, disc_loss = 0.0004916387931161532
Trained batch 66 in epoch 4, gen_loss = 1.4751652141115559, disc_loss = 0.00048628465555705576
Trained batch 67 in epoch 4, gen_loss = 1.474101268193301, disc_loss = 0.00048159799831303055
Trained batch 68 in epoch 4, gen_loss = 1.474363344303076, disc_loss = 0.00048100272829617387
Trained batch 69 in epoch 4, gen_loss = 1.4738167456218174, disc_loss = 0.0004859047322367717
Trained batch 70 in epoch 4, gen_loss = 1.4741141695371816, disc_loss = 0.000493001246506768
Trained batch 71 in epoch 4, gen_loss = 1.4746040503184001, disc_loss = 0.0004979062622522987
Trained batch 72 in epoch 4, gen_loss = 1.4745629764583013, disc_loss = 0.0004995529031961493
Trained batch 73 in epoch 4, gen_loss = 1.4728448535944965, disc_loss = 0.000501255046598286
Trained batch 74 in epoch 4, gen_loss = 1.4724787282943725, disc_loss = 0.0005025380923567961
Trained batch 75 in epoch 4, gen_loss = 1.4726800651926744, disc_loss = 0.0005021250958395141
Trained batch 76 in epoch 4, gen_loss = 1.4738556982634903, disc_loss = 0.0005015848596072333
Trained batch 77 in epoch 4, gen_loss = 1.4742702902891698, disc_loss = 0.0005025855796889234
Trained batch 78 in epoch 4, gen_loss = 1.4749363660812378, disc_loss = 0.0005054218183224432
Trained batch 79 in epoch 4, gen_loss = 1.4750500813126564, disc_loss = 0.00050813884663512
Trained batch 80 in epoch 4, gen_loss = 1.4758942347985726, disc_loss = 0.0005096870705910763
Trained batch 81 in epoch 4, gen_loss = 1.474938937803594, disc_loss = 0.0005122082976613012
Trained batch 82 in epoch 4, gen_loss = 1.474964887262827, disc_loss = 0.0005158315761946142
Trained batch 83 in epoch 4, gen_loss = 1.4746636876038142, disc_loss = 0.0005199317674851045
Trained batch 84 in epoch 4, gen_loss = 1.4747838945949778, disc_loss = 0.0005254051394705825
Trained batch 85 in epoch 4, gen_loss = 1.4756307685097982, disc_loss = 0.0005304035656208303
Trained batch 86 in epoch 4, gen_loss = 1.4755254422111073, disc_loss = 0.0005328409640043546
Trained batch 87 in epoch 4, gen_loss = 1.4753903286023573, disc_loss = 0.0005329106643330306
Trained batch 88 in epoch 4, gen_loss = 1.474762426333481, disc_loss = 0.000531151625223123
Trained batch 89 in epoch 4, gen_loss = 1.4750608139567905, disc_loss = 0.0005299175161376802
Trained batch 90 in epoch 4, gen_loss = 1.4750465835843767, disc_loss = 0.0005291870620567352
Trained batch 91 in epoch 4, gen_loss = 1.4752703995808312, disc_loss = 0.0005294721767827666
Trained batch 92 in epoch 4, gen_loss = 1.475554641856942, disc_loss = 0.0005304051287126758
Trained batch 93 in epoch 4, gen_loss = 1.475311889293346, disc_loss = 0.0005305123826900021
Trained batch 94 in epoch 4, gen_loss = 1.4755833663438496, disc_loss = 0.0005301311915421761
Trained batch 95 in epoch 4, gen_loss = 1.4761635263760884, disc_loss = 0.0005293512640491826
Trained batch 96 in epoch 4, gen_loss = 1.4752684561247678, disc_loss = 0.0005280948697094873
Trained batch 97 in epoch 4, gen_loss = 1.4754524851331905, disc_loss = 0.000529580556832691
Trained batch 98 in epoch 4, gen_loss = 1.4754644247016522, disc_loss = 0.0005330270320304077
Trained batch 99 in epoch 4, gen_loss = 1.4758083522319794, disc_loss = 0.0005351804094971158
Trained batch 100 in epoch 4, gen_loss = 1.4757323418513384, disc_loss = 0.000535168753312163
Trained batch 101 in epoch 4, gen_loss = 1.4765531654451407, disc_loss = 0.0005349216303062241
Trained batch 102 in epoch 4, gen_loss = 1.476583426438489, disc_loss = 0.0005349785112662837
Trained batch 103 in epoch 4, gen_loss = 1.4760649697138712, disc_loss = 0.000534415886739645
Trained batch 104 in epoch 4, gen_loss = 1.475503234636216, disc_loss = 0.000532926066634467
Trained batch 105 in epoch 4, gen_loss = 1.4748416385560665, disc_loss = 0.0005305194862094655
Trained batch 106 in epoch 4, gen_loss = 1.4746866159349958, disc_loss = 0.0005274327899161813
Trained batch 107 in epoch 4, gen_loss = 1.4754751203236756, disc_loss = 0.0005242989208016769
Trained batch 108 in epoch 4, gen_loss = 1.4758383320012223, disc_loss = 0.0005213106447593694
Trained batch 109 in epoch 4, gen_loss = 1.47626858624545, disc_loss = 0.0005188577828283252
Trained batch 110 in epoch 4, gen_loss = 1.4765949184830125, disc_loss = 0.000516259716351743
Trained batch 111 in epoch 4, gen_loss = 1.4760795746530806, disc_loss = 0.00051314788873112
Trained batch 112 in epoch 4, gen_loss = 1.4761023953952621, disc_loss = 0.0005100677105385926
Trained batch 113 in epoch 4, gen_loss = 1.4764609326396072, disc_loss = 0.0005069535771709573
Trained batch 114 in epoch 4, gen_loss = 1.475996906861015, disc_loss = 0.0005045235615081924
Trained batch 115 in epoch 4, gen_loss = 1.4757062731118038, disc_loss = 0.0005043393341174092
Trained batch 116 in epoch 4, gen_loss = 1.4758104452720056, disc_loss = 0.00050481639476095
Trained batch 117 in epoch 4, gen_loss = 1.4752895296630213, disc_loss = 0.0005038369662065249
Trained batch 118 in epoch 4, gen_loss = 1.4752382370604187, disc_loss = 0.0005018386533464297
Trained batch 119 in epoch 4, gen_loss = 1.4753249724706015, disc_loss = 0.0005000483552673056
Trained batch 120 in epoch 4, gen_loss = 1.4754007857693128, disc_loss = 0.0004994138956939694
Trained batch 121 in epoch 4, gen_loss = 1.4754928516559913, disc_loss = 0.0004989658472830522
Trained batch 122 in epoch 4, gen_loss = 1.4752874636068576, disc_loss = 0.0004970301652508901
Trained batch 123 in epoch 4, gen_loss = 1.4753847035669512, disc_loss = 0.0004941883202146498
Trained batch 124 in epoch 4, gen_loss = 1.4751499242782593, disc_loss = 0.0004917852557264268
Trained batch 125 in epoch 4, gen_loss = 1.475052709617312, disc_loss = 0.0004896183698234843
Trained batch 126 in epoch 4, gen_loss = 1.475193712655015, disc_loss = 0.0004874021037184729
Trained batch 127 in epoch 4, gen_loss = 1.4750924492254853, disc_loss = 0.00048484476667454146
Trained batch 128 in epoch 4, gen_loss = 1.475226035413816, disc_loss = 0.000482272124481965
Trained batch 129 in epoch 4, gen_loss = 1.4755336678945101, disc_loss = 0.000479628597811545
Trained batch 130 in epoch 4, gen_loss = 1.4756295380701545, disc_loss = 0.0004767961943951322
Trained batch 131 in epoch 4, gen_loss = 1.4750490450497828, disc_loss = 0.0004739686037558413
Trained batch 132 in epoch 4, gen_loss = 1.474687077049026, disc_loss = 0.00047170027184100557
Trained batch 133 in epoch 4, gen_loss = 1.4744070937384421, disc_loss = 0.00047016799297451334
Trained batch 134 in epoch 4, gen_loss = 1.4735354688432483, disc_loss = 0.0004687667448133989
Trained batch 135 in epoch 4, gen_loss = 1.4734764020232594, disc_loss = 0.0004693227686349179
Trained batch 136 in epoch 4, gen_loss = 1.4733256510574453, disc_loss = 0.000472151034789493
Trained batch 137 in epoch 4, gen_loss = 1.4736539021782253, disc_loss = 0.0004758889683770299
Trained batch 138 in epoch 4, gen_loss = 1.4739212732520892, disc_loss = 0.0004791945369584191
Trained batch 139 in epoch 4, gen_loss = 1.4740764651979719, disc_loss = 0.00048151420019816474
Trained batch 140 in epoch 4, gen_loss = 1.473906101909935, disc_loss = 0.00048341037503671537
Trained batch 141 in epoch 4, gen_loss = 1.473902619220841, disc_loss = 0.00048500893653524566
Trained batch 142 in epoch 4, gen_loss = 1.4734436657045271, disc_loss = 0.00048658229690289344
Trained batch 143 in epoch 4, gen_loss = 1.4732675328850746, disc_loss = 0.0004877617978612155
Trained batch 144 in epoch 4, gen_loss = 1.4731629610061645, disc_loss = 0.0004891463454033987
Trained batch 145 in epoch 4, gen_loss = 1.4731835012566554, disc_loss = 0.0004910300074149982
Trained batch 146 in epoch 4, gen_loss = 1.4726653812693902, disc_loss = 0.000492715618401278
Trained batch 147 in epoch 4, gen_loss = 1.4725959381541691, disc_loss = 0.0004943072990745595
Trained batch 148 in epoch 4, gen_loss = 1.472076166396173, disc_loss = 0.0004959738743608667
Trained batch 149 in epoch 4, gen_loss = 1.4726117142041524, disc_loss = 0.000497385474445764
Trained batch 150 in epoch 4, gen_loss = 1.4719875040433266, disc_loss = 0.0005012065963781075
Trained batch 151 in epoch 4, gen_loss = 1.472795581347064, disc_loss = 0.0005119196613170635
Trained batch 152 in epoch 4, gen_loss = 1.4721265750772812, disc_loss = 0.0005320075874063156
Trained batch 153 in epoch 4, gen_loss = 1.4722004625704381, disc_loss = 0.0005532583756056349
Trained batch 154 in epoch 4, gen_loss = 1.47193776945914, disc_loss = 0.000567366196229423
Trained batch 155 in epoch 4, gen_loss = 1.4716087877750397, disc_loss = 0.000576184469910237
Trained batch 156 in epoch 4, gen_loss = 1.4713006771294175, disc_loss = 0.0005822939349443705
Trained batch 157 in epoch 4, gen_loss = 1.4714212311974055, disc_loss = 0.0005851399397169523
Trained batch 158 in epoch 4, gen_loss = 1.4715565225613192, disc_loss = 0.0005851348732274506
Trained batch 159 in epoch 4, gen_loss = 1.4713689893484116, disc_loss = 0.0005834495103954396
Trained batch 160 in epoch 4, gen_loss = 1.4709249890368918, disc_loss = 0.0005812339795795298
Trained batch 161 in epoch 4, gen_loss = 1.4706704903531957, disc_loss = 0.0005787648665711548
Trained batch 162 in epoch 4, gen_loss = 1.4704873437530424, disc_loss = 0.0005762815201209367
Trained batch 163 in epoch 4, gen_loss = 1.4706553794988773, disc_loss = 0.0005737372507943158
Trained batch 164 in epoch 4, gen_loss = 1.4702759171977187, disc_loss = 0.0005715417145631473
Trained batch 165 in epoch 4, gen_loss = 1.4703612133681057, disc_loss = 0.0005696361337638326
Trained batch 166 in epoch 4, gen_loss = 1.4702395129346562, disc_loss = 0.0005677136196789728
Trained batch 167 in epoch 4, gen_loss = 1.4703094930875868, disc_loss = 0.0005655490270631466
Trained batch 168 in epoch 4, gen_loss = 1.470002795817584, disc_loss = 0.0005637329396724249
Trained batch 169 in epoch 4, gen_loss = 1.4699685138814589, disc_loss = 0.0005633633976685814
Trained batch 170 in epoch 4, gen_loss = 1.4698453040150872, disc_loss = 0.0005643607047624745
Trained batch 171 in epoch 4, gen_loss = 1.4695698674335036, disc_loss = 0.0005647808486469859
Trained batch 172 in epoch 4, gen_loss = 1.4689285245244903, disc_loss = 0.0005649446469907935
Trained batch 173 in epoch 4, gen_loss = 1.4688431408213474, disc_loss = 0.0005660715763659174
Trained batch 174 in epoch 4, gen_loss = 1.46883665902274, disc_loss = 0.000567105962545611
Trained batch 175 in epoch 4, gen_loss = 1.4693121137944134, disc_loss = 0.0005673758803161697
Trained batch 176 in epoch 4, gen_loss = 1.4688917331102878, disc_loss = 0.0005674621607091457
Trained batch 177 in epoch 4, gen_loss = 1.4688310361980053, disc_loss = 0.0005678129201758851
Trained batch 178 in epoch 4, gen_loss = 1.4686256900179986, disc_loss = 0.0005685285369666584
Trained batch 179 in epoch 4, gen_loss = 1.469221771425671, disc_loss = 0.0005693300691038733
Trained batch 180 in epoch 4, gen_loss = 1.4690814927138018, disc_loss = 0.0005703873871098844
Trained batch 181 in epoch 4, gen_loss = 1.469077760046655, disc_loss = 0.0005716539990217015
Trained batch 182 in epoch 4, gen_loss = 1.4695759796705403, disc_loss = 0.0005723670463916168
Trained batch 183 in epoch 4, gen_loss = 1.4694608275009238, disc_loss = 0.0005721175737404417
Trained batch 184 in epoch 4, gen_loss = 1.4694391959422344, disc_loss = 0.0005705462384031381
Trained batch 185 in epoch 4, gen_loss = 1.470077097415924, disc_loss = 0.0005686175237285845
Trained batch 186 in epoch 4, gen_loss = 1.4704839501151428, disc_loss = 0.0005671971274152607
Trained batch 187 in epoch 4, gen_loss = 1.4706142849110542, disc_loss = 0.0005663660274567132
Trained batch 188 in epoch 4, gen_loss = 1.4705861838406356, disc_loss = 0.0005659293641290682
Trained batch 189 in epoch 4, gen_loss = 1.4703856367813914, disc_loss = 0.0005659661163104159
Trained batch 190 in epoch 4, gen_loss = 1.4706102790632798, disc_loss = 0.0005658477865840937
Trained batch 191 in epoch 4, gen_loss = 1.4706562881668408, disc_loss = 0.0005650694492184508
Trained batch 192 in epoch 4, gen_loss = 1.470705201588764, disc_loss = 0.0005638227743606947
Trained batch 193 in epoch 4, gen_loss = 1.470950834529916, disc_loss = 0.0005623753120031775
Trained batch 194 in epoch 4, gen_loss = 1.4710440800740168, disc_loss = 0.0005609497785395107
Trained batch 195 in epoch 4, gen_loss = 1.4711061156525904, disc_loss = 0.0005596578714398582
Trained batch 196 in epoch 4, gen_loss = 1.4712531984154948, disc_loss = 0.0005583651977689312
Trained batch 197 in epoch 4, gen_loss = 1.470741407437758, disc_loss = 0.0005572507922411802
Trained batch 198 in epoch 4, gen_loss = 1.4712928635391158, disc_loss = 0.0005562122641090332
Trained batch 199 in epoch 4, gen_loss = 1.4710334134101868, disc_loss = 0.000555363086386933
Trained batch 200 in epoch 4, gen_loss = 1.4708619396484905, disc_loss = 0.0005547679474650285
Trained batch 201 in epoch 4, gen_loss = 1.4708159424290799, disc_loss = 0.0005539356312907006
Trained batch 202 in epoch 4, gen_loss = 1.4707283339476938, disc_loss = 0.000552583150717595
Trained batch 203 in epoch 4, gen_loss = 1.4707581663832945, disc_loss = 0.0005507749123995274
Trained batch 204 in epoch 4, gen_loss = 1.4708765291586154, disc_loss = 0.0005487740292531869
Trained batch 205 in epoch 4, gen_loss = 1.4711004883340262, disc_loss = 0.0005465788529813968
Trained batch 206 in epoch 4, gen_loss = 1.471200124077175, disc_loss = 0.0005442981342411069
Trained batch 207 in epoch 4, gen_loss = 1.4712856325965662, disc_loss = 0.0005424025258574917
Trained batch 208 in epoch 4, gen_loss = 1.4711287403791145, disc_loss = 0.0005414631621481552
Trained batch 209 in epoch 4, gen_loss = 1.4707892945834569, disc_loss = 0.0005413671102793333
Trained batch 210 in epoch 4, gen_loss = 1.4709654684880333, disc_loss = 0.0005418073579542652
Trained batch 211 in epoch 4, gen_loss = 1.470797154700981, disc_loss = 0.0005414890195613723
Trained batch 212 in epoch 4, gen_loss = 1.4703849212664393, disc_loss = 0.0005406877961588538
Trained batch 213 in epoch 4, gen_loss = 1.4703770084915875, disc_loss = 0.0005395264206951915
Trained batch 214 in epoch 4, gen_loss = 1.470378418301427, disc_loss = 0.000538020787948775
Trained batch 215 in epoch 4, gen_loss = 1.4705826573901706, disc_loss = 0.0005364743873778261
Trained batch 216 in epoch 4, gen_loss = 1.470659737213416, disc_loss = 0.0005350992009985209
Trained batch 217 in epoch 4, gen_loss = 1.4708513972956105, disc_loss = 0.000533890855009187
Trained batch 218 in epoch 4, gen_loss = 1.4714232688625108, disc_loss = 0.0005324971176735465
Trained batch 219 in epoch 4, gen_loss = 1.4715763726017692, disc_loss = 0.0005310765547288941
Trained batch 220 in epoch 4, gen_loss = 1.4716722808812, disc_loss = 0.0005300113069311277
Trained batch 221 in epoch 4, gen_loss = 1.4722015261650085, disc_loss = 0.0005289467098099612
Trained batch 222 in epoch 4, gen_loss = 1.4720795801402207, disc_loss = 0.0005279598098090065
Trained batch 223 in epoch 4, gen_loss = 1.471809535686459, disc_loss = 0.0005275300703228172
Trained batch 224 in epoch 4, gen_loss = 1.4720026869244045, disc_loss = 0.0005264513073295044
Trained batch 225 in epoch 4, gen_loss = 1.472188555033861, disc_loss = 0.0005249835563856033
Trained batch 226 in epoch 4, gen_loss = 1.4726966141604116, disc_loss = 0.0005237116858335971
Trained batch 227 in epoch 4, gen_loss = 1.4725799215467352, disc_loss = 0.0005253742109377064
Trained batch 228 in epoch 4, gen_loss = 1.472438409338872, disc_loss = 0.000530351674549971
Trained batch 229 in epoch 4, gen_loss = 1.4726927124935647, disc_loss = 0.0005346246715065638
Trained batch 230 in epoch 4, gen_loss = 1.4721814765558614, disc_loss = 0.0005359384401041704
Trained batch 231 in epoch 4, gen_loss = 1.4723813806114525, disc_loss = 0.00053513725648874
Trained batch 232 in epoch 4, gen_loss = 1.4726186417714722, disc_loss = 0.0005343514279441912
Trained batch 233 in epoch 4, gen_loss = 1.4726417645429954, disc_loss = 0.0005334506692097654
Trained batch 234 in epoch 4, gen_loss = 1.4724020126018118, disc_loss = 0.0005325884343697095
Trained batch 235 in epoch 4, gen_loss = 1.4723588046381029, disc_loss = 0.000531940866833685
Trained batch 236 in epoch 4, gen_loss = 1.4723458038603707, disc_loss = 0.0005312378808769067
Trained batch 237 in epoch 4, gen_loss = 1.4726210301663696, disc_loss = 0.0005307907239275205
Trained batch 238 in epoch 4, gen_loss = 1.472930313653028, disc_loss = 0.0005309651223112143
Trained batch 239 in epoch 4, gen_loss = 1.472986331085364, disc_loss = 0.0005306096708409313
Trained batch 240 in epoch 4, gen_loss = 1.4728372443266429, disc_loss = 0.0005307439211995101
Trained batch 241 in epoch 4, gen_loss = 1.4726193645768915, disc_loss = 0.0005319350695106189
Trained batch 242 in epoch 4, gen_loss = 1.472738534825329, disc_loss = 0.0005338139618052756
Trained batch 243 in epoch 4, gen_loss = 1.4725230463215562, disc_loss = 0.0005351191917785012
Trained batch 244 in epoch 4, gen_loss = 1.4726939425176504, disc_loss = 0.0005358651593714781
Trained batch 245 in epoch 4, gen_loss = 1.4722239612563839, disc_loss = 0.0005363017179313725
Trained batch 246 in epoch 4, gen_loss = 1.4723689676779002, disc_loss = 0.0005367338710814725
Trained batch 247 in epoch 4, gen_loss = 1.472083118173384, disc_loss = 0.0005376594762339899
Trained batch 248 in epoch 4, gen_loss = 1.4724865500706745, disc_loss = 0.0005400696447402908
Trained batch 249 in epoch 4, gen_loss = 1.4724312472343444, disc_loss = 0.0005435916580900084
Trained batch 250 in epoch 4, gen_loss = 1.472353586162704, disc_loss = 0.0005467028289083002
Trained batch 251 in epoch 4, gen_loss = 1.472513796318145, disc_loss = 0.0005477854308645917
Trained batch 252 in epoch 4, gen_loss = 1.4726252211883606, disc_loss = 0.0005475198726660734
Trained batch 253 in epoch 4, gen_loss = 1.4727428499169237, disc_loss = 0.0005468322477414819
Trained batch 254 in epoch 4, gen_loss = 1.4722890587414013, disc_loss = 0.0005464393716001901
Trained batch 255 in epoch 4, gen_loss = 1.4724585679359734, disc_loss = 0.0005470317391598201
Trained batch 256 in epoch 4, gen_loss = 1.472298697738796, disc_loss = 0.0005485462314430679
Trained batch 257 in epoch 4, gen_loss = 1.4721232199853704, disc_loss = 0.0005506024110866909
Trained batch 258 in epoch 4, gen_loss = 1.4722466234074596, disc_loss = 0.0005527397111302302
Trained batch 259 in epoch 4, gen_loss = 1.4723020150111272, disc_loss = 0.0005542425326544058
Trained batch 260 in epoch 4, gen_loss = 1.4720552282771846, disc_loss = 0.0005549716743294032
Trained batch 261 in epoch 4, gen_loss = 1.4718900650512172, disc_loss = 0.0005549651931139075
Trained batch 262 in epoch 4, gen_loss = 1.4717493877664718, disc_loss = 0.0005545570864950788
Trained batch 263 in epoch 4, gen_loss = 1.4715644261150649, disc_loss = 0.0005537452040119784
Trained batch 264 in epoch 4, gen_loss = 1.4715254284300894, disc_loss = 0.0005526216757507942
Trained batch 265 in epoch 4, gen_loss = 1.4712032120030625, disc_loss = 0.0005511419639011926
Trained batch 266 in epoch 4, gen_loss = 1.4711040423603987, disc_loss = 0.000549551761650946
Trained batch 267 in epoch 4, gen_loss = 1.470945280879291, disc_loss = 0.0005481591876980643
Trained batch 268 in epoch 4, gen_loss = 1.4708344298224467, disc_loss = 0.0005470314161857628
Trained batch 269 in epoch 4, gen_loss = 1.470719541002203, disc_loss = 0.0005460646901661271
Trained batch 270 in epoch 4, gen_loss = 1.4708487235312093, disc_loss = 0.0005454044121137573
Trained batch 271 in epoch 4, gen_loss = 1.4706572776331621, disc_loss = 0.0005449129221500805
Trained batch 272 in epoch 4, gen_loss = 1.4707965684897735, disc_loss = 0.0005442116171219249
Trained batch 273 in epoch 4, gen_loss = 1.4706785061063559, disc_loss = 0.0005430335276532854
Trained batch 274 in epoch 4, gen_loss = 1.4707075812599875, disc_loss = 0.0005415059608375569
Trained batch 275 in epoch 4, gen_loss = 1.4706542211166327, disc_loss = 0.0005398039354169167
Trained batch 276 in epoch 4, gen_loss = 1.4705201262601446, disc_loss = 0.0005380438275549927
Trained batch 277 in epoch 4, gen_loss = 1.4705957701737933, disc_loss = 0.0005365076792893744
Trained batch 278 in epoch 4, gen_loss = 1.4705322416879798, disc_loss = 0.0005353518744378174
Trained batch 279 in epoch 4, gen_loss = 1.4704418169600624, disc_loss = 0.0005343853301643061
Trained batch 280 in epoch 4, gen_loss = 1.4705769990262612, disc_loss = 0.0005331903651420497
Trained batch 281 in epoch 4, gen_loss = 1.470380979226836, disc_loss = 0.0005317476341923607
Trained batch 282 in epoch 4, gen_loss = 1.470309906629286, disc_loss = 0.0005305853020111856
Trained batch 283 in epoch 4, gen_loss = 1.4702619519871725, disc_loss = 0.0005296782022104336
Trained batch 284 in epoch 4, gen_loss = 1.4702515986927769, disc_loss = 0.0005290317405301163
Trained batch 285 in epoch 4, gen_loss = 1.4702711155364563, disc_loss = 0.0005287941063101358
Trained batch 286 in epoch 4, gen_loss = 1.4701476969370029, disc_loss = 0.00052891885210721
Trained batch 287 in epoch 4, gen_loss = 1.4701303326421313, disc_loss = 0.0005291343254106727
Trained batch 288 in epoch 4, gen_loss = 1.4700941144388853, disc_loss = 0.000529411960547068
Trained batch 289 in epoch 4, gen_loss = 1.470137628604626, disc_loss = 0.0005298885445568132
Trained batch 290 in epoch 4, gen_loss = 1.4699239472752994, disc_loss = 0.0005302268419057911
Trained batch 291 in epoch 4, gen_loss = 1.4698590207589817, disc_loss = 0.0005302634944362655
Trained batch 292 in epoch 4, gen_loss = 1.4698598925977844, disc_loss = 0.0005305266605154531
Trained batch 293 in epoch 4, gen_loss = 1.4700460571821043, disc_loss = 0.0005311609354134661
Trained batch 294 in epoch 4, gen_loss = 1.4699458219237247, disc_loss = 0.0005320179985512553
Trained batch 295 in epoch 4, gen_loss = 1.4700692110770457, disc_loss = 0.0005328481692649311
Trained batch 296 in epoch 4, gen_loss = 1.4699373341569997, disc_loss = 0.0005334436955982474
Trained batch 297 in epoch 4, gen_loss = 1.4698965873494245, disc_loss = 0.0005337998395802878
Trained batch 298 in epoch 4, gen_loss = 1.4695564636019958, disc_loss = 0.0005343832424257798
Trained batch 299 in epoch 4, gen_loss = 1.4697036850452423, disc_loss = 0.0005352196742508871
Trained batch 300 in epoch 4, gen_loss = 1.4694073033887287, disc_loss = 0.0005360191752337402
Trained batch 301 in epoch 4, gen_loss = 1.4693426091149944, disc_loss = 0.0005369612599980542
Trained batch 302 in epoch 4, gen_loss = 1.4693933859123256, disc_loss = 0.000537462374898559
Trained batch 303 in epoch 4, gen_loss = 1.4693552071326657, disc_loss = 0.000537496989445093
Trained batch 304 in epoch 4, gen_loss = 1.4694609329348705, disc_loss = 0.0005375091267986315
Trained batch 305 in epoch 4, gen_loss = 1.4694530644447974, disc_loss = 0.0005378381008079909
Trained batch 306 in epoch 4, gen_loss = 1.4695047330390358, disc_loss = 0.0005383563986547133
Trained batch 307 in epoch 4, gen_loss = 1.4696345344766395, disc_loss = 0.0005387546359100258
Trained batch 308 in epoch 4, gen_loss = 1.4693504876689232, disc_loss = 0.0005391334072561651
Trained batch 309 in epoch 4, gen_loss = 1.4695375154095311, disc_loss = 0.0005391078177771921
Trained batch 310 in epoch 4, gen_loss = 1.4694333287297339, disc_loss = 0.0005386473946580273
Trained batch 311 in epoch 4, gen_loss = 1.469202037041004, disc_loss = 0.0005378589511308699
Trained batch 312 in epoch 4, gen_loss = 1.4691476357249786, disc_loss = 0.0005369764384843362
Trained batch 313 in epoch 4, gen_loss = 1.4689742501374263, disc_loss = 0.0005362076026010831
Trained batch 314 in epoch 4, gen_loss = 1.468938688247923, disc_loss = 0.0005354736090844704
Trained batch 315 in epoch 4, gen_loss = 1.468786558018455, disc_loss = 0.0005346582066879278
Trained batch 316 in epoch 4, gen_loss = 1.468719116896861, disc_loss = 0.0005335871047415251
Trained batch 317 in epoch 4, gen_loss = 1.4689753261752099, disc_loss = 0.0005323284956532876
Trained batch 318 in epoch 4, gen_loss = 1.4691265922355055, disc_loss = 0.0005310503351735681
Trained batch 319 in epoch 4, gen_loss = 1.4690514467656612, disc_loss = 0.0005298149247209949
Trained batch 320 in epoch 4, gen_loss = 1.4691578732844082, disc_loss = 0.0005285654855203724
Trained batch 321 in epoch 4, gen_loss = 1.4692868016521383, disc_loss = 0.000527329107143436
Trained batch 322 in epoch 4, gen_loss = 1.4695073011858915, disc_loss = 0.0005260447519377232
Trained batch 323 in epoch 4, gen_loss = 1.4695273251445204, disc_loss = 0.0005247002373599335
Trained batch 324 in epoch 4, gen_loss = 1.469661101928124, disc_loss = 0.0005234402836784004
Trained batch 325 in epoch 4, gen_loss = 1.4696974593437522, disc_loss = 0.0005224824040193265
Trained batch 326 in epoch 4, gen_loss = 1.4696026912887528, disc_loss = 0.0005219178758892701
Trained batch 327 in epoch 4, gen_loss = 1.4695901296487668, disc_loss = 0.0005215707283574241
Trained batch 328 in epoch 4, gen_loss = 1.469522420396196, disc_loss = 0.0005212651164851952
Trained batch 329 in epoch 4, gen_loss = 1.4696676232598045, disc_loss = 0.0005208816771328478
Trained batch 330 in epoch 4, gen_loss = 1.4695777896667896, disc_loss = 0.0005202581832980951
Trained batch 331 in epoch 4, gen_loss = 1.4694957639797623, disc_loss = 0.0005195803839221725
Trained batch 332 in epoch 4, gen_loss = 1.4694089663995278, disc_loss = 0.0005190330086882134
Trained batch 333 in epoch 4, gen_loss = 1.469251354297478, disc_loss = 0.000518665246727868
Trained batch 334 in epoch 4, gen_loss = 1.4693549334113278, disc_loss = 0.000518410094125794
Trained batch 335 in epoch 4, gen_loss = 1.469566160369487, disc_loss = 0.0005182731608458978
Trained batch 336 in epoch 4, gen_loss = 1.4694438833157457, disc_loss = 0.0005180913259676666
Trained batch 337 in epoch 4, gen_loss = 1.4695716253399143, disc_loss = 0.0005179103693360678
Trained batch 338 in epoch 4, gen_loss = 1.4693247431499066, disc_loss = 0.0005176788172186668
Trained batch 339 in epoch 4, gen_loss = 1.469271954017527, disc_loss = 0.0005175228763512089
Trained batch 340 in epoch 4, gen_loss = 1.4692129316218088, disc_loss = 0.0005173361053245819
Trained batch 341 in epoch 4, gen_loss = 1.4692384998003643, disc_loss = 0.0005170410994337518
Trained batch 342 in epoch 4, gen_loss = 1.4692464948743147, disc_loss = 0.0005165359434083174
Trained batch 343 in epoch 4, gen_loss = 1.4690981815720714, disc_loss = 0.0005158682775207887
Trained batch 344 in epoch 4, gen_loss = 1.4693793984426968, disc_loss = 0.0005152491132637648
Trained batch 345 in epoch 4, gen_loss = 1.469412415013837, disc_loss = 0.0005148176430281107
Trained batch 346 in epoch 4, gen_loss = 1.4696138904829876, disc_loss = 0.0005146025098180559
Trained batch 347 in epoch 4, gen_loss = 1.469644900368548, disc_loss = 0.0005144804813373893
Trained batch 348 in epoch 4, gen_loss = 1.4695701008198254, disc_loss = 0.0005142334925780009
Trained batch 349 in epoch 4, gen_loss = 1.469408129623958, disc_loss = 0.00051366573237049
Trained batch 350 in epoch 4, gen_loss = 1.4693007126153363, disc_loss = 0.0005128972649082085
Trained batch 351 in epoch 4, gen_loss = 1.469219133257866, disc_loss = 0.0005119868603949064
Trained batch 352 in epoch 4, gen_loss = 1.4691905681539865, disc_loss = 0.000510981385211893
Trained batch 353 in epoch 4, gen_loss = 1.4693750995027144, disc_loss = 0.0005100261990002641
Trained batch 354 in epoch 4, gen_loss = 1.469363449660825, disc_loss = 0.0005093201368138797
Trained batch 355 in epoch 4, gen_loss = 1.4692716424384813, disc_loss = 0.0005087184875806548
Trained batch 356 in epoch 4, gen_loss = 1.469143617720831, disc_loss = 0.0005081159020536018
Trained batch 357 in epoch 4, gen_loss = 1.4690893778587852, disc_loss = 0.0005074359526400528
Trained batch 358 in epoch 4, gen_loss = 1.4691897026343599, disc_loss = 0.0005066208630974708
Trained batch 359 in epoch 4, gen_loss = 1.469167439474, disc_loss = 0.0005056884922750114
Trained batch 360 in epoch 4, gen_loss = 1.4693302490704607, disc_loss = 0.0005047730400521757
Trained batch 361 in epoch 4, gen_loss = 1.4694180850824599, disc_loss = 0.0005038455484025901
Trained batch 362 in epoch 4, gen_loss = 1.4695064584742565, disc_loss = 0.0005029047076550592
Trained batch 363 in epoch 4, gen_loss = 1.4694478233436963, disc_loss = 0.0005020177355058527
Trained batch 364 in epoch 4, gen_loss = 1.4694901534955795, disc_loss = 0.0005012940323978586
Trained batch 365 in epoch 4, gen_loss = 1.4692159301596261, disc_loss = 0.0005007384439483107
Trained batch 366 in epoch 4, gen_loss = 1.4692389490818782, disc_loss = 0.0005005527275747033
Trained batch 367 in epoch 4, gen_loss = 1.4693384484752365, disc_loss = 0.0005007440704898529
Trained batch 368 in epoch 4, gen_loss = 1.469452643136022, disc_loss = 0.0005011055789282798
Trained batch 369 in epoch 4, gen_loss = 1.4695122245195749, disc_loss = 0.0005015833374518725
Trained batch 370 in epoch 4, gen_loss = 1.4695730308959427, disc_loss = 0.0005020027200210051
Trained batch 371 in epoch 4, gen_loss = 1.4696989466426194, disc_loss = 0.0005023409016708899
Trained batch 372 in epoch 4, gen_loss = 1.4695713069419758, disc_loss = 0.0005024570451525661
Trained batch 373 in epoch 4, gen_loss = 1.4696356571294407, disc_loss = 0.0005021687273081157
Trained batch 374 in epoch 4, gen_loss = 1.4695462446212768, disc_loss = 0.0005016117715664829
Trained batch 375 in epoch 4, gen_loss = 1.4695444531897282, disc_loss = 0.000501048679383375
Trained batch 376 in epoch 4, gen_loss = 1.4693996779798513, disc_loss = 0.00050060638017052
Trained batch 377 in epoch 4, gen_loss = 1.4693334172011683, disc_loss = 0.0005002496985422334
Trained batch 378 in epoch 4, gen_loss = 1.469560798994784, disc_loss = 0.0005001264516713274
Trained batch 379 in epoch 4, gen_loss = 1.4696848125834214, disc_loss = 0.000500288054670244
Trained batch 380 in epoch 4, gen_loss = 1.4697540178699444, disc_loss = 0.0005007226522654427
Trained batch 381 in epoch 4, gen_loss = 1.469747955262349, disc_loss = 0.0005013885098635658
Trained batch 382 in epoch 4, gen_loss = 1.4696587582481124, disc_loss = 0.0005020537700819571
Trained batch 383 in epoch 4, gen_loss = 1.4697672721619408, disc_loss = 0.0005026936714405869
Trained batch 384 in epoch 4, gen_loss = 1.4696431615135885, disc_loss = 0.0005034148877156995
Trained batch 385 in epoch 4, gen_loss = 1.4696453000597385, disc_loss = 0.0005041776314167272
Trained batch 386 in epoch 4, gen_loss = 1.4695248117126545, disc_loss = 0.0005048335225965697
Trained batch 387 in epoch 4, gen_loss = 1.4697761882826226, disc_loss = 0.000505241977473056
Trained batch 388 in epoch 4, gen_loss = 1.4697068960317303, disc_loss = 0.000505368824224323
Trained batch 389 in epoch 4, gen_loss = 1.4696163691007174, disc_loss = 0.0005054964992525175
Trained batch 390 in epoch 4, gen_loss = 1.469578680479923, disc_loss = 0.0005056697101069643
Trained batch 391 in epoch 4, gen_loss = 1.469784751534462, disc_loss = 0.0005055682666315246
Trained batch 392 in epoch 4, gen_loss = 1.4697980125441805, disc_loss = 0.0005051537869576929
Trained batch 393 in epoch 4, gen_loss = 1.4698995857069335, disc_loss = 0.0005045760464532476
Trained batch 394 in epoch 4, gen_loss = 1.4697206095804143, disc_loss = 0.0005038526977553869
Trained batch 395 in epoch 4, gen_loss = 1.4697970516151853, disc_loss = 0.0005031385746516401
Trained batch 396 in epoch 4, gen_loss = 1.469634053388831, disc_loss = 0.0005025088179930435
Trained batch 397 in epoch 4, gen_loss = 1.4700575914215204, disc_loss = 0.000501952611360975
Trained batch 398 in epoch 4, gen_loss = 1.4701008698097746, disc_loss = 0.0005011662798463938
Trained batch 399 in epoch 4, gen_loss = 1.4701085078716278, disc_loss = 0.0005004308993011363
Trained batch 400 in epoch 4, gen_loss = 1.4699312172031165, disc_loss = 0.0004997990190146138
Trained batch 401 in epoch 4, gen_loss = 1.4698593405941827, disc_loss = 0.0004992747806555323
Trained batch 402 in epoch 4, gen_loss = 1.4700761264370334, disc_loss = 0.0004988402164978537
Trained batch 403 in epoch 4, gen_loss = 1.4701601420298662, disc_loss = 0.0004982203434265823
Trained batch 404 in epoch 4, gen_loss = 1.4702232678731282, disc_loss = 0.0004973277575724448
Trained batch 405 in epoch 4, gen_loss = 1.4702432035225366, disc_loss = 0.0004963628977161243
Trained batch 406 in epoch 4, gen_loss = 1.470370381997317, disc_loss = 0.0004954066945985589
Trained batch 407 in epoch 4, gen_loss = 1.470462672850665, disc_loss = 0.0004944452209255199
Trained batch 408 in epoch 4, gen_loss = 1.4703053396313581, disc_loss = 0.0004934787630946899
Trained batch 409 in epoch 4, gen_loss = 1.4702714225141014, disc_loss = 0.0004925499008450282
Trained batch 410 in epoch 4, gen_loss = 1.4703141346465063, disc_loss = 0.0004916927057459731
Trained batch 411 in epoch 4, gen_loss = 1.4701580963667156, disc_loss = 0.0004909264462714895
Trained batch 412 in epoch 4, gen_loss = 1.4700333538124695, disc_loss = 0.0004903051546642604
Trained batch 413 in epoch 4, gen_loss = 1.470175838700815, disc_loss = 0.0004897855807922203
Trained batch 414 in epoch 4, gen_loss = 1.4698871908417668, disc_loss = 0.0004894622292121345
Trained batch 415 in epoch 4, gen_loss = 1.4699489167676523, disc_loss = 0.0004892442108694712
Trained batch 416 in epoch 4, gen_loss = 1.4696551741455957, disc_loss = 0.0004890290223059525
Trained batch 417 in epoch 4, gen_loss = 1.469578946036015, disc_loss = 0.0004887442685306935
Trained batch 418 in epoch 4, gen_loss = 1.4696119813190724, disc_loss = 0.0004884605733381845
Trained batch 419 in epoch 4, gen_loss = 1.4696694762933822, disc_loss = 0.00048823584294864085
Trained batch 420 in epoch 4, gen_loss = 1.4696182825219886, disc_loss = 0.00048796642631347096
Trained batch 421 in epoch 4, gen_loss = 1.4697578851645592, disc_loss = 0.00048756613279899726
Trained batch 422 in epoch 4, gen_loss = 1.4695996392703226, disc_loss = 0.00048699481705526755
Trained batch 423 in epoch 4, gen_loss = 1.4696970840670027, disc_loss = 0.00048626452925813247
Trained batch 424 in epoch 4, gen_loss = 1.4698065909217386, disc_loss = 0.00048547422535621617
Trained batch 425 in epoch 4, gen_loss = 1.4697985318904752, disc_loss = 0.0004846711512790291
Trained batch 426 in epoch 4, gen_loss = 1.4698488963571588, disc_loss = 0.0004840153401527517
Trained batch 427 in epoch 4, gen_loss = 1.4698558043096668, disc_loss = 0.0004834970331332749
Trained batch 428 in epoch 4, gen_loss = 1.4697992112530973, disc_loss = 0.00048295631804945823
Trained batch 429 in epoch 4, gen_loss = 1.4700579626615657, disc_loss = 0.00048232769252134073
Trained batch 430 in epoch 4, gen_loss = 1.4700605885888474, disc_loss = 0.0004815682173071034
Trained batch 431 in epoch 4, gen_loss = 1.470118538097099, disc_loss = 0.00048092300496002145
Trained batch 432 in epoch 4, gen_loss = 1.4702607373993062, disc_loss = 0.0004804590389792007
Trained batch 433 in epoch 4, gen_loss = 1.4702880646226593, disc_loss = 0.0004802387313734073
Trained batch 434 in epoch 4, gen_loss = 1.4702806538548963, disc_loss = 0.0004803106328773569
Trained batch 435 in epoch 4, gen_loss = 1.4702931374584862, disc_loss = 0.00048064144732819876
Trained batch 436 in epoch 4, gen_loss = 1.4703084238606678, disc_loss = 0.00048125869212834615
Trained batch 437 in epoch 4, gen_loss = 1.4701698261853222, disc_loss = 0.0004821240399905946
Trained batch 438 in epoch 4, gen_loss = 1.4705624835637816, disc_loss = 0.00048300625307494475
Trained batch 439 in epoch 4, gen_loss = 1.470575618202036, disc_loss = 0.0004838647520128606
Trained batch 440 in epoch 4, gen_loss = 1.4705840838469075, disc_loss = 0.00048472862746453023
Trained batch 441 in epoch 4, gen_loss = 1.4706661369466134, disc_loss = 0.0004855955570360184
Trained batch 442 in epoch 4, gen_loss = 1.4706872042361017, disc_loss = 0.00048652731424366267
Trained batch 443 in epoch 4, gen_loss = 1.4706617996499345, disc_loss = 0.00048742905924915284
Trained batch 444 in epoch 4, gen_loss = 1.4707608169384216, disc_loss = 0.00048822209409377906
Trained batch 445 in epoch 4, gen_loss = 1.470673218970876, disc_loss = 0.0004886629662640662
Trained batch 446 in epoch 4, gen_loss = 1.4706513604328404, disc_loss = 0.0004887958761218412
Trained batch 447 in epoch 4, gen_loss = 1.4706711189023085, disc_loss = 0.0004887319149702307
Trained batch 448 in epoch 4, gen_loss = 1.4706124425730887, disc_loss = 0.0004885084636853998
Trained batch 449 in epoch 4, gen_loss = 1.4706852555274963, disc_loss = 0.0004882827772558408
Trained batch 450 in epoch 4, gen_loss = 1.4705528747744676, disc_loss = 0.0004880683955705741
Trained batch 451 in epoch 4, gen_loss = 1.4706914999843699, disc_loss = 0.000488005636999228
Trained batch 452 in epoch 4, gen_loss = 1.4704685921700584, disc_loss = 0.0004880966353606665
Trained batch 453 in epoch 4, gen_loss = 1.4704932998455569, disc_loss = 0.0004883715103536542
Trained batch 454 in epoch 4, gen_loss = 1.4707134356865517, disc_loss = 0.0004885021045933232
Trained batch 455 in epoch 4, gen_loss = 1.470657244847532, disc_loss = 0.0004884989722612724
Trained batch 456 in epoch 4, gen_loss = 1.4707495344545962, disc_loss = 0.0004885173048163027
Trained batch 457 in epoch 4, gen_loss = 1.4708238780238223, disc_loss = 0.000488547822611135
Trained batch 458 in epoch 4, gen_loss = 1.4707847771301767, disc_loss = 0.000488487411088646
Trained batch 459 in epoch 4, gen_loss = 1.470795657582905, disc_loss = 0.0004882450297926603
Trained batch 460 in epoch 4, gen_loss = 1.4708949464520766, disc_loss = 0.000488119990047327
Trained batch 461 in epoch 4, gen_loss = 1.4708956918675147, disc_loss = 0.00048808864855121324
Trained batch 462 in epoch 4, gen_loss = 1.4707434239191834, disc_loss = 0.0004883170631905508
Trained batch 463 in epoch 4, gen_loss = 1.4709684689497124, disc_loss = 0.0004891990859756208
Trained batch 464 in epoch 4, gen_loss = 1.4708287869730303, disc_loss = 0.0004906251410839789
Trained batch 465 in epoch 4, gen_loss = 1.470842100008363, disc_loss = 0.0004927174851870166
Trained batch 466 in epoch 4, gen_loss = 1.470890753529567, disc_loss = 0.0004951557647233691
Trained batch 467 in epoch 4, gen_loss = 1.4709745716844869, disc_loss = 0.0004976526262099571
Trained batch 468 in epoch 4, gen_loss = 1.470994554348846, disc_loss = 0.0004993138382235405
Trained batch 469 in epoch 4, gen_loss = 1.471142062988687, disc_loss = 0.0004996990910242064
Trained batch 470 in epoch 4, gen_loss = 1.471049986067851, disc_loss = 0.0004994809256196507
Trained batch 471 in epoch 4, gen_loss = 1.4711030739343773, disc_loss = 0.0004994848323202844
Trained batch 472 in epoch 4, gen_loss = 1.471127712449362, disc_loss = 0.0004994157380942525
Trained batch 473 in epoch 4, gen_loss = 1.4709969510006, disc_loss = 0.0004993396633770562
Trained batch 474 in epoch 4, gen_loss = 1.4709120978807149, disc_loss = 0.000499353592274833
Trained batch 475 in epoch 4, gen_loss = 1.470853102808239, disc_loss = 0.0004993966100117468
Trained batch 476 in epoch 4, gen_loss = 1.4710029006254248, disc_loss = 0.0004994922899305518
Trained batch 477 in epoch 4, gen_loss = 1.4710927296383112, disc_loss = 0.0004996592222931396
Trained batch 478 in epoch 4, gen_loss = 1.4710147826308249, disc_loss = 0.0004997852266799427
Trained batch 479 in epoch 4, gen_loss = 1.4708637773990632, disc_loss = 0.000499957166433281
Trained batch 480 in epoch 4, gen_loss = 1.4710371752043028, disc_loss = 0.0005001924737806048
Trained batch 481 in epoch 4, gen_loss = 1.471073024500455, disc_loss = 0.0005004362506929377
Trained batch 482 in epoch 4, gen_loss = 1.4709272545070136, disc_loss = 0.0005007409195539322
Trained batch 483 in epoch 4, gen_loss = 1.4710846649221152, disc_loss = 0.0005010660692924597
Trained batch 484 in epoch 4, gen_loss = 1.4709540902953786, disc_loss = 0.0005012567581269247
Trained batch 485 in epoch 4, gen_loss = 1.4710023972232646, disc_loss = 0.0005013639422009245
Trained batch 486 in epoch 4, gen_loss = 1.4709362195502562, disc_loss = 0.0005016187295702275
Trained batch 487 in epoch 4, gen_loss = 1.4710396144722329, disc_loss = 0.000502242150060574
Trained batch 488 in epoch 4, gen_loss = 1.4709402839586534, disc_loss = 0.0005033213043294263
Trained batch 489 in epoch 4, gen_loss = 1.47102474606767, disc_loss = 0.0005049961294927777
Trained batch 490 in epoch 4, gen_loss = 1.4707466218233594, disc_loss = 0.0005074732716802494
Trained batch 491 in epoch 4, gen_loss = 1.4708115960039743, disc_loss = 0.0005103114539880649
Trained batch 492 in epoch 4, gen_loss = 1.4707605756562332, disc_loss = 0.0005132882598827453
Trained batch 493 in epoch 4, gen_loss = 1.47092249374158, disc_loss = 0.0005162891309604902
Trained batch 494 in epoch 4, gen_loss = 1.4708946146146216, disc_loss = 0.0005191757260366682
Trained batch 495 in epoch 4, gen_loss = 1.470886662121742, disc_loss = 0.0005216259215382208
Trained batch 496 in epoch 4, gen_loss = 1.470694171830682, disc_loss = 0.0005234994657973148
Trained batch 497 in epoch 4, gen_loss = 1.4708347272681424, disc_loss = 0.0005246495074751725
Trained batch 498 in epoch 4, gen_loss = 1.4707274979245448, disc_loss = 0.000525239150041368
Trained batch 499 in epoch 4, gen_loss = 1.4706640050411224, disc_loss = 0.0005255285756575177
Trained batch 500 in epoch 4, gen_loss = 1.470807188285325, disc_loss = 0.0005256693357023868
Trained batch 501 in epoch 4, gen_loss = 1.4710273073014035, disc_loss = 0.0005256995382405441
Trained batch 502 in epoch 4, gen_loss = 1.4710405455905922, disc_loss = 0.0005256642281429825
Trained batch 503 in epoch 4, gen_loss = 1.4711043754267314, disc_loss = 0.000525754929806262
Trained batch 504 in epoch 4, gen_loss = 1.4710379654818242, disc_loss = 0.0005257362652123942
Trained batch 505 in epoch 4, gen_loss = 1.4710866175150212, disc_loss = 0.000525420978613011
Trained batch 506 in epoch 4, gen_loss = 1.4710335103717782, disc_loss = 0.0005248192384136662
Trained batch 507 in epoch 4, gen_loss = 1.4710298938544717, disc_loss = 0.000524030730929102
Trained batch 508 in epoch 4, gen_loss = 1.471012929567888, disc_loss = 0.0005231877205795508
Trained batch 509 in epoch 4, gen_loss = 1.47105560910468, disc_loss = 0.000522320048299198
Trained batch 510 in epoch 4, gen_loss = 1.4710721218422667, disc_loss = 0.0005214669980016927
Trained batch 511 in epoch 4, gen_loss = 1.4712508679367602, disc_loss = 0.0005206815771714446
Trained batch 512 in epoch 4, gen_loss = 1.4711067353540461, disc_loss = 0.0005199256011606675
Trained batch 513 in epoch 4, gen_loss = 1.471074715894484, disc_loss = 0.0005193676338970466
Trained batch 514 in epoch 4, gen_loss = 1.4711397103892947, disc_loss = 0.0005189896564031001
Trained batch 515 in epoch 4, gen_loss = 1.4710528293783351, disc_loss = 0.0005186649486436075
Trained batch 516 in epoch 4, gen_loss = 1.4711772731471109, disc_loss = 0.0005182980336167812
Trained batch 517 in epoch 4, gen_loss = 1.471265749811666, disc_loss = 0.0005179281581016113
Trained batch 518 in epoch 4, gen_loss = 1.4712028161179354, disc_loss = 0.000517630652353609
Trained batch 519 in epoch 4, gen_loss = 1.471218007344466, disc_loss = 0.0005176165114859872
Trained batch 520 in epoch 4, gen_loss = 1.4712184880379293, disc_loss = 0.0005178636196583345
Trained batch 521 in epoch 4, gen_loss = 1.4711032041644685, disc_loss = 0.0005181345927963476
Trained batch 522 in epoch 4, gen_loss = 1.471159136318112, disc_loss = 0.0005181815508502869
Trained batch 523 in epoch 4, gen_loss = 1.4711550273968064, disc_loss = 0.0005180887758637643
Trained batch 524 in epoch 4, gen_loss = 1.4712983365285963, disc_loss = 0.0005179212702482584
Trained batch 525 in epoch 4, gen_loss = 1.4711616313502816, disc_loss = 0.0005176102572356213
Trained batch 526 in epoch 4, gen_loss = 1.4711827075911201, disc_loss = 0.0005173439085876757
Trained batch 527 in epoch 4, gen_loss = 1.4711815942869042, disc_loss = 0.0005171512926388074
Trained batch 528 in epoch 4, gen_loss = 1.4714075888037006, disc_loss = 0.0005170760475673901
Trained batch 529 in epoch 4, gen_loss = 1.4714690253419695, disc_loss = 0.0005172282714893128
Trained batch 530 in epoch 4, gen_loss = 1.471603149748118, disc_loss = 0.0005175690145276508
Trained batch 531 in epoch 4, gen_loss = 1.471502812957405, disc_loss = 0.0005179081021661912
Trained batch 532 in epoch 4, gen_loss = 1.471505393901417, disc_loss = 0.0005181714264771204
Trained batch 533 in epoch 4, gen_loss = 1.4713864411307631, disc_loss = 0.0005182723965681566
Trained batch 534 in epoch 4, gen_loss = 1.4714068185503237, disc_loss = 0.0005184727835699603
Trained batch 535 in epoch 4, gen_loss = 1.471231469022694, disc_loss = 0.0005188359955083336
Trained batch 536 in epoch 4, gen_loss = 1.4712871765957198, disc_loss = 0.0005189945756651121
Trained batch 537 in epoch 4, gen_loss = 1.4712062739528244, disc_loss = 0.0005188297243294614
Trained batch 538 in epoch 4, gen_loss = 1.4712416207856724, disc_loss = 0.0005185654699406716
Trained batch 539 in epoch 4, gen_loss = 1.4712566055633403, disc_loss = 0.0005183179698953474
Trained batch 540 in epoch 4, gen_loss = 1.4711729726597473, disc_loss = 0.0005181271389390165
Trained batch 541 in epoch 4, gen_loss = 1.4710840670824932, disc_loss = 0.0005180654443527238
Trained batch 542 in epoch 4, gen_loss = 1.4710868873648881, disc_loss = 0.0005179811948670236
Trained batch 543 in epoch 4, gen_loss = 1.4709527556072264, disc_loss = 0.0005177847450635026
Trained batch 544 in epoch 4, gen_loss = 1.4708469139326603, disc_loss = 0.0005175791185246695
Trained batch 545 in epoch 4, gen_loss = 1.471069329824203, disc_loss = 0.000517776275596039
Trained batch 546 in epoch 4, gen_loss = 1.4712010138213525, disc_loss = 0.000518596498721315
Trained batch 547 in epoch 4, gen_loss = 1.4711721104426976, disc_loss = 0.000519623462855136
Trained batch 548 in epoch 4, gen_loss = 1.471197036663257, disc_loss = 0.00052052943030871
Trained batch 549 in epoch 4, gen_loss = 1.471060972213745, disc_loss = 0.0005210163568104194
Trained batch 550 in epoch 4, gen_loss = 1.4711069268886061, disc_loss = 0.0005210538352704429
Trained batch 551 in epoch 4, gen_loss = 1.4710980118184849, disc_loss = 0.0005209092703517999
Trained batch 552 in epoch 4, gen_loss = 1.4712067204401247, disc_loss = 0.0005207661217542543
Trained batch 553 in epoch 4, gen_loss = 1.4710494299227581, disc_loss = 0.0005207082573664862
Trained batch 554 in epoch 4, gen_loss = 1.4710473640544994, disc_loss = 0.0005208102604982586
Trained batch 555 in epoch 4, gen_loss = 1.4710423414655727, disc_loss = 0.0005209450796853731
Trained batch 556 in epoch 4, gen_loss = 1.4711540192633172, disc_loss = 0.0005210390733199652
Trained batch 557 in epoch 4, gen_loss = 1.4711684441481012, disc_loss = 0.0005210681799544675
Trained batch 558 in epoch 4, gen_loss = 1.471137171354618, disc_loss = 0.0005210022990173645
Trained batch 559 in epoch 4, gen_loss = 1.4712402816329684, disc_loss = 0.0005208475457558441
Trained batch 560 in epoch 4, gen_loss = 1.4712799734397792, disc_loss = 0.0005207876846548701
Trained batch 561 in epoch 4, gen_loss = 1.4713184494140734, disc_loss = 0.000520701587725898
Trained batch 562 in epoch 4, gen_loss = 1.4712655364302505, disc_loss = 0.0005202340070165687
Trained batch 563 in epoch 4, gen_loss = 1.4712352420844086, disc_loss = 0.0005195213082689851
Trained batch 564 in epoch 4, gen_loss = 1.4711343058442647, disc_loss = 0.0005188027033129031
Trained batch 565 in epoch 4, gen_loss = 1.470988154621933, disc_loss = 0.0005182032698091587
Trained batch 566 in epoch 4, gen_loss = 1.4709178461599601, disc_loss = 0.0005175879194491134
Trained batch 567 in epoch 4, gen_loss = 1.4708743829962234, disc_loss = 0.0005169784719174445
Trained batch 568 in epoch 4, gen_loss = 1.4709478637665143, disc_loss = 0.0005163202840584839
Trained batch 569 in epoch 4, gen_loss = 1.4709552562027646, disc_loss = 0.0005156152479844821
Trained batch 570 in epoch 4, gen_loss = 1.4710727030258046, disc_loss = 0.0005150654958418347
Trained batch 571 in epoch 4, gen_loss = 1.4711237835300552, disc_loss = 0.000514565980659433
Trained batch 572 in epoch 4, gen_loss = 1.4711697032938453, disc_loss = 0.0005140412540132761
Trained batch 573 in epoch 4, gen_loss = 1.4710713020600508, disc_loss = 0.0005134528714052859
Trained batch 574 in epoch 4, gen_loss = 1.4710376797551694, disc_loss = 0.0005127844623158402
Trained batch 575 in epoch 4, gen_loss = 1.4709456474002864, disc_loss = 0.0005120648736086272
Trained batch 576 in epoch 4, gen_loss = 1.4709919947272156, disc_loss = 0.0005114163844247971
Trained batch 577 in epoch 4, gen_loss = 1.4709716278376463, disc_loss = 0.0005108663263007843
Trained batch 578 in epoch 4, gen_loss = 1.4709173898005115, disc_loss = 0.0005103387065618443
Trained batch 579 in epoch 4, gen_loss = 1.4709245474174104, disc_loss = 0.0005098936759544625
Trained batch 580 in epoch 4, gen_loss = 1.47092392440507, disc_loss = 0.0005094896917300109
Trained batch 581 in epoch 4, gen_loss = 1.4708218150532122, disc_loss = 0.0005091326002565035
Trained batch 582 in epoch 4, gen_loss = 1.4708048892471026, disc_loss = 0.0005088792289510381
Trained batch 583 in epoch 4, gen_loss = 1.4707457929441374, disc_loss = 0.000508709888953029
Trained batch 584 in epoch 4, gen_loss = 1.4708012150903034, disc_loss = 0.0005085806997018293
Trained batch 585 in epoch 4, gen_loss = 1.4707451843157564, disc_loss = 0.0005084521245522665
Trained batch 586 in epoch 4, gen_loss = 1.4708675154226196, disc_loss = 0.0005082186543198463
Trained batch 587 in epoch 4, gen_loss = 1.4709120400908853, disc_loss = 0.0005079142393901283
Trained batch 588 in epoch 4, gen_loss = 1.4709947647586945, disc_loss = 0.0005076249769440352
Trained batch 589 in epoch 4, gen_loss = 1.4711536425655172, disc_loss = 0.0005072835866747605
Trained batch 590 in epoch 4, gen_loss = 1.47122148370178, disc_loss = 0.000506808918893598
Trained batch 591 in epoch 4, gen_loss = 1.4712276583587802, disc_loss = 0.0005062578662373935
Trained batch 592 in epoch 4, gen_loss = 1.471131596758233, disc_loss = 0.0005057144241371588
Trained batch 593 in epoch 4, gen_loss = 1.4710671151125874, disc_loss = 0.0005053003800952351
Trained batch 594 in epoch 4, gen_loss = 1.471018948474852, disc_loss = 0.0005050185809186816
Trained batch 595 in epoch 4, gen_loss = 1.4710724755821611, disc_loss = 0.0005049442664210118
Trained batch 596 in epoch 4, gen_loss = 1.4710876899747993, disc_loss = 0.0005050424943894336
Trained batch 597 in epoch 4, gen_loss = 1.4710236123971716, disc_loss = 0.0005053529870972999
Trained batch 598 in epoch 4, gen_loss = 1.4710022955386588, disc_loss = 0.0005057994566473197
Trained batch 599 in epoch 4, gen_loss = 1.4710479968786239, disc_loss = 0.0005062256347567503
Trained batch 600 in epoch 4, gen_loss = 1.471028137326042, disc_loss = 0.0005065031781640196
Trained batch 601 in epoch 4, gen_loss = 1.4709790150984576, disc_loss = 0.0005065635734136592
Trained batch 602 in epoch 4, gen_loss = 1.4708907274069083, disc_loss = 0.0005066250482402088
Trained batch 603 in epoch 4, gen_loss = 1.470868465718844, disc_loss = 0.0005068491399235174
Trained batch 604 in epoch 4, gen_loss = 1.4708303106717826, disc_loss = 0.0005072626304136366
Trained batch 605 in epoch 4, gen_loss = 1.4706998498919774, disc_loss = 0.0005078275067903288
Trained batch 606 in epoch 4, gen_loss = 1.47066702029654, disc_loss = 0.000508372242836442
Trained batch 607 in epoch 4, gen_loss = 1.4704593837653335, disc_loss = 0.0005088887390732117
Trained batch 608 in epoch 4, gen_loss = 1.470468189328762, disc_loss = 0.0005095651197425557
Trained batch 609 in epoch 4, gen_loss = 1.4704997987043662, disc_loss = 0.0005104334723060286
Trained batch 610 in epoch 4, gen_loss = 1.4705823425770586, disc_loss = 0.0005113399208435879
Trained batch 611 in epoch 4, gen_loss = 1.4706216261667364, disc_loss = 0.0005122164286410755
Trained batch 612 in epoch 4, gen_loss = 1.4706231822391902, disc_loss = 0.0005129153388279846
Trained batch 613 in epoch 4, gen_loss = 1.4706661741974298, disc_loss = 0.0005133445836939805
Trained batch 614 in epoch 4, gen_loss = 1.4708054143238842, disc_loss = 0.0005136348523518518
Trained batch 615 in epoch 4, gen_loss = 1.4707439166384857, disc_loss = 0.0005139453596475741
Trained batch 616 in epoch 4, gen_loss = 1.4707814099529768, disc_loss = 0.0005142661390436105
Trained batch 617 in epoch 4, gen_loss = 1.4706703904763008, disc_loss = 0.000514458627728719
Trained batch 618 in epoch 4, gen_loss = 1.4706897716337337, disc_loss = 0.0005146024500266032
Trained batch 619 in epoch 4, gen_loss = 1.470570570038211, disc_loss = 0.0005145858600195836
Trained batch 620 in epoch 4, gen_loss = 1.4704716101936672, disc_loss = 0.0005144620784518051
Trained batch 621 in epoch 4, gen_loss = 1.4704530764239394, disc_loss = 0.0005143022601283268
Trained batch 622 in epoch 4, gen_loss = 1.4703464087092857, disc_loss = 0.0005142636800766549
Trained batch 623 in epoch 4, gen_loss = 1.4705667873987784, disc_loss = 0.0005153262849233168
Trained batch 624 in epoch 4, gen_loss = 1.4706289060592652, disc_loss = 0.000517665998369921
Trained batch 625 in epoch 4, gen_loss = 1.470530342941467, disc_loss = 0.0005210604841048947
Trained batch 626 in epoch 4, gen_loss = 1.4705880777687548, disc_loss = 0.0005244534913799725
Trained batch 627 in epoch 4, gen_loss = 1.4704674040056338, disc_loss = 0.0005272281806546918
Trained batch 628 in epoch 4, gen_loss = 1.4705190849986478, disc_loss = 0.0005292206596874999
Trained batch 629 in epoch 4, gen_loss = 1.4703670337086632, disc_loss = 0.0005306040087556799
Trained batch 630 in epoch 4, gen_loss = 1.470475610009086, disc_loss = 0.0005314752291567902
Trained batch 631 in epoch 4, gen_loss = 1.470409796207766, disc_loss = 0.000531928753141845
Trained batch 632 in epoch 4, gen_loss = 1.4704900914082217, disc_loss = 0.0005321129337310869
Trained batch 633 in epoch 4, gen_loss = 1.470486837794728, disc_loss = 0.0005320148103418194
Trained batch 634 in epoch 4, gen_loss = 1.4704684987781556, disc_loss = 0.0005317211815813285
Trained batch 635 in epoch 4, gen_loss = 1.4703931397986862, disc_loss = 0.000531359320629916
Trained batch 636 in epoch 4, gen_loss = 1.4703669059594722, disc_loss = 0.0005309730647699257
Trained batch 637 in epoch 4, gen_loss = 1.4703407253964942, disc_loss = 0.000530573335309899
Trained batch 638 in epoch 4, gen_loss = 1.470315327293623, disc_loss = 0.0005301912977541097
Trained batch 639 in epoch 4, gen_loss = 1.4703173402696847, disc_loss = 0.0005298070336834826
Trained batch 640 in epoch 4, gen_loss = 1.4703728072170905, disc_loss = 0.0005293132029047894
Trained batch 641 in epoch 4, gen_loss = 1.4704973172175921, disc_loss = 0.000528775425400709
Trained batch 642 in epoch 4, gen_loss = 1.470510612750313, disc_loss = 0.0005282469762305071
Trained batch 643 in epoch 4, gen_loss = 1.4703734095052163, disc_loss = 0.00052787470317441
Trained batch 644 in epoch 4, gen_loss = 1.4704512366952822, disc_loss = 0.0005277363247623443
Trained batch 645 in epoch 4, gen_loss = 1.4704407030952973, disc_loss = 0.0005276700793061767
Trained batch 646 in epoch 4, gen_loss = 1.4703921997197076, disc_loss = 0.0005276564806709649
Trained batch 647 in epoch 4, gen_loss = 1.4704675889677472, disc_loss = 0.0005276189908671105
Trained batch 648 in epoch 4, gen_loss = 1.4704869449230482, disc_loss = 0.0005275216160656185
Trained batch 649 in epoch 4, gen_loss = 1.4704334279207083, disc_loss = 0.0005272736405626907
Trained batch 650 in epoch 4, gen_loss = 1.4704307013759232, disc_loss = 0.000527008088480752
Trained batch 651 in epoch 4, gen_loss = 1.470523845381532, disc_loss = 0.000526761826685472
Trained batch 652 in epoch 4, gen_loss = 1.4705988342144953, disc_loss = 0.0005265392804108125
Trained batch 653 in epoch 4, gen_loss = 1.4706528937780163, disc_loss = 0.0005262559172440148
Trained batch 654 in epoch 4, gen_loss = 1.4706724081330627, disc_loss = 0.0005258961847182612
Trained batch 655 in epoch 4, gen_loss = 1.470639222823992, disc_loss = 0.0005255119727934936
Trained batch 656 in epoch 4, gen_loss = 1.4707651896745284, disc_loss = 0.000525048465880936
Trained batch 657 in epoch 4, gen_loss = 1.4707884752279357, disc_loss = 0.0005244368699192258
Trained batch 658 in epoch 4, gen_loss = 1.4706996017233194, disc_loss = 0.0005238125427343956
Trained batch 659 in epoch 4, gen_loss = 1.4705353019815504, disc_loss = 0.0005232157028799658
Trained batch 660 in epoch 4, gen_loss = 1.4707150361902235, disc_loss = 0.0005227203572415691
Trained batch 661 in epoch 4, gen_loss = 1.470677594763995, disc_loss = 0.0005222385989986901
Trained batch 662 in epoch 4, gen_loss = 1.470702252416769, disc_loss = 0.0005217737149712166
Trained batch 663 in epoch 4, gen_loss = 1.4705659285726318, disc_loss = 0.0005213562635507985
Trained batch 664 in epoch 4, gen_loss = 1.4705640947012077, disc_loss = 0.000521113664619502
Trained batch 665 in epoch 4, gen_loss = 1.4706239825612433, disc_loss = 0.000521042353628562
Trained batch 666 in epoch 4, gen_loss = 1.4704578966572546, disc_loss = 0.0005209126878192758
Trained batch 667 in epoch 4, gen_loss = 1.4704032777669187, disc_loss = 0.0005206615700074339
Trained batch 668 in epoch 4, gen_loss = 1.4704725182822644, disc_loss = 0.0005203262907777417
Trained batch 669 in epoch 4, gen_loss = 1.4704712036830276, disc_loss = 0.0005198924634679491
Trained batch 670 in epoch 4, gen_loss = 1.4703827911624254, disc_loss = 0.0005193957552021813
Trained batch 671 in epoch 4, gen_loss = 1.4704027339106513, disc_loss = 0.0005188453610896561
Trained batch 672 in epoch 4, gen_loss = 1.470470757222282, disc_loss = 0.0005183199336870787
Trained batch 673 in epoch 4, gen_loss = 1.470485435218415, disc_loss = 0.0005177881228557037
Trained batch 674 in epoch 4, gen_loss = 1.4705914156525224, disc_loss = 0.0005172318041527264
Trained batch 675 in epoch 4, gen_loss = 1.470607902700379, disc_loss = 0.0005166477439855329
Trained batch 676 in epoch 4, gen_loss = 1.4705873903883084, disc_loss = 0.0005161023342343455
Trained batch 677 in epoch 4, gen_loss = 1.4705024257873716, disc_loss = 0.000515577020410776
Trained batch 678 in epoch 4, gen_loss = 1.4705995916442423, disc_loss = 0.0005150695681433599
Trained batch 679 in epoch 4, gen_loss = 1.470589509956977, disc_loss = 0.0005146021835838945
Trained batch 680 in epoch 4, gen_loss = 1.4706569594958805, disc_loss = 0.0005141584168222635
Trained batch 681 in epoch 4, gen_loss = 1.4706924152164516, disc_loss = 0.0005136865540215563
Trained batch 682 in epoch 4, gen_loss = 1.470698401484622, disc_loss = 0.000513181387007323
Trained batch 683 in epoch 4, gen_loss = 1.4707950057342039, disc_loss = 0.000512636118097968
Trained batch 684 in epoch 4, gen_loss = 1.470741468624477, disc_loss = 0.0005120389754386843
Trained batch 685 in epoch 4, gen_loss = 1.4708200491552104, disc_loss = 0.000511426362325692
Trained batch 686 in epoch 4, gen_loss = 1.4708503814416856, disc_loss = 0.0005108357488999233
Trained batch 687 in epoch 4, gen_loss = 1.470735675547012, disc_loss = 0.0005102770940560054
Trained batch 688 in epoch 4, gen_loss = 1.4707440620582923, disc_loss = 0.0005097592029269752
Trained batch 689 in epoch 4, gen_loss = 1.4707126482673314, disc_loss = 0.0005093061720970951
Trained batch 690 in epoch 4, gen_loss = 1.4707487607657823, disc_loss = 0.000508899617453804
Trained batch 691 in epoch 4, gen_loss = 1.470737283801757, disc_loss = 0.0005084795316836374
Trained batch 692 in epoch 4, gen_loss = 1.4707845105409278, disc_loss = 0.0005080677552701714
Trained batch 693 in epoch 4, gen_loss = 1.470773981180933, disc_loss = 0.0005076452518960257
Trained batch 694 in epoch 4, gen_loss = 1.4707474302044876, disc_loss = 0.0005072177985972865
Trained batch 695 in epoch 4, gen_loss = 1.470719408372353, disc_loss = 0.0005067446019119803
Trained batch 696 in epoch 4, gen_loss = 1.4707204276212147, disc_loss = 0.0005062645639194686
Trained batch 697 in epoch 4, gen_loss = 1.4706828621533676, disc_loss = 0.0005058577785986932
Trained batch 698 in epoch 4, gen_loss = 1.470619965349997, disc_loss = 0.0005055373571283492
Trained batch 699 in epoch 4, gen_loss = 1.4706752382005963, disc_loss = 0.0005052663172578572
Trained batch 700 in epoch 4, gen_loss = 1.4707116065453871, disc_loss = 0.0005052897991720831
Trained batch 701 in epoch 4, gen_loss = 1.4707204597628014, disc_loss = 0.0005058638523568259
Trained batch 702 in epoch 4, gen_loss = 1.4707763539269503, disc_loss = 0.000506776479027495
Trained batch 703 in epoch 4, gen_loss = 1.4708507672290911, disc_loss = 0.0005078794555298704
Trained batch 704 in epoch 4, gen_loss = 1.4708271256575347, disc_loss = 0.0005088241000953692
Trained batch 705 in epoch 4, gen_loss = 1.4709178911727818, disc_loss = 0.0005094836236893862
Trained batch 706 in epoch 4, gen_loss = 1.4708072965519432, disc_loss = 0.0005099489256858831
Trained batch 707 in epoch 4, gen_loss = 1.4709439861909144, disc_loss = 0.0005103694045232836
Trained batch 708 in epoch 4, gen_loss = 1.4708816499064437, disc_loss = 0.000510940110721075
Trained batch 709 in epoch 4, gen_loss = 1.4709301187958517, disc_loss = 0.000511694298179912
Trained batch 710 in epoch 4, gen_loss = 1.4708985866541266, disc_loss = 0.0005126884073276419
Trained batch 711 in epoch 4, gen_loss = 1.4708529593569508, disc_loss = 0.0005134845663367619
Trained batch 712 in epoch 4, gen_loss = 1.4708177732384724, disc_loss = 0.0005140064083295124
Trained batch 713 in epoch 4, gen_loss = 1.4708066627758891, disc_loss = 0.0005143320834650906
Trained batch 714 in epoch 4, gen_loss = 1.4707660138190208, disc_loss = 0.0005144785453444933
Trained batch 715 in epoch 4, gen_loss = 1.470675339911903, disc_loss = 0.0005145617968428167
Trained batch 716 in epoch 4, gen_loss = 1.4706284677300658, disc_loss = 0.0005145391924329481
Trained batch 717 in epoch 4, gen_loss = 1.4706473805446147, disc_loss = 0.0005144293516164796
Trained batch 718 in epoch 4, gen_loss = 1.470626836360247, disc_loss = 0.0005142656067902448
Trained batch 719 in epoch 4, gen_loss = 1.4705775345365206, disc_loss = 0.0005140329268518447
Trained batch 720 in epoch 4, gen_loss = 1.470561345804085, disc_loss = 0.0005137063389700216
Trained batch 721 in epoch 4, gen_loss = 1.4705000707977696, disc_loss = 0.000513333068985474
Trained batch 722 in epoch 4, gen_loss = 1.470551243461514, disc_loss = 0.0005129511363209865
Trained batch 723 in epoch 4, gen_loss = 1.4704727156715498, disc_loss = 0.0005126012346815982
Trained batch 724 in epoch 4, gen_loss = 1.470494678267117, disc_loss = 0.0005122692732076193
Trained batch 725 in epoch 4, gen_loss = 1.4704415056002698, disc_loss = 0.0005119668081538757
Trained batch 726 in epoch 4, gen_loss = 1.4704463188389145, disc_loss = 0.0005116726344187412
Trained batch 727 in epoch 4, gen_loss = 1.4703421129302665, disc_loss = 0.0005113863790629094
Trained batch 728 in epoch 4, gen_loss = 1.4704859351588537, disc_loss = 0.0005111175449373423
Trained batch 729 in epoch 4, gen_loss = 1.4704837330400127, disc_loss = 0.00051070651368793
Trained batch 730 in epoch 4, gen_loss = 1.4705046611021384, disc_loss = 0.0005102300433457603
Trained batch 731 in epoch 4, gen_loss = 1.470458434579151, disc_loss = 0.0005098049856076346
Trained batch 732 in epoch 4, gen_loss = 1.4704942934184575, disc_loss = 0.0005094454051251111
Trained batch 733 in epoch 4, gen_loss = 1.4705270928323106, disc_loss = 0.0005092784374873332
Trained batch 734 in epoch 4, gen_loss = 1.4705170375149266, disc_loss = 0.000509319150543987
Trained batch 735 in epoch 4, gen_loss = 1.4704781043464723, disc_loss = 0.0005094755048325485
Trained batch 736 in epoch 4, gen_loss = 1.4704865188093974, disc_loss = 0.0005096861928297975
Trained batch 737 in epoch 4, gen_loss = 1.4704216318078804, disc_loss = 0.0005099578709257981
Trained batch 738 in epoch 4, gen_loss = 1.4704084583483787, disc_loss = 0.0005103259080797573
Trained batch 739 in epoch 4, gen_loss = 1.47028066757563, disc_loss = 0.0005107734387550138
Trained batch 740 in epoch 4, gen_loss = 1.4703932870254826, disc_loss = 0.0005112110310780543
Trained batch 741 in epoch 4, gen_loss = 1.4703996849831225, disc_loss = 0.0005112947257995955
Trained batch 742 in epoch 4, gen_loss = 1.4703583003374, disc_loss = 0.0005112016021985683
Trained batch 743 in epoch 4, gen_loss = 1.470316038336805, disc_loss = 0.0005110908828052049
Trained batch 744 in epoch 4, gen_loss = 1.4702549374343565, disc_loss = 0.0005109679031431138
Trained batch 745 in epoch 4, gen_loss = 1.4702657951746165, disc_loss = 0.0005110099212144472
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 1.415205955505371, disc_loss = 0.0006987269152887166
Trained batch 1 in epoch 5, gen_loss = 1.4147006273269653, disc_loss = 0.0008204994082916528
Trained batch 2 in epoch 5, gen_loss = 1.4390328725179036, disc_loss = 0.00087388502045845
Trained batch 3 in epoch 5, gen_loss = 1.444375991821289, disc_loss = 0.0008474634523736313
Trained batch 4 in epoch 5, gen_loss = 1.4350951194763184, disc_loss = 0.0007835588534362614
Trained batch 5 in epoch 5, gen_loss = 1.4270549813906352, disc_loss = 0.00072730141497838
Trained batch 6 in epoch 5, gen_loss = 1.4346716233662196, disc_loss = 0.0006956494928869818
Trained batch 7 in epoch 5, gen_loss = 1.4345566779375076, disc_loss = 0.0006662787527602632
Trained batch 8 in epoch 5, gen_loss = 1.4305127726660833, disc_loss = 0.0006451015198965453
Trained batch 9 in epoch 5, gen_loss = 1.4229835629463197, disc_loss = 0.000636905021383427
Trained batch 10 in epoch 5, gen_loss = 1.4288506399501453, disc_loss = 0.0006391198337289759
Trained batch 11 in epoch 5, gen_loss = 1.4309638142585754, disc_loss = 0.0006377273311954923
Trained batch 12 in epoch 5, gen_loss = 1.436567865885221, disc_loss = 0.0006322415541105259
Trained batch 13 in epoch 5, gen_loss = 1.440751211983817, disc_loss = 0.0006313821546167933
Trained batch 14 in epoch 5, gen_loss = 1.4389797528584798, disc_loss = 0.0006369615342312803
Trained batch 15 in epoch 5, gen_loss = 1.4440147280693054, disc_loss = 0.0006441785353672458
Trained batch 16 in epoch 5, gen_loss = 1.4421825899797327, disc_loss = 0.0006404796680298579
Trained batch 17 in epoch 5, gen_loss = 1.442724174923367, disc_loss = 0.0006274188846065146
Trained batch 18 in epoch 5, gen_loss = 1.444289345490305, disc_loss = 0.0006115378285022942
Trained batch 19 in epoch 5, gen_loss = 1.444810116291046, disc_loss = 0.000596113852225244
Trained batch 20 in epoch 5, gen_loss = 1.4474491732461112, disc_loss = 0.0005845771132347485
Trained batch 21 in epoch 5, gen_loss = 1.4456826881928877, disc_loss = 0.0005786687701898204
Trained batch 22 in epoch 5, gen_loss = 1.4456596789152727, disc_loss = 0.000571544029061561
Trained batch 23 in epoch 5, gen_loss = 1.4449852605660756, disc_loss = 0.0005629670983277416
Trained batch 24 in epoch 5, gen_loss = 1.444093837738037, disc_loss = 0.000554698167834431
Trained batch 25 in epoch 5, gen_loss = 1.4435804715523353, disc_loss = 0.0005477899428045091
Trained batch 26 in epoch 5, gen_loss = 1.4445579670093678, disc_loss = 0.0005465662721285804
Trained batch 27 in epoch 5, gen_loss = 1.4480596269880022, disc_loss = 0.000546647521592344
Trained batch 28 in epoch 5, gen_loss = 1.4487982412864422, disc_loss = 0.0005476232648200901
Trained batch 29 in epoch 5, gen_loss = 1.450168748696645, disc_loss = 0.0005482219382732486
Trained batch 30 in epoch 5, gen_loss = 1.4477204738124725, disc_loss = 0.0005466831095081063
Trained batch 31 in epoch 5, gen_loss = 1.449854027479887, disc_loss = 0.0005450537892102147
Trained batch 32 in epoch 5, gen_loss = 1.4472501819783992, disc_loss = 0.000543600515370737
Trained batch 33 in epoch 5, gen_loss = 1.4476955322658314, disc_loss = 0.0005446472812978112
Trained batch 34 in epoch 5, gen_loss = 1.4454992021833146, disc_loss = 0.0005448204157541373
Trained batch 35 in epoch 5, gen_loss = 1.4457039369477167, disc_loss = 0.0005431072810703578
Trained batch 36 in epoch 5, gen_loss = 1.4445257670170553, disc_loss = 0.0005389982858056052
Trained batch 37 in epoch 5, gen_loss = 1.4450429019175077, disc_loss = 0.000533605980117021
Trained batch 38 in epoch 5, gen_loss = 1.4441316922505696, disc_loss = 0.0005279004496211807
Trained batch 39 in epoch 5, gen_loss = 1.4446146696805955, disc_loss = 0.0005224749831540976
Trained batch 40 in epoch 5, gen_loss = 1.444042476212106, disc_loss = 0.0005180161877921442
Trained batch 41 in epoch 5, gen_loss = 1.447511619045621, disc_loss = 0.0005167293171065726
Trained batch 42 in epoch 5, gen_loss = 1.4472266130669171, disc_loss = 0.0005217929692873948
Trained batch 43 in epoch 5, gen_loss = 1.448305444283919, disc_loss = 0.0005324568152321841
Trained batch 44 in epoch 5, gen_loss = 1.4493240621354846, disc_loss = 0.0005400363291199837
Trained batch 45 in epoch 5, gen_loss = 1.4502088816269585, disc_loss = 0.0005455901251559186
Trained batch 46 in epoch 5, gen_loss = 1.4499641530057217, disc_loss = 0.0005500726414190486
Trained batch 47 in epoch 5, gen_loss = 1.4506997565428417, disc_loss = 0.0005530616484368996
Trained batch 48 in epoch 5, gen_loss = 1.4501896829021221, disc_loss = 0.0005559783953964254
Trained batch 49 in epoch 5, gen_loss = 1.4518330740928649, disc_loss = 0.0005625264265108854
Trained batch 50 in epoch 5, gen_loss = 1.452382992295658, disc_loss = 0.0005735112411225689
Trained batch 51 in epoch 5, gen_loss = 1.4517290385869832, disc_loss = 0.000584747674740636
Trained batch 52 in epoch 5, gen_loss = 1.4510339543504536, disc_loss = 0.0005919498760464057
Trained batch 53 in epoch 5, gen_loss = 1.4511443773905437, disc_loss = 0.0005968808481055829
Trained batch 54 in epoch 5, gen_loss = 1.4508587988940151, disc_loss = 0.0006000129632990469
Trained batch 55 in epoch 5, gen_loss = 1.4512639790773392, disc_loss = 0.0006006545227137394
Trained batch 56 in epoch 5, gen_loss = 1.4517028896432174, disc_loss = 0.0005997216141080124
Trained batch 57 in epoch 5, gen_loss = 1.4518376444948131, disc_loss = 0.0005980157815241095
Trained batch 58 in epoch 5, gen_loss = 1.451429579217555, disc_loss = 0.0005960450631021758
Trained batch 59 in epoch 5, gen_loss = 1.4518187244733174, disc_loss = 0.000593520811041041
Trained batch 60 in epoch 5, gen_loss = 1.4515625707438735, disc_loss = 0.0005912279369515656
Trained batch 61 in epoch 5, gen_loss = 1.4526451306958352, disc_loss = 0.0005890652373050069
Trained batch 62 in epoch 5, gen_loss = 1.4533467160330877, disc_loss = 0.0005862475608453332
Trained batch 63 in epoch 5, gen_loss = 1.4539544191211462, disc_loss = 0.0005836686941620428
Trained batch 64 in epoch 5, gen_loss = 1.4539493065613966, disc_loss = 0.0005828222304654236
Trained batch 65 in epoch 5, gen_loss = 1.4563290151682766, disc_loss = 0.0005832712481743797
Trained batch 66 in epoch 5, gen_loss = 1.4559294625894348, disc_loss = 0.000583235312552094
Trained batch 67 in epoch 5, gen_loss = 1.4559043698451097, disc_loss = 0.000582733194117763
Trained batch 68 in epoch 5, gen_loss = 1.4562622274177661, disc_loss = 0.0005820631024265742
Trained batch 69 in epoch 5, gen_loss = 1.4571116719927106, disc_loss = 0.0005805484110689057
Trained batch 70 in epoch 5, gen_loss = 1.4567554651851384, disc_loss = 0.00057864178162278
Trained batch 71 in epoch 5, gen_loss = 1.4570398065778944, disc_loss = 0.0005756022526636823
Trained batch 72 in epoch 5, gen_loss = 1.4582786298777959, disc_loss = 0.0005725471144191257
Trained batch 73 in epoch 5, gen_loss = 1.4580430533434894, disc_loss = 0.0005708731639331106
Trained batch 74 in epoch 5, gen_loss = 1.4593257967631021, disc_loss = 0.0005708811963753154
Trained batch 75 in epoch 5, gen_loss = 1.4607803947047184, disc_loss = 0.0005712532212400172
Trained batch 76 in epoch 5, gen_loss = 1.4613520201150474, disc_loss = 0.0005712346086889361
Trained batch 77 in epoch 5, gen_loss = 1.4610951466438098, disc_loss = 0.0005716470011229364
Trained batch 78 in epoch 5, gen_loss = 1.460766765135753, disc_loss = 0.0005727117741922553
Trained batch 79 in epoch 5, gen_loss = 1.4591584622859954, disc_loss = 0.000575170313459239
Trained batch 80 in epoch 5, gen_loss = 1.4592454830805461, disc_loss = 0.0005817195759183601
Trained batch 81 in epoch 5, gen_loss = 1.4596436067325314, disc_loss = 0.0005900238540517621
Trained batch 82 in epoch 5, gen_loss = 1.459655024919165, disc_loss = 0.0005953590387719717
Trained batch 83 in epoch 5, gen_loss = 1.4593925234817324, disc_loss = 0.0005979680125684743
Trained batch 84 in epoch 5, gen_loss = 1.4600972975001616, disc_loss = 0.000598528072826893
Trained batch 85 in epoch 5, gen_loss = 1.4600271291511004, disc_loss = 0.0005977410930723255
Trained batch 86 in epoch 5, gen_loss = 1.4603024104545856, disc_loss = 0.0005965011676735962
Trained batch 87 in epoch 5, gen_loss = 1.4597210572524504, disc_loss = 0.0005945469135688406
Trained batch 88 in epoch 5, gen_loss = 1.460999833064133, disc_loss = 0.0005931532729202567
Trained batch 89 in epoch 5, gen_loss = 1.4605007741186353, disc_loss = 0.0005918003091614487
Trained batch 90 in epoch 5, gen_loss = 1.4605523583653208, disc_loss = 0.0005903176232215508
Trained batch 91 in epoch 5, gen_loss = 1.4598060302112414, disc_loss = 0.0005885323553229682
Trained batch 92 in epoch 5, gen_loss = 1.4595255569745136, disc_loss = 0.0005865407036116687
Trained batch 93 in epoch 5, gen_loss = 1.4593725737105026, disc_loss = 0.0005839059892249235
Trained batch 94 in epoch 5, gen_loss = 1.4597067506689774, disc_loss = 0.0005812131683342158
Trained batch 95 in epoch 5, gen_loss = 1.4597778357565403, disc_loss = 0.0005784412993913671
Trained batch 96 in epoch 5, gen_loss = 1.4592780513861745, disc_loss = 0.0005758324501191065
Trained batch 97 in epoch 5, gen_loss = 1.460558797631945, disc_loss = 0.0005734517311496774
Trained batch 98 in epoch 5, gen_loss = 1.4604233551507044, disc_loss = 0.0005701183039528045
Trained batch 99 in epoch 5, gen_loss = 1.4609599828720092, disc_loss = 0.0005663119231758174
Trained batch 100 in epoch 5, gen_loss = 1.4611501292426987, disc_loss = 0.0005627676087032801
Trained batch 101 in epoch 5, gen_loss = 1.461038934249504, disc_loss = 0.0005597199749044033
Trained batch 102 in epoch 5, gen_loss = 1.4610379529230804, disc_loss = 0.000557117570317079
Trained batch 103 in epoch 5, gen_loss = 1.4611041224919832, disc_loss = 0.0005541520293683369
Trained batch 104 in epoch 5, gen_loss = 1.4609399943124681, disc_loss = 0.0005514686792767385
Trained batch 105 in epoch 5, gen_loss = 1.460789849173348, disc_loss = 0.000548565467157322
Trained batch 106 in epoch 5, gen_loss = 1.4603483175562921, disc_loss = 0.0005451708948555202
Trained batch 107 in epoch 5, gen_loss = 1.4603086102891851, disc_loss = 0.0005420965786066113
Trained batch 108 in epoch 5, gen_loss = 1.4606180792554804, disc_loss = 0.0005403088684484295
Trained batch 109 in epoch 5, gen_loss = 1.460238976912065, disc_loss = 0.0005403021197046407
Trained batch 110 in epoch 5, gen_loss = 1.4598607909572017, disc_loss = 0.000542010121395694
Trained batch 111 in epoch 5, gen_loss = 1.4599055701068469, disc_loss = 0.0005441514487236938
Trained batch 112 in epoch 5, gen_loss = 1.459749483429225, disc_loss = 0.0005447834264487028
Trained batch 113 in epoch 5, gen_loss = 1.4592562913894653, disc_loss = 0.0005442699062098798
Trained batch 114 in epoch 5, gen_loss = 1.4588172311368195, disc_loss = 0.0005434909977180802
Trained batch 115 in epoch 5, gen_loss = 1.4583490922533233, disc_loss = 0.0005431010223250708
Trained batch 116 in epoch 5, gen_loss = 1.4580038266304212, disc_loss = 0.0005441554827002697
Trained batch 117 in epoch 5, gen_loss = 1.457882770037247, disc_loss = 0.0005459272745657333
Trained batch 118 in epoch 5, gen_loss = 1.4583199064270789, disc_loss = 0.0005475958846431194
Trained batch 119 in epoch 5, gen_loss = 1.458403503894806, disc_loss = 0.0005483718244552923
Trained batch 120 in epoch 5, gen_loss = 1.4586359094982304, disc_loss = 0.0005488248459209711
Trained batch 121 in epoch 5, gen_loss = 1.4581491204558825, disc_loss = 0.000549731767530263
Trained batch 122 in epoch 5, gen_loss = 1.4583093005467236, disc_loss = 0.0005512902441214983
Trained batch 123 in epoch 5, gen_loss = 1.4573083145003165, disc_loss = 0.0005540339202965579
Trained batch 124 in epoch 5, gen_loss = 1.4573664293289184, disc_loss = 0.0005568444617092609
Trained batch 125 in epoch 5, gen_loss = 1.456656969728924, disc_loss = 0.0005593386946231245
Trained batch 126 in epoch 5, gen_loss = 1.456547933300649, disc_loss = 0.0005614868631975095
Trained batch 127 in epoch 5, gen_loss = 1.4562512384727597, disc_loss = 0.0005635780448756122
Trained batch 128 in epoch 5, gen_loss = 1.4566956934078719, disc_loss = 0.0005654663451254195
Trained batch 129 in epoch 5, gen_loss = 1.4567191105622512, disc_loss = 0.0005671755159990145
Trained batch 130 in epoch 5, gen_loss = 1.4570875586444185, disc_loss = 0.0005678948937410503
Trained batch 131 in epoch 5, gen_loss = 1.456915725361217, disc_loss = 0.0005678914039339306
Trained batch 132 in epoch 5, gen_loss = 1.4566944165337354, disc_loss = 0.0005681018977026854
Trained batch 133 in epoch 5, gen_loss = 1.4568205244505583, disc_loss = 0.0005681613328129943
Trained batch 134 in epoch 5, gen_loss = 1.4570118268330892, disc_loss = 0.0005676566398944016
Trained batch 135 in epoch 5, gen_loss = 1.4566115342518862, disc_loss = 0.0005658340635230107
Trained batch 136 in epoch 5, gen_loss = 1.456448644617178, disc_loss = 0.0005636353829168599
Trained batch 137 in epoch 5, gen_loss = 1.456714259541553, disc_loss = 0.000561574095627293
Trained batch 138 in epoch 5, gen_loss = 1.456259785796241, disc_loss = 0.0005594812678642195
Trained batch 139 in epoch 5, gen_loss = 1.456581939969744, disc_loss = 0.0005575097078690305
Trained batch 140 in epoch 5, gen_loss = 1.4567038505635364, disc_loss = 0.0005552778577808528
Trained batch 141 in epoch 5, gen_loss = 1.456400326440032, disc_loss = 0.0005525286406980382
Trained batch 142 in epoch 5, gen_loss = 1.4564371600851311, disc_loss = 0.0005497797021896324
Trained batch 143 in epoch 5, gen_loss = 1.4565502454837163, disc_loss = 0.0005473157446734452
Trained batch 144 in epoch 5, gen_loss = 1.457000702825086, disc_loss = 0.0005456224661962739
Trained batch 145 in epoch 5, gen_loss = 1.4565840404327601, disc_loss = 0.0005451582118227746
Trained batch 146 in epoch 5, gen_loss = 1.4568299452463787, disc_loss = 0.0005459818748684385
Trained batch 147 in epoch 5, gen_loss = 1.4561574966520876, disc_loss = 0.0005467769304822148
Trained batch 148 in epoch 5, gen_loss = 1.4561293693196853, disc_loss = 0.000548056493030436
Trained batch 149 in epoch 5, gen_loss = 1.455848248799642, disc_loss = 0.0005494419273842747
Trained batch 150 in epoch 5, gen_loss = 1.4557501503963344, disc_loss = 0.00055001900953068
Trained batch 151 in epoch 5, gen_loss = 1.4554379676517688, disc_loss = 0.0005496210178534966
Trained batch 152 in epoch 5, gen_loss = 1.4550367398978838, disc_loss = 0.0005489927145889869
Trained batch 153 in epoch 5, gen_loss = 1.4545027125965466, disc_loss = 0.0005489416830937148
Trained batch 154 in epoch 5, gen_loss = 1.4544892511060161, disc_loss = 0.0005494126734594183
Trained batch 155 in epoch 5, gen_loss = 1.4544191528589299, disc_loss = 0.0005497690715576307
Trained batch 156 in epoch 5, gen_loss = 1.454153449672043, disc_loss = 0.0005499179338573651
Trained batch 157 in epoch 5, gen_loss = 1.4537476587899123, disc_loss = 0.0005503693776782838
Trained batch 158 in epoch 5, gen_loss = 1.4544564140667706, disc_loss = 0.0005504542371586153
Trained batch 159 in epoch 5, gen_loss = 1.4544185250997543, disc_loss = 0.000549353051246726
Trained batch 160 in epoch 5, gen_loss = 1.4541002341679163, disc_loss = 0.0005475209707029811
Trained batch 161 in epoch 5, gen_loss = 1.4542946344540444, disc_loss = 0.0005455500894315241
Trained batch 162 in epoch 5, gen_loss = 1.4544945713932529, disc_loss = 0.0005436344584664387
Trained batch 163 in epoch 5, gen_loss = 1.4543251649635593, disc_loss = 0.0005417476341990107
Trained batch 164 in epoch 5, gen_loss = 1.4547579136761752, disc_loss = 0.0005398769616890191
Trained batch 165 in epoch 5, gen_loss = 1.4543883376810924, disc_loss = 0.0005379113117450321
Trained batch 166 in epoch 5, gen_loss = 1.454538046242948, disc_loss = 0.0005361585644133735
Trained batch 167 in epoch 5, gen_loss = 1.454464466089294, disc_loss = 0.0005343758626362874
Trained batch 168 in epoch 5, gen_loss = 1.4544036296697764, disc_loss = 0.0005323685587352119
Trained batch 169 in epoch 5, gen_loss = 1.453922694570878, disc_loss = 0.0005306059017825378
Trained batch 170 in epoch 5, gen_loss = 1.4536539971479896, disc_loss = 0.0005292446867049514
Trained batch 171 in epoch 5, gen_loss = 1.4532464347606482, disc_loss = 0.0005278976414681597
Trained batch 172 in epoch 5, gen_loss = 1.4530391334798294, disc_loss = 0.0005263263322486989
Trained batch 173 in epoch 5, gen_loss = 1.4528860292215457, disc_loss = 0.0005246810952934768
Trained batch 174 in epoch 5, gen_loss = 1.4527721398217337, disc_loss = 0.0005229092527380479
Trained batch 175 in epoch 5, gen_loss = 1.4529932100664487, disc_loss = 0.0005211344320989817
Trained batch 176 in epoch 5, gen_loss = 1.4528896013895671, disc_loss = 0.0005193855037970605
Trained batch 177 in epoch 5, gen_loss = 1.4528723921668663, disc_loss = 0.0005177017079772208
Trained batch 178 in epoch 5, gen_loss = 1.452583526765834, disc_loss = 0.000515833603544681
Trained batch 179 in epoch 5, gen_loss = 1.4523954305383895, disc_loss = 0.0005138439555594232
Trained batch 180 in epoch 5, gen_loss = 1.4527817437661945, disc_loss = 0.0005119208239876917
Trained batch 181 in epoch 5, gen_loss = 1.4524322649934789, disc_loss = 0.0005101522411268389
Trained batch 182 in epoch 5, gen_loss = 1.4525424189906302, disc_loss = 0.0005088083898009926
Trained batch 183 in epoch 5, gen_loss = 1.4525760399258656, disc_loss = 0.0005076158155608699
Trained batch 184 in epoch 5, gen_loss = 1.4528708064878308, disc_loss = 0.0005062884004547487
Trained batch 185 in epoch 5, gen_loss = 1.4528141066592226, disc_loss = 0.0005047704055291971
Trained batch 186 in epoch 5, gen_loss = 1.452551821973872, disc_loss = 0.0005033296226482728
Trained batch 187 in epoch 5, gen_loss = 1.4524047064020278, disc_loss = 0.0005020565699948187
Trained batch 188 in epoch 5, gen_loss = 1.4524658994069175, disc_loss = 0.0005007732095826348
Trained batch 189 in epoch 5, gen_loss = 1.4523938655853272, disc_loss = 0.000499387323016938
Trained batch 190 in epoch 5, gen_loss = 1.4523707959040297, disc_loss = 0.0004978725069241491
Trained batch 191 in epoch 5, gen_loss = 1.4522833302617073, disc_loss = 0.0004964441520769469
Trained batch 192 in epoch 5, gen_loss = 1.4518480615912324, disc_loss = 0.0004956004481401941
Trained batch 193 in epoch 5, gen_loss = 1.451813987235433, disc_loss = 0.0004955593367694089
Trained batch 194 in epoch 5, gen_loss = 1.4515735705693562, disc_loss = 0.000495912992911867
Trained batch 195 in epoch 5, gen_loss = 1.451098741317282, disc_loss = 0.0004963645417087626
Trained batch 196 in epoch 5, gen_loss = 1.4508213440173774, disc_loss = 0.0004969946216457396
Trained batch 197 in epoch 5, gen_loss = 1.4508115300024398, disc_loss = 0.000497797007023973
Trained batch 198 in epoch 5, gen_loss = 1.45122671366936, disc_loss = 0.0004982088930728195
Trained batch 199 in epoch 5, gen_loss = 1.4510505652427674, disc_loss = 0.0004979021655890392
Trained batch 200 in epoch 5, gen_loss = 1.4515203018093583, disc_loss = 0.0004977869969330478
Trained batch 201 in epoch 5, gen_loss = 1.4515021944990252, disc_loss = 0.0004976210159181599
Trained batch 202 in epoch 5, gen_loss = 1.451252198571642, disc_loss = 0.0004976883601870965
Trained batch 203 in epoch 5, gen_loss = 1.4510171027744518, disc_loss = 0.0004976847912806917
Trained batch 204 in epoch 5, gen_loss = 1.4511702979483256, disc_loss = 0.0004974203024530875
Trained batch 205 in epoch 5, gen_loss = 1.451382635866554, disc_loss = 0.0004971315398347763
Trained batch 206 in epoch 5, gen_loss = 1.4511700269680667, disc_loss = 0.0004966921763689199
Trained batch 207 in epoch 5, gen_loss = 1.4509588411221137, disc_loss = 0.000496184730204382
Trained batch 208 in epoch 5, gen_loss = 1.4505214987759385, disc_loss = 0.0004957215359872296
Trained batch 209 in epoch 5, gen_loss = 1.4502967675526937, disc_loss = 0.0004955113731696093
Trained batch 210 in epoch 5, gen_loss = 1.450222311426678, disc_loss = 0.0004955431709471004
Trained batch 211 in epoch 5, gen_loss = 1.4498000684774146, disc_loss = 0.0004956591741883696
Trained batch 212 in epoch 5, gen_loss = 1.4500373322079438, disc_loss = 0.0004956082306597863
Trained batch 213 in epoch 5, gen_loss = 1.4498266338187957, disc_loss = 0.0004951866465608729
Trained batch 214 in epoch 5, gen_loss = 1.44956453733666, disc_loss = 0.0004943935611409807
Trained batch 215 in epoch 5, gen_loss = 1.4493113700990323, disc_loss = 0.0004934277256796593
Trained batch 216 in epoch 5, gen_loss = 1.4493252357579596, disc_loss = 0.0004923546645593988
Trained batch 217 in epoch 5, gen_loss = 1.4494095690753481, disc_loss = 0.0004911283531745281
Trained batch 218 in epoch 5, gen_loss = 1.4493893090992758, disc_loss = 0.0004897836289319664
Trained batch 219 in epoch 5, gen_loss = 1.449097496812994, disc_loss = 0.0004886481171442112
Trained batch 220 in epoch 5, gen_loss = 1.4489084697956414, disc_loss = 0.0004877901121940278
Trained batch 221 in epoch 5, gen_loss = 1.4484737579886977, disc_loss = 0.00048729446758558086
Trained batch 222 in epoch 5, gen_loss = 1.448543785398851, disc_loss = 0.0004873185414891907
Trained batch 223 in epoch 5, gen_loss = 1.4485304281115532, disc_loss = 0.00048806925224198494
Trained batch 224 in epoch 5, gen_loss = 1.4485075235366822, disc_loss = 0.0004892049429731237
Trained batch 225 in epoch 5, gen_loss = 1.448132229589783, disc_loss = 0.0004903630021778223
Trained batch 226 in epoch 5, gen_loss = 1.448247221598016, disc_loss = 0.0004916472700506547
Trained batch 227 in epoch 5, gen_loss = 1.4485225965056503, disc_loss = 0.0004933527137230461
Trained batch 228 in epoch 5, gen_loss = 1.4486649895339032, disc_loss = 0.0004953041644238229
Trained batch 229 in epoch 5, gen_loss = 1.4487939088240913, disc_loss = 0.0004969324876108896
Trained batch 230 in epoch 5, gen_loss = 1.448604408280674, disc_loss = 0.0004979029214170911
Trained batch 231 in epoch 5, gen_loss = 1.4486414846675149, disc_loss = 0.0004978868417875392
Trained batch 232 in epoch 5, gen_loss = 1.4487965787429156, disc_loss = 0.0004969990768274012
Trained batch 233 in epoch 5, gen_loss = 1.4486680428187053, disc_loss = 0.0004956967525833892
Trained batch 234 in epoch 5, gen_loss = 1.448837884943536, disc_loss = 0.0004945096991426172
Trained batch 235 in epoch 5, gen_loss = 1.4491383003986489, disc_loss = 0.0004934078331304698
Trained batch 236 in epoch 5, gen_loss = 1.4490198007615809, disc_loss = 0.0004922297885366382
Trained batch 237 in epoch 5, gen_loss = 1.4488121546617074, disc_loss = 0.0004911863709997558
Trained batch 238 in epoch 5, gen_loss = 1.4486251869959812, disc_loss = 0.0004902964061619052
Trained batch 239 in epoch 5, gen_loss = 1.4482474689682325, disc_loss = 0.0004896847053411572
Trained batch 240 in epoch 5, gen_loss = 1.4486006157032187, disc_loss = 0.0004898438124368702
Trained batch 241 in epoch 5, gen_loss = 1.4481980736590614, disc_loss = 0.0004909863771990034
Trained batch 242 in epoch 5, gen_loss = 1.4484718194223725, disc_loss = 0.0004937104430957985
Trained batch 243 in epoch 5, gen_loss = 1.4481693804264069, disc_loss = 0.0004979770634892076
Trained batch 244 in epoch 5, gen_loss = 1.4483662308478842, disc_loss = 0.0005031214943820877
Trained batch 245 in epoch 5, gen_loss = 1.4478891637267135, disc_loss = 0.0005085178959936782
Trained batch 246 in epoch 5, gen_loss = 1.447995359115755, disc_loss = 0.0005135050899846864
Trained batch 247 in epoch 5, gen_loss = 1.447832996326108, disc_loss = 0.000518166696917521
Trained batch 248 in epoch 5, gen_loss = 1.447745844542262, disc_loss = 0.0005222831361358574
Trained batch 249 in epoch 5, gen_loss = 1.447963487148285, disc_loss = 0.0005257202892098576
Trained batch 250 in epoch 5, gen_loss = 1.448077483481145, disc_loss = 0.000529023485890853
Trained batch 251 in epoch 5, gen_loss = 1.4479205778666906, disc_loss = 0.0005316203781163379
Trained batch 252 in epoch 5, gen_loss = 1.4480292759393987, disc_loss = 0.0005331945211236391
Trained batch 253 in epoch 5, gen_loss = 1.4477355846269864, disc_loss = 0.0005335160350064035
Trained batch 254 in epoch 5, gen_loss = 1.4479609999002194, disc_loss = 0.0005328968917156624
Trained batch 255 in epoch 5, gen_loss = 1.4479304691776633, disc_loss = 0.0005316064591625036
Trained batch 256 in epoch 5, gen_loss = 1.4479675979465827, disc_loss = 0.0005304323077760818
Trained batch 257 in epoch 5, gen_loss = 1.4479576834412509, disc_loss = 0.0005299767740219723
Trained batch 258 in epoch 5, gen_loss = 1.4478965519017695, disc_loss = 0.0005306228472240822
Trained batch 259 in epoch 5, gen_loss = 1.4478402669613177, disc_loss = 0.000531605727659413
Trained batch 260 in epoch 5, gen_loss = 1.4478501510802813, disc_loss = 0.0005327586898730953
Trained batch 261 in epoch 5, gen_loss = 1.447958584505183, disc_loss = 0.000534025244896908
Trained batch 262 in epoch 5, gen_loss = 1.447777356484997, disc_loss = 0.000534083167086143
Trained batch 263 in epoch 5, gen_loss = 1.4476888021736434, disc_loss = 0.0005328077828986958
Trained batch 264 in epoch 5, gen_loss = 1.4477017083258, disc_loss = 0.0005313806038103857
Trained batch 265 in epoch 5, gen_loss = 1.4476727157607114, disc_loss = 0.0005301720100801606
Trained batch 266 in epoch 5, gen_loss = 1.4476597228746735, disc_loss = 0.0005297709287149475
Trained batch 267 in epoch 5, gen_loss = 1.447552312665911, disc_loss = 0.0005298012075033525
Trained batch 268 in epoch 5, gen_loss = 1.4476251026068478, disc_loss = 0.0005290857776973507
Trained batch 269 in epoch 5, gen_loss = 1.4475772455886557, disc_loss = 0.0005276173783285129
Trained batch 270 in epoch 5, gen_loss = 1.447353608933762, disc_loss = 0.0005261700933737288
Trained batch 271 in epoch 5, gen_loss = 1.447407207068275, disc_loss = 0.0005249645268229549
Trained batch 272 in epoch 5, gen_loss = 1.4472035147768236, disc_loss = 0.0005243112666373765
Trained batch 273 in epoch 5, gen_loss = 1.4473215585207417, disc_loss = 0.0005247180351611893
Trained batch 274 in epoch 5, gen_loss = 1.4476264546134254, disc_loss = 0.0005254681932274252
Trained batch 275 in epoch 5, gen_loss = 1.447679793489152, disc_loss = 0.0005249148717679866
Trained batch 276 in epoch 5, gen_loss = 1.4473000872436412, disc_loss = 0.0005242046648981084
Trained batch 277 in epoch 5, gen_loss = 1.4473342921236436, disc_loss = 0.0005236257364087329
Trained batch 278 in epoch 5, gen_loss = 1.446939401301859, disc_loss = 0.0005244637699088409
Trained batch 279 in epoch 5, gen_loss = 1.4467586087329047, disc_loss = 0.0005273796812356782
Trained batch 280 in epoch 5, gen_loss = 1.4467564613369437, disc_loss = 0.0005296611655263223
Trained batch 281 in epoch 5, gen_loss = 1.4467394292777311, disc_loss = 0.0005303022947289539
Trained batch 282 in epoch 5, gen_loss = 1.446563450691978, disc_loss = 0.0005310328115582427
Trained batch 283 in epoch 5, gen_loss = 1.4465853634854438, disc_loss = 0.0005338201185558844
Trained batch 284 in epoch 5, gen_loss = 1.4465969470509312, disc_loss = 0.0005383653101601164
Trained batch 285 in epoch 5, gen_loss = 1.4467337948459011, disc_loss = 0.0005437616004251998
Trained batch 286 in epoch 5, gen_loss = 1.4466233938828579, disc_loss = 0.0005490177665725156
Trained batch 287 in epoch 5, gen_loss = 1.4464567282961474, disc_loss = 0.0005534704300266134
Trained batch 288 in epoch 5, gen_loss = 1.446393665970403, disc_loss = 0.0005557461550892702
Trained batch 289 in epoch 5, gen_loss = 1.446538479163729, disc_loss = 0.0005565115488495614
Trained batch 290 in epoch 5, gen_loss = 1.4462819328832464, disc_loss = 0.0005567216983863514
Trained batch 291 in epoch 5, gen_loss = 1.446533152910128, disc_loss = 0.0005567088827438181
Trained batch 292 in epoch 5, gen_loss = 1.4466922889390497, disc_loss = 0.000556761247829817
Trained batch 293 in epoch 5, gen_loss = 1.44687608472344, disc_loss = 0.0005564511010976077
Trained batch 294 in epoch 5, gen_loss = 1.4470810368909675, disc_loss = 0.0005556446410344629
Trained batch 295 in epoch 5, gen_loss = 1.4473504810719877, disc_loss = 0.0005543313352579906
Trained batch 296 in epoch 5, gen_loss = 1.4475648623925668, disc_loss = 0.0005529838248065074
Trained batch 297 in epoch 5, gen_loss = 1.4476627663477954, disc_loss = 0.0005518118703902712
Trained batch 298 in epoch 5, gen_loss = 1.4478647449742192, disc_loss = 0.0005509808513450352
Trained batch 299 in epoch 5, gen_loss = 1.4480006535847982, disc_loss = 0.0005505711282118379
Trained batch 300 in epoch 5, gen_loss = 1.4482553298291179, disc_loss = 0.0005504726598088001
Trained batch 301 in epoch 5, gen_loss = 1.448360897452626, disc_loss = 0.0005506919713791873
Trained batch 302 in epoch 5, gen_loss = 1.4484045171108182, disc_loss = 0.0005509912029347496
Trained batch 303 in epoch 5, gen_loss = 1.448380723987755, disc_loss = 0.0005508252018109104
Trained batch 304 in epoch 5, gen_loss = 1.4484696564127186, disc_loss = 0.0005502910289787458
Trained batch 305 in epoch 5, gen_loss = 1.448584182200089, disc_loss = 0.0005495984101454191
Trained batch 306 in epoch 5, gen_loss = 1.4483922448142732, disc_loss = 0.0005491173515495987
Trained batch 307 in epoch 5, gen_loss = 1.4482107282458963, disc_loss = 0.0005488860185689735
Trained batch 308 in epoch 5, gen_loss = 1.448225246664004, disc_loss = 0.0005487463073740928
Trained batch 309 in epoch 5, gen_loss = 1.4482393764680432, disc_loss = 0.0005485479107348158
Trained batch 310 in epoch 5, gen_loss = 1.44849545319364, disc_loss = 0.0005482666580836734
Trained batch 311 in epoch 5, gen_loss = 1.4485236727274382, disc_loss = 0.0005479475197577043
Trained batch 312 in epoch 5, gen_loss = 1.4484817494218722, disc_loss = 0.0005476325481163767
Trained batch 313 in epoch 5, gen_loss = 1.448391754156465, disc_loss = 0.000547252791968195
Trained batch 314 in epoch 5, gen_loss = 1.4483832957252623, disc_loss = 0.000546739720286698
Trained batch 315 in epoch 5, gen_loss = 1.4485002556179143, disc_loss = 0.0005460237037288055
Trained batch 316 in epoch 5, gen_loss = 1.4484473143466263, disc_loss = 0.0005450718307648036
Trained batch 317 in epoch 5, gen_loss = 1.4485007610710912, disc_loss = 0.0005442370313645118
Trained batch 318 in epoch 5, gen_loss = 1.4483343217066462, disc_loss = 0.0005437735213878415
Trained batch 319 in epoch 5, gen_loss = 1.44834238961339, disc_loss = 0.0005433657413504989
Trained batch 320 in epoch 5, gen_loss = 1.4481736195050297, disc_loss = 0.0005427768433193105
Trained batch 321 in epoch 5, gen_loss = 1.4481055873521367, disc_loss = 0.0005419572601720303
Trained batch 322 in epoch 5, gen_loss = 1.44808249244749, disc_loss = 0.000541050707059624
Trained batch 323 in epoch 5, gen_loss = 1.448132394640534, disc_loss = 0.0005401394242024837
Trained batch 324 in epoch 5, gen_loss = 1.4479059747549203, disc_loss = 0.0005392375440211394
Trained batch 325 in epoch 5, gen_loss = 1.4478957799314722, disc_loss = 0.0005382787095839186
Trained batch 326 in epoch 5, gen_loss = 1.4478314178070162, disc_loss = 0.0005375040086382851
Trained batch 327 in epoch 5, gen_loss = 1.4478254049289516, disc_loss = 0.0005369389320282895
Trained batch 328 in epoch 5, gen_loss = 1.4476703177107142, disc_loss = 0.0005364823699585589
Trained batch 329 in epoch 5, gen_loss = 1.4477192055095325, disc_loss = 0.0005360639163303528
Trained batch 330 in epoch 5, gen_loss = 1.4478022245482016, disc_loss = 0.000535656397205952
Trained batch 331 in epoch 5, gen_loss = 1.4478075439671436, disc_loss = 0.0005353654933169748
Trained batch 332 in epoch 5, gen_loss = 1.447584247803903, disc_loss = 0.0005351104153485901
Trained batch 333 in epoch 5, gen_loss = 1.447405131634124, disc_loss = 0.0005348800556663798
Trained batch 334 in epoch 5, gen_loss = 1.44752761143357, disc_loss = 0.0005349383444035315
Trained batch 335 in epoch 5, gen_loss = 1.4476997291757947, disc_loss = 0.0005351113059077761
Trained batch 336 in epoch 5, gen_loss = 1.447572238013723, disc_loss = 0.0005351836806165264
Trained batch 337 in epoch 5, gen_loss = 1.4477267212416294, disc_loss = 0.0005351703483718117
Trained batch 338 in epoch 5, gen_loss = 1.447628777287351, disc_loss = 0.0005350147415097435
Trained batch 339 in epoch 5, gen_loss = 1.4477002143859863, disc_loss = 0.0005348825907276478
Trained batch 340 in epoch 5, gen_loss = 1.4473425754703735, disc_loss = 0.0005345604193579171
Trained batch 341 in epoch 5, gen_loss = 1.4471844392910338, disc_loss = 0.0005340288551568533
Trained batch 342 in epoch 5, gen_loss = 1.4471917009909716, disc_loss = 0.0005333144216456806
Trained batch 343 in epoch 5, gen_loss = 1.4472650029631549, disc_loss = 0.0005323991151462271
Trained batch 344 in epoch 5, gen_loss = 1.4472432578819385, disc_loss = 0.0005313405268100104
Trained batch 345 in epoch 5, gen_loss = 1.4471494424549831, disc_loss = 0.0005302406908292189
Trained batch 346 in epoch 5, gen_loss = 1.4470354146847464, disc_loss = 0.0005291348490719778
Trained batch 347 in epoch 5, gen_loss = 1.447027337619628, disc_loss = 0.000528086230703081
Trained batch 348 in epoch 5, gen_loss = 1.4469034736682487, disc_loss = 0.0005271487906348376
Trained batch 349 in epoch 5, gen_loss = 1.4468417358398438, disc_loss = 0.0005262876580569095
Trained batch 350 in epoch 5, gen_loss = 1.446750577698406, disc_loss = 0.0005254139853001273
Trained batch 351 in epoch 5, gen_loss = 1.4469153840433469, disc_loss = 0.0005245321073578617
Trained batch 352 in epoch 5, gen_loss = 1.446991913717124, disc_loss = 0.0005236585432331792
Trained batch 353 in epoch 5, gen_loss = 1.4468843936920166, disc_loss = 0.0005227038878924476
Trained batch 354 in epoch 5, gen_loss = 1.4467981217612682, disc_loss = 0.0005216278586271022
Trained batch 355 in epoch 5, gen_loss = 1.446998722767562, disc_loss = 0.0005205854612224071
Trained batch 356 in epoch 5, gen_loss = 1.44671519129884, disc_loss = 0.0005197878018007235
Trained batch 357 in epoch 5, gen_loss = 1.4469297291846248, disc_loss = 0.0005196089399932993
Trained batch 358 in epoch 5, gen_loss = 1.4467551369520948, disc_loss = 0.0005197076780836988
Trained batch 359 in epoch 5, gen_loss = 1.4465871605608198, disc_loss = 0.0005198064252908807
Trained batch 360 in epoch 5, gen_loss = 1.446481095126461, disc_loss = 0.0005197111824998203
Trained batch 361 in epoch 5, gen_loss = 1.4463500462842909, disc_loss = 0.0005193254034882617
Trained batch 362 in epoch 5, gen_loss = 1.4462936269350288, disc_loss = 0.0005186286375834799
Trained batch 363 in epoch 5, gen_loss = 1.4462190853370416, disc_loss = 0.0005177593140595511
Trained batch 364 in epoch 5, gen_loss = 1.4461747463435344, disc_loss = 0.0005168774289602082
Trained batch 365 in epoch 5, gen_loss = 1.446070559689256, disc_loss = 0.0005159772962905579
Trained batch 366 in epoch 5, gen_loss = 1.4460245689189402, disc_loss = 0.0005150026406576395
Trained batch 367 in epoch 5, gen_loss = 1.4458631494123002, disc_loss = 0.0005139902615037104
Trained batch 368 in epoch 5, gen_loss = 1.445767499243987, disc_loss = 0.0005129484916348792
Trained batch 369 in epoch 5, gen_loss = 1.4457732026641432, disc_loss = 0.0005118949869348718
Trained batch 370 in epoch 5, gen_loss = 1.4458506235857858, disc_loss = 0.00051083105504563
Trained batch 371 in epoch 5, gen_loss = 1.4459998796703994, disc_loss = 0.0005097531476724637
Trained batch 372 in epoch 5, gen_loss = 1.4458905436078602, disc_loss = 0.0005087306404338985
Trained batch 373 in epoch 5, gen_loss = 1.4456881409022897, disc_loss = 0.0005077339960467618
Trained batch 374 in epoch 5, gen_loss = 1.4455109726587931, disc_loss = 0.000506861246113355
Trained batch 375 in epoch 5, gen_loss = 1.4455264600667548, disc_loss = 0.0005062393823383435
Trained batch 376 in epoch 5, gen_loss = 1.4457602564156529, disc_loss = 0.000505796117666091
Trained batch 377 in epoch 5, gen_loss = 1.4455371246766793, disc_loss = 0.0005053967206982808
Trained batch 378 in epoch 5, gen_loss = 1.4457302584182619, disc_loss = 0.0005052551427655816
Trained batch 379 in epoch 5, gen_loss = 1.445542986142008, disc_loss = 0.0005051368111468802
Trained batch 380 in epoch 5, gen_loss = 1.44555119610834, disc_loss = 0.0005050000160647766
Trained batch 381 in epoch 5, gen_loss = 1.4455659398857836, disc_loss = 0.0005048059277676524
Trained batch 382 in epoch 5, gen_loss = 1.44570176844186, disc_loss = 0.0005044938669529046
Trained batch 383 in epoch 5, gen_loss = 1.445502517124017, disc_loss = 0.0005040168598497985
Trained batch 384 in epoch 5, gen_loss = 1.4455557727194452, disc_loss = 0.0005033564308579624
Trained batch 385 in epoch 5, gen_loss = 1.445343520974866, disc_loss = 0.0005026600644664375
Trained batch 386 in epoch 5, gen_loss = 1.4454727000352332, disc_loss = 0.0005022278912870805
Trained batch 387 in epoch 5, gen_loss = 1.4453601489976509, disc_loss = 0.0005018974773792224
Trained batch 388 in epoch 5, gen_loss = 1.4453942490727245, disc_loss = 0.0005016590116646112
Trained batch 389 in epoch 5, gen_loss = 1.445415972135006, disc_loss = 0.0005015779216475308
Trained batch 390 in epoch 5, gen_loss = 1.4454673391473873, disc_loss = 0.0005015179571008448
Trained batch 391 in epoch 5, gen_loss = 1.4454823388737075, disc_loss = 0.0005012801656801235
Trained batch 392 in epoch 5, gen_loss = 1.4453865620319473, disc_loss = 0.0005009072985613847
Trained batch 393 in epoch 5, gen_loss = 1.4453104156528027, disc_loss = 0.0005004273117094437
Trained batch 394 in epoch 5, gen_loss = 1.445386137841623, disc_loss = 0.0004999952782033883
Trained batch 395 in epoch 5, gen_loss = 1.4453743145321354, disc_loss = 0.0004996963684191937
Trained batch 396 in epoch 5, gen_loss = 1.4453859404292455, disc_loss = 0.0004994200202560179
Trained batch 397 in epoch 5, gen_loss = 1.4454837675070642, disc_loss = 0.0004990950470875677
Trained batch 398 in epoch 5, gen_loss = 1.4453143837457911, disc_loss = 0.0004987815742347072
Trained batch 399 in epoch 5, gen_loss = 1.445276444852352, disc_loss = 0.0004984919199341676
Trained batch 400 in epoch 5, gen_loss = 1.4453349479118784, disc_loss = 0.000498164939781781
Trained batch 401 in epoch 5, gen_loss = 1.4452596001364106, disc_loss = 0.0004977685676201882
Trained batch 402 in epoch 5, gen_loss = 1.445141526664753, disc_loss = 0.0004973626677085537
Trained batch 403 in epoch 5, gen_loss = 1.4449779288013382, disc_loss = 0.0004969818003494108
Trained batch 404 in epoch 5, gen_loss = 1.4448556496773237, disc_loss = 0.0004966214294171673
Trained batch 405 in epoch 5, gen_loss = 1.4450916007821784, disc_loss = 0.0004962838467484652
Trained batch 406 in epoch 5, gen_loss = 1.4451203319891666, disc_loss = 0.0004957072564523154
Trained batch 407 in epoch 5, gen_loss = 1.4451510763051463, disc_loss = 0.00049488561743084
Trained batch 408 in epoch 5, gen_loss = 1.4449839653187684, disc_loss = 0.0004939619561487667
Trained batch 409 in epoch 5, gen_loss = 1.4449519177762473, disc_loss = 0.0004930141693365863
Trained batch 410 in epoch 5, gen_loss = 1.445015480628559, disc_loss = 0.0004920821179007859
Trained batch 411 in epoch 5, gen_loss = 1.4450551022603675, disc_loss = 0.0004910927452408376
Trained batch 412 in epoch 5, gen_loss = 1.444900169210919, disc_loss = 0.0004900735292398229
Trained batch 413 in epoch 5, gen_loss = 1.4448379695703442, disc_loss = 0.0004890949521503403
Trained batch 414 in epoch 5, gen_loss = 1.444809263872813, disc_loss = 0.0004882151235374678
Trained batch 415 in epoch 5, gen_loss = 1.4448202367012317, disc_loss = 0.0004873884201445505
Trained batch 416 in epoch 5, gen_loss = 1.444716133087945, disc_loss = 0.0004866296341081599
Trained batch 417 in epoch 5, gen_loss = 1.4445671655915, disc_loss = 0.0004859546203757792
Trained batch 418 in epoch 5, gen_loss = 1.44446708734963, disc_loss = 0.0004853039974308415
Trained batch 419 in epoch 5, gen_loss = 1.444583528098606, disc_loss = 0.0004846789498211971
Trained batch 420 in epoch 5, gen_loss = 1.444387402500506, disc_loss = 0.0004840723688992386
Trained batch 421 in epoch 5, gen_loss = 1.4441889767398202, disc_loss = 0.0004839864470849754
Trained batch 422 in epoch 5, gen_loss = 1.4441703673513786, disc_loss = 0.0004844761770546115
Trained batch 423 in epoch 5, gen_loss = 1.4441223566262227, disc_loss = 0.000485097146355536
Trained batch 424 in epoch 5, gen_loss = 1.4440532869451186, disc_loss = 0.0004856655840857831
Trained batch 425 in epoch 5, gen_loss = 1.4439637848469014, disc_loss = 0.0004860219181044696
Trained batch 426 in epoch 5, gen_loss = 1.4440531845115108, disc_loss = 0.0004860988840396981
Trained batch 427 in epoch 5, gen_loss = 1.4440197833230561, disc_loss = 0.00048588532377137785
Trained batch 428 in epoch 5, gen_loss = 1.4440261117228261, disc_loss = 0.0004854519291613186
Trained batch 429 in epoch 5, gen_loss = 1.4440246576486633, disc_loss = 0.0004848654418141408
Trained batch 430 in epoch 5, gen_loss = 1.4439459649150166, disc_loss = 0.0004842393097223005
Trained batch 431 in epoch 5, gen_loss = 1.4439357298391837, disc_loss = 0.0004837091509789052
Trained batch 432 in epoch 5, gen_loss = 1.443809239473409, disc_loss = 0.0004833329656292033
Trained batch 433 in epoch 5, gen_loss = 1.4437512071451284, disc_loss = 0.0004829876076240706
Trained batch 434 in epoch 5, gen_loss = 1.4436498948897438, disc_loss = 0.00048256731553982684
Trained batch 435 in epoch 5, gen_loss = 1.443675427808674, disc_loss = 0.00048228904315609047
Trained batch 436 in epoch 5, gen_loss = 1.4436105822534802, disc_loss = 0.0004819248206830888
Trained batch 437 in epoch 5, gen_loss = 1.4436493211140915, disc_loss = 0.000481514443201385
Trained batch 438 in epoch 5, gen_loss = 1.4436702209616032, disc_loss = 0.00048104851299940324
Trained batch 439 in epoch 5, gen_loss = 1.4436803996562957, disc_loss = 0.0004804498561993982
Trained batch 440 in epoch 5, gen_loss = 1.4438050425782496, disc_loss = 0.00047980839729228834
Trained batch 441 in epoch 5, gen_loss = 1.4436586248389196, disc_loss = 0.0004792372679706069
Trained batch 442 in epoch 5, gen_loss = 1.4435899653230242, disc_loss = 0.0004788583715650743
Trained batch 443 in epoch 5, gen_loss = 1.4436652703328177, disc_loss = 0.0004786006335249309
Trained batch 444 in epoch 5, gen_loss = 1.4435612006133862, disc_loss = 0.0004784166100343396
Trained batch 445 in epoch 5, gen_loss = 1.4433740262493424, disc_loss = 0.00047824602872848453
Trained batch 446 in epoch 5, gen_loss = 1.443293353321835, disc_loss = 0.00047799719746148534
Trained batch 447 in epoch 5, gen_loss = 1.4434428023440498, disc_loss = 0.0004776559830718595
Trained batch 448 in epoch 5, gen_loss = 1.4434756324657618, disc_loss = 0.0004772649081862057
Trained batch 449 in epoch 5, gen_loss = 1.443554692003462, disc_loss = 0.0004769673121174694
Trained batch 450 in epoch 5, gen_loss = 1.4435314664290908, disc_loss = 0.00047678758647471477
Trained batch 451 in epoch 5, gen_loss = 1.4435537913731769, disc_loss = 0.0004766895468266932
Trained batch 452 in epoch 5, gen_loss = 1.4434785342900696, disc_loss = 0.0004767076975229622
Trained batch 453 in epoch 5, gen_loss = 1.4435008034307002, disc_loss = 0.0004769054751180108
Trained batch 454 in epoch 5, gen_loss = 1.443643582522214, disc_loss = 0.000477285062539862
Trained batch 455 in epoch 5, gen_loss = 1.4435919225215912, disc_loss = 0.00047775254984515955
Trained batch 456 in epoch 5, gen_loss = 1.4437831522860203, disc_loss = 0.0004781267818874074
Trained batch 457 in epoch 5, gen_loss = 1.4436826721549554, disc_loss = 0.00047842916680116603
Trained batch 458 in epoch 5, gen_loss = 1.4436544670778162, disc_loss = 0.00047871847326937285
Trained batch 459 in epoch 5, gen_loss = 1.4435083290804986, disc_loss = 0.00047893081915073864
Trained batch 460 in epoch 5, gen_loss = 1.4434402058802045, disc_loss = 0.00047905251573556086
Trained batch 461 in epoch 5, gen_loss = 1.4434163010481633, disc_loss = 0.0004793170837217285
Trained batch 462 in epoch 5, gen_loss = 1.4434299404626274, disc_loss = 0.00047975670521526717
Trained batch 463 in epoch 5, gen_loss = 1.4432080686092377, disc_loss = 0.00048010016209822234
Trained batch 464 in epoch 5, gen_loss = 1.4433165727123138, disc_loss = 0.00048034483205742373
Trained batch 465 in epoch 5, gen_loss = 1.4432626054522306, disc_loss = 0.00048057676618094375
Trained batch 466 in epoch 5, gen_loss = 1.4432109303341687, disc_loss = 0.0004807016027957197
Trained batch 467 in epoch 5, gen_loss = 1.4432725944580176, disc_loss = 0.0004806994415685817
Trained batch 468 in epoch 5, gen_loss = 1.443437824879628, disc_loss = 0.0004807616215581988
Trained batch 469 in epoch 5, gen_loss = 1.4435310678279145, disc_loss = 0.0004812270868259997
Trained batch 470 in epoch 5, gen_loss = 1.4435882206428836, disc_loss = 0.0004819840073351691
Trained batch 471 in epoch 5, gen_loss = 1.443323039149834, disc_loss = 0.0004827794104346402
Trained batch 472 in epoch 5, gen_loss = 1.4432822244111883, disc_loss = 0.0004834721607131978
Trained batch 473 in epoch 5, gen_loss = 1.4430492751709016, disc_loss = 0.0004842106649494447
Trained batch 474 in epoch 5, gen_loss = 1.443154885894374, disc_loss = 0.00048516632385527423
Trained batch 475 in epoch 5, gen_loss = 1.44298896468988, disc_loss = 0.000486438244402931
Trained batch 476 in epoch 5, gen_loss = 1.443032917986376, disc_loss = 0.0004881316473728546
Trained batch 477 in epoch 5, gen_loss = 1.4428290662406378, disc_loss = 0.0004903642475255765
Trained batch 478 in epoch 5, gen_loss = 1.4429728750893867, disc_loss = 0.0004930200694371423
Trained batch 479 in epoch 5, gen_loss = 1.4428883008658886, disc_loss = 0.0004954977844742341
Trained batch 480 in epoch 5, gen_loss = 1.4431486734481462, disc_loss = 0.000497664733088707
Trained batch 481 in epoch 5, gen_loss = 1.4430072421354871, disc_loss = 0.0004990012390687346
Trained batch 482 in epoch 5, gen_loss = 1.4431050423509586, disc_loss = 0.0004997068614972269
Trained batch 483 in epoch 5, gen_loss = 1.443079829954904, disc_loss = 0.0004999481083780492
Trained batch 484 in epoch 5, gen_loss = 1.4431917640351757, disc_loss = 0.0004998953580633093
Trained batch 485 in epoch 5, gen_loss = 1.4431890511708985, disc_loss = 0.0004999922897650883
Trained batch 486 in epoch 5, gen_loss = 1.4433081069276563, disc_loss = 0.0005004778418016335
Trained batch 487 in epoch 5, gen_loss = 1.443197874016449, disc_loss = 0.0005017952488906601
Trained batch 488 in epoch 5, gen_loss = 1.4413789864210507, disc_loss = 0.001451732362933592
Trained batch 489 in epoch 5, gen_loss = 1.4456751993724277, disc_loss = 0.003875466197347791
Trained batch 490 in epoch 5, gen_loss = 1.4445151298206353, disc_loss = 0.0043659676859511415
Trained batch 491 in epoch 5, gen_loss = 1.4438906187206748, disc_loss = 0.006016603622478348
Trained batch 492 in epoch 5, gen_loss = 1.4442201677490683, disc_loss = 0.008436702619443466
Trained batch 493 in epoch 5, gen_loss = 1.4436671320002088, disc_loss = 0.009459137724945086
Trained batch 494 in epoch 5, gen_loss = 1.4433815603304392, disc_loss = 0.010382091085340668
Trained batch 495 in epoch 5, gen_loss = 1.4425616765454892, disc_loss = 0.011032759772176852
Trained batch 496 in epoch 5, gen_loss = 1.4412042384656143, disc_loss = 0.011557555044184896
Trained batch 497 in epoch 5, gen_loss = 1.4398282419246842, disc_loss = 0.012087090536277604
Trained batch 498 in epoch 5, gen_loss = 1.4384437192656951, disc_loss = 0.012577422146790638
Trained batch 499 in epoch 5, gen_loss = 1.4373542165756226, disc_loss = 0.013059043635352282
Trained batch 500 in epoch 5, gen_loss = 1.4361424764949167, disc_loss = 0.013526258135730067
Trained batch 501 in epoch 5, gen_loss = 1.4349876154228987, disc_loss = 0.013977932076514151
Trained batch 502 in epoch 5, gen_loss = 1.4337387306552758, disc_loss = 0.014444803908599447
Trained batch 503 in epoch 5, gen_loss = 1.4328952279119265, disc_loss = 0.014849927739002547
Trained batch 504 in epoch 5, gen_loss = 1.4319893639866668, disc_loss = 0.015178147656122675
Trained batch 505 in epoch 5, gen_loss = 1.430966745958969, disc_loss = 0.015491255000158877
Trained batch 506 in epoch 5, gen_loss = 1.4301723521606926, disc_loss = 0.015743851533757305
Trained batch 507 in epoch 5, gen_loss = 1.4296464758125815, disc_loss = 0.01594583029139995
Trained batch 508 in epoch 5, gen_loss = 1.4288780040497395, disc_loss = 0.016112596005829618
Trained batch 509 in epoch 5, gen_loss = 1.4281802686990477, disc_loss = 0.016232567109531658
Trained batch 510 in epoch 5, gen_loss = 1.4276376178819838, disc_loss = 0.016342249916475256
Trained batch 511 in epoch 5, gen_loss = 1.427915213862434, disc_loss = 0.016398144701014417
Trained batch 512 in epoch 5, gen_loss = 1.4274081107933387, disc_loss = 0.01656447402239604
Trained batch 513 in epoch 5, gen_loss = 1.427556345434968, disc_loss = 0.016820731870611498
Trained batch 514 in epoch 5, gen_loss = 1.4277928370873905, disc_loss = 0.016935340717216744
Trained batch 515 in epoch 5, gen_loss = 1.4276906774025555, disc_loss = 0.017136424365416195
Trained batch 516 in epoch 5, gen_loss = 1.427168795172435, disc_loss = 0.017236808171455037
Trained batch 517 in epoch 5, gen_loss = 1.4267569874704575, disc_loss = 0.017295758168654234
Trained batch 518 in epoch 5, gen_loss = 1.4267701448043646, disc_loss = 0.0173363491633684
Trained batch 519 in epoch 5, gen_loss = 1.4265174652521426, disc_loss = 0.01736005605979209
Trained batch 520 in epoch 5, gen_loss = 1.426621273245784, disc_loss = 0.01738830539685582
Trained batch 521 in epoch 5, gen_loss = 1.4264555975395143, disc_loss = 0.017415297503771136
Trained batch 522 in epoch 5, gen_loss = 1.4264599914532547, disc_loss = 0.01742104200236602
Trained batch 523 in epoch 5, gen_loss = 1.4265115279277771, disc_loss = 0.017422375216552915
Trained batch 524 in epoch 5, gen_loss = 1.4264894044966925, disc_loss = 0.01741399315027853
Trained batch 525 in epoch 5, gen_loss = 1.4264651432690059, disc_loss = 0.017408683147747732
Trained batch 526 in epoch 5, gen_loss = 1.4263377660139689, disc_loss = 0.01739678083959524
Trained batch 527 in epoch 5, gen_loss = 1.4254646276434262, disc_loss = 0.01756483826066511
Trained batch 528 in epoch 5, gen_loss = 1.4263922395237452, disc_loss = 0.01788283666458385
Trained batch 529 in epoch 5, gen_loss = 1.42661338909617, disc_loss = 0.01788404349406263
Trained batch 530 in epoch 5, gen_loss = 1.4262951080408472, disc_loss = 0.01791550408017391
Trained batch 531 in epoch 5, gen_loss = 1.4261686983413266, disc_loss = 0.017919928450556427
Trained batch 532 in epoch 5, gen_loss = 1.4262696822186125, disc_loss = 0.0179137418779759
Trained batch 533 in epoch 5, gen_loss = 1.4265541405267037, disc_loss = 0.017906380477831184
Trained batch 534 in epoch 5, gen_loss = 1.4269081530169907, disc_loss = 0.017892050996143154
Trained batch 535 in epoch 5, gen_loss = 1.4270280724141136, disc_loss = 0.01788684232188141
Trained batch 536 in epoch 5, gen_loss = 1.427749693726694, disc_loss = 0.017906241086579372
Trained batch 537 in epoch 5, gen_loss = 1.4277748410143374, disc_loss = 0.017888271266032575
Trained batch 538 in epoch 5, gen_loss = 1.4280809668309171, disc_loss = 0.017876133107352813
Trained batch 539 in epoch 5, gen_loss = 1.4281626202442028, disc_loss = 0.017859109343407908
Trained batch 540 in epoch 5, gen_loss = 1.428268222844094, disc_loss = 0.017842179686518588
Trained batch 541 in epoch 5, gen_loss = 1.4284580756817358, disc_loss = 0.017824406871962836
Trained batch 542 in epoch 5, gen_loss = 1.4286415508877945, disc_loss = 0.017801594894488074
Trained batch 543 in epoch 5, gen_loss = 1.428926136563806, disc_loss = 0.017778976318555472
Trained batch 544 in epoch 5, gen_loss = 1.4291317834766633, disc_loss = 0.01775318166951824
Trained batch 545 in epoch 5, gen_loss = 1.4293191136021317, disc_loss = 0.017727756012850926
Trained batch 546 in epoch 5, gen_loss = 1.4294921066033122, disc_loss = 0.017701093471579048
Trained batch 547 in epoch 5, gen_loss = 1.4296632452602804, disc_loss = 0.017674765817881147
Trained batch 548 in epoch 5, gen_loss = 1.4298516852825283, disc_loss = 0.017647923006588562
Trained batch 549 in epoch 5, gen_loss = 1.430109340060841, disc_loss = 0.017620883038537365
Trained batch 550 in epoch 5, gen_loss = 1.4303086351353114, disc_loss = 0.017592491412774268
Trained batch 551 in epoch 5, gen_loss = 1.430545570841734, disc_loss = 0.01756455424720775
Trained batch 552 in epoch 5, gen_loss = 1.4307857919989615, disc_loss = 0.01753741741842177
Trained batch 553 in epoch 5, gen_loss = 1.4310347476590841, disc_loss = 0.017510404481420366
Trained batch 554 in epoch 5, gen_loss = 1.4312598093135938, disc_loss = 0.017482076574149456
Trained batch 555 in epoch 5, gen_loss = 1.4314807209608367, disc_loss = 0.0174538173133383
Trained batch 556 in epoch 5, gen_loss = 1.4316797883549113, disc_loss = 0.017425012106762044
Trained batch 557 in epoch 5, gen_loss = 1.431937765904225, disc_loss = 0.017397777180705433
Trained batch 558 in epoch 5, gen_loss = 1.4322361617693962, disc_loss = 0.017370115365800347
Trained batch 559 in epoch 5, gen_loss = 1.432494826401983, disc_loss = 0.017342122619837547
Trained batch 560 in epoch 5, gen_loss = 1.4327062272770519, disc_loss = 0.01731407324097774
Trained batch 561 in epoch 5, gen_loss = 1.4329207397440575, disc_loss = 0.017286133494830293
Trained batch 562 in epoch 5, gen_loss = 1.4330832522038244, disc_loss = 0.017258053676689044
Trained batch 563 in epoch 5, gen_loss = 1.4333285135580294, disc_loss = 0.017229520713889612
Trained batch 564 in epoch 5, gen_loss = 1.4335258711755803, disc_loss = 0.017201393200429693
Trained batch 565 in epoch 5, gen_loss = 1.4337185461192585, disc_loss = 0.017173005101967613
Trained batch 566 in epoch 5, gen_loss = 1.4339513803916002, disc_loss = 0.017144601101997534
Trained batch 567 in epoch 5, gen_loss = 1.4341548903727195, disc_loss = 0.017116162179071335
Trained batch 568 in epoch 5, gen_loss = 1.434372857501092, disc_loss = 0.01708844370698791
Trained batch 569 in epoch 5, gen_loss = 1.4345281262146798, disc_loss = 0.017061005477571917
Trained batch 570 in epoch 5, gen_loss = 1.4347046463376796, disc_loss = 0.01703383563566629
Trained batch 571 in epoch 5, gen_loss = 1.4349921987606928, disc_loss = 0.0170066599103765
Trained batch 572 in epoch 5, gen_loss = 1.4352824338443617, disc_loss = 0.016979286738891392
Trained batch 573 in epoch 5, gen_loss = 1.4354693968536962, disc_loss = 0.016952128518259807
Trained batch 574 in epoch 5, gen_loss = 1.435738517512446, disc_loss = 0.016925120862256532
Trained batch 575 in epoch 5, gen_loss = 1.4360078865041335, disc_loss = 0.01689746760406605
Trained batch 576 in epoch 5, gen_loss = 1.4362562266751426, disc_loss = 0.01686971869875626
Trained batch 577 in epoch 5, gen_loss = 1.436514489997217, disc_loss = 0.016841775398703646
Trained batch 578 in epoch 5, gen_loss = 1.4367906773440373, disc_loss = 0.016814856197851284
Trained batch 579 in epoch 5, gen_loss = 1.437075248874467, disc_loss = 0.016787646218892466
Trained batch 580 in epoch 5, gen_loss = 1.4373185722840223, disc_loss = 0.016759943051007014
Trained batch 581 in epoch 5, gen_loss = 1.4375557627055244, disc_loss = 0.01673297284784966
Trained batch 582 in epoch 5, gen_loss = 1.4378052029765083, disc_loss = 0.01670612563389792
Trained batch 583 in epoch 5, gen_loss = 1.4380833965866533, disc_loss = 0.016679966602667216
Trained batch 584 in epoch 5, gen_loss = 1.4382664918899537, disc_loss = 0.016652719757562447
Trained batch 585 in epoch 5, gen_loss = 1.4384821700154717, disc_loss = 0.01662560507389236
Trained batch 586 in epoch 5, gen_loss = 1.438606999192571, disc_loss = 0.016598921030769927
Trained batch 587 in epoch 5, gen_loss = 1.4388177686808061, disc_loss = 0.016572139015516105
Trained batch 588 in epoch 5, gen_loss = 1.439110988874387, disc_loss = 0.01654542202336207
Trained batch 589 in epoch 5, gen_loss = 1.43932824498516, disc_loss = 0.01651851109273917
Trained batch 590 in epoch 5, gen_loss = 1.4395650641365503, disc_loss = 0.01649178103789551
Trained batch 591 in epoch 5, gen_loss = 1.439879507833236, disc_loss = 0.016465142638456175
Trained batch 592 in epoch 5, gen_loss = 1.4401305143989962, disc_loss = 0.016438694435978052
Trained batch 593 in epoch 5, gen_loss = 1.4403534100111888, disc_loss = 0.01641199975064309
Trained batch 594 in epoch 5, gen_loss = 1.4405223077084839, disc_loss = 0.016385356626769786
Trained batch 595 in epoch 5, gen_loss = 1.4407957290242983, disc_loss = 0.016358863692800006
Trained batch 596 in epoch 5, gen_loss = 1.441028316416333, disc_loss = 0.01633237908265052
Trained batch 597 in epoch 5, gen_loss = 1.4412945929578316, disc_loss = 0.016306352655298777
Trained batch 598 in epoch 5, gen_loss = 1.4414887866114137, disc_loss = 0.016280259817304403
Trained batch 599 in epoch 5, gen_loss = 1.441690406401952, disc_loss = 0.016254328263336597
Trained batch 600 in epoch 5, gen_loss = 1.4419121690677128, disc_loss = 0.016228220574188778
Trained batch 601 in epoch 5, gen_loss = 1.4420821979592409, disc_loss = 0.01620209409802223
Trained batch 602 in epoch 5, gen_loss = 1.442249593054675, disc_loss = 0.016175937051239042
Trained batch 603 in epoch 5, gen_loss = 1.4424802195157436, disc_loss = 0.01615009082780302
Trained batch 604 in epoch 5, gen_loss = 1.442750382423401, disc_loss = 0.016124244461058302
Trained batch 605 in epoch 5, gen_loss = 1.4429952220948223, disc_loss = 0.01609852417752438
Trained batch 606 in epoch 5, gen_loss = 1.4431566946588985, disc_loss = 0.01607272998394642
Trained batch 607 in epoch 5, gen_loss = 1.443308792224056, disc_loss = 0.016047068431577684
Trained batch 608 in epoch 5, gen_loss = 1.443473175632934, disc_loss = 0.01602139538374316
Trained batch 609 in epoch 5, gen_loss = 1.4436286865687762, disc_loss = 0.015995980599025822
Trained batch 610 in epoch 5, gen_loss = 1.4438286933883318, disc_loss = 0.015970513660230355
Trained batch 611 in epoch 5, gen_loss = 1.4440640289019915, disc_loss = 0.015945219115107403
Trained batch 612 in epoch 5, gen_loss = 1.4442621483110487, disc_loss = 0.0159198921374879
Trained batch 613 in epoch 5, gen_loss = 1.4444138458186717, disc_loss = 0.015894686019432797
Trained batch 614 in epoch 5, gen_loss = 1.4445378646617983, disc_loss = 0.015869502876662816
Trained batch 615 in epoch 5, gen_loss = 1.4446669186090495, disc_loss = 0.015844361979444246
Trained batch 616 in epoch 5, gen_loss = 1.4448979016834178, disc_loss = 0.015819466875173036
Trained batch 617 in epoch 5, gen_loss = 1.4450689426903587, disc_loss = 0.015794495244900973
Trained batch 618 in epoch 5, gen_loss = 1.4452181601948038, disc_loss = 0.015769677034571508
Trained batch 619 in epoch 5, gen_loss = 1.445447431264385, disc_loss = 0.015745679484638047
Trained batch 620 in epoch 5, gen_loss = 1.4456010722883657, disc_loss = 0.015721272863780417
Trained batch 621 in epoch 5, gen_loss = 1.4458637379373385, disc_loss = 0.015697496456060958
Trained batch 622 in epoch 5, gen_loss = 1.4460613784973733, disc_loss = 0.01567328455405258
Trained batch 623 in epoch 5, gen_loss = 1.4462024878997068, disc_loss = 0.015648988053983022
Trained batch 624 in epoch 5, gen_loss = 1.4462801851272582, disc_loss = 0.015624701120401733
Trained batch 625 in epoch 5, gen_loss = 1.4463809707675117, disc_loss = 0.01560042712683756
Trained batch 626 in epoch 5, gen_loss = 1.4464861761059677, disc_loss = 0.015576051219463597
Trained batch 627 in epoch 5, gen_loss = 1.4466397171946848, disc_loss = 0.015551805425240477
Trained batch 628 in epoch 5, gen_loss = 1.4468584964688518, disc_loss = 0.015527831305108783
Trained batch 629 in epoch 5, gen_loss = 1.447069732158903, disc_loss = 0.015503735130395008
Trained batch 630 in epoch 5, gen_loss = 1.4473719349375995, disc_loss = 0.01548016812284193
Trained batch 631 in epoch 5, gen_loss = 1.4475856704425207, disc_loss = 0.015456368989465704
Trained batch 632 in epoch 5, gen_loss = 1.4477781145870214, disc_loss = 0.015432495597918594
Trained batch 633 in epoch 5, gen_loss = 1.4479752664310324, disc_loss = 0.015408677557540789
Trained batch 634 in epoch 5, gen_loss = 1.448107727869289, disc_loss = 0.01538493471601923
Trained batch 635 in epoch 5, gen_loss = 1.4483784982618295, disc_loss = 0.01536458635252169
Trained batch 636 in epoch 5, gen_loss = 1.448577027680174, disc_loss = 0.015342075655422702
Trained batch 637 in epoch 5, gen_loss = 1.448785669377605, disc_loss = 0.015318884157111648
Trained batch 638 in epoch 5, gen_loss = 1.448970120464319, disc_loss = 0.015295490793659168
Trained batch 639 in epoch 5, gen_loss = 1.4491223182529211, disc_loss = 0.015272194129897798
Trained batch 640 in epoch 5, gen_loss = 1.4492674840965807, disc_loss = 0.015249049450722509
Trained batch 641 in epoch 5, gen_loss = 1.4494940744382199, disc_loss = 0.015226029298915433
Trained batch 642 in epoch 5, gen_loss = 1.4496405228485771, disc_loss = 0.015202982949668181
Trained batch 643 in epoch 5, gen_loss = 1.4498361634171528, disc_loss = 0.015179805123462864
Trained batch 644 in epoch 5, gen_loss = 1.4500090037205422, disc_loss = 0.015156697081388407
Trained batch 645 in epoch 5, gen_loss = 1.4502161637917392, disc_loss = 0.015133729720227428
Trained batch 646 in epoch 5, gen_loss = 1.4503856433045919, disc_loss = 0.015110724083167916
Trained batch 647 in epoch 5, gen_loss = 1.4506042446987129, disc_loss = 0.015087856783726171
Trained batch 648 in epoch 5, gen_loss = 1.4507617346127337, disc_loss = 0.015065107488381756
Trained batch 649 in epoch 5, gen_loss = 1.450873516339522, disc_loss = 0.01504233093491236
Trained batch 650 in epoch 5, gen_loss = 1.4510153652885542, disc_loss = 0.015019653093223761
Trained batch 651 in epoch 5, gen_loss = 1.4512452457580098, disc_loss = 0.014997177301191666
Trained batch 652 in epoch 5, gen_loss = 1.4513884372039374, disc_loss = 0.014974631395922427
Trained batch 653 in epoch 5, gen_loss = 1.4515257306419747, disc_loss = 0.01495215484369329
Trained batch 654 in epoch 5, gen_loss = 1.4516570511665052, disc_loss = 0.014929702118610545
Trained batch 655 in epoch 5, gen_loss = 1.4518008561032574, disc_loss = 0.01490737738172689
Trained batch 656 in epoch 5, gen_loss = 1.451899286818831, disc_loss = 0.01488524044863791
Trained batch 657 in epoch 5, gen_loss = 1.452121043640067, disc_loss = 0.014863267881574787
Trained batch 658 in epoch 5, gen_loss = 1.452334496790433, disc_loss = 0.014841329689019809
Trained batch 659 in epoch 5, gen_loss = 1.4524783912933235, disc_loss = 0.014819287707183377
Trained batch 660 in epoch 5, gen_loss = 1.452608487068615, disc_loss = 0.014797284086945512
Trained batch 661 in epoch 5, gen_loss = 1.4526909470918314, disc_loss = 0.014775439447668287
Trained batch 662 in epoch 5, gen_loss = 1.452781465797942, disc_loss = 0.014753540592133081
Trained batch 663 in epoch 5, gen_loss = 1.452938523637243, disc_loss = 0.014731632658280081
Trained batch 664 in epoch 5, gen_loss = 1.4530410763016322, disc_loss = 0.014709812987602799
Trained batch 665 in epoch 5, gen_loss = 1.4531685312589009, disc_loss = 0.01468802638085875
Trained batch 666 in epoch 5, gen_loss = 1.453352182701431, disc_loss = 0.014666434572475531
Trained batch 667 in epoch 5, gen_loss = 1.453538778834714, disc_loss = 0.014644752758395479
Trained batch 668 in epoch 5, gen_loss = 1.4536825799799464, disc_loss = 0.014623197054319739
Trained batch 669 in epoch 5, gen_loss = 1.4538460172824006, disc_loss = 0.014601702801101327
Trained batch 670 in epoch 5, gen_loss = 1.4540434800388204, disc_loss = 0.014580263385499568
Trained batch 671 in epoch 5, gen_loss = 1.4542108706775165, disc_loss = 0.014558868866017639
Trained batch 672 in epoch 5, gen_loss = 1.4543227008689212, disc_loss = 0.014537689148185998
Trained batch 673 in epoch 5, gen_loss = 1.454425207231448, disc_loss = 0.014516405883227553
Trained batch 674 in epoch 5, gen_loss = 1.4546265824635825, disc_loss = 0.014495191948285706
Trained batch 675 in epoch 5, gen_loss = 1.454778404983543, disc_loss = 0.01447411523979917
Trained batch 676 in epoch 5, gen_loss = 1.4548710271209875, disc_loss = 0.014453135101062567
Trained batch 677 in epoch 5, gen_loss = 1.4549650639559315, disc_loss = 0.01443211603074391
Trained batch 678 in epoch 5, gen_loss = 1.4550666996937613, disc_loss = 0.014411162479599048
Trained batch 679 in epoch 5, gen_loss = 1.4552040487527846, disc_loss = 0.014390263291095514
Trained batch 680 in epoch 5, gen_loss = 1.4552857434697088, disc_loss = 0.014369771219678012
Trained batch 681 in epoch 5, gen_loss = 1.455383802788698, disc_loss = 0.014349054839936409
Trained batch 682 in epoch 5, gen_loss = 1.4554937870226703, disc_loss = 0.014328357144673955
Trained batch 683 in epoch 5, gen_loss = 1.4556133436877825, disc_loss = 0.01430768465331966
Trained batch 684 in epoch 5, gen_loss = 1.4557579868901385, disc_loss = 0.014287090605191961
Trained batch 685 in epoch 5, gen_loss = 1.4558699329114864, disc_loss = 0.014266499340646723
Trained batch 686 in epoch 5, gen_loss = 1.4560329232153413, disc_loss = 0.014245989116730936
Trained batch 687 in epoch 5, gen_loss = 1.4561969953220943, disc_loss = 0.014225641021259307
Trained batch 688 in epoch 5, gen_loss = 1.4563481665834115, disc_loss = 0.01420529578469933
Trained batch 689 in epoch 5, gen_loss = 1.4564568085946898, disc_loss = 0.014184987743720885
Trained batch 690 in epoch 5, gen_loss = 1.456541041389388, disc_loss = 0.014164759752299506
Trained batch 691 in epoch 5, gen_loss = 1.4566868209425425, disc_loss = 0.014144548737347924
Trained batch 692 in epoch 5, gen_loss = 1.456808080576887, disc_loss = 0.014124407341231224
Trained batch 693 in epoch 5, gen_loss = 1.4569169726083189, disc_loss = 0.014104322555784594
Trained batch 694 in epoch 5, gen_loss = 1.4570242120207642, disc_loss = 0.014084279241305005
Trained batch 695 in epoch 5, gen_loss = 1.4570604497673867, disc_loss = 0.014064359851148055
Trained batch 696 in epoch 5, gen_loss = 1.4572636147311633, disc_loss = 0.014044519585644635
Trained batch 697 in epoch 5, gen_loss = 1.457375610455401, disc_loss = 0.014024718520297425
Trained batch 698 in epoch 5, gen_loss = 1.4574368724836642, disc_loss = 0.014005029100443581
Trained batch 699 in epoch 5, gen_loss = 1.4575628120558604, disc_loss = 0.013985365134909184
Trained batch 700 in epoch 5, gen_loss = 1.4576638394517667, disc_loss = 0.013965707262326961
Trained batch 701 in epoch 5, gen_loss = 1.4577442669121288, disc_loss = 0.013946011403865416
Trained batch 702 in epoch 5, gen_loss = 1.4578232490490715, disc_loss = 0.013926420050348946
Trained batch 703 in epoch 5, gen_loss = 1.4579750717702238, disc_loss = 0.01390690552958321
Trained batch 704 in epoch 5, gen_loss = 1.4580674773412394, disc_loss = 0.013887432518998055
Trained batch 705 in epoch 5, gen_loss = 1.4581677066030314, disc_loss = 0.013868123175848075
Trained batch 706 in epoch 5, gen_loss = 1.4582049076088415, disc_loss = 0.013848832246549909
Trained batch 707 in epoch 5, gen_loss = 1.4582265536327146, disc_loss = 0.013829585852219505
Trained batch 708 in epoch 5, gen_loss = 1.4583763486071266, disc_loss = 0.013810513925691673
Trained batch 709 in epoch 5, gen_loss = 1.4584840618388752, disc_loss = 0.01379148975677926
Trained batch 710 in epoch 5, gen_loss = 1.4585323784757096, disc_loss = 0.013772497864503285
Trained batch 711 in epoch 5, gen_loss = 1.4586464819613467, disc_loss = 0.013753455257449716
Trained batch 712 in epoch 5, gen_loss = 1.4588079698289762, disc_loss = 0.013734450643385146
Trained batch 713 in epoch 5, gen_loss = 1.4588783291541563, disc_loss = 0.013715433716693768
Trained batch 714 in epoch 5, gen_loss = 1.4590233959518113, disc_loss = 0.013696444710701137
Trained batch 715 in epoch 5, gen_loss = 1.4591769849121903, disc_loss = 0.013677501877612602
Trained batch 716 in epoch 5, gen_loss = 1.4593402900456385, disc_loss = 0.013658657178787366
Trained batch 717 in epoch 5, gen_loss = 1.4594118563577658, disc_loss = 0.013639857158834838
Trained batch 718 in epoch 5, gen_loss = 1.4594884235437788, disc_loss = 0.013621173586183285
Trained batch 719 in epoch 5, gen_loss = 1.4595965238081083, disc_loss = 0.013602455666255588
Trained batch 720 in epoch 5, gen_loss = 1.4597215262266203, disc_loss = 0.013583757404528862
Trained batch 721 in epoch 5, gen_loss = 1.4598155743197392, disc_loss = 0.013565249679131008
Trained batch 722 in epoch 5, gen_loss = 1.459884514122748, disc_loss = 0.013546686772536697
Trained batch 723 in epoch 5, gen_loss = 1.4600721062546935, disc_loss = 0.013528334169386251
Trained batch 724 in epoch 5, gen_loss = 1.4601922010553294, disc_loss = 0.013509922391456023
Trained batch 725 in epoch 5, gen_loss = 1.4603207323176801, disc_loss = 0.013491551054109797
Trained batch 726 in epoch 5, gen_loss = 1.4604332778280014, disc_loss = 0.013473192771340344
Trained batch 727 in epoch 5, gen_loss = 1.4605445382031765, disc_loss = 0.013454902293563133
Trained batch 728 in epoch 5, gen_loss = 1.460609453368743, disc_loss = 0.013436723806449696
Trained batch 729 in epoch 5, gen_loss = 1.4607129835102657, disc_loss = 0.013418522467531745
Trained batch 730 in epoch 5, gen_loss = 1.4607983591129288, disc_loss = 0.013400369446565637
Trained batch 731 in epoch 5, gen_loss = 1.4608999920673058, disc_loss = 0.0133822633338216
Trained batch 732 in epoch 5, gen_loss = 1.4609312739573916, disc_loss = 0.013364183624151704
Trained batch 733 in epoch 5, gen_loss = 1.46104422365937, disc_loss = 0.013346138331077263
Trained batch 734 in epoch 5, gen_loss = 1.4611049199590878, disc_loss = 0.01332812149356417
Trained batch 735 in epoch 5, gen_loss = 1.4611693578569784, disc_loss = 0.013310180555198831
Trained batch 736 in epoch 5, gen_loss = 1.4612811582221106, disc_loss = 0.01329232392938232
Trained batch 737 in epoch 5, gen_loss = 1.4613391412952081, disc_loss = 0.013274557843846476
Trained batch 738 in epoch 5, gen_loss = 1.4614946022730557, disc_loss = 0.013256784391481397
Trained batch 739 in epoch 5, gen_loss = 1.4615204659668175, disc_loss = 0.013239120161105766
Trained batch 740 in epoch 5, gen_loss = 1.46154885848685, disc_loss = 0.013221460020414072
Trained batch 741 in epoch 5, gen_loss = 1.4615867378898066, disc_loss = 0.013203830843986856
Trained batch 742 in epoch 5, gen_loss = 1.4616132358522786, disc_loss = 0.013186259689444863
Trained batch 743 in epoch 5, gen_loss = 1.4617194384336472, disc_loss = 0.013168743784106443
Trained batch 744 in epoch 5, gen_loss = 1.4618296320806414, disc_loss = 0.01315122856844479
Trained batch 745 in epoch 5, gen_loss = 1.4619609748709936, disc_loss = 0.013133809086105919
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 1.5485327243804932, disc_loss = 0.00012482257443480194
Trained batch 1 in epoch 6, gen_loss = 1.5222302675247192, disc_loss = 0.0001332242100033909
Trained batch 2 in epoch 6, gen_loss = 1.5319673617680867, disc_loss = 0.00012890770934366932
Trained batch 3 in epoch 6, gen_loss = 1.5185000896453857, disc_loss = 0.00013826008944306523
Trained batch 4 in epoch 6, gen_loss = 1.5159759521484375, disc_loss = 0.0001330666142166592
Trained batch 5 in epoch 6, gen_loss = 1.513162910938263, disc_loss = 0.00013795945293774517
Trained batch 6 in epoch 6, gen_loss = 1.5199541534696306, disc_loss = 0.00013602042391929508
Trained batch 7 in epoch 6, gen_loss = 1.5167214572429657, disc_loss = 0.00013287156343722017
Trained batch 8 in epoch 6, gen_loss = 1.5208710299597845, disc_loss = 0.0001308385310241849
Trained batch 9 in epoch 6, gen_loss = 1.5205425024032593, disc_loss = 0.00013328120767255313
Trained batch 10 in epoch 6, gen_loss = 1.5238922509280117, disc_loss = 0.00013682610072216696
Trained batch 11 in epoch 6, gen_loss = 1.5216691096623738, disc_loss = 0.00014036691391083878
Trained batch 12 in epoch 6, gen_loss = 1.5245186732365534, disc_loss = 0.000142369727724984
Trained batch 13 in epoch 6, gen_loss = 1.524971638407026, disc_loss = 0.00014388703077981648
Trained batch 14 in epoch 6, gen_loss = 1.5263577302296956, disc_loss = 0.00014595745063464467
Trained batch 15 in epoch 6, gen_loss = 1.5256382524967194, disc_loss = 0.00014384248834176105
Trained batch 16 in epoch 6, gen_loss = 1.525488068075741, disc_loss = 0.0001484760530943544
Trained batch 17 in epoch 6, gen_loss = 1.5257036421034071, disc_loss = 0.00014965685477363877
Trained batch 18 in epoch 6, gen_loss = 1.526157674036528, disc_loss = 0.00015097861691365803
Trained batch 19 in epoch 6, gen_loss = 1.5277855217456817, disc_loss = 0.0001519512657978339
Trained batch 20 in epoch 6, gen_loss = 1.5348964588982719, disc_loss = 0.00016957327517004507
Trained batch 21 in epoch 6, gen_loss = 1.5333107980814846, disc_loss = 0.00017297274362962608
Trained batch 22 in epoch 6, gen_loss = 1.5316876484000164, disc_loss = 0.00017153723867680958
Trained batch 23 in epoch 6, gen_loss = 1.5309856832027435, disc_loss = 0.00016847249207785353
Trained batch 24 in epoch 6, gen_loss = 1.53172110080719, disc_loss = 0.0001659447542624548
Trained batch 25 in epoch 6, gen_loss = 1.5314305883187513, disc_loss = 0.00016418865533733668
Trained batch 26 in epoch 6, gen_loss = 1.5319159869794492, disc_loss = 0.00016263373766344525
Trained batch 27 in epoch 6, gen_loss = 1.5292567823614394, disc_loss = 0.0001610498675290728
Trained batch 28 in epoch 6, gen_loss = 1.5284996114928147, disc_loss = 0.00015866010477926968
Trained batch 29 in epoch 6, gen_loss = 1.5294412573178608, disc_loss = 0.0001565506046366257
Trained batch 30 in epoch 6, gen_loss = 1.5269022641643402, disc_loss = 0.00015627946601354427
Trained batch 31 in epoch 6, gen_loss = 1.5266658551990986, disc_loss = 0.00015513210223616625
Trained batch 32 in epoch 6, gen_loss = 1.5256472392515703, disc_loss = 0.0001555235082350643
Trained batch 33 in epoch 6, gen_loss = 1.5261047903229208, disc_loss = 0.00015480332791305366
Trained batch 34 in epoch 6, gen_loss = 1.5273893662861415, disc_loss = 0.00015348564421791317
Trained batch 35 in epoch 6, gen_loss = 1.527959664662679, disc_loss = 0.0001518194666358694
Trained batch 36 in epoch 6, gen_loss = 1.5284928470044523, disc_loss = 0.00015006626199465245
Trained batch 37 in epoch 6, gen_loss = 1.5281529740283364, disc_loss = 0.0001494451245985386
Trained batch 38 in epoch 6, gen_loss = 1.527731913786668, disc_loss = 0.00014802498779504394
Trained batch 39 in epoch 6, gen_loss = 1.528567948937416, disc_loss = 0.00014700038245791803
Trained batch 40 in epoch 6, gen_loss = 1.527774964890829, disc_loss = 0.00014680976537198237
Trained batch 41 in epoch 6, gen_loss = 1.5282284049760728, disc_loss = 0.0001463827722459211
Trained batch 42 in epoch 6, gen_loss = 1.5259553249492201, disc_loss = 0.00014735742585143333
Trained batch 43 in epoch 6, gen_loss = 1.524928317828612, disc_loss = 0.00014767301780176984
Trained batch 44 in epoch 6, gen_loss = 1.5244423151016235, disc_loss = 0.00014694821810634393
Trained batch 45 in epoch 6, gen_loss = 1.5233359596003657, disc_loss = 0.0001461521958686796
Trained batch 46 in epoch 6, gen_loss = 1.5241666448877214, disc_loss = 0.0001458011425479236
Trained batch 47 in epoch 6, gen_loss = 1.5243966355919838, disc_loss = 0.0001448913819028045
Trained batch 48 in epoch 6, gen_loss = 1.524462369023537, disc_loss = 0.00014376965228453926
Trained batch 49 in epoch 6, gen_loss = 1.5236837339401246, disc_loss = 0.00014291523562860676
Trained batch 50 in epoch 6, gen_loss = 1.5230605251648848, disc_loss = 0.0001420307695904436
Trained batch 51 in epoch 6, gen_loss = 1.5217902752069326, disc_loss = 0.00014165536539132099
Trained batch 52 in epoch 6, gen_loss = 1.5209739028282885, disc_loss = 0.00014115284998211482
Trained batch 53 in epoch 6, gen_loss = 1.5203267843634993, disc_loss = 0.0001408782044125945
Trained batch 54 in epoch 6, gen_loss = 1.5199276555668224, disc_loss = 0.00014011724177345804
Trained batch 55 in epoch 6, gen_loss = 1.519411101937294, disc_loss = 0.0001391022819266904
Trained batch 56 in epoch 6, gen_loss = 1.5207253694534302, disc_loss = 0.00013915089629447545
Trained batch 57 in epoch 6, gen_loss = 1.5212995224985584, disc_loss = 0.00013841236080946241
Trained batch 58 in epoch 6, gen_loss = 1.5218518750142243, disc_loss = 0.0001378182167141951
Trained batch 59 in epoch 6, gen_loss = 1.5223926107088726, disc_loss = 0.00013733486836523903
Trained batch 60 in epoch 6, gen_loss = 1.521731689328053, disc_loss = 0.00013690281262884648
Trained batch 61 in epoch 6, gen_loss = 1.5227588222872825, disc_loss = 0.00013669761897143609
Trained batch 62 in epoch 6, gen_loss = 1.5239306423399184, disc_loss = 0.00013646834619095667
Trained batch 63 in epoch 6, gen_loss = 1.524117549881339, disc_loss = 0.0001354949846472664
Trained batch 64 in epoch 6, gen_loss = 1.5239851218003493, disc_loss = 0.00013482686604570168
Trained batch 65 in epoch 6, gen_loss = 1.524340185252103, disc_loss = 0.00013429684567558016
Trained batch 66 in epoch 6, gen_loss = 1.5246025199320778, disc_loss = 0.0001338732927523331
Trained batch 67 in epoch 6, gen_loss = 1.5241523700601913, disc_loss = 0.00013376981566098575
Trained batch 68 in epoch 6, gen_loss = 1.5247595621191936, disc_loss = 0.00013304154624389756
Trained batch 69 in epoch 6, gen_loss = 1.5251256346702575, disc_loss = 0.0001326466627818133
Trained batch 70 in epoch 6, gen_loss = 1.525101681830178, disc_loss = 0.00013182751758968536
Trained batch 71 in epoch 6, gen_loss = 1.5247426761521234, disc_loss = 0.00013151531584298937
Trained batch 72 in epoch 6, gen_loss = 1.524350055276531, disc_loss = 0.00013064247438818063
Trained batch 73 in epoch 6, gen_loss = 1.52434009474677, disc_loss = 0.00013009193296327154
Trained batch 74 in epoch 6, gen_loss = 1.5251209259033203, disc_loss = 0.00012986607131703446
Trained batch 75 in epoch 6, gen_loss = 1.5251876915756024, disc_loss = 0.0001292358138016425
Trained batch 76 in epoch 6, gen_loss = 1.5255514692950558, disc_loss = 0.00012860308811764003
Trained batch 77 in epoch 6, gen_loss = 1.5251698448107793, disc_loss = 0.0001286515182119985
Trained batch 78 in epoch 6, gen_loss = 1.5249033502385587, disc_loss = 0.00012838033691440603
Trained batch 79 in epoch 6, gen_loss = 1.525406427681446, disc_loss = 0.0001284940174627991
Trained batch 80 in epoch 6, gen_loss = 1.5263775336889573, disc_loss = 0.0001285927750875909
Trained batch 81 in epoch 6, gen_loss = 1.5264276135258559, disc_loss = 0.00012834619604002844
Trained batch 82 in epoch 6, gen_loss = 1.5271907786288894, disc_loss = 0.00012985039430499324
Trained batch 83 in epoch 6, gen_loss = 1.5276858565353213, disc_loss = 0.00013011152198790418
Trained batch 84 in epoch 6, gen_loss = 1.5276363022187176, disc_loss = 0.00013012550933875472
Trained batch 85 in epoch 6, gen_loss = 1.5279352734255236, disc_loss = 0.00013013051165914878
Trained batch 86 in epoch 6, gen_loss = 1.5281434456507366, disc_loss = 0.00012962649944010885
Trained batch 87 in epoch 6, gen_loss = 1.527603646570986, disc_loss = 0.00012962307507471203
Trained batch 88 in epoch 6, gen_loss = 1.5284027758609042, disc_loss = 0.00012977473973100378
Trained batch 89 in epoch 6, gen_loss = 1.5287347277005514, disc_loss = 0.00012956868538620053
Trained batch 90 in epoch 6, gen_loss = 1.5282108338324578, disc_loss = 0.00012963691895512947
Trained batch 91 in epoch 6, gen_loss = 1.5275796314944392, disc_loss = 0.00012949096415705634
Trained batch 92 in epoch 6, gen_loss = 1.527553621158805, disc_loss = 0.0001292603548243141
Trained batch 93 in epoch 6, gen_loss = 1.5273773961878838, disc_loss = 0.0001289508838957037
Trained batch 94 in epoch 6, gen_loss = 1.527185246818944, disc_loss = 0.0001285238809558857
Trained batch 95 in epoch 6, gen_loss = 1.5269975513219833, disc_loss = 0.00012801309208043676
Trained batch 96 in epoch 6, gen_loss = 1.5268632308724, disc_loss = 0.00012764880187946285
Trained batch 97 in epoch 6, gen_loss = 1.526729544814752, disc_loss = 0.00012734762491831765
Trained batch 98 in epoch 6, gen_loss = 1.5258036791676222, disc_loss = 0.00012768610479660576
Trained batch 99 in epoch 6, gen_loss = 1.5246350741386414, disc_loss = 0.00012768126041919458
Trained batch 100 in epoch 6, gen_loss = 1.5248377795266632, disc_loss = 0.0001275832394522956
Trained batch 101 in epoch 6, gen_loss = 1.5247634322035546, disc_loss = 0.0001273844414647422
Trained batch 102 in epoch 6, gen_loss = 1.5246516037913203, disc_loss = 0.00012685172888506836
Trained batch 103 in epoch 6, gen_loss = 1.524388218155274, disc_loss = 0.00012646535483676975
Trained batch 104 in epoch 6, gen_loss = 1.5246202582404726, disc_loss = 0.00012607989137038765
Trained batch 105 in epoch 6, gen_loss = 1.5245225170873247, disc_loss = 0.00012566735265108774
Trained batch 106 in epoch 6, gen_loss = 1.524222499856325, disc_loss = 0.00012542656364428558
Trained batch 107 in epoch 6, gen_loss = 1.524374223417706, disc_loss = 0.00012532504627381935
Trained batch 108 in epoch 6, gen_loss = 1.5243971818084017, disc_loss = 0.00012497010228540236
Trained batch 109 in epoch 6, gen_loss = 1.524427312070673, disc_loss = 0.0001245683178157461
Trained batch 110 in epoch 6, gen_loss = 1.5243974333410863, disc_loss = 0.000124173679101692
Trained batch 111 in epoch 6, gen_loss = 1.5238428605454308, disc_loss = 0.0001236150561193686
Trained batch 112 in epoch 6, gen_loss = 1.5235390504904553, disc_loss = 0.0001234328477289033
Trained batch 113 in epoch 6, gen_loss = 1.5237236106604861, disc_loss = 0.0001231696993559844
Trained batch 114 in epoch 6, gen_loss = 1.5241291077240653, disc_loss = 0.0001227786674660266
Trained batch 115 in epoch 6, gen_loss = 1.5236796603120606, disc_loss = 0.00012260109937854176
Trained batch 116 in epoch 6, gen_loss = 1.5236852678478274, disc_loss = 0.00012219312450794788
Trained batch 117 in epoch 6, gen_loss = 1.52365843320297, disc_loss = 0.00012179702858024245
Trained batch 118 in epoch 6, gen_loss = 1.5236201516720427, disc_loss = 0.00012143035968344956
Trained batch 119 in epoch 6, gen_loss = 1.5234366327524185, disc_loss = 0.00012096463633497479
Trained batch 120 in epoch 6, gen_loss = 1.523696833405613, disc_loss = 0.00012094088339858711
Trained batch 121 in epoch 6, gen_loss = 1.5233672241695593, disc_loss = 0.00012050487542883722
Trained batch 122 in epoch 6, gen_loss = 1.5231534639994304, disc_loss = 0.00012010872373272233
Trained batch 123 in epoch 6, gen_loss = 1.522959751467551, disc_loss = 0.00011976690538792735
Trained batch 124 in epoch 6, gen_loss = 1.5229139623641967, disc_loss = 0.00011941747111268341
Trained batch 125 in epoch 6, gen_loss = 1.5227530399958293, disc_loss = 0.00011922450507954059
Trained batch 126 in epoch 6, gen_loss = 1.5229486283354872, disc_loss = 0.00011900960599295941
Trained batch 127 in epoch 6, gen_loss = 1.523302217014134, disc_loss = 0.00011876171441826955
Trained batch 128 in epoch 6, gen_loss = 1.523517368375793, disc_loss = 0.00011856376450434832
Trained batch 129 in epoch 6, gen_loss = 1.5236666202545166, disc_loss = 0.00011833928007175788
Trained batch 130 in epoch 6, gen_loss = 1.5231692445187168, disc_loss = 0.00011818429918600715
Trained batch 131 in epoch 6, gen_loss = 1.5228369579170689, disc_loss = 0.00011807568212547763
Trained batch 132 in epoch 6, gen_loss = 1.5229209634594452, disc_loss = 0.00011764467648787186
Trained batch 133 in epoch 6, gen_loss = 1.522772256118148, disc_loss = 0.0001172986063574538
Trained batch 134 in epoch 6, gen_loss = 1.5230692466100058, disc_loss = 0.00011718043447385922
Trained batch 135 in epoch 6, gen_loss = 1.523094835526803, disc_loss = 0.0001169899674363585
Trained batch 136 in epoch 6, gen_loss = 1.523505674661511, disc_loss = 0.00011694600494845301
Trained batch 137 in epoch 6, gen_loss = 1.5239231335944023, disc_loss = 0.00011665705476290263
Trained batch 138 in epoch 6, gen_loss = 1.5240431698106176, disc_loss = 0.00011634058046838095
Trained batch 139 in epoch 6, gen_loss = 1.524223950931004, disc_loss = 0.00011613426691578102
Trained batch 140 in epoch 6, gen_loss = 1.5244947189980365, disc_loss = 0.00011579438845638569
Trained batch 141 in epoch 6, gen_loss = 1.5241637683250535, disc_loss = 0.00011554877623189307
Trained batch 142 in epoch 6, gen_loss = 1.5239999310953634, disc_loss = 0.00011522372171219268
Trained batch 143 in epoch 6, gen_loss = 1.52403048839834, disc_loss = 0.00011481234077513768
Trained batch 144 in epoch 6, gen_loss = 1.5239736343252248, disc_loss = 0.00011458325479279978
Trained batch 145 in epoch 6, gen_loss = 1.5238961258979693, disc_loss = 0.00011421758058095791
Trained batch 146 in epoch 6, gen_loss = 1.5236288349644667, disc_loss = 0.00011388026754515163
Trained batch 147 in epoch 6, gen_loss = 1.5233968294955589, disc_loss = 0.00011359056969848934
Trained batch 148 in epoch 6, gen_loss = 1.5231425994194594, disc_loss = 0.00011331626062610362
Trained batch 149 in epoch 6, gen_loss = 1.523527549902598, disc_loss = 0.00011327356010345587
Trained batch 150 in epoch 6, gen_loss = 1.5232331160677979, disc_loss = 0.00011293821461134072
Trained batch 151 in epoch 6, gen_loss = 1.5234526842832565, disc_loss = 0.00011266158270173994
Trained batch 152 in epoch 6, gen_loss = 1.5238836777755638, disc_loss = 0.0001125693319278261
Trained batch 153 in epoch 6, gen_loss = 1.5237821534082487, disc_loss = 0.00011249982521626584
Trained batch 154 in epoch 6, gen_loss = 1.5239819211344565, disc_loss = 0.00011250486476778714
Trained batch 155 in epoch 6, gen_loss = 1.524039279191922, disc_loss = 0.00011240974216865978
Trained batch 156 in epoch 6, gen_loss = 1.5239181381881617, disc_loss = 0.00011226663347515337
Trained batch 157 in epoch 6, gen_loss = 1.52401553830014, disc_loss = 0.00011200383336403366
Trained batch 158 in epoch 6, gen_loss = 1.5240625337984577, disc_loss = 0.00011174423403107362
Trained batch 159 in epoch 6, gen_loss = 1.52397313863039, disc_loss = 0.00011137953092656971
Trained batch 160 in epoch 6, gen_loss = 1.5241602037263953, disc_loss = 0.00011104200225050839
Trained batch 161 in epoch 6, gen_loss = 1.5243036658675582, disc_loss = 0.00011067548850270989
Trained batch 162 in epoch 6, gen_loss = 1.5246650368158072, disc_loss = 0.00011083374864620334
Trained batch 163 in epoch 6, gen_loss = 1.5245343381311836, disc_loss = 0.00011096236297950183
Trained batch 164 in epoch 6, gen_loss = 1.5244069727984342, disc_loss = 0.00011091872253349389
Trained batch 165 in epoch 6, gen_loss = 1.5246020067169006, disc_loss = 0.00011065113169725996
Trained batch 166 in epoch 6, gen_loss = 1.5245812510301966, disc_loss = 0.00011043586143610364
Trained batch 167 in epoch 6, gen_loss = 1.5245523154735565, disc_loss = 0.00011021772778414223
Trained batch 168 in epoch 6, gen_loss = 1.5245915009425237, disc_loss = 0.00010999885405628727
Trained batch 169 in epoch 6, gen_loss = 1.5247088390238144, disc_loss = 0.00010967290224524571
Trained batch 170 in epoch 6, gen_loss = 1.5246683129093104, disc_loss = 0.00010936762212979204
Trained batch 171 in epoch 6, gen_loss = 1.5246011476184047, disc_loss = 0.00010919809690592025
Trained batch 172 in epoch 6, gen_loss = 1.5244556603404138, disc_loss = 0.00010888269412529121
Trained batch 173 in epoch 6, gen_loss = 1.5244301660307522, disc_loss = 0.00010857310363284885
Trained batch 174 in epoch 6, gen_loss = 1.5243474653788975, disc_loss = 0.00010832497477947203
Trained batch 175 in epoch 6, gen_loss = 1.5242983014746145, disc_loss = 0.00010818498538934695
Trained batch 176 in epoch 6, gen_loss = 1.5244075996054094, disc_loss = 0.00010795076864809035
Trained batch 177 in epoch 6, gen_loss = 1.524171665143431, disc_loss = 0.00010800897051809811
Trained batch 178 in epoch 6, gen_loss = 1.5241826925863766, disc_loss = 0.00010777821958402572
Trained batch 179 in epoch 6, gen_loss = 1.5243907597329882, disc_loss = 0.00010745546523038583
Trained batch 180 in epoch 6, gen_loss = 1.5243263942760656, disc_loss = 0.00010714232673976591
Trained batch 181 in epoch 6, gen_loss = 1.5240982535121206, disc_loss = 0.00010686409277096262
Trained batch 182 in epoch 6, gen_loss = 1.5237877388469507, disc_loss = 0.00010666236215155912
Trained batch 183 in epoch 6, gen_loss = 1.5235825744660005, disc_loss = 0.00010656469652056568
Trained batch 184 in epoch 6, gen_loss = 1.5236766654091913, disc_loss = 0.00010643864907497365
Trained batch 185 in epoch 6, gen_loss = 1.523327862062762, disc_loss = 0.00010637870572506755
Trained batch 186 in epoch 6, gen_loss = 1.5231217649531237, disc_loss = 0.00010621381871340632
Trained batch 187 in epoch 6, gen_loss = 1.5231192226105548, disc_loss = 0.00010599021552866845
Trained batch 188 in epoch 6, gen_loss = 1.523001790677429, disc_loss = 0.00010571135681910347
Trained batch 189 in epoch 6, gen_loss = 1.5228134450159574, disc_loss = 0.00010544184925062215
Trained batch 190 in epoch 6, gen_loss = 1.5227368545781879, disc_loss = 0.000105186925241169
Trained batch 191 in epoch 6, gen_loss = 1.5224130873878796, disc_loss = 0.00010498682538203259
Trained batch 192 in epoch 6, gen_loss = 1.522589524175219, disc_loss = 0.0001048513305612654
Trained batch 193 in epoch 6, gen_loss = 1.522873063677365, disc_loss = 0.00010460223387143714
Trained batch 194 in epoch 6, gen_loss = 1.5228157728146283, disc_loss = 0.00010428861761540294
Trained batch 195 in epoch 6, gen_loss = 1.5229885237557548, disc_loss = 0.00010406522455830744
Trained batch 196 in epoch 6, gen_loss = 1.5228578445269976, disc_loss = 0.00010388389530120095
Trained batch 197 in epoch 6, gen_loss = 1.522959205237302, disc_loss = 0.00010371286653668968
Trained batch 198 in epoch 6, gen_loss = 1.523051870528178, disc_loss = 0.00010353910863099985
Trained batch 199 in epoch 6, gen_loss = 1.5233044826984405, disc_loss = 0.00010348158863052958
Trained batch 200 in epoch 6, gen_loss = 1.5232834234759582, disc_loss = 0.0001034403324578379
Trained batch 201 in epoch 6, gen_loss = 1.5234663575002463, disc_loss = 0.00010350115546388413
Trained batch 202 in epoch 6, gen_loss = 1.5230527599456862, disc_loss = 0.0001039951187033743
Trained batch 203 in epoch 6, gen_loss = 1.5228331749345743, disc_loss = 0.00010416378894411074
Trained batch 204 in epoch 6, gen_loss = 1.5230678133848237, disc_loss = 0.00010417861556605914
Trained batch 205 in epoch 6, gen_loss = 1.52319865087861, disc_loss = 0.00010436271453356524
Trained batch 206 in epoch 6, gen_loss = 1.5231073386427285, disc_loss = 0.00010435332519965076
Trained batch 207 in epoch 6, gen_loss = 1.5231369504561791, disc_loss = 0.0001043778907282663
Trained batch 208 in epoch 6, gen_loss = 1.5229461780575473, disc_loss = 0.00010457203569476667
Trained batch 209 in epoch 6, gen_loss = 1.5227137809708005, disc_loss = 0.0001048228784514192
Trained batch 210 in epoch 6, gen_loss = 1.522716486623502, disc_loss = 0.00010487634137022349
Trained batch 211 in epoch 6, gen_loss = 1.5225563735332128, disc_loss = 0.00010498603952105184
Trained batch 212 in epoch 6, gen_loss = 1.5222623230705798, disc_loss = 0.00010517390353737417
Trained batch 213 in epoch 6, gen_loss = 1.5221789100459804, disc_loss = 0.00010526646931615449
Trained batch 214 in epoch 6, gen_loss = 1.5220221319863962, disc_loss = 0.00010518669445192181
Trained batch 215 in epoch 6, gen_loss = 1.5221977923755292, disc_loss = 0.00010532535543461563
Trained batch 216 in epoch 6, gen_loss = 1.5220162401550925, disc_loss = 0.0001052282546410307
Trained batch 217 in epoch 6, gen_loss = 1.5220229882712757, disc_loss = 0.00010505365651691495
Trained batch 218 in epoch 6, gen_loss = 1.5218594504273646, disc_loss = 0.00010488463676540972
Trained batch 219 in epoch 6, gen_loss = 1.5218934888189488, disc_loss = 0.0001046447872464672
Trained batch 220 in epoch 6, gen_loss = 1.5219689052029433, disc_loss = 0.00010448697495076182
Trained batch 221 in epoch 6, gen_loss = 1.5222294942752734, disc_loss = 0.00010626442727280428
Trained batch 222 in epoch 6, gen_loss = 1.5224276658130869, disc_loss = 0.00010729108996075399
Trained batch 223 in epoch 6, gen_loss = 1.5224684945174627, disc_loss = 0.00010760724593897717
Trained batch 224 in epoch 6, gen_loss = 1.5226152838601006, disc_loss = 0.00010767659890310218
Trained batch 225 in epoch 6, gen_loss = 1.5224729982097591, disc_loss = 0.00010764283752398549
Trained batch 226 in epoch 6, gen_loss = 1.522219380093041, disc_loss = 0.00010771190357601705
Trained batch 227 in epoch 6, gen_loss = 1.5222037387521643, disc_loss = 0.00010765845000972612
Trained batch 228 in epoch 6, gen_loss = 1.5220988447489177, disc_loss = 0.00010778263997180818
Trained batch 229 in epoch 6, gen_loss = 1.521791972803033, disc_loss = 0.00010803060026576176
Trained batch 230 in epoch 6, gen_loss = 1.521877402351016, disc_loss = 0.0001082477329633485
Trained batch 231 in epoch 6, gen_loss = 1.5220412036468243, disc_loss = 0.00010828308109796189
Trained batch 232 in epoch 6, gen_loss = 1.5218424894267397, disc_loss = 0.00010841578890193782
Trained batch 233 in epoch 6, gen_loss = 1.5219811955068865, disc_loss = 0.00010860067102948649
Trained batch 234 in epoch 6, gen_loss = 1.5220632142208992, disc_loss = 0.00010889320389090225
Trained batch 235 in epoch 6, gen_loss = 1.5221251188698461, disc_loss = 0.00010922702149709023
Trained batch 236 in epoch 6, gen_loss = 1.5224261691298666, disc_loss = 0.00010961503009527985
Trained batch 237 in epoch 6, gen_loss = 1.522420050216322, disc_loss = 0.00011012166220755433
Trained batch 238 in epoch 6, gen_loss = 1.5222219892126745, disc_loss = 0.00011084739173125382
Trained batch 239 in epoch 6, gen_loss = 1.522176556289196, disc_loss = 0.00011173009946408759
Trained batch 240 in epoch 6, gen_loss = 1.5224703589910293, disc_loss = 0.00011307872689079833
Trained batch 241 in epoch 6, gen_loss = 1.5225016193941605, disc_loss = 0.00011452765153261086
Trained batch 242 in epoch 6, gen_loss = 1.5223890964876967, disc_loss = 0.0001159925704248012
Trained batch 243 in epoch 6, gen_loss = 1.5223499546285535, disc_loss = 0.00011726898160528346
Trained batch 244 in epoch 6, gen_loss = 1.522555753162929, disc_loss = 0.00011829917636291333
Trained batch 245 in epoch 6, gen_loss = 1.5225807840262002, disc_loss = 0.00011885501092964238
Trained batch 246 in epoch 6, gen_loss = 1.5227185338132294, disc_loss = 0.00011909482695458284
Trained batch 247 in epoch 6, gen_loss = 1.5226763510896313, disc_loss = 0.00011906906488988053
Trained batch 248 in epoch 6, gen_loss = 1.5229772760207394, disc_loss = 0.0001193116515211903
Trained batch 249 in epoch 6, gen_loss = 1.523086404323578, disc_loss = 0.00011950661247828976
Trained batch 250 in epoch 6, gen_loss = 1.5228661764190492, disc_loss = 0.00011961200731144142
Trained batch 251 in epoch 6, gen_loss = 1.5231458729221707, disc_loss = 0.00011985892752630799
Trained batch 252 in epoch 6, gen_loss = 1.5232952790769192, disc_loss = 0.00012042928007827048
Trained batch 253 in epoch 6, gen_loss = 1.5232434178900531, disc_loss = 0.00012083320589011946
Trained batch 254 in epoch 6, gen_loss = 1.5232739378424252, disc_loss = 0.00012081490502026225
Trained batch 255 in epoch 6, gen_loss = 1.5232159979641438, disc_loss = 0.00012081486713100276
Trained batch 256 in epoch 6, gen_loss = 1.5232977560985876, disc_loss = 0.00012078722509132437
Trained batch 257 in epoch 6, gen_loss = 1.5230811464694118, disc_loss = 0.00012071313734807963
Trained batch 258 in epoch 6, gen_loss = 1.5231419083694693, disc_loss = 0.0001205567892316754
Trained batch 259 in epoch 6, gen_loss = 1.5231688586565164, disc_loss = 0.0001202203941479988
Trained batch 260 in epoch 6, gen_loss = 1.5231646810911625, disc_loss = 0.00011990830175452812
Trained batch 261 in epoch 6, gen_loss = 1.5230397281755927, disc_loss = 0.00011969512570778243
Trained batch 262 in epoch 6, gen_loss = 1.522820994427902, disc_loss = 0.00011948949298617774
Trained batch 263 in epoch 6, gen_loss = 1.5227825235236774, disc_loss = 0.00011923157607077772
Trained batch 264 in epoch 6, gen_loss = 1.522608201458769, disc_loss = 0.00011900905672107155
Trained batch 265 in epoch 6, gen_loss = 1.5226655131892155, disc_loss = 0.0001188411032145316
Trained batch 266 in epoch 6, gen_loss = 1.5224057101131825, disc_loss = 0.00011884358208545846
Trained batch 267 in epoch 6, gen_loss = 1.5223468720023312, disc_loss = 0.00011890583611412734
Trained batch 268 in epoch 6, gen_loss = 1.522528225161329, disc_loss = 0.00011906441537562505
Trained batch 269 in epoch 6, gen_loss = 1.522585380077362, disc_loss = 0.00011912801315635012
Trained batch 270 in epoch 6, gen_loss = 1.5225620190595788, disc_loss = 0.00011917414897105594
Trained batch 271 in epoch 6, gen_loss = 1.522544322644963, disc_loss = 0.00011913538512143372
Trained batch 272 in epoch 6, gen_loss = 1.5226482908367673, disc_loss = 0.00011901614324591846
Trained batch 273 in epoch 6, gen_loss = 1.5226515340108941, disc_loss = 0.00011882074333671701
Trained batch 274 in epoch 6, gen_loss = 1.5228167429837314, disc_loss = 0.00011870467197943733
Trained batch 275 in epoch 6, gen_loss = 1.5228275233420774, disc_loss = 0.00011867743952293033
Trained batch 276 in epoch 6, gen_loss = 1.5228419071500483, disc_loss = 0.00011856338814952048
Trained batch 277 in epoch 6, gen_loss = 1.522983377357181, disc_loss = 0.00011834419543813854
Trained batch 278 in epoch 6, gen_loss = 1.5229361595646027, disc_loss = 0.0001181510090525429
Trained batch 279 in epoch 6, gen_loss = 1.5228076883724757, disc_loss = 0.00011797615674627846
Trained batch 280 in epoch 6, gen_loss = 1.5226540383070812, disc_loss = 0.0001177759230266544
Trained batch 281 in epoch 6, gen_loss = 1.5225496030022911, disc_loss = 0.00011750581717211092
Trained batch 282 in epoch 6, gen_loss = 1.5225936250214862, disc_loss = 0.00011730071738728013
Trained batch 283 in epoch 6, gen_loss = 1.5226878057902968, disc_loss = 0.00011712942187828881
Trained batch 284 in epoch 6, gen_loss = 1.5227613578762924, disc_loss = 0.0001168633784497312
Trained batch 285 in epoch 6, gen_loss = 1.5226773044446131, disc_loss = 0.00011661163071230285
Trained batch 286 in epoch 6, gen_loss = 1.5226904058290276, disc_loss = 0.00011644794974337779
Trained batch 287 in epoch 6, gen_loss = 1.522820549706618, disc_loss = 0.00011620893078795941
Trained batch 288 in epoch 6, gen_loss = 1.5228104426374072, disc_loss = 0.00011601638141082951
Trained batch 289 in epoch 6, gen_loss = 1.5226638859715955, disc_loss = 0.00011582464118466054
Trained batch 290 in epoch 6, gen_loss = 1.5227817063479079, disc_loss = 0.00011562602954542207
Trained batch 291 in epoch 6, gen_loss = 1.5230972677061003, disc_loss = 0.00011549862930933907
Trained batch 292 in epoch 6, gen_loss = 1.5230218566725278, disc_loss = 0.00011534935929562177
Trained batch 293 in epoch 6, gen_loss = 1.5230694307761938, disc_loss = 0.00011528026986531406
Trained batch 294 in epoch 6, gen_loss = 1.5230653694120504, disc_loss = 0.00011522382304419654
Trained batch 295 in epoch 6, gen_loss = 1.522848246065346, disc_loss = 0.00011521518032119225
Trained batch 296 in epoch 6, gen_loss = 1.5226925230186796, disc_loss = 0.00011517865815445285
Trained batch 297 in epoch 6, gen_loss = 1.5227108481746392, disc_loss = 0.00011514900229760327
Trained batch 298 in epoch 6, gen_loss = 1.5226983752936425, disc_loss = 0.00011529754911530701
Trained batch 299 in epoch 6, gen_loss = 1.5225770457585652, disc_loss = 0.00011528667484526522
Trained batch 300 in epoch 6, gen_loss = 1.522578054092255, disc_loss = 0.0001152393464586911
Trained batch 301 in epoch 6, gen_loss = 1.522684420181426, disc_loss = 0.00011508486178045975
Trained batch 302 in epoch 6, gen_loss = 1.5226588563950543, disc_loss = 0.00011498978972475723
Trained batch 303 in epoch 6, gen_loss = 1.5226766216127496, disc_loss = 0.00011497483331511735
Trained batch 304 in epoch 6, gen_loss = 1.522554609032928, disc_loss = 0.00011499829928592978
Trained batch 305 in epoch 6, gen_loss = 1.5223549023952359, disc_loss = 0.0001150916349395784
Trained batch 306 in epoch 6, gen_loss = 1.5224535970035515, disc_loss = 0.00011507049674552741
Trained batch 307 in epoch 6, gen_loss = 1.522302162724656, disc_loss = 0.00011486870174282215
Trained batch 308 in epoch 6, gen_loss = 1.5223897672393947, disc_loss = 0.0001147178226785582
Trained batch 309 in epoch 6, gen_loss = 1.522184323110888, disc_loss = 0.0001146682552996114
Trained batch 310 in epoch 6, gen_loss = 1.5222411420184316, disc_loss = 0.00011460111676324143
Trained batch 311 in epoch 6, gen_loss = 1.522184892724722, disc_loss = 0.00011470361705972046
Trained batch 312 in epoch 6, gen_loss = 1.5220641537596242, disc_loss = 0.00011480609980401042
Trained batch 313 in epoch 6, gen_loss = 1.5219802719772242, disc_loss = 0.00011488193437109692
Trained batch 314 in epoch 6, gen_loss = 1.5219517715393551, disc_loss = 0.00011492564992208611
Trained batch 315 in epoch 6, gen_loss = 1.5219266761707355, disc_loss = 0.00011504006787721596
Trained batch 316 in epoch 6, gen_loss = 1.5219658865161498, disc_loss = 0.00011516362946245111
Trained batch 317 in epoch 6, gen_loss = 1.5217440495700956, disc_loss = 0.00011539994014832323
Trained batch 318 in epoch 6, gen_loss = 1.5217436780002798, disc_loss = 0.00011570410640152292
Trained batch 319 in epoch 6, gen_loss = 1.521884648501873, disc_loss = 0.00011605167500192693
Trained batch 320 in epoch 6, gen_loss = 1.5216702029712474, disc_loss = 0.00011639128078231835
Trained batch 321 in epoch 6, gen_loss = 1.5216196427434128, disc_loss = 0.00011644677026694429
Trained batch 322 in epoch 6, gen_loss = 1.5217293762939264, disc_loss = 0.0001164659479287512
Trained batch 323 in epoch 6, gen_loss = 1.5219487018055387, disc_loss = 0.00011638835379320274
Trained batch 324 in epoch 6, gen_loss = 1.5218962889451246, disc_loss = 0.00011626854385562742
Trained batch 325 in epoch 6, gen_loss = 1.5219123304987245, disc_loss = 0.00011619345095153953
Trained batch 326 in epoch 6, gen_loss = 1.5219024660390452, disc_loss = 0.0001160294284761224
Trained batch 327 in epoch 6, gen_loss = 1.5220159550265568, disc_loss = 0.00011582448767113397
Trained batch 328 in epoch 6, gen_loss = 1.5218800009202813, disc_loss = 0.00011565799592770524
Trained batch 329 in epoch 6, gen_loss = 1.5218053250601797, disc_loss = 0.00011549081100383773
Trained batch 330 in epoch 6, gen_loss = 1.521829788058186, disc_loss = 0.00011530628060240417
Trained batch 331 in epoch 6, gen_loss = 1.5217597226062454, disc_loss = 0.0001151039125954456
Trained batch 332 in epoch 6, gen_loss = 1.5218300783598386, disc_loss = 0.00011486988188226933
Trained batch 333 in epoch 6, gen_loss = 1.5219369998235188, disc_loss = 0.00011466382324770874
Trained batch 334 in epoch 6, gen_loss = 1.5218372658117494, disc_loss = 0.00011454509041678689
Trained batch 335 in epoch 6, gen_loss = 1.5218271112867765, disc_loss = 0.0001143809246340901
Trained batch 336 in epoch 6, gen_loss = 1.521703857342638, disc_loss = 0.0001142369031506965
Trained batch 337 in epoch 6, gen_loss = 1.521916514317665, disc_loss = 0.00011405834283264004
Trained batch 338 in epoch 6, gen_loss = 1.5217756015361235, disc_loss = 0.00011396478794133606
Trained batch 339 in epoch 6, gen_loss = 1.5217310915975009, disc_loss = 0.00011403281362564645
Trained batch 340 in epoch 6, gen_loss = 1.521649054068624, disc_loss = 0.00011417675488589187
Trained batch 341 in epoch 6, gen_loss = 1.5215403779208312, disc_loss = 0.00011427816480668111
Trained batch 342 in epoch 6, gen_loss = 1.521520288970658, disc_loss = 0.00011423670745286045
Trained batch 343 in epoch 6, gen_loss = 1.5214776323978292, disc_loss = 0.0001140678903560234
Trained batch 344 in epoch 6, gen_loss = 1.5214749249859132, disc_loss = 0.00011386665077146102
Trained batch 345 in epoch 6, gen_loss = 1.5216124664152288, disc_loss = 0.00011370463471394032
Trained batch 346 in epoch 6, gen_loss = 1.5214680288985414, disc_loss = 0.000113556644944199
Trained batch 347 in epoch 6, gen_loss = 1.5215915109234295, disc_loss = 0.00011345670397019405
Trained batch 348 in epoch 6, gen_loss = 1.5217069093682363, disc_loss = 0.00011337179982721844
Trained batch 349 in epoch 6, gen_loss = 1.5217307414327348, disc_loss = 0.00011332885067011895
Trained batch 350 in epoch 6, gen_loss = 1.5216509952844037, disc_loss = 0.00011332432561248217
Trained batch 351 in epoch 6, gen_loss = 1.5218327553434805, disc_loss = 0.00011328252462176765
Trained batch 352 in epoch 6, gen_loss = 1.521781597529187, disc_loss = 0.00011324273779686203
Trained batch 353 in epoch 6, gen_loss = 1.5217603623530285, disc_loss = 0.0001131450095929871
Trained batch 354 in epoch 6, gen_loss = 1.5217750112775346, disc_loss = 0.00011308945046859125
Trained batch 355 in epoch 6, gen_loss = 1.5217228910226501, disc_loss = 0.0001129802968034199
Trained batch 356 in epoch 6, gen_loss = 1.521606678388366, disc_loss = 0.00011282623911604835
Trained batch 357 in epoch 6, gen_loss = 1.5215225382890116, disc_loss = 0.00011264014473804741
Trained batch 358 in epoch 6, gen_loss = 1.521462875820468, disc_loss = 0.0001124242990044877
Trained batch 359 in epoch 6, gen_loss = 1.521547214521302, disc_loss = 0.00011221493026217408
Trained batch 360 in epoch 6, gen_loss = 1.5214546552325219, disc_loss = 0.00011202162866518701
Trained batch 361 in epoch 6, gen_loss = 1.521310292884131, disc_loss = 0.00011186456111277767
Trained batch 362 in epoch 6, gen_loss = 1.5211809019740292, disc_loss = 0.00011169217352850938
Trained batch 363 in epoch 6, gen_loss = 1.5210472558225905, disc_loss = 0.00011156925551064318
Trained batch 364 in epoch 6, gen_loss = 1.5208644347648097, disc_loss = 0.00011144607550742054
Trained batch 365 in epoch 6, gen_loss = 1.5207913798061226, disc_loss = 0.00011144459451236406
Trained batch 366 in epoch 6, gen_loss = 1.5207741536626374, disc_loss = 0.00011138123251073955
Trained batch 367 in epoch 6, gen_loss = 1.5208501122567966, disc_loss = 0.00011134118506600751
Trained batch 368 in epoch 6, gen_loss = 1.5208367852337639, disc_loss = 0.00011123128756369668
Trained batch 369 in epoch 6, gen_loss = 1.5207435952650534, disc_loss = 0.00011116282253784153
Trained batch 370 in epoch 6, gen_loss = 1.5207935449569374, disc_loss = 0.00011131742126164039
Trained batch 371 in epoch 6, gen_loss = 1.5207451267908978, disc_loss = 0.0001115766434879568
Trained batch 372 in epoch 6, gen_loss = 1.5207616528620989, disc_loss = 0.00011188240354941864
Trained batch 373 in epoch 6, gen_loss = 1.5207491360883663, disc_loss = 0.00011223538666353486
Trained batch 374 in epoch 6, gen_loss = 1.5208152713775636, disc_loss = 0.00011258825364833077
Trained batch 375 in epoch 6, gen_loss = 1.5208267655144347, disc_loss = 0.00011285370659452189
Trained batch 376 in epoch 6, gen_loss = 1.5207035250625813, disc_loss = 0.00011309036726115977
Trained batch 377 in epoch 6, gen_loss = 1.5206107282764698, disc_loss = 0.0001133057247171617
Trained batch 378 in epoch 6, gen_loss = 1.5205127390833832, disc_loss = 0.0001134905748890644
Trained batch 379 in epoch 6, gen_loss = 1.520530303842143, disc_loss = 0.00011364348239639137
Trained batch 380 in epoch 6, gen_loss = 1.52051088534628, disc_loss = 0.00011371921672604323
Trained batch 381 in epoch 6, gen_loss = 1.5204776063639456, disc_loss = 0.00011371598124604048
Trained batch 382 in epoch 6, gen_loss = 1.5204095852904158, disc_loss = 0.00011368617483058472
Trained batch 383 in epoch 6, gen_loss = 1.5203284205247958, disc_loss = 0.00011363663018452523
Trained batch 384 in epoch 6, gen_loss = 1.5203847978022191, disc_loss = 0.0001135895601148693
Trained batch 385 in epoch 6, gen_loss = 1.5205025895271895, disc_loss = 0.00011362197337001972
Trained batch 386 in epoch 6, gen_loss = 1.520368388764926, disc_loss = 0.00011359925245118956
Trained batch 387 in epoch 6, gen_loss = 1.5204260484459473, disc_loss = 0.00011346607027814204
Trained batch 388 in epoch 6, gen_loss = 1.5204648334140336, disc_loss = 0.00011331834969129342
Trained batch 389 in epoch 6, gen_loss = 1.5203950533500084, disc_loss = 0.00011320571058417837
Trained batch 390 in epoch 6, gen_loss = 1.5205191273213652, disc_loss = 0.00011308489395204283
Trained batch 391 in epoch 6, gen_loss = 1.5205022169619191, disc_loss = 0.00011302094670248394
Trained batch 392 in epoch 6, gen_loss = 1.5205388378550988, disc_loss = 0.00011298863606988961
Trained batch 393 in epoch 6, gen_loss = 1.5205289745693884, disc_loss = 0.00011296082106460273
Trained batch 394 in epoch 6, gen_loss = 1.5205030785331244, disc_loss = 0.00011297379514641612
Trained batch 395 in epoch 6, gen_loss = 1.520438893575861, disc_loss = 0.00011295230501443688
Trained batch 396 in epoch 6, gen_loss = 1.5202698647525508, disc_loss = 0.00011300543067382734
Trained batch 397 in epoch 6, gen_loss = 1.5204459392844731, disc_loss = 0.00011305343568481238
Trained batch 398 in epoch 6, gen_loss = 1.5204281003254099, disc_loss = 0.00011295410983887662
Trained batch 399 in epoch 6, gen_loss = 1.5202713140845299, disc_loss = 0.00011286367109278217
Trained batch 400 in epoch 6, gen_loss = 1.520176087531663, disc_loss = 0.0001127137561218971
Trained batch 401 in epoch 6, gen_loss = 1.5202332826989207, disc_loss = 0.00011261192339950876
Trained batch 402 in epoch 6, gen_loss = 1.5201714195625362, disc_loss = 0.00011247720070490636
Trained batch 403 in epoch 6, gen_loss = 1.5201979255912328, disc_loss = 0.00011231803507531133
Trained batch 404 in epoch 6, gen_loss = 1.5202070901423326, disc_loss = 0.00011218665924029609
Trained batch 405 in epoch 6, gen_loss = 1.5201406252795253, disc_loss = 0.00011205815403605238
Trained batch 406 in epoch 6, gen_loss = 1.520048589905591, disc_loss = 0.00011191788842159046
Trained batch 407 in epoch 6, gen_loss = 1.5200712035099666, disc_loss = 0.00011176341119304804
Trained batch 408 in epoch 6, gen_loss = 1.5200642367738384, disc_loss = 0.00011162221950513292
Trained batch 409 in epoch 6, gen_loss = 1.520093742812552, disc_loss = 0.00011144516247441061
Trained batch 410 in epoch 6, gen_loss = 1.5200421769543575, disc_loss = 0.00011138015530718526
Trained batch 411 in epoch 6, gen_loss = 1.5199657814595307, disc_loss = 0.00011132151974256046
Trained batch 412 in epoch 6, gen_loss = 1.519911726796887, disc_loss = 0.00011121336847854345
Trained batch 413 in epoch 6, gen_loss = 1.519940926256963, disc_loss = 0.00011107881588198847
Trained batch 414 in epoch 6, gen_loss = 1.5198803499520543, disc_loss = 0.00011088618042974183
Trained batch 415 in epoch 6, gen_loss = 1.5200382706064444, disc_loss = 0.00011076946870721607
Trained batch 416 in epoch 6, gen_loss = 1.520140620730192, disc_loss = 0.00011068861910624416
Trained batch 417 in epoch 6, gen_loss = 1.5202273891873337, disc_loss = 0.00011055428967230483
Trained batch 418 in epoch 6, gen_loss = 1.5201613891665293, disc_loss = 0.00011048348630640405
Trained batch 419 in epoch 6, gen_loss = 1.520141107979275, disc_loss = 0.00011039525841278235
Trained batch 420 in epoch 6, gen_loss = 1.5200749496949257, disc_loss = 0.0001103626199742318
Trained batch 421 in epoch 6, gen_loss = 1.5200170699454032, disc_loss = 0.00011034259234931071
Trained batch 422 in epoch 6, gen_loss = 1.519898991494596, disc_loss = 0.00011037168571449998
Trained batch 423 in epoch 6, gen_loss = 1.5200165740723879, disc_loss = 0.00011041468375861889
Trained batch 424 in epoch 6, gen_loss = 1.520050028071684, disc_loss = 0.00011051875812186421
Trained batch 425 in epoch 6, gen_loss = 1.5199866910495667, disc_loss = 0.00011066114221678494
Trained batch 426 in epoch 6, gen_loss = 1.5198399911719687, disc_loss = 0.00011081277883786925
Trained batch 427 in epoch 6, gen_loss = 1.5197756822421171, disc_loss = 0.00011098560036907231
Trained batch 428 in epoch 6, gen_loss = 1.5196582806971801, disc_loss = 0.0001111286593866909
Trained batch 429 in epoch 6, gen_loss = 1.5194443727648534, disc_loss = 0.00011124322897325497
Trained batch 430 in epoch 6, gen_loss = 1.5194871630303544, disc_loss = 0.00011130378065783943
Trained batch 431 in epoch 6, gen_loss = 1.519516772694058, disc_loss = 0.0001113652673312673
Trained batch 432 in epoch 6, gen_loss = 1.5194271888248365, disc_loss = 0.00011147853251976524
Trained batch 433 in epoch 6, gen_loss = 1.5192846032331615, disc_loss = 0.00011159265734257192
Trained batch 434 in epoch 6, gen_loss = 1.5192981506216114, disc_loss = 0.00011168155231581326
Trained batch 435 in epoch 6, gen_loss = 1.5192383147707773, disc_loss = 0.0001117400617675547
Trained batch 436 in epoch 6, gen_loss = 1.51909711759205, disc_loss = 0.00011179283987995806
Trained batch 437 in epoch 6, gen_loss = 1.5188844726510244, disc_loss = 0.00011186380374114312
Trained batch 438 in epoch 6, gen_loss = 1.518987018046455, disc_loss = 0.0001118404749639153
Trained batch 439 in epoch 6, gen_loss = 1.5190469487146898, disc_loss = 0.00011177112196078683
Trained batch 440 in epoch 6, gen_loss = 1.5189744907171547, disc_loss = 0.00011169946342956141
Trained batch 441 in epoch 6, gen_loss = 1.5190512624261605, disc_loss = 0.00011164110835055068
Trained batch 442 in epoch 6, gen_loss = 1.5190747373529265, disc_loss = 0.00011168551052907118
Trained batch 443 in epoch 6, gen_loss = 1.519122786081589, disc_loss = 0.00011173337384821639
Trained batch 444 in epoch 6, gen_loss = 1.519056522980165, disc_loss = 0.00011187601306252025
Trained batch 445 in epoch 6, gen_loss = 1.5189901817539881, disc_loss = 0.00011206913952076976
Trained batch 446 in epoch 6, gen_loss = 1.518930693067427, disc_loss = 0.00011228823671707314
Trained batch 447 in epoch 6, gen_loss = 1.518922676465341, disc_loss = 0.00011251780607933272
Trained batch 448 in epoch 6, gen_loss = 1.5188193204408234, disc_loss = 0.00011274746794598167
Trained batch 449 in epoch 6, gen_loss = 1.5187792796558803, disc_loss = 0.00011295280423332265
Trained batch 450 in epoch 6, gen_loss = 1.518817310322679, disc_loss = 0.00011307561653827528
Trained batch 451 in epoch 6, gen_loss = 1.5187113535615195, disc_loss = 0.00011310036074370403
Trained batch 452 in epoch 6, gen_loss = 1.518641540809446, disc_loss = 0.00011303854148988365
Trained batch 453 in epoch 6, gen_loss = 1.518738415535326, disc_loss = 0.00011296125210375198
Trained batch 454 in epoch 6, gen_loss = 1.51863632778545, disc_loss = 0.00011285473366305079
Trained batch 455 in epoch 6, gen_loss = 1.5185756976144356, disc_loss = 0.0001127377751257435
Trained batch 456 in epoch 6, gen_loss = 1.5184710291856227, disc_loss = 0.00011260959601606226
Trained batch 457 in epoch 6, gen_loss = 1.5185112596599295, disc_loss = 0.00011251690427132925
Trained batch 458 in epoch 6, gen_loss = 1.518539310540509, disc_loss = 0.0001124683419214729
Trained batch 459 in epoch 6, gen_loss = 1.5185851068600364, disc_loss = 0.00011239361569807997
Trained batch 460 in epoch 6, gen_loss = 1.5185450155150606, disc_loss = 0.00011231542511802993
Trained batch 461 in epoch 6, gen_loss = 1.5185168682238757, disc_loss = 0.00011217522345468436
Trained batch 462 in epoch 6, gen_loss = 1.5185359708691262, disc_loss = 0.00011204580890671521
Trained batch 463 in epoch 6, gen_loss = 1.5186233700349414, disc_loss = 0.00011190108352036923
Trained batch 464 in epoch 6, gen_loss = 1.5187452752103088, disc_loss = 0.00011175421258417128
Trained batch 465 in epoch 6, gen_loss = 1.5187391224337239, disc_loss = 0.00011162234756227706
Trained batch 466 in epoch 6, gen_loss = 1.5187075931969751, disc_loss = 0.00011149603485606403
Trained batch 467 in epoch 6, gen_loss = 1.5185559366503332, disc_loss = 0.00011135219845792197
Trained batch 468 in epoch 6, gen_loss = 1.518619493126615, disc_loss = 0.00011124136960358549
Trained batch 469 in epoch 6, gen_loss = 1.5187668703972026, disc_loss = 0.00011114369621320796
Trained batch 470 in epoch 6, gen_loss = 1.518793896758126, disc_loss = 0.00011101583475507785
Trained batch 471 in epoch 6, gen_loss = 1.5186743887804321, disc_loss = 0.00011087622512712773
Trained batch 472 in epoch 6, gen_loss = 1.5186777565998457, disc_loss = 0.00011071490874260724
Trained batch 473 in epoch 6, gen_loss = 1.5187269393904803, disc_loss = 0.00011053946829004432
Trained batch 474 in epoch 6, gen_loss = 1.5186761650286222, disc_loss = 0.0001103756103571198
Trained batch 475 in epoch 6, gen_loss = 1.5186462422378926, disc_loss = 0.00011022945430822267
Trained batch 476 in epoch 6, gen_loss = 1.5186612286157828, disc_loss = 0.000110074614534618
Trained batch 477 in epoch 6, gen_loss = 1.518544356443892, disc_loss = 0.00010991492287746449
Trained batch 478 in epoch 6, gen_loss = 1.518553929687293, disc_loss = 0.00010975431510598359
Trained batch 479 in epoch 6, gen_loss = 1.518523062268893, disc_loss = 0.00010959292786765218
Trained batch 480 in epoch 6, gen_loss = 1.5186471554940555, disc_loss = 0.00010945371109669764
Trained batch 481 in epoch 6, gen_loss = 1.5186432941325967, disc_loss = 0.00010928655703907352
Trained batch 482 in epoch 6, gen_loss = 1.518567769176965, disc_loss = 0.0001091239910030942
Trained batch 483 in epoch 6, gen_loss = 1.5186619379303672, disc_loss = 0.00010895826946865827
Trained batch 484 in epoch 6, gen_loss = 1.5186141144369067, disc_loss = 0.0001087876188433153
Trained batch 485 in epoch 6, gen_loss = 1.5186799320664426, disc_loss = 0.0001086343404588552
Trained batch 486 in epoch 6, gen_loss = 1.5187211734313495, disc_loss = 0.00010846073181387296
Trained batch 487 in epoch 6, gen_loss = 1.5188006829531466, disc_loss = 0.00010829334293747871
Trained batch 488 in epoch 6, gen_loss = 1.5186604636822254, disc_loss = 0.00010816889722423974
Trained batch 489 in epoch 6, gen_loss = 1.5187524669024408, disc_loss = 0.00010804252638731018
Trained batch 490 in epoch 6, gen_loss = 1.5187256853352253, disc_loss = 0.0001079033566749078
Trained batch 491 in epoch 6, gen_loss = 1.5188351477064737, disc_loss = 0.00010781924047626128
Trained batch 492 in epoch 6, gen_loss = 1.5188521831079138, disc_loss = 0.00010775744791450092
Trained batch 493 in epoch 6, gen_loss = 1.518752630422955, disc_loss = 0.00010772271102189693
Trained batch 494 in epoch 6, gen_loss = 1.5189195372841575, disc_loss = 0.0001078986196491792
Trained batch 495 in epoch 6, gen_loss = 1.5188742465069216, disc_loss = 0.00010792742813787152
Trained batch 496 in epoch 6, gen_loss = 1.518879236589735, disc_loss = 0.00010797435222652702
Trained batch 497 in epoch 6, gen_loss = 1.5189099797762062, disc_loss = 0.00010804823449210648
Trained batch 498 in epoch 6, gen_loss = 1.5188123439261336, disc_loss = 0.00010817133505895868
Trained batch 499 in epoch 6, gen_loss = 1.5188782773017884, disc_loss = 0.00010826665651984513
Trained batch 500 in epoch 6, gen_loss = 1.518975320928349, disc_loss = 0.00010838955235314331
Trained batch 501 in epoch 6, gen_loss = 1.5189074892921752, disc_loss = 0.00010851077179784378
Trained batch 502 in epoch 6, gen_loss = 1.518879740423047, disc_loss = 0.00010864981333840876
Trained batch 503 in epoch 6, gen_loss = 1.5189197865270434, disc_loss = 0.00010878337594649998
Trained batch 504 in epoch 6, gen_loss = 1.5188161982168065, disc_loss = 0.00010888830595534516
Trained batch 505 in epoch 6, gen_loss = 1.5188090174565674, disc_loss = 0.00010899229804233357
Trained batch 506 in epoch 6, gen_loss = 1.5187187081963354, disc_loss = 0.00010918763274335186
Trained batch 507 in epoch 6, gen_loss = 1.518762522325741, disc_loss = 0.00010934440785969468
Trained batch 508 in epoch 6, gen_loss = 1.518649053948333, disc_loss = 0.00010947357115979821
Trained batch 509 in epoch 6, gen_loss = 1.5186652856714584, disc_loss = 0.00010959009757475452
Trained batch 510 in epoch 6, gen_loss = 1.5186507837179821, disc_loss = 0.00010965575310633994
Trained batch 511 in epoch 6, gen_loss = 1.5186099144630134, disc_loss = 0.00010972612946602567
Trained batch 512 in epoch 6, gen_loss = 1.5185863804398922, disc_loss = 0.00010980216001199475
Trained batch 513 in epoch 6, gen_loss = 1.5186964769771591, disc_loss = 0.00010987304525104703
Trained batch 514 in epoch 6, gen_loss = 1.5187707363980487, disc_loss = 0.00011006570375949434
Trained batch 515 in epoch 6, gen_loss = 1.518740207418915, disc_loss = 0.0001103308916140651
Trained batch 516 in epoch 6, gen_loss = 1.5187704680736107, disc_loss = 0.00011052452246217162
Trained batch 517 in epoch 6, gen_loss = 1.518723426408289, disc_loss = 0.00011070958626569827
Trained batch 518 in epoch 6, gen_loss = 1.5187512916406913, disc_loss = 0.00011095693263158863
Trained batch 519 in epoch 6, gen_loss = 1.5187636813292136, disc_loss = 0.00011125518716513538
Trained batch 520 in epoch 6, gen_loss = 1.5188454849477464, disc_loss = 0.00011161716769747937
Trained batch 521 in epoch 6, gen_loss = 1.5188602113175667, disc_loss = 0.0001120185429900278
Trained batch 522 in epoch 6, gen_loss = 1.5187865566341188, disc_loss = 0.00011242284729095607
Trained batch 523 in epoch 6, gen_loss = 1.5187701537408902, disc_loss = 0.00011272381252221735
Trained batch 524 in epoch 6, gen_loss = 1.5186987104870024, disc_loss = 0.00011287961268819692
Trained batch 525 in epoch 6, gen_loss = 1.518712848084961, disc_loss = 0.00011296260226301021
Trained batch 526 in epoch 6, gen_loss = 1.5186479195697937, disc_loss = 0.00011299860472521396
Trained batch 527 in epoch 6, gen_loss = 1.5186898972500453, disc_loss = 0.00011302880604048507
Trained batch 528 in epoch 6, gen_loss = 1.5186901392242633, disc_loss = 0.00011299790201137822
Trained batch 529 in epoch 6, gen_loss = 1.5186513920999922, disc_loss = 0.0001130344671936363
Trained batch 530 in epoch 6, gen_loss = 1.5186718765176173, disc_loss = 0.00011312618242235146
Trained batch 531 in epoch 6, gen_loss = 1.5185473783123762, disc_loss = 0.00011333128417103772
Trained batch 532 in epoch 6, gen_loss = 1.5184754987595006, disc_loss = 0.00011357095930539684
Trained batch 533 in epoch 6, gen_loss = 1.5184386546692152, disc_loss = 0.00011382539281506032
Trained batch 534 in epoch 6, gen_loss = 1.518393944134222, disc_loss = 0.00011405612487034767
Trained batch 535 in epoch 6, gen_loss = 1.5182744253482392, disc_loss = 0.00011434091418017651
Trained batch 536 in epoch 6, gen_loss = 1.5182865089988353, disc_loss = 0.00011463208532741717
Trained batch 537 in epoch 6, gen_loss = 1.518349874640043, disc_loss = 0.00011488087512355828
Trained batch 538 in epoch 6, gen_loss = 1.5182906608192288, disc_loss = 0.00011509837410622233
Trained batch 539 in epoch 6, gen_loss = 1.518330525468897, disc_loss = 0.00011521805142735873
Trained batch 540 in epoch 6, gen_loss = 1.5182682220684622, disc_loss = 0.00011518610587940498
Trained batch 541 in epoch 6, gen_loss = 1.5183455688927006, disc_loss = 0.00011511228133065581
Trained batch 542 in epoch 6, gen_loss = 1.518372890918514, disc_loss = 0.00011504935443435211
Trained batch 543 in epoch 6, gen_loss = 1.518336846767103, disc_loss = 0.00011496030159672527
Trained batch 544 in epoch 6, gen_loss = 1.5182990268829766, disc_loss = 0.0001148137863519294
Trained batch 545 in epoch 6, gen_loss = 1.5183106767825592, disc_loss = 0.00011466608873475514
Trained batch 546 in epoch 6, gen_loss = 1.5182559790951242, disc_loss = 0.0001145323711227463
Trained batch 547 in epoch 6, gen_loss = 1.5181828504496246, disc_loss = 0.00011444036497605538
Trained batch 548 in epoch 6, gen_loss = 1.5182147799076713, disc_loss = 0.00011430734293041276
Trained batch 549 in epoch 6, gen_loss = 1.5182220753756437, disc_loss = 0.00011419855194452049
Trained batch 550 in epoch 6, gen_loss = 1.518292438962282, disc_loss = 0.00011405490695918485
Trained batch 551 in epoch 6, gen_loss = 1.5182799591102463, disc_loss = 0.00011392259612098249
Trained batch 552 in epoch 6, gen_loss = 1.5182653301232116, disc_loss = 0.00011380150490581474
Trained batch 553 in epoch 6, gen_loss = 1.5183307022824615, disc_loss = 0.00011371332545130554
Trained batch 554 in epoch 6, gen_loss = 1.518268809662209, disc_loss = 0.00011361865957345192
Trained batch 555 in epoch 6, gen_loss = 1.5183046726014118, disc_loss = 0.00011348687020989332
Trained batch 556 in epoch 6, gen_loss = 1.5181922878354412, disc_loss = 0.00011335278074219455
Trained batch 557 in epoch 6, gen_loss = 1.518167863823607, disc_loss = 0.00011321656390095979
Trained batch 558 in epoch 6, gen_loss = 1.518085205917495, disc_loss = 0.00011313085232552912
Trained batch 559 in epoch 6, gen_loss = 1.5180269162569726, disc_loss = 0.00011306637686954802
Trained batch 560 in epoch 6, gen_loss = 1.5179872145202282, disc_loss = 0.00011301235143802254
Trained batch 561 in epoch 6, gen_loss = 1.5179875514261238, disc_loss = 0.00011297479857253764
Trained batch 562 in epoch 6, gen_loss = 1.5179449732731334, disc_loss = 0.00011295816892445572
Trained batch 563 in epoch 6, gen_loss = 1.5179308363309143, disc_loss = 0.00011295747495389912
Trained batch 564 in epoch 6, gen_loss = 1.5179302460324449, disc_loss = 0.00011298370217792155
Trained batch 565 in epoch 6, gen_loss = 1.5179536256267832, disc_loss = 0.0001130157078841233
Trained batch 566 in epoch 6, gen_loss = 1.5179560573433233, disc_loss = 0.00011303203027444724
Trained batch 567 in epoch 6, gen_loss = 1.517922700500824, disc_loss = 0.00011306126699425259
Trained batch 568 in epoch 6, gen_loss = 1.517861669847123, disc_loss = 0.00011306908147229309
Trained batch 569 in epoch 6, gen_loss = 1.5178672098276909, disc_loss = 0.00011311297430917254
Trained batch 570 in epoch 6, gen_loss = 1.5178688762484416, disc_loss = 0.00011312922623962443
Trained batch 571 in epoch 6, gen_loss = 1.5178040935026182, disc_loss = 0.00011315894577304395
Trained batch 572 in epoch 6, gen_loss = 1.5177968688452224, disc_loss = 0.00011318546437724806
Trained batch 573 in epoch 6, gen_loss = 1.517635601530507, disc_loss = 0.00011318526691520864
Trained batch 574 in epoch 6, gen_loss = 1.517580250657123, disc_loss = 0.00011313091775620073
Trained batch 575 in epoch 6, gen_loss = 1.517663107977973, disc_loss = 0.0001131031981900479
Trained batch 576 in epoch 6, gen_loss = 1.5176861364672047, disc_loss = 0.00011301598642855693
Trained batch 577 in epoch 6, gen_loss = 1.517661912837243, disc_loss = 0.00011292711321330367
Trained batch 578 in epoch 6, gen_loss = 1.5176145266580665, disc_loss = 0.00011282678170669309
Trained batch 579 in epoch 6, gen_loss = 1.5175348279805019, disc_loss = 0.00011271318842396983
Trained batch 580 in epoch 6, gen_loss = 1.5175509467182389, disc_loss = 0.000112598123090839
Trained batch 581 in epoch 6, gen_loss = 1.5174933960757304, disc_loss = 0.000112490958008962
Trained batch 582 in epoch 6, gen_loss = 1.5174501128303044, disc_loss = 0.00011240029669985595
Trained batch 583 in epoch 6, gen_loss = 1.5174526355854452, disc_loss = 0.00011232413203599632
Trained batch 584 in epoch 6, gen_loss = 1.517455349620591, disc_loss = 0.0001122646387549551
Trained batch 585 in epoch 6, gen_loss = 1.5174385931711556, disc_loss = 0.0001121893630202827
Trained batch 586 in epoch 6, gen_loss = 1.517406253635985, disc_loss = 0.00011213377446061741
Trained batch 587 in epoch 6, gen_loss = 1.5173647239500163, disc_loss = 0.00011206551897928529
Trained batch 588 in epoch 6, gen_loss = 1.5172626439905734, disc_loss = 0.0001120007601937699
Trained batch 589 in epoch 6, gen_loss = 1.5171865376375488, disc_loss = 0.00011196748685398557
Trained batch 590 in epoch 6, gen_loss = 1.5172614480436555, disc_loss = 0.00011188776860349062
Trained batch 591 in epoch 6, gen_loss = 1.5172888368770883, disc_loss = 0.0001118081215613406
Trained batch 592 in epoch 6, gen_loss = 1.5172636088794238, disc_loss = 0.00011174964770568892
Trained batch 593 in epoch 6, gen_loss = 1.5173544251557551, disc_loss = 0.00011172633257772741
Trained batch 594 in epoch 6, gen_loss = 1.517331791925831, disc_loss = 0.00011167236084207509
Trained batch 595 in epoch 6, gen_loss = 1.5172603822394506, disc_loss = 0.0001116065486773654
Trained batch 596 in epoch 6, gen_loss = 1.5173894344662102, disc_loss = 0.00011156512101697017
Trained batch 597 in epoch 6, gen_loss = 1.5173770079644628, disc_loss = 0.00011158835831487413
Trained batch 598 in epoch 6, gen_loss = 1.5174736731836513, disc_loss = 0.00011168686954341697
Trained batch 599 in epoch 6, gen_loss = 1.5173799242575963, disc_loss = 0.00011178625933704704
Trained batch 600 in epoch 6, gen_loss = 1.5173245396669612, disc_loss = 0.00011180132741553859
Trained batch 601 in epoch 6, gen_loss = 1.5173249561525262, disc_loss = 0.00011181185120064804
Trained batch 602 in epoch 6, gen_loss = 1.5173585217192793, disc_loss = 0.00011184031981690076
Trained batch 603 in epoch 6, gen_loss = 1.5173084696397086, disc_loss = 0.00011187224849559936
Trained batch 604 in epoch 6, gen_loss = 1.5173495544874964, disc_loss = 0.00011185617718296242
Trained batch 605 in epoch 6, gen_loss = 1.5174537877438485, disc_loss = 0.00011190006424729188
Trained batch 606 in epoch 6, gen_loss = 1.5174894128639183, disc_loss = 0.00011197110451916133
Trained batch 607 in epoch 6, gen_loss = 1.5174075931702788, disc_loss = 0.00011209262857535482
Trained batch 608 in epoch 6, gen_loss = 1.5173596351213252, disc_loss = 0.0001121655995776431
Trained batch 609 in epoch 6, gen_loss = 1.5173488933531964, disc_loss = 0.0001122505830175751
Trained batch 610 in epoch 6, gen_loss = 1.5172681628974878, disc_loss = 0.00011241753503731482
Trained batch 611 in epoch 6, gen_loss = 1.5171393224226883, disc_loss = 0.00011268202355840081
Trained batch 612 in epoch 6, gen_loss = 1.5172556988761243, disc_loss = 0.00011302447760862991
Trained batch 613 in epoch 6, gen_loss = 1.5172982056676758, disc_loss = 0.00011342773386164445
Trained batch 614 in epoch 6, gen_loss = 1.517395278690307, disc_loss = 0.00011386697496333901
Trained batch 615 in epoch 6, gen_loss = 1.5173842937915356, disc_loss = 0.00011425234868204223
Trained batch 616 in epoch 6, gen_loss = 1.5174678662607697, disc_loss = 0.00011460161239243297
Trained batch 617 in epoch 6, gen_loss = 1.5174306737180667, disc_loss = 0.00011483531952203624
Trained batch 618 in epoch 6, gen_loss = 1.5173839488591825, disc_loss = 0.0001149275165763725
Trained batch 619 in epoch 6, gen_loss = 1.5174394242225155, disc_loss = 0.00011502113836961085
Trained batch 620 in epoch 6, gen_loss = 1.5173966865416695, disc_loss = 0.00011518124966128
Trained batch 621 in epoch 6, gen_loss = 1.5174103823888723, disc_loss = 0.00011538743422262055
Trained batch 622 in epoch 6, gen_loss = 1.517379626225124, disc_loss = 0.0001156529584159289
Trained batch 623 in epoch 6, gen_loss = 1.5174170247255228, disc_loss = 0.00011600903648729563
Trained batch 624 in epoch 6, gen_loss = 1.5174037498474122, disc_loss = 0.00011647187292692251
Trained batch 625 in epoch 6, gen_loss = 1.5174157733734424, disc_loss = 0.00011704871786306217
Trained batch 626 in epoch 6, gen_loss = 1.517299553233851, disc_loss = 0.00011766741427068786
Trained batch 627 in epoch 6, gen_loss = 1.5173127909374844, disc_loss = 0.00011824219190938417
Trained batch 628 in epoch 6, gen_loss = 1.517360237709858, disc_loss = 0.00011877126536382597
Trained batch 629 in epoch 6, gen_loss = 1.5173162967439682, disc_loss = 0.00011915959538970446
Trained batch 630 in epoch 6, gen_loss = 1.5172376141495258, disc_loss = 0.00011942563131205308
Trained batch 631 in epoch 6, gen_loss = 1.5171979673301117, disc_loss = 0.00011956713812156246
Trained batch 632 in epoch 6, gen_loss = 1.5172446608355072, disc_loss = 0.00011963195899192657
Trained batch 633 in epoch 6, gen_loss = 1.5172049121149707, disc_loss = 0.00011963471046018917
Trained batch 634 in epoch 6, gen_loss = 1.5171531973861334, disc_loss = 0.00011958083390294002
Trained batch 635 in epoch 6, gen_loss = 1.5171011673204553, disc_loss = 0.0001195197233561124
Trained batch 636 in epoch 6, gen_loss = 1.517198833977596, disc_loss = 0.00011945425253393446
Trained batch 637 in epoch 6, gen_loss = 1.5171822647689652, disc_loss = 0.00011933852975718571
Trained batch 638 in epoch 6, gen_loss = 1.5171728622932017, disc_loss = 0.0001192119295107356
Trained batch 639 in epoch 6, gen_loss = 1.5172090454027056, disc_loss = 0.0001190969431661415
Trained batch 640 in epoch 6, gen_loss = 1.5172730200748177, disc_loss = 0.00011897571765050015
Trained batch 641 in epoch 6, gen_loss = 1.5172701942215086, disc_loss = 0.00011883242124521334
Trained batch 642 in epoch 6, gen_loss = 1.517230730776097, disc_loss = 0.00011870331299705952
Trained batch 643 in epoch 6, gen_loss = 1.517149692921905, disc_loss = 0.0001185792743797618
Trained batch 644 in epoch 6, gen_loss = 1.5170475854430088, disc_loss = 0.00011845462697322567
Trained batch 645 in epoch 6, gen_loss = 1.5170210520549456, disc_loss = 0.00011832016571697018
Trained batch 646 in epoch 6, gen_loss = 1.517002427964896, disc_loss = 0.00011821620899655279
Trained batch 647 in epoch 6, gen_loss = 1.5169176310300827, disc_loss = 0.00011814358782026425
Trained batch 648 in epoch 6, gen_loss = 1.516929416884259, disc_loss = 0.00011813862430470248
Trained batch 649 in epoch 6, gen_loss = 1.5169341356937702, disc_loss = 0.00011812597415812958
Trained batch 650 in epoch 6, gen_loss = 1.5168835450244207, disc_loss = 0.00011806208038366058
Trained batch 651 in epoch 6, gen_loss = 1.5168784491123597, disc_loss = 0.00011803961944924538
Trained batch 652 in epoch 6, gen_loss = 1.516837359387513, disc_loss = 0.00011801518766643768
Trained batch 653 in epoch 6, gen_loss = 1.5168407683343332, disc_loss = 0.00011793126305672042
Trained batch 654 in epoch 6, gen_loss = 1.516784846509686, disc_loss = 0.00011781685837217472
Trained batch 655 in epoch 6, gen_loss = 1.5167088666703643, disc_loss = 0.00011769422318560296
Trained batch 656 in epoch 6, gen_loss = 1.516827142946252, disc_loss = 0.00011763193840956559
Trained batch 657 in epoch 6, gen_loss = 1.5168888139507328, disc_loss = 0.00011757481090204668
Trained batch 658 in epoch 6, gen_loss = 1.5167880302495769, disc_loss = 0.0001174376304005679
Trained batch 659 in epoch 6, gen_loss = 1.5167624634323698, disc_loss = 0.00011737319757340821
Trained batch 660 in epoch 6, gen_loss = 1.5167895876513666, disc_loss = 0.00011726263212766562
Trained batch 661 in epoch 6, gen_loss = 1.5168204384988169, disc_loss = 0.00011713525952206463
Trained batch 662 in epoch 6, gen_loss = 1.5167808949857455, disc_loss = 0.00011706978066107623
Trained batch 663 in epoch 6, gen_loss = 1.5166670701589928, disc_loss = 0.00011698137011508043
Trained batch 664 in epoch 6, gen_loss = 1.5167822628092944, disc_loss = 0.00011709497244135806
Trained batch 665 in epoch 6, gen_loss = 1.5167263484931923, disc_loss = 0.00011729760652295434
Trained batch 666 in epoch 6, gen_loss = 1.5166617605103545, disc_loss = 0.0001175275185772719
Trained batch 667 in epoch 6, gen_loss = 1.5167373989870447, disc_loss = 0.00011750448951617924
Trained batch 668 in epoch 6, gen_loss = 1.516630673265956, disc_loss = 0.00011761901789542875
Trained batch 669 in epoch 6, gen_loss = 1.5166646699407207, disc_loss = 0.00011816281711712216
Trained batch 670 in epoch 6, gen_loss = 1.5165567115593241, disc_loss = 0.00011855957265771529
Trained batch 671 in epoch 6, gen_loss = 1.5166192054748535, disc_loss = 0.0001186398808927368
Trained batch 672 in epoch 6, gen_loss = 1.5166483304475782, disc_loss = 0.00011867983256981128
Trained batch 673 in epoch 6, gen_loss = 1.5167253535649896, disc_loss = 0.00011870596614724663
Trained batch 674 in epoch 6, gen_loss = 1.5167827392507482, disc_loss = 0.00011868686367826605
Trained batch 675 in epoch 6, gen_loss = 1.5168659205620105, disc_loss = 0.00011864075824536022
Trained batch 676 in epoch 6, gen_loss = 1.5168384012478668, disc_loss = 0.00011859924461196646
Trained batch 677 in epoch 6, gen_loss = 1.5167977799356511, disc_loss = 0.00011863935511980954
Trained batch 678 in epoch 6, gen_loss = 1.5168682656337305, disc_loss = 0.00011858181947439673
Trained batch 679 in epoch 6, gen_loss = 1.5168923406039967, disc_loss = 0.0001186800509244409
Trained batch 680 in epoch 6, gen_loss = 1.516953199620464, disc_loss = 0.00011888044086170742
Trained batch 681 in epoch 6, gen_loss = 1.5170030322941868, disc_loss = 0.00011886788567002724
Trained batch 682 in epoch 6, gen_loss = 1.517003571131917, disc_loss = 0.0001187909322573993
Trained batch 683 in epoch 6, gen_loss = 1.5168972607941655, disc_loss = 0.00011881419305338345
Trained batch 684 in epoch 6, gen_loss = 1.5169347263600705, disc_loss = 0.00011912278816559399
Trained batch 685 in epoch 6, gen_loss = 1.5169389327830545, disc_loss = 0.00011960159480312443
Trained batch 686 in epoch 6, gen_loss = 1.516891091671573, disc_loss = 0.0001198322371731538
Trained batch 687 in epoch 6, gen_loss = 1.516838358758494, disc_loss = 0.00011986224439338954
Trained batch 688 in epoch 6, gen_loss = 1.5168303009041508, disc_loss = 0.00011988924770630863
Trained batch 689 in epoch 6, gen_loss = 1.5168470394784126, disc_loss = 0.0001198890690790469
Trained batch 690 in epoch 6, gen_loss = 1.5168826692183697, disc_loss = 0.00011986012068466255
Trained batch 691 in epoch 6, gen_loss = 1.5169640962099065, disc_loss = 0.00012012422577512648
Trained batch 692 in epoch 6, gen_loss = 1.5170006057056686, disc_loss = 0.00012016713040809296
Trained batch 693 in epoch 6, gen_loss = 1.517025699876571, disc_loss = 0.00012010195149235918
Trained batch 694 in epoch 6, gen_loss = 1.5170368232315392, disc_loss = 0.00011998882471992494
Trained batch 695 in epoch 6, gen_loss = 1.5169717727721423, disc_loss = 0.0001199273749038205
Trained batch 696 in epoch 6, gen_loss = 1.5169825610334595, disc_loss = 0.00011980610481776375
Trained batch 697 in epoch 6, gen_loss = 1.5169711808078952, disc_loss = 0.00011972726184613256
Trained batch 698 in epoch 6, gen_loss = 1.517031048329944, disc_loss = 0.00011970569485051021
Trained batch 699 in epoch 6, gen_loss = 1.5170723456995827, disc_loss = 0.00011972815690179622
Trained batch 700 in epoch 6, gen_loss = 1.5171242386060162, disc_loss = 0.0001197308905695209
Trained batch 701 in epoch 6, gen_loss = 1.517102298573551, disc_loss = 0.0001196689331340053
Trained batch 702 in epoch 6, gen_loss = 1.517024399376187, disc_loss = 0.00011956664126424005
Trained batch 703 in epoch 6, gen_loss = 1.5169501897286286, disc_loss = 0.00011951986076300355
Trained batch 704 in epoch 6, gen_loss = 1.5170173171564196, disc_loss = 0.00011950333159770288
Trained batch 705 in epoch 6, gen_loss = 1.5169286557365071, disc_loss = 0.00011958031019010573
Trained batch 706 in epoch 6, gen_loss = 1.5169094853219083, disc_loss = 0.00011970176330791942
Trained batch 707 in epoch 6, gen_loss = 1.516971979437575, disc_loss = 0.00011983264852522368
Trained batch 708 in epoch 6, gen_loss = 1.5169570439288915, disc_loss = 0.00011988834203178213
Trained batch 709 in epoch 6, gen_loss = 1.5168841066494794, disc_loss = 0.00011995438288349632
Trained batch 710 in epoch 6, gen_loss = 1.5169116751554144, disc_loss = 0.0001200128460436229
Trained batch 711 in epoch 6, gen_loss = 1.5169216158349863, disc_loss = 0.00012005623875155109
Trained batch 712 in epoch 6, gen_loss = 1.5169335581978776, disc_loss = 0.00012011405657408668
Trained batch 713 in epoch 6, gen_loss = 1.5169169790938455, disc_loss = 0.00012019894274387963
Trained batch 714 in epoch 6, gen_loss = 1.516861407239954, disc_loss = 0.0001202874081217443
Trained batch 715 in epoch 6, gen_loss = 1.5169100703140876, disc_loss = 0.00012034728779478971
Trained batch 716 in epoch 6, gen_loss = 1.5168710122381128, disc_loss = 0.00012039653337063759
Trained batch 717 in epoch 6, gen_loss = 1.5168226804573888, disc_loss = 0.00012045532670004999
Trained batch 718 in epoch 6, gen_loss = 1.5167865594007044, disc_loss = 0.00012045940748977401
Trained batch 719 in epoch 6, gen_loss = 1.5167382876078288, disc_loss = 0.00012047368145431391
Trained batch 720 in epoch 6, gen_loss = 1.5167490696940111, disc_loss = 0.00012047147523763883
Trained batch 721 in epoch 6, gen_loss = 1.5167997365513006, disc_loss = 0.00012038764574567735
Trained batch 722 in epoch 6, gen_loss = 1.5168618018201772, disc_loss = 0.00012032429137584215
Trained batch 723 in epoch 6, gen_loss = 1.516837130758644, disc_loss = 0.00012025880974027468
Trained batch 724 in epoch 6, gen_loss = 1.5168098954496712, disc_loss = 0.00012021536392396605
Trained batch 725 in epoch 6, gen_loss = 1.5167831684932236, disc_loss = 0.00012014447897115432
Trained batch 726 in epoch 6, gen_loss = 1.5167765679680825, disc_loss = 0.00012003891703161409
Trained batch 727 in epoch 6, gen_loss = 1.5167486927994005, disc_loss = 0.00011993262038171512
Trained batch 728 in epoch 6, gen_loss = 1.5167143683374664, disc_loss = 0.00011980658041933932
Trained batch 729 in epoch 6, gen_loss = 1.5166468481494957, disc_loss = 0.00011970162982360718
Trained batch 730 in epoch 6, gen_loss = 1.516616146313345, disc_loss = 0.0001195918693381469
Trained batch 731 in epoch 6, gen_loss = 1.516569904128059, disc_loss = 0.00011948618313779592
Trained batch 732 in epoch 6, gen_loss = 1.5165259813709442, disc_loss = 0.00011936509659693536
Trained batch 733 in epoch 6, gen_loss = 1.5164934080043346, disc_loss = 0.00011923882503931875
Trained batch 734 in epoch 6, gen_loss = 1.5164558858287578, disc_loss = 0.00011912908307409317
Trained batch 735 in epoch 6, gen_loss = 1.5163960532973642, disc_loss = 0.00011902016733183305
Trained batch 736 in epoch 6, gen_loss = 1.5164551456715392, disc_loss = 0.0001189083414388373
Trained batch 737 in epoch 6, gen_loss = 1.5163975349932828, disc_loss = 0.00011878012275386133
Trained batch 738 in epoch 6, gen_loss = 1.5162983079401824, disc_loss = 0.00011867691488749949
Trained batch 739 in epoch 6, gen_loss = 1.5162696203669985, disc_loss = 0.00011855134372691847
Trained batch 740 in epoch 6, gen_loss = 1.5162764750672417, disc_loss = 0.00011843501882811498
Trained batch 741 in epoch 6, gen_loss = 1.5161685370049387, disc_loss = 0.00011833047218129463
Trained batch 742 in epoch 6, gen_loss = 1.5161748380070579, disc_loss = 0.00011820545880002779
Trained batch 743 in epoch 6, gen_loss = 1.516150156015991, disc_loss = 0.00011808434167368853
Trained batch 744 in epoch 6, gen_loss = 1.5159797524445808, disc_loss = 0.00011810211022296567
Trained batch 745 in epoch 6, gen_loss = 1.516010072691511, disc_loss = 0.00011808547605319936
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 1.462522029876709, disc_loss = 0.00015457089466508478
Trained batch 1 in epoch 7, gen_loss = 1.5039957165718079, disc_loss = 0.00018226679094368592
Trained batch 2 in epoch 7, gen_loss = 1.4948574304580688, disc_loss = 0.00021204253910885504
Trained batch 3 in epoch 7, gen_loss = 1.498653382062912, disc_loss = 0.0002511617240088526
Trained batch 4 in epoch 7, gen_loss = 1.4977264165878297, disc_loss = 0.0002856212871847674
Trained batch 5 in epoch 7, gen_loss = 1.501423140366872, disc_loss = 0.00031667141350529465
Trained batch 6 in epoch 7, gen_loss = 1.498751163482666, disc_loss = 0.0003469293483898842
Trained batch 7 in epoch 7, gen_loss = 1.505737081170082, disc_loss = 0.00036982745041314047
Trained batch 8 in epoch 7, gen_loss = 1.507423374387953, disc_loss = 0.00038355231744288985
Trained batch 9 in epoch 7, gen_loss = 1.5054095387458801, disc_loss = 0.00039110907382564617
Trained batch 10 in epoch 7, gen_loss = 1.5087380842729048, disc_loss = 0.00039697308701844037
Trained batch 11 in epoch 7, gen_loss = 1.5095151563485463, disc_loss = 0.00040298184588512714
Trained batch 12 in epoch 7, gen_loss = 1.5124551424613366, disc_loss = 0.0004073416874654448
Trained batch 13 in epoch 7, gen_loss = 1.5129754032407488, disc_loss = 0.0004105535013617815
Trained batch 14 in epoch 7, gen_loss = 1.514594841003418, disc_loss = 0.00041187660050733633
Trained batch 15 in epoch 7, gen_loss = 1.5116050392389297, disc_loss = 0.0004102118355149287
Trained batch 16 in epoch 7, gen_loss = 1.5108826160430908, disc_loss = 0.00040362691010266324
Trained batch 17 in epoch 7, gen_loss = 1.5074660844273038, disc_loss = 0.00039246821122813143
Trained batch 18 in epoch 7, gen_loss = 1.5065650751716213, disc_loss = 0.00037756119165447
Trained batch 19 in epoch 7, gen_loss = 1.5072637498378754, disc_loss = 0.00036167112775729036
Trained batch 20 in epoch 7, gen_loss = 1.5103809379395985, disc_loss = 0.00034683273753173473
Trained batch 21 in epoch 7, gen_loss = 1.509060095657002, disc_loss = 0.00033272620137061244
Trained batch 22 in epoch 7, gen_loss = 1.5105120513750159, disc_loss = 0.0003199930093694053
Trained batch 23 in epoch 7, gen_loss = 1.5114779273668926, disc_loss = 0.00030754308939625236
Trained batch 24 in epoch 7, gen_loss = 1.5106333303451538, disc_loss = 0.0002960309007175965
Trained batch 25 in epoch 7, gen_loss = 1.5083069388683026, disc_loss = 0.0002862146780339222
Trained batch 26 in epoch 7, gen_loss = 1.507789271849173, disc_loss = 0.0002777027411529734
Trained batch 27 in epoch 7, gen_loss = 1.508540106671197, disc_loss = 0.00026949055070092854
Trained batch 28 in epoch 7, gen_loss = 1.5088788928656742, disc_loss = 0.00026133199803709807
Trained batch 29 in epoch 7, gen_loss = 1.5084556857744853, disc_loss = 0.00025380731149198253
Trained batch 30 in epoch 7, gen_loss = 1.5096110105514526, disc_loss = 0.0002467796457494842
Trained batch 31 in epoch 7, gen_loss = 1.509407252073288, disc_loss = 0.00024032246443539407
Trained batch 32 in epoch 7, gen_loss = 1.509063178842718, disc_loss = 0.00023437664315155638
Trained batch 33 in epoch 7, gen_loss = 1.5089570634505327, disc_loss = 0.00022886360415320857
Trained batch 34 in epoch 7, gen_loss = 1.5080451011657714, disc_loss = 0.00022395173556495658
Trained batch 35 in epoch 7, gen_loss = 1.5066046946578555, disc_loss = 0.00021984638275777493
Trained batch 36 in epoch 7, gen_loss = 1.506455940169257, disc_loss = 0.00021566872478492646
Trained batch 37 in epoch 7, gen_loss = 1.5065359379115857, disc_loss = 0.00021186857755214748
Trained batch 38 in epoch 7, gen_loss = 1.5068558148848705, disc_loss = 0.00020799231774267706
Trained batch 39 in epoch 7, gen_loss = 1.5072924673557282, disc_loss = 0.00020391295215631543
Trained batch 40 in epoch 7, gen_loss = 1.5058213036234787, disc_loss = 0.0001998224770653817
Trained batch 41 in epoch 7, gen_loss = 1.505246945789882, disc_loss = 0.00019600034348903655
Trained batch 42 in epoch 7, gen_loss = 1.5054118799608807, disc_loss = 0.0001925076418512279
Trained batch 43 in epoch 7, gen_loss = 1.504731833934784, disc_loss = 0.00018878921297403974
Trained batch 44 in epoch 7, gen_loss = 1.5031859238942464, disc_loss = 0.0001854708387933594
Trained batch 45 in epoch 7, gen_loss = 1.503880412682243, disc_loss = 0.00018193896389477786
Trained batch 46 in epoch 7, gen_loss = 1.5044932263962767, disc_loss = 0.00017864756378874015
Trained batch 47 in epoch 7, gen_loss = 1.5046090707182884, disc_loss = 0.00017545960986353748
Trained batch 48 in epoch 7, gen_loss = 1.5053950645485703, disc_loss = 0.00017234357471110974
Trained batch 49 in epoch 7, gen_loss = 1.5061624455451965, disc_loss = 0.00016942246667895234
Trained batch 50 in epoch 7, gen_loss = 1.506604182953928, disc_loss = 0.00016673024544491222
Trained batch 51 in epoch 7, gen_loss = 1.5065118670463562, disc_loss = 0.0001640526431681512
Trained batch 52 in epoch 7, gen_loss = 1.50735556854392, disc_loss = 0.00016157036345316984
Trained batch 53 in epoch 7, gen_loss = 1.5055882754149261, disc_loss = 0.0001594317095454985
Trained batch 54 in epoch 7, gen_loss = 1.5050069570541382, disc_loss = 0.0001575294023826824
Trained batch 55 in epoch 7, gen_loss = 1.5060850871460778, disc_loss = 0.00015588356931013031
Trained batch 56 in epoch 7, gen_loss = 1.5070907253968089, disc_loss = 0.00015463415072365918
Trained batch 57 in epoch 7, gen_loss = 1.5067575902774417, disc_loss = 0.0001533229652240748
Trained batch 58 in epoch 7, gen_loss = 1.5067333003221932, disc_loss = 0.00015244596385346703
Trained batch 59 in epoch 7, gen_loss = 1.5072496811548868, disc_loss = 0.0001514700096170903
Trained batch 60 in epoch 7, gen_loss = 1.5071715565978503, disc_loss = 0.00015026090748834262
Trained batch 61 in epoch 7, gen_loss = 1.5077365579143647, disc_loss = 0.00014913234263663218
Trained batch 62 in epoch 7, gen_loss = 1.5072762076816861, disc_loss = 0.00014765701731477517
Trained batch 63 in epoch 7, gen_loss = 1.5079019721597433, disc_loss = 0.00014600969674916087
Trained batch 64 in epoch 7, gen_loss = 1.5086746087441079, disc_loss = 0.00014437474072530256
Trained batch 65 in epoch 7, gen_loss = 1.5085948543115095, disc_loss = 0.00014248441733467519
Trained batch 66 in epoch 7, gen_loss = 1.509322056129797, disc_loss = 0.0001408105869284473
Trained batch 67 in epoch 7, gen_loss = 1.508810628862942, disc_loss = 0.0001394006633959447
Trained batch 68 in epoch 7, gen_loss = 1.5092207556185515, disc_loss = 0.00013864187251559653
Trained batch 69 in epoch 7, gen_loss = 1.508742506163461, disc_loss = 0.0001385454912451678
Trained batch 70 in epoch 7, gen_loss = 1.5090498991415535, disc_loss = 0.00013866428966600363
Trained batch 71 in epoch 7, gen_loss = 1.5086958756049473, disc_loss = 0.0001390368935921692
Trained batch 72 in epoch 7, gen_loss = 1.508975527057909, disc_loss = 0.00013979315571467017
Trained batch 73 in epoch 7, gen_loss = 1.5092329350677696, disc_loss = 0.0001409358101473363
Trained batch 74 in epoch 7, gen_loss = 1.5091976849238078, disc_loss = 0.0001420979386845526
Trained batch 75 in epoch 7, gen_loss = 1.508616223147041, disc_loss = 0.0001431279803048375
Trained batch 76 in epoch 7, gen_loss = 1.5092763451786784, disc_loss = 0.00014424919064875613
Trained batch 77 in epoch 7, gen_loss = 1.5090902967330737, disc_loss = 0.0001458009018722059
Trained batch 78 in epoch 7, gen_loss = 1.5083121544198146, disc_loss = 0.00014754481708223466
Trained batch 79 in epoch 7, gen_loss = 1.5077803239226342, disc_loss = 0.0001492351037768458
Trained batch 80 in epoch 7, gen_loss = 1.50761099362079, disc_loss = 0.00015049453858084213
Trained batch 81 in epoch 7, gen_loss = 1.5074513438271313, disc_loss = 0.00015123248324859406
Trained batch 82 in epoch 7, gen_loss = 1.507628416440573, disc_loss = 0.00015175488313462962
Trained batch 83 in epoch 7, gen_loss = 1.5076548003015064, disc_loss = 0.00015202528402369353
Trained batch 84 in epoch 7, gen_loss = 1.5075572266298183, disc_loss = 0.00015205103715261966
Trained batch 85 in epoch 7, gen_loss = 1.5078587282535643, disc_loss = 0.00015197439920167346
Trained batch 86 in epoch 7, gen_loss = 1.5080637671481605, disc_loss = 0.000151896770221774
Trained batch 87 in epoch 7, gen_loss = 1.507719961079684, disc_loss = 0.00015192000986727098
Trained batch 88 in epoch 7, gen_loss = 1.5079457692885667, disc_loss = 0.00015170747790537288
Trained batch 89 in epoch 7, gen_loss = 1.508412746588389, disc_loss = 0.00015140265077207005
Trained batch 90 in epoch 7, gen_loss = 1.5087896480665102, disc_loss = 0.0001512976376054192
Trained batch 91 in epoch 7, gen_loss = 1.5083665692287942, disc_loss = 0.0001507846179028211
Trained batch 92 in epoch 7, gen_loss = 1.5083222337948379, disc_loss = 0.00014999257725702915
Trained batch 93 in epoch 7, gen_loss = 1.507621298445032, disc_loss = 0.00014898512499519014
Trained batch 94 in epoch 7, gen_loss = 1.5077731358377557, disc_loss = 0.00014803303582946109
Trained batch 95 in epoch 7, gen_loss = 1.5075902690490086, disc_loss = 0.00014683532369493454
Trained batch 96 in epoch 7, gen_loss = 1.5069268143054135, disc_loss = 0.00014569144990410988
Trained batch 97 in epoch 7, gen_loss = 1.5063627082474378, disc_loss = 0.00014463056933371781
Trained batch 98 in epoch 7, gen_loss = 1.5071103187522503, disc_loss = 0.00014349677739385633
Trained batch 99 in epoch 7, gen_loss = 1.5064676868915559, disc_loss = 0.00014259737863540068
Trained batch 100 in epoch 7, gen_loss = 1.5067057550543606, disc_loss = 0.00014186217017010162
Trained batch 101 in epoch 7, gen_loss = 1.5071012471236436, disc_loss = 0.00014149734836203554
Trained batch 102 in epoch 7, gen_loss = 1.5076717925303191, disc_loss = 0.00014121427769177633
Trained batch 103 in epoch 7, gen_loss = 1.5084934395093184, disc_loss = 0.00014121008866123491
Trained batch 104 in epoch 7, gen_loss = 1.5082480839320591, disc_loss = 0.00014090517595052786
Trained batch 105 in epoch 7, gen_loss = 1.5081305683783766, disc_loss = 0.00014017549673090403
Trained batch 106 in epoch 7, gen_loss = 1.5083614175564775, disc_loss = 0.00013942248774455776
Trained batch 107 in epoch 7, gen_loss = 1.5076204869482253, disc_loss = 0.00013885353549388432
Trained batch 108 in epoch 7, gen_loss = 1.5072587531640989, disc_loss = 0.0001385057917396899
Trained batch 109 in epoch 7, gen_loss = 1.5069527073339983, disc_loss = 0.00013826183423423736
Trained batch 110 in epoch 7, gen_loss = 1.5070571867195335, disc_loss = 0.00013823188706114993
Trained batch 111 in epoch 7, gen_loss = 1.5067722797393799, disc_loss = 0.0001387687250209118
Trained batch 112 in epoch 7, gen_loss = 1.505882104941174, disc_loss = 0.00014021362741624595
Trained batch 113 in epoch 7, gen_loss = 1.5059120309980292, disc_loss = 0.00014228971430017273
Trained batch 114 in epoch 7, gen_loss = 1.5064729224080624, disc_loss = 0.000145047800960247
Trained batch 115 in epoch 7, gen_loss = 1.5057955610341038, disc_loss = 0.00014882437409173218
Trained batch 116 in epoch 7, gen_loss = 1.505762547509283, disc_loss = 0.00015352327892077694
Trained batch 117 in epoch 7, gen_loss = 1.5058562705072307, disc_loss = 0.0001586488798716731
Trained batch 118 in epoch 7, gen_loss = 1.5057833044468856, disc_loss = 0.00016354209416755768
Trained batch 119 in epoch 7, gen_loss = 1.5058975179990133, disc_loss = 0.0001678350867981256
Trained batch 120 in epoch 7, gen_loss = 1.5057140972988665, disc_loss = 0.0001713912478415536
Trained batch 121 in epoch 7, gen_loss = 1.5053992945639814, disc_loss = 0.0001740882524722647
Trained batch 122 in epoch 7, gen_loss = 1.5052393403479722, disc_loss = 0.0001758883838222137
Trained batch 123 in epoch 7, gen_loss = 1.505375974601315, disc_loss = 0.00017691098637148952
Trained batch 124 in epoch 7, gen_loss = 1.5050287981033326, disc_loss = 0.00017726345210394357
Trained batch 125 in epoch 7, gen_loss = 1.5050381355815463, disc_loss = 0.00017717515851155253
Trained batch 126 in epoch 7, gen_loss = 1.5047468153510506, disc_loss = 0.00017679717100290012
Trained batch 127 in epoch 7, gen_loss = 1.505139616318047, disc_loss = 0.00017593671999804883
Trained batch 128 in epoch 7, gen_loss = 1.5052021704902945, disc_loss = 0.00017484415150457333
Trained batch 129 in epoch 7, gen_loss = 1.5052567821282608, disc_loss = 0.00017402081017420503
Trained batch 130 in epoch 7, gen_loss = 1.50528154027371, disc_loss = 0.00017323332317122382
Trained batch 131 in epoch 7, gen_loss = 1.504814607627464, disc_loss = 0.00017232218461878912
Trained batch 132 in epoch 7, gen_loss = 1.5051708902631487, disc_loss = 0.00017131313180108467
Trained batch 133 in epoch 7, gen_loss = 1.5053357419682973, disc_loss = 0.00017045973478405955
Trained batch 134 in epoch 7, gen_loss = 1.5052394019232855, disc_loss = 0.00016953238808599524
Trained batch 135 in epoch 7, gen_loss = 1.5054926749537973, disc_loss = 0.00016844635511273844
Trained batch 136 in epoch 7, gen_loss = 1.505742099163306, disc_loss = 0.00016745249566846836
Trained batch 137 in epoch 7, gen_loss = 1.5056835957195447, disc_loss = 0.00016644279061227385
Trained batch 138 in epoch 7, gen_loss = 1.505566675028355, disc_loss = 0.00016557036675988082
Trained batch 139 in epoch 7, gen_loss = 1.5054126867226192, disc_loss = 0.0001649245533371868
Trained batch 140 in epoch 7, gen_loss = 1.5051086380126628, disc_loss = 0.00016433231020212118
Trained batch 141 in epoch 7, gen_loss = 1.5058345467271939, disc_loss = 0.00016747325641940542
Trained batch 142 in epoch 7, gen_loss = 1.5062206441705877, disc_loss = 0.00017263854578187463
Trained batch 143 in epoch 7, gen_loss = 1.506132191254033, disc_loss = 0.0001786209749070622
Trained batch 144 in epoch 7, gen_loss = 1.5062609269701202, disc_loss = 0.00018211800888821018
Trained batch 145 in epoch 7, gen_loss = 1.5061650088388625, disc_loss = 0.00018230379475725174
Trained batch 146 in epoch 7, gen_loss = 1.5065260963375067, disc_loss = 0.00018303498995146273
Trained batch 147 in epoch 7, gen_loss = 1.5063636254619908, disc_loss = 0.00018753950495453396
Trained batch 148 in epoch 7, gen_loss = 1.5064539605339102, disc_loss = 0.00019274199155232347
Trained batch 149 in epoch 7, gen_loss = 1.506754846572876, disc_loss = 0.00019470725071490355
Trained batch 150 in epoch 7, gen_loss = 1.5067707410711326, disc_loss = 0.0001952162011180941
Trained batch 151 in epoch 7, gen_loss = 1.5070986104638953, disc_loss = 0.00019607375934595583
Trained batch 152 in epoch 7, gen_loss = 1.5075615262673572, disc_loss = 0.00019642382039522274
Trained batch 153 in epoch 7, gen_loss = 1.5077008558558178, disc_loss = 0.00019646139229168168
Trained batch 154 in epoch 7, gen_loss = 1.5077911376953126, disc_loss = 0.00019713038720158604
Trained batch 155 in epoch 7, gen_loss = 1.5075318263127253, disc_loss = 0.00019867428728759525
Trained batch 156 in epoch 7, gen_loss = 1.50803382837089, disc_loss = 0.00020090737998080337
Trained batch 157 in epoch 7, gen_loss = 1.5085196676133554, disc_loss = 0.0002028283173371441
Trained batch 158 in epoch 7, gen_loss = 1.5087541469238088, disc_loss = 0.00020452962276324815
Trained batch 159 in epoch 7, gen_loss = 1.5089636653661729, disc_loss = 0.00020623223243774192
Trained batch 160 in epoch 7, gen_loss = 1.5087413817459012, disc_loss = 0.00020748817090330838
Trained batch 161 in epoch 7, gen_loss = 1.508793552716573, disc_loss = 0.00020878378068624038
Trained batch 162 in epoch 7, gen_loss = 1.5084446398027105, disc_loss = 0.00021038400265272131
Trained batch 163 in epoch 7, gen_loss = 1.5083692364576387, disc_loss = 0.000211502284101454
Trained batch 164 in epoch 7, gen_loss = 1.5083327640186657, disc_loss = 0.00021150465868369353
Trained batch 165 in epoch 7, gen_loss = 1.5083461870630104, disc_loss = 0.00021102355566906324
Trained batch 166 in epoch 7, gen_loss = 1.5083565654868851, disc_loss = 0.00021028016564883444
Trained batch 167 in epoch 7, gen_loss = 1.507960970912661, disc_loss = 0.00020946373590612937
Trained batch 168 in epoch 7, gen_loss = 1.5078323268326077, disc_loss = 0.00020866789929759922
Trained batch 169 in epoch 7, gen_loss = 1.5079826004364911, disc_loss = 0.00020793067446100074
Trained batch 170 in epoch 7, gen_loss = 1.5080814033921002, disc_loss = 0.0002070023367398082
Trained batch 171 in epoch 7, gen_loss = 1.5079939427763918, disc_loss = 0.00020611858401533155
Trained batch 172 in epoch 7, gen_loss = 1.5075264025285753, disc_loss = 0.00020517805407476152
Trained batch 173 in epoch 7, gen_loss = 1.507383225292995, disc_loss = 0.00020416811627189322
Trained batch 174 in epoch 7, gen_loss = 1.5075066859381538, disc_loss = 0.0002031636727042496
Trained batch 175 in epoch 7, gen_loss = 1.5077146806500175, disc_loss = 0.00020222133699379893
Trained batch 176 in epoch 7, gen_loss = 1.507576445401725, disc_loss = 0.0002012689910565324
Trained batch 177 in epoch 7, gen_loss = 1.5074657027641039, disc_loss = 0.00020041426009658118
Trained batch 178 in epoch 7, gen_loss = 1.5075120233290689, disc_loss = 0.0001996222867163135
Trained batch 179 in epoch 7, gen_loss = 1.5073992795414395, disc_loss = 0.00019896476832299313
Trained batch 180 in epoch 7, gen_loss = 1.507427336761306, disc_loss = 0.00019838125937382268
Trained batch 181 in epoch 7, gen_loss = 1.5073989603545639, disc_loss = 0.00019797049060218922
Trained batch 182 in epoch 7, gen_loss = 1.5072091889511692, disc_loss = 0.0001975241028476326
Trained batch 183 in epoch 7, gen_loss = 1.5075755799594133, disc_loss = 0.0001970951996198615
Trained batch 184 in epoch 7, gen_loss = 1.5075019862200763, disc_loss = 0.00019641119502626384
Trained batch 185 in epoch 7, gen_loss = 1.5074622496481864, disc_loss = 0.0001957848174937172
Trained batch 186 in epoch 7, gen_loss = 1.5073660038371774, disc_loss = 0.00019506977009695934
Trained batch 187 in epoch 7, gen_loss = 1.5072719499151757, disc_loss = 0.00019431352699184764
Trained batch 188 in epoch 7, gen_loss = 1.5072018601906993, disc_loss = 0.00019353079491694675
Trained batch 189 in epoch 7, gen_loss = 1.506974734758076, disc_loss = 0.0001927629562391973
Trained batch 190 in epoch 7, gen_loss = 1.506881173368524, disc_loss = 0.0001920428834380143
Trained batch 191 in epoch 7, gen_loss = 1.5067195470134418, disc_loss = 0.00019127928400545594
Trained batch 192 in epoch 7, gen_loss = 1.5067656188431182, disc_loss = 0.00019051234988894415
Trained batch 193 in epoch 7, gen_loss = 1.5065942707749986, disc_loss = 0.0001897584251750719
Trained batch 194 in epoch 7, gen_loss = 1.5064026416876377, disc_loss = 0.00018907096815289548
Trained batch 195 in epoch 7, gen_loss = 1.506410845688411, disc_loss = 0.00018847178316904394
Trained batch 196 in epoch 7, gen_loss = 1.5064690258297218, disc_loss = 0.00018787228671194475
Trained batch 197 in epoch 7, gen_loss = 1.5062026200872478, disc_loss = 0.00018733681557050934
Trained batch 198 in epoch 7, gen_loss = 1.5065368563685584, disc_loss = 0.00018694477169552172
Trained batch 199 in epoch 7, gen_loss = 1.5067190945148468, disc_loss = 0.00018665163006517104
Trained batch 200 in epoch 7, gen_loss = 1.5069410445085212, disc_loss = 0.0001863745608499079
Trained batch 201 in epoch 7, gen_loss = 1.5070998349992355, disc_loss = 0.00018608263500108577
Trained batch 202 in epoch 7, gen_loss = 1.5072459745876894, disc_loss = 0.0001857482058023621
Trained batch 203 in epoch 7, gen_loss = 1.5069864152693282, disc_loss = 0.00018542673790886743
Trained batch 204 in epoch 7, gen_loss = 1.5073363879831825, disc_loss = 0.00018523410629912667
Trained batch 205 in epoch 7, gen_loss = 1.5072684866710775, disc_loss = 0.0001850427327297845
Trained batch 206 in epoch 7, gen_loss = 1.507283692198675, disc_loss = 0.00018488778043785785
Trained batch 207 in epoch 7, gen_loss = 1.5072015948020494, disc_loss = 0.00018473131988755014
Trained batch 208 in epoch 7, gen_loss = 1.5073630342072848, disc_loss = 0.00018456586916222457
Trained batch 209 in epoch 7, gen_loss = 1.507431443532308, disc_loss = 0.00018442708657987947
Trained batch 210 in epoch 7, gen_loss = 1.5074066093182676, disc_loss = 0.00018428121025837357
Trained batch 211 in epoch 7, gen_loss = 1.5073769772952457, disc_loss = 0.00018421161775960464
Trained batch 212 in epoch 7, gen_loss = 1.5070506407061652, disc_loss = 0.00018427686342486387
Trained batch 213 in epoch 7, gen_loss = 1.506944252508823, disc_loss = 0.00018435142576372443
Trained batch 214 in epoch 7, gen_loss = 1.506749577854955, disc_loss = 0.00018439409918649945
Trained batch 215 in epoch 7, gen_loss = 1.50701812296002, disc_loss = 0.00018473884173781025
Trained batch 216 in epoch 7, gen_loss = 1.506907565802473, disc_loss = 0.00018497530133828246
Trained batch 217 in epoch 7, gen_loss = 1.5068524868116466, disc_loss = 0.00018504893176531027
Trained batch 218 in epoch 7, gen_loss = 1.5073012369408456, disc_loss = 0.0001853308910195669
Trained batch 219 in epoch 7, gen_loss = 1.507235051285137, disc_loss = 0.00018591145886933769
Trained batch 220 in epoch 7, gen_loss = 1.5071709382587968, disc_loss = 0.00018655026383693774
Trained batch 221 in epoch 7, gen_loss = 1.50703548418509, disc_loss = 0.0001871319384647634
Trained batch 222 in epoch 7, gen_loss = 1.507240123278357, disc_loss = 0.0001875622240532056
Trained batch 223 in epoch 7, gen_loss = 1.507172655314207, disc_loss = 0.0001879294160452056
Trained batch 224 in epoch 7, gen_loss = 1.5069982226689655, disc_loss = 0.0001881327170930389
Trained batch 225 in epoch 7, gen_loss = 1.5068280406757795, disc_loss = 0.00018818293131766346
Trained batch 226 in epoch 7, gen_loss = 1.5065989431305604, disc_loss = 0.00018811304182981425
Trained batch 227 in epoch 7, gen_loss = 1.5066227761276982, disc_loss = 0.00018791664791806078
Trained batch 228 in epoch 7, gen_loss = 1.5066169854334868, disc_loss = 0.00018759415071029583
Trained batch 229 in epoch 7, gen_loss = 1.5066662814306175, disc_loss = 0.00018718089097250333
Trained batch 230 in epoch 7, gen_loss = 1.5063727134233946, disc_loss = 0.0001867112696502918
Trained batch 231 in epoch 7, gen_loss = 1.506789718722475, disc_loss = 0.0001863225019531393
Trained batch 232 in epoch 7, gen_loss = 1.5065826034341248, disc_loss = 0.00018591275594178228
Trained batch 233 in epoch 7, gen_loss = 1.5066274705096188, disc_loss = 0.00018547190294569184
Trained batch 234 in epoch 7, gen_loss = 1.5066785442068222, disc_loss = 0.00018502206292667208
Trained batch 235 in epoch 7, gen_loss = 1.5066749019137884, disc_loss = 0.00018453774415104555
Trained batch 236 in epoch 7, gen_loss = 1.5067818863985407, disc_loss = 0.00018393652040102687
Trained batch 237 in epoch 7, gen_loss = 1.5067814633625896, disc_loss = 0.0001833445144065914
Trained batch 238 in epoch 7, gen_loss = 1.5068294642859423, disc_loss = 0.00018269565734040785
Trained batch 239 in epoch 7, gen_loss = 1.5066159814596176, disc_loss = 0.00018207770727561486
Trained batch 240 in epoch 7, gen_loss = 1.5066064230139324, disc_loss = 0.00018147875821775578
Trained batch 241 in epoch 7, gen_loss = 1.5065826271191116, disc_loss = 0.0001808813746592481
Trained batch 242 in epoch 7, gen_loss = 1.5067033595999573, disc_loss = 0.0001802708889437871
Trained batch 243 in epoch 7, gen_loss = 1.50656231162978, disc_loss = 0.00017971307485569298
Trained batch 244 in epoch 7, gen_loss = 1.5065364462988717, disc_loss = 0.00017911585904473715
Trained batch 245 in epoch 7, gen_loss = 1.5064445806712639, disc_loss = 0.00017856567721049408
Trained batch 246 in epoch 7, gen_loss = 1.5064214188077671, disc_loss = 0.00017807352156037803
Trained batch 247 in epoch 7, gen_loss = 1.506453511695708, disc_loss = 0.00017762382952007043
Trained batch 248 in epoch 7, gen_loss = 1.5064266096635994, disc_loss = 0.00017726912690076675
Trained batch 249 in epoch 7, gen_loss = 1.5063002371788026, disc_loss = 0.00017690769628825364
Trained batch 250 in epoch 7, gen_loss = 1.5062497787741551, disc_loss = 0.00017652597170492656
Trained batch 251 in epoch 7, gen_loss = 1.5061738571477314, disc_loss = 0.00017613274411136415
Trained batch 252 in epoch 7, gen_loss = 1.5064427225957275, disc_loss = 0.00017578228524596875
Trained batch 253 in epoch 7, gen_loss = 1.5066652560797262, disc_loss = 0.0001754740731800172
Trained batch 254 in epoch 7, gen_loss = 1.5068632107154996, disc_loss = 0.00017509210155563492
Trained batch 255 in epoch 7, gen_loss = 1.5072308857925236, disc_loss = 0.0001747975469399421
Trained batch 256 in epoch 7, gen_loss = 1.5070718735572428, disc_loss = 0.00017448592509507928
Trained batch 257 in epoch 7, gen_loss = 1.5070955878080323, disc_loss = 0.00017402610222960402
Trained batch 258 in epoch 7, gen_loss = 1.506826734450793, disc_loss = 0.0001736294351017321
Trained batch 259 in epoch 7, gen_loss = 1.5072072207927705, disc_loss = 0.00017325326745356925
Trained batch 260 in epoch 7, gen_loss = 1.5069387283361735, disc_loss = 0.0001729977912765413
Trained batch 261 in epoch 7, gen_loss = 1.5068925632775285, disc_loss = 0.0001727828421766709
Trained batch 262 in epoch 7, gen_loss = 1.5069659717182695, disc_loss = 0.00017264780673850638
Trained batch 263 in epoch 7, gen_loss = 1.506992861176982, disc_loss = 0.00017248778605486828
Trained batch 264 in epoch 7, gen_loss = 1.5070733502226057, disc_loss = 0.0001722039661920994
Trained batch 265 in epoch 7, gen_loss = 1.5071289395927487, disc_loss = 0.0001718676252890955
Trained batch 266 in epoch 7, gen_loss = 1.5067975690748807, disc_loss = 0.00017169208284998304
Trained batch 267 in epoch 7, gen_loss = 1.5067208605026132, disc_loss = 0.00017156236066539213
Trained batch 268 in epoch 7, gen_loss = 1.5065998375194223, disc_loss = 0.00017152391852728535
Trained batch 269 in epoch 7, gen_loss = 1.5065484868155585, disc_loss = 0.00017142637219270303
Trained batch 270 in epoch 7, gen_loss = 1.5063421215958261, disc_loss = 0.00017154373663254863
Trained batch 271 in epoch 7, gen_loss = 1.5064689692328959, disc_loss = 0.0001718233919251254
Trained batch 272 in epoch 7, gen_loss = 1.5063901654966585, disc_loss = 0.0001723226678389574
Trained batch 273 in epoch 7, gen_loss = 1.5062484828225018, disc_loss = 0.00017294241375021975
Trained batch 274 in epoch 7, gen_loss = 1.5061314400759611, disc_loss = 0.000173506100750687
Trained batch 275 in epoch 7, gen_loss = 1.5060835476370826, disc_loss = 0.00017407062224278428
Trained batch 276 in epoch 7, gen_loss = 1.5060615350193065, disc_loss = 0.00017453522937907543
Trained batch 277 in epoch 7, gen_loss = 1.506172577254206, disc_loss = 0.00017487016978409608
Trained batch 278 in epoch 7, gen_loss = 1.5062262067658072, disc_loss = 0.00017508931309634637
Trained batch 279 in epoch 7, gen_loss = 1.5062366617577416, disc_loss = 0.0001752025480982411
Trained batch 280 in epoch 7, gen_loss = 1.506044566419201, disc_loss = 0.00017520109795959247
Trained batch 281 in epoch 7, gen_loss = 1.5062520491315963, disc_loss = 0.00017513657054765412
Trained batch 282 in epoch 7, gen_loss = 1.5063560678765124, disc_loss = 0.00017501620289040918
Trained batch 283 in epoch 7, gen_loss = 1.5062988102436066, disc_loss = 0.00017478401246016418
Trained batch 284 in epoch 7, gen_loss = 1.5062541781810292, disc_loss = 0.00017446470326256913
Trained batch 285 in epoch 7, gen_loss = 1.5060744402291892, disc_loss = 0.00017411829333729395
Trained batch 286 in epoch 7, gen_loss = 1.5059202676866112, disc_loss = 0.00017371684445435537
Trained batch 287 in epoch 7, gen_loss = 1.5056815954546134, disc_loss = 0.00017342395842787382
Trained batch 288 in epoch 7, gen_loss = 1.5055638601210704, disc_loss = 0.000173123644930091
Trained batch 289 in epoch 7, gen_loss = 1.5057412011870022, disc_loss = 0.00017286590154354004
Trained batch 290 in epoch 7, gen_loss = 1.50586171617213, disc_loss = 0.0001726063975743382
Trained batch 291 in epoch 7, gen_loss = 1.5058501554678565, disc_loss = 0.00017227533934389725
Trained batch 292 in epoch 7, gen_loss = 1.5060351069876765, disc_loss = 0.0001719700744972662
Trained batch 293 in epoch 7, gen_loss = 1.5060815498942421, disc_loss = 0.0001716858408447782
Trained batch 294 in epoch 7, gen_loss = 1.50607946403956, disc_loss = 0.00017140066833605286
Trained batch 295 in epoch 7, gen_loss = 1.505904402684521, disc_loss = 0.0001711231699376898
Trained batch 296 in epoch 7, gen_loss = 1.5061010306933111, disc_loss = 0.00017090421911678474
Trained batch 297 in epoch 7, gen_loss = 1.505984860778655, disc_loss = 0.00017085287827468476
Trained batch 298 in epoch 7, gen_loss = 1.5058060633298944, disc_loss = 0.00017086733940378085
Trained batch 299 in epoch 7, gen_loss = 1.5057769556840261, disc_loss = 0.00017073734034662872
Trained batch 300 in epoch 7, gen_loss = 1.505750350777889, disc_loss = 0.00017057762994964498
Trained batch 301 in epoch 7, gen_loss = 1.505520552199408, disc_loss = 0.00017042464197998587
Trained batch 302 in epoch 7, gen_loss = 1.5056763612004396, disc_loss = 0.00017027506422555565
Trained batch 303 in epoch 7, gen_loss = 1.5055660695621842, disc_loss = 0.00017016799456900787
Trained batch 304 in epoch 7, gen_loss = 1.505571810534743, disc_loss = 0.0001700922911860274
Trained batch 305 in epoch 7, gen_loss = 1.5056896836929072, disc_loss = 0.00016997032914742687
Trained batch 306 in epoch 7, gen_loss = 1.5056140651920331, disc_loss = 0.00016983747916368743
Trained batch 307 in epoch 7, gen_loss = 1.5055207014083862, disc_loss = 0.0001697251353213581
Trained batch 308 in epoch 7, gen_loss = 1.5057748205067656, disc_loss = 0.0001696297526272435
Trained batch 309 in epoch 7, gen_loss = 1.5057477320394208, disc_loss = 0.0001696733804032368
Trained batch 310 in epoch 7, gen_loss = 1.5058029870894944, disc_loss = 0.00016982354634620926
Trained batch 311 in epoch 7, gen_loss = 1.5058079935037172, disc_loss = 0.00017002272632756407
Trained batch 312 in epoch 7, gen_loss = 1.5059192032098008, disc_loss = 0.00017029401053336618
Trained batch 313 in epoch 7, gen_loss = 1.5057955915760841, disc_loss = 0.00017058011419565237
Trained batch 314 in epoch 7, gen_loss = 1.5057264899450635, disc_loss = 0.00017081613590389245
Trained batch 315 in epoch 7, gen_loss = 1.5058302754842783, disc_loss = 0.00017106614519964096
Trained batch 316 in epoch 7, gen_loss = 1.5057578474189204, disc_loss = 0.0001714323013175807
Trained batch 317 in epoch 7, gen_loss = 1.5056926960465293, disc_loss = 0.00017189246573138202
Trained batch 318 in epoch 7, gen_loss = 1.5058399696708846, disc_loss = 0.00017230882602856023
Trained batch 319 in epoch 7, gen_loss = 1.5060569871217013, disc_loss = 0.00017262640137118978
Trained batch 320 in epoch 7, gen_loss = 1.5060265064239502, disc_loss = 0.00017292377325074966
Trained batch 321 in epoch 7, gen_loss = 1.5061051782613957, disc_loss = 0.00017312956104840126
Trained batch 322 in epoch 7, gen_loss = 1.5063625013127047, disc_loss = 0.00017332380790411727
Trained batch 323 in epoch 7, gen_loss = 1.5064048023871432, disc_loss = 0.0001735417422648346
Trained batch 324 in epoch 7, gen_loss = 1.5063399725693922, disc_loss = 0.00017380359185783443
Trained batch 325 in epoch 7, gen_loss = 1.5062549084973482, disc_loss = 0.00017402265094890382
Trained batch 326 in epoch 7, gen_loss = 1.506287770169226, disc_loss = 0.00017419515604886478
Trained batch 327 in epoch 7, gen_loss = 1.5060146988891974, disc_loss = 0.0001744811973688828
Trained batch 328 in epoch 7, gen_loss = 1.5060205908894178, disc_loss = 0.00017481499492458109
Trained batch 329 in epoch 7, gen_loss = 1.5061931718479504, disc_loss = 0.00017516243782059366
Trained batch 330 in epoch 7, gen_loss = 1.5063246776690296, disc_loss = 0.00017541002722458283
Trained batch 331 in epoch 7, gen_loss = 1.5064682364463806, disc_loss = 0.0001756574511036669
Trained batch 332 in epoch 7, gen_loss = 1.5063987522869855, disc_loss = 0.00017590805168424254
Trained batch 333 in epoch 7, gen_loss = 1.5062691308781058, disc_loss = 0.00017605630667216367
Trained batch 334 in epoch 7, gen_loss = 1.5061531173649119, disc_loss = 0.0001759992445175755
Trained batch 335 in epoch 7, gen_loss = 1.5060979880037761, disc_loss = 0.00017582140653649687
Trained batch 336 in epoch 7, gen_loss = 1.506118748237542, disc_loss = 0.00017554234734884751
Trained batch 337 in epoch 7, gen_loss = 1.506137833087402, disc_loss = 0.0001752066186378409
Trained batch 338 in epoch 7, gen_loss = 1.5060683288405428, disc_loss = 0.0001748804157093881
Trained batch 339 in epoch 7, gen_loss = 1.506126350515029, disc_loss = 0.00017456632474611124
Trained batch 340 in epoch 7, gen_loss = 1.5061527004689415, disc_loss = 0.00017420828662899937
Trained batch 341 in epoch 7, gen_loss = 1.506020278261419, disc_loss = 0.00017384007390994785
Trained batch 342 in epoch 7, gen_loss = 1.506081709013736, disc_loss = 0.0001734485624512232
Trained batch 343 in epoch 7, gen_loss = 1.5062516127214876, disc_loss = 0.00017309775305579403
Trained batch 344 in epoch 7, gen_loss = 1.5061166828957158, disc_loss = 0.00017272802483669206
Trained batch 345 in epoch 7, gen_loss = 1.5063313772912659, disc_loss = 0.00017243427737412276
Trained batch 346 in epoch 7, gen_loss = 1.5063889827096153, disc_loss = 0.00017206002722122078
Trained batch 347 in epoch 7, gen_loss = 1.5062958080878204, disc_loss = 0.00017165903565764055
Trained batch 348 in epoch 7, gen_loss = 1.5062064554083314, disc_loss = 0.00017129051866765198
Trained batch 349 in epoch 7, gen_loss = 1.5062112055506025, disc_loss = 0.00017090756832268588
Trained batch 350 in epoch 7, gen_loss = 1.506436575172294, disc_loss = 0.0001706391513366116
Trained batch 351 in epoch 7, gen_loss = 1.506301203573292, disc_loss = 0.00017037181875552548
Trained batch 352 in epoch 7, gen_loss = 1.5063202509461313, disc_loss = 0.00017020846088297326
Trained batch 353 in epoch 7, gen_loss = 1.5062086198289515, disc_loss = 0.0001700736038298606
Trained batch 354 in epoch 7, gen_loss = 1.5063479719027666, disc_loss = 0.00016984713042354126
Trained batch 355 in epoch 7, gen_loss = 1.5062695249412836, disc_loss = 0.00016953637910017768
Trained batch 356 in epoch 7, gen_loss = 1.5060233098118245, disc_loss = 0.00016925764656934662
Trained batch 357 in epoch 7, gen_loss = 1.5060226267942503, disc_loss = 0.000169062869492702
Trained batch 358 in epoch 7, gen_loss = 1.5058647981925264, disc_loss = 0.0001690826593707481
Trained batch 359 in epoch 7, gen_loss = 1.5059171117014356, disc_loss = 0.00016918151841815012
Trained batch 360 in epoch 7, gen_loss = 1.5059540942104899, disc_loss = 0.00016918534128209983
Trained batch 361 in epoch 7, gen_loss = 1.5060201926126007, disc_loss = 0.0001691744465958401
Trained batch 362 in epoch 7, gen_loss = 1.5061793461975643, disc_loss = 0.000169182879352657
Trained batch 363 in epoch 7, gen_loss = 1.5062102125241206, disc_loss = 0.00016915442328464342
Trained batch 364 in epoch 7, gen_loss = 1.5062553921790973, disc_loss = 0.00016908275006057485
Trained batch 365 in epoch 7, gen_loss = 1.5063440614059322, disc_loss = 0.00016896785521074904
Trained batch 366 in epoch 7, gen_loss = 1.5062648434729926, disc_loss = 0.00016885412265165177
Trained batch 367 in epoch 7, gen_loss = 1.5062704235315323, disc_loss = 0.00016876822471460954
Trained batch 368 in epoch 7, gen_loss = 1.5062294245412355, disc_loss = 0.00016872417988888334
Trained batch 369 in epoch 7, gen_loss = 1.5061302114177395, disc_loss = 0.00016865401537723154
Trained batch 370 in epoch 7, gen_loss = 1.5062123122562294, disc_loss = 0.00016857752259995636
Trained batch 371 in epoch 7, gen_loss = 1.506331507877637, disc_loss = 0.00016854696455035297
Trained batch 372 in epoch 7, gen_loss = 1.5063882046666286, disc_loss = 0.00016853388318967234
Trained batch 373 in epoch 7, gen_loss = 1.5064449718291746, disc_loss = 0.0001684818261538873
Trained batch 374 in epoch 7, gen_loss = 1.5065814832051596, disc_loss = 0.00016844585832344214
Trained batch 375 in epoch 7, gen_loss = 1.5064509222482114, disc_loss = 0.000168472188069574
Trained batch 376 in epoch 7, gen_loss = 1.5062158803408594, disc_loss = 0.00016872281448547982
Trained batch 377 in epoch 7, gen_loss = 1.5062480893715349, disc_loss = 0.00016904879280373858
Trained batch 378 in epoch 7, gen_loss = 1.50639932828717, disc_loss = 0.0001694154303972373
Trained batch 379 in epoch 7, gen_loss = 1.5062972467196616, disc_loss = 0.00016982523462789493
Trained batch 380 in epoch 7, gen_loss = 1.5063573222147824, disc_loss = 0.0001702605852588881
Trained batch 381 in epoch 7, gen_loss = 1.506509528734297, disc_loss = 0.00017070114813696717
Trained batch 382 in epoch 7, gen_loss = 1.50652643345666, disc_loss = 0.00017106277175719866
Trained batch 383 in epoch 7, gen_loss = 1.5065883643304308, disc_loss = 0.00017143199135697765
Trained batch 384 in epoch 7, gen_loss = 1.5065241816756014, disc_loss = 0.0001718247844865954
Trained batch 385 in epoch 7, gen_loss = 1.5065449748014539, disc_loss = 0.00017231625313260634
Trained batch 386 in epoch 7, gen_loss = 1.5063588372804706, disc_loss = 0.00017282344503140946
Trained batch 387 in epoch 7, gen_loss = 1.5062904738888299, disc_loss = 0.00017319419705074193
Trained batch 388 in epoch 7, gen_loss = 1.5063783068276924, disc_loss = 0.00017336937279695887
Trained batch 389 in epoch 7, gen_loss = 1.5065128405888875, disc_loss = 0.00017339095908634286
Trained batch 390 in epoch 7, gen_loss = 1.5065384502606014, disc_loss = 0.00017333923804476503
Trained batch 391 in epoch 7, gen_loss = 1.5065995007753372, disc_loss = 0.00017321174026137113
Trained batch 392 in epoch 7, gen_loss = 1.5066035412650072, disc_loss = 0.000173080283974239
Trained batch 393 in epoch 7, gen_loss = 1.5066098731181343, disc_loss = 0.00017298159530254993
Trained batch 394 in epoch 7, gen_loss = 1.5065851510325565, disc_loss = 0.00017288014418618676
Trained batch 395 in epoch 7, gen_loss = 1.5065050682034156, disc_loss = 0.00017279146161606397
Trained batch 396 in epoch 7, gen_loss = 1.5065429111571997, disc_loss = 0.00017275515037863098
Trained batch 397 in epoch 7, gen_loss = 1.5064387015960923, disc_loss = 0.00017279476487693047
Trained batch 398 in epoch 7, gen_loss = 1.5064647642890912, disc_loss = 0.00017281225336773787
Trained batch 399 in epoch 7, gen_loss = 1.5062928533554076, disc_loss = 0.00017285327734043677
Trained batch 400 in epoch 7, gen_loss = 1.5062985390499048, disc_loss = 0.0001729391996221175
Trained batch 401 in epoch 7, gen_loss = 1.5062524053587842, disc_loss = 0.00017304004637453682
Trained batch 402 in epoch 7, gen_loss = 1.506175323988013, disc_loss = 0.00017313233998521933
Trained batch 403 in epoch 7, gen_loss = 1.506274308013444, disc_loss = 0.00017320308052599148
Trained batch 404 in epoch 7, gen_loss = 1.5063496795701392, disc_loss = 0.00017326417596731192
Trained batch 405 in epoch 7, gen_loss = 1.5062321723975571, disc_loss = 0.00017331405034459515
Trained batch 406 in epoch 7, gen_loss = 1.5061769488402608, disc_loss = 0.00017334053955518977
Trained batch 407 in epoch 7, gen_loss = 1.5060611954506706, disc_loss = 0.00017341075471556585
Trained batch 408 in epoch 7, gen_loss = 1.5060429575973735, disc_loss = 0.00017349763469018975
Trained batch 409 in epoch 7, gen_loss = 1.50602998500917, disc_loss = 0.00017359385207183972
Trained batch 410 in epoch 7, gen_loss = 1.5061064450990254, disc_loss = 0.00017370860735370144
Trained batch 411 in epoch 7, gen_loss = 1.5061044235831325, disc_loss = 0.00017384788675062912
Trained batch 412 in epoch 7, gen_loss = 1.5061381807050174, disc_loss = 0.00017399580197232763
Trained batch 413 in epoch 7, gen_loss = 1.5060976654435125, disc_loss = 0.00017413526371535187
Trained batch 414 in epoch 7, gen_loss = 1.5060796392969338, disc_loss = 0.00017422973989640188
Trained batch 415 in epoch 7, gen_loss = 1.506172614888503, disc_loss = 0.00017434129769246563
Trained batch 416 in epoch 7, gen_loss = 1.5061835170649795, disc_loss = 0.00017442803699167962
Trained batch 417 in epoch 7, gen_loss = 1.5062331383308154, disc_loss = 0.00017448939617166077
Trained batch 418 in epoch 7, gen_loss = 1.5061399379038298, disc_loss = 0.00017454674676293925
Trained batch 419 in epoch 7, gen_loss = 1.5061196917579287, disc_loss = 0.00017454941426400355
Trained batch 420 in epoch 7, gen_loss = 1.5061099676508236, disc_loss = 0.00017451715849517904
Trained batch 421 in epoch 7, gen_loss = 1.5060875164389045, disc_loss = 0.00017442940955622848
Trained batch 422 in epoch 7, gen_loss = 1.5059526930464076, disc_loss = 0.00017432334110188
Trained batch 423 in epoch 7, gen_loss = 1.5059914054735652, disc_loss = 0.00017419909368244298
Trained batch 424 in epoch 7, gen_loss = 1.5059996896631578, disc_loss = 0.000174050783213769
Trained batch 425 in epoch 7, gen_loss = 1.5059543959971324, disc_loss = 0.00017385943035360513
Trained batch 426 in epoch 7, gen_loss = 1.5060396152581208, disc_loss = 0.0001736704698806796
Trained batch 427 in epoch 7, gen_loss = 1.5059706270694733, disc_loss = 0.00017347847586143386
Trained batch 428 in epoch 7, gen_loss = 1.5059104154715728, disc_loss = 0.0001732905323782082
Trained batch 429 in epoch 7, gen_loss = 1.5058419321858605, disc_loss = 0.0001731016833853277
Trained batch 430 in epoch 7, gen_loss = 1.5058220848959727, disc_loss = 0.00017290700492248552
Trained batch 431 in epoch 7, gen_loss = 1.5057692028306149, disc_loss = 0.0001727172580566966
Trained batch 432 in epoch 7, gen_loss = 1.5056632024861925, disc_loss = 0.00017257643493526754
Trained batch 433 in epoch 7, gen_loss = 1.5056138563265997, disc_loss = 0.00017243821342410127
Trained batch 434 in epoch 7, gen_loss = 1.505729132685168, disc_loss = 0.00017234911797511332
Trained batch 435 in epoch 7, gen_loss = 1.5058036214167918, disc_loss = 0.0001722601049709112
Trained batch 436 in epoch 7, gen_loss = 1.5058113260181871, disc_loss = 0.00017217461755458617
Trained batch 437 in epoch 7, gen_loss = 1.5058682677952666, disc_loss = 0.00017209692429359785
Trained batch 438 in epoch 7, gen_loss = 1.5056990876556258, disc_loss = 0.0001722474504123452
Trained batch 439 in epoch 7, gen_loss = 1.5057019978761672, disc_loss = 0.00017218172044770405
Trained batch 440 in epoch 7, gen_loss = 1.505617430150644, disc_loss = 0.00017215691742646563
Trained batch 441 in epoch 7, gen_loss = 1.5055612344547635, disc_loss = 0.00017210024715623396
Trained batch 442 in epoch 7, gen_loss = 1.5055935942561578, disc_loss = 0.00017197843567117008
Trained batch 443 in epoch 7, gen_loss = 1.5055776890870687, disc_loss = 0.0001717966618605977
Trained batch 444 in epoch 7, gen_loss = 1.5054531421554223, disc_loss = 0.0001716019072119615
Trained batch 445 in epoch 7, gen_loss = 1.505361298809137, disc_loss = 0.0001713797103878486
Trained batch 446 in epoch 7, gen_loss = 1.5053509273785073, disc_loss = 0.00017115661920689883
Trained batch 447 in epoch 7, gen_loss = 1.5053053045911449, disc_loss = 0.00017092570854515543
Trained batch 448 in epoch 7, gen_loss = 1.5053277390040374, disc_loss = 0.0001706848006080958
Trained batch 449 in epoch 7, gen_loss = 1.5053879960378012, disc_loss = 0.00017042069022863871
Trained batch 450 in epoch 7, gen_loss = 1.505489940125239, disc_loss = 0.00017016820721838704
Trained batch 451 in epoch 7, gen_loss = 1.505404366328653, disc_loss = 0.00016996980902495606
Trained batch 452 in epoch 7, gen_loss = 1.5053285662964744, disc_loss = 0.00016980738434297466
Trained batch 453 in epoch 7, gen_loss = 1.5052218466078133, disc_loss = 0.00016965779404887096
Trained batch 454 in epoch 7, gen_loss = 1.5051965676821195, disc_loss = 0.00016952109934329081
Trained batch 455 in epoch 7, gen_loss = 1.5051429723961312, disc_loss = 0.00016939276122429235
Trained batch 456 in epoch 7, gen_loss = 1.5050699635198914, disc_loss = 0.00016926577744143327
Trained batch 457 in epoch 7, gen_loss = 1.5050303522155795, disc_loss = 0.000169108059760009
Trained batch 458 in epoch 7, gen_loss = 1.505057824722822, disc_loss = 0.00016893315374795303
Trained batch 459 in epoch 7, gen_loss = 1.5049568108890368, disc_loss = 0.00016876259450050976
Trained batch 460 in epoch 7, gen_loss = 1.5049666042183072, disc_loss = 0.00016857977081319382
Trained batch 461 in epoch 7, gen_loss = 1.5050744455614131, disc_loss = 0.00016845378670505691
Trained batch 462 in epoch 7, gen_loss = 1.504953404224717, disc_loss = 0.00016832145765148073
Trained batch 463 in epoch 7, gen_loss = 1.504804799012069, disc_loss = 0.0001682658113630733
Trained batch 464 in epoch 7, gen_loss = 1.5047877644979826, disc_loss = 0.00016828047404468175
Trained batch 465 in epoch 7, gen_loss = 1.5047358453529587, disc_loss = 0.0001683423299231662
Trained batch 466 in epoch 7, gen_loss = 1.5047325174098862, disc_loss = 0.00016842450786576276
Trained batch 467 in epoch 7, gen_loss = 1.5046531970684345, disc_loss = 0.00016852474873225702
Trained batch 468 in epoch 7, gen_loss = 1.504570543638933, disc_loss = 0.00016863724702756593
Trained batch 469 in epoch 7, gen_loss = 1.5046246630080202, disc_loss = 0.00016875385677617196
Trained batch 470 in epoch 7, gen_loss = 1.504780713666523, disc_loss = 0.00016892563818897454
Trained batch 471 in epoch 7, gen_loss = 1.5047020242880966, disc_loss = 0.00016916696741430052
Trained batch 472 in epoch 7, gen_loss = 1.5047351467180958, disc_loss = 0.00016945811815066513
Trained batch 473 in epoch 7, gen_loss = 1.5048511164097846, disc_loss = 0.00016979611078215217
Trained batch 474 in epoch 7, gen_loss = 1.504818488924127, disc_loss = 0.0001701105114395767
Trained batch 475 in epoch 7, gen_loss = 1.5048577562600625, disc_loss = 0.00017043250492876548
Trained batch 476 in epoch 7, gen_loss = 1.5049461976037335, disc_loss = 0.0001706976023681969
Trained batch 477 in epoch 7, gen_loss = 1.5048946428997247, disc_loss = 0.00017090659661197943
Trained batch 478 in epoch 7, gen_loss = 1.504883052162935, disc_loss = 0.00017109672264348485
Trained batch 479 in epoch 7, gen_loss = 1.50487198010087, disc_loss = 0.00017121825486583476
Trained batch 480 in epoch 7, gen_loss = 1.5048746031683844, disc_loss = 0.0001713024186695722
Trained batch 481 in epoch 7, gen_loss = 1.5050037305384751, disc_loss = 0.0001713754438461059
Trained batch 482 in epoch 7, gen_loss = 1.5050080358118252, disc_loss = 0.00017140105458944297
Trained batch 483 in epoch 7, gen_loss = 1.5048869808843313, disc_loss = 0.00017141855119946794
Trained batch 484 in epoch 7, gen_loss = 1.504904961831791, disc_loss = 0.0001714630017155174
Trained batch 485 in epoch 7, gen_loss = 1.5048752218607522, disc_loss = 0.00017152984974804164
Trained batch 486 in epoch 7, gen_loss = 1.5047987755808743, disc_loss = 0.00017155222827732995
Trained batch 487 in epoch 7, gen_loss = 1.5047903070684339, disc_loss = 0.0001715212727347415
Trained batch 488 in epoch 7, gen_loss = 1.504782433158781, disc_loss = 0.00017146896002458856
Trained batch 489 in epoch 7, gen_loss = 1.5049054026603699, disc_loss = 0.00017136248760445076
Trained batch 490 in epoch 7, gen_loss = 1.5048055277336883, disc_loss = 0.00017121200134468292
Trained batch 491 in epoch 7, gen_loss = 1.5048081482329019, disc_loss = 0.00017096642276060524
Trained batch 492 in epoch 7, gen_loss = 1.504853808855672, disc_loss = 0.0001706688869598725
Trained batch 493 in epoch 7, gen_loss = 1.5048143701997363, disc_loss = 0.00017038589647251393
Trained batch 494 in epoch 7, gen_loss = 1.5047327000685413, disc_loss = 0.00017008741559755325
Trained batch 495 in epoch 7, gen_loss = 1.5046795493652743, disc_loss = 0.00016979857300538566
Trained batch 496 in epoch 7, gen_loss = 1.5046397668255167, disc_loss = 0.00016949038651786015
Trained batch 497 in epoch 7, gen_loss = 1.5045816754720298, disc_loss = 0.00016918243630765844
Trained batch 498 in epoch 7, gen_loss = 1.5046097859590948, disc_loss = 0.0001688819934343028
Trained batch 499 in epoch 7, gen_loss = 1.5045948390960693, disc_loss = 0.00016864742881443818
Trained batch 500 in epoch 7, gen_loss = 1.5046458039693014, disc_loss = 0.00016846004795381138
Trained batch 501 in epoch 7, gen_loss = 1.5047010582281775, disc_loss = 0.00016827733948791078
Trained batch 502 in epoch 7, gen_loss = 1.5046435743866573, disc_loss = 0.0001680746547215633
Trained batch 503 in epoch 7, gen_loss = 1.504656567696541, disc_loss = 0.0001678328027039589
Trained batch 504 in epoch 7, gen_loss = 1.5047693264366377, disc_loss = 0.00016757693454492976
Trained batch 505 in epoch 7, gen_loss = 1.5049012211471677, disc_loss = 0.00016731577818114
Trained batch 506 in epoch 7, gen_loss = 1.5048088082195035, disc_loss = 0.00016704729856765706
Trained batch 507 in epoch 7, gen_loss = 1.5048804147036996, disc_loss = 0.00016676907979292697
Trained batch 508 in epoch 7, gen_loss = 1.5048222628464165, disc_loss = 0.00016650233069618418
Trained batch 509 in epoch 7, gen_loss = 1.504784192057217, disc_loss = 0.00016625074916673305
Trained batch 510 in epoch 7, gen_loss = 1.5047559668173296, disc_loss = 0.00016598945782491856
Trained batch 511 in epoch 7, gen_loss = 1.504648257046938, disc_loss = 0.00016571000728760055
Trained batch 512 in epoch 7, gen_loss = 1.504719730473866, disc_loss = 0.00016545307497078867
Trained batch 513 in epoch 7, gen_loss = 1.5048431965163709, disc_loss = 0.00016536059322537527
Trained batch 514 in epoch 7, gen_loss = 1.50484504005284, disc_loss = 0.0001651978351272421
Trained batch 515 in epoch 7, gen_loss = 1.504718447840491, disc_loss = 0.00016513449372018664
Trained batch 516 in epoch 7, gen_loss = 1.5046880305159254, disc_loss = 0.00016511452080842019
Trained batch 517 in epoch 7, gen_loss = 1.5048626152705042, disc_loss = 0.00016511129347253977
Trained batch 518 in epoch 7, gen_loss = 1.504855678260671, disc_loss = 0.00016504113129576757
Trained batch 519 in epoch 7, gen_loss = 1.5048203119864831, disc_loss = 0.00016496746431864895
Trained batch 520 in epoch 7, gen_loss = 1.5047982066240513, disc_loss = 0.0001649264236212187
Trained batch 521 in epoch 7, gen_loss = 1.5048170155949063, disc_loss = 0.00016490655346795643
Trained batch 522 in epoch 7, gen_loss = 1.5047400688350088, disc_loss = 0.00016489460609333962
Trained batch 523 in epoch 7, gen_loss = 1.5046349888994495, disc_loss = 0.00016492046015211586
Trained batch 524 in epoch 7, gen_loss = 1.504605686778114, disc_loss = 0.00016500386522412078
Trained batch 525 in epoch 7, gen_loss = 1.5045603325611738, disc_loss = 0.00016522942977897006
Trained batch 526 in epoch 7, gen_loss = 1.504571017775635, disc_loss = 0.0001655552194389604
Trained batch 527 in epoch 7, gen_loss = 1.504602800264503, disc_loss = 0.0001659046376007058
Trained batch 528 in epoch 7, gen_loss = 1.5046521842141682, disc_loss = 0.00016628412415473968
Trained batch 529 in epoch 7, gen_loss = 1.5047372336657543, disc_loss = 0.00016673172547186524
Trained batch 530 in epoch 7, gen_loss = 1.504825409522838, disc_loss = 0.00016719893356665694
Trained batch 531 in epoch 7, gen_loss = 1.5048713128369553, disc_loss = 0.0001677747912226482
Trained batch 532 in epoch 7, gen_loss = 1.5048523776750404, disc_loss = 0.0001684148165651909
Trained batch 533 in epoch 7, gen_loss = 1.5047871611091528, disc_loss = 0.00016909864272529647
Trained batch 534 in epoch 7, gen_loss = 1.5048969411404334, disc_loss = 0.00016997084192247304
Trained batch 535 in epoch 7, gen_loss = 1.5048602579244927, disc_loss = 0.00017114631763528884
Trained batch 536 in epoch 7, gen_loss = 1.5048996307774407, disc_loss = 0.00017258254502108884
Trained batch 537 in epoch 7, gen_loss = 1.5049610060386942, disc_loss = 0.00017414016649640923
Trained batch 538 in epoch 7, gen_loss = 1.504926889858352, disc_loss = 0.00017570424184425827
Trained batch 539 in epoch 7, gen_loss = 1.5048239054503265, disc_loss = 0.00017723912397842569
Trained batch 540 in epoch 7, gen_loss = 1.504746795802372, disc_loss = 0.0001786568329992636
Trained batch 541 in epoch 7, gen_loss = 1.5047940739406431, disc_loss = 0.0001798739480988249
Trained batch 542 in epoch 7, gen_loss = 1.504875646989868, disc_loss = 0.0001809154458876856
Trained batch 543 in epoch 7, gen_loss = 1.5048765182933386, disc_loss = 0.00018176405797690036
Trained batch 544 in epoch 7, gen_loss = 1.5049843241315368, disc_loss = 0.00018250759294627175
Trained batch 545 in epoch 7, gen_loss = 1.5050020650192932, disc_loss = 0.00018312956818080747
Trained batch 546 in epoch 7, gen_loss = 1.504997435173997, disc_loss = 0.0001835821633885544
Trained batch 547 in epoch 7, gen_loss = 1.5049959086153628, disc_loss = 0.00018386897350652746
Trained batch 548 in epoch 7, gen_loss = 1.50498862040716, disc_loss = 0.000183987532978916
Trained batch 549 in epoch 7, gen_loss = 1.5049048649181018, disc_loss = 0.00018400681831487665
Trained batch 550 in epoch 7, gen_loss = 1.504798562254101, disc_loss = 0.00018392715576254196
Trained batch 551 in epoch 7, gen_loss = 1.5047557317260383, disc_loss = 0.00018376062957875126
Trained batch 552 in epoch 7, gen_loss = 1.5047196253298851, disc_loss = 0.0001835411275602994
Trained batch 553 in epoch 7, gen_loss = 1.504728357499257, disc_loss = 0.00018329273057018914
Trained batch 554 in epoch 7, gen_loss = 1.5046544450897354, disc_loss = 0.0001830444858159853
Trained batch 555 in epoch 7, gen_loss = 1.5045494859595951, disc_loss = 0.00018289587764582838
Trained batch 556 in epoch 7, gen_loss = 1.5044278465010748, disc_loss = 0.00018266691058768374
Trained batch 557 in epoch 7, gen_loss = 1.5043500029485286, disc_loss = 0.0001824436708228595
Trained batch 558 in epoch 7, gen_loss = 1.5044432829445717, disc_loss = 0.00018222226611154665
Trained batch 559 in epoch 7, gen_loss = 1.504434804405485, disc_loss = 0.00018196365400789156
Trained batch 560 in epoch 7, gen_loss = 1.5043613309316244, disc_loss = 0.00018167960196918163
Trained batch 561 in epoch 7, gen_loss = 1.504348335104905, disc_loss = 0.00018140985902847915
Trained batch 562 in epoch 7, gen_loss = 1.5043590068817139, disc_loss = 0.00018113303280249506
Trained batch 563 in epoch 7, gen_loss = 1.5043576588021947, disc_loss = 0.00018086569140215157
Trained batch 564 in epoch 7, gen_loss = 1.504382075672656, disc_loss = 0.00018058257990447696
Trained batch 565 in epoch 7, gen_loss = 1.5044088578476922, disc_loss = 0.0001803073062919697
Trained batch 566 in epoch 7, gen_loss = 1.5044033346563, disc_loss = 0.00018004409622853623
Trained batch 567 in epoch 7, gen_loss = 1.5044721001890344, disc_loss = 0.00017977721850770712
Trained batch 568 in epoch 7, gen_loss = 1.504484755293137, disc_loss = 0.00017948937426196508
Trained batch 569 in epoch 7, gen_loss = 1.5044699405369006, disc_loss = 0.00017921094141983257
Trained batch 570 in epoch 7, gen_loss = 1.5044170881111025, disc_loss = 0.0001789590812131951
Trained batch 571 in epoch 7, gen_loss = 1.5044730436968636, disc_loss = 0.0001787400751518553
Trained batch 572 in epoch 7, gen_loss = 1.5044712781073952, disc_loss = 0.00017857847492855423
Trained batch 573 in epoch 7, gen_loss = 1.504525950769099, disc_loss = 0.00017844900670727044
Trained batch 574 in epoch 7, gen_loss = 1.5045866620022317, disc_loss = 0.00017836018980470607
Trained batch 575 in epoch 7, gen_loss = 1.5045445927729209, disc_loss = 0.0001782367030879565
Trained batch 576 in epoch 7, gen_loss = 1.5044918157405622, disc_loss = 0.00017807682484034869
Trained batch 577 in epoch 7, gen_loss = 1.5044407999226792, disc_loss = 0.00017788268644970947
Trained batch 578 in epoch 7, gen_loss = 1.504441827278269, disc_loss = 0.00017765989270349176
Trained batch 579 in epoch 7, gen_loss = 1.5044876696734593, disc_loss = 0.00017742402104541444
Trained batch 580 in epoch 7, gen_loss = 1.504475551505097, disc_loss = 0.00017721549168976685
Trained batch 581 in epoch 7, gen_loss = 1.504455170680567, disc_loss = 0.00017702879008335578
Trained batch 582 in epoch 7, gen_loss = 1.5045081115300618, disc_loss = 0.00017687613163611652
Trained batch 583 in epoch 7, gen_loss = 1.5044951873691115, disc_loss = 0.00017670578314857565
Trained batch 584 in epoch 7, gen_loss = 1.504396315313812, disc_loss = 0.0001765888353521661
Trained batch 585 in epoch 7, gen_loss = 1.5045247718742683, disc_loss = 0.00017658573633153033
Trained batch 586 in epoch 7, gen_loss = 1.5045166066395566, disc_loss = 0.00017665041105694208
Trained batch 587 in epoch 7, gen_loss = 1.5044291453296637, disc_loss = 0.00017676266438715186
Trained batch 588 in epoch 7, gen_loss = 1.504407288465516, disc_loss = 0.00017683349901412816
Trained batch 589 in epoch 7, gen_loss = 1.5043711953243968, disc_loss = 0.00017683473421222239
Trained batch 590 in epoch 7, gen_loss = 1.504272778627231, disc_loss = 0.00017676134497880054
Trained batch 591 in epoch 7, gen_loss = 1.504230088277443, disc_loss = 0.00017665172023609212
Trained batch 592 in epoch 7, gen_loss = 1.5041537757265628, disc_loss = 0.00017652066520217557
Trained batch 593 in epoch 7, gen_loss = 1.504046957300167, disc_loss = 0.00017637399780221625
Trained batch 594 in epoch 7, gen_loss = 1.504080528772178, disc_loss = 0.00017617169343656078
Trained batch 595 in epoch 7, gen_loss = 1.5041237917522456, disc_loss = 0.00017593402035406247
Trained batch 596 in epoch 7, gen_loss = 1.5041608854354527, disc_loss = 0.00017570159835064272
Trained batch 597 in epoch 7, gen_loss = 1.5042863302804954, disc_loss = 0.00017548878604673116
Trained batch 598 in epoch 7, gen_loss = 1.50425565899513, disc_loss = 0.00017526195758101664
Trained batch 599 in epoch 7, gen_loss = 1.5042278861999512, disc_loss = 0.00017502589462310426
Trained batch 600 in epoch 7, gen_loss = 1.5042207316431944, disc_loss = 0.00017477684027630895
Trained batch 601 in epoch 7, gen_loss = 1.504241208103408, disc_loss = 0.00017456555547126654
Trained batch 602 in epoch 7, gen_loss = 1.5042674549381136, disc_loss = 0.0001743667379233673
Trained batch 603 in epoch 7, gen_loss = 1.5043442249298096, disc_loss = 0.00017415729365327464
Trained batch 604 in epoch 7, gen_loss = 1.5042277639562434, disc_loss = 0.0001739462947407747
Trained batch 605 in epoch 7, gen_loss = 1.504308298869495, disc_loss = 0.00017376894321738417
Trained batch 606 in epoch 7, gen_loss = 1.5043097249365718, disc_loss = 0.0001735732137220342
Trained batch 607 in epoch 7, gen_loss = 1.5043356146075224, disc_loss = 0.00017338708493310295
Trained batch 608 in epoch 7, gen_loss = 1.504321848426155, disc_loss = 0.0001731920006553012
Trained batch 609 in epoch 7, gen_loss = 1.504264256993278, disc_loss = 0.0001730319396391097
Trained batch 610 in epoch 7, gen_loss = 1.5043320097821824, disc_loss = 0.00017293249377122957
Trained batch 611 in epoch 7, gen_loss = 1.5042642520533667, disc_loss = 0.0001728306085728381
Trained batch 612 in epoch 7, gen_loss = 1.504218331168954, disc_loss = 0.0001726969873326742
Trained batch 613 in epoch 7, gen_loss = 1.5041860755569383, disc_loss = 0.00017254156129804332
Trained batch 614 in epoch 7, gen_loss = 1.5040551770993364, disc_loss = 0.00017238236502997438
Trained batch 615 in epoch 7, gen_loss = 1.5039351288374367, disc_loss = 0.00017221243267938138
Trained batch 616 in epoch 7, gen_loss = 1.5039128571314015, disc_loss = 0.0001720291979991251
Trained batch 617 in epoch 7, gen_loss = 1.5038706930324097, disc_loss = 0.00017183884395523133
Trained batch 618 in epoch 7, gen_loss = 1.5038594750865018, disc_loss = 0.00017164152648044815
Trained batch 619 in epoch 7, gen_loss = 1.50382235338611, disc_loss = 0.0001714305552336408
Trained batch 620 in epoch 7, gen_loss = 1.5038213447672157, disc_loss = 0.00017120274141426263
Trained batch 621 in epoch 7, gen_loss = 1.5037565252405272, disc_loss = 0.0001709725278622418
Trained batch 622 in epoch 7, gen_loss = 1.5037534317273773, disc_loss = 0.00017075588116962796
Trained batch 623 in epoch 7, gen_loss = 1.5037760814795127, disc_loss = 0.00017052575575258417
Trained batch 624 in epoch 7, gen_loss = 1.5037977363586426, disc_loss = 0.00017031136972655076
Trained batch 625 in epoch 7, gen_loss = 1.5037205619172167, disc_loss = 0.00017014209320789634
Trained batch 626 in epoch 7, gen_loss = 1.5036838277104938, disc_loss = 0.00016995757413681124
Trained batch 627 in epoch 7, gen_loss = 1.503827501064653, disc_loss = 0.00016984128779959237
Trained batch 628 in epoch 7, gen_loss = 1.5038066101756498, disc_loss = 0.00016979851341816625
Trained batch 629 in epoch 7, gen_loss = 1.5038498645737057, disc_loss = 0.0001698447616685631
Trained batch 630 in epoch 7, gen_loss = 1.5038451232169585, disc_loss = 0.00016985681048952241
Trained batch 631 in epoch 7, gen_loss = 1.5038194333827948, disc_loss = 0.00016970326492821784
Trained batch 632 in epoch 7, gen_loss = 1.503672674368908, disc_loss = 0.00016951122403132055
Trained batch 633 in epoch 7, gen_loss = 1.5037132413229355, disc_loss = 0.00016934513999041328
Trained batch 634 in epoch 7, gen_loss = 1.5037512782990463, disc_loss = 0.00016934123239078922
Trained batch 635 in epoch 7, gen_loss = 1.5037470345602095, disc_loss = 0.00016933234975347532
Trained batch 636 in epoch 7, gen_loss = 1.5037004766134865, disc_loss = 0.0001692591420955471
Trained batch 637 in epoch 7, gen_loss = 1.5035960384670843, disc_loss = 0.0001691333329267692
Trained batch 638 in epoch 7, gen_loss = 1.5035251257751656, disc_loss = 0.0001689349717875906
Trained batch 639 in epoch 7, gen_loss = 1.5035803768783809, disc_loss = 0.00016873645895145727
Trained batch 640 in epoch 7, gen_loss = 1.5035849580898673, disc_loss = 0.00016857521826716545
Trained batch 641 in epoch 7, gen_loss = 1.5035295657279706, disc_loss = 0.00016848849834310965
Trained batch 642 in epoch 7, gen_loss = 1.5034698589037216, disc_loss = 0.00016846037507089326
Trained batch 643 in epoch 7, gen_loss = 1.503529578817557, disc_loss = 0.00016847905370081693
Trained batch 644 in epoch 7, gen_loss = 1.503478842927504, disc_loss = 0.0001685040494599226
Trained batch 645 in epoch 7, gen_loss = 1.503460706018442, disc_loss = 0.00016852359549544198
Trained batch 646 in epoch 7, gen_loss = 1.5033679275645355, disc_loss = 0.00016856449831340018
Trained batch 647 in epoch 7, gen_loss = 1.5034195819386729, disc_loss = 0.0001686025602822032
Trained batch 648 in epoch 7, gen_loss = 1.5033433867162107, disc_loss = 0.0001686984040453635
Trained batch 649 in epoch 7, gen_loss = 1.503295000883249, disc_loss = 0.00016884311263241285
Trained batch 650 in epoch 7, gen_loss = 1.5032901123005857, disc_loss = 0.00016904680537153875
Trained batch 651 in epoch 7, gen_loss = 1.5033331473180853, disc_loss = 0.00016932762153574785
Trained batch 652 in epoch 7, gen_loss = 1.50329073300588, disc_loss = 0.0001697312768326192
Trained batch 653 in epoch 7, gen_loss = 1.5032419181380432, disc_loss = 0.00017031636625493713
Trained batch 654 in epoch 7, gen_loss = 1.5031881285077744, disc_loss = 0.00017105753969599738
Trained batch 655 in epoch 7, gen_loss = 1.5032149080823107, disc_loss = 0.00017197777316507599
Trained batch 656 in epoch 7, gen_loss = 1.5031762219273699, disc_loss = 0.0001730631054454131
Trained batch 657 in epoch 7, gen_loss = 1.503134583992074, disc_loss = 0.0001742715665021737
Trained batch 658 in epoch 7, gen_loss = 1.5030177080938776, disc_loss = 0.0001760115128421719
Trained batch 659 in epoch 7, gen_loss = 1.5031201028462613, disc_loss = 0.00017813157795292984
Trained batch 660 in epoch 7, gen_loss = 1.5030403119172342, disc_loss = 0.00018039540639794844
Trained batch 661 in epoch 7, gen_loss = 1.5029683642517044, disc_loss = 0.00018268834882432272
Trained batch 662 in epoch 7, gen_loss = 1.5029600107112442, disc_loss = 0.00018506614266491168
Trained batch 663 in epoch 7, gen_loss = 1.5029054515692124, disc_loss = 0.00018734667848427735
Trained batch 664 in epoch 7, gen_loss = 1.502816363026325, disc_loss = 0.00018942577057748708
Trained batch 665 in epoch 7, gen_loss = 1.5027862740708544, disc_loss = 0.00019092212768044591
Trained batch 666 in epoch 7, gen_loss = 1.5028460154469045, disc_loss = 0.00019181747982498644
Trained batch 667 in epoch 7, gen_loss = 1.5028870523332836, disc_loss = 0.00019233335347951672
Trained batch 668 in epoch 7, gen_loss = 1.5029739759784464, disc_loss = 0.0001929172398463984
Trained batch 669 in epoch 7, gen_loss = 1.5030360755635732, disc_loss = 0.00019361095884091607
Trained batch 670 in epoch 7, gen_loss = 1.5030194361057083, disc_loss = 0.00019420502510520955
Trained batch 671 in epoch 7, gen_loss = 1.5029954425990582, disc_loss = 0.00019447933711565687
Trained batch 672 in epoch 7, gen_loss = 1.5029581221924848, disc_loss = 0.00019446847428862034
Trained batch 673 in epoch 7, gen_loss = 1.5029692823172323, disc_loss = 0.00019429348175859445
Trained batch 674 in epoch 7, gen_loss = 1.50298690089473, disc_loss = 0.00019410024868934502
Trained batch 675 in epoch 7, gen_loss = 1.5029458183155964, disc_loss = 0.00019388221999609752
Trained batch 676 in epoch 7, gen_loss = 1.502880918222481, disc_loss = 0.00019369786630226508
Trained batch 677 in epoch 7, gen_loss = 1.5028800832486786, disc_loss = 0.0001935607703368684
Trained batch 678 in epoch 7, gen_loss = 1.5028451981354884, disc_loss = 0.00019346200336235563
Trained batch 679 in epoch 7, gen_loss = 1.50284243015682, disc_loss = 0.00019335954380574763
Trained batch 680 in epoch 7, gen_loss = 1.5028223259683573, disc_loss = 0.00019323763852982517
Trained batch 681 in epoch 7, gen_loss = 1.5027806636525038, disc_loss = 0.0001931032564702399
Trained batch 682 in epoch 7, gen_loss = 1.5027225802967523, disc_loss = 0.00019297903349746573
Trained batch 683 in epoch 7, gen_loss = 1.5026106179109093, disc_loss = 0.00019289108490871693
Trained batch 684 in epoch 7, gen_loss = 1.50263666201682, disc_loss = 0.00019267523476913873
Trained batch 685 in epoch 7, gen_loss = 1.5026642358685374, disc_loss = 0.0001924709124450442
Trained batch 686 in epoch 7, gen_loss = 1.502603897187734, disc_loss = 0.00019228637432549476
Trained batch 687 in epoch 7, gen_loss = 1.5024628003322802, disc_loss = 0.00019213456197692637
Trained batch 688 in epoch 7, gen_loss = 1.5025056479458192, disc_loss = 0.00019196048856528117
Trained batch 689 in epoch 7, gen_loss = 1.502425295546435, disc_loss = 0.00019177751642480186
Trained batch 690 in epoch 7, gen_loss = 1.502315444642659, disc_loss = 0.0001916225417374976
Trained batch 691 in epoch 7, gen_loss = 1.5023127323974763, disc_loss = 0.00019143561019392357
Trained batch 692 in epoch 7, gen_loss = 1.5022892554601033, disc_loss = 0.00019121983723052152
Trained batch 693 in epoch 7, gen_loss = 1.502282899120012, disc_loss = 0.0001909949576798335
Trained batch 694 in epoch 7, gen_loss = 1.5022016261121351, disc_loss = 0.00019080401760207324
Trained batch 695 in epoch 7, gen_loss = 1.5022033727032014, disc_loss = 0.00019060539417275332
Trained batch 696 in epoch 7, gen_loss = 1.502208444446197, disc_loss = 0.00019041166607131584
Trained batch 697 in epoch 7, gen_loss = 1.5022373247283236, disc_loss = 0.00019038900062824177
Trained batch 698 in epoch 7, gen_loss = 1.5022439823641798, disc_loss = 0.00019037948791219542
Trained batch 699 in epoch 7, gen_loss = 1.5022093229634421, disc_loss = 0.00019040943089359123
Trained batch 700 in epoch 7, gen_loss = 1.5021947273684295, disc_loss = 0.0001903981231118344
Trained batch 701 in epoch 7, gen_loss = 1.5021891344306815, disc_loss = 0.00019025640268536883
Trained batch 702 in epoch 7, gen_loss = 1.5021950187927289, disc_loss = 0.00019002266135288235
Trained batch 703 in epoch 7, gen_loss = 1.5021030352535574, disc_loss = 0.00018984733445522167
Trained batch 704 in epoch 7, gen_loss = 1.5021199038688173, disc_loss = 0.00018972491968870212
Trained batch 705 in epoch 7, gen_loss = 1.502096064705349, disc_loss = 0.00018960601202768875
Trained batch 706 in epoch 7, gen_loss = 1.5021586171977086, disc_loss = 0.00018943021330510116
Trained batch 707 in epoch 7, gen_loss = 1.5021144144952634, disc_loss = 0.00018922151387563502
Trained batch 708 in epoch 7, gen_loss = 1.5021709329823008, disc_loss = 0.00018906410960728098
Trained batch 709 in epoch 7, gen_loss = 1.502128376759274, disc_loss = 0.00018893413221441835
Trained batch 710 in epoch 7, gen_loss = 1.5020295386575948, disc_loss = 0.00018884249553560432
Trained batch 711 in epoch 7, gen_loss = 1.5019984985335488, disc_loss = 0.0001887117703778601
Trained batch 712 in epoch 7, gen_loss = 1.5019020383856239, disc_loss = 0.00018855596957060062
Trained batch 713 in epoch 7, gen_loss = 1.5018411475737221, disc_loss = 0.0001883819173721762
Trained batch 714 in epoch 7, gen_loss = 1.501877051800281, disc_loss = 0.000188225192170801
Trained batch 715 in epoch 7, gen_loss = 1.5018865397855556, disc_loss = 0.00018808145081716985
Trained batch 716 in epoch 7, gen_loss = 1.5018071587946957, disc_loss = 0.00018798178507685594
Trained batch 717 in epoch 7, gen_loss = 1.5018187645086007, disc_loss = 0.0001878741825021786
Trained batch 718 in epoch 7, gen_loss = 1.5017619268950566, disc_loss = 0.0001877227258544973
Trained batch 719 in epoch 7, gen_loss = 1.5018154381050004, disc_loss = 0.00018755504689427956
Trained batch 720 in epoch 7, gen_loss = 1.5016551297183838, disc_loss = 0.00018756401235383923
Trained batch 721 in epoch 7, gen_loss = 1.5016553132818016, disc_loss = 0.00018753985293396832
Trained batch 722 in epoch 7, gen_loss = 1.501628037969766, disc_loss = 0.00018741437268351546
Trained batch 723 in epoch 7, gen_loss = 1.5014975424958856, disc_loss = 0.0001872555244869309
Trained batch 724 in epoch 7, gen_loss = 1.5015070635696937, disc_loss = 0.00018717699125961096
Trained batch 725 in epoch 7, gen_loss = 1.5014673793283047, disc_loss = 0.00018725469608373217
Trained batch 726 in epoch 7, gen_loss = 1.5013577641286417, disc_loss = 0.00018737342020139553
Trained batch 727 in epoch 7, gen_loss = 1.5013358149227205, disc_loss = 0.00018735395588759436
Trained batch 728 in epoch 7, gen_loss = 1.5013133845048023, disc_loss = 0.00018726596121847696
Trained batch 729 in epoch 7, gen_loss = 1.5013103347935088, disc_loss = 0.00018715910441455453
Trained batch 730 in epoch 7, gen_loss = 1.501311316861989, disc_loss = 0.0001870600403660248
Trained batch 731 in epoch 7, gen_loss = 1.5012642045815785, disc_loss = 0.00018695829826331352
Trained batch 732 in epoch 7, gen_loss = 1.5011933885850164, disc_loss = 0.00018685027074229115
Trained batch 733 in epoch 7, gen_loss = 1.5011710613884783, disc_loss = 0.00018668970029362352
Trained batch 734 in epoch 7, gen_loss = 1.5011236677364428, disc_loss = 0.0001865118484880552
Trained batch 735 in epoch 7, gen_loss = 1.5010157159489135, disc_loss = 0.0001863402089517639
Trained batch 736 in epoch 7, gen_loss = 1.5009297593477784, disc_loss = 0.00018619989915502532
Trained batch 737 in epoch 7, gen_loss = 1.5008193819826534, disc_loss = 0.00018609621846190825
Trained batch 738 in epoch 7, gen_loss = 1.5007385386504404, disc_loss = 0.00018605426210512396
Trained batch 739 in epoch 7, gen_loss = 1.500727996471766, disc_loss = 0.00018596778566682808
Trained batch 740 in epoch 7, gen_loss = 1.5006553591021643, disc_loss = 0.00018589078125340206
Trained batch 741 in epoch 7, gen_loss = 1.5007027956353365, disc_loss = 0.00018583514111872678
Trained batch 742 in epoch 7, gen_loss = 1.500736648269489, disc_loss = 0.00018571555512147774
Trained batch 743 in epoch 7, gen_loss = 1.500804236499212, disc_loss = 0.00018556569351789887
Trained batch 744 in epoch 7, gen_loss = 1.500799638952985, disc_loss = 0.0001853918211872341
Trained batch 745 in epoch 7, gen_loss = 1.5007350021329067, disc_loss = 0.00018522748764833804
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 1.5463480949401855, disc_loss = 7.008726970525458e-05
Trained batch 1 in epoch 8, gen_loss = 1.5039706230163574, disc_loss = 8.25419083412271e-05
Trained batch 2 in epoch 8, gen_loss = 1.4906039635340373, disc_loss = 8.375299754940595e-05
Trained batch 3 in epoch 8, gen_loss = 1.4906142055988312, disc_loss = 9.779046558833215e-05
Trained batch 4 in epoch 8, gen_loss = 1.4996621370315553, disc_loss = 0.00011695267021423205
Trained batch 5 in epoch 8, gen_loss = 1.4867354035377502, disc_loss = 0.00014874919118786542
Trained batch 6 in epoch 8, gen_loss = 1.4924948045185633, disc_loss = 0.00014882696580441137
Trained batch 7 in epoch 8, gen_loss = 1.4925082176923752, disc_loss = 0.00014203808314050548
Trained batch 8 in epoch 8, gen_loss = 1.496161659558614, disc_loss = 0.00013293063198539635
Trained batch 9 in epoch 8, gen_loss = 1.4928810000419617, disc_loss = 0.0001817121508793207
Trained batch 10 in epoch 8, gen_loss = 1.407666731964458, disc_loss = 0.04236928029521633
Trained batch 11 in epoch 8, gen_loss = 1.520808105667432, disc_loss = 0.09152448296572402
Trained batch 12 in epoch 8, gen_loss = 1.5215644515477693, disc_loss = 0.08960428428214912
Trained batch 13 in epoch 8, gen_loss = 1.4577294630663735, disc_loss = 0.13049237904825922
Trained batch 14 in epoch 8, gen_loss = 1.4100062489509582, disc_loss = 0.1406583234272451
Trained batch 15 in epoch 8, gen_loss = 1.4109638296067715, disc_loss = 0.14921015730146792
Trained batch 16 in epoch 8, gen_loss = 1.4177514770451713, disc_loss = 0.14899457768500296
Trained batch 17 in epoch 8, gen_loss = 1.4007612102561526, disc_loss = 0.14422538004004715
Trained batch 18 in epoch 8, gen_loss = 1.3900286178839834, disc_loss = 0.13854398379216468
Trained batch 19 in epoch 8, gen_loss = 1.3890416413545608, disc_loss = 0.13242858934045215
Trained batch 20 in epoch 8, gen_loss = 1.3954334173883711, disc_loss = 0.1268086947129632
Trained batch 21 in epoch 8, gen_loss = 1.4052712402560494, disc_loss = 0.1227017501522906
Trained batch 22 in epoch 8, gen_loss = 1.4109175023825273, disc_loss = 0.11863584858419136
Trained batch 23 in epoch 8, gen_loss = 1.413784387211005, disc_loss = 0.11402501578610706
Trained batch 24 in epoch 8, gen_loss = 1.4180690693855285, disc_loss = 0.1097009503604204
Trained batch 25 in epoch 8, gen_loss = 1.4224782563172853, disc_loss = 0.10567350851670199
Trained batch 26 in epoch 8, gen_loss = 1.4264056439752932, disc_loss = 0.10190595584208495
Trained batch 27 in epoch 8, gen_loss = 1.4285104125738144, disc_loss = 0.09834586311275675
Trained batch 28 in epoch 8, gen_loss = 1.4307249435063065, disc_loss = 0.0950034992115277
Trained batch 29 in epoch 8, gen_loss = 1.4339667737483979, disc_loss = 0.09187404263029748
Trained batch 30 in epoch 8, gen_loss = 1.4379408301845673, disc_loss = 0.08896788418813582
Trained batch 31 in epoch 8, gen_loss = 1.441021816805005, disc_loss = 0.08622989747857446
Trained batch 32 in epoch 8, gen_loss = 1.4434868295987446, disc_loss = 0.0836466442486915
Trained batch 33 in epoch 8, gen_loss = 1.4465057762230145, disc_loss = 0.08122029254071308
Trained batch 34 in epoch 8, gen_loss = 1.450570615700313, disc_loss = 0.07894075556760072
Trained batch 35 in epoch 8, gen_loss = 1.4544705665773816, disc_loss = 0.07677565723911862
Trained batch 36 in epoch 8, gen_loss = 1.4582708220224123, disc_loss = 0.07472896013643697
Trained batch 37 in epoch 8, gen_loss = 1.4606438984996395, disc_loss = 0.07278784600327383
Trained batch 38 in epoch 8, gen_loss = 1.4634758493839166, disc_loss = 0.0709379043245206
Trained batch 39 in epoch 8, gen_loss = 1.4662242129445076, disc_loss = 0.06918109149091833
Trained batch 40 in epoch 8, gen_loss = 1.467365464059318, disc_loss = 0.06751076109317293
Trained batch 41 in epoch 8, gen_loss = 1.4684683893408095, disc_loss = 0.06591533200506612
Trained batch 42 in epoch 8, gen_loss = 1.4697823815567548, disc_loss = 0.0643931241097033
Trained batch 43 in epoch 8, gen_loss = 1.4705011533065275, disc_loss = 0.06294246949362953
Trained batch 44 in epoch 8, gen_loss = 1.4719720615281, disc_loss = 0.061555558195767746
Trained batch 45 in epoch 8, gen_loss = 1.4723912982837013, disc_loss = 0.06023293330421755
Trained batch 46 in epoch 8, gen_loss = 1.4736753562663465, disc_loss = 0.058968531876629676
Trained batch 47 in epoch 8, gen_loss = 1.4749567123750846, disc_loss = 0.05775445002632296
Trained batch 48 in epoch 8, gen_loss = 1.4757734062720318, disc_loss = 0.05658805560136786
Trained batch 49 in epoch 8, gen_loss = 1.4775937759876252, disc_loss = 0.05546926837392675
Trained batch 50 in epoch 8, gen_loss = 1.478430643969891, disc_loss = 0.05439878432926158
Trained batch 51 in epoch 8, gen_loss = 1.4790916454333525, disc_loss = 0.053368364534435386
Trained batch 52 in epoch 8, gen_loss = 1.4796435619300266, disc_loss = 0.05237264846835147
Trained batch 53 in epoch 8, gen_loss = 1.480204066744557, disc_loss = 0.051408248248898655
Trained batch 54 in epoch 8, gen_loss = 1.4806333075870166, disc_loss = 0.05047753515940382
Trained batch 55 in epoch 8, gen_loss = 1.4820856249758176, disc_loss = 0.04958001110084557
Trained batch 56 in epoch 8, gen_loss = 1.4834978339964884, disc_loss = 0.0487153714004084
Trained batch 57 in epoch 8, gen_loss = 1.4845067231819546, disc_loss = 0.04788007469455649
Trained batch 58 in epoch 8, gen_loss = 1.486065582703736, disc_loss = 0.04707309921101669
Trained batch 59 in epoch 8, gen_loss = 1.4871962676445643, disc_loss = 0.04629146942030881
Trained batch 60 in epoch 8, gen_loss = 1.48731479976998, disc_loss = 0.04553534445830203
Trained batch 61 in epoch 8, gen_loss = 1.4879570286120138, disc_loss = 0.04480440306554468
Trained batch 62 in epoch 8, gen_loss = 1.4883998604047866, disc_loss = 0.044095869969804344
Trained batch 63 in epoch 8, gen_loss = 1.4898189110681415, disc_loss = 0.04340963357532246
Trained batch 64 in epoch 8, gen_loss = 1.4907941515629108, disc_loss = 0.04274538984536776
Trained batch 65 in epoch 8, gen_loss = 1.4913509822253026, disc_loss = 0.04210016175415093
Trained batch 66 in epoch 8, gen_loss = 1.4915844495616741, disc_loss = 0.04147419287592265
Trained batch 67 in epoch 8, gen_loss = 1.4924301250892527, disc_loss = 0.040867103165777845
Trained batch 68 in epoch 8, gen_loss = 1.4935742901719136, disc_loss = 0.04027734405114999
Trained batch 69 in epoch 8, gen_loss = 1.4938465876238687, disc_loss = 0.039705255876729746
Trained batch 70 in epoch 8, gen_loss = 1.494611705692721, disc_loss = 0.03914817925371454
Trained batch 71 in epoch 8, gen_loss = 1.4949025337894757, disc_loss = 0.03860667561300741
Trained batch 72 in epoch 8, gen_loss = 1.4951197423347056, disc_loss = 0.03808047210647962
Trained batch 73 in epoch 8, gen_loss = 1.4952847949556403, disc_loss = 0.03756904009871407
Trained batch 74 in epoch 8, gen_loss = 1.4954319755236307, disc_loss = 0.03707036586327983
Trained batch 75 in epoch 8, gen_loss = 1.4953854844758385, disc_loss = 0.036584836090840234
Trained batch 76 in epoch 8, gen_loss = 1.4948142108979163, disc_loss = 0.03611198749833373
Trained batch 77 in epoch 8, gen_loss = 1.4945826568664649, disc_loss = 0.035651465577197644
Trained batch 78 in epoch 8, gen_loss = 1.4950376832032506, disc_loss = 0.035202443291393735
Trained batch 79 in epoch 8, gen_loss = 1.4954236619174481, disc_loss = 0.034765080316037714
Trained batch 80 in epoch 8, gen_loss = 1.495797567161513, disc_loss = 0.03433751085609446
Trained batch 81 in epoch 8, gen_loss = 1.4970501087060788, disc_loss = 0.03392201583807125
Trained batch 82 in epoch 8, gen_loss = 1.497612112257854, disc_loss = 0.03351578699164156
Trained batch 83 in epoch 8, gen_loss = 1.4978778851883752, disc_loss = 0.03311893044784007
Trained batch 84 in epoch 8, gen_loss = 1.4984717123648699, disc_loss = 0.032731001107201924
Trained batch 85 in epoch 8, gen_loss = 1.4986370282117711, disc_loss = 0.032352439028579476
Trained batch 86 in epoch 8, gen_loss = 1.4987220003687103, disc_loss = 0.03198283917864218
Trained batch 87 in epoch 8, gen_loss = 1.4982410445809364, disc_loss = 0.03162182572987149
Trained batch 88 in epoch 8, gen_loss = 1.4984510648116638, disc_loss = 0.03126798928431608
Trained batch 89 in epoch 8, gen_loss = 1.4993755400180817, disc_loss = 0.030925450298794507
Trained batch 90 in epoch 8, gen_loss = 1.4997116386235416, disc_loss = 0.030589963353642297
Trained batch 91 in epoch 8, gen_loss = 1.4996465852727061, disc_loss = 0.03025977041259308
Trained batch 92 in epoch 8, gen_loss = 1.5002171269027136, disc_loss = 0.02993629310253954
Trained batch 93 in epoch 8, gen_loss = 1.500058059362655, disc_loss = 0.02961965452634607
Trained batch 94 in epoch 8, gen_loss = 1.500148440034766, disc_loss = 0.02930912652407546
Trained batch 95 in epoch 8, gen_loss = 1.5007762952397268, disc_loss = 0.029005174404384586
Trained batch 96 in epoch 8, gen_loss = 1.5009064901735365, disc_loss = 0.02870717315671914
Trained batch 97 in epoch 8, gen_loss = 1.5013613086573931, disc_loss = 0.02841507897856176
Trained batch 98 in epoch 8, gen_loss = 1.501201539930671, disc_loss = 0.028129761287364274
Trained batch 99 in epoch 8, gen_loss = 1.5011317771673203, disc_loss = 0.027850456609339744
Trained batch 100 in epoch 8, gen_loss = 1.5015472037957447, disc_loss = 0.027575675766267595
Trained batch 101 in epoch 8, gen_loss = 1.502284007329567, disc_loss = 0.027307108343830253
Trained batch 102 in epoch 8, gen_loss = 1.5025348750132959, disc_loss = 0.02704315001809166
Trained batch 103 in epoch 8, gen_loss = 1.502611595277603, disc_loss = 0.026785025243428278
Trained batch 104 in epoch 8, gen_loss = 1.5029339228357588, disc_loss = 0.026531933070544342
Trained batch 105 in epoch 8, gen_loss = 1.503308522813725, disc_loss = 0.026282698903193
Trained batch 106 in epoch 8, gen_loss = 1.5034423626471902, disc_loss = 0.02603812294985112
Trained batch 107 in epoch 8, gen_loss = 1.5034998230360173, disc_loss = 0.025798291899836505
Trained batch 108 in epoch 8, gen_loss = 1.5035384220814487, disc_loss = 0.02556253638182721
Trained batch 109 in epoch 8, gen_loss = 1.5032873646779494, disc_loss = 0.02533137239677837
Trained batch 110 in epoch 8, gen_loss = 1.5033679711926091, disc_loss = 0.025104005153135968
Trained batch 111 in epoch 8, gen_loss = 1.5034731387027673, disc_loss = 0.024880520362233125
Trained batch 112 in epoch 8, gen_loss = 1.5034896984564519, disc_loss = 0.024661117339545638
Trained batch 113 in epoch 8, gen_loss = 1.5041702227634297, disc_loss = 0.024446398876662306
Trained batch 114 in epoch 8, gen_loss = 1.5042227843533391, disc_loss = 0.02423532438921899
Trained batch 115 in epoch 8, gen_loss = 1.5043459611720051, disc_loss = 0.02402783111326777
Trained batch 116 in epoch 8, gen_loss = 1.5037622334610703, disc_loss = 0.023823894542893426
Trained batch 117 in epoch 8, gen_loss = 1.5038391245623766, disc_loss = 0.023623390652635676
Trained batch 118 in epoch 8, gen_loss = 1.5042614861696708, disc_loss = 0.02342574898461824
Trained batch 119 in epoch 8, gen_loss = 1.5043918624520303, disc_loss = 0.023231489953135072
Trained batch 120 in epoch 8, gen_loss = 1.5041386554063845, disc_loss = 0.023040418358369823
Trained batch 121 in epoch 8, gen_loss = 1.5042644568154069, disc_loss = 0.022852516400055974
Trained batch 122 in epoch 8, gen_loss = 1.504514758664418, disc_loss = 0.022667696683498894
Trained batch 123 in epoch 8, gen_loss = 1.5054100074114338, disc_loss = 0.022486674571507225
Trained batch 124 in epoch 8, gen_loss = 1.5057036051750183, disc_loss = 0.022307751299318626
Trained batch 125 in epoch 8, gen_loss = 1.5060442435362982, disc_loss = 0.022131560092020663
Trained batch 126 in epoch 8, gen_loss = 1.5067650976143485, disc_loss = 0.021958228029631762
Trained batch 127 in epoch 8, gen_loss = 1.506271988619119, disc_loss = 0.021789315202937587
Trained batch 128 in epoch 8, gen_loss = 1.5068941204122794, disc_loss = 0.02162209841777059
Trained batch 129 in epoch 8, gen_loss = 1.5067300305916713, disc_loss = 0.021457158234401363
Trained batch 130 in epoch 8, gen_loss = 1.5071278514752862, disc_loss = 0.021294754771685683
Trained batch 131 in epoch 8, gen_loss = 1.5065544631445047, disc_loss = 0.02113551313675888
Trained batch 132 in epoch 8, gen_loss = 1.5070936272018833, disc_loss = 0.0209784790459345
Trained batch 133 in epoch 8, gen_loss = 1.5075083566245748, disc_loss = 0.020822880383514247
Trained batch 134 in epoch 8, gen_loss = 1.5071236658979346, disc_loss = 0.020669469060036742
Trained batch 135 in epoch 8, gen_loss = 1.5070218115168459, disc_loss = 0.020518519729809188
Trained batch 136 in epoch 8, gen_loss = 1.5069320232328707, disc_loss = 0.020369540832941648
Trained batch 137 in epoch 8, gen_loss = 1.5072837320790775, disc_loss = 0.020222709799096607
Trained batch 138 in epoch 8, gen_loss = 1.507515284226095, disc_loss = 0.020077839895525716
Trained batch 139 in epoch 8, gen_loss = 1.507656416296959, disc_loss = 0.019935089197185465
Trained batch 140 in epoch 8, gen_loss = 1.5075543573562136, disc_loss = 0.019794313450112108
Trained batch 141 in epoch 8, gen_loss = 1.507817955504001, disc_loss = 0.019655587043352695
Trained batch 142 in epoch 8, gen_loss = 1.5071143441266948, disc_loss = 0.01951994172980137
Trained batch 143 in epoch 8, gen_loss = 1.5065262735717826, disc_loss = 0.019385437720529808
Trained batch 144 in epoch 8, gen_loss = 1.5064184127182796, disc_loss = 0.01925268710908532
Trained batch 145 in epoch 8, gen_loss = 1.5066035002061766, disc_loss = 0.019121577332342682
Trained batch 146 in epoch 8, gen_loss = 1.5070880979907757, disc_loss = 0.01899237826795315
Trained batch 147 in epoch 8, gen_loss = 1.507071030703751, disc_loss = 0.01886480175791213
Trained batch 148 in epoch 8, gen_loss = 1.507408905749353, disc_loss = 0.0187389870555753
Trained batch 149 in epoch 8, gen_loss = 1.5075376411279042, disc_loss = 0.018614736322463916
Trained batch 150 in epoch 8, gen_loss = 1.5079034294513678, disc_loss = 0.01849209345486967
Trained batch 151 in epoch 8, gen_loss = 1.5081663065050777, disc_loss = 0.018370921025459546
Trained batch 152 in epoch 8, gen_loss = 1.5081573385818332, disc_loss = 0.018251395976037553
Trained batch 153 in epoch 8, gen_loss = 1.508267518374827, disc_loss = 0.01813328490160612
Trained batch 154 in epoch 8, gen_loss = 1.5083094731453925, disc_loss = 0.018016721949149335
Trained batch 155 in epoch 8, gen_loss = 1.5081912856071422, disc_loss = 0.01790168239226776
Trained batch 156 in epoch 8, gen_loss = 1.5083107959692645, disc_loss = 0.017788054763120162
Trained batch 157 in epoch 8, gen_loss = 1.5087109928644156, disc_loss = 0.017676088063506287
Trained batch 158 in epoch 8, gen_loss = 1.5086642155107461, disc_loss = 0.01756543857717697
Trained batch 159 in epoch 8, gen_loss = 1.508483499661088, disc_loss = 0.017455999714093194
Trained batch 160 in epoch 8, gen_loss = 1.5084071118639122, disc_loss = 0.017347946931018352
Trained batch 161 in epoch 8, gen_loss = 1.5086723731623755, disc_loss = 0.017241567412215605
Trained batch 162 in epoch 8, gen_loss = 1.508425794130454, disc_loss = 0.0171363827617724
Trained batch 163 in epoch 8, gen_loss = 1.5084217768616792, disc_loss = 0.017032248835786915
Trained batch 164 in epoch 8, gen_loss = 1.5082687562162227, disc_loss = 0.016929459096630153
Trained batch 165 in epoch 8, gen_loss = 1.5087389023189086, disc_loss = 0.016828026743310312
Trained batch 166 in epoch 8, gen_loss = 1.508817257638463, disc_loss = 0.016727615145759548
Trained batch 167 in epoch 8, gen_loss = 1.5088770194422632, disc_loss = 0.016628367100067754
Trained batch 168 in epoch 8, gen_loss = 1.5088267400419924, disc_loss = 0.016530501659441713
Trained batch 169 in epoch 8, gen_loss = 1.5089949653429144, disc_loss = 0.016433656996955773
Trained batch 170 in epoch 8, gen_loss = 1.509210328958188, disc_loss = 0.016338065196594056
Trained batch 171 in epoch 8, gen_loss = 1.5089700960142667, disc_loss = 0.01624337453959438
Trained batch 172 in epoch 8, gen_loss = 1.509046171097397, disc_loss = 0.016149747746835415
Trained batch 173 in epoch 8, gen_loss = 1.5091649975584842, disc_loss = 0.01605726344657352
Trained batch 174 in epoch 8, gen_loss = 1.5092270820481437, disc_loss = 0.015965752576261625
Trained batch 175 in epoch 8, gen_loss = 1.5094471787187187, disc_loss = 0.01587541973739545
Trained batch 176 in epoch 8, gen_loss = 1.5096531820162542, disc_loss = 0.015786123227998602
Trained batch 177 in epoch 8, gen_loss = 1.5098432332612155, disc_loss = 0.01569774031030535
Trained batch 178 in epoch 8, gen_loss = 1.5099129620211085, disc_loss = 0.015610457583676567
Trained batch 179 in epoch 8, gen_loss = 1.5097817192475, disc_loss = 0.015523980584435371
Trained batch 180 in epoch 8, gen_loss = 1.5097953176630137, disc_loss = 0.01543854909301163
Trained batch 181 in epoch 8, gen_loss = 1.5098413291213277, disc_loss = 0.015354055593439166
Trained batch 182 in epoch 8, gen_loss = 1.5101152616120428, disc_loss = 0.015270710439741538
Trained batch 183 in epoch 8, gen_loss = 1.5100006010869276, disc_loss = 0.015188764236367917
Trained batch 184 in epoch 8, gen_loss = 1.510155250252904, disc_loss = 0.015107325403958975
Trained batch 185 in epoch 8, gen_loss = 1.51053816624867, disc_loss = 0.01502665102378414
Trained batch 186 in epoch 8, gen_loss = 1.5106357275483442, disc_loss = 0.014946906690080811
Trained batch 187 in epoch 8, gen_loss = 1.5103270560503006, disc_loss = 0.014868013561894298
Trained batch 188 in epoch 8, gen_loss = 1.5105111822880135, disc_loss = 0.014789979632561361
Trained batch 189 in epoch 8, gen_loss = 1.5104310597244062, disc_loss = 0.014712591164540132
Trained batch 190 in epoch 8, gen_loss = 1.5102438861162875, disc_loss = 0.014635866650949928
Trained batch 191 in epoch 8, gen_loss = 1.5102077744280298, disc_loss = 0.014559944821238938
Trained batch 192 in epoch 8, gen_loss = 1.5102920980033478, disc_loss = 0.014485082221050823
Trained batch 193 in epoch 8, gen_loss = 1.510450456253032, disc_loss = 0.01441092343867643
Trained batch 194 in epoch 8, gen_loss = 1.5104379210716639, disc_loss = 0.014337397247380488
Trained batch 195 in epoch 8, gen_loss = 1.5104466898708928, disc_loss = 0.014264812793693895
Trained batch 196 in epoch 8, gen_loss = 1.5102466989289685, disc_loss = 0.014193244637372026
Trained batch 197 in epoch 8, gen_loss = 1.5101649553486796, disc_loss = 0.014122069725613763
Trained batch 198 in epoch 8, gen_loss = 1.5102764706515788, disc_loss = 0.01405145050849208
Trained batch 199 in epoch 8, gen_loss = 1.510344057381153, disc_loss = 0.01398165377062469
Trained batch 200 in epoch 8, gen_loss = 1.5104014496898177, disc_loss = 0.013912453015864999
Trained batch 201 in epoch 8, gen_loss = 1.5105710563683274, disc_loss = 0.013844024471152374
Trained batch 202 in epoch 8, gen_loss = 1.5106225809440237, disc_loss = 0.0137762005775549
Trained batch 203 in epoch 8, gen_loss = 1.5108911783671846, disc_loss = 0.01370900308908555
Trained batch 204 in epoch 8, gen_loss = 1.5109254956245421, disc_loss = 0.013642600546438366
Trained batch 205 in epoch 8, gen_loss = 1.510931350941797, disc_loss = 0.01357668291570608
Trained batch 206 in epoch 8, gen_loss = 1.5108991432305119, disc_loss = 0.013511360408301698
Trained batch 207 in epoch 8, gen_loss = 1.5110892066015646, disc_loss = 0.013446793537818498
Trained batch 208 in epoch 8, gen_loss = 1.510905719544899, disc_loss = 0.013383054602110695
Trained batch 209 in epoch 8, gen_loss = 1.5110728102070945, disc_loss = 0.013319655233100917
Trained batch 210 in epoch 8, gen_loss = 1.510994948199575, disc_loss = 0.013256842234510277
Trained batch 211 in epoch 8, gen_loss = 1.5108249477058087, disc_loss = 0.013194705988029935
Trained batch 212 in epoch 8, gen_loss = 1.510970844069557, disc_loss = 0.013133143559959745
Trained batch 213 in epoch 8, gen_loss = 1.510966960236291, disc_loss = 0.013071989680832294
Trained batch 214 in epoch 8, gen_loss = 1.5105825615483661, disc_loss = 0.013011426289889388
Trained batch 215 in epoch 8, gen_loss = 1.5106560932817283, disc_loss = 0.012951615635655698
Trained batch 216 in epoch 8, gen_loss = 1.5104268347063372, disc_loss = 0.012892470062673597
Trained batch 217 in epoch 8, gen_loss = 1.5104521821945085, disc_loss = 0.01283356515888804
Trained batch 218 in epoch 8, gen_loss = 1.5100579046767597, disc_loss = 0.012775214385810323
Trained batch 219 in epoch 8, gen_loss = 1.5101109458641573, disc_loss = 0.012717369758055694
Trained batch 220 in epoch 8, gen_loss = 1.510051429271698, disc_loss = 0.012660050611983567
Trained batch 221 in epoch 8, gen_loss = 1.50993608005412, disc_loss = 0.01260328965872759
Trained batch 222 in epoch 8, gen_loss = 1.50995495474392, disc_loss = 0.012547029992066963
Trained batch 223 in epoch 8, gen_loss = 1.510109688288399, disc_loss = 0.012491506666135268
Trained batch 224 in epoch 8, gen_loss = 1.5101406137148539, disc_loss = 0.012436242171065209
Trained batch 225 in epoch 8, gen_loss = 1.5101097081087331, disc_loss = 0.012381355181191914
Trained batch 226 in epoch 8, gen_loss = 1.5102960315044756, disc_loss = 0.012327057166349544
Trained batch 227 in epoch 8, gen_loss = 1.5103896602726818, disc_loss = 0.012273246310414515
Trained batch 228 in epoch 8, gen_loss = 1.5107314688149498, disc_loss = 0.012220300357806213
Trained batch 229 in epoch 8, gen_loss = 1.511038500070572, disc_loss = 0.012167574138916478
Trained batch 230 in epoch 8, gen_loss = 1.5109929086326004, disc_loss = 0.012115251191196136
Trained batch 231 in epoch 8, gen_loss = 1.5109715644141724, disc_loss = 0.012063257044136945
Trained batch 232 in epoch 8, gen_loss = 1.5111502585492933, disc_loss = 0.012011717625733394
Trained batch 233 in epoch 8, gen_loss = 1.511015201990421, disc_loss = 0.011960578574312071
Trained batch 234 in epoch 8, gen_loss = 1.5110068207091474, disc_loss = 0.011909936931732909
Trained batch 235 in epoch 8, gen_loss = 1.5107520154472125, disc_loss = 0.011859800973717815
Trained batch 236 in epoch 8, gen_loss = 1.5106283152153723, disc_loss = 0.011809934212954887
Trained batch 237 in epoch 8, gen_loss = 1.510380175183801, disc_loss = 0.011760498599189395
Trained batch 238 in epoch 8, gen_loss = 1.510361355468319, disc_loss = 0.011711520623797102
Trained batch 239 in epoch 8, gen_loss = 1.5101578113933405, disc_loss = 0.011663046560897783
Trained batch 240 in epoch 8, gen_loss = 1.5101149277568358, disc_loss = 0.011614868038790919
Trained batch 241 in epoch 8, gen_loss = 1.5102294227801079, disc_loss = 0.01156707125383863
Trained batch 242 in epoch 8, gen_loss = 1.5104467365967393, disc_loss = 0.011519847988586254
Trained batch 243 in epoch 8, gen_loss = 1.5102931581071166, disc_loss = 0.011472855722801245
Trained batch 244 in epoch 8, gen_loss = 1.5104274985741595, disc_loss = 0.011426492344869576
Trained batch 245 in epoch 8, gen_loss = 1.5102182570996323, disc_loss = 0.011380262985205367
Trained batch 246 in epoch 8, gen_loss = 1.5103607836522555, disc_loss = 0.01133445743624562
Trained batch 247 in epoch 8, gen_loss = 1.5104111233545887, disc_loss = 0.011289058278224172
Trained batch 248 in epoch 8, gen_loss = 1.5103626852054672, disc_loss = 0.011243905116794944
Trained batch 249 in epoch 8, gen_loss = 1.5106883170604706, disc_loss = 0.011199628247399233
Trained batch 250 in epoch 8, gen_loss = 1.5106407662786812, disc_loss = 0.011155690808475656
Trained batch 251 in epoch 8, gen_loss = 1.51088346730149, disc_loss = 0.011112009271369423
Trained batch 252 in epoch 8, gen_loss = 1.510791280759653, disc_loss = 0.011068444382746151
Trained batch 253 in epoch 8, gen_loss = 1.510999173395277, disc_loss = 0.011025220452469025
Trained batch 254 in epoch 8, gen_loss = 1.5111532667103935, disc_loss = 0.01098234379864081
Trained batch 255 in epoch 8, gen_loss = 1.511213681427762, disc_loss = 0.010939653119422132
Trained batch 256 in epoch 8, gen_loss = 1.5113218728206501, disc_loss = 0.010897314569856003
Trained batch 257 in epoch 8, gen_loss = 1.5113009895927223, disc_loss = 0.010855389855083037
Trained batch 258 in epoch 8, gen_loss = 1.5111682067506562, disc_loss = 0.010813717833920392
Trained batch 259 in epoch 8, gen_loss = 1.5111966745211527, disc_loss = 0.010772342879191946
Trained batch 260 in epoch 8, gen_loss = 1.5112670214696862, disc_loss = 0.010731197621900154
Trained batch 261 in epoch 8, gen_loss = 1.5110654446459908, disc_loss = 0.010690386042682359
Trained batch 262 in epoch 8, gen_loss = 1.5111143269466356, disc_loss = 0.010649978525387392
Trained batch 263 in epoch 8, gen_loss = 1.5112490796230056, disc_loss = 0.010609853643459108
Trained batch 264 in epoch 8, gen_loss = 1.5112990961884551, disc_loss = 0.010570012332796325
Trained batch 265 in epoch 8, gen_loss = 1.5114232891036155, disc_loss = 0.01053062730761325
Trained batch 266 in epoch 8, gen_loss = 1.51138118791223, disc_loss = 0.0104914013787997
Trained batch 267 in epoch 8, gen_loss = 1.511371073215755, disc_loss = 0.010452417535599301
Trained batch 268 in epoch 8, gen_loss = 1.5112383288078592, disc_loss = 0.010413794731264168
Trained batch 269 in epoch 8, gen_loss = 1.511211481138512, disc_loss = 0.010375370066038966
Trained batch 270 in epoch 8, gen_loss = 1.5111810133905867, disc_loss = 0.010337272695310493
Trained batch 271 in epoch 8, gen_loss = 1.511135341709151, disc_loss = 0.010299400835546133
Trained batch 272 in epoch 8, gen_loss = 1.5109939874310196, disc_loss = 0.010261828976468185
Trained batch 273 in epoch 8, gen_loss = 1.5111845137864133, disc_loss = 0.01022452507939731
Trained batch 274 in epoch 8, gen_loss = 1.5109925731745633, disc_loss = 0.010187548478120747
Trained batch 275 in epoch 8, gen_loss = 1.5109431896952614, disc_loss = 0.010150771462352735
Trained batch 276 in epoch 8, gen_loss = 1.511041554948483, disc_loss = 0.010114262807361057
Trained batch 277 in epoch 8, gen_loss = 1.5110619662048148, disc_loss = 0.010078011320624584
Trained batch 278 in epoch 8, gen_loss = 1.5110516815202637, disc_loss = 0.010042069181782676
Trained batch 279 in epoch 8, gen_loss = 1.5112240614635604, disc_loss = 0.010006394661247343
Trained batch 280 in epoch 8, gen_loss = 1.5109342597557556, disc_loss = 0.009971088540455591
Trained batch 281 in epoch 8, gen_loss = 1.5107210923171213, disc_loss = 0.009935944874164403
Trained batch 282 in epoch 8, gen_loss = 1.5106248103687705, disc_loss = 0.009901081456586512
Trained batch 283 in epoch 8, gen_loss = 1.5106205820617542, disc_loss = 0.009866405634799687
Trained batch 284 in epoch 8, gen_loss = 1.5107536556427938, disc_loss = 0.00983197796206999
Trained batch 285 in epoch 8, gen_loss = 1.5107024905981716, disc_loss = 0.009797755525179998
Trained batch 286 in epoch 8, gen_loss = 1.510828839569557, disc_loss = 0.009763872732851696
Trained batch 287 in epoch 8, gen_loss = 1.5108163507862225, disc_loss = 0.009730228460158388
Trained batch 288 in epoch 8, gen_loss = 1.5108250888986159, disc_loss = 0.009696771807555321
Trained batch 289 in epoch 8, gen_loss = 1.5107702750584175, disc_loss = 0.009663460680405541
Trained batch 290 in epoch 8, gen_loss = 1.5108436049054987, disc_loss = 0.009630418576623086
Trained batch 291 in epoch 8, gen_loss = 1.5107742856218391, disc_loss = 0.00959765508249715
Trained batch 292 in epoch 8, gen_loss = 1.5109306779330909, disc_loss = 0.009565084098679639
Trained batch 293 in epoch 8, gen_loss = 1.5108436757609958, disc_loss = 0.00953265664203191
Trained batch 294 in epoch 8, gen_loss = 1.5105495822631707, disc_loss = 0.009500525475448092
Trained batch 295 in epoch 8, gen_loss = 1.51027462631464, disc_loss = 0.009468585607231256
Trained batch 296 in epoch 8, gen_loss = 1.5103202530430624, disc_loss = 0.009437010045198512
Trained batch 297 in epoch 8, gen_loss = 1.510221433519517, disc_loss = 0.009405548931425183
Trained batch 298 in epoch 8, gen_loss = 1.5102092456259457, disc_loss = 0.009374203360700835
Trained batch 299 in epoch 8, gen_loss = 1.5103347915410996, disc_loss = 0.009343088175155572
Trained batch 300 in epoch 8, gen_loss = 1.5103421050844794, disc_loss = 0.009312167696776046
Trained batch 301 in epoch 8, gen_loss = 1.510221526125409, disc_loss = 0.009281480735422664
Trained batch 302 in epoch 8, gen_loss = 1.5100955485117318, disc_loss = 0.009251031065132068
Trained batch 303 in epoch 8, gen_loss = 1.5101074456776444, disc_loss = 0.009220739123317176
Trained batch 304 in epoch 8, gen_loss = 1.510024772511154, disc_loss = 0.009190754818414686
Trained batch 305 in epoch 8, gen_loss = 1.5098818008806192, disc_loss = 0.009160874643688052
Trained batch 306 in epoch 8, gen_loss = 1.5100342048884214, disc_loss = 0.009131263487016063
Trained batch 307 in epoch 8, gen_loss = 1.510194157431652, disc_loss = 0.00910178276664336
Trained batch 308 in epoch 8, gen_loss = 1.510139283817563, disc_loss = 0.009072531913779658
Trained batch 309 in epoch 8, gen_loss = 1.510027261126426, disc_loss = 0.009043444042559244
Trained batch 310 in epoch 8, gen_loss = 1.5098030385097123, disc_loss = 0.009014574150820888
Trained batch 311 in epoch 8, gen_loss = 1.5097185486020186, disc_loss = 0.008985933072614362
Trained batch 312 in epoch 8, gen_loss = 1.509915837655052, disc_loss = 0.008957417744437616
Trained batch 313 in epoch 8, gen_loss = 1.5099136584503636, disc_loss = 0.00892905299130521
Trained batch 314 in epoch 8, gen_loss = 1.5098712423491099, disc_loss = 0.008900851053430603
Trained batch 315 in epoch 8, gen_loss = 1.5096415411445159, disc_loss = 0.00887286263428053
Trained batch 316 in epoch 8, gen_loss = 1.5095371175263583, disc_loss = 0.008845103193374317
Trained batch 317 in epoch 8, gen_loss = 1.5095844116975676, disc_loss = 0.008817462229654786
Trained batch 318 in epoch 8, gen_loss = 1.5093688140842234, disc_loss = 0.008789927712242962
Trained batch 319 in epoch 8, gen_loss = 1.5093926722183824, disc_loss = 0.008762658711998484
Trained batch 320 in epoch 8, gen_loss = 1.5097714066505432, disc_loss = 0.008736143699288478
Trained batch 321 in epoch 8, gen_loss = 1.5098174464258347, disc_loss = 0.008709514495693052
Trained batch 322 in epoch 8, gen_loss = 1.5098013115741151, disc_loss = 0.008682886394973947
Trained batch 323 in epoch 8, gen_loss = 1.5097709561203734, disc_loss = 0.008656255238972257
Trained batch 324 in epoch 8, gen_loss = 1.5098968944182762, disc_loss = 0.008629828886164781
Trained batch 325 in epoch 8, gen_loss = 1.510038892001462, disc_loss = 0.00860353339220375
Trained batch 326 in epoch 8, gen_loss = 1.5099214798449012, disc_loss = 0.008577482134769693
Trained batch 327 in epoch 8, gen_loss = 1.510116222973277, disc_loss = 0.00855163755896661
Trained batch 328 in epoch 8, gen_loss = 1.5102491934973419, disc_loss = 0.008525879614317533
Trained batch 329 in epoch 8, gen_loss = 1.5103127484971828, disc_loss = 0.008500259357595385
Trained batch 330 in epoch 8, gen_loss = 1.5103548500473045, disc_loss = 0.008474721491839853
Trained batch 331 in epoch 8, gen_loss = 1.5103006289306893, disc_loss = 0.008449346127816674
Trained batch 332 in epoch 8, gen_loss = 1.5103325369479779, disc_loss = 0.008424172552316726
Trained batch 333 in epoch 8, gen_loss = 1.510405939317749, disc_loss = 0.008399147268800427
Trained batch 334 in epoch 8, gen_loss = 1.5105115810436989, disc_loss = 0.008374249622631478
Trained batch 335 in epoch 8, gen_loss = 1.5105102699072588, disc_loss = 0.008349563220019177
Trained batch 336 in epoch 8, gen_loss = 1.5104510318985325, disc_loss = 0.008324899059656948
Trained batch 337 in epoch 8, gen_loss = 1.5105594821582884, disc_loss = 0.008300567282793096
Trained batch 338 in epoch 8, gen_loss = 1.510544135683054, disc_loss = 0.008276412143663208
Trained batch 339 in epoch 8, gen_loss = 1.5106158482677796, disc_loss = 0.00825235180390711
Trained batch 340 in epoch 8, gen_loss = 1.5104879055204978, disc_loss = 0.008228470033302335
Trained batch 341 in epoch 8, gen_loss = 1.510455699517713, disc_loss = 0.00820458365257248
Trained batch 342 in epoch 8, gen_loss = 1.5103533909202664, disc_loss = 0.008180964068657618
Trained batch 343 in epoch 8, gen_loss = 1.5104332398190055, disc_loss = 0.00815730405611248
Trained batch 344 in epoch 8, gen_loss = 1.510314672753431, disc_loss = 0.008133883839215834
Trained batch 345 in epoch 8, gen_loss = 1.5104866990808807, disc_loss = 0.008110627019113385
Trained batch 346 in epoch 8, gen_loss = 1.5105809435377204, disc_loss = 0.008087515921953607
Trained batch 347 in epoch 8, gen_loss = 1.5105831134935905, disc_loss = 0.008064477656377163
Trained batch 348 in epoch 8, gen_loss = 1.51062337153279, disc_loss = 0.00804149182017799
Trained batch 349 in epoch 8, gen_loss = 1.5108414658478329, disc_loss = 0.008018761181852564
Trained batch 350 in epoch 8, gen_loss = 1.5108723533459198, disc_loss = 0.007996139045183443
Trained batch 351 in epoch 8, gen_loss = 1.5107792339880357, disc_loss = 0.007973562388573637
Trained batch 352 in epoch 8, gen_loss = 1.510843470988125, disc_loss = 0.007951076612696095
Trained batch 353 in epoch 8, gen_loss = 1.5108807741922174, disc_loss = 0.007928748171602074
Trained batch 354 in epoch 8, gen_loss = 1.5110735277055014, disc_loss = 0.007906571103038157
Trained batch 355 in epoch 8, gen_loss = 1.510981365703465, disc_loss = 0.007884583716434699
Trained batch 356 in epoch 8, gen_loss = 1.5109164726500417, disc_loss = 0.007862818051184281
Trained batch 357 in epoch 8, gen_loss = 1.5109420097407016, disc_loss = 0.007840999984151931
Trained batch 358 in epoch 8, gen_loss = 1.510718217965288, disc_loss = 0.007819532436795139
Trained batch 359 in epoch 8, gen_loss = 1.510608577231566, disc_loss = 0.007798037137268289
Trained batch 360 in epoch 8, gen_loss = 1.5105606137550438, disc_loss = 0.007776592417416234
Trained batch 361 in epoch 8, gen_loss = 1.5103944561428786, disc_loss = 0.00775534403863135
Trained batch 362 in epoch 8, gen_loss = 1.5103559810924794, disc_loss = 0.007734064506468672
Trained batch 363 in epoch 8, gen_loss = 1.5103172569812, disc_loss = 0.007712981851719823
Trained batch 364 in epoch 8, gen_loss = 1.5103271130013138, disc_loss = 0.0076920763342059216
Trained batch 365 in epoch 8, gen_loss = 1.5103093690233804, disc_loss = 0.007671153602301085
Trained batch 366 in epoch 8, gen_loss = 1.5101949439386582, disc_loss = 0.007650364053395417
Trained batch 367 in epoch 8, gen_loss = 1.51037325369923, disc_loss = 0.007629696516035082
Trained batch 368 in epoch 8, gen_loss = 1.5104139905957994, disc_loss = 0.007609139035537437
Trained batch 369 in epoch 8, gen_loss = 1.5104364248546394, disc_loss = 0.007588743031944457
Trained batch 370 in epoch 8, gen_loss = 1.5104207174797264, disc_loss = 0.0075684652609129014
Trained batch 371 in epoch 8, gen_loss = 1.510390912813525, disc_loss = 0.007548262682135946
Trained batch 372 in epoch 8, gen_loss = 1.5104885905102174, disc_loss = 0.007528144159875017
Trained batch 373 in epoch 8, gen_loss = 1.510422002026104, disc_loss = 0.007508134124394743
Trained batch 374 in epoch 8, gen_loss = 1.510379323164622, disc_loss = 0.007488227328916158
Trained batch 375 in epoch 8, gen_loss = 1.5102026543401657, disc_loss = 0.0074683894150207085
Trained batch 376 in epoch 8, gen_loss = 1.5102495747156421, disc_loss = 0.0074487420972039866
Trained batch 377 in epoch 8, gen_loss = 1.510249852345734, disc_loss = 0.0074291573775034135
Trained batch 378 in epoch 8, gen_loss = 1.5102478836645865, disc_loss = 0.007409676398363488
Trained batch 379 in epoch 8, gen_loss = 1.5102669959005557, disc_loss = 0.007390294528474777
Trained batch 380 in epoch 8, gen_loss = 1.510391151967637, disc_loss = 0.007371111046227616
Trained batch 381 in epoch 8, gen_loss = 1.510386100146159, disc_loss = 0.0073519879765317165
Trained batch 382 in epoch 8, gen_loss = 1.510395938827226, disc_loss = 0.007332906021493625
Trained batch 383 in epoch 8, gen_loss = 1.5103481571810942, disc_loss = 0.00731401194422195
Trained batch 384 in epoch 8, gen_loss = 1.5101557600033748, disc_loss = 0.007295249048845356
Trained batch 385 in epoch 8, gen_loss = 1.5100796196436017, disc_loss = 0.007276508883982755
Trained batch 386 in epoch 8, gen_loss = 1.5101686671414734, disc_loss = 0.007257812741150955
Trained batch 387 in epoch 8, gen_loss = 1.5100890826625921, disc_loss = 0.007239207694988884
Trained batch 388 in epoch 8, gen_loss = 1.5100596559384796, disc_loss = 0.007220720088537028
Trained batch 389 in epoch 8, gen_loss = 1.5100298213653076, disc_loss = 0.007202315798787869
Trained batch 390 in epoch 8, gen_loss = 1.510160440831538, disc_loss = 0.007183980056954606
Trained batch 391 in epoch 8, gen_loss = 1.5101624674030714, disc_loss = 0.007165741367511406
Trained batch 392 in epoch 8, gen_loss = 1.5101612719870705, disc_loss = 0.007147650088187803
Trained batch 393 in epoch 8, gen_loss = 1.5102217253392118, disc_loss = 0.007129605218088833
Trained batch 394 in epoch 8, gen_loss = 1.5101949294911154, disc_loss = 0.007111645996420647
Trained batch 395 in epoch 8, gen_loss = 1.510149545591287, disc_loss = 0.0070937946792389885
Trained batch 396 in epoch 8, gen_loss = 1.5101497946518194, disc_loss = 0.0070759954710766055
Trained batch 397 in epoch 8, gen_loss = 1.5099478251670473, disc_loss = 0.007058388049544324
Trained batch 398 in epoch 8, gen_loss = 1.5099605347279619, disc_loss = 0.007040816970894733
Trained batch 399 in epoch 8, gen_loss = 1.5099017100036145, disc_loss = 0.007023306745741138
Trained batch 400 in epoch 8, gen_loss = 1.5098914854841636, disc_loss = 0.007005910871488677
Trained batch 401 in epoch 8, gen_loss = 1.5097185401477624, disc_loss = 0.006988586080102386
Trained batch 402 in epoch 8, gen_loss = 1.5097261408422484, disc_loss = 0.006971334981896799
Trained batch 403 in epoch 8, gen_loss = 1.50989994214903, disc_loss = 0.006954950039705568
Trained batch 404 in epoch 8, gen_loss = 1.5099419771889109, disc_loss = 0.006938656726695761
Trained batch 405 in epoch 8, gen_loss = 1.5099125635154143, disc_loss = 0.0069219705764149925
Trained batch 406 in epoch 8, gen_loss = 1.5100535794323726, disc_loss = 0.006905445765007213
Trained batch 407 in epoch 8, gen_loss = 1.5100899287590794, disc_loss = 0.006888857396104725
Trained batch 408 in epoch 8, gen_loss = 1.5100520293986592, disc_loss = 0.006872247399625008
Trained batch 409 in epoch 8, gen_loss = 1.5100866261051922, disc_loss = 0.006855648055379123
Trained batch 410 in epoch 8, gen_loss = 1.5101128797751564, disc_loss = 0.006839156111667554
Trained batch 411 in epoch 8, gen_loss = 1.509811464588619, disc_loss = 0.006823474104687229
Trained batch 412 in epoch 8, gen_loss = 1.5097197806575395, disc_loss = 0.006807662248346838
Trained batch 413 in epoch 8, gen_loss = 1.50985261855494, disc_loss = 0.006791389587402846
Trained batch 414 in epoch 8, gen_loss = 1.509778088977538, disc_loss = 0.00677528545655435
Trained batch 415 in epoch 8, gen_loss = 1.5099329204800038, disc_loss = 0.006759210084729043
Trained batch 416 in epoch 8, gen_loss = 1.5099158900247203, disc_loss = 0.0067432026414980814
Trained batch 417 in epoch 8, gen_loss = 1.5097764583580802, disc_loss = 0.006727274992693236
Trained batch 418 in epoch 8, gen_loss = 1.5097420592581172, disc_loss = 0.006711405823412527
Trained batch 419 in epoch 8, gen_loss = 1.5096806771698452, disc_loss = 0.006695589825115652
Trained batch 420 in epoch 8, gen_loss = 1.5096108379669824, disc_loss = 0.006679806512598122
Trained batch 421 in epoch 8, gen_loss = 1.5096547246261796, disc_loss = 0.006664053420656912
Trained batch 422 in epoch 8, gen_loss = 1.509687977620614, disc_loss = 0.006648376311299234
Trained batch 423 in epoch 8, gen_loss = 1.5094598878948193, disc_loss = 0.006632846613889719
Trained batch 424 in epoch 8, gen_loss = 1.5095115292773527, disc_loss = 0.006617483128759298
Trained batch 425 in epoch 8, gen_loss = 1.5094305012427585, disc_loss = 0.0066021666919287595
Trained batch 426 in epoch 8, gen_loss = 1.5093832397070088, disc_loss = 0.0065867889928914345
Trained batch 427 in epoch 8, gen_loss = 1.5094186765289752, disc_loss = 0.006571563106475555
Trained batch 428 in epoch 8, gen_loss = 1.5093852797032514, disc_loss = 0.006556356816855761
Trained batch 429 in epoch 8, gen_loss = 1.50937714673752, disc_loss = 0.006541162711669871
Trained batch 430 in epoch 8, gen_loss = 1.5093613283540146, disc_loss = 0.0065260722639810375
Trained batch 431 in epoch 8, gen_loss = 1.5092805953765358, disc_loss = 0.0065110645325392865
Trained batch 432 in epoch 8, gen_loss = 1.5092924608919966, disc_loss = 0.006496106292830124
Trained batch 433 in epoch 8, gen_loss = 1.5091651948640972, disc_loss = 0.00648122692722785
Trained batch 434 in epoch 8, gen_loss = 1.5090651584767747, disc_loss = 0.006466426249357153
Trained batch 435 in epoch 8, gen_loss = 1.5090601475687202, disc_loss = 0.006451728697269272
Trained batch 436 in epoch 8, gen_loss = 1.5089810657010199, disc_loss = 0.0064370494346470755
Trained batch 437 in epoch 8, gen_loss = 1.508772593791082, disc_loss = 0.006422491560745887
Trained batch 438 in epoch 8, gen_loss = 1.5086852571415739, disc_loss = 0.006407996036720008
Trained batch 439 in epoch 8, gen_loss = 1.508687390116128, disc_loss = 0.0063935165532670495
Trained batch 440 in epoch 8, gen_loss = 1.5087980173882984, disc_loss = 0.006379135542510685
Trained batch 441 in epoch 8, gen_loss = 1.5087511144342465, disc_loss = 0.006364834758942667
Trained batch 442 in epoch 8, gen_loss = 1.5086742444447416, disc_loss = 0.006350575757568719
Trained batch 443 in epoch 8, gen_loss = 1.508537810262259, disc_loss = 0.006336335634821332
Trained batch 444 in epoch 8, gen_loss = 1.5085324808452907, disc_loss = 0.006322245026513996
Trained batch 445 in epoch 8, gen_loss = 1.5084939100549895, disc_loss = 0.006308208862776865
Trained batch 446 in epoch 8, gen_loss = 1.508533299769331, disc_loss = 0.006294169690631627
Trained batch 447 in epoch 8, gen_loss = 1.508477557583579, disc_loss = 0.0062802058009968475
Trained batch 448 in epoch 8, gen_loss = 1.5084755549452087, disc_loss = 0.006266457071487943
Trained batch 449 in epoch 8, gen_loss = 1.5084626143508488, disc_loss = 0.006252692106924466
Trained batch 450 in epoch 8, gen_loss = 1.5086201626287068, disc_loss = 0.0062393144963504635
Trained batch 451 in epoch 8, gen_loss = 1.5086853850995545, disc_loss = 0.006225969494615901
Trained batch 452 in epoch 8, gen_loss = 1.5087301556111434, disc_loss = 0.0062124725306380215
Trained batch 453 in epoch 8, gen_loss = 1.5086546877669869, disc_loss = 0.006198905762800882
Trained batch 454 in epoch 8, gen_loss = 1.5085911759963402, disc_loss = 0.0061853870054699575
Trained batch 455 in epoch 8, gen_loss = 1.5084853191909038, disc_loss = 0.00617200473392219
Trained batch 456 in epoch 8, gen_loss = 1.5084603971412458, disc_loss = 0.006158642107663663
Trained batch 457 in epoch 8, gen_loss = 1.508338008515179, disc_loss = 0.006145321647227519
Trained batch 458 in epoch 8, gen_loss = 1.5082047225862807, disc_loss = 0.006132038085499223
Trained batch 459 in epoch 8, gen_loss = 1.5080671915541524, disc_loss = 0.006118830818523629
Trained batch 460 in epoch 8, gen_loss = 1.508051620000355, disc_loss = 0.006105626959543492
Trained batch 461 in epoch 8, gen_loss = 1.5080069826020823, disc_loss = 0.0060925471099867205
Trained batch 462 in epoch 8, gen_loss = 1.5079448744493735, disc_loss = 0.006079547061179228
Trained batch 463 in epoch 8, gen_loss = 1.507851876960746, disc_loss = 0.00606659895695743
Trained batch 464 in epoch 8, gen_loss = 1.507963252708476, disc_loss = 0.006053693608089972
Trained batch 465 in epoch 8, gen_loss = 1.5079756554360042, disc_loss = 0.00604081322861161
Trained batch 466 in epoch 8, gen_loss = 1.5079158293103252, disc_loss = 0.006027942692195187
Trained batch 467 in epoch 8, gen_loss = 1.5081014705774112, disc_loss = 0.006015242507025979
Trained batch 468 in epoch 8, gen_loss = 1.5080901652510994, disc_loss = 0.006002517938343642
Trained batch 469 in epoch 8, gen_loss = 1.508172643818754, disc_loss = 0.005989851294013553
Trained batch 470 in epoch 8, gen_loss = 1.5082698664341256, disc_loss = 0.005977238149910739
Trained batch 471 in epoch 8, gen_loss = 1.5082522379392285, disc_loss = 0.0059646919103601
Trained batch 472 in epoch 8, gen_loss = 1.5082347096902875, disc_loss = 0.005952171257000031
Trained batch 474 in epoch 8, gen_loss = 1.5083469801200065, disc_loss = 0.005927310404712395
Trained batch 475 in epoch 8, gen_loss = 1.5082022506399315, disc_loss = 0.0059150146149217365
Trained batch 476 in epoch 8, gen_loss = 1.5082405287014864, disc_loss = 0.005902745454937068
Trained batch 477 in epoch 8, gen_loss = 1.5082970928696908, disc_loss = 0.005890543769702433
Trained batch 478 in epoch 8, gen_loss = 1.5083438194121597, disc_loss = 0.005878317095741222
Trained batch 479 in epoch 8, gen_loss = 1.5082009882976612, disc_loss = 0.005866175776607936
Trained batch 480 in epoch 8, gen_loss = 1.508168997115256, disc_loss = 0.005854156672875113
Trained batch 481 in epoch 8, gen_loss = 1.5079590926773816, disc_loss = 0.005842271820313036
Trained batch 482 in epoch 8, gen_loss = 1.5079254426571154, disc_loss = 0.005830414787508915
Trained batch 483 in epoch 8, gen_loss = 1.5079202138441654, disc_loss = 0.005818551783238584
Trained batch 484 in epoch 8, gen_loss = 1.5079443202805274, disc_loss = 0.005806777849317871
Trained batch 485 in epoch 8, gen_loss = 1.5079601089404935, disc_loss = 0.005794987813737581
Trained batch 486 in epoch 8, gen_loss = 1.507916100338499, disc_loss = 0.005783160780522436
Trained batch 487 in epoch 8, gen_loss = 1.5079510037283428, disc_loss = 0.005771390086174804
Trained batch 488 in epoch 8, gen_loss = 1.507914924060884, disc_loss = 0.005759647818793825
Trained batch 489 in epoch 8, gen_loss = 1.5080603464525573, disc_loss = 0.005748117141771143
Trained batch 490 in epoch 8, gen_loss = 1.5081805649939963, disc_loss = 0.005736602091154669
Trained batch 491 in epoch 8, gen_loss = 1.508119381903633, disc_loss = 0.005725056522029573
Trained batch 492 in epoch 8, gen_loss = 1.5080362603098578, disc_loss = 0.005713568885265227
Trained batch 493 in epoch 8, gen_loss = 1.5081376473189365, disc_loss = 0.005702114389707924
Trained batch 494 in epoch 8, gen_loss = 1.508186987795011, disc_loss = 0.005690713746971045
Trained batch 495 in epoch 8, gen_loss = 1.5081399747681232, disc_loss = 0.005679326024043745
Trained batch 496 in epoch 8, gen_loss = 1.5081425774505202, disc_loss = 0.00566797093027929
Trained batch 497 in epoch 8, gen_loss = 1.5081450217459575, disc_loss = 0.0056566382860277755
Trained batch 498 in epoch 8, gen_loss = 1.5081531938187822, disc_loss = 0.005645371098711884
Trained batch 499 in epoch 8, gen_loss = 1.5081361535787583, disc_loss = 0.005634159716715658
Trained batch 500 in epoch 8, gen_loss = 1.5081247839623106, disc_loss = 0.0056229986209932565
Trained batch 501 in epoch 8, gen_loss = 1.508120890038897, disc_loss = 0.005611852964362023
Trained batch 502 in epoch 8, gen_loss = 1.5080963028354153, disc_loss = 0.005600800019122074
Trained batch 503 in epoch 8, gen_loss = 1.507990286582046, disc_loss = 0.0055897840870531785
Trained batch 504 in epoch 8, gen_loss = 1.5080289695522573, disc_loss = 0.005578789547248427
Trained batch 505 in epoch 8, gen_loss = 1.5079963750283238, disc_loss = 0.005567837065097014
Trained batch 506 in epoch 8, gen_loss = 1.5080228600746546, disc_loss = 0.0055570215451823815
Trained batch 507 in epoch 8, gen_loss = 1.5080720098234537, disc_loss = 0.0055462760362431475
Trained batch 508 in epoch 8, gen_loss = 1.5081136485448285, disc_loss = 0.005535604573338066
Trained batch 509 in epoch 8, gen_loss = 1.5081201687747356, disc_loss = 0.005524897536812276
Trained batch 510 in epoch 8, gen_loss = 1.5081052830307917, disc_loss = 0.005514158319733911
Trained batch 511 in epoch 8, gen_loss = 1.5080828292993829, disc_loss = 0.005503518343555669
Trained batch 512 in epoch 8, gen_loss = 1.5080988050436648, disc_loss = 0.005492914625947502
Trained batch 513 in epoch 8, gen_loss = 1.5081076217300697, disc_loss = 0.0054823253904846695
Trained batch 514 in epoch 8, gen_loss = 1.5080022276026532, disc_loss = 0.00547175916929792
Trained batch 515 in epoch 8, gen_loss = 1.508007671597392, disc_loss = 0.005461256018688871
Trained batch 516 in epoch 8, gen_loss = 1.507919050392837, disc_loss = 0.005450762258864964
Trained batch 517 in epoch 8, gen_loss = 1.5080413518034814, disc_loss = 0.0054404427016509415
Trained batch 518 in epoch 8, gen_loss = 1.5080055596741178, disc_loss = 0.005430157641017726
Trained batch 519 in epoch 8, gen_loss = 1.507919458586436, disc_loss = 0.005419895287500017
Trained batch 520 in epoch 8, gen_loss = 1.5078867112148746, disc_loss = 0.005409574063444722
Trained batch 521 in epoch 8, gen_loss = 1.5078912515521505, disc_loss = 0.0053993188905042885
Trained batch 522 in epoch 8, gen_loss = 1.5079120339444674, disc_loss = 0.005389172487954564
Trained batch 523 in epoch 8, gen_loss = 1.5078397157765526, disc_loss = 0.00537923767080623
Trained batch 524 in epoch 8, gen_loss = 1.5077586781410943, disc_loss = 0.005369206814090527
Trained batch 525 in epoch 8, gen_loss = 1.5077369234634443, disc_loss = 0.005359117231680929
Trained batch 526 in epoch 8, gen_loss = 1.5076718453664255, disc_loss = 0.005349040270562906
Trained batch 527 in epoch 8, gen_loss = 1.5076796838054152, disc_loss = 0.0053390454676425425
Trained batch 528 in epoch 8, gen_loss = 1.507647895294687, disc_loss = 0.005329108877781703
Trained batch 529 in epoch 8, gen_loss = 1.5074764131375078, disc_loss = 0.005319147225390963
Trained batch 530 in epoch 8, gen_loss = 1.507562182829654, disc_loss = 0.005309292145652668
Trained batch 531 in epoch 8, gen_loss = 1.5075846452237969, disc_loss = 0.005299468808451431
Trained batch 532 in epoch 8, gen_loss = 1.5074910409678661, disc_loss = 0.005289624887803207
Trained batch 533 in epoch 8, gen_loss = 1.507295411959123, disc_loss = 0.005279929337669269
Trained batch 534 in epoch 8, gen_loss = 1.507345500282038, disc_loss = 0.005270282048574963
Trained batch 535 in epoch 8, gen_loss = 1.5074279551852996, disc_loss = 0.005260558555032256
Trained batch 536 in epoch 8, gen_loss = 1.5073125037179091, disc_loss = 0.005250957399881945
Trained batch 537 in epoch 8, gen_loss = 1.5073238907028752, disc_loss = 0.005241389270349658
Trained batch 538 in epoch 8, gen_loss = 1.5073108464092404, disc_loss = 0.005231867053802951
Trained batch 539 in epoch 8, gen_loss = 1.5073304526231908, disc_loss = 0.005222371080731978
Trained batch 540 in epoch 8, gen_loss = 1.507278944450033, disc_loss = 0.005212844638064743
Trained batch 541 in epoch 8, gen_loss = 1.507354689150279, disc_loss = 0.005203340655937968
Trained batch 542 in epoch 8, gen_loss = 1.5074397748126949, disc_loss = 0.005193879716979061
Trained batch 543 in epoch 8, gen_loss = 1.5074302417171352, disc_loss = 0.005184404768265401
Trained batch 544 in epoch 8, gen_loss = 1.50753018517013, disc_loss = 0.005174986215400025
Trained batch 545 in epoch 8, gen_loss = 1.5074444990673346, disc_loss = 0.005165580898222458
Trained batch 546 in epoch 8, gen_loss = 1.507445044992611, disc_loss = 0.005156220608180889
Trained batch 547 in epoch 8, gen_loss = 1.5074039679156603, disc_loss = 0.00514687823927349
Trained batch 548 in epoch 8, gen_loss = 1.5073956417255714, disc_loss = 0.005137546253784625
Trained batch 549 in epoch 8, gen_loss = 1.5073175082423471, disc_loss = 0.005128248305677103
Trained batch 550 in epoch 8, gen_loss = 1.5072498545456279, disc_loss = 0.005118976130054839
Trained batch 551 in epoch 8, gen_loss = 1.507211528286554, disc_loss = 0.005109732164377736
Trained batch 552 in epoch 8, gen_loss = 1.5071457034856026, disc_loss = 0.005100539858252143
Trained batch 553 in epoch 8, gen_loss = 1.5071235913447094, disc_loss = 0.005091396430323696
Trained batch 554 in epoch 8, gen_loss = 1.5070839616629454, disc_loss = 0.005082277358471057
Trained batch 555 in epoch 8, gen_loss = 1.5070727440736276, disc_loss = 0.005073197855950547
Trained batch 556 in epoch 8, gen_loss = 1.5070560632317027, disc_loss = 0.005064161544672435
Trained batch 557 in epoch 8, gen_loss = 1.5070700755469688, disc_loss = 0.005055134313552508
Trained batch 558 in epoch 8, gen_loss = 1.507012587433851, disc_loss = 0.005046137805669875
Trained batch 559 in epoch 8, gen_loss = 1.5069065280258656, disc_loss = 0.005037218410396755
Trained batch 560 in epoch 8, gen_loss = 1.5068767475571863, disc_loss = 0.005028325905535207
Trained batch 561 in epoch 8, gen_loss = 1.5068241263411648, disc_loss = 0.005019470436497073
Trained batch 562 in epoch 8, gen_loss = 1.5067945937915552, disc_loss = 0.0050106273512718355
Trained batch 563 in epoch 8, gen_loss = 1.5067607926350113, disc_loss = 0.005001803156190376
Trained batch 564 in epoch 8, gen_loss = 1.5067172583225554, disc_loss = 0.004993004742895193
Trained batch 565 in epoch 8, gen_loss = 1.5067380090694966, disc_loss = 0.004984246609859671
Trained batch 566 in epoch 8, gen_loss = 1.506707231729329, disc_loss = 0.0049755195615921646
Trained batch 567 in epoch 8, gen_loss = 1.5066421647936525, disc_loss = 0.004966845376823675
Trained batch 568 in epoch 8, gen_loss = 1.5066908469099571, disc_loss = 0.004958223858303988
Trained batch 569 in epoch 8, gen_loss = 1.5066819804802276, disc_loss = 0.004949599620037285
Trained batch 570 in epoch 8, gen_loss = 1.5066279430731793, disc_loss = 0.00494099401721908
Trained batch 571 in epoch 8, gen_loss = 1.5066787557793664, disc_loss = 0.004932457315520038
Trained batch 572 in epoch 8, gen_loss = 1.506675729680852, disc_loss = 0.0049239235572657815
Trained batch 573 in epoch 8, gen_loss = 1.506713133759615, disc_loss = 0.00491540357347176
Trained batch 574 in epoch 8, gen_loss = 1.5067516790265623, disc_loss = 0.004906912526759856
Trained batch 575 in epoch 8, gen_loss = 1.5066703540376492, disc_loss = 0.004898468447493087
Trained batch 576 in epoch 8, gen_loss = 1.506635212092507, disc_loss = 0.004890141935215404
Trained batch 577 in epoch 8, gen_loss = 1.5066942565375134, disc_loss = 0.00488180207826835
Trained batch 578 in epoch 8, gen_loss = 1.5066251992561657, disc_loss = 0.004873466329201576
Trained batch 579 in epoch 8, gen_loss = 1.5065520326639044, disc_loss = 0.004865283500795817
Trained batch 580 in epoch 8, gen_loss = 1.5065337330256805, disc_loss = 0.004857043625485393
Trained batch 581 in epoch 8, gen_loss = 1.5065034700628, disc_loss = 0.004848791833871358
Trained batch 582 in epoch 8, gen_loss = 1.5064410765624987, disc_loss = 0.004840630427756012
Trained batch 583 in epoch 8, gen_loss = 1.5064061470840076, disc_loss = 0.004832445456037794
Trained batch 584 in epoch 8, gen_loss = 1.5063374797503153, disc_loss = 0.004824282582017193
Trained batch 585 in epoch 8, gen_loss = 1.5063065289433906, disc_loss = 0.004816144107010652
Trained batch 586 in epoch 8, gen_loss = 1.506262365455725, disc_loss = 0.004808013713584701
Trained batch 587 in epoch 8, gen_loss = 1.5062454331691573, disc_loss = 0.004799907109286107
Trained batch 588 in epoch 8, gen_loss = 1.506219162499763, disc_loss = 0.00479185166604928
Trained batch 589 in epoch 8, gen_loss = 1.50614020187976, disc_loss = 0.0047838644327431075
Trained batch 590 in epoch 8, gen_loss = 1.506140738876943, disc_loss = 0.00477589329580003
Trained batch 591 in epoch 8, gen_loss = 1.5061575952615287, disc_loss = 0.004767990411339171
Trained batch 592 in epoch 8, gen_loss = 1.5060833735771566, disc_loss = 0.004760018318746644
Trained batch 593 in epoch 8, gen_loss = 1.5059775331807057, disc_loss = 0.004752075448128558
Trained batch 594 in epoch 8, gen_loss = 1.5060491290413032, disc_loss = 0.004745306444458053
Trained batch 595 in epoch 8, gen_loss = 1.5061763670020456, disc_loss = 0.004738102045256704
Trained batch 596 in epoch 8, gen_loss = 1.5062276233780125, disc_loss = 0.0047306057966725315
Trained batch 597 in epoch 8, gen_loss = 1.5062540491488465, disc_loss = 0.004722887719144272
Trained batch 598 in epoch 8, gen_loss = 1.5062770410650759, disc_loss = 0.004715285629235388
Trained batch 599 in epoch 8, gen_loss = 1.506130200723807, disc_loss = 0.004707609805870258
Trained batch 600 in epoch 8, gen_loss = 1.5061996426439523, disc_loss = 0.004699964971477615
Trained batch 601 in epoch 8, gen_loss = 1.5062061895761776, disc_loss = 0.004692292317969588
Trained batch 602 in epoch 8, gen_loss = 1.506133026052668, disc_loss = 0.004684664824012988
Trained batch 603 in epoch 8, gen_loss = 1.5061257072039786, disc_loss = 0.004677035678589573
Trained batch 604 in epoch 8, gen_loss = 1.506124234101004, disc_loss = 0.0046693942919991665
Trained batch 605 in epoch 8, gen_loss = 1.5061022473050423, disc_loss = 0.004661803760076383
Trained batch 606 in epoch 8, gen_loss = 1.5060409903526306, disc_loss = 0.004654215231883133
Trained batch 607 in epoch 8, gen_loss = 1.5061013742693161, disc_loss = 0.004646867774956837
Trained batch 608 in epoch 8, gen_loss = 1.5060741248584928, disc_loss = 0.004639648460566195
Trained batch 609 in epoch 8, gen_loss = 1.5061103735790877, disc_loss = 0.004632346569496058
Trained batch 610 in epoch 8, gen_loss = 1.5061137156283602, disc_loss = 0.0046250870124544185
Trained batch 611 in epoch 8, gen_loss = 1.5061039845733082, disc_loss = 0.004617883540299326
Trained batch 612 in epoch 8, gen_loss = 1.506030212704937, disc_loss = 0.004610720271636146
Trained batch 613 in epoch 8, gen_loss = 1.5059899946959865, disc_loss = 0.00460361419411265
Trained batch 614 in epoch 8, gen_loss = 1.5058914348361938, disc_loss = 0.004596545798143247
Trained batch 615 in epoch 8, gen_loss = 1.505886554040692, disc_loss = 0.004589440583346571
Trained batch 616 in epoch 8, gen_loss = 1.5059001925891957, disc_loss = 0.004582423977291108
Trained batch 617 in epoch 8, gen_loss = 1.505948202606158, disc_loss = 0.004575454574799324
Trained batch 618 in epoch 8, gen_loss = 1.5059010105294828, disc_loss = 0.004568491319642701
Trained batch 619 in epoch 8, gen_loss = 1.5058306481569044, disc_loss = 0.0045615855600068065
Trained batch 620 in epoch 8, gen_loss = 1.5058071685298053, disc_loss = 0.004554813963695427
Trained batch 621 in epoch 8, gen_loss = 1.5057345727440627, disc_loss = 0.004548182267791774
Trained batch 622 in epoch 8, gen_loss = 1.5056699561269096, disc_loss = 0.004541701241515492
Trained batch 623 in epoch 8, gen_loss = 1.5056534683666167, disc_loss = 0.004535244769858064
Trained batch 624 in epoch 8, gen_loss = 1.5056201321601868, disc_loss = 0.00452870660739718
Trained batch 625 in epoch 8, gen_loss = 1.5055980193919647, disc_loss = 0.004522147596788726
Trained batch 626 in epoch 8, gen_loss = 1.5055319391179123, disc_loss = 0.0045160076704667765
Trained batch 627 in epoch 8, gen_loss = 1.5055992361276773, disc_loss = 0.004509446275240952
Trained batch 628 in epoch 8, gen_loss = 1.5056339088229194, disc_loss = 0.004502623001511364
Trained batch 629 in epoch 8, gen_loss = 1.505586909585529, disc_loss = 0.0044957280837046535
Trained batch 630 in epoch 8, gen_loss = 1.5055721082891413, disc_loss = 0.004488757544697765
Trained batch 631 in epoch 8, gen_loss = 1.5055561704160292, disc_loss = 0.004481761940686611
Trained batch 632 in epoch 8, gen_loss = 1.5056312653879043, disc_loss = 0.004474797517590528
Trained batch 633 in epoch 8, gen_loss = 1.5056284110440816, disc_loss = 0.004467871096695326
Trained batch 634 in epoch 8, gen_loss = 1.5056106498860937, disc_loss = 0.004460960016945674
Trained batch 635 in epoch 8, gen_loss = 1.5056168196148842, disc_loss = 0.0044540271120475025
Trained batch 636 in epoch 8, gen_loss = 1.5056044274072633, disc_loss = 0.004447093574316778
Trained batch 637 in epoch 8, gen_loss = 1.5055031945526038, disc_loss = 0.004440245058640785
Trained batch 638 in epoch 8, gen_loss = 1.5054343867003452, disc_loss = 0.004433447677377576
Trained batch 639 in epoch 8, gen_loss = 1.5054103556089102, disc_loss = 0.004426625939777296
Trained batch 640 in epoch 8, gen_loss = 1.505355549211993, disc_loss = 0.004419802194886206
Trained batch 641 in epoch 8, gen_loss = 1.505334732038581, disc_loss = 0.004412976347682113
Trained batch 642 in epoch 8, gen_loss = 1.5053587622627684, disc_loss = 0.0044061732082279195
Trained batch 643 in epoch 8, gen_loss = 1.5051821876571785, disc_loss = 0.004399516783925482
Trained batch 644 in epoch 8, gen_loss = 1.5052033817121224, disc_loss = 0.004392876341145273
Trained batch 645 in epoch 8, gen_loss = 1.5052072655859376, disc_loss = 0.004386216176848303
Trained batch 646 in epoch 8, gen_loss = 1.5051875627575186, disc_loss = 0.004379563894988937
Trained batch 647 in epoch 8, gen_loss = 1.5051515967941578, disc_loss = 0.0043729473729938574
Trained batch 648 in epoch 8, gen_loss = 1.505241438953094, disc_loss = 0.004366393526688682
Trained batch 649 in epoch 8, gen_loss = 1.5052780779508443, disc_loss = 0.004359843033643511
Trained batch 650 in epoch 8, gen_loss = 1.5054051093242136, disc_loss = 0.004354060538330927
Trained batch 651 in epoch 8, gen_loss = 1.5054549553825811, disc_loss = 0.004348114185643017
Trained batch 652 in epoch 8, gen_loss = 1.5055112958319519, disc_loss = 0.0043419840535081945
Trained batch 653 in epoch 8, gen_loss = 1.5056033077043132, disc_loss = 0.00433612338098874
Trained batch 654 in epoch 8, gen_loss = 1.5056678847502205, disc_loss = 0.004330070478351118
Trained batch 655 in epoch 8, gen_loss = 1.505698009507685, disc_loss = 0.004324200093656035
Trained batch 656 in epoch 8, gen_loss = 1.5057585572361765, disc_loss = 0.0043181972672522795
Trained batch 657 in epoch 8, gen_loss = 1.5057486827431479, disc_loss = 0.0043121506043799695
Trained batch 658 in epoch 8, gen_loss = 1.5057833622547492, disc_loss = 0.0043060807305849574
Trained batch 659 in epoch 8, gen_loss = 1.5057169075265076, disc_loss = 0.004300032902789429
Trained batch 660 in epoch 8, gen_loss = 1.5056447949423912, disc_loss = 0.0042939582198443325
Trained batch 661 in epoch 8, gen_loss = 1.5055734040693933, disc_loss = 0.004287876827236802
Trained batch 662 in epoch 8, gen_loss = 1.5056029264204103, disc_loss = 0.004281787912413649
Trained batch 663 in epoch 8, gen_loss = 1.505597487181784, disc_loss = 0.0042756103814691054
Trained batch 664 in epoch 8, gen_loss = 1.505691935872673, disc_loss = 0.0042693989010242385
Trained batch 665 in epoch 8, gen_loss = 1.5056623829914644, disc_loss = 0.00426315475612625
Trained batch 666 in epoch 8, gen_loss = 1.5056654966395835, disc_loss = 0.004256871637637445
Trained batch 667 in epoch 8, gen_loss = 1.5056196789363188, disc_loss = 0.004250591939256731
Trained batch 668 in epoch 8, gen_loss = 1.5055832792468848, disc_loss = 0.004244301084879113
Trained batch 669 in epoch 8, gen_loss = 1.5057120665685455, disc_loss = 0.004238061137606456
Trained batch 670 in epoch 8, gen_loss = 1.5057060264617248, disc_loss = 0.004231824685554693
Trained batch 671 in epoch 8, gen_loss = 1.5056556481868029, disc_loss = 0.004225599862869396
Trained batch 672 in epoch 8, gen_loss = 1.5057214104403005, disc_loss = 0.004219423280850482
Trained batch 673 in epoch 8, gen_loss = 1.5057895159686001, disc_loss = 0.004213309572982276
Trained batch 674 in epoch 8, gen_loss = 1.5057770316689103, disc_loss = 0.0042071926685888755
Trained batch 675 in epoch 8, gen_loss = 1.5057231488488836, disc_loss = 0.004201099629249014
Trained batch 676 in epoch 8, gen_loss = 1.505676952475459, disc_loss = 0.004194972855720538
Trained batch 677 in epoch 8, gen_loss = 1.505632656601678, disc_loss = 0.004188882887126611
Trained batch 678 in epoch 8, gen_loss = 1.5057146095386837, disc_loss = 0.004182827553664211
Trained batch 679 in epoch 8, gen_loss = 1.5056724240674693, disc_loss = 0.004176838079627701
Trained batch 680 in epoch 8, gen_loss = 1.5055930405286264, disc_loss = 0.004170836636780738
Trained batch 681 in epoch 8, gen_loss = 1.5055966406099257, disc_loss = 0.004164826561426657
Trained batch 682 in epoch 8, gen_loss = 1.5055182070020003, disc_loss = 0.004158797463442889
Trained batch 683 in epoch 8, gen_loss = 1.5054022714234234, disc_loss = 0.004152813621770116
Trained batch 684 in epoch 8, gen_loss = 1.5052735620171485, disc_loss = 0.00414692972224617
Trained batch 685 in epoch 8, gen_loss = 1.505245326124892, disc_loss = 0.0041410151430422305
Trained batch 686 in epoch 8, gen_loss = 1.5052175239878103, disc_loss = 0.0041350795456318095
Trained batch 687 in epoch 8, gen_loss = 1.5051599457686724, disc_loss = 0.004129187485781332
Trained batch 688 in epoch 8, gen_loss = 1.5051706936778109, disc_loss = 0.004123278016228348
Trained batch 689 in epoch 8, gen_loss = 1.505037248912065, disc_loss = 0.004117819990247169
Trained batch 690 in epoch 8, gen_loss = 1.5051014284494126, disc_loss = 0.0041122965693779
Trained batch 691 in epoch 8, gen_loss = 1.5050761235414902, disc_loss = 0.0041066163519413446
Trained batch 692 in epoch 8, gen_loss = 1.5049866440492274, disc_loss = 0.004101101418415649
Trained batch 693 in epoch 8, gen_loss = 1.5050132148375772, disc_loss = 0.004095485264088638
Trained batch 694 in epoch 8, gen_loss = 1.5049165587631061, disc_loss = 0.0040900988167973835
Trained batch 695 in epoch 8, gen_loss = 1.5048965228528812, disc_loss = 0.004084831881995677
Trained batch 696 in epoch 8, gen_loss = 1.5048069226177385, disc_loss = 0.0040798494579312485
Trained batch 697 in epoch 8, gen_loss = 1.50480658080653, disc_loss = 0.004074485710959267
Trained batch 698 in epoch 8, gen_loss = 1.504708997084518, disc_loss = 0.004068883192097895
Trained batch 699 in epoch 8, gen_loss = 1.5047716008765357, disc_loss = 0.004063337922619082
Trained batch 700 in epoch 8, gen_loss = 1.5047830747129574, disc_loss = 0.00405796849043018
Trained batch 701 in epoch 8, gen_loss = 1.504827126903072, disc_loss = 0.004052906244386216
Trained batch 702 in epoch 8, gen_loss = 1.5035906423036947, disc_loss = 0.0045227520250367805
Trained batch 703 in epoch 8, gen_loss = 1.5049995697018774, disc_loss = 0.005061397998665804
Trained batch 704 in epoch 8, gen_loss = 1.504952004953479, disc_loss = 0.005153926670961437
Trained batch 705 in epoch 8, gen_loss = 1.5044187283718553, disc_loss = 0.005227598842146974
Trained batch 706 in epoch 8, gen_loss = 1.5041091185816613, disc_loss = 0.00528829218389046
Trained batch 707 in epoch 8, gen_loss = 1.5039764822876387, disc_loss = 0.005303329109691048
Trained batch 708 in epoch 8, gen_loss = 1.504136422961656, disc_loss = 0.005318780691364847
Trained batch 709 in epoch 8, gen_loss = 1.5041354427874927, disc_loss = 0.005322978210373754
Trained batch 710 in epoch 8, gen_loss = 1.5041249187351446, disc_loss = 0.005323334634684525
Trained batch 711 in epoch 8, gen_loss = 1.5040717453099368, disc_loss = 0.005321103333878118
Trained batch 712 in epoch 8, gen_loss = 1.5041231846575316, disc_loss = 0.005315375519201229
Trained batch 713 in epoch 8, gen_loss = 1.5041574249748422, disc_loss = 0.00530949826036701
Trained batch 714 in epoch 8, gen_loss = 1.504125816505272, disc_loss = 0.0053037652038955664
Trained batch 715 in epoch 8, gen_loss = 1.5042070643195893, disc_loss = 0.005297277185145605
Trained batch 716 in epoch 8, gen_loss = 1.5042605014359436, disc_loss = 0.0052917445215598805
Trained batch 717 in epoch 8, gen_loss = 1.5030095112356967, disc_loss = 0.005897165398499278
Trained batch 718 in epoch 8, gen_loss = 1.503796597017864, disc_loss = 0.00618095761819859
Trained batch 719 in epoch 8, gen_loss = 1.5044604905777508, disc_loss = 0.0063187700959588256
Trained batch 720 in epoch 8, gen_loss = 1.5040981424003632, disc_loss = 0.006345064357774945
Trained batch 721 in epoch 8, gen_loss = 1.5036337854459345, disc_loss = 0.0063888785534497936
Trained batch 722 in epoch 8, gen_loss = 1.503519703243778, disc_loss = 0.0063891883700625774
Trained batch 723 in epoch 8, gen_loss = 1.5036861843825704, disc_loss = 0.006388020797997277
Trained batch 724 in epoch 8, gen_loss = 1.5038922071456908, disc_loss = 0.006384126954879572
Trained batch 725 in epoch 8, gen_loss = 1.5039886953745334, disc_loss = 0.0063780435335382
Trained batch 726 in epoch 8, gen_loss = 1.5040588938058488, disc_loss = 0.006371132191309622
Trained batch 727 in epoch 8, gen_loss = 1.504163717830574, disc_loss = 0.006364146257075825
Trained batch 728 in epoch 8, gen_loss = 1.5042723376401004, disc_loss = 0.006356421506166449
Trained batch 729 in epoch 8, gen_loss = 1.5043453841993253, disc_loss = 0.006348356510940517
Trained batch 730 in epoch 8, gen_loss = 1.5043856843225607, disc_loss = 0.006340289589178438
Trained batch 731 in epoch 8, gen_loss = 1.5044417938248056, disc_loss = 0.006332122775104145
Trained batch 732 in epoch 8, gen_loss = 1.5044786773957464, disc_loss = 0.0063238809247317205
Trained batch 733 in epoch 8, gen_loss = 1.5044924527487897, disc_loss = 0.006315753913143475
Trained batch 734 in epoch 8, gen_loss = 1.5045865633049789, disc_loss = 0.0063078197132038554
Trained batch 735 in epoch 8, gen_loss = 1.5046842922659025, disc_loss = 0.006299748322318089
Trained batch 736 in epoch 8, gen_loss = 1.5048144041602292, disc_loss = 0.00629148719537768
Trained batch 737 in epoch 8, gen_loss = 1.5049086962612017, disc_loss = 0.006283339713978337
Trained batch 738 in epoch 8, gen_loss = 1.5049903436345886, disc_loss = 0.006275198931172476
Trained batch 739 in epoch 8, gen_loss = 1.5050294102849187, disc_loss = 0.006267071858329055
Trained batch 740 in epoch 8, gen_loss = 1.5051142411676013, disc_loss = 0.006258880265993083
Trained batch 741 in epoch 8, gen_loss = 1.5051513074864595, disc_loss = 0.006250638385569685
Trained batch 742 in epoch 8, gen_loss = 1.5052126597908912, disc_loss = 0.0062424897313629
Trained batch 743 in epoch 8, gen_loss = 1.5052980721317313, disc_loss = 0.006234752766651523
Trained batch 744 in epoch 8, gen_loss = 1.5053639677546968, disc_loss = 0.006226733153123969
Trained batch 745 in epoch 8, gen_loss = 1.5053987956878008, disc_loss = 0.006218662709567124
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 1.5395430326461792, disc_loss = 0.000180753821041435
Trained batch 1 in epoch 9, gen_loss = 1.5128735899925232, disc_loss = 0.00017224308976437896
Trained batch 2 in epoch 9, gen_loss = 1.502117355664571, disc_loss = 0.0001655925007071346
Trained batch 3 in epoch 9, gen_loss = 1.4968440234661102, disc_loss = 0.00015942381651257165
Trained batch 4 in epoch 9, gen_loss = 1.50313241481781, disc_loss = 0.00015493862447328864
Trained batch 5 in epoch 9, gen_loss = 1.507459779580434, disc_loss = 0.00015191927377600223
Trained batch 6 in epoch 9, gen_loss = 1.5069743735449654, disc_loss = 0.0001453355944249779
Trained batch 7 in epoch 9, gen_loss = 1.5121297389268875, disc_loss = 0.0001484717122366419
Trained batch 8 in epoch 9, gen_loss = 1.511574837896559, disc_loss = 0.0001545053544557757
Trained batch 9 in epoch 9, gen_loss = 1.5120108604431153, disc_loss = 0.00015206986136035995
Trained batch 10 in epoch 9, gen_loss = 1.5100213397632947, disc_loss = 0.0001529473295456476
Trained batch 11 in epoch 9, gen_loss = 1.5083525478839874, disc_loss = 0.00015001803573492603
Trained batch 12 in epoch 9, gen_loss = 1.5103584986466627, disc_loss = 0.0001506480968181187
Trained batch 13 in epoch 9, gen_loss = 1.5080313001360213, disc_loss = 0.00015903771834148626
Trained batch 14 in epoch 9, gen_loss = 1.509096630414327, disc_loss = 0.00016737754437296342
Trained batch 15 in epoch 9, gen_loss = 1.5085887983441353, disc_loss = 0.0001654316210988327
Trained batch 16 in epoch 9, gen_loss = 1.5114597853492289, disc_loss = 0.0001851750789415639
Trained batch 17 in epoch 9, gen_loss = 1.5138317743937175, disc_loss = 0.00019976549164210964
Trained batch 18 in epoch 9, gen_loss = 1.5142531018508107, disc_loss = 0.0001987210569878746
Trained batch 19 in epoch 9, gen_loss = 1.513081419467926, disc_loss = 0.00019736657704925165
Trained batch 20 in epoch 9, gen_loss = 1.512444779986427, disc_loss = 0.00019603624241426587
Trained batch 21 in epoch 9, gen_loss = 1.5133736296133562, disc_loss = 0.0001932477309971794
Trained batch 22 in epoch 9, gen_loss = 1.513011652490367, disc_loss = 0.00019155434426426402
Trained batch 23 in epoch 9, gen_loss = 1.5140368888775508, disc_loss = 0.00019012611786214015
Trained batch 24 in epoch 9, gen_loss = 1.5133747625350953, disc_loss = 0.00018838383955881
Trained batch 25 in epoch 9, gen_loss = 1.5127597130261934, disc_loss = 0.00018491265543091757
Trained batch 26 in epoch 9, gen_loss = 1.5148708290523953, disc_loss = 0.00018277404241315607
Trained batch 27 in epoch 9, gen_loss = 1.5148678166525704, disc_loss = 0.0001811773186740798
Trained batch 28 in epoch 9, gen_loss = 1.5162189376765285, disc_loss = 0.00017983370695407662
Trained batch 29 in epoch 9, gen_loss = 1.5144347389539083, disc_loss = 0.00018000255658989772
Trained batch 30 in epoch 9, gen_loss = 1.5143746560619724, disc_loss = 0.0001781910846588172
Trained batch 31 in epoch 9, gen_loss = 1.5150627493858337, disc_loss = 0.000176338109667995
Trained batch 32 in epoch 9, gen_loss = 1.5160657564798992, disc_loss = 0.00017618431152324334
Trained batch 33 in epoch 9, gen_loss = 1.5180739935706644, disc_loss = 0.0001740303917305188
Trained batch 34 in epoch 9, gen_loss = 1.5175236429486956, disc_loss = 0.00017366799355451285
Trained batch 35 in epoch 9, gen_loss = 1.5179711712731256, disc_loss = 0.0001719829544728984
Trained batch 36 in epoch 9, gen_loss = 1.5177936038455448, disc_loss = 0.00017020132705707706
Trained batch 37 in epoch 9, gen_loss = 1.5184603239360608, disc_loss = 0.00016849161750686012
Trained batch 38 in epoch 9, gen_loss = 1.5180980670146453, disc_loss = 0.0001666544259746726
Trained batch 39 in epoch 9, gen_loss = 1.5194145530462264, disc_loss = 0.00016726550347812008
Trained batch 40 in epoch 9, gen_loss = 1.5202374836293662, disc_loss = 0.00016907923258613886
Trained batch 41 in epoch 9, gen_loss = 1.5207606610797701, disc_loss = 0.00016832530222711197
Trained batch 42 in epoch 9, gen_loss = 1.520653480707213, disc_loss = 0.00016755013399064367
Trained batch 43 in epoch 9, gen_loss = 1.5210369337688794, disc_loss = 0.00016566459436779206
Trained batch 44 in epoch 9, gen_loss = 1.5208424674140082, disc_loss = 0.00016538532072445377
Trained batch 45 in epoch 9, gen_loss = 1.5219466323437898, disc_loss = 0.0001668978364487766
Trained batch 46 in epoch 9, gen_loss = 1.5213295830057023, disc_loss = 0.00016541882901715036
Trained batch 47 in epoch 9, gen_loss = 1.5213692436615627, disc_loss = 0.00016379804962222502
Trained batch 48 in epoch 9, gen_loss = 1.521316805664374, disc_loss = 0.00016202873770713007
Trained batch 49 in epoch 9, gen_loss = 1.521474084854126, disc_loss = 0.00016074449275038205
Trained batch 50 in epoch 9, gen_loss = 1.5208180511699003, disc_loss = 0.00016045760218962553
Trained batch 51 in epoch 9, gen_loss = 1.519905645113725, disc_loss = 0.0001595734177569214
Trained batch 52 in epoch 9, gen_loss = 1.5193835204502322, disc_loss = 0.0001583635600564896
Trained batch 53 in epoch 9, gen_loss = 1.5187135051797938, disc_loss = 0.00015764319633254436
Trained batch 54 in epoch 9, gen_loss = 1.5193116383119063, disc_loss = 0.00015825587271882052
Trained batch 55 in epoch 9, gen_loss = 1.5197118116276604, disc_loss = 0.00015800472179502582
Trained batch 56 in epoch 9, gen_loss = 1.5194082071906643, disc_loss = 0.0001564518456130795
Trained batch 57 in epoch 9, gen_loss = 1.5205555681524605, disc_loss = 0.0001575301049060413
Trained batch 58 in epoch 9, gen_loss = 1.5207047361438557, disc_loss = 0.0001576131343411408
Trained batch 59 in epoch 9, gen_loss = 1.5208179851373036, disc_loss = 0.00015608816453701972
Trained batch 60 in epoch 9, gen_loss = 1.5209323812703617, disc_loss = 0.00015457292787776498
Trained batch 61 in epoch 9, gen_loss = 1.5203633000773769, disc_loss = 0.00015314208447366143
Trained batch 62 in epoch 9, gen_loss = 1.5206380647326272, disc_loss = 0.0001517395923858405
Trained batch 63 in epoch 9, gen_loss = 1.520113369449973, disc_loss = 0.00015024331116819667
Trained batch 64 in epoch 9, gen_loss = 1.5199961717312152, disc_loss = 0.0001490523371523103
Trained batch 65 in epoch 9, gen_loss = 1.5202608415574739, disc_loss = 0.00014798259023033702
Trained batch 66 in epoch 9, gen_loss = 1.5195407529375446, disc_loss = 0.00014667388389700216
Trained batch 67 in epoch 9, gen_loss = 1.520124696633395, disc_loss = 0.00014667833538089113
Trained batch 68 in epoch 9, gen_loss = 1.5208193530207095, disc_loss = 0.0001459381675121604
Trained batch 69 in epoch 9, gen_loss = 1.5211072649274553, disc_loss = 0.0001452171162652251
Trained batch 70 in epoch 9, gen_loss = 1.5209757610106132, disc_loss = 0.00014518452648394807
Trained batch 71 in epoch 9, gen_loss = 1.521203100681305, disc_loss = 0.0001449248183133831
Trained batch 72 in epoch 9, gen_loss = 1.5206777706538162, disc_loss = 0.00014411616605572555
Trained batch 73 in epoch 9, gen_loss = 1.5206274776845365, disc_loss = 0.0001431868055275314
Trained batch 74 in epoch 9, gen_loss = 1.5204971647262573, disc_loss = 0.00014241496217437088
Trained batch 75 in epoch 9, gen_loss = 1.5203055598233874, disc_loss = 0.00014138646828972638
Trained batch 76 in epoch 9, gen_loss = 1.52094245421422, disc_loss = 0.00014141543678389016
Trained batch 77 in epoch 9, gen_loss = 1.5210154163531768, disc_loss = 0.00014085244644472064
Trained batch 78 in epoch 9, gen_loss = 1.5211806221853328, disc_loss = 0.0001401474850975814
Trained batch 79 in epoch 9, gen_loss = 1.5204894050955773, disc_loss = 0.00013948859314041328
Trained batch 80 in epoch 9, gen_loss = 1.5207925269633165, disc_loss = 0.00013881402920549275
Trained batch 81 in epoch 9, gen_loss = 1.5208030183140824, disc_loss = 0.00013821664070724738
Trained batch 82 in epoch 9, gen_loss = 1.5207273586686836, disc_loss = 0.00013738867911967416
Trained batch 83 in epoch 9, gen_loss = 1.5203533229373751, disc_loss = 0.00013666769033685947
Trained batch 84 in epoch 9, gen_loss = 1.5206634773927576, disc_loss = 0.00013636798668063848
Trained batch 85 in epoch 9, gen_loss = 1.5203917345335318, disc_loss = 0.00013559206863012448
Trained batch 86 in epoch 9, gen_loss = 1.5204401276577477, disc_loss = 0.00013514085521924192
Trained batch 87 in epoch 9, gen_loss = 1.5201208713379772, disc_loss = 0.00013570591702525482
Trained batch 88 in epoch 9, gen_loss = 1.5201875748259297, disc_loss = 0.0001364333926748453
Trained batch 89 in epoch 9, gen_loss = 1.5194880525271097, disc_loss = 0.0001362255704912564
Trained batch 90 in epoch 9, gen_loss = 1.5194403640516512, disc_loss = 0.0001354527123692026
Trained batch 91 in epoch 9, gen_loss = 1.5191162034221317, disc_loss = 0.00013470515208926213
Trained batch 92 in epoch 9, gen_loss = 1.5185923563536776, disc_loss = 0.00013429773068593775
Trained batch 93 in epoch 9, gen_loss = 1.5186801907864023, disc_loss = 0.00013485788889390298
Trained batch 94 in epoch 9, gen_loss = 1.51834362055126, disc_loss = 0.0001342207929395188
Trained batch 95 in epoch 9, gen_loss = 1.5179230657716591, disc_loss = 0.00013339438836131498
Trained batch 96 in epoch 9, gen_loss = 1.518166671094206, disc_loss = 0.00013307188933093543
Trained batch 97 in epoch 9, gen_loss = 1.518335646512557, disc_loss = 0.00013299969748691275
Trained batch 98 in epoch 9, gen_loss = 1.5184038504205568, disc_loss = 0.0001323430877880927
Trained batch 99 in epoch 9, gen_loss = 1.518208417892456, disc_loss = 0.00013180047571950126
Trained batch 100 in epoch 9, gen_loss = 1.5177928811252708, disc_loss = 0.00013149155026917245
Trained batch 101 in epoch 9, gen_loss = 1.5176117794186461, disc_loss = 0.00013081165846361888
Trained batch 102 in epoch 9, gen_loss = 1.5176807931325969, disc_loss = 0.00013006140159508575
Trained batch 103 in epoch 9, gen_loss = 1.5177761786259139, disc_loss = 0.00012939760850153666
Trained batch 104 in epoch 9, gen_loss = 1.5180413257508052, disc_loss = 0.00012882251058250578
Trained batch 105 in epoch 9, gen_loss = 1.5179105401039124, disc_loss = 0.00012819677939196995
Trained batch 106 in epoch 9, gen_loss = 1.5183618592324657, disc_loss = 0.00012845068942335494
Trained batch 107 in epoch 9, gen_loss = 1.5183828340636358, disc_loss = 0.00012832254927801573
Trained batch 108 in epoch 9, gen_loss = 1.5187490281708744, disc_loss = 0.00012866480452480614
Trained batch 109 in epoch 9, gen_loss = 1.5185697728937322, disc_loss = 0.00012844545615900478
Trained batch 110 in epoch 9, gen_loss = 1.5185237596700858, disc_loss = 0.000127960721042368
Trained batch 111 in epoch 9, gen_loss = 1.5185477648462569, disc_loss = 0.00012764508963820326
Trained batch 112 in epoch 9, gen_loss = 1.5186411332240146, disc_loss = 0.00012698010616189908
Trained batch 113 in epoch 9, gen_loss = 1.518401865373578, disc_loss = 0.00012634527688772467
Trained batch 114 in epoch 9, gen_loss = 1.5183957804804262, disc_loss = 0.000125617021568241
Trained batch 115 in epoch 9, gen_loss = 1.518395348869521, disc_loss = 0.0001251205213865715
Trained batch 116 in epoch 9, gen_loss = 1.5181591174541376, disc_loss = 0.0001244803867700836
Trained batch 117 in epoch 9, gen_loss = 1.5185203057224468, disc_loss = 0.00012457585041174445
Trained batch 118 in epoch 9, gen_loss = 1.5182949945706279, disc_loss = 0.00012433897827883025
Trained batch 119 in epoch 9, gen_loss = 1.5184455504020056, disc_loss = 0.00012404557655827376
Trained batch 120 in epoch 9, gen_loss = 1.5183834911377962, disc_loss = 0.00012340273312196783
Trained batch 121 in epoch 9, gen_loss = 1.5182598203909201, disc_loss = 0.00012284639410981832
Trained batch 122 in epoch 9, gen_loss = 1.518917391939861, disc_loss = 0.00012242504353190175
Trained batch 123 in epoch 9, gen_loss = 1.5188134331857004, disc_loss = 0.0001223773472907675
Trained batch 124 in epoch 9, gen_loss = 1.518727942466736, disc_loss = 0.0001230726412613876
Trained batch 125 in epoch 9, gen_loss = 1.518736095655532, disc_loss = 0.0001227640676670634
Trained batch 126 in epoch 9, gen_loss = 1.5189163928895484, disc_loss = 0.00012219834357305744
Trained batch 127 in epoch 9, gen_loss = 1.5184125946834683, disc_loss = 0.00012192790853760016
Trained batch 128 in epoch 9, gen_loss = 1.5180891927822615, disc_loss = 0.00012165622957377486
Trained batch 129 in epoch 9, gen_loss = 1.5173897101328924, disc_loss = 0.00012143166671963767
Trained batch 130 in epoch 9, gen_loss = 1.517414062987757, disc_loss = 0.00012116980227288072
Trained batch 131 in epoch 9, gen_loss = 1.5176131147326846, disc_loss = 0.0001208200954517286
Trained batch 132 in epoch 9, gen_loss = 1.5173816340310233, disc_loss = 0.00012050087542248595
Trained batch 133 in epoch 9, gen_loss = 1.5174303704233312, disc_loss = 0.00012007828556659715
Trained batch 134 in epoch 9, gen_loss = 1.5176002387647276, disc_loss = 0.00011966151192879167
Trained batch 135 in epoch 9, gen_loss = 1.5177477606955696, disc_loss = 0.00011934537761750536
Trained batch 136 in epoch 9, gen_loss = 1.5176166870298178, disc_loss = 0.00011887597912743205
Trained batch 137 in epoch 9, gen_loss = 1.5175279992214148, disc_loss = 0.00011826679861848748
Trained batch 138 in epoch 9, gen_loss = 1.5174146213119837, disc_loss = 0.00011773003724746225
Trained batch 139 in epoch 9, gen_loss = 1.5172174726213727, disc_loss = 0.00011719546494402624
Trained batch 140 in epoch 9, gen_loss = 1.5172788877013728, disc_loss = 0.00011704687935986279
Trained batch 141 in epoch 9, gen_loss = 1.5172749959247214, disc_loss = 0.00011678129765282969
Trained batch 142 in epoch 9, gen_loss = 1.5173153593823627, disc_loss = 0.00011632708280361127
Trained batch 143 in epoch 9, gen_loss = 1.5174351731936138, disc_loss = 0.00011626227218483918
Trained batch 144 in epoch 9, gen_loss = 1.5174950089947932, disc_loss = 0.00011586700400522236
Trained batch 145 in epoch 9, gen_loss = 1.5171456385965216, disc_loss = 0.00011548239251156976
Trained batch 146 in epoch 9, gen_loss = 1.5168192516378805, disc_loss = 0.00011504799491673594
Trained batch 147 in epoch 9, gen_loss = 1.5171132635425877, disc_loss = 0.00011470398026545268
Trained batch 148 in epoch 9, gen_loss = 1.5172933460081983, disc_loss = 0.00011436179759419967
Trained batch 149 in epoch 9, gen_loss = 1.5171619844436646, disc_loss = 0.00011396445658950445
Trained batch 150 in epoch 9, gen_loss = 1.5168004651732792, disc_loss = 0.00011350090110663707
Trained batch 151 in epoch 9, gen_loss = 1.516824417992642, disc_loss = 0.00011318950514817659
Trained batch 152 in epoch 9, gen_loss = 1.516809280401741, disc_loss = 0.00011281730980746254
Trained batch 153 in epoch 9, gen_loss = 1.5166323649418818, disc_loss = 0.00011235664904045013
Trained batch 154 in epoch 9, gen_loss = 1.5166290936931488, disc_loss = 0.00011203615919634279
Trained batch 155 in epoch 9, gen_loss = 1.51658895611763, disc_loss = 0.00011176337093041721
Trained batch 156 in epoch 9, gen_loss = 1.5165089816804145, disc_loss = 0.00011165726963826604
Trained batch 157 in epoch 9, gen_loss = 1.5165300535250315, disc_loss = 0.00011159355830087304
Trained batch 158 in epoch 9, gen_loss = 1.5162567777453728, disc_loss = 0.00011127261579371316
Trained batch 159 in epoch 9, gen_loss = 1.5164835728704928, disc_loss = 0.00011084236350598076
Trained batch 160 in epoch 9, gen_loss = 1.5163189876153602, disc_loss = 0.00011042355159272277
Trained batch 161 in epoch 9, gen_loss = 1.5162905631241974, disc_loss = 0.00010998843332165478
Trained batch 162 in epoch 9, gen_loss = 1.5163803656408392, disc_loss = 0.00010974227454448318
Trained batch 163 in epoch 9, gen_loss = 1.5166721874620857, disc_loss = 0.00011049293831403214
Trained batch 164 in epoch 9, gen_loss = 1.5167506882638642, disc_loss = 0.00011080700472424118
Trained batch 165 in epoch 9, gen_loss = 1.5165822383869125, disc_loss = 0.00011072268633537292
Trained batch 166 in epoch 9, gen_loss = 1.5165382166822514, disc_loss = 0.00011054625734076892
Trained batch 167 in epoch 9, gen_loss = 1.5166126170328684, disc_loss = 0.00011102319991723995
Trained batch 168 in epoch 9, gen_loss = 1.5167113119328515, disc_loss = 0.00011141353995713526
Trained batch 169 in epoch 9, gen_loss = 1.5167044702698202, disc_loss = 0.00011106923961693503
Trained batch 170 in epoch 9, gen_loss = 1.5165904739446807, disc_loss = 0.00011075751163519521
Trained batch 171 in epoch 9, gen_loss = 1.516701649787814, disc_loss = 0.00011036772477466933
Trained batch 172 in epoch 9, gen_loss = 1.5164014728083086, disc_loss = 0.00011003982234339773
Trained batch 173 in epoch 9, gen_loss = 1.5164306341916665, disc_loss = 0.00010973839982460928
Trained batch 174 in epoch 9, gen_loss = 1.516649980545044, disc_loss = 0.0001093733667221386
Trained batch 175 in epoch 9, gen_loss = 1.516393241557208, disc_loss = 0.00010927768713289962
Trained batch 176 in epoch 9, gen_loss = 1.5164331756742662, disc_loss = 0.0001090256931396046
Trained batch 177 in epoch 9, gen_loss = 1.5163271313302973, disc_loss = 0.00010878957477820059
Trained batch 178 in epoch 9, gen_loss = 1.5160358305083972, disc_loss = 0.00010864933738962997
Trained batch 179 in epoch 9, gen_loss = 1.515662560198042, disc_loss = 0.00010878123436365664
Trained batch 180 in epoch 9, gen_loss = 1.515585933601, disc_loss = 0.00010868258230714256
Trained batch 181 in epoch 9, gen_loss = 1.5154122926376679, disc_loss = 0.00010830460552904616
Trained batch 182 in epoch 9, gen_loss = 1.5153192561832283, disc_loss = 0.0001079062432856388
Trained batch 183 in epoch 9, gen_loss = 1.5150801319143046, disc_loss = 0.00010757525087288029
Trained batch 184 in epoch 9, gen_loss = 1.5149982387955125, disc_loss = 0.00010723193996897396
Trained batch 185 in epoch 9, gen_loss = 1.515322273136467, disc_loss = 0.00010765821494832409
Trained batch 186 in epoch 9, gen_loss = 1.5153609373990227, disc_loss = 0.00010745011036670866
Trained batch 187 in epoch 9, gen_loss = 1.5154196918010712, disc_loss = 0.00010721422568941364
Trained batch 188 in epoch 9, gen_loss = 1.5156476876092335, disc_loss = 0.00010709560867913299
Trained batch 189 in epoch 9, gen_loss = 1.5159580098955254, disc_loss = 0.00010677468200906572
Trained batch 190 in epoch 9, gen_loss = 1.5159577967608786, disc_loss = 0.00010644472978600174
Trained batch 191 in epoch 9, gen_loss = 1.5158247631043196, disc_loss = 0.00010613921834116506
Trained batch 192 in epoch 9, gen_loss = 1.5156875373168313, disc_loss = 0.000105842366995419
Trained batch 193 in epoch 9, gen_loss = 1.5154250546828987, disc_loss = 0.00010556537293353161
Trained batch 194 in epoch 9, gen_loss = 1.5151254311586038, disc_loss = 0.00010543554035860161
Trained batch 195 in epoch 9, gen_loss = 1.5151068787185513, disc_loss = 0.00010536224654432011
Trained batch 196 in epoch 9, gen_loss = 1.5151788540903082, disc_loss = 0.00010554108962308506
Trained batch 197 in epoch 9, gen_loss = 1.5152246747354063, disc_loss = 0.0001053824675402597
Trained batch 198 in epoch 9, gen_loss = 1.5148933928216521, disc_loss = 0.00010523344704167023
Trained batch 199 in epoch 9, gen_loss = 1.5148018670082093, disc_loss = 0.0001049270260045887
Trained batch 200 in epoch 9, gen_loss = 1.5147597060274722, disc_loss = 0.00010467868737600726
Trained batch 201 in epoch 9, gen_loss = 1.5147460852519121, disc_loss = 0.00010451150592416525
Trained batch 202 in epoch 9, gen_loss = 1.5149568971154725, disc_loss = 0.000104271001582495
Trained batch 203 in epoch 9, gen_loss = 1.5148592807498633, disc_loss = 0.00010396797241649919
Trained batch 204 in epoch 9, gen_loss = 1.5148656513632797, disc_loss = 0.00010362435849213109
Trained batch 205 in epoch 9, gen_loss = 1.514808538469296, disc_loss = 0.00010330228111537137
Trained batch 206 in epoch 9, gen_loss = 1.5148361454839292, disc_loss = 0.0001030211916843211
Trained batch 207 in epoch 9, gen_loss = 1.5147218474975, disc_loss = 0.00010275976013382696
Trained batch 208 in epoch 9, gen_loss = 1.5144935059205196, disc_loss = 0.00010251823717892019
Trained batch 209 in epoch 9, gen_loss = 1.5146090836752029, disc_loss = 0.00010232499532451454
Trained batch 210 in epoch 9, gen_loss = 1.5144965998934343, disc_loss = 0.00010207928145059906
Trained batch 211 in epoch 9, gen_loss = 1.5143070119731832, disc_loss = 0.00010178382577784228
Trained batch 212 in epoch 9, gen_loss = 1.514592560803946, disc_loss = 0.00010165742871339515
Trained batch 213 in epoch 9, gen_loss = 1.5146265559107344, disc_loss = 0.00010153981202165596
Trained batch 214 in epoch 9, gen_loss = 1.5145874450373096, disc_loss = 0.00010132484908248189
Trained batch 215 in epoch 9, gen_loss = 1.5145391623179119, disc_loss = 0.00010110309255685058
Trained batch 216 in epoch 9, gen_loss = 1.5147469549135129, disc_loss = 0.00010116256672949615
Trained batch 217 in epoch 9, gen_loss = 1.5148260888703373, disc_loss = 0.00010118909733070363
Trained batch 218 in epoch 9, gen_loss = 1.5149429601077076, disc_loss = 0.00010093660206139538
Trained batch 219 in epoch 9, gen_loss = 1.5146256717768583, disc_loss = 0.00010086499109589072
Trained batch 220 in epoch 9, gen_loss = 1.5149148287276877, disc_loss = 0.00010065078983985191
Trained batch 221 in epoch 9, gen_loss = 1.514950414498647, disc_loss = 0.00010046519426330567
Trained batch 222 in epoch 9, gen_loss = 1.5150193339506073, disc_loss = 0.00010034789825174143
Trained batch 223 in epoch 9, gen_loss = 1.5150382236710616, disc_loss = 0.00010016362840100815
Trained batch 224 in epoch 9, gen_loss = 1.5151559151543512, disc_loss = 0.00010020258952863514
Trained batch 225 in epoch 9, gen_loss = 1.515074249917427, disc_loss = 9.999057563988645e-05
Trained batch 226 in epoch 9, gen_loss = 1.514992508069009, disc_loss = 9.977464003992033e-05
Trained batch 227 in epoch 9, gen_loss = 1.514933002622504, disc_loss = 9.963392311188377e-05
Trained batch 228 in epoch 9, gen_loss = 1.5151333319568216, disc_loss = 9.960907396522868e-05
Trained batch 229 in epoch 9, gen_loss = 1.5148526824038961, disc_loss = 9.933159294039638e-05
Trained batch 230 in epoch 9, gen_loss = 1.515110409104979, disc_loss = 9.922316481898039e-05
Trained batch 231 in epoch 9, gen_loss = 1.5152879002793083, disc_loss = 9.904292277622454e-05
Trained batch 232 in epoch 9, gen_loss = 1.5150894509876234, disc_loss = 9.882862438210946e-05
Trained batch 233 in epoch 9, gen_loss = 1.5151271356476679, disc_loss = 9.869269653682152e-05
Trained batch 234 in epoch 9, gen_loss = 1.5150722934844647, disc_loss = 9.85929386088367e-05
Trained batch 235 in epoch 9, gen_loss = 1.5150617830834145, disc_loss = 9.838069210241359e-05
Trained batch 236 in epoch 9, gen_loss = 1.5150843265187388, disc_loss = 9.815963462239745e-05
Trained batch 237 in epoch 9, gen_loss = 1.5151615017602424, disc_loss = 9.797559441187117e-05
Trained batch 238 in epoch 9, gen_loss = 1.515232069222997, disc_loss = 9.771336020295856e-05
Trained batch 239 in epoch 9, gen_loss = 1.515350337823232, disc_loss = 9.747221600567476e-05
Trained batch 240 in epoch 9, gen_loss = 1.5155063862622526, disc_loss = 9.730042523138817e-05
Trained batch 241 in epoch 9, gen_loss = 1.5155271262176766, disc_loss = 9.7104466521693e-05
Trained batch 242 in epoch 9, gen_loss = 1.5151977450759322, disc_loss = 9.706931830903155e-05
Trained batch 243 in epoch 9, gen_loss = 1.5150833647759234, disc_loss = 9.692377424188203e-05
Trained batch 244 in epoch 9, gen_loss = 1.515096893602488, disc_loss = 9.669870537900537e-05
Trained batch 245 in epoch 9, gen_loss = 1.5149904387753184, disc_loss = 9.643487386548385e-05
Trained batch 246 in epoch 9, gen_loss = 1.5150694880890943, disc_loss = 9.624483179878859e-05
Trained batch 247 in epoch 9, gen_loss = 1.515197475110331, disc_loss = 9.609702202660921e-05
Trained batch 248 in epoch 9, gen_loss = 1.51523302501464, disc_loss = 9.587873175193698e-05
Trained batch 249 in epoch 9, gen_loss = 1.5151475863456727, disc_loss = 9.564877276716289e-05
Trained batch 250 in epoch 9, gen_loss = 1.5149748187616052, disc_loss = 9.538656657574879e-05
Trained batch 251 in epoch 9, gen_loss = 1.5150277704473525, disc_loss = 9.514008776917878e-05
Trained batch 252 in epoch 9, gen_loss = 1.5147971065619246, disc_loss = 9.494688253434009e-05
Trained batch 253 in epoch 9, gen_loss = 1.5149252128413344, disc_loss = 9.477007197561961e-05
Trained batch 254 in epoch 9, gen_loss = 1.5150262757843616, disc_loss = 9.460131482674293e-05
Trained batch 255 in epoch 9, gen_loss = 1.5148013420403004, disc_loss = 9.43947418718949e-05
Trained batch 256 in epoch 9, gen_loss = 1.5145682175335717, disc_loss = 9.419132912707478e-05
Trained batch 257 in epoch 9, gen_loss = 1.5145819103995035, disc_loss = 9.396241339416083e-05
Trained batch 258 in epoch 9, gen_loss = 1.5146292342182293, disc_loss = 9.377911007423969e-05
Trained batch 259 in epoch 9, gen_loss = 1.5145796042222244, disc_loss = 9.357670189554203e-05
Trained batch 260 in epoch 9, gen_loss = 1.5147373922939957, disc_loss = 9.383285357296812e-05
Trained batch 261 in epoch 9, gen_loss = 1.5148929967225053, disc_loss = 9.412882261082418e-05
Trained batch 262 in epoch 9, gen_loss = 1.5148933142310312, disc_loss = 9.402489081626455e-05
Trained batch 263 in epoch 9, gen_loss = 1.5146677909475383, disc_loss = 9.398879320322135e-05
Trained batch 264 in epoch 9, gen_loss = 1.5146009305738053, disc_loss = 9.390753631415241e-05
Trained batch 265 in epoch 9, gen_loss = 1.5147214872496468, disc_loss = 9.374332577343531e-05
Trained batch 266 in epoch 9, gen_loss = 1.5147304048252463, disc_loss = 9.361007356987211e-05
Trained batch 267 in epoch 9, gen_loss = 1.5146276132384342, disc_loss = 9.34041202173776e-05
Trained batch 268 in epoch 9, gen_loss = 1.5143435621793386, disc_loss = 9.326329580147891e-05
Trained batch 269 in epoch 9, gen_loss = 1.514590036427533, disc_loss = 9.498582169692747e-05
Trained batch 270 in epoch 9, gen_loss = 1.5146600720627281, disc_loss = 9.64494492515309e-05
Trained batch 271 in epoch 9, gen_loss = 1.514729442403597, disc_loss = 9.70318364967598e-05
Trained batch 272 in epoch 9, gen_loss = 1.5149259947158478, disc_loss = 9.779032298755848e-05
Trained batch 273 in epoch 9, gen_loss = 1.5147554208762455, disc_loss = 9.805632892686552e-05
Trained batch 274 in epoch 9, gen_loss = 1.5148488933389836, disc_loss = 9.810192171161444e-05
Trained batch 275 in epoch 9, gen_loss = 1.5147069679654164, disc_loss = 9.811907587694198e-05
Trained batch 276 in epoch 9, gen_loss = 1.5145451234996534, disc_loss = 9.833790119253023e-05
Trained batch 277 in epoch 9, gen_loss = 1.51449585518391, disc_loss = 9.835371349136497e-05
Trained batch 278 in epoch 9, gen_loss = 1.5144330874138836, disc_loss = 9.819339509469441e-05
Trained batch 279 in epoch 9, gen_loss = 1.5143487419400896, disc_loss = 9.794905963644851e-05
Trained batch 280 in epoch 9, gen_loss = 1.51416735886679, disc_loss = 9.780367255833139e-05
Trained batch 281 in epoch 9, gen_loss = 1.5142021678018232, disc_loss = 9.761123489902243e-05
Trained batch 282 in epoch 9, gen_loss = 1.514182907111232, disc_loss = 9.746139848217295e-05
Trained batch 283 in epoch 9, gen_loss = 1.5142397725246322, disc_loss = 9.732879618855855e-05
Trained batch 284 in epoch 9, gen_loss = 1.5144597254301373, disc_loss = 9.726153958788992e-05
Trained batch 285 in epoch 9, gen_loss = 1.5144556039696806, disc_loss = 9.71402488347677e-05
Trained batch 286 in epoch 9, gen_loss = 1.514675897588298, disc_loss = 9.694327304191653e-05
Trained batch 287 in epoch 9, gen_loss = 1.5147422945333853, disc_loss = 9.67123749862569e-05
Trained batch 288 in epoch 9, gen_loss = 1.5149269512367909, disc_loss = 9.650933486721671e-05
Trained batch 289 in epoch 9, gen_loss = 1.5146809832803134, disc_loss = 9.632706805232688e-05
Trained batch 290 in epoch 9, gen_loss = 1.5144880174361552, disc_loss = 9.617617710743937e-05
Trained batch 291 in epoch 9, gen_loss = 1.5145617421359232, disc_loss = 9.600233187646229e-05
Trained batch 292 in epoch 9, gen_loss = 1.5146953799211937, disc_loss = 9.579107615998994e-05
Trained batch 293 in epoch 9, gen_loss = 1.5146086329505557, disc_loss = 9.558218279176353e-05
Trained batch 294 in epoch 9, gen_loss = 1.5144812519267454, disc_loss = 9.539718853144006e-05
Trained batch 295 in epoch 9, gen_loss = 1.5144484949273032, disc_loss = 9.525340390216632e-05
Trained batch 296 in epoch 9, gen_loss = 1.5141987194517246, disc_loss = 9.516580237331643e-05
Trained batch 297 in epoch 9, gen_loss = 1.514065618082981, disc_loss = 9.498609753009931e-05
Trained batch 298 in epoch 9, gen_loss = 1.5138794530594228, disc_loss = 9.4881660190495e-05
Trained batch 299 in epoch 9, gen_loss = 1.513887026309967, disc_loss = 9.478186116515038e-05
Trained batch 300 in epoch 9, gen_loss = 1.5136472319447718, disc_loss = 9.472650877838997e-05
Trained batch 301 in epoch 9, gen_loss = 1.5135390083521407, disc_loss = 9.471601019235673e-05
Trained batch 302 in epoch 9, gen_loss = 1.5137999069572676, disc_loss = 9.475427703922707e-05
Trained batch 303 in epoch 9, gen_loss = 1.5136504832066988, disc_loss = 9.477718463370508e-05
Trained batch 304 in epoch 9, gen_loss = 1.5136107456488688, disc_loss = 9.464153208384351e-05
Trained batch 305 in epoch 9, gen_loss = 1.5133490406609829, disc_loss = 9.455270298168495e-05
Trained batch 306 in epoch 9, gen_loss = 1.5132940262070695, disc_loss = 9.437488155088354e-05
Trained batch 307 in epoch 9, gen_loss = 1.513195289419843, disc_loss = 9.422042041313199e-05
Trained batch 308 in epoch 9, gen_loss = 1.5132138833258917, disc_loss = 9.419651423064045e-05
Trained batch 309 in epoch 9, gen_loss = 1.513238775345587, disc_loss = 9.409597046361606e-05
Trained batch 310 in epoch 9, gen_loss = 1.5131119382343108, disc_loss = 9.389584120890796e-05
Trained batch 311 in epoch 9, gen_loss = 1.5131944922300486, disc_loss = 9.377782601241519e-05
Trained batch 312 in epoch 9, gen_loss = 1.513269307514349, disc_loss = 9.361288678842023e-05
Trained batch 313 in epoch 9, gen_loss = 1.513181938107606, disc_loss = 9.34312357359631e-05
Trained batch 314 in epoch 9, gen_loss = 1.5132979767663137, disc_loss = 9.33813399613081e-05
Trained batch 315 in epoch 9, gen_loss = 1.513209617967847, disc_loss = 9.33058230818656e-05
Trained batch 316 in epoch 9, gen_loss = 1.5133149496012306, disc_loss = 9.334422403278875e-05
Trained batch 317 in epoch 9, gen_loss = 1.5134210758988962, disc_loss = 9.329041762921063e-05
Trained batch 318 in epoch 9, gen_loss = 1.5133498723977785, disc_loss = 9.328545676343592e-05
Trained batch 319 in epoch 9, gen_loss = 1.5134683098644017, disc_loss = 9.330019645403809e-05
Trained batch 320 in epoch 9, gen_loss = 1.5135612773746716, disc_loss = 9.325119550067879e-05
Trained batch 321 in epoch 9, gen_loss = 1.5135440533946019, disc_loss = 9.311067439530404e-05
Trained batch 322 in epoch 9, gen_loss = 1.5137341941473286, disc_loss = 9.326895963993131e-05
Trained batch 323 in epoch 9, gen_loss = 1.513746390004217, disc_loss = 9.330923194845385e-05
Trained batch 324 in epoch 9, gen_loss = 1.5136996309573834, disc_loss = 9.327842180097762e-05
Trained batch 325 in epoch 9, gen_loss = 1.5134755852032293, disc_loss = 9.347633354667934e-05
Trained batch 326 in epoch 9, gen_loss = 1.5134420504263781, disc_loss = 9.340419508684113e-05
Trained batch 327 in epoch 9, gen_loss = 1.5134392860459118, disc_loss = 9.329357220760757e-05
Trained batch 328 in epoch 9, gen_loss = 1.5134113907451687, disc_loss = 9.312925092086173e-05
Trained batch 329 in epoch 9, gen_loss = 1.5133362871227842, disc_loss = 9.313377064024803e-05
Trained batch 330 in epoch 9, gen_loss = 1.513396123384781, disc_loss = 9.309766105245349e-05
Trained batch 331 in epoch 9, gen_loss = 1.5132280308080006, disc_loss = 9.302441795154598e-05
Trained batch 332 in epoch 9, gen_loss = 1.513248125712077, disc_loss = 9.292038724582583e-05
Trained batch 333 in epoch 9, gen_loss = 1.5131420346791158, disc_loss = 9.280421377815276e-05
Trained batch 334 in epoch 9, gen_loss = 1.513172295200291, disc_loss = 9.263552880173535e-05
Trained batch 335 in epoch 9, gen_loss = 1.5133728232412111, disc_loss = 9.250177556298565e-05
Trained batch 336 in epoch 9, gen_loss = 1.5131589963103613, disc_loss = 9.245792295131211e-05
Trained batch 337 in epoch 9, gen_loss = 1.5131773754689821, disc_loss = 9.240397904094063e-05
Trained batch 338 in epoch 9, gen_loss = 1.513199364541203, disc_loss = 9.237205187759532e-05
Trained batch 339 in epoch 9, gen_loss = 1.513072333616369, disc_loss = 9.230624625214498e-05
Trained batch 340 in epoch 9, gen_loss = 1.5128596437292015, disc_loss = 9.221561257380929e-05
Trained batch 341 in epoch 9, gen_loss = 1.5127787555170338, disc_loss = 9.212238199973809e-05
Trained batch 342 in epoch 9, gen_loss = 1.5126960489562231, disc_loss = 9.200104959904754e-05
Trained batch 343 in epoch 9, gen_loss = 1.5126738586398059, disc_loss = 9.181775276586047e-05
Trained batch 344 in epoch 9, gen_loss = 1.5124878161195396, disc_loss = 9.180413407443995e-05
Trained batch 345 in epoch 9, gen_loss = 1.512440673188667, disc_loss = 9.16488913594943e-05
Trained batch 346 in epoch 9, gen_loss = 1.5123611743580712, disc_loss = 9.148162009836288e-05
Trained batch 347 in epoch 9, gen_loss = 1.5123125331840297, disc_loss = 9.13066737928017e-05
Trained batch 348 in epoch 9, gen_loss = 1.5120443317473446, disc_loss = 9.170169279322544e-05
Trained batch 349 in epoch 9, gen_loss = 1.512189882482801, disc_loss = 9.193137596802055e-05
Trained batch 350 in epoch 9, gen_loss = 1.5120921888922014, disc_loss = 9.207492600769889e-05
Trained batch 351 in epoch 9, gen_loss = 1.5119801542975686, disc_loss = 9.205885458579195e-05
Trained batch 352 in epoch 9, gen_loss = 1.5118912326715486, disc_loss = 9.199173563638526e-05
Trained batch 353 in epoch 9, gen_loss = 1.5119327643496843, disc_loss = 9.18963237047836e-05
Trained batch 354 in epoch 9, gen_loss = 1.512067185657125, disc_loss = 9.183974957715024e-05
Trained batch 355 in epoch 9, gen_loss = 1.5119886110337932, disc_loss = 9.177752503439499e-05
Trained batch 356 in epoch 9, gen_loss = 1.5120298321507557, disc_loss = 9.171550301908312e-05
Trained batch 357 in epoch 9, gen_loss = 1.5120668854127384, disc_loss = 9.177699391009851e-05
Trained batch 358 in epoch 9, gen_loss = 1.512139854989012, disc_loss = 9.18393268566585e-05
Trained batch 359 in epoch 9, gen_loss = 1.5122141069836086, disc_loss = 9.17635072760782e-05
Trained batch 360 in epoch 9, gen_loss = 1.5123034467987737, disc_loss = 9.174825738474709e-05
Trained batch 361 in epoch 9, gen_loss = 1.5122535732569615, disc_loss = 9.169661473842706e-05
Trained batch 362 in epoch 9, gen_loss = 1.5123002144915998, disc_loss = 9.165872758908323e-05
Trained batch 363 in epoch 9, gen_loss = 1.5122371260281449, disc_loss = 9.163538042840018e-05
Trained batch 364 in epoch 9, gen_loss = 1.5120745714396646, disc_loss = 9.171528984315706e-05
Trained batch 365 in epoch 9, gen_loss = 1.511968570328801, disc_loss = 9.185256057520984e-05
Trained batch 366 in epoch 9, gen_loss = 1.5119729792389622, disc_loss = 9.184683128794572e-05
Trained batch 367 in epoch 9, gen_loss = 1.5118127021452654, disc_loss = 9.189940521497667e-05
Trained batch 368 in epoch 9, gen_loss = 1.511586148887469, disc_loss = 9.202261975006361e-05
Trained batch 369 in epoch 9, gen_loss = 1.5115407772966334, disc_loss = 9.207893262272763e-05
Trained batch 370 in epoch 9, gen_loss = 1.5113807376825585, disc_loss = 9.207325958923909e-05
Trained batch 371 in epoch 9, gen_loss = 1.5112811516049087, disc_loss = 9.198829727494583e-05
Trained batch 372 in epoch 9, gen_loss = 1.511229765319313, disc_loss = 9.187778909810839e-05
Trained batch 373 in epoch 9, gen_loss = 1.5111530757842855, disc_loss = 9.189227714091552e-05
Trained batch 374 in epoch 9, gen_loss = 1.5111205965677896, disc_loss = 9.185532516373011e-05
Trained batch 375 in epoch 9, gen_loss = 1.5110214305050829, disc_loss = 9.176264957398204e-05
Trained batch 376 in epoch 9, gen_loss = 1.510981824417013, disc_loss = 9.16096082293652e-05
Trained batch 377 in epoch 9, gen_loss = 1.5108291853672613, disc_loss = 9.14724691192436e-05
Trained batch 378 in epoch 9, gen_loss = 1.5108455233963938, disc_loss = 9.130822710562645e-05
Trained batch 379 in epoch 9, gen_loss = 1.510654251826437, disc_loss = 9.123550158906973e-05
Trained batch 380 in epoch 9, gen_loss = 1.5106695687051208, disc_loss = 9.117299005871375e-05
Trained batch 381 in epoch 9, gen_loss = 1.5107159701941526, disc_loss = 9.10973048935637e-05
Trained batch 382 in epoch 9, gen_loss = 1.510601459533054, disc_loss = 9.097110384095864e-05
Trained batch 383 in epoch 9, gen_loss = 1.5105158224081, disc_loss = 9.084505801600547e-05
Trained batch 384 in epoch 9, gen_loss = 1.5104867585293658, disc_loss = 9.072027161608559e-05
Trained batch 385 in epoch 9, gen_loss = 1.5104685184869124, disc_loss = 9.057935626585932e-05
Trained batch 386 in epoch 9, gen_loss = 1.5103637109431185, disc_loss = 9.04243635736407e-05
Trained batch 387 in epoch 9, gen_loss = 1.5103713301653714, disc_loss = 9.028592872128524e-05
Trained batch 388 in epoch 9, gen_loss = 1.5102385987352895, disc_loss = 9.015062320747014e-05
Trained batch 389 in epoch 9, gen_loss = 1.5102783236748134, disc_loss = 9.010261033276597e-05
Trained batch 390 in epoch 9, gen_loss = 1.5102599481182635, disc_loss = 9.008049816780431e-05
Trained batch 391 in epoch 9, gen_loss = 1.5102429350419921, disc_loss = 8.996004501624361e-05
Trained batch 392 in epoch 9, gen_loss = 1.5100851923454808, disc_loss = 8.990125673314741e-05
Trained batch 393 in epoch 9, gen_loss = 1.510034943897712, disc_loss = 8.982610336434259e-05
Trained batch 394 in epoch 9, gen_loss = 1.5097766553299337, disc_loss = 9.059593081658506e-05
Trained batch 395 in epoch 9, gen_loss = 1.5097267450106264, disc_loss = 9.142744250431236e-05
Trained batch 396 in epoch 9, gen_loss = 1.5096916632928536, disc_loss = 9.142094259966992e-05
Trained batch 397 in epoch 9, gen_loss = 1.5096724216063417, disc_loss = 9.143186765703918e-05
Trained batch 398 in epoch 9, gen_loss = 1.509586737568217, disc_loss = 9.140305383996583e-05
Trained batch 399 in epoch 9, gen_loss = 1.5094811490178108, disc_loss = 9.143969394244778e-05
Trained batch 400 in epoch 9, gen_loss = 1.5093965794974729, disc_loss = 9.145872639888431e-05
Trained batch 401 in epoch 9, gen_loss = 1.509399575084003, disc_loss = 9.14086523962894e-05
Trained batch 402 in epoch 9, gen_loss = 1.509524421715559, disc_loss = 9.148588248826944e-05
Trained batch 403 in epoch 9, gen_loss = 1.509515352768473, disc_loss = 9.143724071349209e-05
Trained batch 404 in epoch 9, gen_loss = 1.5095263063171764, disc_loss = 9.13658935952512e-05
Trained batch 405 in epoch 9, gen_loss = 1.5095132072570876, disc_loss = 9.127253817917385e-05
Trained batch 406 in epoch 9, gen_loss = 1.5094397366779149, disc_loss = 9.113810224770638e-05
Trained batch 407 in epoch 9, gen_loss = 1.5093409410294365, disc_loss = 9.104718814270717e-05
Trained batch 408 in epoch 9, gen_loss = 1.5094196123132495, disc_loss = 9.108206297713275e-05
Trained batch 409 in epoch 9, gen_loss = 1.5091757495228837, disc_loss = 9.11762566829566e-05
Trained batch 410 in epoch 9, gen_loss = 1.5090024227643535, disc_loss = 9.281288528570751e-05
Trained batch 411 in epoch 9, gen_loss = 1.5091307362885151, disc_loss = 9.43414719745085e-05
Trained batch 412 in epoch 9, gen_loss = 1.5090593953975464, disc_loss = 9.457431552854433e-05
Trained batch 413 in epoch 9, gen_loss = 1.5089800588174718, disc_loss = 9.481292533964382e-05
Trained batch 414 in epoch 9, gen_loss = 1.5088517223496034, disc_loss = 9.49001989393293e-05
Trained batch 415 in epoch 9, gen_loss = 1.5087495268537447, disc_loss = 9.490074760903484e-05
Trained batch 416 in epoch 9, gen_loss = 1.5087701402408042, disc_loss = 9.496517304796726e-05
Trained batch 417 in epoch 9, gen_loss = 1.508708748235657, disc_loss = 9.498473056093522e-05
Trained batch 418 in epoch 9, gen_loss = 1.5087848429463644, disc_loss = 9.499745758326484e-05
Trained batch 419 in epoch 9, gen_loss = 1.5086693863073986, disc_loss = 9.498631041510851e-05
Trained batch 420 in epoch 9, gen_loss = 1.508637342486982, disc_loss = 9.497115238154343e-05
Trained batch 421 in epoch 9, gen_loss = 1.5086350466402787, disc_loss = 9.49427471845135e-05
Trained batch 422 in epoch 9, gen_loss = 1.50850558872764, disc_loss = 9.497183964843147e-05
Trained batch 423 in epoch 9, gen_loss = 1.5085506756912987, disc_loss = 9.498512157871067e-05
Trained batch 424 in epoch 9, gen_loss = 1.5084379431780648, disc_loss = 9.511773565249956e-05
Trained batch 425 in epoch 9, gen_loss = 1.5082793999725663, disc_loss = 9.619594249175315e-05
Trained batch 426 in epoch 9, gen_loss = 1.5083987006538087, disc_loss = 9.68027635308722e-05
Trained batch 427 in epoch 9, gen_loss = 1.5084503565993264, disc_loss = 9.689288400915979e-05
Trained batch 428 in epoch 9, gen_loss = 1.5083491168655716, disc_loss = 9.71623725456724e-05
Trained batch 429 in epoch 9, gen_loss = 1.5083738704060399, disc_loss = 9.720124164528517e-05
Trained batch 430 in epoch 9, gen_loss = 1.5083805314349463, disc_loss = 9.72538331290977e-05
Trained batch 431 in epoch 9, gen_loss = 1.5083246818847127, disc_loss = 9.726163719918716e-05
Trained batch 432 in epoch 9, gen_loss = 1.5084418917363014, disc_loss = 9.733835204588314e-05
Trained batch 433 in epoch 9, gen_loss = 1.5085207292561158, disc_loss = 9.748960161433568e-05
Trained batch 434 in epoch 9, gen_loss = 1.508554129490907, disc_loss = 9.764000377350155e-05
Trained batch 435 in epoch 9, gen_loss = 1.5085618878723284, disc_loss = 9.789661898965512e-05
Trained batch 436 in epoch 9, gen_loss = 1.5085858245736128, disc_loss = 9.80966103751238e-05
Trained batch 437 in epoch 9, gen_loss = 1.508523514009502, disc_loss = 9.826734009811222e-05
Trained batch 438 in epoch 9, gen_loss = 1.5084764753767461, disc_loss = 9.835830308626362e-05
Trained batch 439 in epoch 9, gen_loss = 1.50836285488172, disc_loss = 9.849272133909504e-05
Trained batch 440 in epoch 9, gen_loss = 1.5082330998379627, disc_loss = 9.862997753534027e-05
Trained batch 441 in epoch 9, gen_loss = 1.508219886149756, disc_loss = 9.874963090698155e-05
Trained batch 442 in epoch 9, gen_loss = 1.5080779050865776, disc_loss = 9.917857817323714e-05
Trained batch 443 in epoch 9, gen_loss = 1.5081227658031222, disc_loss = 9.951545966491271e-05
Trained batch 444 in epoch 9, gen_loss = 1.508091913716177, disc_loss = 9.950954708064058e-05
Trained batch 445 in epoch 9, gen_loss = 1.5079984745102613, disc_loss = 9.973413086662825e-05
Trained batch 446 in epoch 9, gen_loss = 1.5079016610813354, disc_loss = 0.00010004132126691861
Trained batch 447 in epoch 9, gen_loss = 1.5078185881887163, disc_loss = 0.00010062913739667627
Trained batch 448 in epoch 9, gen_loss = 1.5078720430488841, disc_loss = 0.00010114506321385159
Trained batch 449 in epoch 9, gen_loss = 1.5079030582639905, disc_loss = 0.00010233282675876075
Trained batch 450 in epoch 9, gen_loss = 1.5069393392677053, disc_loss = 0.0003460899388301186
Trained batch 451 in epoch 9, gen_loss = 1.5080298871065663, disc_loss = 0.0005620416151330058
Trained batch 452 in epoch 9, gen_loss = 1.5086660648287, disc_loss = 0.0006792065928563955
Trained batch 453 in epoch 9, gen_loss = 1.5083160200833223, disc_loss = 0.0007587653109405061
Trained batch 454 in epoch 9, gen_loss = 1.5078549568469708, disc_loss = 0.0008237459547952033
Trained batch 455 in epoch 9, gen_loss = 1.5082608814302243, disc_loss = 0.0008538949651075088
Trained batch 456 in epoch 9, gen_loss = 1.5091063123302335, disc_loss = 0.0008711865037829713
Trained batch 457 in epoch 9, gen_loss = 1.5090592066273418, disc_loss = 0.0009087592949532837
Trained batch 458 in epoch 9, gen_loss = 1.509890706710566, disc_loss = 0.0009311461939420886
Trained batch 459 in epoch 9, gen_loss = 1.5106142782646677, disc_loss = 0.0009471381917809714
Trained batch 460 in epoch 9, gen_loss = 1.5109630197351254, disc_loss = 0.0009535066429415764
Trained batch 461 in epoch 9, gen_loss = 1.5112777192355233, disc_loss = 0.0009598191454130965
Trained batch 462 in epoch 9, gen_loss = 1.511593294710114, disc_loss = 0.0009621871990881122
Trained batch 463 in epoch 9, gen_loss = 1.5119206399239342, disc_loss = 0.0009638201863865482
Trained batch 464 in epoch 9, gen_loss = 1.5122942260516588, disc_loss = 0.0009646614870308117
Trained batch 465 in epoch 9, gen_loss = 1.5124867704293248, disc_loss = 0.0009648958697762439
Trained batch 466 in epoch 9, gen_loss = 1.512727072203185, disc_loss = 0.0009646573945077493
Trained batch 467 in epoch 9, gen_loss = 1.5129026307000055, disc_loss = 0.0009640800084852321
Trained batch 468 in epoch 9, gen_loss = 1.513022815749081, disc_loss = 0.0009673362288819894
Trained batch 469 in epoch 9, gen_loss = 1.5134252822145502, disc_loss = 0.000967386276092742
Trained batch 470 in epoch 9, gen_loss = 1.5139140857506204, disc_loss = 0.0009677932776923236
Trained batch 471 in epoch 9, gen_loss = 1.5141924427727522, disc_loss = 0.000966726553689129
Trained batch 472 in epoch 9, gen_loss = 1.514449962349825, disc_loss = 0.0009690626149453926
Trained batch 473 in epoch 9, gen_loss = 1.5145589158504824, disc_loss = 0.0009742857852145364
Trained batch 474 in epoch 9, gen_loss = 1.51505328730533, disc_loss = 0.0009751024766439131
Trained batch 475 in epoch 9, gen_loss = 1.5152454130789812, disc_loss = 0.0009754792564239661
Trained batch 476 in epoch 9, gen_loss = 1.515589257206307, disc_loss = 0.000976704199427072
Trained batch 477 in epoch 9, gen_loss = 1.5157902834305703, disc_loss = 0.0009766395689066447
Trained batch 478 in epoch 9, gen_loss = 1.5157442282037596, disc_loss = 0.0009761950630012419
Trained batch 479 in epoch 9, gen_loss = 1.5159436705211797, disc_loss = 0.0009750053113900018
Trained batch 480 in epoch 9, gen_loss = 1.5159416771232461, disc_loss = 0.0009804403066680876
Trained batch 481 in epoch 9, gen_loss = 1.516008651108168, disc_loss = 0.0009818611928404076
Trained batch 482 in epoch 9, gen_loss = 1.516344059574925, disc_loss = 0.0009835644448244719
Trained batch 483 in epoch 9, gen_loss = 1.516439345996242, disc_loss = 0.0009825034756897728
Trained batch 484 in epoch 9, gen_loss = 1.5165031614991809, disc_loss = 0.0009830172058013652
Trained batch 485 in epoch 9, gen_loss = 1.5167087674631503, disc_loss = 0.0009824222647001701
Trained batch 486 in epoch 9, gen_loss = 1.5164096296690328, disc_loss = 0.0009979573852513836
Trained batch 487 in epoch 9, gen_loss = 1.517370284092231, disc_loss = 0.0010203729215256733
Trained batch 488 in epoch 9, gen_loss = 1.517832692903, disc_loss = 0.0010211233126318818
Trained batch 489 in epoch 9, gen_loss = 1.5181854727316877, disc_loss = 0.0010233455760035026
Trained batch 490 in epoch 9, gen_loss = 1.5180755982331007, disc_loss = 0.0010309262601915954
Trained batch 491 in epoch 9, gen_loss = 1.5182728786778643, disc_loss = 0.0010426057425519967
Trained batch 492 in epoch 9, gen_loss = 1.518670566667166, disc_loss = 0.0010461273355227441
Trained batch 493 in epoch 9, gen_loss = 1.5188967018474935, disc_loss = 0.0010466149089574438
Trained batch 494 in epoch 9, gen_loss = 1.5190223775728784, disc_loss = 0.001047129123286471
Trained batch 495 in epoch 9, gen_loss = 1.5191703969913144, disc_loss = 0.0010513324626176214
Trained batch 496 in epoch 9, gen_loss = 1.5190940370981842, disc_loss = 0.0010588683301829584
Trained batch 497 in epoch 9, gen_loss = 1.5186462127061253, disc_loss = 0.0010959798980245497
Trained batch 498 in epoch 9, gen_loss = 1.519681417631482, disc_loss = 0.0018315496518098626
Trained batch 499 in epoch 9, gen_loss = 1.5180083799362183, disc_loss = 0.003631244511299883
Trained batch 500 in epoch 9, gen_loss = 1.5162732444123594, disc_loss = 0.004228686234366429
Trained batch 501 in epoch 9, gen_loss = 1.5153783455312964, disc_loss = 0.0048231809330943915
Trained batch 502 in epoch 9, gen_loss = 1.5142403409684866, disc_loss = 0.005380964333381412
Trained batch 503 in epoch 9, gen_loss = 1.5127896784789978, disc_loss = 0.005868133838385615
Trained batch 504 in epoch 9, gen_loss = 1.5113326863487169, disc_loss = 0.0063208006109868285
Trained batch 505 in epoch 9, gen_loss = 1.5098683966007158, disc_loss = 0.006724311694967687
Trained batch 506 in epoch 9, gen_loss = 1.5087328440338903, disc_loss = 0.007063603114029158
Trained batch 507 in epoch 9, gen_loss = 1.5076859873814845, disc_loss = 0.007353481962155907
Trained batch 508 in epoch 9, gen_loss = 1.5061267051106586, disc_loss = 0.007688365570155282
Trained batch 509 in epoch 9, gen_loss = 1.5055995479518292, disc_loss = 0.007855999295319563
Trained batch 510 in epoch 9, gen_loss = 1.5048908894542612, disc_loss = 0.007951444515153887
Trained batch 511 in epoch 9, gen_loss = 1.5038475462934002, disc_loss = 0.008033377439417677
Trained batch 512 in epoch 9, gen_loss = 1.5038455563214324, disc_loss = 0.008098575006038623
Trained batch 513 in epoch 9, gen_loss = 1.5029472920913176, disc_loss = 0.008195923279805208
Trained batch 514 in epoch 9, gen_loss = 1.503044294500814, disc_loss = 0.008255834972389265
Trained batch 515 in epoch 9, gen_loss = 1.5031466445950574, disc_loss = 0.008266650180853185
Trained batch 516 in epoch 9, gen_loss = 1.5027029473961437, disc_loss = 0.008298243877815819
Trained batch 517 in epoch 9, gen_loss = 1.5027718614197145, disc_loss = 0.00829964754002047
Trained batch 518 in epoch 9, gen_loss = 1.5030121923871123, disc_loss = 0.008309121501118035
Trained batch 519 in epoch 9, gen_loss = 1.5030678786910496, disc_loss = 0.008308728842488422
Trained batch 520 in epoch 9, gen_loss = 1.503133558380398, disc_loss = 0.008304363192551687
Trained batch 521 in epoch 9, gen_loss = 1.5032347688501366, disc_loss = 0.008299771744459158
Trained batch 522 in epoch 9, gen_loss = 1.5032470163606093, disc_loss = 0.008290695281564966
Trained batch 523 in epoch 9, gen_loss = 1.503258404499702, disc_loss = 0.008280240148992942
Trained batch 524 in epoch 9, gen_loss = 1.5033069666226704, disc_loss = 0.00826868560781891
Trained batch 525 in epoch 9, gen_loss = 1.5033426267792518, disc_loss = 0.008256034227046596
Trained batch 526 in epoch 9, gen_loss = 1.5035373505197847, disc_loss = 0.008244099516903233
Trained batch 527 in epoch 9, gen_loss = 1.5035248914677086, disc_loss = 0.008231225737883065
Trained batch 528 in epoch 9, gen_loss = 1.5034950398091784, disc_loss = 0.008219486428559507
Trained batch 529 in epoch 9, gen_loss = 1.503306859506751, disc_loss = 0.008208684953995475
Trained batch 530 in epoch 9, gen_loss = 1.5033617227315454, disc_loss = 0.008199371947741277
Trained batch 531 in epoch 9, gen_loss = 1.5035208715756136, disc_loss = 0.008190015067403399
Trained batch 532 in epoch 9, gen_loss = 1.5036083906050248, disc_loss = 0.008177985319666023
Trained batch 533 in epoch 9, gen_loss = 1.503550171963731, disc_loss = 0.008164604819227251
Trained batch 534 in epoch 9, gen_loss = 1.5035501345295772, disc_loss = 0.008151508542607325
Trained batch 535 in epoch 9, gen_loss = 1.5036038523956912, disc_loss = 0.008140626323886442
Trained batch 536 in epoch 9, gen_loss = 1.503323911621584, disc_loss = 0.008131043894827869
Trained batch 537 in epoch 9, gen_loss = 1.5032991592990421, disc_loss = 0.008118827970481333
Trained batch 538 in epoch 9, gen_loss = 1.503125188633772, disc_loss = 0.00810638192414139
Trained batch 539 in epoch 9, gen_loss = 1.5031230746595947, disc_loss = 0.008094193459301433
Trained batch 540 in epoch 9, gen_loss = 1.5031194729857877, disc_loss = 0.008081211465071002
Trained batch 541 in epoch 9, gen_loss = 1.5030710968804095, disc_loss = 0.008068462498437177
Trained batch 542 in epoch 9, gen_loss = 1.50306693877524, disc_loss = 0.008055664508856603
Trained batch 543 in epoch 9, gen_loss = 1.5031076030915274, disc_loss = 0.008043462481576653
Trained batch 544 in epoch 9, gen_loss = 1.503144892968169, disc_loss = 0.008032041690229554
Trained batch 545 in epoch 9, gen_loss = 1.5029821527964904, disc_loss = 0.008021514795786354
Trained batch 546 in epoch 9, gen_loss = 1.5029008446271501, disc_loss = 0.008011424128212298
Trained batch 547 in epoch 9, gen_loss = 1.5028275839821266, disc_loss = 0.007998899504397151
Trained batch 548 in epoch 9, gen_loss = 1.5027684816897242, disc_loss = 0.007990068102042672
Trained batch 549 in epoch 9, gen_loss = 1.502387411919507, disc_loss = 0.007986940562854712
Trained batch 550 in epoch 9, gen_loss = 1.5023567084824758, disc_loss = 0.007976639065885693
Trained batch 551 in epoch 9, gen_loss = 1.5026597398994626, disc_loss = 0.007979155467459666
Trained batch 552 in epoch 9, gen_loss = 1.5027798949917661, disc_loss = 0.007972212869526712
Trained batch 553 in epoch 9, gen_loss = 1.5026528001477142, disc_loss = 0.007964143162597553
Trained batch 554 in epoch 9, gen_loss = 1.5023977800532504, disc_loss = 0.007956640865312373
Trained batch 555 in epoch 9, gen_loss = 1.5025159338180967, disc_loss = 0.007948890819992446
Trained batch 556 in epoch 9, gen_loss = 1.5024397718842197, disc_loss = 0.007939689896737549
Trained batch 557 in epoch 9, gen_loss = 1.502501672207241, disc_loss = 0.007929792773276571
Trained batch 558 in epoch 9, gen_loss = 1.5025204024502545, disc_loss = 0.007919913487659774
Trained batch 559 in epoch 9, gen_loss = 1.50261847323605, disc_loss = 0.007911007326622763
Trained batch 560 in epoch 9, gen_loss = 1.5026165392522082, disc_loss = 0.007899256479935642
Trained batch 561 in epoch 9, gen_loss = 1.5026049523803262, disc_loss = 0.007887448255825408
Trained batch 562 in epoch 9, gen_loss = 1.5024174469825853, disc_loss = 0.007879048147072645
Trained batch 563 in epoch 9, gen_loss = 1.502441132216589, disc_loss = 0.00786959246938137
Trained batch 564 in epoch 9, gen_loss = 1.5025008917909808, disc_loss = 0.007859453720422318
Trained batch 565 in epoch 9, gen_loss = 1.5026639549344674, disc_loss = 0.007848736876089644
Trained batch 566 in epoch 9, gen_loss = 1.5026317539458973, disc_loss = 0.007840047827333059
Trained batch 567 in epoch 9, gen_loss = 1.5028138046323414, disc_loss = 0.00783870520982918
Trained batch 568 in epoch 9, gen_loss = 1.5027248753604654, disc_loss = 0.007830464939494443
Trained batch 569 in epoch 9, gen_loss = 1.5026294880791715, disc_loss = 0.00782109251805722
Trained batch 570 in epoch 9, gen_loss = 1.5026170250204525, disc_loss = 0.007810576520569157
Trained batch 571 in epoch 9, gen_loss = 1.5025932235526038, disc_loss = 0.007799008028125134
Trained batch 572 in epoch 9, gen_loss = 1.5023366850500124, disc_loss = 0.0077884492029609235
Trained batch 573 in epoch 9, gen_loss = 1.5023803020395883, disc_loss = 0.007777602619247431
Trained batch 574 in epoch 9, gen_loss = 1.5023779814139657, disc_loss = 0.007765834604190035
Trained batch 575 in epoch 9, gen_loss = 1.5023014933491747, disc_loss = 0.007754106170940152
Trained batch 576 in epoch 9, gen_loss = 1.50220073725983, disc_loss = 0.007741971106829458
Trained batch 577 in epoch 9, gen_loss = 1.5019382150734173, disc_loss = 0.007738074560041534
Trained batch 578 in epoch 9, gen_loss = 1.5022242002330708, disc_loss = 0.007730672930109227
Trained batch 579 in epoch 9, gen_loss = 1.5023117006852709, disc_loss = 0.007720251781988893
Trained batch 580 in epoch 9, gen_loss = 1.5023794011076634, disc_loss = 0.007708821345881375
Trained batch 581 in epoch 9, gen_loss = 1.5021981542667573, disc_loss = 0.0076975433067107595
Trained batch 582 in epoch 9, gen_loss = 1.5021897291646404, disc_loss = 0.007685783853889487
Trained batch 583 in epoch 9, gen_loss = 1.5021135477374679, disc_loss = 0.007674106765977105
Trained batch 584 in epoch 9, gen_loss = 1.5021418050823048, disc_loss = 0.007664188048187902
Trained batch 585 in epoch 9, gen_loss = 1.5021226569857613, disc_loss = 0.007652890201046234
Trained batch 586 in epoch 9, gen_loss = 1.502075856040649, disc_loss = 0.007641152539205705
Trained batch 587 in epoch 9, gen_loss = 1.501950748822316, disc_loss = 0.007629050222108379
Trained batch 588 in epoch 9, gen_loss = 1.5017635307206767, disc_loss = 0.0076179557003410725
Trained batch 589 in epoch 9, gen_loss = 1.5017450250811497, disc_loss = 0.0076077081885221375
Trained batch 590 in epoch 9, gen_loss = 1.5018955766650424, disc_loss = 0.007596538508374046
Trained batch 591 in epoch 9, gen_loss = 1.5018252459530894, disc_loss = 0.007584872155950654
Trained batch 592 in epoch 9, gen_loss = 1.5017383636350776, disc_loss = 0.00757341978988898
Trained batch 593 in epoch 9, gen_loss = 1.5016032929974372, disc_loss = 0.007561750978179788
Trained batch 594 in epoch 9, gen_loss = 1.5015865833819413, disc_loss = 0.007550043457233202
Trained batch 595 in epoch 9, gen_loss = 1.501667551446281, disc_loss = 0.007542087489701655
Trained batch 596 in epoch 9, gen_loss = 1.5015346014519633, disc_loss = 0.007530908541654145
Trained batch 597 in epoch 9, gen_loss = 1.501437551700152, disc_loss = 0.007519549163556086
Trained batch 598 in epoch 9, gen_loss = 1.501445227453426, disc_loss = 0.007508184965908351
Trained batch 599 in epoch 9, gen_loss = 1.5014927422006925, disc_loss = 0.0074966125320861466
Trained batch 600 in epoch 9, gen_loss = 1.501476656676529, disc_loss = 0.007485145717255787
Trained batch 601 in epoch 9, gen_loss = 1.501440350498472, disc_loss = 0.00747332452623372
Trained batch 602 in epoch 9, gen_loss = 1.5013296162311118, disc_loss = 0.007461521182861121
Trained batch 603 in epoch 9, gen_loss = 1.5012497618695757, disc_loss = 0.007449810619395945
Trained batch 604 in epoch 9, gen_loss = 1.501269642873244, disc_loss = 0.0074380520345043765
Trained batch 605 in epoch 9, gen_loss = 1.501270977675718, disc_loss = 0.007426466130697734
Trained batch 606 in epoch 9, gen_loss = 1.5011748530130213, disc_loss = 0.007414879898513921
Trained batch 607 in epoch 9, gen_loss = 1.5011143512827785, disc_loss = 0.0074034720807958365
Trained batch 608 in epoch 9, gen_loss = 1.501057880950483, disc_loss = 0.007392006792009664
Trained batch 609 in epoch 9, gen_loss = 1.5009595655026984, disc_loss = 0.007380827139363124
Trained batch 610 in epoch 9, gen_loss = 1.5008470199502237, disc_loss = 0.007369411187138315
Trained batch 611 in epoch 9, gen_loss = 1.5008174670872345, disc_loss = 0.007358681286871681
Trained batch 612 in epoch 9, gen_loss = 1.5008048216825987, disc_loss = 0.00734753929484086
Trained batch 613 in epoch 9, gen_loss = 1.500890482035056, disc_loss = 0.007336606551381226
Trained batch 614 in epoch 9, gen_loss = 1.5008333030754957, disc_loss = 0.007325549700311139
Trained batch 615 in epoch 9, gen_loss = 1.5006807646774627, disc_loss = 0.007314156617555112
Trained batch 616 in epoch 9, gen_loss = 1.5005717635927556, disc_loss = 0.0073027809009030865
Trained batch 617 in epoch 9, gen_loss = 1.5004794012188525, disc_loss = 0.007291424896929833
Trained batch 618 in epoch 9, gen_loss = 1.500352379289698, disc_loss = 0.007280567388755239
Trained batch 619 in epoch 9, gen_loss = 1.5003562186033494, disc_loss = 0.007270046357863917
Trained batch 620 in epoch 9, gen_loss = 1.5003734743537533, disc_loss = 0.007259135312105408
Trained batch 621 in epoch 9, gen_loss = 1.500246653890303, disc_loss = 0.007248181618162497
Trained batch 622 in epoch 9, gen_loss = 1.5001494864399514, disc_loss = 0.007237885515323753
Trained batch 623 in epoch 9, gen_loss = 1.5001850889470332, disc_loss = 0.0072275288703983675
Trained batch 624 in epoch 9, gen_loss = 1.5002797505378722, disc_loss = 0.007216857502481434
Trained batch 625 in epoch 9, gen_loss = 1.5002617324693515, disc_loss = 0.007206002546152336
Trained batch 626 in epoch 9, gen_loss = 1.5002530479545229, disc_loss = 0.007195355058122709
Trained batch 627 in epoch 9, gen_loss = 1.5001410757470284, disc_loss = 0.007184360481509557
Trained batch 628 in epoch 9, gen_loss = 1.5000591862751305, disc_loss = 0.00717340122239706
Trained batch 629 in epoch 9, gen_loss = 1.4999738065969377, disc_loss = 0.007163222016647018
Trained batch 630 in epoch 9, gen_loss = 1.4998894411297117, disc_loss = 0.0071525577765915475
Trained batch 631 in epoch 9, gen_loss = 1.4998069093385828, disc_loss = 0.007141917436905415
Trained batch 632 in epoch 9, gen_loss = 1.4996930781698905, disc_loss = 0.007132363324015424
Trained batch 633 in epoch 9, gen_loss = 1.4996615011797343, disc_loss = 0.0071218677804617495
Trained batch 634 in epoch 9, gen_loss = 1.4995718472585904, disc_loss = 0.00711161047386374
Trained batch 635 in epoch 9, gen_loss = 1.4995355033462152, disc_loss = 0.007101195164068486
Trained batch 636 in epoch 9, gen_loss = 1.4995651785021114, disc_loss = 0.0070906280871928275
Trained batch 637 in epoch 9, gen_loss = 1.4994236242995367, disc_loss = 0.007080303092329229
Trained batch 638 in epoch 9, gen_loss = 1.499357498960689, disc_loss = 0.007069877277435651
Trained batch 639 in epoch 9, gen_loss = 1.499406026955694, disc_loss = 0.007060438410564984
Trained batch 640 in epoch 9, gen_loss = 1.4995073034499253, disc_loss = 0.007050155379917772
Trained batch 641 in epoch 9, gen_loss = 1.4993849969541544, disc_loss = 0.0070404238070854
Trained batch 642 in epoch 9, gen_loss = 1.4992471163046674, disc_loss = 0.007030019703056192
Trained batch 643 in epoch 9, gen_loss = 1.499266970879543, disc_loss = 0.007019642180205422
Trained batch 644 in epoch 9, gen_loss = 1.4992051112559415, disc_loss = 0.007009108150871958
Trained batch 645 in epoch 9, gen_loss = 1.4990757597673787, disc_loss = 0.00699868763605017
Trained batch 646 in epoch 9, gen_loss = 1.499054032186452, disc_loss = 0.0069886300916663134
Trained batch 647 in epoch 9, gen_loss = 1.498978295535953, disc_loss = 0.006978454063306502
Trained batch 648 in epoch 9, gen_loss = 1.498818512414747, disc_loss = 0.006968790727546162
Trained batch 649 in epoch 9, gen_loss = 1.498783271221014, disc_loss = 0.0069588089016010945
Trained batch 650 in epoch 9, gen_loss = 1.4987404742914776, disc_loss = 0.006948599907913916
Trained batch 651 in epoch 9, gen_loss = 1.4985158129886615, disc_loss = 0.006938574436763741
Trained batch 652 in epoch 9, gen_loss = 1.4983772858178634, disc_loss = 0.006929207827626591
Trained batch 653 in epoch 9, gen_loss = 1.49822220315627, disc_loss = 0.006919642486342066
Trained batch 654 in epoch 9, gen_loss = 1.4981295999679856, disc_loss = 0.006909723899881302
Trained batch 655 in epoch 9, gen_loss = 1.497992063350067, disc_loss = 0.0068997807280073
Trained batch 656 in epoch 9, gen_loss = 1.4978715623169003, disc_loss = 0.006889826626584832
Trained batch 657 in epoch 9, gen_loss = 1.497785178451915, disc_loss = 0.0068800383158686106
Trained batch 658 in epoch 9, gen_loss = 1.497724911240417, disc_loss = 0.006869912680411342
Trained batch 659 in epoch 9, gen_loss = 1.497623189741915, disc_loss = 0.006860835319413595
Trained batch 660 in epoch 9, gen_loss = 1.49760526761345, disc_loss = 0.006851188453714734
Trained batch 661 in epoch 9, gen_loss = 1.4973674127522552, disc_loss = 0.006841385119341492
Trained batch 662 in epoch 9, gen_loss = 1.497297350727415, disc_loss = 0.006831466325902964
Trained batch 663 in epoch 9, gen_loss = 1.497237761426403, disc_loss = 0.006821863605204359
Trained batch 664 in epoch 9, gen_loss = 1.4972993125592855, disc_loss = 0.006812697384496398
Trained batch 665 in epoch 9, gen_loss = 1.497136759596902, disc_loss = 0.006803662259759281
Trained batch 666 in epoch 9, gen_loss = 1.4970894252163718, disc_loss = 0.006794883785996676
Trained batch 667 in epoch 9, gen_loss = 1.4970270619242492, disc_loss = 0.006786268503167879
Trained batch 668 in epoch 9, gen_loss = 1.496901308207234, disc_loss = 0.006777270462845368
Trained batch 669 in epoch 9, gen_loss = 1.4967889391664249, disc_loss = 0.006768278038025393
Trained batch 670 in epoch 9, gen_loss = 1.49674394882205, disc_loss = 0.00675971716136511
Trained batch 671 in epoch 9, gen_loss = 1.496662455743977, disc_loss = 0.0067502756985504675
Trained batch 672 in epoch 9, gen_loss = 1.4966346368215768, disc_loss = 0.006740977817186397
Trained batch 673 in epoch 9, gen_loss = 1.4965386168716215, disc_loss = 0.006731781288294432
Trained batch 674 in epoch 9, gen_loss = 1.4965925397696318, disc_loss = 0.0067225316909456595
Trained batch 675 in epoch 9, gen_loss = 1.496389326700092, disc_loss = 0.006713133044980453
Trained batch 676 in epoch 9, gen_loss = 1.4963019074682296, disc_loss = 0.006703700670170542
Trained batch 677 in epoch 9, gen_loss = 1.4962716003259022, disc_loss = 0.006694165055268216
Trained batch 678 in epoch 9, gen_loss = 1.4962736397147705, disc_loss = 0.006684720376354285
Trained batch 679 in epoch 9, gen_loss = 1.496063452696099, disc_loss = 0.0066751221773622945
Trained batch 680 in epoch 9, gen_loss = 1.4960324288990003, disc_loss = 0.00666573896234906
Trained batch 681 in epoch 9, gen_loss = 1.4959412873490465, disc_loss = 0.006656898543743647
Trained batch 682 in epoch 9, gen_loss = 1.4958457242517484, disc_loss = 0.006647495614396873
Trained batch 683 in epoch 9, gen_loss = 1.4958659944652815, disc_loss = 0.00663827184586398
Trained batch 684 in epoch 9, gen_loss = 1.495651712469811, disc_loss = 0.006629284643952609
Trained batch 685 in epoch 9, gen_loss = 1.4956327390914061, disc_loss = 0.006620095244571231
Trained batch 686 in epoch 9, gen_loss = 1.4955983164529092, disc_loss = 0.0066109910828836315
Trained batch 687 in epoch 9, gen_loss = 1.4953966952513817, disc_loss = 0.0066019108971357675
Trained batch 688 in epoch 9, gen_loss = 1.4953837594549957, disc_loss = 0.006592883672950879
Trained batch 689 in epoch 9, gen_loss = 1.4952786429204803, disc_loss = 0.006584022985149152
Trained batch 690 in epoch 9, gen_loss = 1.4951907197059322, disc_loss = 0.006574834293927866
Trained batch 691 in epoch 9, gen_loss = 1.4948962750290171, disc_loss = 0.006566057925759307
Trained batch 692 in epoch 9, gen_loss = 1.4948618817122983, disc_loss = 0.006557250964989255
Trained batch 693 in epoch 9, gen_loss = 1.4948335747725683, disc_loss = 0.0065485299313384725
Trained batch 694 in epoch 9, gen_loss = 1.4948371471260948, disc_loss = 0.00653957672985212
Trained batch 695 in epoch 9, gen_loss = 1.4947497927765736, disc_loss = 0.00653049580935543
Trained batch 696 in epoch 9, gen_loss = 1.49453922605925, disc_loss = 0.00652164805058894
Trained batch 697 in epoch 9, gen_loss = 1.49450741311199, disc_loss = 0.00651264825090424
Trained batch 698 in epoch 9, gen_loss = 1.4944284213800116, disc_loss = 0.006503753813207386
Trained batch 699 in epoch 9, gen_loss = 1.4944322016409466, disc_loss = 0.006495018418884554
Trained batch 700 in epoch 9, gen_loss = 1.49427670852604, disc_loss = 0.006486108832893885
Trained batch 701 in epoch 9, gen_loss = 1.4942145896942867, disc_loss = 0.006477321723951249
Trained batch 702 in epoch 9, gen_loss = 1.4941468594084424, disc_loss = 0.006468326254705332
Trained batch 703 in epoch 9, gen_loss = 1.4941109123385765, disc_loss = 0.006459601457901375
Trained batch 704 in epoch 9, gen_loss = 1.493949140301833, disc_loss = 0.006450820038479453
Trained batch 705 in epoch 9, gen_loss = 1.4938854370002368, disc_loss = 0.006441988398235805
Trained batch 706 in epoch 9, gen_loss = 1.4937841319801783, disc_loss = 0.006433098685340755
Trained batch 707 in epoch 9, gen_loss = 1.493716508234288, disc_loss = 0.006424234279743899
Trained batch 708 in epoch 9, gen_loss = 1.4937006782409334, disc_loss = 0.006415708079819265
Trained batch 709 in epoch 9, gen_loss = 1.4935433361731785, disc_loss = 0.006407060534711747
Trained batch 710 in epoch 9, gen_loss = 1.493433630499994, disc_loss = 0.006398311555828083
Trained batch 711 in epoch 9, gen_loss = 1.4933174976639534, disc_loss = 0.006389563009588017
Trained batch 712 in epoch 9, gen_loss = 1.4931857914443103, disc_loss = 0.006380848640307499
Trained batch 713 in epoch 9, gen_loss = 1.493132517200892, disc_loss = 0.00637213531068987
Trained batch 714 in epoch 9, gen_loss = 1.4930397691426578, disc_loss = 0.006363640828320668
Trained batch 715 in epoch 9, gen_loss = 1.4930558723277887, disc_loss = 0.00635526170944556
Trained batch 716 in epoch 9, gen_loss = 1.492923460495522, disc_loss = 0.006346866522076318
Trained batch 717 in epoch 9, gen_loss = 1.492908535478507, disc_loss = 0.0063387717747601805
Trained batch 718 in epoch 9, gen_loss = 1.4927596965486052, disc_loss = 0.006330503734526589
Trained batch 719 in epoch 9, gen_loss = 1.4926547039714124, disc_loss = 0.006322161774500678
Trained batch 720 in epoch 9, gen_loss = 1.4926087688473821, disc_loss = 0.006313788807275108
Trained batch 721 in epoch 9, gen_loss = 1.4925127556944817, disc_loss = 0.0063053745877855024
Trained batch 722 in epoch 9, gen_loss = 1.492409342139918, disc_loss = 0.006296921835177018
Trained batch 723 in epoch 9, gen_loss = 1.4923575491701042, disc_loss = 0.00628844808645568
Trained batch 724 in epoch 9, gen_loss = 1.492216120506155, disc_loss = 0.006280103638549415
Trained batch 725 in epoch 9, gen_loss = 1.4922753698077083, disc_loss = 0.006272311227372639
Trained batch 726 in epoch 9, gen_loss = 1.4922367950089204, disc_loss = 0.0062640385741064165
Trained batch 727 in epoch 9, gen_loss = 1.4922060297576936, disc_loss = 0.0062558855833341
Trained batch 728 in epoch 9, gen_loss = 1.492135993001883, disc_loss = 0.0062477558213413055
Trained batch 729 in epoch 9, gen_loss = 1.4920607752179447, disc_loss = 0.006239627639008351
Trained batch 730 in epoch 9, gen_loss = 1.4919212390394772, disc_loss = 0.006231420840358947
Trained batch 731 in epoch 9, gen_loss = 1.4918662619883898, disc_loss = 0.00622327687007703
Trained batch 732 in epoch 9, gen_loss = 1.4917414177813926, disc_loss = 0.006215154732526918
Trained batch 733 in epoch 9, gen_loss = 1.4916349177626889, disc_loss = 0.0062070284844391215
Trained batch 734 in epoch 9, gen_loss = 1.4916501631542127, disc_loss = 0.006199296657065307
Trained batch 735 in epoch 9, gen_loss = 1.491533172276357, disc_loss = 0.006191336425168312
Trained batch 736 in epoch 9, gen_loss = 1.4914081414486693, disc_loss = 0.006183425010977047
Trained batch 737 in epoch 9, gen_loss = 1.491322799830579, disc_loss = 0.0061754444033455015
Trained batch 738 in epoch 9, gen_loss = 1.4912007651083847, disc_loss = 0.006167378347032374
Trained batch 739 in epoch 9, gen_loss = 1.491104234634219, disc_loss = 0.0061595089444430465
Trained batch 740 in epoch 9, gen_loss = 1.490972606518008, disc_loss = 0.0061516996086731415
Trained batch 741 in epoch 9, gen_loss = 1.49093747982439, disc_loss = 0.006143898872358237
Trained batch 742 in epoch 9, gen_loss = 1.490816787707533, disc_loss = 0.0061359872463566485
Trained batch 743 in epoch 9, gen_loss = 1.4907582846860732, disc_loss = 0.006127885179188114
Trained batch 744 in epoch 9, gen_loss = 1.4906446260893904, disc_loss = 0.006119868312059939
Trained batch 745 in epoch 9, gen_loss = 1.4905028912880465, disc_loss = 0.0061118448239045175
Testing Epoch 9
Training Epoch 10
Trained batch 0 in epoch 10, gen_loss = 1.4297475814819336, disc_loss = 0.0002350077120354399
Trained batch 1 in epoch 10, gen_loss = 1.4147186875343323, disc_loss = 0.00019071698625339195
Trained batch 2 in epoch 10, gen_loss = 1.410650094350179, disc_loss = 0.0001830539113143459
Trained batch 3 in epoch 10, gen_loss = 1.4213536977767944, disc_loss = 0.00017550374468555674
Trained batch 4 in epoch 10, gen_loss = 1.4339461088180543, disc_loss = 0.0001645877055125311
Trained batch 5 in epoch 10, gen_loss = 1.4268412391344707, disc_loss = 0.0001670330238994211
Trained batch 6 in epoch 10, gen_loss = 1.4324371303830827, disc_loss = 0.0001792543168578829
Trained batch 7 in epoch 10, gen_loss = 1.4298289716243744, disc_loss = 0.00017742745694704354
Trained batch 8 in epoch 10, gen_loss = 1.4243635336558025, disc_loss = 0.0001772285452009075
Trained batch 9 in epoch 10, gen_loss = 1.42467257976532, disc_loss = 0.00018171195988543333
Trained batch 10 in epoch 10, gen_loss = 1.426229390231046, disc_loss = 0.00017850252863189036
Trained batch 11 in epoch 10, gen_loss = 1.430948555469513, disc_loss = 0.00017687534515668327
Trained batch 12 in epoch 10, gen_loss = 1.4302354500843928, disc_loss = 0.0001751188023123317
Trained batch 13 in epoch 10, gen_loss = 1.4309509907449995, disc_loss = 0.000175583829072171
Trained batch 14 in epoch 10, gen_loss = 1.4320449352264404, disc_loss = 0.00017055320495273918
Trained batch 15 in epoch 10, gen_loss = 1.4298622235655785, disc_loss = 0.00016755500291765202
Trained batch 16 in epoch 10, gen_loss = 1.4274823946111344, disc_loss = 0.0001636593960403629
Trained batch 17 in epoch 10, gen_loss = 1.4318453735775418, disc_loss = 0.00016369138514467826
Trained batch 18 in epoch 10, gen_loss = 1.4299609535618831, disc_loss = 0.00016277295301398752
Trained batch 19 in epoch 10, gen_loss = 1.4310149431228638, disc_loss = 0.00016735782628529705
Trained batch 20 in epoch 10, gen_loss = 1.4295671667371477, disc_loss = 0.00016455811419291422
Trained batch 21 in epoch 10, gen_loss = 1.4292991107160395, disc_loss = 0.00016238741492005911
Trained batch 22 in epoch 10, gen_loss = 1.4303747104561848, disc_loss = 0.00016044527697174445
Trained batch 23 in epoch 10, gen_loss = 1.4284999817609787, disc_loss = 0.00015971884689254998
Trained batch 24 in epoch 10, gen_loss = 1.4293690061569213, disc_loss = 0.0001616734644630924
Trained batch 25 in epoch 10, gen_loss = 1.428391612493075, disc_loss = 0.00015954614718793891
Trained batch 26 in epoch 10, gen_loss = 1.4248662966269035, disc_loss = 0.00015927051949633837
Trained batch 27 in epoch 10, gen_loss = 1.4254095980099268, disc_loss = 0.00015865601874663428
Trained batch 28 in epoch 10, gen_loss = 1.4278606053056389, disc_loss = 0.00015970767532868697
Trained batch 29 in epoch 10, gen_loss = 1.4267977396647136, disc_loss = 0.00015919843741964238
Trained batch 30 in epoch 10, gen_loss = 1.4275715235740907, disc_loss = 0.00015715258702966235
Trained batch 31 in epoch 10, gen_loss = 1.4282785393297672, disc_loss = 0.0001544478873256594
Trained batch 32 in epoch 10, gen_loss = 1.428450624148051, disc_loss = 0.00015211221365131098
Trained batch 33 in epoch 10, gen_loss = 1.4280046329778784, disc_loss = 0.00015532960798522895
Trained batch 34 in epoch 10, gen_loss = 1.4288019384656634, disc_loss = 0.00016003184511126684
Trained batch 35 in epoch 10, gen_loss = 1.4283946322070227, disc_loss = 0.00016120826209468456
Trained batch 36 in epoch 10, gen_loss = 1.4294598134788308, disc_loss = 0.00016050536194942087
Trained batch 37 in epoch 10, gen_loss = 1.4273109090955634, disc_loss = 0.00016733626666552337
Trained batch 38 in epoch 10, gen_loss = 1.4258004335256724, disc_loss = 0.00016682441361272373
Trained batch 39 in epoch 10, gen_loss = 1.4238832205533982, disc_loss = 0.00016912199425860307
Trained batch 40 in epoch 10, gen_loss = 1.4254620307829322, disc_loss = 0.0001717515022880057
Trained batch 41 in epoch 10, gen_loss = 1.425578466483525, disc_loss = 0.00017172709028402875
Trained batch 42 in epoch 10, gen_loss = 1.4259559221045917, disc_loss = 0.0001697537714620879
Trained batch 43 in epoch 10, gen_loss = 1.4264998490160161, disc_loss = 0.0001699817813377277
Trained batch 44 in epoch 10, gen_loss = 1.4258735868665906, disc_loss = 0.00016879206135248144
Trained batch 45 in epoch 10, gen_loss = 1.4277092373889426, disc_loss = 0.0001688577590950603
Trained batch 46 in epoch 10, gen_loss = 1.4278609701927671, disc_loss = 0.00016912512209989685
Trained batch 47 in epoch 10, gen_loss = 1.4278092607855797, disc_loss = 0.00016930970286921365
Trained batch 48 in epoch 10, gen_loss = 1.4280853003871685, disc_loss = 0.00016799703853950855
Trained batch 49 in epoch 10, gen_loss = 1.4282355308532715, disc_loss = 0.00016625401738565415
Trained batch 50 in epoch 10, gen_loss = 1.4297836481356154, disc_loss = 0.00016527209421231723
Trained batch 51 in epoch 10, gen_loss = 1.429771826817439, disc_loss = 0.00016625008650477795
Trained batch 52 in epoch 10, gen_loss = 1.429893210249127, disc_loss = 0.00016574215685909193
Trained batch 53 in epoch 10, gen_loss = 1.429913094750157, disc_loss = 0.00016714145736100531
Trained batch 54 in epoch 10, gen_loss = 1.4298830357464878, disc_loss = 0.00017188447540816427
Trained batch 55 in epoch 10, gen_loss = 1.4302003937108176, disc_loss = 0.0001741375746340574
Trained batch 56 in epoch 10, gen_loss = 1.430912971496582, disc_loss = 0.00017471429894437294
Trained batch 57 in epoch 10, gen_loss = 1.430044330399612, disc_loss = 0.00017347899496410814
Trained batch 58 in epoch 10, gen_loss = 1.4302742844921048, disc_loss = 0.0001723707016750823
Trained batch 59 in epoch 10, gen_loss = 1.4302551289399466, disc_loss = 0.00017118725712255884
Trained batch 60 in epoch 10, gen_loss = 1.429940305772375, disc_loss = 0.00016997077838197108
Trained batch 61 in epoch 10, gen_loss = 1.428936767962671, disc_loss = 0.00016882840305521723
Trained batch 62 in epoch 10, gen_loss = 1.4282924428818717, disc_loss = 0.00016728704247812165
Trained batch 63 in epoch 10, gen_loss = 1.4286188147962093, disc_loss = 0.0001673253685794407
Trained batch 64 in epoch 10, gen_loss = 1.428177103629479, disc_loss = 0.0001681154292712633
Trained batch 65 in epoch 10, gen_loss = 1.4280846913655598, disc_loss = 0.00016775047598374923
Trained batch 66 in epoch 10, gen_loss = 1.428431582095018, disc_loss = 0.00016688367216361326
Trained batch 67 in epoch 10, gen_loss = 1.4288634237121134, disc_loss = 0.00016634116421782356
Trained batch 68 in epoch 10, gen_loss = 1.4284408956334211, disc_loss = 0.00016540181894779909
Trained batch 69 in epoch 10, gen_loss = 1.4285356657845634, disc_loss = 0.00016797159104109077
Trained batch 70 in epoch 10, gen_loss = 1.4277141144577885, disc_loss = 0.00016940287113497953
Trained batch 71 in epoch 10, gen_loss = 1.4283685270282958, disc_loss = 0.00017086556120678628
Trained batch 72 in epoch 10, gen_loss = 1.4284764136353585, disc_loss = 0.00016956456985933808
Trained batch 73 in epoch 10, gen_loss = 1.4281407514133968, disc_loss = 0.00016895470194081222
Trained batch 74 in epoch 10, gen_loss = 1.4285078048706055, disc_loss = 0.00016869505430804565
Trained batch 75 in epoch 10, gen_loss = 1.4293417350242013, disc_loss = 0.00016875832070103284
Trained batch 76 in epoch 10, gen_loss = 1.4295359818966358, disc_loss = 0.00016787855792563868
Trained batch 77 in epoch 10, gen_loss = 1.429395915606083, disc_loss = 0.00016682637812127956
Trained batch 78 in epoch 10, gen_loss = 1.4294833367383932, disc_loss = 0.00016637256883285186
Trained batch 79 in epoch 10, gen_loss = 1.429190593957901, disc_loss = 0.0001729314903059276
Trained batch 80 in epoch 10, gen_loss = 1.4296738542156455, disc_loss = 0.00017581412023979666
Trained batch 81 in epoch 10, gen_loss = 1.4294692219757452, disc_loss = 0.00017586113102790877
Trained batch 82 in epoch 10, gen_loss = 1.4304637564233986, disc_loss = 0.0001754093463238082
Trained batch 83 in epoch 10, gen_loss = 1.429511030515035, disc_loss = 0.00017693035849896703
Trained batch 84 in epoch 10, gen_loss = 1.4291023478788487, disc_loss = 0.0001762826112954987
Trained batch 85 in epoch 10, gen_loss = 1.4291341803794684, disc_loss = 0.00017712963651933403
Trained batch 86 in epoch 10, gen_loss = 1.429302292308588, disc_loss = 0.00017677103083958077
Trained batch 87 in epoch 10, gen_loss = 1.4292579130692915, disc_loss = 0.00017620724189658756
Trained batch 88 in epoch 10, gen_loss = 1.4293608719043518, disc_loss = 0.0001761339896056393
Trained batch 89 in epoch 10, gen_loss = 1.4288027418984308, disc_loss = 0.00017641445811023004
Trained batch 90 in epoch 10, gen_loss = 1.428857187648396, disc_loss = 0.00017920950631378219
Trained batch 91 in epoch 10, gen_loss = 1.4292852723080178, disc_loss = 0.00017905037645465674
Trained batch 92 in epoch 10, gen_loss = 1.4289635048117688, disc_loss = 0.0001782048414605269
Trained batch 93 in epoch 10, gen_loss = 1.4290965300925234, disc_loss = 0.00017748774514481563
Trained batch 94 in epoch 10, gen_loss = 1.429307618894075, disc_loss = 0.0001764852764225859
Trained batch 95 in epoch 10, gen_loss = 1.4297468264897664, disc_loss = 0.00017530829116670552
Trained batch 96 in epoch 10, gen_loss = 1.430288787969609, disc_loss = 0.00017443293225219395
Trained batch 97 in epoch 10, gen_loss = 1.4308511152559398, disc_loss = 0.00017386266380508089
Trained batch 98 in epoch 10, gen_loss = 1.4307169264013118, disc_loss = 0.00017320696137212876
Trained batch 99 in epoch 10, gen_loss = 1.4310199761390685, disc_loss = 0.00017275060286920052
Trained batch 100 in epoch 10, gen_loss = 1.43165386549317, disc_loss = 0.00017556460338845242
Trained batch 101 in epoch 10, gen_loss = 1.4314879342621447, disc_loss = 0.00017744561024729219
Trained batch 102 in epoch 10, gen_loss = 1.4310583929413732, disc_loss = 0.00017764034461471913
Trained batch 103 in epoch 10, gen_loss = 1.43160991026805, disc_loss = 0.00017681966332579928
Trained batch 104 in epoch 10, gen_loss = 1.4314446528752645, disc_loss = 0.00017663117226523656
Trained batch 105 in epoch 10, gen_loss = 1.4313152185026206, disc_loss = 0.00017792016557716537
Trained batch 106 in epoch 10, gen_loss = 1.4316730644101294, disc_loss = 0.0001792804505044995
Trained batch 107 in epoch 10, gen_loss = 1.4315423689506672, disc_loss = 0.00017932712311179516
Trained batch 108 in epoch 10, gen_loss = 1.4312592712017373, disc_loss = 0.00017852427765252838
Trained batch 109 in epoch 10, gen_loss = 1.4302783185785466, disc_loss = 0.00017743872849678154
Trained batch 110 in epoch 10, gen_loss = 1.4301589007850166, disc_loss = 0.00017659437294282766
Trained batch 111 in epoch 10, gen_loss = 1.4299566554171699, disc_loss = 0.00017602064446821584
Trained batch 112 in epoch 10, gen_loss = 1.4297126362809038, disc_loss = 0.0001757083402030207
Trained batch 113 in epoch 10, gen_loss = 1.4294361911321942, disc_loss = 0.0001756532914314129
Trained batch 114 in epoch 10, gen_loss = 1.4299063402673473, disc_loss = 0.00017549109018190115
Trained batch 115 in epoch 10, gen_loss = 1.4299397622716838, disc_loss = 0.00017523071315297094
Trained batch 116 in epoch 10, gen_loss = 1.430268050258995, disc_loss = 0.0001752997350117339
Trained batch 117 in epoch 10, gen_loss = 1.4305629619097306, disc_loss = 0.00017471044119995018
Trained batch 118 in epoch 10, gen_loss = 1.430789150109812, disc_loss = 0.00017437331550025788
Trained batch 119 in epoch 10, gen_loss = 1.4308255046606064, disc_loss = 0.00017414218173144035
Trained batch 120 in epoch 10, gen_loss = 1.430744451924789, disc_loss = 0.00017395276539119091
Trained batch 121 in epoch 10, gen_loss = 1.4305911113004215, disc_loss = 0.00017395425051976507
Trained batch 122 in epoch 10, gen_loss = 1.4307613857393342, disc_loss = 0.00017389428502633008
Trained batch 123 in epoch 10, gen_loss = 1.4307468620038801, disc_loss = 0.00017340203712299098
Trained batch 124 in epoch 10, gen_loss = 1.43085622882843, disc_loss = 0.00017290881133521908
Trained batch 125 in epoch 10, gen_loss = 1.4309836020545355, disc_loss = 0.00017253529080739504
Trained batch 126 in epoch 10, gen_loss = 1.4310331654360915, disc_loss = 0.00017157283605408202
Trained batch 127 in epoch 10, gen_loss = 1.4314247397705913, disc_loss = 0.00017092964714038317
Trained batch 128 in epoch 10, gen_loss = 1.4317395049472188, disc_loss = 0.00017184725708315553
Trained batch 129 in epoch 10, gen_loss = 1.431727872445033, disc_loss = 0.00017185681393199886
Trained batch 130 in epoch 10, gen_loss = 1.4318328131246203, disc_loss = 0.00017128154836045862
Trained batch 131 in epoch 10, gen_loss = 1.4317878078330646, disc_loss = 0.00017038723005195303
Trained batch 132 in epoch 10, gen_loss = 1.4315225092091954, disc_loss = 0.00016986002414259724
Trained batch 133 in epoch 10, gen_loss = 1.431482571274487, disc_loss = 0.00016907103874011715
Trained batch 134 in epoch 10, gen_loss = 1.4312259550447817, disc_loss = 0.00016820951568661258
Trained batch 135 in epoch 10, gen_loss = 1.4312425869352676, disc_loss = 0.0001674534885430202
Trained batch 136 in epoch 10, gen_loss = 1.4311701694544214, disc_loss = 0.00016763131930849713
Trained batch 137 in epoch 10, gen_loss = 1.4313826491867288, disc_loss = 0.00016720965979165277
Trained batch 138 in epoch 10, gen_loss = 1.4310175540635912, disc_loss = 0.0001665223960948123
Trained batch 139 in epoch 10, gen_loss = 1.4309619435242245, disc_loss = 0.00016582031972315494
Trained batch 140 in epoch 10, gen_loss = 1.4311111311540536, disc_loss = 0.00016489919506327964
Trained batch 141 in epoch 10, gen_loss = 1.4307191548213152, disc_loss = 0.00016421700343977443
Trained batch 142 in epoch 10, gen_loss = 1.4309421669353137, disc_loss = 0.00016397279120922265
Trained batch 143 in epoch 10, gen_loss = 1.4312210463815265, disc_loss = 0.00016361287207978926
Trained batch 144 in epoch 10, gen_loss = 1.4313128323390567, disc_loss = 0.0001629237698517531
Trained batch 145 in epoch 10, gen_loss = 1.4315277338027954, disc_loss = 0.0001625070680135762
Trained batch 146 in epoch 10, gen_loss = 1.4312578058567176, disc_loss = 0.00016215834961146857
Trained batch 147 in epoch 10, gen_loss = 1.4312159692918933, disc_loss = 0.00016232121013033335
Trained batch 148 in epoch 10, gen_loss = 1.4313403135978136, disc_loss = 0.00016287277277731712
Trained batch 149 in epoch 10, gen_loss = 1.431376996835073, disc_loss = 0.00016363333137026833
Trained batch 150 in epoch 10, gen_loss = 1.4315114605505734, disc_loss = 0.0001650458143799279
Trained batch 151 in epoch 10, gen_loss = 1.4315680908529382, disc_loss = 0.00016610199870563904
Trained batch 152 in epoch 10, gen_loss = 1.4312889342214548, disc_loss = 0.0001659502064951108
Trained batch 153 in epoch 10, gen_loss = 1.4307332828447417, disc_loss = 0.00016547586202758286
Trained batch 154 in epoch 10, gen_loss = 1.4304869144193588, disc_loss = 0.0001650366568121113
Trained batch 155 in epoch 10, gen_loss = 1.430430850157371, disc_loss = 0.0001643984309199508
Trained batch 156 in epoch 10, gen_loss = 1.4304709928050923, disc_loss = 0.00016375211746247253
Trained batch 157 in epoch 10, gen_loss = 1.4305959019479872, disc_loss = 0.00016314463198197494
Trained batch 158 in epoch 10, gen_loss = 1.43087296965737, disc_loss = 0.0001625742069959901
Trained batch 159 in epoch 10, gen_loss = 1.43075001090765, disc_loss = 0.00016189285347536497
Trained batch 160 in epoch 10, gen_loss = 1.430610445715626, disc_loss = 0.00016133752358666627
Trained batch 161 in epoch 10, gen_loss = 1.4307124224709875, disc_loss = 0.00016123054121163914
Trained batch 162 in epoch 10, gen_loss = 1.4302855408264816, disc_loss = 0.00016194913224559963
Trained batch 163 in epoch 10, gen_loss = 1.429911569124315, disc_loss = 0.00016176854283335936
Trained batch 164 in epoch 10, gen_loss = 1.4298836541898323, disc_loss = 0.00016192886713807555
Trained batch 165 in epoch 10, gen_loss = 1.429717426558575, disc_loss = 0.00016186601083994988
Trained batch 166 in epoch 10, gen_loss = 1.4295719833431129, disc_loss = 0.00016212424916538695
Trained batch 167 in epoch 10, gen_loss = 1.4294581959644954, disc_loss = 0.00016273411823758145
Trained batch 168 in epoch 10, gen_loss = 1.42930140650484, disc_loss = 0.00016356954821550768
Trained batch 169 in epoch 10, gen_loss = 1.429365970807917, disc_loss = 0.00016386830504737138
Trained batch 170 in epoch 10, gen_loss = 1.4291773811418411, disc_loss = 0.00016413906154124752
Trained batch 171 in epoch 10, gen_loss = 1.428871122903602, disc_loss = 0.0001640954309719788
Trained batch 172 in epoch 10, gen_loss = 1.4293361826439124, disc_loss = 0.00016352153021332168
Trained batch 173 in epoch 10, gen_loss = 1.4290309116758149, disc_loss = 0.0001629292133218079
Trained batch 174 in epoch 10, gen_loss = 1.4288681289127896, disc_loss = 0.00016276036883937196
Trained batch 175 in epoch 10, gen_loss = 1.4290132007815621, disc_loss = 0.00016244225757459802
Trained batch 176 in epoch 10, gen_loss = 1.4288466427959292, disc_loss = 0.0001619561900674776
Trained batch 177 in epoch 10, gen_loss = 1.4289270003190202, disc_loss = 0.00016138084605843054
Trained batch 178 in epoch 10, gen_loss = 1.4289352807252766, disc_loss = 0.00016070546386581352
Trained batch 179 in epoch 10, gen_loss = 1.4289322680897183, disc_loss = 0.0001605619459749303
Trained batch 180 in epoch 10, gen_loss = 1.4290637429906519, disc_loss = 0.0001601597323315218
Trained batch 181 in epoch 10, gen_loss = 1.4289903529397734, disc_loss = 0.00015980461402860174
Trained batch 182 in epoch 10, gen_loss = 1.428853716355204, disc_loss = 0.00015933091523694486
Trained batch 183 in epoch 10, gen_loss = 1.4291541641173156, disc_loss = 0.0001589696779695299
Trained batch 184 in epoch 10, gen_loss = 1.4294180670300045, disc_loss = 0.0001588967362909603
Trained batch 185 in epoch 10, gen_loss = 1.429837155726648, disc_loss = 0.00015858744330715478
Trained batch 186 in epoch 10, gen_loss = 1.4299628791962078, disc_loss = 0.00015815943100565627
Trained batch 187 in epoch 10, gen_loss = 1.430127890186107, disc_loss = 0.00015762684783344702
Trained batch 188 in epoch 10, gen_loss = 1.4300361739264593, disc_loss = 0.00015713640136204453
Trained batch 189 in epoch 10, gen_loss = 1.4299284106806704, disc_loss = 0.00015656372197554448
Trained batch 190 in epoch 10, gen_loss = 1.4298971928851143, disc_loss = 0.00015607063977153855
Trained batch 191 in epoch 10, gen_loss = 1.4295082601408164, disc_loss = 0.00015549658610325423
Trained batch 192 in epoch 10, gen_loss = 1.4294730659593573, disc_loss = 0.0001550766428597175
Trained batch 193 in epoch 10, gen_loss = 1.4293639223600172, disc_loss = 0.00015464439781409084
Trained batch 194 in epoch 10, gen_loss = 1.4292242215229916, disc_loss = 0.00015447995168730043
Trained batch 195 in epoch 10, gen_loss = 1.4295711188900226, disc_loss = 0.00015399519190618683
Trained batch 196 in epoch 10, gen_loss = 1.4294855479661583, disc_loss = 0.0001535309447394566
Trained batch 197 in epoch 10, gen_loss = 1.429817744577774, disc_loss = 0.00015316732731092758
Trained batch 198 in epoch 10, gen_loss = 1.4295397002493317, disc_loss = 0.00015285035986371394
Trained batch 199 in epoch 10, gen_loss = 1.429520898461342, disc_loss = 0.00015238528420013608
Trained batch 200 in epoch 10, gen_loss = 1.4291361321264238, disc_loss = 0.0001519557881873884
Trained batch 201 in epoch 10, gen_loss = 1.4292526109383838, disc_loss = 0.00015156586499023711
Trained batch 202 in epoch 10, gen_loss = 1.4296415715382016, disc_loss = 0.00015113467447089234
Trained batch 203 in epoch 10, gen_loss = 1.4296650413204641, disc_loss = 0.0001506409597841055
Trained batch 204 in epoch 10, gen_loss = 1.4295346620606213, disc_loss = 0.00015023976394753312
Trained batch 205 in epoch 10, gen_loss = 1.4296655562317486, disc_loss = 0.00014994663175916552
Trained batch 206 in epoch 10, gen_loss = 1.430113843097779, disc_loss = 0.00014970084206748907
Trained batch 207 in epoch 10, gen_loss = 1.4298412731060615, disc_loss = 0.00014936393878227906
Trained batch 208 in epoch 10, gen_loss = 1.4294738119298762, disc_loss = 0.00014917514893798934
Trained batch 209 in epoch 10, gen_loss = 1.4294849520637876, disc_loss = 0.000148966131729096
Trained batch 210 in epoch 10, gen_loss = 1.4293914485316705, disc_loss = 0.000149009905640208
Trained batch 211 in epoch 10, gen_loss = 1.4293785477584262, disc_loss = 0.00014880196153480596
Trained batch 212 in epoch 10, gen_loss = 1.4294028170231923, disc_loss = 0.00014876242890459935
Trained batch 213 in epoch 10, gen_loss = 1.4294708231899227, disc_loss = 0.00014866321270406315
Trained batch 214 in epoch 10, gen_loss = 1.4295324053875236, disc_loss = 0.00014844283452771908
Trained batch 215 in epoch 10, gen_loss = 1.429417673084471, disc_loss = 0.00014811932487646118
Trained batch 216 in epoch 10, gen_loss = 1.4294711889759186, disc_loss = 0.00014817473558550228
Trained batch 217 in epoch 10, gen_loss = 1.4294474157718344, disc_loss = 0.0001477951061358641
Trained batch 218 in epoch 10, gen_loss = 1.4294211695727692, disc_loss = 0.00014731989429982436
Trained batch 219 in epoch 10, gen_loss = 1.429306794838472, disc_loss = 0.0001468691505082957
Trained batch 220 in epoch 10, gen_loss = 1.4295884586567253, disc_loss = 0.00014683301084845042
Trained batch 221 in epoch 10, gen_loss = 1.4299007949528393, disc_loss = 0.00014661991403258284
Trained batch 222 in epoch 10, gen_loss = 1.4300967080710714, disc_loss = 0.00014753065603764857
Trained batch 223 in epoch 10, gen_loss = 1.4300946822123868, disc_loss = 0.00014774833661184466
Trained batch 224 in epoch 10, gen_loss = 1.429888293478224, disc_loss = 0.00014768391694006924
Trained batch 225 in epoch 10, gen_loss = 1.429789200820754, disc_loss = 0.00014745466912639702
Trained batch 226 in epoch 10, gen_loss = 1.429662784815885, disc_loss = 0.00014705784393011362
Trained batch 227 in epoch 10, gen_loss = 1.4297614824353604, disc_loss = 0.00014671776856981493
Trained batch 228 in epoch 10, gen_loss = 1.429409547143628, disc_loss = 0.00014639691699499074
Trained batch 229 in epoch 10, gen_loss = 1.429352641623953, disc_loss = 0.00014607095646446713
Trained batch 230 in epoch 10, gen_loss = 1.429333825648089, disc_loss = 0.00014570395976445613
Trained batch 231 in epoch 10, gen_loss = 1.4293695816705967, disc_loss = 0.00014526722546587075
Trained batch 232 in epoch 10, gen_loss = 1.4295643936410993, disc_loss = 0.0001448869677314229
Trained batch 233 in epoch 10, gen_loss = 1.4297053228076706, disc_loss = 0.00014448809786264398
Trained batch 234 in epoch 10, gen_loss = 1.4295185175347835, disc_loss = 0.00014443622527091684
Trained batch 235 in epoch 10, gen_loss = 1.4297199991800018, disc_loss = 0.00014439657994536623
Trained batch 236 in epoch 10, gen_loss = 1.4296376614630977, disc_loss = 0.0001442175559037147
Trained batch 237 in epoch 10, gen_loss = 1.4298495830608016, disc_loss = 0.00014416237595966065
Trained batch 238 in epoch 10, gen_loss = 1.4299766498629518, disc_loss = 0.00014448499593629977
Trained batch 239 in epoch 10, gen_loss = 1.4300115178028743, disc_loss = 0.0001445894505953523
Trained batch 240 in epoch 10, gen_loss = 1.4301518790454786, disc_loss = 0.00014453884770577343
Trained batch 241 in epoch 10, gen_loss = 1.430036361552467, disc_loss = 0.00014485471446511108
Trained batch 242 in epoch 10, gen_loss = 1.429726816008611, disc_loss = 0.00014497597867787294
Trained batch 243 in epoch 10, gen_loss = 1.430081773488248, disc_loss = 0.00014500626130924143
Trained batch 244 in epoch 10, gen_loss = 1.4299766511333232, disc_loss = 0.00014482976642154555
Trained batch 245 in epoch 10, gen_loss = 1.4296312099549828, disc_loss = 0.000144664044847463
Trained batch 246 in epoch 10, gen_loss = 1.4295409135972923, disc_loss = 0.0001445919712459874
Trained batch 247 in epoch 10, gen_loss = 1.4296710486373594, disc_loss = 0.00014423341341288535
Trained batch 248 in epoch 10, gen_loss = 1.4297926167407669, disc_loss = 0.00014391124220920285
Trained batch 249 in epoch 10, gen_loss = 1.429796799182892, disc_loss = 0.0001435849205008708
Trained batch 250 in epoch 10, gen_loss = 1.429938183837678, disc_loss = 0.00014325027639070428
Trained batch 251 in epoch 10, gen_loss = 1.4295263777649592, disc_loss = 0.00014290850648403792
Trained batch 252 in epoch 10, gen_loss = 1.4291056875183648, disc_loss = 0.00014259379067269094
Trained batch 253 in epoch 10, gen_loss = 1.4289827262322734, disc_loss = 0.00014230218405964122
Trained batch 254 in epoch 10, gen_loss = 1.4291045661066093, disc_loss = 0.00014209300186884518
Trained batch 255 in epoch 10, gen_loss = 1.429035954643041, disc_loss = 0.00014184335633160572
Trained batch 256 in epoch 10, gen_loss = 1.4291807436293664, disc_loss = 0.00014159185140620616
Trained batch 257 in epoch 10, gen_loss = 1.4293304635572803, disc_loss = 0.00014128522837050385
Trained batch 258 in epoch 10, gen_loss = 1.4289950413133188, disc_loss = 0.00014102594186940669
Trained batch 259 in epoch 10, gen_loss = 1.4289657060916607, disc_loss = 0.00014072397404491383
Trained batch 260 in epoch 10, gen_loss = 1.4287163864150358, disc_loss = 0.00014046760192272517
Trained batch 261 in epoch 10, gen_loss = 1.4287049206158586, disc_loss = 0.00014020676639023012
Trained batch 262 in epoch 10, gen_loss = 1.4287779467187454, disc_loss = 0.00013997534486877256
Trained batch 263 in epoch 10, gen_loss = 1.428609012202783, disc_loss = 0.00013964506014775853
Trained batch 264 in epoch 10, gen_loss = 1.4286079379747498, disc_loss = 0.00013935048457670008
Trained batch 265 in epoch 10, gen_loss = 1.4283021930465125, disc_loss = 0.00013908950905832006
Trained batch 266 in epoch 10, gen_loss = 1.4284131964494227, disc_loss = 0.0001388820058715003
Trained batch 267 in epoch 10, gen_loss = 1.428162648606656, disc_loss = 0.00013883738889734247
Trained batch 268 in epoch 10, gen_loss = 1.4280996074463799, disc_loss = 0.00013904352782754623
Trained batch 269 in epoch 10, gen_loss = 1.4283267303749367, disc_loss = 0.00013920762780967547
Trained batch 270 in epoch 10, gen_loss = 1.428347879670203, disc_loss = 0.00013903902527426002
Trained batch 271 in epoch 10, gen_loss = 1.4282839245655958, disc_loss = 0.00013896522953954818
Trained batch 272 in epoch 10, gen_loss = 1.4282898636527988, disc_loss = 0.00013893510287157652
Trained batch 273 in epoch 10, gen_loss = 1.4285176883648782, disc_loss = 0.00013867922562848349
Trained batch 274 in epoch 10, gen_loss = 1.4287304362383755, disc_loss = 0.00013845984305424445
Trained batch 275 in epoch 10, gen_loss = 1.428451932426812, disc_loss = 0.00013833986051157927
Trained batch 276 in epoch 10, gen_loss = 1.4285038911908972, disc_loss = 0.00013814372352945588
Trained batch 277 in epoch 10, gen_loss = 1.4285461237962298, disc_loss = 0.00013785127034451035
Trained batch 278 in epoch 10, gen_loss = 1.428716743718766, disc_loss = 0.00013758389005524282
Trained batch 279 in epoch 10, gen_loss = 1.4286807515791484, disc_loss = 0.00013722383183838765
Trained batch 280 in epoch 10, gen_loss = 1.4289420792216507, disc_loss = 0.00013687510841252246
Trained batch 281 in epoch 10, gen_loss = 1.4289415504070038, disc_loss = 0.0001366073427316675
Trained batch 282 in epoch 10, gen_loss = 1.4288898807532375, disc_loss = 0.00013625867622752276
Trained batch 283 in epoch 10, gen_loss = 1.4293406433622602, disc_loss = 0.0001359425963220903
Trained batch 284 in epoch 10, gen_loss = 1.429380965232849, disc_loss = 0.00013564707214276208
Trained batch 285 in epoch 10, gen_loss = 1.4294743225291058, disc_loss = 0.0001354240256869861
Trained batch 286 in epoch 10, gen_loss = 1.4293982525735782, disc_loss = 0.00013515916332784627
Trained batch 287 in epoch 10, gen_loss = 1.4293510255714257, disc_loss = 0.00013484597191866973
Trained batch 288 in epoch 10, gen_loss = 1.4291301458352166, disc_loss = 0.000134575742720441
Trained batch 289 in epoch 10, gen_loss = 1.428865290099177, disc_loss = 0.0001343135973629301
Trained batch 290 in epoch 10, gen_loss = 1.4290124231187749, disc_loss = 0.00013411749037113872
Trained batch 291 in epoch 10, gen_loss = 1.429042439346444, disc_loss = 0.0001339079153694911
Trained batch 292 in epoch 10, gen_loss = 1.429286603227817, disc_loss = 0.00013395070158236792
Trained batch 293 in epoch 10, gen_loss = 1.4293288049243746, disc_loss = 0.0001339207786809713
Trained batch 294 in epoch 10, gen_loss = 1.429173183441162, disc_loss = 0.00013386668130297655
Trained batch 295 in epoch 10, gen_loss = 1.4292928185817357, disc_loss = 0.0001336360997270645
Trained batch 296 in epoch 10, gen_loss = 1.4295935771280668, disc_loss = 0.00013339732764684674
Trained batch 297 in epoch 10, gen_loss = 1.4296155811956264, disc_loss = 0.00013319970877769235
Trained batch 298 in epoch 10, gen_loss = 1.42958147190885, disc_loss = 0.00013308006873253864
Trained batch 299 in epoch 10, gen_loss = 1.4293511231740317, disc_loss = 0.00013311156166309957
Trained batch 300 in epoch 10, gen_loss = 1.4292863837112224, disc_loss = 0.00013322062817757233
Trained batch 301 in epoch 10, gen_loss = 1.4293541746423735, disc_loss = 0.00013348175921929932
Trained batch 302 in epoch 10, gen_loss = 1.429349167118765, disc_loss = 0.0001335896172634904
Trained batch 303 in epoch 10, gen_loss = 1.4293350675388385, disc_loss = 0.0001337856416811471
Trained batch 304 in epoch 10, gen_loss = 1.4291709098659577, disc_loss = 0.00013388166894475915
Trained batch 305 in epoch 10, gen_loss = 1.429388623222027, disc_loss = 0.00013392252633648657
Trained batch 306 in epoch 10, gen_loss = 1.4292541905412457, disc_loss = 0.0001340010312678981
Trained batch 307 in epoch 10, gen_loss = 1.429362052833879, disc_loss = 0.00013432483685935407
Trained batch 308 in epoch 10, gen_loss = 1.4293767792507284, disc_loss = 0.00013430953038721512
Trained batch 309 in epoch 10, gen_loss = 1.4292124371374808, disc_loss = 0.0001341667461665272
Trained batch 310 in epoch 10, gen_loss = 1.4292297930579476, disc_loss = 0.00013388498592017506
Trained batch 311 in epoch 10, gen_loss = 1.4291161741965857, disc_loss = 0.00013374309471076302
Trained batch 312 in epoch 10, gen_loss = 1.428930857691902, disc_loss = 0.00013364398921821295
Trained batch 313 in epoch 10, gen_loss = 1.429113975755728, disc_loss = 0.00013345246446362673
Trained batch 314 in epoch 10, gen_loss = 1.429189822030446, disc_loss = 0.00013317728257139345
Trained batch 315 in epoch 10, gen_loss = 1.4291374249548852, disc_loss = 0.00013288775438853964
Trained batch 316 in epoch 10, gen_loss = 1.4288676777848686, disc_loss = 0.0001326879227399159
Trained batch 317 in epoch 10, gen_loss = 1.428955818872032, disc_loss = 0.0001324723016067244
Trained batch 318 in epoch 10, gen_loss = 1.429152627350021, disc_loss = 0.00013228262102977318
Trained batch 319 in epoch 10, gen_loss = 1.4291432254016398, disc_loss = 0.00013213529618951724
Trained batch 320 in epoch 10, gen_loss = 1.429218151116297, disc_loss = 0.0001318516493098581
Trained batch 321 in epoch 10, gen_loss = 1.4291451177241639, disc_loss = 0.00013158812045889056
Trained batch 322 in epoch 10, gen_loss = 1.4292938879030777, disc_loss = 0.00013144756656052867
Trained batch 323 in epoch 10, gen_loss = 1.4293651602886341, disc_loss = 0.00013133881827938533
Trained batch 324 in epoch 10, gen_loss = 1.4292386964651254, disc_loss = 0.0001312072577778823
Trained batch 325 in epoch 10, gen_loss = 1.4293973647012301, disc_loss = 0.00013103570058021233
Trained batch 326 in epoch 10, gen_loss = 1.4296174497779357, disc_loss = 0.00013090016956982952
Trained batch 327 in epoch 10, gen_loss = 1.4297173641076901, disc_loss = 0.00013075260544499588
Trained batch 328 in epoch 10, gen_loss = 1.4295925231690103, disc_loss = 0.00013052096203734566
Trained batch 329 in epoch 10, gen_loss = 1.429745860894521, disc_loss = 0.00013030253218003604
Trained batch 330 in epoch 10, gen_loss = 1.4297869072219755, disc_loss = 0.0001302101056760084
Trained batch 331 in epoch 10, gen_loss = 1.4297943291175796, disc_loss = 0.00012995046887796438
Trained batch 332 in epoch 10, gen_loss = 1.4298421985752232, disc_loss = 0.00012972224585036538
Trained batch 333 in epoch 10, gen_loss = 1.4297899047057785, disc_loss = 0.00012954970222931288
Trained batch 334 in epoch 10, gen_loss = 1.429899047737691, disc_loss = 0.00012963588098446324
Trained batch 335 in epoch 10, gen_loss = 1.4300387998421986, disc_loss = 0.00012959680645421723
Trained batch 336 in epoch 10, gen_loss = 1.4300648147345296, disc_loss = 0.00012944162937602476
Trained batch 337 in epoch 10, gen_loss = 1.4301815837092653, disc_loss = 0.00012920501266033374
Trained batch 338 in epoch 10, gen_loss = 1.430079552979596, disc_loss = 0.00012897634962245693
Trained batch 339 in epoch 10, gen_loss = 1.430025848570992, disc_loss = 0.00012878888993488063
Trained batch 340 in epoch 10, gen_loss = 1.4300024187809561, disc_loss = 0.00012865708439972434
Trained batch 341 in epoch 10, gen_loss = 1.4301193659765679, disc_loss = 0.00012855630804594316
Trained batch 342 in epoch 10, gen_loss = 1.4299981399458281, disc_loss = 0.00012847096039620012
Trained batch 343 in epoch 10, gen_loss = 1.4301165463619454, disc_loss = 0.00012835817515647355
Trained batch 344 in epoch 10, gen_loss = 1.4302988166394441, disc_loss = 0.0001281799540278819
Trained batch 345 in epoch 10, gen_loss = 1.4302427975428587, disc_loss = 0.00012793909862884482
Trained batch 346 in epoch 10, gen_loss = 1.4301679587845157, disc_loss = 0.0001276774920797598
Trained batch 347 in epoch 10, gen_loss = 1.4302607106751408, disc_loss = 0.00012742855656613065
Trained batch 348 in epoch 10, gen_loss = 1.430092574873763, disc_loss = 0.0001274986699566093
Trained batch 349 in epoch 10, gen_loss = 1.4301489135197232, disc_loss = 0.0001274427548300342
Trained batch 350 in epoch 10, gen_loss = 1.4303055006554324, disc_loss = 0.00012730570398340735
Trained batch 351 in epoch 10, gen_loss = 1.4303646399216219, disc_loss = 0.00012710128957719874
Trained batch 352 in epoch 10, gen_loss = 1.4301779121582636, disc_loss = 0.00012689943977093414
Trained batch 353 in epoch 10, gen_loss = 1.4301390624315726, disc_loss = 0.00012675861477878835
Trained batch 354 in epoch 10, gen_loss = 1.430197789299656, disc_loss = 0.0001266686525974672
Trained batch 355 in epoch 10, gen_loss = 1.4300122364853205, disc_loss = 0.00012651237974229814
Trained batch 356 in epoch 10, gen_loss = 1.4298894074784607, disc_loss = 0.00012636304460351776
Trained batch 357 in epoch 10, gen_loss = 1.4299827531063356, disc_loss = 0.0001261866425351674
Trained batch 358 in epoch 10, gen_loss = 1.4300467307189049, disc_loss = 0.00012600393186765657
Trained batch 359 in epoch 10, gen_loss = 1.42985736893283, disc_loss = 0.00012587099776687358
Trained batch 360 in epoch 10, gen_loss = 1.4297580487840393, disc_loss = 0.0001257812317139585
Trained batch 361 in epoch 10, gen_loss = 1.429597385021863, disc_loss = 0.00012569414170006114
Trained batch 362 in epoch 10, gen_loss = 1.4297520891037196, disc_loss = 0.00012547056942598667
Trained batch 363 in epoch 10, gen_loss = 1.4298659504114926, disc_loss = 0.0001253169777235918
Trained batch 364 in epoch 10, gen_loss = 1.4299961194600144, disc_loss = 0.0001251555757883343
Trained batch 365 in epoch 10, gen_loss = 1.4298817547944074, disc_loss = 0.00012512611477281783
Trained batch 366 in epoch 10, gen_loss = 1.42971868768375, disc_loss = 0.00012496484084743487
Trained batch 367 in epoch 10, gen_loss = 1.429798698619656, disc_loss = 0.00012482423628922413
Trained batch 368 in epoch 10, gen_loss = 1.429970413042601, disc_loss = 0.00012476871804301728
Trained batch 369 in epoch 10, gen_loss = 1.4298429308710872, disc_loss = 0.00012465656403258657
Trained batch 370 in epoch 10, gen_loss = 1.4299151621096218, disc_loss = 0.00012449269639188486
Trained batch 371 in epoch 10, gen_loss = 1.4298299573441988, disc_loss = 0.00012455654307824037
Trained batch 372 in epoch 10, gen_loss = 1.4298379318963426, disc_loss = 0.00012459232313762888
Trained batch 373 in epoch 10, gen_loss = 1.4299910559373743, disc_loss = 0.0001246174607054115
Trained batch 374 in epoch 10, gen_loss = 1.4301401627858479, disc_loss = 0.00012458283282467165
Trained batch 375 in epoch 10, gen_loss = 1.4302980126218592, disc_loss = 0.00012449122174230262
Trained batch 376 in epoch 10, gen_loss = 1.4302785168908319, disc_loss = 0.00012435068325835914
Trained batch 377 in epoch 10, gen_loss = 1.4302817684002023, disc_loss = 0.00012415982682940677
Trained batch 378 in epoch 10, gen_loss = 1.430232842553574, disc_loss = 0.0001239639145643438
Trained batch 379 in epoch 10, gen_loss = 1.4303824126720428, disc_loss = 0.00012372279380590617
Trained batch 380 in epoch 10, gen_loss = 1.4302831775560154, disc_loss = 0.000123500866809184
Trained batch 381 in epoch 10, gen_loss = 1.4303359180220758, disc_loss = 0.00012323905941410843
Trained batch 382 in epoch 10, gen_loss = 1.430514878454781, disc_loss = 0.00012300500248943477
Trained batch 383 in epoch 10, gen_loss = 1.4305530898272991, disc_loss = 0.0001227901723315957
Trained batch 384 in epoch 10, gen_loss = 1.4304106960048923, disc_loss = 0.00012262137715879362
Trained batch 385 in epoch 10, gen_loss = 1.4304894428179054, disc_loss = 0.0001224887480487226
Trained batch 386 in epoch 10, gen_loss = 1.4305517094387872, disc_loss = 0.00012232861066388553
Trained batch 387 in epoch 10, gen_loss = 1.4306680812049157, disc_loss = 0.00012211174792064788
Trained batch 388 in epoch 10, gen_loss = 1.4305835450523003, disc_loss = 0.00012187821214802708
Trained batch 389 in epoch 10, gen_loss = 1.4306276419223882, disc_loss = 0.00012165406026794628
Trained batch 390 in epoch 10, gen_loss = 1.430644115218726, disc_loss = 0.00012144897019469312
Trained batch 391 in epoch 10, gen_loss = 1.430726085998574, disc_loss = 0.00012126941111759783
Trained batch 392 in epoch 10, gen_loss = 1.4307208965146208, disc_loss = 0.00012106216504677991
Trained batch 393 in epoch 10, gen_loss = 1.430901401841701, disc_loss = 0.0001208327774588609
Trained batch 394 in epoch 10, gen_loss = 1.4309898125974438, disc_loss = 0.00012059985722460832
Trained batch 395 in epoch 10, gen_loss = 1.4311004913214482, disc_loss = 0.0001203920022945944
Trained batch 396 in epoch 10, gen_loss = 1.4310849067245983, disc_loss = 0.00012014497642621447
Trained batch 397 in epoch 10, gen_loss = 1.4312073872916062, disc_loss = 0.0001199351308466463
Trained batch 398 in epoch 10, gen_loss = 1.4312169710197544, disc_loss = 0.0001197180944037703
Trained batch 399 in epoch 10, gen_loss = 1.4310880354046822, disc_loss = 0.0001195893209114729
Trained batch 400 in epoch 10, gen_loss = 1.431107235965586, disc_loss = 0.00011958281262885161
Trained batch 401 in epoch 10, gen_loss = 1.4311068301177143, disc_loss = 0.00011952027007870825
Trained batch 402 in epoch 10, gen_loss = 1.4310914798646648, disc_loss = 0.00011933378501311083
Trained batch 403 in epoch 10, gen_loss = 1.4310210845848121, disc_loss = 0.00011915499147440948
Trained batch 404 in epoch 10, gen_loss = 1.4309135398747008, disc_loss = 0.00011909160120585175
Trained batch 405 in epoch 10, gen_loss = 1.430957726657097, disc_loss = 0.00011922858653732304
Trained batch 406 in epoch 10, gen_loss = 1.430837396907572, disc_loss = 0.00011921949173050363
Trained batch 407 in epoch 10, gen_loss = 1.4309788544972737, disc_loss = 0.00011907405035469542
Trained batch 408 in epoch 10, gen_loss = 1.4310547401969183, disc_loss = 0.00011889085312970814
Trained batch 409 in epoch 10, gen_loss = 1.4311231392185861, disc_loss = 0.00011873376796557284
Trained batch 410 in epoch 10, gen_loss = 1.4309665391044895, disc_loss = 0.00011866585513651359
Trained batch 411 in epoch 10, gen_loss = 1.4309777446742196, disc_loss = 0.0001187033403236888
Trained batch 412 in epoch 10, gen_loss = 1.430905626414763, disc_loss = 0.00011870063960682724
Trained batch 413 in epoch 10, gen_loss = 1.4309631030340701, disc_loss = 0.00011860450417705157
Trained batch 414 in epoch 10, gen_loss = 1.4310524972088365, disc_loss = 0.00011849132280043573
Trained batch 415 in epoch 10, gen_loss = 1.4312667605968623, disc_loss = 0.00011832375351926972
Trained batch 416 in epoch 10, gen_loss = 1.4312109695635826, disc_loss = 0.00011813354486206209
Trained batch 417 in epoch 10, gen_loss = 1.431353791763908, disc_loss = 0.00011795801112654453
Trained batch 418 in epoch 10, gen_loss = 1.4313560758399508, disc_loss = 0.00011782774806668902
Trained batch 419 in epoch 10, gen_loss = 1.4312160693463825, disc_loss = 0.00011772684663897269
Trained batch 420 in epoch 10, gen_loss = 1.431189213399366, disc_loss = 0.00011762292972559025
Trained batch 421 in epoch 10, gen_loss = 1.431015983577023, disc_loss = 0.00011752103055359451
Trained batch 422 in epoch 10, gen_loss = 1.4308102446526783, disc_loss = 0.0001173311672184449
Trained batch 423 in epoch 10, gen_loss = 1.430721768511916, disc_loss = 0.00011719918569175413
Trained batch 424 in epoch 10, gen_loss = 1.430672677264494, disc_loss = 0.00011714952949927572
Trained batch 425 in epoch 10, gen_loss = 1.43066813968157, disc_loss = 0.00011722126769605901
Trained batch 426 in epoch 10, gen_loss = 1.4307112663076968, disc_loss = 0.00011734444239346934
Trained batch 427 in epoch 10, gen_loss = 1.4308916550373363, disc_loss = 0.0001173249983596485
Trained batch 428 in epoch 10, gen_loss = 1.4306463086521708, disc_loss = 0.00011728110472931655
Trained batch 429 in epoch 10, gen_loss = 1.4306325579798498, disc_loss = 0.00011719848725776903
Trained batch 430 in epoch 10, gen_loss = 1.4304416395395372, disc_loss = 0.00011707292257223641
Trained batch 431 in epoch 10, gen_loss = 1.4304126583867602, disc_loss = 0.00011698104348127984
Trained batch 432 in epoch 10, gen_loss = 1.4303977156346168, disc_loss = 0.00011680675865930406
Trained batch 433 in epoch 10, gen_loss = 1.4302662306117573, disc_loss = 0.00011664581363580794
Trained batch 434 in epoch 10, gen_loss = 1.4301879027794147, disc_loss = 0.0001164943582629892
Trained batch 435 in epoch 10, gen_loss = 1.4303279081615834, disc_loss = 0.00011635236800546809
Trained batch 436 in epoch 10, gen_loss = 1.430359975969764, disc_loss = 0.0001162267243103348
Trained batch 437 in epoch 10, gen_loss = 1.430332334346423, disc_loss = 0.00011612805615622576
Trained batch 438 in epoch 10, gen_loss = 1.4301476823441803, disc_loss = 0.00011602038669278993
Trained batch 439 in epoch 10, gen_loss = 1.4302989282391287, disc_loss = 0.00011593843982237476
Trained batch 440 in epoch 10, gen_loss = 1.4304167870220954, disc_loss = 0.00011579461694434242
Trained batch 441 in epoch 10, gen_loss = 1.4303326965457175, disc_loss = 0.00011568062715071709
Trained batch 442 in epoch 10, gen_loss = 1.430199289698633, disc_loss = 0.00011558701703968745
Trained batch 443 in epoch 10, gen_loss = 1.4301240731466998, disc_loss = 0.00011546982273717436
Trained batch 444 in epoch 10, gen_loss = 1.4301574741856435, disc_loss = 0.00011538114508920024
Trained batch 445 in epoch 10, gen_loss = 1.4301727879207764, disc_loss = 0.00011535336899324718
Trained batch 446 in epoch 10, gen_loss = 1.430228607499893, disc_loss = 0.0001154011688393101
Trained batch 447 in epoch 10, gen_loss = 1.4300760868936777, disc_loss = 0.00011535324061437027
Trained batch 448 in epoch 10, gen_loss = 1.4302668008613162, disc_loss = 0.0001153961900789664
Trained batch 449 in epoch 10, gen_loss = 1.4303438358836704, disc_loss = 0.00011534596822457388
Trained batch 450 in epoch 10, gen_loss = 1.4302093813530357, disc_loss = 0.0001152817818696018
Trained batch 451 in epoch 10, gen_loss = 1.4300680302940638, disc_loss = 0.00011540016534674369
Trained batch 452 in epoch 10, gen_loss = 1.4301576267015066, disc_loss = 0.00011527527840973791
Trained batch 453 in epoch 10, gen_loss = 1.4301585825529393, disc_loss = 0.00011522293791716195
Trained batch 454 in epoch 10, gen_loss = 1.4301352862473373, disc_loss = 0.00011514751492471147
Trained batch 455 in epoch 10, gen_loss = 1.4301346511694424, disc_loss = 0.00011511568679149302
Trained batch 456 in epoch 10, gen_loss = 1.4302177369203297, disc_loss = 0.00011507246902787444
Trained batch 457 in epoch 10, gen_loss = 1.4301406928545524, disc_loss = 0.00011498463289362559
Trained batch 458 in epoch 10, gen_loss = 1.429908626739236, disc_loss = 0.00011491773370330015
Trained batch 459 in epoch 10, gen_loss = 1.429924988746643, disc_loss = 0.00011480347015015507
Trained batch 460 in epoch 10, gen_loss = 1.429800194411371, disc_loss = 0.00011470463779082455
Trained batch 461 in epoch 10, gen_loss = 1.4299617221345118, disc_loss = 0.00011464738677067075
Trained batch 462 in epoch 10, gen_loss = 1.42999398270642, disc_loss = 0.00011465605015980359
Trained batch 463 in epoch 10, gen_loss = 1.430025226083295, disc_loss = 0.00011459469171846837
Trained batch 464 in epoch 10, gen_loss = 1.430074466684813, disc_loss = 0.0001145737370778431
Trained batch 465 in epoch 10, gen_loss = 1.4299929530835458, disc_loss = 0.00011457346567339233
Trained batch 466 in epoch 10, gen_loss = 1.4299484246292768, disc_loss = 0.00011452706947460784
Trained batch 467 in epoch 10, gen_loss = 1.429838598283947, disc_loss = 0.00011442731174922192
Trained batch 468 in epoch 10, gen_loss = 1.4297826610394377, disc_loss = 0.00011437036472203673
Trained batch 469 in epoch 10, gen_loss = 1.4297361361219527, disc_loss = 0.00011427094815441338
Trained batch 470 in epoch 10, gen_loss = 1.4296589110307634, disc_loss = 0.00011411761873238078
Trained batch 471 in epoch 10, gen_loss = 1.4295312514749623, disc_loss = 0.00011399271024702565
Trained batch 472 in epoch 10, gen_loss = 1.4295588454534842, disc_loss = 0.00011390846495187535
Trained batch 473 in epoch 10, gen_loss = 1.429646833536494, disc_loss = 0.00011386499558407214
Trained batch 474 in epoch 10, gen_loss = 1.4296178958290502, disc_loss = 0.00011373247784305069
Trained batch 475 in epoch 10, gen_loss = 1.429565578699112, disc_loss = 0.00011359935973921572
Trained batch 476 in epoch 10, gen_loss = 1.4293499200349085, disc_loss = 0.00011349153780965114
Trained batch 477 in epoch 10, gen_loss = 1.429341125438403, disc_loss = 0.00011342932183914584
Trained batch 478 in epoch 10, gen_loss = 1.4295480562401217, disc_loss = 0.00011340908068273554
Trained batch 479 in epoch 10, gen_loss = 1.4296070950726667, disc_loss = 0.0001133315588200882
Trained batch 480 in epoch 10, gen_loss = 1.4297388826735054, disc_loss = 0.00011323703358977503
Trained batch 481 in epoch 10, gen_loss = 1.4297972863145885, disc_loss = 0.00011318432120316473
Trained batch 482 in epoch 10, gen_loss = 1.4297581412530587, disc_loss = 0.00011307825809792956
Trained batch 483 in epoch 10, gen_loss = 1.4296360249854316, disc_loss = 0.00011300913897421873
Trained batch 484 in epoch 10, gen_loss = 1.4295873108598376, disc_loss = 0.00011286942429898173
Trained batch 485 in epoch 10, gen_loss = 1.4294532014999861, disc_loss = 0.00011280942918448191
Trained batch 486 in epoch 10, gen_loss = 1.429533224575818, disc_loss = 0.00011268388016946141
Trained batch 487 in epoch 10, gen_loss = 1.4295009887609325, disc_loss = 0.0001125522398830131
Trained batch 488 in epoch 10, gen_loss = 1.4296315659774592, disc_loss = 0.0001125290147575825
Trained batch 489 in epoch 10, gen_loss = 1.4296867295187348, disc_loss = 0.00011255064356581507
Trained batch 490 in epoch 10, gen_loss = 1.429719136106021, disc_loss = 0.0001126381014852501
Trained batch 491 in epoch 10, gen_loss = 1.4297155551309508, disc_loss = 0.00011269287207267746
Trained batch 492 in epoch 10, gen_loss = 1.4296229835939698, disc_loss = 0.00011276347255781737
Trained batch 493 in epoch 10, gen_loss = 1.429637729638984, disc_loss = 0.00011270224714696715
Trained batch 494 in epoch 10, gen_loss = 1.4297838981705482, disc_loss = 0.000112617200640597
Trained batch 495 in epoch 10, gen_loss = 1.429913156455563, disc_loss = 0.00011245675278998181
Trained batch 496 in epoch 10, gen_loss = 1.4300342776645838, disc_loss = 0.00011230225896483177
Trained batch 497 in epoch 10, gen_loss = 1.4300524460742752, disc_loss = 0.00011213852897537479
Trained batch 498 in epoch 10, gen_loss = 1.42997727986567, disc_loss = 0.00011202744977282293
Trained batch 499 in epoch 10, gen_loss = 1.4301111023426056, disc_loss = 0.00011191224264621269
Trained batch 500 in epoch 10, gen_loss = 1.4300930040801119, disc_loss = 0.00011182168662220894
Trained batch 501 in epoch 10, gen_loss = 1.4300345552870002, disc_loss = 0.00011182361872833356
Trained batch 502 in epoch 10, gen_loss = 1.4299882830492783, disc_loss = 0.00011180366094827755
Trained batch 503 in epoch 10, gen_loss = 1.4300874438550737, disc_loss = 0.00011181226929895476
Trained batch 504 in epoch 10, gen_loss = 1.430182155760208, disc_loss = 0.000111764837125556
Trained batch 505 in epoch 10, gen_loss = 1.4302253751415508, disc_loss = 0.00011171534404516581
Trained batch 506 in epoch 10, gen_loss = 1.4302654191116844, disc_loss = 0.00011165768414801464
Trained batch 507 in epoch 10, gen_loss = 1.4301267299126452, disc_loss = 0.00011168938284195816
Trained batch 508 in epoch 10, gen_loss = 1.4301496163332625, disc_loss = 0.00011171880424306737
Trained batch 509 in epoch 10, gen_loss = 1.4302579648354474, disc_loss = 0.00011167719505964687
Trained batch 510 in epoch 10, gen_loss = 1.4303115025425144, disc_loss = 0.00011156502484167159
Trained batch 511 in epoch 10, gen_loss = 1.4303558361716568, disc_loss = 0.00011140062988701516
Trained batch 512 in epoch 10, gen_loss = 1.4303354129456638, disc_loss = 0.00011129354532148491
Trained batch 513 in epoch 10, gen_loss = 1.4302122910662847, disc_loss = 0.00011127125979377956
Trained batch 514 in epoch 10, gen_loss = 1.4303284476104292, disc_loss = 0.00011123593314762738
Trained batch 515 in epoch 10, gen_loss = 1.4303069731523825, disc_loss = 0.00011127308624251831
Trained batch 516 in epoch 10, gen_loss = 1.4303161911162001, disc_loss = 0.00011132334308987334
Trained batch 517 in epoch 10, gen_loss = 1.43020287489799, disc_loss = 0.00011132898797203214
Trained batch 518 in epoch 10, gen_loss = 1.4302076840906015, disc_loss = 0.00011123697328766936
Trained batch 519 in epoch 10, gen_loss = 1.4302419637258237, disc_loss = 0.00011111869651428536
Trained batch 520 in epoch 10, gen_loss = 1.4301893859815689, disc_loss = 0.00011102487133204649
Trained batch 521 in epoch 10, gen_loss = 1.4302741124712188, disc_loss = 0.0001109494776484234
Trained batch 522 in epoch 10, gen_loss = 1.4301484955428436, disc_loss = 0.00011086911105030074
Trained batch 523 in epoch 10, gen_loss = 1.4300694602136395, disc_loss = 0.00011077387311688792
Trained batch 524 in epoch 10, gen_loss = 1.4300190646307809, disc_loss = 0.00011065442420312181
Trained batch 525 in epoch 10, gen_loss = 1.430155187958547, disc_loss = 0.00011052393726559117
Trained batch 526 in epoch 10, gen_loss = 1.430194464082736, disc_loss = 0.0001104232634950252
Trained batch 527 in epoch 10, gen_loss = 1.4301929078770406, disc_loss = 0.00011033308435619828
Trained batch 528 in epoch 10, gen_loss = 1.4300730108989435, disc_loss = 0.00011021974433480523
Trained batch 529 in epoch 10, gen_loss = 1.4300426957742223, disc_loss = 0.00011038422295348696
Trained batch 530 in epoch 10, gen_loss = 1.4300659993723064, disc_loss = 0.00011052345066219406
Trained batch 531 in epoch 10, gen_loss = 1.43006715805907, disc_loss = 0.00011057233085463159
Trained batch 532 in epoch 10, gen_loss = 1.4302259064078555, disc_loss = 0.00011062053043672558
Trained batch 533 in epoch 10, gen_loss = 1.4301724603560086, disc_loss = 0.00011061279572677176
Trained batch 534 in epoch 10, gen_loss = 1.4301116185767628, disc_loss = 0.00011056101366278615
Trained batch 535 in epoch 10, gen_loss = 1.4301161841670078, disc_loss = 0.0001105061452318608
Trained batch 536 in epoch 10, gen_loss = 1.4300896744044356, disc_loss = 0.00011046053795845814
Trained batch 537 in epoch 10, gen_loss = 1.4300747513771057, disc_loss = 0.0001103439592016239
Trained batch 538 in epoch 10, gen_loss = 1.4299995892565414, disc_loss = 0.0001102307719444536
Trained batch 539 in epoch 10, gen_loss = 1.4299412689827107, disc_loss = 0.00011013656752159781
Trained batch 540 in epoch 10, gen_loss = 1.4299610456565393, disc_loss = 0.00011004632057028917
Trained batch 541 in epoch 10, gen_loss = 1.4299350578846526, disc_loss = 0.00010996541898100825
Trained batch 542 in epoch 10, gen_loss = 1.4298998156963791, disc_loss = 0.0001098546009059405
Trained batch 543 in epoch 10, gen_loss = 1.4299399020040737, disc_loss = 0.00010975975674695933
Trained batch 544 in epoch 10, gen_loss = 1.4300086445764664, disc_loss = 0.00010968803175724509
Trained batch 545 in epoch 10, gen_loss = 1.4299342103930184, disc_loss = 0.00010961426287128196
Trained batch 546 in epoch 10, gen_loss = 1.4299416825365976, disc_loss = 0.00010953012281188454
Trained batch 547 in epoch 10, gen_loss = 1.4298470329194173, disc_loss = 0.0001094757431218548
Trained batch 548 in epoch 10, gen_loss = 1.429852341910746, disc_loss = 0.00010942148359480016
Trained batch 549 in epoch 10, gen_loss = 1.4297794593464244, disc_loss = 0.00010935665200535864
Trained batch 550 in epoch 10, gen_loss = 1.42972715320691, disc_loss = 0.00010930658758291193
Trained batch 551 in epoch 10, gen_loss = 1.4296926989935446, disc_loss = 0.00010922345411241965
Trained batch 552 in epoch 10, gen_loss = 1.429711785066408, disc_loss = 0.00010911797423611557
Trained batch 553 in epoch 10, gen_loss = 1.4296761469290145, disc_loss = 0.00010904084719176508
Trained batch 554 in epoch 10, gen_loss = 1.4296904355556042, disc_loss = 0.00010909563719873372
Trained batch 555 in epoch 10, gen_loss = 1.429730271478351, disc_loss = 0.0001094550998884757
Trained batch 556 in epoch 10, gen_loss = 1.4296763837872544, disc_loss = 0.00010970089084951477
Trained batch 557 in epoch 10, gen_loss = 1.429593198829227, disc_loss = 0.00010978487955404118
Trained batch 558 in epoch 10, gen_loss = 1.4296885270338793, disc_loss = 0.00010987251302341815
Trained batch 559 in epoch 10, gen_loss = 1.4296741498368126, disc_loss = 0.00010988237756919262
Trained batch 560 in epoch 10, gen_loss = 1.4296050277835757, disc_loss = 0.00010994849396286322
Trained batch 561 in epoch 10, gen_loss = 1.4295639887823328, disc_loss = 0.00011006380908809635
Trained batch 562 in epoch 10, gen_loss = 1.4294645390332699, disc_loss = 0.00011017937180808961
Trained batch 563 in epoch 10, gen_loss = 1.4294012567252978, disc_loss = 0.0001102866488425026
Trained batch 564 in epoch 10, gen_loss = 1.4294741295080269, disc_loss = 0.00011043511655280032
Trained batch 565 in epoch 10, gen_loss = 1.4296198036561163, disc_loss = 0.00011056148753342176
Trained batch 566 in epoch 10, gen_loss = 1.4296689498151212, disc_loss = 0.00011061411360910592
Trained batch 567 in epoch 10, gen_loss = 1.429730945909527, disc_loss = 0.00011058788024623116
Trained batch 568 in epoch 10, gen_loss = 1.4296520282178855, disc_loss = 0.00011063929000772313
Trained batch 569 in epoch 10, gen_loss = 1.4296160323578015, disc_loss = 0.0001106506933195449
Trained batch 570 in epoch 10, gen_loss = 1.4295066578375688, disc_loss = 0.0001105681559714542
Trained batch 571 in epoch 10, gen_loss = 1.4295814550006307, disc_loss = 0.00011053503354000546
Trained batch 572 in epoch 10, gen_loss = 1.4297087103076422, disc_loss = 0.00011055965528747349
Trained batch 573 in epoch 10, gen_loss = 1.429762161567236, disc_loss = 0.00011058766372734174
Trained batch 574 in epoch 10, gen_loss = 1.4296256110979164, disc_loss = 0.00011057433021525629
Trained batch 575 in epoch 10, gen_loss = 1.4296268706934319, disc_loss = 0.00011052291766431053
Trained batch 576 in epoch 10, gen_loss = 1.429522122006276, disc_loss = 0.00011045866543366077
Trained batch 577 in epoch 10, gen_loss = 1.4295268898191749, disc_loss = 0.00011034805282172855
Trained batch 578 in epoch 10, gen_loss = 1.4294136447610015, disc_loss = 0.00011024998365238407
Trained batch 579 in epoch 10, gen_loss = 1.4294520476768757, disc_loss = 0.0001101700627228199
Trained batch 580 in epoch 10, gen_loss = 1.4294396833790763, disc_loss = 0.00011004537096007735
Trained batch 581 in epoch 10, gen_loss = 1.4292870604295502, disc_loss = 0.00010991683005336996
Trained batch 582 in epoch 10, gen_loss = 1.4293747582116625, disc_loss = 0.00010980772621290959
Trained batch 583 in epoch 10, gen_loss = 1.4293398783631521, disc_loss = 0.00010970408838870317
Trained batch 584 in epoch 10, gen_loss = 1.42920549629081, disc_loss = 0.00010958452528737123
Trained batch 585 in epoch 10, gen_loss = 1.429203293022442, disc_loss = 0.00010980966551112247
Trained batch 586 in epoch 10, gen_loss = 1.4290972221039833, disc_loss = 0.00010988553335269523
Trained batch 587 in epoch 10, gen_loss = 1.4292832617046072, disc_loss = 0.00011004872795038077
Trained batch 588 in epoch 10, gen_loss = 1.4293026446486572, disc_loss = 0.00011032370788295551
Trained batch 589 in epoch 10, gen_loss = 1.4293411267005791, disc_loss = 0.00011053861344099476
Trained batch 590 in epoch 10, gen_loss = 1.4293143716963819, disc_loss = 0.00011077621076823832
Trained batch 591 in epoch 10, gen_loss = 1.4293531545916118, disc_loss = 0.00011095933838090344
Trained batch 592 in epoch 10, gen_loss = 1.4293510809314594, disc_loss = 0.00011106542371595565
Trained batch 593 in epoch 10, gen_loss = 1.4293870331863763, disc_loss = 0.00011104527883577456
Trained batch 594 in epoch 10, gen_loss = 1.4293246443532095, disc_loss = 0.00011094610651961368
Trained batch 595 in epoch 10, gen_loss = 1.429096236924997, disc_loss = 0.00011082866381948651
Trained batch 596 in epoch 10, gen_loss = 1.4289438952153652, disc_loss = 0.00011070857956166316
Trained batch 597 in epoch 10, gen_loss = 1.4289546112551736, disc_loss = 0.00011059525705334037
Trained batch 598 in epoch 10, gen_loss = 1.428982666418429, disc_loss = 0.00011046133678703734
Trained batch 599 in epoch 10, gen_loss = 1.4289137043555578, disc_loss = 0.00011040570796164199
Trained batch 600 in epoch 10, gen_loss = 1.4289201454394271, disc_loss = 0.00011044565310260377
Trained batch 601 in epoch 10, gen_loss = 1.4289831103280533, disc_loss = 0.00011047358488774936
Trained batch 602 in epoch 10, gen_loss = 1.428997549449231, disc_loss = 0.00011039770215333792
Trained batch 603 in epoch 10, gen_loss = 1.4289945482418238, disc_loss = 0.00011029403536752138
Trained batch 604 in epoch 10, gen_loss = 1.4290732141368645, disc_loss = 0.00011027958941915792
Trained batch 605 in epoch 10, gen_loss = 1.4289809066076877, disc_loss = 0.0001103654264682251
Trained batch 606 in epoch 10, gen_loss = 1.4290790995813083, disc_loss = 0.00011052739001934541
Trained batch 607 in epoch 10, gen_loss = 1.4291163267273652, disc_loss = 0.0001106849759546429
Trained batch 608 in epoch 10, gen_loss = 1.4290707608553381, disc_loss = 0.00011066257745962401
Trained batch 609 in epoch 10, gen_loss = 1.4289384761794668, disc_loss = 0.00011058424353577124
Trained batch 610 in epoch 10, gen_loss = 1.4289788417457168, disc_loss = 0.00011052290111959363
Trained batch 611 in epoch 10, gen_loss = 1.428931462219338, disc_loss = 0.00011045780507819609
Trained batch 612 in epoch 10, gen_loss = 1.4289488142894105, disc_loss = 0.00011039794256858362
Trained batch 613 in epoch 10, gen_loss = 1.4288777988586052, disc_loss = 0.00011032114408120869
Trained batch 614 in epoch 10, gen_loss = 1.4289618428160504, disc_loss = 0.00011020932986097679
Trained batch 615 in epoch 10, gen_loss = 1.4290661960840225, disc_loss = 0.00011010057645372788
Trained batch 616 in epoch 10, gen_loss = 1.4290876444580103, disc_loss = 0.0001100268178543548
Trained batch 617 in epoch 10, gen_loss = 1.4291348530636636, disc_loss = 0.00010997498541929391
Trained batch 618 in epoch 10, gen_loss = 1.4290883130903969, disc_loss = 0.0001100096342946139
Trained batch 619 in epoch 10, gen_loss = 1.4290754800842653, disc_loss = 0.0001100513472773591
Trained batch 620 in epoch 10, gen_loss = 1.428981423953881, disc_loss = 0.00011003996055603126
Trained batch 621 in epoch 10, gen_loss = 1.428969909715499, disc_loss = 0.00011000997698955201
Trained batch 622 in epoch 10, gen_loss = 1.428948300034047, disc_loss = 0.00011001594311001888
Trained batch 623 in epoch 10, gen_loss = 1.4290521526948, disc_loss = 0.00011005890488692015
Trained batch 624 in epoch 10, gen_loss = 1.4291826404571533, disc_loss = 0.00011002668128057848
Trained batch 625 in epoch 10, gen_loss = 1.42918934913489, disc_loss = 0.0001099684029297943
Trained batch 626 in epoch 10, gen_loss = 1.4292149863174657, disc_loss = 0.00010991196612076165
Trained batch 627 in epoch 10, gen_loss = 1.429186691524117, disc_loss = 0.000109820136148515
Trained batch 628 in epoch 10, gen_loss = 1.4291343021847676, disc_loss = 0.00010973482782911677
Trained batch 629 in epoch 10, gen_loss = 1.429230070492578, disc_loss = 0.00010967667614807844
Trained batch 630 in epoch 10, gen_loss = 1.4292421333385534, disc_loss = 0.00010963436813124993
Trained batch 631 in epoch 10, gen_loss = 1.4292890437041657, disc_loss = 0.00010957478532792623
Trained batch 632 in epoch 10, gen_loss = 1.4290753439139416, disc_loss = 0.00010955579212653295
Trained batch 633 in epoch 10, gen_loss = 1.4290704546666673, disc_loss = 0.00010955021010806078
Trained batch 634 in epoch 10, gen_loss = 1.4291329380095474, disc_loss = 0.00010949992089783022
Trained batch 635 in epoch 10, gen_loss = 1.4291274317030638, disc_loss = 0.00010943435291327596
Trained batch 636 in epoch 10, gen_loss = 1.4290654256916495, disc_loss = 0.00010932388036474647
Trained batch 637 in epoch 10, gen_loss = 1.4290455185507531, disc_loss = 0.00010933256805535471
Trained batch 638 in epoch 10, gen_loss = 1.4291019016215125, disc_loss = 0.00010939868153117073
Trained batch 639 in epoch 10, gen_loss = 1.4291768925264479, disc_loss = 0.00010944124044556247
Trained batch 640 in epoch 10, gen_loss = 1.429078427566195, disc_loss = 0.0001094818274221427
Trained batch 641 in epoch 10, gen_loss = 1.4291732530356196, disc_loss = 0.00010950136626075544
Trained batch 642 in epoch 10, gen_loss = 1.4291804648854685, disc_loss = 0.00010948886591456356
Trained batch 643 in epoch 10, gen_loss = 1.429235994630719, disc_loss = 0.00010946648803866134
Trained batch 644 in epoch 10, gen_loss = 1.429325582814771, disc_loss = 0.00010942655291813046
Trained batch 645 in epoch 10, gen_loss = 1.429353815114166, disc_loss = 0.00010937740000721442
Trained batch 646 in epoch 10, gen_loss = 1.4294034285007342, disc_loss = 0.00010934994411491483
Trained batch 647 in epoch 10, gen_loss = 1.4294656502243914, disc_loss = 0.00010933175914021971
Trained batch 648 in epoch 10, gen_loss = 1.4294156820638153, disc_loss = 0.00010930350451651356
Trained batch 649 in epoch 10, gen_loss = 1.4293709896161007, disc_loss = 0.00010925503932622423
Trained batch 650 in epoch 10, gen_loss = 1.4293525460678311, disc_loss = 0.00010921777224834931
Trained batch 651 in epoch 10, gen_loss = 1.4293045229707027, disc_loss = 0.00010916855032458002
Trained batch 652 in epoch 10, gen_loss = 1.429262348010018, disc_loss = 0.00010909006275015274
Trained batch 653 in epoch 10, gen_loss = 1.429253684089089, disc_loss = 0.0001090164350092118
Trained batch 654 in epoch 10, gen_loss = 1.4291884788120066, disc_loss = 0.00010891596682315056
Trained batch 655 in epoch 10, gen_loss = 1.4291435387439844, disc_loss = 0.00010879338553211977
Trained batch 656 in epoch 10, gen_loss = 1.4291341582389727, disc_loss = 0.00010867140786193826
Trained batch 657 in epoch 10, gen_loss = 1.4290614731406006, disc_loss = 0.00010854770095998918
Trained batch 658 in epoch 10, gen_loss = 1.4289772559370004, disc_loss = 0.00010843810087615908
Trained batch 659 in epoch 10, gen_loss = 1.4291129984638908, disc_loss = 0.00010831976553549104
Trained batch 660 in epoch 10, gen_loss = 1.4290641721185866, disc_loss = 0.00010824994224067035
Trained batch 661 in epoch 10, gen_loss = 1.4290454985511987, disc_loss = 0.0001082414636642574
Trained batch 662 in epoch 10, gen_loss = 1.429003065707637, disc_loss = 0.00010837775987096157
Trained batch 663 in epoch 10, gen_loss = 1.4290573029633027, disc_loss = 0.00010840187993457527
Trained batch 664 in epoch 10, gen_loss = 1.428995274601126, disc_loss = 0.00010836408307517203
Trained batch 665 in epoch 10, gen_loss = 1.4290365426390021, disc_loss = 0.00010836779510081196
Trained batch 666 in epoch 10, gen_loss = 1.429099151577013, disc_loss = 0.00010836150836419175
Trained batch 667 in epoch 10, gen_loss = 1.4291478274111262, disc_loss = 0.0001083258369330062
Trained batch 668 in epoch 10, gen_loss = 1.4291861709457876, disc_loss = 0.00010828015757208257
Trained batch 669 in epoch 10, gen_loss = 1.4290722096144264, disc_loss = 0.0001082485651410812
Trained batch 670 in epoch 10, gen_loss = 1.428983893017833, disc_loss = 0.00010822026835086643
Trained batch 671 in epoch 10, gen_loss = 1.429136651967253, disc_loss = 0.00010819597877441214
Trained batch 672 in epoch 10, gen_loss = 1.4291199550231888, disc_loss = 0.00010821819896415796
Trained batch 673 in epoch 10, gen_loss = 1.4289870838736922, disc_loss = 0.00010817432492881691
Trained batch 674 in epoch 10, gen_loss = 1.4289825231057627, disc_loss = 0.0001081739676845717
Trained batch 675 in epoch 10, gen_loss = 1.4290411558729657, disc_loss = 0.00010814386558507245
Trained batch 676 in epoch 10, gen_loss = 1.429004662674322, disc_loss = 0.00010806650943925416
Trained batch 677 in epoch 10, gen_loss = 1.4290084650734534, disc_loss = 0.00010802976084209186
Trained batch 678 in epoch 10, gen_loss = 1.428992763359171, disc_loss = 0.00010801003757187948
Trained batch 679 in epoch 10, gen_loss = 1.4289650496314554, disc_loss = 0.00010796566637990883
Trained batch 680 in epoch 10, gen_loss = 1.4289279516222892, disc_loss = 0.00010794479461492702
Trained batch 681 in epoch 10, gen_loss = 1.428826808579856, disc_loss = 0.00010795206762156828
Trained batch 682 in epoch 10, gen_loss = 1.4288568474014194, disc_loss = 0.00010793411664953739
Trained batch 683 in epoch 10, gen_loss = 1.4288206729624007, disc_loss = 0.00010786300106712311
Trained batch 684 in epoch 10, gen_loss = 1.4289414076909532, disc_loss = 0.00010782943038305142
Trained batch 685 in epoch 10, gen_loss = 1.4289155722359526, disc_loss = 0.00010775720147913986
Trained batch 686 in epoch 10, gen_loss = 1.4288549921224558, disc_loss = 0.00010770343552027769
Trained batch 687 in epoch 10, gen_loss = 1.428820988293304, disc_loss = 0.0001076384433835576
Trained batch 688 in epoch 10, gen_loss = 1.4287160415261855, disc_loss = 0.00010754993176034092
Trained batch 689 in epoch 10, gen_loss = 1.4287236533303191, disc_loss = 0.00010745472021274811
Trained batch 690 in epoch 10, gen_loss = 1.4286349542579153, disc_loss = 0.0001073551966025797
Trained batch 691 in epoch 10, gen_loss = 1.4285519796644333, disc_loss = 0.00010724637391211143
Trained batch 692 in epoch 10, gen_loss = 1.428557413653034, disc_loss = 0.00010715893023145673
Trained batch 693 in epoch 10, gen_loss = 1.4284797020535647, disc_loss = 0.00010708872293096867
Trained batch 694 in epoch 10, gen_loss = 1.4284125319487757, disc_loss = 0.00010703252428225928
Trained batch 695 in epoch 10, gen_loss = 1.4283819438397198, disc_loss = 0.00010694076816215439
Trained batch 696 in epoch 10, gen_loss = 1.4284766541320932, disc_loss = 0.00010689582778446138
Trained batch 697 in epoch 10, gen_loss = 1.4285641326262137, disc_loss = 0.0001068605482327059
Trained batch 698 in epoch 10, gen_loss = 1.4285510290675238, disc_loss = 0.00010682157593541023
Trained batch 699 in epoch 10, gen_loss = 1.4284977236815861, disc_loss = 0.00010674260271116509
Trained batch 700 in epoch 10, gen_loss = 1.4285131476915172, disc_loss = 0.00010664918478562138
Trained batch 701 in epoch 10, gen_loss = 1.4284648212612185, disc_loss = 0.00010656397115032303
Trained batch 702 in epoch 10, gen_loss = 1.4285053382727024, disc_loss = 0.00010648789788084387
Trained batch 703 in epoch 10, gen_loss = 1.4284732971679082, disc_loss = 0.00010642329176717298
Trained batch 704 in epoch 10, gen_loss = 1.4284524535456449, disc_loss = 0.00010639167700017759
Trained batch 705 in epoch 10, gen_loss = 1.4284308365316634, disc_loss = 0.00010643640533388509
Trained batch 706 in epoch 10, gen_loss = 1.428297909516762, disc_loss = 0.00010656039843527495
Trained batch 707 in epoch 10, gen_loss = 1.4283090498151079, disc_loss = 0.00010669425338848135
Trained batch 708 in epoch 10, gen_loss = 1.4283858685634705, disc_loss = 0.00010684651544954111
Trained batch 709 in epoch 10, gen_loss = 1.42835044105288, disc_loss = 0.00010695792207116028
Trained batch 710 in epoch 10, gen_loss = 1.4283275621014473, disc_loss = 0.00010700157674361606
Trained batch 711 in epoch 10, gen_loss = 1.4283550174048778, disc_loss = 0.00010699756543534716
Trained batch 712 in epoch 10, gen_loss = 1.428415188448292, disc_loss = 0.00010700385999161868
Trained batch 713 in epoch 10, gen_loss = 1.4284040884477418, disc_loss = 0.00010692761935854473
Trained batch 714 in epoch 10, gen_loss = 1.4284472979032077, disc_loss = 0.00010688073198761632
Trained batch 715 in epoch 10, gen_loss = 1.4284626075675368, disc_loss = 0.00010683171502013308
Trained batch 716 in epoch 10, gen_loss = 1.4285169991156712, disc_loss = 0.00010683229747109392
Trained batch 717 in epoch 10, gen_loss = 1.4285801801840907, disc_loss = 0.00010689911367252912
Trained batch 718 in epoch 10, gen_loss = 1.4286514935141976, disc_loss = 0.00010687449811306483
Trained batch 719 in epoch 10, gen_loss = 1.428697888718711, disc_loss = 0.00010683292267306872
Trained batch 720 in epoch 10, gen_loss = 1.4286896273101086, disc_loss = 0.00010677101026721806
Trained batch 721 in epoch 10, gen_loss = 1.4288003447973827, disc_loss = 0.00010669406895121283
Trained batch 722 in epoch 10, gen_loss = 1.4288157908913175, disc_loss = 0.00010665288318504008
Trained batch 723 in epoch 10, gen_loss = 1.4288357048403493, disc_loss = 0.00010679202495394542
Trained batch 724 in epoch 10, gen_loss = 1.4287645063729122, disc_loss = 0.0001072662774095079
Trained batch 725 in epoch 10, gen_loss = 1.4288031045070364, disc_loss = 0.00010808664851650944
Trained batch 726 in epoch 10, gen_loss = 1.428803304858516, disc_loss = 0.00010921054473344958
Trained batch 727 in epoch 10, gen_loss = 1.4287145678158646, disc_loss = 0.00011064376695225751
Trained batch 728 in epoch 10, gen_loss = 1.4287238168454792, disc_loss = 0.00011223158431571185
Trained batch 729 in epoch 10, gen_loss = 1.4286878871591124, disc_loss = 0.00011371639301776743
Trained batch 730 in epoch 10, gen_loss = 1.4287855106567717, disc_loss = 0.00011485111881907066
Trained batch 731 in epoch 10, gen_loss = 1.4288349356807646, disc_loss = 0.00011556742315331606
Trained batch 732 in epoch 10, gen_loss = 1.428817633229421, disc_loss = 0.00011591551844849735
Trained batch 733 in epoch 10, gen_loss = 1.4287974330969662, disc_loss = 0.00011602843457449349
Trained batch 734 in epoch 10, gen_loss = 1.4287922203946275, disc_loss = 0.0001161323793541892
Trained batch 735 in epoch 10, gen_loss = 1.4286673590540886, disc_loss = 0.0001162236841927868
Trained batch 736 in epoch 10, gen_loss = 1.4286336119171723, disc_loss = 0.00011630738659668572
Trained batch 737 in epoch 10, gen_loss = 1.4287206528955683, disc_loss = 0.00011648564115484914
Trained batch 738 in epoch 10, gen_loss = 1.428658347007225, disc_loss = 0.00011665034838954881
Trained batch 739 in epoch 10, gen_loss = 1.4286707662247322, disc_loss = 0.0001167485815475064
Trained batch 740 in epoch 10, gen_loss = 1.4287051948619436, disc_loss = 0.00011679553628830266
Trained batch 741 in epoch 10, gen_loss = 1.428795765834356, disc_loss = 0.00011688305726961651
Trained batch 742 in epoch 10, gen_loss = 1.4287866299437963, disc_loss = 0.00011691091172052043
Trained batch 743 in epoch 10, gen_loss = 1.4287677037139093, disc_loss = 0.00011695877049200506
Trained batch 744 in epoch 10, gen_loss = 1.4288146715036174, disc_loss = 0.00011698574627561717
Trained batch 745 in epoch 10, gen_loss = 1.4288006595887703, disc_loss = 0.00011700287740527394
Testing Epoch 10
Training Epoch 11
Trained batch 0 in epoch 11, gen_loss = 1.440744161605835, disc_loss = 0.0001334335538558662
Trained batch 1 in epoch 11, gen_loss = 1.4348312616348267, disc_loss = 0.00012748345397994854
Trained batch 2 in epoch 11, gen_loss = 1.4441680908203125, disc_loss = 0.00011351390033572291
Trained batch 3 in epoch 11, gen_loss = 1.4396071434020996, disc_loss = 9.651919026509859e-05
Trained batch 4 in epoch 11, gen_loss = 1.4325455188751222, disc_loss = 8.115295422612689e-05
Trained batch 5 in epoch 11, gen_loss = 1.4194096724192302, disc_loss = 7.116538199625211e-05
Trained batch 6 in epoch 11, gen_loss = 1.4252261434282576, disc_loss = 6.494719127658755e-05
Trained batch 7 in epoch 11, gen_loss = 1.428934171795845, disc_loss = 6.453392325056484e-05
Trained batch 8 in epoch 11, gen_loss = 1.4361798233456082, disc_loss = 6.657573087270268e-05
Trained batch 9 in epoch 11, gen_loss = 1.4364271402359008, disc_loss = 6.763029668945819e-05
Trained batch 10 in epoch 11, gen_loss = 1.4277141744440252, disc_loss = 6.618235651826994e-05
Trained batch 11 in epoch 11, gen_loss = 1.429578463236491, disc_loss = 6.357093449575284e-05
Trained batch 12 in epoch 11, gen_loss = 1.4289051936222956, disc_loss = 6.091180610103318e-05
Trained batch 13 in epoch 11, gen_loss = 1.4296186992100306, disc_loss = 5.8394549991394994e-05
Trained batch 14 in epoch 11, gen_loss = 1.4283259709676106, disc_loss = 5.651305606685734e-05
Trained batch 15 in epoch 11, gen_loss = 1.430292785167694, disc_loss = 5.459054284528975e-05
Trained batch 16 in epoch 11, gen_loss = 1.428512369885164, disc_loss = 5.3201920523219195e-05
Trained batch 17 in epoch 11, gen_loss = 1.426689366499583, disc_loss = 5.1856212545923576e-05
Trained batch 18 in epoch 11, gen_loss = 1.4236423028142828, disc_loss = 5.0629309714024297e-05
Trained batch 19 in epoch 11, gen_loss = 1.4240986347198485, disc_loss = 4.9247336937696674e-05
Trained batch 20 in epoch 11, gen_loss = 1.422280334291004, disc_loss = 4.775862180395052e-05
Trained batch 21 in epoch 11, gen_loss = 1.42511817000129, disc_loss = 4.640255850641882e-05
Trained batch 22 in epoch 11, gen_loss = 1.4247493484745855, disc_loss = 4.513937433923433e-05
Trained batch 23 in epoch 11, gen_loss = 1.426258424917857, disc_loss = 4.7022545459185494e-05
Trained batch 24 in epoch 11, gen_loss = 1.4250555992126466, disc_loss = 5.050321007729508e-05
Trained batch 25 in epoch 11, gen_loss = 1.4249008985666127, disc_loss = 5.302310413613808e-05
Trained batch 26 in epoch 11, gen_loss = 1.4266055645766083, disc_loss = 5.2788785439959075e-05
Trained batch 27 in epoch 11, gen_loss = 1.4299736491271429, disc_loss = 5.216917075553543e-05
Trained batch 28 in epoch 11, gen_loss = 1.431807411128077, disc_loss = 5.281850224429067e-05
Trained batch 29 in epoch 11, gen_loss = 1.4339730938275654, disc_loss = 5.4945144681065966e-05
Trained batch 30 in epoch 11, gen_loss = 1.435841598818379, disc_loss = 5.7334745384474856e-05
Trained batch 31 in epoch 11, gen_loss = 1.435613565146923, disc_loss = 5.932954388754297e-05
Trained batch 32 in epoch 11, gen_loss = 1.435470786961642, disc_loss = 6.201997684635872e-05
Trained batch 33 in epoch 11, gen_loss = 1.4334948483635397, disc_loss = 6.406849987637114e-05
Trained batch 34 in epoch 11, gen_loss = 1.4333155597959246, disc_loss = 6.537739214504004e-05
Trained batch 35 in epoch 11, gen_loss = 1.4337287114726172, disc_loss = 6.596909396547644e-05
Trained batch 36 in epoch 11, gen_loss = 1.433301893440453, disc_loss = 6.620867350500555e-05
Trained batch 37 in epoch 11, gen_loss = 1.4337320515983982, disc_loss = 6.511623656766268e-05
Trained batch 38 in epoch 11, gen_loss = 1.4336669750702686, disc_loss = 6.463274602981236e-05
Trained batch 39 in epoch 11, gen_loss = 1.4351281881332398, disc_loss = 6.438667351176264e-05
Trained batch 40 in epoch 11, gen_loss = 1.4350026177196968, disc_loss = 6.592528565883318e-05
Trained batch 41 in epoch 11, gen_loss = 1.4357459516752333, disc_loss = 6.757708944773877e-05
Trained batch 42 in epoch 11, gen_loss = 1.4357252647710401, disc_loss = 6.919927122802366e-05
Trained batch 43 in epoch 11, gen_loss = 1.43487719243223, disc_loss = 7.055712872401769e-05
Trained batch 44 in epoch 11, gen_loss = 1.4343132389916313, disc_loss = 7.188006954190011e-05
Trained batch 45 in epoch 11, gen_loss = 1.435511853383935, disc_loss = 7.351503455024415e-05
Trained batch 46 in epoch 11, gen_loss = 1.436406597178033, disc_loss = 7.493409933150805e-05
Trained batch 47 in epoch 11, gen_loss = 1.436538740992546, disc_loss = 7.657917482598957e-05
Trained batch 48 in epoch 11, gen_loss = 1.4358731994823533, disc_loss = 7.799748798751519e-05
Trained batch 49 in epoch 11, gen_loss = 1.4349758172035216, disc_loss = 7.898001626017503e-05
Trained batch 50 in epoch 11, gen_loss = 1.4349298103182924, disc_loss = 7.981515969446514e-05
Trained batch 51 in epoch 11, gen_loss = 1.4338916127498333, disc_loss = 8.091975415971738e-05
Trained batch 52 in epoch 11, gen_loss = 1.4338073055699188, disc_loss = 8.156935627822641e-05
Trained batch 53 in epoch 11, gen_loss = 1.43524878554874, disc_loss = 8.261838350639057e-05
Trained batch 54 in epoch 11, gen_loss = 1.4347268624739213, disc_loss = 8.3353607095143e-05
Trained batch 55 in epoch 11, gen_loss = 1.434257686138153, disc_loss = 8.344781352726776e-05
Trained batch 56 in epoch 11, gen_loss = 1.4335200451968009, disc_loss = 8.337306529651151e-05
Trained batch 57 in epoch 11, gen_loss = 1.4337737231419003, disc_loss = 8.265293782360146e-05
Trained batch 58 in epoch 11, gen_loss = 1.4343805979874173, disc_loss = 8.157619647706378e-05
Trained batch 59 in epoch 11, gen_loss = 1.4340828359127045, disc_loss = 8.052773385619124e-05
Trained batch 60 in epoch 11, gen_loss = 1.4327916258671245, disc_loss = 7.961239805540497e-05
Trained batch 61 in epoch 11, gen_loss = 1.4331649407263725, disc_loss = 7.917023990998015e-05
Trained batch 62 in epoch 11, gen_loss = 1.433146807882521, disc_loss = 7.933823554407036e-05
Trained batch 63 in epoch 11, gen_loss = 1.4331575762480497, disc_loss = 7.977893119459623e-05
Trained batch 64 in epoch 11, gen_loss = 1.4340201671306902, disc_loss = 8.1240985981332e-05
Trained batch 65 in epoch 11, gen_loss = 1.4341568278543877, disc_loss = 8.39862841530703e-05
Trained batch 66 in epoch 11, gen_loss = 1.4331624756998091, disc_loss = 8.654888826179138e-05
Trained batch 67 in epoch 11, gen_loss = 1.432766416493584, disc_loss = 8.815791828537305e-05
Trained batch 68 in epoch 11, gen_loss = 1.4318341794221296, disc_loss = 8.91513830182426e-05
Trained batch 69 in epoch 11, gen_loss = 1.431588155882699, disc_loss = 8.956639170979283e-05
Trained batch 70 in epoch 11, gen_loss = 1.431243255104817, disc_loss = 8.920340554487013e-05
Trained batch 71 in epoch 11, gen_loss = 1.431317345963584, disc_loss = 8.842494354313304e-05
Trained batch 72 in epoch 11, gen_loss = 1.4311874761973342, disc_loss = 8.744789753507899e-05
Trained batch 73 in epoch 11, gen_loss = 1.4306216175491746, disc_loss = 8.648153350411637e-05
Trained batch 74 in epoch 11, gen_loss = 1.4310567553838094, disc_loss = 8.565566466131713e-05
Trained batch 75 in epoch 11, gen_loss = 1.430498149834181, disc_loss = 8.52037117654522e-05
Trained batch 76 in epoch 11, gen_loss = 1.4304776269120056, disc_loss = 8.517941299847829e-05
Trained batch 77 in epoch 11, gen_loss = 1.4301369419464698, disc_loss = 8.558513854950434e-05
Trained batch 78 in epoch 11, gen_loss = 1.4310213040701951, disc_loss = 8.601755148504972e-05
Trained batch 79 in epoch 11, gen_loss = 1.4310815632343292, disc_loss = 8.672488859247096e-05
Trained batch 80 in epoch 11, gen_loss = 1.4319044925548412, disc_loss = 8.683602579737824e-05
Trained batch 81 in epoch 11, gen_loss = 1.4305070725882925, disc_loss = 8.681366531474363e-05
Trained batch 82 in epoch 11, gen_loss = 1.430166250251862, disc_loss = 8.695162358046481e-05
Trained batch 83 in epoch 11, gen_loss = 1.4298351506392162, disc_loss = 8.74204135167626e-05
Trained batch 84 in epoch 11, gen_loss = 1.4298419770072488, disc_loss = 8.827905782227925e-05
Trained batch 85 in epoch 11, gen_loss = 1.429789400377939, disc_loss = 8.867790844771323e-05
Trained batch 86 in epoch 11, gen_loss = 1.4302883572962093, disc_loss = 8.877880800459881e-05
Trained batch 87 in epoch 11, gen_loss = 1.4309488250450655, disc_loss = 8.910725378799808e-05
Trained batch 88 in epoch 11, gen_loss = 1.4311928909816098, disc_loss = 8.948749437580916e-05
Trained batch 89 in epoch 11, gen_loss = 1.4303184866905212, disc_loss = 8.956318886501119e-05
Trained batch 90 in epoch 11, gen_loss = 1.4303566767619207, disc_loss = 8.98321280116791e-05
Trained batch 91 in epoch 11, gen_loss = 1.431419981562573, disc_loss = 9.014439434474258e-05
Trained batch 92 in epoch 11, gen_loss = 1.4313556865979267, disc_loss = 9.055140146047442e-05
Trained batch 93 in epoch 11, gen_loss = 1.4313225987109732, disc_loss = 9.092317860120873e-05
Trained batch 94 in epoch 11, gen_loss = 1.431368465172617, disc_loss = 9.140539211665255e-05
Trained batch 95 in epoch 11, gen_loss = 1.4313898372153442, disc_loss = 9.171379355166209e-05
Trained batch 96 in epoch 11, gen_loss = 1.4312276238018704, disc_loss = 9.21112371252468e-05
Trained batch 97 in epoch 11, gen_loss = 1.4317162195030524, disc_loss = 9.290560716849263e-05
Trained batch 98 in epoch 11, gen_loss = 1.431536407181711, disc_loss = 9.384029759861402e-05
Trained batch 99 in epoch 11, gen_loss = 1.4316292476654053, disc_loss = 9.452151463847258e-05
Trained batch 100 in epoch 11, gen_loss = 1.4313671577094804, disc_loss = 9.451955567315188e-05
Trained batch 101 in epoch 11, gen_loss = 1.4314786090570337, disc_loss = 9.443133619831369e-05
Trained batch 102 in epoch 11, gen_loss = 1.4314675898227878, disc_loss = 9.4026733403579e-05
Trained batch 103 in epoch 11, gen_loss = 1.431914658500598, disc_loss = 9.342213124560098e-05
Trained batch 104 in epoch 11, gen_loss = 1.432205183165414, disc_loss = 9.296137018065479e-05
Trained batch 105 in epoch 11, gen_loss = 1.431676038031308, disc_loss = 9.263064616531647e-05
Trained batch 106 in epoch 11, gen_loss = 1.4314430517570995, disc_loss = 9.266158292044463e-05
Trained batch 107 in epoch 11, gen_loss = 1.4316067916375619, disc_loss = 9.292839397150803e-05
Trained batch 108 in epoch 11, gen_loss = 1.4318486966124369, disc_loss = 9.343096070376614e-05
Trained batch 109 in epoch 11, gen_loss = 1.431816250627691, disc_loss = 9.382636921641693e-05
Trained batch 110 in epoch 11, gen_loss = 1.431993283667006, disc_loss = 9.40106051161451e-05
Trained batch 111 in epoch 11, gen_loss = 1.4322402168597494, disc_loss = 9.411507512270743e-05
Trained batch 112 in epoch 11, gen_loss = 1.4322279944884038, disc_loss = 9.409007941183647e-05
Trained batch 113 in epoch 11, gen_loss = 1.4317792633123565, disc_loss = 9.399040804406436e-05
Trained batch 114 in epoch 11, gen_loss = 1.4315837331440138, disc_loss = 9.358746957213557e-05
Trained batch 115 in epoch 11, gen_loss = 1.4312719384144093, disc_loss = 9.319311380624703e-05
Trained batch 116 in epoch 11, gen_loss = 1.430369740877396, disc_loss = 9.279489308821026e-05
Trained batch 117 in epoch 11, gen_loss = 1.4304110791723608, disc_loss = 9.221281703441676e-05
Trained batch 118 in epoch 11, gen_loss = 1.4313801677287126, disc_loss = 9.173252825547468e-05
Trained batch 119 in epoch 11, gen_loss = 1.4306982934474946, disc_loss = 9.1479814439784e-05
Trained batch 120 in epoch 11, gen_loss = 1.4306624329779758, disc_loss = 9.103935818447181e-05
Trained batch 121 in epoch 11, gen_loss = 1.4301623526166698, disc_loss = 9.062797004740102e-05
Trained batch 122 in epoch 11, gen_loss = 1.429958261125456, disc_loss = 9.016619830018921e-05
Trained batch 123 in epoch 11, gen_loss = 1.4298389217545908, disc_loss = 8.96744013809967e-05
Trained batch 124 in epoch 11, gen_loss = 1.4300234746932983, disc_loss = 8.956814580596983e-05
Trained batch 125 in epoch 11, gen_loss = 1.4295735784939356, disc_loss = 8.948159879692534e-05
Trained batch 126 in epoch 11, gen_loss = 1.4298755625101525, disc_loss = 8.955508154059767e-05
Trained batch 127 in epoch 11, gen_loss = 1.4294066727161407, disc_loss = 8.96587906709101e-05
Trained batch 128 in epoch 11, gen_loss = 1.4291774681372236, disc_loss = 8.973950414571824e-05
Trained batch 129 in epoch 11, gen_loss = 1.4291778977100666, disc_loss = 8.973821263330487e-05
Trained batch 130 in epoch 11, gen_loss = 1.429722031564203, disc_loss = 8.972938650621826e-05
Trained batch 131 in epoch 11, gen_loss = 1.4293494080052231, disc_loss = 8.966650635887741e-05
Trained batch 132 in epoch 11, gen_loss = 1.4287837179083573, disc_loss = 8.940009937028197e-05
Trained batch 133 in epoch 11, gen_loss = 1.4289463117941101, disc_loss = 8.906971251873521e-05
Trained batch 134 in epoch 11, gen_loss = 1.428485232812387, disc_loss = 8.882627595017698e-05
Trained batch 135 in epoch 11, gen_loss = 1.428214935695424, disc_loss = 8.858591424059876e-05
Trained batch 136 in epoch 11, gen_loss = 1.4281105046724751, disc_loss = 8.819589586155217e-05
Trained batch 137 in epoch 11, gen_loss = 1.4281225593193718, disc_loss = 8.791062174313466e-05
Trained batch 138 in epoch 11, gen_loss = 1.4281562249437512, disc_loss = 8.80814869370958e-05
Trained batch 139 in epoch 11, gen_loss = 1.4279268775667464, disc_loss = 8.809264246727773e-05
Trained batch 140 in epoch 11, gen_loss = 1.4276086573905133, disc_loss = 8.781140567284863e-05
Trained batch 141 in epoch 11, gen_loss = 1.4278199395663302, disc_loss = 8.749906040796137e-05
Trained batch 142 in epoch 11, gen_loss = 1.4274248685036506, disc_loss = 8.704282074584219e-05
Trained batch 143 in epoch 11, gen_loss = 1.4274518059359655, disc_loss = 8.669238954755403e-05
Trained batch 144 in epoch 11, gen_loss = 1.427582125006051, disc_loss = 8.64255950201086e-05
Trained batch 145 in epoch 11, gen_loss = 1.4274576371663237, disc_loss = 8.604348563058509e-05
Trained batch 146 in epoch 11, gen_loss = 1.4273718449534203, disc_loss = 8.564081173328775e-05
Trained batch 147 in epoch 11, gen_loss = 1.4276147049826544, disc_loss = 8.525220218379636e-05
Trained batch 148 in epoch 11, gen_loss = 1.4279002695275633, disc_loss = 8.478051429407767e-05
Trained batch 149 in epoch 11, gen_loss = 1.428172676563263, disc_loss = 8.431091662714608e-05
Trained batch 150 in epoch 11, gen_loss = 1.4280347816202024, disc_loss = 8.389026329827392e-05
Trained batch 151 in epoch 11, gen_loss = 1.4281701735760037, disc_loss = 8.345223745053725e-05
Trained batch 152 in epoch 11, gen_loss = 1.4283509231081195, disc_loss = 8.367015446494965e-05
Trained batch 153 in epoch 11, gen_loss = 1.4284138749172162, disc_loss = 8.382050350814712e-05
Trained batch 154 in epoch 11, gen_loss = 1.428430478034481, disc_loss = 8.384344707719132e-05
Trained batch 155 in epoch 11, gen_loss = 1.429020637120956, disc_loss = 8.380721627732922e-05
Trained batch 156 in epoch 11, gen_loss = 1.4289356842162504, disc_loss = 8.377178245186798e-05
Trained batch 157 in epoch 11, gen_loss = 1.4293268609650527, disc_loss = 8.384989123327085e-05
Trained batch 158 in epoch 11, gen_loss = 1.4299394072226759, disc_loss = 8.396758422699029e-05
Trained batch 159 in epoch 11, gen_loss = 1.4302286826074124, disc_loss = 8.414212585989844e-05
Trained batch 160 in epoch 11, gen_loss = 1.4301065132484674, disc_loss = 8.440428703110658e-05
Trained batch 161 in epoch 11, gen_loss = 1.4304570967768446, disc_loss = 8.475400706213996e-05
Trained batch 162 in epoch 11, gen_loss = 1.430895629104661, disc_loss = 8.511665194759402e-05
Trained batch 163 in epoch 11, gen_loss = 1.431142154990173, disc_loss = 8.555510489935753e-05
Trained batch 164 in epoch 11, gen_loss = 1.431769263383114, disc_loss = 8.63453109339003e-05
Trained batch 165 in epoch 11, gen_loss = 1.4317141764135246, disc_loss = 8.716019499251522e-05
Trained batch 166 in epoch 11, gen_loss = 1.431800690239775, disc_loss = 8.795981288849743e-05
Trained batch 167 in epoch 11, gen_loss = 1.431637819324221, disc_loss = 8.866792118277815e-05
Trained batch 168 in epoch 11, gen_loss = 1.4315536530060176, disc_loss = 8.935326445545863e-05
Trained batch 169 in epoch 11, gen_loss = 1.4313017704907585, disc_loss = 8.999847107535222e-05
Trained batch 170 in epoch 11, gen_loss = 1.4314251434036165, disc_loss = 9.055352232371129e-05
Trained batch 171 in epoch 11, gen_loss = 1.4316665932189587, disc_loss = 9.089570632335549e-05
Trained batch 172 in epoch 11, gen_loss = 1.432174766683854, disc_loss = 9.136348643882376e-05
Trained batch 173 in epoch 11, gen_loss = 1.4323047666714108, disc_loss = 9.140758033256929e-05
Trained batch 174 in epoch 11, gen_loss = 1.432169041633606, disc_loss = 9.143464605585904e-05
Trained batch 175 in epoch 11, gen_loss = 1.4323894537308, disc_loss = 9.164949474635168e-05
Trained batch 176 in epoch 11, gen_loss = 1.4323744928769473, disc_loss = 9.183455126140218e-05
Trained batch 177 in epoch 11, gen_loss = 1.4323988784565014, disc_loss = 9.189951257989317e-05
Trained batch 178 in epoch 11, gen_loss = 1.4322964445838715, disc_loss = 9.174203448346004e-05
Trained batch 179 in epoch 11, gen_loss = 1.4325443532731799, disc_loss = 9.159386618699096e-05
Trained batch 180 in epoch 11, gen_loss = 1.4323582603127918, disc_loss = 9.157823609892961e-05
Trained batch 181 in epoch 11, gen_loss = 1.4323721318454532, disc_loss = 9.157816426163114e-05
Trained batch 182 in epoch 11, gen_loss = 1.43220033997395, disc_loss = 9.170878881074411e-05
Trained batch 183 in epoch 11, gen_loss = 1.4321093138145364, disc_loss = 9.194737030967467e-05
Trained batch 184 in epoch 11, gen_loss = 1.4317156843236976, disc_loss = 9.25531866635759e-05
Trained batch 185 in epoch 11, gen_loss = 1.4316166459873159, disc_loss = 9.31913570287091e-05
Trained batch 186 in epoch 11, gen_loss = 1.4316862075724066, disc_loss = 9.369586404741531e-05
Trained batch 187 in epoch 11, gen_loss = 1.4317388065317844, disc_loss = 9.4174200381879e-05
Trained batch 188 in epoch 11, gen_loss = 1.4316976701141035, disc_loss = 9.45895297687101e-05
Trained batch 189 in epoch 11, gen_loss = 1.4318021322551526, disc_loss = 9.503454702050811e-05
Trained batch 190 in epoch 11, gen_loss = 1.4318589109400803, disc_loss = 9.54637386679088e-05
Trained batch 191 in epoch 11, gen_loss = 1.4319229933122795, disc_loss = 9.61294249606226e-05
Trained batch 192 in epoch 11, gen_loss = 1.4317660862917727, disc_loss = 9.661445539130876e-05
Trained batch 193 in epoch 11, gen_loss = 1.431468533486435, disc_loss = 9.699287083441453e-05
Trained batch 194 in epoch 11, gen_loss = 1.4313361387986403, disc_loss = 9.725483065640453e-05
Trained batch 195 in epoch 11, gen_loss = 1.4315672036336393, disc_loss = 9.731308998606418e-05
Trained batch 196 in epoch 11, gen_loss = 1.431716575840403, disc_loss = 9.728173551182612e-05
Trained batch 197 in epoch 11, gen_loss = 1.4320772332374496, disc_loss = 9.732825082200997e-05
Trained batch 198 in epoch 11, gen_loss = 1.4321426290962564, disc_loss = 9.728770768944842e-05
Trained batch 199 in epoch 11, gen_loss = 1.4320307487249375, disc_loss = 9.729659328058915e-05
Trained batch 200 in epoch 11, gen_loss = 1.4319498912612003, disc_loss = 9.723845508672264e-05
Trained batch 201 in epoch 11, gen_loss = 1.4316033083613555, disc_loss = 9.719388885564018e-05
Trained batch 202 in epoch 11, gen_loss = 1.431485661732152, disc_loss = 9.712861948832267e-05
Trained batch 203 in epoch 11, gen_loss = 1.4310859137890386, disc_loss = 9.704669535084595e-05
Trained batch 204 in epoch 11, gen_loss = 1.4315595754762975, disc_loss = 9.69589121557031e-05
Trained batch 205 in epoch 11, gen_loss = 1.4314988024026445, disc_loss = 9.693365054595984e-05
Trained batch 206 in epoch 11, gen_loss = 1.4311633305849085, disc_loss = 9.694014982190878e-05
Trained batch 207 in epoch 11, gen_loss = 1.431232118835816, disc_loss = 9.687635175098946e-05
Trained batch 208 in epoch 11, gen_loss = 1.4311404114134574, disc_loss = 9.686723426588044e-05
Trained batch 209 in epoch 11, gen_loss = 1.430895453407651, disc_loss = 9.694918963716537e-05
Trained batch 210 in epoch 11, gen_loss = 1.4307842960854842, disc_loss = 9.707686975644543e-05
Trained batch 211 in epoch 11, gen_loss = 1.4309786732466716, disc_loss = 9.723381170277996e-05
Trained batch 212 in epoch 11, gen_loss = 1.4309254022831088, disc_loss = 9.734656696779377e-05
Trained batch 213 in epoch 11, gen_loss = 1.4311710612796178, disc_loss = 9.753089844818073e-05
Trained batch 214 in epoch 11, gen_loss = 1.4315309180769809, disc_loss = 9.765210511960863e-05
Trained batch 215 in epoch 11, gen_loss = 1.431549713567451, disc_loss = 9.764799403068605e-05
Trained batch 216 in epoch 11, gen_loss = 1.4320571521460186, disc_loss = 9.754427769893973e-05
Trained batch 217 in epoch 11, gen_loss = 1.4322338295639108, disc_loss = 9.735262091695454e-05
Trained batch 218 in epoch 11, gen_loss = 1.4321590182988067, disc_loss = 9.716541443673812e-05
Trained batch 219 in epoch 11, gen_loss = 1.4319326823407954, disc_loss = 9.690881145781366e-05
Trained batch 220 in epoch 11, gen_loss = 1.4320205077866084, disc_loss = 9.663417796420362e-05
Trained batch 221 in epoch 11, gen_loss = 1.43203413808668, disc_loss = 9.646700683079617e-05
Trained batch 222 in epoch 11, gen_loss = 1.4320433685063247, disc_loss = 9.637824417860743e-05
Trained batch 223 in epoch 11, gen_loss = 1.4321965468781335, disc_loss = 9.629284925186507e-05
Trained batch 224 in epoch 11, gen_loss = 1.4318065367804633, disc_loss = 9.620587386355813e-05
Trained batch 225 in epoch 11, gen_loss = 1.4315953244150212, disc_loss = 9.623451713163924e-05
Trained batch 226 in epoch 11, gen_loss = 1.4317251890241312, disc_loss = 9.652241762908405e-05
Trained batch 227 in epoch 11, gen_loss = 1.4319676892799245, disc_loss = 9.701785092019826e-05
Trained batch 228 in epoch 11, gen_loss = 1.4317277222221074, disc_loss = 9.74123776831812e-05
Trained batch 229 in epoch 11, gen_loss = 1.4317089858262435, disc_loss = 9.778803419660265e-05
Trained batch 230 in epoch 11, gen_loss = 1.4315179591571099, disc_loss = 9.817637400575021e-05
Trained batch 231 in epoch 11, gen_loss = 1.4315623024414326, disc_loss = 9.862159781497557e-05
Trained batch 232 in epoch 11, gen_loss = 1.4313510042403388, disc_loss = 9.90655223758481e-05
Trained batch 233 in epoch 11, gen_loss = 1.4314241190241952, disc_loss = 9.962589518523663e-05
Trained batch 234 in epoch 11, gen_loss = 1.431414997831304, disc_loss = 9.995179471514618e-05
Trained batch 235 in epoch 11, gen_loss = 1.4313762768850489, disc_loss = 0.00010012289545418259
Trained batch 236 in epoch 11, gen_loss = 1.431545130814178, disc_loss = 0.00010029022559510197
Trained batch 237 in epoch 11, gen_loss = 1.4316886653419303, disc_loss = 0.00010029768269809775
Trained batch 238 in epoch 11, gen_loss = 1.4316707166168978, disc_loss = 0.00010008645234672741
Trained batch 239 in epoch 11, gen_loss = 1.431450866162777, disc_loss = 9.983811729625813e-05
Trained batch 240 in epoch 11, gen_loss = 1.4319668726307722, disc_loss = 9.955936526556386e-05
Trained batch 241 in epoch 11, gen_loss = 1.4317968926153892, disc_loss = 9.925152835421613e-05
Trained batch 242 in epoch 11, gen_loss = 1.431619026042797, disc_loss = 9.895222193624134e-05
Trained batch 243 in epoch 11, gen_loss = 1.4314827816408189, disc_loss = 9.868228583728211e-05
Trained batch 244 in epoch 11, gen_loss = 1.4314535238304917, disc_loss = 9.843670049660283e-05
Trained batch 245 in epoch 11, gen_loss = 1.4310286825265341, disc_loss = 9.818091775298121e-05
Trained batch 246 in epoch 11, gen_loss = 1.4308293140851533, disc_loss = 9.797005939411319e-05
Trained batch 247 in epoch 11, gen_loss = 1.4310429783598069, disc_loss = 9.781625806226657e-05
Trained batch 248 in epoch 11, gen_loss = 1.4310673245464463, disc_loss = 9.773407486041454e-05
Trained batch 249 in epoch 11, gen_loss = 1.4309097170829772, disc_loss = 9.760668195303878e-05
Trained batch 250 in epoch 11, gen_loss = 1.431036055325512, disc_loss = 9.740739642438712e-05
Trained batch 251 in epoch 11, gen_loss = 1.4308115541934967, disc_loss = 9.720855931095323e-05
Trained batch 252 in epoch 11, gen_loss = 1.4306934228527688, disc_loss = 9.706392307570107e-05
Trained batch 253 in epoch 11, gen_loss = 1.4309624250479571, disc_loss = 9.697862825613431e-05
Trained batch 254 in epoch 11, gen_loss = 1.4311445876663806, disc_loss = 9.6995880145793e-05
Trained batch 255 in epoch 11, gen_loss = 1.4311719257384539, disc_loss = 9.714482740363906e-05
Trained batch 256 in epoch 11, gen_loss = 1.431107352215956, disc_loss = 9.738352922377868e-05
Trained batch 257 in epoch 11, gen_loss = 1.431077076945194, disc_loss = 9.775124048838883e-05
Trained batch 258 in epoch 11, gen_loss = 1.4309651616917614, disc_loss = 9.839317490648218e-05
Trained batch 259 in epoch 11, gen_loss = 1.4309604213787959, disc_loss = 9.864361613836082e-05
Trained batch 260 in epoch 11, gen_loss = 1.4310488065997302, disc_loss = 9.868253575502676e-05
Trained batch 261 in epoch 11, gen_loss = 1.4310790637067257, disc_loss = 9.863647565414808e-05
Trained batch 262 in epoch 11, gen_loss = 1.4308433423930702, disc_loss = 9.874781296652553e-05
Trained batch 263 in epoch 11, gen_loss = 1.4307798847104565, disc_loss = 9.907853786967969e-05
Trained batch 264 in epoch 11, gen_loss = 1.4305885526369202, disc_loss = 9.962532711245519e-05
Trained batch 265 in epoch 11, gen_loss = 1.4305928250900786, disc_loss = 0.00010040468445490968
Trained batch 266 in epoch 11, gen_loss = 1.4306278791320457, disc_loss = 0.00010156654493567906
Trained batch 267 in epoch 11, gen_loss = 1.43058910120779, disc_loss = 0.00010311808773961397
Trained batch 268 in epoch 11, gen_loss = 1.4305658681685154, disc_loss = 0.00010517883557444036
Trained batch 269 in epoch 11, gen_loss = 1.4304405865845857, disc_loss = 0.00010770005973999678
Trained batch 270 in epoch 11, gen_loss = 1.4302978533220467, disc_loss = 0.0001103944423314168
Trained batch 271 in epoch 11, gen_loss = 1.4304692736443352, disc_loss = 0.00011327598731641581
Trained batch 272 in epoch 11, gen_loss = 1.4306498482113792, disc_loss = 0.00011612362577779804
Trained batch 273 in epoch 11, gen_loss = 1.4304783405178654, disc_loss = 0.00011890961316759493
Trained batch 274 in epoch 11, gen_loss = 1.4302062034606933, disc_loss = 0.00012160899014071964
Trained batch 275 in epoch 11, gen_loss = 1.4300794899463654, disc_loss = 0.00012390757301611723
Trained batch 276 in epoch 11, gen_loss = 1.429914260599157, disc_loss = 0.00012548473734851057
Trained batch 277 in epoch 11, gen_loss = 1.4298518197141963, disc_loss = 0.00012649753151687928
Trained batch 278 in epoch 11, gen_loss = 1.4297985654577987, disc_loss = 0.0001271618489699643
Trained batch 279 in epoch 11, gen_loss = 1.4297770764146531, disc_loss = 0.00012758384049383104
Trained batch 280 in epoch 11, gen_loss = 1.429647115625945, disc_loss = 0.00012782880397760736
Trained batch 281 in epoch 11, gen_loss = 1.4296779941159783, disc_loss = 0.0001280069406533559
Trained batch 282 in epoch 11, gen_loss = 1.4297755944012753, disc_loss = 0.00012815859917227434
Trained batch 283 in epoch 11, gen_loss = 1.4299095142895066, disc_loss = 0.00012822942150552067
Trained batch 284 in epoch 11, gen_loss = 1.4298557310773616, disc_loss = 0.00012813122695597324
Trained batch 285 in epoch 11, gen_loss = 1.4298347226389638, disc_loss = 0.0001279387236447381
Trained batch 286 in epoch 11, gen_loss = 1.4300112313094455, disc_loss = 0.00012770754952909637
Trained batch 287 in epoch 11, gen_loss = 1.4301949710481696, disc_loss = 0.0001275109025268901
Trained batch 288 in epoch 11, gen_loss = 1.4299904153421263, disc_loss = 0.00012726273727387244
Trained batch 289 in epoch 11, gen_loss = 1.4300756063954583, disc_loss = 0.0001269558635393533
Trained batch 290 in epoch 11, gen_loss = 1.4302354825730996, disc_loss = 0.0001267171139161323
Trained batch 291 in epoch 11, gen_loss = 1.430127058535406, disc_loss = 0.00012650947058144284
Trained batch 292 in epoch 11, gen_loss = 1.4300528553158758, disc_loss = 0.0001263148652305165
Trained batch 293 in epoch 11, gen_loss = 1.4299136939502897, disc_loss = 0.00012613804275832724
Trained batch 294 in epoch 11, gen_loss = 1.4297746549218389, disc_loss = 0.00012601677097922283
Trained batch 295 in epoch 11, gen_loss = 1.4299862767393525, disc_loss = 0.00012591702263639368
Trained batch 296 in epoch 11, gen_loss = 1.4298967556519941, disc_loss = 0.00012580038514514968
Trained batch 297 in epoch 11, gen_loss = 1.430277226355252, disc_loss = 0.0001259187305665834
Trained batch 298 in epoch 11, gen_loss = 1.4303995147596633, disc_loss = 0.00012573203872781724
Trained batch 299 in epoch 11, gen_loss = 1.4305151800314586, disc_loss = 0.00012559827876430064
Trained batch 300 in epoch 11, gen_loss = 1.4304815202060333, disc_loss = 0.0001253595300720712
Trained batch 301 in epoch 11, gen_loss = 1.4305314125604187, disc_loss = 0.00012506147398301057
Trained batch 302 in epoch 11, gen_loss = 1.4303766445751631, disc_loss = 0.0001248028003840956
Trained batch 303 in epoch 11, gen_loss = 1.4304956158525066, disc_loss = 0.00012451863611766769
Trained batch 304 in epoch 11, gen_loss = 1.4305865623911873, disc_loss = 0.00012422553585357028
Trained batch 305 in epoch 11, gen_loss = 1.4305699946833592, disc_loss = 0.00012393563372444714
Trained batch 306 in epoch 11, gen_loss = 1.4304970530034664, disc_loss = 0.00012366044135831645
Trained batch 307 in epoch 11, gen_loss = 1.4304845263431598, disc_loss = 0.00012337626374680333
Trained batch 308 in epoch 11, gen_loss = 1.430607896020883, disc_loss = 0.00012310888379360425
Trained batch 309 in epoch 11, gen_loss = 1.430588150024414, disc_loss = 0.00012289344007982553
Trained batch 310 in epoch 11, gen_loss = 1.430539021154692, disc_loss = 0.00012271405717513244
Trained batch 311 in epoch 11, gen_loss = 1.430462238498223, disc_loss = 0.0001225698795369914
Trained batch 312 in epoch 11, gen_loss = 1.4306603791995551, disc_loss = 0.0001225002197519318
Trained batch 313 in epoch 11, gen_loss = 1.430418215359852, disc_loss = 0.0001224500846037236
Trained batch 314 in epoch 11, gen_loss = 1.430539371475341, disc_loss = 0.00012241513620485044
Trained batch 315 in epoch 11, gen_loss = 1.4305054975461355, disc_loss = 0.00012229967170311238
Trained batch 316 in epoch 11, gen_loss = 1.4305033604805402, disc_loss = 0.00012219788305551288
Trained batch 317 in epoch 11, gen_loss = 1.430694194334858, disc_loss = 0.00012216325706692756
Trained batch 318 in epoch 11, gen_loss = 1.4305250794162572, disc_loss = 0.00012213226440234448
Trained batch 319 in epoch 11, gen_loss = 1.4307208899408579, disc_loss = 0.00012208684972563332
Trained batch 320 in epoch 11, gen_loss = 1.4307693647818402, disc_loss = 0.00012203209211848473
Trained batch 321 in epoch 11, gen_loss = 1.4306965074183777, disc_loss = 0.00012193519272197524
Trained batch 322 in epoch 11, gen_loss = 1.4308007305989694, disc_loss = 0.00012181069785966476
Trained batch 323 in epoch 11, gen_loss = 1.4305962997454185, disc_loss = 0.00012167740984284732
Trained batch 324 in epoch 11, gen_loss = 1.4306847546650814, disc_loss = 0.00012157680638875508
Trained batch 325 in epoch 11, gen_loss = 1.4306171562042704, disc_loss = 0.00012144696516112229
Trained batch 326 in epoch 11, gen_loss = 1.4306880104432411, disc_loss = 0.00012127037778566076
Trained batch 327 in epoch 11, gen_loss = 1.4307877323249492, disc_loss = 0.00012107122016714572
Trained batch 328 in epoch 11, gen_loss = 1.4306307868029933, disc_loss = 0.00012087349711821713
Trained batch 329 in epoch 11, gen_loss = 1.430762978033586, disc_loss = 0.0001206726914819173
Trained batch 330 in epoch 11, gen_loss = 1.4307966030616415, disc_loss = 0.00012053672468533378
Trained batch 331 in epoch 11, gen_loss = 1.4306595347013817, disc_loss = 0.00012048767850052195
Trained batch 332 in epoch 11, gen_loss = 1.430558226846002, disc_loss = 0.00012046438338735904
Trained batch 333 in epoch 11, gen_loss = 1.4306280877061948, disc_loss = 0.0001204004896574256
Trained batch 334 in epoch 11, gen_loss = 1.4304903336425325, disc_loss = 0.0001203034209701495
Trained batch 335 in epoch 11, gen_loss = 1.430559940636158, disc_loss = 0.00012012227714259487
Trained batch 336 in epoch 11, gen_loss = 1.4304881941317098, disc_loss = 0.00011987211715294175
Trained batch 337 in epoch 11, gen_loss = 1.4304207506969835, disc_loss = 0.00011958053690078169
Trained batch 338 in epoch 11, gen_loss = 1.430425510997266, disc_loss = 0.00011931877765389607
Trained batch 339 in epoch 11, gen_loss = 1.4305197466822233, disc_loss = 0.00011908843637363187
Trained batch 340 in epoch 11, gen_loss = 1.4304451872526376, disc_loss = 0.00011882223416490824
Trained batch 341 in epoch 11, gen_loss = 1.4305722741355673, disc_loss = 0.00011857248024990063
Trained batch 342 in epoch 11, gen_loss = 1.4309365839721857, disc_loss = 0.00011835858573997172
Trained batch 343 in epoch 11, gen_loss = 1.4308163118223811, disc_loss = 0.00011815874427421202
Trained batch 344 in epoch 11, gen_loss = 1.4307581690774447, disc_loss = 0.0001179048833153607
Trained batch 345 in epoch 11, gen_loss = 1.4306344968735139, disc_loss = 0.00011762070990788076
Trained batch 346 in epoch 11, gen_loss = 1.4306073910221242, disc_loss = 0.00011736769031076802
Trained batch 347 in epoch 11, gen_loss = 1.4305664427664089, disc_loss = 0.00011716531669965964
Trained batch 348 in epoch 11, gen_loss = 1.4306407487153323, disc_loss = 0.0001169607326575199
Trained batch 349 in epoch 11, gen_loss = 1.4307011079788208, disc_loss = 0.0001167178080114744
Trained batch 350 in epoch 11, gen_loss = 1.4307233261586594, disc_loss = 0.00011648588545532632
Trained batch 351 in epoch 11, gen_loss = 1.4306628030132165, disc_loss = 0.00011643420577136318
Trained batch 352 in epoch 11, gen_loss = 1.430548105631604, disc_loss = 0.00011651152616941648
Trained batch 353 in epoch 11, gen_loss = 1.4307635248044117, disc_loss = 0.00011650556707330916
Trained batch 354 in epoch 11, gen_loss = 1.4305983291545383, disc_loss = 0.00011638534306001302
Trained batch 355 in epoch 11, gen_loss = 1.4307752234882183, disc_loss = 0.00011621758280239958
Trained batch 356 in epoch 11, gen_loss = 1.4306276121727224, disc_loss = 0.00011607169396308312
Trained batch 357 in epoch 11, gen_loss = 1.4306283020440427, disc_loss = 0.00011595025125643588
Trained batch 358 in epoch 11, gen_loss = 1.4305524201778317, disc_loss = 0.00011593474582214869
Trained batch 359 in epoch 11, gen_loss = 1.4303919080230925, disc_loss = 0.00011588457119968452
Trained batch 360 in epoch 11, gen_loss = 1.4305345064385115, disc_loss = 0.00011575856063943605
Trained batch 361 in epoch 11, gen_loss = 1.4306569194925425, disc_loss = 0.00011555945519634889
Trained batch 362 in epoch 11, gen_loss = 1.4305849259221521, disc_loss = 0.0001153405107561662
Trained batch 363 in epoch 11, gen_loss = 1.4305780294177297, disc_loss = 0.00011510067332852527
Trained batch 364 in epoch 11, gen_loss = 1.4305311960716771, disc_loss = 0.00011487900054356169
Trained batch 365 in epoch 11, gen_loss = 1.4304939003590027, disc_loss = 0.00011463737257413488
Trained batch 366 in epoch 11, gen_loss = 1.4306032784303462, disc_loss = 0.00011443009147516402
Trained batch 367 in epoch 11, gen_loss = 1.4304383643295453, disc_loss = 0.00011427718226286743
Trained batch 368 in epoch 11, gen_loss = 1.4304399070377918, disc_loss = 0.00011422811440089393
Trained batch 369 in epoch 11, gen_loss = 1.4304526335484273, disc_loss = 0.00011429835699714572
Trained batch 370 in epoch 11, gen_loss = 1.4303719990979629, disc_loss = 0.0001144662721633776
Trained batch 371 in epoch 11, gen_loss = 1.4304776502552854, disc_loss = 0.00011476691616657244
Trained batch 372 in epoch 11, gen_loss = 1.430651520596113, disc_loss = 0.00011525084676214225
Trained batch 373 in epoch 11, gen_loss = 1.430456915959955, disc_loss = 0.00011583443366230872
Trained batch 374 in epoch 11, gen_loss = 1.4301668221155803, disc_loss = 0.00011651172505662544
Trained batch 375 in epoch 11, gen_loss = 1.430204246272432, disc_loss = 0.00011725652819542177
Trained batch 376 in epoch 11, gen_loss = 1.4302077751893263, disc_loss = 0.00011795107863162318
Trained batch 377 in epoch 11, gen_loss = 1.4301133165283808, disc_loss = 0.00011870341663707799
Trained batch 378 in epoch 11, gen_loss = 1.430077014623657, disc_loss = 0.0001194463070112996
Trained batch 379 in epoch 11, gen_loss = 1.4302923142910005, disc_loss = 0.00012033849543752838
Trained batch 380 in epoch 11, gen_loss = 1.4302818562415016, disc_loss = 0.0001215385144122571
Trained batch 381 in epoch 11, gen_loss = 1.4304084075683074, disc_loss = 0.00012306864421812928
Trained batch 382 in epoch 11, gen_loss = 1.4303873578188624, disc_loss = 0.00012489392336091472
Trained batch 383 in epoch 11, gen_loss = 1.4302283705522616, disc_loss = 0.00012707354389599837
Trained batch 384 in epoch 11, gen_loss = 1.43014012435814, disc_loss = 0.0001297494134373015
Trained batch 385 in epoch 11, gen_loss = 1.43020899153744, disc_loss = 0.00013272165736080455
Trained batch 386 in epoch 11, gen_loss = 1.4301133697963193, disc_loss = 0.00013540135356280618
Trained batch 387 in epoch 11, gen_loss = 1.4301567341863495, disc_loss = 0.0001376986026805509
Trained batch 388 in epoch 11, gen_loss = 1.4300007112228472, disc_loss = 0.00013925400161237715
Trained batch 389 in epoch 11, gen_loss = 1.4301121561955183, disc_loss = 0.00014000036045940642
Trained batch 390 in epoch 11, gen_loss = 1.429997806049064, disc_loss = 0.00014023101242776687
Trained batch 391 in epoch 11, gen_loss = 1.4299721006228, disc_loss = 0.0001402152742420352
Trained batch 392 in epoch 11, gen_loss = 1.43001688345698, disc_loss = 0.00014012783042168314
Trained batch 393 in epoch 11, gen_loss = 1.4300672905094127, disc_loss = 0.0001399761277697586
Trained batch 394 in epoch 11, gen_loss = 1.4300134743316264, disc_loss = 0.00013979555367054844
Trained batch 395 in epoch 11, gen_loss = 1.4301710393693712, disc_loss = 0.0001396524397257577
Trained batch 396 in epoch 11, gen_loss = 1.4301634381339892, disc_loss = 0.0001395493115091021
Trained batch 397 in epoch 11, gen_loss = 1.430251117926746, disc_loss = 0.00013937002068270895
Trained batch 398 in epoch 11, gen_loss = 1.4301253542266692, disc_loss = 0.00013911768851620056
Trained batch 399 in epoch 11, gen_loss = 1.430243115723133, disc_loss = 0.000138873424796202
Trained batch 400 in epoch 11, gen_loss = 1.4304276511556193, disc_loss = 0.0001386574676848852
Trained batch 401 in epoch 11, gen_loss = 1.4303129875837868, disc_loss = 0.00013853958523951356
Trained batch 402 in epoch 11, gen_loss = 1.4302321024627307, disc_loss = 0.00013839688443555455
Trained batch 403 in epoch 11, gen_loss = 1.4300872152394588, disc_loss = 0.00013823249238643852
Trained batch 404 in epoch 11, gen_loss = 1.4300603304380253, disc_loss = 0.00013801202135648144
Trained batch 405 in epoch 11, gen_loss = 1.4301107320292243, disc_loss = 0.0001377606426968431
Trained batch 406 in epoch 11, gen_loss = 1.4299892450726295, disc_loss = 0.000137516981905375
Trained batch 407 in epoch 11, gen_loss = 1.4300557103227167, disc_loss = 0.000137262510707735
Trained batch 408 in epoch 11, gen_loss = 1.4300740753234453, disc_loss = 0.00013701934416028447
Trained batch 409 in epoch 11, gen_loss = 1.4301047857214766, disc_loss = 0.00013675830742813116
Trained batch 410 in epoch 11, gen_loss = 1.4302285578999205, disc_loss = 0.00013649824930750724
Trained batch 411 in epoch 11, gen_loss = 1.4303014848417448, disc_loss = 0.00013626515044175833
Trained batch 412 in epoch 11, gen_loss = 1.4304325156292672, disc_loss = 0.00013603060792786079
Trained batch 413 in epoch 11, gen_loss = 1.430348915754309, disc_loss = 0.00013575239268762208
Trained batch 414 in epoch 11, gen_loss = 1.430355269650379, disc_loss = 0.00013552695806746593
Trained batch 415 in epoch 11, gen_loss = 1.4302837493327947, disc_loss = 0.00013534520783327236
Trained batch 416 in epoch 11, gen_loss = 1.4301966946187923, disc_loss = 0.0001351564138810276
Trained batch 417 in epoch 11, gen_loss = 1.430163549464285, disc_loss = 0.00013495205371001382
Trained batch 418 in epoch 11, gen_loss = 1.4299873255886724, disc_loss = 0.00013471791607635536
Trained batch 419 in epoch 11, gen_loss = 1.4300603358518509, disc_loss = 0.0001345613763879512
Trained batch 420 in epoch 11, gen_loss = 1.4302209080539803, disc_loss = 0.00013434901483208114
Trained batch 421 in epoch 11, gen_loss = 1.4304197580328484, disc_loss = 0.00013416593110895264
Trained batch 422 in epoch 11, gen_loss = 1.4305719571192497, disc_loss = 0.00013398190791298343
Trained batch 423 in epoch 11, gen_loss = 1.430690050968584, disc_loss = 0.00013391397182984738
Trained batch 424 in epoch 11, gen_loss = 1.4307112870496863, disc_loss = 0.00013393811657057514
Trained batch 425 in epoch 11, gen_loss = 1.4304358021754053, disc_loss = 0.00013407443408619494
Trained batch 426 in epoch 11, gen_loss = 1.430439097540719, disc_loss = 0.0001342670207453009
Trained batch 427 in epoch 11, gen_loss = 1.4305376505183283, disc_loss = 0.00013453081910866387
Trained batch 428 in epoch 11, gen_loss = 1.430514944183243, disc_loss = 0.00013478530549554092
Trained batch 429 in epoch 11, gen_loss = 1.4306077028429784, disc_loss = 0.0001349976438050785
Trained batch 430 in epoch 11, gen_loss = 1.4306831736022525, disc_loss = 0.00013517786460091495
Trained batch 431 in epoch 11, gen_loss = 1.4308348046960655, disc_loss = 0.00013537745839660906
Trained batch 432 in epoch 11, gen_loss = 1.4308187050301815, disc_loss = 0.00013564741315702113
Trained batch 433 in epoch 11, gen_loss = 1.43084006210626, disc_loss = 0.00013602000819848759
Trained batch 434 in epoch 11, gen_loss = 1.430861952113009, disc_loss = 0.0001365139610922712
Trained batch 435 in epoch 11, gen_loss = 1.4309218017333145, disc_loss = 0.00013715488758328178
Trained batch 436 in epoch 11, gen_loss = 1.4311356800917356, disc_loss = 0.0001378462528683866
Trained batch 437 in epoch 11, gen_loss = 1.4312136733912986, disc_loss = 0.00013858192419964109
Trained batch 438 in epoch 11, gen_loss = 1.4311942035896632, disc_loss = 0.00013926267428585826
Trained batch 439 in epoch 11, gen_loss = 1.4311424347487363, disc_loss = 0.0001399091111683116
Trained batch 440 in epoch 11, gen_loss = 1.431097951876063, disc_loss = 0.00014038012739840265
Trained batch 441 in epoch 11, gen_loss = 1.431162445253916, disc_loss = 0.00014070578724768723
Trained batch 442 in epoch 11, gen_loss = 1.4311922417268257, disc_loss = 0.0001408998188038921
Trained batch 443 in epoch 11, gen_loss = 1.4311345592812375, disc_loss = 0.00014093748863824412
Trained batch 444 in epoch 11, gen_loss = 1.430961610761921, disc_loss = 0.00014081474877702623
Trained batch 445 in epoch 11, gen_loss = 1.4308998822631323, disc_loss = 0.000140652819620724
Trained batch 446 in epoch 11, gen_loss = 1.4309686241000557, disc_loss = 0.0001404508517282593
Trained batch 447 in epoch 11, gen_loss = 1.4309124033898115, disc_loss = 0.00014025667300034326
Trained batch 448 in epoch 11, gen_loss = 1.4309179737732511, disc_loss = 0.00014011973010592008
Trained batch 449 in epoch 11, gen_loss = 1.4308783666292826, disc_loss = 0.0001399962741298724
Trained batch 450 in epoch 11, gen_loss = 1.4308875230886455, disc_loss = 0.00014005004430513098
Trained batch 451 in epoch 11, gen_loss = 1.4308870590366094, disc_loss = 0.00013991975657292834
Trained batch 452 in epoch 11, gen_loss = 1.4308072796983697, disc_loss = 0.00013978756646240923
Trained batch 453 in epoch 11, gen_loss = 1.4308760840987318, disc_loss = 0.0001396349220827399
Trained batch 454 in epoch 11, gen_loss = 1.4308710137566367, disc_loss = 0.00013948601414825304
Trained batch 455 in epoch 11, gen_loss = 1.4308120982165922, disc_loss = 0.00013936506613127246
Trained batch 456 in epoch 11, gen_loss = 1.4308631271449952, disc_loss = 0.0001392125748309807
Trained batch 457 in epoch 11, gen_loss = 1.4308111506258037, disc_loss = 0.000138999775032165
Trained batch 458 in epoch 11, gen_loss = 1.4308664710433394, disc_loss = 0.00013877112204660111
Trained batch 459 in epoch 11, gen_loss = 1.4309604375258735, disc_loss = 0.00013854279595959626
Trained batch 460 in epoch 11, gen_loss = 1.4307840685006594, disc_loss = 0.00013830074401998297
Trained batch 461 in epoch 11, gen_loss = 1.4306558115141732, disc_loss = 0.00013805355976602616
Trained batch 462 in epoch 11, gen_loss = 1.4306718759866306, disc_loss = 0.0001378212742412446
Trained batch 463 in epoch 11, gen_loss = 1.4306469433780373, disc_loss = 0.0001376107636921351
Trained batch 464 in epoch 11, gen_loss = 1.4306177769937822, disc_loss = 0.00013745607085056887
Trained batch 465 in epoch 11, gen_loss = 1.4306011726927859, disc_loss = 0.000137314475367317
Trained batch 466 in epoch 11, gen_loss = 1.4305841350963846, disc_loss = 0.0001372233779974711
Trained batch 467 in epoch 11, gen_loss = 1.4304590332202423, disc_loss = 0.00013722245548278728
Trained batch 468 in epoch 11, gen_loss = 1.4303679778885994, disc_loss = 0.00013728923343561913
Trained batch 469 in epoch 11, gen_loss = 1.4303456653939917, disc_loss = 0.00013721809515079665
Trained batch 470 in epoch 11, gen_loss = 1.4303870158084133, disc_loss = 0.0001371283306360484
Trained batch 471 in epoch 11, gen_loss = 1.430266129515939, disc_loss = 0.00013707745567205428
Trained batch 472 in epoch 11, gen_loss = 1.4303067436177936, disc_loss = 0.0001371754121808804
Trained batch 473 in epoch 11, gen_loss = 1.4302194103409973, disc_loss = 0.00013726817804487495
Trained batch 474 in epoch 11, gen_loss = 1.4300701394834017, disc_loss = 0.00013736575750954215
Trained batch 475 in epoch 11, gen_loss = 1.4301268080202472, disc_loss = 0.00013745439842299857
Trained batch 476 in epoch 11, gen_loss = 1.430198430015356, disc_loss = 0.00013747293233606474
Trained batch 477 in epoch 11, gen_loss = 1.4300303596332982, disc_loss = 0.0001376332785512052
Trained batch 478 in epoch 11, gen_loss = 1.4299299702017192, disc_loss = 0.00013780383687464986
Trained batch 479 in epoch 11, gen_loss = 1.4299795597791671, disc_loss = 0.00013782020864141486
Trained batch 480 in epoch 11, gen_loss = 1.42997894911657, disc_loss = 0.00013773434486528705
Trained batch 481 in epoch 11, gen_loss = 1.429972993387721, disc_loss = 0.00013765020052557562
Trained batch 482 in epoch 11, gen_loss = 1.4298574341997103, disc_loss = 0.00013754196499941515
Trained batch 483 in epoch 11, gen_loss = 1.430087613665368, disc_loss = 0.00013736714974155734
Trained batch 484 in epoch 11, gen_loss = 1.4301661555300054, disc_loss = 0.00013714141143432196
Trained batch 485 in epoch 11, gen_loss = 1.4300591592435483, disc_loss = 0.00013694031594926024
Trained batch 486 in epoch 11, gen_loss = 1.4301951254662546, disc_loss = 0.00013678224242775038
Trained batch 487 in epoch 11, gen_loss = 1.4302104054415812, disc_loss = 0.00013663505460238516
Trained batch 488 in epoch 11, gen_loss = 1.4303186276207673, disc_loss = 0.00013651738527280257
Trained batch 489 in epoch 11, gen_loss = 1.4304279492825878, disc_loss = 0.00013637798937990588
Trained batch 490 in epoch 11, gen_loss = 1.4304240551111411, disc_loss = 0.00013621264590845075
Trained batch 491 in epoch 11, gen_loss = 1.4302321396222928, disc_loss = 0.0001360560658438742
Trained batch 492 in epoch 11, gen_loss = 1.4302391246656376, disc_loss = 0.00013589615704197804
Trained batch 493 in epoch 11, gen_loss = 1.4302801974871864, disc_loss = 0.00013573180495558729
Trained batch 494 in epoch 11, gen_loss = 1.4302577779750631, disc_loss = 0.00013558318106802428
Trained batch 495 in epoch 11, gen_loss = 1.4301548636248034, disc_loss = 0.00013546722554690037
Trained batch 496 in epoch 11, gen_loss = 1.4301427595572214, disc_loss = 0.00013530202348419605
Trained batch 497 in epoch 11, gen_loss = 1.4301965715415985, disc_loss = 0.00013513588594807414
Trained batch 498 in epoch 11, gen_loss = 1.4303056868857038, disc_loss = 0.00013498178225586935
Trained batch 499 in epoch 11, gen_loss = 1.4302216653823852, disc_loss = 0.00013482309760911448
Trained batch 500 in epoch 11, gen_loss = 1.430255370225735, disc_loss = 0.00013463729971487036
Trained batch 501 in epoch 11, gen_loss = 1.4304496873897385, disc_loss = 0.00013441241165118158
Trained batch 502 in epoch 11, gen_loss = 1.4304028140384681, disc_loss = 0.00013416724016698816
Trained batch 503 in epoch 11, gen_loss = 1.4303600331620565, disc_loss = 0.00013392669659027426
Trained batch 504 in epoch 11, gen_loss = 1.4302668762679147, disc_loss = 0.00013370122862109538
Trained batch 505 in epoch 11, gen_loss = 1.4302202559742532, disc_loss = 0.0001335045980027759
Trained batch 506 in epoch 11, gen_loss = 1.430229363121695, disc_loss = 0.00013330308225216423
Trained batch 507 in epoch 11, gen_loss = 1.4303372361528592, disc_loss = 0.00013309044760266204
Trained batch 508 in epoch 11, gen_loss = 1.430369583000603, disc_loss = 0.00013287573009332566
Trained batch 509 in epoch 11, gen_loss = 1.4303205109110066, disc_loss = 0.00013264887602774394
Trained batch 510 in epoch 11, gen_loss = 1.4302260196838827, disc_loss = 0.0001324122926156537
Trained batch 511 in epoch 11, gen_loss = 1.4301827128510922, disc_loss = 0.00013219204079284452
Trained batch 512 in epoch 11, gen_loss = 1.4302594415393257, disc_loss = 0.00013196706614467226
Trained batch 513 in epoch 11, gen_loss = 1.4302183531137755, disc_loss = 0.0001317378424212723
Trained batch 514 in epoch 11, gen_loss = 1.430062653486011, disc_loss = 0.000131544061796994
Trained batch 515 in epoch 11, gen_loss = 1.4300963502059612, disc_loss = 0.0001313964090309304
Trained batch 516 in epoch 11, gen_loss = 1.4300474218980948, disc_loss = 0.00013128445764354045
Trained batch 517 in epoch 11, gen_loss = 1.429953436363618, disc_loss = 0.00013119281036315757
Trained batch 518 in epoch 11, gen_loss = 1.4298844845079044, disc_loss = 0.00013114053722618928
Trained batch 519 in epoch 11, gen_loss = 1.4297926414471407, disc_loss = 0.0001311056737729534
Trained batch 520 in epoch 11, gen_loss = 1.429739553045174, disc_loss = 0.0001310737288472698
Trained batch 521 in epoch 11, gen_loss = 1.4296069478623255, disc_loss = 0.0001310320179271358
Trained batch 522 in epoch 11, gen_loss = 1.4296030373691828, disc_loss = 0.00013097150706510566
Trained batch 523 in epoch 11, gen_loss = 1.4296061492148247, disc_loss = 0.00013090576216658352
Trained batch 524 in epoch 11, gen_loss = 1.4296336596352714, disc_loss = 0.00013081363633405307
Trained batch 525 in epoch 11, gen_loss = 1.4296675968079513, disc_loss = 0.0001307948208006509
Trained batch 526 in epoch 11, gen_loss = 1.4295571974604135, disc_loss = 0.0001306599351388645
Trained batch 527 in epoch 11, gen_loss = 1.429421882963542, disc_loss = 0.0001305475748302232
Trained batch 528 in epoch 11, gen_loss = 1.4294028475965128, disc_loss = 0.000130450507530456
Trained batch 529 in epoch 11, gen_loss = 1.429308327638878, disc_loss = 0.00013037714487030105
Trained batch 530 in epoch 11, gen_loss = 1.429329287983379, disc_loss = 0.00013037255635343534
Trained batch 531 in epoch 11, gen_loss = 1.4291947004490329, disc_loss = 0.00013053924176278827
Trained batch 532 in epoch 11, gen_loss = 1.4291333203915135, disc_loss = 0.00013091458626368103
Trained batch 533 in epoch 11, gen_loss = 1.4290751464357982, disc_loss = 0.00013158920809770136
Trained batch 534 in epoch 11, gen_loss = 1.429080764823985, disc_loss = 0.00013241609618642745
Trained batch 535 in epoch 11, gen_loss = 1.4289991092770846, disc_loss = 0.0001334654640917262
Trained batch 536 in epoch 11, gen_loss = 1.4289617021212586, disc_loss = 0.00013486476290444353
Trained batch 537 in epoch 11, gen_loss = 1.4289108379622817, disc_loss = 0.0001365954617827797
Trained batch 538 in epoch 11, gen_loss = 1.4289301187076462, disc_loss = 0.00013965521365999056
Trained batch 539 in epoch 11, gen_loss = 1.4287935164239671, disc_loss = 0.0001440563696767775
Trained batch 540 in epoch 11, gen_loss = 1.4286937762100023, disc_loss = 0.00014795371132133835
Trained batch 541 in epoch 11, gen_loss = 1.4286395953590139, disc_loss = 0.00015118209125914518
Trained batch 542 in epoch 11, gen_loss = 1.4286214986997854, disc_loss = 0.00015408794176636687
Trained batch 543 in epoch 11, gen_loss = 1.428615487892838, disc_loss = 0.00015735285968369628
Trained batch 544 in epoch 11, gen_loss = 1.4285981497633349, disc_loss = 0.0001604601711499635
Trained batch 545 in epoch 11, gen_loss = 1.4284969079188812, disc_loss = 0.00016342292672514956
Trained batch 546 in epoch 11, gen_loss = 1.4284323482234473, disc_loss = 0.00016596136212560593
Trained batch 547 in epoch 11, gen_loss = 1.4285601938727999, disc_loss = 0.00016796596805993862
Trained batch 548 in epoch 11, gen_loss = 1.4285858863038443, disc_loss = 0.0001691817548282104
Trained batch 549 in epoch 11, gen_loss = 1.4284659095243974, disc_loss = 0.00017022973969274476
Trained batch 550 in epoch 11, gen_loss = 1.428370888566365, disc_loss = 0.00017101409229080294
Trained batch 551 in epoch 11, gen_loss = 1.428532304107279, disc_loss = 0.00017178994412922518
Trained batch 552 in epoch 11, gen_loss = 1.4284801832375, disc_loss = 0.00017224449240914642
Trained batch 553 in epoch 11, gen_loss = 1.4285608289043825, disc_loss = 0.00017249800832740922
Trained batch 554 in epoch 11, gen_loss = 1.428594811113031, disc_loss = 0.000172588624050846
Trained batch 555 in epoch 11, gen_loss = 1.4285304381264199, disc_loss = 0.00017255130692221506
Trained batch 556 in epoch 11, gen_loss = 1.4284983289091977, disc_loss = 0.00017245490701463766
Trained batch 557 in epoch 11, gen_loss = 1.428473772754806, disc_loss = 0.00017232275679630854
Trained batch 558 in epoch 11, gen_loss = 1.4284453208629901, disc_loss = 0.00017216438561697614
Trained batch 559 in epoch 11, gen_loss = 1.428517527452537, disc_loss = 0.00017199313621014362
Trained batch 560 in epoch 11, gen_loss = 1.4285224561385292, disc_loss = 0.00017183881190866617
Trained batch 561 in epoch 11, gen_loss = 1.4285248017395942, disc_loss = 0.00017171923957893636
Trained batch 562 in epoch 11, gen_loss = 1.4285281506990666, disc_loss = 0.0001716530196983907
Trained batch 563 in epoch 11, gen_loss = 1.4285633115903706, disc_loss = 0.0001716461759199174
Trained batch 564 in epoch 11, gen_loss = 1.4286799460385753, disc_loss = 0.00017162588214364203
Trained batch 565 in epoch 11, gen_loss = 1.4286774580133257, disc_loss = 0.0001715205358720046
Trained batch 566 in epoch 11, gen_loss = 1.428747388000421, disc_loss = 0.0001713784758800099
Trained batch 567 in epoch 11, gen_loss = 1.4286960159808817, disc_loss = 0.0001712018853864515
Trained batch 568 in epoch 11, gen_loss = 1.4285152832108348, disc_loss = 0.000170985904390608
Trained batch 569 in epoch 11, gen_loss = 1.4284132737862436, disc_loss = 0.00017075531023261933
Trained batch 570 in epoch 11, gen_loss = 1.4284421942488743, disc_loss = 0.00017050323122610268
Trained batch 571 in epoch 11, gen_loss = 1.4284262711351567, disc_loss = 0.00017026974561062402
Trained batch 572 in epoch 11, gen_loss = 1.4283905016814227, disc_loss = 0.0001700362494943676
Trained batch 573 in epoch 11, gen_loss = 1.4284392236001815, disc_loss = 0.0001698012147466127
Trained batch 574 in epoch 11, gen_loss = 1.428500985269961, disc_loss = 0.000169574314663212
Trained batch 575 in epoch 11, gen_loss = 1.428598773976167, disc_loss = 0.00016931787360224208
Trained batch 576 in epoch 11, gen_loss = 1.4286214032660738, disc_loss = 0.0001690577564990191
Trained batch 577 in epoch 11, gen_loss = 1.4285628919370446, disc_loss = 0.00016881485159806872
Trained batch 578 in epoch 11, gen_loss = 1.428547685422222, disc_loss = 0.00016858555727673188
Trained batch 579 in epoch 11, gen_loss = 1.4285354234021286, disc_loss = 0.00016832904309232053
Trained batch 580 in epoch 11, gen_loss = 1.428428255752524, disc_loss = 0.00016808689894087943
Trained batch 581 in epoch 11, gen_loss = 1.4285201176335312, disc_loss = 0.00016783766488228
Trained batch 582 in epoch 11, gen_loss = 1.4284418107714907, disc_loss = 0.0001675934210377921
Trained batch 583 in epoch 11, gen_loss = 1.4284286237742803, disc_loss = 0.0001673482331500976
Trained batch 584 in epoch 11, gen_loss = 1.4282747910572933, disc_loss = 0.00016711650457112298
Trained batch 585 in epoch 11, gen_loss = 1.4282844923055213, disc_loss = 0.00016689164490670338
Trained batch 586 in epoch 11, gen_loss = 1.4283757433168323, disc_loss = 0.00016667652588348667
Trained batch 587 in epoch 11, gen_loss = 1.428510997165628, disc_loss = 0.0001664880790727062
Trained batch 588 in epoch 11, gen_loss = 1.4283955933080261, disc_loss = 0.00016633689219213793
Trained batch 589 in epoch 11, gen_loss = 1.4283259470584029, disc_loss = 0.0001662239939401319
Trained batch 590 in epoch 11, gen_loss = 1.428264052129639, disc_loss = 0.00016612226842254438
Trained batch 591 in epoch 11, gen_loss = 1.4282743888529572, disc_loss = 0.00016603031149377392
Trained batch 592 in epoch 11, gen_loss = 1.428317002261067, disc_loss = 0.00016594655328002953
Trained batch 593 in epoch 11, gen_loss = 1.4282270710074942, disc_loss = 0.00016586724987891185
Trained batch 594 in epoch 11, gen_loss = 1.4282869659552053, disc_loss = 0.00016579053438003978
Trained batch 595 in epoch 11, gen_loss = 1.4282230342794584, disc_loss = 0.00016573300470725297
Trained batch 596 in epoch 11, gen_loss = 1.4282409016610789, disc_loss = 0.0001656849115692425
Trained batch 597 in epoch 11, gen_loss = 1.4281600436638031, disc_loss = 0.00016565158465554696
Trained batch 598 in epoch 11, gen_loss = 1.4280914243354224, disc_loss = 0.00016562386874211248
Trained batch 599 in epoch 11, gen_loss = 1.4280683811505634, disc_loss = 0.0001656054016196625
Trained batch 600 in epoch 11, gen_loss = 1.4278922414224278, disc_loss = 0.0001655935319893815
Trained batch 601 in epoch 11, gen_loss = 1.4279761253005245, disc_loss = 0.00016553257824986013
Trained batch 602 in epoch 11, gen_loss = 1.4280254253700597, disc_loss = 0.00016545695033774168
Trained batch 603 in epoch 11, gen_loss = 1.4280579737480112, disc_loss = 0.00016538332827031803
Trained batch 604 in epoch 11, gen_loss = 1.42808184269046, disc_loss = 0.000165301754772793
Trained batch 605 in epoch 11, gen_loss = 1.4280749944963864, disc_loss = 0.00016521178360454712
Trained batch 606 in epoch 11, gen_loss = 1.4280820717725173, disc_loss = 0.00016510315398122065
Trained batch 607 in epoch 11, gen_loss = 1.4281030967831612, disc_loss = 0.00016498848820770275
Trained batch 608 in epoch 11, gen_loss = 1.4280176448508828, disc_loss = 0.00016488371211037094
Trained batch 609 in epoch 11, gen_loss = 1.4279910802841187, disc_loss = 0.00016476763940459694
Trained batch 610 in epoch 11, gen_loss = 1.4280811717974573, disc_loss = 0.00016462191173925584
Trained batch 611 in epoch 11, gen_loss = 1.4281892120059019, disc_loss = 0.00016449587946482138
Trained batch 612 in epoch 11, gen_loss = 1.4282108245821605, disc_loss = 0.00016431179625321833
Trained batch 613 in epoch 11, gen_loss = 1.4282464266599972, disc_loss = 0.00016411423807367339
Trained batch 614 in epoch 11, gen_loss = 1.4283378779403562, disc_loss = 0.00016388871843490762
Trained batch 615 in epoch 11, gen_loss = 1.4283635585339038, disc_loss = 0.0001636469424803571
Trained batch 616 in epoch 11, gen_loss = 1.428461982133516, disc_loss = 0.00016342851685290167
Trained batch 617 in epoch 11, gen_loss = 1.4284767973384425, disc_loss = 0.00016322421022566222
Trained batch 618 in epoch 11, gen_loss = 1.428566851022748, disc_loss = 0.00016303857467984061
Trained batch 619 in epoch 11, gen_loss = 1.428503256267117, disc_loss = 0.00016287993505043673
Trained batch 620 in epoch 11, gen_loss = 1.4285087046031983, disc_loss = 0.00016270569111679356
Trained batch 621 in epoch 11, gen_loss = 1.4285275702307845, disc_loss = 0.0001624896911006021
Trained batch 622 in epoch 11, gen_loss = 1.428484830198089, disc_loss = 0.00016227506906532063
Trained batch 623 in epoch 11, gen_loss = 1.428385859498611, disc_loss = 0.0001620760292261809
Trained batch 624 in epoch 11, gen_loss = 1.4283370414733887, disc_loss = 0.00016186824913602322
Trained batch 625 in epoch 11, gen_loss = 1.4282536542834565, disc_loss = 0.0001616485422596052
Trained batch 626 in epoch 11, gen_loss = 1.4282117791153026, disc_loss = 0.0001614543168377198
Trained batch 627 in epoch 11, gen_loss = 1.428218632746654, disc_loss = 0.00016134146918740292
Trained batch 628 in epoch 11, gen_loss = 1.428201805806122, disc_loss = 0.00016127393397234976
Trained batch 629 in epoch 11, gen_loss = 1.4283232055013142, disc_loss = 0.0001611549013880052
Trained batch 630 in epoch 11, gen_loss = 1.42835505734155, disc_loss = 0.00016101084283527974
Trained batch 631 in epoch 11, gen_loss = 1.4283657117357738, disc_loss = 0.00016096300422287652
Trained batch 632 in epoch 11, gen_loss = 1.4283162496666209, disc_loss = 0.00016087195716695684
Trained batch 633 in epoch 11, gen_loss = 1.428318272629747, disc_loss = 0.00016081591425909754
Trained batch 634 in epoch 11, gen_loss = 1.4283340174382126, disc_loss = 0.00016075795328228067
Trained batch 635 in epoch 11, gen_loss = 1.4284027942321584, disc_loss = 0.00016067145428586964
Trained batch 636 in epoch 11, gen_loss = 1.4283501592872656, disc_loss = 0.0001605588983223712
Trained batch 637 in epoch 11, gen_loss = 1.428276134882601, disc_loss = 0.00016042643999348782
Trained batch 638 in epoch 11, gen_loss = 1.4282414504619831, disc_loss = 0.0001603195621879445
Trained batch 639 in epoch 11, gen_loss = 1.4282257759943604, disc_loss = 0.00016014465767284493
Trained batch 640 in epoch 11, gen_loss = 1.4282797898591588, disc_loss = 0.0001601397847772544
Trained batch 641 in epoch 11, gen_loss = 1.4282843700821897, disc_loss = 0.00016011226957134765
Trained batch 642 in epoch 11, gen_loss = 1.428137883428096, disc_loss = 0.00016021742742781313
Trained batch 643 in epoch 11, gen_loss = 1.4281966243841633, disc_loss = 0.00016034902288784167
Trained batch 644 in epoch 11, gen_loss = 1.4281614943068157, disc_loss = 0.00016032214383206642
Trained batch 645 in epoch 11, gen_loss = 1.428196455118457, disc_loss = 0.00016024987893469196
Trained batch 646 in epoch 11, gen_loss = 1.428173977772272, disc_loss = 0.00016015651972071588
Trained batch 647 in epoch 11, gen_loss = 1.4282656643125746, disc_loss = 0.00016006642103834397
Trained batch 648 in epoch 11, gen_loss = 1.4282697841456198, disc_loss = 0.00015997151486661345
Trained batch 649 in epoch 11, gen_loss = 1.4283249510251559, disc_loss = 0.0001598772471837807
Trained batch 650 in epoch 11, gen_loss = 1.4281976092978739, disc_loss = 0.00015977523412786856
Trained batch 651 in epoch 11, gen_loss = 1.428216287877662, disc_loss = 0.0001596479064434448
Trained batch 652 in epoch 11, gen_loss = 1.4281954259638765, disc_loss = 0.0001594990021303142
Trained batch 653 in epoch 11, gen_loss = 1.4281645433618388, disc_loss = 0.00015934044995864237
Trained batch 654 in epoch 11, gen_loss = 1.4282066665532935, disc_loss = 0.0001591723601672379
Trained batch 655 in epoch 11, gen_loss = 1.4282861190234744, disc_loss = 0.00015901223517220188
Trained batch 656 in epoch 11, gen_loss = 1.4283648703922056, disc_loss = 0.0001588721912035905
Trained batch 657 in epoch 11, gen_loss = 1.428375705578407, disc_loss = 0.00015877381216579487
Trained batch 658 in epoch 11, gen_loss = 1.4283468104638894, disc_loss = 0.0001587240855489615
Trained batch 659 in epoch 11, gen_loss = 1.4283961104624199, disc_loss = 0.00015871574072882526
Trained batch 660 in epoch 11, gen_loss = 1.4285790238546352, disc_loss = 0.00015873651941842822
Trained batch 661 in epoch 11, gen_loss = 1.428552311892956, disc_loss = 0.0001588449491118204
Trained batch 662 in epoch 11, gen_loss = 1.4284782494175308, disc_loss = 0.0001592275310835122
Trained batch 663 in epoch 11, gen_loss = 1.428495799202517, disc_loss = 0.00015987740084436877
Trained batch 664 in epoch 11, gen_loss = 1.4286128935061002, disc_loss = 0.00016055596677592564
Trained batch 665 in epoch 11, gen_loss = 1.4286701502026737, disc_loss = 0.0001610882268473838
Trained batch 666 in epoch 11, gen_loss = 1.428661784489473, disc_loss = 0.00016144833044717794
Trained batch 667 in epoch 11, gen_loss = 1.4287933087991382, disc_loss = 0.0001616576503197475
Trained batch 668 in epoch 11, gen_loss = 1.4287884843010896, disc_loss = 0.00016172400665860476
Trained batch 669 in epoch 11, gen_loss = 1.42883323306468, disc_loss = 0.0001622210859845361
Trained batch 670 in epoch 11, gen_loss = 1.428827228205037, disc_loss = 0.00016372173057410875
Trained batch 671 in epoch 11, gen_loss = 1.4287768100344, disc_loss = 0.00016621174777464192
Trained batch 672 in epoch 11, gen_loss = 1.4287960258316674, disc_loss = 0.00016927627092645087
Trained batch 673 in epoch 11, gen_loss = 1.4287396787889632, disc_loss = 0.00017204699356854894
Trained batch 674 in epoch 11, gen_loss = 1.4287505582526878, disc_loss = 0.00017382665124993462
Trained batch 675 in epoch 11, gen_loss = 1.4288630194565248, disc_loss = 0.00017474940127155643
Trained batch 676 in epoch 11, gen_loss = 1.4288679967074487, disc_loss = 0.00017522698800567711
Trained batch 677 in epoch 11, gen_loss = 1.4289064089105543, disc_loss = 0.00017553734475197127
Trained batch 678 in epoch 11, gen_loss = 1.4289317680563949, disc_loss = 0.00017582251603123788
Trained batch 679 in epoch 11, gen_loss = 1.4288468229420044, disc_loss = 0.00017604577392643585
Trained batch 680 in epoch 11, gen_loss = 1.4288259429553531, disc_loss = 0.00017625279238999878
Trained batch 681 in epoch 11, gen_loss = 1.4287750827601928, disc_loss = 0.0001764278077694797
Trained batch 682 in epoch 11, gen_loss = 1.428889176681485, disc_loss = 0.0001765683270577259
Trained batch 683 in epoch 11, gen_loss = 1.428882801916167, disc_loss = 0.00017669797179282185
Trained batch 684 in epoch 11, gen_loss = 1.428848880920967, disc_loss = 0.00017683302605398047
Trained batch 685 in epoch 11, gen_loss = 1.428845096781372, disc_loss = 0.00017703005900695945
Trained batch 686 in epoch 11, gen_loss = 1.4288382757525604, disc_loss = 0.00017729504241399146
Trained batch 687 in epoch 11, gen_loss = 1.4287836877412574, disc_loss = 0.0001775628346570366
Trained batch 688 in epoch 11, gen_loss = 1.4288153279848472, disc_loss = 0.0001777631756031385
Trained batch 689 in epoch 11, gen_loss = 1.428871733036594, disc_loss = 0.00017787936770258491
Trained batch 690 in epoch 11, gen_loss = 1.4288263019017995, disc_loss = 0.00017789247729198086
Trained batch 691 in epoch 11, gen_loss = 1.4288202822208405, disc_loss = 0.0001778249989895502
Trained batch 692 in epoch 11, gen_loss = 1.428873811965381, disc_loss = 0.00017767877717964214
Trained batch 693 in epoch 11, gen_loss = 1.4289319305667272, disc_loss = 0.00017750406367528977
Trained batch 694 in epoch 11, gen_loss = 1.4288446371503871, disc_loss = 0.00017735481080779196
Trained batch 695 in epoch 11, gen_loss = 1.42878564712645, disc_loss = 0.00017723063815903786
Trained batch 696 in epoch 11, gen_loss = 1.4287080456912946, disc_loss = 0.00017710055588061288
Trained batch 697 in epoch 11, gen_loss = 1.42875943313697, disc_loss = 0.00017694599337953065
Trained batch 698 in epoch 11, gen_loss = 1.4287342070168862, disc_loss = 0.00017677184299937082
Trained batch 699 in epoch 11, gen_loss = 1.428725153888975, disc_loss = 0.00017659423071433723
Trained batch 700 in epoch 11, gen_loss = 1.428670602756288, disc_loss = 0.0001764247495111509
Trained batch 701 in epoch 11, gen_loss = 1.4284704266450343, disc_loss = 0.00017629249596418887
Trained batch 702 in epoch 11, gen_loss = 1.4284648045706716, disc_loss = 0.00017618588133501306
Trained batch 703 in epoch 11, gen_loss = 1.4284603848037394, disc_loss = 0.0001760277070688558
Trained batch 704 in epoch 11, gen_loss = 1.4284998220754854, disc_loss = 0.00017582377675237095
Trained batch 705 in epoch 11, gen_loss = 1.4284723625642382, disc_loss = 0.0001756093035108346
Trained batch 706 in epoch 11, gen_loss = 1.4284999400925265, disc_loss = 0.0001753911426601832
Trained batch 707 in epoch 11, gen_loss = 1.4284013348110651, disc_loss = 0.0001751804221554667
Trained batch 708 in epoch 11, gen_loss = 1.428438211193542, disc_loss = 0.00017497276756289344
Trained batch 709 in epoch 11, gen_loss = 1.4283565326475762, disc_loss = 0.00017477269613894823
Trained batch 710 in epoch 11, gen_loss = 1.4283052547068535, disc_loss = 0.0001745829599028674
Trained batch 711 in epoch 11, gen_loss = 1.4283179622352793, disc_loss = 0.00017439509233912085
Trained batch 712 in epoch 11, gen_loss = 1.428212009338978, disc_loss = 0.00017421053175058974
Trained batch 713 in epoch 11, gen_loss = 1.4282808604360628, disc_loss = 0.000174043024724021
Trained batch 714 in epoch 11, gen_loss = 1.428402174436129, disc_loss = 0.00017387803353514144
Trained batch 715 in epoch 11, gen_loss = 1.4283637061465386, disc_loss = 0.00017370182290531313
Trained batch 716 in epoch 11, gen_loss = 1.4283983524540644, disc_loss = 0.00017351865898588032
Trained batch 717 in epoch 11, gen_loss = 1.4283990517964271, disc_loss = 0.00017334630877315586
Trained batch 718 in epoch 11, gen_loss = 1.4283301054353674, disc_loss = 0.0001731890005075165
Trained batch 719 in epoch 11, gen_loss = 1.4283881809976366, disc_loss = 0.00017303757833057412
Trained batch 720 in epoch 11, gen_loss = 1.4283397781369425, disc_loss = 0.0001728775648584014
Trained batch 721 in epoch 11, gen_loss = 1.4281777828684143, disc_loss = 0.0001727541854112571
Trained batch 722 in epoch 11, gen_loss = 1.42821287234954, disc_loss = 0.00017265174688749953
Trained batch 723 in epoch 11, gen_loss = 1.4282223455484402, disc_loss = 0.00017256958791568846
Trained batch 724 in epoch 11, gen_loss = 1.4283161270207372, disc_loss = 0.0001725095396325522
Trained batch 725 in epoch 11, gen_loss = 1.4283563878910601, disc_loss = 0.0001724320484631802
Trained batch 726 in epoch 11, gen_loss = 1.4283434985592407, disc_loss = 0.0001723203442459865
Trained batch 727 in epoch 11, gen_loss = 1.4284322325672423, disc_loss = 0.00017217076479177955
Trained batch 728 in epoch 11, gen_loss = 1.4284788376673423, disc_loss = 0.00017198986529521305
Trained batch 729 in epoch 11, gen_loss = 1.428455374992057, disc_loss = 0.00017179363906395077
Trained batch 730 in epoch 11, gen_loss = 1.4283634600332757, disc_loss = 0.00017157878689883163
Trained batch 731 in epoch 11, gen_loss = 1.4283724236683768, disc_loss = 0.00017136040434726835
Trained batch 732 in epoch 11, gen_loss = 1.4283230410428847, disc_loss = 0.00017114555730350542
Trained batch 733 in epoch 11, gen_loss = 1.428364883164294, disc_loss = 0.00017093500121069893
Trained batch 734 in epoch 11, gen_loss = 1.428384685678547, disc_loss = 0.00017072996269649395
Trained batch 735 in epoch 11, gen_loss = 1.4284011183873466, disc_loss = 0.00017052117463030615
Trained batch 736 in epoch 11, gen_loss = 1.4284126383316889, disc_loss = 0.00017031358155847846
Trained batch 737 in epoch 11, gen_loss = 1.4284525789865634, disc_loss = 0.00017011558679091415
Trained batch 738 in epoch 11, gen_loss = 1.4284994698990343, disc_loss = 0.0001699172990049539
Trained batch 739 in epoch 11, gen_loss = 1.4284962939249504, disc_loss = 0.0001697160740420529
Trained batch 740 in epoch 11, gen_loss = 1.4284221291059425, disc_loss = 0.00016952313316239163
Trained batch 741 in epoch 11, gen_loss = 1.428454044854866, disc_loss = 0.00016934156630271302
Trained batch 742 in epoch 11, gen_loss = 1.4284398894290744, disc_loss = 0.00016913049756572997
Trained batch 743 in epoch 11, gen_loss = 1.4283398205554614, disc_loss = 0.00016892444060426554
Trained batch 744 in epoch 11, gen_loss = 1.428308315885147, disc_loss = 0.00016871704129948893
Trained batch 745 in epoch 11, gen_loss = 1.4284002597146634, disc_loss = 0.00016851017802345153
Testing Epoch 11
Training Epoch 12
Trained batch 0 in epoch 12, gen_loss = 1.4922676086425781, disc_loss = 2.658893026818987e-05
Trained batch 1 in epoch 12, gen_loss = 1.484257161617279, disc_loss = 2.5712309252412524e-05
Trained batch 2 in epoch 12, gen_loss = 1.4761151870091755, disc_loss = 2.7920979846385308e-05
Trained batch 3 in epoch 12, gen_loss = 1.4647959172725677, disc_loss = 2.868549972845358e-05
Trained batch 4 in epoch 12, gen_loss = 1.4676556825637816, disc_loss = 2.7071076328866183e-05
Trained batch 5 in epoch 12, gen_loss = 1.4526685277620952, disc_loss = 2.8565921941966128e-05
Trained batch 6 in epoch 12, gen_loss = 1.4358820574624198, disc_loss = 3.017627802494514e-05
Trained batch 7 in epoch 12, gen_loss = 1.4353991150856018, disc_loss = 2.9665888632735005e-05
Trained batch 8 in epoch 12, gen_loss = 1.438796255323622, disc_loss = 2.9718791564745414e-05
Trained batch 9 in epoch 12, gen_loss = 1.4339578866958618, disc_loss = 3.318194030725863e-05
Trained batch 10 in epoch 12, gen_loss = 1.431930953806097, disc_loss = 3.8555674770825796e-05
Trained batch 11 in epoch 12, gen_loss = 1.4269023736317952, disc_loss = 4.17915092233064e-05
Trained batch 12 in epoch 12, gen_loss = 1.425741800895104, disc_loss = 4.255394154684976e-05
Trained batch 13 in epoch 12, gen_loss = 1.4193623917443412, disc_loss = 4.1706649946198536e-05
Trained batch 14 in epoch 12, gen_loss = 1.4142709891001384, disc_loss = 4.073420059285127e-05
Trained batch 15 in epoch 12, gen_loss = 1.417927823960781, disc_loss = 4.0483397015123046e-05
Trained batch 16 in epoch 12, gen_loss = 1.4181272843304802, disc_loss = 4.0950530948226946e-05
Trained batch 17 in epoch 12, gen_loss = 1.4191494252946641, disc_loss = 4.105566525443768e-05
Trained batch 18 in epoch 12, gen_loss = 1.4209043916903044, disc_loss = 4.1155957947730236e-05
Trained batch 19 in epoch 12, gen_loss = 1.4206656157970428, disc_loss = 4.1577651427360254e-05
Trained batch 20 in epoch 12, gen_loss = 1.420041458947318, disc_loss = 4.2085493034738606e-05
Trained batch 21 in epoch 12, gen_loss = 1.4196083599870855, disc_loss = 4.246622070654253e-05
Trained batch 22 in epoch 12, gen_loss = 1.42334697039231, disc_loss = 4.288236248058915e-05
Trained batch 23 in epoch 12, gen_loss = 1.428217406074206, disc_loss = 4.3733644057889855e-05
Trained batch 24 in epoch 12, gen_loss = 1.4268273782730103, disc_loss = 4.564933406072669e-05
Trained batch 25 in epoch 12, gen_loss = 1.4248836361444914, disc_loss = 4.926000488362311e-05
Trained batch 26 in epoch 12, gen_loss = 1.4246825421297993, disc_loss = 5.437963288083362e-05
Trained batch 27 in epoch 12, gen_loss = 1.4231849695955003, disc_loss = 6.013432136699391e-05
Trained batch 28 in epoch 12, gen_loss = 1.424532413482666, disc_loss = 6.554061775236262e-05
Trained batch 29 in epoch 12, gen_loss = 1.4254199504852294, disc_loss = 6.955229800951202e-05
Trained batch 30 in epoch 12, gen_loss = 1.4245367203989336, disc_loss = 7.249183251969367e-05
Trained batch 31 in epoch 12, gen_loss = 1.425230249762535, disc_loss = 7.46827394095817e-05
Trained batch 32 in epoch 12, gen_loss = 1.426118886832035, disc_loss = 7.70755709020181e-05
Trained batch 33 in epoch 12, gen_loss = 1.4261878062697018, disc_loss = 7.944012577354442e-05
Trained batch 34 in epoch 12, gen_loss = 1.4262305293764388, disc_loss = 8.246874027203635e-05
Trained batch 35 in epoch 12, gen_loss = 1.4264698988861508, disc_loss = 8.630224520958209e-05
Trained batch 36 in epoch 12, gen_loss = 1.4261897673477997, disc_loss = 9.122958146837993e-05
Trained batch 37 in epoch 12, gen_loss = 1.4267032177824723, disc_loss = 9.726226055231803e-05
Trained batch 38 in epoch 12, gen_loss = 1.4279744991889367, disc_loss = 0.0001044015325299906
Trained batch 39 in epoch 12, gen_loss = 1.4290939331054688, disc_loss = 0.00011231933485760237
Trained batch 40 in epoch 12, gen_loss = 1.4287622847208163, disc_loss = 0.00012040320276666047
Trained batch 41 in epoch 12, gen_loss = 1.4299560501461936, disc_loss = 0.00012786704255198682
Trained batch 42 in epoch 12, gen_loss = 1.4290509168491807, disc_loss = 0.00013413126159088449
Trained batch 43 in epoch 12, gen_loss = 1.430457662452351, disc_loss = 0.00013888190956508467
Trained batch 44 in epoch 12, gen_loss = 1.4317626926634046, disc_loss = 0.0001423690826211694
Trained batch 45 in epoch 12, gen_loss = 1.431868869325389, disc_loss = 0.00014477104298788143
Trained batch 46 in epoch 12, gen_loss = 1.4308573210493047, disc_loss = 0.00014648277786538064
Trained batch 47 in epoch 12, gen_loss = 1.4321097061038017, disc_loss = 0.00014764799887719468
Trained batch 48 in epoch 12, gen_loss = 1.4312635197931407, disc_loss = 0.00014821065395859032
Trained batch 49 in epoch 12, gen_loss = 1.4305389022827149, disc_loss = 0.00014840230076515582
Trained batch 50 in epoch 12, gen_loss = 1.4301169947081922, disc_loss = 0.00014846264942510365
Trained batch 51 in epoch 12, gen_loss = 1.4301741398297823, disc_loss = 0.00014808970746134248
Trained batch 52 in epoch 12, gen_loss = 1.4295781513430037, disc_loss = 0.00014738125111830842
Trained batch 53 in epoch 12, gen_loss = 1.4292982132346541, disc_loss = 0.00014637527130145355
Trained batch 54 in epoch 12, gen_loss = 1.4283283537084406, disc_loss = 0.00014526191563080912
Trained batch 55 in epoch 12, gen_loss = 1.4268421147550856, disc_loss = 0.0001440499928061659
Trained batch 56 in epoch 12, gen_loss = 1.4286419299610875, disc_loss = 0.00014281118631499754
Trained batch 57 in epoch 12, gen_loss = 1.4291269861418625, disc_loss = 0.00014189913700051718
Trained batch 58 in epoch 12, gen_loss = 1.4298674252073644, disc_loss = 0.00014118734648267708
Trained batch 59 in epoch 12, gen_loss = 1.430285672346751, disc_loss = 0.0001402797712823182
Trained batch 60 in epoch 12, gen_loss = 1.4312591161884245, disc_loss = 0.00013922799261025396
Trained batch 61 in epoch 12, gen_loss = 1.430660726562623, disc_loss = 0.0001383865506913055
Trained batch 62 in epoch 12, gen_loss = 1.4315090311898127, disc_loss = 0.00013796221526082798
Trained batch 63 in epoch 12, gen_loss = 1.4315118081867695, disc_loss = 0.00013776607016779963
Trained batch 64 in epoch 12, gen_loss = 1.4316995730766884, disc_loss = 0.00013775932675343938
Trained batch 65 in epoch 12, gen_loss = 1.4328625491171172, disc_loss = 0.0001385757445721979
Trained batch 66 in epoch 12, gen_loss = 1.4330626103415418, disc_loss = 0.00013989030971902478
Trained batch 67 in epoch 12, gen_loss = 1.433022059061948, disc_loss = 0.00014088124316913309
Trained batch 68 in epoch 12, gen_loss = 1.4331948048826577, disc_loss = 0.00014165525968512182
Trained batch 69 in epoch 12, gen_loss = 1.4329939620835441, disc_loss = 0.0001418846952999177
Trained batch 70 in epoch 12, gen_loss = 1.4331525194812829, disc_loss = 0.00014165731198785656
Trained batch 71 in epoch 12, gen_loss = 1.4322907278935115, disc_loss = 0.00014100195671239312
Trained batch 72 in epoch 12, gen_loss = 1.4325697209737072, disc_loss = 0.00014013680405173233
Trained batch 73 in epoch 12, gen_loss = 1.4319678963841618, disc_loss = 0.00013902332053426967
Trained batch 74 in epoch 12, gen_loss = 1.4318196455637613, disc_loss = 0.0001377732316905167
Trained batch 75 in epoch 12, gen_loss = 1.4329219272262173, disc_loss = 0.00013648838040879988
Trained batch 76 in epoch 12, gen_loss = 1.4329032201271552, disc_loss = 0.0001354037782433594
Trained batch 77 in epoch 12, gen_loss = 1.4331974005087829, disc_loss = 0.00013447472375469844
Trained batch 78 in epoch 12, gen_loss = 1.432200581212587, disc_loss = 0.00013364876097891938
Trained batch 79 in epoch 12, gen_loss = 1.432725763320923, disc_loss = 0.00013308595985108695
Trained batch 80 in epoch 12, gen_loss = 1.4323867956797283, disc_loss = 0.0001325558972624734
Trained batch 81 in epoch 12, gen_loss = 1.4322629672725027, disc_loss = 0.00013189327635301174
Trained batch 82 in epoch 12, gen_loss = 1.4321240847369274, disc_loss = 0.00013092529199244622
Trained batch 83 in epoch 12, gen_loss = 1.4316279419830866, disc_loss = 0.0001298029898992224
Trained batch 84 in epoch 12, gen_loss = 1.4318616572548362, disc_loss = 0.00012882457201211604
Trained batch 85 in epoch 12, gen_loss = 1.4317468501800714, disc_loss = 0.00012808684571842435
Trained batch 86 in epoch 12, gen_loss = 1.4311067825076225, disc_loss = 0.00012783694032334787
Trained batch 87 in epoch 12, gen_loss = 1.4310309087688273, disc_loss = 0.00012814367226548546
Trained batch 88 in epoch 12, gen_loss = 1.4313375253355904, disc_loss = 0.00012873389318832616
Trained batch 89 in epoch 12, gen_loss = 1.4310784816741944, disc_loss = 0.0001293977486865414
Trained batch 90 in epoch 12, gen_loss = 1.4323094572339738, disc_loss = 0.00013009857075003611
Trained batch 91 in epoch 12, gen_loss = 1.4320563984953838, disc_loss = 0.00013122117877134335
Trained batch 92 in epoch 12, gen_loss = 1.4315187866969774, disc_loss = 0.00013229646035426256
Trained batch 93 in epoch 12, gen_loss = 1.4318799744261073, disc_loss = 0.0001328561657886739
Trained batch 94 in epoch 12, gen_loss = 1.4322833400023611, disc_loss = 0.0001326745750128267
Trained batch 95 in epoch 12, gen_loss = 1.431876124193271, disc_loss = 0.0001324530748737137
Trained batch 96 in epoch 12, gen_loss = 1.4323687836066963, disc_loss = 0.00013279174084711542
Trained batch 97 in epoch 12, gen_loss = 1.4327159086052252, disc_loss = 0.00013359223814813032
Trained batch 98 in epoch 12, gen_loss = 1.433535959985521, disc_loss = 0.0001348512374129819
Trained batch 99 in epoch 12, gen_loss = 1.433281775712967, disc_loss = 0.0001363637983376975
Trained batch 100 in epoch 12, gen_loss = 1.4328399105827407, disc_loss = 0.00013805518086306925
Trained batch 101 in epoch 12, gen_loss = 1.4322864880748825, disc_loss = 0.0001397141517301469
Trained batch 102 in epoch 12, gen_loss = 1.4324288773305207, disc_loss = 0.00014140691705815523
Trained batch 103 in epoch 12, gen_loss = 1.4315469563007355, disc_loss = 0.00014320851869342732
Trained batch 104 in epoch 12, gen_loss = 1.4315808954693021, disc_loss = 0.0001450352197155423
Trained batch 105 in epoch 12, gen_loss = 1.431686521701093, disc_loss = 0.0001466964550449772
Trained batch 106 in epoch 12, gen_loss = 1.431633944823363, disc_loss = 0.00014826162727348392
Trained batch 107 in epoch 12, gen_loss = 1.4311551319228277, disc_loss = 0.0001497105084598405
Trained batch 108 in epoch 12, gen_loss = 1.4314806516017389, disc_loss = 0.00015106074064900595
Trained batch 109 in epoch 12, gen_loss = 1.4322466557676141, disc_loss = 0.00015216345263152934
Trained batch 110 in epoch 12, gen_loss = 1.4317035245465803, disc_loss = 0.0001530627454124991
Trained batch 111 in epoch 12, gen_loss = 1.4306888984782355, disc_loss = 0.0001541774483939662
Trained batch 112 in epoch 12, gen_loss = 1.4305304447106555, disc_loss = 0.0001553767508519628
Trained batch 113 in epoch 12, gen_loss = 1.4301340308105737, disc_loss = 0.0001565688895712619
Trained batch 114 in epoch 12, gen_loss = 1.4294855366582455, disc_loss = 0.0001577273510717888
Trained batch 115 in epoch 12, gen_loss = 1.428888031120958, disc_loss = 0.00015881599703224594
Trained batch 116 in epoch 12, gen_loss = 1.429271874264774, disc_loss = 0.0001599971267121593
Trained batch 117 in epoch 12, gen_loss = 1.429395616054535, disc_loss = 0.00016134991235927467
Trained batch 118 in epoch 12, gen_loss = 1.4292520154424075, disc_loss = 0.00016265528891289395
Trained batch 119 in epoch 12, gen_loss = 1.4290894667307537, disc_loss = 0.00016382901361187882
Trained batch 120 in epoch 12, gen_loss = 1.4289755456703754, disc_loss = 0.0001646870900123969
Trained batch 121 in epoch 12, gen_loss = 1.4293890048245914, disc_loss = 0.0001652382082984779
Trained batch 122 in epoch 12, gen_loss = 1.4287289313184537, disc_loss = 0.00016568986600434325
Trained batch 123 in epoch 12, gen_loss = 1.429028343769812, disc_loss = 0.0001661536941150365
Trained batch 124 in epoch 12, gen_loss = 1.4285976810455323, disc_loss = 0.00016662516570067966
Trained batch 125 in epoch 12, gen_loss = 1.4287765555911593, disc_loss = 0.00016718187460297947
Trained batch 126 in epoch 12, gen_loss = 1.4286822277729905, disc_loss = 0.00016797227105176202
Trained batch 127 in epoch 12, gen_loss = 1.428592260926962, disc_loss = 0.00016884548116991027
Trained batch 128 in epoch 12, gen_loss = 1.4287166576976924, disc_loss = 0.00016986026077025007
Trained batch 129 in epoch 12, gen_loss = 1.4284942250985366, disc_loss = 0.0001707989199460896
Trained batch 130 in epoch 12, gen_loss = 1.4289753409742398, disc_loss = 0.00017160215318529114
Trained batch 131 in epoch 12, gen_loss = 1.4291757534850726, disc_loss = 0.00017213321880814019
Trained batch 132 in epoch 12, gen_loss = 1.429297703549378, disc_loss = 0.0001724124317969059
Trained batch 133 in epoch 12, gen_loss = 1.4294126362942938, disc_loss = 0.00017250591285553684
Trained batch 134 in epoch 12, gen_loss = 1.4293024389832107, disc_loss = 0.00017245845528021973
Trained batch 135 in epoch 12, gen_loss = 1.4285864014835918, disc_loss = 0.00017228445227267323
Trained batch 136 in epoch 12, gen_loss = 1.4284784384887583, disc_loss = 0.00017194506428336187
Trained batch 137 in epoch 12, gen_loss = 1.4286037450251372, disc_loss = 0.00017154352971756717
Trained batch 138 in epoch 12, gen_loss = 1.4278929765275914, disc_loss = 0.0001712984384467621
Trained batch 139 in epoch 12, gen_loss = 1.4279630030904498, disc_loss = 0.00017126312125453425
Trained batch 140 in epoch 12, gen_loss = 1.4285925483027249, disc_loss = 0.00017132509878241286
Trained batch 141 in epoch 12, gen_loss = 1.428162351460524, disc_loss = 0.00017132374123833305
Trained batch 142 in epoch 12, gen_loss = 1.4283246685574937, disc_loss = 0.00017127686485357525
Trained batch 143 in epoch 12, gen_loss = 1.4283309272593923, disc_loss = 0.000171174586057532
Trained batch 144 in epoch 12, gen_loss = 1.4287586450576781, disc_loss = 0.00017108377929805007
Trained batch 145 in epoch 12, gen_loss = 1.4288020403417823, disc_loss = 0.00017107524093274787
Trained batch 146 in epoch 12, gen_loss = 1.4287405679015075, disc_loss = 0.00017112593069418372
Trained batch 147 in epoch 12, gen_loss = 1.4284173781807359, disc_loss = 0.00017133075446484303
Trained batch 148 in epoch 12, gen_loss = 1.427784000467134, disc_loss = 0.00017194918841932237
Trained batch 149 in epoch 12, gen_loss = 1.4272390580177308, disc_loss = 0.00017300688833832585
Trained batch 150 in epoch 12, gen_loss = 1.4270764699834861, disc_loss = 0.00017426000610329303
Trained batch 151 in epoch 12, gen_loss = 1.4269121046129025, disc_loss = 0.0001754649574889443
Trained batch 152 in epoch 12, gen_loss = 1.4267396451601015, disc_loss = 0.00017678648975941814
Trained batch 153 in epoch 12, gen_loss = 1.427070902539538, disc_loss = 0.00017813895618775104
Trained batch 154 in epoch 12, gen_loss = 1.4273160472992927, disc_loss = 0.0001794350355809119
Trained batch 155 in epoch 12, gen_loss = 1.427700970417414, disc_loss = 0.00018069260409575715
Trained batch 156 in epoch 12, gen_loss = 1.4276359703890078, disc_loss = 0.00018170906249252087
Trained batch 157 in epoch 12, gen_loss = 1.427373305151734, disc_loss = 0.00018251280145497868
Trained batch 158 in epoch 12, gen_loss = 1.4277710764663025, disc_loss = 0.0001832843044435579
Trained batch 159 in epoch 12, gen_loss = 1.4283321440219878, disc_loss = 0.0001840341228444231
Trained batch 160 in epoch 12, gen_loss = 1.4280976049648308, disc_loss = 0.0001845693035455788
Trained batch 161 in epoch 12, gen_loss = 1.4282468366034238, disc_loss = 0.00018487889572520264
Trained batch 162 in epoch 12, gen_loss = 1.4282128620732781, disc_loss = 0.00018503973626105282
Trained batch 163 in epoch 12, gen_loss = 1.428063468235295, disc_loss = 0.00018508939246669065
Trained batch 164 in epoch 12, gen_loss = 1.4284613782709294, disc_loss = 0.00018506085517318833
Trained batch 165 in epoch 12, gen_loss = 1.4289238610899593, disc_loss = 0.00018494395533115855
Trained batch 166 in epoch 12, gen_loss = 1.4292064305551038, disc_loss = 0.00018478069052467553
Trained batch 167 in epoch 12, gen_loss = 1.4287102087622596, disc_loss = 0.00018467666361521835
Trained batch 168 in epoch 12, gen_loss = 1.428748436228058, disc_loss = 0.00018452501124492296
Trained batch 169 in epoch 12, gen_loss = 1.4292317986488343, disc_loss = 0.00018435868266404964
Trained batch 170 in epoch 12, gen_loss = 1.4295031222683645, disc_loss = 0.00018409818634428275
Trained batch 171 in epoch 12, gen_loss = 1.4299641743648883, disc_loss = 0.00018368888005318505
Trained batch 172 in epoch 12, gen_loss = 1.4298284398338008, disc_loss = 0.00018311242896049403
Trained batch 173 in epoch 12, gen_loss = 1.4299725753137436, disc_loss = 0.00018234127339550386
Trained batch 174 in epoch 12, gen_loss = 1.4298785298211234, disc_loss = 0.00018147150658478494
Trained batch 175 in epoch 12, gen_loss = 1.4296806447885253, disc_loss = 0.00018064121225465485
Trained batch 176 in epoch 12, gen_loss = 1.4293272677114455, disc_loss = 0.0001798167417147677
Trained batch 177 in epoch 12, gen_loss = 1.4296250108922466, disc_loss = 0.00017906491309863822
Trained batch 178 in epoch 12, gen_loss = 1.4299551674773574, disc_loss = 0.00017826849505978094
Trained batch 179 in epoch 12, gen_loss = 1.4301657378673553, disc_loss = 0.00017747347720715981
Trained batch 180 in epoch 12, gen_loss = 1.4302713482419431, disc_loss = 0.00017665141598054257
Trained batch 181 in epoch 12, gen_loss = 1.4304135179781652, disc_loss = 0.00017584264486896034
Trained batch 182 in epoch 12, gen_loss = 1.4302231086407855, disc_loss = 0.00017513830393934153
Trained batch 183 in epoch 12, gen_loss = 1.430155239675356, disc_loss = 0.00017447307166786112
Trained batch 184 in epoch 12, gen_loss = 1.4299867101617763, disc_loss = 0.00017375547832744888
Trained batch 185 in epoch 12, gen_loss = 1.429648696735341, disc_loss = 0.00017300241203580904
Trained batch 186 in epoch 12, gen_loss = 1.4295543744602306, disc_loss = 0.00017222747016073402
Trained batch 187 in epoch 12, gen_loss = 1.4295767342790644, disc_loss = 0.0001715115959570462
Trained batch 188 in epoch 12, gen_loss = 1.4291736247047546, disc_loss = 0.00017077229159156404
Trained batch 189 in epoch 12, gen_loss = 1.4288662370882537, disc_loss = 0.00017000587132842107
Trained batch 190 in epoch 12, gen_loss = 1.4288032485552484, disc_loss = 0.00016923880907621585
Trained batch 191 in epoch 12, gen_loss = 1.4288299903273582, disc_loss = 0.0001686385324433104
Trained batch 192 in epoch 12, gen_loss = 1.4290854708518388, disc_loss = 0.0001681359581716559
Trained batch 193 in epoch 12, gen_loss = 1.4286280372708113, disc_loss = 0.00016791252753521512
Trained batch 194 in epoch 12, gen_loss = 1.4281261878135876, disc_loss = 0.00016778907169608806
Trained batch 195 in epoch 12, gen_loss = 1.4280980685535742, disc_loss = 0.0001676796268003848
Trained batch 196 in epoch 12, gen_loss = 1.4281731517181784, disc_loss = 0.00016765378908355257
Trained batch 197 in epoch 12, gen_loss = 1.4282202515939268, disc_loss = 0.00016782789197065422
Trained batch 198 in epoch 12, gen_loss = 1.4280841242727922, disc_loss = 0.00016821875473780994
Trained batch 199 in epoch 12, gen_loss = 1.428196974992752, disc_loss = 0.00016854900595717482
Trained batch 200 in epoch 12, gen_loss = 1.4279827769122906, disc_loss = 0.00016881424816894643
Trained batch 201 in epoch 12, gen_loss = 1.4277862269099395, disc_loss = 0.000169042459746568
Trained batch 202 in epoch 12, gen_loss = 1.4276138344421763, disc_loss = 0.00016922250210770333
Trained batch 203 in epoch 12, gen_loss = 1.4271419591763441, disc_loss = 0.00016949287171383714
Trained batch 204 in epoch 12, gen_loss = 1.427199544557711, disc_loss = 0.00016989524853515167
Trained batch 205 in epoch 12, gen_loss = 1.427221412797576, disc_loss = 0.00017036353689672097
Trained batch 206 in epoch 12, gen_loss = 1.4272451135847304, disc_loss = 0.00017073893573926424
Trained batch 207 in epoch 12, gen_loss = 1.427393645621263, disc_loss = 0.00017119816869545993
Trained batch 208 in epoch 12, gen_loss = 1.4274300787437475, disc_loss = 0.00017165525754204612
Trained batch 209 in epoch 12, gen_loss = 1.4278271993001301, disc_loss = 0.00017219883688778195
Trained batch 210 in epoch 12, gen_loss = 1.4274938230830911, disc_loss = 0.00017286421666216984
Trained batch 211 in epoch 12, gen_loss = 1.4271612431643144, disc_loss = 0.0001735762739629553
Trained batch 212 in epoch 12, gen_loss = 1.4271316757784203, disc_loss = 0.00017420253054741135
Trained batch 213 in epoch 12, gen_loss = 1.4270484770569847, disc_loss = 0.0001747923687166506
Trained batch 214 in epoch 12, gen_loss = 1.4272359531979228, disc_loss = 0.00017558789308126042
Trained batch 215 in epoch 12, gen_loss = 1.4272322908595756, disc_loss = 0.0001765293890524912
Trained batch 216 in epoch 12, gen_loss = 1.42737928623428, disc_loss = 0.000177626229721644
Trained batch 217 in epoch 12, gen_loss = 1.4276460961464348, disc_loss = 0.0001787545768470117
Trained batch 218 in epoch 12, gen_loss = 1.4275443679121531, disc_loss = 0.00017982380141142105
Trained batch 219 in epoch 12, gen_loss = 1.4277435633269224, disc_loss = 0.00018073585847146618
Trained batch 220 in epoch 12, gen_loss = 1.428034203624294, disc_loss = 0.0001814549903107999
Trained batch 221 in epoch 12, gen_loss = 1.4284235942471135, disc_loss = 0.0001821796574674679
Trained batch 222 in epoch 12, gen_loss = 1.4285597517885968, disc_loss = 0.00018290265307919907
Trained batch 223 in epoch 12, gen_loss = 1.4285139739513397, disc_loss = 0.00018336490774929968
Trained batch 224 in epoch 12, gen_loss = 1.4283653852674696, disc_loss = 0.0001836708202770549
Trained batch 225 in epoch 12, gen_loss = 1.428352709365102, disc_loss = 0.00018406241690929035
Trained batch 226 in epoch 12, gen_loss = 1.4282421540583807, disc_loss = 0.00018438087826754205
Trained batch 227 in epoch 12, gen_loss = 1.4283240113342017, disc_loss = 0.0001847211299064567
Trained batch 228 in epoch 12, gen_loss = 1.4286032889087128, disc_loss = 0.0001851117343601911
Trained batch 229 in epoch 12, gen_loss = 1.4288485267887945, disc_loss = 0.00018553102429153944
Trained batch 230 in epoch 12, gen_loss = 1.4287041399902078, disc_loss = 0.00018593721077321359
Trained batch 231 in epoch 12, gen_loss = 1.4283595804510445, disc_loss = 0.00018644775757914838
Trained batch 232 in epoch 12, gen_loss = 1.4283027802414137, disc_loss = 0.00018703772867477675
Trained batch 233 in epoch 12, gen_loss = 1.4286924738150377, disc_loss = 0.00018755499883661838
Trained batch 234 in epoch 12, gen_loss = 1.428804401133923, disc_loss = 0.0001880199343004472
Trained batch 235 in epoch 12, gen_loss = 1.4284895663544284, disc_loss = 0.00018845857184869138
Trained batch 236 in epoch 12, gen_loss = 1.4284539781039274, disc_loss = 0.00018899389085512636
Trained batch 237 in epoch 12, gen_loss = 1.4282432088331014, disc_loss = 0.00018961621480375164
Trained batch 238 in epoch 12, gen_loss = 1.4284938683569681, disc_loss = 0.00019029377310068705
Trained batch 239 in epoch 12, gen_loss = 1.4285059347748756, disc_loss = 0.00019113490129711862
Trained batch 240 in epoch 12, gen_loss = 1.4284908647853805, disc_loss = 0.00019229358768066936
Trained batch 241 in epoch 12, gen_loss = 1.4285083935280476, disc_loss = 0.0001936361031992359
Trained batch 242 in epoch 12, gen_loss = 1.4289990516356479, disc_loss = 0.00019504450895589271
Trained batch 243 in epoch 12, gen_loss = 1.429086196618002, disc_loss = 0.00019676501358576313
Trained batch 244 in epoch 12, gen_loss = 1.42912426335471, disc_loss = 0.00019876969797353791
Trained batch 245 in epoch 12, gen_loss = 1.4289968997482363, disc_loss = 0.00020116745338789887
Trained batch 246 in epoch 12, gen_loss = 1.428683334999239, disc_loss = 0.00020351137914720769
Trained batch 247 in epoch 12, gen_loss = 1.4289606357774427, disc_loss = 0.00020553352129765347
Trained batch 248 in epoch 12, gen_loss = 1.4287669854949276, disc_loss = 0.0002070425670605899
Trained batch 249 in epoch 12, gen_loss = 1.4285557174682617, disc_loss = 0.00020807675404648762
Trained batch 250 in epoch 12, gen_loss = 1.4286885622488075, disc_loss = 0.00020860865764286038
Trained batch 251 in epoch 12, gen_loss = 1.4286551002472165, disc_loss = 0.000208700182098717
Trained batch 252 in epoch 12, gen_loss = 1.4289175427478293, disc_loss = 0.00020841823694038044
Trained batch 253 in epoch 12, gen_loss = 1.428956023351414, disc_loss = 0.00020784597406926927
Trained batch 254 in epoch 12, gen_loss = 1.4291489068199605, disc_loss = 0.0002072178831868394
Trained batch 255 in epoch 12, gen_loss = 1.4290149086154997, disc_loss = 0.00020655344610531756
Trained batch 256 in epoch 12, gen_loss = 1.4292436652610274, disc_loss = 0.00020593365030995107
Trained batch 257 in epoch 12, gen_loss = 1.428928679274034, disc_loss = 0.0002053160683987184
Trained batch 258 in epoch 12, gen_loss = 1.4289575083375436, disc_loss = 0.00020471235801985857
Trained batch 259 in epoch 12, gen_loss = 1.4288037400979263, disc_loss = 0.00020411524334262
Trained batch 260 in epoch 12, gen_loss = 1.4288509631979054, disc_loss = 0.00020350336504021171
Trained batch 261 in epoch 12, gen_loss = 1.4289028903910221, disc_loss = 0.0002028933310771729
Trained batch 262 in epoch 12, gen_loss = 1.42884306807935, disc_loss = 0.00020230930074644383
Trained batch 263 in epoch 12, gen_loss = 1.4287989062793327, disc_loss = 0.00020171553489600421
Trained batch 264 in epoch 12, gen_loss = 1.4285025853031086, disc_loss = 0.00020108677338114675
Trained batch 265 in epoch 12, gen_loss = 1.428664123205314, disc_loss = 0.00020045291247718121
Trained batch 266 in epoch 12, gen_loss = 1.4287184445599046, disc_loss = 0.0001998404762124484
Trained batch 267 in epoch 12, gen_loss = 1.4287194840943636, disc_loss = 0.0001993044308158039
Trained batch 268 in epoch 12, gen_loss = 1.4288653839919647, disc_loss = 0.00019884498296926563
Trained batch 269 in epoch 12, gen_loss = 1.4293110308823762, disc_loss = 0.00019847491568254083
Trained batch 270 in epoch 12, gen_loss = 1.429223760027727, disc_loss = 0.0001981279503484729
Trained batch 271 in epoch 12, gen_loss = 1.4290512042010532, disc_loss = 0.00019776305777989312
Trained batch 272 in epoch 12, gen_loss = 1.4289776466704986, disc_loss = 0.00019735508647586574
Trained batch 273 in epoch 12, gen_loss = 1.4289760868044665, disc_loss = 0.00019688740734384399
Trained batch 274 in epoch 12, gen_loss = 1.4292276456139303, disc_loss = 0.00019638839480731721
Trained batch 275 in epoch 12, gen_loss = 1.4289997526700946, disc_loss = 0.00019586064089431287
Trained batch 276 in epoch 12, gen_loss = 1.428977353908525, disc_loss = 0.00019529515912879042
Trained batch 277 in epoch 12, gen_loss = 1.4287508571748253, disc_loss = 0.00019471934601235732
Trained batch 278 in epoch 12, gen_loss = 1.428966176979858, disc_loss = 0.00019415013904307342
Trained batch 279 in epoch 12, gen_loss = 1.428860298224858, disc_loss = 0.00019356495978562244
Trained batch 280 in epoch 12, gen_loss = 1.4289786892005134, disc_loss = 0.00019297916465718548
Trained batch 281 in epoch 12, gen_loss = 1.4293148001880511, disc_loss = 0.0001924189787745271
Trained batch 282 in epoch 12, gen_loss = 1.429112067070951, disc_loss = 0.0001918573436322548
Trained batch 283 in epoch 12, gen_loss = 1.429067207893855, disc_loss = 0.00019130231859736327
Trained batch 284 in epoch 12, gen_loss = 1.4289371264608284, disc_loss = 0.00019078300990115263
Trained batch 285 in epoch 12, gen_loss = 1.42880807889925, disc_loss = 0.00019029298511503094
Trained batch 286 in epoch 12, gen_loss = 1.4287726617440946, disc_loss = 0.00018982104761134557
Trained batch 287 in epoch 12, gen_loss = 1.4286652364664607, disc_loss = 0.0001893367445341533
Trained batch 288 in epoch 12, gen_loss = 1.428552026979651, disc_loss = 0.00018882650618560638
Trained batch 289 in epoch 12, gen_loss = 1.4284353248004256, disc_loss = 0.00018829075107250587
Trained batch 290 in epoch 12, gen_loss = 1.42866287198673, disc_loss = 0.0001877546037263853
Trained batch 291 in epoch 12, gen_loss = 1.4288161854221397, disc_loss = 0.00018725614460878478
Trained batch 292 in epoch 12, gen_loss = 1.428904644458367, disc_loss = 0.00018679642836126633
Trained batch 293 in epoch 12, gen_loss = 1.4289378231885481, disc_loss = 0.00018637345846753083
Trained batch 294 in epoch 12, gen_loss = 1.4289292723445568, disc_loss = 0.0001859320609922071
Trained batch 295 in epoch 12, gen_loss = 1.4291722633548685, disc_loss = 0.00018543548728573383
Trained batch 296 in epoch 12, gen_loss = 1.429002300256029, disc_loss = 0.00018491089990261983
Trained batch 297 in epoch 12, gen_loss = 1.4290705527235197, disc_loss = 0.00018441482017879515
Trained batch 298 in epoch 12, gen_loss = 1.4290594488482014, disc_loss = 0.00018394547115169803
Trained batch 299 in epoch 12, gen_loss = 1.4291561230023702, disc_loss = 0.00018350942330168133
Trained batch 300 in epoch 12, gen_loss = 1.4291575822323264, disc_loss = 0.00018310516181215683
Trained batch 301 in epoch 12, gen_loss = 1.429170945227541, disc_loss = 0.00018276436232241057
Trained batch 302 in epoch 12, gen_loss = 1.4291280248377582, disc_loss = 0.00018253625555966923
Trained batch 303 in epoch 12, gen_loss = 1.4291430005901737, disc_loss = 0.00018229648657396816
Trained batch 304 in epoch 12, gen_loss = 1.429197596721962, disc_loss = 0.00018196609172398476
Trained batch 305 in epoch 12, gen_loss = 1.4292050074128544, disc_loss = 0.00018161109239693307
Trained batch 306 in epoch 12, gen_loss = 1.4291569219738343, disc_loss = 0.00018129476095635652
Trained batch 307 in epoch 12, gen_loss = 1.4290889102917212, disc_loss = 0.00018106417262545135
Trained batch 308 in epoch 12, gen_loss = 1.4289821382479375, disc_loss = 0.00018090569726734922
Trained batch 309 in epoch 12, gen_loss = 1.4287359153070758, disc_loss = 0.00018088692948132972
Trained batch 310 in epoch 12, gen_loss = 1.4286368767164912, disc_loss = 0.0001810753629736133
Trained batch 311 in epoch 12, gen_loss = 1.428730070590973, disc_loss = 0.00018147761894537185
Trained batch 312 in epoch 12, gen_loss = 1.428649483397365, disc_loss = 0.00018212747786361643
Trained batch 313 in epoch 12, gen_loss = 1.4288728685136054, disc_loss = 0.00018312709077001308
Trained batch 314 in epoch 12, gen_loss = 1.4289234865279425, disc_loss = 0.00018466456418710073
Trained batch 315 in epoch 12, gen_loss = 1.4290200011639655, disc_loss = 0.00018692195489384636
Trained batch 316 in epoch 12, gen_loss = 1.429085331384316, disc_loss = 0.0001900004613607015
Trained batch 317 in epoch 12, gen_loss = 1.429139161634745, disc_loss = 0.00019375027409439312
Trained batch 318 in epoch 12, gen_loss = 1.4290888380481157, disc_loss = 0.00019849971042082718
Trained batch 319 in epoch 12, gen_loss = 1.429079143702984, disc_loss = 0.00020472551396437665
Trained batch 320 in epoch 12, gen_loss = 1.4288643639407055, disc_loss = 0.00021157587791570553
Trained batch 321 in epoch 12, gen_loss = 1.4288125149211528, disc_loss = 0.00021724696103571112
Trained batch 322 in epoch 12, gen_loss = 1.4287536136875212, disc_loss = 0.00022108154074598323
Trained batch 323 in epoch 12, gen_loss = 1.4288327384878088, disc_loss = 0.0002231770470890847
Trained batch 324 in epoch 12, gen_loss = 1.4286217520787166, disc_loss = 0.00022396502479610857
Trained batch 325 in epoch 12, gen_loss = 1.4285167704330632, disc_loss = 0.00022398725573418617
Trained batch 326 in epoch 12, gen_loss = 1.4286742082794144, disc_loss = 0.0002236731776310183
Trained batch 327 in epoch 12, gen_loss = 1.428681040319001, disc_loss = 0.00022329822452154142
Trained batch 328 in epoch 12, gen_loss = 1.4285273562811065, disc_loss = 0.00022293651786405136
Trained batch 329 in epoch 12, gen_loss = 1.4282371351213166, disc_loss = 0.00022261326279421513
Trained batch 330 in epoch 12, gen_loss = 1.428298632543973, disc_loss = 0.00022236629512170338
Trained batch 331 in epoch 12, gen_loss = 1.428351204438382, disc_loss = 0.00022214779568435828
Trained batch 332 in epoch 12, gen_loss = 1.4282557749533438, disc_loss = 0.00022191568484583864
Trained batch 333 in epoch 12, gen_loss = 1.428279626869156, disc_loss = 0.00022166394687510928
Trained batch 334 in epoch 12, gen_loss = 1.4280976437810642, disc_loss = 0.00022143352752983215
Trained batch 335 in epoch 12, gen_loss = 1.4281498623036204, disc_loss = 0.00022120973799354986
Trained batch 336 in epoch 12, gen_loss = 1.4284041076456404, disc_loss = 0.00022095046157815504
Trained batch 337 in epoch 12, gen_loss = 1.4284566595004156, disc_loss = 0.00022060242475179396
Trained batch 338 in epoch 12, gen_loss = 1.4284577383755934, disc_loss = 0.00022016177255359642
Trained batch 339 in epoch 12, gen_loss = 1.428559443179299, disc_loss = 0.00021968806696510428
Trained batch 340 in epoch 12, gen_loss = 1.4285460311995923, disc_loss = 0.00021919730020979045
Trained batch 341 in epoch 12, gen_loss = 1.428417596203542, disc_loss = 0.00021870217994137154
Trained batch 342 in epoch 12, gen_loss = 1.4283301642615316, disc_loss = 0.00021825279733151675
Trained batch 343 in epoch 12, gen_loss = 1.4283707062172335, disc_loss = 0.0002178604642225299
Trained batch 344 in epoch 12, gen_loss = 1.4282625056695246, disc_loss = 0.00021752265015295604
Trained batch 345 in epoch 12, gen_loss = 1.4281487364989485, disc_loss = 0.00021724465756903024
Trained batch 346 in epoch 12, gen_loss = 1.4281578335363514, disc_loss = 0.00021706204176057627
Trained batch 347 in epoch 12, gen_loss = 1.4281774588014888, disc_loss = 0.00021691188347741161
Trained batch 348 in epoch 12, gen_loss = 1.4281418630933351, disc_loss = 0.0002167465329779573
Trained batch 349 in epoch 12, gen_loss = 1.4282107874325343, disc_loss = 0.00021656045093030636
Trained batch 350 in epoch 12, gen_loss = 1.428131559975127, disc_loss = 0.00021633876017701945
Trained batch 351 in epoch 12, gen_loss = 1.4283862489868293, disc_loss = 0.00021609488134737893
Trained batch 352 in epoch 12, gen_loss = 1.4285272795485369, disc_loss = 0.00021589348600776148
Trained batch 353 in epoch 12, gen_loss = 1.428489227752901, disc_loss = 0.00021564982391364897
Trained batch 354 in epoch 12, gen_loss = 1.4285071406565921, disc_loss = 0.00021548806014860174
Trained batch 355 in epoch 12, gen_loss = 1.4286143779754639, disc_loss = 0.0002154754902068326
Trained batch 356 in epoch 12, gen_loss = 1.4288099065882152, disc_loss = 0.00021570322446257538
Trained batch 357 in epoch 12, gen_loss = 1.4288948987449348, disc_loss = 0.00021614647308859926
Trained batch 358 in epoch 12, gen_loss = 1.428910833215315, disc_loss = 0.000216669874327362
Trained batch 359 in epoch 12, gen_loss = 1.4288467413849302, disc_loss = 0.00021718146500057225
Trained batch 360 in epoch 12, gen_loss = 1.4287171225138318, disc_loss = 0.0002177190035329651
Trained batch 361 in epoch 12, gen_loss = 1.4287107379396975, disc_loss = 0.00021826182438110649
Trained batch 362 in epoch 12, gen_loss = 1.4287647153391982, disc_loss = 0.00021871285131787235
Trained batch 363 in epoch 12, gen_loss = 1.4287686793358771, disc_loss = 0.0002190567315165526
Trained batch 364 in epoch 12, gen_loss = 1.428687835066286, disc_loss = 0.00021922019952074913
Trained batch 365 in epoch 12, gen_loss = 1.4285300357745645, disc_loss = 0.00021921995892109128
Trained batch 366 in epoch 12, gen_loss = 1.4284404870274932, disc_loss = 0.00021900847764733808
Trained batch 367 in epoch 12, gen_loss = 1.4284122547377711, disc_loss = 0.00021858498215628376
Trained batch 368 in epoch 12, gen_loss = 1.4285578369125118, disc_loss = 0.00021816553632825138
Trained batch 369 in epoch 12, gen_loss = 1.4285620956807523, disc_loss = 0.00021774955655780867
Trained batch 370 in epoch 12, gen_loss = 1.428518419638477, disc_loss = 0.00021743490784585122
Trained batch 371 in epoch 12, gen_loss = 1.4285891482266047, disc_loss = 0.00021717005211030482
Trained batch 372 in epoch 12, gen_loss = 1.428693459117061, disc_loss = 0.00021686550073949688
Trained batch 373 in epoch 12, gen_loss = 1.428620997278448, disc_loss = 0.00021657556951923618
Trained batch 374 in epoch 12, gen_loss = 1.4284749739964804, disc_loss = 0.00021638216673454735
Trained batch 375 in epoch 12, gen_loss = 1.4285756492234292, disc_loss = 0.00021626722571241734
Trained batch 376 in epoch 12, gen_loss = 1.428813046738703, disc_loss = 0.00021621154913574857
Trained batch 377 in epoch 12, gen_loss = 1.428710748594274, disc_loss = 0.0002161559198385769
Trained batch 378 in epoch 12, gen_loss = 1.4285276832555402, disc_loss = 0.00021605494453249676
Trained batch 379 in epoch 12, gen_loss = 1.4284859503570355, disc_loss = 0.00021594306945668283
Trained batch 380 in epoch 12, gen_loss = 1.4286490103078326, disc_loss = 0.00021580735284353397
Trained batch 381 in epoch 12, gen_loss = 1.4282960445468962, disc_loss = 0.00021558660431365031
Trained batch 382 in epoch 12, gen_loss = 1.4281538223784525, disc_loss = 0.00021526473777136291
Trained batch 383 in epoch 12, gen_loss = 1.427904569543898, disc_loss = 0.00021490589259561452
Trained batch 384 in epoch 12, gen_loss = 1.4277905448690638, disc_loss = 0.0002144967105518195
Trained batch 385 in epoch 12, gen_loss = 1.427891775425234, disc_loss = 0.00021406970545804094
Trained batch 386 in epoch 12, gen_loss = 1.427979785342549, disc_loss = 0.000213626848106931
Trained batch 387 in epoch 12, gen_loss = 1.4279032257414355, disc_loss = 0.00021317063076062322
Trained batch 388 in epoch 12, gen_loss = 1.4278705705407346, disc_loss = 0.0002127076527697455
Trained batch 389 in epoch 12, gen_loss = 1.4279424163011405, disc_loss = 0.00021225431730552093
Trained batch 390 in epoch 12, gen_loss = 1.4279125861804505, disc_loss = 0.00021183060639405526
Trained batch 391 in epoch 12, gen_loss = 1.4279278200499865, disc_loss = 0.00021140428702892677
Trained batch 392 in epoch 12, gen_loss = 1.4279458098132496, disc_loss = 0.00021094959883974498
Trained batch 393 in epoch 12, gen_loss = 1.4279623642790742, disc_loss = 0.00021047545954568678
Trained batch 394 in epoch 12, gen_loss = 1.4281077412110341, disc_loss = 0.00021002049700344494
Trained batch 395 in epoch 12, gen_loss = 1.4279601435468654, disc_loss = 0.0002096007032185188
Trained batch 396 in epoch 12, gen_loss = 1.428144546840293, disc_loss = 0.00020922670720721466
Trained batch 397 in epoch 12, gen_loss = 1.4281232749397432, disc_loss = 0.00020893046546541826
Trained batch 398 in epoch 12, gen_loss = 1.4280880399813927, disc_loss = 0.00020870108441851612
Trained batch 399 in epoch 12, gen_loss = 1.4279140919446944, disc_loss = 0.00020852724726410087
Trained batch 400 in epoch 12, gen_loss = 1.428036468879243, disc_loss = 0.00020840423544961
Trained batch 401 in epoch 12, gen_loss = 1.4282124763104453, disc_loss = 0.00020834851142380876
Trained batch 402 in epoch 12, gen_loss = 1.4281821023145918, disc_loss = 0.00020838211206025264
Trained batch 403 in epoch 12, gen_loss = 1.4281537323304923, disc_loss = 0.0002084930464355572
Trained batch 404 in epoch 12, gen_loss = 1.4282800927574253, disc_loss = 0.00020857593996351855
Trained batch 405 in epoch 12, gen_loss = 1.4281676267755443, disc_loss = 0.00020870320271829508
Trained batch 406 in epoch 12, gen_loss = 1.428211731172604, disc_loss = 0.00020887092026722123
Trained batch 407 in epoch 12, gen_loss = 1.4281788070996602, disc_loss = 0.0002090474509651697
Trained batch 408 in epoch 12, gen_loss = 1.4282773669016682, disc_loss = 0.00020920162977209437
Trained batch 409 in epoch 12, gen_loss = 1.4284242060126329, disc_loss = 0.00020929885081497516
Trained batch 410 in epoch 12, gen_loss = 1.4284663647050695, disc_loss = 0.00020923657695560432
Trained batch 411 in epoch 12, gen_loss = 1.4285385029987223, disc_loss = 0.00020904945408669272
Trained batch 412 in epoch 12, gen_loss = 1.4286061138564103, disc_loss = 0.00020873667845895292
Trained batch 413 in epoch 12, gen_loss = 1.4285957960114963, disc_loss = 0.0002083775415208631
Trained batch 414 in epoch 12, gen_loss = 1.4284979142338396, disc_loss = 0.00020801817676307022
Trained batch 415 in epoch 12, gen_loss = 1.4285672338536153, disc_loss = 0.0002077210851325617
Trained batch 416 in epoch 12, gen_loss = 1.4286258363609405, disc_loss = 0.00020754513400742907
Trained batch 417 in epoch 12, gen_loss = 1.4288174584151454, disc_loss = 0.00020757796459005667
Trained batch 418 in epoch 12, gen_loss = 1.428783333386897, disc_loss = 0.00020798344363239378
Trained batch 419 in epoch 12, gen_loss = 1.4287707961740947, disc_loss = 0.00020887343206638998
Trained batch 420 in epoch 12, gen_loss = 1.4287681823105256, disc_loss = 0.00021009414733634047
Trained batch 421 in epoch 12, gen_loss = 1.4286895888676576, disc_loss = 0.00021163526923343693
Trained batch 422 in epoch 12, gen_loss = 1.4285885594415326, disc_loss = 0.0002134751280456719
Trained batch 423 in epoch 12, gen_loss = 1.4288097825252786, disc_loss = 0.0002153227535901986
Trained batch 424 in epoch 12, gen_loss = 1.4288780563017902, disc_loss = 0.0002169614348702667
Trained batch 425 in epoch 12, gen_loss = 1.428966220835565, disc_loss = 0.00021831076468464437
Trained batch 426 in epoch 12, gen_loss = 1.42903069338698, disc_loss = 0.00021942714681034113
Trained batch 427 in epoch 12, gen_loss = 1.429043003331835, disc_loss = 0.00022062515068325844
Trained batch 428 in epoch 12, gen_loss = 1.429087047532444, disc_loss = 0.00022181096675396396
Trained batch 429 in epoch 12, gen_loss = 1.429263168989226, disc_loss = 0.00022273702405411399
Trained batch 430 in epoch 12, gen_loss = 1.4291880285656922, disc_loss = 0.00022341774158898104
Trained batch 431 in epoch 12, gen_loss = 1.4292501779618088, disc_loss = 0.00022350051657819373
Trained batch 432 in epoch 12, gen_loss = 1.4292624775862308, disc_loss = 0.0002232152659013611
Trained batch 433 in epoch 12, gen_loss = 1.4292115937180234, disc_loss = 0.00022282508463479557
Trained batch 434 in epoch 12, gen_loss = 1.4293094226683694, disc_loss = 0.00022243684921370173
Trained batch 435 in epoch 12, gen_loss = 1.4293705681595235, disc_loss = 0.00022199425782239756
Trained batch 436 in epoch 12, gen_loss = 1.4293673417660955, disc_loss = 0.00022153379390026453
Trained batch 437 in epoch 12, gen_loss = 1.4293238101484569, disc_loss = 0.00022108684074799832
Trained batch 438 in epoch 12, gen_loss = 1.4292520271075342, disc_loss = 0.00022068027692615847
Trained batch 439 in epoch 12, gen_loss = 1.4292751973325557, disc_loss = 0.0002202795471227794
Trained batch 440 in epoch 12, gen_loss = 1.4291092008690174, disc_loss = 0.000219904772438276
Trained batch 441 in epoch 12, gen_loss = 1.4289772823385523, disc_loss = 0.00021951456090893803
Trained batch 442 in epoch 12, gen_loss = 1.4290177994334132, disc_loss = 0.00021915947529727107
Trained batch 443 in epoch 12, gen_loss = 1.4288123824574925, disc_loss = 0.00021887700603992352
Trained batch 444 in epoch 12, gen_loss = 1.4288103735848758, disc_loss = 0.00021859040677830644
Trained batch 445 in epoch 12, gen_loss = 1.4288015886807122, disc_loss = 0.0002182886908958771
Trained batch 446 in epoch 12, gen_loss = 1.4288695261249074, disc_loss = 0.00021812136950374604
Trained batch 447 in epoch 12, gen_loss = 1.429023994931153, disc_loss = 0.00021813917077143481
Trained batch 448 in epoch 12, gen_loss = 1.429097068336334, disc_loss = 0.00021837916874634916
Trained batch 449 in epoch 12, gen_loss = 1.428980376455519, disc_loss = 0.00021868532228028117
Trained batch 450 in epoch 12, gen_loss = 1.4289756127841722, disc_loss = 0.0002195340922942084
Trained batch 451 in epoch 12, gen_loss = 1.4289976258193497, disc_loss = 0.00022148089632199406
Trained batch 452 in epoch 12, gen_loss = 1.4290608849220192, disc_loss = 0.00022404474656976617
Trained batch 453 in epoch 12, gen_loss = 1.4289876776644836, disc_loss = 0.00022698795367989382
Trained batch 454 in epoch 12, gen_loss = 1.4287780227241935, disc_loss = 0.00022967266506764266
Trained batch 455 in epoch 12, gen_loss = 1.4287171672310746, disc_loss = 0.00023185482095948573
Trained batch 456 in epoch 12, gen_loss = 1.428544212483212, disc_loss = 0.00023350292368880775
Trained batch 457 in epoch 12, gen_loss = 1.428528199029281, disc_loss = 0.0002347216400207342
Trained batch 458 in epoch 12, gen_loss = 1.4285947868766868, disc_loss = 0.00023530589947165655
Trained batch 459 in epoch 12, gen_loss = 1.428592333327169, disc_loss = 0.00023606079936223028
Trained batch 460 in epoch 12, gen_loss = 1.428445675109317, disc_loss = 0.0002375823510715088
Trained batch 461 in epoch 12, gen_loss = 1.4285630238004576, disc_loss = 0.00023903732164312497
Trained batch 462 in epoch 12, gen_loss = 1.4285976644726088, disc_loss = 0.00024015182939453726
Trained batch 463 in epoch 12, gen_loss = 1.4286598971691624, disc_loss = 0.00024082729229074425
Trained batch 464 in epoch 12, gen_loss = 1.4286425982752153, disc_loss = 0.00024119187448807787
Trained batch 465 in epoch 12, gen_loss = 1.4288669883437424, disc_loss = 0.0002413097605086544
Trained batch 466 in epoch 12, gen_loss = 1.4289113844742867, disc_loss = 0.00024123142868716282
Trained batch 467 in epoch 12, gen_loss = 1.4288589798996592, disc_loss = 0.00024102336087746822
Trained batch 468 in epoch 12, gen_loss = 1.4286983938359503, disc_loss = 0.00024122328274521054
Trained batch 469 in epoch 12, gen_loss = 1.4286395374764786, disc_loss = 0.00024196615214215001
Trained batch 470 in epoch 12, gen_loss = 1.4285196096274504, disc_loss = 0.00024314889698114466
Trained batch 471 in epoch 12, gen_loss = 1.4284477170746206, disc_loss = 0.0002442260181242553
Trained batch 472 in epoch 12, gen_loss = 1.4284469786456473, disc_loss = 0.00024493925160156533
Trained batch 473 in epoch 12, gen_loss = 1.4282854702402268, disc_loss = 0.00024520854415023384
Trained batch 474 in epoch 12, gen_loss = 1.4283328472940546, disc_loss = 0.00024517399202618673
Trained batch 475 in epoch 12, gen_loss = 1.4284214334828513, disc_loss = 0.0002449770677307273
Trained batch 476 in epoch 12, gen_loss = 1.4284720158427016, disc_loss = 0.0002447064830763258
Trained batch 477 in epoch 12, gen_loss = 1.4284047160188524, disc_loss = 0.0002443652034481263
Trained batch 478 in epoch 12, gen_loss = 1.4284387406327281, disc_loss = 0.00024441666986858536
Trained batch 479 in epoch 12, gen_loss = 1.428371086716652, disc_loss = 0.00024442352607441836
Trained batch 480 in epoch 12, gen_loss = 1.4283388134347674, disc_loss = 0.00024459912718747227
Trained batch 481 in epoch 12, gen_loss = 1.4283135634734918, disc_loss = 0.00024469532434304105
Trained batch 482 in epoch 12, gen_loss = 1.4282412489502079, disc_loss = 0.0002446298504665055
Trained batch 483 in epoch 12, gen_loss = 1.4280238257459372, disc_loss = 0.0002444238785898983
Trained batch 484 in epoch 12, gen_loss = 1.428044092040701, disc_loss = 0.00024409075635536357
Trained batch 485 in epoch 12, gen_loss = 1.4279212186365953, disc_loss = 0.00024366018922577078
Trained batch 486 in epoch 12, gen_loss = 1.427924242842124, disc_loss = 0.00024320587741027112
Trained batch 487 in epoch 12, gen_loss = 1.4279581977695714, disc_loss = 0.00024276483713574784
Trained batch 488 in epoch 12, gen_loss = 1.4279886510962114, disc_loss = 0.00024234408830889597
Trained batch 489 in epoch 12, gen_loss = 1.4281338601696247, disc_loss = 0.00024196106731286986
Trained batch 490 in epoch 12, gen_loss = 1.4280588500611409, disc_loss = 0.00024162830340861184
Trained batch 491 in epoch 12, gen_loss = 1.4280770207808269, disc_loss = 0.00024129246979625566
Trained batch 492 in epoch 12, gen_loss = 1.4280147658883922, disc_loss = 0.00024094274189776806
Trained batch 493 in epoch 12, gen_loss = 1.4280142899949542, disc_loss = 0.00024056814249281145
Trained batch 494 in epoch 12, gen_loss = 1.4280913880377104, disc_loss = 0.00024016426995689417
Trained batch 495 in epoch 12, gen_loss = 1.4280526724553877, disc_loss = 0.00023977938597072939
Trained batch 496 in epoch 12, gen_loss = 1.4279419876919905, disc_loss = 0.00023943817663170215
Trained batch 497 in epoch 12, gen_loss = 1.4279593487819993, disc_loss = 0.00023920483859348247
Trained batch 498 in epoch 12, gen_loss = 1.4280353151485772, disc_loss = 0.0002390614254637514
Trained batch 499 in epoch 12, gen_loss = 1.4281555795669556, disc_loss = 0.00023900341078842758
Trained batch 500 in epoch 12, gen_loss = 1.4282618178103021, disc_loss = 0.00023905777066364882
Trained batch 501 in epoch 12, gen_loss = 1.4281622302009764, disc_loss = 0.0002392159746534843
Trained batch 502 in epoch 12, gen_loss = 1.4280586801987756, disc_loss = 0.0002393946072933654
Trained batch 503 in epoch 12, gen_loss = 1.4280802233824654, disc_loss = 0.00023952208414537756
Trained batch 504 in epoch 12, gen_loss = 1.428023330764015, disc_loss = 0.00023948131635581087
Trained batch 505 in epoch 12, gen_loss = 1.4279765359497825, disc_loss = 0.0002392387370002735
Trained batch 506 in epoch 12, gen_loss = 1.4280546433356622, disc_loss = 0.0002388838856966998
Trained batch 507 in epoch 12, gen_loss = 1.4280057368785377, disc_loss = 0.00023852246103497307
Trained batch 508 in epoch 12, gen_loss = 1.4280236596442861, disc_loss = 0.0002381704317737798
Trained batch 509 in epoch 12, gen_loss = 1.4281113757806665, disc_loss = 0.00023780881531945173
Trained batch 510 in epoch 12, gen_loss = 1.428106158913465, disc_loss = 0.00023744015780096663
Trained batch 511 in epoch 12, gen_loss = 1.4281203704886138, disc_loss = 0.00023705632665382836
Trained batch 512 in epoch 12, gen_loss = 1.428221280579446, disc_loss = 0.00023664762852737293
Trained batch 513 in epoch 12, gen_loss = 1.4280650290997576, disc_loss = 0.00023626469131933972
Trained batch 514 in epoch 12, gen_loss = 1.4280102225183284, disc_loss = 0.00023590541117371385
Trained batch 515 in epoch 12, gen_loss = 1.428163650886033, disc_loss = 0.00023555574726608677
Trained batch 516 in epoch 12, gen_loss = 1.428168171609624, disc_loss = 0.00023520731291624698
Trained batch 517 in epoch 12, gen_loss = 1.4281365958880274, disc_loss = 0.00023484481571218167
Trained batch 518 in epoch 12, gen_loss = 1.4282152342658512, disc_loss = 0.00023448176632703932
Trained batch 519 in epoch 12, gen_loss = 1.4281124937992828, disc_loss = 0.0002341569707893471
Trained batch 520 in epoch 12, gen_loss = 1.428045017934349, disc_loss = 0.00023388589267078663
Trained batch 521 in epoch 12, gen_loss = 1.4280306052887577, disc_loss = 0.00023365156013677806
Trained batch 522 in epoch 12, gen_loss = 1.4280559271289104, disc_loss = 0.00023344891840255022
Trained batch 523 in epoch 12, gen_loss = 1.4279706548643476, disc_loss = 0.0002332375404612252
Trained batch 524 in epoch 12, gen_loss = 1.4279607282366071, disc_loss = 0.00023298168510553383
Trained batch 525 in epoch 12, gen_loss = 1.4279395922055262, disc_loss = 0.00023268066128255966
Trained batch 526 in epoch 12, gen_loss = 1.427872530649464, disc_loss = 0.0002323637988153921
Trained batch 527 in epoch 12, gen_loss = 1.4278720181548235, disc_loss = 0.00023205258550219833
Trained batch 528 in epoch 12, gen_loss = 1.4279813106208759, disc_loss = 0.00023172756306327958
Trained batch 529 in epoch 12, gen_loss = 1.427911924191241, disc_loss = 0.00023140341714370495
Trained batch 530 in epoch 12, gen_loss = 1.4279889647345534, disc_loss = 0.00023106708387251665
Trained batch 531 in epoch 12, gen_loss = 1.4279126950672694, disc_loss = 0.00023072546805212224
Trained batch 532 in epoch 12, gen_loss = 1.427940972974108, disc_loss = 0.00023038567314784988
Trained batch 533 in epoch 12, gen_loss = 1.427969054336405, disc_loss = 0.00023004991375144234
Trained batch 534 in epoch 12, gen_loss = 1.4279490263662606, disc_loss = 0.00022970859572524205
Trained batch 535 in epoch 12, gen_loss = 1.4278317618725904, disc_loss = 0.00022940908046851957
Trained batch 536 in epoch 12, gen_loss = 1.4277598240744025, disc_loss = 0.00022910976350707223
Trained batch 537 in epoch 12, gen_loss = 1.4277099169319891, disc_loss = 0.00022878145015211887
Trained batch 538 in epoch 12, gen_loss = 1.4277299147147637, disc_loss = 0.00022842886053877346
Trained batch 539 in epoch 12, gen_loss = 1.427716365787718, disc_loss = 0.00022808278513198105
Trained batch 540 in epoch 12, gen_loss = 1.4277840204908756, disc_loss = 0.00022775979845670772
Trained batch 541 in epoch 12, gen_loss = 1.4278577306613711, disc_loss = 0.00022745504261818637
Trained batch 542 in epoch 12, gen_loss = 1.42791339727616, disc_loss = 0.0002271764397824935
Trained batch 543 in epoch 12, gen_loss = 1.4278821962721207, disc_loss = 0.00022692209502645923
Trained batch 544 in epoch 12, gen_loss = 1.4279332248442764, disc_loss = 0.0002266577841944185
Trained batch 545 in epoch 12, gen_loss = 1.427947684958741, disc_loss = 0.00022639846059434234
Trained batch 546 in epoch 12, gen_loss = 1.4278845381693168, disc_loss = 0.00022615706004991735
Trained batch 547 in epoch 12, gen_loss = 1.4279023367558084, disc_loss = 0.00022592957305736172
Trained batch 548 in epoch 12, gen_loss = 1.4279759351455883, disc_loss = 0.00022572121758104933
Trained batch 549 in epoch 12, gen_loss = 1.4279359518397938, disc_loss = 0.00022552583380522925
Trained batch 550 in epoch 12, gen_loss = 1.427861694848256, disc_loss = 0.00022527833978846007
Trained batch 551 in epoch 12, gen_loss = 1.4278655924658845, disc_loss = 0.0002249756935204947
Trained batch 552 in epoch 12, gen_loss = 1.4278479510578066, disc_loss = 0.00022466345981360668
Trained batch 553 in epoch 12, gen_loss = 1.4278019313777828, disc_loss = 0.00022436923486549812
Trained batch 554 in epoch 12, gen_loss = 1.427941082619332, disc_loss = 0.00022409759131643023
Trained batch 555 in epoch 12, gen_loss = 1.4280668454204533, disc_loss = 0.00022386509197191024
Trained batch 556 in epoch 12, gen_loss = 1.4280787338260261, disc_loss = 0.00022367121478112346
Trained batch 557 in epoch 12, gen_loss = 1.4280339391855357, disc_loss = 0.00022352338646832514
Trained batch 558 in epoch 12, gen_loss = 1.4282173822518964, disc_loss = 0.00022344884900331425
Trained batch 559 in epoch 12, gen_loss = 1.4282068906085832, disc_loss = 0.0002234473448035195
Trained batch 560 in epoch 12, gen_loss = 1.4283889655335915, disc_loss = 0.00022352865839974894
Trained batch 561 in epoch 12, gen_loss = 1.4284038681576685, disc_loss = 0.0002236544988976209
Trained batch 562 in epoch 12, gen_loss = 1.428493452961449, disc_loss = 0.0002238124037165295
Trained batch 563 in epoch 12, gen_loss = 1.4284110627275832, disc_loss = 0.00022401927314300943
Trained batch 564 in epoch 12, gen_loss = 1.428477072926749, disc_loss = 0.00022422002994303955
Trained batch 565 in epoch 12, gen_loss = 1.4285020242731479, disc_loss = 0.00022436406081152607
Trained batch 566 in epoch 12, gen_loss = 1.4285893896479664, disc_loss = 0.00022446218566281017
Trained batch 567 in epoch 12, gen_loss = 1.428635987177701, disc_loss = 0.0002245087282229268
Trained batch 568 in epoch 12, gen_loss = 1.428643065303407, disc_loss = 0.00022452162172296902
Trained batch 569 in epoch 12, gen_loss = 1.4285500064230803, disc_loss = 0.00022454088839846296
Trained batch 570 in epoch 12, gen_loss = 1.4285953234874638, disc_loss = 0.0002245750198938012
Trained batch 571 in epoch 12, gen_loss = 1.4286022475966207, disc_loss = 0.00022461931282371304
Trained batch 572 in epoch 12, gen_loss = 1.4286096077314847, disc_loss = 0.0002246386381063751
Trained batch 573 in epoch 12, gen_loss = 1.4287323127224885, disc_loss = 0.0002246695113973631
Trained batch 574 in epoch 12, gen_loss = 1.4286245947298797, disc_loss = 0.0002246927124835328
Trained batch 575 in epoch 12, gen_loss = 1.4285586656381686, disc_loss = 0.0002246885026693235
Trained batch 576 in epoch 12, gen_loss = 1.4285657174459157, disc_loss = 0.00022461546879255477
Trained batch 577 in epoch 12, gen_loss = 1.428528860984789, disc_loss = 0.00022447200774225836
Trained batch 578 in epoch 12, gen_loss = 1.4285289168563737, disc_loss = 0.0002242848289218576
Trained batch 579 in epoch 12, gen_loss = 1.4284673370164016, disc_loss = 0.00022409296134042207
Trained batch 580 in epoch 12, gen_loss = 1.428456256598901, disc_loss = 0.00022387508802325704
Trained batch 581 in epoch 12, gen_loss = 1.4284811884267223, disc_loss = 0.0002236192942847705
Trained batch 582 in epoch 12, gen_loss = 1.4286105714572233, disc_loss = 0.00022338431083398957
Trained batch 583 in epoch 12, gen_loss = 1.4284958745518777, disc_loss = 0.00022318638509067856
Trained batch 584 in epoch 12, gen_loss = 1.428573616957053, disc_loss = 0.00022303469494133432
Trained batch 585 in epoch 12, gen_loss = 1.4285094542714922, disc_loss = 0.00022291864829624442
Trained batch 586 in epoch 12, gen_loss = 1.4284513869927324, disc_loss = 0.00022282499182610168
Trained batch 587 in epoch 12, gen_loss = 1.428490622919433, disc_loss = 0.0002227438847258862
Trained batch 588 in epoch 12, gen_loss = 1.4284723663168164, disc_loss = 0.00022264360517532412
Trained batch 589 in epoch 12, gen_loss = 1.4284186126822132, disc_loss = 0.00022253268559278833
Trained batch 590 in epoch 12, gen_loss = 1.4283471034868114, disc_loss = 0.0002224171789233118
Trained batch 591 in epoch 12, gen_loss = 1.4284238720665108, disc_loss = 0.00022230431891084418
Trained batch 592 in epoch 12, gen_loss = 1.4284752792290853, disc_loss = 0.00022218922360547547
Trained batch 593 in epoch 12, gen_loss = 1.4285121417607523, disc_loss = 0.00022206258484828151
Trained batch 594 in epoch 12, gen_loss = 1.428427816038372, disc_loss = 0.00022190890780345835
Trained batch 595 in epoch 12, gen_loss = 1.4283600839592467, disc_loss = 0.0002217237267951538
Trained batch 596 in epoch 12, gen_loss = 1.4282760983535792, disc_loss = 0.00022152718964000263
Trained batch 597 in epoch 12, gen_loss = 1.4281841662017796, disc_loss = 0.00022133038587480617
Trained batch 598 in epoch 12, gen_loss = 1.4281406711059341, disc_loss = 0.0002211203472035294
Trained batch 599 in epoch 12, gen_loss = 1.4280864236752193, disc_loss = 0.00022090471642513876
Trained batch 600 in epoch 12, gen_loss = 1.4280548327774454, disc_loss = 0.00022071544115233836
Trained batch 601 in epoch 12, gen_loss = 1.428082983557172, disc_loss = 0.00022056577120828513
Trained batch 602 in epoch 12, gen_loss = 1.4281510763105072, disc_loss = 0.00022044730470873914
Trained batch 603 in epoch 12, gen_loss = 1.4281858894603932, disc_loss = 0.000220347322271441
Trained batch 604 in epoch 12, gen_loss = 1.4281348486577183, disc_loss = 0.00022027411171372726
Trained batch 605 in epoch 12, gen_loss = 1.428127080497175, disc_loss = 0.00022025179931264418
Trained batch 606 in epoch 12, gen_loss = 1.4280443656974806, disc_loss = 0.00022032387654543118
Trained batch 607 in epoch 12, gen_loss = 1.428015465995199, disc_loss = 0.00022047099283003933
Trained batch 608 in epoch 12, gen_loss = 1.4279909775957882, disc_loss = 0.00022068833012212403
Trained batch 609 in epoch 12, gen_loss = 1.4280363813775485, disc_loss = 0.00022097020485742805
Trained batch 610 in epoch 12, gen_loss = 1.4281033974037234, disc_loss = 0.00022132983882186527
Trained batch 611 in epoch 12, gen_loss = 1.428139042425779, disc_loss = 0.00022175111356464305
Trained batch 612 in epoch 12, gen_loss = 1.4282034170763722, disc_loss = 0.0002221647170609221
Trained batch 613 in epoch 12, gen_loss = 1.4281325318914282, disc_loss = 0.00022260102227417234
Trained batch 614 in epoch 12, gen_loss = 1.4281664074921026, disc_loss = 0.00022297288632238988
Trained batch 615 in epoch 12, gen_loss = 1.4281072434666868, disc_loss = 0.00022327365754141022
Trained batch 616 in epoch 12, gen_loss = 1.427953197658545, disc_loss = 0.00022354158021318515
Trained batch 617 in epoch 12, gen_loss = 1.4279474016146367, disc_loss = 0.0002238133203135679
Trained batch 618 in epoch 12, gen_loss = 1.4280655599757428, disc_loss = 0.0002241213919226925
Trained batch 619 in epoch 12, gen_loss = 1.428072100877762, disc_loss = 0.00022444937977495776
Trained batch 620 in epoch 12, gen_loss = 1.4280739362305106, disc_loss = 0.00022480844427776544
Trained batch 621 in epoch 12, gen_loss = 1.4282148725733497, disc_loss = 0.00022520774736575793
Trained batch 622 in epoch 12, gen_loss = 1.4280960996116527, disc_loss = 0.00022559753831760565
Trained batch 623 in epoch 12, gen_loss = 1.4281609411805103, disc_loss = 0.00022595894229664572
Trained batch 624 in epoch 12, gen_loss = 1.4281404216766358, disc_loss = 0.00022627448108396492
Trained batch 625 in epoch 12, gen_loss = 1.4280725254799231, disc_loss = 0.00022654256720731694
Trained batch 626 in epoch 12, gen_loss = 1.4280159754806347, disc_loss = 0.0002267539566209628
Trained batch 627 in epoch 12, gen_loss = 1.4280411747230846, disc_loss = 0.0002268983299895779
Trained batch 628 in epoch 12, gen_loss = 1.4279167060821727, disc_loss = 0.00022693364236322277
Trained batch 629 in epoch 12, gen_loss = 1.4279075516594781, disc_loss = 0.00022687830094091912
Trained batch 630 in epoch 12, gen_loss = 1.4279232724154998, disc_loss = 0.00022672518619339693
Trained batch 631 in epoch 12, gen_loss = 1.4277721556681622, disc_loss = 0.00022654853670315742
Trained batch 632 in epoch 12, gen_loss = 1.427913816430934, disc_loss = 0.00022636933701899453
Trained batch 633 in epoch 12, gen_loss = 1.4278016492771426, disc_loss = 0.00022621717720373486
Trained batch 634 in epoch 12, gen_loss = 1.4277542435278103, disc_loss = 0.00022610284910673883
Trained batch 635 in epoch 12, gen_loss = 1.4277550842402116, disc_loss = 0.0002260133196042324
Trained batch 636 in epoch 12, gen_loss = 1.4277600083658049, disc_loss = 0.00022594942056685958
Trained batch 637 in epoch 12, gen_loss = 1.4277082520966247, disc_loss = 0.00022590767659728093
Trained batch 638 in epoch 12, gen_loss = 1.4276522631190005, disc_loss = 0.00022591603469528608
Trained batch 639 in epoch 12, gen_loss = 1.4277411732822656, disc_loss = 0.00022601999699531917
Trained batch 640 in epoch 12, gen_loss = 1.4277028836623742, disc_loss = 0.00022625768443885734
Trained batch 641 in epoch 12, gen_loss = 1.427811008004756, disc_loss = 0.00022658509836805807
Trained batch 642 in epoch 12, gen_loss = 1.4278477269049565, disc_loss = 0.00022695898302544878
Trained batch 643 in epoch 12, gen_loss = 1.4278454051254699, disc_loss = 0.0002274174761262188
Trained batch 644 in epoch 12, gen_loss = 1.4277370493541393, disc_loss = 0.00022795698917385141
Trained batch 645 in epoch 12, gen_loss = 1.4277633530067586, disc_loss = 0.0002284844575132025
Trained batch 646 in epoch 12, gen_loss = 1.4277228207271286, disc_loss = 0.00022896688016962982
Trained batch 647 in epoch 12, gen_loss = 1.4278394108937111, disc_loss = 0.00022938720729615415
Trained batch 648 in epoch 12, gen_loss = 1.4277905352494016, disc_loss = 0.0002297348180915016
Trained batch 649 in epoch 12, gen_loss = 1.4277188711899977, disc_loss = 0.00022999872937641788
Trained batch 650 in epoch 12, gen_loss = 1.4276102488308275, disc_loss = 0.00023031667982015833
Trained batch 651 in epoch 12, gen_loss = 1.4276139734347173, disc_loss = 0.0002303235042728916
Trained batch 652 in epoch 12, gen_loss = 1.4276327513626121, disc_loss = 0.00023018424387720476
Trained batch 653 in epoch 12, gen_loss = 1.4277002333865618, disc_loss = 0.00022998992468157265
Trained batch 654 in epoch 12, gen_loss = 1.4276797221817132, disc_loss = 0.00022977911828877583
Trained batch 655 in epoch 12, gen_loss = 1.4277104475512736, disc_loss = 0.0002295400655417857
Trained batch 656 in epoch 12, gen_loss = 1.427741813695957, disc_loss = 0.00022928203514621548
Trained batch 657 in epoch 12, gen_loss = 1.4276823553633182, disc_loss = 0.00022900534140357978
Trained batch 658 in epoch 12, gen_loss = 1.4277251340188821, disc_loss = 0.0002287233207048972
Trained batch 659 in epoch 12, gen_loss = 1.4276115849162594, disc_loss = 0.0002284424064011105
Trained batch 660 in epoch 12, gen_loss = 1.4276137627920478, disc_loss = 0.00022815307803173218
Trained batch 661 in epoch 12, gen_loss = 1.4275231952033374, disc_loss = 0.0002278588348076826
Trained batch 662 in epoch 12, gen_loss = 1.4274656963204546, disc_loss = 0.0002275737380325955
Trained batch 663 in epoch 12, gen_loss = 1.4274794994348503, disc_loss = 0.00022730397025163738
Trained batch 664 in epoch 12, gen_loss = 1.427448846881551, disc_loss = 0.00022707426833768753
Trained batch 665 in epoch 12, gen_loss = 1.4275071980716947, disc_loss = 0.00022691241961169894
Trained batch 666 in epoch 12, gen_loss = 1.4274827274068005, disc_loss = 0.0002267983366599229
Trained batch 667 in epoch 12, gen_loss = 1.4273963815080906, disc_loss = 0.00022668755214462163
Trained batch 668 in epoch 12, gen_loss = 1.4273652727472053, disc_loss = 0.00022654687636640647
Trained batch 669 in epoch 12, gen_loss = 1.4273839005783422, disc_loss = 0.00022642409764842735
Trained batch 670 in epoch 12, gen_loss = 1.4273947935701305, disc_loss = 0.00022627602693359866
Trained batch 671 in epoch 12, gen_loss = 1.4274943100199813, disc_loss = 0.00022612168619876423
Trained batch 672 in epoch 12, gen_loss = 1.42760514663906, disc_loss = 0.000225959195762817
Trained batch 673 in epoch 12, gen_loss = 1.4275868485518661, disc_loss = 0.00022579435428609837
Trained batch 674 in epoch 12, gen_loss = 1.427598810725742, disc_loss = 0.0002256486299868104
Trained batch 675 in epoch 12, gen_loss = 1.4276537071671007, disc_loss = 0.00022551512155097534
Trained batch 676 in epoch 12, gen_loss = 1.4276588764289282, disc_loss = 0.000225381895711608
Trained batch 677 in epoch 12, gen_loss = 1.4276299397502326, disc_loss = 0.0002252507669453088
Trained batch 678 in epoch 12, gen_loss = 1.4276949760664546, disc_loss = 0.00022511327228832417
Trained batch 679 in epoch 12, gen_loss = 1.4277035883244347, disc_loss = 0.00022496766851498465
Trained batch 680 in epoch 12, gen_loss = 1.4276842773398288, disc_loss = 0.00022482193823251292
Trained batch 681 in epoch 12, gen_loss = 1.427594661363059, disc_loss = 0.00022466876443240436
Trained batch 682 in epoch 12, gen_loss = 1.427735234773002, disc_loss = 0.00022450792398977866
Trained batch 683 in epoch 12, gen_loss = 1.4278111297484728, disc_loss = 0.00022434222668039848
Trained batch 684 in epoch 12, gen_loss = 1.4279264923429837, disc_loss = 0.00022416212976792058
Trained batch 685 in epoch 12, gen_loss = 1.4278911162743415, disc_loss = 0.00022399897031600923
Trained batch 686 in epoch 12, gen_loss = 1.4278312697681277, disc_loss = 0.00022381934611262513
Trained batch 687 in epoch 12, gen_loss = 1.4277774130189143, disc_loss = 0.00022365287697518165
Trained batch 688 in epoch 12, gen_loss = 1.4278589229279228, disc_loss = 0.00022350485106697475
Trained batch 689 in epoch 12, gen_loss = 1.4278294095094652, disc_loss = 0.00022338757898715035
Trained batch 690 in epoch 12, gen_loss = 1.4278830400251619, disc_loss = 0.00022327408648304764
Trained batch 691 in epoch 12, gen_loss = 1.4279154103270846, disc_loss = 0.00022314465101608958
Trained batch 692 in epoch 12, gen_loss = 1.4279061941185383, disc_loss = 0.00022299155972003138
Trained batch 693 in epoch 12, gen_loss = 1.4279368603950962, disc_loss = 0.00022282789352636614
Trained batch 694 in epoch 12, gen_loss = 1.4278616279149228, disc_loss = 0.00022264754754242408
Trained batch 695 in epoch 12, gen_loss = 1.4278389460396492, disc_loss = 0.0002224868749024232
Trained batch 696 in epoch 12, gen_loss = 1.4277981719806512, disc_loss = 0.0002223519948365015
Trained batch 697 in epoch 12, gen_loss = 1.4278049197442895, disc_loss = 0.0002222703426071382
Trained batch 698 in epoch 12, gen_loss = 1.4278999075869123, disc_loss = 0.0002221770109397673
Trained batch 699 in epoch 12, gen_loss = 1.427853387764522, disc_loss = 0.0002220742327595612
Trained batch 700 in epoch 12, gen_loss = 1.4277890204703076, disc_loss = 0.00022195486908536252
Trained batch 701 in epoch 12, gen_loss = 1.4278161787239574, disc_loss = 0.00022184696345278453
Trained batch 702 in epoch 12, gen_loss = 1.4277467123983933, disc_loss = 0.00022176337287901863
Trained batch 703 in epoch 12, gen_loss = 1.4277628837999972, disc_loss = 0.00022170357734487632
Trained batch 704 in epoch 12, gen_loss = 1.4277251292627753, disc_loss = 0.00022168235409222972
Trained batch 705 in epoch 12, gen_loss = 1.4277987724998518, disc_loss = 0.00022169916070150983
Trained batch 706 in epoch 12, gen_loss = 1.427869033779754, disc_loss = 0.0002217864579020303
Trained batch 707 in epoch 12, gen_loss = 1.427855161118642, disc_loss = 0.000221958276653956
Trained batch 708 in epoch 12, gen_loss = 1.4278687795227438, disc_loss = 0.00022223092075007934
Trained batch 709 in epoch 12, gen_loss = 1.4277827331717585, disc_loss = 0.00022259429968753337
Trained batch 710 in epoch 12, gen_loss = 1.4279193066678806, disc_loss = 0.0002230284075147021
Trained batch 711 in epoch 12, gen_loss = 1.4277591452504812, disc_loss = 0.00022349683989008289
Trained batch 712 in epoch 12, gen_loss = 1.42776036295951, disc_loss = 0.00022398086365572436
Trained batch 713 in epoch 12, gen_loss = 1.4277513057243925, disc_loss = 0.00022448525252672603
Trained batch 714 in epoch 12, gen_loss = 1.42784581417804, disc_loss = 0.00022503170740918477
Trained batch 715 in epoch 12, gen_loss = 1.4279298039787975, disc_loss = 0.00022564014621140265
Trained batch 716 in epoch 12, gen_loss = 1.4278842323827279, disc_loss = 0.00022634525058179414
Trained batch 717 in epoch 12, gen_loss = 1.427958720075719, disc_loss = 0.0002270066220933733
Trained batch 718 in epoch 12, gen_loss = 1.4279811876373927, disc_loss = 0.00022755682138051424
Trained batch 719 in epoch 12, gen_loss = 1.4280059524708324, disc_loss = 0.00022804932833019444
Trained batch 720 in epoch 12, gen_loss = 1.4280196408458292, disc_loss = 0.00022853307915150236
Trained batch 721 in epoch 12, gen_loss = 1.4280593882307122, disc_loss = 0.00022895515004339482
Trained batch 722 in epoch 12, gen_loss = 1.427941246646074, disc_loss = 0.00022928430192514044
Trained batch 723 in epoch 12, gen_loss = 1.4279753024077546, disc_loss = 0.0002295682723151963
Trained batch 724 in epoch 12, gen_loss = 1.4279257667475733, disc_loss = 0.00022986901565234114
Trained batch 725 in epoch 12, gen_loss = 1.427848768464133, disc_loss = 0.00023022470971029515
Trained batch 726 in epoch 12, gen_loss = 1.4278715666911297, disc_loss = 0.000230596604509168
Trained batch 727 in epoch 12, gen_loss = 1.4277612000376314, disc_loss = 0.00023100495119941336
Trained batch 728 in epoch 12, gen_loss = 1.4277789927967945, disc_loss = 0.00023149647227069587
Trained batch 729 in epoch 12, gen_loss = 1.4277681407863148, disc_loss = 0.00023196715463773341
Trained batch 730 in epoch 12, gen_loss = 1.4277947766020915, disc_loss = 0.00023241527022723976
Trained batch 731 in epoch 12, gen_loss = 1.4278573841670823, disc_loss = 0.00023280330349267697
Trained batch 732 in epoch 12, gen_loss = 1.4278752099605732, disc_loss = 0.00023311735873430932
Trained batch 733 in epoch 12, gen_loss = 1.4279039757128307, disc_loss = 0.0002333654576100232
Trained batch 734 in epoch 12, gen_loss = 1.42800891577792, disc_loss = 0.00023353951419390845
Trained batch 735 in epoch 12, gen_loss = 1.4281432324129602, disc_loss = 0.00023357986599816996
Trained batch 736 in epoch 12, gen_loss = 1.4282109240825658, disc_loss = 0.0002334973596564726
Trained batch 737 in epoch 12, gen_loss = 1.4282197403067818, disc_loss = 0.0002333346032405409
Trained batch 738 in epoch 12, gen_loss = 1.4282216893481305, disc_loss = 0.00023312570636542054
Trained batch 739 in epoch 12, gen_loss = 1.4283509056310395, disc_loss = 0.0002328978466647567
Trained batch 740 in epoch 12, gen_loss = 1.4284584565683898, disc_loss = 0.00023264763594987425
Trained batch 741 in epoch 12, gen_loss = 1.4284413161303477, disc_loss = 0.00023237852795899756
Trained batch 742 in epoch 12, gen_loss = 1.428392744160597, disc_loss = 0.0002321010067194901
Trained batch 743 in epoch 12, gen_loss = 1.4283890376488368, disc_loss = 0.00023180963558178352
Trained batch 744 in epoch 12, gen_loss = 1.4283541423362374, disc_loss = 0.0002315172689513502
Trained batch 745 in epoch 12, gen_loss = 1.428412915394709, disc_loss = 0.00023123847119796998
Testing Epoch 12
Training Epoch 13
Trained batch 0 in epoch 13, gen_loss = 1.417487621307373, disc_loss = 3.1245857826434076e-05
Trained batch 1 in epoch 13, gen_loss = 1.3751939535140991, disc_loss = 3.338578972034156e-05
Trained batch 2 in epoch 13, gen_loss = 1.3803701400756836, disc_loss = 3.639916879668211e-05
Trained batch 3 in epoch 13, gen_loss = 1.3826033174991608, disc_loss = 3.895648023899412e-05
Trained batch 4 in epoch 13, gen_loss = 1.3788504362106324, disc_loss = 4.118164433748461e-05
Trained batch 5 in epoch 13, gen_loss = 1.3925415674845378, disc_loss = 4.2669122194638476e-05
Trained batch 6 in epoch 13, gen_loss = 1.3921469620295934, disc_loss = 4.32422270283236e-05
Trained batch 7 in epoch 13, gen_loss = 1.3942407816648483, disc_loss = 4.344980925452546e-05
Trained batch 8 in epoch 13, gen_loss = 1.3994017044703166, disc_loss = 4.3198250851775e-05
Trained batch 9 in epoch 13, gen_loss = 1.396785593032837, disc_loss = 4.2587602001731285e-05
Trained batch 10 in epoch 13, gen_loss = 1.400811943140897, disc_loss = 4.180698471662419e-05
Trained batch 11 in epoch 13, gen_loss = 1.402469555536906, disc_loss = 4.2113859611466374e-05
Trained batch 12 in epoch 13, gen_loss = 1.404486216031588, disc_loss = 4.31875643978576e-05
Trained batch 13 in epoch 13, gen_loss = 1.4092570883887154, disc_loss = 4.5079688788973726e-05
Trained batch 14 in epoch 13, gen_loss = 1.409041945139567, disc_loss = 4.720249974828524e-05
Trained batch 15 in epoch 13, gen_loss = 1.4069378599524498, disc_loss = 5.010569407204457e-05
Trained batch 16 in epoch 13, gen_loss = 1.4021306388518389, disc_loss = 5.3334912937476906e-05
Trained batch 17 in epoch 13, gen_loss = 1.4031608435842726, disc_loss = 5.53955115820928e-05
Trained batch 18 in epoch 13, gen_loss = 1.4021151003084684, disc_loss = 5.628513482454429e-05
Trained batch 19 in epoch 13, gen_loss = 1.3968385636806488, disc_loss = 5.7159399329975716e-05
Trained batch 20 in epoch 13, gen_loss = 1.3983583280018397, disc_loss = 5.8472722836692505e-05
Trained batch 21 in epoch 13, gen_loss = 1.3997595472769304, disc_loss = 5.985596577705689e-05
Trained batch 22 in epoch 13, gen_loss = 1.402519739192465, disc_loss = 6.079074939960897e-05
Trained batch 23 in epoch 13, gen_loss = 1.4006309062242508, disc_loss = 6.16735004162668e-05
Trained batch 24 in epoch 13, gen_loss = 1.4029821252822876, disc_loss = 6.26858377654571e-05
Trained batch 25 in epoch 13, gen_loss = 1.4044119348892798, disc_loss = 6.336696452098504e-05
Trained batch 26 in epoch 13, gen_loss = 1.4032804568608601, disc_loss = 6.366432124330593e-05
Trained batch 27 in epoch 13, gen_loss = 1.3999418744019099, disc_loss = 6.38843933172341e-05
Trained batch 28 in epoch 13, gen_loss = 1.4026895967023125, disc_loss = 6.399580048184425e-05
Trained batch 29 in epoch 13, gen_loss = 1.402937360604604, disc_loss = 6.401999889931176e-05
Trained batch 30 in epoch 13, gen_loss = 1.4018120919504473, disc_loss = 6.396917054981685e-05
Trained batch 31 in epoch 13, gen_loss = 1.4018063247203827, disc_loss = 6.35423776884636e-05
Trained batch 32 in epoch 13, gen_loss = 1.403190685041023, disc_loss = 6.29240685983942e-05
Trained batch 33 in epoch 13, gen_loss = 1.4028972212006063, disc_loss = 6.231509231678073e-05
Trained batch 34 in epoch 13, gen_loss = 1.4039156130381993, disc_loss = 6.212327061803081e-05
Trained batch 35 in epoch 13, gen_loss = 1.4012569155957963, disc_loss = 6.341749263406705e-05
Trained batch 36 in epoch 13, gen_loss = 1.4011329605772689, disc_loss = 6.602202198779639e-05
Trained batch 37 in epoch 13, gen_loss = 1.4009090567889966, disc_loss = 6.968862218950802e-05
Trained batch 38 in epoch 13, gen_loss = 1.401506775464767, disc_loss = 7.372394266451757e-05
Trained batch 39 in epoch 13, gen_loss = 1.4042100012302399, disc_loss = 7.847563529139734e-05
Trained batch 40 in epoch 13, gen_loss = 1.4069379509949103, disc_loss = 8.396404607593445e-05
Trained batch 41 in epoch 13, gen_loss = 1.407050024895441, disc_loss = 9.035770744958427e-05
Trained batch 42 in epoch 13, gen_loss = 1.4074742267298144, disc_loss = 9.73943630903472e-05
Trained batch 43 in epoch 13, gen_loss = 1.4087234274907545, disc_loss = 0.00010486219509237509
Trained batch 44 in epoch 13, gen_loss = 1.410082909795973, disc_loss = 0.00011287048942500001
Trained batch 45 in epoch 13, gen_loss = 1.4112928561542346, disc_loss = 0.00012257734417052353
Trained batch 46 in epoch 13, gen_loss = 1.4115342561234818, disc_loss = 0.00013512452967412908
Trained batch 47 in epoch 13, gen_loss = 1.4144084652264912, disc_loss = 0.00014995090646152676
Trained batch 48 in epoch 13, gen_loss = 1.4130933187445816, disc_loss = 0.00016605351065292632
Trained batch 49 in epoch 13, gen_loss = 1.4139662289619446, disc_loss = 0.00018206608125183267
Trained batch 50 in epoch 13, gen_loss = 1.4155747259364408, disc_loss = 0.00019794013275589118
Trained batch 51 in epoch 13, gen_loss = 1.41511774292359, disc_loss = 0.0002129035206403037
Trained batch 52 in epoch 13, gen_loss = 1.4143440948342376, disc_loss = 0.00022637873182659705
Trained batch 53 in epoch 13, gen_loss = 1.4143944448894925, disc_loss = 0.00023878226265541916
Trained batch 54 in epoch 13, gen_loss = 1.4144200671802867, disc_loss = 0.0002496647637268655
Trained batch 55 in epoch 13, gen_loss = 1.414767746414457, disc_loss = 0.0002582804060174177
Trained batch 56 in epoch 13, gen_loss = 1.4147623380025227, disc_loss = 0.0002646470460157408
Trained batch 57 in epoch 13, gen_loss = 1.4157946048111751, disc_loss = 0.0002690559113975253
Trained batch 58 in epoch 13, gen_loss = 1.4163823511640905, disc_loss = 0.00027249261663616953
Trained batch 59 in epoch 13, gen_loss = 1.417355881134669, disc_loss = 0.0002752340926842104
Trained batch 60 in epoch 13, gen_loss = 1.416456048605872, disc_loss = 0.00027773808347983055
Trained batch 61 in epoch 13, gen_loss = 1.4166810762497686, disc_loss = 0.00027928047295004476
Trained batch 62 in epoch 13, gen_loss = 1.417610804239909, disc_loss = 0.00028040285802230107
Trained batch 63 in epoch 13, gen_loss = 1.4174228366464376, disc_loss = 0.000282031251515491
Trained batch 64 in epoch 13, gen_loss = 1.4182208483035748, disc_loss = 0.0002845977208590529
Trained batch 65 in epoch 13, gen_loss = 1.4181382005864924, disc_loss = 0.0002885070500104286
Trained batch 66 in epoch 13, gen_loss = 1.4179657893394357, disc_loss = 0.0002935139962220947
Trained batch 67 in epoch 13, gen_loss = 1.4176079210113077, disc_loss = 0.00029789180462103104
Trained batch 68 in epoch 13, gen_loss = 1.4167740966962732, disc_loss = 0.0003020276814387889
Trained batch 69 in epoch 13, gen_loss = 1.4170827337673733, disc_loss = 0.0003052235114799779
Trained batch 70 in epoch 13, gen_loss = 1.4179379587442102, disc_loss = 0.0003075135804029857
Trained batch 71 in epoch 13, gen_loss = 1.417467873957422, disc_loss = 0.0003088428658581203
Trained batch 72 in epoch 13, gen_loss = 1.4170025472771632, disc_loss = 0.000308592153076411
Trained batch 73 in epoch 13, gen_loss = 1.4174540171752106, disc_loss = 0.0003073849526805822
Trained batch 74 in epoch 13, gen_loss = 1.418145759900411, disc_loss = 0.000305713086418109
Trained batch 75 in epoch 13, gen_loss = 1.4175998270511627, disc_loss = 0.0003037273544051507
Trained batch 76 in epoch 13, gen_loss = 1.4180639409399651, disc_loss = 0.0003014152147939471
Trained batch 77 in epoch 13, gen_loss = 1.4179804202837822, disc_loss = 0.00029880405264311074
Trained batch 78 in epoch 13, gen_loss = 1.417759575421297, disc_loss = 0.0002959341156982398
Trained batch 79 in epoch 13, gen_loss = 1.4182212322950363, disc_loss = 0.0002929305133420712
Trained batch 80 in epoch 13, gen_loss = 1.4182704598815352, disc_loss = 0.0002899962812619008
Trained batch 81 in epoch 13, gen_loss = 1.417897592230541, disc_loss = 0.0002871725736019094
Trained batch 82 in epoch 13, gen_loss = 1.4182543395513512, disc_loss = 0.0002845425346073083
Trained batch 83 in epoch 13, gen_loss = 1.417375269390288, disc_loss = 0.0002819112613516544
Trained batch 84 in epoch 13, gen_loss = 1.417443000569063, disc_loss = 0.0002795035517278045
Trained batch 85 in epoch 13, gen_loss = 1.4175371929656628, disc_loss = 0.0002772834077616206
Trained batch 86 in epoch 13, gen_loss = 1.4175944629756885, disc_loss = 0.00027511206134550283
Trained batch 87 in epoch 13, gen_loss = 1.4170956706458873, disc_loss = 0.00027294892313214155
Trained batch 88 in epoch 13, gen_loss = 1.4171226828285817, disc_loss = 0.000271200006404235
Trained batch 89 in epoch 13, gen_loss = 1.4170040541225009, disc_loss = 0.00026956543737873695
Trained batch 90 in epoch 13, gen_loss = 1.417322454871712, disc_loss = 0.0002679164832183493
Trained batch 91 in epoch 13, gen_loss = 1.417717994555183, disc_loss = 0.0002663859614071755
Trained batch 92 in epoch 13, gen_loss = 1.4166273827193885, disc_loss = 0.0002651730862052445
Trained batch 93 in epoch 13, gen_loss = 1.4168099710281858, disc_loss = 0.0002643171317570105
Trained batch 94 in epoch 13, gen_loss = 1.4161750454651683, disc_loss = 0.0002638046566540939
Trained batch 95 in epoch 13, gen_loss = 1.4158308344582717, disc_loss = 0.00026489286919210525
Trained batch 96 in epoch 13, gen_loss = 1.4160987876125217, disc_loss = 0.00026553832653870315
Trained batch 97 in epoch 13, gen_loss = 1.4163286126389796, disc_loss = 0.00026630358431192487
Trained batch 98 in epoch 13, gen_loss = 1.4160858910493177, disc_loss = 0.0002672858322741854
Trained batch 99 in epoch 13, gen_loss = 1.4156408870220185, disc_loss = 0.0002684557194515946
Trained batch 100 in epoch 13, gen_loss = 1.415377939101493, disc_loss = 0.0002695360549971678
Trained batch 101 in epoch 13, gen_loss = 1.4155255824911828, disc_loss = 0.00027035484922902574
Trained batch 102 in epoch 13, gen_loss = 1.4162299112208838, disc_loss = 0.00027088466104209307
Trained batch 103 in epoch 13, gen_loss = 1.416154267696234, disc_loss = 0.00027117769965256087
Trained batch 104 in epoch 13, gen_loss = 1.4167715787887574, disc_loss = 0.0002713749152982408
Trained batch 105 in epoch 13, gen_loss = 1.4167501127944802, disc_loss = 0.0002716399130632745
Trained batch 106 in epoch 13, gen_loss = 1.4171486558201156, disc_loss = 0.0002716910105922682
Trained batch 107 in epoch 13, gen_loss = 1.4181343747509851, disc_loss = 0.00027140598545143064
Trained batch 108 in epoch 13, gen_loss = 1.4180458805976657, disc_loss = 0.0002708238711537379
Trained batch 109 in epoch 13, gen_loss = 1.4183368411931125, disc_loss = 0.0002699160384509014
Trained batch 110 in epoch 13, gen_loss = 1.4184574457976196, disc_loss = 0.0002688193719124585
Trained batch 111 in epoch 13, gen_loss = 1.418504542538098, disc_loss = 0.00026769497614103396
Trained batch 112 in epoch 13, gen_loss = 1.4190167684470658, disc_loss = 0.0002666461744499743
Trained batch 113 in epoch 13, gen_loss = 1.4191629928455018, disc_loss = 0.0002657089234274105
Trained batch 114 in epoch 13, gen_loss = 1.4197463377662327, disc_loss = 0.00026506109238455435
Trained batch 115 in epoch 13, gen_loss = 1.419632038165783, disc_loss = 0.00026477366451405847
Trained batch 116 in epoch 13, gen_loss = 1.4201938005594106, disc_loss = 0.00026473076053289097
Trained batch 117 in epoch 13, gen_loss = 1.4202758578930872, disc_loss = 0.0002648924215402261
Trained batch 118 in epoch 13, gen_loss = 1.4203608356604056, disc_loss = 0.0002648632320369488
Trained batch 119 in epoch 13, gen_loss = 1.4206713994344076, disc_loss = 0.0002645589546773408
Trained batch 120 in epoch 13, gen_loss = 1.4210132774242685, disc_loss = 0.0002640926444550403
Trained batch 121 in epoch 13, gen_loss = 1.4212468461912187, disc_loss = 0.00026345295247933863
Trained batch 122 in epoch 13, gen_loss = 1.4211837295594254, disc_loss = 0.0002626837746747031
Trained batch 123 in epoch 13, gen_loss = 1.4212810647103093, disc_loss = 0.00026176143725728426
Trained batch 124 in epoch 13, gen_loss = 1.4214893579483032, disc_loss = 0.00026071424686233515
Trained batch 125 in epoch 13, gen_loss = 1.4220597034408933, disc_loss = 0.00025953208673204893
Trained batch 126 in epoch 13, gen_loss = 1.4220240707472553, disc_loss = 0.00025825552051904333
Trained batch 127 in epoch 13, gen_loss = 1.4220587955787778, disc_loss = 0.000256916406755181
Trained batch 128 in epoch 13, gen_loss = 1.422056517859762, disc_loss = 0.0002554691917082031
Trained batch 129 in epoch 13, gen_loss = 1.422894052358774, disc_loss = 0.0002539411606099188
Trained batch 130 in epoch 13, gen_loss = 1.4231026263637396, disc_loss = 0.00025244022789877796
Trained batch 131 in epoch 13, gen_loss = 1.4229289202979116, disc_loss = 0.00025091137349315403
Trained batch 132 in epoch 13, gen_loss = 1.4226526783821278, disc_loss = 0.00024936132402053363
Trained batch 133 in epoch 13, gen_loss = 1.4228097200393677, disc_loss = 0.0002478076570859325
Trained batch 134 in epoch 13, gen_loss = 1.422419176278291, disc_loss = 0.0002462744588868831
Trained batch 135 in epoch 13, gen_loss = 1.4223429867449928, disc_loss = 0.000244731360774441
Trained batch 136 in epoch 13, gen_loss = 1.4229834332083264, disc_loss = 0.00024321104095438088
Trained batch 137 in epoch 13, gen_loss = 1.4229349165722944, disc_loss = 0.00024168940016998153
Trained batch 138 in epoch 13, gen_loss = 1.4233567920520152, disc_loss = 0.00024015975232163223
Trained batch 139 in epoch 13, gen_loss = 1.4230433029787881, disc_loss = 0.00023858896851639396
Trained batch 140 in epoch 13, gen_loss = 1.4230064965308982, disc_loss = 0.00023707343961119632
Trained batch 141 in epoch 13, gen_loss = 1.4231490215785068, disc_loss = 0.00023560238797715652
Trained batch 142 in epoch 13, gen_loss = 1.4230072831774092, disc_loss = 0.00023414777405906007
Trained batch 143 in epoch 13, gen_loss = 1.4235175823171933, disc_loss = 0.0002327541431491732
Trained batch 144 in epoch 13, gen_loss = 1.4230878270905594, disc_loss = 0.00023141053674846952
Trained batch 145 in epoch 13, gen_loss = 1.4236330757402393, disc_loss = 0.0002301723803636739
Trained batch 146 in epoch 13, gen_loss = 1.4239349413891227, disc_loss = 0.00022911430847534885
Trained batch 147 in epoch 13, gen_loss = 1.4237065403848082, disc_loss = 0.00022821820370941045
Trained batch 148 in epoch 13, gen_loss = 1.4237669170302834, disc_loss = 0.00022748253216823227
Trained batch 149 in epoch 13, gen_loss = 1.4242399867375692, disc_loss = 0.0002268298831768334
Trained batch 150 in epoch 13, gen_loss = 1.4239661496206624, disc_loss = 0.00022624298835339777
Trained batch 151 in epoch 13, gen_loss = 1.4244094091026407, disc_loss = 0.00022576221138143935
Trained batch 152 in epoch 13, gen_loss = 1.4249263503193077, disc_loss = 0.00022542484500673692
Trained batch 153 in epoch 13, gen_loss = 1.424619412267363, disc_loss = 0.00022512089325774266
Trained batch 154 in epoch 13, gen_loss = 1.4242191260860813, disc_loss = 0.00022473642377242927
Trained batch 155 in epoch 13, gen_loss = 1.4239323475422003, disc_loss = 0.0002242538547038865
Trained batch 156 in epoch 13, gen_loss = 1.4235821210654678, disc_loss = 0.0002235577821399376
Trained batch 157 in epoch 13, gen_loss = 1.4235980661609504, disc_loss = 0.0002227463515230773
Trained batch 158 in epoch 13, gen_loss = 1.4230336858041632, disc_loss = 0.00022181302264007686
Trained batch 159 in epoch 13, gen_loss = 1.4235062912106513, disc_loss = 0.0002209423641943431
Trained batch 160 in epoch 13, gen_loss = 1.4240174945096793, disc_loss = 0.00022013747922010338
Trained batch 161 in epoch 13, gen_loss = 1.4236256656823334, disc_loss = 0.00021948027597879703
Trained batch 162 in epoch 13, gen_loss = 1.4233397874364093, disc_loss = 0.00021902508798885256
Trained batch 163 in epoch 13, gen_loss = 1.423024907344725, disc_loss = 0.00021875701034931386
Trained batch 164 in epoch 13, gen_loss = 1.4228238380316531, disc_loss = 0.00021856590698889427
Trained batch 165 in epoch 13, gen_loss = 1.4227556787341473, disc_loss = 0.00021835208099219017
Trained batch 166 in epoch 13, gen_loss = 1.4223833762243123, disc_loss = 0.00021810810447462785
Trained batch 167 in epoch 13, gen_loss = 1.4225082759346281, disc_loss = 0.00021774207323774352
Trained batch 168 in epoch 13, gen_loss = 1.422381259280549, disc_loss = 0.0002172334989262111
Trained batch 169 in epoch 13, gen_loss = 1.4223717402009404, disc_loss = 0.00021658897590789232
Trained batch 170 in epoch 13, gen_loss = 1.422083366684049, disc_loss = 0.0002158365481889164
Trained batch 171 in epoch 13, gen_loss = 1.4221536295358526, disc_loss = 0.00021506204951905137
Trained batch 172 in epoch 13, gen_loss = 1.4217579461246557, disc_loss = 0.00021430341691899818
Trained batch 173 in epoch 13, gen_loss = 1.4215452561433288, disc_loss = 0.00021367746514191948
Trained batch 174 in epoch 13, gen_loss = 1.4214218296323504, disc_loss = 0.00021308551966545304
Trained batch 175 in epoch 13, gen_loss = 1.4216546409509399, disc_loss = 0.0002125519374451621
Trained batch 176 in epoch 13, gen_loss = 1.4220502248591622, disc_loss = 0.0002120837512015665
Trained batch 177 in epoch 13, gen_loss = 1.421971984793631, disc_loss = 0.0002117884901922531
Trained batch 178 in epoch 13, gen_loss = 1.4222736305364683, disc_loss = 0.0002117180478480754
Trained batch 179 in epoch 13, gen_loss = 1.422305342886183, disc_loss = 0.00021185022706049494
Trained batch 180 in epoch 13, gen_loss = 1.4224456364278635, disc_loss = 0.00021205552011401552
Trained batch 181 in epoch 13, gen_loss = 1.4223129873747353, disc_loss = 0.00021220422698476526
Trained batch 182 in epoch 13, gen_loss = 1.4219259805366642, disc_loss = 0.00021247187476030097
Trained batch 183 in epoch 13, gen_loss = 1.4221708249786627, disc_loss = 0.0002127638757013736
Trained batch 184 in epoch 13, gen_loss = 1.4223785497046806, disc_loss = 0.0002132347723582407
Trained batch 185 in epoch 13, gen_loss = 1.422361321346734, disc_loss = 0.00021419343798326188
Trained batch 186 in epoch 13, gen_loss = 1.4224049178036777, disc_loss = 0.00021560362370231533
Trained batch 187 in epoch 13, gen_loss = 1.4222687571606738, disc_loss = 0.0002172348104068078
Trained batch 188 in epoch 13, gen_loss = 1.4223831456805032, disc_loss = 0.00021883586736361462
Trained batch 189 in epoch 13, gen_loss = 1.42219608206498, disc_loss = 0.00022042242329151025
Trained batch 190 in epoch 13, gen_loss = 1.4221459957941665, disc_loss = 0.00022200275750718622
Trained batch 191 in epoch 13, gen_loss = 1.4222881365567446, disc_loss = 0.0002235087496652947
Trained batch 192 in epoch 13, gen_loss = 1.422634145138795, disc_loss = 0.00022493246981965793
Trained batch 193 in epoch 13, gen_loss = 1.4228754111171997, disc_loss = 0.00022645080903156172
Trained batch 194 in epoch 13, gen_loss = 1.4226434371410273, disc_loss = 0.00022804694450221573
Trained batch 195 in epoch 13, gen_loss = 1.42249254730283, disc_loss = 0.00022944678865463415
Trained batch 196 in epoch 13, gen_loss = 1.422263262840697, disc_loss = 0.00023054777036496643
Trained batch 197 in epoch 13, gen_loss = 1.4223868268908877, disc_loss = 0.0002313156028964905
Trained batch 198 in epoch 13, gen_loss = 1.4224663643381703, disc_loss = 0.00023190988533095872
Trained batch 199 in epoch 13, gen_loss = 1.4228707510232925, disc_loss = 0.00023247450968483463
Trained batch 200 in epoch 13, gen_loss = 1.422855814297994, disc_loss = 0.000233012152516019
Trained batch 201 in epoch 13, gen_loss = 1.4227808519165115, disc_loss = 0.0002335544824277484
Trained batch 202 in epoch 13, gen_loss = 1.4228912392273325, disc_loss = 0.00023424659891219194
Trained batch 203 in epoch 13, gen_loss = 1.4229292250147052, disc_loss = 0.00023504721649064152
Trained batch 204 in epoch 13, gen_loss = 1.4224858400298328, disc_loss = 0.00023587196525867756
Trained batch 205 in epoch 13, gen_loss = 1.4227877479155087, disc_loss = 0.00023668537366213006
Trained batch 206 in epoch 13, gen_loss = 1.423012015324284, disc_loss = 0.00023770749660046852
Trained batch 207 in epoch 13, gen_loss = 1.423371967787926, disc_loss = 0.00023923790733813524
Trained batch 208 in epoch 13, gen_loss = 1.4233498316632502, disc_loss = 0.00024090425287368907
Trained batch 209 in epoch 13, gen_loss = 1.423440258275895, disc_loss = 0.00024230128148615006
Trained batch 210 in epoch 13, gen_loss = 1.423903359621057, disc_loss = 0.00024343541877397217
Trained batch 211 in epoch 13, gen_loss = 1.423801061117424, disc_loss = 0.0002443426370209979
Trained batch 212 in epoch 13, gen_loss = 1.4238789568484669, disc_loss = 0.0002451028281051071
Trained batch 213 in epoch 13, gen_loss = 1.4242806696446142, disc_loss = 0.0002455375665661696
Trained batch 214 in epoch 13, gen_loss = 1.424444601147674, disc_loss = 0.00024558543863836244
Trained batch 215 in epoch 13, gen_loss = 1.4244904827188563, disc_loss = 0.00024534688661030185
Trained batch 216 in epoch 13, gen_loss = 1.4250452320696572, disc_loss = 0.0002450448103315596
Trained batch 217 in epoch 13, gen_loss = 1.4247408678772253, disc_loss = 0.0002446091904624263
Trained batch 218 in epoch 13, gen_loss = 1.4246187525797107, disc_loss = 0.00024403930812081127
Trained batch 219 in epoch 13, gen_loss = 1.4250015963207592, disc_loss = 0.0002434682619588619
Trained batch 220 in epoch 13, gen_loss = 1.4248797122169943, disc_loss = 0.00024295479087664733
Trained batch 221 in epoch 13, gen_loss = 1.4251711771294877, disc_loss = 0.00024246740278678836
Trained batch 222 in epoch 13, gen_loss = 1.4249327615772127, disc_loss = 0.0002418828385150177
Trained batch 223 in epoch 13, gen_loss = 1.4249355255493097, disc_loss = 0.00024121510260296679
Trained batch 224 in epoch 13, gen_loss = 1.424881839222378, disc_loss = 0.0002405226741878626
Trained batch 225 in epoch 13, gen_loss = 1.4255397936939138, disc_loss = 0.00023985160326052548
Trained batch 226 in epoch 13, gen_loss = 1.4254202469855153, disc_loss = 0.0002392179935969031
Trained batch 227 in epoch 13, gen_loss = 1.4256749221107416, disc_loss = 0.00023859158455595382
Trained batch 228 in epoch 13, gen_loss = 1.426023907015938, disc_loss = 0.00023793162636059299
Trained batch 229 in epoch 13, gen_loss = 1.4261070650556813, disc_loss = 0.00023729119544125
Trained batch 230 in epoch 13, gen_loss = 1.4256729744213483, disc_loss = 0.00023670806474525085
Trained batch 231 in epoch 13, gen_loss = 1.425599775437651, disc_loss = 0.00023617212455378492
Trained batch 232 in epoch 13, gen_loss = 1.4255487274202665, disc_loss = 0.00023569661225571973
Trained batch 233 in epoch 13, gen_loss = 1.425411130118574, disc_loss = 0.00023547318004346333
Trained batch 234 in epoch 13, gen_loss = 1.4257093896257116, disc_loss = 0.00023522626285371866
Trained batch 235 in epoch 13, gen_loss = 1.4257013403763206, disc_loss = 0.00023503669266790246
Trained batch 236 in epoch 13, gen_loss = 1.4254549434919397, disc_loss = 0.0002349995177107537
Trained batch 237 in epoch 13, gen_loss = 1.4254271167666972, disc_loss = 0.0002351591895244421
Trained batch 238 in epoch 13, gen_loss = 1.4251628585440343, disc_loss = 0.00023542857796117413
Trained batch 239 in epoch 13, gen_loss = 1.4255825266242028, disc_loss = 0.0002357249545942371
Trained batch 240 in epoch 13, gen_loss = 1.4259634764857312, disc_loss = 0.00023616046989645762
Trained batch 241 in epoch 13, gen_loss = 1.4261366779153997, disc_loss = 0.00023692473059631731
Trained batch 242 in epoch 13, gen_loss = 1.4262040372738622, disc_loss = 0.00023804789463176924
Trained batch 243 in epoch 13, gen_loss = 1.4263437610180651, disc_loss = 0.00023944496683352704
Trained batch 244 in epoch 13, gen_loss = 1.4263011294968275, disc_loss = 0.00024119777170161964
Trained batch 245 in epoch 13, gen_loss = 1.426295816898346, disc_loss = 0.0002435201257741745
Trained batch 246 in epoch 13, gen_loss = 1.4260789928166007, disc_loss = 0.00024611995471094696
Trained batch 247 in epoch 13, gen_loss = 1.426094205629441, disc_loss = 0.00024860500531259834
Trained batch 248 in epoch 13, gen_loss = 1.4261934249755368, disc_loss = 0.0002510524657601678
Trained batch 249 in epoch 13, gen_loss = 1.4262788705825806, disc_loss = 0.0002535654309904203
Trained batch 250 in epoch 13, gen_loss = 1.4263781228388448, disc_loss = 0.0002559805756195474
Trained batch 251 in epoch 13, gen_loss = 1.4265201129610576, disc_loss = 0.0002581807640371918
Trained batch 252 in epoch 13, gen_loss = 1.42635463725908, disc_loss = 0.0002601101826333437
Trained batch 253 in epoch 13, gen_loss = 1.4265492596025542, disc_loss = 0.0002617303642497479
Trained batch 254 in epoch 13, gen_loss = 1.4267572384254605, disc_loss = 0.00026286802877781583
Trained batch 255 in epoch 13, gen_loss = 1.4269016571342945, disc_loss = 0.000263513745835553
Trained batch 256 in epoch 13, gen_loss = 1.4269924919892842, disc_loss = 0.000263861555027221
Trained batch 257 in epoch 13, gen_loss = 1.4269138801005459, disc_loss = 0.00026400367027264117
Trained batch 258 in epoch 13, gen_loss = 1.4267495493170839, disc_loss = 0.0002640044970867587
Trained batch 259 in epoch 13, gen_loss = 1.4266532682455504, disc_loss = 0.0002639270123416701
Trained batch 260 in epoch 13, gen_loss = 1.4263660345954456, disc_loss = 0.00026381704813561676
Trained batch 261 in epoch 13, gen_loss = 1.426343158001208, disc_loss = 0.0002637084779900122
Trained batch 262 in epoch 13, gen_loss = 1.4261902484603708, disc_loss = 0.0002636031871028563
Trained batch 263 in epoch 13, gen_loss = 1.4264820434830405, disc_loss = 0.00026342086857766844
Trained batch 264 in epoch 13, gen_loss = 1.4262748916194123, disc_loss = 0.00026312362466376487
Trained batch 265 in epoch 13, gen_loss = 1.4264483823812097, disc_loss = 0.0002627464420953415
Trained batch 266 in epoch 13, gen_loss = 1.4264154755667355, disc_loss = 0.00026229742934276814
Trained batch 267 in epoch 13, gen_loss = 1.4261056518376762, disc_loss = 0.00026177021502360784
Trained batch 268 in epoch 13, gen_loss = 1.4260169139138827, disc_loss = 0.00026113180818315766
Trained batch 269 in epoch 13, gen_loss = 1.4259785665406122, disc_loss = 0.0002604281290755521
Trained batch 270 in epoch 13, gen_loss = 1.4261014149197793, disc_loss = 0.0002596512486214399
Trained batch 271 in epoch 13, gen_loss = 1.4261940928066479, disc_loss = 0.00025885313361333613
Trained batch 272 in epoch 13, gen_loss = 1.4262733808803907, disc_loss = 0.0002580384265483466
Trained batch 273 in epoch 13, gen_loss = 1.4264393983966244, disc_loss = 0.00025723796694949064
Trained batch 274 in epoch 13, gen_loss = 1.426168068972501, disc_loss = 0.00025647405161924493
Trained batch 275 in epoch 13, gen_loss = 1.4262442346932231, disc_loss = 0.00025564065103738
Trained batch 276 in epoch 13, gen_loss = 1.4263835732256893, disc_loss = 0.0002547919240817789
Trained batch 277 in epoch 13, gen_loss = 1.4267092501516823, disc_loss = 0.00025394349324951623
Trained batch 278 in epoch 13, gen_loss = 1.426530909794633, disc_loss = 0.0002531204540330473
Trained batch 279 in epoch 13, gen_loss = 1.4265708548682077, disc_loss = 0.00025231626148394885
Trained batch 280 in epoch 13, gen_loss = 1.426322222604446, disc_loss = 0.0002515200560594419
Trained batch 281 in epoch 13, gen_loss = 1.4262156845830012, disc_loss = 0.00025071647643978156
Trained batch 282 in epoch 13, gen_loss = 1.4261927520428446, disc_loss = 0.00024988704325464456
Trained batch 283 in epoch 13, gen_loss = 1.4262699761860806, disc_loss = 0.00024907711861833635
Trained batch 284 in epoch 13, gen_loss = 1.426271528946726, disc_loss = 0.00024829281549165516
Trained batch 285 in epoch 13, gen_loss = 1.4261490089910014, disc_loss = 0.0002475211263149472
Trained batch 286 in epoch 13, gen_loss = 1.4262804577990276, disc_loss = 0.0002467426998881081
Trained batch 287 in epoch 13, gen_loss = 1.4262149909304247, disc_loss = 0.00024597629710064613
Trained batch 288 in epoch 13, gen_loss = 1.4261585214146282, disc_loss = 0.00024525331963745113
Trained batch 289 in epoch 13, gen_loss = 1.4260804094117263, disc_loss = 0.000244572692325415
Trained batch 290 in epoch 13, gen_loss = 1.4258832726691597, disc_loss = 0.0002439374656364869
Trained batch 291 in epoch 13, gen_loss = 1.4260193844364113, disc_loss = 0.00024330093924929738
Trained batch 292 in epoch 13, gen_loss = 1.4258805663919285, disc_loss = 0.0002426509975369085
Trained batch 293 in epoch 13, gen_loss = 1.4257607078876624, disc_loss = 0.0002419923895555802
Trained batch 294 in epoch 13, gen_loss = 1.42584544036348, disc_loss = 0.00024134169134875698
Trained batch 295 in epoch 13, gen_loss = 1.4258722505859427, disc_loss = 0.0002407216186445628
Trained batch 296 in epoch 13, gen_loss = 1.4256305273133094, disc_loss = 0.0002401223077822119
Trained batch 297 in epoch 13, gen_loss = 1.4258825058905071, disc_loss = 0.0002395160264869208
Trained batch 298 in epoch 13, gen_loss = 1.425819273776434, disc_loss = 0.00023890504808241834
Trained batch 299 in epoch 13, gen_loss = 1.4255830057462056, disc_loss = 0.00023832438597310102
Trained batch 300 in epoch 13, gen_loss = 1.4255139047521292, disc_loss = 0.00023770757405846565
Trained batch 301 in epoch 13, gen_loss = 1.4254702838840863, disc_loss = 0.00023708345329908218
Trained batch 302 in epoch 13, gen_loss = 1.4253270976220813, disc_loss = 0.00023644790244271453
Trained batch 303 in epoch 13, gen_loss = 1.425326328136419, disc_loss = 0.00023580551756870256
Trained batch 304 in epoch 13, gen_loss = 1.4255507731046833, disc_loss = 0.00023517523365969328
Trained batch 305 in epoch 13, gen_loss = 1.4256281186552608, disc_loss = 0.0002345511591295161
Trained batch 306 in epoch 13, gen_loss = 1.425452157418192, disc_loss = 0.00023393294997630848
Trained batch 307 in epoch 13, gen_loss = 1.425380031009773, disc_loss = 0.0002333304488132995
Trained batch 308 in epoch 13, gen_loss = 1.4253446307382922, disc_loss = 0.00023274319476698915
Trained batch 309 in epoch 13, gen_loss = 1.4254953115217148, disc_loss = 0.00023216478091912465
Trained batch 310 in epoch 13, gen_loss = 1.425547822878675, disc_loss = 0.00023164985993603046
Trained batch 311 in epoch 13, gen_loss = 1.4255991715651293, disc_loss = 0.00023114146419035163
Trained batch 312 in epoch 13, gen_loss = 1.4258313521790429, disc_loss = 0.00023068558644059265
Trained batch 313 in epoch 13, gen_loss = 1.4255682207216882, disc_loss = 0.0002302769814847055
Trained batch 314 in epoch 13, gen_loss = 1.4257580473309472, disc_loss = 0.00022983965112842501
Trained batch 315 in epoch 13, gen_loss = 1.4257225145267536, disc_loss = 0.00022977033061383564
Trained batch 316 in epoch 13, gen_loss = 1.4258610089118549, disc_loss = 0.0002301918397887466
Trained batch 317 in epoch 13, gen_loss = 1.4259717220780235, disc_loss = 0.00023139649168361248
Trained batch 318 in epoch 13, gen_loss = 1.426037753263611, disc_loss = 0.00023284541111078907
Trained batch 319 in epoch 13, gen_loss = 1.425888044387102, disc_loss = 0.00023433763785760676
Trained batch 320 in epoch 13, gen_loss = 1.4259682526098234, disc_loss = 0.00023594783258013648
Trained batch 321 in epoch 13, gen_loss = 1.4257148052594677, disc_loss = 0.00023795097133741999
Trained batch 322 in epoch 13, gen_loss = 1.4258923024954073, disc_loss = 0.00024037610891025697
Trained batch 323 in epoch 13, gen_loss = 1.4258162905404597, disc_loss = 0.00024313776453642209
Trained batch 324 in epoch 13, gen_loss = 1.4256773515848014, disc_loss = 0.00024604540036167374
Trained batch 325 in epoch 13, gen_loss = 1.425640208223846, disc_loss = 0.00024875550695296455
Trained batch 326 in epoch 13, gen_loss = 1.425767828565125, disc_loss = 0.0002511027970850405
Trained batch 327 in epoch 13, gen_loss = 1.4257133385030234, disc_loss = 0.0002530460221861154
Trained batch 328 in epoch 13, gen_loss = 1.4259658359829053, disc_loss = 0.00025463446262285485
Trained batch 329 in epoch 13, gen_loss = 1.4257463733355205, disc_loss = 0.0002560760226598094
Trained batch 330 in epoch 13, gen_loss = 1.4258448418533693, disc_loss = 0.0002573499837387325
Trained batch 331 in epoch 13, gen_loss = 1.4260096352502525, disc_loss = 0.00025847238259346514
Trained batch 332 in epoch 13, gen_loss = 1.426020964487895, disc_loss = 0.0002594472677953815
Trained batch 333 in epoch 13, gen_loss = 1.4260184918335097, disc_loss = 0.0002602662781443765
Trained batch 334 in epoch 13, gen_loss = 1.4260513576109017, disc_loss = 0.00026084109180808456
Trained batch 335 in epoch 13, gen_loss = 1.4260062866267704, disc_loss = 0.00026108815044218706
Trained batch 336 in epoch 13, gen_loss = 1.4260540899961567, disc_loss = 0.0002611201645226773
Trained batch 337 in epoch 13, gen_loss = 1.4263580028827374, disc_loss = 0.0002609853549311406
Trained batch 338 in epoch 13, gen_loss = 1.4264570893087922, disc_loss = 0.0002606821546583796
Trained batch 339 in epoch 13, gen_loss = 1.4261762198279886, disc_loss = 0.00026046989009688226
Trained batch 340 in epoch 13, gen_loss = 1.4262587716502528, disc_loss = 0.000260207139881112
Trained batch 341 in epoch 13, gen_loss = 1.4259896048328333, disc_loss = 0.00025999400246791725
Trained batch 342 in epoch 13, gen_loss = 1.426034887747584, disc_loss = 0.0002599505785429774
Trained batch 343 in epoch 13, gen_loss = 1.4259552550177241, disc_loss = 0.00025955093558370084
Trained batch 344 in epoch 13, gen_loss = 1.4260948481767073, disc_loss = 0.0002590442111967064
Trained batch 345 in epoch 13, gen_loss = 1.4263267027849407, disc_loss = 0.000258521549273289
Trained batch 346 in epoch 13, gen_loss = 1.426435477451907, disc_loss = 0.0002579985148337487
Trained batch 347 in epoch 13, gen_loss = 1.4262631604041176, disc_loss = 0.00025749637890170896
Trained batch 348 in epoch 13, gen_loss = 1.426081157003911, disc_loss = 0.0002570559469695112
Trained batch 349 in epoch 13, gen_loss = 1.4259741507257735, disc_loss = 0.00025654395250187785
Trained batch 350 in epoch 13, gen_loss = 1.4260268503444486, disc_loss = 0.00025597138639122904
Trained batch 351 in epoch 13, gen_loss = 1.4258913201364605, disc_loss = 0.0002553853216899039
Trained batch 352 in epoch 13, gen_loss = 1.4259146229065849, disc_loss = 0.00025474746542350057
Trained batch 353 in epoch 13, gen_loss = 1.425816124105184, disc_loss = 0.0002541575640348154
Trained batch 354 in epoch 13, gen_loss = 1.4258620960611692, disc_loss = 0.0002535414267288321
Trained batch 355 in epoch 13, gen_loss = 1.4259305047185233, disc_loss = 0.00025296575687932773
Trained batch 356 in epoch 13, gen_loss = 1.425981784067234, disc_loss = 0.00025242740640333427
Trained batch 357 in epoch 13, gen_loss = 1.4261007681905224, disc_loss = 0.0002518725375555519
Trained batch 358 in epoch 13, gen_loss = 1.4259704477607706, disc_loss = 0.00025132779403754885
Trained batch 359 in epoch 13, gen_loss = 1.4259375237756304, disc_loss = 0.00025074119444070677
Trained batch 360 in epoch 13, gen_loss = 1.4259850734488786, disc_loss = 0.00025015690153948556
Trained batch 361 in epoch 13, gen_loss = 1.4260513410383826, disc_loss = 0.00024967637758619874
Trained batch 362 in epoch 13, gen_loss = 1.4259398745439598, disc_loss = 0.00024914574584499236
Trained batch 363 in epoch 13, gen_loss = 1.4258513005225213, disc_loss = 0.0002487673494635181
Trained batch 364 in epoch 13, gen_loss = 1.4258376412195701, disc_loss = 0.00024847055868383605
Trained batch 365 in epoch 13, gen_loss = 1.4257793586110807, disc_loss = 0.0002483580744157108
Trained batch 366 in epoch 13, gen_loss = 1.4258046101484376, disc_loss = 0.0002483384237030019
Trained batch 367 in epoch 13, gen_loss = 1.4258934301526651, disc_loss = 0.00024835292442829717
Trained batch 368 in epoch 13, gen_loss = 1.4259594885637443, disc_loss = 0.0002484231485397543
Trained batch 369 in epoch 13, gen_loss = 1.4259759387454471, disc_loss = 0.00024884861048465954
Trained batch 370 in epoch 13, gen_loss = 1.425884528944113, disc_loss = 0.00024933408558525734
Trained batch 371 in epoch 13, gen_loss = 1.4259090711993556, disc_loss = 0.00024970950247030314
Trained batch 372 in epoch 13, gen_loss = 1.4259451797117177, disc_loss = 0.000250074564442502
Trained batch 373 in epoch 13, gen_loss = 1.425744606849344, disc_loss = 0.0002503644037621116
Trained batch 374 in epoch 13, gen_loss = 1.4257728131612142, disc_loss = 0.0002506155832913161
Trained batch 375 in epoch 13, gen_loss = 1.4257340894100514, disc_loss = 0.00025092583911266936
Trained batch 376 in epoch 13, gen_loss = 1.425671282750542, disc_loss = 0.0002511516438305902
Trained batch 377 in epoch 13, gen_loss = 1.425506361893245, disc_loss = 0.0002512783093388188
Trained batch 378 in epoch 13, gen_loss = 1.4253375376120092, disc_loss = 0.00025133724782329777
Trained batch 379 in epoch 13, gen_loss = 1.4252891189173649, disc_loss = 0.00025126747264757316
Trained batch 380 in epoch 13, gen_loss = 1.4254982039684385, disc_loss = 0.000251084610712606
Trained batch 381 in epoch 13, gen_loss = 1.4255027951994492, disc_loss = 0.0002507681654853742
Trained batch 382 in epoch 13, gen_loss = 1.4254663535260033, disc_loss = 0.0002503930215898056
Trained batch 383 in epoch 13, gen_loss = 1.4253571694716811, disc_loss = 0.00024999657145012105
Trained batch 384 in epoch 13, gen_loss = 1.4252612098470911, disc_loss = 0.00024962610565220435
Trained batch 385 in epoch 13, gen_loss = 1.425290104329895, disc_loss = 0.00024928007572181337
Trained batch 386 in epoch 13, gen_loss = 1.4252347521079602, disc_loss = 0.0002490155679139249
Trained batch 387 in epoch 13, gen_loss = 1.4253457803087137, disc_loss = 0.00024883899911785814
Trained batch 388 in epoch 13, gen_loss = 1.4253356582401344, disc_loss = 0.0002487430712537721
Trained batch 389 in epoch 13, gen_loss = 1.4251259886301482, disc_loss = 0.00024874734937885734
Trained batch 390 in epoch 13, gen_loss = 1.425074747151426, disc_loss = 0.0002487346664472805
Trained batch 391 in epoch 13, gen_loss = 1.4250282131287517, disc_loss = 0.00024877292172017666
Trained batch 392 in epoch 13, gen_loss = 1.4251353082462728, disc_loss = 0.00024888252478295675
Trained batch 393 in epoch 13, gen_loss = 1.4252107364272104, disc_loss = 0.0002489864278631181
Trained batch 394 in epoch 13, gen_loss = 1.425232126441183, disc_loss = 0.00024913361436879717
Trained batch 395 in epoch 13, gen_loss = 1.4252254424071071, disc_loss = 0.0002493285386837596
Trained batch 396 in epoch 13, gen_loss = 1.4252680762288552, disc_loss = 0.0002495127347478967
Trained batch 397 in epoch 13, gen_loss = 1.4254136085510254, disc_loss = 0.00024967111981987643
Trained batch 398 in epoch 13, gen_loss = 1.4255229255609345, disc_loss = 0.00024976236920137536
Trained batch 399 in epoch 13, gen_loss = 1.42559672832489, disc_loss = 0.00024977453637347935
Trained batch 400 in epoch 13, gen_loss = 1.4254768328773708, disc_loss = 0.00024971421754387284
Trained batch 401 in epoch 13, gen_loss = 1.4253028124126035, disc_loss = 0.0002496335414593095
Trained batch 402 in epoch 13, gen_loss = 1.4250639251088977, disc_loss = 0.0002494787955859219
Trained batch 403 in epoch 13, gen_loss = 1.425025826928639, disc_loss = 0.00024926909430060995
Trained batch 404 in epoch 13, gen_loss = 1.424931162080647, disc_loss = 0.0002490303287489906
Trained batch 405 in epoch 13, gen_loss = 1.4249168223348156, disc_loss = 0.00024874028076737886
Trained batch 406 in epoch 13, gen_loss = 1.4248560169112185, disc_loss = 0.0002483916099980792
Trained batch 407 in epoch 13, gen_loss = 1.4249542405207951, disc_loss = 0.00024800136870284156
Trained batch 408 in epoch 13, gen_loss = 1.424903482854512, disc_loss = 0.0002476205524004279
Trained batch 409 in epoch 13, gen_loss = 1.4250030549561106, disc_loss = 0.00024727838767054294
Trained batch 410 in epoch 13, gen_loss = 1.424949310701839, disc_loss = 0.00024701497787975795
Trained batch 411 in epoch 13, gen_loss = 1.4248879036857087, disc_loss = 0.00024677575004371975
Trained batch 412 in epoch 13, gen_loss = 1.4248032800799133, disc_loss = 0.00024649626478250784
Trained batch 413 in epoch 13, gen_loss = 1.4248939813047214, disc_loss = 0.00024620397064297324
Trained batch 414 in epoch 13, gen_loss = 1.4248328263501087, disc_loss = 0.00024593108467682665
Trained batch 415 in epoch 13, gen_loss = 1.4247675899129648, disc_loss = 0.000245673202825331
Trained batch 416 in epoch 13, gen_loss = 1.4248483958575937, disc_loss = 0.0002454033336159731
Trained batch 417 in epoch 13, gen_loss = 1.424847710075561, disc_loss = 0.00024508051009299085
Trained batch 418 in epoch 13, gen_loss = 1.4248476574699749, disc_loss = 0.0002446847250739622
Trained batch 419 in epoch 13, gen_loss = 1.4248555467242285, disc_loss = 0.0002442515865455096
Trained batch 420 in epoch 13, gen_loss = 1.4247499537298063, disc_loss = 0.00024377003060148465
Trained batch 421 in epoch 13, gen_loss = 1.4246284953225845, disc_loss = 0.00024325673456979786
Trained batch 422 in epoch 13, gen_loss = 1.4247035813951605, disc_loss = 0.0002427377275519233
Trained batch 423 in epoch 13, gen_loss = 1.4247405568383775, disc_loss = 0.00024222168711807995
Trained batch 424 in epoch 13, gen_loss = 1.4249434611376595, disc_loss = 0.00024169788847810944
Trained batch 425 in epoch 13, gen_loss = 1.424901248143872, disc_loss = 0.00024121966234901172
Trained batch 426 in epoch 13, gen_loss = 1.424915680282289, disc_loss = 0.0002407757338026767
Trained batch 427 in epoch 13, gen_loss = 1.424893546884305, disc_loss = 0.00024036717020386856
Trained batch 428 in epoch 13, gen_loss = 1.4249933271697073, disc_loss = 0.0002399530255912175
Trained batch 429 in epoch 13, gen_loss = 1.4249321493991585, disc_loss = 0.0002394708702034455
Trained batch 430 in epoch 13, gen_loss = 1.4252252188746724, disc_loss = 0.0002390101804414409
Trained batch 431 in epoch 13, gen_loss = 1.4251236476831965, disc_loss = 0.00023861230503943834
Trained batch 432 in epoch 13, gen_loss = 1.425353118784158, disc_loss = 0.0002383308847024206
Trained batch 433 in epoch 13, gen_loss = 1.4251883724867473, disc_loss = 0.0002382621955824144
Trained batch 434 in epoch 13, gen_loss = 1.4252915004204059, disc_loss = 0.00023839141627497325
Trained batch 435 in epoch 13, gen_loss = 1.4252375465467435, disc_loss = 0.00023867401402197867
Trained batch 436 in epoch 13, gen_loss = 1.4252605784675896, disc_loss = 0.00023903628207502212
Trained batch 437 in epoch 13, gen_loss = 1.4254077414399413, disc_loss = 0.00023946418552034184
Trained batch 438 in epoch 13, gen_loss = 1.425308289723407, disc_loss = 0.00023998160311309297
Trained batch 439 in epoch 13, gen_loss = 1.4251523126255383, disc_loss = 0.00024055772077273023
Trained batch 440 in epoch 13, gen_loss = 1.4252393278134923, disc_loss = 0.00024117207462878137
Trained batch 441 in epoch 13, gen_loss = 1.425077861790204, disc_loss = 0.00024176266829704321
Trained batch 442 in epoch 13, gen_loss = 1.4250100875277552, disc_loss = 0.0002422883799165247
Trained batch 443 in epoch 13, gen_loss = 1.4249787795114088, disc_loss = 0.00024275237511811848
Trained batch 444 in epoch 13, gen_loss = 1.425148307607415, disc_loss = 0.00024322902548223018
Trained batch 445 in epoch 13, gen_loss = 1.4249847178501933, disc_loss = 0.00024380701622163386
Trained batch 446 in epoch 13, gen_loss = 1.425059375346907, disc_loss = 0.000244484824425575
Trained batch 447 in epoch 13, gen_loss = 1.4250139932015113, disc_loss = 0.00024523044256495396
Trained batch 448 in epoch 13, gen_loss = 1.4249984817143804, disc_loss = 0.00024595255683404255
Trained batch 449 in epoch 13, gen_loss = 1.425023263560401, disc_loss = 0.0002464987893270316
Trained batch 450 in epoch 13, gen_loss = 1.4251370731319926, disc_loss = 0.0002468009970551695
Trained batch 451 in epoch 13, gen_loss = 1.4251063123213505, disc_loss = 0.00024695026637201143
Trained batch 452 in epoch 13, gen_loss = 1.4251824377914664, disc_loss = 0.0002470320707156411
Trained batch 453 in epoch 13, gen_loss = 1.4251447280598106, disc_loss = 0.0002469910992650684
Trained batch 454 in epoch 13, gen_loss = 1.4252378890802573, disc_loss = 0.0002468768050975696
Trained batch 455 in epoch 13, gen_loss = 1.425452382679571, disc_loss = 0.00024675961294394114
Trained batch 456 in epoch 13, gen_loss = 1.4254059095090537, disc_loss = 0.0002467047593090365
Trained batch 457 in epoch 13, gen_loss = 1.4253618938433552, disc_loss = 0.0002466615582958327
Trained batch 458 in epoch 13, gen_loss = 1.4253405942896094, disc_loss = 0.0002466872789417858
Trained batch 459 in epoch 13, gen_loss = 1.4253026319586712, disc_loss = 0.00024672919969658403
Trained batch 460 in epoch 13, gen_loss = 1.4255506338111232, disc_loss = 0.000246804632484849
Trained batch 461 in epoch 13, gen_loss = 1.4254143238067627, disc_loss = 0.000246924603727788
Trained batch 462 in epoch 13, gen_loss = 1.4253905030615128, disc_loss = 0.00024711592936861056
Trained batch 463 in epoch 13, gen_loss = 1.4255350139634362, disc_loss = 0.00024735909120220735
Trained batch 464 in epoch 13, gen_loss = 1.4255132941789526, disc_loss = 0.0002476353584893576
Trained batch 465 in epoch 13, gen_loss = 1.4255926573225357, disc_loss = 0.000247950351736557
Trained batch 466 in epoch 13, gen_loss = 1.4256714840262044, disc_loss = 0.00024827880789403037
Trained batch 467 in epoch 13, gen_loss = 1.4256253415702755, disc_loss = 0.00024852086377524026
Trained batch 468 in epoch 13, gen_loss = 1.425633492500289, disc_loss = 0.00024865215383159165
Trained batch 469 in epoch 13, gen_loss = 1.4255664564193564, disc_loss = 0.00024866460655872247
Trained batch 470 in epoch 13, gen_loss = 1.425671573657139, disc_loss = 0.0002486197473404367
Trained batch 471 in epoch 13, gen_loss = 1.4254510261244693, disc_loss = 0.0002485045984377717
Trained batch 472 in epoch 13, gen_loss = 1.425462459913016, disc_loss = 0.00024832224568160005
Trained batch 473 in epoch 13, gen_loss = 1.4254277705643248, disc_loss = 0.0002480412954374603
Trained batch 474 in epoch 13, gen_loss = 1.4254397143815694, disc_loss = 0.00024771019316655214
Trained batch 475 in epoch 13, gen_loss = 1.4253017772145633, disc_loss = 0.0002473571588160965
Trained batch 476 in epoch 13, gen_loss = 1.4252594456982564, disc_loss = 0.0002469889121519075
Trained batch 477 in epoch 13, gen_loss = 1.425255122045094, disc_loss = 0.00024664046051999075
Trained batch 478 in epoch 13, gen_loss = 1.4252768936635059, disc_loss = 0.00024630396697234087
Trained batch 479 in epoch 13, gen_loss = 1.425292150924603, disc_loss = 0.000245959343855399
Trained batch 480 in epoch 13, gen_loss = 1.425243438901128, disc_loss = 0.0002456006560746129
Trained batch 481 in epoch 13, gen_loss = 1.4252912718725401, disc_loss = 0.0002452435702022638
Trained batch 482 in epoch 13, gen_loss = 1.425255449168677, disc_loss = 0.0002449036740436588
Trained batch 483 in epoch 13, gen_loss = 1.4251573839463478, disc_loss = 0.0002445957095967834
Trained batch 484 in epoch 13, gen_loss = 1.425156280429093, disc_loss = 0.00024431174669817414
Trained batch 485 in epoch 13, gen_loss = 1.4251286927074072, disc_loss = 0.00024403872971617355
Trained batch 486 in epoch 13, gen_loss = 1.4251021604518381, disc_loss = 0.00024377219158353727
Trained batch 487 in epoch 13, gen_loss = 1.4250743017822016, disc_loss = 0.0002435185980719653
Trained batch 488 in epoch 13, gen_loss = 1.4251241401173098, disc_loss = 0.00024325495432408936
Trained batch 489 in epoch 13, gen_loss = 1.425192018187776, disc_loss = 0.0002429875507895842
Trained batch 490 in epoch 13, gen_loss = 1.4254244774762093, disc_loss = 0.00024272797196695571
Trained batch 491 in epoch 13, gen_loss = 1.4255312528552078, disc_loss = 0.00024247448144210725
Trained batch 492 in epoch 13, gen_loss = 1.4255809916927655, disc_loss = 0.00024222214044395594
Trained batch 493 in epoch 13, gen_loss = 1.425500084996706, disc_loss = 0.0002419768282265517
Trained batch 494 in epoch 13, gen_loss = 1.4257476250330607, disc_loss = 0.00024174584579319492
Trained batch 495 in epoch 13, gen_loss = 1.4257272885691734, disc_loss = 0.00024152549470698198
Trained batch 496 in epoch 13, gen_loss = 1.4256677673136444, disc_loss = 0.00024129937063364226
Trained batch 497 in epoch 13, gen_loss = 1.4258125410022506, disc_loss = 0.00024108050455465838
Trained batch 498 in epoch 13, gen_loss = 1.4258149107376894, disc_loss = 0.00024090879632566355
Trained batch 499 in epoch 13, gen_loss = 1.4257016441822052, disc_loss = 0.00024078403866951704
Trained batch 500 in epoch 13, gen_loss = 1.4257307635571905, disc_loss = 0.00024070108525473937
Trained batch 501 in epoch 13, gen_loss = 1.4258553437977672, disc_loss = 0.00024065777656271013
Trained batch 502 in epoch 13, gen_loss = 1.4258084797243, disc_loss = 0.00024065759616878385
Trained batch 503 in epoch 13, gen_loss = 1.425590160583693, disc_loss = 0.00024069854941358027
Trained batch 504 in epoch 13, gen_loss = 1.4254687958424634, disc_loss = 0.00024077041834430875
Trained batch 505 in epoch 13, gen_loss = 1.4256016675662617, disc_loss = 0.0002408936588835786
Trained batch 506 in epoch 13, gen_loss = 1.4254924416306927, disc_loss = 0.00024108481128672869
Trained batch 507 in epoch 13, gen_loss = 1.4254428619944204, disc_loss = 0.00024134820662186215
Trained batch 508 in epoch 13, gen_loss = 1.425547489482902, disc_loss = 0.0002416593155205606
Trained batch 509 in epoch 13, gen_loss = 1.4255652093419842, disc_loss = 0.0002419841743104888
Trained batch 510 in epoch 13, gen_loss = 1.4255871635127209, disc_loss = 0.00024235998045906782
Trained batch 511 in epoch 13, gen_loss = 1.425615129293874, disc_loss = 0.00024277312567377862
Trained batch 512 in epoch 13, gen_loss = 1.425659250330042, disc_loss = 0.0002431703687300958
Trained batch 513 in epoch 13, gen_loss = 1.4256200604865523, disc_loss = 0.00024352340304898256
Trained batch 514 in epoch 13, gen_loss = 1.4256111422788749, disc_loss = 0.0002438474740081148
Trained batch 515 in epoch 13, gen_loss = 1.425617161647294, disc_loss = 0.0002441698295904841
Trained batch 516 in epoch 13, gen_loss = 1.425534105162556, disc_loss = 0.00024448987391738043
Trained batch 517 in epoch 13, gen_loss = 1.4255951079162392, disc_loss = 0.0002448282044799313
Trained batch 518 in epoch 13, gen_loss = 1.4254687783346012, disc_loss = 0.00024516858970005624
Trained batch 519 in epoch 13, gen_loss = 1.4254840575731718, disc_loss = 0.0002454969192128304
Trained batch 520 in epoch 13, gen_loss = 1.425547899531769, disc_loss = 0.00024579362114993635
Trained batch 521 in epoch 13, gen_loss = 1.4254819622898467, disc_loss = 0.0002459957370764192
Trained batch 522 in epoch 13, gen_loss = 1.4255686902635185, disc_loss = 0.00024610695026019286
Trained batch 523 in epoch 13, gen_loss = 1.4256647411193557, disc_loss = 0.0002461824825637339
Trained batch 524 in epoch 13, gen_loss = 1.4257155198142641, disc_loss = 0.0002462291324177169
Trained batch 525 in epoch 13, gen_loss = 1.4257727908997482, disc_loss = 0.00024625287613217405
Trained batch 526 in epoch 13, gen_loss = 1.4257671486946843, disc_loss = 0.0002462729062279278
Trained batch 527 in epoch 13, gen_loss = 1.4257569044376865, disc_loss = 0.00024632450331616633
Trained batch 528 in epoch 13, gen_loss = 1.4258468504889477, disc_loss = 0.0002464261219266744
Trained batch 529 in epoch 13, gen_loss = 1.4257961014531693, disc_loss = 0.00024658852343802795
Trained batch 530 in epoch 13, gen_loss = 1.425882618755046, disc_loss = 0.0002467449171653159
Trained batch 531 in epoch 13, gen_loss = 1.4258460478675097, disc_loss = 0.000246862392326246
Trained batch 532 in epoch 13, gen_loss = 1.4259408206921804, disc_loss = 0.00024692403701230455
Trained batch 533 in epoch 13, gen_loss = 1.425908009657699, disc_loss = 0.0002468608060079897
Trained batch 534 in epoch 13, gen_loss = 1.4259653354359565, disc_loss = 0.00024672371349131547
Trained batch 535 in epoch 13, gen_loss = 1.4258792787345487, disc_loss = 0.0002466112191100297
Trained batch 536 in epoch 13, gen_loss = 1.4258795916701161, disc_loss = 0.00024652926771137043
Trained batch 537 in epoch 13, gen_loss = 1.4258372714971521, disc_loss = 0.00024643857316269263
Trained batch 538 in epoch 13, gen_loss = 1.4259101871214461, disc_loss = 0.00024634422600132276
Trained batch 539 in epoch 13, gen_loss = 1.4258893617877253, disc_loss = 0.0002463152723167797
Trained batch 540 in epoch 13, gen_loss = 1.425939026249094, disc_loss = 0.00024627568848140503
Trained batch 541 in epoch 13, gen_loss = 1.4258505873574543, disc_loss = 0.00024621381643760373
Trained batch 542 in epoch 13, gen_loss = 1.4257628856223372, disc_loss = 0.00024607745723006797
Trained batch 543 in epoch 13, gen_loss = 1.425841054714778, disc_loss = 0.00024589921560605303
Trained batch 544 in epoch 13, gen_loss = 1.4258033721818837, disc_loss = 0.0002456929952240231
Trained batch 545 in epoch 13, gen_loss = 1.4259393079813583, disc_loss = 0.00024547019007520543
Trained batch 546 in epoch 13, gen_loss = 1.4260508957467088, disc_loss = 0.0002452448861764936
Trained batch 547 in epoch 13, gen_loss = 1.4259794443628213, disc_loss = 0.0002450270802990045
Trained batch 548 in epoch 13, gen_loss = 1.4260721017754143, disc_loss = 0.0002447938066106474
Trained batch 549 in epoch 13, gen_loss = 1.4261569879271767, disc_loss = 0.0002445393566151986
Trained batch 550 in epoch 13, gen_loss = 1.4261341352428152, disc_loss = 0.00024426852720689783
Trained batch 551 in epoch 13, gen_loss = 1.4262151679267054, disc_loss = 0.00024399177390399058
Trained batch 552 in epoch 13, gen_loss = 1.4263320917677922, disc_loss = 0.00024372218376646896
Trained batch 553 in epoch 13, gen_loss = 1.4261878311418885, disc_loss = 0.00024344790606531597
Trained batch 554 in epoch 13, gen_loss = 1.4261664360493154, disc_loss = 0.00024316878096231466
Trained batch 555 in epoch 13, gen_loss = 1.4261530058847056, disc_loss = 0.00024290061789196174
Trained batch 556 in epoch 13, gen_loss = 1.426233620361109, disc_loss = 0.00024264196917603083
Trained batch 557 in epoch 13, gen_loss = 1.4262581196309845, disc_loss = 0.00024239809620644256
Trained batch 558 in epoch 13, gen_loss = 1.4262141221751041, disc_loss = 0.00024217600412564233
Trained batch 559 in epoch 13, gen_loss = 1.4263332522341183, disc_loss = 0.00024198135063215886
Trained batch 560 in epoch 13, gen_loss = 1.4262654530598307, disc_loss = 0.00024184192692191833
Trained batch 561 in epoch 13, gen_loss = 1.426282444458415, disc_loss = 0.00024178790747644475
Trained batch 562 in epoch 13, gen_loss = 1.426346695867779, disc_loss = 0.00024182750040796676
Trained batch 563 in epoch 13, gen_loss = 1.4262960138895833, disc_loss = 0.00024193755005927925
Trained batch 564 in epoch 13, gen_loss = 1.4263598231087744, disc_loss = 0.0002421035951427627
Trained batch 565 in epoch 13, gen_loss = 1.4263378560753677, disc_loss = 0.00024235023060801102
Trained batch 566 in epoch 13, gen_loss = 1.4262603443556152, disc_loss = 0.00024269869710838505
Trained batch 567 in epoch 13, gen_loss = 1.426173630524689, disc_loss = 0.0002431117663529452
Trained batch 568 in epoch 13, gen_loss = 1.4262944728083686, disc_loss = 0.0002435346489128694
Trained batch 569 in epoch 13, gen_loss = 1.426306122436858, disc_loss = 0.00024392228769054208
Trained batch 570 in epoch 13, gen_loss = 1.426347721478985, disc_loss = 0.0002442760831817254
Trained batch 571 in epoch 13, gen_loss = 1.4263513890596538, disc_loss = 0.0002445610696038504
Trained batch 572 in epoch 13, gen_loss = 1.4263721768976714, disc_loss = 0.00024479665447724473
Trained batch 573 in epoch 13, gen_loss = 1.4263705380702267, disc_loss = 0.0002450172443235468
Trained batch 574 in epoch 13, gen_loss = 1.4263469559213389, disc_loss = 0.00024528731195618014
Trained batch 575 in epoch 13, gen_loss = 1.4263144166519244, disc_loss = 0.00024568684277899894
Trained batch 576 in epoch 13, gen_loss = 1.4263874563022132, disc_loss = 0.0002461458754727923
Trained batch 577 in epoch 13, gen_loss = 1.4265122832311479, disc_loss = 0.00024657147116416796
Trained batch 578 in epoch 13, gen_loss = 1.4265199467308163, disc_loss = 0.00024699463989198695
Trained batch 579 in epoch 13, gen_loss = 1.426492992146262, disc_loss = 0.0002474519338679313
Trained batch 580 in epoch 13, gen_loss = 1.4264826920274614, disc_loss = 0.000247953982471917
Trained batch 581 in epoch 13, gen_loss = 1.4265001029083408, disc_loss = 0.0002485253879783387
Trained batch 582 in epoch 13, gen_loss = 1.4264010769629765, disc_loss = 0.00024913976957426364
Trained batch 583 in epoch 13, gen_loss = 1.4263991054198513, disc_loss = 0.00024971800012717226
Trained batch 584 in epoch 13, gen_loss = 1.4263306839853271, disc_loss = 0.00025023292095843665
Trained batch 585 in epoch 13, gen_loss = 1.4262694586259106, disc_loss = 0.00025071658511562555
Trained batch 586 in epoch 13, gen_loss = 1.4262637903174509, disc_loss = 0.00025120265962786753
Trained batch 587 in epoch 13, gen_loss = 1.4263951129653827, disc_loss = 0.00025171764103533304
Trained batch 588 in epoch 13, gen_loss = 1.4264061175704206, disc_loss = 0.0002522842654233143
Trained batch 589 in epoch 13, gen_loss = 1.4264480606984284, disc_loss = 0.00025289435168938864
Trained batch 590 in epoch 13, gen_loss = 1.4263455912143042, disc_loss = 0.00025349685141866276
Trained batch 591 in epoch 13, gen_loss = 1.4263518239195283, disc_loss = 0.0002540223024210276
Trained batch 592 in epoch 13, gen_loss = 1.4263722920699224, disc_loss = 0.0002543705531213545
Trained batch 593 in epoch 13, gen_loss = 1.4265045527657274, disc_loss = 0.0002544982174335913
Trained batch 594 in epoch 13, gen_loss = 1.4264947272148454, disc_loss = 0.0002544452271030721
Trained batch 595 in epoch 13, gen_loss = 1.4264103968271473, disc_loss = 0.00025430872511184965
Trained batch 596 in epoch 13, gen_loss = 1.4264666550922234, disc_loss = 0.00025413727809023637
Trained batch 597 in epoch 13, gen_loss = 1.4265087571829858, disc_loss = 0.0002539306489299244
Trained batch 598 in epoch 13, gen_loss = 1.4265022027074594, disc_loss = 0.0002537098381118466
Trained batch 599 in epoch 13, gen_loss = 1.426524104475975, disc_loss = 0.00025353724157260634
Trained batch 600 in epoch 13, gen_loss = 1.4264045586800218, disc_loss = 0.0002534498799225529
Trained batch 601 in epoch 13, gen_loss = 1.4263292618368155, disc_loss = 0.0002533537234984672
Trained batch 602 in epoch 13, gen_loss = 1.426330440673069, disc_loss = 0.0002531718580707648
Trained batch 603 in epoch 13, gen_loss = 1.4264859355838093, disc_loss = 0.00025289356359124043
Trained batch 604 in epoch 13, gen_loss = 1.4265925505929742, disc_loss = 0.0002525613772963541
Trained batch 605 in epoch 13, gen_loss = 1.4266088435752164, disc_loss = 0.00025220652655767034
Trained batch 606 in epoch 13, gen_loss = 1.4266853354122533, disc_loss = 0.00025182916747783083
Trained batch 607 in epoch 13, gen_loss = 1.4266817308962345, disc_loss = 0.00025144212955446595
Trained batch 608 in epoch 13, gen_loss = 1.426745827953608, disc_loss = 0.0002510679698541469
Trained batch 609 in epoch 13, gen_loss = 1.426609342020066, disc_loss = 0.0002507192757279807
Trained batch 610 in epoch 13, gen_loss = 1.4266632143682427, disc_loss = 0.0002504395229472613
Trained batch 611 in epoch 13, gen_loss = 1.4265975324936162, disc_loss = 0.0002502307746540074
Trained batch 612 in epoch 13, gen_loss = 1.4265694767965966, disc_loss = 0.0002500745694844381
Trained batch 613 in epoch 13, gen_loss = 1.426609285685449, disc_loss = 0.00024994430496837644
Trained batch 614 in epoch 13, gen_loss = 1.4264930893735188, disc_loss = 0.0002498204752244907
Trained batch 615 in epoch 13, gen_loss = 1.4264815066541945, disc_loss = 0.0002497250925857357
Trained batch 616 in epoch 13, gen_loss = 1.426610560239424, disc_loss = 0.00024967458204622304
Trained batch 617 in epoch 13, gen_loss = 1.4266661471147752, disc_loss = 0.00024964024464459075
Trained batch 618 in epoch 13, gen_loss = 1.426509160410029, disc_loss = 0.000249567666838462
Trained batch 619 in epoch 13, gen_loss = 1.4265939720215337, disc_loss = 0.0002494133006973331
Trained batch 620 in epoch 13, gen_loss = 1.426636333050935, disc_loss = 0.0002492136573831865
Trained batch 621 in epoch 13, gen_loss = 1.426435973099957, disc_loss = 0.00024897098641321727
Trained batch 622 in epoch 13, gen_loss = 1.4264078101989355, disc_loss = 0.0002487106121027559
Trained batch 623 in epoch 13, gen_loss = 1.4264634660421274, disc_loss = 0.00024843660383876105
Trained batch 624 in epoch 13, gen_loss = 1.4265337017059325, disc_loss = 0.0002481671939312946
Trained batch 625 in epoch 13, gen_loss = 1.426551127586121, disc_loss = 0.00024790177379206484
Trained batch 626 in epoch 13, gen_loss = 1.4266161709501033, disc_loss = 0.0002476492041675615
Trained batch 627 in epoch 13, gen_loss = 1.426699653552596, disc_loss = 0.00024743748606527617
Trained batch 628 in epoch 13, gen_loss = 1.4268280201382781, disc_loss = 0.0002473082312215538
Trained batch 629 in epoch 13, gen_loss = 1.426935020704118, disc_loss = 0.00024727051734064136
Trained batch 630 in epoch 13, gen_loss = 1.4268987475408805, disc_loss = 0.0002473055915483152
Trained batch 631 in epoch 13, gen_loss = 1.4269270425355887, disc_loss = 0.0002473929086383716
Trained batch 632 in epoch 13, gen_loss = 1.4269724709539429, disc_loss = 0.0002475068743825183
Trained batch 633 in epoch 13, gen_loss = 1.4268968349751614, disc_loss = 0.0002476320514516124
Trained batch 634 in epoch 13, gen_loss = 1.4268307576967976, disc_loss = 0.0002477724600400442
Trained batch 635 in epoch 13, gen_loss = 1.426874946310835, disc_loss = 0.0002479798403494342
Trained batch 636 in epoch 13, gen_loss = 1.426932501268911, disc_loss = 0.00024825778200180163
Trained batch 637 in epoch 13, gen_loss = 1.4270061628198176, disc_loss = 0.00024862871062034065
Trained batch 638 in epoch 13, gen_loss = 1.427071989795225, disc_loss = 0.0002490654465511856
Trained batch 639 in epoch 13, gen_loss = 1.4271705958992242, disc_loss = 0.00024953715108608774
Trained batch 640 in epoch 13, gen_loss = 1.4271383586800228, disc_loss = 0.0002500547508047781
Trained batch 641 in epoch 13, gen_loss = 1.4273522293827616, disc_loss = 0.000250581795433538
Trained batch 642 in epoch 13, gen_loss = 1.42739703569961, disc_loss = 0.0002511129653727014
Trained batch 643 in epoch 13, gen_loss = 1.427428062287917, disc_loss = 0.0002516624332280986
Trained batch 644 in epoch 13, gen_loss = 1.4275267172229382, disc_loss = 0.0002522008265055041
Trained batch 645 in epoch 13, gen_loss = 1.4274408922475927, disc_loss = 0.0002526836907509559
Trained batch 646 in epoch 13, gen_loss = 1.4274138260108795, disc_loss = 0.0002530839346566326
Trained batch 647 in epoch 13, gen_loss = 1.4274716986182294, disc_loss = 0.0002533778440549752
Trained batch 648 in epoch 13, gen_loss = 1.4275446299962895, disc_loss = 0.0002535371574170429
Trained batch 649 in epoch 13, gen_loss = 1.4275388781840985, disc_loss = 0.0002535580205025886
Trained batch 650 in epoch 13, gen_loss = 1.427491703157967, disc_loss = 0.0002534570953370692
Trained batch 651 in epoch 13, gen_loss = 1.427510702902554, disc_loss = 0.0002532912881151174
Trained batch 652 in epoch 13, gen_loss = 1.4274505553895445, disc_loss = 0.00025309403202872455
Trained batch 653 in epoch 13, gen_loss = 1.427402820244477, disc_loss = 0.00025288587838616215
Trained batch 654 in epoch 13, gen_loss = 1.4273532476133972, disc_loss = 0.0002526584668038324
Trained batch 655 in epoch 13, gen_loss = 1.4273435126354055, disc_loss = 0.00025239429835271105
Trained batch 656 in epoch 13, gen_loss = 1.4273793094960159, disc_loss = 0.00025209231489013544
Trained batch 657 in epoch 13, gen_loss = 1.427412736017291, disc_loss = 0.0002517706491559104
Trained batch 658 in epoch 13, gen_loss = 1.427415495396384, disc_loss = 0.0002514449399247644
Trained batch 659 in epoch 13, gen_loss = 1.4274227315729315, disc_loss = 0.0002511209005729832
Trained batch 660 in epoch 13, gen_loss = 1.4273487966107528, disc_loss = 0.00025080273602045644
Trained batch 661 in epoch 13, gen_loss = 1.427259986494243, disc_loss = 0.0002504984672270378
Trained batch 662 in epoch 13, gen_loss = 1.4271932200249144, disc_loss = 0.0002502050626045655
Trained batch 663 in epoch 13, gen_loss = 1.4273687484393638, disc_loss = 0.0002499265778476319
Trained batch 664 in epoch 13, gen_loss = 1.4274125215702487, disc_loss = 0.000249649236218118
Trained batch 665 in epoch 13, gen_loss = 1.4274757572480508, disc_loss = 0.00024936526196424265
Trained batch 666 in epoch 13, gen_loss = 1.4275034826913515, disc_loss = 0.00024907529689465835
Trained batch 667 in epoch 13, gen_loss = 1.4274894122235076, disc_loss = 0.0002487976383339421
Trained batch 668 in epoch 13, gen_loss = 1.4273750748156788, disc_loss = 0.00024852728794738844
Trained batch 669 in epoch 13, gen_loss = 1.4272754523291518, disc_loss = 0.0002482636361912852
Trained batch 670 in epoch 13, gen_loss = 1.427370914403799, disc_loss = 0.00024800065127553574
Trained batch 671 in epoch 13, gen_loss = 1.4273567270664942, disc_loss = 0.0002477458580025476
Trained batch 672 in epoch 13, gen_loss = 1.427497729681222, disc_loss = 0.00024749296330087465
Trained batch 673 in epoch 13, gen_loss = 1.4275612931930701, disc_loss = 0.0002472491537891632
Trained batch 674 in epoch 13, gen_loss = 1.4275801614478782, disc_loss = 0.0002470189159416973
Trained batch 675 in epoch 13, gen_loss = 1.4276049124771322, disc_loss = 0.00024682540099641803
Trained batch 676 in epoch 13, gen_loss = 1.4276567641177944, disc_loss = 0.0002466572243315333
Trained batch 677 in epoch 13, gen_loss = 1.4275865637447278, disc_loss = 0.0002465198790761168
Trained batch 678 in epoch 13, gen_loss = 1.4276077189045204, disc_loss = 0.00024641234961460755
Trained batch 679 in epoch 13, gen_loss = 1.4275988529710208, disc_loss = 0.0002462857996600659
Trained batch 680 in epoch 13, gen_loss = 1.4275103847710922, disc_loss = 0.0002461147250522307
Trained batch 681 in epoch 13, gen_loss = 1.4274862384166884, disc_loss = 0.0002459078890447644
Trained batch 682 in epoch 13, gen_loss = 1.4274935626355307, disc_loss = 0.00024571059381674177
Trained batch 683 in epoch 13, gen_loss = 1.4275569300553952, disc_loss = 0.0002455544150156161
Trained batch 684 in epoch 13, gen_loss = 1.4275259513924592, disc_loss = 0.000245421810084563
Trained batch 685 in epoch 13, gen_loss = 1.4275955031286522, disc_loss = 0.00024527801146570244
Trained batch 686 in epoch 13, gen_loss = 1.4275393980559303, disc_loss = 0.00024510567869170566
Trained batch 687 in epoch 13, gen_loss = 1.4275563641689544, disc_loss = 0.0002449221347189958
Trained batch 688 in epoch 13, gen_loss = 1.4274634496567038, disc_loss = 0.0002447677939182015
Trained batch 689 in epoch 13, gen_loss = 1.4275588032128155, disc_loss = 0.0002446577938668349
Trained batch 690 in epoch 13, gen_loss = 1.4274533057178327, disc_loss = 0.0002445714638700544
Trained batch 691 in epoch 13, gen_loss = 1.427499702383328, disc_loss = 0.0002445081077957515
Trained batch 692 in epoch 13, gen_loss = 1.4274751558620349, disc_loss = 0.00024448733032287283
Trained batch 693 in epoch 13, gen_loss = 1.4275057293496145, disc_loss = 0.0002445180777773014
Trained batch 694 in epoch 13, gen_loss = 1.4275916387708925, disc_loss = 0.00024460306359294187
Trained batch 695 in epoch 13, gen_loss = 1.4276207921833828, disc_loss = 0.0002447461293563354
Trained batch 696 in epoch 13, gen_loss = 1.427616183350726, disc_loss = 0.0002449605936469133
Trained batch 697 in epoch 13, gen_loss = 1.427674713995532, disc_loss = 0.0002452523941587774
Trained batch 698 in epoch 13, gen_loss = 1.4276462648388994, disc_loss = 0.0002456335868827668
Trained batch 699 in epoch 13, gen_loss = 1.4276954085486275, disc_loss = 0.00024611465316931054
Trained batch 700 in epoch 13, gen_loss = 1.4276669974333889, disc_loss = 0.0002467346383649298
Trained batch 701 in epoch 13, gen_loss = 1.4276951400303093, disc_loss = 0.00024758680956438184
Trained batch 702 in epoch 13, gen_loss = 1.42769715830069, disc_loss = 0.000248788821856739
Trained batch 703 in epoch 13, gen_loss = 1.4278686204078523, disc_loss = 0.00025027766506272286
Trained batch 704 in epoch 13, gen_loss = 1.4278998642103047, disc_loss = 0.000251973056108922
Trained batch 705 in epoch 13, gen_loss = 1.42795711097231, disc_loss = 0.0002537838395397382
Trained batch 706 in epoch 13, gen_loss = 1.4279024968558693, disc_loss = 0.00025548929970347896
Trained batch 707 in epoch 13, gen_loss = 1.4279585790499456, disc_loss = 0.00025689283104371387
Trained batch 708 in epoch 13, gen_loss = 1.427996839723735, disc_loss = 0.00025793134329422826
Trained batch 709 in epoch 13, gen_loss = 1.4280251355238365, disc_loss = 0.00025863112024241455
Trained batch 710 in epoch 13, gen_loss = 1.4280237014786603, disc_loss = 0.00025904175762215474
Trained batch 711 in epoch 13, gen_loss = 1.4281126850106742, disc_loss = 0.0002592590066383258
Trained batch 712 in epoch 13, gen_loss = 1.4280170989738774, disc_loss = 0.0002593314645372378
Trained batch 713 in epoch 13, gen_loss = 1.4280162398554699, disc_loss = 0.00025931199801745316
Trained batch 714 in epoch 13, gen_loss = 1.4280971433732894, disc_loss = 0.0002592069370602095
Trained batch 715 in epoch 13, gen_loss = 1.4281843885696135, disc_loss = 0.0002590552266760646
Trained batch 716 in epoch 13, gen_loss = 1.4282191778991677, disc_loss = 0.000258906991539245
Trained batch 717 in epoch 13, gen_loss = 1.4281890131636914, disc_loss = 0.00025895368833157097
Trained batch 718 in epoch 13, gen_loss = 1.4281368340172589, disc_loss = 0.0002590878140433887
Trained batch 719 in epoch 13, gen_loss = 1.42815566841099, disc_loss = 0.0002593323204362403
Trained batch 720 in epoch 13, gen_loss = 1.428257906321183, disc_loss = 0.00025964130467609936
Trained batch 721 in epoch 13, gen_loss = 1.4282986875055899, disc_loss = 0.0002602674975608143
Trained batch 722 in epoch 13, gen_loss = 1.4284039678085558, disc_loss = 0.00026095349830800713
Trained batch 723 in epoch 13, gen_loss = 1.4283170329602384, disc_loss = 0.00026155989776295997
Trained batch 724 in epoch 13, gen_loss = 1.4283192080464857, disc_loss = 0.00026211123271235106
Trained batch 725 in epoch 13, gen_loss = 1.4283481826466962, disc_loss = 0.00026261929662182374
Trained batch 726 in epoch 13, gen_loss = 1.4283139449858109, disc_loss = 0.000263106147086112
Trained batch 727 in epoch 13, gen_loss = 1.4283021360963255, disc_loss = 0.0002633667190221476
Trained batch 728 in epoch 13, gen_loss = 1.4283081536757438, disc_loss = 0.0002634742388895244
Trained batch 729 in epoch 13, gen_loss = 1.428344269158089, disc_loss = 0.0002634800480174743
Trained batch 730 in epoch 13, gen_loss = 1.4283542960841418, disc_loss = 0.0002634875927370159
Trained batch 731 in epoch 13, gen_loss = 1.4284881369663718, disc_loss = 0.00026345800882258806
Trained batch 732 in epoch 13, gen_loss = 1.4284673911324952, disc_loss = 0.0002633826770215571
Trained batch 733 in epoch 13, gen_loss = 1.4285111118727225, disc_loss = 0.00026340957657892093
Trained batch 734 in epoch 13, gen_loss = 1.4284984095566937, disc_loss = 0.0002633554689098327
Trained batch 735 in epoch 13, gen_loss = 1.428436331127001, disc_loss = 0.0002633986309576911
Trained batch 736 in epoch 13, gen_loss = 1.4284815822236412, disc_loss = 0.0002635172485728373
Trained batch 737 in epoch 13, gen_loss = 1.4285546061469288, disc_loss = 0.0002636476769664156
Trained batch 738 in epoch 13, gen_loss = 1.4284612909866767, disc_loss = 0.0002637274933273807
Trained batch 739 in epoch 13, gen_loss = 1.4284556897910865, disc_loss = 0.00026371877642845535
Trained batch 740 in epoch 13, gen_loss = 1.4284217254674707, disc_loss = 0.0002635978278546882
Trained batch 741 in epoch 13, gen_loss = 1.4283940483617654, disc_loss = 0.000263393636639299
Trained batch 742 in epoch 13, gen_loss = 1.4283190880617576, disc_loss = 0.000263152966001773
Trained batch 743 in epoch 13, gen_loss = 1.4282376341601855, disc_loss = 0.0002629430313860329
Trained batch 744 in epoch 13, gen_loss = 1.428317505081228, disc_loss = 0.000262665303043893
Trained batch 745 in epoch 13, gen_loss = 1.4283317535236757, disc_loss = 0.00026237833846739497
Testing Epoch 13
Training Epoch 14
Trained batch 0 in epoch 14, gen_loss = 1.4091594219207764, disc_loss = 6.172017310746014e-05
Trained batch 1 in epoch 14, gen_loss = 1.4211487174034119, disc_loss = 5.078922549728304e-05
Trained batch 2 in epoch 14, gen_loss = 1.4016939401626587, disc_loss = 4.974114320551356e-05
Trained batch 3 in epoch 14, gen_loss = 1.4048900604248047, disc_loss = 5.407942626334261e-05
Trained batch 4 in epoch 14, gen_loss = 1.4184717893600465, disc_loss = 6.00163300987333e-05
Trained batch 5 in epoch 14, gen_loss = 1.4260315895080566, disc_loss = 6.377276925680538e-05
Trained batch 6 in epoch 14, gen_loss = 1.4360121147973197, disc_loss = 6.706616633372115e-05
Trained batch 7 in epoch 14, gen_loss = 1.4347184747457504, disc_loss = 7.062104941724101e-05
Trained batch 8 in epoch 14, gen_loss = 1.435874833001031, disc_loss = 7.632001668551109e-05
Trained batch 9 in epoch 14, gen_loss = 1.4409188389778138, disc_loss = 8.089482362265699e-05
Trained batch 10 in epoch 14, gen_loss = 1.4483477960933338, disc_loss = 8.376840163360943e-05
Trained batch 11 in epoch 14, gen_loss = 1.445040335257848, disc_loss = 8.736338835054387e-05
Trained batch 12 in epoch 14, gen_loss = 1.4484702898905828, disc_loss = 9.189331187651708e-05
Trained batch 13 in epoch 14, gen_loss = 1.4487691010747636, disc_loss = 9.736508322280965e-05
Trained batch 14 in epoch 14, gen_loss = 1.4485880931218464, disc_loss = 0.00010438215977046639
Trained batch 15 in epoch 14, gen_loss = 1.445113517343998, disc_loss = 0.0001116019820983638
Trained batch 16 in epoch 14, gen_loss = 1.4466941076166489, disc_loss = 0.00011940515918575008
Trained batch 17 in epoch 14, gen_loss = 1.444606648551093, disc_loss = 0.0001282763720761674
Trained batch 18 in epoch 14, gen_loss = 1.4467676438783343, disc_loss = 0.0001370431005182725
Trained batch 19 in epoch 14, gen_loss = 1.4439826011657715, disc_loss = 0.0001470627415983472
Trained batch 20 in epoch 14, gen_loss = 1.4435406980060397, disc_loss = 0.0001563033195755755
Trained batch 21 in epoch 14, gen_loss = 1.4413654912601819, disc_loss = 0.0001649040899461728
Trained batch 22 in epoch 14, gen_loss = 1.4426004057345183, disc_loss = 0.00017025288126087221
Trained batch 23 in epoch 14, gen_loss = 1.4438643554846446, disc_loss = 0.0001729325122141745
Trained batch 24 in epoch 14, gen_loss = 1.4421579599380494, disc_loss = 0.00017413387424312533
Trained batch 25 in epoch 14, gen_loss = 1.4406682848930359, disc_loss = 0.00017454390595398413
Trained batch 26 in epoch 14, gen_loss = 1.4395206371943157, disc_loss = 0.00017493845263271833
Trained batch 27 in epoch 14, gen_loss = 1.4366697839328222, disc_loss = 0.00017477332533287284
Trained batch 28 in epoch 14, gen_loss = 1.4380929716702164, disc_loss = 0.00017374130477727358
Trained batch 29 in epoch 14, gen_loss = 1.4386601209640504, disc_loss = 0.00017180198653174255
Trained batch 30 in epoch 14, gen_loss = 1.4393000679631387, disc_loss = 0.000169082437482317
Trained batch 31 in epoch 14, gen_loss = 1.438807651400566, disc_loss = 0.00016572950244153617
Trained batch 32 in epoch 14, gen_loss = 1.4382167729464443, disc_loss = 0.00016230138487916327
Trained batch 33 in epoch 14, gen_loss = 1.4381096222821403, disc_loss = 0.00015939997662345004
Trained batch 34 in epoch 14, gen_loss = 1.438555771963937, disc_loss = 0.00015748272479478535
Trained batch 35 in epoch 14, gen_loss = 1.4380743636025324, disc_loss = 0.00015609594831605337
Trained batch 36 in epoch 14, gen_loss = 1.4368655456079018, disc_loss = 0.00015477906531855665
Trained batch 37 in epoch 14, gen_loss = 1.4358813103876615, disc_loss = 0.00015363252858055363
Trained batch 38 in epoch 14, gen_loss = 1.435786485671997, disc_loss = 0.00015272431371088786
Trained batch 39 in epoch 14, gen_loss = 1.4336789697408676, disc_loss = 0.00015180525442701765
Trained batch 40 in epoch 14, gen_loss = 1.4334103334240798, disc_loss = 0.00015073789126756487
Trained batch 41 in epoch 14, gen_loss = 1.4323597777457464, disc_loss = 0.00014944866901108375
Trained batch 42 in epoch 14, gen_loss = 1.4327807260114094, disc_loss = 0.00014794311252000288
Trained batch 43 in epoch 14, gen_loss = 1.43251094492999, disc_loss = 0.0001463004001297205
Trained batch 44 in epoch 14, gen_loss = 1.4332812865575155, disc_loss = 0.0001445388426266921
Trained batch 45 in epoch 14, gen_loss = 1.4322658284850742, disc_loss = 0.00014265774734667502
Trained batch 46 in epoch 14, gen_loss = 1.4316723955438493, disc_loss = 0.00014073698982061382
Trained batch 47 in epoch 14, gen_loss = 1.4325727621714275, disc_loss = 0.0001389665932644372
Trained batch 48 in epoch 14, gen_loss = 1.4320012355337337, disc_loss = 0.0001373528024004725
Trained batch 49 in epoch 14, gen_loss = 1.4319460487365723, disc_loss = 0.0001357589252438629
Trained batch 50 in epoch 14, gen_loss = 1.4311005554947198, disc_loss = 0.00013431455084298482
Trained batch 51 in epoch 14, gen_loss = 1.4320282660997832, disc_loss = 0.00013302665802956864
Trained batch 52 in epoch 14, gen_loss = 1.4299134735791188, disc_loss = 0.00013200292576001166
Trained batch 53 in epoch 14, gen_loss = 1.4301709400282965, disc_loss = 0.00013128960111956716
Trained batch 54 in epoch 14, gen_loss = 1.4310059547424316, disc_loss = 0.00013070890384948473
Trained batch 55 in epoch 14, gen_loss = 1.4309362471103668, disc_loss = 0.00013031026154359488
Trained batch 56 in epoch 14, gen_loss = 1.4305547873179119, disc_loss = 0.0001303240973548351
Trained batch 57 in epoch 14, gen_loss = 1.4313590732114068, disc_loss = 0.00013108671511621777
Trained batch 58 in epoch 14, gen_loss = 1.4315854856523418, disc_loss = 0.00013308035945016654
Trained batch 59 in epoch 14, gen_loss = 1.4324382682641348, disc_loss = 0.00013649960631785993
Trained batch 60 in epoch 14, gen_loss = 1.4320213384315617, disc_loss = 0.00014071371894163753
Trained batch 61 in epoch 14, gen_loss = 1.4305332591456752, disc_loss = 0.00014524889675451578
Trained batch 62 in epoch 14, gen_loss = 1.4305508288126143, disc_loss = 0.00014943352491374954
Trained batch 63 in epoch 14, gen_loss = 1.4306278638541698, disc_loss = 0.00015317526123226344
Trained batch 64 in epoch 14, gen_loss = 1.4307962124164288, disc_loss = 0.00015656617766720817
Trained batch 65 in epoch 14, gen_loss = 1.4308826887246333, disc_loss = 0.00015939612306035335
Trained batch 66 in epoch 14, gen_loss = 1.4305907256567656, disc_loss = 0.00016163094274381718
Trained batch 67 in epoch 14, gen_loss = 1.4304246972588932, disc_loss = 0.00016343311317006524
Trained batch 68 in epoch 14, gen_loss = 1.4304992392443228, disc_loss = 0.00016496546569228025
Trained batch 69 in epoch 14, gen_loss = 1.4314767565046038, disc_loss = 0.00016646122785459738
Trained batch 70 in epoch 14, gen_loss = 1.4308945142047507, disc_loss = 0.00016784015166758506
Trained batch 71 in epoch 14, gen_loss = 1.431092530488968, disc_loss = 0.00016898022482160336
Trained batch 72 in epoch 14, gen_loss = 1.4315034004106915, disc_loss = 0.00017004456533133434
Trained batch 73 in epoch 14, gen_loss = 1.4317015006735518, disc_loss = 0.000171123731913237
Trained batch 74 in epoch 14, gen_loss = 1.4317580938339234, disc_loss = 0.00017199489719738872
Trained batch 75 in epoch 14, gen_loss = 1.4311304923735166, disc_loss = 0.00017266088257441114
Trained batch 76 in epoch 14, gen_loss = 1.4301625273444436, disc_loss = 0.00017312425344633603
Trained batch 77 in epoch 14, gen_loss = 1.4298020524856372, disc_loss = 0.00017330718200798565
Trained batch 78 in epoch 14, gen_loss = 1.4297609827186488, disc_loss = 0.00017348132443450732
Trained batch 79 in epoch 14, gen_loss = 1.4296075448393821, disc_loss = 0.00017365966527904675
Trained batch 80 in epoch 14, gen_loss = 1.4293523673658017, disc_loss = 0.00017387067356016084
Trained batch 81 in epoch 14, gen_loss = 1.4298974828022282, disc_loss = 0.00017397181723137646
Trained batch 82 in epoch 14, gen_loss = 1.4299814830343407, disc_loss = 0.0001741690364899815
Trained batch 83 in epoch 14, gen_loss = 1.4295522698334284, disc_loss = 0.00017456186595241196
Trained batch 84 in epoch 14, gen_loss = 1.429465864686405, disc_loss = 0.0001752164115982048
Trained batch 85 in epoch 14, gen_loss = 1.4291558584501578, disc_loss = 0.00017619375678403358
Trained batch 86 in epoch 14, gen_loss = 1.428972186713383, disc_loss = 0.00017767967379433852
Trained batch 87 in epoch 14, gen_loss = 1.4288271150805734, disc_loss = 0.00017988583803426908
Trained batch 88 in epoch 14, gen_loss = 1.4286279718527632, disc_loss = 0.0001827110154204348
Trained batch 89 in epoch 14, gen_loss = 1.4290364940961202, disc_loss = 0.00018628161281715924
Trained batch 90 in epoch 14, gen_loss = 1.4290876205150898, disc_loss = 0.00019041077937619955
Trained batch 91 in epoch 14, gen_loss = 1.4288780274598494, disc_loss = 0.00019461427137170887
Trained batch 92 in epoch 14, gen_loss = 1.4288811324745097, disc_loss = 0.0001986283932637889
Trained batch 93 in epoch 14, gen_loss = 1.428341010783581, disc_loss = 0.0002023245241171606
Trained batch 94 in epoch 14, gen_loss = 1.4289011152167068, disc_loss = 0.00020585147036686786
Trained batch 95 in epoch 14, gen_loss = 1.4285189372797806, disc_loss = 0.0002095037826090144
Trained batch 96 in epoch 14, gen_loss = 1.4283043822062385, disc_loss = 0.00021323340032975785
Trained batch 97 in epoch 14, gen_loss = 1.4285187721252441, disc_loss = 0.00021671295990574659
Trained batch 98 in epoch 14, gen_loss = 1.4289959488493023, disc_loss = 0.00021938499651356563
Trained batch 99 in epoch 14, gen_loss = 1.4293504714965821, disc_loss = 0.0002211296311361366
Trained batch 100 in epoch 14, gen_loss = 1.4303146400073967, disc_loss = 0.00022188981965162312
Trained batch 101 in epoch 14, gen_loss = 1.430421796499514, disc_loss = 0.00022161888720053386
Trained batch 102 in epoch 14, gen_loss = 1.4307229958691643, disc_loss = 0.00022054882363378955
Trained batch 103 in epoch 14, gen_loss = 1.4307190225674555, disc_loss = 0.00021914678077686962
Trained batch 104 in epoch 14, gen_loss = 1.4309137957436697, disc_loss = 0.00021774434007100008
Trained batch 105 in epoch 14, gen_loss = 1.430940589814816, disc_loss = 0.00021645306158049761
Trained batch 106 in epoch 14, gen_loss = 1.4304326806112984, disc_loss = 0.00021509480667131884
Trained batch 107 in epoch 14, gen_loss = 1.43074835340182, disc_loss = 0.00021378976436136764
Trained batch 108 in epoch 14, gen_loss = 1.4310476222169508, disc_loss = 0.00021254189587876398
Trained batch 109 in epoch 14, gen_loss = 1.431455444205891, disc_loss = 0.00021132820861980277
Trained batch 110 in epoch 14, gen_loss = 1.4314069909018439, disc_loss = 0.00021014613125484798
Trained batch 111 in epoch 14, gen_loss = 1.431747847369739, disc_loss = 0.00020903367927920563
Trained batch 112 in epoch 14, gen_loss = 1.4315437700896136, disc_loss = 0.00020802985815371517
Trained batch 113 in epoch 14, gen_loss = 1.4317965863043802, disc_loss = 0.00020714929514884206
Trained batch 114 in epoch 14, gen_loss = 1.4320890074190886, disc_loss = 0.00020641072443812965
Trained batch 115 in epoch 14, gen_loss = 1.4312860081935752, disc_loss = 0.00020583192640358526
Trained batch 116 in epoch 14, gen_loss = 1.4308568300345006, disc_loss = 0.00020543911681997063
Trained batch 117 in epoch 14, gen_loss = 1.4304207674527571, disc_loss = 0.00020536487385994652
Trained batch 118 in epoch 14, gen_loss = 1.4300327691711296, disc_loss = 0.00020571131281336543
Trained batch 119 in epoch 14, gen_loss = 1.4302135874827704, disc_loss = 0.0002065122606836667
Trained batch 120 in epoch 14, gen_loss = 1.4298628332201115, disc_loss = 0.00020748612506162138
Trained batch 121 in epoch 14, gen_loss = 1.4303224682807922, disc_loss = 0.00020858089523184778
Trained batch 122 in epoch 14, gen_loss = 1.4308780935721668, disc_loss = 0.00020972458254456012
Trained batch 123 in epoch 14, gen_loss = 1.429976814216183, disc_loss = 0.00021073756887480773
Trained batch 124 in epoch 14, gen_loss = 1.4304316930770875, disc_loss = 0.00021167729762964883
Trained batch 125 in epoch 14, gen_loss = 1.4300643054265825, disc_loss = 0.0002126511941270788
Trained batch 126 in epoch 14, gen_loss = 1.4300212963359562, disc_loss = 0.0002136224120047299
Trained batch 127 in epoch 14, gen_loss = 1.4299119841307402, disc_loss = 0.00021461314409521037
Trained batch 128 in epoch 14, gen_loss = 1.4294605162716651, disc_loss = 0.00021563201787716405
Trained batch 129 in epoch 14, gen_loss = 1.4289768567452064, disc_loss = 0.00021667560898864534
Trained batch 130 in epoch 14, gen_loss = 1.4293307338962118, disc_loss = 0.00021777869498677986
Trained batch 131 in epoch 14, gen_loss = 1.4297641696351948, disc_loss = 0.00021888589333574407
Trained batch 132 in epoch 14, gen_loss = 1.4299579509218832, disc_loss = 0.00021987656736768314
Trained batch 133 in epoch 14, gen_loss = 1.4298912251173561, disc_loss = 0.00022069664373702835
Trained batch 134 in epoch 14, gen_loss = 1.4306391698342782, disc_loss = 0.00022142989190696325
Trained batch 135 in epoch 14, gen_loss = 1.4303035885095596, disc_loss = 0.00022224301437745453
Trained batch 136 in epoch 14, gen_loss = 1.4306134281367282, disc_loss = 0.00022294801625573539
Trained batch 137 in epoch 14, gen_loss = 1.430231373379196, disc_loss = 0.00022331150548648176
Trained batch 138 in epoch 14, gen_loss = 1.4306049183975877, disc_loss = 0.00022337500043334807
Trained batch 139 in epoch 14, gen_loss = 1.4303037328379495, disc_loss = 0.0002233308759969077
Trained batch 140 in epoch 14, gen_loss = 1.430169568839648, disc_loss = 0.0002231113855441758
Trained batch 141 in epoch 14, gen_loss = 1.430080835248383, disc_loss = 0.0002226075714236391
Trained batch 142 in epoch 14, gen_loss = 1.429910986573546, disc_loss = 0.000222039756523258
Trained batch 143 in epoch 14, gen_loss = 1.4298449688487582, disc_loss = 0.00022161858904231244
Trained batch 144 in epoch 14, gen_loss = 1.4302174395528333, disc_loss = 0.0002213359365073145
Trained batch 145 in epoch 14, gen_loss = 1.4301946889864254, disc_loss = 0.0002209790179209723
Trained batch 146 in epoch 14, gen_loss = 1.430700148854937, disc_loss = 0.00022046521231694445
Trained batch 147 in epoch 14, gen_loss = 1.4303086641672496, disc_loss = 0.00021984449112760312
Trained batch 148 in epoch 14, gen_loss = 1.4305903159531972, disc_loss = 0.00021912143005612119
Trained batch 149 in epoch 14, gen_loss = 1.4306281558672587, disc_loss = 0.00021826019755584033
Trained batch 150 in epoch 14, gen_loss = 1.430582869921299, disc_loss = 0.00021726095925886276
Trained batch 151 in epoch 14, gen_loss = 1.4301938987091969, disc_loss = 0.0002161923097159352
Trained batch 152 in epoch 14, gen_loss = 1.4303587753009173, disc_loss = 0.00021507102128987966
Trained batch 153 in epoch 14, gen_loss = 1.430244482182837, disc_loss = 0.00021392746894925005
Trained batch 154 in epoch 14, gen_loss = 1.430256002180038, disc_loss = 0.00021277477914531296
Trained batch 155 in epoch 14, gen_loss = 1.4300334805097334, disc_loss = 0.00021180981926031213
Trained batch 156 in epoch 14, gen_loss = 1.4302451200545974, disc_loss = 0.00021087483563263912
Trained batch 157 in epoch 14, gen_loss = 1.4300705224652834, disc_loss = 0.00021003714161302417
Trained batch 158 in epoch 14, gen_loss = 1.4297590758065757, disc_loss = 0.00020923740716022148
Trained batch 159 in epoch 14, gen_loss = 1.429229561239481, disc_loss = 0.00020843148961375847
Trained batch 160 in epoch 14, gen_loss = 1.429170909135238, disc_loss = 0.0002075424442031227
Trained batch 161 in epoch 14, gen_loss = 1.4296041513666695, disc_loss = 0.00020661824578663656
Trained batch 162 in epoch 14, gen_loss = 1.4296021651636603, disc_loss = 0.0002057024938742876
Trained batch 163 in epoch 14, gen_loss = 1.4297313944595615, disc_loss = 0.0002049167251687145
Trained batch 164 in epoch 14, gen_loss = 1.4299502596710667, disc_loss = 0.00020422805149185783
Trained batch 165 in epoch 14, gen_loss = 1.4298458760043224, disc_loss = 0.00020362433589257142
Trained batch 166 in epoch 14, gen_loss = 1.4295904907637726, disc_loss = 0.00020305112237459282
Trained batch 167 in epoch 14, gen_loss = 1.4294414009366716, disc_loss = 0.00020249682711437345
Trained batch 168 in epoch 14, gen_loss = 1.4295609815586248, disc_loss = 0.0002020315576093988
Trained batch 169 in epoch 14, gen_loss = 1.429832215168897, disc_loss = 0.00020163604255204145
Trained batch 170 in epoch 14, gen_loss = 1.4299129031554998, disc_loss = 0.00020142180573846057
Trained batch 171 in epoch 14, gen_loss = 1.4297697356967038, disc_loss = 0.00020139114941378276
Trained batch 172 in epoch 14, gen_loss = 1.4296698322185892, disc_loss = 0.00020142452726732788
Trained batch 173 in epoch 14, gen_loss = 1.4299693580331474, disc_loss = 0.00020149731041793978
Trained batch 174 in epoch 14, gen_loss = 1.429810790334429, disc_loss = 0.00020156596072151193
Trained batch 175 in epoch 14, gen_loss = 1.4299244061112404, disc_loss = 0.0002016534227467756
Trained batch 176 in epoch 14, gen_loss = 1.4294122316069522, disc_loss = 0.00020185352911801724
Trained batch 177 in epoch 14, gen_loss = 1.429920933219824, disc_loss = 0.00020214009549654498
Trained batch 178 in epoch 14, gen_loss = 1.429677916638678, disc_loss = 0.00020239474705495877
Trained batch 179 in epoch 14, gen_loss = 1.4299022614955903, disc_loss = 0.0002026586821658485
Trained batch 180 in epoch 14, gen_loss = 1.4297455812686055, disc_loss = 0.00020293680169858883
Trained batch 181 in epoch 14, gen_loss = 1.4298245651381356, disc_loss = 0.00020319427554508425
Trained batch 182 in epoch 14, gen_loss = 1.4293028331193767, disc_loss = 0.00020340458361770388
Trained batch 183 in epoch 14, gen_loss = 1.4295825776846514, disc_loss = 0.00020351519750598212
Trained batch 184 in epoch 14, gen_loss = 1.4293964141124003, disc_loss = 0.00020361652084928308
Trained batch 185 in epoch 14, gen_loss = 1.4294153272464711, disc_loss = 0.00020375970490677382
Trained batch 186 in epoch 14, gen_loss = 1.4293669188086362, disc_loss = 0.0002040307267561535
Trained batch 187 in epoch 14, gen_loss = 1.4294865327946684, disc_loss = 0.00020444648017725373
Trained batch 188 in epoch 14, gen_loss = 1.4294551882163558, disc_loss = 0.0002051261276753235
Trained batch 189 in epoch 14, gen_loss = 1.4294806417665984, disc_loss = 0.00020593915879113699
Trained batch 190 in epoch 14, gen_loss = 1.4289520922755696, disc_loss = 0.00020656624247554045
Trained batch 191 in epoch 14, gen_loss = 1.4289454625298579, disc_loss = 0.0002068774567002644
Trained batch 192 in epoch 14, gen_loss = 1.4289214771646293, disc_loss = 0.00020690964715232
Trained batch 193 in epoch 14, gen_loss = 1.4290492079921604, disc_loss = 0.00020686326242116827
Trained batch 194 in epoch 14, gen_loss = 1.4289862755017402, disc_loss = 0.0002068224089900748
Trained batch 195 in epoch 14, gen_loss = 1.429367618901389, disc_loss = 0.00020677103584974395
Trained batch 196 in epoch 14, gen_loss = 1.42907915986734, disc_loss = 0.000206671953898604
Trained batch 197 in epoch 14, gen_loss = 1.4289642169017984, disc_loss = 0.00020647169760489516
Trained batch 198 in epoch 14, gen_loss = 1.429354577208284, disc_loss = 0.00020615341189790087
Trained batch 199 in epoch 14, gen_loss = 1.429658887386322, disc_loss = 0.00020576176430040505
Trained batch 200 in epoch 14, gen_loss = 1.4293049888231268, disc_loss = 0.00020535316159578032
Trained batch 201 in epoch 14, gen_loss = 1.429192089798427, disc_loss = 0.00020496808270529596
Trained batch 202 in epoch 14, gen_loss = 1.4293928375385079, disc_loss = 0.00020469253097965927
Trained batch 203 in epoch 14, gen_loss = 1.4292360234494303, disc_loss = 0.00020454687040125696
Trained batch 204 in epoch 14, gen_loss = 1.4290890495951583, disc_loss = 0.00020455690285349945
Trained batch 205 in epoch 14, gen_loss = 1.4288749972593437, disc_loss = 0.000204639368675292
Trained batch 206 in epoch 14, gen_loss = 1.4290556965242838, disc_loss = 0.0002048577023540727
Trained batch 207 in epoch 14, gen_loss = 1.429124279664113, disc_loss = 0.00020518842246439398
Trained batch 208 in epoch 14, gen_loss = 1.4290402061060856, disc_loss = 0.00020559841445836564
Trained batch 209 in epoch 14, gen_loss = 1.4291284600893657, disc_loss = 0.0002060661711203422
Trained batch 210 in epoch 14, gen_loss = 1.4290627653564887, disc_loss = 0.00020654107973926318
Trained batch 211 in epoch 14, gen_loss = 1.4290167869261976, disc_loss = 0.0002071091791703849
Trained batch 212 in epoch 14, gen_loss = 1.4292282229857824, disc_loss = 0.00020778561364848412
Trained batch 213 in epoch 14, gen_loss = 1.4290162436315947, disc_loss = 0.00020862738246905452
Trained batch 214 in epoch 14, gen_loss = 1.4289411317470462, disc_loss = 0.0002098094998875113
Trained batch 215 in epoch 14, gen_loss = 1.4285700249451179, disc_loss = 0.0002113970856077719
Trained batch 216 in epoch 14, gen_loss = 1.4288896728770524, disc_loss = 0.00021328158564769023
Trained batch 217 in epoch 14, gen_loss = 1.4287651782735773, disc_loss = 0.0002152997435795767
Trained batch 218 in epoch 14, gen_loss = 1.4288654076998637, disc_loss = 0.00021747055698184033
Trained batch 219 in epoch 14, gen_loss = 1.4293127488006245, disc_loss = 0.00022003313080693425
Trained batch 220 in epoch 14, gen_loss = 1.4295175167230458, disc_loss = 0.00022308005311587464
Trained batch 221 in epoch 14, gen_loss = 1.4297013986218083, disc_loss = 0.00022649475674067313
Trained batch 222 in epoch 14, gen_loss = 1.4297387658747858, disc_loss = 0.0002299944810530655
Trained batch 223 in epoch 14, gen_loss = 1.4296133677874292, disc_loss = 0.00023315244854010025
Trained batch 224 in epoch 14, gen_loss = 1.429714487393697, disc_loss = 0.00023588538499704252
Trained batch 225 in epoch 14, gen_loss = 1.4294383198814054, disc_loss = 0.00023830768648912075
Trained batch 226 in epoch 14, gen_loss = 1.4299206964770077, disc_loss = 0.00024054126934782246
Trained batch 227 in epoch 14, gen_loss = 1.4298770087852812, disc_loss = 0.00024249687250407428
Trained batch 228 in epoch 14, gen_loss = 1.4301050266324173, disc_loss = 0.00024415590076180637
Trained batch 229 in epoch 14, gen_loss = 1.430168044567108, disc_loss = 0.00024548434170276815
Trained batch 230 in epoch 14, gen_loss = 1.4297863688819852, disc_loss = 0.00024653485721910524
Trained batch 231 in epoch 14, gen_loss = 1.4298746154226105, disc_loss = 0.0002473816998801716
Trained batch 232 in epoch 14, gen_loss = 1.4300666039593741, disc_loss = 0.0002482945585744296
Trained batch 233 in epoch 14, gen_loss = 1.4297234074682252, disc_loss = 0.0002494443459341772
Trained batch 234 in epoch 14, gen_loss = 1.4298749020759096, disc_loss = 0.00025084050368527546
Trained batch 235 in epoch 14, gen_loss = 1.4300589611974812, disc_loss = 0.0002524256139576348
Trained batch 236 in epoch 14, gen_loss = 1.4302066358332897, disc_loss = 0.0002540392906897218
Trained batch 237 in epoch 14, gen_loss = 1.430099272928318, disc_loss = 0.00025544531024383976
Trained batch 238 in epoch 14, gen_loss = 1.4300882502081005, disc_loss = 0.0002565617831039075
Trained batch 239 in epoch 14, gen_loss = 1.4302239939570427, disc_loss = 0.00025735207642962145
Trained batch 240 in epoch 14, gen_loss = 1.430030704039261, disc_loss = 0.0002578107443424637
Trained batch 241 in epoch 14, gen_loss = 1.430033755203909, disc_loss = 0.00025796797240782175
Trained batch 242 in epoch 14, gen_loss = 1.4303059695679465, disc_loss = 0.00025791613392986033
Trained batch 243 in epoch 14, gen_loss = 1.4305116553775599, disc_loss = 0.00025772573763922573
Trained batch 244 in epoch 14, gen_loss = 1.430192094919633, disc_loss = 0.0002574404323240742
Trained batch 245 in epoch 14, gen_loss = 1.429973697274681, disc_loss = 0.00025709655543560225
Trained batch 246 in epoch 14, gen_loss = 1.4300946668092056, disc_loss = 0.00025672042979915373
Trained batch 247 in epoch 14, gen_loss = 1.4301578791872147, disc_loss = 0.00025629885238876956
Trained batch 248 in epoch 14, gen_loss = 1.43030379048313, disc_loss = 0.0002558607709534227
Trained batch 249 in epoch 14, gen_loss = 1.4302674670219422, disc_loss = 0.00025541423697723073
Trained batch 250 in epoch 14, gen_loss = 1.4304961056348338, disc_loss = 0.0002549895610306894
Trained batch 251 in epoch 14, gen_loss = 1.430365484858316, disc_loss = 0.0002545804592724409
Trained batch 252 in epoch 14, gen_loss = 1.4304131208201172, disc_loss = 0.00025413621208039683
Trained batch 253 in epoch 14, gen_loss = 1.4305403899020097, disc_loss = 0.00025364113601491106
Trained batch 254 in epoch 14, gen_loss = 1.4303318818410238, disc_loss = 0.0002531491841449786
Trained batch 255 in epoch 14, gen_loss = 1.430168351624161, disc_loss = 0.00025270588031389707
Trained batch 256 in epoch 14, gen_loss = 1.4302863453148869, disc_loss = 0.0002522815025347223
Trained batch 257 in epoch 14, gen_loss = 1.4304008299066115, disc_loss = 0.0002518967374398503
Trained batch 258 in epoch 14, gen_loss = 1.4307419084674142, disc_loss = 0.00025152585974401833
Trained batch 259 in epoch 14, gen_loss = 1.430757053081806, disc_loss = 0.0002511292721185153
Trained batch 260 in epoch 14, gen_loss = 1.4305245574863477, disc_loss = 0.0002507594486759169
Trained batch 261 in epoch 14, gen_loss = 1.429893956384586, disc_loss = 0.00025041086520583776
Trained batch 262 in epoch 14, gen_loss = 1.430085848946082, disc_loss = 0.00025004905448454526
Trained batch 263 in epoch 14, gen_loss = 1.43021507786982, disc_loss = 0.0002496693752728981
Trained batch 264 in epoch 14, gen_loss = 1.4300741771482073, disc_loss = 0.00024927750291337946
Trained batch 265 in epoch 14, gen_loss = 1.4299056090806659, disc_loss = 0.00024885644972555453
Trained batch 266 in epoch 14, gen_loss = 1.429746324203434, disc_loss = 0.0002483788819190931
Trained batch 267 in epoch 14, gen_loss = 1.429624531251281, disc_loss = 0.00024787039864580704
Trained batch 268 in epoch 14, gen_loss = 1.4297844397534225, disc_loss = 0.00024732828716276606
Trained batch 269 in epoch 14, gen_loss = 1.4297191505078917, disc_loss = 0.0002467608442034193
Trained batch 270 in epoch 14, gen_loss = 1.4299419154980086, disc_loss = 0.0002461544458350129
Trained batch 271 in epoch 14, gen_loss = 1.4297100533457363, disc_loss = 0.00024568302898628376
Trained batch 272 in epoch 14, gen_loss = 1.4296133588085245, disc_loss = 0.0002452955464406055
Trained batch 273 in epoch 14, gen_loss = 1.4296193370853898, disc_loss = 0.0002448269263029704
Trained batch 274 in epoch 14, gen_loss = 1.4295516460592097, disc_loss = 0.000244241063139105
Trained batch 275 in epoch 14, gen_loss = 1.429588159357292, disc_loss = 0.00024359721449044352
Trained batch 276 in epoch 14, gen_loss = 1.4295078645114003, disc_loss = 0.0002429195649806109
Trained batch 277 in epoch 14, gen_loss = 1.4294259063631511, disc_loss = 0.0002422243416613586
Trained batch 278 in epoch 14, gen_loss = 1.4295905469566264, disc_loss = 0.00024151385889948165
Trained batch 279 in epoch 14, gen_loss = 1.4297950791461127, disc_loss = 0.00024076854329645617
Trained batch 280 in epoch 14, gen_loss = 1.4297905753091562, disc_loss = 0.000239996214970421
Trained batch 281 in epoch 14, gen_loss = 1.4297536095828876, disc_loss = 0.00023922515653103924
Trained batch 282 in epoch 14, gen_loss = 1.4297461716109368, disc_loss = 0.0002384894351406449
Trained batch 283 in epoch 14, gen_loss = 1.4298856438885272, disc_loss = 0.0002377866118018881
Trained batch 284 in epoch 14, gen_loss = 1.429741208595142, disc_loss = 0.00023711052953761903
Trained batch 285 in epoch 14, gen_loss = 1.4295026497407393, disc_loss = 0.00023646615070876603
Trained batch 286 in epoch 14, gen_loss = 1.4298258467418392, disc_loss = 0.00023589612830068044
Trained batch 287 in epoch 14, gen_loss = 1.43001067555613, disc_loss = 0.00023537536012301844
Trained batch 288 in epoch 14, gen_loss = 1.4301075514625101, disc_loss = 0.00023480647366268763
Trained batch 289 in epoch 14, gen_loss = 1.4296940803527831, disc_loss = 0.00023419650842070356
Trained batch 290 in epoch 14, gen_loss = 1.429529197846901, disc_loss = 0.00023356342068471292
Trained batch 291 in epoch 14, gen_loss = 1.429459465693121, disc_loss = 0.0002329450182689271
Trained batch 292 in epoch 14, gen_loss = 1.4295924393390227, disc_loss = 0.0002323392013517175
Trained batch 293 in epoch 14, gen_loss = 1.429637774318254, disc_loss = 0.00023176409660267952
Trained batch 294 in epoch 14, gen_loss = 1.4293689129716258, disc_loss = 0.0002312366910731633
Trained batch 295 in epoch 14, gen_loss = 1.4291489502868138, disc_loss = 0.0002307887700005046
Trained batch 296 in epoch 14, gen_loss = 1.4294026584336252, disc_loss = 0.00023043172923004903
Trained batch 297 in epoch 14, gen_loss = 1.4294073893719872, disc_loss = 0.00023019968263889685
Trained batch 298 in epoch 14, gen_loss = 1.4292478417871788, disc_loss = 0.00023011617578052524
Trained batch 299 in epoch 14, gen_loss = 1.4290297389030457, disc_loss = 0.0002301824389360263
Trained batch 300 in epoch 14, gen_loss = 1.4290399963277518, disc_loss = 0.00023039453079163228
Trained batch 301 in epoch 14, gen_loss = 1.42908788595768, disc_loss = 0.00023070907652995238
Trained batch 302 in epoch 14, gen_loss = 1.428937526425906, disc_loss = 0.0002310772194772407
Trained batch 303 in epoch 14, gen_loss = 1.428991036195504, disc_loss = 0.0002314382039745205
Trained batch 304 in epoch 14, gen_loss = 1.4286747846447054, disc_loss = 0.00023183903956764805
Trained batch 305 in epoch 14, gen_loss = 1.4286231312876434, disc_loss = 0.00023232878933995856
Trained batch 306 in epoch 14, gen_loss = 1.4286541309729461, disc_loss = 0.00023283523349146396
Trained batch 307 in epoch 14, gen_loss = 1.4285380186198593, disc_loss = 0.00023328507007124255
Trained batch 308 in epoch 14, gen_loss = 1.428324544314042, disc_loss = 0.00023369304229466556
Trained batch 309 in epoch 14, gen_loss = 1.4282939576333569, disc_loss = 0.00023406327655398093
Trained batch 310 in epoch 14, gen_loss = 1.4283523318085256, disc_loss = 0.00023433031964460553
Trained batch 311 in epoch 14, gen_loss = 1.4284578221730697, disc_loss = 0.00023445845882190787
Trained batch 312 in epoch 14, gen_loss = 1.4285882444808278, disc_loss = 0.00023447092443850775
Trained batch 313 in epoch 14, gen_loss = 1.4287827166782063, disc_loss = 0.00023434044861883165
Trained batch 314 in epoch 14, gen_loss = 1.4286509597112262, disc_loss = 0.00023410718848546302
Trained batch 315 in epoch 14, gen_loss = 1.428668518232394, disc_loss = 0.0002338531824799374
Trained batch 316 in epoch 14, gen_loss = 1.4288076583519342, disc_loss = 0.000233600300613057
Trained batch 317 in epoch 14, gen_loss = 1.4287018179893494, disc_loss = 0.00023333946533829526
Trained batch 318 in epoch 14, gen_loss = 1.4286054903436978, disc_loss = 0.00023308375675924967
Trained batch 319 in epoch 14, gen_loss = 1.4285787880420684, disc_loss = 0.00023285891949171856
Trained batch 320 in epoch 14, gen_loss = 1.4284534929697388, disc_loss = 0.00023271050477573414
Trained batch 321 in epoch 14, gen_loss = 1.428419023567105, disc_loss = 0.00023262418452652117
Trained batch 322 in epoch 14, gen_loss = 1.4285907911442381, disc_loss = 0.00023265547221485054
Trained batch 323 in epoch 14, gen_loss = 1.42870913648311, disc_loss = 0.00023283029127520017
Trained batch 324 in epoch 14, gen_loss = 1.428624322964595, disc_loss = 0.00023314305743462262
Trained batch 325 in epoch 14, gen_loss = 1.42847659214874, disc_loss = 0.00023350604661667872
Trained batch 326 in epoch 14, gen_loss = 1.4283439919853793, disc_loss = 0.00023390920474295452
Trained batch 327 in epoch 14, gen_loss = 1.428647236489668, disc_loss = 0.00023435336672220018
Trained batch 328 in epoch 14, gen_loss = 1.4286808018264074, disc_loss = 0.00023479804632688822
Trained batch 329 in epoch 14, gen_loss = 1.428555957476298, disc_loss = 0.00023519088802762174
Trained batch 330 in epoch 14, gen_loss = 1.428462441954368, disc_loss = 0.00023551650349589928
Trained batch 331 in epoch 14, gen_loss = 1.4283028367054031, disc_loss = 0.0002357765174291485
Trained batch 332 in epoch 14, gen_loss = 1.4282493154565852, disc_loss = 0.0002359781631478493
Trained batch 333 in epoch 14, gen_loss = 1.4280291810007153, disc_loss = 0.00023616156921818542
Trained batch 334 in epoch 14, gen_loss = 1.4282017732734111, disc_loss = 0.00023631774343649246
Trained batch 335 in epoch 14, gen_loss = 1.4279419002788407, disc_loss = 0.0002364362028835049
Trained batch 336 in epoch 14, gen_loss = 1.4279418631901726, disc_loss = 0.00023649137147651496
Trained batch 337 in epoch 14, gen_loss = 1.4279450830623244, disc_loss = 0.00023643235487978115
Trained batch 338 in epoch 14, gen_loss = 1.427954616448169, disc_loss = 0.00023625334899278103
Trained batch 339 in epoch 14, gen_loss = 1.4279224553528953, disc_loss = 0.00023598470409470952
Trained batch 340 in epoch 14, gen_loss = 1.427850666283862, disc_loss = 0.0002356279279875038
Trained batch 341 in epoch 14, gen_loss = 1.427814074775629, disc_loss = 0.00023521998176960157
Trained batch 342 in epoch 14, gen_loss = 1.4277171688941754, disc_loss = 0.00023479238985951124
Trained batch 343 in epoch 14, gen_loss = 1.4276511350343393, disc_loss = 0.00023437950463884653
Trained batch 344 in epoch 14, gen_loss = 1.42769949954489, disc_loss = 0.00023399491726287534
Trained batch 345 in epoch 14, gen_loss = 1.4276823074142369, disc_loss = 0.00023363861003212666
Trained batch 346 in epoch 14, gen_loss = 1.4278118957360126, disc_loss = 0.0002333379943435911
Trained batch 347 in epoch 14, gen_loss = 1.4279444330725177, disc_loss = 0.00023310584651619723
Trained batch 348 in epoch 14, gen_loss = 1.428088039928316, disc_loss = 0.0002330015977714671
Trained batch 349 in epoch 14, gen_loss = 1.4279348829814367, disc_loss = 0.0002330342440421061
Trained batch 350 in epoch 14, gen_loss = 1.4279074818320423, disc_loss = 0.00023318842007850557
Trained batch 351 in epoch 14, gen_loss = 1.4282274408773943, disc_loss = 0.00023345204926334355
Trained batch 352 in epoch 14, gen_loss = 1.4280607646315362, disc_loss = 0.00023385960996098534
Trained batch 353 in epoch 14, gen_loss = 1.4280226200313892, disc_loss = 0.00023440444575154715
Trained batch 354 in epoch 14, gen_loss = 1.4280401998842267, disc_loss = 0.00023503910524083602
Trained batch 355 in epoch 14, gen_loss = 1.4281161759006844, disc_loss = 0.00023581121529766758
Trained batch 356 in epoch 14, gen_loss = 1.428030836482008, disc_loss = 0.00023675028979069037
Trained batch 357 in epoch 14, gen_loss = 1.4281077634688861, disc_loss = 0.00023778750185470042
Trained batch 358 in epoch 14, gen_loss = 1.428119117835106, disc_loss = 0.00023892018983140913
Trained batch 359 in epoch 14, gen_loss = 1.428273484441969, disc_loss = 0.00024017403966354324
Trained batch 360 in epoch 14, gen_loss = 1.4281658673880833, disc_loss = 0.0002415495841471908
Trained batch 361 in epoch 14, gen_loss = 1.4282165400231082, disc_loss = 0.00024298688207917977
Trained batch 362 in epoch 14, gen_loss = 1.4281255702998683, disc_loss = 0.0002443971047608455
Trained batch 363 in epoch 14, gen_loss = 1.4281005751300644, disc_loss = 0.0002457492026343851
Trained batch 364 in epoch 14, gen_loss = 1.4278757261903319, disc_loss = 0.00024693809280830617
Trained batch 365 in epoch 14, gen_loss = 1.4278714327864308, disc_loss = 0.00024794199363568025
Trained batch 366 in epoch 14, gen_loss = 1.4278938640365808, disc_loss = 0.00024870862865419895
Trained batch 367 in epoch 14, gen_loss = 1.4278620996552964, disc_loss = 0.0002492556944300462
Trained batch 368 in epoch 14, gen_loss = 1.4279107449823603, disc_loss = 0.00024966039490921684
Trained batch 369 in epoch 14, gen_loss = 1.4278684567760778, disc_loss = 0.0002499257487805743
Trained batch 370 in epoch 14, gen_loss = 1.4278319167962292, disc_loss = 0.000250023671297932
Trained batch 371 in epoch 14, gen_loss = 1.4278289627644323, disc_loss = 0.0002499740103890109
Trained batch 372 in epoch 14, gen_loss = 1.427681365856856, disc_loss = 0.0002498389625221637
Trained batch 373 in epoch 14, gen_loss = 1.427782686955151, disc_loss = 0.0002496318875711298
Trained batch 374 in epoch 14, gen_loss = 1.4276662349700928, disc_loss = 0.0002493389657562754
Trained batch 375 in epoch 14, gen_loss = 1.4277373913754807, disc_loss = 0.0002489741967381517
Trained batch 376 in epoch 14, gen_loss = 1.4276643839691932, disc_loss = 0.00024856232783986585
Trained batch 377 in epoch 14, gen_loss = 1.4277617893521748, disc_loss = 0.0002481115913084337
Trained batch 378 in epoch 14, gen_loss = 1.4277022850544911, disc_loss = 0.0002476549150521583
Trained batch 379 in epoch 14, gen_loss = 1.4277774616291647, disc_loss = 0.0002471851489309828
Trained batch 380 in epoch 14, gen_loss = 1.4278060032001005, disc_loss = 0.00024669078596393406
Trained batch 381 in epoch 14, gen_loss = 1.4278171571137392, disc_loss = 0.0002461679737161021
Trained batch 382 in epoch 14, gen_loss = 1.4278617667778353, disc_loss = 0.0002456273873588593
Trained batch 383 in epoch 14, gen_loss = 1.4280297411605716, disc_loss = 0.0002450878174708275
Trained batch 384 in epoch 14, gen_loss = 1.4278913284276986, disc_loss = 0.00024454815967300266
Trained batch 385 in epoch 14, gen_loss = 1.4276906014106434, disc_loss = 0.00024402589278058582
Trained batch 386 in epoch 14, gen_loss = 1.4276394345039545, disc_loss = 0.00024349607773322505
Trained batch 387 in epoch 14, gen_loss = 1.4276060406694706, disc_loss = 0.0002429802358240044
Trained batch 388 in epoch 14, gen_loss = 1.4274092783964691, disc_loss = 0.00024247566805869655
Trained batch 389 in epoch 14, gen_loss = 1.427303851262117, disc_loss = 0.00024201102583342268
Trained batch 390 in epoch 14, gen_loss = 1.4272662248757795, disc_loss = 0.0002415940624723822
Trained batch 391 in epoch 14, gen_loss = 1.4272865887199129, disc_loss = 0.0002412475668353757
Trained batch 392 in epoch 14, gen_loss = 1.427206936986695, disc_loss = 0.00024094545094803765
Trained batch 393 in epoch 14, gen_loss = 1.4272715240565654, disc_loss = 0.00024062876116954496
Trained batch 394 in epoch 14, gen_loss = 1.4271851219708407, disc_loss = 0.00024029503719582033
Trained batch 395 in epoch 14, gen_loss = 1.4272296260101627, disc_loss = 0.0002399699690824785
Trained batch 396 in epoch 14, gen_loss = 1.4271755362638, disc_loss = 0.00023965213818351566
Trained batch 397 in epoch 14, gen_loss = 1.42729731870057, disc_loss = 0.0002393500765825209
Trained batch 398 in epoch 14, gen_loss = 1.4274083325139861, disc_loss = 0.00023905502121922102
Trained batch 399 in epoch 14, gen_loss = 1.4274679434299469, disc_loss = 0.00023874231451372906
Trained batch 400 in epoch 14, gen_loss = 1.427528241328765, disc_loss = 0.00023840766386780713
Trained batch 401 in epoch 14, gen_loss = 1.4274819347988907, disc_loss = 0.00023804804389224567
Trained batch 402 in epoch 14, gen_loss = 1.427347854112573, disc_loss = 0.00023768906385044766
Trained batch 403 in epoch 14, gen_loss = 1.4274173744834295, disc_loss = 0.00023733846883980804
Trained batch 404 in epoch 14, gen_loss = 1.4273205091923844, disc_loss = 0.00023701285775772435
Trained batch 405 in epoch 14, gen_loss = 1.4271623777051277, disc_loss = 0.0002367585993269682
Trained batch 406 in epoch 14, gen_loss = 1.426949448608942, disc_loss = 0.00023655464268437958
Trained batch 407 in epoch 14, gen_loss = 1.4271996702049292, disc_loss = 0.0002363816230778563
Trained batch 408 in epoch 14, gen_loss = 1.4272698962601007, disc_loss = 0.00023621083726623428
Trained batch 409 in epoch 14, gen_loss = 1.4274192690849303, disc_loss = 0.0002360018708714051
Trained batch 410 in epoch 14, gen_loss = 1.4274018222688178, disc_loss = 0.00023575448367166573
Trained batch 411 in epoch 14, gen_loss = 1.427372148314726, disc_loss = 0.00023546778446014517
Trained batch 412 in epoch 14, gen_loss = 1.4272621665104828, disc_loss = 0.0002351545476163405
Trained batch 413 in epoch 14, gen_loss = 1.427188067332558, disc_loss = 0.00023481583648302494
Trained batch 414 in epoch 14, gen_loss = 1.4269983731120466, disc_loss = 0.00023445266914162615
Trained batch 415 in epoch 14, gen_loss = 1.4269624891189427, disc_loss = 0.00023409160013880654
Trained batch 416 in epoch 14, gen_loss = 1.4270635497369926, disc_loss = 0.0002337468129126115
Trained batch 417 in epoch 14, gen_loss = 1.426940755410628, disc_loss = 0.0002334114691551299
Trained batch 418 in epoch 14, gen_loss = 1.4269448157426565, disc_loss = 0.000233069858325188
Trained batch 419 in epoch 14, gen_loss = 1.4268026144731611, disc_loss = 0.0002327545819449976
Trained batch 420 in epoch 14, gen_loss = 1.4268091636712081, disc_loss = 0.00023247698784454376
Trained batch 421 in epoch 14, gen_loss = 1.4266796770254018, disc_loss = 0.00023222346255127882
Trained batch 422 in epoch 14, gen_loss = 1.4264786525257371, disc_loss = 0.00023198246199344
Trained batch 423 in epoch 14, gen_loss = 1.4263758046447106, disc_loss = 0.00023171507693816993
Trained batch 424 in epoch 14, gen_loss = 1.4262375567941106, disc_loss = 0.0002314844923624632
Trained batch 425 in epoch 14, gen_loss = 1.4263418672230321, disc_loss = 0.00023123605287038914
Trained batch 426 in epoch 14, gen_loss = 1.4262597946149125, disc_loss = 0.00023101607182157767
Trained batch 427 in epoch 14, gen_loss = 1.4261895100647044, disc_loss = 0.0002308156729915052
Trained batch 428 in epoch 14, gen_loss = 1.4263404793950505, disc_loss = 0.00023060991147896416
Trained batch 429 in epoch 14, gen_loss = 1.4263887352721636, disc_loss = 0.00023040311805447726
Trained batch 430 in epoch 14, gen_loss = 1.4265285179952458, disc_loss = 0.00023023360850970938
Trained batch 431 in epoch 14, gen_loss = 1.4266086507726599, disc_loss = 0.00023015355643312633
Trained batch 432 in epoch 14, gen_loss = 1.4266153615286388, disc_loss = 0.000230207349991791
Trained batch 433 in epoch 14, gen_loss = 1.4265251854597698, disc_loss = 0.0002303079661372314
Trained batch 434 in epoch 14, gen_loss = 1.4264722355480852, disc_loss = 0.00023034468249534258
Trained batch 435 in epoch 14, gen_loss = 1.4265811790566925, disc_loss = 0.00023032896425579023
Trained batch 436 in epoch 14, gen_loss = 1.4266935248669552, disc_loss = 0.00023030590343610618
Trained batch 437 in epoch 14, gen_loss = 1.4266715316467633, disc_loss = 0.00023028879320204044
Trained batch 438 in epoch 14, gen_loss = 1.4267162035700944, disc_loss = 0.00023027453055611392
Trained batch 439 in epoch 14, gen_loss = 1.4266130049120296, disc_loss = 0.00023027003245178177
Trained batch 440 in epoch 14, gen_loss = 1.4265181034330339, disc_loss = 0.00023024775824965454
Trained batch 441 in epoch 14, gen_loss = 1.4265123055531428, disc_loss = 0.00023023628279806706
Trained batch 442 in epoch 14, gen_loss = 1.4266065135766368, disc_loss = 0.0002302452422487029
Trained batch 443 in epoch 14, gen_loss = 1.4266899458996884, disc_loss = 0.000230273206881549
Trained batch 444 in epoch 14, gen_loss = 1.4265422914805037, disc_loss = 0.0002303868433342216
Trained batch 445 in epoch 14, gen_loss = 1.4264235052827228, disc_loss = 0.0002306727181454873
Trained batch 446 in epoch 14, gen_loss = 1.4264010470985566, disc_loss = 0.00023108228910848514
Trained batch 447 in epoch 14, gen_loss = 1.4263137195791518, disc_loss = 0.0002315593461048593
Trained batch 448 in epoch 14, gen_loss = 1.426292955742647, disc_loss = 0.00023215725010628852
Trained batch 449 in epoch 14, gen_loss = 1.426250338289473, disc_loss = 0.00023289982383883196
Trained batch 450 in epoch 14, gen_loss = 1.4264351407070117, disc_loss = 0.00023372086838522498
Trained batch 451 in epoch 14, gen_loss = 1.4263455807107739, disc_loss = 0.0002346599387672428
Trained batch 452 in epoch 14, gen_loss = 1.4262652002423015, disc_loss = 0.0002357470118010876
Trained batch 453 in epoch 14, gen_loss = 1.4261583861800542, disc_loss = 0.00023674762536204135
Trained batch 454 in epoch 14, gen_loss = 1.4261646684709486, disc_loss = 0.00023743234123685397
Trained batch 455 in epoch 14, gen_loss = 1.4262584557658748, disc_loss = 0.0002377338379566234
Trained batch 456 in epoch 14, gen_loss = 1.4266156352061934, disc_loss = 0.00023763320522342862
Trained batch 457 in epoch 14, gen_loss = 1.426607411501189, disc_loss = 0.00023739908277899723
Trained batch 458 in epoch 14, gen_loss = 1.426494911085806, disc_loss = 0.0002371293554294419
Trained batch 459 in epoch 14, gen_loss = 1.4265166780223018, disc_loss = 0.00023688324824394405
Trained batch 460 in epoch 14, gen_loss = 1.4264759218356615, disc_loss = 0.0002366728543534591
Trained batch 461 in epoch 14, gen_loss = 1.4265661706656088, disc_loss = 0.00023650241244121433
Trained batch 462 in epoch 14, gen_loss = 1.4265434868134896, disc_loss = 0.00023637940884097862
Trained batch 463 in epoch 14, gen_loss = 1.426555280798468, disc_loss = 0.00023631944807299266
Trained batch 464 in epoch 14, gen_loss = 1.4264355354411629, disc_loss = 0.0002363103947221046
Trained batch 465 in epoch 14, gen_loss = 1.4264445023475287, disc_loss = 0.0002363513083163576
Trained batch 466 in epoch 14, gen_loss = 1.4264988557174323, disc_loss = 0.00023645221876777953
Trained batch 467 in epoch 14, gen_loss = 1.4265671805438833, disc_loss = 0.0002366370502067705
Trained batch 468 in epoch 14, gen_loss = 1.4265308113240485, disc_loss = 0.00023692249293484516
Trained batch 469 in epoch 14, gen_loss = 1.4266468535078334, disc_loss = 0.0002373317484678874
Trained batch 470 in epoch 14, gen_loss = 1.4266824919706698, disc_loss = 0.00023786324016138616
Trained batch 471 in epoch 14, gen_loss = 1.4266202086109225, disc_loss = 0.00023852677119621304
Trained batch 472 in epoch 14, gen_loss = 1.4267470544286813, disc_loss = 0.00023939880751752408
Trained batch 473 in epoch 14, gen_loss = 1.4268854791102028, disc_loss = 0.00024055465641877277
Trained batch 474 in epoch 14, gen_loss = 1.4270118482489336, disc_loss = 0.00024191742354703723
Trained batch 475 in epoch 14, gen_loss = 1.426995367062192, disc_loss = 0.0002433253984228574
Trained batch 476 in epoch 14, gen_loss = 1.4270244991754335, disc_loss = 0.000244781098376305
Trained batch 477 in epoch 14, gen_loss = 1.427184404937792, disc_loss = 0.00024639485618307803
Trained batch 478 in epoch 14, gen_loss = 1.42726787545238, disc_loss = 0.0002479769416951933
Trained batch 479 in epoch 14, gen_loss = 1.4273187783857186, disc_loss = 0.0002493801215905478
Trained batch 480 in epoch 14, gen_loss = 1.427167160347445, disc_loss = 0.00025051951708591336
Trained batch 481 in epoch 14, gen_loss = 1.4272100960070662, disc_loss = 0.00025134929343356406
Trained batch 482 in epoch 14, gen_loss = 1.427180836659781, disc_loss = 0.0002519612622699304
Trained batch 483 in epoch 14, gen_loss = 1.427328579681964, disc_loss = 0.0002524382189071467
Trained batch 484 in epoch 14, gen_loss = 1.4272591458153479, disc_loss = 0.00025273235439000045
Trained batch 485 in epoch 14, gen_loss = 1.427324910222748, disc_loss = 0.00025283233547498664
Trained batch 486 in epoch 14, gen_loss = 1.4271840060271277, disc_loss = 0.00025279617316496664
Trained batch 487 in epoch 14, gen_loss = 1.4272000120311488, disc_loss = 0.00025267390001914225
Trained batch 488 in epoch 14, gen_loss = 1.4271847636177983, disc_loss = 0.0002525168132490563
Trained batch 489 in epoch 14, gen_loss = 1.4270985705511912, disc_loss = 0.00025234948756851553
Trained batch 490 in epoch 14, gen_loss = 1.4272150405798327, disc_loss = 0.0002521761872469805
Trained batch 491 in epoch 14, gen_loss = 1.4270743180096634, disc_loss = 0.00025199582969656967
Trained batch 492 in epoch 14, gen_loss = 1.4270261337500798, disc_loss = 0.0002518052054940686
Trained batch 493 in epoch 14, gen_loss = 1.4270109729728235, disc_loss = 0.00025156840156010394
Trained batch 494 in epoch 14, gen_loss = 1.4270437125003699, disc_loss = 0.0002513044645243696
Trained batch 495 in epoch 14, gen_loss = 1.426961620007792, disc_loss = 0.00025104936677170403
Trained batch 496 in epoch 14, gen_loss = 1.4270984949000645, disc_loss = 0.0002508397718439543
Trained batch 497 in epoch 14, gen_loss = 1.427058263476115, disc_loss = 0.00025069699164071584
Trained batch 498 in epoch 14, gen_loss = 1.4271659631289557, disc_loss = 0.0002506837984169661
Trained batch 499 in epoch 14, gen_loss = 1.427164259672165, disc_loss = 0.00025082787950668717
Trained batch 500 in epoch 14, gen_loss = 1.4271174069650159, disc_loss = 0.00025107335594968134
Trained batch 501 in epoch 14, gen_loss = 1.4269867632018618, disc_loss = 0.0002513898863792591
Trained batch 502 in epoch 14, gen_loss = 1.4268892200045273, disc_loss = 0.0002518330447512441
Trained batch 503 in epoch 14, gen_loss = 1.426843558038984, disc_loss = 0.0002524399068793822
Trained batch 504 in epoch 14, gen_loss = 1.426918630316706, disc_loss = 0.0002532069798167634
Trained batch 505 in epoch 14, gen_loss = 1.4268909452460972, disc_loss = 0.00025411570070293254
Trained batch 506 in epoch 14, gen_loss = 1.4268971735674014, disc_loss = 0.00025519555068720195
Trained batch 507 in epoch 14, gen_loss = 1.4267989307876647, disc_loss = 0.0002564542827405073
Trained batch 508 in epoch 14, gen_loss = 1.4270454788020646, disc_loss = 0.00025778907337158503
Trained batch 509 in epoch 14, gen_loss = 1.4270160305733774, disc_loss = 0.0002590655464255
Trained batch 510 in epoch 14, gen_loss = 1.4270870205007653, disc_loss = 0.00026021567465052414
Trained batch 511 in epoch 14, gen_loss = 1.4270776882767677, disc_loss = 0.0002611830909486912
Trained batch 512 in epoch 14, gen_loss = 1.4270499628654465, disc_loss = 0.00026188967552188774
Trained batch 513 in epoch 14, gen_loss = 1.426923835555867, disc_loss = 0.00026226547263262127
Trained batch 514 in epoch 14, gen_loss = 1.426947884652221, disc_loss = 0.0002623271407659541
Trained batch 515 in epoch 14, gen_loss = 1.4270187202812166, disc_loss = 0.00026216374842551323
Trained batch 516 in epoch 14, gen_loss = 1.4269096074297996, disc_loss = 0.0002618825139288815
Trained batch 517 in epoch 14, gen_loss = 1.4269480157542873, disc_loss = 0.0002615383696928553
Trained batch 518 in epoch 14, gen_loss = 1.42695195252266, disc_loss = 0.0002611560934898511
Trained batch 519 in epoch 14, gen_loss = 1.426861627973043, disc_loss = 0.0002607387004200763
Trained batch 520 in epoch 14, gen_loss = 1.426945337864808, disc_loss = 0.00026029407550270657
Trained batch 521 in epoch 14, gen_loss = 1.4270350017310103, disc_loss = 0.00025984587595846915
Trained batch 522 in epoch 14, gen_loss = 1.4272096428314998, disc_loss = 0.0002594020618711212
Trained batch 523 in epoch 14, gen_loss = 1.4271169818994653, disc_loss = 0.0002589635244246976
Trained batch 524 in epoch 14, gen_loss = 1.4271637775784447, disc_loss = 0.000258522668882506
Trained batch 525 in epoch 14, gen_loss = 1.4273542727807629, disc_loss = 0.00025807593995423063
Trained batch 526 in epoch 14, gen_loss = 1.4273939942499265, disc_loss = 0.00025761969082079125
Trained batch 527 in epoch 14, gen_loss = 1.427220666498849, disc_loss = 0.0002571548489372204
Trained batch 528 in epoch 14, gen_loss = 1.4271230424960304, disc_loss = 0.0002566892403412123
Trained batch 529 in epoch 14, gen_loss = 1.4270870615851203, disc_loss = 0.0002562207325268592
Trained batch 530 in epoch 14, gen_loss = 1.42718657104758, disc_loss = 0.0002557515411168979
Trained batch 531 in epoch 14, gen_loss = 1.4272540545553194, disc_loss = 0.0002552879325483965
Trained batch 532 in epoch 14, gen_loss = 1.4272855860207363, disc_loss = 0.0002548439235685758
Trained batch 533 in epoch 14, gen_loss = 1.4272382395544303, disc_loss = 0.00025441739408579926
Trained batch 534 in epoch 14, gen_loss = 1.427160187970812, disc_loss = 0.0002540156647627784
Trained batch 535 in epoch 14, gen_loss = 1.4271227039063155, disc_loss = 0.00025365315177911874
Trained batch 536 in epoch 14, gen_loss = 1.427068849071666, disc_loss = 0.0002533184424219127
Trained batch 537 in epoch 14, gen_loss = 1.4270684464270298, disc_loss = 0.00025298072528400915
Trained batch 538 in epoch 14, gen_loss = 1.4271871886580685, disc_loss = 0.0002526347564404586
Trained batch 539 in epoch 14, gen_loss = 1.4271689788058952, disc_loss = 0.0002522861066920625
Trained batch 540 in epoch 14, gen_loss = 1.4272155217454525, disc_loss = 0.00025193118014735715
Trained batch 541 in epoch 14, gen_loss = 1.427379541951352, disc_loss = 0.0002515756681023922
Trained batch 542 in epoch 14, gen_loss = 1.4274801924742389, disc_loss = 0.00025123361624277595
Trained batch 543 in epoch 14, gen_loss = 1.4274742623024128, disc_loss = 0.00025091028992275206
Trained batch 544 in epoch 14, gen_loss = 1.4273998409236244, disc_loss = 0.00025061065593987106
Trained batch 545 in epoch 14, gen_loss = 1.4274749020080426, disc_loss = 0.00025036009401030354
Trained batch 546 in epoch 14, gen_loss = 1.4273727399993423, disc_loss = 0.0002501865294956757
Trained batch 547 in epoch 14, gen_loss = 1.4273851716170345, disc_loss = 0.00025006991827019465
Trained batch 548 in epoch 14, gen_loss = 1.4274370107928696, disc_loss = 0.0002499617975948908
Trained batch 549 in epoch 14, gen_loss = 1.4275871950929815, disc_loss = 0.000249930618742424
Trained batch 550 in epoch 14, gen_loss = 1.42744111603704, disc_loss = 0.000250011555720047
Trained batch 551 in epoch 14, gen_loss = 1.4275376522454664, disc_loss = 0.0002501720530825667
Trained batch 552 in epoch 14, gen_loss = 1.427518693491089, disc_loss = 0.0002503035628039222
Trained batch 553 in epoch 14, gen_loss = 1.4275832372021589, disc_loss = 0.0002503455708246611
Trained batch 554 in epoch 14, gen_loss = 1.427656202273326, disc_loss = 0.0002503150930671246
Trained batch 555 in epoch 14, gen_loss = 1.4278211906659517, disc_loss = 0.0002502290009473484
Trained batch 556 in epoch 14, gen_loss = 1.4278850322137828, disc_loss = 0.0002500859818765599
Trained batch 557 in epoch 14, gen_loss = 1.4279204592055317, disc_loss = 0.00024993934961193805
Trained batch 558 in epoch 14, gen_loss = 1.427889834789556, disc_loss = 0.0002498105852245185
Trained batch 559 in epoch 14, gen_loss = 1.4278566190174649, disc_loss = 0.00024973903019096205
Trained batch 560 in epoch 14, gen_loss = 1.4278712874002848, disc_loss = 0.0002497618095288425
Trained batch 561 in epoch 14, gen_loss = 1.4279490804757087, disc_loss = 0.0002498470482045105
Trained batch 562 in epoch 14, gen_loss = 1.4280403558144985, disc_loss = 0.0002499443467446588
Trained batch 563 in epoch 14, gen_loss = 1.4281310912565137, disc_loss = 0.0002500340186206297
Trained batch 564 in epoch 14, gen_loss = 1.4281088371192459, disc_loss = 0.0002500962731839568
Trained batch 565 in epoch 14, gen_loss = 1.428090292447026, disc_loss = 0.0002501275943810894
Trained batch 566 in epoch 14, gen_loss = 1.4280215943301167, disc_loss = 0.0002501342800646925
Trained batch 567 in epoch 14, gen_loss = 1.4279784077489879, disc_loss = 0.00025011699323895174
Trained batch 568 in epoch 14, gen_loss = 1.4280613040672665, disc_loss = 0.0002500761591096764
Trained batch 569 in epoch 14, gen_loss = 1.4281647468868055, disc_loss = 0.00025002767774981693
Trained batch 570 in epoch 14, gen_loss = 1.4282252817771899, disc_loss = 0.00024996412570856826
Trained batch 571 in epoch 14, gen_loss = 1.42826959303209, disc_loss = 0.00024988400108449005
Trained batch 572 in epoch 14, gen_loss = 1.428123723357968, disc_loss = 0.0002497892912826158
Trained batch 573 in epoch 14, gen_loss = 1.428198828306763, disc_loss = 0.0002497007452008964
Trained batch 574 in epoch 14, gen_loss = 1.4281340771136077, disc_loss = 0.00024963529100125966
Trained batch 575 in epoch 14, gen_loss = 1.4281076799250312, disc_loss = 0.0002495687491711844
Trained batch 576 in epoch 14, gen_loss = 1.4279554813738713, disc_loss = 0.0002494794276025108
Trained batch 577 in epoch 14, gen_loss = 1.4280177855986624, disc_loss = 0.0002493536761263247
Trained batch 578 in epoch 14, gen_loss = 1.428040406246877, disc_loss = 0.0002491854327347471
Trained batch 579 in epoch 14, gen_loss = 1.4281484897794394, disc_loss = 0.00024899492356294573
Trained batch 580 in epoch 14, gen_loss = 1.4281194716845855, disc_loss = 0.00024879728288523817
Trained batch 581 in epoch 14, gen_loss = 1.4281871832932804, disc_loss = 0.0002486088403063221
Trained batch 582 in epoch 14, gen_loss = 1.4282746499030503, disc_loss = 0.00024843399661326587
Trained batch 583 in epoch 14, gen_loss = 1.4282743973683005, disc_loss = 0.00024827119615836586
Trained batch 584 in epoch 14, gen_loss = 1.4283588888298753, disc_loss = 0.0002481097997798105
Trained batch 585 in epoch 14, gen_loss = 1.4283473509977296, disc_loss = 0.0002479324233657687
Trained batch 586 in epoch 14, gen_loss = 1.4282562192497708, disc_loss = 0.0002477406977823271
Trained batch 587 in epoch 14, gen_loss = 1.4282732099091926, disc_loss = 0.0002475403529006082
Trained batch 588 in epoch 14, gen_loss = 1.428354273425298, disc_loss = 0.00024733407091631035
Trained batch 589 in epoch 14, gen_loss = 1.428222023026418, disc_loss = 0.00024713094640608656
Trained batch 590 in epoch 14, gen_loss = 1.428264443039289, disc_loss = 0.0002469395550785218
Trained batch 591 in epoch 14, gen_loss = 1.428261194478821, disc_loss = 0.0002467732326112115
Trained batch 592 in epoch 14, gen_loss = 1.4281398468033661, disc_loss = 0.0002466380041066978
Trained batch 593 in epoch 14, gen_loss = 1.428144582794973, disc_loss = 0.00024655341253522847
Trained batch 594 in epoch 14, gen_loss = 1.428230313493424, disc_loss = 0.0002465209426022853
Trained batch 595 in epoch 14, gen_loss = 1.4282820770804514, disc_loss = 0.00024647942945080865
Trained batch 596 in epoch 14, gen_loss = 1.4282913090196288, disc_loss = 0.0002464375733061586
Trained batch 597 in epoch 14, gen_loss = 1.4282957287536417, disc_loss = 0.00024638361436438914
Trained batch 598 in epoch 14, gen_loss = 1.4282877469102608, disc_loss = 0.0002463367080984765
Trained batch 599 in epoch 14, gen_loss = 1.4283026389280955, disc_loss = 0.00024630411225264954
Trained batch 600 in epoch 14, gen_loss = 1.4282835434359837, disc_loss = 0.0002462939482432008
Trained batch 601 in epoch 14, gen_loss = 1.428411912086398, disc_loss = 0.0002462982104255289
Trained batch 602 in epoch 14, gen_loss = 1.4283700940225452, disc_loss = 0.0002463190310031806
Trained batch 603 in epoch 14, gen_loss = 1.4284349597053023, disc_loss = 0.0002463630763036205
Trained batch 604 in epoch 14, gen_loss = 1.4285647896695728, disc_loss = 0.0002463900320383026
Trained batch 605 in epoch 14, gen_loss = 1.4285131504039954, disc_loss = 0.00024641657645882724
Trained batch 606 in epoch 14, gen_loss = 1.4285961269743164, disc_loss = 0.0002464494388981144
Trained batch 607 in epoch 14, gen_loss = 1.4286821308104616, disc_loss = 0.0002464458848206014
Trained batch 608 in epoch 14, gen_loss = 1.4284653211462086, disc_loss = 0.0002464301063330737
Trained batch 609 in epoch 14, gen_loss = 1.4284614582530788, disc_loss = 0.0002463848418144943
Trained batch 610 in epoch 14, gen_loss = 1.4285891836481672, disc_loss = 0.00024634459558956894
Trained batch 611 in epoch 14, gen_loss = 1.4286224643389385, disc_loss = 0.0002463104542592346
Trained batch 612 in epoch 14, gen_loss = 1.4284762013794743, disc_loss = 0.00024627043104354736
Trained batch 613 in epoch 14, gen_loss = 1.4284474372087161, disc_loss = 0.00024621004035463014
Trained batch 614 in epoch 14, gen_loss = 1.4284238169832928, disc_loss = 0.00024614145495064347
Trained batch 615 in epoch 14, gen_loss = 1.4284119157048014, disc_loss = 0.000246079805289615
Trained batch 616 in epoch 14, gen_loss = 1.4283156835472564, disc_loss = 0.0002460160023947773
Trained batch 617 in epoch 14, gen_loss = 1.4284361220872133, disc_loss = 0.00024595621161374045
Trained batch 618 in epoch 14, gen_loss = 1.4284413440547197, disc_loss = 0.00024590717372438076
Trained batch 619 in epoch 14, gen_loss = 1.4284933405537759, disc_loss = 0.0002458722604805805
Trained batch 620 in epoch 14, gen_loss = 1.4284888507855302, disc_loss = 0.00024584008542074913
Trained batch 621 in epoch 14, gen_loss = 1.4285277264294518, disc_loss = 0.0002458058700070908
Trained batch 622 in epoch 14, gen_loss = 1.4284597017217793, disc_loss = 0.000245776110318182
Trained batch 623 in epoch 14, gen_loss = 1.4285675298709135, disc_loss = 0.00024578965307452377
Trained batch 624 in epoch 14, gen_loss = 1.4283949199676513, disc_loss = 0.00024587741261711927
Trained batch 625 in epoch 14, gen_loss = 1.4283923350584011, disc_loss = 0.0002459934871280646
Trained batch 626 in epoch 14, gen_loss = 1.4283451575791817, disc_loss = 0.00024608706685771075
Trained batch 627 in epoch 14, gen_loss = 1.4283367678238328, disc_loss = 0.00024615610748184106
Trained batch 628 in epoch 14, gen_loss = 1.4281884611884816, disc_loss = 0.00024619846611973904
Trained batch 629 in epoch 14, gen_loss = 1.4282417371159508, disc_loss = 0.000246214079729653
Trained batch 630 in epoch 14, gen_loss = 1.4281412438620855, disc_loss = 0.00024620476791703256
Trained batch 631 in epoch 14, gen_loss = 1.4281477845167811, disc_loss = 0.0002461673979120883
Trained batch 632 in epoch 14, gen_loss = 1.4280860273382299, disc_loss = 0.0002460971444200283
Trained batch 633 in epoch 14, gen_loss = 1.4279565954057951, disc_loss = 0.0002460014428086864
Trained batch 634 in epoch 14, gen_loss = 1.4280234366890014, disc_loss = 0.00024589429739084093
Trained batch 635 in epoch 14, gen_loss = 1.4279880311878972, disc_loss = 0.0002457828895420841
Trained batch 636 in epoch 14, gen_loss = 1.4279761308777839, disc_loss = 0.0002456687685898913
Trained batch 637 in epoch 14, gen_loss = 1.4279434054996527, disc_loss = 0.00024555106284099233
Trained batch 638 in epoch 14, gen_loss = 1.4279592960653171, disc_loss = 0.000245431510623822
Trained batch 639 in epoch 14, gen_loss = 1.4278663208708167, disc_loss = 0.00024530438954926124
Trained batch 640 in epoch 14, gen_loss = 1.4278730473912635, disc_loss = 0.0002451919989264336
Trained batch 641 in epoch 14, gen_loss = 1.4279313388271866, disc_loss = 0.00024511065290734737
Trained batch 642 in epoch 14, gen_loss = 1.4278923376908013, disc_loss = 0.0002450395211584533
Trained batch 643 in epoch 14, gen_loss = 1.427904195481946, disc_loss = 0.0002449681583249901
Trained batch 644 in epoch 14, gen_loss = 1.427825517987096, disc_loss = 0.00024488553133976035
Trained batch 645 in epoch 14, gen_loss = 1.427760799787362, disc_loss = 0.00024478833334084556
Trained batch 646 in epoch 14, gen_loss = 1.427703314254973, disc_loss = 0.00024468450022617575
Trained batch 647 in epoch 14, gen_loss = 1.4276902458550018, disc_loss = 0.00024458730944806916
Trained batch 648 in epoch 14, gen_loss = 1.4277263354446927, disc_loss = 0.0002445140676873431
Trained batch 649 in epoch 14, gen_loss = 1.4276665700398958, disc_loss = 0.0002444695098844162
Trained batch 650 in epoch 14, gen_loss = 1.4276138199822328, disc_loss = 0.00024443458010646614
Trained batch 651 in epoch 14, gen_loss = 1.427622306017788, disc_loss = 0.00024438391782694263
Trained batch 652 in epoch 14, gen_loss = 1.427603971720837, disc_loss = 0.00024431434010716203
Trained batch 653 in epoch 14, gen_loss = 1.4276704297882337, disc_loss = 0.0002442251929248111
Trained batch 654 in epoch 14, gen_loss = 1.4277044714862153, disc_loss = 0.00024410183046392244
Trained batch 655 in epoch 14, gen_loss = 1.4278605656652916, disc_loss = 0.00024395582089302325
Trained batch 656 in epoch 14, gen_loss = 1.4278606524750523, disc_loss = 0.00024378770621874267
Trained batch 657 in epoch 14, gen_loss = 1.4279165305989854, disc_loss = 0.00024359926836851244
Trained batch 658 in epoch 14, gen_loss = 1.4278978861879688, disc_loss = 0.00024339257379807447
Trained batch 659 in epoch 14, gen_loss = 1.4277618897683693, disc_loss = 0.00024317089076344984
Trained batch 660 in epoch 14, gen_loss = 1.4277106631721923, disc_loss = 0.0002429347602171884
Trained batch 661 in epoch 14, gen_loss = 1.4276398098000587, disc_loss = 0.00024268608891029036
Trained batch 662 in epoch 14, gen_loss = 1.4276563119744463, disc_loss = 0.00024243287039599207
Trained batch 663 in epoch 14, gen_loss = 1.42764815580414, disc_loss = 0.0002421908872771021
Trained batch 664 in epoch 14, gen_loss = 1.4277042462413472, disc_loss = 0.00024197325997021862
Trained batch 665 in epoch 14, gen_loss = 1.4278476472731467, disc_loss = 0.00024177799488139722
Trained batch 666 in epoch 14, gen_loss = 1.4279888215987222, disc_loss = 0.00024161024434508945
Trained batch 667 in epoch 14, gen_loss = 1.42793926328956, disc_loss = 0.00024147833300753926
Trained batch 668 in epoch 14, gen_loss = 1.4279626399412284, disc_loss = 0.00024137690596943236
Trained batch 669 in epoch 14, gen_loss = 1.4279870517218292, disc_loss = 0.00024131316991268033
Trained batch 670 in epoch 14, gen_loss = 1.4279355469830168, disc_loss = 0.00024127897185431197
Trained batch 671 in epoch 14, gen_loss = 1.42798370548657, disc_loss = 0.00024121661937282992
Trained batch 672 in epoch 14, gen_loss = 1.4279278851547355, disc_loss = 0.00024114406545085537
Trained batch 673 in epoch 14, gen_loss = 1.4279393145167862, disc_loss = 0.0002410955042416838
Trained batch 674 in epoch 14, gen_loss = 1.4279258911697952, disc_loss = 0.0002410534104685077
Trained batch 675 in epoch 14, gen_loss = 1.4279550788317912, disc_loss = 0.00024099718987091208
Trained batch 676 in epoch 14, gen_loss = 1.4280237223584331, disc_loss = 0.0002409427925380189
Trained batch 677 in epoch 14, gen_loss = 1.428022831414653, disc_loss = 0.00024088792540818635
Trained batch 678 in epoch 14, gen_loss = 1.4279155826006793, disc_loss = 0.00024083026518676465
Trained batch 679 in epoch 14, gen_loss = 1.4278546210597542, disc_loss = 0.0002407550176224718
Trained batch 680 in epoch 14, gen_loss = 1.4277353227226044, disc_loss = 0.00024066574239538745
Trained batch 681 in epoch 14, gen_loss = 1.4276767609056489, disc_loss = 0.00024055331425809786
Trained batch 682 in epoch 14, gen_loss = 1.4276667671008132, disc_loss = 0.0002404601667694273
Trained batch 683 in epoch 14, gen_loss = 1.4276561099186278, disc_loss = 0.00024040570646419098
Trained batch 684 in epoch 14, gen_loss = 1.4277204633629235, disc_loss = 0.0002403805822882698
Trained batch 685 in epoch 14, gen_loss = 1.4277971675375112, disc_loss = 0.00024037497908323136
Trained batch 686 in epoch 14, gen_loss = 1.4277710852144065, disc_loss = 0.00024036456070025133
Trained batch 687 in epoch 14, gen_loss = 1.4278707166397295, disc_loss = 0.00024034186519405774
Trained batch 688 in epoch 14, gen_loss = 1.4278974235490376, disc_loss = 0.0002403234013013158
Trained batch 689 in epoch 14, gen_loss = 1.4280150137085845, disc_loss = 0.00024035555322265336
Trained batch 690 in epoch 14, gen_loss = 1.4279349046919694, disc_loss = 0.00024044577788008505
Trained batch 691 in epoch 14, gen_loss = 1.4279560818837558, disc_loss = 0.0002405655964146013
Trained batch 692 in epoch 14, gen_loss = 1.4278780627904344, disc_loss = 0.00024070268536928135
Trained batch 693 in epoch 14, gen_loss = 1.4277507959937499, disc_loss = 0.0002408923152224475
Trained batch 694 in epoch 14, gen_loss = 1.4278569010521869, disc_loss = 0.0002411385229528304
Trained batch 695 in epoch 14, gen_loss = 1.4279008285067547, disc_loss = 0.00024142017796672613
Trained batch 696 in epoch 14, gen_loss = 1.4277161732636703, disc_loss = 0.00024169157998988637
Trained batch 697 in epoch 14, gen_loss = 1.4278851475961571, disc_loss = 0.0002419457224156542
Trained batch 698 in epoch 14, gen_loss = 1.4279179491198626, disc_loss = 0.0002421765022709497
Trained batch 699 in epoch 14, gen_loss = 1.4280346492358615, disc_loss = 0.0002423611436129899
Trained batch 700 in epoch 14, gen_loss = 1.427985060402058, disc_loss = 0.00024248274068354274
Trained batch 701 in epoch 14, gen_loss = 1.4280311911873669, disc_loss = 0.00024253158422727776
Trained batch 702 in epoch 14, gen_loss = 1.427918728520487, disc_loss = 0.00024250830506356976
Trained batch 703 in epoch 14, gen_loss = 1.4278271242298863, disc_loss = 0.00024243391569714586
Trained batch 704 in epoch 14, gen_loss = 1.4277932630363086, disc_loss = 0.0002423391298296028
Trained batch 705 in epoch 14, gen_loss = 1.4277328516200987, disc_loss = 0.00024226124997463305
Trained batch 706 in epoch 14, gen_loss = 1.4277925165910195, disc_loss = 0.00024221903475881587
Trained batch 707 in epoch 14, gen_loss = 1.4279027985314192, disc_loss = 0.0002421809843507756
Trained batch 708 in epoch 14, gen_loss = 1.4278372376526696, disc_loss = 0.00024214269712228613
Trained batch 709 in epoch 14, gen_loss = 1.4278360509536636, disc_loss = 0.0002421121836121042
Trained batch 710 in epoch 14, gen_loss = 1.4277493333347069, disc_loss = 0.00024211699019424781
Trained batch 711 in epoch 14, gen_loss = 1.4277714872628116, disc_loss = 0.0002421475842700939
Trained batch 712 in epoch 14, gen_loss = 1.4277752074419532, disc_loss = 0.00024221883115558684
Trained batch 713 in epoch 14, gen_loss = 1.4279100183679276, disc_loss = 0.00024235098090221252
Trained batch 714 in epoch 14, gen_loss = 1.4278845621989324, disc_loss = 0.00024252180230203497
Trained batch 715 in epoch 14, gen_loss = 1.4278971887500593, disc_loss = 0.00024273560872793319
Trained batch 716 in epoch 14, gen_loss = 1.4278811771666822, disc_loss = 0.00024302367779199149
Trained batch 717 in epoch 14, gen_loss = 1.4278934641136765, disc_loss = 0.00024344183157597822
Trained batch 718 in epoch 14, gen_loss = 1.4278293843063758, disc_loss = 0.0002440389035941121
Trained batch 719 in epoch 14, gen_loss = 1.4278061310450236, disc_loss = 0.0002448121308923924
Trained batch 720 in epoch 14, gen_loss = 1.4277483332339007, disc_loss = 0.00024570492287087804
Trained batch 721 in epoch 14, gen_loss = 1.4277631902958878, disc_loss = 0.00024668134377108566
Trained batch 722 in epoch 14, gen_loss = 1.4277860437356256, disc_loss = 0.0002476972972884545
Trained batch 723 in epoch 14, gen_loss = 1.4278030329646327, disc_loss = 0.0002487355321278371
Trained batch 724 in epoch 14, gen_loss = 1.4277679270711439, disc_loss = 0.0002497765203519646
Trained batch 725 in epoch 14, gen_loss = 1.4277691885459523, disc_loss = 0.0002508469221993437
Trained batch 726 in epoch 14, gen_loss = 1.4277281651306677, disc_loss = 0.0002518963207108239
Trained batch 727 in epoch 14, gen_loss = 1.4278519991989975, disc_loss = 0.000252901334996685
Trained batch 728 in epoch 14, gen_loss = 1.427871846040744, disc_loss = 0.0002538329373631741
Trained batch 729 in epoch 14, gen_loss = 1.4278390530037552, disc_loss = 0.0002546464899196881
Trained batch 730 in epoch 14, gen_loss = 1.4278290147820512, disc_loss = 0.0002552903952966838
Trained batch 731 in epoch 14, gen_loss = 1.4278004101065338, disc_loss = 0.00025576999257985537
Trained batch 732 in epoch 14, gen_loss = 1.4276432143714874, disc_loss = 0.0002561256595718785
Trained batch 733 in epoch 14, gen_loss = 1.4276403154599244, disc_loss = 0.00025639819514984823
Trained batch 734 in epoch 14, gen_loss = 1.4277104273945296, disc_loss = 0.0002565976495641574
Trained batch 735 in epoch 14, gen_loss = 1.427748920476955, disc_loss = 0.0002567395690904376
Trained batch 736 in epoch 14, gen_loss = 1.4278068904799068, disc_loss = 0.00025682255996919566
Trained batch 737 in epoch 14, gen_loss = 1.4277933669607168, disc_loss = 0.000256856927808381
Trained batch 738 in epoch 14, gen_loss = 1.4278189042263005, disc_loss = 0.0002568273360717994
Trained batch 739 in epoch 14, gen_loss = 1.4277339239378233, disc_loss = 0.00025673506931611515
Trained batch 740 in epoch 14, gen_loss = 1.4277927476545738, disc_loss = 0.0002565845766761666
Trained batch 741 in epoch 14, gen_loss = 1.4277808960235987, disc_loss = 0.0002564119359732101
Trained batch 742 in epoch 14, gen_loss = 1.4278380288410315, disc_loss = 0.00025621026681514424
Trained batch 743 in epoch 14, gen_loss = 1.4278244483535008, disc_loss = 0.00025601043834131494
Trained batch 744 in epoch 14, gen_loss = 1.4279682925883554, disc_loss = 0.00025580569083604436
Trained batch 745 in epoch 14, gen_loss = 1.4279827181519515, disc_loss = 0.0002556091215516628
Testing Epoch 14
Training Epoch 15
Trained batch 0 in epoch 15, gen_loss = 1.4434581995010376, disc_loss = 0.0001158260929514654
Trained batch 1 in epoch 15, gen_loss = 1.4440798163414001, disc_loss = 0.00011694947534124367
Trained batch 2 in epoch 15, gen_loss = 1.4346505800882976, disc_loss = 0.00011891915103963886
Trained batch 3 in epoch 15, gen_loss = 1.4346608519554138, disc_loss = 0.00012046763913531322
Trained batch 4 in epoch 15, gen_loss = 1.4084059715270996, disc_loss = 0.00012311104364925995
Trained batch 5 in epoch 15, gen_loss = 1.409324844678243, disc_loss = 0.00012751429676427506
Trained batch 6 in epoch 15, gen_loss = 1.4160285336630685, disc_loss = 0.00013431681249390489
Trained batch 7 in epoch 15, gen_loss = 1.4121886491775513, disc_loss = 0.0001418616220689728
Trained batch 8 in epoch 15, gen_loss = 1.418379333284166, disc_loss = 0.00014799326648547625
Trained batch 9 in epoch 15, gen_loss = 1.4120389461517333, disc_loss = 0.00015240606953739188
Trained batch 10 in epoch 15, gen_loss = 1.4103121324019, disc_loss = 0.00015594132591187108
Trained batch 11 in epoch 15, gen_loss = 1.4097600380579631, disc_loss = 0.00015913958183470336
Trained batch 12 in epoch 15, gen_loss = 1.414311830814068, disc_loss = 0.00016222574665264873
Trained batch 13 in epoch 15, gen_loss = 1.415687118257795, disc_loss = 0.00016528126486394155
Trained batch 14 in epoch 15, gen_loss = 1.4172754287719727, disc_loss = 0.0001679934546700679
Trained batch 15 in epoch 15, gen_loss = 1.417252704501152, disc_loss = 0.0001704017045085493
Trained batch 16 in epoch 15, gen_loss = 1.41855867470012, disc_loss = 0.0001727482522255741
Trained batch 17 in epoch 15, gen_loss = 1.4196510314941406, disc_loss = 0.0001750073558165847
Trained batch 18 in epoch 15, gen_loss = 1.4215420296317653, disc_loss = 0.00017677282870097674
Trained batch 19 in epoch 15, gen_loss = 1.4180188536643983, disc_loss = 0.00017772046812751795
Trained batch 20 in epoch 15, gen_loss = 1.418368975321452, disc_loss = 0.00017784604382801002
Trained batch 21 in epoch 15, gen_loss = 1.4148331718011335, disc_loss = 0.00017720778619563632
Trained batch 22 in epoch 15, gen_loss = 1.4161042700643125, disc_loss = 0.0001762185107192794
Trained batch 23 in epoch 15, gen_loss = 1.4190002232789993, disc_loss = 0.00017525403897404127
Trained batch 24 in epoch 15, gen_loss = 1.4186400079727173, disc_loss = 0.00017434288369258866
Trained batch 25 in epoch 15, gen_loss = 1.4186153090917146, disc_loss = 0.0001733744264548967
Trained batch 26 in epoch 15, gen_loss = 1.4184444348017375, disc_loss = 0.0001723393390959784
Trained batch 27 in epoch 15, gen_loss = 1.421591852392469, disc_loss = 0.00017123596808232833
Trained batch 28 in epoch 15, gen_loss = 1.4233911242978325, disc_loss = 0.00016987417169228388
Trained batch 29 in epoch 15, gen_loss = 1.4232277433077494, disc_loss = 0.00016806573718592215
Trained batch 30 in epoch 15, gen_loss = 1.4229641345239454, disc_loss = 0.00016600369816578383
Trained batch 31 in epoch 15, gen_loss = 1.42034375295043, disc_loss = 0.00016362889596166497
Trained batch 32 in epoch 15, gen_loss = 1.4177604949835576, disc_loss = 0.00016092534078228655
Trained batch 33 in epoch 15, gen_loss = 1.4186025121632744, disc_loss = 0.0001580279867459253
Trained batch 34 in epoch 15, gen_loss = 1.418700351033892, disc_loss = 0.0001549302806129812
Trained batch 35 in epoch 15, gen_loss = 1.4205103052986994, disc_loss = 0.00015179464490857854
Trained batch 36 in epoch 15, gen_loss = 1.4233850659550846, disc_loss = 0.00014868392188234153
Trained batch 37 in epoch 15, gen_loss = 1.422925011107796, disc_loss = 0.00014567705195651413
Trained batch 38 in epoch 15, gen_loss = 1.4241722149726672, disc_loss = 0.00014277641327144243
Trained batch 39 in epoch 15, gen_loss = 1.4241846829652787, disc_loss = 0.00014002700117998756
Trained batch 40 in epoch 15, gen_loss = 1.4246804219920461, disc_loss = 0.00013746685070190124
Trained batch 41 in epoch 15, gen_loss = 1.4246813995497567, disc_loss = 0.0001351489062515265
Trained batch 42 in epoch 15, gen_loss = 1.4242253885712735, disc_loss = 0.0001329670532107039
Trained batch 43 in epoch 15, gen_loss = 1.4225248721512882, disc_loss = 0.00013090435268995034
Trained batch 44 in epoch 15, gen_loss = 1.42397088209788, disc_loss = 0.00012877895844414726
Trained batch 45 in epoch 15, gen_loss = 1.4264632126559382, disc_loss = 0.00012666597546700834
Trained batch 46 in epoch 15, gen_loss = 1.426772472706247, disc_loss = 0.0001245797575393226
Trained batch 47 in epoch 15, gen_loss = 1.4267383192976315, disc_loss = 0.00012262982234763817
Trained batch 48 in epoch 15, gen_loss = 1.4271306140082223, disc_loss = 0.00012078176527842404
Trained batch 49 in epoch 15, gen_loss = 1.4276696419715882, disc_loss = 0.00011902505386387929
Trained batch 50 in epoch 15, gen_loss = 1.4279821690391092, disc_loss = 0.00011731520991067074
Trained batch 51 in epoch 15, gen_loss = 1.4267129783446972, disc_loss = 0.00011574061528125849
Trained batch 52 in epoch 15, gen_loss = 1.4271575932232838, disc_loss = 0.00011434466906170853
Trained batch 53 in epoch 15, gen_loss = 1.4267719476311296, disc_loss = 0.0001131240632848521
Trained batch 54 in epoch 15, gen_loss = 1.4255457184531473, disc_loss = 0.00011203611780233173
Trained batch 55 in epoch 15, gen_loss = 1.4259006891931807, disc_loss = 0.00011112700264805296
Trained batch 56 in epoch 15, gen_loss = 1.4256692350956433, disc_loss = 0.00011030718310952612
Trained batch 57 in epoch 15, gen_loss = 1.425320906885739, disc_loss = 0.0001096327169166059
Trained batch 58 in epoch 15, gen_loss = 1.4251094187720348, disc_loss = 0.0001090727445582654
Trained batch 59 in epoch 15, gen_loss = 1.424899407227834, disc_loss = 0.00010858316078762678
Trained batch 60 in epoch 15, gen_loss = 1.4249269258780557, disc_loss = 0.00010814482430148808
Trained batch 61 in epoch 15, gen_loss = 1.424160284380759, disc_loss = 0.00010792618852593154
Trained batch 62 in epoch 15, gen_loss = 1.4245891381823828, disc_loss = 0.00010799499363028666
Trained batch 63 in epoch 15, gen_loss = 1.424743641167879, disc_loss = 0.00010832493069301563
Trained batch 64 in epoch 15, gen_loss = 1.4237207596118633, disc_loss = 0.00010903026615359033
Trained batch 65 in epoch 15, gen_loss = 1.424127627502788, disc_loss = 0.00011027866551585524
Trained batch 66 in epoch 15, gen_loss = 1.4231176500889793, disc_loss = 0.0001120860606941061
Trained batch 67 in epoch 15, gen_loss = 1.4240906589171465, disc_loss = 0.0001143011400820208
Trained batch 68 in epoch 15, gen_loss = 1.423902988433838, disc_loss = 0.0001164814108262257
Trained batch 69 in epoch 15, gen_loss = 1.4233075295175825, disc_loss = 0.0001184588519598557
Trained batch 70 in epoch 15, gen_loss = 1.4226798255678634, disc_loss = 0.0001202705436145139
Trained batch 71 in epoch 15, gen_loss = 1.4238210800621245, disc_loss = 0.00012183163047059982
Trained batch 72 in epoch 15, gen_loss = 1.423409101081221, disc_loss = 0.00012303930071377105
Trained batch 73 in epoch 15, gen_loss = 1.4235571864488963, disc_loss = 0.00012384107223526272
Trained batch 74 in epoch 15, gen_loss = 1.4236338345209758, disc_loss = 0.0001244771906446355
Trained batch 75 in epoch 15, gen_loss = 1.4243102842255642, disc_loss = 0.00012525857633399458
Trained batch 76 in epoch 15, gen_loss = 1.4253898750651965, disc_loss = 0.00012621583574672242
Trained batch 77 in epoch 15, gen_loss = 1.4260772619491968, disc_loss = 0.00012716020762290544
Trained batch 78 in epoch 15, gen_loss = 1.426433152790311, disc_loss = 0.0001281110012256894
Trained batch 79 in epoch 15, gen_loss = 1.427247777581215, disc_loss = 0.00012919218142997123
Trained batch 80 in epoch 15, gen_loss = 1.4273076057434082, disc_loss = 0.00013028956792693883
Trained batch 81 in epoch 15, gen_loss = 1.4278000854864352, disc_loss = 0.0001314188457177895
Trained batch 82 in epoch 15, gen_loss = 1.4278648071978466, disc_loss = 0.0001325667773531918
Trained batch 83 in epoch 15, gen_loss = 1.4280537721656619, disc_loss = 0.00013398843891211852
Trained batch 84 in epoch 15, gen_loss = 1.4285595963982975, disc_loss = 0.00013577595245271154
Trained batch 85 in epoch 15, gen_loss = 1.4286024556603543, disc_loss = 0.0001377853921778381
Trained batch 86 in epoch 15, gen_loss = 1.4289904312155712, disc_loss = 0.00014003239387723929
Trained batch 87 in epoch 15, gen_loss = 1.4297921291806481, disc_loss = 0.0001428239303012643
Trained batch 88 in epoch 15, gen_loss = 1.430293479662263, disc_loss = 0.00014627066297323202
Trained batch 89 in epoch 15, gen_loss = 1.4305102189381917, disc_loss = 0.00015041848989009546
Trained batch 90 in epoch 15, gen_loss = 1.4315573304564089, disc_loss = 0.00015532586969509415
Trained batch 91 in epoch 15, gen_loss = 1.4319224279859792, disc_loss = 0.0001609836795662135
Trained batch 92 in epoch 15, gen_loss = 1.4314840378299836, disc_loss = 0.00016717355010182326
Trained batch 93 in epoch 15, gen_loss = 1.4321680804516406, disc_loss = 0.00017393788050654583
Trained batch 94 in epoch 15, gen_loss = 1.432697898463199, disc_loss = 0.00018109564713851892
Trained batch 95 in epoch 15, gen_loss = 1.433558326214552, disc_loss = 0.0001885314663165142
Trained batch 96 in epoch 15, gen_loss = 1.4341337004887689, disc_loss = 0.00019636457150180335
Trained batch 97 in epoch 15, gen_loss = 1.433681599947871, disc_loss = 0.0002042050788930988
Trained batch 98 in epoch 15, gen_loss = 1.4333341519037883, disc_loss = 0.00021212940015230384
Trained batch 99 in epoch 15, gen_loss = 1.432965577840805, disc_loss = 0.0002198355418659048
Trained batch 100 in epoch 15, gen_loss = 1.4328658687006128, disc_loss = 0.000226921426771453
Trained batch 101 in epoch 15, gen_loss = 1.432589590549469, disc_loss = 0.00023297420778487554
Trained batch 102 in epoch 15, gen_loss = 1.4320957348184677, disc_loss = 0.00023784330438255123
Trained batch 103 in epoch 15, gen_loss = 1.4325843006372452, disc_loss = 0.000241628111535437
Trained batch 104 in epoch 15, gen_loss = 1.4324841045197987, disc_loss = 0.00024443083627071854
Trained batch 105 in epoch 15, gen_loss = 1.432430848760425, disc_loss = 0.0002464931398517022
Trained batch 106 in epoch 15, gen_loss = 1.4320790355450639, disc_loss = 0.0002479039075611394
Trained batch 107 in epoch 15, gen_loss = 1.4327768893153578, disc_loss = 0.00024884518434528554
Trained batch 108 in epoch 15, gen_loss = 1.432356918623688, disc_loss = 0.00024936470415906707
Trained batch 109 in epoch 15, gen_loss = 1.4324314973571084, disc_loss = 0.00024946570344830187
Trained batch 110 in epoch 15, gen_loss = 1.4320640778756357, disc_loss = 0.00024912553976514366
Trained batch 111 in epoch 15, gen_loss = 1.4321236929723196, disc_loss = 0.0002484016007266681
Trained batch 112 in epoch 15, gen_loss = 1.4323864004253286, disc_loss = 0.0002473851983807363
Trained batch 113 in epoch 15, gen_loss = 1.4325007712631894, disc_loss = 0.000246212482970645
Trained batch 114 in epoch 15, gen_loss = 1.431852298197539, disc_loss = 0.00024498677281055436
Trained batch 115 in epoch 15, gen_loss = 1.4310000775189236, disc_loss = 0.00024370962662566132
Trained batch 116 in epoch 15, gen_loss = 1.4304705868419418, disc_loss = 0.0002424799619266429
Trained batch 117 in epoch 15, gen_loss = 1.4312789046158225, disc_loss = 0.00024130544508067434
Trained batch 118 in epoch 15, gen_loss = 1.431429245892693, disc_loss = 0.00024010457152044871
Trained batch 119 in epoch 15, gen_loss = 1.4316547989845276, disc_loss = 0.00023885274767962983
Trained batch 120 in epoch 15, gen_loss = 1.431048251380605, disc_loss = 0.00023759153621292418
Trained batch 121 in epoch 15, gen_loss = 1.4303943387797622, disc_loss = 0.00023633865501204902
Trained batch 122 in epoch 15, gen_loss = 1.4303401892747336, disc_loss = 0.0002351518859045686
Trained batch 123 in epoch 15, gen_loss = 1.4307015720875031, disc_loss = 0.0002340570315408836
Trained batch 124 in epoch 15, gen_loss = 1.4309724016189576, disc_loss = 0.00023301377752795816
Trained batch 125 in epoch 15, gen_loss = 1.4304206314541044, disc_loss = 0.00023199074360216775
Trained batch 126 in epoch 15, gen_loss = 1.4306671168860488, disc_loss = 0.00023095746744400273
Trained batch 127 in epoch 15, gen_loss = 1.4307009130716324, disc_loss = 0.00022986993280937895
Trained batch 128 in epoch 15, gen_loss = 1.4305076488228732, disc_loss = 0.00022873701144175877
Trained batch 129 in epoch 15, gen_loss = 1.4303119989541861, disc_loss = 0.0002276374098773186
Trained batch 130 in epoch 15, gen_loss = 1.4300225272433449, disc_loss = 0.0002266454194580873
Trained batch 131 in epoch 15, gen_loss = 1.4302761383128888, disc_loss = 0.00022581624403811117
Trained batch 132 in epoch 15, gen_loss = 1.4293724047510248, disc_loss = 0.00022513442366432987
Trained batch 133 in epoch 15, gen_loss = 1.429352673132028, disc_loss = 0.0002243991313743711
Trained batch 134 in epoch 15, gen_loss = 1.4288453340530396, disc_loss = 0.00022360081250856942
Trained batch 135 in epoch 15, gen_loss = 1.429145459743107, disc_loss = 0.00022271169457192575
Trained batch 136 in epoch 15, gen_loss = 1.4289885411297318, disc_loss = 0.0002217615532784818
Trained batch 137 in epoch 15, gen_loss = 1.4286956061487612, disc_loss = 0.0002208174440623396
Trained batch 138 in epoch 15, gen_loss = 1.4286915955783652, disc_loss = 0.00021988447013741573
Trained batch 139 in epoch 15, gen_loss = 1.4283601411751339, disc_loss = 0.00021897586801579953
Trained batch 140 in epoch 15, gen_loss = 1.4277835323455486, disc_loss = 0.00021814321123801687
Trained batch 141 in epoch 15, gen_loss = 1.4279883176508084, disc_loss = 0.00021736703407876915
Trained batch 142 in epoch 15, gen_loss = 1.4276235353696596, disc_loss = 0.00021662781476222264
Trained batch 143 in epoch 15, gen_loss = 1.4276403627461858, disc_loss = 0.00021595901161062001
Trained batch 144 in epoch 15, gen_loss = 1.4276105921843956, disc_loss = 0.00021539248244090262
Trained batch 145 in epoch 15, gen_loss = 1.4275498047266921, disc_loss = 0.0002148659440448782
Trained batch 146 in epoch 15, gen_loss = 1.427277999670327, disc_loss = 0.00021431643905262242
Trained batch 147 in epoch 15, gen_loss = 1.4271616307464805, disc_loss = 0.00021372334668813965
Trained batch 148 in epoch 15, gen_loss = 1.4269160056274208, disc_loss = 0.0002131125236444969
Trained batch 149 in epoch 15, gen_loss = 1.426802136103312, disc_loss = 0.0002125342490520173
Trained batch 150 in epoch 15, gen_loss = 1.4264922599918795, disc_loss = 0.00021194543082163738
Trained batch 151 in epoch 15, gen_loss = 1.4266350379115658, disc_loss = 0.00021136797501017818
Trained batch 152 in epoch 15, gen_loss = 1.4267446207844354, disc_loss = 0.0002108283578802442
Trained batch 153 in epoch 15, gen_loss = 1.427228611785096, disc_loss = 0.00021033042342766405
Trained batch 154 in epoch 15, gen_loss = 1.4274794340133667, disc_loss = 0.00020985810462603225
Trained batch 155 in epoch 15, gen_loss = 1.4275232347158284, disc_loss = 0.00020941505103203384
Trained batch 156 in epoch 15, gen_loss = 1.4269904232328865, disc_loss = 0.00020897573772721455
Trained batch 157 in epoch 15, gen_loss = 1.4272796300393116, disc_loss = 0.00020860029358521422
Trained batch 158 in epoch 15, gen_loss = 1.4268369142364405, disc_loss = 0.00020832035802385284
Trained batch 159 in epoch 15, gen_loss = 1.42697888687253, disc_loss = 0.00020810017754229192
Trained batch 160 in epoch 15, gen_loss = 1.4273799776290514, disc_loss = 0.00020795125005042226
Trained batch 161 in epoch 15, gen_loss = 1.4273953577618541, disc_loss = 0.00020791206478872797
Trained batch 162 in epoch 15, gen_loss = 1.4274170259756545, disc_loss = 0.0002078561809437458
Trained batch 163 in epoch 15, gen_loss = 1.427280801825407, disc_loss = 0.00020775101283350788
Trained batch 164 in epoch 15, gen_loss = 1.4272644252488107, disc_loss = 0.00020757858208415918
Trained batch 165 in epoch 15, gen_loss = 1.4272350611456905, disc_loss = 0.00020727360825698138
Trained batch 166 in epoch 15, gen_loss = 1.427157892438466, disc_loss = 0.0002068418006584868
Trained batch 167 in epoch 15, gen_loss = 1.4271893834783917, disc_loss = 0.00020639275434015353
Trained batch 168 in epoch 15, gen_loss = 1.4271495109479102, disc_loss = 0.00020600158981076502
Trained batch 169 in epoch 15, gen_loss = 1.4274187648997587, disc_loss = 0.00020571049274568554
Trained batch 170 in epoch 15, gen_loss = 1.4276309626841406, disc_loss = 0.00020551012083649777
Trained batch 171 in epoch 15, gen_loss = 1.4274415949056314, disc_loss = 0.00020540978648357343
Trained batch 172 in epoch 15, gen_loss = 1.4268863538786165, disc_loss = 0.00020543074334071238
Trained batch 173 in epoch 15, gen_loss = 1.4274525039497463, disc_loss = 0.00020552473991604833
Trained batch 174 in epoch 15, gen_loss = 1.4275060381208147, disc_loss = 0.00020571065763111358
Trained batch 175 in epoch 15, gen_loss = 1.42803393304348, disc_loss = 0.00020603644320131437
Trained batch 176 in epoch 15, gen_loss = 1.4282042643444686, disc_loss = 0.00020644755909544294
Trained batch 177 in epoch 15, gen_loss = 1.4280214142263605, disc_loss = 0.0002069648103366653
Trained batch 178 in epoch 15, gen_loss = 1.428266689098081, disc_loss = 0.00020763363884131075
Trained batch 179 in epoch 15, gen_loss = 1.4285466021961637, disc_loss = 0.00020842340353637053
Trained batch 180 in epoch 15, gen_loss = 1.4284371473512596, disc_loss = 0.000209367667247338
Trained batch 181 in epoch 15, gen_loss = 1.4285858836802807, disc_loss = 0.00021049166129419712
Trained batch 182 in epoch 15, gen_loss = 1.4284004025120554, disc_loss = 0.00021172847860089446
Trained batch 183 in epoch 15, gen_loss = 1.4283481376326603, disc_loss = 0.00021296260199407064
Trained batch 184 in epoch 15, gen_loss = 1.4285724433692726, disc_loss = 0.00021415666682563872
Trained batch 185 in epoch 15, gen_loss = 1.428801134709389, disc_loss = 0.00021536642261023474
Trained batch 186 in epoch 15, gen_loss = 1.4288630797901256, disc_loss = 0.0002165691844822047
Trained batch 187 in epoch 15, gen_loss = 1.4288887958577339, disc_loss = 0.0002176893755104368
Trained batch 188 in epoch 15, gen_loss = 1.4291674396979115, disc_loss = 0.0002186516514734769
Trained batch 189 in epoch 15, gen_loss = 1.4294159512770803, disc_loss = 0.00021943580922149857
Trained batch 190 in epoch 15, gen_loss = 1.4296004510050668, disc_loss = 0.0002201025379033569
Trained batch 191 in epoch 15, gen_loss = 1.4296099667747815, disc_loss = 0.00022067487918775441
Trained batch 192 in epoch 15, gen_loss = 1.4299476492590237, disc_loss = 0.00022113908843319487
Trained batch 193 in epoch 15, gen_loss = 1.429870274263559, disc_loss = 0.00022138748734261716
Trained batch 194 in epoch 15, gen_loss = 1.4299905734184462, disc_loss = 0.00022142604735936636
Trained batch 195 in epoch 15, gen_loss = 1.4299452815737044, disc_loss = 0.00022127377343743004
Trained batch 196 in epoch 15, gen_loss = 1.4297948930469262, disc_loss = 0.00022097820498676837
Trained batch 197 in epoch 15, gen_loss = 1.429915433580225, disc_loss = 0.00022059292608202962
Trained batch 198 in epoch 15, gen_loss = 1.429692930312612, disc_loss = 0.00022011616830474196
Trained batch 199 in epoch 15, gen_loss = 1.4297880440950395, disc_loss = 0.00021959157969831723
Trained batch 200 in epoch 15, gen_loss = 1.429642091343059, disc_loss = 0.00021907718658426416
Trained batch 201 in epoch 15, gen_loss = 1.4296090337309506, disc_loss = 0.0002186938573227098
Trained batch 202 in epoch 15, gen_loss = 1.429422154215169, disc_loss = 0.00021844635322733593
Trained batch 203 in epoch 15, gen_loss = 1.429275144548977, disc_loss = 0.0002183112231375394
Trained batch 204 in epoch 15, gen_loss = 1.4290799675918207, disc_loss = 0.00021821305996215924
Trained batch 205 in epoch 15, gen_loss = 1.428635366912027, disc_loss = 0.00021818180426387839
Trained batch 206 in epoch 15, gen_loss = 1.4284666644202337, disc_loss = 0.00021822906836275696
Trained batch 207 in epoch 15, gen_loss = 1.428754713672858, disc_loss = 0.0002182918887438763
Trained batch 208 in epoch 15, gen_loss = 1.4286508081061988, disc_loss = 0.0002182876693589488
Trained batch 209 in epoch 15, gen_loss = 1.4288126650310697, disc_loss = 0.00021821687495546593
Trained batch 210 in epoch 15, gen_loss = 1.4286129824923113, disc_loss = 0.0002181189302581261
Trained batch 211 in epoch 15, gen_loss = 1.4284601132824737, disc_loss = 0.00021806223539554267
Trained batch 212 in epoch 15, gen_loss = 1.4281709809818177, disc_loss = 0.00021805540038744958
Trained batch 213 in epoch 15, gen_loss = 1.4283640379103544, disc_loss = 0.00021811264904899192
Trained batch 214 in epoch 15, gen_loss = 1.4283924812494322, disc_loss = 0.00021824293842994023
Trained batch 215 in epoch 15, gen_loss = 1.4286160353157256, disc_loss = 0.0002184253885557323
Trained batch 216 in epoch 15, gen_loss = 1.4284701715416623, disc_loss = 0.0002185615980761632
Trained batch 217 in epoch 15, gen_loss = 1.428488296106321, disc_loss = 0.00021864612650344096
Trained batch 218 in epoch 15, gen_loss = 1.4286505109098948, disc_loss = 0.00021869704934245307
Trained batch 219 in epoch 15, gen_loss = 1.428347157348286, disc_loss = 0.00021880131898797118
Trained batch 220 in epoch 15, gen_loss = 1.4283455939314484, disc_loss = 0.00021897652008669762
Trained batch 221 in epoch 15, gen_loss = 1.4283586917696773, disc_loss = 0.00021913409714748546
Trained batch 222 in epoch 15, gen_loss = 1.428623804597042, disc_loss = 0.0002192222325192898
Trained batch 223 in epoch 15, gen_loss = 1.428779968193599, disc_loss = 0.00021923343060084984
Trained batch 224 in epoch 15, gen_loss = 1.4287776284747653, disc_loss = 0.0002191407815553248
Trained batch 225 in epoch 15, gen_loss = 1.4286016995927928, disc_loss = 0.0002190407523442373
Trained batch 226 in epoch 15, gen_loss = 1.4284824621309793, disc_loss = 0.00021895645317079968
Trained batch 227 in epoch 15, gen_loss = 1.428624306331601, disc_loss = 0.0002188412327086553
Trained batch 228 in epoch 15, gen_loss = 1.4285717499828756, disc_loss = 0.00021867013815231215
Trained batch 229 in epoch 15, gen_loss = 1.4284242225729902, disc_loss = 0.00021848228112187075
Trained batch 230 in epoch 15, gen_loss = 1.4280012097709622, disc_loss = 0.0002183446551529989
Trained batch 231 in epoch 15, gen_loss = 1.4280179738998413, disc_loss = 0.00021825171806367821
Trained batch 232 in epoch 15, gen_loss = 1.4280917659849568, disc_loss = 0.00021813029395626227
Trained batch 233 in epoch 15, gen_loss = 1.4284236466782725, disc_loss = 0.00021799959433384432
Trained batch 234 in epoch 15, gen_loss = 1.4283851527153177, disc_loss = 0.0002179309855799805
Trained batch 235 in epoch 15, gen_loss = 1.4285389578948586, disc_loss = 0.0002179819701700195
Trained batch 236 in epoch 15, gen_loss = 1.4282501121110553, disc_loss = 0.00021820054675662646
Trained batch 237 in epoch 15, gen_loss = 1.4283665113088464, disc_loss = 0.0002185800005784532
Trained batch 238 in epoch 15, gen_loss = 1.427982211112976, disc_loss = 0.00021914246648688368
Trained batch 239 in epoch 15, gen_loss = 1.427946865061919, disc_loss = 0.00021994174621795537
Trained batch 240 in epoch 15, gen_loss = 1.4277576559312115, disc_loss = 0.00022101020255692195
Trained batch 241 in epoch 15, gen_loss = 1.4277769721243991, disc_loss = 0.0002222351398783705
Trained batch 242 in epoch 15, gen_loss = 1.4274232740755435, disc_loss = 0.00022355462643634067
Trained batch 243 in epoch 15, gen_loss = 1.4273396061092127, disc_loss = 0.00022498411755029828
Trained batch 244 in epoch 15, gen_loss = 1.4276183206207897, disc_loss = 0.00022650078165924596
Trained batch 245 in epoch 15, gen_loss = 1.4277001120210664, disc_loss = 0.00022804441054236158
Trained batch 246 in epoch 15, gen_loss = 1.4275015457439038, disc_loss = 0.00022955859231485454
Trained batch 247 in epoch 15, gen_loss = 1.4276491812159937, disc_loss = 0.00023103024942693377
Trained batch 248 in epoch 15, gen_loss = 1.4276946342613803, disc_loss = 0.00023240578143687239
Trained batch 249 in epoch 15, gen_loss = 1.4278733067512512, disc_loss = 0.00023360574239632116
Trained batch 250 in epoch 15, gen_loss = 1.4280621877229547, disc_loss = 0.00023463074681655212
Trained batch 251 in epoch 15, gen_loss = 1.4280809632369451, disc_loss = 0.00023552655612648878
Trained batch 252 in epoch 15, gen_loss = 1.4284215468191819, disc_loss = 0.00023636882479363322
Trained batch 253 in epoch 15, gen_loss = 1.428325657769451, disc_loss = 0.00023717763319228388
Trained batch 254 in epoch 15, gen_loss = 1.4281293265959796, disc_loss = 0.0002380348219851251
Trained batch 255 in epoch 15, gen_loss = 1.427892568986863, disc_loss = 0.0002389513448974867
Trained batch 256 in epoch 15, gen_loss = 1.4280112522585382, disc_loss = 0.00023997547044935148
Trained batch 257 in epoch 15, gen_loss = 1.4283182219017383, disc_loss = 0.00024111818560794385
Trained batch 258 in epoch 15, gen_loss = 1.428559474042944, disc_loss = 0.00024230917213389355
Trained batch 259 in epoch 15, gen_loss = 1.4288283701126392, disc_loss = 0.00024347819243512975
Trained batch 260 in epoch 15, gen_loss = 1.4290494562565594, disc_loss = 0.0002445721500031329
Trained batch 261 in epoch 15, gen_loss = 1.428851950259609, disc_loss = 0.0002454752790655422
Trained batch 262 in epoch 15, gen_loss = 1.4288577770552255, disc_loss = 0.0002460702330280386
Trained batch 263 in epoch 15, gen_loss = 1.4287741337761735, disc_loss = 0.0002464030719486552
Trained batch 264 in epoch 15, gen_loss = 1.428896633184181, disc_loss = 0.0002465676852910481
Trained batch 265 in epoch 15, gen_loss = 1.428750185141886, disc_loss = 0.00024661798555538744
Trained batch 266 in epoch 15, gen_loss = 1.4288431281007632, disc_loss = 0.0002465712696061843
Trained batch 267 in epoch 15, gen_loss = 1.428979185534947, disc_loss = 0.00024644534989501653
Trained batch 268 in epoch 15, gen_loss = 1.4292161540027888, disc_loss = 0.00024622475576273697
Trained batch 269 in epoch 15, gen_loss = 1.429601526260376, disc_loss = 0.0002459059302863251
Trained batch 270 in epoch 15, gen_loss = 1.4294642944617464, disc_loss = 0.00024556042653348683
Trained batch 271 in epoch 15, gen_loss = 1.42934828470735, disc_loss = 0.0002452445937438717
Trained batch 272 in epoch 15, gen_loss = 1.4293884165557749, disc_loss = 0.00024494503643073743
Trained batch 273 in epoch 15, gen_loss = 1.429423942183056, disc_loss = 0.0002446192727563563
Trained batch 274 in epoch 15, gen_loss = 1.4293031133304943, disc_loss = 0.00024428902463775805
Trained batch 275 in epoch 15, gen_loss = 1.4291142626948978, disc_loss = 0.00024395634497615401
Trained batch 276 in epoch 15, gen_loss = 1.4290700023355036, disc_loss = 0.00024362933452767304
Trained batch 277 in epoch 15, gen_loss = 1.4290390559237638, disc_loss = 0.00024329677215574657
Trained batch 278 in epoch 15, gen_loss = 1.4291022426338607, disc_loss = 0.0002429575735380152
Trained batch 279 in epoch 15, gen_loss = 1.428953556929316, disc_loss = 0.0002426006675835067
Trained batch 280 in epoch 15, gen_loss = 1.4289286123900227, disc_loss = 0.0002422407733481974
Trained batch 281 in epoch 15, gen_loss = 1.4290437601136823, disc_loss = 0.00024189951425874012
Trained batch 282 in epoch 15, gen_loss = 1.4289411858198078, disc_loss = 0.00024159657243390768
Trained batch 283 in epoch 15, gen_loss = 1.4288848210388505, disc_loss = 0.0002413227024666873
Trained batch 284 in epoch 15, gen_loss = 1.4286785418527168, disc_loss = 0.0002410893873801749
Trained batch 285 in epoch 15, gen_loss = 1.4287847964080063, disc_loss = 0.0002408969776551858
Trained batch 286 in epoch 15, gen_loss = 1.4287468190807915, disc_loss = 0.00024074793347881178
Trained batch 287 in epoch 15, gen_loss = 1.4285382653276126, disc_loss = 0.00024064585381387992
Trained batch 288 in epoch 15, gen_loss = 1.4286407083788546, disc_loss = 0.00024055165125284292
Trained batch 289 in epoch 15, gen_loss = 1.428568002684363, disc_loss = 0.00024042385133537305
Trained batch 290 in epoch 15, gen_loss = 1.4286194253213627, disc_loss = 0.000240250450350533
Trained batch 291 in epoch 15, gen_loss = 1.428558790112195, disc_loss = 0.00024002914122395116
Trained batch 292 in epoch 15, gen_loss = 1.4285911956337938, disc_loss = 0.0002397447050693715
Trained batch 293 in epoch 15, gen_loss = 1.4284038353128499, disc_loss = 0.00023945674921273488
Trained batch 294 in epoch 15, gen_loss = 1.4287272392693213, disc_loss = 0.00023920379437987645
Trained batch 295 in epoch 15, gen_loss = 1.4288338330146428, disc_loss = 0.00023896768195570345
Trained batch 296 in epoch 15, gen_loss = 1.4288125897096062, disc_loss = 0.0002387305125355037
Trained batch 297 in epoch 15, gen_loss = 1.4287285964761005, disc_loss = 0.00023848369682243645
Trained batch 298 in epoch 15, gen_loss = 1.4287155691197884, disc_loss = 0.00023819688753533272
Trained batch 299 in epoch 15, gen_loss = 1.4288563446203868, disc_loss = 0.00023789346790484462
Trained batch 300 in epoch 15, gen_loss = 1.4287159034976136, disc_loss = 0.0002375821743672559
Trained batch 301 in epoch 15, gen_loss = 1.4285309504199502, disc_loss = 0.00023725489231554286
Trained batch 302 in epoch 15, gen_loss = 1.4288273404533713, disc_loss = 0.000236894748691952
Trained batch 303 in epoch 15, gen_loss = 1.428609311580658, disc_loss = 0.00023648439056207855
Trained batch 304 in epoch 15, gen_loss = 1.4284142658358714, disc_loss = 0.00023603605201418253
Trained batch 305 in epoch 15, gen_loss = 1.4283772200540779, disc_loss = 0.00023557482794417202
Trained batch 306 in epoch 15, gen_loss = 1.428494967544506, disc_loss = 0.0002350910284809756
Trained batch 307 in epoch 15, gen_loss = 1.428358942657322, disc_loss = 0.00023458100783157877
Trained batch 308 in epoch 15, gen_loss = 1.4284572400707258, disc_loss = 0.00023405212873380487
Trained batch 309 in epoch 15, gen_loss = 1.4284491377492106, disc_loss = 0.0002335184364534554
Trained batch 310 in epoch 15, gen_loss = 1.4283897171449815, disc_loss = 0.0002329856222997033
Trained batch 311 in epoch 15, gen_loss = 1.4284817622258112, disc_loss = 0.00023245294736485588
Trained batch 312 in epoch 15, gen_loss = 1.4284238701049512, disc_loss = 0.00023196166120514203
Trained batch 313 in epoch 15, gen_loss = 1.428359640631706, disc_loss = 0.00023154259246335051
Trained batch 314 in epoch 15, gen_loss = 1.4281504699162075, disc_loss = 0.0002311945473405695
Trained batch 315 in epoch 15, gen_loss = 1.4281185450433176, disc_loss = 0.00023089629338974652
Trained batch 316 in epoch 15, gen_loss = 1.4282450010347818, disc_loss = 0.00023061379781859554
Trained batch 317 in epoch 15, gen_loss = 1.4281913758073963, disc_loss = 0.00023031344933072164
Trained batch 318 in epoch 15, gen_loss = 1.4279397221568235, disc_loss = 0.00022998953502344953
Trained batch 319 in epoch 15, gen_loss = 1.4280328135937452, disc_loss = 0.00022966818960412638
Trained batch 320 in epoch 15, gen_loss = 1.4278700444557213, disc_loss = 0.00022936199954565835
Trained batch 321 in epoch 15, gen_loss = 1.4277747232721458, disc_loss = 0.00022906520570590744
Trained batch 322 in epoch 15, gen_loss = 1.4279489635313996, disc_loss = 0.0002288114324200541
Trained batch 323 in epoch 15, gen_loss = 1.4281058749298992, disc_loss = 0.00022860011975151591
Trained batch 324 in epoch 15, gen_loss = 1.428214665559622, disc_loss = 0.0002284267087144634
Trained batch 325 in epoch 15, gen_loss = 1.4281322162575516, disc_loss = 0.00022829366903937782
Trained batch 326 in epoch 15, gen_loss = 1.4282953881342477, disc_loss = 0.0002281979602706029
Trained batch 327 in epoch 15, gen_loss = 1.4282161437156724, disc_loss = 0.00022811744716685697
Trained batch 328 in epoch 15, gen_loss = 1.428192537606306, disc_loss = 0.00022805483714892532
Trained batch 329 in epoch 15, gen_loss = 1.4281758871945467, disc_loss = 0.0002280636841367761
Trained batch 330 in epoch 15, gen_loss = 1.4282514267457576, disc_loss = 0.00022818069872333811
Trained batch 331 in epoch 15, gen_loss = 1.428148134286145, disc_loss = 0.00022839292665068284
Trained batch 332 in epoch 15, gen_loss = 1.4281771351267267, disc_loss = 0.00022866295179696167
Trained batch 333 in epoch 15, gen_loss = 1.4280040942266317, disc_loss = 0.00022890011776129934
Trained batch 334 in epoch 15, gen_loss = 1.42815690396437, disc_loss = 0.00022903588989666148
Trained batch 335 in epoch 15, gen_loss = 1.427936159429096, disc_loss = 0.00022908123165030876
Trained batch 336 in epoch 15, gen_loss = 1.4281103250180933, disc_loss = 0.00022907473832798586
Trained batch 337 in epoch 15, gen_loss = 1.428007341700898, disc_loss = 0.0002289787026986028
Trained batch 338 in epoch 15, gen_loss = 1.4279425555625849, disc_loss = 0.0002287827620343209
Trained batch 339 in epoch 15, gen_loss = 1.4278242766857148, disc_loss = 0.00022850444340078598
Trained batch 340 in epoch 15, gen_loss = 1.427952546528008, disc_loss = 0.00022818559022907774
Trained batch 341 in epoch 15, gen_loss = 1.4278855313334549, disc_loss = 0.00022784524482939725
Trained batch 342 in epoch 15, gen_loss = 1.4280708760631329, disc_loss = 0.0002274845479702463
Trained batch 343 in epoch 15, gen_loss = 1.4278874723024146, disc_loss = 0.00022711160130880714
Trained batch 344 in epoch 15, gen_loss = 1.4277660787969395, disc_loss = 0.00022677107850356244
Trained batch 345 in epoch 15, gen_loss = 1.427962800326375, disc_loss = 0.00022648892570552794
Trained batch 346 in epoch 15, gen_loss = 1.428089956385258, disc_loss = 0.00022627144379045423
Trained batch 347 in epoch 15, gen_loss = 1.4278794756565971, disc_loss = 0.0002260922653800955
Trained batch 348 in epoch 15, gen_loss = 1.427814290653327, disc_loss = 0.00022591408104872607
Trained batch 349 in epoch 15, gen_loss = 1.4277547236851285, disc_loss = 0.00022573017542267085
Trained batch 350 in epoch 15, gen_loss = 1.4277194996505043, disc_loss = 0.0002255483342945228
Trained batch 351 in epoch 15, gen_loss = 1.4278007214042274, disc_loss = 0.00022537475927658141
Trained batch 352 in epoch 15, gen_loss = 1.4278601995608624, disc_loss = 0.0002252179314506045
Trained batch 353 in epoch 15, gen_loss = 1.4279706404034027, disc_loss = 0.00022506125786885656
Trained batch 354 in epoch 15, gen_loss = 1.4280988330572424, disc_loss = 0.0002248776824300466
Trained batch 355 in epoch 15, gen_loss = 1.4280231588342216, disc_loss = 0.00022468352850164898
Trained batch 356 in epoch 15, gen_loss = 1.4281231151575469, disc_loss = 0.0002245126329895555
Trained batch 357 in epoch 15, gen_loss = 1.4281234265039753, disc_loss = 0.00022439010059295154
Trained batch 358 in epoch 15, gen_loss = 1.4280616280760274, disc_loss = 0.00022429130945246392
Trained batch 359 in epoch 15, gen_loss = 1.4279808104038239, disc_loss = 0.00022419822960526088
Trained batch 360 in epoch 15, gen_loss = 1.4280271318810798, disc_loss = 0.0002241138711036699
Trained batch 361 in epoch 15, gen_loss = 1.4281683462100794, disc_loss = 0.0002240460351418552
Trained batch 362 in epoch 15, gen_loss = 1.4284075695621081, disc_loss = 0.00022399939600100546
Trained batch 363 in epoch 15, gen_loss = 1.4283017286887536, disc_loss = 0.00022397260087658012
Trained batch 364 in epoch 15, gen_loss = 1.4282132877062446, disc_loss = 0.00022398749450524657
Trained batch 365 in epoch 15, gen_loss = 1.428138414693009, disc_loss = 0.00022407562665236082
Trained batch 366 in epoch 15, gen_loss = 1.42811055436771, disc_loss = 0.0002242186412966064
Trained batch 367 in epoch 15, gen_loss = 1.428173934959847, disc_loss = 0.00022439027434697692
Trained batch 368 in epoch 15, gen_loss = 1.4281978817166998, disc_loss = 0.00022462318819139258
Trained batch 369 in epoch 15, gen_loss = 1.4282230670387681, disc_loss = 0.0002249404770515645
Trained batch 370 in epoch 15, gen_loss = 1.4284693201918486, disc_loss = 0.00022536988909129741
Trained batch 371 in epoch 15, gen_loss = 1.4285283184820605, disc_loss = 0.0002259383410844709
Trained batch 372 in epoch 15, gen_loss = 1.428508325172813, disc_loss = 0.00022662071149965408
Trained batch 373 in epoch 15, gen_loss = 1.4284182398077, disc_loss = 0.00022741721561013591
Trained batch 374 in epoch 15, gen_loss = 1.4283402910232543, disc_loss = 0.00022828966773037488
Trained batch 375 in epoch 15, gen_loss = 1.428402896574203, disc_loss = 0.0002291869755703993
Trained batch 376 in epoch 15, gen_loss = 1.4282660557041118, disc_loss = 0.0002300237285660948
Trained batch 377 in epoch 15, gen_loss = 1.4283078246646457, disc_loss = 0.0002307691628865777
Trained batch 378 in epoch 15, gen_loss = 1.4282596312600893, disc_loss = 0.00023145072974524482
Trained batch 379 in epoch 15, gen_loss = 1.4283682512609581, disc_loss = 0.00023205906317774573
Trained batch 380 in epoch 15, gen_loss = 1.4284045111163082, disc_loss = 0.0002326280377391821
Trained batch 381 in epoch 15, gen_loss = 1.42847171909522, disc_loss = 0.00023317783183758928
Trained batch 382 in epoch 15, gen_loss = 1.4285292687677529, disc_loss = 0.00023369534389409491
Trained batch 383 in epoch 15, gen_loss = 1.4283975698053837, disc_loss = 0.00023417412866895879
Trained batch 384 in epoch 15, gen_loss = 1.4283988965022099, disc_loss = 0.0002345771827945159
Trained batch 385 in epoch 15, gen_loss = 1.428338835894135, disc_loss = 0.00023488405549586895
Trained batch 386 in epoch 15, gen_loss = 1.4283915068136013, disc_loss = 0.00023509379291232526
Trained batch 387 in epoch 15, gen_loss = 1.4283096762662082, disc_loss = 0.00023524174274328842
Trained batch 388 in epoch 15, gen_loss = 1.4280792376682507, disc_loss = 0.0002353656753276087
Trained batch 389 in epoch 15, gen_loss = 1.4280622191918202, disc_loss = 0.00023549524774306262
Trained batch 390 in epoch 15, gen_loss = 1.428080398103465, disc_loss = 0.00023564407958865256
Trained batch 391 in epoch 15, gen_loss = 1.4281810427806816, disc_loss = 0.00023580775092452722
Trained batch 392 in epoch 15, gen_loss = 1.4281687848743896, disc_loss = 0.0002359880588090571
Trained batch 393 in epoch 15, gen_loss = 1.4281431917611718, disc_loss = 0.0002361814545041723
Trained batch 394 in epoch 15, gen_loss = 1.4280307996122144, disc_loss = 0.00023641160678610653
Trained batch 395 in epoch 15, gen_loss = 1.4278392894099456, disc_loss = 0.00023669145004091797
Trained batch 396 in epoch 15, gen_loss = 1.4276872341819014, disc_loss = 0.00023697910106301623
Trained batch 397 in epoch 15, gen_loss = 1.4276661747065023, disc_loss = 0.00023721925885841863
Trained batch 398 in epoch 15, gen_loss = 1.4276837845493977, disc_loss = 0.00023738829072032073
Trained batch 399 in epoch 15, gen_loss = 1.4276991719007492, disc_loss = 0.0002375001597647497
Trained batch 400 in epoch 15, gen_loss = 1.427783763914037, disc_loss = 0.00023759510899017775
Trained batch 401 in epoch 15, gen_loss = 1.4277551773175672, disc_loss = 0.00023768116780183168
Trained batch 402 in epoch 15, gen_loss = 1.4277687344894219, disc_loss = 0.00023773629784167494
Trained batch 403 in epoch 15, gen_loss = 1.427511424711435, disc_loss = 0.0002377118253027202
Trained batch 404 in epoch 15, gen_loss = 1.427593868161425, disc_loss = 0.00023761664800716703
Trained batch 405 in epoch 15, gen_loss = 1.4277184323724268, disc_loss = 0.00023747157907842318
Trained batch 406 in epoch 15, gen_loss = 1.4276778243976378, disc_loss = 0.00023732829839491723
Trained batch 407 in epoch 15, gen_loss = 1.4276208608758216, disc_loss = 0.00023723565788945873
Trained batch 408 in epoch 15, gen_loss = 1.4275168471930955, disc_loss = 0.00023720477729245067
Trained batch 409 in epoch 15, gen_loss = 1.4275212869411562, disc_loss = 0.00023719633426503051
Trained batch 410 in epoch 15, gen_loss = 1.4276100429015148, disc_loss = 0.0002372032988621341
Trained batch 411 in epoch 15, gen_loss = 1.4276325610077496, disc_loss = 0.00023721345784456256
Trained batch 412 in epoch 15, gen_loss = 1.4277088844170005, disc_loss = 0.00023722158103026155
Trained batch 413 in epoch 15, gen_loss = 1.4277496599920705, disc_loss = 0.0002371940677902596
Trained batch 414 in epoch 15, gen_loss = 1.427721876983183, disc_loss = 0.00023716642969801282
Trained batch 415 in epoch 15, gen_loss = 1.4277456915722444, disc_loss = 0.00023717232535930705
Trained batch 416 in epoch 15, gen_loss = 1.427664144147786, disc_loss = 0.00023721996106794194
Trained batch 417 in epoch 15, gen_loss = 1.427722395607159, disc_loss = 0.0002372655351739544
Trained batch 418 in epoch 15, gen_loss = 1.4278316938791753, disc_loss = 0.00023733549468985565
Trained batch 419 in epoch 15, gen_loss = 1.4279312488578615, disc_loss = 0.00023744948555845657
Trained batch 420 in epoch 15, gen_loss = 1.4280242832143064, disc_loss = 0.00023760845979181784
Trained batch 421 in epoch 15, gen_loss = 1.4281173297579255, disc_loss = 0.00023779161050637094
Trained batch 422 in epoch 15, gen_loss = 1.4284319206896121, disc_loss = 0.0002379609732281793
Trained batch 423 in epoch 15, gen_loss = 1.4284128001276053, disc_loss = 0.00023806279978947164
Trained batch 424 in epoch 15, gen_loss = 1.428550367635839, disc_loss = 0.0002380598198643009
Trained batch 425 in epoch 15, gen_loss = 1.4285266105557832, disc_loss = 0.00023803000656809733
Trained batch 426 in epoch 15, gen_loss = 1.428515336831783, disc_loss = 0.00023805149380006966
Trained batch 427 in epoch 15, gen_loss = 1.428526637431617, disc_loss = 0.00023814940513462528
Trained batch 428 in epoch 15, gen_loss = 1.4284622788707138, disc_loss = 0.0002383035942940595
Trained batch 429 in epoch 15, gen_loss = 1.428418236555055, disc_loss = 0.00023847563122196102
Trained batch 430 in epoch 15, gen_loss = 1.4285026824667946, disc_loss = 0.00023863197387298223
Trained batch 431 in epoch 15, gen_loss = 1.4284009983142216, disc_loss = 0.0002387687396987059
Trained batch 432 in epoch 15, gen_loss = 1.4285531374378513, disc_loss = 0.00023891400360928711
Trained batch 433 in epoch 15, gen_loss = 1.4285367416896029, disc_loss = 0.00023908725129142682
Trained batch 434 in epoch 15, gen_loss = 1.4285510608519632, disc_loss = 0.00023926317656008613
Trained batch 435 in epoch 15, gen_loss = 1.4283325521770966, disc_loss = 0.00023948971909770438
Trained batch 436 in epoch 15, gen_loss = 1.4283330323221481, disc_loss = 0.00023969102422645512
Trained batch 437 in epoch 15, gen_loss = 1.4281896379984678, disc_loss = 0.0002399162503394466
Trained batch 438 in epoch 15, gen_loss = 1.428223754930605, disc_loss = 0.0002401391296878994
Trained batch 439 in epoch 15, gen_loss = 1.4283481234853919, disc_loss = 0.0002403211937483072
Trained batch 440 in epoch 15, gen_loss = 1.428460056819613, disc_loss = 0.00024045885926550213
Trained batch 441 in epoch 15, gen_loss = 1.428408625438742, disc_loss = 0.00024055042390027336
Trained batch 442 in epoch 15, gen_loss = 1.4284684897545499, disc_loss = 0.0002405945314694896
Trained batch 443 in epoch 15, gen_loss = 1.4283033187861915, disc_loss = 0.00024059326498392184
Trained batch 444 in epoch 15, gen_loss = 1.4282148109393173, disc_loss = 0.00024064182484682042
Trained batch 445 in epoch 15, gen_loss = 1.4281751660488111, disc_loss = 0.00024074695283255221
Trained batch 446 in epoch 15, gen_loss = 1.4282134075292805, disc_loss = 0.00024099018250842594
Trained batch 447 in epoch 15, gen_loss = 1.4280168802610465, disc_loss = 0.00024125674919365077
Trained batch 448 in epoch 15, gen_loss = 1.4280061849241532, disc_loss = 0.0002414633239831263
Trained batch 449 in epoch 15, gen_loss = 1.427950668334961, disc_loss = 0.00024172208571043383
Trained batch 450 in epoch 15, gen_loss = 1.4278972709258222, disc_loss = 0.00024189255661405973
Trained batch 451 in epoch 15, gen_loss = 1.427965407350422, disc_loss = 0.00024201532005060946
Trained batch 452 in epoch 15, gen_loss = 1.4280483991105035, disc_loss = 0.00024224649260612616
Trained batch 453 in epoch 15, gen_loss = 1.4281463906628444, disc_loss = 0.0002427762350723166
Trained batch 454 in epoch 15, gen_loss = 1.4281952569772909, disc_loss = 0.00024306337039848626
Trained batch 455 in epoch 15, gen_loss = 1.4282612021554981, disc_loss = 0.00024332509349876905
Trained batch 456 in epoch 15, gen_loss = 1.428218073604926, disc_loss = 0.00024348188566945236
Trained batch 457 in epoch 15, gen_loss = 1.4282523640899158, disc_loss = 0.0002435399567146377
Trained batch 458 in epoch 15, gen_loss = 1.4283930180119533, disc_loss = 0.00024353326234572377
Trained batch 459 in epoch 15, gen_loss = 1.4282817796520564, disc_loss = 0.00024347263538600046
Trained batch 460 in epoch 15, gen_loss = 1.428403276424863, disc_loss = 0.00024332532789161703
Trained batch 461 in epoch 15, gen_loss = 1.4284631960835807, disc_loss = 0.00024308876338371003
Trained batch 462 in epoch 15, gen_loss = 1.428408868626951, disc_loss = 0.00024287135894503345
Trained batch 463 in epoch 15, gen_loss = 1.428450141744367, disc_loss = 0.00024275369568040959
Trained batch 464 in epoch 15, gen_loss = 1.4286344974271712, disc_loss = 0.00024262180816950478
Trained batch 465 in epoch 15, gen_loss = 1.428491085639839, disc_loss = 0.0002448767491049471
Trained batch 466 in epoch 15, gen_loss = 1.4285423625460019, disc_loss = 0.0002452280710378265
Trained batch 467 in epoch 15, gen_loss = 1.4286084613229475, disc_loss = 0.00024572081192439864
Trained batch 468 in epoch 15, gen_loss = 1.4283730312705294, disc_loss = 0.00024645900155399254
Trained batch 469 in epoch 15, gen_loss = 1.4284122413777292, disc_loss = 0.0002472402899931036
Trained batch 470 in epoch 15, gen_loss = 1.4282389195861331, disc_loss = 0.0002481883328926805
Trained batch 471 in epoch 15, gen_loss = 1.4283697488954512, disc_loss = 0.0002492693212874563
Trained batch 472 in epoch 15, gen_loss = 1.428343368635117, disc_loss = 0.0002505960508000379
Trained batch 473 in epoch 15, gen_loss = 1.4285001913203468, disc_loss = 0.0002521759099473161
Trained batch 474 in epoch 15, gen_loss = 1.4283427180741963, disc_loss = 0.0002540116392437516
Trained batch 475 in epoch 15, gen_loss = 1.4284343691934056, disc_loss = 0.00025600887875807835
Trained batch 476 in epoch 15, gen_loss = 1.4283475296052497, disc_loss = 0.0002581868206454193
Trained batch 477 in epoch 15, gen_loss = 1.4284371082752818, disc_loss = 0.0002605357126469936
Trained batch 478 in epoch 15, gen_loss = 1.4284291466491954, disc_loss = 0.00026302304904067515
Trained batch 479 in epoch 15, gen_loss = 1.4286139716704687, disc_loss = 0.0002655898572963148
Trained batch 480 in epoch 15, gen_loss = 1.4286552020764895, disc_loss = 0.00026827862247785463
Trained batch 481 in epoch 15, gen_loss = 1.4286713508649487, disc_loss = 0.00027095157482757434
Trained batch 482 in epoch 15, gen_loss = 1.4287117068071542, disc_loss = 0.00027341886517708914
Trained batch 483 in epoch 15, gen_loss = 1.4287170292424762, disc_loss = 0.00027551470172083035
Trained batch 484 in epoch 15, gen_loss = 1.4287415973918953, disc_loss = 0.0002770633161153174
Trained batch 485 in epoch 15, gen_loss = 1.4286898975509674, disc_loss = 0.000278030198836702
Trained batch 486 in epoch 15, gen_loss = 1.4285939887808579, disc_loss = 0.0002784733511563687
Trained batch 487 in epoch 15, gen_loss = 1.4286014940895018, disc_loss = 0.0002785687295086138
Trained batch 488 in epoch 15, gen_loss = 1.428649594447364, disc_loss = 0.0002784118938667115
Trained batch 489 in epoch 15, gen_loss = 1.4286026368335802, disc_loss = 0.0002780738305532117
Trained batch 490 in epoch 15, gen_loss = 1.428517615722299, disc_loss = 0.0002776396676976008
Trained batch 491 in epoch 15, gen_loss = 1.42847345684602, disc_loss = 0.00027716145748529265
Trained batch 492 in epoch 15, gen_loss = 1.4283829999985609, disc_loss = 0.0002766734498333253
Trained batch 493 in epoch 15, gen_loss = 1.4283659364047803, disc_loss = 0.00027618351027501234
Trained batch 494 in epoch 15, gen_loss = 1.4283400196017642, disc_loss = 0.000275700168710289
Trained batch 495 in epoch 15, gen_loss = 1.4284610075335349, disc_loss = 0.0002752263476542148
Trained batch 496 in epoch 15, gen_loss = 1.4285545874409513, disc_loss = 0.0002747549207606334
Trained batch 497 in epoch 15, gen_loss = 1.4285139743104038, disc_loss = 0.00027427728150450635
Trained batch 498 in epoch 15, gen_loss = 1.4284093439698458, disc_loss = 0.00027380001211168203
Trained batch 499 in epoch 15, gen_loss = 1.4283074824810027, disc_loss = 0.00027331423471332525
Trained batch 500 in epoch 15, gen_loss = 1.4284115387294107, disc_loss = 0.0002728277108209529
Trained batch 501 in epoch 15, gen_loss = 1.428369537055255, disc_loss = 0.00027234046798453
Trained batch 502 in epoch 15, gen_loss = 1.4283551738465994, disc_loss = 0.00027187430395592105
Trained batch 503 in epoch 15, gen_loss = 1.4284216250692094, disc_loss = 0.0002713681283672659
Trained batch 504 in epoch 15, gen_loss = 1.4283101926935782, disc_loss = 0.0002708712599636747
Trained batch 505 in epoch 15, gen_loss = 1.428479562635007, disc_loss = 0.0002703701133925832
Trained batch 506 in epoch 15, gen_loss = 1.4284027292883608, disc_loss = 0.0002698745026788858
Trained batch 507 in epoch 15, gen_loss = 1.4282891473432227, disc_loss = 0.00026939064302252774
Trained batch 508 in epoch 15, gen_loss = 1.428223420688352, disc_loss = 0.0002689166329269037
Trained batch 509 in epoch 15, gen_loss = 1.4282782292833516, disc_loss = 0.00026846635876912235
Trained batch 510 in epoch 15, gen_loss = 1.428427305706793, disc_loss = 0.0002680517301174305
Trained batch 511 in epoch 15, gen_loss = 1.4283693593461066, disc_loss = 0.0002676801638976656
Trained batch 512 in epoch 15, gen_loss = 1.4282574177253085, disc_loss = 0.00026740648572173283
Trained batch 513 in epoch 15, gen_loss = 1.4283634644538048, disc_loss = 0.0002670617269051471
Trained batch 514 in epoch 15, gen_loss = 1.4284774752496516, disc_loss = 0.00026670816781898413
Trained batch 515 in epoch 15, gen_loss = 1.4282824720523155, disc_loss = 0.0002663295493277488
Trained batch 516 in epoch 15, gen_loss = 1.4281032966230087, disc_loss = 0.0002659306942783461
Trained batch 517 in epoch 15, gen_loss = 1.428365428015072, disc_loss = 0.00026551483716927743
Trained batch 518 in epoch 15, gen_loss = 1.4284404677003335, disc_loss = 0.00026510388941001275
Trained batch 519 in epoch 15, gen_loss = 1.428314426770577, disc_loss = 0.0002647079667615169
Trained batch 520 in epoch 15, gen_loss = 1.4282074304093784, disc_loss = 0.000264323345174922
Trained batch 521 in epoch 15, gen_loss = 1.4281700342551045, disc_loss = 0.0002639473308507191
Trained batch 522 in epoch 15, gen_loss = 1.4282234804580134, disc_loss = 0.0002635792943988279
Trained batch 523 in epoch 15, gen_loss = 1.42825012079632, disc_loss = 0.0002632243705151448
Trained batch 524 in epoch 15, gen_loss = 1.428125607172648, disc_loss = 0.00026290386990391804
Trained batch 525 in epoch 15, gen_loss = 1.4280934243147818, disc_loss = 0.00026261838355970667
Trained batch 526 in epoch 15, gen_loss = 1.4279409178746494, disc_loss = 0.00026237664709148324
Trained batch 527 in epoch 15, gen_loss = 1.4279065235997692, disc_loss = 0.0002621863153742445
Trained batch 528 in epoch 15, gen_loss = 1.427899607863904, disc_loss = 0.0002620343499875987
Trained batch 529 in epoch 15, gen_loss = 1.4279735882327242, disc_loss = 0.00026191232373780365
Trained batch 530 in epoch 15, gen_loss = 1.427979055995546, disc_loss = 0.0002618020983283128
Trained batch 531 in epoch 15, gen_loss = 1.428013788354128, disc_loss = 0.00026169772397217894
Trained batch 532 in epoch 15, gen_loss = 1.4280193565486743, disc_loss = 0.00026162198519432594
Trained batch 533 in epoch 15, gen_loss = 1.4279645478234309, disc_loss = 0.0002615768380428733
Trained batch 534 in epoch 15, gen_loss = 1.4279737227430969, disc_loss = 0.0002615259320315498
Trained batch 535 in epoch 15, gen_loss = 1.4280019980757983, disc_loss = 0.00026148278380557047
Trained batch 536 in epoch 15, gen_loss = 1.4279046382761977, disc_loss = 0.00026142622693130175
Trained batch 537 in epoch 15, gen_loss = 1.428029642007608, disc_loss = 0.0002613570773791486
Trained batch 538 in epoch 15, gen_loss = 1.4279935432940114, disc_loss = 0.0002613067475258183
Trained batch 539 in epoch 15, gen_loss = 1.4280235782817559, disc_loss = 0.00026125355793232705
Trained batch 540 in epoch 15, gen_loss = 1.428107286997952, disc_loss = 0.000261206752738048
Trained batch 541 in epoch 15, gen_loss = 1.4281187721724, disc_loss = 0.000261207969155515
Trained batch 542 in epoch 15, gen_loss = 1.4280993624506295, disc_loss = 0.00026122918850211125
Trained batch 543 in epoch 15, gen_loss = 1.4281207627671606, disc_loss = 0.00026128866835506415
Trained batch 544 in epoch 15, gen_loss = 1.4280020243530973, disc_loss = 0.0002613558893770443
Trained batch 545 in epoch 15, gen_loss = 1.4279765416850974, disc_loss = 0.0002613952785875401
Trained batch 546 in epoch 15, gen_loss = 1.427930968771033, disc_loss = 0.0002614126347189301
Trained batch 547 in epoch 15, gen_loss = 1.4278872485143426, disc_loss = 0.0002614262094924341
Trained batch 548 in epoch 15, gen_loss = 1.427801479841625, disc_loss = 0.000261419442498753
Trained batch 549 in epoch 15, gen_loss = 1.4279223110459067, disc_loss = 0.00026140336238644193
Trained batch 550 in epoch 15, gen_loss = 1.4279191465862433, disc_loss = 0.0002613928049777479
Trained batch 551 in epoch 15, gen_loss = 1.4279269461614499, disc_loss = 0.00026140500990154777
Trained batch 552 in epoch 15, gen_loss = 1.4277761019160045, disc_loss = 0.0002614221728067547
Trained batch 553 in epoch 15, gen_loss = 1.4277253114359474, disc_loss = 0.00026139897755499017
Trained batch 554 in epoch 15, gen_loss = 1.4276591960374299, disc_loss = 0.0002613530728184914
Trained batch 555 in epoch 15, gen_loss = 1.4277046957461954, disc_loss = 0.00026130133910032293
Trained batch 556 in epoch 15, gen_loss = 1.4275335206163635, disc_loss = 0.00026126135058636353
Trained batch 557 in epoch 15, gen_loss = 1.4276046829838906, disc_loss = 0.00026119811121470024
Trained batch 558 in epoch 15, gen_loss = 1.4276490313848997, disc_loss = 0.00026110800795460873
Trained batch 559 in epoch 15, gen_loss = 1.4278066364782198, disc_loss = 0.0002609953507252223
Trained batch 560 in epoch 15, gen_loss = 1.4278479013425993, disc_loss = 0.00026084176358823815
Trained batch 561 in epoch 15, gen_loss = 1.4279282778183335, disc_loss = 0.00026062016141716596
Trained batch 562 in epoch 15, gen_loss = 1.4278600692325545, disc_loss = 0.00026037010846244026
Trained batch 563 in epoch 15, gen_loss = 1.427947186620523, disc_loss = 0.0002600726097883751
Trained batch 564 in epoch 15, gen_loss = 1.4278529975266583, disc_loss = 0.00025974470214205854
Trained batch 565 in epoch 15, gen_loss = 1.4278155141921431, disc_loss = 0.00025940189701838723
Trained batch 566 in epoch 15, gen_loss = 1.4278990103874678, disc_loss = 0.0002590607682850372
Trained batch 567 in epoch 15, gen_loss = 1.4279687159078223, disc_loss = 0.0002587306454848069
Trained batch 568 in epoch 15, gen_loss = 1.4280634536055983, disc_loss = 0.0002583968262994502
Trained batch 569 in epoch 15, gen_loss = 1.4280779679616293, disc_loss = 0.0002580654451919959
Trained batch 570 in epoch 15, gen_loss = 1.4279828633193168, disc_loss = 0.00025774965291095494
Trained batch 571 in epoch 15, gen_loss = 1.4279877370470888, disc_loss = 0.0002574372715698573
Trained batch 572 in epoch 15, gen_loss = 1.4280890163950895, disc_loss = 0.0002571262175352225
Trained batch 573 in epoch 15, gen_loss = 1.4279380341024763, disc_loss = 0.00025682007091701255
Trained batch 574 in epoch 15, gen_loss = 1.4279690193093342, disc_loss = 0.0002565110621261461
Trained batch 575 in epoch 15, gen_loss = 1.4278822634369135, disc_loss = 0.0002562048589077727
Trained batch 576 in epoch 15, gen_loss = 1.427895948213349, disc_loss = 0.00025589698744598113
Trained batch 577 in epoch 15, gen_loss = 1.42798954929035, disc_loss = 0.00025561037730242013
Trained batch 578 in epoch 15, gen_loss = 1.428022834715242, disc_loss = 0.0002553339256874709
Trained batch 579 in epoch 15, gen_loss = 1.4280658678761844, disc_loss = 0.0002550440577390967
Trained batch 580 in epoch 15, gen_loss = 1.4280012454100197, disc_loss = 0.00025473250836743986
Trained batch 581 in epoch 15, gen_loss = 1.4279303024314933, disc_loss = 0.00025439597827097246
Trained batch 582 in epoch 15, gen_loss = 1.4277868377201348, disc_loss = 0.0002540537286876039
Trained batch 583 in epoch 15, gen_loss = 1.4278204657443583, disc_loss = 0.0002537186524801804
Trained batch 584 in epoch 15, gen_loss = 1.4277629929730016, disc_loss = 0.0002533967615771615
Trained batch 585 in epoch 15, gen_loss = 1.4278825090200014, disc_loss = 0.000253084893724157
Trained batch 586 in epoch 15, gen_loss = 1.4280153352519722, disc_loss = 0.0002528011178301266
Trained batch 587 in epoch 15, gen_loss = 1.428036680432404, disc_loss = 0.00025255458815366113
Trained batch 588 in epoch 15, gen_loss = 1.4281970098589394, disc_loss = 0.00025231442091994344
Trained batch 589 in epoch 15, gen_loss = 1.428089957116014, disc_loss = 0.0002521110897960479
Trained batch 590 in epoch 15, gen_loss = 1.4280326283724376, disc_loss = 0.00025193611059497705
Trained batch 591 in epoch 15, gen_loss = 1.4281799076376736, disc_loss = 0.0002517907723168301
Trained batch 592 in epoch 15, gen_loss = 1.428060421654185, disc_loss = 0.00025167656203664264
Trained batch 593 in epoch 15, gen_loss = 1.4280068234161094, disc_loss = 0.0002515826088294568
Trained batch 594 in epoch 15, gen_loss = 1.4280711937351387, disc_loss = 0.00025151456629369747
Trained batch 595 in epoch 15, gen_loss = 1.4280798831242043, disc_loss = 0.00025146319096727395
Trained batch 596 in epoch 15, gen_loss = 1.4281298445297446, disc_loss = 0.00025141958784975695
Trained batch 597 in epoch 15, gen_loss = 1.4281265155527505, disc_loss = 0.0002513970739558722
Trained batch 598 in epoch 15, gen_loss = 1.4280523051801628, disc_loss = 0.00025139929941803965
Trained batch 599 in epoch 15, gen_loss = 1.4279872818787893, disc_loss = 0.0002514317063802688
Trained batch 600 in epoch 15, gen_loss = 1.4279963343393387, disc_loss = 0.00025148084136277665
Trained batch 601 in epoch 15, gen_loss = 1.427796367592986, disc_loss = 0.00025155774195404607
Trained batch 602 in epoch 15, gen_loss = 1.42781554288532, disc_loss = 0.0002516737873629066
Trained batch 603 in epoch 15, gen_loss = 1.4278609101345996, disc_loss = 0.0002518016118928009
Trained batch 604 in epoch 15, gen_loss = 1.4279168917127878, disc_loss = 0.0002519085793653724
Trained batch 605 in epoch 15, gen_loss = 1.4278319013787575, disc_loss = 0.000252012592619115
Trained batch 606 in epoch 15, gen_loss = 1.4278018260512753, disc_loss = 0.00025208314314510585
Trained batch 607 in epoch 15, gen_loss = 1.4277763615705465, disc_loss = 0.0002521283001388646
Trained batch 608 in epoch 15, gen_loss = 1.4277289506837065, disc_loss = 0.00025215913608078315
Trained batch 609 in epoch 15, gen_loss = 1.427806914438967, disc_loss = 0.0002521556167624515
Trained batch 610 in epoch 15, gen_loss = 1.427829041223479, disc_loss = 0.00025211762023421213
Trained batch 611 in epoch 15, gen_loss = 1.4278071251959583, disc_loss = 0.0002520391382615368
Trained batch 612 in epoch 15, gen_loss = 1.4277632907397595, disc_loss = 0.0002519253544933814
Trained batch 613 in epoch 15, gen_loss = 1.4277332201842765, disc_loss = 0.0002517883606176702
Trained batch 614 in epoch 15, gen_loss = 1.4277452558036743, disc_loss = 0.0002516224120105418
Trained batch 615 in epoch 15, gen_loss = 1.4277800708622128, disc_loss = 0.00025142572656465756
Trained batch 616 in epoch 15, gen_loss = 1.4276289010550254, disc_loss = 0.0002512101838942321
Trained batch 617 in epoch 15, gen_loss = 1.4276062971565715, disc_loss = 0.00025099457120646715
Trained batch 618 in epoch 15, gen_loss = 1.427587668807133, disc_loss = 0.00025077417580683447
Trained batch 619 in epoch 15, gen_loss = 1.4275418268096063, disc_loss = 0.0002505728688799624
Trained batch 620 in epoch 15, gen_loss = 1.427538115621189, disc_loss = 0.0002503797189322375
Trained batch 621 in epoch 15, gen_loss = 1.4275257742673255, disc_loss = 0.0002502278192033136
Trained batch 622 in epoch 15, gen_loss = 1.4274712402977492, disc_loss = 0.0002501096103333987
Trained batch 623 in epoch 15, gen_loss = 1.4274647042919428, disc_loss = 0.00025002062589534873
Trained batch 624 in epoch 15, gen_loss = 1.4274828210830688, disc_loss = 0.00024995165725413246
Trained batch 625 in epoch 15, gen_loss = 1.4275407499779527, disc_loss = 0.0002499069754799674
Trained batch 626 in epoch 15, gen_loss = 1.4274859721200508, disc_loss = 0.0002498943162748493
Trained batch 627 in epoch 15, gen_loss = 1.427505032841567, disc_loss = 0.0002499032100288086
Trained batch 628 in epoch 15, gen_loss = 1.4274275266877798, disc_loss = 0.00024992089590770934
Trained batch 629 in epoch 15, gen_loss = 1.4274448566966587, disc_loss = 0.0002499230012420282
Trained batch 630 in epoch 15, gen_loss = 1.42737698913943, disc_loss = 0.00024990356924932833
Trained batch 631 in epoch 15, gen_loss = 1.4273853498169138, disc_loss = 0.00024985763770582936
Trained batch 632 in epoch 15, gen_loss = 1.427468018885849, disc_loss = 0.00024979660011990065
Trained batch 633 in epoch 15, gen_loss = 1.427547537942038, disc_loss = 0.0002497374345653803
Trained batch 634 in epoch 15, gen_loss = 1.4275078050733552, disc_loss = 0.00024968912370040494
Trained batch 635 in epoch 15, gen_loss = 1.4274261725023858, disc_loss = 0.0002496733665633564
Trained batch 636 in epoch 15, gen_loss = 1.4274829676611644, disc_loss = 0.00024968477670169375
Trained batch 637 in epoch 15, gen_loss = 1.4275061370437048, disc_loss = 0.0002497081493765733
Trained batch 638 in epoch 15, gen_loss = 1.427463414336967, disc_loss = 0.0002497764817235293
Trained batch 639 in epoch 15, gen_loss = 1.4274393422529101, disc_loss = 0.00024995490700518985
Trained batch 640 in epoch 15, gen_loss = 1.42754621122631, disc_loss = 0.0002501510344400983
Trained batch 641 in epoch 15, gen_loss = 1.4275176064619022, disc_loss = 0.00025025895434040325
Trained batch 642 in epoch 15, gen_loss = 1.427631055585704, disc_loss = 0.00025027316098392836
Trained batch 643 in epoch 15, gen_loss = 1.4275979199764892, disc_loss = 0.0002502706552375864
Trained batch 644 in epoch 15, gen_loss = 1.4275645780932995, disc_loss = 0.0002502877946306596
Trained batch 645 in epoch 15, gen_loss = 1.4275636318667386, disc_loss = 0.00025039831822259686
Trained batch 646 in epoch 15, gen_loss = 1.4275489559129364, disc_loss = 0.00025050601491389613
Trained batch 647 in epoch 15, gen_loss = 1.4275745195739062, disc_loss = 0.0002506567475982727
Trained batch 648 in epoch 15, gen_loss = 1.4274773121982216, disc_loss = 0.0002508264773137441
Trained batch 649 in epoch 15, gen_loss = 1.427493498325348, disc_loss = 0.0002510221174200594
Trained batch 650 in epoch 15, gen_loss = 1.4274196767587266, disc_loss = 0.0002512037322838201
Trained batch 651 in epoch 15, gen_loss = 1.4273921282379174, disc_loss = 0.0002513522165665641
Trained batch 652 in epoch 15, gen_loss = 1.4273445637266267, disc_loss = 0.0002515006506301712
Trained batch 653 in epoch 15, gen_loss = 1.4274027320223117, disc_loss = 0.0002516844047592632
Trained batch 654 in epoch 15, gen_loss = 1.4274549833690846, disc_loss = 0.0002518822937306925
Trained batch 655 in epoch 15, gen_loss = 1.4274765100420974, disc_loss = 0.00025209102588311306
Trained batch 656 in epoch 15, gen_loss = 1.4273890541750183, disc_loss = 0.0002522599349602448
Trained batch 657 in epoch 15, gen_loss = 1.427404279223329, disc_loss = 0.0002523606822320278
Trained batch 658 in epoch 15, gen_loss = 1.427396299082882, disc_loss = 0.0002523884537334726
Trained batch 659 in epoch 15, gen_loss = 1.4273704306645827, disc_loss = 0.0002523562907271932
Trained batch 660 in epoch 15, gen_loss = 1.4274673598977694, disc_loss = 0.0002522840841623605
Trained batch 661 in epoch 15, gen_loss = 1.4275548735414028, disc_loss = 0.000252219406059331
Trained batch 662 in epoch 15, gen_loss = 1.4276243989464026, disc_loss = 0.00025217375354928706
Trained batch 663 in epoch 15, gen_loss = 1.42762735521937, disc_loss = 0.0002521265734263711
Trained batch 664 in epoch 15, gen_loss = 1.427577539314901, disc_loss = 0.00025207272253891617
Trained batch 665 in epoch 15, gen_loss = 1.4276273397354033, disc_loss = 0.00025201807073261097
Trained batch 666 in epoch 15, gen_loss = 1.4276146434772496, disc_loss = 0.00025198339934486913
Trained batch 667 in epoch 15, gen_loss = 1.4275597799680904, disc_loss = 0.00025191517945763383
Trained batch 668 in epoch 15, gen_loss = 1.4275277462775398, disc_loss = 0.00025188021472228813
Trained batch 669 in epoch 15, gen_loss = 1.427589202994731, disc_loss = 0.0002518632450051312
Trained batch 670 in epoch 15, gen_loss = 1.4275814630590857, disc_loss = 0.00025186368372247866
Trained batch 671 in epoch 15, gen_loss = 1.427640088612125, disc_loss = 0.00025186601296971797
Trained batch 672 in epoch 15, gen_loss = 1.4274896346087973, disc_loss = 0.0002518626684807945
Trained batch 673 in epoch 15, gen_loss = 1.4275460038057775, disc_loss = 0.0002518408854125793
Trained batch 674 in epoch 15, gen_loss = 1.4275504569654112, disc_loss = 0.0002517857493943733
Trained batch 675 in epoch 15, gen_loss = 1.4275745469084857, disc_loss = 0.0002516858199082917
Trained batch 676 in epoch 15, gen_loss = 1.4276058881638498, disc_loss = 0.00025154322438310277
Trained batch 677 in epoch 15, gen_loss = 1.4276049161730966, disc_loss = 0.000251382150268899
Trained batch 678 in epoch 15, gen_loss = 1.4276084109855505, disc_loss = 0.0002512311026355516
Trained batch 679 in epoch 15, gen_loss = 1.4276819286977545, disc_loss = 0.00025110935615724455
Trained batch 680 in epoch 15, gen_loss = 1.4277296418135386, disc_loss = 0.0002509982619310786
Trained batch 681 in epoch 15, gen_loss = 1.4277065728416891, disc_loss = 0.0002508800973875004
Trained batch 682 in epoch 15, gen_loss = 1.4276987754059396, disc_loss = 0.00025076629736195784
Trained batch 683 in epoch 15, gen_loss = 1.4277237094285196, disc_loss = 0.0002506498798969628
Trained batch 684 in epoch 15, gen_loss = 1.4277713979247713, disc_loss = 0.0002505274525609668
Trained batch 685 in epoch 15, gen_loss = 1.4277286680724808, disc_loss = 0.00025038013702251933
Trained batch 686 in epoch 15, gen_loss = 1.4277809303053255, disc_loss = 0.00025023044119517436
Trained batch 687 in epoch 15, gen_loss = 1.4277951185439908, disc_loss = 0.0002500944907947193
Trained batch 688 in epoch 15, gen_loss = 1.4278509073575798, disc_loss = 0.00024998607335456987
Trained batch 689 in epoch 15, gen_loss = 1.4276852896248085, disc_loss = 0.00024990786283867063
Trained batch 690 in epoch 15, gen_loss = 1.4276841737427002, disc_loss = 0.0002498367656015866
Trained batch 691 in epoch 15, gen_loss = 1.4277054689867648, disc_loss = 0.00024977706338744863
Trained batch 692 in epoch 15, gen_loss = 1.4277915773969707, disc_loss = 0.0002497308995237016
Trained batch 693 in epoch 15, gen_loss = 1.42783184199237, disc_loss = 0.0002496860030964002
Trained batch 694 in epoch 15, gen_loss = 1.4278672738040952, disc_loss = 0.0002496055789222135
Trained batch 695 in epoch 15, gen_loss = 1.4277596362363334, disc_loss = 0.000249519579784155
Trained batch 696 in epoch 15, gen_loss = 1.427726247389313, disc_loss = 0.0002494274394587643
Trained batch 697 in epoch 15, gen_loss = 1.4277054585495104, disc_loss = 0.0002493295607517597
Trained batch 698 in epoch 15, gen_loss = 1.4276932529113835, disc_loss = 0.0002492416565050962
Trained batch 699 in epoch 15, gen_loss = 1.4276884348051888, disc_loss = 0.00024915382213813633
Trained batch 700 in epoch 15, gen_loss = 1.4277547201654541, disc_loss = 0.0002490748471653143
Trained batch 701 in epoch 15, gen_loss = 1.4277649876738545, disc_loss = 0.000248991582118683
Trained batch 702 in epoch 15, gen_loss = 1.4277371909167316, disc_loss = 0.0002488998766478433
Trained batch 703 in epoch 15, gen_loss = 1.4276041945611888, disc_loss = 0.00024882874942281063
Trained batch 704 in epoch 15, gen_loss = 1.4276004948514573, disc_loss = 0.0002487494992908604
Trained batch 705 in epoch 15, gen_loss = 1.4275808989495122, disc_loss = 0.00024868217670126133
Trained batch 706 in epoch 15, gen_loss = 1.4276756231990528, disc_loss = 0.0002486167699165069
Trained batch 707 in epoch 15, gen_loss = 1.4277190840513694, disc_loss = 0.0002485585711894734
Trained batch 708 in epoch 15, gen_loss = 1.4277017439370094, disc_loss = 0.0002485414167401394
Trained batch 709 in epoch 15, gen_loss = 1.427595190598931, disc_loss = 0.00024852196515189783
Trained batch 710 in epoch 15, gen_loss = 1.4275728184127272, disc_loss = 0.00024854111315134595
Trained batch 711 in epoch 15, gen_loss = 1.4275018904316292, disc_loss = 0.0002486022998009809
Trained batch 712 in epoch 15, gen_loss = 1.4276064037440703, disc_loss = 0.0002486979607045923
Trained batch 713 in epoch 15, gen_loss = 1.4275994414374942, disc_loss = 0.00024881084521564164
Trained batch 714 in epoch 15, gen_loss = 1.427613218680962, disc_loss = 0.0002489402484354503
Trained batch 715 in epoch 15, gen_loss = 1.4275005223364803, disc_loss = 0.0002490871742536799
Trained batch 716 in epoch 15, gen_loss = 1.427425392834545, disc_loss = 0.00024925498214473275
Trained batch 717 in epoch 15, gen_loss = 1.4274329053326238, disc_loss = 0.0002494410524190127
Trained batch 718 in epoch 15, gen_loss = 1.4274609476866742, disc_loss = 0.0002496592956359337
Trained batch 719 in epoch 15, gen_loss = 1.4274952744444211, disc_loss = 0.00024988097647767266
Trained batch 720 in epoch 15, gen_loss = 1.4274929570093564, disc_loss = 0.0002501176009136089
Trained batch 721 in epoch 15, gen_loss = 1.427591692212546, disc_loss = 0.0002503773749189365
Trained batch 722 in epoch 15, gen_loss = 1.427637494286396, disc_loss = 0.0002506091888971396
Trained batch 723 in epoch 15, gen_loss = 1.4276954745719446, disc_loss = 0.0002508157150983225
Trained batch 724 in epoch 15, gen_loss = 1.4277610713037951, disc_loss = 0.0002510122509230659
Trained batch 725 in epoch 15, gen_loss = 1.4278251139585636, disc_loss = 0.00025117397412327655
Trained batch 726 in epoch 15, gen_loss = 1.4277947549150931, disc_loss = 0.0002512507503468534
Trained batch 727 in epoch 15, gen_loss = 1.4277418878052262, disc_loss = 0.0002512717876570505
Trained batch 728 in epoch 15, gen_loss = 1.427790214985977, disc_loss = 0.00025125743717773044
Trained batch 729 in epoch 15, gen_loss = 1.4278291522640072, disc_loss = 0.00025122517586854357
Trained batch 730 in epoch 15, gen_loss = 1.4278454213070642, disc_loss = 0.0002511841916110615
Trained batch 731 in epoch 15, gen_loss = 1.4277884696350722, disc_loss = 0.0002511194861579527
Trained batch 732 in epoch 15, gen_loss = 1.427819510599113, disc_loss = 0.0002510372722900965
Trained batch 733 in epoch 15, gen_loss = 1.42784139538331, disc_loss = 0.0002509823114312359
Trained batch 734 in epoch 15, gen_loss = 1.4278344517662411, disc_loss = 0.0002509727093230158
Trained batch 735 in epoch 15, gen_loss = 1.4278013035655022, disc_loss = 0.0002509828881255524
Trained batch 736 in epoch 15, gen_loss = 1.4277482893282556, disc_loss = 0.0002509899855755594
Trained batch 737 in epoch 15, gen_loss = 1.4277098967130915, disc_loss = 0.00025099826347641505
Trained batch 738 in epoch 15, gen_loss = 1.4278055402035643, disc_loss = 0.00025100347803752723
Trained batch 739 in epoch 15, gen_loss = 1.427729882098533, disc_loss = 0.0002510002817355082
Trained batch 740 in epoch 15, gen_loss = 1.427762213667073, disc_loss = 0.00025100188315273767
Trained batch 741 in epoch 15, gen_loss = 1.4277714850767604, disc_loss = 0.00025101462894249463
Trained batch 742 in epoch 15, gen_loss = 1.4277705273429286, disc_loss = 0.0002510338755454177
Trained batch 743 in epoch 15, gen_loss = 1.427747461744534, disc_loss = 0.0002510565973328192
Trained batch 744 in epoch 15, gen_loss = 1.4277225944019805, disc_loss = 0.00025105960393430365
Trained batch 745 in epoch 15, gen_loss = 1.4278286729037921, disc_loss = 0.0002510318774521442
Testing Epoch 15
Training Epoch 16
Trained batch 0 in epoch 16, gen_loss = 1.4684700965881348, disc_loss = 0.00022203181288205087
Trained batch 1 in epoch 16, gen_loss = 1.4334944486618042, disc_loss = 0.0002441921824356541
Trained batch 2 in epoch 16, gen_loss = 1.4299437204996746, disc_loss = 0.00028181885136291385
Trained batch 3 in epoch 16, gen_loss = 1.449571967124939, disc_loss = 0.0003257530552218668
Trained batch 4 in epoch 16, gen_loss = 1.4536793231964111, disc_loss = 0.0003627380297984928
Trained batch 5 in epoch 16, gen_loss = 1.4442625045776367, disc_loss = 0.0003889848352021848
Trained batch 6 in epoch 16, gen_loss = 1.4456173011234827, disc_loss = 0.00040576824436097274
Trained batch 7 in epoch 16, gen_loss = 1.4467901587486267, disc_loss = 0.00041613680878072046
Trained batch 8 in epoch 16, gen_loss = 1.4499803119235568, disc_loss = 0.00042096607244780497
Trained batch 9 in epoch 16, gen_loss = 1.4502202153205872, disc_loss = 0.00042170547822024674
Trained batch 10 in epoch 16, gen_loss = 1.4474693970246748, disc_loss = 0.0004177911693907597
Trained batch 11 in epoch 16, gen_loss = 1.4402761260668437, disc_loss = 0.0004103766259504482
Trained batch 12 in epoch 16, gen_loss = 1.4387506796763494, disc_loss = 0.0003994998450462635
Trained batch 13 in epoch 16, gen_loss = 1.43776136636734, disc_loss = 0.0003868664851844577
Trained batch 14 in epoch 16, gen_loss = 1.4363713026046754, disc_loss = 0.0003747808785798649
Trained batch 15 in epoch 16, gen_loss = 1.4367852434515953, disc_loss = 0.0003597826571422047
Trained batch 16 in epoch 16, gen_loss = 1.4351854254217709, disc_loss = 0.00034431331647176514
Trained batch 17 in epoch 16, gen_loss = 1.433627982934316, disc_loss = 0.00032920336242467683
Trained batch 18 in epoch 16, gen_loss = 1.436309720340528, disc_loss = 0.0003146822457079236
Trained batch 19 in epoch 16, gen_loss = 1.4373150885105133, disc_loss = 0.0003013497840584023
Trained batch 20 in epoch 16, gen_loss = 1.4347256478809176, disc_loss = 0.00028930592747028206
Trained batch 21 in epoch 16, gen_loss = 1.435907623984597, disc_loss = 0.00027839088629248596
Trained batch 22 in epoch 16, gen_loss = 1.4364230218140974, disc_loss = 0.00026857541208459145
Trained batch 23 in epoch 16, gen_loss = 1.4371992945671082, disc_loss = 0.00025969743243573856
Trained batch 24 in epoch 16, gen_loss = 1.4375182437896727, disc_loss = 0.00025162190315313637
Trained batch 25 in epoch 16, gen_loss = 1.4368928487484272, disc_loss = 0.0002442246604914544
Trained batch 26 in epoch 16, gen_loss = 1.4367553216439706, disc_loss = 0.00023738506166005714
Trained batch 27 in epoch 16, gen_loss = 1.435988085610526, disc_loss = 0.00023114013336973066
Trained batch 28 in epoch 16, gen_loss = 1.434403814118484, disc_loss = 0.00022537717299640243
Trained batch 29 in epoch 16, gen_loss = 1.4350586891174317, disc_loss = 0.00021988326091862593
Trained batch 30 in epoch 16, gen_loss = 1.4345038667801888, disc_loss = 0.0002145614517728738
Trained batch 31 in epoch 16, gen_loss = 1.4350685440003872, disc_loss = 0.00020926671595589141
Trained batch 32 in epoch 16, gen_loss = 1.43502194592447, disc_loss = 0.00020394591719554174
Trained batch 33 in epoch 16, gen_loss = 1.4347467141992905, disc_loss = 0.00019875405943072538
Trained batch 34 in epoch 16, gen_loss = 1.4348731109074184, disc_loss = 0.00019382691030581814
Trained batch 35 in epoch 16, gen_loss = 1.4338750839233398, disc_loss = 0.0001893491368921079
Trained batch 36 in epoch 16, gen_loss = 1.4321284358565871, disc_loss = 0.00018546477700953333
Trained batch 37 in epoch 16, gen_loss = 1.4313489324168156, disc_loss = 0.0001820316993440716
Trained batch 38 in epoch 16, gen_loss = 1.432523094690763, disc_loss = 0.0001790058494150752
Trained batch 39 in epoch 16, gen_loss = 1.433853629231453, disc_loss = 0.00017647914096414753
Trained batch 40 in epoch 16, gen_loss = 1.4344996039460345, disc_loss = 0.00017438026136404938
Trained batch 41 in epoch 16, gen_loss = 1.4331052331697374, disc_loss = 0.00017250275669496097
Trained batch 42 in epoch 16, gen_loss = 1.4336358003838117, disc_loss = 0.0001711262647467963
Trained batch 43 in epoch 16, gen_loss = 1.4335864728147334, disc_loss = 0.00017003209685836654
Trained batch 44 in epoch 16, gen_loss = 1.4338283803727891, disc_loss = 0.00016912434103788756
Trained batch 45 in epoch 16, gen_loss = 1.4323850144510684, disc_loss = 0.00016830250732037592
Trained batch 46 in epoch 16, gen_loss = 1.4317696931514334, disc_loss = 0.0001674075396914169
Trained batch 47 in epoch 16, gen_loss = 1.4313156331578891, disc_loss = 0.00016634264992868944
Trained batch 48 in epoch 16, gen_loss = 1.4316889242250093, disc_loss = 0.00016513402416811523
Trained batch 49 in epoch 16, gen_loss = 1.4321534323692322, disc_loss = 0.000163957051372563
Trained batch 50 in epoch 16, gen_loss = 1.4331945367887908, disc_loss = 0.0001629815284175885
Trained batch 51 in epoch 16, gen_loss = 1.433827076966946, disc_loss = 0.00016223519444863015
Trained batch 52 in epoch 16, gen_loss = 1.4336282284754627, disc_loss = 0.0001615490184705331
Trained batch 53 in epoch 16, gen_loss = 1.432923831321575, disc_loss = 0.00016063077482950003
Trained batch 54 in epoch 16, gen_loss = 1.433362171866677, disc_loss = 0.00015969108350294515
Trained batch 55 in epoch 16, gen_loss = 1.4330266884395055, disc_loss = 0.00015870871600652338
Trained batch 56 in epoch 16, gen_loss = 1.4335833306898151, disc_loss = 0.00015776758724920606
Trained batch 57 in epoch 16, gen_loss = 1.4349401243801774, disc_loss = 0.00015685652218460996
Trained batch 58 in epoch 16, gen_loss = 1.4347665552365578, disc_loss = 0.0001559582674494546
Trained batch 59 in epoch 16, gen_loss = 1.4349731147289275, disc_loss = 0.00015518741647611023
Trained batch 60 in epoch 16, gen_loss = 1.4342640403841362, disc_loss = 0.0001548631666321212
Trained batch 61 in epoch 16, gen_loss = 1.4339485303048165, disc_loss = 0.000155207748057071
Trained batch 62 in epoch 16, gen_loss = 1.4355964660644531, disc_loss = 0.00015639462900354475
Trained batch 63 in epoch 16, gen_loss = 1.4357912056148052, disc_loss = 0.00015854055968134162
Trained batch 64 in epoch 16, gen_loss = 1.4367370458749624, disc_loss = 0.0001616861365339271
Trained batch 65 in epoch 16, gen_loss = 1.4347643274249453, disc_loss = 0.00016571642335651578
Trained batch 66 in epoch 16, gen_loss = 1.4357340122336772, disc_loss = 0.0001707726678975646
Trained batch 67 in epoch 16, gen_loss = 1.4342683939372791, disc_loss = 0.000176682943594428
Trained batch 68 in epoch 16, gen_loss = 1.4338338133217632, disc_loss = 0.00018361310817388164
Trained batch 69 in epoch 16, gen_loss = 1.4334918584142413, disc_loss = 0.00019183948198977824
Trained batch 70 in epoch 16, gen_loss = 1.4347133115983346, disc_loss = 0.00020113527150410654
Trained batch 71 in epoch 16, gen_loss = 1.4344605803489685, disc_loss = 0.00021069367870849319
Trained batch 72 in epoch 16, gen_loss = 1.4342293771978927, disc_loss = 0.0002206052514301431
Trained batch 73 in epoch 16, gen_loss = 1.4333989136927836, disc_loss = 0.00023080649847346453
Trained batch 74 in epoch 16, gen_loss = 1.4333149274190267, disc_loss = 0.000240601304564431
Trained batch 75 in epoch 16, gen_loss = 1.4330268078728725, disc_loss = 0.00024892278133847867
Trained batch 76 in epoch 16, gen_loss = 1.4333524316936344, disc_loss = 0.00025580065084795933
Trained batch 77 in epoch 16, gen_loss = 1.4324030402379158, disc_loss = 0.0002612097494373955
Trained batch 78 in epoch 16, gen_loss = 1.4325924553448641, disc_loss = 0.00026514083452362867
Trained batch 79 in epoch 16, gen_loss = 1.4318881407380104, disc_loss = 0.0002678360650634204
Trained batch 80 in epoch 16, gen_loss = 1.4321594841686296, disc_loss = 0.0002699057217628083
Trained batch 81 in epoch 16, gen_loss = 1.4317745958886496, disc_loss = 0.00027145895699770957
Trained batch 82 in epoch 16, gen_loss = 1.432459859962923, disc_loss = 0.00027265396422453375
Trained batch 83 in epoch 16, gen_loss = 1.4315763484864008, disc_loss = 0.0002737442017253973
Trained batch 84 in epoch 16, gen_loss = 1.4314849629121669, disc_loss = 0.000274761964336743
Trained batch 85 in epoch 16, gen_loss = 1.4304980926735456, disc_loss = 0.00027552367750061866
Trained batch 86 in epoch 16, gen_loss = 1.4310641014712981, disc_loss = 0.00027610953744944456
Trained batch 87 in epoch 16, gen_loss = 1.431013823910193, disc_loss = 0.00027655508022855264
Trained batch 88 in epoch 16, gen_loss = 1.4308623852354756, disc_loss = 0.00027698182276161674
Trained batch 89 in epoch 16, gen_loss = 1.4308742178810967, disc_loss = 0.00027743271968776954
Trained batch 90 in epoch 16, gen_loss = 1.4310725023458293, disc_loss = 0.00027779249239256884
Trained batch 91 in epoch 16, gen_loss = 1.4308101586673572, disc_loss = 0.0002785042368921732
Trained batch 92 in epoch 16, gen_loss = 1.43145158983046, disc_loss = 0.00027965917523874607
Trained batch 93 in epoch 16, gen_loss = 1.431384028272426, disc_loss = 0.0002812569302980766
Trained batch 94 in epoch 16, gen_loss = 1.4316914859570955, disc_loss = 0.00028277188009125987
Trained batch 95 in epoch 16, gen_loss = 1.4319519052902858, disc_loss = 0.0002839510842894318
Trained batch 96 in epoch 16, gen_loss = 1.4321505458084578, disc_loss = 0.00028477142676792093
Trained batch 97 in epoch 16, gen_loss = 1.4324547526787739, disc_loss = 0.0002851126876762743
Trained batch 98 in epoch 16, gen_loss = 1.432107889291012, disc_loss = 0.000284977799549439
Trained batch 99 in epoch 16, gen_loss = 1.4312399673461913, disc_loss = 0.00028443680223062985
Trained batch 100 in epoch 16, gen_loss = 1.4316620425422593, disc_loss = 0.00028345280817561753
Trained batch 101 in epoch 16, gen_loss = 1.4314459270122004, disc_loss = 0.00028203924730583894
Trained batch 102 in epoch 16, gen_loss = 1.4322138353458886, disc_loss = 0.0002803537611999646
Trained batch 103 in epoch 16, gen_loss = 1.4326292058596244, disc_loss = 0.0002785006738926873
Trained batch 104 in epoch 16, gen_loss = 1.4329525799978347, disc_loss = 0.00027655168217149495
Trained batch 105 in epoch 16, gen_loss = 1.4333653843627785, disc_loss = 0.00027462813960603015
Trained batch 106 in epoch 16, gen_loss = 1.4329678232424727, disc_loss = 0.00027286373544960376
Trained batch 107 in epoch 16, gen_loss = 1.4330417337240997, disc_loss = 0.0002713672653819096
Trained batch 108 in epoch 16, gen_loss = 1.4327204096207924, disc_loss = 0.0002702057375854315
Trained batch 109 in epoch 16, gen_loss = 1.4327285007996993, disc_loss = 0.00026931837173006817
Trained batch 110 in epoch 16, gen_loss = 1.4320629416285335, disc_loss = 0.00026844496557083683
Trained batch 111 in epoch 16, gen_loss = 1.4317420337881361, disc_loss = 0.0002673601421747662
Trained batch 112 in epoch 16, gen_loss = 1.4316141573728713, disc_loss = 0.00026609220108224916
Trained batch 113 in epoch 16, gen_loss = 1.4315326370690997, disc_loss = 0.00026466983474580176
Trained batch 114 in epoch 16, gen_loss = 1.4319799267727396, disc_loss = 0.00026311276835812075
Trained batch 115 in epoch 16, gen_loss = 1.4315535600843101, disc_loss = 0.0002614581317645608
Trained batch 116 in epoch 16, gen_loss = 1.4307426030819232, disc_loss = 0.00025980408471284143
Trained batch 117 in epoch 16, gen_loss = 1.431637167930603, disc_loss = 0.0002582517997587398
Trained batch 118 in epoch 16, gen_loss = 1.4311344282967704, disc_loss = 0.0002569988172420862
Trained batch 119 in epoch 16, gen_loss = 1.4308319509029388, disc_loss = 0.00025619253754787983
Trained batch 120 in epoch 16, gen_loss = 1.4309928870398152, disc_loss = 0.0002558753718057992
Trained batch 121 in epoch 16, gen_loss = 1.4311118477680644, disc_loss = 0.00025613184625101104
Trained batch 122 in epoch 16, gen_loss = 1.4302451785017805, disc_loss = 0.000256953033016085
Trained batch 123 in epoch 16, gen_loss = 1.430349224998105, disc_loss = 0.00025817389364273105
Trained batch 124 in epoch 16, gen_loss = 1.4303625659942627, disc_loss = 0.0002593490701256087
Trained batch 125 in epoch 16, gen_loss = 1.4302085940800016, disc_loss = 0.0002602677537392343
Trained batch 126 in epoch 16, gen_loss = 1.4293975811305009, disc_loss = 0.00026096448204129493
Trained batch 127 in epoch 16, gen_loss = 1.4290795642882586, disc_loss = 0.00026160704429400994
Trained batch 128 in epoch 16, gen_loss = 1.4286733653194221, disc_loss = 0.00026204187546569275
Trained batch 129 in epoch 16, gen_loss = 1.4289157408934372, disc_loss = 0.00026215600405871207
Trained batch 130 in epoch 16, gen_loss = 1.4281002255796476, disc_loss = 0.0002618324443983858
Trained batch 131 in epoch 16, gen_loss = 1.4280645188057062, disc_loss = 0.0002610662359488329
Trained batch 132 in epoch 16, gen_loss = 1.4281487267716486, disc_loss = 0.0002600822239387492
Trained batch 133 in epoch 16, gen_loss = 1.4283032630806538, disc_loss = 0.00025902976304040303
Trained batch 134 in epoch 16, gen_loss = 1.4285315610744336, disc_loss = 0.000257964454970163
Trained batch 135 in epoch 16, gen_loss = 1.4283297500189613, disc_loss = 0.0002569455657254259
Trained batch 136 in epoch 16, gen_loss = 1.4276251401344355, disc_loss = 0.0002559713510273621
Trained batch 137 in epoch 16, gen_loss = 1.4277792624805286, disc_loss = 0.00025507634082727685
Trained batch 138 in epoch 16, gen_loss = 1.4275834869137771, disc_loss = 0.0002542078918784735
Trained batch 139 in epoch 16, gen_loss = 1.4278127423354559, disc_loss = 0.0002532970042141512
Trained batch 140 in epoch 16, gen_loss = 1.427543948728142, disc_loss = 0.00025230554878207645
Trained batch 141 in epoch 16, gen_loss = 1.4281242884380716, disc_loss = 0.0002511791071810876
Trained batch 142 in epoch 16, gen_loss = 1.4276333922272795, disc_loss = 0.0002499690628381588
Trained batch 143 in epoch 16, gen_loss = 1.4274749449557729, disc_loss = 0.0002486561162160999
Trained batch 144 in epoch 16, gen_loss = 1.427439913256415, disc_loss = 0.000247241967372247
Trained batch 145 in epoch 16, gen_loss = 1.427570689214419, disc_loss = 0.00024572811220772165
Trained batch 146 in epoch 16, gen_loss = 1.4272209332913768, disc_loss = 0.0002445852117854302
Trained batch 147 in epoch 16, gen_loss = 1.4270493065988696, disc_loss = 0.00024319618489391506
Trained batch 148 in epoch 16, gen_loss = 1.4270968581206047, disc_loss = 0.00024180992993738288
Trained batch 149 in epoch 16, gen_loss = 1.4273409628868103, disc_loss = 0.00024047330942266853
Trained batch 150 in epoch 16, gen_loss = 1.427374178210631, disc_loss = 0.00023915479527059742
Trained batch 151 in epoch 16, gen_loss = 1.4270881477155184, disc_loss = 0.00023786438222678523
Trained batch 152 in epoch 16, gen_loss = 1.4273291779499429, disc_loss = 0.00023664181765590815
Trained batch 153 in epoch 16, gen_loss = 1.427435270377568, disc_loss = 0.0002354778428513794
Trained batch 154 in epoch 16, gen_loss = 1.4272235262778497, disc_loss = 0.00023438852148237563
Trained batch 155 in epoch 16, gen_loss = 1.4271987118782141, disc_loss = 0.00023337307605358475
Trained batch 156 in epoch 16, gen_loss = 1.4268263039315583, disc_loss = 0.00023241476948526139
Trained batch 157 in epoch 16, gen_loss = 1.426567498641678, disc_loss = 0.00023151453455906034
Trained batch 158 in epoch 16, gen_loss = 1.4264322976646184, disc_loss = 0.0002306595871466799
Trained batch 159 in epoch 16, gen_loss = 1.4259772881865502, disc_loss = 0.00022986733839616135
Trained batch 160 in epoch 16, gen_loss = 1.4256663685259612, disc_loss = 0.00022916376520635529
Trained batch 161 in epoch 16, gen_loss = 1.425360608248063, disc_loss = 0.0002284307210972241
Trained batch 162 in epoch 16, gen_loss = 1.4250315705691379, disc_loss = 0.0002275484783273723
Trained batch 163 in epoch 16, gen_loss = 1.425084915829868, disc_loss = 0.00022660222900479466
Trained batch 164 in epoch 16, gen_loss = 1.4250313094168, disc_loss = 0.0002256433508701968
Trained batch 165 in epoch 16, gen_loss = 1.4246171626699977, disc_loss = 0.00022467273041013004
Trained batch 166 in epoch 16, gen_loss = 1.425082838463926, disc_loss = 0.00022369586814218967
Trained batch 167 in epoch 16, gen_loss = 1.4250096274273736, disc_loss = 0.00022274523833705948
Trained batch 168 in epoch 16, gen_loss = 1.4250770962449926, disc_loss = 0.0002218350343608205
Trained batch 169 in epoch 16, gen_loss = 1.4248043305733624, disc_loss = 0.000220939874794995
Trained batch 170 in epoch 16, gen_loss = 1.4252676148163645, disc_loss = 0.00022008149747504261
Trained batch 171 in epoch 16, gen_loss = 1.4250963399576586, disc_loss = 0.00021928755336904392
Trained batch 172 in epoch 16, gen_loss = 1.424893508756781, disc_loss = 0.0002185874802065977
Trained batch 173 in epoch 16, gen_loss = 1.4249594780220383, disc_loss = 0.00021801585051267548
Trained batch 174 in epoch 16, gen_loss = 1.425166916847229, disc_loss = 0.0002175860857927806
Trained batch 175 in epoch 16, gen_loss = 1.4251045672730966, disc_loss = 0.00021732808877252617
Trained batch 176 in epoch 16, gen_loss = 1.4249751513960671, disc_loss = 0.00021724108570443773
Trained batch 177 in epoch 16, gen_loss = 1.4248100599546112, disc_loss = 0.00021730665984444824
Trained batch 178 in epoch 16, gen_loss = 1.4240670317378123, disc_loss = 0.00021762018419476032
Trained batch 179 in epoch 16, gen_loss = 1.4245302047994401, disc_loss = 0.00021817000622629873
Trained batch 180 in epoch 16, gen_loss = 1.424512851962727, disc_loss = 0.00021897810602340993
Trained batch 181 in epoch 16, gen_loss = 1.424696120587024, disc_loss = 0.00022005155020891394
Trained batch 182 in epoch 16, gen_loss = 1.4246620389281726, disc_loss = 0.00022149494375572017
Trained batch 183 in epoch 16, gen_loss = 1.4249237374119137, disc_loss = 0.00022323251988856774
Trained batch 184 in epoch 16, gen_loss = 1.424955281695804, disc_loss = 0.0002251135871365723
Trained batch 185 in epoch 16, gen_loss = 1.4250088981402818, disc_loss = 0.00022705927334442017
Trained batch 186 in epoch 16, gen_loss = 1.4246248287313126, disc_loss = 0.00022914329044158846
Trained batch 187 in epoch 16, gen_loss = 1.4249206477023186, disc_loss = 0.0002312267928708876
Trained batch 188 in epoch 16, gen_loss = 1.425161428552456, disc_loss = 0.00023322398454992153
Trained batch 189 in epoch 16, gen_loss = 1.4250756734295895, disc_loss = 0.00023515996904040405
Trained batch 190 in epoch 16, gen_loss = 1.4250501281928019, disc_loss = 0.0002370720847570904
Trained batch 191 in epoch 16, gen_loss = 1.4250042742739122, disc_loss = 0.0002390180561728054
Trained batch 192 in epoch 16, gen_loss = 1.42459460120127, disc_loss = 0.00024090825256487715
Trained batch 193 in epoch 16, gen_loss = 1.4245383014384003, disc_loss = 0.00024269380458828948
Trained batch 194 in epoch 16, gen_loss = 1.4243008399621033, disc_loss = 0.00024433667497830285
Trained batch 195 in epoch 16, gen_loss = 1.4247047700444047, disc_loss = 0.00024580217456917
Trained batch 196 in epoch 16, gen_loss = 1.4244871557061443, disc_loss = 0.00024705052939292366
Trained batch 197 in epoch 16, gen_loss = 1.4246356282571349, disc_loss = 0.0002480410204144492
Trained batch 198 in epoch 16, gen_loss = 1.4244882814848243, disc_loss = 0.00024873791813323026
Trained batch 199 in epoch 16, gen_loss = 1.424312794804573, disc_loss = 0.000249388151723906
Trained batch 200 in epoch 16, gen_loss = 1.424012066119939, disc_loss = 0.0002500989931420248
Trained batch 201 in epoch 16, gen_loss = 1.4244600251169488, disc_loss = 0.00025083284507862046
Trained batch 202 in epoch 16, gen_loss = 1.4243166722687595, disc_loss = 0.0002514341604765281
Trained batch 203 in epoch 16, gen_loss = 1.4244439274657006, disc_loss = 0.0002519623005587075
Trained batch 204 in epoch 16, gen_loss = 1.4242598882535609, disc_loss = 0.00025247814909806304
Trained batch 205 in epoch 16, gen_loss = 1.424658923473173, disc_loss = 0.0002529657977434396
Trained batch 206 in epoch 16, gen_loss = 1.424609905279777, disc_loss = 0.0002534422045830184
Trained batch 207 in epoch 16, gen_loss = 1.4249199021321077, disc_loss = 0.0002539648454558119
Trained batch 208 in epoch 16, gen_loss = 1.4249450607162915, disc_loss = 0.000254528856712394
Trained batch 209 in epoch 16, gen_loss = 1.4255609120641435, disc_loss = 0.0002550370607423247
Trained batch 210 in epoch 16, gen_loss = 1.4257823149739848, disc_loss = 0.0002554468904438862
Trained batch 211 in epoch 16, gen_loss = 1.4255696259579569, disc_loss = 0.00025607836513236697
Trained batch 212 in epoch 16, gen_loss = 1.4257397506158676, disc_loss = 0.0002568616265977734
Trained batch 213 in epoch 16, gen_loss = 1.4261071035795123, disc_loss = 0.0002578372669232292
Trained batch 214 in epoch 16, gen_loss = 1.4263889528984248, disc_loss = 0.00025889192570608684
Trained batch 215 in epoch 16, gen_loss = 1.4266299390130572, disc_loss = 0.00025988422904716843
Trained batch 216 in epoch 16, gen_loss = 1.4263570281217723, disc_loss = 0.0002606756791335231
Trained batch 217 in epoch 16, gen_loss = 1.4262570328668718, disc_loss = 0.00026127496730289775
Trained batch 218 in epoch 16, gen_loss = 1.4257229757091225, disc_loss = 0.00026169170843753334
Trained batch 219 in epoch 16, gen_loss = 1.4255527583035557, disc_loss = 0.00026197378214915673
Trained batch 220 in epoch 16, gen_loss = 1.4255277517154745, disc_loss = 0.00026218332069257236
Trained batch 221 in epoch 16, gen_loss = 1.4253068598541054, disc_loss = 0.00026242650609846523
Trained batch 222 in epoch 16, gen_loss = 1.4250692973757004, disc_loss = 0.00026268367262249404
Trained batch 223 in epoch 16, gen_loss = 1.4251404463180475, disc_loss = 0.0002629337301008101
Trained batch 224 in epoch 16, gen_loss = 1.4250822750727337, disc_loss = 0.000263176439984818
Trained batch 225 in epoch 16, gen_loss = 1.4251311073261024, disc_loss = 0.00026344815880325223
Trained batch 226 in epoch 16, gen_loss = 1.4250368447030692, disc_loss = 0.00026380578797837026
Trained batch 227 in epoch 16, gen_loss = 1.4253530643488233, disc_loss = 0.0002641702021639758
Trained batch 228 in epoch 16, gen_loss = 1.4252923904027481, disc_loss = 0.0002645668653824278
Trained batch 229 in epoch 16, gen_loss = 1.4255207554153775, disc_loss = 0.00026483310642936924
Trained batch 230 in epoch 16, gen_loss = 1.4253642853204307, disc_loss = 0.0002649506425323873
Trained batch 231 in epoch 16, gen_loss = 1.4255834833301346, disc_loss = 0.0002648749584280048
Trained batch 232 in epoch 16, gen_loss = 1.4256875330798104, disc_loss = 0.0002646074497244993
Trained batch 233 in epoch 16, gen_loss = 1.4254461109128773, disc_loss = 0.00026433758175232634
Trained batch 234 in epoch 16, gen_loss = 1.4255228879603934, disc_loss = 0.00026409291326188474
Trained batch 235 in epoch 16, gen_loss = 1.4255070868185011, disc_loss = 0.00026391912653275925
Trained batch 236 in epoch 16, gen_loss = 1.4256816192015314, disc_loss = 0.0002637745370896939
Trained batch 237 in epoch 16, gen_loss = 1.4257363156110299, disc_loss = 0.00026357755642424644
Trained batch 238 in epoch 16, gen_loss = 1.4255061608478115, disc_loss = 0.0002633152378309118
Trained batch 239 in epoch 16, gen_loss = 1.4257728884617487, disc_loss = 0.00026299522063861027
Trained batch 240 in epoch 16, gen_loss = 1.4259367889388468, disc_loss = 0.000262606140891589
Trained batch 241 in epoch 16, gen_loss = 1.4258649063504432, disc_loss = 0.00026214860182252863
Trained batch 242 in epoch 16, gen_loss = 1.4259623779681485, disc_loss = 0.00026156754646774376
Trained batch 243 in epoch 16, gen_loss = 1.426084066023592, disc_loss = 0.0002608574768228358
Trained batch 244 in epoch 16, gen_loss = 1.4259669196848967, disc_loss = 0.0002600399407184545
Trained batch 245 in epoch 16, gen_loss = 1.4262186216145027, disc_loss = 0.00025915088806173817
Trained batch 246 in epoch 16, gen_loss = 1.4261667800818378, disc_loss = 0.0002582011191642877
Trained batch 247 in epoch 16, gen_loss = 1.4261606412549173, disc_loss = 0.00025724218086554994
Trained batch 248 in epoch 16, gen_loss = 1.4263641293269085, disc_loss = 0.0002562739548785799
Trained batch 249 in epoch 16, gen_loss = 1.4265068125724794, disc_loss = 0.000255308357445756
Trained batch 250 in epoch 16, gen_loss = 1.4266205323169905, disc_loss = 0.0002543578818922216
Trained batch 251 in epoch 16, gen_loss = 1.4264655146333907, disc_loss = 0.00025341834652718964
Trained batch 252 in epoch 16, gen_loss = 1.426389823317999, disc_loss = 0.0002524827678168258
Trained batch 253 in epoch 16, gen_loss = 1.4264202315037644, disc_loss = 0.00025152686978219393
Trained batch 254 in epoch 16, gen_loss = 1.4263664306378832, disc_loss = 0.0002505679313603026
Trained batch 255 in epoch 16, gen_loss = 1.4262613710016012, disc_loss = 0.0002496286980608886
Trained batch 256 in epoch 16, gen_loss = 1.426351722576275, disc_loss = 0.00024873781854934887
Trained batch 257 in epoch 16, gen_loss = 1.426515124564947, disc_loss = 0.0002479183638097875
Trained batch 258 in epoch 16, gen_loss = 1.4265662068105573, disc_loss = 0.0002471882722131909
Trained batch 259 in epoch 16, gen_loss = 1.4264531681170831, disc_loss = 0.0002465558942941033
Trained batch 260 in epoch 16, gen_loss = 1.4267665056433259, disc_loss = 0.0002459718601712527
Trained batch 261 in epoch 16, gen_loss = 1.4269574029755046, disc_loss = 0.000245427050904671
Trained batch 262 in epoch 16, gen_loss = 1.4269009529411112, disc_loss = 0.000244948341445319
Trained batch 263 in epoch 16, gen_loss = 1.4268131378022106, disc_loss = 0.00024450269582950676
Trained batch 264 in epoch 16, gen_loss = 1.4266843305443817, disc_loss = 0.0002440670483715707
Trained batch 265 in epoch 16, gen_loss = 1.4266616244961445, disc_loss = 0.00024363822006861504
Trained batch 266 in epoch 16, gen_loss = 1.4268211403143094, disc_loss = 0.0002432623101985167
Trained batch 267 in epoch 16, gen_loss = 1.4269437394035396, disc_loss = 0.00024295261429340746
Trained batch 268 in epoch 16, gen_loss = 1.4270760862357554, disc_loss = 0.00024268984248771114
Trained batch 269 in epoch 16, gen_loss = 1.426842952657629, disc_loss = 0.00024251628087936466
Trained batch 270 in epoch 16, gen_loss = 1.4269117059742833, disc_loss = 0.00024239736751874378
Trained batch 271 in epoch 16, gen_loss = 1.4271854319993187, disc_loss = 0.00024234242300401413
Trained batch 272 in epoch 16, gen_loss = 1.4275048268147004, disc_loss = 0.00024229151009028796
Trained batch 273 in epoch 16, gen_loss = 1.4276379359899647, disc_loss = 0.0002422278894997747
Trained batch 274 in epoch 16, gen_loss = 1.4276470687172629, disc_loss = 0.0002421351225315117
Trained batch 275 in epoch 16, gen_loss = 1.4274717171986897, disc_loss = 0.00024203383630238946
Trained batch 276 in epoch 16, gen_loss = 1.4273253012219922, disc_loss = 0.00024192101779462252
Trained batch 277 in epoch 16, gen_loss = 1.427290427599022, disc_loss = 0.00024177687422994993
Trained batch 278 in epoch 16, gen_loss = 1.4275878808831657, disc_loss = 0.0002415277482950874
Trained batch 279 in epoch 16, gen_loss = 1.427464571595192, disc_loss = 0.00024121815850841293
Trained batch 280 in epoch 16, gen_loss = 1.4274811710751354, disc_loss = 0.00024091919709346153
Trained batch 281 in epoch 16, gen_loss = 1.4273740070085998, disc_loss = 0.00024062872243514562
Trained batch 282 in epoch 16, gen_loss = 1.4272657872931276, disc_loss = 0.00024036926554577972
Trained batch 283 in epoch 16, gen_loss = 1.4275244566756236, disc_loss = 0.0002401610598092664
Trained batch 284 in epoch 16, gen_loss = 1.427552096048991, disc_loss = 0.00024001096520997203
Trained batch 285 in epoch 16, gen_loss = 1.4275962589504, disc_loss = 0.00023992191252902203
Trained batch 286 in epoch 16, gen_loss = 1.4279100321726517, disc_loss = 0.00023992994927868832
Trained batch 287 in epoch 16, gen_loss = 1.428136861572663, disc_loss = 0.00024004642075839102
Trained batch 288 in epoch 16, gen_loss = 1.4279855382483724, disc_loss = 0.00024024971522225989
Trained batch 289 in epoch 16, gen_loss = 1.4281046575513379, disc_loss = 0.00024047765909613347
Trained batch 290 in epoch 16, gen_loss = 1.4282362997736717, disc_loss = 0.00024074359065132464
Trained batch 291 in epoch 16, gen_loss = 1.4283096537198106, disc_loss = 0.00024104169323411592
Trained batch 292 in epoch 16, gen_loss = 1.4281839079417467, disc_loss = 0.00024134047946355002
Trained batch 293 in epoch 16, gen_loss = 1.4281872960985924, disc_loss = 0.00024159916562034069
Trained batch 294 in epoch 16, gen_loss = 1.427837563773333, disc_loss = 0.0002418193827506295
Trained batch 295 in epoch 16, gen_loss = 1.4277387813136384, disc_loss = 0.00024196722276391901
Trained batch 296 in epoch 16, gen_loss = 1.4276807637327047, disc_loss = 0.00024212116208867704
Trained batch 297 in epoch 16, gen_loss = 1.4279006887602326, disc_loss = 0.00024226130213206708
Trained batch 298 in epoch 16, gen_loss = 1.427626831874401, disc_loss = 0.00024235528074079843
Trained batch 299 in epoch 16, gen_loss = 1.4274990383783976, disc_loss = 0.00024245145046431087
Trained batch 300 in epoch 16, gen_loss = 1.427115060166267, disc_loss = 0.0002426005793226358
Trained batch 301 in epoch 16, gen_loss = 1.427207099680869, disc_loss = 0.0002427161073213432
Trained batch 302 in epoch 16, gen_loss = 1.4273240334129964, disc_loss = 0.00024279886632573252
Trained batch 303 in epoch 16, gen_loss = 1.4272875350556875, disc_loss = 0.00024293155877629894
Trained batch 304 in epoch 16, gen_loss = 1.427169834590349, disc_loss = 0.00024305179397101785
Trained batch 305 in epoch 16, gen_loss = 1.4270417581196704, disc_loss = 0.00024319216449869308
Trained batch 306 in epoch 16, gen_loss = 1.4268491116719448, disc_loss = 0.0002433069652551586
Trained batch 307 in epoch 16, gen_loss = 1.4271057832550693, disc_loss = 0.00024338152060668757
Trained batch 308 in epoch 16, gen_loss = 1.427033513109275, disc_loss = 0.00024338913192975084
Trained batch 309 in epoch 16, gen_loss = 1.4273324654948327, disc_loss = 0.00024334192519804234
Trained batch 310 in epoch 16, gen_loss = 1.4272597422553794, disc_loss = 0.0002432605372360708
Trained batch 311 in epoch 16, gen_loss = 1.427317468019632, disc_loss = 0.00024311800118772598
Trained batch 312 in epoch 16, gen_loss = 1.4270924215499585, disc_loss = 0.00024290505037449144
Trained batch 313 in epoch 16, gen_loss = 1.4269904277886554, disc_loss = 0.0002426289061888128
Trained batch 314 in epoch 16, gen_loss = 1.4266563112773591, disc_loss = 0.00024228579912319436
Trained batch 315 in epoch 16, gen_loss = 1.426551843745799, disc_loss = 0.00024186134014080726
Trained batch 316 in epoch 16, gen_loss = 1.4262521800934704, disc_loss = 0.00024139709274250296
Trained batch 317 in epoch 16, gen_loss = 1.4260364174842834, disc_loss = 0.00024091689290673126
Trained batch 318 in epoch 16, gen_loss = 1.4258765692247493, disc_loss = 0.0002404305613392387
Trained batch 319 in epoch 16, gen_loss = 1.426173362508416, disc_loss = 0.00023993106505884043
Trained batch 320 in epoch 16, gen_loss = 1.426256202463049, disc_loss = 0.00023942428766401188
Trained batch 321 in epoch 16, gen_loss = 1.426325623663316, disc_loss = 0.00023888837055401042
Trained batch 322 in epoch 16, gen_loss = 1.426258548494463, disc_loss = 0.00023831646570781495
Trained batch 323 in epoch 16, gen_loss = 1.426279350931262, disc_loss = 0.0002377576240689203
Trained batch 324 in epoch 16, gen_loss = 1.4261431396924533, disc_loss = 0.00023724121044674227
Trained batch 325 in epoch 16, gen_loss = 1.4262892837904713, disc_loss = 0.00023678483574347557
Trained batch 326 in epoch 16, gen_loss = 1.4263178890269101, disc_loss = 0.00023639733170207489
Trained batch 327 in epoch 16, gen_loss = 1.4263469086187641, disc_loss = 0.00023608418109965785
Trained batch 328 in epoch 16, gen_loss = 1.4265946765801103, disc_loss = 0.00023586504732940743
Trained batch 329 in epoch 16, gen_loss = 1.4268072124683495, disc_loss = 0.00023570915642597934
Trained batch 330 in epoch 16, gen_loss = 1.4266932698535055, disc_loss = 0.00023589860926590366
Trained batch 331 in epoch 16, gen_loss = 1.4269100632294114, disc_loss = 0.0002360571088584367
Trained batch 332 in epoch 16, gen_loss = 1.4268230568539273, disc_loss = 0.00023640136369176726
Trained batch 333 in epoch 16, gen_loss = 1.4269648929555974, disc_loss = 0.0002367868685854512
Trained batch 334 in epoch 16, gen_loss = 1.4269564934630892, disc_loss = 0.00023711130063780567
Trained batch 335 in epoch 16, gen_loss = 1.4267857770125072, disc_loss = 0.00023737520817370577
Trained batch 336 in epoch 16, gen_loss = 1.4267146106289827, disc_loss = 0.00023756133398789969
Trained batch 337 in epoch 16, gen_loss = 1.4269140704849061, disc_loss = 0.00023770121971646667
Trained batch 338 in epoch 16, gen_loss = 1.4270021120707195, disc_loss = 0.00023780638304077398
Trained batch 339 in epoch 16, gen_loss = 1.427048451059005, disc_loss = 0.0002378862189476315
Trained batch 340 in epoch 16, gen_loss = 1.4271791995096066, disc_loss = 0.00023796530077665348
Trained batch 341 in epoch 16, gen_loss = 1.4270557084975883, disc_loss = 0.0002381070458365062
Trained batch 342 in epoch 16, gen_loss = 1.4267410116362502, disc_loss = 0.00023829743259094852
Trained batch 343 in epoch 16, gen_loss = 1.4271580351646556, disc_loss = 0.00023856262970279796
Trained batch 344 in epoch 16, gen_loss = 1.4268857468729435, disc_loss = 0.00023892613464367046
Trained batch 345 in epoch 16, gen_loss = 1.4269542873250267, disc_loss = 0.00023942287482848747
Trained batch 346 in epoch 16, gen_loss = 1.4269179435559582, disc_loss = 0.0002400472500944711
Trained batch 347 in epoch 16, gen_loss = 1.4269986971356403, disc_loss = 0.00024080077195708587
Trained batch 348 in epoch 16, gen_loss = 1.4271518179885296, disc_loss = 0.00024166969562539037
Trained batch 349 in epoch 16, gen_loss = 1.4272675902502878, disc_loss = 0.0002426755636276669
Trained batch 350 in epoch 16, gen_loss = 1.4273389825793752, disc_loss = 0.00024380648965156553
Trained batch 351 in epoch 16, gen_loss = 1.4274453920396892, disc_loss = 0.0002450147769107761
Trained batch 352 in epoch 16, gen_loss = 1.4274402492107143, disc_loss = 0.00024617381876833105
Trained batch 353 in epoch 16, gen_loss = 1.4273127081704005, disc_loss = 0.0002471943947334771
Trained batch 354 in epoch 16, gen_loss = 1.4273716681440112, disc_loss = 0.0002480715495270052
Trained batch 355 in epoch 16, gen_loss = 1.4273736008097617, disc_loss = 0.0002487767744543326
Trained batch 356 in epoch 16, gen_loss = 1.4274666730095358, disc_loss = 0.0002492769567257552
Trained batch 357 in epoch 16, gen_loss = 1.4276635720077173, disc_loss = 0.0002495629204755287
Trained batch 358 in epoch 16, gen_loss = 1.42763400476291, disc_loss = 0.00024958961001322275
Trained batch 359 in epoch 16, gen_loss = 1.4275424930784437, disc_loss = 0.00024938136768418596
Trained batch 360 in epoch 16, gen_loss = 1.4274354895726467, disc_loss = 0.0002490554398892651
Trained batch 361 in epoch 16, gen_loss = 1.4274593117487364, disc_loss = 0.00024867671576309845
Trained batch 362 in epoch 16, gen_loss = 1.4272963935021854, disc_loss = 0.00024826392868804967
Trained batch 363 in epoch 16, gen_loss = 1.4271304319193074, disc_loss = 0.0002478244826651572
Trained batch 364 in epoch 16, gen_loss = 1.427204258801186, disc_loss = 0.0002473592701839875
Trained batch 365 in epoch 16, gen_loss = 1.4270840143896844, disc_loss = 0.0002469202176854579
Trained batch 366 in epoch 16, gen_loss = 1.4271786411061924, disc_loss = 0.00024651392200075983
Trained batch 367 in epoch 16, gen_loss = 1.4272856618399206, disc_loss = 0.00024616228648710603
Trained batch 368 in epoch 16, gen_loss = 1.427280035768421, disc_loss = 0.00024581337740360793
Trained batch 369 in epoch 16, gen_loss = 1.427311584756181, disc_loss = 0.0002454180655936275
Trained batch 370 in epoch 16, gen_loss = 1.4271455309140393, disc_loss = 0.00024496450426112756
Trained batch 371 in epoch 16, gen_loss = 1.4271012881109792, disc_loss = 0.00024447633700708715
Trained batch 372 in epoch 16, gen_loss = 1.4271367545421898, disc_loss = 0.00024397343189892751
Trained batch 373 in epoch 16, gen_loss = 1.4271130080529075, disc_loss = 0.00024348533433730284
Trained batch 374 in epoch 16, gen_loss = 1.4271607999801637, disc_loss = 0.00024300835556884218
Trained batch 375 in epoch 16, gen_loss = 1.4271007275327723, disc_loss = 0.00024253727825849792
Trained batch 376 in epoch 16, gen_loss = 1.4269549286966299, disc_loss = 0.00024208205110545623
Trained batch 377 in epoch 16, gen_loss = 1.4267057038488842, disc_loss = 0.00024165278520220973
Trained batch 378 in epoch 16, gen_loss = 1.4267701398099633, disc_loss = 0.0002412233432114398
Trained batch 379 in epoch 16, gen_loss = 1.4267516666337063, disc_loss = 0.00024080071714850323
Trained batch 380 in epoch 16, gen_loss = 1.4267793818721621, disc_loss = 0.00024039031548817502
Trained batch 381 in epoch 16, gen_loss = 1.4267383336396742, disc_loss = 0.00024001115982497158
Trained batch 382 in epoch 16, gen_loss = 1.4267149802598877, disc_loss = 0.0002396637858773663
Trained batch 383 in epoch 16, gen_loss = 1.426670093399783, disc_loss = 0.00023938002356989804
Trained batch 384 in epoch 16, gen_loss = 1.426741082637341, disc_loss = 0.00023913072068884882
Trained batch 385 in epoch 16, gen_loss = 1.4266112576494563, disc_loss = 0.00023887988483994928
Trained batch 386 in epoch 16, gen_loss = 1.4266321766900154, disc_loss = 0.00023862496349823017
Trained batch 387 in epoch 16, gen_loss = 1.4264683047520745, disc_loss = 0.00023836052048292126
Trained batch 388 in epoch 16, gen_loss = 1.4264807385466705, disc_loss = 0.00023808784264619484
Trained batch 389 in epoch 16, gen_loss = 1.4264184808119749, disc_loss = 0.0002378177307060142
Trained batch 390 in epoch 16, gen_loss = 1.4263955244932638, disc_loss = 0.0002375500904291931
Trained batch 391 in epoch 16, gen_loss = 1.4263042695060069, disc_loss = 0.00023725280683191492
Trained batch 392 in epoch 16, gen_loss = 1.426094688835338, disc_loss = 0.00023692112750010243
Trained batch 393 in epoch 16, gen_loss = 1.4260182111396402, disc_loss = 0.00023656674539516333
Trained batch 394 in epoch 16, gen_loss = 1.4259174618539932, disc_loss = 0.00023618778419933986
Trained batch 395 in epoch 16, gen_loss = 1.4257152583261934, disc_loss = 0.00023577180910582354
Trained batch 396 in epoch 16, gen_loss = 1.425889600134016, disc_loss = 0.00023534535810618439
Trained batch 397 in epoch 16, gen_loss = 1.425985867354139, disc_loss = 0.00023493950676772819
Trained batch 398 in epoch 16, gen_loss = 1.425894153745551, disc_loss = 0.00023458243360533073
Trained batch 399 in epoch 16, gen_loss = 1.4258806812763214, disc_loss = 0.00023426554556635893
Trained batch 400 in epoch 16, gen_loss = 1.4259825760586897, disc_loss = 0.000233987100231266
Trained batch 401 in epoch 16, gen_loss = 1.4258938078856587, disc_loss = 0.00023374343130338126
Trained batch 402 in epoch 16, gen_loss = 1.425787532299979, disc_loss = 0.00023355202132187972
Trained batch 403 in epoch 16, gen_loss = 1.4256645924974196, disc_loss = 0.00023340864116801072
Trained batch 404 in epoch 16, gen_loss = 1.4255292539243345, disc_loss = 0.0002333166021838415
Trained batch 405 in epoch 16, gen_loss = 1.4254771609024461, disc_loss = 0.00023326207652250107
Trained batch 406 in epoch 16, gen_loss = 1.425540637325596, disc_loss = 0.0002332262257218991
Trained batch 407 in epoch 16, gen_loss = 1.4254663338263829, disc_loss = 0.0002331941669184494
Trained batch 408 in epoch 16, gen_loss = 1.4254091071616175, disc_loss = 0.00023319176040423797
Trained batch 409 in epoch 16, gen_loss = 1.4252981427239209, disc_loss = 0.0002332613715225307
Trained batch 410 in epoch 16, gen_loss = 1.4253277227536316, disc_loss = 0.00023335842240916962
Trained batch 411 in epoch 16, gen_loss = 1.4252282849793296, disc_loss = 0.00023342928300700046
Trained batch 412 in epoch 16, gen_loss = 1.4254325175112155, disc_loss = 0.00023348522035127883
Trained batch 413 in epoch 16, gen_loss = 1.4254099098956527, disc_loss = 0.00023351283074158865
Trained batch 414 in epoch 16, gen_loss = 1.4255054091832724, disc_loss = 0.00023354033731386634
Trained batch 415 in epoch 16, gen_loss = 1.4254308741253157, disc_loss = 0.00023358963816104522
Trained batch 416 in epoch 16, gen_loss = 1.4253616018546857, disc_loss = 0.00023369202495831983
Trained batch 417 in epoch 16, gen_loss = 1.4252096063782724, disc_loss = 0.00023388376204916552
Trained batch 418 in epoch 16, gen_loss = 1.4251900749161022, disc_loss = 0.0002341664515919382
Trained batch 419 in epoch 16, gen_loss = 1.42508753935496, disc_loss = 0.00023449184689828447
Trained batch 420 in epoch 16, gen_loss = 1.4252385232340978, disc_loss = 0.00023482487763981863
Trained batch 421 in epoch 16, gen_loss = 1.425217233280435, disc_loss = 0.0002351866429863889
Trained batch 422 in epoch 16, gen_loss = 1.4251122753670875, disc_loss = 0.0002355547074665805
Trained batch 423 in epoch 16, gen_loss = 1.4251707930047557, disc_loss = 0.00023593631839340337
Trained batch 424 in epoch 16, gen_loss = 1.4250888128841626, disc_loss = 0.00023634851805528503
Trained batch 425 in epoch 16, gen_loss = 1.425126635972323, disc_loss = 0.00023674648832532175
Trained batch 426 in epoch 16, gen_loss = 1.4251236605700062, disc_loss = 0.00023711413422327005
Trained batch 427 in epoch 16, gen_loss = 1.425101432009278, disc_loss = 0.00023742424916286904
Trained batch 428 in epoch 16, gen_loss = 1.4250988140528575, disc_loss = 0.0002376388372621348
Trained batch 429 in epoch 16, gen_loss = 1.4251495073007983, disc_loss = 0.00023778319616826066
Trained batch 430 in epoch 16, gen_loss = 1.4252855050314883, disc_loss = 0.00023788537293677086
Trained batch 431 in epoch 16, gen_loss = 1.4253658326687637, disc_loss = 0.00023794083074546034
Trained batch 432 in epoch 16, gen_loss = 1.4253994300789425, disc_loss = 0.0002379547327854981
Trained batch 433 in epoch 16, gen_loss = 1.4254271143592447, disc_loss = 0.0002379263188390828
Trained batch 434 in epoch 16, gen_loss = 1.4255137986150281, disc_loss = 0.0002378656313266711
Trained batch 435 in epoch 16, gen_loss = 1.4254744971564057, disc_loss = 0.0002377813607611
Trained batch 436 in epoch 16, gen_loss = 1.4257445379034606, disc_loss = 0.00023764830155506103
Trained batch 437 in epoch 16, gen_loss = 1.425586715952991, disc_loss = 0.00023749431860587678
Trained batch 438 in epoch 16, gen_loss = 1.4255914438286783, disc_loss = 0.00023734404063581186
Trained batch 439 in epoch 16, gen_loss = 1.425646019523794, disc_loss = 0.00023723411942765696
Trained batch 440 in epoch 16, gen_loss = 1.42568327618294, disc_loss = 0.00023720083234885742
Trained batch 441 in epoch 16, gen_loss = 1.425510899243851, disc_loss = 0.00023730942258962345
Trained batch 442 in epoch 16, gen_loss = 1.425506685711191, disc_loss = 0.00023751476918718435
Trained batch 443 in epoch 16, gen_loss = 1.4253116811180975, disc_loss = 0.00023786145025779488
Trained batch 444 in epoch 16, gen_loss = 1.4253664946288205, disc_loss = 0.00023835427253472743
Trained batch 445 in epoch 16, gen_loss = 1.4253046264028335, disc_loss = 0.0002389585883567242
Trained batch 446 in epoch 16, gen_loss = 1.4253019803855778, disc_loss = 0.00023963399446676878
Trained batch 447 in epoch 16, gen_loss = 1.4251739270985126, disc_loss = 0.0002403587805811672
Trained batch 448 in epoch 16, gen_loss = 1.424957980026381, disc_loss = 0.00024111693323750806
Trained batch 449 in epoch 16, gen_loss = 1.4248268800311619, disc_loss = 0.00024188280488589146
Trained batch 450 in epoch 16, gen_loss = 1.4247805765621413, disc_loss = 0.00024255370884478295
Trained batch 451 in epoch 16, gen_loss = 1.4247639854397394, disc_loss = 0.00024311887239539918
Trained batch 452 in epoch 16, gen_loss = 1.4247845845506681, disc_loss = 0.00024360053405331366
Trained batch 453 in epoch 16, gen_loss = 1.4247475450259472, disc_loss = 0.00024398817934240673
Trained batch 454 in epoch 16, gen_loss = 1.424639310155596, disc_loss = 0.00024430431627819074
Trained batch 455 in epoch 16, gen_loss = 1.424706514205849, disc_loss = 0.0002445340179799148
Trained batch 456 in epoch 16, gen_loss = 1.424705194174852, disc_loss = 0.0002446758725409083
Trained batch 457 in epoch 16, gen_loss = 1.4245033688420292, disc_loss = 0.00024477840279598246
Trained batch 458 in epoch 16, gen_loss = 1.4244229645510904, disc_loss = 0.0002448773371221817
Trained batch 459 in epoch 16, gen_loss = 1.4244811511558035, disc_loss = 0.000244989807025258
Trained batch 460 in epoch 16, gen_loss = 1.4244234184380984, disc_loss = 0.0002450727849075218
Trained batch 461 in epoch 16, gen_loss = 1.4245592564731449, disc_loss = 0.0002451048736589238
Trained batch 462 in epoch 16, gen_loss = 1.4246195482641266, disc_loss = 0.00024514129258745756
Trained batch 463 in epoch 16, gen_loss = 1.424621308158184, disc_loss = 0.0002452237983918386
Trained batch 464 in epoch 16, gen_loss = 1.4246540613071892, disc_loss = 0.0002453169624723453
Trained batch 465 in epoch 16, gen_loss = 1.4247229155552745, disc_loss = 0.0002453689207009842
Trained batch 466 in epoch 16, gen_loss = 1.424733185666021, disc_loss = 0.00024536099094053126
Trained batch 467 in epoch 16, gen_loss = 1.424680319861469, disc_loss = 0.0002454181540068596
Trained batch 468 in epoch 16, gen_loss = 1.4246159741110893, disc_loss = 0.0002454429481394691
Trained batch 469 in epoch 16, gen_loss = 1.4245454207379766, disc_loss = 0.00024551294672300113
Trained batch 470 in epoch 16, gen_loss = 1.4246029329907364, disc_loss = 0.00024560779186660875
Trained batch 471 in epoch 16, gen_loss = 1.424643729450339, disc_loss = 0.00024572777909971763
Trained batch 472 in epoch 16, gen_loss = 1.4244655537050823, disc_loss = 0.0002458740250355864
Trained batch 473 in epoch 16, gen_loss = 1.42463371170221, disc_loss = 0.00024601499440129993
Trained batch 474 in epoch 16, gen_loss = 1.4245907161110325, disc_loss = 0.00024611743156128797
Trained batch 475 in epoch 16, gen_loss = 1.4245265248943777, disc_loss = 0.0002461723506999193
Trained batch 476 in epoch 16, gen_loss = 1.4244440004260785, disc_loss = 0.00024617484651729684
Trained batch 477 in epoch 16, gen_loss = 1.4244829067126477, disc_loss = 0.0002461419608742777
Trained batch 478 in epoch 16, gen_loss = 1.4245894746641028, disc_loss = 0.000246079152294102
Trained batch 479 in epoch 16, gen_loss = 1.4245514432589212, disc_loss = 0.0002459655628153238
Trained batch 480 in epoch 16, gen_loss = 1.4245079217978178, disc_loss = 0.00024580315797240415
Trained batch 481 in epoch 16, gen_loss = 1.4244812316419673, disc_loss = 0.00024560496307896143
Trained batch 482 in epoch 16, gen_loss = 1.424494090534392, disc_loss = 0.0002453962815481239
Trained batch 483 in epoch 16, gen_loss = 1.4245417573727852, disc_loss = 0.0002451826992079784
Trained batch 484 in epoch 16, gen_loss = 1.4244549114679552, disc_loss = 0.0002449588377109564
Trained batch 485 in epoch 16, gen_loss = 1.4243668359493522, disc_loss = 0.0002447225628400799
Trained batch 486 in epoch 16, gen_loss = 1.4243566133158407, disc_loss = 0.0002444441672524951
Trained batch 487 in epoch 16, gen_loss = 1.4243340497134163, disc_loss = 0.000244113700078429
Trained batch 488 in epoch 16, gen_loss = 1.4242204371649307, disc_loss = 0.00024375182801325448
Trained batch 489 in epoch 16, gen_loss = 1.4242428373317328, disc_loss = 0.00024336243419495484
Trained batch 490 in epoch 16, gen_loss = 1.4241939870500273, disc_loss = 0.00024294978111486277
Trained batch 491 in epoch 16, gen_loss = 1.4240542405504522, disc_loss = 0.00024252498791781357
Trained batch 492 in epoch 16, gen_loss = 1.4239930799476515, disc_loss = 0.000242094721138353
Trained batch 493 in epoch 16, gen_loss = 1.4238749860751967, disc_loss = 0.00024164991530666995
Trained batch 494 in epoch 16, gen_loss = 1.4237863249248928, disc_loss = 0.00024119919659888826
Trained batch 495 in epoch 16, gen_loss = 1.4237778177184444, disc_loss = 0.00024077358124479303
Trained batch 496 in epoch 16, gen_loss = 1.4236321482859866, disc_loss = 0.0002403663063400735
Trained batch 497 in epoch 16, gen_loss = 1.4236094027637956, disc_loss = 0.000239978186085915
Trained batch 498 in epoch 16, gen_loss = 1.4234832632756664, disc_loss = 0.00023959737349859333
Trained batch 499 in epoch 16, gen_loss = 1.4235860395431519, disc_loss = 0.00023920362810713413
Trained batch 500 in epoch 16, gen_loss = 1.4235585337865377, disc_loss = 0.00023880568107393672
Trained batch 501 in epoch 16, gen_loss = 1.4236807317372813, disc_loss = 0.00023840774105359655
Trained batch 502 in epoch 16, gen_loss = 1.4236592521250366, disc_loss = 0.00023804274266259084
Trained batch 503 in epoch 16, gen_loss = 1.4238103330135345, disc_loss = 0.00023767710610216107
Trained batch 504 in epoch 16, gen_loss = 1.4239014205366078, disc_loss = 0.00023732689892177846
Trained batch 505 in epoch 16, gen_loss = 1.4238635296878137, disc_loss = 0.000236988559737281
Trained batch 506 in epoch 16, gen_loss = 1.4237960927350046, disc_loss = 0.0002366748725586791
Trained batch 507 in epoch 16, gen_loss = 1.42387500428778, disc_loss = 0.00023638312854641334
Trained batch 508 in epoch 16, gen_loss = 1.4236719891692426, disc_loss = 0.00023611739125080288
Trained batch 509 in epoch 16, gen_loss = 1.4237298469917448, disc_loss = 0.00023585866865330756
Trained batch 510 in epoch 16, gen_loss = 1.4237207447246096, disc_loss = 0.00023559688809080313
Trained batch 511 in epoch 16, gen_loss = 1.423694074852392, disc_loss = 0.00023533552699994686
Trained batch 512 in epoch 16, gen_loss = 1.4237412548901742, disc_loss = 0.0002351055323409608
Trained batch 513 in epoch 16, gen_loss = 1.4236066489831947, disc_loss = 0.0002349141689040149
Trained batch 514 in epoch 16, gen_loss = 1.4235331859403444, disc_loss = 0.00023473150829762815
Trained batch 515 in epoch 16, gen_loss = 1.4235369720200235, disc_loss = 0.00023453891131871633
Trained batch 516 in epoch 16, gen_loss = 1.423426632493792, disc_loss = 0.00023433772787462496
Trained batch 517 in epoch 16, gen_loss = 1.4234845893723624, disc_loss = 0.00023413821701424205
Trained batch 518 in epoch 16, gen_loss = 1.4234259888845602, disc_loss = 0.0002339653726244207
Trained batch 519 in epoch 16, gen_loss = 1.4234579964325977, disc_loss = 0.0002338446998324938
Trained batch 520 in epoch 16, gen_loss = 1.4234102724152198, disc_loss = 0.00023380709454384996
Trained batch 521 in epoch 16, gen_loss = 1.4233438900147362, disc_loss = 0.00023389969832720572
Trained batch 522 in epoch 16, gen_loss = 1.4233910649957895, disc_loss = 0.00023416581682814496
Trained batch 523 in epoch 16, gen_loss = 1.4234554708458995, disc_loss = 0.00023467500565982303
Trained batch 524 in epoch 16, gen_loss = 1.4233328578585671, disc_loss = 0.0002354514828957257
Trained batch 525 in epoch 16, gen_loss = 1.4233678284706726, disc_loss = 0.00023644056919544258
Trained batch 526 in epoch 16, gen_loss = 1.4232565580780638, disc_loss = 0.00023777394124605342
Trained batch 527 in epoch 16, gen_loss = 1.4231079545888035, disc_loss = 0.00023920792917255258
Trained batch 528 in epoch 16, gen_loss = 1.4231471411447219, disc_loss = 0.00024070239128815994
Trained batch 529 in epoch 16, gen_loss = 1.4231225405099257, disc_loss = 0.00024216747376484355
Trained batch 530 in epoch 16, gen_loss = 1.4229461949199382, disc_loss = 0.00024335902146833653
Trained batch 531 in epoch 16, gen_loss = 1.42294364585016, disc_loss = 0.0002442827312956398
Trained batch 532 in epoch 16, gen_loss = 1.4226752401069227, disc_loss = 0.000244972092774268
Trained batch 533 in epoch 16, gen_loss = 1.4226003043660511, disc_loss = 0.0002454205367469645
Trained batch 534 in epoch 16, gen_loss = 1.4226717024206001, disc_loss = 0.0002457226406851273
Trained batch 535 in epoch 16, gen_loss = 1.4226427894474856, disc_loss = 0.00024597912961292137
Trained batch 536 in epoch 16, gen_loss = 1.422758892927756, disc_loss = 0.00024619851187310254
Trained batch 537 in epoch 16, gen_loss = 1.4227582067805151, disc_loss = 0.00024650756228654537
Trained batch 538 in epoch 16, gen_loss = 1.4225941489490375, disc_loss = 0.00024686831331770324
Trained batch 539 in epoch 16, gen_loss = 1.422507526035662, disc_loss = 0.0002472894017298838
Trained batch 540 in epoch 16, gen_loss = 1.4225031423921286, disc_loss = 0.0002477866565891796
Trained batch 541 in epoch 16, gen_loss = 1.422522300063904, disc_loss = 0.00024831427087328547
Trained batch 542 in epoch 16, gen_loss = 1.4224816786869674, disc_loss = 0.0002487673324327499
Trained batch 543 in epoch 16, gen_loss = 1.4224516403149157, disc_loss = 0.0002490986304053422
Trained batch 544 in epoch 16, gen_loss = 1.4225232417430353, disc_loss = 0.0002492802918280786
Trained batch 545 in epoch 16, gen_loss = 1.4225476663627905, disc_loss = 0.00024934553352194775
Trained batch 546 in epoch 16, gen_loss = 1.4224156097694551, disc_loss = 0.0002493195237534905
Trained batch 547 in epoch 16, gen_loss = 1.4222927328443875, disc_loss = 0.0002492383552359643
Trained batch 548 in epoch 16, gen_loss = 1.422302952012512, disc_loss = 0.0002491269495009604
Trained batch 549 in epoch 16, gen_loss = 1.4221813386136835, disc_loss = 0.0002489921635341571
Trained batch 550 in epoch 16, gen_loss = 1.4222119237463617, disc_loss = 0.0002488511633935942
Trained batch 551 in epoch 16, gen_loss = 1.4221824327672736, disc_loss = 0.00024876349491280604
Trained batch 552 in epoch 16, gen_loss = 1.4221372544010984, disc_loss = 0.0002487397313141638
Trained batch 553 in epoch 16, gen_loss = 1.4220885163179804, disc_loss = 0.0002488144921679431
Trained batch 554 in epoch 16, gen_loss = 1.4220399132719985, disc_loss = 0.0002489660407501343
Trained batch 555 in epoch 16, gen_loss = 1.4219526414819759, disc_loss = 0.00024919230083645966
Trained batch 556 in epoch 16, gen_loss = 1.4219452996656325, disc_loss = 0.0002494596225884278
Trained batch 557 in epoch 16, gen_loss = 1.4217228573282987, disc_loss = 0.0002497382351552051
Trained batch 558 in epoch 16, gen_loss = 1.4217228998225149, disc_loss = 0.0002499845172133715
Trained batch 559 in epoch 16, gen_loss = 1.4217398373144015, disc_loss = 0.00025014556182441084
Trained batch 560 in epoch 16, gen_loss = 1.4217798983987002, disc_loss = 0.0002501800479928571
Trained batch 561 in epoch 16, gen_loss = 1.4218787351537006, disc_loss = 0.0002501294118853602
Trained batch 562 in epoch 16, gen_loss = 1.421825365952446, disc_loss = 0.00025005153439543615
Trained batch 563 in epoch 16, gen_loss = 1.4218097832186003, disc_loss = 0.00024995518560738396
Trained batch 564 in epoch 16, gen_loss = 1.4216813074803984, disc_loss = 0.00024984158167533886
Trained batch 565 in epoch 16, gen_loss = 1.4216272489763402, disc_loss = 0.0002497138402132763
Trained batch 566 in epoch 16, gen_loss = 1.4216891836237024, disc_loss = 0.000249579053947125
Trained batch 567 in epoch 16, gen_loss = 1.4217474930722949, disc_loss = 0.00024942626137378196
Trained batch 568 in epoch 16, gen_loss = 1.421699216579511, disc_loss = 0.0002492427524861012
Trained batch 569 in epoch 16, gen_loss = 1.4217329845093845, disc_loss = 0.00024902546424448047
Trained batch 570 in epoch 16, gen_loss = 1.4216467697440847, disc_loss = 0.0002487534105164139
Trained batch 571 in epoch 16, gen_loss = 1.4217579012567347, disc_loss = 0.00024846526034198686
Trained batch 572 in epoch 16, gen_loss = 1.4216469002019672, disc_loss = 0.00024819209855284253
Trained batch 573 in epoch 16, gen_loss = 1.4217308390015924, disc_loss = 0.0002479472292125835
Trained batch 574 in epoch 16, gen_loss = 1.4216225047733473, disc_loss = 0.0002477551132877757
Trained batch 575 in epoch 16, gen_loss = 1.4215949310196772, disc_loss = 0.0002476129149597581
Trained batch 576 in epoch 16, gen_loss = 1.4214455234322638, disc_loss = 0.0002475114941899095
Trained batch 577 in epoch 16, gen_loss = 1.4214561626985411, disc_loss = 0.0002474337290729847
Trained batch 578 in epoch 16, gen_loss = 1.421416950349363, disc_loss = 0.000247357928639447
Trained batch 579 in epoch 16, gen_loss = 1.4213559783738234, disc_loss = 0.0002472616277169311
Trained batch 580 in epoch 16, gen_loss = 1.4213712551917965, disc_loss = 0.00024714487625654213
Trained batch 581 in epoch 16, gen_loss = 1.4213589186111266, disc_loss = 0.0002470307522719278
Trained batch 582 in epoch 16, gen_loss = 1.4212307279760188, disc_loss = 0.00024695237855107025
Trained batch 583 in epoch 16, gen_loss = 1.4212072757008958, disc_loss = 0.0002469348113934707
Trained batch 584 in epoch 16, gen_loss = 1.4211776101691092, disc_loss = 0.00024698357988549665
Trained batch 585 in epoch 16, gen_loss = 1.4212374231514264, disc_loss = 0.0002470893134466572
Trained batch 586 in epoch 16, gen_loss = 1.4212884951693845, disc_loss = 0.00024722032053843074
Trained batch 587 in epoch 16, gen_loss = 1.421290851369196, disc_loss = 0.00024738463267091166
Trained batch 588 in epoch 16, gen_loss = 1.4211559991885123, disc_loss = 0.00024756994959402933
Trained batch 589 in epoch 16, gen_loss = 1.4210847929372625, disc_loss = 0.00024777500602332587
Trained batch 590 in epoch 16, gen_loss = 1.4209878236912632, disc_loss = 0.0002479809476635745
Trained batch 591 in epoch 16, gen_loss = 1.4208804103168282, disc_loss = 0.0002481964438061368
Trained batch 592 in epoch 16, gen_loss = 1.4208779095799284, disc_loss = 0.00024844253387651947
Trained batch 593 in epoch 16, gen_loss = 1.421027467307017, disc_loss = 0.00024870733191945495
Trained batch 594 in epoch 16, gen_loss = 1.4209446943106772, disc_loss = 0.0002489311050668534
Trained batch 595 in epoch 16, gen_loss = 1.421078874760826, disc_loss = 0.00024908537794611973
Trained batch 596 in epoch 16, gen_loss = 1.4209419802405328, disc_loss = 0.0002492210068457078
Trained batch 597 in epoch 16, gen_loss = 1.4209149623395607, disc_loss = 0.00024935137995624207
Trained batch 598 in epoch 16, gen_loss = 1.4209722413841592, disc_loss = 0.0002493884540005436
Trained batch 599 in epoch 16, gen_loss = 1.420867214401563, disc_loss = 0.0002492960158921657
Trained batch 600 in epoch 16, gen_loss = 1.4207026567712997, disc_loss = 0.000249115614061458
Trained batch 601 in epoch 16, gen_loss = 1.4207919810301441, disc_loss = 0.00024888135787048884
Trained batch 602 in epoch 16, gen_loss = 1.420689582231626, disc_loss = 0.00024860687485074725
Trained batch 603 in epoch 16, gen_loss = 1.4206627704055104, disc_loss = 0.0002483159452795188
Trained batch 604 in epoch 16, gen_loss = 1.4205391556763451, disc_loss = 0.00024803318183556195
Trained batch 605 in epoch 16, gen_loss = 1.420529845130719, disc_loss = 0.00024774582502221575
Trained batch 606 in epoch 16, gen_loss = 1.420322276811427, disc_loss = 0.00024745904127191444
Trained batch 607 in epoch 16, gen_loss = 1.4202972030953358, disc_loss = 0.000247162108344786
Trained batch 608 in epoch 16, gen_loss = 1.4204194408723678, disc_loss = 0.00024685805194812346
Trained batch 609 in epoch 16, gen_loss = 1.4203007455732002, disc_loss = 0.00024658998264519635
Trained batch 610 in epoch 16, gen_loss = 1.4202765981421337, disc_loss = 0.0002463927187025237
Trained batch 611 in epoch 16, gen_loss = 1.4202033452738345, disc_loss = 0.00024621098271744536
Trained batch 612 in epoch 16, gen_loss = 1.4201548430114548, disc_loss = 0.000245965484444072
Trained batch 613 in epoch 16, gen_loss = 1.419939581462537, disc_loss = 0.00024568894787228477
Trained batch 614 in epoch 16, gen_loss = 1.4199963178091901, disc_loss = 0.00024539549457829973
Trained batch 615 in epoch 16, gen_loss = 1.4199793919340356, disc_loss = 0.00024512292356410563
Trained batch 616 in epoch 16, gen_loss = 1.4198078494790694, disc_loss = 0.0002448727224255806
Trained batch 617 in epoch 16, gen_loss = 1.4198180815162782, disc_loss = 0.00024461434855901524
Trained batch 618 in epoch 16, gen_loss = 1.4197565534773473, disc_loss = 0.00024434666734703684
Trained batch 619 in epoch 16, gen_loss = 1.4197353861024302, disc_loss = 0.00024405634096858134
Trained batch 620 in epoch 16, gen_loss = 1.419751473095106, disc_loss = 0.00024375341770839013
Trained batch 621 in epoch 16, gen_loss = 1.4197712513794853, disc_loss = 0.00024346360791025344
Trained batch 622 in epoch 16, gen_loss = 1.4196854278708346, disc_loss = 0.00024318397836001725
Trained batch 623 in epoch 16, gen_loss = 1.4196852623270109, disc_loss = 0.0002428962232207036
Trained batch 624 in epoch 16, gen_loss = 1.4196611543655395, disc_loss = 0.00024261528484494194
Trained batch 625 in epoch 16, gen_loss = 1.4196252581029654, disc_loss = 0.00024232879779313439
Trained batch 626 in epoch 16, gen_loss = 1.4196854008441906, disc_loss = 0.00024203033213574166
Trained batch 627 in epoch 16, gen_loss = 1.4196393852400933, disc_loss = 0.00024178081343961821
Trained batch 628 in epoch 16, gen_loss = 1.4196030826371502, disc_loss = 0.0002415682124802083
Trained batch 629 in epoch 16, gen_loss = 1.4196137398008317, disc_loss = 0.00024135871453547715
Trained batch 630 in epoch 16, gen_loss = 1.4196709033615427, disc_loss = 0.00024112989092499147
Trained batch 631 in epoch 16, gen_loss = 1.419571963292134, disc_loss = 0.00024092153848092102
Trained batch 632 in epoch 16, gen_loss = 1.4195113306361917, disc_loss = 0.0002407069407535034
Trained batch 633 in epoch 16, gen_loss = 1.4194608357050442, disc_loss = 0.00024048231194993326
Trained batch 634 in epoch 16, gen_loss = 1.419409594761105, disc_loss = 0.00024028075586675116
Trained batch 635 in epoch 16, gen_loss = 1.419395813589576, disc_loss = 0.00024019652103435542
Trained batch 636 in epoch 16, gen_loss = 1.4193761539608942, disc_loss = 0.00024023404991568503
Trained batch 637 in epoch 16, gen_loss = 1.4192828709802658, disc_loss = 0.00024185269716737285
Trained batch 638 in epoch 16, gen_loss = 1.4199295961800875, disc_loss = 0.000281213418729151
Trained batch 639 in epoch 16, gen_loss = 1.420549905858934, disc_loss = 0.0005907315866394925
Trained batch 640 in epoch 16, gen_loss = 1.419971246801189, disc_loss = 0.002101208798536368
Trained batch 641 in epoch 16, gen_loss = 1.4213625005101118, disc_loss = 0.002833308517499043
Trained batch 642 in epoch 16, gen_loss = 1.4220276396159621, disc_loss = 0.0032741599480923212
Trained batch 643 in epoch 16, gen_loss = 1.4217748058878856, disc_loss = 0.003575790938506125
Trained batch 644 in epoch 16, gen_loss = 1.4214652721271959, disc_loss = 0.003824478629330981
Trained batch 645 in epoch 16, gen_loss = 1.4218691853177805, disc_loss = 0.003992772611055491
Trained batch 646 in epoch 16, gen_loss = 1.4219359146572155, disc_loss = 0.0041513894278010985
Trained batch 647 in epoch 16, gen_loss = 1.421567459165314, disc_loss = 0.004253394992661239
Trained batch 648 in epoch 16, gen_loss = 1.421972620101482, disc_loss = 0.0044706833462067695
Trained batch 649 in epoch 16, gen_loss = 1.4229296313799344, disc_loss = 0.00463994463941932
Trained batch 650 in epoch 16, gen_loss = 1.4230821740608977, disc_loss = 0.004653173439085852
Trained batch 651 in epoch 16, gen_loss = 1.4229836542547847, disc_loss = 0.004680044382337689
Trained batch 652 in epoch 16, gen_loss = 1.4229340529551366, disc_loss = 0.004681982357090504
Trained batch 653 in epoch 16, gen_loss = 1.4232037929584491, disc_loss = 0.004682829101226657
Trained batch 654 in epoch 16, gen_loss = 1.4236700292762, disc_loss = 0.0046837571421893065
Trained batch 655 in epoch 16, gen_loss = 1.423950669423836, disc_loss = 0.0046808788188769076
Trained batch 656 in epoch 16, gen_loss = 1.4242029130186664, disc_loss = 0.004677634446317432
Trained batch 657 in epoch 16, gen_loss = 1.4244821767314226, disc_loss = 0.004674101409741427
Trained batch 658 in epoch 16, gen_loss = 1.4249257232784682, disc_loss = 0.004669770753871669
Trained batch 659 in epoch 16, gen_loss = 1.4253130455811818, disc_loss = 0.004665581234840746
Trained batch 660 in epoch 16, gen_loss = 1.4253907634703367, disc_loss = 0.0046614992307996836
Trained batch 661 in epoch 16, gen_loss = 1.4253988094920478, disc_loss = 0.004657432013314985
Trained batch 662 in epoch 16, gen_loss = 1.4255492313235414, disc_loss = 0.004653046242819599
Trained batch 663 in epoch 16, gen_loss = 1.4257627386285598, disc_loss = 0.004647925960890155
Trained batch 664 in epoch 16, gen_loss = 1.425855050768171, disc_loss = 0.004642865419763049
Trained batch 665 in epoch 16, gen_loss = 1.4263521368439134, disc_loss = 0.004638370927063756
Trained batch 666 in epoch 16, gen_loss = 1.426429311017404, disc_loss = 0.004632933022887131
Trained batch 667 in epoch 16, gen_loss = 1.4265798390982394, disc_loss = 0.004627459233597347
Trained batch 668 in epoch 16, gen_loss = 1.4266955296554908, disc_loss = 0.0046218318286321645
Trained batch 669 in epoch 16, gen_loss = 1.4270520233396273, disc_loss = 0.00461669831637895
Trained batch 670 in epoch 16, gen_loss = 1.427204051245165, disc_loss = 0.004611215301746219
Trained batch 671 in epoch 16, gen_loss = 1.4271784110793047, disc_loss = 0.004605863774317175
Trained batch 672 in epoch 16, gen_loss = 1.4275229423573963, disc_loss = 0.0046009338697193414
Trained batch 673 in epoch 16, gen_loss = 1.4278962001956181, disc_loss = 0.004595612788069841
Trained batch 674 in epoch 16, gen_loss = 1.4279934404514454, disc_loss = 0.004590799090870456
Trained batch 675 in epoch 16, gen_loss = 1.4281992097578105, disc_loss = 0.0045849693590917446
Trained batch 676 in epoch 16, gen_loss = 1.428340847594347, disc_loss = 0.004579100155559694
Trained batch 677 in epoch 16, gen_loss = 1.428379495938619, disc_loss = 0.004573427034689533
Trained batch 678 in epoch 16, gen_loss = 1.4285881478937454, disc_loss = 0.004567921736702742
Trained batch 679 in epoch 16, gen_loss = 1.4286578432602042, disc_loss = 0.0045621022545286475
Trained batch 680 in epoch 16, gen_loss = 1.4287644482919297, disc_loss = 0.004556144094088384
Trained batch 681 in epoch 16, gen_loss = 1.4289769906102736, disc_loss = 0.0045503147543568155
Trained batch 682 in epoch 16, gen_loss = 1.4290901783793772, disc_loss = 0.004544412906252919
Trained batch 683 in epoch 16, gen_loss = 1.4292734786432388, disc_loss = 0.004538442340214731
Trained batch 684 in epoch 16, gen_loss = 1.4293153101510374, disc_loss = 0.004532806669751657
Trained batch 685 in epoch 16, gen_loss = 1.429414492480609, disc_loss = 0.004526852349014437
Trained batch 686 in epoch 16, gen_loss = 1.4295024418934985, disc_loss = 0.004520978202331876
Trained batch 687 in epoch 16, gen_loss = 1.4296516985740773, disc_loss = 0.004515008487142622
Trained batch 688 in epoch 16, gen_loss = 1.4299235515220763, disc_loss = 0.004509525102354607
Trained batch 689 in epoch 16, gen_loss = 1.430108844715616, disc_loss = 0.004503682359721269
Trained batch 690 in epoch 16, gen_loss = 1.4305022728943446, disc_loss = 0.004498096956619655
Trained batch 691 in epoch 16, gen_loss = 1.430638982898238, disc_loss = 0.0044921245807020465
Trained batch 692 in epoch 16, gen_loss = 1.4307057176317488, disc_loss = 0.004486106784605296
Trained batch 693 in epoch 16, gen_loss = 1.4307509344661613, disc_loss = 0.004480315891146412
Trained batch 694 in epoch 16, gen_loss = 1.4308536615303094, disc_loss = 0.004474407074794334
Trained batch 695 in epoch 16, gen_loss = 1.4309098533857827, disc_loss = 0.004468478217058194
Trained batch 696 in epoch 16, gen_loss = 1.4310911392720904, disc_loss = 0.004462561412775792
Trained batch 697 in epoch 16, gen_loss = 1.4310938680069494, disc_loss = 0.004456887224807782
Trained batch 698 in epoch 16, gen_loss = 1.4313158934379, disc_loss = 0.0044513583349540045
Trained batch 699 in epoch 16, gen_loss = 1.4314128855296544, disc_loss = 0.004445631049751942
Trained batch 700 in epoch 16, gen_loss = 1.4314911124029446, disc_loss = 0.004439895570349485
Trained batch 701 in epoch 16, gen_loss = 1.4316421536638526, disc_loss = 0.004434221669310077
Trained batch 702 in epoch 16, gen_loss = 1.431700576928737, disc_loss = 0.004428302642376868
Trained batch 703 in epoch 16, gen_loss = 1.4318246827884153, disc_loss = 0.004422472995557314
Trained batch 704 in epoch 16, gen_loss = 1.4321799467641412, disc_loss = 0.004416965505777574
Trained batch 705 in epoch 16, gen_loss = 1.4323069826401664, disc_loss = 0.0044112749695509835
Trained batch 706 in epoch 16, gen_loss = 1.4323418538337718, disc_loss = 0.004405444770038649
Trained batch 707 in epoch 16, gen_loss = 1.432367103584742, disc_loss = 0.0043998482943558275
Trained batch 708 in epoch 16, gen_loss = 1.432588966508174, disc_loss = 0.0043942504195907325
Trained batch 709 in epoch 16, gen_loss = 1.4326912601229171, disc_loss = 0.004388439211822809
Trained batch 710 in epoch 16, gen_loss = 1.4328071625088505, disc_loss = 0.0043827133896650345
Trained batch 711 in epoch 16, gen_loss = 1.4329203407416182, disc_loss = 0.004376927404555471
Trained batch 712 in epoch 16, gen_loss = 1.4329430170848358, disc_loss = 0.00437111535102125
Trained batch 713 in epoch 16, gen_loss = 1.4331558588840045, disc_loss = 0.0043654576239018
Trained batch 714 in epoch 16, gen_loss = 1.4331528800350803, disc_loss = 0.0043598335667004405
Trained batch 715 in epoch 16, gen_loss = 1.4333914774756191, disc_loss = 0.004354309372068876
Trained batch 716 in epoch 16, gen_loss = 1.4334141163978948, disc_loss = 0.004348664633015201
Trained batch 717 in epoch 16, gen_loss = 1.4335899676785164, disc_loss = 0.004343025721963612
Trained batch 718 in epoch 16, gen_loss = 1.4337596782225395, disc_loss = 0.004337385083343328
Trained batch 719 in epoch 16, gen_loss = 1.433948417007923, disc_loss = 0.004331765529063129
Trained batch 720 in epoch 16, gen_loss = 1.433967357700311, disc_loss = 0.00432627531320775
Trained batch 721 in epoch 16, gen_loss = 1.4342945003443477, disc_loss = 0.004321061619648289
Trained batch 722 in epoch 16, gen_loss = 1.4343004399810095, disc_loss = 0.004315572705868809
Trained batch 723 in epoch 16, gen_loss = 1.4343840015527294, disc_loss = 0.004309961888978285
Trained batch 724 in epoch 16, gen_loss = 1.4346460957362734, disc_loss = 0.004304563315380274
Trained batch 725 in epoch 16, gen_loss = 1.4346259571304005, disc_loss = 0.00429914011629982
Trained batch 726 in epoch 16, gen_loss = 1.434738757521775, disc_loss = 0.004293529712971103
Trained batch 727 in epoch 16, gen_loss = 1.4348508294794586, disc_loss = 0.00428792762644097
Trained batch 728 in epoch 16, gen_loss = 1.4351443918971205, disc_loss = 0.004282381253443544
Trained batch 729 in epoch 16, gen_loss = 1.4352368069021668, disc_loss = 0.004276904313249124
Trained batch 730 in epoch 16, gen_loss = 1.4352834620978046, disc_loss = 0.004271291616205616
Trained batch 731 in epoch 16, gen_loss = 1.4354301239949105, disc_loss = 0.004265775944200183
Trained batch 732 in epoch 16, gen_loss = 1.435555959951341, disc_loss = 0.004260183531273922
Trained batch 733 in epoch 16, gen_loss = 1.435831945013935, disc_loss = 0.004254756885982056
Trained batch 734 in epoch 16, gen_loss = 1.4358988984101484, disc_loss = 0.004249249732059806
Trained batch 735 in epoch 16, gen_loss = 1.4359326532677463, disc_loss = 0.0042437405222736525
Trained batch 736 in epoch 16, gen_loss = 1.4361781580639015, disc_loss = 0.0042384037301349394
Trained batch 737 in epoch 16, gen_loss = 1.4362620238043105, disc_loss = 0.004232903902185519
Trained batch 738 in epoch 16, gen_loss = 1.436270150505964, disc_loss = 0.004227621682643006
Trained batch 739 in epoch 16, gen_loss = 1.4362238951631494, disc_loss = 0.004222409457237075
Trained batch 740 in epoch 16, gen_loss = 1.4362669972433897, disc_loss = 0.004216975641094767
Trained batch 741 in epoch 16, gen_loss = 1.4363524798113059, disc_loss = 0.004211625378598111
Trained batch 742 in epoch 16, gen_loss = 1.4364129104331878, disc_loss = 0.004206297948633792
Trained batch 743 in epoch 16, gen_loss = 1.436484585526169, disc_loss = 0.004200973381766597
Trained batch 744 in epoch 16, gen_loss = 1.4365184723130808, disc_loss = 0.00419557280643528
Trained batch 745 in epoch 16, gen_loss = 1.4365238469024126, disc_loss = 0.004190246190967752
Testing Epoch 16

Training Epoch 17
Trained batch 0 in epoch 17, gen_loss = 1.5248103141784668, disc_loss = 0.000233339931583032
Trained batch 1 in epoch 17, gen_loss = 1.5713001489639282, disc_loss = 0.0003694356855703518
Trained batch 2 in epoch 17, gen_loss = 1.5443902413050334, disc_loss = 0.00036729297911127407
Trained batch 3 in epoch 17, gen_loss = 1.5298242270946503, disc_loss = 0.00033079151762649417
Trained batch 4 in epoch 17, gen_loss = 1.5110225915908813, disc_loss = 0.0003261512552853674
Trained batch 5 in epoch 17, gen_loss = 1.5125293533007305, disc_loss = 0.00031073754022751626
Trained batch 6 in epoch 17, gen_loss = 1.5137323992592948, disc_loss = 0.0002999246145399021
Trained batch 7 in epoch 17, gen_loss = 1.5102776288986206, disc_loss = 0.00029462436577887274
Trained batch 8 in epoch 17, gen_loss = 1.5071296294530232, disc_loss = 0.00027983826779139537
Trained batch 9 in epoch 17, gen_loss = 1.5024052500724792, disc_loss = 0.00027305307885399087
Trained batch 10 in epoch 17, gen_loss = 1.503432198004289, disc_loss = 0.0002694120035316287
Trained batch 11 in epoch 17, gen_loss = 1.497414102156957, disc_loss = 0.00026749507257288013
Trained batch 12 in epoch 17, gen_loss = 1.4976926033313458, disc_loss = 0.0002587887776406625
Trained batch 13 in epoch 17, gen_loss = 1.4913196223122733, disc_loss = 0.0002560215777651008
Trained batch 14 in epoch 17, gen_loss = 1.487990673383077, disc_loss = 0.0002565620932728052
Trained batch 15 in epoch 17, gen_loss = 1.49146518856287, disc_loss = 0.0002568449799582595
Trained batch 16 in epoch 17, gen_loss = 1.494935477481169, disc_loss = 0.00025154903157860697
Trained batch 17 in epoch 17, gen_loss = 1.4938993983798556, disc_loss = 0.0002492992215492349
Trained batch 18 in epoch 17, gen_loss = 1.4941249960347225, disc_loss = 0.0002441846598613713
Trained batch 19 in epoch 17, gen_loss = 1.493586927652359, disc_loss = 0.0002402060097665526
Trained batch 20 in epoch 17, gen_loss = 1.4939886785688854, disc_loss = 0.00023535272200769257
Trained batch 21 in epoch 17, gen_loss = 1.492111552845348, disc_loss = 0.0002324992118784311
Trained batch 22 in epoch 17, gen_loss = 1.494639464046644, disc_loss = 0.00023139684471180257
Trained batch 23 in epoch 17, gen_loss = 1.4976853132247925, disc_loss = 0.00022825217153391955
Trained batch 24 in epoch 17, gen_loss = 1.4989412117004395, disc_loss = 0.00022482790343929083
Trained batch 25 in epoch 17, gen_loss = 1.498563752724574, disc_loss = 0.00022194554856888807
Trained batch 26 in epoch 17, gen_loss = 1.5021160046259563, disc_loss = 0.00022196394221046594
Trained batch 27 in epoch 17, gen_loss = 1.5019796448094505, disc_loss = 0.00022252475485272174
Trained batch 28 in epoch 17, gen_loss = 1.5011155276462949, disc_loss = 0.00022120750157949355
Trained batch 29 in epoch 17, gen_loss = 1.5030240535736084, disc_loss = 0.00022114515450084583
Trained batch 30 in epoch 17, gen_loss = 1.5050033830827283, disc_loss = 0.00022124274936129127
Trained batch 31 in epoch 17, gen_loss = 1.5061203055083752, disc_loss = 0.00021972422609906062
Trained batch 32 in epoch 17, gen_loss = 1.5032570253718982, disc_loss = 0.00022385828770259678
Trained batch 33 in epoch 17, gen_loss = 1.5023233925595003, disc_loss = 0.00022350690372096484
Trained batch 34 in epoch 17, gen_loss = 1.5025729417800904, disc_loss = 0.00022154708567541094
Trained batch 35 in epoch 17, gen_loss = 1.5032444728745356, disc_loss = 0.00021945416139917343
Trained batch 36 in epoch 17, gen_loss = 1.5038886843500912, disc_loss = 0.00021923984270354077
Trained batch 37 in epoch 17, gen_loss = 1.501884661222759, disc_loss = 0.00021867497592833579
Trained batch 38 in epoch 17, gen_loss = 1.499242174319732, disc_loss = 0.0002185743584190137
Trained batch 39 in epoch 17, gen_loss = 1.502941507101059, disc_loss = 0.00022367826240952127
Trained batch 40 in epoch 17, gen_loss = 1.5036726550358097, disc_loss = 0.000221809507887129
Trained batch 41 in epoch 17, gen_loss = 1.5015295999390739, disc_loss = 0.0002213765006412619
Trained batch 42 in epoch 17, gen_loss = 1.502558902252552, disc_loss = 0.00022060295829527774
Trained batch 43 in epoch 17, gen_loss = 1.5037896091287786, disc_loss = 0.00021938461312939498
Trained batch 44 in epoch 17, gen_loss = 1.5056768311394586, disc_loss = 0.00021808820666693564
Trained batch 45 in epoch 17, gen_loss = 1.5051484496697136, disc_loss = 0.00021824086655650044
Trained batch 46 in epoch 17, gen_loss = 1.5030664586006326, disc_loss = 0.00021848806639528892
Trained batch 47 in epoch 17, gen_loss = 1.5054959580302238, disc_loss = 0.00021980607834848342
Trained batch 48 in epoch 17, gen_loss = 1.5055454920749276, disc_loss = 0.00021773921141676528
Trained batch 49 in epoch 17, gen_loss = 1.5052401518821716, disc_loss = 0.00021584139933111145
Trained batch 50 in epoch 17, gen_loss = 1.5049099945554547, disc_loss = 0.00021484540861017783
Trained batch 51 in epoch 17, gen_loss = 1.5049535517509167, disc_loss = 0.00021370529318049265
Trained batch 52 in epoch 17, gen_loss = 1.50525970503969, disc_loss = 0.0002121606142642328
Trained batch 53 in epoch 17, gen_loss = 1.5044905896540042, disc_loss = 0.0002117835567871764
Trained batch 54 in epoch 17, gen_loss = 1.5031410867517645, disc_loss = 0.00021101781511044298
Trained batch 55 in epoch 17, gen_loss = 1.5005196588379996, disc_loss = 0.00021295970119743806
Trained batch 56 in epoch 17, gen_loss = 1.4999326885792248, disc_loss = 0.0002135489753288168
Trained batch 57 in epoch 17, gen_loss = 1.4991546417104786, disc_loss = 0.0002127260354584372
Trained batch 58 in epoch 17, gen_loss = 1.4979715791799255, disc_loss = 0.00021176200835586732
Trained batch 59 in epoch 17, gen_loss = 1.498694896697998, disc_loss = 0.00021107933910874028
Trained batch 60 in epoch 17, gen_loss = 1.4982060408983073, disc_loss = 0.00020939469114174974
Trained batch 61 in epoch 17, gen_loss = 1.4973766150013093, disc_loss = 0.00020909561370048793
Trained batch 62 in epoch 17, gen_loss = 1.497388101759411, disc_loss = 0.00020801528963992105
Trained batch 63 in epoch 17, gen_loss = 1.4977736361324787, disc_loss = 0.00020656271988173103
Trained batch 64 in epoch 17, gen_loss = 1.4980517075611994, disc_loss = 0.00020535160135925533
Trained batch 65 in epoch 17, gen_loss = 1.4983876076611606, disc_loss = 0.00020391853677486353
Trained batch 66 in epoch 17, gen_loss = 1.4988934726857428, disc_loss = 0.00020353493305468764
Trained batch 67 in epoch 17, gen_loss = 1.4977340014541851, disc_loss = 0.00020301026629835286
Trained batch 68 in epoch 17, gen_loss = 1.4959467960440593, disc_loss = 0.00020194670155499318
Trained batch 69 in epoch 17, gen_loss = 1.4967961668968202, disc_loss = 0.00020252228745708375
Trained batch 70 in epoch 17, gen_loss = 1.4960245448099057, disc_loss = 0.00020129599169463994
Trained batch 71 in epoch 17, gen_loss = 1.4974644316567316, disc_loss = 0.00020067762579856208
Trained batch 72 in epoch 17, gen_loss = 1.496367046277817, disc_loss = 0.00019976620537257586
Trained batch 73 in epoch 17, gen_loss = 1.496583108966415, disc_loss = 0.00019888429773886487
Trained batch 74 in epoch 17, gen_loss = 1.496355341275533, disc_loss = 0.00019746823265450074
Trained batch 75 in epoch 17, gen_loss = 1.4962550746767145, disc_loss = 0.00019645303817876418
Trained batch 76 in epoch 17, gen_loss = 1.4960014417574004, disc_loss = 0.00019546927522880013
Trained batch 77 in epoch 17, gen_loss = 1.4971075057983398, disc_loss = 0.0001952704661585486
Trained batch 78 in epoch 17, gen_loss = 1.4965293211273, disc_loss = 0.00019489265160481858
Trained batch 79 in epoch 17, gen_loss = 1.4961683347821235, disc_loss = 0.00019391842479308253
Trained batch 80 in epoch 17, gen_loss = 1.4964743764312178, disc_loss = 0.00019265054558032985
Trained batch 81 in epoch 17, gen_loss = 1.4960918615504009, disc_loss = 0.00019194924731514554
Trained batch 82 in epoch 17, gen_loss = 1.4968739690550839, disc_loss = 0.00019099562527423905
Trained batch 83 in epoch 17, gen_loss = 1.4969795587516965, disc_loss = 0.00018983086010848638
Trained batch 84 in epoch 17, gen_loss = 1.4972339588053085, disc_loss = 0.0001885603491887998
Trained batch 85 in epoch 17, gen_loss = 1.4979325089343758, disc_loss = 0.00018757910406430858
Trained batch 86 in epoch 17, gen_loss = 1.4967789375919036, disc_loss = 0.00018702300799670681
Trained batch 87 in epoch 17, gen_loss = 1.4969744330102748, disc_loss = 0.0001865128963552045
Trained batch 88 in epoch 17, gen_loss = 1.4960199380188846, disc_loss = 0.00018631464406374445
Trained batch 89 in epoch 17, gen_loss = 1.4957156194580925, disc_loss = 0.0001857073548308108
Trained batch 90 in epoch 17, gen_loss = 1.4957528454916817, disc_loss = 0.00018468817031064717
Trained batch 91 in epoch 17, gen_loss = 1.4959254990453306, disc_loss = 0.00018393413539224244
Trained batch 92 in epoch 17, gen_loss = 1.4959264237393615, disc_loss = 0.00018320400344510812
Trained batch 93 in epoch 17, gen_loss = 1.4956840961537463, disc_loss = 0.00018282286041636673
Trained batch 94 in epoch 17, gen_loss = 1.4959552915472734, disc_loss = 0.00018207353630139933
Trained batch 95 in epoch 17, gen_loss = 1.4960359533627827, disc_loss = 0.00018151437560239478
Trained batch 96 in epoch 17, gen_loss = 1.4957946035050855, disc_loss = 0.0001807330757860795
Trained batch 97 in epoch 17, gen_loss = 1.4949069169102882, disc_loss = 0.00018060809793960474
Trained batch 98 in epoch 17, gen_loss = 1.4959187290885232, disc_loss = 0.00018040415917045785
Trained batch 99 in epoch 17, gen_loss = 1.4956204664707184, disc_loss = 0.00017939136174391023
Trained batch 100 in epoch 17, gen_loss = 1.4956528562130313, disc_loss = 0.00017852565483420643
Trained batch 101 in epoch 17, gen_loss = 1.495871825545442, disc_loss = 0.00017747821459802342
Trained batch 102 in epoch 17, gen_loss = 1.495797790369941, disc_loss = 0.00017681274519559646
Trained batch 103 in epoch 17, gen_loss = 1.495242646107307, disc_loss = 0.00017649899452338176
Trained batch 104 in epoch 17, gen_loss = 1.4945775645119803, disc_loss = 0.00017603017858207402
Trained batch 105 in epoch 17, gen_loss = 1.4942971670402672, disc_loss = 0.0001754597156695178
Trained batch 106 in epoch 17, gen_loss = 1.4937417574017962, disc_loss = 0.00017559114994838068
Trained batch 107 in epoch 17, gen_loss = 1.492951743028782, disc_loss = 0.0001755398151106891
Trained batch 108 in epoch 17, gen_loss = 1.4928907593455882, disc_loss = 0.00017519661243001016
Trained batch 109 in epoch 17, gen_loss = 1.4926258444786071, disc_loss = 0.00017445824103726244
Trained batch 110 in epoch 17, gen_loss = 1.4926441993799295, disc_loss = 0.00017462388417255638
Trained batch 111 in epoch 17, gen_loss = 1.4927028779472624, disc_loss = 0.00017424485823929508
Trained batch 112 in epoch 17, gen_loss = 1.491889755282782, disc_loss = 0.00017415341561602478
Trained batch 113 in epoch 17, gen_loss = 1.493064166161052, disc_loss = 0.0001740210428946292
Trained batch 114 in epoch 17, gen_loss = 1.4923689313556836, disc_loss = 0.00017371798635197237
Trained batch 115 in epoch 17, gen_loss = 1.4921223593169246, disc_loss = 0.00017310009627243713
Trained batch 116 in epoch 17, gen_loss = 1.492689058311984, disc_loss = 0.00017240988717486078
Trained batch 117 in epoch 17, gen_loss = 1.4915816511138011, disc_loss = 0.00017185162283505818
Trained batch 118 in epoch 17, gen_loss = 1.4914243121107085, disc_loss = 0.0001710788852475513
Trained batch 119 in epoch 17, gen_loss = 1.491145098209381, disc_loss = 0.00017047733836079716
Trained batch 120 in epoch 17, gen_loss = 1.491440446908809, disc_loss = 0.00016972544180442894
Trained batch 121 in epoch 17, gen_loss = 1.4907929056980571, disc_loss = 0.00016942123192330045
Trained batch 122 in epoch 17, gen_loss = 1.4914374448419587, disc_loss = 0.00016951816738819763
Trained batch 123 in epoch 17, gen_loss = 1.4913562651603454, disc_loss = 0.00016884163573371142
Trained batch 124 in epoch 17, gen_loss = 1.4908122367858887, disc_loss = 0.00016827733151149004
Trained batch 125 in epoch 17, gen_loss = 1.4913370041620164, disc_loss = 0.00016776020701010047
Trained batch 126 in epoch 17, gen_loss = 1.491813452225032, disc_loss = 0.00016740879250642674
Trained batch 127 in epoch 17, gen_loss = 1.4913005661219358, disc_loss = 0.00016746874598538852
Trained batch 128 in epoch 17, gen_loss = 1.4915956240291743, disc_loss = 0.00016709000598449738
Trained batch 129 in epoch 17, gen_loss = 1.4916456690201392, disc_loss = 0.00016648780376551887
Trained batch 130 in epoch 17, gen_loss = 1.4910640780252356, disc_loss = 0.00016626255936211487
Trained batch 131 in epoch 17, gen_loss = 1.4905403626687599, disc_loss = 0.00016569395792788728
Trained batch 132 in epoch 17, gen_loss = 1.490812295361569, disc_loss = 0.0001654292368071847
Trained batch 133 in epoch 17, gen_loss = 1.4912060250097245, disc_loss = 0.00016532854585162948
Trained batch 134 in epoch 17, gen_loss = 1.4912635918016788, disc_loss = 0.00016519500657321057
Trained batch 135 in epoch 17, gen_loss = 1.4915332531227785, disc_loss = 0.0001645362296639017
Trained batch 136 in epoch 17, gen_loss = 1.491564071961563, disc_loss = 0.00016416813890376625
Trained batch 137 in epoch 17, gen_loss = 1.4919219353924627, disc_loss = 0.00016361370517583765
Trained batch 138 in epoch 17, gen_loss = 1.4918453230274666, disc_loss = 0.00016285658086103173
Trained batch 139 in epoch 17, gen_loss = 1.491876597063882, disc_loss = 0.00016220809128364116
Trained batch 140 in epoch 17, gen_loss = 1.4927003324454557, disc_loss = 0.0001618502806227717
Trained batch 141 in epoch 17, gen_loss = 1.4927052838701598, disc_loss = 0.0001611801097323236
Trained batch 142 in epoch 17, gen_loss = 1.4921720853218665, disc_loss = 0.00016093449957625634
Trained batch 143 in epoch 17, gen_loss = 1.4920940639244185, disc_loss = 0.00016024531429239787
Trained batch 144 in epoch 17, gen_loss = 1.4914907956945485, disc_loss = 0.0001601169822418436
Trained batch 145 in epoch 17, gen_loss = 1.4911309864423046, disc_loss = 0.00015958457837245675
Trained batch 146 in epoch 17, gen_loss = 1.4908758401870728, disc_loss = 0.00015928470411319696
Trained batch 147 in epoch 17, gen_loss = 1.4905324715214807, disc_loss = 0.00015891592893485968
Trained batch 148 in epoch 17, gen_loss = 1.490722503438092, disc_loss = 0.00015854267836622614
Trained batch 149 in epoch 17, gen_loss = 1.490758200486501, disc_loss = 0.00015812626309828678
Trained batch 150 in epoch 17, gen_loss = 1.4905559108746762, disc_loss = 0.0001575599287646986
Trained batch 151 in epoch 17, gen_loss = 1.4902451626564328, disc_loss = 0.00015722312412579318
Trained batch 152 in epoch 17, gen_loss = 1.4895143532285504, disc_loss = 0.000157530629223485
Trained batch 153 in epoch 17, gen_loss = 1.4896634639083566, disc_loss = 0.00015723900450412455
Trained batch 154 in epoch 17, gen_loss = 1.4900554910782844, disc_loss = 0.00015681137520004996
Trained batch 155 in epoch 17, gen_loss = 1.4896092078624628, disc_loss = 0.00015653469668345328
Trained batch 156 in epoch 17, gen_loss = 1.489597155030366, disc_loss = 0.00015636301824395178
Trained batch 157 in epoch 17, gen_loss = 1.4897735292398477, disc_loss = 0.0001561144448876089
Trained batch 158 in epoch 17, gen_loss = 1.490078957575672, disc_loss = 0.00015569029564170442
Trained batch 159 in epoch 17, gen_loss = 1.4900849372148515, disc_loss = 0.00015511946237438677
Trained batch 160 in epoch 17, gen_loss = 1.4893756638402524, disc_loss = 0.00015484175649063044
Trained batch 161 in epoch 17, gen_loss = 1.489223441959899, disc_loss = 0.00015453159692607402
Trained batch 162 in epoch 17, gen_loss = 1.4890522123114462, disc_loss = 0.00015405929961011093
Trained batch 163 in epoch 17, gen_loss = 1.4890116525859367, disc_loss = 0.0001536266130997541
Trained batch 164 in epoch 17, gen_loss = 1.4881718440489335, disc_loss = 0.00015446713750310608
Trained batch 165 in epoch 17, gen_loss = 1.4886361532900707, disc_loss = 0.000155124649762615
Trained batch 166 in epoch 17, gen_loss = 1.4891945659043546, disc_loss = 0.00015486495674000132
Trained batch 167 in epoch 17, gen_loss = 1.4894719407671975, disc_loss = 0.00015492993426440598
Trained batch 168 in epoch 17, gen_loss = 1.4894555764790822, disc_loss = 0.00015468114236429659
Trained batch 169 in epoch 17, gen_loss = 1.4890964781536775, disc_loss = 0.00015445748711713617
Trained batch 170 in epoch 17, gen_loss = 1.489265585503383, disc_loss = 0.00015418366179716425
Trained batch 171 in epoch 17, gen_loss = 1.4895666560461356, disc_loss = 0.00015382659793706195
Trained batch 172 in epoch 17, gen_loss = 1.489148281902247, disc_loss = 0.00015338622978629376
Trained batch 173 in epoch 17, gen_loss = 1.4896348221548672, disc_loss = 0.00015294789980167667
Trained batch 174 in epoch 17, gen_loss = 1.489798390524728, disc_loss = 0.000152440428313899
Trained batch 175 in epoch 17, gen_loss = 1.489814273335717, disc_loss = 0.00015188769988195747
Trained batch 176 in epoch 17, gen_loss = 1.4897639690819433, disc_loss = 0.00015135915452709137
Trained batch 177 in epoch 17, gen_loss = 1.4897363219368325, disc_loss = 0.0001508104238648352
Trained batch 178 in epoch 17, gen_loss = 1.4901726199261969, disc_loss = 0.0001507481383821503
Trained batch 179 in epoch 17, gen_loss = 1.4900828361511231, disc_loss = 0.00015024641917180917
Trained batch 180 in epoch 17, gen_loss = 1.4901752359959302, disc_loss = 0.00014985928128075334
Trained batch 181 in epoch 17, gen_loss = 1.4906822534707875, disc_loss = 0.0001497752251492744
Trained batch 182 in epoch 17, gen_loss = 1.4911607041385004, disc_loss = 0.0001495551342223173
Trained batch 183 in epoch 17, gen_loss = 1.4911477773085884, disc_loss = 0.0001493043865672877
Trained batch 184 in epoch 17, gen_loss = 1.490786287591264, disc_loss = 0.00014895950760645163
Trained batch 185 in epoch 17, gen_loss = 1.4910937252865042, disc_loss = 0.00014877247974831706
Trained batch 186 in epoch 17, gen_loss = 1.4906028515514842, disc_loss = 0.00014861906529015133
Trained batch 187 in epoch 17, gen_loss = 1.4905593883483967, disc_loss = 0.0001481269186734472
Trained batch 188 in epoch 17, gen_loss = 1.4908606211344402, disc_loss = 0.00014774441016020582
Trained batch 189 in epoch 17, gen_loss = 1.4904782332872089, disc_loss = 0.00014732696395903508
Trained batch 190 in epoch 17, gen_loss = 1.4900581044052283, disc_loss = 0.00014746324874991576
Trained batch 191 in epoch 17, gen_loss = 1.4899428722759087, disc_loss = 0.00014746273016423098
Trained batch 192 in epoch 17, gen_loss = 1.4902049939249464, disc_loss = 0.00014709624616170443
Trained batch 193 in epoch 17, gen_loss = 1.4905020828099595, disc_loss = 0.00014676983289636032
Trained batch 194 in epoch 17, gen_loss = 1.49048472734598, disc_loss = 0.000146308833810065
Trained batch 195 in epoch 17, gen_loss = 1.4903825655275462, disc_loss = 0.0001459512889095076
Trained batch 196 in epoch 17, gen_loss = 1.4901210214885963, disc_loss = 0.00014607812360926001
Trained batch 197 in epoch 17, gen_loss = 1.490128001179358, disc_loss = 0.00014579288962880983
Trained batch 198 in epoch 17, gen_loss = 1.4900504566317228, disc_loss = 0.00014550416649833448
Trained batch 199 in epoch 17, gen_loss = 1.4900790357589722, disc_loss = 0.0001450874416877923
Trained batch 200 in epoch 17, gen_loss = 1.4900609355660814, disc_loss = 0.00014471172766550907
Trained batch 201 in epoch 17, gen_loss = 1.4902775193204973, disc_loss = 0.00014428216138077175
Trained batch 202 in epoch 17, gen_loss = 1.4901326971101057, disc_loss = 0.000143888619841791
Trained batch 203 in epoch 17, gen_loss = 1.4899578632092942, disc_loss = 0.00014348316199175315
Trained batch 204 in epoch 17, gen_loss = 1.489894880899569, disc_loss = 0.00014303939258353217
Trained batch 205 in epoch 17, gen_loss = 1.4902223556944467, disc_loss = 0.00014273410179334108
Trained batch 206 in epoch 17, gen_loss = 1.4901216744224806, disc_loss = 0.00014228060026301616
Trained batch 207 in epoch 17, gen_loss = 1.489805529323908, disc_loss = 0.00014216998553050731
Trained batch 208 in epoch 17, gen_loss = 1.4895693120773899, disc_loss = 0.00014206013917902364
Trained batch 209 in epoch 17, gen_loss = 1.4894779665129525, disc_loss = 0.00014180865603391013
Trained batch 210 in epoch 17, gen_loss = 1.4891940366600362, disc_loss = 0.00014145334384123293
Trained batch 211 in epoch 17, gen_loss = 1.4891358867006481, disc_loss = 0.00014108136728505346
Trained batch 212 in epoch 17, gen_loss = 1.488941534584117, disc_loss = 0.0001408770757662012
Trained batch 213 in epoch 17, gen_loss = 1.4886244117656602, disc_loss = 0.0001405951871530416
Trained batch 214 in epoch 17, gen_loss = 1.4884340075559395, disc_loss = 0.00014023666622368943
Trained batch 215 in epoch 17, gen_loss = 1.4883300446801715, disc_loss = 0.00013985471782184
Trained batch 216 in epoch 17, gen_loss = 1.4884648328552599, disc_loss = 0.00013961193423631305
Trained batch 217 in epoch 17, gen_loss = 1.4882977025224529, disc_loss = 0.00013923899292555498
Trained batch 218 in epoch 17, gen_loss = 1.4882225429630715, disc_loss = 0.00013903790982756401
Trained batch 219 in epoch 17, gen_loss = 1.4883829263123598, disc_loss = 0.0001386919381151198
Trained batch 220 in epoch 17, gen_loss = 1.4887146216172438, disc_loss = 0.00013836734876238396
Trained batch 221 in epoch 17, gen_loss = 1.4890817360835031, disc_loss = 0.0001381031060527102
Trained batch 222 in epoch 17, gen_loss = 1.4888764031799384, disc_loss = 0.00013784670504658365
Trained batch 223 in epoch 17, gen_loss = 1.4888886218624455, disc_loss = 0.0001377994552740347
Trained batch 224 in epoch 17, gen_loss = 1.4890851354599, disc_loss = 0.00013745702830621868
Trained batch 225 in epoch 17, gen_loss = 1.4889475254885918, disc_loss = 0.00013707963154425607
Trained batch 226 in epoch 17, gen_loss = 1.488882491767144, disc_loss = 0.00013665563634549072
Trained batch 227 in epoch 17, gen_loss = 1.4885633666264384, disc_loss = 0.00013631200435108775
Trained batch 228 in epoch 17, gen_loss = 1.4885659800866806, disc_loss = 0.0001359872793088419
Trained batch 229 in epoch 17, gen_loss = 1.488476928420689, disc_loss = 0.00013555337350028466
Trained batch 230 in epoch 17, gen_loss = 1.488537909664633, disc_loss = 0.00013517318462594654
Trained batch 231 in epoch 17, gen_loss = 1.4886226546147774, disc_loss = 0.00013487377172450893
Trained batch 232 in epoch 17, gen_loss = 1.4882608672579982, disc_loss = 0.0001346668932338839
Trained batch 233 in epoch 17, gen_loss = 1.4880588946179447, disc_loss = 0.00013440424469376728
Trained batch 234 in epoch 17, gen_loss = 1.4881603895349707, disc_loss = 0.00013405481815348042
Trained batch 235 in epoch 17, gen_loss = 1.4880903888556918, disc_loss = 0.0001337180788526647
Trained batch 236 in epoch 17, gen_loss = 1.488098902038381, disc_loss = 0.00013353945747585693
Trained batch 237 in epoch 17, gen_loss = 1.488109644721536, disc_loss = 0.00013316045904105544
Trained batch 238 in epoch 17, gen_loss = 1.4880035701655943, disc_loss = 0.00013281405647918505
Trained batch 239 in epoch 17, gen_loss = 1.4881806711355845, disc_loss = 0.00013270119549512553
Trained batch 240 in epoch 17, gen_loss = 1.4882965325319915, disc_loss = 0.00013238283275642058
Trained batch 241 in epoch 17, gen_loss = 1.4883512923540163, disc_loss = 0.0001320496667176485
Trained batch 242 in epoch 17, gen_loss = 1.4882484929551802, disc_loss = 0.00013191637602479508
Trained batch 243 in epoch 17, gen_loss = 1.488342749290779, disc_loss = 0.00013171834322494135
Trained batch 244 in epoch 17, gen_loss = 1.488617430901041, disc_loss = 0.0001315269416687554
Trained batch 245 in epoch 17, gen_loss = 1.4886469148038848, disc_loss = 0.00013120081786201638
Trained batch 246 in epoch 17, gen_loss = 1.4886475589111265, disc_loss = 0.00013090100542709104
Trained batch 247 in epoch 17, gen_loss = 1.4883989658086532, disc_loss = 0.00013067420141235362
Trained batch 248 in epoch 17, gen_loss = 1.488507514019089, disc_loss = 0.00013040060619379478
Trained batch 249 in epoch 17, gen_loss = 1.4889341793060302, disc_loss = 0.0001304424057889264
Trained batch 250 in epoch 17, gen_loss = 1.4891261213804146, disc_loss = 0.0001302199838884765
Trained batch 251 in epoch 17, gen_loss = 1.489171182825452, disc_loss = 0.00013011534140368607
Trained batch 252 in epoch 17, gen_loss = 1.4890174540606411, disc_loss = 0.0001302347667186278
Trained batch 253 in epoch 17, gen_loss = 1.488977616227518, disc_loss = 0.00013001217002321335
Trained batch 254 in epoch 17, gen_loss = 1.4889044855155198, disc_loss = 0.00012968778971174057
Trained batch 255 in epoch 17, gen_loss = 1.4886813974007964, disc_loss = 0.00012949006448081946
Trained batch 256 in epoch 17, gen_loss = 1.488647852426373, disc_loss = 0.0001292377222400269
Trained batch 257 in epoch 17, gen_loss = 1.4884282202683679, disc_loss = 0.00012893920554001112
Trained batch 258 in epoch 17, gen_loss = 1.4889172697619582, disc_loss = 0.0001289767492714232
Trained batch 259 in epoch 17, gen_loss = 1.4887592196464539, disc_loss = 0.00012874542969187202
Trained batch 260 in epoch 17, gen_loss = 1.488952167189441, disc_loss = 0.00012865803439816428
Trained batch 261 in epoch 17, gen_loss = 1.4889347252954963, disc_loss = 0.00012842567014885188
Trained batch 262 in epoch 17, gen_loss = 1.4887831152165345, disc_loss = 0.0001282259820536188
Trained batch 263 in epoch 17, gen_loss = 1.488887239134673, disc_loss = 0.00012791418065248627
Trained batch 264 in epoch 17, gen_loss = 1.4888291529889377, disc_loss = 0.0001276334386757127
Trained batch 265 in epoch 17, gen_loss = 1.4890091499887912, disc_loss = 0.00012740492436426947
Trained batch 266 in epoch 17, gen_loss = 1.4889286216278648, disc_loss = 0.00012716906181349565
Trained batch 267 in epoch 17, gen_loss = 1.4887734011038025, disc_loss = 0.00012691147896557188
Trained batch 268 in epoch 17, gen_loss = 1.4886932718709498, disc_loss = 0.00012666421960156452
Trained batch 269 in epoch 17, gen_loss = 1.4888353806954844, disc_loss = 0.00012638416655708743
Trained batch 270 in epoch 17, gen_loss = 1.4888830365290062, disc_loss = 0.0001260799451546857
Trained batch 271 in epoch 17, gen_loss = 1.488621502676431, disc_loss = 0.00012587575608503197
Trained batch 272 in epoch 17, gen_loss = 1.4886451701978187, disc_loss = 0.00012568105683805278
Trained batch 273 in epoch 17, gen_loss = 1.4888301422126102, disc_loss = 0.00012548236233410833
Trained batch 274 in epoch 17, gen_loss = 1.4886412000656128, disc_loss = 0.00012529832993591713
Trained batch 275 in epoch 17, gen_loss = 1.4886974847835044, disc_loss = 0.00012502707691516886
Trained batch 276 in epoch 17, gen_loss = 1.4887299722712823, disc_loss = 0.00012479068416211542
Trained batch 277 in epoch 17, gen_loss = 1.4884313803782565, disc_loss = 0.00012465834239631365
Trained batch 278 in epoch 17, gen_loss = 1.4884428127692164, disc_loss = 0.00012436752385381814
Trained batch 279 in epoch 17, gen_loss = 1.4885151952505111, disc_loss = 0.00012405956986185628
Trained batch 280 in epoch 17, gen_loss = 1.4885547712604346, disc_loss = 0.00012376275900542136
Trained batch 281 in epoch 17, gen_loss = 1.4885237745359434, disc_loss = 0.00012357901991664924
Trained batch 282 in epoch 17, gen_loss = 1.488526086082728, disc_loss = 0.00012328876678127624
Trained batch 283 in epoch 17, gen_loss = 1.4884163615569261, disc_loss = 0.00012301888392344986
Trained batch 284 in epoch 17, gen_loss = 1.4883885701497397, disc_loss = 0.00012275220176793242
Trained batch 285 in epoch 17, gen_loss = 1.4882644673327465, disc_loss = 0.00012250044954754656
Trained batch 286 in epoch 17, gen_loss = 1.4883158892289272, disc_loss = 0.00012233201707159623
Trained batch 287 in epoch 17, gen_loss = 1.488304927531216, disc_loss = 0.00012204603249049089
Trained batch 288 in epoch 17, gen_loss = 1.4882738107628475, disc_loss = 0.00012173676660341198
Trained batch 289 in epoch 17, gen_loss = 1.4881255408813214, disc_loss = 0.0001214520013459621
Trained batch 290 in epoch 17, gen_loss = 1.488226718918974, disc_loss = 0.00012125866615139043
Trained batch 291 in epoch 17, gen_loss = 1.4880925180160836, disc_loss = 0.0001210727481869582
Trained batch 292 in epoch 17, gen_loss = 1.4881943972851228, disc_loss = 0.00012081354114641404
Trained batch 293 in epoch 17, gen_loss = 1.4881247221207132, disc_loss = 0.00012055341145229609
Trained batch 294 in epoch 17, gen_loss = 1.4884315405861805, disc_loss = 0.00012041372888311112
Trained batch 295 in epoch 17, gen_loss = 1.488503700575313, disc_loss = 0.0001202499209751762
Trained batch 296 in epoch 17, gen_loss = 1.4889239530370693, disc_loss = 0.00012025577247927517
Trained batch 297 in epoch 17, gen_loss = 1.48888443300388, disc_loss = 0.00012006006746993544
Trained batch 298 in epoch 17, gen_loss = 1.4889053357484747, disc_loss = 0.00011977906847749541
Trained batch 299 in epoch 17, gen_loss = 1.4889738448460896, disc_loss = 0.00011951343442585009
Trained batch 300 in epoch 17, gen_loss = 1.4888729455067073, disc_loss = 0.00011925337405825433
Trained batch 301 in epoch 17, gen_loss = 1.4887277558939347, disc_loss = 0.0001190530293022085
Trained batch 302 in epoch 17, gen_loss = 1.4888349515770134, disc_loss = 0.00011881896982003286
Trained batch 303 in epoch 17, gen_loss = 1.4889797160499973, disc_loss = 0.00011864725380100456
Trained batch 304 in epoch 17, gen_loss = 1.4887621387106473, disc_loss = 0.00011845098141166686
Trained batch 305 in epoch 17, gen_loss = 1.4885849800764346, disc_loss = 0.0001181898256332965
Trained batch 306 in epoch 17, gen_loss = 1.488363876793206, disc_loss = 0.00011799497463645987
Trained batch 307 in epoch 17, gen_loss = 1.488216786802589, disc_loss = 0.0001178984342111001
Trained batch 308 in epoch 17, gen_loss = 1.4881451928499834, disc_loss = 0.00011783245506421
Trained batch 309 in epoch 17, gen_loss = 1.488022699663716, disc_loss = 0.00011759113121145
Trained batch 310 in epoch 17, gen_loss = 1.4881309420349513, disc_loss = 0.00011738334524417535
Trained batch 311 in epoch 17, gen_loss = 1.4880160047457769, disc_loss = 0.00011713621078785927
Trained batch 312 in epoch 17, gen_loss = 1.4878838001348722, disc_loss = 0.00011692004355803927
Trained batch 313 in epoch 17, gen_loss = 1.4877794586169493, disc_loss = 0.00011673730119918607
Trained batch 314 in epoch 17, gen_loss = 1.4878957911143227, disc_loss = 0.00011653451244152772
Trained batch 315 in epoch 17, gen_loss = 1.4877279513998876, disc_loss = 0.00011639289330767358
Trained batch 316 in epoch 17, gen_loss = 1.487653615722897, disc_loss = 0.00011615424255327445
Trained batch 317 in epoch 17, gen_loss = 1.4876884259517837, disc_loss = 0.00011591445364507572
Trained batch 318 in epoch 17, gen_loss = 1.4877266640947158, disc_loss = 0.00011566451758541879
Trained batch 319 in epoch 17, gen_loss = 1.4880237083882093, disc_loss = 0.00011550619908575754
Trained batch 320 in epoch 17, gen_loss = 1.4877328438179516, disc_loss = 0.00011552650639402891
Trained batch 321 in epoch 17, gen_loss = 1.4875509579729589, disc_loss = 0.000115405031431449
Trained batch 322 in epoch 17, gen_loss = 1.4874662559467942, disc_loss = 0.00011536262238065888
Trained batch 323 in epoch 17, gen_loss = 1.4875156345926686, disc_loss = 0.00011525756859937022
Trained batch 324 in epoch 17, gen_loss = 1.4873824541385356, disc_loss = 0.00011520813922218692
Trained batch 325 in epoch 17, gen_loss = 1.4874539905530544, disc_loss = 0.0001151016371005409
Trained batch 326 in epoch 17, gen_loss = 1.4873868846747489, disc_loss = 0.0001148972143420867
Trained batch 327 in epoch 17, gen_loss = 1.4875276724739772, disc_loss = 0.00011492850262584398
Trained batch 328 in epoch 17, gen_loss = 1.4874982496887716, disc_loss = 0.00011479097722706139
Trained batch 329 in epoch 17, gen_loss = 1.4875328150662508, disc_loss = 0.00011465064032535972
Trained batch 330 in epoch 17, gen_loss = 1.4874528527619975, disc_loss = 0.00011451783622727586
Trained batch 331 in epoch 17, gen_loss = 1.4871724962470043, disc_loss = 0.00011442440196136097
Trained batch 332 in epoch 17, gen_loss = 1.4871454532440003, disc_loss = 0.00011430236136166004
Trained batch 333 in epoch 17, gen_loss = 1.4872939322523013, disc_loss = 0.00011409538180492735
Trained batch 334 in epoch 17, gen_loss = 1.487256223408144, disc_loss = 0.00011390859734418163
Trained batch 335 in epoch 17, gen_loss = 1.4873067371192432, disc_loss = 0.00011374034546038491
Trained batch 336 in epoch 17, gen_loss = 1.4873929564959925, disc_loss = 0.00011358642432484942
Trained batch 337 in epoch 17, gen_loss = 1.4875124654120948, disc_loss = 0.00011371980542998993
Trained batch 338 in epoch 17, gen_loss = 1.487558029745884, disc_loss = 0.00011353348684874926
Trained batch 339 in epoch 17, gen_loss = 1.4874869392198675, disc_loss = 0.00011332997036173337
Trained batch 340 in epoch 17, gen_loss = 1.4874569492256187, disc_loss = 0.00011311893738772792
Trained batch 341 in epoch 17, gen_loss = 1.4873702975741603, disc_loss = 0.00011291275247368126
Trained batch 342 in epoch 17, gen_loss = 1.487233124043434, disc_loss = 0.00011271462043631569
Trained batch 343 in epoch 17, gen_loss = 1.4872379652982535, disc_loss = 0.0001124895374507401
Trained batch 344 in epoch 17, gen_loss = 1.4872317207032355, disc_loss = 0.00011227546332309535
Trained batch 345 in epoch 17, gen_loss = 1.4872111430057902, disc_loss = 0.00011212818224973589
Trained batch 346 in epoch 17, gen_loss = 1.487083685157622, disc_loss = 0.00011193029649934117
Trained batch 347 in epoch 17, gen_loss = 1.4871977584800502, disc_loss = 0.00011173061330350458
Trained batch 348 in epoch 17, gen_loss = 1.4871941172974157, disc_loss = 0.0001115735965419993
Trained batch 349 in epoch 17, gen_loss = 1.4872016910144261, disc_loss = 0.00011135398036068571
Trained batch 350 in epoch 17, gen_loss = 1.4871740833646552, disc_loss = 0.00011117446779915559
Trained batch 351 in epoch 17, gen_loss = 1.4871814223853024, disc_loss = 0.00011098122261252932
Trained batch 352 in epoch 17, gen_loss = 1.487362659011279, disc_loss = 0.00011084600219505683
Trained batch 353 in epoch 17, gen_loss = 1.4873306724311268, disc_loss = 0.00011066292740572652
Trained batch 354 in epoch 17, gen_loss = 1.4871555704466055, disc_loss = 0.00011046967020505895
Trained batch 355 in epoch 17, gen_loss = 1.4869403313384968, disc_loss = 0.00011043643232543229
Trained batch 356 in epoch 17, gen_loss = 1.4867748062149817, disc_loss = 0.00011039873441338542
Trained batch 357 in epoch 17, gen_loss = 1.4867203062473062, disc_loss = 0.00011027827783523182
Trained batch 358 in epoch 17, gen_loss = 1.4867108366283535, disc_loss = 0.00011013603269978307
Trained batch 359 in epoch 17, gen_loss = 1.4867383195294275, disc_loss = 0.00011001751371521903
Trained batch 360 in epoch 17, gen_loss = 1.4866796540421463, disc_loss = 0.00010980798548577325
Trained batch 361 in epoch 17, gen_loss = 1.486626253272947, disc_loss = 0.00010964024223032529
Trained batch 362 in epoch 17, gen_loss = 1.4868721797774975, disc_loss = 0.00010964429898457871
Trained batch 363 in epoch 17, gen_loss = 1.4868317790083834, disc_loss = 0.00010945555902083639
Trained batch 364 in epoch 17, gen_loss = 1.4867682554950452, disc_loss = 0.00010931995464688205
Trained batch 365 in epoch 17, gen_loss = 1.4867556349175874, disc_loss = 0.00010925446955407296
Trained batch 366 in epoch 17, gen_loss = 1.4868696080241606, disc_loss = 0.00010908517933364042
Trained batch 367 in epoch 17, gen_loss = 1.4868144606766494, disc_loss = 0.00010895216812810838
Trained batch 368 in epoch 17, gen_loss = 1.4870399382056259, disc_loss = 0.0001088745675366315
Trained batch 369 in epoch 17, gen_loss = 1.4870138986690624, disc_loss = 0.00010869968781834531
Trained batch 370 in epoch 17, gen_loss = 1.48715285149546, disc_loss = 0.00010856073451499238
Trained batch 371 in epoch 17, gen_loss = 1.4870593297866084, disc_loss = 0.00010843075429014574
Trained batch 372 in epoch 17, gen_loss = 1.486882680862263, disc_loss = 0.00010828292295569241
Trained batch 373 in epoch 17, gen_loss = 1.4870916917362316, disc_loss = 0.00010838695083108897
Trained batch 374 in epoch 17, gen_loss = 1.4870020011266072, disc_loss = 0.00010824040757142939
Trained batch 375 in epoch 17, gen_loss = 1.4872151188393856, disc_loss = 0.00010817594877269275
Trained batch 376 in epoch 17, gen_loss = 1.4872197738060584, disc_loss = 0.00010804516210888366
Trained batch 377 in epoch 17, gen_loss = 1.487095660633511, disc_loss = 0.00010804906308068278
Trained batch 378 in epoch 17, gen_loss = 1.4870131921642373, disc_loss = 0.00010799318086279133
Trained batch 379 in epoch 17, gen_loss = 1.486912631361108, disc_loss = 0.00010785460022146396
Trained batch 380 in epoch 17, gen_loss = 1.486887700914398, disc_loss = 0.00010767991425907373
Trained batch 381 in epoch 17, gen_loss = 1.4867470726292795, disc_loss = 0.00010754819991782
Trained batch 382 in epoch 17, gen_loss = 1.4865316971163838, disc_loss = 0.00010749358055698527
Trained batch 383 in epoch 17, gen_loss = 1.4862534912923973, disc_loss = 0.00010751150167228236
Trained batch 384 in epoch 17, gen_loss = 1.4864572069861672, disc_loss = 0.00010753447118490426
Trained batch 385 in epoch 17, gen_loss = 1.486459748423779, disc_loss = 0.00010739342351983919
Trained batch 386 in epoch 17, gen_loss = 1.4864583529859243, disc_loss = 0.00010719567160762832
Trained batch 387 in epoch 17, gen_loss = 1.486301496164086, disc_loss = 0.00010704569048516766
Trained batch 388 in epoch 17, gen_loss = 1.4863801357985156, disc_loss = 0.00010688928873219843
Trained batch 389 in epoch 17, gen_loss = 1.4864409183844542, disc_loss = 0.00010673670022254392
Trained batch 390 in epoch 17, gen_loss = 1.4867753259971013, disc_loss = 0.000110158105064115
Trained batch 391 in epoch 17, gen_loss = 1.486934212397556, disc_loss = 0.00011117765800417127
Trained batch 392 in epoch 17, gen_loss = 1.4871257582996942, disc_loss = 0.00011136910868531659
Trained batch 393 in epoch 17, gen_loss = 1.487226965463706, disc_loss = 0.00011144884336105404
Trained batch 394 in epoch 17, gen_loss = 1.4875189527680601, disc_loss = 0.00011174377523505577
Trained batch 395 in epoch 17, gen_loss = 1.487434122899566, disc_loss = 0.00011179419976138484
Trained batch 396 in epoch 17, gen_loss = 1.4872961296542766, disc_loss = 0.00011168443316528374
Trained batch 397 in epoch 17, gen_loss = 1.4871898937464958, disc_loss = 0.00011154262702533303
Trained batch 398 in epoch 17, gen_loss = 1.4870722207210416, disc_loss = 0.00011135018619022771
Trained batch 399 in epoch 17, gen_loss = 1.487048279941082, disc_loss = 0.0001111599541582109
Trained batch 400 in epoch 17, gen_loss = 1.4869501760178374, disc_loss = 0.00011094830130930048
Trained batch 401 in epoch 17, gen_loss = 1.4869501759756858, disc_loss = 0.00011074637363641494
Trained batch 402 in epoch 17, gen_loss = 1.4868903890732796, disc_loss = 0.00011064474469089907
Trained batch 403 in epoch 17, gen_loss = 1.4868980654985597, disc_loss = 0.00011045545735925932
Trained batch 404 in epoch 17, gen_loss = 1.486823731587257, disc_loss = 0.0001102910940971924
Trained batch 405 in epoch 17, gen_loss = 1.4867490885292955, disc_loss = 0.00011010657335601298
Trained batch 406 in epoch 17, gen_loss = 1.4868375215249214, disc_loss = 0.00010993420546940906
Trained batch 407 in epoch 17, gen_loss = 1.4868731148102705, disc_loss = 0.00010974944099389712
Trained batch 408 in epoch 17, gen_loss = 1.4870929994909572, disc_loss = 0.00010962197088957667
Trained batch 409 in epoch 17, gen_loss = 1.4872238420858617, disc_loss = 0.00010949350818874536
Trained batch 410 in epoch 17, gen_loss = 1.4870884212554227, disc_loss = 0.0001097431679067829
Trained batch 411 in epoch 17, gen_loss = 1.4871411175982465, disc_loss = 0.00010978824044834202
Trained batch 412 in epoch 17, gen_loss = 1.4871843204659931, disc_loss = 0.00010964210527312979
Trained batch 413 in epoch 17, gen_loss = 1.487327730310136, disc_loss = 0.0001094979840852891
Trained batch 414 in epoch 17, gen_loss = 1.4874436007924827, disc_loss = 0.00010939663207612185
Trained batch 415 in epoch 17, gen_loss = 1.4875889165470233, disc_loss = 0.00010934872635568984
Trained batch 416 in epoch 17, gen_loss = 1.4874661863564873, disc_loss = 0.00010926403953928732
Trained batch 417 in epoch 17, gen_loss = 1.4877263983470972, disc_loss = 0.00010916505112383336
Trained batch 418 in epoch 17, gen_loss = 1.4877082442326877, disc_loss = 0.00010903400513830429
Trained batch 419 in epoch 17, gen_loss = 1.4877728604135059, disc_loss = 0.00010888171543791985
Trained batch 420 in epoch 17, gen_loss = 1.4879998866282846, disc_loss = 0.00010878459576519694
Trained batch 421 in epoch 17, gen_loss = 1.4879986013846376, disc_loss = 0.00010868102995700438
Trained batch 422 in epoch 17, gen_loss = 1.4881002316801824, disc_loss = 0.00010852582199817846
Trained batch 423 in epoch 17, gen_loss = 1.4881539912718647, disc_loss = 0.00010834329206755803
Trained batch 424 in epoch 17, gen_loss = 1.4881521884132833, disc_loss = 0.00010814762577972621
Trained batch 425 in epoch 17, gen_loss = 1.488205675228101, disc_loss = 0.0001079535087173069
Trained batch 426 in epoch 17, gen_loss = 1.4882267484620249, disc_loss = 0.0001077876667289251
Trained batch 427 in epoch 17, gen_loss = 1.488029680240934, disc_loss = 0.00010764186456037912
Trained batch 428 in epoch 17, gen_loss = 1.4877159203682746, disc_loss = 0.00010805098719282688
Trained batch 429 in epoch 17, gen_loss = 1.4878502762594887, disc_loss = 0.00010801345872392249
Trained batch 430 in epoch 17, gen_loss = 1.4878940325048848, disc_loss = 0.00010785223760389833
Trained batch 431 in epoch 17, gen_loss = 1.4878923525964771, disc_loss = 0.00010771869635088176
Trained batch 432 in epoch 17, gen_loss = 1.4880273240267818, disc_loss = 0.00010757178527436931
Trained batch 433 in epoch 17, gen_loss = 1.4880013968538028, disc_loss = 0.00010744887283939625
Trained batch 434 in epoch 17, gen_loss = 1.4880067395067762, disc_loss = 0.00010735028668075275
Trained batch 435 in epoch 17, gen_loss = 1.488189773001802, disc_loss = 0.00010719641320958227
Trained batch 436 in epoch 17, gen_loss = 1.4880952461360522, disc_loss = 0.00010704301952567426
Trained batch 437 in epoch 17, gen_loss = 1.4879732131958008, disc_loss = 0.00010687777143856564
Trained batch 438 in epoch 17, gen_loss = 1.4879647748616942, disc_loss = 0.00010672683755581846
Trained batch 439 in epoch 17, gen_loss = 1.487911344929175, disc_loss = 0.0001065795850412211
Trained batch 440 in epoch 17, gen_loss = 1.4878999146204146, disc_loss = 0.00010649371577945249
Trained batch 441 in epoch 17, gen_loss = 1.4880884643054115, disc_loss = 0.00010634957585163516
Trained batch 442 in epoch 17, gen_loss = 1.4880286675812697, disc_loss = 0.00010628508410532695
Trained batch 443 in epoch 17, gen_loss = 1.4881024282794815, disc_loss = 0.00010624681055707845
Trained batch 444 in epoch 17, gen_loss = 1.4880429889378923, disc_loss = 0.00010609620807004382
Trained batch 445 in epoch 17, gen_loss = 1.487805625248383, disc_loss = 0.00010601379341553404
Trained batch 446 in epoch 17, gen_loss = 1.487848292794537, disc_loss = 0.00010587380717617098
Trained batch 447 in epoch 17, gen_loss = 1.4878664131143264, disc_loss = 0.00010571816653737187
Trained batch 448 in epoch 17, gen_loss = 1.4878494328008198, disc_loss = 0.00010557285062297204
Trained batch 449 in epoch 17, gen_loss = 1.4878012919425965, disc_loss = 0.00010540527119398273
Trained batch 450 in epoch 17, gen_loss = 1.4878848452790085, disc_loss = 0.00010524342475791189
Trained batch 451 in epoch 17, gen_loss = 1.4880367367141014, disc_loss = 0.00010511870134430752
Trained batch 452 in epoch 17, gen_loss = 1.4881279110645353, disc_loss = 0.0001049779684823284
Trained batch 453 in epoch 17, gen_loss = 1.4880850632810383, disc_loss = 0.00010482285790107447
Trained batch 454 in epoch 17, gen_loss = 1.488271002455072, disc_loss = 0.00010480250418697904
Trained batch 455 in epoch 17, gen_loss = 1.48823248843352, disc_loss = 0.00010464029899020189
Trained batch 456 in epoch 17, gen_loss = 1.488110142411497, disc_loss = 0.00010452489107510959
Trained batch 457 in epoch 17, gen_loss = 1.4880653336058538, disc_loss = 0.00010438746929886256
Trained batch 458 in epoch 17, gen_loss = 1.4882593069201202, disc_loss = 0.00010428200068639861
Trained batch 459 in epoch 17, gen_loss = 1.4882910466712453, disc_loss = 0.00010416327629924206
Trained batch 460 in epoch 17, gen_loss = 1.4882508102570076, disc_loss = 0.00010399171754130952
Trained batch 461 in epoch 17, gen_loss = 1.4881631592651465, disc_loss = 0.00010383787978308485
Trained batch 462 in epoch 17, gen_loss = 1.4883777358876964, disc_loss = 0.00010375010882947819
Trained batch 463 in epoch 17, gen_loss = 1.488508067511279, disc_loss = 0.00010362505546599378
Trained batch 464 in epoch 17, gen_loss = 1.4883036849319293, disc_loss = 0.00010357336227228784
Trained batch 466 in epoch 17, gen_loss = 1.4883882897313707, disc_loss = 0.00010333950922358781
Trained batch 467 in epoch 17, gen_loss = 1.4883760381967595, disc_loss = 0.00010322815209152535
Trained batch 468 in epoch 17, gen_loss = 1.488272583560903, disc_loss = 0.00010312904822461402
Trained batch 469 in epoch 17, gen_loss = 1.4884769749134146, disc_loss = 0.00010300485906129247
Trained batch 470 in epoch 17, gen_loss = 1.4884809045528404, disc_loss = 0.00010289042565730378
Trained batch 471 in epoch 17, gen_loss = 1.4884417587417667, disc_loss = 0.00010272574792321332
Trained batch 472 in epoch 17, gen_loss = 1.4883412336950321, disc_loss = 0.00010262692886205089
Trained batch 473 in epoch 17, gen_loss = 1.4882704608048065, disc_loss = 0.00010251566024869485
Trained batch 474 in epoch 17, gen_loss = 1.4881600221834685, disc_loss = 0.00010237861855114859
Trained batch 475 in epoch 17, gen_loss = 1.4881725944891697, disc_loss = 0.00010223283618511271
Trained batch 476 in epoch 17, gen_loss = 1.4881939523125094, disc_loss = 0.00010210827879191072
Trained batch 477 in epoch 17, gen_loss = 1.488126939809472, disc_loss = 0.00010197389485378055
Trained batch 478 in epoch 17, gen_loss = 1.4878841419558435, disc_loss = 0.00010188564250225275
Trained batch 479 in epoch 17, gen_loss = 1.4879693582653999, disc_loss = 0.00010175425301592137
Trained batch 480 in epoch 17, gen_loss = 1.4877962882702167, disc_loss = 0.00010166653488707494
Trained batch 481 in epoch 17, gen_loss = 1.4878125309449508, disc_loss = 0.00010162268074084927
Trained batch 482 in epoch 17, gen_loss = 1.4879530957026512, disc_loss = 0.00010154750309298856
Trained batch 483 in epoch 17, gen_loss = 1.4879598580608684, disc_loss = 0.0001014405789338668
Trained batch 484 in epoch 17, gen_loss = 1.487874920097823, disc_loss = 0.00010133861030329538
Trained batch 485 in epoch 17, gen_loss = 1.4879106263564938, disc_loss = 0.00010122837985165363
Trained batch 486 in epoch 17, gen_loss = 1.48781526455889, disc_loss = 0.00010111677545293481
Trained batch 487 in epoch 17, gen_loss = 1.4879167832312037, disc_loss = 0.00010099011127690052
Trained batch 488 in epoch 17, gen_loss = 1.4879797996918849, disc_loss = 0.00010086916808193932
Trained batch 489 in epoch 17, gen_loss = 1.4879506622041976, disc_loss = 0.00010079716424171442
Trained batch 490 in epoch 17, gen_loss = 1.4879715544628758, disc_loss = 0.00010075905712105878
Trained batch 491 in epoch 17, gen_loss = 1.4880274803173252, disc_loss = 0.0001006589082322993
Trained batch 492 in epoch 17, gen_loss = 1.4879827313200698, disc_loss = 0.00010052564423510041
Trained batch 493 in epoch 17, gen_loss = 1.48788411414575, disc_loss = 0.00010038680375882647
Trained batch 494 in epoch 17, gen_loss = 1.4878652577448372, disc_loss = 0.00010028369810004163
Trained batch 495 in epoch 17, gen_loss = 1.488001328802878, disc_loss = 0.00010017705404431083
Trained batch 496 in epoch 17, gen_loss = 1.4879651765228517, disc_loss = 0.0001000696976341905
Trained batch 497 in epoch 17, gen_loss = 1.4879985083059135, disc_loss = 9.993975419571239e-05
Trained batch 498 in epoch 17, gen_loss = 1.4880517532448014, disc_loss = 9.988366275615636e-05
Trained batch 499 in epoch 17, gen_loss = 1.4880321259498597, disc_loss = 9.974428878558683e-05
Trained batch 500 in epoch 17, gen_loss = 1.4879740588441341, disc_loss = 9.9620600473669e-05
Trained batch 501 in epoch 17, gen_loss = 1.4879022269134978, disc_loss = 9.948514917302682e-05
Trained batch 502 in epoch 17, gen_loss = 1.4877858661989094, disc_loss = 9.936238817773296e-05
Trained batch 503 in epoch 17, gen_loss = 1.4875368984445694, disc_loss = 9.924981357052895e-05
Trained batch 504 in epoch 17, gen_loss = 1.4875559193072934, disc_loss = 9.913227594291012e-05
Trained batch 505 in epoch 17, gen_loss = 1.4875835024792214, disc_loss = 9.899299530221657e-05
Trained batch 506 in epoch 17, gen_loss = 1.4872722931397266, disc_loss = 9.921031217379527e-05
Trained batch 507 in epoch 17, gen_loss = 1.4873591980596228, disc_loss = 9.919237167496893e-05
Trained batch 508 in epoch 17, gen_loss = 1.4873732234733748, disc_loss = 9.910573222684607e-05
Trained batch 509 in epoch 17, gen_loss = 1.487326539965237, disc_loss = 9.904020716217644e-05
Trained batch 510 in epoch 17, gen_loss = 1.487370642897201, disc_loss = 9.891535563911234e-05
Trained batch 511 in epoch 17, gen_loss = 1.4873754531145096, disc_loss = 9.879994872008524e-05
Trained batch 512 in epoch 17, gen_loss = 1.4872603753389206, disc_loss = 9.868385547561118e-05
Trained batch 513 in epoch 17, gen_loss = 1.4873143573679348, disc_loss = 9.85682553962244e-05
Trained batch 514 in epoch 17, gen_loss = 1.4872218344975443, disc_loss = 9.845799628520289e-05
Trained batch 515 in epoch 17, gen_loss = 1.4870895630167436, disc_loss = 9.833573164379873e-05
Trained batch 516 in epoch 17, gen_loss = 1.4869335972824687, disc_loss = 9.824191940734114e-05
Trained batch 517 in epoch 17, gen_loss = 1.4869101208609503, disc_loss = 9.817131961647868e-05
Trained batch 518 in epoch 17, gen_loss = 1.4867730386454705, disc_loss = 9.807063628988846e-05
Trained batch 519 in epoch 17, gen_loss = 1.4869372730071728, disc_loss = 9.802526027530033e-05
Trained batch 520 in epoch 17, gen_loss = 1.4868106961021497, disc_loss = 9.791028081432621e-05
Trained batch 521 in epoch 17, gen_loss = 1.4867384312710086, disc_loss = 9.777843603992324e-05
Trained batch 522 in epoch 17, gen_loss = 1.4867620762174034, disc_loss = 9.764615352159026e-05
Trained batch 523 in epoch 17, gen_loss = 1.4867553485713842, disc_loss = 9.751396538994767e-05
Trained batch 524 in epoch 17, gen_loss = 1.4867156208129155, disc_loss = 9.738503989259092e-05
Trained batch 525 in epoch 17, gen_loss = 1.4865883686243355, disc_loss = 9.723861350769977e-05
Trained batch 526 in epoch 17, gen_loss = 1.4865164306629768, disc_loss = 9.713317644924846e-05
Trained batch 527 in epoch 17, gen_loss = 1.4866541495377368, disc_loss = 9.712413817865264e-05
Trained batch 528 in epoch 17, gen_loss = 1.4867267683007541, disc_loss = 9.705280951918138e-05
Trained batch 529 in epoch 17, gen_loss = 1.4865683652319999, disc_loss = 9.69363958231626e-05
Trained batch 530 in epoch 17, gen_loss = 1.4865456653404594, disc_loss = 9.680806879550938e-05
Trained batch 531 in epoch 17, gen_loss = 1.4865536548589404, disc_loss = 9.666714403212431e-05
Trained batch 532 in epoch 17, gen_loss = 1.4865084175320995, disc_loss = 9.653403739241021e-05
Trained batch 533 in epoch 17, gen_loss = 1.4864805251471558, disc_loss = 9.642179557385532e-05
Trained batch 534 in epoch 17, gen_loss = 1.4866515320038127, disc_loss = 9.64086376957184e-05
Trained batch 535 in epoch 17, gen_loss = 1.4864340731457097, disc_loss = 9.649988360319755e-05
Trained batch 536 in epoch 17, gen_loss = 1.486529424425832, disc_loss = 9.644909091523065e-05
Trained batch 537 in epoch 17, gen_loss = 1.4865313845939352, disc_loss = 9.63634154713636e-05
Trained batch 538 in epoch 17, gen_loss = 1.486476410961328, disc_loss = 9.625252026637238e-05
Trained batch 539 in epoch 17, gen_loss = 1.4865599144388129, disc_loss = 9.61747981145217e-05
Trained batch 540 in epoch 17, gen_loss = 1.4866460473612364, disc_loss = 9.606698224023084e-05
Trained batch 541 in epoch 17, gen_loss = 1.4865872673002996, disc_loss = 9.594110327696976e-05
Trained batch 542 in epoch 17, gen_loss = 1.4866375268932646, disc_loss = 9.581199408125395e-05
Trained batch 543 in epoch 17, gen_loss = 1.4866549942423315, disc_loss = 9.573552138336334e-05
Trained batch 544 in epoch 17, gen_loss = 1.4867516069237245, disc_loss = 9.564149964516961e-05
Trained batch 545 in epoch 17, gen_loss = 1.486827130501087, disc_loss = 9.55499589885148e-05
Trained batch 546 in epoch 17, gen_loss = 1.4868052790326218, disc_loss = 9.550730528494993e-05
Trained batch 547 in epoch 17, gen_loss = 1.486720898073085, disc_loss = 9.543253758317943e-05
Trained batch 548 in epoch 17, gen_loss = 1.4867290089039202, disc_loss = 9.531601164966567e-05
Trained batch 549 in epoch 17, gen_loss = 1.4867343000932174, disc_loss = 9.52104334117559e-05
Trained batch 550 in epoch 17, gen_loss = 1.4867183746746362, disc_loss = 9.508392638190921e-05
Trained batch 551 in epoch 17, gen_loss = 1.4867598429538202, disc_loss = 9.497226566331254e-05
Trained batch 552 in epoch 17, gen_loss = 1.4867774399021003, disc_loss = 9.485870676269252e-05
Trained batch 553 in epoch 17, gen_loss = 1.4867669365466287, disc_loss = 9.474877280368897e-05
Trained batch 554 in epoch 17, gen_loss = 1.4866225075077366, disc_loss = 9.46301603271586e-05
Trained batch 555 in epoch 17, gen_loss = 1.4865653433388086, disc_loss = 9.45705189858783e-05
Trained batch 556 in epoch 17, gen_loss = 1.4865073010566205, disc_loss = 9.446991565027521e-05
Trained batch 557 in epoch 17, gen_loss = 1.4864408730606025, disc_loss = 9.43487878733625e-05
Trained batch 558 in epoch 17, gen_loss = 1.4863221244436684, disc_loss = 9.423251681572616e-05
Trained batch 559 in epoch 17, gen_loss = 1.4865353620478086, disc_loss = 9.439411975173634e-05
Trained batch 560 in epoch 17, gen_loss = 1.4865303970275716, disc_loss = 9.437209094012652e-05
Trained batch 561 in epoch 17, gen_loss = 1.4865714292509276, disc_loss = 9.426728316042195e-05
Trained batch 562 in epoch 17, gen_loss = 1.4865582997167937, disc_loss = 9.422238161384693e-05
Trained batch 563 in epoch 17, gen_loss = 1.4865334397512124, disc_loss = 9.41172530693743e-05
Trained batch 564 in epoch 17, gen_loss = 1.4862898478465798, disc_loss = 9.41455263748252e-05
Trained batch 565 in epoch 17, gen_loss = 1.4862983317341485, disc_loss = 9.409882092797308e-05
Trained batch 566 in epoch 17, gen_loss = 1.486333641005151, disc_loss = 9.39879662025836e-05
Trained batch 567 in epoch 17, gen_loss = 1.486357653644723, disc_loss = 9.387341522686795e-05
Trained batch 568 in epoch 17, gen_loss = 1.4863036751537624, disc_loss = 9.376100221946398e-05
Trained batch 569 in epoch 17, gen_loss = 1.4863235352332131, disc_loss = 9.364759640575676e-05
Trained batch 570 in epoch 17, gen_loss = 1.4863370934635036, disc_loss = 9.35498794011746e-05
Trained batch 571 in epoch 17, gen_loss = 1.486468371394631, disc_loss = 9.346018842333652e-05
Trained batch 572 in epoch 17, gen_loss = 1.486434010518991, disc_loss = 9.334370431021025e-05
Trained batch 573 in epoch 17, gen_loss = 1.4863959725310163, disc_loss = 9.323976365531465e-05
Trained batch 574 in epoch 17, gen_loss = 1.486359156732974, disc_loss = 9.313187544530197e-05
Trained batch 575 in epoch 17, gen_loss = 1.486247504957848, disc_loss = 9.302832431343531e-05
Trained batch 576 in epoch 17, gen_loss = 1.4863194993711633, disc_loss = 9.292177691093007e-05
Trained batch 577 in epoch 17, gen_loss = 1.486329519624941, disc_loss = 9.279274161970811e-05
Trained batch 578 in epoch 17, gen_loss = 1.486242823444294, disc_loss = 9.267089622749083e-05
Trained batch 579 in epoch 17, gen_loss = 1.4862286651956624, disc_loss = 9.256804741794597e-05
Trained batch 580 in epoch 17, gen_loss = 1.4863116041518325, disc_loss = 9.246071032706786e-05
Trained batch 581 in epoch 17, gen_loss = 1.4863086777044736, disc_loss = 9.239445751649627e-05
Trained batch 582 in epoch 17, gen_loss = 1.48625483541505, disc_loss = 9.233630796280705e-05
Trained batch 583 in epoch 17, gen_loss = 1.4862352970936528, disc_loss = 9.222513137987558e-05
Trained batch 584 in epoch 17, gen_loss = 1.4862009975645276, disc_loss = 9.217213067356955e-05
Trained batch 585 in epoch 17, gen_loss = 1.4861402749608401, disc_loss = 9.209253383065242e-05
Trained batch 586 in epoch 17, gen_loss = 1.4860746029897687, disc_loss = 9.203551463020535e-05
Trained batch 587 in epoch 17, gen_loss = 1.4860718637502113, disc_loss = 9.212965793873688e-05
Trained batch 588 in epoch 17, gen_loss = 1.4861244930678597, disc_loss = 9.208882157386938e-05
Trained batch 589 in epoch 17, gen_loss = 1.4860854005409498, disc_loss = 9.198929819214786e-05
Trained batch 590 in epoch 17, gen_loss = 1.4860100875247755, disc_loss = 9.189044015155376e-05
Trained batch 591 in epoch 17, gen_loss = 1.4859478787795917, disc_loss = 9.17886172060576e-05
Trained batch 592 in epoch 17, gen_loss = 1.48591009420649, disc_loss = 9.18669067125665e-05
Trained batch 593 in epoch 17, gen_loss = 1.4859136680159906, disc_loss = 9.178124350098864e-05
Trained batch 594 in epoch 17, gen_loss = 1.4859713410129067, disc_loss = 9.167856952758064e-05
Trained batch 595 in epoch 17, gen_loss = 1.4859987693344987, disc_loss = 9.163990058832557e-05
Trained batch 596 in epoch 17, gen_loss = 1.4862672006664563, disc_loss = 9.293265700296104e-05
Trained batch 597 in epoch 17, gen_loss = 1.4864611446259413, disc_loss = 9.372991323127956e-05
Trained batch 598 in epoch 17, gen_loss = 1.4865441644729078, disc_loss = 9.375054441943499e-05
Trained batch 599 in epoch 17, gen_loss = 1.486518143216769, disc_loss = 9.390033459870514e-05
Trained batch 600 in epoch 17, gen_loss = 1.486590755561029, disc_loss = 9.382497419195134e-05
Trained batch 601 in epoch 17, gen_loss = 1.4865934597297363, disc_loss = 9.375899103104173e-05
Trained batch 602 in epoch 17, gen_loss = 1.4865349254402553, disc_loss = 9.368514387895277e-05
Trained batch 603 in epoch 17, gen_loss = 1.48639456483702, disc_loss = 9.359513248774414e-05
Trained batch 604 in epoch 17, gen_loss = 1.4866225869202416, disc_loss = 9.355003921657104e-05
Trained batch 605 in epoch 17, gen_loss = 1.486678135080306, disc_loss = 9.344972839262302e-05
Trained batch 606 in epoch 17, gen_loss = 1.4867062001094786, disc_loss = 9.333664559576234e-05
Trained batch 607 in epoch 17, gen_loss = 1.4865920204473169, disc_loss = 9.326049351593131e-05
Trained batch 608 in epoch 17, gen_loss = 1.4865278154366905, disc_loss = 9.322864704814889e-05
Trained batch 609 in epoch 17, gen_loss = 1.486559365030195, disc_loss = 9.316213915747644e-05
Trained batch 610 in epoch 17, gen_loss = 1.4865905635680778, disc_loss = 9.30452653799536e-05
Trained batch 611 in epoch 17, gen_loss = 1.4865797637334837, disc_loss = 9.294025822289328e-05
Trained batch 612 in epoch 17, gen_loss = 1.4866751107656158, disc_loss = 9.285774948876362e-05
Trained batch 613 in epoch 17, gen_loss = 1.4866196221948058, disc_loss = 9.277487773089787e-05
Trained batch 614 in epoch 17, gen_loss = 1.4865958489053617, disc_loss = 9.266213485575944e-05
Trained batch 615 in epoch 17, gen_loss = 1.4865397791583816, disc_loss = 9.25384734409227e-05
Trained batch 616 in epoch 17, gen_loss = 1.4864226338156232, disc_loss = 9.248458713343453e-05
Trained batch 617 in epoch 17, gen_loss = 1.48641079104834, disc_loss = 9.242587380679543e-05
Trained batch 618 in epoch 17, gen_loss = 1.486498719463441, disc_loss = 9.237975564467275e-05
Trained batch 619 in epoch 17, gen_loss = 1.486359594714257, disc_loss = 9.23217488361256e-05
Trained batch 620 in epoch 17, gen_loss = 1.4863756568727478, disc_loss = 9.222335555113968e-05
Trained batch 621 in epoch 17, gen_loss = 1.4863608582993413, disc_loss = 9.216731082686594e-05
Trained batch 622 in epoch 17, gen_loss = 1.4863213782899836, disc_loss = 9.20755736642692e-05
Trained batch 623 in epoch 17, gen_loss = 1.486273389787246, disc_loss = 9.20059112384199e-05
Trained batch 624 in epoch 17, gen_loss = 1.48628060131073, disc_loss = 9.196486750151962e-05
Trained batch 625 in epoch 17, gen_loss = 1.4863197959650059, disc_loss = 9.190067530566151e-05
Trained batch 626 in epoch 17, gen_loss = 1.4863029509259944, disc_loss = 9.179365406163034e-05
Trained batch 627 in epoch 17, gen_loss = 1.486380180166026, disc_loss = 9.169024873421465e-05
Trained batch 628 in epoch 17, gen_loss = 1.4863750286435853, disc_loss = 9.159137274640011e-05
Trained batch 629 in epoch 17, gen_loss = 1.4864696833822462, disc_loss = 9.150869275525486e-05
Trained batch 630 in epoch 17, gen_loss = 1.4863848000434234, disc_loss = 9.143031038634115e-05
Trained batch 631 in epoch 17, gen_loss = 1.486404007371468, disc_loss = 9.132132327413044e-05
Trained batch 632 in epoch 17, gen_loss = 1.486277621692579, disc_loss = 9.12340728513728e-05
Trained batch 633 in epoch 17, gen_loss = 1.4862431684503044, disc_loss = 9.115003846745133e-05
Trained batch 634 in epoch 17, gen_loss = 1.486275413280397, disc_loss = 9.1067345503087e-05
Trained batch 635 in epoch 17, gen_loss = 1.486197312110625, disc_loss = 9.098077821678009e-05
Trained batch 636 in epoch 17, gen_loss = 1.4862189901118377, disc_loss = 9.088948519525427e-05
Trained batch 637 in epoch 17, gen_loss = 1.4861495089381467, disc_loss = 9.082458036630392e-05
Trained batch 638 in epoch 17, gen_loss = 1.486211336088106, disc_loss = 9.07775584736938e-05
Trained batch 639 in epoch 17, gen_loss = 1.486351479589939, disc_loss = 9.085014673928526e-05
Trained batch 640 in epoch 17, gen_loss = 1.4863588058632362, disc_loss = 9.085583058921417e-05
Trained batch 641 in epoch 17, gen_loss = 1.4863118286073393, disc_loss = 9.0819842838432e-05
Trained batch 642 in epoch 17, gen_loss = 1.4862714588734818, disc_loss = 9.075668421477075e-05
Trained batch 643 in epoch 17, gen_loss = 1.486257439074309, disc_loss = 9.068914287070482e-05
Trained batch 644 in epoch 17, gen_loss = 1.4861800160518912, disc_loss = 9.060791425601861e-05
Trained batch 645 in epoch 17, gen_loss = 1.4862447571090132, disc_loss = 9.052695920440404e-05
Trained batch 646 in epoch 17, gen_loss = 1.4863238233318654, disc_loss = 9.053462531377664e-05
Trained batch 647 in epoch 17, gen_loss = 1.4863179887150542, disc_loss = 9.047833084058553e-05
Trained batch 648 in epoch 17, gen_loss = 1.486363729269736, disc_loss = 9.061022994840533e-05
Trained batch 649 in epoch 17, gen_loss = 1.4863916398928716, disc_loss = 9.070588813651388e-05
Trained batch 650 in epoch 17, gen_loss = 1.4863564609199442, disc_loss = 9.072253693199357e-05
Trained batch 651 in epoch 17, gen_loss = 1.4864593530359445, disc_loss = 9.280314304969635e-05
Trained batch 652 in epoch 17, gen_loss = 1.4865430122495245, disc_loss = 9.42790484900289e-05
Trained batch 653 in epoch 17, gen_loss = 1.4864323241265907, disc_loss = 9.436434616811967e-05
Trained batch 654 in epoch 17, gen_loss = 1.486397486970625, disc_loss = 9.463501746792041e-05
Trained batch 655 in epoch 17, gen_loss = 1.4864299315504912, disc_loss = 9.460147164579056e-05
Trained batch 656 in epoch 17, gen_loss = 1.4864536830460826, disc_loss = 9.45345550151191e-05
Trained batch 657 in epoch 17, gen_loss = 1.4864210995497311, disc_loss = 9.443919877708348e-05
Trained batch 658 in epoch 17, gen_loss = 1.486358935807652, disc_loss = 9.434559982991106e-05
Trained batch 659 in epoch 17, gen_loss = 1.486355036497116, disc_loss = 9.424524784635375e-05
Trained batch 660 in epoch 17, gen_loss = 1.486411704779032, disc_loss = 9.414944670232398e-05
Trained batch 661 in epoch 17, gen_loss = 1.4863136578182439, disc_loss = 9.415064406529082e-05
Trained batch 662 in epoch 17, gen_loss = 1.4863178273311748, disc_loss = 9.410577994009861e-05
Trained batch 663 in epoch 17, gen_loss = 1.486281294061477, disc_loss = 9.405697483363114e-05
Trained batch 664 in epoch 17, gen_loss = 1.4862930177745963, disc_loss = 9.396361983133938e-05
Trained batch 665 in epoch 17, gen_loss = 1.4863314607121922, disc_loss = 9.385694445406878e-05
Trained batch 666 in epoch 17, gen_loss = 1.4862742831503255, disc_loss = 9.377652847912247e-05
Trained batch 667 in epoch 17, gen_loss = 1.4862214212646028, disc_loss = 9.372087152132191e-05
Trained batch 668 in epoch 17, gen_loss = 1.486164710268668, disc_loss = 9.362160653972275e-05
Trained batch 669 in epoch 17, gen_loss = 1.4861627852738792, disc_loss = 9.352111209775999e-05
Trained batch 670 in epoch 17, gen_loss = 1.4862997235200088, disc_loss = 9.348025472468891e-05
Trained batch 671 in epoch 17, gen_loss = 1.4862089669775396, disc_loss = 9.341531843379666e-05
Trained batch 672 in epoch 17, gen_loss = 1.4862067095415021, disc_loss = 9.333845181630653e-05
Trained batch 673 in epoch 17, gen_loss = 1.4861380937191428, disc_loss = 9.325702025798873e-05
Trained batch 674 in epoch 17, gen_loss = 1.4860563845104642, disc_loss = 9.316531052819401e-05
Trained batch 675 in epoch 17, gen_loss = 1.4859898137975727, disc_loss = 9.309633644359285e-05
Trained batch 676 in epoch 17, gen_loss = 1.4858915029283464, disc_loss = 9.30051408316075e-05
Trained batch 677 in epoch 17, gen_loss = 1.4859861193505008, disc_loss = 9.291582517638809e-05
Trained batch 678 in epoch 17, gen_loss = 1.485954907751575, disc_loss = 9.284149263493819e-05
Trained batch 679 in epoch 17, gen_loss = 1.4859216218485551, disc_loss = 9.278181689885113e-05
Trained batch 680 in epoch 17, gen_loss = 1.4858870961417536, disc_loss = 9.267682543343409e-05
Trained batch 681 in epoch 17, gen_loss = 1.4858267314273241, disc_loss = 9.2612100169206e-05
Trained batch 682 in epoch 17, gen_loss = 1.485789871320543, disc_loss = 9.26097257341985e-05
Trained batch 683 in epoch 17, gen_loss = 1.4858476125706008, disc_loss = 9.254688007807447e-05
Trained batch 684 in epoch 17, gen_loss = 1.4859336771234108, disc_loss = 9.246655493629689e-05
Trained batch 685 in epoch 17, gen_loss = 1.486037121396023, disc_loss = 9.249229845650285e-05
Trained batch 686 in epoch 17, gen_loss = 1.4860244529563094, disc_loss = 9.306879640037324e-05
Trained batch 687 in epoch 17, gen_loss = 1.485977606544661, disc_loss = 9.314942655353576e-05
Trained batch 688 in epoch 17, gen_loss = 1.485902415996712, disc_loss = 9.358643324319503e-05
Trained batch 689 in epoch 17, gen_loss = 1.4859169804531596, disc_loss = 9.370115978948678e-05
Trained batch 690 in epoch 17, gen_loss = 1.4858815914987655, disc_loss = 9.408093966025112e-05
Trained batch 691 in epoch 17, gen_loss = 1.4859811543040193, disc_loss = 9.57941911268254e-05
Trained batch 692 in epoch 17, gen_loss = 1.486048438848355, disc_loss = 9.733635768965276e-05
Trained batch 693 in epoch 17, gen_loss = 1.4861197664002521, disc_loss = 9.823172714573637e-05
Trained batch 694 in epoch 17, gen_loss = 1.4861638232100782, disc_loss = 9.899816297626176e-05
Trained batch 695 in epoch 17, gen_loss = 1.4861123674902423, disc_loss = 0.00010006546170021549
Trained batch 696 in epoch 17, gen_loss = 1.4861515640699368, disc_loss = 0.000101342869193378
Trained batch 697 in epoch 17, gen_loss = 1.4862944118272952, disc_loss = 0.00010374228494086058
Trained batch 698 in epoch 17, gen_loss = 1.486301323886593, disc_loss = 0.00010536301248243548
Trained batch 699 in epoch 17, gen_loss = 1.486376186779567, disc_loss = 0.00010685989709080396
Trained batch 700 in epoch 17, gen_loss = 1.4865611369871718, disc_loss = 0.00010782060713964593
Trained batch 701 in epoch 17, gen_loss = 1.4866655681207988, disc_loss = 0.00010869783805419579
Trained batch 702 in epoch 17, gen_loss = 1.4867827698991105, disc_loss = 0.0001104103577271757
Trained batch 703 in epoch 17, gen_loss = 1.4868405852466822, disc_loss = 0.00011144145836086946
Trained batch 704 in epoch 17, gen_loss = 1.4870497375515337, disc_loss = 0.0001126870478388642
Trained batch 705 in epoch 17, gen_loss = 1.487098703641054, disc_loss = 0.0001148147823223244
Trained batch 706 in epoch 17, gen_loss = 1.487278064035796, disc_loss = 0.0001170933827968766
Trained batch 707 in epoch 17, gen_loss = 1.4873483849447326, disc_loss = 0.00011759513238187429
Trained batch 708 in epoch 17, gen_loss = 1.487370703385142, disc_loss = 0.00011850071362489361
Trained batch 709 in epoch 17, gen_loss = 1.487393694696292, disc_loss = 0.00011965669458936966
Trained batch 710 in epoch 17, gen_loss = 1.4873901942611243, disc_loss = 0.00012009324473055451
Trained batch 711 in epoch 17, gen_loss = 1.4873147680518333, disc_loss = 0.00012119314067788079
Trained batch 712 in epoch 17, gen_loss = 1.4872532044687579, disc_loss = 0.00012247534570204835
Trained batch 713 in epoch 17, gen_loss = 1.487216921413646, disc_loss = 0.00012309826628302735
Trained batch 714 in epoch 17, gen_loss = 1.487106171854726, disc_loss = 0.00012492505322459602
Trained batch 715 in epoch 17, gen_loss = 1.4865133898884224, disc_loss = 0.0002006943605264796
Trained batch 716 in epoch 17, gen_loss = 1.4859112160308923, disc_loss = 0.0004431751090079329
Trained batch 717 in epoch 17, gen_loss = 1.4859959421715696, disc_loss = 0.0005090560486189493
Trained batch 718 in epoch 17, gen_loss = 1.485178171344858, disc_loss = 0.0006805418722121199
Trained batch 719 in epoch 17, gen_loss = 1.4866399885879622, disc_loss = 0.0014707912134427816
Trained batch 720 in epoch 17, gen_loss = 1.4854001779000736, disc_loss = 0.002140631122889928
Trained batch 721 in epoch 17, gen_loss = 1.484737115223322, disc_loss = 0.0022721328731024684
Trained batch 722 in epoch 17, gen_loss = 1.4847492759488266, disc_loss = 0.0024399331952162625
Trained batch 723 in epoch 17, gen_loss = 1.4850481908295037, disc_loss = 0.002472713205017338
Trained batch 724 in epoch 17, gen_loss = 1.4844217663797838, disc_loss = 0.0025406029473303755
Trained batch 725 in epoch 17, gen_loss = 1.4846479958410763, disc_loss = 0.0025488183045710567
Trained batch 726 in epoch 17, gen_loss = 1.4849146019149844, disc_loss = 0.0025559896859136204
Trained batch 727 in epoch 17, gen_loss = 1.4850097865193754, disc_loss = 0.00255769064933502
Trained batch 728 in epoch 17, gen_loss = 1.4851234446500718, disc_loss = 0.0025581625272030114
Trained batch 729 in epoch 17, gen_loss = 1.4852749876780054, disc_loss = 0.0025597886347920756
Trained batch 730 in epoch 17, gen_loss = 1.485409143033008, disc_loss = 0.0025597384910115294
Trained batch 731 in epoch 17, gen_loss = 1.4854246664568376, disc_loss = 0.002558541398903287
Trained batch 732 in epoch 17, gen_loss = 1.485426920335257, disc_loss = 0.002556921705976589
Trained batch 733 in epoch 17, gen_loss = 1.485573851607476, disc_loss = 0.002557524547937002
Trained batch 734 in epoch 17, gen_loss = 1.4855982087907338, disc_loss = 0.002556917321090951
Trained batch 735 in epoch 17, gen_loss = 1.4857707345939202, disc_loss = 0.0025549733255878023
Trained batch 736 in epoch 17, gen_loss = 1.4858003120409424, disc_loss = 0.0025533667167863022
Trained batch 737 in epoch 17, gen_loss = 1.4858317328339348, disc_loss = 0.002550953774977438
Trained batch 738 in epoch 17, gen_loss = 1.4858702897057643, disc_loss = 0.002548564697053181
Trained batch 739 in epoch 17, gen_loss = 1.4860151113690556, disc_loss = 0.002546163867638726
Trained batch 740 in epoch 17, gen_loss = 1.485954289011627, disc_loss = 0.002543581942319521
Trained batch 741 in epoch 17, gen_loss = 1.48599233331706, disc_loss = 0.002541033896391115
Trained batch 742 in epoch 17, gen_loss = 1.486065849962658, disc_loss = 0.00253848525900013
Trained batch 743 in epoch 17, gen_loss = 1.4859687203681597, disc_loss = 0.0025360488310764997
Trained batch 744 in epoch 17, gen_loss = 1.486040797649614, disc_loss = 0.0025349420423939006
Trained batch 745 in epoch 17, gen_loss = 1.4860276520731621, disc_loss = 0.002532451437496666
Testing Epoch 17
Training Epoch 18
Trained batch 0 in epoch 18, gen_loss = 1.498081088066101, disc_loss = 0.000560027314350009
Trained batch 1 in epoch 18, gen_loss = 1.4966119527816772, disc_loss = 0.0005643339827656746
Trained batch 2 in epoch 18, gen_loss = 1.4814035097757976, disc_loss = 0.0005404454423114657
Trained batch 3 in epoch 18, gen_loss = 1.4708818197250366, disc_loss = 0.0005229152884567156
Trained batch 4 in epoch 18, gen_loss = 1.4825852394104004, disc_loss = 0.0005115672014653682
Trained batch 5 in epoch 18, gen_loss = 1.4917081197102864, disc_loss = 0.0004989940886540959
Trained batch 6 in epoch 18, gen_loss = 1.4915187529155187, disc_loss = 0.0005010506720282137
Trained batch 7 in epoch 18, gen_loss = 1.4874852448701859, disc_loss = 0.0004961235354130622
Trained batch 8 in epoch 18, gen_loss = 1.4815586275524564, disc_loss = 0.000482244924771496
Trained batch 9 in epoch 18, gen_loss = 1.4846062660217285, disc_loss = 0.0004686193919042125
Trained batch 10 in epoch 18, gen_loss = 1.4844450950622559, disc_loss = 0.00046057489287870175
Trained batch 11 in epoch 18, gen_loss = 1.4854936798413594, disc_loss = 0.0004614267163560726
Trained batch 12 in epoch 18, gen_loss = 1.4791492132040172, disc_loss = 0.00045356427346212935
Trained batch 13 in epoch 18, gen_loss = 1.4759679266384669, disc_loss = 0.00044857701245096644
Trained batch 14 in epoch 18, gen_loss = 1.4751893202463786, disc_loss = 0.00043874124336677295
Trained batch 15 in epoch 18, gen_loss = 1.477515771985054, disc_loss = 0.00045475100523617584
Trained batch 16 in epoch 18, gen_loss = 1.4709651049445658, disc_loss = 0.0004458889443947769
Trained batch 17 in epoch 18, gen_loss = 1.471167458428277, disc_loss = 0.00044852950345052197
Trained batch 18 in epoch 18, gen_loss = 1.4695128641630475, disc_loss = 0.0004590488035893558
Trained batch 19 in epoch 18, gen_loss = 1.4670379281044006, disc_loss = 0.00045335668401094156
Trained batch 20 in epoch 18, gen_loss = 1.4673720825286138, disc_loss = 0.00044889886686134907
Trained batch 21 in epoch 18, gen_loss = 1.4662649794058367, disc_loss = 0.0004423475911607966
Trained batch 22 in epoch 18, gen_loss = 1.4682996221210645, disc_loss = 0.00044207223412661773
Trained batch 23 in epoch 18, gen_loss = 1.4680915226538975, disc_loss = 0.0004348038746684324
Trained batch 24 in epoch 18, gen_loss = 1.4648262786865234, disc_loss = 0.00042710489593446256
Trained batch 25 in epoch 18, gen_loss = 1.466297869498913, disc_loss = 0.0004394114165244481
Trained batch 26 in epoch 18, gen_loss = 1.463294925513091, disc_loss = 0.0004424001629188381
Trained batch 27 in epoch 18, gen_loss = 1.4634782373905182, disc_loss = 0.00043710061228401694
Trained batch 28 in epoch 18, gen_loss = 1.4619591030581245, disc_loss = 0.0004332915353909906
Trained batch 29 in epoch 18, gen_loss = 1.4623409827550253, disc_loss = 0.00043102618656121194
Trained batch 30 in epoch 18, gen_loss = 1.4613545979222944, disc_loss = 0.00043304024204131097
Trained batch 31 in epoch 18, gen_loss = 1.4586903303861618, disc_loss = 0.00042840537480515195
Trained batch 32 in epoch 18, gen_loss = 1.4581614913362446, disc_loss = 0.00042566843419053566
Trained batch 33 in epoch 18, gen_loss = 1.456163763999939, disc_loss = 0.00042085971268962193
Trained batch 34 in epoch 18, gen_loss = 1.4563968930925641, disc_loss = 0.00041565160333578076
Trained batch 35 in epoch 18, gen_loss = 1.4541968835724726, disc_loss = 0.00041246274809560017
Trained batch 36 in epoch 18, gen_loss = 1.454274151776288, disc_loss = 0.00041332190802849427
Trained batch 37 in epoch 18, gen_loss = 1.4534484775442826, disc_loss = 0.00041115562903302675
Trained batch 38 in epoch 18, gen_loss = 1.4524924632830498, disc_loss = 0.00040734800262352784
Trained batch 39 in epoch 18, gen_loss = 1.4504397004842757, disc_loss = 0.00040242428876808846
Trained batch 40 in epoch 18, gen_loss = 1.4493895013157914, disc_loss = 0.00039728813827401256
Trained batch 41 in epoch 18, gen_loss = 1.447768781866346, disc_loss = 0.0003927867683593095
Trained batch 42 in epoch 18, gen_loss = 1.4466429893360582, disc_loss = 0.0003878760481859709
Trained batch 43 in epoch 18, gen_loss = 1.4458263651891188, disc_loss = 0.00041783995799381626
Trained batch 44 in epoch 18, gen_loss = 1.4444603946473864, disc_loss = 0.000421831364898632
Trained batch 45 in epoch 18, gen_loss = 1.445444923380147, disc_loss = 0.0004207447092757439
Trained batch 46 in epoch 18, gen_loss = 1.4446130788072626, disc_loss = 0.0004170978716772763
Trained batch 47 in epoch 18, gen_loss = 1.445910635093848, disc_loss = 0.0004150258937443141
Trained batch 48 in epoch 18, gen_loss = 1.4452910034023985, disc_loss = 0.0004098897559891398
Trained batch 49 in epoch 18, gen_loss = 1.4440660405158996, disc_loss = 0.0004052072766353376
Trained batch 50 in epoch 18, gen_loss = 1.443059012001636, disc_loss = 0.0004038250569696995
Trained batch 51 in epoch 18, gen_loss = 1.4433137407669654, disc_loss = 0.00040343312502955087
Trained batch 52 in epoch 18, gen_loss = 1.443075400478435, disc_loss = 0.00040148744795620795
Trained batch 53 in epoch 18, gen_loss = 1.4427426523632474, disc_loss = 0.0003979124502856629
Trained batch 54 in epoch 18, gen_loss = 1.4412563454021108, disc_loss = 0.00039365082153711807
Trained batch 55 in epoch 18, gen_loss = 1.4417231976985931, disc_loss = 0.0003902035441569751
Trained batch 56 in epoch 18, gen_loss = 1.4426541914019668, disc_loss = 0.00038899713744237825
Trained batch 57 in epoch 18, gen_loss = 1.4417371318258088, disc_loss = 0.000386118074700413
Trained batch 58 in epoch 18, gen_loss = 1.4417602591595406, disc_loss = 0.00038297861884545407
Trained batch 59 in epoch 18, gen_loss = 1.4418314735094706, disc_loss = 0.00038085735844409403
Trained batch 60 in epoch 18, gen_loss = 1.4418841541790572, disc_loss = 0.00038400144849667233
Trained batch 61 in epoch 18, gen_loss = 1.4416274082276128, disc_loss = 0.00038846874127968124
Trained batch 62 in epoch 18, gen_loss = 1.4419349280614702, disc_loss = 0.000386157849413668
Trained batch 63 in epoch 18, gen_loss = 1.4417256955057383, disc_loss = 0.0003829253084859374
Trained batch 64 in epoch 18, gen_loss = 1.4405292951143704, disc_loss = 0.00038041480091543725
Trained batch 65 in epoch 18, gen_loss = 1.4398831959926721, disc_loss = 0.0003770448282452752
Trained batch 66 in epoch 18, gen_loss = 1.4385029326623946, disc_loss = 0.0003737558546882651
Trained batch 67 in epoch 18, gen_loss = 1.4381747684058022, disc_loss = 0.000371144940265153
Trained batch 68 in epoch 18, gen_loss = 1.4376169132149739, disc_loss = 0.0003679954690227717
Trained batch 69 in epoch 18, gen_loss = 1.4378456098692758, disc_loss = 0.00036518000810506886
Trained batch 70 in epoch 18, gen_loss = 1.4370769967495556, disc_loss = 0.0003619376751577849
Trained batch 71 in epoch 18, gen_loss = 1.4371474732955296, disc_loss = 0.00035920695881941356
Trained batch 72 in epoch 18, gen_loss = 1.4352456037312338, disc_loss = 0.00035637093680808706
Trained batch 73 in epoch 18, gen_loss = 1.436414836226283, disc_loss = 0.0003564407871218046
Trained batch 74 in epoch 18, gen_loss = 1.4364105240503946, disc_loss = 0.0003542936213004092
Trained batch 75 in epoch 18, gen_loss = 1.435874404091584, disc_loss = 0.0003517587185916981
Trained batch 76 in epoch 18, gen_loss = 1.43582089690419, disc_loss = 0.0003491342324739346
Trained batch 77 in epoch 18, gen_loss = 1.4358085516171577, disc_loss = 0.0003471410583677845
Trained batch 78 in epoch 18, gen_loss = 1.4365775947329364, disc_loss = 0.00034474222710845356
Trained batch 79 in epoch 18, gen_loss = 1.4367215156555175, disc_loss = 0.000342644534430292
Trained batch 80 in epoch 18, gen_loss = 1.4358781738045774, disc_loss = 0.00034029599093044475
Trained batch 81 in epoch 18, gen_loss = 1.4351358762601527, disc_loss = 0.0003379116325693137
Trained batch 82 in epoch 18, gen_loss = 1.434593769441168, disc_loss = 0.0003354830661415493
Trained batch 83 in epoch 18, gen_loss = 1.4342969074135734, disc_loss = 0.00033307352645178546
Trained batch 84 in epoch 18, gen_loss = 1.4330687003977158, disc_loss = 0.0003312495338511379
Trained batch 85 in epoch 18, gen_loss = 1.4326578836108363, disc_loss = 0.000329405473251448
Trained batch 86 in epoch 18, gen_loss = 1.4326946940915337, disc_loss = 0.00032715673271389997
Trained batch 87 in epoch 18, gen_loss = 1.4323517219586805, disc_loss = 0.0003249646723071981
Trained batch 88 in epoch 18, gen_loss = 1.4314786088600586, disc_loss = 0.00032280378120171766
Trained batch 89 in epoch 18, gen_loss = 1.4312739253044129, disc_loss = 0.00032082408433780073
Trained batch 90 in epoch 18, gen_loss = 1.4312517132077898, disc_loss = 0.00031884477533282364
Trained batch 91 in epoch 18, gen_loss = 1.4308582026025523, disc_loss = 0.0003173970410147297
Trained batch 92 in epoch 18, gen_loss = 1.4310064110704648, disc_loss = 0.00031558985797493086
Trained batch 93 in epoch 18, gen_loss = 1.4310167533286073, disc_loss = 0.00031437907888717516
Trained batch 94 in epoch 18, gen_loss = 1.4303276400817069, disc_loss = 0.00031239361805522717
Trained batch 95 in epoch 18, gen_loss = 1.4302856860061486, disc_loss = 0.0003103396168171457
Trained batch 96 in epoch 18, gen_loss = 1.4293351898488311, disc_loss = 0.00030868737719840243
Trained batch 97 in epoch 18, gen_loss = 1.429864904102014, disc_loss = 0.0003071332431893691
Trained batch 98 in epoch 18, gen_loss = 1.4292847399759774, disc_loss = 0.0003052757374002749
Trained batch 99 in epoch 18, gen_loss = 1.4287621104717254, disc_loss = 0.00030319274672365283
Trained batch 100 in epoch 18, gen_loss = 1.4286653688638518, disc_loss = 0.0003013444680744773
Trained batch 101 in epoch 18, gen_loss = 1.4282375340368234, disc_loss = 0.00029982307444465823
Trained batch 102 in epoch 18, gen_loss = 1.42767054479099, disc_loss = 0.00029808497747227787
Trained batch 103 in epoch 18, gen_loss = 1.4275171699432225, disc_loss = 0.00029642322869431856
Trained batch 104 in epoch 18, gen_loss = 1.4266783930006481, disc_loss = 0.00029459312846440643
Trained batch 105 in epoch 18, gen_loss = 1.4267233182799142, disc_loss = 0.000293741976147087
Trained batch 106 in epoch 18, gen_loss = 1.4265447242237697, disc_loss = 0.0002927710681611881
Trained batch 107 in epoch 18, gen_loss = 1.4267123341560364, disc_loss = 0.0002913551881512696
Trained batch 108 in epoch 18, gen_loss = 1.4268240009972808, disc_loss = 0.00028982799614506237
Trained batch 109 in epoch 18, gen_loss = 1.426731888814406, disc_loss = 0.00028822782551287676
Trained batch 110 in epoch 18, gen_loss = 1.425979224411217, disc_loss = 0.0002865774401905107
Trained batch 111 in epoch 18, gen_loss = 1.4264351863946234, disc_loss = 0.00028578173552367455
Trained batch 112 in epoch 18, gen_loss = 1.4259118379744808, disc_loss = 0.0002841863112727106
Trained batch 113 in epoch 18, gen_loss = 1.4254246531871326, disc_loss = 0.0002826818798846369
Trained batch 114 in epoch 18, gen_loss = 1.4251914729242738, disc_loss = 0.00028121011260815934
Trained batch 115 in epoch 18, gen_loss = 1.4244205540624157, disc_loss = 0.00027965793397642896
Trained batch 116 in epoch 18, gen_loss = 1.4248415180760572, disc_loss = 0.0002793605466976236
Trained batch 117 in epoch 18, gen_loss = 1.4246714499037145, disc_loss = 0.0002785252518922296
Trained batch 118 in epoch 18, gen_loss = 1.4245020732158373, disc_loss = 0.00027756995539583983
Trained batch 119 in epoch 18, gen_loss = 1.4248605459928512, disc_loss = 0.0002764300444444719
Trained batch 120 in epoch 18, gen_loss = 1.4252737533947653, disc_loss = 0.0002757130708585855
Trained batch 121 in epoch 18, gen_loss = 1.425238260480224, disc_loss = 0.0002747100345422056
Trained batch 122 in epoch 18, gen_loss = 1.4250786236631192, disc_loss = 0.0002737628612847151
Trained batch 123 in epoch 18, gen_loss = 1.4245417916005658, disc_loss = 0.00027245128066785966
Trained batch 124 in epoch 18, gen_loss = 1.4246520624160766, disc_loss = 0.0002714999843155965
Trained batch 125 in epoch 18, gen_loss = 1.4244210937666515, disc_loss = 0.00027011020303313946
Trained batch 126 in epoch 18, gen_loss = 1.4242005958331851, disc_loss = 0.0002695962878454689
Trained batch 127 in epoch 18, gen_loss = 1.4240548824891448, disc_loss = 0.0002693766220431826
Trained batch 128 in epoch 18, gen_loss = 1.4250138998031616, disc_loss = 0.00026983041477582755
Trained batch 129 in epoch 18, gen_loss = 1.425255099626688, disc_loss = 0.00026887112510918924
Trained batch 130 in epoch 18, gen_loss = 1.4248500470896714, disc_loss = 0.00026992655718896384
Trained batch 131 in epoch 18, gen_loss = 1.4243509354013386, disc_loss = 0.00026966101033780654
Trained batch 132 in epoch 18, gen_loss = 1.4244202429190613, disc_loss = 0.00026859426364360406
Trained batch 133 in epoch 18, gen_loss = 1.4249794296364287, disc_loss = 0.0002677310772353971
Trained batch 134 in epoch 18, gen_loss = 1.4246293942133585, disc_loss = 0.00026695191341719624
Trained batch 135 in epoch 18, gen_loss = 1.4243458237718134, disc_loss = 0.0002659797879352803
Trained batch 136 in epoch 18, gen_loss = 1.4248473444124208, disc_loss = 0.00026497092639923733
Trained batch 137 in epoch 18, gen_loss = 1.4250682808350825, disc_loss = 0.0002639219769596399
Trained batch 138 in epoch 18, gen_loss = 1.42519302076573, disc_loss = 0.0002629704973488718
Trained batch 139 in epoch 18, gen_loss = 1.4252544956547872, disc_loss = 0.00026193511995578384
Trained batch 140 in epoch 18, gen_loss = 1.4253397960189387, disc_loss = 0.00026249949995169075
Trained batch 141 in epoch 18, gen_loss = 1.425476180835509, disc_loss = 0.00026209148410076446
Trained batch 142 in epoch 18, gen_loss = 1.4259329700803423, disc_loss = 0.0002614582016786489
Trained batch 143 in epoch 18, gen_loss = 1.4257511008116934, disc_loss = 0.0002605208323984698
Trained batch 144 in epoch 18, gen_loss = 1.4258392210664421, disc_loss = 0.00025970192474578026
Trained batch 145 in epoch 18, gen_loss = 1.4257185410146844, disc_loss = 0.0002585167871299359
Trained batch 146 in epoch 18, gen_loss = 1.4254229352587746, disc_loss = 0.00025753229113056506
Trained batch 147 in epoch 18, gen_loss = 1.4247975711886947, disc_loss = 0.00025642232631562856
Trained batch 148 in epoch 18, gen_loss = 1.4242005756237364, disc_loss = 0.000255530031969077
Trained batch 149 in epoch 18, gen_loss = 1.4245397440592449, disc_loss = 0.0002547962817091805
Trained batch 150 in epoch 18, gen_loss = 1.4246718394045799, disc_loss = 0.0002538172207427341
Trained batch 151 in epoch 18, gen_loss = 1.4241557035006975, disc_loss = 0.00025281609348320143
Trained batch 152 in epoch 18, gen_loss = 1.424195404146232, disc_loss = 0.0002517585683628472
Trained batch 153 in epoch 18, gen_loss = 1.42438130951547, disc_loss = 0.0002508173697547195
Trained batch 154 in epoch 18, gen_loss = 1.4241633353694794, disc_loss = 0.00024990024455379876
Trained batch 155 in epoch 18, gen_loss = 1.423906500522907, disc_loss = 0.0002490263926189912
Trained batch 156 in epoch 18, gen_loss = 1.423653058185699, disc_loss = 0.0002479088269036922
Trained batch 157 in epoch 18, gen_loss = 1.4236714960653571, disc_loss = 0.00024793462958032136
Trained batch 158 in epoch 18, gen_loss = 1.4239983671116379, disc_loss = 0.0002474182599927767
Trained batch 159 in epoch 18, gen_loss = 1.4236829288303852, disc_loss = 0.00024726019505578735
Trained batch 160 in epoch 18, gen_loss = 1.4234822721955198, disc_loss = 0.0002464660475813633
Trained batch 161 in epoch 18, gen_loss = 1.4232762706132582, disc_loss = 0.00024591333100415573
Trained batch 162 in epoch 18, gen_loss = 1.4229342118362707, disc_loss = 0.0002449613086489298
Trained batch 163 in epoch 18, gen_loss = 1.4227577258900899, disc_loss = 0.00024402948270662596
Trained batch 164 in epoch 18, gen_loss = 1.4224742903853909, disc_loss = 0.00024370894014172142
Trained batch 165 in epoch 18, gen_loss = 1.4225817286824605, disc_loss = 0.000243092891749651
Trained batch 166 in epoch 18, gen_loss = 1.4225651132846306, disc_loss = 0.00024247684588859383
Trained batch 167 in epoch 18, gen_loss = 1.4225583672523499, disc_loss = 0.00024161304472294259
Trained batch 168 in epoch 18, gen_loss = 1.4227075407490928, disc_loss = 0.00024081455538815338
Trained batch 169 in epoch 18, gen_loss = 1.4227661876117481, disc_loss = 0.00024010867953834617
Trained batch 170 in epoch 18, gen_loss = 1.4228908862286842, disc_loss = 0.0002392634291325053
Trained batch 171 in epoch 18, gen_loss = 1.423074604466904, disc_loss = 0.00023859474462961918
Trained batch 172 in epoch 18, gen_loss = 1.4231159066878303, disc_loss = 0.0002383046279741435
Trained batch 173 in epoch 18, gen_loss = 1.4229617269559838, disc_loss = 0.00023782902636234756
Trained batch 174 in epoch 18, gen_loss = 1.4228858981813703, disc_loss = 0.0002368635923318964
Trained batch 175 in epoch 18, gen_loss = 1.422927331518043, disc_loss = 0.00023637719753175836
Trained batch 176 in epoch 18, gen_loss = 1.4226319729271582, disc_loss = 0.00023563635925397981
Trained batch 177 in epoch 18, gen_loss = 1.4224928175465446, disc_loss = 0.00023493779478352673
Trained batch 178 in epoch 18, gen_loss = 1.4224762330508098, disc_loss = 0.0002346133126557919
Trained batch 179 in epoch 18, gen_loss = 1.4225616640514798, disc_loss = 0.00023413120971882664
Trained batch 180 in epoch 18, gen_loss = 1.4226394068470318, disc_loss = 0.00023345864084144046
Trained batch 181 in epoch 18, gen_loss = 1.422610119148925, disc_loss = 0.00023270612647328373
Trained batch 182 in epoch 18, gen_loss = 1.422512894771138, disc_loss = 0.0002322060978367716
Trained batch 183 in epoch 18, gen_loss = 1.4225578593171162, disc_loss = 0.00023146594630025388
Trained batch 184 in epoch 18, gen_loss = 1.4226271294258737, disc_loss = 0.00023068604130310484
Trained batch 185 in epoch 18, gen_loss = 1.4225010500159314, disc_loss = 0.00023017902487716186
Trained batch 186 in epoch 18, gen_loss = 1.4223972884091465, disc_loss = 0.00022947611794607803
Trained batch 187 in epoch 18, gen_loss = 1.4225244972300022, disc_loss = 0.0002287779938574494
Trained batch 188 in epoch 18, gen_loss = 1.422599123268531, disc_loss = 0.00022813074052686156
Trained batch 189 in epoch 18, gen_loss = 1.422698278176157, disc_loss = 0.0002273562114217049
Trained batch 190 in epoch 18, gen_loss = 1.422178692218521, disc_loss = 0.0002267404493091979
Trained batch 191 in epoch 18, gen_loss = 1.4218844876935084, disc_loss = 0.0002262685753369927
Trained batch 192 in epoch 18, gen_loss = 1.4215036247678372, disc_loss = 0.0002259763036559003
Trained batch 193 in epoch 18, gen_loss = 1.4214880245248067, disc_loss = 0.00022529779350416275
Trained batch 194 in epoch 18, gen_loss = 1.421354026060838, disc_loss = 0.00022466334033733568
Trained batch 195 in epoch 18, gen_loss = 1.4209520859377724, disc_loss = 0.00022407668141995044
Trained batch 196 in epoch 18, gen_loss = 1.420746225996066, disc_loss = 0.00022333489031723563
Trained batch 197 in epoch 18, gen_loss = 1.420357756542437, disc_loss = 0.00022254084640992757
Trained batch 198 in epoch 18, gen_loss = 1.4202084930697878, disc_loss = 0.00022183589894826474
Trained batch 199 in epoch 18, gen_loss = 1.4206788581609726, disc_loss = 0.00022224576303415234
Trained batch 200 in epoch 18, gen_loss = 1.4202456456511767, disc_loss = 0.0002220419650148503
Trained batch 201 in epoch 18, gen_loss = 1.4200216106849142, disc_loss = 0.00022184787598919205
Trained batch 202 in epoch 18, gen_loss = 1.4198880072297722, disc_loss = 0.00022138025385259966
Trained batch 203 in epoch 18, gen_loss = 1.4198761810274685, disc_loss = 0.00022072666412414573
Trained batch 204 in epoch 18, gen_loss = 1.419682158493414, disc_loss = 0.00022010093390879154
Trained batch 205 in epoch 18, gen_loss = 1.4194584170591484, disc_loss = 0.0002197507576798247
Trained batch 206 in epoch 18, gen_loss = 1.419443909096833, disc_loss = 0.00022079307318958655
Trained batch 207 in epoch 18, gen_loss = 1.4196219151982894, disc_loss = 0.00022064629995209264
Trained batch 208 in epoch 18, gen_loss = 1.4193653592652682, disc_loss = 0.00022059396748585875
Trained batch 209 in epoch 18, gen_loss = 1.419358608268556, disc_loss = 0.00022068877868670306
Trained batch 210 in epoch 18, gen_loss = 1.419478195538453, disc_loss = 0.0002202672048477937
Trained batch 211 in epoch 18, gen_loss = 1.419260416390761, disc_loss = 0.00021958240664252167
Trained batch 212 in epoch 18, gen_loss = 1.4193384361938692, disc_loss = 0.0002189945702702288
Trained batch 213 in epoch 18, gen_loss = 1.4189289017258404, disc_loss = 0.00021852155439892922
Trained batch 214 in epoch 18, gen_loss = 1.418446118332619, disc_loss = 0.00021807014384458577
Trained batch 215 in epoch 18, gen_loss = 1.4182667555632416, disc_loss = 0.00021818744695607434
Trained batch 216 in epoch 18, gen_loss = 1.418381164700205, disc_loss = 0.00021788428159600148
Trained batch 217 in epoch 18, gen_loss = 1.4180773420071384, disc_loss = 0.00021734786183314842
Trained batch 218 in epoch 18, gen_loss = 1.4178873284222329, disc_loss = 0.00021674267024856451
Trained batch 219 in epoch 18, gen_loss = 1.4179463803768158, disc_loss = 0.0002165018903641877
Trained batch 220 in epoch 18, gen_loss = 1.4179295409319088, disc_loss = 0.00021601365881811877
Trained batch 221 in epoch 18, gen_loss = 1.4177637245203998, disc_loss = 0.00021544827069265994
Trained batch 222 in epoch 18, gen_loss = 1.4177533291915072, disc_loss = 0.00021527991792622477
Trained batch 223 in epoch 18, gen_loss = 1.4177897641701358, disc_loss = 0.0002148934813378998
Trained batch 224 in epoch 18, gen_loss = 1.417500639491611, disc_loss = 0.0002153146818293155
Trained batch 225 in epoch 18, gen_loss = 1.4174368935348713, disc_loss = 0.00021496463214295538
Trained batch 226 in epoch 18, gen_loss = 1.4169519761585454, disc_loss = 0.00021484312640491766
Trained batch 227 in epoch 18, gen_loss = 1.4168592827361928, disc_loss = 0.00021435409051487672
Trained batch 228 in epoch 18, gen_loss = 1.4165941919301794, disc_loss = 0.0002138144399233134
Trained batch 229 in epoch 18, gen_loss = 1.4167029230490975, disc_loss = 0.00021321809187571964
Trained batch 230 in epoch 18, gen_loss = 1.416626947266715, disc_loss = 0.00021263168114529784
Trained batch 231 in epoch 18, gen_loss = 1.4165533822158287, disc_loss = 0.00021202347902701525
Trained batch 232 in epoch 18, gen_loss = 1.4163485627317633, disc_loss = 0.00021151851338924952
Trained batch 233 in epoch 18, gen_loss = 1.4164736016183836, disc_loss = 0.00021110614397912286
Trained batch 234 in epoch 18, gen_loss = 1.4165402808087937, disc_loss = 0.00021057441908658105
Trained batch 235 in epoch 18, gen_loss = 1.4161723518775682, disc_loss = 0.00021010037306627116
Trained batch 236 in epoch 18, gen_loss = 1.415984917793596, disc_loss = 0.000209546661474015
Trained batch 237 in epoch 18, gen_loss = 1.4160368778124577, disc_loss = 0.0002091414667311332
Trained batch 238 in epoch 18, gen_loss = 1.415816643746827, disc_loss = 0.000208701287116417
Trained batch 239 in epoch 18, gen_loss = 1.4155995016296705, disc_loss = 0.0002083440012029314
Trained batch 240 in epoch 18, gen_loss = 1.415614812205936, disc_loss = 0.00020801268725803787
Trained batch 241 in epoch 18, gen_loss = 1.4157468868681222, disc_loss = 0.00020760466297871957
Trained batch 242 in epoch 18, gen_loss = 1.415449660010789, disc_loss = 0.00020716974130638113
Trained batch 243 in epoch 18, gen_loss = 1.41510116028004, disc_loss = 0.00020672907700574171
Trained batch 244 in epoch 18, gen_loss = 1.4149723855816587, disc_loss = 0.00020620835228105626
Trained batch 245 in epoch 18, gen_loss = 1.4148747039035083, disc_loss = 0.00020573417060678196
Trained batch 246 in epoch 18, gen_loss = 1.414990646153809, disc_loss = 0.00020524979425737492
Trained batch 247 in epoch 18, gen_loss = 1.4149877544372313, disc_loss = 0.00020470581095592463
Trained batch 248 in epoch 18, gen_loss = 1.4146969146039112, disc_loss = 0.0002042139433223818
Trained batch 249 in epoch 18, gen_loss = 1.4144783544540405, disc_loss = 0.00020376186061184853
Trained batch 250 in epoch 18, gen_loss = 1.4143109872521633, disc_loss = 0.0002033097085492422
Trained batch 251 in epoch 18, gen_loss = 1.4143663512335882, disc_loss = 0.00020281335361817452
Trained batch 252 in epoch 18, gen_loss = 1.4140726893315674, disc_loss = 0.00020261647836802152
Trained batch 253 in epoch 18, gen_loss = 1.4140948263678963, disc_loss = 0.00020226382637372623
Trained batch 254 in epoch 18, gen_loss = 1.4140830245672489, disc_loss = 0.00020181314729259112
Trained batch 255 in epoch 18, gen_loss = 1.413789615035057, disc_loss = 0.00020126976195911084
Trained batch 256 in epoch 18, gen_loss = 1.413769327712894, disc_loss = 0.00020124399823345904
Trained batch 257 in epoch 18, gen_loss = 1.4134868734566741, disc_loss = 0.00020089026843062276
Trained batch 258 in epoch 18, gen_loss = 1.413559119213502, disc_loss = 0.00020051172599722325
Trained batch 259 in epoch 18, gen_loss = 1.4137312806569613, disc_loss = 0.00020010416245405885
Trained batch 260 in epoch 18, gen_loss = 1.4139916526860203, disc_loss = 0.0001997250301812033
Trained batch 261 in epoch 18, gen_loss = 1.413847901893936, disc_loss = 0.0001992800468563383
Trained batch 262 in epoch 18, gen_loss = 1.4137136324276942, disc_loss = 0.00019890503644586467
Trained batch 263 in epoch 18, gen_loss = 1.4136893911795183, disc_loss = 0.00019845887549529311
Trained batch 264 in epoch 18, gen_loss = 1.4134147491095201, disc_loss = 0.00019805014228452665
Trained batch 265 in epoch 18, gen_loss = 1.4134339165866823, disc_loss = 0.00019761652624868277
Trained batch 266 in epoch 18, gen_loss = 1.4133031453086196, disc_loss = 0.00019735236466236148
Trained batch 267 in epoch 18, gen_loss = 1.4129970082596166, disc_loss = 0.0001970741137320961
Trained batch 268 in epoch 18, gen_loss = 1.4130372389541683, disc_loss = 0.00019680653809315307
Trained batch 269 in epoch 18, gen_loss = 1.4130531915911921, disc_loss = 0.00019641049296263157
Trained batch 270 in epoch 18, gen_loss = 1.4129875207739122, disc_loss = 0.0001959136040813403
Trained batch 271 in epoch 18, gen_loss = 1.4128367331098108, disc_loss = 0.00019547127340047155
Trained batch 272 in epoch 18, gen_loss = 1.4125378223565908, disc_loss = 0.00019498746333628441
Trained batch 273 in epoch 18, gen_loss = 1.4123669584302136, disc_loss = 0.00019447715122577306
Trained batch 274 in epoch 18, gen_loss = 1.4121911690451883, disc_loss = 0.00019393735623452813
Trained batch 275 in epoch 18, gen_loss = 1.4126362506894097, disc_loss = 0.00019363129417731704
Trained batch 276 in epoch 18, gen_loss = 1.4126295548483783, disc_loss = 0.0001931823273926943
Trained batch 277 in epoch 18, gen_loss = 1.4126958156661165, disc_loss = 0.0001927429295667169
Trained batch 278 in epoch 18, gen_loss = 1.4125637482571345, disc_loss = 0.000192263858362792
Trained batch 279 in epoch 18, gen_loss = 1.412765024815287, disc_loss = 0.000192380267981207
Trained batch 280 in epoch 18, gen_loss = 1.4126485539500824, disc_loss = 0.00019219230693305953
Trained batch 281 in epoch 18, gen_loss = 1.4127754539462691, disc_loss = 0.0001918820670788533
Trained batch 282 in epoch 18, gen_loss = 1.4130943141640706, disc_loss = 0.0001916626122551427
Trained batch 283 in epoch 18, gen_loss = 1.4129029143024499, disc_loss = 0.00019123280148512133
Trained batch 284 in epoch 18, gen_loss = 1.4129134847406755, disc_loss = 0.00019087355515997237
Trained batch 285 in epoch 18, gen_loss = 1.413040419558545, disc_loss = 0.00019059453549928363
Trained batch 286 in epoch 18, gen_loss = 1.4129666210466976, disc_loss = 0.0001902194278524014
Trained batch 287 in epoch 18, gen_loss = 1.413239484031995, disc_loss = 0.00018977643445497152
Trained batch 288 in epoch 18, gen_loss = 1.4130941373666677, disc_loss = 0.00018947604325822326
Trained batch 289 in epoch 18, gen_loss = 1.4130314366570835, disc_loss = 0.00018918631979212132
Trained batch 290 in epoch 18, gen_loss = 1.4128930748942792, disc_loss = 0.0001889984156663171
Trained batch 291 in epoch 18, gen_loss = 1.412774871881694, disc_loss = 0.00018863184139836573
Trained batch 292 in epoch 18, gen_loss = 1.4128269543013068, disc_loss = 0.0001883023572597357
Trained batch 293 in epoch 18, gen_loss = 1.4130446363468558, disc_loss = 0.00018808180697442057
Trained batch 294 in epoch 18, gen_loss = 1.4131115016290696, disc_loss = 0.00018792769669898453
Trained batch 295 in epoch 18, gen_loss = 1.4131598851165257, disc_loss = 0.00018775410021712683
Trained batch 296 in epoch 18, gen_loss = 1.4128337038887873, disc_loss = 0.0001874125343545572
Trained batch 297 in epoch 18, gen_loss = 1.4126418068905005, disc_loss = 0.00018700045750194366
Trained batch 298 in epoch 18, gen_loss = 1.4126715703951476, disc_loss = 0.00018657529579645278
Trained batch 299 in epoch 18, gen_loss = 1.4127905134359995, disc_loss = 0.00018622866138078584
Trained batch 300 in epoch 18, gen_loss = 1.4124083883342553, disc_loss = 0.00018591092180258027
Trained batch 301 in epoch 18, gen_loss = 1.4123701859783653, disc_loss = 0.0001855503697089376
Trained batch 302 in epoch 18, gen_loss = 1.4125921494103109, disc_loss = 0.00018524582898889734
Trained batch 303 in epoch 18, gen_loss = 1.4125235163067515, disc_loss = 0.00018484320059398765
Trained batch 304 in epoch 18, gen_loss = 1.4123677882991854, disc_loss = 0.000184510747108181
Trained batch 305 in epoch 18, gen_loss = 1.4121310784925822, disc_loss = 0.00018411894520825334
Trained batch 306 in epoch 18, gen_loss = 1.4120367602339008, disc_loss = 0.00018369424181161008
Trained batch 307 in epoch 18, gen_loss = 1.4120655439116738, disc_loss = 0.00018375497620581882
Trained batch 308 in epoch 18, gen_loss = 1.4117376260387087, disc_loss = 0.0001835570631976937
Trained batch 309 in epoch 18, gen_loss = 1.4116128959963399, disc_loss = 0.00018322212820367573
Trained batch 310 in epoch 18, gen_loss = 1.4114991418801703, disc_loss = 0.00018305916894237372
Trained batch 311 in epoch 18, gen_loss = 1.4116580428985448, disc_loss = 0.0001829402282895059
Trained batch 312 in epoch 18, gen_loss = 1.4115096136403922, disc_loss = 0.0001827836299337225
Trained batch 313 in epoch 18, gen_loss = 1.4115964014818714, disc_loss = 0.00018274192593331452
Trained batch 314 in epoch 18, gen_loss = 1.4117075185927133, disc_loss = 0.00018244289948063578
Trained batch 315 in epoch 18, gen_loss = 1.41172607073301, disc_loss = 0.00018211733776631343
Trained batch 316 in epoch 18, gen_loss = 1.4117654261152828, disc_loss = 0.00018178109285116493
Trained batch 317 in epoch 18, gen_loss = 1.411489339369648, disc_loss = 0.00018143973205230892
Trained batch 318 in epoch 18, gen_loss = 1.4116259678777856, disc_loss = 0.00018113634223054561
Trained batch 319 in epoch 18, gen_loss = 1.411505526304245, disc_loss = 0.00018082265188468227
Trained batch 320 in epoch 18, gen_loss = 1.4115556534205642, disc_loss = 0.00018047840116921642
Trained batch 321 in epoch 18, gen_loss = 1.4118062998197094, disc_loss = 0.00018031930493131953
Trained batch 322 in epoch 18, gen_loss = 1.4117893548941833, disc_loss = 0.00018010436574218076
Trained batch 323 in epoch 18, gen_loss = 1.4116195782467171, disc_loss = 0.0001797901828961776
Trained batch 324 in epoch 18, gen_loss = 1.4116941829828116, disc_loss = 0.00017951894816808188
Trained batch 325 in epoch 18, gen_loss = 1.411598225678403, disc_loss = 0.00017914642745504324
Trained batch 326 in epoch 18, gen_loss = 1.4115104912253331, disc_loss = 0.00017878120832598416
Trained batch 327 in epoch 18, gen_loss = 1.4117363353328007, disc_loss = 0.00017842074559178776
Trained batch 328 in epoch 18, gen_loss = 1.4118645129595122, disc_loss = 0.00017808238679092338
Trained batch 329 in epoch 18, gen_loss = 1.411810053839828, disc_loss = 0.00017771540837147217
Trained batch 330 in epoch 18, gen_loss = 1.4118216819273381, disc_loss = 0.0001776038390189322
Trained batch 331 in epoch 18, gen_loss = 1.4116653387086937, disc_loss = 0.00017730104761529174
Trained batch 332 in epoch 18, gen_loss = 1.4117522053532414, disc_loss = 0.00017693565012876633
Trained batch 333 in epoch 18, gen_loss = 1.411636269021177, disc_loss = 0.0001765816330829214
Trained batch 334 in epoch 18, gen_loss = 1.4114358421581894, disc_loss = 0.00017622208424518927
Trained batch 335 in epoch 18, gen_loss = 1.4111725858279638, disc_loss = 0.00017583795926969157
Trained batch 336 in epoch 18, gen_loss = 1.411045540334209, disc_loss = 0.00017551780320665638
Trained batch 337 in epoch 18, gen_loss = 1.410974986807129, disc_loss = 0.00017513057312192105
Trained batch 338 in epoch 18, gen_loss = 1.4107964204124293, disc_loss = 0.00017490331979616474
Trained batch 339 in epoch 18, gen_loss = 1.4107063570443321, disc_loss = 0.0001746330112890813
Trained batch 340 in epoch 18, gen_loss = 1.4105871803949306, disc_loss = 0.00017426207798100938
Trained batch 341 in epoch 18, gen_loss = 1.410564827291589, disc_loss = 0.00017389559966245836
Trained batch 342 in epoch 18, gen_loss = 1.4105561307845935, disc_loss = 0.0001735308734664786
Trained batch 343 in epoch 18, gen_loss = 1.4105789599030516, disc_loss = 0.00017319397291557412
Trained batch 344 in epoch 18, gen_loss = 1.4106385452159937, disc_loss = 0.00017289745865391393
Trained batch 345 in epoch 18, gen_loss = 1.4106373159871626, disc_loss = 0.0001725668724226924
Trained batch 346 in epoch 18, gen_loss = 1.4104648584591208, disc_loss = 0.0001722158974244411
Trained batch 347 in epoch 18, gen_loss = 1.4102613429228466, disc_loss = 0.00017192731520063016
Trained batch 348 in epoch 18, gen_loss = 1.4102069552785004, disc_loss = 0.00017160108934819064
Trained batch 349 in epoch 18, gen_loss = 1.4100449064799718, disc_loss = 0.00017127419562062383
Trained batch 350 in epoch 18, gen_loss = 1.4100449207501533, disc_loss = 0.00017094759344676524
Trained batch 351 in epoch 18, gen_loss = 1.4097644561393694, disc_loss = 0.0001705745265884285
Trained batch 352 in epoch 18, gen_loss = 1.4097853291136009, disc_loss = 0.0001702814764625501
Trained batch 353 in epoch 18, gen_loss = 1.4097623356991569, disc_loss = 0.00016999645270459818
Trained batch 354 in epoch 18, gen_loss = 1.4099117980876439, disc_loss = 0.00016974387817497981
Trained batch 355 in epoch 18, gen_loss = 1.4098874752441148, disc_loss = 0.0001694097154540941
Trained batch 356 in epoch 18, gen_loss = 1.4096603276682835, disc_loss = 0.00016907853430547264
Trained batch 357 in epoch 18, gen_loss = 1.409673252252227, disc_loss = 0.00016874495941518634
Trained batch 358 in epoch 18, gen_loss = 1.4094509092214047, disc_loss = 0.00016848152450027728
Trained batch 359 in epoch 18, gen_loss = 1.4094574057393603, disc_loss = 0.00016817617755198928
Trained batch 360 in epoch 18, gen_loss = 1.4092432802073513, disc_loss = 0.00016788445013076055
Trained batch 361 in epoch 18, gen_loss = 1.4090928168586605, disc_loss = 0.0001675785335052716
Trained batch 362 in epoch 18, gen_loss = 1.4091430340916657, disc_loss = 0.0001672943015229284
Trained batch 363 in epoch 18, gen_loss = 1.4088659162049766, disc_loss = 0.00016698000914342688
Trained batch 364 in epoch 18, gen_loss = 1.4087670267444767, disc_loss = 0.00016668887270896771
Trained batch 365 in epoch 18, gen_loss = 1.4086859779931158, disc_loss = 0.00016637916989884367
Trained batch 366 in epoch 18, gen_loss = 1.40861305326467, disc_loss = 0.00016609010906889717
Trained batch 367 in epoch 18, gen_loss = 1.40854230037202, disc_loss = 0.00016583341350625508
Trained batch 368 in epoch 18, gen_loss = 1.4085188432114557, disc_loss = 0.0001656264395297342
Trained batch 369 in epoch 18, gen_loss = 1.408412661101367, disc_loss = 0.00016529564748673915
Trained batch 370 in epoch 18, gen_loss = 1.4084102660819204, disc_loss = 0.00016507726232921317
Trained batch 371 in epoch 18, gen_loss = 1.4082800710713992, disc_loss = 0.00016490978583944173
Trained batch 372 in epoch 18, gen_loss = 1.408280230079835, disc_loss = 0.0001646680647483746
Trained batch 373 in epoch 18, gen_loss = 1.4083189141941581, disc_loss = 0.00016437147273864152
Trained batch 374 in epoch 18, gen_loss = 1.4082696164449056, disc_loss = 0.00016404597710546417
Trained batch 375 in epoch 18, gen_loss = 1.4083063177605892, disc_loss = 0.00016378386525251157
Trained batch 376 in epoch 18, gen_loss = 1.4084814888096615, disc_loss = 0.0001635662603697064
Trained batch 377 in epoch 18, gen_loss = 1.4084517302967252, disc_loss = 0.0001632957995579567
Trained batch 378 in epoch 18, gen_loss = 1.4084749184057392, disc_loss = 0.00016313165710650146
Trained batch 379 in epoch 18, gen_loss = 1.408735275895972, disc_loss = 0.00016341303439012814
Trained batch 380 in epoch 18, gen_loss = 1.4086058199249227, disc_loss = 0.00016333567338323117
Trained batch 381 in epoch 18, gen_loss = 1.408416294614682, disc_loss = 0.00016309441119962412
Trained batch 382 in epoch 18, gen_loss = 1.4084053447290126, disc_loss = 0.00016293976993055943
Trained batch 383 in epoch 18, gen_loss = 1.408362911393245, disc_loss = 0.00016275669383010913
Trained batch 384 in epoch 18, gen_loss = 1.4085084785114634, disc_loss = 0.00016252669652617029
Trained batch 385 in epoch 18, gen_loss = 1.4087829951177606, disc_loss = 0.00016242998270530535
Trained batch 386 in epoch 18, gen_loss = 1.408767165139664, disc_loss = 0.00016223033112709926
Trained batch 387 in epoch 18, gen_loss = 1.4086414769138258, disc_loss = 0.0001621070036655754
Trained batch 388 in epoch 18, gen_loss = 1.4084131236554418, disc_loss = 0.00016190607489886033
Trained batch 389 in epoch 18, gen_loss = 1.4081568531500988, disc_loss = 0.00016166100858521157
Trained batch 390 in epoch 18, gen_loss = 1.408317804946314, disc_loss = 0.00016141470560654842
Trained batch 391 in epoch 18, gen_loss = 1.408444158276733, disc_loss = 0.00016113514567798714
Trained batch 392 in epoch 18, gen_loss = 1.408444562941107, disc_loss = 0.00016087334208244057
Trained batch 393 in epoch 18, gen_loss = 1.408423338444705, disc_loss = 0.0001609112296229362
Trained batch 394 in epoch 18, gen_loss = 1.4082143246373044, disc_loss = 0.00016077424498470912
Trained batch 395 in epoch 18, gen_loss = 1.4081528219911787, disc_loss = 0.00016054250178480875
Trained batch 396 in epoch 18, gen_loss = 1.4080530549176695, disc_loss = 0.00016023570246519745
Trained batch 397 in epoch 18, gen_loss = 1.408255635194443, disc_loss = 0.00016005298587072104
Trained batch 398 in epoch 18, gen_loss = 1.4082937769423751, disc_loss = 0.00015976301819180315
Trained batch 399 in epoch 18, gen_loss = 1.4084363144636154, disc_loss = 0.00015957210335727724
Trained batch 400 in epoch 18, gen_loss = 1.4085197520077675, disc_loss = 0.0001593128157370379
Trained batch 401 in epoch 18, gen_loss = 1.4083661929291873, disc_loss = 0.00015905057632121657
Trained batch 402 in epoch 18, gen_loss = 1.408380319995265, disc_loss = 0.00015880429964003017
Trained batch 403 in epoch 18, gen_loss = 1.408138807752345, disc_loss = 0.00015855553009723645
Trained batch 404 in epoch 18, gen_loss = 1.4080664378625376, disc_loss = 0.00015834228889829836
Trained batch 405 in epoch 18, gen_loss = 1.4082312258006318, disc_loss = 0.00015813377691579643
Trained batch 406 in epoch 18, gen_loss = 1.4084347228746157, disc_loss = 0.0001580143004036005
Trained batch 407 in epoch 18, gen_loss = 1.4083943229679967, disc_loss = 0.0001577808468794626
Trained batch 408 in epoch 18, gen_loss = 1.4083104999257767, disc_loss = 0.000157549658032108
Trained batch 409 in epoch 18, gen_loss = 1.40838625111231, disc_loss = 0.0001574056968199396
Trained batch 410 in epoch 18, gen_loss = 1.4083294810459852, disc_loss = 0.00015729591863653612
Trained batch 411 in epoch 18, gen_loss = 1.408292094480644, disc_loss = 0.0001570237620169403
Trained batch 412 in epoch 18, gen_loss = 1.408250338517436, disc_loss = 0.00015680040274061754
Trained batch 413 in epoch 18, gen_loss = 1.4081308499050602, disc_loss = 0.00015658389004428224
Trained batch 414 in epoch 18, gen_loss = 1.4080760625471551, disc_loss = 0.00015634698280468526
Trained batch 415 in epoch 18, gen_loss = 1.408005791501357, disc_loss = 0.0001562473903067467
Trained batch 416 in epoch 18, gen_loss = 1.4078501019832328, disc_loss = 0.0001560396086772858
Trained batch 417 in epoch 18, gen_loss = 1.4078629478883515, disc_loss = 0.00015594182992859524
Trained batch 418 in epoch 18, gen_loss = 1.407754724520772, disc_loss = 0.00015570986319797588
Trained batch 419 in epoch 18, gen_loss = 1.4077568031492687, disc_loss = 0.0001554605797753625
Trained batch 420 in epoch 18, gen_loss = 1.407996412410872, disc_loss = 0.00015531231737291913
Trained batch 421 in epoch 18, gen_loss = 1.4080513018002443, disc_loss = 0.00015510537220088995
Trained batch 422 in epoch 18, gen_loss = 1.408082892426926, disc_loss = 0.00015495747258863576
Trained batch 423 in epoch 18, gen_loss = 1.4080272173544146, disc_loss = 0.00015473202553416827
Trained batch 424 in epoch 18, gen_loss = 1.4079239421732286, disc_loss = 0.00015447193070191562
Trained batch 425 in epoch 18, gen_loss = 1.4079576154270081, disc_loss = 0.0001542251243699012
Trained batch 426 in epoch 18, gen_loss = 1.4079107160590572, disc_loss = 0.00015398754425217622
Trained batch 427 in epoch 18, gen_loss = 1.4077585662636802, disc_loss = 0.0001537518199545736
Trained batch 428 in epoch 18, gen_loss = 1.4076887755405096, disc_loss = 0.00015350753884082216
Trained batch 429 in epoch 18, gen_loss = 1.407687583080558, disc_loss = 0.00015326575486924836
Trained batch 430 in epoch 18, gen_loss = 1.4075633992728391, disc_loss = 0.0001530171523981197
Trained batch 431 in epoch 18, gen_loss = 1.4074904355737898, disc_loss = 0.00015279901765973558
Trained batch 432 in epoch 18, gen_loss = 1.4073671606341356, disc_loss = 0.00015255907336309097
Trained batch 433 in epoch 18, gen_loss = 1.4073457212492069, disc_loss = 0.00015230790353606806
Trained batch 434 in epoch 18, gen_loss = 1.4072922109187334, disc_loss = 0.00015206137883989407
Trained batch 435 in epoch 18, gen_loss = 1.4073463929902523, disc_loss = 0.00015186463698319965
Trained batch 436 in epoch 18, gen_loss = 1.4072332395841656, disc_loss = 0.0001516007836746266
Trained batch 437 in epoch 18, gen_loss = 1.4071904282047325, disc_loss = 0.00015134314390835744
Trained batch 438 in epoch 18, gen_loss = 1.4071806549754393, disc_loss = 0.00015107483557415626
Trained batch 439 in epoch 18, gen_loss = 1.4071402525359935, disc_loss = 0.0001508460336729265
Trained batch 440 in epoch 18, gen_loss = 1.4069952159241483, disc_loss = 0.00015060485567446944
Trained batch 441 in epoch 18, gen_loss = 1.4070341889135438, disc_loss = 0.00015036320087861543
Trained batch 442 in epoch 18, gen_loss = 1.4071133976327108, disc_loss = 0.0001502460194137352
Trained batch 443 in epoch 18, gen_loss = 1.4070111475549303, disc_loss = 0.00015008307143140988
Trained batch 444 in epoch 18, gen_loss = 1.4069526372330912, disc_loss = 0.00014988208094610455
Trained batch 445 in epoch 18, gen_loss = 1.406789836060306, disc_loss = 0.00014964916148438846
Trained batch 446 in epoch 18, gen_loss = 1.406788865458512, disc_loss = 0.0001494850332950168
Trained batch 447 in epoch 18, gen_loss = 1.4068103642868144, disc_loss = 0.0001492383793544962
Trained batch 448 in epoch 18, gen_loss = 1.4068315939807678, disc_loss = 0.0001490337029125392
Trained batch 449 in epoch 18, gen_loss = 1.4067856979370117, disc_loss = 0.0001488041658901946
Trained batch 450 in epoch 18, gen_loss = 1.4068855649880454, disc_loss = 0.00014857940018847389
Trained batch 451 in epoch 18, gen_loss = 1.4068166178412143, disc_loss = 0.00014836529748514553
Trained batch 452 in epoch 18, gen_loss = 1.4069110178789557, disc_loss = 0.0001482626398070998
Trained batch 453 in epoch 18, gen_loss = 1.4069105998534988, disc_loss = 0.00014812254460790298
Trained batch 454 in epoch 18, gen_loss = 1.4069053723261906, disc_loss = 0.0001479221252688708
Trained batch 455 in epoch 18, gen_loss = 1.4067734566174055, disc_loss = 0.00014773478537870432
Trained batch 456 in epoch 18, gen_loss = 1.406874010025542, disc_loss = 0.00014753507334508176
Trained batch 457 in epoch 18, gen_loss = 1.4068016253704587, disc_loss = 0.00014730606816989151
Trained batch 458 in epoch 18, gen_loss = 1.4068406804714328, disc_loss = 0.00014708409703803079
Trained batch 459 in epoch 18, gen_loss = 1.4068085408729056, disc_loss = 0.00014687507798004409
Trained batch 460 in epoch 18, gen_loss = 1.406700632577346, disc_loss = 0.00014665515680269362
Trained batch 461 in epoch 18, gen_loss = 1.4065268888618008, disc_loss = 0.00014643863422156853
Trained batch 462 in epoch 18, gen_loss = 1.406463870734427, disc_loss = 0.00014623990720702429
Trained batch 463 in epoch 18, gen_loss = 1.4064752053597878, disc_loss = 0.00014610513237349896
Trained batch 464 in epoch 18, gen_loss = 1.406498881052899, disc_loss = 0.00014590434403808397
Trained batch 465 in epoch 18, gen_loss = 1.406394314356628, disc_loss = 0.0001457014160758247
Trained batch 466 in epoch 18, gen_loss = 1.4063108661700623, disc_loss = 0.00014549996570029149
Trained batch 467 in epoch 18, gen_loss = 1.4063627284306746, disc_loss = 0.00014529069183979125
Trained batch 468 in epoch 18, gen_loss = 1.406276919948521, disc_loss = 0.000145085327864214
Trained batch 469 in epoch 18, gen_loss = 1.4062751105491151, disc_loss = 0.0001449522191483374
Trained batch 470 in epoch 18, gen_loss = 1.4062478754930436, disc_loss = 0.0001447495708868996
Trained batch 471 in epoch 18, gen_loss = 1.4063521876173504, disc_loss = 0.00014458762341561495
Trained batch 472 in epoch 18, gen_loss = 1.4063395765820719, disc_loss = 0.00014437586315843546
Trained batch 473 in epoch 18, gen_loss = 1.4063420066853616, disc_loss = 0.00014424207835224406
Trained batch 474 in epoch 18, gen_loss = 1.4063669159537868, disc_loss = 0.00014409902992682826
Trained batch 475 in epoch 18, gen_loss = 1.4063220384742032, disc_loss = 0.0001439141249861945
Trained batch 476 in epoch 18, gen_loss = 1.4063542718907323, disc_loss = 0.0001437314042938796
Trained batch 477 in epoch 18, gen_loss = 1.4062810547681035, disc_loss = 0.00014354992925740337
Trained batch 478 in epoch 18, gen_loss = 1.4062166495213677, disc_loss = 0.0001433340401866518
Trained batch 479 in epoch 18, gen_loss = 1.4062350528935592, disc_loss = 0.00014315805353059356
Trained batch 480 in epoch 18, gen_loss = 1.40622263861793, disc_loss = 0.00014294556470884575
Trained batch 481 in epoch 18, gen_loss = 1.406283737960198, disc_loss = 0.00014285472303730845
Trained batch 482 in epoch 18, gen_loss = 1.406354468061317, disc_loss = 0.0001427113462759396
Trained batch 483 in epoch 18, gen_loss = 1.4062976691841094, disc_loss = 0.00014257761289597457
Trained batch 484 in epoch 18, gen_loss = 1.4062479267415313, disc_loss = 0.0001424187800028486
Trained batch 485 in epoch 18, gen_loss = 1.4062591965306444, disc_loss = 0.00014223130921232695
Trained batch 486 in epoch 18, gen_loss = 1.4062463828425633, disc_loss = 0.00014203774002008953
Trained batch 487 in epoch 18, gen_loss = 1.4064062665231893, disc_loss = 0.00014184432960019712
Trained batch 488 in epoch 18, gen_loss = 1.406460364903409, disc_loss = 0.0001416397822819291
Trained batch 489 in epoch 18, gen_loss = 1.4064422103823448, disc_loss = 0.0001414402845159425
Trained batch 490 in epoch 18, gen_loss = 1.406323622540398, disc_loss = 0.00014125578424761966
Trained batch 491 in epoch 18, gen_loss = 1.4064191805153359, disc_loss = 0.00014112780869860822
Trained batch 492 in epoch 18, gen_loss = 1.406347205866181, disc_loss = 0.00014098236454427847
Trained batch 493 in epoch 18, gen_loss = 1.4062655013099856, disc_loss = 0.0001409132322444965
Trained batch 494 in epoch 18, gen_loss = 1.406340558841975, disc_loss = 0.00014076802913085416
Trained batch 495 in epoch 18, gen_loss = 1.4062663242220879, disc_loss = 0.0001406061854932857
Trained batch 496 in epoch 18, gen_loss = 1.406247288168556, disc_loss = 0.00014040557792138774
Trained batch 497 in epoch 18, gen_loss = 1.4061456418420417, disc_loss = 0.00014022819663931654
Trained batch 498 in epoch 18, gen_loss = 1.405938934228702, disc_loss = 0.00014005548955774903
Trained batch 499 in epoch 18, gen_loss = 1.4057509911060333, disc_loss = 0.00013986915411078372
Trained batch 500 in epoch 18, gen_loss = 1.4056390849892013, disc_loss = 0.00013965760751421974
Trained batch 501 in epoch 18, gen_loss = 1.4056282128945765, disc_loss = 0.0001394926358512473
Trained batch 502 in epoch 18, gen_loss = 1.4056483670684026, disc_loss = 0.00013930370304321549
Trained batch 503 in epoch 18, gen_loss = 1.4055522306570931, disc_loss = 0.00013910488596882223
Trained batch 504 in epoch 18, gen_loss = 1.405524510676318, disc_loss = 0.00013892349806074792
Trained batch 505 in epoch 18, gen_loss = 1.405382431778512, disc_loss = 0.0001387632372980043
Trained batch 506 in epoch 18, gen_loss = 1.4051669577404828, disc_loss = 0.0001386359082964291
Trained batch 507 in epoch 18, gen_loss = 1.4049960203527465, disc_loss = 0.00013853383677810848
Trained batch 508 in epoch 18, gen_loss = 1.404898456365514, disc_loss = 0.00013836929982291143
Trained batch 509 in epoch 18, gen_loss = 1.4048552071346956, disc_loss = 0.00013820230357369464
Trained batch 510 in epoch 18, gen_loss = 1.4047259176313993, disc_loss = 0.0001380298186692504
Trained batch 511 in epoch 18, gen_loss = 1.4047318517696112, disc_loss = 0.00013784164539032417
Trained batch 512 in epoch 18, gen_loss = 1.4047532302361947, disc_loss = 0.00013766790571327313
Trained batch 513 in epoch 18, gen_loss = 1.4046468917961714, disc_loss = 0.00013747276642849237
Trained batch 514 in epoch 18, gen_loss = 1.4046981864762538, disc_loss = 0.00013729146473619462
Trained batch 515 in epoch 18, gen_loss = 1.4045678712138834, disc_loss = 0.00013708563401169086
Trained batch 516 in epoch 18, gen_loss = 1.4045053990251553, disc_loss = 0.0001369457790435889
Trained batch 517 in epoch 18, gen_loss = 1.4044877548475523, disc_loss = 0.00013676349220825062
Trained batch 518 in epoch 18, gen_loss = 1.4045239845452282, disc_loss = 0.00013660172966645576
Trained batch 519 in epoch 18, gen_loss = 1.4044046356127813, disc_loss = 0.000136409486577367
Trained batch 520 in epoch 18, gen_loss = 1.40449984952264, disc_loss = 0.00013626385832651413
Trained batch 521 in epoch 18, gen_loss = 1.4043902517278533, disc_loss = 0.000136062375629335
Trained batch 522 in epoch 18, gen_loss = 1.40440235561896, disc_loss = 0.0001358708341320599
Trained batch 523 in epoch 18, gen_loss = 1.4042499272422937, disc_loss = 0.00013568605749839197
Trained batch 524 in epoch 18, gen_loss = 1.4041201634634108, disc_loss = 0.00013548117528400672
Trained batch 525 in epoch 18, gen_loss = 1.4039944750274542, disc_loss = 0.00013528164852500302
Trained batch 526 in epoch 18, gen_loss = 1.4039216661362766, disc_loss = 0.00013508447435781369
Trained batch 527 in epoch 18, gen_loss = 1.4038024752429037, disc_loss = 0.00013488844992039185
Trained batch 528 in epoch 18, gen_loss = 1.4038868971267584, disc_loss = 0.00013480308133812682
Trained batch 529 in epoch 18, gen_loss = 1.4038294097162642, disc_loss = 0.00013467475861755204
Trained batch 530 in epoch 18, gen_loss = 1.4038883050282795, disc_loss = 0.00013457273690908793
Trained batch 531 in epoch 18, gen_loss = 1.403807926895027, disc_loss = 0.0001344764737451558
Trained batch 532 in epoch 18, gen_loss = 1.4038909660271364, disc_loss = 0.00013440503263508041
Trained batch 533 in epoch 18, gen_loss = 1.40394488099809, disc_loss = 0.0001342583508007562
Trained batch 534 in epoch 18, gen_loss = 1.4038767496002054, disc_loss = 0.0001341746972361634
Trained batch 535 in epoch 18, gen_loss = 1.4039598120682275, disc_loss = 0.00013403104202579789
Trained batch 536 in epoch 18, gen_loss = 1.4038718053082515, disc_loss = 0.00013387951786244297
Trained batch 537 in epoch 18, gen_loss = 1.403891839059312, disc_loss = 0.0001337054130979318
Trained batch 538 in epoch 18, gen_loss = 1.4039203443863397, disc_loss = 0.0001335405212488634
Trained batch 539 in epoch 18, gen_loss = 1.4040581425031027, disc_loss = 0.00013339803512011443
Trained batch 540 in epoch 18, gen_loss = 1.4040453438397476, disc_loss = 0.00013323523807887556
Trained batch 541 in epoch 18, gen_loss = 1.403916018035579, disc_loss = 0.00013305251877849972
Trained batch 542 in epoch 18, gen_loss = 1.4039280476052018, disc_loss = 0.00013291714201047464
Trained batch 543 in epoch 18, gen_loss = 1.4038679794791866, disc_loss = 0.00013275105372071374
Trained batch 544 in epoch 18, gen_loss = 1.4039463423807688, disc_loss = 0.00013262583275601683
Trained batch 545 in epoch 18, gen_loss = 1.4037801123364069, disc_loss = 0.00013246203918122895
Trained batch 546 in epoch 18, gen_loss = 1.4037820626002562, disc_loss = 0.00013229102074992574
Trained batch 547 in epoch 18, gen_loss = 1.403740259200117, disc_loss = 0.00013210885840203945
Trained batch 548 in epoch 18, gen_loss = 1.4036484563719813, disc_loss = 0.00013191979929990028
Trained batch 549 in epoch 18, gen_loss = 1.4036640704761851, disc_loss = 0.00013175138979766582
Trained batch 550 in epoch 18, gen_loss = 1.4037021681963857, disc_loss = 0.00013159069515507058
Trained batch 551 in epoch 18, gen_loss = 1.403614538087361, disc_loss = 0.0001314174260022665
Trained batch 552 in epoch 18, gen_loss = 1.403596731034153, disc_loss = 0.00013125844382197083
Trained batch 553 in epoch 18, gen_loss = 1.4036132002565405, disc_loss = 0.0001310993582900983
Trained batch 554 in epoch 18, gen_loss = 1.4037355667835958, disc_loss = 0.0001309447072852489
Trained batch 555 in epoch 18, gen_loss = 1.4036701394499635, disc_loss = 0.00013079472907631773
Trained batch 556 in epoch 18, gen_loss = 1.4037007919547801, disc_loss = 0.00013064570032363516
Trained batch 557 in epoch 18, gen_loss = 1.403584289508054, disc_loss = 0.00013055038101074355
Trained batch 558 in epoch 18, gen_loss = 1.4035741316824353, disc_loss = 0.00013043424574506144
Trained batch 559 in epoch 18, gen_loss = 1.4034628331661225, disc_loss = 0.00013025625676488874
Trained batch 560 in epoch 18, gen_loss = 1.4034457032480767, disc_loss = 0.00013010325532630373
Trained batch 561 in epoch 18, gen_loss = 1.4035005476126892, disc_loss = 0.00012995239341043966
Trained batch 562 in epoch 18, gen_loss = 1.403559051229094, disc_loss = 0.0001300345670037064
Trained batch 563 in epoch 18, gen_loss = 1.403535767015836, disc_loss = 0.00012995358697835463
Trained batch 564 in epoch 18, gen_loss = 1.403566963482747, disc_loss = 0.00012984285979421986
Trained batch 565 in epoch 18, gen_loss = 1.4035418025175168, disc_loss = 0.00012967395259339635
Trained batch 566 in epoch 18, gen_loss = 1.4035936459452176, disc_loss = 0.00012955117365311995
Trained batch 567 in epoch 18, gen_loss = 1.4035755179717506, disc_loss = 0.00012942672225095444
Trained batch 568 in epoch 18, gen_loss = 1.403646357449161, disc_loss = 0.00012929437647877783
Trained batch 569 in epoch 18, gen_loss = 1.4035419721352427, disc_loss = 0.0001291373179539509
Trained batch 570 in epoch 18, gen_loss = 1.4035793741196132, disc_loss = 0.00012901790642420432
Trained batch 571 in epoch 18, gen_loss = 1.4035746928278383, disc_loss = 0.0001288506509013927
Trained batch 572 in epoch 18, gen_loss = 1.4035763859124708, disc_loss = 0.00012872538654703868
Trained batch 573 in epoch 18, gen_loss = 1.4034979366259293, disc_loss = 0.00012857947423429986
Trained batch 574 in epoch 18, gen_loss = 1.4034122605945754, disc_loss = 0.000128485350594375
Trained batch 575 in epoch 18, gen_loss = 1.403461878084474, disc_loss = 0.0001284681870256716
Trained batch 576 in epoch 18, gen_loss = 1.4034911668899774, disc_loss = 0.00012834229777427167
Trained batch 577 in epoch 18, gen_loss = 1.403517905403586, disc_loss = 0.00012819870621459716
Trained batch 578 in epoch 18, gen_loss = 1.403590583636559, disc_loss = 0.00012822361336294654
Trained batch 579 in epoch 18, gen_loss = 1.4035957585121024, disc_loss = 0.00012817145274750835
Trained batch 580 in epoch 18, gen_loss = 1.4037425903773348, disc_loss = 0.00012807598790907153
Trained batch 581 in epoch 18, gen_loss = 1.403751659434276, disc_loss = 0.00012795405714579916
Trained batch 582 in epoch 18, gen_loss = 1.4038326460133286, disc_loss = 0.00012781131165961261
Trained batch 583 in epoch 18, gen_loss = 1.4037702930708453, disc_loss = 0.00012764102125838192
Trained batch 584 in epoch 18, gen_loss = 1.4038486808793158, disc_loss = 0.00012751840144912234
Trained batch 585 in epoch 18, gen_loss = 1.4037957671559305, disc_loss = 0.00012736338600323618
Trained batch 586 in epoch 18, gen_loss = 1.403791187162903, disc_loss = 0.00012720659999981057
Trained batch 587 in epoch 18, gen_loss = 1.4037622428264747, disc_loss = 0.00012704583687515143
Trained batch 588 in epoch 18, gen_loss = 1.4037549260921511, disc_loss = 0.0001268864450181209
Trained batch 589 in epoch 18, gen_loss = 1.4037473551297592, disc_loss = 0.00012672551864066547
Trained batch 590 in epoch 18, gen_loss = 1.4036504691829133, disc_loss = 0.0001265689028939055
Trained batch 591 in epoch 18, gen_loss = 1.403747004028913, disc_loss = 0.00012646823158222006
Trained batch 592 in epoch 18, gen_loss = 1.4037866684879863, disc_loss = 0.00012633267929684254
Trained batch 593 in epoch 18, gen_loss = 1.403766433397929, disc_loss = 0.00012618427621670066
Trained batch 594 in epoch 18, gen_loss = 1.40371294542521, disc_loss = 0.0001260362585694451
Trained batch 595 in epoch 18, gen_loss = 1.4036872560945934, disc_loss = 0.00012586592733987954
Trained batch 596 in epoch 18, gen_loss = 1.4037334102282373, disc_loss = 0.0001257649477448106
Trained batch 597 in epoch 18, gen_loss = 1.40382772405012, disc_loss = 0.0001256657255375754
Trained batch 598 in epoch 18, gen_loss = 1.4039227922691129, disc_loss = 0.0001255441748739538
Trained batch 599 in epoch 18, gen_loss = 1.4040176222721736, disc_loss = 0.0001255278306234686
Trained batch 600 in epoch 18, gen_loss = 1.4039875493073424, disc_loss = 0.0001254180453615724
Trained batch 601 in epoch 18, gen_loss = 1.4040073342497563, disc_loss = 0.00012534357002638304
Trained batch 602 in epoch 18, gen_loss = 1.4039646094513571, disc_loss = 0.00012520201404973407
Trained batch 603 in epoch 18, gen_loss = 1.4039142256146235, disc_loss = 0.00012507406123609294
Trained batch 604 in epoch 18, gen_loss = 1.4039703790806541, disc_loss = 0.00012501780285734744
Trained batch 605 in epoch 18, gen_loss = 1.403842011300644, disc_loss = 0.00012492992470587263
Trained batch 606 in epoch 18, gen_loss = 1.4037433185137478, disc_loss = 0.00012479507993948738
Trained batch 607 in epoch 18, gen_loss = 1.4038220006776483, disc_loss = 0.00012465738477299295
Trained batch 608 in epoch 18, gen_loss = 1.4037033433005923, disc_loss = 0.00012453652887681784
Trained batch 609 in epoch 18, gen_loss = 1.4036935778914905, disc_loss = 0.00012441299996814942
Trained batch 610 in epoch 18, gen_loss = 1.4036579253045314, disc_loss = 0.0001242820271161753
Trained batch 611 in epoch 18, gen_loss = 1.4037302465610255, disc_loss = 0.0001241263754618439
Trained batch 612 in epoch 18, gen_loss = 1.4037573961799334, disc_loss = 0.00012397816874361564
Trained batch 613 in epoch 18, gen_loss = 1.403629665071879, disc_loss = 0.00012385584180973184
Trained batch 614 in epoch 18, gen_loss = 1.4035723515642369, disc_loss = 0.00012372714283436488
Trained batch 615 in epoch 18, gen_loss = 1.403586255652564, disc_loss = 0.00012359909253548238
Trained batch 616 in epoch 18, gen_loss = 1.4036870713751746, disc_loss = 0.00012346495796997168
Trained batch 617 in epoch 18, gen_loss = 1.403678657746238, disc_loss = 0.00012333875751987188
Trained batch 618 in epoch 18, gen_loss = 1.403651503060669, disc_loss = 0.00012319538078146445
Trained batch 619 in epoch 18, gen_loss = 1.403789064768822, disc_loss = 0.00012308352525876892
Trained batch 620 in epoch 18, gen_loss = 1.4038532058589892, disc_loss = 0.00012294113322283646
Trained batch 621 in epoch 18, gen_loss = 1.4038002738232014, disc_loss = 0.00012278834955398648
Trained batch 622 in epoch 18, gen_loss = 1.4037945982349818, disc_loss = 0.00012264017376900735
Trained batch 623 in epoch 18, gen_loss = 1.403752829401921, disc_loss = 0.0001225184914335095
Trained batch 624 in epoch 18, gen_loss = 1.4038461376190186, disc_loss = 0.0001225170874968171
Trained batch 625 in epoch 18, gen_loss = 1.403796543328526, disc_loss = 0.00012253176172847112
Trained batch 626 in epoch 18, gen_loss = 1.4038875817872312, disc_loss = 0.00012249693459611343
Trained batch 627 in epoch 18, gen_loss = 1.4038623036093014, disc_loss = 0.0001223852740778943
Trained batch 628 in epoch 18, gen_loss = 1.4039525422837662, disc_loss = 0.00012227989725145032
Trained batch 629 in epoch 18, gen_loss = 1.4039012038518512, disc_loss = 0.0001222087837150967
Trained batch 630 in epoch 18, gen_loss = 1.4039260980255441, disc_loss = 0.00012209543906256117
Trained batch 631 in epoch 18, gen_loss = 1.404017421452305, disc_loss = 0.00012203490774205605
Trained batch 632 in epoch 18, gen_loss = 1.4041008081104707, disc_loss = 0.00012191009668346073
Trained batch 633 in epoch 18, gen_loss = 1.4040230390401294, disc_loss = 0.00012178975458118083
Trained batch 634 in epoch 18, gen_loss = 1.4039511949058592, disc_loss = 0.0001216725205776179
Trained batch 635 in epoch 18, gen_loss = 1.4038525547996257, disc_loss = 0.00012153026671272391
Trained batch 636 in epoch 18, gen_loss = 1.4038705457136433, disc_loss = 0.00012147243494957246
Trained batch 637 in epoch 18, gen_loss = 1.4039286092904668, disc_loss = 0.0001213948833075995
Trained batch 638 in epoch 18, gen_loss = 1.4038852111834315, disc_loss = 0.00012125159122495885
Trained batch 639 in epoch 18, gen_loss = 1.4040099887177349, disc_loss = 0.00012113378709557309
Trained batch 640 in epoch 18, gen_loss = 1.4039889523837943, disc_loss = 0.00012099368927033502
Trained batch 641 in epoch 18, gen_loss = 1.4039830741852615, disc_loss = 0.00012085603381856798
Trained batch 642 in epoch 18, gen_loss = 1.4039762442812764, disc_loss = 0.0001207262193703324
Trained batch 643 in epoch 18, gen_loss = 1.4038479502156656, disc_loss = 0.00012059217122565902
Trained batch 644 in epoch 18, gen_loss = 1.403941665693771, disc_loss = 0.00012056547368625306
Trained batch 645 in epoch 18, gen_loss = 1.404071034108153, disc_loss = 0.0001205530882208749
Trained batch 646 in epoch 18, gen_loss = 1.4040100502636186, disc_loss = 0.00012046937070076856
Trained batch 647 in epoch 18, gen_loss = 1.4039103420060357, disc_loss = 0.00012038355142931885
Trained batch 648 in epoch 18, gen_loss = 1.4038968874236284, disc_loss = 0.00012029061779402357
Trained batch 649 in epoch 18, gen_loss = 1.4038648616350613, disc_loss = 0.00012016530253066985
Trained batch 650 in epoch 18, gen_loss = 1.4039217301411198, disc_loss = 0.00012006369133018256
Trained batch 651 in epoch 18, gen_loss = 1.4039102928038756, disc_loss = 0.00011997238861799452
Trained batch 652 in epoch 18, gen_loss = 1.4039003082292916, disc_loss = 0.0001198576986392367
Trained batch 653 in epoch 18, gen_loss = 1.4040510359160396, disc_loss = 0.00011983752447066615
Trained batch 654 in epoch 18, gen_loss = 1.404065100109304, disc_loss = 0.00011973836532701073
Trained batch 655 in epoch 18, gen_loss = 1.403982278777332, disc_loss = 0.00011962631293865742
Trained batch 656 in epoch 18, gen_loss = 1.4040086436307957, disc_loss = 0.00011949924418895064
Trained batch 657 in epoch 18, gen_loss = 1.4041214768285084, disc_loss = 0.00011938309428408316
Trained batch 658 in epoch 18, gen_loss = 1.4040944896446192, disc_loss = 0.00011924283259313473
Trained batch 659 in epoch 18, gen_loss = 1.4040372906309186, disc_loss = 0.00011911161320974564
Trained batch 660 in epoch 18, gen_loss = 1.403977535676307, disc_loss = 0.00011899166481096351
Trained batch 661 in epoch 18, gen_loss = 1.403858877380809, disc_loss = 0.0001188717316638283
Trained batch 662 in epoch 18, gen_loss = 1.4038701176103963, disc_loss = 0.00011874714357709775
Trained batch 663 in epoch 18, gen_loss = 1.4037878104003079, disc_loss = 0.00011861272023123596
Trained batch 664 in epoch 18, gen_loss = 1.4037875422857757, disc_loss = 0.00011849027575401561
Trained batch 665 in epoch 18, gen_loss = 1.4036632643805609, disc_loss = 0.00011835846103727468
Trained batch 666 in epoch 18, gen_loss = 1.4036562385587679, disc_loss = 0.0001182274282073031
Trained batch 667 in epoch 18, gen_loss = 1.4036052785590738, disc_loss = 0.00011808715948074656
Trained batch 668 in epoch 18, gen_loss = 1.4036003671954032, disc_loss = 0.00011795187958983234
Trained batch 669 in epoch 18, gen_loss = 1.4037279159275453, disc_loss = 0.00011785822058680342
Trained batch 670 in epoch 18, gen_loss = 1.4036887875257058, disc_loss = 0.00011781537064534006
Trained batch 671 in epoch 18, gen_loss = 1.4036414236539887, disc_loss = 0.00011771655902391233
Trained batch 672 in epoch 18, gen_loss = 1.4035627353067384, disc_loss = 0.00011759176364029795
Trained batch 673 in epoch 18, gen_loss = 1.403602817999503, disc_loss = 0.00011748384915837895
Trained batch 674 in epoch 18, gen_loss = 1.4034714698791504, disc_loss = 0.00011736575885421459
Trained batch 675 in epoch 18, gen_loss = 1.4034298429122338, disc_loss = 0.00011725374654616703
Trained batch 676 in epoch 18, gen_loss = 1.4033512829677746, disc_loss = 0.00011712929876363888
Trained batch 677 in epoch 18, gen_loss = 1.4033522451170075, disc_loss = 0.00011701016953384303
Trained batch 678 in epoch 18, gen_loss = 1.4033988766887928, disc_loss = 0.0001169217036432564
Trained batch 679 in epoch 18, gen_loss = 1.403409293995184, disc_loss = 0.00011681120525763083
Trained batch 680 in epoch 18, gen_loss = 1.4034367397143102, disc_loss = 0.0001166926464525331
Trained batch 681 in epoch 18, gen_loss = 1.4033606400238103, disc_loss = 0.0001165504216825594
Trained batch 682 in epoch 18, gen_loss = 1.4033763239359263, disc_loss = 0.00011644162984937242
Trained batch 683 in epoch 18, gen_loss = 1.4034178743236942, disc_loss = 0.00011631994215221902
Trained batch 684 in epoch 18, gen_loss = 1.4033551701664055, disc_loss = 0.00011619496733949937
Trained batch 685 in epoch 18, gen_loss = 1.4033783707257264, disc_loss = 0.00011607200933859867
Trained batch 686 in epoch 18, gen_loss = 1.4033397122068003, disc_loss = 0.0001159495714462145
Trained batch 687 in epoch 18, gen_loss = 1.40331127390612, disc_loss = 0.00011586730174131358
Trained batch 688 in epoch 18, gen_loss = 1.4033863570416787, disc_loss = 0.0001157586313311238
Trained batch 689 in epoch 18, gen_loss = 1.403371236462524, disc_loss = 0.00011563524469133024
Trained batch 690 in epoch 18, gen_loss = 1.4032427486565973, disc_loss = 0.00011554732918476079
Trained batch 691 in epoch 18, gen_loss = 1.403348261049028, disc_loss = 0.00011549795100355983
Trained batch 692 in epoch 18, gen_loss = 1.4033326719058368, disc_loss = 0.00011539736107313212
Trained batch 693 in epoch 18, gen_loss = 1.403322622652356, disc_loss = 0.00011528355086348352
Trained batch 694 in epoch 18, gen_loss = 1.4031679530795529, disc_loss = 0.00011523849766719467
Trained batch 695 in epoch 18, gen_loss = 1.403136213449226, disc_loss = 0.00011516686525272694
Trained batch 696 in epoch 18, gen_loss = 1.4033215947267486, disc_loss = 0.00011508234334017509
Trained batch 697 in epoch 18, gen_loss = 1.4032768723274711, disc_loss = 0.00011498759075059681
Trained batch 698 in epoch 18, gen_loss = 1.4032733240864308, disc_loss = 0.00011489701073944255
Trained batch 699 in epoch 18, gen_loss = 1.4032815338884082, disc_loss = 0.00011479678537008502
Trained batch 700 in epoch 18, gen_loss = 1.403287680955144, disc_loss = 0.00011468327346108983
Trained batch 701 in epoch 18, gen_loss = 1.4032811069080973, disc_loss = 0.00011456031644097221
Trained batch 702 in epoch 18, gen_loss = 1.4033264130311534, disc_loss = 0.00011444546728712294
Trained batch 703 in epoch 18, gen_loss = 1.4032067497345535, disc_loss = 0.0001143229449744674
Trained batch 704 in epoch 18, gen_loss = 1.4032819313360445, disc_loss = 0.0001142084982696341
Trained batch 705 in epoch 18, gen_loss = 1.403249734690777, disc_loss = 0.00011408068665991971
Trained batch 706 in epoch 18, gen_loss = 1.403262143256472, disc_loss = 0.00011396121162619614
Trained batch 707 in epoch 18, gen_loss = 1.4032725806290147, disc_loss = 0.00011383836093400378
Trained batch 708 in epoch 18, gen_loss = 1.4032584615419545, disc_loss = 0.00011372103758301368
Trained batch 709 in epoch 18, gen_loss = 1.4031538996897952, disc_loss = 0.00011359686109052502
Trained batch 710 in epoch 18, gen_loss = 1.4031219237632053, disc_loss = 0.0001134792314133577
Trained batch 711 in epoch 18, gen_loss = 1.4031643748618243, disc_loss = 0.00011354047978273413
Trained batch 712 in epoch 18, gen_loss = 1.4031171643215676, disc_loss = 0.00011348391352154835
Trained batch 713 in epoch 18, gen_loss = 1.4031369540871692, disc_loss = 0.00011341022262986014
Trained batch 714 in epoch 18, gen_loss = 1.4031771184681179, disc_loss = 0.00011331227527277208
Trained batch 715 in epoch 18, gen_loss = 1.403191901618542, disc_loss = 0.0001131984681324871
Trained batch 716 in epoch 18, gen_loss = 1.4031570453191569, disc_loss = 0.00011309116133545948
Trained batch 717 in epoch 18, gen_loss = 1.4032339920240524, disc_loss = 0.00011301306038194652
Trained batch 718 in epoch 18, gen_loss = 1.4031951032858732, disc_loss = 0.00011293694281730634
Trained batch 719 in epoch 18, gen_loss = 1.4031353188885582, disc_loss = 0.00011282452955785831
Trained batch 720 in epoch 18, gen_loss = 1.4031342056356422, disc_loss = 0.00011272365171283477
Trained batch 721 in epoch 18, gen_loss = 1.4031019526175184, disc_loss = 0.0001126325416301967
Trained batch 722 in epoch 18, gen_loss = 1.4030778063448304, disc_loss = 0.00011251162740013148
Trained batch 723 in epoch 18, gen_loss = 1.4029736448058765, disc_loss = 0.00011239600303898085
Trained batch 724 in epoch 18, gen_loss = 1.4029347497019276, disc_loss = 0.00011227462931730832
Trained batch 725 in epoch 18, gen_loss = 1.402925154886955, disc_loss = 0.00011215357892931622
Trained batch 726 in epoch 18, gen_loss = 1.4029342641200784, disc_loss = 0.00011204755201844413
Trained batch 727 in epoch 18, gen_loss = 1.4029103394720581, disc_loss = 0.0001119339546581254
Trained batch 728 in epoch 18, gen_loss = 1.4029848891194139, disc_loss = 0.00011184253882215853
Trained batch 729 in epoch 18, gen_loss = 1.403002219494075, disc_loss = 0.0001117488872009682
Trained batch 730 in epoch 18, gen_loss = 1.40291264918206, disc_loss = 0.00011163430329183373
Trained batch 731 in epoch 18, gen_loss = 1.402838673910808, disc_loss = 0.00011152026655891645
Trained batch 732 in epoch 18, gen_loss = 1.4029129629733619, disc_loss = 0.00011141233383507963
Trained batch 733 in epoch 18, gen_loss = 1.4027803686399225, disc_loss = 0.0001112954469259639
Trained batch 734 in epoch 18, gen_loss = 1.4027165130693084, disc_loss = 0.0001111830431439551
Trained batch 735 in epoch 18, gen_loss = 1.4027323515518852, disc_loss = 0.00011109091022252987
Trained batch 736 in epoch 18, gen_loss = 1.4027241015531315, disc_loss = 0.00011101433131713885
Trained batch 737 in epoch 18, gen_loss = 1.402705367180067, disc_loss = 0.00011090028686790843
Trained batch 738 in epoch 18, gen_loss = 1.4028054567731927, disc_loss = 0.00011081141784540406
Trained batch 739 in epoch 18, gen_loss = 1.4028769446385874, disc_loss = 0.00011073079155992034
Trained batch 740 in epoch 18, gen_loss = 1.4028668635287265, disc_loss = 0.00011062694861555259
Trained batch 741 in epoch 18, gen_loss = 1.402801621153027, disc_loss = 0.00011051198465072546
Trained batch 742 in epoch 18, gen_loss = 1.4028072017038173, disc_loss = 0.00011039688360856104
Trained batch 743 in epoch 18, gen_loss = 1.4028078344880894, disc_loss = 0.00011027517029526613
Trained batch 744 in epoch 18, gen_loss = 1.4027953909547537, disc_loss = 0.00011018032760667183
Trained batch 745 in epoch 18, gen_loss = 1.4028722140488612, disc_loss = 0.00011009987455467512
Testing Epoch 18
Training Epoch 19
Trained batch 0 in epoch 19, gen_loss = 1.4086384773254395, disc_loss = 4.4705775508191437e-05
Trained batch 1 in epoch 19, gen_loss = 1.3848252892494202, disc_loss = 3.7421617889776826e-05
Trained batch 2 in epoch 19, gen_loss = 1.3881996075312297, disc_loss = 3.516204985013852e-05
Trained batch 3 in epoch 19, gen_loss = 1.418667048215866, disc_loss = 3.709520842676284e-05
Trained batch 4 in epoch 19, gen_loss = 1.4119377851486206, disc_loss = 3.550390865711961e-05
Trained batch 5 in epoch 19, gen_loss = 1.3947786887486775, disc_loss = 3.5366731329607624e-05
Trained batch 6 in epoch 19, gen_loss = 1.3989481244768416, disc_loss = 3.4450499047774687e-05
Trained batch 7 in epoch 19, gen_loss = 1.4020682871341705, disc_loss = 3.3403584211555426e-05
Trained batch 8 in epoch 19, gen_loss = 1.3996124664942424, disc_loss = 3.305703244728243e-05
Trained batch 9 in epoch 19, gen_loss = 1.3968778491020202, disc_loss = 3.311103173473384e-05
Trained batch 10 in epoch 19, gen_loss = 1.3990745436061511, disc_loss = 3.330620827248574e-05
Trained batch 11 in epoch 19, gen_loss = 1.3923420707384746, disc_loss = 3.684978855744703e-05
Trained batch 12 in epoch 19, gen_loss = 1.3983080203716571, disc_loss = 3.9982928753418564e-05
Trained batch 13 in epoch 19, gen_loss = 1.3982652596064977, disc_loss = 3.922790139248329e-05
Trained batch 14 in epoch 19, gen_loss = 1.3955062866210937, disc_loss = 3.845060612851133e-05
Trained batch 15 in epoch 19, gen_loss = 1.3918765187263489, disc_loss = 3.770183354845358e-05
Trained batch 16 in epoch 19, gen_loss = 1.3937053399927475, disc_loss = 3.730022270995987e-05
Trained batch 17 in epoch 19, gen_loss = 1.3925409780608282, disc_loss = 3.7050723019799785e-05
Trained batch 18 in epoch 19, gen_loss = 1.3943535214976261, disc_loss = 3.748944082441372e-05
Trained batch 19 in epoch 19, gen_loss = 1.3989117085933684, disc_loss = 3.782158355534193e-05
Trained batch 20 in epoch 19, gen_loss = 1.3955875408081782, disc_loss = 3.794740483239626e-05
Trained batch 21 in epoch 19, gen_loss = 1.396299665624445, disc_loss = 3.867821587019452e-05
Trained batch 22 in epoch 19, gen_loss = 1.3997019477512525, disc_loss = 3.8838971032300435e-05
Trained batch 23 in epoch 19, gen_loss = 1.3970569372177124, disc_loss = 3.868961668255603e-05
Trained batch 24 in epoch 19, gen_loss = 1.399375081062317, disc_loss = 3.933647567464504e-05
Trained batch 25 in epoch 19, gen_loss = 1.3985856358821576, disc_loss = 3.906962977523038e-05
Trained batch 26 in epoch 19, gen_loss = 1.397575440230193, disc_loss = 3.8784497384633006e-05
Trained batch 27 in epoch 19, gen_loss = 1.3963524145739419, disc_loss = 4.02626581360112e-05
Trained batch 28 in epoch 19, gen_loss = 1.3988502436670764, disc_loss = 4.091444479227307e-05
Trained batch 29 in epoch 19, gen_loss = 1.3993803183237712, disc_loss = 4.1164178704396666e-05
Trained batch 30 in epoch 19, gen_loss = 1.4003823034224971, disc_loss = 4.089587961178979e-05
Trained batch 31 in epoch 19, gen_loss = 1.4022232592105865, disc_loss = 4.104043927100065e-05
Trained batch 32 in epoch 19, gen_loss = 1.4029280055652966, disc_loss = 4.126446203206962e-05
Trained batch 33 in epoch 19, gen_loss = 1.4029009061701156, disc_loss = 4.1130438469682465e-05
Trained batch 34 in epoch 19, gen_loss = 1.4043862308774675, disc_loss = 4.096627032725207e-05
Trained batch 35 in epoch 19, gen_loss = 1.4043857091002994, disc_loss = 4.1182613889153195e-05
Trained batch 36 in epoch 19, gen_loss = 1.4058551433924082, disc_loss = 5.194068054717374e-05
Trained batch 37 in epoch 19, gen_loss = 1.4050481476281818, disc_loss = 5.929520993001796e-05
Trained batch 38 in epoch 19, gen_loss = 1.4049551334136572, disc_loss = 6.260107306260556e-05
Trained batch 39 in epoch 19, gen_loss = 1.4055960446596145, disc_loss = 6.266727555157559e-05
Trained batch 40 in epoch 19, gen_loss = 1.4055849371886835, disc_loss = 6.253915059304989e-05
Trained batch 41 in epoch 19, gen_loss = 1.404610778604235, disc_loss = 6.210297158845823e-05
Trained batch 42 in epoch 19, gen_loss = 1.4049120781033537, disc_loss = 6.1663573221669e-05
Trained batch 43 in epoch 19, gen_loss = 1.4062757004391064, disc_loss = 6.093977113282149e-05
Trained batch 44 in epoch 19, gen_loss = 1.4064289145999485, disc_loss = 6.021734730489293e-05
Trained batch 45 in epoch 19, gen_loss = 1.4050344798875891, disc_loss = 5.951558424662242e-05
Trained batch 46 in epoch 19, gen_loss = 1.4046040392936545, disc_loss = 5.882830493569503e-05
Trained batch 47 in epoch 19, gen_loss = 1.4029690871636074, disc_loss = 5.827019288062729e-05
Trained batch 48 in epoch 19, gen_loss = 1.4032975946153914, disc_loss = 5.771587051157792e-05
Trained batch 49 in epoch 19, gen_loss = 1.4035789585113525, disc_loss = 5.710851579351583e-05
Trained batch 50 in epoch 19, gen_loss = 1.4027528716068642, disc_loss = 5.642732446408356e-05
Trained batch 51 in epoch 19, gen_loss = 1.4024196312977717, disc_loss = 5.593353622456422e-05
Trained batch 52 in epoch 19, gen_loss = 1.4021575495881855, disc_loss = 5.54137694498937e-05
Trained batch 53 in epoch 19, gen_loss = 1.402325603697035, disc_loss = 5.4938726255689595e-05
Trained batch 54 in epoch 19, gen_loss = 1.4005334377288818, disc_loss = 5.507492450388699e-05
Trained batch 55 in epoch 19, gen_loss = 1.4006868643420083, disc_loss = 5.479975142666912e-05
Trained batch 56 in epoch 19, gen_loss = 1.3991002701876456, disc_loss = 5.4247860948395866e-05
Trained batch 57 in epoch 19, gen_loss = 1.397238065456522, disc_loss = 5.3822663615172695e-05
Trained batch 58 in epoch 19, gen_loss = 1.3958029928853957, disc_loss = 5.354615976842578e-05
Trained batch 59 in epoch 19, gen_loss = 1.3957099219163258, disc_loss = 5.3589774567323426e-05
Trained batch 60 in epoch 19, gen_loss = 1.3950388568346617, disc_loss = 5.3345392263479164e-05
Trained batch 61 in epoch 19, gen_loss = 1.394349261637657, disc_loss = 5.305303461829035e-05
Trained batch 62 in epoch 19, gen_loss = 1.3936212687265306, disc_loss = 5.273620476983192e-05
Trained batch 63 in epoch 19, gen_loss = 1.3934543542563915, disc_loss = 5.244675622861905e-05
Trained batch 64 in epoch 19, gen_loss = 1.3933903804192176, disc_loss = 5.2122386841801925e-05
Trained batch 65 in epoch 19, gen_loss = 1.3927475123694448, disc_loss = 5.184757444085059e-05
Trained batch 66 in epoch 19, gen_loss = 1.3929776807329548, disc_loss = 5.1502536924959005e-05
Trained batch 67 in epoch 19, gen_loss = 1.3938083701273973, disc_loss = 5.1157849103380135e-05
Trained batch 68 in epoch 19, gen_loss = 1.3936461624891863, disc_loss = 5.0893870059593134e-05
Trained batch 69 in epoch 19, gen_loss = 1.394143727847508, disc_loss = 5.060190682602947e-05
Trained batch 70 in epoch 19, gen_loss = 1.3934112518606052, disc_loss = 5.038938900430418e-05
Trained batch 71 in epoch 19, gen_loss = 1.392746572693189, disc_loss = 5.0708810729500125e-05
Trained batch 72 in epoch 19, gen_loss = 1.3940518555575854, disc_loss = 5.1516241200422956e-05
Trained batch 73 in epoch 19, gen_loss = 1.3939653957212292, disc_loss = 5.1581589203222494e-05
Trained batch 74 in epoch 19, gen_loss = 1.3930213816960653, disc_loss = 5.177744424145203e-05
Trained batch 75 in epoch 19, gen_loss = 1.3933774766169096, disc_loss = 5.163007567956045e-05
Trained batch 76 in epoch 19, gen_loss = 1.3939900367290943, disc_loss = 5.1459988399428414e-05
Trained batch 77 in epoch 19, gen_loss = 1.3934756349294612, disc_loss = 5.1266287673803534e-05
Trained batch 78 in epoch 19, gen_loss = 1.3924867005287846, disc_loss = 5.108808957779326e-05
Trained batch 79 in epoch 19, gen_loss = 1.3929616197943688, disc_loss = 5.0973942938981055e-05
Trained batch 80 in epoch 19, gen_loss = 1.3926877754705924, disc_loss = 5.070671386981561e-05
Trained batch 81 in epoch 19, gen_loss = 1.3926380494745767, disc_loss = 5.03709060489555e-05
Trained batch 82 in epoch 19, gen_loss = 1.3925470544631222, disc_loss = 5.009282340982183e-05
Trained batch 83 in epoch 19, gen_loss = 1.393081166914531, disc_loss = 4.9858334824377726e-05
Trained batch 84 in epoch 19, gen_loss = 1.3925006992676678, disc_loss = 4.949007488903589e-05
Trained batch 85 in epoch 19, gen_loss = 1.3925984335500141, disc_loss = 4.935406121698771e-05
Trained batch 86 in epoch 19, gen_loss = 1.3925428267182975, disc_loss = 4.923112906051275e-05
Trained batch 87 in epoch 19, gen_loss = 1.39194825833494, disc_loss = 4.900395788354217e-05
Trained batch 88 in epoch 19, gen_loss = 1.3925303421663435, disc_loss = 4.9039169865087446e-05
Trained batch 89 in epoch 19, gen_loss = 1.3922079059812758, disc_loss = 4.8996222216778225e-05
Trained batch 90 in epoch 19, gen_loss = 1.3925178771490578, disc_loss = 4.885450763030459e-05
Trained batch 91 in epoch 19, gen_loss = 1.3926458786363187, disc_loss = 4.8606333324562953e-05
Trained batch 92 in epoch 19, gen_loss = 1.3925678473646923, disc_loss = 4.8363722261681064e-05
Trained batch 93 in epoch 19, gen_loss = 1.3917489432274026, disc_loss = 4.823626254910004e-05
Trained batch 94 in epoch 19, gen_loss = 1.3912733052906237, disc_loss = 4.803584007803645e-05
Trained batch 95 in epoch 19, gen_loss = 1.3908044596513112, disc_loss = 4.787396600628805e-05
Trained batch 96 in epoch 19, gen_loss = 1.3903248445274903, disc_loss = 4.76243697720719e-05
Trained batch 97 in epoch 19, gen_loss = 1.3897505220101805, disc_loss = 4.746841952918639e-05
Trained batch 98 in epoch 19, gen_loss = 1.3888321850034926, disc_loss = 4.73458135504666e-05
Trained batch 99 in epoch 19, gen_loss = 1.3896989619731903, disc_loss = 4.735436690680217e-05
Trained batch 100 in epoch 19, gen_loss = 1.3890032968898811, disc_loss = 4.723268799658976e-05
Trained batch 101 in epoch 19, gen_loss = 1.3896807934723647, disc_loss = 4.7166199781749326e-05
Trained batch 102 in epoch 19, gen_loss = 1.389890211299785, disc_loss = 4.697394401817786e-05
Trained batch 103 in epoch 19, gen_loss = 1.3905880004167557, disc_loss = 4.7004443768645826e-05
Trained batch 104 in epoch 19, gen_loss = 1.3907091152100337, disc_loss = 4.6933724470796904e-05
Trained batch 105 in epoch 19, gen_loss = 1.390417145108277, disc_loss = 4.6884778247710166e-05
Trained batch 106 in epoch 19, gen_loss = 1.39076761218989, disc_loss = 4.687694245914028e-05
Trained batch 107 in epoch 19, gen_loss = 1.3910106420516968, disc_loss = 4.6696211332649305e-05
Trained batch 108 in epoch 19, gen_loss = 1.3903923614309468, disc_loss = 4.657291099130082e-05
Trained batch 109 in epoch 19, gen_loss = 1.391340021653609, disc_loss = 4.655211556713436e-05
Trained batch 110 in epoch 19, gen_loss = 1.3916874350728214, disc_loss = 4.6428469644737776e-05
Trained batch 111 in epoch 19, gen_loss = 1.3910770214029722, disc_loss = 4.634624045658191e-05
Trained batch 112 in epoch 19, gen_loss = 1.390555968326805, disc_loss = 4.6154754844172735e-05
Trained batch 113 in epoch 19, gen_loss = 1.3905329620629026, disc_loss = 4.597941098613215e-05
Trained batch 114 in epoch 19, gen_loss = 1.391001958432405, disc_loss = 4.5946198509267086e-05
Trained batch 115 in epoch 19, gen_loss = 1.3911087071073467, disc_loss = 4.581896249372472e-05
Trained batch 116 in epoch 19, gen_loss = 1.3914304778107212, disc_loss = 4.5714406966993935e-05
Trained batch 117 in epoch 19, gen_loss = 1.3919545806060403, disc_loss = 4.5623090107070866e-05
Trained batch 118 in epoch 19, gen_loss = 1.392006842028193, disc_loss = 4.547603277708678e-05
Trained batch 119 in epoch 19, gen_loss = 1.391931559642156, disc_loss = 4.534664838805232e-05
Trained batch 120 in epoch 19, gen_loss = 1.3927533183216063, disc_loss = 4.532702826336315e-05
Trained batch 121 in epoch 19, gen_loss = 1.3927925043418758, disc_loss = 4.5163253132353126e-05
Trained batch 122 in epoch 19, gen_loss = 1.392528175338497, disc_loss = 4.512029485843273e-05
Trained batch 123 in epoch 19, gen_loss = 1.3926484815536007, disc_loss = 4.539947815740767e-05
Trained batch 124 in epoch 19, gen_loss = 1.3924745311737061, disc_loss = 4.5286574808415024e-05
Trained batch 125 in epoch 19, gen_loss = 1.3919046530647883, disc_loss = 4.5322601542307344e-05
Trained batch 126 in epoch 19, gen_loss = 1.3918374335671972, disc_loss = 4.5190160297953675e-05
Trained batch 127 in epoch 19, gen_loss = 1.3917885143309832, disc_loss = 4.510990729045261e-05
Trained batch 128 in epoch 19, gen_loss = 1.3917623906172523, disc_loss = 4.496999979384655e-05
Trained batch 129 in epoch 19, gen_loss = 1.391783370421483, disc_loss = 4.481083655823918e-05
Trained batch 130 in epoch 19, gen_loss = 1.3920296667186358, disc_loss = 4.4694957867125227e-05
Trained batch 131 in epoch 19, gen_loss = 1.391631057768157, disc_loss = 4.45127314819591e-05
Trained batch 132 in epoch 19, gen_loss = 1.3912850600436217, disc_loss = 4.4344365755419943e-05
Trained batch 133 in epoch 19, gen_loss = 1.3913486688884336, disc_loss = 4.4150573096464825e-05
Trained batch 134 in epoch 19, gen_loss = 1.3918090926276312, disc_loss = 4.413406957745017e-05
Trained batch 135 in epoch 19, gen_loss = 1.3918880066450905, disc_loss = 4.3994909834937594e-05
Trained batch 136 in epoch 19, gen_loss = 1.3916725190016475, disc_loss = 4.385035928172216e-05
Trained batch 137 in epoch 19, gen_loss = 1.3917359891145125, disc_loss = 4.375970665010306e-05
Trained batch 138 in epoch 19, gen_loss = 1.391376516801848, disc_loss = 4.3645978575696326e-05
Trained batch 139 in epoch 19, gen_loss = 1.3913496962615421, disc_loss = 4.349755994813417e-05
Trained batch 140 in epoch 19, gen_loss = 1.390861895912928, disc_loss = 4.348108996055089e-05
Trained batch 141 in epoch 19, gen_loss = 1.39078637160046, disc_loss = 4.351765341531243e-05
Trained batch 142 in epoch 19, gen_loss = 1.3909768633075528, disc_loss = 4.344852419893283e-05
Trained batch 143 in epoch 19, gen_loss = 1.3914601032932599, disc_loss = 4.34146651918531e-05
Trained batch 144 in epoch 19, gen_loss = 1.3914797338946112, disc_loss = 4.337997530016984e-05
Trained batch 145 in epoch 19, gen_loss = 1.392188068938582, disc_loss = 4.467102867425164e-05
Trained batch 146 in epoch 19, gen_loss = 1.3926426975094541, disc_loss = 4.5674757845462203e-05
Trained batch 147 in epoch 19, gen_loss = 1.3928072194795351, disc_loss = 4.625157340047441e-05
Trained batch 148 in epoch 19, gen_loss = 1.3925176530876415, disc_loss = 4.636884104240148e-05
Trained batch 149 in epoch 19, gen_loss = 1.3933292134602864, disc_loss = 4.657365566041941e-05
Trained batch 150 in epoch 19, gen_loss = 1.3932275851041276, disc_loss = 4.661433715396407e-05
Trained batch 151 in epoch 19, gen_loss = 1.3937605588059676, disc_loss = 4.670222436911181e-05
Trained batch 152 in epoch 19, gen_loss = 1.3935703623528575, disc_loss = 4.681613263171897e-05
Trained batch 153 in epoch 19, gen_loss = 1.393056490204551, disc_loss = 4.673847918154508e-05
Trained batch 154 in epoch 19, gen_loss = 1.3929486466992287, disc_loss = 4.663665348479915e-05
Trained batch 155 in epoch 19, gen_loss = 1.3929351973227966, disc_loss = 4.650290746865675e-05
Trained batch 156 in epoch 19, gen_loss = 1.3934279543579005, disc_loss = 4.645194587665521e-05
Trained batch 157 in epoch 19, gen_loss = 1.393010601967196, disc_loss = 4.642490045936731e-05
Trained batch 158 in epoch 19, gen_loss = 1.3932911869864795, disc_loss = 4.637454485018451e-05
Trained batch 159 in epoch 19, gen_loss = 1.3933530829846859, disc_loss = 4.631162828445667e-05
Trained batch 160 in epoch 19, gen_loss = 1.3930071969950422, disc_loss = 4.631098423905885e-05
Trained batch 161 in epoch 19, gen_loss = 1.3928819350254389, disc_loss = 4.624755526077215e-05
Trained batch 162 in epoch 19, gen_loss = 1.3933106273229867, disc_loss = 4.6287244600936645e-05
Trained batch 163 in epoch 19, gen_loss = 1.3929095224636356, disc_loss = 4.6226754354237774e-05
Trained batch 164 in epoch 19, gen_loss = 1.392540829109423, disc_loss = 4.620974123650795e-05
Trained batch 165 in epoch 19, gen_loss = 1.3926237922116935, disc_loss = 4.6202209547578626e-05
Trained batch 166 in epoch 19, gen_loss = 1.3927969340078845, disc_loss = 4.617856604759553e-05
Trained batch 167 in epoch 19, gen_loss = 1.392665799884569, disc_loss = 4.610562135504941e-05
Trained batch 168 in epoch 19, gen_loss = 1.3925034428489278, disc_loss = 4.5996489327145363e-05
Trained batch 169 in epoch 19, gen_loss = 1.3925433481440825, disc_loss = 4.59222827831742e-05
Trained batch 170 in epoch 19, gen_loss = 1.3929748047165007, disc_loss = 4.5891966314952987e-05
Trained batch 171 in epoch 19, gen_loss = 1.392600832983505, disc_loss = 4.58456207144441e-05
Trained batch 172 in epoch 19, gen_loss = 1.3924056050405338, disc_loss = 4.5819969467513906e-05
Trained batch 173 in epoch 19, gen_loss = 1.3920634546499142, disc_loss = 4.570279687523625e-05
Trained batch 174 in epoch 19, gen_loss = 1.3925930309295653, disc_loss = 4.5695977657617605e-05
Trained batch 175 in epoch 19, gen_loss = 1.3923916450955651, disc_loss = 4.5596030748707896e-05
Trained batch 176 in epoch 19, gen_loss = 1.3921778195321897, disc_loss = 4.545180450743104e-05
Trained batch 177 in epoch 19, gen_loss = 1.3922074517507232, disc_loss = 4.533372819505428e-05
Trained batch 178 in epoch 19, gen_loss = 1.3923032843200853, disc_loss = 4.5194300171247994e-05
Trained batch 179 in epoch 19, gen_loss = 1.3923836913373735, disc_loss = 4.510985962850909e-05
Trained batch 180 in epoch 19, gen_loss = 1.3922264687922778, disc_loss = 4.5023666076022536e-05
Trained batch 181 in epoch 19, gen_loss = 1.3922277341832172, disc_loss = 4.495578296872746e-05
Trained batch 182 in epoch 19, gen_loss = 1.3922145470895402, disc_loss = 4.485384890925116e-05
Trained batch 183 in epoch 19, gen_loss = 1.3924474593089975, disc_loss = 4.484244056149454e-05
Trained batch 184 in epoch 19, gen_loss = 1.3921598241135882, disc_loss = 4.471138755262301e-05
Trained batch 185 in epoch 19, gen_loss = 1.3924045274334569, disc_loss = 4.466231304479973e-05
Trained batch 186 in epoch 19, gen_loss = 1.3924114124022704, disc_loss = 4.455278178799604e-05
Trained batch 187 in epoch 19, gen_loss = 1.3919959214139492, disc_loss = 4.447789545705978e-05
Trained batch 188 in epoch 19, gen_loss = 1.3919712374450037, disc_loss = 4.4456975080754125e-05
Trained batch 189 in epoch 19, gen_loss = 1.391794879185526, disc_loss = 4.4400675592202646e-05
Trained batch 190 in epoch 19, gen_loss = 1.39218207741283, disc_loss = 4.4299583298569246e-05
Trained batch 191 in epoch 19, gen_loss = 1.3923575015117724, disc_loss = 4.423237742419891e-05
Trained batch 192 in epoch 19, gen_loss = 1.3920769932356523, disc_loss = 4.4161916158594544e-05
Trained batch 193 in epoch 19, gen_loss = 1.3919833191891307, disc_loss = 4.405350843917029e-05
Trained batch 194 in epoch 19, gen_loss = 1.3920042478121244, disc_loss = 4.394070373307794e-05
Trained batch 195 in epoch 19, gen_loss = 1.3915726043740098, disc_loss = 4.3948454638629464e-05
Trained batch 196 in epoch 19, gen_loss = 1.3912925829137037, disc_loss = 4.392416104302047e-05
Trained batch 197 in epoch 19, gen_loss = 1.391463820380394, disc_loss = 4.389122507130407e-05
Trained batch 198 in epoch 19, gen_loss = 1.39122990028343, disc_loss = 4.3851049206261736e-05
Trained batch 199 in epoch 19, gen_loss = 1.391388450860977, disc_loss = 4.385099366118084e-05
Trained batch 200 in epoch 19, gen_loss = 1.3915394627632787, disc_loss = 4.377323822874173e-05
Trained batch 201 in epoch 19, gen_loss = 1.391844907019398, disc_loss = 4.3707552142204984e-05
Trained batch 202 in epoch 19, gen_loss = 1.391660446603897, disc_loss = 4.3589419623583974e-05
Trained batch 203 in epoch 19, gen_loss = 1.3917515751193552, disc_loss = 4.351913096744444e-05
Trained batch 204 in epoch 19, gen_loss = 1.3916267993973523, disc_loss = 4.3419105270181826e-05
Trained batch 205 in epoch 19, gen_loss = 1.3911889438490266, disc_loss = 4.333533290917736e-05
Trained batch 206 in epoch 19, gen_loss = 1.3911568300735548, disc_loss = 4.3275653139141426e-05
Trained batch 207 in epoch 19, gen_loss = 1.3910865691991954, disc_loss = 4.323306585809825e-05
Trained batch 208 in epoch 19, gen_loss = 1.3912767257416647, disc_loss = 4.3202050667452185e-05
Trained batch 209 in epoch 19, gen_loss = 1.391312877337138, disc_loss = 4.3129594286299486e-05
Trained batch 210 in epoch 19, gen_loss = 1.391298381073215, disc_loss = 4.303665665889786e-05
Trained batch 211 in epoch 19, gen_loss = 1.3915320691072717, disc_loss = 4.29885340225773e-05
Trained batch 212 in epoch 19, gen_loss = 1.3912462734840285, disc_loss = 4.296334354278518e-05
Trained batch 213 in epoch 19, gen_loss = 1.3913477185730623, disc_loss = 4.288258758810388e-05
Trained batch 214 in epoch 19, gen_loss = 1.3915065599042316, disc_loss = 4.280408635210289e-05
Trained batch 215 in epoch 19, gen_loss = 1.3915569644283365, disc_loss = 4.277355273424527e-05
Trained batch 216 in epoch 19, gen_loss = 1.391607561419087, disc_loss = 4.269518234449426e-05
Trained batch 217 in epoch 19, gen_loss = 1.391746200552774, disc_loss = 4.26365931821029e-05
Trained batch 218 in epoch 19, gen_loss = 1.3918438768822308, disc_loss = 4.2625471357732996e-05
Trained batch 219 in epoch 19, gen_loss = 1.3916493166576733, disc_loss = 4.302418668554641e-05
Trained batch 220 in epoch 19, gen_loss = 1.3910459781663989, disc_loss = 4.426089604312767e-05
Trained batch 221 in epoch 19, gen_loss = 1.390815260711017, disc_loss = 6.069822547369194e-05
Trained batch 222 in epoch 19, gen_loss = 1.3928520438917014, disc_loss = 8.529160130016491e-05
Trained batch 223 in epoch 19, gen_loss = 1.394015657050269, disc_loss = 8.98165415443535e-05
Trained batch 224 in epoch 19, gen_loss = 1.3948712004555597, disc_loss = 9.603757547867847e-05
Trained batch 225 in epoch 19, gen_loss = 1.3960322030877645, disc_loss = 9.778270554612648e-05
Trained batch 226 in epoch 19, gen_loss = 1.3973563090294994, disc_loss = 9.930417569907277e-05
Trained batch 227 in epoch 19, gen_loss = 1.3984089033645497, disc_loss = 9.981031511766527e-05
Trained batch 228 in epoch 19, gen_loss = 1.3993366930682587, disc_loss = 0.00010007682711418004
Trained batch 229 in epoch 19, gen_loss = 1.400158845341724, disc_loss = 0.00010017553552682764
Trained batch 230 in epoch 19, gen_loss = 1.4011692706640664, disc_loss = 0.00010049454271431773
Trained batch 231 in epoch 19, gen_loss = 1.4021253811902012, disc_loss = 0.00010086521208528399
Trained batch 232 in epoch 19, gen_loss = 1.4030399639719033, disc_loss = 0.0001009208156344158
Trained batch 233 in epoch 19, gen_loss = 1.4040399575844789, disc_loss = 0.0001008073681171085
Trained batch 234 in epoch 19, gen_loss = 1.405068654709674, disc_loss = 0.00010077631342666907
Trained batch 235 in epoch 19, gen_loss = 1.4060672405412642, disc_loss = 0.00010074872277797668
Trained batch 236 in epoch 19, gen_loss = 1.4069393702197175, disc_loss = 0.00010090068330108296
Trained batch 237 in epoch 19, gen_loss = 1.4078973777153914, disc_loss = 0.00010082573493598509
Trained batch 238 in epoch 19, gen_loss = 1.408855271139903, disc_loss = 0.00010092098448211454
Trained batch 239 in epoch 19, gen_loss = 1.4097616240382194, disc_loss = 0.000100973343349627
Trained batch 240 in epoch 19, gen_loss = 1.4106063674594356, disc_loss = 0.00010092141771916333
Trained batch 241 in epoch 19, gen_loss = 1.4113985960148583, disc_loss = 0.00010079656911044322
Trained batch 242 in epoch 19, gen_loss = 1.4122109020688407, disc_loss = 0.0001008134153485322
Trained batch 243 in epoch 19, gen_loss = 1.4130139829682522, disc_loss = 0.00010071114764018528
Trained batch 244 in epoch 19, gen_loss = 1.4138011893447564, disc_loss = 0.00010067602434363073
Trained batch 245 in epoch 19, gen_loss = 1.4150981282800195, disc_loss = 0.00010072126327778404
Trained batch 246 in epoch 19, gen_loss = 1.416122375712221, disc_loss = 0.00010070393804390303
Trained batch 247 in epoch 19, gen_loss = 1.4170227791032484, disc_loss = 0.00010079540845342103
Trained batch 248 in epoch 19, gen_loss = 1.41796568550738, disc_loss = 0.0001010619813226744
Trained batch 249 in epoch 19, gen_loss = 1.418889051914215, disc_loss = 0.00010100495280494215
Trained batch 250 in epoch 19, gen_loss = 1.4197680204513063, disc_loss = 0.00010090017318847335
Trained batch 251 in epoch 19, gen_loss = 1.4205614101319086, disc_loss = 0.0001008035907929413
Trained batch 252 in epoch 19, gen_loss = 1.4213105138582673, disc_loss = 0.0001009344565684989
Trained batch 253 in epoch 19, gen_loss = 1.4222026833399075, disc_loss = 0.00010105270073148944
Trained batch 254 in epoch 19, gen_loss = 1.423236969873017, disc_loss = 0.00010150057434443357
Trained batch 255 in epoch 19, gen_loss = 1.4240250559523702, disc_loss = 0.00010161923245988191
Trained batch 256 in epoch 19, gen_loss = 1.424952934224318, disc_loss = 0.00010148215848719928
Trained batch 257 in epoch 19, gen_loss = 1.425707917804866, disc_loss = 0.00010174525909825425
Trained batch 258 in epoch 19, gen_loss = 1.4264245834129659, disc_loss = 0.0001017364549667338
Trained batch 259 in epoch 19, gen_loss = 1.4269823051415957, disc_loss = 0.00010169928935003834
Trained batch 260 in epoch 19, gen_loss = 1.4276951670189928, disc_loss = 0.00010154945778793618
Trained batch 261 in epoch 19, gen_loss = 1.4286071462485626, disc_loss = 0.0001017794396108099
Trained batch 262 in epoch 19, gen_loss = 1.4291728113993947, disc_loss = 0.00010229586728321993
Trained batch 263 in epoch 19, gen_loss = 1.4298844490990494, disc_loss = 0.00010270596602491754
Trained batch 264 in epoch 19, gen_loss = 1.4304795508114796, disc_loss = 0.00010277225421373688
Trained batch 265 in epoch 19, gen_loss = 1.4310555511847474, disc_loss = 0.00010263303904782121
Trained batch 266 in epoch 19, gen_loss = 1.4316068240319297, disc_loss = 0.00010273514004091319
Trained batch 267 in epoch 19, gen_loss = 1.4322121303472946, disc_loss = 0.00010262070830987198
Trained batch 268 in epoch 19, gen_loss = 1.4327263388935074, disc_loss = 0.00010263235441983121
Trained batch 269 in epoch 19, gen_loss = 1.4332415492446333, disc_loss = 0.0001024379960788927
Trained batch 270 in epoch 19, gen_loss = 1.433741812336489, disc_loss = 0.00010223851880144346
Trained batch 271 in epoch 19, gen_loss = 1.4342795728760607, disc_loss = 0.00010203044315831528
Trained batch 272 in epoch 19, gen_loss = 1.4349333021666977, disc_loss = 0.00010177713272405059
Trained batch 273 in epoch 19, gen_loss = 1.4354416932502803, disc_loss = 0.00010163304171454625
Trained batch 274 in epoch 19, gen_loss = 1.435950427055359, disc_loss = 0.00010140131167480088
Trained batch 275 in epoch 19, gen_loss = 1.4363984353300454, disc_loss = 0.0001011616194035383
Trained batch 276 in epoch 19, gen_loss = 1.4370726265201499, disc_loss = 0.00010094052691251966
Trained batch 277 in epoch 19, gen_loss = 1.43753538714896, disc_loss = 0.00010077831144280281
Trained batch 278 in epoch 19, gen_loss = 1.4381907507510168, disc_loss = 0.00010062777604825342
Trained batch 279 in epoch 19, gen_loss = 1.4386897742748261, disc_loss = 0.00010051576631277774
Trained batch 280 in epoch 19, gen_loss = 1.4390864049836833, disc_loss = 0.00010039444280784367
Trained batch 281 in epoch 19, gen_loss = 1.4395278852882114, disc_loss = 0.00010038537221325186
Trained batch 282 in epoch 19, gen_loss = 1.4399016012993802, disc_loss = 0.00010031326478656732
Trained batch 283 in epoch 19, gen_loss = 1.440273772662794, disc_loss = 0.00010009612452436991
Trained batch 284 in epoch 19, gen_loss = 1.4409565101590074, disc_loss = 9.989736982996029e-05
Trained batch 285 in epoch 19, gen_loss = 1.4412803670743128, disc_loss = 9.967720619694068e-05
Trained batch 286 in epoch 19, gen_loss = 1.4417200715699678, disc_loss = 9.95596283214724e-05
Trained batch 287 in epoch 19, gen_loss = 1.4421829916536808, disc_loss = 9.967460105523666e-05
Trained batch 288 in epoch 19, gen_loss = 1.4428377572227926, disc_loss = 9.9943917860536e-05
Trained batch 289 in epoch 19, gen_loss = 1.4431576889136741, disc_loss = 9.994016465874478e-05
Trained batch 290 in epoch 19, gen_loss = 1.4436147241657953, disc_loss = 9.988140998482409e-05
Trained batch 291 in epoch 19, gen_loss = 1.4439146477882177, disc_loss = 9.972159760103725e-05
Trained batch 292 in epoch 19, gen_loss = 1.444358938383161, disc_loss = 9.954950511160524e-05
Trained batch 293 in epoch 19, gen_loss = 1.4448328074954806, disc_loss = 9.936998272913573e-05
Trained batch 294 in epoch 19, gen_loss = 1.4452564554699396, disc_loss = 9.917083551630702e-05
Trained batch 295 in epoch 19, gen_loss = 1.4456058474811349, disc_loss = 9.899894662585457e-05
Trained batch 296 in epoch 19, gen_loss = 1.4460221870178325, disc_loss = 9.876372553935347e-05
Trained batch 297 in epoch 19, gen_loss = 1.4466488169343679, disc_loss = 9.870643818748243e-05
Trained batch 298 in epoch 19, gen_loss = 1.447101665181061, disc_loss = 9.863248607056157e-05
Trained batch 299 in epoch 19, gen_loss = 1.4474777694543202, disc_loss = 9.847596987431947e-05
Trained batch 300 in epoch 19, gen_loss = 1.4478500344824554, disc_loss = 9.845887042535237e-05
Trained batch 301 in epoch 19, gen_loss = 1.4485048667484561, disc_loss = 9.870269315905903e-05
Trained batch 302 in epoch 19, gen_loss = 1.4489588753224993, disc_loss = 9.86997538918388e-05
Trained batch 303 in epoch 19, gen_loss = 1.4493259705210988, disc_loss = 9.865584794217859e-05
Trained batch 304 in epoch 19, gen_loss = 1.4496811272668058, disc_loss = 9.851463802958472e-05
Trained batch 305 in epoch 19, gen_loss = 1.4499851874276704, disc_loss = 9.837407573631104e-05
Trained batch 306 in epoch 19, gen_loss = 1.450368719691174, disc_loss = 9.829377366981852e-05
Trained batch 307 in epoch 19, gen_loss = 1.4506366794759578, disc_loss = 9.811823622237773e-05
Trained batch 308 in epoch 19, gen_loss = 1.4509068368708047, disc_loss = 9.798083829376651e-05
Trained batch 309 in epoch 19, gen_loss = 1.4511565346871653, disc_loss = 9.782778528930183e-05
Trained batch 310 in epoch 19, gen_loss = 1.4516500169441249, disc_loss = 9.772802057698102e-05
Trained batch 311 in epoch 19, gen_loss = 1.4520918887395124, disc_loss = 9.755649151161495e-05
Trained batch 312 in epoch 19, gen_loss = 1.4523744705005195, disc_loss = 9.741326667803203e-05
Trained batch 313 in epoch 19, gen_loss = 1.4528310287530255, disc_loss = 9.736224874243463e-05
Trained batch 314 in epoch 19, gen_loss = 1.4532098478741116, disc_loss = 9.738876393558235e-05
Trained batch 315 in epoch 19, gen_loss = 1.453647111412845, disc_loss = 9.726885958956746e-05
Trained batch 316 in epoch 19, gen_loss = 1.4540843903454321, disc_loss = 9.718757960844376e-05
Trained batch 317 in epoch 19, gen_loss = 1.4543976502598457, disc_loss = 9.70406813823227e-05
Trained batch 318 in epoch 19, gen_loss = 1.4548064806618286, disc_loss = 9.689187141719966e-05
Trained batch 319 in epoch 19, gen_loss = 1.455153964087367, disc_loss = 9.679994752787024e-05
Trained batch 320 in epoch 19, gen_loss = 1.455493634734941, disc_loss = 9.669073750108997e-05
Trained batch 321 in epoch 19, gen_loss = 1.4558984107852722, disc_loss = 9.688633400169548e-05
Trained batch 322 in epoch 19, gen_loss = 1.456055290558759, disc_loss = 9.707607479456772e-05
Trained batch 323 in epoch 19, gen_loss = 1.4565957137096075, disc_loss = 9.710753338255511e-05
Trained batch 324 in epoch 19, gen_loss = 1.4570168861976036, disc_loss = 9.707941971450615e-05
Trained batch 325 in epoch 19, gen_loss = 1.45741686645461, disc_loss = 9.688856113875967e-05
Trained batch 326 in epoch 19, gen_loss = 1.4578633796913543, disc_loss = 9.671179391915443e-05
Trained batch 327 in epoch 19, gen_loss = 1.4581629056029204, disc_loss = 9.658542478241654e-05
Trained batch 328 in epoch 19, gen_loss = 1.4584324262062467, disc_loss = 9.64046378206323e-05
Trained batch 329 in epoch 19, gen_loss = 1.4588865359624228, disc_loss = 9.627657378917898e-05
Trained batch 330 in epoch 19, gen_loss = 1.4592786836480085, disc_loss = 9.616436759684181e-05
Trained batch 331 in epoch 19, gen_loss = 1.4595105831163475, disc_loss = 9.602503721535287e-05
Trained batch 332 in epoch 19, gen_loss = 1.4597866277436953, disc_loss = 9.591500411834777e-05
Trained batch 333 in epoch 19, gen_loss = 1.4601501469126719, disc_loss = 9.580390214542566e-05
Trained batch 334 in epoch 19, gen_loss = 1.4606633104495148, disc_loss = 9.785628558958381e-05
Trained batch 335 in epoch 19, gen_loss = 1.460902989620254, disc_loss = 9.917850514371129e-05
Trained batch 336 in epoch 19, gen_loss = 1.461209328309011, disc_loss = 9.99839723498653e-05
Trained batch 337 in epoch 19, gen_loss = 1.4615743699863817, disc_loss = 0.00010009224000863921
Trained batch 338 in epoch 19, gen_loss = 1.461993917251407, disc_loss = 0.0001001989209852257
Trained batch 339 in epoch 19, gen_loss = 1.4622658939922557, disc_loss = 0.0001001603434975978
Trained batch 340 in epoch 19, gen_loss = 1.462580874518565, disc_loss = 0.00010002374219873037
Trained batch 341 in epoch 19, gen_loss = 1.4629540213367396, disc_loss = 9.983018596267889e-05
Trained batch 342 in epoch 19, gen_loss = 1.4632433545137633, disc_loss = 9.963631443866004e-05
Trained batch 343 in epoch 19, gen_loss = 1.4635530086450799, disc_loss = 9.943910980689187e-05
Trained batch 344 in epoch 19, gen_loss = 1.4638189951578775, disc_loss = 9.922809277549792e-05
Trained batch 345 in epoch 19, gen_loss = 1.4641834414763257, disc_loss = 9.902834211066674e-05
Trained batch 346 in epoch 19, gen_loss = 1.4643920330218005, disc_loss = 9.88372131944426e-05
Trained batch 347 in epoch 19, gen_loss = 1.4645623814785618, disc_loss = 9.862314570570048e-05
Trained batch 348 in epoch 19, gen_loss = 1.4650101504558137, disc_loss = 9.853839923051935e-05
Trained batch 349 in epoch 19, gen_loss = 1.4653067111968994, disc_loss = 9.849451064448138e-05
Trained batch 350 in epoch 19, gen_loss = 1.4656131749818808, disc_loss = 9.841161160753043e-05
Trained batch 351 in epoch 19, gen_loss = 1.4656689234755256, disc_loss = 9.828587322276276e-05
Trained batch 352 in epoch 19, gen_loss = 1.4659259299043217, disc_loss = 9.811710546783531e-05
Trained batch 353 in epoch 19, gen_loss = 1.466306943677913, disc_loss = 9.795682169585804e-05
Trained batch 354 in epoch 19, gen_loss = 1.466534323759482, disc_loss = 9.775342208433332e-05
Trained batch 355 in epoch 19, gen_loss = 1.4668146542618783, disc_loss = 9.759179924453185e-05
Trained batch 356 in epoch 19, gen_loss = 1.4672358179626679, disc_loss = 9.77778374760396e-05
Trained batch 357 in epoch 19, gen_loss = 1.4673686530336987, disc_loss = 9.789314076214035e-05
Trained batch 358 in epoch 19, gen_loss = 1.4676388947080437, disc_loss = 9.803761252475135e-05
Trained batch 359 in epoch 19, gen_loss = 1.4678294638792673, disc_loss = 9.797089427997384e-05
Trained batch 360 in epoch 19, gen_loss = 1.468220830954343, disc_loss = 9.794415976775428e-05
Trained batch 361 in epoch 19, gen_loss = 1.4685058633266892, disc_loss = 9.782500680020202e-05
Trained batch 362 in epoch 19, gen_loss = 1.4687190784895716, disc_loss = 9.764911819053121e-05
Trained batch 363 in epoch 19, gen_loss = 1.4689699286942954, disc_loss = 9.748497501317575e-05
Trained batch 364 in epoch 19, gen_loss = 1.4691004452640064, disc_loss = 9.732533049728237e-05
Trained batch 365 in epoch 19, gen_loss = 1.4693184442858878, disc_loss = 9.716464587232185e-05
Trained batch 366 in epoch 19, gen_loss = 1.4694806876559348, disc_loss = 9.699726226433162e-05
Trained batch 367 in epoch 19, gen_loss = 1.4697859387682832, disc_loss = 9.684977043355542e-05
Trained batch 368 in epoch 19, gen_loss = 1.4698543978254324, disc_loss = 9.666766223365499e-05
Trained batch 369 in epoch 19, gen_loss = 1.4701284862853385, disc_loss = 9.65313633453145e-05
Trained batch 370 in epoch 19, gen_loss = 1.470332226020628, disc_loss = 9.640241238093092e-05
Trained batch 371 in epoch 19, gen_loss = 1.4705870920611965, disc_loss = 9.632351059256614e-05
Trained batch 372 in epoch 19, gen_loss = 1.4708386835399965, disc_loss = 9.622659131638949e-05
Trained batch 373 in epoch 19, gen_loss = 1.4710497231406963, disc_loss = 9.604473705787149e-05
Trained batch 374 in epoch 19, gen_loss = 1.4712503522237141, disc_loss = 9.587685923421911e-05
Trained batch 375 in epoch 19, gen_loss = 1.471601259201131, disc_loss = 9.57752017856887e-05
Trained batch 376 in epoch 19, gen_loss = 1.4718189543058764, disc_loss = 9.56844394349611e-05
Trained batch 377 in epoch 19, gen_loss = 1.4720467231261036, disc_loss = 9.552857408808359e-05
Trained batch 378 in epoch 19, gen_loss = 1.4722687367713545, disc_loss = 9.535699086702253e-05
Trained batch 379 in epoch 19, gen_loss = 1.4725704685637826, disc_loss = 9.53609817291803e-05
Trained batch 380 in epoch 19, gen_loss = 1.4727488959555237, disc_loss = 9.525678035247187e-05
Trained batch 381 in epoch 19, gen_loss = 1.4729569370209858, disc_loss = 9.512245301909212e-05
Trained batch 382 in epoch 19, gen_loss = 1.473170447909801, disc_loss = 9.498499601929085e-05
Trained batch 383 in epoch 19, gen_loss = 1.4733381740128, disc_loss = 9.488974535069399e-05
Trained batch 384 in epoch 19, gen_loss = 1.4734653092049934, disc_loss = 9.472320391021687e-05
Trained batch 385 in epoch 19, gen_loss = 1.4737692413552437, disc_loss = 9.459119715342278e-05
Trained batch 386 in epoch 19, gen_loss = 1.4739544918370802, disc_loss = 9.449366763912025e-05
Trained batch 387 in epoch 19, gen_loss = 1.4740285071515546, disc_loss = 9.434851719242474e-05
Trained batch 388 in epoch 19, gen_loss = 1.4741543883836055, disc_loss = 9.416711634720926e-05
Trained batch 389 in epoch 19, gen_loss = 1.4744197457264632, disc_loss = 9.400694541396567e-05
Trained batch 390 in epoch 19, gen_loss = 1.4744918038473105, disc_loss = 9.386444568738688e-05
Trained batch 391 in epoch 19, gen_loss = 1.474725410950427, disc_loss = 9.386765878027328e-05
Trained batch 392 in epoch 19, gen_loss = 1.4749307489880472, disc_loss = 9.38067605926548e-05
Trained batch 393 in epoch 19, gen_loss = 1.47516212336303, disc_loss = 9.380423729416535e-05
Trained batch 394 in epoch 19, gen_loss = 1.4752315343180789, disc_loss = 9.37282983970731e-05
Trained batch 395 in epoch 19, gen_loss = 1.475282723554457, disc_loss = 9.370933768804381e-05
Trained batch 396 in epoch 19, gen_loss = 1.475400692569819, disc_loss = 9.36144644185072e-05
Trained batch 397 in epoch 19, gen_loss = 1.4756920280768044, disc_loss = 9.351782533193175e-05
Trained batch 398 in epoch 19, gen_loss = 1.4758418956794834, disc_loss = 9.338211032201187e-05
Trained batch 399 in epoch 19, gen_loss = 1.4760361269116402, disc_loss = 9.321986529357673e-05
Trained batch 400 in epoch 19, gen_loss = 1.4762458825051934, disc_loss = 9.305696090777112e-05
Trained batch 401 in epoch 19, gen_loss = 1.4764958124848742, disc_loss = 9.292497432497341e-05
Trained batch 402 in epoch 19, gen_loss = 1.4766322486749655, disc_loss = 9.277295182567672e-05
Trained batch 403 in epoch 19, gen_loss = 1.476783946894183, disc_loss = 9.262964128835603e-05
Trained batch 404 in epoch 19, gen_loss = 1.4770696878433227, disc_loss = 9.247592883813339e-05
Trained batch 405 in epoch 19, gen_loss = 1.4771635144802149, disc_loss = 9.230902875338341e-05
Trained batch 406 in epoch 19, gen_loss = 1.477431348266414, disc_loss = 9.215147276617775e-05
Trained batch 407 in epoch 19, gen_loss = 1.4776776348258935, disc_loss = 9.199377374595012e-05
Trained batch 408 in epoch 19, gen_loss = 1.4777906063424928, disc_loss = 9.181523835290056e-05
Trained batch 409 in epoch 19, gen_loss = 1.4779792989172587, disc_loss = 9.165767138123245e-05
Trained batch 410 in epoch 19, gen_loss = 1.4781158834768329, disc_loss = 9.150924482121536e-05
Trained batch 411 in epoch 19, gen_loss = 1.4783530967328156, disc_loss = 9.141565663598051e-05
Trained batch 412 in epoch 19, gen_loss = 1.4786613787057614, disc_loss = 9.140716765151888e-05
Trained batch 413 in epoch 19, gen_loss = 1.478864876256473, disc_loss = 9.137263719637396e-05
Trained batch 414 in epoch 19, gen_loss = 1.4791023280247149, disc_loss = 9.136252211394905e-05
Trained batch 415 in epoch 19, gen_loss = 1.4792101517892802, disc_loss = 9.130937041408497e-05
Trained batch 416 in epoch 19, gen_loss = 1.4794139093060574, disc_loss = 9.117505992140885e-05
Trained batch 417 in epoch 19, gen_loss = 1.4795522635633296, disc_loss = 9.103356185289123e-05
Trained batch 418 in epoch 19, gen_loss = 1.4797011909735232, disc_loss = 9.08994924796699e-05
Trained batch 419 in epoch 19, gen_loss = 1.4797755536578951, disc_loss = 9.076238989326243e-05
Trained batch 420 in epoch 19, gen_loss = 1.4799003838926483, disc_loss = 9.062530402724731e-05
Trained batch 421 in epoch 19, gen_loss = 1.4801276930700547, disc_loss = 9.052152361368934e-05
Trained batch 422 in epoch 19, gen_loss = 1.480300528501506, disc_loss = 9.038239059396375e-05
Trained batch 423 in epoch 19, gen_loss = 1.4804477067488544, disc_loss = 9.025399401493042e-05
Trained batch 424 in epoch 19, gen_loss = 1.4806284994237564, disc_loss = 9.012977427012041e-05
Trained batch 425 in epoch 19, gen_loss = 1.4808185360801052, disc_loss = 9.002389050662837e-05
Trained batch 426 in epoch 19, gen_loss = 1.4809079904466937, disc_loss = 8.991000360054202e-05
Trained batch 427 in epoch 19, gen_loss = 1.4810061301583441, disc_loss = 8.977756613042564e-05
Trained batch 428 in epoch 19, gen_loss = 1.4811407644431909, disc_loss = 8.974533004712424e-05
Trained batch 429 in epoch 19, gen_loss = 1.4812508064647054, disc_loss = 8.968930990725544e-05
Trained batch 430 in epoch 19, gen_loss = 1.481369782766444, disc_loss = 8.964400723098595e-05
Trained batch 431 in epoch 19, gen_loss = 1.4814629985226526, disc_loss = 8.962466533493743e-05
Trained batch 432 in epoch 19, gen_loss = 1.4815660164482873, disc_loss = 8.956610207278824e-05
Trained batch 433 in epoch 19, gen_loss = 1.4816820225957352, disc_loss = 8.952286282814057e-05
Trained batch 434 in epoch 19, gen_loss = 1.4816682286646174, disc_loss = 8.95115657317808e-05
Trained batch 435 in epoch 19, gen_loss = 1.4817640620087265, disc_loss = 8.954827307281965e-05
Trained batch 436 in epoch 19, gen_loss = 1.4817687218467486, disc_loss = 8.957523555837564e-05
Trained batch 437 in epoch 19, gen_loss = 1.4820014850734031, disc_loss = 8.952618693881993e-05
Trained batch 438 in epoch 19, gen_loss = 1.4823357469671679, disc_loss = 8.946329388536904e-05
Trained batch 439 in epoch 19, gen_loss = 1.482489370216023, disc_loss = 8.949048957137248e-05
Trained batch 440 in epoch 19, gen_loss = 1.4825897492519042, disc_loss = 8.953666812366074e-05
Trained batch 441 in epoch 19, gen_loss = 1.4826923015430502, disc_loss = 8.952317412008824e-05
Trained batch 442 in epoch 19, gen_loss = 1.4828573742515616, disc_loss = 8.947036692189525e-05
Trained batch 443 in epoch 19, gen_loss = 1.482935211679957, disc_loss = 8.94192353821832e-05
Trained batch 444 in epoch 19, gen_loss = 1.483082359024648, disc_loss = 8.93514799786368e-05
Trained batch 445 in epoch 19, gen_loss = 1.4831877310714379, disc_loss = 8.929932620974739e-05
Trained batch 446 in epoch 19, gen_loss = 1.4833375226197894, disc_loss = 8.923684674882516e-05
Trained batch 447 in epoch 19, gen_loss = 1.4834014286420174, disc_loss = 8.923018306258459e-05
Trained batch 448 in epoch 19, gen_loss = 1.4833552303717767, disc_loss = 8.918183148875008e-05
Trained batch 449 in epoch 19, gen_loss = 1.4833518142170377, disc_loss = 8.90874821319206e-05
Trained batch 450 in epoch 19, gen_loss = 1.4834255500801916, disc_loss = 8.901063902843708e-05
Trained batch 451 in epoch 19, gen_loss = 1.4834882258313946, disc_loss = 8.896461175397308e-05
Trained batch 452 in epoch 19, gen_loss = 1.48354656412112, disc_loss = 8.888123565403951e-05
Trained batch 453 in epoch 19, gen_loss = 1.4836658060813266, disc_loss = 8.88041196381563e-05
Trained batch 454 in epoch 19, gen_loss = 1.48375152860369, disc_loss = 8.871900359476317e-05
Trained batch 455 in epoch 19, gen_loss = 1.4837874602853207, disc_loss = 8.86547820117126e-05
Trained batch 456 in epoch 19, gen_loss = 1.483906921203079, disc_loss = 8.863073392960072e-05
Trained batch 457 in epoch 19, gen_loss = 1.4839977525727717, disc_loss = 8.858149616905223e-05
Trained batch 458 in epoch 19, gen_loss = 1.4840523251261326, disc_loss = 8.851785507772299e-05
Trained batch 459 in epoch 19, gen_loss = 1.4839604592841604, disc_loss = 8.860239266774126e-05
Trained batch 460 in epoch 19, gen_loss = 1.4840068214627513, disc_loss = 8.856311744116747e-05
Trained batch 461 in epoch 19, gen_loss = 1.4841034951664152, disc_loss = 8.859509787064532e-05
Trained batch 462 in epoch 19, gen_loss = 1.4841786648748245, disc_loss = 8.876537263529053e-05
Trained batch 463 in epoch 19, gen_loss = 1.4841947642893627, disc_loss = 8.877482159654204e-05
Trained batch 464 in epoch 19, gen_loss = 1.4842024787779777, disc_loss = 8.878155333482565e-05
Trained batch 465 in epoch 19, gen_loss = 1.4840582619409193, disc_loss = 8.884041049552541e-05
Trained batch 466 in epoch 19, gen_loss = 1.4839102984495796, disc_loss = 8.889038256631653e-05
Trained batch 467 in epoch 19, gen_loss = 1.4838212970485034, disc_loss = 8.884674570774814e-05
Trained batch 468 in epoch 19, gen_loss = 1.4837752916157119, disc_loss = 8.919199303420919e-05
Trained batch 469 in epoch 19, gen_loss = 1.4837878990680613, disc_loss = 8.95874518236985e-05
Trained batch 470 in epoch 19, gen_loss = 1.4837463031149214, disc_loss = 8.978621520379715e-05
Trained batch 471 in epoch 19, gen_loss = 1.4838817283763723, disc_loss = 8.993341153439098e-05
Trained batch 472 in epoch 19, gen_loss = 1.4838858621065008, disc_loss = 9.065709935338654e-05
Trained batch 473 in epoch 19, gen_loss = 1.4839994235883784, disc_loss = 9.06788639091277e-05
Trained batch 474 in epoch 19, gen_loss = 1.4840346416674162, disc_loss = 9.057221094400647e-05
Trained batch 475 in epoch 19, gen_loss = 1.4840395405512898, disc_loss = 9.054421938910171e-05
Trained batch 476 in epoch 19, gen_loss = 1.4839160802229396, disc_loss = 9.05053727195461e-05
Trained batch 477 in epoch 19, gen_loss = 1.483804563598154, disc_loss = 9.047121070256573e-05
Trained batch 478 in epoch 19, gen_loss = 1.4838566785067755, disc_loss = 9.044513130817044e-05
Trained batch 479 in epoch 19, gen_loss = 1.4838772321740785, disc_loss = 9.041756988684332e-05
Trained batch 480 in epoch 19, gen_loss = 1.4836940259794684, disc_loss = 9.03737275955776e-05
Trained batch 481 in epoch 19, gen_loss = 1.4837868238385783, disc_loss = 9.03545221991253e-05
Trained batch 482 in epoch 19, gen_loss = 1.4838636716206868, disc_loss = 9.038734898535997e-05
Trained batch 483 in epoch 19, gen_loss = 1.4838143633909462, disc_loss = 9.03111610178028e-05
Trained batch 484 in epoch 19, gen_loss = 1.4837604394893056, disc_loss = 9.024817156068351e-05
Trained batch 485 in epoch 19, gen_loss = 1.4836918189201826, disc_loss = 9.018536339482937e-05
Trained batch 486 in epoch 19, gen_loss = 1.4835576634142678, disc_loss = 9.024174150404711e-05
Trained batch 487 in epoch 19, gen_loss = 1.4835738759548938, disc_loss = 9.031548320755794e-05
Trained batch 488 in epoch 19, gen_loss = 1.4835946689110349, disc_loss = 9.035818969380564e-05
Trained batch 489 in epoch 19, gen_loss = 1.4835648113367508, disc_loss = 9.046397446990323e-05
Trained batch 490 in epoch 19, gen_loss = 1.4835555985600302, disc_loss = 9.052520789220373e-05
Trained batch 491 in epoch 19, gen_loss = 1.4833909093849058, disc_loss = 9.056864657425212e-05
Trained batch 492 in epoch 19, gen_loss = 1.4830334002783043, disc_loss = 9.581997626913644e-05
Trained batch 493 in epoch 19, gen_loss = 1.4830171347629686, disc_loss = 9.866533892350918e-05
Trained batch 494 in epoch 19, gen_loss = 1.483051236952194, disc_loss = 0.00010008728227562229
Trained batch 495 in epoch 19, gen_loss = 1.4828082133204705, disc_loss = 0.00010152854850554333
Trained batch 496 in epoch 19, gen_loss = 1.4828908311529179, disc_loss = 0.00010258117687827659
Trained batch 497 in epoch 19, gen_loss = 1.482903325414083, disc_loss = 0.00010358085766499306
Trained batch 498 in epoch 19, gen_loss = 1.482904298988755, disc_loss = 0.00010406199868077078
Trained batch 499 in epoch 19, gen_loss = 1.4828766655921937, disc_loss = 0.00010460930942281266
Trained batch 500 in epoch 19, gen_loss = 1.4830219821777648, disc_loss = 0.00010538375395689529
Trained batch 501 in epoch 19, gen_loss = 1.482969395905377, disc_loss = 0.00010623709645785648
Trained batch 502 in epoch 19, gen_loss = 1.4828749350003647, disc_loss = 0.00010667690603115394
Trained batch 503 in epoch 19, gen_loss = 1.4828886872246152, disc_loss = 0.00010677077826614319
Trained batch 504 in epoch 19, gen_loss = 1.482840404888191, disc_loss = 0.00010679546914868504
Trained batch 505 in epoch 19, gen_loss = 1.4828052829376794, disc_loss = 0.00010680365870608843
Trained batch 506 in epoch 19, gen_loss = 1.482804390805713, disc_loss = 0.00010678433058995233
Trained batch 507 in epoch 19, gen_loss = 1.4827549807199343, disc_loss = 0.000106685639720821
Trained batch 508 in epoch 19, gen_loss = 1.4826788291013078, disc_loss = 0.00010662766865469824
Trained batch 509 in epoch 19, gen_loss = 1.482654855999292, disc_loss = 0.000106596373930812
Trained batch 510 in epoch 19, gen_loss = 1.482664021027298, disc_loss = 0.00010662179367656983
Trained batch 511 in epoch 19, gen_loss = 1.4826421542093158, disc_loss = 0.0001066147232400283
Trained batch 512 in epoch 19, gen_loss = 1.482622940405535, disc_loss = 0.00010656309413708783
Trained batch 513 in epoch 19, gen_loss = 1.4825649495718545, disc_loss = 0.00010690723486976352
Trained batch 514 in epoch 19, gen_loss = 1.4824539330399151, disc_loss = 0.00010734982074035481
Trained batch 515 in epoch 19, gen_loss = 1.4824060961719632, disc_loss = 0.00010782488494766394
Trained batch 516 in epoch 19, gen_loss = 1.4823638509735608, disc_loss = 0.00010817660114515011
Trained batch 517 in epoch 19, gen_loss = 1.4823475088852254, disc_loss = 0.00010841383802935208
Trained batch 518 in epoch 19, gen_loss = 1.482292626175118, disc_loss = 0.0001085339849158955
Trained batch 519 in epoch 19, gen_loss = 1.4822470039129256, disc_loss = 0.00010849376047959735
Trained batch 520 in epoch 19, gen_loss = 1.4822412518759378, disc_loss = 0.00010841042400868328
Trained batch 521 in epoch 19, gen_loss = 1.4821058559691769, disc_loss = 0.00010830708679942601
Trained batch 522 in epoch 19, gen_loss = 1.4820462013977664, disc_loss = 0.00010822130069012524
Trained batch 523 in epoch 19, gen_loss = 1.4820215485933173, disc_loss = 0.00010809715511030157
Trained batch 524 in epoch 19, gen_loss = 1.4817629864102317, disc_loss = 0.00010812891994733252
Trained batch 525 in epoch 19, gen_loss = 1.4817698427932797, disc_loss = 0.00010957066099663038
Trained batch 526 in epoch 19, gen_loss = 1.481792742432408, disc_loss = 0.00011085237970438621
Trained batch 527 in epoch 19, gen_loss = 1.481913927829627, disc_loss = 0.00011165155673566143
Trained batch 528 in epoch 19, gen_loss = 1.481989041618679, disc_loss = 0.0001118405934989385
Trained batch 529 in epoch 19, gen_loss = 1.4820111137516094, disc_loss = 0.00011225341845516287
Trained batch 530 in epoch 19, gen_loss = 1.4819554597868982, disc_loss = 0.0001124684638034352
Trained batch 531 in epoch 19, gen_loss = 1.482079996874458, disc_loss = 0.00011252730272255056
Trained batch 532 in epoch 19, gen_loss = 1.4820377278730525, disc_loss = 0.00011252004598925571
Trained batch 533 in epoch 19, gen_loss = 1.4820320961180697, disc_loss = 0.00011246030031672783
Trained batch 534 in epoch 19, gen_loss = 1.4817666323385505, disc_loss = 0.00011242987506380457
Trained batch 535 in epoch 19, gen_loss = 1.4817531549218874, disc_loss = 0.00011236440591075272
Trained batch 536 in epoch 19, gen_loss = 1.4815747884398731, disc_loss = 0.00011237276369140305
Trained batch 537 in epoch 19, gen_loss = 1.4813943675902697, disc_loss = 0.0001124170255184
Trained batch 538 in epoch 19, gen_loss = 1.4812690826868966, disc_loss = 0.0001124185214318015
Trained batch 539 in epoch 19, gen_loss = 1.481194896168179, disc_loss = 0.00011241283707729761
Trained batch 540 in epoch 19, gen_loss = 1.481198270748371, disc_loss = 0.00011234512657616025
Trained batch 541 in epoch 19, gen_loss = 1.4811793647129157, disc_loss = 0.00011237084017786764
Trained batch 542 in epoch 19, gen_loss = 1.4810941160054496, disc_loss = 0.00011244824756773315
Trained batch 543 in epoch 19, gen_loss = 1.4810751093661083, disc_loss = 0.00011248779513299964
Trained batch 544 in epoch 19, gen_loss = 1.48103715826612, disc_loss = 0.00011253809642007707
Trained batch 545 in epoch 19, gen_loss = 1.4808774186577989, disc_loss = 0.00011264668587384035
Trained batch 546 in epoch 19, gen_loss = 1.480825936118689, disc_loss = 0.0001125837822856926
Trained batch 547 in epoch 19, gen_loss = 1.480644497340613, disc_loss = 0.0001124605938411064
Trained batch 548 in epoch 19, gen_loss = 1.4806163287119354, disc_loss = 0.00011243030614575743
Trained batch 549 in epoch 19, gen_loss = 1.4805263135649942, disc_loss = 0.00011237108029242584
Trained batch 550 in epoch 19, gen_loss = 1.4803791303600027, disc_loss = 0.00011238314371558473
Trained batch 551 in epoch 19, gen_loss = 1.4803991276716841, disc_loss = 0.0001122876554231682
Trained batch 552 in epoch 19, gen_loss = 1.4804125715983496, disc_loss = 0.00011222935768972579
Trained batch 553 in epoch 19, gen_loss = 1.4803250462139557, disc_loss = 0.00011218616748095758
Trained batch 554 in epoch 19, gen_loss = 1.4802598753490963, disc_loss = 0.00011220936135319167
Trained batch 555 in epoch 19, gen_loss = 1.4800868801933398, disc_loss = 0.00011229377600324918
Trained batch 556 in epoch 19, gen_loss = 1.4799623681998124, disc_loss = 0.00011255241313543655
Trained batch 557 in epoch 19, gen_loss = 1.4798244400263687, disc_loss = 0.00011268491453198965
Trained batch 558 in epoch 19, gen_loss = 1.479741943543627, disc_loss = 0.00011268081210596026
Trained batch 559 in epoch 19, gen_loss = 1.4797589480876923, disc_loss = 0.00011261119827850052
Trained batch 560 in epoch 19, gen_loss = 1.4797470340116776, disc_loss = 0.00011257356426006979
Trained batch 561 in epoch 19, gen_loss = 1.4796726837276988, disc_loss = 0.00011255915705016727
Trained batch 562 in epoch 19, gen_loss = 1.4796133877752518, disc_loss = 0.00011256074305709272
Trained batch 563 in epoch 19, gen_loss = 1.4795055112517472, disc_loss = 0.00011252060122832846
Trained batch 564 in epoch 19, gen_loss = 1.4793985812009964, disc_loss = 0.00011248835206350653
Trained batch 565 in epoch 19, gen_loss = 1.4795224356988295, disc_loss = 0.00011241154220362352
Trained batch 566 in epoch 19, gen_loss = 1.4794017692512096, disc_loss = 0.00011233384849240727
Trained batch 567 in epoch 19, gen_loss = 1.4792310140082534, disc_loss = 0.00011228139761813918
Trained batch 568 in epoch 19, gen_loss = 1.4790921531787866, disc_loss = 0.00011238214607971581
Trained batch 569 in epoch 19, gen_loss = 1.4789704931409735, disc_loss = 0.00011253192536203546
Trained batch 570 in epoch 19, gen_loss = 1.4789068728111254, disc_loss = 0.00011252725503756359
Trained batch 571 in epoch 19, gen_loss = 1.4787518486276374, disc_loss = 0.0001126351870740249
Trained batch 572 in epoch 19, gen_loss = 1.478672214411524, disc_loss = 0.00011265258651417636
Trained batch 573 in epoch 19, gen_loss = 1.478586303232439, disc_loss = 0.00011261837265957922
Trained batch 574 in epoch 19, gen_loss = 1.4784488269557123, disc_loss = 0.00011252138549499922
Trained batch 575 in epoch 19, gen_loss = 1.4782580931981404, disc_loss = 0.00011243194370220206
Trained batch 576 in epoch 19, gen_loss = 1.478108418049804, disc_loss = 0.00011231446857877383
Trained batch 577 in epoch 19, gen_loss = 1.4780928754476528, disc_loss = 0.00011217604469965437
Trained batch 578 in epoch 19, gen_loss = 1.4780233878134035, disc_loss = 0.00011202514824790326
Trained batch 579 in epoch 19, gen_loss = 1.4778969705104827, disc_loss = 0.00011193235030642144
Trained batch 580 in epoch 19, gen_loss = 1.4778130466884671, disc_loss = 0.00011187416832944079
Trained batch 581 in epoch 19, gen_loss = 1.4776991060918958, disc_loss = 0.00011175544235830438
Trained batch 582 in epoch 19, gen_loss = 1.477549839183356, disc_loss = 0.00011164568618455032
Trained batch 583 in epoch 19, gen_loss = 1.4775325615112096, disc_loss = 0.00011156295866771559
Trained batch 584 in epoch 19, gen_loss = 1.477307482662364, disc_loss = 0.00011146324447594467
Trained batch 585 in epoch 19, gen_loss = 1.4773092176320204, disc_loss = 0.0001114611271142778
Trained batch 586 in epoch 19, gen_loss = 1.4773104915830102, disc_loss = 0.00011139361345816743
Trained batch 587 in epoch 19, gen_loss = 1.4773418645874983, disc_loss = 0.00011152513335051778
Trained batch 588 in epoch 19, gen_loss = 1.4771138010688873, disc_loss = 0.00011175466610012708
Trained batch 589 in epoch 19, gen_loss = 1.4770096782910622, disc_loss = 0.00011179692308175263
Trained batch 590 in epoch 19, gen_loss = 1.476982168134699, disc_loss = 0.00011189082228042742
Trained batch 591 in epoch 19, gen_loss = 1.4769682251923792, disc_loss = 0.00011195771436804707
Trained batch 592 in epoch 19, gen_loss = 1.4767421952387534, disc_loss = 0.0001119087138597751
Trained batch 593 in epoch 19, gen_loss = 1.4767324358525902, disc_loss = 0.00011203796220062867
Trained batch 594 in epoch 19, gen_loss = 1.4767218108938522, disc_loss = 0.00011209332003067893
Trained batch 595 in epoch 19, gen_loss = 1.4766494761777404, disc_loss = 0.00011216001189037929
Trained batch 596 in epoch 19, gen_loss = 1.476601271174062, disc_loss = 0.00011213964154107564
Trained batch 597 in epoch 19, gen_loss = 1.476480459289806, disc_loss = 0.00011207815214372407
Trained batch 598 in epoch 19, gen_loss = 1.476437854050396, disc_loss = 0.00011200344182215363
Trained batch 599 in epoch 19, gen_loss = 1.476336009502411, disc_loss = 0.00011193967682326426
Trained batch 600 in epoch 19, gen_loss = 1.4762920214610171, disc_loss = 0.00011185710095083662
Trained batch 601 in epoch 19, gen_loss = 1.4762185909027277, disc_loss = 0.00011175062011646868
Trained batch 602 in epoch 19, gen_loss = 1.4761699230516727, disc_loss = 0.00011162372232035129
Trained batch 603 in epoch 19, gen_loss = 1.4761917543727041, disc_loss = 0.00011151136238627048
Trained batch 604 in epoch 19, gen_loss = 1.4761864002085914, disc_loss = 0.00011138164980155666
Trained batch 605 in epoch 19, gen_loss = 1.4761616599441756, disc_loss = 0.00011128692797086145
Trained batch 606 in epoch 19, gen_loss = 1.476121131827843, disc_loss = 0.00011146529999066698
Trained batch 607 in epoch 19, gen_loss = 1.4758896868872016, disc_loss = 0.00011237964878318962
Trained batch 608 in epoch 19, gen_loss = 1.4758644693199245, disc_loss = 0.00011359895498692826
Trained batch 609 in epoch 19, gen_loss = 1.475684943941773, disc_loss = 0.0001141037782753167
Trained batch 610 in epoch 19, gen_loss = 1.475662861049858, disc_loss = 0.00011409344210621612
Trained batch 611 in epoch 19, gen_loss = 1.475575120036119, disc_loss = 0.00011406913428170073
Trained batch 612 in epoch 19, gen_loss = 1.4754997970229455, disc_loss = 0.00011423471202136364
Trained batch 613 in epoch 19, gen_loss = 1.475482309097576, disc_loss = 0.00011435980948898543
Trained batch 614 in epoch 19, gen_loss = 1.4754193141208432, disc_loss = 0.0001144261043881988
Trained batch 615 in epoch 19, gen_loss = 1.4753380868729058, disc_loss = 0.00011439776681249719
Trained batch 616 in epoch 19, gen_loss = 1.4753234156526662, disc_loss = 0.00011444469080336307
Trained batch 617 in epoch 19, gen_loss = 1.4752445573945647, disc_loss = 0.00011439840666467794
Trained batch 618 in epoch 19, gen_loss = 1.4752085170376088, disc_loss = 0.00011436633378167517
Trained batch 619 in epoch 19, gen_loss = 1.4752091469303255, disc_loss = 0.00011435851629064399
Trained batch 620 in epoch 19, gen_loss = 1.4751689760389344, disc_loss = 0.00011440503434884987
Trained batch 621 in epoch 19, gen_loss = 1.4751889880063833, disc_loss = 0.00011446585110508013
Trained batch 622 in epoch 19, gen_loss = 1.4751828491783447, disc_loss = 0.00011447434069027352
Trained batch 623 in epoch 19, gen_loss = 1.4752175853802607, disc_loss = 0.00011447590483944972
Trained batch 624 in epoch 19, gen_loss = 1.4751271535873414, disc_loss = 0.00011458959994779434
Trained batch 625 in epoch 19, gen_loss = 1.4749827691541313, disc_loss = 0.00011496390706947212
Trained batch 626 in epoch 19, gen_loss = 1.4748753324459996, disc_loss = 0.00011527501964739518
Trained batch 627 in epoch 19, gen_loss = 1.4748390656747636, disc_loss = 0.00011558762242978904
Trained batch 628 in epoch 19, gen_loss = 1.4747923862763543, disc_loss = 0.00011588482799495526
Trained batch 629 in epoch 19, gen_loss = 1.4748070805791824, disc_loss = 0.00011628092150146138
Trained batch 630 in epoch 19, gen_loss = 1.4747303656277302, disc_loss = 0.00011643504865170791
Trained batch 631 in epoch 19, gen_loss = 1.474558927024467, disc_loss = 0.00011655469572786709
Trained batch 632 in epoch 19, gen_loss = 1.4744734248090505, disc_loss = 0.00011655228266855801
Trained batch 633 in epoch 19, gen_loss = 1.4744512579794562, disc_loss = 0.00011648331818422681
Trained batch 634 in epoch 19, gen_loss = 1.4743717272450605, disc_loss = 0.00011645300631165251
Trained batch 635 in epoch 19, gen_loss = 1.4742070593923893, disc_loss = 0.00011644037425032148
Trained batch 636 in epoch 19, gen_loss = 1.4740894353558167, disc_loss = 0.00011639299802105194
Trained batch 637 in epoch 19, gen_loss = 1.4740462034099902, disc_loss = 0.0001163869717851167
Trained batch 638 in epoch 19, gen_loss = 1.4740214172476707, disc_loss = 0.0001164797516129552
Trained batch 639 in epoch 19, gen_loss = 1.473912670277059, disc_loss = 0.00011649885348958832
Trained batch 640 in epoch 19, gen_loss = 1.4739088718307185, disc_loss = 0.00011654379631353338
Trained batch 641 in epoch 19, gen_loss = 1.4738394207672167, disc_loss = 0.00011648398786942338
Trained batch 642 in epoch 19, gen_loss = 1.473864643977923, disc_loss = 0.00011643004540893453
Trained batch 643 in epoch 19, gen_loss = 1.4738648544927562, disc_loss = 0.00011630917888340162
Trained batch 644 in epoch 19, gen_loss = 1.473711541271949, disc_loss = 0.00011619863779946906
Trained batch 645 in epoch 19, gen_loss = 1.473622385562389, disc_loss = 0.00011608737265415351
Trained batch 646 in epoch 19, gen_loss = 1.473707247185744, disc_loss = 0.00011602605980110857
Trained batch 647 in epoch 19, gen_loss = 1.4735795822408464, disc_loss = 0.0001159639161139722
Trained batch 648 in epoch 19, gen_loss = 1.4735351424371517, disc_loss = 0.00011589735168197284
Trained batch 649 in epoch 19, gen_loss = 1.473409704061655, disc_loss = 0.00011582258121332136
Trained batch 650 in epoch 19, gen_loss = 1.4733640982808056, disc_loss = 0.00011578478134664533
Trained batch 651 in epoch 19, gen_loss = 1.4732107549357267, disc_loss = 0.00011575184854152709
Trained batch 652 in epoch 19, gen_loss = 1.4731570692193818, disc_loss = 0.0001157145949596834
Trained batch 653 in epoch 19, gen_loss = 1.4730730891592276, disc_loss = 0.00011570276679103644
Trained batch 654 in epoch 19, gen_loss = 1.4730347960959864, disc_loss = 0.00011565675435510894
Trained batch 655 in epoch 19, gen_loss = 1.4730616462666815, disc_loss = 0.00011559948717515398
Trained batch 656 in epoch 19, gen_loss = 1.472995266159557, disc_loss = 0.00011552545983771615
Trained batch 657 in epoch 19, gen_loss = 1.4729560715086916, disc_loss = 0.0001154720962030902
Trained batch 658 in epoch 19, gen_loss = 1.47288645760966, disc_loss = 0.00011537193964829132
Trained batch 659 in epoch 19, gen_loss = 1.4727802804022125, disc_loss = 0.00011525885846078216
Trained batch 660 in epoch 19, gen_loss = 1.47270548253485, disc_loss = 0.0001151767907015926
Trained batch 661 in epoch 19, gen_loss = 1.4726391702980433, disc_loss = 0.00011506260912536993
Trained batch 662 in epoch 19, gen_loss = 1.4724640312237978, disc_loss = 0.00011498918520291684
Trained batch 663 in epoch 19, gen_loss = 1.4723711669085973, disc_loss = 0.00011491225458244062
Trained batch 664 in epoch 19, gen_loss = 1.4723549471761948, disc_loss = 0.00011484830178151037
Trained batch 665 in epoch 19, gen_loss = 1.472227320835755, disc_loss = 0.00011476973975584622
Trained batch 666 in epoch 19, gen_loss = 1.4722463332194795, disc_loss = 0.00011475581753359932
Trained batch 667 in epoch 19, gen_loss = 1.4721071475637173, disc_loss = 0.00011472813918668387
Trained batch 668 in epoch 19, gen_loss = 1.4720023400045832, disc_loss = 0.00011466181726273312
Trained batch 669 in epoch 19, gen_loss = 1.4719204918662114, disc_loss = 0.00011454584901953036
Trained batch 670 in epoch 19, gen_loss = 1.4719092947182464, disc_loss = 0.0001144409913924877
Trained batch 671 in epoch 19, gen_loss = 1.4718347135044278, disc_loss = 0.00011434777297024214
Trained batch 672 in epoch 19, gen_loss = 1.4717499313524538, disc_loss = 0.00011421177307872744
Trained batch 673 in epoch 19, gen_loss = 1.4716765059915424, disc_loss = 0.0001141051862255248
Trained batch 674 in epoch 19, gen_loss = 1.4715862706855491, disc_loss = 0.0001140032671995599
Trained batch 675 in epoch 19, gen_loss = 1.4714568657635232, disc_loss = 0.00011390417426196513
Trained batch 676 in epoch 19, gen_loss = 1.4713583536655195, disc_loss = 0.0001138424285026931
Trained batch 677 in epoch 19, gen_loss = 1.471285903172507, disc_loss = 0.00011383828442379081
Trained batch 678 in epoch 19, gen_loss = 1.4712302725164108, disc_loss = 0.00011385860868434927
Trained batch 679 in epoch 19, gen_loss = 1.4710949906531503, disc_loss = 0.00011383568413186688
Trained batch 680 in epoch 19, gen_loss = 1.471074214765854, disc_loss = 0.00011377434078649284
Trained batch 681 in epoch 19, gen_loss = 1.4711323785991612, disc_loss = 0.00011376882372943778
Trained batch 682 in epoch 19, gen_loss = 1.4711316415540994, disc_loss = 0.00011410097892780169
Trained batch 683 in epoch 19, gen_loss = 1.4710302521959382, disc_loss = 0.0001146836830655808
Trained batch 684 in epoch 19, gen_loss = 1.4708929909406787, disc_loss = 0.00011511328911096925
Trained batch 685 in epoch 19, gen_loss = 1.4707622064098325, disc_loss = 0.00011526924287755234
Trained batch 686 in epoch 19, gen_loss = 1.4707269528026665, disc_loss = 0.00011530690096655766
Trained batch 687 in epoch 19, gen_loss = 1.4706145821269168, disc_loss = 0.00011523528712322606
Trained batch 688 in epoch 19, gen_loss = 1.4704992137903399, disc_loss = 0.00011513521627112257
Trained batch 689 in epoch 19, gen_loss = 1.4704478775245555, disc_loss = 0.0001150925564708313
Trained batch 690 in epoch 19, gen_loss = 1.4704437524985992, disc_loss = 0.00011503312054704962
Trained batch 691 in epoch 19, gen_loss = 1.4703361898488392, disc_loss = 0.00011517753199048541
Trained batch 692 in epoch 19, gen_loss = 1.4702487052089037, disc_loss = 0.00011522044206642368
Trained batch 693 in epoch 19, gen_loss = 1.4702256409510412, disc_loss = 0.00011531515577553889
Trained batch 694 in epoch 19, gen_loss = 1.4700987884466596, disc_loss = 0.00011532928061478088
Trained batch 695 in epoch 19, gen_loss = 1.4700704617746945, disc_loss = 0.0001152706259253837
Trained batch 696 in epoch 19, gen_loss = 1.4700821017261214, disc_loss = 0.0001151981702045764
Trained batch 697 in epoch 19, gen_loss = 1.4700919604916285, disc_loss = 0.00011511455704749096
Trained batch 698 in epoch 19, gen_loss = 1.4700170151665486, disc_loss = 0.00011505923720010229
Trained batch 699 in epoch 19, gen_loss = 1.4699185413973672, disc_loss = 0.00011498145496131786
Trained batch 700 in epoch 19, gen_loss = 1.4698085903951343, disc_loss = 0.00011489259628750072
Trained batch 701 in epoch 19, gen_loss = 1.4697859536888254, disc_loss = 0.00011480784755842919
Trained batch 702 in epoch 19, gen_loss = 1.4696218596074524, disc_loss = 0.00011470736484583978
Trained batch 703 in epoch 19, gen_loss = 1.4695380518043584, disc_loss = 0.00011459470920788755
Trained batch 704 in epoch 19, gen_loss = 1.4693558298949654, disc_loss = 0.00011447524246392302
Trained batch 705 in epoch 19, gen_loss = 1.469333467841486, disc_loss = 0.00011439458607226377
Trained batch 706 in epoch 19, gen_loss = 1.4692467201548554, disc_loss = 0.00011430995043324665
Trained batch 707 in epoch 19, gen_loss = 1.4691565594093947, disc_loss = 0.00011424143127123641
Trained batch 708 in epoch 19, gen_loss = 1.4690561842683003, disc_loss = 0.00011415337811187875
Trained batch 709 in epoch 19, gen_loss = 1.4689435777529865, disc_loss = 0.00011402968643971024
Trained batch 710 in epoch 19, gen_loss = 1.469010362142249, disc_loss = 0.00011392926999421642
Trained batch 711 in epoch 19, gen_loss = 1.4690120287155837, disc_loss = 0.00011380545908415636
Trained batch 712 in epoch 19, gen_loss = 1.468963623046875, disc_loss = 0.00011369509816323708
Trained batch 713 in epoch 19, gen_loss = 1.4689440623718817, disc_loss = 0.00011357206560195478
Trained batch 714 in epoch 19, gen_loss = 1.4688413553304605, disc_loss = 0.00011345447751950274
Trained batch 715 in epoch 19, gen_loss = 1.468765839351622, disc_loss = 0.00011334199575050367
Trained batch 716 in epoch 19, gen_loss = 1.4687356770953042, disc_loss = 0.00011323011781752185
Trained batch 717 in epoch 19, gen_loss = 1.4686826054100206, disc_loss = 0.00011314959524662353
Trained batch 718 in epoch 19, gen_loss = 1.468601849215087, disc_loss = 0.00011305831224658486
Trained batch 719 in epoch 19, gen_loss = 1.4686050795846515, disc_loss = 0.00011302018928947494
Trained batch 720 in epoch 19, gen_loss = 1.4684823696887774, disc_loss = 0.00011295984488328317
Trained batch 721 in epoch 19, gen_loss = 1.4684024061852876, disc_loss = 0.00011295737665206812
Trained batch 722 in epoch 19, gen_loss = 1.468311690195962, disc_loss = 0.00011293328723816358
Trained batch 723 in epoch 19, gen_loss = 1.4682335028661548, disc_loss = 0.00011285920657513928
Trained batch 724 in epoch 19, gen_loss = 1.4681631126074954, disc_loss = 0.00011277230642886495
Trained batch 725 in epoch 19, gen_loss = 1.4681298860833665, disc_loss = 0.0001126605312059306
Trained batch 726 in epoch 19, gen_loss = 1.4680095458457034, disc_loss = 0.00011256062141390234
Trained batch 727 in epoch 19, gen_loss = 1.4679934472500622, disc_loss = 0.0001124608876540191
Trained batch 728 in epoch 19, gen_loss = 1.467929913673872, disc_loss = 0.00011235039888705725
Trained batch 729 in epoch 19, gen_loss = 1.4678460553900836, disc_loss = 0.00011225171782240218
Trained batch 730 in epoch 19, gen_loss = 1.4678264665538407, disc_loss = 0.00011213786384296538
Trained batch 731 in epoch 19, gen_loss = 1.467783251583902, disc_loss = 0.00011202713305534874
Trained batch 732 in epoch 19, gen_loss = 1.4676672169814169, disc_loss = 0.00011191733220506696
Trained batch 733 in epoch 19, gen_loss = 1.467646219587456, disc_loss = 0.0001118134773072751
Trained batch 734 in epoch 19, gen_loss = 1.4675375082054916, disc_loss = 0.00011170190493405962
Trained batch 735 in epoch 19, gen_loss = 1.4673861023848471, disc_loss = 0.00011160795709795069
Trained batch 736 in epoch 19, gen_loss = 1.4673849596582564, disc_loss = 0.00011153097419050684
Trained batch 737 in epoch 19, gen_loss = 1.4673735602761349, disc_loss = 0.00011146940815881328
Trained batch 738 in epoch 19, gen_loss = 1.4672578392557911, disc_loss = 0.00011137124708434157
Trained batch 739 in epoch 19, gen_loss = 1.467174993173496, disc_loss = 0.0001112982730577445
Trained batch 740 in epoch 19, gen_loss = 1.4671393497752758, disc_loss = 0.00011120387079049966
Trained batch 741 in epoch 19, gen_loss = 1.4670018887905418, disc_loss = 0.00011113234869468201
Trained batch 742 in epoch 19, gen_loss = 1.466889808508461, disc_loss = 0.00011107727497671781
Trained batch 743 in epoch 19, gen_loss = 1.4668319135583856, disc_loss = 0.00011101739990467209
Trained batch 744 in epoch 19, gen_loss = 1.466789347373399, disc_loss = 0.00011098883643604959
Trained batch 745 in epoch 19, gen_loss = 1.4666922300175111, disc_loss = 0.00011097549621621116
Testing Epoch 19
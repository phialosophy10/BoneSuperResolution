/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 2.8657898902893066, disc_loss = 0.7025480270385742
Trained batch 1 in epoch 0, gen_loss = 2.648480772972107, disc_loss = 0.6662629544734955
Trained batch 2 in epoch 0, gen_loss = 2.808587153752645, disc_loss = 0.8275380730628967
Trained batch 3 in epoch 0, gen_loss = 2.7733660340309143, disc_loss = 0.7294413968920708
Trained batch 4 in epoch 0, gen_loss = 2.6674299240112305, disc_loss = 0.6715214788913727
Trained batch 5 in epoch 0, gen_loss = 2.6624532540639243, disc_loss = 0.6148848086595535
Trained batch 6 in epoch 0, gen_loss = 2.5864374297005788, disc_loss = 0.5694877803325653
Trained batch 7 in epoch 0, gen_loss = 2.5196609497070312, disc_loss = 0.5318209417164326
Trained batch 8 in epoch 0, gen_loss = 2.4486496580971613, disc_loss = 0.497756905025906
Trained batch 9 in epoch 0, gen_loss = 2.4012267708778383, disc_loss = 0.46863666772842405
Trained batch 10 in epoch 0, gen_loss = 2.3828458460894497, disc_loss = 0.4425091784108769
Trained batch 11 in epoch 0, gen_loss = 2.383193681637446, disc_loss = 0.41888512422641117
Trained batch 12 in epoch 0, gen_loss = 2.350281101006728, disc_loss = 0.3985387831926346
Trained batch 13 in epoch 0, gen_loss = 2.3572379095213756, disc_loss = 0.38188760195459637
Trained batch 14 in epoch 0, gen_loss = 2.3590018510818482, disc_loss = 0.3673782338698705
Trained batch 15 in epoch 0, gen_loss = 2.3483283445239067, disc_loss = 0.3584179664030671
Trained batch 16 in epoch 0, gen_loss = 2.337226720417247, disc_loss = 0.3545395074521794
Trained batch 17 in epoch 0, gen_loss = 2.3451155622800193, disc_loss = 0.34771432479222614
Trained batch 18 in epoch 0, gen_loss = 2.3520120131342033, disc_loss = 0.3373363065092187
Trained batch 19 in epoch 0, gen_loss = 2.3403890073299407, disc_loss = 0.326338367909193
Trained batch 20 in epoch 0, gen_loss = 2.3500171332132247, disc_loss = 0.3165495306963012
Trained batch 21 in epoch 0, gen_loss = 2.360386897217144, disc_loss = 0.30644015392119234
Trained batch 22 in epoch 0, gen_loss = 2.3412056072898535, disc_loss = 0.2975782308241595
Trained batch 23 in epoch 0, gen_loss = 2.333065023024877, disc_loss = 0.289403408455352
Trained batch 24 in epoch 0, gen_loss = 2.322267084121704, disc_loss = 0.2821580424904823
Trained batch 25 in epoch 0, gen_loss = 2.3207426162866445, disc_loss = 0.2749654303949613
Trained batch 26 in epoch 0, gen_loss = 2.330771728798195, disc_loss = 0.2692242940818822
Trained batch 27 in epoch 0, gen_loss = 2.344826817512512, disc_loss = 0.264707675203681
Trained batch 28 in epoch 0, gen_loss = 2.354093050134593, disc_loss = 0.2624451515489611
Trained batch 29 in epoch 0, gen_loss = 2.354452602068583, disc_loss = 0.2605334686736266
Trained batch 30 in epoch 0, gen_loss = 2.350635059418217, disc_loss = 0.25586731587686845
Trained batch 31 in epoch 0, gen_loss = 2.338648896664381, disc_loss = 0.2506806394085288
Trained batch 32 in epoch 0, gen_loss = 2.343384623527527, disc_loss = 0.24579624763943933
Trained batch 33 in epoch 0, gen_loss = 2.3409827281447018, disc_loss = 0.24117070655612385
Trained batch 34 in epoch 0, gen_loss = 2.34237152167729, disc_loss = 0.23630693235567637
Trained batch 35 in epoch 0, gen_loss = 2.3363466693295374, disc_loss = 0.23258312770889866
Trained batch 36 in epoch 0, gen_loss = 2.339144606848021, disc_loss = 0.2288120006387298
Trained batch 37 in epoch 0, gen_loss = 2.342276475931469, disc_loss = 0.22436162819595715
Trained batch 38 in epoch 0, gen_loss = 2.3430652893506565, disc_loss = 0.21996398031329498
Trained batch 39 in epoch 0, gen_loss = 2.344571629166603, disc_loss = 0.2159626609645784
Trained batch 40 in epoch 0, gen_loss = 2.3384246971549056, disc_loss = 0.21255266275711177
Trained batch 41 in epoch 0, gen_loss = 2.3323321030253457, disc_loss = 0.21013404650702364
Trained batch 42 in epoch 0, gen_loss = 2.3339478387389074, disc_loss = 0.2079100289143795
Trained batch 43 in epoch 0, gen_loss = 2.335342675447464, disc_loss = 0.20629000926220958
Trained batch 44 in epoch 0, gen_loss = 2.3411214060253567, disc_loss = 0.20506430657373534
Trained batch 45 in epoch 0, gen_loss = 2.346951917461727, disc_loss = 0.20417646440150944
Trained batch 46 in epoch 0, gen_loss = 2.344179267578937, disc_loss = 0.2027801572483905
Trained batch 47 in epoch 0, gen_loss = 2.3451512778798738, disc_loss = 0.20123546128161252
Trained batch 48 in epoch 0, gen_loss = 2.349270239168284, disc_loss = 0.20016284674710158
Trained batch 49 in epoch 0, gen_loss = 2.3433064341545107, disc_loss = 0.19787740789353847
Trained batch 50 in epoch 0, gen_loss = 2.3388575315475464, disc_loss = 0.1950516571455142
Trained batch 51 in epoch 0, gen_loss = 2.3411976534586687, disc_loss = 0.19214847031980753
Trained batch 52 in epoch 0, gen_loss = 2.3435578593667947, disc_loss = 0.18918542381165163
Trained batch 53 in epoch 0, gen_loss = 2.354284973056228, disc_loss = 0.1862183164253279
Trained batch 54 in epoch 0, gen_loss = 2.3511077252301305, disc_loss = 0.18335462300614877
Trained batch 55 in epoch 0, gen_loss = 2.3537827794040953, disc_loss = 0.18048390832596592
Trained batch 56 in epoch 0, gen_loss = 2.3564410356053136, disc_loss = 0.17787080983582296
Trained batch 57 in epoch 0, gen_loss = 2.356365407335347, disc_loss = 0.17532246794294695
Trained batch 58 in epoch 0, gen_loss = 2.3556521201537826, disc_loss = 0.17294790358992956
Trained batch 59 in epoch 0, gen_loss = 2.3589469532171887, disc_loss = 0.17048819155121844
Trained batch 60 in epoch 0, gen_loss = 2.3600728961287953, disc_loss = 0.16811063418500735
Trained batch 61 in epoch 0, gen_loss = 2.3558597314742302, disc_loss = 0.16576400276033149
Trained batch 62 in epoch 0, gen_loss = 2.355753945925879, disc_loss = 0.16348697697477682
Trained batch 63 in epoch 0, gen_loss = 2.361094309017062, disc_loss = 0.1612605404225178
Trained batch 64 in epoch 0, gen_loss = 2.3587652591558603, disc_loss = 0.15907868553812687
Trained batch 65 in epoch 0, gen_loss = 2.3610128290725476, disc_loss = 0.1569926277028792
Trained batch 66 in epoch 0, gen_loss = 2.370649730981286, disc_loss = 0.1550979675419295
Trained batch 67 in epoch 0, gen_loss = 2.3750966243884144, disc_loss = 0.1532206637237002
Trained batch 68 in epoch 0, gen_loss = 2.3797887321831523, disc_loss = 0.15124836558665056
Trained batch 69 in epoch 0, gen_loss = 2.383404208932604, disc_loss = 0.14940398532365048
Trained batch 70 in epoch 0, gen_loss = 2.3830965992430566, disc_loss = 0.14760147423391612
Trained batch 71 in epoch 0, gen_loss = 2.383454751637247, disc_loss = 0.14596701410806012
Trained batch 72 in epoch 0, gen_loss = 2.3880641640049136, disc_loss = 0.14431578295994296
Trained batch 73 in epoch 0, gen_loss = 2.3872247016107715, disc_loss = 0.1427506087599574
Trained batch 74 in epoch 0, gen_loss = 2.389342563947042, disc_loss = 0.1412920167048772
Trained batch 75 in epoch 0, gen_loss = 2.3933964387366644, disc_loss = 0.1396905094581215
Trained batch 76 in epoch 0, gen_loss = 2.3902750185557773, disc_loss = 0.138115839452132
Trained batch 77 in epoch 0, gen_loss = 2.394508656782982, disc_loss = 0.13662754885183695
Trained batch 78 in epoch 0, gen_loss = 2.3941763126397433, disc_loss = 0.13514355765773525
Trained batch 79 in epoch 0, gen_loss = 2.3974027588963507, disc_loss = 0.1336301663890481
Trained batch 80 in epoch 0, gen_loss = 2.3980703604074174, disc_loss = 0.1321556121110916
Trained batch 81 in epoch 0, gen_loss = 2.40075330472574, disc_loss = 0.130752053407089
Trained batch 82 in epoch 0, gen_loss = 2.399237542267305, disc_loss = 0.12935770689004875
Trained batch 83 in epoch 0, gen_loss = 2.39919256738254, disc_loss = 0.12803935818374157
Trained batch 84 in epoch 0, gen_loss = 2.4009662361706003, disc_loss = 0.126699346961344
Trained batch 85 in epoch 0, gen_loss = 2.4016415005506473, disc_loss = 0.1254051919311805
Trained batch 86 in epoch 0, gen_loss = 2.403854864767228, disc_loss = 0.12418079225282216
Trained batch 87 in epoch 0, gen_loss = 2.405836068771102, disc_loss = 0.12299841408490796
Trained batch 88 in epoch 0, gen_loss = 2.4086255558421104, disc_loss = 0.12182902870176548
Trained batch 89 in epoch 0, gen_loss = 2.4081360061963397, disc_loss = 0.1206607385745479
Trained batch 90 in epoch 0, gen_loss = 2.409497110398261, disc_loss = 0.11951967739182842
Trained batch 91 in epoch 0, gen_loss = 2.4112499084161674, disc_loss = 0.11839351492286053
Trained batch 92 in epoch 0, gen_loss = 2.411429624403677, disc_loss = 0.11728176940232515
Trained batch 93 in epoch 0, gen_loss = 2.408889015938373, disc_loss = 0.11623613850431556
Trained batch 94 in epoch 0, gen_loss = 2.409874119256672, disc_loss = 0.11521754085429405
Trained batch 95 in epoch 0, gen_loss = 2.413296204060316, disc_loss = 0.11421842928393744
Trained batch 96 in epoch 0, gen_loss = 2.414700902614397, disc_loss = 0.11319195699023525
Trained batch 97 in epoch 0, gen_loss = 2.414727968829019, disc_loss = 0.11219205653142868
Trained batch 98 in epoch 0, gen_loss = 2.4133756630348437, disc_loss = 0.11130157917399298
Trained batch 99 in epoch 0, gen_loss = 2.411912945508957, disc_loss = 0.11047232043929398
Trained batch 100 in epoch 0, gen_loss = 2.409472655541826, disc_loss = 0.10958698337510375
Trained batch 101 in epoch 0, gen_loss = 2.4134858577859166, disc_loss = 0.1086553492784208
Trained batch 102 in epoch 0, gen_loss = 2.41210924884648, disc_loss = 0.10773077965216729
Trained batch 103 in epoch 0, gen_loss = 2.4118868788847556, disc_loss = 0.10680420857925828
Trained batch 104 in epoch 0, gen_loss = 2.4126642579124087, disc_loss = 0.10590646203075137
Trained batch 105 in epoch 0, gen_loss = 2.412467253658007, disc_loss = 0.10501927224356893
Trained batch 106 in epoch 0, gen_loss = 2.411694336160321, disc_loss = 0.10412628138350828
Trained batch 107 in epoch 0, gen_loss = 2.4145898785856037, disc_loss = 0.10326751567319864
Trained batch 108 in epoch 0, gen_loss = 2.412535276981669, disc_loss = 0.1024657169596181
Trained batch 109 in epoch 0, gen_loss = 2.4123451937328686, disc_loss = 0.10165590500797737
Trained batch 110 in epoch 0, gen_loss = 2.4090479118329986, disc_loss = 0.10086161876516836
Trained batch 111 in epoch 0, gen_loss = 2.4070795934115137, disc_loss = 0.10017476932677839
Trained batch 112 in epoch 0, gen_loss = 2.409517238625383, disc_loss = 0.09943820358113906
Trained batch 113 in epoch 0, gen_loss = 2.4092380007108054, disc_loss = 0.09868745708413292
Trained batch 114 in epoch 0, gen_loss = 2.408586874215499, disc_loss = 0.09794945183979428
Trained batch 115 in epoch 0, gen_loss = 2.4104054703794677, disc_loss = 0.09719003824485016
Trained batch 116 in epoch 0, gen_loss = 2.410713502484509, disc_loss = 0.09644915154760975
Trained batch 117 in epoch 0, gen_loss = 2.410616065486003, disc_loss = 0.0957420353335723
Trained batch 118 in epoch 0, gen_loss = 2.411536588388331, disc_loss = 0.0950646160107826
Trained batch 119 in epoch 0, gen_loss = 2.4112991084655127, disc_loss = 0.09438620194947968
Trained batch 120 in epoch 0, gen_loss = 2.4091975915530495, disc_loss = 0.09372207490065373
Trained batch 121 in epoch 0, gen_loss = 2.4055190477214876, disc_loss = 0.09309917103621315
Trained batch 122 in epoch 0, gen_loss = 2.405845766145039, disc_loss = 0.09248844132857109
Trained batch 123 in epoch 0, gen_loss = 2.404969330756895, disc_loss = 0.0918827366023775
Trained batch 124 in epoch 0, gen_loss = 2.4074249000549317, disc_loss = 0.09140027129650116
Trained batch 125 in epoch 0, gen_loss = 2.405828250779046, disc_loss = 0.09095241561058968
Trained batch 126 in epoch 0, gen_loss = 2.405747652053833, disc_loss = 0.09046375722162367
Trained batch 127 in epoch 0, gen_loss = 2.4048552811145782, disc_loss = 0.0899728176445933
Trained batch 128 in epoch 0, gen_loss = 2.4050111068311586, disc_loss = 0.08945461879520453
Trained batch 129 in epoch 0, gen_loss = 2.4079092759352463, disc_loss = 0.08897860053067023
Trained batch 130 in epoch 0, gen_loss = 2.404979964249007, disc_loss = 0.08851423626410142
Trained batch 131 in epoch 0, gen_loss = 2.4048331289580376, disc_loss = 0.08797376156982148
Trained batch 132 in epoch 0, gen_loss = 2.403947129285425, disc_loss = 0.08745943557443027
Trained batch 133 in epoch 0, gen_loss = 2.403666837891536, disc_loss = 0.08696049058448467
Trained batch 134 in epoch 0, gen_loss = 2.404774883058336, disc_loss = 0.08644335867354164
Trained batch 135 in epoch 0, gen_loss = 2.40594746260082, disc_loss = 0.085979457355707
Trained batch 136 in epoch 0, gen_loss = 2.404320930912547, disc_loss = 0.0856111364126423
Trained batch 137 in epoch 0, gen_loss = 2.4070986198342363, disc_loss = 0.08523144344866708
Trained batch 138 in epoch 0, gen_loss = 2.406779222351184, disc_loss = 0.0849460269719791
Trained batch 139 in epoch 0, gen_loss = 2.4070567658969333, disc_loss = 0.08458945662049311
Trained batch 140 in epoch 0, gen_loss = 2.406166617751967, disc_loss = 0.08412245215834878
Trained batch 141 in epoch 0, gen_loss = 2.404268523337136, disc_loss = 0.08371700557657111
Trained batch 142 in epoch 0, gen_loss = 2.4078527964078464, disc_loss = 0.0834114316434085
Trained batch 143 in epoch 0, gen_loss = 2.408648931317859, disc_loss = 0.08296100048917449
Trained batch 144 in epoch 0, gen_loss = 2.4085623774035225, disc_loss = 0.08259322942587836
Trained batch 145 in epoch 0, gen_loss = 2.4082382901074135, disc_loss = 0.08216011853352802
Trained batch 146 in epoch 0, gen_loss = 2.4093125466586782, disc_loss = 0.08173908829232868
Trained batch 147 in epoch 0, gen_loss = 2.4097225150546513, disc_loss = 0.08135519938140705
Trained batch 148 in epoch 0, gen_loss = 2.4095986257463493, disc_loss = 0.08094308817846663
Trained batch 149 in epoch 0, gen_loss = 2.411358453432719, disc_loss = 0.08050287079066037
Trained batch 150 in epoch 0, gen_loss = 2.412242748879439, disc_loss = 0.08006864878663558
Trained batch 151 in epoch 0, gen_loss = 2.412179647307647, disc_loss = 0.07962835823970013
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 2.020554304122925, disc_loss = 0.01607920229434967
Trained batch 1 in epoch 1, gen_loss = 2.27601420879364, disc_loss = 0.016132828779518604
Trained batch 2 in epoch 1, gen_loss = 2.371365785598755, disc_loss = 0.01722229706744353
Trained batch 3 in epoch 1, gen_loss = 2.3843886852264404, disc_loss = 0.01583620742894709
Trained batch 4 in epoch 1, gen_loss = 2.3573142528533935, disc_loss = 0.01534848790615797
Trained batch 5 in epoch 1, gen_loss = 2.3625274499257407, disc_loss = 0.01567100655908386
Trained batch 6 in epoch 1, gen_loss = 2.354142802102225, disc_loss = 0.015364842223269599
Trained batch 7 in epoch 1, gen_loss = 2.3449884951114655, disc_loss = 0.015206804731860757
Trained batch 8 in epoch 1, gen_loss = 2.3820619848039417, disc_loss = 0.015622066747811105
Trained batch 9 in epoch 1, gen_loss = 2.3737215995788574, disc_loss = 0.01558051398023963
Trained batch 10 in epoch 1, gen_loss = 2.36450702493841, disc_loss = 0.015452195043590937
Trained batch 11 in epoch 1, gen_loss = 2.3569100300470986, disc_loss = 0.015828022655720513
Trained batch 12 in epoch 1, gen_loss = 2.3597718752347507, disc_loss = 0.01564620055544835
Trained batch 13 in epoch 1, gen_loss = 2.357267584119524, disc_loss = 0.015418208137686764
Trained batch 14 in epoch 1, gen_loss = 2.3521744569142657, disc_loss = 0.015522057625154654
Trained batch 15 in epoch 1, gen_loss = 2.3675048798322678, disc_loss = 0.01535667950520292
Trained batch 16 in epoch 1, gen_loss = 2.3776521262000587, disc_loss = 0.015171097481951994
Trained batch 17 in epoch 1, gen_loss = 2.3749803172217474, disc_loss = 0.015457553478578726
Trained batch 18 in epoch 1, gen_loss = 2.3797838060479415, disc_loss = 0.01532061981331361
Trained batch 19 in epoch 1, gen_loss = 2.3735451221466066, disc_loss = 0.015067417547106743
Trained batch 20 in epoch 1, gen_loss = 2.391073783238729, disc_loss = 0.014861203996198518
Trained batch 21 in epoch 1, gen_loss = 2.3876184441826562, disc_loss = 0.014656140934675932
Trained batch 22 in epoch 1, gen_loss = 2.4008065617602803, disc_loss = 0.014583314728477726
Trained batch 23 in epoch 1, gen_loss = 2.396036773920059, disc_loss = 0.01452327884423236
Trained batch 24 in epoch 1, gen_loss = 2.401227560043335, disc_loss = 0.014459748938679694
Trained batch 25 in epoch 1, gen_loss = 2.4050131210914025, disc_loss = 0.014358240752839126
Trained batch 26 in epoch 1, gen_loss = 2.4012624246102794, disc_loss = 0.014319139705212027
Trained batch 27 in epoch 1, gen_loss = 2.3960009472710744, disc_loss = 0.014296674302646093
Trained batch 28 in epoch 1, gen_loss = 2.3957611199083, disc_loss = 0.014285724867006829
Trained batch 29 in epoch 1, gen_loss = 2.3981826146443685, disc_loss = 0.014173867305119832
Trained batch 30 in epoch 1, gen_loss = 2.3866090543808474, disc_loss = 0.014174119599403874
Trained batch 31 in epoch 1, gen_loss = 2.3942661806941032, disc_loss = 0.01417129667242989
Trained batch 32 in epoch 1, gen_loss = 2.389191844246604, disc_loss = 0.014291336590593512
Trained batch 33 in epoch 1, gen_loss = 2.398958683013916, disc_loss = 0.014330089448348564
Trained batch 34 in epoch 1, gen_loss = 2.3898247718811034, disc_loss = 0.014367495716682502
Trained batch 35 in epoch 1, gen_loss = 2.3776743047767215, disc_loss = 0.014333209747241603
Trained batch 36 in epoch 1, gen_loss = 2.383443539207046, disc_loss = 0.014375761956781955
Trained batch 37 in epoch 1, gen_loss = 2.3726387337634436, disc_loss = 0.014388983137905598
Trained batch 38 in epoch 1, gen_loss = 2.3672718145908456, disc_loss = 0.014301778223270025
Trained batch 39 in epoch 1, gen_loss = 2.368243384361267, disc_loss = 0.014383091079071163
Trained batch 40 in epoch 1, gen_loss = 2.369722645457198, disc_loss = 0.014361445701158628
Trained batch 41 in epoch 1, gen_loss = 2.3749493019921437, disc_loss = 0.014413696602873859
Trained batch 42 in epoch 1, gen_loss = 2.377435329348542, disc_loss = 0.014342585188704867
Trained batch 43 in epoch 1, gen_loss = 2.3729701313105496, disc_loss = 0.01425700395537371
Trained batch 44 in epoch 1, gen_loss = 2.381620995203654, disc_loss = 0.014257748735447724
Trained batch 45 in epoch 1, gen_loss = 2.3764651391817178, disc_loss = 0.014196263565479414
Trained batch 46 in epoch 1, gen_loss = 2.3702335357666016, disc_loss = 0.014197574809510657
Trained batch 47 in epoch 1, gen_loss = 2.3679086416959763, disc_loss = 0.014129799286214014
Trained batch 48 in epoch 1, gen_loss = 2.3647235996869145, disc_loss = 0.014114231669477053
Trained batch 49 in epoch 1, gen_loss = 2.3672986936569216, disc_loss = 0.014084640629589558
Trained batch 50 in epoch 1, gen_loss = 2.370513490602082, disc_loss = 0.014068159585197767
Trained batch 51 in epoch 1, gen_loss = 2.361884818627284, disc_loss = 0.014101977495906444
Trained batch 52 in epoch 1, gen_loss = 2.363846167078558, disc_loss = 0.014173555381174357
Trained batch 53 in epoch 1, gen_loss = 2.3684531626877963, disc_loss = 0.014335552299464191
Trained batch 54 in epoch 1, gen_loss = 2.3652073600075463, disc_loss = 0.01434172164987434
Trained batch 55 in epoch 1, gen_loss = 2.3587477122034346, disc_loss = 0.014392376045829483
Trained batch 56 in epoch 1, gen_loss = 2.359710266715602, disc_loss = 0.014542602100654653
Trained batch 57 in epoch 1, gen_loss = 2.3623840027842027, disc_loss = 0.01465910682775851
Trained batch 58 in epoch 1, gen_loss = 2.3591885849580927, disc_loss = 0.014752450067613084
Trained batch 59 in epoch 1, gen_loss = 2.3624635100364686, disc_loss = 0.014771797135472298
Trained batch 60 in epoch 1, gen_loss = 2.373345793270674, disc_loss = 0.014761016551466262
Trained batch 61 in epoch 1, gen_loss = 2.3736366802646267, disc_loss = 0.01477947111632074
Trained batch 62 in epoch 1, gen_loss = 2.372839575722104, disc_loss = 0.014746096561707202
Trained batch 63 in epoch 1, gen_loss = 2.377214904874563, disc_loss = 0.014760633479454555
Trained batch 64 in epoch 1, gen_loss = 2.378512584246122, disc_loss = 0.014904380632707706
Trained batch 65 in epoch 1, gen_loss = 2.3789563106768057, disc_loss = 0.015157233909562681
Trained batch 66 in epoch 1, gen_loss = 2.3790766374388737, disc_loss = 0.015316538832414506
Trained batch 67 in epoch 1, gen_loss = 2.3830304987290325, disc_loss = 0.015536996083991492
Trained batch 68 in epoch 1, gen_loss = 2.3853510946467305, disc_loss = 0.01553324894790632
Trained batch 69 in epoch 1, gen_loss = 2.381000883238656, disc_loss = 0.0156723211253328
Trained batch 70 in epoch 1, gen_loss = 2.386547481510001, disc_loss = 0.015702414929761852
Trained batch 71 in epoch 1, gen_loss = 2.386071036259333, disc_loss = 0.01570491494041764
Trained batch 72 in epoch 1, gen_loss = 2.3894919271338475, disc_loss = 0.01563625902651924
Trained batch 73 in epoch 1, gen_loss = 2.387773968077995, disc_loss = 0.015536488939982813
Trained batch 74 in epoch 1, gen_loss = 2.3835722478230794, disc_loss = 0.015481515477101008
Trained batch 75 in epoch 1, gen_loss = 2.3793492003491052, disc_loss = 0.015411454461220848
Trained batch 76 in epoch 1, gen_loss = 2.378562561877362, disc_loss = 0.015351878346077033
Trained batch 77 in epoch 1, gen_loss = 2.3763246689087305, disc_loss = 0.0152661022849572
Trained batch 78 in epoch 1, gen_loss = 2.3729536895510517, disc_loss = 0.015176139701204964
Trained batch 79 in epoch 1, gen_loss = 2.372920635342598, disc_loss = 0.01506783205550164
Trained batch 80 in epoch 1, gen_loss = 2.374152887014695, disc_loss = 0.0149679274217766
Trained batch 81 in epoch 1, gen_loss = 2.3713464649712166, disc_loss = 0.014867960674143055
Trained batch 82 in epoch 1, gen_loss = 2.3758933860135367, disc_loss = 0.014818990305739355
Trained batch 83 in epoch 1, gen_loss = 2.375548087415241, disc_loss = 0.014769837421010294
Trained batch 84 in epoch 1, gen_loss = 2.379453998453477, disc_loss = 0.014827839487834888
Trained batch 85 in epoch 1, gen_loss = 2.377940141877463, disc_loss = 0.014815783090239693
Trained batch 86 in epoch 1, gen_loss = 2.3754930276980346, disc_loss = 0.014832407070173958
Trained batch 87 in epoch 1, gen_loss = 2.373435751958327, disc_loss = 0.01484375858192586
Trained batch 88 in epoch 1, gen_loss = 2.368587376026625, disc_loss = 0.014833116992847638
Trained batch 89 in epoch 1, gen_loss = 2.367304852273729, disc_loss = 0.01478631309647527
Trained batch 90 in epoch 1, gen_loss = 2.3687658336136366, disc_loss = 0.014721442694560839
Trained batch 91 in epoch 1, gen_loss = 2.3687348132548123, disc_loss = 0.014663749217541645
Trained batch 92 in epoch 1, gen_loss = 2.3660059180310977, disc_loss = 0.014629226673634784
Trained batch 93 in epoch 1, gen_loss = 2.371777920012778, disc_loss = 0.014583681982525803
Trained batch 94 in epoch 1, gen_loss = 2.3708388253262167, disc_loss = 0.01452639632809319
Trained batch 95 in epoch 1, gen_loss = 2.372186807294687, disc_loss = 0.014520160548272543
Trained batch 96 in epoch 1, gen_loss = 2.370996838992404, disc_loss = 0.014546661056846995
Trained batch 97 in epoch 1, gen_loss = 2.370710917881557, disc_loss = 0.014533461209348574
Trained batch 98 in epoch 1, gen_loss = 2.3705272120658796, disc_loss = 0.014532547674583967
Trained batch 99 in epoch 1, gen_loss = 2.3718243408203126, disc_loss = 0.014539592084474862
Trained batch 100 in epoch 1, gen_loss = 2.371884312960181, disc_loss = 0.01455882802550303
Trained batch 101 in epoch 1, gen_loss = 2.3730342668645523, disc_loss = 0.014515004454034508
Trained batch 102 in epoch 1, gen_loss = 2.373838163116603, disc_loss = 0.014440569000372898
Trained batch 103 in epoch 1, gen_loss = 2.3751501463926754, disc_loss = 0.01438501397989547
Trained batch 104 in epoch 1, gen_loss = 2.3785439173380536, disc_loss = 0.014356684467444817
Trained batch 105 in epoch 1, gen_loss = 2.376948556810055, disc_loss = 0.014286192582111876
Trained batch 106 in epoch 1, gen_loss = 2.3760423303764555, disc_loss = 0.014248266441869401
Trained batch 107 in epoch 1, gen_loss = 2.377903766102261, disc_loss = 0.01418805388837225
Trained batch 108 in epoch 1, gen_loss = 2.382042526105128, disc_loss = 0.01414509068046688
Trained batch 109 in epoch 1, gen_loss = 2.3852855118838225, disc_loss = 0.014101830548183484
Trained batch 110 in epoch 1, gen_loss = 2.3799316496462435, disc_loss = 0.014103193205219132
Trained batch 111 in epoch 1, gen_loss = 2.3787986657449176, disc_loss = 0.014102696083552604
Trained batch 112 in epoch 1, gen_loss = 2.3794428099573186, disc_loss = 0.01407367652034865
Trained batch 113 in epoch 1, gen_loss = 2.3796040091598245, disc_loss = 0.014069586583788981
Trained batch 114 in epoch 1, gen_loss = 2.3781721695609717, disc_loss = 0.014024557432402735
Trained batch 115 in epoch 1, gen_loss = 2.3775275102977096, disc_loss = 0.013978335251710538
Trained batch 116 in epoch 1, gen_loss = 2.376337721816495, disc_loss = 0.013960628252890375
Trained batch 117 in epoch 1, gen_loss = 2.3781086529715587, disc_loss = 0.013912343751575988
Trained batch 118 in epoch 1, gen_loss = 2.3768175089058756, disc_loss = 0.013864920247627907
Trained batch 119 in epoch 1, gen_loss = 2.3756767014662423, disc_loss = 0.013821378404585024
Trained batch 120 in epoch 1, gen_loss = 2.377436444779073, disc_loss = 0.013792802541216544
Trained batch 121 in epoch 1, gen_loss = 2.380874223396426, disc_loss = 0.013748783190719416
Trained batch 122 in epoch 1, gen_loss = 2.380791214423451, disc_loss = 0.013692410931566625
Trained batch 123 in epoch 1, gen_loss = 2.378088656933077, disc_loss = 0.01364494963068395
Trained batch 124 in epoch 1, gen_loss = 2.3759120235443114, disc_loss = 0.013580176442861558
Trained batch 125 in epoch 1, gen_loss = 2.3777466387975785, disc_loss = 0.013534314191294096
Trained batch 126 in epoch 1, gen_loss = 2.378975462725782, disc_loss = 0.013465902133749461
Trained batch 127 in epoch 1, gen_loss = 2.381942680105567, disc_loss = 0.013401696953224018
Trained batch 128 in epoch 1, gen_loss = 2.382319313611171, disc_loss = 0.013344393516060456
Trained batch 129 in epoch 1, gen_loss = 2.382656955718994, disc_loss = 0.013281340216501401
Trained batch 130 in epoch 1, gen_loss = 2.379606077689251, disc_loss = 0.013233916784231444
Trained batch 131 in epoch 1, gen_loss = 2.3798278931415444, disc_loss = 0.013195730766958812
Trained batch 132 in epoch 1, gen_loss = 2.3804887757265476, disc_loss = 0.013133274783429346
Trained batch 133 in epoch 1, gen_loss = 2.3816984144609368, disc_loss = 0.013076627463686154
Trained batch 134 in epoch 1, gen_loss = 2.3826878388722736, disc_loss = 0.013038098884539471
Trained batch 135 in epoch 1, gen_loss = 2.3822207783951477, disc_loss = 0.012994903817718081
Trained batch 136 in epoch 1, gen_loss = 2.381648857228077, disc_loss = 0.01294557801889677
Trained batch 137 in epoch 1, gen_loss = 2.3823383804680645, disc_loss = 0.012903476771696107
Trained batch 138 in epoch 1, gen_loss = 2.3820591315948705, disc_loss = 0.012897826252143375
Trained batch 139 in epoch 1, gen_loss = 2.38180593422481, disc_loss = 0.012846185895614325
Trained batch 140 in epoch 1, gen_loss = 2.3805423188716808, disc_loss = 0.012801603840148829
Trained batch 141 in epoch 1, gen_loss = 2.379770733940769, disc_loss = 0.012754215068564239
Trained batch 142 in epoch 1, gen_loss = 2.383134113325106, disc_loss = 0.012725154429648097
Trained batch 143 in epoch 1, gen_loss = 2.3827404412958355, disc_loss = 0.012681565965370586
Trained batch 144 in epoch 1, gen_loss = 2.3817659197182492, disc_loss = 0.012642005182288843
Trained batch 145 in epoch 1, gen_loss = 2.3845371269199944, disc_loss = 0.012603863840922713
Trained batch 146 in epoch 1, gen_loss = 2.3857502239902004, disc_loss = 0.01258147606423416
Trained batch 147 in epoch 1, gen_loss = 2.388835054797095, disc_loss = 0.012563145389100788
Trained batch 148 in epoch 1, gen_loss = 2.39066089399709, disc_loss = 0.012525446675467811
Trained batch 149 in epoch 1, gen_loss = 2.390174996058146, disc_loss = 0.012486245551457009
Trained batch 150 in epoch 1, gen_loss = 2.3907552854904277, disc_loss = 0.012478400817424651
Trained batch 151 in epoch 1, gen_loss = 2.3917953481799676, disc_loss = 0.012455795064421469
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 2.363814115524292, disc_loss = 0.00716155581176281
Trained batch 1 in epoch 2, gen_loss = 2.220903158187866, disc_loss = 0.009038768708705902
Trained batch 2 in epoch 2, gen_loss = 2.3152101039886475, disc_loss = 0.009350023542841276
Trained batch 3 in epoch 2, gen_loss = 2.3437355160713196, disc_loss = 0.009692350402474403
Trained batch 4 in epoch 2, gen_loss = 2.3561469078063966, disc_loss = 0.00956299751996994
Trained batch 5 in epoch 2, gen_loss = 2.324834624926249, disc_loss = 0.009046793604890505
Trained batch 6 in epoch 2, gen_loss = 2.3048555510384694, disc_loss = 0.008538819317306792
Trained batch 7 in epoch 2, gen_loss = 2.2842829823493958, disc_loss = 0.008278450346551836
Trained batch 8 in epoch 2, gen_loss = 2.2939552466074624, disc_loss = 0.008051132990254296
Trained batch 9 in epoch 2, gen_loss = 2.2834368467330934, disc_loss = 0.008027225965633988
Trained batch 10 in epoch 2, gen_loss = 2.2696822339838203, disc_loss = 0.008205144877799532
Trained batch 11 in epoch 2, gen_loss = 2.278781215349833, disc_loss = 0.007992306064503888
Trained batch 12 in epoch 2, gen_loss = 2.300472993117112, disc_loss = 0.007871036919263693
Trained batch 13 in epoch 2, gen_loss = 2.2875978776386807, disc_loss = 0.007786086893507412
Trained batch 14 in epoch 2, gen_loss = 2.2829710165659587, disc_loss = 0.007569769707818826
Trained batch 15 in epoch 2, gen_loss = 2.2906222343444824, disc_loss = 0.007637966773472726
Trained batch 16 in epoch 2, gen_loss = 2.2910675722009994, disc_loss = 0.007458847070879796
Trained batch 17 in epoch 2, gen_loss = 2.305726316240099, disc_loss = 0.007341575679472751
Trained batch 18 in epoch 2, gen_loss = 2.3177085675691305, disc_loss = 0.007320111078259192
Trained batch 19 in epoch 2, gen_loss = 2.316398859024048, disc_loss = 0.007313179597258568
Trained batch 20 in epoch 2, gen_loss = 2.32559871673584, disc_loss = 0.00735568024572872
Trained batch 21 in epoch 2, gen_loss = 2.336724107915705, disc_loss = 0.007312350567768921
Trained batch 22 in epoch 2, gen_loss = 2.325266848439756, disc_loss = 0.007358788269693437
Trained batch 23 in epoch 2, gen_loss = 2.34317754705747, disc_loss = 0.007324091469248136
Trained batch 24 in epoch 2, gen_loss = 2.3362706661224366, disc_loss = 0.00732268387451768
Trained batch 25 in epoch 2, gen_loss = 2.3488617218457737, disc_loss = 0.007329699959462652
Trained batch 26 in epoch 2, gen_loss = 2.3486566455275923, disc_loss = 0.007272664129872013
Trained batch 27 in epoch 2, gen_loss = 2.3473702328545705, disc_loss = 0.007178061458814357
Trained batch 28 in epoch 2, gen_loss = 2.3469969568581415, disc_loss = 0.007156964985589529
Trained batch 29 in epoch 2, gen_loss = 2.344569524129232, disc_loss = 0.007150801286722223
Trained batch 30 in epoch 2, gen_loss = 2.3444531117716143, disc_loss = 0.007142844324510905
Trained batch 31 in epoch 2, gen_loss = 2.3438327610492706, disc_loss = 0.007124644849682227
Trained batch 32 in epoch 2, gen_loss = 2.3346008893215293, disc_loss = 0.007095258090306412
Trained batch 33 in epoch 2, gen_loss = 2.329936840954949, disc_loss = 0.007077957161099595
Trained batch 34 in epoch 2, gen_loss = 2.3284062589917864, disc_loss = 0.007160366100392172
Trained batch 35 in epoch 2, gen_loss = 2.331513888306088, disc_loss = 0.007248476082976494
Trained batch 36 in epoch 2, gen_loss = 2.329808338268383, disc_loss = 0.0072562898811254955
Trained batch 37 in epoch 2, gen_loss = 2.3273280670768335, disc_loss = 0.00725148791006129
Trained batch 38 in epoch 2, gen_loss = 2.333762804667155, disc_loss = 0.007402949691869509
Trained batch 39 in epoch 2, gen_loss = 2.3375831067562105, disc_loss = 0.007337543868925422
Trained batch 40 in epoch 2, gen_loss = 2.3462790512457126, disc_loss = 0.007281544561520583
Trained batch 41 in epoch 2, gen_loss = 2.3505462294533137, disc_loss = 0.007212195811527116
Trained batch 42 in epoch 2, gen_loss = 2.355961616649184, disc_loss = 0.007176193755206673
Trained batch 43 in epoch 2, gen_loss = 2.36037630926479, disc_loss = 0.007164060413329439
Trained batch 44 in epoch 2, gen_loss = 2.364914157655504, disc_loss = 0.007156111299991608
Trained batch 45 in epoch 2, gen_loss = 2.367163704789203, disc_loss = 0.007136456405177065
Trained batch 46 in epoch 2, gen_loss = 2.361333395572419, disc_loss = 0.007100979817357469
Trained batch 47 in epoch 2, gen_loss = 2.3591895451148353, disc_loss = 0.007062725683984657
Trained batch 48 in epoch 2, gen_loss = 2.359160851459114, disc_loss = 0.007002715154417923
Trained batch 49 in epoch 2, gen_loss = 2.3710469388961792, disc_loss = 0.007010754439979791
Trained batch 50 in epoch 2, gen_loss = 2.373542121812409, disc_loss = 0.00703202350539904
Trained batch 51 in epoch 2, gen_loss = 2.366058205182736, disc_loss = 0.007017369999980124
Trained batch 52 in epoch 2, gen_loss = 2.3665310279378353, disc_loss = 0.006993046575138029
Trained batch 53 in epoch 2, gen_loss = 2.363774244432096, disc_loss = 0.006949158678590147
Trained batch 54 in epoch 2, gen_loss = 2.3625559438358654, disc_loss = 0.006912007030438293
Trained batch 55 in epoch 2, gen_loss = 2.361453645995685, disc_loss = 0.006875140193317618
Trained batch 56 in epoch 2, gen_loss = 2.3643894802060044, disc_loss = 0.006846038183491481
Trained batch 57 in epoch 2, gen_loss = 2.3616922333322723, disc_loss = 0.006829770651228469
Trained batch 58 in epoch 2, gen_loss = 2.3629940990674294, disc_loss = 0.006817931988102905
Trained batch 59 in epoch 2, gen_loss = 2.363758263985316, disc_loss = 0.006822612547936539
Trained batch 60 in epoch 2, gen_loss = 2.3624060408013765, disc_loss = 0.006841036086505065
Trained batch 61 in epoch 2, gen_loss = 2.36539924721564, disc_loss = 0.006823612309451546
Trained batch 62 in epoch 2, gen_loss = 2.3664110596217807, disc_loss = 0.006801890201925758
Trained batch 63 in epoch 2, gen_loss = 2.371550662443042, disc_loss = 0.006771509397367481
Trained batch 64 in epoch 2, gen_loss = 2.3686301433123074, disc_loss = 0.006761125998141674
Trained batch 65 in epoch 2, gen_loss = 2.3672900543068396, disc_loss = 0.006751021673677094
Trained batch 66 in epoch 2, gen_loss = 2.3713242491679405, disc_loss = 0.006714317113605898
Trained batch 67 in epoch 2, gen_loss = 2.3695582309189964, disc_loss = 0.006740117034710506
Trained batch 68 in epoch 2, gen_loss = 2.3695340173831885, disc_loss = 0.006750645574884138
Trained batch 69 in epoch 2, gen_loss = 2.3680377670696804, disc_loss = 0.006760486587882042
Trained batch 70 in epoch 2, gen_loss = 2.3715741181037795, disc_loss = 0.006787417535210999
Trained batch 71 in epoch 2, gen_loss = 2.373122312956386, disc_loss = 0.006782087917801821
Trained batch 72 in epoch 2, gen_loss = 2.3746431804683112, disc_loss = 0.006804377000064474
Trained batch 73 in epoch 2, gen_loss = 2.3711474119005977, disc_loss = 0.0068089195929870415
Trained batch 74 in epoch 2, gen_loss = 2.3743486801783242, disc_loss = 0.006820793629934391
Trained batch 75 in epoch 2, gen_loss = 2.3758636791455117, disc_loss = 0.006843911955672267
Trained batch 76 in epoch 2, gen_loss = 2.3754181165199775, disc_loss = 0.006851002253446873
Trained batch 77 in epoch 2, gen_loss = 2.3731640103535776, disc_loss = 0.006837882800027728
Trained batch 78 in epoch 2, gen_loss = 2.370093968850148, disc_loss = 0.006908998630139269
Trained batch 79 in epoch 2, gen_loss = 2.373554401099682, disc_loss = 0.006944908207515255
Trained batch 80 in epoch 2, gen_loss = 2.3735313371375755, disc_loss = 0.0069668368942299745
Trained batch 81 in epoch 2, gen_loss = 2.3734783908215964, disc_loss = 0.006968842597860025
Trained batch 82 in epoch 2, gen_loss = 2.3709496920367323, disc_loss = 0.006969668930508645
Trained batch 83 in epoch 2, gen_loss = 2.373118433214369, disc_loss = 0.006965961035651465
Trained batch 84 in epoch 2, gen_loss = 2.376566767692566, disc_loss = 0.006965772292631514
Trained batch 85 in epoch 2, gen_loss = 2.3746609868005266, disc_loss = 0.006960106499189901
Trained batch 86 in epoch 2, gen_loss = 2.3741142900510765, disc_loss = 0.006930095459409486
Trained batch 87 in epoch 2, gen_loss = 2.3758626024831426, disc_loss = 0.006937832666815005
Trained batch 88 in epoch 2, gen_loss = 2.3796371998411887, disc_loss = 0.006930570714594273
Trained batch 89 in epoch 2, gen_loss = 2.37751688030031, disc_loss = 0.006925568093235294
Trained batch 90 in epoch 2, gen_loss = 2.3786630486394023, disc_loss = 0.006905339765720642
Trained batch 91 in epoch 2, gen_loss = 2.3790345153082972, disc_loss = 0.006930012888599025
Trained batch 92 in epoch 2, gen_loss = 2.381861316260471, disc_loss = 0.006966833140380601
Trained batch 93 in epoch 2, gen_loss = 2.3792556156503393, disc_loss = 0.007017501188996941
Trained batch 94 in epoch 2, gen_loss = 2.377945354110316, disc_loss = 0.00704671840036386
Trained batch 95 in epoch 2, gen_loss = 2.3791972311834493, disc_loss = 0.007069111496093683
Trained batch 96 in epoch 2, gen_loss = 2.3788076442541537, disc_loss = 0.00709497981906398
Trained batch 97 in epoch 2, gen_loss = 2.3784608220567507, disc_loss = 0.007092006575810362
Trained batch 98 in epoch 2, gen_loss = 2.3784510451133807, disc_loss = 0.007089582408279783
Trained batch 99 in epoch 2, gen_loss = 2.377956393957138, disc_loss = 0.00707044328097254
Trained batch 100 in epoch 2, gen_loss = 2.3765714817708083, disc_loss = 0.007059305661938863
Trained batch 101 in epoch 2, gen_loss = 2.378603992508907, disc_loss = 0.007052785342595741
Trained batch 102 in epoch 2, gen_loss = 2.3794163743269094, disc_loss = 0.0070518900332881985
Trained batch 103 in epoch 2, gen_loss = 2.382116360160021, disc_loss = 0.007037230552389071
Trained batch 104 in epoch 2, gen_loss = 2.3809055339722405, disc_loss = 0.007022403020943914
Trained batch 105 in epoch 2, gen_loss = 2.3837073557781725, disc_loss = 0.007002943775282716
Trained batch 106 in epoch 2, gen_loss = 2.38730916018798, disc_loss = 0.006973354152412476
Trained batch 107 in epoch 2, gen_loss = 2.3877564238177404, disc_loss = 0.006948917873496948
Trained batch 108 in epoch 2, gen_loss = 2.387440144468885, disc_loss = 0.006925239592978577
Trained batch 109 in epoch 2, gen_loss = 2.3879241780801252, disc_loss = 0.006900538578206166
Trained batch 110 in epoch 2, gen_loss = 2.3851257498199874, disc_loss = 0.0068806744168034275
Trained batch 111 in epoch 2, gen_loss = 2.3838378159063205, disc_loss = 0.006865242464950175
Trained batch 112 in epoch 2, gen_loss = 2.381792423999415, disc_loss = 0.006852523846123203
Trained batch 113 in epoch 2, gen_loss = 2.379151669510624, disc_loss = 0.006840228244025064
Trained batch 114 in epoch 2, gen_loss = 2.3782946825027467, disc_loss = 0.0068216097196969
Trained batch 115 in epoch 2, gen_loss = 2.377300960236582, disc_loss = 0.006817897847966002
Trained batch 116 in epoch 2, gen_loss = 2.375086135334439, disc_loss = 0.006847845392429039
Trained batch 117 in epoch 2, gen_loss = 2.3756431856397855, disc_loss = 0.006865332923213936
Trained batch 118 in epoch 2, gen_loss = 2.3783967885650505, disc_loss = 0.006853677514361359
Trained batch 119 in epoch 2, gen_loss = 2.377534462014834, disc_loss = 0.006840937543893233
Trained batch 120 in epoch 2, gen_loss = 2.377590381409511, disc_loss = 0.0068352495816590125
Trained batch 121 in epoch 2, gen_loss = 2.3771079026284765, disc_loss = 0.006834415640666714
Trained batch 122 in epoch 2, gen_loss = 2.377137371195041, disc_loss = 0.006850491722712551
Trained batch 123 in epoch 2, gen_loss = 2.3767481609698264, disc_loss = 0.006841289414648687
Trained batch 124 in epoch 2, gen_loss = 2.378636912345886, disc_loss = 0.0068453963119536635
Trained batch 125 in epoch 2, gen_loss = 2.377733193692707, disc_loss = 0.006866015917030237
Trained batch 126 in epoch 2, gen_loss = 2.375179338642931, disc_loss = 0.0069048644582498965
Trained batch 127 in epoch 2, gen_loss = 2.375803674571216, disc_loss = 0.0069501714260695735
Trained batch 128 in epoch 2, gen_loss = 2.376132618549258, disc_loss = 0.007010135685938389
Trained batch 129 in epoch 2, gen_loss = 2.3767254435099088, disc_loss = 0.0070480829624172585
Trained batch 130 in epoch 2, gen_loss = 2.375832813386699, disc_loss = 0.00706091589464998
Trained batch 131 in epoch 2, gen_loss = 2.3762020387432794, disc_loss = 0.00705192513785071
Trained batch 132 in epoch 2, gen_loss = 2.3772969362431002, disc_loss = 0.007064416330601824
Trained batch 133 in epoch 2, gen_loss = 2.37711225783647, disc_loss = 0.0070686605602586225
Trained batch 134 in epoch 2, gen_loss = 2.3786414949982255, disc_loss = 0.007068440233598705
Trained batch 135 in epoch 2, gen_loss = 2.3807962352738663, disc_loss = 0.0070685948132236
Trained batch 136 in epoch 2, gen_loss = 2.3802317328696705, disc_loss = 0.007069313886786138
Trained batch 137 in epoch 2, gen_loss = 2.3805184096529866, disc_loss = 0.007052974382320932
Trained batch 138 in epoch 2, gen_loss = 2.3818289573244056, disc_loss = 0.007056992707050426
Trained batch 139 in epoch 2, gen_loss = 2.382155327286039, disc_loss = 0.007059758061742676
Trained batch 140 in epoch 2, gen_loss = 2.384223017286747, disc_loss = 0.007047627472932985
Trained batch 141 in epoch 2, gen_loss = 2.3830794591299247, disc_loss = 0.007042642858233565
Trained batch 142 in epoch 2, gen_loss = 2.3826040529704593, disc_loss = 0.007038579695252376
Trained batch 143 in epoch 2, gen_loss = 2.3818303272128105, disc_loss = 0.007031855660089705
Trained batch 144 in epoch 2, gen_loss = 2.3831398659739, disc_loss = 0.007025394445799034
Trained batch 145 in epoch 2, gen_loss = 2.380955879818903, disc_loss = 0.007026363707989557
Trained batch 146 in epoch 2, gen_loss = 2.3803731316611882, disc_loss = 0.0070404233933635514
Trained batch 147 in epoch 2, gen_loss = 2.3804949723385476, disc_loss = 0.007025056045087105
Trained batch 148 in epoch 2, gen_loss = 2.3812558226937415, disc_loss = 0.007027419426184673
Trained batch 149 in epoch 2, gen_loss = 2.383731537659963, disc_loss = 0.0070237306334699195
Trained batch 150 in epoch 2, gen_loss = 2.3849290293573544, disc_loss = 0.007013291513719997
Trained batch 151 in epoch 2, gen_loss = 2.3837397153440274, disc_loss = 0.007006443361445379
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 2.4758810997009277, disc_loss = 0.0038524779956787825
Trained batch 1 in epoch 3, gen_loss = 2.3609830141067505, disc_loss = 0.00415678892750293
Trained batch 2 in epoch 3, gen_loss = 2.4968551794687905, disc_loss = 0.0040442978497594595
Trained batch 3 in epoch 3, gen_loss = 2.4280856251716614, disc_loss = 0.0048280913033522666
Trained batch 4 in epoch 3, gen_loss = 2.4871641635894775, disc_loss = 0.0046754887793213126
Trained batch 5 in epoch 3, gen_loss = 2.4825135469436646, disc_loss = 0.0049561324606960016
Trained batch 6 in epoch 3, gen_loss = 2.4873527118137906, disc_loss = 0.005285751639998385
Trained batch 7 in epoch 3, gen_loss = 2.427895098924637, disc_loss = 0.005578534473897889
Trained batch 8 in epoch 3, gen_loss = 2.4285919666290283, disc_loss = 0.006248761201277375
Trained batch 9 in epoch 3, gen_loss = 2.408725070953369, disc_loss = 0.006185556692071259
Trained batch 10 in epoch 3, gen_loss = 2.3975159471685235, disc_loss = 0.006133116083219647
Trained batch 11 in epoch 3, gen_loss = 2.4046782652537027, disc_loss = 0.0059996370497780544
Trained batch 12 in epoch 3, gen_loss = 2.398290982613197, disc_loss = 0.006026416497591596
Trained batch 13 in epoch 3, gen_loss = 2.405884163720267, disc_loss = 0.006239483981127185
Trained batch 14 in epoch 3, gen_loss = 2.429671287536621, disc_loss = 0.006120932303989927
Trained batch 15 in epoch 3, gen_loss = 2.41527396440506, disc_loss = 0.0060252488910919055
Trained batch 16 in epoch 3, gen_loss = 2.4042407765108, disc_loss = 0.006017917534336448
Trained batch 17 in epoch 3, gen_loss = 2.4036989476945667, disc_loss = 0.005886489370216926
Trained batch 18 in epoch 3, gen_loss = 2.398253603985435, disc_loss = 0.0058763050719311365
Trained batch 19 in epoch 3, gen_loss = 2.400138461589813, disc_loss = 0.0057920223567634824
Trained batch 20 in epoch 3, gen_loss = 2.3922144117809476, disc_loss = 0.005729722125189645
Trained batch 21 in epoch 3, gen_loss = 2.392538244074041, disc_loss = 0.0056897306137464266
Trained batch 22 in epoch 3, gen_loss = 2.3770500577014424, disc_loss = 0.005581926432964595
Trained batch 23 in epoch 3, gen_loss = 2.380912015835444, disc_loss = 0.0054930634796619415
Trained batch 24 in epoch 3, gen_loss = 2.380372142791748, disc_loss = 0.0054385621286928655
Trained batch 25 in epoch 3, gen_loss = 2.380537060590891, disc_loss = 0.00539339965997407
Trained batch 26 in epoch 3, gen_loss = 2.385634281017162, disc_loss = 0.005351317494555756
Trained batch 27 in epoch 3, gen_loss = 2.3811043756348744, disc_loss = 0.005347257613071373
Trained batch 28 in epoch 3, gen_loss = 2.3689026750367264, disc_loss = 0.005314978610338836
Trained batch 29 in epoch 3, gen_loss = 2.3613752285639444, disc_loss = 0.005280704221998652
Trained batch 30 in epoch 3, gen_loss = 2.3584537736831175, disc_loss = 0.005315893945554572
Trained batch 31 in epoch 3, gen_loss = 2.352259524166584, disc_loss = 0.005383292824262753
Trained batch 32 in epoch 3, gen_loss = 2.3510996861891313, disc_loss = 0.005393140413092844
Trained batch 33 in epoch 3, gen_loss = 2.35696944769691, disc_loss = 0.005358183893429882
Trained batch 34 in epoch 3, gen_loss = 2.3518029144832067, disc_loss = 0.0053576955970908915
Trained batch 35 in epoch 3, gen_loss = 2.3633676634894476, disc_loss = 0.005340745750193794
Trained batch 36 in epoch 3, gen_loss = 2.36697784630028, disc_loss = 0.005309879981182717
Trained batch 37 in epoch 3, gen_loss = 2.3602716734534814, disc_loss = 0.005279748112355408
Trained batch 38 in epoch 3, gen_loss = 2.3694586081382556, disc_loss = 0.005264580178146179
Trained batch 39 in epoch 3, gen_loss = 2.36236732006073, disc_loss = 0.005251719581428916
Trained batch 40 in epoch 3, gen_loss = 2.361147502573525, disc_loss = 0.005227462036489714
Trained batch 41 in epoch 3, gen_loss = 2.3636165743782405, disc_loss = 0.005177152254396961
Trained batch 42 in epoch 3, gen_loss = 2.362510542536891, disc_loss = 0.005131924259584657
Trained batch 43 in epoch 3, gen_loss = 2.3573660146106374, disc_loss = 0.005091018260414289
Trained batch 44 in epoch 3, gen_loss = 2.358604711956448, disc_loss = 0.005058695070652498
Trained batch 45 in epoch 3, gen_loss = 2.3655990984128867, disc_loss = 0.005039484386899225
Trained batch 46 in epoch 3, gen_loss = 2.36516690761485, disc_loss = 0.004999893771960063
Trained batch 47 in epoch 3, gen_loss = 2.365521381298701, disc_loss = 0.005013688103645109
Trained batch 48 in epoch 3, gen_loss = 2.3669437680925642, disc_loss = 0.004976418871926714
Trained batch 49 in epoch 3, gen_loss = 2.36468710899353, disc_loss = 0.004962557493709028
Trained batch 50 in epoch 3, gen_loss = 2.3616017360313264, disc_loss = 0.00494790166232954
Trained batch 51 in epoch 3, gen_loss = 2.356933071063115, disc_loss = 0.0049293307506909165
Trained batch 52 in epoch 3, gen_loss = 2.3518219938818015, disc_loss = 0.004908773455030794
Trained batch 53 in epoch 3, gen_loss = 2.3502776975984925, disc_loss = 0.004879682544722325
Trained batch 54 in epoch 3, gen_loss = 2.3465962453321976, disc_loss = 0.004842310949144038
Trained batch 55 in epoch 3, gen_loss = 2.3452921339443753, disc_loss = 0.004812660764270861
Trained batch 56 in epoch 3, gen_loss = 2.3478529411449767, disc_loss = 0.004799077740723365
Trained batch 57 in epoch 3, gen_loss = 2.349431436637352, disc_loss = 0.004776653307811196
Trained batch 58 in epoch 3, gen_loss = 2.350965588779773, disc_loss = 0.004751217074029274
Trained batch 59 in epoch 3, gen_loss = 2.354386035601298, disc_loss = 0.004719473312919339
Trained batch 60 in epoch 3, gen_loss = 2.3551196934746916, disc_loss = 0.004687494682300774
Trained batch 61 in epoch 3, gen_loss = 2.3527328160501297, disc_loss = 0.004653647868713784
Trained batch 62 in epoch 3, gen_loss = 2.3468867975568015, disc_loss = 0.004641067062962859
Trained batch 63 in epoch 3, gen_loss = 2.35504312440753, disc_loss = 0.004617361795681063
Trained batch 64 in epoch 3, gen_loss = 2.355503804867084, disc_loss = 0.004594022619466369
Trained batch 65 in epoch 3, gen_loss = 2.35668805512515, disc_loss = 0.004576278046112169
Trained batch 66 in epoch 3, gen_loss = 2.359725678144996, disc_loss = 0.0045554573619877225
Trained batch 67 in epoch 3, gen_loss = 2.3619998132481292, disc_loss = 0.004539322542875786
Trained batch 68 in epoch 3, gen_loss = 2.3601844690848086, disc_loss = 0.004545753561905113
Trained batch 69 in epoch 3, gen_loss = 2.363889527320862, disc_loss = 0.00453324425034225
Trained batch 70 in epoch 3, gen_loss = 2.3649715403435936, disc_loss = 0.004518049883879196
Trained batch 71 in epoch 3, gen_loss = 2.3615984320640564, disc_loss = 0.00451778642147676
Trained batch 72 in epoch 3, gen_loss = 2.3614819017175126, disc_loss = 0.004515684500004943
Trained batch 73 in epoch 3, gen_loss = 2.360867880486153, disc_loss = 0.004523322826276558
Trained batch 74 in epoch 3, gen_loss = 2.3609857114156085, disc_loss = 0.004512884691357613
Trained batch 75 in epoch 3, gen_loss = 2.364397660682076, disc_loss = 0.004497514621011521
Trained batch 76 in epoch 3, gen_loss = 2.366773239977948, disc_loss = 0.004487173423146853
Trained batch 77 in epoch 3, gen_loss = 2.3660011199804454, disc_loss = 0.0044766805427244455
Trained batch 78 in epoch 3, gen_loss = 2.3663747039022325, disc_loss = 0.004456996136710425
Trained batch 79 in epoch 3, gen_loss = 2.366457939147949, disc_loss = 0.0044375502184266225
Trained batch 80 in epoch 3, gen_loss = 2.364231439284336, disc_loss = 0.004434584067950462
Trained batch 81 in epoch 3, gen_loss = 2.365648397585241, disc_loss = 0.00443399035678495
Trained batch 82 in epoch 3, gen_loss = 2.364842702107257, disc_loss = 0.00442015238005264
Trained batch 83 in epoch 3, gen_loss = 2.362385693050566, disc_loss = 0.0044158972838583095
Trained batch 84 in epoch 3, gen_loss = 2.36340906199287, disc_loss = 0.0043955447398783525
Trained batch 85 in epoch 3, gen_loss = 2.3627483428910723, disc_loss = 0.004379978557767043
Trained batch 86 in epoch 3, gen_loss = 2.364664940998472, disc_loss = 0.0043839904795475735
Trained batch 87 in epoch 3, gen_loss = 2.3661916039206763, disc_loss = 0.004381640589351512
Trained batch 88 in epoch 3, gen_loss = 2.36422494824013, disc_loss = 0.00438716490439066
Trained batch 89 in epoch 3, gen_loss = 2.361946945720249, disc_loss = 0.004391782914495303
Trained batch 90 in epoch 3, gen_loss = 2.3603022884536577, disc_loss = 0.00439926897237016
Trained batch 91 in epoch 3, gen_loss = 2.3577575268952744, disc_loss = 0.004398661921225974
Trained batch 92 in epoch 3, gen_loss = 2.3538994225122596, disc_loss = 0.004395970130860004
Trained batch 93 in epoch 3, gen_loss = 2.354039780637051, disc_loss = 0.004384785110348875
Trained batch 94 in epoch 3, gen_loss = 2.356650139156141, disc_loss = 0.0043762800920950735
Trained batch 95 in epoch 3, gen_loss = 2.3547952895363173, disc_loss = 0.00437701064220164
Trained batch 96 in epoch 3, gen_loss = 2.356871686030909, disc_loss = 0.0044102781433036035
Trained batch 97 in epoch 3, gen_loss = 2.3582861058566036, disc_loss = 0.004409738108325674
Trained batch 98 in epoch 3, gen_loss = 2.362843621860851, disc_loss = 0.0044179252311211045
Trained batch 99 in epoch 3, gen_loss = 2.3629137229919435, disc_loss = 0.004417373337782919
Trained batch 100 in epoch 3, gen_loss = 2.3614453041907586, disc_loss = 0.004425430167835242
Trained batch 101 in epoch 3, gen_loss = 2.360484342949063, disc_loss = 0.004440868382944781
Trained batch 102 in epoch 3, gen_loss = 2.3594503078645874, disc_loss = 0.004443733433026423
Trained batch 103 in epoch 3, gen_loss = 2.356134676016294, disc_loss = 0.004456778437508127
Trained batch 104 in epoch 3, gen_loss = 2.3550526709783646, disc_loss = 0.004476777934247539
Trained batch 105 in epoch 3, gen_loss = 2.35384134976369, disc_loss = 0.004481462304884533
Trained batch 106 in epoch 3, gen_loss = 2.355218593205247, disc_loss = 0.004479439520042076
Trained batch 107 in epoch 3, gen_loss = 2.3566030263900757, disc_loss = 0.004474285623507091
Trained batch 108 in epoch 3, gen_loss = 2.3573953427306007, disc_loss = 0.004485534995349995
Trained batch 109 in epoch 3, gen_loss = 2.357828809998252, disc_loss = 0.00447186500850049
Trained batch 110 in epoch 3, gen_loss = 2.35907016358934, disc_loss = 0.004466568740705649
Trained batch 111 in epoch 3, gen_loss = 2.3583896585873196, disc_loss = 0.004472224698734603
Trained batch 112 in epoch 3, gen_loss = 2.357137460624222, disc_loss = 0.004480400633693269
Trained batch 113 in epoch 3, gen_loss = 2.3575070531744706, disc_loss = 0.004471510571117203
Trained batch 114 in epoch 3, gen_loss = 2.3571811219920282, disc_loss = 0.004466744678337937
Trained batch 115 in epoch 3, gen_loss = 2.362032851268505, disc_loss = 0.004459731212560216
Trained batch 116 in epoch 3, gen_loss = 2.3610571775680933, disc_loss = 0.00445028417942743
Trained batch 117 in epoch 3, gen_loss = 2.360534975084208, disc_loss = 0.0044340065352902825
Trained batch 118 in epoch 3, gen_loss = 2.3596106397003687, disc_loss = 0.00442628379512046
Trained batch 119 in epoch 3, gen_loss = 2.3591992715994516, disc_loss = 0.004426773313510542
Trained batch 120 in epoch 3, gen_loss = 2.357286512359115, disc_loss = 0.004425154777613184
Trained batch 121 in epoch 3, gen_loss = 2.355492769694719, disc_loss = 0.004426401171482123
Trained batch 122 in epoch 3, gen_loss = 2.3526010086865927, disc_loss = 0.00443172985044255
Trained batch 123 in epoch 3, gen_loss = 2.3578882371225665, disc_loss = 0.004431732425150732
Trained batch 124 in epoch 3, gen_loss = 2.358682819366455, disc_loss = 0.004434127209708095
Trained batch 125 in epoch 3, gen_loss = 2.357029405851213, disc_loss = 0.004441221475615979
Trained batch 126 in epoch 3, gen_loss = 2.3587898701194705, disc_loss = 0.004447415113581095
Trained batch 127 in epoch 3, gen_loss = 2.3591853249818087, disc_loss = 0.004449696987649077
Trained batch 128 in epoch 3, gen_loss = 2.3592839296474013, disc_loss = 0.0044473579763470925
Trained batch 129 in epoch 3, gen_loss = 2.359199278171246, disc_loss = 0.00444788177891706
Trained batch 130 in epoch 3, gen_loss = 2.360509024321578, disc_loss = 0.004439930049418152
Trained batch 131 in epoch 3, gen_loss = 2.3612841403845586, disc_loss = 0.004430980157022449
Trained batch 132 in epoch 3, gen_loss = 2.3604319938143394, disc_loss = 0.00443161030026867
Trained batch 133 in epoch 3, gen_loss = 2.3614107886357094, disc_loss = 0.004429356486939672
Trained batch 134 in epoch 3, gen_loss = 2.361760058226409, disc_loss = 0.004422041763448053
Trained batch 135 in epoch 3, gen_loss = 2.360755839768578, disc_loss = 0.004412518458112198
Trained batch 136 in epoch 3, gen_loss = 2.362167048628313, disc_loss = 0.004404858104803048
Trained batch 137 in epoch 3, gen_loss = 2.361028018205062, disc_loss = 0.004405388551210795
Trained batch 138 in epoch 3, gen_loss = 2.3605203439863467, disc_loss = 0.004401796805612046
Trained batch 139 in epoch 3, gen_loss = 2.361004252093179, disc_loss = 0.004397581083633538
Trained batch 140 in epoch 3, gen_loss = 2.363762649238532, disc_loss = 0.0043877735717473085
Trained batch 141 in epoch 3, gen_loss = 2.3668833635222746, disc_loss = 0.004373030561599618
Trained batch 142 in epoch 3, gen_loss = 2.36628398028287, disc_loss = 0.004367081331206368
Trained batch 143 in epoch 3, gen_loss = 2.3646737221214504, disc_loss = 0.00435980893639175
Trained batch 144 in epoch 3, gen_loss = 2.364265016029621, disc_loss = 0.004347228632982949
Trained batch 145 in epoch 3, gen_loss = 2.3676098078897554, disc_loss = 0.004342559315200435
Trained batch 146 in epoch 3, gen_loss = 2.371176949974631, disc_loss = 0.004344941590450147
Trained batch 147 in epoch 3, gen_loss = 2.3715898475131474, disc_loss = 0.004336177789908205
Trained batch 148 in epoch 3, gen_loss = 2.374073947036026, disc_loss = 0.004325273781139779
Trained batch 149 in epoch 3, gen_loss = 2.373998457590739, disc_loss = 0.004312367035696904
Trained batch 150 in epoch 3, gen_loss = 2.3730594717114175, disc_loss = 0.004306025263415465
Trained batch 151 in epoch 3, gen_loss = 2.373328966529746, disc_loss = 0.004299206512146874
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 2.31534481048584, disc_loss = 0.00220443494617939
Trained batch 1 in epoch 4, gen_loss = 2.278960347175598, disc_loss = 0.0021982742473483086
Trained batch 2 in epoch 4, gen_loss = 2.4358274141947427, disc_loss = 0.0027706961457928023
Trained batch 3 in epoch 4, gen_loss = 2.479827404022217, disc_loss = 0.003019713156390935
Trained batch 4 in epoch 4, gen_loss = 2.4158305644989015, disc_loss = 0.0030301761347800494
Trained batch 5 in epoch 4, gen_loss = 2.4228968620300293, disc_loss = 0.003072778422695895
Trained batch 6 in epoch 4, gen_loss = 2.4918791907174245, disc_loss = 0.0030123726797423194
Trained batch 7 in epoch 4, gen_loss = 2.4664494395256042, disc_loss = 0.002975995885208249
Trained batch 8 in epoch 4, gen_loss = 2.4553818702697754, disc_loss = 0.0029553441951672235
Trained batch 9 in epoch 4, gen_loss = 2.4674762964248655, disc_loss = 0.0029515275033190846
Trained batch 10 in epoch 4, gen_loss = 2.426426128907637, disc_loss = 0.0029212852982296185
Trained batch 11 in epoch 4, gen_loss = 2.411501924196879, disc_loss = 0.0029085659965251884
Trained batch 12 in epoch 4, gen_loss = 2.432131363795354, disc_loss = 0.0029361155779602435
Trained batch 13 in epoch 4, gen_loss = 2.4234375102179393, disc_loss = 0.002935617945955268
Trained batch 14 in epoch 4, gen_loss = 2.417490530014038, disc_loss = 0.0029499446041882037
Trained batch 15 in epoch 4, gen_loss = 2.4001851975917816, disc_loss = 0.0029108688759151846
Trained batch 16 in epoch 4, gen_loss = 2.394962422987994, disc_loss = 0.00291093229316175
Trained batch 17 in epoch 4, gen_loss = 2.389952818552653, disc_loss = 0.002963897293537027
Trained batch 18 in epoch 4, gen_loss = 2.380881560476203, disc_loss = 0.002943822121443717
Trained batch 19 in epoch 4, gen_loss = 2.3730574250221252, disc_loss = 0.003005269484128803
Trained batch 20 in epoch 4, gen_loss = 2.3676847276233493, disc_loss = 0.00302022133421685
Trained batch 21 in epoch 4, gen_loss = 2.365464860742742, disc_loss = 0.0030061608624898577
Trained batch 22 in epoch 4, gen_loss = 2.3662749891695767, disc_loss = 0.0029720471483533797
Trained batch 23 in epoch 4, gen_loss = 2.3565632700920105, disc_loss = 0.00297253862178574
Trained batch 24 in epoch 4, gen_loss = 2.3464742851257325, disc_loss = 0.0030270447209477425
Trained batch 25 in epoch 4, gen_loss = 2.351993542451125, disc_loss = 0.0030492991746331635
Trained batch 26 in epoch 4, gen_loss = 2.3494075845789024, disc_loss = 0.0030742807624240718
Trained batch 27 in epoch 4, gen_loss = 2.3501707911491394, disc_loss = 0.0031005015896101084
Trained batch 28 in epoch 4, gen_loss = 2.361662215199964, disc_loss = 0.0030903753278584316
Trained batch 29 in epoch 4, gen_loss = 2.3506258010864256, disc_loss = 0.003137692514186104
Trained batch 30 in epoch 4, gen_loss = 2.3523806602724138, disc_loss = 0.0031476829411281695
Trained batch 31 in epoch 4, gen_loss = 2.357900507748127, disc_loss = 0.0031699384562671185
Trained batch 32 in epoch 4, gen_loss = 2.3553713090492017, disc_loss = 0.0032164048911495643
Trained batch 33 in epoch 4, gen_loss = 2.3576580005533554, disc_loss = 0.0032321290140423704
Trained batch 34 in epoch 4, gen_loss = 2.3654972076416017, disc_loss = 0.0032297628399516856
Trained batch 35 in epoch 4, gen_loss = 2.38007691833708, disc_loss = 0.003280452569015324
Trained batch 36 in epoch 4, gen_loss = 2.383633768236315, disc_loss = 0.0032880570726922234
Trained batch 37 in epoch 4, gen_loss = 2.3786902678640267, disc_loss = 0.0032821655408234187
Trained batch 38 in epoch 4, gen_loss = 2.3787330236190405, disc_loss = 0.003271679459617306
Trained batch 39 in epoch 4, gen_loss = 2.3771542489528654, disc_loss = 0.0032561211031861604
Trained batch 40 in epoch 4, gen_loss = 2.379343503858985, disc_loss = 0.0032546311821334247
Trained batch 41 in epoch 4, gen_loss = 2.3757063093639554, disc_loss = 0.0032646455524844072
Trained batch 42 in epoch 4, gen_loss = 2.3678934906804283, disc_loss = 0.003253751537264433
Trained batch 43 in epoch 4, gen_loss = 2.3670967004515906, disc_loss = 0.0032680110571990635
Trained batch 44 in epoch 4, gen_loss = 2.36470906469557, disc_loss = 0.0032975455176913076
Trained batch 45 in epoch 4, gen_loss = 2.365398038988528, disc_loss = 0.003316725133513303
Trained batch 46 in epoch 4, gen_loss = 2.364209423673914, disc_loss = 0.003359389119841
Trained batch 47 in epoch 4, gen_loss = 2.3625950862963996, disc_loss = 0.003352928441017866
Trained batch 48 in epoch 4, gen_loss = 2.36360333890331, disc_loss = 0.003351759897278888
Trained batch 49 in epoch 4, gen_loss = 2.3665719127655027, disc_loss = 0.0033393098181113603
Trained batch 50 in epoch 4, gen_loss = 2.3642040000242344, disc_loss = 0.00332025010777893
Trained batch 51 in epoch 4, gen_loss = 2.368243167033562, disc_loss = 0.003317889305225645
Trained batch 52 in epoch 4, gen_loss = 2.3659806386479794, disc_loss = 0.0033137048375002057
Trained batch 53 in epoch 4, gen_loss = 2.3650500465322426, disc_loss = 0.003297457725878943
Trained batch 54 in epoch 4, gen_loss = 2.365096243945035, disc_loss = 0.003294115149500695
Trained batch 55 in epoch 4, gen_loss = 2.3614150626318797, disc_loss = 0.0032835237881434815
Trained batch 56 in epoch 4, gen_loss = 2.3568918830470036, disc_loss = 0.003294228649649181
Trained batch 57 in epoch 4, gen_loss = 2.3562411357616555, disc_loss = 0.0032874347144288235
Trained batch 58 in epoch 4, gen_loss = 2.3508775072582697, disc_loss = 0.003269336565192473
Trained batch 59 in epoch 4, gen_loss = 2.3491543531417847, disc_loss = 0.0032647505751810966
Trained batch 60 in epoch 4, gen_loss = 2.349865819587082, disc_loss = 0.003261285036283194
Trained batch 61 in epoch 4, gen_loss = 2.3492791652679443, disc_loss = 0.003288217636215831
Trained batch 62 in epoch 4, gen_loss = 2.3478511325896734, disc_loss = 0.003284883467362277
Trained batch 63 in epoch 4, gen_loss = 2.349718600511551, disc_loss = 0.0032793773752928246
Trained batch 64 in epoch 4, gen_loss = 2.3608392825493447, disc_loss = 0.003275557259957378
Trained batch 65 in epoch 4, gen_loss = 2.358882138223359, disc_loss = 0.0032637443386413383
Trained batch 66 in epoch 4, gen_loss = 2.360985122509857, disc_loss = 0.0032464182664598547
Trained batch 67 in epoch 4, gen_loss = 2.35880086702459, disc_loss = 0.0032345002777326632
Trained batch 68 in epoch 4, gen_loss = 2.3624471374180005, disc_loss = 0.0032274147657596545
Trained batch 69 in epoch 4, gen_loss = 2.359377033369882, disc_loss = 0.0032214794041854995
Trained batch 70 in epoch 4, gen_loss = 2.3619909454399433, disc_loss = 0.0032245286405873552
Trained batch 71 in epoch 4, gen_loss = 2.3626272645261555, disc_loss = 0.003211938384791008
Trained batch 72 in epoch 4, gen_loss = 2.3605898830988634, disc_loss = 0.003200363099881231
Trained batch 73 in epoch 4, gen_loss = 2.3593523921193302, disc_loss = 0.0031916806128228434
Trained batch 74 in epoch 4, gen_loss = 2.35978551864624, disc_loss = 0.0032004805002361536
Trained batch 75 in epoch 4, gen_loss = 2.362858606012244, disc_loss = 0.0032047548999176606
Trained batch 76 in epoch 4, gen_loss = 2.3608807062173818, disc_loss = 0.003197461351534569
Trained batch 77 in epoch 4, gen_loss = 2.3631072411170373, disc_loss = 0.003185353310516056
Trained batch 78 in epoch 4, gen_loss = 2.364688689195657, disc_loss = 0.0031681887310328364
Trained batch 79 in epoch 4, gen_loss = 2.362801283597946, disc_loss = 0.003149036000831984
Trained batch 80 in epoch 4, gen_loss = 2.367305060963572, disc_loss = 0.0031387844197682023
Trained batch 81 in epoch 4, gen_loss = 2.3664199782580866, disc_loss = 0.0031229628153463325
Trained batch 82 in epoch 4, gen_loss = 2.3623537098068788, disc_loss = 0.0031143356400755154
Trained batch 83 in epoch 4, gen_loss = 2.365770859377725, disc_loss = 0.0030975856546623013
Trained batch 84 in epoch 4, gen_loss = 2.3631811226115507, disc_loss = 0.0030927227180012886
Trained batch 85 in epoch 4, gen_loss = 2.362631634224293, disc_loss = 0.003090468589974524
Trained batch 86 in epoch 4, gen_loss = 2.36114344925716, disc_loss = 0.0030884900927843377
Trained batch 87 in epoch 4, gen_loss = 2.3634606952017005, disc_loss = 0.003077460900054906
Trained batch 88 in epoch 4, gen_loss = 2.3644286889708446, disc_loss = 0.003068977566645219
Trained batch 89 in epoch 4, gen_loss = 2.364795772234599, disc_loss = 0.003059015073813498
Trained batch 90 in epoch 4, gen_loss = 2.3618814526023444, disc_loss = 0.00306071754759894
Trained batch 91 in epoch 4, gen_loss = 2.360084100909855, disc_loss = 0.003059513074771056
Trained batch 92 in epoch 4, gen_loss = 2.3556691651703208, disc_loss = 0.0030553523245798325
Trained batch 93 in epoch 4, gen_loss = 2.35734091413782, disc_loss = 0.0030488959845512155
Trained batch 94 in epoch 4, gen_loss = 2.3578537664915387, disc_loss = 0.003046444443201548
Trained batch 95 in epoch 4, gen_loss = 2.3617717723051705, disc_loss = 0.0030374930356629193
Trained batch 96 in epoch 4, gen_loss = 2.363512690534297, disc_loss = 0.0030373586557767133
Trained batch 97 in epoch 4, gen_loss = 2.3631750661499646, disc_loss = 0.003037935837970248
Trained batch 98 in epoch 4, gen_loss = 2.363954939023413, disc_loss = 0.003042084529450295
Trained batch 99 in epoch 4, gen_loss = 2.364787468910217, disc_loss = 0.0030473086913116276
Trained batch 100 in epoch 4, gen_loss = 2.366631016872897, disc_loss = 0.0030427816840312857
Trained batch 101 in epoch 4, gen_loss = 2.3639125146117865, disc_loss = 0.003049702694018682
Trained batch 102 in epoch 4, gen_loss = 2.3631073919314782, disc_loss = 0.0030548473123858852
Trained batch 103 in epoch 4, gen_loss = 2.3614615201950073, disc_loss = 0.003051379279126055
Trained batch 104 in epoch 4, gen_loss = 2.3608144873664494, disc_loss = 0.003057896037630382
Trained batch 105 in epoch 4, gen_loss = 2.360471689476157, disc_loss = 0.0030561687143624955
Trained batch 106 in epoch 4, gen_loss = 2.3612425371865244, disc_loss = 0.0030535467308467237
Trained batch 107 in epoch 4, gen_loss = 2.3626496880142778, disc_loss = 0.0030537170715871508
Trained batch 108 in epoch 4, gen_loss = 2.3668322125706105, disc_loss = 0.003055239683700674
Trained batch 109 in epoch 4, gen_loss = 2.365230673009699, disc_loss = 0.00305157860275358
Trained batch 110 in epoch 4, gen_loss = 2.3683080157718144, disc_loss = 0.003049673613261532
Trained batch 111 in epoch 4, gen_loss = 2.3678858258894513, disc_loss = 0.003044018108214784
Trained batch 112 in epoch 4, gen_loss = 2.367458134625865, disc_loss = 0.0030352479749383918
Trained batch 113 in epoch 4, gen_loss = 2.369744156536303, disc_loss = 0.0030291837685038907
Trained batch 114 in epoch 4, gen_loss = 2.369121566026107, disc_loss = 0.0030224806568382875
Trained batch 115 in epoch 4, gen_loss = 2.3703097803839324, disc_loss = 0.0030095435745195196
Trained batch 116 in epoch 4, gen_loss = 2.3684419852036696, disc_loss = 0.0029987294005994233
Trained batch 117 in epoch 4, gen_loss = 2.3706182867793713, disc_loss = 0.002988305987624483
Trained batch 118 in epoch 4, gen_loss = 2.3722917612861183, disc_loss = 0.0029819097727959774
Trained batch 119 in epoch 4, gen_loss = 2.370621645450592, disc_loss = 0.002975878570578061
Trained batch 120 in epoch 4, gen_loss = 2.3698866229411983, disc_loss = 0.0029687780303849784
Trained batch 121 in epoch 4, gen_loss = 2.370108672829925, disc_loss = 0.002962952074174937
Trained batch 122 in epoch 4, gen_loss = 2.369332265078537, disc_loss = 0.00295553438656971
Trained batch 123 in epoch 4, gen_loss = 2.3711348137547894, disc_loss = 0.002956664017889829
Trained batch 124 in epoch 4, gen_loss = 2.3713562755584716, disc_loss = 0.0029622834445908667
Trained batch 125 in epoch 4, gen_loss = 2.3695056873654563, disc_loss = 0.002958927195452686
Trained batch 126 in epoch 4, gen_loss = 2.369611589927373, disc_loss = 0.002950686132755336
Trained batch 127 in epoch 4, gen_loss = 2.368339415639639, disc_loss = 0.0029429650858219247
Trained batch 128 in epoch 4, gen_loss = 2.3677060511685157, disc_loss = 0.002945763997502567
Trained batch 129 in epoch 4, gen_loss = 2.366515064239502, disc_loss = 0.002943318568241711
Trained batch 130 in epoch 4, gen_loss = 2.3660954064085282, disc_loss = 0.0029393363875543114
Trained batch 131 in epoch 4, gen_loss = 2.3641987587466384, disc_loss = 0.002936566932917093
Trained batch 132 in epoch 4, gen_loss = 2.363701033412962, disc_loss = 0.002940661522482795
Trained batch 133 in epoch 4, gen_loss = 2.3637022456126426, disc_loss = 0.0029335140108144773
Trained batch 134 in epoch 4, gen_loss = 2.3626663402274803, disc_loss = 0.0029281998708568235
Trained batch 135 in epoch 4, gen_loss = 2.3641051913008972, disc_loss = 0.0029250360333689432
Trained batch 136 in epoch 4, gen_loss = 2.3646409320135184, disc_loss = 0.002917431475064398
Trained batch 137 in epoch 4, gen_loss = 2.3668948792029116, disc_loss = 0.0029133559049417577
Trained batch 138 in epoch 4, gen_loss = 2.362923361414628, disc_loss = 0.002908016317155507
Trained batch 139 in epoch 4, gen_loss = 2.3607745255742754, disc_loss = 0.0029010145833516226
Trained batch 140 in epoch 4, gen_loss = 2.3572958411899863, disc_loss = 0.0028964512352336277
Trained batch 141 in epoch 4, gen_loss = 2.359856064890472, disc_loss = 0.0028924739544122467
Trained batch 142 in epoch 4, gen_loss = 2.3596921483953515, disc_loss = 0.002887675029850871
Trained batch 143 in epoch 4, gen_loss = 2.360366958710882, disc_loss = 0.002886647652000344
Trained batch 144 in epoch 4, gen_loss = 2.3603151074771223, disc_loss = 0.0028847450960491753
Trained batch 145 in epoch 4, gen_loss = 2.3611016812389845, disc_loss = 0.002876871117958416
Trained batch 146 in epoch 4, gen_loss = 2.3616398743220737, disc_loss = 0.0028678340588689966
Trained batch 147 in epoch 4, gen_loss = 2.361325993731215, disc_loss = 0.0028688120616385967
Trained batch 148 in epoch 4, gen_loss = 2.3610047702021246, disc_loss = 0.0028729993270260076
Trained batch 149 in epoch 4, gen_loss = 2.361094667116801, disc_loss = 0.002871147848200053
Trained batch 150 in epoch 4, gen_loss = 2.3616801239796823, disc_loss = 0.0028684324074524227
Trained batch 151 in epoch 4, gen_loss = 2.3617329581787714, disc_loss = 0.0028676268633908444
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 2.179253578186035, disc_loss = 0.0030684657394886017
Trained batch 1 in epoch 5, gen_loss = 2.2916815280914307, disc_loss = 0.0025723567232489586
Trained batch 2 in epoch 5, gen_loss = 2.3311750094095864, disc_loss = 0.0025381138548254967
Trained batch 3 in epoch 5, gen_loss = 2.430745005607605, disc_loss = 0.002595712197944522
Trained batch 4 in epoch 5, gen_loss = 2.3917888164520265, disc_loss = 0.00249486886896193
Trained batch 5 in epoch 5, gen_loss = 2.3579429388046265, disc_loss = 0.002575269628626605
Trained batch 6 in epoch 5, gen_loss = 2.3922058173588345, disc_loss = 0.002473573399973767
Trained batch 7 in epoch 5, gen_loss = 2.360973834991455, disc_loss = 0.002491768856998533
Trained batch 8 in epoch 5, gen_loss = 2.3897107707129583, disc_loss = 0.002508043156315883
Trained batch 9 in epoch 5, gen_loss = 2.4042153358459473, disc_loss = 0.0024644180200994016
Trained batch 10 in epoch 5, gen_loss = 2.4037612568248403, disc_loss = 0.0023783315819772806
Trained batch 11 in epoch 5, gen_loss = 2.3978435595830283, disc_loss = 0.002335684315767139
Trained batch 12 in epoch 5, gen_loss = 2.398220942570613, disc_loss = 0.002410830625404532
Trained batch 13 in epoch 5, gen_loss = 2.3752071176256453, disc_loss = 0.0025107095383905937
Trained batch 14 in epoch 5, gen_loss = 2.37143988609314, disc_loss = 0.0025393983504424494
Trained batch 15 in epoch 5, gen_loss = 2.385442227125168, disc_loss = 0.0025455599679844454
Trained batch 16 in epoch 5, gen_loss = 2.3971668131211223, disc_loss = 0.0025306515368249487
Trained batch 17 in epoch 5, gen_loss = 2.385544326570299, disc_loss = 0.00253520845176859
Trained batch 18 in epoch 5, gen_loss = 2.38140869140625, disc_loss = 0.0025139073473646454
Trained batch 19 in epoch 5, gen_loss = 2.363948404788971, disc_loss = 0.0024958204361610115
Trained batch 20 in epoch 5, gen_loss = 2.3807828539893743, disc_loss = 0.0024579567612991447
Trained batch 21 in epoch 5, gen_loss = 2.39507502859289, disc_loss = 0.002446502595293251
Trained batch 22 in epoch 5, gen_loss = 2.4096550215845522, disc_loss = 0.00245943661455227
Trained batch 23 in epoch 5, gen_loss = 2.4178683757781982, disc_loss = 0.0024634675258615366
Trained batch 24 in epoch 5, gen_loss = 2.4173775196075438, disc_loss = 0.0024450383055955173
Trained batch 25 in epoch 5, gen_loss = 2.424421136195843, disc_loss = 0.002435327838891401
Trained batch 26 in epoch 5, gen_loss = 2.4121563964419894, disc_loss = 0.0025418619883971084
Trained batch 27 in epoch 5, gen_loss = 2.4106457829475403, disc_loss = 0.0026200630652186063
Trained batch 28 in epoch 5, gen_loss = 2.3998291328035553, disc_loss = 0.002664311130627476
Trained batch 29 in epoch 5, gen_loss = 2.3928789536158246, disc_loss = 0.002684723787630598
Trained batch 30 in epoch 5, gen_loss = 2.3823782474763933, disc_loss = 0.0026840649905704684
Trained batch 31 in epoch 5, gen_loss = 2.383715867996216, disc_loss = 0.002672213231562637
Trained batch 32 in epoch 5, gen_loss = 2.380688775669445, disc_loss = 0.0026925164980418754
Trained batch 33 in epoch 5, gen_loss = 2.388266984154196, disc_loss = 0.0027183381881674424
Trained batch 34 in epoch 5, gen_loss = 2.3818832533700127, disc_loss = 0.0027209394944033454
Trained batch 35 in epoch 5, gen_loss = 2.38064444065094, disc_loss = 0.0027501295359494784
Trained batch 36 in epoch 5, gen_loss = 2.3827570837897225, disc_loss = 0.002781695654817127
Trained batch 37 in epoch 5, gen_loss = 2.3809177185359753, disc_loss = 0.002791875691496228
Trained batch 38 in epoch 5, gen_loss = 2.3794771096645255, disc_loss = 0.0027971523694503
Trained batch 39 in epoch 5, gen_loss = 2.380723291635513, disc_loss = 0.002815004100557417
Trained batch 40 in epoch 5, gen_loss = 2.37389051041952, disc_loss = 0.002832883088735909
Trained batch 41 in epoch 5, gen_loss = 2.3820608116331554, disc_loss = 0.002851674798876047
Trained batch 42 in epoch 5, gen_loss = 2.38150252852329, disc_loss = 0.0028464856644182706
Trained batch 43 in epoch 5, gen_loss = 2.379181683063507, disc_loss = 0.002830427441618998
Trained batch 44 in epoch 5, gen_loss = 2.380752690633138, disc_loss = 0.002860475005581975
Trained batch 45 in epoch 5, gen_loss = 2.3832531752793686, disc_loss = 0.0028779647647119736
Trained batch 46 in epoch 5, gen_loss = 2.38414691864176, disc_loss = 0.002890601982065338
Trained batch 47 in epoch 5, gen_loss = 2.382407600680987, disc_loss = 0.002887765018385835
Trained batch 48 in epoch 5, gen_loss = 2.3851275784628734, disc_loss = 0.0028695443987238165
Trained batch 49 in epoch 5, gen_loss = 2.3902240324020387, disc_loss = 0.0028471618331968786
Trained batch 50 in epoch 5, gen_loss = 2.3859252882938757, disc_loss = 0.0028232100839708364
Trained batch 51 in epoch 5, gen_loss = 2.38281642473661, disc_loss = 0.0028153710837404314
Trained batch 52 in epoch 5, gen_loss = 2.3862794615187735, disc_loss = 0.002839030987881827
Trained batch 53 in epoch 5, gen_loss = 2.3796221724262945, disc_loss = 0.002831267856958288
Trained batch 54 in epoch 5, gen_loss = 2.3812753894112326, disc_loss = 0.002820690247145566
Trained batch 55 in epoch 5, gen_loss = 2.381791991846902, disc_loss = 0.0028141416800541003
Trained batch 56 in epoch 5, gen_loss = 2.378600526274296, disc_loss = 0.0028108054886392332
Trained batch 57 in epoch 5, gen_loss = 2.386584450458658, disc_loss = 0.002793592661779759
Trained batch 58 in epoch 5, gen_loss = 2.3853626493680276, disc_loss = 0.002810397315612536
Trained batch 59 in epoch 5, gen_loss = 2.3906237920125326, disc_loss = 0.002804302416431407
Trained batch 60 in epoch 5, gen_loss = 2.390972657281844, disc_loss = 0.002785801511547971
Trained batch 61 in epoch 5, gen_loss = 2.3889690945225377, disc_loss = 0.0027778272257907495
Trained batch 62 in epoch 5, gen_loss = 2.3878433628687783, disc_loss = 0.002765318709573457
Trained batch 63 in epoch 5, gen_loss = 2.386501181870699, disc_loss = 0.0027540141072677216
Trained batch 64 in epoch 5, gen_loss = 2.384975209602943, disc_loss = 0.0027420972384369145
Trained batch 65 in epoch 5, gen_loss = 2.385290821393331, disc_loss = 0.002728112170712627
Trained batch 66 in epoch 5, gen_loss = 2.3830089391167486, disc_loss = 0.0027211167825274725
Trained batch 67 in epoch 5, gen_loss = 2.3835173705044914, disc_loss = 0.0027200476735529
Trained batch 68 in epoch 5, gen_loss = 2.3815619910972705, disc_loss = 0.0027055232077027144
Trained batch 69 in epoch 5, gen_loss = 2.380732784952436, disc_loss = 0.002690622185556484
Trained batch 70 in epoch 5, gen_loss = 2.3773471738251164, disc_loss = 0.0026899806804246674
Trained batch 71 in epoch 5, gen_loss = 2.378265963660346, disc_loss = 0.0026997668044512263
Trained batch 72 in epoch 5, gen_loss = 2.376390195872686, disc_loss = 0.0026933346629423433
Trained batch 73 in epoch 5, gen_loss = 2.3797356921273307, disc_loss = 0.002695151977555675
Trained batch 74 in epoch 5, gen_loss = 2.378401314417521, disc_loss = 0.0026906452560797336
Trained batch 75 in epoch 5, gen_loss = 2.3765015257032296, disc_loss = 0.002681169240723217
Trained batch 76 in epoch 5, gen_loss = 2.3728828956554464, disc_loss = 0.0026736177289374656
Trained batch 77 in epoch 5, gen_loss = 2.3751823749297705, disc_loss = 0.0026672440476548406
Trained batch 78 in epoch 5, gen_loss = 2.3736765988265414, disc_loss = 0.002659246427172064
Trained batch 79 in epoch 5, gen_loss = 2.3798751056194307, disc_loss = 0.0026528649948886597
Trained batch 80 in epoch 5, gen_loss = 2.3814236146432384, disc_loss = 0.002656452744382859
Trained batch 81 in epoch 5, gen_loss = 2.3836931164671733, disc_loss = 0.0026678149829754924
Trained batch 82 in epoch 5, gen_loss = 2.3843740928603943, disc_loss = 0.002667059534206897
Trained batch 83 in epoch 5, gen_loss = 2.384430147352673, disc_loss = 0.0026618360078871427
Trained batch 84 in epoch 5, gen_loss = 2.3837016161750344, disc_loss = 0.002659111438483438
Trained batch 85 in epoch 5, gen_loss = 2.386051604914111, disc_loss = 0.002654296915902388
Trained batch 86 in epoch 5, gen_loss = 2.3904453255664344, disc_loss = 0.0026469513808708937
Trained batch 87 in epoch 5, gen_loss = 2.388615207238631, disc_loss = 0.002643402354971675
Trained batch 88 in epoch 5, gen_loss = 2.387030424696676, disc_loss = 0.002639542628090117
Trained batch 89 in epoch 5, gen_loss = 2.3876490513483684, disc_loss = 0.0026363473631338115
Trained batch 90 in epoch 5, gen_loss = 2.385150676245218, disc_loss = 0.0026404697148661527
Trained batch 91 in epoch 5, gen_loss = 2.3839598764543948, disc_loss = 0.0026370386388051606
Trained batch 92 in epoch 5, gen_loss = 2.3853197431051605, disc_loss = 0.0026417393224834594
Trained batch 93 in epoch 5, gen_loss = 2.384982887734758, disc_loss = 0.002647026014722329
Trained batch 94 in epoch 5, gen_loss = 2.3854055304276316, disc_loss = 0.0026547207484806054
Trained batch 95 in epoch 5, gen_loss = 2.3861011465390525, disc_loss = 0.002665188055592201
Trained batch 96 in epoch 5, gen_loss = 2.3892693224641466, disc_loss = 0.0026673323957287927
Trained batch 97 in epoch 5, gen_loss = 2.3899962123559444, disc_loss = 0.00266707533785161
Trained batch 98 in epoch 5, gen_loss = 2.389183167255286, disc_loss = 0.00265835138799792
Trained batch 99 in epoch 5, gen_loss = 2.38794588804245, disc_loss = 0.0026506718422751874
Trained batch 100 in epoch 5, gen_loss = 2.3879990931784754, disc_loss = 0.0026508226937678927
Trained batch 101 in epoch 5, gen_loss = 2.3872720774482277, disc_loss = 0.002643490391646457
Trained batch 102 in epoch 5, gen_loss = 2.388140108978864, disc_loss = 0.002638058331162099
Trained batch 103 in epoch 5, gen_loss = 2.38756119287931, disc_loss = 0.002636247709653197
Trained batch 104 in epoch 5, gen_loss = 2.385276472000849, disc_loss = 0.0026373289980082992
Trained batch 105 in epoch 5, gen_loss = 2.3820757258613154, disc_loss = 0.002635505343655581
Trained batch 106 in epoch 5, gen_loss = 2.381673705912082, disc_loss = 0.0026324495583964144
Trained batch 107 in epoch 5, gen_loss = 2.3810330165757074, disc_loss = 0.002628545730624831
Trained batch 108 in epoch 5, gen_loss = 2.382215257084698, disc_loss = 0.002626227878179367
Trained batch 109 in epoch 5, gen_loss = 2.3820289633490823, disc_loss = 0.002618941304866563
Trained batch 110 in epoch 5, gen_loss = 2.3819029331207275, disc_loss = 0.002614082900706578
Trained batch 111 in epoch 5, gen_loss = 2.381517597607204, disc_loss = 0.0026065271117009354
Trained batch 112 in epoch 5, gen_loss = 2.379830134653412, disc_loss = 0.0026058328237005437
Trained batch 113 in epoch 5, gen_loss = 2.3788668126390693, disc_loss = 0.002608442245043095
Trained batch 114 in epoch 5, gen_loss = 2.376770606248275, disc_loss = 0.0026055229574684863
Trained batch 115 in epoch 5, gen_loss = 2.3754494580729255, disc_loss = 0.0026035832616516613
Trained batch 116 in epoch 5, gen_loss = 2.3753676577510996, disc_loss = 0.002606288421477199
Trained batch 117 in epoch 5, gen_loss = 2.376813536983425, disc_loss = 0.002597447866534467
Trained batch 118 in epoch 5, gen_loss = 2.38027517935809, disc_loss = 0.002603326884035741
Trained batch 119 in epoch 5, gen_loss = 2.37895867228508, disc_loss = 0.002604583979700692
Trained batch 120 in epoch 5, gen_loss = 2.3804878163928826, disc_loss = 0.002605504005154487
Trained batch 121 in epoch 5, gen_loss = 2.379290445906217, disc_loss = 0.002613328255094649
Trained batch 122 in epoch 5, gen_loss = 2.3781839521919808, disc_loss = 0.0026148748006747384
Trained batch 123 in epoch 5, gen_loss = 2.3781969201180244, disc_loss = 0.002606567139023795
Trained batch 124 in epoch 5, gen_loss = 2.376346992492676, disc_loss = 0.002601337336935103
Trained batch 125 in epoch 5, gen_loss = 2.3724695444107056, disc_loss = 0.002606065693451831
Trained batch 126 in epoch 5, gen_loss = 2.3722981730784016, disc_loss = 0.0026066031693810906
Trained batch 127 in epoch 5, gen_loss = 2.372780591249466, disc_loss = 0.002602436160486832
Trained batch 128 in epoch 5, gen_loss = 2.3755548591761624, disc_loss = 0.0026071389871757736
Trained batch 129 in epoch 5, gen_loss = 2.3724688896766075, disc_loss = 0.00261038192995609
Trained batch 130 in epoch 5, gen_loss = 2.3734829753409814, disc_loss = 0.0026121858821982757
Trained batch 131 in epoch 5, gen_loss = 2.374881406625112, disc_loss = 0.0026140958626373586
Trained batch 132 in epoch 5, gen_loss = 2.37312814884616, disc_loss = 0.002609455631520683
Trained batch 133 in epoch 5, gen_loss = 2.3707377786066997, disc_loss = 0.0026054675577889515
Trained batch 134 in epoch 5, gen_loss = 2.3693197409311932, disc_loss = 0.002605680073611438
Trained batch 135 in epoch 5, gen_loss = 2.3690633335534264, disc_loss = 0.0025980506573379148
Trained batch 136 in epoch 5, gen_loss = 2.3673888088142783, disc_loss = 0.00259750480270761
Trained batch 137 in epoch 5, gen_loss = 2.3675910839136094, disc_loss = 0.0025973983650581667
Trained batch 138 in epoch 5, gen_loss = 2.3667522694567125, disc_loss = 0.0025915054482133163
Trained batch 139 in epoch 5, gen_loss = 2.3669903550829208, disc_loss = 0.0025867739368030536
Trained batch 140 in epoch 5, gen_loss = 2.3647251433514533, disc_loss = 0.0025819338517963676
Trained batch 141 in epoch 5, gen_loss = 2.3627590830896943, disc_loss = 0.0025768763431623367
Trained batch 142 in epoch 5, gen_loss = 2.3613499628080357, disc_loss = 0.0025699860277956913
Trained batch 143 in epoch 5, gen_loss = 2.3632253143522473, disc_loss = 0.0025654693882744242
Trained batch 144 in epoch 5, gen_loss = 2.3623779872368122, disc_loss = 0.002562532372419433
Trained batch 145 in epoch 5, gen_loss = 2.36197097660744, disc_loss = 0.0025575698284776753
Trained batch 146 in epoch 5, gen_loss = 2.3625116737521425, disc_loss = 0.0025607101218521494
Trained batch 147 in epoch 5, gen_loss = 2.3605862904239343, disc_loss = 0.0025620965210003525
Trained batch 148 in epoch 5, gen_loss = 2.358710599425655, disc_loss = 0.002556797528745694
Trained batch 149 in epoch 5, gen_loss = 2.3583297395706175, disc_loss = 0.0025559006825399896
Trained batch 150 in epoch 5, gen_loss = 2.3592455260801, disc_loss = 0.002556022904992153
Trained batch 151 in epoch 5, gen_loss = 2.3580399563438013, disc_loss = 0.0025533268811781646
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 2.136620044708252, disc_loss = 0.002556965686380863
Trained batch 1 in epoch 6, gen_loss = 2.144351005554199, disc_loss = 0.00282623537350446
Trained batch 2 in epoch 6, gen_loss = 2.4249768257141113, disc_loss = 0.0026897144659111896
Trained batch 3 in epoch 6, gen_loss = 2.3132402300834656, disc_loss = 0.0026623900048434734
Trained batch 4 in epoch 6, gen_loss = 2.3818113803863525, disc_loss = 0.0028388957027345894
Trained batch 5 in epoch 6, gen_loss = 2.3759028116861978, disc_loss = 0.0028293903839463987
Trained batch 6 in epoch 6, gen_loss = 2.382144178662981, disc_loss = 0.002823766620297517
Trained batch 7 in epoch 6, gen_loss = 2.392185688018799, disc_loss = 0.002725222846493125
Trained batch 8 in epoch 6, gen_loss = 2.393365012274848, disc_loss = 0.0028202994467897546
Trained batch 9 in epoch 6, gen_loss = 2.4134257316589354, disc_loss = 0.0030267803696915506
Trained batch 10 in epoch 6, gen_loss = 2.408977660265836, disc_loss = 0.0029922105287286367
Trained batch 11 in epoch 6, gen_loss = 2.413811981678009, disc_loss = 0.0029649442294612527
Trained batch 12 in epoch 6, gen_loss = 2.409685116547805, disc_loss = 0.0030413256026804447
Trained batch 13 in epoch 6, gen_loss = 2.4055675779070174, disc_loss = 0.0031628985556640793
Trained batch 14 in epoch 6, gen_loss = 2.397992006937663, disc_loss = 0.003130114156131943
Trained batch 15 in epoch 6, gen_loss = 2.379541337490082, disc_loss = 0.0031134374876273796
Trained batch 16 in epoch 6, gen_loss = 2.3725302079144646, disc_loss = 0.0030921883196296063
Trained batch 17 in epoch 6, gen_loss = 2.3773380517959595, disc_loss = 0.0030506464471626612
Trained batch 18 in epoch 6, gen_loss = 2.3794064647273014, disc_loss = 0.0030424608971531455
Trained batch 19 in epoch 6, gen_loss = 2.380105268955231, disc_loss = 0.003068248915951699
Trained batch 20 in epoch 6, gen_loss = 2.385628654843285, disc_loss = 0.003041767193714068
Trained batch 21 in epoch 6, gen_loss = 2.3646738962693648, disc_loss = 0.0030476574320346117
Trained batch 22 in epoch 6, gen_loss = 2.3687432123267134, disc_loss = 0.0030307618739164395
Trained batch 23 in epoch 6, gen_loss = 2.369707296291987, disc_loss = 0.0030633369266676405
Trained batch 24 in epoch 6, gen_loss = 2.3720351886749267, disc_loss = 0.003128687757998705
Trained batch 25 in epoch 6, gen_loss = 2.3814832338920007, disc_loss = 0.003224033110130292
Trained batch 26 in epoch 6, gen_loss = 2.3711689666465476, disc_loss = 0.003205062674910382
Trained batch 27 in epoch 6, gen_loss = 2.3610155412128995, disc_loss = 0.0032399415753648748
Trained batch 28 in epoch 6, gen_loss = 2.3673685419148414, disc_loss = 0.003293809649566638
Trained batch 29 in epoch 6, gen_loss = 2.3707667430241903, disc_loss = 0.003311442824391027
Trained batch 30 in epoch 6, gen_loss = 2.373031962302423, disc_loss = 0.003311639636634819
Trained batch 31 in epoch 6, gen_loss = 2.3724519163370132, disc_loss = 0.0033026972523657605
Trained batch 32 in epoch 6, gen_loss = 2.3762843536608145, disc_loss = 0.003270038685789614
Trained batch 33 in epoch 6, gen_loss = 2.3680514027090633, disc_loss = 0.003234226263456923
Trained batch 34 in epoch 6, gen_loss = 2.3618390832628524, disc_loss = 0.0032084290270826647
Trained batch 35 in epoch 6, gen_loss = 2.3591272168689303, disc_loss = 0.003193089861371037
Trained batch 36 in epoch 6, gen_loss = 2.3707010230502568, disc_loss = 0.0031547766506067805
Trained batch 37 in epoch 6, gen_loss = 2.369522772337261, disc_loss = 0.0031347708090355524
Trained batch 38 in epoch 6, gen_loss = 2.3807744551927614, disc_loss = 0.0031223618485129033
Trained batch 39 in epoch 6, gen_loss = 2.377046024799347, disc_loss = 0.0031052535923663527
Trained batch 40 in epoch 6, gen_loss = 2.3783993255801317, disc_loss = 0.0031073385645158406
Trained batch 41 in epoch 6, gen_loss = 2.371888739722116, disc_loss = 0.0030998083474558023
Trained batch 42 in epoch 6, gen_loss = 2.3770461082458496, disc_loss = 0.0030852718776914964
Trained batch 43 in epoch 6, gen_loss = 2.375154814936898, disc_loss = 0.003075391927268356
Trained batch 44 in epoch 6, gen_loss = 2.3699073155721027, disc_loss = 0.003064387845289376
Trained batch 45 in epoch 6, gen_loss = 2.3655900955200195, disc_loss = 0.003047860156663734
Trained batch 46 in epoch 6, gen_loss = 2.3624112048047654, disc_loss = 0.0030320316771084957
Trained batch 47 in epoch 6, gen_loss = 2.36040269335111, disc_loss = 0.003031394080608152
Trained batch 48 in epoch 6, gen_loss = 2.358067566034745, disc_loss = 0.00300894013121344
Trained batch 49 in epoch 6, gen_loss = 2.354541440010071, disc_loss = 0.003018284149002284
Trained batch 50 in epoch 6, gen_loss = 2.351337521683936, disc_loss = 0.003010910504278453
Trained batch 51 in epoch 6, gen_loss = 2.350751899755918, disc_loss = 0.003031853718521933
Trained batch 52 in epoch 6, gen_loss = 2.345784173821503, disc_loss = 0.0030542012844410426
Trained batch 53 in epoch 6, gen_loss = 2.3450113049259893, disc_loss = 0.003061499004683423
Trained batch 54 in epoch 6, gen_loss = 2.3493717193603514, disc_loss = 0.0030641143273731526
Trained batch 55 in epoch 6, gen_loss = 2.349564347948347, disc_loss = 0.003059732122762528
Trained batch 56 in epoch 6, gen_loss = 2.3445976993493867, disc_loss = 0.0030431455642540464
Trained batch 57 in epoch 6, gen_loss = 2.347341274393016, disc_loss = 0.003034799245330666
Trained batch 58 in epoch 6, gen_loss = 2.346723374673876, disc_loss = 0.003014060167469463
Trained batch 59 in epoch 6, gen_loss = 2.3446327010790506, disc_loss = 0.0029978855474231143
Trained batch 60 in epoch 6, gen_loss = 2.3501430769435694, disc_loss = 0.0029850740779618747
Trained batch 61 in epoch 6, gen_loss = 2.346983536597221, disc_loss = 0.00296761603620384
Trained batch 62 in epoch 6, gen_loss = 2.347130983594864, disc_loss = 0.0029568623248783367
Trained batch 63 in epoch 6, gen_loss = 2.3470452167093754, disc_loss = 0.0029501045428332873
Trained batch 64 in epoch 6, gen_loss = 2.3460321206312913, disc_loss = 0.0029271405978271593
Trained batch 65 in epoch 6, gen_loss = 2.3442629792473535, disc_loss = 0.002908859592439099
Trained batch 66 in epoch 6, gen_loss = 2.34510623874949, disc_loss = 0.0029016786095088544
Trained batch 67 in epoch 6, gen_loss = 2.3539793771855972, disc_loss = 0.00288797593470115
Trained batch 68 in epoch 6, gen_loss = 2.355269673941792, disc_loss = 0.002891617162369084
Trained batch 69 in epoch 6, gen_loss = 2.352358865737915, disc_loss = 0.0029129193663331014
Trained batch 70 in epoch 6, gen_loss = 2.35479818263524, disc_loss = 0.0029536728570106583
Trained batch 71 in epoch 6, gen_loss = 2.3491017917792, disc_loss = 0.0029581205874112332
Trained batch 72 in epoch 6, gen_loss = 2.3471974771316737, disc_loss = 0.002946060083883062
Trained batch 73 in epoch 6, gen_loss = 2.3453036643363334, disc_loss = 0.0029341154731810093
Trained batch 74 in epoch 6, gen_loss = 2.3492238680521647, disc_loss = 0.0029264643229544164
Trained batch 75 in epoch 6, gen_loss = 2.3478650858527734, disc_loss = 0.002910015929955989
Trained batch 76 in epoch 6, gen_loss = 2.350749155143639, disc_loss = 0.0028916339650024454
Trained batch 77 in epoch 6, gen_loss = 2.348754781943101, disc_loss = 0.0028773779795767786
Trained batch 78 in epoch 6, gen_loss = 2.3468563013438937, disc_loss = 0.0028833397870435366
Trained batch 79 in epoch 6, gen_loss = 2.3439193069934845, disc_loss = 0.0028772508463589474
Trained batch 80 in epoch 6, gen_loss = 2.343471179773778, disc_loss = 0.002880340074131518
Trained batch 81 in epoch 6, gen_loss = 2.344164095273832, disc_loss = 0.002890157717757109
Trained batch 82 in epoch 6, gen_loss = 2.3465896945401847, disc_loss = 0.0030243917289807134
Trained batch 83 in epoch 6, gen_loss = 2.3450539168857394, disc_loss = 0.0031587834957809676
Trained batch 84 in epoch 6, gen_loss = 2.344091533212101, disc_loss = 0.0032698759480434304
Trained batch 85 in epoch 6, gen_loss = 2.3457387103590857, disc_loss = 0.003372295239810334
Trained batch 86 in epoch 6, gen_loss = 2.3481126270074952, disc_loss = 0.0039905422934512986
Trained batch 87 in epoch 6, gen_loss = 2.344719163396142, disc_loss = 0.004586829401722009
Trained batch 88 in epoch 6, gen_loss = 2.3408711492345575, disc_loss = 0.006995044251003962
Trained batch 89 in epoch 6, gen_loss = 2.3415889104207355, disc_loss = 0.010661872745388084
Trained batch 90 in epoch 6, gen_loss = 2.343180470414214, disc_loss = 0.0156534987368754
Trained batch 91 in epoch 6, gen_loss = 2.3449583908785945, disc_loss = 0.0202465470596824
Trained batch 92 in epoch 6, gen_loss = 2.3483617151937177, disc_loss = 0.027539851063842415
Trained batch 93 in epoch 6, gen_loss = 2.3532531388262483, disc_loss = 0.037149339775614285
Trained batch 94 in epoch 6, gen_loss = 2.3508418334157843, disc_loss = 0.038410661271528194
Trained batch 95 in epoch 6, gen_loss = 2.347404181957245, disc_loss = 0.03928066838610297
Trained batch 96 in epoch 6, gen_loss = 2.3433651838105978, disc_loss = 0.03939292140151422
Trained batch 97 in epoch 6, gen_loss = 2.3420830320338815, disc_loss = 0.03924714150477429
Trained batch 98 in epoch 6, gen_loss = 2.3441810860778345, disc_loss = 0.038988343938583074
Trained batch 99 in epoch 6, gen_loss = 2.345411194562912, disc_loss = 0.038697689650580284
Trained batch 100 in epoch 6, gen_loss = 2.3446486503771036, disc_loss = 0.03842526967498926
Trained batch 101 in epoch 6, gen_loss = 2.3419553847873913, disc_loss = 0.038108026937526816
Trained batch 102 in epoch 6, gen_loss = 2.339865262068591, disc_loss = 0.037823894377617004
Trained batch 103 in epoch 6, gen_loss = 2.340205606359702, disc_loss = 0.037533913842008375
Trained batch 104 in epoch 6, gen_loss = 2.3402773505165464, disc_loss = 0.03723620878798621
Trained batch 105 in epoch 6, gen_loss = 2.341323682722056, disc_loss = 0.036913414371533775
Trained batch 106 in epoch 6, gen_loss = 2.3439133624050106, disc_loss = 0.03659160808816761
Trained batch 107 in epoch 6, gen_loss = 2.3398926898285195, disc_loss = 0.03638968831661192
Trained batch 108 in epoch 6, gen_loss = 2.34406117124295, disc_loss = 0.036148033346211826
Trained batch 109 in epoch 6, gen_loss = 2.3480069593949753, disc_loss = 0.03585744516881691
Trained batch 110 in epoch 6, gen_loss = 2.349182605743408, disc_loss = 0.035585522762843755
Trained batch 111 in epoch 6, gen_loss = 2.3492078525679454, disc_loss = 0.03529136404020911
Trained batch 112 in epoch 6, gen_loss = 2.3489946306279275, disc_loss = 0.03500152142322828
Trained batch 113 in epoch 6, gen_loss = 2.3501395593609726, disc_loss = 0.03473025901047023
Trained batch 114 in epoch 6, gen_loss = 2.3522931326990544, disc_loss = 0.03446964756788119
Trained batch 115 in epoch 6, gen_loss = 2.352055140610399, disc_loss = 0.034187209132079295
Trained batch 116 in epoch 6, gen_loss = 2.3529452421726327, disc_loss = 0.033911156982509814
Trained batch 117 in epoch 6, gen_loss = 2.3528573917130293, disc_loss = 0.03365484234320505
Trained batch 118 in epoch 6, gen_loss = 2.354449135916574, disc_loss = 0.0334038622393625
Trained batch 119 in epoch 6, gen_loss = 2.3528177698453265, disc_loss = 0.033147171398741196
Trained batch 120 in epoch 6, gen_loss = 2.353066708430771, disc_loss = 0.0328908074514417
Trained batch 121 in epoch 6, gen_loss = 2.354826657498469, disc_loss = 0.03263753947904944
Trained batch 122 in epoch 6, gen_loss = 2.3542892797206476, disc_loss = 0.03239709782561787
Trained batch 123 in epoch 6, gen_loss = 2.352719230036582, disc_loss = 0.03215750711763488
Trained batch 124 in epoch 6, gen_loss = 2.3527755908966066, disc_loss = 0.03192648048419505
Trained batch 125 in epoch 6, gen_loss = 2.3508699829616244, disc_loss = 0.03172121358950371
Trained batch 126 in epoch 6, gen_loss = 2.349566431496087, disc_loss = 0.031531751978093776
Trained batch 127 in epoch 6, gen_loss = 2.3502928763628006, disc_loss = 0.031458971688152815
Trained batch 128 in epoch 6, gen_loss = 2.351697093756624, disc_loss = 0.03156108286524148
Trained batch 129 in epoch 6, gen_loss = 2.35319017630357, disc_loss = 0.031754906318831044
Trained batch 130 in epoch 6, gen_loss = 2.353735650768717, disc_loss = 0.03163878672368796
Trained batch 131 in epoch 6, gen_loss = 2.3543438785003894, disc_loss = 0.03144184815094129
Trained batch 132 in epoch 6, gen_loss = 2.3523060827326954, disc_loss = 0.031257081644686595
Trained batch 133 in epoch 6, gen_loss = 2.354702618584704, disc_loss = 0.031046314179765257
Trained batch 134 in epoch 6, gen_loss = 2.355968049720482, disc_loss = 0.030849820403899584
Trained batch 135 in epoch 6, gen_loss = 2.3575737178325653, disc_loss = 0.03067180080945357
Trained batch 136 in epoch 6, gen_loss = 2.358965017499715, disc_loss = 0.03047290530113544
Trained batch 137 in epoch 6, gen_loss = 2.360838470251664, disc_loss = 0.030293547427720405
Trained batch 138 in epoch 6, gen_loss = 2.359151653248629, disc_loss = 0.030133679188392628
Trained batch 139 in epoch 6, gen_loss = 2.361077981335776, disc_loss = 0.029947827221725936
Trained batch 140 in epoch 6, gen_loss = 2.361241284837114, disc_loss = 0.029760487776427987
Trained batch 141 in epoch 6, gen_loss = 2.3581376210064957, disc_loss = 0.029605280515298406
Trained batch 142 in epoch 6, gen_loss = 2.359624922692359, disc_loss = 0.0294329982138584
Trained batch 143 in epoch 6, gen_loss = 2.3609576142496533, disc_loss = 0.02926288991309573
Trained batch 144 in epoch 6, gen_loss = 2.360395283534609, disc_loss = 0.02909919285809557
Trained batch 145 in epoch 6, gen_loss = 2.359913024183822, disc_loss = 0.02892385969458352
Trained batch 146 in epoch 6, gen_loss = 2.3595789841243198, disc_loss = 0.02874685374966056
Trained batch 147 in epoch 6, gen_loss = 2.3584336509575716, disc_loss = 0.02857322960610602
Trained batch 148 in epoch 6, gen_loss = 2.3594420532252163, disc_loss = 0.02839930360314855
Trained batch 149 in epoch 6, gen_loss = 2.36216148853302, disc_loss = 0.028229187389370053
Trained batch 150 in epoch 6, gen_loss = 2.3613017079056493, disc_loss = 0.028082372760245982
Trained batch 151 in epoch 6, gen_loss = 2.3617791423672125, disc_loss = 0.027945203532765032
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 2.383331537246704, disc_loss = 0.003392706159502268
Trained batch 1 in epoch 7, gen_loss = 2.3247894048690796, disc_loss = 0.004634842975065112
Trained batch 2 in epoch 7, gen_loss = 2.2114214499791465, disc_loss = 0.0047025312669575214
Trained batch 3 in epoch 7, gen_loss = 2.302004784345627, disc_loss = 0.005036521819420159
Trained batch 4 in epoch 7, gen_loss = 2.338328719139099, disc_loss = 0.005677417386323214
Trained batch 5 in epoch 7, gen_loss = 2.372561196486155, disc_loss = 0.006133938130612175
Trained batch 6 in epoch 7, gen_loss = 2.3706679173878262, disc_loss = 0.006815311565463032
Trained batch 7 in epoch 7, gen_loss = 2.357190564274788, disc_loss = 0.006478237395640463
Trained batch 8 in epoch 7, gen_loss = 2.3346306880315146, disc_loss = 0.007022272536738051
Trained batch 9 in epoch 7, gen_loss = 2.3515183329582214, disc_loss = 0.007138340501114726
Trained batch 10 in epoch 7, gen_loss = 2.322596690871499, disc_loss = 0.006814550862393596
Trained batch 11 in epoch 7, gen_loss = 2.347259114185969, disc_loss = 0.007034480028475325
Trained batch 12 in epoch 7, gen_loss = 2.323761674074026, disc_loss = 0.007146731663781863
Trained batch 13 in epoch 7, gen_loss = 2.310364067554474, disc_loss = 0.006980807187833956
Trained batch 14 in epoch 7, gen_loss = 2.308211159706116, disc_loss = 0.00682351803407073
Trained batch 15 in epoch 7, gen_loss = 2.332719512283802, disc_loss = 0.006838169327238575
Trained batch 16 in epoch 7, gen_loss = 2.3329500520930573, disc_loss = 0.0067925576175398685
Trained batch 17 in epoch 7, gen_loss = 2.321434862083859, disc_loss = 0.006653110858880811
Trained batch 18 in epoch 7, gen_loss = 2.322782196496662, disc_loss = 0.006701825358169644
Trained batch 19 in epoch 7, gen_loss = 2.3337196171283723, disc_loss = 0.0066373791778460145
Trained batch 20 in epoch 7, gen_loss = 2.3238967884154547, disc_loss = 0.00658259591797278
Trained batch 21 in epoch 7, gen_loss = 2.3268920345739885, disc_loss = 0.006566867761483247
Trained batch 22 in epoch 7, gen_loss = 2.323018483493639, disc_loss = 0.00638344910238748
Trained batch 23 in epoch 7, gen_loss = 2.327245985468229, disc_loss = 0.00644374896849816
Trained batch 24 in epoch 7, gen_loss = 2.3307164335250854, disc_loss = 0.006646950896829366
Trained batch 25 in epoch 7, gen_loss = 2.341342710531675, disc_loss = 0.0066792657777953604
Trained batch 26 in epoch 7, gen_loss = 2.330872231059604, disc_loss = 0.0066449117708813265
Trained batch 27 in epoch 7, gen_loss = 2.3267065499510085, disc_loss = 0.006599263903418822
Trained batch 28 in epoch 7, gen_loss = 2.3248265981674194, disc_loss = 0.006584719546010782
Trained batch 29 in epoch 7, gen_loss = 2.327572023868561, disc_loss = 0.006698551665370663
Trained batch 30 in epoch 7, gen_loss = 2.3348650740038965, disc_loss = 0.007014416293391297
Trained batch 31 in epoch 7, gen_loss = 2.329530496150255, disc_loss = 0.007279278055648319
Trained batch 32 in epoch 7, gen_loss = 2.3352105725895274, disc_loss = 0.007552786857228388
Trained batch 33 in epoch 7, gen_loss = 2.345362968304578, disc_loss = 0.008212006746736519
Trained batch 34 in epoch 7, gen_loss = 2.345362775666373, disc_loss = 0.009198809880763293
Trained batch 35 in epoch 7, gen_loss = 2.3483023742834725, disc_loss = 0.009828629631859561
Trained batch 36 in epoch 7, gen_loss = 2.3571423485472396, disc_loss = 0.009656458816214188
Trained batch 37 in epoch 7, gen_loss = 2.354358814264599, disc_loss = 0.00954391031624063
Trained batch 38 in epoch 7, gen_loss = 2.354886394280654, disc_loss = 0.009406901167657895
Trained batch 39 in epoch 7, gen_loss = 2.359067788720131, disc_loss = 0.00926850566174835
Trained batch 40 in epoch 7, gen_loss = 2.352162695512539, disc_loss = 0.009140382907012613
Trained batch 41 in epoch 7, gen_loss = 2.360891362031301, disc_loss = 0.009117978913266035
Trained batch 42 in epoch 7, gen_loss = 2.3541060353434364, disc_loss = 0.009118873994191026
Trained batch 43 in epoch 7, gen_loss = 2.3486209972338243, disc_loss = 0.009036205042238262
Trained batch 44 in epoch 7, gen_loss = 2.353494715690613, disc_loss = 0.008890823756034175
Trained batch 45 in epoch 7, gen_loss = 2.3496187743933303, disc_loss = 0.00883834313540517
Trained batch 46 in epoch 7, gen_loss = 2.3515660788150545, disc_loss = 0.008832902771400962
Trained batch 47 in epoch 7, gen_loss = 2.353873334825039, disc_loss = 0.008919330842521353
Trained batch 48 in epoch 7, gen_loss = 2.3532511628403956, disc_loss = 0.008872313249133984
Trained batch 49 in epoch 7, gen_loss = 2.3540045762062074, disc_loss = 0.008825950878672302
Trained batch 50 in epoch 7, gen_loss = 2.3504929799659577, disc_loss = 0.008810576740834936
Trained batch 51 in epoch 7, gen_loss = 2.344796293056928, disc_loss = 0.008761761598109912
Trained batch 52 in epoch 7, gen_loss = 2.346540192388139, disc_loss = 0.008724016018809294
Trained batch 53 in epoch 7, gen_loss = 2.34974839731499, disc_loss = 0.008817315192168785
Trained batch 54 in epoch 7, gen_loss = 2.350436048074202, disc_loss = 0.008896788755770433
Trained batch 55 in epoch 7, gen_loss = 2.353131283606802, disc_loss = 0.00885763146132896
Trained batch 56 in epoch 7, gen_loss = 2.355145573616028, disc_loss = 0.008783999761043671
Trained batch 57 in epoch 7, gen_loss = 2.3588556441767463, disc_loss = 0.008690689060162625
Trained batch 58 in epoch 7, gen_loss = 2.358908376451266, disc_loss = 0.00860396426139494
Trained batch 59 in epoch 7, gen_loss = 2.35929652651151, disc_loss = 0.008551247293750446
Trained batch 60 in epoch 7, gen_loss = 2.3619772391241103, disc_loss = 0.008582468190398372
Trained batch 61 in epoch 7, gen_loss = 2.362557509253102, disc_loss = 0.00854522333810887
Trained batch 62 in epoch 7, gen_loss = 2.3693096429582625, disc_loss = 0.00846885499500093
Trained batch 63 in epoch 7, gen_loss = 2.3713150899857283, disc_loss = 0.008417971162998583
Trained batch 64 in epoch 7, gen_loss = 2.3755181074142455, disc_loss = 0.008396378961893228
Trained batch 65 in epoch 7, gen_loss = 2.3761286572976545, disc_loss = 0.008359260574886293
Trained batch 66 in epoch 7, gen_loss = 2.377855765285777, disc_loss = 0.008317415296697795
Trained batch 67 in epoch 7, gen_loss = 2.3804877242621254, disc_loss = 0.008292506668059266
Trained batch 68 in epoch 7, gen_loss = 2.37792324156001, disc_loss = 0.008237738803406988
Trained batch 69 in epoch 7, gen_loss = 2.380564984253475, disc_loss = 0.00819021440776331
Trained batch 70 in epoch 7, gen_loss = 2.3779274896836617, disc_loss = 0.00813392059169185
Trained batch 71 in epoch 7, gen_loss = 2.3749534206257925, disc_loss = 0.008085602014842961
Trained batch 72 in epoch 7, gen_loss = 2.3742833447782963, disc_loss = 0.008051903688744323
Trained batch 73 in epoch 7, gen_loss = 2.3767642314369612, disc_loss = 0.008009531327548463
Trained batch 74 in epoch 7, gen_loss = 2.381262714068095, disc_loss = 0.008112649514029423
Trained batch 75 in epoch 7, gen_loss = 2.377948960191325, disc_loss = 0.00818417718217365
Trained batch 76 in epoch 7, gen_loss = 2.380885438485579, disc_loss = 0.008251130816756517
Trained batch 77 in epoch 7, gen_loss = 2.3837426274250717, disc_loss = 0.008279971163481092
Trained batch 78 in epoch 7, gen_loss = 2.385779970808874, disc_loss = 0.00824205333932857
Trained batch 79 in epoch 7, gen_loss = 2.385568808019161, disc_loss = 0.008231126389000564
Trained batch 80 in epoch 7, gen_loss = 2.391220568138876, disc_loss = 0.0082491770800617
Trained batch 81 in epoch 7, gen_loss = 2.3933955212918723, disc_loss = 0.008560814076989161
Trained batch 82 in epoch 7, gen_loss = 2.397246342107474, disc_loss = 0.008890220805643553
Trained batch 83 in epoch 7, gen_loss = 2.3976634386039914, disc_loss = 0.008884211824763389
Trained batch 84 in epoch 7, gen_loss = 2.3949050047818354, disc_loss = 0.00884463791461552
Trained batch 85 in epoch 7, gen_loss = 2.3923882925233175, disc_loss = 0.008843394472848537
Trained batch 86 in epoch 7, gen_loss = 2.3888171061702157, disc_loss = 0.008804778290120349
Trained batch 87 in epoch 7, gen_loss = 2.3862775577740236, disc_loss = 0.008788505468559875
Trained batch 88 in epoch 7, gen_loss = 2.386370105689831, disc_loss = 0.008840799064825424
Trained batch 89 in epoch 7, gen_loss = 2.3870943744977313, disc_loss = 0.008797262852183647
Trained batch 90 in epoch 7, gen_loss = 2.3851015947677277, disc_loss = 0.008735550191396704
Trained batch 91 in epoch 7, gen_loss = 2.389119600472243, disc_loss = 0.008661584898262568
Trained batch 92 in epoch 7, gen_loss = 2.3902158775637226, disc_loss = 0.008588027015017966
Trained batch 93 in epoch 7, gen_loss = 2.3918974818067347, disc_loss = 0.008512648052852997
Trained batch 94 in epoch 7, gen_loss = 2.394071253977324, disc_loss = 0.00843868262722696
Trained batch 95 in epoch 7, gen_loss = 2.3938656163712344, disc_loss = 0.008368006390810478
Trained batch 96 in epoch 7, gen_loss = 2.3907082781349263, disc_loss = 0.008304886527109853
Trained batch 97 in epoch 7, gen_loss = 2.3893733426016204, disc_loss = 0.008244866571788276
Trained batch 98 in epoch 7, gen_loss = 2.387503073673056, disc_loss = 0.008179943498242834
Trained batch 99 in epoch 7, gen_loss = 2.388475433588028, disc_loss = 0.008112402257975191
Trained batch 100 in epoch 7, gen_loss = 2.3864948808556736, disc_loss = 0.00805002926171084
Trained batch 101 in epoch 7, gen_loss = 2.383845024249133, disc_loss = 0.00798970777495746
Trained batch 102 in epoch 7, gen_loss = 2.3814927686765355, disc_loss = 0.007932524578826665
Trained batch 103 in epoch 7, gen_loss = 2.3811262261409025, disc_loss = 0.007871482034366077
Trained batch 104 in epoch 7, gen_loss = 2.3781647852488925, disc_loss = 0.00781498371202144
Trained batch 105 in epoch 7, gen_loss = 2.375889738775649, disc_loss = 0.007759965421359564
Trained batch 106 in epoch 7, gen_loss = 2.3751948136035526, disc_loss = 0.007715009245368713
Trained batch 107 in epoch 7, gen_loss = 2.3745090751736253, disc_loss = 0.007663972610047225
Trained batch 108 in epoch 7, gen_loss = 2.374505258481437, disc_loss = 0.007609246671413405
Trained batch 109 in epoch 7, gen_loss = 2.3719347661191765, disc_loss = 0.007565720490476286
Trained batch 110 in epoch 7, gen_loss = 2.3724323833310925, disc_loss = 0.007514207536849688
Trained batch 111 in epoch 7, gen_loss = 2.3754324774656976, disc_loss = 0.007461624792735425
Trained batch 112 in epoch 7, gen_loss = 2.372346613259442, disc_loss = 0.007415552490671058
Trained batch 113 in epoch 7, gen_loss = 2.372123426512668, disc_loss = 0.007369614552436887
Trained batch 114 in epoch 7, gen_loss = 2.3755174709402995, disc_loss = 0.007321563550352079
Trained batch 115 in epoch 7, gen_loss = 2.379236392933747, disc_loss = 0.007278183540369481
Trained batch 116 in epoch 7, gen_loss = 2.3804623051586313, disc_loss = 0.00723106662531853
Trained batch 117 in epoch 7, gen_loss = 2.3800788865251055, disc_loss = 0.007186021439739013
Trained batch 118 in epoch 7, gen_loss = 2.3817061406223714, disc_loss = 0.007137177092367548
Trained batch 119 in epoch 7, gen_loss = 2.38133684694767, disc_loss = 0.007089244881838871
Trained batch 120 in epoch 7, gen_loss = 2.3840579227967695, disc_loss = 0.007042455142517843
Trained batch 121 in epoch 7, gen_loss = 2.3839512213331755, disc_loss = 0.0069988981045813106
Trained batch 122 in epoch 7, gen_loss = 2.3819778401677203, disc_loss = 0.00695484059737859
Trained batch 123 in epoch 7, gen_loss = 2.38271336305526, disc_loss = 0.006913018353741556
Trained batch 124 in epoch 7, gen_loss = 2.3826280851364134, disc_loss = 0.0068777073537930845
Trained batch 125 in epoch 7, gen_loss = 2.3840169480868747, disc_loss = 0.006837077409265533
Trained batch 126 in epoch 7, gen_loss = 2.3849360482899225, disc_loss = 0.006793658823823542
Trained batch 127 in epoch 7, gen_loss = 2.385575101710856, disc_loss = 0.006750232599188166
Trained batch 128 in epoch 7, gen_loss = 2.389956090801446, disc_loss = 0.006709768833022189
Trained batch 129 in epoch 7, gen_loss = 2.3887246031027574, disc_loss = 0.00668009377639884
Trained batch 130 in epoch 7, gen_loss = 2.3896747827529907, disc_loss = 0.006646857702685164
Trained batch 131 in epoch 7, gen_loss = 2.3890392084916434, disc_loss = 0.006607969362062939
Trained batch 132 in epoch 7, gen_loss = 2.3859052057553054, disc_loss = 0.006570348642150262
Trained batch 133 in epoch 7, gen_loss = 2.385750726977391, disc_loss = 0.006532613505129772
Trained batch 134 in epoch 7, gen_loss = 2.3852343497452915, disc_loss = 0.006494071603649192
Trained batch 135 in epoch 7, gen_loss = 2.3874364153427234, disc_loss = 0.006456136893522104
Trained batch 136 in epoch 7, gen_loss = 2.3891664551992484, disc_loss = 0.006416605973283141
Trained batch 137 in epoch 7, gen_loss = 2.3889313081036443, disc_loss = 0.0063775274396428595
Trained batch 138 in epoch 7, gen_loss = 2.38745969233753, disc_loss = 0.00634049230067582
Trained batch 139 in epoch 7, gen_loss = 2.3881159722805023, disc_loss = 0.006307851676995467
Trained batch 140 in epoch 7, gen_loss = 2.387345517780764, disc_loss = 0.006274407777393646
Trained batch 141 in epoch 7, gen_loss = 2.384520477812055, disc_loss = 0.006241249363266037
Trained batch 142 in epoch 7, gen_loss = 2.3825693322228383, disc_loss = 0.006207921896357793
Trained batch 143 in epoch 7, gen_loss = 2.3830461642808385, disc_loss = 0.006173807678957625
Trained batch 144 in epoch 7, gen_loss = 2.382849694120473, disc_loss = 0.006137284007051895
Trained batch 145 in epoch 7, gen_loss = 2.380486930069858, disc_loss = 0.0061083525030121
Trained batch 146 in epoch 7, gen_loss = 2.3834736371526914, disc_loss = 0.006078170490495506
Trained batch 147 in epoch 7, gen_loss = 2.381986435200717, disc_loss = 0.00604438191323818
Trained batch 148 in epoch 7, gen_loss = 2.382944858314207, disc_loss = 0.0060143917556789595
Trained batch 149 in epoch 7, gen_loss = 2.383934627374013, disc_loss = 0.005980860621202737
Trained batch 150 in epoch 7, gen_loss = 2.383320275521436, disc_loss = 0.0059530771497809725
Trained batch 151 in epoch 7, gen_loss = 2.3846216789985957, disc_loss = 0.005919773352185362
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 2.454141855239868, disc_loss = 0.0011585965985432267
Trained batch 1 in epoch 8, gen_loss = 2.556715726852417, disc_loss = 0.0009430174250155687
Trained batch 2 in epoch 8, gen_loss = 2.3429352045059204, disc_loss = 0.0011350697216888268
Trained batch 3 in epoch 8, gen_loss = 2.3825510442256927, disc_loss = 0.0012266304111108184
Trained batch 4 in epoch 8, gen_loss = 2.358588767051697, disc_loss = 0.0012179226614534855
Trained batch 5 in epoch 8, gen_loss = 2.373875598112742, disc_loss = 0.0012001799962793787
Trained batch 6 in epoch 8, gen_loss = 2.3905872447150096, disc_loss = 0.001142543466163001
Trained batch 7 in epoch 8, gen_loss = 2.380593165755272, disc_loss = 0.0011283850399195217
Trained batch 8 in epoch 8, gen_loss = 2.392532335387336, disc_loss = 0.0010921189677901566
Trained batch 9 in epoch 8, gen_loss = 2.3954806685447694, disc_loss = 0.0010894703504163773
Trained batch 10 in epoch 8, gen_loss = 2.4249624880877407, disc_loss = 0.0010492647098462012
Trained batch 11 in epoch 8, gen_loss = 2.414321114619573, disc_loss = 0.0010648470148832228
Trained batch 12 in epoch 8, gen_loss = 2.402577409377465, disc_loss = 0.0010608007746318786
Trained batch 13 in epoch 8, gen_loss = 2.401855136666979, disc_loss = 0.001082114047936297
Trained batch 14 in epoch 8, gen_loss = 2.382948883374532, disc_loss = 0.0011324046761728823
Trained batch 15 in epoch 8, gen_loss = 2.3801048323512077, disc_loss = 0.0011597816446737852
Trained batch 16 in epoch 8, gen_loss = 2.358994757427889, disc_loss = 0.0011621941093300633
Trained batch 17 in epoch 8, gen_loss = 2.3674594230122037, disc_loss = 0.00113359830639739
Trained batch 18 in epoch 8, gen_loss = 2.37595145953329, disc_loss = 0.0011124010350996333
Trained batch 19 in epoch 8, gen_loss = 2.379528373479843, disc_loss = 0.001097088269307278
Trained batch 20 in epoch 8, gen_loss = 2.386268076442537, disc_loss = 0.0010884203033388726
Trained batch 21 in epoch 8, gen_loss = 2.371419847011566, disc_loss = 0.001083681579488753
Trained batch 22 in epoch 8, gen_loss = 2.3685221309247226, disc_loss = 0.0010782214559857612
Trained batch 23 in epoch 8, gen_loss = 2.368135377764702, disc_loss = 0.001066052713819469
Trained batch 24 in epoch 8, gen_loss = 2.369633593559265, disc_loss = 0.001052937009371817
Trained batch 25 in epoch 8, gen_loss = 2.3704811930656433, disc_loss = 0.0010485719540156424
Trained batch 26 in epoch 8, gen_loss = 2.3810382463313915, disc_loss = 0.001037235815871369
Trained batch 27 in epoch 8, gen_loss = 2.3763869532517026, disc_loss = 0.0010282150074739807
Trained batch 28 in epoch 8, gen_loss = 2.374454346196405, disc_loss = 0.0010113265056259416
Trained batch 29 in epoch 8, gen_loss = 2.365298251310984, disc_loss = 0.001013246331907188
Trained batch 30 in epoch 8, gen_loss = 2.3638940280483616, disc_loss = 0.001003878121639812
Trained batch 31 in epoch 8, gen_loss = 2.3670804761350155, disc_loss = 0.0010011114263761556
Trained batch 32 in epoch 8, gen_loss = 2.3647161794431284, disc_loss = 0.0009872192326425152
Trained batch 33 in epoch 8, gen_loss = 2.3600004806238064, disc_loss = 0.000981363413088462
Trained batch 34 in epoch 8, gen_loss = 2.3555580241339547, disc_loss = 0.0009746045107021928
Trained batch 35 in epoch 8, gen_loss = 2.351820452345742, disc_loss = 0.0009674432092449731
Trained batch 36 in epoch 8, gen_loss = 2.3565271255132316, disc_loss = 0.0009613863374987566
Trained batch 37 in epoch 8, gen_loss = 2.355567991733551, disc_loss = 0.0009599107587219853
Trained batch 38 in epoch 8, gen_loss = 2.362794047746903, disc_loss = 0.0009599544185524186
Trained batch 39 in epoch 8, gen_loss = 2.3665542989969253, disc_loss = 0.0009547725450829603
Trained batch 40 in epoch 8, gen_loss = 2.3647704037224373, disc_loss = 0.000947897562405049
Trained batch 41 in epoch 8, gen_loss = 2.365015821797507, disc_loss = 0.0009437555106290217
Trained batch 42 in epoch 8, gen_loss = 2.3605553078096966, disc_loss = 0.0009382519678775827
Trained batch 43 in epoch 8, gen_loss = 2.3731012750755656, disc_loss = 0.0009360208443302491
Trained batch 44 in epoch 8, gen_loss = 2.3732503281699286, disc_loss = 0.000934238126501441
Trained batch 45 in epoch 8, gen_loss = 2.373470531857532, disc_loss = 0.0009302786708323528
Trained batch 46 in epoch 8, gen_loss = 2.3699684168430086, disc_loss = 0.0009261400753414219
Trained batch 47 in epoch 8, gen_loss = 2.3646678750713668, disc_loss = 0.0009209942909365054
Trained batch 48 in epoch 8, gen_loss = 2.3616907669573415, disc_loss = 0.0009120189446993933
Trained batch 49 in epoch 8, gen_loss = 2.35786333322525, disc_loss = 0.0009051297535188496
Trained batch 50 in epoch 8, gen_loss = 2.3528182623433134, disc_loss = 0.0008967399189714342
Trained batch 51 in epoch 8, gen_loss = 2.3552804428797502, disc_loss = 0.0008894575154184937
Trained batch 52 in epoch 8, gen_loss = 2.358597753182897, disc_loss = 0.0008818206046751859
Trained batch 53 in epoch 8, gen_loss = 2.3614479060526246, disc_loss = 0.0008749442074784181
Trained batch 54 in epoch 8, gen_loss = 2.3625054771249943, disc_loss = 0.0008685144548177381
Trained batch 55 in epoch 8, gen_loss = 2.360925642507417, disc_loss = 0.0008669965126110972
Trained batch 56 in epoch 8, gen_loss = 2.3563253189388074, disc_loss = 0.0008699680232287695
Trained batch 57 in epoch 8, gen_loss = 2.3533612345827035, disc_loss = 0.0008724231432505144
Trained batch 58 in epoch 8, gen_loss = 2.3512733406939748, disc_loss = 0.0008695291792303008
Trained batch 59 in epoch 8, gen_loss = 2.3555480738480887, disc_loss = 0.0008684995094275413
Trained batch 60 in epoch 8, gen_loss = 2.351510511070001, disc_loss = 0.0008667008202240542
Trained batch 61 in epoch 8, gen_loss = 2.3530119138379253, disc_loss = 0.0008630283160938791
Trained batch 62 in epoch 8, gen_loss = 2.3561050380979265, disc_loss = 0.0008600071688840491
Trained batch 63 in epoch 8, gen_loss = 2.354668466374278, disc_loss = 0.0008534518592568929
Trained batch 64 in epoch 8, gen_loss = 2.3580196105516875, disc_loss = 0.0008484485908411444
Trained batch 65 in epoch 8, gen_loss = 2.3519220334110837, disc_loss = 0.000850334864949356
Trained batch 66 in epoch 8, gen_loss = 2.3517160077593218, disc_loss = 0.0008518961840309203
Trained batch 67 in epoch 8, gen_loss = 2.3497724620734943, disc_loss = 0.0008513566871817388
Trained batch 68 in epoch 8, gen_loss = 2.3508714541144995, disc_loss = 0.0008486143196932971
Trained batch 69 in epoch 8, gen_loss = 2.3530210852622986, disc_loss = 0.0008452736315250929
Trained batch 70 in epoch 8, gen_loss = 2.3488287841770012, disc_loss = 0.000845426077049383
Trained batch 71 in epoch 8, gen_loss = 2.34762937327226, disc_loss = 0.0008437118740403093
Trained batch 72 in epoch 8, gen_loss = 2.347893393203004, disc_loss = 0.0008411297458223999
Trained batch 73 in epoch 8, gen_loss = 2.35092427762779, disc_loss = 0.0008391116681269597
Trained batch 74 in epoch 8, gen_loss = 2.353047162691752, disc_loss = 0.0008364287833683193
Trained batch 75 in epoch 8, gen_loss = 2.356597180429258, disc_loss = 0.0008329984917317665
Trained batch 76 in epoch 8, gen_loss = 2.35947691465353, disc_loss = 0.0008323972511056859
Trained batch 77 in epoch 8, gen_loss = 2.359186354355934, disc_loss = 0.0008346165406505745
Trained batch 78 in epoch 8, gen_loss = 2.357642637023443, disc_loss = 0.0008362012854895165
Trained batch 79 in epoch 8, gen_loss = 2.357165388762951, disc_loss = 0.000835703805933008
Trained batch 80 in epoch 8, gen_loss = 2.3606000756040033, disc_loss = 0.000832761240473454
Trained batch 81 in epoch 8, gen_loss = 2.3580776176801543, disc_loss = 0.0008312110887079431
Trained batch 82 in epoch 8, gen_loss = 2.3571539427860673, disc_loss = 0.0008332658515603518
Trained batch 83 in epoch 8, gen_loss = 2.3576807337147847, disc_loss = 0.0008332790041874562
Trained batch 84 in epoch 8, gen_loss = 2.356269498432384, disc_loss = 0.0008302225936752032
Trained batch 85 in epoch 8, gen_loss = 2.361220341782237, disc_loss = 0.0008268743025160633
Trained batch 86 in epoch 8, gen_loss = 2.358695823570778, disc_loss = 0.0008245159446358167
Trained batch 87 in epoch 8, gen_loss = 2.355906081470576, disc_loss = 0.0008204171175417617
Trained batch 88 in epoch 8, gen_loss = 2.354936702867572, disc_loss = 0.0008162509508069939
Trained batch 89 in epoch 8, gen_loss = 2.357448150051965, disc_loss = 0.0008131948341744849
Trained batch 90 in epoch 8, gen_loss = 2.357966523904067, disc_loss = 0.000811527542332392
Trained batch 91 in epoch 8, gen_loss = 2.3575523353141286, disc_loss = 0.0008079526758039086
Trained batch 92 in epoch 8, gen_loss = 2.359437382349404, disc_loss = 0.0008046900423529048
Trained batch 93 in epoch 8, gen_loss = 2.3600313168890934, disc_loss = 0.0008030257616910409
Trained batch 94 in epoch 8, gen_loss = 2.3629810170123453, disc_loss = 0.0008015679725519333
Trained batch 95 in epoch 8, gen_loss = 2.3606543553372226, disc_loss = 0.0007992875631922894
Trained batch 96 in epoch 8, gen_loss = 2.362088116173892, disc_loss = 0.0007960171923017341
Trained batch 97 in epoch 8, gen_loss = 2.3625118695959753, disc_loss = 0.0007927363292356877
Trained batch 98 in epoch 8, gen_loss = 2.3657925381804956, disc_loss = 0.0007898985203049813
Trained batch 99 in epoch 8, gen_loss = 2.365347627401352, disc_loss = 0.0007861291829613038
Trained batch 100 in epoch 8, gen_loss = 2.366292947589761, disc_loss = 0.0007861859040072022
Trained batch 101 in epoch 8, gen_loss = 2.367864472024581, disc_loss = 0.0007865364653601622
Trained batch 102 in epoch 8, gen_loss = 2.369448996284633, disc_loss = 0.0007874553317308101
Trained batch 103 in epoch 8, gen_loss = 2.3700334143180113, disc_loss = 0.0007873980326761599
Trained batch 104 in epoch 8, gen_loss = 2.3700625635328745, disc_loss = 0.0007846943488056283
Trained batch 105 in epoch 8, gen_loss = 2.367801494193527, disc_loss = 0.0007828715796042058
Trained batch 106 in epoch 8, gen_loss = 2.365425035218212, disc_loss = 0.0007818266871781306
Trained batch 107 in epoch 8, gen_loss = 2.363091677427292, disc_loss = 0.0007817144901815078
Trained batch 108 in epoch 8, gen_loss = 2.3622963855025967, disc_loss = 0.0007800349499496264
Trained batch 109 in epoch 8, gen_loss = 2.361940575729717, disc_loss = 0.0007775508526141163
Trained batch 110 in epoch 8, gen_loss = 2.364290790514903, disc_loss = 0.0007753249922209327
Trained batch 111 in epoch 8, gen_loss = 2.3639376493436948, disc_loss = 0.0007734879953724365
Trained batch 112 in epoch 8, gen_loss = 2.36230312933964, disc_loss = 0.0007744743656140415
Trained batch 113 in epoch 8, gen_loss = 2.3629194529433, disc_loss = 0.0007719065819911888
Trained batch 114 in epoch 8, gen_loss = 2.361734758252683, disc_loss = 0.0007694824920137129
Trained batch 115 in epoch 8, gen_loss = 2.3614284159808325, disc_loss = 0.0007668218717424616
Trained batch 116 in epoch 8, gen_loss = 2.3618934674140735, disc_loss = 0.0007638835557636956
Trained batch 117 in epoch 8, gen_loss = 2.3627877366744867, disc_loss = 0.0007606251981657914
Trained batch 118 in epoch 8, gen_loss = 2.3609309727404297, disc_loss = 0.0007574981415522981
Trained batch 119 in epoch 8, gen_loss = 2.358026310801506, disc_loss = 0.0007558897702741282
Trained batch 120 in epoch 8, gen_loss = 2.35633592861743, disc_loss = 0.0007540126581780212
Trained batch 121 in epoch 8, gen_loss = 2.354739330831121, disc_loss = 0.0007523314654731695
Trained batch 122 in epoch 8, gen_loss = 2.3536955583386305, disc_loss = 0.0007504347252292271
Trained batch 123 in epoch 8, gen_loss = 2.3534492667644256, disc_loss = 0.0007487912678756871
Trained batch 124 in epoch 8, gen_loss = 2.351087321281433, disc_loss = 0.000746267561102286
Trained batch 125 in epoch 8, gen_loss = 2.3503400134661843, disc_loss = 0.0007441657882217052
Trained batch 126 in epoch 8, gen_loss = 2.350322397675101, disc_loss = 0.0007421712523535275
Trained batch 127 in epoch 8, gen_loss = 2.3485575625672936, disc_loss = 0.0007427826487855782
Trained batch 128 in epoch 8, gen_loss = 2.348870884540469, disc_loss = 0.0007451874027552097
Trained batch 129 in epoch 8, gen_loss = 2.3474318861961363, disc_loss = 0.0007454770135854442
Trained batch 130 in epoch 8, gen_loss = 2.349827345090968, disc_loss = 0.0007439509853063051
Trained batch 131 in epoch 8, gen_loss = 2.3501857925545084, disc_loss = 0.0007414063246952454
Trained batch 132 in epoch 8, gen_loss = 2.350365150243716, disc_loss = 0.000740127735797498
Trained batch 133 in epoch 8, gen_loss = 2.3495862848723115, disc_loss = 0.0007390246334322381
Trained batch 134 in epoch 8, gen_loss = 2.351780014567905, disc_loss = 0.0007383760575774229
Trained batch 135 in epoch 8, gen_loss = 2.3515373319387436, disc_loss = 0.0007363921354493976
Trained batch 136 in epoch 8, gen_loss = 2.3500369961244347, disc_loss = 0.0007352747376175448
Trained batch 137 in epoch 8, gen_loss = 2.3507126129191853, disc_loss = 0.0007337093556998298
Trained batch 138 in epoch 8, gen_loss = 2.3518266789347146, disc_loss = 0.0007322516567459022
Trained batch 139 in epoch 8, gen_loss = 2.3516040538038525, disc_loss = 0.0007301057873909095
Trained batch 140 in epoch 8, gen_loss = 2.3522700105153076, disc_loss = 0.0007273360159238206
Trained batch 141 in epoch 8, gen_loss = 2.3529667946654307, disc_loss = 0.0007250728761993716
Trained batch 142 in epoch 8, gen_loss = 2.3531116630647566, disc_loss = 0.0007230112075942432
Trained batch 143 in epoch 8, gen_loss = 2.3544576176338725, disc_loss = 0.0007208644795658378
Trained batch 144 in epoch 8, gen_loss = 2.356780401591597, disc_loss = 0.0007186275541557577
Trained batch 145 in epoch 8, gen_loss = 2.356474178294613, disc_loss = 0.0007166417757342633
Trained batch 146 in epoch 8, gen_loss = 2.3596054996762956, disc_loss = 0.0007140603784446408
Trained batch 147 in epoch 8, gen_loss = 2.359731641170141, disc_loss = 0.0007115810538478498
Trained batch 148 in epoch 8, gen_loss = 2.360394345833951, disc_loss = 0.000709140457637958
Trained batch 149 in epoch 8, gen_loss = 2.3611255876223245, disc_loss = 0.0007071533985435963
Trained batch 150 in epoch 8, gen_loss = 2.3626570093710693, disc_loss = 0.0007055050027340848
Trained batch 151 in epoch 8, gen_loss = 2.3639710474955407, disc_loss = 0.0007039387155122025
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 2.329314708709717, disc_loss = 0.00048809562576934695
Trained batch 1 in epoch 9, gen_loss = 2.5514190196990967, disc_loss = 0.00045822102401871234
Trained batch 2 in epoch 9, gen_loss = 2.627856651941935, disc_loss = 0.0004703169009493043
Trained batch 3 in epoch 9, gen_loss = 2.482852876186371, disc_loss = 0.0004874831429333426
Trained batch 4 in epoch 9, gen_loss = 2.4849791526794434, disc_loss = 0.000476981233805418
Trained batch 5 in epoch 9, gen_loss = 2.4848903020222983, disc_loss = 0.0004884654190391302
Trained batch 6 in epoch 9, gen_loss = 2.519045386995588, disc_loss = 0.0004898299063955035
Trained batch 7 in epoch 9, gen_loss = 2.4917363822460175, disc_loss = 0.0004860611188632902
Trained batch 8 in epoch 9, gen_loss = 2.4769061141543918, disc_loss = 0.0004805572259808994
Trained batch 9 in epoch 9, gen_loss = 2.4517817974090574, disc_loss = 0.00047671712236478924
Trained batch 10 in epoch 9, gen_loss = 2.4659385681152344, disc_loss = 0.0004675028507005085
Trained batch 11 in epoch 9, gen_loss = 2.4500329891840615, disc_loss = 0.0004646725647035055
Trained batch 12 in epoch 9, gen_loss = 2.450882544884315, disc_loss = 0.0004559324611014185
Trained batch 13 in epoch 9, gen_loss = 2.4272357395717075, disc_loss = 0.0004537514323601499
Trained batch 14 in epoch 9, gen_loss = 2.420577557881673, disc_loss = 0.00045347033883444963
Trained batch 15 in epoch 9, gen_loss = 2.432492643594742, disc_loss = 0.0004502874671743484
Trained batch 16 in epoch 9, gen_loss = 2.432153252994313, disc_loss = 0.00046353105982929906
Trained batch 17 in epoch 9, gen_loss = 2.4236040247811212, disc_loss = 0.0004750972584588453
Trained batch 18 in epoch 9, gen_loss = 2.4445029434404875, disc_loss = 0.0004802352862163006
Trained batch 19 in epoch 9, gen_loss = 2.4519828081130983, disc_loss = 0.0004774000393808819
Trained batch 20 in epoch 9, gen_loss = 2.430030941963196, disc_loss = 0.0004778964336894985
Trained batch 21 in epoch 9, gen_loss = 2.4319904771718113, disc_loss = 0.000476032515342178
Trained batch 22 in epoch 9, gen_loss = 2.42200071397035, disc_loss = 0.0004801178394067709
Trained batch 23 in epoch 9, gen_loss = 2.410718167821566, disc_loss = 0.00048176111037416075
Trained batch 24 in epoch 9, gen_loss = 2.419940676689148, disc_loss = 0.00047846046509221197
Trained batch 25 in epoch 9, gen_loss = 2.403093470976903, disc_loss = 0.00048431184348793555
Trained batch 26 in epoch 9, gen_loss = 2.3912812736299305, disc_loss = 0.00048660503105363913
Trained batch 27 in epoch 9, gen_loss = 2.388623386621475, disc_loss = 0.0004935226606903598
Trained batch 28 in epoch 9, gen_loss = 2.389067086680182, disc_loss = 0.0004925289600766424
Trained batch 29 in epoch 9, gen_loss = 2.3936055461565653, disc_loss = 0.0004948027102121463
Trained batch 30 in epoch 9, gen_loss = 2.395980208150802, disc_loss = 0.0004909218574363378
Trained batch 31 in epoch 9, gen_loss = 2.3784033246338367, disc_loss = 0.0005171325938135851
Trained batch 32 in epoch 9, gen_loss = 2.3732917922915835, disc_loss = 0.0005221487601485217
Trained batch 33 in epoch 9, gen_loss = 2.3633886891252853, disc_loss = 0.0005241738673409118
Trained batch 34 in epoch 9, gen_loss = 2.374956686156137, disc_loss = 0.0005243534721168024
Trained batch 35 in epoch 9, gen_loss = 2.388162331448661, disc_loss = 0.0005229655669407091
Trained batch 36 in epoch 9, gen_loss = 2.38244996521924, disc_loss = 0.0005217346479184926
Trained batch 37 in epoch 9, gen_loss = 2.3801978418701575, disc_loss = 0.0005202184386833228
Trained batch 38 in epoch 9, gen_loss = 2.386077786103273, disc_loss = 0.0005178675227141819
Trained batch 39 in epoch 9, gen_loss = 2.39182263314724, disc_loss = 0.0005130996854859404
Trained batch 40 in epoch 9, gen_loss = 2.388104738258734, disc_loss = 0.0005089523101782017
Trained batch 41 in epoch 9, gen_loss = 2.3832998474438987, disc_loss = 0.0005055100288397322
Trained batch 42 in epoch 9, gen_loss = 2.379833739857341, disc_loss = 0.0005010350155210945
Trained batch 43 in epoch 9, gen_loss = 2.385411888360977, disc_loss = 0.0004974020802447657
Trained batch 44 in epoch 9, gen_loss = 2.3817341513103907, disc_loss = 0.0004944903653166774
Trained batch 45 in epoch 9, gen_loss = 2.385113661703856, disc_loss = 0.0004928952188018467
Trained batch 46 in epoch 9, gen_loss = 2.383907269924245, disc_loss = 0.0004898780106041739
Trained batch 47 in epoch 9, gen_loss = 2.382404111325741, disc_loss = 0.00048744516546624556
Trained batch 48 in epoch 9, gen_loss = 2.3824332903842538, disc_loss = 0.00048511566140460875
Trained batch 49 in epoch 9, gen_loss = 2.3822344756126403, disc_loss = 0.00048380864318460227
Trained batch 50 in epoch 9, gen_loss = 2.383241739927554, disc_loss = 0.0004826612900668646
Trained batch 51 in epoch 9, gen_loss = 2.3846085919783664, disc_loss = 0.00047928207921079145
Trained batch 52 in epoch 9, gen_loss = 2.3785994390271745, disc_loss = 0.0004777748495744506
Trained batch 53 in epoch 9, gen_loss = 2.3794186887917697, disc_loss = 0.0004768990976218548
Trained batch 54 in epoch 9, gen_loss = 2.3778353149240665, disc_loss = 0.00047511149261316116
Trained batch 55 in epoch 9, gen_loss = 2.3757205115897313, disc_loss = 0.00047419955704494247
Trained batch 56 in epoch 9, gen_loss = 2.372723476928577, disc_loss = 0.0004737769190238364
Trained batch 57 in epoch 9, gen_loss = 2.373494664142872, disc_loss = 0.00047463620611434354
Trained batch 58 in epoch 9, gen_loss = 2.373173634884721, disc_loss = 0.0004734237642832479
Trained batch 59 in epoch 9, gen_loss = 2.3718752960364022, disc_loss = 0.00047475632842785366
Trained batch 60 in epoch 9, gen_loss = 2.3736832669523897, disc_loss = 0.0004733209956254138
Trained batch 61 in epoch 9, gen_loss = 2.3749125599861145, disc_loss = 0.00047203836372993407
Trained batch 62 in epoch 9, gen_loss = 2.37304987793877, disc_loss = 0.00047267312442676886
Trained batch 63 in epoch 9, gen_loss = 2.3700928818434477, disc_loss = 0.0004751528485940071
Trained batch 64 in epoch 9, gen_loss = 2.3722153241817767, disc_loss = 0.0004758093667288239
Trained batch 65 in epoch 9, gen_loss = 2.3683901501424387, disc_loss = 0.0004749214020910475
Trained batch 66 in epoch 9, gen_loss = 2.3696986472428736, disc_loss = 0.00047368555566045775
Trained batch 67 in epoch 9, gen_loss = 2.3726548464859234, disc_loss = 0.00047240089856238817
Trained batch 68 in epoch 9, gen_loss = 2.371127990708835, disc_loss = 0.0004712027818997107
Trained batch 69 in epoch 9, gen_loss = 2.3673211319105967, disc_loss = 0.00047131901207779134
Trained batch 70 in epoch 9, gen_loss = 2.368162754555823, disc_loss = 0.00046995034011762955
Trained batch 71 in epoch 9, gen_loss = 2.3683432423406177, disc_loss = 0.0004677972392528318
Trained batch 72 in epoch 9, gen_loss = 2.36114220749842, disc_loss = 0.0004703357619590649
Trained batch 73 in epoch 9, gen_loss = 2.3635009462768966, disc_loss = 0.00047025911830919415
Trained batch 74 in epoch 9, gen_loss = 2.3682379881540934, disc_loss = 0.0004708174786840876
Trained batch 75 in epoch 9, gen_loss = 2.3662267829242505, disc_loss = 0.0004725548803291627
Trained batch 76 in epoch 9, gen_loss = 2.366657696761094, disc_loss = 0.00047261278899447
Trained batch 77 in epoch 9, gen_loss = 2.363428158637805, disc_loss = 0.0004724627017425612
Trained batch 78 in epoch 9, gen_loss = 2.3619739858410025, disc_loss = 0.0004729484104775364
Trained batch 79 in epoch 9, gen_loss = 2.364226135611534, disc_loss = 0.0004714057857199805
Trained batch 80 in epoch 9, gen_loss = 2.3671549279012796, disc_loss = 0.00046974868207514563
Trained batch 81 in epoch 9, gen_loss = 2.366034199551838, disc_loss = 0.0004673136917096222
Trained batch 82 in epoch 9, gen_loss = 2.3699443254126122, disc_loss = 0.0004653481465725071
Trained batch 83 in epoch 9, gen_loss = 2.3677315144311812, disc_loss = 0.00046510915611482534
Trained batch 84 in epoch 9, gen_loss = 2.3632141337675208, disc_loss = 0.0004643831480814911
Trained batch 85 in epoch 9, gen_loss = 2.3648705898329268, disc_loss = 0.0004670600536100696
Trained batch 86 in epoch 9, gen_loss = 2.366440422233494, disc_loss = 0.0004674219991342732
Trained batch 87 in epoch 9, gen_loss = 2.3628054938533087, disc_loss = 0.0004683445463756057
Trained batch 88 in epoch 9, gen_loss = 2.3614801422933516, disc_loss = 0.0004685224368095691
Trained batch 89 in epoch 9, gen_loss = 2.3628909799787734, disc_loss = 0.00046778149359549083
Trained batch 90 in epoch 9, gen_loss = 2.3605040979909373, disc_loss = 0.0004690421360115019
Trained batch 91 in epoch 9, gen_loss = 2.362154403458471, disc_loss = 0.0004678111679664732
Trained batch 92 in epoch 9, gen_loss = 2.360868856471072, disc_loss = 0.0004664234793870159
Trained batch 93 in epoch 9, gen_loss = 2.361641843268212, disc_loss = 0.00046565141460729487
Trained batch 94 in epoch 9, gen_loss = 2.3624074433979234, disc_loss = 0.0004645914605230485
Trained batch 95 in epoch 9, gen_loss = 2.364216168721517, disc_loss = 0.0004623051375650296
Trained batch 96 in epoch 9, gen_loss = 2.3665232879599345, disc_loss = 0.0004614861319009599
Trained batch 97 in epoch 9, gen_loss = 2.367076041747113, disc_loss = 0.00046019870621551363
Trained batch 98 in epoch 9, gen_loss = 2.3680125053482826, disc_loss = 0.00045852133395112677
Trained batch 99 in epoch 9, gen_loss = 2.3666774225234986, disc_loss = 0.0004572564084082842
Trained batch 100 in epoch 9, gen_loss = 2.3644228217625383, disc_loss = 0.0004571036442579462
Trained batch 101 in epoch 9, gen_loss = 2.3664894571491315, disc_loss = 0.0004565557921487911
Trained batch 102 in epoch 9, gen_loss = 2.366946042162701, disc_loss = 0.0004550446937023436
Trained batch 103 in epoch 9, gen_loss = 2.367679630334561, disc_loss = 0.00045342378087717894
Trained batch 104 in epoch 9, gen_loss = 2.367497911907378, disc_loss = 0.00045193193363957107
Trained batch 105 in epoch 9, gen_loss = 2.3661829278154194, disc_loss = 0.0004510743467176755
Trained batch 106 in epoch 9, gen_loss = 2.3639576702474434, disc_loss = 0.0004503586268048107
Trained batch 107 in epoch 9, gen_loss = 2.35956507479703, disc_loss = 0.0004509303681617085
Trained batch 108 in epoch 9, gen_loss = 2.356774039224747, disc_loss = 0.0004501252431409656
Trained batch 109 in epoch 9, gen_loss = 2.357561841878024, disc_loss = 0.00044957966496109625
Trained batch 110 in epoch 9, gen_loss = 2.3558971022700406, disc_loss = 0.0004485588133238625
Trained batch 111 in epoch 9, gen_loss = 2.354989673410143, disc_loss = 0.0004480514193606463
Trained batch 112 in epoch 9, gen_loss = 2.3533686367811355, disc_loss = 0.00044752839222278413
Trained batch 113 in epoch 9, gen_loss = 2.35597825050354, disc_loss = 0.0004476324194049659
Trained batch 114 in epoch 9, gen_loss = 2.3562231167503027, disc_loss = 0.0004476567950484383
Trained batch 115 in epoch 9, gen_loss = 2.35663680372567, disc_loss = 0.0004472936335991233
Trained batch 116 in epoch 9, gen_loss = 2.3576347461113563, disc_loss = 0.0004460122008433836
Trained batch 117 in epoch 9, gen_loss = 2.3573888843342408, disc_loss = 0.0004450017556753325
Trained batch 118 in epoch 9, gen_loss = 2.3606675692967007, disc_loss = 0.00044361179637793105
Trained batch 119 in epoch 9, gen_loss = 2.3594688137372333, disc_loss = 0.0004421719306265004
Trained batch 120 in epoch 9, gen_loss = 2.3609476109181555, disc_loss = 0.0004408779115827893
Trained batch 121 in epoch 9, gen_loss = 2.360620428304203, disc_loss = 0.0004394393715793725
Trained batch 122 in epoch 9, gen_loss = 2.3586622680105815, disc_loss = 0.0004386929998636185
Trained batch 123 in epoch 9, gen_loss = 2.3605822690071596, disc_loss = 0.00043823988497963237
Trained batch 124 in epoch 9, gen_loss = 2.358005220413208, disc_loss = 0.00043834454519674183
Trained batch 125 in epoch 9, gen_loss = 2.355843432365902, disc_loss = 0.0004410314838409365
Trained batch 126 in epoch 9, gen_loss = 2.3538726202146276, disc_loss = 0.00044097883262906196
Trained batch 127 in epoch 9, gen_loss = 2.356018101796508, disc_loss = 0.0004414267639276659
Trained batch 128 in epoch 9, gen_loss = 2.3555800803872042, disc_loss = 0.0004425212005857205
Trained batch 129 in epoch 9, gen_loss = 2.3558077537096462, disc_loss = 0.00044213671264095377
Trained batch 130 in epoch 9, gen_loss = 2.3541912231736513, disc_loss = 0.00044382074519010785
Trained batch 131 in epoch 9, gen_loss = 2.3531037641294077, disc_loss = 0.00044454313033246296
Trained batch 132 in epoch 9, gen_loss = 2.3536800047508755, disc_loss = 0.0004449287946756117
Trained batch 133 in epoch 9, gen_loss = 2.3538951695854986, disc_loss = 0.00044504199468065053
Trained batch 134 in epoch 9, gen_loss = 2.3545064714219834, disc_loss = 0.0004438888701972448
Trained batch 135 in epoch 9, gen_loss = 2.356390761978486, disc_loss = 0.00044218030758630075
Trained batch 136 in epoch 9, gen_loss = 2.3593080913933524, disc_loss = 0.0004411041865126998
Trained batch 137 in epoch 9, gen_loss = 2.3571580959403, disc_loss = 0.00043992649317142025
Trained batch 138 in epoch 9, gen_loss = 2.3545166862954336, disc_loss = 0.00043918045202903313
Trained batch 139 in epoch 9, gen_loss = 2.3526488849094935, disc_loss = 0.0004383184952270572
Trained batch 140 in epoch 9, gen_loss = 2.354402261422881, disc_loss = 0.00043698010897240766
Trained batch 141 in epoch 9, gen_loss = 2.3532056304770457, disc_loss = 0.0004366338711099135
Trained batch 142 in epoch 9, gen_loss = 2.3534805491254045, disc_loss = 0.0004356589541368356
Trained batch 143 in epoch 9, gen_loss = 2.353699470559756, disc_loss = 0.0004343527940970186
Trained batch 144 in epoch 9, gen_loss = 2.354035389012304, disc_loss = 0.0004335248586922434
Trained batch 145 in epoch 9, gen_loss = 2.3538425246330155, disc_loss = 0.00043321546290328166
Trained batch 146 in epoch 9, gen_loss = 2.351073651897664, disc_loss = 0.0004335117438644944
Trained batch 147 in epoch 9, gen_loss = 2.3543977262200535, disc_loss = 0.00043325782629639235
Trained batch 148 in epoch 9, gen_loss = 2.3567752926141625, disc_loss = 0.0004334085795367387
Trained batch 149 in epoch 9, gen_loss = 2.3569680110613507, disc_loss = 0.0004333893932440939
Trained batch 150 in epoch 9, gen_loss = 2.3550431752047003, disc_loss = 0.0004329167776517508
Trained batch 151 in epoch 9, gen_loss = 2.353321355424429, disc_loss = 0.00043239823447181963
Testing Epoch 9
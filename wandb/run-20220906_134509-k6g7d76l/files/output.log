/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 1.1249351501464844, disc_loss = 0.5841636657714844
Trained batch 1 in epoch 0, gen_loss = 1.0443131923675537, disc_loss = 0.8002660274505615
Trained batch 2 in epoch 0, gen_loss = 0.9759968717892965, disc_loss = 0.649179220199585
Trained batch 3 in epoch 0, gen_loss = 0.9468218982219696, disc_loss = 0.6217281818389893
Trained batch 4 in epoch 0, gen_loss = 0.921921181678772, disc_loss = 0.5443133324384689
Trained batch 5 in epoch 0, gen_loss = 0.9249150256315867, disc_loss = 0.49294840544462204
Trained batch 6 in epoch 0, gen_loss = 0.9274175763130188, disc_loss = 0.44893573224544525
Trained batch 7 in epoch 0, gen_loss = 0.9056724831461906, disc_loss = 0.4105274975299835
Trained batch 8 in epoch 0, gen_loss = 0.8922285636266073, disc_loss = 0.3828452510966195
Trained batch 9 in epoch 0, gen_loss = 0.8708876430988312, disc_loss = 0.36413138955831525
Trained batch 10 in epoch 0, gen_loss = 0.8684986125339161, disc_loss = 0.3473869873718782
Trained batch 11 in epoch 0, gen_loss = 0.8679757217566172, disc_loss = 0.3323737556735675
Trained batch 12 in epoch 0, gen_loss = 0.8806869433476374, disc_loss = 0.32151596133525556
Trained batch 13 in epoch 0, gen_loss = 0.8754554603781018, disc_loss = 0.3155104038970811
Trained batch 14 in epoch 0, gen_loss = 0.8809144934018452, disc_loss = 0.3096325804789861
Trained batch 15 in epoch 0, gen_loss = 0.9057442806661129, disc_loss = 0.30426616314798594
Trained batch 16 in epoch 0, gen_loss = 0.899813645026263, disc_loss = 0.2988308361347984
Trained batch 17 in epoch 0, gen_loss = 0.9031578004360199, disc_loss = 0.29055175599124694
Trained batch 18 in epoch 0, gen_loss = 0.9093495387780038, disc_loss = 0.28078838202514145
Trained batch 19 in epoch 0, gen_loss = 0.9092776596546173, disc_loss = 0.2745520453900099
Trained batch 20 in epoch 0, gen_loss = 0.9180304493222918, disc_loss = 0.2686195668010485
Trained batch 21 in epoch 0, gen_loss = 0.9227348295125094, disc_loss = 0.2624634609303691
Trained batch 22 in epoch 0, gen_loss = 0.9224964172943778, disc_loss = 0.25894159564505453
Trained batch 23 in epoch 0, gen_loss = 0.9244906554619471, disc_loss = 0.25380190058300894
Trained batch 24 in epoch 0, gen_loss = 0.9317368793487549, disc_loss = 0.2491583666205406
Trained batch 25 in epoch 0, gen_loss = 0.9321045394127185, disc_loss = 0.2423533834517002
Trained batch 26 in epoch 0, gen_loss = 0.9337959620687697, disc_loss = 0.236226634018951
Trained batch 27 in epoch 0, gen_loss = 0.9343889696257455, disc_loss = 0.23025036257292544
Trained batch 28 in epoch 0, gen_loss = 0.933616436761001, disc_loss = 0.22461849528140035
Trained batch 29 in epoch 0, gen_loss = 0.9370443065961201, disc_loss = 0.21923544779419898
Trained batch 30 in epoch 0, gen_loss = 0.9352697230154469, disc_loss = 0.21688927637953911
Trained batch 31 in epoch 0, gen_loss = 0.9344459529966116, disc_loss = 0.21615690854378045
Trained batch 32 in epoch 0, gen_loss = 0.9426348155195062, disc_loss = 0.2114833469192187
Trained batch 33 in epoch 0, gen_loss = 0.9463637804283815, disc_loss = 0.20707483173293226
Trained batch 34 in epoch 0, gen_loss = 0.9477260197911944, disc_loss = 0.20294244566134045
Trained batch 35 in epoch 0, gen_loss = 0.9500249640809165, disc_loss = 0.19933869855271447
Trained batch 36 in epoch 0, gen_loss = 0.9522660857922322, disc_loss = 0.1969976833945996
Trained batch 37 in epoch 0, gen_loss = 0.9563833459427482, disc_loss = 0.19356710601009822
Trained batch 38 in epoch 0, gen_loss = 0.9578525301737663, disc_loss = 0.19072541537193152
Trained batch 39 in epoch 0, gen_loss = 0.9628693744540214, disc_loss = 0.18740176856517793
Trained batch 40 in epoch 0, gen_loss = 0.9710985407596682, disc_loss = 0.18428576356027185
Trained batch 41 in epoch 0, gen_loss = 0.9768690736520858, disc_loss = 0.18125319347849914
Trained batch 42 in epoch 0, gen_loss = 0.9869966326757919, disc_loss = 0.17854408512628356
Trained batch 43 in epoch 0, gen_loss = 0.9925719215111299, disc_loss = 0.1755436718971892
Trained batch 44 in epoch 0, gen_loss = 0.9987485580974155, disc_loss = 0.1730554593106111
Trained batch 45 in epoch 0, gen_loss = 1.0030617597310438, disc_loss = 0.17103198081578896
Trained batch 46 in epoch 0, gen_loss = 1.007311632024481, disc_loss = 0.16846380644339196
Trained batch 47 in epoch 0, gen_loss = 1.0089839758972328, disc_loss = 0.16582608649817607
Trained batch 48 in epoch 0, gen_loss = 1.0139658755185652, disc_loss = 0.16332711910410802
Trained batch 49 in epoch 0, gen_loss = 1.020481048822403, disc_loss = 0.16087190978229046
Trained batch 50 in epoch 0, gen_loss = 1.0223523366685008, disc_loss = 0.15855862791923916
Trained batch 51 in epoch 0, gen_loss = 1.0240672586055903, disc_loss = 0.15650447278928298
Trained batch 52 in epoch 0, gen_loss = 1.027273361412984, disc_loss = 0.15420838241588394
Trained batch 53 in epoch 0, gen_loss = 1.028884498057542, disc_loss = 0.15206207610942699
Trained batch 54 in epoch 0, gen_loss = 1.0284716725349425, disc_loss = 0.15031296421181073
Trained batch 55 in epoch 0, gen_loss = 1.033563538321427, disc_loss = 0.14853894118485705
Trained batch 56 in epoch 0, gen_loss = 1.0346743213502985, disc_loss = 0.14665023139432856
Trained batch 57 in epoch 0, gen_loss = 1.034901418562593, disc_loss = 0.14466596285587754
Trained batch 58 in epoch 0, gen_loss = 1.0313336485523288, disc_loss = 0.1431271750164234
Trained batch 59 in epoch 0, gen_loss = 1.0352355062961578, disc_loss = 0.14188524441172679
Trained batch 60 in epoch 0, gen_loss = 1.034925781312536, disc_loss = 0.1403596527019485
Trained batch 61 in epoch 0, gen_loss = 1.0388156694750632, disc_loss = 0.13917719837157957
Trained batch 62 in epoch 0, gen_loss = 1.0343064183280581, disc_loss = 0.14159079771193248
Trained batch 63 in epoch 0, gen_loss = 1.0377681888639927, disc_loss = 0.14216658426448703
Trained batch 64 in epoch 0, gen_loss = 1.0358871019803562, disc_loss = 0.1418756753206253
Trained batch 65 in epoch 0, gen_loss = 1.0388913840958567, disc_loss = 0.14099829531077182
Trained batch 66 in epoch 0, gen_loss = 1.0394796364342989, disc_loss = 0.1396508542681808
Trained batch 67 in epoch 0, gen_loss = 1.0373285903650171, disc_loss = 0.13818286583923242
Trained batch 68 in epoch 0, gen_loss = 1.0338441850482554, disc_loss = 0.13705960801546124
Trained batch 69 in epoch 0, gen_loss = 1.034686804669244, disc_loss = 0.13599403096096857
Trained batch 70 in epoch 0, gen_loss = 1.035543378809808, disc_loss = 0.13487529770379336
Trained batch 71 in epoch 0, gen_loss = 1.0379998857776325, disc_loss = 0.13353183363667792
Trained batch 72 in epoch 0, gen_loss = 1.034705438842512, disc_loss = 0.1332691411347422
Trained batch 73 in epoch 0, gen_loss = 1.0401874063788235, disc_loss = 0.1343357216164067
Trained batch 74 in epoch 0, gen_loss = 1.0370642749468486, disc_loss = 0.13373115614056588
Trained batch 75 in epoch 0, gen_loss = 1.0344378171782744, disc_loss = 0.1350017201253458
Trained batch 76 in epoch 0, gen_loss = 1.0336249532637658, disc_loss = 0.1344963065892845
Trained batch 77 in epoch 0, gen_loss = 1.035188194268789, disc_loss = 0.13576454989230022
Trained batch 78 in epoch 0, gen_loss = 1.0313278640372843, disc_loss = 0.13578052304779428
Trained batch 79 in epoch 0, gen_loss = 1.030132430791855, disc_loss = 0.1347617621999234
Trained batch 80 in epoch 0, gen_loss = 1.030015527466197, disc_loss = 0.1339035923190323
Trained batch 81 in epoch 0, gen_loss = 1.0271459810617494, disc_loss = 0.13287305123195414
Trained batch 82 in epoch 0, gen_loss = 1.0271859219275326, disc_loss = 0.1316836588533528
Trained batch 83 in epoch 0, gen_loss = 1.0240327950034822, disc_loss = 0.13082727497177465
Trained batch 84 in epoch 0, gen_loss = 1.0223809473654804, disc_loss = 0.1298842447645524
Trained batch 85 in epoch 0, gen_loss = 1.021105976298798, disc_loss = 0.12888820122840794
Trained batch 86 in epoch 0, gen_loss = 1.019841261978807, disc_loss = 0.12788485769910374
Trained batch 87 in epoch 0, gen_loss = 1.017961141060699, disc_loss = 0.126897277479822
Trained batch 88 in epoch 0, gen_loss = 1.0170487091782388, disc_loss = 0.12595737842696436
Trained batch 89 in epoch 0, gen_loss = 1.0167367604043749, disc_loss = 0.12492986387676663
Trained batch 90 in epoch 0, gen_loss = 1.0183879831335048, disc_loss = 0.12422075053001498
Trained batch 91 in epoch 0, gen_loss = 1.0191893318425054, disc_loss = 0.12322453591648651
Trained batch 92 in epoch 0, gen_loss = 1.017958027060314, disc_loss = 0.12295527888401862
Trained batch 93 in epoch 0, gen_loss = 1.0220552289739568, disc_loss = 0.12283586936586714
Trained batch 94 in epoch 0, gen_loss = 1.0205649877849379, disc_loss = 0.12241675026322665
Trained batch 95 in epoch 0, gen_loss = 1.0198568627238274, disc_loss = 0.12200665827064465
Trained batch 96 in epoch 0, gen_loss = 1.0219484272691393, disc_loss = 0.12157553722409858
Trained batch 97 in epoch 0, gen_loss = 1.0207059949028248, disc_loss = 0.12096968331203169
Trained batch 98 in epoch 0, gen_loss = 1.0214367689508381, disc_loss = 0.12053205539481808
Trained batch 99 in epoch 0, gen_loss = 1.0249001342058182, disc_loss = 0.12054132267832757
Trained batch 100 in epoch 0, gen_loss = 1.0233913335469689, disc_loss = 0.12020503382871647
Trained batch 101 in epoch 0, gen_loss = 1.0227793425905938, disc_loss = 0.1197653378487802
Trained batch 102 in epoch 0, gen_loss = 1.023197095949673, disc_loss = 0.11904650611929524
Trained batch 103 in epoch 0, gen_loss = 1.0213669458260903, disc_loss = 0.11886169342324138
Trained batch 104 in epoch 0, gen_loss = 1.0230036247344243, disc_loss = 0.12199139889507067
Trained batch 105 in epoch 0, gen_loss = 1.0201675801906946, disc_loss = 0.12385867687188229
Trained batch 106 in epoch 0, gen_loss = 1.0177886408066081, disc_loss = 0.12420286206859295
Trained batch 107 in epoch 0, gen_loss = 1.016314857535892, disc_loss = 0.1245021211259343
Trained batch 108 in epoch 0, gen_loss = 1.0154077109940556, disc_loss = 0.12466293091484167
Trained batch 109 in epoch 0, gen_loss = 1.0122815186327154, disc_loss = 0.1250068237497048
Trained batch 110 in epoch 0, gen_loss = 1.010381771100534, disc_loss = 0.12530580978538539
Trained batch 111 in epoch 0, gen_loss = 1.0096209171627248, disc_loss = 0.1251773321003254
Trained batch 112 in epoch 0, gen_loss = 1.008077666822788, disc_loss = 0.12562146443313202
Trained batch 113 in epoch 0, gen_loss = 1.0100590869000083, disc_loss = 0.126894660196022
Trained batch 114 in epoch 0, gen_loss = 1.0080726307371388, disc_loss = 0.126825360921414
Trained batch 115 in epoch 0, gen_loss = 1.00575601900446, disc_loss = 0.12685546128015066
Trained batch 116 in epoch 0, gen_loss = 1.00478386777079, disc_loss = 0.12653931411795127
Trained batch 117 in epoch 0, gen_loss = 1.0045980871733973, disc_loss = 0.1262453773327298
Trained batch 118 in epoch 0, gen_loss = 1.0033659589390795, disc_loss = 0.12657884818290463
Trained batch 119 in epoch 0, gen_loss = 1.0055124337474506, disc_loss = 0.12710738508030772
Trained batch 120 in epoch 0, gen_loss = 1.0050446824593977, disc_loss = 0.1268930226133382
Trained batch 121 in epoch 0, gen_loss = 1.0040018534074064, disc_loss = 0.12655615418782976
Trained batch 122 in epoch 0, gen_loss = 1.0054328320472221, disc_loss = 0.12644197334482418
Trained batch 123 in epoch 0, gen_loss = 1.0027664803689527, disc_loss = 0.12681672899352928
Trained batch 124 in epoch 0, gen_loss = 1.0006569709777833, disc_loss = 0.12760216256976128
Trained batch 125 in epoch 0, gen_loss = 1.002819750044081, disc_loss = 0.13218511401542596
Trained batch 126 in epoch 0, gen_loss = 1.0022192057662123, disc_loss = 0.13283126804185666
Trained batch 127 in epoch 0, gen_loss = 0.9998297430574894, disc_loss = 0.13363970196223818
Trained batch 128 in epoch 0, gen_loss = 0.9975802958473678, disc_loss = 0.13492122347387234
Trained batch 129 in epoch 0, gen_loss = 0.995555404974864, disc_loss = 0.13498497430521708
Trained batch 130 in epoch 0, gen_loss = 0.9940612347981402, disc_loss = 0.1354417863181074
Trained batch 131 in epoch 0, gen_loss = 0.9918945052407004, disc_loss = 0.13530490070468548
Trained batch 132 in epoch 0, gen_loss = 0.9912681095582202, disc_loss = 0.13551835051940797
Trained batch 133 in epoch 0, gen_loss = 0.9901201066686146, disc_loss = 0.13564064606690585
Trained batch 134 in epoch 0, gen_loss = 0.988970461598149, disc_loss = 0.13541343899236785
Trained batch 135 in epoch 0, gen_loss = 0.987633088055779, disc_loss = 0.13497677590588436
Trained batch 136 in epoch 0, gen_loss = 0.9875040837448009, disc_loss = 0.13464565566965264
Trained batch 137 in epoch 0, gen_loss = 0.9861993539160576, disc_loss = 0.13424707401165928
Trained batch 138 in epoch 0, gen_loss = 0.9861990264851412, disc_loss = 0.13444409709718588
Trained batch 139 in epoch 0, gen_loss = 0.9831284314393998, disc_loss = 0.13606104331889324
Trained batch 140 in epoch 0, gen_loss = 0.9834422672048528, disc_loss = 0.1363420456066622
Trained batch 141 in epoch 0, gen_loss = 0.9826216538187483, disc_loss = 0.13613610197855552
Trained batch 142 in epoch 0, gen_loss = 0.9818726627976744, disc_loss = 0.1361018707650108
Trained batch 143 in epoch 0, gen_loss = 0.9814236677355237, disc_loss = 0.13694364709469178
Trained batch 144 in epoch 0, gen_loss = 0.9803814254958054, disc_loss = 0.13649057178147908
Trained batch 145 in epoch 0, gen_loss = 0.9783262451217599, disc_loss = 0.13720609316576834
Trained batch 146 in epoch 0, gen_loss = 0.980029512830332, disc_loss = 0.1390494261013002
Trained batch 147 in epoch 0, gen_loss = 0.9807631409651524, disc_loss = 0.13931217233373508
Trained batch 148 in epoch 0, gen_loss = 0.9807007400781517, disc_loss = 0.13922355226522323
Trained batch 149 in epoch 0, gen_loss = 0.979064423640569, disc_loss = 0.13913438734908898
Trained batch 150 in epoch 0, gen_loss = 0.97707385140539, disc_loss = 0.13943626931467593
Trained batch 151 in epoch 0, gen_loss = 0.9764263657362837, disc_loss = 0.13963121741912082
Trained batch 152 in epoch 0, gen_loss = 0.9764175450100618, disc_loss = 0.13951481106916283
Trained batch 153 in epoch 0, gen_loss = 0.9757297364148226, disc_loss = 0.13931756038460638
Trained batch 154 in epoch 0, gen_loss = 0.9756926440423535, disc_loss = 0.13879790551239443
Trained batch 155 in epoch 0, gen_loss = 0.9752442359160154, disc_loss = 0.14020221656522688
Trained batch 156 in epoch 0, gen_loss = 0.973407261310869, disc_loss = 0.14202222204322268
Trained batch 157 in epoch 0, gen_loss = 0.9721874292892746, disc_loss = 0.14223453397803668
Trained batch 158 in epoch 0, gen_loss = 0.9721370253173061, disc_loss = 0.14258693913056417
Trained batch 159 in epoch 0, gen_loss = 0.9710420981049538, disc_loss = 0.1426858627703041
Trained batch 160 in epoch 0, gen_loss = 0.9699595389158829, disc_loss = 0.14267314216179877
Trained batch 161 in epoch 0, gen_loss = 0.9701271609023765, disc_loss = 0.14235080511849604
Trained batch 162 in epoch 0, gen_loss = 0.9712215245135722, disc_loss = 0.142360205390702
Trained batch 163 in epoch 0, gen_loss = 0.9693588788916425, disc_loss = 0.14237521189015087
Trained batch 164 in epoch 0, gen_loss = 0.9672676415154429, disc_loss = 0.14256822304292158
Trained batch 165 in epoch 0, gen_loss = 0.9653343447001583, disc_loss = 0.14345282693225217
Trained batch 166 in epoch 0, gen_loss = 0.9667059586433593, disc_loss = 0.14347399244765321
Trained batch 167 in epoch 0, gen_loss = 0.9668015631891432, disc_loss = 0.1439784775000243
Trained batch 168 in epoch 0, gen_loss = 0.9646598255845922, disc_loss = 0.14481810555302885
Trained batch 169 in epoch 0, gen_loss = 0.9633109800955828, disc_loss = 0.14490389972925186
Trained batch 170 in epoch 0, gen_loss = 0.9619206301650108, disc_loss = 0.14584469594802077
Trained batch 171 in epoch 0, gen_loss = 0.9602455527976502, disc_loss = 0.14617372538114703
Trained batch 172 in epoch 0, gen_loss = 0.958401074643769, disc_loss = 0.14636180554166695
Trained batch 173 in epoch 0, gen_loss = 0.9576282860903904, disc_loss = 0.14633136602311297
Trained batch 174 in epoch 0, gen_loss = 0.9565406182834081, disc_loss = 0.14648816577025822
Trained batch 175 in epoch 0, gen_loss = 0.9558958688920195, disc_loss = 0.14620630091733552
Trained batch 176 in epoch 0, gen_loss = 0.9559434187614312, disc_loss = 0.14616667672907566
Trained batch 177 in epoch 0, gen_loss = 0.955433259854156, disc_loss = 0.14658056806479947
Trained batch 178 in epoch 0, gen_loss = 0.9538327115874051, disc_loss = 0.14698226970500786
Trained batch 179 in epoch 0, gen_loss = 0.9540007518397438, disc_loss = 0.14675945618914232
Trained batch 180 in epoch 0, gen_loss = 0.9534357878384669, disc_loss = 0.14714410501784383
Trained batch 181 in epoch 0, gen_loss = 0.9524031969217154, disc_loss = 0.14723476395010948
Trained batch 182 in epoch 0, gen_loss = 0.951505970108053, disc_loss = 0.14707029688228024
Trained batch 183 in epoch 0, gen_loss = 0.9518287858885267, disc_loss = 0.1469678617204013
Trained batch 184 in epoch 0, gen_loss = 0.9503668759320233, disc_loss = 0.14710116096445033
Trained batch 185 in epoch 0, gen_loss = 0.9486070707921059, disc_loss = 0.14838782193199282
Trained batch 186 in epoch 0, gen_loss = 0.9486809111533956, disc_loss = 0.1481877181300505
Trained batch 187 in epoch 0, gen_loss = 0.9498507383655994, disc_loss = 0.1482862986307195
Trained batch 188 in epoch 0, gen_loss = 0.9482927376000339, disc_loss = 0.14818966475428727
Trained batch 189 in epoch 0, gen_loss = 0.9470270084707361, disc_loss = 0.14801136349376878
Trained batch 190 in epoch 0, gen_loss = 0.9463974515180937, disc_loss = 0.14799229410618386
Trained batch 191 in epoch 0, gen_loss = 0.9472465977693597, disc_loss = 0.14745719011019295
Trained batch 192 in epoch 0, gen_loss = 0.946449756313482, disc_loss = 0.14720633176247072
Trained batch 193 in epoch 0, gen_loss = 0.9469741567508462, disc_loss = 0.14710327320415334
Trained batch 194 in epoch 0, gen_loss = 0.9455822308858236, disc_loss = 0.1485460505844691
Trained batch 195 in epoch 0, gen_loss = 0.9461478834249535, disc_loss = 0.148850261233747
Trained batch 196 in epoch 0, gen_loss = 0.9449109314056823, disc_loss = 0.14885388789367554
Trained batch 197 in epoch 0, gen_loss = 0.944203313552972, disc_loss = 0.148953362076421
Trained batch 198 in epoch 0, gen_loss = 0.9439216858178527, disc_loss = 0.14887815442441696
Trained batch 199 in epoch 0, gen_loss = 0.9437375211715698, disc_loss = 0.14913018537685274
Trained batch 200 in epoch 0, gen_loss = 0.9430025830790771, disc_loss = 0.14912326743279525
Trained batch 201 in epoch 0, gen_loss = 0.9435543409078428, disc_loss = 0.14865019497009788
Trained batch 202 in epoch 0, gen_loss = 0.9432438212662495, disc_loss = 0.14866258460899878
Trained batch 203 in epoch 0, gen_loss = 0.9433967818816503, disc_loss = 0.14838488206413447
Trained batch 204 in epoch 0, gen_loss = 0.9435295942353039, disc_loss = 0.14851102076652573
Trained batch 205 in epoch 0, gen_loss = 0.9421441459540024, disc_loss = 0.14868806052989172
Trained batch 206 in epoch 0, gen_loss = 0.9417385954211875, disc_loss = 0.1484088474785648
Trained batch 207 in epoch 0, gen_loss = 0.9440986860830051, disc_loss = 0.1488843668037309
Trained batch 208 in epoch 0, gen_loss = 0.9434849477270574, disc_loss = 0.148726085762373
Trained batch 209 in epoch 0, gen_loss = 0.9419602930545807, disc_loss = 0.15067988013227782
Trained batch 210 in epoch 0, gen_loss = 0.9405348637092735, disc_loss = 0.15085614380819537
Trained batch 211 in epoch 0, gen_loss = 0.9406426889154146, disc_loss = 0.15088158575290778
Trained batch 212 in epoch 0, gen_loss = 0.9403655257583224, disc_loss = 0.1515107564453228
Trained batch 213 in epoch 0, gen_loss = 0.9397230084254363, disc_loss = 0.1518581791946264
Trained batch 214 in epoch 0, gen_loss = 0.9393266855284225, disc_loss = 0.15162796017735503
Trained batch 215 in epoch 0, gen_loss = 0.9394049048423767, disc_loss = 0.1515401276173415
Trained batch 216 in epoch 0, gen_loss = 0.9397558836343651, disc_loss = 0.15141212480134128
Trained batch 217 in epoch 0, gen_loss = 0.9384841850591362, disc_loss = 0.1517895366483872
Trained batch 218 in epoch 0, gen_loss = 0.9385463622607053, disc_loss = 0.15248807019566837
Trained batch 219 in epoch 0, gen_loss = 0.9379208361560648, disc_loss = 0.15233683724972336
Trained batch 220 in epoch 0, gen_loss = 0.9365881608622106, disc_loss = 0.15288458572388774
Trained batch 221 in epoch 0, gen_loss = 0.9367278011532517, disc_loss = 0.1531695784279355
Trained batch 222 in epoch 0, gen_loss = 0.9370662259948628, disc_loss = 0.15316364392972312
Trained batch 223 in epoch 0, gen_loss = 0.9369393044284412, disc_loss = 0.15302881442143448
Trained batch 224 in epoch 0, gen_loss = 0.9361347224977281, disc_loss = 0.15309364878469042
Trained batch 225 in epoch 0, gen_loss = 0.9355369247166456, disc_loss = 0.1530022206098105
Trained batch 226 in epoch 0, gen_loss = 0.9356160179633927, disc_loss = 0.15300348942631667
Trained batch 227 in epoch 0, gen_loss = 0.9348475797134533, disc_loss = 0.15312828649685048
Trained batch 228 in epoch 0, gen_loss = 0.9337331853058661, disc_loss = 0.153257545457917
Trained batch 229 in epoch 0, gen_loss = 0.9332812511402627, disc_loss = 0.1529269911672758
Trained batch 230 in epoch 0, gen_loss = 0.9336730468840826, disc_loss = 0.15273079169648035
Trained batch 231 in epoch 0, gen_loss = 0.9323520467712961, disc_loss = 0.15352621067572256
Trained batch 232 in epoch 0, gen_loss = 0.9329156653052236, disc_loss = 0.1531297749012325
Trained batch 233 in epoch 0, gen_loss = 0.9332311242564112, disc_loss = 0.153509810152981
Trained batch 234 in epoch 0, gen_loss = 0.9327596337237256, disc_loss = 0.15340509031047211
Trained batch 235 in epoch 0, gen_loss = 0.9327131881047104, disc_loss = 0.1532122771239887
Trained batch 236 in epoch 0, gen_loss = 0.9332803560711663, disc_loss = 0.15398390918089871
Trained batch 237 in epoch 0, gen_loss = 0.9320070377918852, disc_loss = 0.15449826125086857
Trained batch 238 in epoch 0, gen_loss = 0.9311704306422915, disc_loss = 0.15475760886609305
Trained batch 239 in epoch 0, gen_loss = 0.9299093807737032, disc_loss = 0.15504601939270893
Trained batch 240 in epoch 0, gen_loss = 0.9296828147286696, disc_loss = 0.15507410157518267
Trained batch 241 in epoch 0, gen_loss = 0.9306393645026467, disc_loss = 0.1554848776499102
Trained batch 242 in epoch 0, gen_loss = 0.930629652468756, disc_loss = 0.15535696687889688
Trained batch 243 in epoch 0, gen_loss = 0.9302201158687716, disc_loss = 0.15517595819518215
Trained batch 244 in epoch 0, gen_loss = 0.9298423112655173, disc_loss = 0.15533239263661053
Trained batch 245 in epoch 0, gen_loss = 0.9301787602707623, disc_loss = 0.15517226885247037
Trained batch 246 in epoch 0, gen_loss = 0.9304448923601313, disc_loss = 0.1552770961272089
Trained batch 247 in epoch 0, gen_loss = 0.9293962205129285, disc_loss = 0.1553431306515009
Trained batch 248 in epoch 0, gen_loss = 0.9287801643452013, disc_loss = 0.1553234207223218
Trained batch 249 in epoch 0, gen_loss = 0.9289079802036285, disc_loss = 0.15556609153747558
Trained batch 250 in epoch 0, gen_loss = 0.9279820460722266, disc_loss = 0.15557471802272646
Trained batch 251 in epoch 0, gen_loss = 0.927377365411274, disc_loss = 0.15561170361581303
Trained batch 252 in epoch 0, gen_loss = 0.9261532220915843, disc_loss = 0.15648625791072845
Trained batch 253 in epoch 0, gen_loss = 0.9252734627780013, disc_loss = 0.1571592272618624
Trained batch 254 in epoch 0, gen_loss = 0.9249505064066719, disc_loss = 0.1574108963503557
Trained batch 255 in epoch 0, gen_loss = 0.925399794941768, disc_loss = 0.15742894425056875
Trained batch 256 in epoch 0, gen_loss = 0.9235974244106604, disc_loss = 0.15771586201534196
Trained batch 257 in epoch 0, gen_loss = 0.9230569249899813, disc_loss = 0.15792275768841885
Trained batch 258 in epoch 0, gen_loss = 0.9233380611338671, disc_loss = 0.1583326277125296
Trained batch 259 in epoch 0, gen_loss = 0.9227217976863568, disc_loss = 0.1584675779709449
Trained batch 260 in epoch 0, gen_loss = 0.921781036817251, disc_loss = 0.15879780779168068
Trained batch 261 in epoch 0, gen_loss = 0.921276421719835, disc_loss = 0.1588225257760696
Trained batch 262 in epoch 0, gen_loss = 0.92089331965936, disc_loss = 0.15903501501554773
Trained batch 263 in epoch 0, gen_loss = 0.9202048455675443, disc_loss = 0.1592026509796128
Trained batch 264 in epoch 0, gen_loss = 0.9200436265963429, disc_loss = 0.15927017443584945
Trained batch 265 in epoch 0, gen_loss = 0.9196611701097703, disc_loss = 0.15931159829286703
Trained batch 266 in epoch 0, gen_loss = 0.9186296362555428, disc_loss = 0.15950049292505458
Trained batch 267 in epoch 0, gen_loss = 0.9185929856638411, disc_loss = 0.15964616523749792
Trained batch 268 in epoch 0, gen_loss = 0.9175944148829436, disc_loss = 0.15975544067120465
Trained batch 269 in epoch 0, gen_loss = 0.9165618404194161, disc_loss = 0.15986744496557448
Trained batch 270 in epoch 0, gen_loss = 0.9166278386028051, disc_loss = 0.15968005551623243
Trained batch 271 in epoch 0, gen_loss = 0.9165094865157324, disc_loss = 0.15974808593883233
Trained batch 272 in epoch 0, gen_loss = 0.9161039787334401, disc_loss = 0.15975808813458398
Trained batch 273 in epoch 0, gen_loss = 0.916216675382461, disc_loss = 0.1601758986493967
Trained batch 274 in epoch 0, gen_loss = 0.915472268407995, disc_loss = 0.1604657914421775
Trained batch 275 in epoch 0, gen_loss = 0.914832329188568, disc_loss = 0.1606033152860144
Trained batch 276 in epoch 0, gen_loss = 0.9151346644769938, disc_loss = 0.1615259517185955
Trained batch 277 in epoch 0, gen_loss = 0.9141934421851481, disc_loss = 0.16179726304982206
Trained batch 278 in epoch 0, gen_loss = 0.9130048929149532, disc_loss = 0.16238802452454856
Trained batch 279 in epoch 0, gen_loss = 0.9125347805874688, disc_loss = 0.1624579449317285
Trained batch 280 in epoch 0, gen_loss = 0.9124808082376935, disc_loss = 0.1625398279190912
Trained batch 281 in epoch 0, gen_loss = 0.9126613121083442, disc_loss = 0.1625515579226169
Trained batch 282 in epoch 0, gen_loss = 0.9113649252025483, disc_loss = 0.16268256680493642
Trained batch 283 in epoch 0, gen_loss = 0.9107249777921489, disc_loss = 0.16258763700303897
Trained batch 284 in epoch 0, gen_loss = 0.9106998698753223, disc_loss = 0.16248446451990228
Trained batch 285 in epoch 0, gen_loss = 0.9101673912751925, disc_loss = 0.16271478271150921
Trained batch 286 in epoch 0, gen_loss = 0.9095481405690157, disc_loss = 0.16362454864206213
Trained batch 287 in epoch 0, gen_loss = 0.9095258950773213, disc_loss = 0.16361281291271249
Trained batch 288 in epoch 0, gen_loss = 0.9091556818840001, disc_loss = 0.16361112387328824
Trained batch 289 in epoch 0, gen_loss = 0.9082228711966811, disc_loss = 0.16371125291133748
Trained batch 290 in epoch 0, gen_loss = 0.9072183933864344, disc_loss = 0.16391862529454773
Trained batch 291 in epoch 0, gen_loss = 0.9065949279968053, disc_loss = 0.1638942221052026
Trained batch 292 in epoch 0, gen_loss = 0.9066606764093601, disc_loss = 0.16373605258228835
Trained batch 293 in epoch 0, gen_loss = 0.9064688045962327, disc_loss = 0.16367905678189532
Trained batch 294 in epoch 0, gen_loss = 0.9055931491366888, disc_loss = 0.1636595423948967
Trained batch 295 in epoch 0, gen_loss = 0.9051318202872534, disc_loss = 0.1635251645804257
Trained batch 296 in epoch 0, gen_loss = 0.9052361918218208, disc_loss = 0.16417796588706648
Trained batch 297 in epoch 0, gen_loss = 0.904585025254512, disc_loss = 0.16409572558915056
Trained batch 298 in epoch 0, gen_loss = 0.9034507659366697, disc_loss = 0.16460372482653846
Trained batch 299 in epoch 0, gen_loss = 0.9029263865947723, disc_loss = 0.16456607063611348
Trained batch 300 in epoch 0, gen_loss = 0.9027399258360118, disc_loss = 0.16457566420897296
Trained batch 301 in epoch 0, gen_loss = 0.9017255742423582, disc_loss = 0.16502801925930755
Trained batch 302 in epoch 0, gen_loss = 0.9007208420105106, disc_loss = 0.16529200789165183
Trained batch 303 in epoch 0, gen_loss = 0.9002734377588096, disc_loss = 0.16543350388344966
Trained batch 304 in epoch 0, gen_loss = 0.899794837490457, disc_loss = 0.1654901288571905
Trained batch 305 in epoch 0, gen_loss = 0.8990145880802005, disc_loss = 0.1656406876308466
Trained batch 306 in epoch 0, gen_loss = 0.8977170899170618, disc_loss = 0.16582228418087727
Trained batch 307 in epoch 0, gen_loss = 0.8975247800737233, disc_loss = 0.16571756844203195
Trained batch 308 in epoch 0, gen_loss = 0.897428860363451, disc_loss = 0.16567123268993156
Trained batch 309 in epoch 0, gen_loss = 0.8970917542134562, disc_loss = 0.16563637251815488
Trained batch 310 in epoch 0, gen_loss = 0.8970343514654031, disc_loss = 0.1657790762051892
Trained batch 311 in epoch 0, gen_loss = 0.8960725590586662, disc_loss = 0.16600620546019995
Trained batch 312 in epoch 0, gen_loss = 0.8957127344113188, disc_loss = 0.16600964425470882
Trained batch 313 in epoch 0, gen_loss = 0.8950817622956196, disc_loss = 0.16602739136499964
Trained batch 314 in epoch 0, gen_loss = 0.894553159721314, disc_loss = 0.16620705794720422
Trained batch 315 in epoch 0, gen_loss = 0.8948875969346566, disc_loss = 0.16620725765824318
Trained batch 316 in epoch 0, gen_loss = 0.894887779037283, disc_loss = 0.1661943780134905
Trained batch 317 in epoch 0, gen_loss = 0.8945957444748789, disc_loss = 0.16615737070265058
Trained batch 318 in epoch 0, gen_loss = 0.8939893757661682, disc_loss = 0.1661949977045149
Trained batch 319 in epoch 0, gen_loss = 0.8933385081589222, disc_loss = 0.16619913540780545
Trained batch 320 in epoch 0, gen_loss = 0.8931578620571956, disc_loss = 0.16627099000590612
Trained batch 321 in epoch 0, gen_loss = 0.8925023641645539, disc_loss = 0.166281600361285
Trained batch 322 in epoch 0, gen_loss = 0.8924373779503554, disc_loss = 0.16657548699954716
Trained batch 323 in epoch 0, gen_loss = 0.8912173397379157, disc_loss = 0.16665667277059437
Trained batch 324 in epoch 0, gen_loss = 0.8905290029599117, disc_loss = 0.16658300894957323
Trained batch 325 in epoch 0, gen_loss = 0.8901903941953109, disc_loss = 0.16654838237660063
Trained batch 326 in epoch 0, gen_loss = 0.8903467646068025, disc_loss = 0.16654455301776208
Trained batch 327 in epoch 0, gen_loss = 0.8901289730537228, disc_loss = 0.16651048697531223
Trained batch 328 in epoch 0, gen_loss = 0.8900165717290165, disc_loss = 0.16645225556425772
Trained batch 329 in epoch 0, gen_loss = 0.8904879801201098, disc_loss = 0.1665063665671782
Trained batch 330 in epoch 0, gen_loss = 0.8898121716392725, disc_loss = 0.16646592062405588
Trained batch 331 in epoch 0, gen_loss = 0.8887875019067741, disc_loss = 0.1667882034397987
Trained batch 332 in epoch 0, gen_loss = 0.8887337575087676, disc_loss = 0.16726901840877245
Trained batch 333 in epoch 0, gen_loss = 0.8886396920609617, disc_loss = 0.16724207511026704
Trained batch 334 in epoch 0, gen_loss = 0.887890948110552, disc_loss = 0.1675258918929456
Trained batch 335 in epoch 0, gen_loss = 0.8877480663359165, disc_loss = 0.1674285532374467
Trained batch 336 in epoch 0, gen_loss = 0.88677674602684, disc_loss = 0.1674355087188302
Trained batch 337 in epoch 0, gen_loss = 0.8864099258149164, disc_loss = 0.16726688926036543
Trained batch 338 in epoch 0, gen_loss = 0.886150156678, disc_loss = 0.16716367538172236
Trained batch 339 in epoch 0, gen_loss = 0.885224066937671, disc_loss = 0.16715759306269534
Trained batch 340 in epoch 0, gen_loss = 0.8849109378028824, disc_loss = 0.16705414220210044
Trained batch 341 in epoch 0, gen_loss = 0.8843570395171294, disc_loss = 0.16689640183372106
Trained batch 342 in epoch 0, gen_loss = 0.8845358226806708, disc_loss = 0.16664436707169947
Trained batch 343 in epoch 0, gen_loss = 0.8843723474893459, disc_loss = 0.1664183820749438
Trained batch 344 in epoch 0, gen_loss = 0.8839935812397279, disc_loss = 0.16634268583594888
Trained batch 345 in epoch 0, gen_loss = 0.8844555766251735, disc_loss = 0.16658723108858042
Trained batch 346 in epoch 0, gen_loss = 0.8838966327373163, disc_loss = 0.16741565191951885
Trained batch 347 in epoch 0, gen_loss = 0.8836393292950487, disc_loss = 0.16739652254458132
Trained batch 348 in epoch 0, gen_loss = 0.883392965212934, disc_loss = 0.16723680748126568
Trained batch 349 in epoch 0, gen_loss = 0.8828309764180865, disc_loss = 0.16722210769142423
Trained batch 350 in epoch 0, gen_loss = 0.883646485812304, disc_loss = 0.1671776230263914
Trained batch 351 in epoch 0, gen_loss = 0.8835742065513675, disc_loss = 0.16711242374202068
Trained batch 352 in epoch 0, gen_loss = 0.8837545574893357, disc_loss = 0.16694361497001675
Trained batch 353 in epoch 0, gen_loss = 0.8835778076433193, disc_loss = 0.1669168407676247
Trained batch 354 in epoch 0, gen_loss = 0.8842976199069493, disc_loss = 0.16696377512015087
Trained batch 355 in epoch 0, gen_loss = 0.8836269546090887, disc_loss = 0.16712955806111351
Trained batch 356 in epoch 0, gen_loss = 0.8837645204127336, disc_loss = 0.16715380964743323
Trained batch 357 in epoch 0, gen_loss = 0.8833455896244369, disc_loss = 0.1671287328962174
Trained batch 358 in epoch 0, gen_loss = 0.8825554062397035, disc_loss = 0.16726212658008824
Trained batch 359 in epoch 0, gen_loss = 0.8822596823175748, disc_loss = 0.16769271155612336
Trained batch 360 in epoch 0, gen_loss = 0.8819966808250406, disc_loss = 0.16807895727517533
Trained batch 361 in epoch 0, gen_loss = 0.8820024132728577, disc_loss = 0.16861436489290296
Trained batch 362 in epoch 0, gen_loss = 0.881627362293317, disc_loss = 0.16876338703491142
Trained batch 363 in epoch 0, gen_loss = 0.8813424439548136, disc_loss = 0.1686972049934851
Trained batch 364 in epoch 0, gen_loss = 0.8810878967585629, disc_loss = 0.16871940920205966
Trained batch 365 in epoch 0, gen_loss = 0.8810756908414142, disc_loss = 0.16854255797107362
Trained batch 366 in epoch 0, gen_loss = 0.880797632870947, disc_loss = 0.16856886028269005
Trained batch 367 in epoch 0, gen_loss = 0.880252440986426, disc_loss = 0.16852374115715857
Trained batch 368 in epoch 0, gen_loss = 0.8803849170201516, disc_loss = 0.1682933514034199
Trained batch 369 in epoch 0, gen_loss = 0.8801008851141543, disc_loss = 0.16818800137655154
Trained batch 370 in epoch 0, gen_loss = 0.8803303069824157, disc_loss = 0.1682516032393088
Trained batch 371 in epoch 0, gen_loss = 0.8796105051553378, disc_loss = 0.1683946859532146
Trained batch 372 in epoch 0, gen_loss = 0.8802121008369302, disc_loss = 0.16841656281225803
Trained batch 373 in epoch 0, gen_loss = 0.8799880005140356, disc_loss = 0.16828662527595611
Trained batch 374 in epoch 0, gen_loss = 0.8793306471506754, disc_loss = 0.16826697071393332
Trained batch 375 in epoch 0, gen_loss = 0.8791970593181062, disc_loss = 0.16816326535921147
Trained batch 376 in epoch 0, gen_loss = 0.8791758558794421, disc_loss = 0.16806721687316895
Trained batch 377 in epoch 0, gen_loss = 0.8789306021241284, disc_loss = 0.16801600670688366
Trained batch 378 in epoch 0, gen_loss = 0.8797361448131954, disc_loss = 0.16813708232386446
Trained batch 379 in epoch 0, gen_loss = 0.8794127592914983, disc_loss = 0.16803223631883923
Trained batch 380 in epoch 0, gen_loss = 0.8793189312842261, disc_loss = 0.16801711658793173
Trained batch 381 in epoch 0, gen_loss = 0.8785696808268263, disc_loss = 0.16813770389057578
Trained batch 382 in epoch 0, gen_loss = 0.8791969894740351, disc_loss = 0.1682430764480297
Trained batch 383 in epoch 0, gen_loss = 0.8791304978852471, disc_loss = 0.16808481716240445
Trained batch 384 in epoch 0, gen_loss = 0.8788988571662407, disc_loss = 0.16796704964204268
Trained batch 385 in epoch 0, gen_loss = 0.8791405041291924, disc_loss = 0.16819141581268507
Trained batch 386 in epoch 0, gen_loss = 0.8787118558427777, disc_loss = 0.16814911184538858
Trained batch 387 in epoch 0, gen_loss = 0.8781841939564833, disc_loss = 0.168171188304412
Trained batch 388 in epoch 0, gen_loss = 0.8781750390646084, disc_loss = 0.168091772531176
Trained batch 389 in epoch 0, gen_loss = 0.877901232853914, disc_loss = 0.16813301543394724
Trained batch 390 in epoch 0, gen_loss = 0.8774477850140818, disc_loss = 0.16831954852546877
Trained batch 391 in epoch 0, gen_loss = 0.8778268597563919, disc_loss = 0.16831057286840312
Trained batch 392 in epoch 0, gen_loss = 0.8778011754875571, disc_loss = 0.168149257396317
Trained batch 393 in epoch 0, gen_loss = 0.8772483675310454, disc_loss = 0.16811799783694562
Trained batch 394 in epoch 0, gen_loss = 0.8774056526679027, disc_loss = 0.16801043299934532
Trained batch 395 in epoch 0, gen_loss = 0.8779578860660996, disc_loss = 0.16841513449043938
Trained batch 396 in epoch 0, gen_loss = 0.8773581043298659, disc_loss = 0.16843285597391633
Trained batch 397 in epoch 0, gen_loss = 0.8765227448700661, disc_loss = 0.16850461294153826
Trained batch 398 in epoch 0, gen_loss = 0.8763155690709451, disc_loss = 0.168532535956617
Trained batch 399 in epoch 0, gen_loss = 0.8758978807926178, disc_loss = 0.16852700751274824
Trained batch 400 in epoch 0, gen_loss = 0.87544497082061, disc_loss = 0.16850995285403997
Trained batch 401 in epoch 0, gen_loss = 0.874688725269849, disc_loss = 0.16844753516995492
Trained batch 402 in epoch 0, gen_loss = 0.8746720629353677, disc_loss = 0.1682784916745226
Trained batch 403 in epoch 0, gen_loss = 0.8746360854642226, disc_loss = 0.16855439049477625
Trained batch 404 in epoch 0, gen_loss = 0.8736273581599012, disc_loss = 0.16849902559209753
Trained batch 405 in epoch 0, gen_loss = 0.8730673516912414, disc_loss = 0.1689287935718527
Trained batch 406 in epoch 0, gen_loss = 0.8736569354223678, disc_loss = 0.16980109028792792
Trained batch 407 in epoch 0, gen_loss = 0.8735559521352544, disc_loss = 0.17008348327933573
Trained batch 408 in epoch 0, gen_loss = 0.8732442406978467, disc_loss = 0.17024048729310118
Trained batch 409 in epoch 0, gen_loss = 0.8723873097722123, disc_loss = 0.1703226907587633
Trained batch 410 in epoch 0, gen_loss = 0.8722231769503758, disc_loss = 0.1702623618562726
Trained batch 411 in epoch 0, gen_loss = 0.8716973821515018, disc_loss = 0.17028824749936178
Trained batch 412 in epoch 0, gen_loss = 0.8713083164743881, disc_loss = 0.17019307093816577
Trained batch 413 in epoch 0, gen_loss = 0.8708976212043117, disc_loss = 0.17011091372241144
Trained batch 414 in epoch 0, gen_loss = 0.8705231283084456, disc_loss = 0.17004240844623153
Trained batch 415 in epoch 0, gen_loss = 0.8701776455228145, disc_loss = 0.16993111780343148
Trained batch 416 in epoch 0, gen_loss = 0.8696027130817624, disc_loss = 0.16989470074931495
Trained batch 417 in epoch 0, gen_loss = 0.8691365861436396, disc_loss = 0.16975774284470024
Trained batch 418 in epoch 0, gen_loss = 0.8690343597339275, disc_loss = 0.16967119144938156
Trained batch 419 in epoch 0, gen_loss = 0.8690039648896172, disc_loss = 0.16958911837566468
Trained batch 420 in epoch 0, gen_loss = 0.8688548610782397, disc_loss = 0.16945888675448448
Trained batch 421 in epoch 0, gen_loss = 0.8687544275799068, disc_loss = 0.16931404012709997
Trained batch 422 in epoch 0, gen_loss = 0.8688843047365229, disc_loss = 0.16911509779257697
Trained batch 423 in epoch 0, gen_loss = 0.8689367037336782, disc_loss = 0.16895737801239175
Trained batch 424 in epoch 0, gen_loss = 0.8692370047288782, disc_loss = 0.16947077330420998
Trained batch 425 in epoch 0, gen_loss = 0.8684629775548764, disc_loss = 0.16942880246700814
Trained batch 426 in epoch 0, gen_loss = 0.8681303702416967, disc_loss = 0.16941322909724796
Trained batch 427 in epoch 0, gen_loss = 0.8681005832747878, disc_loss = 0.16933797362530342
Trained batch 428 in epoch 0, gen_loss = 0.8677630046586613, disc_loss = 0.16918673527824296
Trained batch 429 in epoch 0, gen_loss = 0.8677604389745136, disc_loss = 0.1690797637195088
Trained batch 430 in epoch 0, gen_loss = 0.8674105881538302, disc_loss = 0.1690697027435159
Trained batch 431 in epoch 0, gen_loss = 0.8676282999416193, disc_loss = 0.16899747882659236
Trained batch 432 in epoch 0, gen_loss = 0.867514875827155, disc_loss = 0.16882445487703518
Trained batch 433 in epoch 0, gen_loss = 0.8673784140892292, disc_loss = 0.16856099805936287
Trained batch 434 in epoch 0, gen_loss = 0.8669188052758403, disc_loss = 0.16843648467255734
Trained batch 435 in epoch 0, gen_loss = 0.866818371169064, disc_loss = 0.16832673711992732
Trained batch 436 in epoch 0, gen_loss = 0.865933791041647, disc_loss = 0.16836391244450205
Trained batch 437 in epoch 0, gen_loss = 0.866099317732467, disc_loss = 0.16820045582711968
Trained batch 438 in epoch 0, gen_loss = 0.866093877372003, disc_loss = 0.16828908571010298
Trained batch 439 in epoch 0, gen_loss = 0.8654137867418202, disc_loss = 0.16824732610786503
Trained batch 440 in epoch 0, gen_loss = 0.8654490605233207, disc_loss = 0.16806055593585212
Trained batch 441 in epoch 0, gen_loss = 0.8664423781552466, disc_loss = 0.16897325607109392
Trained batch 442 in epoch 0, gen_loss = 0.8664108761008114, disc_loss = 0.16925913934715714
Trained batch 443 in epoch 0, gen_loss = 0.8657682002396196, disc_loss = 0.1695875299775654
Trained batch 444 in epoch 0, gen_loss = 0.8652884216790788, disc_loss = 0.1695711531498459
Trained batch 445 in epoch 0, gen_loss = 0.8650328364607465, disc_loss = 0.16954268874274775
Trained batch 446 in epoch 0, gen_loss = 0.8649394965545176, disc_loss = 0.16945300297915802
Trained batch 447 in epoch 0, gen_loss = 0.8643988867157272, disc_loss = 0.16935586189252458
Trained batch 448 in epoch 0, gen_loss = 0.8642578138274977, disc_loss = 0.16924071904346513
Trained batch 449 in epoch 0, gen_loss = 0.864032312101788, disc_loss = 0.1691716262201468
Trained batch 450 in epoch 0, gen_loss = 0.8637565151022173, disc_loss = 0.16912897924031492
Trained batch 451 in epoch 0, gen_loss = 0.8637916560457871, disc_loss = 0.16901427728280558
Trained batch 452 in epoch 0, gen_loss = 0.863158683245282, disc_loss = 0.16892837201785832
Trained batch 453 in epoch 0, gen_loss = 0.8626203363687457, disc_loss = 0.16886767938667457
Trained batch 454 in epoch 0, gen_loss = 0.862951949926523, disc_loss = 0.16908626088074274
Trained batch 455 in epoch 0, gen_loss = 0.8625728189945221, disc_loss = 0.1690505189788446
Trained batch 456 in epoch 0, gen_loss = 0.8622019958704775, disc_loss = 0.16893644011385853
Trained batch 457 in epoch 0, gen_loss = 0.8620092650167807, disc_loss = 0.16893449282542067
Trained batch 458 in epoch 0, gen_loss = 0.8613289053144019, disc_loss = 0.16888244550731965
Trained batch 459 in epoch 0, gen_loss = 0.8613843281631884, disc_loss = 0.16874193609084773
Trained batch 460 in epoch 0, gen_loss = 0.861640886991505, disc_loss = 0.16863336391472247
Trained batch 461 in epoch 0, gen_loss = 0.8614145274802204, disc_loss = 0.16860127760282842
Trained batch 462 in epoch 0, gen_loss = 0.8607441502307455, disc_loss = 0.16900097939224015
Trained batch 463 in epoch 0, gen_loss = 0.8609143555935087, disc_loss = 0.16884153132359014
Trained batch 464 in epoch 0, gen_loss = 0.8609684362206408, disc_loss = 0.1687826904718594
Trained batch 465 in epoch 0, gen_loss = 0.8605229310979148, disc_loss = 0.16889054105964854
Trained batch 466 in epoch 0, gen_loss = 0.8605347925386286, disc_loss = 0.16887868763739342
Trained batch 467 in epoch 0, gen_loss = 0.8605993502160423, disc_loss = 0.16886425137710878
Trained batch 468 in epoch 0, gen_loss = 0.8602968624659947, disc_loss = 0.16875452287733428
Trained batch 469 in epoch 0, gen_loss = 0.8600403809801062, disc_loss = 0.16865028937129264
Trained batch 470 in epoch 0, gen_loss = 0.8599602671185876, disc_loss = 0.16852569334889167
Trained batch 471 in epoch 0, gen_loss = 0.8598040512810319, disc_loss = 0.16830628041683113
Trained batch 472 in epoch 0, gen_loss = 0.859765180573655, disc_loss = 0.16827412789203147
Trained batch 473 in epoch 0, gen_loss = 0.8589282489778624, disc_loss = 0.16874705750165106
Trained batch 474 in epoch 0, gen_loss = 0.859004678098779, disc_loss = 0.16876394505563536
Trained batch 475 in epoch 0, gen_loss = 0.8587970207719242, disc_loss = 0.16869450011486267
Trained batch 476 in epoch 0, gen_loss = 0.8582681368731853, disc_loss = 0.1687599187658268
Trained batch 477 in epoch 0, gen_loss = 0.8582138690988389, disc_loss = 0.16874682586873924
Trained batch 478 in epoch 0, gen_loss = 0.8580681558441767, disc_loss = 0.16876401574912797
Trained batch 479 in epoch 0, gen_loss = 0.8572984740138054, disc_loss = 0.16875818407473464
Trained batch 480 in epoch 0, gen_loss = 0.8572187788025505, disc_loss = 0.16867912743480687
Trained batch 481 in epoch 0, gen_loss = 0.8576146193559734, disc_loss = 0.16887480365228355
Trained batch 482 in epoch 0, gen_loss = 0.8572020367806003, disc_loss = 0.16872630006099587
Trained batch 483 in epoch 0, gen_loss = 0.8567031113323101, disc_loss = 0.16860509345169403
Trained batch 484 in epoch 0, gen_loss = 0.8567647630406409, disc_loss = 0.16843080365473462
Trained batch 485 in epoch 0, gen_loss = 0.85704941305604, disc_loss = 0.16846943862828206
Trained batch 486 in epoch 0, gen_loss = 0.856429123046217, disc_loss = 0.16833199771767524
Trained batch 487 in epoch 0, gen_loss = 0.8559515172096549, disc_loss = 0.16839074987734928
Trained batch 488 in epoch 0, gen_loss = 0.8563795295717282, disc_loss = 0.16820100955436565
Trained batch 489 in epoch 0, gen_loss = 0.8566839722954497, disc_loss = 0.16807453195963587
Trained batch 490 in epoch 0, gen_loss = 0.8566236749685952, disc_loss = 0.16791165729343527
Trained batch 491 in epoch 0, gen_loss = 0.8564733721134139, disc_loss = 0.16790347856779894
Trained batch 492 in epoch 0, gen_loss = 0.8572731437596056, disc_loss = 0.16821100511427584
Trained batch 493 in epoch 0, gen_loss = 0.8569840037147043, disc_loss = 0.168207359413507
Trained batch 494 in epoch 0, gen_loss = 0.8566316175942469, disc_loss = 0.16817228693251657
Trained batch 495 in epoch 0, gen_loss = 0.8565319971211495, disc_loss = 0.16807710679788743
Trained batch 496 in epoch 0, gen_loss = 0.8563985859364331, disc_loss = 0.16804899782002333
Trained batch 497 in epoch 0, gen_loss = 0.8557835701239636, disc_loss = 0.16806814008687873
Trained batch 498 in epoch 0, gen_loss = 0.8557623188815757, disc_loss = 0.1679006400023529
Trained batch 499 in epoch 0, gen_loss = 0.8557276391983032, disc_loss = 0.16793127627670765
Trained batch 500 in epoch 0, gen_loss = 0.8552968483009262, disc_loss = 0.16784213203750922
Trained batch 501 in epoch 0, gen_loss = 0.8550988096164992, disc_loss = 0.16768128715782052
Trained batch 502 in epoch 0, gen_loss = 0.8550354147526189, disc_loss = 0.16769692630582964
Trained batch 503 in epoch 0, gen_loss = 0.8547385642452846, disc_loss = 0.16795706509479455
Trained batch 504 in epoch 0, gen_loss = 0.8548366454568239, disc_loss = 0.16796782075768651
Trained batch 505 in epoch 0, gen_loss = 0.8545907434267489, disc_loss = 0.16787119560208716
Trained batch 506 in epoch 0, gen_loss = 0.8541747373942088, disc_loss = 0.1679191028284133
Trained batch 507 in epoch 0, gen_loss = 0.8535750605693952, disc_loss = 0.16787916952817458
Trained batch 508 in epoch 0, gen_loss = 0.8536396170646128, disc_loss = 0.16810735512693176
Trained batch 509 in epoch 0, gen_loss = 0.8533292437300962, disc_loss = 0.16809951052361843
Trained batch 510 in epoch 0, gen_loss = 0.8530009324769918, disc_loss = 0.16810123476613525
Trained batch 511 in epoch 0, gen_loss = 0.8528533568605781, disc_loss = 0.16805741269490682
Trained batch 512 in epoch 0, gen_loss = 0.8525219127448679, disc_loss = 0.16799182579879873
Trained batch 513 in epoch 0, gen_loss = 0.8524881610610606, disc_loss = 0.16793525007332347
Trained batch 514 in epoch 0, gen_loss = 0.8520876067355998, disc_loss = 0.16789389348145828
Trained batch 515 in epoch 0, gen_loss = 0.8520185457643612, disc_loss = 0.1677350667702366
Trained batch 516 in epoch 0, gen_loss = 0.8520808433195147, disc_loss = 0.16762651400766704
Trained batch 517 in epoch 0, gen_loss = 0.8520124774411838, disc_loss = 0.16746940869392116
Trained batch 518 in epoch 0, gen_loss = 0.8519816717890186, disc_loss = 0.16728670702733975
Trained batch 519 in epoch 0, gen_loss = 0.8522227537173491, disc_loss = 0.1671357372775674
Trained batch 520 in epoch 0, gen_loss = 0.8516460444327737, disc_loss = 0.1671379279924446
Trained batch 521 in epoch 0, gen_loss = 0.85185792711046, disc_loss = 0.1672750118962878
Trained batch 522 in epoch 0, gen_loss = 0.8512970076920198, disc_loss = 0.1671219096015106
Trained batch 523 in epoch 0, gen_loss = 0.8509554374991483, disc_loss = 0.16717114620877585
Trained batch 524 in epoch 0, gen_loss = 0.8515030766668774, disc_loss = 0.16765944847038813
Trained batch 525 in epoch 0, gen_loss = 0.851596706380409, disc_loss = 0.16747340302163657
Trained batch 526 in epoch 0, gen_loss = 0.8514510198607617, disc_loss = 0.16732740946524058
Trained batch 527 in epoch 0, gen_loss = 0.8512410686323137, disc_loss = 0.16717338532378728
Trained batch 528 in epoch 0, gen_loss = 0.8512195025364708, disc_loss = 0.16710956379179692
Trained batch 529 in epoch 0, gen_loss = 0.8508600864770277, disc_loss = 0.1669729994293654
Trained batch 530 in epoch 0, gen_loss = 0.8509041977916509, disc_loss = 0.16674166875005667
Trained batch 531 in epoch 0, gen_loss = 0.8507248164343655, disc_loss = 0.16684073318300166
Trained batch 532 in epoch 0, gen_loss = 0.8505190592993044, disc_loss = 0.16675533391325603
Trained batch 533 in epoch 0, gen_loss = 0.850531030795101, disc_loss = 0.16654383541130172
Trained batch 534 in epoch 0, gen_loss = 0.8507804936337694, disc_loss = 0.16660765266724836
Trained batch 535 in epoch 0, gen_loss = 0.8505232177341162, disc_loss = 0.16655278480403238
Trained batch 536 in epoch 0, gen_loss = 0.8500912068498423, disc_loss = 0.16652749650166465
Trained batch 537 in epoch 0, gen_loss = 0.8503117980123895, disc_loss = 0.16672185879740795
Trained batch 538 in epoch 0, gen_loss = 0.8500160090556171, disc_loss = 0.16676561984342414
Trained batch 539 in epoch 0, gen_loss = 0.8497075958384408, disc_loss = 0.16675638335032594
Trained batch 540 in epoch 0, gen_loss = 0.8497851396223974, disc_loss = 0.16658612435026002
Trained batch 541 in epoch 0, gen_loss = 0.8498922077272211, disc_loss = 0.16645509658237004
Trained batch 542 in epoch 0, gen_loss = 0.8496082031046268, disc_loss = 0.16635094939098174
Trained batch 543 in epoch 0, gen_loss = 0.8500005177715245, disc_loss = 0.16657513310886263
Trained batch 544 in epoch 0, gen_loss = 0.8497671448856319, disc_loss = 0.1664740405019817
Trained batch 545 in epoch 0, gen_loss = 0.8494281463133984, disc_loss = 0.16639747319831735
Trained batch 546 in epoch 0, gen_loss = 0.8493179065435852, disc_loss = 0.16657747128736602
Trained batch 547 in epoch 0, gen_loss = 0.8493467830393436, disc_loss = 0.1664412091724085
Trained batch 548 in epoch 0, gen_loss = 0.8490390663589936, disc_loss = 0.1663385770183552
Trained batch 549 in epoch 0, gen_loss = 0.8492090437629006, disc_loss = 0.16638577663763002
Trained batch 550 in epoch 0, gen_loss = 0.8489235285838589, disc_loss = 0.1662867413985859
Trained batch 551 in epoch 0, gen_loss = 0.8490617575420849, disc_loss = 0.16610668399168746
Trained batch 552 in epoch 0, gen_loss = 0.8490939833372023, disc_loss = 0.1660662059475134
Trained batch 553 in epoch 0, gen_loss = 0.8487526793772563, disc_loss = 0.1659811626689421
Trained batch 554 in epoch 0, gen_loss = 0.8487011332769652, disc_loss = 0.1658179822335909
Trained batch 555 in epoch 0, gen_loss = 0.8490560866302723, disc_loss = 0.1657261109488795
Trained batch 556 in epoch 0, gen_loss = 0.848698314687294, disc_loss = 0.16559819742716195
Trained batch 557 in epoch 0, gen_loss = 0.8485504311899985, disc_loss = 0.16554523216006362
Trained batch 558 in epoch 0, gen_loss = 0.8484545647564855, disc_loss = 0.16539588849824954
Trained batch 559 in epoch 0, gen_loss = 0.8479512908629009, disc_loss = 0.16542240494995245
Trained batch 560 in epoch 0, gen_loss = 0.8486191724923418, disc_loss = 0.16581699764107
Trained batch 561 in epoch 0, gen_loss = 0.8484230809364455, disc_loss = 0.16571256695348385
Trained batch 562 in epoch 0, gen_loss = 0.8481808987646289, disc_loss = 0.16558640659993537
Trained batch 563 in epoch 0, gen_loss = 0.847970872166309, disc_loss = 0.16569886746955045
Trained batch 564 in epoch 0, gen_loss = 0.8474913196226137, disc_loss = 0.16563303142917896
Trained batch 565 in epoch 0, gen_loss = 0.8477371775219381, disc_loss = 0.16549741328684053
Trained batch 566 in epoch 0, gen_loss = 0.8475062963823793, disc_loss = 0.16532350990533617
Trained batch 567 in epoch 0, gen_loss = 0.8472467932692715, disc_loss = 0.1651830190569687
Trained batch 568 in epoch 0, gen_loss = 0.8473575593926576, disc_loss = 0.1653216508510138
Trained batch 569 in epoch 0, gen_loss = 0.8471197882242371, disc_loss = 0.16515235689779123
Trained batch 570 in epoch 0, gen_loss = 0.8469354286920378, disc_loss = 0.16506020974648394
Trained batch 571 in epoch 0, gen_loss = 0.8471432906555962, disc_loss = 0.16492285973464066
Trained batch 572 in epoch 0, gen_loss = 0.8469097607006786, disc_loss = 0.16490998011843072
Trained batch 573 in epoch 0, gen_loss = 0.8469521054407445, disc_loss = 0.1647487081626255
Trained batch 574 in epoch 0, gen_loss = 0.8471381516041963, disc_loss = 0.16457105586710183
Trained batch 575 in epoch 0, gen_loss = 0.8468872255956134, disc_loss = 0.16449622087465185
Trained batch 576 in epoch 0, gen_loss = 0.8468049015701333, disc_loss = 0.16441027956338441
Trained batch 577 in epoch 0, gen_loss = 0.8467879226257232, disc_loss = 0.16424886808186048
Trained batch 578 in epoch 0, gen_loss = 0.8460124817536903, disc_loss = 0.16459778124315338
Trained batch 579 in epoch 0, gen_loss = 0.8463656365871429, disc_loss = 0.1648248785335956
Trained batch 580 in epoch 0, gen_loss = 0.8458177387816975, disc_loss = 0.16489690565944948
Trained batch 581 in epoch 0, gen_loss = 0.8456048837437253, disc_loss = 0.1649509162235608
Trained batch 582 in epoch 0, gen_loss = 0.8453821862950334, disc_loss = 0.16501385712833183
Trained batch 583 in epoch 0, gen_loss = 0.8455322839013518, disc_loss = 0.16504654092459034
Trained batch 584 in epoch 0, gen_loss = 0.8452702787187364, disc_loss = 0.16524058583582568
Trained batch 585 in epoch 0, gen_loss = 0.8448528570119839, disc_loss = 0.1652536854821769
Trained batch 586 in epoch 0, gen_loss = 0.8446025040121257, disc_loss = 0.16539843472472854
Trained batch 587 in epoch 0, gen_loss = 0.8446491660714961, disc_loss = 0.16547122732641137
Trained batch 588 in epoch 0, gen_loss = 0.8445793642252937, disc_loss = 0.16541357678068716
Trained batch 589 in epoch 0, gen_loss = 0.8441306012161708, disc_loss = 0.16540018222215822
Trained batch 590 in epoch 0, gen_loss = 0.8438685433513622, disc_loss = 0.16535878550204527
Trained batch 591 in epoch 0, gen_loss = 0.8434764711639365, disc_loss = 0.16539358723329733
Trained batch 592 in epoch 0, gen_loss = 0.8436799196127495, disc_loss = 0.1653575384408286
Trained batch 593 in epoch 0, gen_loss = 0.8433030135302432, disc_loss = 0.1654252523136159
Trained batch 594 in epoch 0, gen_loss = 0.8436821306453032, disc_loss = 0.16569528427569807
Trained batch 595 in epoch 0, gen_loss = 0.84348295198991, disc_loss = 0.16564433964831918
Trained batch 596 in epoch 0, gen_loss = 0.8434905474709107, disc_loss = 0.16561744573652445
Trained batch 597 in epoch 0, gen_loss = 0.8432326575984126, disc_loss = 0.1655361667512153
Trained batch 598 in epoch 0, gen_loss = 0.8430460181976599, disc_loss = 0.1654882444650283
Trained batch 599 in epoch 0, gen_loss = 0.8431663684050242, disc_loss = 0.16542467705284555
Trained batch 600 in epoch 0, gen_loss = 0.8429765754848867, disc_loss = 0.16526110040739847
Trained batch 601 in epoch 0, gen_loss = 0.8431213109992272, disc_loss = 0.165100814205319
Trained batch 602 in epoch 0, gen_loss = 0.8434159686513999, disc_loss = 0.1650768530371276
Trained batch 603 in epoch 0, gen_loss = 0.8430708829338187, disc_loss = 0.1650713864800255
Trained batch 604 in epoch 0, gen_loss = 0.8433005357576796, disc_loss = 0.16496969475603301
Trained batch 605 in epoch 0, gen_loss = 0.8433814639895663, disc_loss = 0.1648667049179278
Trained batch 606 in epoch 0, gen_loss = 0.8429942426610818, disc_loss = 0.16480115558675917
Trained batch 607 in epoch 0, gen_loss = 0.8431186247617006, disc_loss = 0.16490807449812755
Trained batch 608 in epoch 0, gen_loss = 0.8427859220794465, disc_loss = 0.16502313403342353
Trained batch 609 in epoch 0, gen_loss = 0.8429635749488581, disc_loss = 0.16507334173580662
Trained batch 610 in epoch 0, gen_loss = 0.8429150481856201, disc_loss = 0.1651219508493298
Trained batch 611 in epoch 0, gen_loss = 0.8426447724984363, disc_loss = 0.16512235803712233
Trained batch 612 in epoch 0, gen_loss = 0.8422509671035443, disc_loss = 0.16522344445496748
Trained batch 613 in epoch 0, gen_loss = 0.8426589130966982, disc_loss = 0.1653332517266953
Trained batch 614 in epoch 0, gen_loss = 0.8425690836053553, disc_loss = 0.16528443788004116
Trained batch 615 in epoch 0, gen_loss = 0.8422708714550192, disc_loss = 0.16524246704534856
Trained batch 616 in epoch 0, gen_loss = 0.8418976688694142, disc_loss = 0.16525801329766332
Trained batch 617 in epoch 0, gen_loss = 0.8417600983554877, disc_loss = 0.16521918814038575
Trained batch 618 in epoch 0, gen_loss = 0.8417371278433115, disc_loss = 0.16524571959705653
Trained batch 619 in epoch 0, gen_loss = 0.8416192763274716, disc_loss = 0.16512043879277283
Trained batch 620 in epoch 0, gen_loss = 0.8413625798171653, disc_loss = 0.16501673621136018
Trained batch 621 in epoch 0, gen_loss = 0.8412963506493154, disc_loss = 0.16488552083324198
Trained batch 622 in epoch 0, gen_loss = 0.8412499422054995, disc_loss = 0.16475834365617215
Trained batch 623 in epoch 0, gen_loss = 0.8413043013558938, disc_loss = 0.16460276398067483
Trained batch 624 in epoch 0, gen_loss = 0.8410383438110351, disc_loss = 0.16467915590405463
Trained batch 625 in epoch 0, gen_loss = 0.8412560779637042, disc_loss = 0.16469762698649026
Trained batch 626 in epoch 0, gen_loss = 0.8410970497359499, disc_loss = 0.16456197373913617
Trained batch 627 in epoch 0, gen_loss = 0.840946366452867, disc_loss = 0.16446191577276417
Trained batch 628 in epoch 0, gen_loss = 0.8410533577535414, disc_loss = 0.1643982286519106
Trained batch 629 in epoch 0, gen_loss = 0.8406409935345726, disc_loss = 0.16433803843009093
Trained batch 630 in epoch 0, gen_loss = 0.8405932208815392, disc_loss = 0.16422455774977354
Trained batch 631 in epoch 0, gen_loss = 0.8404790266782423, disc_loss = 0.16413127754142956
Trained batch 632 in epoch 0, gen_loss = 0.8402532148888514, disc_loss = 0.16396326032036102
Trained batch 633 in epoch 0, gen_loss = 0.8401993218844621, disc_loss = 0.16379722260079738
Trained batch 634 in epoch 0, gen_loss = 0.8402967272781011, disc_loss = 0.16380862873487584
Trained batch 635 in epoch 0, gen_loss = 0.8397579035669003, disc_loss = 0.16391790595561642
Trained batch 636 in epoch 0, gen_loss = 0.8397966176037511, disc_loss = 0.1637943685347188
Trained batch 637 in epoch 0, gen_loss = 0.8401273746849227, disc_loss = 0.1637756175253552
Trained batch 638 in epoch 0, gen_loss = 0.8398036010015365, disc_loss = 0.1637441444623172
Trained batch 639 in epoch 0, gen_loss = 0.8394829296506942, disc_loss = 0.16371091239270755
Trained batch 640 in epoch 0, gen_loss = 0.8391427372621486, disc_loss = 0.16360254525882592
Trained batch 641 in epoch 0, gen_loss = 0.8389731126596623, disc_loss = 0.1635693372793008
Trained batch 642 in epoch 0, gen_loss = 0.8387829835641069, disc_loss = 0.16344962446931546
Trained batch 643 in epoch 0, gen_loss = 0.8385863970525517, disc_loss = 0.16327704268258922
Trained batch 644 in epoch 0, gen_loss = 0.8384022163790326, disc_loss = 0.1631330232403075
Trained batch 645 in epoch 0, gen_loss = 0.8388553080913083, disc_loss = 0.16316469432353603
Trained batch 646 in epoch 0, gen_loss = 0.838554710287952, disc_loss = 0.16353660931312688
Trained batch 647 in epoch 0, gen_loss = 0.839123731042132, disc_loss = 0.1641331617547958
Trained batch 648 in epoch 0, gen_loss = 0.838899491839857, disc_loss = 0.1641183127125349
Trained batch 649 in epoch 0, gen_loss = 0.8387577844583071, disc_loss = 0.16409170816724117
Trained batch 650 in epoch 0, gen_loss = 0.8384455062460423, disc_loss = 0.16403466306294898
Trained batch 651 in epoch 0, gen_loss = 0.8382304493634979, disc_loss = 0.1639293894011733
Trained batch 652 in epoch 0, gen_loss = 0.8381679545500377, disc_loss = 0.16381626772433291
Trained batch 653 in epoch 0, gen_loss = 0.8375847292693748, disc_loss = 0.16390681384125616
Trained batch 654 in epoch 0, gen_loss = 0.8378926162956325, disc_loss = 0.16405873961803566
Trained batch 655 in epoch 0, gen_loss = 0.8377559925088796, disc_loss = 0.1640888107599827
Trained batch 656 in epoch 0, gen_loss = 0.8374237543825327, disc_loss = 0.16442129527370317
Trained batch 657 in epoch 0, gen_loss = 0.8374643387856092, disc_loss = 0.16443943822229887
Trained batch 658 in epoch 0, gen_loss = 0.837451492482867, disc_loss = 0.16444820689096798
Trained batch 659 in epoch 0, gen_loss = 0.8373825602007635, disc_loss = 0.1645260130252802
Trained batch 660 in epoch 0, gen_loss = 0.8372169339440414, disc_loss = 0.1645205502543435
Trained batch 661 in epoch 0, gen_loss = 0.8370895450118805, disc_loss = 0.16445318007352128
Trained batch 662 in epoch 0, gen_loss = 0.8370730505180215, disc_loss = 0.16439585002254398
Trained batch 663 in epoch 0, gen_loss = 0.8367912239249212, disc_loss = 0.16439025087214737
Trained batch 664 in epoch 0, gen_loss = 0.8368678724407254, disc_loss = 0.16441597581133807
Trained batch 665 in epoch 0, gen_loss = 0.8366622749839101, disc_loss = 0.16438812712157094
Trained batch 666 in epoch 0, gen_loss = 0.8362810212722246, disc_loss = 0.1644294514492534
Trained batch 667 in epoch 0, gen_loss = 0.8363895588916933, disc_loss = 0.16434331636452032
Trained batch 668 in epoch 0, gen_loss = 0.8362921454535828, disc_loss = 0.16421318328166756
Trained batch 669 in epoch 0, gen_loss = 0.8362721555713397, disc_loss = 0.16408382932196802
Trained batch 670 in epoch 0, gen_loss = 0.8361723815186723, disc_loss = 0.16405570749110152
Trained batch 671 in epoch 0, gen_loss = 0.8360483629983806, disc_loss = 0.16428141546480002
Trained batch 672 in epoch 0, gen_loss = 0.8356965847125202, disc_loss = 0.16440257069171804
Trained batch 673 in epoch 0, gen_loss = 0.8362808359748178, disc_loss = 0.1645171866484141
Trained batch 674 in epoch 0, gen_loss = 0.8361124909807135, disc_loss = 0.164460017018848
Trained batch 675 in epoch 0, gen_loss = 0.8355873853585424, disc_loss = 0.16450654702073725
Trained batch 676 in epoch 0, gen_loss = 0.83539062716408, disc_loss = 0.16443655792860373
Trained batch 677 in epoch 0, gen_loss = 0.8352599693874342, disc_loss = 0.16433807097617154
Trained batch 678 in epoch 0, gen_loss = 0.8351185735704622, disc_loss = 0.16422674806023205
Trained batch 679 in epoch 0, gen_loss = 0.8345861406887278, disc_loss = 0.16420948774937322
Trained batch 680 in epoch 0, gen_loss = 0.834236595249036, disc_loss = 0.164143798864623
Trained batch 681 in epoch 0, gen_loss = 0.8346253186027326, disc_loss = 0.16416795303788353
Trained batch 682 in epoch 0, gen_loss = 0.8344972478348549, disc_loss = 0.16406009021170143
Trained batch 683 in epoch 0, gen_loss = 0.8341560973758586, disc_loss = 0.16410491366091876
Trained batch 684 in epoch 0, gen_loss = 0.8344302854398742, disc_loss = 0.16423124095601757
Trained batch 685 in epoch 0, gen_loss = 0.8340806662167474, disc_loss = 0.1642345805535685
Trained batch 686 in epoch 0, gen_loss = 0.8338196534430269, disc_loss = 0.16422096162687397
Trained batch 687 in epoch 0, gen_loss = 0.8338242925183718, disc_loss = 0.16450253205893692
Trained batch 688 in epoch 0, gen_loss = 0.8335837509877796, disc_loss = 0.16441252125840747
Trained batch 689 in epoch 0, gen_loss = 0.8331023957418359, disc_loss = 0.16440242182301437
Trained batch 690 in epoch 0, gen_loss = 0.833309483424627, disc_loss = 0.16437213449548882
Trained batch 691 in epoch 0, gen_loss = 0.8332465461568336, disc_loss = 0.16428584137102428
Trained batch 692 in epoch 0, gen_loss = 0.8329610446142772, disc_loss = 0.16421984046869637
Trained batch 693 in epoch 0, gen_loss = 0.832852036362079, disc_loss = 0.16430505645335236
Trained batch 694 in epoch 0, gen_loss = 0.8325854563884598, disc_loss = 0.16426217295497442
Trained batch 695 in epoch 0, gen_loss = 0.8324036650445269, disc_loss = 0.1645237229785871
Trained batch 696 in epoch 0, gen_loss = 0.8321102410341096, disc_loss = 0.164461501455803
Trained batch 697 in epoch 0, gen_loss = 0.8319499648915321, disc_loss = 0.16432986202460306
Trained batch 698 in epoch 0, gen_loss = 0.8318258091615505, disc_loss = 0.1642559221352801
Trained batch 699 in epoch 0, gen_loss = 0.8314623532976423, disc_loss = 0.16431660634066378
Trained batch 700 in epoch 0, gen_loss = 0.8313071714148201, disc_loss = 0.16433479804837925
Trained batch 701 in epoch 0, gen_loss = 0.8313848244668411, disc_loss = 0.16448120166815583
Trained batch 702 in epoch 0, gen_loss = 0.8309565081365756, disc_loss = 0.16441489249510244
Trained batch 703 in epoch 0, gen_loss = 0.8305672332644463, disc_loss = 0.16440143457359888
Trained batch 704 in epoch 0, gen_loss = 0.8305253329851948, disc_loss = 0.164570348989879
Trained batch 705 in epoch 0, gen_loss = 0.8303038493938554, disc_loss = 0.16447041382110827
Trained batch 706 in epoch 0, gen_loss = 0.8298654552902157, disc_loss = 0.16455600013405802
Trained batch 707 in epoch 0, gen_loss = 0.83000104651276, disc_loss = 0.16469622376022366
Trained batch 708 in epoch 0, gen_loss = 0.8298998513746328, disc_loss = 0.16469723997146354
Trained batch 709 in epoch 0, gen_loss = 0.8295932357579889, disc_loss = 0.16477346439176882
Trained batch 710 in epoch 0, gen_loss = 0.8292748512262701, disc_loss = 0.16476181088704434
Trained batch 711 in epoch 0, gen_loss = 0.8292652412914159, disc_loss = 0.16490540253730973
Trained batch 712 in epoch 0, gen_loss = 0.8290618337053404, disc_loss = 0.16490936929263372
Trained batch 713 in epoch 0, gen_loss = 0.8289948655944579, disc_loss = 0.16484708989075586
Trained batch 714 in epoch 0, gen_loss = 0.8287103382023898, disc_loss = 0.16481649320233951
Trained batch 715 in epoch 0, gen_loss = 0.8287180976827717, disc_loss = 0.16483227329006075
Trained batch 716 in epoch 0, gen_loss = 0.8284683146071068, disc_loss = 0.16477032567957622
Trained batch 717 in epoch 0, gen_loss = 0.8281820413129908, disc_loss = 0.16470971133840118
Trained batch 718 in epoch 0, gen_loss = 0.8279314777284074, disc_loss = 0.16470455836312994
Trained batch 719 in epoch 0, gen_loss = 0.8278762316538228, disc_loss = 0.16455229947136507
Trained batch 720 in epoch 0, gen_loss = 0.8279166188550888, disc_loss = 0.16443792944476937
Trained batch 721 in epoch 0, gen_loss = 0.8280870460407226, disc_loss = 0.16424818465181748
Trained batch 722 in epoch 0, gen_loss = 0.8281334600672847, disc_loss = 0.16407345650385277
Trained batch 723 in epoch 0, gen_loss = 0.8280485135744948, disc_loss = 0.16391879903893528
Trained batch 724 in epoch 0, gen_loss = 0.8282900497831147, disc_loss = 0.16378390856087208
Trained batch 725 in epoch 0, gen_loss = 0.8283812702523119, disc_loss = 0.16369266653325687
Trained batch 726 in epoch 0, gen_loss = 0.8280794131870611, disc_loss = 0.16360877155284032
Trained batch 727 in epoch 0, gen_loss = 0.828405614901375, disc_loss = 0.16371261078997382
Trained batch 728 in epoch 0, gen_loss = 0.8282798146024163, disc_loss = 0.16373260215241642
Trained batch 729 in epoch 0, gen_loss = 0.828485198788447, disc_loss = 0.16362027854799
Trained batch 730 in epoch 0, gen_loss = 0.8282596263448452, disc_loss = 0.1635241057703376
Trained batch 731 in epoch 0, gen_loss = 0.8282997778367475, disc_loss = 0.16343881494411436
Trained batch 732 in epoch 0, gen_loss = 0.8285220114140687, disc_loss = 0.16324189570344894
Trained batch 733 in epoch 0, gen_loss = 0.8283076816586122, disc_loss = 0.16345969115305256
Trained batch 734 in epoch 0, gen_loss = 0.8287402187885882, disc_loss = 0.16383493243380876
Trained batch 735 in epoch 0, gen_loss = 0.8287586211024419, disc_loss = 0.16390737833242622
Trained batch 736 in epoch 0, gen_loss = 0.8282237551105556, disc_loss = 0.16418397105886542
Trained batch 737 in epoch 0, gen_loss = 0.8278670631611573, disc_loss = 0.1642195987502532
Trained batch 738 in epoch 0, gen_loss = 0.8277176503238239, disc_loss = 0.16428899884738118
Trained batch 739 in epoch 0, gen_loss = 0.8275896630577139, disc_loss = 0.16434449703256424
Trained batch 740 in epoch 0, gen_loss = 0.8272594147526462, disc_loss = 0.16439570732635927
Trained batch 741 in epoch 0, gen_loss = 0.8271798607152748, disc_loss = 0.16444785263128278
Trained batch 742 in epoch 0, gen_loss = 0.8266164285016734, disc_loss = 0.16457716092557556
Trained batch 743 in epoch 0, gen_loss = 0.8265602969193971, disc_loss = 0.16460820103955445
Trained batch 744 in epoch 0, gen_loss = 0.8263244641707248, disc_loss = 0.1646245118830628
Trained batch 745 in epoch 0, gen_loss = 0.8260415482457137, disc_loss = 0.16460212376767686
Trained batch 746 in epoch 0, gen_loss = 0.8260285935727468, disc_loss = 0.16455736090809386
Trained batch 747 in epoch 0, gen_loss = 0.8256759684991072, disc_loss = 0.16456726524869308
Trained batch 748 in epoch 0, gen_loss = 0.8256072270695135, disc_loss = 0.16456371958358823
Trained batch 749 in epoch 0, gen_loss = 0.8254856530825297, disc_loss = 0.1645877664362391
Trained batch 750 in epoch 0, gen_loss = 0.8254906412923384, disc_loss = 0.16454139747439864
Trained batch 751 in epoch 0, gen_loss = 0.825674574584403, disc_loss = 0.16444555110981726
Trained batch 752 in epoch 0, gen_loss = 0.8256112250040568, disc_loss = 0.1643837222911091
Trained batch 753 in epoch 0, gen_loss = 0.8253510804644314, disc_loss = 0.16431208290604365
Trained batch 754 in epoch 0, gen_loss = 0.8251334013528382, disc_loss = 0.16423214025400726
Trained batch 755 in epoch 0, gen_loss = 0.8252165582444932, disc_loss = 0.16415887734749252
Trained batch 756 in epoch 0, gen_loss = 0.8253115201405836, disc_loss = 0.1640094966065419
Trained batch 757 in epoch 0, gen_loss = 0.824994706148208, disc_loss = 0.1640293238006316
Trained batch 758 in epoch 0, gen_loss = 0.8250094158219098, disc_loss = 0.1639103967774959
Trained batch 759 in epoch 0, gen_loss = 0.8250898649818019, disc_loss = 0.16393788693913897
Trained batch 760 in epoch 0, gen_loss = 0.8248373743112392, disc_loss = 0.16388474256730345
Trained batch 761 in epoch 0, gen_loss = 0.8247057574940478, disc_loss = 0.1637970210759463
Trained batch 762 in epoch 0, gen_loss = 0.8244992768780119, disc_loss = 0.16368649285506373
Trained batch 763 in epoch 0, gen_loss = 0.8245709926202035, disc_loss = 0.16365600832499055
Trained batch 764 in epoch 0, gen_loss = 0.8244682089176053, disc_loss = 0.16359609050639703
Trained batch 765 in epoch 0, gen_loss = 0.8243171157164612, disc_loss = 0.16346037281584724
Trained batch 766 in epoch 0, gen_loss = 0.8241722981653127, disc_loss = 0.16336198864842255
Trained batch 767 in epoch 0, gen_loss = 0.82406837772578, disc_loss = 0.1633575559123225
Trained batch 768 in epoch 0, gen_loss = 0.8240318760295218, disc_loss = 0.16326970391711815
Trained batch 769 in epoch 0, gen_loss = 0.8239674557339062, disc_loss = 0.163161452354065
Trained batch 770 in epoch 0, gen_loss = 0.8243349768926815, disc_loss = 0.1631222142585482
Trained batch 771 in epoch 0, gen_loss = 0.8241222476094497, disc_loss = 0.1632859597122538
Trained batch 772 in epoch 0, gen_loss = 0.8246282622854275, disc_loss = 0.16343547466221864
Trained batch 773 in epoch 0, gen_loss = 0.8246019656652012, disc_loss = 0.16335686815791892
Trained batch 774 in epoch 0, gen_loss = 0.824353420580587, disc_loss = 0.16340112649385005
Trained batch 775 in epoch 0, gen_loss = 0.8240973676756486, disc_loss = 0.16342540000584552
Trained batch 776 in epoch 0, gen_loss = 0.8239929595509091, disc_loss = 0.1634681325290769
Trained batch 777 in epoch 0, gen_loss = 0.8240587083876593, disc_loss = 0.1635054792888022
Trained batch 778 in epoch 0, gen_loss = 0.8237201625024553, disc_loss = 0.16359616823456177
Trained batch 779 in epoch 0, gen_loss = 0.8237342496713003, disc_loss = 0.16359047996453369
Trained batch 780 in epoch 0, gen_loss = 0.8236777903023206, disc_loss = 0.16359268565556076
Trained batch 781 in epoch 0, gen_loss = 0.823462010649464, disc_loss = 0.16355539583708242
Trained batch 782 in epoch 0, gen_loss = 0.8236060766729206, disc_loss = 0.16351849639771618
Trained batch 783 in epoch 0, gen_loss = 0.8236699783984496, disc_loss = 0.16341148553254578
Trained batch 784 in epoch 0, gen_loss = 0.823518890711912, disc_loss = 0.16327235460233916
Trained batch 785 in epoch 0, gen_loss = 0.8232889794211351, disc_loss = 0.1633824153706128
Trained batch 786 in epoch 0, gen_loss = 0.8238972745068949, disc_loss = 0.16358409017996609
Trained batch 787 in epoch 0, gen_loss = 0.8236164650336135, disc_loss = 0.16352866314644665
Trained batch 788 in epoch 0, gen_loss = 0.8233181546396175, disc_loss = 0.16356155526303745
Trained batch 789 in epoch 0, gen_loss = 0.8233032374442378, disc_loss = 0.16348800372238023
Trained batch 790 in epoch 0, gen_loss = 0.8234663166378904, disc_loss = 0.16385021330800506
Trained batch 791 in epoch 0, gen_loss = 0.8233493117973057, disc_loss = 0.16377493473607105
Trained batch 792 in epoch 0, gen_loss = 0.8232377892334254, disc_loss = 0.16367696752492222
Trained batch 793 in epoch 0, gen_loss = 0.8231435954120357, disc_loss = 0.16365458967131316
Trained batch 794 in epoch 0, gen_loss = 0.8230251830328935, disc_loss = 0.16348909424770178
Trained batch 795 in epoch 0, gen_loss = 0.8231156775400267, disc_loss = 0.16334934040539004
Trained batch 796 in epoch 0, gen_loss = 0.8232095534708748, disc_loss = 0.16319421649100715
Trained batch 797 in epoch 0, gen_loss = 0.8234698400461584, disc_loss = 0.16303584547503328
Trained batch 798 in epoch 0, gen_loss = 0.8237489106807303, disc_loss = 0.16285708717050704
Trained batch 799 in epoch 0, gen_loss = 0.8239226473867893, disc_loss = 0.1626698605204001
Trained batch 800 in epoch 0, gen_loss = 0.824304699600115, disc_loss = 0.16250619841053543
Trained batch 801 in epoch 0, gen_loss = 0.8244312412275043, disc_loss = 0.1623346883701416
Trained batch 802 in epoch 0, gen_loss = 0.8245270993760039, disc_loss = 0.1622126736721096
Trained batch 803 in epoch 0, gen_loss = 0.8248753926498973, disc_loss = 0.16206879550081432
Trained batch 804 in epoch 0, gen_loss = 0.8246183228788909, disc_loss = 0.16215404664044794
Trained batch 805 in epoch 0, gen_loss = 0.8246182747573474, disc_loss = 0.16208592131641456
Trained batch 806 in epoch 0, gen_loss = 0.8249911855735448, disc_loss = 0.16200463580431548
Trained batch 807 in epoch 0, gen_loss = 0.8248466254756002, disc_loss = 0.1619159688315548
Trained batch 808 in epoch 0, gen_loss = 0.825180531432219, disc_loss = 0.1618177100454258
Trained batch 809 in epoch 0, gen_loss = 0.8250841564602323, disc_loss = 0.16174331752146467
Trained batch 810 in epoch 0, gen_loss = 0.8253360645691652, disc_loss = 0.16156034527344196
Trained batch 811 in epoch 0, gen_loss = 0.8251520924527069, disc_loss = 0.16148250296097158
Trained batch 812 in epoch 0, gen_loss = 0.8254876023142393, disc_loss = 0.1614168202126488
Trained batch 813 in epoch 0, gen_loss = 0.8256565058553541, disc_loss = 0.1612342247597562
Trained batch 814 in epoch 0, gen_loss = 0.8260041685923477, disc_loss = 0.16105850527257276
Trained batch 815 in epoch 0, gen_loss = 0.8261194658630034, disc_loss = 0.16089304113833636
Trained batch 816 in epoch 0, gen_loss = 0.8260700094218353, disc_loss = 0.160720416899848
Trained batch 817 in epoch 0, gen_loss = 0.8263300916676416, disc_loss = 0.1605433521491719
Trained batch 818 in epoch 0, gen_loss = 0.8260517926006526, disc_loss = 0.160424180804173
Trained batch 819 in epoch 0, gen_loss = 0.8261418372392655, disc_loss = 0.16029027834216633
Trained batch 820 in epoch 0, gen_loss = 0.8266033782883481, disc_loss = 0.16020801274307825
Trained batch 821 in epoch 0, gen_loss = 0.8268363045804982, disc_loss = 0.16005734615526424
Trained batch 822 in epoch 0, gen_loss = 0.8264920522491668, disc_loss = 0.1599972813094843
Trained batch 823 in epoch 0, gen_loss = 0.8263391113831001, disc_loss = 0.15996019360699773
Trained batch 824 in epoch 0, gen_loss = 0.8266068629785017, disc_loss = 0.16023288289028587
Trained batch 825 in epoch 0, gen_loss = 0.8266624601210578, disc_loss = 0.16012708261185135
Trained batch 826 in epoch 0, gen_loss = 0.826302192303405, disc_loss = 0.16012932163096757
Trained batch 827 in epoch 0, gen_loss = 0.8263769311029554, disc_loss = 0.160146559127449
Trained batch 828 in epoch 0, gen_loss = 0.826177024007275, disc_loss = 0.16011024908408683
Trained batch 829 in epoch 0, gen_loss = 0.8260626873338078, disc_loss = 0.16006150090595686
Trained batch 830 in epoch 0, gen_loss = 0.8258346724452812, disc_loss = 0.16026161809448516
Trained batch 831 in epoch 0, gen_loss = 0.8262124307310352, disc_loss = 0.1605367270016219
Trained batch 832 in epoch 0, gen_loss = 0.8263220277582468, disc_loss = 0.16065065463667227
Trained batch 833 in epoch 0, gen_loss = 0.826004306403853, disc_loss = 0.16067527530478132
Trained batch 834 in epoch 0, gen_loss = 0.8257777208339668, disc_loss = 0.16076113398962036
Trained batch 835 in epoch 0, gen_loss = 0.8257462917760229, disc_loss = 0.16078976257681918
Trained batch 836 in epoch 0, gen_loss = 0.8256508923061148, disc_loss = 0.16082804655631738
Trained batch 837 in epoch 0, gen_loss = 0.8254525172824222, disc_loss = 0.16080166397033913
Trained batch 838 in epoch 0, gen_loss = 0.8252838361249066, disc_loss = 0.16081487758837737
Trained batch 839 in epoch 0, gen_loss = 0.825314375048592, disc_loss = 0.16083767707903115
Trained batch 840 in epoch 0, gen_loss = 0.8252649448289315, disc_loss = 0.16081881502977663
Trained batch 841 in epoch 0, gen_loss = 0.8250876242502851, disc_loss = 0.16085049534114765
Trained batch 842 in epoch 0, gen_loss = 0.824990865952321, disc_loss = 0.16083257262012784
Trained batch 843 in epoch 0, gen_loss = 0.824985160152494, disc_loss = 0.16076491278115113
Trained batch 844 in epoch 0, gen_loss = 0.8247485654593925, disc_loss = 0.16068867788203722
Trained batch 845 in epoch 0, gen_loss = 0.8246346977021959, disc_loss = 0.1605821397203961
Trained batch 846 in epoch 0, gen_loss = 0.8246471639788558, disc_loss = 0.16053094173239493
Trained batch 847 in epoch 0, gen_loss = 0.8248087552920828, disc_loss = 0.16040691984422012
Trained batch 848 in epoch 0, gen_loss = 0.8249896067612584, disc_loss = 0.16024416454083718
Trained batch 849 in epoch 0, gen_loss = 0.8247212525676278, disc_loss = 0.16011838915812618
Trained batch 850 in epoch 0, gen_loss = 0.824879189145551, disc_loss = 0.15999400626417123
Trained batch 851 in epoch 0, gen_loss = 0.8245805514530397, disc_loss = 0.1600373914495915
Trained batch 852 in epoch 0, gen_loss = 0.8247833506303544, disc_loss = 0.16027556924238923
Trained batch 853 in epoch 0, gen_loss = 0.8244974855377188, disc_loss = 0.16032448412950828
Trained batch 854 in epoch 0, gen_loss = 0.8242458333746034, disc_loss = 0.16035931861757882
Trained batch 855 in epoch 0, gen_loss = 0.8245168389561021, disc_loss = 0.16031987390863908
Trained batch 856 in epoch 0, gen_loss = 0.8243947794167553, disc_loss = 0.16044641455881029
Trained batch 857 in epoch 0, gen_loss = 0.8238035771813426, disc_loss = 0.16063429543961247
Trained batch 858 in epoch 0, gen_loss = 0.8234425644380527, disc_loss = 0.16064237001134088
Trained batch 859 in epoch 0, gen_loss = 0.8232428779435712, disc_loss = 0.1606310026611873
Trained batch 860 in epoch 0, gen_loss = 0.8233713141440238, disc_loss = 0.160588953901476
Trained batch 861 in epoch 0, gen_loss = 0.8233540613385751, disc_loss = 0.16057294005800357
Trained batch 862 in epoch 0, gen_loss = 0.8232546032234802, disc_loss = 0.16050265983463646
Trained batch 863 in epoch 0, gen_loss = 0.8230585332407996, disc_loss = 0.1605895882562941
Trained batch 864 in epoch 0, gen_loss = 0.8230579027550758, disc_loss = 0.1606191556599271
Trained batch 865 in epoch 0, gen_loss = 0.8227684350542328, disc_loss = 0.16061759291229635
Trained batch 866 in epoch 0, gen_loss = 0.8227504882295514, disc_loss = 0.16061242277311824
Trained batch 867 in epoch 0, gen_loss = 0.8227982133077586, disc_loss = 0.1607003961174753
Trained batch 868 in epoch 0, gen_loss = 0.8226765510813688, disc_loss = 0.1606211348857958
Trained batch 869 in epoch 0, gen_loss = 0.8227521744952805, disc_loss = 0.160480600837404
Trained batch 870 in epoch 0, gen_loss = 0.8227313676192484, disc_loss = 0.16038592508967311
Trained batch 871 in epoch 0, gen_loss = 0.8227848446833979, disc_loss = 0.16025411746242518
Trained batch 872 in epoch 0, gen_loss = 0.8228015732382854, disc_loss = 0.16010232726144014
Trained batch 873 in epoch 0, gen_loss = 0.8227548747231813, disc_loss = 0.15997737791662017
Trained batch 874 in epoch 0, gen_loss = 0.8226256608963013, disc_loss = 0.15991407668377672
Trained batch 875 in epoch 0, gen_loss = 0.8225279384415988, disc_loss = 0.15987904961582391
Trained batch 876 in epoch 0, gen_loss = 0.8228906940163337, disc_loss = 0.16001100764910403
Trained batch 877 in epoch 0, gen_loss = 0.8227333966854764, disc_loss = 0.1599439730367078
Trained batch 878 in epoch 0, gen_loss = 0.8225043606568251, disc_loss = 0.1600101967580591
Trained batch 879 in epoch 0, gen_loss = 0.8224941436539996, disc_loss = 0.1599505792943422
Trained batch 880 in epoch 0, gen_loss = 0.8223421330755063, disc_loss = 0.15997696871510902
Trained batch 881 in epoch 0, gen_loss = 0.8222017938993416, disc_loss = 0.15993655771819576
Trained batch 882 in epoch 0, gen_loss = 0.82224656508166, disc_loss = 0.1598594495973899
Trained batch 883 in epoch 0, gen_loss = 0.8220888239361043, disc_loss = 0.15987026008537114
Trained batch 884 in epoch 0, gen_loss = 0.8221201818541618, disc_loss = 0.15987761224183322
Trained batch 885 in epoch 0, gen_loss = 0.8217869942532705, disc_loss = 0.15989661235025923
Trained batch 886 in epoch 0, gen_loss = 0.8217212057839386, disc_loss = 0.15985158883589567
Trained batch 887 in epoch 0, gen_loss = 0.8217011739139084, disc_loss = 0.1597848655886713
Trained batch 888 in epoch 0, gen_loss = 0.821522128662457, disc_loss = 0.1598819465061107
Trained batch 889 in epoch 0, gen_loss = 0.8214991754360413, disc_loss = 0.1598246980814284
Trained batch 890 in epoch 0, gen_loss = 0.8218556496698313, disc_loss = 0.1599146407891972
Trained batch 891 in epoch 0, gen_loss = 0.8216414782364807, disc_loss = 0.159963281839802
Trained batch 892 in epoch 0, gen_loss = 0.8213673766623152, disc_loss = 0.1599605564436847
Trained batch 893 in epoch 0, gen_loss = 0.821174868867968, disc_loss = 0.15990833859574008
Trained batch 894 in epoch 0, gen_loss = 0.8214164328308745, disc_loss = 0.15986673859202996
Trained batch 895 in epoch 0, gen_loss = 0.8213034045350339, disc_loss = 0.15985301762910759
Trained batch 896 in epoch 0, gen_loss = 0.8208854377203296, disc_loss = 0.15998473508260655
Trained batch 897 in epoch 0, gen_loss = 0.8208238434685365, disc_loss = 0.15997290738001632
Trained batch 898 in epoch 0, gen_loss = 0.8207167032298045, disc_loss = 0.15996136512810383
Trained batch 899 in epoch 0, gen_loss = 0.8204437613487243, disc_loss = 0.16000100782141088
Trained batch 900 in epoch 0, gen_loss = 0.8204715591953544, disc_loss = 0.15997755888655169
Trained batch 901 in epoch 0, gen_loss = 0.8202524711181742, disc_loss = 0.15991658699841232
Trained batch 902 in epoch 0, gen_loss = 0.8200718029788958, disc_loss = 0.15984849874982207
Trained batch 903 in epoch 0, gen_loss = 0.8200472332207502, disc_loss = 0.15982772417127492
Trained batch 904 in epoch 0, gen_loss = 0.819987027289459, disc_loss = 0.15982999877993903
Trained batch 905 in epoch 0, gen_loss = 0.8198024563442002, disc_loss = 0.15982963832888844
Trained batch 906 in epoch 0, gen_loss = 0.8197961300447205, disc_loss = 0.15979852188735905
Trained batch 907 in epoch 0, gen_loss = 0.8199452550400721, disc_loss = 0.1597149532907827
Trained batch 908 in epoch 0, gen_loss = 0.8199244123218608, disc_loss = 0.1595894815779329
Trained batch 909 in epoch 0, gen_loss = 0.819604794730197, disc_loss = 0.1595792779043972
Trained batch 910 in epoch 0, gen_loss = 0.8195052780251865, disc_loss = 0.1596423588697231
Trained batch 911 in epoch 0, gen_loss = 0.8195458174797526, disc_loss = 0.15960821007549958
Trained batch 912 in epoch 0, gen_loss = 0.8192825083664709, disc_loss = 0.1595749512930918
Trained batch 913 in epoch 0, gen_loss = 0.819580167727606, disc_loss = 0.1596782576573984
Trained batch 914 in epoch 0, gen_loss = 0.819405468109527, disc_loss = 0.15963749311294387
Trained batch 915 in epoch 0, gen_loss = 0.8194566310493187, disc_loss = 0.15959303823450183
Trained batch 916 in epoch 0, gen_loss = 0.8194051967322371, disc_loss = 0.15958020510913695
Trained batch 917 in epoch 0, gen_loss = 0.8194224160481123, disc_loss = 0.1594682986419932
Trained batch 918 in epoch 0, gen_loss = 0.8192304431808397, disc_loss = 0.15952751173215216
Trained batch 919 in epoch 0, gen_loss = 0.819374550814214, disc_loss = 0.15955634060234802
Trained batch 920 in epoch 0, gen_loss = 0.8195198780162327, disc_loss = 0.1594212852988744
Trained batch 921 in epoch 0, gen_loss = 0.8195563620057386, disc_loss = 0.15929232068852786
Trained batch 922 in epoch 0, gen_loss = 0.81929647786904, disc_loss = 0.15936529151853154
Trained batch 923 in epoch 0, gen_loss = 0.8194267967820683, disc_loss = 0.1593409654748872
Trained batch 924 in epoch 0, gen_loss = 0.819563429033434, disc_loss = 0.15925746240929978
Trained batch 925 in epoch 0, gen_loss = 0.8195152501565591, disc_loss = 0.1591324034623689
Trained batch 926 in epoch 0, gen_loss = 0.8193070098934565, disc_loss = 0.15910237622693454
Trained batch 927 in epoch 0, gen_loss = 0.8193592461275643, disc_loss = 0.15909646302341193
Trained batch 928 in epoch 0, gen_loss = 0.8194727968220049, disc_loss = 0.1589901877388727
Trained batch 929 in epoch 0, gen_loss = 0.8193546014447366, disc_loss = 0.15893901416491116
Trained batch 930 in epoch 0, gen_loss = 0.8198387344977013, disc_loss = 0.15887378200800603
Trained batch 931 in epoch 0, gen_loss = 0.8196723360744157, disc_loss = 0.15892803118776033
Trained batch 932 in epoch 0, gen_loss = 0.8197453779039658, disc_loss = 0.15901511624687034
Trained batch 933 in epoch 0, gen_loss = 0.8198013656016846, disc_loss = 0.15889646308556424
Trained batch 934 in epoch 0, gen_loss = 0.8197717860420758, disc_loss = 0.1588007162618924
Trained batch 935 in epoch 0, gen_loss = 0.8198071129174314, disc_loss = 0.15875079249764162
Trained batch 936 in epoch 0, gen_loss = 0.8196647731446152, disc_loss = 0.1586802633083649
Trained batch 937 in epoch 0, gen_loss = 0.8194910562368852, disc_loss = 0.15865185568685025
Trained batch 938 in epoch 0, gen_loss = 0.8194698344150417, disc_loss = 0.15856543649285557
Trained batch 939 in epoch 0, gen_loss = 0.819680071764804, disc_loss = 0.15846804501885112
Trained batch 940 in epoch 0, gen_loss = 0.8195479522982768, disc_loss = 0.1584185919448274
Trained batch 941 in epoch 0, gen_loss = 0.8191540821469261, disc_loss = 0.15845867770184188
Trained batch 942 in epoch 0, gen_loss = 0.8194056025618334, disc_loss = 0.1584681679582577
Trained batch 943 in epoch 0, gen_loss = 0.8194648476349096, disc_loss = 0.15838152148279408
Trained batch 944 in epoch 0, gen_loss = 0.8194091156676964, disc_loss = 0.15827536072246928
Trained batch 945 in epoch 0, gen_loss = 0.8190811545475845, disc_loss = 0.15838523612536853
Trained batch 946 in epoch 0, gen_loss = 0.8193337876416562, disc_loss = 0.15839258354224084
Trained batch 947 in epoch 0, gen_loss = 0.8192166930638285, disc_loss = 0.15830513622163783
Trained batch 948 in epoch 0, gen_loss = 0.8191869258252537, disc_loss = 0.15817299932908774
Trained batch 949 in epoch 0, gen_loss = 0.8196360899900135, disc_loss = 0.15806237979350907
Trained batch 950 in epoch 0, gen_loss = 0.8200225534875311, disc_loss = 0.15791724623424774
Trained batch 951 in epoch 0, gen_loss = 0.8201909599935308, disc_loss = 0.15778655521258586
Trained batch 952 in epoch 0, gen_loss = 0.8201642017049279, disc_loss = 0.15768015897927604
Trained batch 953 in epoch 0, gen_loss = 0.820137453903942, disc_loss = 0.1575315243679741
Trained batch 954 in epoch 0, gen_loss = 0.8200416767160306, disc_loss = 0.15749899933592498
Trained batch 955 in epoch 0, gen_loss = 0.820097910310434, disc_loss = 0.15741820918458463
Trained batch 956 in epoch 0, gen_loss = 0.8203740772657883, disc_loss = 0.15730809885327282
Trained batch 957 in epoch 0, gen_loss = 0.8201917999721519, disc_loss = 0.15728543185685334
Trained batch 958 in epoch 0, gen_loss = 0.8200191728017129, disc_loss = 0.15728111613475804
Trained batch 959 in epoch 0, gen_loss = 0.8201030898218353, disc_loss = 0.15743640453438273
Trained batch 960 in epoch 0, gen_loss = 0.8199229464322546, disc_loss = 0.15745179170818221
Trained batch 961 in epoch 0, gen_loss = 0.8198751007320975, disc_loss = 0.15744411006856424
Trained batch 962 in epoch 0, gen_loss = 0.8200636293162685, disc_loss = 0.15751585429524645
Trained batch 963 in epoch 0, gen_loss = 0.8199902228176347, disc_loss = 0.15750986170912493
Trained batch 964 in epoch 0, gen_loss = 0.8196172741101814, disc_loss = 0.15765455146103016
Trained batch 965 in epoch 0, gen_loss = 0.8198433919167667, disc_loss = 0.15759249579346513
Trained batch 966 in epoch 0, gen_loss = 0.8197630470947987, disc_loss = 0.15763751547802876
Trained batch 967 in epoch 0, gen_loss = 0.81972791694782, disc_loss = 0.15776818335125578
Trained batch 968 in epoch 0, gen_loss = 0.8195611527891228, disc_loss = 0.15776688383528875
Trained batch 969 in epoch 0, gen_loss = 0.8194585907397811, disc_loss = 0.15772988100526567
Trained batch 970 in epoch 0, gen_loss = 0.819658196334613, disc_loss = 0.15774356909326434
Trained batch 971 in epoch 0, gen_loss = 0.8194076457815896, disc_loss = 0.15785966346178343
Trained batch 972 in epoch 0, gen_loss = 0.8193444094150677, disc_loss = 0.15801932123075224
Trained batch 973 in epoch 0, gen_loss = 0.8191020219171806, disc_loss = 0.15802300433978225
Trained batch 974 in epoch 0, gen_loss = 0.8190089270090446, disc_loss = 0.15800099522830585
Trained batch 975 in epoch 0, gen_loss = 0.8187594050083493, disc_loss = 0.15801880053878137
Trained batch 976 in epoch 0, gen_loss = 0.8186581212581119, disc_loss = 0.15802064219426779
Trained batch 977 in epoch 0, gen_loss = 0.8184995391312796, disc_loss = 0.15800214594073883
Trained batch 978 in epoch 0, gen_loss = 0.8182134066039622, disc_loss = 0.15801036024734424
Trained batch 979 in epoch 0, gen_loss = 0.8183066614124239, disc_loss = 0.15790944935905996
Trained batch 980 in epoch 0, gen_loss = 0.8182126134482121, disc_loss = 0.15789207144926143
Trained batch 981 in epoch 0, gen_loss = 0.818018148271955, disc_loss = 0.15787464688492223
Trained batch 982 in epoch 0, gen_loss = 0.8179636904751902, disc_loss = 0.15785553896968327
Trained batch 983 in epoch 0, gen_loss = 0.8178196833809701, disc_loss = 0.15780369817218706
Trained batch 984 in epoch 0, gen_loss = 0.8177797081204236, disc_loss = 0.15783886423306115
Trained batch 985 in epoch 0, gen_loss = 0.817506586894786, disc_loss = 0.1578880533458888
Trained batch 986 in epoch 0, gen_loss = 0.817006835368629, disc_loss = 0.15801817979833457
Trained batch 987 in epoch 0, gen_loss = 0.8170646192875468, disc_loss = 0.1581301708245718
Trained batch 988 in epoch 0, gen_loss = 0.8168376537437265, disc_loss = 0.15818192336907944
Trained batch 989 in epoch 0, gen_loss = 0.8166548813533301, disc_loss = 0.1582137513284882
Trained batch 990 in epoch 0, gen_loss = 0.8165217972728006, disc_loss = 0.1582260361086017
Trained batch 991 in epoch 0, gen_loss = 0.8164233394387749, disc_loss = 0.1582590690907842
Trained batch 992 in epoch 0, gen_loss = 0.816231882434117, disc_loss = 0.15826708787615146
Trained batch 993 in epoch 0, gen_loss = 0.8161556740222082, disc_loss = 0.15822462086384026
Trained batch 994 in epoch 0, gen_loss = 0.8161553283732141, disc_loss = 0.15821556319580904
Trained batch 995 in epoch 0, gen_loss = 0.8162366480054147, disc_loss = 0.15808373022203645
Trained batch 996 in epoch 0, gen_loss = 0.8163377329064467, disc_loss = 0.15797650149519907
Trained batch 997 in epoch 0, gen_loss = 0.816085688486128, disc_loss = 0.15812564716452288
Trained batch 998 in epoch 0, gen_loss = 0.8163509890660867, disc_loss = 0.15818205483824582
Trained batch 999 in epoch 0, gen_loss = 0.8162509811222554, disc_loss = 0.15818393143080176
Trained batch 1000 in epoch 0, gen_loss = 0.8158837904284646, disc_loss = 0.15832204402765848
Trained batch 1001 in epoch 0, gen_loss = 0.8160678865369446, disc_loss = 0.15830789315151775
Trained batch 1002 in epoch 0, gen_loss = 0.8158488218651218, disc_loss = 0.1583087314365957
Trained batch 1003 in epoch 0, gen_loss = 0.8157656280939798, disc_loss = 0.15831558678514396
Trained batch 1004 in epoch 0, gen_loss = 0.815550932925732, disc_loss = 0.15831042457538755
Trained batch 1005 in epoch 0, gen_loss = 0.8155772678598495, disc_loss = 0.1583201155329408
Trained batch 1006 in epoch 0, gen_loss = 0.8154228318116398, disc_loss = 0.1582952866306697
Trained batch 1007 in epoch 0, gen_loss = 0.8154708377957817, disc_loss = 0.1582425643656669
Trained batch 1008 in epoch 0, gen_loss = 0.8156605105038559, disc_loss = 0.15816144530575563
Trained batch 1009 in epoch 0, gen_loss = 0.8156070546643569, disc_loss = 0.15815688419423185
Trained batch 1010 in epoch 0, gen_loss = 0.8156990706920624, disc_loss = 0.15821875946303326
Trained batch 1011 in epoch 0, gen_loss = 0.8155915472406172, disc_loss = 0.15820698695360377
Trained batch 1012 in epoch 0, gen_loss = 0.8155447456761385, disc_loss = 0.15813207601152016
Trained batch 1013 in epoch 0, gen_loss = 0.8155235706055188, disc_loss = 0.15812225798347
Trained batch 1014 in epoch 0, gen_loss = 0.8153475965478737, disc_loss = 0.1581469420710661
Trained batch 1015 in epoch 0, gen_loss = 0.8151085629883245, disc_loss = 0.1581385070513054
Trained batch 1016 in epoch 0, gen_loss = 0.8151127722117988, disc_loss = 0.15812447784155342
Trained batch 1017 in epoch 0, gen_loss = 0.8149884815944436, disc_loss = 0.15805020702779585
Trained batch 1018 in epoch 0, gen_loss = 0.8150318137738375, disc_loss = 0.15796560500734746
Trained batch 1019 in epoch 0, gen_loss = 0.8148984445952902, disc_loss = 0.15799770563950433
Trained batch 1020 in epoch 0, gen_loss = 0.8149223355366597, disc_loss = 0.15795859836596524
Trained batch 1021 in epoch 0, gen_loss = 0.8148970538914321, disc_loss = 0.15788766592850365
Trained batch 1022 in epoch 0, gen_loss = 0.8147563886840555, disc_loss = 0.15789419107998512
Trained batch 1023 in epoch 0, gen_loss = 0.814695220644353, disc_loss = 0.15784415866619383
Trained batch 1024 in epoch 0, gen_loss = 0.8146849971573528, disc_loss = 0.15778773410109484
Trained batch 1025 in epoch 0, gen_loss = 0.8146963805889758, disc_loss = 0.15767320919215505
Trained batch 1026 in epoch 0, gen_loss = 0.8144591930372225, disc_loss = 0.15766565250495798
Trained batch 1027 in epoch 0, gen_loss = 0.8146303201869768, disc_loss = 0.15769507327019183
Trained batch 1028 in epoch 0, gen_loss = 0.8146106561082909, disc_loss = 0.15757653699505375
Trained batch 1029 in epoch 0, gen_loss = 0.8145781627268467, disc_loss = 0.1575027481752258
Trained batch 1030 in epoch 0, gen_loss = 0.8146568979890918, disc_loss = 0.15742088550978153
Trained batch 1031 in epoch 0, gen_loss = 0.8148173392685347, disc_loss = 0.15751858314232137
Trained batch 1032 in epoch 0, gen_loss = 0.8146322178298252, disc_loss = 0.1575090960335322
Trained batch 1033 in epoch 0, gen_loss = 0.8145367110893851, disc_loss = 0.15748323317314544
Trained batch 1034 in epoch 0, gen_loss = 0.8147169330557763, disc_loss = 0.15774852793465777
Trained batch 1035 in epoch 0, gen_loss = 0.8147595420940043, disc_loss = 0.15767233045124468
Trained batch 1036 in epoch 0, gen_loss = 0.8144794526359959, disc_loss = 0.1577087645378528
Trained batch 1037 in epoch 0, gen_loss = 0.8142607969183453, disc_loss = 0.1576549150713635
Trained batch 1038 in epoch 0, gen_loss = 0.8142465788716875, disc_loss = 0.15765763535428723
Trained batch 1039 in epoch 0, gen_loss = 0.8141782032469145, disc_loss = 0.15758432880796205
Trained batch 1040 in epoch 0, gen_loss = 0.8141903600992776, disc_loss = 0.15756391106382742
Trained batch 1041 in epoch 0, gen_loss = 0.8138589131111376, disc_loss = 0.15751368012064765
Trained batch 1042 in epoch 0, gen_loss = 0.8137662447596099, disc_loss = 0.15746551435101466
Trained batch 1043 in epoch 0, gen_loss = 0.8140950911175245, disc_loss = 0.15742207103912
Trained batch 1044 in epoch 0, gen_loss = 0.8139324810231131, disc_loss = 0.15741982760362364
Trained batch 1045 in epoch 0, gen_loss = 0.813698113164072, disc_loss = 0.1575712792194283
Trained batch 1046 in epoch 0, gen_loss = 0.8137724910504269, disc_loss = 0.1576015124010294
Trained batch 1047 in epoch 0, gen_loss = 0.8136838616817507, disc_loss = 0.1576534537616264
Trained batch 1048 in epoch 0, gen_loss = 0.8133203339247163, disc_loss = 0.1577257906149778
Trained batch 1049 in epoch 0, gen_loss = 0.8131712559575126, disc_loss = 0.15773356569132635
Trained batch 1050 in epoch 0, gen_loss = 0.8132182500625541, disc_loss = 0.15770603452129495
Trained batch 1051 in epoch 0, gen_loss = 0.8132111081435653, disc_loss = 0.15764299176895402
Trained batch 1052 in epoch 0, gen_loss = 0.8131921388994255, disc_loss = 0.1575832739207055
Trained batch 1053 in epoch 0, gen_loss = 0.8131480456473027, disc_loss = 0.1576254239546195
Trained batch 1054 in epoch 0, gen_loss = 0.8130953074349047, disc_loss = 0.15755166112846955
Trained batch 1055 in epoch 0, gen_loss = 0.8129921479037765, disc_loss = 0.15757139760358824
Trained batch 1056 in epoch 0, gen_loss = 0.813097723187877, disc_loss = 0.1575464557031612
Trained batch 1057 in epoch 0, gen_loss = 0.8133545428063784, disc_loss = 0.15743865759159476
Trained batch 1058 in epoch 0, gen_loss = 0.8131360279658248, disc_loss = 0.15741658907795256
Trained batch 1059 in epoch 0, gen_loss = 0.8130436322880241, disc_loss = 0.15737220926632015
Trained batch 1060 in epoch 0, gen_loss = 0.8130501874149352, disc_loss = 0.1573514974922728
Trained batch 1061 in epoch 0, gen_loss = 0.812890301793533, disc_loss = 0.1572802806792258
Trained batch 1062 in epoch 0, gen_loss = 0.8125935614333327, disc_loss = 0.15733632365257416
Trained batch 1063 in epoch 0, gen_loss = 0.8126508733327675, disc_loss = 0.15737131718175024
Trained batch 1064 in epoch 0, gen_loss = 0.8126713283464942, disc_loss = 0.15731738834978548
Trained batch 1065 in epoch 0, gen_loss = 0.8125575726352087, disc_loss = 0.15733827011551407
Trained batch 1066 in epoch 0, gen_loss = 0.8123644492340177, disc_loss = 0.1574195834119379
Trained batch 1067 in epoch 0, gen_loss = 0.8121503957927451, disc_loss = 0.15739865049768645
Trained batch 1068 in epoch 0, gen_loss = 0.8119452337832848, disc_loss = 0.15736842505159893
Trained batch 1069 in epoch 0, gen_loss = 0.8120033249955311, disc_loss = 0.15740135193532595
Trained batch 1070 in epoch 0, gen_loss = 0.8118281713108612, disc_loss = 0.15741192036587484
Trained batch 1071 in epoch 0, gen_loss = 0.8116629643282339, disc_loss = 0.15735049423268205
Trained batch 1072 in epoch 0, gen_loss = 0.8119096488510462, disc_loss = 0.15723191341081458
Trained batch 1073 in epoch 0, gen_loss = 0.8122810883728485, disc_loss = 0.15712681415992022
Trained batch 1074 in epoch 0, gen_loss = 0.81222322721814, disc_loss = 0.15706132898323757
Trained batch 1075 in epoch 0, gen_loss = 0.8121543251061085, disc_loss = 0.15698071179883796
Trained batch 1076 in epoch 0, gen_loss = 0.812062343542733, disc_loss = 0.156886490566886
Trained batch 1077 in epoch 0, gen_loss = 0.8119774569441083, disc_loss = 0.15689122225011048
Trained batch 1078 in epoch 0, gen_loss = 0.8119637553232262, disc_loss = 0.15681868211726163
Trained batch 1079 in epoch 0, gen_loss = 0.8119700390155669, disc_loss = 0.15690899011334059
Trained batch 1080 in epoch 0, gen_loss = 0.8118896168707478, disc_loss = 0.15684913329187364
Trained batch 1081 in epoch 0, gen_loss = 0.8118958276267854, disc_loss = 0.15681792640896744
Trained batch 1082 in epoch 0, gen_loss = 0.8121909288653376, disc_loss = 0.15682071856879187
Trained batch 1083 in epoch 0, gen_loss = 0.8118625302761243, disc_loss = 0.15687577546886908
Trained batch 1084 in epoch 0, gen_loss = 0.8118742324514873, disc_loss = 0.15679844798614628
Trained batch 1085 in epoch 0, gen_loss = 0.8121780878546927, disc_loss = 0.15677427475273772
Trained batch 1086 in epoch 0, gen_loss = 0.8121595150468102, disc_loss = 0.15685061598582178
Trained batch 1087 in epoch 0, gen_loss = 0.8122135785627452, disc_loss = 0.15679885636884994
Trained batch 1088 in epoch 0, gen_loss = 0.8121972677628856, disc_loss = 0.15684799332243515
Trained batch 1089 in epoch 0, gen_loss = 0.8121899176901634, disc_loss = 0.15693029278222848
Trained batch 1090 in epoch 0, gen_loss = 0.8122764255178838, disc_loss = 0.15699006828260084
Trained batch 1091 in epoch 0, gen_loss = 0.8120603085164622, disc_loss = 0.1570076501361971
Trained batch 1092 in epoch 0, gen_loss = 0.8121713594297477, disc_loss = 0.15698797877601878
Trained batch 1093 in epoch 0, gen_loss = 0.8119597948501925, disc_loss = 0.15707247109889602
Trained batch 1094 in epoch 0, gen_loss = 0.8122557983278684, disc_loss = 0.15718609950075682
Trained batch 1095 in epoch 0, gen_loss = 0.8121670493516173, disc_loss = 0.15713617230262472
Trained batch 1096 in epoch 0, gen_loss = 0.8121648124650922, disc_loss = 0.1571443090563404
Trained batch 1097 in epoch 0, gen_loss = 0.812042620528374, disc_loss = 0.1571136381636579
Trained batch 1098 in epoch 0, gen_loss = 0.8121138303739792, disc_loss = 0.15705312173084793
Trained batch 1099 in epoch 0, gen_loss = 0.8119499209523201, disc_loss = 0.15707165234637532
Trained batch 1100 in epoch 0, gen_loss = 0.8116922813529431, disc_loss = 0.15705430151879463
Trained batch 1101 in epoch 0, gen_loss = 0.8114800974321019, disc_loss = 0.15706171075257383
Trained batch 1102 in epoch 0, gen_loss = 0.8115196951334842, disc_loss = 0.15707207965079428
Trained batch 1103 in epoch 0, gen_loss = 0.8113897201753613, disc_loss = 0.15705603341052335
Trained batch 1104 in epoch 0, gen_loss = 0.8112837147119358, disc_loss = 0.15702565119041306
Trained batch 1105 in epoch 0, gen_loss = 0.811226860443248, disc_loss = 0.15698283786294312
Trained batch 1106 in epoch 0, gen_loss = 0.8111778562577221, disc_loss = 0.1569708558228523
Trained batch 1107 in epoch 0, gen_loss = 0.8110756499403651, disc_loss = 0.15690962017584417
Trained batch 1108 in epoch 0, gen_loss = 0.8110232175041471, disc_loss = 0.1568762580230093
Trained batch 1109 in epoch 0, gen_loss = 0.8110506418857488, disc_loss = 0.15680443133219138
Trained batch 1110 in epoch 0, gen_loss = 0.8110378633255791, disc_loss = 0.15675863348162195
Trained batch 1111 in epoch 0, gen_loss = 0.8109761436583756, disc_loss = 0.15670513473752645
Trained batch 1112 in epoch 0, gen_loss = 0.811113902099049, disc_loss = 0.1567007205854877
Trained batch 1113 in epoch 0, gen_loss = 0.8107814371746361, disc_loss = 0.1567091773108611
Trained batch 1114 in epoch 0, gen_loss = 0.8104919567236452, disc_loss = 0.15684817944707624
Trained batch 1115 in epoch 0, gen_loss = 0.8106628743978385, disc_loss = 0.1570412311586134
Trained batch 1116 in epoch 0, gen_loss = 0.8103196945378262, disc_loss = 0.15706434301138192
Trained batch 1117 in epoch 0, gen_loss = 0.810010988725106, disc_loss = 0.15709404914751515
Trained batch 1118 in epoch 0, gen_loss = 0.8101271738741843, disc_loss = 0.15719174053203697
Trained batch 1119 in epoch 0, gen_loss = 0.8100483775138855, disc_loss = 0.1571661340421997
Trained batch 1120 in epoch 0, gen_loss = 0.8098463396958003, disc_loss = 0.1572405142488621
Trained batch 1121 in epoch 0, gen_loss = 0.809611375690994, disc_loss = 0.15731802620757337
Trained batch 1122 in epoch 0, gen_loss = 0.8095165890768395, disc_loss = 0.15737388464966365
Trained batch 1123 in epoch 0, gen_loss = 0.8094024592447111, disc_loss = 0.15736952902139348
Trained batch 1124 in epoch 0, gen_loss = 0.8093154119385614, disc_loss = 0.1573455623206165
Trained batch 1125 in epoch 0, gen_loss = 0.809215804982143, disc_loss = 0.15729858986470935
Trained batch 1126 in epoch 0, gen_loss = 0.8091157979952517, disc_loss = 0.15726012365847905
Trained batch 1127 in epoch 0, gen_loss = 0.8091893488316672, disc_loss = 0.15723050905702016
Trained batch 1128 in epoch 0, gen_loss = 0.809161550814964, disc_loss = 0.1572548142255699
Trained batch 1129 in epoch 0, gen_loss = 0.8089186207910555, disc_loss = 0.1573456238015695
Trained batch 1130 in epoch 0, gen_loss = 0.8089763223861405, disc_loss = 0.15732784256516938
Trained batch 1131 in epoch 0, gen_loss = 0.8090302407109695, disc_loss = 0.15735954322190726
Trained batch 1132 in epoch 0, gen_loss = 0.8088757491490531, disc_loss = 0.15735805587841417
Trained batch 1133 in epoch 0, gen_loss = 0.8086763434309178, disc_loss = 0.15736570102335126
Trained batch 1134 in epoch 0, gen_loss = 0.8086249276930015, disc_loss = 0.15736348845130285
Trained batch 1135 in epoch 0, gen_loss = 0.808565525416757, disc_loss = 0.15733041411141116
Trained batch 1136 in epoch 0, gen_loss = 0.8085951582842368, disc_loss = 0.15734636192697385
Trained batch 1137 in epoch 0, gen_loss = 0.8084484479129839, disc_loss = 0.1573631850550825
Trained batch 1138 in epoch 0, gen_loss = 0.8082443733190213, disc_loss = 0.15741906395710226
Trained batch 1139 in epoch 0, gen_loss = 0.8082204235750332, disc_loss = 0.15736143374815584
Trained batch 1140 in epoch 0, gen_loss = 0.8083361016878634, disc_loss = 0.15738754840461597
Trained batch 1141 in epoch 0, gen_loss = 0.8081767762083097, disc_loss = 0.15738146726185565
Trained batch 1142 in epoch 0, gen_loss = 0.8080539301311563, disc_loss = 0.15737988213965326
Trained batch 1143 in epoch 0, gen_loss = 0.8081275627954857, disc_loss = 0.1572738692662646
Trained batch 1144 in epoch 0, gen_loss = 0.808304620413801, disc_loss = 0.1572244585162297
Trained batch 1145 in epoch 0, gen_loss = 0.8080369833772303, disc_loss = 0.15722922405575843
Trained batch 1146 in epoch 0, gen_loss = 0.8078643018615277, disc_loss = 0.15726447420612094
Trained batch 1147 in epoch 0, gen_loss = 0.8076398867970975, disc_loss = 0.15732111760580633
Trained batch 1148 in epoch 0, gen_loss = 0.8076554560682067, disc_loss = 0.15738545100912257
Trained batch 1149 in epoch 0, gen_loss = 0.807560513123222, disc_loss = 0.1574374721053502
Trained batch 1150 in epoch 0, gen_loss = 0.8075842304813872, disc_loss = 0.15735671806637097
Trained batch 1151 in epoch 0, gen_loss = 0.8073561233985755, disc_loss = 0.1573434572282066
Trained batch 1152 in epoch 0, gen_loss = 0.8072506946165047, disc_loss = 0.15730334536785523
Trained batch 1153 in epoch 0, gen_loss = 0.8073674008585965, disc_loss = 0.15728742264023945
Trained batch 1154 in epoch 0, gen_loss = 0.8073517807634362, disc_loss = 0.15724590203494995
Trained batch 1155 in epoch 0, gen_loss = 0.8072785942921589, disc_loss = 0.15728832338694934
Trained batch 1156 in epoch 0, gen_loss = 0.8071111212440266, disc_loss = 0.157275114445114
Trained batch 1157 in epoch 0, gen_loss = 0.8069715652235225, disc_loss = 0.1573267026863902
Trained batch 1158 in epoch 0, gen_loss = 0.8072297501090892, disc_loss = 0.1573592305160911
Trained batch 1159 in epoch 0, gen_loss = 0.8072054997086525, disc_loss = 0.15732748577339126
Trained batch 1160 in epoch 0, gen_loss = 0.807125866926507, disc_loss = 0.15731187894600254
Trained batch 1161 in epoch 0, gen_loss = 0.8069813949105662, disc_loss = 0.15731891151838223
Trained batch 1162 in epoch 0, gen_loss = 0.8070499231768188, disc_loss = 0.15722801735719164
Trained batch 1163 in epoch 0, gen_loss = 0.8067912333404895, disc_loss = 0.15731827907193824
Trained batch 1164 in epoch 0, gen_loss = 0.8066729638709531, disc_loss = 0.1572505891594892
Trained batch 1165 in epoch 0, gen_loss = 0.8068866299315137, disc_loss = 0.1572222294777913
Trained batch 1166 in epoch 0, gen_loss = 0.8069166144246, disc_loss = 0.15713040576808812
Trained batch 1167 in epoch 0, gen_loss = 0.8067938002617392, disc_loss = 0.15705520063415424
Trained batch 1168 in epoch 0, gen_loss = 0.8066693055415581, disc_loss = 0.1570138783489694
Trained batch 1169 in epoch 0, gen_loss = 0.8069441752046601, disc_loss = 0.1569043047980875
Trained batch 1170 in epoch 0, gen_loss = 0.8071220886697126, disc_loss = 0.15683133473236474
Trained batch 1171 in epoch 0, gen_loss = 0.8069670566011208, disc_loss = 0.15688147514727946
Trained batch 1172 in epoch 0, gen_loss = 0.8068747073284906, disc_loss = 0.1569057007821218
Trained batch 1173 in epoch 0, gen_loss = 0.8071095472300073, disc_loss = 0.15684865043836518
Trained batch 1174 in epoch 0, gen_loss = 0.8070703446611445, disc_loss = 0.15676738862027514
Trained batch 1175 in epoch 0, gen_loss = 0.8068602458149398, disc_loss = 0.15680510995491426
Trained batch 1176 in epoch 0, gen_loss = 0.8068461777704088, disc_loss = 0.15678849552988297
Trained batch 1177 in epoch 0, gen_loss = 0.8070400357246399, disc_loss = 0.15670168676519536
Trained batch 1178 in epoch 0, gen_loss = 0.8068691219587868, disc_loss = 0.15685163190283444
Trained batch 1179 in epoch 0, gen_loss = 0.8070518995240583, disc_loss = 0.1569566389861501
Trained batch 1180 in epoch 0, gen_loss = 0.8070637366713154, disc_loss = 0.15688354648479358
Trained batch 1181 in epoch 0, gen_loss = 0.8069808567336771, disc_loss = 0.15681759338327975
Trained batch 1182 in epoch 0, gen_loss = 0.806888203497973, disc_loss = 0.15682072691550117
Trained batch 1183 in epoch 0, gen_loss = 0.8068062867969275, disc_loss = 0.15677914977690355
Trained batch 1184 in epoch 0, gen_loss = 0.8067339118522934, disc_loss = 0.15675227582014561
Trained batch 1185 in epoch 0, gen_loss = 0.8066894623119554, disc_loss = 0.1567001708800485
Trained batch 1186 in epoch 0, gen_loss = 0.8067284982146189, disc_loss = 0.15667357043109728
Trained batch 1187 in epoch 0, gen_loss = 0.8064812491036425, disc_loss = 0.15664894906772608
Trained batch 1188 in epoch 0, gen_loss = 0.8065387173998346, disc_loss = 0.15655454399833366
Trained batch 1189 in epoch 0, gen_loss = 0.8063820852451966, disc_loss = 0.15652326370487693
Trained batch 1190 in epoch 0, gen_loss = 0.8065091005700862, disc_loss = 0.15646330997235228
Trained batch 1191 in epoch 0, gen_loss = 0.8066740637557619, disc_loss = 0.15637791875887336
Trained batch 1192 in epoch 0, gen_loss = 0.8065153738579026, disc_loss = 0.15638513943338134
Trained batch 1193 in epoch 0, gen_loss = 0.8065883825272572, disc_loss = 0.15635464285224226
Trained batch 1194 in epoch 0, gen_loss = 0.8066978144845205, disc_loss = 0.15632978625065613
Trained batch 1195 in epoch 0, gen_loss = 0.8066337087680664, disc_loss = 0.1562635192248883
Trained batch 1196 in epoch 0, gen_loss = 0.8064378448197915, disc_loss = 0.15627716304602082
Trained batch 1197 in epoch 0, gen_loss = 0.8065639788996994, disc_loss = 0.15634755335922332
Trained batch 1198 in epoch 0, gen_loss = 0.8064847639742446, disc_loss = 0.15636962911640734
Trained batch 1199 in epoch 0, gen_loss = 0.8062253509213527, disc_loss = 0.15647673664925
Trained batch 1200 in epoch 0, gen_loss = 0.8060915711072958, disc_loss = 0.1564994578922073
Trained batch 1201 in epoch 0, gen_loss = 0.8060219286136738, disc_loss = 0.15644815249582397
Trained batch 1202 in epoch 0, gen_loss = 0.8059257341491513, disc_loss = 0.1565001496235381
Trained batch 1203 in epoch 0, gen_loss = 0.805552740528734, disc_loss = 0.1566362195614218
Trained batch 1204 in epoch 0, gen_loss = 0.8056418956068047, disc_loss = 0.15663754778346087
Trained batch 1205 in epoch 0, gen_loss = 0.8057401135786256, disc_loss = 0.1566388270358986
Trained batch 1206 in epoch 0, gen_loss = 0.8055162018947396, disc_loss = 0.1566465590751013
Trained batch 1207 in epoch 0, gen_loss = 0.8053122805246454, disc_loss = 0.15679082275978876
Trained batch 1208 in epoch 0, gen_loss = 0.805303754838071, disc_loss = 0.15691204608485065
Trained batch 1209 in epoch 0, gen_loss = 0.8051344540493548, disc_loss = 0.15689299408623503
Trained batch 1210 in epoch 0, gen_loss = 0.8051888041019833, disc_loss = 0.15683993264343699
Trained batch 1211 in epoch 0, gen_loss = 0.8052024441485358, disc_loss = 0.15680774663061692
Trained batch 1212 in epoch 0, gen_loss = 0.8049492013424955, disc_loss = 0.15693125839100233
Trained batch 1213 in epoch 0, gen_loss = 0.8048927046518153, disc_loss = 0.15695072219843625
Trained batch 1214 in epoch 0, gen_loss = 0.8050295822904925, disc_loss = 0.15700153387439103
Trained batch 1215 in epoch 0, gen_loss = 0.8048904473942361, disc_loss = 0.15697458689407395
Trained batch 1216 in epoch 0, gen_loss = 0.8046769166737182, disc_loss = 0.15701367800034455
Trained batch 1217 in epoch 0, gen_loss = 0.8045750799633208, disc_loss = 0.15705842829702424
Trained batch 1218 in epoch 0, gen_loss = 0.8045186351028204, disc_loss = 0.15700015171726675
Trained batch 1219 in epoch 0, gen_loss = 0.8044357270490928, disc_loss = 0.15696331000902125
Trained batch 1220 in epoch 0, gen_loss = 0.8044656694765271, disc_loss = 0.15689712663064426
Trained batch 1221 in epoch 0, gen_loss = 0.8043846392885168, disc_loss = 0.15686345193382664
Trained batch 1222 in epoch 0, gen_loss = 0.8043251766694538, disc_loss = 0.15683928164040467
Trained batch 1223 in epoch 0, gen_loss = 0.8041747358499789, disc_loss = 0.1568099502504505
Trained batch 1224 in epoch 0, gen_loss = 0.8040387786164576, disc_loss = 0.15680076362223042
Trained batch 1225 in epoch 0, gen_loss = 0.804140364657024, disc_loss = 0.15676885213380828
Trained batch 1226 in epoch 0, gen_loss = 0.8040306078484123, disc_loss = 0.15676541883610765
Trained batch 1227 in epoch 0, gen_loss = 0.8040687511235184, disc_loss = 0.1567844041510931
Trained batch 1228 in epoch 0, gen_loss = 0.8041924234810062, disc_loss = 0.15670193919413355
Trained batch 1229 in epoch 0, gen_loss = 0.8043078100293632, disc_loss = 0.15666945198989982
Trained batch 1230 in epoch 0, gen_loss = 0.8042777783981094, disc_loss = 0.1566607792363188
Trained batch 1231 in epoch 0, gen_loss = 0.8043630431321535, disc_loss = 0.15659901227910894
Trained batch 1232 in epoch 0, gen_loss = 0.8044829880524146, disc_loss = 0.15649767608260198
Trained batch 1233 in epoch 0, gen_loss = 0.8044088631143833, disc_loss = 0.15644380399833524
Trained batch 1234 in epoch 0, gen_loss = 0.8045021692750908, disc_loss = 0.1563619445753001
Trained batch 1235 in epoch 0, gen_loss = 0.8047336122461122, disc_loss = 0.15632850028767362
Trained batch 1236 in epoch 0, gen_loss = 0.8046671885006256, disc_loss = 0.15634614276784797
Trained batch 1237 in epoch 0, gen_loss = 0.8046904877911477, disc_loss = 0.15633247524909133
Trained batch 1238 in epoch 0, gen_loss = 0.804561519978795, disc_loss = 0.15633720342938798
Trained batch 1239 in epoch 0, gen_loss = 0.8045238429500211, disc_loss = 0.15629966137029472
Trained batch 1240 in epoch 0, gen_loss = 0.8046827894559702, disc_loss = 0.15623943882301677
Trained batch 1241 in epoch 0, gen_loss = 0.8045547882907824, disc_loss = 0.15622869834615796
Trained batch 1242 in epoch 0, gen_loss = 0.8045994217416882, disc_loss = 0.15626792139759585
Trained batch 1243 in epoch 0, gen_loss = 0.8044670259166761, disc_loss = 0.15622932711238838
Trained batch 1244 in epoch 0, gen_loss = 0.8044110605036877, disc_loss = 0.1561971759640548
Trained batch 1245 in epoch 0, gen_loss = 0.8043466488297066, disc_loss = 0.15613458460468924
Trained batch 1246 in epoch 0, gen_loss = 0.8042145364745292, disc_loss = 0.15607510418082202
Trained batch 1247 in epoch 0, gen_loss = 0.804177190296543, disc_loss = 0.15609640227511334
Trained batch 1248 in epoch 0, gen_loss = 0.8040558604167116, disc_loss = 0.15608532028235464
Trained batch 1249 in epoch 0, gen_loss = 0.8043821338176728, disc_loss = 0.15636242260336877
Trained batch 1250 in epoch 0, gen_loss = 0.8042588807124313, disc_loss = 0.1564804641879815
Trained batch 1251 in epoch 0, gen_loss = 0.8042542164603742, disc_loss = 0.1564338010863755
Trained batch 1252 in epoch 0, gen_loss = 0.8040607050239612, disc_loss = 0.15643439302183776
Trained batch 1253 in epoch 0, gen_loss = 0.8041825315883856, disc_loss = 0.1565208334885716
Trained batch 1254 in epoch 0, gen_loss = 0.804033737306101, disc_loss = 0.15649392057462516
Trained batch 1255 in epoch 0, gen_loss = 0.8038971634332541, disc_loss = 0.15645631380189376
Trained batch 1256 in epoch 0, gen_loss = 0.8038146145872967, disc_loss = 0.1564805427049016
Trained batch 1257 in epoch 0, gen_loss = 0.8036068970239788, disc_loss = 0.15649030895367716
Trained batch 1258 in epoch 0, gen_loss = 0.8036164630018027, disc_loss = 0.15647667470055976
Trained batch 1259 in epoch 0, gen_loss = 0.8035754857555268, disc_loss = 0.1564461958195482
Trained batch 1260 in epoch 0, gen_loss = 0.8035151436629511, disc_loss = 0.15646736957221444
Trained batch 1261 in epoch 0, gen_loss = 0.8033392787829821, disc_loss = 0.15649069177367608
Trained batch 1262 in epoch 0, gen_loss = 0.8030812618804185, disc_loss = 0.15650740343714553
Trained batch 1263 in epoch 0, gen_loss = 0.8029321838830468, disc_loss = 0.15649954506632272
Trained batch 1264 in epoch 0, gen_loss = 0.8028391789777477, disc_loss = 0.1564826904549429
Trained batch 1265 in epoch 0, gen_loss = 0.8026307274897894, disc_loss = 0.1564690224696863
Trained batch 1266 in epoch 0, gen_loss = 0.8025284310966001, disc_loss = 0.1564134623393734
Trained batch 1267 in epoch 0, gen_loss = 0.8024348135955326, disc_loss = 0.15641156491185965
Trained batch 1268 in epoch 0, gen_loss = 0.8024233203172871, disc_loss = 0.15636917476089476
Trained batch 1269 in epoch 0, gen_loss = 0.8023334713667396, disc_loss = 0.1563126107428487
Trained batch 1270 in epoch 0, gen_loss = 0.8022788299011677, disc_loss = 0.15628827416010488
Trained batch 1271 in epoch 0, gen_loss = 0.802211409399532, disc_loss = 0.15626600207233765
Trained batch 1272 in epoch 0, gen_loss = 0.8019879474147323, disc_loss = 0.15628750462491775
Trained batch 1273 in epoch 0, gen_loss = 0.8020764443105206, disc_loss = 0.1563940648533392
Trained batch 1274 in epoch 0, gen_loss = 0.8020001271892997, disc_loss = 0.15634762046968237
Trained batch 1275 in epoch 0, gen_loss = 0.8019417967402076, disc_loss = 0.15634535926286142
Trained batch 1276 in epoch 0, gen_loss = 0.8020067402368051, disc_loss = 0.15635408929599479
Trained batch 1277 in epoch 0, gen_loss = 0.8018793911674587, disc_loss = 0.15630497718710853
Trained batch 1278 in epoch 0, gen_loss = 0.8019062018981662, disc_loss = 0.1563345253688922
Trained batch 1279 in epoch 0, gen_loss = 0.8018873267574236, disc_loss = 0.1563444059516769
Trained batch 1280 in epoch 0, gen_loss = 0.8019644973754511, disc_loss = 0.1563306421704538
Trained batch 1281 in epoch 0, gen_loss = 0.8020068186912075, disc_loss = 0.15627946921401947
Trained batch 1282 in epoch 0, gen_loss = 0.801976233627865, disc_loss = 0.1562078913800064
Trained batch 1283 in epoch 0, gen_loss = 0.8018983397574811, disc_loss = 0.15616703175031507
Trained batch 1284 in epoch 0, gen_loss = 0.8020569576131694, disc_loss = 0.15615453197102602
Trained batch 1285 in epoch 0, gen_loss = 0.8020682695262354, disc_loss = 0.15605668620746668
Trained batch 1286 in epoch 0, gen_loss = 0.8019083935388226, disc_loss = 0.15609240835560045
Trained batch 1287 in epoch 0, gen_loss = 0.8019642781535661, disc_loss = 0.15604143209975235
Trained batch 1288 in epoch 0, gen_loss = 0.8019849834884203, disc_loss = 0.15598116883584656
Trained batch 1289 in epoch 0, gen_loss = 0.8018391451401304, disc_loss = 0.1559933275013238
Trained batch 1290 in epoch 0, gen_loss = 0.8019778281796541, disc_loss = 0.1560029701916263
Trained batch 1291 in epoch 0, gen_loss = 0.8018807332166946, disc_loss = 0.15601012333593225
Trained batch 1292 in epoch 0, gen_loss = 0.8019316475564716, disc_loss = 0.15594528525871817
Trained batch 1293 in epoch 0, gen_loss = 0.8018913945007545, disc_loss = 0.15589806908767503
Trained batch 1294 in epoch 0, gen_loss = 0.8020216613892883, disc_loss = 0.1558824887750922
Trained batch 1295 in epoch 0, gen_loss = 0.8019414144211713, disc_loss = 0.1557937837522017
Trained batch 1296 in epoch 0, gen_loss = 0.8018066565302949, disc_loss = 0.15572464283707974
Trained batch 1297 in epoch 0, gen_loss = 0.8016514353603355, disc_loss = 0.15570707759534358
Trained batch 1298 in epoch 0, gen_loss = 0.8019151841566322, disc_loss = 0.1556940002824317
Trained batch 1299 in epoch 0, gen_loss = 0.8020218339103918, disc_loss = 0.15562807668000458
Trained batch 1300 in epoch 0, gen_loss = 0.8021449220583678, disc_loss = 0.1555505203831938
Trained batch 1301 in epoch 0, gen_loss = 0.8020973543188722, disc_loss = 0.15546914904210973
Trained batch 1302 in epoch 0, gen_loss = 0.8020778849366438, disc_loss = 0.15539599384423503
Trained batch 1303 in epoch 0, gen_loss = 0.8021554871707972, disc_loss = 0.15542387524676834
Trained batch 1304 in epoch 0, gen_loss = 0.801996872320029, disc_loss = 0.15539107519091316
Trained batch 1305 in epoch 0, gen_loss = 0.8021370803004567, disc_loss = 0.15540847304358416
Trained batch 1306 in epoch 0, gen_loss = 0.8020680514153581, disc_loss = 0.15541965715649844
Trained batch 1307 in epoch 0, gen_loss = 0.80215049931489, disc_loss = 0.15533886706336922
Trained batch 1308 in epoch 0, gen_loss = 0.8023330401472685, disc_loss = 0.1553612993339986
Trained batch 1309 in epoch 0, gen_loss = 0.8021454236662114, disc_loss = 0.15539913018241183
Trained batch 1310 in epoch 0, gen_loss = 0.8021409589538676, disc_loss = 0.1553814696342685
Trained batch 1311 in epoch 0, gen_loss = 0.8020102276989236, disc_loss = 0.15538615559613922
Trained batch 1312 in epoch 0, gen_loss = 0.8019081372526522, disc_loss = 0.15538325572140962
Trained batch 1313 in epoch 0, gen_loss = 0.8019271927745375, disc_loss = 0.1553295950208262
Trained batch 1314 in epoch 0, gen_loss = 0.8019029888136758, disc_loss = 0.15526005442151553
Trained batch 1315 in epoch 0, gen_loss = 0.8019425504158696, disc_loss = 0.15524495557222323
Trained batch 1316 in epoch 0, gen_loss = 0.8020151024210517, disc_loss = 0.15517462434737903
Trained batch 1317 in epoch 0, gen_loss = 0.8018900958965327, disc_loss = 0.15512095339743248
Trained batch 1318 in epoch 0, gen_loss = 0.801802791434766, disc_loss = 0.15509476314402604
Trained batch 1319 in epoch 0, gen_loss = 0.8019494388816935, disc_loss = 0.1550054677846757
Trained batch 1320 in epoch 0, gen_loss = 0.8019822250930402, disc_loss = 0.15491139781601407
Trained batch 1321 in epoch 0, gen_loss = 0.8018465270027632, disc_loss = 0.1549056948764241
Trained batch 1322 in epoch 0, gen_loss = 0.8019139723217316, disc_loss = 0.15489811234553474
Trained batch 1323 in epoch 0, gen_loss = 0.8020189186822612, disc_loss = 0.15483173834345673
Trained batch 1324 in epoch 0, gen_loss = 0.8019147554658493, disc_loss = 0.154800236989867
Trained batch 1325 in epoch 0, gen_loss = 0.8017541217093734, disc_loss = 0.15483774926912372
Trained batch 1326 in epoch 0, gen_loss = 0.8021262242053807, disc_loss = 0.1548759344720984
Trained batch 1327 in epoch 0, gen_loss = 0.8022666397807469, disc_loss = 0.15478998882112555
Trained batch 1328 in epoch 0, gen_loss = 0.8020463999139357, disc_loss = 0.1547945401973972
Trained batch 1329 in epoch 0, gen_loss = 0.8019721162274368, disc_loss = 0.1547395221496883
Trained batch 1330 in epoch 0, gen_loss = 0.8021494844504355, disc_loss = 0.15468778598922076
Trained batch 1331 in epoch 0, gen_loss = 0.8020927926396823, disc_loss = 0.1547949647212082
Trained batch 1332 in epoch 0, gen_loss = 0.8019552605767404, disc_loss = 0.15501932319692446
Trained batch 1333 in epoch 0, gen_loss = 0.8021977068646916, disc_loss = 0.15506719897823712
Trained batch 1334 in epoch 0, gen_loss = 0.8020462496227093, disc_loss = 0.1552053170090311
Trained batch 1335 in epoch 0, gen_loss = 0.8019226882941352, disc_loss = 0.15527146777506182
Trained batch 1336 in epoch 0, gen_loss = 0.8018982605918094, disc_loss = 0.1552523923069573
Trained batch 1337 in epoch 0, gen_loss = 0.802043075496484, disc_loss = 0.15522710899356057
Trained batch 1338 in epoch 0, gen_loss = 0.802171391124063, disc_loss = 0.15519880319238155
Trained batch 1339 in epoch 0, gen_loss = 0.8020796159532533, disc_loss = 0.15524118085628125
Trained batch 1340 in epoch 0, gen_loss = 0.8020907572229614, disc_loss = 0.15517700441865045
Trained batch 1341 in epoch 0, gen_loss = 0.8021031341192086, disc_loss = 0.15509627379710203
Trained batch 1342 in epoch 0, gen_loss = 0.8019221509603627, disc_loss = 0.1550670635518261
Trained batch 1343 in epoch 0, gen_loss = 0.8018781278681543, disc_loss = 0.15500686392520688
Trained batch 1344 in epoch 0, gen_loss = 0.8019396096578761, disc_loss = 0.15493416756280737
Trained batch 1345 in epoch 0, gen_loss = 0.8016681074653302, disc_loss = 0.15494035817627388
Trained batch 1346 in epoch 0, gen_loss = 0.8018179361521092, disc_loss = 0.15488542026737132
Trained batch 1347 in epoch 0, gen_loss = 0.8017369405717454, disc_loss = 0.15489097800691687
Trained batch 1348 in epoch 0, gen_loss = 0.8017229998968901, disc_loss = 0.15484867041158712
Trained batch 1349 in epoch 0, gen_loss = 0.8020327185259924, disc_loss = 0.154945065136309
Trained batch 1350 in epoch 0, gen_loss = 0.8019578549528369, disc_loss = 0.15498402786422535
Trained batch 1351 in epoch 0, gen_loss = 0.8018592837646868, disc_loss = 0.15494092830495368
Trained batch 1352 in epoch 0, gen_loss = 0.8019684747863679, disc_loss = 0.15488699606102832
Trained batch 1353 in epoch 0, gen_loss = 0.8018459269620115, disc_loss = 0.15490897427941708
Trained batch 1354 in epoch 0, gen_loss = 0.8017571896644536, disc_loss = 0.1548672546979686
Trained batch 1355 in epoch 0, gen_loss = 0.8017419511150118, disc_loss = 0.1548175764844305
Trained batch 1356 in epoch 0, gen_loss = 0.8019177010152475, disc_loss = 0.15476705591271886
Trained batch 1357 in epoch 0, gen_loss = 0.8016341245227078, disc_loss = 0.15490626792295867
Trained batch 1358 in epoch 0, gen_loss = 0.8017902891806068, disc_loss = 0.1548685512674741
Trained batch 1359 in epoch 0, gen_loss = 0.8016642730902223, disc_loss = 0.1548070036148762
Trained batch 1360 in epoch 0, gen_loss = 0.8014720223740038, disc_loss = 0.1548295502635068
Trained batch 1361 in epoch 0, gen_loss = 0.8013885296038769, disc_loss = 0.15481087247596262
Trained batch 1362 in epoch 0, gen_loss = 0.8012707140720337, disc_loss = 0.15480104428241118
Trained batch 1363 in epoch 0, gen_loss = 0.8011221503319979, disc_loss = 0.15481564237072495
Trained batch 1364 in epoch 0, gen_loss = 0.8011737485071678, disc_loss = 0.1549064249619023
Trained batch 1365 in epoch 0, gen_loss = 0.8012703342109613, disc_loss = 0.15487635626538082
Trained batch 1366 in epoch 0, gen_loss = 0.8011444639618935, disc_loss = 0.15486878407376478
Trained batch 1367 in epoch 0, gen_loss = 0.800881503378613, disc_loss = 0.15487752065106095
Trained batch 1368 in epoch 0, gen_loss = 0.8008418022454263, disc_loss = 0.15490277113707246
Trained batch 1369 in epoch 0, gen_loss = 0.8007288289113637, disc_loss = 0.15486273093924036
Trained batch 1370 in epoch 0, gen_loss = 0.8005312744889443, disc_loss = 0.15486726856618618
Trained batch 1371 in epoch 0, gen_loss = 0.8005456357716472, disc_loss = 0.15485713731378056
Trained batch 1372 in epoch 0, gen_loss = 0.8004134630991956, disc_loss = 0.1548554867951
Trained batch 1373 in epoch 0, gen_loss = 0.8004207229119722, disc_loss = 0.15489209171661122
Trained batch 1374 in epoch 0, gen_loss = 0.8003391011194749, disc_loss = 0.15485466080904006
Trained batch 1375 in epoch 0, gen_loss = 0.8002649980358952, disc_loss = 0.15485872525916716
Trained batch 1376 in epoch 0, gen_loss = 0.8002098121544374, disc_loss = 0.15484260387864768
Trained batch 1377 in epoch 0, gen_loss = 0.8001664261643184, disc_loss = 0.1548215966450026
Trained batch 1378 in epoch 0, gen_loss = 0.7999907908576221, disc_loss = 0.15481472766922383
Trained batch 1379 in epoch 0, gen_loss = 0.7998874483980994, disc_loss = 0.1547637717069491
Trained batch 1380 in epoch 0, gen_loss = 0.7999527708375739, disc_loss = 0.15467215292452471
Trained batch 1381 in epoch 0, gen_loss = 0.7998594013939028, disc_loss = 0.15460498057920405
Trained batch 1382 in epoch 0, gen_loss = 0.7997805204886246, disc_loss = 0.1545950828829884
Trained batch 1383 in epoch 0, gen_loss = 0.7997961482948306, disc_loss = 0.15457858170538796
Trained batch 1384 in epoch 0, gen_loss = 0.7997593836879041, disc_loss = 0.15450464566692118
Trained batch 1385 in epoch 0, gen_loss = 0.7998074626208728, disc_loss = 0.15442196796628047
Trained batch 1386 in epoch 0, gen_loss = 0.7995838961458585, disc_loss = 0.15441112618600625
Trained batch 1387 in epoch 0, gen_loss = 0.7995999182120868, disc_loss = 0.15435430331032196
Trained batch 1388 in epoch 0, gen_loss = 0.7997762142238727, disc_loss = 0.15437165641576545
Trained batch 1389 in epoch 0, gen_loss = 0.7995676353466596, disc_loss = 0.1543343431309616
Trained batch 1390 in epoch 0, gen_loss = 0.7994309653274281, disc_loss = 0.15431670952483872
Trained batch 1391 in epoch 0, gen_loss = 0.7997178205599388, disc_loss = 0.15435125977175587
Trained batch 1392 in epoch 0, gen_loss = 0.7996054214063687, disc_loss = 0.15429780472602164
Trained batch 1393 in epoch 0, gen_loss = 0.79940079751196, disc_loss = 0.15431331898990372
Trained batch 1394 in epoch 0, gen_loss = 0.7995922242227849, disc_loss = 0.1545794022045896
Trained batch 1395 in epoch 0, gen_loss = 0.7995080945100689, disc_loss = 0.1546019495072585
Trained batch 1396 in epoch 0, gen_loss = 0.7994107383656007, disc_loss = 0.15463010417717477
Trained batch 1397 in epoch 0, gen_loss = 0.799232088722214, disc_loss = 0.15460639945011537
Trained batch 1398 in epoch 0, gen_loss = 0.7992674760131686, disc_loss = 0.15454627298953025
Trained batch 1399 in epoch 0, gen_loss = 0.7991382138005325, disc_loss = 0.15453238537535072
Trained batch 1400 in epoch 0, gen_loss = 0.7992455321792872, disc_loss = 0.15451138816258042
Trained batch 1401 in epoch 0, gen_loss = 0.7991067459129233, disc_loss = 0.15445433351106294
Trained batch 1402 in epoch 0, gen_loss = 0.7989383094538474, disc_loss = 0.15456194862595898
Trained batch 1403 in epoch 0, gen_loss = 0.7991091556995683, disc_loss = 0.15458211190520954
Trained batch 1404 in epoch 0, gen_loss = 0.7990401167674421, disc_loss = 0.15461462967601536
Trained batch 1405 in epoch 0, gen_loss = 0.7989095229639607, disc_loss = 0.154588805039971
Trained batch 1406 in epoch 0, gen_loss = 0.7987726366553818, disc_loss = 0.15454644740803408
Trained batch 1407 in epoch 0, gen_loss = 0.7987195258663798, disc_loss = 0.1544970281088767
Trained batch 1408 in epoch 0, gen_loss = 0.7988249864072305, disc_loss = 0.15449271984319046
Trained batch 1409 in epoch 0, gen_loss = 0.7988449173827543, disc_loss = 0.1544696004810274
Trained batch 1410 in epoch 0, gen_loss = 0.7987973277109215, disc_loss = 0.15440541474923522
Trained batch 1411 in epoch 0, gen_loss = 0.7987331622003158, disc_loss = 0.15438911967538824
Trained batch 1412 in epoch 0, gen_loss = 0.7985939248731941, disc_loss = 0.15433918558435497
Trained batch 1413 in epoch 0, gen_loss = 0.7985537051943775, disc_loss = 0.15428894057163844
Trained batch 1414 in epoch 0, gen_loss = 0.7988070268723653, disc_loss = 0.15430788157422215
Trained batch 1415 in epoch 0, gen_loss = 0.7987570181531084, disc_loss = 0.15427865479720262
Trained batch 1416 in epoch 0, gen_loss = 0.7987248330319862, disc_loss = 0.15424211376629923
Trained batch 1417 in epoch 0, gen_loss = 0.79863840658927, disc_loss = 0.1542037289106249
Trained batch 1418 in epoch 0, gen_loss = 0.7986378312908989, disc_loss = 0.1541702023788058
Trained batch 1419 in epoch 0, gen_loss = 0.7987331863230382, disc_loss = 0.1541384590264987
Trained batch 1420 in epoch 0, gen_loss = 0.7988047510658159, disc_loss = 0.15413126418921497
Trained batch 1421 in epoch 0, gen_loss = 0.7987039400429665, disc_loss = 0.1540929866370479
Trained batch 1422 in epoch 0, gen_loss = 0.7986068287242573, disc_loss = 0.15404682494673777
Trained batch 1423 in epoch 0, gen_loss = 0.7987800347461794, disc_loss = 0.1540262480083267
Trained batch 1424 in epoch 0, gen_loss = 0.7985005941934753, disc_loss = 0.15409255034829442
Trained batch 1425 in epoch 0, gen_loss = 0.7984183094820836, disc_loss = 0.15406964470333254
Trained batch 1426 in epoch 0, gen_loss = 0.7983216166120354, disc_loss = 0.15405196066066026
Trained batch 1427 in epoch 0, gen_loss = 0.7983299239802093, disc_loss = 0.1540495230782391
Trained batch 1428 in epoch 0, gen_loss = 0.7982793490189285, disc_loss = 0.1540602712316518
Trained batch 1429 in epoch 0, gen_loss = 0.7981381078908494, disc_loss = 0.15399014523344023
Trained batch 1430 in epoch 0, gen_loss = 0.797893406064422, disc_loss = 0.15405826688927007
Trained batch 1431 in epoch 0, gen_loss = 0.7979528637779825, disc_loss = 0.15403303060441292
Trained batch 1432 in epoch 0, gen_loss = 0.7979665710763006, disc_loss = 0.15401132757056035
Trained batch 1433 in epoch 0, gen_loss = 0.797890410450712, disc_loss = 0.15411709363064424
Trained batch 1434 in epoch 0, gen_loss = 0.7979794338812811, disc_loss = 0.15417236733260056
Trained batch 1435 in epoch 0, gen_loss = 0.797996969338413, disc_loss = 0.1541481177947772
Trained batch 1436 in epoch 0, gen_loss = 0.797842106743662, disc_loss = 0.15415383082870898
Trained batch 1437 in epoch 0, gen_loss = 0.7976941541562658, disc_loss = 0.15421297929414207
Trained batch 1438 in epoch 0, gen_loss = 0.7978476048799916, disc_loss = 0.15423597108321607
Trained batch 1439 in epoch 0, gen_loss = 0.7978699392949541, disc_loss = 0.15424497993404251
Trained batch 1440 in epoch 0, gen_loss = 0.7978488023830403, disc_loss = 0.15428722310891424
Trained batch 1441 in epoch 0, gen_loss = 0.7978363154293264, disc_loss = 0.15426715403206223
Trained batch 1442 in epoch 0, gen_loss = 0.7979655803406478, disc_loss = 0.15426706212133232
Trained batch 1443 in epoch 0, gen_loss = 0.7977660008373353, disc_loss = 0.15426491979777895
Trained batch 1444 in epoch 0, gen_loss = 0.7975928424757657, disc_loss = 0.15430138054139475
Trained batch 1445 in epoch 0, gen_loss = 0.7976550281171482, disc_loss = 0.15427696718518746
Trained batch 1446 in epoch 0, gen_loss = 0.7977462611325297, disc_loss = 0.15425598960943937
Trained batch 1447 in epoch 0, gen_loss = 0.7976591029919643, disc_loss = 0.1542664500061443
Trained batch 1448 in epoch 0, gen_loss = 0.7975716530618543, disc_loss = 0.15425203740339677
Trained batch 1449 in epoch 0, gen_loss = 0.7976878584047844, disc_loss = 0.1542628013342619
Trained batch 1450 in epoch 0, gen_loss = 0.7976008586888474, disc_loss = 0.15424394629880284
Trained batch 1451 in epoch 0, gen_loss = 0.7975665096285914, disc_loss = 0.1542196675606544
Trained batch 1452 in epoch 0, gen_loss = 0.7975931244518375, disc_loss = 0.1542424135145982
Trained batch 1453 in epoch 0, gen_loss = 0.7975475227939377, disc_loss = 0.15419644801179266
Trained batch 1454 in epoch 0, gen_loss = 0.7975929839299717, disc_loss = 0.1541629264265606
Trained batch 1455 in epoch 0, gen_loss = 0.797561800926105, disc_loss = 0.15409693822193032
Trained batch 1456 in epoch 0, gen_loss = 0.7976248238335428, disc_loss = 0.15401964720821823
Trained batch 1457 in epoch 0, gen_loss = 0.7975034682879886, disc_loss = 0.15394522557073415
Trained batch 1458 in epoch 0, gen_loss = 0.7972903027568802, disc_loss = 0.15413215648921652
Trained batch 1459 in epoch 0, gen_loss = 0.7975599649630181, disc_loss = 0.15431359849921236
Trained batch 1460 in epoch 0, gen_loss = 0.7975328672552338, disc_loss = 0.15423927572412413
Trained batch 1461 in epoch 0, gen_loss = 0.7973117166480352, disc_loss = 0.1542541948178969
Trained batch 1462 in epoch 0, gen_loss = 0.7972120890980784, disc_loss = 0.15421533145097047
Trained batch 1463 in epoch 0, gen_loss = 0.7972230607735329, disc_loss = 0.15419555192334894
Trained batch 1464 in epoch 0, gen_loss = 0.7971322251871584, disc_loss = 0.1542028961989253
Trained batch 1465 in epoch 0, gen_loss = 0.7971261561445455, disc_loss = 0.15418136576736932
Trained batch 1466 in epoch 0, gen_loss = 0.7970464085143036, disc_loss = 0.1541747895476358
Trained batch 1467 in epoch 0, gen_loss = 0.7969334560575863, disc_loss = 0.15416358717354345
Trained batch 1468 in epoch 0, gen_loss = 0.7968499642436078, disc_loss = 0.15412999307667016
Trained batch 1469 in epoch 0, gen_loss = 0.7969370921250103, disc_loss = 0.1540967124254525
Trained batch 1470 in epoch 0, gen_loss = 0.7969093446136737, disc_loss = 0.15403262973540824
Trained batch 1471 in epoch 0, gen_loss = 0.7968272741924486, disc_loss = 0.15401460374604262
Trained batch 1472 in epoch 0, gen_loss = 0.796840163229763, disc_loss = 0.15401864916248056
Trained batch 1473 in epoch 0, gen_loss = 0.7967903044079828, disc_loss = 0.15400293971357545
Trained batch 1474 in epoch 0, gen_loss = 0.7968932535890806, disc_loss = 0.1539461961893712
Trained batch 1475 in epoch 0, gen_loss = 0.7966514428658538, disc_loss = 0.1539455634721007
Trained batch 1476 in epoch 0, gen_loss = 0.7967365897218359, disc_loss = 0.15390000408597307
Trained batch 1477 in epoch 0, gen_loss = 0.7969367446249328, disc_loss = 0.1539443332414585
Trained batch 1478 in epoch 0, gen_loss = 0.7968328582063731, disc_loss = 0.15393017745747448
Trained batch 1479 in epoch 0, gen_loss = 0.7968520371696434, disc_loss = 0.15384317979946532
Trained batch 1480 in epoch 0, gen_loss = 0.7967624166662189, disc_loss = 0.15379665578306123
Trained batch 1481 in epoch 0, gen_loss = 0.7969226791911762, disc_loss = 0.15383373128122044
Trained batch 1482 in epoch 0, gen_loss = 0.796816583649982, disc_loss = 0.15381148716890763
Trained batch 1483 in epoch 0, gen_loss = 0.7967880168814222, disc_loss = 0.15381240724357512
Trained batch 1484 in epoch 0, gen_loss = 0.7968303063702503, disc_loss = 0.15377435134441564
Trained batch 1485 in epoch 0, gen_loss = 0.7968419935268477, disc_loss = 0.1536995631380666
Trained batch 1486 in epoch 0, gen_loss = 0.7968194106118985, disc_loss = 0.1537254823292853
Trained batch 1487 in epoch 0, gen_loss = 0.7968541325861087, disc_loss = 0.15371066819681156
Trained batch 1488 in epoch 0, gen_loss = 0.7969939426698486, disc_loss = 0.153693483401868
Trained batch 1489 in epoch 0, gen_loss = 0.7969441026849234, disc_loss = 0.15374647237035452
Trained batch 1490 in epoch 0, gen_loss = 0.7968914357509331, disc_loss = 0.1537114967355326
Trained batch 1491 in epoch 0, gen_loss = 0.796928350891089, disc_loss = 0.15373744329327751
Trained batch 1492 in epoch 0, gen_loss = 0.7969532452289162, disc_loss = 0.153735575715937
Trained batch 1493 in epoch 0, gen_loss = 0.7968342202295421, disc_loss = 0.15375962242149963
Trained batch 1494 in epoch 0, gen_loss = 0.7968065045151025, disc_loss = 0.15372653541880907
Trained batch 1495 in epoch 0, gen_loss = 0.7967572458247769, disc_loss = 0.1537329107336202
Trained batch 1496 in epoch 0, gen_loss = 0.796685496229447, disc_loss = 0.1536752093862058
Trained batch 1497 in epoch 0, gen_loss = 0.7966448740066292, disc_loss = 0.15362533890780244
Trained batch 1498 in epoch 0, gen_loss = 0.7965480399537357, disc_loss = 0.15361143728771592
Trained batch 1499 in epoch 0, gen_loss = 0.7966280410885811, disc_loss = 0.15359293591603637
Trained batch 1500 in epoch 0, gen_loss = 0.7966519148845342, disc_loss = 0.15354101113270197
Trained batch 1501 in epoch 0, gen_loss = 0.7965491509112156, disc_loss = 0.1534918736227442
Trained batch 1502 in epoch 0, gen_loss = 0.7964364238881462, disc_loss = 0.15348498381089348
Trained batch 1503 in epoch 0, gen_loss = 0.796569795070335, disc_loss = 0.1535521750796606
Trained batch 1504 in epoch 0, gen_loss = 0.7963512546794359, disc_loss = 0.15371561386681276
Trained batch 1505 in epoch 0, gen_loss = 0.7964780843788251, disc_loss = 0.15373842454432532
Trained batch 1506 in epoch 0, gen_loss = 0.7964662300211433, disc_loss = 0.15368296222930605
Trained batch 1507 in epoch 0, gen_loss = 0.7963599643474865, disc_loss = 0.15366046316551157
Trained batch 1508 in epoch 0, gen_loss = 0.7963477201893125, disc_loss = 0.1536195815174863
Trained batch 1509 in epoch 0, gen_loss = 0.7963457168530155, disc_loss = 0.15361752818085697
Trained batch 1510 in epoch 0, gen_loss = 0.7962450624340658, disc_loss = 0.1536383519983406
Trained batch 1511 in epoch 0, gen_loss = 0.7962241322787665, disc_loss = 0.15363150396601113
Trained batch 1512 in epoch 0, gen_loss = 0.7961996403145459, disc_loss = 0.15361189419835786
Trained batch 1513 in epoch 0, gen_loss = 0.7961423290571102, disc_loss = 0.15359264508485204
Trained batch 1514 in epoch 0, gen_loss = 0.7961645412169668, disc_loss = 0.15354611768015344
Trained batch 1515 in epoch 0, gen_loss = 0.7961033041881382, disc_loss = 0.15350386046369544
Trained batch 1516 in epoch 0, gen_loss = 0.7960423089087442, disc_loss = 0.15344985496515534
Trained batch 1517 in epoch 0, gen_loss = 0.7961417647257781, disc_loss = 0.15342161389330355
Trained batch 1518 in epoch 0, gen_loss = 0.7960049816265634, disc_loss = 0.15341587047938102
Trained batch 1519 in epoch 0, gen_loss = 0.7960071836451167, disc_loss = 0.153378668311052
Trained batch 1520 in epoch 0, gen_loss = 0.7960685876973909, disc_loss = 0.15334229952215483
Trained batch 1521 in epoch 0, gen_loss = 0.7960099659165008, disc_loss = 0.15329747729409735
Trained batch 1522 in epoch 0, gen_loss = 0.7958755869459965, disc_loss = 0.15328835281748288
Trained batch 1523 in epoch 0, gen_loss = 0.7960313562294004, disc_loss = 0.15331022903015176
Trained batch 1524 in epoch 0, gen_loss = 0.7959484931093748, disc_loss = 0.1533024738179367
Trained batch 1525 in epoch 0, gen_loss = 0.7958523281709551, disc_loss = 0.15328829628226212
Trained batch 1526 in epoch 0, gen_loss = 0.7958301116652011, disc_loss = 0.153398797307566
Trained batch 1527 in epoch 0, gen_loss = 0.7957129285558668, disc_loss = 0.15337243623158733
Trained batch 1528 in epoch 0, gen_loss = 0.795514278683965, disc_loss = 0.1533875689409951
Trained batch 1529 in epoch 0, gen_loss = 0.7955782887398027, disc_loss = 0.15334597669809666
Trained batch 1530 in epoch 0, gen_loss = 0.7954445635275775, disc_loss = 0.15338276244534493
Trained batch 1531 in epoch 0, gen_loss = 0.795376166448425, disc_loss = 0.15334594443892724
Trained batch 1532 in epoch 0, gen_loss = 0.7953188553287247, disc_loss = 0.15335459811448934
Trained batch 1533 in epoch 0, gen_loss = 0.7952308455261133, disc_loss = 0.1533643394050515
Trained batch 1534 in epoch 0, gen_loss = 0.7954282808187342, disc_loss = 0.1533772958958285
Trained batch 1535 in epoch 0, gen_loss = 0.7953092245734297, disc_loss = 0.1533697453814966
Trained batch 1536 in epoch 0, gen_loss = 0.7952277539570609, disc_loss = 0.15334845856971258
Trained batch 1537 in epoch 0, gen_loss = 0.7951788112269267, disc_loss = 0.15330541460994046
Trained batch 1538 in epoch 0, gen_loss = 0.7952754538387661, disc_loss = 0.15327551578128587
Trained batch 1539 in epoch 0, gen_loss = 0.7952875368587382, disc_loss = 0.1532206403853541
Trained batch 1540 in epoch 0, gen_loss = 0.7951695738985196, disc_loss = 0.15322410983095727
Trained batch 1541 in epoch 0, gen_loss = 0.7950770538566023, disc_loss = 0.15319749270475214
Trained batch 1542 in epoch 0, gen_loss = 0.7950555582712474, disc_loss = 0.15316533262654897
Trained batch 1543 in epoch 0, gen_loss = 0.7951172869555999, disc_loss = 0.1531220255624696
Trained batch 1544 in epoch 0, gen_loss = 0.7950861988908651, disc_loss = 0.15307990236503213
Trained batch 1545 in epoch 0, gen_loss = 0.7948890980935498, disc_loss = 0.15309227140497458
Trained batch 1546 in epoch 0, gen_loss = 0.7948998145195616, disc_loss = 0.15305826838628547
Trained batch 1547 in epoch 0, gen_loss = 0.7948378966182701, disc_loss = 0.15302239175650076
Trained batch 1548 in epoch 0, gen_loss = 0.7948703961537067, disc_loss = 0.152992509349969
Trained batch 1549 in epoch 0, gen_loss = 0.794763692713553, disc_loss = 0.15298870450186153
Trained batch 1550 in epoch 0, gen_loss = 0.7947586518691325, disc_loss = 0.1529422998632503
Trained batch 1551 in epoch 0, gen_loss = 0.794600207224181, disc_loss = 0.15291785955856332
Trained batch 1552 in epoch 0, gen_loss = 0.7946521711019416, disc_loss = 0.15290331780186064
Trained batch 1553 in epoch 0, gen_loss = 0.7945569259051037, disc_loss = 0.15291315868635935
Trained batch 1554 in epoch 0, gen_loss = 0.7945453013062861, disc_loss = 0.15286853088371433
Trained batch 1555 in epoch 0, gen_loss = 0.7944538093586201, disc_loss = 0.1528696753766991
Trained batch 1556 in epoch 0, gen_loss = 0.7944484616635162, disc_loss = 0.1527995360296222
Trained batch 1557 in epoch 0, gen_loss = 0.7944151894004109, disc_loss = 0.1527591448179201
Trained batch 1558 in epoch 0, gen_loss = 0.7942991352104238, disc_loss = 0.15272535662440972
Trained batch 1559 in epoch 0, gen_loss = 0.7941660079245384, disc_loss = 0.1527383560135674
Trained batch 1560 in epoch 0, gen_loss = 0.7941776688743447, disc_loss = 0.15269503539247936
Trained batch 1561 in epoch 0, gen_loss = 0.7941116633969294, disc_loss = 0.1526764523912884
Trained batch 1562 in epoch 0, gen_loss = 0.7940155452859761, disc_loss = 0.1526681617181212
Trained batch 1563 in epoch 0, gen_loss = 0.7941246451738545, disc_loss = 0.1526035102062842
Trained batch 1564 in epoch 0, gen_loss = 0.7941914913562921, disc_loss = 0.152548402015822
Trained batch 1565 in epoch 0, gen_loss = 0.7941105620195734, disc_loss = 0.15253234487312392
Trained batch 1566 in epoch 0, gen_loss = 0.79417449237818, disc_loss = 0.15246584510695768
Trained batch 1567 in epoch 0, gen_loss = 0.7940130907928153, disc_loss = 0.15245038325475452
Trained batch 1568 in epoch 0, gen_loss = 0.7942366222236626, disc_loss = 0.15244724388650416
Trained batch 1569 in epoch 0, gen_loss = 0.7942400721038223, disc_loss = 0.15240020537333693
Trained batch 1570 in epoch 0, gen_loss = 0.7941124910271752, disc_loss = 0.15260187362307087
Trained batch 1571 in epoch 0, gen_loss = 0.7942625195280892, disc_loss = 0.15270394638403492
Trained batch 1572 in epoch 0, gen_loss = 0.7941605517118506, disc_loss = 0.15269445766590048
Trained batch 1573 in epoch 0, gen_loss = 0.7941677803422171, disc_loss = 0.15266072302181014
Trained batch 1574 in epoch 0, gen_loss = 0.7940572009578584, disc_loss = 0.15269853640998166
Trained batch 1575 in epoch 0, gen_loss = 0.7939852604519595, disc_loss = 0.15275415920813185
Trained batch 1576 in epoch 0, gen_loss = 0.7939639226613199, disc_loss = 0.15274673351544366
Trained batch 1577 in epoch 0, gen_loss = 0.7938914589291138, disc_loss = 0.15272666244674357
Trained batch 1578 in epoch 0, gen_loss = 0.7939078579264551, disc_loss = 0.15270587332792077
Trained batch 1579 in epoch 0, gen_loss = 0.7937684874934486, disc_loss = 0.15272782645718772
Trained batch 1580 in epoch 0, gen_loss = 0.7936266402629717, disc_loss = 0.15278426459168687
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 1.0680804252624512, disc_loss = 0.2935050129890442
Trained batch 1 in epoch 1, gen_loss = 0.9777733087539673, disc_loss = 0.16939949057996273
Trained batch 2 in epoch 1, gen_loss = 0.9099398454030355, disc_loss = 0.1275759612520536
Trained batch 3 in epoch 1, gen_loss = 0.8624554574489594, disc_loss = 0.13265848346054554
Trained batch 4 in epoch 1, gen_loss = 0.8339764595031738, disc_loss = 0.12348390817642212
Trained batch 5 in epoch 1, gen_loss = 0.8271213173866272, disc_loss = 0.1177630287905534
Trained batch 6 in epoch 1, gen_loss = 0.801247136933463, disc_loss = 0.11949554617915835
Trained batch 7 in epoch 1, gen_loss = 0.8059921264648438, disc_loss = 0.11591288726776838
Trained batch 8 in epoch 1, gen_loss = 0.8230567375818888, disc_loss = 0.1195571083161566
Trained batch 9 in epoch 1, gen_loss = 0.8228399753570557, disc_loss = 0.11944899782538414
Trained batch 10 in epoch 1, gen_loss = 0.8173837986859408, disc_loss = 0.11335834556005218
Trained batch 11 in epoch 1, gen_loss = 0.8123586674531301, disc_loss = 0.11162365383158128
Trained batch 12 in epoch 1, gen_loss = 0.7952100588725164, disc_loss = 0.11121400646292247
Trained batch 13 in epoch 1, gen_loss = 0.8000208778040749, disc_loss = 0.11096335282283169
Trained batch 14 in epoch 1, gen_loss = 0.7840686519940694, disc_loss = 0.11215843930840493
Trained batch 15 in epoch 1, gen_loss = 0.7914970703423023, disc_loss = 0.10765084996819496
Trained batch 16 in epoch 1, gen_loss = 0.8164167088620803, disc_loss = 0.10350699898074656
Trained batch 17 in epoch 1, gen_loss = 0.8061182465818193, disc_loss = 0.10539587090412776
Trained batch 18 in epoch 1, gen_loss = 0.8220393814538655, disc_loss = 0.10175276135927752
Trained batch 19 in epoch 1, gen_loss = 0.828947713971138, disc_loss = 0.09923314098268747
Trained batch 20 in epoch 1, gen_loss = 0.8202517742202395, disc_loss = 0.10270919065390315
Trained batch 21 in epoch 1, gen_loss = 0.823204140771519, disc_loss = 0.09947807341814041
Trained batch 22 in epoch 1, gen_loss = 0.8266686848972155, disc_loss = 0.09892984835997871
Trained batch 23 in epoch 1, gen_loss = 0.8245964373151461, disc_loss = 0.1029260413100322
Trained batch 24 in epoch 1, gen_loss = 0.8123502111434937, disc_loss = 0.10812049627304077
Trained batch 25 in epoch 1, gen_loss = 0.808334625684298, disc_loss = 0.10676128417253494
Trained batch 26 in epoch 1, gen_loss = 0.8106327189339532, disc_loss = 0.10583785535008819
Trained batch 27 in epoch 1, gen_loss = 0.8165280520915985, disc_loss = 0.10510180358375822
Trained batch 28 in epoch 1, gen_loss = 0.8196598085863837, disc_loss = 0.10254899739962199
Trained batch 29 in epoch 1, gen_loss = 0.8206610540548961, disc_loss = 0.10054302805413802
Trained batch 30 in epoch 1, gen_loss = 0.8392444214513225, disc_loss = 0.10004340779156454
Trained batch 31 in epoch 1, gen_loss = 0.8406481426209211, disc_loss = 0.09758804348530248
Trained batch 32 in epoch 1, gen_loss = 0.8343933062119917, disc_loss = 0.09630790064958009
Trained batch 33 in epoch 1, gen_loss = 0.8323940161396476, disc_loss = 0.09679827274864211
Trained batch 34 in epoch 1, gen_loss = 0.829237037045615, disc_loss = 0.09658668195562703
Trained batch 35 in epoch 1, gen_loss = 0.8271865993738174, disc_loss = 0.09603091231029895
Trained batch 36 in epoch 1, gen_loss = 0.828152638834876, disc_loss = 0.09463986165418818
Trained batch 37 in epoch 1, gen_loss = 0.8345801908718912, disc_loss = 0.09263887222072012
Trained batch 38 in epoch 1, gen_loss = 0.8421000777146755, disc_loss = 0.0909338136896109
Trained batch 39 in epoch 1, gen_loss = 0.8480715826153755, disc_loss = 0.08920924640260637
Trained batch 40 in epoch 1, gen_loss = 0.845437401678504, disc_loss = 0.08817319603773152
Trained batch 41 in epoch 1, gen_loss = 0.846879358802523, disc_loss = 0.0867200939516936
Trained batch 42 in epoch 1, gen_loss = 0.8410478705583617, disc_loss = 0.08916982336966105
Trained batch 43 in epoch 1, gen_loss = 0.8456887074492194, disc_loss = 0.08939449899745258
Trained batch 44 in epoch 1, gen_loss = 0.8463757766617669, disc_loss = 0.0888234263079034
Trained batch 45 in epoch 1, gen_loss = 0.8427189899527509, disc_loss = 0.08917013932343411
Trained batch 46 in epoch 1, gen_loss = 0.8461336176446144, disc_loss = 0.09111452629750079
Trained batch 47 in epoch 1, gen_loss = 0.8384298825015625, disc_loss = 0.09422427838823448
Trained batch 48 in epoch 1, gen_loss = 0.8387888274630722, disc_loss = 0.09338421652055516
Trained batch 49 in epoch 1, gen_loss = 0.8405954021215439, disc_loss = 0.0926404831930995
Trained batch 50 in epoch 1, gen_loss = 0.8361192082657534, disc_loss = 0.09352151709882651
Trained batch 51 in epoch 1, gen_loss = 0.8310051978780673, disc_loss = 0.09423389239236712
Trained batch 52 in epoch 1, gen_loss = 0.8346164232155062, disc_loss = 0.09577049297403614
Trained batch 53 in epoch 1, gen_loss = 0.8304857109431867, disc_loss = 0.09771635945610425
Trained batch 54 in epoch 1, gen_loss = 0.8324637548490004, disc_loss = 0.09783595322885297
Trained batch 55 in epoch 1, gen_loss = 0.827692620988403, disc_loss = 0.09783298505603202
Trained batch 56 in epoch 1, gen_loss = 0.8284306123591306, disc_loss = 0.09834687473873298
Trained batch 57 in epoch 1, gen_loss = 0.8305014880566761, disc_loss = 0.09729004949973576
Trained batch 58 in epoch 1, gen_loss = 0.8289775823132467, disc_loss = 0.09712251152653816
Trained batch 59 in epoch 1, gen_loss = 0.8321105296413104, disc_loss = 0.09602875942364335
Trained batch 60 in epoch 1, gen_loss = 0.8373825388853667, disc_loss = 0.09551732458907072
Trained batch 61 in epoch 1, gen_loss = 0.8330248897114108, disc_loss = 0.09767227376540823
Trained batch 62 in epoch 1, gen_loss = 0.8417367211409977, disc_loss = 0.10029920861716309
Trained batch 63 in epoch 1, gen_loss = 0.8463678988628089, disc_loss = 0.09917602353380062
Trained batch 64 in epoch 1, gen_loss = 0.8447396750633533, disc_loss = 0.10031651249871804
Trained batch 65 in epoch 1, gen_loss = 0.8437659401785244, disc_loss = 0.09944612546965029
Trained batch 66 in epoch 1, gen_loss = 0.8437491650901624, disc_loss = 0.09876939295721587
Trained batch 67 in epoch 1, gen_loss = 0.8429042096523678, disc_loss = 0.09881762105642873
Trained batch 68 in epoch 1, gen_loss = 0.8404008482677349, disc_loss = 0.09844256610866042
Trained batch 69 in epoch 1, gen_loss = 0.8373229959181376, disc_loss = 0.09973976268832173
Trained batch 70 in epoch 1, gen_loss = 0.8434956556474659, disc_loss = 0.10187856199770746
Trained batch 71 in epoch 1, gen_loss = 0.8408807768589921, disc_loss = 0.10204145061369571
Trained batch 72 in epoch 1, gen_loss = 0.8397514252629998, disc_loss = 0.10240564584629992
Trained batch 73 in epoch 1, gen_loss = 0.8401539055882273, disc_loss = 0.10125832634701117
Trained batch 74 in epoch 1, gen_loss = 0.8368876500924428, disc_loss = 0.1015272964288791
Trained batch 75 in epoch 1, gen_loss = 0.8345298104380307, disc_loss = 0.10182504799511087
Trained batch 76 in epoch 1, gen_loss = 0.8336235900203903, disc_loss = 0.1015671275120664
Trained batch 77 in epoch 1, gen_loss = 0.8335098941356708, disc_loss = 0.10195623550755091
Trained batch 78 in epoch 1, gen_loss = 0.8325217769870276, disc_loss = 0.10121253172902367
Trained batch 79 in epoch 1, gen_loss = 0.8297311294823885, disc_loss = 0.10148889946285636
Trained batch 80 in epoch 1, gen_loss = 0.8300546462889071, disc_loss = 0.10129657150878582
Trained batch 81 in epoch 1, gen_loss = 0.8307038367521472, disc_loss = 0.10143116427721774
Trained batch 82 in epoch 1, gen_loss = 0.8321353100150465, disc_loss = 0.1014410126505487
Trained batch 83 in epoch 1, gen_loss = 0.8309244729933285, disc_loss = 0.10172010037959331
Trained batch 84 in epoch 1, gen_loss = 0.8298913005520315, disc_loss = 0.1015186457292122
Trained batch 85 in epoch 1, gen_loss = 0.8335562975600709, disc_loss = 0.1011904246108823
Trained batch 86 in epoch 1, gen_loss = 0.8315381918145323, disc_loss = 0.10149313939799523
Trained batch 87 in epoch 1, gen_loss = 0.8315662331879139, disc_loss = 0.10136371590620415
Trained batch 88 in epoch 1, gen_loss = 0.831546349806732, disc_loss = 0.10116775997317909
Trained batch 89 in epoch 1, gen_loss = 0.8322967512740029, disc_loss = 0.10238887661447128
Trained batch 90 in epoch 1, gen_loss = 0.8273567652309334, disc_loss = 0.10527066863909527
Trained batch 91 in epoch 1, gen_loss = 0.8279479479660159, disc_loss = 0.10532250970035144
Trained batch 92 in epoch 1, gen_loss = 0.8292354111389447, disc_loss = 0.10534721094193639
Trained batch 93 in epoch 1, gen_loss = 0.8289160598465737, disc_loss = 0.10500127903403754
Trained batch 94 in epoch 1, gen_loss = 0.8268349293031191, disc_loss = 0.10499525919164482
Trained batch 95 in epoch 1, gen_loss = 0.8237390589589874, disc_loss = 0.10558514004029955
Trained batch 96 in epoch 1, gen_loss = 0.8236341829766932, disc_loss = 0.10530615561478532
Trained batch 97 in epoch 1, gen_loss = 0.8243819727581374, disc_loss = 0.10465325242174524
Trained batch 98 in epoch 1, gen_loss = 0.8243765021213377, disc_loss = 0.10415997990228311
Trained batch 99 in epoch 1, gen_loss = 0.82537532299757, disc_loss = 0.1034500682540238
Trained batch 100 in epoch 1, gen_loss = 0.8231402166409068, disc_loss = 0.1033417773018084
Trained batch 101 in epoch 1, gen_loss = 0.8216066573764763, disc_loss = 0.10333615565197725
Trained batch 102 in epoch 1, gen_loss = 0.8220161503379785, disc_loss = 0.10323989414836018
Trained batch 103 in epoch 1, gen_loss = 0.8255132794953309, disc_loss = 0.102752819388675
Trained batch 104 in epoch 1, gen_loss = 0.824461224249431, disc_loss = 0.10221568887077627
Trained batch 105 in epoch 1, gen_loss = 0.8220674533326671, disc_loss = 0.10287064624915146
Trained batch 106 in epoch 1, gen_loss = 0.8208919766350328, disc_loss = 0.10267935618410044
Trained batch 107 in epoch 1, gen_loss = 0.8229364943173196, disc_loss = 0.10229897693972345
Trained batch 108 in epoch 1, gen_loss = 0.820708061850399, disc_loss = 0.10249845726295896
Trained batch 109 in epoch 1, gen_loss = 0.8184259184382179, disc_loss = 0.10309610070491379
Trained batch 110 in epoch 1, gen_loss = 0.8201361806006044, disc_loss = 0.10397000303743659
Trained batch 111 in epoch 1, gen_loss = 0.8213109296879598, disc_loss = 0.1032528231818495
Trained batch 112 in epoch 1, gen_loss = 0.8180266911477114, disc_loss = 0.1047444497688418
Trained batch 113 in epoch 1, gen_loss = 0.8199786070668906, disc_loss = 0.10733794811459486
Trained batch 114 in epoch 1, gen_loss = 0.8178679645061493, disc_loss = 0.10782017848737861
Trained batch 115 in epoch 1, gen_loss = 0.8151875115160284, disc_loss = 0.10782720031345198
Trained batch 116 in epoch 1, gen_loss = 0.8143376985676268, disc_loss = 0.10790539919756927
Trained batch 117 in epoch 1, gen_loss = 0.8157949238005331, disc_loss = 0.10795868319159342
Trained batch 118 in epoch 1, gen_loss = 0.8151350078963432, disc_loss = 0.10747269492502473
Trained batch 119 in epoch 1, gen_loss = 0.814329082518816, disc_loss = 0.1074826046358794
Trained batch 120 in epoch 1, gen_loss = 0.8132910568359469, disc_loss = 0.10699973949654536
Trained batch 121 in epoch 1, gen_loss = 0.8114309880088587, disc_loss = 0.10682676309628077
Trained batch 122 in epoch 1, gen_loss = 0.8111952579602962, disc_loss = 0.10632985483521853
Trained batch 123 in epoch 1, gen_loss = 0.8104996760526011, disc_loss = 0.1067099413053403
Trained batch 124 in epoch 1, gen_loss = 0.8092405598163604, disc_loss = 0.10739077953994274
Trained batch 125 in epoch 1, gen_loss = 0.8103171002770228, disc_loss = 0.10735902135511713
Trained batch 126 in epoch 1, gen_loss = 0.80962095040036, disc_loss = 0.10762084590813775
Trained batch 127 in epoch 1, gen_loss = 0.8096207513008267, disc_loss = 0.1075027492333902
Trained batch 128 in epoch 1, gen_loss = 0.8088271814261296, disc_loss = 0.10852597323210203
Trained batch 129 in epoch 1, gen_loss = 0.8076609237835958, disc_loss = 0.10833119639696984
Trained batch 130 in epoch 1, gen_loss = 0.8060351953706668, disc_loss = 0.10915014197523812
Trained batch 131 in epoch 1, gen_loss = 0.8067378096959807, disc_loss = 0.10928686328627395
Trained batch 132 in epoch 1, gen_loss = 0.8068940829961819, disc_loss = 0.1092995048213498
Trained batch 133 in epoch 1, gen_loss = 0.8057733598484922, disc_loss = 0.10905850599450406
Trained batch 134 in epoch 1, gen_loss = 0.8072354610319491, disc_loss = 0.10871764237957972
Trained batch 135 in epoch 1, gen_loss = 0.8070436358890113, disc_loss = 0.10840157083893086
Trained batch 136 in epoch 1, gen_loss = 0.8087048985227181, disc_loss = 0.10778038334237398
Trained batch 137 in epoch 1, gen_loss = 0.8075290713189305, disc_loss = 0.10788941836875418
Trained batch 138 in epoch 1, gen_loss = 0.8055062484826973, disc_loss = 0.10863720577397792
Trained batch 139 in epoch 1, gen_loss = 0.8070579786385809, disc_loss = 0.1088196808738368
Trained batch 140 in epoch 1, gen_loss = 0.8080910099736343, disc_loss = 0.10920971632003784
Trained batch 141 in epoch 1, gen_loss = 0.8066964336264302, disc_loss = 0.10961728448599158
Trained batch 142 in epoch 1, gen_loss = 0.8069912989239593, disc_loss = 0.10947934381820106
Trained batch 143 in epoch 1, gen_loss = 0.8077930818415351, disc_loss = 0.1097459687023527
Trained batch 144 in epoch 1, gen_loss = 0.8069286036080328, disc_loss = 0.10971251422988958
Trained batch 145 in epoch 1, gen_loss = 0.8057691816189517, disc_loss = 0.10987222495756738
Trained batch 146 in epoch 1, gen_loss = 0.80561833904714, disc_loss = 0.10974802821874619
Trained batch 147 in epoch 1, gen_loss = 0.8051627699185062, disc_loss = 0.10957061141930721
Trained batch 148 in epoch 1, gen_loss = 0.8053417835859644, disc_loss = 0.1092496581325595
Trained batch 149 in epoch 1, gen_loss = 0.8067386561632156, disc_loss = 0.10890232709546883
Trained batch 150 in epoch 1, gen_loss = 0.8060710329488413, disc_loss = 0.10892335026962868
Trained batch 151 in epoch 1, gen_loss = 0.8061161098119459, disc_loss = 0.10976877928662457
Trained batch 152 in epoch 1, gen_loss = 0.8061972987028508, disc_loss = 0.10952779609296057
Trained batch 153 in epoch 1, gen_loss = 0.8054359909388926, disc_loss = 0.10931615209714933
Trained batch 154 in epoch 1, gen_loss = 0.8070436191174292, disc_loss = 0.10951484756604318
Trained batch 155 in epoch 1, gen_loss = 0.8057170099554918, disc_loss = 0.1099515703196327
Trained batch 156 in epoch 1, gen_loss = 0.8059441126455926, disc_loss = 0.11007901397385415
Trained batch 157 in epoch 1, gen_loss = 0.806231529086451, disc_loss = 0.1099166344568322
Trained batch 158 in epoch 1, gen_loss = 0.8081184739961564, disc_loss = 0.11008970943168274
Trained batch 159 in epoch 1, gen_loss = 0.8063650699332356, disc_loss = 0.11070643186103553
Trained batch 160 in epoch 1, gen_loss = 0.8064890235477353, disc_loss = 0.11053227024696628
Trained batch 161 in epoch 1, gen_loss = 0.8069586840308742, disc_loss = 0.11084707695300933
Trained batch 162 in epoch 1, gen_loss = 0.8061771347113182, disc_loss = 0.11072119076284895
Trained batch 163 in epoch 1, gen_loss = 0.8050399929648493, disc_loss = 0.11154905890637054
Trained batch 164 in epoch 1, gen_loss = 0.8066103442148729, disc_loss = 0.11185495024829199
Trained batch 165 in epoch 1, gen_loss = 0.8084256403058409, disc_loss = 0.11153993098042815
Trained batch 166 in epoch 1, gen_loss = 0.8061364168178535, disc_loss = 0.11191254860894409
Trained batch 167 in epoch 1, gen_loss = 0.8057198389655068, disc_loss = 0.11159003537059539
Trained batch 168 in epoch 1, gen_loss = 0.8059444695534791, disc_loss = 0.11114609027667159
Trained batch 169 in epoch 1, gen_loss = 0.805553726939594, disc_loss = 0.11119510415284073
Trained batch 170 in epoch 1, gen_loss = 0.8060181067700971, disc_loss = 0.11183145300251002
Trained batch 171 in epoch 1, gen_loss = 0.8066418122413547, disc_loss = 0.11150034774787897
Trained batch 172 in epoch 1, gen_loss = 0.8055969290650649, disc_loss = 0.11150862015999122
Trained batch 173 in epoch 1, gen_loss = 0.8051008081984246, disc_loss = 0.11144842590665681
Trained batch 174 in epoch 1, gen_loss = 0.8052850900377546, disc_loss = 0.11104089368666921
Trained batch 175 in epoch 1, gen_loss = 0.8072772960771214, disc_loss = 0.11054805861997673
Trained batch 176 in epoch 1, gen_loss = 0.8066839306367992, disc_loss = 0.11020837146473134
Trained batch 177 in epoch 1, gen_loss = 0.805039812004968, disc_loss = 0.1100182496743758
Trained batch 178 in epoch 1, gen_loss = 0.8073251423889032, disc_loss = 0.10959642525117158
Trained batch 179 in epoch 1, gen_loss = 0.8076162325011359, disc_loss = 0.1091551736721562
Trained batch 180 in epoch 1, gen_loss = 0.806908266320413, disc_loss = 0.10906325049122065
Trained batch 181 in epoch 1, gen_loss = 0.8081080959393427, disc_loss = 0.1089785378119284
Trained batch 182 in epoch 1, gen_loss = 0.808373669457566, disc_loss = 0.1089074081471546
Trained batch 183 in epoch 1, gen_loss = 0.8081519202045773, disc_loss = 0.10868634618616299
Trained batch 184 in epoch 1, gen_loss = 0.8068521125896557, disc_loss = 0.10844653167233274
Trained batch 185 in epoch 1, gen_loss = 0.8069003858873921, disc_loss = 0.10808005489368913
Trained batch 186 in epoch 1, gen_loss = 0.8067568872064192, disc_loss = 0.10784348778745388
Trained batch 187 in epoch 1, gen_loss = 0.8068221725047903, disc_loss = 0.107788685520992
Trained batch 188 in epoch 1, gen_loss = 0.807027867546788, disc_loss = 0.10751068127888536
Trained batch 189 in epoch 1, gen_loss = 0.8071456090400093, disc_loss = 0.10721425052340093
Trained batch 190 in epoch 1, gen_loss = 0.8078987857434138, disc_loss = 0.10680458485026946
Trained batch 191 in epoch 1, gen_loss = 0.8071869472041726, disc_loss = 0.10753093082651806
Trained batch 192 in epoch 1, gen_loss = 0.8089217895670876, disc_loss = 0.10751631420704058
Trained batch 193 in epoch 1, gen_loss = 0.809860797272515, disc_loss = 0.10725876353873112
Trained batch 194 in epoch 1, gen_loss = 0.8104994984773489, disc_loss = 0.106880991667127
Trained batch 195 in epoch 1, gen_loss = 0.8085671879199087, disc_loss = 0.10825072936903761
Trained batch 196 in epoch 1, gen_loss = 0.8114855843147045, disc_loss = 0.10881288259805459
Trained batch 197 in epoch 1, gen_loss = 0.8109554178787001, disc_loss = 0.10877192962086862
Trained batch 198 in epoch 1, gen_loss = 0.810792515026265, disc_loss = 0.1086546347836903
Trained batch 199 in epoch 1, gen_loss = 0.8100651630759239, disc_loss = 0.10832988758571446
Trained batch 200 in epoch 1, gen_loss = 0.8094757442450642, disc_loss = 0.10828853740509767
Trained batch 201 in epoch 1, gen_loss = 0.8099411846977649, disc_loss = 0.1080879952371268
Trained batch 202 in epoch 1, gen_loss = 0.8094047995036459, disc_loss = 0.10808038580336887
Trained batch 203 in epoch 1, gen_loss = 0.8088945454242182, disc_loss = 0.10807645307196413
Trained batch 204 in epoch 1, gen_loss = 0.807171957667281, disc_loss = 0.10829362986473048
Trained batch 205 in epoch 1, gen_loss = 0.8060358337406973, disc_loss = 0.10809474989084654
Trained batch 206 in epoch 1, gen_loss = 0.8074994193758942, disc_loss = 0.10870404024091032
Trained batch 207 in epoch 1, gen_loss = 0.8067131048211684, disc_loss = 0.10892735816574153
Trained batch 208 in epoch 1, gen_loss = 0.80702571578003, disc_loss = 0.10925574451863196
Trained batch 209 in epoch 1, gen_loss = 0.805749166295642, disc_loss = 0.10961071764606806
Trained batch 210 in epoch 1, gen_loss = 0.804948454784556, disc_loss = 0.10975276195925276
Trained batch 211 in epoch 1, gen_loss = 0.806138147160692, disc_loss = 0.11009764060694373
Trained batch 212 in epoch 1, gen_loss = 0.8052271408654155, disc_loss = 0.11021328050240944
Trained batch 213 in epoch 1, gen_loss = 0.8042374467738321, disc_loss = 0.11031962451568553
Trained batch 214 in epoch 1, gen_loss = 0.8031237627184669, disc_loss = 0.11060868578768054
Trained batch 215 in epoch 1, gen_loss = 0.8029198080853179, disc_loss = 0.11094968221840207
Trained batch 216 in epoch 1, gen_loss = 0.8032553890883098, disc_loss = 0.1113469692093024
Trained batch 217 in epoch 1, gen_loss = 0.8016474513559166, disc_loss = 0.11230170884844634
Trained batch 218 in epoch 1, gen_loss = 0.8010300641462683, disc_loss = 0.112749604814469
Trained batch 219 in epoch 1, gen_loss = 0.8016216376965696, disc_loss = 0.11328208941796963
Trained batch 220 in epoch 1, gen_loss = 0.8004558203716623, disc_loss = 0.11393839047539019
Trained batch 221 in epoch 1, gen_loss = 0.8000782141545871, disc_loss = 0.11401445956414079
Trained batch 222 in epoch 1, gen_loss = 0.7996652509866808, disc_loss = 0.11439300372762264
Trained batch 223 in epoch 1, gen_loss = 0.7986997284793428, disc_loss = 0.11466624275947522
Trained batch 224 in epoch 1, gen_loss = 0.7988092386722565, disc_loss = 0.11495420556101534
Trained batch 225 in epoch 1, gen_loss = 0.798902011682502, disc_loss = 0.11469985718583375
Trained batch 226 in epoch 1, gen_loss = 0.7979919835596883, disc_loss = 0.11480863099417235
Trained batch 227 in epoch 1, gen_loss = 0.7975149121985101, disc_loss = 0.11486567369776599
Trained batch 228 in epoch 1, gen_loss = 0.7978332619219368, disc_loss = 0.11545409954368548
Trained batch 229 in epoch 1, gen_loss = 0.7968341333710629, disc_loss = 0.11575867387101701
Trained batch 230 in epoch 1, gen_loss = 0.7960763224017569, disc_loss = 0.1157357884869302
Trained batch 231 in epoch 1, gen_loss = 0.7956579881238526, disc_loss = 0.11590662148203058
Trained batch 232 in epoch 1, gen_loss = 0.7957129282756936, disc_loss = 0.11581476767399536
Trained batch 233 in epoch 1, gen_loss = 0.7956758089299895, disc_loss = 0.11573317834040803
Trained batch 234 in epoch 1, gen_loss = 0.7952755031433512, disc_loss = 0.11567797552239388
Trained batch 235 in epoch 1, gen_loss = 0.7943589158229909, disc_loss = 0.11569622151900903
Trained batch 236 in epoch 1, gen_loss = 0.7929706997257747, disc_loss = 0.11592494189456294
Trained batch 237 in epoch 1, gen_loss = 0.7927994230965606, disc_loss = 0.11574149944921251
Trained batch 238 in epoch 1, gen_loss = 0.7926915014887455, disc_loss = 0.11563609586444111
Trained batch 239 in epoch 1, gen_loss = 0.7929675920555989, disc_loss = 0.11558375590636084
Trained batch 240 in epoch 1, gen_loss = 0.7931396702760483, disc_loss = 0.11559789234393612
Trained batch 241 in epoch 1, gen_loss = 0.7933845102540718, disc_loss = 0.11550469086159112
Trained batch 242 in epoch 1, gen_loss = 0.793882300456365, disc_loss = 0.11647268227558323
Trained batch 243 in epoch 1, gen_loss = 0.7930689142619978, disc_loss = 0.11699152792055832
Trained batch 244 in epoch 1, gen_loss = 0.792469912524126, disc_loss = 0.11716952827968159
Trained batch 245 in epoch 1, gen_loss = 0.7931830867276928, disc_loss = 0.11747704536419332
Trained batch 246 in epoch 1, gen_loss = 0.7934713483098065, disc_loss = 0.11749730735021806
Trained batch 247 in epoch 1, gen_loss = 0.7929018523183561, disc_loss = 0.11740417116802306
Trained batch 248 in epoch 1, gen_loss = 0.7920083323396353, disc_loss = 0.11738856462200722
Trained batch 249 in epoch 1, gen_loss = 0.7931036761999131, disc_loss = 0.1172184786722064
Trained batch 250 in epoch 1, gen_loss = 0.7931737813104196, disc_loss = 0.11723603705218825
Trained batch 251 in epoch 1, gen_loss = 0.7932945980675636, disc_loss = 0.11690442446648838
Trained batch 252 in epoch 1, gen_loss = 0.7936149504580516, disc_loss = 0.11716009104410886
Trained batch 253 in epoch 1, gen_loss = 0.7935952777702977, disc_loss = 0.11698132811304857
Trained batch 254 in epoch 1, gen_loss = 0.7939713526005838, disc_loss = 0.11674793157361302
Trained batch 255 in epoch 1, gen_loss = 0.7941121814073995, disc_loss = 0.11649081030191155
Trained batch 256 in epoch 1, gen_loss = 0.7936882584243433, disc_loss = 0.11658362204259703
Trained batch 257 in epoch 1, gen_loss = 0.7934647961411365, disc_loss = 0.1164496556112124
Trained batch 258 in epoch 1, gen_loss = 0.7929884260915881, disc_loss = 0.11641373503305967
Trained batch 259 in epoch 1, gen_loss = 0.7943341967004997, disc_loss = 0.11665788204767383
Trained batch 260 in epoch 1, gen_loss = 0.7941503484815473, disc_loss = 0.11666877825398327
Trained batch 261 in epoch 1, gen_loss = 0.7937044359117974, disc_loss = 0.11671844313191321
Trained batch 262 in epoch 1, gen_loss = 0.7933283961544472, disc_loss = 0.11653811184993941
Trained batch 263 in epoch 1, gen_loss = 0.7937433136006197, disc_loss = 0.11661895362406292
Trained batch 264 in epoch 1, gen_loss = 0.7934248446293597, disc_loss = 0.11661033830693308
Trained batch 265 in epoch 1, gen_loss = 0.7937164157629013, disc_loss = 0.11642800697958783
Trained batch 266 in epoch 1, gen_loss = 0.7941006820523338, disc_loss = 0.1164758750743299
Trained batch 267 in epoch 1, gen_loss = 0.7936098687906763, disc_loss = 0.11699646183831701
Trained batch 268 in epoch 1, gen_loss = 0.7947354220324733, disc_loss = 0.117043631954541
Trained batch 269 in epoch 1, gen_loss = 0.7950862115180051, disc_loss = 0.1169892954122689
Trained batch 270 in epoch 1, gen_loss = 0.7938737902254196, disc_loss = 0.11702287368256448
Trained batch 271 in epoch 1, gen_loss = 0.7934936168877518, disc_loss = 0.11698597229277606
Trained batch 272 in epoch 1, gen_loss = 0.7942355325370482, disc_loss = 0.1167224175586696
Trained batch 273 in epoch 1, gen_loss = 0.795897532118498, disc_loss = 0.1166777193315164
Trained batch 274 in epoch 1, gen_loss = 0.7948678181388161, disc_loss = 0.11754215502603488
Trained batch 275 in epoch 1, gen_loss = 0.794626666151959, disc_loss = 0.11775223480915462
Trained batch 276 in epoch 1, gen_loss = 0.7953503900056281, disc_loss = 0.11790839625045066
Trained batch 277 in epoch 1, gen_loss = 0.7956873227795251, disc_loss = 0.11775614618049036
Trained batch 278 in epoch 1, gen_loss = 0.7948099643953385, disc_loss = 0.11782573630172079
Trained batch 279 in epoch 1, gen_loss = 0.7948625189917428, disc_loss = 0.11790293425188533
Trained batch 280 in epoch 1, gen_loss = 0.7947954138827069, disc_loss = 0.11791041694263335
Trained batch 281 in epoch 1, gen_loss = 0.7952780026070615, disc_loss = 0.11834417013385405
Trained batch 282 in epoch 1, gen_loss = 0.7941845306869951, disc_loss = 0.11897153288204973
Trained batch 283 in epoch 1, gen_loss = 0.7942095055756434, disc_loss = 0.11875731956449823
Trained batch 284 in epoch 1, gen_loss = 0.7940682060885847, disc_loss = 0.11882661765996824
Trained batch 285 in epoch 1, gen_loss = 0.7937236356360096, disc_loss = 0.11917911570883923
Trained batch 286 in epoch 1, gen_loss = 0.7930690211078432, disc_loss = 0.11975506547098584
Trained batch 287 in epoch 1, gen_loss = 0.7926075325037042, disc_loss = 0.11947538599553001
Trained batch 288 in epoch 1, gen_loss = 0.7931079104491171, disc_loss = 0.1192882186233688
Trained batch 289 in epoch 1, gen_loss = 0.792452063950999, disc_loss = 0.11935154969707645
Trained batch 290 in epoch 1, gen_loss = 0.7921297772438666, disc_loss = 0.11934614403627787
Trained batch 291 in epoch 1, gen_loss = 0.7915427479637812, disc_loss = 0.11928962762403773
Trained batch 292 in epoch 1, gen_loss = 0.7917913612448721, disc_loss = 0.11946376771014501
Trained batch 293 in epoch 1, gen_loss = 0.7915001431492721, disc_loss = 0.11946503482885709
Trained batch 294 in epoch 1, gen_loss = 0.7913405863915459, disc_loss = 0.11934084277915752
Trained batch 295 in epoch 1, gen_loss = 0.7909480817615986, disc_loss = 0.11928299408582216
Trained batch 296 in epoch 1, gen_loss = 0.7902661861996056, disc_loss = 0.11932634988091008
Trained batch 297 in epoch 1, gen_loss = 0.7898429503176836, disc_loss = 0.11940509432789263
Trained batch 298 in epoch 1, gen_loss = 0.7900037202348678, disc_loss = 0.11914372347594304
Trained batch 299 in epoch 1, gen_loss = 0.7905140289664269, disc_loss = 0.11901598839089274
Trained batch 300 in epoch 1, gen_loss = 0.7896660975245542, disc_loss = 0.11942537671629574
Trained batch 301 in epoch 1, gen_loss = 0.7902509209928134, disc_loss = 0.120011050408299
Trained batch 302 in epoch 1, gen_loss = 0.7901427904174666, disc_loss = 0.1197454871628249
Trained batch 303 in epoch 1, gen_loss = 0.7890624230433452, disc_loss = 0.11995387448022436
Trained batch 304 in epoch 1, gen_loss = 0.7892158919670543, disc_loss = 0.11968875879757716
Trained batch 305 in epoch 1, gen_loss = 0.7898401196291244, disc_loss = 0.11955850401564556
Trained batch 306 in epoch 1, gen_loss = 0.78996298377211, disc_loss = 0.11941453254499536
Trained batch 307 in epoch 1, gen_loss = 0.7896537355981864, disc_loss = 0.11957672188155256
Trained batch 308 in epoch 1, gen_loss = 0.7898925727046423, disc_loss = 0.11989835356166255
Trained batch 309 in epoch 1, gen_loss = 0.790322581702663, disc_loss = 0.11991544291977921
Trained batch 310 in epoch 1, gen_loss = 0.7898993774817304, disc_loss = 0.12005970958272935
Trained batch 311 in epoch 1, gen_loss = 0.7902409696999269, disc_loss = 0.11990779772615777
Trained batch 312 in epoch 1, gen_loss = 0.7898769446264822, disc_loss = 0.11988168050901006
Trained batch 313 in epoch 1, gen_loss = 0.7894137584289928, disc_loss = 0.11994450445031854
Trained batch 314 in epoch 1, gen_loss = 0.7893363370781853, disc_loss = 0.11983376103379424
Trained batch 315 in epoch 1, gen_loss = 0.7889155844532991, disc_loss = 0.11973430745044275
Trained batch 316 in epoch 1, gen_loss = 0.7879742217552774, disc_loss = 0.11977222388498603
Trained batch 317 in epoch 1, gen_loss = 0.7884481096605085, disc_loss = 0.11989614335269486
Trained batch 318 in epoch 1, gen_loss = 0.7882370975884524, disc_loss = 0.11964700808369066
Trained batch 319 in epoch 1, gen_loss = 0.7874771437607706, disc_loss = 0.11974443626240827
Trained batch 320 in epoch 1, gen_loss = 0.7884141023842345, disc_loss = 0.11974028728298866
Trained batch 321 in epoch 1, gen_loss = 0.7887787538470689, disc_loss = 0.1195073035713401
Trained batch 322 in epoch 1, gen_loss = 0.7885731258444003, disc_loss = 0.11988854302733491
Trained batch 323 in epoch 1, gen_loss = 0.788649768833025, disc_loss = 0.1197598429431242
Trained batch 324 in epoch 1, gen_loss = 0.7891821282643539, disc_loss = 0.1197196832127296
Trained batch 325 in epoch 1, gen_loss = 0.7890272552798863, disc_loss = 0.11975776409284651
Trained batch 326 in epoch 1, gen_loss = 0.7888571865150323, disc_loss = 0.11990822483116151
Trained batch 327 in epoch 1, gen_loss = 0.7896826062805768, disc_loss = 0.12052726964239122
Trained batch 328 in epoch 1, gen_loss = 0.7892316077074382, disc_loss = 0.12048066025288452
Trained batch 329 in epoch 1, gen_loss = 0.7885402488889116, disc_loss = 0.12047126634667317
Trained batch 330 in epoch 1, gen_loss = 0.788915794871725, disc_loss = 0.12042470841902081
Trained batch 331 in epoch 1, gen_loss = 0.7885135736271559, disc_loss = 0.1203203014636704
Trained batch 332 in epoch 1, gen_loss = 0.7880137400763171, disc_loss = 0.12034188967768673
Trained batch 333 in epoch 1, gen_loss = 0.7877358705876116, disc_loss = 0.12023660695057607
Trained batch 334 in epoch 1, gen_loss = 0.7880329570663509, disc_loss = 0.12012712299934963
Trained batch 335 in epoch 1, gen_loss = 0.7875190369252648, disc_loss = 0.12000231625002232
Trained batch 336 in epoch 1, gen_loss = 0.7870692761963128, disc_loss = 0.11993347763329833
Trained batch 337 in epoch 1, gen_loss = 0.7871151637925199, disc_loss = 0.11981331930115555
Trained batch 338 in epoch 1, gen_loss = 0.786977309480881, disc_loss = 0.11968975824614365
Trained batch 339 in epoch 1, gen_loss = 0.7874994511989987, disc_loss = 0.11951036220416426
Trained batch 340 in epoch 1, gen_loss = 0.7883671535250029, disc_loss = 0.11934696019373157
Trained batch 341 in epoch 1, gen_loss = 0.7883047293327008, disc_loss = 0.11948395149553553
Trained batch 342 in epoch 1, gen_loss = 0.788280607225596, disc_loss = 0.11930511002876842
Trained batch 343 in epoch 1, gen_loss = 0.7883621952388176, disc_loss = 0.1190950806891589
Trained batch 344 in epoch 1, gen_loss = 0.7884933892367543, disc_loss = 0.11913022714788499
Trained batch 345 in epoch 1, gen_loss = 0.7878804464388445, disc_loss = 0.11917961987995171
Trained batch 346 in epoch 1, gen_loss = 0.7876933996031539, disc_loss = 0.11939782759319637
Trained batch 347 in epoch 1, gen_loss = 0.7876593187108807, disc_loss = 0.11932563429013238
Trained batch 348 in epoch 1, gen_loss = 0.7869652247531366, disc_loss = 0.11935389462997203
Trained batch 349 in epoch 1, gen_loss = 0.7863758534193039, disc_loss = 0.11936016843255078
Trained batch 350 in epoch 1, gen_loss = 0.7864528294132646, disc_loss = 0.11941626347983494
Trained batch 351 in epoch 1, gen_loss = 0.7856878761032765, disc_loss = 0.11944183811481873
Trained batch 352 in epoch 1, gen_loss = 0.7858559473209273, disc_loss = 0.11939688164624715
Trained batch 353 in epoch 1, gen_loss = 0.7855006640745421, disc_loss = 0.11923875407668325
Trained batch 354 in epoch 1, gen_loss = 0.7852039527725166, disc_loss = 0.11920165778990363
Trained batch 355 in epoch 1, gen_loss = 0.7863898962903558, disc_loss = 0.11914713045038032
Trained batch 356 in epoch 1, gen_loss = 0.787007839322424, disc_loss = 0.1188584212735504
Trained batch 357 in epoch 1, gen_loss = 0.7866989799551458, disc_loss = 0.11868780604225464
Trained batch 358 in epoch 1, gen_loss = 0.7870034224309629, disc_loss = 0.11845146207278984
Trained batch 359 in epoch 1, gen_loss = 0.7872520083354579, disc_loss = 0.11822359167142875
Trained batch 360 in epoch 1, gen_loss = 0.787106442401944, disc_loss = 0.11834581285570632
Trained batch 361 in epoch 1, gen_loss = 0.7868780736600497, disc_loss = 0.11830808130190681
Trained batch 362 in epoch 1, gen_loss = 0.7862176503524307, disc_loss = 0.11840255257286152
Trained batch 363 in epoch 1, gen_loss = 0.7865867240579574, disc_loss = 0.11848832477027407
Trained batch 364 in epoch 1, gen_loss = 0.7863444351986663, disc_loss = 0.11825725991942294
Trained batch 365 in epoch 1, gen_loss = 0.7861147601910627, disc_loss = 0.1180439905563746
Trained batch 366 in epoch 1, gen_loss = 0.7860238895591664, disc_loss = 0.11796865316376862
Trained batch 367 in epoch 1, gen_loss = 0.7863713774182226, disc_loss = 0.11780757732871595
Trained batch 368 in epoch 1, gen_loss = 0.7861528956308598, disc_loss = 0.1176083185091655
Trained batch 369 in epoch 1, gen_loss = 0.7853286476554098, disc_loss = 0.11802221289458308
Trained batch 370 in epoch 1, gen_loss = 0.7857826499122815, disc_loss = 0.11801958944136402
Trained batch 371 in epoch 1, gen_loss = 0.7858806766008818, disc_loss = 0.11809900463608805
Trained batch 372 in epoch 1, gen_loss = 0.7849802991659968, disc_loss = 0.11838179675427743
Trained batch 373 in epoch 1, gen_loss = 0.7852795224457501, disc_loss = 0.11842083525071967
Trained batch 374 in epoch 1, gen_loss = 0.785837724049886, disc_loss = 0.11815277333557606
Trained batch 375 in epoch 1, gen_loss = 0.7856676935198459, disc_loss = 0.11788492155400046
Trained batch 376 in epoch 1, gen_loss = 0.7850550917478708, disc_loss = 0.1180403633858386
Trained batch 377 in epoch 1, gen_loss = 0.7854854967543687, disc_loss = 0.11801969485662916
Trained batch 378 in epoch 1, gen_loss = 0.7852020419367385, disc_loss = 0.11800216337896903
Trained batch 379 in epoch 1, gen_loss = 0.7854815479956175, disc_loss = 0.11780856439941807
Trained batch 380 in epoch 1, gen_loss = 0.7860592916568746, disc_loss = 0.11757671329488592
Trained batch 381 in epoch 1, gen_loss = 0.7862324365146497, disc_loss = 0.11737442923543966
Trained batch 382 in epoch 1, gen_loss = 0.7855626213955195, disc_loss = 0.11739097057061158
Trained batch 383 in epoch 1, gen_loss = 0.7859779813637336, disc_loss = 0.11734388353458296
Trained batch 384 in epoch 1, gen_loss = 0.7859343191245933, disc_loss = 0.11719369100672858
Trained batch 385 in epoch 1, gen_loss = 0.7857055336700203, disc_loss = 0.11704752450432493
Trained batch 386 in epoch 1, gen_loss = 0.7857321329819139, disc_loss = 0.1168707129509412
Trained batch 387 in epoch 1, gen_loss = 0.7862050875867765, disc_loss = 0.11667638397823597
Trained batch 388 in epoch 1, gen_loss = 0.7864147628487536, disc_loss = 0.11641811328080595
Trained batch 389 in epoch 1, gen_loss = 0.7857999176551134, disc_loss = 0.11662417374646816
Trained batch 390 in epoch 1, gen_loss = 0.7864746762358624, disc_loss = 0.1169674401040501
Trained batch 391 in epoch 1, gen_loss = 0.7867912327756688, disc_loss = 0.11723549116155779
Trained batch 392 in epoch 1, gen_loss = 0.7857379372641634, disc_loss = 0.11808435136864659
Trained batch 393 in epoch 1, gen_loss = 0.7854315562145359, disc_loss = 0.11796333606302889
Trained batch 394 in epoch 1, gen_loss = 0.7860579396350474, disc_loss = 0.11799271536307245
Trained batch 395 in epoch 1, gen_loss = 0.7854061801776742, disc_loss = 0.1179939343951492
Trained batch 396 in epoch 1, gen_loss = 0.785652286534946, disc_loss = 0.11834092497806856
Trained batch 397 in epoch 1, gen_loss = 0.7851224779034379, disc_loss = 0.11869853476165378
Trained batch 398 in epoch 1, gen_loss = 0.7844451089998833, disc_loss = 0.11884273539640401
Trained batch 399 in epoch 1, gen_loss = 0.7847430915385485, disc_loss = 0.11870455478783697
Trained batch 400 in epoch 1, gen_loss = 0.7851574002507321, disc_loss = 0.11873012109940635
Trained batch 401 in epoch 1, gen_loss = 0.7851322423018033, disc_loss = 0.11867908654799361
Trained batch 402 in epoch 1, gen_loss = 0.7846964404689467, disc_loss = 0.11877526897040401
Trained batch 403 in epoch 1, gen_loss = 0.784260265086547, disc_loss = 0.11879680913845354
Trained batch 404 in epoch 1, gen_loss = 0.7839504030751593, disc_loss = 0.11926204800881722
Trained batch 405 in epoch 1, gen_loss = 0.7838148613428247, disc_loss = 0.11934083189558366
Trained batch 406 in epoch 1, gen_loss = 0.7834711468044019, disc_loss = 0.11952120603430623
Trained batch 407 in epoch 1, gen_loss = 0.7833431702764595, disc_loss = 0.11942103603288677
Trained batch 408 in epoch 1, gen_loss = 0.7829831011575126, disc_loss = 0.11937002624068546
Trained batch 409 in epoch 1, gen_loss = 0.7827480049394979, disc_loss = 0.11947484072297812
Trained batch 410 in epoch 1, gen_loss = 0.7824700125957638, disc_loss = 0.1194682834021874
Trained batch 411 in epoch 1, gen_loss = 0.7824251108522554, disc_loss = 0.1194785981963488
Trained batch 412 in epoch 1, gen_loss = 0.7820288382344327, disc_loss = 0.11961218465309022
Trained batch 413 in epoch 1, gen_loss = 0.7820976472275268, disc_loss = 0.11952978163363709
Trained batch 414 in epoch 1, gen_loss = 0.7814568026238177, disc_loss = 0.11956507336931775
Trained batch 415 in epoch 1, gen_loss = 0.7814319567181743, disc_loss = 0.11946887243091343
Trained batch 416 in epoch 1, gen_loss = 0.7817858782746523, disc_loss = 0.11957735112227268
Trained batch 417 in epoch 1, gen_loss = 0.7817412962040833, disc_loss = 0.11942491506150607
Trained batch 418 in epoch 1, gen_loss = 0.781207331822994, disc_loss = 0.11967850823693316
Trained batch 419 in epoch 1, gen_loss = 0.7811507539380165, disc_loss = 0.11968516541112746
Trained batch 420 in epoch 1, gen_loss = 0.7814189524803479, disc_loss = 0.11968787234373869
Trained batch 421 in epoch 1, gen_loss = 0.7809806510594219, disc_loss = 0.11977944188084788
Trained batch 422 in epoch 1, gen_loss = 0.7807253811235405, disc_loss = 0.11968889642709395
Trained batch 423 in epoch 1, gen_loss = 0.7812212877818998, disc_loss = 0.1197405974512463
Trained batch 424 in epoch 1, gen_loss = 0.7809423610042123, disc_loss = 0.11975594496464029
Trained batch 425 in epoch 1, gen_loss = 0.7805999374025864, disc_loss = 0.11968131223912111
Trained batch 426 in epoch 1, gen_loss = 0.7812408096477633, disc_loss = 0.11961598124189315
Trained batch 427 in epoch 1, gen_loss = 0.7810867167661123, disc_loss = 0.11961754554638936
Trained batch 428 in epoch 1, gen_loss = 0.7812883907403702, disc_loss = 0.11949373860268186
Trained batch 429 in epoch 1, gen_loss = 0.7818844477104586, disc_loss = 0.11944930602384861
Trained batch 430 in epoch 1, gen_loss = 0.7815534433051771, disc_loss = 0.11956544691078762
Trained batch 431 in epoch 1, gen_loss = 0.7810163828371851, disc_loss = 0.1196640296364893
Trained batch 432 in epoch 1, gen_loss = 0.7808989243061383, disc_loss = 0.11970537367941463
Trained batch 433 in epoch 1, gen_loss = 0.7809935138659543, disc_loss = 0.11967945121623541
Trained batch 434 in epoch 1, gen_loss = 0.7814538010920601, disc_loss = 0.11973458249764196
Trained batch 435 in epoch 1, gen_loss = 0.7815549217096163, disc_loss = 0.11970226639676668
Trained batch 436 in epoch 1, gen_loss = 0.7812605683672619, disc_loss = 0.11964972704666021
Trained batch 437 in epoch 1, gen_loss = 0.7820163417488473, disc_loss = 0.11966929903262419
Trained batch 438 in epoch 1, gen_loss = 0.7816726449274528, disc_loss = 0.11974510742703576
Trained batch 439 in epoch 1, gen_loss = 0.78188197335059, disc_loss = 0.11954860164445233
Trained batch 440 in epoch 1, gen_loss = 0.7820315279252404, disc_loss = 0.11965243175811643
Trained batch 441 in epoch 1, gen_loss = 0.7814530547522851, disc_loss = 0.11975795541767756
Trained batch 442 in epoch 1, gen_loss = 0.7817175612358154, disc_loss = 0.11959464187496269
Trained batch 443 in epoch 1, gen_loss = 0.7816130918291238, disc_loss = 0.11943754722020244
Trained batch 444 in epoch 1, gen_loss = 0.7825333190098237, disc_loss = 0.11933970036550184
Trained batch 445 in epoch 1, gen_loss = 0.7826044606921919, disc_loss = 0.11923808541416187
Trained batch 446 in epoch 1, gen_loss = 0.782117536337317, disc_loss = 0.11928179350492005
Trained batch 447 in epoch 1, gen_loss = 0.7820065767238182, disc_loss = 0.11913854375598021
Trained batch 448 in epoch 1, gen_loss = 0.782071439155226, disc_loss = 0.1192219002433702
Trained batch 449 in epoch 1, gen_loss = 0.7819913666115866, disc_loss = 0.1195158110683163
Trained batch 450 in epoch 1, gen_loss = 0.7817770218241241, disc_loss = 0.11937094830439123
Trained batch 451 in epoch 1, gen_loss = 0.781523339186622, disc_loss = 0.11946246217919794
Trained batch 452 in epoch 1, gen_loss = 0.7816016253651372, disc_loss = 0.11942854976367871
Trained batch 453 in epoch 1, gen_loss = 0.7816543682162457, disc_loss = 0.11937629571389653
Trained batch 454 in epoch 1, gen_loss = 0.7817228452844934, disc_loss = 0.11922738816138807
Trained batch 455 in epoch 1, gen_loss = 0.7815690179796595, disc_loss = 0.11907896841876209
Trained batch 456 in epoch 1, gen_loss = 0.7818153489470743, disc_loss = 0.11887876936835716
Trained batch 457 in epoch 1, gen_loss = 0.7825344999414344, disc_loss = 0.1188911523580486
Trained batch 458 in epoch 1, gen_loss = 0.7822115219366577, disc_loss = 0.11892377615608031
Trained batch 459 in epoch 1, gen_loss = 0.7816701446538387, disc_loss = 0.11897923035709107
Trained batch 460 in epoch 1, gen_loss = 0.7817049789971747, disc_loss = 0.11894783965532149
Trained batch 461 in epoch 1, gen_loss = 0.7830417407152457, disc_loss = 0.11907135465815341
Trained batch 462 in epoch 1, gen_loss = 0.7825354510841823, disc_loss = 0.11947675264535017
Trained batch 463 in epoch 1, gen_loss = 0.7828595646624935, disc_loss = 0.11942565773115975
Trained batch 464 in epoch 1, gen_loss = 0.7830630005687795, disc_loss = 0.11933433973901375
Trained batch 465 in epoch 1, gen_loss = 0.7828378598705382, disc_loss = 0.11925436071491932
Trained batch 466 in epoch 1, gen_loss = 0.7831619953062601, disc_loss = 0.11908742979695379
Trained batch 467 in epoch 1, gen_loss = 0.783436050081355, disc_loss = 0.11919936913057652
Trained batch 468 in epoch 1, gen_loss = 0.7833766465120987, disc_loss = 0.11921126984441077
Trained batch 469 in epoch 1, gen_loss = 0.7826562317127878, disc_loss = 0.11939818728715182
Trained batch 470 in epoch 1, gen_loss = 0.7832500751104577, disc_loss = 0.11941476697359242
Trained batch 471 in epoch 1, gen_loss = 0.7832462634828131, disc_loss = 0.11936521632360074
Trained batch 472 in epoch 1, gen_loss = 0.7831540779381927, disc_loss = 0.11936989234047636
Trained batch 473 in epoch 1, gen_loss = 0.7830499691047749, disc_loss = 0.11928704121240458
Trained batch 474 in epoch 1, gen_loss = 0.7836436039523075, disc_loss = 0.11929152748694545
Trained batch 475 in epoch 1, gen_loss = 0.7836122693133956, disc_loss = 0.11912834720623468
Trained batch 476 in epoch 1, gen_loss = 0.7835019302068267, disc_loss = 0.11900165191689502
Trained batch 477 in epoch 1, gen_loss = 0.783221874651051, disc_loss = 0.11909523436791852
Trained batch 478 in epoch 1, gen_loss = 0.7834017469639072, disc_loss = 0.11910229756852654
Trained batch 479 in epoch 1, gen_loss = 0.7831827163696289, disc_loss = 0.11900151539981986
Trained batch 480 in epoch 1, gen_loss = 0.7831295112810115, disc_loss = 0.11885599641365593
Trained batch 481 in epoch 1, gen_loss = 0.7834024386039908, disc_loss = 0.11914669763667826
Trained batch 482 in epoch 1, gen_loss = 0.7828666977507234, disc_loss = 0.1192728719533292
Trained batch 483 in epoch 1, gen_loss = 0.7827094660317602, disc_loss = 0.11941214261022358
Trained batch 484 in epoch 1, gen_loss = 0.7832926081627914, disc_loss = 0.11931610704620474
Trained batch 485 in epoch 1, gen_loss = 0.7833874301655303, disc_loss = 0.11924446545495296
Trained batch 486 in epoch 1, gen_loss = 0.783376521276008, disc_loss = 0.11916304295175006
Trained batch 487 in epoch 1, gen_loss = 0.7831491020614983, disc_loss = 0.11906270160278702
Trained batch 488 in epoch 1, gen_loss = 0.7827072673780056, disc_loss = 0.11893093090405371
Trained batch 489 in epoch 1, gen_loss = 0.7830409023226524, disc_loss = 0.11879887417795099
Trained batch 490 in epoch 1, gen_loss = 0.7830469418931638, disc_loss = 0.11879339804702159
Trained batch 491 in epoch 1, gen_loss = 0.7826168894525466, disc_loss = 0.11878695132634867
Trained batch 492 in epoch 1, gen_loss = 0.7820954667385404, disc_loss = 0.11891637557766138
Trained batch 493 in epoch 1, gen_loss = 0.7828459453727552, disc_loss = 0.11920647491674553
Trained batch 494 in epoch 1, gen_loss = 0.7827202865571686, disc_loss = 0.11912650190143272
Trained batch 495 in epoch 1, gen_loss = 0.7824039899053112, disc_loss = 0.11905102354789814
Trained batch 496 in epoch 1, gen_loss = 0.7821031804055995, disc_loss = 0.11903912798544651
Trained batch 497 in epoch 1, gen_loss = 0.781897886689887, disc_loss = 0.1188763937609921
Trained batch 498 in epoch 1, gen_loss = 0.7819575776079136, disc_loss = 0.11877863480520989
Trained batch 499 in epoch 1, gen_loss = 0.7824878199100495, disc_loss = 0.11887055717036128
Trained batch 500 in epoch 1, gen_loss = 0.7823989239043581, disc_loss = 0.1188036214798213
Trained batch 501 in epoch 1, gen_loss = 0.781940513754271, disc_loss = 0.11895762245538107
Trained batch 502 in epoch 1, gen_loss = 0.7819451766744049, disc_loss = 0.11934619292868653
Trained batch 503 in epoch 1, gen_loss = 0.7817541224852441, disc_loss = 0.11939774673535591
Trained batch 504 in epoch 1, gen_loss = 0.7814512638762445, disc_loss = 0.11949641325022324
Trained batch 505 in epoch 1, gen_loss = 0.7813876724761465, disc_loss = 0.1195377876923195
Trained batch 506 in epoch 1, gen_loss = 0.7817489989175364, disc_loss = 0.11950797084682203
Trained batch 507 in epoch 1, gen_loss = 0.7813444184506033, disc_loss = 0.11944331524629645
Trained batch 508 in epoch 1, gen_loss = 0.7810902245386645, disc_loss = 0.11934206921292546
Trained batch 509 in epoch 1, gen_loss = 0.7807961532882616, disc_loss = 0.11934478580586466
Trained batch 510 in epoch 1, gen_loss = 0.7810905168667698, disc_loss = 0.11926153182268959
Trained batch 511 in epoch 1, gen_loss = 0.7811583483126014, disc_loss = 0.11919522337484523
Trained batch 512 in epoch 1, gen_loss = 0.7810732240100585, disc_loss = 0.11905975005504099
Trained batch 513 in epoch 1, gen_loss = 0.7806436964510016, disc_loss = 0.11911199739427535
Trained batch 514 in epoch 1, gen_loss = 0.7809097728682953, disc_loss = 0.11899615847731679
Trained batch 515 in epoch 1, gen_loss = 0.7815461762884791, disc_loss = 0.11880446684207449
Trained batch 516 in epoch 1, gen_loss = 0.7816544350387972, disc_loss = 0.11863346839219159
Trained batch 517 in epoch 1, gen_loss = 0.7812934181865118, disc_loss = 0.11884782964212669
Trained batch 518 in epoch 1, gen_loss = 0.7816414513799267, disc_loss = 0.11883282811095604
Trained batch 519 in epoch 1, gen_loss = 0.7816506028175354, disc_loss = 0.11868508564523206
Trained batch 520 in epoch 1, gen_loss = 0.7819854436360028, disc_loss = 0.11855147908765272
Trained batch 521 in epoch 1, gen_loss = 0.7820784553485812, disc_loss = 0.11845437101520227
Trained batch 522 in epoch 1, gen_loss = 0.781564606649242, disc_loss = 0.1186052388253392
Trained batch 523 in epoch 1, gen_loss = 0.7821689569995603, disc_loss = 0.1186512325435365
Trained batch 524 in epoch 1, gen_loss = 0.7820447651545207, disc_loss = 0.11856074730200426
Trained batch 525 in epoch 1, gen_loss = 0.7819190171508281, disc_loss = 0.11859163686902237
Trained batch 526 in epoch 1, gen_loss = 0.7821865041070464, disc_loss = 0.11892442119288377
Trained batch 527 in epoch 1, gen_loss = 0.7820274825348998, disc_loss = 0.11896619920012061
Trained batch 528 in epoch 1, gen_loss = 0.7823280666185461, disc_loss = 0.11893553875161367
Trained batch 529 in epoch 1, gen_loss = 0.7825184097829855, disc_loss = 0.11879398515272253
Trained batch 530 in epoch 1, gen_loss = 0.7822363057827995, disc_loss = 0.11881997085855169
Trained batch 531 in epoch 1, gen_loss = 0.7824676998127672, disc_loss = 0.11867425053317408
Trained batch 532 in epoch 1, gen_loss = 0.7825494132390837, disc_loss = 0.11854809806743326
Trained batch 533 in epoch 1, gen_loss = 0.7825775121928155, disc_loss = 0.11856463218407796
Trained batch 534 in epoch 1, gen_loss = 0.7821957211628139, disc_loss = 0.1185462206358386
Trained batch 535 in epoch 1, gen_loss = 0.782135506730471, disc_loss = 0.11847747082877626
Trained batch 536 in epoch 1, gen_loss = 0.7819186974060158, disc_loss = 0.11841700587151104
Trained batch 537 in epoch 1, gen_loss = 0.7822763498830972, disc_loss = 0.11827272904836002
Trained batch 538 in epoch 1, gen_loss = 0.7821917440984156, disc_loss = 0.11812037388156539
Trained batch 539 in epoch 1, gen_loss = 0.7820348768322556, disc_loss = 0.1181322172663554
Trained batch 540 in epoch 1, gen_loss = 0.7822778443091458, disc_loss = 0.11813602330380028
Trained batch 541 in epoch 1, gen_loss = 0.782113874310497, disc_loss = 0.11811976021712446
Trained batch 542 in epoch 1, gen_loss = 0.7819079825891315, disc_loss = 0.11816082348357577
Trained batch 543 in epoch 1, gen_loss = 0.7821717194336302, disc_loss = 0.11805810972103192
Trained batch 544 in epoch 1, gen_loss = 0.7822565551197856, disc_loss = 0.11814091171078178
Trained batch 545 in epoch 1, gen_loss = 0.7818158164129152, disc_loss = 0.11824381136891497
Trained batch 546 in epoch 1, gen_loss = 0.7815820902749433, disc_loss = 0.11822307462271106
Trained batch 547 in epoch 1, gen_loss = 0.7820074577836225, disc_loss = 0.11853684543081335
Trained batch 548 in epoch 1, gen_loss = 0.7821549471393092, disc_loss = 0.11844256016441056
Trained batch 549 in epoch 1, gen_loss = 0.7815786692229184, disc_loss = 0.1186368473924019
Trained batch 550 in epoch 1, gen_loss = 0.7815572833625462, disc_loss = 0.11878107459421275
Trained batch 551 in epoch 1, gen_loss = 0.7814605499523274, disc_loss = 0.11878828411125511
Trained batch 552 in epoch 1, gen_loss = 0.7811943933933596, disc_loss = 0.1187600072769694
Trained batch 553 in epoch 1, gen_loss = 0.7811829516603628, disc_loss = 0.11888578248677593
Trained batch 554 in epoch 1, gen_loss = 0.7809487110859639, disc_loss = 0.11880126980443796
Trained batch 555 in epoch 1, gen_loss = 0.7808035940146275, disc_loss = 0.11883897429144533
Trained batch 556 in epoch 1, gen_loss = 0.7805414902885683, disc_loss = 0.11880674175383052
Trained batch 557 in epoch 1, gen_loss = 0.7812490690779942, disc_loss = 0.11894785942289457
Trained batch 558 in epoch 1, gen_loss = 0.7810870928286653, disc_loss = 0.11901036844203958
Trained batch 559 in epoch 1, gen_loss = 0.7807842076889107, disc_loss = 0.11902204686443188
Trained batch 560 in epoch 1, gen_loss = 0.7806230472158409, disc_loss = 0.11899427925825863
Trained batch 561 in epoch 1, gen_loss = 0.7815002354650735, disc_loss = 0.11924781040139364
Trained batch 562 in epoch 1, gen_loss = 0.7811911850373656, disc_loss = 0.11935934977238703
Trained batch 563 in epoch 1, gen_loss = 0.7813771634448504, disc_loss = 0.11941734143592259
Trained batch 564 in epoch 1, gen_loss = 0.7810475508723639, disc_loss = 0.1193694855622222
Trained batch 565 in epoch 1, gen_loss = 0.7810948260470751, disc_loss = 0.11927291174014444
Trained batch 566 in epoch 1, gen_loss = 0.7810708796326236, disc_loss = 0.11921229240742415
Trained batch 567 in epoch 1, gen_loss = 0.781351903374766, disc_loss = 0.11924225298858339
Trained batch 568 in epoch 1, gen_loss = 0.7811985606677921, disc_loss = 0.11920821985887832
Trained batch 569 in epoch 1, gen_loss = 0.7812127656058261, disc_loss = 0.11917005596649752
Trained batch 570 in epoch 1, gen_loss = 0.7809402612796389, disc_loss = 0.11922890143289562
Trained batch 571 in epoch 1, gen_loss = 0.7810480613391716, disc_loss = 0.11923496228141281
Trained batch 572 in epoch 1, gen_loss = 0.780660155868031, disc_loss = 0.11920743055615646
Trained batch 573 in epoch 1, gen_loss = 0.7803315963686966, disc_loss = 0.11916915452893083
Trained batch 574 in epoch 1, gen_loss = 0.7801854362695113, disc_loss = 0.11919392809595751
Trained batch 575 in epoch 1, gen_loss = 0.7804628751344151, disc_loss = 0.11914834052570061
Trained batch 576 in epoch 1, gen_loss = 0.7809383681163424, disc_loss = 0.11928976437906562
Trained batch 577 in epoch 1, gen_loss = 0.7806116121862999, disc_loss = 0.1193935445068359
Trained batch 578 in epoch 1, gen_loss = 0.7804930566300177, disc_loss = 0.11937459602964871
Trained batch 579 in epoch 1, gen_loss = 0.7806254257415903, disc_loss = 0.11926207985279375
Trained batch 580 in epoch 1, gen_loss = 0.7805535964629325, disc_loss = 0.11918147627373263
Trained batch 581 in epoch 1, gen_loss = 0.7801820057159436, disc_loss = 0.11913919771134955
Trained batch 582 in epoch 1, gen_loss = 0.7804999317762986, disc_loss = 0.11914598127414902
Trained batch 583 in epoch 1, gen_loss = 0.7802553461634949, disc_loss = 0.11916927453321852
Trained batch 584 in epoch 1, gen_loss = 0.7803215553617885, disc_loss = 0.11903373482836108
Trained batch 585 in epoch 1, gen_loss = 0.7803149716642529, disc_loss = 0.11897108328461953
Trained batch 586 in epoch 1, gen_loss = 0.7803930299042436, disc_loss = 0.1189123626633387
Trained batch 587 in epoch 1, gen_loss = 0.7800300659573808, disc_loss = 0.1189401477644993
Trained batch 588 in epoch 1, gen_loss = 0.7799319612757257, disc_loss = 0.11903022634140603
Trained batch 589 in epoch 1, gen_loss = 0.7795841007919635, disc_loss = 0.11909495811530595
Trained batch 590 in epoch 1, gen_loss = 0.7798184268365657, disc_loss = 0.1191503270395264
Trained batch 591 in epoch 1, gen_loss = 0.7799163989319995, disc_loss = 0.11900424550451036
Trained batch 592 in epoch 1, gen_loss = 0.7798788435945624, disc_loss = 0.11893302296142252
Trained batch 593 in epoch 1, gen_loss = 0.7796818645112844, disc_loss = 0.11887043751838934
Trained batch 594 in epoch 1, gen_loss = 0.7796678516043335, disc_loss = 0.1188827486567888
Trained batch 595 in epoch 1, gen_loss = 0.7793807187336403, disc_loss = 0.11881427419053128
Trained batch 596 in epoch 1, gen_loss = 0.7797307315184243, disc_loss = 0.11870756507905783
Trained batch 597 in epoch 1, gen_loss = 0.7800340349458931, disc_loss = 0.11857824711234972
Trained batch 598 in epoch 1, gen_loss = 0.7799401100171428, disc_loss = 0.11855057615457174
Trained batch 599 in epoch 1, gen_loss = 0.7799316892027854, disc_loss = 0.11844386382338902
Trained batch 600 in epoch 1, gen_loss = 0.7797081499250479, disc_loss = 0.11837906830211149
Trained batch 601 in epoch 1, gen_loss = 0.7794934644849594, disc_loss = 0.1183668404811393
Trained batch 602 in epoch 1, gen_loss = 0.7803104974539521, disc_loss = 0.11855520316357933
Trained batch 603 in epoch 1, gen_loss = 0.7801305465153511, disc_loss = 0.11862196680466762
Trained batch 604 in epoch 1, gen_loss = 0.7803261357890673, disc_loss = 0.11856836739096267
Trained batch 605 in epoch 1, gen_loss = 0.7804035588656322, disc_loss = 0.11857096748518767
Trained batch 606 in epoch 1, gen_loss = 0.780211079749087, disc_loss = 0.11846746760535574
Trained batch 607 in epoch 1, gen_loss = 0.7803232600226214, disc_loss = 0.11836309076323615
Trained batch 608 in epoch 1, gen_loss = 0.780504949476527, disc_loss = 0.11835284475757081
Trained batch 609 in epoch 1, gen_loss = 0.7804963409900665, disc_loss = 0.11842738451955259
Trained batch 610 in epoch 1, gen_loss = 0.7807740433516557, disc_loss = 0.1184768535154102
Trained batch 611 in epoch 1, gen_loss = 0.7804863135409511, disc_loss = 0.11848531698418502
Trained batch 612 in epoch 1, gen_loss = 0.7807725319854587, disc_loss = 0.11858171850236264
Trained batch 613 in epoch 1, gen_loss = 0.7808254289316432, disc_loss = 0.11846557681536733
Trained batch 614 in epoch 1, gen_loss = 0.7807291206305589, disc_loss = 0.11841275589919187
Trained batch 615 in epoch 1, gen_loss = 0.7807571806690909, disc_loss = 0.11837856616377347
Trained batch 616 in epoch 1, gen_loss = 0.7810033164688989, disc_loss = 0.11831915565438847
Trained batch 617 in epoch 1, gen_loss = 0.7813687036145467, disc_loss = 0.11820173843139872
Trained batch 618 in epoch 1, gen_loss = 0.7815756653352778, disc_loss = 0.11807260252174248
Trained batch 619 in epoch 1, gen_loss = 0.7813996567841499, disc_loss = 0.11802880040880653
Trained batch 620 in epoch 1, gen_loss = 0.7815740655585763, disc_loss = 0.11794710392357359
Trained batch 621 in epoch 1, gen_loss = 0.7814629900110496, disc_loss = 0.11788497143200452
Trained batch 622 in epoch 1, gen_loss = 0.7813808666377734, disc_loss = 0.11780656164102436
Trained batch 623 in epoch 1, gen_loss = 0.7812932471816356, disc_loss = 0.11779554915698007
Trained batch 624 in epoch 1, gen_loss = 0.7813585634231568, disc_loss = 0.11774978350698947
Trained batch 625 in epoch 1, gen_loss = 0.7819082272319368, disc_loss = 0.11767763760202704
Trained batch 626 in epoch 1, gen_loss = 0.7821149437241197, disc_loss = 0.11754716499344679
Trained batch 627 in epoch 1, gen_loss = 0.7818744363868313, disc_loss = 0.11744825927255924
Trained batch 628 in epoch 1, gen_loss = 0.7828649620752077, disc_loss = 0.11744694455285425
Trained batch 629 in epoch 1, gen_loss = 0.7825938507678016, disc_loss = 0.11756717066857077
Trained batch 630 in epoch 1, gen_loss = 0.7827652225214782, disc_loss = 0.11749521459610734
Trained batch 631 in epoch 1, gen_loss = 0.7836788552282732, disc_loss = 0.1174234716734507
Trained batch 632 in epoch 1, gen_loss = 0.7837724151769521, disc_loss = 0.11733186651921668
Trained batch 633 in epoch 1, gen_loss = 0.7838754744183754, disc_loss = 0.11718307833895322
Trained batch 634 in epoch 1, gen_loss = 0.7846165311618114, disc_loss = 0.1170956307978142
Trained batch 635 in epoch 1, gen_loss = 0.7849955316984428, disc_loss = 0.11693905113827226
Trained batch 636 in epoch 1, gen_loss = 0.7850884554711766, disc_loss = 0.11682952796891215
Trained batch 637 in epoch 1, gen_loss = 0.7851646299646192, disc_loss = 0.11668021017014046
Trained batch 638 in epoch 1, gen_loss = 0.7854800696290901, disc_loss = 0.11651512583446615
Trained batch 639 in epoch 1, gen_loss = 0.7855161795392632, disc_loss = 0.11646708477637731
Trained batch 640 in epoch 1, gen_loss = 0.7852458019338421, disc_loss = 0.11650532729888854
Trained batch 641 in epoch 1, gen_loss = 0.7849357633204475, disc_loss = 0.11647043409075507
Trained batch 642 in epoch 1, gen_loss = 0.7852571591804409, disc_loss = 0.1164594169989993
Trained batch 643 in epoch 1, gen_loss = 0.7851930874289933, disc_loss = 0.11645092897880707
Trained batch 644 in epoch 1, gen_loss = 0.7851792188577874, disc_loss = 0.11632205532618271
Trained batch 645 in epoch 1, gen_loss = 0.7849912371244224, disc_loss = 0.1162568557107873
Trained batch 646 in epoch 1, gen_loss = 0.7853540337804296, disc_loss = 0.11617117953217564
Trained batch 647 in epoch 1, gen_loss = 0.7850149176370951, disc_loss = 0.11625996079111908
Trained batch 648 in epoch 1, gen_loss = 0.7852447381923305, disc_loss = 0.11622686165231402
Trained batch 649 in epoch 1, gen_loss = 0.7854506219350375, disc_loss = 0.11620602309703827
Trained batch 650 in epoch 1, gen_loss = 0.7851050351438801, disc_loss = 0.11630434601262968
Trained batch 651 in epoch 1, gen_loss = 0.7849521753063963, disc_loss = 0.11627572426355325
Trained batch 652 in epoch 1, gen_loss = 0.7857206071317653, disc_loss = 0.1163039377121794
Trained batch 653 in epoch 1, gen_loss = 0.7858271279830816, disc_loss = 0.11620829769891519
Trained batch 654 in epoch 1, gen_loss = 0.7856074117522204, disc_loss = 0.11623083726709126
Trained batch 655 in epoch 1, gen_loss = 0.7859241143777603, disc_loss = 0.11641908896428238
Trained batch 656 in epoch 1, gen_loss = 0.785456779385992, disc_loss = 0.1165750113399515
Trained batch 657 in epoch 1, gen_loss = 0.7850621000702258, disc_loss = 0.11659484916567621
Trained batch 658 in epoch 1, gen_loss = 0.7854940779563689, disc_loss = 0.11707993333930311
Trained batch 659 in epoch 1, gen_loss = 0.785238363209999, disc_loss = 0.1171248031667236
Trained batch 660 in epoch 1, gen_loss = 0.7853576779455713, disc_loss = 0.1171201880113891
Trained batch 661 in epoch 1, gen_loss = 0.7855734110688876, disc_loss = 0.11717968243329006
Trained batch 662 in epoch 1, gen_loss = 0.7852474311268347, disc_loss = 0.11721484464780058
Trained batch 663 in epoch 1, gen_loss = 0.7850963054561472, disc_loss = 0.1172691025344812
Trained batch 664 in epoch 1, gen_loss = 0.785048321449667, disc_loss = 0.11731380399568636
Trained batch 665 in epoch 1, gen_loss = 0.7847958312288776, disc_loss = 0.11726409449121794
Trained batch 666 in epoch 1, gen_loss = 0.7850322540642797, disc_loss = 0.11718311297638842
Trained batch 667 in epoch 1, gen_loss = 0.785370331993717, disc_loss = 0.11706709151831038
Trained batch 668 in epoch 1, gen_loss = 0.7850588499074204, disc_loss = 0.11713376382340765
Trained batch 669 in epoch 1, gen_loss = 0.7849463199056796, disc_loss = 0.1170800229006294
Trained batch 670 in epoch 1, gen_loss = 0.784792905548468, disc_loss = 0.11720771776115307
Trained batch 671 in epoch 1, gen_loss = 0.7852325174691421, disc_loss = 0.11707176035824454
Trained batch 672 in epoch 1, gen_loss = 0.785421910071621, disc_loss = 0.11698495184263716
Trained batch 673 in epoch 1, gen_loss = 0.7858833006917546, disc_loss = 0.11693352324340923
Trained batch 674 in epoch 1, gen_loss = 0.7856901316731064, disc_loss = 0.11683262067260565
Trained batch 675 in epoch 1, gen_loss = 0.7854015456413376, disc_loss = 0.11684249173408959
Trained batch 676 in epoch 1, gen_loss = 0.7854564428945764, disc_loss = 0.11692208896337443
Trained batch 677 in epoch 1, gen_loss = 0.7855969216883358, disc_loss = 0.11678700827084108
Trained batch 678 in epoch 1, gen_loss = 0.7855314333677643, disc_loss = 0.11671389869807922
Trained batch 679 in epoch 1, gen_loss = 0.7857445766382357, disc_loss = 0.11666972499121638
Trained batch 680 in epoch 1, gen_loss = 0.7863010397829148, disc_loss = 0.11656784020068887
Trained batch 681 in epoch 1, gen_loss = 0.7862176497048996, disc_loss = 0.11655563146662502
Trained batch 682 in epoch 1, gen_loss = 0.7864505289501537, disc_loss = 0.11650131653727061
Trained batch 683 in epoch 1, gen_loss = 0.7862731109847102, disc_loss = 0.11644234240316508
Trained batch 684 in epoch 1, gen_loss = 0.7858843784697734, disc_loss = 0.11653082159748912
Trained batch 685 in epoch 1, gen_loss = 0.7860063016849078, disc_loss = 0.11647549578947158
Trained batch 686 in epoch 1, gen_loss = 0.7858318403211396, disc_loss = 0.11651893705129623
Trained batch 687 in epoch 1, gen_loss = 0.7864218638820011, disc_loss = 0.11654038381827779
Trained batch 688 in epoch 1, gen_loss = 0.7860554936402768, disc_loss = 0.11665888906001007
Trained batch 689 in epoch 1, gen_loss = 0.7857968056979386, disc_loss = 0.11679719320457915
Trained batch 690 in epoch 1, gen_loss = 0.7861090214914938, disc_loss = 0.11696423548132225
Trained batch 691 in epoch 1, gen_loss = 0.7861406709675844, disc_loss = 0.11686423176501183
Trained batch 692 in epoch 1, gen_loss = 0.7860167604074162, disc_loss = 0.11675968502808098
Trained batch 693 in epoch 1, gen_loss = 0.7859705523815897, disc_loss = 0.11667695833150007
Trained batch 694 in epoch 1, gen_loss = 0.7860094084585313, disc_loss = 0.11659023664730916
Trained batch 695 in epoch 1, gen_loss = 0.7862555969121128, disc_loss = 0.11651408116215434
Trained batch 696 in epoch 1, gen_loss = 0.7860156694050328, disc_loss = 0.11651126324724262
Trained batch 697 in epoch 1, gen_loss = 0.7862102172009241, disc_loss = 0.11655061647701571
Trained batch 698 in epoch 1, gen_loss = 0.7862860044099401, disc_loss = 0.11661777915552962
Trained batch 699 in epoch 1, gen_loss = 0.7861568747673716, disc_loss = 0.11671625035681894
Trained batch 700 in epoch 1, gen_loss = 0.7862878372512768, disc_loss = 0.11666792023730346
Trained batch 701 in epoch 1, gen_loss = 0.7865700458953863, disc_loss = 0.11659624195655018
Trained batch 702 in epoch 1, gen_loss = 0.7865577850962431, disc_loss = 0.11654841789119952
Trained batch 703 in epoch 1, gen_loss = 0.7863541813990609, disc_loss = 0.11660908214980736
Trained batch 704 in epoch 1, gen_loss = 0.7869396782513206, disc_loss = 0.11664847090628976
Trained batch 705 in epoch 1, gen_loss = 0.7869326363795202, disc_loss = 0.1165293927855853
Trained batch 706 in epoch 1, gen_loss = 0.7867309320849779, disc_loss = 0.1165722227448537
Trained batch 707 in epoch 1, gen_loss = 0.7864181337467695, disc_loss = 0.11662289274509176
Trained batch 708 in epoch 1, gen_loss = 0.7867436027745434, disc_loss = 0.11659203327362057
Trained batch 709 in epoch 1, gen_loss = 0.7871284950367162, disc_loss = 0.11647944692784631
Trained batch 710 in epoch 1, gen_loss = 0.7870603295569681, disc_loss = 0.11642768525331164
Trained batch 711 in epoch 1, gen_loss = 0.7870912423378296, disc_loss = 0.11633725677815716
Trained batch 712 in epoch 1, gen_loss = 0.7871815060248382, disc_loss = 0.11626828396052832
Trained batch 713 in epoch 1, gen_loss = 0.787250255044101, disc_loss = 0.11620398589960333
Trained batch 714 in epoch 1, gen_loss = 0.7874069680283953, disc_loss = 0.11608028522321394
Trained batch 715 in epoch 1, gen_loss = 0.7871111389561738, disc_loss = 0.11622310877262547
Trained batch 716 in epoch 1, gen_loss = 0.7877000822598632, disc_loss = 0.11645855662131077
Trained batch 717 in epoch 1, gen_loss = 0.7876879428007476, disc_loss = 0.1164336428149995
Trained batch 718 in epoch 1, gen_loss = 0.7876785376390264, disc_loss = 0.11632514637745969
Trained batch 719 in epoch 1, gen_loss = 0.787854701321986, disc_loss = 0.11621806809368233
Trained batch 720 in epoch 1, gen_loss = 0.7875139612017326, disc_loss = 0.11623756806062593
Trained batch 721 in epoch 1, gen_loss = 0.7875733219933312, disc_loss = 0.11610954531940562
Trained batch 722 in epoch 1, gen_loss = 0.7876382762383294, disc_loss = 0.11602408233334414
Trained batch 723 in epoch 1, gen_loss = 0.7874908960573581, disc_loss = 0.11598710906666122
Trained batch 724 in epoch 1, gen_loss = 0.7874914696709863, disc_loss = 0.11593895482092068
Trained batch 725 in epoch 1, gen_loss = 0.7880296665692789, disc_loss = 0.11587981358888885
Trained batch 726 in epoch 1, gen_loss = 0.7880766113407838, disc_loss = 0.11577864792684742
Trained batch 727 in epoch 1, gen_loss = 0.7882166665743341, disc_loss = 0.11563600927647613
Trained batch 728 in epoch 1, gen_loss = 0.7882471695767181, disc_loss = 0.1155532551571645
Trained batch 729 in epoch 1, gen_loss = 0.7881961710240742, disc_loss = 0.11545111588904099
Trained batch 730 in epoch 1, gen_loss = 0.7886104076978446, disc_loss = 0.1154539056119755
Trained batch 731 in epoch 1, gen_loss = 0.7886393837671463, disc_loss = 0.11539971283789663
Trained batch 732 in epoch 1, gen_loss = 0.7883162554175597, disc_loss = 0.11547417404945802
Trained batch 733 in epoch 1, gen_loss = 0.7884680781036372, disc_loss = 0.11540834385297725
Trained batch 734 in epoch 1, gen_loss = 0.7888716381017854, disc_loss = 0.11543084254146231
Trained batch 735 in epoch 1, gen_loss = 0.788518495493285, disc_loss = 0.11545264065827486
Trained batch 736 in epoch 1, gen_loss = 0.7881879434090618, disc_loss = 0.1154654213445946
Trained batch 737 in epoch 1, gen_loss = 0.7885369092710619, disc_loss = 0.11557327927567246
Trained batch 738 in epoch 1, gen_loss = 0.7883546785911462, disc_loss = 0.11551955346199551
Trained batch 739 in epoch 1, gen_loss = 0.7884200566926518, disc_loss = 0.11543263623214049
Trained batch 740 in epoch 1, gen_loss = 0.7885455263529711, disc_loss = 0.11529669416854699
Trained batch 741 in epoch 1, gen_loss = 0.7883997603327116, disc_loss = 0.11525027351353488
Trained batch 742 in epoch 1, gen_loss = 0.7883808730348122, disc_loss = 0.11541547709361501
Trained batch 743 in epoch 1, gen_loss = 0.788440484393348, disc_loss = 0.11528082839989413
Trained batch 744 in epoch 1, gen_loss = 0.7882652158305149, disc_loss = 0.11526733897001351
Trained batch 745 in epoch 1, gen_loss = 0.7880127786711137, disc_loss = 0.11523586519726679
Trained batch 746 in epoch 1, gen_loss = 0.7882025594133609, disc_loss = 0.11532824050754788
Trained batch 747 in epoch 1, gen_loss = 0.7884112124376118, disc_loss = 0.11520666489004093
Trained batch 748 in epoch 1, gen_loss = 0.7880835036171453, disc_loss = 0.1152679212478416
Trained batch 749 in epoch 1, gen_loss = 0.7878230706453323, disc_loss = 0.1152459101813535
Trained batch 750 in epoch 1, gen_loss = 0.7882036541733697, disc_loss = 0.11550986621350288
Trained batch 751 in epoch 1, gen_loss = 0.7884355087942899, disc_loss = 0.11538832959040325
Trained batch 752 in epoch 1, gen_loss = 0.7881465766771856, disc_loss = 0.11543208229445802
Trained batch 753 in epoch 1, gen_loss = 0.788225955727562, disc_loss = 0.11533427425593494
Trained batch 754 in epoch 1, gen_loss = 0.7880206046909686, disc_loss = 0.11526909410731484
Trained batch 755 in epoch 1, gen_loss = 0.788068562785469, disc_loss = 0.11513347862776191
Trained batch 756 in epoch 1, gen_loss = 0.7880035743137017, disc_loss = 0.11514551719205264
Trained batch 757 in epoch 1, gen_loss = 0.7880781021234543, disc_loss = 0.115027732548788
Trained batch 758 in epoch 1, gen_loss = 0.7880733389706794, disc_loss = 0.11512755963961166
Trained batch 759 in epoch 1, gen_loss = 0.7878272382444457, disc_loss = 0.11513609788258021
Trained batch 760 in epoch 1, gen_loss = 0.7876426256047598, disc_loss = 0.11515256100788263
Trained batch 761 in epoch 1, gen_loss = 0.7877408975925971, disc_loss = 0.11510560409412805
Trained batch 762 in epoch 1, gen_loss = 0.7874929799867958, disc_loss = 0.1150917894613403
Trained batch 763 in epoch 1, gen_loss = 0.7873386211342213, disc_loss = 0.11504151617635178
Trained batch 764 in epoch 1, gen_loss = 0.7870637715641969, disc_loss = 0.11518487823287062
Trained batch 765 in epoch 1, gen_loss = 0.787764538011414, disc_loss = 0.11551660861620587
Trained batch 766 in epoch 1, gen_loss = 0.7875383193598577, disc_loss = 0.11553219199846007
Trained batch 767 in epoch 1, gen_loss = 0.7871885892236605, disc_loss = 0.11555361771146029
Trained batch 768 in epoch 1, gen_loss = 0.7871901030580771, disc_loss = 0.11556624203692681
Trained batch 769 in epoch 1, gen_loss = 0.7872620554326417, disc_loss = 0.11556744450800024
Trained batch 770 in epoch 1, gen_loss = 0.7869466782466601, disc_loss = 0.11558561549967714
Trained batch 771 in epoch 1, gen_loss = 0.7868980188984327, disc_loss = 0.11560994574988329
Trained batch 772 in epoch 1, gen_loss = 0.7868551882164598, disc_loss = 0.11560290041867581
Trained batch 773 in epoch 1, gen_loss = 0.7870325825396126, disc_loss = 0.11551196483933687
Trained batch 774 in epoch 1, gen_loss = 0.7869385711223849, disc_loss = 0.1154116930031488
Trained batch 775 in epoch 1, gen_loss = 0.7868104244092691, disc_loss = 0.11537372899006515
Trained batch 776 in epoch 1, gen_loss = 0.7868346070614254, disc_loss = 0.11535298507037349
Trained batch 777 in epoch 1, gen_loss = 0.7868181042239109, disc_loss = 0.11531905040915835
Trained batch 778 in epoch 1, gen_loss = 0.7870547404567758, disc_loss = 0.11545062357911287
Trained batch 779 in epoch 1, gen_loss = 0.7867830469440191, disc_loss = 0.11552039837727371
Trained batch 780 in epoch 1, gen_loss = 0.7873028312617777, disc_loss = 0.11571274541447203
Trained batch 781 in epoch 1, gen_loss = 0.7870825642286359, disc_loss = 0.11569266609223489
Trained batch 782 in epoch 1, gen_loss = 0.786883968693391, disc_loss = 0.11574384858558194
Trained batch 783 in epoch 1, gen_loss = 0.7869436501772428, disc_loss = 0.11575255740780802
Trained batch 784 in epoch 1, gen_loss = 0.7868811199239865, disc_loss = 0.11569649994871609
Trained batch 785 in epoch 1, gen_loss = 0.7867978640260891, disc_loss = 0.11569267153175922
Trained batch 786 in epoch 1, gen_loss = 0.786662976464595, disc_loss = 0.11568379233765216
Trained batch 787 in epoch 1, gen_loss = 0.7864631072140588, disc_loss = 0.11571193269104106
Trained batch 788 in epoch 1, gen_loss = 0.7861383127093466, disc_loss = 0.11571107540487374
Trained batch 789 in epoch 1, gen_loss = 0.7862387305196328, disc_loss = 0.1156700512288209
Trained batch 790 in epoch 1, gen_loss = 0.7864827099627099, disc_loss = 0.11557521133338644
Trained batch 791 in epoch 1, gen_loss = 0.7861947947454573, disc_loss = 0.11562317254308686
Trained batch 792 in epoch 1, gen_loss = 0.7864310077355158, disc_loss = 0.11550601416891076
Trained batch 793 in epoch 1, gen_loss = 0.786446626713354, disc_loss = 0.11546962367727301
Trained batch 794 in epoch 1, gen_loss = 0.7865874765429107, disc_loss = 0.11544952332715756
Trained batch 795 in epoch 1, gen_loss = 0.786291634504819, disc_loss = 0.11548098298515094
Trained batch 796 in epoch 1, gen_loss = 0.7862353048554926, disc_loss = 0.11536174129760138
Trained batch 797 in epoch 1, gen_loss = 0.7860882112331558, disc_loss = 0.11542602915685614
Trained batch 798 in epoch 1, gen_loss = 0.7861892157636386, disc_loss = 0.11534929457930697
Trained batch 799 in epoch 1, gen_loss = 0.7863299978896976, disc_loss = 0.11522274749237113
Trained batch 800 in epoch 1, gen_loss = 0.7864845788359791, disc_loss = 0.11527336715196217
Trained batch 801 in epoch 1, gen_loss = 0.7863321075044071, disc_loss = 0.11529166446394866
Trained batch 802 in epoch 1, gen_loss = 0.7863001425195008, disc_loss = 0.11524861681612572
Trained batch 803 in epoch 1, gen_loss = 0.7864060183588545, disc_loss = 0.1151934982594844
Trained batch 804 in epoch 1, gen_loss = 0.7867316632167153, disc_loss = 0.11512214749102823
Trained batch 805 in epoch 1, gen_loss = 0.7866410756155515, disc_loss = 0.11503193627640827
Trained batch 806 in epoch 1, gen_loss = 0.786653855734746, disc_loss = 0.11493532324401383
Trained batch 807 in epoch 1, gen_loss = 0.7866966396496438, disc_loss = 0.1148643931039692
Trained batch 808 in epoch 1, gen_loss = 0.7867575767087406, disc_loss = 0.11483341193330855
Trained batch 809 in epoch 1, gen_loss = 0.7872531085470577, disc_loss = 0.11495478800210504
Trained batch 810 in epoch 1, gen_loss = 0.7873546216182145, disc_loss = 0.11492901526359352
Trained batch 811 in epoch 1, gen_loss = 0.7872306097096997, disc_loss = 0.11489176278901768
Trained batch 812 in epoch 1, gen_loss = 0.7874631695861746, disc_loss = 0.11478443709654598
Trained batch 813 in epoch 1, gen_loss = 0.788093791144193, disc_loss = 0.11476765787320473
Trained batch 814 in epoch 1, gen_loss = 0.7880844037591314, disc_loss = 0.11471535532501029
Trained batch 815 in epoch 1, gen_loss = 0.7877543708492144, disc_loss = 0.11472962513753195
Trained batch 816 in epoch 1, gen_loss = 0.7880441651860824, disc_loss = 0.11480926391366536
Trained batch 817 in epoch 1, gen_loss = 0.7879603408586716, disc_loss = 0.11493304084125715
Trained batch 818 in epoch 1, gen_loss = 0.7880434258153005, disc_loss = 0.11490798743512204
Trained batch 819 in epoch 1, gen_loss = 0.7880705794546662, disc_loss = 0.11488863922223994
Trained batch 820 in epoch 1, gen_loss = 0.7880479979093995, disc_loss = 0.11486737486474152
Trained batch 821 in epoch 1, gen_loss = 0.7880058805220318, disc_loss = 0.11480931718459855
Trained batch 822 in epoch 1, gen_loss = 0.7881425926563661, disc_loss = 0.11485139477119882
Trained batch 823 in epoch 1, gen_loss = 0.7882392274450909, disc_loss = 0.11476704209378369
Trained batch 824 in epoch 1, gen_loss = 0.7881161992838889, disc_loss = 0.11471737938058196
Trained batch 825 in epoch 1, gen_loss = 0.7880039341729721, disc_loss = 0.11467520659563941
Trained batch 826 in epoch 1, gen_loss = 0.7879865458178837, disc_loss = 0.1146417990779592
Trained batch 827 in epoch 1, gen_loss = 0.7884030132262028, disc_loss = 0.11456711816709435
Trained batch 828 in epoch 1, gen_loss = 0.7881052334791788, disc_loss = 0.11452185023414248
Trained batch 829 in epoch 1, gen_loss = 0.7884608244680497, disc_loss = 0.1144454496059881
Trained batch 830 in epoch 1, gen_loss = 0.7882969836680898, disc_loss = 0.11444118342482262
Trained batch 831 in epoch 1, gen_loss = 0.788452976419089, disc_loss = 0.11433773570528362
Trained batch 832 in epoch 1, gen_loss = 0.7884250038883694, disc_loss = 0.11436893486295964
Trained batch 833 in epoch 1, gen_loss = 0.7889536665998202, disc_loss = 0.11441750513898918
Trained batch 834 in epoch 1, gen_loss = 0.7888409728418567, disc_loss = 0.1143490752629088
Trained batch 835 in epoch 1, gen_loss = 0.7888457915928375, disc_loss = 0.11430638126971013
Trained batch 836 in epoch 1, gen_loss = 0.7888360531597867, disc_loss = 0.11425196336139452
Trained batch 837 in epoch 1, gen_loss = 0.7893061061391967, disc_loss = 0.11431248994935349
Trained batch 838 in epoch 1, gen_loss = 0.7891494769944906, disc_loss = 0.11444422393411184
Trained batch 839 in epoch 1, gen_loss = 0.7892642754529203, disc_loss = 0.11440523439197846
Trained batch 840 in epoch 1, gen_loss = 0.7893908864040012, disc_loss = 0.11434406777744167
Trained batch 841 in epoch 1, gen_loss = 0.7895116008588084, disc_loss = 0.11431824180879353
Trained batch 842 in epoch 1, gen_loss = 0.7894432097496653, disc_loss = 0.114215415557747
Trained batch 843 in epoch 1, gen_loss = 0.7892520369441023, disc_loss = 0.1141606621097738
Trained batch 844 in epoch 1, gen_loss = 0.789577293219651, disc_loss = 0.11408014732065815
Trained batch 845 in epoch 1, gen_loss = 0.7899335122207096, disc_loss = 0.11397584273323558
Trained batch 846 in epoch 1, gen_loss = 0.7899271205788942, disc_loss = 0.11390038368258067
Trained batch 847 in epoch 1, gen_loss = 0.7900446692376204, disc_loss = 0.11383287707576528
Trained batch 848 in epoch 1, gen_loss = 0.7898595620591733, disc_loss = 0.11378844056576841
Trained batch 849 in epoch 1, gen_loss = 0.7899575456100352, disc_loss = 0.11367858828538481
Trained batch 850 in epoch 1, gen_loss = 0.7900581967466447, disc_loss = 0.11359371981757543
Trained batch 851 in epoch 1, gen_loss = 0.7902187693496825, disc_loss = 0.11350528282952875
Trained batch 852 in epoch 1, gen_loss = 0.7901860335437801, disc_loss = 0.11344868382428099
Trained batch 853 in epoch 1, gen_loss = 0.7902273466980708, disc_loss = 0.11334699719808385
Trained batch 854 in epoch 1, gen_loss = 0.7903918432561975, disc_loss = 0.11323063954144542
Trained batch 855 in epoch 1, gen_loss = 0.7902950616292307, disc_loss = 0.11324954802544665
Trained batch 856 in epoch 1, gen_loss = 0.7901848942354374, disc_loss = 0.11321532952543804
Trained batch 857 in epoch 1, gen_loss = 0.7900565970680374, disc_loss = 0.11328114868122173
Trained batch 858 in epoch 1, gen_loss = 0.7905055769872055, disc_loss = 0.11351713923492379
Trained batch 859 in epoch 1, gen_loss = 0.7903197658962982, disc_loss = 0.11358240908878141
Trained batch 860 in epoch 1, gen_loss = 0.7899319149129759, disc_loss = 0.1135904402618105
Trained batch 861 in epoch 1, gen_loss = 0.790236442624278, disc_loss = 0.11351713565180377
Trained batch 862 in epoch 1, gen_loss = 0.7901235582999807, disc_loss = 0.11350412072175693
Trained batch 863 in epoch 1, gen_loss = 0.7899336412342058, disc_loss = 0.11350607205639351
Trained batch 864 in epoch 1, gen_loss = 0.7898961500280854, disc_loss = 0.11355968196311093
Trained batch 865 in epoch 1, gen_loss = 0.7898044263036367, disc_loss = 0.11349825652888341
Trained batch 866 in epoch 1, gen_loss = 0.7898388207646252, disc_loss = 0.11344486768674342
Trained batch 867 in epoch 1, gen_loss = 0.7897407179397922, disc_loss = 0.1134373938325741
Trained batch 868 in epoch 1, gen_loss = 0.7894070135435932, disc_loss = 0.11339240834777113
Trained batch 869 in epoch 1, gen_loss = 0.7893434545089458, disc_loss = 0.11334109825092828
Trained batch 870 in epoch 1, gen_loss = 0.7892943160815846, disc_loss = 0.11335581706796188
Trained batch 871 in epoch 1, gen_loss = 0.7893094104637793, disc_loss = 0.11331127335983884
Trained batch 872 in epoch 1, gen_loss = 0.7894280315947559, disc_loss = 0.11331393555839378
Trained batch 873 in epoch 1, gen_loss = 0.7891865038489859, disc_loss = 0.11336271051164008
Trained batch 874 in epoch 1, gen_loss = 0.7894793600354876, disc_loss = 0.11335025909755911
Trained batch 875 in epoch 1, gen_loss = 0.7897471343273441, disc_loss = 0.11323442383027171
Trained batch 876 in epoch 1, gen_loss = 0.789675278090017, disc_loss = 0.11320125901840092
Trained batch 877 in epoch 1, gen_loss = 0.7896019620205655, disc_loss = 0.11325385823531886
Trained batch 878 in epoch 1, gen_loss = 0.7896418632500815, disc_loss = 0.11331008935603605
Trained batch 879 in epoch 1, gen_loss = 0.7895374957810749, disc_loss = 0.11334712974176826
Trained batch 880 in epoch 1, gen_loss = 0.7894475305121007, disc_loss = 0.11348020622589193
Trained batch 881 in epoch 1, gen_loss = 0.7898205599141499, disc_loss = 0.1134149265156683
Trained batch 882 in epoch 1, gen_loss = 0.7900003857007788, disc_loss = 0.1133211322069708
Trained batch 883 in epoch 1, gen_loss = 0.7897489710765726, disc_loss = 0.1134323360929392
Trained batch 884 in epoch 1, gen_loss = 0.7900279994064805, disc_loss = 0.11358771110321843
Trained batch 885 in epoch 1, gen_loss = 0.7896839271953359, disc_loss = 0.11372309369844454
Trained batch 886 in epoch 1, gen_loss = 0.7897357638282733, disc_loss = 0.11364698038345125
Trained batch 887 in epoch 1, gen_loss = 0.7895950211195258, disc_loss = 0.11367403396598257
Trained batch 888 in epoch 1, gen_loss = 0.78948492944844, disc_loss = 0.11371047457489442
Trained batch 889 in epoch 1, gen_loss = 0.7896236502722408, disc_loss = 0.1136373259336426
Trained batch 890 in epoch 1, gen_loss = 0.7893120200278114, disc_loss = 0.11383236976033108
Trained batch 891 in epoch 1, gen_loss = 0.7899521911358085, disc_loss = 0.11399349178951819
Trained batch 892 in epoch 1, gen_loss = 0.7897303879327764, disc_loss = 0.11400123127013412
Trained batch 893 in epoch 1, gen_loss = 0.7895360748373156, disc_loss = 0.1139601352989207
Trained batch 894 in epoch 1, gen_loss = 0.789490402011232, disc_loss = 0.11404622261667385
Trained batch 895 in epoch 1, gen_loss = 0.7894582957295435, disc_loss = 0.11401336635546093
Trained batch 896 in epoch 1, gen_loss = 0.7894825700134737, disc_loss = 0.11404357076837467
Trained batch 897 in epoch 1, gen_loss = 0.7898250288580999, disc_loss = 0.11399396461225167
Trained batch 898 in epoch 1, gen_loss = 0.7894634474172475, disc_loss = 0.11428688253142412
Trained batch 899 in epoch 1, gen_loss = 0.7896193575527933, disc_loss = 0.1143575057759881
Trained batch 900 in epoch 1, gen_loss = 0.7898816862262447, disc_loss = 0.11439126201147641
Trained batch 901 in epoch 1, gen_loss = 0.7897199806313293, disc_loss = 0.1145373612617508
Trained batch 902 in epoch 1, gen_loss = 0.7896422039828823, disc_loss = 0.1144991611498733
Trained batch 903 in epoch 1, gen_loss = 0.7896097453096799, disc_loss = 0.11449007113439451
Trained batch 904 in epoch 1, gen_loss = 0.7896213023372777, disc_loss = 0.11450647198445889
Trained batch 905 in epoch 1, gen_loss = 0.7894599624224846, disc_loss = 0.11449128305066632
Trained batch 906 in epoch 1, gen_loss = 0.7892829833969128, disc_loss = 0.11451986599241229
Trained batch 907 in epoch 1, gen_loss = 0.7891769861137814, disc_loss = 0.11447036896097897
Trained batch 908 in epoch 1, gen_loss = 0.7891335634574114, disc_loss = 0.11441188729783096
Trained batch 909 in epoch 1, gen_loss = 0.7894487491348288, disc_loss = 0.11451158987378682
Trained batch 910 in epoch 1, gen_loss = 0.7893013940749917, disc_loss = 0.11450260690731354
Trained batch 911 in epoch 1, gen_loss = 0.7890718682227951, disc_loss = 0.1145520612654652
Trained batch 912 in epoch 1, gen_loss = 0.7890477840832525, disc_loss = 0.1144744762283753
Trained batch 913 in epoch 1, gen_loss = 0.7888647566673792, disc_loss = 0.1144595028999663
Trained batch 914 in epoch 1, gen_loss = 0.7891975239652103, disc_loss = 0.11442218519380835
Trained batch 915 in epoch 1, gen_loss = 0.789319392277424, disc_loss = 0.11442457607593469
Trained batch 916 in epoch 1, gen_loss = 0.7891037617865929, disc_loss = 0.1145931926546791
Trained batch 917 in epoch 1, gen_loss = 0.7890344615660462, disc_loss = 0.11465662699557987
Trained batch 918 in epoch 1, gen_loss = 0.7889846274396152, disc_loss = 0.11471595224783522
Trained batch 919 in epoch 1, gen_loss = 0.7888572095852832, disc_loss = 0.1147372386985175
Trained batch 920 in epoch 1, gen_loss = 0.7885918857673351, disc_loss = 0.11482599089235618
Trained batch 921 in epoch 1, gen_loss = 0.7888007780411755, disc_loss = 0.11484590237010715
Trained batch 922 in epoch 1, gen_loss = 0.7888543843125212, disc_loss = 0.1148724757409367
Trained batch 923 in epoch 1, gen_loss = 0.7888002790091357, disc_loss = 0.11486473979097811
Trained batch 924 in epoch 1, gen_loss = 0.7886819558208054, disc_loss = 0.11488065345464527
Trained batch 925 in epoch 1, gen_loss = 0.7888111697095517, disc_loss = 0.11478524182402161
Trained batch 926 in epoch 1, gen_loss = 0.7890065426515273, disc_loss = 0.1147766936823581
Trained batch 927 in epoch 1, gen_loss = 0.7888193888718198, disc_loss = 0.11476756200788478
Trained batch 928 in epoch 1, gen_loss = 0.7885401879945535, disc_loss = 0.11488605989594378
Trained batch 929 in epoch 1, gen_loss = 0.7885394454963746, disc_loss = 0.11491244041551185
Trained batch 930 in epoch 1, gen_loss = 0.788820130196345, disc_loss = 0.11493280920911296
Trained batch 931 in epoch 1, gen_loss = 0.7886707530448877, disc_loss = 0.11497233167306677
Trained batch 932 in epoch 1, gen_loss = 0.788440613980462, disc_loss = 0.11494590653883172
Trained batch 933 in epoch 1, gen_loss = 0.788453468897358, disc_loss = 0.11486924248219046
Trained batch 934 in epoch 1, gen_loss = 0.7882293927159539, disc_loss = 0.11490315184554951
Trained batch 935 in epoch 1, gen_loss = 0.788035242826256, disc_loss = 0.11497615537263899
Trained batch 936 in epoch 1, gen_loss = 0.7881224521514318, disc_loss = 0.11500159041158926
Trained batch 937 in epoch 1, gen_loss = 0.7878566038316247, disc_loss = 0.11512030935935628
Trained batch 938 in epoch 1, gen_loss = 0.7878547755483621, disc_loss = 0.11514016416189643
Trained batch 939 in epoch 1, gen_loss = 0.7875835280152077, disc_loss = 0.11517382481313766
Trained batch 940 in epoch 1, gen_loss = 0.787472190784724, disc_loss = 0.11518738357851026
Trained batch 941 in epoch 1, gen_loss = 0.7877827123155513, disc_loss = 0.11511147194670517
Trained batch 942 in epoch 1, gen_loss = 0.7878318343347103, disc_loss = 0.11506795127849437
Trained batch 943 in epoch 1, gen_loss = 0.7875747958166619, disc_loss = 0.11514259079250239
Trained batch 944 in epoch 1, gen_loss = 0.7873979517707118, disc_loss = 0.11511843452062556
Trained batch 945 in epoch 1, gen_loss = 0.7875085598759621, disc_loss = 0.11504901164303874
Trained batch 946 in epoch 1, gen_loss = 0.7881294907775827, disc_loss = 0.11504313726580004
Trained batch 947 in epoch 1, gen_loss = 0.7880028450099225, disc_loss = 0.11499243206835749
Trained batch 948 in epoch 1, gen_loss = 0.7879158072840928, disc_loss = 0.11500035443817225
Trained batch 949 in epoch 1, gen_loss = 0.7879530966595599, disc_loss = 0.11500522210409767
Trained batch 950 in epoch 1, gen_loss = 0.7877503200096286, disc_loss = 0.11501924308128537
Trained batch 951 in epoch 1, gen_loss = 0.7877370528876781, disc_loss = 0.11493787935254078
Trained batch 952 in epoch 1, gen_loss = 0.7880677007615629, disc_loss = 0.11492684089108629
Trained batch 953 in epoch 1, gen_loss = 0.7879035028958971, disc_loss = 0.11501573706807205
Trained batch 954 in epoch 1, gen_loss = 0.7878179442508059, disc_loss = 0.11502282205598517
Trained batch 955 in epoch 1, gen_loss = 0.787880852849663, disc_loss = 0.11501906687105425
Trained batch 956 in epoch 1, gen_loss = 0.7882286727179305, disc_loss = 0.11503024811514867
Trained batch 957 in epoch 1, gen_loss = 0.7881089403820933, disc_loss = 0.11497933561826175
Trained batch 958 in epoch 1, gen_loss = 0.7879092233086528, disc_loss = 0.11495378035061427
Trained batch 959 in epoch 1, gen_loss = 0.7879167183923225, disc_loss = 0.11493027084118997
Trained batch 960 in epoch 1, gen_loss = 0.7878678631770127, disc_loss = 0.1149047236932242
Trained batch 961 in epoch 1, gen_loss = 0.7878126618829934, disc_loss = 0.11486446747087763
Trained batch 962 in epoch 1, gen_loss = 0.7875895269006212, disc_loss = 0.1149546969275794
Trained batch 963 in epoch 1, gen_loss = 0.7875698701289184, disc_loss = 0.11488783332476725
Trained batch 964 in epoch 1, gen_loss = 0.7876014297799125, disc_loss = 0.11478597668863331
Trained batch 965 in epoch 1, gen_loss = 0.7877478249386477, disc_loss = 0.11479902196883784
Trained batch 966 in epoch 1, gen_loss = 0.7880528776019411, disc_loss = 0.11477032645519789
Trained batch 967 in epoch 1, gen_loss = 0.7877945174917209, disc_loss = 0.1149008408889236
Trained batch 968 in epoch 1, gen_loss = 0.7877628074649441, disc_loss = 0.11485405135188556
Trained batch 969 in epoch 1, gen_loss = 0.7879081820397033, disc_loss = 0.11487464910545915
Trained batch 970 in epoch 1, gen_loss = 0.7878379302154978, disc_loss = 0.11485972833636492
Trained batch 971 in epoch 1, gen_loss = 0.7877761885646439, disc_loss = 0.11477612233778209
Trained batch 972 in epoch 1, gen_loss = 0.7876950357518975, disc_loss = 0.11474335722372564
Trained batch 973 in epoch 1, gen_loss = 0.7876626011710882, disc_loss = 0.11472896740865536
Trained batch 974 in epoch 1, gen_loss = 0.787322461482806, disc_loss = 0.11478556830531511
Trained batch 975 in epoch 1, gen_loss = 0.7873881625958153, disc_loss = 0.11490423748742973
Trained batch 976 in epoch 1, gen_loss = 0.7874817397357742, disc_loss = 0.11482862711425569
Trained batch 977 in epoch 1, gen_loss = 0.7874427732148784, disc_loss = 0.11481987425566086
Trained batch 978 in epoch 1, gen_loss = 0.7874884128083491, disc_loss = 0.11481776327062189
Trained batch 979 in epoch 1, gen_loss = 0.7876015022701147, disc_loss = 0.11472698423859416
Trained batch 980 in epoch 1, gen_loss = 0.7874744212469438, disc_loss = 0.11474372368689463
Trained batch 981 in epoch 1, gen_loss = 0.7874759493316021, disc_loss = 0.11469686440668257
Trained batch 982 in epoch 1, gen_loss = 0.7875912824943131, disc_loss = 0.11463255136219798
Trained batch 983 in epoch 1, gen_loss = 0.7875893117208791, disc_loss = 0.11465528904558803
Trained batch 984 in epoch 1, gen_loss = 0.7876358928414166, disc_loss = 0.1146378436404739
Trained batch 985 in epoch 1, gen_loss = 0.7876614754146785, disc_loss = 0.11457047435033757
Trained batch 986 in epoch 1, gen_loss = 0.7877068057007098, disc_loss = 0.11449031047183329
Trained batch 987 in epoch 1, gen_loss = 0.7878079989902403, disc_loss = 0.11443088066421057
Trained batch 988 in epoch 1, gen_loss = 0.7882541730261668, disc_loss = 0.11444230835707773
Trained batch 989 in epoch 1, gen_loss = 0.7880481975849228, disc_loss = 0.11456693434956097
Trained batch 990 in epoch 1, gen_loss = 0.7883022303658225, disc_loss = 0.1146232952954911
Trained batch 991 in epoch 1, gen_loss = 0.788179844497673, disc_loss = 0.11462127514213565
Trained batch 992 in epoch 1, gen_loss = 0.7882778312624521, disc_loss = 0.11461532785963316
Trained batch 993 in epoch 1, gen_loss = 0.7885077295288954, disc_loss = 0.11457848252065225
Trained batch 994 in epoch 1, gen_loss = 0.78819096154304, disc_loss = 0.11458983205670688
Trained batch 995 in epoch 1, gen_loss = 0.7882878198681107, disc_loss = 0.1145945585007409
Trained batch 996 in epoch 1, gen_loss = 0.7884327710093323, disc_loss = 0.11452044359031867
Trained batch 997 in epoch 1, gen_loss = 0.7882233642504545, disc_loss = 0.1144891166779584
Trained batch 998 in epoch 1, gen_loss = 0.7884451186096108, disc_loss = 0.11441835509361448
Trained batch 999 in epoch 1, gen_loss = 0.788358988583088, disc_loss = 0.11439157359674573
Trained batch 1000 in epoch 1, gen_loss = 0.7885726346717133, disc_loss = 0.1143306498783273
Trained batch 1001 in epoch 1, gen_loss = 0.7885050941965062, disc_loss = 0.11434727050215303
Trained batch 1002 in epoch 1, gen_loss = 0.7883478618809138, disc_loss = 0.11438573097228885
Trained batch 1003 in epoch 1, gen_loss = 0.7882316087584097, disc_loss = 0.11440194155872462
Trained batch 1004 in epoch 1, gen_loss = 0.7884614003831474, disc_loss = 0.11434257964589703
Trained batch 1005 in epoch 1, gen_loss = 0.7883979514033846, disc_loss = 0.11431779191046064
Trained batch 1006 in epoch 1, gen_loss = 0.7883550132279836, disc_loss = 0.11428871568821393
Trained batch 1007 in epoch 1, gen_loss = 0.7882512777688957, disc_loss = 0.11424264020567375
Trained batch 1008 in epoch 1, gen_loss = 0.7882749180136871, disc_loss = 0.11429953303398534
Trained batch 1009 in epoch 1, gen_loss = 0.7882326067674278, disc_loss = 0.11422302589041762
Trained batch 1010 in epoch 1, gen_loss = 0.7879306069703296, disc_loss = 0.11427574125362669
Trained batch 1011 in epoch 1, gen_loss = 0.7882504696431367, disc_loss = 0.11428919747074248
Trained batch 1012 in epoch 1, gen_loss = 0.7883003386434422, disc_loss = 0.11426821769916647
Trained batch 1013 in epoch 1, gen_loss = 0.7881206673748159, disc_loss = 0.11438788718652325
Trained batch 1014 in epoch 1, gen_loss = 0.7881109641690559, disc_loss = 0.11434645742691796
Trained batch 1015 in epoch 1, gen_loss = 0.7880641163334133, disc_loss = 0.11428043871062009
Trained batch 1016 in epoch 1, gen_loss = 0.7883061333509087, disc_loss = 0.11423090913478604
Trained batch 1017 in epoch 1, gen_loss = 0.7883857062968384, disc_loss = 0.11414617251912187
Trained batch 1018 in epoch 1, gen_loss = 0.7881814228540782, disc_loss = 0.11409997597329458
Trained batch 1019 in epoch 1, gen_loss = 0.7881944627154107, disc_loss = 0.11405963828495028
Trained batch 1020 in epoch 1, gen_loss = 0.788308669374225, disc_loss = 0.11415781058283499
Trained batch 1021 in epoch 1, gen_loss = 0.7884105912859892, disc_loss = 0.11406239408474787
Trained batch 1022 in epoch 1, gen_loss = 0.7882870730533394, disc_loss = 0.11407681547090746
Trained batch 1023 in epoch 1, gen_loss = 0.7883230079314671, disc_loss = 0.11400313678859675
Trained batch 1024 in epoch 1, gen_loss = 0.7884325577573078, disc_loss = 0.11401640071192892
Trained batch 1025 in epoch 1, gen_loss = 0.7883540706792538, disc_loss = 0.1139701092216326
Trained batch 1026 in epoch 1, gen_loss = 0.7881965543186072, disc_loss = 0.11393139677298161
Trained batch 1027 in epoch 1, gen_loss = 0.7885047936022049, disc_loss = 0.11416900369378553
Trained batch 1028 in epoch 1, gen_loss = 0.7882898315512172, disc_loss = 0.11427227354656445
Trained batch 1029 in epoch 1, gen_loss = 0.7881954922838118, disc_loss = 0.11424300140945368
Trained batch 1030 in epoch 1, gen_loss = 0.7882642918830931, disc_loss = 0.11416339381958361
Trained batch 1031 in epoch 1, gen_loss = 0.7883997711446858, disc_loss = 0.11419509668011478
Trained batch 1032 in epoch 1, gen_loss = 0.7884529265868121, disc_loss = 0.11418473294828833
Trained batch 1033 in epoch 1, gen_loss = 0.7882703878201646, disc_loss = 0.11416495911150133
Trained batch 1034 in epoch 1, gen_loss = 0.7883651940718941, disc_loss = 0.11422840885026156
Trained batch 1035 in epoch 1, gen_loss = 0.7881983409286926, disc_loss = 0.11418521803224811
Trained batch 1036 in epoch 1, gen_loss = 0.7881098809789439, disc_loss = 0.11417641458905364
Trained batch 1037 in epoch 1, gen_loss = 0.7881193721455186, disc_loss = 0.11419370987763007
Trained batch 1038 in epoch 1, gen_loss = 0.7879820218214746, disc_loss = 0.11416129120181855
Trained batch 1039 in epoch 1, gen_loss = 0.787843003238623, disc_loss = 0.11413211953432227
Trained batch 1040 in epoch 1, gen_loss = 0.7877566800108331, disc_loss = 0.11406926477039868
Trained batch 1041 in epoch 1, gen_loss = 0.7877262300470282, disc_loss = 0.11415522220775114
Trained batch 1042 in epoch 1, gen_loss = 0.7878616812816631, disc_loss = 0.11406777162829902
Trained batch 1043 in epoch 1, gen_loss = 0.787670437346473, disc_loss = 0.11402729253009874
Trained batch 1044 in epoch 1, gen_loss = 0.7878257394977733, disc_loss = 0.11399612474705328
Trained batch 1045 in epoch 1, gen_loss = 0.7878095807354492, disc_loss = 0.11393105486019676
Trained batch 1046 in epoch 1, gen_loss = 0.787764314195602, disc_loss = 0.11392288236792529
Trained batch 1047 in epoch 1, gen_loss = 0.7878394927687318, disc_loss = 0.113890505397607
Trained batch 1048 in epoch 1, gen_loss = 0.7878884745280554, disc_loss = 0.11381824558034355
Trained batch 1049 in epoch 1, gen_loss = 0.7877786759535471, disc_loss = 0.11376178314111063
Trained batch 1050 in epoch 1, gen_loss = 0.7877115412171288, disc_loss = 0.11373318544456949
Trained batch 1051 in epoch 1, gen_loss = 0.7878747793771468, disc_loss = 0.11373968587961657
Trained batch 1052 in epoch 1, gen_loss = 0.7877372705925111, disc_loss = 0.11369353012559477
Trained batch 1053 in epoch 1, gen_loss = 0.7876318703340172, disc_loss = 0.11362658908848688
Trained batch 1054 in epoch 1, gen_loss = 0.7877873504331326, disc_loss = 0.11357913714837971
Trained batch 1055 in epoch 1, gen_loss = 0.7881451109142015, disc_loss = 0.11359545423218867
Trained batch 1056 in epoch 1, gen_loss = 0.7879094421694385, disc_loss = 0.11356802884394139
Trained batch 1057 in epoch 1, gen_loss = 0.7879734944643731, disc_loss = 0.113508484326303
Trained batch 1058 in epoch 1, gen_loss = 0.7877849420361973, disc_loss = 0.1134968496510817
Trained batch 1059 in epoch 1, gen_loss = 0.7881705983629766, disc_loss = 0.11359618754424858
Trained batch 1060 in epoch 1, gen_loss = 0.7882093630457239, disc_loss = 0.11356474960382595
Trained batch 1061 in epoch 1, gen_loss = 0.7881073339959771, disc_loss = 0.11360729952814608
Trained batch 1062 in epoch 1, gen_loss = 0.7880692847584736, disc_loss = 0.11355566697568402
Trained batch 1063 in epoch 1, gen_loss = 0.7883085714919227, disc_loss = 0.11350456820765889
Trained batch 1064 in epoch 1, gen_loss = 0.7881962474523015, disc_loss = 0.11346480721354205
Trained batch 1065 in epoch 1, gen_loss = 0.7879370300564041, disc_loss = 0.11350980253739887
Trained batch 1066 in epoch 1, gen_loss = 0.7880693498122547, disc_loss = 0.11355381628154536
Trained batch 1067 in epoch 1, gen_loss = 0.7880491774515266, disc_loss = 0.11360321032957693
Trained batch 1068 in epoch 1, gen_loss = 0.7878403273891131, disc_loss = 0.1136436564664873
Trained batch 1069 in epoch 1, gen_loss = 0.7877390453191561, disc_loss = 0.1136472185725503
Trained batch 1070 in epoch 1, gen_loss = 0.7879645031373373, disc_loss = 0.11375875879047799
Trained batch 1071 in epoch 1, gen_loss = 0.787778351789535, disc_loss = 0.11380307007504543
Trained batch 1072 in epoch 1, gen_loss = 0.7878063996595861, disc_loss = 0.11375915425250659
Trained batch 1073 in epoch 1, gen_loss = 0.7878245233490481, disc_loss = 0.11375433887273517
Trained batch 1074 in epoch 1, gen_loss = 0.7880136335173319, disc_loss = 0.11374019167624241
Trained batch 1075 in epoch 1, gen_loss = 0.7879734625382051, disc_loss = 0.11372098509658501
Trained batch 1076 in epoch 1, gen_loss = 0.7878903936985586, disc_loss = 0.11376813514990007
Trained batch 1077 in epoch 1, gen_loss = 0.787876167135911, disc_loss = 0.11373661624540701
Trained batch 1078 in epoch 1, gen_loss = 0.7879936147664187, disc_loss = 0.1137235736469216
Trained batch 1079 in epoch 1, gen_loss = 0.7881877191640713, disc_loss = 0.11367364386613998
Trained batch 1080 in epoch 1, gen_loss = 0.7880476188262672, disc_loss = 0.11372560833535131
Trained batch 1081 in epoch 1, gen_loss = 0.7882360371996867, disc_loss = 0.11373814550880859
Trained batch 1082 in epoch 1, gen_loss = 0.7881851264534454, disc_loss = 0.11372775446351821
Trained batch 1083 in epoch 1, gen_loss = 0.7879786722334549, disc_loss = 0.11370269640269809
Trained batch 1084 in epoch 1, gen_loss = 0.787942631453413, disc_loss = 0.11367942351796385
Trained batch 1085 in epoch 1, gen_loss = 0.7877566681601944, disc_loss = 0.11364731854119409
Trained batch 1086 in epoch 1, gen_loss = 0.7882267313477307, disc_loss = 0.11363918649712998
Trained batch 1087 in epoch 1, gen_loss = 0.7883379146018449, disc_loss = 0.11357604192658875
Trained batch 1088 in epoch 1, gen_loss = 0.7881174030601704, disc_loss = 0.11363429699479657
Trained batch 1089 in epoch 1, gen_loss = 0.7885867536614795, disc_loss = 0.11371837250990878
Trained batch 1090 in epoch 1, gen_loss = 0.7886265923297263, disc_loss = 0.11366984223064264
Trained batch 1091 in epoch 1, gen_loss = 0.7885753006943853, disc_loss = 0.11369801864826254
Trained batch 1092 in epoch 1, gen_loss = 0.7889142188039922, disc_loss = 0.11366395270051426
Trained batch 1093 in epoch 1, gen_loss = 0.7889189208556355, disc_loss = 0.1136317824999337
Trained batch 1094 in epoch 1, gen_loss = 0.7889938350681845, disc_loss = 0.11354477374418957
Trained batch 1095 in epoch 1, gen_loss = 0.7889757394029276, disc_loss = 0.11347490014936638
Trained batch 1096 in epoch 1, gen_loss = 0.7891899842290088, disc_loss = 0.1135070108933376
Trained batch 1097 in epoch 1, gen_loss = 0.7891524542116294, disc_loss = 0.11344925511818386
Trained batch 1098 in epoch 1, gen_loss = 0.7891324532910625, disc_loss = 0.11347013140593853
Trained batch 1099 in epoch 1, gen_loss = 0.789138962247155, disc_loss = 0.11343759066171266
Trained batch 1100 in epoch 1, gen_loss = 0.7890082872206249, disc_loss = 0.11340799854795951
Trained batch 1101 in epoch 1, gen_loss = 0.7890327392710532, disc_loss = 0.11332934134438662
Trained batch 1102 in epoch 1, gen_loss = 0.7892612914334398, disc_loss = 0.11324749947107605
Trained batch 1103 in epoch 1, gen_loss = 0.7893263735956904, disc_loss = 0.1132620835636297
Trained batch 1104 in epoch 1, gen_loss = 0.7893378567911381, disc_loss = 0.1133008238349565
Trained batch 1105 in epoch 1, gen_loss = 0.7891666807274706, disc_loss = 0.1132665730837672
Trained batch 1106 in epoch 1, gen_loss = 0.7891171987571475, disc_loss = 0.11326149219096837
Trained batch 1107 in epoch 1, gen_loss = 0.7892750615677678, disc_loss = 0.11319889684648182
Trained batch 1108 in epoch 1, gen_loss = 0.7894269361272387, disc_loss = 0.11321858116790881
Trained batch 1109 in epoch 1, gen_loss = 0.7891584937368428, disc_loss = 0.1134233017191962
Trained batch 1110 in epoch 1, gen_loss = 0.7892386232218583, disc_loss = 0.11356788436093382
Trained batch 1111 in epoch 1, gen_loss = 0.7892565326564175, disc_loss = 0.11352991337197826
Trained batch 1112 in epoch 1, gen_loss = 0.7890162998400394, disc_loss = 0.11368152271932776
Trained batch 1113 in epoch 1, gen_loss = 0.7893707178920989, disc_loss = 0.11373544950205398
Trained batch 1114 in epoch 1, gen_loss = 0.7894611646508957, disc_loss = 0.1136743307781861
Trained batch 1115 in epoch 1, gen_loss = 0.7894574881507932, disc_loss = 0.11359478788296809
Trained batch 1116 in epoch 1, gen_loss = 0.789280339848707, disc_loss = 0.11367269097798192
Trained batch 1117 in epoch 1, gen_loss = 0.789361273639957, disc_loss = 0.11364874603603309
Trained batch 1118 in epoch 1, gen_loss = 0.7899589390228432, disc_loss = 0.11375693424244455
Trained batch 1119 in epoch 1, gen_loss = 0.7899698238021561, disc_loss = 0.113711172967617
Trained batch 1120 in epoch 1, gen_loss = 0.7899640317637403, disc_loss = 0.11375085390060741
Trained batch 1121 in epoch 1, gen_loss = 0.7898448748968927, disc_loss = 0.11373264948155153
Trained batch 1122 in epoch 1, gen_loss = 0.7900569042720014, disc_loss = 0.1136581631143472
Trained batch 1123 in epoch 1, gen_loss = 0.7903482335689229, disc_loss = 0.11372430819945138
Trained batch 1124 in epoch 1, gen_loss = 0.7901355946593814, disc_loss = 0.11374295364320278
Trained batch 1125 in epoch 1, gen_loss = 0.7902661835903808, disc_loss = 0.113807316133372
Trained batch 1126 in epoch 1, gen_loss = 0.7900424542264168, disc_loss = 0.11390265890999557
Trained batch 1127 in epoch 1, gen_loss = 0.7899955985869499, disc_loss = 0.11385273675645656
Trained batch 1128 in epoch 1, gen_loss = 0.7901007351197428, disc_loss = 0.11379368455570762
Trained batch 1129 in epoch 1, gen_loss = 0.7903061228779565, disc_loss = 0.11380656460646243
Trained batch 1130 in epoch 1, gen_loss = 0.7902872401407395, disc_loss = 0.11377385327350398
Trained batch 1131 in epoch 1, gen_loss = 0.7901726243721301, disc_loss = 0.11391120699033562
Trained batch 1132 in epoch 1, gen_loss = 0.7903536572618391, disc_loss = 0.1139115444207786
Trained batch 1133 in epoch 1, gen_loss = 0.7905007642045012, disc_loss = 0.1138943782982924
Trained batch 1134 in epoch 1, gen_loss = 0.7905225231521456, disc_loss = 0.11388142174725228
Trained batch 1135 in epoch 1, gen_loss = 0.7902600532004111, disc_loss = 0.11410982130442969
Trained batch 1136 in epoch 1, gen_loss = 0.7904392406147829, disc_loss = 0.11414937305582806
Trained batch 1137 in epoch 1, gen_loss = 0.7904849260626443, disc_loss = 0.11410128559445822
Trained batch 1138 in epoch 1, gen_loss = 0.7903844821704282, disc_loss = 0.11408865161868069
Trained batch 1139 in epoch 1, gen_loss = 0.7903976475721911, disc_loss = 0.1140653400355133
Trained batch 1140 in epoch 1, gen_loss = 0.790395273308708, disc_loss = 0.11403291341893565
Trained batch 1141 in epoch 1, gen_loss = 0.7903905522123945, disc_loss = 0.1139832221170571
Trained batch 1142 in epoch 1, gen_loss = 0.7903538167163768, disc_loss = 0.11392250422580609
Trained batch 1143 in epoch 1, gen_loss = 0.7902756218466308, disc_loss = 0.11389924781364422
Trained batch 1144 in epoch 1, gen_loss = 0.7904757495270025, disc_loss = 0.11386342996235238
Trained batch 1145 in epoch 1, gen_loss = 0.7904630973024934, disc_loss = 0.11385506331875114
Trained batch 1146 in epoch 1, gen_loss = 0.7903454135112796, disc_loss = 0.11386717963921525
Trained batch 1147 in epoch 1, gen_loss = 0.7904164405598042, disc_loss = 0.11382724155383087
Trained batch 1148 in epoch 1, gen_loss = 0.7903487189268422, disc_loss = 0.11381434122209086
Trained batch 1149 in epoch 1, gen_loss = 0.7904925217576649, disc_loss = 0.11380456410834323
Trained batch 1150 in epoch 1, gen_loss = 0.7902773546457912, disc_loss = 0.11383591515443359
Trained batch 1151 in epoch 1, gen_loss = 0.7901655627259364, disc_loss = 0.11382580581670886
Trained batch 1152 in epoch 1, gen_loss = 0.7900331988349131, disc_loss = 0.11380915108063329
Trained batch 1153 in epoch 1, gen_loss = 0.7900630228699184, disc_loss = 0.11375681219373925
Trained batch 1154 in epoch 1, gen_loss = 0.7901639176911606, disc_loss = 0.11375496649542154
Trained batch 1155 in epoch 1, gen_loss = 0.7901489998900354, disc_loss = 0.11369879672522931
Trained batch 1156 in epoch 1, gen_loss = 0.7899462457298717, disc_loss = 0.11367212293078752
Trained batch 1157 in epoch 1, gen_loss = 0.7899744004937651, disc_loss = 0.11363339571954621
Trained batch 1158 in epoch 1, gen_loss = 0.7898376799277749, disc_loss = 0.11360972412444838
Trained batch 1159 in epoch 1, gen_loss = 0.7896517475360426, disc_loss = 0.11361527167870823
Trained batch 1160 in epoch 1, gen_loss = 0.789570231128622, disc_loss = 0.11357943125672375
Trained batch 1161 in epoch 1, gen_loss = 0.7895502588886402, disc_loss = 0.11365969805928547
Trained batch 1162 in epoch 1, gen_loss = 0.7893880497302255, disc_loss = 0.11365192795936291
Trained batch 1163 in epoch 1, gen_loss = 0.7892401369730222, disc_loss = 0.11363195333329007
Trained batch 1164 in epoch 1, gen_loss = 0.7896065266603053, disc_loss = 0.1136460787093051
Trained batch 1165 in epoch 1, gen_loss = 0.7895301263236263, disc_loss = 0.11368333649107512
Trained batch 1166 in epoch 1, gen_loss = 0.7895227677564695, disc_loss = 0.11371596601744595
Trained batch 1167 in epoch 1, gen_loss = 0.7892745252800722, disc_loss = 0.11383728158488002
Trained batch 1168 in epoch 1, gen_loss = 0.7891948601697836, disc_loss = 0.11383626785788963
Trained batch 1169 in epoch 1, gen_loss = 0.789256727313384, disc_loss = 0.11378032207711894
Trained batch 1170 in epoch 1, gen_loss = 0.7891514257780005, disc_loss = 0.11375796101847385
Trained batch 1171 in epoch 1, gen_loss = 0.7892241544334961, disc_loss = 0.11373968730575751
Trained batch 1172 in epoch 1, gen_loss = 0.7891220567527228, disc_loss = 0.11372707128518429
Trained batch 1173 in epoch 1, gen_loss = 0.7891803776029834, disc_loss = 0.11372317786104787
Trained batch 1174 in epoch 1, gen_loss = 0.7895162208283201, disc_loss = 0.11366286179645264
Trained batch 1175 in epoch 1, gen_loss = 0.7894024636317678, disc_loss = 0.11364483881621387
Trained batch 1176 in epoch 1, gen_loss = 0.7895556313817341, disc_loss = 0.1135627435047113
Trained batch 1177 in epoch 1, gen_loss = 0.789436688472743, disc_loss = 0.1135714738938091
Trained batch 1178 in epoch 1, gen_loss = 0.7895040586148409, disc_loss = 0.11355264740028403
Trained batch 1179 in epoch 1, gen_loss = 0.7895733884077961, disc_loss = 0.11358102422239164
Trained batch 1180 in epoch 1, gen_loss = 0.7898024068506565, disc_loss = 0.11350347013524233
Trained batch 1181 in epoch 1, gen_loss = 0.7898266235029233, disc_loss = 0.11349585958852633
Trained batch 1182 in epoch 1, gen_loss = 0.7898150185911915, disc_loss = 0.1134539924495848
Trained batch 1183 in epoch 1, gen_loss = 0.7899201929921637, disc_loss = 0.11342022888444213
Trained batch 1184 in epoch 1, gen_loss = 0.7897524695607681, disc_loss = 0.11352026504837763
Trained batch 1185 in epoch 1, gen_loss = 0.7902247623036321, disc_loss = 0.11366267999379721
Trained batch 1186 in epoch 1, gen_loss = 0.7901491531074398, disc_loss = 0.11370147500585737
Trained batch 1187 in epoch 1, gen_loss = 0.7899837062665911, disc_loss = 0.11381801316414267
Trained batch 1188 in epoch 1, gen_loss = 0.7900593502617764, disc_loss = 0.11378018117664089
Trained batch 1189 in epoch 1, gen_loss = 0.7901041731363585, disc_loss = 0.11371916803773963
Trained batch 1190 in epoch 1, gen_loss = 0.7900048881443882, disc_loss = 0.11373162157771019
Trained batch 1191 in epoch 1, gen_loss = 0.7899865461825925, disc_loss = 0.11370717569866887
Trained batch 1192 in epoch 1, gen_loss = 0.7900744836218498, disc_loss = 0.1137187987119459
Trained batch 1193 in epoch 1, gen_loss = 0.7901843981676965, disc_loss = 0.113718005326238
Trained batch 1194 in epoch 1, gen_loss = 0.7898741046753888, disc_loss = 0.11385049360597732
Trained batch 1195 in epoch 1, gen_loss = 0.7898361194990949, disc_loss = 0.11392174998335665
Trained batch 1196 in epoch 1, gen_loss = 0.7899960665874115, disc_loss = 0.11388357897555967
Trained batch 1197 in epoch 1, gen_loss = 0.7899972256117551, disc_loss = 0.11382153608644993
Trained batch 1198 in epoch 1, gen_loss = 0.7898898716267195, disc_loss = 0.11380790269236897
Trained batch 1199 in epoch 1, gen_loss = 0.7901249424616495, disc_loss = 0.11374181957449764
Trained batch 1200 in epoch 1, gen_loss = 0.7901486325125016, disc_loss = 0.11374293807599319
Trained batch 1201 in epoch 1, gen_loss = 0.7903466649142755, disc_loss = 0.11367899506583735
Trained batch 1202 in epoch 1, gen_loss = 0.7904731227473626, disc_loss = 0.1137533496402619
Trained batch 1203 in epoch 1, gen_loss = 0.7902549289389702, disc_loss = 0.11388144331312804
Trained batch 1204 in epoch 1, gen_loss = 0.7903048413423087, disc_loss = 0.11380619734865749
Trained batch 1205 in epoch 1, gen_loss = 0.790263262702458, disc_loss = 0.11375160880578346
Trained batch 1206 in epoch 1, gen_loss = 0.7906484790053758, disc_loss = 0.113696592697116
Trained batch 1207 in epoch 1, gen_loss = 0.790523852092146, disc_loss = 0.11364543832844703
Trained batch 1208 in epoch 1, gen_loss = 0.7904636938282041, disc_loss = 0.11358209286344209
Trained batch 1209 in epoch 1, gen_loss = 0.7904112927677217, disc_loss = 0.11358062363083452
Trained batch 1210 in epoch 1, gen_loss = 0.790196578380591, disc_loss = 0.11369353263776574
Trained batch 1211 in epoch 1, gen_loss = 0.7901584508002001, disc_loss = 0.11364646871165425
Trained batch 1212 in epoch 1, gen_loss = 0.7901983362333105, disc_loss = 0.1135986773381647
Trained batch 1213 in epoch 1, gen_loss = 0.7902977797992933, disc_loss = 0.11352262585201413
Trained batch 1214 in epoch 1, gen_loss = 0.79034384680383, disc_loss = 0.11344781974982086
Trained batch 1215 in epoch 1, gen_loss = 0.7903179932189616, disc_loss = 0.11339386193369712
Trained batch 1216 in epoch 1, gen_loss = 0.790403289048517, disc_loss = 0.11335196837801226
Trained batch 1217 in epoch 1, gen_loss = 0.7904498877587969, disc_loss = 0.11334288277019469
Trained batch 1218 in epoch 1, gen_loss = 0.7902678287449775, disc_loss = 0.11337602263357768
Trained batch 1219 in epoch 1, gen_loss = 0.7905071669914684, disc_loss = 0.11335684436174934
Trained batch 1220 in epoch 1, gen_loss = 0.7905714410333532, disc_loss = 0.11339863494227745
Trained batch 1221 in epoch 1, gen_loss = 0.7903936044381605, disc_loss = 0.11352117548798822
Trained batch 1222 in epoch 1, gen_loss = 0.7905565385728807, disc_loss = 0.11349781273193323
Trained batch 1223 in epoch 1, gen_loss = 0.7905325343698458, disc_loss = 0.11346313570553035
Trained batch 1224 in epoch 1, gen_loss = 0.7905374437935498, disc_loss = 0.11347818175292745
Trained batch 1225 in epoch 1, gen_loss = 0.7904115880780275, disc_loss = 0.1135458265116733
Trained batch 1226 in epoch 1, gen_loss = 0.7904130280163585, disc_loss = 0.11351951925325364
Trained batch 1227 in epoch 1, gen_loss = 0.7908128594633811, disc_loss = 0.11357795364748238
Trained batch 1228 in epoch 1, gen_loss = 0.7907536829555781, disc_loss = 0.11356213668390103
Trained batch 1229 in epoch 1, gen_loss = 0.7907642895128669, disc_loss = 0.11359167325696568
Trained batch 1230 in epoch 1, gen_loss = 0.7907540655349155, disc_loss = 0.11357569941005553
Trained batch 1231 in epoch 1, gen_loss = 0.7906825722908819, disc_loss = 0.1135749677332215
Trained batch 1232 in epoch 1, gen_loss = 0.79080258407732, disc_loss = 0.11349821096891953
Trained batch 1233 in epoch 1, gen_loss = 0.7906222910027063, disc_loss = 0.11347246075402251
Trained batch 1234 in epoch 1, gen_loss = 0.7909248018554348, disc_loss = 0.11351637692616777
Trained batch 1235 in epoch 1, gen_loss = 0.7908858014059684, disc_loss = 0.11345307514957577
Trained batch 1236 in epoch 1, gen_loss = 0.7907398775786089, disc_loss = 0.11340818336277164
Trained batch 1237 in epoch 1, gen_loss = 0.7907703503942258, disc_loss = 0.11342485189612395
Trained batch 1238 in epoch 1, gen_loss = 0.7907153165465501, disc_loss = 0.11341827526490134
Trained batch 1239 in epoch 1, gen_loss = 0.7905655843115622, disc_loss = 0.11347049634092518
Trained batch 1240 in epoch 1, gen_loss = 0.7904248499370793, disc_loss = 0.11352616346363911
Trained batch 1241 in epoch 1, gen_loss = 0.7903662028807948, disc_loss = 0.11349721066503757
Trained batch 1242 in epoch 1, gen_loss = 0.7904076883606822, disc_loss = 0.11346440441151204
Trained batch 1243 in epoch 1, gen_loss = 0.7904304447568881, disc_loss = 0.11352561865379238
Trained batch 1244 in epoch 1, gen_loss = 0.7901109471617932, disc_loss = 0.11359216021037245
Trained batch 1245 in epoch 1, gen_loss = 0.7898850453655755, disc_loss = 0.11359525707671433
Trained batch 1246 in epoch 1, gen_loss = 0.7900748888826791, disc_loss = 0.11370400742813647
Trained batch 1247 in epoch 1, gen_loss = 0.7900864020324289, disc_loss = 0.11369727153289251
Trained batch 1248 in epoch 1, gen_loss = 0.7899988821690516, disc_loss = 0.11367641752205485
Trained batch 1249 in epoch 1, gen_loss = 0.7899241941690445, disc_loss = 0.11378919733911752
Trained batch 1250 in epoch 1, gen_loss = 0.7897727784159467, disc_loss = 0.11384761525388006
Trained batch 1251 in epoch 1, gen_loss = 0.7898146718407211, disc_loss = 0.1139192232585396
Trained batch 1252 in epoch 1, gen_loss = 0.789725113966326, disc_loss = 0.11393367518884176
Trained batch 1253 in epoch 1, gen_loss = 0.7895782258379402, disc_loss = 0.11408599277295801
Trained batch 1254 in epoch 1, gen_loss = 0.7894716770288004, disc_loss = 0.11408859918346681
Trained batch 1255 in epoch 1, gen_loss = 0.7898315632846326, disc_loss = 0.11414739276745185
Trained batch 1256 in epoch 1, gen_loss = 0.7898025200920819, disc_loss = 0.11414430502805097
Trained batch 1257 in epoch 1, gen_loss = 0.7896359182645483, disc_loss = 0.11421865294280274
Trained batch 1258 in epoch 1, gen_loss = 0.7894594316401115, disc_loss = 0.11419587286013143
Trained batch 1259 in epoch 1, gen_loss = 0.7898262693058877, disc_loss = 0.11424766677387413
Trained batch 1260 in epoch 1, gen_loss = 0.7897885944945391, disc_loss = 0.11421433842277877
Trained batch 1261 in epoch 1, gen_loss = 0.7896384528104552, disc_loss = 0.11422425699339096
Trained batch 1262 in epoch 1, gen_loss = 0.7896335048752934, disc_loss = 0.11422849207178572
Trained batch 1263 in epoch 1, gen_loss = 0.7894778631486093, disc_loss = 0.11421065337961846
Trained batch 1264 in epoch 1, gen_loss = 0.7894121993436173, disc_loss = 0.11417447256859348
Trained batch 1265 in epoch 1, gen_loss = 0.7893187268320795, disc_loss = 0.1141133622161891
Trained batch 1266 in epoch 1, gen_loss = 0.7894232549484828, disc_loss = 0.11411612045281547
Trained batch 1267 in epoch 1, gen_loss = 0.7894159521355237, disc_loss = 0.11405709094576515
Trained batch 1268 in epoch 1, gen_loss = 0.7894073446450786, disc_loss = 0.11400007880590063
Trained batch 1269 in epoch 1, gen_loss = 0.7894241438371928, disc_loss = 0.11395904863121237
Trained batch 1270 in epoch 1, gen_loss = 0.7895193110527156, disc_loss = 0.11393776036693438
Trained batch 1271 in epoch 1, gen_loss = 0.7895459592482954, disc_loss = 0.11388352786999126
Trained batch 1272 in epoch 1, gen_loss = 0.7897398800289921, disc_loss = 0.11380584200131594
Trained batch 1273 in epoch 1, gen_loss = 0.7897328376723234, disc_loss = 0.11374802169721906
Trained batch 1274 in epoch 1, gen_loss = 0.7895067980476455, disc_loss = 0.11382811355094115
Trained batch 1275 in epoch 1, gen_loss = 0.7895636381727401, disc_loss = 0.11383549403545204
Trained batch 1276 in epoch 1, gen_loss = 0.7898427434469819, disc_loss = 0.11384517797352797
Trained batch 1277 in epoch 1, gen_loss = 0.7897338713978378, disc_loss = 0.11381944124798213
Trained batch 1278 in epoch 1, gen_loss = 0.7897261213613171, disc_loss = 0.11383454632552878
Trained batch 1279 in epoch 1, gen_loss = 0.7896098752738908, disc_loss = 0.11382956730521983
Trained batch 1280 in epoch 1, gen_loss = 0.7896399517760995, disc_loss = 0.11376777010810599
Trained batch 1281 in epoch 1, gen_loss = 0.7895431819135053, disc_loss = 0.1138622583966708
Trained batch 1282 in epoch 1, gen_loss = 0.7894672666642225, disc_loss = 0.1138354713548721
Trained batch 1283 in epoch 1, gen_loss = 0.7896784632423214, disc_loss = 0.11410835092144546
Trained batch 1284 in epoch 1, gen_loss = 0.7894499943182163, disc_loss = 0.11418218412490902
Trained batch 1285 in epoch 1, gen_loss = 0.7892161159780496, disc_loss = 0.11428936608396413
Trained batch 1286 in epoch 1, gen_loss = 0.7893565732236045, disc_loss = 0.11425675073003204
Trained batch 1287 in epoch 1, gen_loss = 0.7895167829318447, disc_loss = 0.11435369719022317
Trained batch 1288 in epoch 1, gen_loss = 0.7892645541737485, disc_loss = 0.11440985105769916
Trained batch 1289 in epoch 1, gen_loss = 0.7891672955233922, disc_loss = 0.11441717755858057
Trained batch 1290 in epoch 1, gen_loss = 0.7889842623938524, disc_loss = 0.11445729776576312
Trained batch 1291 in epoch 1, gen_loss = 0.7891898507442636, disc_loss = 0.11443249945710457
Trained batch 1292 in epoch 1, gen_loss = 0.7892152229345591, disc_loss = 0.11439076581881984
Trained batch 1293 in epoch 1, gen_loss = 0.7891333182176814, disc_loss = 0.11438470772702183
Trained batch 1294 in epoch 1, gen_loss = 0.7889518403408611, disc_loss = 0.11443696187873835
Trained batch 1295 in epoch 1, gen_loss = 0.7889119007475214, disc_loss = 0.11447377454771165
Trained batch 1296 in epoch 1, gen_loss = 0.7890377014576699, disc_loss = 0.11442139397361642
Trained batch 1297 in epoch 1, gen_loss = 0.7889453828197047, disc_loss = 0.11446307901040477
Trained batch 1298 in epoch 1, gen_loss = 0.7890282062450861, disc_loss = 0.11445107807285562
Trained batch 1299 in epoch 1, gen_loss = 0.7890782053424762, disc_loss = 0.11447434435813472
Trained batch 1300 in epoch 1, gen_loss = 0.7889757423699589, disc_loss = 0.11448353117934609
Trained batch 1301 in epoch 1, gen_loss = 0.7889024962981542, disc_loss = 0.11444550581682708
Trained batch 1302 in epoch 1, gen_loss = 0.7891031136580458, disc_loss = 0.11441748702637022
Trained batch 1303 in epoch 1, gen_loss = 0.7890625770426601, disc_loss = 0.11438556533289697
Trained batch 1304 in epoch 1, gen_loss = 0.7890523521607863, disc_loss = 0.11440237593976245
Trained batch 1305 in epoch 1, gen_loss = 0.7890341097737162, disc_loss = 0.11438691538614527
Trained batch 1306 in epoch 1, gen_loss = 0.7891008393082257, disc_loss = 0.1143729209731737
Trained batch 1307 in epoch 1, gen_loss = 0.7890812835972244, disc_loss = 0.11433719235987884
Trained batch 1308 in epoch 1, gen_loss = 0.7890565991174, disc_loss = 0.11432229810749374
Trained batch 1309 in epoch 1, gen_loss = 0.7890601327173582, disc_loss = 0.1142576354733519
Trained batch 1310 in epoch 1, gen_loss = 0.7889809161765624, disc_loss = 0.11420732755768082
Trained batch 1311 in epoch 1, gen_loss = 0.7891540093710874, disc_loss = 0.11415856808463748
Trained batch 1312 in epoch 1, gen_loss = 0.7891371316203432, disc_loss = 0.11411141425297402
Trained batch 1313 in epoch 1, gen_loss = 0.7891959176714924, disc_loss = 0.11404233308908739
Trained batch 1314 in epoch 1, gen_loss = 0.7896346284182806, disc_loss = 0.11408072152376855
Trained batch 1315 in epoch 1, gen_loss = 0.7895037509885965, disc_loss = 0.11409151193892475
Trained batch 1316 in epoch 1, gen_loss = 0.78959019659773, disc_loss = 0.11402746916366013
Trained batch 1317 in epoch 1, gen_loss = 0.7896494118098243, disc_loss = 0.11396997314997934
Trained batch 1318 in epoch 1, gen_loss = 0.7896775963226894, disc_loss = 0.11389524981215698
Trained batch 1319 in epoch 1, gen_loss = 0.789606885047573, disc_loss = 0.11394471025630606
Trained batch 1320 in epoch 1, gen_loss = 0.7895950442412691, disc_loss = 0.11388945144253594
Trained batch 1321 in epoch 1, gen_loss = 0.7895434955740841, disc_loss = 0.11384821275274484
Trained batch 1322 in epoch 1, gen_loss = 0.7896113496383572, disc_loss = 0.11380817210238402
Trained batch 1323 in epoch 1, gen_loss = 0.7895928687244383, disc_loss = 0.11385309986708253
Trained batch 1324 in epoch 1, gen_loss = 0.7896740663501451, disc_loss = 0.11382043076151947
Trained batch 1325 in epoch 1, gen_loss = 0.7899611117838016, disc_loss = 0.11378064162068373
Trained batch 1326 in epoch 1, gen_loss = 0.7899964609672544, disc_loss = 0.11370951928669965
Trained batch 1327 in epoch 1, gen_loss = 0.7902557806123093, disc_loss = 0.11364252932779266
Trained batch 1328 in epoch 1, gen_loss = 0.7900329523511719, disc_loss = 0.11365678195720377
Trained batch 1329 in epoch 1, gen_loss = 0.7900949079515343, disc_loss = 0.11358818208196557
Trained batch 1330 in epoch 1, gen_loss = 0.7902262612315248, disc_loss = 0.11351196142368349
Trained batch 1331 in epoch 1, gen_loss = 0.7900114741187554, disc_loss = 0.11348794781331632
Trained batch 1332 in epoch 1, gen_loss = 0.790138945598309, disc_loss = 0.11341929843471807
Trained batch 1333 in epoch 1, gen_loss = 0.7902484698140103, disc_loss = 0.11346670838611862
Trained batch 1334 in epoch 1, gen_loss = 0.7902417190289229, disc_loss = 0.11339639166042152
Trained batch 1335 in epoch 1, gen_loss = 0.7901002269706683, disc_loss = 0.1133695658056545
Trained batch 1336 in epoch 1, gen_loss = 0.7901799560886046, disc_loss = 0.11330913308458981
Trained batch 1337 in epoch 1, gen_loss = 0.790428647612777, disc_loss = 0.11331513612315348
Trained batch 1338 in epoch 1, gen_loss = 0.790371339142189, disc_loss = 0.11330512613113733
Trained batch 1339 in epoch 1, gen_loss = 0.7903717397086656, disc_loss = 0.11335307428363099
Trained batch 1340 in epoch 1, gen_loss = 0.7903383861141006, disc_loss = 0.1133127413317839
Trained batch 1341 in epoch 1, gen_loss = 0.7901627411385762, disc_loss = 0.11330527595720419
Trained batch 1342 in epoch 1, gen_loss = 0.7902277168593829, disc_loss = 0.1132591645457322
Trained batch 1343 in epoch 1, gen_loss = 0.7901443276066511, disc_loss = 0.11332681514267322
Trained batch 1344 in epoch 1, gen_loss = 0.7905398218383576, disc_loss = 0.11327257785378335
Trained batch 1345 in epoch 1, gen_loss = 0.790646663502988, disc_loss = 0.1132332025618911
Trained batch 1346 in epoch 1, gen_loss = 0.7906625567539232, disc_loss = 0.11318316633115455
Trained batch 1347 in epoch 1, gen_loss = 0.7906333831766239, disc_loss = 0.11313316832885191
Trained batch 1348 in epoch 1, gen_loss = 0.7907809654680157, disc_loss = 0.11313765381688626
Trained batch 1349 in epoch 1, gen_loss = 0.7905814407269159, disc_loss = 0.113121373531995
Trained batch 1350 in epoch 1, gen_loss = 0.7905821581181555, disc_loss = 0.11310940489536916
Trained batch 1351 in epoch 1, gen_loss = 0.7904868292782081, disc_loss = 0.11309471857574212
Trained batch 1352 in epoch 1, gen_loss = 0.790691729858022, disc_loss = 0.11306145238219943
Trained batch 1353 in epoch 1, gen_loss = 0.7908506696518274, disc_loss = 0.1130093930253382
Trained batch 1354 in epoch 1, gen_loss = 0.7908033823395128, disc_loss = 0.11297829964668989
Trained batch 1355 in epoch 1, gen_loss = 0.7908517628864201, disc_loss = 0.11293910267408443
Trained batch 1356 in epoch 1, gen_loss = 0.7910493984104696, disc_loss = 0.11286743123471385
Trained batch 1357 in epoch 1, gen_loss = 0.7915325343213833, disc_loss = 0.11292010417210818
Trained batch 1358 in epoch 1, gen_loss = 0.7914218356321628, disc_loss = 0.1129323969402565
Trained batch 1359 in epoch 1, gen_loss = 0.7914795318289715, disc_loss = 0.11287132153041003
Trained batch 1360 in epoch 1, gen_loss = 0.7918505833527343, disc_loss = 0.11282132068768001
Trained batch 1361 in epoch 1, gen_loss = 0.792107084270966, disc_loss = 0.11279111627281456
Trained batch 1362 in epoch 1, gen_loss = 0.7921468374795627, disc_loss = 0.11276112861319097
Trained batch 1363 in epoch 1, gen_loss = 0.7920751413248501, disc_loss = 0.11283687246919684
Trained batch 1364 in epoch 1, gen_loss = 0.7925367040730221, disc_loss = 0.11298765702098063
Trained batch 1365 in epoch 1, gen_loss = 0.7925931133035335, disc_loss = 0.11294604379869179
Trained batch 1366 in epoch 1, gen_loss = 0.792645217143626, disc_loss = 0.11287865112586752
Trained batch 1367 in epoch 1, gen_loss = 0.7927917020929138, disc_loss = 0.11282060840929592
Trained batch 1368 in epoch 1, gen_loss = 0.7929199417853025, disc_loss = 0.11276381719555403
Trained batch 1369 in epoch 1, gen_loss = 0.7928975069392337, disc_loss = 0.11273199047784518
Trained batch 1370 in epoch 1, gen_loss = 0.7929975563248607, disc_loss = 0.11266474432449851
Trained batch 1371 in epoch 1, gen_loss = 0.7930778406842804, disc_loss = 0.1126071454769777
Trained batch 1372 in epoch 1, gen_loss = 0.7931618102475491, disc_loss = 0.11256303377340983
Trained batch 1373 in epoch 1, gen_loss = 0.7930768586185475, disc_loss = 0.11261567882407224
Trained batch 1374 in epoch 1, gen_loss = 0.7934056581367146, disc_loss = 0.11255537184395574
Trained batch 1375 in epoch 1, gen_loss = 0.793791825016744, disc_loss = 0.11255862893195563
Trained batch 1376 in epoch 1, gen_loss = 0.7941089141559324, disc_loss = 0.11250910557774027
Trained batch 1377 in epoch 1, gen_loss = 0.7939810829212773, disc_loss = 0.11254720397277347
Trained batch 1378 in epoch 1, gen_loss = 0.794016993914591, disc_loss = 0.11250270650660629
Trained batch 1379 in epoch 1, gen_loss = 0.7942160503371902, disc_loss = 0.1125139140928893
Trained batch 1380 in epoch 1, gen_loss = 0.7942050447893868, disc_loss = 0.11247070527390714
Trained batch 1381 in epoch 1, gen_loss = 0.7939233871125623, disc_loss = 0.11250536037978276
Trained batch 1382 in epoch 1, gen_loss = 0.7938123669688114, disc_loss = 0.112534200118091
Trained batch 1383 in epoch 1, gen_loss = 0.7939042689526357, disc_loss = 0.1125937869618889
Trained batch 1384 in epoch 1, gen_loss = 0.7938792022341855, disc_loss = 0.11255426526688281
Trained batch 1385 in epoch 1, gen_loss = 0.7938479492373625, disc_loss = 0.11265270854245661
Trained batch 1386 in epoch 1, gen_loss = 0.7938017695819893, disc_loss = 0.11264337219362347
Trained batch 1387 in epoch 1, gen_loss = 0.7937440879277949, disc_loss = 0.11264226018110296
Trained batch 1388 in epoch 1, gen_loss = 0.7937954728812773, disc_loss = 0.11279869505892863
Trained batch 1389 in epoch 1, gen_loss = 0.7938306745222147, disc_loss = 0.1127584305209972
Trained batch 1390 in epoch 1, gen_loss = 0.7937564506837569, disc_loss = 0.11274091500218483
Trained batch 1391 in epoch 1, gen_loss = 0.7936671323774532, disc_loss = 0.1127390806956602
Trained batch 1392 in epoch 1, gen_loss = 0.7936907668423498, disc_loss = 0.112716858537984
Trained batch 1393 in epoch 1, gen_loss = 0.7935063752373801, disc_loss = 0.11270218190083674
Trained batch 1394 in epoch 1, gen_loss = 0.7935720221329761, disc_loss = 0.1126575944391096
Trained batch 1395 in epoch 1, gen_loss = 0.793591668258253, disc_loss = 0.11263801761499918
Trained batch 1396 in epoch 1, gen_loss = 0.7934961154491627, disc_loss = 0.112726677717133
Trained batch 1397 in epoch 1, gen_loss = 0.7934913110195823, disc_loss = 0.11267983303065592
Trained batch 1398 in epoch 1, gen_loss = 0.7935697795707384, disc_loss = 0.11264550718235876
Trained batch 1399 in epoch 1, gen_loss = 0.7933801151386329, disc_loss = 0.11264767318830958
Trained batch 1400 in epoch 1, gen_loss = 0.7932517738915783, disc_loss = 0.11265544537361778
Trained batch 1401 in epoch 1, gen_loss = 0.793387816801731, disc_loss = 0.1126154688374271
Trained batch 1402 in epoch 1, gen_loss = 0.7932878817436275, disc_loss = 0.11264652591424378
Trained batch 1403 in epoch 1, gen_loss = 0.7934648908059142, disc_loss = 0.1126971919808611
Trained batch 1404 in epoch 1, gen_loss = 0.7934837197705944, disc_loss = 0.11267647531506642
Trained batch 1405 in epoch 1, gen_loss = 0.7932781104639618, disc_loss = 0.11277257736274181
Trained batch 1406 in epoch 1, gen_loss = 0.7934170524829994, disc_loss = 0.11272153782167796
Trained batch 1407 in epoch 1, gen_loss = 0.7935477781151845, disc_loss = 0.11271097693745767
Trained batch 1408 in epoch 1, gen_loss = 0.7935427438502112, disc_loss = 0.11265178678347085
Trained batch 1409 in epoch 1, gen_loss = 0.79354099434741, disc_loss = 0.11262774926128116
Trained batch 1410 in epoch 1, gen_loss = 0.7935803277242446, disc_loss = 0.11256391364978105
Trained batch 1411 in epoch 1, gen_loss = 0.7936425888462377, disc_loss = 0.11254857789735619
Trained batch 1412 in epoch 1, gen_loss = 0.7934567631556476, disc_loss = 0.1126147290851238
Trained batch 1413 in epoch 1, gen_loss = 0.7933969622664944, disc_loss = 0.11262957816034598
Trained batch 1414 in epoch 1, gen_loss = 0.7933057037975257, disc_loss = 0.11261317624114849
Trained batch 1415 in epoch 1, gen_loss = 0.7933338003096271, disc_loss = 0.11257400673861473
Trained batch 1416 in epoch 1, gen_loss = 0.7933314213596269, disc_loss = 0.11251676672558256
Trained batch 1417 in epoch 1, gen_loss = 0.7932713567496018, disc_loss = 0.11248031656595396
Trained batch 1418 in epoch 1, gen_loss = 0.7932266250851291, disc_loss = 0.11249284304211138
Trained batch 1419 in epoch 1, gen_loss = 0.793055926934934, disc_loss = 0.11248323144784696
Trained batch 1420 in epoch 1, gen_loss = 0.7931595867280806, disc_loss = 0.11244504303683872
Trained batch 1421 in epoch 1, gen_loss = 0.7934424624203295, disc_loss = 0.11240823497228146
Trained batch 1422 in epoch 1, gen_loss = 0.793468003887068, disc_loss = 0.11236726347610972
Trained batch 1423 in epoch 1, gen_loss = 0.7934325576205267, disc_loss = 0.11237500453618972
Trained batch 1424 in epoch 1, gen_loss = 0.7934022282508382, disc_loss = 0.11231860616750884
Trained batch 1425 in epoch 1, gen_loss = 0.7938367664855794, disc_loss = 0.1124254115876777
Trained batch 1426 in epoch 1, gen_loss = 0.7938501108711887, disc_loss = 0.11239892656809815
Trained batch 1427 in epoch 1, gen_loss = 0.7940022574544621, disc_loss = 0.11234558655434296
Trained batch 1428 in epoch 1, gen_loss = 0.7941090724658432, disc_loss = 0.11228074273648506
Trained batch 1429 in epoch 1, gen_loss = 0.7940331808545372, disc_loss = 0.11221827313538406
Trained batch 1430 in epoch 1, gen_loss = 0.7942653481440474, disc_loss = 0.11217165402130885
Trained batch 1431 in epoch 1, gen_loss = 0.7940751733934747, disc_loss = 0.11218107074067288
Trained batch 1432 in epoch 1, gen_loss = 0.7943953062093765, disc_loss = 0.11213137868295286
Trained batch 1433 in epoch 1, gen_loss = 0.7946603524510332, disc_loss = 0.11207555297689416
Trained batch 1434 in epoch 1, gen_loss = 0.7948066498967413, disc_loss = 0.11200872233546362
Trained batch 1435 in epoch 1, gen_loss = 0.7948537531378873, disc_loss = 0.11195536136943691
Trained batch 1436 in epoch 1, gen_loss = 0.7948760157794528, disc_loss = 0.11190996175565775
Trained batch 1437 in epoch 1, gen_loss = 0.7949158766712366, disc_loss = 0.11184785828015072
Trained batch 1438 in epoch 1, gen_loss = 0.7949585989790712, disc_loss = 0.11178616042520081
Trained batch 1439 in epoch 1, gen_loss = 0.7950667400947875, disc_loss = 0.11171534364758473
Trained batch 1440 in epoch 1, gen_loss = 0.7952827308469146, disc_loss = 0.11165346708446017
Trained batch 1441 in epoch 1, gen_loss = 0.7954319105192957, disc_loss = 0.11161878872301104
Trained batch 1442 in epoch 1, gen_loss = 0.7954442011384772, disc_loss = 0.11156550869836175
Trained batch 1443 in epoch 1, gen_loss = 0.7953823537583826, disc_loss = 0.11151095595948625
Trained batch 1444 in epoch 1, gen_loss = 0.7955627606608051, disc_loss = 0.11144250407943883
Trained batch 1445 in epoch 1, gen_loss = 0.7957040989258807, disc_loss = 0.11138829150537279
Trained batch 1446 in epoch 1, gen_loss = 0.7957730040973684, disc_loss = 0.11132163658954394
Trained batch 1447 in epoch 1, gen_loss = 0.7958948667166312, disc_loss = 0.11125345196116983
Trained batch 1448 in epoch 1, gen_loss = 0.7959940696972004, disc_loss = 0.11118548194857879
Trained batch 1449 in epoch 1, gen_loss = 0.7961900446538267, disc_loss = 0.11111538062514416
Trained batch 1450 in epoch 1, gen_loss = 0.7963251764202512, disc_loss = 0.11104678519796721
Trained batch 1451 in epoch 1, gen_loss = 0.7963169867136919, disc_loss = 0.11099935503427667
Trained batch 1452 in epoch 1, gen_loss = 0.796416498736029, disc_loss = 0.11093752638995134
Trained batch 1453 in epoch 1, gen_loss = 0.7967543047551767, disc_loss = 0.1108857743843027
Trained batch 1454 in epoch 1, gen_loss = 0.7970792598126271, disc_loss = 0.11083816406973142
Trained batch 1455 in epoch 1, gen_loss = 0.7970068893794503, disc_loss = 0.11081553274921684
Trained batch 1456 in epoch 1, gen_loss = 0.796796283168832, disc_loss = 0.11088284806974166
Trained batch 1457 in epoch 1, gen_loss = 0.7968578574915809, disc_loss = 0.1109241075559541
Trained batch 1458 in epoch 1, gen_loss = 0.796950639805784, disc_loss = 0.1108986041690539
Trained batch 1459 in epoch 1, gen_loss = 0.7968937248808063, disc_loss = 0.11091115151480962
Trained batch 1460 in epoch 1, gen_loss = 0.7969236927110801, disc_loss = 0.11087391511546696
Trained batch 1461 in epoch 1, gen_loss = 0.7970214200737376, disc_loss = 0.110856954796334
Trained batch 1462 in epoch 1, gen_loss = 0.7970001089678834, disc_loss = 0.11092513793365176
Trained batch 1463 in epoch 1, gen_loss = 0.7969063195944484, disc_loss = 0.11087833038376023
Trained batch 1464 in epoch 1, gen_loss = 0.7968080634550023, disc_loss = 0.11084915068788842
Trained batch 1465 in epoch 1, gen_loss = 0.7969655151419229, disc_loss = 0.11084242390041807
Trained batch 1466 in epoch 1, gen_loss = 0.7970487740304735, disc_loss = 0.11077576631904867
Trained batch 1467 in epoch 1, gen_loss = 0.7970428835468656, disc_loss = 0.11074573956734478
Trained batch 1468 in epoch 1, gen_loss = 0.7969935502707349, disc_loss = 0.11072678631203284
Trained batch 1469 in epoch 1, gen_loss = 0.7968604317327745, disc_loss = 0.11072706623243637
Trained batch 1470 in epoch 1, gen_loss = 0.7969742920186388, disc_loss = 0.11071855422390471
Trained batch 1471 in epoch 1, gen_loss = 0.7969498472774158, disc_loss = 0.11071658744375505
Trained batch 1472 in epoch 1, gen_loss = 0.7971622395580186, disc_loss = 0.11065245408233501
Trained batch 1473 in epoch 1, gen_loss = 0.7970561359274824, disc_loss = 0.11062530742697872
Trained batch 1474 in epoch 1, gen_loss = 0.7970763725749517, disc_loss = 0.11057799700584452
Trained batch 1475 in epoch 1, gen_loss = 0.7969140384174621, disc_loss = 0.11057626930138646
Trained batch 1476 in epoch 1, gen_loss = 0.796984693006478, disc_loss = 0.11055423100034409
Trained batch 1477 in epoch 1, gen_loss = 0.7971539717969133, disc_loss = 0.11056306430029006
Trained batch 1478 in epoch 1, gen_loss = 0.7970890081597793, disc_loss = 0.11058435363013693
Trained batch 1479 in epoch 1, gen_loss = 0.7969243690774247, disc_loss = 0.11057759760627271
Trained batch 1480 in epoch 1, gen_loss = 0.7971380815402951, disc_loss = 0.11065461880110511
Trained batch 1481 in epoch 1, gen_loss = 0.7971165259437845, disc_loss = 0.11063806170298543
Trained batch 1482 in epoch 1, gen_loss = 0.797057709497772, disc_loss = 0.11065615518288643
Trained batch 1483 in epoch 1, gen_loss = 0.7969335367014466, disc_loss = 0.1106918833790864
Trained batch 1484 in epoch 1, gen_loss = 0.7968531911220614, disc_loss = 0.11071738641495857
Trained batch 1485 in epoch 1, gen_loss = 0.7969945319408042, disc_loss = 0.11072098184627648
Trained batch 1486 in epoch 1, gen_loss = 0.7968937701319558, disc_loss = 0.11074570864163434
Trained batch 1487 in epoch 1, gen_loss = 0.7970761957988944, disc_loss = 0.1107521118027889
Trained batch 1488 in epoch 1, gen_loss = 0.797053653654274, disc_loss = 0.11070601634250903
Trained batch 1489 in epoch 1, gen_loss = 0.7968775810811344, disc_loss = 0.11072717779159746
Trained batch 1490 in epoch 1, gen_loss = 0.796907435520474, disc_loss = 0.11071172973864395
Trained batch 1491 in epoch 1, gen_loss = 0.7967365650165497, disc_loss = 0.11069082453891875
Trained batch 1492 in epoch 1, gen_loss = 0.7967956889338407, disc_loss = 0.11069764469470142
Trained batch 1493 in epoch 1, gen_loss = 0.7968227657448336, disc_loss = 0.11064743498337755
Trained batch 1494 in epoch 1, gen_loss = 0.7966616774881166, disc_loss = 0.11079645042609809
Trained batch 1495 in epoch 1, gen_loss = 0.7968732592734423, disc_loss = 0.11084851128905812
Trained batch 1496 in epoch 1, gen_loss = 0.7970260809323114, disc_loss = 0.11101647700216066
Trained batch 1497 in epoch 1, gen_loss = 0.796834972974296, disc_loss = 0.11102119983809296
Trained batch 1498 in epoch 1, gen_loss = 0.7966723492576568, disc_loss = 0.1110552954484396
Trained batch 1499 in epoch 1, gen_loss = 0.7967957175572713, disc_loss = 0.11106369631861647
Trained batch 1500 in epoch 1, gen_loss = 0.7968519148550218, disc_loss = 0.11104597204763797
Trained batch 1501 in epoch 1, gen_loss = 0.7967381500769233, disc_loss = 0.11110081284439635
Trained batch 1502 in epoch 1, gen_loss = 0.7968693396605735, disc_loss = 0.11107648971427977
Trained batch 1503 in epoch 1, gen_loss = 0.7968459871221096, disc_loss = 0.11105472656298786
Trained batch 1504 in epoch 1, gen_loss = 0.7968711748471687, disc_loss = 0.11103794436493387
Trained batch 1505 in epoch 1, gen_loss = 0.7966758053141286, disc_loss = 0.11104848295583787
Trained batch 1506 in epoch 1, gen_loss = 0.7964885468188705, disc_loss = 0.11108580468359694
Trained batch 1507 in epoch 1, gen_loss = 0.7964706045404986, disc_loss = 0.11120749120069395
Trained batch 1508 in epoch 1, gen_loss = 0.79645282559398, disc_loss = 0.11119102576909237
Trained batch 1509 in epoch 1, gen_loss = 0.7964030289097338, disc_loss = 0.11116000695511798
Trained batch 1510 in epoch 1, gen_loss = 0.7962158074211712, disc_loss = 0.11114728313079936
Trained batch 1511 in epoch 1, gen_loss = 0.7962031200449303, disc_loss = 0.11117843519181762
Trained batch 1512 in epoch 1, gen_loss = 0.7962522802964316, disc_loss = 0.11113890940637401
Trained batch 1513 in epoch 1, gen_loss = 0.7962958883184108, disc_loss = 0.11111667622471305
Trained batch 1514 in epoch 1, gen_loss = 0.7962831656924962, disc_loss = 0.11107961343287831
Trained batch 1515 in epoch 1, gen_loss = 0.7962704631929977, disc_loss = 0.111035664918486
Trained batch 1516 in epoch 1, gen_loss = 0.7962799740214841, disc_loss = 0.11101849986781749
Trained batch 1517 in epoch 1, gen_loss = 0.7962316225954038, disc_loss = 0.11100846997858546
Trained batch 1518 in epoch 1, gen_loss = 0.7963041104008447, disc_loss = 0.11096071560423848
Trained batch 1519 in epoch 1, gen_loss = 0.7962715675172053, disc_loss = 0.11092076951662373
Trained batch 1520 in epoch 1, gen_loss = 0.796239555783369, disc_loss = 0.11090620232526799
Trained batch 1521 in epoch 1, gen_loss = 0.7961905286518879, disc_loss = 0.11085627938445741
Trained batch 1522 in epoch 1, gen_loss = 0.7960308091231889, disc_loss = 0.11085689693655101
Trained batch 1523 in epoch 1, gen_loss = 0.7958959643765697, disc_loss = 0.11087664409987921
Trained batch 1524 in epoch 1, gen_loss = 0.7960528505825606, disc_loss = 0.11085733899449716
Trained batch 1525 in epoch 1, gen_loss = 0.7959306897060899, disc_loss = 0.11086787053092162
Trained batch 1526 in epoch 1, gen_loss = 0.795875445954848, disc_loss = 0.11083946290798607
Trained batch 1527 in epoch 1, gen_loss = 0.7960002946603985, disc_loss = 0.11077532623480049
Trained batch 1528 in epoch 1, gen_loss = 0.7958917321528852, disc_loss = 0.11074850296734438
Trained batch 1529 in epoch 1, gen_loss = 0.7958132230768017, disc_loss = 0.11082590334604378
Trained batch 1530 in epoch 1, gen_loss = 0.7956691406895957, disc_loss = 0.11083447062340458
Trained batch 1531 in epoch 1, gen_loss = 0.7956151499682868, disc_loss = 0.11082566359539957
Trained batch 1532 in epoch 1, gen_loss = 0.7957118587095755, disc_loss = 0.11076575616315075
Trained batch 1533 in epoch 1, gen_loss = 0.7958391247392478, disc_loss = 0.11079651620020456
Trained batch 1534 in epoch 1, gen_loss = 0.7957437940063228, disc_loss = 0.11080379412791629
Trained batch 1535 in epoch 1, gen_loss = 0.7956456428704163, disc_loss = 0.11085712251466855
Trained batch 1536 in epoch 1, gen_loss = 0.7957088326818383, disc_loss = 0.11085772829914373
Trained batch 1537 in epoch 1, gen_loss = 0.7955889868875784, disc_loss = 0.11082502201402994
Trained batch 1538 in epoch 1, gen_loss = 0.7955750947729808, disc_loss = 0.110824302809532
Trained batch 1539 in epoch 1, gen_loss = 0.7955561478803684, disc_loss = 0.11080839713527398
Trained batch 1540 in epoch 1, gen_loss = 0.7955980244044899, disc_loss = 0.1107776322360359
Trained batch 1541 in epoch 1, gen_loss = 0.795426533302599, disc_loss = 0.11077378037229818
Trained batch 1542 in epoch 1, gen_loss = 0.7953353084223037, disc_loss = 0.11076751589166678
Trained batch 1543 in epoch 1, gen_loss = 0.7952823409994032, disc_loss = 0.11077109165248399
Trained batch 1544 in epoch 1, gen_loss = 0.7952146031324145, disc_loss = 0.11076021330208069
Trained batch 1545 in epoch 1, gen_loss = 0.7954459858511275, disc_loss = 0.11071050882503332
Trained batch 1546 in epoch 1, gen_loss = 0.7955550290957218, disc_loss = 0.11072519032673521
Trained batch 1547 in epoch 1, gen_loss = 0.7954507616062189, disc_loss = 0.1107153554088424
Trained batch 1548 in epoch 1, gen_loss = 0.7953640787812338, disc_loss = 0.11071963735968549
Trained batch 1549 in epoch 1, gen_loss = 0.7953500040500395, disc_loss = 0.11073939286653073
Trained batch 1550 in epoch 1, gen_loss = 0.7954505422590319, disc_loss = 0.11071231293772436
Trained batch 1551 in epoch 1, gen_loss = 0.7954939907973575, disc_loss = 0.1106634755023592
Trained batch 1552 in epoch 1, gen_loss = 0.7955449644550537, disc_loss = 0.11061470076940709
Trained batch 1553 in epoch 1, gen_loss = 0.7955682925889545, disc_loss = 0.11077721410957159
Trained batch 1554 in epoch 1, gen_loss = 0.7953349105031544, disc_loss = 0.11084114682779818
Trained batch 1555 in epoch 1, gen_loss = 0.7952171233518571, disc_loss = 0.1108551079187073
Trained batch 1556 in epoch 1, gen_loss = 0.7952542174451995, disc_loss = 0.11092423367467766
Trained batch 1557 in epoch 1, gen_loss = 0.7952790575171312, disc_loss = 0.11093563781345839
Trained batch 1558 in epoch 1, gen_loss = 0.7951997200444083, disc_loss = 0.11103887851944406
Trained batch 1559 in epoch 1, gen_loss = 0.7950624120541108, disc_loss = 0.11105198502683869
Trained batch 1560 in epoch 1, gen_loss = 0.7951988650773444, disc_loss = 0.11111717217009393
Trained batch 1561 in epoch 1, gen_loss = 0.7950242923408098, disc_loss = 0.11117865014272753
Trained batch 1562 in epoch 1, gen_loss = 0.795021767350854, disc_loss = 0.11115114705223574
Trained batch 1563 in epoch 1, gen_loss = 0.794772806565475, disc_loss = 0.11113500995013643
Trained batch 1564 in epoch 1, gen_loss = 0.7947258536808026, disc_loss = 0.11111605865553545
Trained batch 1565 in epoch 1, gen_loss = 0.7947269752716805, disc_loss = 0.11108428709646676
Trained batch 1566 in epoch 1, gen_loss = 0.7946547711816044, disc_loss = 0.11108201342066078
Trained batch 1567 in epoch 1, gen_loss = 0.7947125910420199, disc_loss = 0.11108824051203853
Trained batch 1568 in epoch 1, gen_loss = 0.794759246746851, disc_loss = 0.11104716197928857
Trained batch 1569 in epoch 1, gen_loss = 0.7946280977148918, disc_loss = 0.11100524281667676
Trained batch 1570 in epoch 1, gen_loss = 0.7945302584078721, disc_loss = 0.11106130570163779
Trained batch 1571 in epoch 1, gen_loss = 0.7944299974514328, disc_loss = 0.11103002554511902
Trained batch 1572 in epoch 1, gen_loss = 0.7943887541571469, disc_loss = 0.11100889831421411
Trained batch 1573 in epoch 1, gen_loss = 0.7944977203954432, disc_loss = 0.11098468928506747
Trained batch 1574 in epoch 1, gen_loss = 0.7944429765050374, disc_loss = 0.11096815555814712
Trained batch 1575 in epoch 1, gen_loss = 0.7943154921008245, disc_loss = 0.11099164121722813
Trained batch 1576 in epoch 1, gen_loss = 0.7944709799224694, disc_loss = 0.11101196976538012
Trained batch 1577 in epoch 1, gen_loss = 0.7944727882610679, disc_loss = 0.11097744440114543
Trained batch 1578 in epoch 1, gen_loss = 0.7945599746598406, disc_loss = 0.11093842299057004
Trained batch 1579 in epoch 1, gen_loss = 0.7944772443439387, disc_loss = 0.11089705475429192
Trained batch 1580 in epoch 1, gen_loss = 0.7944627194974635, disc_loss = 0.11084882781182867
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 0.898425817489624, disc_loss = 0.1489180624485016
Trained batch 1 in epoch 2, gen_loss = 0.7349706292152405, disc_loss = 0.151410311460495
Trained batch 2 in epoch 2, gen_loss = 0.7603716452916464, disc_loss = 0.13121544818083444
Trained batch 3 in epoch 2, gen_loss = 0.7924385815858841, disc_loss = 0.12514137476682663
Trained batch 4 in epoch 2, gen_loss = 0.8057223081588745, disc_loss = 0.10545747429132461
Trained batch 5 in epoch 2, gen_loss = 0.7779203553994497, disc_loss = 0.12052335465947787
Trained batch 6 in epoch 2, gen_loss = 0.7683593375342233, disc_loss = 0.11257780769041606
Trained batch 7 in epoch 2, gen_loss = 0.7997119277715683, disc_loss = 0.10032355762086809
Trained batch 8 in epoch 2, gen_loss = 0.829857071240743, disc_loss = 0.09087436397870381
Trained batch 9 in epoch 2, gen_loss = 0.8177619576454163, disc_loss = 0.08557132333517074
Trained batch 10 in epoch 2, gen_loss = 0.8421381711959839, disc_loss = 0.09644962711767717
Trained batch 11 in epoch 2, gen_loss = 0.8277668158213297, disc_loss = 0.09462694637477398
Trained batch 12 in epoch 2, gen_loss = 0.8131071695914636, disc_loss = 0.09404554447302452
Trained batch 13 in epoch 2, gen_loss = 0.8173659529004779, disc_loss = 0.09480680046336991
Trained batch 14 in epoch 2, gen_loss = 0.8207587639490763, disc_loss = 0.09020661016305288
Trained batch 15 in epoch 2, gen_loss = 0.8109353631734848, disc_loss = 0.09023348614573479
Trained batch 16 in epoch 2, gen_loss = 0.8143754846909467, disc_loss = 0.09312448606771581
Trained batch 17 in epoch 2, gen_loss = 0.8346485164430406, disc_loss = 0.09102039949761496
Trained batch 18 in epoch 2, gen_loss = 0.8198771915937725, disc_loss = 0.11100789355604272
Trained batch 19 in epoch 2, gen_loss = 0.840008944272995, disc_loss = 0.11304483339190483
Trained batch 20 in epoch 2, gen_loss = 0.8478507711773827, disc_loss = 0.10925197849671046
Trained batch 21 in epoch 2, gen_loss = 0.834463739937002, disc_loss = 0.11375748264518651
Trained batch 22 in epoch 2, gen_loss = 0.8261083053505939, disc_loss = 0.11420928136162135
Trained batch 23 in epoch 2, gen_loss = 0.8247742603222529, disc_loss = 0.11573534086346626
Trained batch 24 in epoch 2, gen_loss = 0.827731831073761, disc_loss = 0.11368183493614196
Trained batch 25 in epoch 2, gen_loss = 0.8275617063045502, disc_loss = 0.11142747132824017
Trained batch 26 in epoch 2, gen_loss = 0.8406640887260437, disc_loss = 0.11123739652059696
Trained batch 27 in epoch 2, gen_loss = 0.8318826726504734, disc_loss = 0.11100004640008722
Trained batch 28 in epoch 2, gen_loss = 0.8225492691171581, disc_loss = 0.11717440984372435
Trained batch 29 in epoch 2, gen_loss = 0.8270186463991801, disc_loss = 0.11676563546061516
Trained batch 30 in epoch 2, gen_loss = 0.8385390081713276, disc_loss = 0.11635795500009291
Trained batch 31 in epoch 2, gen_loss = 0.829371202737093, disc_loss = 0.11687090643681586
Trained batch 32 in epoch 2, gen_loss = 0.8217096960905826, disc_loss = 0.11625579609112306
Trained batch 33 in epoch 2, gen_loss = 0.8277942696038414, disc_loss = 0.11459351681611117
Trained batch 34 in epoch 2, gen_loss = 0.8278324331556047, disc_loss = 0.11343382809843336
Trained batch 35 in epoch 2, gen_loss = 0.825533797343572, disc_loss = 0.11207589817543824
Trained batch 36 in epoch 2, gen_loss = 0.8321914769507743, disc_loss = 0.10987779508168632
Trained batch 37 in epoch 2, gen_loss = 0.8270755237654636, disc_loss = 0.10869829797823179
Trained batch 38 in epoch 2, gen_loss = 0.8295966707743131, disc_loss = 0.10708598162119205
Trained batch 39 in epoch 2, gen_loss = 0.8211512513458729, disc_loss = 0.10824455861002207
Trained batch 40 in epoch 2, gen_loss = 0.8248187717868061, disc_loss = 0.10850596155335264
Trained batch 41 in epoch 2, gen_loss = 0.8196213167338144, disc_loss = 0.10758494355139278
Trained batch 42 in epoch 2, gen_loss = 0.8196706723335178, disc_loss = 0.10840005982060764
Trained batch 43 in epoch 2, gen_loss = 0.8285319540988315, disc_loss = 0.10894620333882896
Trained batch 44 in epoch 2, gen_loss = 0.8286833902200063, disc_loss = 0.10694072933660613
Trained batch 45 in epoch 2, gen_loss = 0.8246191616939462, disc_loss = 0.10634229874805264
Trained batch 46 in epoch 2, gen_loss = 0.82342828651692, disc_loss = 0.10432656469972844
Trained batch 47 in epoch 2, gen_loss = 0.8189725782722235, disc_loss = 0.10436287751266111
Trained batch 48 in epoch 2, gen_loss = 0.8151601632030643, disc_loss = 0.1046675444789687
Trained batch 49 in epoch 2, gen_loss = 0.8192446476221085, disc_loss = 0.10306996673345566
Trained batch 50 in epoch 2, gen_loss = 0.8191123727489921, disc_loss = 0.10234122591860154
Trained batch 51 in epoch 2, gen_loss = 0.8163606541661116, disc_loss = 0.10254071566921014
Trained batch 52 in epoch 2, gen_loss = 0.8121469105189701, disc_loss = 0.1025128997159454
Trained batch 53 in epoch 2, gen_loss = 0.8143423922635891, disc_loss = 0.10284770252528014
Trained batch 54 in epoch 2, gen_loss = 0.8116789205507798, disc_loss = 0.10237027948552913
Trained batch 55 in epoch 2, gen_loss = 0.8172751446919782, disc_loss = 0.10100711366560843
Trained batch 56 in epoch 2, gen_loss = 0.8148563708129682, disc_loss = 0.1016119976380938
Trained batch 57 in epoch 2, gen_loss = 0.8134702243681612, disc_loss = 0.10121425437130804
Trained batch 58 in epoch 2, gen_loss = 0.8207400840217784, disc_loss = 0.10339018970854201
Trained batch 59 in epoch 2, gen_loss = 0.8169486130277316, disc_loss = 0.10361488402510682
Trained batch 60 in epoch 2, gen_loss = 0.8159685384054653, disc_loss = 0.10390120320266387
Trained batch 61 in epoch 2, gen_loss = 0.81088473671867, disc_loss = 0.10453606219661812
Trained batch 62 in epoch 2, gen_loss = 0.8130673241047632, disc_loss = 0.10331322125617474
Trained batch 63 in epoch 2, gen_loss = 0.8113156012259424, disc_loss = 0.10306537328870036
Trained batch 64 in epoch 2, gen_loss = 0.8116267052980569, disc_loss = 0.10181584974321035
Trained batch 65 in epoch 2, gen_loss = 0.8132209673975453, disc_loss = 0.10109268227648555
Trained batch 66 in epoch 2, gen_loss = 0.8097003035580934, disc_loss = 0.10087323675293532
Trained batch 67 in epoch 2, gen_loss = 0.8077292928800863, disc_loss = 0.10060064579524539
Trained batch 68 in epoch 2, gen_loss = 0.808488045481668, disc_loss = 0.10037291209226933
Trained batch 69 in epoch 2, gen_loss = 0.8111313985926765, disc_loss = 0.09919339024594852
Trained batch 70 in epoch 2, gen_loss = 0.8129730421892354, disc_loss = 0.09818924184311444
Trained batch 71 in epoch 2, gen_loss = 0.8146713818940852, disc_loss = 0.09699444215382552
Trained batch 72 in epoch 2, gen_loss = 0.8123041068854397, disc_loss = 0.09620752748204013
Trained batch 73 in epoch 2, gen_loss = 0.8118013872488125, disc_loss = 0.09566814342916415
Trained batch 74 in epoch 2, gen_loss = 0.8132868802547455, disc_loss = 0.09606886239101489
Trained batch 75 in epoch 2, gen_loss = 0.8084678802835313, disc_loss = 0.09690456848444515
Trained batch 76 in epoch 2, gen_loss = 0.8057071013110024, disc_loss = 0.09599940804159873
Trained batch 77 in epoch 2, gen_loss = 0.8157560668694668, disc_loss = 0.09887513896832481
Trained batch 78 in epoch 2, gen_loss = 0.8142450334905069, disc_loss = 0.0989049818909055
Trained batch 79 in epoch 2, gen_loss = 0.8174617912620306, disc_loss = 0.09799689768115058
Trained batch 80 in epoch 2, gen_loss = 0.8167950065783512, disc_loss = 0.09759539132362899
Trained batch 81 in epoch 2, gen_loss = 0.8156286888733143, disc_loss = 0.0974955370354398
Trained batch 82 in epoch 2, gen_loss = 0.8143398535538868, disc_loss = 0.09734345654990659
Trained batch 83 in epoch 2, gen_loss = 0.8129851566184134, disc_loss = 0.0979284181680885
Trained batch 84 in epoch 2, gen_loss = 0.8098073205527138, disc_loss = 0.09935943665092482
Trained batch 85 in epoch 2, gen_loss = 0.8102980010038199, disc_loss = 0.09961765957996249
Trained batch 86 in epoch 2, gen_loss = 0.8103734340475893, disc_loss = 0.09951930481341036
Trained batch 87 in epoch 2, gen_loss = 0.8078540756621144, disc_loss = 0.09988297281829132
Trained batch 88 in epoch 2, gen_loss = 0.8080710845716884, disc_loss = 0.09990079798264785
Trained batch 89 in epoch 2, gen_loss = 0.8054839726951387, disc_loss = 0.10043932759306497
Trained batch 90 in epoch 2, gen_loss = 0.8084441551140377, disc_loss = 0.10156403036767638
Trained batch 91 in epoch 2, gen_loss = 0.8088101184238559, disc_loss = 0.10121745256828549
Trained batch 92 in epoch 2, gen_loss = 0.8061620397593385, disc_loss = 0.10294074297792488
Trained batch 93 in epoch 2, gen_loss = 0.8062883770846306, disc_loss = 0.10274722677794226
Trained batch 94 in epoch 2, gen_loss = 0.8058614846907164, disc_loss = 0.10220850938440938
Trained batch 95 in epoch 2, gen_loss = 0.8062500671173135, disc_loss = 0.10371839609191132
Trained batch 96 in epoch 2, gen_loss = 0.8053738066216105, disc_loss = 0.10310080421838871
Trained batch 97 in epoch 2, gen_loss = 0.805584250360119, disc_loss = 0.10267257113579889
Trained batch 98 in epoch 2, gen_loss = 0.8072060975763533, disc_loss = 0.10213896358442126
Trained batch 99 in epoch 2, gen_loss = 0.8040020808577537, disc_loss = 0.10235631090588868
Trained batch 100 in epoch 2, gen_loss = 0.8044094694132852, disc_loss = 0.10209275963762314
Trained batch 101 in epoch 2, gen_loss = 0.803843204589451, disc_loss = 0.10213954933900751
Trained batch 102 in epoch 2, gen_loss = 0.8061024445353202, disc_loss = 0.1022652119705544
Trained batch 103 in epoch 2, gen_loss = 0.8052392094754256, disc_loss = 0.10200849996628956
Trained batch 104 in epoch 2, gen_loss = 0.8056158982572101, disc_loss = 0.1013151341339662
Trained batch 105 in epoch 2, gen_loss = 0.8076608166942056, disc_loss = 0.10055416116912691
Trained batch 106 in epoch 2, gen_loss = 0.8095710219066834, disc_loss = 0.09988699970923573
Trained batch 107 in epoch 2, gen_loss = 0.8084843266341422, disc_loss = 0.09927142210546192
Trained batch 108 in epoch 2, gen_loss = 0.8072560476053745, disc_loss = 0.09870271476139443
Trained batch 109 in epoch 2, gen_loss = 0.8063170359893279, disc_loss = 0.09847308941693468
Trained batch 110 in epoch 2, gen_loss = 0.8054068762439865, disc_loss = 0.0982500778779656
Trained batch 111 in epoch 2, gen_loss = 0.8064415516065699, disc_loss = 0.09756178527771096
Trained batch 112 in epoch 2, gen_loss = 0.8048131869430035, disc_loss = 0.09717071615983691
Trained batch 113 in epoch 2, gen_loss = 0.8063975972564597, disc_loss = 0.09759867484599613
Trained batch 114 in epoch 2, gen_loss = 0.8033114153405895, disc_loss = 0.09823933158717725
Trained batch 115 in epoch 2, gen_loss = 0.8039077453572174, disc_loss = 0.09807800314517627
Trained batch 116 in epoch 2, gen_loss = 0.8038127845169133, disc_loss = 0.0975279625521129
Trained batch 117 in epoch 2, gen_loss = 0.8041484042749567, disc_loss = 0.09726091924960077
Trained batch 118 in epoch 2, gen_loss = 0.8063573426559192, disc_loss = 0.09752807067315869
Trained batch 119 in epoch 2, gen_loss = 0.8035507738590241, disc_loss = 0.09814705584043017
Trained batch 120 in epoch 2, gen_loss = 0.8035513546841204, disc_loss = 0.09788948022721966
Trained batch 121 in epoch 2, gen_loss = 0.8037534580856073, disc_loss = 0.09829026383546288
Trained batch 122 in epoch 2, gen_loss = 0.804653830644561, disc_loss = 0.09778263870384393
Trained batch 123 in epoch 2, gen_loss = 0.8032061303815534, disc_loss = 0.09778191253633028
Trained batch 124 in epoch 2, gen_loss = 0.8051431341171265, disc_loss = 0.09762798073142767
Trained batch 125 in epoch 2, gen_loss = 0.8034925129678514, disc_loss = 0.09812422974094276
Trained batch 126 in epoch 2, gen_loss = 0.8055598125683041, disc_loss = 0.09816285676696873
Trained batch 127 in epoch 2, gen_loss = 0.8069760901853442, disc_loss = 0.0978120367435622
Trained batch 128 in epoch 2, gen_loss = 0.8066317129504773, disc_loss = 0.09803585834483537
Trained batch 129 in epoch 2, gen_loss = 0.8041096375538752, disc_loss = 0.09894688025546762
Trained batch 130 in epoch 2, gen_loss = 0.803536887387283, disc_loss = 0.09965514009889528
Trained batch 131 in epoch 2, gen_loss = 0.8036855486306277, disc_loss = 0.09940436950207433
Trained batch 132 in epoch 2, gen_loss = 0.8048315133367266, disc_loss = 0.09970290717297703
Trained batch 133 in epoch 2, gen_loss = 0.8058252058812042, disc_loss = 0.09913051273645972
Trained batch 134 in epoch 2, gen_loss = 0.8046473697379783, disc_loss = 0.10006578112779944
Trained batch 135 in epoch 2, gen_loss = 0.8039046990520814, disc_loss = 0.10009643622427522
Trained batch 136 in epoch 2, gen_loss = 0.8035661621685446, disc_loss = 0.10005591233961121
Trained batch 137 in epoch 2, gen_loss = 0.803454211656598, disc_loss = 0.10137838579417355
Trained batch 138 in epoch 2, gen_loss = 0.8023698943124401, disc_loss = 0.10099970855542438
Trained batch 139 in epoch 2, gen_loss = 0.8011470756360463, disc_loss = 0.10093587408773601
Trained batch 140 in epoch 2, gen_loss = 0.8033713461659479, disc_loss = 0.10184043419302989
Trained batch 141 in epoch 2, gen_loss = 0.8037595085694756, disc_loss = 0.10129375260611864
Trained batch 142 in epoch 2, gen_loss = 0.8043400328476112, disc_loss = 0.10092588316753402
Trained batch 143 in epoch 2, gen_loss = 0.8052746732201841, disc_loss = 0.10065032102607398
Trained batch 144 in epoch 2, gen_loss = 0.8033183196495319, disc_loss = 0.1013950320731463
Trained batch 145 in epoch 2, gen_loss = 0.8044204911957048, disc_loss = 0.10141207181453092
Trained batch 146 in epoch 2, gen_loss = 0.8078267367518678, disc_loss = 0.10228737647055972
Trained batch 147 in epoch 2, gen_loss = 0.8080202856579343, disc_loss = 0.1021601970596994
Trained batch 148 in epoch 2, gen_loss = 0.8069154648172775, disc_loss = 0.10278969313699327
Trained batch 149 in epoch 2, gen_loss = 0.8073844885826111, disc_loss = 0.10236368614559373
Trained batch 150 in epoch 2, gen_loss = 0.8089620143372491, disc_loss = 0.10246823336435668
Trained batch 151 in epoch 2, gen_loss = 0.8104011871312794, disc_loss = 0.10192073893267661
Trained batch 152 in epoch 2, gen_loss = 0.8082858277302162, disc_loss = 0.10238049147054067
Trained batch 153 in epoch 2, gen_loss = 0.8073141927068884, disc_loss = 0.10233717394218624
Trained batch 154 in epoch 2, gen_loss = 0.806241261959076, disc_loss = 0.10253183257075087
Trained batch 155 in epoch 2, gen_loss = 0.8073338644626813, disc_loss = 0.10235612750507127
Trained batch 156 in epoch 2, gen_loss = 0.808782509178113, disc_loss = 0.1022455575253079
Trained batch 157 in epoch 2, gen_loss = 0.8067951958767975, disc_loss = 0.10226716131231264
Trained batch 158 in epoch 2, gen_loss = 0.8067299204427492, disc_loss = 0.10201298644028182
Trained batch 159 in epoch 2, gen_loss = 0.8051399687305093, disc_loss = 0.10319167316774838
Trained batch 160 in epoch 2, gen_loss = 0.8058285174532707, disc_loss = 0.10325554524033521
Trained batch 161 in epoch 2, gen_loss = 0.8078243616554472, disc_loss = 0.10307277874147266
Trained batch 162 in epoch 2, gen_loss = 0.8074820464008425, disc_loss = 0.10283409824103483
Trained batch 163 in epoch 2, gen_loss = 0.8059552768018188, disc_loss = 0.10291991171018197
Trained batch 164 in epoch 2, gen_loss = 0.8078837009993467, disc_loss = 0.10339072479330229
Trained batch 165 in epoch 2, gen_loss = 0.8083795181599008, disc_loss = 0.10288172724084502
Trained batch 166 in epoch 2, gen_loss = 0.8079019072883857, disc_loss = 0.10268669041754779
Trained batch 167 in epoch 2, gen_loss = 0.8065212633283365, disc_loss = 0.10287875714822717
Trained batch 168 in epoch 2, gen_loss = 0.8066871901588327, disc_loss = 0.1032151498462586
Trained batch 169 in epoch 2, gen_loss = 0.8077599474612405, disc_loss = 0.10346749764045372
Trained batch 170 in epoch 2, gen_loss = 0.8057938214631108, disc_loss = 0.1049121489900856
Trained batch 171 in epoch 2, gen_loss = 0.8055267115665037, disc_loss = 0.10469562345357655
Trained batch 172 in epoch 2, gen_loss = 0.8054569684012087, disc_loss = 0.10480348509063438
Trained batch 173 in epoch 2, gen_loss = 0.805263828272107, disc_loss = 0.10524674780645418
Trained batch 174 in epoch 2, gen_loss = 0.8036020435605731, disc_loss = 0.10557247955352068
Trained batch 175 in epoch 2, gen_loss = 0.8037211793390188, disc_loss = 0.10528443103381009
Trained batch 176 in epoch 2, gen_loss = 0.8026412459416578, disc_loss = 0.10520399502336474
Trained batch 177 in epoch 2, gen_loss = 0.8019383432490103, disc_loss = 0.1049822279817184
Trained batch 178 in epoch 2, gen_loss = 0.8016698317154826, disc_loss = 0.10460944824940499
Trained batch 179 in epoch 2, gen_loss = 0.799976047873497, disc_loss = 0.10487087411909468
Trained batch 180 in epoch 2, gen_loss = 0.8005549990011184, disc_loss = 0.1048222566743829
Trained batch 181 in epoch 2, gen_loss = 0.8010392365874824, disc_loss = 0.10461204062512779
Trained batch 182 in epoch 2, gen_loss = 0.8014518068136414, disc_loss = 0.10438219952025538
Trained batch 183 in epoch 2, gen_loss = 0.8008991227201794, disc_loss = 0.10416528328989996
Trained batch 184 in epoch 2, gen_loss = 0.8003433156657863, disc_loss = 0.10379510251553477
Trained batch 185 in epoch 2, gen_loss = 0.8000869706112851, disc_loss = 0.10375727952948662
Trained batch 186 in epoch 2, gen_loss = 0.7997578873353846, disc_loss = 0.10381349522301699
Trained batch 187 in epoch 2, gen_loss = 0.7993671697504977, disc_loss = 0.10378403541077166
Trained batch 188 in epoch 2, gen_loss = 0.7983208374371604, disc_loss = 0.10373615177358111
Trained batch 189 in epoch 2, gen_loss = 0.7979376011773159, disc_loss = 0.10352372283508118
Trained batch 190 in epoch 2, gen_loss = 0.7986655656579902, disc_loss = 0.10351479606927222
Trained batch 191 in epoch 2, gen_loss = 0.7990315174683928, disc_loss = 0.10322597791188552
Trained batch 192 in epoch 2, gen_loss = 0.7985637898272183, disc_loss = 0.10329603690924268
Trained batch 193 in epoch 2, gen_loss = 0.7976331348271714, disc_loss = 0.10329650244051494
Trained batch 194 in epoch 2, gen_loss = 0.7987463896091168, disc_loss = 0.10299720163815297
Trained batch 195 in epoch 2, gen_loss = 0.7991343158848432, disc_loss = 0.1027954521028287
Trained batch 196 in epoch 2, gen_loss = 0.7998202657941634, disc_loss = 0.10294225410591376
Trained batch 197 in epoch 2, gen_loss = 0.7986217138141093, disc_loss = 0.10351904910151856
Trained batch 198 in epoch 2, gen_loss = 0.799523217893725, disc_loss = 0.10389501949182557
Trained batch 199 in epoch 2, gen_loss = 0.7995584204792976, disc_loss = 0.10388109508436173
Trained batch 200 in epoch 2, gen_loss = 0.7985207788386748, disc_loss = 0.10420815012329698
Trained batch 201 in epoch 2, gen_loss = 0.8001969382904544, disc_loss = 0.10399512226905415
Trained batch 202 in epoch 2, gen_loss = 0.8014616246881157, disc_loss = 0.10369035105675166
Trained batch 203 in epoch 2, gen_loss = 0.8013131443191978, disc_loss = 0.10340684345083348
Trained batch 204 in epoch 2, gen_loss = 0.8013946158129994, disc_loss = 0.10313714547764237
Trained batch 205 in epoch 2, gen_loss = 0.8013373870872756, disc_loss = 0.10290209718898517
Trained batch 206 in epoch 2, gen_loss = 0.8023653269389978, disc_loss = 0.1028359496858025
Trained batch 207 in epoch 2, gen_loss = 0.8029643540772108, disc_loss = 0.10255984454684389
Trained batch 208 in epoch 2, gen_loss = 0.8021028555181038, disc_loss = 0.10281617327651196
Trained batch 209 in epoch 2, gen_loss = 0.8021930944351923, disc_loss = 0.10284834473526903
Trained batch 210 in epoch 2, gen_loss = 0.8009810594585834, disc_loss = 0.10281728082270278
Trained batch 211 in epoch 2, gen_loss = 0.8017789164804062, disc_loss = 0.10261923487227902
Trained batch 212 in epoch 2, gen_loss = 0.8014260088334061, disc_loss = 0.10253668469355
Trained batch 213 in epoch 2, gen_loss = 0.8008212296762199, disc_loss = 0.10260074116968523
Trained batch 214 in epoch 2, gen_loss = 0.8022866127102875, disc_loss = 0.10244248954276013
Trained batch 215 in epoch 2, gen_loss = 0.8057628395380797, disc_loss = 0.10292462716137783
Trained batch 216 in epoch 2, gen_loss = 0.8064120804659233, disc_loss = 0.10258923640500428
Trained batch 217 in epoch 2, gen_loss = 0.8053639416300923, disc_loss = 0.10323554644395315
Trained batch 218 in epoch 2, gen_loss = 0.8048489164544023, disc_loss = 0.10299292653714005
Trained batch 219 in epoch 2, gen_loss = 0.8049210434610193, disc_loss = 0.10269296626052396
Trained batch 220 in epoch 2, gen_loss = 0.8057487097261179, disc_loss = 0.10291392254596787
Trained batch 221 in epoch 2, gen_loss = 0.8050058253176577, disc_loss = 0.1027956262256044
Trained batch 222 in epoch 2, gen_loss = 0.8038102206627884, disc_loss = 0.10283729607331245
Trained batch 223 in epoch 2, gen_loss = 0.803225928651435, disc_loss = 0.10285299513738469
Trained batch 224 in epoch 2, gen_loss = 0.8028342077467177, disc_loss = 0.10295621609936158
Trained batch 225 in epoch 2, gen_loss = 0.8024415189186028, disc_loss = 0.10272953939104898
Trained batch 226 in epoch 2, gen_loss = 0.8015937295779257, disc_loss = 0.10273432708242786
Trained batch 227 in epoch 2, gen_loss = 0.8037242936460596, disc_loss = 0.10300512536298156
Trained batch 228 in epoch 2, gen_loss = 0.8027513464465412, disc_loss = 0.10295941358163757
Trained batch 229 in epoch 2, gen_loss = 0.8031793032003486, disc_loss = 0.10271252451626503
Trained batch 230 in epoch 2, gen_loss = 0.8027246393166579, disc_loss = 0.1024938156360607
Trained batch 231 in epoch 2, gen_loss = 0.8038092617844713, disc_loss = 0.10217959854093477
Trained batch 232 in epoch 2, gen_loss = 0.8039096348275443, disc_loss = 0.10190015973307416
Trained batch 233 in epoch 2, gen_loss = 0.8037652931152246, disc_loss = 0.1020475248965379
Trained batch 234 in epoch 2, gen_loss = 0.8029520871791433, disc_loss = 0.10215785376172751
Trained batch 235 in epoch 2, gen_loss = 0.8036932786137371, disc_loss = 0.10205607627265913
Trained batch 236 in epoch 2, gen_loss = 0.8036196631721303, disc_loss = 0.10186573997815827
Trained batch 237 in epoch 2, gen_loss = 0.8043896984152433, disc_loss = 0.10158990119669993
Trained batch 238 in epoch 2, gen_loss = 0.8056982982607566, disc_loss = 0.10144190318399268
Trained batch 239 in epoch 2, gen_loss = 0.8052809034784635, disc_loss = 0.10143011519297336
Trained batch 240 in epoch 2, gen_loss = 0.8049137082831989, disc_loss = 0.10118601996358871
Trained batch 241 in epoch 2, gen_loss = 0.8037260805279756, disc_loss = 0.10131472825988634
Trained batch 242 in epoch 2, gen_loss = 0.8035186931429577, disc_loss = 0.1012343312632829
Trained batch 243 in epoch 2, gen_loss = 0.8039820690135486, disc_loss = 0.10131749617256468
Trained batch 244 in epoch 2, gen_loss = 0.8054028649719394, disc_loss = 0.10146381851589802
Trained batch 245 in epoch 2, gen_loss = 0.8053353508798088, disc_loss = 0.10153771055165708
Trained batch 246 in epoch 2, gen_loss = 0.8052272285044435, disc_loss = 0.1015403534018016
Trained batch 247 in epoch 2, gen_loss = 0.8049637687302404, disc_loss = 0.10135475236306628
Trained batch 248 in epoch 2, gen_loss = 0.8041040844706646, disc_loss = 0.10162098469010677
Trained batch 249 in epoch 2, gen_loss = 0.8039695153236389, disc_loss = 0.1017580228112638
Trained batch 250 in epoch 2, gen_loss = 0.8040952746611667, disc_loss = 0.1015359319976542
Trained batch 251 in epoch 2, gen_loss = 0.8049390502865352, disc_loss = 0.10193016344223112
Trained batch 252 in epoch 2, gen_loss = 0.8042139330871492, disc_loss = 0.10229611525996754
Trained batch 253 in epoch 2, gen_loss = 0.8054846555698575, disc_loss = 0.1021966299108105
Trained batch 254 in epoch 2, gen_loss = 0.805377875589857, disc_loss = 0.10190738319401063
Trained batch 255 in epoch 2, gen_loss = 0.8050529400352389, disc_loss = 0.10190659699946991
Trained batch 256 in epoch 2, gen_loss = 0.8050531269511361, disc_loss = 0.10207774588323637
Trained batch 257 in epoch 2, gen_loss = 0.8051667747109436, disc_loss = 0.10177444137069722
Trained batch 258 in epoch 2, gen_loss = 0.8046103837867501, disc_loss = 0.10180788693237604
Trained batch 259 in epoch 2, gen_loss = 0.8059008265917118, disc_loss = 0.10183085147649623
Trained batch 260 in epoch 2, gen_loss = 0.8067096391856898, disc_loss = 0.10163053530857138
Trained batch 261 in epoch 2, gen_loss = 0.8056587560941245, disc_loss = 0.10230143564817218
Trained batch 262 in epoch 2, gen_loss = 0.8052534878027303, disc_loss = 0.10215150624754424
Trained batch 263 in epoch 2, gen_loss = 0.8068162214123842, disc_loss = 0.10250835606447337
Trained batch 264 in epoch 2, gen_loss = 0.807396388053894, disc_loss = 0.10231048496053466
Trained batch 265 in epoch 2, gen_loss = 0.8065086199824971, disc_loss = 0.10235340563104228
Trained batch 266 in epoch 2, gen_loss = 0.8068935862194733, disc_loss = 0.10204337956907039
Trained batch 267 in epoch 2, gen_loss = 0.806974699915345, disc_loss = 0.1018384783146486
Trained batch 268 in epoch 2, gen_loss = 0.8075116033004562, disc_loss = 0.10178353883616875
Trained batch 269 in epoch 2, gen_loss = 0.8080659912692176, disc_loss = 0.10148944192117564
Trained batch 270 in epoch 2, gen_loss = 0.8079647091921845, disc_loss = 0.10131414213674865
Trained batch 271 in epoch 2, gen_loss = 0.8086061904973844, disc_loss = 0.10120429729645633
Trained batch 272 in epoch 2, gen_loss = 0.809872186882592, disc_loss = 0.10107842077852497
Trained batch 273 in epoch 2, gen_loss = 0.8095635913149284, disc_loss = 0.10096759548628309
Trained batch 274 in epoch 2, gen_loss = 0.8095017760450189, disc_loss = 0.10087791422212666
Trained batch 275 in epoch 2, gen_loss = 0.8090551605691081, disc_loss = 0.10084850231415012
Trained batch 276 in epoch 2, gen_loss = 0.8101664095148713, disc_loss = 0.10079669531112005
Trained batch 277 in epoch 2, gen_loss = 0.8103231856291243, disc_loss = 0.10057368409223587
Trained batch 278 in epoch 2, gen_loss = 0.8099801365192646, disc_loss = 0.10033160135296831
Trained batch 279 in epoch 2, gen_loss = 0.8092129871249198, disc_loss = 0.10080261679831892
Trained batch 280 in epoch 2, gen_loss = 0.8091803829440867, disc_loss = 0.10063080248021888
Trained batch 281 in epoch 2, gen_loss = 0.8104255598910312, disc_loss = 0.10115481925969745
Trained batch 282 in epoch 2, gen_loss = 0.810503547267442, disc_loss = 0.10099235586098036
Trained batch 283 in epoch 2, gen_loss = 0.8103751561171572, disc_loss = 0.10084288385959053
Trained batch 284 in epoch 2, gen_loss = 0.8095414408466273, disc_loss = 0.10132754504876701
Trained batch 285 in epoch 2, gen_loss = 0.8099221149524609, disc_loss = 0.10134279717189762
Trained batch 286 in epoch 2, gen_loss = 0.8091147548230267, disc_loss = 0.10150758999656198
Trained batch 287 in epoch 2, gen_loss = 0.8099195150037607, disc_loss = 0.10124509573021594
Trained batch 288 in epoch 2, gen_loss = 0.809305460395285, disc_loss = 0.10113266675981168
Trained batch 289 in epoch 2, gen_loss = 0.810322683844073, disc_loss = 0.10095332399460262
Trained batch 290 in epoch 2, gen_loss = 0.8098671608364459, disc_loss = 0.10078001658262563
Trained batch 291 in epoch 2, gen_loss = 0.810308087362002, disc_loss = 0.10063804115474939
Trained batch 292 in epoch 2, gen_loss = 0.8107024746543311, disc_loss = 0.1004533921384313
Trained batch 293 in epoch 2, gen_loss = 0.8111101573421842, disc_loss = 0.100161311812192
Trained batch 294 in epoch 2, gen_loss = 0.8102423793178494, disc_loss = 0.10033246024306548
Trained batch 295 in epoch 2, gen_loss = 0.8096929265035165, disc_loss = 0.10009399705214074
Trained batch 296 in epoch 2, gen_loss = 0.8103131659905919, disc_loss = 0.09986126609773749
Trained batch 297 in epoch 2, gen_loss = 0.8107575232150571, disc_loss = 0.09968107494981897
Trained batch 298 in epoch 2, gen_loss = 0.8107584435804233, disc_loss = 0.09956453188655767
Trained batch 299 in epoch 2, gen_loss = 0.8108107711871465, disc_loss = 0.09933185606574019
Trained batch 300 in epoch 2, gen_loss = 0.8100990890664516, disc_loss = 0.09951315893856592
Trained batch 301 in epoch 2, gen_loss = 0.8095114292293195, disc_loss = 0.09971472812779494
Trained batch 302 in epoch 2, gen_loss = 0.8098456712052373, disc_loss = 0.09964217694949593
Trained batch 303 in epoch 2, gen_loss = 0.8094327734097054, disc_loss = 0.0996641224483028
Trained batch 304 in epoch 2, gen_loss = 0.8098583766671478, disc_loss = 0.09951407770763655
Trained batch 305 in epoch 2, gen_loss = 0.8091448282494265, disc_loss = 0.09945790969395364
Trained batch 306 in epoch 2, gen_loss = 0.8087689645515591, disc_loss = 0.09930993851383463
Trained batch 307 in epoch 2, gen_loss = 0.8086693000483822, disc_loss = 0.09940789119255813
Trained batch 308 in epoch 2, gen_loss = 0.8094375372704564, disc_loss = 0.09921800026302392
Trained batch 309 in epoch 2, gen_loss = 0.8089765598697047, disc_loss = 0.09915963285752842
Trained batch 310 in epoch 2, gen_loss = 0.809305944243428, disc_loss = 0.09893504781139434
Trained batch 311 in epoch 2, gen_loss = 0.8099854435676184, disc_loss = 0.09884516266174614
Trained batch 312 in epoch 2, gen_loss = 0.8097448642261493, disc_loss = 0.09879800769539115
Trained batch 313 in epoch 2, gen_loss = 0.8090937729853733, disc_loss = 0.09886538236740099
Trained batch 314 in epoch 2, gen_loss = 0.8101913501345922, disc_loss = 0.09869086633007677
Trained batch 315 in epoch 2, gen_loss = 0.8106220951185951, disc_loss = 0.09861075679500457
Trained batch 316 in epoch 2, gen_loss = 0.8112839240381018, disc_loss = 0.09841206253209513
Trained batch 317 in epoch 2, gen_loss = 0.811016857998926, disc_loss = 0.09835398819813002
Trained batch 318 in epoch 2, gen_loss = 0.8102787721867099, disc_loss = 0.09861674404419889
Trained batch 319 in epoch 2, gen_loss = 0.8110498789697885, disc_loss = 0.09876158791012131
Trained batch 320 in epoch 2, gen_loss = 0.8111036373447407, disc_loss = 0.09860418794380728
Trained batch 321 in epoch 2, gen_loss = 0.8104064383121751, disc_loss = 0.09849758956997846
Trained batch 322 in epoch 2, gen_loss = 0.8105756712402722, disc_loss = 0.09848123151612909
Trained batch 323 in epoch 2, gen_loss = 0.8110407620300482, disc_loss = 0.09829562579937003
Trained batch 324 in epoch 2, gen_loss = 0.8100191817833827, disc_loss = 0.09851988131610247
Trained batch 325 in epoch 2, gen_loss = 0.8100400050542106, disc_loss = 0.09830423175397278
Trained batch 326 in epoch 2, gen_loss = 0.8098128504527089, disc_loss = 0.09842887566929016
Trained batch 327 in epoch 2, gen_loss = 0.8090838227511906, disc_loss = 0.09867074890857244
Trained batch 328 in epoch 2, gen_loss = 0.8094135973047702, disc_loss = 0.09853432266930498
Trained batch 329 in epoch 2, gen_loss = 0.8112113296082526, disc_loss = 0.09865699794820763
Trained batch 330 in epoch 2, gen_loss = 0.8112963096792964, disc_loss = 0.09844788391807108
Trained batch 331 in epoch 2, gen_loss = 0.8106189450047102, disc_loss = 0.09856699762237539
Trained batch 332 in epoch 2, gen_loss = 0.8100063157332195, disc_loss = 0.09850059588951571
Trained batch 333 in epoch 2, gen_loss = 0.8124008554362965, disc_loss = 0.09922314092271521
Trained batch 334 in epoch 2, gen_loss = 0.8122292174332177, disc_loss = 0.09947277254689095
Trained batch 335 in epoch 2, gen_loss = 0.8115602885151193, disc_loss = 0.09960557148414886
Trained batch 336 in epoch 2, gen_loss = 0.8134683290115096, disc_loss = 0.09997402622919939
Trained batch 337 in epoch 2, gen_loss = 0.8139574722601817, disc_loss = 0.09980064777646368
Trained batch 338 in epoch 2, gen_loss = 0.8136836338711347, disc_loss = 0.09972936615545665
Trained batch 339 in epoch 2, gen_loss = 0.8135126719579977, disc_loss = 0.09977579504141913
Trained batch 340 in epoch 2, gen_loss = 0.8136326328925023, disc_loss = 0.10012264061948596
Trained batch 341 in epoch 2, gen_loss = 0.8132510574763281, disc_loss = 0.10008202398969242
Trained batch 342 in epoch 2, gen_loss = 0.813096600875215, disc_loss = 0.0999887725474101
Trained batch 343 in epoch 2, gen_loss = 0.813043165778698, disc_loss = 0.0998673262995083
Trained batch 344 in epoch 2, gen_loss = 0.8120053394117217, disc_loss = 0.10002718164545038
Trained batch 345 in epoch 2, gen_loss = 0.8121376722362, disc_loss = 0.09990101482589982
Trained batch 346 in epoch 2, gen_loss = 0.8120257980713583, disc_loss = 0.09985195802959482
Trained batch 347 in epoch 2, gen_loss = 0.8115845530711371, disc_loss = 0.09971570740079229
Trained batch 348 in epoch 2, gen_loss = 0.8108159497508347, disc_loss = 0.09982134020196162
Trained batch 349 in epoch 2, gen_loss = 0.8108677127531596, disc_loss = 0.09964797214205776
Trained batch 350 in epoch 2, gen_loss = 0.8104077503721938, disc_loss = 0.09986480304764377
Trained batch 351 in epoch 2, gen_loss = 0.8104929821565747, disc_loss = 0.09982877043181691
Trained batch 352 in epoch 2, gen_loss = 0.8105381432572438, disc_loss = 0.09975625452698966
Trained batch 353 in epoch 2, gen_loss = 0.8103087801212645, disc_loss = 0.09963922046314357
Trained batch 354 in epoch 2, gen_loss = 0.810065010987537, disc_loss = 0.09976568746209984
Trained batch 355 in epoch 2, gen_loss = 0.8108416558818871, disc_loss = 0.09954554270011153
Trained batch 356 in epoch 2, gen_loss = 0.8109428930182417, disc_loss = 0.09938611050008558
Trained batch 357 in epoch 2, gen_loss = 0.8106755362043168, disc_loss = 0.09933387599989522
Trained batch 358 in epoch 2, gen_loss = 0.810855484523481, disc_loss = 0.09919243402945133
Trained batch 359 in epoch 2, gen_loss = 0.8115366984572675, disc_loss = 0.09905719329189096
Trained batch 360 in epoch 2, gen_loss = 0.810470237873928, disc_loss = 0.09952579874679487
Trained batch 361 in epoch 2, gen_loss = 0.8102922675853276, disc_loss = 0.09954030767021423
Trained batch 362 in epoch 2, gen_loss = 0.8102707871885011, disc_loss = 0.09951814570394922
Trained batch 363 in epoch 2, gen_loss = 0.8096014843373508, disc_loss = 0.09971910899832517
Trained batch 364 in epoch 2, gen_loss = 0.8103749189474811, disc_loss = 0.0997843927359336
Trained batch 365 in epoch 2, gen_loss = 0.8108596465463846, disc_loss = 0.09961551991215006
Trained batch 366 in epoch 2, gen_loss = 0.8102679235571412, disc_loss = 0.09963063515560341
Trained batch 367 in epoch 2, gen_loss = 0.8096465043237676, disc_loss = 0.09971014529203429
Trained batch 368 in epoch 2, gen_loss = 0.8099341895683672, disc_loss = 0.09980879967835377
Trained batch 369 in epoch 2, gen_loss = 0.8099021430756594, disc_loss = 0.09961224935848165
Trained batch 370 in epoch 2, gen_loss = 0.8099653959434951, disc_loss = 0.09947838838591248
Trained batch 371 in epoch 2, gen_loss = 0.8094624810481584, disc_loss = 0.099517623278042
Trained batch 372 in epoch 2, gen_loss = 0.8095895394722834, disc_loss = 0.09936841944327462
Trained batch 373 in epoch 2, gen_loss = 0.8096449924184677, disc_loss = 0.09923476089827996
Trained batch 374 in epoch 2, gen_loss = 0.8095719233353933, disc_loss = 0.09909813199937344
Trained batch 375 in epoch 2, gen_loss = 0.8101225004709781, disc_loss = 0.09887222671247226
Trained batch 376 in epoch 2, gen_loss = 0.8093395290861711, disc_loss = 0.09884815926932845
Trained batch 377 in epoch 2, gen_loss = 0.8097433894872665, disc_loss = 0.09917287300858232
Trained batch 378 in epoch 2, gen_loss = 0.8093286262810387, disc_loss = 0.09900952287824298
Trained batch 379 in epoch 2, gen_loss = 0.809024781851392, disc_loss = 0.09904514700174331
Trained batch 380 in epoch 2, gen_loss = 0.8091622529223835, disc_loss = 0.09887814615655133
Trained batch 381 in epoch 2, gen_loss = 0.8103957548347444, disc_loss = 0.09886095528515222
Trained batch 382 in epoch 2, gen_loss = 0.8112254694454353, disc_loss = 0.09869033461995909
Trained batch 383 in epoch 2, gen_loss = 0.8106259066456308, disc_loss = 0.09899930172832683
Trained batch 384 in epoch 2, gen_loss = 0.8110167638822036, disc_loss = 0.09906566481698643
Trained batch 385 in epoch 2, gen_loss = 0.8104455028636468, disc_loss = 0.09909282999180759
Trained batch 386 in epoch 2, gen_loss = 0.8107101271164817, disc_loss = 0.09921422100190352
Trained batch 387 in epoch 2, gen_loss = 0.8106013193112058, disc_loss = 0.09907551048342715
Trained batch 388 in epoch 2, gen_loss = 0.8102219255693774, disc_loss = 0.09893665102652842
Trained batch 389 in epoch 2, gen_loss = 0.8099460880725812, disc_loss = 0.09892432783276607
Trained batch 390 in epoch 2, gen_loss = 0.810150793217637, disc_loss = 0.09871773181668937
Trained batch 391 in epoch 2, gen_loss = 0.8107091307792128, disc_loss = 0.09855795847442077
Trained batch 392 in epoch 2, gen_loss = 0.8104592920411331, disc_loss = 0.09857635702416491
Trained batch 393 in epoch 2, gen_loss = 0.8107519046152909, disc_loss = 0.09838736952674873
Trained batch 394 in epoch 2, gen_loss = 0.8107085764408112, disc_loss = 0.09832978123162366
Trained batch 395 in epoch 2, gen_loss = 0.8105797830103624, disc_loss = 0.09820100313259496
Trained batch 396 in epoch 2, gen_loss = 0.8104252910583987, disc_loss = 0.09809291524160418
Trained batch 397 in epoch 2, gen_loss = 0.8105822270689298, disc_loss = 0.09790113312777263
Trained batch 398 in epoch 2, gen_loss = 0.8105633691289371, disc_loss = 0.09771349623724632
Trained batch 399 in epoch 2, gen_loss = 0.8113307925313711, disc_loss = 0.09753692278172821
Trained batch 400 in epoch 2, gen_loss = 0.811557661491142, disc_loss = 0.09739493773297925
Trained batch 401 in epoch 2, gen_loss = 0.8117984918071263, disc_loss = 0.0973347345533878
Trained batch 402 in epoch 2, gen_loss = 0.8113901938309445, disc_loss = 0.09735130632836972
Trained batch 403 in epoch 2, gen_loss = 0.8121777962487523, disc_loss = 0.09757190132698063
Trained batch 404 in epoch 2, gen_loss = 0.8118395778132074, disc_loss = 0.09750050786008806
Trained batch 405 in epoch 2, gen_loss = 0.8119151302305936, disc_loss = 0.09732404454001065
Trained batch 406 in epoch 2, gen_loss = 0.811821218863752, disc_loss = 0.097228492360736
Trained batch 407 in epoch 2, gen_loss = 0.8117477302896041, disc_loss = 0.09711039951071143
Trained batch 408 in epoch 2, gen_loss = 0.8116586178468317, disc_loss = 0.09702011854513058
Trained batch 409 in epoch 2, gen_loss = 0.8116943338295308, disc_loss = 0.09706418709602298
Trained batch 410 in epoch 2, gen_loss = 0.8120637644091372, disc_loss = 0.09759402339439613
Trained batch 411 in epoch 2, gen_loss = 0.812176954905385, disc_loss = 0.09751992304673762
Trained batch 412 in epoch 2, gen_loss = 0.8113182604890181, disc_loss = 0.09788316878835168
Trained batch 413 in epoch 2, gen_loss = 0.8123894524603075, disc_loss = 0.0982403232657535
Trained batch 414 in epoch 2, gen_loss = 0.8123868404382683, disc_loss = 0.09813873898911189
Trained batch 415 in epoch 2, gen_loss = 0.8122584006677454, disc_loss = 0.09816969682175952
Trained batch 416 in epoch 2, gen_loss = 0.8123648224545897, disc_loss = 0.09819229940573375
Trained batch 417 in epoch 2, gen_loss = 0.8119677696644404, disc_loss = 0.09821788877533953
Trained batch 418 in epoch 2, gen_loss = 0.8122494614067396, disc_loss = 0.09818002595821827
Trained batch 419 in epoch 2, gen_loss = 0.8121351833144824, disc_loss = 0.0980224903318144
Trained batch 420 in epoch 2, gen_loss = 0.8118360983362674, disc_loss = 0.09812707779597217
Trained batch 421 in epoch 2, gen_loss = 0.8120637214720532, disc_loss = 0.09811806857091555
Trained batch 422 in epoch 2, gen_loss = 0.8118622089531404, disc_loss = 0.0980007683431144
Trained batch 423 in epoch 2, gen_loss = 0.8113941874284789, disc_loss = 0.09792875270974243
Trained batch 424 in epoch 2, gen_loss = 0.8114050478794995, disc_loss = 0.09785736961399807
Trained batch 425 in epoch 2, gen_loss = 0.8113927573245456, disc_loss = 0.09766182811939521
Trained batch 426 in epoch 2, gen_loss = 0.8112723601925289, disc_loss = 0.09752955027273584
Trained batch 427 in epoch 2, gen_loss = 0.8114344933740446, disc_loss = 0.09739062086914048
Trained batch 428 in epoch 2, gen_loss = 0.811672942969071, disc_loss = 0.09735257983954497
Trained batch 429 in epoch 2, gen_loss = 0.8114237364641456, disc_loss = 0.09734005608790836
Trained batch 430 in epoch 2, gen_loss = 0.8117793171284093, disc_loss = 0.09717624739521202
Trained batch 431 in epoch 2, gen_loss = 0.8113823188813748, disc_loss = 0.09703865954738662
Trained batch 432 in epoch 2, gen_loss = 0.8114400992630261, disc_loss = 0.0969869720579639
Trained batch 433 in epoch 2, gen_loss = 0.8123869330789636, disc_loss = 0.09716536671627089
Trained batch 434 in epoch 2, gen_loss = 0.8125986380823728, disc_loss = 0.09704579223247095
Trained batch 435 in epoch 2, gen_loss = 0.8118085235083868, disc_loss = 0.09716952187564531
Trained batch 436 in epoch 2, gen_loss = 0.8115245733981274, disc_loss = 0.09712682120945279
Trained batch 437 in epoch 2, gen_loss = 0.8114350238074995, disc_loss = 0.09706782447982189
Trained batch 438 in epoch 2, gen_loss = 0.8115639630917264, disc_loss = 0.09701358041978507
Trained batch 439 in epoch 2, gen_loss = 0.8118581315333193, disc_loss = 0.0970582236324183
Trained batch 440 in epoch 2, gen_loss = 0.8111912359456086, disc_loss = 0.09737970962562933
Trained batch 441 in epoch 2, gen_loss = 0.8113483674655673, disc_loss = 0.097250267125801
Trained batch 442 in epoch 2, gen_loss = 0.8114467957488032, disc_loss = 0.09730028329547452
Trained batch 443 in epoch 2, gen_loss = 0.8118712630894807, disc_loss = 0.09733769682294748
Trained batch 444 in epoch 2, gen_loss = 0.8117388690455576, disc_loss = 0.0973125560104512
Trained batch 445 in epoch 2, gen_loss = 0.8113072740390161, disc_loss = 0.09721173045764189
Trained batch 446 in epoch 2, gen_loss = 0.811965979852399, disc_loss = 0.09716290074256842
Trained batch 447 in epoch 2, gen_loss = 0.8116920746064612, disc_loss = 0.0970220206446746
Trained batch 448 in epoch 2, gen_loss = 0.8114143059089083, disc_loss = 0.09705205369981333
Trained batch 449 in epoch 2, gen_loss = 0.8110091480943892, disc_loss = 0.09711648012614912
Trained batch 450 in epoch 2, gen_loss = 0.8113086962382704, disc_loss = 0.09699814442437794
Trained batch 451 in epoch 2, gen_loss = 0.8108926795225228, disc_loss = 0.09691905084816096
Trained batch 452 in epoch 2, gen_loss = 0.8106162771747075, disc_loss = 0.0969779859965145
Trained batch 453 in epoch 2, gen_loss = 0.8106252016737597, disc_loss = 0.0968935715100248
Trained batch 454 in epoch 2, gen_loss = 0.8109853373779046, disc_loss = 0.09730279579513021
Trained batch 455 in epoch 2, gen_loss = 0.8105457708762404, disc_loss = 0.09725830528738075
Trained batch 456 in epoch 2, gen_loss = 0.8102557312216226, disc_loss = 0.0972639841498314
Trained batch 457 in epoch 2, gen_loss = 0.8109011072258762, disc_loss = 0.09738031317231827
Trained batch 458 in epoch 2, gen_loss = 0.8111207704658342, disc_loss = 0.0972616769381533
Trained batch 459 in epoch 2, gen_loss = 0.8107120981682902, disc_loss = 0.09726460784592707
Trained batch 460 in epoch 2, gen_loss = 0.8103269288183035, disc_loss = 0.0971727001878742
Trained batch 461 in epoch 2, gen_loss = 0.8104807826089653, disc_loss = 0.09727826457696431
Trained batch 462 in epoch 2, gen_loss = 0.809858740405954, disc_loss = 0.09739934150572085
Trained batch 463 in epoch 2, gen_loss = 0.8096538946546358, disc_loss = 0.09733808709806281
Trained batch 464 in epoch 2, gen_loss = 0.8099893431509695, disc_loss = 0.09749604285324133
Trained batch 465 in epoch 2, gen_loss = 0.8101526507748044, disc_loss = 0.09734537261398309
Trained batch 466 in epoch 2, gen_loss = 0.8103618499298423, disc_loss = 0.09722598516073165
Trained batch 467 in epoch 2, gen_loss = 0.8094324133971817, disc_loss = 0.09746086517842407
Trained batch 468 in epoch 2, gen_loss = 0.8090919415706764, disc_loss = 0.09752645125902538
Trained batch 469 in epoch 2, gen_loss = 0.8093115663908897, disc_loss = 0.09749083140111985
Trained batch 470 in epoch 2, gen_loss = 0.8096838201813384, disc_loss = 0.09757281632623349
Trained batch 471 in epoch 2, gen_loss = 0.8092650606344312, disc_loss = 0.09766619998204001
Trained batch 472 in epoch 2, gen_loss = 0.8091901808536078, disc_loss = 0.0975730838785716
Trained batch 473 in epoch 2, gen_loss = 0.8089925278968448, disc_loss = 0.09752930626901896
Trained batch 474 in epoch 2, gen_loss = 0.8093557590559909, disc_loss = 0.09743881636544278
Trained batch 475 in epoch 2, gen_loss = 0.8093148426724082, disc_loss = 0.09734789677308638
Trained batch 476 in epoch 2, gen_loss = 0.8087967499871924, disc_loss = 0.09739897986659214
Trained batch 477 in epoch 2, gen_loss = 0.8090988565314265, disc_loss = 0.09740681562058347
Trained batch 478 in epoch 2, gen_loss = 0.8092976154638979, disc_loss = 0.09739070793998764
Trained batch 479 in epoch 2, gen_loss = 0.8093732094392181, disc_loss = 0.09762396001412223
Trained batch 480 in epoch 2, gen_loss = 0.8089734157876513, disc_loss = 0.09784422228558148
Trained batch 481 in epoch 2, gen_loss = 0.8089256170997976, disc_loss = 0.09775915018503102
Trained batch 482 in epoch 2, gen_loss = 0.8090857582679694, disc_loss = 0.09766024501519914
Trained batch 483 in epoch 2, gen_loss = 0.8091092207584499, disc_loss = 0.09758329876382982
Trained batch 484 in epoch 2, gen_loss = 0.809398447299741, disc_loss = 0.09753363415138008
Trained batch 485 in epoch 2, gen_loss = 0.8087893662506661, disc_loss = 0.09774254342165503
Trained batch 486 in epoch 2, gen_loss = 0.808777091133521, disc_loss = 0.09771353808027028
Trained batch 487 in epoch 2, gen_loss = 0.8083439993931621, disc_loss = 0.09791873148108116
Trained batch 488 in epoch 2, gen_loss = 0.8091972285618811, disc_loss = 0.09809281236676838
Trained batch 489 in epoch 2, gen_loss = 0.80912915985195, disc_loss = 0.0980866161232092
Trained batch 490 in epoch 2, gen_loss = 0.808930221315314, disc_loss = 0.09797126485713874
Trained batch 491 in epoch 2, gen_loss = 0.8091025584475781, disc_loss = 0.09799744661261396
Trained batch 492 in epoch 2, gen_loss = 0.8092876906689959, disc_loss = 0.09783102078155499
Trained batch 493 in epoch 2, gen_loss = 0.8088978142270192, disc_loss = 0.09783038912107225
Trained batch 494 in epoch 2, gen_loss = 0.8092948395194429, disc_loss = 0.09772161235186187
Trained batch 495 in epoch 2, gen_loss = 0.8102662791047366, disc_loss = 0.09771047255039335
Trained batch 496 in epoch 2, gen_loss = 0.8098923116022912, disc_loss = 0.09782199971227938
Trained batch 497 in epoch 2, gen_loss = 0.8095483468119878, disc_loss = 0.09780668184894276
Trained batch 498 in epoch 2, gen_loss = 0.8098941879544803, disc_loss = 0.09800610640916772
Trained batch 499 in epoch 2, gen_loss = 0.8093439415097237, disc_loss = 0.09807483373954892
Trained batch 500 in epoch 2, gen_loss = 0.8091944863577327, disc_loss = 0.09799286256546151
Trained batch 501 in epoch 2, gen_loss = 0.8087916020971845, disc_loss = 0.09801499078428721
Trained batch 502 in epoch 2, gen_loss = 0.8092263515735004, disc_loss = 0.09792261733997532
Trained batch 503 in epoch 2, gen_loss = 0.809588138605394, disc_loss = 0.09780388583044802
Trained batch 504 in epoch 2, gen_loss = 0.8099085005793241, disc_loss = 0.0976362708255206
Trained batch 505 in epoch 2, gen_loss = 0.809471605382418, disc_loss = 0.0975849167351784
Trained batch 506 in epoch 2, gen_loss = 0.809326950085939, disc_loss = 0.09762346851079186
Trained batch 507 in epoch 2, gen_loss = 0.8093823233809997, disc_loss = 0.09746304920353875
Trained batch 508 in epoch 2, gen_loss = 0.8090239207613444, disc_loss = 0.09754730205185169
Trained batch 509 in epoch 2, gen_loss = 0.8086967609092302, disc_loss = 0.09742640627584621
Trained batch 510 in epoch 2, gen_loss = 0.8087227737017108, disc_loss = 0.09783193728214024
Trained batch 511 in epoch 2, gen_loss = 0.8081358464551158, disc_loss = 0.09819838413022808
Trained batch 512 in epoch 2, gen_loss = 0.8080480212008047, disc_loss = 0.09807067077977268
Trained batch 513 in epoch 2, gen_loss = 0.8080917939485743, disc_loss = 0.09795625864778164
Trained batch 514 in epoch 2, gen_loss = 0.8078312119812642, disc_loss = 0.09787069738851589
Trained batch 515 in epoch 2, gen_loss = 0.8076309399433839, disc_loss = 0.09778225129152569
Trained batch 516 in epoch 2, gen_loss = 0.8078018341004503, disc_loss = 0.09769044671301338
Trained batch 517 in epoch 2, gen_loss = 0.8074343506548856, disc_loss = 0.09763253702059331
Trained batch 518 in epoch 2, gen_loss = 0.8070647439171124, disc_loss = 0.0976768321965988
Trained batch 519 in epoch 2, gen_loss = 0.8069067955590211, disc_loss = 0.09761898459221881
Trained batch 520 in epoch 2, gen_loss = 0.8066137001175798, disc_loss = 0.09752565140044049
Trained batch 521 in epoch 2, gen_loss = 0.8069285940507362, disc_loss = 0.09753375638533256
Trained batch 522 in epoch 2, gen_loss = 0.8061860635677214, disc_loss = 0.09819329330202613
Trained batch 523 in epoch 2, gen_loss = 0.8058289382748931, disc_loss = 0.09855246155359249
Trained batch 524 in epoch 2, gen_loss = 0.8059150196257092, disc_loss = 0.09852808459528854
Trained batch 525 in epoch 2, gen_loss = 0.8060238729638292, disc_loss = 0.0984757588609713
Trained batch 526 in epoch 2, gen_loss = 0.8054322621854025, disc_loss = 0.09854408627485528
Trained batch 527 in epoch 2, gen_loss = 0.8053519344239524, disc_loss = 0.0984482123114338
Trained batch 528 in epoch 2, gen_loss = 0.8051470804304617, disc_loss = 0.09835686890623183
Trained batch 529 in epoch 2, gen_loss = 0.8064497700277364, disc_loss = 0.09870530602715488
Trained batch 530 in epoch 2, gen_loss = 0.8060144151222459, disc_loss = 0.09876735965509087
Trained batch 531 in epoch 2, gen_loss = 0.805760338566357, disc_loss = 0.09868810849292274
Trained batch 532 in epoch 2, gen_loss = 0.8061516539911839, disc_loss = 0.09858049233889603
Trained batch 533 in epoch 2, gen_loss = 0.8059247113792191, disc_loss = 0.09864004388493433
Trained batch 534 in epoch 2, gen_loss = 0.8062539559658443, disc_loss = 0.09855888977159406
Trained batch 535 in epoch 2, gen_loss = 0.8059313536357524, disc_loss = 0.09867088211380612
Trained batch 536 in epoch 2, gen_loss = 0.806387276955823, disc_loss = 0.09858118095114356
Trained batch 537 in epoch 2, gen_loss = 0.8060305488597062, disc_loss = 0.09857542946117628
Trained batch 538 in epoch 2, gen_loss = 0.805766858948405, disc_loss = 0.0986470932897754
Trained batch 539 in epoch 2, gen_loss = 0.8060815138949289, disc_loss = 0.09856442098885222
Trained batch 540 in epoch 2, gen_loss = 0.8062145697872212, disc_loss = 0.09855756013828042
Trained batch 541 in epoch 2, gen_loss = 0.8061585992684663, disc_loss = 0.09848592248556248
Trained batch 542 in epoch 2, gen_loss = 0.8059899015540796, disc_loss = 0.09842209130676521
Trained batch 543 in epoch 2, gen_loss = 0.8058250937610865, disc_loss = 0.0983378309653798
Trained batch 544 in epoch 2, gen_loss = 0.8059565785827987, disc_loss = 0.09820000312948993
Trained batch 545 in epoch 2, gen_loss = 0.8059105234486716, disc_loss = 0.09812992352364591
Trained batch 546 in epoch 2, gen_loss = 0.806579722673845, disc_loss = 0.0980261888055359
Trained batch 547 in epoch 2, gen_loss = 0.8065312542837032, disc_loss = 0.09815766500907332
Trained batch 548 in epoch 2, gen_loss = 0.8063932152393737, disc_loss = 0.09813116063687863
Trained batch 549 in epoch 2, gen_loss = 0.8064215139909224, disc_loss = 0.0981079717556184
Trained batch 550 in epoch 2, gen_loss = 0.8065375442297186, disc_loss = 0.09796046976426011
Trained batch 551 in epoch 2, gen_loss = 0.8071085590383281, disc_loss = 0.09787570990527561
Trained batch 552 in epoch 2, gen_loss = 0.8070177180426461, disc_loss = 0.09795594029802203
Trained batch 553 in epoch 2, gen_loss = 0.8067416128053562, disc_loss = 0.09806246391500914
Trained batch 554 in epoch 2, gen_loss = 0.8064648829064928, disc_loss = 0.09796769879758357
Trained batch 555 in epoch 2, gen_loss = 0.8071297382493671, disc_loss = 0.09831567937106216
Trained batch 556 in epoch 2, gen_loss = 0.8066810747237351, disc_loss = 0.09837404565293763
Trained batch 557 in epoch 2, gen_loss = 0.8064910295189068, disc_loss = 0.09842212340964746
Trained batch 558 in epoch 2, gen_loss = 0.8061909972021959, disc_loss = 0.09849117456707097
Trained batch 559 in epoch 2, gen_loss = 0.8061394023043769, disc_loss = 0.09846680162008851
Trained batch 560 in epoch 2, gen_loss = 0.8063512473182882, disc_loss = 0.09833466595971754
Trained batch 561 in epoch 2, gen_loss = 0.8065474553040338, disc_loss = 0.09817964256180987
Trained batch 562 in epoch 2, gen_loss = 0.8064159934093008, disc_loss = 0.09819607334757359
Trained batch 563 in epoch 2, gen_loss = 0.8063886313573688, disc_loss = 0.09811753240011051
Trained batch 564 in epoch 2, gen_loss = 0.8070541016823423, disc_loss = 0.09811457666543733
Trained batch 565 in epoch 2, gen_loss = 0.806958768056054, disc_loss = 0.09800134877618337
Trained batch 566 in epoch 2, gen_loss = 0.8068544661767478, disc_loss = 0.0979107794675457
Trained batch 567 in epoch 2, gen_loss = 0.8077056478236763, disc_loss = 0.09810638118167998
Trained batch 568 in epoch 2, gen_loss = 0.8076067376220583, disc_loss = 0.09811439170045468
Trained batch 569 in epoch 2, gen_loss = 0.8072711678973415, disc_loss = 0.098197983309888
Trained batch 570 in epoch 2, gen_loss = 0.8070130674935055, disc_loss = 0.09818149950427058
Trained batch 571 in epoch 2, gen_loss = 0.8077936990486159, disc_loss = 0.09823201259376703
Trained batch 572 in epoch 2, gen_loss = 0.807911258821504, disc_loss = 0.09814849096703071
Trained batch 573 in epoch 2, gen_loss = 0.8079265479634448, disc_loss = 0.098036347508742
Trained batch 574 in epoch 2, gen_loss = 0.8075452904079271, disc_loss = 0.09798164026892703
Trained batch 575 in epoch 2, gen_loss = 0.8073870523108376, disc_loss = 0.09796153285747601
Trained batch 576 in epoch 2, gen_loss = 0.8073331185808628, disc_loss = 0.09786966517955013
Trained batch 577 in epoch 2, gen_loss = 0.807108336872708, disc_loss = 0.09781239576199476
Trained batch 578 in epoch 2, gen_loss = 0.8078253475083794, disc_loss = 0.0979003993752501
Trained batch 579 in epoch 2, gen_loss = 0.8075049612028845, disc_loss = 0.09785291302049982
Trained batch 580 in epoch 2, gen_loss = 0.8073513784835342, disc_loss = 0.09778332964175744
Trained batch 581 in epoch 2, gen_loss = 0.8070220642073458, disc_loss = 0.09773443699446331
Trained batch 582 in epoch 2, gen_loss = 0.8068338516032512, disc_loss = 0.09773158197695354
Trained batch 583 in epoch 2, gen_loss = 0.8069892353186868, disc_loss = 0.09768516423614466
Trained batch 584 in epoch 2, gen_loss = 0.8068583727901817, disc_loss = 0.09758052517715682
Trained batch 585 in epoch 2, gen_loss = 0.8067871333185723, disc_loss = 0.09753084524753965
Trained batch 586 in epoch 2, gen_loss = 0.8066285559225326, disc_loss = 0.09746849496913931
Trained batch 587 in epoch 2, gen_loss = 0.8064798123779751, disc_loss = 0.09747875638331482
Trained batch 588 in epoch 2, gen_loss = 0.806670136180515, disc_loss = 0.09747736594293438
Trained batch 589 in epoch 2, gen_loss = 0.8062886201729209, disc_loss = 0.09746471329639524
Trained batch 590 in epoch 2, gen_loss = 0.8063702686183949, disc_loss = 0.09748060319906765
Trained batch 591 in epoch 2, gen_loss = 0.806167637375561, disc_loss = 0.09756414845862703
Trained batch 592 in epoch 2, gen_loss = 0.8064918270802619, disc_loss = 0.09751212234415654
Trained batch 593 in epoch 2, gen_loss = 0.8066458643887581, disc_loss = 0.09738079289770889
Trained batch 594 in epoch 2, gen_loss = 0.8061138976521852, disc_loss = 0.09756751500633584
Trained batch 595 in epoch 2, gen_loss = 0.806557719539476, disc_loss = 0.09748013673237706
Trained batch 596 in epoch 2, gen_loss = 0.8067630998652984, disc_loss = 0.09747566886158844
Trained batch 597 in epoch 2, gen_loss = 0.8067868491478987, disc_loss = 0.09739824087922788
Trained batch 598 in epoch 2, gen_loss = 0.8067309303156323, disc_loss = 0.0972972480029813
Trained batch 599 in epoch 2, gen_loss = 0.8067141749461492, disc_loss = 0.09719238265107076
Trained batch 600 in epoch 2, gen_loss = 0.8065920777606488, disc_loss = 0.09713871870034943
Trained batch 601 in epoch 2, gen_loss = 0.8069346744158735, disc_loss = 0.0972468746931252
Trained batch 602 in epoch 2, gen_loss = 0.8065126965295023, disc_loss = 0.09737760749078707
Trained batch 603 in epoch 2, gen_loss = 0.8060722416205122, disc_loss = 0.09736852109777612
Trained batch 604 in epoch 2, gen_loss = 0.8062449489743256, disc_loss = 0.09748558794910257
Trained batch 605 in epoch 2, gen_loss = 0.8058953631435684, disc_loss = 0.09747981635404893
Trained batch 606 in epoch 2, gen_loss = 0.8057311956925682, disc_loss = 0.09744621802250282
Trained batch 607 in epoch 2, gen_loss = 0.8062329946183845, disc_loss = 0.09744802060978193
Trained batch 608 in epoch 2, gen_loss = 0.8061451972607517, disc_loss = 0.09743977420044259
Trained batch 609 in epoch 2, gen_loss = 0.8062563746679025, disc_loss = 0.0973562160964872
Trained batch 610 in epoch 2, gen_loss = 0.8068175115874083, disc_loss = 0.09729630932967909
Trained batch 611 in epoch 2, gen_loss = 0.8074260631612703, disc_loss = 0.0971847101163387
Trained batch 612 in epoch 2, gen_loss = 0.807339253277802, disc_loss = 0.09708947581079519
Trained batch 613 in epoch 2, gen_loss = 0.8071942390564598, disc_loss = 0.09706871070465262
Trained batch 614 in epoch 2, gen_loss = 0.8075984496411269, disc_loss = 0.09707844029294281
Trained batch 615 in epoch 2, gen_loss = 0.8075225213905434, disc_loss = 0.09698378261747201
Trained batch 616 in epoch 2, gen_loss = 0.8083112603068545, disc_loss = 0.09703104614281674
Trained batch 617 in epoch 2, gen_loss = 0.808445553370664, disc_loss = 0.09692278396169442
Trained batch 618 in epoch 2, gen_loss = 0.8080286815979176, disc_loss = 0.09689185718113559
Trained batch 619 in epoch 2, gen_loss = 0.808067246214036, disc_loss = 0.09678405315705364
Trained batch 620 in epoch 2, gen_loss = 0.8080723504513359, disc_loss = 0.09670483063300547
Trained batch 621 in epoch 2, gen_loss = 0.8084131084454405, disc_loss = 0.09663509326864189
Trained batch 622 in epoch 2, gen_loss = 0.8084894051329856, disc_loss = 0.09656828225412395
Trained batch 623 in epoch 2, gen_loss = 0.8079693908683765, disc_loss = 0.09662725823895577
Trained batch 624 in epoch 2, gen_loss = 0.8080716143608093, disc_loss = 0.09649686700105667
Trained batch 625 in epoch 2, gen_loss = 0.8087691221945583, disc_loss = 0.09685570488389307
Trained batch 626 in epoch 2, gen_loss = 0.8088049292564392, disc_loss = 0.09683690583734421
Trained batch 627 in epoch 2, gen_loss = 0.8085638928185602, disc_loss = 0.09700286119084829
Trained batch 628 in epoch 2, gen_loss = 0.8087272285846534, disc_loss = 0.09687738591695533
Trained batch 629 in epoch 2, gen_loss = 0.8091710542875623, disc_loss = 0.09694892406641017
Trained batch 630 in epoch 2, gen_loss = 0.809216022019152, disc_loss = 0.09691346774140458
Trained batch 631 in epoch 2, gen_loss = 0.8088125772302663, disc_loss = 0.09699955045929344
Trained batch 632 in epoch 2, gen_loss = 0.8089379005334201, disc_loss = 0.09690910632211544
Trained batch 633 in epoch 2, gen_loss = 0.8090557998475216, disc_loss = 0.0970241736285741
Trained batch 634 in epoch 2, gen_loss = 0.8089871478831674, disc_loss = 0.09694292641824155
Trained batch 635 in epoch 2, gen_loss = 0.8090142188769467, disc_loss = 0.09697437129692181
Trained batch 636 in epoch 2, gen_loss = 0.8087765864524961, disc_loss = 0.09696801740448086
Trained batch 637 in epoch 2, gen_loss = 0.8089529611287072, disc_loss = 0.09685150164013093
Trained batch 638 in epoch 2, gen_loss = 0.8090016865207929, disc_loss = 0.09681839491524886
Trained batch 639 in epoch 2, gen_loss = 0.8090275292284786, disc_loss = 0.09684742117824499
Trained batch 640 in epoch 2, gen_loss = 0.808690556776877, disc_loss = 0.09690004323613532
Trained batch 641 in epoch 2, gen_loss = 0.8083497332263958, disc_loss = 0.0970086878618208
Trained batch 642 in epoch 2, gen_loss = 0.8082845843227617, disc_loss = 0.09703711910726587
Trained batch 643 in epoch 2, gen_loss = 0.8086087416788066, disc_loss = 0.09714065272627133
Trained batch 644 in epoch 2, gen_loss = 0.8084955706152805, disc_loss = 0.09706614270170992
Trained batch 645 in epoch 2, gen_loss = 0.8083596526653773, disc_loss = 0.097092001877679
Trained batch 646 in epoch 2, gen_loss = 0.808083770264061, disc_loss = 0.09724960798308414
Trained batch 647 in epoch 2, gen_loss = 0.8081614010863833, disc_loss = 0.09719053145072619
Trained batch 648 in epoch 2, gen_loss = 0.8078445102474171, disc_loss = 0.09724697139751287
Trained batch 649 in epoch 2, gen_loss = 0.8073892191740183, disc_loss = 0.09735380628647712
Trained batch 650 in epoch 2, gen_loss = 0.8080448836957987, disc_loss = 0.09736461766613519
Trained batch 651 in epoch 2, gen_loss = 0.8082536553129828, disc_loss = 0.0975013962729714
Trained batch 652 in epoch 2, gen_loss = 0.8081154464580016, disc_loss = 0.09748128253629981
Trained batch 653 in epoch 2, gen_loss = 0.8077041840334551, disc_loss = 0.09751254711755827
Trained batch 654 in epoch 2, gen_loss = 0.8078192234039306, disc_loss = 0.09764295452139304
Trained batch 655 in epoch 2, gen_loss = 0.8076037517408046, disc_loss = 0.09770264380849988
Trained batch 656 in epoch 2, gen_loss = 0.807086755333063, disc_loss = 0.09799472799119249
Trained batch 657 in epoch 2, gen_loss = 0.8075599429455209, disc_loss = 0.09830449149861796
Trained batch 658 in epoch 2, gen_loss = 0.8075883644484605, disc_loss = 0.09839958725539524
Trained batch 659 in epoch 2, gen_loss = 0.807600781863386, disc_loss = 0.0983323599098984
Trained batch 660 in epoch 2, gen_loss = 0.8075717169109523, disc_loss = 0.09826752552748538
Trained batch 661 in epoch 2, gen_loss = 0.8074274975187469, disc_loss = 0.09829504853480261
Trained batch 662 in epoch 2, gen_loss = 0.8075383752359704, disc_loss = 0.09827068639388181
Trained batch 663 in epoch 2, gen_loss = 0.8076540149119963, disc_loss = 0.0981993943660419
Trained batch 664 in epoch 2, gen_loss = 0.807711736958726, disc_loss = 0.0980868585967928
Trained batch 665 in epoch 2, gen_loss = 0.8077761460173953, disc_loss = 0.09800801053083874
Trained batch 666 in epoch 2, gen_loss = 0.8076625400218649, disc_loss = 0.09797600160228616
Trained batch 667 in epoch 2, gen_loss = 0.8079293284587518, disc_loss = 0.09795876585147874
Trained batch 668 in epoch 2, gen_loss = 0.8077258500639455, disc_loss = 0.09785170476432606
Trained batch 669 in epoch 2, gen_loss = 0.8075338631423552, disc_loss = 0.09775458957666337
Trained batch 670 in epoch 2, gen_loss = 0.8072600562775011, disc_loss = 0.09766907294609774
Trained batch 671 in epoch 2, gen_loss = 0.8073204984622342, disc_loss = 0.0975945149853249
Trained batch 672 in epoch 2, gen_loss = 0.8079565993744056, disc_loss = 0.09752831008855425
Trained batch 673 in epoch 2, gen_loss = 0.8082383542987642, disc_loss = 0.09740313324104519
Trained batch 674 in epoch 2, gen_loss = 0.8082391725646125, disc_loss = 0.09734301284783416
Trained batch 675 in epoch 2, gen_loss = 0.8080584039173183, disc_loss = 0.09736691926986243
Trained batch 676 in epoch 2, gen_loss = 0.8078811854520259, disc_loss = 0.09744187320363838
Trained batch 677 in epoch 2, gen_loss = 0.8079568066779843, disc_loss = 0.09742396153718409
Trained batch 678 in epoch 2, gen_loss = 0.8081868512992129, disc_loss = 0.09756743352975428
Trained batch 679 in epoch 2, gen_loss = 0.808012354286278, disc_loss = 0.09758383305469419
Trained batch 680 in epoch 2, gen_loss = 0.8081040729860202, disc_loss = 0.09751549937793774
Trained batch 681 in epoch 2, gen_loss = 0.8078612573335597, disc_loss = 0.097522665691887
Trained batch 682 in epoch 2, gen_loss = 0.8078166059658782, disc_loss = 0.09742375111444629
Trained batch 683 in epoch 2, gen_loss = 0.8075251222005364, disc_loss = 0.09743756642401741
Trained batch 684 in epoch 2, gen_loss = 0.807534910292521, disc_loss = 0.09759440028863231
Trained batch 685 in epoch 2, gen_loss = 0.8074102914368099, disc_loss = 0.09761174061707609
Trained batch 686 in epoch 2, gen_loss = 0.8069340039635676, disc_loss = 0.09781046100557285
Trained batch 687 in epoch 2, gen_loss = 0.8074872180559608, disc_loss = 0.09787981716244547
Trained batch 688 in epoch 2, gen_loss = 0.8076560848942689, disc_loss = 0.09784531146179781
Trained batch 689 in epoch 2, gen_loss = 0.8073765109846558, disc_loss = 0.09813432812798714
Trained batch 690 in epoch 2, gen_loss = 0.8074850515501544, disc_loss = 0.09802846059569746
Trained batch 691 in epoch 2, gen_loss = 0.8075507306036233, disc_loss = 0.09797686883221472
Trained batch 692 in epoch 2, gen_loss = 0.8076343354466674, disc_loss = 0.0979999392730161
Trained batch 693 in epoch 2, gen_loss = 0.8072052035019103, disc_loss = 0.09802834804489222
Trained batch 694 in epoch 2, gen_loss = 0.8072956758866208, disc_loss = 0.09793009379570433
Trained batch 695 in epoch 2, gen_loss = 0.8076906423030914, disc_loss = 0.09808885514864633
Trained batch 696 in epoch 2, gen_loss = 0.8074276663224016, disc_loss = 0.09806107970187107
Trained batch 697 in epoch 2, gen_loss = 0.8073989499178862, disc_loss = 0.09795233140296615
Trained batch 698 in epoch 2, gen_loss = 0.8074174909206249, disc_loss = 0.09786531781092904
Trained batch 699 in epoch 2, gen_loss = 0.8077018768021038, disc_loss = 0.09795160927942821
Trained batch 700 in epoch 2, gen_loss = 0.807711433539547, disc_loss = 0.09787732263902114
Trained batch 701 in epoch 2, gen_loss = 0.807419857365793, disc_loss = 0.09795753794730219
Trained batch 702 in epoch 2, gen_loss = 0.807573570423411, disc_loss = 0.09796714898235936
Trained batch 703 in epoch 2, gen_loss = 0.8081570423038845, disc_loss = 0.09810775064397603
Trained batch 704 in epoch 2, gen_loss = 0.80803531666174, disc_loss = 0.09828009454282463
Trained batch 705 in epoch 2, gen_loss = 0.8081839629594058, disc_loss = 0.09818193480034726
Trained batch 706 in epoch 2, gen_loss = 0.8082108853814288, disc_loss = 0.09815749202497946
Trained batch 707 in epoch 2, gen_loss = 0.808478275050888, disc_loss = 0.09809811345412064
Trained batch 708 in epoch 2, gen_loss = 0.8082416652372089, disc_loss = 0.09817192168073527
Trained batch 709 in epoch 2, gen_loss = 0.808396004329265, disc_loss = 0.09809935974927855
Trained batch 710 in epoch 2, gen_loss = 0.8082833271237868, disc_loss = 0.09811317478994278
Trained batch 711 in epoch 2, gen_loss = 0.8087594281003047, disc_loss = 0.09825687498126305
Trained batch 712 in epoch 2, gen_loss = 0.8085195800448869, disc_loss = 0.09823936667570225
Trained batch 713 in epoch 2, gen_loss = 0.8086392030078156, disc_loss = 0.09814842446010653
Trained batch 714 in epoch 2, gen_loss = 0.8084877604788, disc_loss = 0.09814787634185977
Trained batch 715 in epoch 2, gen_loss = 0.8083236680766723, disc_loss = 0.09817756874767762
Trained batch 716 in epoch 2, gen_loss = 0.8081747470124828, disc_loss = 0.09811324679203114
Trained batch 717 in epoch 2, gen_loss = 0.8081137818961422, disc_loss = 0.09809559688470158
Trained batch 718 in epoch 2, gen_loss = 0.8084460893575937, disc_loss = 0.09823067454162658
Trained batch 719 in epoch 2, gen_loss = 0.8082157997207509, disc_loss = 0.09823310686689284
Trained batch 720 in epoch 2, gen_loss = 0.8080383869464123, disc_loss = 0.09818466368354806
Trained batch 721 in epoch 2, gen_loss = 0.8079758731859873, disc_loss = 0.09815549061032544
Trained batch 722 in epoch 2, gen_loss = 0.8082457130792889, disc_loss = 0.09806473145099101
Trained batch 723 in epoch 2, gen_loss = 0.8083318342243769, disc_loss = 0.0979550345980907
Trained batch 724 in epoch 2, gen_loss = 0.8082280951121757, disc_loss = 0.0978646303610555
Trained batch 725 in epoch 2, gen_loss = 0.8085266288893282, disc_loss = 0.097857624420655
Trained batch 726 in epoch 2, gen_loss = 0.808056390515056, disc_loss = 0.09801582342841274
Trained batch 727 in epoch 2, gen_loss = 0.8085834442095442, disc_loss = 0.09790510332191384
Trained batch 728 in epoch 2, gen_loss = 0.808656928961169, disc_loss = 0.09783565263750622
Trained batch 729 in epoch 2, gen_loss = 0.8091347847899345, disc_loss = 0.09787927116331173
Trained batch 730 in epoch 2, gen_loss = 0.8090381941129995, disc_loss = 0.09786192187593508
Trained batch 731 in epoch 2, gen_loss = 0.8090508367683067, disc_loss = 0.09775804438694416
Trained batch 732 in epoch 2, gen_loss = 0.808887346054327, disc_loss = 0.09771405387603732
Trained batch 733 in epoch 2, gen_loss = 0.808607016986982, disc_loss = 0.09766365174072153
Trained batch 734 in epoch 2, gen_loss = 0.8087457615502026, disc_loss = 0.09770360200279424
Trained batch 735 in epoch 2, gen_loss = 0.8089176571077626, disc_loss = 0.0975998455516832
Trained batch 736 in epoch 2, gen_loss = 0.8088054217024121, disc_loss = 0.0975992823755078
Trained batch 737 in epoch 2, gen_loss = 0.8086416244829896, disc_loss = 0.09752740948221225
Trained batch 738 in epoch 2, gen_loss = 0.8086621493544727, disc_loss = 0.09746793853131618
Trained batch 739 in epoch 2, gen_loss = 0.8089820146560669, disc_loss = 0.09739136661629419
Trained batch 740 in epoch 2, gen_loss = 0.8091557824659926, disc_loss = 0.09733967394561742
Trained batch 741 in epoch 2, gen_loss = 0.8090215539032558, disc_loss = 0.09740560266849486
Trained batch 742 in epoch 2, gen_loss = 0.8092091314564803, disc_loss = 0.09733711812810654
Trained batch 743 in epoch 2, gen_loss = 0.8095232841148171, disc_loss = 0.09728777962386288
Trained batch 744 in epoch 2, gen_loss = 0.8093138240327771, disc_loss = 0.09722834940524709
Trained batch 745 in epoch 2, gen_loss = 0.8089502776595926, disc_loss = 0.09729083688385365
Trained batch 746 in epoch 2, gen_loss = 0.8092150862118007, disc_loss = 0.09725136531285014
Trained batch 747 in epoch 2, gen_loss = 0.8089220691970326, disc_loss = 0.09725976620805774
Trained batch 748 in epoch 2, gen_loss = 0.8090454485610585, disc_loss = 0.09717213164502693
Trained batch 749 in epoch 2, gen_loss = 0.8089117321968079, disc_loss = 0.09710616710285346
Trained batch 750 in epoch 2, gen_loss = 0.8089211356941457, disc_loss = 0.09703936061255147
Trained batch 751 in epoch 2, gen_loss = 0.8088708952703374, disc_loss = 0.09700474593332632
Trained batch 752 in epoch 2, gen_loss = 0.8092990898357761, disc_loss = 0.09700125145662829
Trained batch 753 in epoch 2, gen_loss = 0.8096185636457145, disc_loss = 0.0969390020772459
Trained batch 754 in epoch 2, gen_loss = 0.8093534775917104, disc_loss = 0.09695176119539911
Trained batch 755 in epoch 2, gen_loss = 0.8094797905475374, disc_loss = 0.09685755222198114
Trained batch 756 in epoch 2, gen_loss = 0.8096698918619748, disc_loss = 0.09678566916704257
Trained batch 757 in epoch 2, gen_loss = 0.8097774174880227, disc_loss = 0.09680374209722381
Trained batch 758 in epoch 2, gen_loss = 0.8101372746296708, disc_loss = 0.09671133419201858
Trained batch 759 in epoch 2, gen_loss = 0.8099287862840452, disc_loss = 0.09671656121009667
Trained batch 760 in epoch 2, gen_loss = 0.809837646929256, disc_loss = 0.09670489054520795
Trained batch 761 in epoch 2, gen_loss = 0.8101828921185391, disc_loss = 0.09682726777180678
Trained batch 762 in epoch 2, gen_loss = 0.8097502425176288, disc_loss = 0.09698477339824639
Trained batch 763 in epoch 2, gen_loss = 0.8095344127940882, disc_loss = 0.09694065845264269
Trained batch 764 in epoch 2, gen_loss = 0.8094326276405185, disc_loss = 0.09688677568889521
Trained batch 765 in epoch 2, gen_loss = 0.8096178153787519, disc_loss = 0.09684717345146301
Trained batch 766 in epoch 2, gen_loss = 0.809382000211942, disc_loss = 0.0968939389722638
Trained batch 767 in epoch 2, gen_loss = 0.8096658151286343, disc_loss = 0.09697862746785783
Trained batch 768 in epoch 2, gen_loss = 0.809753536247928, disc_loss = 0.09692483069072387
Trained batch 769 in epoch 2, gen_loss = 0.8098492586767518, disc_loss = 0.09690884589036176
Trained batch 770 in epoch 2, gen_loss = 0.8098726215374918, disc_loss = 0.09682229205956332
Trained batch 771 in epoch 2, gen_loss = 0.8102252228581226, disc_loss = 0.09674077326373964
Trained batch 772 in epoch 2, gen_loss = 0.8104688421874892, disc_loss = 0.0969049694211756
Trained batch 773 in epoch 2, gen_loss = 0.8101342612304737, disc_loss = 0.09730662959712036
Trained batch 774 in epoch 2, gen_loss = 0.8103145177902714, disc_loss = 0.09723435209403115
Trained batch 775 in epoch 2, gen_loss = 0.8105362339578953, disc_loss = 0.09729524144720401
Trained batch 776 in epoch 2, gen_loss = 0.8104250356650874, disc_loss = 0.09726155091657218
Trained batch 777 in epoch 2, gen_loss = 0.8105057406701281, disc_loss = 0.09721793627706392
Trained batch 778 in epoch 2, gen_loss = 0.8101773502278848, disc_loss = 0.09722873975734427
Trained batch 779 in epoch 2, gen_loss = 0.8104507099359464, disc_loss = 0.09724450674719917
Trained batch 780 in epoch 2, gen_loss = 0.8102258397278194, disc_loss = 0.09720329751192608
Trained batch 781 in epoch 2, gen_loss = 0.8104812357279346, disc_loss = 0.09712196698607616
Trained batch 782 in epoch 2, gen_loss = 0.8107540474236392, disc_loss = 0.09724012796325777
Trained batch 783 in epoch 2, gen_loss = 0.8104955715944573, disc_loss = 0.09731587658075577
Trained batch 784 in epoch 2, gen_loss = 0.8108678410007696, disc_loss = 0.09728199923826251
Trained batch 785 in epoch 2, gen_loss = 0.8105985873376443, disc_loss = 0.09735722487920341
Trained batch 786 in epoch 2, gen_loss = 0.8106663984446544, disc_loss = 0.09730032855334776
Trained batch 787 in epoch 2, gen_loss = 0.8103663054517078, disc_loss = 0.09726333363114048
Trained batch 788 in epoch 2, gen_loss = 0.8104318591880557, disc_loss = 0.09718388631344975
Trained batch 789 in epoch 2, gen_loss = 0.8104063280021088, disc_loss = 0.0971462916229156
Trained batch 790 in epoch 2, gen_loss = 0.8106428118029376, disc_loss = 0.09707875725696648
Trained batch 791 in epoch 2, gen_loss = 0.810442421698209, disc_loss = 0.09707521295146734
Trained batch 792 in epoch 2, gen_loss = 0.8104074710855568, disc_loss = 0.09701348760624476
Trained batch 793 in epoch 2, gen_loss = 0.8106887627308554, disc_loss = 0.09701703262916515
Trained batch 794 in epoch 2, gen_loss = 0.8106288780206404, disc_loss = 0.09693891127482525
Trained batch 795 in epoch 2, gen_loss = 0.8107921908698489, disc_loss = 0.09687177168823143
Trained batch 796 in epoch 2, gen_loss = 0.8107521077769912, disc_loss = 0.09678154094717284
Trained batch 797 in epoch 2, gen_loss = 0.8109010014318883, disc_loss = 0.09671492649611076
Trained batch 798 in epoch 2, gen_loss = 0.8106560116267771, disc_loss = 0.0966564124876701
Trained batch 799 in epoch 2, gen_loss = 0.810891836732626, disc_loss = 0.09658003865741194
Trained batch 800 in epoch 2, gen_loss = 0.811117537161533, disc_loss = 0.09659471632575573
Trained batch 801 in epoch 2, gen_loss = 0.811059208433527, disc_loss = 0.09655134196850725
Trained batch 802 in epoch 2, gen_loss = 0.8108885077432558, disc_loss = 0.09652360705925549
Trained batch 803 in epoch 2, gen_loss = 0.8110905656618859, disc_loss = 0.09657150058455728
Trained batch 804 in epoch 2, gen_loss = 0.8109881863090562, disc_loss = 0.09655894475138706
Trained batch 805 in epoch 2, gen_loss = 0.8107957961245743, disc_loss = 0.09654086880922022
Trained batch 806 in epoch 2, gen_loss = 0.8107809465023074, disc_loss = 0.09660343837819282
Trained batch 807 in epoch 2, gen_loss = 0.8107414160772125, disc_loss = 0.09652004346924623
Trained batch 808 in epoch 2, gen_loss = 0.8106863607729616, disc_loss = 0.0964421093192214
Trained batch 809 in epoch 2, gen_loss = 0.8111156996385551, disc_loss = 0.09638142151827062
Trained batch 810 in epoch 2, gen_loss = 0.8108475189908659, disc_loss = 0.09638275093319751
Trained batch 811 in epoch 2, gen_loss = 0.8109616473537361, disc_loss = 0.09634759362667726
Trained batch 812 in epoch 2, gen_loss = 0.8110251312326241, disc_loss = 0.09646031639205353
Trained batch 813 in epoch 2, gen_loss = 0.8107636833073759, disc_loss = 0.09647896959325093
Trained batch 814 in epoch 2, gen_loss = 0.810772547692609, disc_loss = 0.09642552229935772
Trained batch 815 in epoch 2, gen_loss = 0.8110281373648083, disc_loss = 0.09633905508363728
Trained batch 816 in epoch 2, gen_loss = 0.811257729842584, disc_loss = 0.0962804587149817
Trained batch 817 in epoch 2, gen_loss = 0.8113510250170831, disc_loss = 0.09620290360479526
Trained batch 818 in epoch 2, gen_loss = 0.8114987708564497, disc_loss = 0.09610932269184799
Trained batch 819 in epoch 2, gen_loss = 0.8115334461374981, disc_loss = 0.09608487214029926
Trained batch 820 in epoch 2, gen_loss = 0.8116566704338855, disc_loss = 0.09598576957666191
Trained batch 821 in epoch 2, gen_loss = 0.8119074733442924, disc_loss = 0.09588281087658919
Trained batch 822 in epoch 2, gen_loss = 0.811618027464008, disc_loss = 0.09599214765771698
Trained batch 823 in epoch 2, gen_loss = 0.8117798628303611, disc_loss = 0.09591698906728004
Trained batch 824 in epoch 2, gen_loss = 0.8118381031354268, disc_loss = 0.09583897156923106
Trained batch 825 in epoch 2, gen_loss = 0.8117015733412911, disc_loss = 0.0959170899414807
Trained batch 826 in epoch 2, gen_loss = 0.8123425880251081, disc_loss = 0.09592790758189945
Trained batch 827 in epoch 2, gen_loss = 0.8125120464730378, disc_loss = 0.09585713709205174
Trained batch 828 in epoch 2, gen_loss = 0.8124796160023807, disc_loss = 0.09580290769378512
Trained batch 829 in epoch 2, gen_loss = 0.8124031016625554, disc_loss = 0.09572492569729865
Trained batch 830 in epoch 2, gen_loss = 0.812402250606087, disc_loss = 0.09571881741330153
Trained batch 831 in epoch 2, gen_loss = 0.8125997342599126, disc_loss = 0.0956549621522964
Trained batch 832 in epoch 2, gen_loss = 0.8126344426768739, disc_loss = 0.09556198914592363
Trained batch 833 in epoch 2, gen_loss = 0.8126387462484465, disc_loss = 0.09551651135971434
Trained batch 834 in epoch 2, gen_loss = 0.8125777310240054, disc_loss = 0.09545408714183433
Trained batch 835 in epoch 2, gen_loss = 0.8125619888305664, disc_loss = 0.09542494000973956
Trained batch 836 in epoch 2, gen_loss = 0.8129196151325495, disc_loss = 0.09532923003927923
Trained batch 837 in epoch 2, gen_loss = 0.8128874616292894, disc_loss = 0.09527356578103825
Trained batch 838 in epoch 2, gen_loss = 0.8128765501055303, disc_loss = 0.09521245863621652
Trained batch 839 in epoch 2, gen_loss = 0.8128870529078301, disc_loss = 0.09529819825131979
Trained batch 840 in epoch 2, gen_loss = 0.8129090112539874, disc_loss = 0.0952063632949602
Trained batch 841 in epoch 2, gen_loss = 0.8127150548325581, disc_loss = 0.09516595987350882
Trained batch 842 in epoch 2, gen_loss = 0.8126861519519403, disc_loss = 0.09511313645096224
Trained batch 843 in epoch 2, gen_loss = 0.8132640365599456, disc_loss = 0.09512930149124203
Trained batch 844 in epoch 2, gen_loss = 0.8129438785406259, disc_loss = 0.09546817976033546
Trained batch 845 in epoch 2, gen_loss = 0.8134702589213143, disc_loss = 0.09542743387207142
Trained batch 846 in epoch 2, gen_loss = 0.8134976508625845, disc_loss = 0.0953464455168074
Trained batch 847 in epoch 2, gen_loss = 0.8136406705345748, disc_loss = 0.09524911041217768
Trained batch 848 in epoch 2, gen_loss = 0.8134479925685834, disc_loss = 0.09517758683322351
Trained batch 849 in epoch 2, gen_loss = 0.8137941350656397, disc_loss = 0.09527479144251522
Trained batch 850 in epoch 2, gen_loss = 0.813833042541486, disc_loss = 0.09521707830366216
Trained batch 851 in epoch 2, gen_loss = 0.8138907048763804, disc_loss = 0.09514967772449441
Trained batch 852 in epoch 2, gen_loss = 0.8138845483974443, disc_loss = 0.09505114035412303
Trained batch 853 in epoch 2, gen_loss = 0.8139807654488003, disc_loss = 0.0949745583893247
Trained batch 854 in epoch 2, gen_loss = 0.8139752719137404, disc_loss = 0.09496863496473484
Trained batch 855 in epoch 2, gen_loss = 0.8136414226109736, disc_loss = 0.09502775573593816
Trained batch 856 in epoch 2, gen_loss = 0.813596043592295, disc_loss = 0.09500057141480221
Trained batch 857 in epoch 2, gen_loss = 0.8137192950521038, disc_loss = 0.09501304884608357
Trained batch 858 in epoch 2, gen_loss = 0.8136190294664314, disc_loss = 0.0949562392614964
Trained batch 859 in epoch 2, gen_loss = 0.8133845073539158, disc_loss = 0.0950215276709736
Trained batch 860 in epoch 2, gen_loss = 0.8134895214220372, disc_loss = 0.09501177353219807
Trained batch 861 in epoch 2, gen_loss = 0.8132684994186437, disc_loss = 0.09497561448700985
Trained batch 862 in epoch 2, gen_loss = 0.81329390451502, disc_loss = 0.09489729295906676
Trained batch 863 in epoch 2, gen_loss = 0.8139500733189009, disc_loss = 0.09489802026116566
Trained batch 864 in epoch 2, gen_loss = 0.8137973820543014, disc_loss = 0.0948601556080528
Trained batch 865 in epoch 2, gen_loss = 0.8135942145665854, disc_loss = 0.09484467640256737
Trained batch 866 in epoch 2, gen_loss = 0.8136356950081206, disc_loss = 0.09499942667185057
Trained batch 867 in epoch 2, gen_loss = 0.8133931374906944, disc_loss = 0.09494431474254668
Trained batch 868 in epoch 2, gen_loss = 0.8130402814669768, disc_loss = 0.09517898136520517
Trained batch 869 in epoch 2, gen_loss = 0.813401249359394, disc_loss = 0.0951980900265619
Trained batch 870 in epoch 2, gen_loss = 0.8136290139363636, disc_loss = 0.0951736920922738
Trained batch 871 in epoch 2, gen_loss = 0.8138318661976298, disc_loss = 0.09510791979606238
Trained batch 872 in epoch 2, gen_loss = 0.8135367464636882, disc_loss = 0.09524191389732993
Trained batch 873 in epoch 2, gen_loss = 0.8136336921418014, disc_loss = 0.09516370761180531
Trained batch 874 in epoch 2, gen_loss = 0.8134541798319136, disc_loss = 0.09526052692213229
Trained batch 875 in epoch 2, gen_loss = 0.8129839453863227, disc_loss = 0.09534547494226837
Trained batch 876 in epoch 2, gen_loss = 0.8129344122779546, disc_loss = 0.09533221679957352
Trained batch 877 in epoch 2, gen_loss = 0.8127360409443906, disc_loss = 0.09530792430420841
Trained batch 878 in epoch 2, gen_loss = 0.8129460729226318, disc_loss = 0.09529910558798649
Trained batch 879 in epoch 2, gen_loss = 0.8127539880235087, disc_loss = 0.09523949532621455
Trained batch 880 in epoch 2, gen_loss = 0.8127662231310543, disc_loss = 0.09520839984453665
Trained batch 881 in epoch 2, gen_loss = 0.8125846131521017, disc_loss = 0.0952414629522652
Trained batch 882 in epoch 2, gen_loss = 0.8123427639933701, disc_loss = 0.09533410520310749
Trained batch 883 in epoch 2, gen_loss = 0.8124409273806201, disc_loss = 0.09532690355111739
Trained batch 884 in epoch 2, gen_loss = 0.8126165205139225, disc_loss = 0.09525566610512928
Trained batch 885 in epoch 2, gen_loss = 0.8125814854358712, disc_loss = 0.09524199116079486
Trained batch 886 in epoch 2, gen_loss = 0.8124370839375386, disc_loss = 0.09520741330466014
Trained batch 887 in epoch 2, gen_loss = 0.8125134960555278, disc_loss = 0.09513856058726339
Trained batch 888 in epoch 2, gen_loss = 0.8121611698204808, disc_loss = 0.09520105322921403
Trained batch 889 in epoch 2, gen_loss = 0.812512343016903, disc_loss = 0.09525317656127422
Trained batch 890 in epoch 2, gen_loss = 0.8124749666178133, disc_loss = 0.09519880185662596
Trained batch 891 in epoch 2, gen_loss = 0.8123763988437674, disc_loss = 0.09524475474165327
Trained batch 892 in epoch 2, gen_loss = 0.8124062006110441, disc_loss = 0.0951800694634923
Trained batch 893 in epoch 2, gen_loss = 0.8126818012671183, disc_loss = 0.09513882373540894
Trained batch 894 in epoch 2, gen_loss = 0.8128508759943467, disc_loss = 0.09506613123204621
Trained batch 895 in epoch 2, gen_loss = 0.8127647878136486, disc_loss = 0.09504473139220083
Trained batch 896 in epoch 2, gen_loss = 0.8125172742167975, disc_loss = 0.09503777951122559
Trained batch 897 in epoch 2, gen_loss = 0.8126361864911421, disc_loss = 0.09499608150855503
Trained batch 898 in epoch 2, gen_loss = 0.8128018911277359, disc_loss = 0.09500026204483428
Trained batch 899 in epoch 2, gen_loss = 0.812977207534843, disc_loss = 0.09499946573231784
Trained batch 900 in epoch 2, gen_loss = 0.8126770933050163, disc_loss = 0.0951288668170042
Trained batch 901 in epoch 2, gen_loss = 0.8129780069489172, disc_loss = 0.09504534258195374
Trained batch 902 in epoch 2, gen_loss = 0.8135191746394368, disc_loss = 0.09505324065994682
Trained batch 903 in epoch 2, gen_loss = 0.8137609997220272, disc_loss = 0.09496601810369773
Trained batch 904 in epoch 2, gen_loss = 0.8136620705628264, disc_loss = 0.09495872016378694
Trained batch 905 in epoch 2, gen_loss = 0.8139474228452109, disc_loss = 0.09488864141160717
Trained batch 906 in epoch 2, gen_loss = 0.8140647325586721, disc_loss = 0.09480058306842516
Trained batch 907 in epoch 2, gen_loss = 0.8139473873678809, disc_loss = 0.0947421535732643
Trained batch 908 in epoch 2, gen_loss = 0.8143442441986994, disc_loss = 0.09466111594124628
Trained batch 909 in epoch 2, gen_loss = 0.8146529014621462, disc_loss = 0.09458610723409187
Trained batch 910 in epoch 2, gen_loss = 0.8148085385659131, disc_loss = 0.09457309262031684
Trained batch 911 in epoch 2, gen_loss = 0.8146955385608109, disc_loss = 0.09449007548085463
Trained batch 912 in epoch 2, gen_loss = 0.8147340313432512, disc_loss = 0.09440474390171608
Trained batch 913 in epoch 2, gen_loss = 0.8148280769847415, disc_loss = 0.09435850030618273
Trained batch 914 in epoch 2, gen_loss = 0.815014472261804, disc_loss = 0.09434489273247335
Trained batch 915 in epoch 2, gen_loss = 0.8149061386176593, disc_loss = 0.09432776017809961
Trained batch 916 in epoch 2, gen_loss = 0.8149667582114104, disc_loss = 0.09434392067706344
Trained batch 917 in epoch 2, gen_loss = 0.8152186187848546, disc_loss = 0.09452971937094282
Trained batch 918 in epoch 2, gen_loss = 0.8149338782611947, disc_loss = 0.09457076765836031
Trained batch 919 in epoch 2, gen_loss = 0.8146070499459038, disc_loss = 0.09480283590053896
Trained batch 920 in epoch 2, gen_loss = 0.8151128461319512, disc_loss = 0.09494152971837633
Trained batch 921 in epoch 2, gen_loss = 0.8152107934825074, disc_loss = 0.09488613764632194
Trained batch 922 in epoch 2, gen_loss = 0.8152594989647973, disc_loss = 0.09485827980589279
Trained batch 923 in epoch 2, gen_loss = 0.8152161507960006, disc_loss = 0.09490315862971628
Trained batch 924 in epoch 2, gen_loss = 0.8153388780194359, disc_loss = 0.09496048610053352
Trained batch 925 in epoch 2, gen_loss = 0.8152097484527345, disc_loss = 0.09492030446206423
Trained batch 926 in epoch 2, gen_loss = 0.8150895756489508, disc_loss = 0.09485696935011506
Trained batch 927 in epoch 2, gen_loss = 0.8151870358028802, disc_loss = 0.09483219645134623
Trained batch 928 in epoch 2, gen_loss = 0.8153122951255548, disc_loss = 0.09483514662503202
Trained batch 929 in epoch 2, gen_loss = 0.8151625430391681, disc_loss = 0.09485968327830716
Trained batch 930 in epoch 2, gen_loss = 0.8152554375464627, disc_loss = 0.09487059167921383
Trained batch 931 in epoch 2, gen_loss = 0.8151987171671933, disc_loss = 0.09488706456701164
Trained batch 932 in epoch 2, gen_loss = 0.8151094471079487, disc_loss = 0.09489435735003901
Trained batch 933 in epoch 2, gen_loss = 0.8150409611632022, disc_loss = 0.09488781300379358
Trained batch 934 in epoch 2, gen_loss = 0.8153412388926521, disc_loss = 0.09489067597364519
Trained batch 935 in epoch 2, gen_loss = 0.8151797159041605, disc_loss = 0.09485568578701276
Trained batch 936 in epoch 2, gen_loss = 0.8158401114391034, disc_loss = 0.09489649942635758
Trained batch 937 in epoch 2, gen_loss = 0.8155923518481285, disc_loss = 0.09499452868079357
Trained batch 938 in epoch 2, gen_loss = 0.8155519012381601, disc_loss = 0.09495792890322634
Trained batch 939 in epoch 2, gen_loss = 0.8156959660192753, disc_loss = 0.09493294640523481
Trained batch 940 in epoch 2, gen_loss = 0.8157904176288913, disc_loss = 0.09486072869252861
Trained batch 941 in epoch 2, gen_loss = 0.8159722015419837, disc_loss = 0.09485940275429065
Trained batch 942 in epoch 2, gen_loss = 0.8159566173687467, disc_loss = 0.09480251445437951
Trained batch 943 in epoch 2, gen_loss = 0.8160422339846017, disc_loss = 0.09474408587192233
Trained batch 944 in epoch 2, gen_loss = 0.8156857894841956, disc_loss = 0.09489131924750471
Trained batch 945 in epoch 2, gen_loss = 0.815328998747134, disc_loss = 0.09493188949175825
Trained batch 946 in epoch 2, gen_loss = 0.81502058664622, disc_loss = 0.09497818966133573
Trained batch 947 in epoch 2, gen_loss = 0.8151551429103698, disc_loss = 0.09490608128538269
Trained batch 948 in epoch 2, gen_loss = 0.8153353257475713, disc_loss = 0.09490874914591789
Trained batch 949 in epoch 2, gen_loss = 0.8150168079451511, disc_loss = 0.09493441432028224
Trained batch 950 in epoch 2, gen_loss = 0.8149304647550975, disc_loss = 0.09487647429739295
Trained batch 951 in epoch 2, gen_loss = 0.8147230082575012, disc_loss = 0.09490892374516316
Trained batch 952 in epoch 2, gen_loss = 0.8148799877602055, disc_loss = 0.09496098649390003
Trained batch 953 in epoch 2, gen_loss = 0.8147803301956169, disc_loss = 0.09492487207043378
Trained batch 954 in epoch 2, gen_loss = 0.8146140367572844, disc_loss = 0.09494252550215777
Trained batch 955 in epoch 2, gen_loss = 0.8146223520634065, disc_loss = 0.09489775875439112
Trained batch 956 in epoch 2, gen_loss = 0.8146719217549546, disc_loss = 0.09492232236435079
Trained batch 957 in epoch 2, gen_loss = 0.814909024751261, disc_loss = 0.0948614635376458
Trained batch 958 in epoch 2, gen_loss = 0.8146664461080175, disc_loss = 0.09497903963420792
Trained batch 959 in epoch 2, gen_loss = 0.8145981647074223, disc_loss = 0.09498025289212819
Trained batch 960 in epoch 2, gen_loss = 0.8146986292750729, disc_loss = 0.09493206442274642
Trained batch 961 in epoch 2, gen_loss = 0.8152610774843212, disc_loss = 0.0948838119611934
Trained batch 962 in epoch 2, gen_loss = 0.8152440168652084, disc_loss = 0.09490023770099767
Trained batch 963 in epoch 2, gen_loss = 0.8150897105205108, disc_loss = 0.09491605923078274
Trained batch 964 in epoch 2, gen_loss = 0.8151809138955229, disc_loss = 0.09487010678807226
Trained batch 965 in epoch 2, gen_loss = 0.8153191129860177, disc_loss = 0.09482269821395446
Trained batch 966 in epoch 2, gen_loss = 0.8153856298053154, disc_loss = 0.09478101637137373
Trained batch 967 in epoch 2, gen_loss = 0.8151374543624476, disc_loss = 0.0948056565060796
Trained batch 968 in epoch 2, gen_loss = 0.8150529273400243, disc_loss = 0.09477229585623133
Trained batch 969 in epoch 2, gen_loss = 0.8150900043163103, disc_loss = 0.09474295455405546
Trained batch 970 in epoch 2, gen_loss = 0.815439501579709, disc_loss = 0.09473831960154519
Trained batch 971 in epoch 2, gen_loss = 0.8156347528651908, disc_loss = 0.09472063938136607
Trained batch 972 in epoch 2, gen_loss = 0.81586450724293, disc_loss = 0.09463983863680207
Trained batch 973 in epoch 2, gen_loss = 0.8157542524151733, disc_loss = 0.09478459123893042
Trained batch 974 in epoch 2, gen_loss = 0.8154864637056987, disc_loss = 0.09484243499067349
Trained batch 975 in epoch 2, gen_loss = 0.8158259766145808, disc_loss = 0.09500060493763933
Trained batch 976 in epoch 2, gen_loss = 0.8159608108238408, disc_loss = 0.09500960303239807
Trained batch 977 in epoch 2, gen_loss = 0.8156837278592318, disc_loss = 0.09503105370297357
Trained batch 978 in epoch 2, gen_loss = 0.8156529296649976, disc_loss = 0.09504652375581772
Trained batch 979 in epoch 2, gen_loss = 0.8155811801248667, disc_loss = 0.09499052996291038
Trained batch 980 in epoch 2, gen_loss = 0.8152929504347868, disc_loss = 0.09500906352811966
Trained batch 981 in epoch 2, gen_loss = 0.8151746947022417, disc_loss = 0.09495323839030265
Trained batch 982 in epoch 2, gen_loss = 0.8146873643415263, disc_loss = 0.09503625653445387
Trained batch 983 in epoch 2, gen_loss = 0.8147468115619527, disc_loss = 0.0952509784327093
Trained batch 984 in epoch 2, gen_loss = 0.8145312711672129, disc_loss = 0.0953041552315433
Trained batch 985 in epoch 2, gen_loss = 0.8145496773308721, disc_loss = 0.09525970426911363
Trained batch 986 in epoch 2, gen_loss = 0.8143638564460546, disc_loss = 0.09526734568061648
Trained batch 987 in epoch 2, gen_loss = 0.8142506378864952, disc_loss = 0.09530429848892094
Trained batch 988 in epoch 2, gen_loss = 0.8143830893615861, disc_loss = 0.09532124665824751
Trained batch 989 in epoch 2, gen_loss = 0.8142489793324711, disc_loss = 0.09544213873174305
Trained batch 990 in epoch 2, gen_loss = 0.8140866998225962, disc_loss = 0.0953921757546356
Trained batch 991 in epoch 2, gen_loss = 0.8137769467167316, disc_loss = 0.09575737274398337
Trained batch 992 in epoch 2, gen_loss = 0.8137407798061198, disc_loss = 0.09580655570713145
Trained batch 993 in epoch 2, gen_loss = 0.8137798095253151, disc_loss = 0.09607480402559912
Trained batch 994 in epoch 2, gen_loss = 0.8137870049955856, disc_loss = 0.09606266959883909
Trained batch 995 in epoch 2, gen_loss = 0.8135235410737225, disc_loss = 0.09613039602533013
Trained batch 996 in epoch 2, gen_loss = 0.8135721102999589, disc_loss = 0.0960909067648449
Trained batch 997 in epoch 2, gen_loss = 0.8135003140550816, disc_loss = 0.096146418628113
Trained batch 998 in epoch 2, gen_loss = 0.8134788854702099, disc_loss = 0.09611143389095862
Trained batch 999 in epoch 2, gen_loss = 0.8136612578630448, disc_loss = 0.09609050428401679
Trained batch 1000 in epoch 2, gen_loss = 0.8134699348326806, disc_loss = 0.09619282002464964
Trained batch 1001 in epoch 2, gen_loss = 0.8133297305621073, disc_loss = 0.09619931242672239
Trained batch 1002 in epoch 2, gen_loss = 0.8133886523641356, disc_loss = 0.09621296828503118
Trained batch 1003 in epoch 2, gen_loss = 0.813143524100106, disc_loss = 0.096274290258896
Trained batch 1004 in epoch 2, gen_loss = 0.813103915802875, disc_loss = 0.09638973592655427
Trained batch 1005 in epoch 2, gen_loss = 0.812614488850531, disc_loss = 0.09653039693843507
Trained batch 1006 in epoch 2, gen_loss = 0.8123481796301584, disc_loss = 0.09660180451213396
Trained batch 1007 in epoch 2, gen_loss = 0.8121217263951188, disc_loss = 0.09655287519137981
Trained batch 1008 in epoch 2, gen_loss = 0.8120864902071957, disc_loss = 0.09676976772477505
Trained batch 1009 in epoch 2, gen_loss = 0.8120986929624388, disc_loss = 0.0967601554403727
Trained batch 1010 in epoch 2, gen_loss = 0.8121413961716151, disc_loss = 0.09670464268818306
Trained batch 1011 in epoch 2, gen_loss = 0.8120391170380143, disc_loss = 0.09668620024520624
Trained batch 1012 in epoch 2, gen_loss = 0.8120796313878932, disc_loss = 0.09664824906817517
Trained batch 1013 in epoch 2, gen_loss = 0.8121052752937791, disc_loss = 0.09657703723144925
Trained batch 1014 in epoch 2, gen_loss = 0.8122957763413491, disc_loss = 0.09652630820631834
Trained batch 1015 in epoch 2, gen_loss = 0.8119927373692746, disc_loss = 0.0965845199754667
Trained batch 1016 in epoch 2, gen_loss = 0.8118532205049971, disc_loss = 0.09658819692247825
Trained batch 1017 in epoch 2, gen_loss = 0.8118100605451288, disc_loss = 0.09658002796581049
Trained batch 1018 in epoch 2, gen_loss = 0.8115550534647978, disc_loss = 0.09661625508745443
Trained batch 1019 in epoch 2, gen_loss = 0.8112623435609481, disc_loss = 0.09666187237564694
Trained batch 1020 in epoch 2, gen_loss = 0.8114357144078358, disc_loss = 0.0967810034604121
Trained batch 1021 in epoch 2, gen_loss = 0.8112087169272092, disc_loss = 0.09679880005137999
Trained batch 1022 in epoch 2, gen_loss = 0.8110336911293768, disc_loss = 0.09674211309900468
Trained batch 1023 in epoch 2, gen_loss = 0.8110917674493976, disc_loss = 0.09669142701659439
Trained batch 1024 in epoch 2, gen_loss = 0.8110230846521331, disc_loss = 0.0966427719947405
Trained batch 1025 in epoch 2, gen_loss = 0.8109539188952939, disc_loss = 0.09659144357046508
Trained batch 1026 in epoch 2, gen_loss = 0.8109812313997293, disc_loss = 0.09655782410524924
Trained batch 1027 in epoch 2, gen_loss = 0.8110664960591246, disc_loss = 0.09668086947427504
Trained batch 1028 in epoch 2, gen_loss = 0.8108248382198567, disc_loss = 0.09677704592281546
Trained batch 1029 in epoch 2, gen_loss = 0.8107165933234021, disc_loss = 0.09674814328894887
Trained batch 1030 in epoch 2, gen_loss = 0.8105251493671355, disc_loss = 0.09672764455944763
Trained batch 1031 in epoch 2, gen_loss = 0.8108183464916178, disc_loss = 0.09670724869839298
Trained batch 1032 in epoch 2, gen_loss = 0.8107293644579198, disc_loss = 0.09672039971458803
Trained batch 1033 in epoch 2, gen_loss = 0.8110325330691827, disc_loss = 0.09666254780952399
Trained batch 1034 in epoch 2, gen_loss = 0.8108782815472515, disc_loss = 0.09682523569605057
Trained batch 1035 in epoch 2, gen_loss = 0.8112157492333858, disc_loss = 0.09682598500332748
Trained batch 1036 in epoch 2, gen_loss = 0.8109474902327748, disc_loss = 0.09693708051922897
Trained batch 1037 in epoch 2, gen_loss = 0.8113277960489711, disc_loss = 0.0969132274732008
Trained batch 1038 in epoch 2, gen_loss = 0.8113773177746285, disc_loss = 0.09691195832018644
Trained batch 1039 in epoch 2, gen_loss = 0.8114659170691784, disc_loss = 0.09684592158838104
Trained batch 1040 in epoch 2, gen_loss = 0.8114806630082364, disc_loss = 0.09678986927764589
Trained batch 1041 in epoch 2, gen_loss = 0.8113613969533777, disc_loss = 0.09676903530672878
Trained batch 1042 in epoch 2, gen_loss = 0.81134422079143, disc_loss = 0.09669592397864318
Trained batch 1043 in epoch 2, gen_loss = 0.8114887770565077, disc_loss = 0.09667496399515062
Trained batch 1044 in epoch 2, gen_loss = 0.8117841069207807, disc_loss = 0.09667973302251272
Trained batch 1045 in epoch 2, gen_loss = 0.811536614970085, disc_loss = 0.09684544090042692
Trained batch 1046 in epoch 2, gen_loss = 0.8114569063628414, disc_loss = 0.09682175321299885
Trained batch 1047 in epoch 2, gen_loss = 0.8116469543057544, disc_loss = 0.09694328789602795
Trained batch 1048 in epoch 2, gen_loss = 0.8114021637532913, disc_loss = 0.09697042735785359
Trained batch 1049 in epoch 2, gen_loss = 0.8116535048825401, disc_loss = 0.09696501369898518
Trained batch 1050 in epoch 2, gen_loss = 0.8119146783617311, disc_loss = 0.09693283474889826
Trained batch 1051 in epoch 2, gen_loss = 0.8117981964984321, disc_loss = 0.09692805176760165
Trained batch 1052 in epoch 2, gen_loss = 0.8117280938120423, disc_loss = 0.0968791550973471
Trained batch 1053 in epoch 2, gen_loss = 0.8115105007472934, disc_loss = 0.0968858264978671
Trained batch 1054 in epoch 2, gen_loss = 0.8115272747396858, disc_loss = 0.09682525365185257
Trained batch 1055 in epoch 2, gen_loss = 0.8115317631851543, disc_loss = 0.09676097034720112
Trained batch 1056 in epoch 2, gen_loss = 0.8115548388283548, disc_loss = 0.0967061436244321
Trained batch 1057 in epoch 2, gen_loss = 0.8114802611460081, disc_loss = 0.0966636152534846
Trained batch 1058 in epoch 2, gen_loss = 0.8113873727598542, disc_loss = 0.0966343221257285
Trained batch 1059 in epoch 2, gen_loss = 0.8115484696514201, disc_loss = 0.09657837701170653
Trained batch 1060 in epoch 2, gen_loss = 0.8117845539323122, disc_loss = 0.09650685787850484
Trained batch 1061 in epoch 2, gen_loss = 0.8118305521159522, disc_loss = 0.09644775228441575
Trained batch 1062 in epoch 2, gen_loss = 0.8119516046901749, disc_loss = 0.09640961570484759
Trained batch 1063 in epoch 2, gen_loss = 0.8116382063275441, disc_loss = 0.09650824454707563
Trained batch 1064 in epoch 2, gen_loss = 0.8117105342692612, disc_loss = 0.09642901744588579
Trained batch 1065 in epoch 2, gen_loss = 0.811729541387388, disc_loss = 0.09637201853589229
Trained batch 1066 in epoch 2, gen_loss = 0.811850293144067, disc_loss = 0.09644015110425141
Trained batch 1067 in epoch 2, gen_loss = 0.8115032761730951, disc_loss = 0.09656431687183065
Trained batch 1068 in epoch 2, gen_loss = 0.8113560589593186, disc_loss = 0.09670494085001795
Trained batch 1069 in epoch 2, gen_loss = 0.8115872115732353, disc_loss = 0.09663860480797207
Trained batch 1070 in epoch 2, gen_loss = 0.8117865801525384, disc_loss = 0.09667850709863765
Trained batch 1071 in epoch 2, gen_loss = 0.811544104298549, disc_loss = 0.09667940024693093
Trained batch 1072 in epoch 2, gen_loss = 0.8116859952534679, disc_loss = 0.09661690011283752
Trained batch 1073 in epoch 2, gen_loss = 0.8115516182874613, disc_loss = 0.09660959168418798
Trained batch 1074 in epoch 2, gen_loss = 0.8113185733418132, disc_loss = 0.09659478333367165
Trained batch 1075 in epoch 2, gen_loss = 0.811180566157107, disc_loss = 0.09659121911470747
Trained batch 1076 in epoch 2, gen_loss = 0.8112615648529102, disc_loss = 0.09651302558023175
Trained batch 1077 in epoch 2, gen_loss = 0.8111678779346381, disc_loss = 0.09649605013720401
Trained batch 1078 in epoch 2, gen_loss = 0.8112937667725593, disc_loss = 0.09651043393111428
Trained batch 1079 in epoch 2, gen_loss = 0.8111470836732123, disc_loss = 0.09647298944010227
Trained batch 1080 in epoch 2, gen_loss = 0.811176161871918, disc_loss = 0.09643189266847858
Trained batch 1081 in epoch 2, gen_loss = 0.8109939951112222, disc_loss = 0.09645560942590237
Trained batch 1082 in epoch 2, gen_loss = 0.8112080804969245, disc_loss = 0.09639596019631608
Trained batch 1083 in epoch 2, gen_loss = 0.8111796180040634, disc_loss = 0.09634934175360907
Trained batch 1084 in epoch 2, gen_loss = 0.8111108302520716, disc_loss = 0.09635570271086583
Trained batch 1085 in epoch 2, gen_loss = 0.811344834048006, disc_loss = 0.09628135067604578
Trained batch 1086 in epoch 2, gen_loss = 0.8115633699251296, disc_loss = 0.09624944092824082
Trained batch 1087 in epoch 2, gen_loss = 0.8113003242760897, disc_loss = 0.09641853132565945
Trained batch 1088 in epoch 2, gen_loss = 0.8114186513303506, disc_loss = 0.09642591681314291
Trained batch 1089 in epoch 2, gen_loss = 0.8114775736944391, disc_loss = 0.09644514450273656
Trained batch 1090 in epoch 2, gen_loss = 0.8112514100962008, disc_loss = 0.09650108326946946
Trained batch 1091 in epoch 2, gen_loss = 0.811198740760922, disc_loss = 0.09648755448102787
Trained batch 1092 in epoch 2, gen_loss = 0.8112818058324537, disc_loss = 0.09641635955429798
Trained batch 1093 in epoch 2, gen_loss = 0.8112604599548214, disc_loss = 0.09636752123874655
Trained batch 1094 in epoch 2, gen_loss = 0.8112877382535368, disc_loss = 0.09631079551359834
Trained batch 1095 in epoch 2, gen_loss = 0.811188718317634, disc_loss = 0.09625675547256196
Trained batch 1096 in epoch 2, gen_loss = 0.8114458135071948, disc_loss = 0.09619135159656148
Trained batch 1097 in epoch 2, gen_loss = 0.8114103135841141, disc_loss = 0.09611732359697367
Trained batch 1098 in epoch 2, gen_loss = 0.8116666012942737, disc_loss = 0.0960561033097639
Trained batch 1099 in epoch 2, gen_loss = 0.8115309945019809, disc_loss = 0.09604617679322308
Trained batch 1100 in epoch 2, gen_loss = 0.8113153140508078, disc_loss = 0.09610542480061533
Trained batch 1101 in epoch 2, gen_loss = 0.8116525350486734, disc_loss = 0.0961671722123227
Trained batch 1102 in epoch 2, gen_loss = 0.8118497867640428, disc_loss = 0.09616931551157186
Trained batch 1103 in epoch 2, gen_loss = 0.811635537477939, disc_loss = 0.09631511798141983
Trained batch 1104 in epoch 2, gen_loss = 0.8118705310972567, disc_loss = 0.09625945571995428
Trained batch 1105 in epoch 2, gen_loss = 0.8121555948235889, disc_loss = 0.09621551228016885
Trained batch 1106 in epoch 2, gen_loss = 0.8121520268992465, disc_loss = 0.09623477686038401
Trained batch 1107 in epoch 2, gen_loss = 0.8118528314876212, disc_loss = 0.09623639170578026
Trained batch 1108 in epoch 2, gen_loss = 0.8117275350904336, disc_loss = 0.096215241906931
Trained batch 1109 in epoch 2, gen_loss = 0.8122048401617789, disc_loss = 0.09623692266575926
Trained batch 1110 in epoch 2, gen_loss = 0.8124309221331222, disc_loss = 0.09616967502220271
Trained batch 1111 in epoch 2, gen_loss = 0.8124327105369499, disc_loss = 0.0961092914782947
Trained batch 1112 in epoch 2, gen_loss = 0.8125561173714074, disc_loss = 0.09603588458448514
Trained batch 1113 in epoch 2, gen_loss = 0.8125206366903692, disc_loss = 0.09598479640655072
Trained batch 1114 in epoch 2, gen_loss = 0.8126166468778533, disc_loss = 0.09590892494225983
Trained batch 1115 in epoch 2, gen_loss = 0.8127935153822745, disc_loss = 0.09590231592343006
Trained batch 1116 in epoch 2, gen_loss = 0.8127493639555805, disc_loss = 0.0958577335237683
Trained batch 1117 in epoch 2, gen_loss = 0.8127201037458103, disc_loss = 0.09586463522579194
Trained batch 1118 in epoch 2, gen_loss = 0.812941306291466, disc_loss = 0.0958415931198909
Trained batch 1119 in epoch 2, gen_loss = 0.812830808066896, disc_loss = 0.09580319952386032
Trained batch 1120 in epoch 2, gen_loss = 0.8129471985491975, disc_loss = 0.09575886840796652
Trained batch 1121 in epoch 2, gen_loss = 0.8126618752186311, disc_loss = 0.09572307941621691
Trained batch 1122 in epoch 2, gen_loss = 0.8126516846387597, disc_loss = 0.09566989514349776
Trained batch 1123 in epoch 2, gen_loss = 0.8126789937558123, disc_loss = 0.09561613378913748
Trained batch 1124 in epoch 2, gen_loss = 0.8125406316651238, disc_loss = 0.09557982599569692
Trained batch 1125 in epoch 2, gen_loss = 0.8126986589990755, disc_loss = 0.09552534578159637
Trained batch 1126 in epoch 2, gen_loss = 0.8128730231084544, disc_loss = 0.09545264438045903
Trained batch 1127 in epoch 2, gen_loss = 0.8126567695157748, disc_loss = 0.09544870547342596
Trained batch 1128 in epoch 2, gen_loss = 0.8127708143106702, disc_loss = 0.09537425465911521
Trained batch 1129 in epoch 2, gen_loss = 0.8129309104079694, disc_loss = 0.09537262428898068
Trained batch 1130 in epoch 2, gen_loss = 0.81323598070971, disc_loss = 0.09532767959074122
Trained batch 1131 in epoch 2, gen_loss = 0.8130972624456925, disc_loss = 0.09531942641036749
Trained batch 1132 in epoch 2, gen_loss = 0.8130786560429795, disc_loss = 0.09528967509225392
Trained batch 1133 in epoch 2, gen_loss = 0.8129281580868642, disc_loss = 0.09525719611466955
Trained batch 1134 in epoch 2, gen_loss = 0.8132692885818985, disc_loss = 0.09523307525425624
Trained batch 1135 in epoch 2, gen_loss = 0.8133406595025264, disc_loss = 0.09516972779791513
Trained batch 1136 in epoch 2, gen_loss = 0.8135659666363356, disc_loss = 0.09509837654850911
Trained batch 1137 in epoch 2, gen_loss = 0.8134417080292593, disc_loss = 0.09517759402807939
Trained batch 1138 in epoch 2, gen_loss = 0.8136239253815273, disc_loss = 0.09521683729952815
Trained batch 1139 in epoch 2, gen_loss = 0.8134775599889588, disc_loss = 0.09516000441733029
Trained batch 1140 in epoch 2, gen_loss = 0.8132567832492925, disc_loss = 0.09511376147409027
Trained batch 1141 in epoch 2, gen_loss = 0.8133450005914618, disc_loss = 0.09507356797330303
Trained batch 1142 in epoch 2, gen_loss = 0.8131659034564634, disc_loss = 0.09505008419116834
Trained batch 1143 in epoch 2, gen_loss = 0.8130302415131689, disc_loss = 0.09507839022109846
Trained batch 1144 in epoch 2, gen_loss = 0.8130104681810437, disc_loss = 0.09502697502990867
Trained batch 1145 in epoch 2, gen_loss = 0.813179807461161, disc_loss = 0.09502107943172516
Trained batch 1146 in epoch 2, gen_loss = 0.8133213595919954, disc_loss = 0.09496679982542341
Trained batch 1147 in epoch 2, gen_loss = 0.8131077156145814, disc_loss = 0.09500317258568876
Trained batch 1148 in epoch 2, gen_loss = 0.8132437574956809, disc_loss = 0.09493610713131616
Trained batch 1149 in epoch 2, gen_loss = 0.8131376842312191, disc_loss = 0.09496732173001636
Trained batch 1150 in epoch 2, gen_loss = 0.8130285844504574, disc_loss = 0.09497030286100587
Trained batch 1151 in epoch 2, gen_loss = 0.8130972826749914, disc_loss = 0.0949545832271623
Trained batch 1152 in epoch 2, gen_loss = 0.8133668606423959, disc_loss = 0.09489465602863409
Trained batch 1153 in epoch 2, gen_loss = 0.8131902246789254, disc_loss = 0.09494493308152674
Trained batch 1154 in epoch 2, gen_loss = 0.8134695827186882, disc_loss = 0.09488308138709951
Trained batch 1155 in epoch 2, gen_loss = 0.8135058201308069, disc_loss = 0.09481652026792994
Trained batch 1156 in epoch 2, gen_loss = 0.8136116945238698, disc_loss = 0.09475336093036982
Trained batch 1157 in epoch 2, gen_loss = 0.8136070881276962, disc_loss = 0.09469510677523126
Trained batch 1158 in epoch 2, gen_loss = 0.8135652808509478, disc_loss = 0.0947330761805331
Trained batch 1159 in epoch 2, gen_loss = 0.8135424571818319, disc_loss = 0.0946679556798511
Trained batch 1160 in epoch 2, gen_loss = 0.8135315741474108, disc_loss = 0.09468396083659571
Trained batch 1161 in epoch 2, gen_loss = 0.8138728800410864, disc_loss = 0.09466709740854248
Trained batch 1162 in epoch 2, gen_loss = 0.8137410561892869, disc_loss = 0.09474051719321609
Trained batch 1163 in epoch 2, gen_loss = 0.8136238474206826, disc_loss = 0.0947063296570849
Trained batch 1164 in epoch 2, gen_loss = 0.8139496842167409, disc_loss = 0.09471814004632409
Trained batch 1165 in epoch 2, gen_loss = 0.8139740464311113, disc_loss = 0.09466567837695494
Trained batch 1166 in epoch 2, gen_loss = 0.813930310698381, disc_loss = 0.09462368443860468
Trained batch 1167 in epoch 2, gen_loss = 0.814079479301629, disc_loss = 0.09455153027275093
Trained batch 1168 in epoch 2, gen_loss = 0.8144807119059502, disc_loss = 0.09454061333297205
Trained batch 1169 in epoch 2, gen_loss = 0.8144525970149245, disc_loss = 0.09451242722730097
Trained batch 1170 in epoch 2, gen_loss = 0.8143217583989405, disc_loss = 0.09446698870513044
Trained batch 1171 in epoch 2, gen_loss = 0.8142652062018984, disc_loss = 0.09443085159273634
Trained batch 1172 in epoch 2, gen_loss = 0.8145290854032082, disc_loss = 0.09450449259556315
Trained batch 1173 in epoch 2, gen_loss = 0.8142619279214837, disc_loss = 0.09452943492909256
Trained batch 1174 in epoch 2, gen_loss = 0.814121276774305, disc_loss = 0.09454512086795999
Trained batch 1175 in epoch 2, gen_loss = 0.8141231066515656, disc_loss = 0.09454540365223525
Trained batch 1176 in epoch 2, gen_loss = 0.813880596559941, disc_loss = 0.0946059059541587
Trained batch 1177 in epoch 2, gen_loss = 0.8141721781020659, disc_loss = 0.09459231233347606
Trained batch 1178 in epoch 2, gen_loss = 0.8142972801882297, disc_loss = 0.09465304422614886
Trained batch 1179 in epoch 2, gen_loss = 0.8143397425696001, disc_loss = 0.094653563698659
Trained batch 1180 in epoch 2, gen_loss = 0.8140025628410488, disc_loss = 0.0948185941833722
Trained batch 1181 in epoch 2, gen_loss = 0.8139251103961932, disc_loss = 0.09482298164065871
Trained batch 1182 in epoch 2, gen_loss = 0.8142643230301994, disc_loss = 0.09479731879813481
Trained batch 1183 in epoch 2, gen_loss = 0.8141330529407069, disc_loss = 0.09476047235924902
Trained batch 1184 in epoch 2, gen_loss = 0.8141013929612526, disc_loss = 0.09478609030162484
Trained batch 1185 in epoch 2, gen_loss = 0.8140536009963809, disc_loss = 0.09479867690988827
Trained batch 1186 in epoch 2, gen_loss = 0.8140972893882822, disc_loss = 0.09478276156566931
Trained batch 1187 in epoch 2, gen_loss = 0.8140987085573601, disc_loss = 0.0947264001723567
Trained batch 1188 in epoch 2, gen_loss = 0.8142993842181887, disc_loss = 0.09477964209516425
Trained batch 1189 in epoch 2, gen_loss = 0.8142135453825238, disc_loss = 0.09475741539025256
Trained batch 1190 in epoch 2, gen_loss = 0.8139473116267738, disc_loss = 0.09474193011226772
Trained batch 1191 in epoch 2, gen_loss = 0.8142482155821468, disc_loss = 0.09483881619596392
Trained batch 1192 in epoch 2, gen_loss = 0.8143024056375476, disc_loss = 0.09489264059889896
Trained batch 1193 in epoch 2, gen_loss = 0.8144403534318934, disc_loss = 0.09484189192622501
Trained batch 1194 in epoch 2, gen_loss = 0.8144526042698816, disc_loss = 0.09477457775262858
Trained batch 1195 in epoch 2, gen_loss = 0.8145117684949601, disc_loss = 0.09471935549451904
Trained batch 1196 in epoch 2, gen_loss = 0.8144409783999922, disc_loss = 0.09468911226400009
Trained batch 1197 in epoch 2, gen_loss = 0.8145325031622821, disc_loss = 0.09463094697428714
Trained batch 1198 in epoch 2, gen_loss = 0.8145218566619326, disc_loss = 0.09463234819484265
Trained batch 1199 in epoch 2, gen_loss = 0.8145441587766011, disc_loss = 0.09465687721502036
Trained batch 1200 in epoch 2, gen_loss = 0.8144720469188135, disc_loss = 0.09464382171959652
Trained batch 1201 in epoch 2, gen_loss = 0.814646619826109, disc_loss = 0.09464719607192595
Trained batch 1202 in epoch 2, gen_loss = 0.8148608656595473, disc_loss = 0.0946349215369396
Trained batch 1203 in epoch 2, gen_loss = 0.8145932936391165, disc_loss = 0.0946446245434103
Trained batch 1204 in epoch 2, gen_loss = 0.8146724691034847, disc_loss = 0.09458687605328579
Trained batch 1205 in epoch 2, gen_loss = 0.8145385483406472, disc_loss = 0.09460773548207077
Trained batch 1206 in epoch 2, gen_loss = 0.8146757799530188, disc_loss = 0.09465607674213708
Trained batch 1207 in epoch 2, gen_loss = 0.8148912724773616, disc_loss = 0.09458590361030636
Trained batch 1208 in epoch 2, gen_loss = 0.814873566599894, disc_loss = 0.09459201747981402
Trained batch 1209 in epoch 2, gen_loss = 0.8147470758966178, disc_loss = 0.09456347867015226
Trained batch 1210 in epoch 2, gen_loss = 0.814971300809468, disc_loss = 0.0945157022449987
Trained batch 1211 in epoch 2, gen_loss = 0.8148863384924313, disc_loss = 0.09452731778734538
Trained batch 1212 in epoch 2, gen_loss = 0.8149200984985496, disc_loss = 0.0944640966361083
Trained batch 1213 in epoch 2, gen_loss = 0.8149144282745568, disc_loss = 0.09442264653122455
Trained batch 1214 in epoch 2, gen_loss = 0.8147889647954776, disc_loss = 0.0944412436152314
Trained batch 1215 in epoch 2, gen_loss = 0.8146999139632833, disc_loss = 0.09442049848363049
Trained batch 1216 in epoch 2, gen_loss = 0.8147841749763332, disc_loss = 0.09448365382421624
Trained batch 1217 in epoch 2, gen_loss = 0.8146612886920547, disc_loss = 0.09452205484240563
Trained batch 1218 in epoch 2, gen_loss = 0.8147366692337275, disc_loss = 0.09454461907275737
Trained batch 1219 in epoch 2, gen_loss = 0.8145905427268294, disc_loss = 0.09452155593507847
Trained batch 1220 in epoch 2, gen_loss = 0.8146832277304222, disc_loss = 0.09449747719944597
Trained batch 1221 in epoch 2, gen_loss = 0.8146859338650336, disc_loss = 0.09444158135741071
Trained batch 1222 in epoch 2, gen_loss = 0.8147052665372804, disc_loss = 0.09440879976850548
Trained batch 1223 in epoch 2, gen_loss = 0.8145776580459152, disc_loss = 0.09438103554752089
Trained batch 1224 in epoch 2, gen_loss = 0.814443217491617, disc_loss = 0.09434732507230068
Trained batch 1225 in epoch 2, gen_loss = 0.8145711399602656, disc_loss = 0.0943094906769389
Trained batch 1226 in epoch 2, gen_loss = 0.814796862508965, disc_loss = 0.09425077101894287
Trained batch 1227 in epoch 2, gen_loss = 0.8148511440920907, disc_loss = 0.094198314932627
Trained batch 1228 in epoch 2, gen_loss = 0.8146276224231798, disc_loss = 0.09421445989937342
Trained batch 1229 in epoch 2, gen_loss = 0.8145579535302108, disc_loss = 0.0942320855394975
Trained batch 1230 in epoch 2, gen_loss = 0.8147919413812948, disc_loss = 0.09416696838626017
Trained batch 1231 in epoch 2, gen_loss = 0.8148487709075599, disc_loss = 0.09414433085816223
Trained batch 1232 in epoch 2, gen_loss = 0.8148721691465726, disc_loss = 0.0940817279139925
Trained batch 1233 in epoch 2, gen_loss = 0.8150847466297242, disc_loss = 0.09406742235989804
Trained batch 1234 in epoch 2, gen_loss = 0.8149500337206883, disc_loss = 0.0940760816617111
Trained batch 1235 in epoch 2, gen_loss = 0.8148328302168923, disc_loss = 0.09413548083719722
Trained batch 1236 in epoch 2, gen_loss = 0.8151126287594473, disc_loss = 0.09424100658218636
Trained batch 1237 in epoch 2, gen_loss = 0.815171788505283, disc_loss = 0.09426554796543207
Trained batch 1238 in epoch 2, gen_loss = 0.8152297358535969, disc_loss = 0.09427467041255799
Trained batch 1239 in epoch 2, gen_loss = 0.8150125012763085, disc_loss = 0.09434653193494605
Trained batch 1240 in epoch 2, gen_loss = 0.8149057116170356, disc_loss = 0.09434123674451128
Trained batch 1241 in epoch 2, gen_loss = 0.8148303440323582, disc_loss = 0.0943157948926991
Trained batch 1242 in epoch 2, gen_loss = 0.8146986116925652, disc_loss = 0.09431490976788996
Trained batch 1243 in epoch 2, gen_loss = 0.8145666613072827, disc_loss = 0.09428541528860593
Trained batch 1244 in epoch 2, gen_loss = 0.8148662056788862, disc_loss = 0.09428263553848348
Trained batch 1245 in epoch 2, gen_loss = 0.8150188954454364, disc_loss = 0.09422692258948427
Trained batch 1246 in epoch 2, gen_loss = 0.8149533401801285, disc_loss = 0.09420071442558489
Trained batch 1247 in epoch 2, gen_loss = 0.8148153780553585, disc_loss = 0.09423115974342904
Trained batch 1248 in epoch 2, gen_loss = 0.81465551245203, disc_loss = 0.09424981197567464
Trained batch 1249 in epoch 2, gen_loss = 0.8146122486114502, disc_loss = 0.0942204392798245
Trained batch 1250 in epoch 2, gen_loss = 0.8148371666360149, disc_loss = 0.09418005279252688
Trained batch 1251 in epoch 2, gen_loss = 0.8146894856954154, disc_loss = 0.09419430629647792
Trained batch 1252 in epoch 2, gen_loss = 0.8149141176928545, disc_loss = 0.09424434335053514
Trained batch 1253 in epoch 2, gen_loss = 0.815013370635597, disc_loss = 0.09424029885786786
Trained batch 1254 in epoch 2, gen_loss = 0.8148668658685874, disc_loss = 0.0942260949416049
Trained batch 1255 in epoch 2, gen_loss = 0.8146777543577419, disc_loss = 0.09420533119745339
Trained batch 1256 in epoch 2, gen_loss = 0.8147635431923179, disc_loss = 0.0941479003691102
Trained batch 1257 in epoch 2, gen_loss = 0.8148713709345303, disc_loss = 0.0942305379846268
Trained batch 1258 in epoch 2, gen_loss = 0.8147849265406111, disc_loss = 0.09426001141201394
Trained batch 1259 in epoch 2, gen_loss = 0.8147908803962526, disc_loss = 0.0942549388463949
Trained batch 1260 in epoch 2, gen_loss = 0.8147200080348234, disc_loss = 0.09421149575912957
Trained batch 1261 in epoch 2, gen_loss = 0.8146433148255627, disc_loss = 0.0941848822326212
Trained batch 1262 in epoch 2, gen_loss = 0.8149149482059554, disc_loss = 0.09431870246522854
Trained batch 1263 in epoch 2, gen_loss = 0.8146299195676288, disc_loss = 0.09440686663574409
Trained batch 1264 in epoch 2, gen_loss = 0.8144765929977884, disc_loss = 0.09438720459979867
Trained batch 1265 in epoch 2, gen_loss = 0.8145510127994499, disc_loss = 0.09435601856362363
Trained batch 1266 in epoch 2, gen_loss = 0.8145495613870793, disc_loss = 0.09430524211923791
Trained batch 1267 in epoch 2, gen_loss = 0.814755318410201, disc_loss = 0.09427267587626183
Trained batch 1268 in epoch 2, gen_loss = 0.8146797250207716, disc_loss = 0.09424350298192555
Trained batch 1269 in epoch 2, gen_loss = 0.814624303790528, disc_loss = 0.09420042941933425
Trained batch 1270 in epoch 2, gen_loss = 0.8145656304083688, disc_loss = 0.09417964522100335
Trained batch 1271 in epoch 2, gen_loss = 0.8144982707153701, disc_loss = 0.09413179931444637
Trained batch 1272 in epoch 2, gen_loss = 0.8146560104784775, disc_loss = 0.09412079430803458
Trained batch 1273 in epoch 2, gen_loss = 0.8143755245480095, disc_loss = 0.09418952512354524
Trained batch 1274 in epoch 2, gen_loss = 0.8144440133665122, disc_loss = 0.09414362779946304
Trained batch 1275 in epoch 2, gen_loss = 0.8145454648566844, disc_loss = 0.09408705703969636
Trained batch 1276 in epoch 2, gen_loss = 0.8145016253741346, disc_loss = 0.09407283261508777
Trained batch 1277 in epoch 2, gen_loss = 0.8147351122658018, disc_loss = 0.09407158210765751
Trained batch 1278 in epoch 2, gen_loss = 0.8147461019380657, disc_loss = 0.09402614662917426
Trained batch 1279 in epoch 2, gen_loss = 0.8147595432819799, disc_loss = 0.09397024304707884
Trained batch 1280 in epoch 2, gen_loss = 0.8147783409004375, disc_loss = 0.09394874625783312
Trained batch 1281 in epoch 2, gen_loss = 0.814934309043118, disc_loss = 0.09391252940822852
Trained batch 1282 in epoch 2, gen_loss = 0.8148863704197126, disc_loss = 0.09388011283025621
Trained batch 1283 in epoch 2, gen_loss = 0.8148420904516431, disc_loss = 0.09385650121241321
Trained batch 1284 in epoch 2, gen_loss = 0.814850090148384, disc_loss = 0.09404763195750662
Trained batch 1285 in epoch 2, gen_loss = 0.8149259106877432, disc_loss = 0.09399213388049468
Trained batch 1286 in epoch 2, gen_loss = 0.814694806389227, disc_loss = 0.09402648470036702
Trained batch 1287 in epoch 2, gen_loss = 0.8145807745247524, disc_loss = 0.09404757305305822
Trained batch 1288 in epoch 2, gen_loss = 0.814707022036019, disc_loss = 0.09399800514188199
Trained batch 1289 in epoch 2, gen_loss = 0.814590436659118, disc_loss = 0.09399111702994899
Trained batch 1290 in epoch 2, gen_loss = 0.8147644678305324, disc_loss = 0.09393830438188511
Trained batch 1291 in epoch 2, gen_loss = 0.8150060435428339, disc_loss = 0.09387948162112697
Trained batch 1292 in epoch 2, gen_loss = 0.8148479847279244, disc_loss = 0.09383961847822678
Trained batch 1293 in epoch 2, gen_loss = 0.8148547485355616, disc_loss = 0.09380518906379846
Trained batch 1294 in epoch 2, gen_loss = 0.8148427167684416, disc_loss = 0.09383385745182805
Trained batch 1295 in epoch 2, gen_loss = 0.8147376469209974, disc_loss = 0.0937965746018978
Trained batch 1296 in epoch 2, gen_loss = 0.8146773600403676, disc_loss = 0.09377808008291282
Trained batch 1297 in epoch 2, gen_loss = 0.8148400423293488, disc_loss = 0.09377345359469484
Trained batch 1298 in epoch 2, gen_loss = 0.8149794461958403, disc_loss = 0.09376529246221674
Trained batch 1299 in epoch 2, gen_loss = 0.8148354903780497, disc_loss = 0.09373208722171301
Trained batch 1300 in epoch 2, gen_loss = 0.8148468944725855, disc_loss = 0.09372039749677208
Trained batch 1301 in epoch 2, gen_loss = 0.8150374911576739, disc_loss = 0.09370204137306311
Trained batch 1302 in epoch 2, gen_loss = 0.8153839032876885, disc_loss = 0.09376248991129747
Trained batch 1303 in epoch 2, gen_loss = 0.8152319982510768, disc_loss = 0.09379769696502667
Trained batch 1304 in epoch 2, gen_loss = 0.815268953892463, disc_loss = 0.09375990613995269
Trained batch 1305 in epoch 2, gen_loss = 0.8154219830519938, disc_loss = 0.09371580595612686
Trained batch 1306 in epoch 2, gen_loss = 0.8155955594965038, disc_loss = 0.09366402077519241
Trained batch 1307 in epoch 2, gen_loss = 0.8157750847279479, disc_loss = 0.09360351219890063
Trained batch 1308 in epoch 2, gen_loss = 0.8156433583353201, disc_loss = 0.0935816352523869
Trained batch 1309 in epoch 2, gen_loss = 0.8157446897439374, disc_loss = 0.09358614928920875
Trained batch 1310 in epoch 2, gen_loss = 0.8157492651682969, disc_loss = 0.09355014905938772
Trained batch 1311 in epoch 2, gen_loss = 0.8157623042466073, disc_loss = 0.0934928825640449
Trained batch 1312 in epoch 2, gen_loss = 0.8155830219013493, disc_loss = 0.09351140377519586
Trained batch 1313 in epoch 2, gen_loss = 0.8155823664986379, disc_loss = 0.09344813623359283
Trained batch 1314 in epoch 2, gen_loss = 0.8158057365354023, disc_loss = 0.0933925411794972
Trained batch 1315 in epoch 2, gen_loss = 0.8160299327462277, disc_loss = 0.09334626402295447
Trained batch 1316 in epoch 2, gen_loss = 0.8158818994993139, disc_loss = 0.09330271640912706
Trained batch 1317 in epoch 2, gen_loss = 0.815911139473206, disc_loss = 0.09328440318946842
Trained batch 1318 in epoch 2, gen_loss = 0.8158882795589453, disc_loss = 0.09324590346286633
Trained batch 1319 in epoch 2, gen_loss = 0.8159439426705692, disc_loss = 0.09320367840753699
Trained batch 1320 in epoch 2, gen_loss = 0.8159214057180576, disc_loss = 0.09316340156455075
Trained batch 1321 in epoch 2, gen_loss = 0.8157756264785054, disc_loss = 0.09318700371839884
Trained batch 1322 in epoch 2, gen_loss = 0.8160234024960799, disc_loss = 0.09329016199117232
Trained batch 1323 in epoch 2, gen_loss = 0.8159623324105747, disc_loss = 0.09327065820237368
Trained batch 1324 in epoch 2, gen_loss = 0.8158314207140005, disc_loss = 0.09325124074195354
Trained batch 1325 in epoch 2, gen_loss = 0.8159250380811288, disc_loss = 0.09322164799571374
Trained batch 1326 in epoch 2, gen_loss = 0.8159181409836175, disc_loss = 0.09318605941996125
Trained batch 1327 in epoch 2, gen_loss = 0.8159360404698605, disc_loss = 0.09317235549538766
Trained batch 1328 in epoch 2, gen_loss = 0.8159507421778054, disc_loss = 0.09314397567122099
Trained batch 1329 in epoch 2, gen_loss = 0.8160146697347326, disc_loss = 0.0930910718445211
Trained batch 1330 in epoch 2, gen_loss = 0.8161096233653449, disc_loss = 0.09306749963963573
Trained batch 1331 in epoch 2, gen_loss = 0.816246026203976, disc_loss = 0.09300782891793048
Trained batch 1332 in epoch 2, gen_loss = 0.8163347166682756, disc_loss = 0.09320258468302876
Trained batch 1333 in epoch 2, gen_loss = 0.8160836571740961, disc_loss = 0.09340672664179549
Trained batch 1334 in epoch 2, gen_loss = 0.8161204745483756, disc_loss = 0.09351572879984249
Trained batch 1335 in epoch 2, gen_loss = 0.8159501282888615, disc_loss = 0.0935189690682089
Trained batch 1336 in epoch 2, gen_loss = 0.8161557648684787, disc_loss = 0.0934961534480696
Trained batch 1337 in epoch 2, gen_loss = 0.816087421614493, disc_loss = 0.09352613798508307
Trained batch 1338 in epoch 2, gen_loss = 0.8159015530120801, disc_loss = 0.09358007030782747
Trained batch 1339 in epoch 2, gen_loss = 0.8157041020580192, disc_loss = 0.09360686085854115
Trained batch 1340 in epoch 2, gen_loss = 0.8160160479707383, disc_loss = 0.09369954538005866
Trained batch 1341 in epoch 2, gen_loss = 0.8159323261187436, disc_loss = 0.0937115089522311
Trained batch 1342 in epoch 2, gen_loss = 0.8157856144615722, disc_loss = 0.09375904866148199
Trained batch 1343 in epoch 2, gen_loss = 0.8158741190009529, disc_loss = 0.09376166449995556
Trained batch 1344 in epoch 2, gen_loss = 0.815924368050905, disc_loss = 0.0937706824634432
Trained batch 1345 in epoch 2, gen_loss = 0.8158049572585774, disc_loss = 0.09377189961512522
Trained batch 1346 in epoch 2, gen_loss = 0.815779726794674, disc_loss = 0.09373998395896724
Trained batch 1347 in epoch 2, gen_loss = 0.815883717988825, disc_loss = 0.09385074682337527
Trained batch 1348 in epoch 2, gen_loss = 0.8158060630177285, disc_loss = 0.09387590277807482
Trained batch 1349 in epoch 2, gen_loss = 0.8157077686654197, disc_loss = 0.09389922855697848
Trained batch 1350 in epoch 2, gen_loss = 0.8155096089681108, disc_loss = 0.09392586186718468
Trained batch 1351 in epoch 2, gen_loss = 0.8154624160709818, disc_loss = 0.09386850484528375
Trained batch 1352 in epoch 2, gen_loss = 0.8156305927527189, disc_loss = 0.09388989239796192
Trained batch 1353 in epoch 2, gen_loss = 0.8153534221904493, disc_loss = 0.09397407304124145
Trained batch 1354 in epoch 2, gen_loss = 0.8154282372156193, disc_loss = 0.09397375281157859
Trained batch 1355 in epoch 2, gen_loss = 0.8154649357132855, disc_loss = 0.0939310413605333
Trained batch 1356 in epoch 2, gen_loss = 0.8155789227940707, disc_loss = 0.09393875617067231
Trained batch 1357 in epoch 2, gen_loss = 0.815625932347441, disc_loss = 0.09391747116535046
Trained batch 1358 in epoch 2, gen_loss = 0.815471989626916, disc_loss = 0.09393792655291563
Trained batch 1359 in epoch 2, gen_loss = 0.8155570219763938, disc_loss = 0.09404401923187405
Trained batch 1360 in epoch 2, gen_loss = 0.8154521699034055, disc_loss = 0.0940366855307231
Trained batch 1361 in epoch 2, gen_loss = 0.8154532389274953, disc_loss = 0.09397854151959133
Trained batch 1362 in epoch 2, gen_loss = 0.8155835130725463, disc_loss = 0.09393498461190625
Trained batch 1363 in epoch 2, gen_loss = 0.815726852421362, disc_loss = 0.09391651466513419
Trained batch 1364 in epoch 2, gen_loss = 0.8156335712134183, disc_loss = 0.09394159960072665
Trained batch 1365 in epoch 2, gen_loss = 0.815613524565585, disc_loss = 0.09398106791114497
Trained batch 1366 in epoch 2, gen_loss = 0.8157285620412777, disc_loss = 0.09395159451030713
Trained batch 1367 in epoch 2, gen_loss = 0.8156818601340927, disc_loss = 0.09392335498501268
Trained batch 1368 in epoch 2, gen_loss = 0.815704511869032, disc_loss = 0.09388398591135108
Trained batch 1369 in epoch 2, gen_loss = 0.8155321853656838, disc_loss = 0.0939406017025076
Trained batch 1370 in epoch 2, gen_loss = 0.8160208988633145, disc_loss = 0.09399340805861851
Trained batch 1371 in epoch 2, gen_loss = 0.8160439267233232, disc_loss = 0.09400994976121747
Trained batch 1372 in epoch 2, gen_loss = 0.8159672643308299, disc_loss = 0.09399720933966647
Trained batch 1373 in epoch 2, gen_loss = 0.8159887222180027, disc_loss = 0.0939714175586628
Trained batch 1374 in epoch 2, gen_loss = 0.8160633870254863, disc_loss = 0.09395813057165255
Trained batch 1375 in epoch 2, gen_loss = 0.8159750750028464, disc_loss = 0.09395616773453672
Trained batch 1376 in epoch 2, gen_loss = 0.815872879307947, disc_loss = 0.09393657968002835
Trained batch 1377 in epoch 2, gen_loss = 0.8161406662147519, disc_loss = 0.09391541050811919
Trained batch 1378 in epoch 2, gen_loss = 0.8163342852580365, disc_loss = 0.09390965952964106
Trained batch 1379 in epoch 2, gen_loss = 0.8162241481568502, disc_loss = 0.09391133901933073
Trained batch 1380 in epoch 2, gen_loss = 0.8160932727217415, disc_loss = 0.09388578337921365
Trained batch 1381 in epoch 2, gen_loss = 0.8162329518027313, disc_loss = 0.09392307279901053
Trained batch 1382 in epoch 2, gen_loss = 0.8162475408675096, disc_loss = 0.09387655892164937
Trained batch 1383 in epoch 2, gen_loss = 0.816197660681657, disc_loss = 0.09384290226452548
Trained batch 1384 in epoch 2, gen_loss = 0.8161465787069893, disc_loss = 0.09383094218838624
Trained batch 1385 in epoch 2, gen_loss = 0.8164676920031056, disc_loss = 0.09396550726497607
Trained batch 1386 in epoch 2, gen_loss = 0.8162739961243569, disc_loss = 0.0939963777282993
Trained batch 1387 in epoch 2, gen_loss = 0.8162392452788628, disc_loss = 0.09399937481957592
Trained batch 1388 in epoch 2, gen_loss = 0.8164080633930031, disc_loss = 0.09399021293061448
Trained batch 1389 in epoch 2, gen_loss = 0.8164853690553913, disc_loss = 0.09396300762958772
Trained batch 1390 in epoch 2, gen_loss = 0.8163594519337847, disc_loss = 0.09400486555164726
Trained batch 1391 in epoch 2, gen_loss = 0.8164071576648403, disc_loss = 0.09396294677354416
Trained batch 1392 in epoch 2, gen_loss = 0.8165600416862272, disc_loss = 0.09395008163068012
Trained batch 1393 in epoch 2, gen_loss = 0.8165663105129682, disc_loss = 0.09391290803040395
Trained batch 1394 in epoch 2, gen_loss = 0.8167111347866742, disc_loss = 0.09387473214123945
Trained batch 1395 in epoch 2, gen_loss = 0.8167520180173795, disc_loss = 0.0938361657411127
Trained batch 1396 in epoch 2, gen_loss = 0.8167884597926799, disc_loss = 0.0937984338704878
Trained batch 1397 in epoch 2, gen_loss = 0.8169526298968748, disc_loss = 0.0937461220880488
Trained batch 1398 in epoch 2, gen_loss = 0.8171300446458848, disc_loss = 0.09379706423985289
Trained batch 1399 in epoch 2, gen_loss = 0.8171405522099563, disc_loss = 0.09377482720052026
Trained batch 1400 in epoch 2, gen_loss = 0.8172144756029539, disc_loss = 0.09378022139295032
Trained batch 1401 in epoch 2, gen_loss = 0.8173608561172635, disc_loss = 0.09376670935984366
Trained batch 1402 in epoch 2, gen_loss = 0.8173945875186539, disc_loss = 0.09382632588576034
Trained batch 1403 in epoch 2, gen_loss = 0.8172390162732527, disc_loss = 0.09393792946828249
Trained batch 1404 in epoch 2, gen_loss = 0.817232553751019, disc_loss = 0.0938885533174639
Trained batch 1405 in epoch 2, gen_loss = 0.8175577226480414, disc_loss = 0.09385490622623144
Trained batch 1406 in epoch 2, gen_loss = 0.8176900951804722, disc_loss = 0.09379785827492769
Trained batch 1407 in epoch 2, gen_loss = 0.8176267084623263, disc_loss = 0.09377283810648475
Trained batch 1408 in epoch 2, gen_loss = 0.8175230872512625, disc_loss = 0.09375602080148954
Trained batch 1409 in epoch 2, gen_loss = 0.8177676888433754, disc_loss = 0.09379472140988983
Trained batch 1410 in epoch 2, gen_loss = 0.817778627577612, disc_loss = 0.09377731246349662
Trained batch 1411 in epoch 2, gen_loss = 0.8177254366933793, disc_loss = 0.09373319601750914
Trained batch 1412 in epoch 2, gen_loss = 0.8177161699098977, disc_loss = 0.09367554542863635
Trained batch 1413 in epoch 2, gen_loss = 0.8175422953707832, disc_loss = 0.09368245450969485
Trained batch 1414 in epoch 2, gen_loss = 0.8175707019049372, disc_loss = 0.09364115801498346
Trained batch 1415 in epoch 2, gen_loss = 0.8177290625112542, disc_loss = 0.09360912146828121
Trained batch 1416 in epoch 2, gen_loss = 0.8178982339909822, disc_loss = 0.09356641929055089
Trained batch 1417 in epoch 2, gen_loss = 0.8176980056236426, disc_loss = 0.09357712738155499
Trained batch 1418 in epoch 2, gen_loss = 0.8175492596886711, disc_loss = 0.0935673881788135
Trained batch 1419 in epoch 2, gen_loss = 0.8177079873395637, disc_loss = 0.09351710051127618
Trained batch 1420 in epoch 2, gen_loss = 0.8176483828404015, disc_loss = 0.09346945672233725
Trained batch 1421 in epoch 2, gen_loss = 0.8175530021410283, disc_loss = 0.09343494016758354
Trained batch 1422 in epoch 2, gen_loss = 0.8176561314416284, disc_loss = 0.09342537665162405
Trained batch 1423 in epoch 2, gen_loss = 0.8176321259835798, disc_loss = 0.09347255589516332
Trained batch 1424 in epoch 2, gen_loss = 0.817512927034445, disc_loss = 0.09347133429230828
Trained batch 1425 in epoch 2, gen_loss = 0.8175093166080799, disc_loss = 0.09345825067505784
Trained batch 1426 in epoch 2, gen_loss = 0.8175905491600691, disc_loss = 0.09346086083707082
Trained batch 1427 in epoch 2, gen_loss = 0.8174663514775389, disc_loss = 0.09345781037529163
Trained batch 1428 in epoch 2, gen_loss = 0.8173245465405092, disc_loss = 0.09347010521508853
Trained batch 1429 in epoch 2, gen_loss = 0.8174904529239748, disc_loss = 0.09343348420648412
Trained batch 1430 in epoch 2, gen_loss = 0.8177458321315104, disc_loss = 0.09337897371477301
Trained batch 1431 in epoch 2, gen_loss = 0.817742988945885, disc_loss = 0.09337185818816447
Trained batch 1432 in epoch 2, gen_loss = 0.8177795507278961, disc_loss = 0.09333838605882817
Trained batch 1433 in epoch 2, gen_loss = 0.8176425566774698, disc_loss = 0.09337626914318387
Trained batch 1434 in epoch 2, gen_loss = 0.8177470683013105, disc_loss = 0.09336008237162118
Trained batch 1435 in epoch 2, gen_loss = 0.8179358984226968, disc_loss = 0.09331055557028414
Trained batch 1436 in epoch 2, gen_loss = 0.8180935659712192, disc_loss = 0.09327353217438765
Trained batch 1437 in epoch 2, gen_loss = 0.8179823583580025, disc_loss = 0.0932639040058072
Trained batch 1438 in epoch 2, gen_loss = 0.817934433543243, disc_loss = 0.09322298578063674
Trained batch 1439 in epoch 2, gen_loss = 0.8178705911048585, disc_loss = 0.09317825608757428
Trained batch 1440 in epoch 2, gen_loss = 0.8180904353889303, disc_loss = 0.09319843974747771
Trained batch 1441 in epoch 2, gen_loss = 0.8180001191433194, disc_loss = 0.09317055702772659
Trained batch 1442 in epoch 2, gen_loss = 0.8179537012646451, disc_loss = 0.09318537927121028
Trained batch 1443 in epoch 2, gen_loss = 0.8180194005287585, disc_loss = 0.09314069378259399
Trained batch 1444 in epoch 2, gen_loss = 0.8182374410769518, disc_loss = 0.09309216383909065
Trained batch 1445 in epoch 2, gen_loss = 0.8180863610977619, disc_loss = 0.09309520680498574
Trained batch 1446 in epoch 2, gen_loss = 0.8181063788012958, disc_loss = 0.09316899849239636
Trained batch 1447 in epoch 2, gen_loss = 0.8179541665916614, disc_loss = 0.09320380929625949
Trained batch 1448 in epoch 2, gen_loss = 0.8180324068926712, disc_loss = 0.09316065571328086
Trained batch 1449 in epoch 2, gen_loss = 0.8181585284142658, disc_loss = 0.0931275888545246
Trained batch 1450 in epoch 2, gen_loss = 0.8181087411452292, disc_loss = 0.09308672559638216
Trained batch 1451 in epoch 2, gen_loss = 0.8180844167416746, disc_loss = 0.09310501409417465
Trained batch 1452 in epoch 2, gen_loss = 0.8180488666951533, disc_loss = 0.0930961260106735
Trained batch 1453 in epoch 2, gen_loss = 0.8179590236984879, disc_loss = 0.0930945021093937
Trained batch 1454 in epoch 2, gen_loss = 0.8180003585479514, disc_loss = 0.0931346494294831
Trained batch 1455 in epoch 2, gen_loss = 0.8179814475537329, disc_loss = 0.09314107025876273
Trained batch 1456 in epoch 2, gen_loss = 0.8178241678149879, disc_loss = 0.09313729889537467
Trained batch 1457 in epoch 2, gen_loss = 0.8179462200697557, disc_loss = 0.09314423490223693
Trained batch 1458 in epoch 2, gen_loss = 0.8176629472832879, disc_loss = 0.09319859221603177
Trained batch 1459 in epoch 2, gen_loss = 0.8177967374251314, disc_loss = 0.09317074702950577
Trained batch 1460 in epoch 2, gen_loss = 0.8177326212469476, disc_loss = 0.09320217307878838
Trained batch 1461 in epoch 2, gen_loss = 0.8177595568461555, disc_loss = 0.09315894195547508
Trained batch 1462 in epoch 2, gen_loss = 0.81778078519638, disc_loss = 0.09311575882559514
Trained batch 1463 in epoch 2, gen_loss = 0.8178665266865915, disc_loss = 0.09307518010562071
Trained batch 1464 in epoch 2, gen_loss = 0.8179909994374364, disc_loss = 0.09303144667895173
Trained batch 1465 in epoch 2, gen_loss = 0.817926884652973, disc_loss = 0.09301672142258201
Trained batch 1466 in epoch 2, gen_loss = 0.8181534973674676, disc_loss = 0.09305449006107687
Trained batch 1467 in epoch 2, gen_loss = 0.8183807489292173, disc_loss = 0.09301554471792334
Trained batch 1468 in epoch 2, gen_loss = 0.8183468818623976, disc_loss = 0.09301964841514238
Trained batch 1469 in epoch 2, gen_loss = 0.818432644739443, disc_loss = 0.09299749734805149
Trained batch 1470 in epoch 2, gen_loss = 0.8185329228781422, disc_loss = 0.09295321315435792
Trained batch 1471 in epoch 2, gen_loss = 0.8183412893837236, disc_loss = 0.0930836639878259
Trained batch 1472 in epoch 2, gen_loss = 0.8184537175595153, disc_loss = 0.09309928644972032
Trained batch 1473 in epoch 2, gen_loss = 0.8183229239088871, disc_loss = 0.09317471811565567
Trained batch 1474 in epoch 2, gen_loss = 0.8182669266401711, disc_loss = 0.09314370657175275
Trained batch 1475 in epoch 2, gen_loss = 0.8181493000649824, disc_loss = 0.09313929712697662
Trained batch 1476 in epoch 2, gen_loss = 0.8180271570514648, disc_loss = 0.09315548749160105
Trained batch 1477 in epoch 2, gen_loss = 0.8182415223613644, disc_loss = 0.09325212762213447
Trained batch 1478 in epoch 2, gen_loss = 0.8181795412378589, disc_loss = 0.09322981055047642
Trained batch 1479 in epoch 2, gen_loss = 0.8179675293331211, disc_loss = 0.09326085602562573
Trained batch 1480 in epoch 2, gen_loss = 0.8178763109674976, disc_loss = 0.09326763002605634
Trained batch 1481 in epoch 2, gen_loss = 0.8179270397273474, disc_loss = 0.09322683597875912
Trained batch 1482 in epoch 2, gen_loss = 0.8179831158970147, disc_loss = 0.09331031803064305
Trained batch 1483 in epoch 2, gen_loss = 0.8177875854536851, disc_loss = 0.09332801829621878
Trained batch 1484 in epoch 2, gen_loss = 0.8180062818808186, disc_loss = 0.09336036853366829
Trained batch 1485 in epoch 2, gen_loss = 0.8179292601619723, disc_loss = 0.09339852806827502
Trained batch 1486 in epoch 2, gen_loss = 0.8178348868143342, disc_loss = 0.09338452027410409
Trained batch 1487 in epoch 2, gen_loss = 0.8178986836304908, disc_loss = 0.09333949984972595
Trained batch 1488 in epoch 2, gen_loss = 0.8181279913501662, disc_loss = 0.09334468979405988
Trained batch 1489 in epoch 2, gen_loss = 0.8180610734544345, disc_loss = 0.09335364556102545
Trained batch 1490 in epoch 2, gen_loss = 0.8181207537211322, disc_loss = 0.09331111330976229
Trained batch 1491 in epoch 2, gen_loss = 0.8181384107342674, disc_loss = 0.09327047853418513
Trained batch 1492 in epoch 2, gen_loss = 0.8181891344931808, disc_loss = 0.09323119776721417
Trained batch 1493 in epoch 2, gen_loss = 0.8182914949843842, disc_loss = 0.09318723942251649
Trained batch 1494 in epoch 2, gen_loss = 0.8182991398018739, disc_loss = 0.09315501335123709
Trained batch 1495 in epoch 2, gen_loss = 0.8184818686210217, disc_loss = 0.09312745845592756
Trained batch 1496 in epoch 2, gen_loss = 0.8184152752579095, disc_loss = 0.0931255938205308
Trained batch 1497 in epoch 2, gen_loss = 0.818279474555889, disc_loss = 0.09310542869173956
Trained batch 1498 in epoch 2, gen_loss = 0.8182718919824965, disc_loss = 0.0930914848724789
Trained batch 1499 in epoch 2, gen_loss = 0.8182960926095645, disc_loss = 0.09305923218280077
Trained batch 1500 in epoch 2, gen_loss = 0.8183933707136539, disc_loss = 0.09305656666828345
Trained batch 1501 in epoch 2, gen_loss = 0.8183975519932379, disc_loss = 0.09301677189727676
Trained batch 1502 in epoch 2, gen_loss = 0.8183404112250823, disc_loss = 0.0930011921592617
Trained batch 1503 in epoch 2, gen_loss = 0.8182836561166542, disc_loss = 0.09296231903383469
Trained batch 1504 in epoch 2, gen_loss = 0.8182634741166898, disc_loss = 0.09295254469264386
Trained batch 1505 in epoch 2, gen_loss = 0.8183387129865636, disc_loss = 0.09293453366425171
Trained batch 1506 in epoch 2, gen_loss = 0.818212985339826, disc_loss = 0.09297763723595774
Trained batch 1507 in epoch 2, gen_loss = 0.8182462369059694, disc_loss = 0.09294198913652875
Trained batch 1508 in epoch 2, gen_loss = 0.8182540729671539, disc_loss = 0.09295018618424022
Trained batch 1509 in epoch 2, gen_loss = 0.8180330508394746, disc_loss = 0.09303082468247177
Trained batch 1510 in epoch 2, gen_loss = 0.8180237067092893, disc_loss = 0.09299438270973812
Trained batch 1511 in epoch 2, gen_loss = 0.8181529516383769, disc_loss = 0.09294312748511041
Trained batch 1512 in epoch 2, gen_loss = 0.8181254997091111, disc_loss = 0.09297306091701323
Trained batch 1513 in epoch 2, gen_loss = 0.8179978155278782, disc_loss = 0.09297802887950461
Trained batch 1514 in epoch 2, gen_loss = 0.8179913868801822, disc_loss = 0.09296771391808199
Trained batch 1515 in epoch 2, gen_loss = 0.8181516289278511, disc_loss = 0.0929470595751341
Trained batch 1516 in epoch 2, gen_loss = 0.8181908480533268, disc_loss = 0.09292307677178416
Trained batch 1517 in epoch 2, gen_loss = 0.8180115911447012, disc_loss = 0.09290464535448822
Trained batch 1518 in epoch 2, gen_loss = 0.8182486078902402, disc_loss = 0.09300222620981119
Trained batch 1519 in epoch 2, gen_loss = 0.8181038710435754, disc_loss = 0.09301368838151623
Trained batch 1520 in epoch 2, gen_loss = 0.8181255782888878, disc_loss = 0.09296971335051915
Trained batch 1521 in epoch 2, gen_loss = 0.8181078962874005, disc_loss = 0.09294423029321135
Trained batch 1522 in epoch 2, gen_loss = 0.8181563027384089, disc_loss = 0.09289025056872392
Trained batch 1523 in epoch 2, gen_loss = 0.8180866217402023, disc_loss = 0.0928711509497059
Trained batch 1524 in epoch 2, gen_loss = 0.8180631527158081, disc_loss = 0.0928363692290226
Trained batch 1525 in epoch 2, gen_loss = 0.8180786398377362, disc_loss = 0.09280058266448533
Trained batch 1526 in epoch 2, gen_loss = 0.8180340792942297, disc_loss = 0.09277744823670321
Trained batch 1527 in epoch 2, gen_loss = 0.8179205222084572, disc_loss = 0.0927750746986502
Trained batch 1528 in epoch 2, gen_loss = 0.8178425891832872, disc_loss = 0.09275748032681824
Trained batch 1529 in epoch 2, gen_loss = 0.8177614833210028, disc_loss = 0.09276138566178727
Trained batch 1530 in epoch 2, gen_loss = 0.8177781408515186, disc_loss = 0.09271539454813743
Trained batch 1531 in epoch 2, gen_loss = 0.8175598690894191, disc_loss = 0.09281740037118895
Trained batch 1532 in epoch 2, gen_loss = 0.8175883213251304, disc_loss = 0.09280789095850082
Trained batch 1533 in epoch 2, gen_loss = 0.8177449704187946, disc_loss = 0.09284131720509123
Trained batch 1534 in epoch 2, gen_loss = 0.8175430791968243, disc_loss = 0.0928477088001584
Trained batch 1535 in epoch 2, gen_loss = 0.8173215965895603, disc_loss = 0.0928562248597397
Trained batch 1536 in epoch 2, gen_loss = 0.8172581169460994, disc_loss = 0.09283276622425389
Trained batch 1537 in epoch 2, gen_loss = 0.8173252506125888, disc_loss = 0.092800518583206
Trained batch 1538 in epoch 2, gen_loss = 0.8174820917624014, disc_loss = 0.09280024507204633
Trained batch 1539 in epoch 2, gen_loss = 0.8175201373440879, disc_loss = 0.09277897102020487
Trained batch 1540 in epoch 2, gen_loss = 0.8174367582233287, disc_loss = 0.09273951834080998
Trained batch 1541 in epoch 2, gen_loss = 0.817521321247833, disc_loss = 0.09276526495053321
Trained batch 1542 in epoch 2, gen_loss = 0.8173818052858017, disc_loss = 0.09277070519210781
Trained batch 1543 in epoch 2, gen_loss = 0.8174196796713715, disc_loss = 0.09271859475640687
Trained batch 1544 in epoch 2, gen_loss = 0.817862808588639, disc_loss = 0.09286545672812604
Trained batch 1545 in epoch 2, gen_loss = 0.817695599786677, disc_loss = 0.09289301368546458
Trained batch 1546 in epoch 2, gen_loss = 0.8175619241493166, disc_loss = 0.0928897118441515
Trained batch 1547 in epoch 2, gen_loss = 0.817514018032902, disc_loss = 0.0928910642974223
Trained batch 1548 in epoch 2, gen_loss = 0.8174971714182928, disc_loss = 0.09291881986210103
Trained batch 1549 in epoch 2, gen_loss = 0.8175907646840619, disc_loss = 0.09301478553743613
Trained batch 1550 in epoch 2, gen_loss = 0.8175161030121882, disc_loss = 0.0929994225594486
Trained batch 1551 in epoch 2, gen_loss = 0.817287167457422, disc_loss = 0.09303605981403962
Trained batch 1552 in epoch 2, gen_loss = 0.8173046327566071, disc_loss = 0.0931236219897636
Trained batch 1553 in epoch 2, gen_loss = 0.8173193342245377, disc_loss = 0.09312125923054501
Trained batch 1554 in epoch 2, gen_loss = 0.817212883471676, disc_loss = 0.09312859533648112
Trained batch 1555 in epoch 2, gen_loss = 0.817271969331414, disc_loss = 0.09310141948032598
Trained batch 1556 in epoch 2, gen_loss = 0.8172817935182562, disc_loss = 0.093114815528553
Trained batch 1557 in epoch 2, gen_loss = 0.8172749022119924, disc_loss = 0.09309938203827962
Trained batch 1558 in epoch 2, gen_loss = 0.8171171565672157, disc_loss = 0.09311022744779884
Trained batch 1559 in epoch 2, gen_loss = 0.8171930703788232, disc_loss = 0.09307122963707512
Trained batch 1560 in epoch 2, gen_loss = 0.8171056634451166, disc_loss = 0.09305329100645883
Trained batch 1561 in epoch 2, gen_loss = 0.8171370814956257, disc_loss = 0.09300619590176072
Trained batch 1562 in epoch 2, gen_loss = 0.8170216203460462, disc_loss = 0.0930426743433299
Trained batch 1563 in epoch 2, gen_loss = 0.8170314194715541, disc_loss = 0.09299738056626637
Trained batch 1564 in epoch 2, gen_loss = 0.8171949700235178, disc_loss = 0.09297277739646431
Trained batch 1565 in epoch 2, gen_loss = 0.8172169499584542, disc_loss = 0.09292603189025746
Trained batch 1566 in epoch 2, gen_loss = 0.817295570071518, disc_loss = 0.09287800828925671
Trained batch 1567 in epoch 2, gen_loss = 0.8172404603956609, disc_loss = 0.09288024087733475
Trained batch 1568 in epoch 2, gen_loss = 0.817205827372176, disc_loss = 0.09287259029966487
Trained batch 1569 in epoch 2, gen_loss = 0.8171860441470602, disc_loss = 0.09287196245744445
Trained batch 1570 in epoch 2, gen_loss = 0.8171335145176634, disc_loss = 0.09285582398389894
Trained batch 1571 in epoch 2, gen_loss = 0.8171655666320076, disc_loss = 0.09286701879535184
Trained batch 1572 in epoch 2, gen_loss = 0.8171681964276175, disc_loss = 0.09283541776512223
Trained batch 1573 in epoch 2, gen_loss = 0.8170510346621389, disc_loss = 0.09283470362720696
Trained batch 1574 in epoch 2, gen_loss = 0.8170991584043654, disc_loss = 0.09279991847241209
Trained batch 1575 in epoch 2, gen_loss = 0.8172854099441603, disc_loss = 0.09275901220032123
Trained batch 1576 in epoch 2, gen_loss = 0.8174846780662984, disc_loss = 0.09271377223775915
Trained batch 1577 in epoch 2, gen_loss = 0.8176223804704439, disc_loss = 0.09266545415144173
Trained batch 1578 in epoch 2, gen_loss = 0.8175633713706828, disc_loss = 0.09263680964068965
Trained batch 1579 in epoch 2, gen_loss = 0.8175131520704378, disc_loss = 0.09264705808821452
Trained batch 1580 in epoch 2, gen_loss = 0.8175946324592448, disc_loss = 0.09261801585397206
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 0.7329399585723877, disc_loss = 0.047570183873176575
Trained batch 1 in epoch 3, gen_loss = 0.8220903873443604, disc_loss = 0.07061464712023735
Trained batch 2 in epoch 3, gen_loss = 0.8284287850062052, disc_loss = 0.09104735404253006
Trained batch 3 in epoch 3, gen_loss = 0.820585697889328, disc_loss = 0.09037269465625286
Trained batch 4 in epoch 3, gen_loss = 0.8219880223274231, disc_loss = 0.08733468353748322
Trained batch 5 in epoch 3, gen_loss = 0.874588261047999, disc_loss = 0.09573068469762802
Trained batch 6 in epoch 3, gen_loss = 0.8643875547817775, disc_loss = 0.09058898900236402
Trained batch 7 in epoch 3, gen_loss = 0.8829698637127876, disc_loss = 0.08246379205957055
Trained batch 8 in epoch 3, gen_loss = 0.8595547477404276, disc_loss = 0.08214588421914312
Trained batch 9 in epoch 3, gen_loss = 0.8586018264293671, disc_loss = 0.0768393961712718
Trained batch 10 in epoch 3, gen_loss = 0.8945697708563372, disc_loss = 0.07541459307751873
Trained batch 11 in epoch 3, gen_loss = 0.8999524762233099, disc_loss = 0.0733075028595825
Trained batch 12 in epoch 3, gen_loss = 0.885153013926286, disc_loss = 0.07764486954189263
Trained batch 13 in epoch 3, gen_loss = 0.8731525668076107, disc_loss = 0.07743039022066764
Trained batch 14 in epoch 3, gen_loss = 0.8802660981814067, disc_loss = 0.07537752675513426
Trained batch 15 in epoch 3, gen_loss = 0.883518859744072, disc_loss = 0.07489867031108588
Trained batch 16 in epoch 3, gen_loss = 0.8843752811936771, disc_loss = 0.07236553761450683
Trained batch 17 in epoch 3, gen_loss = 0.8701194723447164, disc_loss = 0.07100033646242486
Trained batch 18 in epoch 3, gen_loss = 0.8567294698012503, disc_loss = 0.0773021301352664
Trained batch 19 in epoch 3, gen_loss = 0.8603906512260437, disc_loss = 0.07550931861624122
Trained batch 20 in epoch 3, gen_loss = 0.8511121386573428, disc_loss = 0.07423645284559045
Trained batch 21 in epoch 3, gen_loss = 0.8518418886444785, disc_loss = 0.0720209020443938
Trained batch 22 in epoch 3, gen_loss = 0.8476204923961473, disc_loss = 0.07030864140909651
Trained batch 23 in epoch 3, gen_loss = 0.8403132905562719, disc_loss = 0.0745103385609885
Trained batch 24 in epoch 3, gen_loss = 0.8353065991401672, disc_loss = 0.07281198486685753
Trained batch 25 in epoch 3, gen_loss = 0.8380805872953855, disc_loss = 0.07323272741184784
Trained batch 26 in epoch 3, gen_loss = 0.8419342239697775, disc_loss = 0.07243205193016264
Trained batch 27 in epoch 3, gen_loss = 0.8370710462331772, disc_loss = 0.07158535386302642
Trained batch 28 in epoch 3, gen_loss = 0.8238803035226362, disc_loss = 0.07653143372515152
Trained batch 29 in epoch 3, gen_loss = 0.8298704673846563, disc_loss = 0.07900739548106989
Trained batch 30 in epoch 3, gen_loss = 0.8314090053881368, disc_loss = 0.08026362246563358
Trained batch 31 in epoch 3, gen_loss = 0.8396500619128346, disc_loss = 0.0829047403531149
Trained batch 32 in epoch 3, gen_loss = 0.8366769778006005, disc_loss = 0.08472942865707657
Trained batch 33 in epoch 3, gen_loss = 0.8359271138906479, disc_loss = 0.08410885678056408
Trained batch 34 in epoch 3, gen_loss = 0.8332053346293313, disc_loss = 0.08443608060479164
Trained batch 35 in epoch 3, gen_loss = 0.8358315270808008, disc_loss = 0.08297688141465187
Trained batch 36 in epoch 3, gen_loss = 0.8385880871399028, disc_loss = 0.08236609630890794
Trained batch 37 in epoch 3, gen_loss = 0.8436783120820397, disc_loss = 0.08108030818402767
Trained batch 38 in epoch 3, gen_loss = 0.8406009070384197, disc_loss = 0.08154141721435082
Trained batch 39 in epoch 3, gen_loss = 0.8368138365447522, disc_loss = 0.08043497493490577
Trained batch 40 in epoch 3, gen_loss = 0.8435500300512081, disc_loss = 0.07930523220722269
Trained batch 41 in epoch 3, gen_loss = 0.8496701539981932, disc_loss = 0.08180739721726804
Trained batch 42 in epoch 3, gen_loss = 0.8435671752275422, disc_loss = 0.08532118130215378
Trained batch 43 in epoch 3, gen_loss = 0.8366019935770468, disc_loss = 0.08687510095875371
Trained batch 44 in epoch 3, gen_loss = 0.8479081173737844, disc_loss = 0.09259115879734357
Trained batch 45 in epoch 3, gen_loss = 0.8444741387730059, disc_loss = 0.09173730509760587
Trained batch 46 in epoch 3, gen_loss = 0.8448699173775125, disc_loss = 0.09011931479611296
Trained batch 47 in epoch 3, gen_loss = 0.8477011490613222, disc_loss = 0.08864460210315883
Trained batch 48 in epoch 3, gen_loss = 0.8441646324128521, disc_loss = 0.08866885342464155
Trained batch 49 in epoch 3, gen_loss = 0.848756759762764, disc_loss = 0.08838043265044689
Trained batch 50 in epoch 3, gen_loss = 0.8500552533888349, disc_loss = 0.08918166240932894
Trained batch 51 in epoch 3, gen_loss = 0.8430826451915961, disc_loss = 0.09029360853422147
Trained batch 52 in epoch 3, gen_loss = 0.8476300841232516, disc_loss = 0.08942804309838223
Trained batch 53 in epoch 3, gen_loss = 0.8453966384684598, disc_loss = 0.08888160071715161
Trained batch 54 in epoch 3, gen_loss = 0.8412852617827329, disc_loss = 0.08931456662037156
Trained batch 55 in epoch 3, gen_loss = 0.8442407021565097, disc_loss = 0.08853771690545338
Trained batch 56 in epoch 3, gen_loss = 0.8431407239353448, disc_loss = 0.09010868055517213
Trained batch 57 in epoch 3, gen_loss = 0.8434536277220167, disc_loss = 0.08913543550618763
Trained batch 58 in epoch 3, gen_loss = 0.8389024800163204, disc_loss = 0.08973214964745409
Trained batch 59 in epoch 3, gen_loss = 0.8429339910546939, disc_loss = 0.08891096698741117
Trained batch 60 in epoch 3, gen_loss = 0.8473074734210968, disc_loss = 0.09016169082434451
Trained batch 61 in epoch 3, gen_loss = 0.8469306216124566, disc_loss = 0.08955518925382246
Trained batch 62 in epoch 3, gen_loss = 0.8437603574896616, disc_loss = 0.089762539617599
Trained batch 63 in epoch 3, gen_loss = 0.8428647513501346, disc_loss = 0.08932911104056984
Trained batch 64 in epoch 3, gen_loss = 0.8467679239236392, disc_loss = 0.09003976503243813
Trained batch 65 in epoch 3, gen_loss = 0.8427014418623664, disc_loss = 0.08961158488510233
Trained batch 66 in epoch 3, gen_loss = 0.841397591046433, disc_loss = 0.08980113484743815
Trained batch 67 in epoch 3, gen_loss = 0.841545503367396, disc_loss = 0.09030156357980826
Trained batch 68 in epoch 3, gen_loss = 0.8407327943090079, disc_loss = 0.08948074292013611
Trained batch 69 in epoch 3, gen_loss = 0.8414777393851961, disc_loss = 0.08870052413216659
Trained batch 70 in epoch 3, gen_loss = 0.8412732066402973, disc_loss = 0.08848796758643339
Trained batch 71 in epoch 3, gen_loss = 0.8483364164001412, disc_loss = 0.08853921837483843
Trained batch 72 in epoch 3, gen_loss = 0.8462051157265493, disc_loss = 0.08802836444484044
Trained batch 73 in epoch 3, gen_loss = 0.8459408657776343, disc_loss = 0.08721184038330575
Trained batch 74 in epoch 3, gen_loss = 0.8451159648100535, disc_loss = 0.08674334404369195
Trained batch 75 in epoch 3, gen_loss = 0.8418184828601385, disc_loss = 0.08685505632801276
Trained batch 76 in epoch 3, gen_loss = 0.8444943439650845, disc_loss = 0.08734757189530057
Trained batch 77 in epoch 3, gen_loss = 0.8446154399560049, disc_loss = 0.08651787052169824
Trained batch 78 in epoch 3, gen_loss = 0.8446645453760896, disc_loss = 0.0861497472830211
Trained batch 79 in epoch 3, gen_loss = 0.8403848867863417, disc_loss = 0.08628547596745192
Trained batch 80 in epoch 3, gen_loss = 0.8392715479856656, disc_loss = 0.08636580301839629
Trained batch 81 in epoch 3, gen_loss = 0.8431531158162326, disc_loss = 0.08598024743359263
Trained batch 82 in epoch 3, gen_loss = 0.8441719990896891, disc_loss = 0.08539309698235557
Trained batch 83 in epoch 3, gen_loss = 0.8420175438125929, disc_loss = 0.0852897044359928
Trained batch 84 in epoch 3, gen_loss = 0.8410195024574504, disc_loss = 0.08507191762328148
Trained batch 85 in epoch 3, gen_loss = 0.8435855906370074, disc_loss = 0.0847701958358981
Trained batch 86 in epoch 3, gen_loss = 0.8421496368687729, disc_loss = 0.08455904825836763
Trained batch 87 in epoch 3, gen_loss = 0.8396681699563157, disc_loss = 0.08480380115691911
Trained batch 88 in epoch 3, gen_loss = 0.8402421430925305, disc_loss = 0.08415910088865275
Trained batch 89 in epoch 3, gen_loss = 0.8417440000507567, disc_loss = 0.08417404250552257
Trained batch 90 in epoch 3, gen_loss = 0.8425925645854447, disc_loss = 0.0836146580935507
Trained batch 91 in epoch 3, gen_loss = 0.8406772415923036, disc_loss = 0.08361332351341844
Trained batch 92 in epoch 3, gen_loss = 0.8431491092328103, disc_loss = 0.08447325956677237
Trained batch 93 in epoch 3, gen_loss = 0.8439459543912968, disc_loss = 0.08398477754932135
Trained batch 94 in epoch 3, gen_loss = 0.8446510343175185, disc_loss = 0.08355420198487608
Trained batch 95 in epoch 3, gen_loss = 0.8422101149335504, disc_loss = 0.08421858879349504
Trained batch 96 in epoch 3, gen_loss = 0.8422384455646437, disc_loss = 0.08547416450359772
Trained batch 97 in epoch 3, gen_loss = 0.8406858234381189, disc_loss = 0.08522099976865005
Trained batch 98 in epoch 3, gen_loss = 0.8411576720801267, disc_loss = 0.08465174382383173
Trained batch 99 in epoch 3, gen_loss = 0.8431001052260398, disc_loss = 0.08439457174390555
Trained batch 100 in epoch 3, gen_loss = 0.8437202906254495, disc_loss = 0.08376664214647643
Trained batch 101 in epoch 3, gen_loss = 0.8425899840453092, disc_loss = 0.08322027044407293
Trained batch 102 in epoch 3, gen_loss = 0.8414154576445089, disc_loss = 0.08308376346542998
Trained batch 103 in epoch 3, gen_loss = 0.8389420122481309, disc_loss = 0.08340891232140936
Trained batch 104 in epoch 3, gen_loss = 0.8430663860979535, disc_loss = 0.0829021302362283
Trained batch 105 in epoch 3, gen_loss = 0.8444823569284295, disc_loss = 0.08287006697424178
Trained batch 106 in epoch 3, gen_loss = 0.8449762655752842, disc_loss = 0.08219409521634334
Trained batch 107 in epoch 3, gen_loss = 0.8447430423564382, disc_loss = 0.08167068943105361
Trained batch 108 in epoch 3, gen_loss = 0.8429114509613143, disc_loss = 0.08157541889936552
Trained batch 109 in epoch 3, gen_loss = 0.845079480247064, disc_loss = 0.0825501372191039
Trained batch 110 in epoch 3, gen_loss = 0.846327271278914, disc_loss = 0.0820144340899345
Trained batch 111 in epoch 3, gen_loss = 0.844329572947962, disc_loss = 0.08287783510916467
Trained batch 112 in epoch 3, gen_loss = 0.8461306039738444, disc_loss = 0.08276981951058966
Trained batch 113 in epoch 3, gen_loss = 0.8455611187637898, disc_loss = 0.08253392307577949
Trained batch 114 in epoch 3, gen_loss = 0.8457905735658563, disc_loss = 0.08246481572480305
Trained batch 115 in epoch 3, gen_loss = 0.844555716833164, disc_loss = 0.0823737272254095
Trained batch 116 in epoch 3, gen_loss = 0.8426153993504679, disc_loss = 0.08286188897859846
Trained batch 117 in epoch 3, gen_loss = 0.8452953431060759, disc_loss = 0.08319302009008193
Trained batch 118 in epoch 3, gen_loss = 0.8448109033227968, disc_loss = 0.08308983742877715
Trained batch 119 in epoch 3, gen_loss = 0.8414442643523217, disc_loss = 0.08440312474655608
Trained batch 120 in epoch 3, gen_loss = 0.8422741313611181, disc_loss = 0.08531967327306586
Trained batch 121 in epoch 3, gen_loss = 0.8407419553545655, disc_loss = 0.08517478716361229
Trained batch 122 in epoch 3, gen_loss = 0.840854267279307, disc_loss = 0.0846872558832411
Trained batch 123 in epoch 3, gen_loss = 0.842149029335668, disc_loss = 0.08492293504757746
Trained batch 124 in epoch 3, gen_loss = 0.8412798790931701, disc_loss = 0.0849345891624689
Trained batch 125 in epoch 3, gen_loss = 0.8411909431692154, disc_loss = 0.08481051378129494
Trained batch 126 in epoch 3, gen_loss = 0.8402909965027036, disc_loss = 0.08486852192092599
Trained batch 127 in epoch 3, gen_loss = 0.8402455667965114, disc_loss = 0.08448364654032048
Trained batch 128 in epoch 3, gen_loss = 0.8405111233393351, disc_loss = 0.08447851620383504
Trained batch 129 in epoch 3, gen_loss = 0.8440364645077632, disc_loss = 0.08528331562590141
Trained batch 130 in epoch 3, gen_loss = 0.8430908558932879, disc_loss = 0.08595152652843763
Trained batch 131 in epoch 3, gen_loss = 0.842061334938714, disc_loss = 0.08588066029672821
Trained batch 132 in epoch 3, gen_loss = 0.843340984412602, disc_loss = 0.08549148935292449
Trained batch 133 in epoch 3, gen_loss = 0.8429107092209717, disc_loss = 0.08687837904235765
Trained batch 134 in epoch 3, gen_loss = 0.8401229218200401, disc_loss = 0.08778976195112423
Trained batch 135 in epoch 3, gen_loss = 0.8390680735602098, disc_loss = 0.08791518040165744
Trained batch 136 in epoch 3, gen_loss = 0.8404630248564003, disc_loss = 0.0890317717363147
Trained batch 137 in epoch 3, gen_loss = 0.8398072853468467, disc_loss = 0.08874069298685029
Trained batch 138 in epoch 3, gen_loss = 0.8400712309123801, disc_loss = 0.08825195407856712
Trained batch 139 in epoch 3, gen_loss = 0.8378757600273404, disc_loss = 0.08865928100422024
Trained batch 140 in epoch 3, gen_loss = 0.8366708793538682, disc_loss = 0.0886424801953084
Trained batch 141 in epoch 3, gen_loss = 0.8369629114446505, disc_loss = 0.0884483268117191
Trained batch 142 in epoch 3, gen_loss = 0.838576150107217, disc_loss = 0.08821831459921974
Trained batch 143 in epoch 3, gen_loss = 0.8378841239545081, disc_loss = 0.08809492554670821
Trained batch 144 in epoch 3, gen_loss = 0.837771762239522, disc_loss = 0.0880140356334119
Trained batch 145 in epoch 3, gen_loss = 0.8374402004562013, disc_loss = 0.08786892899860667
Trained batch 146 in epoch 3, gen_loss = 0.8366197712567388, disc_loss = 0.08771423892859294
Trained batch 147 in epoch 3, gen_loss = 0.8370159928863113, disc_loss = 0.08758871276183305
Trained batch 148 in epoch 3, gen_loss = 0.8384652793807471, disc_loss = 0.08720017148294305
Trained batch 149 in epoch 3, gen_loss = 0.8371529666582743, disc_loss = 0.08715407439817985
Trained batch 150 in epoch 3, gen_loss = 0.8377954178298546, disc_loss = 0.08674350968062483
Trained batch 151 in epoch 3, gen_loss = 0.8399369802914167, disc_loss = 0.08636390985185771
Trained batch 152 in epoch 3, gen_loss = 0.8404848949581969, disc_loss = 0.08606911210793686
Trained batch 153 in epoch 3, gen_loss = 0.8408464642314167, disc_loss = 0.08570679721071736
Trained batch 154 in epoch 3, gen_loss = 0.8411417418910611, disc_loss = 0.08532978081174435
Trained batch 155 in epoch 3, gen_loss = 0.8411776113968629, disc_loss = 0.08496173548822601
Trained batch 156 in epoch 3, gen_loss = 0.8392339519634369, disc_loss = 0.08525664877787137
Trained batch 157 in epoch 3, gen_loss = 0.8408684323105631, disc_loss = 0.08498494281091645
Trained batch 158 in epoch 3, gen_loss = 0.842313953915482, disc_loss = 0.0848652265567637
Trained batch 159 in epoch 3, gen_loss = 0.8407978974282742, disc_loss = 0.08502527374075726
Trained batch 160 in epoch 3, gen_loss = 0.8417014031676773, disc_loss = 0.08461887966725767
Trained batch 161 in epoch 3, gen_loss = 0.8414005747547856, disc_loss = 0.08433608118628647
Trained batch 162 in epoch 3, gen_loss = 0.8399859703391608, disc_loss = 0.08427328759221578
Trained batch 163 in epoch 3, gen_loss = 0.8394737905118523, disc_loss = 0.0841074625779761
Trained batch 164 in epoch 3, gen_loss = 0.8406967076388272, disc_loss = 0.08380788272303162
Trained batch 165 in epoch 3, gen_loss = 0.8416046672556774, disc_loss = 0.08355617596128259
Trained batch 166 in epoch 3, gen_loss = 0.8401561440108065, disc_loss = 0.08359329260796487
Trained batch 167 in epoch 3, gen_loss = 0.8409100763854527, disc_loss = 0.0833646996456775
Trained batch 168 in epoch 3, gen_loss = 0.8410856815484854, disc_loss = 0.08304168301573872
Trained batch 169 in epoch 3, gen_loss = 0.840628091727986, disc_loss = 0.08277324950870346
Trained batch 170 in epoch 3, gen_loss = 0.8398810492621528, disc_loss = 0.0826233326953057
Trained batch 171 in epoch 3, gen_loss = 0.8390901334757028, disc_loss = 0.08254533824185993
Trained batch 172 in epoch 3, gen_loss = 0.8391664293460074, disc_loss = 0.08224322453055079
Trained batch 173 in epoch 3, gen_loss = 0.8386126557985941, disc_loss = 0.08203051001604261
Trained batch 174 in epoch 3, gen_loss = 0.8383591982296535, disc_loss = 0.0822280322441033
Trained batch 175 in epoch 3, gen_loss = 0.8358927866951986, disc_loss = 0.08384345698339696
Trained batch 176 in epoch 3, gen_loss = 0.8377750387973031, disc_loss = 0.08383413014859803
Trained batch 177 in epoch 3, gen_loss = 0.8388735507981161, disc_loss = 0.08417661322720266
Trained batch 178 in epoch 3, gen_loss = 0.8374696074251357, disc_loss = 0.08456403618501551
Trained batch 179 in epoch 3, gen_loss = 0.8371540662315157, disc_loss = 0.08434982357753648
Trained batch 180 in epoch 3, gen_loss = 0.8363819662378638, disc_loss = 0.08481372958718084
Trained batch 181 in epoch 3, gen_loss = 0.8348566051367875, disc_loss = 0.08505096826907042
Trained batch 182 in epoch 3, gen_loss = 0.834215260594269, disc_loss = 0.08554021859429572
Trained batch 183 in epoch 3, gen_loss = 0.8326156482748364, disc_loss = 0.085800942843375
Trained batch 184 in epoch 3, gen_loss = 0.831992346531636, disc_loss = 0.08621586094031462
Trained batch 185 in epoch 3, gen_loss = 0.8319945623797755, disc_loss = 0.08596363900009021
Trained batch 186 in epoch 3, gen_loss = 0.8312803851091926, disc_loss = 0.08603144787690219
Trained batch 187 in epoch 3, gen_loss = 0.8324521095194715, disc_loss = 0.08588990228290254
Trained batch 188 in epoch 3, gen_loss = 0.8328391357704445, disc_loss = 0.08582054614705384
Trained batch 189 in epoch 3, gen_loss = 0.8320519748486971, disc_loss = 0.08578044662350102
Trained batch 190 in epoch 3, gen_loss = 0.8304069700665498, disc_loss = 0.085815867399358
Trained batch 191 in epoch 3, gen_loss = 0.8298224493240317, disc_loss = 0.08657127715802442
Trained batch 192 in epoch 3, gen_loss = 0.8289695502562844, disc_loss = 0.08687865606706995
Trained batch 193 in epoch 3, gen_loss = 0.8298918967394485, disc_loss = 0.0873986775650806
Trained batch 194 in epoch 3, gen_loss = 0.8309678077697754, disc_loss = 0.08709111008315515
Trained batch 195 in epoch 3, gen_loss = 0.8300923887564211, disc_loss = 0.08713034727629654
Trained batch 196 in epoch 3, gen_loss = 0.8309632824157095, disc_loss = 0.08674155477774778
Trained batch 197 in epoch 3, gen_loss = 0.831712349195673, disc_loss = 0.08645552264601745
Trained batch 198 in epoch 3, gen_loss = 0.8310423667107395, disc_loss = 0.08633881731979062
Trained batch 199 in epoch 3, gen_loss = 0.8308488550782204, disc_loss = 0.08622043434064836
Trained batch 200 in epoch 3, gen_loss = 0.8303693227506989, disc_loss = 0.08624857178059828
Trained batch 201 in epoch 3, gen_loss = 0.8307644479935712, disc_loss = 0.08601958320780408
Trained batch 202 in epoch 3, gen_loss = 0.8303099397955269, disc_loss = 0.08576854422523324
Trained batch 203 in epoch 3, gen_loss = 0.8295563275323194, disc_loss = 0.08614186713855494
Trained batch 204 in epoch 3, gen_loss = 0.829034503494821, disc_loss = 0.08606917397914136
Trained batch 205 in epoch 3, gen_loss = 0.8285909682801627, disc_loss = 0.08599810451902087
Trained batch 206 in epoch 3, gen_loss = 0.8292336124152953, disc_loss = 0.08588892748300436
Trained batch 207 in epoch 3, gen_loss = 0.8294552524502461, disc_loss = 0.08559994526261178
Trained batch 208 in epoch 3, gen_loss = 0.8275308403672214, disc_loss = 0.08598751868410971
Trained batch 209 in epoch 3, gen_loss = 0.8268569429715474, disc_loss = 0.08574349922349765
Trained batch 210 in epoch 3, gen_loss = 0.8290259928499918, disc_loss = 0.08603790825700731
Trained batch 211 in epoch 3, gen_loss = 0.8288960569309738, disc_loss = 0.08611800120528436
Trained batch 212 in epoch 3, gen_loss = 0.8281525496585828, disc_loss = 0.08639284044486677
Trained batch 213 in epoch 3, gen_loss = 0.8282091962956937, disc_loss = 0.08609380015546333
Trained batch 214 in epoch 3, gen_loss = 0.8290144498958144, disc_loss = 0.08591654444070057
Trained batch 215 in epoch 3, gen_loss = 0.8278937828209665, disc_loss = 0.08594652056193876
Trained batch 216 in epoch 3, gen_loss = 0.829576394250316, disc_loss = 0.08602084800995852
Trained batch 217 in epoch 3, gen_loss = 0.8297078152862164, disc_loss = 0.08569934567299868
Trained batch 218 in epoch 3, gen_loss = 0.8303029316745393, disc_loss = 0.08557326938174495
Trained batch 219 in epoch 3, gen_loss = 0.8291443212465807, disc_loss = 0.08554053316316144
Trained batch 220 in epoch 3, gen_loss = 0.8292136340659129, disc_loss = 0.08545125356340165
Trained batch 221 in epoch 3, gen_loss = 0.8284266046038619, disc_loss = 0.08527095987973315
Trained batch 222 in epoch 3, gen_loss = 0.8307314386816838, disc_loss = 0.08544721734613982
Trained batch 223 in epoch 3, gen_loss = 0.8301181625574827, disc_loss = 0.0854906951634413
Trained batch 224 in epoch 3, gen_loss = 0.829609157509274, disc_loss = 0.08543525612602632
Trained batch 225 in epoch 3, gen_loss = 0.8314908814113752, disc_loss = 0.08570354335850715
Trained batch 226 in epoch 3, gen_loss = 0.8309436556001066, disc_loss = 0.08565123237685879
Trained batch 227 in epoch 3, gen_loss = 0.8302990948421913, disc_loss = 0.08580811295184519
Trained batch 228 in epoch 3, gen_loss = 0.8302212242996849, disc_loss = 0.08576435195160094
Trained batch 229 in epoch 3, gen_loss = 0.8307389013145281, disc_loss = 0.08612746893954666
Trained batch 230 in epoch 3, gen_loss = 0.8292656115123204, disc_loss = 0.08680432847422825
Trained batch 231 in epoch 3, gen_loss = 0.8293886087064085, disc_loss = 0.08668379363170343
Trained batch 232 in epoch 3, gen_loss = 0.8304722856554351, disc_loss = 0.08644662285423457
Trained batch 233 in epoch 3, gen_loss = 0.8307161369384863, disc_loss = 0.08619896862576278
Trained batch 234 in epoch 3, gen_loss = 0.830560395311802, disc_loss = 0.08613628078093555
Trained batch 235 in epoch 3, gen_loss = 0.8303590358818992, disc_loss = 0.08629222333005046
Trained batch 236 in epoch 3, gen_loss = 0.830415419385403, disc_loss = 0.08610255048386281
Trained batch 237 in epoch 3, gen_loss = 0.8302867157118661, disc_loss = 0.0858335712838511
Trained batch 238 in epoch 3, gen_loss = 0.8297582774980298, disc_loss = 0.08590834431552861
Trained batch 239 in epoch 3, gen_loss = 0.8295187210043271, disc_loss = 0.0857989096043942
Trained batch 240 in epoch 3, gen_loss = 0.829431374290672, disc_loss = 0.08570165103262761
Trained batch 241 in epoch 3, gen_loss = 0.830188402213341, disc_loss = 0.08559424280427581
Trained batch 242 in epoch 3, gen_loss = 0.8301182087556815, disc_loss = 0.08543808739479064
Trained batch 243 in epoch 3, gen_loss = 0.8289032314644486, disc_loss = 0.08558622246501266
Trained batch 244 in epoch 3, gen_loss = 0.8287756124321295, disc_loss = 0.08581024407960322
Trained batch 245 in epoch 3, gen_loss = 0.8290212907926823, disc_loss = 0.08565170055527876
Trained batch 246 in epoch 3, gen_loss = 0.8289146838400528, disc_loss = 0.08544713995883219
Trained batch 247 in epoch 3, gen_loss = 0.8301384458618779, disc_loss = 0.08570374098921855
Trained batch 248 in epoch 3, gen_loss = 0.8301666343068502, disc_loss = 0.08562224975835726
Trained batch 249 in epoch 3, gen_loss = 0.8296532697677612, disc_loss = 0.08550816270336509
Trained batch 250 in epoch 3, gen_loss = 0.8302574969857812, disc_loss = 0.08574855674533137
Trained batch 251 in epoch 3, gen_loss = 0.8291589631920769, disc_loss = 0.08581598915736235
Trained batch 252 in epoch 3, gen_loss = 0.8297891786447156, disc_loss = 0.08575275966993316
Trained batch 253 in epoch 3, gen_loss = 0.8300841037682661, disc_loss = 0.08600066968525841
Trained batch 254 in epoch 3, gen_loss = 0.8303748413628222, disc_loss = 0.0858884737443398
Trained batch 255 in epoch 3, gen_loss = 0.8290856394451112, disc_loss = 0.08600294793359353
Trained batch 256 in epoch 3, gen_loss = 0.8286159829406887, disc_loss = 0.08581215264601814
Trained batch 257 in epoch 3, gen_loss = 0.8289907396763794, disc_loss = 0.08560246540695544
Trained batch 258 in epoch 3, gen_loss = 0.828971702850003, disc_loss = 0.0854213167823362
Trained batch 259 in epoch 3, gen_loss = 0.8279880122496531, disc_loss = 0.08548490373202815
Trained batch 260 in epoch 3, gen_loss = 0.8286296645343532, disc_loss = 0.08552661943124515
Trained batch 261 in epoch 3, gen_loss = 0.8279907596475296, disc_loss = 0.08581476942600526
Trained batch 262 in epoch 3, gen_loss = 0.826977311205048, disc_loss = 0.08574711471555238
Trained batch 263 in epoch 3, gen_loss = 0.8282390640992107, disc_loss = 0.08603144860050331
Trained batch 264 in epoch 3, gen_loss = 0.8279116135723186, disc_loss = 0.08592474818721695
Trained batch 265 in epoch 3, gen_loss = 0.827446935320259, disc_loss = 0.08581736530842525
Trained batch 266 in epoch 3, gen_loss = 0.8286517568295368, disc_loss = 0.08562173608913738
Trained batch 267 in epoch 3, gen_loss = 0.8280556333153996, disc_loss = 0.08549186584206103
Trained batch 268 in epoch 3, gen_loss = 0.8286278484922359, disc_loss = 0.08523748865953498
Trained batch 269 in epoch 3, gen_loss = 0.8282482855849795, disc_loss = 0.08501164047737364
Trained batch 270 in epoch 3, gen_loss = 0.8272244527771024, disc_loss = 0.08493399692568722
Trained batch 271 in epoch 3, gen_loss = 0.826519454445909, disc_loss = 0.08505805163740125
Trained batch 272 in epoch 3, gen_loss = 0.8264843111946469, disc_loss = 0.08521227656962561
Trained batch 273 in epoch 3, gen_loss = 0.8257025976250641, disc_loss = 0.08516371340905554
Trained batch 274 in epoch 3, gen_loss = 0.8261655556071889, disc_loss = 0.08492223574017936
Trained batch 275 in epoch 3, gen_loss = 0.826390141810196, disc_loss = 0.08468479957040129
Trained batch 276 in epoch 3, gen_loss = 0.8253776149198897, disc_loss = 0.0846303158846519
Trained batch 277 in epoch 3, gen_loss = 0.8257463913169696, disc_loss = 0.08441375152764025
Trained batch 278 in epoch 3, gen_loss = 0.8263882659242144, disc_loss = 0.08452271389371072
Trained batch 279 in epoch 3, gen_loss = 0.8262825007949557, disc_loss = 0.08434485631795334
Trained batch 280 in epoch 3, gen_loss = 0.8254917467616206, disc_loss = 0.08440306515920099
Trained batch 281 in epoch 3, gen_loss = 0.8267115842788777, disc_loss = 0.08419429303100663
Trained batch 282 in epoch 3, gen_loss = 0.8275191562757054, disc_loss = 0.08408662411894373
Trained batch 283 in epoch 3, gen_loss = 0.8277047494767418, disc_loss = 0.08388950458963887
Trained batch 284 in epoch 3, gen_loss = 0.8266120753790203, disc_loss = 0.08397545854708081
Trained batch 285 in epoch 3, gen_loss = 0.8273116402275913, disc_loss = 0.08373797136860398
Trained batch 286 in epoch 3, gen_loss = 0.8266858119997829, disc_loss = 0.0839701576729529
Trained batch 287 in epoch 3, gen_loss = 0.8268349046508471, disc_loss = 0.08380274938018475
Trained batch 288 in epoch 3, gen_loss = 0.8267991864557497, disc_loss = 0.08361121743053816
Trained batch 289 in epoch 3, gen_loss = 0.8275859092843943, disc_loss = 0.08339869895436126
Trained batch 290 in epoch 3, gen_loss = 0.8279337112846243, disc_loss = 0.08320485479502436
Trained batch 291 in epoch 3, gen_loss = 0.8280178941275975, disc_loss = 0.08319741958586423
Trained batch 292 in epoch 3, gen_loss = 0.8286086068625336, disc_loss = 0.08299857455881077
Trained batch 293 in epoch 3, gen_loss = 0.829881544826793, disc_loss = 0.08297708447148301
Trained batch 294 in epoch 3, gen_loss = 0.8286976845587715, disc_loss = 0.08331796404731981
Trained batch 295 in epoch 3, gen_loss = 0.8304922656231636, disc_loss = 0.08321634144207614
Trained batch 296 in epoch 3, gen_loss = 0.8307458506489442, disc_loss = 0.08304354561310927
Trained batch 297 in epoch 3, gen_loss = 0.8305456093293708, disc_loss = 0.08301878053282431
Trained batch 298 in epoch 3, gen_loss = 0.8306463654822729, disc_loss = 0.08280670185912911
Trained batch 299 in epoch 3, gen_loss = 0.8309132867058118, disc_loss = 0.08263869303278625
Trained batch 300 in epoch 3, gen_loss = 0.8315703616387821, disc_loss = 0.08240856935712586
Trained batch 301 in epoch 3, gen_loss = 0.8306438491636554, disc_loss = 0.0829630603902782
Trained batch 302 in epoch 3, gen_loss = 0.8319409982402726, disc_loss = 0.08304944597553499
Trained batch 303 in epoch 3, gen_loss = 0.8315763121568843, disc_loss = 0.08344230455297388
Trained batch 304 in epoch 3, gen_loss = 0.8301618913158042, disc_loss = 0.0839640025965503
Trained batch 305 in epoch 3, gen_loss = 0.8299560070622201, disc_loss = 0.08374357093247323
Trained batch 306 in epoch 3, gen_loss = 0.8302561296119753, disc_loss = 0.08356956301517907
Trained batch 307 in epoch 3, gen_loss = 0.8305863270705397, disc_loss = 0.08382523852073914
Trained batch 308 in epoch 3, gen_loss = 0.8296387925695833, disc_loss = 0.08417569606001322
Trained batch 309 in epoch 3, gen_loss = 0.829217047364481, disc_loss = 0.0842123960655543
Trained batch 310 in epoch 3, gen_loss = 0.8303884929974362, disc_loss = 0.0845727792003722
Trained batch 311 in epoch 3, gen_loss = 0.8302369449192133, disc_loss = 0.08454718217492485
Trained batch 312 in epoch 3, gen_loss = 0.8295578576695805, disc_loss = 0.08464163233534977
Trained batch 313 in epoch 3, gen_loss = 0.8293638849144529, disc_loss = 0.08464899636615233
Trained batch 314 in epoch 3, gen_loss = 0.8295900854799483, disc_loss = 0.08496876648730702
Trained batch 315 in epoch 3, gen_loss = 0.8285361709474008, disc_loss = 0.08540209063293436
Trained batch 316 in epoch 3, gen_loss = 0.8282253943407197, disc_loss = 0.0852844208502431
Trained batch 317 in epoch 3, gen_loss = 0.8285959559791493, disc_loss = 0.08554415302878281
Trained batch 318 in epoch 3, gen_loss = 0.8290576985263526, disc_loss = 0.08548718610293812
Trained batch 319 in epoch 3, gen_loss = 0.8289533155038953, disc_loss = 0.08531721744220704
Trained batch 320 in epoch 3, gen_loss = 0.8282369741026857, disc_loss = 0.08528881979601405
Trained batch 321 in epoch 3, gen_loss = 0.8280464338589899, disc_loss = 0.08520175282907042
Trained batch 322 in epoch 3, gen_loss = 0.8287418473615735, disc_loss = 0.08562597445566957
Trained batch 323 in epoch 3, gen_loss = 0.8284960013848764, disc_loss = 0.08571653477387664
Trained batch 324 in epoch 3, gen_loss = 0.8277343170459454, disc_loss = 0.08591469017358927
Trained batch 325 in epoch 3, gen_loss = 0.8271516433522745, disc_loss = 0.08592211025441351
Trained batch 326 in epoch 3, gen_loss = 0.8264999920075092, disc_loss = 0.0860286953571375
Trained batch 327 in epoch 3, gen_loss = 0.8269227803116892, disc_loss = 0.08613336767728735
Trained batch 328 in epoch 3, gen_loss = 0.8271110816929478, disc_loss = 0.08590900586595289
Trained batch 329 in epoch 3, gen_loss = 0.8262193450421998, disc_loss = 0.08641168137617183
Trained batch 330 in epoch 3, gen_loss = 0.8260501563729116, disc_loss = 0.08627429488607403
Trained batch 331 in epoch 3, gen_loss = 0.826407073132963, disc_loss = 0.08643934199115239
Trained batch 332 in epoch 3, gen_loss = 0.8264497377135016, disc_loss = 0.08633867673598253
Trained batch 333 in epoch 3, gen_loss = 0.8264153289223859, disc_loss = 0.08627250966822315
Trained batch 334 in epoch 3, gen_loss = 0.8264731061992361, disc_loss = 0.08616790954968823
Trained batch 335 in epoch 3, gen_loss = 0.8262927966813246, disc_loss = 0.08608671714596096
Trained batch 336 in epoch 3, gen_loss = 0.8265348338585579, disc_loss = 0.0862096417418927
Trained batch 337 in epoch 3, gen_loss = 0.8278463551631341, disc_loss = 0.08616554340314583
Trained batch 338 in epoch 3, gen_loss = 0.8273572406585941, disc_loss = 0.08630687363204
Trained batch 339 in epoch 3, gen_loss = 0.8274226555052926, disc_loss = 0.08614455566686742
Trained batch 340 in epoch 3, gen_loss = 0.8269924841318662, disc_loss = 0.0864008630126103
Trained batch 341 in epoch 3, gen_loss = 0.8267751684662892, disc_loss = 0.08645096656523253
Trained batch 342 in epoch 3, gen_loss = 0.8269275885629237, disc_loss = 0.08624232172390375
Trained batch 343 in epoch 3, gen_loss = 0.8269766588197198, disc_loss = 0.08611987945677843
Trained batch 344 in epoch 3, gen_loss = 0.8279041734294615, disc_loss = 0.08616368846994811
Trained batch 345 in epoch 3, gen_loss = 0.8280356236964981, disc_loss = 0.0860603917578526
Trained batch 346 in epoch 3, gen_loss = 0.8272106125306671, disc_loss = 0.08609277476698847
Trained batch 347 in epoch 3, gen_loss = 0.8268342956729319, disc_loss = 0.08597987063560934
Trained batch 348 in epoch 3, gen_loss = 0.8271980265150097, disc_loss = 0.08610139133670183
Trained batch 349 in epoch 3, gen_loss = 0.8266351631709508, disc_loss = 0.08614218837182437
Trained batch 350 in epoch 3, gen_loss = 0.8270029182787295, disc_loss = 0.08613931896838962
Trained batch 351 in epoch 3, gen_loss = 0.8264984927055511, disc_loss = 0.0864011614175979
Trained batch 352 in epoch 3, gen_loss = 0.8264889951805893, disc_loss = 0.08622404039380993
Trained batch 353 in epoch 3, gen_loss = 0.8273558177180209, disc_loss = 0.08613895885067555
Trained batch 354 in epoch 3, gen_loss = 0.8285464217965032, disc_loss = 0.08612093437777858
Trained batch 355 in epoch 3, gen_loss = 0.8285407502664609, disc_loss = 0.08593529490283115
Trained batch 356 in epoch 3, gen_loss = 0.8280943683883389, disc_loss = 0.08606015477872112
Trained batch 357 in epoch 3, gen_loss = 0.8285495465694193, disc_loss = 0.0859335739004254
Trained batch 358 in epoch 3, gen_loss = 0.8286412471184159, disc_loss = 0.08587207682793933
Trained batch 359 in epoch 3, gen_loss = 0.8281148743298319, disc_loss = 0.08583955984407415
Trained batch 360 in epoch 3, gen_loss = 0.8280875879311496, disc_loss = 0.08586156884481785
Trained batch 361 in epoch 3, gen_loss = 0.8292477366344705, disc_loss = 0.08581065419721752
Trained batch 362 in epoch 3, gen_loss = 0.8290522801317788, disc_loss = 0.08585253193943708
Trained batch 363 in epoch 3, gen_loss = 0.8285407427248064, disc_loss = 0.08594564944352177
Trained batch 364 in epoch 3, gen_loss = 0.8283161098009919, disc_loss = 0.08593755587169977
Trained batch 365 in epoch 3, gen_loss = 0.8278938772899856, disc_loss = 0.0859972021766414
Trained batch 366 in epoch 3, gen_loss = 0.8285664212801152, disc_loss = 0.08714332890618157
Trained batch 367 in epoch 3, gen_loss = 0.8275133658848379, disc_loss = 0.08795157421390405
Trained batch 368 in epoch 3, gen_loss = 0.8284109739591758, disc_loss = 0.08819782720035735
Trained batch 369 in epoch 3, gen_loss = 0.8276326521828368, disc_loss = 0.08828909719564222
Trained batch 370 in epoch 3, gen_loss = 0.8267322291100443, disc_loss = 0.08864816633929219
Trained batch 371 in epoch 3, gen_loss = 0.8259336670399994, disc_loss = 0.08873251118817396
Trained batch 372 in epoch 3, gen_loss = 0.8260521446891509, disc_loss = 0.08868590538856891
Trained batch 373 in epoch 3, gen_loss = 0.8261745555356225, disc_loss = 0.08867844443439561
Trained batch 374 in epoch 3, gen_loss = 0.8253267789681753, disc_loss = 0.08882914326836666
Trained batch 375 in epoch 3, gen_loss = 0.8256326550023353, disc_loss = 0.08867289071674755
Trained batch 376 in epoch 3, gen_loss = 0.8257602577342279, disc_loss = 0.08856411062092064
Trained batch 377 in epoch 3, gen_loss = 0.8255041553072198, disc_loss = 0.08849014593386854
Trained batch 378 in epoch 3, gen_loss = 0.8252531194907066, disc_loss = 0.08854523966811342
Trained batch 379 in epoch 3, gen_loss = 0.8256235090525527, disc_loss = 0.08844631021401207
Trained batch 380 in epoch 3, gen_loss = 0.8250517387559094, disc_loss = 0.08862960019107331
Trained batch 381 in epoch 3, gen_loss = 0.8241258467211149, disc_loss = 0.08887130073978716
Trained batch 382 in epoch 3, gen_loss = 0.824071438521069, disc_loss = 0.08885516589337245
Trained batch 383 in epoch 3, gen_loss = 0.8236973348539323, disc_loss = 0.08891312055493472
Trained batch 384 in epoch 3, gen_loss = 0.8238939713348042, disc_loss = 0.08929150351504614
Trained batch 385 in epoch 3, gen_loss = 0.8232945380587652, disc_loss = 0.08936154347521114
Trained batch 386 in epoch 3, gen_loss = 0.8228695581279676, disc_loss = 0.08948918825944342
Trained batch 387 in epoch 3, gen_loss = 0.8231323420540574, disc_loss = 0.08956537729119594
Trained batch 388 in epoch 3, gen_loss = 0.8233554290468711, disc_loss = 0.08970328774015901
Trained batch 389 in epoch 3, gen_loss = 0.822648914425801, disc_loss = 0.0900053058225566
Trained batch 390 in epoch 3, gen_loss = 0.8231072716243432, disc_loss = 0.09013496601568236
Trained batch 391 in epoch 3, gen_loss = 0.8235646687752131, disc_loss = 0.09000284075784516
Trained batch 392 in epoch 3, gen_loss = 0.8232775657383237, disc_loss = 0.08985333386619052
Trained batch 393 in epoch 3, gen_loss = 0.82260936687743, disc_loss = 0.08984051859668139
Trained batch 394 in epoch 3, gen_loss = 0.8226938393297075, disc_loss = 0.08967966370614647
Trained batch 395 in epoch 3, gen_loss = 0.8231240042080783, disc_loss = 0.08965449815267941
Trained batch 396 in epoch 3, gen_loss = 0.8234004889537465, disc_loss = 0.08952727500274214
Trained batch 397 in epoch 3, gen_loss = 0.8235965129268829, disc_loss = 0.08932657192587554
Trained batch 398 in epoch 3, gen_loss = 0.8233405400188943, disc_loss = 0.08955106674168344
Trained batch 399 in epoch 3, gen_loss = 0.8226483020931482, disc_loss = 0.08969409727491438
Trained batch 400 in epoch 3, gen_loss = 0.822701546542365, disc_loss = 0.08975729581312349
Trained batch 401 in epoch 3, gen_loss = 0.8220693305208908, disc_loss = 0.0900088104312841
Trained batch 402 in epoch 3, gen_loss = 0.8220938517349233, disc_loss = 0.0899953209418369
Trained batch 403 in epoch 3, gen_loss = 0.8214382139025348, disc_loss = 0.09007231218943207
Trained batch 404 in epoch 3, gen_loss = 0.8211585338468905, disc_loss = 0.09009797406601316
Trained batch 405 in epoch 3, gen_loss = 0.8214879551984994, disc_loss = 0.09019431206650041
Trained batch 406 in epoch 3, gen_loss = 0.8210451701788704, disc_loss = 0.09020717175681996
Trained batch 407 in epoch 3, gen_loss = 0.8207344694026545, disc_loss = 0.09010476482046001
Trained batch 408 in epoch 3, gen_loss = 0.8206847918499944, disc_loss = 0.09006450392651966
Trained batch 409 in epoch 3, gen_loss = 0.8208055219272288, disc_loss = 0.09012466431027505
Trained batch 410 in epoch 3, gen_loss = 0.8206176603362508, disc_loss = 0.09007821326345714
Trained batch 411 in epoch 3, gen_loss = 0.8202046722318362, disc_loss = 0.09019739634710029
Trained batch 412 in epoch 3, gen_loss = 0.8201618818769155, disc_loss = 0.0904017832788659
Trained batch 413 in epoch 3, gen_loss = 0.8203991888369915, disc_loss = 0.09023139758962365
Trained batch 414 in epoch 3, gen_loss = 0.8205600026860295, disc_loss = 0.09007623408393688
Trained batch 415 in epoch 3, gen_loss = 0.8203883237706927, disc_loss = 0.09007044141001713
Trained batch 416 in epoch 3, gen_loss = 0.8199057036595379, disc_loss = 0.0899605950077089
Trained batch 417 in epoch 3, gen_loss = 0.820735653407836, disc_loss = 0.09006443573384765
Trained batch 418 in epoch 3, gen_loss = 0.8209681771962342, disc_loss = 0.08996472380575246
Trained batch 419 in epoch 3, gen_loss = 0.8208141832834198, disc_loss = 0.08989764071468796
Trained batch 420 in epoch 3, gen_loss = 0.821264218901795, disc_loss = 0.08972324947704895
Trained batch 421 in epoch 3, gen_loss = 0.8219305548763953, disc_loss = 0.08959541578393129
Trained batch 422 in epoch 3, gen_loss = 0.8219041014816744, disc_loss = 0.08951303808472118
Trained batch 423 in epoch 3, gen_loss = 0.821870901041998, disc_loss = 0.08946784633159074
Trained batch 424 in epoch 3, gen_loss = 0.8215058642976424, disc_loss = 0.08940800689599093
Trained batch 425 in epoch 3, gen_loss = 0.8215568744940377, disc_loss = 0.089268287888645
Trained batch 426 in epoch 3, gen_loss = 0.8219531408098878, disc_loss = 0.0891816281392926
Trained batch 427 in epoch 3, gen_loss = 0.8216595435950244, disc_loss = 0.08912120498368674
Trained batch 428 in epoch 3, gen_loss = 0.821794385329271, disc_loss = 0.08898156200967608
Trained batch 429 in epoch 3, gen_loss = 0.8213345664185147, disc_loss = 0.08895405288785696
Trained batch 430 in epoch 3, gen_loss = 0.8212474469104112, disc_loss = 0.08882777370823647
Trained batch 431 in epoch 3, gen_loss = 0.82072254691135, disc_loss = 0.08889098226144496
Trained batch 432 in epoch 3, gen_loss = 0.8225443380396581, disc_loss = 0.08932569859157946
Trained batch 433 in epoch 3, gen_loss = 0.8227801362078311, disc_loss = 0.08915270920542459
Trained batch 434 in epoch 3, gen_loss = 0.822801361755393, disc_loss = 0.08902924071740488
Trained batch 435 in epoch 3, gen_loss = 0.8225078225272511, disc_loss = 0.08894023433148246
Trained batch 436 in epoch 3, gen_loss = 0.8222576570047121, disc_loss = 0.08883506251239054
Trained batch 437 in epoch 3, gen_loss = 0.8223302320122174, disc_loss = 0.0886982160271677
Trained batch 438 in epoch 3, gen_loss = 0.8227754811626904, disc_loss = 0.08885839317367329
Trained batch 439 in epoch 3, gen_loss = 0.8225455444644798, disc_loss = 0.08888494318816811
Trained batch 440 in epoch 3, gen_loss = 0.8223031172000902, disc_loss = 0.08886338118886124
Trained batch 441 in epoch 3, gen_loss = 0.8219432371639018, disc_loss = 0.08892459712914144
Trained batch 442 in epoch 3, gen_loss = 0.8229656132699136, disc_loss = 0.08898677056945406
Trained batch 443 in epoch 3, gen_loss = 0.8228844629080446, disc_loss = 0.08896921429707594
Trained batch 444 in epoch 3, gen_loss = 0.8229394236977181, disc_loss = 0.08891266693852926
Trained batch 445 in epoch 3, gen_loss = 0.8232374937678666, disc_loss = 0.08911150174983881
Trained batch 446 in epoch 3, gen_loss = 0.8236033397099582, disc_loss = 0.08895044365243557
Trained batch 447 in epoch 3, gen_loss = 0.8229495636187494, disc_loss = 0.08918772178627218
Trained batch 448 in epoch 3, gen_loss = 0.8230800254971519, disc_loss = 0.0890489547162883
Trained batch 449 in epoch 3, gen_loss = 0.8237901500198577, disc_loss = 0.08947231722995638
Trained batch 450 in epoch 3, gen_loss = 0.8239496884879939, disc_loss = 0.08933599927811625
Trained batch 451 in epoch 3, gen_loss = 0.8233867875110786, disc_loss = 0.08932300759438194
Trained batch 452 in epoch 3, gen_loss = 0.823518701670712, disc_loss = 0.08921413329403198
Trained batch 453 in epoch 3, gen_loss = 0.8232828882165942, disc_loss = 0.08924219165087599
Trained batch 454 in epoch 3, gen_loss = 0.823982825580534, disc_loss = 0.08911416758015588
Trained batch 455 in epoch 3, gen_loss = 0.823796894139888, disc_loss = 0.08901859793542444
Trained batch 456 in epoch 3, gen_loss = 0.8237754529753712, disc_loss = 0.08889096160775918
Trained batch 457 in epoch 3, gen_loss = 0.8236304091444182, disc_loss = 0.08877192267448555
Trained batch 458 in epoch 3, gen_loss = 0.8237400882773929, disc_loss = 0.0886184763556959
Trained batch 459 in epoch 3, gen_loss = 0.8243293774516686, disc_loss = 0.08865579993302083
Trained batch 460 in epoch 3, gen_loss = 0.8246734097696954, disc_loss = 0.08848865678707651
Trained batch 461 in epoch 3, gen_loss = 0.8243793567150702, disc_loss = 0.0884436629813374
Trained batch 462 in epoch 3, gen_loss = 0.8238370977905347, disc_loss = 0.08846052148083695
Trained batch 463 in epoch 3, gen_loss = 0.8238894595796692, disc_loss = 0.08833293843781576
Trained batch 464 in epoch 3, gen_loss = 0.8240371589378644, disc_loss = 0.0881794579307078
Trained batch 465 in epoch 3, gen_loss = 0.8251915370062185, disc_loss = 0.08818810491307034
Trained batch 466 in epoch 3, gen_loss = 0.8251604142357502, disc_loss = 0.08802827146717963
Trained batch 467 in epoch 3, gen_loss = 0.8245100144010323, disc_loss = 0.08816393315752284
Trained batch 468 in epoch 3, gen_loss = 0.8247142204724903, disc_loss = 0.08837590584837234
Trained batch 469 in epoch 3, gen_loss = 0.8241771367636133, disc_loss = 0.08855388364853695
Trained batch 470 in epoch 3, gen_loss = 0.8242061542477578, disc_loss = 0.08845366636239736
Trained batch 471 in epoch 3, gen_loss = 0.8241351786685192, disc_loss = 0.0883632629411295
Trained batch 472 in epoch 3, gen_loss = 0.8245680417243321, disc_loss = 0.08834717021644682
Trained batch 473 in epoch 3, gen_loss = 0.8245383593477781, disc_loss = 0.08837091634128605
Trained batch 474 in epoch 3, gen_loss = 0.8244184662793812, disc_loss = 0.08849858378697383
Trained batch 475 in epoch 3, gen_loss = 0.8241312279045081, disc_loss = 0.08852362843081668
Trained batch 476 in epoch 3, gen_loss = 0.8242687097510452, disc_loss = 0.08839481914185565
Trained batch 477 in epoch 3, gen_loss = 0.8246249910054346, disc_loss = 0.0884596417057932
Trained batch 478 in epoch 3, gen_loss = 0.8248359138507684, disc_loss = 0.08832036858397324
Trained batch 479 in epoch 3, gen_loss = 0.8244994288310409, disc_loss = 0.08827944428000288
Trained batch 480 in epoch 3, gen_loss = 0.8240989950367418, disc_loss = 0.08818021511732603
Trained batch 481 in epoch 3, gen_loss = 0.8243167274844102, disc_loss = 0.08804444901266471
Trained batch 482 in epoch 3, gen_loss = 0.824363990168147, disc_loss = 0.08794443723292517
Trained batch 483 in epoch 3, gen_loss = 0.8239575150953836, disc_loss = 0.08800812578790874
Trained batch 484 in epoch 3, gen_loss = 0.8245945902829318, disc_loss = 0.08803559121358948
Trained batch 485 in epoch 3, gen_loss = 0.8251730693588532, disc_loss = 0.08796328627178637
Trained batch 486 in epoch 3, gen_loss = 0.8248479397512315, disc_loss = 0.08793253816274096
Trained batch 487 in epoch 3, gen_loss = 0.8245406506857911, disc_loss = 0.08807529260778464
Trained batch 488 in epoch 3, gen_loss = 0.8250356329365011, disc_loss = 0.0880451610784193
Trained batch 489 in epoch 3, gen_loss = 0.825413975362875, disc_loss = 0.08797389331026649
Trained batch 490 in epoch 3, gen_loss = 0.8251064230978125, disc_loss = 0.08789673608266833
Trained batch 491 in epoch 3, gen_loss = 0.8249327358070427, disc_loss = 0.08781543542721831
Trained batch 492 in epoch 3, gen_loss = 0.8246044086757103, disc_loss = 0.08769383559354843
Trained batch 493 in epoch 3, gen_loss = 0.8249299286710106, disc_loss = 0.08754415271298485
Trained batch 494 in epoch 3, gen_loss = 0.8254657679736012, disc_loss = 0.08742533569609878
Trained batch 495 in epoch 3, gen_loss = 0.8251894604895385, disc_loss = 0.08735646969533616
Trained batch 496 in epoch 3, gen_loss = 0.8251436889411458, disc_loss = 0.08727040710358673
Trained batch 497 in epoch 3, gen_loss = 0.825141033793549, disc_loss = 0.08726822615163513
Trained batch 498 in epoch 3, gen_loss = 0.8254686779751329, disc_loss = 0.08715472269228441
Trained batch 499 in epoch 3, gen_loss = 0.8250046921372414, disc_loss = 0.08710322162136436
Trained batch 500 in epoch 3, gen_loss = 0.8249636760609831, disc_loss = 0.08699368783263509
Trained batch 501 in epoch 3, gen_loss = 0.825049092866985, disc_loss = 0.08690154318330416
Trained batch 502 in epoch 3, gen_loss = 0.8249797925915917, disc_loss = 0.0870167011095148
Trained batch 503 in epoch 3, gen_loss = 0.8255852073549278, disc_loss = 0.08689416502602398
Trained batch 504 in epoch 3, gen_loss = 0.8255823971611438, disc_loss = 0.08675871049192282
Trained batch 505 in epoch 3, gen_loss = 0.8250658616364709, disc_loss = 0.08669767215509307
Trained batch 506 in epoch 3, gen_loss = 0.8253955655902095, disc_loss = 0.08664807035446284
Trained batch 507 in epoch 3, gen_loss = 0.8252766980078277, disc_loss = 0.08656803207970627
Trained batch 508 in epoch 3, gen_loss = 0.8254415207269852, disc_loss = 0.08655625770933384
Trained batch 509 in epoch 3, gen_loss = 0.8265110540039399, disc_loss = 0.08656035216488675
Trained batch 510 in epoch 3, gen_loss = 0.8265424358518156, disc_loss = 0.0864924143037509
Trained batch 511 in epoch 3, gen_loss = 0.8264393123681657, disc_loss = 0.08642311585208517
Trained batch 512 in epoch 3, gen_loss = 0.8271798289891107, disc_loss = 0.08630252733361883
Trained batch 513 in epoch 3, gen_loss = 0.8266373160168354, disc_loss = 0.08636494478797867
Trained batch 514 in epoch 3, gen_loss = 0.8269334269380106, disc_loss = 0.08622221087548629
Trained batch 515 in epoch 3, gen_loss = 0.8268795045193775, disc_loss = 0.08616922206837366
Trained batch 516 in epoch 3, gen_loss = 0.8267376104106755, disc_loss = 0.08610277858741106
Trained batch 517 in epoch 3, gen_loss = 0.827060384122101, disc_loss = 0.08602590833226054
Trained batch 518 in epoch 3, gen_loss = 0.827155232486927, disc_loss = 0.08592934717167607
Trained batch 519 in epoch 3, gen_loss = 0.8272254822919002, disc_loss = 0.08583632045819496
Trained batch 520 in epoch 3, gen_loss = 0.8269952318833108, disc_loss = 0.08579894807547217
Trained batch 521 in epoch 3, gen_loss = 0.8267584278094814, disc_loss = 0.08568317640280187
Trained batch 522 in epoch 3, gen_loss = 0.8271257605538997, disc_loss = 0.08586188042661029
Trained batch 523 in epoch 3, gen_loss = 0.8274018754827157, disc_loss = 0.08583969473732166
Trained batch 524 in epoch 3, gen_loss = 0.8268747670877548, disc_loss = 0.08592100431699129
Trained batch 525 in epoch 3, gen_loss = 0.8263404709871277, disc_loss = 0.0859722074266424
Trained batch 526 in epoch 3, gen_loss = 0.8263922328627765, disc_loss = 0.08610287853172031
Trained batch 527 in epoch 3, gen_loss = 0.8261713686427383, disc_loss = 0.08614271025660193
Trained batch 528 in epoch 3, gen_loss = 0.8264984670456055, disc_loss = 0.08611693375678786
Trained batch 529 in epoch 3, gen_loss = 0.8259549415898773, disc_loss = 0.08617245342828474
Trained batch 530 in epoch 3, gen_loss = 0.825437024207663, disc_loss = 0.08629772820722192
Trained batch 531 in epoch 3, gen_loss = 0.8252424126616994, disc_loss = 0.08626870448434991
Trained batch 532 in epoch 3, gen_loss = 0.8251395787463627, disc_loss = 0.0864191264574596
Trained batch 533 in epoch 3, gen_loss = 0.8247785863470048, disc_loss = 0.08638605103071095
Trained batch 534 in epoch 3, gen_loss = 0.8249997346757728, disc_loss = 0.08630116646151954
Trained batch 535 in epoch 3, gen_loss = 0.8248891793191433, disc_loss = 0.08622046658915203
Trained batch 536 in epoch 3, gen_loss = 0.8250071930818718, disc_loss = 0.08617845087639946
Trained batch 537 in epoch 3, gen_loss = 0.8254058010405324, disc_loss = 0.08622769729085406
Trained batch 538 in epoch 3, gen_loss = 0.8252692976223516, disc_loss = 0.0862521583124553
Trained batch 539 in epoch 3, gen_loss = 0.8250398122050144, disc_loss = 0.08635266246791515
Trained batch 540 in epoch 3, gen_loss = 0.825129192274291, disc_loss = 0.08634476947758257
Trained batch 541 in epoch 3, gen_loss = 0.8253889173489215, disc_loss = 0.08621690515256951
Trained batch 542 in epoch 3, gen_loss = 0.8262211448250555, disc_loss = 0.08618534557541925
Trained batch 543 in epoch 3, gen_loss = 0.826352174174698, disc_loss = 0.08611365189426579
Trained batch 544 in epoch 3, gen_loss = 0.8263191440236678, disc_loss = 0.08606358499462725
Trained batch 545 in epoch 3, gen_loss = 0.8266523801909261, disc_loss = 0.08592875072077572
Trained batch 546 in epoch 3, gen_loss = 0.8265881146656747, disc_loss = 0.08586071589808414
Trained batch 547 in epoch 3, gen_loss = 0.826420426205562, disc_loss = 0.08576284303588208
Trained batch 548 in epoch 3, gen_loss = 0.8271448673554891, disc_loss = 0.08571306961624185
Trained batch 549 in epoch 3, gen_loss = 0.8268662643974478, disc_loss = 0.08564598983831026
Trained batch 550 in epoch 3, gen_loss = 0.8272816239705753, disc_loss = 0.08566074643432824
Trained batch 551 in epoch 3, gen_loss = 0.8275989771861098, disc_loss = 0.08556253837752223
Trained batch 552 in epoch 3, gen_loss = 0.8273691573259412, disc_loss = 0.08559405043296799
Trained batch 553 in epoch 3, gen_loss = 0.8280174754264122, disc_loss = 0.08555476898192983
Trained batch 554 in epoch 3, gen_loss = 0.8279016138734044, disc_loss = 0.08542502579019144
Trained batch 555 in epoch 3, gen_loss = 0.8278464482520982, disc_loss = 0.08531302353199706
Trained batch 556 in epoch 3, gen_loss = 0.8273955025514538, disc_loss = 0.08526846462328996
Trained batch 557 in epoch 3, gen_loss = 0.8280556826288128, disc_loss = 0.08522092654640155
Trained batch 558 in epoch 3, gen_loss = 0.8279374942903228, disc_loss = 0.08514968493256937
Trained batch 559 in epoch 3, gen_loss = 0.8283519462283169, disc_loss = 0.085014167063803
Trained batch 560 in epoch 3, gen_loss = 0.8290086717422845, disc_loss = 0.08490095711387893
Trained batch 561 in epoch 3, gen_loss = 0.8289706415871284, disc_loss = 0.08480565169879178
Trained batch 562 in epoch 3, gen_loss = 0.8287488172892779, disc_loss = 0.08471717239650327
Trained batch 563 in epoch 3, gen_loss = 0.8289991274264688, disc_loss = 0.08462965978038701
Trained batch 564 in epoch 3, gen_loss = 0.8287319568933639, disc_loss = 0.08455019899998355
Trained batch 565 in epoch 3, gen_loss = 0.8290776479265294, disc_loss = 0.08470463082227238
Trained batch 566 in epoch 3, gen_loss = 0.8288160000633731, disc_loss = 0.0847705009966642
Trained batch 567 in epoch 3, gen_loss = 0.8293588555509775, disc_loss = 0.08474318467533137
Trained batch 568 in epoch 3, gen_loss = 0.8297280401567583, disc_loss = 0.08461422160077965
Trained batch 569 in epoch 3, gen_loss = 0.8294667365781048, disc_loss = 0.08456088769037211
Trained batch 570 in epoch 3, gen_loss = 0.8292555718726744, disc_loss = 0.08457055912824468
Trained batch 571 in epoch 3, gen_loss = 0.829430882382643, disc_loss = 0.08448955744758925
Trained batch 572 in epoch 3, gen_loss = 0.829206669985936, disc_loss = 0.08439201265280939
Trained batch 573 in epoch 3, gen_loss = 0.8302358673943875, disc_loss = 0.08459938229759344
Trained batch 574 in epoch 3, gen_loss = 0.8297762158124343, disc_loss = 0.08497637497828059
Trained batch 575 in epoch 3, gen_loss = 0.8298617266635928, disc_loss = 0.08519409315421297
Trained batch 576 in epoch 3, gen_loss = 0.8294100606978663, disc_loss = 0.08527605941089797
Trained batch 577 in epoch 3, gen_loss = 0.8291625925517, disc_loss = 0.08529062824852275
Trained batch 578 in epoch 3, gen_loss = 0.8286118025092057, disc_loss = 0.08540701858911644
Trained batch 579 in epoch 3, gen_loss = 0.8289693519473076, disc_loss = 0.0855196727038329
Trained batch 580 in epoch 3, gen_loss = 0.8287361380668187, disc_loss = 0.08547048253230045
Trained batch 581 in epoch 3, gen_loss = 0.82852336554388, disc_loss = 0.08539143010583479
Trained batch 582 in epoch 3, gen_loss = 0.8280788280235964, disc_loss = 0.08545097606943515
Trained batch 583 in epoch 3, gen_loss = 0.8281787014885308, disc_loss = 0.08566460952845287
Trained batch 584 in epoch 3, gen_loss = 0.8287607561319302, disc_loss = 0.08555333805867495
Trained batch 585 in epoch 3, gen_loss = 0.8281132482729674, disc_loss = 0.08576323799375737
Trained batch 586 in epoch 3, gen_loss = 0.828525065715715, disc_loss = 0.08584256909844772
Trained batch 587 in epoch 3, gen_loss = 0.8282687536814586, disc_loss = 0.08586965049426927
Trained batch 588 in epoch 3, gen_loss = 0.8285093448664013, disc_loss = 0.08599830917691487
Trained batch 589 in epoch 3, gen_loss = 0.8286240324630576, disc_loss = 0.08608038255439723
Trained batch 590 in epoch 3, gen_loss = 0.8283146043416812, disc_loss = 0.08606888816964556
Trained batch 591 in epoch 3, gen_loss = 0.8281655839669544, disc_loss = 0.08610383516045388
Trained batch 592 in epoch 3, gen_loss = 0.8281334540594689, disc_loss = 0.08607009717092094
Trained batch 593 in epoch 3, gen_loss = 0.8280675586325552, disc_loss = 0.08601203625269159
Trained batch 594 in epoch 3, gen_loss = 0.8279934156341713, disc_loss = 0.08594268745578387
Trained batch 595 in epoch 3, gen_loss = 0.8282769722926536, disc_loss = 0.08583935296269221
Trained batch 596 in epoch 3, gen_loss = 0.8282211422421025, disc_loss = 0.08580914520232671
Trained batch 597 in epoch 3, gen_loss = 0.827493259539971, disc_loss = 0.08618785157943001
Trained batch 598 in epoch 3, gen_loss = 0.8281959386819193, disc_loss = 0.08636432573765218
Trained batch 599 in epoch 3, gen_loss = 0.828276597559452, disc_loss = 0.08633859512551377
Trained batch 600 in epoch 3, gen_loss = 0.8278342126411526, disc_loss = 0.08652325995892485
Trained batch 601 in epoch 3, gen_loss = 0.8279334751276479, disc_loss = 0.08641451593346126
Trained batch 602 in epoch 3, gen_loss = 0.8277953591315109, disc_loss = 0.08635941307040343
Trained batch 603 in epoch 3, gen_loss = 0.8275836430835408, disc_loss = 0.08631644960930757
Trained batch 604 in epoch 3, gen_loss = 0.8276165766164291, disc_loss = 0.08624838699455842
Trained batch 605 in epoch 3, gen_loss = 0.8282303921263604, disc_loss = 0.08616454516177868
Trained batch 606 in epoch 3, gen_loss = 0.8282067051043817, disc_loss = 0.08609225788603259
Trained batch 607 in epoch 3, gen_loss = 0.8281423764205292, disc_loss = 0.08597693671809363
Trained batch 608 in epoch 3, gen_loss = 0.8280293365025951, disc_loss = 0.08588125803377877
Trained batch 609 in epoch 3, gen_loss = 0.8278229431050723, disc_loss = 0.08601821742371701
Trained batch 610 in epoch 3, gen_loss = 0.8278254068619686, disc_loss = 0.08596637333650295
Trained batch 611 in epoch 3, gen_loss = 0.8276668953544953, disc_loss = 0.08588876734256404
Trained batch 612 in epoch 3, gen_loss = 0.8279096812836303, disc_loss = 0.08579109622648694
Trained batch 613 in epoch 3, gen_loss = 0.8278772422273306, disc_loss = 0.0857091077560929
Trained batch 614 in epoch 3, gen_loss = 0.8276841499941135, disc_loss = 0.08566854275248158
Trained batch 615 in epoch 3, gen_loss = 0.8279379044066776, disc_loss = 0.08555409481730795
Trained batch 616 in epoch 3, gen_loss = 0.8279689708830279, disc_loss = 0.08548769258367232
Trained batch 617 in epoch 3, gen_loss = 0.8279407183522159, disc_loss = 0.08540040662837695
Trained batch 618 in epoch 3, gen_loss = 0.8275598051667405, disc_loss = 0.08545246605516106
Trained batch 619 in epoch 3, gen_loss = 0.8270784989480049, disc_loss = 0.08546888704051174
Trained batch 620 in epoch 3, gen_loss = 0.8277888981424476, disc_loss = 0.08570611799186795
Trained batch 621 in epoch 3, gen_loss = 0.8281103044844134, disc_loss = 0.08564223142017362
Trained batch 622 in epoch 3, gen_loss = 0.828074917173309, disc_loss = 0.08573865348900733
Trained batch 623 in epoch 3, gen_loss = 0.8274827212668382, disc_loss = 0.08620025737073798
Trained batch 624 in epoch 3, gen_loss = 0.8280097640037537, disc_loss = 0.08615551145225764
Trained batch 625 in epoch 3, gen_loss = 0.828335091995355, disc_loss = 0.08606874250238553
Trained batch 626 in epoch 3, gen_loss = 0.8286316829244866, disc_loss = 0.08612495104810505
Trained batch 627 in epoch 3, gen_loss = 0.8280773078370246, disc_loss = 0.08626632978635466
Trained batch 628 in epoch 3, gen_loss = 0.8279919710561088, disc_loss = 0.08621061952349349
Trained batch 629 in epoch 3, gen_loss = 0.828505536961177, disc_loss = 0.08630696563641467
Trained batch 630 in epoch 3, gen_loss = 0.8280991016401542, disc_loss = 0.08636403712111919
Trained batch 631 in epoch 3, gen_loss = 0.8279644944999791, disc_loss = 0.0863170004228743
Trained batch 632 in epoch 3, gen_loss = 0.8276764035789888, disc_loss = 0.08630695419553755
Trained batch 633 in epoch 3, gen_loss = 0.8275444337434197, disc_loss = 0.08624273147992202
Trained batch 634 in epoch 3, gen_loss = 0.8277508091738843, disc_loss = 0.08678416966013316
Trained batch 635 in epoch 3, gen_loss = 0.8279764952149781, disc_loss = 0.08672863916997686
Trained batch 636 in epoch 3, gen_loss = 0.8277020238258026, disc_loss = 0.08674557808365561
Trained batch 637 in epoch 3, gen_loss = 0.8274522074337664, disc_loss = 0.08681251792540791
Trained batch 638 in epoch 3, gen_loss = 0.8277483934154719, disc_loss = 0.0869591411200231
Trained batch 639 in epoch 3, gen_loss = 0.8274036926217377, disc_loss = 0.0870338644090225
Trained batch 640 in epoch 3, gen_loss = 0.827431820019173, disc_loss = 0.08694041482435885
Trained batch 641 in epoch 3, gen_loss = 0.8274954561132508, disc_loss = 0.08695032653424924
Trained batch 642 in epoch 3, gen_loss = 0.8275627858160443, disc_loss = 0.08691461954822019
Trained batch 643 in epoch 3, gen_loss = 0.8271534345720125, disc_loss = 0.08697902444050132
Trained batch 644 in epoch 3, gen_loss = 0.8267496830733247, disc_loss = 0.08706193885571042
Trained batch 645 in epoch 3, gen_loss = 0.8267235452361151, disc_loss = 0.08705357383019738
Trained batch 646 in epoch 3, gen_loss = 0.8267716909118192, disc_loss = 0.08695891264169671
Trained batch 647 in epoch 3, gen_loss = 0.8266864553277875, disc_loss = 0.0868717123147813
Trained batch 648 in epoch 3, gen_loss = 0.8266639932645672, disc_loss = 0.08688809506405713
Trained batch 649 in epoch 3, gen_loss = 0.8263390763906332, disc_loss = 0.08697786061379773
Trained batch 650 in epoch 3, gen_loss = 0.8261021643007223, disc_loss = 0.0870314596804537
Trained batch 651 in epoch 3, gen_loss = 0.8261823798615509, disc_loss = 0.08701189283561533
Trained batch 652 in epoch 3, gen_loss = 0.8261535874187125, disc_loss = 0.0871149933473371
Trained batch 653 in epoch 3, gen_loss = 0.8257573857584496, disc_loss = 0.08719969227118275
Trained batch 654 in epoch 3, gen_loss = 0.8256494780533187, disc_loss = 0.08718575638015079
Trained batch 655 in epoch 3, gen_loss = 0.8257046812554685, disc_loss = 0.08710812232258343
Trained batch 656 in epoch 3, gen_loss = 0.8255023237777083, disc_loss = 0.08729246887130325
Trained batch 657 in epoch 3, gen_loss = 0.8250979000311854, disc_loss = 0.0875006780993635
Trained batch 658 in epoch 3, gen_loss = 0.8251217665187506, disc_loss = 0.08748958577657731
Trained batch 659 in epoch 3, gen_loss = 0.8254130401394584, disc_loss = 0.0875441165711505
Trained batch 660 in epoch 3, gen_loss = 0.8252057542238221, disc_loss = 0.08746490190890525
Trained batch 661 in epoch 3, gen_loss = 0.8247904398470126, disc_loss = 0.08742106190018828
Trained batch 662 in epoch 3, gen_loss = 0.8247540288381447, disc_loss = 0.08736887582764591
Trained batch 663 in epoch 3, gen_loss = 0.8249974241816854, disc_loss = 0.08742758779399411
Trained batch 664 in epoch 3, gen_loss = 0.8250469326076652, disc_loss = 0.08734887226771815
Trained batch 665 in epoch 3, gen_loss = 0.824793720657045, disc_loss = 0.0873344006651716
Trained batch 666 in epoch 3, gen_loss = 0.8248334524334817, disc_loss = 0.08739294193411383
Trained batch 667 in epoch 3, gen_loss = 0.8245757011596314, disc_loss = 0.08745422460902817
Trained batch 668 in epoch 3, gen_loss = 0.8244003421878957, disc_loss = 0.08745437817194225
Trained batch 669 in epoch 3, gen_loss = 0.8248576394657591, disc_loss = 0.08735287302493382
Trained batch 670 in epoch 3, gen_loss = 0.825242976229166, disc_loss = 0.08740949090681248
Trained batch 671 in epoch 3, gen_loss = 0.8250678929367236, disc_loss = 0.08739057989996149
Trained batch 672 in epoch 3, gen_loss = 0.8248527630122952, disc_loss = 0.08738929099288463
Trained batch 673 in epoch 3, gen_loss = 0.8250264671329929, disc_loss = 0.08732374856602235
Trained batch 674 in epoch 3, gen_loss = 0.824975036073614, disc_loss = 0.08732772305745769
Trained batch 675 in epoch 3, gen_loss = 0.8248120298576073, disc_loss = 0.08725835314191349
Trained batch 676 in epoch 3, gen_loss = 0.824474451813071, disc_loss = 0.08723664119360938
Trained batch 677 in epoch 3, gen_loss = 0.8251092826018994, disc_loss = 0.08721619890178595
Trained batch 678 in epoch 3, gen_loss = 0.8253280015687001, disc_loss = 0.08714918857673526
Trained batch 679 in epoch 3, gen_loss = 0.8250266360009417, disc_loss = 0.08721382488250075
Trained batch 680 in epoch 3, gen_loss = 0.8246928883194048, disc_loss = 0.08722810490568347
Trained batch 681 in epoch 3, gen_loss = 0.8250898090450645, disc_loss = 0.0872714543275404
Trained batch 682 in epoch 3, gen_loss = 0.8251902740312356, disc_loss = 0.08726590808131902
Trained batch 683 in epoch 3, gen_loss = 0.8252008915470358, disc_loss = 0.08720845601804642
Trained batch 684 in epoch 3, gen_loss = 0.8247420463248761, disc_loss = 0.08719085835763356
Trained batch 685 in epoch 3, gen_loss = 0.8254666337987772, disc_loss = 0.08714442385317155
Trained batch 686 in epoch 3, gen_loss = 0.8254117277685384, disc_loss = 0.08704853651765869
Trained batch 687 in epoch 3, gen_loss = 0.8252733265764491, disc_loss = 0.08697256642572451
Trained batch 688 in epoch 3, gen_loss = 0.8252467703404032, disc_loss = 0.08689281226139846
Trained batch 689 in epoch 3, gen_loss = 0.8252136243426281, disc_loss = 0.0868322954243184
Trained batch 690 in epoch 3, gen_loss = 0.8252895018988856, disc_loss = 0.08675639406951784
Trained batch 691 in epoch 3, gen_loss = 0.8254010755719478, disc_loss = 0.08665127727079254
Trained batch 692 in epoch 3, gen_loss = 0.8251912322911349, disc_loss = 0.08658935553239709
Trained batch 693 in epoch 3, gen_loss = 0.8255054013701612, disc_loss = 0.08652588964496291
Trained batch 694 in epoch 3, gen_loss = 0.8254246037641018, disc_loss = 0.08644513288955037
Trained batch 695 in epoch 3, gen_loss = 0.8254272548974245, disc_loss = 0.08634522025227204
Trained batch 696 in epoch 3, gen_loss = 0.8257025576048295, disc_loss = 0.08624427887735357
Trained batch 697 in epoch 3, gen_loss = 0.8255654342878173, disc_loss = 0.08622751610465668
Trained batch 698 in epoch 3, gen_loss = 0.825597216557706, disc_loss = 0.08612703658821587
Trained batch 699 in epoch 3, gen_loss = 0.8262051659822464, disc_loss = 0.0862186539386
Trained batch 700 in epoch 3, gen_loss = 0.8262293812381728, disc_loss = 0.08620820525029246
Trained batch 701 in epoch 3, gen_loss = 0.8259408966428534, disc_loss = 0.08633624594605546
Trained batch 702 in epoch 3, gen_loss = 0.825936622673892, disc_loss = 0.08632862186364056
Trained batch 703 in epoch 3, gen_loss = 0.8260075044394894, disc_loss = 0.08639147843826901
Trained batch 704 in epoch 3, gen_loss = 0.8259023219981092, disc_loss = 0.08639570068805776
Trained batch 705 in epoch 3, gen_loss = 0.8255219061043715, disc_loss = 0.08653626278591561
Trained batch 706 in epoch 3, gen_loss = 0.8255107278871064, disc_loss = 0.08645875045905863
Trained batch 707 in epoch 3, gen_loss = 0.8254450056175727, disc_loss = 0.0864230578838937
Trained batch 708 in epoch 3, gen_loss = 0.8256683295805465, disc_loss = 0.08631974395117571
Trained batch 709 in epoch 3, gen_loss = 0.8256933826795766, disc_loss = 0.08623649882493724
Trained batch 710 in epoch 3, gen_loss = 0.8257969710058971, disc_loss = 0.08613865102121264
Trained batch 711 in epoch 3, gen_loss = 0.826184087924743, disc_loss = 0.0860650723831456
Trained batch 712 in epoch 3, gen_loss = 0.8260080974867768, disc_loss = 0.08606050757568481
Trained batch 713 in epoch 3, gen_loss = 0.8261384627565282, disc_loss = 0.0860524090888704
Trained batch 714 in epoch 3, gen_loss = 0.8263028770893603, disc_loss = 0.08610784100381644
Trained batch 715 in epoch 3, gen_loss = 0.8259472382468218, disc_loss = 0.0865652740740493
Trained batch 716 in epoch 3, gen_loss = 0.8260791073949434, disc_loss = 0.08657492467071055
Trained batch 717 in epoch 3, gen_loss = 0.8261846956436348, disc_loss = 0.08656136817649049
Trained batch 718 in epoch 3, gen_loss = 0.8261996733130931, disc_loss = 0.08650166475018474
Trained batch 719 in epoch 3, gen_loss = 0.8256998086141215, disc_loss = 0.08666136766680413
Trained batch 720 in epoch 3, gen_loss = 0.8255659737798609, disc_loss = 0.08664083708175839
Trained batch 721 in epoch 3, gen_loss = 0.8261412792423756, disc_loss = 0.08665698413786135
Trained batch 722 in epoch 3, gen_loss = 0.8260624304022202, disc_loss = 0.08668585570933578
Trained batch 723 in epoch 3, gen_loss = 0.8258933857988916, disc_loss = 0.08666545128995214
Trained batch 724 in epoch 3, gen_loss = 0.826052256945906, disc_loss = 0.08657081389735485
Trained batch 725 in epoch 3, gen_loss = 0.8257934867350523, disc_loss = 0.0865227591923692
Trained batch 726 in epoch 3, gen_loss = 0.8259252871411047, disc_loss = 0.08644944524195204
Trained batch 727 in epoch 3, gen_loss = 0.8261619021113102, disc_loss = 0.08637545002972359
Trained batch 728 in epoch 3, gen_loss = 0.8260989202229901, disc_loss = 0.08635081356935541
Trained batch 729 in epoch 3, gen_loss = 0.8263437555260854, disc_loss = 0.08625540415922256
Trained batch 730 in epoch 3, gen_loss = 0.8268737404845482, disc_loss = 0.08628348847175916
Trained batch 731 in epoch 3, gen_loss = 0.8271858835480904, disc_loss = 0.08620719729205135
Trained batch 732 in epoch 3, gen_loss = 0.8266087467966431, disc_loss = 0.08637226253524322
Trained batch 733 in epoch 3, gen_loss = 0.8265668432296784, disc_loss = 0.0863076084082799
Trained batch 734 in epoch 3, gen_loss = 0.8265990307541932, disc_loss = 0.08624516670294359
Trained batch 735 in epoch 3, gen_loss = 0.8264379087511612, disc_loss = 0.08619589052345279
Trained batch 736 in epoch 3, gen_loss = 0.8270478556728751, disc_loss = 0.08629173052015751
Trained batch 737 in epoch 3, gen_loss = 0.8273392919763963, disc_loss = 0.08623040442766375
Trained batch 738 in epoch 3, gen_loss = 0.8271736868018227, disc_loss = 0.08614493778708904
Trained batch 739 in epoch 3, gen_loss = 0.8271119072630598, disc_loss = 0.08613677507367086
Trained batch 740 in epoch 3, gen_loss = 0.8269401153250423, disc_loss = 0.08613129090090432
Trained batch 741 in epoch 3, gen_loss = 0.8271098727325223, disc_loss = 0.08627191193231112
Trained batch 742 in epoch 3, gen_loss = 0.8271810775008529, disc_loss = 0.08620375456240825
Trained batch 743 in epoch 3, gen_loss = 0.8270207436014247, disc_loss = 0.08623613644721767
Trained batch 744 in epoch 3, gen_loss = 0.8268462119486508, disc_loss = 0.08616432280798486
Trained batch 745 in epoch 3, gen_loss = 0.8265650395413826, disc_loss = 0.08625385482063962
Trained batch 746 in epoch 3, gen_loss = 0.8262673520658869, disc_loss = 0.08643743760105836
Trained batch 747 in epoch 3, gen_loss = 0.8267392175082855, disc_loss = 0.08638871380720627
Trained batch 748 in epoch 3, gen_loss = 0.8266703698122613, disc_loss = 0.08630244522660135
Trained batch 749 in epoch 3, gen_loss = 0.8268879318237304, disc_loss = 0.08620624199757973
Trained batch 750 in epoch 3, gen_loss = 0.8265721759846938, disc_loss = 0.08621874204855387
Trained batch 751 in epoch 3, gen_loss = 0.8265487088802013, disc_loss = 0.08613109936630552
Trained batch 752 in epoch 3, gen_loss = 0.8266922398550736, disc_loss = 0.08618162657724196
Trained batch 753 in epoch 3, gen_loss = 0.826647456112844, disc_loss = 0.08611218337048665
Trained batch 754 in epoch 3, gen_loss = 0.8265077700678086, disc_loss = 0.08607445425101069
Trained batch 755 in epoch 3, gen_loss = 0.826567622483092, disc_loss = 0.08598297835381889
Trained batch 756 in epoch 3, gen_loss = 0.8266900254996639, disc_loss = 0.08590384035849823
Trained batch 757 in epoch 3, gen_loss = 0.8266281020043708, disc_loss = 0.08584126383852518
Trained batch 758 in epoch 3, gen_loss = 0.8270200172117733, disc_loss = 0.08579209858210504
Trained batch 759 in epoch 3, gen_loss = 0.8268861866311024, disc_loss = 0.08576464176570114
Trained batch 760 in epoch 3, gen_loss = 0.8265882425019995, disc_loss = 0.08575932141124185
Trained batch 761 in epoch 3, gen_loss = 0.8265338648022629, disc_loss = 0.08580441542184884
Trained batch 762 in epoch 3, gen_loss = 0.8267482245733978, disc_loss = 0.08575179073886352
Trained batch 763 in epoch 3, gen_loss = 0.8267948430870216, disc_loss = 0.08570663917673196
Trained batch 764 in epoch 3, gen_loss = 0.8264378366906658, disc_loss = 0.08575687530188779
Trained batch 765 in epoch 3, gen_loss = 0.8261262329377954, disc_loss = 0.08568381726031749
Trained batch 766 in epoch 3, gen_loss = 0.8267064299701556, disc_loss = 0.08562664391115948
Trained batch 767 in epoch 3, gen_loss = 0.8271190837646524, disc_loss = 0.08556557405245258
Trained batch 768 in epoch 3, gen_loss = 0.8273494197116251, disc_loss = 0.08546974387392886
Trained batch 769 in epoch 3, gen_loss = 0.8274881400845268, disc_loss = 0.08544352440187683
Trained batch 770 in epoch 3, gen_loss = 0.8273367030611298, disc_loss = 0.08542986854369693
Trained batch 771 in epoch 3, gen_loss = 0.8275919614523803, disc_loss = 0.08535328341426009
Trained batch 772 in epoch 3, gen_loss = 0.8277506262333859, disc_loss = 0.08528915739691735
Trained batch 773 in epoch 3, gen_loss = 0.8276712984539741, disc_loss = 0.08521441040315138
Trained batch 774 in epoch 3, gen_loss = 0.8273648715019226, disc_loss = 0.08527525883768836
Trained batch 775 in epoch 3, gen_loss = 0.8275688835179683, disc_loss = 0.08519132783367615
Trained batch 776 in epoch 3, gen_loss = 0.8277350907313471, disc_loss = 0.08513887497468191
Trained batch 777 in epoch 3, gen_loss = 0.8276772922752449, disc_loss = 0.08521610426125152
Trained batch 778 in epoch 3, gen_loss = 0.8276634881217917, disc_loss = 0.08515123380240489
Trained batch 779 in epoch 3, gen_loss = 0.8275191572232125, disc_loss = 0.08512232379080394
Trained batch 780 in epoch 3, gen_loss = 0.8276161417918382, disc_loss = 0.0850542969095417
Trained batch 781 in epoch 3, gen_loss = 0.8279225065580109, disc_loss = 0.08500483154755115
Trained batch 782 in epoch 3, gen_loss = 0.828133099228334, disc_loss = 0.08492367448211477
Trained batch 783 in epoch 3, gen_loss = 0.8281095103189653, disc_loss = 0.08484863566367754
Trained batch 784 in epoch 3, gen_loss = 0.8283401172631865, disc_loss = 0.08475767520796151
Trained batch 785 in epoch 3, gen_loss = 0.8282318153150816, disc_loss = 0.08470613133214396
Trained batch 786 in epoch 3, gen_loss = 0.828656239158165, disc_loss = 0.0846245298777462
Trained batch 787 in epoch 3, gen_loss = 0.8282630862620881, disc_loss = 0.0847871638349905
Trained batch 788 in epoch 3, gen_loss = 0.8283126200106661, disc_loss = 0.08473725367044731
Trained batch 789 in epoch 3, gen_loss = 0.8285365868218337, disc_loss = 0.084674772067302
Trained batch 790 in epoch 3, gen_loss = 0.8285654835242839, disc_loss = 0.08460043830733496
Trained batch 791 in epoch 3, gen_loss = 0.8284138130268666, disc_loss = 0.08456375526447753
Trained batch 792 in epoch 3, gen_loss = 0.8282713163996405, disc_loss = 0.08448662508448203
Trained batch 793 in epoch 3, gen_loss = 0.8282842928126116, disc_loss = 0.08442158749449051
Trained batch 794 in epoch 3, gen_loss = 0.8283835653239077, disc_loss = 0.08449621487455736
Trained batch 795 in epoch 3, gen_loss = 0.8281453732569614, disc_loss = 0.08452584368092518
Trained batch 796 in epoch 3, gen_loss = 0.8279629148533533, disc_loss = 0.08448143554979952
Trained batch 797 in epoch 3, gen_loss = 0.8280535423964784, disc_loss = 0.08444389678131704
Trained batch 798 in epoch 3, gen_loss = 0.8279015712057693, disc_loss = 0.0844075915197351
Trained batch 799 in epoch 3, gen_loss = 0.8279160311818123, disc_loss = 0.084438779061893
Trained batch 800 in epoch 3, gen_loss = 0.8279311972462133, disc_loss = 0.08434651238488013
Trained batch 801 in epoch 3, gen_loss = 0.8282217917002347, disc_loss = 0.08425859501236989
Trained batch 802 in epoch 3, gen_loss = 0.8280479360933173, disc_loss = 0.08427026262912773
Trained batch 803 in epoch 3, gen_loss = 0.8278939330310964, disc_loss = 0.08421024261274147
Trained batch 804 in epoch 3, gen_loss = 0.8276026082335052, disc_loss = 0.08420400270579025
Trained batch 805 in epoch 3, gen_loss = 0.82744911379613, disc_loss = 0.08417831648778974
Trained batch 806 in epoch 3, gen_loss = 0.8275230026895081, disc_loss = 0.0841929205639064
Trained batch 807 in epoch 3, gen_loss = 0.8275760534671274, disc_loss = 0.08411183166271537
Trained batch 808 in epoch 3, gen_loss = 0.827701938903818, disc_loss = 0.08402439622077239
Trained batch 809 in epoch 3, gen_loss = 0.8274484684437882, disc_loss = 0.08403355328274179
Trained batch 810 in epoch 3, gen_loss = 0.8273617211458274, disc_loss = 0.08400447601762528
Trained batch 811 in epoch 3, gen_loss = 0.8278751639016156, disc_loss = 0.08394715961486358
Trained batch 812 in epoch 3, gen_loss = 0.8277967009890417, disc_loss = 0.08390183408537291
Trained batch 813 in epoch 3, gen_loss = 0.8277450340825159, disc_loss = 0.08388982754296805
Trained batch 814 in epoch 3, gen_loss = 0.8275262686372534, disc_loss = 0.08382455098322747
Trained batch 815 in epoch 3, gen_loss = 0.8274379578583381, disc_loss = 0.08386286745856826
Trained batch 816 in epoch 3, gen_loss = 0.8275374743170955, disc_loss = 0.08381754661610434
Trained batch 817 in epoch 3, gen_loss = 0.828705795673986, disc_loss = 0.08409123926157072
Trained batch 818 in epoch 3, gen_loss = 0.82853379878369, disc_loss = 0.08407310330137265
Trained batch 819 in epoch 3, gen_loss = 0.8281147021345976, disc_loss = 0.08408897852684122
Trained batch 820 in epoch 3, gen_loss = 0.8281747601499801, disc_loss = 0.08407722721296056
Trained batch 821 in epoch 3, gen_loss = 0.828045664840081, disc_loss = 0.08402235938888723
Trained batch 822 in epoch 3, gen_loss = 0.8278480055555248, disc_loss = 0.08404273560263878
Trained batch 823 in epoch 3, gen_loss = 0.8279623823258483, disc_loss = 0.08398855793249152
Trained batch 824 in epoch 3, gen_loss = 0.8283462822076046, disc_loss = 0.08400062971155751
Trained batch 825 in epoch 3, gen_loss = 0.8284083052784132, disc_loss = 0.0839855963190607
Trained batch 826 in epoch 3, gen_loss = 0.8280958658694645, disc_loss = 0.0840561039477785
Trained batch 827 in epoch 3, gen_loss = 0.8279495728764557, disc_loss = 0.08413207880221307
Trained batch 828 in epoch 3, gen_loss = 0.8279284279079, disc_loss = 0.08427881144899403
Trained batch 829 in epoch 3, gen_loss = 0.828202370706811, disc_loss = 0.08436658883422433
Trained batch 830 in epoch 3, gen_loss = 0.8281878273122721, disc_loss = 0.08437694813697526
Trained batch 831 in epoch 3, gen_loss = 0.8279492142252051, disc_loss = 0.08442784179687106
Trained batch 832 in epoch 3, gen_loss = 0.8278332030644365, disc_loss = 0.08437836744977968
Trained batch 833 in epoch 3, gen_loss = 0.8278554908806186, disc_loss = 0.08432979069368766
Trained batch 834 in epoch 3, gen_loss = 0.8280269495027508, disc_loss = 0.08434849224070054
Trained batch 835 in epoch 3, gen_loss = 0.8277532133189115, disc_loss = 0.08433222631326738
Trained batch 836 in epoch 3, gen_loss = 0.8275332521366817, disc_loss = 0.08429330458871245
Trained batch 837 in epoch 3, gen_loss = 0.8272585789884189, disc_loss = 0.08434353194139489
Trained batch 838 in epoch 3, gen_loss = 0.827473102152987, disc_loss = 0.08455603360725707
Trained batch 839 in epoch 3, gen_loss = 0.827071275526569, disc_loss = 0.08460043461749418
Trained batch 840 in epoch 3, gen_loss = 0.8271656280890657, disc_loss = 0.08451356109913868
Trained batch 841 in epoch 3, gen_loss = 0.8270633241201523, disc_loss = 0.08447828323573688
Trained batch 842 in epoch 3, gen_loss = 0.8273114276384826, disc_loss = 0.08439569140443068
Trained batch 843 in epoch 3, gen_loss = 0.8271784947664251, disc_loss = 0.08434559574893619
Trained batch 844 in epoch 3, gen_loss = 0.8271928050814296, disc_loss = 0.08426341699579587
Trained batch 845 in epoch 3, gen_loss = 0.8270657359849195, disc_loss = 0.0842048129623857
Trained batch 846 in epoch 3, gen_loss = 0.8268006500978256, disc_loss = 0.08419476348660455
Trained batch 847 in epoch 3, gen_loss = 0.8268961102332709, disc_loss = 0.08414069425538709
Trained batch 848 in epoch 3, gen_loss = 0.8274280949110698, disc_loss = 0.08417554742363759
Trained batch 849 in epoch 3, gen_loss = 0.8275249495225794, disc_loss = 0.08409892513142789
Trained batch 850 in epoch 3, gen_loss = 0.8275106012751157, disc_loss = 0.08413735583323885
Trained batch 851 in epoch 3, gen_loss = 0.8275487681789577, disc_loss = 0.08416800522420363
Trained batch 852 in epoch 3, gen_loss = 0.8271651820029631, disc_loss = 0.08419515195674976
Trained batch 853 in epoch 3, gen_loss = 0.8270043882888151, disc_loss = 0.08414840937834189
Trained batch 854 in epoch 3, gen_loss = 0.8272366876490632, disc_loss = 0.08427275442436599
Trained batch 855 in epoch 3, gen_loss = 0.8272657172284393, disc_loss = 0.08424905707263257
Trained batch 856 in epoch 3, gen_loss = 0.826892068603075, disc_loss = 0.08429064552648517
Trained batch 857 in epoch 3, gen_loss = 0.8269242005887287, disc_loss = 0.08423011383206729
Trained batch 858 in epoch 3, gen_loss = 0.8270419898493881, disc_loss = 0.08417467557097653
Trained batch 859 in epoch 3, gen_loss = 0.8269142536229865, disc_loss = 0.08416819615874353
Trained batch 860 in epoch 3, gen_loss = 0.826908894047643, disc_loss = 0.08410749027265385
Trained batch 861 in epoch 3, gen_loss = 0.8272068582803633, disc_loss = 0.0840432031432344
Trained batch 862 in epoch 3, gen_loss = 0.8268472185554814, disc_loss = 0.0840873356276167
Trained batch 863 in epoch 3, gen_loss = 0.8272242648182092, disc_loss = 0.08401970170261511
Trained batch 864 in epoch 3, gen_loss = 0.8272591045137085, disc_loss = 0.08393751717780884
Trained batch 865 in epoch 3, gen_loss = 0.8272349282445313, disc_loss = 0.08388430733496095
Trained batch 866 in epoch 3, gen_loss = 0.8273160457611084, disc_loss = 0.08380377047073263
Trained batch 867 in epoch 3, gen_loss = 0.827292442665122, disc_loss = 0.08376589976465716
Trained batch 868 in epoch 3, gen_loss = 0.8278230551471645, disc_loss = 0.0838159463798115
Trained batch 869 in epoch 3, gen_loss = 0.8279683435785359, disc_loss = 0.08384405230011406
Trained batch 870 in epoch 3, gen_loss = 0.8275929759208425, disc_loss = 0.08396779160933776
Trained batch 871 in epoch 3, gen_loss = 0.8275506485492812, disc_loss = 0.08397164003744106
Trained batch 872 in epoch 3, gen_loss = 0.8279739421667512, disc_loss = 0.0839847171911703
Trained batch 873 in epoch 3, gen_loss = 0.8278435531415438, disc_loss = 0.08396123678932815
Trained batch 874 in epoch 3, gen_loss = 0.827705981527056, disc_loss = 0.08397451988501207
Trained batch 875 in epoch 3, gen_loss = 0.8272999217861319, disc_loss = 0.08403703973726391
Trained batch 876 in epoch 3, gen_loss = 0.8275839032237858, disc_loss = 0.08404288666286722
Trained batch 877 in epoch 3, gen_loss = 0.8278426564975317, disc_loss = 0.08397477212020436
Trained batch 878 in epoch 3, gen_loss = 0.8279650746012982, disc_loss = 0.08389135179733932
Trained batch 879 in epoch 3, gen_loss = 0.8277318444103002, disc_loss = 0.08402078315954317
Trained batch 880 in epoch 3, gen_loss = 0.8280801558264539, disc_loss = 0.08409040482983281
Trained batch 881 in epoch 3, gen_loss = 0.8277862603499505, disc_loss = 0.0840891792255194
Trained batch 882 in epoch 3, gen_loss = 0.8276924298209215, disc_loss = 0.08407230789130839
Trained batch 883 in epoch 3, gen_loss = 0.8278025922394986, disc_loss = 0.0840450455160702
Trained batch 884 in epoch 3, gen_loss = 0.8280285783743454, disc_loss = 0.08396901422638003
Trained batch 885 in epoch 3, gen_loss = 0.8278171349123423, disc_loss = 0.08393428293445714
Trained batch 886 in epoch 3, gen_loss = 0.8274868728410297, disc_loss = 0.08394665922444595
Trained batch 887 in epoch 3, gen_loss = 0.8275568553389193, disc_loss = 0.08396619160214926
Trained batch 888 in epoch 3, gen_loss = 0.8276530573620169, disc_loss = 0.0839210213764379
Trained batch 889 in epoch 3, gen_loss = 0.8277074668849452, disc_loss = 0.08389855900758438
Trained batch 890 in epoch 3, gen_loss = 0.8277270758125249, disc_loss = 0.0838392250988252
Trained batch 891 in epoch 3, gen_loss = 0.827982665077186, disc_loss = 0.08382650941084119
Trained batch 892 in epoch 3, gen_loss = 0.8279601813764348, disc_loss = 0.08376475465499607
Trained batch 893 in epoch 3, gen_loss = 0.8278139905974903, disc_loss = 0.08370171412117196
Trained batch 894 in epoch 3, gen_loss = 0.8275325033584786, disc_loss = 0.08378347437932837
Trained batch 895 in epoch 3, gen_loss = 0.8272653448595, disc_loss = 0.08392869544539801
Trained batch 896 in epoch 3, gen_loss = 0.8272837111051532, disc_loss = 0.0838715642495465
Trained batch 897 in epoch 3, gen_loss = 0.8272001722408562, disc_loss = 0.08384745229732553
Trained batch 898 in epoch 3, gen_loss = 0.8275619420710872, disc_loss = 0.08377546925425065
Trained batch 899 in epoch 3, gen_loss = 0.827924596104357, disc_loss = 0.0837869841667513
Trained batch 900 in epoch 3, gen_loss = 0.8278858702997786, disc_loss = 0.0837199848442939
Trained batch 901 in epoch 3, gen_loss = 0.8278184693364505, disc_loss = 0.08371265540457024
Trained batch 902 in epoch 3, gen_loss = 0.8277603260108403, disc_loss = 0.08373879004117196
Trained batch 903 in epoch 3, gen_loss = 0.8283985625392041, disc_loss = 0.08397171679941888
Trained batch 904 in epoch 3, gen_loss = 0.8284833438159352, disc_loss = 0.08393810112955491
Trained batch 905 in epoch 3, gen_loss = 0.8281927453826858, disc_loss = 0.08431583183877187
Trained batch 906 in epoch 3, gen_loss = 0.8282911422957133, disc_loss = 0.08438858752731386
Trained batch 907 in epoch 3, gen_loss = 0.8285342082381248, disc_loss = 0.08439631193736773
Trained batch 908 in epoch 3, gen_loss = 0.8281696665667333, disc_loss = 0.08464309109049072
Trained batch 909 in epoch 3, gen_loss = 0.8283426043096479, disc_loss = 0.08484134030333915
Trained batch 910 in epoch 3, gen_loss = 0.8280894703320693, disc_loss = 0.08490061280486286
Trained batch 911 in epoch 3, gen_loss = 0.8279327424079702, disc_loss = 0.08498024291628481
Trained batch 912 in epoch 3, gen_loss = 0.8277911182823474, disc_loss = 0.08502834759293551
Trained batch 913 in epoch 3, gen_loss = 0.8279813740655161, disc_loss = 0.08522228855656
Trained batch 914 in epoch 3, gen_loss = 0.8276943600894323, disc_loss = 0.08536069935258946
Trained batch 915 in epoch 3, gen_loss = 0.8277310607344823, disc_loss = 0.0853210307686187
Trained batch 916 in epoch 3, gen_loss = 0.8275763305348944, disc_loss = 0.0853547834188981
Trained batch 917 in epoch 3, gen_loss = 0.8274305441410713, disc_loss = 0.08529120190616916
Trained batch 918 in epoch 3, gen_loss = 0.8272024836062866, disc_loss = 0.0852751983481665
Trained batch 919 in epoch 3, gen_loss = 0.8273781593079153, disc_loss = 0.08524154987915054
Trained batch 920 in epoch 3, gen_loss = 0.8273577182740782, disc_loss = 0.08516907212238488
Trained batch 921 in epoch 3, gen_loss = 0.8276109752324036, disc_loss = 0.08515875340477763
Trained batch 922 in epoch 3, gen_loss = 0.8273069633822787, disc_loss = 0.08519552520527741
Trained batch 923 in epoch 3, gen_loss = 0.8270283162077784, disc_loss = 0.08518979820176895
Trained batch 924 in epoch 3, gen_loss = 0.8272963816410787, disc_loss = 0.08529856421657511
Trained batch 925 in epoch 3, gen_loss = 0.8272333894383572, disc_loss = 0.08527087357064174
Trained batch 926 in epoch 3, gen_loss = 0.8270607040280792, disc_loss = 0.08530900262882923
Trained batch 927 in epoch 3, gen_loss = 0.826738420681193, disc_loss = 0.08527856400027743
Trained batch 928 in epoch 3, gen_loss = 0.8268487611935906, disc_loss = 0.08522132989440205
Trained batch 929 in epoch 3, gen_loss = 0.8269778645807697, disc_loss = 0.08518101635879727
Trained batch 930 in epoch 3, gen_loss = 0.8269284733768181, disc_loss = 0.08512359033273703
Trained batch 931 in epoch 3, gen_loss = 0.8267361763465046, disc_loss = 0.08515156079643274
Trained batch 932 in epoch 3, gen_loss = 0.8267446559597313, disc_loss = 0.08525459626479931
Trained batch 933 in epoch 3, gen_loss = 0.8265739969701787, disc_loss = 0.0852701440293988
Trained batch 934 in epoch 3, gen_loss = 0.8265485080805692, disc_loss = 0.08519904707125164
Trained batch 935 in epoch 3, gen_loss = 0.8263132917320627, disc_loss = 0.08517911753609267
Trained batch 936 in epoch 3, gen_loss = 0.8266135550868422, disc_loss = 0.08512707295546282
Trained batch 937 in epoch 3, gen_loss = 0.826471322889267, disc_loss = 0.08508786093642208
Trained batch 938 in epoch 3, gen_loss = 0.8261495277650567, disc_loss = 0.0850822108701522
Trained batch 939 in epoch 3, gen_loss = 0.8261520909502151, disc_loss = 0.08502345494925975
Trained batch 940 in epoch 3, gen_loss = 0.8260218562532561, disc_loss = 0.0849710343431337
Trained batch 941 in epoch 3, gen_loss = 0.8260073166997063, disc_loss = 0.08498346003567338
Trained batch 942 in epoch 3, gen_loss = 0.825900024346304, disc_loss = 0.08497148105916137
Trained batch 943 in epoch 3, gen_loss = 0.825908731353485, disc_loss = 0.08491354812946865
Trained batch 944 in epoch 3, gen_loss = 0.8257207918419409, disc_loss = 0.08495202472916356
Trained batch 945 in epoch 3, gen_loss = 0.8258454490917682, disc_loss = 0.08490016783172182
Trained batch 946 in epoch 3, gen_loss = 0.826067013624729, disc_loss = 0.08485624766116913
Trained batch 947 in epoch 3, gen_loss = 0.8258789503624671, disc_loss = 0.08483247158710967
Trained batch 948 in epoch 3, gen_loss = 0.8257036545756494, disc_loss = 0.0849055426609403
Trained batch 949 in epoch 3, gen_loss = 0.8255168580381493, disc_loss = 0.08487441793868417
Trained batch 950 in epoch 3, gen_loss = 0.8254654682647793, disc_loss = 0.08483573090829559
Trained batch 951 in epoch 3, gen_loss = 0.8253943155668363, disc_loss = 0.08491586956406842
Trained batch 952 in epoch 3, gen_loss = 0.8253905247165924, disc_loss = 0.08485393135653024
Trained batch 953 in epoch 3, gen_loss = 0.8257813829171082, disc_loss = 0.08489552751941064
Trained batch 954 in epoch 3, gen_loss = 0.8255287038718219, disc_loss = 0.08499091647721398
Trained batch 955 in epoch 3, gen_loss = 0.8260602504014969, disc_loss = 0.0850367494586029
Trained batch 956 in epoch 3, gen_loss = 0.825959702831077, disc_loss = 0.08499672745190008
Trained batch 957 in epoch 3, gen_loss = 0.8257771149308796, disc_loss = 0.08501239841325609
Trained batch 958 in epoch 3, gen_loss = 0.8256976393141762, disc_loss = 0.08496520902312772
Trained batch 959 in epoch 3, gen_loss = 0.8258600290864706, disc_loss = 0.08495728319394402
Trained batch 960 in epoch 3, gen_loss = 0.8260923642645766, disc_loss = 0.08493853199347062
Trained batch 961 in epoch 3, gen_loss = 0.825700702637496, disc_loss = 0.08510290733161005
Trained batch 962 in epoch 3, gen_loss = 0.8257854265834931, disc_loss = 0.08515913096891943
Trained batch 963 in epoch 3, gen_loss = 0.8256696981389493, disc_loss = 0.08518371766788646
Trained batch 964 in epoch 3, gen_loss = 0.8256515388044051, disc_loss = 0.08519027660277532
Trained batch 965 in epoch 3, gen_loss = 0.825582606451852, disc_loss = 0.08513966252676387
Trained batch 966 in epoch 3, gen_loss = 0.825547222514187, disc_loss = 0.08522349300735554
Trained batch 967 in epoch 3, gen_loss = 0.8252755159065743, disc_loss = 0.08527014502093258
Trained batch 968 in epoch 3, gen_loss = 0.8248767087580127, disc_loss = 0.08532889015680435
Trained batch 969 in epoch 3, gen_loss = 0.8251853512734482, disc_loss = 0.08532528161196057
Trained batch 970 in epoch 3, gen_loss = 0.8253895838646147, disc_loss = 0.0852629702776118
Trained batch 971 in epoch 3, gen_loss = 0.8255096186458328, disc_loss = 0.08520603417553038
Trained batch 972 in epoch 3, gen_loss = 0.8252839607790587, disc_loss = 0.0851898134168226
Trained batch 973 in epoch 3, gen_loss = 0.8252829789992965, disc_loss = 0.0851412987684567
Trained batch 974 in epoch 3, gen_loss = 0.8252752491144033, disc_loss = 0.08508246350937929
Trained batch 975 in epoch 3, gen_loss = 0.8254531554755618, disc_loss = 0.08501605153251744
Trained batch 976 in epoch 3, gen_loss = 0.825822226344746, disc_loss = 0.08498901792610314
Trained batch 977 in epoch 3, gen_loss = 0.825893049713049, disc_loss = 0.08491780154087061
Trained batch 978 in epoch 3, gen_loss = 0.8257353927434039, disc_loss = 0.08492798373422779
Trained batch 979 in epoch 3, gen_loss = 0.8255053037891582, disc_loss = 0.08495643739493526
Trained batch 980 in epoch 3, gen_loss = 0.8257391692787621, disc_loss = 0.08502236049656474
Trained batch 981 in epoch 3, gen_loss = 0.8257617007812026, disc_loss = 0.08494692611604808
Trained batch 982 in epoch 3, gen_loss = 0.8258079856118739, disc_loss = 0.08487931331041688
Trained batch 983 in epoch 3, gen_loss = 0.8259363324055827, disc_loss = 0.08486235556495565
Trained batch 984 in epoch 3, gen_loss = 0.8257789793353395, disc_loss = 0.08483507415553942
Trained batch 985 in epoch 3, gen_loss = 0.8257542334753891, disc_loss = 0.08478705099695051
Trained batch 986 in epoch 3, gen_loss = 0.8257652020502718, disc_loss = 0.08473791046730472
Trained batch 987 in epoch 3, gen_loss = 0.8259394535048288, disc_loss = 0.08469094041742475
Trained batch 988 in epoch 3, gen_loss = 0.8257621089778124, disc_loss = 0.08463696160808552
Trained batch 989 in epoch 3, gen_loss = 0.825863301513171, disc_loss = 0.0845770326772272
Trained batch 990 in epoch 3, gen_loss = 0.8260991930600733, disc_loss = 0.08478657228592125
Trained batch 991 in epoch 3, gen_loss = 0.8259067742093917, disc_loss = 0.08483191938026838
Trained batch 992 in epoch 3, gen_loss = 0.825707658239962, disc_loss = 0.08488330841702217
Trained batch 993 in epoch 3, gen_loss = 0.8258008012469386, disc_loss = 0.08483555842700678
Trained batch 994 in epoch 3, gen_loss = 0.8256858742416804, disc_loss = 0.08481486275904442
Trained batch 995 in epoch 3, gen_loss = 0.8255183006745266, disc_loss = 0.08478873975417879
Trained batch 996 in epoch 3, gen_loss = 0.8256292429826444, disc_loss = 0.08494303990323601
Trained batch 997 in epoch 3, gen_loss = 0.8256203195972289, disc_loss = 0.0848985545968036
Trained batch 998 in epoch 3, gen_loss = 0.8254082173079222, disc_loss = 0.08494525151634896
Trained batch 999 in epoch 3, gen_loss = 0.8256472676992417, disc_loss = 0.0849085437413305
Trained batch 1000 in epoch 3, gen_loss = 0.825759400556852, disc_loss = 0.08493532936138051
Trained batch 1001 in epoch 3, gen_loss = 0.8255599143500337, disc_loss = 0.08492787960663943
Trained batch 1002 in epoch 3, gen_loss = 0.8253894020410502, disc_loss = 0.0849336892912389
Trained batch 1003 in epoch 3, gen_loss = 0.8254652821210277, disc_loss = 0.08513070699161446
Trained batch 1004 in epoch 3, gen_loss = 0.8253078559737893, disc_loss = 0.0852398718452424
Trained batch 1005 in epoch 3, gen_loss = 0.8251897118556096, disc_loss = 0.08524239356361078
Trained batch 1006 in epoch 3, gen_loss = 0.8255962628830509, disc_loss = 0.08554842212637877
Trained batch 1007 in epoch 3, gen_loss = 0.825331715778226, disc_loss = 0.0857264658506398
Trained batch 1008 in epoch 3, gen_loss = 0.8251514077422877, disc_loss = 0.08576969078550903
Trained batch 1009 in epoch 3, gen_loss = 0.825207401207178, disc_loss = 0.08581022177407942
Trained batch 1010 in epoch 3, gen_loss = 0.8250659055101411, disc_loss = 0.08585317359001005
Trained batch 1011 in epoch 3, gen_loss = 0.825533660798676, disc_loss = 0.08595180970693943
Trained batch 1012 in epoch 3, gen_loss = 0.8253563875507155, disc_loss = 0.08593772105166554
Trained batch 1013 in epoch 3, gen_loss = 0.8252303166502326, disc_loss = 0.08594165666532176
Trained batch 1014 in epoch 3, gen_loss = 0.8252531812696035, disc_loss = 0.08590226775870241
Trained batch 1015 in epoch 3, gen_loss = 0.8253744381853915, disc_loss = 0.08586141936239002
Trained batch 1016 in epoch 3, gen_loss = 0.8255082225260364, disc_loss = 0.08582067208121015
Trained batch 1017 in epoch 3, gen_loss = 0.8255062862088965, disc_loss = 0.08583456428432452
Trained batch 1018 in epoch 3, gen_loss = 0.8252448269967593, disc_loss = 0.08588261932858482
Trained batch 1019 in epoch 3, gen_loss = 0.8255791168002521, disc_loss = 0.08587898665893019
Trained batch 1020 in epoch 3, gen_loss = 0.8256798472974256, disc_loss = 0.08583241427293545
Trained batch 1021 in epoch 3, gen_loss = 0.8253929044635795, disc_loss = 0.08590808304285524
Trained batch 1022 in epoch 3, gen_loss = 0.8254653558586583, disc_loss = 0.08586880690868824
Trained batch 1023 in epoch 3, gen_loss = 0.8255285868071951, disc_loss = 0.08583737250773993
Trained batch 1024 in epoch 3, gen_loss = 0.8253340386762852, disc_loss = 0.08587714124198367
Trained batch 1025 in epoch 3, gen_loss = 0.8252534897703874, disc_loss = 0.08585401593397061
Trained batch 1026 in epoch 3, gen_loss = 0.8253078864635256, disc_loss = 0.08583000684819006
Trained batch 1027 in epoch 3, gen_loss = 0.8253041622355755, disc_loss = 0.08581499208366418
Trained batch 1028 in epoch 3, gen_loss = 0.825287345431173, disc_loss = 0.08591843008509936
Trained batch 1029 in epoch 3, gen_loss = 0.8249860957988258, disc_loss = 0.08601787353061068
Trained batch 1030 in epoch 3, gen_loss = 0.824888975960207, disc_loss = 0.08601761074731294
Trained batch 1031 in epoch 3, gen_loss = 0.8245814038339512, disc_loss = 0.08606776376543639
Trained batch 1032 in epoch 3, gen_loss = 0.8247080183906222, disc_loss = 0.08627219434145979
Trained batch 1033 in epoch 3, gen_loss = 0.8245163626205068, disc_loss = 0.08627691910542706
Trained batch 1034 in epoch 3, gen_loss = 0.8245289936733706, disc_loss = 0.08629983036738376
Trained batch 1035 in epoch 3, gen_loss = 0.8245753957728161, disc_loss = 0.08630136914846116
Trained batch 1036 in epoch 3, gen_loss = 0.824408445546804, disc_loss = 0.08643061575895622
Trained batch 1037 in epoch 3, gen_loss = 0.8241974279026075, disc_loss = 0.08642144184846696
Trained batch 1038 in epoch 3, gen_loss = 0.8241668933280049, disc_loss = 0.08640185279074314
Trained batch 1039 in epoch 3, gen_loss = 0.8241032604414683, disc_loss = 0.08642126752529293
Trained batch 1040 in epoch 3, gen_loss = 0.8241600356459274, disc_loss = 0.08636030410376165
Trained batch 1041 in epoch 3, gen_loss = 0.8239824325132279, disc_loss = 0.08635119025035978
Trained batch 1042 in epoch 3, gen_loss = 0.8240541193423541, disc_loss = 0.08635431417547101
Trained batch 1043 in epoch 3, gen_loss = 0.8240893652726864, disc_loss = 0.08630831879153276
Trained batch 1044 in epoch 3, gen_loss = 0.8240343874721436, disc_loss = 0.08627503932270993
Trained batch 1045 in epoch 3, gen_loss = 0.8237647417056629, disc_loss = 0.08639470402535984
Trained batch 1046 in epoch 3, gen_loss = 0.8238461904562191, disc_loss = 0.08639567805971833
Trained batch 1047 in epoch 3, gen_loss = 0.8238345282223388, disc_loss = 0.08646204548831034
Trained batch 1048 in epoch 3, gen_loss = 0.8238454627013411, disc_loss = 0.08661000861176374
Trained batch 1049 in epoch 3, gen_loss = 0.8234896077712377, disc_loss = 0.0870811560909663
Trained batch 1050 in epoch 3, gen_loss = 0.8235619121738891, disc_loss = 0.0870250072259346
Trained batch 1051 in epoch 3, gen_loss = 0.8238974392924019, disc_loss = 0.08704389101460916
Trained batch 1052 in epoch 3, gen_loss = 0.8240678487283665, disc_loss = 0.08699375468660907
Trained batch 1053 in epoch 3, gen_loss = 0.8237450983820649, disc_loss = 0.08703845679809462
Trained batch 1054 in epoch 3, gen_loss = 0.8240221036271461, disc_loss = 0.08703466856331339
Trained batch 1055 in epoch 3, gen_loss = 0.8238898496228185, disc_loss = 0.08703758673227364
Trained batch 1056 in epoch 3, gen_loss = 0.8240489755865529, disc_loss = 0.08697432619867566
Trained batch 1057 in epoch 3, gen_loss = 0.8238236817103478, disc_loss = 0.08697016323636689
Trained batch 1058 in epoch 3, gen_loss = 0.8239959359900697, disc_loss = 0.08702205075610629
Trained batch 1059 in epoch 3, gen_loss = 0.823856207306655, disc_loss = 0.0870714310117347
Trained batch 1060 in epoch 3, gen_loss = 0.82359480529209, disc_loss = 0.08718306762074154
Trained batch 1061 in epoch 3, gen_loss = 0.823628975088987, disc_loss = 0.08711721664803232
Trained batch 1062 in epoch 3, gen_loss = 0.8237474244210592, disc_loss = 0.08708066601036353
Trained batch 1063 in epoch 3, gen_loss = 0.8236194578160468, disc_loss = 0.08705006539646565
Trained batch 1064 in epoch 3, gen_loss = 0.8239116290645421, disc_loss = 0.08702113993395942
Trained batch 1065 in epoch 3, gen_loss = 0.8239085455940544, disc_loss = 0.0870096676705115
Trained batch 1066 in epoch 3, gen_loss = 0.8236141864283686, disc_loss = 0.08715450489106252
Trained batch 1067 in epoch 3, gen_loss = 0.8235111490226863, disc_loss = 0.08712078671211775
Trained batch 1068 in epoch 3, gen_loss = 0.8236243196521773, disc_loss = 0.08711688549992244
Trained batch 1069 in epoch 3, gen_loss = 0.823807222514509, disc_loss = 0.08704918895665313
Trained batch 1070 in epoch 3, gen_loss = 0.8235932337859321, disc_loss = 0.08706117638871143
Trained batch 1071 in epoch 3, gen_loss = 0.8236295322595693, disc_loss = 0.08701094818986091
Trained batch 1072 in epoch 3, gen_loss = 0.8237211575101495, disc_loss = 0.08695462815730876
Trained batch 1073 in epoch 3, gen_loss = 0.8237789882350456, disc_loss = 0.08689718611722247
Trained batch 1074 in epoch 3, gen_loss = 0.8236291765889456, disc_loss = 0.08686198099841212
Trained batch 1075 in epoch 3, gen_loss = 0.8236781803260949, disc_loss = 0.0868445490928346
Trained batch 1076 in epoch 3, gen_loss = 0.8236964900900948, disc_loss = 0.0868042571930182
Trained batch 1077 in epoch 3, gen_loss = 0.8238475886424088, disc_loss = 0.08691134032273254
Trained batch 1078 in epoch 3, gen_loss = 0.8243198572374031, disc_loss = 0.08687349955833572
Trained batch 1079 in epoch 3, gen_loss = 0.8241182136038939, disc_loss = 0.08688725329745838
Trained batch 1080 in epoch 3, gen_loss = 0.824073578090606, disc_loss = 0.08688102257382004
Trained batch 1081 in epoch 3, gen_loss = 0.8240714569243839, disc_loss = 0.08681579852173735
Trained batch 1082 in epoch 3, gen_loss = 0.8241291480656586, disc_loss = 0.08687881179521977
Trained batch 1083 in epoch 3, gen_loss = 0.8240430734199351, disc_loss = 0.08685495644013957
Trained batch 1084 in epoch 3, gen_loss = 0.8238478713046571, disc_loss = 0.08686376133083885
Trained batch 1085 in epoch 3, gen_loss = 0.8237700801802385, disc_loss = 0.08680748284415343
Trained batch 1086 in epoch 3, gen_loss = 0.8238208377536766, disc_loss = 0.08679712133391279
Trained batch 1087 in epoch 3, gen_loss = 0.8235747695571798, disc_loss = 0.08675616090476979
Trained batch 1088 in epoch 3, gen_loss = 0.8235152496505593, disc_loss = 0.08674579510966417
Trained batch 1089 in epoch 3, gen_loss = 0.8235310962714186, disc_loss = 0.08672371379296304
Trained batch 1090 in epoch 3, gen_loss = 0.8238295535501485, disc_loss = 0.08684920450360074
Trained batch 1091 in epoch 3, gen_loss = 0.8236193036039671, disc_loss = 0.08692764829001612
Trained batch 1092 in epoch 3, gen_loss = 0.823687040385912, disc_loss = 0.08687597392288812
Trained batch 1093 in epoch 3, gen_loss = 0.823958978165874, disc_loss = 0.08698861824409862
Trained batch 1094 in epoch 3, gen_loss = 0.8236803941802892, disc_loss = 0.08705149641745302
Trained batch 1095 in epoch 3, gen_loss = 0.8235407539908468, disc_loss = 0.087077351855488
Trained batch 1096 in epoch 3, gen_loss = 0.823552146621911, disc_loss = 0.08706630404814467
Trained batch 1097 in epoch 3, gen_loss = 0.8234087813150253, disc_loss = 0.0874424388230132
Trained batch 1098 in epoch 3, gen_loss = 0.8232143501512997, disc_loss = 0.08744857897278636
Trained batch 1099 in epoch 3, gen_loss = 0.823148318502036, disc_loss = 0.08742250678637488
Trained batch 1100 in epoch 3, gen_loss = 0.8232042798933173, disc_loss = 0.08742020162521141
Trained batch 1101 in epoch 3, gen_loss = 0.8231219660402859, disc_loss = 0.08738729339211286
Trained batch 1102 in epoch 3, gen_loss = 0.8229353270364261, disc_loss = 0.08735195367410441
Trained batch 1103 in epoch 3, gen_loss = 0.8229948226362467, disc_loss = 0.08730520999507871
Trained batch 1104 in epoch 3, gen_loss = 0.8230804901047529, disc_loss = 0.08726942529859721
Trained batch 1105 in epoch 3, gen_loss = 0.8229993032880977, disc_loss = 0.08724174617619589
Trained batch 1106 in epoch 3, gen_loss = 0.8232135148929279, disc_loss = 0.08718299280259802
Trained batch 1107 in epoch 3, gen_loss = 0.8234743876954278, disc_loss = 0.08713371382054573
Trained batch 1108 in epoch 3, gen_loss = 0.8236801856213373, disc_loss = 0.08708355239633642
Trained batch 1109 in epoch 3, gen_loss = 0.8238660950649966, disc_loss = 0.08706026723071396
Trained batch 1110 in epoch 3, gen_loss = 0.8235509971527234, disc_loss = 0.08714044208174805
Trained batch 1111 in epoch 3, gen_loss = 0.8235035794619605, disc_loss = 0.08720477809878267
Trained batch 1112 in epoch 3, gen_loss = 0.8235136981441005, disc_loss = 0.08713992146619487
Trained batch 1113 in epoch 3, gen_loss = 0.8233737607137092, disc_loss = 0.08713672919152053
Trained batch 1114 in epoch 3, gen_loss = 0.8231535615675118, disc_loss = 0.08717059969918745
Trained batch 1115 in epoch 3, gen_loss = 0.8236351511224196, disc_loss = 0.08731992482408
Trained batch 1116 in epoch 3, gen_loss = 0.8236929381811523, disc_loss = 0.08726191259136852
Trained batch 1117 in epoch 3, gen_loss = 0.8234867526881383, disc_loss = 0.0872186471321595
Trained batch 1118 in epoch 3, gen_loss = 0.8234111519931575, disc_loss = 0.08718953872477374
Trained batch 1119 in epoch 3, gen_loss = 0.8234743520883577, disc_loss = 0.08715010046144016
Trained batch 1120 in epoch 3, gen_loss = 0.8233694171235564, disc_loss = 0.0871526619160247
Trained batch 1121 in epoch 3, gen_loss = 0.8234744926453061, disc_loss = 0.0872578070575368
Trained batch 1122 in epoch 3, gen_loss = 0.823368399539168, disc_loss = 0.08726614853242812
Trained batch 1123 in epoch 3, gen_loss = 0.8232353543630698, disc_loss = 0.08726705601720597
Trained batch 1124 in epoch 3, gen_loss = 0.8231880338721805, disc_loss = 0.08730763120369779
Trained batch 1125 in epoch 3, gen_loss = 0.8230108201874298, disc_loss = 0.08734071363494805
Trained batch 1126 in epoch 3, gen_loss = 0.8229505591881201, disc_loss = 0.08728733844146093
Trained batch 1127 in epoch 3, gen_loss = 0.8229692876074753, disc_loss = 0.08725917611703779
Trained batch 1128 in epoch 3, gen_loss = 0.8232006515360597, disc_loss = 0.08731325809077498
Trained batch 1129 in epoch 3, gen_loss = 0.8231993356373458, disc_loss = 0.08730814322680894
Trained batch 1130 in epoch 3, gen_loss = 0.8229953673800782, disc_loss = 0.08735028773819604
Trained batch 1131 in epoch 3, gen_loss = 0.8227347051560246, disc_loss = 0.08743367024513074
Trained batch 1132 in epoch 3, gen_loss = 0.8226935213525424, disc_loss = 0.08764389403483322
Trained batch 1133 in epoch 3, gen_loss = 0.8227680624845377, disc_loss = 0.08760161746073206
Trained batch 1134 in epoch 3, gen_loss = 0.8227291279164705, disc_loss = 0.08756252627918243
Trained batch 1135 in epoch 3, gen_loss = 0.8228974117517052, disc_loss = 0.08758250053588328
Trained batch 1136 in epoch 3, gen_loss = 0.8226417642522508, disc_loss = 0.08762043478866759
Trained batch 1137 in epoch 3, gen_loss = 0.8226476474836967, disc_loss = 0.08756233734178548
Trained batch 1138 in epoch 3, gen_loss = 0.8227864476910174, disc_loss = 0.08758907946426817
Trained batch 1139 in epoch 3, gen_loss = 0.8228292456060126, disc_loss = 0.08763468583245157
Trained batch 1140 in epoch 3, gen_loss = 0.8227003908126005, disc_loss = 0.08764022292355426
Trained batch 1141 in epoch 3, gen_loss = 0.8228284905806523, disc_loss = 0.08765126382540618
Trained batch 1142 in epoch 3, gen_loss = 0.8225313952015036, disc_loss = 0.08780540512957832
Trained batch 1143 in epoch 3, gen_loss = 0.8226005246120316, disc_loss = 0.08776813149663874
Trained batch 1144 in epoch 3, gen_loss = 0.8227623540501408, disc_loss = 0.08777812845663342
Trained batch 1145 in epoch 3, gen_loss = 0.8227348020511563, disc_loss = 0.08780850279656927
Trained batch 1146 in epoch 3, gen_loss = 0.8226269147608107, disc_loss = 0.08784125935702009
Trained batch 1147 in epoch 3, gen_loss = 0.8225532959926004, disc_loss = 0.08784290686824103
Trained batch 1148 in epoch 3, gen_loss = 0.8224304332174976, disc_loss = 0.08798890095366226
Trained batch 1149 in epoch 3, gen_loss = 0.8222450682132141, disc_loss = 0.08796771475235406
Trained batch 1150 in epoch 3, gen_loss = 0.8220660775304358, disc_loss = 0.08799743783829343
Trained batch 1151 in epoch 3, gen_loss = 0.8218307035406016, disc_loss = 0.08801890797864569
Trained batch 1152 in epoch 3, gen_loss = 0.8222870477002698, disc_loss = 0.08812942014763202
Trained batch 1153 in epoch 3, gen_loss = 0.8221598496625081, disc_loss = 0.08810143446569142
Trained batch 1154 in epoch 3, gen_loss = 0.8219075036513341, disc_loss = 0.08811814592852867
Trained batch 1155 in epoch 3, gen_loss = 0.8218942136861461, disc_loss = 0.08809159808005868
Trained batch 1156 in epoch 3, gen_loss = 0.822057315240982, disc_loss = 0.08814910052677451
Trained batch 1157 in epoch 3, gen_loss = 0.8221163318101606, disc_loss = 0.08809694992088823
Trained batch 1158 in epoch 3, gen_loss = 0.82192253405622, disc_loss = 0.08809259982668731
Trained batch 1159 in epoch 3, gen_loss = 0.8219528658893601, disc_loss = 0.08803470894967302
Trained batch 1160 in epoch 3, gen_loss = 0.8219576850982702, disc_loss = 0.08798904655121016
Trained batch 1161 in epoch 3, gen_loss = 0.8220599092889366, disc_loss = 0.08798273932749787
Trained batch 1162 in epoch 3, gen_loss = 0.8219046815396995, disc_loss = 0.08795658619842162
Trained batch 1163 in epoch 3, gen_loss = 0.8219900070033532, disc_loss = 0.08793255852301736
Trained batch 1164 in epoch 3, gen_loss = 0.8219273730153178, disc_loss = 0.08787447926008778
Trained batch 1165 in epoch 3, gen_loss = 0.8219027881403526, disc_loss = 0.08786643674200972
Trained batch 1166 in epoch 3, gen_loss = 0.8218171959415704, disc_loss = 0.08784343465770042
Trained batch 1167 in epoch 3, gen_loss = 0.821576783892839, disc_loss = 0.08786138728953106
Trained batch 1168 in epoch 3, gen_loss = 0.8216328087834031, disc_loss = 0.08782439976309206
Trained batch 1169 in epoch 3, gen_loss = 0.8214124094981413, disc_loss = 0.08786202242247697
Trained batch 1170 in epoch 3, gen_loss = 0.8214537737259592, disc_loss = 0.08782984616424186
Trained batch 1171 in epoch 3, gen_loss = 0.8213295520826818, disc_loss = 0.08783459640902692
Trained batch 1172 in epoch 3, gen_loss = 0.8214406008051688, disc_loss = 0.0878735243526223
Trained batch 1173 in epoch 3, gen_loss = 0.8213782872262155, disc_loss = 0.08785149862266303
Trained batch 1174 in epoch 3, gen_loss = 0.8211199210806096, disc_loss = 0.08790935147078113
Trained batch 1175 in epoch 3, gen_loss = 0.8211167400234005, disc_loss = 0.08787185996279856
Trained batch 1176 in epoch 3, gen_loss = 0.8213041026458562, disc_loss = 0.08786282749544314
Trained batch 1177 in epoch 3, gen_loss = 0.8213147922515465, disc_loss = 0.08781003678559068
Trained batch 1178 in epoch 3, gen_loss = 0.8212891271854478, disc_loss = 0.08777354616968813
Trained batch 1179 in epoch 3, gen_loss = 0.8213693976149721, disc_loss = 0.08774709936815424
Trained batch 1180 in epoch 3, gen_loss = 0.8213348571119623, disc_loss = 0.08771228471457025
Trained batch 1181 in epoch 3, gen_loss = 0.821287567315973, disc_loss = 0.08769905238527358
Trained batch 1182 in epoch 3, gen_loss = 0.8214210621754395, disc_loss = 0.08775555248988677
Trained batch 1183 in epoch 3, gen_loss = 0.8211897347072089, disc_loss = 0.08792678327567095
Trained batch 1184 in epoch 3, gen_loss = 0.8211394913840394, disc_loss = 0.08794643762383908
Trained batch 1185 in epoch 3, gen_loss = 0.8210532957496369, disc_loss = 0.08794253270265852
Trained batch 1186 in epoch 3, gen_loss = 0.8211151739831923, disc_loss = 0.08792662433259936
Trained batch 1187 in epoch 3, gen_loss = 0.8209898407360922, disc_loss = 0.08789307864066151
Trained batch 1188 in epoch 3, gen_loss = 0.8211379860057061, disc_loss = 0.08783152847902503
Trained batch 1189 in epoch 3, gen_loss = 0.821083996851905, disc_loss = 0.08785720585821932
Trained batch 1190 in epoch 3, gen_loss = 0.8210014344813141, disc_loss = 0.08785665399878967
Trained batch 1191 in epoch 3, gen_loss = 0.8208289627210806, disc_loss = 0.0878389702739519
Trained batch 1192 in epoch 3, gen_loss = 0.8210302332270975, disc_loss = 0.08793274501115333
Trained batch 1193 in epoch 3, gen_loss = 0.8209611175198052, disc_loss = 0.08796999546023744
Trained batch 1194 in epoch 3, gen_loss = 0.8208860387113802, disc_loss = 0.08793456871685996
Trained batch 1195 in epoch 3, gen_loss = 0.8211111214796835, disc_loss = 0.08812871633212777
Trained batch 1196 in epoch 3, gen_loss = 0.8211053891438889, disc_loss = 0.08813191295438816
Trained batch 1197 in epoch 3, gen_loss = 0.8209435578329933, disc_loss = 0.08823483644942683
Trained batch 1198 in epoch 3, gen_loss = 0.8209052497740086, disc_loss = 0.08820288789204576
Trained batch 1199 in epoch 3, gen_loss = 0.8212006849298874, disc_loss = 0.0882823356729932
Trained batch 1200 in epoch 3, gen_loss = 0.8212647443756672, disc_loss = 0.08823838128594311
Trained batch 1201 in epoch 3, gen_loss = 0.8212047910283687, disc_loss = 0.08822134964883997
Trained batch 1202 in epoch 3, gen_loss = 0.8213660142021385, disc_loss = 0.08820487203576594
Trained batch 1203 in epoch 3, gen_loss = 0.821325962403882, disc_loss = 0.08823765987805725
Trained batch 1204 in epoch 3, gen_loss = 0.8214003882220178, disc_loss = 0.0882410971849724
Trained batch 1205 in epoch 3, gen_loss = 0.8210600916524827, disc_loss = 0.0882804515249533
Trained batch 1206 in epoch 3, gen_loss = 0.8212110834765651, disc_loss = 0.08824588573138849
Trained batch 1207 in epoch 3, gen_loss = 0.8213463910664154, disc_loss = 0.0881975316897417
Trained batch 1208 in epoch 3, gen_loss = 0.8213177682251058, disc_loss = 0.08819016024726077
Trained batch 1209 in epoch 3, gen_loss = 0.8213127857890011, disc_loss = 0.08815624537100354
Trained batch 1210 in epoch 3, gen_loss = 0.8210392327076339, disc_loss = 0.0882349932154073
Trained batch 1211 in epoch 3, gen_loss = 0.8212411316117831, disc_loss = 0.08818247433515149
Trained batch 1212 in epoch 3, gen_loss = 0.8213562903478926, disc_loss = 0.0881328626243307
Trained batch 1213 in epoch 3, gen_loss = 0.8214958964109028, disc_loss = 0.08820538616722336
Trained batch 1214 in epoch 3, gen_loss = 0.8214187314971484, disc_loss = 0.0881559160641498
Trained batch 1215 in epoch 3, gen_loss = 0.8212619129764406, disc_loss = 0.08816372521151176
Trained batch 1216 in epoch 3, gen_loss = 0.8212365084431068, disc_loss = 0.08812062443603648
Trained batch 1217 in epoch 3, gen_loss = 0.8211189228521387, disc_loss = 0.08809682577986068
Trained batch 1218 in epoch 3, gen_loss = 0.8211450198324515, disc_loss = 0.08804430340671143
Trained batch 1219 in epoch 3, gen_loss = 0.821307023626859, disc_loss = 0.08803335528927626
Trained batch 1220 in epoch 3, gen_loss = 0.8212491493553142, disc_loss = 0.08801263682376426
Trained batch 1221 in epoch 3, gen_loss = 0.8212136429187319, disc_loss = 0.08797932518554666
Trained batch 1222 in epoch 3, gen_loss = 0.8210139965679639, disc_loss = 0.08807097849278472
Trained batch 1223 in epoch 3, gen_loss = 0.8211069995281743, disc_loss = 0.08811835265258826
Trained batch 1224 in epoch 3, gen_loss = 0.8212282389037463, disc_loss = 0.08807500112345633
Trained batch 1225 in epoch 3, gen_loss = 0.821288337618064, disc_loss = 0.08801909820609657
Trained batch 1226 in epoch 3, gen_loss = 0.8212331648075007, disc_loss = 0.0879904605856601
Trained batch 1227 in epoch 3, gen_loss = 0.8214010976813126, disc_loss = 0.08793886919681844
Trained batch 1228 in epoch 3, gen_loss = 0.8215372808780779, disc_loss = 0.08797151823978995
Trained batch 1229 in epoch 3, gen_loss = 0.8213446880259165, disc_loss = 0.08796451717569698
Trained batch 1230 in epoch 3, gen_loss = 0.8213559766303805, disc_loss = 0.08796734089950277
Trained batch 1231 in epoch 3, gen_loss = 0.8212439210287162, disc_loss = 0.08793772443261166
Trained batch 1232 in epoch 3, gen_loss = 0.8213707544604454, disc_loss = 0.08792092857862742
Trained batch 1233 in epoch 3, gen_loss = 0.821479379840956, disc_loss = 0.08788655222600365
Trained batch 1234 in epoch 3, gen_loss = 0.8214267796833022, disc_loss = 0.0878721409488605
Trained batch 1235 in epoch 3, gen_loss = 0.8213101032771725, disc_loss = 0.08787109570285384
Trained batch 1236 in epoch 3, gen_loss = 0.8213004834148897, disc_loss = 0.08781057499987567
Trained batch 1237 in epoch 3, gen_loss = 0.8214120571659532, disc_loss = 0.08774699108759378
Trained batch 1238 in epoch 3, gen_loss = 0.8213894532225227, disc_loss = 0.08777057478028479
Trained batch 1239 in epoch 3, gen_loss = 0.8212962438021937, disc_loss = 0.08778939622589538
Trained batch 1240 in epoch 3, gen_loss = 0.821477356982942, disc_loss = 0.08780299681767906
Trained batch 1241 in epoch 3, gen_loss = 0.8212485144007801, disc_loss = 0.0877975101744675
Trained batch 1242 in epoch 3, gen_loss = 0.821250885844902, disc_loss = 0.0879486925706675
Trained batch 1243 in epoch 3, gen_loss = 0.8210068738441375, disc_loss = 0.08803487654065659
Trained batch 1244 in epoch 3, gen_loss = 0.8209333333145662, disc_loss = 0.08813596360579912
Trained batch 1245 in epoch 3, gen_loss = 0.8206244039305906, disc_loss = 0.08824205574285042
Trained batch 1246 in epoch 3, gen_loss = 0.8206464100476734, disc_loss = 0.08819806779441278
Trained batch 1247 in epoch 3, gen_loss = 0.8205502128276305, disc_loss = 0.08818778613483748
Trained batch 1248 in epoch 3, gen_loss = 0.8207912875997057, disc_loss = 0.08821542895629442
Trained batch 1249 in epoch 3, gen_loss = 0.8207183415412903, disc_loss = 0.08816619366332888
Trained batch 1250 in epoch 3, gen_loss = 0.8206555575585003, disc_loss = 0.08814332024272468
Trained batch 1251 in epoch 3, gen_loss = 0.8207191060811948, disc_loss = 0.08815985406189562
Trained batch 1252 in epoch 3, gen_loss = 0.820632847089912, disc_loss = 0.08814193924899374
Trained batch 1253 in epoch 3, gen_loss = 0.8204026404275088, disc_loss = 0.08812000228098016
Trained batch 1254 in epoch 3, gen_loss = 0.8204616417922822, disc_loss = 0.08810217242717625
Trained batch 1255 in epoch 3, gen_loss = 0.8206882746830867, disc_loss = 0.08809386529428825
Trained batch 1256 in epoch 3, gen_loss = 0.8204949886057238, disc_loss = 0.08813211737851136
Trained batch 1257 in epoch 3, gen_loss = 0.8203301388527517, disc_loss = 0.08810057657413978
Trained batch 1258 in epoch 3, gen_loss = 0.8202538273938598, disc_loss = 0.08809804320379772
Trained batch 1259 in epoch 3, gen_loss = 0.8204674146951191, disc_loss = 0.08809142689191042
Trained batch 1260 in epoch 3, gen_loss = 0.820283985062311, disc_loss = 0.0881561277032454
Trained batch 1261 in epoch 3, gen_loss = 0.8205909541971899, disc_loss = 0.08821555941916187
Trained batch 1262 in epoch 3, gen_loss = 0.8205075306922599, disc_loss = 0.0881801937667687
Trained batch 1263 in epoch 3, gen_loss = 0.8204339135296738, disc_loss = 0.08817403816508979
Trained batch 1264 in epoch 3, gen_loss = 0.8205843464659137, disc_loss = 0.08817295083341745
Trained batch 1265 in epoch 3, gen_loss = 0.8203973378427032, disc_loss = 0.08817304065745282
Trained batch 1266 in epoch 3, gen_loss = 0.8202487281108335, disc_loss = 0.08816404818779926
Trained batch 1267 in epoch 3, gen_loss = 0.8201592176306511, disc_loss = 0.0881573832366169
Trained batch 1268 in epoch 3, gen_loss = 0.8203051387089458, disc_loss = 0.0881736500576209
Trained batch 1269 in epoch 3, gen_loss = 0.8202460467346071, disc_loss = 0.08813441365766596
Trained batch 1270 in epoch 3, gen_loss = 0.8200826141235867, disc_loss = 0.08821402151829305
Trained batch 1271 in epoch 3, gen_loss = 0.8199295564173902, disc_loss = 0.08836122040428901
Trained batch 1272 in epoch 3, gen_loss = 0.8199262831123064, disc_loss = 0.08833607857664996
Trained batch 1273 in epoch 3, gen_loss = 0.8201079500058382, disc_loss = 0.08828036704435477
Trained batch 1274 in epoch 3, gen_loss = 0.8200404512648489, disc_loss = 0.08823740579407005
Trained batch 1275 in epoch 3, gen_loss = 0.8201150613425293, disc_loss = 0.08822677501763412
Trained batch 1276 in epoch 3, gen_loss = 0.8202190918668509, disc_loss = 0.08816696135451202
Trained batch 1277 in epoch 3, gen_loss = 0.8204812455531764, disc_loss = 0.08818862840521596
Trained batch 1278 in epoch 3, gen_loss = 0.8202054575609918, disc_loss = 0.08834816999238296
Trained batch 1279 in epoch 3, gen_loss = 0.820070510962978, disc_loss = 0.08836096359009389
Trained batch 1280 in epoch 3, gen_loss = 0.8202318890684754, disc_loss = 0.08832135922758957
Trained batch 1281 in epoch 3, gen_loss = 0.820136825956532, disc_loss = 0.08827511805535386
Trained batch 1282 in epoch 3, gen_loss = 0.8200972057466663, disc_loss = 0.08823067741650023
Trained batch 1283 in epoch 3, gen_loss = 0.8200810571140218, disc_loss = 0.08825623136988589
Trained batch 1284 in epoch 3, gen_loss = 0.8200589236118451, disc_loss = 0.08820383667018163
Trained batch 1285 in epoch 3, gen_loss = 0.8199463739272781, disc_loss = 0.0882079859566911
Trained batch 1286 in epoch 3, gen_loss = 0.8199601385513756, disc_loss = 0.08815595144210579
Trained batch 1287 in epoch 3, gen_loss = 0.8198824678518757, disc_loss = 0.08812971900344496
Trained batch 1288 in epoch 3, gen_loss = 0.8201424842476382, disc_loss = 0.08812196525153354
Trained batch 1289 in epoch 3, gen_loss = 0.819995534604834, disc_loss = 0.0881657922005122
Trained batch 1290 in epoch 3, gen_loss = 0.8202674737002479, disc_loss = 0.08827829746620355
Trained batch 1291 in epoch 3, gen_loss = 0.8202179978506484, disc_loss = 0.08825685805424863
Trained batch 1292 in epoch 3, gen_loss = 0.820262150255544, disc_loss = 0.0882176423412211
Trained batch 1293 in epoch 3, gen_loss = 0.8201151651890237, disc_loss = 0.08827399760283172
Trained batch 1294 in epoch 3, gen_loss = 0.8201861869874608, disc_loss = 0.08830374859733701
Trained batch 1295 in epoch 3, gen_loss = 0.8201369644591102, disc_loss = 0.08826939798575355
Trained batch 1296 in epoch 3, gen_loss = 0.820164183469212, disc_loss = 0.08822083940231167
Trained batch 1297 in epoch 3, gen_loss = 0.8199815676190269, disc_loss = 0.08819452767333558
Trained batch 1298 in epoch 3, gen_loss = 0.820002435766063, disc_loss = 0.08817807200140362
Trained batch 1299 in epoch 3, gen_loss = 0.8200111256654445, disc_loss = 0.08816152039055641
Trained batch 1300 in epoch 3, gen_loss = 0.8200400017207627, disc_loss = 0.08811264724644627
Trained batch 1301 in epoch 3, gen_loss = 0.8200113878180537, disc_loss = 0.08811521949174995
Trained batch 1302 in epoch 3, gen_loss = 0.8199081867818913, disc_loss = 0.08823339458260505
Trained batch 1303 in epoch 3, gen_loss = 0.8198538336194366, disc_loss = 0.08825645539938169
Trained batch 1304 in epoch 3, gen_loss = 0.8197551421278738, disc_loss = 0.08823190324750668
Trained batch 1305 in epoch 3, gen_loss = 0.8202129029205346, disc_loss = 0.08826255657001303
Trained batch 1306 in epoch 3, gen_loss = 0.8203746227243973, disc_loss = 0.08821573585853289
Trained batch 1307 in epoch 3, gen_loss = 0.8200966541737956, disc_loss = 0.08828021487112894
Trained batch 1308 in epoch 3, gen_loss = 0.8202221634007302, disc_loss = 0.08826736809587643
Trained batch 1309 in epoch 3, gen_loss = 0.8201867593153742, disc_loss = 0.08833352258812835
Trained batch 1310 in epoch 3, gen_loss = 0.8201258884050935, disc_loss = 0.08831730319867599
Trained batch 1311 in epoch 3, gen_loss = 0.8200019437183694, disc_loss = 0.08829046763400207
Trained batch 1312 in epoch 3, gen_loss = 0.8199183084723247, disc_loss = 0.08828871172582567
Trained batch 1313 in epoch 3, gen_loss = 0.8199220237122279, disc_loss = 0.08825366601313903
Trained batch 1314 in epoch 3, gen_loss = 0.8204050825575911, disc_loss = 0.08840454364400853
Trained batch 1315 in epoch 3, gen_loss = 0.820417230252437, disc_loss = 0.08836599459481004
Trained batch 1316 in epoch 3, gen_loss = 0.8202528171495859, disc_loss = 0.0885657022029003
Trained batch 1317 in epoch 3, gen_loss = 0.8203296123216655, disc_loss = 0.0885180688232794
Trained batch 1318 in epoch 3, gen_loss = 0.8205955869958109, disc_loss = 0.08852375806694097
Trained batch 1319 in epoch 3, gen_loss = 0.8205729169375968, disc_loss = 0.08847759948676509
Trained batch 1320 in epoch 3, gen_loss = 0.8203721455693876, disc_loss = 0.08854555497249134
Trained batch 1321 in epoch 3, gen_loss = 0.820392527306134, disc_loss = 0.08854724614600595
Trained batch 1322 in epoch 3, gen_loss = 0.8204747296514965, disc_loss = 0.08853262642754674
Trained batch 1323 in epoch 3, gen_loss = 0.8204026207823047, disc_loss = 0.08853431857610262
Trained batch 1324 in epoch 3, gen_loss = 0.8205723630257372, disc_loss = 0.08853142667632058
Trained batch 1325 in epoch 3, gen_loss = 0.8204105647890456, disc_loss = 0.0885410292501116
Trained batch 1326 in epoch 3, gen_loss = 0.8204674810597837, disc_loss = 0.0886586635094908
Trained batch 1327 in epoch 3, gen_loss = 0.8203878615455455, disc_loss = 0.08864019332728516
Trained batch 1328 in epoch 3, gen_loss = 0.8202818501166063, disc_loss = 0.08866209979817283
Trained batch 1329 in epoch 3, gen_loss = 0.8201560029858037, disc_loss = 0.08873692171270013
Trained batch 1330 in epoch 3, gen_loss = 0.8200647579736946, disc_loss = 0.08882123838262079
Trained batch 1331 in epoch 3, gen_loss = 0.8203556451264087, disc_loss = 0.08879065428169684
Trained batch 1332 in epoch 3, gen_loss = 0.8203694934426441, disc_loss = 0.08873718288508423
Trained batch 1333 in epoch 3, gen_loss = 0.8201566388135192, disc_loss = 0.0887460135484765
Trained batch 1334 in epoch 3, gen_loss = 0.8202990084105216, disc_loss = 0.0886924460600043
Trained batch 1335 in epoch 3, gen_loss = 0.820287502722112, disc_loss = 0.08867681817385831
Trained batch 1336 in epoch 3, gen_loss = 0.8203940545344585, disc_loss = 0.08865776716709894
Trained batch 1337 in epoch 3, gen_loss = 0.820378274616461, disc_loss = 0.0886217980995017
Trained batch 1338 in epoch 3, gen_loss = 0.8202664606868553, disc_loss = 0.08860444802654555
Trained batch 1339 in epoch 3, gen_loss = 0.8201919221611166, disc_loss = 0.08858828556153979
Trained batch 1340 in epoch 3, gen_loss = 0.820227190463246, disc_loss = 0.0886251384754909
Trained batch 1341 in epoch 3, gen_loss = 0.8200673020809844, disc_loss = 0.08864050259016976
Trained batch 1342 in epoch 3, gen_loss = 0.8200019349025774, disc_loss = 0.0886224092803313
Trained batch 1343 in epoch 3, gen_loss = 0.8198107449071748, disc_loss = 0.08877280919252717
Trained batch 1344 in epoch 3, gen_loss = 0.8200211604731676, disc_loss = 0.08872170506606093
Trained batch 1345 in epoch 3, gen_loss = 0.8198586202394024, disc_loss = 0.0887197740057713
Trained batch 1346 in epoch 3, gen_loss = 0.8198725044417576, disc_loss = 0.08868885912144946
Trained batch 1347 in epoch 3, gen_loss = 0.8197027344908842, disc_loss = 0.08868960856711519
Trained batch 1348 in epoch 3, gen_loss = 0.8198129281545233, disc_loss = 0.08870169988869958
Trained batch 1349 in epoch 3, gen_loss = 0.8195879729588826, disc_loss = 0.08870326533499691
Trained batch 1350 in epoch 3, gen_loss = 0.8197377176305967, disc_loss = 0.08874250834960791
Trained batch 1351 in epoch 3, gen_loss = 0.819816266247154, disc_loss = 0.08871879638172686
Trained batch 1352 in epoch 3, gen_loss = 0.819651805200316, disc_loss = 0.08870518845364903
Trained batch 1353 in epoch 3, gen_loss = 0.8194000746510054, disc_loss = 0.08877774021083398
Trained batch 1354 in epoch 3, gen_loss = 0.8195816257343082, disc_loss = 0.08874910895152506
Trained batch 1355 in epoch 3, gen_loss = 0.8196139927722711, disc_loss = 0.08874566958678727
Trained batch 1356 in epoch 3, gen_loss = 0.8197785156038463, disc_loss = 0.0887789017450155
Trained batch 1357 in epoch 3, gen_loss = 0.8195892783521026, disc_loss = 0.08889036948363323
Trained batch 1358 in epoch 3, gen_loss = 0.8193865954393494, disc_loss = 0.08892845005657718
Trained batch 1359 in epoch 3, gen_loss = 0.8196281555382644, disc_loss = 0.0889282252324526
Trained batch 1360 in epoch 3, gen_loss = 0.8198459445773285, disc_loss = 0.08893646743945083
Trained batch 1361 in epoch 3, gen_loss = 0.8198255570974644, disc_loss = 0.08891431435740248
Trained batch 1362 in epoch 3, gen_loss = 0.8196494639225944, disc_loss = 0.08901379838372668
Trained batch 1363 in epoch 3, gen_loss = 0.8196215939836419, disc_loss = 0.0890465252131464
Trained batch 1364 in epoch 3, gen_loss = 0.8199904329174168, disc_loss = 0.08917664943242466
Trained batch 1365 in epoch 3, gen_loss = 0.8198655282595845, disc_loss = 0.08916550022611289
Trained batch 1366 in epoch 3, gen_loss = 0.8197508001292633, disc_loss = 0.08915270032019143
Trained batch 1367 in epoch 3, gen_loss = 0.8195884167625193, disc_loss = 0.08911030361978936
Trained batch 1368 in epoch 3, gen_loss = 0.8196684805645047, disc_loss = 0.08913648319944271
Trained batch 1369 in epoch 3, gen_loss = 0.8197016813459187, disc_loss = 0.08908135365613186
Trained batch 1370 in epoch 3, gen_loss = 0.8196364836828453, disc_loss = 0.08904325318088678
Trained batch 1371 in epoch 3, gen_loss = 0.8194982844782293, disc_loss = 0.08904350996994938
Trained batch 1372 in epoch 3, gen_loss = 0.8193662974926476, disc_loss = 0.0890884780299898
Trained batch 1373 in epoch 3, gen_loss = 0.8191548841835977, disc_loss = 0.0890462223245197
Trained batch 1374 in epoch 3, gen_loss = 0.8189090873544866, disc_loss = 0.0890537651154128
Trained batch 1375 in epoch 3, gen_loss = 0.8189296877488147, disc_loss = 0.08900064549430511
Trained batch 1376 in epoch 3, gen_loss = 0.8191705672915811, disc_loss = 0.08898360468853013
Trained batch 1377 in epoch 3, gen_loss = 0.8190794361347038, disc_loss = 0.08896907750403588
Trained batch 1378 in epoch 3, gen_loss = 0.8190725190298898, disc_loss = 0.08892903082272642
Trained batch 1379 in epoch 3, gen_loss = 0.8190457480541175, disc_loss = 0.0889846002413095
Trained batch 1380 in epoch 3, gen_loss = 0.8191656985203483, disc_loss = 0.08899412880625351
Trained batch 1381 in epoch 3, gen_loss = 0.8189956643301912, disc_loss = 0.08906730575764663
Trained batch 1382 in epoch 3, gen_loss = 0.8191406156218578, disc_loss = 0.0890154204010123
Trained batch 1383 in epoch 3, gen_loss = 0.819168366922464, disc_loss = 0.08898150608228854
Trained batch 1384 in epoch 3, gen_loss = 0.8193996053740435, disc_loss = 0.08893510321229159
Trained batch 1385 in epoch 3, gen_loss = 0.8195175857082934, disc_loss = 0.08888205234767683
Trained batch 1386 in epoch 3, gen_loss = 0.8193777025648391, disc_loss = 0.08884979039833497
Trained batch 1387 in epoch 3, gen_loss = 0.8193278036990151, disc_loss = 0.08885440263516063
Trained batch 1388 in epoch 3, gen_loss = 0.8191955026917701, disc_loss = 0.08882697827341618
Trained batch 1389 in epoch 3, gen_loss = 0.8191609848746293, disc_loss = 0.08878978689556284
Trained batch 1390 in epoch 3, gen_loss = 0.8191481516740032, disc_loss = 0.08873880694343793
Trained batch 1391 in epoch 3, gen_loss = 0.8190780974838926, disc_loss = 0.08869878267039727
Trained batch 1392 in epoch 3, gen_loss = 0.8190647311032632, disc_loss = 0.08865578826289552
Trained batch 1393 in epoch 3, gen_loss = 0.8188834924523424, disc_loss = 0.08864932398377268
Trained batch 1394 in epoch 3, gen_loss = 0.8188640224890897, disc_loss = 0.08865961359954008
Trained batch 1395 in epoch 3, gen_loss = 0.8188540135806475, disc_loss = 0.08863113488185415
Trained batch 1396 in epoch 3, gen_loss = 0.8191298623979305, disc_loss = 0.08861936951614784
Trained batch 1397 in epoch 3, gen_loss = 0.8190129823524382, disc_loss = 0.08859772560918153
Trained batch 1398 in epoch 3, gen_loss = 0.8188277759494059, disc_loss = 0.08860924170672724
Trained batch 1399 in epoch 3, gen_loss = 0.8187667648707118, disc_loss = 0.08858748891923045
Trained batch 1400 in epoch 3, gen_loss = 0.8187041273719493, disc_loss = 0.08856440125316445
Trained batch 1401 in epoch 3, gen_loss = 0.8186968935709367, disc_loss = 0.08855020226551999
Trained batch 1402 in epoch 3, gen_loss = 0.8186084690556217, disc_loss = 0.08853699260936282
Trained batch 1403 in epoch 3, gen_loss = 0.818608082979493, disc_loss = 0.08852313638152687
Trained batch 1404 in epoch 3, gen_loss = 0.8184817783773157, disc_loss = 0.08851583183633688
Trained batch 1405 in epoch 3, gen_loss = 0.8185499986662803, disc_loss = 0.08847384787778004
Trained batch 1406 in epoch 3, gen_loss = 0.818504283804375, disc_loss = 0.08843086066032947
Trained batch 1407 in epoch 3, gen_loss = 0.818447747733444, disc_loss = 0.08841697137474759
Trained batch 1408 in epoch 3, gen_loss = 0.8184609684730947, disc_loss = 0.08836435992535101
Trained batch 1409 in epoch 3, gen_loss = 0.8185260302631567, disc_loss = 0.08832287203243121
Trained batch 1410 in epoch 3, gen_loss = 0.8187201908511696, disc_loss = 0.0882715459505108
Trained batch 1411 in epoch 3, gen_loss = 0.8184529763063357, disc_loss = 0.08830822551578135
Trained batch 1412 in epoch 3, gen_loss = 0.818677072038232, disc_loss = 0.08826230636086665
Trained batch 1413 in epoch 3, gen_loss = 0.8188515624829701, disc_loss = 0.08825368424640413
Trained batch 1414 in epoch 3, gen_loss = 0.818789688753155, disc_loss = 0.08821165300708252
Trained batch 1415 in epoch 3, gen_loss = 0.8186294393308755, disc_loss = 0.0882258893899609
Trained batch 1416 in epoch 3, gen_loss = 0.8186289111366555, disc_loss = 0.08818245862709882
Trained batch 1417 in epoch 3, gen_loss = 0.8186149374175979, disc_loss = 0.08823681424197193
Trained batch 1418 in epoch 3, gen_loss = 0.8184162019381144, disc_loss = 0.0882353979242287
Trained batch 1419 in epoch 3, gen_loss = 0.8185729276756166, disc_loss = 0.08826542004588729
Trained batch 1420 in epoch 3, gen_loss = 0.8185934704806417, disc_loss = 0.08821035202731556
Trained batch 1421 in epoch 3, gen_loss = 0.8184297381364511, disc_loss = 0.08821862135947002
Trained batch 1422 in epoch 3, gen_loss = 0.8183471540582071, disc_loss = 0.08819666105889973
Trained batch 1423 in epoch 3, gen_loss = 0.8184401376821687, disc_loss = 0.08814863655376091
Trained batch 1424 in epoch 3, gen_loss = 0.8187509870320036, disc_loss = 0.08824077030937923
Trained batch 1425 in epoch 3, gen_loss = 0.818919653122589, disc_loss = 0.0882088169311846
Trained batch 1426 in epoch 3, gen_loss = 0.8188006832579591, disc_loss = 0.0883094932434959
Trained batch 1427 in epoch 3, gen_loss = 0.8189165295631278, disc_loss = 0.08826027552438091
Trained batch 1428 in epoch 3, gen_loss = 0.8188783669279871, disc_loss = 0.0882204390522627
Trained batch 1429 in epoch 3, gen_loss = 0.8190921394766627, disc_loss = 0.08830002570147072
Trained batch 1430 in epoch 3, gen_loss = 0.818795630621127, disc_loss = 0.08843482922369537
Trained batch 1431 in epoch 3, gen_loss = 0.8189286074533476, disc_loss = 0.08844974280501502
Trained batch 1432 in epoch 3, gen_loss = 0.8189291026695409, disc_loss = 0.0884109852667859
Trained batch 1433 in epoch 3, gen_loss = 0.8188214883353754, disc_loss = 0.08838902700775546
Trained batch 1434 in epoch 3, gen_loss = 0.8189507214657521, disc_loss = 0.08835997307731507
Trained batch 1435 in epoch 3, gen_loss = 0.818968677856962, disc_loss = 0.08831296465294773
Trained batch 1436 in epoch 3, gen_loss = 0.8190134718298663, disc_loss = 0.08826691978244874
Trained batch 1437 in epoch 3, gen_loss = 0.8188536905570886, disc_loss = 0.08825250580823969
Trained batch 1438 in epoch 3, gen_loss = 0.8187993118918713, disc_loss = 0.088227734798106
Trained batch 1439 in epoch 3, gen_loss = 0.8186826303808226, disc_loss = 0.08822328503140145
Trained batch 1440 in epoch 3, gen_loss = 0.8188000568534499, disc_loss = 0.08820261697153678
Trained batch 1441 in epoch 3, gen_loss = 0.8187534769637905, disc_loss = 0.08829268802799563
Trained batch 1442 in epoch 3, gen_loss = 0.8188190971367573, disc_loss = 0.08828015573844263
Trained batch 1443 in epoch 3, gen_loss = 0.818749226258237, disc_loss = 0.088290696102001
Trained batch 1444 in epoch 3, gen_loss = 0.8188000946515159, disc_loss = 0.08826938619560024
Trained batch 1445 in epoch 3, gen_loss = 0.818996750158393, disc_loss = 0.08823416654128752
Trained batch 1446 in epoch 3, gen_loss = 0.8187629856689271, disc_loss = 0.08829319807646105
Trained batch 1447 in epoch 3, gen_loss = 0.8187572940237285, disc_loss = 0.08827019820391144
Trained batch 1448 in epoch 3, gen_loss = 0.8187869523746379, disc_loss = 0.08824410988307148
Trained batch 1449 in epoch 3, gen_loss = 0.8187542119313931, disc_loss = 0.08821771583166615
Trained batch 1450 in epoch 3, gen_loss = 0.8189705489299611, disc_loss = 0.08818483078463335
Trained batch 1451 in epoch 3, gen_loss = 0.8186709118324534, disc_loss = 0.08831246196197412
Trained batch 1452 in epoch 3, gen_loss = 0.8187698426323764, disc_loss = 0.0882667408049804
Trained batch 1453 in epoch 3, gen_loss = 0.8190216641191603, disc_loss = 0.08834105040852437
Trained batch 1454 in epoch 3, gen_loss = 0.8191026835302307, disc_loss = 0.08828920677073837
Trained batch 1455 in epoch 3, gen_loss = 0.8188306913393867, disc_loss = 0.08835286791513132
Trained batch 1456 in epoch 3, gen_loss = 0.818863323660198, disc_loss = 0.08831489183949581
Trained batch 1457 in epoch 3, gen_loss = 0.8188217148818433, disc_loss = 0.08831428507130865
Trained batch 1458 in epoch 3, gen_loss = 0.8188453091383797, disc_loss = 0.08833651296855694
Trained batch 1459 in epoch 3, gen_loss = 0.8188892430434488, disc_loss = 0.08828687862403793
Trained batch 1460 in epoch 3, gen_loss = 0.8189640326462405, disc_loss = 0.08823616971171919
Trained batch 1461 in epoch 3, gen_loss = 0.818726714002287, disc_loss = 0.0882425420311128
Trained batch 1462 in epoch 3, gen_loss = 0.8189046325662408, disc_loss = 0.08820036591380143
Trained batch 1463 in epoch 3, gen_loss = 0.8188468742036754, disc_loss = 0.08819739317936222
Trained batch 1464 in epoch 3, gen_loss = 0.818764734532646, disc_loss = 0.08817885798996525
Trained batch 1465 in epoch 3, gen_loss = 0.8187335894873815, disc_loss = 0.08813088167507054
Trained batch 1466 in epoch 3, gen_loss = 0.8186592191315543, disc_loss = 0.08809496845095212
Trained batch 1467 in epoch 3, gen_loss = 0.8188462947832791, disc_loss = 0.0880423490312052
Trained batch 1468 in epoch 3, gen_loss = 0.8188349821074143, disc_loss = 0.08807200848881264
Trained batch 1469 in epoch 3, gen_loss = 0.8190108704931882, disc_loss = 0.08802685359949056
Trained batch 1470 in epoch 3, gen_loss = 0.8189013788969155, disc_loss = 0.08804090374689436
Trained batch 1471 in epoch 3, gen_loss = 0.8186266850477651, disc_loss = 0.08807761527777588
Trained batch 1472 in epoch 3, gen_loss = 0.8188353940207215, disc_loss = 0.08816697651258615
Trained batch 1473 in epoch 3, gen_loss = 0.8189869978170705, disc_loss = 0.08817292325226452
Trained batch 1474 in epoch 3, gen_loss = 0.8190825100874497, disc_loss = 0.08814811092501475
Trained batch 1475 in epoch 3, gen_loss = 0.8189557759459749, disc_loss = 0.08822506144428298
Trained batch 1476 in epoch 3, gen_loss = 0.8190123541942705, disc_loss = 0.08820795187803544
Trained batch 1477 in epoch 3, gen_loss = 0.8189487580073864, disc_loss = 0.08821124412278179
Trained batch 1478 in epoch 3, gen_loss = 0.8189146331107802, disc_loss = 0.0882050296495731
Trained batch 1479 in epoch 3, gen_loss = 0.8189411091039309, disc_loss = 0.08816622013817667
Trained batch 1480 in epoch 3, gen_loss = 0.8189491140810241, disc_loss = 0.08823837342330586
Trained batch 1481 in epoch 3, gen_loss = 0.8190844892530467, disc_loss = 0.08819235792740496
Trained batch 1482 in epoch 3, gen_loss = 0.8190337930148466, disc_loss = 0.08816321338423284
Trained batch 1483 in epoch 3, gen_loss = 0.8190642883072323, disc_loss = 0.08812638931290179
Trained batch 1484 in epoch 3, gen_loss = 0.8191866274433907, disc_loss = 0.088093636697315
Trained batch 1485 in epoch 3, gen_loss = 0.8193024634552837, disc_loss = 0.0880523007845664
Trained batch 1486 in epoch 3, gen_loss = 0.819159566374056, disc_loss = 0.08808150983753125
Trained batch 1487 in epoch 3, gen_loss = 0.8191317596462786, disc_loss = 0.08812330809474413
Trained batch 1488 in epoch 3, gen_loss = 0.8191298105277977, disc_loss = 0.08808933344623981
Trained batch 1489 in epoch 3, gen_loss = 0.819105842269507, disc_loss = 0.08804633381070207
Trained batch 1490 in epoch 3, gen_loss = 0.819474077940307, disc_loss = 0.08802009672413709
Trained batch 1491 in epoch 3, gen_loss = 0.8194327760118262, disc_loss = 0.08797777884380129
Trained batch 1492 in epoch 3, gen_loss = 0.8194882407614791, disc_loss = 0.08792925287631939
Trained batch 1493 in epoch 3, gen_loss = 0.8195145333028702, disc_loss = 0.08789488357470597
Trained batch 1494 in epoch 3, gen_loss = 0.8194568036990022, disc_loss = 0.08790212195790233
Trained batch 1495 in epoch 3, gen_loss = 0.8195134519056522, disc_loss = 0.08786215964283914
Trained batch 1496 in epoch 3, gen_loss = 0.8197518253254747, disc_loss = 0.08781182043983507
Trained batch 1497 in epoch 3, gen_loss = 0.8196812032340206, disc_loss = 0.08778430988703753
Trained batch 1498 in epoch 3, gen_loss = 0.8197527637753668, disc_loss = 0.08775478387667765
Trained batch 1499 in epoch 3, gen_loss = 0.8198022793332735, disc_loss = 0.08773339655436575
Trained batch 1500 in epoch 3, gen_loss = 0.8198027772199782, disc_loss = 0.08770005504906594
Trained batch 1501 in epoch 3, gen_loss = 0.8199338848874985, disc_loss = 0.08769874512025722
Trained batch 1502 in epoch 3, gen_loss = 0.8197954974210984, disc_loss = 0.08770589615916678
Trained batch 1503 in epoch 3, gen_loss = 0.8197322621188582, disc_loss = 0.08768557810826484
Trained batch 1504 in epoch 3, gen_loss = 0.8198058850147399, disc_loss = 0.08771445924645148
Trained batch 1505 in epoch 3, gen_loss = 0.819711572561131, disc_loss = 0.0877325878624531
Trained batch 1506 in epoch 3, gen_loss = 0.8195160494668641, disc_loss = 0.08778985304165911
Trained batch 1507 in epoch 3, gen_loss = 0.8196620937407175, disc_loss = 0.08781801475105752
Trained batch 1508 in epoch 3, gen_loss = 0.8197049747206977, disc_loss = 0.08783100238977144
Trained batch 1509 in epoch 3, gen_loss = 0.819660949884661, disc_loss = 0.0877880019468829
Trained batch 1510 in epoch 3, gen_loss = 0.819639981364983, disc_loss = 0.08775989637382867
Trained batch 1511 in epoch 3, gen_loss = 0.8195650759473364, disc_loss = 0.08776109510966178
Trained batch 1512 in epoch 3, gen_loss = 0.8196097479028884, disc_loss = 0.0877354094630596
Trained batch 1513 in epoch 3, gen_loss = 0.8198847194132118, disc_loss = 0.08786358110559919
Trained batch 1514 in epoch 3, gen_loss = 0.8200616144701199, disc_loss = 0.08781561147753555
Trained batch 1515 in epoch 3, gen_loss = 0.8199965402012136, disc_loss = 0.08780890286440585
Trained batch 1516 in epoch 3, gen_loss = 0.8197421511891805, disc_loss = 0.08793091770057704
Trained batch 1517 in epoch 3, gen_loss = 0.8197045966845413, disc_loss = 0.08792788387130214
Trained batch 1518 in epoch 3, gen_loss = 0.8196724956760758, disc_loss = 0.08799450338828556
Trained batch 1519 in epoch 3, gen_loss = 0.8196865627444104, disc_loss = 0.08796274393404785
Trained batch 1520 in epoch 3, gen_loss = 0.8194168472587866, disc_loss = 0.08817051160029876
Trained batch 1521 in epoch 3, gen_loss = 0.8196118577786093, disc_loss = 0.08826421052413294
Trained batch 1522 in epoch 3, gen_loss = 0.8196975678812103, disc_loss = 0.08826299406984332
Trained batch 1523 in epoch 3, gen_loss = 0.819609422266014, disc_loss = 0.08824033346124913
Trained batch 1524 in epoch 3, gen_loss = 0.8197055324570077, disc_loss = 0.0882122462108487
Trained batch 1525 in epoch 3, gen_loss = 0.8198093216119243, disc_loss = 0.08816391578600846
Trained batch 1526 in epoch 3, gen_loss = 0.8196945495674168, disc_loss = 0.0881328701975401
Trained batch 1527 in epoch 3, gen_loss = 0.8196479042319103, disc_loss = 0.08812411832233101
Trained batch 1528 in epoch 3, gen_loss = 0.8195566808265202, disc_loss = 0.08810406152531748
Trained batch 1529 in epoch 3, gen_loss = 0.819414539196912, disc_loss = 0.08813657901962013
Trained batch 1530 in epoch 3, gen_loss = 0.8193161482128888, disc_loss = 0.0881287299843589
Trained batch 1531 in epoch 3, gen_loss = 0.8192284406787733, disc_loss = 0.0881103852644621
Trained batch 1532 in epoch 3, gen_loss = 0.8192826938722465, disc_loss = 0.08808163418243192
Trained batch 1533 in epoch 3, gen_loss = 0.8192163200701698, disc_loss = 0.08810132178884714
Trained batch 1534 in epoch 3, gen_loss = 0.8191243232267299, disc_loss = 0.08810775331327697
Trained batch 1535 in epoch 3, gen_loss = 0.8189713382550204, disc_loss = 0.08809139139945425
Trained batch 1536 in epoch 3, gen_loss = 0.8190996239304775, disc_loss = 0.08806771075228204
Trained batch 1537 in epoch 3, gen_loss = 0.8189922121628364, disc_loss = 0.08804086376688841
Trained batch 1538 in epoch 3, gen_loss = 0.81912512233925, disc_loss = 0.0880062108274847
Trained batch 1539 in epoch 3, gen_loss = 0.8191050179592975, disc_loss = 0.0879756352017549
Trained batch 1540 in epoch 3, gen_loss = 0.8193931999645939, disc_loss = 0.08794224279522316
Trained batch 1541 in epoch 3, gen_loss = 0.8194002141903037, disc_loss = 0.08790111020400676
Trained batch 1542 in epoch 3, gen_loss = 0.819480292069317, disc_loss = 0.08788461982238162
Trained batch 1543 in epoch 3, gen_loss = 0.8193931527860424, disc_loss = 0.08786112480251591
Trained batch 1544 in epoch 3, gen_loss = 0.8194172044402187, disc_loss = 0.08784931251435604
Trained batch 1545 in epoch 3, gen_loss = 0.8195193285389983, disc_loss = 0.0878182869949131
Trained batch 1546 in epoch 3, gen_loss = 0.8194425127239634, disc_loss = 0.08777155531612457
Trained batch 1547 in epoch 3, gen_loss = 0.81936855360057, disc_loss = 0.0877960989015894
Trained batch 1548 in epoch 3, gen_loss = 0.8194530096032528, disc_loss = 0.08776831080724609
Trained batch 1549 in epoch 3, gen_loss = 0.8195689037153798, disc_loss = 0.08776604308476371
Trained batch 1550 in epoch 3, gen_loss = 0.819395510055879, disc_loss = 0.08779990268831557
Trained batch 1551 in epoch 3, gen_loss = 0.8195155175767609, disc_loss = 0.08778243270443425
Trained batch 1552 in epoch 3, gen_loss = 0.8194916543466233, disc_loss = 0.08774188671954317
Trained batch 1553 in epoch 3, gen_loss = 0.8195495419827514, disc_loss = 0.08771720338142938
Trained batch 1554 in epoch 3, gen_loss = 0.8197503761463226, disc_loss = 0.08767264141099246
Trained batch 1555 in epoch 3, gen_loss = 0.8198764967734525, disc_loss = 0.08762458732512068
Trained batch 1556 in epoch 3, gen_loss = 0.8201575662053083, disc_loss = 0.08759936186507124
Trained batch 1557 in epoch 3, gen_loss = 0.8200529597613564, disc_loss = 0.08758865689992694
Trained batch 1558 in epoch 3, gen_loss = 0.8199544079874173, disc_loss = 0.08757075574249029
Trained batch 1559 in epoch 3, gen_loss = 0.8200797270505856, disc_loss = 0.08752095616207672
Trained batch 1560 in epoch 3, gen_loss = 0.8199702573845892, disc_loss = 0.08751917189890418
Trained batch 1561 in epoch 3, gen_loss = 0.8202904763508698, disc_loss = 0.08755818641864994
Trained batch 1562 in epoch 3, gen_loss = 0.8204772452551512, disc_loss = 0.08752683223352094
Trained batch 1563 in epoch 3, gen_loss = 0.8204573350946617, disc_loss = 0.08748812227250288
Trained batch 1564 in epoch 3, gen_loss = 0.8203462807134317, disc_loss = 0.08748940054458171
Trained batch 1565 in epoch 3, gen_loss = 0.8203897099385317, disc_loss = 0.08745681399082239
Trained batch 1566 in epoch 3, gen_loss = 0.8202979757516492, disc_loss = 0.08745499314465717
Trained batch 1567 in epoch 3, gen_loss = 0.8202063552655128, disc_loss = 0.08742383310846909
Trained batch 1568 in epoch 3, gen_loss = 0.8201834471686165, disc_loss = 0.08743140431699135
Trained batch 1569 in epoch 3, gen_loss = 0.8204382761268859, disc_loss = 0.08748895215333267
Trained batch 1570 in epoch 3, gen_loss = 0.8202012014912619, disc_loss = 0.08749298319543038
Trained batch 1571 in epoch 3, gen_loss = 0.8201305739031797, disc_loss = 0.08748653392916493
Trained batch 1572 in epoch 3, gen_loss = 0.8200700213518101, disc_loss = 0.08747190913186662
Trained batch 1573 in epoch 3, gen_loss = 0.8199811765055492, disc_loss = 0.08745483581208668
Trained batch 1574 in epoch 3, gen_loss = 0.820211224347826, disc_loss = 0.08742151229154496
Trained batch 1575 in epoch 3, gen_loss = 0.8204274725376954, disc_loss = 0.08747621903640365
Trained batch 1576 in epoch 3, gen_loss = 0.8202714046384234, disc_loss = 0.08751262692272777
Trained batch 1577 in epoch 3, gen_loss = 0.8202496850331926, disc_loss = 0.08749232318899175
Trained batch 1578 in epoch 3, gen_loss = 0.8203833823607193, disc_loss = 0.08744735257290752
Trained batch 1579 in epoch 3, gen_loss = 0.8206071736880496, disc_loss = 0.08757209952543431
Trained batch 1580 in epoch 3, gen_loss = 0.8205222431841265, disc_loss = 0.08755793072551885
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 0.7192205190658569, disc_loss = 0.06570743024349213
Trained batch 1 in epoch 4, gen_loss = 0.8868004679679871, disc_loss = 0.0477535268291831
Trained batch 2 in epoch 4, gen_loss = 0.862204114596049, disc_loss = 0.04316219501197338
Trained batch 3 in epoch 4, gen_loss = 0.8443881869316101, disc_loss = 0.059235234279185534
Trained batch 4 in epoch 4, gen_loss = 0.8409349679946899, disc_loss = 0.09760922528803348
Trained batch 5 in epoch 4, gen_loss = 0.8078445295492808, disc_loss = 0.09426378489782412
Trained batch 6 in epoch 4, gen_loss = 0.780213109084538, disc_loss = 0.08914584001260144
Trained batch 7 in epoch 4, gen_loss = 0.7640200927853584, disc_loss = 0.08960902947001159
Trained batch 8 in epoch 4, gen_loss = 0.7342012855741713, disc_loss = 0.10783405664066474
Trained batch 9 in epoch 4, gen_loss = 0.7473792910575867, disc_loss = 0.10623969864100218
Trained batch 10 in epoch 4, gen_loss = 0.74200285022909, disc_loss = 0.10251542367041111
Trained batch 11 in epoch 4, gen_loss = 0.7364838918050131, disc_loss = 0.09940553378934662
Trained batch 12 in epoch 4, gen_loss = 0.7564425193346463, disc_loss = 0.09806024440779136
Trained batch 13 in epoch 4, gen_loss = 0.7557237574032375, disc_loss = 0.10186358740819353
Trained batch 14 in epoch 4, gen_loss = 0.7467698017756145, disc_loss = 0.10403333293894927
Trained batch 15 in epoch 4, gen_loss = 0.7605745941400528, disc_loss = 0.10617496992927045
Trained batch 16 in epoch 4, gen_loss = 0.7540693738881279, disc_loss = 0.10660756719024743
Trained batch 17 in epoch 4, gen_loss = 0.7598246799574958, disc_loss = 0.10288831622650225
Trained batch 18 in epoch 4, gen_loss = 0.7571798437520078, disc_loss = 0.1027872847687257
Trained batch 19 in epoch 4, gen_loss = 0.7717851340770722, disc_loss = 0.09917959524318576
Trained batch 20 in epoch 4, gen_loss = 0.7795638981319609, disc_loss = 0.09789474370578925
Trained batch 21 in epoch 4, gen_loss = 0.7826908962293104, disc_loss = 0.09525028235194358
Trained batch 22 in epoch 4, gen_loss = 0.7782152450602987, disc_loss = 0.09534807592306448
Trained batch 23 in epoch 4, gen_loss = 0.786330483853817, disc_loss = 0.09794700106916328
Trained batch 24 in epoch 4, gen_loss = 0.7981156420707702, disc_loss = 0.09547740377485753
Trained batch 25 in epoch 4, gen_loss = 0.7883404264083276, disc_loss = 0.09736075345426798
Trained batch 26 in epoch 4, gen_loss = 0.7922213717743203, disc_loss = 0.09493795968592167
Trained batch 27 in epoch 4, gen_loss = 0.8023310665573392, disc_loss = 0.09275741256507379
Trained batch 28 in epoch 4, gen_loss = 0.8158533758130567, disc_loss = 0.09457490484005418
Trained batch 29 in epoch 4, gen_loss = 0.8058840076128642, disc_loss = 0.09580149371176958
Trained batch 30 in epoch 4, gen_loss = 0.8054257862029537, disc_loss = 0.09419324002679318
Trained batch 31 in epoch 4, gen_loss = 0.8238234184682369, disc_loss = 0.09453903342364356
Trained batch 32 in epoch 4, gen_loss = 0.8167385188016024, disc_loss = 0.09424243455357624
Trained batch 33 in epoch 4, gen_loss = 0.8198931252255159, disc_loss = 0.09226225727402113
Trained batch 34 in epoch 4, gen_loss = 0.824407376561846, disc_loss = 0.08989626773233925
Trained batch 35 in epoch 4, gen_loss = 0.8262389699618021, disc_loss = 0.08781495322990748
Trained batch 36 in epoch 4, gen_loss = 0.8305296543482188, disc_loss = 0.08586938991337209
Trained batch 37 in epoch 4, gen_loss = 0.828090062266902, disc_loss = 0.08453772442513391
Trained batch 38 in epoch 4, gen_loss = 0.831431433176383, disc_loss = 0.08255600790755871
Trained batch 39 in epoch 4, gen_loss = 0.8380902454257011, disc_loss = 0.08103511407971382
Trained batch 40 in epoch 4, gen_loss = 0.841480784299897, disc_loss = 0.08023884592623245
Trained batch 41 in epoch 4, gen_loss = 0.8402138324010939, disc_loss = 0.0787428751410473
Trained batch 42 in epoch 4, gen_loss = 0.8395172537759293, disc_loss = 0.07747592491119407
Trained batch 43 in epoch 4, gen_loss = 0.8426609513434496, disc_loss = 0.07594337739812379
Trained batch 44 in epoch 4, gen_loss = 0.8493870033158196, disc_loss = 0.07475419468763801
Trained batch 45 in epoch 4, gen_loss = 0.8557449980922367, disc_loss = 0.07349420697225825
Trained batch 46 in epoch 4, gen_loss = 0.8507774142508812, disc_loss = 0.07419844893144166
Trained batch 47 in epoch 4, gen_loss = 0.8490530140697956, disc_loss = 0.07383063018399601
Trained batch 48 in epoch 4, gen_loss = 0.8500475433407998, disc_loss = 0.07317346594847586
Trained batch 49 in epoch 4, gen_loss = 0.8516566455364227, disc_loss = 0.07186602069996298
Trained batch 50 in epoch 4, gen_loss = 0.8547207315762838, disc_loss = 0.07173704851747435
Trained batch 51 in epoch 4, gen_loss = 0.8493267870866336, disc_loss = 0.07166655948206496
Trained batch 52 in epoch 4, gen_loss = 0.8451141152741775, disc_loss = 0.0722295518103495
Trained batch 53 in epoch 4, gen_loss = 0.8449737793869443, disc_loss = 0.07123155477111814
Trained batch 54 in epoch 4, gen_loss = 0.8561809659004211, disc_loss = 0.07259969574991952
Trained batch 55 in epoch 4, gen_loss = 0.849027406424284, disc_loss = 0.07345122417401788
Trained batch 56 in epoch 4, gen_loss = 0.8471902823239043, disc_loss = 0.07292096923807995
Trained batch 57 in epoch 4, gen_loss = 0.8515280839698068, disc_loss = 0.07348228110289522
Trained batch 58 in epoch 4, gen_loss = 0.8536235179941533, disc_loss = 0.0747447826394464
Trained batch 59 in epoch 4, gen_loss = 0.8478327885270118, disc_loss = 0.07576170233854403
Trained batch 60 in epoch 4, gen_loss = 0.8467367736042523, disc_loss = 0.07582799399454819
Trained batch 61 in epoch 4, gen_loss = 0.8496993919534068, disc_loss = 0.07490122203354634
Trained batch 62 in epoch 4, gen_loss = 0.8552676027729398, disc_loss = 0.07451866927098423
Trained batch 63 in epoch 4, gen_loss = 0.8562442329712212, disc_loss = 0.07530995114211692
Trained batch 64 in epoch 4, gen_loss = 0.8519780970536746, disc_loss = 0.07723779843833584
Trained batch 65 in epoch 4, gen_loss = 0.8505790102662463, disc_loss = 0.07734475899346624
Trained batch 66 in epoch 4, gen_loss = 0.855034196109914, disc_loss = 0.07658706165488753
Trained batch 67 in epoch 4, gen_loss = 0.8624610317980542, disc_loss = 0.0779752054676304
Trained batch 68 in epoch 4, gen_loss = 0.8630089038524075, disc_loss = 0.07701276239358644
Trained batch 69 in epoch 4, gen_loss = 0.8608804315328598, disc_loss = 0.07687440819905272
Trained batch 70 in epoch 4, gen_loss = 0.8599029741656612, disc_loss = 0.07605122671869229
Trained batch 71 in epoch 4, gen_loss = 0.8633560434811645, disc_loss = 0.0757723370140108
Trained batch 72 in epoch 4, gen_loss = 0.863978338976429, disc_loss = 0.07500711309863892
Trained batch 73 in epoch 4, gen_loss = 0.8662457711793281, disc_loss = 0.07417193863767425
Trained batch 74 in epoch 4, gen_loss = 0.8638048239549001, disc_loss = 0.07421743972226977
Trained batch 75 in epoch 4, gen_loss = 0.8630286984537777, disc_loss = 0.07382598777277101
Trained batch 76 in epoch 4, gen_loss = 0.8654983968703778, disc_loss = 0.07314525344469525
Trained batch 77 in epoch 4, gen_loss = 0.8641773290359057, disc_loss = 0.07244229195520091
Trained batch 78 in epoch 4, gen_loss = 0.8635944893843011, disc_loss = 0.07195756096935159
Trained batch 79 in epoch 4, gen_loss = 0.8615461986511945, disc_loss = 0.07144536097184755
Trained batch 80 in epoch 4, gen_loss = 0.8591097560193803, disc_loss = 0.07098629813710297
Trained batch 81 in epoch 4, gen_loss = 0.8594978913301374, disc_loss = 0.07118979960157559
Trained batch 82 in epoch 4, gen_loss = 0.8581509959984974, disc_loss = 0.07173453882359059
Trained batch 83 in epoch 4, gen_loss = 0.8607634784919875, disc_loss = 0.07121575198557582
Trained batch 84 in epoch 4, gen_loss = 0.8591824401827419, disc_loss = 0.07113011988318142
Trained batch 85 in epoch 4, gen_loss = 0.8563055780737899, disc_loss = 0.07107943080387316
Trained batch 86 in epoch 4, gen_loss = 0.8593663932948277, disc_loss = 0.07219230469808667
Trained batch 87 in epoch 4, gen_loss = 0.8568249693648382, disc_loss = 0.07226144776954739
Trained batch 88 in epoch 4, gen_loss = 0.855921577536658, disc_loss = 0.07168835983873251
Trained batch 89 in epoch 4, gen_loss = 0.8530429154634476, disc_loss = 0.07183694993145764
Trained batch 90 in epoch 4, gen_loss = 0.8509305836735191, disc_loss = 0.07156468809653933
Trained batch 91 in epoch 4, gen_loss = 0.8491967284808988, disc_loss = 0.0716367598430699
Trained batch 92 in epoch 4, gen_loss = 0.84740248835215, disc_loss = 0.07248105361597032
Trained batch 93 in epoch 4, gen_loss = 0.8464893137520932, disc_loss = 0.0724131943350856
Trained batch 94 in epoch 4, gen_loss = 0.847109244685424, disc_loss = 0.07237016696384863
Trained batch 95 in epoch 4, gen_loss = 0.8487552736575404, disc_loss = 0.07246233162489564
Trained batch 96 in epoch 4, gen_loss = 0.8471954259061322, disc_loss = 0.07237208669659556
Trained batch 97 in epoch 4, gen_loss = 0.8492824298386671, disc_loss = 0.07178304179533555
Trained batch 98 in epoch 4, gen_loss = 0.8503589223731648, disc_loss = 0.07116938975517346
Trained batch 99 in epoch 4, gen_loss = 0.8504508343338967, disc_loss = 0.07137823587749154
Trained batch 100 in epoch 4, gen_loss = 0.8529253304004669, disc_loss = 0.071204670276124
Trained batch 101 in epoch 4, gen_loss = 0.84963078446248, disc_loss = 0.07241415537838988
Trained batch 102 in epoch 4, gen_loss = 0.8507861735172642, disc_loss = 0.07184543051458533
Trained batch 103 in epoch 4, gen_loss = 0.8543387952332313, disc_loss = 0.07166068610072565
Trained batch 104 in epoch 4, gen_loss = 0.8558487781456539, disc_loss = 0.0711563591934031
Trained batch 105 in epoch 4, gen_loss = 0.8537410747892452, disc_loss = 0.07204373762064245
Trained batch 106 in epoch 4, gen_loss = 0.8565296906734181, disc_loss = 0.07196628864175666
Trained batch 107 in epoch 4, gen_loss = 0.8590049636032846, disc_loss = 0.07187251316780155
Trained batch 108 in epoch 4, gen_loss = 0.8598041077819439, disc_loss = 0.0713731918714667
Trained batch 109 in epoch 4, gen_loss = 0.8588822676376863, disc_loss = 0.0713799501134252
Trained batch 110 in epoch 4, gen_loss = 0.8581568451078089, disc_loss = 0.07118294322191998
Trained batch 111 in epoch 4, gen_loss = 0.8572453789945159, disc_loss = 0.071566777382811
Trained batch 112 in epoch 4, gen_loss = 0.8577132264597226, disc_loss = 0.0716650513808482
Trained batch 113 in epoch 4, gen_loss = 0.857170016880621, disc_loss = 0.07133448415991377
Trained batch 114 in epoch 4, gen_loss = 0.8562763600245766, disc_loss = 0.07103573243822092
Trained batch 115 in epoch 4, gen_loss = 0.85409957504478, disc_loss = 0.07141014430591644
Trained batch 116 in epoch 4, gen_loss = 0.8555010641232516, disc_loss = 0.07157607718458416
Trained batch 117 in epoch 4, gen_loss = 0.8544826944500713, disc_loss = 0.07162854004004118
Trained batch 118 in epoch 4, gen_loss = 0.8543433754884896, disc_loss = 0.07143690998611205
Trained batch 119 in epoch 4, gen_loss = 0.8536919939021269, disc_loss = 0.07131525673515474
Trained batch 120 in epoch 4, gen_loss = 0.8531558368324248, disc_loss = 0.07115936850020585
Trained batch 121 in epoch 4, gen_loss = 0.8535083910969438, disc_loss = 0.07074748844931238
Trained batch 122 in epoch 4, gen_loss = 0.8532711206897488, disc_loss = 0.07034284219796944
Trained batch 123 in epoch 4, gen_loss = 0.8540791924442014, disc_loss = 0.06992447203130371
Trained batch 124 in epoch 4, gen_loss = 0.8526486794948578, disc_loss = 0.07013038928434252
Trained batch 125 in epoch 4, gen_loss = 0.8553206218140466, disc_loss = 0.06990526044105608
Trained batch 126 in epoch 4, gen_loss = 0.8569107644670592, disc_loss = 0.06956540222287061
Trained batch 127 in epoch 4, gen_loss = 0.8547322710510343, disc_loss = 0.07001561436845805
Trained batch 128 in epoch 4, gen_loss = 0.856467592392781, disc_loss = 0.07023877550508509
Trained batch 129 in epoch 4, gen_loss = 0.8586433463371717, disc_loss = 0.06993913608603179
Trained batch 130 in epoch 4, gen_loss = 0.8546485464081509, disc_loss = 0.07076415719236923
Trained batch 131 in epoch 4, gen_loss = 0.855208640297254, disc_loss = 0.07030675373618689
Trained batch 132 in epoch 4, gen_loss = 0.8553280816938644, disc_loss = 0.0701455602989553
Trained batch 133 in epoch 4, gen_loss = 0.8566906723513532, disc_loss = 0.06989102924256516
Trained batch 134 in epoch 4, gen_loss = 0.8553998161245275, disc_loss = 0.0701139028115129
Trained batch 135 in epoch 4, gen_loss = 0.8565829527728698, disc_loss = 0.06980696021620293
Trained batch 136 in epoch 4, gen_loss = 0.8560934079824573, disc_loss = 0.06938500001849811
Trained batch 137 in epoch 4, gen_loss = 0.8578575024570244, disc_loss = 0.06926440875099944
Trained batch 138 in epoch 4, gen_loss = 0.8574958816706706, disc_loss = 0.0694278038656272
Trained batch 139 in epoch 4, gen_loss = 0.8576403660433632, disc_loss = 0.06924191320514572
Trained batch 140 in epoch 4, gen_loss = 0.8564992733035527, disc_loss = 0.06924927600243307
Trained batch 141 in epoch 4, gen_loss = 0.8552292153029375, disc_loss = 0.06956789669790633
Trained batch 142 in epoch 4, gen_loss = 0.8555104444910596, disc_loss = 0.06979823202038041
Trained batch 143 in epoch 4, gen_loss = 0.8550081348253621, disc_loss = 0.06950961358314897
Trained batch 144 in epoch 4, gen_loss = 0.855902779513392, disc_loss = 0.06909659387029965
Trained batch 145 in epoch 4, gen_loss = 0.8537153021930015, disc_loss = 0.06913596764525833
Trained batch 146 in epoch 4, gen_loss = 0.8520335964605111, disc_loss = 0.06952675858031021
Trained batch 147 in epoch 4, gen_loss = 0.8518784195184708, disc_loss = 0.06954272972684153
Trained batch 148 in epoch 4, gen_loss = 0.8514119114651776, disc_loss = 0.06979203359505175
Trained batch 149 in epoch 4, gen_loss = 0.8500394686063131, disc_loss = 0.06970125556302567
Trained batch 150 in epoch 4, gen_loss = 0.8502572624888641, disc_loss = 0.06962289762627703
Trained batch 151 in epoch 4, gen_loss = 0.8483991599396655, disc_loss = 0.06976928211760854
Trained batch 152 in epoch 4, gen_loss = 0.8486106547654844, disc_loss = 0.06944268248257002
Trained batch 153 in epoch 4, gen_loss = 0.8481006192696559, disc_loss = 0.06983487073682829
Trained batch 154 in epoch 4, gen_loss = 0.8469536781311036, disc_loss = 0.06983150981907402
Trained batch 155 in epoch 4, gen_loss = 0.8464109668364892, disc_loss = 0.06970184170103703
Trained batch 156 in epoch 4, gen_loss = 0.8473150228998464, disc_loss = 0.06946437355356326
Trained batch 157 in epoch 4, gen_loss = 0.8487438265281387, disc_loss = 0.06918297364093552
Trained batch 158 in epoch 4, gen_loss = 0.8500535997954555, disc_loss = 0.06943308295236912
Trained batch 159 in epoch 4, gen_loss = 0.8494028396904468, disc_loss = 0.06998188738070894
Trained batch 160 in epoch 4, gen_loss = 0.8480865662882787, disc_loss = 0.0699897696356642
Trained batch 161 in epoch 4, gen_loss = 0.8493377680395856, disc_loss = 0.0696908186023112
Trained batch 162 in epoch 4, gen_loss = 0.848718531658313, disc_loss = 0.06949702651737018
Trained batch 163 in epoch 4, gen_loss = 0.849971188641176, disc_loss = 0.06973699395397179
Trained batch 164 in epoch 4, gen_loss = 0.8493815638802268, disc_loss = 0.06949125756650712
Trained batch 165 in epoch 4, gen_loss = 0.8479276672903314, disc_loss = 0.0700267161304378
Trained batch 166 in epoch 4, gen_loss = 0.8476105432310505, disc_loss = 0.06980364825743847
Trained batch 167 in epoch 4, gen_loss = 0.8483378149214245, disc_loss = 0.06966312957229093
Trained batch 168 in epoch 4, gen_loss = 0.8486606157743014, disc_loss = 0.069332777211145
Trained batch 169 in epoch 4, gen_loss = 0.8495193993344027, disc_loss = 0.06900045922957361
Trained batch 170 in epoch 4, gen_loss = 0.8475086089463262, disc_loss = 0.06930723170646363
Trained batch 171 in epoch 4, gen_loss = 0.8471686874711236, disc_loss = 0.06931682388828851
Trained batch 172 in epoch 4, gen_loss = 0.8495168238016911, disc_loss = 0.069380038032965
Trained batch 173 in epoch 4, gen_loss = 0.8479183854042799, disc_loss = 0.06963049636179602
Trained batch 174 in epoch 4, gen_loss = 0.8467256130490984, disc_loss = 0.07000411849735039
Trained batch 175 in epoch 4, gen_loss = 0.8454185365275904, disc_loss = 0.0703448915552475
Trained batch 176 in epoch 4, gen_loss = 0.8465795160013404, disc_loss = 0.07052249805265143
Trained batch 177 in epoch 4, gen_loss = 0.8467508862527569, disc_loss = 0.07018170184246526
Trained batch 178 in epoch 4, gen_loss = 0.848988392499572, disc_loss = 0.07014314077700899
Trained batch 179 in epoch 4, gen_loss = 0.8470644957489437, disc_loss = 0.07091600014052044
Trained batch 180 in epoch 4, gen_loss = 0.8462076457165881, disc_loss = 0.07092571666834681
Trained batch 181 in epoch 4, gen_loss = 0.8460361400803367, disc_loss = 0.07085451910241537
Trained batch 182 in epoch 4, gen_loss = 0.8452985680819861, disc_loss = 0.07098825313303558
Trained batch 183 in epoch 4, gen_loss = 0.8451138796365779, disc_loss = 0.07103169248591218
Trained batch 184 in epoch 4, gen_loss = 0.8441555213283848, disc_loss = 0.07094049625652464
Trained batch 185 in epoch 4, gen_loss = 0.8447386253905552, disc_loss = 0.07077688418118463
Trained batch 186 in epoch 4, gen_loss = 0.8452355934974344, disc_loss = 0.07060588428870163
Trained batch 187 in epoch 4, gen_loss = 0.8449247834530282, disc_loss = 0.0706717623868323
Trained batch 188 in epoch 4, gen_loss = 0.8444774358991592, disc_loss = 0.07056193614240598
Trained batch 189 in epoch 4, gen_loss = 0.8436949165243851, disc_loss = 0.07038641315884889
Trained batch 190 in epoch 4, gen_loss = 0.8429287331890686, disc_loss = 0.07040411919228616
Trained batch 191 in epoch 4, gen_loss = 0.8451324021443725, disc_loss = 0.07069346144514081
Trained batch 192 in epoch 4, gen_loss = 0.8470560377125913, disc_loss = 0.07077389224697811
Trained batch 193 in epoch 4, gen_loss = 0.8481329479782852, disc_loss = 0.07048922330477111
Trained batch 194 in epoch 4, gen_loss = 0.8468697453156496, disc_loss = 0.07257049647995677
Trained batch 195 in epoch 4, gen_loss = 0.8458407937872167, disc_loss = 0.07281386531765896
Trained batch 196 in epoch 4, gen_loss = 0.8471149372570406, disc_loss = 0.07301726535217941
Trained batch 197 in epoch 4, gen_loss = 0.846272984839449, disc_loss = 0.07310199980962682
Trained batch 198 in epoch 4, gen_loss = 0.8439307458436669, disc_loss = 0.07395142873505776
Trained batch 199 in epoch 4, gen_loss = 0.8435939824581147, disc_loss = 0.07501269894419238
Trained batch 200 in epoch 4, gen_loss = 0.8431324211519156, disc_loss = 0.07552070517917696
Trained batch 201 in epoch 4, gen_loss = 0.8429681744315837, disc_loss = 0.07546758219037242
Trained batch 202 in epoch 4, gen_loss = 0.8434588888595844, disc_loss = 0.07536108258496878
Trained batch 203 in epoch 4, gen_loss = 0.841988624310961, disc_loss = 0.07590671996449065
Trained batch 204 in epoch 4, gen_loss = 0.8404601972277571, disc_loss = 0.07609352275683749
Trained batch 205 in epoch 4, gen_loss = 0.8409582318611515, disc_loss = 0.07913606630828122
Trained batch 206 in epoch 4, gen_loss = 0.8412865817834789, disc_loss = 0.07882165541908376
Trained batch 207 in epoch 4, gen_loss = 0.8409961462020874, disc_loss = 0.07870424642952947
Trained batch 208 in epoch 4, gen_loss = 0.8398651372302662, disc_loss = 0.07895287511531603
Trained batch 209 in epoch 4, gen_loss = 0.8389481104555584, disc_loss = 0.07934389366502208
Trained batch 210 in epoch 4, gen_loss = 0.8385030822166334, disc_loss = 0.07974477765763893
Trained batch 211 in epoch 4, gen_loss = 0.8376077649728307, disc_loss = 0.07980037600302822
Trained batch 212 in epoch 4, gen_loss = 0.836957294616341, disc_loss = 0.07991688345458375
Trained batch 213 in epoch 4, gen_loss = 0.8374912638530553, disc_loss = 0.07996953658489772
Trained batch 214 in epoch 4, gen_loss = 0.8365611597549084, disc_loss = 0.07992691314714247
Trained batch 215 in epoch 4, gen_loss = 0.8366108487049738, disc_loss = 0.08041580145773305
Trained batch 216 in epoch 4, gen_loss = 0.8368000003599352, disc_loss = 0.08038478241890051
Trained batch 217 in epoch 4, gen_loss = 0.8354839761869624, disc_loss = 0.08082322342483618
Trained batch 218 in epoch 4, gen_loss = 0.8353329954082018, disc_loss = 0.08053095896673053
Trained batch 219 in epoch 4, gen_loss = 0.8350341959433122, disc_loss = 0.08051899396602742
Trained batch 220 in epoch 4, gen_loss = 0.8352310614348537, disc_loss = 0.08036029361803675
Trained batch 221 in epoch 4, gen_loss = 0.8346210876563648, disc_loss = 0.08050638832663698
Trained batch 222 in epoch 4, gen_loss = 0.8356630895704432, disc_loss = 0.08045710101431328
Trained batch 223 in epoch 4, gen_loss = 0.8349905777722597, disc_loss = 0.08054676870857033
Trained batch 224 in epoch 4, gen_loss = 0.8343724486562941, disc_loss = 0.08042503361279765
Trained batch 225 in epoch 4, gen_loss = 0.8344661382447301, disc_loss = 0.08094824076860946
Trained batch 226 in epoch 4, gen_loss = 0.8333402052849925, disc_loss = 0.08126232472129395
Trained batch 227 in epoch 4, gen_loss = 0.8323869982309509, disc_loss = 0.08154333393669508
Trained batch 228 in epoch 4, gen_loss = 0.8328895935845687, disc_loss = 0.08205273693150894
Trained batch 229 in epoch 4, gen_loss = 0.8339156086030214, disc_loss = 0.08177168046367234
Trained batch 230 in epoch 4, gen_loss = 0.8338792151186889, disc_loss = 0.08158555535954379
Trained batch 231 in epoch 4, gen_loss = 0.8336983641673779, disc_loss = 0.08138535269094503
Trained batch 232 in epoch 4, gen_loss = 0.8341553119119145, disc_loss = 0.0815977451087739
Trained batch 233 in epoch 4, gen_loss = 0.8336174699485811, disc_loss = 0.08164163348742594
Trained batch 234 in epoch 4, gen_loss = 0.8323222457094396, disc_loss = 0.08226147206262388
Trained batch 235 in epoch 4, gen_loss = 0.8341659138263282, disc_loss = 0.08225015716003728
Trained batch 236 in epoch 4, gen_loss = 0.8352600564936545, disc_loss = 0.08235630444309945
Trained batch 237 in epoch 4, gen_loss = 0.8346815166854057, disc_loss = 0.08252389582867946
Trained batch 238 in epoch 4, gen_loss = 0.8345849252146158, disc_loss = 0.08244669834292147
Trained batch 239 in epoch 4, gen_loss = 0.8356336874266466, disc_loss = 0.0826230113802012
Trained batch 240 in epoch 4, gen_loss = 0.8350980954546157, disc_loss = 0.08267813139784447
Trained batch 241 in epoch 4, gen_loss = 0.8346754031733048, disc_loss = 0.08254752846334652
Trained batch 242 in epoch 4, gen_loss = 0.8346697673385526, disc_loss = 0.08243218689214116
Trained batch 243 in epoch 4, gen_loss = 0.8335091574270217, disc_loss = 0.08274674549370577
Trained batch 244 in epoch 4, gen_loss = 0.8328779055147755, disc_loss = 0.08295389534905553
Trained batch 245 in epoch 4, gen_loss = 0.8331333568425683, disc_loss = 0.08293843626165838
Trained batch 246 in epoch 4, gen_loss = 0.8320405767996785, disc_loss = 0.08306299788907533
Trained batch 247 in epoch 4, gen_loss = 0.8321943662820324, disc_loss = 0.08292257250474405
Trained batch 248 in epoch 4, gen_loss = 0.8317649828861038, disc_loss = 0.08329025012100616
Trained batch 249 in epoch 4, gen_loss = 0.8313474192619323, disc_loss = 0.08303568227775394
Trained batch 250 in epoch 4, gen_loss = 0.830314522008022, disc_loss = 0.08287172306113806
Trained batch 251 in epoch 4, gen_loss = 0.8306065821458423, disc_loss = 0.08274362731673238
Trained batch 252 in epoch 4, gen_loss = 0.830213000651876, disc_loss = 0.08265004566366317
Trained batch 253 in epoch 4, gen_loss = 0.8287202796832783, disc_loss = 0.08283386488195772
Trained batch 254 in epoch 4, gen_loss = 0.8283837415424048, disc_loss = 0.0827246498846102
Trained batch 255 in epoch 4, gen_loss = 0.827743899426423, disc_loss = 0.08297488116841123
Trained batch 256 in epoch 4, gen_loss = 0.8280360741606019, disc_loss = 0.0830566482745285
Trained batch 257 in epoch 4, gen_loss = 0.8271840714900068, disc_loss = 0.08299308452329258
Trained batch 258 in epoch 4, gen_loss = 0.826074572488608, disc_loss = 0.08314928030019848
Trained batch 259 in epoch 4, gen_loss = 0.8264138931265244, disc_loss = 0.0830190629644606
Trained batch 260 in epoch 4, gen_loss = 0.8264129343389095, disc_loss = 0.0828866303498746
Trained batch 261 in epoch 4, gen_loss = 0.827099539737665, disc_loss = 0.08279154725721148
Trained batch 262 in epoch 4, gen_loss = 0.8267932798246014, disc_loss = 0.08290650253803841
Trained batch 263 in epoch 4, gen_loss = 0.8260896584075509, disc_loss = 0.08296225663225139
Trained batch 264 in epoch 4, gen_loss = 0.8257108291365066, disc_loss = 0.0834187148613328
Trained batch 265 in epoch 4, gen_loss = 0.8261961131391669, disc_loss = 0.08363611046820038
Trained batch 266 in epoch 4, gen_loss = 0.8250734324982104, disc_loss = 0.0839968635979691
Trained batch 267 in epoch 4, gen_loss = 0.825470637140879, disc_loss = 0.08382902733821755
Trained batch 268 in epoch 4, gen_loss = 0.825288974773485, disc_loss = 0.08365124874128561
Trained batch 269 in epoch 4, gen_loss = 0.8256038865557424, disc_loss = 0.08372454847623077
Trained batch 270 in epoch 4, gen_loss = 0.8248048205877142, disc_loss = 0.0837486628528918
Trained batch 271 in epoch 4, gen_loss = 0.8259825933286372, disc_loss = 0.08369778948733309
Trained batch 272 in epoch 4, gen_loss = 0.8262888982400789, disc_loss = 0.08366064880309361
Trained batch 273 in epoch 4, gen_loss = 0.825012726614075, disc_loss = 0.08399128076538824
Trained batch 274 in epoch 4, gen_loss = 0.8255919405547055, disc_loss = 0.08372413324192167
Trained batch 275 in epoch 4, gen_loss = 0.8255259985293167, disc_loss = 0.08356576788650853
Trained batch 276 in epoch 4, gen_loss = 0.8250720456834304, disc_loss = 0.08375490527257108
Trained batch 277 in epoch 4, gen_loss = 0.8241931469105989, disc_loss = 0.08363174319287374
Trained batch 278 in epoch 4, gen_loss = 0.8240199053800235, disc_loss = 0.0834700169232023
Trained batch 279 in epoch 4, gen_loss = 0.8244209654629231, disc_loss = 0.08337303125133205
Trained batch 280 in epoch 4, gen_loss = 0.8251868604128896, disc_loss = 0.08314060529004584
Trained batch 281 in epoch 4, gen_loss = 0.8248226476687912, disc_loss = 0.083019334510801
Trained batch 282 in epoch 4, gen_loss = 0.8239104133823314, disc_loss = 0.08295447045489619
Trained batch 283 in epoch 4, gen_loss = 0.8238328434002231, disc_loss = 0.08281244340674086
Trained batch 284 in epoch 4, gen_loss = 0.8240402059596882, disc_loss = 0.08296955863602068
Trained batch 285 in epoch 4, gen_loss = 0.8250278885756339, disc_loss = 0.0840371250894598
Trained batch 286 in epoch 4, gen_loss = 0.8236146222423594, disc_loss = 0.08463345855338181
Trained batch 287 in epoch 4, gen_loss = 0.8231757692992687, disc_loss = 0.08492481075194923
Trained batch 288 in epoch 4, gen_loss = 0.8232777040309972, disc_loss = 0.08473844269200334
Trained batch 289 in epoch 4, gen_loss = 0.8223477723269627, disc_loss = 0.0847267269815222
Trained batch 290 in epoch 4, gen_loss = 0.8229168120938068, disc_loss = 0.08479038474735678
Trained batch 291 in epoch 4, gen_loss = 0.8224770659453249, disc_loss = 0.08477635788635593
Trained batch 292 in epoch 4, gen_loss = 0.8222252679766242, disc_loss = 0.08483000730129385
Trained batch 293 in epoch 4, gen_loss = 0.8219515512995168, disc_loss = 0.0847324982117608
Trained batch 294 in epoch 4, gen_loss = 0.8225084096698437, disc_loss = 0.08508966122990695
Trained batch 295 in epoch 4, gen_loss = 0.82259446966487, disc_loss = 0.08493477400436343
Trained batch 296 in epoch 4, gen_loss = 0.8226821219880974, disc_loss = 0.08476110551387121
Trained batch 297 in epoch 4, gen_loss = 0.822401529790571, disc_loss = 0.08459664896074308
Trained batch 298 in epoch 4, gen_loss = 0.8222932115845059, disc_loss = 0.08443630618638169
Trained batch 299 in epoch 4, gen_loss = 0.8221448471148809, disc_loss = 0.08440662053568909
Trained batch 300 in epoch 4, gen_loss = 0.8222702125774269, disc_loss = 0.0846196946446657
Trained batch 301 in epoch 4, gen_loss = 0.8217921083336635, disc_loss = 0.0845595188916889
Trained batch 302 in epoch 4, gen_loss = 0.8213125823354563, disc_loss = 0.08469990921043867
Trained batch 303 in epoch 4, gen_loss = 0.8208669018196432, disc_loss = 0.08477333660917602
Trained batch 304 in epoch 4, gen_loss = 0.8205912396556041, disc_loss = 0.08472311467268183
Trained batch 305 in epoch 4, gen_loss = 0.8199744713462256, disc_loss = 0.08478814626289105
Trained batch 306 in epoch 4, gen_loss = 0.8197695350802294, disc_loss = 0.08461162836081576
Trained batch 307 in epoch 4, gen_loss = 0.8209477179236226, disc_loss = 0.08454444738219843
Trained batch 308 in epoch 4, gen_loss = 0.8212356725556951, disc_loss = 0.08442654887298695
Trained batch 309 in epoch 4, gen_loss = 0.8211645860825816, disc_loss = 0.08427814418119528
Trained batch 310 in epoch 4, gen_loss = 0.8206236255130583, disc_loss = 0.0843139536352379
Trained batch 311 in epoch 4, gen_loss = 0.8209709202249845, disc_loss = 0.08409562591576758
Trained batch 312 in epoch 4, gen_loss = 0.8208896807207468, disc_loss = 0.08391366059781787
Trained batch 313 in epoch 4, gen_loss = 0.8217464979666813, disc_loss = 0.08390150879877531
Trained batch 314 in epoch 4, gen_loss = 0.8214127720348419, disc_loss = 0.08376651309164507
Trained batch 315 in epoch 4, gen_loss = 0.821407797781727, disc_loss = 0.08373494241003512
Trained batch 316 in epoch 4, gen_loss = 0.8213238031706224, disc_loss = 0.08352717533208172
Trained batch 317 in epoch 4, gen_loss = 0.8205484024383737, disc_loss = 0.08369163908035078
Trained batch 318 in epoch 4, gen_loss = 0.8206835973972811, disc_loss = 0.08349285522756111
Trained batch 319 in epoch 4, gen_loss = 0.8211018536239862, disc_loss = 0.0834394523917581
Trained batch 320 in epoch 4, gen_loss = 0.8214195003019316, disc_loss = 0.08329032903908523
Trained batch 321 in epoch 4, gen_loss = 0.8208362019580343, disc_loss = 0.08352164747569456
Trained batch 322 in epoch 4, gen_loss = 0.8207469196880565, disc_loss = 0.08356293938310108
Trained batch 323 in epoch 4, gen_loss = 0.8209754673787105, disc_loss = 0.08333605658521669
Trained batch 324 in epoch 4, gen_loss = 0.8207310106204107, disc_loss = 0.08318388026064405
Trained batch 325 in epoch 4, gen_loss = 0.8198660734606666, disc_loss = 0.08324550446037181
Trained batch 326 in epoch 4, gen_loss = 0.8215188759547125, disc_loss = 0.08331949944644938
Trained batch 327 in epoch 4, gen_loss = 0.8209224445063893, disc_loss = 0.08333181232787533
Trained batch 328 in epoch 4, gen_loss = 0.8205452782404822, disc_loss = 0.08331070801435678
Trained batch 329 in epoch 4, gen_loss = 0.8206728637218476, disc_loss = 0.08311439875767312
Trained batch 330 in epoch 4, gen_loss = 0.8203969277283937, disc_loss = 0.08296357168537477
Trained batch 331 in epoch 4, gen_loss = 0.8201782347926174, disc_loss = 0.08283255842979997
Trained batch 332 in epoch 4, gen_loss = 0.8207807111310529, disc_loss = 0.08286656438325485
Trained batch 333 in epoch 4, gen_loss = 0.8203936472624361, disc_loss = 0.08321108739449458
Trained batch 334 in epoch 4, gen_loss = 0.8202873080524046, disc_loss = 0.08317620461917857
Trained batch 335 in epoch 4, gen_loss = 0.8192151879803056, disc_loss = 0.08396241256351848
Trained batch 336 in epoch 4, gen_loss = 0.8188833833978862, disc_loss = 0.08420680539726724
Trained batch 337 in epoch 4, gen_loss = 0.8188561343053389, disc_loss = 0.08440897923607665
Trained batch 338 in epoch 4, gen_loss = 0.8183772315142077, disc_loss = 0.08445340451155309
Trained batch 339 in epoch 4, gen_loss = 0.8187898389556829, disc_loss = 0.08435584808672394
Trained batch 340 in epoch 4, gen_loss = 0.8190917604305178, disc_loss = 0.0842592060754398
Trained batch 341 in epoch 4, gen_loss = 0.818331049809679, disc_loss = 0.08430160096389029
Trained batch 342 in epoch 4, gen_loss = 0.8177682855560202, disc_loss = 0.08422069952201434
Trained batch 343 in epoch 4, gen_loss = 0.8185652760398943, disc_loss = 0.08430987565242144
Trained batch 344 in epoch 4, gen_loss = 0.8185628606789354, disc_loss = 0.08425246357404884
Trained batch 345 in epoch 4, gen_loss = 0.8175744009500294, disc_loss = 0.08445590890734053
Trained batch 346 in epoch 4, gen_loss = 0.8176338399521556, disc_loss = 0.08434483731133322
Trained batch 347 in epoch 4, gen_loss = 0.8175019316974728, disc_loss = 0.0842413327552314
Trained batch 348 in epoch 4, gen_loss = 0.8174072562111141, disc_loss = 0.08436437240564251
Trained batch 349 in epoch 4, gen_loss = 0.8171012912477765, disc_loss = 0.08428438185714185
Trained batch 350 in epoch 4, gen_loss = 0.8170315526489519, disc_loss = 0.08412233951429908
Trained batch 351 in epoch 4, gen_loss = 0.8191477500579574, disc_loss = 0.08459545601164625
Trained batch 352 in epoch 4, gen_loss = 0.8191627493661119, disc_loss = 0.08471138835633991
Trained batch 353 in epoch 4, gen_loss = 0.8180117899246808, disc_loss = 0.08479310312350465
Trained batch 354 in epoch 4, gen_loss = 0.8179895161742895, disc_loss = 0.08487360184802346
Trained batch 355 in epoch 4, gen_loss = 0.8185239905554257, disc_loss = 0.08469830570726791
Trained batch 356 in epoch 4, gen_loss = 0.8179629809883129, disc_loss = 0.08465224425295363
Trained batch 357 in epoch 4, gen_loss = 0.8179534612920697, disc_loss = 0.08460596861583103
Trained batch 358 in epoch 4, gen_loss = 0.8183544298898543, disc_loss = 0.08502566187790385
Trained batch 359 in epoch 4, gen_loss = 0.8174121285478274, disc_loss = 0.08569024971091292
Trained batch 360 in epoch 4, gen_loss = 0.8186543316392026, disc_loss = 0.08558402614090127
Trained batch 361 in epoch 4, gen_loss = 0.8188728784000018, disc_loss = 0.08541006342898952
Trained batch 362 in epoch 4, gen_loss = 0.8181564192141383, disc_loss = 0.08548265787036499
Trained batch 363 in epoch 4, gen_loss = 0.8178222521648302, disc_loss = 0.08536881591311073
Trained batch 364 in epoch 4, gen_loss = 0.8186358355496027, disc_loss = 0.08539123220930565
Trained batch 365 in epoch 4, gen_loss = 0.8185583169017333, disc_loss = 0.08533982252778455
Trained batch 366 in epoch 4, gen_loss = 0.817886769121934, disc_loss = 0.08526426870553508
Trained batch 367 in epoch 4, gen_loss = 0.8178895378242368, disc_loss = 0.0851861549270562
Trained batch 368 in epoch 4, gen_loss = 0.8174630666812908, disc_loss = 0.08515764561009803
Trained batch 369 in epoch 4, gen_loss = 0.8167142363818916, disc_loss = 0.08526054735647867
Trained batch 370 in epoch 4, gen_loss = 0.8165525058209093, disc_loss = 0.08529449475306586
Trained batch 371 in epoch 4, gen_loss = 0.8169078722756397, disc_loss = 0.08524382781482712
Trained batch 372 in epoch 4, gen_loss = 0.8169140179738922, disc_loss = 0.08514679819670064
Trained batch 373 in epoch 4, gen_loss = 0.8173220517801091, disc_loss = 0.08496586277826944
Trained batch 374 in epoch 4, gen_loss = 0.8181157611211141, disc_loss = 0.08489106192812323
Trained batch 375 in epoch 4, gen_loss = 0.8184901968912875, disc_loss = 0.08472942081007591
Trained batch 376 in epoch 4, gen_loss = 0.8184840328181138, disc_loss = 0.08456233235332987
Trained batch 377 in epoch 4, gen_loss = 0.8177422269311532, disc_loss = 0.08499193140896895
Trained batch 378 in epoch 4, gen_loss = 0.81907841240825, disc_loss = 0.08531769984930085
Trained batch 379 in epoch 4, gen_loss = 0.8195872686411205, disc_loss = 0.08513577066876582
Trained batch 380 in epoch 4, gen_loss = 0.820028193353668, disc_loss = 0.08502965830290919
Trained batch 381 in epoch 4, gen_loss = 0.8190567956857032, disc_loss = 0.08597442984741903
Trained batch 382 in epoch 4, gen_loss = 0.8196943729104323, disc_loss = 0.08585747776981005
Trained batch 383 in epoch 4, gen_loss = 0.8199011594988406, disc_loss = 0.08588263262572582
Trained batch 384 in epoch 4, gen_loss = 0.8196492769501426, disc_loss = 0.08604832363327022
Trained batch 385 in epoch 4, gen_loss = 0.8195016940022998, disc_loss = 0.0860641237572704
Trained batch 386 in epoch 4, gen_loss = 0.8193623003109481, disc_loss = 0.08599514943651027
Trained batch 387 in epoch 4, gen_loss = 0.8194017405669713, disc_loss = 0.08587813440868727
Trained batch 388 in epoch 4, gen_loss = 0.8192684308728706, disc_loss = 0.08593319833474976
Trained batch 389 in epoch 4, gen_loss = 0.8195543524546501, disc_loss = 0.08603740489373031
Trained batch 390 in epoch 4, gen_loss = 0.8186419644319188, disc_loss = 0.08616934230913172
Trained batch 391 in epoch 4, gen_loss = 0.8175948274378874, disc_loss = 0.08633559689576718
Trained batch 392 in epoch 4, gen_loss = 0.818458281703881, disc_loss = 0.08665403850855301
Trained batch 393 in epoch 4, gen_loss = 0.8186704380258085, disc_loss = 0.08650556751432342
Trained batch 394 in epoch 4, gen_loss = 0.8185161503055428, disc_loss = 0.08655997299813206
Trained batch 395 in epoch 4, gen_loss = 0.8174863671413576, disc_loss = 0.08709785285890291
Trained batch 396 in epoch 4, gen_loss = 0.8170487628475545, disc_loss = 0.08712598315606677
Trained batch 397 in epoch 4, gen_loss = 0.8173448641096527, disc_loss = 0.08699127374773835
Trained batch 398 in epoch 4, gen_loss = 0.81797044348896, disc_loss = 0.08690342094333735
Trained batch 399 in epoch 4, gen_loss = 0.8180226746201515, disc_loss = 0.0867935411829967
Trained batch 400 in epoch 4, gen_loss = 0.8180153586917982, disc_loss = 0.08668661503204866
Trained batch 401 in epoch 4, gen_loss = 0.8175627248204169, disc_loss = 0.08687931750623036
Trained batch 402 in epoch 4, gen_loss = 0.8171449949960259, disc_loss = 0.08696756226405797
Trained batch 403 in epoch 4, gen_loss = 0.8169676811978368, disc_loss = 0.08690224338143068
Trained batch 404 in epoch 4, gen_loss = 0.8174233651455538, disc_loss = 0.08709260660488112
Trained batch 405 in epoch 4, gen_loss = 0.8177402157501634, disc_loss = 0.08701616877189888
Trained batch 406 in epoch 4, gen_loss = 0.8179246853551935, disc_loss = 0.0869053123251098
Trained batch 407 in epoch 4, gen_loss = 0.8173211145342565, disc_loss = 0.08709523172286686
Trained batch 408 in epoch 4, gen_loss = 0.8168786427502527, disc_loss = 0.08712034130669347
Trained batch 409 in epoch 4, gen_loss = 0.8168537068657759, disc_loss = 0.08742047525692459
Trained batch 410 in epoch 4, gen_loss = 0.8168874008812174, disc_loss = 0.08730250648778032
Trained batch 411 in epoch 4, gen_loss = 0.8166629920885401, disc_loss = 0.0876435144969434
Trained batch 412 in epoch 4, gen_loss = 0.8158186731846512, disc_loss = 0.08798674983930826
Trained batch 413 in epoch 4, gen_loss = 0.8154990064061206, disc_loss = 0.08800391090813359
Trained batch 414 in epoch 4, gen_loss = 0.8152955760438758, disc_loss = 0.08807596541963607
Trained batch 415 in epoch 4, gen_loss = 0.8160104609739322, disc_loss = 0.08872755401199146
Trained batch 416 in epoch 4, gen_loss = 0.815949473592589, disc_loss = 0.08875665266169526
Trained batch 417 in epoch 4, gen_loss = 0.8152632282681442, disc_loss = 0.08907414414099993
Trained batch 418 in epoch 4, gen_loss = 0.815155574985222, disc_loss = 0.08898158327994206
Trained batch 419 in epoch 4, gen_loss = 0.8153752326965332, disc_loss = 0.08883696163095356
Trained batch 420 in epoch 4, gen_loss = 0.815296191925674, disc_loss = 0.0886675888802989
Trained batch 421 in epoch 4, gen_loss = 0.8156962211098151, disc_loss = 0.08869290774824955
Trained batch 422 in epoch 4, gen_loss = 0.8155427517338566, disc_loss = 0.0885685969498581
Trained batch 423 in epoch 4, gen_loss = 0.8151459440870105, disc_loss = 0.08863801084884952
Trained batch 424 in epoch 4, gen_loss = 0.815054959970362, disc_loss = 0.08861447272164856
Trained batch 425 in epoch 4, gen_loss = 0.8147783923037175, disc_loss = 0.08854850083523967
Trained batch 426 in epoch 4, gen_loss = 0.8150499819034156, disc_loss = 0.08844021427831165
Trained batch 427 in epoch 4, gen_loss = 0.8151470308548936, disc_loss = 0.08827940362971276
Trained batch 428 in epoch 4, gen_loss = 0.8150443433325886, disc_loss = 0.08818145762013145
Trained batch 429 in epoch 4, gen_loss = 0.8154002342113229, disc_loss = 0.08809811268976435
Trained batch 430 in epoch 4, gen_loss = 0.8150871159582292, disc_loss = 0.08801318161954494
Trained batch 431 in epoch 4, gen_loss = 0.8153070189334728, disc_loss = 0.08783241253695451
Trained batch 432 in epoch 4, gen_loss = 0.8154990004061551, disc_loss = 0.08773723509760603
Trained batch 433 in epoch 4, gen_loss = 0.815302375549545, disc_loss = 0.08764898003731351
Trained batch 434 in epoch 4, gen_loss = 0.8156987129956826, disc_loss = 0.08761537591552084
Trained batch 435 in epoch 4, gen_loss = 0.8154170215129852, disc_loss = 0.08760738602749696
Trained batch 436 in epoch 4, gen_loss = 0.8153793545827713, disc_loss = 0.08751207052301659
Trained batch 437 in epoch 4, gen_loss = 0.816181922203874, disc_loss = 0.08742645388090617
Trained batch 438 in epoch 4, gen_loss = 0.8159388717866433, disc_loss = 0.08745544848556297
Trained batch 439 in epoch 4, gen_loss = 0.8157347355376591, disc_loss = 0.08733104406538504
Trained batch 440 in epoch 4, gen_loss = 0.8162559823654677, disc_loss = 0.08723920167375213
Trained batch 441 in epoch 4, gen_loss = 0.8163111184247479, disc_loss = 0.08707535743178184
Trained batch 442 in epoch 4, gen_loss = 0.8164934902105051, disc_loss = 0.08714510561923579
Trained batch 443 in epoch 4, gen_loss = 0.816308565102182, disc_loss = 0.08716723696341284
Trained batch 444 in epoch 4, gen_loss = 0.8160302728749393, disc_loss = 0.08711823959301195
Trained batch 445 in epoch 4, gen_loss = 0.8156741558169036, disc_loss = 0.08716799445020143
Trained batch 446 in epoch 4, gen_loss = 0.8161971395714438, disc_loss = 0.08721859712399525
Trained batch 447 in epoch 4, gen_loss = 0.8166003674268723, disc_loss = 0.08767560459611039
Trained batch 448 in epoch 4, gen_loss = 0.8159644104590129, disc_loss = 0.08808197531712247
Trained batch 449 in epoch 4, gen_loss = 0.8152911292182075, disc_loss = 0.08815769330598414
Trained batch 450 in epoch 4, gen_loss = 0.8156719146969578, disc_loss = 0.08829238207209567
Trained batch 451 in epoch 4, gen_loss = 0.8159428266561137, disc_loss = 0.08863549731544063
Trained batch 452 in epoch 4, gen_loss = 0.8152627743632588, disc_loss = 0.08880862240961221
Trained batch 453 in epoch 4, gen_loss = 0.814292924257102, disc_loss = 0.089132661460427
Trained batch 454 in epoch 4, gen_loss = 0.8147701800524534, disc_loss = 0.08945387447211932
Trained batch 455 in epoch 4, gen_loss = 0.8145022035429352, disc_loss = 0.08963223477404793
Trained batch 456 in epoch 4, gen_loss = 0.8145807347621125, disc_loss = 0.08964469353209863
Trained batch 457 in epoch 4, gen_loss = 0.8142455631468494, disc_loss = 0.0898089117612527
Trained batch 458 in epoch 4, gen_loss = 0.8136974048510616, disc_loss = 0.08996847764668024
Trained batch 459 in epoch 4, gen_loss = 0.8144812140775763, disc_loss = 0.08986200892022285
Trained batch 460 in epoch 4, gen_loss = 0.814374692527953, disc_loss = 0.0898042686552278
Trained batch 461 in epoch 4, gen_loss = 0.8147856753109853, disc_loss = 0.08996323967912916
Trained batch 462 in epoch 4, gen_loss = 0.81445591599071, disc_loss = 0.0898527283126943
Trained batch 463 in epoch 4, gen_loss = 0.8140446243101153, disc_loss = 0.08992560142912132
Trained batch 464 in epoch 4, gen_loss = 0.8140326208965752, disc_loss = 0.0897894657477336
Trained batch 465 in epoch 4, gen_loss = 0.8144317777115899, disc_loss = 0.08978067828210415
Trained batch 466 in epoch 4, gen_loss = 0.814390904004875, disc_loss = 0.08974078577310964
Trained batch 467 in epoch 4, gen_loss = 0.8138272415878426, disc_loss = 0.08986592043338455
Trained batch 468 in epoch 4, gen_loss = 0.8134614707056139, disc_loss = 0.089841663000434
Trained batch 469 in epoch 4, gen_loss = 0.8137756352728985, disc_loss = 0.08996821038444784
Trained batch 470 in epoch 4, gen_loss = 0.8140716760274964, disc_loss = 0.08996153746745421
Trained batch 471 in epoch 4, gen_loss = 0.8139120985643339, disc_loss = 0.09003610402775802
Trained batch 472 in epoch 4, gen_loss = 0.813568335254903, disc_loss = 0.09030565782204018
Trained batch 473 in epoch 4, gen_loss = 0.8132044479313782, disc_loss = 0.09020880882958351
Trained batch 474 in epoch 4, gen_loss = 0.8131612426356265, disc_loss = 0.09062480210963833
Trained batch 475 in epoch 4, gen_loss = 0.8131628492299248, disc_loss = 0.09054199363273263
Trained batch 476 in epoch 4, gen_loss = 0.8127796087624892, disc_loss = 0.09063017781944926
Trained batch 477 in epoch 4, gen_loss = 0.8129441917690772, disc_loss = 0.0905886180669646
Trained batch 478 in epoch 4, gen_loss = 0.8122362439094855, disc_loss = 0.09100807905838765
Trained batch 479 in epoch 4, gen_loss = 0.8122495917603374, disc_loss = 0.09097100876291127
Trained batch 480 in epoch 4, gen_loss = 0.8126626382126878, disc_loss = 0.09115637158549036
Trained batch 481 in epoch 4, gen_loss = 0.8124826669816654, disc_loss = 0.09108886058264531
Trained batch 482 in epoch 4, gen_loss = 0.812016746210509, disc_loss = 0.09102821915929146
Trained batch 483 in epoch 4, gen_loss = 0.8119571563010374, disc_loss = 0.09089297771334556
Trained batch 484 in epoch 4, gen_loss = 0.8113265586268041, disc_loss = 0.09089597568933651
Trained batch 485 in epoch 4, gen_loss = 0.8112875989067211, disc_loss = 0.09073870674775983
Trained batch 486 in epoch 4, gen_loss = 0.8116046420969757, disc_loss = 0.09060679325734473
Trained batch 487 in epoch 4, gen_loss = 0.8116743320935085, disc_loss = 0.09062803333690085
Trained batch 488 in epoch 4, gen_loss = 0.8120988512941177, disc_loss = 0.09058298356545393
Trained batch 489 in epoch 4, gen_loss = 0.8119485821650952, disc_loss = 0.0905566679741427
Trained batch 490 in epoch 4, gen_loss = 0.8113113729749823, disc_loss = 0.09075485529613259
Trained batch 491 in epoch 4, gen_loss = 0.8111256024822956, disc_loss = 0.09089798712061824
Trained batch 492 in epoch 4, gen_loss = 0.8107000922455507, disc_loss = 0.0909272456063717
Trained batch 493 in epoch 4, gen_loss = 0.810286647214098, disc_loss = 0.09087929894359639
Trained batch 494 in epoch 4, gen_loss = 0.8101960439272601, disc_loss = 0.09074804299050057
Trained batch 495 in epoch 4, gen_loss = 0.8101046403209048, disc_loss = 0.09061390091758972
Trained batch 496 in epoch 4, gen_loss = 0.8098081233395897, disc_loss = 0.09055089195852938
Trained batch 497 in epoch 4, gen_loss = 0.8098497168725753, disc_loss = 0.09053385611642227
Trained batch 498 in epoch 4, gen_loss = 0.8108714645157358, disc_loss = 0.09059390731114812
Trained batch 499 in epoch 4, gen_loss = 0.8115310488343239, disc_loss = 0.09048259838763624
Trained batch 500 in epoch 4, gen_loss = 0.8115209716403794, disc_loss = 0.09036130397608448
Trained batch 501 in epoch 4, gen_loss = 0.8120246063546831, disc_loss = 0.09037089116771174
Trained batch 502 in epoch 4, gen_loss = 0.8115174770947716, disc_loss = 0.0905921436137118
Trained batch 503 in epoch 4, gen_loss = 0.8112202443418994, disc_loss = 0.09053267157610713
Trained batch 504 in epoch 4, gen_loss = 0.8116918687183078, disc_loss = 0.09045848465515392
Trained batch 505 in epoch 4, gen_loss = 0.8119663715715936, disc_loss = 0.09049097882683127
Trained batch 506 in epoch 4, gen_loss = 0.8116104374152904, disc_loss = 0.09060671973764103
Trained batch 507 in epoch 4, gen_loss = 0.8121030531882301, disc_loss = 0.09055485603982567
Trained batch 508 in epoch 4, gen_loss = 0.8121828221970316, disc_loss = 0.09047096305067535
Trained batch 509 in epoch 4, gen_loss = 0.8118709367279913, disc_loss = 0.09047713164769697
Trained batch 510 in epoch 4, gen_loss = 0.8119944053503398, disc_loss = 0.0904866857554421
Trained batch 511 in epoch 4, gen_loss = 0.8127785710967146, disc_loss = 0.09046839345410262
Trained batch 512 in epoch 4, gen_loss = 0.8123716003829741, disc_loss = 0.09045798715374652
Trained batch 513 in epoch 4, gen_loss = 0.8124956148259834, disc_loss = 0.09035025825198552
Trained batch 514 in epoch 4, gen_loss = 0.8120682575748962, disc_loss = 0.09030029504351969
Trained batch 515 in epoch 4, gen_loss = 0.8133647227587626, disc_loss = 0.09038873553698407
Trained batch 516 in epoch 4, gen_loss = 0.8136638311283731, disc_loss = 0.09028357301696385
Trained batch 517 in epoch 4, gen_loss = 0.8134581988037323, disc_loss = 0.09033822851942341
Trained batch 518 in epoch 4, gen_loss = 0.8134042499497217, disc_loss = 0.09027862057595842
Trained batch 519 in epoch 4, gen_loss = 0.8136332039076548, disc_loss = 0.09015695096727891
Trained batch 520 in epoch 4, gen_loss = 0.814087323343914, disc_loss = 0.09005215696207536
Trained batch 521 in epoch 4, gen_loss = 0.8142183377939166, disc_loss = 0.08997890453204027
Trained batch 522 in epoch 4, gen_loss = 0.8137577765872328, disc_loss = 0.08999106967572415
Trained batch 523 in epoch 4, gen_loss = 0.8137601884153053, disc_loss = 0.08990419538823162
Trained batch 524 in epoch 4, gen_loss = 0.8138241939885276, disc_loss = 0.08981226993547309
Trained batch 525 in epoch 4, gen_loss = 0.8143427054125093, disc_loss = 0.0897730008598077
Trained batch 526 in epoch 4, gen_loss = 0.8147864051629742, disc_loss = 0.08968570124467506
Trained batch 527 in epoch 4, gen_loss = 0.8146295361785274, disc_loss = 0.08965997582841241
Trained batch 528 in epoch 4, gen_loss = 0.8141180866720095, disc_loss = 0.08967822122639345
Trained batch 529 in epoch 4, gen_loss = 0.8141914319879604, disc_loss = 0.08959850524200724
Trained batch 530 in epoch 4, gen_loss = 0.8145285522084676, disc_loss = 0.08946564430967253
Trained batch 531 in epoch 4, gen_loss = 0.8142236424680043, disc_loss = 0.08941398872696284
Trained batch 532 in epoch 4, gen_loss = 0.8144481797714842, disc_loss = 0.0892893448026456
Trained batch 533 in epoch 4, gen_loss = 0.8142430564102608, disc_loss = 0.08925887921123943
Trained batch 534 in epoch 4, gen_loss = 0.8142091350577702, disc_loss = 0.08916961143802955
Trained batch 535 in epoch 4, gen_loss = 0.8144981793836871, disc_loss = 0.08904121910767462
Trained batch 536 in epoch 4, gen_loss = 0.8146373429222924, disc_loss = 0.08905651786727085
Trained batch 537 in epoch 4, gen_loss = 0.8149971419661461, disc_loss = 0.08901633674081512
Trained batch 538 in epoch 4, gen_loss = 0.8146396210220174, disc_loss = 0.08900778259691508
Trained batch 539 in epoch 4, gen_loss = 0.8139912499321832, disc_loss = 0.08911498855471749
Trained batch 540 in epoch 4, gen_loss = 0.8146006117907116, disc_loss = 0.08914293187744433
Trained batch 541 in epoch 4, gen_loss = 0.8152502480468187, disc_loss = 0.08905502969684334
Trained batch 542 in epoch 4, gen_loss = 0.8151169451121687, disc_loss = 0.08898384047974017
Trained batch 543 in epoch 4, gen_loss = 0.815103643847739, disc_loss = 0.08890865235812004
Trained batch 544 in epoch 4, gen_loss = 0.8154771967765388, disc_loss = 0.08886833655126734
Trained batch 545 in epoch 4, gen_loss = 0.8158013197310242, disc_loss = 0.08875252253328188
Trained batch 546 in epoch 4, gen_loss = 0.8157508776436341, disc_loss = 0.08870796119739767
Trained batch 547 in epoch 4, gen_loss = 0.8156544361671392, disc_loss = 0.08873423682542748
Trained batch 548 in epoch 4, gen_loss = 0.8155763377257383, disc_loss = 0.08870318119510845
Trained batch 549 in epoch 4, gen_loss = 0.8148776724663648, disc_loss = 0.0891301464501091
Trained batch 550 in epoch 4, gen_loss = 0.8147323365761018, disc_loss = 0.08921586488290756
Trained batch 551 in epoch 4, gen_loss = 0.8151955117026101, disc_loss = 0.0892183786347522
Trained batch 552 in epoch 4, gen_loss = 0.8158359437588111, disc_loss = 0.08923337076475699
Trained batch 553 in epoch 4, gen_loss = 0.8152247383276048, disc_loss = 0.08947381315440181
Trained batch 554 in epoch 4, gen_loss = 0.8151783602731721, disc_loss = 0.08952051022652167
Trained batch 555 in epoch 4, gen_loss = 0.8149840000936454, disc_loss = 0.0894896838849196
Trained batch 556 in epoch 4, gen_loss = 0.8152107322451456, disc_loss = 0.08939380007520104
Trained batch 557 in epoch 4, gen_loss = 0.8146908468029405, disc_loss = 0.0894865255584226
Trained batch 558 in epoch 4, gen_loss = 0.8145606372778659, disc_loss = 0.08938823661755284
Trained batch 559 in epoch 4, gen_loss = 0.8155514870371138, disc_loss = 0.08941057289900657
Trained batch 560 in epoch 4, gen_loss = 0.815992044467552, disc_loss = 0.08929597267402924
Trained batch 561 in epoch 4, gen_loss = 0.8160666420366416, disc_loss = 0.08932296012766872
Trained batch 562 in epoch 4, gen_loss = 0.8157457022218043, disc_loss = 0.08926710090475888
Trained batch 563 in epoch 4, gen_loss = 0.8153956777660559, disc_loss = 0.08931294827084618
Trained batch 564 in epoch 4, gen_loss = 0.8159179029211534, disc_loss = 0.08922312815912661
Trained batch 565 in epoch 4, gen_loss = 0.8164039803899219, disc_loss = 0.08923703225168264
Trained batch 566 in epoch 4, gen_loss = 0.8165238992667493, disc_loss = 0.08910291867882565
Trained batch 567 in epoch 4, gen_loss = 0.8160270861756633, disc_loss = 0.08911585881174738
Trained batch 568 in epoch 4, gen_loss = 0.8156380804226143, disc_loss = 0.08921838503229466
Trained batch 569 in epoch 4, gen_loss = 0.8162842794468529, disc_loss = 0.08911418740866346
Trained batch 570 in epoch 4, gen_loss = 0.8165452081560045, disc_loss = 0.0890892997584689
Trained batch 571 in epoch 4, gen_loss = 0.8171277408833271, disc_loss = 0.08900063295956127
Trained batch 572 in epoch 4, gen_loss = 0.8167697807049044, disc_loss = 0.08905908525116858
Trained batch 573 in epoch 4, gen_loss = 0.8167571583276011, disc_loss = 0.08899267634964234
Trained batch 574 in epoch 4, gen_loss = 0.8170076992200769, disc_loss = 0.08900595157609685
Trained batch 575 in epoch 4, gen_loss = 0.8165772358576456, disc_loss = 0.08902139325881661
Trained batch 576 in epoch 4, gen_loss = 0.8163336861484799, disc_loss = 0.08895674292918172
Trained batch 577 in epoch 4, gen_loss = 0.8162677225150864, disc_loss = 0.08886124849702944
Trained batch 578 in epoch 4, gen_loss = 0.8166198855031134, disc_loss = 0.08885953348815209
Trained batch 579 in epoch 4, gen_loss = 0.8165679975830276, disc_loss = 0.08888397638059767
Trained batch 580 in epoch 4, gen_loss = 0.8161965555250131, disc_loss = 0.08883681638076542
Trained batch 581 in epoch 4, gen_loss = 0.8160998955420202, disc_loss = 0.08875606499557924
Trained batch 582 in epoch 4, gen_loss = 0.816029497628351, disc_loss = 0.08865345227508127
Trained batch 583 in epoch 4, gen_loss = 0.8156745688964243, disc_loss = 0.08867858720493618
Trained batch 584 in epoch 4, gen_loss = 0.8157084921486357, disc_loss = 0.08880749238081849
Trained batch 585 in epoch 4, gen_loss = 0.8151333870639573, disc_loss = 0.0890243403611978
Trained batch 586 in epoch 4, gen_loss = 0.815208286960852, disc_loss = 0.08908914890397321
Trained batch 587 in epoch 4, gen_loss = 0.8147621152250946, disc_loss = 0.08915613429719063
Trained batch 588 in epoch 4, gen_loss = 0.8147724944282266, disc_loss = 0.08913345139312395
Trained batch 589 in epoch 4, gen_loss = 0.8146980245739727, disc_loss = 0.08925844370545345
Trained batch 590 in epoch 4, gen_loss = 0.8152063417858278, disc_loss = 0.08913735942221712
Trained batch 591 in epoch 4, gen_loss = 0.8149281730623664, disc_loss = 0.08916367847406356
Trained batch 592 in epoch 4, gen_loss = 0.8152438883134124, disc_loss = 0.08907002523701645
Trained batch 593 in epoch 4, gen_loss = 0.8148705921690873, disc_loss = 0.08908681682097766
Trained batch 594 in epoch 4, gen_loss = 0.8149530797946353, disc_loss = 0.08896441296478655
Trained batch 595 in epoch 4, gen_loss = 0.8153507255967831, disc_loss = 0.08903886862458574
Trained batch 596 in epoch 4, gen_loss = 0.8152538472583745, disc_loss = 0.0889673509550791
Trained batch 597 in epoch 4, gen_loss = 0.8152385763201028, disc_loss = 0.08886313406255308
Trained batch 598 in epoch 4, gen_loss = 0.814566026744938, disc_loss = 0.08889449477578219
Trained batch 599 in epoch 4, gen_loss = 0.8147825157642364, disc_loss = 0.08878005902205284
Trained batch 600 in epoch 4, gen_loss = 0.8150423230625032, disc_loss = 0.08865419569070422
Trained batch 601 in epoch 4, gen_loss = 0.8149967438160779, disc_loss = 0.08856450405785585
Trained batch 602 in epoch 4, gen_loss = 0.8148967827335124, disc_loss = 0.08846567649236736
Trained batch 603 in epoch 4, gen_loss = 0.815282544454202, disc_loss = 0.08834593458677834
Trained batch 604 in epoch 4, gen_loss = 0.8153551782458281, disc_loss = 0.088314439534125
Trained batch 605 in epoch 4, gen_loss = 0.8156182662685318, disc_loss = 0.0882582904044047
Trained batch 606 in epoch 4, gen_loss = 0.8155107434341896, disc_loss = 0.0881955040460744
Trained batch 607 in epoch 4, gen_loss = 0.8153711128979921, disc_loss = 0.08819255724129586
Trained batch 608 in epoch 4, gen_loss = 0.815002606909459, disc_loss = 0.08826276321003859
Trained batch 609 in epoch 4, gen_loss = 0.8159910877219966, disc_loss = 0.0884686017004376
Trained batch 610 in epoch 4, gen_loss = 0.8158169814100438, disc_loss = 0.08848924097054792
Trained batch 611 in epoch 4, gen_loss = 0.8157985542529549, disc_loss = 0.08840006472941585
Trained batch 612 in epoch 4, gen_loss = 0.8158448521309147, disc_loss = 0.08828760322174255
Trained batch 613 in epoch 4, gen_loss = 0.8161839437989536, disc_loss = 0.08818133385527381
Trained batch 614 in epoch 4, gen_loss = 0.8163244643831641, disc_loss = 0.08806115880502555
Trained batch 615 in epoch 4, gen_loss = 0.8169085715304721, disc_loss = 0.08802160821241242
Trained batch 616 in epoch 4, gen_loss = 0.8164028886651298, disc_loss = 0.08818125550678933
Trained batch 617 in epoch 4, gen_loss = 0.8167952628004512, disc_loss = 0.08816422847352777
Trained batch 618 in epoch 4, gen_loss = 0.8170555911849889, disc_loss = 0.08803808084359582
Trained batch 619 in epoch 4, gen_loss = 0.8173760759253655, disc_loss = 0.08793469242105681
Trained batch 620 in epoch 4, gen_loss = 0.8169876522296101, disc_loss = 0.08801693919275239
Trained batch 621 in epoch 4, gen_loss = 0.8175339540676289, disc_loss = 0.0879368882250472
Trained batch 622 in epoch 4, gen_loss = 0.8175978148729806, disc_loss = 0.0878823864584666
Trained batch 623 in epoch 4, gen_loss = 0.8174223648623015, disc_loss = 0.08784663765049444
Trained batch 624 in epoch 4, gen_loss = 0.8171313341140747, disc_loss = 0.08785170618966222
Trained batch 625 in epoch 4, gen_loss = 0.8171216368484802, disc_loss = 0.08779852927852862
Trained batch 626 in epoch 4, gen_loss = 0.8174320853878246, disc_loss = 0.08768570080972864
Trained batch 627 in epoch 4, gen_loss = 0.81715349710671, disc_loss = 0.08763406807808859
Trained batch 628 in epoch 4, gen_loss = 0.8174936820668522, disc_loss = 0.08753791545104644
Trained batch 629 in epoch 4, gen_loss = 0.8177078837440127, disc_loss = 0.08750503834351779
Trained batch 630 in epoch 4, gen_loss = 0.817605033540499, disc_loss = 0.08745611784979701
Trained batch 631 in epoch 4, gen_loss = 0.8169026031995876, disc_loss = 0.08762717415664133
Trained batch 632 in epoch 4, gen_loss = 0.8170780152976984, disc_loss = 0.08752064964561877
Trained batch 633 in epoch 4, gen_loss = 0.8170488477223303, disc_loss = 0.08744491200544505
Trained batch 634 in epoch 4, gen_loss = 0.8172835925901969, disc_loss = 0.0873958431279624
Trained batch 635 in epoch 4, gen_loss = 0.8172004905605467, disc_loss = 0.08742901585987364
Trained batch 636 in epoch 4, gen_loss = 0.8174500703530932, disc_loss = 0.0874521855880423
Trained batch 637 in epoch 4, gen_loss = 0.8171135050282583, disc_loss = 0.08737851436203199
Trained batch 638 in epoch 4, gen_loss = 0.8169134979796522, disc_loss = 0.08732987576308594
Trained batch 639 in epoch 4, gen_loss = 0.8174829249735922, disc_loss = 0.08725796725266263
Trained batch 640 in epoch 4, gen_loss = 0.8173638137286985, disc_loss = 0.08721560891063858
Trained batch 641 in epoch 4, gen_loss = 0.817248997612163, disc_loss = 0.08714907196628922
Trained batch 642 in epoch 4, gen_loss = 0.817252492784156, disc_loss = 0.08714575896729045
Trained batch 643 in epoch 4, gen_loss = 0.8171133289333457, disc_loss = 0.08723934052977711
Trained batch 644 in epoch 4, gen_loss = 0.8172684579394585, disc_loss = 0.08725584828937354
Trained batch 645 in epoch 4, gen_loss = 0.8169600726927028, disc_loss = 0.08732008823660713
Trained batch 646 in epoch 4, gen_loss = 0.8169101486342399, disc_loss = 0.08725915973936964
Trained batch 647 in epoch 4, gen_loss = 0.8172438689680012, disc_loss = 0.08720072926047982
Trained batch 648 in epoch 4, gen_loss = 0.8168959163462253, disc_loss = 0.08718191268990169
Trained batch 649 in epoch 4, gen_loss = 0.8166895305651884, disc_loss = 0.0871773786076273
Trained batch 650 in epoch 4, gen_loss = 0.8173172992586907, disc_loss = 0.08738509692987012
Trained batch 651 in epoch 4, gen_loss = 0.8169212275944604, disc_loss = 0.08738084058948661
Trained batch 652 in epoch 4, gen_loss = 0.816843559557592, disc_loss = 0.0873043870454965
Trained batch 653 in epoch 4, gen_loss = 0.8166964982354313, disc_loss = 0.08731111956244784
Trained batch 654 in epoch 4, gen_loss = 0.8168312939523741, disc_loss = 0.08734358217325489
Trained batch 655 in epoch 4, gen_loss = 0.8174340725399372, disc_loss = 0.08777853006443077
Trained batch 656 in epoch 4, gen_loss = 0.8172826415418308, disc_loss = 0.08768716673161182
Trained batch 657 in epoch 4, gen_loss = 0.8170668910792533, disc_loss = 0.08771956418527681
Trained batch 658 in epoch 4, gen_loss = 0.8168841575545136, disc_loss = 0.08764071380776071
Trained batch 659 in epoch 4, gen_loss = 0.8167864221063528, disc_loss = 0.08760407562861501
Trained batch 660 in epoch 4, gen_loss = 0.8171618000552081, disc_loss = 0.08773238071326431
Trained batch 661 in epoch 4, gen_loss = 0.8167839988030696, disc_loss = 0.08794711796170117
Trained batch 662 in epoch 4, gen_loss = 0.816913150239674, disc_loss = 0.08786052522540294
Trained batch 663 in epoch 4, gen_loss = 0.8168734165290034, disc_loss = 0.08786019972169277
Trained batch 664 in epoch 4, gen_loss = 0.8169184272002457, disc_loss = 0.08785875774429817
Trained batch 665 in epoch 4, gen_loss = 0.8167390065776693, disc_loss = 0.08777417138277611
Trained batch 666 in epoch 4, gen_loss = 0.8165310505537436, disc_loss = 0.08777332677669276
Trained batch 667 in epoch 4, gen_loss = 0.8168641068710538, disc_loss = 0.08770968337629749
Trained batch 668 in epoch 4, gen_loss = 0.81659887123001, disc_loss = 0.08768125710123524
Trained batch 669 in epoch 4, gen_loss = 0.8168402535257054, disc_loss = 0.08758075854240625
Trained batch 670 in epoch 4, gen_loss = 0.8166492275349607, disc_loss = 0.08757999793441769
Trained batch 671 in epoch 4, gen_loss = 0.8167701658482353, disc_loss = 0.08748137404923216
Trained batch 672 in epoch 4, gen_loss = 0.8164826616047042, disc_loss = 0.08756997870879156
Trained batch 673 in epoch 4, gen_loss = 0.81658473199659, disc_loss = 0.08749760515526357
Trained batch 674 in epoch 4, gen_loss = 0.8163450601807347, disc_loss = 0.0874602379684371
Trained batch 675 in epoch 4, gen_loss = 0.8166543397413203, disc_loss = 0.08749998687730673
Trained batch 676 in epoch 4, gen_loss = 0.8172703511693805, disc_loss = 0.08754328982299263
Trained batch 677 in epoch 4, gen_loss = 0.8170240636156724, disc_loss = 0.08772077936209342
Trained batch 678 in epoch 4, gen_loss = 0.8172182306888703, disc_loss = 0.08766113849362257
Trained batch 679 in epoch 4, gen_loss = 0.817221205243293, disc_loss = 0.08757515353602631
Trained batch 680 in epoch 4, gen_loss = 0.8171065486912861, disc_loss = 0.0875219722530051
Trained batch 681 in epoch 4, gen_loss = 0.8172857742592736, disc_loss = 0.08741686220657725
Trained batch 682 in epoch 4, gen_loss = 0.8172624783582254, disc_loss = 0.08731626094513918
Trained batch 683 in epoch 4, gen_loss = 0.8171877134700267, disc_loss = 0.08728274651081437
Trained batch 684 in epoch 4, gen_loss = 0.8170725875092248, disc_loss = 0.08723100014098913
Trained batch 685 in epoch 4, gen_loss = 0.8173584168662831, disc_loss = 0.08716663376987524
Trained batch 686 in epoch 4, gen_loss = 0.8173416700685909, disc_loss = 0.08707003044967676
Trained batch 687 in epoch 4, gen_loss = 0.8172294342847064, disc_loss = 0.08709736405614611
Trained batch 688 in epoch 4, gen_loss = 0.8172501190220842, disc_loss = 0.0870235299668579
Trained batch 689 in epoch 4, gen_loss = 0.8178174374328143, disc_loss = 0.0870753764357094
Trained batch 690 in epoch 4, gen_loss = 0.8175746242579089, disc_loss = 0.08723955058092427
Trained batch 691 in epoch 4, gen_loss = 0.8173545152379599, disc_loss = 0.08721613921723033
Trained batch 692 in epoch 4, gen_loss = 0.8173087603516049, disc_loss = 0.08714650474652691
Trained batch 693 in epoch 4, gen_loss = 0.8172169117745474, disc_loss = 0.08707809621690953
Trained batch 694 in epoch 4, gen_loss = 0.8173034399962253, disc_loss = 0.08708344116445176
Trained batch 695 in epoch 4, gen_loss = 0.8172810087515705, disc_loss = 0.08699816630834756
Trained batch 696 in epoch 4, gen_loss = 0.8174861032873862, disc_loss = 0.08690763396442129
Trained batch 697 in epoch 4, gen_loss = 0.8173104361937858, disc_loss = 0.08685479608876764
Trained batch 698 in epoch 4, gen_loss = 0.8176138107271835, disc_loss = 0.08678641729389926
Trained batch 699 in epoch 4, gen_loss = 0.8177555253250258, disc_loss = 0.0868121115178136
Trained batch 700 in epoch 4, gen_loss = 0.8177627734467918, disc_loss = 0.0867422462185943
Trained batch 701 in epoch 4, gen_loss = 0.8178413803675915, disc_loss = 0.08666180777416546
Trained batch 702 in epoch 4, gen_loss = 0.8179595570052162, disc_loss = 0.08677590714242961
Trained batch 703 in epoch 4, gen_loss = 0.8178768736648966, disc_loss = 0.086763598824539
Trained batch 704 in epoch 4, gen_loss = 0.8173405408859253, disc_loss = 0.08696561799787567
Trained batch 705 in epoch 4, gen_loss = 0.8171201155813828, disc_loss = 0.0869213092034002
Trained batch 706 in epoch 4, gen_loss = 0.8177712198025435, disc_loss = 0.08702420917585955
Trained batch 707 in epoch 4, gen_loss = 0.8178661300637627, disc_loss = 0.0869259659659991
Trained batch 708 in epoch 4, gen_loss = 0.8179843229030184, disc_loss = 0.08690610652584556
Trained batch 709 in epoch 4, gen_loss = 0.8178679671086057, disc_loss = 0.0868338622579115
Trained batch 710 in epoch 4, gen_loss = 0.8179540858825383, disc_loss = 0.08673846743720598
Trained batch 711 in epoch 4, gen_loss = 0.8177614734413918, disc_loss = 0.08673123099770544
Trained batch 712 in epoch 4, gen_loss = 0.8176404656568048, disc_loss = 0.08667973126513363
Trained batch 713 in epoch 4, gen_loss = 0.8178750914351947, disc_loss = 0.08672318197017227
Trained batch 714 in epoch 4, gen_loss = 0.817775396950595, disc_loss = 0.08664675355543727
Trained batch 715 in epoch 4, gen_loss = 0.81765194470323, disc_loss = 0.08660204812699628
Trained batch 716 in epoch 4, gen_loss = 0.8173998814580165, disc_loss = 0.08656721964356395
Trained batch 717 in epoch 4, gen_loss = 0.8176935631418627, disc_loss = 0.08661514021583358
Trained batch 718 in epoch 4, gen_loss = 0.8176472742467994, disc_loss = 0.08655598793393816
Trained batch 719 in epoch 4, gen_loss = 0.8182166943947474, disc_loss = 0.08650573236001138
Trained batch 720 in epoch 4, gen_loss = 0.8182190216860725, disc_loss = 0.08641668342004805
Trained batch 721 in epoch 4, gen_loss = 0.8181779004034904, disc_loss = 0.08636001566711328
Trained batch 722 in epoch 4, gen_loss = 0.818435132668391, disc_loss = 0.08641865238467461
Trained batch 723 in epoch 4, gen_loss = 0.818097552459543, disc_loss = 0.08636414860207998
Trained batch 724 in epoch 4, gen_loss = 0.8180436599665675, disc_loss = 0.08631146539966095
Trained batch 725 in epoch 4, gen_loss = 0.8178033832019354, disc_loss = 0.08635299868391667
Trained batch 726 in epoch 4, gen_loss = 0.8180299593953023, disc_loss = 0.0862499312408002
Trained batch 727 in epoch 4, gen_loss = 0.8180192795756099, disc_loss = 0.08624107069092812
Trained batch 728 in epoch 4, gen_loss = 0.8184274699952867, disc_loss = 0.08619710960743543
Trained batch 729 in epoch 4, gen_loss = 0.8182646461545604, disc_loss = 0.08626743312478576
Trained batch 730 in epoch 4, gen_loss = 0.8181314516491505, disc_loss = 0.08623536415563746
Trained batch 731 in epoch 4, gen_loss = 0.8180703038726348, disc_loss = 0.08619087530221138
Trained batch 732 in epoch 4, gen_loss = 0.8186780794906096, disc_loss = 0.08622679958821339
Trained batch 733 in epoch 4, gen_loss = 0.8188841439560258, disc_loss = 0.08613037128998753
Trained batch 734 in epoch 4, gen_loss = 0.8187497170604006, disc_loss = 0.08615851604829536
Trained batch 735 in epoch 4, gen_loss = 0.8188560094036486, disc_loss = 0.08620600057980957
Trained batch 736 in epoch 4, gen_loss = 0.8188475214318958, disc_loss = 0.08616229995208181
Trained batch 737 in epoch 4, gen_loss = 0.8189046417633046, disc_loss = 0.08625323967793629
Trained batch 738 in epoch 4, gen_loss = 0.8189978172879097, disc_loss = 0.0861631181268765
Trained batch 739 in epoch 4, gen_loss = 0.8187098002917058, disc_loss = 0.08620809784624725
Trained batch 740 in epoch 4, gen_loss = 0.8188485604548744, disc_loss = 0.08611064480476875
Trained batch 741 in epoch 4, gen_loss = 0.8193486865479348, disc_loss = 0.08609431054043983
Trained batch 742 in epoch 4, gen_loss = 0.8196323367981379, disc_loss = 0.08601134404111378
Trained batch 743 in epoch 4, gen_loss = 0.8195647062954082, disc_loss = 0.08599601665283904
Trained batch 744 in epoch 4, gen_loss = 0.8194915958698964, disc_loss = 0.08599965627673989
Trained batch 745 in epoch 4, gen_loss = 0.8198839341347722, disc_loss = 0.08597840036480281
Trained batch 746 in epoch 4, gen_loss = 0.8198611760235216, disc_loss = 0.08588312149429357
Trained batch 747 in epoch 4, gen_loss = 0.8197185680827993, disc_loss = 0.08586767496214931
Trained batch 748 in epoch 4, gen_loss = 0.8199495621453299, disc_loss = 0.0857749162210731
Trained batch 749 in epoch 4, gen_loss = 0.8199900029500325, disc_loss = 0.08575804177485406
Trained batch 750 in epoch 4, gen_loss = 0.8197376282015113, disc_loss = 0.08574822164647847
Trained batch 751 in epoch 4, gen_loss = 0.8196359249822637, disc_loss = 0.08581443938013028
Trained batch 752 in epoch 4, gen_loss = 0.819717926649775, disc_loss = 0.08572013952533107
Trained batch 753 in epoch 4, gen_loss = 0.819933505842477, disc_loss = 0.08565608113917673
Trained batch 754 in epoch 4, gen_loss = 0.8201914231508773, disc_loss = 0.08556203904888586
Trained batch 755 in epoch 4, gen_loss = 0.8198986335721596, disc_loss = 0.08560668006502388
Trained batch 756 in epoch 4, gen_loss = 0.8200761667960859, disc_loss = 0.08554215464049574
Trained batch 757 in epoch 4, gen_loss = 0.8204445383636807, disc_loss = 0.08547725020858674
Trained batch 758 in epoch 4, gen_loss = 0.8201861488332233, disc_loss = 0.08543369159831302
Trained batch 759 in epoch 4, gen_loss = 0.8204042210390693, disc_loss = 0.0853436637136742
Trained batch 760 in epoch 4, gen_loss = 0.8202221841599092, disc_loss = 0.0853366802909146
Trained batch 761 in epoch 4, gen_loss = 0.8201406688827855, disc_loss = 0.08525744546999241
Trained batch 762 in epoch 4, gen_loss = 0.8206106669624699, disc_loss = 0.08527308045355493
Trained batch 763 in epoch 4, gen_loss = 0.8204588815179795, disc_loss = 0.08521078327604867
Trained batch 764 in epoch 4, gen_loss = 0.8206260838539772, disc_loss = 0.08514111587485554
Trained batch 765 in epoch 4, gen_loss = 0.8205261096630644, disc_loss = 0.08510557136148234
Trained batch 766 in epoch 4, gen_loss = 0.8203473473465582, disc_loss = 0.08506781100860106
Trained batch 767 in epoch 4, gen_loss = 0.8207330253596107, disc_loss = 0.08502668653151584
Trained batch 768 in epoch 4, gen_loss = 0.8210629638676835, disc_loss = 0.08496764554703906
Trained batch 769 in epoch 4, gen_loss = 0.8209892034530639, disc_loss = 0.08501047453867247
Trained batch 770 in epoch 4, gen_loss = 0.8209324077100296, disc_loss = 0.08500177978118821
Trained batch 771 in epoch 4, gen_loss = 0.8206715274196832, disc_loss = 0.08502170577261674
Trained batch 772 in epoch 4, gen_loss = 0.8207593235593256, disc_loss = 0.08497997276535568
Trained batch 773 in epoch 4, gen_loss = 0.8206338672212852, disc_loss = 0.08496511713673845
Trained batch 774 in epoch 4, gen_loss = 0.8208993600260827, disc_loss = 0.08495042898541977
Trained batch 775 in epoch 4, gen_loss = 0.8218441853664585, disc_loss = 0.08505790459397777
Trained batch 776 in epoch 4, gen_loss = 0.8217885298618479, disc_loss = 0.08500858544500274
Trained batch 777 in epoch 4, gen_loss = 0.8215974228394368, disc_loss = 0.08506513830899215
Trained batch 778 in epoch 4, gen_loss = 0.8217690323069404, disc_loss = 0.08503894388869367
Trained batch 779 in epoch 4, gen_loss = 0.8216499273593609, disc_loss = 0.08501175176411963
Trained batch 780 in epoch 4, gen_loss = 0.8214412032413116, disc_loss = 0.08499684860743821
Trained batch 781 in epoch 4, gen_loss = 0.8213703976110425, disc_loss = 0.08522914505868559
Trained batch 782 in epoch 4, gen_loss = 0.8211901990237669, disc_loss = 0.08518477330950124
Trained batch 783 in epoch 4, gen_loss = 0.8210183961354957, disc_loss = 0.08512343979043867
Trained batch 784 in epoch 4, gen_loss = 0.821389561853591, disc_loss = 0.085043871061651
Trained batch 785 in epoch 4, gen_loss = 0.8213295298071611, disc_loss = 0.08504356424983013
Trained batch 786 in epoch 4, gen_loss = 0.8211255697616325, disc_loss = 0.08504906637603571
Trained batch 787 in epoch 4, gen_loss = 0.8211131979366244, disc_loss = 0.08495981323114374
Trained batch 788 in epoch 4, gen_loss = 0.8208906047697756, disc_loss = 0.0848852256189026
Trained batch 789 in epoch 4, gen_loss = 0.8210581209086165, disc_loss = 0.08480206253655444
Trained batch 790 in epoch 4, gen_loss = 0.8209828531696883, disc_loss = 0.08472805051603996
Trained batch 791 in epoch 4, gen_loss = 0.820892469675252, disc_loss = 0.08471153185978024
Trained batch 792 in epoch 4, gen_loss = 0.8206818096273935, disc_loss = 0.08478533173647027
Trained batch 793 in epoch 4, gen_loss = 0.820734768805636, disc_loss = 0.08476939494838887
Trained batch 794 in epoch 4, gen_loss = 0.8210036437466459, disc_loss = 0.08488349488661068
Trained batch 795 in epoch 4, gen_loss = 0.8209840498078409, disc_loss = 0.08480899928935602
Trained batch 796 in epoch 4, gen_loss = 0.8207288549715184, disc_loss = 0.08479880016248023
Trained batch 797 in epoch 4, gen_loss = 0.820678403727094, disc_loss = 0.08475230195919019
Trained batch 798 in epoch 4, gen_loss = 0.8208361247155783, disc_loss = 0.08471188906904249
Trained batch 799 in epoch 4, gen_loss = 0.8208814215660095, disc_loss = 0.08461858509865124
Trained batch 800 in epoch 4, gen_loss = 0.8207835609397935, disc_loss = 0.08456484040305874
Trained batch 801 in epoch 4, gen_loss = 0.8208726974496817, disc_loss = 0.08455825146308582
Trained batch 802 in epoch 4, gen_loss = 0.8205206073532959, disc_loss = 0.08455798839732707
Trained batch 803 in epoch 4, gen_loss = 0.8205839255407675, disc_loss = 0.08449370754866477
Trained batch 804 in epoch 4, gen_loss = 0.8207214552423229, disc_loss = 0.08442737237833764
Trained batch 805 in epoch 4, gen_loss = 0.820813699484463, disc_loss = 0.0843376311648027
Trained batch 806 in epoch 4, gen_loss = 0.8207489234364166, disc_loss = 0.0842581314203252
Trained batch 807 in epoch 4, gen_loss = 0.8205905312506279, disc_loss = 0.08419064567297568
Trained batch 808 in epoch 4, gen_loss = 0.820959964331944, disc_loss = 0.08411094841083376
Trained batch 809 in epoch 4, gen_loss = 0.8209170380492269, disc_loss = 0.08409704325065293
Trained batch 810 in epoch 4, gen_loss = 0.8208718227840381, disc_loss = 0.0840491507525077
Trained batch 811 in epoch 4, gen_loss = 0.8204968352916793, disc_loss = 0.08416052953640614
Trained batch 812 in epoch 4, gen_loss = 0.8209215399670572, disc_loss = 0.08429202257837702
Trained batch 813 in epoch 4, gen_loss = 0.8209325621403406, disc_loss = 0.08420576611064667
Trained batch 814 in epoch 4, gen_loss = 0.821163790796432, disc_loss = 0.08415667182977306
Trained batch 815 in epoch 4, gen_loss = 0.8208056743092397, disc_loss = 0.08429177003677514
Trained batch 816 in epoch 4, gen_loss = 0.8210908134389244, disc_loss = 0.084222505054342
Trained batch 817 in epoch 4, gen_loss = 0.8209548256653737, disc_loss = 0.08417125512199125
Trained batch 818 in epoch 4, gen_loss = 0.821096860081576, disc_loss = 0.08419488533769572
Trained batch 819 in epoch 4, gen_loss = 0.8212100428052065, disc_loss = 0.0841505418605421
Trained batch 820 in epoch 4, gen_loss = 0.8209894337259169, disc_loss = 0.08413856744768504
Trained batch 821 in epoch 4, gen_loss = 0.8212152746327022, disc_loss = 0.08408857406674455
Trained batch 822 in epoch 4, gen_loss = 0.8209626363954741, disc_loss = 0.08410375151174417
Trained batch 823 in epoch 4, gen_loss = 0.8209864872607212, disc_loss = 0.08407209279723195
Trained batch 824 in epoch 4, gen_loss = 0.8211534997911164, disc_loss = 0.08399089079971114
Trained batch 825 in epoch 4, gen_loss = 0.82134255694708, disc_loss = 0.08392002286116614
Trained batch 826 in epoch 4, gen_loss = 0.8214138574006336, disc_loss = 0.083833399493959
Trained batch 827 in epoch 4, gen_loss = 0.8217774509375798, disc_loss = 0.08382737481401972
Trained batch 828 in epoch 4, gen_loss = 0.8213821401138789, disc_loss = 0.08389483228274167
Trained batch 829 in epoch 4, gen_loss = 0.8212861930390438, disc_loss = 0.08400315810724285
Trained batch 830 in epoch 4, gen_loss = 0.8212464810063262, disc_loss = 0.08394827216327926
Trained batch 831 in epoch 4, gen_loss = 0.821376437930247, disc_loss = 0.08399252443576607
Trained batch 832 in epoch 4, gen_loss = 0.8212090107787843, disc_loss = 0.0840010823730026
Trained batch 833 in epoch 4, gen_loss = 0.820912472457051, disc_loss = 0.08411053132670049
Trained batch 834 in epoch 4, gen_loss = 0.8215171066943757, disc_loss = 0.0840596665483258
Trained batch 835 in epoch 4, gen_loss = 0.8214497851056345, disc_loss = 0.08406705530104117
Trained batch 836 in epoch 4, gen_loss = 0.8214330479876543, disc_loss = 0.08405796906286617
Trained batch 837 in epoch 4, gen_loss = 0.821476040670297, disc_loss = 0.08404232527413862
Trained batch 838 in epoch 4, gen_loss = 0.8214039361732651, disc_loss = 0.08407536321802507
Trained batch 839 in epoch 4, gen_loss = 0.8211307868716262, disc_loss = 0.08409215195514705
Trained batch 840 in epoch 4, gen_loss = 0.8209252372720721, disc_loss = 0.08411741568169841
Trained batch 841 in epoch 4, gen_loss = 0.8211617538807228, disc_loss = 0.08420514383999246
Trained batch 842 in epoch 4, gen_loss = 0.8211785944826097, disc_loss = 0.08418646316548914
Trained batch 843 in epoch 4, gen_loss = 0.8208819291249836, disc_loss = 0.08433667940729832
Trained batch 844 in epoch 4, gen_loss = 0.8207674447954054, disc_loss = 0.08433327011422381
Trained batch 845 in epoch 4, gen_loss = 0.8207143283411684, disc_loss = 0.08433875106506261
Trained batch 846 in epoch 4, gen_loss = 0.821181330834257, disc_loss = 0.08466753964900636
Trained batch 847 in epoch 4, gen_loss = 0.8209830023137465, disc_loss = 0.08464438307048525
Trained batch 848 in epoch 4, gen_loss = 0.8207129197561558, disc_loss = 0.08471541463488491
Trained batch 849 in epoch 4, gen_loss = 0.8205035435101565, disc_loss = 0.08469996007542838
Trained batch 850 in epoch 4, gen_loss = 0.8203075355494485, disc_loss = 0.08479878788411215
Trained batch 851 in epoch 4, gen_loss = 0.8209221294858087, disc_loss = 0.08502503392284412
Trained batch 852 in epoch 4, gen_loss = 0.8207319122755513, disc_loss = 0.08508087214735388
Trained batch 853 in epoch 4, gen_loss = 0.8202419172126181, disc_loss = 0.08569000264034286
Trained batch 854 in epoch 4, gen_loss = 0.8204554727900097, disc_loss = 0.08571456427255657
Trained batch 855 in epoch 4, gen_loss = 0.8205059794622047, disc_loss = 0.08578127494275517
Trained batch 856 in epoch 4, gen_loss = 0.8202522405387362, disc_loss = 0.085842427258057
Trained batch 857 in epoch 4, gen_loss = 0.8199150407369876, disc_loss = 0.08588012587984628
Trained batch 858 in epoch 4, gen_loss = 0.8203286338463096, disc_loss = 0.08600941130878433
Trained batch 859 in epoch 4, gen_loss = 0.8201650244552036, disc_loss = 0.08606955976127972
Trained batch 860 in epoch 4, gen_loss = 0.8199038043116305, disc_loss = 0.08618559390274022
Trained batch 861 in epoch 4, gen_loss = 0.8196380434346033, disc_loss = 0.08622357971467112
Trained batch 862 in epoch 4, gen_loss = 0.8199630010169461, disc_loss = 0.08636846373112374
Trained batch 863 in epoch 4, gen_loss = 0.8199924325777425, disc_loss = 0.08635660421795263
Trained batch 864 in epoch 4, gen_loss = 0.8200796156260319, disc_loss = 0.08634398984911211
Trained batch 865 in epoch 4, gen_loss = 0.8197666620685101, disc_loss = 0.08641969172152805
Trained batch 866 in epoch 4, gen_loss = 0.8195141705812192, disc_loss = 0.08644501872268326
Trained batch 867 in epoch 4, gen_loss = 0.8198173431344845, disc_loss = 0.08648306571326995
Trained batch 868 in epoch 4, gen_loss = 0.819509380911793, disc_loss = 0.08645621403007928
Trained batch 869 in epoch 4, gen_loss = 0.8194986812684728, disc_loss = 0.08637102252760924
Trained batch 870 in epoch 4, gen_loss = 0.819344022722934, disc_loss = 0.08633975889138133
Trained batch 871 in epoch 4, gen_loss = 0.8192848161956586, disc_loss = 0.08638528887440937
Trained batch 872 in epoch 4, gen_loss = 0.819155902455626, disc_loss = 0.08637053519540722
Trained batch 873 in epoch 4, gen_loss = 0.8190848918746756, disc_loss = 0.086329120827745
Trained batch 874 in epoch 4, gen_loss = 0.8192088643482753, disc_loss = 0.0862468999022884
Trained batch 875 in epoch 4, gen_loss = 0.8193830959328777, disc_loss = 0.08619118230917053
Trained batch 876 in epoch 4, gen_loss = 0.8195237781737794, disc_loss = 0.08615492551429292
Trained batch 877 in epoch 4, gen_loss = 0.8193315110744268, disc_loss = 0.08615898785121942
Trained batch 878 in epoch 4, gen_loss = 0.8193855318871239, disc_loss = 0.08611831632183188
Trained batch 879 in epoch 4, gen_loss = 0.8192824513397433, disc_loss = 0.0861189435357863
Trained batch 880 in epoch 4, gen_loss = 0.8195182211553333, disc_loss = 0.08604227628814697
Trained batch 881 in epoch 4, gen_loss = 0.8191967797792958, disc_loss = 0.08615851174150921
Trained batch 882 in epoch 4, gen_loss = 0.8189642623083778, disc_loss = 0.08613334399503514
Trained batch 883 in epoch 4, gen_loss = 0.8190558696359531, disc_loss = 0.08611624587561126
Trained batch 884 in epoch 4, gen_loss = 0.8189001189786835, disc_loss = 0.08607789856344883
Trained batch 885 in epoch 4, gen_loss = 0.8189030417470308, disc_loss = 0.08601499544130743
Trained batch 886 in epoch 4, gen_loss = 0.8193066440010286, disc_loss = 0.08620883884084786
Trained batch 887 in epoch 4, gen_loss = 0.8191492191037616, disc_loss = 0.08618687787292492
Trained batch 888 in epoch 4, gen_loss = 0.8189873310524648, disc_loss = 0.08623561255698782
Trained batch 889 in epoch 4, gen_loss = 0.8189359384976076, disc_loss = 0.08620253346515087
Trained batch 890 in epoch 4, gen_loss = 0.8194669180044822, disc_loss = 0.08631460004623072
Trained batch 891 in epoch 4, gen_loss = 0.8191296713501883, disc_loss = 0.08635881296494734
Trained batch 892 in epoch 4, gen_loss = 0.8190717643746337, disc_loss = 0.08636538529756072
Trained batch 893 in epoch 4, gen_loss = 0.8185570849734931, disc_loss = 0.08662964684224085
Trained batch 894 in epoch 4, gen_loss = 0.8186731040477753, disc_loss = 0.08664749500045148
Trained batch 895 in epoch 4, gen_loss = 0.8189463676951293, disc_loss = 0.08691967926227205
Trained batch 896 in epoch 4, gen_loss = 0.8188870364806325, disc_loss = 0.0868897342669218
Trained batch 897 in epoch 4, gen_loss = 0.8187398015457166, disc_loss = 0.08690859959564505
Trained batch 898 in epoch 4, gen_loss = 0.8187319038640936, disc_loss = 0.08691390985581564
Trained batch 899 in epoch 4, gen_loss = 0.818713564839628, disc_loss = 0.0868316489390822
Trained batch 900 in epoch 4, gen_loss = 0.8185736317679567, disc_loss = 0.08679103592232895
Trained batch 901 in epoch 4, gen_loss = 0.8184258361283004, disc_loss = 0.08673425409230434
Trained batch 902 in epoch 4, gen_loss = 0.818247758833937, disc_loss = 0.08680530528332688
Trained batch 903 in epoch 4, gen_loss = 0.8180887555720004, disc_loss = 0.08679945203753815
Trained batch 904 in epoch 4, gen_loss = 0.818213032194264, disc_loss = 0.08676051348190528
Trained batch 905 in epoch 4, gen_loss = 0.8180071633580505, disc_loss = 0.08672123588775808
Trained batch 906 in epoch 4, gen_loss = 0.8181742691612559, disc_loss = 0.08664384667013075
Trained batch 907 in epoch 4, gen_loss = 0.8182368492830693, disc_loss = 0.08661664742925143
Trained batch 908 in epoch 4, gen_loss = 0.8183740586271905, disc_loss = 0.08659350989607743
Trained batch 909 in epoch 4, gen_loss = 0.8182127290047132, disc_loss = 0.0866582503967028
Trained batch 910 in epoch 4, gen_loss = 0.8183634386169923, disc_loss = 0.08661616592730358
Trained batch 911 in epoch 4, gen_loss = 0.8192209065810108, disc_loss = 0.08679577987590037
Trained batch 912 in epoch 4, gen_loss = 0.8192533886902695, disc_loss = 0.08671615523850262
Trained batch 913 in epoch 4, gen_loss = 0.819085692322489, disc_loss = 0.08666616201928574
Trained batch 914 in epoch 4, gen_loss = 0.8189645904335168, disc_loss = 0.08663565232851059
Trained batch 915 in epoch 4, gen_loss = 0.819058494504102, disc_loss = 0.0866317499371034
Trained batch 916 in epoch 4, gen_loss = 0.819165881905977, disc_loss = 0.0865625981155137
Trained batch 917 in epoch 4, gen_loss = 0.8192847657112774, disc_loss = 0.08648829561585158
Trained batch 918 in epoch 4, gen_loss = 0.8195248993034591, disc_loss = 0.08646516639068398
Trained batch 919 in epoch 4, gen_loss = 0.8195285881667034, disc_loss = 0.08647114177102871
Trained batch 920 in epoch 4, gen_loss = 0.8194596134813807, disc_loss = 0.08640327940600945
Trained batch 921 in epoch 4, gen_loss = 0.8198500975416954, disc_loss = 0.08646666178724238
Trained batch 922 in epoch 4, gen_loss = 0.8198482418434849, disc_loss = 0.08645359083015233
Trained batch 923 in epoch 4, gen_loss = 0.8199872703843819, disc_loss = 0.08637266812969031
Trained batch 924 in epoch 4, gen_loss = 0.8202983370664957, disc_loss = 0.08630014718031964
Trained batch 925 in epoch 4, gen_loss = 0.820359254662213, disc_loss = 0.08624554621850263
Trained batch 926 in epoch 4, gen_loss = 0.820265598956821, disc_loss = 0.0861808761010929
Trained batch 927 in epoch 4, gen_loss = 0.820514843413799, disc_loss = 0.08611698517955213
Trained batch 928 in epoch 4, gen_loss = 0.8206796264045333, disc_loss = 0.08604014694211509
Trained batch 929 in epoch 4, gen_loss = 0.8207655642942716, disc_loss = 0.08596128845457188
Trained batch 930 in epoch 4, gen_loss = 0.8206421258818322, disc_loss = 0.08596374690742757
Trained batch 931 in epoch 4, gen_loss = 0.8207389837362735, disc_loss = 0.08588217103867811
Trained batch 932 in epoch 4, gen_loss = 0.8210620444112269, disc_loss = 0.08588719196439923
Trained batch 933 in epoch 4, gen_loss = 0.8212527165257191, disc_loss = 0.0858361819929521
Trained batch 934 in epoch 4, gen_loss = 0.8213254452707933, disc_loss = 0.08581589031416703
Trained batch 935 in epoch 4, gen_loss = 0.8211676419481763, disc_loss = 0.08580689038832584
Trained batch 936 in epoch 4, gen_loss = 0.821702769465482, disc_loss = 0.0858728938980531
Trained batch 937 in epoch 4, gen_loss = 0.8218081683428811, disc_loss = 0.08591695376651994
Trained batch 938 in epoch 4, gen_loss = 0.8216042737927808, disc_loss = 0.08599787562266309
Trained batch 939 in epoch 4, gen_loss = 0.8214025757097183, disc_loss = 0.08599856449637878
Trained batch 940 in epoch 4, gen_loss = 0.8216676320267028, disc_loss = 0.08596316620254223
Trained batch 941 in epoch 4, gen_loss = 0.8219846107081497, disc_loss = 0.08594623131078377
Trained batch 942 in epoch 4, gen_loss = 0.8220457708026546, disc_loss = 0.08589768915931958
Trained batch 943 in epoch 4, gen_loss = 0.8218589465181201, disc_loss = 0.08592092586529315
Trained batch 944 in epoch 4, gen_loss = 0.8218511415221704, disc_loss = 0.08585226448824403
Trained batch 945 in epoch 4, gen_loss = 0.8217462060252405, disc_loss = 0.08581632639312956
Trained batch 946 in epoch 4, gen_loss = 0.8221392165456427, disc_loss = 0.08584687630414821
Trained batch 947 in epoch 4, gen_loss = 0.822551243635924, disc_loss = 0.08579556337991957
Trained batch 948 in epoch 4, gen_loss = 0.8225242539816335, disc_loss = 0.08577886305197885
Trained batch 949 in epoch 4, gen_loss = 0.8224401159976658, disc_loss = 0.08578084013718916
Trained batch 950 in epoch 4, gen_loss = 0.8221433557859856, disc_loss = 0.08577788571585225
Trained batch 951 in epoch 4, gen_loss = 0.8222056112306959, disc_loss = 0.08572939449692332
Trained batch 952 in epoch 4, gen_loss = 0.8221908694236751, disc_loss = 0.08566263109467072
Trained batch 953 in epoch 4, gen_loss = 0.8224144993150759, disc_loss = 0.08573581532290131
Trained batch 954 in epoch 4, gen_loss = 0.8223009159739729, disc_loss = 0.08567060540669173
Trained batch 955 in epoch 4, gen_loss = 0.8221805435157221, disc_loss = 0.08563169355311326
Trained batch 956 in epoch 4, gen_loss = 0.8220402480977954, disc_loss = 0.08557862775155042
Trained batch 957 in epoch 4, gen_loss = 0.8217733579849151, disc_loss = 0.08557484256898856
Trained batch 958 in epoch 4, gen_loss = 0.8220879499867512, disc_loss = 0.08576683888048695
Trained batch 959 in epoch 4, gen_loss = 0.8221423067462941, disc_loss = 0.08573913006839576
Trained batch 960 in epoch 4, gen_loss = 0.8220020919945188, disc_loss = 0.08572290207401817
Trained batch 961 in epoch 4, gen_loss = 0.8217829376954794, disc_loss = 0.08569175430104957
Trained batch 962 in epoch 4, gen_loss = 0.8219323134434681, disc_loss = 0.08562123829398308
Trained batch 963 in epoch 4, gen_loss = 0.822112743507035, disc_loss = 0.08554244966340865
Trained batch 964 in epoch 4, gen_loss = 0.8220063718798247, disc_loss = 0.08548726989728413
Trained batch 965 in epoch 4, gen_loss = 0.8221088405042949, disc_loss = 0.08541185594082851
Trained batch 966 in epoch 4, gen_loss = 0.8221449336998219, disc_loss = 0.08552115302072547
Trained batch 967 in epoch 4, gen_loss = 0.8219065979923591, disc_loss = 0.08554367145498414
Trained batch 968 in epoch 4, gen_loss = 0.8217163300305083, disc_loss = 0.08562608510861318
Trained batch 969 in epoch 4, gen_loss = 0.8216165018143113, disc_loss = 0.0856032143025323
Trained batch 970 in epoch 4, gen_loss = 0.8217511417384497, disc_loss = 0.08558274354511368
Trained batch 971 in epoch 4, gen_loss = 0.8215406666751262, disc_loss = 0.08562182887397905
Trained batch 972 in epoch 4, gen_loss = 0.822007425489308, disc_loss = 0.08567252710130437
Trained batch 973 in epoch 4, gen_loss = 0.8217735378343222, disc_loss = 0.0857847004730132
Trained batch 974 in epoch 4, gen_loss = 0.8219870911806058, disc_loss = 0.08591698204238828
Trained batch 975 in epoch 4, gen_loss = 0.8217101669641304, disc_loss = 0.08599006722931231
Trained batch 976 in epoch 4, gen_loss = 0.8215617438360759, disc_loss = 0.08605468004108802
Trained batch 977 in epoch 4, gen_loss = 0.8212726778352675, disc_loss = 0.08609496307814521
Trained batch 978 in epoch 4, gen_loss = 0.8214447256919678, disc_loss = 0.08635133986748504
Trained batch 979 in epoch 4, gen_loss = 0.8213233094130243, disc_loss = 0.08630211205193203
Trained batch 980 in epoch 4, gen_loss = 0.8215299243530853, disc_loss = 0.08629591318861288
Trained batch 981 in epoch 4, gen_loss = 0.8211303149063572, disc_loss = 0.08646708327182426
Trained batch 982 in epoch 4, gen_loss = 0.8211780235641243, disc_loss = 0.08640456331101751
Trained batch 983 in epoch 4, gen_loss = 0.8215914323501955, disc_loss = 0.08633577770778789
Trained batch 984 in epoch 4, gen_loss = 0.8215745425163792, disc_loss = 0.08637866511099457
Trained batch 985 in epoch 4, gen_loss = 0.8213416735431969, disc_loss = 0.08641645823261544
Trained batch 986 in epoch 4, gen_loss = 0.8215842688760013, disc_loss = 0.08641066110203195
Trained batch 987 in epoch 4, gen_loss = 0.8213861762934368, disc_loss = 0.0863856454337438
Trained batch 988 in epoch 4, gen_loss = 0.8213699811088303, disc_loss = 0.08632770127355976
Trained batch 989 in epoch 4, gen_loss = 0.821111734858667, disc_loss = 0.0863396558285023
Trained batch 990 in epoch 4, gen_loss = 0.8211626670014125, disc_loss = 0.08629266035580475
Trained batch 991 in epoch 4, gen_loss = 0.8210031304568532, disc_loss = 0.08632890154342843
Trained batch 992 in epoch 4, gen_loss = 0.8207797213923655, disc_loss = 0.0864035614854342
Trained batch 993 in epoch 4, gen_loss = 0.8204851887775378, disc_loss = 0.086383698809371
Trained batch 994 in epoch 4, gen_loss = 0.8202988249872198, disc_loss = 0.0864385435755491
Trained batch 995 in epoch 4, gen_loss = 0.8209431058012817, disc_loss = 0.08651526695459587
Trained batch 996 in epoch 4, gen_loss = 0.8212592787405433, disc_loss = 0.08648084270849137
Trained batch 997 in epoch 4, gen_loss = 0.8210616792908652, disc_loss = 0.0864753205275988
Trained batch 998 in epoch 4, gen_loss = 0.8208999351278559, disc_loss = 0.08653290979368417
Trained batch 999 in epoch 4, gen_loss = 0.8211603809893131, disc_loss = 0.08650815031072125
Trained batch 1000 in epoch 4, gen_loss = 0.8211877012288534, disc_loss = 0.08648892463167215
Trained batch 1001 in epoch 4, gen_loss = 0.821201238416864, disc_loss = 0.08644626161107745
Trained batch 1002 in epoch 4, gen_loss = 0.8210120802208528, disc_loss = 0.08641395107392641
Trained batch 1003 in epoch 4, gen_loss = 0.8209433319618502, disc_loss = 0.08636302677348656
Trained batch 1004 in epoch 4, gen_loss = 0.8210495353634678, disc_loss = 0.08634138887711054
Trained batch 1005 in epoch 4, gen_loss = 0.8211740967826863, disc_loss = 0.0862670478019419
Trained batch 1006 in epoch 4, gen_loss = 0.8212305474009035, disc_loss = 0.08622161167060592
Trained batch 1007 in epoch 4, gen_loss = 0.8209847074356817, disc_loss = 0.0862433284143215
Trained batch 1008 in epoch 4, gen_loss = 0.8210067924765576, disc_loss = 0.08621523694464765
Trained batch 1009 in epoch 4, gen_loss = 0.8211196732698101, disc_loss = 0.08621569746266128
Trained batch 1010 in epoch 4, gen_loss = 0.8211044433621577, disc_loss = 0.08616195131750994
Trained batch 1011 in epoch 4, gen_loss = 0.8209978569696543, disc_loss = 0.08610511233564466
Trained batch 1012 in epoch 4, gen_loss = 0.8208779825333429, disc_loss = 0.08603253272230584
Trained batch 1013 in epoch 4, gen_loss = 0.8207164757409274, disc_loss = 0.08601748610523399
Trained batch 1014 in epoch 4, gen_loss = 0.8207930408968714, disc_loss = 0.08594849590129526
Trained batch 1015 in epoch 4, gen_loss = 0.8209237825624117, disc_loss = 0.08591262138985815
Trained batch 1016 in epoch 4, gen_loss = 0.8208296820301574, disc_loss = 0.08589014313582079
Trained batch 1017 in epoch 4, gen_loss = 0.8206968058361754, disc_loss = 0.08583859053864885
Trained batch 1018 in epoch 4, gen_loss = 0.8211481149168548, disc_loss = 0.08578245056668796
Trained batch 1019 in epoch 4, gen_loss = 0.8214904428989279, disc_loss = 0.08585319229830787
Trained batch 1020 in epoch 4, gen_loss = 0.8214090702641139, disc_loss = 0.08581244831003548
Trained batch 1021 in epoch 4, gen_loss = 0.8211265537311886, disc_loss = 0.085831770159891
Trained batch 1022 in epoch 4, gen_loss = 0.8209911187198504, disc_loss = 0.08582388028504286
Trained batch 1023 in epoch 4, gen_loss = 0.8211100225744303, disc_loss = 0.08576513900743521
Trained batch 1024 in epoch 4, gen_loss = 0.8214822387404558, disc_loss = 0.08593749425442117
Trained batch 1025 in epoch 4, gen_loss = 0.8215045690478405, disc_loss = 0.08592386401102281
Trained batch 1026 in epoch 4, gen_loss = 0.8212340148247438, disc_loss = 0.08600207544843273
Trained batch 1027 in epoch 4, gen_loss = 0.8208672256437257, disc_loss = 0.08606427871388408
Trained batch 1028 in epoch 4, gen_loss = 0.8210843460321194, disc_loss = 0.08601040327631886
Trained batch 1029 in epoch 4, gen_loss = 0.8213931468505303, disc_loss = 0.08605584058485635
Trained batch 1030 in epoch 4, gen_loss = 0.8213032493882684, disc_loss = 0.08608004553821642
Trained batch 1031 in epoch 4, gen_loss = 0.8211679452264956, disc_loss = 0.08611489149115532
Trained batch 1032 in epoch 4, gen_loss = 0.8211759603496673, disc_loss = 0.08612076971014566
Trained batch 1033 in epoch 4, gen_loss = 0.8215417784694546, disc_loss = 0.08616462725708243
Trained batch 1034 in epoch 4, gen_loss = 0.8214823903668905, disc_loss = 0.08614186851559702
Trained batch 1035 in epoch 4, gen_loss = 0.8213556614276525, disc_loss = 0.08608816001558871
Trained batch 1036 in epoch 4, gen_loss = 0.8212461485927107, disc_loss = 0.08620262862898934
Trained batch 1037 in epoch 4, gen_loss = 0.8212603598775662, disc_loss = 0.08618874608015063
Trained batch 1038 in epoch 4, gen_loss = 0.8211773894978213, disc_loss = 0.08619304208436315
Trained batch 1039 in epoch 4, gen_loss = 0.821399762137578, disc_loss = 0.0861909500166523
Trained batch 1040 in epoch 4, gen_loss = 0.8214390040245569, disc_loss = 0.08616672063203426
Trained batch 1041 in epoch 4, gen_loss = 0.8216537894420112, disc_loss = 0.08619957836836419
Trained batch 1042 in epoch 4, gen_loss = 0.8215895284285138, disc_loss = 0.08617230442112396
Trained batch 1043 in epoch 4, gen_loss = 0.8217093615125423, disc_loss = 0.08611397511616592
Trained batch 1044 in epoch 4, gen_loss = 0.8215474903868716, disc_loss = 0.08617396831699607
Trained batch 1045 in epoch 4, gen_loss = 0.821409155887126, disc_loss = 0.08617265514689311
Trained batch 1046 in epoch 4, gen_loss = 0.8214267037431741, disc_loss = 0.08610601356224563
Trained batch 1047 in epoch 4, gen_loss = 0.8213252414956348, disc_loss = 0.08613406219350828
Trained batch 1048 in epoch 4, gen_loss = 0.821611188160339, disc_loss = 0.08613801392654687
Trained batch 1049 in epoch 4, gen_loss = 0.8217170522326515, disc_loss = 0.08626540431885847
Trained batch 1050 in epoch 4, gen_loss = 0.8214102515030997, disc_loss = 0.08630003146587965
Trained batch 1051 in epoch 4, gen_loss = 0.8211385910275318, disc_loss = 0.08639529131630881
Trained batch 1052 in epoch 4, gen_loss = 0.8211852407749788, disc_loss = 0.0863671205669875
Trained batch 1053 in epoch 4, gen_loss = 0.8211424070811588, disc_loss = 0.0863825810823123
Trained batch 1054 in epoch 4, gen_loss = 0.8216093349795771, disc_loss = 0.08642522613098624
Trained batch 1055 in epoch 4, gen_loss = 0.8217602525132172, disc_loss = 0.0863578202353727
Trained batch 1056 in epoch 4, gen_loss = 0.8216495968986482, disc_loss = 0.08640152124984078
Trained batch 1057 in epoch 4, gen_loss = 0.8215333421649464, disc_loss = 0.08639888609020085
Trained batch 1058 in epoch 4, gen_loss = 0.8216507599193944, disc_loss = 0.08633203522413899
Trained batch 1059 in epoch 4, gen_loss = 0.8216077561648387, disc_loss = 0.08629239136572786
Trained batch 1060 in epoch 4, gen_loss = 0.8216719561090569, disc_loss = 0.08623732118072948
Trained batch 1061 in epoch 4, gen_loss = 0.8218033613458191, disc_loss = 0.08617314106167387
Trained batch 1062 in epoch 4, gen_loss = 0.8220978748764727, disc_loss = 0.08613591739182427
Trained batch 1063 in epoch 4, gen_loss = 0.8220763133096516, disc_loss = 0.08606784387283321
Trained batch 1064 in epoch 4, gen_loss = 0.8219711659100134, disc_loss = 0.08604252540808119
Trained batch 1065 in epoch 4, gen_loss = 0.821831038868226, disc_loss = 0.08604117716561241
Trained batch 1066 in epoch 4, gen_loss = 0.8218077444091733, disc_loss = 0.08599830230509456
Trained batch 1067 in epoch 4, gen_loss = 0.8222317416011617, disc_loss = 0.08602675733684949
Trained batch 1068 in epoch 4, gen_loss = 0.8222414244548308, disc_loss = 0.08599883897345029
Trained batch 1069 in epoch 4, gen_loss = 0.8220038555492865, disc_loss = 0.08599392404979983
Trained batch 1070 in epoch 4, gen_loss = 0.8219506637054999, disc_loss = 0.08597237485513981
Trained batch 1071 in epoch 4, gen_loss = 0.821882040754183, disc_loss = 0.08598337370646882
Trained batch 1072 in epoch 4, gen_loss = 0.8218362221402313, disc_loss = 0.08595900626623966
Trained batch 1073 in epoch 4, gen_loss = 0.8218115590360133, disc_loss = 0.08598531898695566
Trained batch 1074 in epoch 4, gen_loss = 0.8216992054429165, disc_loss = 0.0859738653365436
Trained batch 1075 in epoch 4, gen_loss = 0.8216316562602954, disc_loss = 0.08593760356938875
Trained batch 1076 in epoch 4, gen_loss = 0.8218069639932035, disc_loss = 0.08588763463597125
Trained batch 1077 in epoch 4, gen_loss = 0.8216930194334551, disc_loss = 0.08599344203689227
Trained batch 1078 in epoch 4, gen_loss = 0.8216727744439225, disc_loss = 0.08594222010033027
Trained batch 1079 in epoch 4, gen_loss = 0.8213715361500228, disc_loss = 0.0859722508139115
Trained batch 1080 in epoch 4, gen_loss = 0.821240288835229, disc_loss = 0.08596529260451778
Trained batch 1081 in epoch 4, gen_loss = 0.8213465101672629, disc_loss = 0.08595069030483982
Trained batch 1082 in epoch 4, gen_loss = 0.8215221929693266, disc_loss = 0.08592578773072895
Trained batch 1083 in epoch 4, gen_loss = 0.8216995919377601, disc_loss = 0.08586566598537787
Trained batch 1084 in epoch 4, gen_loss = 0.821524761596583, disc_loss = 0.08592484432920676
Trained batch 1085 in epoch 4, gen_loss = 0.8212957561400275, disc_loss = 0.08597255997834848
Trained batch 1086 in epoch 4, gen_loss = 0.8213461015952653, disc_loss = 0.0859939715920981
Trained batch 1087 in epoch 4, gen_loss = 0.8211966258035425, disc_loss = 0.08599322007306481
Trained batch 1088 in epoch 4, gen_loss = 0.8213041628633102, disc_loss = 0.08592595077950176
Trained batch 1089 in epoch 4, gen_loss = 0.8214090766983295, disc_loss = 0.08587815809798419
Trained batch 1090 in epoch 4, gen_loss = 0.8214552721280116, disc_loss = 0.08584268573854259
Trained batch 1091 in epoch 4, gen_loss = 0.8212774865083642, disc_loss = 0.08583686108856152
Trained batch 1092 in epoch 4, gen_loss = 0.8213897512958122, disc_loss = 0.08578050282143895
Trained batch 1093 in epoch 4, gen_loss = 0.8212874308637117, disc_loss = 0.08575264094491068
Trained batch 1094 in epoch 4, gen_loss = 0.8210469472081694, disc_loss = 0.08574108472944462
Trained batch 1095 in epoch 4, gen_loss = 0.8212565112668667, disc_loss = 0.08576576735010288
Trained batch 1096 in epoch 4, gen_loss = 0.8213099934289754, disc_loss = 0.08570221622594197
Trained batch 1097 in epoch 4, gen_loss = 0.8211056843318575, disc_loss = 0.08569009636549146
Trained batch 1098 in epoch 4, gen_loss = 0.8211218937892497, disc_loss = 0.0856421371880373
Trained batch 1099 in epoch 4, gen_loss = 0.821327793516896, disc_loss = 0.08558552522423932
Trained batch 1100 in epoch 4, gen_loss = 0.8214272630691095, disc_loss = 0.08555927105818102
Trained batch 1101 in epoch 4, gen_loss = 0.8214435457588324, disc_loss = 0.08553529103005984
Trained batch 1102 in epoch 4, gen_loss = 0.8213150343188133, disc_loss = 0.08555332664695862
Trained batch 1103 in epoch 4, gen_loss = 0.8211609263620947, disc_loss = 0.08562901754656037
Trained batch 1104 in epoch 4, gen_loss = 0.8213722043717069, disc_loss = 0.08568885858587887
Trained batch 1105 in epoch 4, gen_loss = 0.8213422908759247, disc_loss = 0.08562623188918486
Trained batch 1106 in epoch 4, gen_loss = 0.8213003555341357, disc_loss = 0.08557444566258422
Trained batch 1107 in epoch 4, gen_loss = 0.821116254137096, disc_loss = 0.08556154207284444
Trained batch 1108 in epoch 4, gen_loss = 0.8214426697697911, disc_loss = 0.08563268470566979
Trained batch 1109 in epoch 4, gen_loss = 0.821587844716536, disc_loss = 0.08557570897218947
Trained batch 1110 in epoch 4, gen_loss = 0.8214816410567286, disc_loss = 0.08556653135083113
Trained batch 1111 in epoch 4, gen_loss = 0.821350154875637, disc_loss = 0.08555007724320891
Trained batch 1112 in epoch 4, gen_loss = 0.8214368078747207, disc_loss = 0.08571311339831376
Trained batch 1113 in epoch 4, gen_loss = 0.821995154397706, disc_loss = 0.08571122655991124
Trained batch 1114 in epoch 4, gen_loss = 0.8218220240599371, disc_loss = 0.08579581010744243
Trained batch 1115 in epoch 4, gen_loss = 0.8217586015341103, disc_loss = 0.08576458780717532
Trained batch 1116 in epoch 4, gen_loss = 0.8220317687375692, disc_loss = 0.08571224482796733
Trained batch 1117 in epoch 4, gen_loss = 0.8221184981583696, disc_loss = 0.0857091852666207
Trained batch 1118 in epoch 4, gen_loss = 0.8222504098091518, disc_loss = 0.08565261354669929
Trained batch 1119 in epoch 4, gen_loss = 0.8222814498469233, disc_loss = 0.08561519225269357
Trained batch 1120 in epoch 4, gen_loss = 0.8219765594609607, disc_loss = 0.08562653407289993
Trained batch 1121 in epoch 4, gen_loss = 0.821612721936588, disc_loss = 0.08572928826474052
Trained batch 1122 in epoch 4, gen_loss = 0.8218868911956319, disc_loss = 0.08570264360991009
Trained batch 1123 in epoch 4, gen_loss = 0.8220534821528133, disc_loss = 0.08566183812818506
Trained batch 1124 in epoch 4, gen_loss = 0.8218814226256477, disc_loss = 0.0856817513294518
Trained batch 1125 in epoch 4, gen_loss = 0.8218635034815245, disc_loss = 0.08572078169220942
Trained batch 1126 in epoch 4, gen_loss = 0.8219722618862074, disc_loss = 0.08572483066586777
Trained batch 1127 in epoch 4, gen_loss = 0.8221714084981181, disc_loss = 0.08567180231928574
Trained batch 1128 in epoch 4, gen_loss = 0.822003073508598, disc_loss = 0.08570610402247632
Trained batch 1129 in epoch 4, gen_loss = 0.821869944523921, disc_loss = 0.08565994458957121
Trained batch 1130 in epoch 4, gen_loss = 0.821907160347484, disc_loss = 0.0856485998642546
Trained batch 1131 in epoch 4, gen_loss = 0.821938908405523, disc_loss = 0.0857227711675873
Trained batch 1132 in epoch 4, gen_loss = 0.8218317960914214, disc_loss = 0.08575318145482667
Trained batch 1133 in epoch 4, gen_loss = 0.8216179842145775, disc_loss = 0.08584223229748507
Trained batch 1134 in epoch 4, gen_loss = 0.8215845314941742, disc_loss = 0.08579544978429633
Trained batch 1135 in epoch 4, gen_loss = 0.8212616955205588, disc_loss = 0.08583944265338803
Trained batch 1136 in epoch 4, gen_loss = 0.8214544358228316, disc_loss = 0.08583788743501458
Trained batch 1137 in epoch 4, gen_loss = 0.821513725447948, disc_loss = 0.08579730652706445
Trained batch 1138 in epoch 4, gen_loss = 0.8214382992385248, disc_loss = 0.08579535057925218
Trained batch 1139 in epoch 4, gen_loss = 0.8213530818621317, disc_loss = 0.08575602618920242
Trained batch 1140 in epoch 4, gen_loss = 0.8214655810025154, disc_loss = 0.08580520159485738
Trained batch 1141 in epoch 4, gen_loss = 0.8216966937072641, disc_loss = 0.08574098449130257
Trained batch 1142 in epoch 4, gen_loss = 0.8216005692018924, disc_loss = 0.08570869280716317
Trained batch 1143 in epoch 4, gen_loss = 0.8214597872920804, disc_loss = 0.08566068754233486
Trained batch 1144 in epoch 4, gen_loss = 0.8214646833952858, disc_loss = 0.08562254854498276
Trained batch 1145 in epoch 4, gen_loss = 0.8215467159556676, disc_loss = 0.08566909999404604
Trained batch 1146 in epoch 4, gen_loss = 0.8213281956255281, disc_loss = 0.08569757141044596
Trained batch 1147 in epoch 4, gen_loss = 0.8214314174465186, disc_loss = 0.08565556809171476
Trained batch 1148 in epoch 4, gen_loss = 0.8215597027068142, disc_loss = 0.0856712512672758
Trained batch 1149 in epoch 4, gen_loss = 0.8215040885365528, disc_loss = 0.08564200726742653
Trained batch 1150 in epoch 4, gen_loss = 0.8215699634999425, disc_loss = 0.08560566419855303
Trained batch 1151 in epoch 4, gen_loss = 0.821635237429291, disc_loss = 0.08556344831797308
Trained batch 1152 in epoch 4, gen_loss = 0.8216163507256421, disc_loss = 0.08551797603118877
Trained batch 1153 in epoch 4, gen_loss = 0.8218726259583617, disc_loss = 0.08570485510637393
Trained batch 1154 in epoch 4, gen_loss = 0.8218142867088318, disc_loss = 0.08571742591347335
Trained batch 1155 in epoch 4, gen_loss = 0.8214429238469543, disc_loss = 0.08579714397962647
Trained batch 1156 in epoch 4, gen_loss = 0.8214275200200061, disc_loss = 0.08584633289474926
Trained batch 1157 in epoch 4, gen_loss = 0.8216704636657793, disc_loss = 0.08588385232161273
Trained batch 1158 in epoch 4, gen_loss = 0.8216877242837928, disc_loss = 0.08585279886719287
Trained batch 1159 in epoch 4, gen_loss = 0.8215625140687515, disc_loss = 0.08593784982924639
Trained batch 1160 in epoch 4, gen_loss = 0.821243265802546, disc_loss = 0.08601711972670359
Trained batch 1161 in epoch 4, gen_loss = 0.8213539756513915, disc_loss = 0.08597649749498269
Trained batch 1162 in epoch 4, gen_loss = 0.8214446834111562, disc_loss = 0.08605708112869723
Trained batch 1163 in epoch 4, gen_loss = 0.8213646234720433, disc_loss = 0.08603492352184984
Trained batch 1164 in epoch 4, gen_loss = 0.8211239302107193, disc_loss = 0.08604019482384231
Trained batch 1165 in epoch 4, gen_loss = 0.8210034072910328, disc_loss = 0.08602653532512614
Trained batch 1166 in epoch 4, gen_loss = 0.8208666821269777, disc_loss = 0.0860192431915063
Trained batch 1167 in epoch 4, gen_loss = 0.8207315950054829, disc_loss = 0.08600847341944719
Trained batch 1168 in epoch 4, gen_loss = 0.8204993735122518, disc_loss = 0.08605665791185431
Trained batch 1169 in epoch 4, gen_loss = 0.8205771966877147, disc_loss = 0.08602846645527225
Trained batch 1170 in epoch 4, gen_loss = 0.8207290331386888, disc_loss = 0.08605761155939441
Trained batch 1171 in epoch 4, gen_loss = 0.8207528167006912, disc_loss = 0.08601098290426853
Trained batch 1172 in epoch 4, gen_loss = 0.8206867060901157, disc_loss = 0.08598099506554613
Trained batch 1173 in epoch 4, gen_loss = 0.8205304952557286, disc_loss = 0.08600260235973693
Trained batch 1174 in epoch 4, gen_loss = 0.8205696049142391, disc_loss = 0.08597963469657809
Trained batch 1175 in epoch 4, gen_loss = 0.8210643201458211, disc_loss = 0.08599149410614465
Trained batch 1176 in epoch 4, gen_loss = 0.8212721337680606, disc_loss = 0.08592978097022073
Trained batch 1177 in epoch 4, gen_loss = 0.82108300762387, disc_loss = 0.0860052857613618
Trained batch 1178 in epoch 4, gen_loss = 0.8210135459697682, disc_loss = 0.0859968482281308
Trained batch 1179 in epoch 4, gen_loss = 0.8211293919611785, disc_loss = 0.08616641466860991
Trained batch 1180 in epoch 4, gen_loss = 0.8210519322089277, disc_loss = 0.08613470276174191
Trained batch 1181 in epoch 4, gen_loss = 0.8210298117949878, disc_loss = 0.08609043020406791
Trained batch 1182 in epoch 4, gen_loss = 0.8210384966655999, disc_loss = 0.08605177788967652
Trained batch 1183 in epoch 4, gen_loss = 0.8209915061456126, disc_loss = 0.08600210519216489
Trained batch 1184 in epoch 4, gen_loss = 0.8210483290978122, disc_loss = 0.08595684281970818
Trained batch 1185 in epoch 4, gen_loss = 0.8209585941461045, disc_loss = 0.0859511753769582
Trained batch 1186 in epoch 4, gen_loss = 0.8208647405990754, disc_loss = 0.08591139566023044
Trained batch 1187 in epoch 4, gen_loss = 0.8208343094647533, disc_loss = 0.08588004136036279
Trained batch 1188 in epoch 4, gen_loss = 0.820908908336678, disc_loss = 0.0859220396500955
Trained batch 1189 in epoch 4, gen_loss = 0.8207837387794206, disc_loss = 0.08591737845450828
Trained batch 1190 in epoch 4, gen_loss = 0.8204531843025679, disc_loss = 0.08600514584770669
Trained batch 1191 in epoch 4, gen_loss = 0.820409954469276, disc_loss = 0.0859920655954598
Trained batch 1192 in epoch 4, gen_loss = 0.820149367008505, disc_loss = 0.08603581792986441
Trained batch 1193 in epoch 4, gen_loss = 0.8204345643969636, disc_loss = 0.08610903930310565
Trained batch 1194 in epoch 4, gen_loss = 0.8202357005624092, disc_loss = 0.08617945539737783
Trained batch 1195 in epoch 4, gen_loss = 0.820366690913371, disc_loss = 0.08612451383362783
Trained batch 1196 in epoch 4, gen_loss = 0.8204735709461652, disc_loss = 0.08610782439881934
Trained batch 1197 in epoch 4, gen_loss = 0.8203073483028873, disc_loss = 0.08618904984142563
Trained batch 1198 in epoch 4, gen_loss = 0.820060859206719, disc_loss = 0.08622062616974575
Trained batch 1199 in epoch 4, gen_loss = 0.8200547697395086, disc_loss = 0.08621375658200123
Trained batch 1200 in epoch 4, gen_loss = 0.8203381549359162, disc_loss = 0.08615444811312273
Trained batch 1201 in epoch 4, gen_loss = 0.820350509440641, disc_loss = 0.08610032911462005
Trained batch 1202 in epoch 4, gen_loss = 0.8204743747451557, disc_loss = 0.08605156703685671
Trained batch 1203 in epoch 4, gen_loss = 0.8205758156223947, disc_loss = 0.08604999273153721
Trained batch 1204 in epoch 4, gen_loss = 0.8203586153222318, disc_loss = 0.08611786231143531
Trained batch 1205 in epoch 4, gen_loss = 0.8204601330691902, disc_loss = 0.08606501273111213
Trained batch 1206 in epoch 4, gen_loss = 0.820357592098952, disc_loss = 0.08606187589181079
Trained batch 1207 in epoch 4, gen_loss = 0.820265233047948, disc_loss = 0.08605964225061571
Trained batch 1208 in epoch 4, gen_loss = 0.8203807532590119, disc_loss = 0.08609246686093257
Trained batch 1209 in epoch 4, gen_loss = 0.8201228803100665, disc_loss = 0.08615309414838648
Trained batch 1210 in epoch 4, gen_loss = 0.8200563592767046, disc_loss = 0.0861267266632769
Trained batch 1211 in epoch 4, gen_loss = 0.819928593392616, disc_loss = 0.08616909131879547
Trained batch 1212 in epoch 4, gen_loss = 0.8199093557789812, disc_loss = 0.08626519764373532
Trained batch 1213 in epoch 4, gen_loss = 0.8196315882233458, disc_loss = 0.08633791558755964
Trained batch 1214 in epoch 4, gen_loss = 0.8195806988963374, disc_loss = 0.08634479425257309
Trained batch 1215 in epoch 4, gen_loss = 0.8196781132076132, disc_loss = 0.08631671570956793
Trained batch 1216 in epoch 4, gen_loss = 0.8193246170253957, disc_loss = 0.08638443489082237
Trained batch 1217 in epoch 4, gen_loss = 0.819304576550407, disc_loss = 0.08635711475514023
Trained batch 1218 in epoch 4, gen_loss = 0.8191325565749646, disc_loss = 0.08642819396795444
Trained batch 1219 in epoch 4, gen_loss = 0.8193598391579799, disc_loss = 0.08639783882574163
Trained batch 1220 in epoch 4, gen_loss = 0.819462750701998, disc_loss = 0.08637169596718519
Trained batch 1221 in epoch 4, gen_loss = 0.8192762789086312, disc_loss = 0.08646877343025601
Trained batch 1222 in epoch 4, gen_loss = 0.8192955212620371, disc_loss = 0.08644292748000897
Trained batch 1223 in epoch 4, gen_loss = 0.8192915291665426, disc_loss = 0.08642879734842983
Trained batch 1224 in epoch 4, gen_loss = 0.8191429133804476, disc_loss = 0.08639105477617408
Trained batch 1225 in epoch 4, gen_loss = 0.8191149967432411, disc_loss = 0.08643887407863497
Trained batch 1226 in epoch 4, gen_loss = 0.819101570676572, disc_loss = 0.08640999288185094
Trained batch 1227 in epoch 4, gen_loss = 0.8190213479223003, disc_loss = 0.08637902339433505
Trained batch 1228 in epoch 4, gen_loss = 0.8190367376057475, disc_loss = 0.08632742442104259
Trained batch 1229 in epoch 4, gen_loss = 0.8194493273409401, disc_loss = 0.08632759046135091
Trained batch 1230 in epoch 4, gen_loss = 0.8192064588772969, disc_loss = 0.08636740300460899
Trained batch 1231 in epoch 4, gen_loss = 0.8192654238505797, disc_loss = 0.08636087546988341
Trained batch 1232 in epoch 4, gen_loss = 0.819157998540589, disc_loss = 0.08634160467614597
Trained batch 1233 in epoch 4, gen_loss = 0.8192156576936404, disc_loss = 0.08633554538574546
Trained batch 1234 in epoch 4, gen_loss = 0.8194490072215617, disc_loss = 0.08628315394367224
Trained batch 1235 in epoch 4, gen_loss = 0.819322647882511, disc_loss = 0.08624527032500658
Trained batch 1236 in epoch 4, gen_loss = 0.8195881649863845, disc_loss = 0.08619885833665922
Trained batch 1237 in epoch 4, gen_loss = 0.8195999113538924, disc_loss = 0.08614208247709676
Trained batch 1238 in epoch 4, gen_loss = 0.8196073856153634, disc_loss = 0.08619534161695015
Trained batch 1239 in epoch 4, gen_loss = 0.8196590305816742, disc_loss = 0.08622527499195008
Trained batch 1240 in epoch 4, gen_loss = 0.8195147338074893, disc_loss = 0.08625266374344731
Trained batch 1241 in epoch 4, gen_loss = 0.8194809829555272, disc_loss = 0.0862164200488298
Trained batch 1242 in epoch 4, gen_loss = 0.8194504319806303, disc_loss = 0.08617488952347603
Trained batch 1243 in epoch 4, gen_loss = 0.8195855556672792, disc_loss = 0.0862489950710644
Trained batch 1244 in epoch 4, gen_loss = 0.8195708229359853, disc_loss = 0.08621052665426489
Trained batch 1245 in epoch 4, gen_loss = 0.8194161734362858, disc_loss = 0.08617785651002073
Trained batch 1246 in epoch 4, gen_loss = 0.8194324307759093, disc_loss = 0.08613482016043883
Trained batch 1247 in epoch 4, gen_loss = 0.819439652399757, disc_loss = 0.08613825031781557
Trained batch 1248 in epoch 4, gen_loss = 0.819149092209635, disc_loss = 0.08610853368753464
Trained batch 1249 in epoch 4, gen_loss = 0.8192873549938202, disc_loss = 0.0860516836475581
Trained batch 1250 in epoch 4, gen_loss = 0.8194737216646818, disc_loss = 0.08599200044132525
Trained batch 1251 in epoch 4, gen_loss = 0.819627754366436, disc_loss = 0.08594081420324945
Trained batch 1252 in epoch 4, gen_loss = 0.819587462679063, disc_loss = 0.08591496281835703
Trained batch 1253 in epoch 4, gen_loss = 0.8196667319184475, disc_loss = 0.085866494898564
Trained batch 1254 in epoch 4, gen_loss = 0.8195729117469484, disc_loss = 0.0858632258696118
Trained batch 1255 in epoch 4, gen_loss = 0.8196490115136098, disc_loss = 0.08587594169071894
Trained batch 1256 in epoch 4, gen_loss = 0.8194013584580039, disc_loss = 0.08588611001560766
Trained batch 1257 in epoch 4, gen_loss = 0.8195873137877363, disc_loss = 0.08582919037202003
Trained batch 1258 in epoch 4, gen_loss = 0.8199403783080121, disc_loss = 0.08617583465909644
Trained batch 1259 in epoch 4, gen_loss = 0.8196977861816921, disc_loss = 0.08625684982010474
Trained batch 1260 in epoch 4, gen_loss = 0.8195268062255763, disc_loss = 0.08631508441828044
Trained batch 1261 in epoch 4, gen_loss = 0.8194805768136932, disc_loss = 0.08630430357856897
Trained batch 1262 in epoch 4, gen_loss = 0.8195057218733611, disc_loss = 0.08639431862906802
Trained batch 1263 in epoch 4, gen_loss = 0.819351557359288, disc_loss = 0.08642731278750138
Trained batch 1264 in epoch 4, gen_loss = 0.8193111952585665, disc_loss = 0.08643487671375451
Trained batch 1265 in epoch 4, gen_loss = 0.8192703804416114, disc_loss = 0.0864091359625466
Trained batch 1266 in epoch 4, gen_loss = 0.8194519923536817, disc_loss = 0.08638484699095893
Trained batch 1267 in epoch 4, gen_loss = 0.8195486663831897, disc_loss = 0.0863403166634727
Trained batch 1268 in epoch 4, gen_loss = 0.8193590717582462, disc_loss = 0.08639826500638614
Trained batch 1269 in epoch 4, gen_loss = 0.8195316822979394, disc_loss = 0.0863697205835176
Trained batch 1270 in epoch 4, gen_loss = 0.8195659851671484, disc_loss = 0.08636888805491062
Trained batch 1271 in epoch 4, gen_loss = 0.8194086795801636, disc_loss = 0.08647385518521995
Trained batch 1272 in epoch 4, gen_loss = 0.8192726236483476, disc_loss = 0.0864539722991026
Trained batch 1273 in epoch 4, gen_loss = 0.8195065646849022, disc_loss = 0.0865510992155362
Trained batch 1274 in epoch 4, gen_loss = 0.8194808325113034, disc_loss = 0.08650542658004982
Trained batch 1275 in epoch 4, gen_loss = 0.8192814450746045, disc_loss = 0.08654917572474627
Trained batch 1276 in epoch 4, gen_loss = 0.8191073042579059, disc_loss = 0.08657158428391758
Trained batch 1277 in epoch 4, gen_loss = 0.8191293334363958, disc_loss = 0.08655233561944549
Trained batch 1278 in epoch 4, gen_loss = 0.8193611052932919, disc_loss = 0.08661514091574127
Trained batch 1279 in epoch 4, gen_loss = 0.8192453525494784, disc_loss = 0.08660806468360534
Trained batch 1280 in epoch 4, gen_loss = 0.8191121879450332, disc_loss = 0.08662304187638453
Trained batch 1281 in epoch 4, gen_loss = 0.8191232339547316, disc_loss = 0.08661831420477241
Trained batch 1282 in epoch 4, gen_loss = 0.8191575973831111, disc_loss = 0.0865887294310005
Trained batch 1283 in epoch 4, gen_loss = 0.8191004703256571, disc_loss = 0.08658793233182699
Trained batch 1284 in epoch 4, gen_loss = 0.818881497911906, disc_loss = 0.08663448930214293
Trained batch 1285 in epoch 4, gen_loss = 0.8190858530497662, disc_loss = 0.08664683449519495
Trained batch 1286 in epoch 4, gen_loss = 0.8191359451137593, disc_loss = 0.08660240958335505
Trained batch 1287 in epoch 4, gen_loss = 0.8190244147496194, disc_loss = 0.08657838650133103
Trained batch 1288 in epoch 4, gen_loss = 0.8191087207561135, disc_loss = 0.08656172442905276
Trained batch 1289 in epoch 4, gen_loss = 0.8189076193081316, disc_loss = 0.08656568367922202
Trained batch 1290 in epoch 4, gen_loss = 0.8190260583074586, disc_loss = 0.08651315913832149
Trained batch 1291 in epoch 4, gen_loss = 0.8189938408394716, disc_loss = 0.08648598631346546
Trained batch 1292 in epoch 4, gen_loss = 0.8190081461584117, disc_loss = 0.08650201763158227
Trained batch 1293 in epoch 4, gen_loss = 0.8191047554498846, disc_loss = 0.08648420825501302
Trained batch 1294 in epoch 4, gen_loss = 0.8193221435123429, disc_loss = 0.08642783998961212
Trained batch 1295 in epoch 4, gen_loss = 0.8191498821992197, disc_loss = 0.0864601575594861
Trained batch 1296 in epoch 4, gen_loss = 0.8192600776529717, disc_loss = 0.08640524501385959
Trained batch 1297 in epoch 4, gen_loss = 0.8192647263889871, disc_loss = 0.08635722418840923
Trained batch 1298 in epoch 4, gen_loss = 0.819259452443567, disc_loss = 0.08631317636924433
Trained batch 1299 in epoch 4, gen_loss = 0.8195398545723696, disc_loss = 0.08627283110319135
Trained batch 1300 in epoch 4, gen_loss = 0.8195635112865809, disc_loss = 0.08622884188243958
Trained batch 1301 in epoch 4, gen_loss = 0.8195417632796614, disc_loss = 0.086223334007855
Trained batch 1302 in epoch 4, gen_loss = 0.8194996282309637, disc_loss = 0.08623921187560225
Trained batch 1303 in epoch 4, gen_loss = 0.8193558376808108, disc_loss = 0.08627811392184999
Trained batch 1304 in epoch 4, gen_loss = 0.8196719925065606, disc_loss = 0.08628395340473202
Trained batch 1305 in epoch 4, gen_loss = 0.8199201662544087, disc_loss = 0.08627106691710651
Trained batch 1306 in epoch 4, gen_loss = 0.8198237267266546, disc_loss = 0.08629975341048089
Trained batch 1307 in epoch 4, gen_loss = 0.8199469943841299, disc_loss = 0.08624815216411862
Trained batch 1308 in epoch 4, gen_loss = 0.8200886423483981, disc_loss = 0.08620572758189668
Trained batch 1309 in epoch 4, gen_loss = 0.8202130072899447, disc_loss = 0.08616446965118117
Trained batch 1310 in epoch 4, gen_loss = 0.8202289248313002, disc_loss = 0.086154681473081
Trained batch 1311 in epoch 4, gen_loss = 0.8202286851478786, disc_loss = 0.08615309753414051
Trained batch 1312 in epoch 4, gen_loss = 0.8202424229144687, disc_loss = 0.08611656509315693
Trained batch 1313 in epoch 4, gen_loss = 0.8204307700401028, disc_loss = 0.08607708343908566
Trained batch 1314 in epoch 4, gen_loss = 0.8202160384265189, disc_loss = 0.0860893453974206
Trained batch 1315 in epoch 4, gen_loss = 0.8203429633179696, disc_loss = 0.08612134167606061
Trained batch 1316 in epoch 4, gen_loss = 0.8202227107394167, disc_loss = 0.08608670898549818
Trained batch 1317 in epoch 4, gen_loss = 0.8203643896420556, disc_loss = 0.08603398643302616
Trained batch 1318 in epoch 4, gen_loss = 0.8204558776399238, disc_loss = 0.08597520597305904
Trained batch 1319 in epoch 4, gen_loss = 0.8204873100826234, disc_loss = 0.08593076577120827
Trained batch 1320 in epoch 4, gen_loss = 0.8203980052768959, disc_loss = 0.08590977236362038
Trained batch 1321 in epoch 4, gen_loss = 0.8204050768341492, disc_loss = 0.08587021786830869
Trained batch 1322 in epoch 4, gen_loss = 0.8207153824361454, disc_loss = 0.08596006537402556
Trained batch 1323 in epoch 4, gen_loss = 0.8207835926029977, disc_loss = 0.08600139295298247
Trained batch 1324 in epoch 4, gen_loss = 0.8205376330861506, disc_loss = 0.08635605777596246
Trained batch 1325 in epoch 4, gen_loss = 0.8205418668541253, disc_loss = 0.08635387404296452
Trained batch 1326 in epoch 4, gen_loss = 0.8206941772423567, disc_loss = 0.08634386432673656
Trained batch 1327 in epoch 4, gen_loss = 0.8208342174808663, disc_loss = 0.08629294693664961
Trained batch 1328 in epoch 4, gen_loss = 0.8207093945923741, disc_loss = 0.08632157199845794
Trained batch 1329 in epoch 4, gen_loss = 0.820718489777773, disc_loss = 0.08637943772662122
Trained batch 1330 in epoch 4, gen_loss = 0.8205787319155405, disc_loss = 0.0864306704048837
Trained batch 1331 in epoch 4, gen_loss = 0.820513166509591, disc_loss = 0.08643882480126948
Trained batch 1332 in epoch 4, gen_loss = 0.8202768436787455, disc_loss = 0.08641815544486839
Trained batch 1333 in epoch 4, gen_loss = 0.8200171248264041, disc_loss = 0.08663245205728357
Trained batch 1334 in epoch 4, gen_loss = 0.8201822693205059, disc_loss = 0.08658184540398726
Trained batch 1335 in epoch 4, gen_loss = 0.8202947021021457, disc_loss = 0.08666189788515864
Trained batch 1336 in epoch 4, gen_loss = 0.8204851621955567, disc_loss = 0.08664792892122579
Trained batch 1337 in epoch 4, gen_loss = 0.8203472821835445, disc_loss = 0.0866816457711099
Trained batch 1338 in epoch 4, gen_loss = 0.8201768305027458, disc_loss = 0.08674596253500123
Trained batch 1339 in epoch 4, gen_loss = 0.8201549213991236, disc_loss = 0.08677329852058094
Trained batch 1340 in epoch 4, gen_loss = 0.8202931003326982, disc_loss = 0.0867252998608932
Trained batch 1341 in epoch 4, gen_loss = 0.8202632878603061, disc_loss = 0.08667951095092837
Trained batch 1342 in epoch 4, gen_loss = 0.8201219241785985, disc_loss = 0.08664797463753189
Trained batch 1343 in epoch 4, gen_loss = 0.8201810287178627, disc_loss = 0.08663238624181499
Trained batch 1344 in epoch 4, gen_loss = 0.8202224780857341, disc_loss = 0.0865872423801585
Trained batch 1345 in epoch 4, gen_loss = 0.8201679648253043, disc_loss = 0.08660671965946978
Trained batch 1346 in epoch 4, gen_loss = 0.8201799215921758, disc_loss = 0.0865956028724959
Trained batch 1347 in epoch 4, gen_loss = 0.8202697779950119, disc_loss = 0.08656395530122268
Trained batch 1348 in epoch 4, gen_loss = 0.820187333758625, disc_loss = 0.08653859847402677
Trained batch 1349 in epoch 4, gen_loss = 0.8204794987705019, disc_loss = 0.08652334619692906
Trained batch 1350 in epoch 4, gen_loss = 0.8203027843767232, disc_loss = 0.08652681896192808
Trained batch 1351 in epoch 4, gen_loss = 0.8205178759815778, disc_loss = 0.08659852046716529
Trained batch 1352 in epoch 4, gen_loss = 0.8205170088887479, disc_loss = 0.08657130919753436
Trained batch 1353 in epoch 4, gen_loss = 0.8206383589671669, disc_loss = 0.08656957790914488
Trained batch 1354 in epoch 4, gen_loss = 0.8204414195460147, disc_loss = 0.08664260797195714
Trained batch 1355 in epoch 4, gen_loss = 0.8203570319004466, disc_loss = 0.08660193157669399
Trained batch 1356 in epoch 4, gen_loss = 0.820446950003955, disc_loss = 0.08664931011795943
Trained batch 1357 in epoch 4, gen_loss = 0.8202681517083094, disc_loss = 0.08668420827791194
Trained batch 1358 in epoch 4, gen_loss = 0.8201508810846484, disc_loss = 0.08668401576626589
Trained batch 1359 in epoch 4, gen_loss = 0.8202197668087833, disc_loss = 0.08665206356432892
Trained batch 1360 in epoch 4, gen_loss = 0.8202036340870812, disc_loss = 0.0866320010252067
Trained batch 1361 in epoch 4, gen_loss = 0.8203597494377789, disc_loss = 0.0865852356489704
Trained batch 1362 in epoch 4, gen_loss = 0.8204221311117565, disc_loss = 0.08653294944845998
Trained batch 1363 in epoch 4, gen_loss = 0.8204972979741013, disc_loss = 0.08650771679071288
Trained batch 1364 in epoch 4, gen_loss = 0.8205482833769732, disc_loss = 0.08648514001299337
Trained batch 1365 in epoch 4, gen_loss = 0.820533712537711, disc_loss = 0.08647091597649999
Trained batch 1366 in epoch 4, gen_loss = 0.8205512742666581, disc_loss = 0.08642625062669891
Trained batch 1367 in epoch 4, gen_loss = 0.8204853568030032, disc_loss = 0.0864181014398053
Trained batch 1368 in epoch 4, gen_loss = 0.8206877632895205, disc_loss = 0.08637473237625248
Trained batch 1369 in epoch 4, gen_loss = 0.8207616708792039, disc_loss = 0.08637608535091536
Trained batch 1370 in epoch 4, gen_loss = 0.8207375026592627, disc_loss = 0.08639151944909965
Trained batch 1371 in epoch 4, gen_loss = 0.820731895549478, disc_loss = 0.08636829405907628
Trained batch 1372 in epoch 4, gen_loss = 0.8206291781102144, disc_loss = 0.08634757882293426
Trained batch 1373 in epoch 4, gen_loss = 0.8204897464059152, disc_loss = 0.08632328502089598
Trained batch 1374 in epoch 4, gen_loss = 0.8207902329835025, disc_loss = 0.08628158863396806
Trained batch 1375 in epoch 4, gen_loss = 0.8208813582178812, disc_loss = 0.08622672078558406
Trained batch 1376 in epoch 4, gen_loss = 0.820718974481048, disc_loss = 0.08626619558179441
Trained batch 1377 in epoch 4, gen_loss = 0.8206423908385552, disc_loss = 0.08622300471598215
Trained batch 1378 in epoch 4, gen_loss = 0.8205635068942189, disc_loss = 0.08620633499661733
Trained batch 1379 in epoch 4, gen_loss = 0.8205341016252835, disc_loss = 0.08623514501816607
Trained batch 1380 in epoch 4, gen_loss = 0.8205036642454743, disc_loss = 0.08619514270129247
Trained batch 1381 in epoch 4, gen_loss = 0.820415013282413, disc_loss = 0.08619255856166064
Trained batch 1382 in epoch 4, gen_loss = 0.8202767871853587, disc_loss = 0.08615600642602048
Trained batch 1383 in epoch 4, gen_loss = 0.8201962377596108, disc_loss = 0.08611060746284632
Trained batch 1384 in epoch 4, gen_loss = 0.8204359991670946, disc_loss = 0.0861220320858169
Trained batch 1385 in epoch 4, gen_loss = 0.8205011228763351, disc_loss = 0.08615801085631966
Trained batch 1386 in epoch 4, gen_loss = 0.8204868394819712, disc_loss = 0.08612374433369337
Trained batch 1387 in epoch 4, gen_loss = 0.8203934882619882, disc_loss = 0.08619573014024752
Trained batch 1388 in epoch 4, gen_loss = 0.8203850552664977, disc_loss = 0.08615993434305808
Trained batch 1389 in epoch 4, gen_loss = 0.8204057833059228, disc_loss = 0.08613034122047289
Trained batch 1390 in epoch 4, gen_loss = 0.8206565680690672, disc_loss = 0.08615712403459709
Trained batch 1391 in epoch 4, gen_loss = 0.8205615084447052, disc_loss = 0.08615856400146363
Trained batch 1392 in epoch 4, gen_loss = 0.8205957540443966, disc_loss = 0.08614382801152236
Trained batch 1393 in epoch 4, gen_loss = 0.8205789724629442, disc_loss = 0.08611015349905804
Trained batch 1394 in epoch 4, gen_loss = 0.8207617214717318, disc_loss = 0.08610443843288287
Trained batch 1395 in epoch 4, gen_loss = 0.820677884051144, disc_loss = 0.08613872431775016
Trained batch 1396 in epoch 4, gen_loss = 0.8204507259232023, disc_loss = 0.08621646113775047
Trained batch 1397 in epoch 4, gen_loss = 0.8205379731793261, disc_loss = 0.08619670177415514
Trained batch 1398 in epoch 4, gen_loss = 0.8206421110653894, disc_loss = 0.0862722871768514
Trained batch 1399 in epoch 4, gen_loss = 0.8206908806945596, disc_loss = 0.08622525191233893
Trained batch 1400 in epoch 4, gen_loss = 0.8207981316937795, disc_loss = 0.0861707822669651
Trained batch 1401 in epoch 4, gen_loss = 0.8205506895348621, disc_loss = 0.08621496217658799
Trained batch 1402 in epoch 4, gen_loss = 0.8205053212595088, disc_loss = 0.08617671577695356
Trained batch 1403 in epoch 4, gen_loss = 0.8206142497240988, disc_loss = 0.08632782419136542
Trained batch 1404 in epoch 4, gen_loss = 0.820548892975702, disc_loss = 0.08632347417425272
Trained batch 1405 in epoch 4, gen_loss = 0.8204934202971872, disc_loss = 0.08629269405813943
Trained batch 1406 in epoch 4, gen_loss = 0.8203603633558318, disc_loss = 0.08634097092204436
Trained batch 1407 in epoch 4, gen_loss = 0.8200404837050221, disc_loss = 0.0864952218534282
Trained batch 1408 in epoch 4, gen_loss = 0.8202129608354642, disc_loss = 0.08651269762033188
Trained batch 1409 in epoch 4, gen_loss = 0.8201002500158675, disc_loss = 0.0865432246373504
Trained batch 1410 in epoch 4, gen_loss = 0.8199872515625687, disc_loss = 0.0865464409384916
Trained batch 1411 in epoch 4, gen_loss = 0.820178136820496, disc_loss = 0.08651932907157522
Trained batch 1412 in epoch 4, gen_loss = 0.8201843633857586, disc_loss = 0.08647548744945358
Trained batch 1413 in epoch 4, gen_loss = 0.8200927928111172, disc_loss = 0.08644273844903237
Trained batch 1414 in epoch 4, gen_loss = 0.8201388037246866, disc_loss = 0.08641046214447268
Trained batch 1415 in epoch 4, gen_loss = 0.8203142518545948, disc_loss = 0.08636211914616758
Trained batch 1416 in epoch 4, gen_loss = 0.8202072561165776, disc_loss = 0.08638563353388229
Trained batch 1417 in epoch 4, gen_loss = 0.8201560715189774, disc_loss = 0.08635100883915127
Trained batch 1418 in epoch 4, gen_loss = 0.8200533118694916, disc_loss = 0.08640414637882969
Trained batch 1419 in epoch 4, gen_loss = 0.8202132029432646, disc_loss = 0.0863754315593634
Trained batch 1420 in epoch 4, gen_loss = 0.8201798516037933, disc_loss = 0.08635493931586656
Trained batch 1421 in epoch 4, gen_loss = 0.8201174694945206, disc_loss = 0.08631727630737514
Trained batch 1422 in epoch 4, gen_loss = 0.8204095516921933, disc_loss = 0.08627551633344985
Trained batch 1423 in epoch 4, gen_loss = 0.8204177020305998, disc_loss = 0.08624849244043116
Trained batch 1424 in epoch 4, gen_loss = 0.8203702760997571, disc_loss = 0.08620715167863588
Trained batch 1425 in epoch 4, gen_loss = 0.8201492392832902, disc_loss = 0.08620782450872093
Trained batch 1426 in epoch 4, gen_loss = 0.8201567311761424, disc_loss = 0.08615892400871114
Trained batch 1427 in epoch 4, gen_loss = 0.8200175308880686, disc_loss = 0.08619935835642527
Trained batch 1428 in epoch 4, gen_loss = 0.8201497164199701, disc_loss = 0.08617331501079542
Trained batch 1429 in epoch 4, gen_loss = 0.8201076034065726, disc_loss = 0.08614766202847493
Trained batch 1430 in epoch 4, gen_loss = 0.8200110333270747, disc_loss = 0.0861365225437474
Trained batch 1431 in epoch 4, gen_loss = 0.8198728725813621, disc_loss = 0.08617589163871003
Trained batch 1432 in epoch 4, gen_loss = 0.8198386752264365, disc_loss = 0.08615350887596618
Trained batch 1433 in epoch 4, gen_loss = 0.819655103746651, disc_loss = 0.08616230555295663
Trained batch 1434 in epoch 4, gen_loss = 0.8195604321017913, disc_loss = 0.08618640608417084
Trained batch 1435 in epoch 4, gen_loss = 0.8197125792503357, disc_loss = 0.08637321094462186
Trained batch 1436 in epoch 4, gen_loss = 0.8197033696483221, disc_loss = 0.08635397428366703
Trained batch 1437 in epoch 4, gen_loss = 0.8195497260969107, disc_loss = 0.08636429101540882
Trained batch 1438 in epoch 4, gen_loss = 0.8193901914784774, disc_loss = 0.08647498240709936
Trained batch 1439 in epoch 4, gen_loss = 0.8192442781395383, disc_loss = 0.08645128821727768
Trained batch 1440 in epoch 4, gen_loss = 0.8190944265111464, disc_loss = 0.08645879760375512
Trained batch 1441 in epoch 4, gen_loss = 0.8193056099788492, disc_loss = 0.08646512817205207
Trained batch 1442 in epoch 4, gen_loss = 0.8193155505635716, disc_loss = 0.08644672465941153
Trained batch 1443 in epoch 4, gen_loss = 0.819221684683393, disc_loss = 0.08648483358985304
Trained batch 1444 in epoch 4, gen_loss = 0.8192579558563893, disc_loss = 0.08643880713260556
Trained batch 1445 in epoch 4, gen_loss = 0.8191103394018334, disc_loss = 0.08646025476084551
Trained batch 1446 in epoch 4, gen_loss = 0.8190153286056677, disc_loss = 0.08645867461495683
Trained batch 1447 in epoch 4, gen_loss = 0.8189459822619158, disc_loss = 0.08649387820244339
Trained batch 1448 in epoch 4, gen_loss = 0.8188509188330199, disc_loss = 0.08652640035275685
Trained batch 1449 in epoch 4, gen_loss = 0.8188396979200429, disc_loss = 0.08650888024122808
Trained batch 1450 in epoch 4, gen_loss = 0.8186520268225325, disc_loss = 0.08654585386627064
Trained batch 1451 in epoch 4, gen_loss = 0.8186029314009611, disc_loss = 0.0865405718978756
Trained batch 1452 in epoch 4, gen_loss = 0.8187475547409845, disc_loss = 0.08649373617944937
Trained batch 1453 in epoch 4, gen_loss = 0.8188081259084699, disc_loss = 0.0865160836437858
Trained batch 1454 in epoch 4, gen_loss = 0.8187321050879881, disc_loss = 0.086491443523081
Trained batch 1455 in epoch 4, gen_loss = 0.8188062186588297, disc_loss = 0.08646644284381981
Trained batch 1456 in epoch 4, gen_loss = 0.8186752603900048, disc_loss = 0.08645988827860193
Trained batch 1457 in epoch 4, gen_loss = 0.8184692728830136, disc_loss = 0.08654360899245635
Trained batch 1458 in epoch 4, gen_loss = 0.8188715917431711, disc_loss = 0.08665473488426938
Trained batch 1459 in epoch 4, gen_loss = 0.819127533207201, disc_loss = 0.08663189212555601
Trained batch 1460 in epoch 4, gen_loss = 0.8191328237188915, disc_loss = 0.0866142145560737
Trained batch 1461 in epoch 4, gen_loss = 0.8191372131681638, disc_loss = 0.08657266205990823
Trained batch 1462 in epoch 4, gen_loss = 0.8190076227719378, disc_loss = 0.08658343653645945
Trained batch 1463 in epoch 4, gen_loss = 0.8190123512526679, disc_loss = 0.08656515355401322
Trained batch 1464 in epoch 4, gen_loss = 0.8192008074233149, disc_loss = 0.08655915005806414
Trained batch 1465 in epoch 4, gen_loss = 0.8193016090058044, disc_loss = 0.0865299895251396
Trained batch 1466 in epoch 4, gen_loss = 0.8191476718210897, disc_loss = 0.0865493805392759
Trained batch 1467 in epoch 4, gen_loss = 0.8189158042948642, disc_loss = 0.08657032249613389
Trained batch 1468 in epoch 4, gen_loss = 0.8189137380816159, disc_loss = 0.08652524931617513
Trained batch 1469 in epoch 4, gen_loss = 0.8189230497191552, disc_loss = 0.08649902415499851
Trained batch 1470 in epoch 4, gen_loss = 0.8190749376343676, disc_loss = 0.08664145517459913
Trained batch 1471 in epoch 4, gen_loss = 0.8188983357066045, disc_loss = 0.08667829862331375
Trained batch 1472 in epoch 4, gen_loss = 0.8188404390703474, disc_loss = 0.08668798145294969
Trained batch 1473 in epoch 4, gen_loss = 0.8188655042017493, disc_loss = 0.08668746103992588
Trained batch 1474 in epoch 4, gen_loss = 0.8190044276593095, disc_loss = 0.08665374934452318
Trained batch 1475 in epoch 4, gen_loss = 0.8187896260401097, disc_loss = 0.08667458367482242
Trained batch 1476 in epoch 4, gen_loss = 0.8187798026775135, disc_loss = 0.08663847249035314
Trained batch 1477 in epoch 4, gen_loss = 0.8187136254871973, disc_loss = 0.08661714139273478
Trained batch 1478 in epoch 4, gen_loss = 0.8188977749304162, disc_loss = 0.08664511750213565
Trained batch 1479 in epoch 4, gen_loss = 0.8187138938420527, disc_loss = 0.08665695485463869
Trained batch 1480 in epoch 4, gen_loss = 0.8186238178282795, disc_loss = 0.0866427380069059
Trained batch 1481 in epoch 4, gen_loss = 0.8187181536967938, disc_loss = 0.08660570040436942
Trained batch 1482 in epoch 4, gen_loss = 0.8189504975333699, disc_loss = 0.0866708741831045
Trained batch 1483 in epoch 4, gen_loss = 0.8188427149285524, disc_loss = 0.08672936429423996
Trained batch 1484 in epoch 4, gen_loss = 0.8188500977525808, disc_loss = 0.08669818659102926
Trained batch 1485 in epoch 4, gen_loss = 0.818972449524085, disc_loss = 0.0867392906438419
Trained batch 1486 in epoch 4, gen_loss = 0.8189342663283307, disc_loss = 0.08673897727092611
Trained batch 1487 in epoch 4, gen_loss = 0.8188643598909019, disc_loss = 0.08673014564681247
Trained batch 1488 in epoch 4, gen_loss = 0.8187390457390938, disc_loss = 0.08676047294692726
Trained batch 1489 in epoch 4, gen_loss = 0.8187860402084837, disc_loss = 0.08676877264589722
Trained batch 1490 in epoch 4, gen_loss = 0.8186700627117809, disc_loss = 0.08675258621944477
Trained batch 1491 in epoch 4, gen_loss = 0.8186073653180223, disc_loss = 0.08673165887925055
Trained batch 1492 in epoch 4, gen_loss = 0.8186584257951776, disc_loss = 0.0866943691665031
Trained batch 1493 in epoch 4, gen_loss = 0.8185913877155248, disc_loss = 0.08665661869908482
Trained batch 1494 in epoch 4, gen_loss = 0.8184185601397103, disc_loss = 0.0866479151228125
Trained batch 1495 in epoch 4, gen_loss = 0.8185274856772652, disc_loss = 0.08661137577077813
Trained batch 1496 in epoch 4, gen_loss = 0.8185200445159881, disc_loss = 0.08657032440888708
Trained batch 1497 in epoch 4, gen_loss = 0.8184113261776073, disc_loss = 0.08653732867089557
Trained batch 1498 in epoch 4, gen_loss = 0.8184695719797823, disc_loss = 0.08655781532886915
Trained batch 1499 in epoch 4, gen_loss = 0.8183963120381037, disc_loss = 0.08652416100756576
Trained batch 1500 in epoch 4, gen_loss = 0.8185065531238248, disc_loss = 0.08647795024915517
Trained batch 1501 in epoch 4, gen_loss = 0.8184784341271168, disc_loss = 0.08644717508032869
Trained batch 1502 in epoch 4, gen_loss = 0.8184531337010884, disc_loss = 0.08645981943720601
Trained batch 1503 in epoch 4, gen_loss = 0.8185346589839839, disc_loss = 0.08648812879735178
Trained batch 1504 in epoch 4, gen_loss = 0.818360797630196, disc_loss = 0.08652690259826391
Trained batch 1505 in epoch 4, gen_loss = 0.8182830944320911, disc_loss = 0.08654107954779795
Trained batch 1506 in epoch 4, gen_loss = 0.8182707920561741, disc_loss = 0.08650148206241504
Trained batch 1507 in epoch 4, gen_loss = 0.8184545701789603, disc_loss = 0.08647739784131246
Trained batch 1508 in epoch 4, gen_loss = 0.818703152392383, disc_loss = 0.08646769720580827
Trained batch 1509 in epoch 4, gen_loss = 0.8186814053958615, disc_loss = 0.08644991988680073
Trained batch 1510 in epoch 4, gen_loss = 0.8185893361099819, disc_loss = 0.08645468133623131
Trained batch 1511 in epoch 4, gen_loss = 0.8188387794154031, disc_loss = 0.08647190122994491
Trained batch 1512 in epoch 4, gen_loss = 0.8189555528301005, disc_loss = 0.08643738580658362
Trained batch 1513 in epoch 4, gen_loss = 0.8191324027164136, disc_loss = 0.08639108658094043
Trained batch 1514 in epoch 4, gen_loss = 0.8190837578018113, disc_loss = 0.08638813418210192
Trained batch 1515 in epoch 4, gen_loss = 0.8192880463867515, disc_loss = 0.08636817503702092
Trained batch 1516 in epoch 4, gen_loss = 0.8195331496239966, disc_loss = 0.08635577614509408
Trained batch 1517 in epoch 4, gen_loss = 0.8193382672248936, disc_loss = 0.08640151879288825
Trained batch 1518 in epoch 4, gen_loss = 0.819279801814159, disc_loss = 0.08643708565965824
Trained batch 1519 in epoch 4, gen_loss = 0.8193220427946041, disc_loss = 0.08639924655895141
Trained batch 1520 in epoch 4, gen_loss = 0.8193832021806681, disc_loss = 0.08635784392835992
Trained batch 1521 in epoch 4, gen_loss = 0.8195899155935696, disc_loss = 0.08637778142940757
Trained batch 1522 in epoch 4, gen_loss = 0.8195822870582635, disc_loss = 0.08638942635630992
Trained batch 1523 in epoch 4, gen_loss = 0.8195714776127982, disc_loss = 0.08640566409236734
Trained batch 1524 in epoch 4, gen_loss = 0.8198627392972102, disc_loss = 0.08637978255901424
Trained batch 1525 in epoch 4, gen_loss = 0.8199336972492863, disc_loss = 0.08633118260653047
Trained batch 1526 in epoch 4, gen_loss = 0.81988268493435, disc_loss = 0.08632619383445433
Trained batch 1527 in epoch 4, gen_loss = 0.8199554976290433, disc_loss = 0.08631012873652182
Trained batch 1528 in epoch 4, gen_loss = 0.8200621871951361, disc_loss = 0.08627345691848622
Trained batch 1529 in epoch 4, gen_loss = 0.8202213089840085, disc_loss = 0.08628772376074755
Trained batch 1530 in epoch 4, gen_loss = 0.8201681398084006, disc_loss = 0.08630811249968674
Trained batch 1531 in epoch 4, gen_loss = 0.8199437823214668, disc_loss = 0.08640768290126535
Trained batch 1532 in epoch 4, gen_loss = 0.8199261890387737, disc_loss = 0.08637126407507668
Trained batch 1533 in epoch 4, gen_loss = 0.8198654262307725, disc_loss = 0.08633509836028508
Trained batch 1534 in epoch 4, gen_loss = 0.8202217116029721, disc_loss = 0.08640922307149061
Trained batch 1535 in epoch 4, gen_loss = 0.8201300577881435, disc_loss = 0.08640028511247995
Trained batch 1536 in epoch 4, gen_loss = 0.820167108720669, disc_loss = 0.08636261884301231
Trained batch 1537 in epoch 4, gen_loss = 0.8201851427787612, disc_loss = 0.08633369368123149
Trained batch 1538 in epoch 4, gen_loss = 0.8202695463910515, disc_loss = 0.08630152277272048
Trained batch 1539 in epoch 4, gen_loss = 0.8202387942122175, disc_loss = 0.08628482556774873
Trained batch 1540 in epoch 4, gen_loss = 0.8201802288998573, disc_loss = 0.08625129051294993
Trained batch 1541 in epoch 4, gen_loss = 0.8201079119658811, disc_loss = 0.08622091019196355
Trained batch 1542 in epoch 4, gen_loss = 0.8202250471998945, disc_loss = 0.08618740879309474
Trained batch 1543 in epoch 4, gen_loss = 0.8201237071903876, disc_loss = 0.08618781830388039
Trained batch 1544 in epoch 4, gen_loss = 0.81993119728218, disc_loss = 0.08619473660846985
Trained batch 1545 in epoch 4, gen_loss = 0.8200442859996954, disc_loss = 0.08618345566456571
Trained batch 1546 in epoch 4, gen_loss = 0.8199275304366483, disc_loss = 0.08616855709633532
Trained batch 1547 in epoch 4, gen_loss = 0.8199961639805974, disc_loss = 0.08611968623562079
Trained batch 1548 in epoch 4, gen_loss = 0.8201118409826034, disc_loss = 0.08608231491880014
Trained batch 1549 in epoch 4, gen_loss = 0.8199761877905938, disc_loss = 0.08617971628814215
Trained batch 1550 in epoch 4, gen_loss = 0.8201949965715563, disc_loss = 0.08616397575625992
Trained batch 1551 in epoch 4, gen_loss = 0.8203941030984687, disc_loss = 0.08612342650153597
Trained batch 1552 in epoch 4, gen_loss = 0.8202173626967882, disc_loss = 0.08616593729492328
Trained batch 1553 in epoch 4, gen_loss = 0.8202321608017463, disc_loss = 0.08612324934640954
Trained batch 1554 in epoch 4, gen_loss = 0.8203896889349273, disc_loss = 0.086233287269004
Trained batch 1555 in epoch 4, gen_loss = 0.8205511691407863, disc_loss = 0.08623136085868696
Trained batch 1556 in epoch 4, gen_loss = 0.8203965707627642, disc_loss = 0.08625822768420431
Trained batch 1557 in epoch 4, gen_loss = 0.8203479035904533, disc_loss = 0.08621995066428875
Trained batch 1558 in epoch 4, gen_loss = 0.8204461729931786, disc_loss = 0.0861735355381981
Trained batch 1559 in epoch 4, gen_loss = 0.8205036176320833, disc_loss = 0.0863205353398091
Trained batch 1560 in epoch 4, gen_loss = 0.8204110766129186, disc_loss = 0.08631982377292988
Trained batch 1561 in epoch 4, gen_loss = 0.820258820446139, disc_loss = 0.08640931242636897
Trained batch 1562 in epoch 4, gen_loss = 0.8204231268689942, disc_loss = 0.08640054893910513
Trained batch 1563 in epoch 4, gen_loss = 0.8204409145104611, disc_loss = 0.08651673864088524
Trained batch 1564 in epoch 4, gen_loss = 0.8204333916639749, disc_loss = 0.08649145798733869
Trained batch 1565 in epoch 4, gen_loss = 0.8203578778229759, disc_loss = 0.08648756158592877
Trained batch 1566 in epoch 4, gen_loss = 0.8203414074539301, disc_loss = 0.08645455022185004
Trained batch 1567 in epoch 4, gen_loss = 0.8204775512674634, disc_loss = 0.08647582406559437
Trained batch 1568 in epoch 4, gen_loss = 0.820378939690599, disc_loss = 0.08650169061696296
Trained batch 1569 in epoch 4, gen_loss = 0.8202573743215792, disc_loss = 0.08653954239295214
Trained batch 1570 in epoch 4, gen_loss = 0.8202777635815947, disc_loss = 0.0865349846828034
Trained batch 1571 in epoch 4, gen_loss = 0.8202132561052119, disc_loss = 0.0865539658092479
Trained batch 1572 in epoch 4, gen_loss = 0.8201910080761191, disc_loss = 0.08661294439381245
Trained batch 1573 in epoch 4, gen_loss = 0.8202470673539284, disc_loss = 0.08658611771634045
Trained batch 1574 in epoch 4, gen_loss = 0.8199066606400505, disc_loss = 0.08672794524668938
Trained batch 1575 in epoch 4, gen_loss = 0.8200779458139148, disc_loss = 0.08668699303108887
Trained batch 1576 in epoch 4, gen_loss = 0.820253305671029, disc_loss = 0.08666818190842025
Trained batch 1577 in epoch 4, gen_loss = 0.820282247507678, disc_loss = 0.08665219932961005
Trained batch 1578 in epoch 4, gen_loss = 0.8201361030925294, disc_loss = 0.08665533767402069
Trained batch 1579 in epoch 4, gen_loss = 0.820207001287726, disc_loss = 0.08661429907071487
Trained batch 1580 in epoch 4, gen_loss = 0.8201244079486092, disc_loss = 0.08659618813986315
Testing Epoch 4
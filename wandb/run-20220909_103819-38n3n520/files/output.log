/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 1.4610180854797363, disc_loss = 0.5306534171104431
Trained batch 1 in epoch 0, gen_loss = 1.5450342893600464, disc_loss = 0.6913624703884125
Trained batch 2 in epoch 0, gen_loss = 1.5871923764546711, disc_loss = 0.7070214549700419
Trained batch 3 in epoch 0, gen_loss = 1.5574044585227966, disc_loss = 0.6214974671602249
Trained batch 4 in epoch 0, gen_loss = 1.5941459894180299, disc_loss = 0.571570748090744
Trained batch 5 in epoch 0, gen_loss = 1.551455318927765, disc_loss = 0.5210981518030167
Trained batch 6 in epoch 0, gen_loss = 1.5114353895187378, disc_loss = 0.4945987548146929
Trained batch 7 in epoch 0, gen_loss = 1.521353229880333, disc_loss = 0.46282810531556606
Trained batch 8 in epoch 0, gen_loss = 1.4918367995156183, disc_loss = 0.434833738538954
Trained batch 9 in epoch 0, gen_loss = 1.4744470238685607, disc_loss = 0.4126131534576416
Trained batch 10 in epoch 0, gen_loss = 1.4741095846349543, disc_loss = 0.3912392488934777
Trained batch 11 in epoch 0, gen_loss = 1.481620321671168, disc_loss = 0.3722567980488141
Trained batch 12 in epoch 0, gen_loss = 1.4855516782173743, disc_loss = 0.35612916831786817
Trained batch 13 in epoch 0, gen_loss = 1.4757570794650487, disc_loss = 0.3405246723975454
Trained batch 14 in epoch 0, gen_loss = 1.4771822690963745, disc_loss = 0.32698886692523954
Trained batch 15 in epoch 0, gen_loss = 1.4749321416020393, disc_loss = 0.31498361751437187
Trained batch 16 in epoch 0, gen_loss = 1.48505699634552, disc_loss = 0.3042077018934138
Trained batch 17 in epoch 0, gen_loss = 1.4886945287386577, disc_loss = 0.29319117218255997
Trained batch 18 in epoch 0, gen_loss = 1.4811523901788812, disc_loss = 0.28652933945781306
Trained batch 19 in epoch 0, gen_loss = 1.4881350815296173, disc_loss = 0.27973366230726243
Trained batch 20 in epoch 0, gen_loss = 1.4926314183643885, disc_loss = 0.27511689492634367
Trained batch 21 in epoch 0, gen_loss = 1.5007988160306758, disc_loss = 0.27030186219648883
Trained batch 22 in epoch 0, gen_loss = 1.503366320029549, disc_loss = 0.26283573715583136
Trained batch 23 in epoch 0, gen_loss = 1.5081342458724976, disc_loss = 0.2576018000642459
Trained batch 24 in epoch 0, gen_loss = 1.5127309274673462, disc_loss = 0.2505605801939964
Trained batch 25 in epoch 0, gen_loss = 1.5162374560649579, disc_loss = 0.2438039329762642
Trained batch 26 in epoch 0, gen_loss = 1.5219277011023626, disc_loss = 0.2374921151333385
Trained batch 27 in epoch 0, gen_loss = 1.525184656892504, disc_loss = 0.23241416018988406
Trained batch 28 in epoch 0, gen_loss = 1.5320450437480007, disc_loss = 0.22752942273329044
Trained batch 29 in epoch 0, gen_loss = 1.5370418389638265, disc_loss = 0.22266677791873615
Trained batch 30 in epoch 0, gen_loss = 1.5401641361175045, disc_loss = 0.2192025795098274
Trained batch 31 in epoch 0, gen_loss = 1.5490191020071507, disc_loss = 0.21497669466771185
Trained batch 32 in epoch 0, gen_loss = 1.5544588060090037, disc_loss = 0.2103915803811767
Trained batch 33 in epoch 0, gen_loss = 1.555146525887882, disc_loss = 0.2065433528931702
Trained batch 34 in epoch 0, gen_loss = 1.5613638469151088, disc_loss = 0.2026884064078331
Trained batch 35 in epoch 0, gen_loss = 1.563597900999917, disc_loss = 0.19895576582186753
Trained batch 36 in epoch 0, gen_loss = 1.5611322344960392, disc_loss = 0.1950968133436667
Trained batch 37 in epoch 0, gen_loss = 1.5688012336429797, disc_loss = 0.1914995925402955
Trained batch 38 in epoch 0, gen_loss = 1.5719789022054427, disc_loss = 0.1883888652500434
Trained batch 39 in epoch 0, gen_loss = 1.5731241643428802, disc_loss = 0.18502188613638282
Trained batch 40 in epoch 0, gen_loss = 1.574836469278103, disc_loss = 0.18263630232796435
Trained batch 41 in epoch 0, gen_loss = 1.5801144384202503, disc_loss = 0.18017705982284887
Trained batch 42 in epoch 0, gen_loss = 1.582696521004965, disc_loss = 0.1782547085610933
Trained batch 43 in epoch 0, gen_loss = 1.58542830564759, disc_loss = 0.17696846572851593
Trained batch 44 in epoch 0, gen_loss = 1.587259414460924, disc_loss = 0.17534459357460339
Trained batch 45 in epoch 0, gen_loss = 1.5926964801290762, disc_loss = 0.1726602685192357
Trained batch 46 in epoch 0, gen_loss = 1.5914220607027094, disc_loss = 0.17014738346667999
Trained batch 47 in epoch 0, gen_loss = 1.590674728155136, disc_loss = 0.16738163881624737
Trained batch 48 in epoch 0, gen_loss = 1.5896665393089762, disc_loss = 0.16488573973884388
Trained batch 49 in epoch 0, gen_loss = 1.5891886281967162, disc_loss = 0.16249914027750492
Trained batch 50 in epoch 0, gen_loss = 1.5882008122462852, disc_loss = 0.16051151252844753
Trained batch 51 in epoch 0, gen_loss = 1.5883372219709249, disc_loss = 0.15827750278493533
Trained batch 52 in epoch 0, gen_loss = 1.5893929859377303, disc_loss = 0.15586249829041507
Trained batch 53 in epoch 0, gen_loss = 1.590386931542997, disc_loss = 0.15366319694590788
Trained batch 54 in epoch 0, gen_loss = 1.5887241992083463, disc_loss = 0.1518783132799647
Trained batch 55 in epoch 0, gen_loss = 1.5909034694944109, disc_loss = 0.1501053516819541
Trained batch 56 in epoch 0, gen_loss = 1.5911003727661936, disc_loss = 0.14798246043031676
Trained batch 57 in epoch 0, gen_loss = 1.5910661241103863, disc_loss = 0.14613743286965222
Trained batch 58 in epoch 0, gen_loss = 1.5907581276812797, disc_loss = 0.14429690486798852
Trained batch 59 in epoch 0, gen_loss = 1.5907109518845877, disc_loss = 0.14226019497339923
Trained batch 60 in epoch 0, gen_loss = 1.5881101459753317, disc_loss = 0.14048988014826033
Trained batch 61 in epoch 0, gen_loss = 1.5890975325338301, disc_loss = 0.13861038406649906
Trained batch 62 in epoch 0, gen_loss = 1.5904403641110374, disc_loss = 0.13677248497685743
Trained batch 63 in epoch 0, gen_loss = 1.5886880829930305, disc_loss = 0.13528374300221913
Trained batch 64 in epoch 0, gen_loss = 1.5873507316295916, disc_loss = 0.13363269851184809
Trained batch 65 in epoch 0, gen_loss = 1.5878524202289004, disc_loss = 0.13201764700087634
Trained batch 66 in epoch 0, gen_loss = 1.5884295790942746, disc_loss = 0.13051913745367705
Trained batch 67 in epoch 0, gen_loss = 1.5885401823941399, disc_loss = 0.12906926251290476
Trained batch 68 in epoch 0, gen_loss = 1.5861622578855874, disc_loss = 0.12755040586858557
Trained batch 69 in epoch 0, gen_loss = 1.5832408905029296, disc_loss = 0.1261007025305714
Trained batch 70 in epoch 0, gen_loss = 1.5824004764288244, disc_loss = 0.12486079455891126
Trained batch 71 in epoch 0, gen_loss = 1.5801699062188466, disc_loss = 0.12373084849160579
Trained batch 72 in epoch 0, gen_loss = 1.583318627043946, disc_loss = 0.12242384466712605
Trained batch 73 in epoch 0, gen_loss = 1.5827304559784967, disc_loss = 0.12102954661020555
Trained batch 74 in epoch 0, gen_loss = 1.5800009568532307, disc_loss = 0.11974554715057215
Trained batch 75 in epoch 0, gen_loss = 1.5795518897081677, disc_loss = 0.11847174944552152
Trained batch 76 in epoch 0, gen_loss = 1.5784659215382166, disc_loss = 0.11720438482989738
Trained batch 77 in epoch 0, gen_loss = 1.582145583935273, disc_loss = 0.11593682641306749
Trained batch 78 in epoch 0, gen_loss = 1.58067101315607, disc_loss = 0.11470259926458702
Trained batch 79 in epoch 0, gen_loss = 1.5793871328234672, disc_loss = 0.11350739856716245
Trained batch 80 in epoch 0, gen_loss = 1.5783477550671425, disc_loss = 0.11230260529267935
Trained batch 81 in epoch 0, gen_loss = 1.5769953596882704, disc_loss = 0.11111909607652484
Trained batch 82 in epoch 0, gen_loss = 1.5760635094470288, disc_loss = 0.10996122293578214
Trained batch 83 in epoch 0, gen_loss = 1.5744903513363429, disc_loss = 0.10883447890436011
Trained batch 84 in epoch 0, gen_loss = 1.574544808443855, disc_loss = 0.10775180387803737
Trained batch 85 in epoch 0, gen_loss = 1.572876185871834, disc_loss = 0.10673966749333018
Trained batch 86 in epoch 0, gen_loss = 1.5710455741005382, disc_loss = 0.10577334049318371
Trained batch 87 in epoch 0, gen_loss = 1.5690762414173647, disc_loss = 0.10479735848705539
Trained batch 88 in epoch 0, gen_loss = 1.5667361275533611, disc_loss = 0.10380254082088725
Trained batch 89 in epoch 0, gen_loss = 1.5675816271040175, disc_loss = 0.10283503028460675
Trained batch 90 in epoch 0, gen_loss = 1.5667147937711778, disc_loss = 0.10191933582485704
Trained batch 91 in epoch 0, gen_loss = 1.564473500718241, disc_loss = 0.10098470250428047
Trained batch 92 in epoch 0, gen_loss = 1.56317816370277, disc_loss = 0.10003692801961656
Trained batch 93 in epoch 0, gen_loss = 1.5633706399734983, disc_loss = 0.09913906547181467
Trained batch 94 in epoch 0, gen_loss = 1.561394547161303, disc_loss = 0.09826902134442016
Trained batch 95 in epoch 0, gen_loss = 1.5598452215393384, disc_loss = 0.0974054823066884
Trained batch 96 in epoch 0, gen_loss = 1.557430010480979, disc_loss = 0.0965944971870055
Trained batch 97 in epoch 0, gen_loss = 1.5580022347216704, disc_loss = 0.09573577945025599
Trained batch 98 in epoch 0, gen_loss = 1.5571226001989962, disc_loss = 0.09488462972821611
Trained batch 99 in epoch 0, gen_loss = 1.556690376996994, disc_loss = 0.09405247049406171
Trained batch 100 in epoch 0, gen_loss = 1.558614673000751, disc_loss = 0.09325283157205817
Trained batch 101 in epoch 0, gen_loss = 1.5581259528795879, disc_loss = 0.09245593424009926
Trained batch 102 in epoch 0, gen_loss = 1.5567303514017643, disc_loss = 0.09166157205851333
Trained batch 103 in epoch 0, gen_loss = 1.5555516206301176, disc_loss = 0.09088801194985326
Trained batch 104 in epoch 0, gen_loss = 1.5534636122839791, disc_loss = 0.09013547547871158
Trained batch 105 in epoch 0, gen_loss = 1.5524076065927181, disc_loss = 0.08939026953336203
Trained batch 106 in epoch 0, gen_loss = 1.5524705726409627, disc_loss = 0.08866286378736808
Trained batch 107 in epoch 0, gen_loss = 1.550689615585186, disc_loss = 0.08797477616031689
Trained batch 108 in epoch 0, gen_loss = 1.5494438464488458, disc_loss = 0.08731264896998438
Trained batch 109 in epoch 0, gen_loss = 1.548181647604162, disc_loss = 0.08676090444522826
Trained batch 110 in epoch 0, gen_loss = 1.5460444269953548, disc_loss = 0.08613042341259954
Trained batch 111 in epoch 0, gen_loss = 1.54347077863557, disc_loss = 0.08558872712144096
Trained batch 112 in epoch 0, gen_loss = 1.5438969958145006, disc_loss = 0.0849926686244069
Trained batch 113 in epoch 0, gen_loss = 1.5415677313219036, disc_loss = 0.08439831536165193
Trained batch 114 in epoch 0, gen_loss = 1.5394758504369985, disc_loss = 0.08385065650648398
Trained batch 115 in epoch 0, gen_loss = 1.5384931882907604, disc_loss = 0.08324795101512351
Trained batch 116 in epoch 0, gen_loss = 1.5367125293128512, disc_loss = 0.08269772988258518
Trained batch 117 in epoch 0, gen_loss = 1.5352302294666484, disc_loss = 0.082131439022783
Trained batch 118 in epoch 0, gen_loss = 1.5340874956435515, disc_loss = 0.08152069650715639
Trained batch 119 in epoch 0, gen_loss = 1.5347876797119777, disc_loss = 0.08095438911113888
Trained batch 120 in epoch 0, gen_loss = 1.5338701364422633, disc_loss = 0.0803765976447458
Trained batch 121 in epoch 0, gen_loss = 1.5328572607431254, disc_loss = 0.07980325178350092
Trained batch 122 in epoch 0, gen_loss = 1.533485703352021, disc_loss = 0.07922436242423407
Trained batch 123 in epoch 0, gen_loss = 1.534221819331569, disc_loss = 0.07865110819318122
Trained batch 124 in epoch 0, gen_loss = 1.532507246017456, disc_loss = 0.07813439369201661
Trained batch 125 in epoch 0, gen_loss = 1.5309901436169941, disc_loss = 0.07758630055283743
Trained batch 126 in epoch 0, gen_loss = 1.5305348109072587, disc_loss = 0.07704136272760358
Trained batch 127 in epoch 0, gen_loss = 1.5287975398823619, disc_loss = 0.0765340513898991
Trained batch 128 in epoch 0, gen_loss = 1.5273202084755713, disc_loss = 0.07602559619171675
Trained batch 129 in epoch 0, gen_loss = 1.5266438805139981, disc_loss = 0.07550005663114671
Trained batch 130 in epoch 0, gen_loss = 1.5253462554844281, disc_loss = 0.07500579554715571
Trained batch 131 in epoch 0, gen_loss = 1.5229549245400862, disc_loss = 0.07450128049998911
Trained batch 132 in epoch 0, gen_loss = 1.5243623803432722, disc_loss = 0.07401351569416492
Trained batch 133 in epoch 0, gen_loss = 1.522468989464774, disc_loss = 0.07355487678519715
Trained batch 134 in epoch 0, gen_loss = 1.5221871261243467, disc_loss = 0.07309252775308711
Trained batch 135 in epoch 0, gen_loss = 1.5211461598382277, disc_loss = 0.07265001850079417
Trained batch 136 in epoch 0, gen_loss = 1.5208328118289474, disc_loss = 0.07221377420368312
Trained batch 137 in epoch 0, gen_loss = 1.51975615300994, disc_loss = 0.07176977017745916
Trained batch 138 in epoch 0, gen_loss = 1.5191254727274395, disc_loss = 0.07131553608455139
Trained batch 139 in epoch 0, gen_loss = 1.5180421795163836, disc_loss = 0.0708667358749413
Trained batch 140 in epoch 0, gen_loss = 1.5168113801496248, disc_loss = 0.07041761121243661
Trained batch 141 in epoch 0, gen_loss = 1.5156777601846507, disc_loss = 0.06997659562391714
Trained batch 142 in epoch 0, gen_loss = 1.5144217631199977, disc_loss = 0.06954508355551667
Trained batch 143 in epoch 0, gen_loss = 1.51528999209404, disc_loss = 0.06913924002502528
Trained batch 144 in epoch 0, gen_loss = 1.5136842686554481, disc_loss = 0.06877855350231302
Trained batch 145 in epoch 0, gen_loss = 1.5122726233038184, disc_loss = 0.06837278437379697
Trained batch 146 in epoch 0, gen_loss = 1.5103598119450263, disc_loss = 0.06798987700065383
Trained batch 147 in epoch 0, gen_loss = 1.5091631283631195, disc_loss = 0.06759458264285648
Trained batch 148 in epoch 0, gen_loss = 1.5097136913529978, disc_loss = 0.06719768127338999
Trained batch 149 in epoch 0, gen_loss = 1.5079180693626404, disc_loss = 0.0668004527501762
Trained batch 150 in epoch 0, gen_loss = 1.5076040684782117, disc_loss = 0.06642012747732416
Trained batch 151 in epoch 0, gen_loss = 1.50575611152147, disc_loss = 0.06606516743225879
Trained batch 152 in epoch 0, gen_loss = 1.5040476555917777, disc_loss = 0.0656885829528952
Trained batch 153 in epoch 0, gen_loss = 1.5025134125313202, disc_loss = 0.06531709614028404
Trained batch 154 in epoch 0, gen_loss = 1.5016119103277883, disc_loss = 0.06494793572252797
Trained batch 155 in epoch 0, gen_loss = 1.5009191280756242, disc_loss = 0.06460180578944393
Trained batch 156 in epoch 0, gen_loss = 1.4993814920923512, disc_loss = 0.06423557404677864
Trained batch 157 in epoch 0, gen_loss = 1.497932931290397, disc_loss = 0.06387197480041863
Trained batch 158 in epoch 0, gen_loss = 1.499304475274476, disc_loss = 0.06352146644930139
Trained batch 159 in epoch 0, gen_loss = 1.4977266184985638, disc_loss = 0.06317131893883925
Trained batch 160 in epoch 0, gen_loss = 1.4970237520170508, disc_loss = 0.06282338163358454
Trained batch 161 in epoch 0, gen_loss = 1.4965365219999243, disc_loss = 0.062470770803176694
Trained batch 162 in epoch 0, gen_loss = 1.4957863414214432, disc_loss = 0.06213309021346682
Trained batch 163 in epoch 0, gen_loss = 1.4949261982266495, disc_loss = 0.06178937681734834
Trained batch 164 in epoch 0, gen_loss = 1.4948838465141527, disc_loss = 0.06145364887391527
Trained batch 165 in epoch 0, gen_loss = 1.4955237443188587, disc_loss = 0.06113175350151597
Trained batch 166 in epoch 0, gen_loss = 1.4953166153616535, disc_loss = 0.06081240139567031
Trained batch 167 in epoch 0, gen_loss = 1.4944834056354703, disc_loss = 0.060504566096434634
Trained batch 168 in epoch 0, gen_loss = 1.4946669587016812, disc_loss = 0.06020425718564253
Trained batch 169 in epoch 0, gen_loss = 1.4946662986979764, disc_loss = 0.059891474901643746
Trained batch 170 in epoch 0, gen_loss = 1.4938010067967644, disc_loss = 0.05958869928298028
Trained batch 171 in epoch 0, gen_loss = 1.4927657274312751, disc_loss = 0.05929265818071314
Trained batch 172 in epoch 0, gen_loss = 1.4927604074423024, disc_loss = 0.058990009987694506
Trained batch 173 in epoch 0, gen_loss = 1.492659709919458, disc_loss = 0.058687914077235365
Trained batch 174 in epoch 0, gen_loss = 1.491897531918117, disc_loss = 0.0583829789981246
Trained batch 175 in epoch 0, gen_loss = 1.4911252890120854, disc_loss = 0.0580904189476066
Trained batch 176 in epoch 0, gen_loss = 1.4904922772262057, disc_loss = 0.05780479171455412
Trained batch 177 in epoch 0, gen_loss = 1.4895596095685208, disc_loss = 0.05752346644784962
Trained batch 178 in epoch 0, gen_loss = 1.4879079677539164, disc_loss = 0.05725149423216974
Trained batch 179 in epoch 0, gen_loss = 1.4865543988015917, disc_loss = 0.056975850276649
Trained batch 180 in epoch 0, gen_loss = 1.4856591817423783, disc_loss = 0.05669545457384534
Trained batch 181 in epoch 0, gen_loss = 1.4842321577962938, disc_loss = 0.0564156932536267
Trained batch 182 in epoch 0, gen_loss = 1.4845853014721897, disc_loss = 0.05613502716808453
Trained batch 183 in epoch 0, gen_loss = 1.4848316292399946, disc_loss = 0.05585921323686109
Trained batch 184 in epoch 0, gen_loss = 1.4841757407059541, disc_loss = 0.05559580161714473
Trained batch 185 in epoch 0, gen_loss = 1.4830747964561626, disc_loss = 0.0553489778045645
Trained batch 186 in epoch 0, gen_loss = 1.481878949359139, disc_loss = 0.05510553494245212
Trained batch 187 in epoch 0, gen_loss = 1.482619155594643, disc_loss = 0.05484803676595317
Trained batch 188 in epoch 0, gen_loss = 1.4814407037048745, disc_loss = 0.05459056973023705
Trained batch 189 in epoch 0, gen_loss = 1.4807379854352851, disc_loss = 0.0543393108258514
Trained batch 190 in epoch 0, gen_loss = 1.479481843753635, disc_loss = 0.054076258356424524
Trained batch 191 in epoch 0, gen_loss = 1.4784519579261541, disc_loss = 0.05382841511891456
Trained batch 192 in epoch 0, gen_loss = 1.4777178072558783, disc_loss = 0.0535728289248721
Trained batch 193 in epoch 0, gen_loss = 1.4777798750965865, disc_loss = 0.05332322688725268
Trained batch 194 in epoch 0, gen_loss = 1.4770942082771887, disc_loss = 0.05307600303099323
Trained batch 195 in epoch 0, gen_loss = 1.4762066766923787, disc_loss = 0.05283085124956786
Trained batch 196 in epoch 0, gen_loss = 1.4758623862629614, disc_loss = 0.05258663649892974
Trained batch 197 in epoch 0, gen_loss = 1.4756615529156694, disc_loss = 0.05234287301727542
Trained batch 198 in epoch 0, gen_loss = 1.475324491160599, disc_loss = 0.05210607132673189
Trained batch 199 in epoch 0, gen_loss = 1.4757062524557114, disc_loss = 0.051877101880963894
Trained batch 200 in epoch 0, gen_loss = 1.4745503853802657, disc_loss = 0.051667066826137586
Trained batch 201 in epoch 0, gen_loss = 1.4749016862104434, disc_loss = 0.05144977663864962
Trained batch 202 in epoch 0, gen_loss = 1.4740920378069573, disc_loss = 0.051236274879278954
Trained batch 203 in epoch 0, gen_loss = 1.473060784971013, disc_loss = 0.051027622870534806
Trained batch 204 in epoch 0, gen_loss = 1.4735054184750813, disc_loss = 0.05081807648217896
Trained batch 205 in epoch 0, gen_loss = 1.4724466042611206, disc_loss = 0.05061162699655928
Trained batch 206 in epoch 0, gen_loss = 1.472735291517875, disc_loss = 0.05041855610772104
Trained batch 207 in epoch 0, gen_loss = 1.472095260826441, disc_loss = 0.050257022378411
Trained batch 208 in epoch 0, gen_loss = 1.4719920922694594, disc_loss = 0.05006841628290891
Trained batch 209 in epoch 0, gen_loss = 1.4709117571512857, disc_loss = 0.04986421120397392
Trained batch 210 in epoch 0, gen_loss = 1.470586035488906, disc_loss = 0.049654287502381475
Trained batch 211 in epoch 0, gen_loss = 1.469215229997095, disc_loss = 0.049451521380347606
Trained batch 212 in epoch 0, gen_loss = 1.4699653303119498, disc_loss = 0.04924834459285501
Trained batch 213 in epoch 0, gen_loss = 1.4703333054747536, disc_loss = 0.04903671831310352
Trained batch 214 in epoch 0, gen_loss = 1.4696616394575253, disc_loss = 0.04883920516342271
Trained batch 215 in epoch 0, gen_loss = 1.4689960689456374, disc_loss = 0.04863725996498639
Trained batch 216 in epoch 0, gen_loss = 1.4686141838126467, disc_loss = 0.04844012192111411
Trained batch 217 in epoch 0, gen_loss = 1.468507108885214, disc_loss = 0.048245409633878855
Trained batch 218 in epoch 0, gen_loss = 1.468301060537225, disc_loss = 0.048044217263505745
Trained batch 219 in epoch 0, gen_loss = 1.4674306696111505, disc_loss = 0.04785226010082459
Trained batch 220 in epoch 0, gen_loss = 1.4669504402989175, disc_loss = 0.0476652033947307
Trained batch 221 in epoch 0, gen_loss = 1.4662113318572174, disc_loss = 0.047471418255218514
Trained batch 222 in epoch 0, gen_loss = 1.464852872985361, disc_loss = 0.04728197006951399
Trained batch 223 in epoch 0, gen_loss = 1.464217133820057, disc_loss = 0.04709359540512586
Trained batch 224 in epoch 0, gen_loss = 1.463621162838406, disc_loss = 0.046902603252480426
Trained batch 225 in epoch 0, gen_loss = 1.4628789546215428, disc_loss = 0.04674091949786958
Trained batch 226 in epoch 0, gen_loss = 1.4629529268205954, disc_loss = 0.046590069905826044
Trained batch 227 in epoch 0, gen_loss = 1.4622938842104192, disc_loss = 0.046417062279049376
Trained batch 228 in epoch 0, gen_loss = 1.4614095323471004, disc_loss = 0.04624848794720774
Trained batch 229 in epoch 0, gen_loss = 1.4610127189885016, disc_loss = 0.046071593858220655
Trained batch 230 in epoch 0, gen_loss = 1.4604834225270655, disc_loss = 0.045893711326200334
Trained batch 231 in epoch 0, gen_loss = 1.4604944149995673, disc_loss = 0.04573279705725546
Trained batch 232 in epoch 0, gen_loss = 1.459361144401485, disc_loss = 0.045581956108224624
Trained batch 233 in epoch 0, gen_loss = 1.4587992954457927, disc_loss = 0.045420443046137564
Trained batch 234 in epoch 0, gen_loss = 1.4581818950937149, disc_loss = 0.04526675508773707
Trained batch 235 in epoch 0, gen_loss = 1.4594771013421528, disc_loss = 0.045106468294052626
Trained batch 236 in epoch 0, gen_loss = 1.4581437100841024, disc_loss = 0.04493504573634279
Trained batch 237 in epoch 0, gen_loss = 1.4575182204486943, disc_loss = 0.04477907544659341
Trained batch 238 in epoch 0, gen_loss = 1.4572872267607366, disc_loss = 0.04461915721282924
Trained batch 239 in epoch 0, gen_loss = 1.4563095902403196, disc_loss = 0.04445751007879153
Trained batch 240 in epoch 0, gen_loss = 1.4551169812926612, disc_loss = 0.04430168376717701
Trained batch 241 in epoch 0, gen_loss = 1.4540988285679461, disc_loss = 0.044148954087560456
Trained batch 242 in epoch 0, gen_loss = 1.4537129358009055, disc_loss = 0.04399106838958867
Trained batch 243 in epoch 0, gen_loss = 1.4536822638550744, disc_loss = 0.04384294878233407
Trained batch 244 in epoch 0, gen_loss = 1.452565630601377, disc_loss = 0.043695755316210644
Trained batch 245 in epoch 0, gen_loss = 1.452286512386508, disc_loss = 0.04353742811041392
Trained batch 246 in epoch 0, gen_loss = 1.4515270496669568, disc_loss = 0.043381941365266616
Trained batch 247 in epoch 0, gen_loss = 1.4505288634569413, disc_loss = 0.043229902450430895
Trained batch 248 in epoch 0, gen_loss = 1.4491369302971775, disc_loss = 0.04308188685504009
Trained batch 249 in epoch 0, gen_loss = 1.4502144303321838, disc_loss = 0.042931833988055584
Trained batch 250 in epoch 0, gen_loss = 1.4496090473881755, disc_loss = 0.0427736249192065
Trained batch 251 in epoch 0, gen_loss = 1.4502023439558724, disc_loss = 0.04262140740285672
Trained batch 252 in epoch 0, gen_loss = 1.449623300152805, disc_loss = 0.04247138059510308
Trained batch 253 in epoch 0, gen_loss = 1.449038293417983, disc_loss = 0.042323278189878764
Trained batch 254 in epoch 0, gen_loss = 1.4480060324949378, disc_loss = 0.04217954059953199
Trained batch 255 in epoch 0, gen_loss = 1.4489240562543273, disc_loss = 0.04203145642168238
Trained batch 256 in epoch 0, gen_loss = 1.4480340295264693, disc_loss = 0.04188596035067557
Trained batch 257 in epoch 0, gen_loss = 1.4475390476773875, disc_loss = 0.04174750973650998
Trained batch 258 in epoch 0, gen_loss = 1.4467758847019387, disc_loss = 0.04161001087083665
Trained batch 259 in epoch 0, gen_loss = 1.445997754427103, disc_loss = 0.04146670379066983
Trained batch 260 in epoch 0, gen_loss = 1.448016168513974, disc_loss = 0.04132543703348472
Trained batch 261 in epoch 0, gen_loss = 1.4481253314564246, disc_loss = 0.041192443966723356
Trained batch 262 in epoch 0, gen_loss = 1.447645675093502, disc_loss = 0.04105559786951644
Trained batch 263 in epoch 0, gen_loss = 1.4472733564449078, disc_loss = 0.04091068449744136
Trained batch 264 in epoch 0, gen_loss = 1.4466573445302136, disc_loss = 0.04076886590622928
Trained batch 265 in epoch 0, gen_loss = 1.447167778821816, disc_loss = 0.04063113381704526
Trained batch 266 in epoch 0, gen_loss = 1.447028502989351, disc_loss = 0.04049822077598102
Trained batch 267 in epoch 0, gen_loss = 1.4460396228441552, disc_loss = 0.04036214863864093
Trained batch 268 in epoch 0, gen_loss = 1.4454390107477464, disc_loss = 0.04022660970317415
Trained batch 269 in epoch 0, gen_loss = 1.4448056636033235, disc_loss = 0.04009008193647282
Trained batch 270 in epoch 0, gen_loss = 1.4448209996592956, disc_loss = 0.03995668965673617
Trained batch 271 in epoch 0, gen_loss = 1.4455225147745188, disc_loss = 0.039821614632862344
Trained batch 272 in epoch 0, gen_loss = 1.4451242510652367, disc_loss = 0.039690031204372644
Trained batch 273 in epoch 0, gen_loss = 1.4447848165992403, disc_loss = 0.03955619318162628
Trained batch 274 in epoch 0, gen_loss = 1.4444868564605713, disc_loss = 0.0394321468684145
Trained batch 275 in epoch 0, gen_loss = 1.444089532762334, disc_loss = 0.03930669528030642
Trained batch 276 in epoch 0, gen_loss = 1.4435768463120995, disc_loss = 0.03918446430563254
Trained batch 277 in epoch 0, gen_loss = 1.4428883559412236, disc_loss = 0.03906384190768941
Trained batch 278 in epoch 0, gen_loss = 1.4429372544784271, disc_loss = 0.038941628796192
Trained batch 279 in epoch 0, gen_loss = 1.4421504718916758, disc_loss = 0.03882856813808238
Trained batch 280 in epoch 0, gen_loss = 1.4416118720248077, disc_loss = 0.03870786746443511
Trained batch 281 in epoch 0, gen_loss = 1.4406218858475381, disc_loss = 0.038601685950288164
Trained batch 282 in epoch 0, gen_loss = 1.4400218476676268, disc_loss = 0.03847907370453299
Trained batch 283 in epoch 0, gen_loss = 1.4393377841358455, disc_loss = 0.0383584084977973
Trained batch 284 in epoch 0, gen_loss = 1.438296257403859, disc_loss = 0.038250146955741866
Trained batch 285 in epoch 0, gen_loss = 1.4381260075769224, disc_loss = 0.038140756818075126
Trained batch 286 in epoch 0, gen_loss = 1.4386118953651668, disc_loss = 0.03803165210492078
Trained batch 287 in epoch 0, gen_loss = 1.4379640569289525, disc_loss = 0.03791434908230763
Trained batch 288 in epoch 0, gen_loss = 1.4374679958119112, disc_loss = 0.03780435531393699
Trained batch 289 in epoch 0, gen_loss = 1.437309743618143, disc_loss = 0.0376942507481074
Trained batch 290 in epoch 0, gen_loss = 1.437345802988793, disc_loss = 0.03757944437547161
Trained batch 291 in epoch 0, gen_loss = 1.437199835091421, disc_loss = 0.03747158336743381
Trained batch 292 in epoch 0, gen_loss = 1.4364917270152642, disc_loss = 0.037363199150800046
Trained batch 293 in epoch 0, gen_loss = 1.4365784225820684, disc_loss = 0.03725231804039177
Trained batch 294 in epoch 0, gen_loss = 1.4358973240448256, disc_loss = 0.03714066005501328
Trained batch 295 in epoch 0, gen_loss = 1.4356701144495525, disc_loss = 0.03704010605626438
Trained batch 296 in epoch 0, gen_loss = 1.4352427207259617, disc_loss = 0.036944453592760246
Trained batch 297 in epoch 0, gen_loss = 1.4349962188893517, disc_loss = 0.03683996138134784
Trained batch 298 in epoch 0, gen_loss = 1.434894746362565, disc_loss = 0.0367322726974133
Trained batch 299 in epoch 0, gen_loss = 1.4348457968235016, disc_loss = 0.036626473815025144
Trained batch 300 in epoch 0, gen_loss = 1.4344043347526627, disc_loss = 0.03651450993570552
Trained batch 301 in epoch 0, gen_loss = 1.4340251072353085, disc_loss = 0.036407154826724915
Trained batch 302 in epoch 0, gen_loss = 1.4336706014356204, disc_loss = 0.03629906576437255
Trained batch 303 in epoch 0, gen_loss = 1.4336545490904857, disc_loss = 0.036193488073063475
Trained batch 304 in epoch 0, gen_loss = 1.43341992761268, disc_loss = 0.03609439944161377
Trained batch 305 in epoch 0, gen_loss = 1.432911606006373, disc_loss = 0.03599082588239457
Trained batch 306 in epoch 0, gen_loss = 1.432283199182939, disc_loss = 0.035881636304028505
Trained batch 307 in epoch 0, gen_loss = 1.4326901462945072, disc_loss = 0.035775532846961944
Trained batch 308 in epoch 0, gen_loss = 1.4324041743880336, disc_loss = 0.0356691682072278
Trained batch 309 in epoch 0, gen_loss = 1.4318627834320068, disc_loss = 0.03556280760319844
Trained batch 310 in epoch 0, gen_loss = 1.431480653032996, disc_loss = 0.03545937066451554
Trained batch 311 in epoch 0, gen_loss = 1.4313751715116012, disc_loss = 0.035364154927008666
Trained batch 312 in epoch 0, gen_loss = 1.4308987040870107, disc_loss = 0.03527101112110094
Trained batch 313 in epoch 0, gen_loss = 1.430200507306749, disc_loss = 0.03516733620440362
Trained batch 314 in epoch 0, gen_loss = 1.4297681532208881, disc_loss = 0.035070088720096954
Trained batch 315 in epoch 0, gen_loss = 1.429979290766052, disc_loss = 0.034972176287335024
Trained batch 316 in epoch 0, gen_loss = 1.429190144177867, disc_loss = 0.03487031733358649
Trained batch 317 in epoch 0, gen_loss = 1.4292035781362522, disc_loss = 0.03477243672904072
Trained batch 318 in epoch 0, gen_loss = 1.4292601432919876, disc_loss = 0.03468074498779861
Trained batch 319 in epoch 0, gen_loss = 1.4291306897997855, disc_loss = 0.034584364815964365
Trained batch 320 in epoch 0, gen_loss = 1.4286547706134594, disc_loss = 0.034486518765152706
Trained batch 321 in epoch 0, gen_loss = 1.428094362250026, disc_loss = 0.034389909298263306
Trained batch 322 in epoch 0, gen_loss = 1.4278857770719027, disc_loss = 0.034290774103294445
Trained batch 323 in epoch 0, gen_loss = 1.4284809044113866, disc_loss = 0.03419315092262731
Trained batch 324 in epoch 0, gen_loss = 1.4278237790327806, disc_loss = 0.03409476050963769
Trained batch 325 in epoch 0, gen_loss = 1.4272201617071234, disc_loss = 0.03400187665722304
Trained batch 326 in epoch 0, gen_loss = 1.4264245047846336, disc_loss = 0.033912862252318716
Trained batch 327 in epoch 0, gen_loss = 1.4266397640472506, disc_loss = 0.03381931751742164
Trained batch 328 in epoch 0, gen_loss = 1.4261490001504544, disc_loss = 0.03372318953442696
Trained batch 329 in epoch 0, gen_loss = 1.4256993113142071, disc_loss = 0.03363181972509306
Trained batch 330 in epoch 0, gen_loss = 1.4263916080451804, disc_loss = 0.033540224500304354
Trained batch 331 in epoch 0, gen_loss = 1.4258135962917144, disc_loss = 0.03344882978547185
Trained batch 332 in epoch 0, gen_loss = 1.42604813060245, disc_loss = 0.03335798537923588
Trained batch 333 in epoch 0, gen_loss = 1.4259527297077064, disc_loss = 0.03327212064711009
Trained batch 334 in epoch 0, gen_loss = 1.4255617550949553, disc_loss = 0.033191626852572854
Trained batch 335 in epoch 0, gen_loss = 1.4263002741194906, disc_loss = 0.03311074879630247
Trained batch 336 in epoch 0, gen_loss = 1.4256913301145289, disc_loss = 0.03303289502991767
Trained batch 337 in epoch 0, gen_loss = 1.42574014854149, disc_loss = 0.03295726417674071
Trained batch 338 in epoch 0, gen_loss = 1.424979528142991, disc_loss = 0.032878960489644324
Trained batch 339 in epoch 0, gen_loss = 1.4244314842364367, disc_loss = 0.03279357783783994
Trained batch 340 in epoch 0, gen_loss = 1.4238678898629555, disc_loss = 0.03271812011072647
Trained batch 341 in epoch 0, gen_loss = 1.424562202559577, disc_loss = 0.03263991956846865
Trained batch 342 in epoch 0, gen_loss = 1.4250563581205318, disc_loss = 0.03255578557452942
Trained batch 343 in epoch 0, gen_loss = 1.4247963601766631, disc_loss = 0.03247873025383194
Trained batch 344 in epoch 0, gen_loss = 1.424311974428702, disc_loss = 0.03240045681190879
Trained batch 345 in epoch 0, gen_loss = 1.4238882278431357, disc_loss = 0.03231875823186226
Trained batch 346 in epoch 0, gen_loss = 1.4232301375364365, disc_loss = 0.032236681885410755
Trained batch 347 in epoch 0, gen_loss = 1.422805510718247, disc_loss = 0.03215419137703212
Trained batch 348 in epoch 0, gen_loss = 1.4220087808319355, disc_loss = 0.03207533187926734
Trained batch 349 in epoch 0, gen_loss = 1.4214457569803511, disc_loss = 0.03199633841735444
Trained batch 350 in epoch 0, gen_loss = 1.42108867752586, disc_loss = 0.031918449467313384
Trained batch 351 in epoch 0, gen_loss = 1.4203958182849667, disc_loss = 0.03184227896682304
Trained batch 352 in epoch 0, gen_loss = 1.4201455376303567, disc_loss = 0.031763852697272096
Trained batch 353 in epoch 0, gen_loss = 1.4196434105183444, disc_loss = 0.03169240466895182
Trained batch 354 in epoch 0, gen_loss = 1.418920530399806, disc_loss = 0.03162059993614298
Trained batch 355 in epoch 0, gen_loss = 1.4183785587214353, disc_loss = 0.031543809910739115
Trained batch 356 in epoch 0, gen_loss = 1.4175959738696657, disc_loss = 0.03147218579945548
Trained batch 357 in epoch 0, gen_loss = 1.4179654647518136, disc_loss = 0.031401643967229935
Trained batch 358 in epoch 0, gen_loss = 1.4180412926713737, disc_loss = 0.031324305159784335
Trained batch 359 in epoch 0, gen_loss = 1.4181521942218145, disc_loss = 0.031246159345351368
Trained batch 360 in epoch 0, gen_loss = 1.4176903398413407, disc_loss = 0.03116584739936748
Trained batch 361 in epoch 0, gen_loss = 1.4173464020971436, disc_loss = 0.031086948447480015
Trained batch 362 in epoch 0, gen_loss = 1.4174689172713224, disc_loss = 0.03101247404804633
Trained batch 363 in epoch 0, gen_loss = 1.417311593398943, disc_loss = 0.03093789849599189
Trained batch 364 in epoch 0, gen_loss = 1.417156178004121, disc_loss = 0.03086326257453287
Trained batch 365 in epoch 0, gen_loss = 1.4169254000069664, disc_loss = 0.030793013690482277
Trained batch 366 in epoch 0, gen_loss = 1.4163915529562927, disc_loss = 0.03071715210929858
Trained batch 367 in epoch 0, gen_loss = 1.4160362725024638, disc_loss = 0.0306439278615669
Trained batch 368 in epoch 0, gen_loss = 1.4164196608189321, disc_loss = 0.030573386145594118
Trained batch 369 in epoch 0, gen_loss = 1.4160796168688181, disc_loss = 0.030500558624673334
Trained batch 370 in epoch 0, gen_loss = 1.4155402463080105, disc_loss = 0.03042700707051411
Trained batch 371 in epoch 0, gen_loss = 1.415493082936092, disc_loss = 0.030353506279718733
Trained batch 372 in epoch 0, gen_loss = 1.4150100281666815, disc_loss = 0.030279032413500682
Trained batch 373 in epoch 0, gen_loss = 1.414321452219856, disc_loss = 0.030203238614887138
Trained batch 374 in epoch 0, gen_loss = 1.4145832532246907, disc_loss = 0.030133518571344515
Trained batch 375 in epoch 0, gen_loss = 1.4137917785568441, disc_loss = 0.030069550574556528
Trained batch 376 in epoch 0, gen_loss = 1.4132383084739868, disc_loss = 0.030000833019710564
Trained batch 377 in epoch 0, gen_loss = 1.4128153992708399, disc_loss = 0.029931371205267076
Trained batch 378 in epoch 0, gen_loss = 1.4126193117655046, disc_loss = 0.029865230473267078
Trained batch 379 in epoch 0, gen_loss = 1.4123439525303088, disc_loss = 0.029806150197308805
Trained batch 380 in epoch 0, gen_loss = 1.4121122147467506, disc_loss = 0.029744036784432243
Trained batch 381 in epoch 0, gen_loss = 1.4118075280289375, disc_loss = 0.029675589337108746
Trained batch 382 in epoch 0, gen_loss = 1.4117462028100036, disc_loss = 0.029612811914810487
Trained batch 383 in epoch 0, gen_loss = 1.4112408415724833, disc_loss = 0.029545579062263034
Trained batch 384 in epoch 0, gen_loss = 1.4106812619543694, disc_loss = 0.029475191203792665
Trained batch 385 in epoch 0, gen_loss = 1.4108469387410218, disc_loss = 0.029405874146179928
Trained batch 386 in epoch 0, gen_loss = 1.411292800299573, disc_loss = 0.02933495886803145
Trained batch 387 in epoch 0, gen_loss = 1.4116218581642073, disc_loss = 0.029268263504041128
Trained batch 388 in epoch 0, gen_loss = 1.4115759517355873, disc_loss = 0.02919988842246513
Trained batch 389 in epoch 0, gen_loss = 1.411375618286622, disc_loss = 0.029132400176380403
Trained batch 390 in epoch 0, gen_loss = 1.411068505643274, disc_loss = 0.02906723627064358
Trained batch 391 in epoch 0, gen_loss = 1.4108629533830954, disc_loss = 0.02900068542286896
Trained batch 392 in epoch 0, gen_loss = 1.4112751547616857, disc_loss = 0.028937308765585243
Trained batch 393 in epoch 0, gen_loss = 1.411440076259187, disc_loss = 0.028870461063357875
Trained batch 394 in epoch 0, gen_loss = 1.4111870865278606, disc_loss = 0.028801886462370713
Trained batch 395 in epoch 0, gen_loss = 1.4109082249077884, disc_loss = 0.028734167043832273
Trained batch 396 in epoch 0, gen_loss = 1.41061564746972, disc_loss = 0.028670174311623633
Trained batch 397 in epoch 0, gen_loss = 1.4102909687775462, disc_loss = 0.028608495683406933
Trained batch 398 in epoch 0, gen_loss = 1.4098174849847205, disc_loss = 0.028541956789835933
Trained batch 399 in epoch 0, gen_loss = 1.4092939773201942, disc_loss = 0.02847593140875688
Trained batch 400 in epoch 0, gen_loss = 1.4093094811475189, disc_loss = 0.028413074428710314
Trained batch 401 in epoch 0, gen_loss = 1.4090127452689023, disc_loss = 0.028351740461869154
Trained batch 402 in epoch 0, gen_loss = 1.4087952567685036, disc_loss = 0.028290814072732574
Trained batch 403 in epoch 0, gen_loss = 1.408509864665494, disc_loss = 0.028232387305954287
Trained batch 404 in epoch 0, gen_loss = 1.4082421117358737, disc_loss = 0.02816894204258045
Trained batch 405 in epoch 0, gen_loss = 1.407746117396895, disc_loss = 0.028106372471694636
Trained batch 406 in epoch 0, gen_loss = 1.4077740758291333, disc_loss = 0.028046421562229952
Trained batch 407 in epoch 0, gen_loss = 1.4088114926628037, disc_loss = 0.0279946030575814
Trained batch 408 in epoch 0, gen_loss = 1.4088610553508283, disc_loss = 0.027938473215702385
Trained batch 409 in epoch 0, gen_loss = 1.4086704893809994, disc_loss = 0.027924528379254496
Trained batch 410 in epoch 0, gen_loss = 1.4079261145162467, disc_loss = 0.027891876490689235
Trained batch 411 in epoch 0, gen_loss = 1.408341447705204, disc_loss = 0.027845777229584517
Trained batch 412 in epoch 0, gen_loss = 1.4089593592913907, disc_loss = 0.027793791153824486
Trained batch 413 in epoch 0, gen_loss = 1.4089044620449416, disc_loss = 0.02774092050439089
Trained batch 414 in epoch 0, gen_loss = 1.4085774504994772, disc_loss = 0.027682114841629673
Trained batch 415 in epoch 0, gen_loss = 1.408424792667994, disc_loss = 0.027621842908746867
Trained batch 416 in epoch 0, gen_loss = 1.4084670489354671, disc_loss = 0.027560151647218017
Trained batch 417 in epoch 0, gen_loss = 1.4081065067263883, disc_loss = 0.027499797804677706
Trained batch 418 in epoch 0, gen_loss = 1.4078580286167117, disc_loss = 0.027439162446861655
Trained batch 419 in epoch 0, gen_loss = 1.4072753276143755, disc_loss = 0.02737963239640175
Trained batch 420 in epoch 0, gen_loss = 1.406610000728145, disc_loss = 0.02732022751162532
Trained batch 421 in epoch 0, gen_loss = 1.4066993441626925, disc_loss = 0.027261295744275313
Trained batch 422 in epoch 0, gen_loss = 1.406137236184826, disc_loss = 0.02720396835621156
Trained batch 423 in epoch 0, gen_loss = 1.4059077116116039, disc_loss = 0.027145060106567195
Trained batch 424 in epoch 0, gen_loss = 1.4059397630130543, disc_loss = 0.027086381260305645
Trained batch 425 in epoch 0, gen_loss = 1.4055278133338607, disc_loss = 0.02702644432975775
Trained batch 426 in epoch 0, gen_loss = 1.405196218914952, disc_loss = 0.02697265904071791
Trained batch 427 in epoch 0, gen_loss = 1.4058002623442178, disc_loss = 0.026918282905902504
Trained batch 428 in epoch 0, gen_loss = 1.4053359615219223, disc_loss = 0.02686358590519147
Trained batch 429 in epoch 0, gen_loss = 1.405784033897311, disc_loss = 0.02680903963668835
Trained batch 430 in epoch 0, gen_loss = 1.405374967028536, disc_loss = 0.026754272182789692
Trained batch 431 in epoch 0, gen_loss = 1.4051855932231303, disc_loss = 0.026696916814587354
Trained batch 432 in epoch 0, gen_loss = 1.404943587598294, disc_loss = 0.026639855236103262
Trained batch 433 in epoch 0, gen_loss = 1.4043559322159411, disc_loss = 0.02658528978196037
Trained batch 434 in epoch 0, gen_loss = 1.4039863136993058, disc_loss = 0.0265346125266033
Trained batch 435 in epoch 0, gen_loss = 1.4043508989548465, disc_loss = 0.026482651544170916
Trained batch 436 in epoch 0, gen_loss = 1.4044282182676022, disc_loss = 0.026433140827977958
Trained batch 437 in epoch 0, gen_loss = 1.4043561691018545, disc_loss = 0.026382522557577177
Trained batch 438 in epoch 0, gen_loss = 1.404229578233254, disc_loss = 0.026331619042394033
Trained batch 439 in epoch 0, gen_loss = 1.4040386592799967, disc_loss = 0.02627960953660394
Trained batch 440 in epoch 0, gen_loss = 1.4035888704853534, disc_loss = 0.026229716047049077
Trained batch 441 in epoch 0, gen_loss = 1.4033469244905188, disc_loss = 0.026183037480815605
Trained batch 442 in epoch 0, gen_loss = 1.4031181488833633, disc_loss = 0.026130543683779595
Trained batch 443 in epoch 0, gen_loss = 1.4032613154467162, disc_loss = 0.026078116011843587
Trained batch 444 in epoch 0, gen_loss = 1.4032685049464193, disc_loss = 0.026024246211634593
Trained batch 445 in epoch 0, gen_loss = 1.4030530118621518, disc_loss = 0.025974445568602282
Trained batch 446 in epoch 0, gen_loss = 1.403206535367091, disc_loss = 0.025927293005501496
Trained batch 447 in epoch 0, gen_loss = 1.4030194615146943, disc_loss = 0.02587806526103772
Trained batch 448 in epoch 0, gen_loss = 1.4027326545099372, disc_loss = 0.025828634603944647
Trained batch 449 in epoch 0, gen_loss = 1.4023736219935947, disc_loss = 0.025780760988903542
Trained batch 450 in epoch 0, gen_loss = 1.401925242925166, disc_loss = 0.025731897326971006
Trained batch 451 in epoch 0, gen_loss = 1.4018493231418914, disc_loss = 0.025682799224494502
Trained batch 452 in epoch 0, gen_loss = 1.4024748320611107, disc_loss = 0.02563573814369327
Trained batch 453 in epoch 0, gen_loss = 1.4018916151597112, disc_loss = 0.025592272282713442
Trained batch 454 in epoch 0, gen_loss = 1.4019447386919797, disc_loss = 0.02554512075609067
Trained batch 455 in epoch 0, gen_loss = 1.4015733131714034, disc_loss = 0.025494914169509064
Trained batch 456 in epoch 0, gen_loss = 1.4011398856436397, disc_loss = 0.025447515568021415
Trained batch 457 in epoch 0, gen_loss = 1.4011924909712445, disc_loss = 0.025400278415717997
Trained batch 458 in epoch 0, gen_loss = 1.402253350141521, disc_loss = 0.025350785317114495
Trained batch 459 in epoch 0, gen_loss = 1.4019533527934034, disc_loss = 0.02530610919120195
Trained batch 460 in epoch 0, gen_loss = 1.4017414956185927, disc_loss = 0.025255912686587025
Trained batch 461 in epoch 0, gen_loss = 1.401508523788287, disc_loss = 0.02520758522476888
Trained batch 462 in epoch 0, gen_loss = 1.4008539142670435, disc_loss = 0.025159176707581554
Trained batch 463 in epoch 0, gen_loss = 1.4003944895390807, disc_loss = 0.025109208410742274
Trained batch 464 in epoch 0, gen_loss = 1.4001122384942988, disc_loss = 0.025058738736596
Trained batch 465 in epoch 0, gen_loss = 1.399867877172298, disc_loss = 0.025008769045372057
Trained batch 466 in epoch 0, gen_loss = 1.3998896909730083, disc_loss = 0.02496059118456963
Trained batch 467 in epoch 0, gen_loss = 1.3994398071215703, disc_loss = 0.024916206434783008
Trained batch 468 in epoch 0, gen_loss = 1.3989552709339523, disc_loss = 0.024868945558386635
Trained batch 469 in epoch 0, gen_loss = 1.3990430443844897, disc_loss = 0.02481998080942542
Trained batch 470 in epoch 0, gen_loss = 1.3987556017634721, disc_loss = 0.024770487111749923
Trained batch 471 in epoch 0, gen_loss = 1.3982018532894425, disc_loss = 0.02472308976181104
Trained batch 472 in epoch 0, gen_loss = 1.3980697562276183, disc_loss = 0.024673908298646137
Trained batch 473 in epoch 0, gen_loss = 1.3979040738902515, disc_loss = 0.02462619276793933
Trained batch 474 in epoch 0, gen_loss = 1.3974408729452836, disc_loss = 0.024579564360901713
Trained batch 475 in epoch 0, gen_loss = 1.3969431256546694, disc_loss = 0.02454104706470878
Trained batch 476 in epoch 0, gen_loss = 1.3970733596094, disc_loss = 0.024504612687588582
Trained batch 477 in epoch 0, gen_loss = 1.3965549002631439, disc_loss = 0.02446063755325599
Trained batch 478 in epoch 0, gen_loss = 1.3968824815152832, disc_loss = 0.024413115235088326
Trained batch 479 in epoch 0, gen_loss = 1.3968361660838127, disc_loss = 0.024366535049436304
Trained batch 480 in epoch 0, gen_loss = 1.3963905793465596, disc_loss = 0.02431976429420076
Trained batch 481 in epoch 0, gen_loss = 1.3960578990675108, disc_loss = 0.024272421864489347
Trained batch 482 in epoch 0, gen_loss = 1.3956743034516803, disc_loss = 0.02422558120958021
Trained batch 483 in epoch 0, gen_loss = 1.3958291532086933, disc_loss = 0.0241797019971423
Trained batch 484 in epoch 0, gen_loss = 1.3964777826033916, disc_loss = 0.02413455045604406
Trained batch 485 in epoch 0, gen_loss = 1.3961355458071203, disc_loss = 0.024089927467232024
Trained batch 486 in epoch 0, gen_loss = 1.3960312027216448, disc_loss = 0.024045127224764217
Trained batch 487 in epoch 0, gen_loss = 1.3959650128591257, disc_loss = 0.024002471461855867
Trained batch 488 in epoch 0, gen_loss = 1.395505895400096, disc_loss = 0.023959001174609886
Trained batch 489 in epoch 0, gen_loss = 1.395447546608594, disc_loss = 0.023917717665994577
Trained batch 490 in epoch 0, gen_loss = 1.395037505874323, disc_loss = 0.023877162864486746
Trained batch 491 in epoch 0, gen_loss = 1.3945681840423647, disc_loss = 0.02383588371032705
Trained batch 492 in epoch 0, gen_loss = 1.394995094796465, disc_loss = 0.023793787908698783
Trained batch 493 in epoch 0, gen_loss = 1.394517750633873, disc_loss = 0.02375033440380376
Trained batch 494 in epoch 0, gen_loss = 1.3940460048540675, disc_loss = 0.023706287115276087
Trained batch 495 in epoch 0, gen_loss = 1.3945004495401536, disc_loss = 0.023662818231265016
Trained batch 496 in epoch 0, gen_loss = 1.3947987045560564, disc_loss = 0.023620634909177676
Trained batch 497 in epoch 0, gen_loss = 1.3944908191401317, disc_loss = 0.02357743286745563
Trained batch 498 in epoch 0, gen_loss = 1.3941549863031728, disc_loss = 0.023533077702208055
Trained batch 499 in epoch 0, gen_loss = 1.3941953704357146, disc_loss = 0.02349119211710058
Trained batch 500 in epoch 0, gen_loss = 1.3939877091767545, disc_loss = 0.023447571885344496
Trained batch 501 in epoch 0, gen_loss = 1.3935145621755685, disc_loss = 0.023405964409077235
Trained batch 502 in epoch 0, gen_loss = 1.3930952902105647, disc_loss = 0.023364950102665063
Trained batch 503 in epoch 0, gen_loss = 1.3928999941027354, disc_loss = 0.02333464639031306
Trained batch 504 in epoch 0, gen_loss = 1.3923995728539948, disc_loss = 0.023310358458807193
Trained batch 505 in epoch 0, gen_loss = 1.392580790717611, disc_loss = 0.023276387697054448
Trained batch 506 in epoch 0, gen_loss = 1.3924776532005747, disc_loss = 0.02323473775525131
Trained batch 507 in epoch 0, gen_loss = 1.3923742578724239, disc_loss = 0.023194381235007885
Trained batch 508 in epoch 0, gen_loss = 1.3921266150146665, disc_loss = 0.02315773886389672
Trained batch 509 in epoch 0, gen_loss = 1.391773692299338, disc_loss = 0.023120040845755925
Trained batch 510 in epoch 0, gen_loss = 1.391741736294472, disc_loss = 0.023084037387953185
Trained batch 511 in epoch 0, gen_loss = 1.3914285944774747, disc_loss = 0.023049893317192982
Trained batch 512 in epoch 0, gen_loss = 1.3913612107784428, disc_loss = 0.023010693960932044
Trained batch 513 in epoch 0, gen_loss = 1.3910755927924516, disc_loss = 0.022969341379135543
Trained batch 514 in epoch 0, gen_loss = 1.3915861597338925, disc_loss = 0.022930015476863578
Trained batch 515 in epoch 0, gen_loss = 1.391601215499316, disc_loss = 0.02289161515668533
Trained batch 516 in epoch 0, gen_loss = 1.3915349812295497, disc_loss = 0.022850798693354057
Trained batch 517 in epoch 0, gen_loss = 1.3914070845110535, disc_loss = 0.02280955042188419
Trained batch 518 in epoch 0, gen_loss = 1.3912416675876331, disc_loss = 0.022768980751230395
Trained batch 519 in epoch 0, gen_loss = 1.3912857211553133, disc_loss = 0.022728984038202234
Trained batch 520 in epoch 0, gen_loss = 1.3914649285190166, disc_loss = 0.022688890225254
Trained batch 521 in epoch 0, gen_loss = 1.3918101657396076, disc_loss = 0.022649294496255204
Trained batch 522 in epoch 0, gen_loss = 1.391873972137845, disc_loss = 0.022610856782169533
Trained batch 523 in epoch 0, gen_loss = 1.3918235443020595, disc_loss = 0.022571300790478113
Trained batch 524 in epoch 0, gen_loss = 1.3917141103744506, disc_loss = 0.022530425102671697
Trained batch 525 in epoch 0, gen_loss = 1.3915074377005545, disc_loss = 0.02248946509785249
Trained batch 526 in epoch 0, gen_loss = 1.3912907187355086, disc_loss = 0.022450759818917053
Trained batch 527 in epoch 0, gen_loss = 1.3909964362780254, disc_loss = 0.022412246598722766
Trained batch 528 in epoch 0, gen_loss = 1.3905390057086042, disc_loss = 0.022373343164731514
Trained batch 529 in epoch 0, gen_loss = 1.3904501496620898, disc_loss = 0.022333665444287207
Trained batch 530 in epoch 0, gen_loss = 1.3903055296554854, disc_loss = 0.02229436682344269
Trained batch 531 in epoch 0, gen_loss = 1.3905594750006396, disc_loss = 0.022256013171185383
Trained batch 532 in epoch 0, gen_loss = 1.3905646713768565, disc_loss = 0.022217104935059306
Trained batch 533 in epoch 0, gen_loss = 1.390386991509784, disc_loss = 0.022180522418596645
Trained batch 534 in epoch 0, gen_loss = 1.3901322257853, disc_loss = 0.022143786251501433
Trained batch 535 in epoch 0, gen_loss = 1.3899317641756428, disc_loss = 0.022105027491890535
Trained batch 536 in epoch 0, gen_loss = 1.389545803407495, disc_loss = 0.022065818073918254
Trained batch 537 in epoch 0, gen_loss = 1.3892143286736924, disc_loss = 0.02202764720734742
Trained batch 538 in epoch 0, gen_loss = 1.3887194242459724, disc_loss = 0.02199251114598999
Trained batch 539 in epoch 0, gen_loss = 1.3881754884013424, disc_loss = 0.02196916499136326
Trained batch 540 in epoch 0, gen_loss = 1.388205418304683, disc_loss = 0.021951951321288462
Trained batch 541 in epoch 0, gen_loss = 1.3885559653004158, disc_loss = 0.02192336464849751
Trained batch 542 in epoch 0, gen_loss = 1.3883424426530167, disc_loss = 0.021889448400653735
Trained batch 543 in epoch 0, gen_loss = 1.3879900423481184, disc_loss = 0.021854965294230224
Trained batch 544 in epoch 0, gen_loss = 1.3879788204070624, disc_loss = 0.021823326580935595
Trained batch 545 in epoch 0, gen_loss = 1.3874550885333246, disc_loss = 0.021794843540958474
Trained batch 546 in epoch 0, gen_loss = 1.387269024657157, disc_loss = 0.021762330508773884
Trained batch 547 in epoch 0, gen_loss = 1.3868095959625104, disc_loss = 0.021728822937444273
Trained batch 548 in epoch 0, gen_loss = 1.3865086643639375, disc_loss = 0.021704594502675065
Trained batch 549 in epoch 0, gen_loss = 1.3864797141335228, disc_loss = 0.021676905176136643
Trained batch 550 in epoch 0, gen_loss = 1.3860466302847472, disc_loss = 0.0216463675902913
Trained batch 551 in epoch 0, gen_loss = 1.3863052723632343, disc_loss = 0.021614573602151275
Trained batch 552 in epoch 0, gen_loss = 1.3862397653500382, disc_loss = 0.021583168196262856
Trained batch 553 in epoch 0, gen_loss = 1.3860120949762393, disc_loss = 0.021547741870041128
Trained batch 554 in epoch 0, gen_loss = 1.3857927569397934, disc_loss = 0.02151190146346585
Trained batch 555 in epoch 0, gen_loss = 1.3856340007816288, disc_loss = 0.02147723598930844
Trained batch 556 in epoch 0, gen_loss = 1.3858324180171562, disc_loss = 0.021442962495845874
Trained batch 557 in epoch 0, gen_loss = 1.3860505219001495, disc_loss = 0.02140914219807947
Trained batch 558 in epoch 0, gen_loss = 1.385882986039723, disc_loss = 0.021377229020341046
Trained batch 559 in epoch 0, gen_loss = 1.3855561275567327, disc_loss = 0.021345577964634037
Trained batch 560 in epoch 0, gen_loss = 1.3852056670741388, disc_loss = 0.02131251502369569
Trained batch 561 in epoch 0, gen_loss = 1.3851965827025552, disc_loss = 0.02128002215802398
Trained batch 562 in epoch 0, gen_loss = 1.384959483654842, disc_loss = 0.021245199748394318
Trained batch 563 in epoch 0, gen_loss = 1.3845587935008057, disc_loss = 0.021210918855458723
Trained batch 564 in epoch 0, gen_loss = 1.3842611135634701, disc_loss = 0.021177704220398667
Trained batch 565 in epoch 0, gen_loss = 1.3839633260514628, disc_loss = 0.021146543787803843
Trained batch 566 in epoch 0, gen_loss = 1.3836223303325592, disc_loss = 0.021112175077295202
Trained batch 567 in epoch 0, gen_loss = 1.3841722506872365, disc_loss = 0.021077620140588383
Trained batch 568 in epoch 0, gen_loss = 1.3839084722874244, disc_loss = 0.021044755609450707
Trained batch 569 in epoch 0, gen_loss = 1.3834414488390872, disc_loss = 0.021011338104379544
Trained batch 570 in epoch 0, gen_loss = 1.3831085490679365, disc_loss = 0.020976859485141726
Trained batch 571 in epoch 0, gen_loss = 1.3828681924126365, disc_loss = 0.02094349374370226
Trained batch 572 in epoch 0, gen_loss = 1.3823919718594244, disc_loss = 0.02092807972905296
Trained batch 573 in epoch 0, gen_loss = 1.3820780287220917, disc_loss = 0.020927391549002847
Trained batch 574 in epoch 0, gen_loss = 1.382031424149223, disc_loss = 0.020935924550639872
Trained batch 575 in epoch 0, gen_loss = 1.3817858489023314, disc_loss = 0.020918729875322443
Trained batch 576 in epoch 0, gen_loss = 1.3813264088986033, disc_loss = 0.02088854073339418
Trained batch 577 in epoch 0, gen_loss = 1.381027969934536, disc_loss = 0.020855630287952127
Trained batch 578 in epoch 0, gen_loss = 1.3808608331004983, disc_loss = 0.020824070281987697
Trained batch 579 in epoch 0, gen_loss = 1.3804953024305147, disc_loss = 0.020792071470300315
Trained batch 580 in epoch 0, gen_loss = 1.380030701780073, disc_loss = 0.020759737639240727
Trained batch 581 in epoch 0, gen_loss = 1.379924276850068, disc_loss = 0.020728486695301262
Trained batch 582 in epoch 0, gen_loss = 1.3794361275219795, disc_loss = 0.020697073096019657
Trained batch 583 in epoch 0, gen_loss = 1.3792839115613127, disc_loss = 0.02066387179325979
Trained batch 584 in epoch 0, gen_loss = 1.3789361499313615, disc_loss = 0.020630687322969046
Trained batch 585 in epoch 0, gen_loss = 1.379400479712177, disc_loss = 0.02059818545329375
Trained batch 586 in epoch 0, gen_loss = 1.3791930222633142, disc_loss = 0.020566475925906807
Trained batch 587 in epoch 0, gen_loss = 1.3789471987964346, disc_loss = 0.020534710430177436
Trained batch 588 in epoch 0, gen_loss = 1.3785673912190823, disc_loss = 0.020504879886766733
Trained batch 589 in epoch 0, gen_loss = 1.3786520832676, disc_loss = 0.020475576545103943
Trained batch 590 in epoch 0, gen_loss = 1.3782801131911688, disc_loss = 0.0204437305672526
Trained batch 591 in epoch 0, gen_loss = 1.378495613465438, disc_loss = 0.020415393753225815
Trained batch 592 in epoch 0, gen_loss = 1.378262571701513, disc_loss = 0.02038827486859217
Trained batch 593 in epoch 0, gen_loss = 1.3782479042557354, disc_loss = 0.020357936401992585
Trained batch 594 in epoch 0, gen_loss = 1.3782802816198654, disc_loss = 0.02032768488587702
Trained batch 595 in epoch 0, gen_loss = 1.3783122267099035, disc_loss = 0.020297854254334766
Trained batch 596 in epoch 0, gen_loss = 1.3782740212365412, disc_loss = 0.020267356309175515
Trained batch 597 in epoch 0, gen_loss = 1.378167647581834, disc_loss = 0.020235713958128176
Trained batch 598 in epoch 0, gen_loss = 1.377831478946794, disc_loss = 0.020205274472465562
Trained batch 599 in epoch 0, gen_loss = 1.3779287707805634, disc_loss = 0.02017435282721029
Trained batch 600 in epoch 0, gen_loss = 1.3775121039043052, disc_loss = 0.020145372045381357
Trained batch 601 in epoch 0, gen_loss = 1.3774160122950607, disc_loss = 0.020115680332207415
Trained batch 602 in epoch 0, gen_loss = 1.37788587996418, disc_loss = 0.020085725724229134
Trained batch 603 in epoch 0, gen_loss = 1.37753085801933, disc_loss = 0.02005566362158969
Trained batch 604 in epoch 0, gen_loss = 1.377516135302457, disc_loss = 0.02002822875953472
Trained batch 605 in epoch 0, gen_loss = 1.3776220811082192, disc_loss = 0.019998820154718662
Trained batch 606 in epoch 0, gen_loss = 1.3773832784649567, disc_loss = 0.019969003009793995
Trained batch 607 in epoch 0, gen_loss = 1.3771859521144314, disc_loss = 0.019938442527506452
Trained batch 608 in epoch 0, gen_loss = 1.377054195490181, disc_loss = 0.019911023121012134
Trained batch 609 in epoch 0, gen_loss = 1.376950780094647, disc_loss = 0.019884285825060407
Trained batch 610 in epoch 0, gen_loss = 1.3769644042278857, disc_loss = 0.019854829169934807
Trained batch 611 in epoch 0, gen_loss = 1.3767611265572068, disc_loss = 0.01982642723220017
Trained batch 612 in epoch 0, gen_loss = 1.3764939500690478, disc_loss = 0.01979894439354053
Trained batch 613 in epoch 0, gen_loss = 1.376506429541771, disc_loss = 0.01976896171076587
Trained batch 614 in epoch 0, gen_loss = 1.3763154274079858, disc_loss = 0.019740017016827153
Trained batch 615 in epoch 0, gen_loss = 1.3760191879489205, disc_loss = 0.01971094660644643
Trained batch 616 in epoch 0, gen_loss = 1.3758290953922117, disc_loss = 0.019686972472410667
Trained batch 617 in epoch 0, gen_loss = 1.3757210557129005, disc_loss = 0.019666151906714797
Trained batch 618 in epoch 0, gen_loss = 1.3756820762677415, disc_loss = 0.019638870394207922
Trained batch 619 in epoch 0, gen_loss = 1.3753899401234042, disc_loss = 0.01961323979907789
Trained batch 620 in epoch 0, gen_loss = 1.375795261103558, disc_loss = 0.0195881378851552
Trained batch 621 in epoch 0, gen_loss = 1.375601605587067, disc_loss = 0.01955953987268132
Trained batch 622 in epoch 0, gen_loss = 1.375202044820709, disc_loss = 0.019531910450655197
Trained batch 623 in epoch 0, gen_loss = 1.3752932372765663, disc_loss = 0.019503711100416973
Trained batch 624 in epoch 0, gen_loss = 1.3750158967971802, disc_loss = 0.019475489554181696
Trained batch 625 in epoch 0, gen_loss = 1.3748809377225444, disc_loss = 0.01944824580226641
Trained batch 626 in epoch 0, gen_loss = 1.3750144138670803, disc_loss = 0.0194235169436438
Trained batch 627 in epoch 0, gen_loss = 1.3747934382052938, disc_loss = 0.01939746391608018
Trained batch 628 in epoch 0, gen_loss = 1.374566295188637, disc_loss = 0.019372511319357116
Trained batch 629 in epoch 0, gen_loss = 1.3745440753679428, disc_loss = 0.019345404374383625
Trained batch 630 in epoch 0, gen_loss = 1.374425153724743, disc_loss = 0.019321054250825486
Trained batch 631 in epoch 0, gen_loss = 1.374266116490847, disc_loss = 0.01929540043074897
Trained batch 632 in epoch 0, gen_loss = 1.3742767060160825, disc_loss = 0.01926777620967566
Trained batch 633 in epoch 0, gen_loss = 1.3740709435300495, disc_loss = 0.019241137494338964
Trained batch 634 in epoch 0, gen_loss = 1.3740245588182465, disc_loss = 0.01921587373885348
Trained batch 635 in epoch 0, gen_loss = 1.373959391372009, disc_loss = 0.019192287856537215
Trained batch 636 in epoch 0, gen_loss = 1.3736356620324464, disc_loss = 0.019167382054080605
Trained batch 637 in epoch 0, gen_loss = 1.3736983821683544, disc_loss = 0.01914150184086089
Trained batch 638 in epoch 0, gen_loss = 1.3738184549812233, disc_loss = 0.019113410083163116
Trained batch 639 in epoch 0, gen_loss = 1.3736449103802442, disc_loss = 0.019088276866386877
Trained batch 640 in epoch 0, gen_loss = 1.3734526271567145, disc_loss = 0.019063029284974015
Trained batch 641 in epoch 0, gen_loss = 1.373286270092581, disc_loss = 0.019039036874366328
Trained batch 642 in epoch 0, gen_loss = 1.3728637999361077, disc_loss = 0.019016709117129053
Trained batch 643 in epoch 0, gen_loss = 1.3726548297064645, disc_loss = 0.01899110792517107
Trained batch 644 in epoch 0, gen_loss = 1.3724591610043548, disc_loss = 0.01896434722237231
Trained batch 645 in epoch 0, gen_loss = 1.3720994204190493, disc_loss = 0.01893736296437894
Trained batch 646 in epoch 0, gen_loss = 1.3719165691820878, disc_loss = 0.018909826479964476
Trained batch 647 in epoch 0, gen_loss = 1.3716845400171516, disc_loss = 0.018882356764264346
Trained batch 648 in epoch 0, gen_loss = 1.3714654684434135, disc_loss = 0.01885599205474899
Trained batch 649 in epoch 0, gen_loss = 1.371091213959914, disc_loss = 0.018829922577043853
Trained batch 650 in epoch 0, gen_loss = 1.3711222932086014, disc_loss = 0.018803415992390222
Trained batch 651 in epoch 0, gen_loss = 1.3708476303545243, disc_loss = 0.01877626830814092
Trained batch 652 in epoch 0, gen_loss = 1.3704948180667473, disc_loss = 0.0187501281093033
Trained batch 653 in epoch 0, gen_loss = 1.3705387286819084, disc_loss = 0.01872362100625331
Trained batch 654 in epoch 0, gen_loss = 1.370959567295686, disc_loss = 0.018697454404078766
Trained batch 655 in epoch 0, gen_loss = 1.3707482882025765, disc_loss = 0.018671329953798617
Trained batch 656 in epoch 0, gen_loss = 1.3706163120777821, disc_loss = 0.018645711853934377
Trained batch 657 in epoch 0, gen_loss = 1.3703950138077547, disc_loss = 0.018620114981750237
Trained batch 658 in epoch 0, gen_loss = 1.3702020124166254, disc_loss = 0.018594444846686355
Trained batch 659 in epoch 0, gen_loss = 1.3704900102181867, disc_loss = 0.018568725056353617
Trained batch 660 in epoch 0, gen_loss = 1.3702752197023238, disc_loss = 0.0185426160733324
Trained batch 661 in epoch 0, gen_loss = 1.3705117407162024, disc_loss = 0.018516042687067778
Trained batch 662 in epoch 0, gen_loss = 1.3707355215898287, disc_loss = 0.01848986431437251
Trained batch 663 in epoch 0, gen_loss = 1.370758518576622, disc_loss = 0.01846340215250889
Trained batch 664 in epoch 0, gen_loss = 1.370937204540224, disc_loss = 0.01843674671205979
Trained batch 665 in epoch 0, gen_loss = 1.3707554621381444, disc_loss = 0.018410671960496745
Trained batch 666 in epoch 0, gen_loss = 1.3709580426452042, disc_loss = 0.0183844754580238
Trained batch 667 in epoch 0, gen_loss = 1.3708919814960685, disc_loss = 0.018358560130704183
Trained batch 668 in epoch 0, gen_loss = 1.3708628649490653, disc_loss = 0.01833271407309964
Trained batch 669 in epoch 0, gen_loss = 1.3708472474297482, disc_loss = 0.018307734420696803
Trained batch 670 in epoch 0, gen_loss = 1.3708896015155867, disc_loss = 0.018282753567908087
Trained batch 671 in epoch 0, gen_loss = 1.3706393060939652, disc_loss = 0.01825745516907773
Trained batch 672 in epoch 0, gen_loss = 1.3705051016134457, disc_loss = 0.018231659226761617
Trained batch 673 in epoch 0, gen_loss = 1.3702769711038834, disc_loss = 0.018206569014492968
Trained batch 674 in epoch 0, gen_loss = 1.370039964781867, disc_loss = 0.01818219764985972
Trained batch 675 in epoch 0, gen_loss = 1.3697908000480494, disc_loss = 0.018157650282284103
Trained batch 676 in epoch 0, gen_loss = 1.3697530371047546, disc_loss = 0.01813354304588594
Trained batch 677 in epoch 0, gen_loss = 1.3693896257771856, disc_loss = 0.018109480373748196
Trained batch 678 in epoch 0, gen_loss = 1.369070335761788, disc_loss = 0.01808456380903688
Trained batch 679 in epoch 0, gen_loss = 1.3687132507562638, disc_loss = 0.018060165713712408
Trained batch 680 in epoch 0, gen_loss = 1.3683693848342446, disc_loss = 0.018035446783075063
Trained batch 681 in epoch 0, gen_loss = 1.3682500323242457, disc_loss = 0.01801069714746894
Trained batch 682 in epoch 0, gen_loss = 1.3679504638884112, disc_loss = 0.0179870357785693
Trained batch 683 in epoch 0, gen_loss = 1.3677339993025128, disc_loss = 0.01796370198557355
Trained batch 684 in epoch 0, gen_loss = 1.3677064015047393, disc_loss = 0.017938820466766283
Trained batch 685 in epoch 0, gen_loss = 1.367437298721892, disc_loss = 0.017915622321019932
Trained batch 686 in epoch 0, gen_loss = 1.3673984331161522, disc_loss = 0.01789317189158636
Trained batch 687 in epoch 0, gen_loss = 1.3670978109503902, disc_loss = 0.017870866893898954
Trained batch 688 in epoch 0, gen_loss = 1.3668965198132055, disc_loss = 0.017848850211671978
Trained batch 689 in epoch 0, gen_loss = 1.3666447077972301, disc_loss = 0.017825475381349848
Trained batch 690 in epoch 0, gen_loss = 1.3665866415338475, disc_loss = 0.01780187434991269
Trained batch 691 in epoch 0, gen_loss = 1.366544521785196, disc_loss = 0.01777853297219057
Trained batch 692 in epoch 0, gen_loss = 1.3665160926389488, disc_loss = 0.01775545280438164
Trained batch 693 in epoch 0, gen_loss = 1.3663715780296655, disc_loss = 0.01773400164846068
Trained batch 694 in epoch 0, gen_loss = 1.3661671995259017, disc_loss = 0.01771203137937558
Trained batch 695 in epoch 0, gen_loss = 1.3661087473918652, disc_loss = 0.017690566580658297
Trained batch 696 in epoch 0, gen_loss = 1.3659150090758052, disc_loss = 0.01767135965968569
Trained batch 697 in epoch 0, gen_loss = 1.3657905751449673, disc_loss = 0.017650385155578686
Trained batch 698 in epoch 0, gen_loss = 1.3658139836975773, disc_loss = 0.01762711432597897
Trained batch 699 in epoch 0, gen_loss = 1.3655270338058472, disc_loss = 0.01760449843763906
Trained batch 700 in epoch 0, gen_loss = 1.365241253427024, disc_loss = 0.017582052629759877
Trained batch 701 in epoch 0, gen_loss = 1.365070591115544, disc_loss = 0.017559072426308022
Trained batch 702 in epoch 0, gen_loss = 1.3655513489398983, disc_loss = 0.017536428675537726
Trained batch 703 in epoch 0, gen_loss = 1.3653911829672076, disc_loss = 0.017513613161017103
Trained batch 704 in epoch 0, gen_loss = 1.3652948124188904, disc_loss = 0.017493212868373655
Trained batch 705 in epoch 0, gen_loss = 1.3651087257071866, disc_loss = 0.01747205676200929
Trained batch 706 in epoch 0, gen_loss = 1.365360680193004, disc_loss = 0.01745007421967575
Trained batch 707 in epoch 0, gen_loss = 1.3650878765488748, disc_loss = 0.017428953490301567
Trained batch 708 in epoch 0, gen_loss = 1.3650503049280143, disc_loss = 0.01740885165629039
Trained batch 709 in epoch 0, gen_loss = 1.3648382989453598, disc_loss = 0.01738809808714866
Trained batch 710 in epoch 0, gen_loss = 1.3647475356626444, disc_loss = 0.0173672182903312
Trained batch 711 in epoch 0, gen_loss = 1.3647390776470807, disc_loss = 0.01734553880236122
Trained batch 712 in epoch 0, gen_loss = 1.3655093588969482, disc_loss = 0.01732487641705976
Trained batch 713 in epoch 0, gen_loss = 1.3652896047974168, disc_loss = 0.017302349116522765
Trained batch 714 in epoch 0, gen_loss = 1.3650067361084732, disc_loss = 0.017280072824202374
Trained batch 715 in epoch 0, gen_loss = 1.3651883463952794, disc_loss = 0.01725809965442018
Trained batch 716 in epoch 0, gen_loss = 1.3648986633518916, disc_loss = 0.017236696534616045
Trained batch 717 in epoch 0, gen_loss = 1.3649517785871925, disc_loss = 0.017215411243460876
Trained batch 718 in epoch 0, gen_loss = 1.3646143182428225, disc_loss = 0.017193198607365377
Trained batch 719 in epoch 0, gen_loss = 1.3643415970934762, disc_loss = 0.017172406061015662
Trained batch 720 in epoch 0, gen_loss = 1.3642465071274734, disc_loss = 0.017154114534813605
Trained batch 721 in epoch 0, gen_loss = 1.3639901495045903, disc_loss = 0.017134731245734097
Trained batch 722 in epoch 0, gen_loss = 1.363686271887762, disc_loss = 0.017113645971793923
Trained batch 723 in epoch 0, gen_loss = 1.363503540747732, disc_loss = 0.017092944504416584
Trained batch 724 in epoch 0, gen_loss = 1.3639949665398434, disc_loss = 0.017071804581049444
Trained batch 725 in epoch 0, gen_loss = 1.3638043802631787, disc_loss = 0.017050005143095247
Trained batch 726 in epoch 0, gen_loss = 1.363802229521855, disc_loss = 0.017028625998479485
Trained batch 727 in epoch 0, gen_loss = 1.3636771324244175, disc_loss = 0.01700632986882868
Trained batch 728 in epoch 0, gen_loss = 1.3634573648005357, disc_loss = 0.016984472479955492
Trained batch 729 in epoch 0, gen_loss = 1.3631819578066264, disc_loss = 0.01696328922670832
Trained batch 730 in epoch 0, gen_loss = 1.363481321021731, disc_loss = 0.016943530459132137
Trained batch 731 in epoch 0, gen_loss = 1.3631484081836347, disc_loss = 0.01692461590605465
Trained batch 732 in epoch 0, gen_loss = 1.3628874202379588, disc_loss = 0.016904123548890298
Trained batch 733 in epoch 0, gen_loss = 1.3632242889105461, disc_loss = 0.016882855450777
Trained batch 734 in epoch 0, gen_loss = 1.3631378269519936, disc_loss = 0.016861531497090167
Trained batch 735 in epoch 0, gen_loss = 1.36337526369354, disc_loss = 0.01684040900039216
Trained batch 736 in epoch 0, gen_loss = 1.3632571444906083, disc_loss = 0.01681926579262336
Trained batch 737 in epoch 0, gen_loss = 1.3631928159292475, disc_loss = 0.016798420428808875
Trained batch 738 in epoch 0, gen_loss = 1.362938116303316, disc_loss = 0.01677732743836085
Trained batch 739 in epoch 0, gen_loss = 1.3630258864647633, disc_loss = 0.016757010300470693
Trained batch 740 in epoch 0, gen_loss = 1.3631516707892681, disc_loss = 0.016736230981776897
Trained batch 741 in epoch 0, gen_loss = 1.3630619905386974, disc_loss = 0.016715116323253662
Trained batch 742 in epoch 0, gen_loss = 1.3629278177207445, disc_loss = 0.01669872343838829
Trained batch 743 in epoch 0, gen_loss = 1.3632303282458296, disc_loss = 0.01668310691034534
Trained batch 744 in epoch 0, gen_loss = 1.3630353229957939, disc_loss = 0.01666831065152128
Trained batch 745 in epoch 0, gen_loss = 1.3626960106893136, disc_loss = 0.01665467526347017
Trained batch 746 in epoch 0, gen_loss = 1.3623646505705642, disc_loss = 0.016638996007953866
Trained batch 747 in epoch 0, gen_loss = 1.362245828550767, disc_loss = 0.016621234627608037
Trained batch 748 in epoch 0, gen_loss = 1.3620920434335522, disc_loss = 0.016602647363426454
Trained batch 749 in epoch 0, gen_loss = 1.3620665696461995, disc_loss = 0.016582946045712258
Trained batch 750 in epoch 0, gen_loss = 1.3619599307424695, disc_loss = 0.016563048240336182
Trained batch 751 in epoch 0, gen_loss = 1.3620080632415223, disc_loss = 0.016542691391340996
Trained batch 752 in epoch 0, gen_loss = 1.361773504520634, disc_loss = 0.016522135770991618
Trained batch 753 in epoch 0, gen_loss = 1.361609382401727, disc_loss = 0.0165024818793101
Trained batch 754 in epoch 0, gen_loss = 1.3614720565593794, disc_loss = 0.016483082763452873
Trained batch 755 in epoch 0, gen_loss = 1.3618879236241497, disc_loss = 0.0164625935339481
Trained batch 756 in epoch 0, gen_loss = 1.361730868939207, disc_loss = 0.01644269832743017
Trained batch 757 in epoch 0, gen_loss = 1.3617430109147346, disc_loss = 0.016422755555738144
Trained batch 758 in epoch 0, gen_loss = 1.3618708855235686, disc_loss = 0.016402823540301717
Trained batch 759 in epoch 0, gen_loss = 1.3619478581767333, disc_loss = 0.016382812572364378
Trained batch 760 in epoch 0, gen_loss = 1.3618121018704228, disc_loss = 0.01636390717256185
Trained batch 761 in epoch 0, gen_loss = 1.361703461705856, disc_loss = 0.016344556084536433
Trained batch 762 in epoch 0, gen_loss = 1.3616247888005109, disc_loss = 0.01632464437803185
Trained batch 763 in epoch 0, gen_loss = 1.3615465189149867, disc_loss = 0.01630604171192003
Trained batch 764 in epoch 0, gen_loss = 1.3613858104531282, disc_loss = 0.016287112527974316
Trained batch 765 in epoch 0, gen_loss = 1.3610785433891237, disc_loss = 0.016267807251246713
Trained batch 766 in epoch 0, gen_loss = 1.3608445351872949, disc_loss = 0.01624856894582964
Trained batch 767 in epoch 0, gen_loss = 1.3607031347540517, disc_loss = 0.016229042450125537
Trained batch 768 in epoch 0, gen_loss = 1.3608532496019519, disc_loss = 0.016209867121261195
Trained batch 769 in epoch 0, gen_loss = 1.3605675980642244, disc_loss = 0.016190490123510433
Trained batch 770 in epoch 0, gen_loss = 1.3604128550926535, disc_loss = 0.01617086694801429
Trained batch 771 in epoch 0, gen_loss = 1.360116871064191, disc_loss = 0.016151566800846565
Trained batch 772 in epoch 0, gen_loss = 1.3598954873436635, disc_loss = 0.01613316842995495
Trained batch 773 in epoch 0, gen_loss = 1.3597444235816483, disc_loss = 0.016113909398724785
Trained batch 774 in epoch 0, gen_loss = 1.3597276559952767, disc_loss = 0.01609435145547914
Trained batch 775 in epoch 0, gen_loss = 1.3596025636208426, disc_loss = 0.016074840058470576
Trained batch 776 in epoch 0, gen_loss = 1.359699290231388, disc_loss = 0.016056316058952098
Trained batch 777 in epoch 0, gen_loss = 1.3594734391393881, disc_loss = 0.01603837135103639
Trained batch 778 in epoch 0, gen_loss = 1.3595903542595742, disc_loss = 0.01601954818920224
Trained batch 779 in epoch 0, gen_loss = 1.3595531553794176, disc_loss = 0.01600008133115271
Trained batch 780 in epoch 0, gen_loss = 1.3595114360240297, disc_loss = 0.015982065245475758
Trained batch 781 in epoch 0, gen_loss = 1.3592247043729133, disc_loss = 0.015967051877313867
Trained batch 782 in epoch 0, gen_loss = 1.358941968068918, disc_loss = 0.01595306832409948
Trained batch 783 in epoch 0, gen_loss = 1.3586781354887145, disc_loss = 0.015937141265734384
Trained batch 784 in epoch 0, gen_loss = 1.3585488346731587, disc_loss = 0.015921374561656623
Trained batch 785 in epoch 0, gen_loss = 1.3584128525724242, disc_loss = 0.01590510563653569
Trained batch 786 in epoch 0, gen_loss = 1.3582330893682555, disc_loss = 0.015886934269089464
Trained batch 787 in epoch 0, gen_loss = 1.3580919581318869, disc_loss = 0.015868768941163118
Trained batch 788 in epoch 0, gen_loss = 1.3579777240450996, disc_loss = 0.015849756546060616
Trained batch 789 in epoch 0, gen_loss = 1.3579260942302174, disc_loss = 0.015831347657706517
Testing Epoch 0
Traceback (most recent call last):
  File "srgan_bones.py", line 358, in <module>
    img_grid1 = utils.make_images2(imgs_hr[:5], imgs_lr[:5], gen_hr[:5])
  File "/work3/soeba/HALOS/utils.py", line 133, in make_images2
    axs[i,0].imshow(target[i], interpolation='none', origin='upper', cmap=plt.cm.jet)
  File "/work3/soeba/HALOS/halos/lib/python3.8/site-packages/matplotlib/_api/deprecation.py", line 459, in wrapper
    return func(*args, **kwargs)
  File "/work3/soeba/HALOS/halos/lib/python3.8/site-packages/matplotlib/__init__.py", line 1412, in inner
    return func(ax, *map(sanitize_sequence, args), **kwargs)
  File "/work3/soeba/HALOS/halos/lib/python3.8/site-packages/matplotlib/axes/_axes.py", line 5481, in imshow
    im.set_data(X)
  File "/work3/soeba/HALOS/halos/lib/python3.8/site-packages/matplotlib/image.py", line 702, in set_data
    self._A = cbook.safe_masked_invalid(A, copy=True)
  File "/work3/soeba/HALOS/halos/lib/python3.8/site-packages/matplotlib/cbook/__init__.py", line 701, in safe_masked_invalid
    x = np.array(x, subok=True, copy=copy)
  File "/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torch/_tensor.py", line 757, in __array__
    return self.numpy()
TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 1.4524691104888916, disc_loss = 0.577932596206665
Trained batch 1 in epoch 0, gen_loss = 1.5656220316886902, disc_loss = 0.7946094274520874
Trained batch 2 in epoch 0, gen_loss = 1.6037698984146118, disc_loss = 0.802037517229716
Trained batch 3 in epoch 0, gen_loss = 1.5492462813854218, disc_loss = 0.6988362073898315
Trained batch 4 in epoch 0, gen_loss = 1.5788917541503906, disc_loss = 0.6425072073936462
Trained batch 5 in epoch 0, gen_loss = 1.5726290543874104, disc_loss = 0.5866937239964803
Trained batch 6 in epoch 0, gen_loss = 1.5453838620867049, disc_loss = 0.5459587574005127
Trained batch 7 in epoch 0, gen_loss = 1.5026088207960129, disc_loss = 0.5111421123147011
Trained batch 8 in epoch 0, gen_loss = 1.4774124489890204, disc_loss = 0.48317261868053013
Trained batch 9 in epoch 0, gen_loss = 1.4597989201545716, disc_loss = 0.46030962765216826
Trained batch 10 in epoch 0, gen_loss = 1.463252771984447, disc_loss = 0.44276510856368323
Trained batch 11 in epoch 0, gen_loss = 1.465016484260559, disc_loss = 0.42393891140818596
Trained batch 12 in epoch 0, gen_loss = 1.4674000373253455, disc_loss = 0.4071179295961673
Trained batch 13 in epoch 0, gen_loss = 1.4697532228061132, disc_loss = 0.39180576907736914
Trained batch 14 in epoch 0, gen_loss = 1.4772193431854248, disc_loss = 0.3776505579551061
Trained batch 15 in epoch 0, gen_loss = 1.4661448150873184, disc_loss = 0.3638801323249936
Trained batch 16 in epoch 0, gen_loss = 1.464699198217953, disc_loss = 0.34958597710903955
Trained batch 17 in epoch 0, gen_loss = 1.4602648417154949, disc_loss = 0.33707498634854954
Trained batch 18 in epoch 0, gen_loss = 1.4696217524377924, disc_loss = 0.3275296448876983
Trained batch 19 in epoch 0, gen_loss = 1.4751579344272614, disc_loss = 0.3209710191935301
Trained batch 20 in epoch 0, gen_loss = 1.4827351626895724, disc_loss = 0.31519965082407
Trained batch 21 in epoch 0, gen_loss = 1.482073729688471, disc_loss = 0.3077642392705787
Trained batch 22 in epoch 0, gen_loss = 1.4873668784680574, disc_loss = 0.3007245987005856
Trained batch 23 in epoch 0, gen_loss = 1.4853400935729344, disc_loss = 0.29699717617283267
Trained batch 24 in epoch 0, gen_loss = 1.4797677850723268, disc_loss = 0.29777627021074293
Trained batch 25 in epoch 0, gen_loss = 1.4803207287421594, disc_loss = 0.29452621621581226
Trained batch 26 in epoch 0, gen_loss = 1.4856130723600034, disc_loss = 0.2883321739457272
Trained batch 27 in epoch 0, gen_loss = 1.488915741443634, disc_loss = 0.2818425925714629
Trained batch 28 in epoch 0, gen_loss = 1.4994581896683266, disc_loss = 0.27493265373953457
Trained batch 29 in epoch 0, gen_loss = 1.5047013799349467, disc_loss = 0.2689678971966108
Trained batch 30 in epoch 0, gen_loss = 1.5087828251623339, disc_loss = 0.2629831320335788
Trained batch 31 in epoch 0, gen_loss = 1.5106136873364449, disc_loss = 0.2568712786305696
Trained batch 32 in epoch 0, gen_loss = 1.5121707518895466, disc_loss = 0.2508192640362364
Trained batch 33 in epoch 0, gen_loss = 1.5193226337432861, disc_loss = 0.24555577666443937
Trained batch 34 in epoch 0, gen_loss = 1.5198069504329137, disc_loss = 0.24058470789875303
Trained batch 35 in epoch 0, gen_loss = 1.5207819210158453, disc_loss = 0.23754168612261614
Trained batch 36 in epoch 0, gen_loss = 1.5224069260262154, disc_loss = 0.23320106135026827
Trained batch 37 in epoch 0, gen_loss = 1.5283222449453253, disc_loss = 0.22937594471793427
Trained batch 38 in epoch 0, gen_loss = 1.5348953222617125, disc_loss = 0.22503593697761878
Trained batch 39 in epoch 0, gen_loss = 1.5369892805814742, disc_loss = 0.2206808858551085
Trained batch 40 in epoch 0, gen_loss = 1.5375027453027121, disc_loss = 0.2167231754013678
Trained batch 41 in epoch 0, gen_loss = 1.539796945594606, disc_loss = 0.21333961304099786
Trained batch 42 in epoch 0, gen_loss = 1.5440214345621508, disc_loss = 0.20983002482112065
Trained batch 43 in epoch 0, gen_loss = 1.5503245294094086, disc_loss = 0.20647066916254433
Trained batch 44 in epoch 0, gen_loss = 1.555825448036194, disc_loss = 0.20303987645440633
Trained batch 45 in epoch 0, gen_loss = 1.5619436061900596, disc_loss = 0.19971632204301978
Trained batch 46 in epoch 0, gen_loss = 1.5661666444007387, disc_loss = 0.19674012786213388
Trained batch 47 in epoch 0, gen_loss = 1.5690493981043498, disc_loss = 0.19401699638304612
Trained batch 48 in epoch 0, gen_loss = 1.5712245727071956, disc_loss = 0.19127492538216162
Trained batch 49 in epoch 0, gen_loss = 1.5738898372650147, disc_loss = 0.18828253842890263
Trained batch 50 in epoch 0, gen_loss = 1.5769226504307168, disc_loss = 0.185780115206452
Trained batch 51 in epoch 0, gen_loss = 1.5845085244912367, disc_loss = 0.18441463054086155
Trained batch 52 in epoch 0, gen_loss = 1.588215578277156, disc_loss = 0.1855870765756886
Trained batch 53 in epoch 0, gen_loss = 1.5999933194231104, disc_loss = 0.1866576350811455
Trained batch 54 in epoch 0, gen_loss = 1.608358745141463, disc_loss = 0.18522322482683443
Trained batch 55 in epoch 0, gen_loss = 1.6110359387738364, disc_loss = 0.18290184850671462
Trained batch 56 in epoch 0, gen_loss = 1.6174666337799608, disc_loss = 0.18074303532117292
Trained batch 57 in epoch 0, gen_loss = 1.6217329378785759, disc_loss = 0.17825477602409906
Trained batch 58 in epoch 0, gen_loss = 1.6225976782330012, disc_loss = 0.17583384263818547
Trained batch 59 in epoch 0, gen_loss = 1.6306426445643107, disc_loss = 0.17341675125062467
Trained batch 60 in epoch 0, gen_loss = 1.631455448807263, disc_loss = 0.1711294851952889
Trained batch 61 in epoch 0, gen_loss = 1.630748039291751, disc_loss = 0.1691510039832323
Trained batch 62 in epoch 0, gen_loss = 1.6290192717597598, disc_loss = 0.16703895810577604
Trained batch 63 in epoch 0, gen_loss = 1.631537314504385, disc_loss = 0.16482023464050144
Trained batch 64 in epoch 0, gen_loss = 1.63066972219027, disc_loss = 0.16269109266308637
Trained batch 65 in epoch 0, gen_loss = 1.6331117713090144, disc_loss = 0.16063251639857437
Trained batch 66 in epoch 0, gen_loss = 1.6327991467803271, disc_loss = 0.1586559136578841
Trained batch 67 in epoch 0, gen_loss = 1.6336263225359076, disc_loss = 0.15675694391350536
Trained batch 68 in epoch 0, gen_loss = 1.636825910512952, disc_loss = 0.15485569691636425
Trained batch 69 in epoch 0, gen_loss = 1.634960617337908, disc_loss = 0.15298811266464846
Trained batch 70 in epoch 0, gen_loss = 1.6347510613186258, disc_loss = 0.15118809946825806
Trained batch 71 in epoch 0, gen_loss = 1.6367308265633054, disc_loss = 0.1495103667386704
Trained batch 72 in epoch 0, gen_loss = 1.637895887845183, disc_loss = 0.14791170609732196
Trained batch 73 in epoch 0, gen_loss = 1.6389771313280672, disc_loss = 0.146334908927816
Trained batch 74 in epoch 0, gen_loss = 1.6402318255106607, disc_loss = 0.1446902350584666
Trained batch 75 in epoch 0, gen_loss = 1.640874977174558, disc_loss = 0.14304830930440834
Trained batch 76 in epoch 0, gen_loss = 1.6421913496859661, disc_loss = 0.14149556524277507
Trained batch 77 in epoch 0, gen_loss = 1.6442263539020832, disc_loss = 0.1399503467986599
Trained batch 78 in epoch 0, gen_loss = 1.6452605166012728, disc_loss = 0.13840066978731488
Trained batch 79 in epoch 0, gen_loss = 1.6467173472046852, disc_loss = 0.13694982493761926
Trained batch 80 in epoch 0, gen_loss = 1.6489326144442147, disc_loss = 0.13554410102926653
Trained batch 81 in epoch 0, gen_loss = 1.6473260434662425, disc_loss = 0.13418412583357678
Trained batch 82 in epoch 0, gen_loss = 1.6507805025721172, disc_loss = 0.1330382621297276
Trained batch 83 in epoch 0, gen_loss = 1.652484016759055, disc_loss = 0.13205470342100376
Trained batch 84 in epoch 0, gen_loss = 1.652556366078994, disc_loss = 0.1309909676146858
Trained batch 85 in epoch 0, gen_loss = 1.6523520087086878, disc_loss = 0.12981553971334253
Trained batch 86 in epoch 0, gen_loss = 1.6516601080181954, disc_loss = 0.12852317739235258
Trained batch 87 in epoch 0, gen_loss = 1.6523756940256467, disc_loss = 0.12735174990005113
Trained batch 88 in epoch 0, gen_loss = 1.6512989609429005, disc_loss = 0.12613176914413324
Trained batch 89 in epoch 0, gen_loss = 1.6503866129451328, disc_loss = 0.12488577245838112
Trained batch 90 in epoch 0, gen_loss = 1.6522727995128421, disc_loss = 0.12372996514806381
Trained batch 91 in epoch 0, gen_loss = 1.6514870952004972, disc_loss = 0.12257144126393225
Trained batch 92 in epoch 0, gen_loss = 1.6506091420368483, disc_loss = 0.1213760484230294
Trained batch 93 in epoch 0, gen_loss = 1.653767077212638, disc_loss = 0.12025599039972146
Trained batch 94 in epoch 0, gen_loss = 1.6540230148716977, disc_loss = 0.1191419213127933
Trained batch 95 in epoch 0, gen_loss = 1.6530696836610634, disc_loss = 0.11805415762743603
Trained batch 96 in epoch 0, gen_loss = 1.6529234315931183, disc_loss = 0.11700958643377442
Trained batch 97 in epoch 0, gen_loss = 1.6546424724617783, disc_loss = 0.11600009889855069
Trained batch 98 in epoch 0, gen_loss = 1.6541899406548701, disc_loss = 0.11495899866250428
Trained batch 99 in epoch 0, gen_loss = 1.6561045634746552, disc_loss = 0.11393248818814755
Trained batch 100 in epoch 0, gen_loss = 1.6561071046508185, disc_loss = 0.11297347333909262
Trained batch 101 in epoch 0, gen_loss = 1.6559492069132187, disc_loss = 0.1120487448266324
Trained batch 102 in epoch 0, gen_loss = 1.6542527258974835, disc_loss = 0.11113880782668452
Trained batch 103 in epoch 0, gen_loss = 1.653749249302424, disc_loss = 0.1103016058018861
Trained batch 104 in epoch 0, gen_loss = 1.6523362216495332, disc_loss = 0.10953414796718529
Trained batch 105 in epoch 0, gen_loss = 1.6555854903077178, disc_loss = 0.10881034901611647
Trained batch 106 in epoch 0, gen_loss = 1.6551438269214096, disc_loss = 0.10797042096747417
Trained batch 107 in epoch 0, gen_loss = 1.6533046099874709, disc_loss = 0.10715382789365119
Trained batch 108 in epoch 0, gen_loss = 1.6538156697509485, disc_loss = 0.10630929239367673
Trained batch 109 in epoch 0, gen_loss = 1.6545858632434498, disc_loss = 0.10550090455534783
Trained batch 110 in epoch 0, gen_loss = 1.653672168920706, disc_loss = 0.10470321276099295
Trained batch 111 in epoch 0, gen_loss = 1.6536093758685249, disc_loss = 0.10394386669421303
Trained batch 112 in epoch 0, gen_loss = 1.6536328739824548, disc_loss = 0.10316594424698733
Trained batch 113 in epoch 0, gen_loss = 1.6535375777043795, disc_loss = 0.1023919887415934
Trained batch 114 in epoch 0, gen_loss = 1.6549519155336463, disc_loss = 0.10161309216333472
Trained batch 115 in epoch 0, gen_loss = 1.6546199455343444, disc_loss = 0.1008511527666244
Trained batch 116 in epoch 0, gen_loss = 1.6550549105701284, disc_loss = 0.10009255529277855
Trained batch 117 in epoch 0, gen_loss = 1.6566543488179224, disc_loss = 0.09933537066424802
Trained batch 118 in epoch 0, gen_loss = 1.6581803570274545, disc_loss = 0.09862839580051788
Trained batch 119 in epoch 0, gen_loss = 1.6568763434886933, disc_loss = 0.09811647735380878
Trained batch 120 in epoch 0, gen_loss = 1.6551284139806575, disc_loss = 0.09754272023108133
Trained batch 121 in epoch 0, gen_loss = 1.652670931620676, disc_loss = 0.09689079233460494
Trained batch 122 in epoch 0, gen_loss = 1.6534998959642115, disc_loss = 0.0963544968167335
Trained batch 123 in epoch 0, gen_loss = 1.6542185218103471, disc_loss = 0.09591457466294448
Trained batch 124 in epoch 0, gen_loss = 1.6539925584793091, disc_loss = 0.09540744360536337
Trained batch 125 in epoch 0, gen_loss = 1.652313993090675, disc_loss = 0.09480044614553215
Trained batch 126 in epoch 0, gen_loss = 1.6512499475103664, disc_loss = 0.09419574229941359
Trained batch 127 in epoch 0, gen_loss = 1.6503858547657728, disc_loss = 0.09357186327542877
Trained batch 128 in epoch 0, gen_loss = 1.6498144245886988, disc_loss = 0.09299156883399384
Trained batch 129 in epoch 0, gen_loss = 1.6489358021662786, disc_loss = 0.09236647575520553
Trained batch 130 in epoch 0, gen_loss = 1.648509045593611, disc_loss = 0.09176975814981088
Trained batch 131 in epoch 0, gen_loss = 1.6491938585584813, disc_loss = 0.09116425662245037
Trained batch 132 in epoch 0, gen_loss = 1.6481475095103557, disc_loss = 0.09058300640321988
Trained batch 133 in epoch 0, gen_loss = 1.6475269874530052, disc_loss = 0.08998328785120106
Trained batch 134 in epoch 0, gen_loss = 1.6467589404847887, disc_loss = 0.08943998968159711
Trained batch 135 in epoch 0, gen_loss = 1.6467673725941603, disc_loss = 0.08897725358495817
Trained batch 136 in epoch 0, gen_loss = 1.6455508279104303, disc_loss = 0.08859583645732734
Trained batch 137 in epoch 0, gen_loss = 1.6463135955990225, disc_loss = 0.08806226727809163
Trained batch 138 in epoch 0, gen_loss = 1.6472572911557535, disc_loss = 0.0875647386817409
Trained batch 139 in epoch 0, gen_loss = 1.647354464020048, disc_loss = 0.08705663915191378
Trained batch 140 in epoch 0, gen_loss = 1.646984708224628, disc_loss = 0.08662272047859135
Trained batch 141 in epoch 0, gen_loss = 1.6450430297515761, disc_loss = 0.08620771536157584
Trained batch 142 in epoch 0, gen_loss = 1.6427626368049142, disc_loss = 0.08574533995266978
Trained batch 143 in epoch 0, gen_loss = 1.6427891610397234, disc_loss = 0.08523638455921577
Trained batch 144 in epoch 0, gen_loss = 1.641792392730713, disc_loss = 0.08473495659900122
Trained batch 145 in epoch 0, gen_loss = 1.6423869516751537, disc_loss = 0.08428262945979018
Trained batch 146 in epoch 0, gen_loss = 1.6425497329153982, disc_loss = 0.08381558702561726
Trained batch 147 in epoch 0, gen_loss = 1.641802551778587, disc_loss = 0.08334473108973454
Trained batch 148 in epoch 0, gen_loss = 1.640071375258017, disc_loss = 0.08288519778257648
Trained batch 149 in epoch 0, gen_loss = 1.6396201046307881, disc_loss = 0.08242050847038626
Trained batch 150 in epoch 0, gen_loss = 1.6400532383002981, disc_loss = 0.0819579790845908
Trained batch 151 in epoch 0, gen_loss = 1.6407077116401572, disc_loss = 0.08148996932064428
Trained batch 152 in epoch 0, gen_loss = 1.6397535317863514, disc_loss = 0.0810091698761372
Trained batch 153 in epoch 0, gen_loss = 1.6391811061215091, disc_loss = 0.08054852091961286
Trained batch 154 in epoch 0, gen_loss = 1.6396226144606068, disc_loss = 0.08008694636124757
Trained batch 155 in epoch 0, gen_loss = 1.6393910356056995, disc_loss = 0.0796459509859769
Trained batch 156 in epoch 0, gen_loss = 1.6403248758073066, disc_loss = 0.07919641383063451
Trained batch 157 in epoch 0, gen_loss = 1.6410302731055249, disc_loss = 0.07875802413902327
Trained batch 158 in epoch 0, gen_loss = 1.639540879981323, disc_loss = 0.07836904040531917
Trained batch 159 in epoch 0, gen_loss = 1.638725497573614, disc_loss = 0.07797273611649871
Trained batch 160 in epoch 0, gen_loss = 1.6393519366009635, disc_loss = 0.07754127595064618
Trained batch 161 in epoch 0, gen_loss = 1.6378472381167941, disc_loss = 0.07714934803453492
Trained batch 162 in epoch 0, gen_loss = 1.639312932096376, disc_loss = 0.07675456006559858
Trained batch 163 in epoch 0, gen_loss = 1.6377335423376502, disc_loss = 0.07635352607225863
Trained batch 164 in epoch 0, gen_loss = 1.636894051956408, disc_loss = 0.07594430919623736
Trained batch 165 in epoch 0, gen_loss = 1.6355389722858567, disc_loss = 0.07561213916997953
Trained batch 166 in epoch 0, gen_loss = 1.635506984002576, disc_loss = 0.07524683197101432
Trained batch 167 in epoch 0, gen_loss = 1.6356152445077896, disc_loss = 0.07487770704375137
Trained batch 168 in epoch 0, gen_loss = 1.6365323800307054, disc_loss = 0.07451537833411313
Trained batch 169 in epoch 0, gen_loss = 1.6368818591622745, disc_loss = 0.07415337214136825
Trained batch 170 in epoch 0, gen_loss = 1.6363929342805295, disc_loss = 0.07378112928865597
Trained batch 171 in epoch 0, gen_loss = 1.6355313416137252, disc_loss = 0.07340196776745278
Trained batch 172 in epoch 0, gen_loss = 1.634598006402826, disc_loss = 0.0730114299857806
Trained batch 173 in epoch 0, gen_loss = 1.6335029581497456, disc_loss = 0.07263255479274554
Trained batch 174 in epoch 0, gen_loss = 1.6338734674453734, disc_loss = 0.0722753752688212
Trained batch 175 in epoch 0, gen_loss = 1.6329679197885774, disc_loss = 0.07190436073473062
Trained batch 176 in epoch 0, gen_loss = 1.631426453590393, disc_loss = 0.07153936314243971
Trained batch 177 in epoch 0, gen_loss = 1.6314130479030395, disc_loss = 0.07119197911959602
Trained batch 178 in epoch 0, gen_loss = 1.6318031589412156, disc_loss = 0.07085049539731618
Trained batch 179 in epoch 0, gen_loss = 1.6317242205142974, disc_loss = 0.07051441695592883
Trained batch 180 in epoch 0, gen_loss = 1.6330507374600152, disc_loss = 0.07017024953525451
Trained batch 181 in epoch 0, gen_loss = 1.6319364197961577, disc_loss = 0.06982282315032905
Trained batch 182 in epoch 0, gen_loss = 1.631520496691511, disc_loss = 0.06948412513828588
Trained batch 183 in epoch 0, gen_loss = 1.6314119087613148, disc_loss = 0.06915461726274098
Trained batch 184 in epoch 0, gen_loss = 1.6304760984472326, disc_loss = 0.0690195630606566
Trained batch 185 in epoch 0, gen_loss = 1.6291124878391143, disc_loss = 0.06889148602031812
Trained batch 186 in epoch 0, gen_loss = 1.6287848751812695, disc_loss = 0.06857813027423414
Trained batch 187 in epoch 0, gen_loss = 1.6287005461276847, disc_loss = 0.06828613563668617
Trained batch 188 in epoch 0, gen_loss = 1.6281139856923825, disc_loss = 0.06796695946632002
Trained batch 189 in epoch 0, gen_loss = 1.6278205338277314, disc_loss = 0.06764762242520718
Trained batch 190 in epoch 0, gen_loss = 1.6289273163411007, disc_loss = 0.06733421443020486
Trained batch 191 in epoch 0, gen_loss = 1.6278688920040925, disc_loss = 0.06702757945943934
Trained batch 192 in epoch 0, gen_loss = 1.6280502945647957, disc_loss = 0.06673703718100496
Trained batch 193 in epoch 0, gen_loss = 1.6268221772823137, disc_loss = 0.06647480471232503
Trained batch 194 in epoch 0, gen_loss = 1.626848629804758, disc_loss = 0.06618249391993651
Trained batch 195 in epoch 0, gen_loss = 1.6265148003490604, disc_loss = 0.06588091733580341
Trained batch 196 in epoch 0, gen_loss = 1.6252707787576666, disc_loss = 0.0655966053910667
Trained batch 197 in epoch 0, gen_loss = 1.623997986316681, disc_loss = 0.0653057063816849
Trained batch 198 in epoch 0, gen_loss = 1.6226569018771302, disc_loss = 0.06501204973021195
Trained batch 199 in epoch 0, gen_loss = 1.6215419536828994, disc_loss = 0.0647173628443852
Trained batch 200 in epoch 0, gen_loss = 1.6212641866646003, disc_loss = 0.06442963154708493
Trained batch 201 in epoch 0, gen_loss = 1.6207395614963946, disc_loss = 0.06414082450653878
Trained batch 202 in epoch 0, gen_loss = 1.6193251421886126, disc_loss = 0.06385809720122242
Trained batch 203 in epoch 0, gen_loss = 1.6183394649449516, disc_loss = 0.06357624263310914
Trained batch 204 in epoch 0, gen_loss = 1.6175020124854111, disc_loss = 0.06330592506224426
Trained batch 205 in epoch 0, gen_loss = 1.6170060055927165, disc_loss = 0.06303031478999453
Trained batch 206 in epoch 0, gen_loss = 1.6168250542332008, disc_loss = 0.06276050125640156
Trained batch 207 in epoch 0, gen_loss = 1.616470934679875, disc_loss = 0.062497721530514985
Trained batch 208 in epoch 0, gen_loss = 1.6163801639273976, disc_loss = 0.06224512161116637
Trained batch 209 in epoch 0, gen_loss = 1.6156228627477374, disc_loss = 0.061989977199672947
Trained batch 210 in epoch 0, gen_loss = 1.614275644740787, disc_loss = 0.061740341099747124
Trained batch 211 in epoch 0, gen_loss = 1.6138772722685113, disc_loss = 0.061480245399200974
Trained batch 212 in epoch 0, gen_loss = 1.6131134458550824, disc_loss = 0.061228769201732855
Trained batch 213 in epoch 0, gen_loss = 1.6116980993859122, disc_loss = 0.06100566089414408
Trained batch 214 in epoch 0, gen_loss = 1.610977660777957, disc_loss = 0.06075751647179903
Trained batch 215 in epoch 0, gen_loss = 1.6094850136174097, disc_loss = 0.060543119859950686
Trained batch 216 in epoch 0, gen_loss = 1.6083711440662085, disc_loss = 0.06033470617255308
Trained batch 217 in epoch 0, gen_loss = 1.6075358888424864, disc_loss = 0.060101338773282297
Trained batch 218 in epoch 0, gen_loss = 1.6082597105470422, disc_loss = 0.05988519924127212
Trained batch 219 in epoch 0, gen_loss = 1.607517426664179, disc_loss = 0.059677564568648284
Trained batch 220 in epoch 0, gen_loss = 1.6058486522053161, disc_loss = 0.05955945755612122
Trained batch 221 in epoch 0, gen_loss = 1.6045761333929527, disc_loss = 0.05939415610303079
Trained batch 222 in epoch 0, gen_loss = 1.6041398775417175, disc_loss = 0.05918276637391659
Trained batch 223 in epoch 0, gen_loss = 1.6025161450462682, disc_loss = 0.05901216099404597
Trained batch 224 in epoch 0, gen_loss = 1.601319972674052, disc_loss = 0.05884153274198373
Trained batch 225 in epoch 0, gen_loss = 1.6000182623356844, disc_loss = 0.058651733731405926
Trained batch 226 in epoch 0, gen_loss = 1.5983904689419113, disc_loss = 0.05843076136964271
Trained batch 227 in epoch 0, gen_loss = 1.5971278495955885, disc_loss = 0.05821951514665495
Trained batch 228 in epoch 0, gen_loss = 1.5966578305548456, disc_loss = 0.05800047662824913
Trained batch 229 in epoch 0, gen_loss = 1.5957303591396497, disc_loss = 0.05780245684006292
Trained batch 230 in epoch 0, gen_loss = 1.5961360621761966, disc_loss = 0.0575834971538128
Trained batch 231 in epoch 0, gen_loss = 1.595398226174815, disc_loss = 0.057366427048189755
Trained batch 232 in epoch 0, gen_loss = 1.594094150567771, disc_loss = 0.05715059335723263
Trained batch 233 in epoch 0, gen_loss = 1.5929591793280382, disc_loss = 0.056933402069884106
Trained batch 234 in epoch 0, gen_loss = 1.5923603225261607, disc_loss = 0.05672027194040253
Trained batch 235 in epoch 0, gen_loss = 1.5916494929184348, disc_loss = 0.05651274047223693
Trained batch 236 in epoch 0, gen_loss = 1.591786965036191, disc_loss = 0.056297528848272084
Trained batch 237 in epoch 0, gen_loss = 1.5903918632940084, disc_loss = 0.05609318092974106
Trained batch 238 in epoch 0, gen_loss = 1.5902750546962148, disc_loss = 0.055885673952620146
Trained batch 239 in epoch 0, gen_loss = 1.589892906943957, disc_loss = 0.05568389200100986
Trained batch 240 in epoch 0, gen_loss = 1.589054726960748, disc_loss = 0.05547786120101191
Trained batch 241 in epoch 0, gen_loss = 1.5884744983074093, disc_loss = 0.05527821089687549
Trained batch 242 in epoch 0, gen_loss = 1.5880510650053927, disc_loss = 0.05509586137079408
Trained batch 243 in epoch 0, gen_loss = 1.587757997336935, disc_loss = 0.05491951175919566
Trained batch 244 in epoch 0, gen_loss = 1.5864764724458966, disc_loss = 0.05472480972886694
Trained batch 245 in epoch 0, gen_loss = 1.5859021912745344, disc_loss = 0.054537120797648664
Trained batch 246 in epoch 0, gen_loss = 1.5856383551470181, disc_loss = 0.05435240234395391
Trained batch 247 in epoch 0, gen_loss = 1.5865432975753662, disc_loss = 0.05416210844451862
Trained batch 248 in epoch 0, gen_loss = 1.5865207302522468, disc_loss = 0.053979068354939125
Trained batch 249 in epoch 0, gen_loss = 1.5851764588356019, disc_loss = 0.053798918470740316
Trained batch 250 in epoch 0, gen_loss = 1.5843809178150983, disc_loss = 0.05363892250327
Trained batch 251 in epoch 0, gen_loss = 1.5833406382136874, disc_loss = 0.05345291162781891
Trained batch 252 in epoch 0, gen_loss = 1.5830856886777012, disc_loss = 0.05326575209228359
Trained batch 253 in epoch 0, gen_loss = 1.5819210245853335, disc_loss = 0.05307586413192174
Trained batch 254 in epoch 0, gen_loss = 1.5823202984005798, disc_loss = 0.05289069798537621
Trained batch 255 in epoch 0, gen_loss = 1.5809097401797771, disc_loss = 0.052731165904333466
Trained batch 256 in epoch 0, gen_loss = 1.5796620920010578, disc_loss = 0.052567934858384416
Trained batch 257 in epoch 0, gen_loss = 1.5786474864612254, disc_loss = 0.052417917651766836
Trained batch 258 in epoch 0, gen_loss = 1.5791787553477932, disc_loss = 0.05224481027062738
Trained batch 259 in epoch 0, gen_loss = 1.5785186093587142, disc_loss = 0.05207871090298375
Trained batch 260 in epoch 0, gen_loss = 1.57721421545036, disc_loss = 0.05189835457345364
Trained batch 261 in epoch 0, gen_loss = 1.5761025689030421, disc_loss = 0.051724763546238534
Trained batch 262 in epoch 0, gen_loss = 1.5759114430431178, disc_loss = 0.05154581830266707
Trained batch 263 in epoch 0, gen_loss = 1.5747803756684968, disc_loss = 0.051369333017095356
Trained batch 264 in epoch 0, gen_loss = 1.5742841351707026, disc_loss = 0.05119692255865853
Trained batch 265 in epoch 0, gen_loss = 1.5734204757482486, disc_loss = 0.05102781133194055
Trained batch 266 in epoch 0, gen_loss = 1.573492898923181, disc_loss = 0.050859482568245705
Trained batch 267 in epoch 0, gen_loss = 1.5723550955751049, disc_loss = 0.05069145934878668
Trained batch 268 in epoch 0, gen_loss = 1.5714756742285974, disc_loss = 0.050522717693993704
Trained batch 269 in epoch 0, gen_loss = 1.571632213945742, disc_loss = 0.05035294575996145
Trained batch 270 in epoch 0, gen_loss = 1.57057000526203, disc_loss = 0.05018896148351066
Trained batch 271 in epoch 0, gen_loss = 1.5706075675347273, disc_loss = 0.050028007260099164
Trained batch 272 in epoch 0, gen_loss = 1.5701283749206598, disc_loss = 0.04986239048642117
Trained batch 273 in epoch 0, gen_loss = 1.569210837792306, disc_loss = 0.049694551937588
Trained batch 274 in epoch 0, gen_loss = 1.568943849476901, disc_loss = 0.04952915969643403
Trained batch 275 in epoch 0, gen_loss = 1.5680017985295558, disc_loss = 0.04936606155293386
Trained batch 276 in epoch 0, gen_loss = 1.5672361502148184, disc_loss = 0.04920631648707019
Trained batch 277 in epoch 0, gen_loss = 1.5663661755246223, disc_loss = 0.04904268836693021
Trained batch 278 in epoch 0, gen_loss = 1.5660247033642185, disc_loss = 0.04888327410327785
Trained batch 279 in epoch 0, gen_loss = 1.56575234574931, disc_loss = 0.04872844780246461
Trained batch 280 in epoch 0, gen_loss = 1.5652048396894516, disc_loss = 0.048577697242500786
Trained batch 281 in epoch 0, gen_loss = 1.5642069971307795, disc_loss = 0.04841982904270106
Trained batch 282 in epoch 0, gen_loss = 1.5642045310866286, disc_loss = 0.04826208593754934
Trained batch 283 in epoch 0, gen_loss = 1.5634389821912202, disc_loss = 0.04810973144756158
Trained batch 284 in epoch 0, gen_loss = 1.5631677497897232, disc_loss = 0.04796573931040863
Trained batch 285 in epoch 0, gen_loss = 1.5631162932702711, disc_loss = 0.0478111030029172
Trained batch 286 in epoch 0, gen_loss = 1.5629235921421119, disc_loss = 0.047659815623317864
Trained batch 287 in epoch 0, gen_loss = 1.5622855453855462, disc_loss = 0.04750895673997649
Trained batch 288 in epoch 0, gen_loss = 1.563107989651109, disc_loss = 0.04735771456578663
Trained batch 289 in epoch 0, gen_loss = 1.562215573212196, disc_loss = 0.047207790654120514
Trained batch 290 in epoch 0, gen_loss = 1.5615879670041533, disc_loss = 0.04705812945830735
Trained batch 291 in epoch 0, gen_loss = 1.561134197532314, disc_loss = 0.04691977148049524
Trained batch 292 in epoch 0, gen_loss = 1.5600312663426579, disc_loss = 0.04677654596907007
Trained batch 293 in epoch 0, gen_loss = 1.5595704211669714, disc_loss = 0.04663021809921986
Trained batch 294 in epoch 0, gen_loss = 1.559439457069009, disc_loss = 0.04648668565550598
Trained batch 295 in epoch 0, gen_loss = 1.5589716273385126, disc_loss = 0.04634748273717894
Trained batch 296 in epoch 0, gen_loss = 1.5582698366858743, disc_loss = 0.046212298353437826
Trained batch 297 in epoch 0, gen_loss = 1.5570922657947412, disc_loss = 0.046078193167087014
Trained batch 298 in epoch 0, gen_loss = 1.5564141010360972, disc_loss = 0.04594224169351983
Trained batch 299 in epoch 0, gen_loss = 1.5556347946325937, disc_loss = 0.04580507302035888
Trained batch 300 in epoch 0, gen_loss = 1.5551713728825516, disc_loss = 0.04567157278499532
Trained batch 301 in epoch 0, gen_loss = 1.555008587063543, disc_loss = 0.04553799891677864
Trained batch 302 in epoch 0, gen_loss = 1.554541808543819, disc_loss = 0.04540432858197849
Trained batch 303 in epoch 0, gen_loss = 1.5534180806655633, disc_loss = 0.045276472104505
Trained batch 304 in epoch 0, gen_loss = 1.552571870459885, disc_loss = 0.04514360864967352
Trained batch 305 in epoch 0, gen_loss = 1.5526719662099102, disc_loss = 0.04501402820460498
Trained batch 306 in epoch 0, gen_loss = 1.5518460794069868, disc_loss = 0.04487902884817521
Trained batch 307 in epoch 0, gen_loss = 1.5516464702494732, disc_loss = 0.04474405859681693
Trained batch 308 in epoch 0, gen_loss = 1.5514724069428676, disc_loss = 0.044610220525250995
Trained batch 309 in epoch 0, gen_loss = 1.5504644551584799, disc_loss = 0.04448500042555914
Trained batch 310 in epoch 0, gen_loss = 1.5501137235923594, disc_loss = 0.04435653548007921
Trained batch 311 in epoch 0, gen_loss = 1.550061006958668, disc_loss = 0.04423251613983526
Trained batch 312 in epoch 0, gen_loss = 1.5495137593235833, disc_loss = 0.04410412149970976
Trained batch 313 in epoch 0, gen_loss = 1.5487376367969878, disc_loss = 0.044063472081491854
Trained batch 314 in epoch 0, gen_loss = 1.5476752788301498, disc_loss = 0.04403843786789193
Trained batch 315 in epoch 0, gen_loss = 1.547729203595391, disc_loss = 0.04392516608217354
Trained batch 316 in epoch 0, gen_loss = 1.5468896905706508, disc_loss = 0.043814827616793645
Trained batch 317 in epoch 0, gen_loss = 1.5457638648321044, disc_loss = 0.043703814671937166
Trained batch 318 in epoch 0, gen_loss = 1.545105662839166, disc_loss = 0.04359740329699059
Trained batch 319 in epoch 0, gen_loss = 1.5444983124732972, disc_loss = 0.043512515562906626
Trained batch 320 in epoch 0, gen_loss = 1.544165062384442, disc_loss = 0.043447186998483316
Trained batch 321 in epoch 0, gen_loss = 1.5435637702112612, disc_loss = 0.04336836379562267
Trained batch 322 in epoch 0, gen_loss = 1.5428025394032245, disc_loss = 0.04326529677989013
Trained batch 323 in epoch 0, gen_loss = 1.5421158594113809, disc_loss = 0.043157098098387824
Trained batch 324 in epoch 0, gen_loss = 1.541358510164114, disc_loss = 0.04304191549165318
Trained batch 325 in epoch 0, gen_loss = 1.5406401683947792, disc_loss = 0.04293132711850404
Trained batch 326 in epoch 0, gen_loss = 1.5401549321066714, disc_loss = 0.042835756591649364
Trained batch 327 in epoch 0, gen_loss = 1.5391043744436124, disc_loss = 0.04271793409560171
Trained batch 328 in epoch 0, gen_loss = 1.5388830171892345, disc_loss = 0.04260660566058361
Trained batch 329 in epoch 0, gen_loss = 1.5386228185711486, disc_loss = 0.042492881690321324
Trained batch 330 in epoch 0, gen_loss = 1.5375995340664221, disc_loss = 0.04237512777435658
Trained batch 331 in epoch 0, gen_loss = 1.53691433423973, disc_loss = 0.04226574613305976
Trained batch 332 in epoch 0, gen_loss = 1.5366158929315057, disc_loss = 0.042162285896029335
Trained batch 333 in epoch 0, gen_loss = 1.5369202812274774, disc_loss = 0.04205356250185252
Trained batch 334 in epoch 0, gen_loss = 1.5362665574942063, disc_loss = 0.04195013787500115
Trained batch 335 in epoch 0, gen_loss = 1.5362637060738744, disc_loss = 0.04184066531472906
Trained batch 336 in epoch 0, gen_loss = 1.5361538616061565, disc_loss = 0.04172701285309117
Trained batch 337 in epoch 0, gen_loss = 1.535755736940711, disc_loss = 0.04161442658373502
Trained batch 338 in epoch 0, gen_loss = 1.5351689248661728, disc_loss = 0.041502152516020345
Trained batch 339 in epoch 0, gen_loss = 1.5348916355301352, disc_loss = 0.041389393579105246
Trained batch 340 in epoch 0, gen_loss = 1.5343598302158792, disc_loss = 0.04127751210638898
Trained batch 341 in epoch 0, gen_loss = 1.534022273027409, disc_loss = 0.04116696447790301
Trained batch 342 in epoch 0, gen_loss = 1.533944277652151, disc_loss = 0.04105924366452017
Trained batch 343 in epoch 0, gen_loss = 1.5334238202072854, disc_loss = 0.040962223817058295
Trained batch 344 in epoch 0, gen_loss = 1.5328188408976016, disc_loss = 0.04086075388907415
Trained batch 345 in epoch 0, gen_loss = 1.5321533710970354, disc_loss = 0.04075265431041813
Trained batch 346 in epoch 0, gen_loss = 1.5315313933562134, disc_loss = 0.04064332750781576
Trained batch 347 in epoch 0, gen_loss = 1.5320720956928429, disc_loss = 0.04053799423654082
Trained batch 348 in epoch 0, gen_loss = 1.531482533602455, disc_loss = 0.040438198183601816
Trained batch 349 in epoch 0, gen_loss = 1.5311987035615104, disc_loss = 0.04034611931403301
Trained batch 350 in epoch 0, gen_loss = 1.5304198832253786, disc_loss = 0.040243849031590034
Trained batch 351 in epoch 0, gen_loss = 1.5295788564465262, disc_loss = 0.04022538348759885
Trained batch 352 in epoch 0, gen_loss = 1.5284726248246752, disc_loss = 0.04019740652939352
Trained batch 353 in epoch 0, gen_loss = 1.5275431356187594, disc_loss = 0.04012701690978355
Trained batch 354 in epoch 0, gen_loss = 1.52728481460625, disc_loss = 0.04004699025945869
Trained batch 355 in epoch 0, gen_loss = 1.526827265372437, disc_loss = 0.03995110221230687
Trained batch 356 in epoch 0, gen_loss = 1.5259280041152357, disc_loss = 0.039853919622897895
Trained batch 357 in epoch 0, gen_loss = 1.525103277001301, disc_loss = 0.039755990865962924
Trained batch 358 in epoch 0, gen_loss = 1.52434970973926, disc_loss = 0.039659839933530575
Trained batch 359 in epoch 0, gen_loss = 1.5238906969626744, disc_loss = 0.03955982583963002
Trained batch 360 in epoch 0, gen_loss = 1.5233385856792208, disc_loss = 0.03945972907635541
Trained batch 361 in epoch 0, gen_loss = 1.5231019479135124, disc_loss = 0.03935932683776447
Trained batch 362 in epoch 0, gen_loss = 1.5231370091766694, disc_loss = 0.03925865699124032
Trained batch 363 in epoch 0, gen_loss = 1.5226602311972732, disc_loss = 0.03916063716003139
Trained batch 364 in epoch 0, gen_loss = 1.5221529310696746, disc_loss = 0.03906513803689549
Trained batch 365 in epoch 0, gen_loss = 1.5211091504070928, disc_loss = 0.03896978042340364
Trained batch 366 in epoch 0, gen_loss = 1.520271590360179, disc_loss = 0.0388717501296101
Trained batch 367 in epoch 0, gen_loss = 1.5193613864805386, disc_loss = 0.03877348564539874
Trained batch 368 in epoch 0, gen_loss = 1.5185179471323484, disc_loss = 0.03868014736449331
Trained batch 369 in epoch 0, gen_loss = 1.517883480561746, disc_loss = 0.0385862295994082
Trained batch 370 in epoch 0, gen_loss = 1.5174111285299625, disc_loss = 0.038490306452981064
Trained batch 371 in epoch 0, gen_loss = 1.5168426491880929, disc_loss = 0.03839639007797344
Trained batch 372 in epoch 0, gen_loss = 1.5162223861939785, disc_loss = 0.03830567330444087
Trained batch 373 in epoch 0, gen_loss = 1.5156438280554378, disc_loss = 0.03821442534532
Trained batch 374 in epoch 0, gen_loss = 1.5152201499938964, disc_loss = 0.0381255210172385
Trained batch 375 in epoch 0, gen_loss = 1.5148711220381108, disc_loss = 0.038032909677527406
Trained batch 376 in epoch 0, gen_loss = 1.515240527906848, disc_loss = 0.037944224573528536
Trained batch 377 in epoch 0, gen_loss = 1.5150223468977309, disc_loss = 0.03785474983440643
Trained batch 378 in epoch 0, gen_loss = 1.5144379418883915, disc_loss = 0.03777072181013513
Trained batch 379 in epoch 0, gen_loss = 1.513908769896156, disc_loss = 0.03768900723968584
Trained batch 380 in epoch 0, gen_loss = 1.5136148244377197, disc_loss = 0.03760201481337173
Trained batch 381 in epoch 0, gen_loss = 1.5134048000056082, disc_loss = 0.037516236844648124
Trained batch 382 in epoch 0, gen_loss = 1.5129164251895237, disc_loss = 0.037432303669796795
Trained batch 383 in epoch 0, gen_loss = 1.5128164862593014, disc_loss = 0.03734773765305969
Trained batch 384 in epoch 0, gen_loss = 1.5122118510209122, disc_loss = 0.037263574402222964
Trained batch 385 in epoch 0, gen_loss = 1.512011107076635, disc_loss = 0.037179809047386936
Trained batch 386 in epoch 0, gen_loss = 1.5117188094506275, disc_loss = 0.03709453940259182
Trained batch 387 in epoch 0, gen_loss = 1.5109440115923733, disc_loss = 0.03700714265344396
Trained batch 388 in epoch 0, gen_loss = 1.5104462870595388, disc_loss = 0.036919265649709994
Trained batch 389 in epoch 0, gen_loss = 1.5096753921264257, disc_loss = 0.036837515423002724
Trained batch 390 in epoch 0, gen_loss = 1.5087693411370982, disc_loss = 0.03676012489894676
Trained batch 391 in epoch 0, gen_loss = 1.5087402721448822, disc_loss = 0.03668205264174113
Trained batch 392 in epoch 0, gen_loss = 1.5083990363977642, disc_loss = 0.036597027415504475
Trained batch 393 in epoch 0, gen_loss = 1.5081952138600616, disc_loss = 0.0365169903489189
Trained batch 394 in epoch 0, gen_loss = 1.508151960071129, disc_loss = 0.036434848258224656
Trained batch 395 in epoch 0, gen_loss = 1.507446154500499, disc_loss = 0.036351099199347314
Trained batch 396 in epoch 0, gen_loss = 1.5074014309371448, disc_loss = 0.03627013535970723
Trained batch 397 in epoch 0, gen_loss = 1.5070517632230442, disc_loss = 0.03619010205294038
Trained batch 398 in epoch 0, gen_loss = 1.5065711524552272, disc_loss = 0.0361121137723336
Trained batch 399 in epoch 0, gen_loss = 1.5058303660154342, disc_loss = 0.03603043477633037
Trained batch 400 in epoch 0, gen_loss = 1.5056579912689856, disc_loss = 0.03594839569538869
Trained batch 401 in epoch 0, gen_loss = 1.5059251654800492, disc_loss = 0.0358670847247174
Trained batch 402 in epoch 0, gen_loss = 1.5058017013682325, disc_loss = 0.0357880863689219
Trained batch 403 in epoch 0, gen_loss = 1.5050539014363054, disc_loss = 0.03570851136983308
Trained batch 404 in epoch 0, gen_loss = 1.5051454385121663, disc_loss = 0.035627140195603355
Trained batch 405 in epoch 0, gen_loss = 1.504486795716685, disc_loss = 0.03555081235107236
Trained batch 406 in epoch 0, gen_loss = 1.5043240056283937, disc_loss = 0.0354751288474375
Trained batch 407 in epoch 0, gen_loss = 1.5039444147956138, disc_loss = 0.03539453927591881
Trained batch 408 in epoch 0, gen_loss = 1.503453418794646, disc_loss = 0.035317291263126584
Trained batch 409 in epoch 0, gen_loss = 1.5028602399477144, disc_loss = 0.035242192017868525
Trained batch 410 in epoch 0, gen_loss = 1.5027035750321809, disc_loss = 0.035165913789952284
Trained batch 411 in epoch 0, gen_loss = 1.5019858751482176, disc_loss = 0.03509655300453215
Trained batch 412 in epoch 0, gen_loss = 1.5023671951478677, disc_loss = 0.03503024989578954
Trained batch 413 in epoch 0, gen_loss = 1.5018058514249497, disc_loss = 0.03496570176060271
Trained batch 414 in epoch 0, gen_loss = 1.5024695695164692, disc_loss = 0.0348943563733609
Trained batch 415 in epoch 0, gen_loss = 1.5026093469216273, disc_loss = 0.03481762477895245
Trained batch 416 in epoch 0, gen_loss = 1.5019405042524818, disc_loss = 0.03474308255271499
Trained batch 417 in epoch 0, gen_loss = 1.501671983864889, disc_loss = 0.03467123841579433
Trained batch 418 in epoch 0, gen_loss = 1.5010728625522878, disc_loss = 0.034596315343355256
Trained batch 419 in epoch 0, gen_loss = 1.5007259584608532, disc_loss = 0.03451988103555604
Trained batch 420 in epoch 0, gen_loss = 1.5007425991203327, disc_loss = 0.03444529955680183
Trained batch 421 in epoch 0, gen_loss = 1.50057458595077, disc_loss = 0.034375329691722495
Trained batch 422 in epoch 0, gen_loss = 1.5001468246992034, disc_loss = 0.0343040472841062
Trained batch 423 in epoch 0, gen_loss = 1.4997564318045131, disc_loss = 0.03423330805347881
Trained batch 424 in epoch 0, gen_loss = 1.4994045145371382, disc_loss = 0.03416122010415968
Trained batch 425 in epoch 0, gen_loss = 1.4995521074729345, disc_loss = 0.034085819213498084
Trained batch 426 in epoch 0, gen_loss = 1.499079059381954, disc_loss = 0.034014618494253454
Trained batch 427 in epoch 0, gen_loss = 1.4987444509969694, disc_loss = 0.03394994228560408
Trained batch 428 in epoch 0, gen_loss = 1.498011034963292, disc_loss = 0.03388609219286026
Trained batch 429 in epoch 0, gen_loss = 1.497843616785005, disc_loss = 0.03381893673565152
Trained batch 430 in epoch 0, gen_loss = 1.4975003540654193, disc_loss = 0.033755929123938704
Trained batch 431 in epoch 0, gen_loss = 1.4973954500423536, disc_loss = 0.03369248543512421
Trained batch 432 in epoch 0, gen_loss = 1.4972459917531002, disc_loss = 0.033623105378533275
Trained batch 433 in epoch 0, gen_loss = 1.4969311150537659, disc_loss = 0.033563156402991734
Trained batch 434 in epoch 0, gen_loss = 1.4963032308666186, disc_loss = 0.03350008893222816
Trained batch 435 in epoch 0, gen_loss = 1.4954463082169174, disc_loss = 0.033435116559395205
Trained batch 436 in epoch 0, gen_loss = 1.4951150583729864, disc_loss = 0.033365296678366116
Trained batch 437 in epoch 0, gen_loss = 1.494421776299063, disc_loss = 0.03329592628817002
Trained batch 438 in epoch 0, gen_loss = 1.4941866764446596, disc_loss = 0.03322612220455377
Trained batch 439 in epoch 0, gen_loss = 1.4944384176622738, disc_loss = 0.033158415817359295
Trained batch 440 in epoch 0, gen_loss = 1.4948668050117233, disc_loss = 0.033091726792076614
Trained batch 441 in epoch 0, gen_loss = 1.4944424246231356, disc_loss = 0.03302465922228689
Trained batch 442 in epoch 0, gen_loss = 1.4944961601132465, disc_loss = 0.032956849885620934
Trained batch 443 in epoch 0, gen_loss = 1.4943466234851528, disc_loss = 0.03288973621061273
Trained batch 444 in epoch 0, gen_loss = 1.4943336157316571, disc_loss = 0.032825993873660315
Trained batch 445 in epoch 0, gen_loss = 1.4938326627684282, disc_loss = 0.0327655112787438
Trained batch 446 in epoch 0, gen_loss = 1.4940107426120663, disc_loss = 0.032698930951639574
Trained batch 447 in epoch 0, gen_loss = 1.4941092537982124, disc_loss = 0.032637054913461076
Trained batch 448 in epoch 0, gen_loss = 1.4939161331988124, disc_loss = 0.03257735537672063
Trained batch 449 in epoch 0, gen_loss = 1.4936088315645855, disc_loss = 0.03251021668004493
Trained batch 450 in epoch 0, gen_loss = 1.4931621229040648, disc_loss = 0.03244558083948714
Trained batch 451 in epoch 0, gen_loss = 1.4930526851552777, disc_loss = 0.03238205321079565
Trained batch 452 in epoch 0, gen_loss = 1.4922511811814299, disc_loss = 0.032318106952182964
Trained batch 453 in epoch 0, gen_loss = 1.4917458524262852, disc_loss = 0.03225304478715842
Trained batch 454 in epoch 0, gen_loss = 1.491569308396224, disc_loss = 0.032186938843761496
Trained batch 455 in epoch 0, gen_loss = 1.4910435164183902, disc_loss = 0.03212097751562843
Trained batch 456 in epoch 0, gen_loss = 1.490798552396261, disc_loss = 0.03205701090442322
Trained batch 457 in epoch 0, gen_loss = 1.4905306223178014, disc_loss = 0.03199317726747877
Trained batch 458 in epoch 0, gen_loss = 1.4898073379770083, disc_loss = 0.03192737401936869
Trained batch 459 in epoch 0, gen_loss = 1.4893744867780934, disc_loss = 0.031869665627701854
Trained batch 460 in epoch 0, gen_loss = 1.4887614255354875, disc_loss = 0.03181240602912595
Trained batch 461 in epoch 0, gen_loss = 1.488201482987507, disc_loss = 0.03174811517199889
Trained batch 462 in epoch 0, gen_loss = 1.487845236745303, disc_loss = 0.031684875399524
Trained batch 463 in epoch 0, gen_loss = 1.4874181356923333, disc_loss = 0.03162104092966886
Trained batch 464 in epoch 0, gen_loss = 1.4874728689911545, disc_loss = 0.03156049140974358
Trained batch 465 in epoch 0, gen_loss = 1.4879629407317854, disc_loss = 0.031502933996627625
Trained batch 466 in epoch 0, gen_loss = 1.4875797908872812, disc_loss = 0.03144395509131484
Trained batch 467 in epoch 0, gen_loss = 1.4872510542726924, disc_loss = 0.0313832760481542
Trained batch 468 in epoch 0, gen_loss = 1.486614753188355, disc_loss = 0.03132153491351579
Trained batch 469 in epoch 0, gen_loss = 1.4860813229642016, disc_loss = 0.03125883004048522
Trained batch 470 in epoch 0, gen_loss = 1.4853165957072232, disc_loss = 0.03119709443438387
Trained batch 471 in epoch 0, gen_loss = 1.4850232214745829, disc_loss = 0.031135946081830897
Trained batch 472 in epoch 0, gen_loss = 1.4845281524335607, disc_loss = 0.031075831639273268
Trained batch 473 in epoch 0, gen_loss = 1.483781937053938, disc_loss = 0.031030728570863465
Trained batch 474 in epoch 0, gen_loss = 1.4833924291008398, disc_loss = 0.030992131263360773
Trained batch 475 in epoch 0, gen_loss = 1.483246436890434, disc_loss = 0.03094452084702471
Trained batch 476 in epoch 0, gen_loss = 1.483187759197483, disc_loss = 0.030884330895772315
Trained batch 477 in epoch 0, gen_loss = 1.483261542090811, disc_loss = 0.030825928442723752
Trained batch 478 in epoch 0, gen_loss = 1.483751519736766, disc_loss = 0.030767900833037598
Trained batch 479 in epoch 0, gen_loss = 1.4833391149838766, disc_loss = 0.030709024087749035
Trained batch 480 in epoch 0, gen_loss = 1.4828844677633655, disc_loss = 0.030654143433380878
Trained batch 481 in epoch 0, gen_loss = 1.482443811735177, disc_loss = 0.03060150258141643
Trained batch 482 in epoch 0, gen_loss = 1.4820934385986801, disc_loss = 0.03054351800272731
Trained batch 483 in epoch 0, gen_loss = 1.4816455129256918, disc_loss = 0.03048692675945272
Trained batch 484 in epoch 0, gen_loss = 1.4812099446955416, disc_loss = 0.03043032076531426
Trained batch 485 in epoch 0, gen_loss = 1.4811801998703569, disc_loss = 0.030372925754492804
Trained batch 486 in epoch 0, gen_loss = 1.4809630367545377, disc_loss = 0.030316428314594197
Trained batch 487 in epoch 0, gen_loss = 1.4805536766032703, disc_loss = 0.030259872671955297
Trained batch 488 in epoch 0, gen_loss = 1.479942208418817, disc_loss = 0.030204164886281488
Trained batch 489 in epoch 0, gen_loss = 1.479560742329578, disc_loss = 0.03014685402087373
Trained batch 490 in epoch 0, gen_loss = 1.479055099477593, disc_loss = 0.03009315283258698
Trained batch 491 in epoch 0, gen_loss = 1.4793229854203822, disc_loss = 0.030042208554895172
Trained batch 492 in epoch 0, gen_loss = 1.478706613273698, disc_loss = 0.029989336655781233
Trained batch 493 in epoch 0, gen_loss = 1.4781863448108257, disc_loss = 0.029938984346276277
Trained batch 494 in epoch 0, gen_loss = 1.4775710854867492, disc_loss = 0.02988439092266778
Trained batch 495 in epoch 0, gen_loss = 1.4772705702531723, disc_loss = 0.029830894226653335
Trained batch 496 in epoch 0, gen_loss = 1.477077623488198, disc_loss = 0.029778980742062495
Trained batch 497 in epoch 0, gen_loss = 1.4765187951934386, disc_loss = 0.029725839004030894
Trained batch 498 in epoch 0, gen_loss = 1.4763142768749016, disc_loss = 0.029672988657074382
Trained batch 499 in epoch 0, gen_loss = 1.4764699449539185, disc_loss = 0.029618974446551875
Trained batch 500 in epoch 0, gen_loss = 1.4765648489702723, disc_loss = 0.029566864749582155
Trained batch 501 in epoch 0, gen_loss = 1.4761658659969192, disc_loss = 0.029681407936256884
Trained batch 502 in epoch 0, gen_loss = 1.4746226548674566, disc_loss = 0.030433466058792862
Trained batch 503 in epoch 0, gen_loss = 1.4743291702535417, disc_loss = 0.030519824782488054
Trained batch 504 in epoch 0, gen_loss = 1.4744384005518243, disc_loss = 0.03063659387350193
Trained batch 505 in epoch 0, gen_loss = 1.4741017964517646, disc_loss = 0.03062398865033979
Trained batch 506 in epoch 0, gen_loss = 1.47338459853825, disc_loss = 0.030600664465544887
Trained batch 507 in epoch 0, gen_loss = 1.472503731335242, disc_loss = 0.03057061069838402
Trained batch 508 in epoch 0, gen_loss = 1.4719768589278335, disc_loss = 0.030543108275645065
Trained batch 509 in epoch 0, gen_loss = 1.4717118915389567, disc_loss = 0.030506449850851342
Trained batch 510 in epoch 0, gen_loss = 1.4716489727949675, disc_loss = 0.030464455383964643
Trained batch 511 in epoch 0, gen_loss = 1.471201762324199, disc_loss = 0.030420544117760073
Trained batch 512 in epoch 0, gen_loss = 1.4709071185853746, disc_loss = 0.030372289157123984
Trained batch 513 in epoch 0, gen_loss = 1.4708822884448307, disc_loss = 0.03032306941649206
Trained batch 514 in epoch 0, gen_loss = 1.4708484656602434, disc_loss = 0.03027635834347095
Trained batch 515 in epoch 0, gen_loss = 1.4706551458022392, disc_loss = 0.030226123095769795
Trained batch 516 in epoch 0, gen_loss = 1.470030957771685, disc_loss = 0.030179425180309617
Trained batch 517 in epoch 0, gen_loss = 1.4702089543968555, disc_loss = 0.03013312815968127
Trained batch 518 in epoch 0, gen_loss = 1.4701307173638904, disc_loss = 0.030082709730875557
Trained batch 519 in epoch 0, gen_loss = 1.4696802033827856, disc_loss = 0.030040539140911558
Trained batch 520 in epoch 0, gen_loss = 1.4697790383834985, disc_loss = 0.02999049858319718
Trained batch 521 in epoch 0, gen_loss = 1.4695808809835793, disc_loss = 0.029939438109116635
Trained batch 522 in epoch 0, gen_loss = 1.4692117078354436, disc_loss = 0.029888039828548797
Trained batch 523 in epoch 0, gen_loss = 1.4689661830891179, disc_loss = 0.029836827867978984
Trained batch 524 in epoch 0, gen_loss = 1.4685815232140678, disc_loss = 0.029785096699682375
Trained batch 525 in epoch 0, gen_loss = 1.4684600886736532, disc_loss = 0.02973501372373284
Trained batch 526 in epoch 0, gen_loss = 1.4681147305291338, disc_loss = 0.02968317222100218
Trained batch 527 in epoch 0, gen_loss = 1.4678996952645706, disc_loss = 0.029632674838164046
Trained batch 528 in epoch 0, gen_loss = 1.4673889005567267, disc_loss = 0.0296390280103318
Trained batch 529 in epoch 0, gen_loss = 1.466696159119876, disc_loss = 0.029660302904249994
Trained batch 530 in epoch 0, gen_loss = 1.4667249273670147, disc_loss = 0.02966591183788085
Trained batch 531 in epoch 0, gen_loss = 1.4667250531956666, disc_loss = 0.029636877257406668
Trained batch 532 in epoch 0, gen_loss = 1.4662630182269814, disc_loss = 0.02961872514327691
Trained batch 533 in epoch 0, gen_loss = 1.4658657392759002, disc_loss = 0.02958821575179145
Trained batch 534 in epoch 0, gen_loss = 1.4651954354526842, disc_loss = 0.029546110424491637
Trained batch 535 in epoch 0, gen_loss = 1.4651241057844304, disc_loss = 0.02950423287245994
Trained batch 536 in epoch 0, gen_loss = 1.4645396331169085, disc_loss = 0.029457885197284015
Trained batch 537 in epoch 0, gen_loss = 1.4640673102056228, disc_loss = 0.029409317357931286
Trained batch 538 in epoch 0, gen_loss = 1.463780100580049, disc_loss = 0.029358997475571847
Trained batch 539 in epoch 0, gen_loss = 1.4635603573587206, disc_loss = 0.02930840583953627
Trained batch 540 in epoch 0, gen_loss = 1.4633179043665832, disc_loss = 0.029258833800669754
Trained batch 541 in epoch 0, gen_loss = 1.463028844212254, disc_loss = 0.029211094220833872
Trained batch 542 in epoch 0, gen_loss = 1.4626023442266616, disc_loss = 0.02916222652802021
Trained batch 543 in epoch 0, gen_loss = 1.4620175070184118, disc_loss = 0.029126101480120698
Trained batch 544 in epoch 0, gen_loss = 1.461582280517718, disc_loss = 0.029089516591186713
Trained batch 545 in epoch 0, gen_loss = 1.4618282383614845, disc_loss = 0.029044192108016925
Trained batch 546 in epoch 0, gen_loss = 1.4616275775149274, disc_loss = 0.028998845564397274
Trained batch 547 in epoch 0, gen_loss = 1.4614867689835764, disc_loss = 0.028952318780934846
Trained batch 548 in epoch 0, gen_loss = 1.4611199301665816, disc_loss = 0.028906091133544802
Trained batch 549 in epoch 0, gen_loss = 1.4608831644058227, disc_loss = 0.02886061484988948
Trained batch 550 in epoch 0, gen_loss = 1.4603388387365046, disc_loss = 0.028816348105498307
Trained batch 551 in epoch 0, gen_loss = 1.4599846238675325, disc_loss = 0.028770120853036846
Trained batch 552 in epoch 0, gen_loss = 1.4594152887734109, disc_loss = 0.02872389329451677
Trained batch 553 in epoch 0, gen_loss = 1.4590365071158977, disc_loss = 0.0286775897414632
Trained batch 554 in epoch 0, gen_loss = 1.4592263172338675, disc_loss = 0.028629716484689968
Trained batch 555 in epoch 0, gen_loss = 1.4587882720738006, disc_loss = 0.028581925851867446
Trained batch 556 in epoch 0, gen_loss = 1.4584278150777628, disc_loss = 0.028534927100897892
Trained batch 557 in epoch 0, gen_loss = 1.457979551139271, disc_loss = 0.028490224343058604
Trained batch 558 in epoch 0, gen_loss = 1.4577048357995976, disc_loss = 0.028442539138076345
Trained batch 559 in epoch 0, gen_loss = 1.458056002855301, disc_loss = 0.02839461918338202
Trained batch 560 in epoch 0, gen_loss = 1.4578495229629271, disc_loss = 0.028348224331772556
Trained batch 561 in epoch 0, gen_loss = 1.45758992709299, disc_loss = 0.028302134663028992
Trained batch 562 in epoch 0, gen_loss = 1.4570162596965133, disc_loss = 0.028257051930261602
Trained batch 563 in epoch 0, gen_loss = 1.4569467821865216, disc_loss = 0.028212187049253216
Trained batch 564 in epoch 0, gen_loss = 1.4565249198305923, disc_loss = 0.028171137668011065
Trained batch 565 in epoch 0, gen_loss = 1.4562640695605598, disc_loss = 0.028128679427515728
Trained batch 566 in epoch 0, gen_loss = 1.4561779431775344, disc_loss = 0.02808375043073436
Trained batch 567 in epoch 0, gen_loss = 1.4564613725098086, disc_loss = 0.028040496491036758
Trained batch 568 in epoch 0, gen_loss = 1.4560454451136933, disc_loss = 0.027995389474143383
Trained batch 569 in epoch 0, gen_loss = 1.4557641552205671, disc_loss = 0.02795000213664025
Trained batch 570 in epoch 0, gen_loss = 1.4559045823359447, disc_loss = 0.027904272600584347
Trained batch 571 in epoch 0, gen_loss = 1.4556217466617798, disc_loss = 0.027860306718686296
Trained batch 572 in epoch 0, gen_loss = 1.4555610268527925, disc_loss = 0.027817536480269717
Trained batch 573 in epoch 0, gen_loss = 1.455513063415833, disc_loss = 0.027772976539847328
Trained batch 574 in epoch 0, gen_loss = 1.4553942470965178, disc_loss = 0.027728682457995802
Trained batch 575 in epoch 0, gen_loss = 1.4552740309801366, disc_loss = 0.02768353675188943
Trained batch 576 in epoch 0, gen_loss = 1.4549601435454713, disc_loss = 0.027639496793278026
Trained batch 577 in epoch 0, gen_loss = 1.4547238762403443, disc_loss = 0.02759715250494268
Trained batch 578 in epoch 0, gen_loss = 1.454388431110942, disc_loss = 0.027554664251938244
Trained batch 579 in epoch 0, gen_loss = 1.4543768183938388, disc_loss = 0.027510568351235946
Trained batch 580 in epoch 0, gen_loss = 1.4542720108557485, disc_loss = 0.027466459224832512
Trained batch 581 in epoch 0, gen_loss = 1.4540227434479494, disc_loss = 0.027423000972297145
Trained batch 582 in epoch 0, gen_loss = 1.4537658981761639, disc_loss = 0.02737942652790416
Trained batch 583 in epoch 0, gen_loss = 1.453467175976871, disc_loss = 0.02733657066809964
Trained batch 584 in epoch 0, gen_loss = 1.4529951908649543, disc_loss = 0.027292372167914407
Trained batch 585 in epoch 0, gen_loss = 1.4530247730606651, disc_loss = 0.02725118886041312
Trained batch 586 in epoch 0, gen_loss = 1.4527836979146305, disc_loss = 0.027208487742209214
Trained batch 587 in epoch 0, gen_loss = 1.452961039786436, disc_loss = 0.027164574270809805
Trained batch 588 in epoch 0, gen_loss = 1.4526480956474266, disc_loss = 0.027120726821661084
Trained batch 589 in epoch 0, gen_loss = 1.4523040322934166, disc_loss = 0.027079232088961024
Trained batch 590 in epoch 0, gen_loss = 1.4518229269537628, disc_loss = 0.027037883055862827
Trained batch 591 in epoch 0, gen_loss = 1.4516901659804422, disc_loss = 0.026995406456203578
Trained batch 592 in epoch 0, gen_loss = 1.4513724244264086, disc_loss = 0.026953167991137877
Trained batch 593 in epoch 0, gen_loss = 1.4509589142269559, disc_loss = 0.02691060507133829
Trained batch 594 in epoch 0, gen_loss = 1.4506924647243082, disc_loss = 0.02686947080768457
Trained batch 595 in epoch 0, gen_loss = 1.450443301424884, disc_loss = 0.026829503182065517
Trained batch 596 in epoch 0, gen_loss = 1.4501077785364147, disc_loss = 0.026790542158312235
Trained batch 597 in epoch 0, gen_loss = 1.4497539542590496, disc_loss = 0.026748825251833416
Trained batch 598 in epoch 0, gen_loss = 1.4496809713828545, disc_loss = 0.02670768743325709
Trained batch 599 in epoch 0, gen_loss = 1.4492801972230276, disc_loss = 0.02666831915441435
Trained batch 600 in epoch 0, gen_loss = 1.4495671249665754, disc_loss = 0.02662695563973986
Trained batch 601 in epoch 0, gen_loss = 1.4494699469436443, disc_loss = 0.026588450147471764
Trained batch 602 in epoch 0, gen_loss = 1.4490279241976256, disc_loss = 0.026550995561473417
Trained batch 603 in epoch 0, gen_loss = 1.4488995477853233, disc_loss = 0.026511075158814734
Trained batch 604 in epoch 0, gen_loss = 1.4487953623464285, disc_loss = 0.026470746439188904
Trained batch 605 in epoch 0, gen_loss = 1.448286506602473, disc_loss = 0.026432044715536052
Trained batch 606 in epoch 0, gen_loss = 1.4483645879456395, disc_loss = 0.026391921079904762
Trained batch 607 in epoch 0, gen_loss = 1.4480887353420258, disc_loss = 0.02635201329643391
Trained batch 608 in epoch 0, gen_loss = 1.447575739647563, disc_loss = 0.026313763551302376
Trained batch 609 in epoch 0, gen_loss = 1.4475259003092031, disc_loss = 0.02627375732103485
Trained batch 610 in epoch 0, gen_loss = 1.4469616705774286, disc_loss = 0.026233456276643734
Trained batch 611 in epoch 0, gen_loss = 1.4466771191241694, disc_loss = 0.026193723542687293
Trained batch 612 in epoch 0, gen_loss = 1.4461407925915368, disc_loss = 0.02615510174251795
Trained batch 613 in epoch 0, gen_loss = 1.4459311841753484, disc_loss = 0.02611538320070691
Trained batch 614 in epoch 0, gen_loss = 1.4453374936328671, disc_loss = 0.02607626436463731
Trained batch 615 in epoch 0, gen_loss = 1.4452575398729992, disc_loss = 0.026037628460991464
Trained batch 616 in epoch 0, gen_loss = 1.4449405913608, disc_loss = 0.026002604143227626
Trained batch 617 in epoch 0, gen_loss = 1.4449366464198214, disc_loss = 0.025964883535318256
Trained batch 618 in epoch 0, gen_loss = 1.4446261439454382, disc_loss = 0.02592537475404554
Trained batch 619 in epoch 0, gen_loss = 1.4447015933452114, disc_loss = 0.02588654641689162
Trained batch 620 in epoch 0, gen_loss = 1.4448082425936024, disc_loss = 0.025847463707901513
Trained batch 621 in epoch 0, gen_loss = 1.444638904267952, disc_loss = 0.02580841927556321
Trained batch 622 in epoch 0, gen_loss = 1.4444375933651747, disc_loss = 0.025770263977529687
Trained batch 623 in epoch 0, gen_loss = 1.444194608200819, disc_loss = 0.025733507008669384
Trained batch 624 in epoch 0, gen_loss = 1.44389262008667, disc_loss = 0.0256978768741712
Trained batch 625 in epoch 0, gen_loss = 1.443434248145777, disc_loss = 0.02566018271741246
Trained batch 626 in epoch 0, gen_loss = 1.4432180074223302, disc_loss = 0.02562221361434108
Trained batch 627 in epoch 0, gen_loss = 1.4431623457723362, disc_loss = 0.025585030052057544
Trained batch 628 in epoch 0, gen_loss = 1.4428324602745675, disc_loss = 0.025549742738925074
Trained batch 629 in epoch 0, gen_loss = 1.4426415513432216, disc_loss = 0.025512341866713195
Trained batch 630 in epoch 0, gen_loss = 1.4424997911967112, disc_loss = 0.025474927327802283
Trained batch 631 in epoch 0, gen_loss = 1.4422271530839461, disc_loss = 0.025436886039538944
Trained batch 632 in epoch 0, gen_loss = 1.4418015726746354, disc_loss = 0.025399445125385882
Trained batch 633 in epoch 0, gen_loss = 1.4416989646499465, disc_loss = 0.02536276207865166
Trained batch 634 in epoch 0, gen_loss = 1.4414358991337572, disc_loss = 0.025326058500277714
Trained batch 635 in epoch 0, gen_loss = 1.4417279638209433, disc_loss = 0.02528953369459395
Trained batch 636 in epoch 0, gen_loss = 1.4415914995516863, disc_loss = 0.025254111040348488
Trained batch 637 in epoch 0, gen_loss = 1.4413567807607142, disc_loss = 0.02521961859827365
Trained batch 638 in epoch 0, gen_loss = 1.4410433938992042, disc_loss = 0.025183561373886786
Trained batch 639 in epoch 0, gen_loss = 1.4405509728938342, disc_loss = 0.02514716017376486
Trained batch 640 in epoch 0, gen_loss = 1.4405452617431023, disc_loss = 0.025110820973765647
Trained batch 641 in epoch 0, gen_loss = 1.4400835007521966, disc_loss = 0.0250755792434365
Trained batch 642 in epoch 0, gen_loss = 1.4398463664121612, disc_loss = 0.025043145478971036
Trained batch 643 in epoch 0, gen_loss = 1.439640217130969, disc_loss = 0.025010426154198205
Trained batch 644 in epoch 0, gen_loss = 1.4391947788785595, disc_loss = 0.0249758740641581
Trained batch 645 in epoch 0, gen_loss = 1.4389462620481248, disc_loss = 0.024939647610457874
Trained batch 646 in epoch 0, gen_loss = 1.438635191556291, disc_loss = 0.02490368317143338
Trained batch 647 in epoch 0, gen_loss = 1.4386826519980842, disc_loss = 0.024867807297764725
Trained batch 648 in epoch 0, gen_loss = 1.438349978949513, disc_loss = 0.024832223765537693
Trained batch 649 in epoch 0, gen_loss = 1.438126110296983, disc_loss = 0.024797638632858603
Trained batch 650 in epoch 0, gen_loss = 1.43775343601971, disc_loss = 0.024762774149911584
Trained batch 651 in epoch 0, gen_loss = 1.437350805551728, disc_loss = 0.024726349749013873
Trained batch 652 in epoch 0, gen_loss = 1.4370588301516967, disc_loss = 0.024690862563381665
Trained batch 653 in epoch 0, gen_loss = 1.436996504801129, disc_loss = 0.024655895305702048
Trained batch 654 in epoch 0, gen_loss = 1.4369385955897906, disc_loss = 0.02462088490608824
Trained batch 655 in epoch 0, gen_loss = 1.437007706521488, disc_loss = 0.024585869738607803
Trained batch 656 in epoch 0, gen_loss = 1.4369051171582947, disc_loss = 0.024551637173039185
Trained batch 657 in epoch 0, gen_loss = 1.436667125819302, disc_loss = 0.024516785739727126
Trained batch 658 in epoch 0, gen_loss = 1.4367053275405004, disc_loss = 0.02448270634987585
Trained batch 659 in epoch 0, gen_loss = 1.4363680317546381, disc_loss = 0.02444838266343471
Trained batch 660 in epoch 0, gen_loss = 1.4361858120844693, disc_loss = 0.024414580350399367
Trained batch 661 in epoch 0, gen_loss = 1.4358331335995493, disc_loss = 0.024380657791470958
Trained batch 662 in epoch 0, gen_loss = 1.4362446488658047, disc_loss = 0.02434648815131582
Trained batch 663 in epoch 0, gen_loss = 1.4366399714027542, disc_loss = 0.0243123934233592
Trained batch 664 in epoch 0, gen_loss = 1.4367417964720188, disc_loss = 0.024278073208021434
Trained batch 665 in epoch 0, gen_loss = 1.436603571022595, disc_loss = 0.02424676011175941
Trained batch 666 in epoch 0, gen_loss = 1.436471615416714, disc_loss = 0.0242144357728265
Trained batch 667 in epoch 0, gen_loss = 1.436277502489661, disc_loss = 0.024180998159732816
Trained batch 668 in epoch 0, gen_loss = 1.436049346432023, disc_loss = 0.02414724428567935
Trained batch 669 in epoch 0, gen_loss = 1.43578541438971, disc_loss = 0.02411436210021571
Trained batch 670 in epoch 0, gen_loss = 1.4356374239601783, disc_loss = 0.024080206772268107
Trained batch 671 in epoch 0, gen_loss = 1.4352891221642494, disc_loss = 0.024046186737818755
Trained batch 672 in epoch 0, gen_loss = 1.4353949495800182, disc_loss = 0.024012835468179415
Trained batch 673 in epoch 0, gen_loss = 1.435379648774597, disc_loss = 0.02398006788414187
Trained batch 674 in epoch 0, gen_loss = 1.43512700981564, disc_loss = 0.023948347160972102
Trained batch 675 in epoch 0, gen_loss = 1.4351683909723745, disc_loss = 0.023919694976551876
Trained batch 676 in epoch 0, gen_loss = 1.4347036094397878, disc_loss = 0.02388900626699084
Trained batch 677 in epoch 0, gen_loss = 1.4343612635381806, disc_loss = 0.023856562147965065
Trained batch 678 in epoch 0, gen_loss = 1.4340357331007676, disc_loss = 0.02382428403216824
Trained batch 679 in epoch 0, gen_loss = 1.4337050548371146, disc_loss = 0.023791261111995587
Trained batch 680 in epoch 0, gen_loss = 1.4338454351201106, disc_loss = 0.023759028118920188
Trained batch 681 in epoch 0, gen_loss = 1.433364346754516, disc_loss = 0.023730088850992658
Trained batch 682 in epoch 0, gen_loss = 1.4333235713084655, disc_loss = 0.02370342253322139
Trained batch 683 in epoch 0, gen_loss = 1.4329648690614087, disc_loss = 0.023678432534107046
Trained batch 684 in epoch 0, gen_loss = 1.4328165435442959, disc_loss = 0.023654645681551175
Trained batch 685 in epoch 0, gen_loss = 1.4324318895187045, disc_loss = 0.02362466754263495
Trained batch 686 in epoch 0, gen_loss = 1.4324878072461014, disc_loss = 0.02359662902845799
Trained batch 687 in epoch 0, gen_loss = 1.4322969534022862, disc_loss = 0.023565694176203432
Trained batch 688 in epoch 0, gen_loss = 1.4323400968391076, disc_loss = 0.02353645696089142
Trained batch 689 in epoch 0, gen_loss = 1.4325275191362354, disc_loss = 0.02350869496214622
Trained batch 690 in epoch 0, gen_loss = 1.4329662623177735, disc_loss = 0.023479061678163816
Trained batch 691 in epoch 0, gen_loss = 1.4326162579431698, disc_loss = 0.02344866042315416
Trained batch 692 in epoch 0, gen_loss = 1.4323337628555848, disc_loss = 0.023417295895961702
Trained batch 693 in epoch 0, gen_loss = 1.43189757581403, disc_loss = 0.02338709758902613
Trained batch 694 in epoch 0, gen_loss = 1.4318007536071669, disc_loss = 0.023356146098235154
Trained batch 695 in epoch 0, gen_loss = 1.4317416855316052, disc_loss = 0.023324434659022293
Trained batch 696 in epoch 0, gen_loss = 1.4315639381942311, disc_loss = 0.023293534513907654
Trained batch 697 in epoch 0, gen_loss = 1.431123644540508, disc_loss = 0.023266644284121136
Trained batch 698 in epoch 0, gen_loss = 1.4308850415615906, disc_loss = 0.023236949515071974
Trained batch 699 in epoch 0, gen_loss = 1.4304991936683655, disc_loss = 0.023209689256868192
Trained batch 700 in epoch 0, gen_loss = 1.4302589039659703, disc_loss = 0.023180215500265933
Trained batch 701 in epoch 0, gen_loss = 1.42991397234789, disc_loss = 0.023152807676047618
Trained batch 702 in epoch 0, gen_loss = 1.4295705170244783, disc_loss = 0.023124356592831814
Trained batch 703 in epoch 0, gen_loss = 1.429189081388441, disc_loss = 0.023093363085949517
Trained batch 704 in epoch 0, gen_loss = 1.4287078382275629, disc_loss = 0.023063456243340004
Trained batch 705 in epoch 0, gen_loss = 1.428536462547421, disc_loss = 0.02303327593382543
Trained batch 706 in epoch 0, gen_loss = 1.42846146904596, disc_loss = 0.023003409151646507
Trained batch 707 in epoch 0, gen_loss = 1.4282937347888947, disc_loss = 0.0229730724962494
Trained batch 708 in epoch 0, gen_loss = 1.428365872676349, disc_loss = 0.022943315547247312
Trained batch 709 in epoch 0, gen_loss = 1.4281138566178335, disc_loss = 0.02291252193152642
Trained batch 710 in epoch 0, gen_loss = 1.4278059557352722, disc_loss = 0.022884037697677266
Trained batch 711 in epoch 0, gen_loss = 1.4274933828731602, disc_loss = 0.02285639915891316
Trained batch 712 in epoch 0, gen_loss = 1.4275222959892948, disc_loss = 0.022829245634541584
Trained batch 713 in epoch 0, gen_loss = 1.4274053283098365, disc_loss = 0.022799476826920875
Trained batch 714 in epoch 0, gen_loss = 1.4277352853254839, disc_loss = 0.02277148718639583
Trained batch 715 in epoch 0, gen_loss = 1.4276061589158446, disc_loss = 0.02274408860017634
Trained batch 716 in epoch 0, gen_loss = 1.4276257341044385, disc_loss = 0.02271489468270022
Trained batch 717 in epoch 0, gen_loss = 1.4274984667892243, disc_loss = 0.022686065019472842
Trained batch 718 in epoch 0, gen_loss = 1.4273159450881172, disc_loss = 0.02265651323068343
Trained batch 719 in epoch 0, gen_loss = 1.427305050359832, disc_loss = 0.02262791585461754
Trained batch 720 in epoch 0, gen_loss = 1.4271036391450034, disc_loss = 0.022599457461521255
Trained batch 721 in epoch 0, gen_loss = 1.42711228049693, disc_loss = 0.0225706134946666
Trained batch 722 in epoch 0, gen_loss = 1.4269994043875203, disc_loss = 0.02254227285574797
Trained batch 723 in epoch 0, gen_loss = 1.4269458598853475, disc_loss = 0.02251433223570846
Trained batch 724 in epoch 0, gen_loss = 1.4266648483276367, disc_loss = 0.02248563346292438
Trained batch 725 in epoch 0, gen_loss = 1.4267986329790645, disc_loss = 0.022456956237423702
Trained batch 726 in epoch 0, gen_loss = 1.4267017393689372, disc_loss = 0.022429157946799387
Trained batch 727 in epoch 0, gen_loss = 1.4264440940959113, disc_loss = 0.022401904846556936
Trained batch 728 in epoch 0, gen_loss = 1.4260988721141108, disc_loss = 0.022375732693828858
Trained batch 729 in epoch 0, gen_loss = 1.425734319425609, disc_loss = 0.02234744241378232
Trained batch 730 in epoch 0, gen_loss = 1.4253976814724025, disc_loss = 0.022321689923621317
Trained batch 731 in epoch 0, gen_loss = 1.4251196029407731, disc_loss = 0.02229813378192281
Trained batch 732 in epoch 0, gen_loss = 1.4249612860595058, disc_loss = 0.022270243044111668
Trained batch 733 in epoch 0, gen_loss = 1.4246574645146362, disc_loss = 0.022242292227941673
Trained batch 734 in epoch 0, gen_loss = 1.4243215283569024, disc_loss = 0.022218784381046283
Trained batch 735 in epoch 0, gen_loss = 1.4240187215416327, disc_loss = 0.022191018474626144
Trained batch 736 in epoch 0, gen_loss = 1.4235340258159663, disc_loss = 0.022163604287426853
Trained batch 737 in epoch 0, gen_loss = 1.4239288137211064, disc_loss = 0.022136189512811287
Trained batch 738 in epoch 0, gen_loss = 1.423726360433318, disc_loss = 0.022108357012963757
Trained batch 739 in epoch 0, gen_loss = 1.4233007675892597, disc_loss = 0.022081098435257837
Trained batch 740 in epoch 0, gen_loss = 1.423169843259289, disc_loss = 0.0220536467395836
Trained batch 741 in epoch 0, gen_loss = 1.423098482532964, disc_loss = 0.02202673373204804
Trained batch 742 in epoch 0, gen_loss = 1.4228922000322817, disc_loss = 0.0219993127054318
Trained batch 743 in epoch 0, gen_loss = 1.4226045153474296, disc_loss = 0.021972324197044125
Trained batch 744 in epoch 0, gen_loss = 1.4222788697121127, disc_loss = 0.02195229630639164
Trained batch 745 in epoch 0, gen_loss = 1.4219143034306032, disc_loss = 0.02192661366672018
Trained batch 746 in epoch 0, gen_loss = 1.4219032928168056, disc_loss = 0.021900425219211424
Trained batch 747 in epoch 0, gen_loss = 1.4214661373174127, disc_loss = 0.021875159510686484
Trained batch 748 in epoch 0, gen_loss = 1.4215131114735622, disc_loss = 0.02185034265419038
Trained batch 749 in epoch 0, gen_loss = 1.4212134863535564, disc_loss = 0.021823575505210708
Trained batch 750 in epoch 0, gen_loss = 1.4215799908187197, disc_loss = 0.021797158209868668
Trained batch 751 in epoch 0, gen_loss = 1.4214175091461931, disc_loss = 0.02177297093046636
Trained batch 752 in epoch 0, gen_loss = 1.4212685779113061, disc_loss = 0.021748226552621607
Trained batch 753 in epoch 0, gen_loss = 1.4212103282108863, disc_loss = 0.021721410867696335
Trained batch 754 in epoch 0, gen_loss = 1.4209577018851476, disc_loss = 0.021696279053915513
Trained batch 755 in epoch 0, gen_loss = 1.4205740792726083, disc_loss = 0.0216712548792308
Trained batch 756 in epoch 0, gen_loss = 1.4202348370218214, disc_loss = 0.02164511780237319
Trained batch 757 in epoch 0, gen_loss = 1.4201817537675119, disc_loss = 0.021618708366734567
Trained batch 758 in epoch 0, gen_loss = 1.4200084463880938, disc_loss = 0.021593317849321073
Trained batch 759 in epoch 0, gen_loss = 1.4197336843139248, disc_loss = 0.021568946422714935
Trained batch 760 in epoch 0, gen_loss = 1.419408907088281, disc_loss = 0.02154282820117311
Trained batch 761 in epoch 0, gen_loss = 1.4192178144542564, disc_loss = 0.02151607287839285
Trained batch 762 in epoch 0, gen_loss = 1.4188790916615357, disc_loss = 0.021490004948257355
Trained batch 763 in epoch 0, gen_loss = 1.418601511816704, disc_loss = 0.021465192025518824
Trained batch 764 in epoch 0, gen_loss = 1.4183857077866597, disc_loss = 0.021439140049125876
Trained batch 765 in epoch 0, gen_loss = 1.4185457052200954, disc_loss = 0.021412959485253995
Trained batch 766 in epoch 0, gen_loss = 1.4183656929990924, disc_loss = 0.02138658352284249
Trained batch 767 in epoch 0, gen_loss = 1.4181556062151988, disc_loss = 0.021362724829941726
Trained batch 768 in epoch 0, gen_loss = 1.418159578804542, disc_loss = 0.02133638275150205
Trained batch 769 in epoch 0, gen_loss = 1.417739207713635, disc_loss = 0.021313416557809845
Trained batch 770 in epoch 0, gen_loss = 1.4175413013586893, disc_loss = 0.0212888650879404
Trained batch 771 in epoch 0, gen_loss = 1.4173474716399, disc_loss = 0.021264195068223024
Trained batch 772 in epoch 0, gen_loss = 1.4172832256455317, disc_loss = 0.02124050331788733
Trained batch 773 in epoch 0, gen_loss = 1.4169487749883372, disc_loss = 0.021214587089920883
Trained batch 774 in epoch 0, gen_loss = 1.4167743987421835, disc_loss = 0.021189203126836687
Trained batch 775 in epoch 0, gen_loss = 1.4167362599028754, disc_loss = 0.02116363886629769
Trained batch 776 in epoch 0, gen_loss = 1.4165708911311519, disc_loss = 0.021140528328901342
Trained batch 777 in epoch 0, gen_loss = 1.416265325252072, disc_loss = 0.021121974727126906
Trained batch 778 in epoch 0, gen_loss = 1.4162040835626624, disc_loss = 0.0211024933769003
Trained batch 779 in epoch 0, gen_loss = 1.4158576624515729, disc_loss = 0.02108003521302285
Trained batch 780 in epoch 0, gen_loss = 1.4155683042755811, disc_loss = 0.02105589421220343
Trained batch 781 in epoch 0, gen_loss = 1.4152840813407508, disc_loss = 0.02103194178265455
Trained batch 782 in epoch 0, gen_loss = 1.4149709455811659, disc_loss = 0.021007263820498258
Trained batch 783 in epoch 0, gen_loss = 1.414978705498637, disc_loss = 0.020983187778293375
Trained batch 784 in epoch 0, gen_loss = 1.4147498709381006, disc_loss = 0.020960146703187875
Trained batch 785 in epoch 0, gen_loss = 1.414509608545376, disc_loss = 0.020936991838571253
Trained batch 786 in epoch 0, gen_loss = 1.4142382384255396, disc_loss = 0.02091308700537908
Trained batch 787 in epoch 0, gen_loss = 1.4139597376591058, disc_loss = 0.020890010627037443
Trained batch 788 in epoch 0, gen_loss = 1.4136520477604353, disc_loss = 0.02086851913030454
Trained batch 789 in epoch 0, gen_loss = 1.4136746180208424, disc_loss = 0.02084540453653995
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 1.2016066312789917, disc_loss = 0.001546112005598843
Trained batch 1 in epoch 1, gen_loss = 1.1514889597892761, disc_loss = 0.0018503526807762682
Trained batch 2 in epoch 1, gen_loss = 1.2067485253016155, disc_loss = 0.002405920337575177
Trained batch 3 in epoch 1, gen_loss = 1.2679038345813751, disc_loss = 0.0026371943240519613
Trained batch 4 in epoch 1, gen_loss = 1.2977693319320678, disc_loss = 0.0023330474738031625
Trained batch 5 in epoch 1, gen_loss = 1.3168643116950989, disc_loss = 0.0022242814884521067
Trained batch 6 in epoch 1, gen_loss = 1.3695574317659651, disc_loss = 0.0020859589900023173
Trained batch 7 in epoch 1, gen_loss = 1.3642687648534775, disc_loss = 0.0020877434144495055
Trained batch 8 in epoch 1, gen_loss = 1.3403777281443279, disc_loss = 0.0020601583463657233
Trained batch 9 in epoch 1, gen_loss = 1.3279513716697693, disc_loss = 0.002033129252959043
Trained batch 10 in epoch 1, gen_loss = 1.3476718013936824, disc_loss = 0.002015330733477392
Trained batch 11 in epoch 1, gen_loss = 1.3599714934825897, disc_loss = 0.002023803642562901
Trained batch 12 in epoch 1, gen_loss = 1.3489495240725005, disc_loss = 0.001966140635956365
Trained batch 13 in epoch 1, gen_loss = 1.3497418931552343, disc_loss = 0.0019481113662810198
Trained batch 14 in epoch 1, gen_loss = 1.3362271070480347, disc_loss = 0.0019562221054608623
Trained batch 15 in epoch 1, gen_loss = 1.3213874995708466, disc_loss = 0.0019223844356019981
Trained batch 16 in epoch 1, gen_loss = 1.3172397333032944, disc_loss = 0.0018823194413391106
Trained batch 17 in epoch 1, gen_loss = 1.3035139309035406, disc_loss = 0.0018867754261009395
Trained batch 18 in epoch 1, gen_loss = 1.3162093727212203, disc_loss = 0.0018492112009737053
Trained batch 19 in epoch 1, gen_loss = 1.308987957239151, disc_loss = 0.0018360251327976585
Trained batch 20 in epoch 1, gen_loss = 1.3072548253195626, disc_loss = 0.00183726987978887
Trained batch 21 in epoch 1, gen_loss = 1.3012464263222434, disc_loss = 0.001821792673912238
Trained batch 22 in epoch 1, gen_loss = 1.2958402737327244, disc_loss = 0.0017742202389458923
Trained batch 23 in epoch 1, gen_loss = 1.2924402157465618, disc_loss = 0.0017492921979282983
Trained batch 24 in epoch 1, gen_loss = 1.3011630916595458, disc_loss = 0.001716306444723159
Trained batch 25 in epoch 1, gen_loss = 1.2975789675345788, disc_loss = 0.001695883802872581
Trained batch 26 in epoch 1, gen_loss = 1.2989346186319988, disc_loss = 0.0016682627071902432
Trained batch 27 in epoch 1, gen_loss = 1.3148478439876012, disc_loss = 0.001685808676744013
Trained batch 28 in epoch 1, gen_loss = 1.3149724088866135, disc_loss = 0.001700491136630419
Trained batch 29 in epoch 1, gen_loss = 1.3184775114059448, disc_loss = 0.0017295865555449078
Trained batch 30 in epoch 1, gen_loss = 1.3123901659442532, disc_loss = 0.0017962725288535079
Trained batch 31 in epoch 1, gen_loss = 1.3101572915911674, disc_loss = 0.0018467453901394038
Trained batch 32 in epoch 1, gen_loss = 1.309316584558198, disc_loss = 0.0018506453806449745
Trained batch 33 in epoch 1, gen_loss = 1.3072769501629997, disc_loss = 0.0018544050313614529
Trained batch 34 in epoch 1, gen_loss = 1.3046726601464407, disc_loss = 0.0018310346391185053
Trained batch 35 in epoch 1, gen_loss = 1.3000439239872827, disc_loss = 0.0018645407803382517
Trained batch 36 in epoch 1, gen_loss = 1.2964055087115314, disc_loss = 0.0018867974537676452
Trained batch 37 in epoch 1, gen_loss = 1.2946737251783673, disc_loss = 0.0019013707443312007
Trained batch 38 in epoch 1, gen_loss = 1.292172713157458, disc_loss = 0.0019290869568999952
Trained batch 39 in epoch 1, gen_loss = 1.2885874807834625, disc_loss = 0.001915205032855738
Trained batch 40 in epoch 1, gen_loss = 1.2833529012959177, disc_loss = 0.0019264445461264653
Trained batch 41 in epoch 1, gen_loss = 1.279147168000539, disc_loss = 0.0019083473557007632
Trained batch 42 in epoch 1, gen_loss = 1.274811725283778, disc_loss = 0.0018995350002051267
Trained batch 43 in epoch 1, gen_loss = 1.2702977684411136, disc_loss = 0.001882863608030179
Trained batch 44 in epoch 1, gen_loss = 1.269892684618632, disc_loss = 0.0019183041282101639
Trained batch 45 in epoch 1, gen_loss = 1.2753105448639912, disc_loss = 0.0019465282865617748
Trained batch 46 in epoch 1, gen_loss = 1.2785300828040915, disc_loss = 0.0019554310351947045
Trained batch 47 in epoch 1, gen_loss = 1.2791764214634895, disc_loss = 0.0019926435064310986
Trained batch 48 in epoch 1, gen_loss = 1.2771021881882025, disc_loss = 0.0019888504733787658
Trained batch 49 in epoch 1, gen_loss = 1.2759113121032715, disc_loss = 0.0019699864007998256
Trained batch 50 in epoch 1, gen_loss = 1.282077060026281, disc_loss = 0.0019946540078129983
Trained batch 51 in epoch 1, gen_loss = 1.2823439836502075, disc_loss = 0.0019962535510645607
Trained batch 52 in epoch 1, gen_loss = 1.2809426514607556, disc_loss = 0.0019791089448603395
Trained batch 53 in epoch 1, gen_loss = 1.2828385829925537, disc_loss = 0.0019635660325918623
Trained batch 54 in epoch 1, gen_loss = 1.283562055501071, disc_loss = 0.001957144011447037
Trained batch 55 in epoch 1, gen_loss = 1.2849927140133721, disc_loss = 0.0019907556946106653
Trained batch 56 in epoch 1, gen_loss = 1.2849446200487906, disc_loss = 0.002034466598272781
Trained batch 57 in epoch 1, gen_loss = 1.2827619478620331, disc_loss = 0.0020863162825317605
Trained batch 58 in epoch 1, gen_loss = 1.2854039406372328, disc_loss = 0.0021336827322572345
Trained batch 59 in epoch 1, gen_loss = 1.28550825715065, disc_loss = 0.0021618850907543672
Trained batch 60 in epoch 1, gen_loss = 1.282068723537883, disc_loss = 0.0021844198383375634
Trained batch 61 in epoch 1, gen_loss = 1.2899315972482004, disc_loss = 0.00222443945371666
Trained batch 62 in epoch 1, gen_loss = 1.2885310687716045, disc_loss = 0.0022615731226295114
Trained batch 63 in epoch 1, gen_loss = 1.2879054099321365, disc_loss = 0.00226086651582591
Trained batch 64 in epoch 1, gen_loss = 1.286954247034513, disc_loss = 0.0022514725560680605
Trained batch 65 in epoch 1, gen_loss = 1.28780719908801, disc_loss = 0.0022380850127912267
Trained batch 66 in epoch 1, gen_loss = 1.287752975278826, disc_loss = 0.0022251485636694108
Trained batch 67 in epoch 1, gen_loss = 1.287226405213861, disc_loss = 0.002209166795022183
Trained batch 68 in epoch 1, gen_loss = 1.2859953019929968, disc_loss = 0.0021967974742807014
Trained batch 69 in epoch 1, gen_loss = 1.2863658819879804, disc_loss = 0.0021907039227828918
Trained batch 70 in epoch 1, gen_loss = 1.2833810742472258, disc_loss = 0.0021916981007654586
Trained batch 71 in epoch 1, gen_loss = 1.2830618570248287, disc_loss = 0.0021942509475694452
Trained batch 72 in epoch 1, gen_loss = 1.284102777912192, disc_loss = 0.0022015733690613445
Trained batch 73 in epoch 1, gen_loss = 1.2850639079068158, disc_loss = 0.002199333004584234
Trained batch 74 in epoch 1, gen_loss = 1.2852304649353028, disc_loss = 0.0021875704677465063
Trained batch 75 in epoch 1, gen_loss = 1.2860069525869269, disc_loss = 0.002183016283149635
Trained batch 76 in epoch 1, gen_loss = 1.2857826437268938, disc_loss = 0.0021945864072541233
Trained batch 77 in epoch 1, gen_loss = 1.2835432015932524, disc_loss = 0.002199323618790517
Trained batch 78 in epoch 1, gen_loss = 1.28268839739546, disc_loss = 0.0021942320679125813
Trained batch 79 in epoch 1, gen_loss = 1.2814141169190407, disc_loss = 0.0022010112377756743
Trained batch 80 in epoch 1, gen_loss = 1.2803725710621587, disc_loss = 0.002195411664290055
Trained batch 81 in epoch 1, gen_loss = 1.283009219460371, disc_loss = 0.002185391630585555
Trained batch 82 in epoch 1, gen_loss = 1.284807732306331, disc_loss = 0.002176395296932658
Trained batch 83 in epoch 1, gen_loss = 1.2832863827546437, disc_loss = 0.002189513394980514
Trained batch 84 in epoch 1, gen_loss = 1.282231349103591, disc_loss = 0.0021839463336886292
Trained batch 85 in epoch 1, gen_loss = 1.2844948976538901, disc_loss = 0.0021724704805988993
Trained batch 86 in epoch 1, gen_loss = 1.2847869642849625, disc_loss = 0.0021626081701699943
Trained batch 87 in epoch 1, gen_loss = 1.2834955724802883, disc_loss = 0.0022328008113122037
Trained batch 88 in epoch 1, gen_loss = 1.2818643109182293, disc_loss = 0.002280491934644498
Trained batch 89 in epoch 1, gen_loss = 1.283591424094306, disc_loss = 0.0023118806867084155
Trained batch 90 in epoch 1, gen_loss = 1.281860073844155, disc_loss = 0.0023174651528729104
Trained batch 91 in epoch 1, gen_loss = 1.2833642674529033, disc_loss = 0.0023124766448745504
Trained batch 92 in epoch 1, gen_loss = 1.2839173091355192, disc_loss = 0.0023044006584803023
Trained batch 93 in epoch 1, gen_loss = 1.2829805599882247, disc_loss = 0.0023009569509242207
Trained batch 94 in epoch 1, gen_loss = 1.283402008759348, disc_loss = 0.002291270588696199
Trained batch 95 in epoch 1, gen_loss = 1.2822620049118996, disc_loss = 0.0022859014285738035
Trained batch 96 in epoch 1, gen_loss = 1.280762177152732, disc_loss = 0.0022999808419082966
Trained batch 97 in epoch 1, gen_loss = 1.2790306867385397, disc_loss = 0.002307585091924067
Trained batch 98 in epoch 1, gen_loss = 1.2778924968507555, disc_loss = 0.002300987571049858
Trained batch 99 in epoch 1, gen_loss = 1.2767666614055633, disc_loss = 0.002292753565707244
Trained batch 100 in epoch 1, gen_loss = 1.2756767568021719, disc_loss = 0.002280929431867887
Trained batch 101 in epoch 1, gen_loss = 1.274343468394934, disc_loss = 0.0022799328771903747
Trained batch 102 in epoch 1, gen_loss = 1.2735523216932723, disc_loss = 0.002272443698371028
Trained batch 103 in epoch 1, gen_loss = 1.27547963651327, disc_loss = 0.0022628428755874317
Trained batch 104 in epoch 1, gen_loss = 1.2759727080663046, disc_loss = 0.002255998004693538
Trained batch 105 in epoch 1, gen_loss = 1.277386875647419, disc_loss = 0.002249396644985163
Trained batch 106 in epoch 1, gen_loss = 1.2765616746706383, disc_loss = 0.0022421097203384143
Trained batch 107 in epoch 1, gen_loss = 1.2794017880051225, disc_loss = 0.0022322637642328454
Trained batch 108 in epoch 1, gen_loss = 1.2800444353611098, disc_loss = 0.0022223311718852353
Trained batch 109 in epoch 1, gen_loss = 1.2843658989126032, disc_loss = 0.0022187543625477703
Trained batch 110 in epoch 1, gen_loss = 1.2840122371106535, disc_loss = 0.0022146917710726796
Trained batch 111 in epoch 1, gen_loss = 1.284609317779541, disc_loss = 0.0022099103074911647
Trained batch 112 in epoch 1, gen_loss = 1.2839914022293766, disc_loss = 0.0022166040968108693
Trained batch 113 in epoch 1, gen_loss = 1.2853670674457884, disc_loss = 0.0022465993375558276
Trained batch 114 in epoch 1, gen_loss = 1.2847144417140794, disc_loss = 0.0022501450978502954
Trained batch 115 in epoch 1, gen_loss = 1.2851974984695171, disc_loss = 0.0022548519146171047
Trained batch 116 in epoch 1, gen_loss = 1.2845276624728472, disc_loss = 0.002248598695991354
Trained batch 117 in epoch 1, gen_loss = 1.2845187894368575, disc_loss = 0.002239523806226424
Trained batch 118 in epoch 1, gen_loss = 1.283412290220501, disc_loss = 0.002230052655746675
Trained batch 119 in epoch 1, gen_loss = 1.2824425101280212, disc_loss = 0.002222531940302967
Trained batch 120 in epoch 1, gen_loss = 1.282242406498302, disc_loss = 0.002211261209204393
Trained batch 121 in epoch 1, gen_loss = 1.2831912714926923, disc_loss = 0.0022023311624356895
Trained batch 122 in epoch 1, gen_loss = 1.282584336715016, disc_loss = 0.002193103890347378
Trained batch 123 in epoch 1, gen_loss = 1.2825798613409842, disc_loss = 0.0021824781044063367
Trained batch 124 in epoch 1, gen_loss = 1.281612368583679, disc_loss = 0.002183128882665187
Trained batch 125 in epoch 1, gen_loss = 1.2808153846907238, disc_loss = 0.002202921118753563
Trained batch 126 in epoch 1, gen_loss = 1.2795575913481825, disc_loss = 0.002212751514230686
Trained batch 127 in epoch 1, gen_loss = 1.279042256064713, disc_loss = 0.0022087192614890228
Trained batch 128 in epoch 1, gen_loss = 1.2779811482096828, disc_loss = 0.0022006273434800635
Trained batch 129 in epoch 1, gen_loss = 1.2774246720167306, disc_loss = 0.0021990864730189338
Trained batch 130 in epoch 1, gen_loss = 1.2777631119007373, disc_loss = 0.0022051568966863664
Trained batch 131 in epoch 1, gen_loss = 1.2771454019979998, disc_loss = 0.0022189098698700864
Trained batch 132 in epoch 1, gen_loss = 1.2760021767221896, disc_loss = 0.0022272270788172527
Trained batch 133 in epoch 1, gen_loss = 1.2747841939997318, disc_loss = 0.0022267739079135066
Trained batch 134 in epoch 1, gen_loss = 1.2747646570205688, disc_loss = 0.002225238500007739
Trained batch 135 in epoch 1, gen_loss = 1.2745011790710337, disc_loss = 0.0022273283611866646
Trained batch 136 in epoch 1, gen_loss = 1.2745588321755403, disc_loss = 0.0022307357807766076
Trained batch 137 in epoch 1, gen_loss = 1.274407258068306, disc_loss = 0.0022239916712430345
Trained batch 138 in epoch 1, gen_loss = 1.2734310412578445, disc_loss = 0.002216056059198387
Trained batch 139 in epoch 1, gen_loss = 1.2735125865255084, disc_loss = 0.0022123491104658957
Trained batch 140 in epoch 1, gen_loss = 1.2731485316093931, disc_loss = 0.0022178610389662497
Trained batch 141 in epoch 1, gen_loss = 1.273957522822098, disc_loss = 0.0022228817061134155
Trained batch 142 in epoch 1, gen_loss = 1.2745522769181046, disc_loss = 0.0022279097307050092
Trained batch 143 in epoch 1, gen_loss = 1.2742941222257085, disc_loss = 0.0022199476609077668
Trained batch 144 in epoch 1, gen_loss = 1.274052568961834, disc_loss = 0.002216932151450551
Trained batch 145 in epoch 1, gen_loss = 1.2752007613443348, disc_loss = 0.002214416066959679
Trained batch 146 in epoch 1, gen_loss = 1.2750969371017145, disc_loss = 0.0022062010454096306
Trained batch 147 in epoch 1, gen_loss = 1.2762010709659473, disc_loss = 0.0022005108495815533
Trained batch 148 in epoch 1, gen_loss = 1.2761997344509868, disc_loss = 0.0021995062023345007
Trained batch 149 in epoch 1, gen_loss = 1.2760057902336122, disc_loss = 0.0022085608444952715
Trained batch 150 in epoch 1, gen_loss = 1.2749657133557148, disc_loss = 0.0022115552692291702
Trained batch 151 in epoch 1, gen_loss = 1.2763411786995436, disc_loss = 0.00220826097134513
Trained batch 152 in epoch 1, gen_loss = 1.2758040482701818, disc_loss = 0.0022118006398432638
Trained batch 153 in epoch 1, gen_loss = 1.2746599424969067, disc_loss = 0.0022066549217334475
Trained batch 154 in epoch 1, gen_loss = 1.2736174098906978, disc_loss = 0.0022066373291665746
Trained batch 155 in epoch 1, gen_loss = 1.2732225465468872, disc_loss = 0.0022032750312997126
Trained batch 156 in epoch 1, gen_loss = 1.2728845237926314, disc_loss = 0.0021945434584650122
Trained batch 157 in epoch 1, gen_loss = 1.273023338257512, disc_loss = 0.002200480410902867
Trained batch 158 in epoch 1, gen_loss = 1.2732505603406414, disc_loss = 0.002224476137066717
Trained batch 159 in epoch 1, gen_loss = 1.2738346688449382, disc_loss = 0.002240222915497725
Trained batch 160 in epoch 1, gen_loss = 1.275433735817856, disc_loss = 0.0022401812544919734
Trained batch 161 in epoch 1, gen_loss = 1.2755012887495536, disc_loss = 0.0022393943024023124
Trained batch 162 in epoch 1, gen_loss = 1.2750943153182421, disc_loss = 0.0022379845752883588
Trained batch 163 in epoch 1, gen_loss = 1.2747883077074842, disc_loss = 0.002232882942757342
Trained batch 164 in epoch 1, gen_loss = 1.2750978325352524, disc_loss = 0.002225594136821614
Trained batch 165 in epoch 1, gen_loss = 1.2763236574379795, disc_loss = 0.002222414797169145
Trained batch 166 in epoch 1, gen_loss = 1.2771579726727422, disc_loss = 0.0022160842687778265
Trained batch 167 in epoch 1, gen_loss = 1.2772505035003026, disc_loss = 0.002211004782847816
Trained batch 168 in epoch 1, gen_loss = 1.276667822747541, disc_loss = 0.0022082197725822456
Trained batch 169 in epoch 1, gen_loss = 1.2761553596047794, disc_loss = 0.0022047373483313577
Trained batch 170 in epoch 1, gen_loss = 1.275244955430951, disc_loss = 0.0021973960925362004
Trained batch 171 in epoch 1, gen_loss = 1.2742973524470662, disc_loss = 0.0021888364741286304
Trained batch 172 in epoch 1, gen_loss = 1.2741340240302113, disc_loss = 0.0021802678605342403
Trained batch 173 in epoch 1, gen_loss = 1.2746369715394645, disc_loss = 0.0021728836669019243
Trained batch 174 in epoch 1, gen_loss = 1.2755307960510254, disc_loss = 0.002173360994617854
Trained batch 175 in epoch 1, gen_loss = 1.2749390629204838, disc_loss = 0.002179319209641438
Trained batch 176 in epoch 1, gen_loss = 1.2761295346890467, disc_loss = 0.002174747838128337
Trained batch 177 in epoch 1, gen_loss = 1.2755083622557393, disc_loss = 0.0021759954168660083
Trained batch 178 in epoch 1, gen_loss = 1.275200966350193, disc_loss = 0.0021876720282348007
Trained batch 179 in epoch 1, gen_loss = 1.2748453577359518, disc_loss = 0.002180005443127205
Trained batch 180 in epoch 1, gen_loss = 1.2740150209289889, disc_loss = 0.002178386595995469
Trained batch 181 in epoch 1, gen_loss = 1.2741094211955646, disc_loss = 0.0021728799437878876
Trained batch 182 in epoch 1, gen_loss = 1.2737440229113637, disc_loss = 0.002168256384218773
Trained batch 183 in epoch 1, gen_loss = 1.2741117380235507, disc_loss = 0.0021637892382189066
Trained batch 184 in epoch 1, gen_loss = 1.2735449404329866, disc_loss = 0.0021672519483930757
Trained batch 185 in epoch 1, gen_loss = 1.2729517939270183, disc_loss = 0.0021724302881217052
Trained batch 186 in epoch 1, gen_loss = 1.272144116819861, disc_loss = 0.002170429725005705
Trained batch 187 in epoch 1, gen_loss = 1.2724661567109696, disc_loss = 0.002169867119865809
Trained batch 188 in epoch 1, gen_loss = 1.2720177116848173, disc_loss = 0.002167266795396923
Trained batch 189 in epoch 1, gen_loss = 1.273540899628087, disc_loss = 0.002165430625532999
Trained batch 190 in epoch 1, gen_loss = 1.2726582569601648, disc_loss = 0.0021792564654469254
Trained batch 191 in epoch 1, gen_loss = 1.272446586440007, disc_loss = 0.00218831008108585
Trained batch 192 in epoch 1, gen_loss = 1.2719196173811207, disc_loss = 0.002186832689545045
Trained batch 193 in epoch 1, gen_loss = 1.2723938208265402, disc_loss = 0.002180833656931315
Trained batch 194 in epoch 1, gen_loss = 1.2727463960647583, disc_loss = 0.0021776984511420894
Trained batch 195 in epoch 1, gen_loss = 1.2725258615552162, disc_loss = 0.0021754534278369073
Trained batch 196 in epoch 1, gen_loss = 1.2717549558823484, disc_loss = 0.002168921306717498
Trained batch 197 in epoch 1, gen_loss = 1.2711204832250422, disc_loss = 0.0021700029719428095
Trained batch 198 in epoch 1, gen_loss = 1.2709109303939283, disc_loss = 0.0021713636227621317
Trained batch 199 in epoch 1, gen_loss = 1.2709902787208558, disc_loss = 0.002167618220264558
Trained batch 200 in epoch 1, gen_loss = 1.2713971873420982, disc_loss = 0.002165197424036891
Trained batch 201 in epoch 1, gen_loss = 1.271341839639267, disc_loss = 0.0021600946913690002
Trained batch 202 in epoch 1, gen_loss = 1.270864384514945, disc_loss = 0.0021554358636735587
Trained batch 203 in epoch 1, gen_loss = 1.2707977236485948, disc_loss = 0.00215219817661872
Trained batch 204 in epoch 1, gen_loss = 1.2709528370601375, disc_loss = 0.0021466755123649974
Trained batch 205 in epoch 1, gen_loss = 1.2710638295099572, disc_loss = 0.0021409627125887833
Trained batch 206 in epoch 1, gen_loss = 1.2718587031111048, disc_loss = 0.002137349838062509
Trained batch 207 in epoch 1, gen_loss = 1.2712672742513509, disc_loss = 0.002132431180843224
Trained batch 208 in epoch 1, gen_loss = 1.2720603834499011, disc_loss = 0.0021297485872871424
Trained batch 209 in epoch 1, gen_loss = 1.2716316274234227, disc_loss = 0.0021300741482437368
Trained batch 210 in epoch 1, gen_loss = 1.2706862925353208, disc_loss = 0.002125309722859995
Trained batch 211 in epoch 1, gen_loss = 1.2716374217339281, disc_loss = 0.0021260331949342114
Trained batch 212 in epoch 1, gen_loss = 1.2728250843818198, disc_loss = 0.002122711485356722
Trained batch 213 in epoch 1, gen_loss = 1.2729931200776146, disc_loss = 0.0021240486574106822
Trained batch 214 in epoch 1, gen_loss = 1.2727479602015295, disc_loss = 0.0021246798542263203
Trained batch 215 in epoch 1, gen_loss = 1.27284341553847, disc_loss = 0.00212226355021509
Trained batch 216 in epoch 1, gen_loss = 1.2722316332127093, disc_loss = 0.002120366234177818
Trained batch 217 in epoch 1, gen_loss = 1.2714630294283595, disc_loss = 0.0021152382966455655
Trained batch 218 in epoch 1, gen_loss = 1.2715396500069256, disc_loss = 0.00210930538559375
Trained batch 219 in epoch 1, gen_loss = 1.270652003179897, disc_loss = 0.00210361229758498
Trained batch 220 in epoch 1, gen_loss = 1.2708946353170127, disc_loss = 0.0021020181777853335
Trained batch 221 in epoch 1, gen_loss = 1.2712251205702085, disc_loss = 0.0021041259901107266
Trained batch 222 in epoch 1, gen_loss = 1.2717565068214998, disc_loss = 0.00210458251220621
Trained batch 223 in epoch 1, gen_loss = 1.2715157462017876, disc_loss = 0.0021028222854511114
Trained batch 224 in epoch 1, gen_loss = 1.2707503864500258, disc_loss = 0.0021042332692175277
Trained batch 225 in epoch 1, gen_loss = 1.2700744387322822, disc_loss = 0.002115734224156188
Trained batch 226 in epoch 1, gen_loss = 1.270840360729705, disc_loss = 0.002135020177883182
Trained batch 227 in epoch 1, gen_loss = 1.2717552472624862, disc_loss = 0.0021391506345121583
Trained batch 228 in epoch 1, gen_loss = 1.2719118990752374, disc_loss = 0.0021371684918143506
Trained batch 229 in epoch 1, gen_loss = 1.2718862476556196, disc_loss = 0.0021379758120494206
Trained batch 230 in epoch 1, gen_loss = 1.2718343755383512, disc_loss = 0.002133517053625365
Trained batch 231 in epoch 1, gen_loss = 1.2712088026877106, disc_loss = 0.002129742734441293
Trained batch 232 in epoch 1, gen_loss = 1.271345964828786, disc_loss = 0.0021241684396783203
Trained batch 233 in epoch 1, gen_loss = 1.2710046253652654, disc_loss = 0.0021219506800576695
Trained batch 234 in epoch 1, gen_loss = 1.2710163121527813, disc_loss = 0.0021194170845890456
Trained batch 235 in epoch 1, gen_loss = 1.2727550919783317, disc_loss = 0.002116169726971332
Trained batch 236 in epoch 1, gen_loss = 1.274028362604133, disc_loss = 0.002122715401182242
Trained batch 237 in epoch 1, gen_loss = 1.2742044209432202, disc_loss = 0.0021327927837269615
Trained batch 238 in epoch 1, gen_loss = 1.2739257782572981, disc_loss = 0.0021315433957349024
Trained batch 239 in epoch 1, gen_loss = 1.2738220105568567, disc_loss = 0.0021278400025039447
Trained batch 240 in epoch 1, gen_loss = 1.2735477784857216, disc_loss = 0.0021327500788521996
Trained batch 241 in epoch 1, gen_loss = 1.2741795512270335, disc_loss = 0.002135656405796397
Trained batch 242 in epoch 1, gen_loss = 1.2742352132444028, disc_loss = 0.0021316542952712395
Trained batch 243 in epoch 1, gen_loss = 1.273568728419601, disc_loss = 0.0021319797452917077
Trained batch 244 in epoch 1, gen_loss = 1.2742285538692864, disc_loss = 0.002131947375862498
Trained batch 245 in epoch 1, gen_loss = 1.274383138350355, disc_loss = 0.0021304436663555633
Trained batch 246 in epoch 1, gen_loss = 1.2737617140356827, disc_loss = 0.0021341119679388577
Trained batch 247 in epoch 1, gen_loss = 1.2728657924359845, disc_loss = 0.002129975825335996
Trained batch 248 in epoch 1, gen_loss = 1.2724657958769894, disc_loss = 0.0021319334415333666
Trained batch 249 in epoch 1, gen_loss = 1.2724381990432738, disc_loss = 0.002144572730874643
Trained batch 250 in epoch 1, gen_loss = 1.2722442544314017, disc_loss = 0.0021444644323973154
Trained batch 251 in epoch 1, gen_loss = 1.2713917536394936, disc_loss = 0.002142599811786712
Trained batch 252 in epoch 1, gen_loss = 1.2714800900621377, disc_loss = 0.002142322682471865
Trained batch 253 in epoch 1, gen_loss = 1.2714163599990485, disc_loss = 0.0021434207751661336
Trained batch 254 in epoch 1, gen_loss = 1.2708444651435404, disc_loss = 0.0021401331575094337
Trained batch 255 in epoch 1, gen_loss = 1.2717688446864486, disc_loss = 0.002137646409437366
Trained batch 256 in epoch 1, gen_loss = 1.272317468888101, disc_loss = 0.0021323504715483883
Trained batch 257 in epoch 1, gen_loss = 1.2719151081964952, disc_loss = 0.0021295244611489275
Trained batch 258 in epoch 1, gen_loss = 1.2716882339315525, disc_loss = 0.0021258525502720568
Trained batch 259 in epoch 1, gen_loss = 1.2713869145283332, disc_loss = 0.0021221403126569036
Trained batch 260 in epoch 1, gen_loss = 1.2707210998425538, disc_loss = 0.002121390564317219
Trained batch 261 in epoch 1, gen_loss = 1.2707406064026228, disc_loss = 0.0021198014275505
Trained batch 262 in epoch 1, gen_loss = 1.2706421092435887, disc_loss = 0.002117916112128263
Trained batch 263 in epoch 1, gen_loss = 1.2706426242084214, disc_loss = 0.0021189568841223127
Trained batch 264 in epoch 1, gen_loss = 1.270554311770313, disc_loss = 0.002117256973079353
Trained batch 265 in epoch 1, gen_loss = 1.2699506013913262, disc_loss = 0.002219366776245765
Trained batch 266 in epoch 1, gen_loss = 1.2689531202173412, disc_loss = 0.002682289532438088
Trained batch 267 in epoch 1, gen_loss = 1.2700641657879104, disc_loss = 0.0029387544239384694
Trained batch 268 in epoch 1, gen_loss = 1.2702862201570135, disc_loss = 0.003125858667988649
Trained batch 269 in epoch 1, gen_loss = 1.26996436825505, disc_loss = 0.0033238061996935693
Trained batch 270 in epoch 1, gen_loss = 1.2695114449821274, disc_loss = 0.0034468990778103747
Trained batch 271 in epoch 1, gen_loss = 1.2693084710661102, disc_loss = 0.0035147930423537377
Trained batch 272 in epoch 1, gen_loss = 1.2690238109875074, disc_loss = 0.003582588262214656
Trained batch 273 in epoch 1, gen_loss = 1.2691598856536142, disc_loss = 0.0035996316119783767
Trained batch 274 in epoch 1, gen_loss = 1.269741097797047, disc_loss = 0.0036104333976453
Trained batch 275 in epoch 1, gen_loss = 1.2707358266132465, disc_loss = 0.003615123381757218
Trained batch 276 in epoch 1, gen_loss = 1.2705386506951672, disc_loss = 0.0036113483760680746
Trained batch 277 in epoch 1, gen_loss = 1.2709658767679612, disc_loss = 0.003614311732968195
Trained batch 278 in epoch 1, gen_loss = 1.2703641729970132, disc_loss = 0.0036187068772866094
Trained batch 279 in epoch 1, gen_loss = 1.2700810900756292, disc_loss = 0.0036130520881020598
Trained batch 280 in epoch 1, gen_loss = 1.2709912188960988, disc_loss = 0.0036098680929595676
Trained batch 281 in epoch 1, gen_loss = 1.2709493662448639, disc_loss = 0.0036048768624887925
Trained batch 282 in epoch 1, gen_loss = 1.2708210869307233, disc_loss = 0.003597717409683622
Trained batch 283 in epoch 1, gen_loss = 1.2715655943037758, disc_loss = 0.0035908943698839874
Trained batch 284 in epoch 1, gen_loss = 1.271501091906899, disc_loss = 0.0035858378194174485
Trained batch 285 in epoch 1, gen_loss = 1.2720916800565654, disc_loss = 0.0035830299704583115
Trained batch 286 in epoch 1, gen_loss = 1.272076384531081, disc_loss = 0.003596096690208732
Trained batch 287 in epoch 1, gen_loss = 1.271935777945651, disc_loss = 0.0035997467926386483
Trained batch 288 in epoch 1, gen_loss = 1.2722822716491857, disc_loss = 0.0035938815480407497
Trained batch 289 in epoch 1, gen_loss = 1.2717159526101474, disc_loss = 0.0035883480052720626
Trained batch 290 in epoch 1, gen_loss = 1.2714672768648547, disc_loss = 0.003584035593437037
Trained batch 291 in epoch 1, gen_loss = 1.2714507975806928, disc_loss = 0.0035764814018788556
Trained batch 292 in epoch 1, gen_loss = 1.2718085799200949, disc_loss = 0.0035687988928325295
Trained batch 293 in epoch 1, gen_loss = 1.2724340225563568, disc_loss = 0.0035615746723012807
Trained batch 294 in epoch 1, gen_loss = 1.2721593747704716, disc_loss = 0.0035548298031691525
Trained batch 295 in epoch 1, gen_loss = 1.2717060990430213, disc_loss = 0.003547516434746039
Trained batch 296 in epoch 1, gen_loss = 1.2717173761791654, disc_loss = 0.0035421981806286707
Trained batch 297 in epoch 1, gen_loss = 1.2714414816574762, disc_loss = 0.003538279062458908
Trained batch 298 in epoch 1, gen_loss = 1.2708668537363161, disc_loss = 0.003533141974462539
Trained batch 299 in epoch 1, gen_loss = 1.2712613761425018, disc_loss = 0.0035244547773618253
Trained batch 300 in epoch 1, gen_loss = 1.271353121611763, disc_loss = 0.003515855107917466
Trained batch 301 in epoch 1, gen_loss = 1.2713694805341051, disc_loss = 0.003507962795390766
Trained batch 302 in epoch 1, gen_loss = 1.2709118234048975, disc_loss = 0.0035011708861671805
Trained batch 303 in epoch 1, gen_loss = 1.2703331661851782, disc_loss = 0.0034952815189363286
Trained batch 304 in epoch 1, gen_loss = 1.2706018596399027, disc_loss = 0.003488940026870639
Trained batch 305 in epoch 1, gen_loss = 1.270343573654399, disc_loss = 0.0034860907334779553
Trained batch 306 in epoch 1, gen_loss = 1.2703969649460882, disc_loss = 0.0034824774266108386
Trained batch 307 in epoch 1, gen_loss = 1.2702286382774255, disc_loss = 0.00347593855475644
Trained batch 308 in epoch 1, gen_loss = 1.2704143886813068, disc_loss = 0.0034729204762992253
Trained batch 309 in epoch 1, gen_loss = 1.2703860182915965, disc_loss = 0.0034679130853844746
Trained batch 310 in epoch 1, gen_loss = 1.2706750443510688, disc_loss = 0.0034597053458701546
Trained batch 311 in epoch 1, gen_loss = 1.2708954757604844, disc_loss = 0.0034530960731969504
Trained batch 312 in epoch 1, gen_loss = 1.2704174739484209, disc_loss = 0.003446493169684082
Trained batch 313 in epoch 1, gen_loss = 1.2703721978861815, disc_loss = 0.003438778153203938
Trained batch 314 in epoch 1, gen_loss = 1.2708354791005452, disc_loss = 0.0034336742917297496
Trained batch 315 in epoch 1, gen_loss = 1.2709873680826984, disc_loss = 0.0034274688490468987
Trained batch 316 in epoch 1, gen_loss = 1.2708274242629765, disc_loss = 0.0034193540359582835
Trained batch 317 in epoch 1, gen_loss = 1.2702278536070817, disc_loss = 0.0034127881929480455
Trained batch 318 in epoch 1, gen_loss = 1.2700168107370597, disc_loss = 0.0034055359164168212
Trained batch 319 in epoch 1, gen_loss = 1.2700286321341991, disc_loss = 0.0033971043239944265
Trained batch 320 in epoch 1, gen_loss = 1.2698862630630208, disc_loss = 0.0033892288405485914
Trained batch 321 in epoch 1, gen_loss = 1.269625879592777, disc_loss = 0.0033822823267051173
Trained batch 322 in epoch 1, gen_loss = 1.2694265366338724, disc_loss = 0.003374861682161124
Trained batch 323 in epoch 1, gen_loss = 1.2697481170848564, disc_loss = 0.0033698761136843076
Trained batch 324 in epoch 1, gen_loss = 1.2696290445327758, disc_loss = 0.0033704714038266014
Trained batch 325 in epoch 1, gen_loss = 1.2696985543871218, disc_loss = 0.0033653028910348272
Trained batch 326 in epoch 1, gen_loss = 1.2696162958028485, disc_loss = 0.003357743475029376
Trained batch 327 in epoch 1, gen_loss = 1.2699303765122483, disc_loss = 0.0033499737520043442
Trained batch 328 in epoch 1, gen_loss = 1.2693071952344437, disc_loss = 0.003376387940057324
Trained batch 329 in epoch 1, gen_loss = 1.2689277988491636, disc_loss = 0.0033900588666173543
Trained batch 330 in epoch 1, gen_loss = 1.268715679105315, disc_loss = 0.0033945520591339676
Trained batch 331 in epoch 1, gen_loss = 1.2680239045476338, disc_loss = 0.003398394423918462
Trained batch 332 in epoch 1, gen_loss = 1.2676549695275567, disc_loss = 0.003407419761279234
Trained batch 333 in epoch 1, gen_loss = 1.2675096314110441, disc_loss = 0.003406134845332025
Trained batch 334 in epoch 1, gen_loss = 1.26697432354315, disc_loss = 0.003399554380118402
Trained batch 335 in epoch 1, gen_loss = 1.2669159901284037, disc_loss = 0.00339303573959374
Trained batch 336 in epoch 1, gen_loss = 1.2669271959395365, disc_loss = 0.0033867687065684917
Trained batch 337 in epoch 1, gen_loss = 1.2671146593855682, disc_loss = 0.003382272816183233
Trained batch 338 in epoch 1, gen_loss = 1.2669830459409055, disc_loss = 0.0033787970234032795
Trained batch 339 in epoch 1, gen_loss = 1.2668594160500695, disc_loss = 0.003378865318989162
Trained batch 340 in epoch 1, gen_loss = 1.266947892753959, disc_loss = 0.0033804185342322214
Trained batch 341 in epoch 1, gen_loss = 1.2687709732362402, disc_loss = 0.003382107932243104
Trained batch 342 in epoch 1, gen_loss = 1.2692284372040552, disc_loss = 0.0033789385695949894
Trained batch 343 in epoch 1, gen_loss = 1.268985229522683, disc_loss = 0.0033745773885870177
Trained batch 344 in epoch 1, gen_loss = 1.2687328438827956, disc_loss = 0.0033723896534681537
Trained batch 345 in epoch 1, gen_loss = 1.2683698476394476, disc_loss = 0.0033663166908956418
Trained batch 346 in epoch 1, gen_loss = 1.2680771790595151, disc_loss = 0.0033623117071868965
Trained batch 347 in epoch 1, gen_loss = 1.2687617266315154, disc_loss = 0.003357055723792927
Trained batch 348 in epoch 1, gen_loss = 1.2692583310911512, disc_loss = 0.0033511374840235345
Trained batch 349 in epoch 1, gen_loss = 1.2691825584002903, disc_loss = 0.003345030458045325
Trained batch 350 in epoch 1, gen_loss = 1.2689582367568275, disc_loss = 0.00334073345082682
Trained batch 351 in epoch 1, gen_loss = 1.2684450342573903, disc_loss = 0.00333775318755546
Trained batch 352 in epoch 1, gen_loss = 1.2684865872515498, disc_loss = 0.00333215463009502
Trained batch 353 in epoch 1, gen_loss = 1.2685451854420247, disc_loss = 0.003324666933457783
Trained batch 354 in epoch 1, gen_loss = 1.2682730130746331, disc_loss = 0.0033180976117646297
Trained batch 355 in epoch 1, gen_loss = 1.2678704040773798, disc_loss = 0.0033114686789150675
Trained batch 356 in epoch 1, gen_loss = 1.2674755642727977, disc_loss = 0.0033044309561735628
Trained batch 357 in epoch 1, gen_loss = 1.2674280062068108, disc_loss = 0.0032999221088856395
Trained batch 358 in epoch 1, gen_loss = 1.26708665465246, disc_loss = 0.003299815352120201
Trained batch 359 in epoch 1, gen_loss = 1.2665605717235142, disc_loss = 0.0032971311530369954
Trained batch 360 in epoch 1, gen_loss = 1.2660946165755844, disc_loss = 0.0032919548596049095
Trained batch 361 in epoch 1, gen_loss = 1.2666304947921585, disc_loss = 0.003292228248149146
Trained batch 362 in epoch 1, gen_loss = 1.2668983033209136, disc_loss = 0.003289696252321152
Trained batch 363 in epoch 1, gen_loss = 1.2675600625001466, disc_loss = 0.0032870745154258865
Trained batch 364 in epoch 1, gen_loss = 1.2676612177940265, disc_loss = 0.003294317801770027
Trained batch 365 in epoch 1, gen_loss = 1.2672697048369652, disc_loss = 0.003295431137333059
Trained batch 366 in epoch 1, gen_loss = 1.2676922904698011, disc_loss = 0.0032909840035470514
Trained batch 367 in epoch 1, gen_loss = 1.2675719909046008, disc_loss = 0.0032871761743634756
Trained batch 368 in epoch 1, gen_loss = 1.267525168615305, disc_loss = 0.003283482473526594
Trained batch 369 in epoch 1, gen_loss = 1.2670529626511238, disc_loss = 0.003280980933640102
Trained batch 370 in epoch 1, gen_loss = 1.2667180524682098, disc_loss = 0.0032789077883714312
Trained batch 371 in epoch 1, gen_loss = 1.2665743196523318, disc_loss = 0.003274485095991172
Trained batch 372 in epoch 1, gen_loss = 1.2665802438521194, disc_loss = 0.003268730002249424
Trained batch 373 in epoch 1, gen_loss = 1.266548755015919, disc_loss = 0.0032636756334207297
Trained batch 374 in epoch 1, gen_loss = 1.2661550378799438, disc_loss = 0.003257762382583072
Trained batch 375 in epoch 1, gen_loss = 1.265703320186189, disc_loss = 0.0032540764286556837
Trained batch 376 in epoch 1, gen_loss = 1.2651997033101494, disc_loss = 0.0032489623876587447
Trained batch 377 in epoch 1, gen_loss = 1.2644742973267087, disc_loss = 0.003244406459440364
Trained batch 378 in epoch 1, gen_loss = 1.2639477564351225, disc_loss = 0.003243137127811969
Trained batch 379 in epoch 1, gen_loss = 1.2638249168270512, disc_loss = 0.0032384466938980808
Trained batch 380 in epoch 1, gen_loss = 1.2632344907975885, disc_loss = 0.0032321512052884663
Trained batch 381 in epoch 1, gen_loss = 1.2629578425622112, disc_loss = 0.003228973609630594
Trained batch 382 in epoch 1, gen_loss = 1.2628554622436006, disc_loss = 0.0032251703046206337
Trained batch 383 in epoch 1, gen_loss = 1.2623446605478723, disc_loss = 0.003219537263400222
Trained batch 384 in epoch 1, gen_loss = 1.2624756286670635, disc_loss = 0.0032131197401201474
Trained batch 385 in epoch 1, gen_loss = 1.2630689579588144, disc_loss = 0.003208965876645172
Trained batch 386 in epoch 1, gen_loss = 1.262940552191525, disc_loss = 0.003205359992673452
Trained batch 387 in epoch 1, gen_loss = 1.2632570312809699, disc_loss = 0.0031997108681681903
Trained batch 388 in epoch 1, gen_loss = 1.2629620894061875, disc_loss = 0.0031950039485921953
Trained batch 389 in epoch 1, gen_loss = 1.2636460038331838, disc_loss = 0.003190776663802516
Trained batch 390 in epoch 1, gen_loss = 1.2635236634012987, disc_loss = 0.0031861629820300165
Trained batch 391 in epoch 1, gen_loss = 1.2633527413922914, disc_loss = 0.0031801560078153616
Trained batch 392 in epoch 1, gen_loss = 1.264340333356202, disc_loss = 0.0031759201856472225
Trained batch 393 in epoch 1, gen_loss = 1.2642582642850537, disc_loss = 0.003172606083228806
Trained batch 394 in epoch 1, gen_loss = 1.263827414754071, disc_loss = 0.0031709985489237914
Trained batch 395 in epoch 1, gen_loss = 1.2635720923091427, disc_loss = 0.0031690626120608714
Trained batch 396 in epoch 1, gen_loss = 1.2641216444428682, disc_loss = 0.0031647553288563146
Trained batch 397 in epoch 1, gen_loss = 1.2643832869865188, disc_loss = 0.0031621400296135836
Trained batch 398 in epoch 1, gen_loss = 1.2643369131518485, disc_loss = 0.0031601617732470422
Trained batch 399 in epoch 1, gen_loss = 1.2643218922615052, disc_loss = 0.0031602945597842334
Trained batch 400 in epoch 1, gen_loss = 1.2649589854285603, disc_loss = 0.0031541445123570554
Trained batch 401 in epoch 1, gen_loss = 1.264997174194203, disc_loss = 0.00315143920936441
Trained batch 402 in epoch 1, gen_loss = 1.2651109242853396, disc_loss = 0.0031469948592690506
Trained batch 403 in epoch 1, gen_loss = 1.2655700607465046, disc_loss = 0.0031420586162159165
Trained batch 404 in epoch 1, gen_loss = 1.2653807996231832, disc_loss = 0.0031398028425619375
Trained batch 405 in epoch 1, gen_loss = 1.2651378259870218, disc_loss = 0.003134887510958802
Trained batch 406 in epoch 1, gen_loss = 1.2649854673507466, disc_loss = 0.003128973637159493
Trained batch 407 in epoch 1, gen_loss = 1.2650799239967383, disc_loss = 0.0031270808487498273
Trained batch 408 in epoch 1, gen_loss = 1.2652414151100775, disc_loss = 0.003127095982185303
Trained batch 409 in epoch 1, gen_loss = 1.2648675950562083, disc_loss = 0.003122299041161768
Trained batch 410 in epoch 1, gen_loss = 1.264789417132264, disc_loss = 0.0031183312595776595
Trained batch 411 in epoch 1, gen_loss = 1.2647931043384144, disc_loss = 0.003120098983415728
Trained batch 412 in epoch 1, gen_loss = 1.264599037516781, disc_loss = 0.003119987007608236
Trained batch 413 in epoch 1, gen_loss = 1.2642000475943376, disc_loss = 0.0031196069907889687
Trained batch 414 in epoch 1, gen_loss = 1.263596237136657, disc_loss = 0.003115556178283485
Trained batch 415 in epoch 1, gen_loss = 1.263289144405952, disc_loss = 0.0031130379951579156
Trained batch 416 in epoch 1, gen_loss = 1.2627737579299962, disc_loss = 0.0031107259793955234
Trained batch 417 in epoch 1, gen_loss = 1.262359480253247, disc_loss = 0.0031054501433446825
Trained batch 418 in epoch 1, gen_loss = 1.262588073359469, disc_loss = 0.0031003245503446065
Trained batch 419 in epoch 1, gen_loss = 1.2625877457005636, disc_loss = 0.0030955802683906982
Trained batch 420 in epoch 1, gen_loss = 1.2624972888806087, disc_loss = 0.0030901321018338116
Trained batch 421 in epoch 1, gen_loss = 1.2627239283792215, disc_loss = 0.0030847344056745083
Trained batch 422 in epoch 1, gen_loss = 1.2627007076362629, disc_loss = 0.003080027170361506
Trained batch 423 in epoch 1, gen_loss = 1.2624796786398258, disc_loss = 0.0030762331489141907
Trained batch 424 in epoch 1, gen_loss = 1.2621477132685044, disc_loss = 0.003073298668844954
Trained batch 425 in epoch 1, gen_loss = 1.2625015621453943, disc_loss = 0.0030693658885814932
Trained batch 426 in epoch 1, gen_loss = 1.2622149582489872, disc_loss = 0.0030651282023178277
Trained batch 427 in epoch 1, gen_loss = 1.262470778739341, disc_loss = 0.0030608681493240766
Trained batch 428 in epoch 1, gen_loss = 1.262419374672683, disc_loss = 0.0030559912976040344
Trained batch 429 in epoch 1, gen_loss = 1.2627561760503192, disc_loss = 0.00305047148234904
Trained batch 430 in epoch 1, gen_loss = 1.2625995727813437, disc_loss = 0.003045543118703056
Trained batch 431 in epoch 1, gen_loss = 1.262459779503169, disc_loss = 0.0030408890782348827
Trained batch 432 in epoch 1, gen_loss = 1.2631593268132375, disc_loss = 0.00303672459129756
Trained batch 433 in epoch 1, gen_loss = 1.2630970615395753, disc_loss = 0.003033389163140233
Trained batch 434 in epoch 1, gen_loss = 1.263000056935453, disc_loss = 0.0030296503414999395
Trained batch 435 in epoch 1, gen_loss = 1.262723534205638, disc_loss = 0.0030250570699711407
Trained batch 436 in epoch 1, gen_loss = 1.2631728662778912, disc_loss = 0.0030212095994299843
Trained batch 437 in epoch 1, gen_loss = 1.26367819880786, disc_loss = 0.0030155923733430315
Trained batch 438 in epoch 1, gen_loss = 1.2639518085536219, disc_loss = 0.0030108619080103324
Trained batch 439 in epoch 1, gen_loss = 1.2640372425317765, disc_loss = 0.0030097037182051944
Trained batch 440 in epoch 1, gen_loss = 1.2639642180769353, disc_loss = 0.00300584048496838
Trained batch 441 in epoch 1, gen_loss = 1.2638668951945067, disc_loss = 0.003000981982205299
Trained batch 442 in epoch 1, gen_loss = 1.2642299364705656, disc_loss = 0.002996905602495823
Trained batch 443 in epoch 1, gen_loss = 1.264123057728415, disc_loss = 0.002991833029653634
Trained batch 444 in epoch 1, gen_loss = 1.2638593954986401, disc_loss = 0.0029870144688011555
Trained batch 445 in epoch 1, gen_loss = 1.2634959915828277, disc_loss = 0.002982569323077948
Trained batch 446 in epoch 1, gen_loss = 1.263067707652747, disc_loss = 0.002978896674016695
Trained batch 447 in epoch 1, gen_loss = 1.2630480615688222, disc_loss = 0.002975511757800372
Trained batch 448 in epoch 1, gen_loss = 1.2626808202080844, disc_loss = 0.0029746193834424917
Trained batch 449 in epoch 1, gen_loss = 1.2624874499109056, disc_loss = 0.002971049637481984
Trained batch 450 in epoch 1, gen_loss = 1.2621389442431161, disc_loss = 0.002966621854397243
Trained batch 451 in epoch 1, gen_loss = 1.2618127763271332, disc_loss = 0.002964987616189673
Trained batch 452 in epoch 1, gen_loss = 1.2617029030591447, disc_loss = 0.0029623606338609774
Trained batch 453 in epoch 1, gen_loss = 1.2613723128377603, disc_loss = 0.003191461354173055
Trained batch 454 in epoch 1, gen_loss = 1.2601876801186866, disc_loss = 0.004368007545753454
Trained batch 455 in epoch 1, gen_loss = 1.2604085274955683, disc_loss = 0.004586998833187145
Trained batch 456 in epoch 1, gen_loss = 1.2606197819928893, disc_loss = 0.00488377321973602
Trained batch 457 in epoch 1, gen_loss = 1.2606636134818132, disc_loss = 0.004967866467864061
Trained batch 458 in epoch 1, gen_loss = 1.2605375625469066, disc_loss = 0.005022040779691206
Trained batch 459 in epoch 1, gen_loss = 1.2604968153912088, disc_loss = 0.005035220730781514
Trained batch 460 in epoch 1, gen_loss = 1.260547660436651, disc_loss = 0.005034045740904452
Trained batch 461 in epoch 1, gen_loss = 1.2610026187710948, disc_loss = 0.005039580305811477
Trained batch 462 in epoch 1, gen_loss = 1.261004532387653, disc_loss = 0.005042522918753785
Trained batch 463 in epoch 1, gen_loss = 1.260935401094371, disc_loss = 0.005037223879455645
Trained batch 464 in epoch 1, gen_loss = 1.2607361875554566, disc_loss = 0.0050316389638840435
Trained batch 465 in epoch 1, gen_loss = 1.2608521700928652, disc_loss = 0.005024969760031747
Trained batch 466 in epoch 1, gen_loss = 1.260878848314796, disc_loss = 0.005018834741481996
Trained batch 467 in epoch 1, gen_loss = 1.2605149261971824, disc_loss = 0.005012822745275349
Trained batch 468 in epoch 1, gen_loss = 1.260577136011266, disc_loss = 0.005008540744620211
Trained batch 469 in epoch 1, gen_loss = 1.2602426932213153, disc_loss = 0.005003139224928863
Trained batch 470 in epoch 1, gen_loss = 1.2599538792470457, disc_loss = 0.005000035236851607
Trained batch 471 in epoch 1, gen_loss = 1.2598430163274377, disc_loss = 0.004993611093195179
Trained batch 472 in epoch 1, gen_loss = 1.2594681920259245, disc_loss = 0.004995416743404195
Trained batch 473 in epoch 1, gen_loss = 1.2589885371143807, disc_loss = 0.00501831243674758
Trained batch 474 in epoch 1, gen_loss = 1.2593365207471345, disc_loss = 0.005027924238728654
Trained batch 475 in epoch 1, gen_loss = 1.2589440801564384, disc_loss = 0.005030576254024969
Trained batch 476 in epoch 1, gen_loss = 1.2586792549997006, disc_loss = 0.005038333524568143
Trained batch 477 in epoch 1, gen_loss = 1.2583797481768302, disc_loss = 0.005039195146165188
Trained batch 478 in epoch 1, gen_loss = 1.258102802742498, disc_loss = 0.005034243441425023
Trained batch 479 in epoch 1, gen_loss = 1.2581117649873097, disc_loss = 0.005030206996768053
Trained batch 480 in epoch 1, gen_loss = 1.2580410023984692, disc_loss = 0.005033658633832461
Trained batch 481 in epoch 1, gen_loss = 1.2582489771467027, disc_loss = 0.005035200334396561
Trained batch 482 in epoch 1, gen_loss = 1.2579991489216902, disc_loss = 0.005032258350127348
Trained batch 483 in epoch 1, gen_loss = 1.2578448924151333, disc_loss = 0.005028290380526542
Trained batch 484 in epoch 1, gen_loss = 1.2574986226779898, disc_loss = 0.0050202159346657395
Trained batch 485 in epoch 1, gen_loss = 1.2575183579460583, disc_loss = 0.005014250039744839
Trained batch 486 in epoch 1, gen_loss = 1.2572350494670672, disc_loss = 0.005008216734207761
Trained batch 487 in epoch 1, gen_loss = 1.257664107885517, disc_loss = 0.005001470037343813
Trained batch 488 in epoch 1, gen_loss = 1.257728184659057, disc_loss = 0.004993743014284781
Trained batch 489 in epoch 1, gen_loss = 1.2575354157661904, disc_loss = 0.0049868013368852965
Trained batch 490 in epoch 1, gen_loss = 1.2583859078510231, disc_loss = 0.004979879288178301
Trained batch 491 in epoch 1, gen_loss = 1.2586261852969969, disc_loss = 0.004973991016968063
Trained batch 492 in epoch 1, gen_loss = 1.2585019760634788, disc_loss = 0.004967577634667354
Trained batch 493 in epoch 1, gen_loss = 1.2590290882326813, disc_loss = 0.0049594821098971325
Trained batch 494 in epoch 1, gen_loss = 1.2589332368638781, disc_loss = 0.004952315505090725
Trained batch 495 in epoch 1, gen_loss = 1.2588361290193373, disc_loss = 0.004945069040859967
Trained batch 496 in epoch 1, gen_loss = 1.2587953506101306, disc_loss = 0.004940185833734533
Trained batch 497 in epoch 1, gen_loss = 1.2594662033410435, disc_loss = 0.004938379811972986
Trained batch 498 in epoch 1, gen_loss = 1.2590280030676742, disc_loss = 0.004931178274410469
Trained batch 499 in epoch 1, gen_loss = 1.2591961393356323, disc_loss = 0.004925882600364275
Trained batch 500 in epoch 1, gen_loss = 1.2591750507583162, disc_loss = 0.004917749966482656
Trained batch 501 in epoch 1, gen_loss = 1.2589344888094411, disc_loss = 0.004910600924167775
Trained batch 502 in epoch 1, gen_loss = 1.2585686160840286, disc_loss = 0.004906384755415698
Trained batch 503 in epoch 1, gen_loss = 1.258507132293686, disc_loss = 0.004899480360830831
Trained batch 504 in epoch 1, gen_loss = 1.2585387298376254, disc_loss = 0.004892507992283727
Trained batch 505 in epoch 1, gen_loss = 1.2583739675080823, disc_loss = 0.004885850078863434
Trained batch 506 in epoch 1, gen_loss = 1.2583598690860605, disc_loss = 0.004884668433358177
Trained batch 507 in epoch 1, gen_loss = 1.2580901166116158, disc_loss = 0.004886469086352553
Trained batch 508 in epoch 1, gen_loss = 1.2578367767727445, disc_loss = 0.004880189415902697
Trained batch 509 in epoch 1, gen_loss = 1.257569166024526, disc_loss = 0.004873505365628494
Trained batch 510 in epoch 1, gen_loss = 1.2577943953515967, disc_loss = 0.004866388127815576
Trained batch 511 in epoch 1, gen_loss = 1.2580428863875568, disc_loss = 0.004858697927261346
Trained batch 512 in epoch 1, gen_loss = 1.2587937946208039, disc_loss = 0.004852422135795846
Trained batch 513 in epoch 1, gen_loss = 1.2587359157981575, disc_loss = 0.004844570664823932
Trained batch 514 in epoch 1, gen_loss = 1.2587681427742672, disc_loss = 0.0048372965289089935
Trained batch 515 in epoch 1, gen_loss = 1.258684670509294, disc_loss = 0.004829747287728896
Trained batch 516 in epoch 1, gen_loss = 1.2583265477499601, disc_loss = 0.004821703481268159
Trained batch 517 in epoch 1, gen_loss = 1.2579428146244476, disc_loss = 0.004813975468120613
Trained batch 518 in epoch 1, gen_loss = 1.257642191039804, disc_loss = 0.004807264021546661
Trained batch 519 in epoch 1, gen_loss = 1.2572706846090465, disc_loss = 0.004799925930498061
Trained batch 520 in epoch 1, gen_loss = 1.2570454589236035, disc_loss = 0.004792048979055444
Trained batch 521 in epoch 1, gen_loss = 1.2564920116201672, disc_loss = 0.004783987082247498
Trained batch 522 in epoch 1, gen_loss = 1.2563640813754575, disc_loss = 0.004778760127312758
Trained batch 523 in epoch 1, gen_loss = 1.256529234292853, disc_loss = 0.0047719686989492974
Trained batch 524 in epoch 1, gen_loss = 1.2570790853954497, disc_loss = 0.004764367487569828
Trained batch 525 in epoch 1, gen_loss = 1.2569836323705463, disc_loss = 0.004757163695926413
Trained batch 526 in epoch 1, gen_loss = 1.2569626924887554, disc_loss = 0.004749838395668918
Trained batch 527 in epoch 1, gen_loss = 1.256676990425948, disc_loss = 0.004742781988721673
Trained batch 528 in epoch 1, gen_loss = 1.2572545879053934, disc_loss = 0.004735429994062131
Trained batch 529 in epoch 1, gen_loss = 1.2570606728769698, disc_loss = 0.004730331573639733
Trained batch 530 in epoch 1, gen_loss = 1.2568334444319011, disc_loss = 0.0047237799655718
Trained batch 531 in epoch 1, gen_loss = 1.2567982895481855, disc_loss = 0.004717179581184199
Trained batch 532 in epoch 1, gen_loss = 1.256965953011003, disc_loss = 0.004709717799148454
Trained batch 533 in epoch 1, gen_loss = 1.25695132048389, disc_loss = 0.0047027549787279745
Trained batch 534 in epoch 1, gen_loss = 1.2572207718252022, disc_loss = 0.004697490662279774
Trained batch 535 in epoch 1, gen_loss = 1.2574173943765128, disc_loss = 0.004691963367370034
Trained batch 536 in epoch 1, gen_loss = 1.2572230850962065, disc_loss = 0.004688305457818948
Trained batch 537 in epoch 1, gen_loss = 1.2570762168962273, disc_loss = 0.00468499054554521
Trained batch 538 in epoch 1, gen_loss = 1.2569386534434304, disc_loss = 0.004680547103089676
Trained batch 539 in epoch 1, gen_loss = 1.2566602914421647, disc_loss = 0.004673690515186603
Trained batch 540 in epoch 1, gen_loss = 1.2572183324757433, disc_loss = 0.0046687808894645254
Trained batch 541 in epoch 1, gen_loss = 1.2575255093539333, disc_loss = 0.00466197738228486
Trained batch 542 in epoch 1, gen_loss = 1.2573841118680837, disc_loss = 0.004654855392877575
Trained batch 543 in epoch 1, gen_loss = 1.2571308306034874, disc_loss = 0.004648555053790915
Trained batch 544 in epoch 1, gen_loss = 1.2573880792757788, disc_loss = 0.004642438692352606
Trained batch 545 in epoch 1, gen_loss = 1.2571045208326626, disc_loss = 0.004635558779937328
Trained batch 546 in epoch 1, gen_loss = 1.2568093448931819, disc_loss = 0.004628351353976358
Trained batch 547 in epoch 1, gen_loss = 1.2569290229873935, disc_loss = 0.004621167579792393
Trained batch 548 in epoch 1, gen_loss = 1.256783550554286, disc_loss = 0.004615044834211855
Trained batch 549 in epoch 1, gen_loss = 1.2565535393628207, disc_loss = 0.004608878869118847
Trained batch 550 in epoch 1, gen_loss = 1.2563628955674908, disc_loss = 0.004602202636226944
Trained batch 551 in epoch 1, gen_loss = 1.256453793981801, disc_loss = 0.004595967600808775
Trained batch 552 in epoch 1, gen_loss = 1.2562966566620426, disc_loss = 0.004589299495255315
Trained batch 553 in epoch 1, gen_loss = 1.2560755537305068, disc_loss = 0.004583671700696054
Trained batch 554 in epoch 1, gen_loss = 1.2558814196973234, disc_loss = 0.004576819071017609
Trained batch 555 in epoch 1, gen_loss = 1.2563527530903438, disc_loss = 0.004569761169255249
Trained batch 556 in epoch 1, gen_loss = 1.2563636675343266, disc_loss = 0.004562833219351953
Trained batch 557 in epoch 1, gen_loss = 1.2563076837515745, disc_loss = 0.004558151205008562
Trained batch 558 in epoch 1, gen_loss = 1.2559254263296111, disc_loss = 0.004551088070802637
Trained batch 559 in epoch 1, gen_loss = 1.2557473163519586, disc_loss = 0.004546112530702626
Trained batch 560 in epoch 1, gen_loss = 1.2555134908400756, disc_loss = 0.00453956972051465
Trained batch 561 in epoch 1, gen_loss = 1.2551590827860442, disc_loss = 0.004533338860328578
Trained batch 562 in epoch 1, gen_loss = 1.2551701496591787, disc_loss = 0.004526423537056582
Trained batch 563 in epoch 1, gen_loss = 1.2552424130287576, disc_loss = 0.0045196568999598
Trained batch 564 in epoch 1, gen_loss = 1.2553212648999375, disc_loss = 0.004513235789707211
Trained batch 565 in epoch 1, gen_loss = 1.2555012157443555, disc_loss = 0.004507993141233645
Trained batch 566 in epoch 1, gen_loss = 1.255688599388015, disc_loss = 0.004504885759600479
Trained batch 567 in epoch 1, gen_loss = 1.255466145528874, disc_loss = 0.004499082612390236
Trained batch 568 in epoch 1, gen_loss = 1.255388540417113, disc_loss = 0.004495049747212844
Trained batch 569 in epoch 1, gen_loss = 1.2552994876577144, disc_loss = 0.004489063798539798
Trained batch 570 in epoch 1, gen_loss = 1.2550962770882923, disc_loss = 0.004482866781918681
Trained batch 571 in epoch 1, gen_loss = 1.2549748687477378, disc_loss = 0.004478004088192215
Trained batch 572 in epoch 1, gen_loss = 1.2552485657404022, disc_loss = 0.00447364822013814
Trained batch 573 in epoch 1, gen_loss = 1.2554609773466396, disc_loss = 0.004467691340887731
Trained batch 574 in epoch 1, gen_loss = 1.2553982997977216, disc_loss = 0.004462148099935249
Trained batch 575 in epoch 1, gen_loss = 1.2554759410106473, disc_loss = 0.004457809777805879
Trained batch 576 in epoch 1, gen_loss = 1.2557169959284817, disc_loss = 0.0044590687946992665
Trained batch 577 in epoch 1, gen_loss = 1.2559844971115615, disc_loss = 0.004453367286178067
Trained batch 578 in epoch 1, gen_loss = 1.2559134410452966, disc_loss = 0.004447717446792028
Trained batch 579 in epoch 1, gen_loss = 1.2559817145610679, disc_loss = 0.004442073988471309
Trained batch 580 in epoch 1, gen_loss = 1.2556282665561276, disc_loss = 0.004436425228720201
Trained batch 581 in epoch 1, gen_loss = 1.25560734095852, disc_loss = 0.004430847313083849
Trained batch 582 in epoch 1, gen_loss = 1.2553370827058168, disc_loss = 0.004424433048181939
Trained batch 583 in epoch 1, gen_loss = 1.255141052685372, disc_loss = 0.004418888637813586
Trained batch 584 in epoch 1, gen_loss = 1.2554732773039077, disc_loss = 0.004414498075866738
Trained batch 585 in epoch 1, gen_loss = 1.2556430762538324, disc_loss = 0.004409452022209052
Trained batch 586 in epoch 1, gen_loss = 1.255908330620046, disc_loss = 0.004404045421482592
Trained batch 587 in epoch 1, gen_loss = 1.2557163913639224, disc_loss = 0.004397866880397635
Trained batch 588 in epoch 1, gen_loss = 1.2558931148720112, disc_loss = 0.004394469002786714
Trained batch 589 in epoch 1, gen_loss = 1.255841608774864, disc_loss = 0.004388820008627312
Trained batch 590 in epoch 1, gen_loss = 1.2557728552777956, disc_loss = 0.004383100878664761
Trained batch 591 in epoch 1, gen_loss = 1.2557770750812582, disc_loss = 0.004377409555426975
Trained batch 592 in epoch 1, gen_loss = 1.255621079047655, disc_loss = 0.004375190071645389
Trained batch 593 in epoch 1, gen_loss = 1.255915682725232, disc_loss = 0.0043709092900495634
Trained batch 594 in epoch 1, gen_loss = 1.2559088141978287, disc_loss = 0.00436473566893989
Trained batch 595 in epoch 1, gen_loss = 1.255671183334901, disc_loss = 0.00436033781648351
Trained batch 596 in epoch 1, gen_loss = 1.2555667149960694, disc_loss = 0.004355422046013688
Trained batch 597 in epoch 1, gen_loss = 1.2559032613617123, disc_loss = 0.004351570475363736
Trained batch 598 in epoch 1, gen_loss = 1.2558053310008996, disc_loss = 0.004346467518808945
Trained batch 599 in epoch 1, gen_loss = 1.255598416129748, disc_loss = 0.004340249191542777
Trained batch 600 in epoch 1, gen_loss = 1.2553130394210434, disc_loss = 0.004334791457495914
Trained batch 601 in epoch 1, gen_loss = 1.255562330401221, disc_loss = 0.004331419780653935
Trained batch 602 in epoch 1, gen_loss = 1.2554835434972154, disc_loss = 0.004326922170529034
Trained batch 603 in epoch 1, gen_loss = 1.2552749966548769, disc_loss = 0.004321762110455122
Trained batch 604 in epoch 1, gen_loss = 1.2551971445398882, disc_loss = 0.0043167579922948245
Trained batch 605 in epoch 1, gen_loss = 1.2548361656689409, disc_loss = 0.004310885492693818
Trained batch 606 in epoch 1, gen_loss = 1.2549393245769294, disc_loss = 0.004304743084030094
Trained batch 607 in epoch 1, gen_loss = 1.2549308673723747, disc_loss = 0.004298867429832554
Trained batch 608 in epoch 1, gen_loss = 1.254933403826308, disc_loss = 0.00429351013836226
Trained batch 609 in epoch 1, gen_loss = 1.254825734701313, disc_loss = 0.0042884324330905235
Trained batch 610 in epoch 1, gen_loss = 1.2545999405622092, disc_loss = 0.0042835699670426795
Trained batch 611 in epoch 1, gen_loss = 1.254628411695069, disc_loss = 0.004278721985102059
Trained batch 612 in epoch 1, gen_loss = 1.2542785042456275, disc_loss = 0.004274200327594903
Trained batch 613 in epoch 1, gen_loss = 1.2540295485176558, disc_loss = 0.004268200781555841
Trained batch 614 in epoch 1, gen_loss = 1.2538525949648724, disc_loss = 0.004262208703401824
Trained batch 615 in epoch 1, gen_loss = 1.2534568580714138, disc_loss = 0.004260817265146345
Trained batch 616 in epoch 1, gen_loss = 1.254343120166896, disc_loss = 0.004258264302871548
Trained batch 617 in epoch 1, gen_loss = 1.2540685922196768, disc_loss = 0.004253691159438155
Trained batch 618 in epoch 1, gen_loss = 1.2539186360185097, disc_loss = 0.004251269081901602
Trained batch 619 in epoch 1, gen_loss = 1.2541786026570105, disc_loss = 0.004247535999409945
Trained batch 620 in epoch 1, gen_loss = 1.2538900862953322, disc_loss = 0.004243771842438668
Trained batch 621 in epoch 1, gen_loss = 1.2538692542977654, disc_loss = 0.004237976994749512
Trained batch 622 in epoch 1, gen_loss = 1.2541111738302926, disc_loss = 0.004232776909898428
Trained batch 623 in epoch 1, gen_loss = 1.2539794951295242, disc_loss = 0.004227262235359283
Trained batch 624 in epoch 1, gen_loss = 1.2537332485198975, disc_loss = 0.004221854140702635
Trained batch 625 in epoch 1, gen_loss = 1.253818572138826, disc_loss = 0.004216621426538901
Trained batch 626 in epoch 1, gen_loss = 1.2536248468706293, disc_loss = 0.004210753056838621
Trained batch 627 in epoch 1, gen_loss = 1.254000847506675, disc_loss = 0.0042050703274639275
Trained batch 628 in epoch 1, gen_loss = 1.2538483307736856, disc_loss = 0.004199870942021307
Trained batch 629 in epoch 1, gen_loss = 1.253708931567177, disc_loss = 0.004195340625047388
Trained batch 630 in epoch 1, gen_loss = 1.2538882475080657, disc_loss = 0.004190849799481287
Trained batch 631 in epoch 1, gen_loss = 1.2539826529689981, disc_loss = 0.004185298309827966
Trained batch 632 in epoch 1, gen_loss = 1.2537654851096878, disc_loss = 0.004180047674123698
Trained batch 633 in epoch 1, gen_loss = 1.2539202271951861, disc_loss = 0.004174338608513049
Trained batch 634 in epoch 1, gen_loss = 1.2537742128522378, disc_loss = 0.004170336238453238
Trained batch 635 in epoch 1, gen_loss = 1.2539110491110843, disc_loss = 0.004165950688678455
Trained batch 636 in epoch 1, gen_loss = 1.2535888688343473, disc_loss = 0.004164075650518915
Trained batch 637 in epoch 1, gen_loss = 1.2538239384145946, disc_loss = 0.004160052693272331
Trained batch 638 in epoch 1, gen_loss = 1.2535949883886346, disc_loss = 0.004156239182653317
Trained batch 639 in epoch 1, gen_loss = 1.2533899005502462, disc_loss = 0.004151826348061149
Trained batch 640 in epoch 1, gen_loss = 1.2534121455342833, disc_loss = 0.004146438715114969
Trained batch 641 in epoch 1, gen_loss = 1.253226534599827, disc_loss = 0.00414132424969316
Trained batch 642 in epoch 1, gen_loss = 1.2529941155788131, disc_loss = 0.004137121240987151
Trained batch 643 in epoch 1, gen_loss = 1.25335049277507, disc_loss = 0.004132382452479991
Trained batch 644 in epoch 1, gen_loss = 1.2530070439789647, disc_loss = 0.004127946554578465
Trained batch 645 in epoch 1, gen_loss = 1.2532516784343188, disc_loss = 0.004123186124485107
Trained batch 646 in epoch 1, gen_loss = 1.2530606915077434, disc_loss = 0.004118007466422287
Trained batch 647 in epoch 1, gen_loss = 1.2529661063058877, disc_loss = 0.004115624424162821
Trained batch 648 in epoch 1, gen_loss = 1.2531340790823537, disc_loss = 0.004111145191000077
Trained batch 649 in epoch 1, gen_loss = 1.2531708462421711, disc_loss = 0.00410583910648711
Trained batch 650 in epoch 1, gen_loss = 1.252995215619581, disc_loss = 0.004100565200856817
Trained batch 651 in epoch 1, gen_loss = 1.2527533374681064, disc_loss = 0.0040953603400484566
Trained batch 652 in epoch 1, gen_loss = 1.2529105304028685, disc_loss = 0.0040903819432007195
Trained batch 653 in epoch 1, gen_loss = 1.2527156907848627, disc_loss = 0.004085142762006463
Trained batch 654 in epoch 1, gen_loss = 1.2523847559936174, disc_loss = 0.004080524768605686
Trained batch 655 in epoch 1, gen_loss = 1.2524341343016159, disc_loss = 0.004075341379087526
Trained batch 656 in epoch 1, gen_loss = 1.2529851954821583, disc_loss = 0.004070059693566576
Trained batch 657 in epoch 1, gen_loss = 1.2529453531949353, disc_loss = 0.004065162001979483
Trained batch 658 in epoch 1, gen_loss = 1.2527047408368772, disc_loss = 0.004060167818554933
Trained batch 659 in epoch 1, gen_loss = 1.252716893860788, disc_loss = 0.004055002247068015
Trained batch 660 in epoch 1, gen_loss = 1.2523495310553985, disc_loss = 0.004052248127538705
Trained batch 661 in epoch 1, gen_loss = 1.2520230722211279, disc_loss = 0.004051250000442083
Trained batch 662 in epoch 1, gen_loss = 1.2516301165518897, disc_loss = 0.00404723502378096
Trained batch 663 in epoch 1, gen_loss = 1.2515705768243377, disc_loss = 0.0040423161592488795
Trained batch 664 in epoch 1, gen_loss = 1.2515125660071695, disc_loss = 0.0040377363455796934
Trained batch 665 in epoch 1, gen_loss = 1.251607321225129, disc_loss = 0.004032391322524617
Trained batch 666 in epoch 1, gen_loss = 1.2514432464939902, disc_loss = 0.004027196892034165
Trained batch 667 in epoch 1, gen_loss = 1.2513973977037534, disc_loss = 0.004022194009996089
Trained batch 668 in epoch 1, gen_loss = 1.251076268864676, disc_loss = 0.004017114304783942
Trained batch 669 in epoch 1, gen_loss = 1.2506966970749755, disc_loss = 0.004012093897309474
Trained batch 670 in epoch 1, gen_loss = 1.2509883406798281, disc_loss = 0.00400717338805098
Trained batch 671 in epoch 1, gen_loss = 1.2506776766940242, disc_loss = 0.004002176026439147
Trained batch 672 in epoch 1, gen_loss = 1.2503226730657013, disc_loss = 0.003997214101706417
Trained batch 673 in epoch 1, gen_loss = 1.2506956706591812, disc_loss = 0.003993260959042057
Trained batch 674 in epoch 1, gen_loss = 1.250697767911134, disc_loss = 0.003988990729924775
Trained batch 675 in epoch 1, gen_loss = 1.2509202023406, disc_loss = 0.0039840963578796065
Trained batch 676 in epoch 1, gen_loss = 1.2510314692950848, disc_loss = 0.003978972684392882
Trained batch 677 in epoch 1, gen_loss = 1.250874327962729, disc_loss = 0.003975332659371486
Trained batch 678 in epoch 1, gen_loss = 1.2505550278304076, disc_loss = 0.00397242447921138
Trained batch 679 in epoch 1, gen_loss = 1.250842166209922, disc_loss = 0.003968156137895729
Trained batch 680 in epoch 1, gen_loss = 1.2507362816477312, disc_loss = 0.0039636230153232
Trained batch 681 in epoch 1, gen_loss = 1.250597667047355, disc_loss = 0.003958675545861171
Trained batch 682 in epoch 1, gen_loss = 1.2503143242651686, disc_loss = 0.003954486292778374
Trained batch 683 in epoch 1, gen_loss = 1.250520353864508, disc_loss = 0.003952659994296726
Trained batch 684 in epoch 1, gen_loss = 1.2505967972922498, disc_loss = 0.003949265491963452
Trained batch 685 in epoch 1, gen_loss = 1.250826142706607, disc_loss = 0.003945055772520197
Trained batch 686 in epoch 1, gen_loss = 1.2507408630899988, disc_loss = 0.00394047984918288
Trained batch 687 in epoch 1, gen_loss = 1.2505269056662571, disc_loss = 0.003937474534828906
Trained batch 688 in epoch 1, gen_loss = 1.2502846163312307, disc_loss = 0.003936318640388664
Trained batch 689 in epoch 1, gen_loss = 1.250309122040652, disc_loss = 0.003936711792198037
Trained batch 690 in epoch 1, gen_loss = 1.2503720036291353, disc_loss = 0.003937078329494261
Trained batch 691 in epoch 1, gen_loss = 1.250076701961501, disc_loss = 0.003935747954486721
Trained batch 692 in epoch 1, gen_loss = 1.2502880771610816, disc_loss = 0.003931440332994163
Trained batch 693 in epoch 1, gen_loss = 1.2504774386154471, disc_loss = 0.00392724609119725
Trained batch 694 in epoch 1, gen_loss = 1.2506231063561475, disc_loss = 0.003922463441560742
Trained batch 695 in epoch 1, gen_loss = 1.2505270724837807, disc_loss = 0.003917402310173787
Trained batch 696 in epoch 1, gen_loss = 1.2510551646073886, disc_loss = 0.003912718663372265
Trained batch 697 in epoch 1, gen_loss = 1.2508656608853437, disc_loss = 0.003908825158204931
Trained batch 698 in epoch 1, gen_loss = 1.250648616124291, disc_loss = 0.003904060863417431
Trained batch 699 in epoch 1, gen_loss = 1.250718074100358, disc_loss = 0.003899324219673872
Trained batch 700 in epoch 1, gen_loss = 1.2503840147003467, disc_loss = 0.0038949393552027843
Trained batch 701 in epoch 1, gen_loss = 1.2509150074587927, disc_loss = 0.0038906598349726703
Trained batch 702 in epoch 1, gen_loss = 1.2509935967952734, disc_loss = 0.003886099453935344
Trained batch 703 in epoch 1, gen_loss = 1.251002940857275, disc_loss = 0.0038834466215782663
Trained batch 704 in epoch 1, gen_loss = 1.2509588676986965, disc_loss = 0.0038804818814164622
Trained batch 705 in epoch 1, gen_loss = 1.2509336886088505, disc_loss = 0.003876558674592393
Trained batch 706 in epoch 1, gen_loss = 1.2510458383566925, disc_loss = 0.003872602695649914
Trained batch 707 in epoch 1, gen_loss = 1.251076111601571, disc_loss = 0.0038677967386320233
Trained batch 708 in epoch 1, gen_loss = 1.2510687767702702, disc_loss = 0.0038634480957607823
Trained batch 709 in epoch 1, gen_loss = 1.2512294679460392, disc_loss = 0.003859443179557992
Trained batch 710 in epoch 1, gen_loss = 1.2510527968406677, disc_loss = 0.0038555221133223577
Trained batch 711 in epoch 1, gen_loss = 1.250848068196452, disc_loss = 0.003851614629649008
Trained batch 712 in epoch 1, gen_loss = 1.2510509546976771, disc_loss = 0.0038476794980809898
Trained batch 713 in epoch 1, gen_loss = 1.251338531072734, disc_loss = 0.0038433326744958395
Trained batch 714 in epoch 1, gen_loss = 1.2513796253637834, disc_loss = 0.0038402494867788173
Trained batch 715 in epoch 1, gen_loss = 1.2512850142890515, disc_loss = 0.0038363639273916177
Trained batch 716 in epoch 1, gen_loss = 1.25114427791646, disc_loss = 0.003832029033909491
Trained batch 717 in epoch 1, gen_loss = 1.250945300029845, disc_loss = 0.003828284841563947
Trained batch 718 in epoch 1, gen_loss = 1.2514104686459846, disc_loss = 0.0038242329436455375
Trained batch 719 in epoch 1, gen_loss = 1.2515206836163997, disc_loss = 0.003820183401613677
Trained batch 720 in epoch 1, gen_loss = 1.2516403602495603, disc_loss = 0.003816019824735727
Trained batch 721 in epoch 1, gen_loss = 1.251617667500002, disc_loss = 0.00381196471440046
Trained batch 722 in epoch 1, gen_loss = 1.2517635872584985, disc_loss = 0.0038077698740013265
Trained batch 723 in epoch 1, gen_loss = 1.2517390258569085, disc_loss = 0.0038037795841356853
Trained batch 724 in epoch 1, gen_loss = 1.251699598164394, disc_loss = 0.0038001196396312323
Trained batch 725 in epoch 1, gen_loss = 1.251494707729534, disc_loss = 0.003796731980200652
Trained batch 726 in epoch 1, gen_loss = 1.2514686331132419, disc_loss = 0.003792837262634019
Trained batch 727 in epoch 1, gen_loss = 1.251719897183088, disc_loss = 0.0037886878341381377
Trained batch 728 in epoch 1, gen_loss = 1.2516186194001238, disc_loss = 0.0037842492502858536
Trained batch 729 in epoch 1, gen_loss = 1.2515578047053455, disc_loss = 0.0037797766089381984
Trained batch 730 in epoch 1, gen_loss = 1.2513338329853991, disc_loss = 0.0037751901580597926
Trained batch 731 in epoch 1, gen_loss = 1.2510530552088888, disc_loss = 0.003771285446061081
Trained batch 732 in epoch 1, gen_loss = 1.2511006461159107, disc_loss = 0.003767037527787526
Trained batch 733 in epoch 1, gen_loss = 1.2509281345381724, disc_loss = 0.003762570014480395
Trained batch 734 in epoch 1, gen_loss = 1.2508401925061026, disc_loss = 0.0037583580368109755
Trained batch 735 in epoch 1, gen_loss = 1.2509403833714516, disc_loss = 0.0037542309091013917
Trained batch 736 in epoch 1, gen_loss = 1.250872258011004, disc_loss = 0.0037501574716034118
Trained batch 737 in epoch 1, gen_loss = 1.2508567086241755, disc_loss = 0.0037457759154999634
Trained batch 738 in epoch 1, gen_loss = 1.2506068245645143, disc_loss = 0.0037413165719955353
Trained batch 739 in epoch 1, gen_loss = 1.2507144695198213, disc_loss = 0.003737208519895511
Trained batch 740 in epoch 1, gen_loss = 1.2505892100926193, disc_loss = 0.0037327233934303676
Trained batch 741 in epoch 1, gen_loss = 1.250599203003706, disc_loss = 0.0037283957806432174
Trained batch 742 in epoch 1, gen_loss = 1.2506048861454826, disc_loss = 0.00372413447144608
Trained batch 743 in epoch 1, gen_loss = 1.2505300202837555, disc_loss = 0.0037200863809376122
Trained batch 744 in epoch 1, gen_loss = 1.250426460032495, disc_loss = 0.003718393216075238
Trained batch 745 in epoch 1, gen_loss = 1.250465795038213, disc_loss = 0.003717087188079559
Trained batch 746 in epoch 1, gen_loss = 1.250446278965936, disc_loss = 0.0037136882793069774
Trained batch 747 in epoch 1, gen_loss = 1.250417341762048, disc_loss = 0.0037109477220278702
Trained batch 748 in epoch 1, gen_loss = 1.2503365132614512, disc_loss = 0.003707022246614332
Trained batch 749 in epoch 1, gen_loss = 1.250585050344467, disc_loss = 0.00370273987405623
Trained batch 750 in epoch 1, gen_loss = 1.2506486629042899, disc_loss = 0.0036983756945603657
Trained batch 751 in epoch 1, gen_loss = 1.2505558782276955, disc_loss = 0.003694095977481722
Trained batch 752 in epoch 1, gen_loss = 1.2505633523106416, disc_loss = 0.003689998216929525
Trained batch 753 in epoch 1, gen_loss = 1.2506728544633647, disc_loss = 0.0036857087186424045
Trained batch 754 in epoch 1, gen_loss = 1.2505513834637523, disc_loss = 0.0036814661571657322
Trained batch 755 in epoch 1, gen_loss = 1.250689128955836, disc_loss = 0.0036773620299297687
Trained batch 756 in epoch 1, gen_loss = 1.250763680456179, disc_loss = 0.003673530497607902
Trained batch 757 in epoch 1, gen_loss = 1.251528439153782, disc_loss = 0.0036706939526393732
Trained batch 758 in epoch 1, gen_loss = 1.2515716702727617, disc_loss = 0.0036671739820101357
Trained batch 759 in epoch 1, gen_loss = 1.2518707084812617, disc_loss = 0.0036632981080114597
Trained batch 760 in epoch 1, gen_loss = 1.2520222789981206, disc_loss = 0.0036594362798821225
Trained batch 761 in epoch 1, gen_loss = 1.2521271595335381, disc_loss = 0.003655848919390762
Trained batch 762 in epoch 1, gen_loss = 1.2525073671872151, disc_loss = 0.0036520931556507175
Trained batch 763 in epoch 1, gen_loss = 1.2522936172354284, disc_loss = 0.003648236363377125
Trained batch 764 in epoch 1, gen_loss = 1.2526052555227591, disc_loss = 0.003644522606909543
Trained batch 765 in epoch 1, gen_loss = 1.2524111701209613, disc_loss = 0.0036415763545991713
Trained batch 766 in epoch 1, gen_loss = 1.2526275350808165, disc_loss = 0.003638420001657697
Trained batch 767 in epoch 1, gen_loss = 1.2525063626623403, disc_loss = 0.0036355135173380404
Trained batch 768 in epoch 1, gen_loss = 1.2523499320325369, disc_loss = 0.0036318672941882593
Trained batch 769 in epoch 1, gen_loss = 1.2523612908728712, disc_loss = 0.00362781216617214
Trained batch 770 in epoch 1, gen_loss = 1.2523224110269362, disc_loss = 0.0036244453397554126
Trained batch 771 in epoch 1, gen_loss = 1.252133320109832, disc_loss = 0.0036215533894773844
Trained batch 772 in epoch 1, gen_loss = 1.2521897069386956, disc_loss = 0.003618041702207626
Trained batch 773 in epoch 1, gen_loss = 1.2520230319302827, disc_loss = 0.003614147799194836
Trained batch 774 in epoch 1, gen_loss = 1.2521509805033284, disc_loss = 0.0036105107072169984
Trained batch 775 in epoch 1, gen_loss = 1.2520306124976002, disc_loss = 0.0036072327756741774
Trained batch 776 in epoch 1, gen_loss = 1.251969944786381, disc_loss = 0.003603585871677256
Trained batch 777 in epoch 1, gen_loss = 1.2524347747352864, disc_loss = 0.0036001761454686637
Trained batch 778 in epoch 1, gen_loss = 1.2521866409249116, disc_loss = 0.003597237738369413
Trained batch 779 in epoch 1, gen_loss = 1.2519730632885908, disc_loss = 0.0035956459330359044
Trained batch 780 in epoch 1, gen_loss = 1.2517638581205117, disc_loss = 0.0035925150800331777
Trained batch 781 in epoch 1, gen_loss = 1.2517821905405626, disc_loss = 0.0035887123209119433
Trained batch 782 in epoch 1, gen_loss = 1.2517006028048685, disc_loss = 0.0035851835422628197
Trained batch 783 in epoch 1, gen_loss = 1.2519784657170578, disc_loss = 0.003581330429926534
Trained batch 784 in epoch 1, gen_loss = 1.2517907948250984, disc_loss = 0.003594392897845928
Trained batch 785 in epoch 1, gen_loss = 1.2515437247340613, disc_loss = 0.0036016643137976754
Trained batch 786 in epoch 1, gen_loss = 1.251457383929547, disc_loss = 0.003602544137180855
Trained batch 787 in epoch 1, gen_loss = 1.251440966114175, disc_loss = 0.0036017058690806596
Trained batch 788 in epoch 1, gen_loss = 1.2515043957756198, disc_loss = 0.0035986012946790692
Trained batch 789 in epoch 1, gen_loss = 1.2514696416221087, disc_loss = 0.003595979416689871
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 1.2391083240509033, disc_loss = 0.0017835097387433052
Trained batch 1 in epoch 2, gen_loss = 1.1802650690078735, disc_loss = 0.001729900948703289
Trained batch 2 in epoch 2, gen_loss = 1.2354291677474976, disc_loss = 0.001657230081036687
Trained batch 3 in epoch 2, gen_loss = 1.248160034418106, disc_loss = 0.0018031797953881323
Trained batch 4 in epoch 2, gen_loss = 1.2719431877136231, disc_loss = 0.0016733936965465546
Trained batch 5 in epoch 2, gen_loss = 1.2510523796081543, disc_loss = 0.0017859240372975667
Trained batch 6 in epoch 2, gen_loss = 1.252596480505807, disc_loss = 0.0018887589020388468
Trained batch 7 in epoch 2, gen_loss = 1.2425284683704376, disc_loss = 0.0019758914422709495
Trained batch 8 in epoch 2, gen_loss = 1.2574887010786269, disc_loss = 0.0019607170898881224
Trained batch 9 in epoch 2, gen_loss = 1.2560816526412963, disc_loss = 0.0019190623424947262
Trained batch 10 in epoch 2, gen_loss = 1.2807742248881946, disc_loss = 0.0018441604810174215
Trained batch 11 in epoch 2, gen_loss = 1.2712789177894592, disc_loss = 0.0017775865368700277
Trained batch 12 in epoch 2, gen_loss = 1.303529510131249, disc_loss = 0.0017114656332593698
Trained batch 13 in epoch 2, gen_loss = 1.3065587452479772, disc_loss = 0.0016475072604537541
Trained batch 14 in epoch 2, gen_loss = 1.3010942459106445, disc_loss = 0.0015900174039416015
Trained batch 15 in epoch 2, gen_loss = 1.3045417070388794, disc_loss = 0.0015237427251122426
Trained batch 16 in epoch 2, gen_loss = 1.293453020208022, disc_loss = 0.0015229295274954947
Trained batch 17 in epoch 2, gen_loss = 1.2979953686396282, disc_loss = 0.0015245100916622
Trained batch 18 in epoch 2, gen_loss = 1.2896990901545475, disc_loss = 0.0014890426782106882
Trained batch 19 in epoch 2, gen_loss = 1.28602676987648, disc_loss = 0.0014351822246680968
Trained batch 20 in epoch 2, gen_loss = 1.2980636131195795, disc_loss = 0.001389949952551563
Trained batch 21 in epoch 2, gen_loss = 1.2881490913304416, disc_loss = 0.0013592678151326254
Trained batch 22 in epoch 2, gen_loss = 1.2872436720391978, disc_loss = 0.0013282807106050946
Trained batch 23 in epoch 2, gen_loss = 1.2915719002485275, disc_loss = 0.0013016614017639465
Trained batch 24 in epoch 2, gen_loss = 1.2911978006362914, disc_loss = 0.0012840900605078788
Trained batch 25 in epoch 2, gen_loss = 1.28895909511126, disc_loss = 0.0012759622399104186
Trained batch 26 in epoch 2, gen_loss = 1.2834649527514423, disc_loss = 0.0012821838878422837
Trained batch 27 in epoch 2, gen_loss = 1.2856328913143702, disc_loss = 0.001265393905798971
Trained batch 28 in epoch 2, gen_loss = 1.2830589639729466, disc_loss = 0.001255474610310369
Trained batch 29 in epoch 2, gen_loss = 1.2788233121236166, disc_loss = 0.0012421671213814988
Trained batch 30 in epoch 2, gen_loss = 1.2739640820410945, disc_loss = 0.0012158733415192054
Trained batch 31 in epoch 2, gen_loss = 1.2716547958552837, disc_loss = 0.001194397579638462
Trained batch 32 in epoch 2, gen_loss = 1.2712632489926887, disc_loss = 0.0011803028658808519
Trained batch 33 in epoch 2, gen_loss = 1.2654594323214363, disc_loss = 0.00118035298125024
Trained batch 34 in epoch 2, gen_loss = 1.2616474832807267, disc_loss = 0.0011997268626665963
Trained batch 35 in epoch 2, gen_loss = 1.2643796006838481, disc_loss = 0.0011974736367442852
Trained batch 36 in epoch 2, gen_loss = 1.2596989902290139, disc_loss = 0.001192016208487739
Trained batch 37 in epoch 2, gen_loss = 1.254346910275911, disc_loss = 0.001173393884336723
Trained batch 38 in epoch 2, gen_loss = 1.2522796056209466, disc_loss = 0.0011601220564140629
Trained batch 39 in epoch 2, gen_loss = 1.2533299535512925, disc_loss = 0.0011631958121142815
Trained batch 40 in epoch 2, gen_loss = 1.2554269796464501, disc_loss = 0.0011551304338443115
Trained batch 41 in epoch 2, gen_loss = 1.2515565639450437, disc_loss = 0.001143281704918038
Trained batch 42 in epoch 2, gen_loss = 1.2478289243786833, disc_loss = 0.001127867546571462
Trained batch 43 in epoch 2, gen_loss = 1.2449743341315875, disc_loss = 0.0011150057266191156
Trained batch 44 in epoch 2, gen_loss = 1.2425243457158406, disc_loss = 0.0010994046661330181
Trained batch 45 in epoch 2, gen_loss = 1.2398839230122773, disc_loss = 0.0010952827028434156
Trained batch 46 in epoch 2, gen_loss = 1.2351916115334693, disc_loss = 0.0010856740130854652
Trained batch 47 in epoch 2, gen_loss = 1.2314778044819832, disc_loss = 0.001074864847396384
Trained batch 48 in epoch 2, gen_loss = 1.2371286786332423, disc_loss = 0.001069801854212027
Trained batch 49 in epoch 2, gen_loss = 1.2370389699935913, disc_loss = 0.001059397139470093
Trained batch 50 in epoch 2, gen_loss = 1.2351888418197632, disc_loss = 0.0010515995518824853
Trained batch 51 in epoch 2, gen_loss = 1.2340048070137317, disc_loss = 0.0010466565318683234
Trained batch 52 in epoch 2, gen_loss = 1.2331122047496292, disc_loss = 0.0010363819898009511
Trained batch 53 in epoch 2, gen_loss = 1.2301114091166743, disc_loss = 0.0010253939668742802
Trained batch 54 in epoch 2, gen_loss = 1.22804930860346, disc_loss = 0.0010153279941402036
Trained batch 55 in epoch 2, gen_loss = 1.228537523320743, disc_loss = 0.0010170284206521632
Trained batch 56 in epoch 2, gen_loss = 1.2265850493782444, disc_loss = 0.0010178888879365108
Trained batch 57 in epoch 2, gen_loss = 1.232100404542068, disc_loss = 0.0010124382854977238
Trained batch 58 in epoch 2, gen_loss = 1.2355355650691662, disc_loss = 0.0010051452500500985
Trained batch 59 in epoch 2, gen_loss = 1.2372156023979186, disc_loss = 0.0010304695562808775
Trained batch 60 in epoch 2, gen_loss = 1.2457494735717773, disc_loss = 0.0010915877718333398
Trained batch 61 in epoch 2, gen_loss = 1.251374690763412, disc_loss = 0.0011350659661993926
Trained batch 62 in epoch 2, gen_loss = 1.2518801083640447, disc_loss = 0.0011377745988919207
Trained batch 63 in epoch 2, gen_loss = 1.2538065481930971, disc_loss = 0.001128009311742062
Trained batch 64 in epoch 2, gen_loss = 1.2518636611791758, disc_loss = 0.0011341151284376303
Trained batch 65 in epoch 2, gen_loss = 1.2522526582082112, disc_loss = 0.0011425796198609257
Trained batch 66 in epoch 2, gen_loss = 1.2521881541209434, disc_loss = 0.0011384152835964766
Trained batch 67 in epoch 2, gen_loss = 1.2531396623919993, disc_loss = 0.0011328680415959645
Trained batch 68 in epoch 2, gen_loss = 1.2528237691823987, disc_loss = 0.0011310092628211378
Trained batch 69 in epoch 2, gen_loss = 1.2510248201234, disc_loss = 0.001125040405479792
Trained batch 70 in epoch 2, gen_loss = 1.2486991428993117, disc_loss = 0.0011213258467122754
Trained batch 71 in epoch 2, gen_loss = 1.2494795769453049, disc_loss = 0.0011174431876699803
Trained batch 72 in epoch 2, gen_loss = 1.2512210052307338, disc_loss = 0.00111754935383095
Trained batch 73 in epoch 2, gen_loss = 1.2528254824715692, disc_loss = 0.0011191164207097295
Trained batch 74 in epoch 2, gen_loss = 1.2503983545303345, disc_loss = 0.0011137780745048077
Trained batch 75 in epoch 2, gen_loss = 1.254689274649871, disc_loss = 0.0011114081613701082
Trained batch 76 in epoch 2, gen_loss = 1.254487497465951, disc_loss = 0.0011156804685015231
Trained batch 77 in epoch 2, gen_loss = 1.2546182152552483, disc_loss = 0.0011150539238513329
Trained batch 78 in epoch 2, gen_loss = 1.253361861917037, disc_loss = 0.0011075309199970688
Trained batch 79 in epoch 2, gen_loss = 1.2536486595869065, disc_loss = 0.0011000881549989572
Trained batch 80 in epoch 2, gen_loss = 1.251983415933303, disc_loss = 0.0010966198633131743
Trained batch 81 in epoch 2, gen_loss = 1.2496850170740268, disc_loss = 0.0010941175437992347
Trained batch 82 in epoch 2, gen_loss = 1.2547374777047031, disc_loss = 0.0010898897430651922
Trained batch 83 in epoch 2, gen_loss = 1.2545040987786793, disc_loss = 0.001095980127588735
Trained batch 84 in epoch 2, gen_loss = 1.2543339701259837, disc_loss = 0.0010988212207688347
Trained batch 85 in epoch 2, gen_loss = 1.2542339688123658, disc_loss = 0.001096956293453289
Trained batch 86 in epoch 2, gen_loss = 1.2539791608678883, disc_loss = 0.0010932264471528303
Trained batch 87 in epoch 2, gen_loss = 1.2535864399238066, disc_loss = 0.00109509118159291
Trained batch 88 in epoch 2, gen_loss = 1.2543765708301844, disc_loss = 0.0010973371998956323
Trained batch 89 in epoch 2, gen_loss = 1.2545753969086542, disc_loss = 0.001102288264923522
Trained batch 90 in epoch 2, gen_loss = 1.2529225035028144, disc_loss = 0.0011074521644731758
Trained batch 91 in epoch 2, gen_loss = 1.2523873266966448, disc_loss = 0.0011113337022834457
Trained batch 92 in epoch 2, gen_loss = 1.2495456011064592, disc_loss = 0.0011145327905548476
Trained batch 93 in epoch 2, gen_loss = 1.2507547736167908, disc_loss = 0.001112267923320921
Trained batch 94 in epoch 2, gen_loss = 1.2490963747626858, disc_loss = 0.0011067347867585915
Trained batch 95 in epoch 2, gen_loss = 1.2474509937067826, disc_loss = 0.0011093155708294944
Trained batch 96 in epoch 2, gen_loss = 1.2473659675145887, disc_loss = 0.0011208277329509675
Trained batch 97 in epoch 2, gen_loss = 1.2473952770233154, disc_loss = 0.0011265367725080031
Trained batch 98 in epoch 2, gen_loss = 1.2463015197503446, disc_loss = 0.0011213214146655354
Trained batch 99 in epoch 2, gen_loss = 1.2443269956111909, disc_loss = 0.0011172489213640802
Trained batch 100 in epoch 2, gen_loss = 1.245308783974978, disc_loss = 0.001116386413894649
Trained batch 101 in epoch 2, gen_loss = 1.2445893942141066, disc_loss = 0.0011113179381366126
Trained batch 102 in epoch 2, gen_loss = 1.244579620731687, disc_loss = 0.0011053658590665612
Trained batch 103 in epoch 2, gen_loss = 1.2438768331821148, disc_loss = 0.00110451109027893
Trained batch 104 in epoch 2, gen_loss = 1.2456865753446307, disc_loss = 0.0011031577233335979
Trained batch 105 in epoch 2, gen_loss = 1.2450035214424133, disc_loss = 0.0011060179602728174
Trained batch 106 in epoch 2, gen_loss = 1.2439055587643775, disc_loss = 0.0011146801720247125
Trained batch 107 in epoch 2, gen_loss = 1.2431665990087721, disc_loss = 0.0011163103769865335
Trained batch 108 in epoch 2, gen_loss = 1.2438090219410187, disc_loss = 0.0011207537371515715
Trained batch 109 in epoch 2, gen_loss = 1.242906857620586, disc_loss = 0.0011218379233138298
Trained batch 110 in epoch 2, gen_loss = 1.242721928132547, disc_loss = 0.0011177188740426522
Trained batch 111 in epoch 2, gen_loss = 1.2418388820120267, disc_loss = 0.0011237108600263518
Trained batch 112 in epoch 2, gen_loss = 1.2404458280158255, disc_loss = 0.00112553162163379
Trained batch 113 in epoch 2, gen_loss = 1.2388758659362793, disc_loss = 0.0011218295337146213
Trained batch 114 in epoch 2, gen_loss = 1.237053080227064, disc_loss = 0.0011266131746157518
Trained batch 115 in epoch 2, gen_loss = 1.2359770125356213, disc_loss = 0.0011243136523889602
Trained batch 116 in epoch 2, gen_loss = 1.235043286258339, disc_loss = 0.0011215472017299447
Trained batch 117 in epoch 2, gen_loss = 1.2348837296841508, disc_loss = 0.0011174318647521185
Trained batch 118 in epoch 2, gen_loss = 1.2355495871616011, disc_loss = 0.0011137718412567307
Trained batch 119 in epoch 2, gen_loss = 1.2344895839691161, disc_loss = 0.00111206565319056
Trained batch 120 in epoch 2, gen_loss = 1.2333372151556095, disc_loss = 0.0011082419378525186
Trained batch 121 in epoch 2, gen_loss = 1.2344344238765905, disc_loss = 0.0011027175558589735
Trained batch 122 in epoch 2, gen_loss = 1.2360177117634594, disc_loss = 0.001097468163096914
Trained batch 123 in epoch 2, gen_loss = 1.2377076206668731, disc_loss = 0.0010922052392890046
Trained batch 124 in epoch 2, gen_loss = 1.2388129177093505, disc_loss = 0.0010864726814907044
Trained batch 125 in epoch 2, gen_loss = 1.238199338080391, disc_loss = 0.0010829034766333828
Trained batch 126 in epoch 2, gen_loss = 1.2374001206375482, disc_loss = 0.0010791150635332016
Trained batch 127 in epoch 2, gen_loss = 1.2384326234459877, disc_loss = 0.001074093520628594
Trained batch 128 in epoch 2, gen_loss = 1.238302743712137, disc_loss = 0.0010697913327698358
Trained batch 129 in epoch 2, gen_loss = 1.2369175351583042, disc_loss = 0.0010698577328674638
Trained batch 130 in epoch 2, gen_loss = 1.2361719881305258, disc_loss = 0.0010777592460379602
Trained batch 131 in epoch 2, gen_loss = 1.234816357944951, disc_loss = 0.0010796893561332995
Trained batch 132 in epoch 2, gen_loss = 1.235497366216846, disc_loss = 0.0010795487212174734
Trained batch 133 in epoch 2, gen_loss = 1.234816910615608, disc_loss = 0.0010783674572021076
Trained batch 134 in epoch 2, gen_loss = 1.2342809050171464, disc_loss = 0.0010774244776392287
Trained batch 135 in epoch 2, gen_loss = 1.2332383630906834, disc_loss = 0.0010814420536061173
Trained batch 136 in epoch 2, gen_loss = 1.2334087852143893, disc_loss = 0.001079343397630868
Trained batch 137 in epoch 2, gen_loss = 1.2328832080398782, disc_loss = 0.0010741640488023236
Trained batch 138 in epoch 2, gen_loss = 1.2327498926533211, disc_loss = 0.0010707657114207316
Trained batch 139 in epoch 2, gen_loss = 1.2316421031951905, disc_loss = 0.0010671224112489394
Trained batch 140 in epoch 2, gen_loss = 1.231478807773996, disc_loss = 0.001064404128168888
Trained batch 141 in epoch 2, gen_loss = 1.2307042026183974, disc_loss = 0.0010634108408006616
Trained batch 142 in epoch 2, gen_loss = 1.2302976880040202, disc_loss = 0.0010594254395423026
Trained batch 143 in epoch 2, gen_loss = 1.2293367245131068, disc_loss = 0.0010586394330150345
Trained batch 144 in epoch 2, gen_loss = 1.229414463043213, disc_loss = 0.0010553306285773628
Trained batch 145 in epoch 2, gen_loss = 1.2299519801793033, disc_loss = 0.0010520225228926755
Trained batch 146 in epoch 2, gen_loss = 1.2296720459347679, disc_loss = 0.0010515382488853722
Trained batch 147 in epoch 2, gen_loss = 1.2299880578711226, disc_loss = 0.0010508679732919445
Trained batch 148 in epoch 2, gen_loss = 1.229062115586044, disc_loss = 0.0010499559384270652
Trained batch 149 in epoch 2, gen_loss = 1.2305822149912515, disc_loss = 0.0010501693930321683
Trained batch 150 in epoch 2, gen_loss = 1.2317998006643838, disc_loss = 0.0010522232643044892
Trained batch 151 in epoch 2, gen_loss = 1.2307911491707753, disc_loss = 0.0010501313384003496
Trained batch 152 in epoch 2, gen_loss = 1.2311375585256839, disc_loss = 0.0010469216454676749
Trained batch 153 in epoch 2, gen_loss = 1.2302710561009196, disc_loss = 0.0010453900979989052
Trained batch 154 in epoch 2, gen_loss = 1.2296891158626926, disc_loss = 0.001042573407833134
Trained batch 155 in epoch 2, gen_loss = 1.2290258392309532, disc_loss = 0.0010392343855271928
Trained batch 156 in epoch 2, gen_loss = 1.2282587616306961, disc_loss = 0.0010412318534128795
Trained batch 157 in epoch 2, gen_loss = 1.229228307174731, disc_loss = 0.0010438133082706245
Trained batch 158 in epoch 2, gen_loss = 1.2297379775617108, disc_loss = 0.0010409070121756984
Trained batch 159 in epoch 2, gen_loss = 1.2287152990698815, disc_loss = 0.0010396030083938967
Trained batch 160 in epoch 2, gen_loss = 1.227927187214727, disc_loss = 0.0010387828867876705
Trained batch 161 in epoch 2, gen_loss = 1.2280230360266604, disc_loss = 0.00103665163767823
Trained batch 162 in epoch 2, gen_loss = 1.226963334288334, disc_loss = 0.0010371077959311474
Trained batch 163 in epoch 2, gen_loss = 1.2276768640774052, disc_loss = 0.0010346401459395476
Trained batch 164 in epoch 2, gen_loss = 1.2269334547447435, disc_loss = 0.0010391028848420263
Trained batch 165 in epoch 2, gen_loss = 1.2272621048502175, disc_loss = 0.0010426576436547764
Trained batch 166 in epoch 2, gen_loss = 1.2266667188998468, disc_loss = 0.001040359018970013
Trained batch 167 in epoch 2, gen_loss = 1.2262124177955447, disc_loss = 0.00103745762836687
Trained batch 168 in epoch 2, gen_loss = 1.2282228886023077, disc_loss = 0.0010346870076534001
Trained batch 169 in epoch 2, gen_loss = 1.2277390409918392, disc_loss = 0.0010326914455029456
Trained batch 170 in epoch 2, gen_loss = 1.227860587382177, disc_loss = 0.0010323331640946151
Trained batch 171 in epoch 2, gen_loss = 1.2271030365034592, disc_loss = 0.0010323234045943029
Trained batch 172 in epoch 2, gen_loss = 1.2263063281946789, disc_loss = 0.0010300533310375634
Trained batch 173 in epoch 2, gen_loss = 1.2253912139212948, disc_loss = 0.0010262444535412173
Trained batch 174 in epoch 2, gen_loss = 1.225677033833095, disc_loss = 0.001032885147557993
Trained batch 175 in epoch 2, gen_loss = 1.22739846191623, disc_loss = 0.0010378463274801934
Trained batch 176 in epoch 2, gen_loss = 1.2272577083716958, disc_loss = 0.0010382227619681087
Trained batch 177 in epoch 2, gen_loss = 1.2268470592713088, disc_loss = 0.0010457432142451008
Trained batch 178 in epoch 2, gen_loss = 1.226548063688438, disc_loss = 0.0010436723392792358
Trained batch 179 in epoch 2, gen_loss = 1.2257205122047001, disc_loss = 0.0010418379124732585
Trained batch 180 in epoch 2, gen_loss = 1.226206987602276, disc_loss = 0.00104260562680461
Trained batch 181 in epoch 2, gen_loss = 1.226649026949327, disc_loss = 0.001042052860541914
Trained batch 182 in epoch 2, gen_loss = 1.2265312026758663, disc_loss = 0.0010420774897532486
Trained batch 183 in epoch 2, gen_loss = 1.2257873992557111, disc_loss = 0.0010393194197208884
Trained batch 184 in epoch 2, gen_loss = 1.2257460755270881, disc_loss = 0.0010380422603653594
Trained batch 185 in epoch 2, gen_loss = 1.225646464414494, disc_loss = 0.001038675769313579
Trained batch 186 in epoch 2, gen_loss = 1.2268335965865436, disc_loss = 0.0010362396825710062
Trained batch 187 in epoch 2, gen_loss = 1.225892575497323, disc_loss = 0.001033418952887432
Trained batch 188 in epoch 2, gen_loss = 1.2256897517613001, disc_loss = 0.0010329414189549251
Trained batch 189 in epoch 2, gen_loss = 1.2268242453273974, disc_loss = 0.0010297500896022508
Trained batch 190 in epoch 2, gen_loss = 1.2275682918688389, disc_loss = 0.0010270565478204315
Trained batch 191 in epoch 2, gen_loss = 1.2271000891923904, disc_loss = 0.0010243306145033178
Trained batch 192 in epoch 2, gen_loss = 1.226621628425282, disc_loss = 0.0010220033727065115
Trained batch 193 in epoch 2, gen_loss = 1.228881215926298, disc_loss = 0.001019453371517341
Trained batch 194 in epoch 2, gen_loss = 1.2286132953105828, disc_loss = 0.0010185078762543316
Trained batch 195 in epoch 2, gen_loss = 1.2283136011386404, disc_loss = 0.0010168389280621267
Trained batch 196 in epoch 2, gen_loss = 1.2275643832792484, disc_loss = 0.0010179009768393288
Trained batch 197 in epoch 2, gen_loss = 1.2268903183214592, disc_loss = 0.0010166668884028125
Trained batch 198 in epoch 2, gen_loss = 1.2265687102648481, disc_loss = 0.001014215192797327
Trained batch 199 in epoch 2, gen_loss = 1.2271401727199553, disc_loss = 0.0010140760909416713
Trained batch 200 in epoch 2, gen_loss = 1.2268906351345688, disc_loss = 0.0010133196098211022
Trained batch 201 in epoch 2, gen_loss = 1.2266777346629907, disc_loss = 0.0010111247163985184
Trained batch 202 in epoch 2, gen_loss = 1.2273864329154855, disc_loss = 0.0010109610736296682
Trained batch 203 in epoch 2, gen_loss = 1.2277974486351013, disc_loss = 0.0010136275052312104
Trained batch 204 in epoch 2, gen_loss = 1.227356653678708, disc_loss = 0.0010160315191236938
Trained batch 205 in epoch 2, gen_loss = 1.2260590490785617, disc_loss = 0.001014534055675805
Trained batch 206 in epoch 2, gen_loss = 1.2262468994527622, disc_loss = 0.0010135432079339912
Trained batch 207 in epoch 2, gen_loss = 1.225926435337617, disc_loss = 0.0010114328831080527
Trained batch 208 in epoch 2, gen_loss = 1.2274406948728425, disc_loss = 0.0010098188234889728
Trained batch 209 in epoch 2, gen_loss = 1.2273089119366236, disc_loss = 0.0010084856742261243
Trained batch 210 in epoch 2, gen_loss = 1.2279144553776602, disc_loss = 0.0010078893386829485
Trained batch 211 in epoch 2, gen_loss = 1.2275960029296156, disc_loss = 0.0010071662089892856
Trained batch 212 in epoch 2, gen_loss = 1.226843168478057, disc_loss = 0.0010054599903108544
Trained batch 213 in epoch 2, gen_loss = 1.2260776557654978, disc_loss = 0.0010044742911449137
Trained batch 214 in epoch 2, gen_loss = 1.2261782596277637, disc_loss = 0.0010013393448600762
Trained batch 215 in epoch 2, gen_loss = 1.225917868592121, disc_loss = 0.0010001606273430366
Trained batch 216 in epoch 2, gen_loss = 1.2256887568856165, disc_loss = 0.0009988214442944196
Trained batch 217 in epoch 2, gen_loss = 1.2266102788645192, disc_loss = 0.0009998100993454182
Trained batch 218 in epoch 2, gen_loss = 1.2259543486381774, disc_loss = 0.00100045348304966
Trained batch 219 in epoch 2, gen_loss = 1.2256218487566168, disc_loss = 0.0010008054219228638
Trained batch 220 in epoch 2, gen_loss = 1.2262494515509628, disc_loss = 0.0010010243822268434
Trained batch 221 in epoch 2, gen_loss = 1.226206531932762, disc_loss = 0.0010021746914775052
Trained batch 222 in epoch 2, gen_loss = 1.2268516851647553, disc_loss = 0.0010021048897643462
Trained batch 223 in epoch 2, gen_loss = 1.2258561695260661, disc_loss = 0.0010272830711203693
Trained batch 224 in epoch 2, gen_loss = 1.2254838842815823, disc_loss = 0.0010474132430843182
Trained batch 225 in epoch 2, gen_loss = 1.22746488320089, disc_loss = 0.0010499574596359008
Trained batch 226 in epoch 2, gen_loss = 1.22740434234888, disc_loss = 0.0010517315512383562
Trained batch 227 in epoch 2, gen_loss = 1.2271610142891867, disc_loss = 0.0010504586210580576
Trained batch 228 in epoch 2, gen_loss = 1.226604387749751, disc_loss = 0.0010488186622298766
Trained batch 229 in epoch 2, gen_loss = 1.225821968783503, disc_loss = 0.0010529690204471674
Trained batch 230 in epoch 2, gen_loss = 1.2254348575294791, disc_loss = 0.0010583544935168319
Trained batch 231 in epoch 2, gen_loss = 1.2257008007888137, disc_loss = 0.0010601607194483473
Trained batch 232 in epoch 2, gen_loss = 1.2261675355772093, disc_loss = 0.0010635849571079335
Trained batch 233 in epoch 2, gen_loss = 1.2257804982682579, disc_loss = 0.0010688954871744872
Trained batch 234 in epoch 2, gen_loss = 1.2250881073322701, disc_loss = 0.0010688855179010871
Trained batch 235 in epoch 2, gen_loss = 1.2247774833339755, disc_loss = 0.0010682368585425508
Trained batch 236 in epoch 2, gen_loss = 1.2254164691715803, disc_loss = 0.001067601861717093
Trained batch 237 in epoch 2, gen_loss = 1.2245689345007182, disc_loss = 0.0010670380734842458
Trained batch 238 in epoch 2, gen_loss = 1.2243251032410307, disc_loss = 0.001065148365300024
Trained batch 239 in epoch 2, gen_loss = 1.2258240814010302, disc_loss = 0.0010640535767985663
Trained batch 240 in epoch 2, gen_loss = 1.2251978667445202, disc_loss = 0.001062253430916607
Trained batch 241 in epoch 2, gen_loss = 1.2261061417169807, disc_loss = 0.001060909803038894
Trained batch 242 in epoch 2, gen_loss = 1.225502407109296, disc_loss = 0.0010608413336710399
Trained batch 243 in epoch 2, gen_loss = 1.225417876341304, disc_loss = 0.001061251027019099
Trained batch 244 in epoch 2, gen_loss = 1.2257003623612073, disc_loss = 0.0010595293808253292
Trained batch 245 in epoch 2, gen_loss = 1.2257293360989268, disc_loss = 0.0010575274700238332
Trained batch 246 in epoch 2, gen_loss = 1.2249745801392837, disc_loss = 0.0010558023953599184
Trained batch 247 in epoch 2, gen_loss = 1.2253806129578622, disc_loss = 0.00105394929696265
Trained batch 248 in epoch 2, gen_loss = 1.2252685578472644, disc_loss = 0.0010516965333054434
Trained batch 249 in epoch 2, gen_loss = 1.224590952396393, disc_loss = 0.0010512237711809576
Trained batch 250 in epoch 2, gen_loss = 1.2242102580241474, disc_loss = 0.001051053967404799
Trained batch 251 in epoch 2, gen_loss = 1.2236564457416534, disc_loss = 0.0010507864977366158
Trained batch 252 in epoch 2, gen_loss = 1.2242058440159431, disc_loss = 0.0010519772597768974
Trained batch 253 in epoch 2, gen_loss = 1.2239251052300761, disc_loss = 0.0010499659181832828
Trained batch 254 in epoch 2, gen_loss = 1.2241290859147613, disc_loss = 0.0010485278940120457
Trained batch 255 in epoch 2, gen_loss = 1.223383757751435, disc_loss = 0.0010470197585163987
Trained batch 256 in epoch 2, gen_loss = 1.222685978570337, disc_loss = 0.001044877608223358
Trained batch 257 in epoch 2, gen_loss = 1.2217951172082, disc_loss = 0.0010432463505687987
Trained batch 258 in epoch 2, gen_loss = 1.2221719624913336, disc_loss = 0.0010411619041546547
Trained batch 259 in epoch 2, gen_loss = 1.2221273894493396, disc_loss = 0.0010394074591414
Trained batch 260 in epoch 2, gen_loss = 1.2217854549144875, disc_loss = 0.0010412649239923705
Trained batch 261 in epoch 2, gen_loss = 1.221627185362896, disc_loss = 0.0010428638419648277
Trained batch 262 in epoch 2, gen_loss = 1.2215697334746445, disc_loss = 0.0010425870153192474
Trained batch 263 in epoch 2, gen_loss = 1.2209477027257283, disc_loss = 0.0010425025126702774
Trained batch 264 in epoch 2, gen_loss = 1.2204112718690117, disc_loss = 0.0010431898171345722
Trained batch 265 in epoch 2, gen_loss = 1.2197057430009197, disc_loss = 0.0010427443165755726
Trained batch 266 in epoch 2, gen_loss = 1.21921009115512, disc_loss = 0.0010408247094636275
Trained batch 267 in epoch 2, gen_loss = 1.2186321384871184, disc_loss = 0.001039355220064632
Trained batch 268 in epoch 2, gen_loss = 1.2181097796415308, disc_loss = 0.001038313917746442
Trained batch 269 in epoch 2, gen_loss = 1.2179642615494906, disc_loss = 0.0010376656440914504
Trained batch 270 in epoch 2, gen_loss = 1.2177344556224303, disc_loss = 0.0010361127261969353
Trained batch 271 in epoch 2, gen_loss = 1.2175093100351446, disc_loss = 0.0010352156538882649
Trained batch 272 in epoch 2, gen_loss = 1.217248484328553, disc_loss = 0.0010331200110391737
Trained batch 273 in epoch 2, gen_loss = 1.2172688780909908, disc_loss = 0.001033476453799632
Trained batch 274 in epoch 2, gen_loss = 1.216960997581482, disc_loss = 0.0010349584212103352
Trained batch 275 in epoch 2, gen_loss = 1.216310418602349, disc_loss = 0.0010393250978676656
Trained batch 276 in epoch 2, gen_loss = 1.2161601205164776, disc_loss = 0.0010490159637341781
Trained batch 277 in epoch 2, gen_loss = 1.2167198902411427, disc_loss = 0.0010604445854781477
Trained batch 278 in epoch 2, gen_loss = 1.2164171113762805, disc_loss = 0.0010660177450977587
Trained batch 279 in epoch 2, gen_loss = 1.216987595813615, disc_loss = 0.001064945122301911
Trained batch 280 in epoch 2, gen_loss = 1.216979025945969, disc_loss = 0.0010648557679724358
Trained batch 281 in epoch 2, gen_loss = 1.217230924477814, disc_loss = 0.0010698238696906293
Trained batch 282 in epoch 2, gen_loss = 1.2167183417734746, disc_loss = 0.001074150272327485
Trained batch 283 in epoch 2, gen_loss = 1.2171384196885875, disc_loss = 0.001074621336031246
Trained batch 284 in epoch 2, gen_loss = 1.2168832473587572, disc_loss = 0.0010739075301803257
Trained batch 285 in epoch 2, gen_loss = 1.2173334614380256, disc_loss = 0.0010730390802475174
Trained batch 286 in epoch 2, gen_loss = 1.2173557505790364, disc_loss = 0.0010719942387342712
Trained batch 287 in epoch 2, gen_loss = 1.2168284327619605, disc_loss = 0.0010699094772361503
Trained batch 288 in epoch 2, gen_loss = 1.2170223071913406, disc_loss = 0.0010684278624850908
Trained batch 289 in epoch 2, gen_loss = 1.2175490687633383, disc_loss = 0.0010666521814057667
Trained batch 290 in epoch 2, gen_loss = 1.217666643591681, disc_loss = 0.0010661537500171957
Trained batch 291 in epoch 2, gen_loss = 1.218487614638185, disc_loss = 0.001065738614184514
Trained batch 292 in epoch 2, gen_loss = 1.2183561691245122, disc_loss = 0.0010674608104112129
Trained batch 293 in epoch 2, gen_loss = 1.2179826307458943, disc_loss = 0.0010665394205419461
Trained batch 294 in epoch 2, gen_loss = 1.2184494030677666, disc_loss = 0.001064831920370649
Trained batch 295 in epoch 2, gen_loss = 1.218205797108444, disc_loss = 0.0010638681865325576
Trained batch 296 in epoch 2, gen_loss = 1.218511011865404, disc_loss = 0.0010636862834228786
Trained batch 297 in epoch 2, gen_loss = 1.217725779786206, disc_loss = 0.0010649934768498619
Trained batch 298 in epoch 2, gen_loss = 1.2179199313639, disc_loss = 0.0010695867285204048
Trained batch 299 in epoch 2, gen_loss = 1.2171553488572437, disc_loss = 0.0010745242049839969
Trained batch 300 in epoch 2, gen_loss = 1.2168890332858824, disc_loss = 0.001074328237140483
Trained batch 301 in epoch 2, gen_loss = 1.2165283442333044, disc_loss = 0.0010743140964229153
Trained batch 302 in epoch 2, gen_loss = 1.2161446266835279, disc_loss = 0.0010741864737943922
Trained batch 303 in epoch 2, gen_loss = 1.2163278150715326, disc_loss = 0.0010757703794776095
Trained batch 304 in epoch 2, gen_loss = 1.2166641723914224, disc_loss = 0.001077229607674736
Trained batch 305 in epoch 2, gen_loss = 1.2163008478731892, disc_loss = 0.001078994295847438
Trained batch 306 in epoch 2, gen_loss = 1.2160182142878977, disc_loss = 0.0010777848388951162
Trained batch 307 in epoch 2, gen_loss = 1.2158415874877533, disc_loss = 0.0010763205492992994
Trained batch 308 in epoch 2, gen_loss = 1.2152509129934712, disc_loss = 0.0010744424574122338
Trained batch 309 in epoch 2, gen_loss = 1.216057542447121, disc_loss = 0.0010732189299643882
Trained batch 310 in epoch 2, gen_loss = 1.2153411565102947, disc_loss = 0.0010713250831089962
Trained batch 311 in epoch 2, gen_loss = 1.2154295545740006, disc_loss = 0.001069099919382447
Trained batch 312 in epoch 2, gen_loss = 1.2153197726883447, disc_loss = 0.0010709424022237023
Trained batch 313 in epoch 2, gen_loss = 1.2155252226219055, disc_loss = 0.001070384890846552
Trained batch 314 in epoch 2, gen_loss = 1.2154566433694627, disc_loss = 0.0010699564227021285
Trained batch 315 in epoch 2, gen_loss = 1.215880212338665, disc_loss = 0.001070428107123928
Trained batch 316 in epoch 2, gen_loss = 1.2165325765354025, disc_loss = 0.001071523056234812
Trained batch 317 in epoch 2, gen_loss = 1.2166928129750978, disc_loss = 0.00107285905495409
Trained batch 318 in epoch 2, gen_loss = 1.217572773698729, disc_loss = 0.0010717983438259685
Trained batch 319 in epoch 2, gen_loss = 1.2172786572948098, disc_loss = 0.0010709338437663973
Trained batch 320 in epoch 2, gen_loss = 1.2171736994636393, disc_loss = 0.0010724549627474094
Trained batch 321 in epoch 2, gen_loss = 1.2183853045383595, disc_loss = 0.0010747583020805317
Trained batch 322 in epoch 2, gen_loss = 1.2180160928067778, disc_loss = 0.001077340650711001
Trained batch 323 in epoch 2, gen_loss = 1.2177137307546757, disc_loss = 0.0010771632475137457
Trained batch 324 in epoch 2, gen_loss = 1.2176818515704229, disc_loss = 0.0010757825079445655
Trained batch 325 in epoch 2, gen_loss = 1.217439646187004, disc_loss = 0.0010756155939492756
Trained batch 326 in epoch 2, gen_loss = 1.2184217185784554, disc_loss = 0.0010745654743099273
Trained batch 327 in epoch 2, gen_loss = 1.2180896515889865, disc_loss = 0.0010737890291394007
Trained batch 328 in epoch 2, gen_loss = 1.2176519750099415, disc_loss = 0.001073663041036644
Trained batch 329 in epoch 2, gen_loss = 1.2180824014273557, disc_loss = 0.0010748878532357402
Trained batch 330 in epoch 2, gen_loss = 1.2181808136381052, disc_loss = 0.0010761380291633938
Trained batch 331 in epoch 2, gen_loss = 1.218728333532092, disc_loss = 0.0010754936984852404
Trained batch 332 in epoch 2, gen_loss = 1.2183948008863776, disc_loss = 0.001074235919022558
Trained batch 333 in epoch 2, gen_loss = 1.218814465992465, disc_loss = 0.0010733972643404463
Trained batch 334 in epoch 2, gen_loss = 1.2181010393954035, disc_loss = 0.0010722542998255855
Trained batch 335 in epoch 2, gen_loss = 1.217577858872357, disc_loss = 0.0010723453520941327
Trained batch 336 in epoch 2, gen_loss = 1.2173825589061138, disc_loss = 0.0010718746557804128
Trained batch 337 in epoch 2, gen_loss = 1.2167592981510613, disc_loss = 0.0010701327093190806
Trained batch 338 in epoch 2, gen_loss = 1.217762650465895, disc_loss = 0.001068840254576201
Trained batch 339 in epoch 2, gen_loss = 1.2181897992596906, disc_loss = 0.0010697939960450371
Trained batch 340 in epoch 2, gen_loss = 1.2177572056345227, disc_loss = 0.001070852455945243
Trained batch 341 in epoch 2, gen_loss = 1.2175813434068223, disc_loss = 0.0010699610740194172
Trained batch 342 in epoch 2, gen_loss = 1.2174429088917835, disc_loss = 0.0010705228388219875
Trained batch 343 in epoch 2, gen_loss = 1.2171779113800028, disc_loss = 0.0010703986029744386
Trained batch 344 in epoch 2, gen_loss = 1.2172127037808516, disc_loss = 0.0010688359537026912
Trained batch 345 in epoch 2, gen_loss = 1.2166364101660734, disc_loss = 0.001067387976924582
Trained batch 346 in epoch 2, gen_loss = 1.2161401305830788, disc_loss = 0.0010664670264163196
Trained batch 347 in epoch 2, gen_loss = 1.2170907654638947, disc_loss = 0.0010652886136587516
Trained batch 348 in epoch 2, gen_loss = 1.2170307583317033, disc_loss = 0.001064145246908912
Trained batch 349 in epoch 2, gen_loss = 1.2167124034677232, disc_loss = 0.001063696799101308
Trained batch 350 in epoch 2, gen_loss = 1.2161876002268235, disc_loss = 0.0010782665587322218
Trained batch 351 in epoch 2, gen_loss = 1.2162841214713724, disc_loss = 0.0010896956940665734
Trained batch 352 in epoch 2, gen_loss = 1.2159271809264554, disc_loss = 0.0010951528787050955
Trained batch 353 in epoch 2, gen_loss = 1.2157069197145558, disc_loss = 0.001095887213862517
Trained batch 354 in epoch 2, gen_loss = 1.2162748590321608, disc_loss = 0.0010988011793889316
Trained batch 355 in epoch 2, gen_loss = 1.2173468776968088, disc_loss = 0.0010997216386283654
Trained batch 356 in epoch 2, gen_loss = 1.2170782147669326, disc_loss = 0.0011022721049741056
Trained batch 357 in epoch 2, gen_loss = 1.2175112201847844, disc_loss = 0.001115630869395958
Trained batch 358 in epoch 2, gen_loss = 1.2182148623599316, disc_loss = 0.001128281787858918
Trained batch 359 in epoch 2, gen_loss = 1.2183643852670987, disc_loss = 0.0011370788025993129
Trained batch 360 in epoch 2, gen_loss = 1.2184576587003353, disc_loss = 0.0011373477134340214
Trained batch 361 in epoch 2, gen_loss = 1.218107339591611, disc_loss = 0.001140701045051927
Trained batch 362 in epoch 2, gen_loss = 1.21829135112526, disc_loss = 0.0011568762878015042
Trained batch 363 in epoch 2, gen_loss = 1.2177955437820036, disc_loss = 0.0011687766177551615
Trained batch 364 in epoch 2, gen_loss = 1.2175409828146844, disc_loss = 0.0011709441413324684
Trained batch 365 in epoch 2, gen_loss = 1.217302921202665, disc_loss = 0.0011730952618727614
Trained batch 366 in epoch 2, gen_loss = 1.2171218478062498, disc_loss = 0.0011728181535751135
Trained batch 367 in epoch 2, gen_loss = 1.2165889718934246, disc_loss = 0.00117717430317577
Trained batch 368 in epoch 2, gen_loss = 1.2158284208315822, disc_loss = 0.001180398931788649
Trained batch 369 in epoch 2, gen_loss = 1.2154433303588146, disc_loss = 0.0011793192446143744
Trained batch 370 in epoch 2, gen_loss = 1.2153048124917434, disc_loss = 0.0011794673577967699
Trained batch 371 in epoch 2, gen_loss = 1.2149580385415786, disc_loss = 0.0011784093752090308
Trained batch 372 in epoch 2, gen_loss = 1.214880058177355, disc_loss = 0.001177244267118071
Trained batch 373 in epoch 2, gen_loss = 1.2151545686199066, disc_loss = 0.0011765100777816565
Trained batch 374 in epoch 2, gen_loss = 1.215252604643504, disc_loss = 0.0011770736273999016
Trained batch 375 in epoch 2, gen_loss = 1.2150893628280213, disc_loss = 0.0011768728148494351
Trained batch 376 in epoch 2, gen_loss = 1.2154529969002903, disc_loss = 0.001175064220993634
Trained batch 377 in epoch 2, gen_loss = 1.2157178756105838, disc_loss = 0.0011739800855081293
Trained batch 378 in epoch 2, gen_loss = 1.2153404587806058, disc_loss = 0.001173543255244158
Trained batch 379 in epoch 2, gen_loss = 1.2152317720024208, disc_loss = 0.001172013734743048
Trained batch 380 in epoch 2, gen_loss = 1.215163581483946, disc_loss = 0.0011702615328027996
Trained batch 381 in epoch 2, gen_loss = 1.215037390979797, disc_loss = 0.0011685018457230961
Trained batch 382 in epoch 2, gen_loss = 1.214712186052656, disc_loss = 0.0011665687213777067
Trained batch 383 in epoch 2, gen_loss = 1.2145454466032486, disc_loss = 0.001165596467293047
Trained batch 384 in epoch 2, gen_loss = 1.2146729826927185, disc_loss = 0.0011639372670158212
Trained batch 385 in epoch 2, gen_loss = 1.214754714094913, disc_loss = 0.0011623322354042131
Trained batch 386 in epoch 2, gen_loss = 1.2151417203959876, disc_loss = 0.0011619458941999072
Trained batch 387 in epoch 2, gen_loss = 1.2153034694108766, disc_loss = 0.0011613530288516428
Trained batch 388 in epoch 2, gen_loss = 1.2151365621843804, disc_loss = 0.001160447602235092
Trained batch 389 in epoch 2, gen_loss = 1.2146563592629556, disc_loss = 0.0011599522975768942
Trained batch 390 in epoch 2, gen_loss = 1.214376918037834, disc_loss = 0.0011586506381038996
Trained batch 391 in epoch 2, gen_loss = 1.2142132117736095, disc_loss = 0.0011572494978300172
Trained batch 392 in epoch 2, gen_loss = 1.214490304618088, disc_loss = 0.0011564136765519295
Trained batch 393 in epoch 2, gen_loss = 1.2147834907630979, disc_loss = 0.0011565792203678746
Trained batch 394 in epoch 2, gen_loss = 1.2144230656985995, disc_loss = 0.0011548608814843612
Trained batch 395 in epoch 2, gen_loss = 1.2151122684731628, disc_loss = 0.0011547922554062538
Trained batch 396 in epoch 2, gen_loss = 1.2145675641463445, disc_loss = 0.0011565528515467107
Trained batch 397 in epoch 2, gen_loss = 1.2142772379532532, disc_loss = 0.001156895047848712
Trained batch 398 in epoch 2, gen_loss = 1.213650117093758, disc_loss = 0.0011567261984267209
Trained batch 399 in epoch 2, gen_loss = 1.2137778721749783, disc_loss = 0.0011569599681388353
Trained batch 400 in epoch 2, gen_loss = 1.2142371538274008, disc_loss = 0.001163473663061388
Trained batch 401 in epoch 2, gen_loss = 1.2140037475237206, disc_loss = 0.001179567809475572
Trained batch 402 in epoch 2, gen_loss = 1.213495290752676, disc_loss = 0.0011930767987379874
Trained batch 403 in epoch 2, gen_loss = 1.2131027970278616, disc_loss = 0.001194727599795442
Trained batch 404 in epoch 2, gen_loss = 1.2125465597635434, disc_loss = 0.0011949820095460493
Trained batch 405 in epoch 2, gen_loss = 1.212177157548848, disc_loss = 0.0011976781180627377
Trained batch 406 in epoch 2, gen_loss = 1.2115947347894054, disc_loss = 0.0011997685817908953
Trained batch 407 in epoch 2, gen_loss = 1.211575587882715, disc_loss = 0.0011983548952854356
Trained batch 408 in epoch 2, gen_loss = 1.2112201947746184, disc_loss = 0.001197652644571714
Trained batch 409 in epoch 2, gen_loss = 1.210968242331249, disc_loss = 0.0011974126822457127
Trained batch 410 in epoch 2, gen_loss = 1.2111308992344096, disc_loss = 0.0011961259044295544
Trained batch 411 in epoch 2, gen_loss = 1.2113713570011473, disc_loss = 0.0011945250478727987
Trained batch 412 in epoch 2, gen_loss = 1.21159076834995, disc_loss = 0.0011928979396627264
Trained batch 413 in epoch 2, gen_loss = 1.21139390255518, disc_loss = 0.0011911786892192645
Trained batch 414 in epoch 2, gen_loss = 1.21108882743192, disc_loss = 0.001189140769784866
Trained batch 415 in epoch 2, gen_loss = 1.2107875948915114, disc_loss = 0.001186951009353484
Trained batch 416 in epoch 2, gen_loss = 1.2106060075531189, disc_loss = 0.0011852904657997433
Trained batch 417 in epoch 2, gen_loss = 1.2103158979895012, disc_loss = 0.0011834252837925044
Trained batch 418 in epoch 2, gen_loss = 1.209899960383595, disc_loss = 0.0011816393483434593
Trained batch 419 in epoch 2, gen_loss = 1.210036021187192, disc_loss = 0.0011800999342951746
Trained batch 420 in epoch 2, gen_loss = 1.2101655057377034, disc_loss = 0.0011783898904844411
Trained batch 421 in epoch 2, gen_loss = 1.210824675469602, disc_loss = 0.0011767611195558408
Trained batch 422 in epoch 2, gen_loss = 1.2116169726594965, disc_loss = 0.0011750448953517741
Trained batch 423 in epoch 2, gen_loss = 1.212295360441478, disc_loss = 0.0011734324490255018
Trained batch 424 in epoch 2, gen_loss = 1.2123202124763937, disc_loss = 0.0011717623424278025
Trained batch 425 in epoch 2, gen_loss = 1.212060633119843, disc_loss = 0.0011713955803619076
Trained batch 426 in epoch 2, gen_loss = 1.2118755860965202, disc_loss = 0.001170328333106904
Trained batch 427 in epoch 2, gen_loss = 1.2119906656095916, disc_loss = 0.0011696827889770426
Trained batch 428 in epoch 2, gen_loss = 1.2116154907466647, disc_loss = 0.0011686766777938722
Trained batch 429 in epoch 2, gen_loss = 1.2114535969357159, disc_loss = 0.0011681009289743595
Trained batch 430 in epoch 2, gen_loss = 1.2121057493780716, disc_loss = 0.0011669415769895448
Trained batch 431 in epoch 2, gen_loss = 1.211955361896091, disc_loss = 0.0011658979926357494
Trained batch 432 in epoch 2, gen_loss = 1.2119243065149075, disc_loss = 0.0011648393692351947
Trained batch 433 in epoch 2, gen_loss = 1.2114714845534293, disc_loss = 0.0011643163586509617
Trained batch 434 in epoch 2, gen_loss = 1.2117957986634353, disc_loss = 0.0011654669570137115
Trained batch 435 in epoch 2, gen_loss = 1.212154754258077, disc_loss = 0.0011656657337913837
Trained batch 436 in epoch 2, gen_loss = 1.212423172368065, disc_loss = 0.0011648470003081132
Trained batch 437 in epoch 2, gen_loss = 1.2126986689219192, disc_loss = 0.0011632094201849792
Trained batch 438 in epoch 2, gen_loss = 1.2127672938931233, disc_loss = 0.0011628108711808215
Trained batch 439 in epoch 2, gen_loss = 1.2137100742621856, disc_loss = 0.0011664662664274642
Trained batch 440 in epoch 2, gen_loss = 1.213758963035618, disc_loss = 0.0011709471373230666
Trained batch 441 in epoch 2, gen_loss = 1.2137245382119088, disc_loss = 0.0011706434352122188
Trained batch 442 in epoch 2, gen_loss = 1.213792733091264, disc_loss = 0.0011698464013801143
Trained batch 443 in epoch 2, gen_loss = 1.2134676325965572, disc_loss = 0.0011686404301341296
Trained batch 444 in epoch 2, gen_loss = 1.213091736697079, disc_loss = 0.0011671340610345385
Trained batch 445 in epoch 2, gen_loss = 1.213199179536024, disc_loss = 0.0011666964984529196
Trained batch 446 in epoch 2, gen_loss = 1.2129621991108461, disc_loss = 0.0011657023606681258
Trained batch 447 in epoch 2, gen_loss = 1.2128290422260761, disc_loss = 0.0011640993540303107
Trained batch 448 in epoch 2, gen_loss = 1.212595189865554, disc_loss = 0.0011625057412389217
Trained batch 449 in epoch 2, gen_loss = 1.2124103122287326, disc_loss = 0.0011608215120051885
Trained batch 450 in epoch 2, gen_loss = 1.2122056161749388, disc_loss = 0.0011601900691403997
Trained batch 451 in epoch 2, gen_loss = 1.2123993318692772, disc_loss = 0.0011591761213556278
Trained batch 452 in epoch 2, gen_loss = 1.2123547989801067, disc_loss = 0.0011576815362722627
Trained batch 453 in epoch 2, gen_loss = 1.2120552966248097, disc_loss = 0.00115609096516014
Trained batch 454 in epoch 2, gen_loss = 1.2118921607405275, disc_loss = 0.0011546166261253818
Trained batch 455 in epoch 2, gen_loss = 1.211460493897137, disc_loss = 0.0011530647918749437
Trained batch 456 in epoch 2, gen_loss = 1.2118657386537715, disc_loss = 0.0011513881106133403
Trained batch 457 in epoch 2, gen_loss = 1.2116293037822674, disc_loss = 0.0011500765866392564
Trained batch 458 in epoch 2, gen_loss = 1.2113513824467046, disc_loss = 0.001148409281034542
Trained batch 459 in epoch 2, gen_loss = 1.21160557658776, disc_loss = 0.001146860834484434
Trained batch 460 in epoch 2, gen_loss = 1.2123705774481022, disc_loss = 0.0011459693417191473
Trained batch 461 in epoch 2, gen_loss = 1.212477295171647, disc_loss = 0.0011456746956256916
Trained batch 462 in epoch 2, gen_loss = 1.2125853307818748, disc_loss = 0.001144993170234928
Trained batch 463 in epoch 2, gen_loss = 1.2126245290554802, disc_loss = 0.001147053860316599
Trained batch 464 in epoch 2, gen_loss = 1.2128511098123367, disc_loss = 0.0011492076099559826
Trained batch 465 in epoch 2, gen_loss = 1.212996043360796, disc_loss = 0.001148783467917867
Trained batch 466 in epoch 2, gen_loss = 1.2124975744866202, disc_loss = 0.0011479788066219036
Trained batch 467 in epoch 2, gen_loss = 1.2132633479996624, disc_loss = 0.0011497057640266358
Trained batch 468 in epoch 2, gen_loss = 1.213582804843561, disc_loss = 0.0011525478112006952
Trained batch 469 in epoch 2, gen_loss = 1.213693307181622, disc_loss = 0.0011534572634697357
Trained batch 470 in epoch 2, gen_loss = 1.213702668936136, disc_loss = 0.0011539114128764631
Trained batch 471 in epoch 2, gen_loss = 1.2134858060438753, disc_loss = 0.0011545257075340487
Trained batch 472 in epoch 2, gen_loss = 1.2132945291335688, disc_loss = 0.0011549643438996601
Trained batch 473 in epoch 2, gen_loss = 1.2134056411966492, disc_loss = 0.0011574516854129088
Trained batch 474 in epoch 2, gen_loss = 1.2138212569136368, disc_loss = 0.0011589566099849578
Trained batch 475 in epoch 2, gen_loss = 1.2138133238093192, disc_loss = 0.0011607532648950768
Trained batch 476 in epoch 2, gen_loss = 1.2142048393155545, disc_loss = 0.0011614247368486594
Trained batch 477 in epoch 2, gen_loss = 1.2140708542019751, disc_loss = 0.0011658001140443896
Trained batch 478 in epoch 2, gen_loss = 1.2143484745991255, disc_loss = 0.0011757786009248758
Trained batch 479 in epoch 2, gen_loss = 1.2140163904676835, disc_loss = 0.0011815691249163743
Trained batch 480 in epoch 2, gen_loss = 1.2145347051214033, disc_loss = 0.0011823213664793532
Trained batch 481 in epoch 2, gen_loss = 1.2146738157974735, disc_loss = 0.0011820948441924443
Trained batch 482 in epoch 2, gen_loss = 1.2147953536199487, disc_loss = 0.001182588884451737
Trained batch 483 in epoch 2, gen_loss = 1.215063749389215, disc_loss = 0.001181626837933436
Trained batch 484 in epoch 2, gen_loss = 1.214757039497808, disc_loss = 0.001180662261802204
Trained batch 485 in epoch 2, gen_loss = 1.2150886982311437, disc_loss = 0.001181631785464845
Trained batch 486 in epoch 2, gen_loss = 1.2153059742289158, disc_loss = 0.0011817616600833941
Trained batch 487 in epoch 2, gen_loss = 1.2155242964136797, disc_loss = 0.0011808798029602765
Trained batch 488 in epoch 2, gen_loss = 1.2155995901620704, disc_loss = 0.0011800883113119013
Trained batch 489 in epoch 2, gen_loss = 1.2154257797465033, disc_loss = 0.0011791279668948251
Trained batch 490 in epoch 2, gen_loss = 1.2153161964445638, disc_loss = 0.00117753885232117
Trained batch 491 in epoch 2, gen_loss = 1.215079685415679, disc_loss = 0.0011759788104109617
Trained batch 492 in epoch 2, gen_loss = 1.2145994463992167, disc_loss = 0.0011749394780164678
Trained batch 493 in epoch 2, gen_loss = 1.2146658897399902, disc_loss = 0.0011738435340986817
Trained batch 494 in epoch 2, gen_loss = 1.2145282297423392, disc_loss = 0.0011720688592623731
Trained batch 495 in epoch 2, gen_loss = 1.2141667219900316, disc_loss = 0.0011708493794656298
Trained batch 496 in epoch 2, gen_loss = 1.213835968338028, disc_loss = 0.0011693318171255194
Trained batch 497 in epoch 2, gen_loss = 1.2138378567484966, disc_loss = 0.0011685539464663572
Trained batch 498 in epoch 2, gen_loss = 1.2135636008574155, disc_loss = 0.001167830535015166
Trained batch 499 in epoch 2, gen_loss = 1.2141455512046815, disc_loss = 0.0011668315780698321
Trained batch 500 in epoch 2, gen_loss = 1.2138200957856016, disc_loss = 0.001167290246552377
Trained batch 501 in epoch 2, gen_loss = 1.213819500222149, disc_loss = 0.001168988107699452
Trained batch 502 in epoch 2, gen_loss = 1.2137521322868454, disc_loss = 0.0011702526386093096
Trained batch 503 in epoch 2, gen_loss = 1.213636108807155, disc_loss = 0.0011702836938696684
Trained batch 504 in epoch 2, gen_loss = 1.2133822110619876, disc_loss = 0.001169934532418386
Trained batch 505 in epoch 2, gen_loss = 1.2129073018141887, disc_loss = 0.00116900008719593
Trained batch 506 in epoch 2, gen_loss = 1.2126414251515616, disc_loss = 0.0011680189764546873
Trained batch 507 in epoch 2, gen_loss = 1.2131966040359707, disc_loss = 0.0011665743984090435
Trained batch 508 in epoch 2, gen_loss = 1.2130510945217081, disc_loss = 0.0011651000000096397
Trained batch 509 in epoch 2, gen_loss = 1.2136336892258888, disc_loss = 0.0011639574688160792
Trained batch 510 in epoch 2, gen_loss = 1.213655251812795, disc_loss = 0.0011634120503836904
Trained batch 511 in epoch 2, gen_loss = 1.2135634836740792, disc_loss = 0.0011623612799098737
Trained batch 512 in epoch 2, gen_loss = 1.2133364863330625, disc_loss = 0.001161362785611349
Trained batch 513 in epoch 2, gen_loss = 1.2135403416036168, disc_loss = 0.001161038888659571
Trained batch 514 in epoch 2, gen_loss = 1.2131248210240337, disc_loss = 0.0011602542726481242
Trained batch 515 in epoch 2, gen_loss = 1.213058736897254, disc_loss = 0.0011594883467331565
Trained batch 516 in epoch 2, gen_loss = 1.2132950656879802, disc_loss = 0.0011592577995729724
Trained batch 517 in epoch 2, gen_loss = 1.2131732297219826, disc_loss = 0.001158412458214632
Trained batch 518 in epoch 2, gen_loss = 1.2130087359103163, disc_loss = 0.0011572236567444073
Trained batch 519 in epoch 2, gen_loss = 1.2126412286208226, disc_loss = 0.001156812608342779
Trained batch 520 in epoch 2, gen_loss = 1.2131651422570169, disc_loss = 0.0011561198335792511
Trained batch 521 in epoch 2, gen_loss = 1.2131351282770149, disc_loss = 0.001156419337697245
Trained batch 522 in epoch 2, gen_loss = 1.2128527966785614, disc_loss = 0.001157872241320281
Trained batch 523 in epoch 2, gen_loss = 1.2130876383708633, disc_loss = 0.0011575126926390675
Trained batch 524 in epoch 2, gen_loss = 1.2129789620354061, disc_loss = 0.0011563330261768507
Trained batch 525 in epoch 2, gen_loss = 1.2126546653957875, disc_loss = 0.0011552475819859066
Trained batch 526 in epoch 2, gen_loss = 1.2126660756413352, disc_loss = 0.0011536832940826577
Trained batch 527 in epoch 2, gen_loss = 1.2125210493351475, disc_loss = 0.0011524527715554348
Trained batch 528 in epoch 2, gen_loss = 1.2122087708493037, disc_loss = 0.0011519433316309886
Trained batch 529 in epoch 2, gen_loss = 1.2119966889327427, disc_loss = 0.001151607886620112
Trained batch 530 in epoch 2, gen_loss = 1.2116512668559332, disc_loss = 0.001150206663372195
Trained batch 531 in epoch 2, gen_loss = 1.2111273149126454, disc_loss = 0.0011502806984826474
Trained batch 532 in epoch 2, gen_loss = 1.210938491136898, disc_loss = 0.0011511590514387971
Trained batch 533 in epoch 2, gen_loss = 1.2106645943296983, disc_loss = 0.001150202966201004
Trained batch 534 in epoch 2, gen_loss = 1.2107997082104194, disc_loss = 0.0011496151230628734
Trained batch 535 in epoch 2, gen_loss = 1.2107795724895463, disc_loss = 0.0011500293138539488
Trained batch 536 in epoch 2, gen_loss = 1.2107770268699531, disc_loss = 0.001149962881551379
Trained batch 537 in epoch 2, gen_loss = 1.2104143485925454, disc_loss = 0.0011488958414458776
Trained batch 538 in epoch 2, gen_loss = 1.209985938165095, disc_loss = 0.0011496409048768648
Trained batch 539 in epoch 2, gen_loss = 1.209885240594546, disc_loss = 0.001153213005939809
Trained batch 540 in epoch 2, gen_loss = 1.2100087989280053, disc_loss = 0.0011555266426919225
Trained batch 541 in epoch 2, gen_loss = 1.2096782149643917, disc_loss = 0.0011555652328074405
Trained batch 542 in epoch 2, gen_loss = 1.209709207546206, disc_loss = 0.0011552345944769186
Trained batch 543 in epoch 2, gen_loss = 1.209690250127631, disc_loss = 0.0011555723796097001
Trained batch 544 in epoch 2, gen_loss = 1.2097010504215135, disc_loss = 0.0011549007151822705
Trained batch 545 in epoch 2, gen_loss = 1.2094370769712077, disc_loss = 0.0011540449993265281
Trained batch 546 in epoch 2, gen_loss = 1.2091359683538923, disc_loss = 0.0011536305574691723
Trained batch 547 in epoch 2, gen_loss = 1.2090305939425516, disc_loss = 0.0011530627534141846
Trained batch 548 in epoch 2, gen_loss = 1.2088068435969466, disc_loss = 0.0011518666752273106
Trained batch 549 in epoch 2, gen_loss = 1.2085772905566476, disc_loss = 0.0011514196049591356
Trained batch 550 in epoch 2, gen_loss = 1.2084929130687472, disc_loss = 0.0011506655630393599
Trained batch 551 in epoch 2, gen_loss = 1.2085156707444054, disc_loss = 0.0011494079727276255
Trained batch 552 in epoch 2, gen_loss = 1.2085167246097681, disc_loss = 0.0011487451741332103
Trained batch 553 in epoch 2, gen_loss = 1.2082790927120926, disc_loss = 0.001148405982667264
Trained batch 554 in epoch 2, gen_loss = 1.2080554282343066, disc_loss = 0.0011477506169965408
Trained batch 555 in epoch 2, gen_loss = 1.2080110597739118, disc_loss = 0.0011472971155140684
Trained batch 556 in epoch 2, gen_loss = 1.2084375130851992, disc_loss = 0.001147856777851575
Trained batch 557 in epoch 2, gen_loss = 1.208501768475365, disc_loss = 0.001147412939817481
Trained batch 558 in epoch 2, gen_loss = 1.2086126732911535, disc_loss = 0.001147167935108596
Trained batch 559 in epoch 2, gen_loss = 1.2082356613661562, disc_loss = 0.0011462440827537128
Trained batch 560 in epoch 2, gen_loss = 1.2086212891095887, disc_loss = 0.0011465768417992601
Trained batch 561 in epoch 2, gen_loss = 1.2084572269611087, disc_loss = 0.0011494390148001647
Trained batch 562 in epoch 2, gen_loss = 1.2084264912994886, disc_loss = 0.0011513512388250558
Trained batch 563 in epoch 2, gen_loss = 1.2083962510029476, disc_loss = 0.0011513578671019141
Trained batch 564 in epoch 2, gen_loss = 1.2083380991378716, disc_loss = 0.0011500951607888812
Trained batch 565 in epoch 2, gen_loss = 1.2082194655396492, disc_loss = 0.0011489531967822666
Trained batch 566 in epoch 2, gen_loss = 1.2079557158328869, disc_loss = 0.001148018028229439
Trained batch 567 in epoch 2, gen_loss = 1.2079714881912085, disc_loss = 0.0011494812979563763
Trained batch 568 in epoch 2, gen_loss = 1.2077297193304306, disc_loss = 0.0011506118821999081
Trained batch 569 in epoch 2, gen_loss = 1.207669442055518, disc_loss = 0.0011500420538492076
Trained batch 570 in epoch 2, gen_loss = 1.2073886595966519, disc_loss = 0.001149111158398409
Trained batch 571 in epoch 2, gen_loss = 1.2070992510843943, disc_loss = 0.0011478015780835608
Trained batch 572 in epoch 2, gen_loss = 1.2071196769752635, disc_loss = 0.001146536639269464
Trained batch 573 in epoch 2, gen_loss = 1.2076069219394843, disc_loss = 0.0011451347552678785
Trained batch 574 in epoch 2, gen_loss = 1.2076094076944435, disc_loss = 0.0011440251181003354
Trained batch 575 in epoch 2, gen_loss = 1.207734596915543, disc_loss = 0.001142607000575582
Trained batch 576 in epoch 2, gen_loss = 1.2078572713109814, disc_loss = 0.0011412651478123256
Trained batch 577 in epoch 2, gen_loss = 1.2082476505564983, disc_loss = 0.0011398427547008013
Trained batch 578 in epoch 2, gen_loss = 1.2080657713771483, disc_loss = 0.0011385045855166148
Trained batch 579 in epoch 2, gen_loss = 1.2077151357099927, disc_loss = 0.0011375408455055079
Trained batch 580 in epoch 2, gen_loss = 1.2074715429452119, disc_loss = 0.0011366170393415243
Trained batch 581 in epoch 2, gen_loss = 1.2076985154979418, disc_loss = 0.0011367206889783957
Trained batch 582 in epoch 2, gen_loss = 1.2075104454778276, disc_loss = 0.0011372463498104805
Trained batch 583 in epoch 2, gen_loss = 1.2071706727147102, disc_loss = 0.0011367258613399702
Trained batch 584 in epoch 2, gen_loss = 1.2071575169889337, disc_loss = 0.0011355947764813263
Trained batch 585 in epoch 2, gen_loss = 1.2070537440402516, disc_loss = 0.0011346049623884922
Trained batch 586 in epoch 2, gen_loss = 1.207109753784979, disc_loss = 0.0011339055737591582
Trained batch 587 in epoch 2, gen_loss = 1.2069651051646186, disc_loss = 0.0011337766699812876
Trained batch 588 in epoch 2, gen_loss = 1.2078140216084208, disc_loss = 0.0011336637582987268
Trained batch 589 in epoch 2, gen_loss = 1.2078820168972015, disc_loss = 0.0011325613279842724
Trained batch 590 in epoch 2, gen_loss = 1.2076358451254274, disc_loss = 0.0011317104738609086
Trained batch 591 in epoch 2, gen_loss = 1.2072539231865793, disc_loss = 0.0011319201115150685
Trained batch 592 in epoch 2, gen_loss = 1.2072640803169843, disc_loss = 0.0011333255707812425
Trained batch 593 in epoch 2, gen_loss = 1.2075271025450542, disc_loss = 0.0011357222532818992
Trained batch 594 in epoch 2, gen_loss = 1.2073703626624677, disc_loss = 0.0011373863193527365
Trained batch 595 in epoch 2, gen_loss = 1.2072050084403698, disc_loss = 0.0011375319256037848
Trained batch 596 in epoch 2, gen_loss = 1.2071751155445922, disc_loss = 0.0011366722817490599
Trained batch 597 in epoch 2, gen_loss = 1.206735908088078, disc_loss = 0.001136461134616871
Trained batch 598 in epoch 2, gen_loss = 1.2066087473015952, disc_loss = 0.0011362663807599294
Trained batch 599 in epoch 2, gen_loss = 1.206373493373394, disc_loss = 0.0011359475017525256
Trained batch 600 in epoch 2, gen_loss = 1.2064153784126688, disc_loss = 0.001135126104541185
Trained batch 601 in epoch 2, gen_loss = 1.2061610876325752, disc_loss = 0.0011353802714849578
Trained batch 602 in epoch 2, gen_loss = 1.2063239926524818, disc_loss = 0.0011362173931617568
Trained batch 603 in epoch 2, gen_loss = 1.2059758871004282, disc_loss = 0.0011369201739392682
Trained batch 604 in epoch 2, gen_loss = 1.2056459812093372, disc_loss = 0.0011366066275633995
Trained batch 605 in epoch 2, gen_loss = 1.206073427456047, disc_loss = 0.0011354778324086342
Trained batch 606 in epoch 2, gen_loss = 1.2061771196627735, disc_loss = 0.0011348038702003376
Trained batch 607 in epoch 2, gen_loss = 1.206055922433734, disc_loss = 0.0011336685996579227
Trained batch 608 in epoch 2, gen_loss = 1.206567518523174, disc_loss = 0.0011332387773492886
Trained batch 609 in epoch 2, gen_loss = 1.2063955974383431, disc_loss = 0.0011333787975046539
Trained batch 610 in epoch 2, gen_loss = 1.2064507666078996, disc_loss = 0.0011330618122562084
Trained batch 611 in epoch 2, gen_loss = 1.2061642294420916, disc_loss = 0.0011322690261295065
Trained batch 612 in epoch 2, gen_loss = 1.206495000623762, disc_loss = 0.0011314615041517378
Trained batch 613 in epoch 2, gen_loss = 1.2064669595285036, disc_loss = 0.001130949044603921
Trained batch 614 in epoch 2, gen_loss = 1.2063859533488266, disc_loss = 0.0011297578497494502
Trained batch 615 in epoch 2, gen_loss = 1.2062094082886523, disc_loss = 0.001128757418044117
Trained batch 616 in epoch 2, gen_loss = 1.206155915411017, disc_loss = 0.0011276773951522782
Trained batch 617 in epoch 2, gen_loss = 1.2059667074757487, disc_loss = 0.0011272457474710805
Trained batch 618 in epoch 2, gen_loss = 1.205942634908371, disc_loss = 0.0011276823962848297
Trained batch 619 in epoch 2, gen_loss = 1.2057521163455902, disc_loss = 0.0011280463297284329
Trained batch 620 in epoch 2, gen_loss = 1.206161431932219, disc_loss = 0.001128599476063588
Trained batch 621 in epoch 2, gen_loss = 1.2060709832373924, disc_loss = 0.0011292664105184166
Trained batch 622 in epoch 2, gen_loss = 1.2056989511938385, disc_loss = 0.0011296820925211573
Trained batch 623 in epoch 2, gen_loss = 1.205494539764447, disc_loss = 0.0011298729902754973
Trained batch 624 in epoch 2, gen_loss = 1.2061552077293396, disc_loss = 0.0011294767269399016
Trained batch 625 in epoch 2, gen_loss = 1.2061082576981748, disc_loss = 0.0011294513663999326
Trained batch 626 in epoch 2, gen_loss = 1.2060088543800647, disc_loss = 0.0011294573844663734
Trained batch 627 in epoch 2, gen_loss = 1.2060228721920851, disc_loss = 0.0011288043940465772
Trained batch 628 in epoch 2, gen_loss = 1.2060880686596203, disc_loss = 0.0011283102227742851
Trained batch 629 in epoch 2, gen_loss = 1.2058024133008625, disc_loss = 0.001127744904425483
Trained batch 630 in epoch 2, gen_loss = 1.2057645701568591, disc_loss = 0.0011276004215788758
Trained batch 631 in epoch 2, gen_loss = 1.2057219337247596, disc_loss = 0.001127382276789359
Trained batch 632 in epoch 2, gen_loss = 1.2054026346259397, disc_loss = 0.0011266855185790396
Trained batch 633 in epoch 2, gen_loss = 1.205523201813833, disc_loss = 0.0011266000798484017
Trained batch 634 in epoch 2, gen_loss = 1.2056410422475319, disc_loss = 0.0011260172259154194
Trained batch 635 in epoch 2, gen_loss = 1.2052919490719742, disc_loss = 0.0011256828906622996
Trained batch 636 in epoch 2, gen_loss = 1.205406385931527, disc_loss = 0.0011254448159557608
Trained batch 637 in epoch 2, gen_loss = 1.2055123585705474, disc_loss = 0.0011247604217093444
Trained batch 638 in epoch 2, gen_loss = 1.2054909918229904, disc_loss = 0.0011235997644205708
Trained batch 639 in epoch 2, gen_loss = 1.2053129118867218, disc_loss = 0.001122364377943086
Trained batch 640 in epoch 2, gen_loss = 1.2051525793841773, disc_loss = 0.001121591373378347
Trained batch 641 in epoch 2, gen_loss = 1.2053727330262787, disc_loss = 0.0011211841581973197
Trained batch 642 in epoch 2, gen_loss = 1.205082864913377, disc_loss = 0.0011205131632603942
Trained batch 643 in epoch 2, gen_loss = 1.2048198918563238, disc_loss = 0.0011197691083280514
Trained batch 644 in epoch 2, gen_loss = 1.2047009860822397, disc_loss = 0.001119996919684733
Trained batch 645 in epoch 2, gen_loss = 1.2046453881743522, disc_loss = 0.0011199986071152117
Trained batch 646 in epoch 2, gen_loss = 1.2048492279634961, disc_loss = 0.0011203776739758672
Trained batch 647 in epoch 2, gen_loss = 1.2049918659491303, disc_loss = 0.0011198916430725217
Trained batch 648 in epoch 2, gen_loss = 1.2047734843747826, disc_loss = 0.0011191774979509982
Trained batch 649 in epoch 2, gen_loss = 1.2046961277264816, disc_loss = 0.001118318078134997
Trained batch 650 in epoch 2, gen_loss = 1.2045410207705929, disc_loss = 0.0011171857860746196
Trained batch 651 in epoch 2, gen_loss = 1.2044374859589009, disc_loss = 0.001115949721919427
Trained batch 652 in epoch 2, gen_loss = 1.2043277955347327, disc_loss = 0.0011150579717973672
Trained batch 653 in epoch 2, gen_loss = 1.2044024092888614, disc_loss = 0.0011141168106071771
Trained batch 654 in epoch 2, gen_loss = 1.2042090802702285, disc_loss = 0.0011133968108067048
Trained batch 655 in epoch 2, gen_loss = 1.2040250774745533, disc_loss = 0.001112356868827369
Trained batch 656 in epoch 2, gen_loss = 1.204001704398174, disc_loss = 0.0011111468093893582
Trained batch 657 in epoch 2, gen_loss = 1.2041886060252378, disc_loss = 0.001109951575772163
Trained batch 658 in epoch 2, gen_loss = 1.2043667934914097, disc_loss = 0.0011087458209581222
Trained batch 659 in epoch 2, gen_loss = 1.204617054624991, disc_loss = 0.0011077244030523368
Trained batch 660 in epoch 2, gen_loss = 1.2048154772680575, disc_loss = 0.0011068311445598185
Trained batch 661 in epoch 2, gen_loss = 1.2047342689555938, disc_loss = 0.0011058361648938553
Trained batch 662 in epoch 2, gen_loss = 1.204675769104677, disc_loss = 0.0011045739797332366
Trained batch 663 in epoch 2, gen_loss = 1.204451933772449, disc_loss = 0.0011034542495694786
Trained batch 664 in epoch 2, gen_loss = 1.2044639602639622, disc_loss = 0.0011025900415957141
Trained batch 665 in epoch 2, gen_loss = 1.2042997365778272, disc_loss = 0.0011013677892066796
Trained batch 666 in epoch 2, gen_loss = 1.2041192623986297, disc_loss = 0.0011012257263378548
Trained batch 667 in epoch 2, gen_loss = 1.2039513692349018, disc_loss = 0.0011012203646175462
Trained batch 668 in epoch 2, gen_loss = 1.2038184146888231, disc_loss = 0.0011013686100629356
Trained batch 669 in epoch 2, gen_loss = 1.2038434561508804, disc_loss = 0.0011010505371108485
Trained batch 670 in epoch 2, gen_loss = 1.2037341572488651, disc_loss = 0.0011002950235158926
Trained batch 671 in epoch 2, gen_loss = 1.2038481355245625, disc_loss = 0.0010994060498238209
Trained batch 672 in epoch 2, gen_loss = 1.2037721889157176, disc_loss = 0.0010988366420631246
Trained batch 673 in epoch 2, gen_loss = 1.2039041587259367, disc_loss = 0.0010981623993430686
Trained batch 674 in epoch 2, gen_loss = 1.203976620833079, disc_loss = 0.001097425467127727
Trained batch 675 in epoch 2, gen_loss = 1.2040026430371245, disc_loss = 0.001096580206907696
Trained batch 676 in epoch 2, gen_loss = 1.203959214370395, disc_loss = 0.0010959348132169393
Trained batch 677 in epoch 2, gen_loss = 1.2036638717911587, disc_loss = 0.0010956019860421716
Trained batch 678 in epoch 2, gen_loss = 1.2035520990572552, disc_loss = 0.0010953206674055923
Trained batch 679 in epoch 2, gen_loss = 1.203679275775657, disc_loss = 0.0010953034966780038
Trained batch 680 in epoch 2, gen_loss = 1.2035221336696642, disc_loss = 0.0010956725976279445
Trained batch 681 in epoch 2, gen_loss = 1.2035559096818795, disc_loss = 0.0010952523416536382
Trained batch 682 in epoch 2, gen_loss = 1.2034076917398377, disc_loss = 0.0010952293872151463
Trained batch 683 in epoch 2, gen_loss = 1.2032325510915958, disc_loss = 0.0010956376265089044
Trained batch 684 in epoch 2, gen_loss = 1.2032264752109556, disc_loss = 0.0010951008095344814
Trained batch 685 in epoch 2, gen_loss = 1.2032356237009731, disc_loss = 0.0010941532467550982
Trained batch 686 in epoch 2, gen_loss = 1.2036712052520187, disc_loss = 0.00109515680532104
Trained batch 687 in epoch 2, gen_loss = 1.2039831829105698, disc_loss = 0.0010973327820846502
Trained batch 688 in epoch 2, gen_loss = 1.2042274659361651, disc_loss = 0.0010976978232229131
Trained batch 689 in epoch 2, gen_loss = 1.2041956769383473, disc_loss = 0.0010969488907257852
Trained batch 690 in epoch 2, gen_loss = 1.2041189129721757, disc_loss = 0.0010975989196452887
Trained batch 691 in epoch 2, gen_loss = 1.204149244923812, disc_loss = 0.001097928793070302
Trained batch 692 in epoch 2, gen_loss = 1.203922958171041, disc_loss = 0.0010973060948180886
Trained batch 693 in epoch 2, gen_loss = 1.2039497344397674, disc_loss = 0.001096288653659924
Trained batch 694 in epoch 2, gen_loss = 1.2038871042162393, disc_loss = 0.001095212681600891
Trained batch 695 in epoch 2, gen_loss = 1.2038424663331317, disc_loss = 0.0010942707794829507
Trained batch 696 in epoch 2, gen_loss = 1.2039926167540091, disc_loss = 0.0010940187812450114
Trained batch 697 in epoch 2, gen_loss = 1.2037042294839733, disc_loss = 0.0010937756481333597
Trained batch 698 in epoch 2, gen_loss = 1.2037815666505707, disc_loss = 0.0010927606416327909
Trained batch 699 in epoch 2, gen_loss = 1.2039836533580508, disc_loss = 0.0010924529344109551
Trained batch 700 in epoch 2, gen_loss = 1.2036570710224364, disc_loss = 0.0010920877913185815
Trained batch 701 in epoch 2, gen_loss = 1.2036447300870194, disc_loss = 0.0010923259210656065
Trained batch 702 in epoch 2, gen_loss = 1.2038025757666164, disc_loss = 0.001094821123651376
Trained batch 703 in epoch 2, gen_loss = 1.203893419355154, disc_loss = 0.001097648255546863
Trained batch 704 in epoch 2, gen_loss = 1.2038883706356616, disc_loss = 0.0010985546646283028
Trained batch 705 in epoch 2, gen_loss = 1.204241659756085, disc_loss = 0.0010993983979117937
Trained batch 706 in epoch 2, gen_loss = 1.204055067504818, disc_loss = 0.001102906503270695
Trained batch 707 in epoch 2, gen_loss = 1.2041008836131986, disc_loss = 0.0011072676397970546
Trained batch 708 in epoch 2, gen_loss = 1.2038517089085115, disc_loss = 0.0011105008356993012
Trained batch 709 in epoch 2, gen_loss = 1.2036042273884089, disc_loss = 0.00111142567057215
Trained batch 710 in epoch 2, gen_loss = 1.2039214453113734, disc_loss = 0.0011115191863265554
Trained batch 711 in epoch 2, gen_loss = 1.2038971492078867, disc_loss = 0.0011116334209689514
Trained batch 712 in epoch 2, gen_loss = 1.203856297830044, disc_loss = 0.0011108946712357142
Trained batch 713 in epoch 2, gen_loss = 1.203748248037504, disc_loss = 0.0011102213058457645
Trained batch 714 in epoch 2, gen_loss = 1.2037879705429078, disc_loss = 0.0011097083392494417
Trained batch 715 in epoch 2, gen_loss = 1.2038160484263352, disc_loss = 0.0011089783120905596
Trained batch 716 in epoch 2, gen_loss = 1.203969101360486, disc_loss = 0.001108643260974089
Trained batch 717 in epoch 2, gen_loss = 1.2038105269660524, disc_loss = 0.0011080957027891532
Trained batch 718 in epoch 2, gen_loss = 1.2037637814029698, disc_loss = 0.0011073588497252805
Trained batch 719 in epoch 2, gen_loss = 1.2035205857621298, disc_loss = 0.001106348607734415
Trained batch 720 in epoch 2, gen_loss = 1.2034466053345, disc_loss = 0.0011052240251212145
Trained batch 721 in epoch 2, gen_loss = 1.2034952295453925, disc_loss = 0.001104080505215065
Trained batch 722 in epoch 2, gen_loss = 1.2033802282430983, disc_loss = 0.0011030357976876879
Trained batch 723 in epoch 2, gen_loss = 1.203199737967707, disc_loss = 0.0011023739916407528
Trained batch 724 in epoch 2, gen_loss = 1.2029979158269948, disc_loss = 0.0011020384449511767
Trained batch 725 in epoch 2, gen_loss = 1.202770864175371, disc_loss = 0.0011022429824768265
Trained batch 726 in epoch 2, gen_loss = 1.2026832798980125, disc_loss = 0.0011022890845257302
Trained batch 727 in epoch 2, gen_loss = 1.2028411260017982, disc_loss = 0.00110150073969335
Trained batch 728 in epoch 2, gen_loss = 1.2030171136306638, disc_loss = 0.0011008502239206823
Trained batch 729 in epoch 2, gen_loss = 1.20322020658075, disc_loss = 0.001100527563798943
Trained batch 730 in epoch 2, gen_loss = 1.2031000203538365, disc_loss = 0.0011005835170811743
Trained batch 731 in epoch 2, gen_loss = 1.2028740072836641, disc_loss = 0.0011019246584177272
Trained batch 732 in epoch 2, gen_loss = 1.2028543267698926, disc_loss = 0.0011030129079343586
Trained batch 733 in epoch 2, gen_loss = 1.2025220715707265, disc_loss = 0.0011048937521396555
Trained batch 734 in epoch 2, gen_loss = 1.2028730348664887, disc_loss = 0.0011058245235135412
Trained batch 735 in epoch 2, gen_loss = 1.202991235839284, disc_loss = 0.0011055163382558892
Trained batch 736 in epoch 2, gen_loss = 1.2029952583998806, disc_loss = 0.0011049430437317799
Trained batch 737 in epoch 2, gen_loss = 1.2030212392975, disc_loss = 0.0011042610132943101
Trained batch 738 in epoch 2, gen_loss = 1.2030923419779467, disc_loss = 0.0011032609159066385
Trained batch 739 in epoch 2, gen_loss = 1.2030981706606376, disc_loss = 0.0011029805140129315
Trained batch 740 in epoch 2, gen_loss = 1.2030210165198838, disc_loss = 0.0011027666285141357
Trained batch 741 in epoch 2, gen_loss = 1.2033546353286166, disc_loss = 0.0011021076760259821
Trained batch 742 in epoch 2, gen_loss = 1.203364191594387, disc_loss = 0.0011012952444632443
Trained batch 743 in epoch 2, gen_loss = 1.2032743621897954, disc_loss = 0.0011006416450943096
Trained batch 744 in epoch 2, gen_loss = 1.2032382955487142, disc_loss = 0.0011000780713738211
Trained batch 745 in epoch 2, gen_loss = 1.2029962082650643, disc_loss = 0.001099531920021275
Trained batch 746 in epoch 2, gen_loss = 1.2026537995900175, disc_loss = 0.0010990705365256483
Trained batch 747 in epoch 2, gen_loss = 1.2026603782081349, disc_loss = 0.00109842261475359
Trained batch 748 in epoch 2, gen_loss = 1.2030990516073077, disc_loss = 0.0010980416134525792
Trained batch 749 in epoch 2, gen_loss = 1.2035445646444956, disc_loss = 0.0010978190504635373
Trained batch 750 in epoch 2, gen_loss = 1.2034674605897835, disc_loss = 0.0010976337834097663
Trained batch 751 in epoch 2, gen_loss = 1.2032823181374277, disc_loss = 0.0010973259436952425
Trained batch 752 in epoch 2, gen_loss = 1.2034241419389429, disc_loss = 0.001097400131317506
Trained batch 753 in epoch 2, gen_loss = 1.203863071589002, disc_loss = 0.001097922144051325
Trained batch 754 in epoch 2, gen_loss = 1.203778862084774, disc_loss = 0.001097895621186406
Trained batch 755 in epoch 2, gen_loss = 1.2039059305159503, disc_loss = 0.0010986160684041877
Trained batch 756 in epoch 2, gen_loss = 1.2038653903939764, disc_loss = 0.0011005813909185215
Trained batch 757 in epoch 2, gen_loss = 1.2042034231421186, disc_loss = 0.0011023690022213635
Trained batch 758 in epoch 2, gen_loss = 1.2042942844203652, disc_loss = 0.0011032210832905903
Trained batch 759 in epoch 2, gen_loss = 1.2045090061269308, disc_loss = 0.0011031652243170692
Trained batch 760 in epoch 2, gen_loss = 1.2043082511221375, disc_loss = 0.0011025015878186374
Trained batch 761 in epoch 2, gen_loss = 1.204057445441644, disc_loss = 0.0011015142214220515
Trained batch 762 in epoch 2, gen_loss = 1.203908128554043, disc_loss = 0.001101074915905367
Trained batch 763 in epoch 2, gen_loss = 1.203796993141399, disc_loss = 0.0011005933748202213
Trained batch 764 in epoch 2, gen_loss = 1.2036673979821548, disc_loss = 0.001101833463530817
Trained batch 765 in epoch 2, gen_loss = 1.2044039307157302, disc_loss = 0.0011024025375845382
Trained batch 766 in epoch 2, gen_loss = 1.204642743688208, disc_loss = 0.0011017640274427248
Trained batch 767 in epoch 2, gen_loss = 1.204534309528147, disc_loss = 0.0011019584310361097
Trained batch 768 in epoch 2, gen_loss = 1.204642910253552, disc_loss = 0.0011025162881345613
Trained batch 769 in epoch 2, gen_loss = 1.2046531258465407, disc_loss = 0.001102295762922784
Trained batch 770 in epoch 2, gen_loss = 1.2046114030824406, disc_loss = 0.0011013669906130927
Trained batch 771 in epoch 2, gen_loss = 1.204745001357454, disc_loss = 0.0011007372868805881
Trained batch 772 in epoch 2, gen_loss = 1.204666298003277, disc_loss = 0.0011007021887458012
Trained batch 773 in epoch 2, gen_loss = 1.204633883958639, disc_loss = 0.0011005853608855858
Trained batch 774 in epoch 2, gen_loss = 1.2047086571878003, disc_loss = 0.0010999331132869326
Trained batch 775 in epoch 2, gen_loss = 1.2047369874168916, disc_loss = 0.001099168698329805
Trained batch 776 in epoch 2, gen_loss = 1.2044738619330613, disc_loss = 0.001098248340599083
Trained batch 777 in epoch 2, gen_loss = 1.2045052395535005, disc_loss = 0.0010973558197657465
Trained batch 778 in epoch 2, gen_loss = 1.2043134661938932, disc_loss = 0.001096681312870698
Trained batch 779 in epoch 2, gen_loss = 1.20412173920717, disc_loss = 0.0010961003791845332
Trained batch 780 in epoch 2, gen_loss = 1.2042107153946244, disc_loss = 0.0010952994941925169
Trained batch 781 in epoch 2, gen_loss = 1.203914696908058, disc_loss = 0.0010945340203519678
Trained batch 782 in epoch 2, gen_loss = 1.2039371013336864, disc_loss = 0.0010942210487401088
Trained batch 783 in epoch 2, gen_loss = 1.2039831712537883, disc_loss = 0.0010939556187269995
Trained batch 784 in epoch 2, gen_loss = 1.204147008422074, disc_loss = 0.0010936896977753372
Trained batch 785 in epoch 2, gen_loss = 1.2041436879689458, disc_loss = 0.001093541861133491
Trained batch 786 in epoch 2, gen_loss = 1.204079767648874, disc_loss = 0.0010927894081032257
Trained batch 787 in epoch 2, gen_loss = 1.2040482217890358, disc_loss = 0.0010922317713931047
Trained batch 788 in epoch 2, gen_loss = 1.2040052463799829, disc_loss = 0.0010920779130563815
Trained batch 789 in epoch 2, gen_loss = 1.2039693249931818, disc_loss = 0.0010923203555027118
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 1.0009979009628296, disc_loss = 0.001441457192413509
Trained batch 1 in epoch 3, gen_loss = 1.109671175479889, disc_loss = 0.001260274148080498
Trained batch 2 in epoch 3, gen_loss = 1.1561385790507, disc_loss = 0.001104854008493324
Trained batch 3 in epoch 3, gen_loss = 1.1648521721363068, disc_loss = 0.0009532167023280635
Trained batch 4 in epoch 3, gen_loss = 1.1637001514434815, disc_loss = 0.0008778644958510994
Trained batch 5 in epoch 3, gen_loss = 1.2007823586463928, disc_loss = 0.0008835953000622491
Trained batch 6 in epoch 3, gen_loss = 1.2167314631598336, disc_loss = 0.0008274885642874454
Trained batch 7 in epoch 3, gen_loss = 1.211985930800438, disc_loss = 0.0008576106411055662
Trained batch 8 in epoch 3, gen_loss = 1.1932927899890475, disc_loss = 0.0008761473194075128
Trained batch 9 in epoch 3, gen_loss = 1.1871235966682434, disc_loss = 0.0008842047129292041
Trained batch 10 in epoch 3, gen_loss = 1.174349470572038, disc_loss = 0.0008512875488535924
Trained batch 11 in epoch 3, gen_loss = 1.17311625679334, disc_loss = 0.0008209288256087651
Trained batch 12 in epoch 3, gen_loss = 1.1688551811071544, disc_loss = 0.0008227684660456502
Trained batch 13 in epoch 3, gen_loss = 1.16715179170881, disc_loss = 0.0008148728146417332
Trained batch 14 in epoch 3, gen_loss = 1.1997807502746582, disc_loss = 0.0008110848915142318
Trained batch 15 in epoch 3, gen_loss = 1.1964973509311676, disc_loss = 0.0008221227362810168
Trained batch 16 in epoch 3, gen_loss = 1.2073225063436173, disc_loss = 0.0008029157727244584
Trained batch 17 in epoch 3, gen_loss = 1.2060771783192952, disc_loss = 0.0007825482817780641
Trained batch 18 in epoch 3, gen_loss = 1.1995339456357454, disc_loss = 0.000780716198373978
Trained batch 19 in epoch 3, gen_loss = 1.1883727699518203, disc_loss = 0.0007753431185847148
Trained batch 20 in epoch 3, gen_loss = 1.181775913352058, disc_loss = 0.0007937228490066316
Trained batch 21 in epoch 3, gen_loss = 1.1870189607143402, disc_loss = 0.0008211799669714475
Trained batch 22 in epoch 3, gen_loss = 1.1808613720147505, disc_loss = 0.0008723031066398581
Trained batch 23 in epoch 3, gen_loss = 1.1841944778958957, disc_loss = 0.0008716187609631257
Trained batch 24 in epoch 3, gen_loss = 1.1919845747947693, disc_loss = 0.0008589431829750538
Trained batch 25 in epoch 3, gen_loss = 1.1912008546865904, disc_loss = 0.000860601739707188
Trained batch 26 in epoch 3, gen_loss = 1.1888274153073628, disc_loss = 0.0008613595553604817
Trained batch 27 in epoch 3, gen_loss = 1.1876101642847061, disc_loss = 0.0008580631256336346
Trained batch 28 in epoch 3, gen_loss = 1.1850844477785045, disc_loss = 0.0008489480001273854
Trained batch 29 in epoch 3, gen_loss = 1.1831836760044099, disc_loss = 0.000832056709138366
Trained batch 30 in epoch 3, gen_loss = 1.184677768138147, disc_loss = 0.0008124890530692233
Trained batch 31 in epoch 3, gen_loss = 1.186879301443696, disc_loss = 0.0007954888815220329
Trained batch 32 in epoch 3, gen_loss = 1.1843620231657317, disc_loss = 0.0007832079312665331
Trained batch 33 in epoch 3, gen_loss = 1.183317350990632, disc_loss = 0.0007718897678012796
Trained batch 34 in epoch 3, gen_loss = 1.1914383905274528, disc_loss = 0.0007607913210189768
Trained batch 35 in epoch 3, gen_loss = 1.1886162045929167, disc_loss = 0.0007591039563218752
Trained batch 36 in epoch 3, gen_loss = 1.1838137217470117, disc_loss = 0.0007682979528515323
Trained batch 37 in epoch 3, gen_loss = 1.181932215627871, disc_loss = 0.0007936903857626021
Trained batch 38 in epoch 3, gen_loss = 1.182619252266028, disc_loss = 0.0008103687238569061
Trained batch 39 in epoch 3, gen_loss = 1.1817401990294456, disc_loss = 0.0008207137376302853
Trained batch 40 in epoch 3, gen_loss = 1.180620476966951, disc_loss = 0.0008475949260883215
Trained batch 41 in epoch 3, gen_loss = 1.1815390686194103, disc_loss = 0.0008849431483429813
Trained batch 42 in epoch 3, gen_loss = 1.178419522074766, disc_loss = 0.0009148942284979099
Trained batch 43 in epoch 3, gen_loss = 1.1822909157384525, disc_loss = 0.0009240519615228881
Trained batch 44 in epoch 3, gen_loss = 1.1796885636117724, disc_loss = 0.0009183679862568776
Trained batch 45 in epoch 3, gen_loss = 1.1811400561229042, disc_loss = 0.000908534444296611
Trained batch 46 in epoch 3, gen_loss = 1.1866244217182726, disc_loss = 0.0009085318089730324
Trained batch 47 in epoch 3, gen_loss = 1.1913930885493755, disc_loss = 0.0009068480061008207
Trained batch 48 in epoch 3, gen_loss = 1.1946134190170132, disc_loss = 0.0009039474113093576
Trained batch 49 in epoch 3, gen_loss = 1.1914825975894927, disc_loss = 0.000908155936631374
Trained batch 50 in epoch 3, gen_loss = 1.190329847382564, disc_loss = 0.0009261053369389664
Trained batch 51 in epoch 3, gen_loss = 1.1914157695495164, disc_loss = 0.0009360972723628108
Trained batch 52 in epoch 3, gen_loss = 1.1881921819920809, disc_loss = 0.0009321618121214
Trained batch 53 in epoch 3, gen_loss = 1.1950822130397514, disc_loss = 0.000934169441784939
Trained batch 54 in epoch 3, gen_loss = 1.1952866066585888, disc_loss = 0.0009459741577633064
Trained batch 55 in epoch 3, gen_loss = 1.1941246805446488, disc_loss = 0.0009436012566896222
Trained batch 56 in epoch 3, gen_loss = 1.1938922520269428, disc_loss = 0.0009460119952308831
Trained batch 57 in epoch 3, gen_loss = 1.192856068241185, disc_loss = 0.0009683908795303633
Trained batch 58 in epoch 3, gen_loss = 1.1895734809212766, disc_loss = 0.0009772722590596305
Trained batch 59 in epoch 3, gen_loss = 1.1866284837325414, disc_loss = 0.0009814163946430198
Trained batch 60 in epoch 3, gen_loss = 1.1845021961165256, disc_loss = 0.000994828404175484
Trained batch 61 in epoch 3, gen_loss = 1.1863687124944502, disc_loss = 0.0010083700767755809
Trained batch 62 in epoch 3, gen_loss = 1.1851951820509774, disc_loss = 0.0010129952815265233
Trained batch 63 in epoch 3, gen_loss = 1.1822539716959, disc_loss = 0.0010149439772249025
Trained batch 64 in epoch 3, gen_loss = 1.181438313997709, disc_loss = 0.0010210315414811843
Trained batch 65 in epoch 3, gen_loss = 1.1819014043518992, disc_loss = 0.0010355736987107914
Trained batch 66 in epoch 3, gen_loss = 1.1839874466853355, disc_loss = 0.0010444171897851541
Trained batch 67 in epoch 3, gen_loss = 1.1869089515770184, disc_loss = 0.001042081850755494
Trained batch 68 in epoch 3, gen_loss = 1.1869234244028728, disc_loss = 0.0010525021643843502
Trained batch 69 in epoch 3, gen_loss = 1.1913119213921683, disc_loss = 0.0010710478689621335
Trained batch 70 in epoch 3, gen_loss = 1.1894417547843825, disc_loss = 0.0010794024815304127
Trained batch 71 in epoch 3, gen_loss = 1.190554807583491, disc_loss = 0.0010794108752128927
Trained batch 72 in epoch 3, gen_loss = 1.1907200045781592, disc_loss = 0.0010749762937624313
Trained batch 73 in epoch 3, gen_loss = 1.1896896088445508, disc_loss = 0.0010686982938283552
Trained batch 74 in epoch 3, gen_loss = 1.1904042132695516, disc_loss = 0.0010671070959263791
Trained batch 75 in epoch 3, gen_loss = 1.1884204839405261, disc_loss = 0.0010664810860793008
Trained batch 76 in epoch 3, gen_loss = 1.1862417753640708, disc_loss = 0.0010618349191787132
Trained batch 77 in epoch 3, gen_loss = 1.1824750097898336, disc_loss = 0.0010665901500033215
Trained batch 78 in epoch 3, gen_loss = 1.1805815085580078, disc_loss = 0.001061786976687115
Trained batch 79 in epoch 3, gen_loss = 1.1808431454002857, disc_loss = 0.0010562363033386646
Trained batch 80 in epoch 3, gen_loss = 1.1861852135187314, disc_loss = 0.0010486741864300666
Trained batch 81 in epoch 3, gen_loss = 1.1883278830749233, disc_loss = 0.0010416531852281811
Trained batch 82 in epoch 3, gen_loss = 1.1875857380499322, disc_loss = 0.0010332652141132493
Trained batch 83 in epoch 3, gen_loss = 1.1912984386796044, disc_loss = 0.0010265214496896426
Trained batch 84 in epoch 3, gen_loss = 1.1949202740893645, disc_loss = 0.001021236421280157
Trained batch 85 in epoch 3, gen_loss = 1.193611707105193, disc_loss = 0.0010160289039472551
Trained batch 86 in epoch 3, gen_loss = 1.192401048095747, disc_loss = 0.0010129824396485098
Trained batch 87 in epoch 3, gen_loss = 1.1901713331991977, disc_loss = 0.0010098213708922478
Trained batch 88 in epoch 3, gen_loss = 1.1895359238881744, disc_loss = 0.0010079263354353398
Trained batch 89 in epoch 3, gen_loss = 1.1878897474871741, disc_loss = 0.0010268632286978472
Trained batch 90 in epoch 3, gen_loss = 1.187063033109183, disc_loss = 0.0010333509689099717
Trained batch 91 in epoch 3, gen_loss = 1.1886853387822276, disc_loss = 0.0010332698587697687
Trained batch 92 in epoch 3, gen_loss = 1.191119542044978, disc_loss = 0.0010311448178629602
Trained batch 93 in epoch 3, gen_loss = 1.1917257188482488, disc_loss = 0.0010251604847887413
Trained batch 94 in epoch 3, gen_loss = 1.1915329236733285, disc_loss = 0.0010191117603282787
Trained batch 95 in epoch 3, gen_loss = 1.1898946097741525, disc_loss = 0.0010139449095731834
Trained batch 96 in epoch 3, gen_loss = 1.1900629683868171, disc_loss = 0.0010107510744776461
Trained batch 97 in epoch 3, gen_loss = 1.1902510201444432, disc_loss = 0.0010046613077770881
Trained batch 98 in epoch 3, gen_loss = 1.190278466903802, disc_loss = 0.0010006089163873571
Trained batch 99 in epoch 3, gen_loss = 1.190106424689293, disc_loss = 0.0009953543686424381
Trained batch 100 in epoch 3, gen_loss = 1.1890860282548583, disc_loss = 0.0009880626273323036
Trained batch 101 in epoch 3, gen_loss = 1.1898072017174142, disc_loss = 0.000981404303684922
Trained batch 102 in epoch 3, gen_loss = 1.1892263409003472, disc_loss = 0.0009753021478847356
Trained batch 103 in epoch 3, gen_loss = 1.189521587238862, disc_loss = 0.0009702983443276025
Trained batch 104 in epoch 3, gen_loss = 1.1891262468837556, disc_loss = 0.0009643444428331263
Trained batch 105 in epoch 3, gen_loss = 1.187154765961305, disc_loss = 0.0009588733843180685
Trained batch 106 in epoch 3, gen_loss = 1.1872517800776758, disc_loss = 0.0009547162343525963
Trained batch 107 in epoch 3, gen_loss = 1.186018481850624, disc_loss = 0.0009486314474661076
Trained batch 108 in epoch 3, gen_loss = 1.1850879755588846, disc_loss = 0.000945044662472322
Trained batch 109 in epoch 3, gen_loss = 1.1839955454522912, disc_loss = 0.0009446153356376188
Trained batch 110 in epoch 3, gen_loss = 1.1825908771506302, disc_loss = 0.0009491050813603006
Trained batch 111 in epoch 3, gen_loss = 1.1805015169084072, disc_loss = 0.0009639673654809096
Trained batch 112 in epoch 3, gen_loss = 1.182619518410843, disc_loss = 0.0009667556797281995
Trained batch 113 in epoch 3, gen_loss = 1.18338932018531, disc_loss = 0.0009728455857328841
Trained batch 114 in epoch 3, gen_loss = 1.1817396578581436, disc_loss = 0.0009773806387902764
Trained batch 115 in epoch 3, gen_loss = 1.1809585926861599, disc_loss = 0.0009749302972240599
Trained batch 116 in epoch 3, gen_loss = 1.1807634035746257, disc_loss = 0.0009701451767757376
Trained batch 117 in epoch 3, gen_loss = 1.1811490604432964, disc_loss = 0.0009652934586175449
Trained batch 118 in epoch 3, gen_loss = 1.1801960728749508, disc_loss = 0.0009595010478045603
Trained batch 119 in epoch 3, gen_loss = 1.1787072678407033, disc_loss = 0.0009591330199327786
Trained batch 120 in epoch 3, gen_loss = 1.177101064319453, disc_loss = 0.0009582379536052843
Trained batch 121 in epoch 3, gen_loss = 1.1772908060277094, disc_loss = 0.0009547780040311856
Trained batch 122 in epoch 3, gen_loss = 1.1776960283760134, disc_loss = 0.0009629787568180874
Trained batch 123 in epoch 3, gen_loss = 1.1784340450840611, disc_loss = 0.0009832382856984623
Trained batch 124 in epoch 3, gen_loss = 1.1786134128570556, disc_loss = 0.0010071654447820037
Trained batch 125 in epoch 3, gen_loss = 1.1789971135911488, disc_loss = 0.0010347845610730083
Trained batch 126 in epoch 3, gen_loss = 1.1779588751905545, disc_loss = 0.0010657399270855858
Trained batch 127 in epoch 3, gen_loss = 1.1789123117923737, disc_loss = 0.0010811329827902227
Trained batch 128 in epoch 3, gen_loss = 1.1786527707595233, disc_loss = 0.0010829081218743826
Trained batch 129 in epoch 3, gen_loss = 1.178257863338177, disc_loss = 0.0010907359401104398
Trained batch 130 in epoch 3, gen_loss = 1.1778545179439865, disc_loss = 0.0011063120307894922
Trained batch 131 in epoch 3, gen_loss = 1.1794876013741349, disc_loss = 0.0011129872994691443
Trained batch 132 in epoch 3, gen_loss = 1.1800122404457034, disc_loss = 0.0011108556442414375
Trained batch 133 in epoch 3, gen_loss = 1.179600436296036, disc_loss = 0.0011084238425637387
Trained batch 134 in epoch 3, gen_loss = 1.178861195952804, disc_loss = 0.0011065183106068247
Trained batch 135 in epoch 3, gen_loss = 1.1798151450998642, disc_loss = 0.001106407885612605
Trained batch 136 in epoch 3, gen_loss = 1.1808328593734407, disc_loss = 0.001104850807426035
Trained batch 137 in epoch 3, gen_loss = 1.1812523491140725, disc_loss = 0.001101575073730403
Trained batch 138 in epoch 3, gen_loss = 1.1813581324309754, disc_loss = 0.0010985581138549816
Trained batch 139 in epoch 3, gen_loss = 1.1818986432892935, disc_loss = 0.0010939013691053593
Trained batch 140 in epoch 3, gen_loss = 1.1831539649489924, disc_loss = 0.0010912058142621519
Trained batch 141 in epoch 3, gen_loss = 1.1828771267138736, disc_loss = 0.0010973062373625614
Trained batch 142 in epoch 3, gen_loss = 1.182470533397648, disc_loss = 0.0010992142838308705
Trained batch 143 in epoch 3, gen_loss = 1.1807201223240957, disc_loss = 0.00109983508486443
Trained batch 144 in epoch 3, gen_loss = 1.1821497933617953, disc_loss = 0.0011034211990873105
Trained batch 145 in epoch 3, gen_loss = 1.181630211333706, disc_loss = 0.0011029136745890678
Trained batch 146 in epoch 3, gen_loss = 1.1804680378258634, disc_loss = 0.0011016817586844926
Trained batch 147 in epoch 3, gen_loss = 1.180237231222359, disc_loss = 0.0011008250667883487
Trained batch 148 in epoch 3, gen_loss = 1.1789693708387798, disc_loss = 0.001105740163615911
Trained batch 149 in epoch 3, gen_loss = 1.1808920737107595, disc_loss = 0.001105984867317602
Trained batch 150 in epoch 3, gen_loss = 1.1816154635505172, disc_loss = 0.0011049986463070951
Trained batch 151 in epoch 3, gen_loss = 1.1836576716680276, disc_loss = 0.00110302130671794
Trained batch 152 in epoch 3, gen_loss = 1.1829200690867854, disc_loss = 0.0011003813892755097
Trained batch 153 in epoch 3, gen_loss = 1.184881669747365, disc_loss = 0.0010973487080334892
Trained batch 154 in epoch 3, gen_loss = 1.1839899243847016, disc_loss = 0.0010936693337205196
Trained batch 155 in epoch 3, gen_loss = 1.184239434508177, disc_loss = 0.0010893196281708346
Trained batch 156 in epoch 3, gen_loss = 1.183773748054626, disc_loss = 0.0010869226742470579
Trained batch 157 in epoch 3, gen_loss = 1.1829887285262723, disc_loss = 0.001084316338049955
Trained batch 158 in epoch 3, gen_loss = 1.1818856057131066, disc_loss = 0.0010803383381513046
Trained batch 159 in epoch 3, gen_loss = 1.1817144680768252, disc_loss = 0.0010770799470265046
Trained batch 160 in epoch 3, gen_loss = 1.1815868590189063, disc_loss = 0.0010745088276612393
Trained batch 161 in epoch 3, gen_loss = 1.1809672746393416, disc_loss = 0.0010712738459668248
Trained batch 162 in epoch 3, gen_loss = 1.1814627987475483, disc_loss = 0.0010670814611391946
Trained batch 163 in epoch 3, gen_loss = 1.1808708720817798, disc_loss = 0.0010635117448656252
Trained batch 164 in epoch 3, gen_loss = 1.1796712344343012, disc_loss = 0.001058971447954801
Trained batch 165 in epoch 3, gen_loss = 1.1798390871789082, disc_loss = 0.001054569824278938
Trained batch 166 in epoch 3, gen_loss = 1.179700652639309, disc_loss = 0.001050790302346678
Trained batch 167 in epoch 3, gen_loss = 1.179098553245976, disc_loss = 0.0010480727228457994
Trained batch 168 in epoch 3, gen_loss = 1.1784710704222234, disc_loss = 0.0010506775293543317
Trained batch 169 in epoch 3, gen_loss = 1.1780052714488085, disc_loss = 0.00105182480354629
Trained batch 170 in epoch 3, gen_loss = 1.1775247099106771, disc_loss = 0.0010475506888612646
Trained batch 171 in epoch 3, gen_loss = 1.1778966434473215, disc_loss = 0.001045346699504799
Trained batch 172 in epoch 3, gen_loss = 1.1785279791479166, disc_loss = 0.0010433352168452942
Trained batch 173 in epoch 3, gen_loss = 1.1779447352064067, disc_loss = 0.0010405851495599416
Trained batch 174 in epoch 3, gen_loss = 1.1775307645116533, disc_loss = 0.001039025495327743
Trained batch 175 in epoch 3, gen_loss = 1.177491103044965, disc_loss = 0.0010367148859751812
Trained batch 176 in epoch 3, gen_loss = 1.1775213604593007, disc_loss = 0.0010342541981769968
Trained batch 177 in epoch 3, gen_loss = 1.1801400301831493, disc_loss = 0.001032722088229696
Trained batch 178 in epoch 3, gen_loss = 1.1810319740013038, disc_loss = 0.0010312884347188135
Trained batch 179 in epoch 3, gen_loss = 1.1813220477766462, disc_loss = 0.0010315307589027927
Trained batch 180 in epoch 3, gen_loss = 1.1819049393274508, disc_loss = 0.0010330878596595946
Trained batch 181 in epoch 3, gen_loss = 1.1806783502573495, disc_loss = 0.001033462708589498
Trained batch 182 in epoch 3, gen_loss = 1.1802052497212352, disc_loss = 0.0010369729740186365
Trained batch 183 in epoch 3, gen_loss = 1.1798348799347878, disc_loss = 0.0010358401909204827
Trained batch 184 in epoch 3, gen_loss = 1.1791492871336036, disc_loss = 0.001033465884393081
Trained batch 185 in epoch 3, gen_loss = 1.1793577308936785, disc_loss = 0.0010299859721819439
Trained batch 186 in epoch 3, gen_loss = 1.178692031990398, disc_loss = 0.0010286864372005158
Trained batch 187 in epoch 3, gen_loss = 1.1785056004498868, disc_loss = 0.001027950496249337
Trained batch 188 in epoch 3, gen_loss = 1.1783378531062414, disc_loss = 0.0010263964197494918
Trained batch 189 in epoch 3, gen_loss = 1.1784452830490313, disc_loss = 0.0010278683020978382
Trained batch 190 in epoch 3, gen_loss = 1.1788091275704469, disc_loss = 0.001030265677266837
Trained batch 191 in epoch 3, gen_loss = 1.1788489324972034, disc_loss = 0.001030064555379795
Trained batch 192 in epoch 3, gen_loss = 1.1782131012857269, disc_loss = 0.0010265606980881814
Trained batch 193 in epoch 3, gen_loss = 1.1784847019259463, disc_loss = 0.0010251760679013911
Trained batch 194 in epoch 3, gen_loss = 1.1785554081965715, disc_loss = 0.0010297070546911504
Trained batch 195 in epoch 3, gen_loss = 1.1793868824535487, disc_loss = 0.001042406540661005
Trained batch 196 in epoch 3, gen_loss = 1.178623522901293, disc_loss = 0.0010506850977541717
Trained batch 197 in epoch 3, gen_loss = 1.1792294927919753, disc_loss = 0.0010482756826071765
Trained batch 198 in epoch 3, gen_loss = 1.17988783480534, disc_loss = 0.001048806088627901
Trained batch 199 in epoch 3, gen_loss = 1.1797304394841195, disc_loss = 0.0010506081362836994
Trained batch 200 in epoch 3, gen_loss = 1.1795988234121408, disc_loss = 0.0010517762620025199
Trained batch 201 in epoch 3, gen_loss = 1.1782666778210367, disc_loss = 0.0010529242897991755
Trained batch 202 in epoch 3, gen_loss = 1.1807162606070194, disc_loss = 0.0010524367586149848
Trained batch 203 in epoch 3, gen_loss = 1.1817100308105057, disc_loss = 0.0010516705443995877
Trained batch 204 in epoch 3, gen_loss = 1.1814300051549587, disc_loss = 0.0010519845584384734
Trained batch 205 in epoch 3, gen_loss = 1.180846428697549, disc_loss = 0.0010559253258409106
Trained batch 206 in epoch 3, gen_loss = 1.179707660191301, disc_loss = 0.0010601748683678823
Trained batch 207 in epoch 3, gen_loss = 1.1795047607559423, disc_loss = 0.0010585943214559497
Trained batch 208 in epoch 3, gen_loss = 1.1798740819310458, disc_loss = 0.0010583286578031747
Trained batch 209 in epoch 3, gen_loss = 1.1792370421545846, disc_loss = 0.0010613451783900104
Trained batch 210 in epoch 3, gen_loss = 1.179170269536746, disc_loss = 0.0010619262488276403
Trained batch 211 in epoch 3, gen_loss = 1.1786288135456588, disc_loss = 0.0010603072241449482
Trained batch 212 in epoch 3, gen_loss = 1.1788594739537843, disc_loss = 0.0010605421520664658
Trained batch 213 in epoch 3, gen_loss = 1.1784672007382473, disc_loss = 0.0010650451305957737
Trained batch 214 in epoch 3, gen_loss = 1.177747030036394, disc_loss = 0.001066864034984001
Trained batch 215 in epoch 3, gen_loss = 1.1773969613843493, disc_loss = 0.0010652613141078123
Trained batch 216 in epoch 3, gen_loss = 1.1766152310481268, disc_loss = 0.0010640690457783984
Trained batch 217 in epoch 3, gen_loss = 1.1776893133417181, disc_loss = 0.001065444479185934
Trained batch 218 in epoch 3, gen_loss = 1.177213319904728, disc_loss = 0.0010644996293701367
Trained batch 219 in epoch 3, gen_loss = 1.1769397730177098, disc_loss = 0.0010633521546630866
Trained batch 220 in epoch 3, gen_loss = 1.1768829957392422, disc_loss = 0.0010607925686686051
Trained batch 221 in epoch 3, gen_loss = 1.1764830528078853, disc_loss = 0.0010583896170525502
Trained batch 222 in epoch 3, gen_loss = 1.1762467612065541, disc_loss = 0.001056960787553123
Trained batch 223 in epoch 3, gen_loss = 1.1771960785346371, disc_loss = 0.001055307565755876
Trained batch 224 in epoch 3, gen_loss = 1.1778957902060614, disc_loss = 0.0010524772804799594
Trained batch 225 in epoch 3, gen_loss = 1.1769647292331256, disc_loss = 0.0010507671015421588
Trained batch 226 in epoch 3, gen_loss = 1.1764246052057208, disc_loss = 0.0010500562600104246
Trained batch 227 in epoch 3, gen_loss = 1.1769425706905232, disc_loss = 0.0010477361608074013
Trained batch 228 in epoch 3, gen_loss = 1.1775007185457054, disc_loss = 0.0010445979625895603
Trained batch 229 in epoch 3, gen_loss = 1.1771151371624158, disc_loss = 0.0010455573543288704
Trained batch 230 in epoch 3, gen_loss = 1.1766972681144616, disc_loss = 0.0010482625474143386
Trained batch 231 in epoch 3, gen_loss = 1.1763977146354214, disc_loss = 0.0010509788416725471
Trained batch 232 in epoch 3, gen_loss = 1.1764547640673593, disc_loss = 0.0010501437266147396
Trained batch 233 in epoch 3, gen_loss = 1.1777477539502657, disc_loss = 0.0010487359116882738
Trained batch 234 in epoch 3, gen_loss = 1.1778875898807606, disc_loss = 0.0010467364855279075
Trained batch 235 in epoch 3, gen_loss = 1.1776978333117598, disc_loss = 0.0010445990817477312
Trained batch 236 in epoch 3, gen_loss = 1.1775826552749182, disc_loss = 0.00104202014231516
Trained batch 237 in epoch 3, gen_loss = 1.1769977637699671, disc_loss = 0.0010398778509976686
Trained batch 238 in epoch 3, gen_loss = 1.1782394966819796, disc_loss = 0.0010400151705542758
Trained batch 239 in epoch 3, gen_loss = 1.1778064812223117, disc_loss = 0.0010413708190753824
Trained batch 240 in epoch 3, gen_loss = 1.1778734472282695, disc_loss = 0.0010451194034412086
Trained batch 241 in epoch 3, gen_loss = 1.178482898995896, disc_loss = 0.0010462806057156071
Trained batch 242 in epoch 3, gen_loss = 1.178197607581998, disc_loss = 0.0010447192005573584
Trained batch 243 in epoch 3, gen_loss = 1.1785040629691765, disc_loss = 0.0010446714609241127
Trained batch 244 in epoch 3, gen_loss = 1.1782638943925197, disc_loss = 0.0010442948939364252
Trained batch 245 in epoch 3, gen_loss = 1.179218724975741, disc_loss = 0.0010429470726748837
Trained batch 246 in epoch 3, gen_loss = 1.178978875098441, disc_loss = 0.0010413339069096168
Trained batch 247 in epoch 3, gen_loss = 1.1784347262113326, disc_loss = 0.0010393335367318228
Trained batch 248 in epoch 3, gen_loss = 1.1795782865769413, disc_loss = 0.0010370701369333893
Trained batch 249 in epoch 3, gen_loss = 1.1799252638816833, disc_loss = 0.001034973683883436
Trained batch 250 in epoch 3, gen_loss = 1.1797692742480699, disc_loss = 0.001033715475781958
Trained batch 251 in epoch 3, gen_loss = 1.1798726646673112, disc_loss = 0.0010340539388596966
Trained batch 252 in epoch 3, gen_loss = 1.180026777176989, disc_loss = 0.0010360970476820785
Trained batch 253 in epoch 3, gen_loss = 1.1802473687750148, disc_loss = 0.0010346575337874622
Trained batch 254 in epoch 3, gen_loss = 1.1802632551567227, disc_loss = 0.0010354511080282356
Trained batch 255 in epoch 3, gen_loss = 1.1811348530463874, disc_loss = 0.0010394565384785892
Trained batch 256 in epoch 3, gen_loss = 1.1806342504367755, disc_loss = 0.001040031417868198
Trained batch 257 in epoch 3, gen_loss = 1.1810280763825705, disc_loss = 0.0010386273413111435
Trained batch 258 in epoch 3, gen_loss = 1.1807308348909769, disc_loss = 0.0010384507820011984
Trained batch 259 in epoch 3, gen_loss = 1.1814054567080277, disc_loss = 0.0010375798067588432
Trained batch 260 in epoch 3, gen_loss = 1.1810065530725822, disc_loss = 0.0010375514064721006
Trained batch 261 in epoch 3, gen_loss = 1.1813672421542742, disc_loss = 0.0010378629104491992
Trained batch 262 in epoch 3, gen_loss = 1.1813897080294533, disc_loss = 0.001037254413087877
Trained batch 263 in epoch 3, gen_loss = 1.1815371450149652, disc_loss = 0.0010378263181006662
Trained batch 264 in epoch 3, gen_loss = 1.1817307436241293, disc_loss = 0.001038409459496901
Trained batch 265 in epoch 3, gen_loss = 1.181884084877215, disc_loss = 0.0010369188548109488
Trained batch 266 in epoch 3, gen_loss = 1.1817407849129666, disc_loss = 0.0010353706020396203
Trained batch 267 in epoch 3, gen_loss = 1.181327714848874, disc_loss = 0.0010345693217866721
Trained batch 268 in epoch 3, gen_loss = 1.182482976895726, disc_loss = 0.0010338794239009056
Trained batch 269 in epoch 3, gen_loss = 1.1832070876050877, disc_loss = 0.0010318531334633009
Trained batch 270 in epoch 3, gen_loss = 1.183247704787448, disc_loss = 0.0010316543227596024
Trained batch 271 in epoch 3, gen_loss = 1.1827626250245993, disc_loss = 0.0010321081579818651
Trained batch 272 in epoch 3, gen_loss = 1.1824795531702565, disc_loss = 0.0010318318457596836
Trained batch 273 in epoch 3, gen_loss = 1.1820730340741847, disc_loss = 0.0010304428019049326
Trained batch 274 in epoch 3, gen_loss = 1.182346863746643, disc_loss = 0.0010298870483794334
Trained batch 275 in epoch 3, gen_loss = 1.1822699001733807, disc_loss = 0.0010321528235985222
Trained batch 276 in epoch 3, gen_loss = 1.181751311901244, disc_loss = 0.001034358092386188
Trained batch 277 in epoch 3, gen_loss = 1.1818234341607676, disc_loss = 0.001034455252966254
Trained batch 278 in epoch 3, gen_loss = 1.1819252185924078, disc_loss = 0.001033355814582538
Trained batch 279 in epoch 3, gen_loss = 1.1812623415674481, disc_loss = 0.0010326410075192274
Trained batch 280 in epoch 3, gen_loss = 1.181350376258117, disc_loss = 0.0010325654847522555
Trained batch 281 in epoch 3, gen_loss = 1.1808765035994508, disc_loss = 0.0010317158942062948
Trained batch 282 in epoch 3, gen_loss = 1.180861663481372, disc_loss = 0.001030963037945429
Trained batch 283 in epoch 3, gen_loss = 1.1812922719498755, disc_loss = 0.0010315557989139358
Trained batch 284 in epoch 3, gen_loss = 1.182523688935397, disc_loss = 0.0010303816659041076
Trained batch 285 in epoch 3, gen_loss = 1.1827241215672526, disc_loss = 0.001030213713146896
Trained batch 286 in epoch 3, gen_loss = 1.1838369365353203, disc_loss = 0.0010304212697354901
Trained batch 287 in epoch 3, gen_loss = 1.1835609301924706, disc_loss = 0.0010296671198375407
Trained batch 288 in epoch 3, gen_loss = 1.1832973726067988, disc_loss = 0.0010303933197385905
Trained batch 289 in epoch 3, gen_loss = 1.184243298810104, disc_loss = 0.001031023229709184
Trained batch 290 in epoch 3, gen_loss = 1.1840004400699, disc_loss = 0.0010295576447760207
Trained batch 291 in epoch 3, gen_loss = 1.1843350480680597, disc_loss = 0.00102769457878647
Trained batch 292 in epoch 3, gen_loss = 1.184399237811769, disc_loss = 0.0010256493230089672
Trained batch 293 in epoch 3, gen_loss = 1.1841234009282118, disc_loss = 0.0010230127422275262
Trained batch 294 in epoch 3, gen_loss = 1.1850647881879646, disc_loss = 0.0010220395476099545
Trained batch 295 in epoch 3, gen_loss = 1.1845870271727845, disc_loss = 0.0010236382670857868
Trained batch 296 in epoch 3, gen_loss = 1.1851553326905375, disc_loss = 0.0010275049139008628
Trained batch 297 in epoch 3, gen_loss = 1.1850218584873533, disc_loss = 0.0010334796435512203
Trained batch 298 in epoch 3, gen_loss = 1.1854162786317908, disc_loss = 0.001042371746978059
Trained batch 299 in epoch 3, gen_loss = 1.1853659522533417, disc_loss = 0.0010442460743555178
Trained batch 300 in epoch 3, gen_loss = 1.1856281088040121, disc_loss = 0.0010420327041757624
Trained batch 301 in epoch 3, gen_loss = 1.1852266962165074, disc_loss = 0.0010398969356632108
Trained batch 302 in epoch 3, gen_loss = 1.1851985128012428, disc_loss = 0.0010376061577382174
Trained batch 303 in epoch 3, gen_loss = 1.1858071253487938, disc_loss = 0.001035484650090343
Trained batch 304 in epoch 3, gen_loss = 1.1861944151706383, disc_loss = 0.0010343263174796508
Trained batch 305 in epoch 3, gen_loss = 1.1856648376564574, disc_loss = 0.0010347683474404763
Trained batch 306 in epoch 3, gen_loss = 1.1852812013719292, disc_loss = 0.0010347760602693811
Trained batch 307 in epoch 3, gen_loss = 1.1847483035805937, disc_loss = 0.0010335541997587175
Trained batch 308 in epoch 3, gen_loss = 1.184531624648949, disc_loss = 0.0010319567114245869
Trained batch 309 in epoch 3, gen_loss = 1.1839201235002088, disc_loss = 0.001031305773968568
Trained batch 310 in epoch 3, gen_loss = 1.1842144371228969, disc_loss = 0.0010315178306002195
Trained batch 311 in epoch 3, gen_loss = 1.1838057530231965, disc_loss = 0.0010307911690734983
Trained batch 312 in epoch 3, gen_loss = 1.1832745897884187, disc_loss = 0.0010301935953830484
Trained batch 313 in epoch 3, gen_loss = 1.1832950585966657, disc_loss = 0.0010296978386583186
Trained batch 314 in epoch 3, gen_loss = 1.1837693259829567, disc_loss = 0.0010307118670815337
Trained batch 315 in epoch 3, gen_loss = 1.1841211658489854, disc_loss = 0.001036517827972752
Trained batch 316 in epoch 3, gen_loss = 1.1839394569396973, disc_loss = 0.001044393375046604
Trained batch 317 in epoch 3, gen_loss = 1.1833940062133022, disc_loss = 0.0010486295020812537
Trained batch 318 in epoch 3, gen_loss = 1.1837213771843984, disc_loss = 0.0010486413389159698
Trained batch 319 in epoch 3, gen_loss = 1.1840538922697306, disc_loss = 0.0010479597821358767
Trained batch 320 in epoch 3, gen_loss = 1.1839600571219424, disc_loss = 0.0010471411078923159
Trained batch 321 in epoch 3, gen_loss = 1.1835324630974242, disc_loss = 0.0010471613071707036
Trained batch 322 in epoch 3, gen_loss = 1.1840217290647996, disc_loss = 0.0010464130274572298
Trained batch 323 in epoch 3, gen_loss = 1.1842274555453547, disc_loss = 0.0010466919609174465
Trained batch 324 in epoch 3, gen_loss = 1.184310105397151, disc_loss = 0.001046281656375728
Trained batch 325 in epoch 3, gen_loss = 1.1839906803669373, disc_loss = 0.001045473910096113
Trained batch 326 in epoch 3, gen_loss = 1.1835333280242546, disc_loss = 0.0010441424077147453
Trained batch 327 in epoch 3, gen_loss = 1.1832847173621015, disc_loss = 0.0010432520585465415
Trained batch 328 in epoch 3, gen_loss = 1.182994341777813, disc_loss = 0.0010411453286134906
Trained batch 329 in epoch 3, gen_loss = 1.1830158193906148, disc_loss = 0.0010396521542023755
Trained batch 330 in epoch 3, gen_loss = 1.1837505022924832, disc_loss = 0.0010380237503962034
Trained batch 331 in epoch 3, gen_loss = 1.1837244769894932, disc_loss = 0.0010360064259723265
Trained batch 332 in epoch 3, gen_loss = 1.183235235758372, disc_loss = 0.0010341051771052393
Trained batch 333 in epoch 3, gen_loss = 1.1835391514315576, disc_loss = 0.0010325467930430501
Trained batch 334 in epoch 3, gen_loss = 1.183831880341715, disc_loss = 0.0010349632907179253
Trained batch 335 in epoch 3, gen_loss = 1.183852039632343, disc_loss = 0.0010379366464933679
Trained batch 336 in epoch 3, gen_loss = 1.1835723167357175, disc_loss = 0.0010371462490170564
Trained batch 337 in epoch 3, gen_loss = 1.18307885051479, disc_loss = 0.0010353373531520797
Trained batch 338 in epoch 3, gen_loss = 1.1833048025063708, disc_loss = 0.0010339490909460427
Trained batch 339 in epoch 3, gen_loss = 1.1834798914544722, disc_loss = 0.0010341639966902543
Trained batch 340 in epoch 3, gen_loss = 1.1834852559126017, disc_loss = 0.001035373819847878
Trained batch 341 in epoch 3, gen_loss = 1.1838930636121516, disc_loss = 0.0010366820232780671
Trained batch 342 in epoch 3, gen_loss = 1.1835636682482573, disc_loss = 0.0010361030750260377
Trained batch 343 in epoch 3, gen_loss = 1.1833377882491711, disc_loss = 0.0010338842728869653
Trained batch 344 in epoch 3, gen_loss = 1.1831757973933565, disc_loss = 0.0010323683116281325
Trained batch 345 in epoch 3, gen_loss = 1.1825318203840642, disc_loss = 0.0010315422240390329
Trained batch 346 in epoch 3, gen_loss = 1.1834191566585464, disc_loss = 0.0010307570063054121
Trained batch 347 in epoch 3, gen_loss = 1.1836732925697304, disc_loss = 0.0010298532200475417
Trained batch 348 in epoch 3, gen_loss = 1.1839774315883231, disc_loss = 0.0010277690444465855
Trained batch 349 in epoch 3, gen_loss = 1.1837211791106632, disc_loss = 0.00102759093869411
Trained batch 350 in epoch 3, gen_loss = 1.183768457666761, disc_loss = 0.0010267193614076717
Trained batch 351 in epoch 3, gen_loss = 1.1835526368496092, disc_loss = 0.001024738623775854
Trained batch 352 in epoch 3, gen_loss = 1.1836929603271376, disc_loss = 0.0010235365561807196
Trained batch 353 in epoch 3, gen_loss = 1.1837469974143358, disc_loss = 0.0010227194312587644
Trained batch 354 in epoch 3, gen_loss = 1.1839275291268254, disc_loss = 0.001021607224517961
Trained batch 355 in epoch 3, gen_loss = 1.1839304685257794, disc_loss = 0.0010203497748059388
Trained batch 356 in epoch 3, gen_loss = 1.1839218258189887, disc_loss = 0.0010187169436674502
Trained batch 357 in epoch 3, gen_loss = 1.184239168906345, disc_loss = 0.001016494456185002
Trained batch 358 in epoch 3, gen_loss = 1.184018328163285, disc_loss = 0.0010146692123304284
Trained batch 359 in epoch 3, gen_loss = 1.1832611658506924, disc_loss = 0.0010136573720147782
Trained batch 360 in epoch 3, gen_loss = 1.1829989895926287, disc_loss = 0.0010127294398270226
Trained batch 361 in epoch 3, gen_loss = 1.1834425318636288, disc_loss = 0.0010113590098666644
Trained batch 362 in epoch 3, gen_loss = 1.1831276415136562, disc_loss = 0.0010097472551317255
Trained batch 363 in epoch 3, gen_loss = 1.1834802223103387, disc_loss = 0.0010089530612106671
Trained batch 364 in epoch 3, gen_loss = 1.183486161329975, disc_loss = 0.001008109478535105
Trained batch 365 in epoch 3, gen_loss = 1.1841259932583148, disc_loss = 0.0010063329126617153
Trained batch 366 in epoch 3, gen_loss = 1.1849656863498428, disc_loss = 0.0010044700255153107
Trained batch 367 in epoch 3, gen_loss = 1.185117419809103, disc_loss = 0.0010030327459547982
Trained batch 368 in epoch 3, gen_loss = 1.1852378808062898, disc_loss = 0.0010016719907046444
Trained batch 369 in epoch 3, gen_loss = 1.1855769242789294, disc_loss = 0.0010000043368514476
Trained batch 370 in epoch 3, gen_loss = 1.185309671488091, disc_loss = 0.0009980000518802102
Trained batch 371 in epoch 3, gen_loss = 1.185496168591643, disc_loss = 0.000996901782796598
Trained batch 372 in epoch 3, gen_loss = 1.1850129019159414, disc_loss = 0.000996385237524141
Trained batch 373 in epoch 3, gen_loss = 1.1850558214965352, disc_loss = 0.0009972505407771445
Trained batch 374 in epoch 3, gen_loss = 1.1849290954271952, disc_loss = 0.0009987661344930529
Trained batch 375 in epoch 3, gen_loss = 1.185184567374118, disc_loss = 0.0009986645182312288
Trained batch 376 in epoch 3, gen_loss = 1.1854365177116597, disc_loss = 0.00099746611053297
Trained batch 377 in epoch 3, gen_loss = 1.184980247544233, disc_loss = 0.0009969060426878512
Trained batch 378 in epoch 3, gen_loss = 1.1846383053583331, disc_loss = 0.0009955125378621717
Trained batch 379 in epoch 3, gen_loss = 1.1843845547814118, disc_loss = 0.0009961740175066026
Trained batch 380 in epoch 3, gen_loss = 1.1843418247430657, disc_loss = 0.000998517814620332
Trained batch 381 in epoch 3, gen_loss = 1.183991171770695, disc_loss = 0.000998304130116975
Trained batch 382 in epoch 3, gen_loss = 1.1842138840386514, disc_loss = 0.0009989827854908983
Trained batch 383 in epoch 3, gen_loss = 1.1841741953976452, disc_loss = 0.001006619912914175
Trained batch 384 in epoch 3, gen_loss = 1.1839176965998364, disc_loss = 0.001011179975693586
Trained batch 385 in epoch 3, gen_loss = 1.183791362405441, disc_loss = 0.0010143524169116016
Trained batch 386 in epoch 3, gen_loss = 1.1845143505153113, disc_loss = 0.0010160488032589087
Trained batch 387 in epoch 3, gen_loss = 1.184430639000283, disc_loss = 0.0010160196961993447
Trained batch 388 in epoch 3, gen_loss = 1.1838708763563848, disc_loss = 0.0010163199819701037
Trained batch 389 in epoch 3, gen_loss = 1.183905139641884, disc_loss = 0.0010161983643252497
Trained batch 390 in epoch 3, gen_loss = 1.183814737193115, disc_loss = 0.0010155556914622865
Trained batch 391 in epoch 3, gen_loss = 1.183478831332557, disc_loss = 0.0010146987908080276
Trained batch 392 in epoch 3, gen_loss = 1.1830350027132883, disc_loss = 0.0010141911242529276
Trained batch 393 in epoch 3, gen_loss = 1.1829186317884377, disc_loss = 0.0010144253461420781
Trained batch 394 in epoch 3, gen_loss = 1.1826975487455538, disc_loss = 0.001014112635910558
Trained batch 395 in epoch 3, gen_loss = 1.1827690345470352, disc_loss = 0.0010132362858528705
Trained batch 396 in epoch 3, gen_loss = 1.1830909543433779, disc_loss = 0.0010122964058953434
Trained batch 397 in epoch 3, gen_loss = 1.1832905893948809, disc_loss = 0.0010113909752248558
Trained batch 398 in epoch 3, gen_loss = 1.1831130112024177, disc_loss = 0.0010108121730303182
Trained batch 399 in epoch 3, gen_loss = 1.1827990451455117, disc_loss = 0.0010117425711359828
Trained batch 400 in epoch 3, gen_loss = 1.1827214896827565, disc_loss = 0.0010134136136458662
Trained batch 401 in epoch 3, gen_loss = 1.1825508030492868, disc_loss = 0.0010140620919746064
Trained batch 402 in epoch 3, gen_loss = 1.1828602839344489, disc_loss = 0.0010130230751045732
Trained batch 403 in epoch 3, gen_loss = 1.1829221664678933, disc_loss = 0.001012268058072757
Trained batch 404 in epoch 3, gen_loss = 1.1825865783809144, disc_loss = 0.0010116316478722442
Trained batch 405 in epoch 3, gen_loss = 1.1826576581729458, disc_loss = 0.0010108089410261769
Trained batch 406 in epoch 3, gen_loss = 1.181984368354741, disc_loss = 0.0010122610863895413
Trained batch 407 in epoch 3, gen_loss = 1.1823796816900665, disc_loss = 0.0010148513859295396
Trained batch 408 in epoch 3, gen_loss = 1.1819989287765802, disc_loss = 0.0010148538790317593
Trained batch 409 in epoch 3, gen_loss = 1.1819006626198931, disc_loss = 0.0010133954691388303
Trained batch 410 in epoch 3, gen_loss = 1.1820885482495718, disc_loss = 0.001012672024590378
Trained batch 411 in epoch 3, gen_loss = 1.1818913938929734, disc_loss = 0.0010147809855005866
Trained batch 412 in epoch 3, gen_loss = 1.1817319878077104, disc_loss = 0.0010178762732031947
Trained batch 413 in epoch 3, gen_loss = 1.1819112384376895, disc_loss = 0.0010219581277140053
Trained batch 414 in epoch 3, gen_loss = 1.1820869198764663, disc_loss = 0.0010272970192375626
Trained batch 415 in epoch 3, gen_loss = 1.1820038665945714, disc_loss = 0.0010323757618467566
Trained batch 416 in epoch 3, gen_loss = 1.1823664629202095, disc_loss = 0.001038672713430518
Trained batch 417 in epoch 3, gen_loss = 1.1822930859606802, disc_loss = 0.0010430572384441468
Trained batch 418 in epoch 3, gen_loss = 1.182710847877375, disc_loss = 0.0010445203241333143
Trained batch 419 in epoch 3, gen_loss = 1.1824915976751418, disc_loss = 0.0010458318227652592
Trained batch 420 in epoch 3, gen_loss = 1.1823533807401136, disc_loss = 0.0010483524448380997
Trained batch 421 in epoch 3, gen_loss = 1.1821152573513194, disc_loss = 0.001050122681068879
Trained batch 422 in epoch 3, gen_loss = 1.181490810627633, disc_loss = 0.0010521653590335272
Trained batch 423 in epoch 3, gen_loss = 1.1820508088424522, disc_loss = 0.0010537406138472812
Trained batch 424 in epoch 3, gen_loss = 1.1824021419356852, disc_loss = 0.0010535476345103234
Trained batch 425 in epoch 3, gen_loss = 1.1820786218967796, disc_loss = 0.0010531329425645362
Trained batch 426 in epoch 3, gen_loss = 1.1816646956448253, disc_loss = 0.0010522205205508823
Trained batch 427 in epoch 3, gen_loss = 1.182104615825359, disc_loss = 0.0010508798328271814
Trained batch 428 in epoch 3, gen_loss = 1.1817856603291208, disc_loss = 0.0010492913690905818
Trained batch 429 in epoch 3, gen_loss = 1.181703103281731, disc_loss = 0.001047670975500761
Trained batch 430 in epoch 3, gen_loss = 1.181042858315178, disc_loss = 0.0010465973354238593
Trained batch 431 in epoch 3, gen_loss = 1.1814380824841835, disc_loss = 0.0010458340197887824
Trained batch 432 in epoch 3, gen_loss = 1.18119411118862, disc_loss = 0.0010446798331674198
Trained batch 433 in epoch 3, gen_loss = 1.1812784717104952, disc_loss = 0.0010427516194858185
Trained batch 434 in epoch 3, gen_loss = 1.1811651812202628, disc_loss = 0.0010422960089334962
Trained batch 435 in epoch 3, gen_loss = 1.1819215822930729, disc_loss = 0.001043759863640752
Trained batch 436 in epoch 3, gen_loss = 1.1820216867689137, disc_loss = 0.001043227161258167
Trained batch 437 in epoch 3, gen_loss = 1.1817505649507862, disc_loss = 0.0010421855261081034
Trained batch 438 in epoch 3, gen_loss = 1.1816613029238847, disc_loss = 0.0010410088539992805
Trained batch 439 in epoch 3, gen_loss = 1.181496487557888, disc_loss = 0.001040969024358095
Trained batch 440 in epoch 3, gen_loss = 1.1820904128675829, disc_loss = 0.0010438530796348453
Trained batch 441 in epoch 3, gen_loss = 1.1818018300770634, disc_loss = 0.0010470362101685218
Trained batch 442 in epoch 3, gen_loss = 1.1817809896329186, disc_loss = 0.001048035079761278
Trained batch 443 in epoch 3, gen_loss = 1.18122966802335, disc_loss = 0.0010476784735982546
Trained batch 444 in epoch 3, gen_loss = 1.181306589185522, disc_loss = 0.001049338058624783
Trained batch 445 in epoch 3, gen_loss = 1.1808041454430653, disc_loss = 0.0010531332494621583
Trained batch 446 in epoch 3, gen_loss = 1.1813462396596102, disc_loss = 0.001056411920652633
Trained batch 447 in epoch 3, gen_loss = 1.180975588570748, disc_loss = 0.0010577542752473943
Trained batch 448 in epoch 3, gen_loss = 1.1810225699685994, disc_loss = 0.0010568711924237534
Trained batch 449 in epoch 3, gen_loss = 1.1809333448939854, disc_loss = 0.0010576944594827688
Trained batch 450 in epoch 3, gen_loss = 1.1807646690609714, disc_loss = 0.0010590313835636901
Trained batch 451 in epoch 3, gen_loss = 1.1804483258618719, disc_loss = 0.0010582996549770396
Trained batch 452 in epoch 3, gen_loss = 1.1800954215573949, disc_loss = 0.0010587207729315024
Trained batch 453 in epoch 3, gen_loss = 1.1796495138548544, disc_loss = 0.0010611101250522688
Trained batch 454 in epoch 3, gen_loss = 1.1803877318298424, disc_loss = 0.0010635613275443686
Trained batch 455 in epoch 3, gen_loss = 1.1804561062078727, disc_loss = 0.0010636691421128937
Trained batch 456 in epoch 3, gen_loss = 1.1804121342738296, disc_loss = 0.0010637574477558873
Trained batch 457 in epoch 3, gen_loss = 1.1804889936374265, disc_loss = 0.0010645791457589272
Trained batch 458 in epoch 3, gen_loss = 1.180372203746912, disc_loss = 0.0010650348224084162
Trained batch 459 in epoch 3, gen_loss = 1.1799747525349906, disc_loss = 0.001065319037898798
Trained batch 460 in epoch 3, gen_loss = 1.1805368588182776, disc_loss = 0.001065288696213577
Trained batch 461 in epoch 3, gen_loss = 1.1801356333932835, disc_loss = 0.0010658892974178347
Trained batch 462 in epoch 3, gen_loss = 1.1799685181345847, disc_loss = 0.0010694018973389108
Trained batch 463 in epoch 3, gen_loss = 1.1798434759779224, disc_loss = 0.0010736114943562104
Trained batch 464 in epoch 3, gen_loss = 1.1794690100095606, disc_loss = 0.0010748191862755144
Trained batch 465 in epoch 3, gen_loss = 1.1797181090316036, disc_loss = 0.001074316498043781
Trained batch 466 in epoch 3, gen_loss = 1.1792767079790347, disc_loss = 0.0010742864827214137
Trained batch 467 in epoch 3, gen_loss = 1.179338802766596, disc_loss = 0.0010754550625527832
Trained batch 468 in epoch 3, gen_loss = 1.1792585396054964, disc_loss = 0.0010750759170509315
Trained batch 469 in epoch 3, gen_loss = 1.1793688638413207, disc_loss = 0.0010737712198107979
Trained batch 470 in epoch 3, gen_loss = 1.1794925486459347, disc_loss = 0.0010732605596650846
Trained batch 471 in epoch 3, gen_loss = 1.1796461233900766, disc_loss = 0.0010729973645985887
Trained batch 472 in epoch 3, gen_loss = 1.1795937345849534, disc_loss = 0.0010723926780224103
Trained batch 473 in epoch 3, gen_loss = 1.179537218457033, disc_loss = 0.0010715339851100488
Trained batch 474 in epoch 3, gen_loss = 1.179005752864637, disc_loss = 0.0010701890111177866
Trained batch 475 in epoch 3, gen_loss = 1.1789399435540207, disc_loss = 0.0010687498095557349
Trained batch 476 in epoch 3, gen_loss = 1.1785878100485172, disc_loss = 0.001067234004526282
Trained batch 477 in epoch 3, gen_loss = 1.1787577099381132, disc_loss = 0.0010655381850799386
Trained batch 478 in epoch 3, gen_loss = 1.1788347200461369, disc_loss = 0.0010640476430809546
Trained batch 479 in epoch 3, gen_loss = 1.1786561879018942, disc_loss = 0.0010635072872598053
Trained batch 480 in epoch 3, gen_loss = 1.1788089994085553, disc_loss = 0.001062512293966485
Trained batch 481 in epoch 3, gen_loss = 1.1787319608743754, disc_loss = 0.0010610238059447533
Trained batch 482 in epoch 3, gen_loss = 1.1784046098559047, disc_loss = 0.0010609183669021338
Trained batch 483 in epoch 3, gen_loss = 1.178863850014269, disc_loss = 0.0010602202439694646
Trained batch 484 in epoch 3, gen_loss = 1.1791028376707096, disc_loss = 0.0010589613599316266
Trained batch 485 in epoch 3, gen_loss = 1.1795405487955353, disc_loss = 0.0010573979223244287
Trained batch 486 in epoch 3, gen_loss = 1.1793148684061039, disc_loss = 0.001056520965946427
Trained batch 487 in epoch 3, gen_loss = 1.1794734333382277, disc_loss = 0.0010553763118192276
Trained batch 488 in epoch 3, gen_loss = 1.1795155260948071, disc_loss = 0.0010541963341547337
Trained batch 489 in epoch 3, gen_loss = 1.1792626015994014, disc_loss = 0.0010531990812932216
Trained batch 490 in epoch 3, gen_loss = 1.1790633383690703, disc_loss = 0.0010521485391815047
Trained batch 491 in epoch 3, gen_loss = 1.1793269815483713, disc_loss = 0.001050993614685504
Trained batch 492 in epoch 3, gen_loss = 1.1795044694904382, disc_loss = 0.0010497320250527269
Trained batch 493 in epoch 3, gen_loss = 1.1793068159929654, disc_loss = 0.0010485589746204356
Trained batch 494 in epoch 3, gen_loss = 1.1794884358993685, disc_loss = 0.0010474686242458928
Trained batch 495 in epoch 3, gen_loss = 1.1792906027647756, disc_loss = 0.0010460773975512806
Trained batch 496 in epoch 3, gen_loss = 1.1793139635677068, disc_loss = 0.0010446287378360999
Trained batch 497 in epoch 3, gen_loss = 1.179466027332597, disc_loss = 0.0010431439712623519
Trained batch 498 in epoch 3, gen_loss = 1.1794202963192622, disc_loss = 0.0010419721700396214
Trained batch 499 in epoch 3, gen_loss = 1.179163775205612, disc_loss = 0.0010406621315923986
Trained batch 500 in epoch 3, gen_loss = 1.1787295478308748, disc_loss = 0.0010403662007903874
Trained batch 501 in epoch 3, gen_loss = 1.1785932414797673, disc_loss = 0.0010390701094460007
Trained batch 502 in epoch 3, gen_loss = 1.1788853161614647, disc_loss = 0.001037934460732984
Trained batch 503 in epoch 3, gen_loss = 1.1787020456459787, disc_loss = 0.001036918906561729
Trained batch 504 in epoch 3, gen_loss = 1.1784920646412538, disc_loss = 0.001036296104856693
Trained batch 505 in epoch 3, gen_loss = 1.1785060060118497, disc_loss = 0.001035770750173189
Trained batch 506 in epoch 3, gen_loss = 1.1781714683218585, disc_loss = 0.0010355566094707076
Trained batch 507 in epoch 3, gen_loss = 1.1785964577451467, disc_loss = 0.0010349203873525178
Trained batch 508 in epoch 3, gen_loss = 1.178381366790629, disc_loss = 0.001034237870751891
Trained batch 509 in epoch 3, gen_loss = 1.1780765249448664, disc_loss = 0.001035957223782544
Trained batch 510 in epoch 3, gen_loss = 1.1775762162329866, disc_loss = 0.0010402586011577365
Trained batch 511 in epoch 3, gen_loss = 1.1774496149737388, disc_loss = 0.0010449873912250496
Trained batch 512 in epoch 3, gen_loss = 1.1770604005333973, disc_loss = 0.001048354744271477
Trained batch 513 in epoch 3, gen_loss = 1.1770803854159344, disc_loss = 0.0010493262159352278
Trained batch 514 in epoch 3, gen_loss = 1.1773078129129502, disc_loss = 0.001050335525572345
Trained batch 515 in epoch 3, gen_loss = 1.1774184798547465, disc_loss = 0.001053255275208837
Trained batch 516 in epoch 3, gen_loss = 1.1770160048335387, disc_loss = 0.001058267844270967
Trained batch 517 in epoch 3, gen_loss = 1.1766903922824785, disc_loss = 0.0010671298389341485
Trained batch 518 in epoch 3, gen_loss = 1.1768219578932246, disc_loss = 0.0010815746665302833
Trained batch 519 in epoch 3, gen_loss = 1.176600943849637, disc_loss = 0.0010957236809470208
Trained batch 520 in epoch 3, gen_loss = 1.1766754752614905, disc_loss = 0.0011148851936258065
Trained batch 521 in epoch 3, gen_loss = 1.1768348459083002, disc_loss = 0.0011340636395417972
Trained batch 522 in epoch 3, gen_loss = 1.17655535227482, disc_loss = 0.0011400689543049024
Trained batch 523 in epoch 3, gen_loss = 1.176091769041906, disc_loss = 0.0011409982454437383
Trained batch 524 in epoch 3, gen_loss = 1.1756812986873446, disc_loss = 0.001141459842994144
Trained batch 525 in epoch 3, gen_loss = 1.1757469622581178, disc_loss = 0.0011433228578858038
Trained batch 526 in epoch 3, gen_loss = 1.175727848196844, disc_loss = 0.0011439310736961724
Trained batch 527 in epoch 3, gen_loss = 1.175947213150335, disc_loss = 0.0011441524036744147
Trained batch 528 in epoch 3, gen_loss = 1.1759639767708083, disc_loss = 0.001145230216267501
Trained batch 529 in epoch 3, gen_loss = 1.176404743262057, disc_loss = 0.0011455991455048482
Trained batch 530 in epoch 3, gen_loss = 1.1764709941635922, disc_loss = 0.0011456247499195523
Trained batch 531 in epoch 3, gen_loss = 1.1765447887486982, disc_loss = 0.0011464374860553018
Trained batch 532 in epoch 3, gen_loss = 1.176435273874544, disc_loss = 0.0011465753744302604
Trained batch 533 in epoch 3, gen_loss = 1.1764810041765148, disc_loss = 0.0011463128403363285
Trained batch 534 in epoch 3, gen_loss = 1.1767539754092136, disc_loss = 0.0011461849803394402
Trained batch 535 in epoch 3, gen_loss = 1.1769197719977862, disc_loss = 0.0011464155122123871
Trained batch 536 in epoch 3, gen_loss = 1.1768139080184354, disc_loss = 0.0011469469045245937
Trained batch 537 in epoch 3, gen_loss = 1.1770230324516509, disc_loss = 0.0011467710527131372
Trained batch 538 in epoch 3, gen_loss = 1.1767178542759953, disc_loss = 0.0011466447707425011
Trained batch 539 in epoch 3, gen_loss = 1.1766071329514185, disc_loss = 0.0011472755715658423
Trained batch 540 in epoch 3, gen_loss = 1.176490778072484, disc_loss = 0.001148727218528595
Trained batch 541 in epoch 3, gen_loss = 1.1764115415156107, disc_loss = 0.001148572069623059
Trained batch 542 in epoch 3, gen_loss = 1.1762645801127944, disc_loss = 0.001147275769213278
Trained batch 543 in epoch 3, gen_loss = 1.1763336517135887, disc_loss = 0.0011463013500039832
Trained batch 544 in epoch 3, gen_loss = 1.1757974443085697, disc_loss = 0.0011453408837359005
Trained batch 545 in epoch 3, gen_loss = 1.1759026775429973, disc_loss = 0.0011442319302972757
Trained batch 546 in epoch 3, gen_loss = 1.1756150421756277, disc_loss = 0.0011441317106581376
Trained batch 547 in epoch 3, gen_loss = 1.1759562218276254, disc_loss = 0.0011431315620793081
Trained batch 548 in epoch 3, gen_loss = 1.1757167634199661, disc_loss = 0.0011419184551901271
Trained batch 549 in epoch 3, gen_loss = 1.17561138456518, disc_loss = 0.0011408018157552844
Trained batch 550 in epoch 3, gen_loss = 1.1755961168915736, disc_loss = 0.0011400670675337297
Trained batch 551 in epoch 3, gen_loss = 1.175772713146348, disc_loss = 0.00113951792527455
Trained batch 552 in epoch 3, gen_loss = 1.175676235885344, disc_loss = 0.0011388962798881148
Trained batch 553 in epoch 3, gen_loss = 1.175661124907676, disc_loss = 0.001138212636048235
Trained batch 554 in epoch 3, gen_loss = 1.1755662424070341, disc_loss = 0.001137076181580883
Trained batch 555 in epoch 3, gen_loss = 1.1756831079507046, disc_loss = 0.001135549047477535
Trained batch 556 in epoch 3, gen_loss = 1.1760506212604325, disc_loss = 0.0011344166994594368
Trained batch 557 in epoch 3, gen_loss = 1.1763397957261745, disc_loss = 0.0011343611759752432
Trained batch 558 in epoch 3, gen_loss = 1.1766854223923522, disc_loss = 0.0011346823043489416
Trained batch 559 in epoch 3, gen_loss = 1.176567826952253, disc_loss = 0.001133948714699987
Trained batch 560 in epoch 3, gen_loss = 1.1766759044558819, disc_loss = 0.0011327420972728
Trained batch 561 in epoch 3, gen_loss = 1.176337342563473, disc_loss = 0.0011313259806925201
Trained batch 562 in epoch 3, gen_loss = 1.176122910917123, disc_loss = 0.0011304280267861715
Trained batch 563 in epoch 3, gen_loss = 1.1762742208884962, disc_loss = 0.0011294743700536276
Trained batch 564 in epoch 3, gen_loss = 1.17635262402813, disc_loss = 0.0011290238246340221
Trained batch 565 in epoch 3, gen_loss = 1.175878035095471, disc_loss = 0.0011281351253273897
Trained batch 566 in epoch 3, gen_loss = 1.1757226385557251, disc_loss = 0.0011271647680101168
Trained batch 567 in epoch 3, gen_loss = 1.1753711635378046, disc_loss = 0.0011263632260496207
Trained batch 568 in epoch 3, gen_loss = 1.1754865966907495, disc_loss = 0.0011250238394479699
Trained batch 569 in epoch 3, gen_loss = 1.1752481171959326, disc_loss = 0.0011243552321071834
Trained batch 570 in epoch 3, gen_loss = 1.1752894958138675, disc_loss = 0.001125080497135594
Trained batch 571 in epoch 3, gen_loss = 1.1750100888572372, disc_loss = 0.0011256204906476977
Trained batch 572 in epoch 3, gen_loss = 1.1747743284515062, disc_loss = 0.0011250817519500868
Trained batch 573 in epoch 3, gen_loss = 1.1752541331048627, disc_loss = 0.0011277769944796465
Trained batch 574 in epoch 3, gen_loss = 1.1756893354913462, disc_loss = 0.001129466791298119
Trained batch 575 in epoch 3, gen_loss = 1.175708258110616, disc_loss = 0.0011290193358996072
Trained batch 576 in epoch 3, gen_loss = 1.1759705562112237, disc_loss = 0.001128091074574127
Trained batch 577 in epoch 3, gen_loss = 1.175855925132659, disc_loss = 0.0011275208060547892
Trained batch 578 in epoch 3, gen_loss = 1.1762967877643302, disc_loss = 0.001126761013117783
Trained batch 579 in epoch 3, gen_loss = 1.1761957832451524, disc_loss = 0.0011266483862308288
Trained batch 580 in epoch 3, gen_loss = 1.1761880776557987, disc_loss = 0.0011272880144983534
Trained batch 581 in epoch 3, gen_loss = 1.1764126639185901, disc_loss = 0.00112783237088082
Trained batch 582 in epoch 3, gen_loss = 1.176575571963145, disc_loss = 0.0011279183280613117
Trained batch 583 in epoch 3, gen_loss = 1.176518202236254, disc_loss = 0.0011271027307560722
Trained batch 584 in epoch 3, gen_loss = 1.176073251116989, disc_loss = 0.0011264143877067706
Trained batch 585 in epoch 3, gen_loss = 1.175887258081306, disc_loss = 0.0011267177422132435
Trained batch 586 in epoch 3, gen_loss = 1.175474300193624, disc_loss = 0.0011275375572128818
Trained batch 587 in epoch 3, gen_loss = 1.1751064239513307, disc_loss = 0.0011273687926398632
Trained batch 588 in epoch 3, gen_loss = 1.1749739060984807, disc_loss = 0.0011276031728149653
Trained batch 589 in epoch 3, gen_loss = 1.1748652754193645, disc_loss = 0.0011273919294195612
Trained batch 590 in epoch 3, gen_loss = 1.1746108547079988, disc_loss = 0.0011274286751115738
Trained batch 591 in epoch 3, gen_loss = 1.1743928434679638, disc_loss = 0.001127296581954225
Trained batch 592 in epoch 3, gen_loss = 1.1741986736077281, disc_loss = 0.0011267945976328327
Trained batch 593 in epoch 3, gen_loss = 1.1743035355601648, disc_loss = 0.001125858956541253
Trained batch 594 in epoch 3, gen_loss = 1.174101313322532, disc_loss = 0.0011248340393160273
Trained batch 595 in epoch 3, gen_loss = 1.1742241909639948, disc_loss = 0.0011236285251940697
Trained batch 596 in epoch 3, gen_loss = 1.174685737895007, disc_loss = 0.0011231732815108223
Trained batch 597 in epoch 3, gen_loss = 1.1748181151905188, disc_loss = 0.0011233756454035804
Trained batch 598 in epoch 3, gen_loss = 1.1747623692967857, disc_loss = 0.0011222255136594192
Trained batch 599 in epoch 3, gen_loss = 1.174775051176548, disc_loss = 0.0011212651227106107
Trained batch 600 in epoch 3, gen_loss = 1.1746061243947452, disc_loss = 0.001122318928719021
Trained batch 601 in epoch 3, gen_loss = 1.1742062993421902, disc_loss = 0.001122811891296546
Trained batch 602 in epoch 3, gen_loss = 1.1739134336783124, disc_loss = 0.0011230796359753188
Trained batch 603 in epoch 3, gen_loss = 1.173829796199767, disc_loss = 0.0011229117946448314
Trained batch 604 in epoch 3, gen_loss = 1.1738268295595469, disc_loss = 0.0011216173699166057
Trained batch 605 in epoch 3, gen_loss = 1.1739246431160288, disc_loss = 0.001120831324664527
Trained batch 606 in epoch 3, gen_loss = 1.1740737928590037, disc_loss = 0.0011214703180540669
Trained batch 607 in epoch 3, gen_loss = 1.1737558252521252, disc_loss = 0.001122136212224608
Trained batch 608 in epoch 3, gen_loss = 1.1737473317359273, disc_loss = 0.0011213601784819235
Trained batch 609 in epoch 3, gen_loss = 1.1744418696301882, disc_loss = 0.0011203086923294487
Trained batch 610 in epoch 3, gen_loss = 1.174706943979435, disc_loss = 0.001119254194744009
Trained batch 611 in epoch 3, gen_loss = 1.1745265059027017, disc_loss = 0.0011183215882102243
Trained batch 612 in epoch 3, gen_loss = 1.1742483148955987, disc_loss = 0.0011170187844774422
Trained batch 613 in epoch 3, gen_loss = 1.1741176491257421, disc_loss = 0.0011160285188162363
Trained batch 614 in epoch 3, gen_loss = 1.1746492239517894, disc_loss = 0.001115129411583047
Trained batch 615 in epoch 3, gen_loss = 1.175075221468102, disc_loss = 0.0011140484815320172
Trained batch 616 in epoch 3, gen_loss = 1.17495154977038, disc_loss = 0.001112895052374576
Trained batch 617 in epoch 3, gen_loss = 1.1748138072999936, disc_loss = 0.0011121651703692615
Trained batch 618 in epoch 3, gen_loss = 1.1746764707834925, disc_loss = 0.0011111404887588262
Trained batch 619 in epoch 3, gen_loss = 1.1749812542430815, disc_loss = 0.0011099525143142654
Trained batch 620 in epoch 3, gen_loss = 1.174892027500939, disc_loss = 0.0011091601739188764
Trained batch 621 in epoch 3, gen_loss = 1.1747260585283543, disc_loss = 0.0011082309147504375
Trained batch 622 in epoch 3, gen_loss = 1.1746004665835519, disc_loss = 0.001107067048446317
Trained batch 623 in epoch 3, gen_loss = 1.1744040341522448, disc_loss = 0.0011060343498544311
Trained batch 624 in epoch 3, gen_loss = 1.174455417728424, disc_loss = 0.0011051149948267266
Trained batch 625 in epoch 3, gen_loss = 1.1741379995506032, disc_loss = 0.0011041946157531518
Trained batch 626 in epoch 3, gen_loss = 1.1741408878726443, disc_loss = 0.0011028554315366478
Trained batch 627 in epoch 3, gen_loss = 1.1738660114396149, disc_loss = 0.0011022327452552116
Trained batch 628 in epoch 3, gen_loss = 1.1746696564465144, disc_loss = 0.001102500779006226
Trained batch 629 in epoch 3, gen_loss = 1.1745191213630495, disc_loss = 0.001103588134038358
Trained batch 630 in epoch 3, gen_loss = 1.1745592634386948, disc_loss = 0.0011034057284076218
Trained batch 631 in epoch 3, gen_loss = 1.1747503602240659, disc_loss = 0.0011027878400811828
Trained batch 632 in epoch 3, gen_loss = 1.1746811786722422, disc_loss = 0.0011029802682788565
Trained batch 633 in epoch 3, gen_loss = 1.1749788489815565, disc_loss = 0.0011027587662120085
Trained batch 634 in epoch 3, gen_loss = 1.1747687825067776, disc_loss = 0.001101800857187894
Trained batch 635 in epoch 3, gen_loss = 1.1745243114682864, disc_loss = 0.0011009231738337247
Trained batch 636 in epoch 3, gen_loss = 1.1743615039476607, disc_loss = 0.001100378367844991
Trained batch 637 in epoch 3, gen_loss = 1.1744299281540336, disc_loss = 0.0010995276471507608
Trained batch 638 in epoch 3, gen_loss = 1.1742581534833416, disc_loss = 0.0010992553350302509
Trained batch 639 in epoch 3, gen_loss = 1.174099297914654, disc_loss = 0.0010995405897801902
Trained batch 640 in epoch 3, gen_loss = 1.1740147309630597, disc_loss = 0.0010989173091851777
Trained batch 641 in epoch 3, gen_loss = 1.1740075367447744, disc_loss = 0.0010978683642852642
Trained batch 642 in epoch 3, gen_loss = 1.1738840676206823, disc_loss = 0.0010969159067280715
Trained batch 643 in epoch 3, gen_loss = 1.173630479977738, disc_loss = 0.001096534773830132
Trained batch 644 in epoch 3, gen_loss = 1.1738842101984246, disc_loss = 0.0010963411089132157
Trained batch 645 in epoch 3, gen_loss = 1.1737172445830177, disc_loss = 0.0010952908381426508
Trained batch 646 in epoch 3, gen_loss = 1.1734603659078549, disc_loss = 0.0010942800296497512
Trained batch 647 in epoch 3, gen_loss = 1.1734692309925585, disc_loss = 0.0010935224325316715
Trained batch 648 in epoch 3, gen_loss = 1.1733779393836787, disc_loss = 0.0010927905464135556
Trained batch 649 in epoch 3, gen_loss = 1.1734150564670562, disc_loss = 0.001091664731301045
Trained batch 650 in epoch 3, gen_loss = 1.1733968053728387, disc_loss = 0.0010907662829758669
Trained batch 651 in epoch 3, gen_loss = 1.1731885186185134, disc_loss = 0.0010897168544636384
Trained batch 652 in epoch 3, gen_loss = 1.173426866987763, disc_loss = 0.0010886879188889654
Trained batch 653 in epoch 3, gen_loss = 1.173426769104208, disc_loss = 0.0010878452284228475
Trained batch 654 in epoch 3, gen_loss = 1.1737749823177135, disc_loss = 0.0010870348932070458
Trained batch 655 in epoch 3, gen_loss = 1.1737721176227418, disc_loss = 0.001086009761554412
Trained batch 656 in epoch 3, gen_loss = 1.1735788885861227, disc_loss = 0.0010857676302979075
Trained batch 657 in epoch 3, gen_loss = 1.173900718112847, disc_loss = 0.0010869071574424857
Trained batch 658 in epoch 3, gen_loss = 1.1737785524772042, disc_loss = 0.0010909759415900448
Trained batch 659 in epoch 3, gen_loss = 1.173492435614268, disc_loss = 0.001098243373372966
Trained batch 660 in epoch 3, gen_loss = 1.1732884382155586, disc_loss = 0.001101420630575665
Trained batch 661 in epoch 3, gen_loss = 1.173065348874406, disc_loss = 0.0011018940135796155
Trained batch 662 in epoch 3, gen_loss = 1.172974148127468, disc_loss = 0.0011020135165406054
Trained batch 663 in epoch 3, gen_loss = 1.1727770423314658, disc_loss = 0.001101818277521784
Trained batch 664 in epoch 3, gen_loss = 1.1725872276420881, disc_loss = 0.0011008187615762543
Trained batch 665 in epoch 3, gen_loss = 1.1724071799813807, disc_loss = 0.0010999806485792228
Trained batch 666 in epoch 3, gen_loss = 1.1724383055359526, disc_loss = 0.0010996732951431274
Trained batch 667 in epoch 3, gen_loss = 1.1728773415088654, disc_loss = 0.0010995317787821837
Trained batch 668 in epoch 3, gen_loss = 1.1728974867651103, disc_loss = 0.001099330549145233
Trained batch 669 in epoch 3, gen_loss = 1.1729470491409302, disc_loss = 0.0010985295762830942
Trained batch 670 in epoch 3, gen_loss = 1.1728372897192192, disc_loss = 0.0010974506212177377
Trained batch 671 in epoch 3, gen_loss = 1.172863001802138, disc_loss = 0.0010962953916056168
Trained batch 672 in epoch 3, gen_loss = 1.172812944889777, disc_loss = 0.0010953521224565286
Trained batch 673 in epoch 3, gen_loss = 1.173088125199168, disc_loss = 0.0010944624905426467
Trained batch 674 in epoch 3, gen_loss = 1.1728885263866848, disc_loss = 0.0010939797706669197
Trained batch 675 in epoch 3, gen_loss = 1.1725680735513304, disc_loss = 0.001093797278426038
Trained batch 676 in epoch 3, gen_loss = 1.1724705082451048, disc_loss = 0.0010936954284186215
Trained batch 677 in epoch 3, gen_loss = 1.1726241954835819, disc_loss = 0.001093273726931552
Trained batch 678 in epoch 3, gen_loss = 1.1728127960428398, disc_loss = 0.0010924773588949755
Trained batch 679 in epoch 3, gen_loss = 1.172935339896118, disc_loss = 0.001091514361970065
Trained batch 680 in epoch 3, gen_loss = 1.172835968577039, disc_loss = 0.0010904545071403183
Trained batch 681 in epoch 3, gen_loss = 1.1728945884012407, disc_loss = 0.0010896859366180105
Trained batch 682 in epoch 3, gen_loss = 1.1728343255872433, disc_loss = 0.001088853821472543
Trained batch 683 in epoch 3, gen_loss = 1.1730469302301518, disc_loss = 0.0010878732591982842
Trained batch 684 in epoch 3, gen_loss = 1.1730497747442148, disc_loss = 0.0010873745106981497
Trained batch 685 in epoch 3, gen_loss = 1.1731759354081168, disc_loss = 0.0010870961023658533
Trained batch 686 in epoch 3, gen_loss = 1.1727654301443475, disc_loss = 0.0010877562120780173
Trained batch 687 in epoch 3, gen_loss = 1.1726272980314354, disc_loss = 0.0010885843607760508
Trained batch 688 in epoch 3, gen_loss = 1.172482405501284, disc_loss = 0.0010882964629890446
Trained batch 689 in epoch 3, gen_loss = 1.172414612683697, disc_loss = 0.0010872930887895907
Trained batch 690 in epoch 3, gen_loss = 1.1721395641435934, disc_loss = 0.0010862973647425625
Trained batch 691 in epoch 3, gen_loss = 1.1721724272635632, disc_loss = 0.0010851259083452438
Trained batch 692 in epoch 3, gen_loss = 1.1720320031928466, disc_loss = 0.0010840617155585329
Trained batch 693 in epoch 3, gen_loss = 1.171808911932992, disc_loss = 0.0010835623092218356
Trained batch 694 in epoch 3, gen_loss = 1.1719031053481341, disc_loss = 0.0010850658016522221
Trained batch 695 in epoch 3, gen_loss = 1.1722177112068253, disc_loss = 0.001086813948942976
Trained batch 696 in epoch 3, gen_loss = 1.1721974295728348, disc_loss = 0.0010866936131247215
Trained batch 697 in epoch 3, gen_loss = 1.172002386654004, disc_loss = 0.0010863190756706764
Trained batch 698 in epoch 3, gen_loss = 1.1719179734139995, disc_loss = 0.001086426401802789
Trained batch 699 in epoch 3, gen_loss = 1.1719766248123986, disc_loss = 0.0010859563183579926
Trained batch 700 in epoch 3, gen_loss = 1.1716683251881566, disc_loss = 0.0010852019412194932
Trained batch 701 in epoch 3, gen_loss = 1.171762032471491, disc_loss = 0.0010852560200013733
Trained batch 702 in epoch 3, gen_loss = 1.1719658799564856, disc_loss = 0.001084885683615631
Trained batch 703 in epoch 3, gen_loss = 1.1719137085601687, disc_loss = 0.0010839387153241246
Trained batch 704 in epoch 3, gen_loss = 1.1720641629070254, disc_loss = 0.0010831539620065746
Trained batch 705 in epoch 3, gen_loss = 1.1721313765467734, disc_loss = 0.0010827215625741256
Trained batch 706 in epoch 3, gen_loss = 1.1722805290107512, disc_loss = 0.0010823626509418743
Trained batch 707 in epoch 3, gen_loss = 1.1722936577210992, disc_loss = 0.0010815356758965434
Trained batch 708 in epoch 3, gen_loss = 1.1724339450364052, disc_loss = 0.0010812133018852491
Trained batch 709 in epoch 3, gen_loss = 1.1724969478560165, disc_loss = 0.0010810301635245478
Trained batch 710 in epoch 3, gen_loss = 1.1725359812232177, disc_loss = 0.0010806369588393706
Trained batch 711 in epoch 3, gen_loss = 1.172804342980465, disc_loss = 0.0010805185522278836
Trained batch 712 in epoch 3, gen_loss = 1.1725703032287609, disc_loss = 0.0010803871306463056
Trained batch 713 in epoch 3, gen_loss = 1.1727296735893111, disc_loss = 0.0010797613419937062
Trained batch 714 in epoch 3, gen_loss = 1.1728462328443994, disc_loss = 0.0010794487784468484
Trained batch 715 in epoch 3, gen_loss = 1.1729286655200926, disc_loss = 0.0010801877904861876
Trained batch 716 in epoch 3, gen_loss = 1.1728211416027703, disc_loss = 0.0010799086720929799
Trained batch 717 in epoch 3, gen_loss = 1.172478570330442, disc_loss = 0.0010817086302085447
Trained batch 718 in epoch 3, gen_loss = 1.1723277778552537, disc_loss = 0.0010819581878426263
Trained batch 719 in epoch 3, gen_loss = 1.1724662036531501, disc_loss = 0.0010818780669271492
Trained batch 720 in epoch 3, gen_loss = 1.172607219582953, disc_loss = 0.0010812753187946203
Trained batch 721 in epoch 3, gen_loss = 1.1726547054471732, disc_loss = 0.001080449889617981
Trained batch 722 in epoch 3, gen_loss = 1.1728813536928897, disc_loss = 0.001080105969390734
Trained batch 723 in epoch 3, gen_loss = 1.1728164014401357, disc_loss = 0.0010800491711544452
Trained batch 724 in epoch 3, gen_loss = 1.1729107124229958, disc_loss = 0.0010804949474625353
Trained batch 725 in epoch 3, gen_loss = 1.1731377679946995, disc_loss = 0.0010798776735907315
Trained batch 726 in epoch 3, gen_loss = 1.1732580593724362, disc_loss = 0.0010788912311901866
Trained batch 727 in epoch 3, gen_loss = 1.1733524230319066, disc_loss = 0.0010779750792897795
Trained batch 728 in epoch 3, gen_loss = 1.1734839186419839, disc_loss = 0.001077128653998221
Trained batch 729 in epoch 3, gen_loss = 1.1734047162206205, disc_loss = 0.001076096208022161
Trained batch 730 in epoch 3, gen_loss = 1.1736706584162002, disc_loss = 0.0010752627649272838
Trained batch 731 in epoch 3, gen_loss = 1.173721282941396, disc_loss = 0.0010742235858916735
Trained batch 732 in epoch 3, gen_loss = 1.1735652001297652, disc_loss = 0.0010733724805270098
Trained batch 733 in epoch 3, gen_loss = 1.1739569115541286, disc_loss = 0.0010727605150927845
Trained batch 734 in epoch 3, gen_loss = 1.1738100933379867, disc_loss = 0.0010718312196245062
Trained batch 735 in epoch 3, gen_loss = 1.173614206602392, disc_loss = 0.0010708066013490759
Trained batch 736 in epoch 3, gen_loss = 1.1734891841175437, disc_loss = 0.0010703151091815413
Trained batch 737 in epoch 3, gen_loss = 1.17362364480489, disc_loss = 0.0010705940414314425
Trained batch 738 in epoch 3, gen_loss = 1.1733249493638944, disc_loss = 0.0010707955210996131
Trained batch 739 in epoch 3, gen_loss = 1.1730960398106962, disc_loss = 0.0010701920463337023
Trained batch 740 in epoch 3, gen_loss = 1.1731529229404793, disc_loss = 0.0010693070344058495
Trained batch 741 in epoch 3, gen_loss = 1.173019324351514, disc_loss = 0.001068518560140794
Trained batch 742 in epoch 3, gen_loss = 1.1727751979596843, disc_loss = 0.0010679319756825344
Trained batch 743 in epoch 3, gen_loss = 1.1723863605850486, disc_loss = 0.001083093546400559
Trained batch 744 in epoch 3, gen_loss = 1.172122473604727, disc_loss = 0.0011804502195055166
Trained batch 745 in epoch 3, gen_loss = 1.1726558081426186, disc_loss = 0.0015362519433981883
Trained batch 746 in epoch 3, gen_loss = 1.1724781176970507, disc_loss = 0.0019785884625836024
Trained batch 747 in epoch 3, gen_loss = 1.1727940445755893, disc_loss = 0.004464965364740904
Trained batch 748 in epoch 3, gen_loss = 1.1734900152253531, disc_loss = 0.006312146754295799
Trained batch 749 in epoch 3, gen_loss = 1.173770050605138, disc_loss = 0.007665479889779817
Trained batch 750 in epoch 3, gen_loss = 1.1741362868072824, disc_loss = 0.008723926678388727
Trained batch 751 in epoch 3, gen_loss = 1.1741407241751538, disc_loss = 0.009161094630879697
Trained batch 752 in epoch 3, gen_loss = 1.1742885843374498, disc_loss = 0.009461873072462502
Trained batch 753 in epoch 3, gen_loss = 1.1738197937093933, disc_loss = 0.009638248067072053
Trained batch 754 in epoch 3, gen_loss = 1.1735305189296898, disc_loss = 0.009715592832823396
Trained batch 755 in epoch 3, gen_loss = 1.173250656436991, disc_loss = 0.009778071462230482
Trained batch 756 in epoch 3, gen_loss = 1.1734711734905268, disc_loss = 0.009796466145688599
Trained batch 757 in epoch 3, gen_loss = 1.1736565186669141, disc_loss = 0.00980599994077682
Trained batch 758 in epoch 3, gen_loss = 1.1733864526974824, disc_loss = 0.009840848872871984
Trained batch 759 in epoch 3, gen_loss = 1.173031345088231, disc_loss = 0.009845967888606155
Trained batch 760 in epoch 3, gen_loss = 1.1727450003605164, disc_loss = 0.009862793253389133
Trained batch 761 in epoch 3, gen_loss = 1.1728009537761919, disc_loss = 0.009868299646023936
Trained batch 762 in epoch 3, gen_loss = 1.172899794141087, disc_loss = 0.009868094696393109
Trained batch 763 in epoch 3, gen_loss = 1.1728733848214774, disc_loss = 0.00986834513683665
Trained batch 764 in epoch 3, gen_loss = 1.1729611036824246, disc_loss = 0.009867353994247893
Trained batch 765 in epoch 3, gen_loss = 1.1727608269561987, disc_loss = 0.009865407540187679
Trained batch 766 in epoch 3, gen_loss = 1.1724398141578714, disc_loss = 0.0098698755393706
Trained batch 767 in epoch 3, gen_loss = 1.172435814126705, disc_loss = 0.009869229620884804
Trained batch 768 in epoch 3, gen_loss = 1.1724035252365241, disc_loss = 0.009867050286561223
Trained batch 769 in epoch 3, gen_loss = 1.1723677665382237, disc_loss = 0.009862844377484735
Trained batch 770 in epoch 3, gen_loss = 1.1724480284636432, disc_loss = 0.009855889387921148
Trained batch 771 in epoch 3, gen_loss = 1.1725061257114064, disc_loss = 0.009849526866362823
Trained batch 772 in epoch 3, gen_loss = 1.1728818560787808, disc_loss = 0.009841417263667544
Trained batch 773 in epoch 3, gen_loss = 1.17317812841684, disc_loss = 0.00983305354827118
Trained batch 774 in epoch 3, gen_loss = 1.1732384988569444, disc_loss = 0.009825107944967796
Trained batch 775 in epoch 3, gen_loss = 1.1730182326792442, disc_loss = 0.009822245879890426
Trained batch 776 in epoch 3, gen_loss = 1.1732408975082014, disc_loss = 0.009819034855601382
Trained batch 777 in epoch 3, gen_loss = 1.173245469141742, disc_loss = 0.00981384898528201
Trained batch 778 in epoch 3, gen_loss = 1.1729757587625065, disc_loss = 0.009819010472893075
Trained batch 779 in epoch 3, gen_loss = 1.17284577695223, disc_loss = 0.009815082062078335
Trained batch 780 in epoch 3, gen_loss = 1.1727613689194263, disc_loss = 0.009807240991858692
Trained batch 781 in epoch 3, gen_loss = 1.1729978096607092, disc_loss = 0.009801983530830402
Trained batch 782 in epoch 3, gen_loss = 1.1730577597825158, disc_loss = 0.00979711696992692
Trained batch 783 in epoch 3, gen_loss = 1.1732070597306805, disc_loss = 0.009788600472533365
Trained batch 784 in epoch 3, gen_loss = 1.1731771031003089, disc_loss = 0.0097790953727138
Trained batch 785 in epoch 3, gen_loss = 1.1733300874706443, disc_loss = 0.0097701598803814
Trained batch 786 in epoch 3, gen_loss = 1.1733183713092585, disc_loss = 0.009762034017204074
Trained batch 787 in epoch 3, gen_loss = 1.1733088805742071, disc_loss = 0.009754054641917963
Trained batch 788 in epoch 3, gen_loss = 1.1733591447009484, disc_loss = 0.009750330281262853
Trained batch 789 in epoch 3, gen_loss = 1.1731684324862082, disc_loss = 0.00974348826170678
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 0.916137158870697, disc_loss = 0.006916684098541737
Trained batch 1 in epoch 4, gen_loss = 1.0273263156414032, disc_loss = 0.006528068333864212
Trained batch 2 in epoch 4, gen_loss = 1.0837375124295552, disc_loss = 0.0062352583433190984
Trained batch 3 in epoch 4, gen_loss = 1.075353130698204, disc_loss = 0.005521456652786583
Trained batch 4 in epoch 4, gen_loss = 1.0822710394859314, disc_loss = 0.005639176955446601
Trained batch 5 in epoch 4, gen_loss = 1.0868805944919586, disc_loss = 0.005533978304204841
Trained batch 6 in epoch 4, gen_loss = 1.0897390757288252, disc_loss = 0.005214832357263991
Trained batch 7 in epoch 4, gen_loss = 1.094084970653057, disc_loss = 0.005346435733372346
Trained batch 8 in epoch 4, gen_loss = 1.1008723510636225, disc_loss = 0.005106624681502581
Trained batch 9 in epoch 4, gen_loss = 1.1016863286495209, disc_loss = 0.004878577776253223
Trained batch 10 in epoch 4, gen_loss = 1.1237039511854, disc_loss = 0.0048324352299625225
Trained batch 11 in epoch 4, gen_loss = 1.133281444509824, disc_loss = 0.004619578501054396
Trained batch 12 in epoch 4, gen_loss = 1.1422722477179308, disc_loss = 0.004470657646799317
Trained batch 13 in epoch 4, gen_loss = 1.1461696667330605, disc_loss = 0.004290957120247185
Trained batch 14 in epoch 4, gen_loss = 1.156042182445526, disc_loss = 0.00420484187391897
Trained batch 15 in epoch 4, gen_loss = 1.1554433144629002, disc_loss = 0.004069884846103378
Trained batch 16 in epoch 4, gen_loss = 1.1574582387419308, disc_loss = 0.004177209387040313
Trained batch 17 in epoch 4, gen_loss = 1.155856215291553, disc_loss = 0.004230097906353573
Trained batch 18 in epoch 4, gen_loss = 1.1537408358172367, disc_loss = 0.004110437388973017
Trained batch 19 in epoch 4, gen_loss = 1.1438290804624558, disc_loss = 0.004083154199179262
Trained batch 20 in epoch 4, gen_loss = 1.1448342544691903, disc_loss = 0.003982842955294819
Trained batch 21 in epoch 4, gen_loss = 1.1417152204296805, disc_loss = 0.003954622598195618
Trained batch 22 in epoch 4, gen_loss = 1.1433883464854697, disc_loss = 0.0038838090435804233
Trained batch 23 in epoch 4, gen_loss = 1.1450603529810905, disc_loss = 0.003836141685800006
Trained batch 24 in epoch 4, gen_loss = 1.1454659008979797, disc_loss = 0.0037315896432846786
Trained batch 25 in epoch 4, gen_loss = 1.1410184846474574, disc_loss = 0.00365069737801185
Trained batch 26 in epoch 4, gen_loss = 1.14071833425098, disc_loss = 0.0035609162231493327
Trained batch 27 in epoch 4, gen_loss = 1.1411136069468089, disc_loss = 0.0035011192043644507
Trained batch 28 in epoch 4, gen_loss = 1.1432135413432944, disc_loss = 0.0034273165350394517
Trained batch 29 in epoch 4, gen_loss = 1.1498086591561636, disc_loss = 0.003412582698122909
Trained batch 30 in epoch 4, gen_loss = 1.1470914252342717, disc_loss = 0.003416838413555055
Trained batch 31 in epoch 4, gen_loss = 1.1427019108086824, disc_loss = 0.0033802512371039484
Trained batch 32 in epoch 4, gen_loss = 1.1382634115941597, disc_loss = 0.003329661942905549
Trained batch 33 in epoch 4, gen_loss = 1.1400113333674038, disc_loss = 0.003299054402091047
Trained batch 34 in epoch 4, gen_loss = 1.1370734640530178, disc_loss = 0.003324364165642432
Trained batch 35 in epoch 4, gen_loss = 1.1366078009208043, disc_loss = 0.003277798564845903
Trained batch 36 in epoch 4, gen_loss = 1.1312797923345823, disc_loss = 0.0033234848477248407
Trained batch 37 in epoch 4, gen_loss = 1.1403648492537046, disc_loss = 0.003384704707729581
Trained batch 38 in epoch 4, gen_loss = 1.1419341640594678, disc_loss = 0.0034234037873550104
Trained batch 39 in epoch 4, gen_loss = 1.1430182710289956, disc_loss = 0.0034634481242392214
Trained batch 40 in epoch 4, gen_loss = 1.1388537142334916, disc_loss = 0.0034577429078791926
Trained batch 41 in epoch 4, gen_loss = 1.1375979625043415, disc_loss = 0.003445047813112892
Trained batch 42 in epoch 4, gen_loss = 1.13896006068518, disc_loss = 0.0033925246977962033
Trained batch 43 in epoch 4, gen_loss = 1.1459129059856588, disc_loss = 0.003392389483368871
Trained batch 44 in epoch 4, gen_loss = 1.1470241321457757, disc_loss = 0.0033546399428612656
Trained batch 45 in epoch 4, gen_loss = 1.1523557447868844, disc_loss = 0.0033026371700385503
Trained batch 46 in epoch 4, gen_loss = 1.149196575296686, disc_loss = 0.0033476386836016592
Trained batch 47 in epoch 4, gen_loss = 1.145205815633138, disc_loss = 0.003406000989343738
Trained batch 48 in epoch 4, gen_loss = 1.147933478258094, disc_loss = 0.0034418364247896386
Trained batch 49 in epoch 4, gen_loss = 1.1473181104660035, disc_loss = 0.003405432760482654
Trained batch 50 in epoch 4, gen_loss = 1.152503628356784, disc_loss = 0.0033672035422961356
Trained batch 51 in epoch 4, gen_loss = 1.1518213817706475, disc_loss = 0.0033394531067013023
Trained batch 52 in epoch 4, gen_loss = 1.150546908378601, disc_loss = 0.0033144227499230148
Trained batch 53 in epoch 4, gen_loss = 1.1483426381040502, disc_loss = 0.0032805706303204512
Trained batch 54 in epoch 4, gen_loss = 1.1495802380821922, disc_loss = 0.0032769090866416016
Trained batch 55 in epoch 4, gen_loss = 1.1492167966706412, disc_loss = 0.0032474671056011823
Trained batch 56 in epoch 4, gen_loss = 1.1519591390040882, disc_loss = 0.003204906742260056
Trained batch 57 in epoch 4, gen_loss = 1.150550400388652, disc_loss = 0.003171793067755563
Trained batch 58 in epoch 4, gen_loss = 1.1474305189262002, disc_loss = 0.0031431683909416324
Trained batch 59 in epoch 4, gen_loss = 1.1495341738065084, disc_loss = 0.0031170095559597635
Trained batch 60 in epoch 4, gen_loss = 1.1495275946914172, disc_loss = 0.0030794634901704725
Trained batch 61 in epoch 4, gen_loss = 1.1478097111948076, disc_loss = 0.00306102383652732
Trained batch 62 in epoch 4, gen_loss = 1.1485868692398071, disc_loss = 0.003030961376637043
Trained batch 63 in epoch 4, gen_loss = 1.1472897436469793, disc_loss = 0.003008771010172495
Trained batch 64 in epoch 4, gen_loss = 1.1462635847238394, disc_loss = 0.00298699059505732
Trained batch 65 in epoch 4, gen_loss = 1.1455098462827278, disc_loss = 0.0029606443581129
Trained batch 66 in epoch 4, gen_loss = 1.145095679297376, disc_loss = 0.0029332870852077073
Trained batch 67 in epoch 4, gen_loss = 1.1489990967161514, disc_loss = 0.0029149461453712054
Trained batch 68 in epoch 4, gen_loss = 1.148449661075205, disc_loss = 0.002883525669871681
Trained batch 69 in epoch 4, gen_loss = 1.1498096346855164, disc_loss = 0.002860256956358041
Trained batch 70 in epoch 4, gen_loss = 1.1466845685327556, disc_loss = 0.0028897443799380685
Trained batch 71 in epoch 4, gen_loss = 1.1450714957382944, disc_loss = 0.0028862799453135165
Trained batch 72 in epoch 4, gen_loss = 1.1466847013120782, disc_loss = 0.0028700821312169916
Trained batch 73 in epoch 4, gen_loss = 1.1467615422364827, disc_loss = 0.002844686550717499
Trained batch 74 in epoch 4, gen_loss = 1.1477461123466492, disc_loss = 0.002821691483259201
Trained batch 75 in epoch 4, gen_loss = 1.1465561178169752, disc_loss = 0.0028005110308233845
Trained batch 76 in epoch 4, gen_loss = 1.1453247263834074, disc_loss = 0.002776834924777897
Trained batch 77 in epoch 4, gen_loss = 1.1440433806333787, disc_loss = 0.002756828846684538
Trained batch 78 in epoch 4, gen_loss = 1.1463715328445918, disc_loss = 0.0027658353851447944
Trained batch 79 in epoch 4, gen_loss = 1.1467495314776897, disc_loss = 0.0027488439372973517
Trained batch 80 in epoch 4, gen_loss = 1.1472800271010692, disc_loss = 0.0027396115215702187
Trained batch 81 in epoch 4, gen_loss = 1.1474483660081538, disc_loss = 0.002722668268422528
Trained batch 82 in epoch 4, gen_loss = 1.1475481577666409, disc_loss = 0.0027054322712370253
Trained batch 83 in epoch 4, gen_loss = 1.1487320540916353, disc_loss = 0.0026952291996816973
Trained batch 84 in epoch 4, gen_loss = 1.1495307831203236, disc_loss = 0.002689374623107998
Trained batch 85 in epoch 4, gen_loss = 1.1527970772843028, disc_loss = 0.00267405875655281
Trained batch 86 in epoch 4, gen_loss = 1.1516139692273633, disc_loss = 0.0026670583957356625
Trained batch 87 in epoch 4, gen_loss = 1.150076356123794, disc_loss = 0.002661713941382583
Trained batch 88 in epoch 4, gen_loss = 1.1506593756461412, disc_loss = 0.00264322310110575
Trained batch 89 in epoch 4, gen_loss = 1.1489389406310186, disc_loss = 0.002629935148999923
Trained batch 90 in epoch 4, gen_loss = 1.1498026913338966, disc_loss = 0.002614216932740349
Trained batch 91 in epoch 4, gen_loss = 1.150876389897388, disc_loss = 0.002597981922166503
Trained batch 92 in epoch 4, gen_loss = 1.1531602067332114, disc_loss = 0.0025884465674959846
Trained batch 93 in epoch 4, gen_loss = 1.151590422112891, disc_loss = 0.002583282449817721
Trained batch 94 in epoch 4, gen_loss = 1.1525548006358899, disc_loss = 0.0025683654888876174
Trained batch 95 in epoch 4, gen_loss = 1.1536740958690643, disc_loss = 0.0025507053536178623
Trained batch 96 in epoch 4, gen_loss = 1.1537201552046943, disc_loss = 0.002539290280258955
Trained batch 97 in epoch 4, gen_loss = 1.1561947769048262, disc_loss = 0.0025263388091175606
Trained batch 98 in epoch 4, gen_loss = 1.1548682981067233, disc_loss = 0.0025311599213940403
Trained batch 99 in epoch 4, gen_loss = 1.1541738176345826, disc_loss = 0.0025154530920553954
Trained batch 100 in epoch 4, gen_loss = 1.1534478499157594, disc_loss = 0.002501447822225492
Trained batch 101 in epoch 4, gen_loss = 1.156529726935368, disc_loss = 0.002495071071190942
Trained batch 102 in epoch 4, gen_loss = 1.1556857778030691, disc_loss = 0.002495120271579227
Trained batch 103 in epoch 4, gen_loss = 1.1599086740842233, disc_loss = 0.002498343223123811
Trained batch 104 in epoch 4, gen_loss = 1.158943751880101, disc_loss = 0.0024856619658835586
Trained batch 105 in epoch 4, gen_loss = 1.1579621400473252, disc_loss = 0.002472699635205263
Trained batch 106 in epoch 4, gen_loss = 1.157579388573905, disc_loss = 0.0024569975097977043
Trained batch 107 in epoch 4, gen_loss = 1.1575503923274852, disc_loss = 0.0024458314739469506
Trained batch 108 in epoch 4, gen_loss = 1.1586764372816873, disc_loss = 0.0024423484809038766
Trained batch 109 in epoch 4, gen_loss = 1.1589763370427217, disc_loss = 0.0024301108877724884
Trained batch 110 in epoch 4, gen_loss = 1.1595499719585385, disc_loss = 0.0024187412424440924
Trained batch 111 in epoch 4, gen_loss = 1.1594675832561083, disc_loss = 0.002406372460557447
Trained batch 112 in epoch 4, gen_loss = 1.158766387838178, disc_loss = 0.0023910460789663204
Trained batch 113 in epoch 4, gen_loss = 1.1588537379315025, disc_loss = 0.002376825546666065
Trained batch 114 in epoch 4, gen_loss = 1.1590404676354449, disc_loss = 0.002361808343709487
Trained batch 115 in epoch 4, gen_loss = 1.1602995046253861, disc_loss = 0.002347288046590181
Trained batch 116 in epoch 4, gen_loss = 1.1610625564542592, disc_loss = 0.002333280391111556
Trained batch 117 in epoch 4, gen_loss = 1.1609557563975705, disc_loss = 0.002320441949650866
Trained batch 118 in epoch 4, gen_loss = 1.1608914527572503, disc_loss = 0.0023056192513351806
Trained batch 119 in epoch 4, gen_loss = 1.1605110049247742, disc_loss = 0.002293378545922072
Trained batch 120 in epoch 4, gen_loss = 1.1599606640082745, disc_loss = 0.00228015168604618
Trained batch 121 in epoch 4, gen_loss = 1.161245481889756, disc_loss = 0.0022713538806992356
Trained batch 122 in epoch 4, gen_loss = 1.1624820319617666, disc_loss = 0.002261286663890975
Trained batch 123 in epoch 4, gen_loss = 1.1626467310613202, disc_loss = 0.002255467172231405
Trained batch 124 in epoch 4, gen_loss = 1.1631139211654664, disc_loss = 0.00224212156701833
Trained batch 125 in epoch 4, gen_loss = 1.1638647800400144, disc_loss = 0.002233169103477387
Trained batch 126 in epoch 4, gen_loss = 1.1645536920217079, disc_loss = 0.0022206370252199235
Trained batch 127 in epoch 4, gen_loss = 1.1655452763661742, disc_loss = 0.002212502756719914
Trained batch 128 in epoch 4, gen_loss = 1.1640274307524512, disc_loss = 0.0022116611389508254
Trained batch 129 in epoch 4, gen_loss = 1.1630030654943906, disc_loss = 0.0022011878152485365
Trained batch 130 in epoch 4, gen_loss = 1.1635875779253837, disc_loss = 0.0021951914918680055
Trained batch 131 in epoch 4, gen_loss = 1.1635027712944783, disc_loss = 0.002187961238439929
Trained batch 132 in epoch 4, gen_loss = 1.164461674994992, disc_loss = 0.0021780571323483343
Trained batch 133 in epoch 4, gen_loss = 1.1657312169893463, disc_loss = 0.0021668161520101963
Trained batch 134 in epoch 4, gen_loss = 1.1661056258060314, disc_loss = 0.002157334847530971
Trained batch 135 in epoch 4, gen_loss = 1.1676073972793186, disc_loss = 0.002147824717052144
Trained batch 136 in epoch 4, gen_loss = 1.1679153411927885, disc_loss = 0.002138591349808105
Trained batch 137 in epoch 4, gen_loss = 1.1685631288134533, disc_loss = 0.002131122023127028
Trained batch 138 in epoch 4, gen_loss = 1.1686870858823653, disc_loss = 0.0021206551104140797
Trained batch 139 in epoch 4, gen_loss = 1.168292653134891, disc_loss = 0.00211018870634559
Trained batch 140 in epoch 4, gen_loss = 1.1671209956737274, disc_loss = 0.0021002826294102142
Trained batch 141 in epoch 4, gen_loss = 1.1660824959546747, disc_loss = 0.0020899530983871034
Trained batch 142 in epoch 4, gen_loss = 1.1673166839392868, disc_loss = 0.0020836743027935704
Trained batch 143 in epoch 4, gen_loss = 1.1687267733116944, disc_loss = 0.0020746711864679432
Trained batch 144 in epoch 4, gen_loss = 1.16858852197384, disc_loss = 0.0020679283758689615
Trained batch 145 in epoch 4, gen_loss = 1.1677596842589444, disc_loss = 0.0020616271378383145
Trained batch 146 in epoch 4, gen_loss = 1.1660010964692045, disc_loss = 0.0020542563157802335
Trained batch 147 in epoch 4, gen_loss = 1.1646473069448728, disc_loss = 0.002048101795308695
Trained batch 148 in epoch 4, gen_loss = 1.1654412986448146, disc_loss = 0.0020432877971559463
Trained batch 149 in epoch 4, gen_loss = 1.16506946404775, disc_loss = 0.002037830762565136
Trained batch 150 in epoch 4, gen_loss = 1.1667982734591755, disc_loss = 0.0020279806787271474
Trained batch 151 in epoch 4, gen_loss = 1.1686274581833889, disc_loss = 0.002021963493653426
Trained batch 152 in epoch 4, gen_loss = 1.1682138591030844, disc_loss = 0.002013692969008915
Trained batch 153 in epoch 4, gen_loss = 1.1685433968321068, disc_loss = 0.0020061166017382804
Trained batch 154 in epoch 4, gen_loss = 1.1705983031180598, disc_loss = 0.0019982043499757927
Trained batch 155 in epoch 4, gen_loss = 1.1703819525547516, disc_loss = 0.001989819217273273
Trained batch 156 in epoch 4, gen_loss = 1.1703189376053538, disc_loss = 0.001980502307815418
Trained batch 157 in epoch 4, gen_loss = 1.1696577026874204, disc_loss = 0.001974449052012679
Trained batch 158 in epoch 4, gen_loss = 1.169306997982961, disc_loss = 0.00196732703849685
Trained batch 159 in epoch 4, gen_loss = 1.1688169986009598, disc_loss = 0.0019594695429987043
Trained batch 160 in epoch 4, gen_loss = 1.1691788427577996, disc_loss = 0.0019519673841166662
Trained batch 161 in epoch 4, gen_loss = 1.1706001905747403, disc_loss = 0.0019453193444074533
Trained batch 162 in epoch 4, gen_loss = 1.1696195646297711, disc_loss = 0.0019399057056017769
Trained batch 163 in epoch 4, gen_loss = 1.1686746274552695, disc_loss = 0.0019319730323864284
Trained batch 164 in epoch 4, gen_loss = 1.1690132328958223, disc_loss = 0.0019245133580019077
Trained batch 165 in epoch 4, gen_loss = 1.1682243347167969, disc_loss = 0.0019173993222718407
Trained batch 166 in epoch 4, gen_loss = 1.169463969990165, disc_loss = 0.0019124247618911867
Trained batch 167 in epoch 4, gen_loss = 1.1708509567238035, disc_loss = 0.0019065453178925616
Trained batch 168 in epoch 4, gen_loss = 1.1704599970191187, disc_loss = 0.0019000554371200855
Trained batch 169 in epoch 4, gen_loss = 1.1732964698006125, disc_loss = 0.0018966244468602406
Trained batch 170 in epoch 4, gen_loss = 1.1729406076565123, disc_loss = 0.001891715905822443
Trained batch 171 in epoch 4, gen_loss = 1.1729176023671792, disc_loss = 0.00188438352305702
Trained batch 172 in epoch 4, gen_loss = 1.1722509978134508, disc_loss = 0.001877461089698781
Trained batch 173 in epoch 4, gen_loss = 1.1719357261712524, disc_loss = 0.0018696571986629874
Trained batch 174 in epoch 4, gen_loss = 1.1719310215541294, disc_loss = 0.001862476573857878
Trained batch 175 in epoch 4, gen_loss = 1.172448878261176, disc_loss = 0.001855597979804522
Trained batch 176 in epoch 4, gen_loss = 1.172082714441806, disc_loss = 0.0018498515039366687
Trained batch 177 in epoch 4, gen_loss = 1.1710275425000136, disc_loss = 0.0018495581599391913
Trained batch 178 in epoch 4, gen_loss = 1.1714086992114616, disc_loss = 0.0018467809406613838
Trained batch 179 in epoch 4, gen_loss = 1.1709235277440813, disc_loss = 0.0018392562717458026
Trained batch 180 in epoch 4, gen_loss = 1.169622334986102, disc_loss = 0.0018444157299426132
Trained batch 181 in epoch 4, gen_loss = 1.1701863224689777, disc_loss = 0.0018429993914061604
Trained batch 182 in epoch 4, gen_loss = 1.170005246589744, disc_loss = 0.0018366040627578975
Trained batch 183 in epoch 4, gen_loss = 1.169734277802965, disc_loss = 0.0018292504271654332
Trained batch 184 in epoch 4, gen_loss = 1.168524175721246, disc_loss = 0.001825521037460783
Trained batch 185 in epoch 4, gen_loss = 1.169082789010899, disc_loss = 0.0018191781800655869
Trained batch 186 in epoch 4, gen_loss = 1.1694791533730247, disc_loss = 0.0018151933952971775
Trained batch 187 in epoch 4, gen_loss = 1.169281766769734, disc_loss = 0.0018095862887616448
Trained batch 188 in epoch 4, gen_loss = 1.1699149772603676, disc_loss = 0.0018030033892183195
Trained batch 189 in epoch 4, gen_loss = 1.1701247102335879, disc_loss = 0.0017982498289232977
Trained batch 190 in epoch 4, gen_loss = 1.169906068222685, disc_loss = 0.0017931975877760904
Trained batch 191 in epoch 4, gen_loss = 1.1702602157990138, disc_loss = 0.001786925594994197
Trained batch 192 in epoch 4, gen_loss = 1.1703494422794005, disc_loss = 0.0017811957004219487
Trained batch 193 in epoch 4, gen_loss = 1.170847275822433, disc_loss = 0.0017752822190907197
Trained batch 194 in epoch 4, gen_loss = 1.1710834423700969, disc_loss = 0.0017696085463588436
Trained batch 195 in epoch 4, gen_loss = 1.1725183348266446, disc_loss = 0.0017637040745823321
Trained batch 196 in epoch 4, gen_loss = 1.171855368589992, disc_loss = 0.0017582210283702815
Trained batch 197 in epoch 4, gen_loss = 1.1709900691051676, disc_loss = 0.0017576954857272218
Trained batch 198 in epoch 4, gen_loss = 1.1706793416085555, disc_loss = 0.0017527184173015493
Trained batch 199 in epoch 4, gen_loss = 1.172275897860527, disc_loss = 0.0017483417520998046
Trained batch 200 in epoch 4, gen_loss = 1.1722041641301777, disc_loss = 0.001743436679220874
Trained batch 201 in epoch 4, gen_loss = 1.1738495218871843, disc_loss = 0.0017393262700136235
Trained batch 202 in epoch 4, gen_loss = 1.174783633260304, disc_loss = 0.0017339069335469105
Trained batch 203 in epoch 4, gen_loss = 1.1747047094737781, disc_loss = 0.0017277627337927127
Trained batch 204 in epoch 4, gen_loss = 1.175247840765046, disc_loss = 0.001722078786441693
Trained batch 205 in epoch 4, gen_loss = 1.1745267394676948, disc_loss = 0.0017178214972587845
Trained batch 206 in epoch 4, gen_loss = 1.1740309996305456, disc_loss = 0.001713481709920095
Trained batch 207 in epoch 4, gen_loss = 1.1735427161821952, disc_loss = 0.001708066820915869
Trained batch 208 in epoch 4, gen_loss = 1.1741784759685754, disc_loss = 0.0017046661838347706
Trained batch 209 in epoch 4, gen_loss = 1.1737546182814098, disc_loss = 0.0017009489453076163
Trained batch 210 in epoch 4, gen_loss = 1.173420175556888, disc_loss = 0.0016945731321016495
Trained batch 211 in epoch 4, gen_loss = 1.1728712921997286, disc_loss = 0.001690895195456248
Trained batch 212 in epoch 4, gen_loss = 1.1732858620898825, disc_loss = 0.0016853256226777417
Trained batch 213 in epoch 4, gen_loss = 1.1727420743380752, disc_loss = 0.0016802040046509617
Trained batch 214 in epoch 4, gen_loss = 1.1720834881760354, disc_loss = 0.0016773426397649442
Trained batch 215 in epoch 4, gen_loss = 1.1713743800366367, disc_loss = 0.0016750080891749046
Trained batch 216 in epoch 4, gen_loss = 1.1706882308705062, disc_loss = 0.0016713975597449798
Trained batch 217 in epoch 4, gen_loss = 1.1706363985297876, disc_loss = 0.0016664279671012073
Trained batch 218 in epoch 4, gen_loss = 1.1702679466439165, disc_loss = 0.001663055433174085
Trained batch 219 in epoch 4, gen_loss = 1.1711101391098715, disc_loss = 0.0016598229943404228
Trained batch 220 in epoch 4, gen_loss = 1.1704031202048737, disc_loss = 0.0016567678117283885
Trained batch 221 in epoch 4, gen_loss = 1.1713139710125622, disc_loss = 0.0016518893824976257
Trained batch 222 in epoch 4, gen_loss = 1.170849323807276, disc_loss = 0.001646878913639013
Trained batch 223 in epoch 4, gen_loss = 1.1696863578898566, disc_loss = 0.0016428089985700872
Trained batch 224 in epoch 4, gen_loss = 1.17006468878852, disc_loss = 0.0016384450073302205
Trained batch 225 in epoch 4, gen_loss = 1.1701016294217743, disc_loss = 0.001636767255238142
Trained batch 226 in epoch 4, gen_loss = 1.1718475524549443, disc_loss = 0.0016343069206646312
Trained batch 227 in epoch 4, gen_loss = 1.1718017793538278, disc_loss = 0.0016308127132217858
Trained batch 228 in epoch 4, gen_loss = 1.1714607492805047, disc_loss = 0.0016293856049694657
Trained batch 229 in epoch 4, gen_loss = 1.1716483883235767, disc_loss = 0.0016254787407967302
Trained batch 230 in epoch 4, gen_loss = 1.1710376362779955, disc_loss = 0.0016206495590594665
Trained batch 231 in epoch 4, gen_loss = 1.1711469636908893, disc_loss = 0.001615375919284596
Trained batch 232 in epoch 4, gen_loss = 1.1709302407989175, disc_loss = 0.0016124320358623522
Trained batch 233 in epoch 4, gen_loss = 1.1702434165864928, disc_loss = 0.0016092871064290356
Trained batch 234 in epoch 4, gen_loss = 1.1690411486524217, disc_loss = 0.0016062728583842436
Trained batch 235 in epoch 4, gen_loss = 1.1689022829977131, disc_loss = 0.0016051728594841008
Trained batch 236 in epoch 4, gen_loss = 1.1687178973910175, disc_loss = 0.0016022075783266815
Trained batch 237 in epoch 4, gen_loss = 1.1697246627647335, disc_loss = 0.0015989807729086909
Trained batch 238 in epoch 4, gen_loss = 1.1706103051556702, disc_loss = 0.0015941381348037866
Trained batch 239 in epoch 4, gen_loss = 1.1707329710324605, disc_loss = 0.0015894055478080796
Trained batch 240 in epoch 4, gen_loss = 1.1704200145119947, disc_loss = 0.0015848239543712484
Trained batch 241 in epoch 4, gen_loss = 1.1699643617819164, disc_loss = 0.0015809509678539812
Trained batch 242 in epoch 4, gen_loss = 1.1696251743614918, disc_loss = 0.0015776219306831774
Trained batch 243 in epoch 4, gen_loss = 1.1705875328329742, disc_loss = 0.0015745070549663248
Trained batch 244 in epoch 4, gen_loss = 1.1708249982522458, disc_loss = 0.0015705634010670592
Trained batch 245 in epoch 4, gen_loss = 1.1707742776327985, disc_loss = 0.0015677172729435067
Trained batch 246 in epoch 4, gen_loss = 1.1705915927886963, disc_loss = 0.0015639589337334188
Trained batch 247 in epoch 4, gen_loss = 1.1706606649583386, disc_loss = 0.0015602044664011637
Trained batch 248 in epoch 4, gen_loss = 1.1705764766677795, disc_loss = 0.0015573152399390008
Trained batch 249 in epoch 4, gen_loss = 1.1701584434509278, disc_loss = 0.001554548452142626
Trained batch 250 in epoch 4, gen_loss = 1.1704028080184146, disc_loss = 0.0015521737156933048
Trained batch 251 in epoch 4, gen_loss = 1.1702374607797652, disc_loss = 0.0015481766759111205
Trained batch 252 in epoch 4, gen_loss = 1.1704813439855462, disc_loss = 0.0015438992296356575
Trained batch 253 in epoch 4, gen_loss = 1.1702070250285892, disc_loss = 0.0015395474927243228
Trained batch 254 in epoch 4, gen_loss = 1.170118808746338, disc_loss = 0.0015360320712823202
Trained batch 255 in epoch 4, gen_loss = 1.1694370387122035, disc_loss = 0.001532443849100673
Trained batch 256 in epoch 4, gen_loss = 1.170223444352354, disc_loss = 0.001528240202274717
Trained batch 257 in epoch 4, gen_loss = 1.1698527017305063, disc_loss = 0.0015245207088824377
Trained batch 258 in epoch 4, gen_loss = 1.16967743842298, disc_loss = 0.0015208128614766473
Trained batch 259 in epoch 4, gen_loss = 1.1693984082111946, disc_loss = 0.0015177439283713913
Trained batch 260 in epoch 4, gen_loss = 1.1693587051954306, disc_loss = 0.0015135720390933513
Trained batch 261 in epoch 4, gen_loss = 1.169453214598066, disc_loss = 0.0015099818355275873
Trained batch 262 in epoch 4, gen_loss = 1.169587555493692, disc_loss = 0.0015089252778637036
Trained batch 263 in epoch 4, gen_loss = 1.16955189677802, disc_loss = 0.0015056167826652668
Trained batch 264 in epoch 4, gen_loss = 1.1697403624372662, disc_loss = 0.0015024975069605237
Trained batch 265 in epoch 4, gen_loss = 1.169751875382617, disc_loss = 0.0014991645805828302
Trained batch 266 in epoch 4, gen_loss = 1.1694349889898121, disc_loss = 0.0014955682770701384
Trained batch 267 in epoch 4, gen_loss = 1.1686847112072047, disc_loss = 0.0014925846897774556
Trained batch 268 in epoch 4, gen_loss = 1.1685621153466321, disc_loss = 0.001489435297914791
Trained batch 269 in epoch 4, gen_loss = 1.1687198921486184, disc_loss = 0.0014864064845756663
Trained batch 270 in epoch 4, gen_loss = 1.1681298989651387, disc_loss = 0.0014828319600748922
Trained batch 271 in epoch 4, gen_loss = 1.1693513489821379, disc_loss = 0.00147964622160276
Trained batch 272 in epoch 4, gen_loss = 1.1693444413579863, disc_loss = 0.0014761662393835656
Trained batch 273 in epoch 4, gen_loss = 1.1695994491124675, disc_loss = 0.0014719303388677088
Trained batch 274 in epoch 4, gen_loss = 1.16969435041601, disc_loss = 0.0014677202113142069
Trained batch 275 in epoch 4, gen_loss = 1.1692070516123287, disc_loss = 0.0014647947958808904
Trained batch 276 in epoch 4, gen_loss = 1.1698383660953398, disc_loss = 0.001463670254347086
Trained batch 277 in epoch 4, gen_loss = 1.169829278541126, disc_loss = 0.0014619567289549803
Trained batch 278 in epoch 4, gen_loss = 1.169808584729403, disc_loss = 0.0014581714152178216
Trained batch 279 in epoch 4, gen_loss = 1.170119291969708, disc_loss = 0.0014550625240579913
Trained batch 280 in epoch 4, gen_loss = 1.1692732638311556, disc_loss = 0.0014524894813738524
Trained batch 281 in epoch 4, gen_loss = 1.169017122358295, disc_loss = 0.0014485749318008476
Trained batch 282 in epoch 4, gen_loss = 1.1685807850251348, disc_loss = 0.0014450233571590072
Trained batch 283 in epoch 4, gen_loss = 1.1681780078461472, disc_loss = 0.0014420514961156969
Trained batch 284 in epoch 4, gen_loss = 1.1684368993106642, disc_loss = 0.0014387383219671614
Trained batch 285 in epoch 4, gen_loss = 1.1684624846581813, disc_loss = 0.0014348114176996874
Trained batch 286 in epoch 4, gen_loss = 1.1685252607076426, disc_loss = 0.0014310176758085887
Trained batch 287 in epoch 4, gen_loss = 1.1682657924377255, disc_loss = 0.0014273019455180878
Trained batch 288 in epoch 4, gen_loss = 1.1685708981896767, disc_loss = 0.00142341495489953
Trained batch 289 in epoch 4, gen_loss = 1.1682557494475925, disc_loss = 0.001420358657949315
Trained batch 290 in epoch 4, gen_loss = 1.1683861953286372, disc_loss = 0.0014175195899020713
Trained batch 291 in epoch 4, gen_loss = 1.1689367500478274, disc_loss = 0.00141497223585372
Trained batch 292 in epoch 4, gen_loss = 1.1691203070581977, disc_loss = 0.001413567829241423
Trained batch 293 in epoch 4, gen_loss = 1.1690587010107885, disc_loss = 0.0014113709096936192
Trained batch 294 in epoch 4, gen_loss = 1.168832455045086, disc_loss = 0.001407440082698871
Trained batch 295 in epoch 4, gen_loss = 1.1686974878649454, disc_loss = 0.0014050304439356173
Trained batch 296 in epoch 4, gen_loss = 1.1684493410466896, disc_loss = 0.0014019980738550952
Trained batch 297 in epoch 4, gen_loss = 1.168845216099848, disc_loss = 0.0014000101266553838
Trained batch 298 in epoch 4, gen_loss = 1.1689480445456744, disc_loss = 0.0013981050740457125
Trained batch 299 in epoch 4, gen_loss = 1.1685788307587306, disc_loss = 0.0013949507339081416
Trained batch 300 in epoch 4, gen_loss = 1.1685789377982434, disc_loss = 0.0013923879286995239
Trained batch 301 in epoch 4, gen_loss = 1.167980834150946, disc_loss = 0.0013929145148144234
Trained batch 302 in epoch 4, gen_loss = 1.1678715072842714, disc_loss = 0.0013901471176104797
Trained batch 303 in epoch 4, gen_loss = 1.1680186075207435, disc_loss = 0.0013878982828923892
Trained batch 304 in epoch 4, gen_loss = 1.1679019433553102, disc_loss = 0.001386044018703406
Trained batch 305 in epoch 4, gen_loss = 1.1672640844108233, disc_loss = 0.001384706412947256
Trained batch 306 in epoch 4, gen_loss = 1.1675117295417412, disc_loss = 0.0013823119194644234
Trained batch 307 in epoch 4, gen_loss = 1.1674717916296673, disc_loss = 0.0013788342880320964
Trained batch 308 in epoch 4, gen_loss = 1.1675522447018176, disc_loss = 0.0013756813028598246
Trained batch 309 in epoch 4, gen_loss = 1.1671395536391966, disc_loss = 0.001373134212823765
Trained batch 310 in epoch 4, gen_loss = 1.1673071311601104, disc_loss = 0.0013697056979063743
Trained batch 311 in epoch 4, gen_loss = 1.1674534812187538, disc_loss = 0.0013666246630190215
Trained batch 312 in epoch 4, gen_loss = 1.1670608623340106, disc_loss = 0.001363412910844006
Trained batch 313 in epoch 4, gen_loss = 1.166940075576685, disc_loss = 0.0013603571175625786
Trained batch 314 in epoch 4, gen_loss = 1.1668239725960625, disc_loss = 0.0013571666420570442
Trained batch 315 in epoch 4, gen_loss = 1.1666146882727175, disc_loss = 0.0013544406906533632
Trained batch 316 in epoch 4, gen_loss = 1.1665238627123908, disc_loss = 0.001351143153419583
Trained batch 317 in epoch 4, gen_loss = 1.1666463043704722, disc_loss = 0.0013480273734539478
Trained batch 318 in epoch 4, gen_loss = 1.1666261316466855, disc_loss = 0.0013449199115061917
Trained batch 319 in epoch 4, gen_loss = 1.1666990716010333, disc_loss = 0.0013415306115348359
Trained batch 320 in epoch 4, gen_loss = 1.1667424990009296, disc_loss = 0.001338581854696574
Trained batch 321 in epoch 4, gen_loss = 1.1670038070737945, disc_loss = 0.0013354272145621757
Trained batch 322 in epoch 4, gen_loss = 1.1671142925049867, disc_loss = 0.0013331861805384142
Trained batch 323 in epoch 4, gen_loss = 1.166903132273827, disc_loss = 0.0013302808600897545
Trained batch 324 in epoch 4, gen_loss = 1.1668564238915076, disc_loss = 0.0013273880276112602
Trained batch 325 in epoch 4, gen_loss = 1.1668327147243944, disc_loss = 0.001324731048908616
Trained batch 326 in epoch 4, gen_loss = 1.16624174533634, disc_loss = 0.0013218586152776881
Trained batch 327 in epoch 4, gen_loss = 1.166398584115796, disc_loss = 0.0013190609822298185
Trained batch 328 in epoch 4, gen_loss = 1.1661757857603867, disc_loss = 0.0013160256599571477
Trained batch 329 in epoch 4, gen_loss = 1.1670272744063175, disc_loss = 0.0013134429213647364
Trained batch 330 in epoch 4, gen_loss = 1.1672321644434396, disc_loss = 0.0013113078806166651
Trained batch 331 in epoch 4, gen_loss = 1.1673432060753006, disc_loss = 0.0013087804225681585
Trained batch 332 in epoch 4, gen_loss = 1.1675502720537845, disc_loss = 0.0013068152441085225
Trained batch 333 in epoch 4, gen_loss = 1.1675325021772327, disc_loss = 0.0013053709438766358
Trained batch 334 in epoch 4, gen_loss = 1.166883064383891, disc_loss = 0.0013030473694531943
Trained batch 335 in epoch 4, gen_loss = 1.1668808956940968, disc_loss = 0.0013014542307376229
Trained batch 336 in epoch 4, gen_loss = 1.1665313335837526, disc_loss = 0.0013000676751265285
Trained batch 337 in epoch 4, gen_loss = 1.1666126826105738, disc_loss = 0.0012996707680068922
Trained batch 338 in epoch 4, gen_loss = 1.1661267931130783, disc_loss = 0.001298050217486363
Trained batch 339 in epoch 4, gen_loss = 1.166131603717804, disc_loss = 0.0012957725376883686
Trained batch 340 in epoch 4, gen_loss = 1.1657955611556157, disc_loss = 0.0012932929627377475
Trained batch 341 in epoch 4, gen_loss = 1.1660474211151837, disc_loss = 0.0012906003809446873
Trained batch 342 in epoch 4, gen_loss = 1.1660223827417668, disc_loss = 0.0012882505607168101
Trained batch 343 in epoch 4, gen_loss = 1.1657689331575882, disc_loss = 0.0012875145722043885
Trained batch 344 in epoch 4, gen_loss = 1.1651642543682155, disc_loss = 0.0012858174642568212
Trained batch 345 in epoch 4, gen_loss = 1.164724693822034, disc_loss = 0.0012844935816751708
Trained batch 346 in epoch 4, gen_loss = 1.1651714968062958, disc_loss = 0.001283261485237451
Trained batch 347 in epoch 4, gen_loss = 1.1645550803206433, disc_loss = 0.0012815968357140317
Trained batch 348 in epoch 4, gen_loss = 1.1644071521595079, disc_loss = 0.0012800875234112068
Trained batch 349 in epoch 4, gen_loss = 1.1656984792436873, disc_loss = 0.001278890760898191
Trained batch 350 in epoch 4, gen_loss = 1.1660412835259724, disc_loss = 0.0012767371371490588
Trained batch 351 in epoch 4, gen_loss = 1.1665906171229752, disc_loss = 0.0012740646018507753
Trained batch 352 in epoch 4, gen_loss = 1.1662569501920057, disc_loss = 0.0012721507509124252
Trained batch 353 in epoch 4, gen_loss = 1.166424611530735, disc_loss = 0.0012699755348198085
Trained batch 354 in epoch 4, gen_loss = 1.1666332798944392, disc_loss = 0.0012680227105000752
Trained batch 355 in epoch 4, gen_loss = 1.1660906782980716, disc_loss = 0.0012655383700425108
Trained batch 356 in epoch 4, gen_loss = 1.1661341464152188, disc_loss = 0.0012626924005980115
Trained batch 357 in epoch 4, gen_loss = 1.1659130457393283, disc_loss = 0.0012603518654697695
Trained batch 358 in epoch 4, gen_loss = 1.16587316358986, disc_loss = 0.001258325545051755
Trained batch 359 in epoch 4, gen_loss = 1.1653979134228494, disc_loss = 0.001256005958566675
Trained batch 360 in epoch 4, gen_loss = 1.1652167878652875, disc_loss = 0.0012533812533897656
Trained batch 361 in epoch 4, gen_loss = 1.1659093872947588, disc_loss = 0.0012521514129916267
Trained batch 362 in epoch 4, gen_loss = 1.165655041036527, disc_loss = 0.001249799584089868
Trained batch 363 in epoch 4, gen_loss = 1.165484600833484, disc_loss = 0.0012471916687810424
Trained batch 364 in epoch 4, gen_loss = 1.1653599074442094, disc_loss = 0.0012449911753296189
Trained batch 365 in epoch 4, gen_loss = 1.1648707472887196, disc_loss = 0.001242495467393313
Trained batch 366 in epoch 4, gen_loss = 1.1651879407729375, disc_loss = 0.0012403439263475688
Trained batch 367 in epoch 4, gen_loss = 1.1655996838665528, disc_loss = 0.001237808639574644
Trained batch 368 in epoch 4, gen_loss = 1.1650802557707478, disc_loss = 0.0012355936518592663
Trained batch 369 in epoch 4, gen_loss = 1.1647577735217842, disc_loss = 0.0012338326075051382
Trained batch 370 in epoch 4, gen_loss = 1.164888615074826, disc_loss = 0.0012314152804070286
Trained batch 371 in epoch 4, gen_loss = 1.1646826217571895, disc_loss = 0.0012294821039352927
Trained batch 372 in epoch 4, gen_loss = 1.1649198763811557, disc_loss = 0.0012277751769645803
Trained batch 373 in epoch 4, gen_loss = 1.1649416616574966, disc_loss = 0.0012255335668037162
Trained batch 374 in epoch 4, gen_loss = 1.1654441679318746, disc_loss = 0.0012234115592048814
Trained batch 375 in epoch 4, gen_loss = 1.1655952472318993, disc_loss = 0.0012215353898237151
Trained batch 376 in epoch 4, gen_loss = 1.1660020615441098, disc_loss = 0.0012199718640859064
Trained batch 377 in epoch 4, gen_loss = 1.1660442836385556, disc_loss = 0.0012180381964999325
Trained batch 378 in epoch 4, gen_loss = 1.1668932197276394, disc_loss = 0.0012159525859261812
Trained batch 379 in epoch 4, gen_loss = 1.1672148044172086, disc_loss = 0.001213358534388183
Trained batch 380 in epoch 4, gen_loss = 1.1666368277367019, disc_loss = 0.0012131082245042998
Trained batch 381 in epoch 4, gen_loss = 1.1666272557218662, disc_loss = 0.0012118147988361794
Trained batch 382 in epoch 4, gen_loss = 1.1664440018701179, disc_loss = 0.0012101592237598509
Trained batch 383 in epoch 4, gen_loss = 1.166686094366014, disc_loss = 0.0012077962970806766
Trained batch 384 in epoch 4, gen_loss = 1.1661975814150525, disc_loss = 0.0012067749442807821
Trained batch 385 in epoch 4, gen_loss = 1.166049776608462, disc_loss = 0.0012044660004601967
Trained batch 386 in epoch 4, gen_loss = 1.1658900147568656, disc_loss = 0.001203497658967695
Trained batch 387 in epoch 4, gen_loss = 1.1667316085899, disc_loss = 0.0012033171575596272
Trained batch 388 in epoch 4, gen_loss = 1.1669883455286296, disc_loss = 0.0012013650146372266
Trained batch 389 in epoch 4, gen_loss = 1.1671832595116054, disc_loss = 0.0011996925123056803
Trained batch 390 in epoch 4, gen_loss = 1.1667812221190508, disc_loss = 0.0011976030521595594
Trained batch 391 in epoch 4, gen_loss = 1.1667976528406143, disc_loss = 0.0011954290256820672
Trained batch 392 in epoch 4, gen_loss = 1.1666077293512476, disc_loss = 0.0011934409860824295
Trained batch 393 in epoch 4, gen_loss = 1.1666322447321742, disc_loss = 0.0011913004789786852
Trained batch 394 in epoch 4, gen_loss = 1.1662586354002167, disc_loss = 0.0011893242883829023
Trained batch 395 in epoch 4, gen_loss = 1.1667426544608492, disc_loss = 0.0011871298617431119
Trained batch 396 in epoch 4, gen_loss = 1.167230868819979, disc_loss = 0.0011854587950534364
Trained batch 397 in epoch 4, gen_loss = 1.1672476227559037, disc_loss = 0.0011835529457765454
Trained batch 398 in epoch 4, gen_loss = 1.1674595351207226, disc_loss = 0.0011812526367462933
Trained batch 399 in epoch 4, gen_loss = 1.1676313561201095, disc_loss = 0.0011787853280111448
Trained batch 400 in epoch 4, gen_loss = 1.1673987937389765, disc_loss = 0.0011765224004293238
Trained batch 401 in epoch 4, gen_loss = 1.1669846793905418, disc_loss = 0.0011746590691780793
Trained batch 402 in epoch 4, gen_loss = 1.1667532769977011, disc_loss = 0.0011737269295088338
Trained batch 403 in epoch 4, gen_loss = 1.1664899242396403, disc_loss = 0.0011719447765343748
Trained batch 404 in epoch 4, gen_loss = 1.167527390409399, disc_loss = 0.0011710911297187624
Trained batch 405 in epoch 4, gen_loss = 1.1674275101699265, disc_loss = 0.0011696987442031109
Trained batch 406 in epoch 4, gen_loss = 1.1674003964267141, disc_loss = 0.001167697889194881
Trained batch 407 in epoch 4, gen_loss = 1.167469226846508, disc_loss = 0.0011656912830207433
Trained batch 408 in epoch 4, gen_loss = 1.167392985453524, disc_loss = 0.0011636005387348886
Trained batch 409 in epoch 4, gen_loss = 1.1673490605703214, disc_loss = 0.0011620504433067697
Trained batch 410 in epoch 4, gen_loss = 1.1671363399556665, disc_loss = 0.0011618820457677346
Trained batch 411 in epoch 4, gen_loss = 1.1670481276164935, disc_loss = 0.0011605800153349653
Trained batch 412 in epoch 4, gen_loss = 1.167391075926312, disc_loss = 0.0011595119491752833
Trained batch 413 in epoch 4, gen_loss = 1.1671382813637958, disc_loss = 0.0011581491827565484
Trained batch 414 in epoch 4, gen_loss = 1.166668096220637, disc_loss = 0.0011577487960373646
Trained batch 415 in epoch 4, gen_loss = 1.166496288891022, disc_loss = 0.001155924761895641
Trained batch 416 in epoch 4, gen_loss = 1.1663664307811563, disc_loss = 0.0011540007845490805
Trained batch 417 in epoch 4, gen_loss = 1.1661461734315426, disc_loss = 0.0011521728270554594
Trained batch 418 in epoch 4, gen_loss = 1.166433013993402, disc_loss = 0.0011502050807580646
Trained batch 419 in epoch 4, gen_loss = 1.1664623623802548, disc_loss = 0.0011481360959199568
Trained batch 420 in epoch 4, gen_loss = 1.1660774824455062, disc_loss = 0.001146054083111999
Trained batch 421 in epoch 4, gen_loss = 1.1658690687604425, disc_loss = 0.0011438846716619211
Trained batch 422 in epoch 4, gen_loss = 1.1659416340767068, disc_loss = 0.001141830022416813
Trained batch 423 in epoch 4, gen_loss = 1.1657805127917595, disc_loss = 0.0011406386392133394
Trained batch 424 in epoch 4, gen_loss = 1.1656346674526439, disc_loss = 0.0011386914719375507
Trained batch 425 in epoch 4, gen_loss = 1.165398833337524, disc_loss = 0.0011370413713066997
Trained batch 426 in epoch 4, gen_loss = 1.1655088336462158, disc_loss = 0.001136073041744083
Trained batch 427 in epoch 4, gen_loss = 1.1655183245088452, disc_loss = 0.0011350801930951593
Trained batch 428 in epoch 4, gen_loss = 1.1657309037544232, disc_loss = 0.0011332523265171314
Trained batch 429 in epoch 4, gen_loss = 1.165567439933156, disc_loss = 0.0011316014773572448
Trained batch 430 in epoch 4, gen_loss = 1.1653390943036002, disc_loss = 0.001129778439975603
Trained batch 431 in epoch 4, gen_loss = 1.1650119564599462, disc_loss = 0.001128525534383058
Trained batch 432 in epoch 4, gen_loss = 1.1646104665606456, disc_loss = 0.0011269697625021714
Trained batch 433 in epoch 4, gen_loss = 1.1644318419667432, disc_loss = 0.0011258523429146848
Trained batch 434 in epoch 4, gen_loss = 1.1644836751894019, disc_loss = 0.0011241186572434167
Trained batch 435 in epoch 4, gen_loss = 1.1639832580855134, disc_loss = 0.0011251409541895088
Trained batch 436 in epoch 4, gen_loss = 1.164277664311145, disc_loss = 0.0011241839205576064
Trained batch 437 in epoch 4, gen_loss = 1.1643475468300248, disc_loss = 0.0011229484695072082
Trained batch 438 in epoch 4, gen_loss = 1.164294552151326, disc_loss = 0.0011210640677124164
Trained batch 439 in epoch 4, gen_loss = 1.1640053524212404, disc_loss = 0.0011201473200675206
Trained batch 440 in epoch 4, gen_loss = 1.1641236497701701, disc_loss = 0.0011193111222176633
Trained batch 441 in epoch 4, gen_loss = 1.1642467622303856, disc_loss = 0.0011183474005404882
Trained batch 442 in epoch 4, gen_loss = 1.1639587300625664, disc_loss = 0.0011172057696080475
Trained batch 443 in epoch 4, gen_loss = 1.1644001573592693, disc_loss = 0.0011159125229447077
Trained batch 444 in epoch 4, gen_loss = 1.1646364696909872, disc_loss = 0.0011141130782132758
Trained batch 445 in epoch 4, gen_loss = 1.1643678765125873, disc_loss = 0.0011127980259487786
Trained batch 446 in epoch 4, gen_loss = 1.1643872626409169, disc_loss = 0.0011115306780334474
Trained batch 447 in epoch 4, gen_loss = 1.165481391495892, disc_loss = 0.001110362074054397
Trained batch 448 in epoch 4, gen_loss = 1.165311841762942, disc_loss = 0.0011095905734886226
Trained batch 449 in epoch 4, gen_loss = 1.1653071000840929, disc_loss = 0.0011082390746580332
Trained batch 450 in epoch 4, gen_loss = 1.1654538185792065, disc_loss = 0.0011065569527830802
Trained batch 451 in epoch 4, gen_loss = 1.1655871617583047, disc_loss = 0.0011053730164687005
Trained batch 452 in epoch 4, gen_loss = 1.1654808908108845, disc_loss = 0.0011035075133204334
Trained batch 453 in epoch 4, gen_loss = 1.1656756781796527, disc_loss = 0.0011016711724282546
Trained batch 454 in epoch 4, gen_loss = 1.1658181942426242, disc_loss = 0.0010998201152568191
Trained batch 455 in epoch 4, gen_loss = 1.166014201808394, disc_loss = 0.0010982303287675134
Trained batch 456 in epoch 4, gen_loss = 1.1656909870631846, disc_loss = 0.001096632040157472
Trained batch 457 in epoch 4, gen_loss = 1.1653249621651578, disc_loss = 0.0010948026280249794
Trained batch 458 in epoch 4, gen_loss = 1.166108284251103, disc_loss = 0.0010934807408678655
Trained batch 459 in epoch 4, gen_loss = 1.1658772723830264, disc_loss = 0.001091976269842986
Trained batch 460 in epoch 4, gen_loss = 1.1657395131417314, disc_loss = 0.001091051291339271
Trained batch 461 in epoch 4, gen_loss = 1.1656473453168745, disc_loss = 0.0010899110915236583
Trained batch 462 in epoch 4, gen_loss = 1.1658599269827807, disc_loss = 0.001088489842864878
Trained batch 463 in epoch 4, gen_loss = 1.1657969713981808, disc_loss = 0.0010878036891881493
Trained batch 464 in epoch 4, gen_loss = 1.1656321467891817, disc_loss = 0.0010862142938221754
Trained batch 465 in epoch 4, gen_loss = 1.165225431514912, disc_loss = 0.00108522933345341
Trained batch 466 in epoch 4, gen_loss = 1.1656556447261917, disc_loss = 0.0010840065626298403
Trained batch 467 in epoch 4, gen_loss = 1.1656611275214415, disc_loss = 0.001083016037274576
Trained batch 468 in epoch 4, gen_loss = 1.1656989040913612, disc_loss = 0.0010821310735840315
Trained batch 469 in epoch 4, gen_loss = 1.1660046216021194, disc_loss = 0.0010809995369314453
Trained batch 470 in epoch 4, gen_loss = 1.1662136912345886, disc_loss = 0.0010793110540924166
Trained batch 471 in epoch 4, gen_loss = 1.1657957463698871, disc_loss = 0.0010789006652068287
Trained batch 472 in epoch 4, gen_loss = 1.165820572265359, disc_loss = 0.0010785469961616982
Trained batch 473 in epoch 4, gen_loss = 1.1656677960594999, disc_loss = 0.0010770626727111916
Trained batch 474 in epoch 4, gen_loss = 1.1653700824787743, disc_loss = 0.0010760460109878823
Trained batch 475 in epoch 4, gen_loss = 1.1653789864117359, disc_loss = 0.0010743036838001356
Trained batch 476 in epoch 4, gen_loss = 1.1654656616896704, disc_loss = 0.0010727926323556905
Trained batch 477 in epoch 4, gen_loss = 1.165281371965568, disc_loss = 0.0010712946333499161
Trained batch 478 in epoch 4, gen_loss = 1.164908922664308, disc_loss = 0.0010698127398028725
Trained batch 479 in epoch 4, gen_loss = 1.164826250448823, disc_loss = 0.0010689489558293038
Trained batch 480 in epoch 4, gen_loss = 1.1651467180301642, disc_loss = 0.0010676385048283613
Trained batch 481 in epoch 4, gen_loss = 1.1650865902791874, disc_loss = 0.0010659684701757486
Trained batch 482 in epoch 4, gen_loss = 1.16497911861471, disc_loss = 0.0010644648946047035
Trained batch 483 in epoch 4, gen_loss = 1.1651315904599575, disc_loss = 0.0010628231515406057
Trained batch 484 in epoch 4, gen_loss = 1.1650201530800652, disc_loss = 0.0010616543566263233
Trained batch 485 in epoch 4, gen_loss = 1.1649494567280443, disc_loss = 0.0010601895158104848
Trained batch 486 in epoch 4, gen_loss = 1.1648985628474664, disc_loss = 0.0010585352920726787
Trained batch 487 in epoch 4, gen_loss = 1.1651037373259419, disc_loss = 0.0010570351099826827
Trained batch 488 in epoch 4, gen_loss = 1.165074221073728, disc_loss = 0.0010559960512279158
Trained batch 489 in epoch 4, gen_loss = 1.1650901987844584, disc_loss = 0.0010545851265101657
Trained batch 490 in epoch 4, gen_loss = 1.1657448716901713, disc_loss = 0.0010530651580386316
Trained batch 491 in epoch 4, gen_loss = 1.1654398919847924, disc_loss = 0.0010518225819278013
Trained batch 492 in epoch 4, gen_loss = 1.165144745645852, disc_loss = 0.0010513214624506227
Trained batch 493 in epoch 4, gen_loss = 1.1647669377355923, disc_loss = 0.0010509802970758578
Trained batch 494 in epoch 4, gen_loss = 1.1645225164866206, disc_loss = 0.001049774084939866
Trained batch 495 in epoch 4, gen_loss = 1.1645347763213418, disc_loss = 0.0010482407403669053
Trained batch 496 in epoch 4, gen_loss = 1.1648656438054212, disc_loss = 0.0010472664537699518
Trained batch 497 in epoch 4, gen_loss = 1.1647702964194808, disc_loss = 0.0010457792021364562
Trained batch 498 in epoch 4, gen_loss = 1.1645966511451171, disc_loss = 0.001044619831524627
Trained batch 499 in epoch 4, gen_loss = 1.1642627015113831, disc_loss = 0.0010438548792444636
Trained batch 500 in epoch 4, gen_loss = 1.1646131755349165, disc_loss = 0.001042718914012841
Trained batch 501 in epoch 4, gen_loss = 1.1649391786510725, disc_loss = 0.00104137043904284
Trained batch 502 in epoch 4, gen_loss = 1.1647089177050125, disc_loss = 0.0010403294001289812
Trained batch 503 in epoch 4, gen_loss = 1.1644016882729908, disc_loss = 0.0010393297723653848
Trained batch 504 in epoch 4, gen_loss = 1.1648463629259922, disc_loss = 0.0010385746166564173
Trained batch 505 in epoch 4, gen_loss = 1.1651665554216257, disc_loss = 0.0010370958878361002
Trained batch 506 in epoch 4, gen_loss = 1.165149347316584, disc_loss = 0.0010363600863232433
Trained batch 507 in epoch 4, gen_loss = 1.16547792727553, disc_loss = 0.001034913280747114
Trained batch 508 in epoch 4, gen_loss = 1.1652509777391356, disc_loss = 0.001033795443755732
Trained batch 509 in epoch 4, gen_loss = 1.1655001027911318, disc_loss = 0.0010327768203626643
Trained batch 510 in epoch 4, gen_loss = 1.1654628666879614, disc_loss = 0.0010312828353509114
Trained batch 511 in epoch 4, gen_loss = 1.1653580912388861, disc_loss = 0.001029824719211092
Trained batch 512 in epoch 4, gen_loss = 1.1656558295207182, disc_loss = 0.0010286604186629362
Trained batch 513 in epoch 4, gen_loss = 1.1658370283791064, disc_loss = 0.0010280268695597276
Trained batch 514 in epoch 4, gen_loss = 1.1657099149759533, disc_loss = 0.0010272263571025478
Trained batch 515 in epoch 4, gen_loss = 1.1653684229813805, disc_loss = 0.0010260722963213868
Trained batch 516 in epoch 4, gen_loss = 1.165496886583546, disc_loss = 0.001024527685691754
Trained batch 517 in epoch 4, gen_loss = 1.1658296921078302, disc_loss = 0.00102303486616188
Trained batch 518 in epoch 4, gen_loss = 1.1658813163264867, disc_loss = 0.0010216468509709686
Trained batch 519 in epoch 4, gen_loss = 1.1656710076790588, disc_loss = 0.0010207690991172478
Trained batch 520 in epoch 4, gen_loss = 1.1657099952624534, disc_loss = 0.001019776600895444
Trained batch 521 in epoch 4, gen_loss = 1.1657455727971833, disc_loss = 0.0010186748173976784
Trained batch 522 in epoch 4, gen_loss = 1.1660705542701153, disc_loss = 0.0010174719028183336
Trained batch 523 in epoch 4, gen_loss = 1.1660916605068528, disc_loss = 0.0010161926994712949
Trained batch 524 in epoch 4, gen_loss = 1.1658394731794084, disc_loss = 0.0010151459462109155
Trained batch 525 in epoch 4, gen_loss = 1.1658624501282724, disc_loss = 0.0010139640643823087
Trained batch 526 in epoch 4, gen_loss = 1.1657601072394643, disc_loss = 0.0010133757170316705
Trained batch 527 in epoch 4, gen_loss = 1.1657968624071642, disc_loss = 0.0010123532820216496
Trained batch 528 in epoch 4, gen_loss = 1.1656282412307248, disc_loss = 0.001011246415710082
Trained batch 529 in epoch 4, gen_loss = 1.1653451942047983, disc_loss = 0.0010100859075945028
Trained batch 530 in epoch 4, gen_loss = 1.165036055776808, disc_loss = 0.0010093262727627103
Trained batch 531 in epoch 4, gen_loss = 1.1648733806341214, disc_loss = 0.0010083964417780017
Trained batch 532 in epoch 4, gen_loss = 1.1649365753885952, disc_loss = 0.0010070033091276371
Trained batch 533 in epoch 4, gen_loss = 1.164903673116634, disc_loss = 0.001005737686645081
Trained batch 534 in epoch 4, gen_loss = 1.1645391459776977, disc_loss = 0.0010046903858076624
Trained batch 535 in epoch 4, gen_loss = 1.1648644851659662, disc_loss = 0.0010033581953366728
Trained batch 536 in epoch 4, gen_loss = 1.1647026296878438, disc_loss = 0.0010022524524719873
Trained batch 537 in epoch 4, gen_loss = 1.165196158407346, disc_loss = 0.0010013872236119441
Trained batch 538 in epoch 4, gen_loss = 1.1649196046181645, disc_loss = 0.0010022448006974608
Trained batch 539 in epoch 4, gen_loss = 1.1647436846185613, disc_loss = 0.001001249736523109
Trained batch 540 in epoch 4, gen_loss = 1.16463025550525, disc_loss = 0.0010011351114909755
Trained batch 541 in epoch 4, gen_loss = 1.164684037880704, disc_loss = 0.0010004464974375596
Trained batch 542 in epoch 4, gen_loss = 1.1644795898135416, disc_loss = 0.0009995750779477695
Trained batch 543 in epoch 4, gen_loss = 1.1643987959798645, disc_loss = 0.0009985862166104198
Trained batch 544 in epoch 4, gen_loss = 1.1644724885258106, disc_loss = 0.0009972266888901712
Trained batch 545 in epoch 4, gen_loss = 1.1643779921881008, disc_loss = 0.000996186700068549
Trained batch 546 in epoch 4, gen_loss = 1.164079154649208, disc_loss = 0.000995534630589165
Trained batch 547 in epoch 4, gen_loss = 1.164210912737533, disc_loss = 0.0009948148481736052
Trained batch 548 in epoch 4, gen_loss = 1.1644410902468016, disc_loss = 0.000993517578969869
Trained batch 549 in epoch 4, gen_loss = 1.1647135229544205, disc_loss = 0.0009922435268791478
Trained batch 550 in epoch 4, gen_loss = 1.1651604069555737, disc_loss = 0.0009910612407606518
Trained batch 551 in epoch 4, gen_loss = 1.164928811399833, disc_loss = 0.000989752058518681
Trained batch 552 in epoch 4, gen_loss = 1.1649165134102268, disc_loss = 0.0009883656290698305
Trained batch 553 in epoch 4, gen_loss = 1.1650100445058802, disc_loss = 0.0009871425468765454
Trained batch 554 in epoch 4, gen_loss = 1.164739195076195, disc_loss = 0.0009858967357751418
Trained batch 555 in epoch 4, gen_loss = 1.1649055502397552, disc_loss = 0.0009846581888268702
Trained batch 556 in epoch 4, gen_loss = 1.1650288319031255, disc_loss = 0.0009837124056849107
Trained batch 557 in epoch 4, gen_loss = 1.1647939284642537, disc_loss = 0.0009826587274312593
Trained batch 558 in epoch 4, gen_loss = 1.1644555931654301, disc_loss = 0.0009818007751040607
Trained batch 559 in epoch 4, gen_loss = 1.1645965535725866, disc_loss = 0.0009808332210273615
Trained batch 560 in epoch 4, gen_loss = 1.1642994769116775, disc_loss = 0.0009796298232465756
Trained batch 561 in epoch 4, gen_loss = 1.1640474371002238, disc_loss = 0.0009787377187347511
Trained batch 562 in epoch 4, gen_loss = 1.1642194280192442, disc_loss = 0.0009782413457235782
Trained batch 563 in epoch 4, gen_loss = 1.1640940992333364, disc_loss = 0.0009778800396932328
Trained batch 564 in epoch 4, gen_loss = 1.1638872656147037, disc_loss = 0.0009768881107705225
Trained batch 565 in epoch 4, gen_loss = 1.1636755781333774, disc_loss = 0.0009755374187671056
Trained batch 566 in epoch 4, gen_loss = 1.1634491430809049, disc_loss = 0.0009743693433853927
Trained batch 567 in epoch 4, gen_loss = 1.1633663327551225, disc_loss = 0.0009731032232209568
Trained batch 568 in epoch 4, gen_loss = 1.1633376793408854, disc_loss = 0.0009718340347309864
Trained batch 569 in epoch 4, gen_loss = 1.1631276639929988, disc_loss = 0.0009706126479023512
Trained batch 570 in epoch 4, gen_loss = 1.1631595995505513, disc_loss = 0.0009696283031111476
Trained batch 571 in epoch 4, gen_loss = 1.163090867075053, disc_loss = 0.0009684940641627881
Trained batch 572 in epoch 4, gen_loss = 1.163371946071039, disc_loss = 0.0009672950675819121
Trained batch 573 in epoch 4, gen_loss = 1.1632544802248685, disc_loss = 0.0009662017485517067
Trained batch 574 in epoch 4, gen_loss = 1.163202294992364, disc_loss = 0.0009650876394817201
Trained batch 575 in epoch 4, gen_loss = 1.1634541138385732, disc_loss = 0.0009638761070568257
Trained batch 576 in epoch 4, gen_loss = 1.1634286700956122, disc_loss = 0.0009630246939738014
Trained batch 577 in epoch 4, gen_loss = 1.1631705392809475, disc_loss = 0.0009622745764535243
Trained batch 578 in epoch 4, gen_loss = 1.163134642730311, disc_loss = 0.0009612297150768848
Trained batch 579 in epoch 4, gen_loss = 1.1632572140159279, disc_loss = 0.0009601738193004135
Trained batch 580 in epoch 4, gen_loss = 1.163090023341975, disc_loss = 0.0009590771826498673
Trained batch 581 in epoch 4, gen_loss = 1.1630021123746825, disc_loss = 0.0009580863221857338
Trained batch 582 in epoch 4, gen_loss = 1.1631665306475722, disc_loss = 0.0009569232165873351
Trained batch 583 in epoch 4, gen_loss = 1.1629038382678816, disc_loss = 0.0009556778107390241
Trained batch 584 in epoch 4, gen_loss = 1.162688809276646, disc_loss = 0.0009544360063597957
Trained batch 585 in epoch 4, gen_loss = 1.162563378595248, disc_loss = 0.0009531932205034089
Trained batch 586 in epoch 4, gen_loss = 1.1624351298179496, disc_loss = 0.0009521151265844202
Trained batch 587 in epoch 4, gen_loss = 1.1628889326943832, disc_loss = 0.0009510197341529222
Trained batch 588 in epoch 4, gen_loss = 1.1626596395147677, disc_loss = 0.0009498353630497242
Trained batch 589 in epoch 4, gen_loss = 1.162806702973479, disc_loss = 0.0009487946776246999
Trained batch 590 in epoch 4, gen_loss = 1.1628691140568599, disc_loss = 0.0009477248146669867
Trained batch 591 in epoch 4, gen_loss = 1.162613418758721, disc_loss = 0.0009468337210253938
Trained batch 592 in epoch 4, gen_loss = 1.1625803896990836, disc_loss = 0.0009456313102608971
Trained batch 593 in epoch 4, gen_loss = 1.1625488150601435, disc_loss = 0.0009444747239693071
Trained batch 594 in epoch 4, gen_loss = 1.1625210598737252, disc_loss = 0.0009432835555772352
Trained batch 595 in epoch 4, gen_loss = 1.16234707942345, disc_loss = 0.000942111475756095
Trained batch 596 in epoch 4, gen_loss = 1.1625013905553963, disc_loss = 0.0009408051766598694
Trained batch 597 in epoch 4, gen_loss = 1.1627191230405534, disc_loss = 0.0009395341124075284
Trained batch 598 in epoch 4, gen_loss = 1.162572406269672, disc_loss = 0.0009389760787550201
Trained batch 599 in epoch 4, gen_loss = 1.1626818961898486, disc_loss = 0.0009378571089716085
Trained batch 600 in epoch 4, gen_loss = 1.1627310713793395, disc_loss = 0.0009369552991391329
Trained batch 601 in epoch 4, gen_loss = 1.1631072396257787, disc_loss = 0.0009357719412390638
Trained batch 602 in epoch 4, gen_loss = 1.1630884769741774, disc_loss = 0.000934747272927104
Trained batch 603 in epoch 4, gen_loss = 1.1631702412635285, disc_loss = 0.0009334884919415055
Trained batch 604 in epoch 4, gen_loss = 1.162857455557043, disc_loss = 0.0009325030005790971
Trained batch 605 in epoch 4, gen_loss = 1.162394963081914, disc_loss = 0.0009322932645872161
Trained batch 606 in epoch 4, gen_loss = 1.1624913087983109, disc_loss = 0.0009313629262373343
Trained batch 607 in epoch 4, gen_loss = 1.162469834285347, disc_loss = 0.0009307545932594957
Trained batch 608 in epoch 4, gen_loss = 1.1625877806705793, disc_loss = 0.0009300087802536474
Trained batch 609 in epoch 4, gen_loss = 1.1624289512634278, disc_loss = 0.000929222731768978
Trained batch 610 in epoch 4, gen_loss = 1.1624706251921708, disc_loss = 0.0009281971706603326
Trained batch 611 in epoch 4, gen_loss = 1.1623249612992106, disc_loss = 0.0009274420969863879
Trained batch 612 in epoch 4, gen_loss = 1.1624252358618608, disc_loss = 0.0009264770143575735
Trained batch 613 in epoch 4, gen_loss = 1.1622729235440978, disc_loss = 0.0009257017739279444
Trained batch 614 in epoch 4, gen_loss = 1.1625107827225352, disc_loss = 0.0009251265766712406
Trained batch 615 in epoch 4, gen_loss = 1.162535691803152, disc_loss = 0.0009247305045734377
Trained batch 616 in epoch 4, gen_loss = 1.1625515311425083, disc_loss = 0.0009237989986400653
Trained batch 617 in epoch 4, gen_loss = 1.1625470133275275, disc_loss = 0.0009226624229542375
Trained batch 618 in epoch 4, gen_loss = 1.1621670721998507, disc_loss = 0.0009216985185965384
Trained batch 619 in epoch 4, gen_loss = 1.1620813859085883, disc_loss = 0.0009207900942138006
Trained batch 620 in epoch 4, gen_loss = 1.162138323948963, disc_loss = 0.0009205641872481999
Trained batch 621 in epoch 4, gen_loss = 1.1621258378603834, disc_loss = 0.0009200387565835328
Trained batch 622 in epoch 4, gen_loss = 1.162339394490562, disc_loss = 0.000919805418002609
Trained batch 623 in epoch 4, gen_loss = 1.1623627884456744, disc_loss = 0.0009196780562118734
Trained batch 624 in epoch 4, gen_loss = 1.162461221408844, disc_loss = 0.0009189637698698789
Trained batch 625 in epoch 4, gen_loss = 1.1623063021764968, disc_loss = 0.0009179210237591132
Trained batch 626 in epoch 4, gen_loss = 1.1622469101035804, disc_loss = 0.0009169782224750707
Trained batch 627 in epoch 4, gen_loss = 1.1623159106939462, disc_loss = 0.0009158784536582531
Trained batch 628 in epoch 4, gen_loss = 1.1624374043770929, disc_loss = 0.0009148765285665966
Trained batch 629 in epoch 4, gen_loss = 1.1624956796093593, disc_loss = 0.0009138493819461604
Trained batch 630 in epoch 4, gen_loss = 1.1623411880431198, disc_loss = 0.0009129130408900647
Trained batch 631 in epoch 4, gen_loss = 1.1621870842726925, disc_loss = 0.0009119487664134749
Trained batch 632 in epoch 4, gen_loss = 1.1618816583265814, disc_loss = 0.0009112633969068328
Trained batch 633 in epoch 4, gen_loss = 1.1621404209347554, disc_loss = 0.0009111594867801488
Trained batch 634 in epoch 4, gen_loss = 1.162291423542293, disc_loss = 0.0009100213511681962
Trained batch 635 in epoch 4, gen_loss = 1.1623318948835697, disc_loss = 0.0009090837901904769
Trained batch 636 in epoch 4, gen_loss = 1.1622793910267588, disc_loss = 0.0009083254397130356
Trained batch 637 in epoch 4, gen_loss = 1.1626836956481574, disc_loss = 0.0009075029167240094
Trained batch 638 in epoch 4, gen_loss = 1.1623560339445613, disc_loss = 0.0009069055198044669
Trained batch 639 in epoch 4, gen_loss = 1.1624202482402324, disc_loss = 0.0009060563529601495
Trained batch 640 in epoch 4, gen_loss = 1.1628404865026847, disc_loss = 0.0009051483862215359
Trained batch 641 in epoch 4, gen_loss = 1.162856872950759, disc_loss = 0.0009045000917915069
Trained batch 642 in epoch 4, gen_loss = 1.1628343855055459, disc_loss = 0.0009037393390495782
Trained batch 643 in epoch 4, gen_loss = 1.1627326713215491, disc_loss = 0.0009029294761032971
Trained batch 644 in epoch 4, gen_loss = 1.1627184849376826, disc_loss = 0.0009023258518048584
Trained batch 645 in epoch 4, gen_loss = 1.1630603901742043, disc_loss = 0.0009016924848669747
Trained batch 646 in epoch 4, gen_loss = 1.163224466432928, disc_loss = 0.0009007961814035553
Trained batch 647 in epoch 4, gen_loss = 1.163325991159604, disc_loss = 0.000900075583626016
Trained batch 648 in epoch 4, gen_loss = 1.1632458322404529, disc_loss = 0.0008992649590056993
Trained batch 649 in epoch 4, gen_loss = 1.1632397182171161, disc_loss = 0.0008982417818445426
Trained batch 650 in epoch 4, gen_loss = 1.1631216794115058, disc_loss = 0.0008971073160705496
Trained batch 651 in epoch 4, gen_loss = 1.1632038173865686, disc_loss = 0.0008962034141845527
Trained batch 652 in epoch 4, gen_loss = 1.163088974324704, disc_loss = 0.0008953262313827445
Trained batch 653 in epoch 4, gen_loss = 1.1629780224703867, disc_loss = 0.0008943612361629423
Trained batch 654 in epoch 4, gen_loss = 1.1629124179141213, disc_loss = 0.0008936141453192832
Trained batch 655 in epoch 4, gen_loss = 1.162595022469759, disc_loss = 0.0008927903246530616
Trained batch 656 in epoch 4, gen_loss = 1.1625148231217488, disc_loss = 0.0008919070467892949
Trained batch 657 in epoch 4, gen_loss = 1.1624811772698689, disc_loss = 0.0008908341488624728
Trained batch 658 in epoch 4, gen_loss = 1.162812764167062, disc_loss = 0.0008900000482613196
Trained batch 659 in epoch 4, gen_loss = 1.1627578235936888, disc_loss = 0.0008890699723093404
Trained batch 660 in epoch 4, gen_loss = 1.1628668689691715, disc_loss = 0.0008881918106047766
Trained batch 661 in epoch 4, gen_loss = 1.1628935721525613, disc_loss = 0.0008875051574599352
Trained batch 662 in epoch 4, gen_loss = 1.1625706895084582, disc_loss = 0.0008866741298452065
Trained batch 663 in epoch 4, gen_loss = 1.162261503647609, disc_loss = 0.0008858107246478868
Trained batch 664 in epoch 4, gen_loss = 1.1622802728997137, disc_loss = 0.0008850304672014865
Trained batch 665 in epoch 4, gen_loss = 1.1623315723450691, disc_loss = 0.0008843034726001921
Trained batch 666 in epoch 4, gen_loss = 1.1622665680866728, disc_loss = 0.0008833900374511181
Trained batch 667 in epoch 4, gen_loss = 1.1621993565987685, disc_loss = 0.0008827251662579671
Trained batch 668 in epoch 4, gen_loss = 1.162274067711937, disc_loss = 0.0008817953472175345
Trained batch 669 in epoch 4, gen_loss = 1.1622859552725038, disc_loss = 0.0008807775467406583
Trained batch 670 in epoch 4, gen_loss = 1.162472755827243, disc_loss = 0.0008797822789271361
Trained batch 671 in epoch 4, gen_loss = 1.162567805144049, disc_loss = 0.0008788666663176194
Trained batch 672 in epoch 4, gen_loss = 1.1626816598302718, disc_loss = 0.0008780820216552146
Trained batch 673 in epoch 4, gen_loss = 1.1624546401224787, disc_loss = 0.0008771274248022345
Trained batch 674 in epoch 4, gen_loss = 1.1622402230015507, disc_loss = 0.0008762955280339897
Trained batch 675 in epoch 4, gen_loss = 1.162542135052427, disc_loss = 0.0008753696203615155
Trained batch 676 in epoch 4, gen_loss = 1.1626776159249874, disc_loss = 0.0008751459707455445
Trained batch 677 in epoch 4, gen_loss = 1.1625026605122208, disc_loss = 0.0008745203104382175
Trained batch 678 in epoch 4, gen_loss = 1.1625404222724365, disc_loss = 0.0008735970992569925
Trained batch 679 in epoch 4, gen_loss = 1.1625271090689828, disc_loss = 0.0008731768295975224
Trained batch 680 in epoch 4, gen_loss = 1.1625782265362061, disc_loss = 0.0008725285647061234
Trained batch 681 in epoch 4, gen_loss = 1.1622520718406721, disc_loss = 0.0008718692781866249
Trained batch 682 in epoch 4, gen_loss = 1.162219251057414, disc_loss = 0.0008710796408442846
Trained batch 683 in epoch 4, gen_loss = 1.162420920461242, disc_loss = 0.0008703826890098631
Trained batch 684 in epoch 4, gen_loss = 1.1623707423244949, disc_loss = 0.0008695970278999761
Trained batch 685 in epoch 4, gen_loss = 1.1620971161665792, disc_loss = 0.0008691137625980761
Trained batch 686 in epoch 4, gen_loss = 1.1621970339980534, disc_loss = 0.0008683397321837441
Trained batch 687 in epoch 4, gen_loss = 1.162322030597648, disc_loss = 0.0008677767744217796
Trained batch 688 in epoch 4, gen_loss = 1.1622815925427894, disc_loss = 0.0008673449214394117
Trained batch 689 in epoch 4, gen_loss = 1.1627623603827713, disc_loss = 0.0008665277808862468
Trained batch 690 in epoch 4, gen_loss = 1.1624589476157545, disc_loss = 0.0008657818558676756
Trained batch 691 in epoch 4, gen_loss = 1.1622221946199505, disc_loss = 0.0008655337083637593
Trained batch 692 in epoch 4, gen_loss = 1.1620414337038478, disc_loss = 0.000865261466523752
Trained batch 693 in epoch 4, gen_loss = 1.1620830566292193, disc_loss = 0.0008645457230830063
Trained batch 694 in epoch 4, gen_loss = 1.1619208257832974, disc_loss = 0.0008637744396306883
Trained batch 695 in epoch 4, gen_loss = 1.1615551127784554, disc_loss = 0.0008629515553460304
Trained batch 696 in epoch 4, gen_loss = 1.1615367065714284, disc_loss = 0.0008621479053602459
Trained batch 697 in epoch 4, gen_loss = 1.161488181540481, disc_loss = 0.000861472349146409
Trained batch 698 in epoch 4, gen_loss = 1.1612636794007045, disc_loss = 0.0008606282763360655
Trained batch 699 in epoch 4, gen_loss = 1.1610066468375069, disc_loss = 0.0008598400423111993
Trained batch 700 in epoch 4, gen_loss = 1.1611329385115314, disc_loss = 0.0008590866990887976
Trained batch 701 in epoch 4, gen_loss = 1.1609436022250401, disc_loss = 0.0008586336524374026
Trained batch 702 in epoch 4, gen_loss = 1.1612291875299314, disc_loss = 0.0008581713087527892
Trained batch 703 in epoch 4, gen_loss = 1.1612173884429715, disc_loss = 0.0008573945424979519
Trained batch 704 in epoch 4, gen_loss = 1.1613092385285289, disc_loss = 0.0008569708541291601
Trained batch 705 in epoch 4, gen_loss = 1.1612745749714017, disc_loss = 0.0008560580596533569
Trained batch 706 in epoch 4, gen_loss = 1.1612842027335053, disc_loss = 0.0008552194517165096
Trained batch 707 in epoch 4, gen_loss = 1.1610543766600938, disc_loss = 0.0008544874261051158
Trained batch 708 in epoch 4, gen_loss = 1.1611520058681666, disc_loss = 0.0008542427762522532
Trained batch 709 in epoch 4, gen_loss = 1.1608132665425959, disc_loss = 0.0008551161224268455
Trained batch 710 in epoch 4, gen_loss = 1.1609007588754057, disc_loss = 0.0008550773179646497
Trained batch 711 in epoch 4, gen_loss = 1.1607305699687325, disc_loss = 0.0008555251661981744
Trained batch 712 in epoch 4, gen_loss = 1.1607000174896915, disc_loss = 0.0008559980004621593
Trained batch 713 in epoch 4, gen_loss = 1.1607934851773314, disc_loss = 0.0008558490324106083
Trained batch 714 in epoch 4, gen_loss = 1.1605940449487913, disc_loss = 0.0008553961996506848
Trained batch 715 in epoch 4, gen_loss = 1.1604210492119442, disc_loss = 0.0008545283909172324
Trained batch 716 in epoch 4, gen_loss = 1.1605471960337757, disc_loss = 0.0008539466225594734
Trained batch 717 in epoch 4, gen_loss = 1.1609006772300328, disc_loss = 0.0008530903657950839
Trained batch 718 in epoch 4, gen_loss = 1.1607204373091748, disc_loss = 0.0008523677444501271
Trained batch 719 in epoch 4, gen_loss = 1.1609368348287212, disc_loss = 0.000851592702949549
Trained batch 720 in epoch 4, gen_loss = 1.160767419906992, disc_loss = 0.0008509030827836505
Trained batch 721 in epoch 4, gen_loss = 1.1608727768352487, disc_loss = 0.0008502387848180923
Trained batch 722 in epoch 4, gen_loss = 1.1611055878517869, disc_loss = 0.0008496293006046195
Trained batch 723 in epoch 4, gen_loss = 1.1614911425344192, disc_loss = 0.0008488753601893891
Trained batch 724 in epoch 4, gen_loss = 1.1613267256473674, disc_loss = 0.0008481420853560598
Trained batch 725 in epoch 4, gen_loss = 1.1614419258823079, disc_loss = 0.0008474852393968827
Trained batch 726 in epoch 4, gen_loss = 1.1615156919952927, disc_loss = 0.0008467185248007826
Trained batch 727 in epoch 4, gen_loss = 1.162048921398409, disc_loss = 0.0008460190522552924
Trained batch 728 in epoch 4, gen_loss = 1.162042317485286, disc_loss = 0.0008451862306450973
Trained batch 729 in epoch 4, gen_loss = 1.1622040313400634, disc_loss = 0.0008442331616183079
Trained batch 730 in epoch 4, gen_loss = 1.162130099070219, disc_loss = 0.000843352048703063
Trained batch 731 in epoch 4, gen_loss = 1.1619415259589263, disc_loss = 0.0008425094240974531
Trained batch 732 in epoch 4, gen_loss = 1.1616434805389966, disc_loss = 0.0008417905504171422
Trained batch 733 in epoch 4, gen_loss = 1.1616004840229772, disc_loss = 0.0008411261188070929
Trained batch 734 in epoch 4, gen_loss = 1.16156893522561, disc_loss = 0.0008404612442008125
Trained batch 735 in epoch 4, gen_loss = 1.1617449938279132, disc_loss = 0.0008396181949889149
Trained batch 736 in epoch 4, gen_loss = 1.161576992621092, disc_loss = 0.0008389462342002749
Trained batch 737 in epoch 4, gen_loss = 1.1615592611191397, disc_loss = 0.0008383490897292021
Trained batch 738 in epoch 4, gen_loss = 1.1611913047398217, disc_loss = 0.0008380125706291699
Trained batch 739 in epoch 4, gen_loss = 1.1609916975369325, disc_loss = 0.000837317970483029
Trained batch 740 in epoch 4, gen_loss = 1.1606331190116974, disc_loss = 0.0008367162760305966
Trained batch 741 in epoch 4, gen_loss = 1.1606422222528174, disc_loss = 0.0008360622488952247
Trained batch 742 in epoch 4, gen_loss = 1.1606822806444335, disc_loss = 0.0008352226021671091
Trained batch 743 in epoch 4, gen_loss = 1.1607814150792297, disc_loss = 0.0008344669357577141
Trained batch 744 in epoch 4, gen_loss = 1.1605527857005997, disc_loss = 0.0008337439642008081
Trained batch 745 in epoch 4, gen_loss = 1.16065622606482, disc_loss = 0.0008331267419278974
Trained batch 746 in epoch 4, gen_loss = 1.1604806041143028, disc_loss = 0.0008324602324619373
Trained batch 747 in epoch 4, gen_loss = 1.1602612743403184, disc_loss = 0.0008317369081238397
Trained batch 748 in epoch 4, gen_loss = 1.160246895534174, disc_loss = 0.0008309662598099755
Trained batch 749 in epoch 4, gen_loss = 1.1600964605013528, disc_loss = 0.0008304432680791554
Trained batch 750 in epoch 4, gen_loss = 1.160088843416755, disc_loss = 0.0008298005004726244
Trained batch 751 in epoch 4, gen_loss = 1.1601447765814497, disc_loss = 0.0008291118983060129
Trained batch 752 in epoch 4, gen_loss = 1.1598670400313014, disc_loss = 0.000828831843087347
Trained batch 753 in epoch 4, gen_loss = 1.1600139047802285, disc_loss = 0.0008283872543134731
Trained batch 754 in epoch 4, gen_loss = 1.15989641811674, disc_loss = 0.000827671645539936
Trained batch 755 in epoch 4, gen_loss = 1.1597624507846025, disc_loss = 0.0008272497475902715
Trained batch 756 in epoch 4, gen_loss = 1.15977676179324, disc_loss = 0.0008265667653907413
Trained batch 757 in epoch 4, gen_loss = 1.1600313197654282, disc_loss = 0.0008257044660132366
Trained batch 758 in epoch 4, gen_loss = 1.1603670756336257, disc_loss = 0.0008249393654445785
Trained batch 759 in epoch 4, gen_loss = 1.1602411855208246, disc_loss = 0.000824267642957765
Trained batch 760 in epoch 4, gen_loss = 1.1602825576466425, disc_loss = 0.0008235248934109505
Trained batch 761 in epoch 4, gen_loss = 1.1602563421557268, disc_loss = 0.0008228255393314469
Trained batch 762 in epoch 4, gen_loss = 1.1603617263496468, disc_loss = 0.0008220475899857538
Trained batch 763 in epoch 4, gen_loss = 1.1602188453312319, disc_loss = 0.0008212282540511611
Trained batch 764 in epoch 4, gen_loss = 1.1601799441318885, disc_loss = 0.0008204643427032149
Trained batch 765 in epoch 4, gen_loss = 1.1599027269347217, disc_loss = 0.0008200643499100377
Trained batch 766 in epoch 4, gen_loss = 1.1600120921644737, disc_loss = 0.0008192867542798552
Trained batch 767 in epoch 4, gen_loss = 1.1601609704860796, disc_loss = 0.0008184537198682543
Trained batch 768 in epoch 4, gen_loss = 1.160344037262454, disc_loss = 0.0008177335586148146
Trained batch 769 in epoch 4, gen_loss = 1.1602990886607727, disc_loss = 0.0008170473765787463
Trained batch 770 in epoch 4, gen_loss = 1.160269775511226, disc_loss = 0.0008162265095487418
Trained batch 771 in epoch 4, gen_loss = 1.1602173256904968, disc_loss = 0.0008154220922168169
Trained batch 772 in epoch 4, gen_loss = 1.1600564578680603, disc_loss = 0.0008146495104896598
Trained batch 773 in epoch 4, gen_loss = 1.1599638339623, disc_loss = 0.000813913615284342
Trained batch 774 in epoch 4, gen_loss = 1.1599755801693086, disc_loss = 0.0008131191619078538
Trained batch 775 in epoch 4, gen_loss = 1.1601325386424655, disc_loss = 0.0008123521855072185
Trained batch 776 in epoch 4, gen_loss = 1.1602077167313378, disc_loss = 0.0008117003367699568
Trained batch 777 in epoch 4, gen_loss = 1.1599992146682003, disc_loss = 0.0008112162293699884
Trained batch 778 in epoch 4, gen_loss = 1.1598422531138948, disc_loss = 0.0008104278663647348
Trained batch 779 in epoch 4, gen_loss = 1.1596196279311792, disc_loss = 0.0008099362053400957
Trained batch 780 in epoch 4, gen_loss = 1.1594736163197956, disc_loss = 0.0008094075417832356
Trained batch 781 in epoch 4, gen_loss = 1.1599745136850022, disc_loss = 0.0008089366650534556
Trained batch 782 in epoch 4, gen_loss = 1.1602053023389474, disc_loss = 0.0008082283034981353
Trained batch 783 in epoch 4, gen_loss = 1.1608295649746243, disc_loss = 0.0008074669497787277
Trained batch 784 in epoch 4, gen_loss = 1.1607881028940723, disc_loss = 0.0008070448783499183
Trained batch 785 in epoch 4, gen_loss = 1.1608548924971476, disc_loss = 0.0008063760287861242
Trained batch 786 in epoch 4, gen_loss = 1.1608476010938158, disc_loss = 0.0008056608475695909
Trained batch 787 in epoch 4, gen_loss = 1.1610161761190685, disc_loss = 0.0008049243961391157
Trained batch 788 in epoch 4, gen_loss = 1.1608701718473011, disc_loss = 0.0008042812099088932
Trained batch 789 in epoch 4, gen_loss = 1.1605689407149449, disc_loss = 0.0008045293154236213
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 1.0826358795166016, disc_loss = 0.0004253168008290231
Trained batch 1 in epoch 5, gen_loss = 1.0117310285568237, disc_loss = 0.0003978783206548542
Trained batch 2 in epoch 5, gen_loss = 1.0533589124679565, disc_loss = 0.00042157712353703875
Trained batch 3 in epoch 5, gen_loss = 1.0415458977222443, disc_loss = 0.00042047435272252187
Trained batch 4 in epoch 5, gen_loss = 1.0308450698852538, disc_loss = 0.00039200176834128795
Trained batch 5 in epoch 5, gen_loss = 1.056406577428182, disc_loss = 0.00039733007724862546
Trained batch 6 in epoch 5, gen_loss = 1.075828960963658, disc_loss = 0.0003946639730462006
Trained batch 7 in epoch 5, gen_loss = 1.0640674158930779, disc_loss = 0.0003948008525185287
Trained batch 8 in epoch 5, gen_loss = 1.0689260098669264, disc_loss = 0.00041831046756770875
Trained batch 9 in epoch 5, gen_loss = 1.0859807193279267, disc_loss = 0.0004418453550897539
Trained batch 10 in epoch 5, gen_loss = 1.0887701999057422, disc_loss = 0.0004448476035825231
Trained batch 11 in epoch 5, gen_loss = 1.1026350210110347, disc_loss = 0.0004330716668240105
Trained batch 12 in epoch 5, gen_loss = 1.11188038954368, disc_loss = 0.00041393364013996546
Trained batch 13 in epoch 5, gen_loss = 1.1209300032683782, disc_loss = 0.00039766875228711536
Trained batch 14 in epoch 5, gen_loss = 1.141421631971995, disc_loss = 0.0003988069307524711
Trained batch 15 in epoch 5, gen_loss = 1.1346931122243404, disc_loss = 0.00040249670200864784
Trained batch 16 in epoch 5, gen_loss = 1.1338958564926596, disc_loss = 0.0004165065646007219
Trained batch 17 in epoch 5, gen_loss = 1.144790593120787, disc_loss = 0.00042342829854331084
Trained batch 18 in epoch 5, gen_loss = 1.1375313652189154, disc_loss = 0.0004240637920845888
Trained batch 19 in epoch 5, gen_loss = 1.1505955308675766, disc_loss = 0.00041461764340056106
Trained batch 20 in epoch 5, gen_loss = 1.1524716644060045, disc_loss = 0.00040958311902137385
Trained batch 21 in epoch 5, gen_loss = 1.1447607305916874, disc_loss = 0.0004083447129232809
Trained batch 22 in epoch 5, gen_loss = 1.1521026958589968, disc_loss = 0.00040650474282143557
Trained batch 23 in epoch 5, gen_loss = 1.1547131364544232, disc_loss = 0.0004009694530395791
Trained batch 24 in epoch 5, gen_loss = 1.1560538220405578, disc_loss = 0.00039561494952067733
Trained batch 25 in epoch 5, gen_loss = 1.160569110741982, disc_loss = 0.00039061079307710036
Trained batch 26 in epoch 5, gen_loss = 1.1634760984668024, disc_loss = 0.0003862091031839588
Trained batch 27 in epoch 5, gen_loss = 1.1660054006746836, disc_loss = 0.00038062382165143
Trained batch 28 in epoch 5, gen_loss = 1.1627199423724208, disc_loss = 0.0003747168179713832
Trained batch 29 in epoch 5, gen_loss = 1.1607640246550242, disc_loss = 0.00037096455926075576
Trained batch 30 in epoch 5, gen_loss = 1.1607008614847738, disc_loss = 0.00036696267160286585
Trained batch 31 in epoch 5, gen_loss = 1.1680200081318617, disc_loss = 0.00036707185336126713
Trained batch 32 in epoch 5, gen_loss = 1.1709240945902737, disc_loss = 0.0003686575280770547
Trained batch 33 in epoch 5, gen_loss = 1.1683282028226292, disc_loss = 0.0003752731093246599
Trained batch 34 in epoch 5, gen_loss = 1.165137892110007, disc_loss = 0.0003907826155357595
Trained batch 35 in epoch 5, gen_loss = 1.1689660201470058, disc_loss = 0.00039710817428486835
Trained batch 36 in epoch 5, gen_loss = 1.1704696304089315, disc_loss = 0.000391653274041223
Trained batch 37 in epoch 5, gen_loss = 1.1660550566096055, disc_loss = 0.00038628922936224724
Trained batch 38 in epoch 5, gen_loss = 1.163263187958644, disc_loss = 0.0003823955085886738
Trained batch 39 in epoch 5, gen_loss = 1.156699313223362, disc_loss = 0.0003837714863038855
Trained batch 40 in epoch 5, gen_loss = 1.1573045384593126, disc_loss = 0.0003844732975888225
Trained batch 41 in epoch 5, gen_loss = 1.1567718060243697, disc_loss = 0.00038373484338600453
Trained batch 42 in epoch 5, gen_loss = 1.1540248879166537, disc_loss = 0.00038356618071787145
Trained batch 43 in epoch 5, gen_loss = 1.1517360223965212, disc_loss = 0.00038063934301714073
Trained batch 44 in epoch 5, gen_loss = 1.1575959139400058, disc_loss = 0.00037765953618670915
Trained batch 45 in epoch 5, gen_loss = 1.154966757349346, disc_loss = 0.0003731895270428377
Trained batch 46 in epoch 5, gen_loss = 1.1525471451434683, disc_loss = 0.00037071695322160944
Trained batch 47 in epoch 5, gen_loss = 1.1483772210776806, disc_loss = 0.0003699201773391299
Trained batch 48 in epoch 5, gen_loss = 1.145757223878588, disc_loss = 0.0003674698227954724
Trained batch 49 in epoch 5, gen_loss = 1.144437175989151, disc_loss = 0.00036660837096860635
Trained batch 50 in epoch 5, gen_loss = 1.142879071188908, disc_loss = 0.0003652665555801279
Trained batch 51 in epoch 5, gen_loss = 1.141104933161002, disc_loss = 0.00036557083820718195
Trained batch 52 in epoch 5, gen_loss = 1.1415790533119778, disc_loss = 0.0003660043807511376
Trained batch 53 in epoch 5, gen_loss = 1.1387698440640062, disc_loss = 0.00036571770653137247
Trained batch 54 in epoch 5, gen_loss = 1.1387038805268028, disc_loss = 0.0003624672689263455
Trained batch 55 in epoch 5, gen_loss = 1.137075306049415, disc_loss = 0.00035920012955362575
Trained batch 56 in epoch 5, gen_loss = 1.1424369278707003, disc_loss = 0.000354934665282551
Trained batch 57 in epoch 5, gen_loss = 1.143901914358139, disc_loss = 0.00035103419439361336
Trained batch 58 in epoch 5, gen_loss = 1.1433254146980028, disc_loss = 0.0003481555936790971
Trained batch 59 in epoch 5, gen_loss = 1.1473710149526597, disc_loss = 0.00034669663412690476
Trained batch 60 in epoch 5, gen_loss = 1.1498995032466826, disc_loss = 0.00034540596195748537
Trained batch 61 in epoch 5, gen_loss = 1.1490195614676322, disc_loss = 0.0003458626083410045
Trained batch 62 in epoch 5, gen_loss = 1.150475181284405, disc_loss = 0.00034472446436882906
Trained batch 63 in epoch 5, gen_loss = 1.150801363401115, disc_loss = 0.0003424401500069507
Trained batch 64 in epoch 5, gen_loss = 1.1495348774469816, disc_loss = 0.00034245921840640503
Trained batch 65 in epoch 5, gen_loss = 1.146748712568572, disc_loss = 0.00034013105235344756
Trained batch 66 in epoch 5, gen_loss = 1.1449535497978551, disc_loss = 0.0003377800310419789
Trained batch 67 in epoch 5, gen_loss = 1.1482128728838528, disc_loss = 0.00033547174440600965
Trained batch 68 in epoch 5, gen_loss = 1.1462730514830437, disc_loss = 0.0003333856727914426
Trained batch 69 in epoch 5, gen_loss = 1.1441352733543941, disc_loss = 0.0003320181804675875
Trained batch 70 in epoch 5, gen_loss = 1.145293523728008, disc_loss = 0.0003300729727464348
Trained batch 71 in epoch 5, gen_loss = 1.1462232776814036, disc_loss = 0.00032758411644964427
Trained batch 72 in epoch 5, gen_loss = 1.1443745542878974, disc_loss = 0.00032668043951
Trained batch 73 in epoch 5, gen_loss = 1.1430352289934416, disc_loss = 0.00032753010993867457
Trained batch 74 in epoch 5, gen_loss = 1.1426354956626892, disc_loss = 0.0003278321293570722
Trained batch 75 in epoch 5, gen_loss = 1.139709192671274, disc_loss = 0.0003276120545419154
Trained batch 76 in epoch 5, gen_loss = 1.1394858135805501, disc_loss = 0.00032843523277060506
Trained batch 77 in epoch 5, gen_loss = 1.1407295763492584, disc_loss = 0.00032823422766224935
Trained batch 78 in epoch 5, gen_loss = 1.1390519828736028, disc_loss = 0.0003289819396280719
Trained batch 79 in epoch 5, gen_loss = 1.142089370638132, disc_loss = 0.00032824705358507343
Trained batch 80 in epoch 5, gen_loss = 1.142654064996743, disc_loss = 0.00032633902680381766
Trained batch 81 in epoch 5, gen_loss = 1.1412114057599045, disc_loss = 0.00032609433614330863
Trained batch 82 in epoch 5, gen_loss = 1.138983477310962, disc_loss = 0.0003274845791116626
Trained batch 83 in epoch 5, gen_loss = 1.137040458264805, disc_loss = 0.00032931562080713254
Trained batch 84 in epoch 5, gen_loss = 1.1375443100929261, disc_loss = 0.00032972199979293
Trained batch 85 in epoch 5, gen_loss = 1.1364817127238873, disc_loss = 0.00032871830524865885
Trained batch 86 in epoch 5, gen_loss = 1.1371264861918045, disc_loss = 0.00032711227343487284
Trained batch 87 in epoch 5, gen_loss = 1.1359860700639812, disc_loss = 0.00032822540164157874
Trained batch 88 in epoch 5, gen_loss = 1.1390419588999803, disc_loss = 0.00032982216337617236
Trained batch 89 in epoch 5, gen_loss = 1.1391273028320736, disc_loss = 0.0003305915835274694
Trained batch 90 in epoch 5, gen_loss = 1.1377350976178935, disc_loss = 0.0003320912638318387
Trained batch 91 in epoch 5, gen_loss = 1.1383360073618267, disc_loss = 0.0003316082389653235
Trained batch 92 in epoch 5, gen_loss = 1.138564939780902, disc_loss = 0.0003307646064410707
Trained batch 93 in epoch 5, gen_loss = 1.139047492691811, disc_loss = 0.00033085211814861705
Trained batch 94 in epoch 5, gen_loss = 1.1397702838245192, disc_loss = 0.0003307089505190226
Trained batch 95 in epoch 5, gen_loss = 1.1401620550702016, disc_loss = 0.00032898964627747773
Trained batch 96 in epoch 5, gen_loss = 1.1405768855330871, disc_loss = 0.0003285635340437965
Trained batch 97 in epoch 5, gen_loss = 1.1393350198560832, disc_loss = 0.0003280285138539419
Trained batch 98 in epoch 5, gen_loss = 1.1417917464718674, disc_loss = 0.0003264794805830326
Trained batch 99 in epoch 5, gen_loss = 1.1426455503702164, disc_loss = 0.0003268401004606858
Trained batch 100 in epoch 5, gen_loss = 1.1435214475830002, disc_loss = 0.0003271280830532386
Trained batch 101 in epoch 5, gen_loss = 1.1434603514624577, disc_loss = 0.0003256382065135803
Trained batch 102 in epoch 5, gen_loss = 1.1426621264624364, disc_loss = 0.00032421553609734494
Trained batch 103 in epoch 5, gen_loss = 1.141439543893704, disc_loss = 0.0003238755851690747
Trained batch 104 in epoch 5, gen_loss = 1.1429524245716276, disc_loss = 0.00032293379259672726
Trained batch 105 in epoch 5, gen_loss = 1.1430953015696328, disc_loss = 0.00032286514747198144
Trained batch 106 in epoch 5, gen_loss = 1.1444056028517606, disc_loss = 0.00032248453383451484
Trained batch 107 in epoch 5, gen_loss = 1.1434843181459993, disc_loss = 0.0003234130365146686
Trained batch 108 in epoch 5, gen_loss = 1.1426281704815155, disc_loss = 0.00032242918718144845
Trained batch 109 in epoch 5, gen_loss = 1.143320314992558, disc_loss = 0.00032169061093802816
Trained batch 110 in epoch 5, gen_loss = 1.143658771708205, disc_loss = 0.0003199326723965036
Trained batch 111 in epoch 5, gen_loss = 1.1436202084379536, disc_loss = 0.00032066303382245157
Trained batch 112 in epoch 5, gen_loss = 1.1420027334078224, disc_loss = 0.0003211074797189341
Trained batch 113 in epoch 5, gen_loss = 1.1403766379021762, disc_loss = 0.00032183719419040963
Trained batch 114 in epoch 5, gen_loss = 1.1436902294988218, disc_loss = 0.0003206358048255029
Trained batch 115 in epoch 5, gen_loss = 1.1426753052349747, disc_loss = 0.0003196994988809757
Trained batch 116 in epoch 5, gen_loss = 1.1443170512843335, disc_loss = 0.00031879549394819373
Trained batch 117 in epoch 5, gen_loss = 1.1470016786607646, disc_loss = 0.00031726630574774973
Trained batch 118 in epoch 5, gen_loss = 1.147066540076953, disc_loss = 0.00031650431200807146
Trained batch 119 in epoch 5, gen_loss = 1.1463308085997899, disc_loss = 0.00031633038064076877
Trained batch 120 in epoch 5, gen_loss = 1.1477864113720981, disc_loss = 0.00031580924044925075
Trained batch 121 in epoch 5, gen_loss = 1.147337336032117, disc_loss = 0.0003159198498250306
Trained batch 122 in epoch 5, gen_loss = 1.148382755799022, disc_loss = 0.00031491317722389886
Trained batch 123 in epoch 5, gen_loss = 1.1471153742844058, disc_loss = 0.000315168639292918
Trained batch 124 in epoch 5, gen_loss = 1.145043118953705, disc_loss = 0.0003158122930908576
Trained batch 125 in epoch 5, gen_loss = 1.1463006389519526, disc_loss = 0.0003152257263464557
Trained batch 126 in epoch 5, gen_loss = 1.1500069996503395, disc_loss = 0.0003145696172732713
Trained batch 127 in epoch 5, gen_loss = 1.148547202348709, disc_loss = 0.000313863685164506
Trained batch 128 in epoch 5, gen_loss = 1.1490456401839737, disc_loss = 0.0003132377016807495
Trained batch 129 in epoch 5, gen_loss = 1.1503492511235751, disc_loss = 0.000312349137563545
Trained batch 130 in epoch 5, gen_loss = 1.1494869658055196, disc_loss = 0.00031161452530268296
Trained batch 131 in epoch 5, gen_loss = 1.1485433966824503, disc_loss = 0.0003124786653092032
Trained batch 132 in epoch 5, gen_loss = 1.1505720041748275, disc_loss = 0.0003122861729715986
Trained batch 133 in epoch 5, gen_loss = 1.149639480149568, disc_loss = 0.000312478763616901
Trained batch 134 in epoch 5, gen_loss = 1.1499159150653415, disc_loss = 0.0003130115759429625
Trained batch 135 in epoch 5, gen_loss = 1.1489434478914036, disc_loss = 0.0003132591763834866
Trained batch 136 in epoch 5, gen_loss = 1.1494824425147399, disc_loss = 0.00031502494797956904
Trained batch 137 in epoch 5, gen_loss = 1.1502681305443032, disc_loss = 0.00031983641204441074
Trained batch 138 in epoch 5, gen_loss = 1.1496447461972135, disc_loss = 0.00032627405383098176
Trained batch 139 in epoch 5, gen_loss = 1.148790796313967, disc_loss = 0.00032669049407039503
Trained batch 140 in epoch 5, gen_loss = 1.1490272554099983, disc_loss = 0.0003266704747831475
Trained batch 141 in epoch 5, gen_loss = 1.1476679314190232, disc_loss = 0.00033057637278623484
Trained batch 142 in epoch 5, gen_loss = 1.1471178877603758, disc_loss = 0.0003318649247961145
Trained batch 143 in epoch 5, gen_loss = 1.145621528642045, disc_loss = 0.0003336677959345656
Trained batch 144 in epoch 5, gen_loss = 1.1450745751117837, disc_loss = 0.0003345993444813287
Trained batch 145 in epoch 5, gen_loss = 1.1456266335428578, disc_loss = 0.0003347727060453545
Trained batch 146 in epoch 5, gen_loss = 1.1444684996896861, disc_loss = 0.000334274178496752
Trained batch 147 in epoch 5, gen_loss = 1.1430846714490168, disc_loss = 0.00033396586995631633
Trained batch 148 in epoch 5, gen_loss = 1.1432336116797173, disc_loss = 0.00033371451483873787
Trained batch 149 in epoch 5, gen_loss = 1.1419497752189636, disc_loss = 0.00033528009807923807
Trained batch 150 in epoch 5, gen_loss = 1.1422448245105365, disc_loss = 0.000335631300275066
Trained batch 151 in epoch 5, gen_loss = 1.1411371611450847, disc_loss = 0.00033534417458500493
Trained batch 152 in epoch 5, gen_loss = 1.1408021235777661, disc_loss = 0.00033407881429869366
Trained batch 153 in epoch 5, gen_loss = 1.1411987841129303, disc_loss = 0.00033287242147164394
Trained batch 154 in epoch 5, gen_loss = 1.1420350247813809, disc_loss = 0.00033223341620947804
Trained batch 155 in epoch 5, gen_loss = 1.1424489544752316, disc_loss = 0.0003311189444875942
Trained batch 156 in epoch 5, gen_loss = 1.1429805865712985, disc_loss = 0.00033036156562690853
Trained batch 157 in epoch 5, gen_loss = 1.142391577174392, disc_loss = 0.00032947623503211697
Trained batch 158 in epoch 5, gen_loss = 1.1418543967810817, disc_loss = 0.00032871464220148
Trained batch 159 in epoch 5, gen_loss = 1.1413618136197328, disc_loss = 0.0003287398724751256
Trained batch 160 in epoch 5, gen_loss = 1.140398111032403, disc_loss = 0.0003288776850760249
Trained batch 161 in epoch 5, gen_loss = 1.139585245170711, disc_loss = 0.00032873195946363183
Trained batch 162 in epoch 5, gen_loss = 1.1390718905472317, disc_loss = 0.00032902929774396967
Trained batch 163 in epoch 5, gen_loss = 1.1379237665635784, disc_loss = 0.00032887336747967867
Trained batch 164 in epoch 5, gen_loss = 1.1376381082968279, disc_loss = 0.0003316382058211743
Trained batch 165 in epoch 5, gen_loss = 1.1378748190690235, disc_loss = 0.00033454391402290594
Trained batch 166 in epoch 5, gen_loss = 1.1381603090349073, disc_loss = 0.00033659398098110954
Trained batch 167 in epoch 5, gen_loss = 1.1380176987676394, disc_loss = 0.00033648733499701066
Trained batch 168 in epoch 5, gen_loss = 1.1385335763530617, disc_loss = 0.0003365044906210518
Trained batch 169 in epoch 5, gen_loss = 1.137881153821945, disc_loss = 0.00033691488899742527
Trained batch 170 in epoch 5, gen_loss = 1.1391333428739805, disc_loss = 0.00033609172758545554
Trained batch 171 in epoch 5, gen_loss = 1.1382294806630113, disc_loss = 0.00033745374085535946
Trained batch 172 in epoch 5, gen_loss = 1.1369761535198013, disc_loss = 0.00034065187460880164
Trained batch 173 in epoch 5, gen_loss = 1.1375451242101604, disc_loss = 0.0003426241262410446
Trained batch 174 in epoch 5, gen_loss = 1.1377217950139726, disc_loss = 0.00034266941257685954
Trained batch 175 in epoch 5, gen_loss = 1.1379120874811302, disc_loss = 0.00034284248472844905
Trained batch 176 in epoch 5, gen_loss = 1.1384602929912717, disc_loss = 0.0003423275404490036
Trained batch 177 in epoch 5, gen_loss = 1.1374120554897222, disc_loss = 0.0003424866714094912
Trained batch 178 in epoch 5, gen_loss = 1.1377281646488766, disc_loss = 0.0003419919753240359
Trained batch 179 in epoch 5, gen_loss = 1.1380558917919794, disc_loss = 0.00034227212203808853
Trained batch 180 in epoch 5, gen_loss = 1.1388733284908106, disc_loss = 0.00034330627366126057
Trained batch 181 in epoch 5, gen_loss = 1.1393439386572157, disc_loss = 0.0003425175644544332
Trained batch 182 in epoch 5, gen_loss = 1.1383691820941988, disc_loss = 0.00034253596127175733
Trained batch 183 in epoch 5, gen_loss = 1.139587536778139, disc_loss = 0.00034193922763971267
Trained batch 184 in epoch 5, gen_loss = 1.1395519472457267, disc_loss = 0.0003414113709319232
Trained batch 185 in epoch 5, gen_loss = 1.1393051003256152, disc_loss = 0.00034105751132379756
Trained batch 186 in epoch 5, gen_loss = 1.1398398656258608, disc_loss = 0.0003411672640695202
Trained batch 187 in epoch 5, gen_loss = 1.1411624522285257, disc_loss = 0.00034145689549288673
Trained batch 188 in epoch 5, gen_loss = 1.140472573262674, disc_loss = 0.00034126153093499067
Trained batch 189 in epoch 5, gen_loss = 1.1403815956492174, disc_loss = 0.0003407595333747419
Trained batch 190 in epoch 5, gen_loss = 1.1397700319115405, disc_loss = 0.00034062027163542707
Trained batch 191 in epoch 5, gen_loss = 1.1410406452293198, disc_loss = 0.0003417981219323944
Trained batch 192 in epoch 5, gen_loss = 1.1403217436118447, disc_loss = 0.0003432626764373275
Trained batch 193 in epoch 5, gen_loss = 1.1393083395417203, disc_loss = 0.00034387085636892865
Trained batch 194 in epoch 5, gen_loss = 1.1400175241323618, disc_loss = 0.0003431311830167826
Trained batch 195 in epoch 5, gen_loss = 1.139965157727806, disc_loss = 0.0003423087411870163
Trained batch 196 in epoch 5, gen_loss = 1.1409681902319042, disc_loss = 0.00034153584660052174
Trained batch 197 in epoch 5, gen_loss = 1.1413139399856027, disc_loss = 0.00034078398863185254
Trained batch 198 in epoch 5, gen_loss = 1.1414559768072923, disc_loss = 0.0003413156472145341
Trained batch 199 in epoch 5, gen_loss = 1.1409324270486831, disc_loss = 0.00034228988333779854
Trained batch 200 in epoch 5, gen_loss = 1.1412333605894402, disc_loss = 0.0003431578622453276
Trained batch 201 in epoch 5, gen_loss = 1.1408497791479129, disc_loss = 0.00034244674366569185
Trained batch 202 in epoch 5, gen_loss = 1.1406767603211803, disc_loss = 0.00034163017985766543
Trained batch 203 in epoch 5, gen_loss = 1.139351838944005, disc_loss = 0.00034200411562992754
Trained batch 204 in epoch 5, gen_loss = 1.13903574245732, disc_loss = 0.0003415572361185829
Trained batch 205 in epoch 5, gen_loss = 1.139409958158882, disc_loss = 0.0003409756047174208
Trained batch 206 in epoch 5, gen_loss = 1.139213822890019, disc_loss = 0.0003405973077065577
Trained batch 207 in epoch 5, gen_loss = 1.1384922856321702, disc_loss = 0.0003408287698570908
Trained batch 208 in epoch 5, gen_loss = 1.1374339486993672, disc_loss = 0.00034228440763486737
Trained batch 209 in epoch 5, gen_loss = 1.1372545174189976, disc_loss = 0.0003420505500842063
Trained batch 210 in epoch 5, gen_loss = 1.1380196623327608, disc_loss = 0.00034216479387275556
Trained batch 211 in epoch 5, gen_loss = 1.1380898929991812, disc_loss = 0.00034165134776179364
Trained batch 212 in epoch 5, gen_loss = 1.13865490866379, disc_loss = 0.0003409695153249244
Trained batch 213 in epoch 5, gen_loss = 1.139570230635527, disc_loss = 0.0003399665551216594
Trained batch 214 in epoch 5, gen_loss = 1.1396614928578221, disc_loss = 0.00033909982194864124
Trained batch 215 in epoch 5, gen_loss = 1.1390350433411423, disc_loss = 0.0003385767185709146
Trained batch 216 in epoch 5, gen_loss = 1.139189260346549, disc_loss = 0.0003380314398702869
Trained batch 217 in epoch 5, gen_loss = 1.1390134916393035, disc_loss = 0.00033800367283562215
Trained batch 218 in epoch 5, gen_loss = 1.1390196830714674, disc_loss = 0.0003375725296525855
Trained batch 219 in epoch 5, gen_loss = 1.138393827460029, disc_loss = 0.0003372933789664371
Trained batch 220 in epoch 5, gen_loss = 1.139637191371141, disc_loss = 0.0003377775736974881
Trained batch 221 in epoch 5, gen_loss = 1.1396595857164882, disc_loss = 0.0003379358803047924
Trained batch 222 in epoch 5, gen_loss = 1.1397759577618587, disc_loss = 0.00033749791569308264
Trained batch 223 in epoch 5, gen_loss = 1.1396734389875616, disc_loss = 0.00033661176316205195
Trained batch 224 in epoch 5, gen_loss = 1.138860413763258, disc_loss = 0.0003356961214578607
Trained batch 225 in epoch 5, gen_loss = 1.1393750046206788, disc_loss = 0.0003347583182065426
Trained batch 226 in epoch 5, gen_loss = 1.1396205871640848, disc_loss = 0.00033396249470333796
Trained batch 227 in epoch 5, gen_loss = 1.1405076604140432, disc_loss = 0.00033348096194299215
Trained batch 228 in epoch 5, gen_loss = 1.1396190813014602, disc_loss = 0.00033273739903183107
Trained batch 229 in epoch 5, gen_loss = 1.1395373961199884, disc_loss = 0.00033198112828161
Trained batch 230 in epoch 5, gen_loss = 1.138934412043848, disc_loss = 0.0003319140134991078
Trained batch 231 in epoch 5, gen_loss = 1.1388892880801498, disc_loss = 0.00033233349520365855
Trained batch 232 in epoch 5, gen_loss = 1.1398471235717316, disc_loss = 0.00033349965596841366
Trained batch 233 in epoch 5, gen_loss = 1.1398851010534499, disc_loss = 0.00033434919343065296
Trained batch 234 in epoch 5, gen_loss = 1.1400077028477447, disc_loss = 0.00033505112892561693
Trained batch 235 in epoch 5, gen_loss = 1.1397632708994008, disc_loss = 0.0003358295326830496
Trained batch 236 in epoch 5, gen_loss = 1.1392767585279568, disc_loss = 0.00033567025664386256
Trained batch 237 in epoch 5, gen_loss = 1.1390207530069751, disc_loss = 0.0003350205864867845
Trained batch 238 in epoch 5, gen_loss = 1.1389602956412725, disc_loss = 0.0003349064374035692
Trained batch 239 in epoch 5, gen_loss = 1.138538983464241, disc_loss = 0.0003353578604219365
Trained batch 240 in epoch 5, gen_loss = 1.138652733252751, disc_loss = 0.00033550278694973677
Trained batch 241 in epoch 5, gen_loss = 1.1385110680722008, disc_loss = 0.0003351598388389376
Trained batch 242 in epoch 5, gen_loss = 1.1382740863556724, disc_loss = 0.0003347748748832593
Trained batch 243 in epoch 5, gen_loss = 1.1383471210471918, disc_loss = 0.00033409979219928184
Trained batch 244 in epoch 5, gen_loss = 1.1386775532547309, disc_loss = 0.0003332528589193576
Trained batch 245 in epoch 5, gen_loss = 1.138709383282235, disc_loss = 0.000332566873230536
Trained batch 246 in epoch 5, gen_loss = 1.1383151805352585, disc_loss = 0.00033190326386005033
Trained batch 247 in epoch 5, gen_loss = 1.1382500413925416, disc_loss = 0.0003314296749698359
Trained batch 248 in epoch 5, gen_loss = 1.138637266005857, disc_loss = 0.0003308826068301225
Trained batch 249 in epoch 5, gen_loss = 1.1386082124710084, disc_loss = 0.0003304064103285782
Trained batch 250 in epoch 5, gen_loss = 1.1377828681611444, disc_loss = 0.00033001292986698834
Trained batch 251 in epoch 5, gen_loss = 1.1384731786591666, disc_loss = 0.0003293165901263747
Trained batch 252 in epoch 5, gen_loss = 1.1402178413783137, disc_loss = 0.00032888708627882153
Trained batch 253 in epoch 5, gen_loss = 1.139227451771263, disc_loss = 0.0003352368460861805
Trained batch 254 in epoch 5, gen_loss = 1.1395083544301052, disc_loss = 0.00034093873497719563
Trained batch 255 in epoch 5, gen_loss = 1.138983519282192, disc_loss = 0.00034325881665608904
Trained batch 256 in epoch 5, gen_loss = 1.1388263243181695, disc_loss = 0.0003463536727872717
Trained batch 257 in epoch 5, gen_loss = 1.138897292835768, disc_loss = 0.0003484138276323301
Trained batch 258 in epoch 5, gen_loss = 1.139583074908459, disc_loss = 0.00035016386298656926
Trained batch 259 in epoch 5, gen_loss = 1.1396742339317616, disc_loss = 0.00035152958970194537
Trained batch 260 in epoch 5, gen_loss = 1.1392316754293625, disc_loss = 0.00035278722345008306
Trained batch 261 in epoch 5, gen_loss = 1.1391342837391918, disc_loss = 0.00035320693948697157
Trained batch 262 in epoch 5, gen_loss = 1.1391521044103818, disc_loss = 0.0003529683741680683
Trained batch 263 in epoch 5, gen_loss = 1.1395119270592025, disc_loss = 0.0003528770123948837
Trained batch 264 in epoch 5, gen_loss = 1.1394690850995621, disc_loss = 0.0003528305947701535
Trained batch 265 in epoch 5, gen_loss = 1.1398442759549707, disc_loss = 0.0003523401821056675
Trained batch 266 in epoch 5, gen_loss = 1.13935935899113, disc_loss = 0.0003520672348866846
Trained batch 267 in epoch 5, gen_loss = 1.1397699055387014, disc_loss = 0.0003515669311276887
Trained batch 268 in epoch 5, gen_loss = 1.139498493042134, disc_loss = 0.00035107396030192677
Trained batch 269 in epoch 5, gen_loss = 1.1392623062487002, disc_loss = 0.0003510178494724204
Trained batch 270 in epoch 5, gen_loss = 1.1390040743394971, disc_loss = 0.0003507417093788882
Trained batch 271 in epoch 5, gen_loss = 1.1381214863675482, disc_loss = 0.00035111050312801073
Trained batch 272 in epoch 5, gen_loss = 1.1378320959898143, disc_loss = 0.00035139143589761233
Trained batch 273 in epoch 5, gen_loss = 1.1374314729749722, disc_loss = 0.0003509617370874519
Trained batch 274 in epoch 5, gen_loss = 1.1374166542833501, disc_loss = 0.0003512661419385536
Trained batch 275 in epoch 5, gen_loss = 1.1379169517237206, disc_loss = 0.0003519990568747744
Trained batch 276 in epoch 5, gen_loss = 1.1376639064468632, disc_loss = 0.0003519942252711807
Trained batch 277 in epoch 5, gen_loss = 1.1377413553728475, disc_loss = 0.00035147834040531083
Trained batch 278 in epoch 5, gen_loss = 1.1375297814287164, disc_loss = 0.00035094791106582624
Trained batch 279 in epoch 5, gen_loss = 1.1385582921760422, disc_loss = 0.000350925686507253
Trained batch 280 in epoch 5, gen_loss = 1.1377536128424242, disc_loss = 0.0003511231854347532
Trained batch 281 in epoch 5, gen_loss = 1.137749859415893, disc_loss = 0.00035089759186243783
Trained batch 282 in epoch 5, gen_loss = 1.13738904803886, disc_loss = 0.00035040349680634194
Trained batch 283 in epoch 5, gen_loss = 1.13758811081799, disc_loss = 0.00035013141970127216
Trained batch 284 in epoch 5, gen_loss = 1.1384043904772976, disc_loss = 0.0003496545348561516
Trained batch 285 in epoch 5, gen_loss = 1.1384538510045805, disc_loss = 0.00034910280124562747
Trained batch 286 in epoch 5, gen_loss = 1.1382996967445267, disc_loss = 0.00034899056370115355
Trained batch 287 in epoch 5, gen_loss = 1.1386795546859503, disc_loss = 0.00034845588121849386
Trained batch 288 in epoch 5, gen_loss = 1.138925383866452, disc_loss = 0.00034774743029799404
Trained batch 289 in epoch 5, gen_loss = 1.1387221630277304, disc_loss = 0.000347284446339974
Trained batch 290 in epoch 5, gen_loss = 1.1385358320069068, disc_loss = 0.0003470083786341877
Trained batch 291 in epoch 5, gen_loss = 1.138587841228263, disc_loss = 0.0003465827282762142
Trained batch 292 in epoch 5, gen_loss = 1.1388597400928926, disc_loss = 0.00034602229320920954
Trained batch 293 in epoch 5, gen_loss = 1.138426037264519, disc_loss = 0.00034560221144422685
Trained batch 294 in epoch 5, gen_loss = 1.1380931508743157, disc_loss = 0.0003454795118097721
Trained batch 295 in epoch 5, gen_loss = 1.1376268664324605, disc_loss = 0.00034635950293237773
Trained batch 296 in epoch 5, gen_loss = 1.1374473625963384, disc_loss = 0.00034593843102575866
Trained batch 297 in epoch 5, gen_loss = 1.1377338377021302, disc_loss = 0.00034548337896543575
Trained batch 298 in epoch 5, gen_loss = 1.1378016007385126, disc_loss = 0.0003451858408204794
Trained batch 299 in epoch 5, gen_loss = 1.1373189665873846, disc_loss = 0.0003445599401311483
Trained batch 300 in epoch 5, gen_loss = 1.1367138546962674, disc_loss = 0.00034425797450868257
Trained batch 301 in epoch 5, gen_loss = 1.1371053178973545, disc_loss = 0.0003445028668652683
Trained batch 302 in epoch 5, gen_loss = 1.1371559166278775, disc_loss = 0.0003449092376589154
Trained batch 303 in epoch 5, gen_loss = 1.1369717668153738, disc_loss = 0.00034548991334304446
Trained batch 304 in epoch 5, gen_loss = 1.1362350846900315, disc_loss = 0.0003457452527907692
Trained batch 305 in epoch 5, gen_loss = 1.1363142670369615, disc_loss = 0.00034618363176431395
Trained batch 306 in epoch 5, gen_loss = 1.1364333757748433, disc_loss = 0.0003459920386874029
Trained batch 307 in epoch 5, gen_loss = 1.1362192611415665, disc_loss = 0.00034623446887738506
Trained batch 308 in epoch 5, gen_loss = 1.136819354152988, disc_loss = 0.00034666415954778774
Trained batch 309 in epoch 5, gen_loss = 1.1361791589567738, disc_loss = 0.00034679279154759923
Trained batch 310 in epoch 5, gen_loss = 1.136748295696602, disc_loss = 0.00034640075971478735
Trained batch 311 in epoch 5, gen_loss = 1.1366936100217013, disc_loss = 0.00034719525851519743
Trained batch 312 in epoch 5, gen_loss = 1.1377523107269703, disc_loss = 0.0003481002386600618
Trained batch 313 in epoch 5, gen_loss = 1.1376829840195406, disc_loss = 0.0003483174406277508
Trained batch 314 in epoch 5, gen_loss = 1.1372762212677607, disc_loss = 0.000348210573198259
Trained batch 315 in epoch 5, gen_loss = 1.1377779005826274, disc_loss = 0.00034896698947060157
Trained batch 316 in epoch 5, gen_loss = 1.13769338841694, disc_loss = 0.0003492042969207923
Trained batch 317 in epoch 5, gen_loss = 1.1381427857485957, disc_loss = 0.00034866190088785444
Trained batch 318 in epoch 5, gen_loss = 1.1385565332858167, disc_loss = 0.00034811391219092375
Trained batch 319 in epoch 5, gen_loss = 1.1379955543205142, disc_loss = 0.00034889733774434717
Trained batch 320 in epoch 5, gen_loss = 1.138189370201384, disc_loss = 0.0003490840924691229
Trained batch 321 in epoch 5, gen_loss = 1.138709558278137, disc_loss = 0.00034895210405949055
Trained batch 322 in epoch 5, gen_loss = 1.1382773553623873, disc_loss = 0.0003485822055475129
Trained batch 323 in epoch 5, gen_loss = 1.1389615101578794, disc_loss = 0.0003480723010139672
Trained batch 324 in epoch 5, gen_loss = 1.138880999638484, disc_loss = 0.0003474114687952141
Trained batch 325 in epoch 5, gen_loss = 1.1385756387301018, disc_loss = 0.0003470414533030579
Trained batch 326 in epoch 5, gen_loss = 1.138367570139217, disc_loss = 0.00034711320630156515
Trained batch 327 in epoch 5, gen_loss = 1.137696343224223, disc_loss = 0.00034806187201267186
Trained batch 328 in epoch 5, gen_loss = 1.1380153745865749, disc_loss = 0.00034772368940761127
Trained batch 329 in epoch 5, gen_loss = 1.1386842789071978, disc_loss = 0.0003475749339982444
Trained batch 330 in epoch 5, gen_loss = 1.1386720280632872, disc_loss = 0.0003476615067451117
Trained batch 331 in epoch 5, gen_loss = 1.1387276229370071, disc_loss = 0.0003473150303849603
Trained batch 332 in epoch 5, gen_loss = 1.1382597480808292, disc_loss = 0.0003469914730006197
Trained batch 333 in epoch 5, gen_loss = 1.1379101172892634, disc_loss = 0.00034666125394939304
Trained batch 334 in epoch 5, gen_loss = 1.1382055521011352, disc_loss = 0.00034692931256548906
Trained batch 335 in epoch 5, gen_loss = 1.1381151842929067, disc_loss = 0.0003464311360706536
Trained batch 336 in epoch 5, gen_loss = 1.1379286627387435, disc_loss = 0.0003460521828065397
Trained batch 337 in epoch 5, gen_loss = 1.1377569197197637, disc_loss = 0.00034572982288533325
Trained batch 338 in epoch 5, gen_loss = 1.137438746328551, disc_loss = 0.0003454733739887257
Trained batch 339 in epoch 5, gen_loss = 1.1367215063642053, disc_loss = 0.0003461439515162698
Trained batch 340 in epoch 5, gen_loss = 1.1361814788010114, disc_loss = 0.0003461807100286658
Trained batch 341 in epoch 5, gen_loss = 1.1376280985031908, disc_loss = 0.0003464805565288356
Trained batch 342 in epoch 5, gen_loss = 1.1371244534459128, disc_loss = 0.0003470626170780922
Trained batch 343 in epoch 5, gen_loss = 1.1367096583857093, disc_loss = 0.0003482954430923158
Trained batch 344 in epoch 5, gen_loss = 1.1366773897323055, disc_loss = 0.00035024295836025716
Trained batch 345 in epoch 5, gen_loss = 1.1368726448861162, disc_loss = 0.0003505302662927539
Trained batch 346 in epoch 5, gen_loss = 1.1371884729058324, disc_loss = 0.000350214504641521
Trained batch 347 in epoch 5, gen_loss = 1.1379023336473553, disc_loss = 0.0003498721873737609
Trained batch 348 in epoch 5, gen_loss = 1.1376481303854453, disc_loss = 0.0003495074498879438
Trained batch 349 in epoch 5, gen_loss = 1.1370569741725922, disc_loss = 0.00035004699178638735
Trained batch 350 in epoch 5, gen_loss = 1.1373432563920307, disc_loss = 0.00034990453201431005
Trained batch 351 in epoch 5, gen_loss = 1.1380686514418235, disc_loss = 0.0003498591867438253
Trained batch 352 in epoch 5, gen_loss = 1.138297303033618, disc_loss = 0.0003497761704071185
Trained batch 353 in epoch 5, gen_loss = 1.1387109128432085, disc_loss = 0.00034987365214961795
Trained batch 354 in epoch 5, gen_loss = 1.138658413920604, disc_loss = 0.0003494739002043145
Trained batch 355 in epoch 5, gen_loss = 1.138495420304577, disc_loss = 0.00034931693181952753
Trained batch 356 in epoch 5, gen_loss = 1.1385726903666968, disc_loss = 0.0003488244760634132
Trained batch 357 in epoch 5, gen_loss = 1.1386394049535251, disc_loss = 0.00034857583880963
Trained batch 358 in epoch 5, gen_loss = 1.1391507192906563, disc_loss = 0.00034808098924836575
Trained batch 359 in epoch 5, gen_loss = 1.1394042457143465, disc_loss = 0.0003475884937668323
Trained batch 360 in epoch 5, gen_loss = 1.1393468517015515, disc_loss = 0.000347260167997026
Trained batch 361 in epoch 5, gen_loss = 1.1393495506673887, disc_loss = 0.0003471486739948063
Trained batch 362 in epoch 5, gen_loss = 1.1394796248309869, disc_loss = 0.00034718451463135045
Trained batch 363 in epoch 5, gen_loss = 1.1395680257579783, disc_loss = 0.0003481603148079907
Trained batch 364 in epoch 5, gen_loss = 1.139843109372544, disc_loss = 0.00034913628813427913
Trained batch 365 in epoch 5, gen_loss = 1.1394405366618776, disc_loss = 0.000349280931188501
Trained batch 366 in epoch 5, gen_loss = 1.139674000096906, disc_loss = 0.00034918647368276134
Trained batch 367 in epoch 5, gen_loss = 1.1395481428050476, disc_loss = 0.0003489058491022265
Trained batch 368 in epoch 5, gen_loss = 1.13909050426509, disc_loss = 0.0003489679296477004
Trained batch 369 in epoch 5, gen_loss = 1.1394712713924615, disc_loss = 0.0003488626956429987
Trained batch 370 in epoch 5, gen_loss = 1.139264094379713, disc_loss = 0.0003484826837948742
Trained batch 371 in epoch 5, gen_loss = 1.139079731478486, disc_loss = 0.0003480517778527467
Trained batch 372 in epoch 5, gen_loss = 1.138757199288693, disc_loss = 0.0003476308434159213
Trained batch 373 in epoch 5, gen_loss = 1.1387440774211273, disc_loss = 0.0003471172738130538
Trained batch 374 in epoch 5, gen_loss = 1.1387867197990418, disc_loss = 0.00034690796032858394
Trained batch 375 in epoch 5, gen_loss = 1.138497087074087, disc_loss = 0.00034669784160561243
Trained batch 376 in epoch 5, gen_loss = 1.1387460043639024, disc_loss = 0.0003463995018964683
Trained batch 377 in epoch 5, gen_loss = 1.1384594098285392, disc_loss = 0.00034591036280660236
Trained batch 378 in epoch 5, gen_loss = 1.1396710292330519, disc_loss = 0.00034552115819842056
Trained batch 379 in epoch 5, gen_loss = 1.139885860210971, disc_loss = 0.0003451362757340049
Trained batch 380 in epoch 5, gen_loss = 1.1399004589228492, disc_loss = 0.00034460623913140246
Trained batch 381 in epoch 5, gen_loss = 1.1395935161887663, disc_loss = 0.00034441618378797096
Trained batch 382 in epoch 5, gen_loss = 1.1392970242326004, disc_loss = 0.00034440179813960837
Trained batch 383 in epoch 5, gen_loss = 1.1389132807962596, disc_loss = 0.0003447023629708686
Trained batch 384 in epoch 5, gen_loss = 1.1388417976243155, disc_loss = 0.0003451288165600196
Trained batch 385 in epoch 5, gen_loss = 1.1389420423174152, disc_loss = 0.0003450274553950369
Trained batch 386 in epoch 5, gen_loss = 1.1388250905105926, disc_loss = 0.00034454599888008615
Trained batch 387 in epoch 5, gen_loss = 1.1386544782783568, disc_loss = 0.00034414308699815216
Trained batch 388 in epoch 5, gen_loss = 1.138985877938013, disc_loss = 0.0003439112645567929
Trained batch 389 in epoch 5, gen_loss = 1.1396207820146511, disc_loss = 0.00034367640313202847
Trained batch 390 in epoch 5, gen_loss = 1.139473699090426, disc_loss = 0.0003436988315936845
Trained batch 391 in epoch 5, gen_loss = 1.139242170872737, disc_loss = 0.0003434914313921971
Trained batch 392 in epoch 5, gen_loss = 1.139310311876787, disc_loss = 0.0003434856558211489
Trained batch 393 in epoch 5, gen_loss = 1.1391180443582196, disc_loss = 0.0003438142996528399
Trained batch 394 in epoch 5, gen_loss = 1.1386274472067628, disc_loss = 0.00034396800321609346
Trained batch 395 in epoch 5, gen_loss = 1.138918636874719, disc_loss = 0.00034360127072873047
Trained batch 396 in epoch 5, gen_loss = 1.1389013608396803, disc_loss = 0.0003432168774699712
Trained batch 397 in epoch 5, gen_loss = 1.1390590109118266, disc_loss = 0.00034280492049283885
Trained batch 398 in epoch 5, gen_loss = 1.1392906798157179, disc_loss = 0.0003425489975002951
Trained batch 399 in epoch 5, gen_loss = 1.1394438229501247, disc_loss = 0.0003422873529416393
Trained batch 400 in epoch 5, gen_loss = 1.1401534400081397, disc_loss = 0.0003420055045239962
Trained batch 401 in epoch 5, gen_loss = 1.1397566782004798, disc_loss = 0.00034179379908710867
Trained batch 402 in epoch 5, gen_loss = 1.1394200113511854, disc_loss = 0.00034146809447256306
Trained batch 403 in epoch 5, gen_loss = 1.139178013004879, disc_loss = 0.00034105102654078534
Trained batch 404 in epoch 5, gen_loss = 1.1386461558165373, disc_loss = 0.00034096433384412967
Trained batch 405 in epoch 5, gen_loss = 1.1388139977243734, disc_loss = 0.00034087310571526293
Trained batch 406 in epoch 5, gen_loss = 1.1388088297785353, disc_loss = 0.00034040078202992474
Trained batch 407 in epoch 5, gen_loss = 1.1388832377452476, disc_loss = 0.00033992000395550813
Trained batch 408 in epoch 5, gen_loss = 1.1389848165815208, disc_loss = 0.000339557446943867
Trained batch 409 in epoch 5, gen_loss = 1.139840697951433, disc_loss = 0.0003392309431702171
Trained batch 410 in epoch 5, gen_loss = 1.1395395060235276, disc_loss = 0.0003391199908389227
Trained batch 411 in epoch 5, gen_loss = 1.1395908973170716, disc_loss = 0.00033915636892028117
Trained batch 412 in epoch 5, gen_loss = 1.139295904457425, disc_loss = 0.0003390967325571266
Trained batch 413 in epoch 5, gen_loss = 1.1390968898068303, disc_loss = 0.00033897638076563154
Trained batch 414 in epoch 5, gen_loss = 1.1388981586479279, disc_loss = 0.00033898246776121836
Trained batch 415 in epoch 5, gen_loss = 1.1385986515535758, disc_loss = 0.0003386845141903905
Trained batch 416 in epoch 5, gen_loss = 1.1380304626995426, disc_loss = 0.0003389809648793892
Trained batch 417 in epoch 5, gen_loss = 1.1377378419825905, disc_loss = 0.00033892589324219685
Trained batch 418 in epoch 5, gen_loss = 1.1376895839103935, disc_loss = 0.0003392973301478224
Trained batch 419 in epoch 5, gen_loss = 1.1376944252422878, disc_loss = 0.00033939580694312185
Trained batch 420 in epoch 5, gen_loss = 1.138077284547892, disc_loss = 0.00033929850812807827
Trained batch 421 in epoch 5, gen_loss = 1.1380286163063411, disc_loss = 0.00033899360247120763
Trained batch 422 in epoch 5, gen_loss = 1.1383633241585807, disc_loss = 0.0003387564007150467
Trained batch 423 in epoch 5, gen_loss = 1.1386404689752831, disc_loss = 0.0003383494262517109
Trained batch 424 in epoch 5, gen_loss = 1.1388439071879668, disc_loss = 0.0003379417158430442
Trained batch 425 in epoch 5, gen_loss = 1.1391227732241993, disc_loss = 0.00033771033506614195
Trained batch 426 in epoch 5, gen_loss = 1.1389620862464993, disc_loss = 0.00033742329998615804
Trained batch 427 in epoch 5, gen_loss = 1.1389551875747252, disc_loss = 0.00033710019671952214
Trained batch 428 in epoch 5, gen_loss = 1.1385556084292752, disc_loss = 0.00033704523860893725
Trained batch 429 in epoch 5, gen_loss = 1.1383958029192547, disc_loss = 0.00033686360680000035
Trained batch 430 in epoch 5, gen_loss = 1.1379659242253846, disc_loss = 0.00033713851655885283
Trained batch 431 in epoch 5, gen_loss = 1.1380213063072275, disc_loss = 0.000337859211935278
Trained batch 432 in epoch 5, gen_loss = 1.138069064182167, disc_loss = 0.000339146115691842
Trained batch 433 in epoch 5, gen_loss = 1.138159178643732, disc_loss = 0.0003402689283403615
Trained batch 434 in epoch 5, gen_loss = 1.1380845212388313, disc_loss = 0.00034054392532595356
Trained batch 435 in epoch 5, gen_loss = 1.1378633658820336, disc_loss = 0.00034046155433149137
Trained batch 436 in epoch 5, gen_loss = 1.1377911354911683, disc_loss = 0.000340351456676629
Trained batch 437 in epoch 5, gen_loss = 1.1383323021675353, disc_loss = 0.0003408153508029682
Trained batch 438 in epoch 5, gen_loss = 1.138756895934259, disc_loss = 0.0003408691236576392
Trained batch 439 in epoch 5, gen_loss = 1.1385963247580961, disc_loss = 0.0003405978029728761
Trained batch 440 in epoch 5, gen_loss = 1.1384086352086662, disc_loss = 0.00034022681694768176
Trained batch 441 in epoch 5, gen_loss = 1.1383335172320923, disc_loss = 0.00033978557680855714
Trained batch 442 in epoch 5, gen_loss = 1.1382743168630665, disc_loss = 0.00033945730658990184
Trained batch 443 in epoch 5, gen_loss = 1.138558034961288, disc_loss = 0.0003391646061720314
Trained batch 444 in epoch 5, gen_loss = 1.1386120764057288, disc_loss = 0.0003389395172694656
Trained batch 445 in epoch 5, gen_loss = 1.1388254857918607, disc_loss = 0.00033874687965935297
Trained batch 446 in epoch 5, gen_loss = 1.1385695990300018, disc_loss = 0.00033847355708048596
Trained batch 447 in epoch 5, gen_loss = 1.1384337536458458, disc_loss = 0.00033800652581053976
Trained batch 448 in epoch 5, gen_loss = 1.1385375715310961, disc_loss = 0.00033765793161571464
Trained batch 449 in epoch 5, gen_loss = 1.13822973118888, disc_loss = 0.0003372795183935927
Trained batch 450 in epoch 5, gen_loss = 1.1383354037405382, disc_loss = 0.0003371022814216749
Trained batch 451 in epoch 5, gen_loss = 1.1383498722473078, disc_loss = 0.0003368066143400584
Trained batch 452 in epoch 5, gen_loss = 1.1383928521053155, disc_loss = 0.0003364544729514574
Trained batch 453 in epoch 5, gen_loss = 1.1381025831604845, disc_loss = 0.00033634685290570164
Trained batch 454 in epoch 5, gen_loss = 1.137786123254797, disc_loss = 0.0003362261665573057
Trained batch 455 in epoch 5, gen_loss = 1.1373155028150792, disc_loss = 0.0003358720243436676
Trained batch 456 in epoch 5, gen_loss = 1.1372270766702732, disc_loss = 0.000335579351869746
Trained batch 457 in epoch 5, gen_loss = 1.1369712576595457, disc_loss = 0.0003352114044861384
Trained batch 458 in epoch 5, gen_loss = 1.1371720647500232, disc_loss = 0.00033487440583378295
Trained batch 459 in epoch 5, gen_loss = 1.1370842140653858, disc_loss = 0.0003344477292874059
Trained batch 460 in epoch 5, gen_loss = 1.1368739144662456, disc_loss = 0.0003340693926559903
Trained batch 461 in epoch 5, gen_loss = 1.1366419270957187, disc_loss = 0.00033375753251809495
Trained batch 462 in epoch 5, gen_loss = 1.136900950971484, disc_loss = 0.0003334357095585601
Trained batch 463 in epoch 5, gen_loss = 1.1367961823426445, disc_loss = 0.000333098832078545
Trained batch 464 in epoch 5, gen_loss = 1.1368612625265635, disc_loss = 0.00033289141463546424
Trained batch 465 in epoch 5, gen_loss = 1.1366704083307617, disc_loss = 0.0003326947673657597
Trained batch 466 in epoch 5, gen_loss = 1.1368466383384688, disc_loss = 0.00033228298788416606
Trained batch 467 in epoch 5, gen_loss = 1.13727407119213, disc_loss = 0.0003322924327283887
Trained batch 468 in epoch 5, gen_loss = 1.1373494210273727, disc_loss = 0.00033260733201312447
Trained batch 469 in epoch 5, gen_loss = 1.1378871428205612, disc_loss = 0.0003323950411249051
Trained batch 470 in epoch 5, gen_loss = 1.137945433078045, disc_loss = 0.00033225444449638776
Trained batch 471 in epoch 5, gen_loss = 1.138232414247626, disc_loss = 0.00033203337193684756
Trained batch 472 in epoch 5, gen_loss = 1.1379271481052262, disc_loss = 0.0003318445109794247
Trained batch 473 in epoch 5, gen_loss = 1.1377390497344455, disc_loss = 0.0003315952637138038
Trained batch 474 in epoch 5, gen_loss = 1.1374773085744758, disc_loss = 0.00033169411254532045
Trained batch 475 in epoch 5, gen_loss = 1.1373881332012785, disc_loss = 0.00033167449821900973
Trained batch 476 in epoch 5, gen_loss = 1.1373457106404334, disc_loss = 0.00033172264712129525
Trained batch 477 in epoch 5, gen_loss = 1.1378095775967363, disc_loss = 0.00033194965253185646
Trained batch 478 in epoch 5, gen_loss = 1.1386080213777705, disc_loss = 0.0003325199863097158
Trained batch 479 in epoch 5, gen_loss = 1.13865183716019, disc_loss = 0.0003336818628971135
Trained batch 480 in epoch 5, gen_loss = 1.1388084273824077, disc_loss = 0.0003348627424372453
Trained batch 481 in epoch 5, gen_loss = 1.1391502888370846, disc_loss = 0.0003352640086484984
Trained batch 482 in epoch 5, gen_loss = 1.1392425930524712, disc_loss = 0.00033495186846274264
Trained batch 483 in epoch 5, gen_loss = 1.1390893176074857, disc_loss = 0.00033484019985742877
Trained batch 484 in epoch 5, gen_loss = 1.1389731881544762, disc_loss = 0.0003344775153235196
Trained batch 485 in epoch 5, gen_loss = 1.139188653892941, disc_loss = 0.0003341849640439602
Trained batch 486 in epoch 5, gen_loss = 1.13955216535063, disc_loss = 0.00033377908845288676
Trained batch 487 in epoch 5, gen_loss = 1.1398098727718728, disc_loss = 0.0003333595740230998
Trained batch 488 in epoch 5, gen_loss = 1.1396268706136443, disc_loss = 0.00033336511501472953
Trained batch 489 in epoch 5, gen_loss = 1.1396057617907622, disc_loss = 0.00033408009550505677
Trained batch 490 in epoch 5, gen_loss = 1.139329379299265, disc_loss = 0.0003348392921773994
Trained batch 491 in epoch 5, gen_loss = 1.1395989932665012, disc_loss = 0.0003349419937107515
Trained batch 492 in epoch 5, gen_loss = 1.1395202057840375, disc_loss = 0.00033512230024816615
Trained batch 493 in epoch 5, gen_loss = 1.1397596197089686, disc_loss = 0.0003357233922303605
Trained batch 494 in epoch 5, gen_loss = 1.1403790026000051, disc_loss = 0.0003359869091343511
Trained batch 495 in epoch 5, gen_loss = 1.1402245156707302, disc_loss = 0.00033573122081795575
Trained batch 496 in epoch 5, gen_loss = 1.140171505076065, disc_loss = 0.0003355018017107107
Trained batch 497 in epoch 5, gen_loss = 1.1400542783449932, disc_loss = 0.00033524493769491017
Trained batch 498 in epoch 5, gen_loss = 1.1396629356430146, disc_loss = 0.00033483205259687084
Trained batch 499 in epoch 5, gen_loss = 1.1397224898338318, disc_loss = 0.00033460692927474156
Trained batch 500 in epoch 5, gen_loss = 1.1400101408511103, disc_loss = 0.0003343217013061731
Trained batch 501 in epoch 5, gen_loss = 1.1400797818286486, disc_loss = 0.0003340318953524255
Trained batch 502 in epoch 5, gen_loss = 1.1401590834081055, disc_loss = 0.00033417845769876997
Trained batch 503 in epoch 5, gen_loss = 1.1403213240324506, disc_loss = 0.0003342597391320086
Trained batch 504 in epoch 5, gen_loss = 1.1404446004640938, disc_loss = 0.0003342932193035186
Trained batch 505 in epoch 5, gen_loss = 1.1403272858721465, disc_loss = 0.00033428869305087414
Trained batch 506 in epoch 5, gen_loss = 1.1401914014853904, disc_loss = 0.00033455429678710263
Trained batch 507 in epoch 5, gen_loss = 1.1400795055655983, disc_loss = 0.00033505220877902224
Trained batch 508 in epoch 5, gen_loss = 1.139957547656211, disc_loss = 0.00033489397101077727
Trained batch 509 in epoch 5, gen_loss = 1.140034068331999, disc_loss = 0.00033460746227658594
Trained batch 510 in epoch 5, gen_loss = 1.140457857844881, disc_loss = 0.0003343931841652625
Trained batch 511 in epoch 5, gen_loss = 1.1410139701329172, disc_loss = 0.00033441454442595386
Trained batch 512 in epoch 5, gen_loss = 1.141067809296398, disc_loss = 0.00033437818595499606
Trained batch 513 in epoch 5, gen_loss = 1.1412574136303557, disc_loss = 0.00033404854892260223
Trained batch 514 in epoch 5, gen_loss = 1.1410916624717342, disc_loss = 0.00033366367335598555
Trained batch 515 in epoch 5, gen_loss = 1.1410389293071836, disc_loss = 0.00033345234731159016
Trained batch 516 in epoch 5, gen_loss = 1.1418199280936205, disc_loss = 0.0003336492878426771
Trained batch 517 in epoch 5, gen_loss = 1.1417418884034323, disc_loss = 0.0003339271626624451
Trained batch 518 in epoch 5, gen_loss = 1.1416477518504295, disc_loss = 0.0003339241682796296
Trained batch 519 in epoch 5, gen_loss = 1.141691080881999, disc_loss = 0.0003341670569240635
Trained batch 520 in epoch 5, gen_loss = 1.1418975127178053, disc_loss = 0.0003346189298864093
Trained batch 521 in epoch 5, gen_loss = 1.1417885201187425, disc_loss = 0.0003352594143772137
Trained batch 522 in epoch 5, gen_loss = 1.141959452492329, disc_loss = 0.00033536785887977214
Trained batch 523 in epoch 5, gen_loss = 1.1418576743311555, disc_loss = 0.0003352183352910135
Trained batch 524 in epoch 5, gen_loss = 1.141694409052531, disc_loss = 0.0003352050267304072
Trained batch 525 in epoch 5, gen_loss = 1.1412878793455348, disc_loss = 0.00039155231652088186
Trained batch 526 in epoch 5, gen_loss = 1.1404954380509522, disc_loss = 0.001627328499593415
Trained batch 527 in epoch 5, gen_loss = 1.140433924667763, disc_loss = 0.0021952119737541193
Trained batch 528 in epoch 5, gen_loss = 1.140726469640245, disc_loss = 0.0028751993897410165
Trained batch 529 in epoch 5, gen_loss = 1.14030966826205, disc_loss = 0.0034037473063777586
Trained batch 530 in epoch 5, gen_loss = 1.1398321835783691, disc_loss = 0.003938498189143368
Trained batch 531 in epoch 5, gen_loss = 1.1395225765785777, disc_loss = 0.004494375023774013
Trained batch 532 in epoch 5, gen_loss = 1.1386714853891513, disc_loss = 0.005164335525205217
Trained batch 533 in epoch 5, gen_loss = 1.1380325433020289, disc_loss = 0.005715438433054509
Trained batch 534 in epoch 5, gen_loss = 1.1375173241178567, disc_loss = 0.0061435887186677045
Trained batch 535 in epoch 5, gen_loss = 1.1370986684489606, disc_loss = 0.006547473898943064
Trained batch 536 in epoch 5, gen_loss = 1.1366165611109031, disc_loss = 0.006942322550241114
Trained batch 537 in epoch 5, gen_loss = 1.135957665935325, disc_loss = 0.007332500277765893
Trained batch 538 in epoch 5, gen_loss = 1.1352017988521668, disc_loss = 0.007679881793815091
Trained batch 539 in epoch 5, gen_loss = 1.1348004627007025, disc_loss = 0.008002945697673432
Trained batch 540 in epoch 5, gen_loss = 1.1340938904589515, disc_loss = 0.008245772470091986
Trained batch 541 in epoch 5, gen_loss = 1.1336804152194864, disc_loss = 0.008484624683341687
Trained batch 542 in epoch 5, gen_loss = 1.1330456890673488, disc_loss = 0.008727583985885693
Trained batch 543 in epoch 5, gen_loss = 1.132846751524245, disc_loss = 0.009060070904444514
Trained batch 544 in epoch 5, gen_loss = 1.1322212059563452, disc_loss = 0.009578872929725566
Trained batch 545 in epoch 5, gen_loss = 1.1322048561913627, disc_loss = 0.010189331494551706
Trained batch 546 in epoch 5, gen_loss = 1.1318456847663336, disc_loss = 0.010528310452051796
Trained batch 547 in epoch 5, gen_loss = 1.1315594986624962, disc_loss = 0.010745084470348904
Trained batch 548 in epoch 5, gen_loss = 1.131319876468464, disc_loss = 0.010947553539027982
Trained batch 549 in epoch 5, gen_loss = 1.1312375713478435, disc_loss = 0.011089347681924912
Trained batch 550 in epoch 5, gen_loss = 1.1308977617975156, disc_loss = 0.011208494215534565
Trained batch 551 in epoch 5, gen_loss = 1.1307379278367844, disc_loss = 0.011296607155494765
Trained batch 552 in epoch 5, gen_loss = 1.1306240139343855, disc_loss = 0.01136927942549713
Trained batch 553 in epoch 5, gen_loss = 1.1305058733005386, disc_loss = 0.01148483520243943
Trained batch 554 in epoch 5, gen_loss = 1.1302110872827136, disc_loss = 0.011538707410947101
Trained batch 555 in epoch 5, gen_loss = 1.1305284859250775, disc_loss = 0.011630155186035055
Trained batch 556 in epoch 5, gen_loss = 1.130186657931261, disc_loss = 0.01184820774345407
Trained batch 557 in epoch 5, gen_loss = 1.1308325952099216, disc_loss = 0.012084384264945392
Trained batch 558 in epoch 5, gen_loss = 1.1307467872640102, disc_loss = 0.012218697952596622
Trained batch 559 in epoch 5, gen_loss = 1.1305097973772458, disc_loss = 0.012318933049729301
Trained batch 560 in epoch 5, gen_loss = 1.1301973122113953, disc_loss = 0.012416629137023296
Trained batch 561 in epoch 5, gen_loss = 1.130326056077387, disc_loss = 0.01247585745122026
Trained batch 562 in epoch 5, gen_loss = 1.1300867034741024, disc_loss = 0.012521878162488469
Trained batch 563 in epoch 5, gen_loss = 1.1303257636778743, disc_loss = 0.012572670374970746
Trained batch 564 in epoch 5, gen_loss = 1.1307048783893079, disc_loss = 0.01263972742998647
Trained batch 565 in epoch 5, gen_loss = 1.1307846119252194, disc_loss = 0.012649610697571723
Trained batch 566 in epoch 5, gen_loss = 1.1305635762803348, disc_loss = 0.012655663246259535
Trained batch 567 in epoch 5, gen_loss = 1.1306901012717838, disc_loss = 0.012649280048336408
Trained batch 568 in epoch 5, gen_loss = 1.1306844347390643, disc_loss = 0.012643800511255882
Trained batch 569 in epoch 5, gen_loss = 1.131323573568411, disc_loss = 0.01267365240708929
Trained batch 570 in epoch 5, gen_loss = 1.1316505621485868, disc_loss = 0.012687778537209152
Trained batch 571 in epoch 5, gen_loss = 1.1314912991715478, disc_loss = 0.012697586001405189
Trained batch 572 in epoch 5, gen_loss = 1.1315540679670337, disc_loss = 0.012701624041927262
Trained batch 573 in epoch 5, gen_loss = 1.1321811895129572, disc_loss = 0.012706163679765747
Trained batch 574 in epoch 5, gen_loss = 1.1323197906950246, disc_loss = 0.012705877790678008
Trained batch 575 in epoch 5, gen_loss = 1.1324869823745556, disc_loss = 0.01272007223262032
Trained batch 576 in epoch 5, gen_loss = 1.1328198886000305, disc_loss = 0.012743117011470384
Trained batch 577 in epoch 5, gen_loss = 1.1334407425462993, disc_loss = 0.012749738193397647
Trained batch 578 in epoch 5, gen_loss = 1.13390526551245, disc_loss = 0.012752358930066609
Trained batch 579 in epoch 5, gen_loss = 1.1339817231071407, disc_loss = 0.012746459850765451
Trained batch 580 in epoch 5, gen_loss = 1.1337250166423554, disc_loss = 0.012751945066543275
Trained batch 581 in epoch 5, gen_loss = 1.1353931391157235, disc_loss = 0.012852680870725676
Trained batch 582 in epoch 5, gen_loss = 1.1355625557654105, disc_loss = 0.012899229451292115
Trained batch 583 in epoch 5, gen_loss = 1.1358416524447807, disc_loss = 0.012918957376463716
Trained batch 584 in epoch 5, gen_loss = 1.1357666169476306, disc_loss = 0.01291339535111438
Trained batch 585 in epoch 5, gen_loss = 1.1357978280290402, disc_loss = 0.01290231679281424
Trained batch 586 in epoch 5, gen_loss = 1.1358608930439924, disc_loss = 0.012894876505684756
Trained batch 587 in epoch 5, gen_loss = 1.1358591538100016, disc_loss = 0.01288719819419638
Trained batch 588 in epoch 5, gen_loss = 1.1360119106611695, disc_loss = 0.01287308215264548
Trained batch 589 in epoch 5, gen_loss = 1.136057640435332, disc_loss = 0.012866306126288383
Trained batch 590 in epoch 5, gen_loss = 1.1364877592085179, disc_loss = 0.012855074612401913
Trained batch 591 in epoch 5, gen_loss = 1.136914099692493, disc_loss = 0.012841465947186973
Trained batch 592 in epoch 5, gen_loss = 1.1370504190909723, disc_loss = 0.01282682036247256
Trained batch 593 in epoch 5, gen_loss = 1.1370702619705135, disc_loss = 0.01281165070130638
Trained batch 594 in epoch 5, gen_loss = 1.1367956020251042, disc_loss = 0.012816764806136059
Trained batch 595 in epoch 5, gen_loss = 1.1371055708435558, disc_loss = 0.012825203791223412
Trained batch 596 in epoch 5, gen_loss = 1.1370381583121154, disc_loss = 0.012817640794045057
Trained batch 597 in epoch 5, gen_loss = 1.137433578437786, disc_loss = 0.012813450778445368
Trained batch 598 in epoch 5, gen_loss = 1.1377696018784194, disc_loss = 0.012802410479492153
Trained batch 599 in epoch 5, gen_loss = 1.1378182539343833, disc_loss = 0.012789731271453397
Trained batch 600 in epoch 5, gen_loss = 1.1380576076801128, disc_loss = 0.012775755708711959
Trained batch 601 in epoch 5, gen_loss = 1.1380701010607406, disc_loss = 0.012759653765649614
Trained batch 602 in epoch 5, gen_loss = 1.1381272108202944, disc_loss = 0.012744337956774956
Trained batch 603 in epoch 5, gen_loss = 1.1382879138190225, disc_loss = 0.012730192140309295
Trained batch 604 in epoch 5, gen_loss = 1.13839918020343, disc_loss = 0.012723954166752318
Trained batch 605 in epoch 5, gen_loss = 1.1382971090255398, disc_loss = 0.012715978320599066
Trained batch 606 in epoch 5, gen_loss = 1.1381832703923471, disc_loss = 0.01269950012226579
Trained batch 607 in epoch 5, gen_loss = 1.1378448606517755, disc_loss = 0.01268953503210325
Trained batch 608 in epoch 5, gen_loss = 1.138232771496859, disc_loss = 0.012676883237448838
Trained batch 609 in epoch 5, gen_loss = 1.138358333169437, disc_loss = 0.012658855742436154
Trained batch 610 in epoch 5, gen_loss = 1.138276073721934, disc_loss = 0.012646410743552168
Trained batch 611 in epoch 5, gen_loss = 1.13856324563229, disc_loss = 0.012632396389937425
Trained batch 612 in epoch 5, gen_loss = 1.1387428802728263, disc_loss = 0.012616141157367778
Trained batch 613 in epoch 5, gen_loss = 1.138650441693949, disc_loss = 0.012605280514260646
Trained batch 614 in epoch 5, gen_loss = 1.1387027708495536, disc_loss = 0.012591137294586543
Trained batch 615 in epoch 5, gen_loss = 1.1385647429080752, disc_loss = 0.012580746594048597
Trained batch 616 in epoch 5, gen_loss = 1.1391601308431578, disc_loss = 0.012579336925188036
Trained batch 617 in epoch 5, gen_loss = 1.1392611798537973, disc_loss = 0.012564175018652087
Trained batch 618 in epoch 5, gen_loss = 1.139359496040375, disc_loss = 0.012549110496179156
Trained batch 619 in epoch 5, gen_loss = 1.139344009564769, disc_loss = 0.012538755045675169
Trained batch 620 in epoch 5, gen_loss = 1.1395125987065202, disc_loss = 0.012522766279359799
Trained batch 621 in epoch 5, gen_loss = 1.139588292484498, disc_loss = 0.012508287728758314
Trained batch 622 in epoch 5, gen_loss = 1.140038235899342, disc_loss = 0.01249257523883123
Trained batch 623 in epoch 5, gen_loss = 1.1401054032911093, disc_loss = 0.012477039854391664
Trained batch 624 in epoch 5, gen_loss = 1.1401757300376891, disc_loss = 0.012459638396953233
Trained batch 625 in epoch 5, gen_loss = 1.1402318910859264, disc_loss = 0.012445386241346534
Trained batch 626 in epoch 5, gen_loss = 1.140071309829633, disc_loss = 0.012429153873029824
Trained batch 627 in epoch 5, gen_loss = 1.1402308632423923, disc_loss = 0.012412016768017554
Trained batch 628 in epoch 5, gen_loss = 1.1401313858873703, disc_loss = 0.012395115410736008
Trained batch 629 in epoch 5, gen_loss = 1.1402740768970006, disc_loss = 0.012381040099717211
Trained batch 630 in epoch 5, gen_loss = 1.140828207536658, disc_loss = 0.012364995143293821
Trained batch 631 in epoch 5, gen_loss = 1.141078860793687, disc_loss = 0.012350529198660228
Trained batch 632 in epoch 5, gen_loss = 1.141175473188337, disc_loss = 0.012338103646987947
Trained batch 633 in epoch 5, gen_loss = 1.1411942849963999, disc_loss = 0.012325824285297889
Trained batch 634 in epoch 5, gen_loss = 1.1411508176270433, disc_loss = 0.012311157560655223
Trained batch 635 in epoch 5, gen_loss = 1.1414818245472398, disc_loss = 0.012297137189330131
Trained batch 636 in epoch 5, gen_loss = 1.1416168333597048, disc_loss = 0.012286002673081699
Trained batch 637 in epoch 5, gen_loss = 1.1418298689362398, disc_loss = 0.012274511599973273
Trained batch 638 in epoch 5, gen_loss = 1.1418042652110725, disc_loss = 0.012263554828216873
Trained batch 639 in epoch 5, gen_loss = 1.1419201283715665, disc_loss = 0.012254395723653033
Trained batch 640 in epoch 5, gen_loss = 1.1417786914175274, disc_loss = 0.012244898187256834
Trained batch 641 in epoch 5, gen_loss = 1.141680459459994, disc_loss = 0.012230845537357433
Trained batch 642 in epoch 5, gen_loss = 1.1419306378898502, disc_loss = 0.012219545965103402
Trained batch 643 in epoch 5, gen_loss = 1.1418684251745295, disc_loss = 0.01221190656597964
Trained batch 644 in epoch 5, gen_loss = 1.1419921022052912, disc_loss = 0.012195087554833
Trained batch 645 in epoch 5, gen_loss = 1.1423617648450952, disc_loss = 0.012180867231449713
Trained batch 646 in epoch 5, gen_loss = 1.1423723368777374, disc_loss = 0.012166344656338562
Trained batch 647 in epoch 5, gen_loss = 1.1424878996647434, disc_loss = 0.01214913016086445
Trained batch 648 in epoch 5, gen_loss = 1.1425196473330306, disc_loss = 0.012131641966740828
Trained batch 649 in epoch 5, gen_loss = 1.1426734099938318, disc_loss = 0.012115442739248885
Trained batch 650 in epoch 5, gen_loss = 1.142853319644928, disc_loss = 0.012100092961565383
Trained batch 651 in epoch 5, gen_loss = 1.1435308055095146, disc_loss = 0.012083629304079798
Trained batch 652 in epoch 5, gen_loss = 1.143501760492281, disc_loss = 0.012071728520260255
Trained batch 653 in epoch 5, gen_loss = 1.1433112463637594, disc_loss = 0.012058769631156284
Trained batch 654 in epoch 5, gen_loss = 1.1435723716976078, disc_loss = 0.01204457174036172
Trained batch 655 in epoch 5, gen_loss = 1.1437047041225723, disc_loss = 0.012034291757162264
Trained batch 656 in epoch 5, gen_loss = 1.1443427689543597, disc_loss = 0.012022619526940496
Trained batch 657 in epoch 5, gen_loss = 1.144413634183559, disc_loss = 0.012007011644356271
Trained batch 658 in epoch 5, gen_loss = 1.14456079102069, disc_loss = 0.011992665334366727
Trained batch 659 in epoch 5, gen_loss = 1.144452953248313, disc_loss = 0.011979562615482737
Trained batch 660 in epoch 5, gen_loss = 1.144432505302458, disc_loss = 0.011965339317758082
Trained batch 661 in epoch 5, gen_loss = 1.1443887537519737, disc_loss = 0.011949462839178044
Trained batch 662 in epoch 5, gen_loss = 1.144266130607772, disc_loss = 0.011933122886237506
Trained batch 663 in epoch 5, gen_loss = 1.1441107755863522, disc_loss = 0.011919919762246526
Trained batch 664 in epoch 5, gen_loss = 1.1441491065168738, disc_loss = 0.011903467447224732
Trained batch 665 in epoch 5, gen_loss = 1.1438504173769966, disc_loss = 0.011896287559381477
Trained batch 666 in epoch 5, gen_loss = 1.1435437593860427, disc_loss = 0.011892117989813104
Trained batch 667 in epoch 5, gen_loss = 1.1438033493336088, disc_loss = 0.011884469842012102
Trained batch 668 in epoch 5, gen_loss = 1.1440034228055467, disc_loss = 0.011870958794157024
Trained batch 669 in epoch 5, gen_loss = 1.1443369564725392, disc_loss = 0.011859054751055656
Trained batch 670 in epoch 5, gen_loss = 1.1441819030019813, disc_loss = 0.01185177663574429
Trained batch 671 in epoch 5, gen_loss = 1.1441241759984266, disc_loss = 0.011838022343194357
Trained batch 672 in epoch 5, gen_loss = 1.1442420952033145, disc_loss = 0.011827235073626995
Trained batch 673 in epoch 5, gen_loss = 1.144423322260203, disc_loss = 0.011816608476528009
Trained batch 674 in epoch 5, gen_loss = 1.1448745107650757, disc_loss = 0.011802065482350169
Trained batch 675 in epoch 5, gen_loss = 1.144929695940582, disc_loss = 0.011795845958212226
Trained batch 676 in epoch 5, gen_loss = 1.1448566330764636, disc_loss = 0.011788683726977278
Trained batch 677 in epoch 5, gen_loss = 1.1448919345847273, disc_loss = 0.011775007607968378
Trained batch 678 in epoch 5, gen_loss = 1.1450167931232256, disc_loss = 0.01176123738559172
Trained batch 679 in epoch 5, gen_loss = 1.1451208621263504, disc_loss = 0.011748063079999958
Trained batch 680 in epoch 5, gen_loss = 1.1452240299723397, disc_loss = 0.011737205059953593
Trained batch 681 in epoch 5, gen_loss = 1.1457393796912387, disc_loss = 0.011723010702990849
Trained batch 682 in epoch 5, gen_loss = 1.145851209432454, disc_loss = 0.011717632147545742
Trained batch 683 in epoch 5, gen_loss = 1.1460862910886953, disc_loss = 0.011707216960621204
Trained batch 684 in epoch 5, gen_loss = 1.1460436920179937, disc_loss = 0.011693793691097364
Trained batch 685 in epoch 5, gen_loss = 1.1461401182082929, disc_loss = 0.01168103456589595
Trained batch 686 in epoch 5, gen_loss = 1.1461221215679829, disc_loss = 0.011666921122133321
Trained batch 687 in epoch 5, gen_loss = 1.1462550345201825, disc_loss = 0.011651440624941748
Trained batch 688 in epoch 5, gen_loss = 1.1462593893527293, disc_loss = 0.01163931537596715
Trained batch 689 in epoch 5, gen_loss = 1.1463994831278703, disc_loss = 0.011626833294829577
Trained batch 690 in epoch 5, gen_loss = 1.1466721018557955, disc_loss = 0.011612814452685988
Trained batch 691 in epoch 5, gen_loss = 1.1467872361916338, disc_loss = 0.011597703103867872
Trained batch 692 in epoch 5, gen_loss = 1.1469274024770717, disc_loss = 0.011583001419894625
Trained batch 693 in epoch 5, gen_loss = 1.1467275059532362, disc_loss = 0.01156948718646362
Trained batch 694 in epoch 5, gen_loss = 1.146405666937931, disc_loss = 0.011555293811633413
Trained batch 695 in epoch 5, gen_loss = 1.1463475771162701, disc_loss = 0.011542945930483548
Trained batch 696 in epoch 5, gen_loss = 1.1464015064998885, disc_loss = 0.011528730066948292
Trained batch 697 in epoch 5, gen_loss = 1.146370233727731, disc_loss = 0.011516126000675484
Trained batch 698 in epoch 5, gen_loss = 1.1462147347575775, disc_loss = 0.011501314375171996
Trained batch 699 in epoch 5, gen_loss = 1.1459373824085508, disc_loss = 0.011486519150889113
Trained batch 700 in epoch 5, gen_loss = 1.1463518274493631, disc_loss = 0.011473224047471281
Trained batch 701 in epoch 5, gen_loss = 1.146419499759321, disc_loss = 0.011461385346517436
Trained batch 702 in epoch 5, gen_loss = 1.1465002066888985, disc_loss = 0.011449146140645825
Trained batch 703 in epoch 5, gen_loss = 1.146525666710328, disc_loss = 0.011434433111327797
Trained batch 704 in epoch 5, gen_loss = 1.1462879798936505, disc_loss = 0.011423211643849632
Trained batch 705 in epoch 5, gen_loss = 1.1462209178266713, disc_loss = 0.011412181635935515
Trained batch 706 in epoch 5, gen_loss = 1.1464415485990436, disc_loss = 0.01139995545385385
Trained batch 707 in epoch 5, gen_loss = 1.1462103014780303, disc_loss = 0.011386075176813773
Trained batch 708 in epoch 5, gen_loss = 1.146086596719637, disc_loss = 0.011372295991677366
Trained batch 709 in epoch 5, gen_loss = 1.145895771325474, disc_loss = 0.011357788369571954
Trained batch 710 in epoch 5, gen_loss = 1.145775904719169, disc_loss = 0.011344320908878634
Trained batch 711 in epoch 5, gen_loss = 1.1457644293314955, disc_loss = 0.01133105438155612
Trained batch 712 in epoch 5, gen_loss = 1.145974304448672, disc_loss = 0.011316599204032067
Trained batch 713 in epoch 5, gen_loss = 1.146213766490044, disc_loss = 0.011302379753359258
Trained batch 714 in epoch 5, gen_loss = 1.1465904631814756, disc_loss = 0.011288743054390872
Trained batch 715 in epoch 5, gen_loss = 1.146637892506642, disc_loss = 0.011274421104548177
Trained batch 716 in epoch 5, gen_loss = 1.146976556821182, disc_loss = 0.011260398188847016
Trained batch 717 in epoch 5, gen_loss = 1.1474730114252787, disc_loss = 0.01124623322129865
Trained batch 718 in epoch 5, gen_loss = 1.1473604275719347, disc_loss = 0.011232920690014296
Trained batch 719 in epoch 5, gen_loss = 1.1474242363539007, disc_loss = 0.011218796086763582
Trained batch 720 in epoch 5, gen_loss = 1.147403623211235, disc_loss = 0.011204176160350124
Trained batch 721 in epoch 5, gen_loss = 1.1472561279327256, disc_loss = 0.011191659756321647
Trained batch 722 in epoch 5, gen_loss = 1.1469265046950692, disc_loss = 0.011178373438062212
Trained batch 723 in epoch 5, gen_loss = 1.1469009771366805, disc_loss = 0.011167650404650729
Trained batch 724 in epoch 5, gen_loss = 1.1470509590773748, disc_loss = 0.011153682703814663
Trained batch 725 in epoch 5, gen_loss = 1.1468336768550977, disc_loss = 0.011141345378919216
Trained batch 726 in epoch 5, gen_loss = 1.1467555608021345, disc_loss = 0.011130617485059639
Trained batch 727 in epoch 5, gen_loss = 1.1469637172726483, disc_loss = 0.011118153311974391
Trained batch 728 in epoch 5, gen_loss = 1.1469973024026847, disc_loss = 0.011104196542574557
Trained batch 729 in epoch 5, gen_loss = 1.146905887698474, disc_loss = 0.011090689109122438
Trained batch 730 in epoch 5, gen_loss = 1.1466026608660185, disc_loss = 0.011078181674675449
Trained batch 731 in epoch 5, gen_loss = 1.146577742174675, disc_loss = 0.011066067490563379
Trained batch 732 in epoch 5, gen_loss = 1.146510860360498, disc_loss = 0.011053324592101075
Trained batch 733 in epoch 5, gen_loss = 1.1464567092686324, disc_loss = 0.011039257423251351
Trained batch 734 in epoch 5, gen_loss = 1.1463148122742062, disc_loss = 0.01102541283845702
Trained batch 735 in epoch 5, gen_loss = 1.1461407907469117, disc_loss = 0.011012901091125177
Trained batch 736 in epoch 5, gen_loss = 1.1463555308662892, disc_loss = 0.010999190371839445
Trained batch 737 in epoch 5, gen_loss = 1.1462806989022387, disc_loss = 0.010985643567908132
Trained batch 738 in epoch 5, gen_loss = 1.1463707986316758, disc_loss = 0.010971858196108759
Trained batch 739 in epoch 5, gen_loss = 1.1460861146450043, disc_loss = 0.010959991020786835
Trained batch 740 in epoch 5, gen_loss = 1.1460506682775602, disc_loss = 0.010947852043891999
Trained batch 741 in epoch 5, gen_loss = 1.1460144598529023, disc_loss = 0.01093407017899369
Trained batch 742 in epoch 5, gen_loss = 1.1459682881431015, disc_loss = 0.010920229321083243
Trained batch 743 in epoch 5, gen_loss = 1.1455918355814871, disc_loss = 0.011073058971344845
Trained batch 744 in epoch 5, gen_loss = 1.14484069211371, disc_loss = 0.01164284816479401
Trained batch 745 in epoch 5, gen_loss = 1.1443301085332762, disc_loss = 0.01178842606152868
Trained batch 746 in epoch 5, gen_loss = 1.1443379634674613, disc_loss = 0.01189015909406114
Trained batch 747 in epoch 5, gen_loss = 1.144988778201654, disc_loss = 0.011982807450863827
Trained batch 748 in epoch 5, gen_loss = 1.144781807315684, disc_loss = 0.012030740301653983
Trained batch 749 in epoch 5, gen_loss = 1.1447761056423187, disc_loss = 0.012044996171743453
Trained batch 750 in epoch 5, gen_loss = 1.1451764656764054, disc_loss = 0.012040622767542933
Trained batch 751 in epoch 5, gen_loss = 1.1455602703734915, disc_loss = 0.012032331315048337
Trained batch 752 in epoch 5, gen_loss = 1.1456583175526198, disc_loss = 0.012026437593656927
Trained batch 753 in epoch 5, gen_loss = 1.1461415258421506, disc_loss = 0.012028500024743894
Trained batch 754 in epoch 5, gen_loss = 1.146481342741985, disc_loss = 0.012018806843371562
Trained batch 755 in epoch 5, gen_loss = 1.1463438139233009, disc_loss = 0.012028666393802576
Trained batch 756 in epoch 5, gen_loss = 1.1468500211500272, disc_loss = 0.01202467339908193
Trained batch 757 in epoch 5, gen_loss = 1.147193727439815, disc_loss = 0.012019371763314827
Trained batch 758 in epoch 5, gen_loss = 1.1477340971057124, disc_loss = 0.012011058428724313
Trained batch 759 in epoch 5, gen_loss = 1.1477215276736963, disc_loss = 0.01200268358426049
Trained batch 760 in epoch 5, gen_loss = 1.1478340145636168, disc_loss = 0.011990092953768162
Trained batch 761 in epoch 5, gen_loss = 1.1478954455827477, disc_loss = 0.011981744973253723
Trained batch 762 in epoch 5, gen_loss = 1.1480841568694358, disc_loss = 0.011970601479302716
Trained batch 763 in epoch 5, gen_loss = 1.1483836834811416, disc_loss = 0.011958966105592014
Trained batch 764 in epoch 5, gen_loss = 1.1488037987472186, disc_loss = 0.011945894876593158
Trained batch 765 in epoch 5, gen_loss = 1.1487694679134508, disc_loss = 0.011933077297128
Trained batch 766 in epoch 5, gen_loss = 1.148858950144309, disc_loss = 0.011919798081331083
Trained batch 767 in epoch 5, gen_loss = 1.1489870437265683, disc_loss = 0.011907565720491675
Trained batch 768 in epoch 5, gen_loss = 1.1492608893367187, disc_loss = 0.011893696854423437
Trained batch 769 in epoch 5, gen_loss = 1.1493224680423737, disc_loss = 0.011880660886961707
Trained batch 770 in epoch 5, gen_loss = 1.1498312817937206, disc_loss = 0.011872533901043305
Trained batch 771 in epoch 5, gen_loss = 1.1501940051045443, disc_loss = 0.01185891167591329
Trained batch 772 in epoch 5, gen_loss = 1.1501312383087918, disc_loss = 0.011850091622273238
Trained batch 773 in epoch 5, gen_loss = 1.1501157475534336, disc_loss = 0.01183906828704334
Trained batch 774 in epoch 5, gen_loss = 1.149950365789475, disc_loss = 0.011828636279378477
Trained batch 775 in epoch 5, gen_loss = 1.1498415183621584, disc_loss = 0.01181814202920071
Trained batch 776 in epoch 5, gen_loss = 1.1500943148151481, disc_loss = 0.011808055982658456
Trained batch 777 in epoch 5, gen_loss = 1.150307603467706, disc_loss = 0.01179779775710109
Trained batch 778 in epoch 5, gen_loss = 1.1502951362931835, disc_loss = 0.011785502041486363
Trained batch 779 in epoch 5, gen_loss = 1.1504560940540753, disc_loss = 0.011773160672974205
Trained batch 780 in epoch 5, gen_loss = 1.1505461315339414, disc_loss = 0.011761975413709002
Trained batch 781 in epoch 5, gen_loss = 1.150305214211764, disc_loss = 0.0117534871790637
Trained batch 782 in epoch 5, gen_loss = 1.1503033279459138, disc_loss = 0.011742882736701201
Trained batch 783 in epoch 5, gen_loss = 1.1504877852085902, disc_loss = 0.011730833667644795
Trained batch 784 in epoch 5, gen_loss = 1.150336792590512, disc_loss = 0.01171853573517177
Trained batch 785 in epoch 5, gen_loss = 1.1503839552705828, disc_loss = 0.011706570188418468
Trained batch 786 in epoch 5, gen_loss = 1.15044574354322, disc_loss = 0.011693474902491691
Trained batch 787 in epoch 5, gen_loss = 1.1504057061097344, disc_loss = 0.011680477994499606
Trained batch 788 in epoch 5, gen_loss = 1.1505403140198596, disc_loss = 0.011668120573454947
Trained batch 789 in epoch 5, gen_loss = 1.1504823913302602, disc_loss = 0.011655523422003954
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 1.1893975734710693, disc_loss = 0.0011950600892305374
Trained batch 1 in epoch 6, gen_loss = 1.2354240417480469, disc_loss = 0.001284838654100895
Trained batch 2 in epoch 6, gen_loss = 1.2638461192448933, disc_loss = 0.0014191380857179563
Trained batch 3 in epoch 6, gen_loss = 1.2545196413993835, disc_loss = 0.0014664978079963475
Trained batch 4 in epoch 6, gen_loss = 1.254866886138916, disc_loss = 0.0014250457054004074
Trained batch 5 in epoch 6, gen_loss = 1.2388194799423218, disc_loss = 0.0013327000779099762
Trained batch 6 in epoch 6, gen_loss = 1.2229201453072684, disc_loss = 0.0014388639579660126
Trained batch 7 in epoch 6, gen_loss = 1.2221073806285858, disc_loss = 0.0014121279527898878
Trained batch 8 in epoch 6, gen_loss = 1.2179434299468994, disc_loss = 0.0013296610235960947
Trained batch 9 in epoch 6, gen_loss = 1.196332335472107, disc_loss = 0.0013600669684819878
Trained batch 10 in epoch 6, gen_loss = 1.1829939105293967, disc_loss = 0.001406213109889491
Trained batch 11 in epoch 6, gen_loss = 1.1686734557151794, disc_loss = 0.0014200187773288537
Trained batch 12 in epoch 6, gen_loss = 1.185084581375122, disc_loss = 0.0013705320172728254
Trained batch 13 in epoch 6, gen_loss = 1.1732772077832903, disc_loss = 0.0013368306764667587
Trained batch 14 in epoch 6, gen_loss = 1.1679526408513388, disc_loss = 0.0013678092431897919
Trained batch 15 in epoch 6, gen_loss = 1.1611657068133354, disc_loss = 0.0014032615727046505
Trained batch 16 in epoch 6, gen_loss = 1.1596749740488388, disc_loss = 0.00149185091311879
Trained batch 17 in epoch 6, gen_loss = 1.1585121154785156, disc_loss = 0.001462904823711142
Trained batch 18 in epoch 6, gen_loss = 1.1604399618349577, disc_loss = 0.0014352596971500468
Trained batch 19 in epoch 6, gen_loss = 1.175940328836441, disc_loss = 0.0014732911571627484
Trained batch 20 in epoch 6, gen_loss = 1.169206142425537, disc_loss = 0.0015109510665449004
Trained batch 21 in epoch 6, gen_loss = 1.1694985736500134, disc_loss = 0.0014799839330159805
Trained batch 22 in epoch 6, gen_loss = 1.176227797632632, disc_loss = 0.0014618053303464599
Trained batch 23 in epoch 6, gen_loss = 1.1736959119637806, disc_loss = 0.0014283922355389223
Trained batch 24 in epoch 6, gen_loss = 1.1773936080932617, disc_loss = 0.001461650119163096
Trained batch 25 in epoch 6, gen_loss = 1.178339352974525, disc_loss = 0.0014546365396549495
Trained batch 26 in epoch 6, gen_loss = 1.1709516489947285, disc_loss = 0.0014991420536750444
Trained batch 27 in epoch 6, gen_loss = 1.174674826008933, disc_loss = 0.001559368272345247
Trained batch 28 in epoch 6, gen_loss = 1.1800454156152134, disc_loss = 0.0015882220930130832
Trained batch 29 in epoch 6, gen_loss = 1.1739030003547668, disc_loss = 0.001576768762121598
Trained batch 30 in epoch 6, gen_loss = 1.1757508054856332, disc_loss = 0.001615278708237794
Trained batch 31 in epoch 6, gen_loss = 1.1738249845802784, disc_loss = 0.0015933320555632235
Trained batch 32 in epoch 6, gen_loss = 1.1739882086262559, disc_loss = 0.0015822938717478378
Trained batch 33 in epoch 6, gen_loss = 1.1736636968219982, disc_loss = 0.0016080948322162252
Trained batch 34 in epoch 6, gen_loss = 1.171025116103036, disc_loss = 0.0016153645518768047
Trained batch 35 in epoch 6, gen_loss = 1.1745363341437445, disc_loss = 0.001592647402301534
Trained batch 36 in epoch 6, gen_loss = 1.175658242122547, disc_loss = 0.0015760079652347879
Trained batch 37 in epoch 6, gen_loss = 1.177561066652599, disc_loss = 0.0015587549194031837
Trained batch 38 in epoch 6, gen_loss = 1.1751212920898046, disc_loss = 0.0015456339430947525
Trained batch 39 in epoch 6, gen_loss = 1.1765357971191406, disc_loss = 0.0015350678833783605
Trained batch 40 in epoch 6, gen_loss = 1.176222612218159, disc_loss = 0.0015572904021388329
Trained batch 41 in epoch 6, gen_loss = 1.1784461339314778, disc_loss = 0.0015524077863942477
Trained batch 42 in epoch 6, gen_loss = 1.1765512727027716, disc_loss = 0.0015644972377759946
Trained batch 43 in epoch 6, gen_loss = 1.1734395650300113, disc_loss = 0.0015556225830964236
Trained batch 44 in epoch 6, gen_loss = 1.1734465519587198, disc_loss = 0.0015533222467638552
Trained batch 45 in epoch 6, gen_loss = 1.169781594172768, disc_loss = 0.0015481251491861337
Trained batch 46 in epoch 6, gen_loss = 1.1659460625749953, disc_loss = 0.0015458759958261346
Trained batch 47 in epoch 6, gen_loss = 1.1668129811684291, disc_loss = 0.001542599766253261
Trained batch 48 in epoch 6, gen_loss = 1.1632405774933952, disc_loss = 0.0015323772202055826
Trained batch 49 in epoch 6, gen_loss = 1.1623581635951996, disc_loss = 0.0015326404722873122
Trained batch 50 in epoch 6, gen_loss = 1.1604851262242186, disc_loss = 0.001550481340838779
Trained batch 51 in epoch 6, gen_loss = 1.161968851318726, disc_loss = 0.0015456701344541775
Trained batch 52 in epoch 6, gen_loss = 1.1613594462286752, disc_loss = 0.0015369405506512608
Trained batch 53 in epoch 6, gen_loss = 1.1633368697431352, disc_loss = 0.0015266779454476717
Trained batch 54 in epoch 6, gen_loss = 1.1621725353327665, disc_loss = 0.0015203830606134777
Trained batch 55 in epoch 6, gen_loss = 1.1669915222695895, disc_loss = 0.0015101308464571567
Trained batch 56 in epoch 6, gen_loss = 1.165386702930718, disc_loss = 0.0014941655875494082
Trained batch 57 in epoch 6, gen_loss = 1.1650954413002934, disc_loss = 0.0014907020617854492
Trained batch 58 in epoch 6, gen_loss = 1.163974334627895, disc_loss = 0.0015310155803937527
Trained batch 59 in epoch 6, gen_loss = 1.1661177903413773, disc_loss = 0.0015193802867239962
Trained batch 60 in epoch 6, gen_loss = 1.1693304513321547, disc_loss = 0.0015116277414175575
Trained batch 61 in epoch 6, gen_loss = 1.1695615851110028, disc_loss = 0.0015150262024103394
Trained batch 62 in epoch 6, gen_loss = 1.1693875704492842, disc_loss = 0.0015044149181376847
Trained batch 63 in epoch 6, gen_loss = 1.167918968014419, disc_loss = 0.0014941868685127702
Trained batch 64 in epoch 6, gen_loss = 1.1664599812947787, disc_loss = 0.001485474940496855
Trained batch 65 in epoch 6, gen_loss = 1.16570363351793, disc_loss = 0.0014914278493079385
Trained batch 66 in epoch 6, gen_loss = 1.1657896940387897, disc_loss = 0.001488852574413559
Trained batch 67 in epoch 6, gen_loss = 1.1683360346976448, disc_loss = 0.0014804881151683409
Trained batch 68 in epoch 6, gen_loss = 1.1661052487898564, disc_loss = 0.0014726736252128646
Trained batch 69 in epoch 6, gen_loss = 1.1644460925034115, disc_loss = 0.0014587409178992467
Trained batch 70 in epoch 6, gen_loss = 1.1623459928472277, disc_loss = 0.0014457394644408158
Trained batch 71 in epoch 6, gen_loss = 1.1594183370471, disc_loss = 0.0014381920660121574
Trained batch 72 in epoch 6, gen_loss = 1.1568367718017265, disc_loss = 0.001429537803968032
Trained batch 73 in epoch 6, gen_loss = 1.1575979082971006, disc_loss = 0.0014281924106054813
Trained batch 74 in epoch 6, gen_loss = 1.157600306669871, disc_loss = 0.0014173924752200644
Trained batch 75 in epoch 6, gen_loss = 1.15647381465686, disc_loss = 0.0014125174968380872
Trained batch 76 in epoch 6, gen_loss = 1.154265802402001, disc_loss = 0.0014082955108810362
Trained batch 77 in epoch 6, gen_loss = 1.15471317141484, disc_loss = 0.0013987145846327527
Trained batch 78 in epoch 6, gen_loss = 1.154379505899888, disc_loss = 0.0013918423674458378
Trained batch 79 in epoch 6, gen_loss = 1.1540838591754436, disc_loss = 0.0014024088464793748
Trained batch 80 in epoch 6, gen_loss = 1.1538531434388808, disc_loss = 0.001391393956038411
Trained batch 81 in epoch 6, gen_loss = 1.1510682229588671, disc_loss = 0.0014188536457013247
Trained batch 82 in epoch 6, gen_loss = 1.1506111743938492, disc_loss = 0.00143619564625558
Trained batch 83 in epoch 6, gen_loss = 1.1526665978488468, disc_loss = 0.001433583544678099
Trained batch 84 in epoch 6, gen_loss = 1.1524944494752323, disc_loss = 0.0014268130577607628
Trained batch 85 in epoch 6, gen_loss = 1.1514602310435718, disc_loss = 0.0014273009383455352
Trained batch 86 in epoch 6, gen_loss = 1.1495501919724476, disc_loss = 0.0014225702817102187
Trained batch 87 in epoch 6, gen_loss = 1.147872611202977, disc_loss = 0.001430602246149316
Trained batch 88 in epoch 6, gen_loss = 1.1473210775450375, disc_loss = 0.0014312217042132627
Trained batch 89 in epoch 6, gen_loss = 1.14573868976699, disc_loss = 0.0014380591009588292
Trained batch 90 in epoch 6, gen_loss = 1.144126941214551, disc_loss = 0.001443819876550441
Trained batch 91 in epoch 6, gen_loss = 1.1436187605495038, disc_loss = 0.00144113276632118
Trained batch 92 in epoch 6, gen_loss = 1.1440009795209414, disc_loss = 0.0014377720935660745
Trained batch 93 in epoch 6, gen_loss = 1.1417668151094558, disc_loss = 0.0014313320639206374
Trained batch 94 in epoch 6, gen_loss = 1.139570939540863, disc_loss = 0.0014376667279161904
Trained batch 95 in epoch 6, gen_loss = 1.14142380344371, disc_loss = 0.00144445117378685
Trained batch 96 in epoch 6, gen_loss = 1.141250899772054, disc_loss = 0.001470774284938408
Trained batch 97 in epoch 6, gen_loss = 1.1456995174592854, disc_loss = 0.0015291693187983973
Trained batch 98 in epoch 6, gen_loss = 1.1466401327740063, disc_loss = 0.0015244133020233777
Trained batch 99 in epoch 6, gen_loss = 1.147949017882347, disc_loss = 0.0015213161299470813
Trained batch 100 in epoch 6, gen_loss = 1.1477533242490032, disc_loss = 0.0015236348038225776
Trained batch 101 in epoch 6, gen_loss = 1.1476009739380257, disc_loss = 0.0015269843713088217
Trained batch 102 in epoch 6, gen_loss = 1.1477505043872351, disc_loss = 0.0015255896706875523
Trained batch 103 in epoch 6, gen_loss = 1.1469174686532755, disc_loss = 0.001524331436555188
Trained batch 104 in epoch 6, gen_loss = 1.1447790906542823, disc_loss = 0.0015388720790811238
Trained batch 105 in epoch 6, gen_loss = 1.1453606610028249, disc_loss = 0.0015483036876726404
Trained batch 106 in epoch 6, gen_loss = 1.1449289734118453, disc_loss = 0.00156642139179928
Trained batch 107 in epoch 6, gen_loss = 1.1445947488149006, disc_loss = 0.0015701701146705698
Trained batch 108 in epoch 6, gen_loss = 1.144103190220824, disc_loss = 0.001587156876024508
Trained batch 109 in epoch 6, gen_loss = 1.1438317038796164, disc_loss = 0.0015960767156105828
Trained batch 110 in epoch 6, gen_loss = 1.143746170911703, disc_loss = 0.0015910420648602617
Trained batch 111 in epoch 6, gen_loss = 1.143443217234952, disc_loss = 0.001587569604453165
Trained batch 112 in epoch 6, gen_loss = 1.14129111144395, disc_loss = 0.0015967440723433299
Trained batch 113 in epoch 6, gen_loss = 1.1443619555548619, disc_loss = 0.0016047046591299015
Trained batch 114 in epoch 6, gen_loss = 1.1445944221123405, disc_loss = 0.0016051221770517852
Trained batch 115 in epoch 6, gen_loss = 1.1452245933228526, disc_loss = 0.001602865989392238
Trained batch 116 in epoch 6, gen_loss = 1.1445800804684305, disc_loss = 0.001602628456357007
Trained batch 117 in epoch 6, gen_loss = 1.1449157560275773, disc_loss = 0.0016086500945059045
Trained batch 118 in epoch 6, gen_loss = 1.1465183220991568, disc_loss = 0.0016105888350749342
Trained batch 119 in epoch 6, gen_loss = 1.1477071498831113, disc_loss = 0.0016025484820905453
Trained batch 120 in epoch 6, gen_loss = 1.1474500800952439, disc_loss = 0.0016006521249482455
Trained batch 121 in epoch 6, gen_loss = 1.1477136089176427, disc_loss = 0.0016046612977706752
Trained batch 122 in epoch 6, gen_loss = 1.1468095532277736, disc_loss = 0.0016009736942445359
Trained batch 123 in epoch 6, gen_loss = 1.1485213930568388, disc_loss = 0.0016144271827332915
Trained batch 124 in epoch 6, gen_loss = 1.1492540383338927, disc_loss = 0.0016145632127299906
Trained batch 125 in epoch 6, gen_loss = 1.149278819087952, disc_loss = 0.001617161604198849
Trained batch 126 in epoch 6, gen_loss = 1.1485392338647618, disc_loss = 0.0016134481961420906
Trained batch 127 in epoch 6, gen_loss = 1.1478117653168738, disc_loss = 0.0016096890776680084
Trained batch 128 in epoch 6, gen_loss = 1.1471425659896792, disc_loss = 0.0016060539524886729
Trained batch 129 in epoch 6, gen_loss = 1.1454606423011193, disc_loss = 0.0016042980884846587
Trained batch 130 in epoch 6, gen_loss = 1.1454852955941937, disc_loss = 0.001600660547215975
Trained batch 131 in epoch 6, gen_loss = 1.1457036444635103, disc_loss = 0.0015996034348835096
Trained batch 132 in epoch 6, gen_loss = 1.144918336007828, disc_loss = 0.0015928184182936313
Trained batch 133 in epoch 6, gen_loss = 1.1451216873837942, disc_loss = 0.0015861479280544306
Trained batch 134 in epoch 6, gen_loss = 1.1462904232519644, disc_loss = 0.0015853579069867178
Trained batch 135 in epoch 6, gen_loss = 1.145075656911906, disc_loss = 0.001581244293929023
Trained batch 136 in epoch 6, gen_loss = 1.1462238852995155, disc_loss = 0.0015758651930730056
Trained batch 137 in epoch 6, gen_loss = 1.1453310700430386, disc_loss = 0.001574481390349135
Trained batch 138 in epoch 6, gen_loss = 1.1451869165297035, disc_loss = 0.0015708128536428266
Trained batch 139 in epoch 6, gen_loss = 1.1441529291016714, disc_loss = 0.0015663404637182663
Trained batch 140 in epoch 6, gen_loss = 1.1440158380684278, disc_loss = 0.0015603848390367066
Trained batch 141 in epoch 6, gen_loss = 1.1425807282958231, disc_loss = 0.0015607103570134864
Trained batch 142 in epoch 6, gen_loss = 1.1422406118232886, disc_loss = 0.0015546060667920312
Trained batch 143 in epoch 6, gen_loss = 1.1425806507468224, disc_loss = 0.001549029783038552
Trained batch 144 in epoch 6, gen_loss = 1.1421891031594111, disc_loss = 0.001542454899352943
Trained batch 145 in epoch 6, gen_loss = 1.1439101622529226, disc_loss = 0.0015382426519788904
Trained batch 146 in epoch 6, gen_loss = 1.1436011012719602, disc_loss = 0.0015373622830703753
Trained batch 147 in epoch 6, gen_loss = 1.143680089228862, disc_loss = 0.00153328431573558
Trained batch 148 in epoch 6, gen_loss = 1.1438638331906108, disc_loss = 0.001527977542836069
Trained batch 149 in epoch 6, gen_loss = 1.1430846047401428, disc_loss = 0.001521702443715185
Trained batch 150 in epoch 6, gen_loss = 1.144361252026842, disc_loss = 0.0015207152306379763
Trained batch 151 in epoch 6, gen_loss = 1.1439204953218762, disc_loss = 0.0015189413243206218
Trained batch 152 in epoch 6, gen_loss = 1.1429035842808244, disc_loss = 0.001515965197338826
Trained batch 153 in epoch 6, gen_loss = 1.1447813147074217, disc_loss = 0.00151242674540051
Trained batch 154 in epoch 6, gen_loss = 1.1476663458731866, disc_loss = 0.001510024623524758
Trained batch 155 in epoch 6, gen_loss = 1.1475615723010821, disc_loss = 0.0015079071461700667
Trained batch 156 in epoch 6, gen_loss = 1.1483394742771318, disc_loss = 0.0015022028274656197
Trained batch 157 in epoch 6, gen_loss = 1.149249636674229, disc_loss = 0.0014956510125488467
Trained batch 158 in epoch 6, gen_loss = 1.1489609442416977, disc_loss = 0.0014914516824496757
Trained batch 159 in epoch 6, gen_loss = 1.1485864847898484, disc_loss = 0.0014859372298815289
Trained batch 160 in epoch 6, gen_loss = 1.148283210600385, disc_loss = 0.0014879460061859825
Trained batch 161 in epoch 6, gen_loss = 1.1497821233890675, disc_loss = 0.0014858640109499295
Trained batch 162 in epoch 6, gen_loss = 1.149255095815366, disc_loss = 0.0014901622941294696
Trained batch 163 in epoch 6, gen_loss = 1.1502615147974433, disc_loss = 0.0014851993974156269
Trained batch 164 in epoch 6, gen_loss = 1.1502910960804333, disc_loss = 0.0014827688023532656
Trained batch 165 in epoch 6, gen_loss = 1.1507215744041535, disc_loss = 0.001481226444488436
Trained batch 166 in epoch 6, gen_loss = 1.1514522957944584, disc_loss = 0.0014800214272098404
Trained batch 167 in epoch 6, gen_loss = 1.1516392018113817, disc_loss = 0.0014769869435223796
Trained batch 168 in epoch 6, gen_loss = 1.1516033488617847, disc_loss = 0.0014718678726858773
Trained batch 169 in epoch 6, gen_loss = 1.1513835682588465, disc_loss = 0.0014657032768488588
Trained batch 170 in epoch 6, gen_loss = 1.150820255279541, disc_loss = 0.0014608426731657128
Trained batch 171 in epoch 6, gen_loss = 1.1497955557911894, disc_loss = 0.0014564992933057594
Trained batch 172 in epoch 6, gen_loss = 1.1497399765632057, disc_loss = 0.0014525765379503196
Trained batch 173 in epoch 6, gen_loss = 1.1494409996887733, disc_loss = 0.0014504255819262873
Trained batch 174 in epoch 6, gen_loss = 1.1500922312055315, disc_loss = 0.001446650832492326
Trained batch 175 in epoch 6, gen_loss = 1.1494181460954926, disc_loss = 0.0014408018131772142
Trained batch 176 in epoch 6, gen_loss = 1.1490968438865101, disc_loss = 0.001435123570131843
Trained batch 177 in epoch 6, gen_loss = 1.1486372130640436, disc_loss = 0.0014293985379195322
Trained batch 178 in epoch 6, gen_loss = 1.1485214246717912, disc_loss = 0.0014253672672170292
Trained batch 179 in epoch 6, gen_loss = 1.1489321218596564, disc_loss = 0.0014209910745396175
Trained batch 180 in epoch 6, gen_loss = 1.1491344594165107, disc_loss = 0.0014158041565035834
Trained batch 181 in epoch 6, gen_loss = 1.1485855959273956, disc_loss = 0.0014115183135740214
Trained batch 182 in epoch 6, gen_loss = 1.1471574453056836, disc_loss = 0.0014103412872455159
Trained batch 183 in epoch 6, gen_loss = 1.1479567266676738, disc_loss = 0.0014083868059653628
Trained batch 184 in epoch 6, gen_loss = 1.149138405838528, disc_loss = 0.0014077374315191362
Trained batch 185 in epoch 6, gen_loss = 1.1503404837141755, disc_loss = 0.0014068720504260993
Trained batch 186 in epoch 6, gen_loss = 1.1490864218237566, disc_loss = 0.001410768702277605
Trained batch 187 in epoch 6, gen_loss = 1.1482270886289312, disc_loss = 0.0014092965110977912
Trained batch 188 in epoch 6, gen_loss = 1.1494782116047289, disc_loss = 0.001409357530680835
Trained batch 189 in epoch 6, gen_loss = 1.150825089529941, disc_loss = 0.0014064294022605999
Trained batch 190 in epoch 6, gen_loss = 1.1507524351799052, disc_loss = 0.0014037329698083874
Trained batch 191 in epoch 6, gen_loss = 1.1504469917466242, disc_loss = 0.0013996149740099402
Trained batch 192 in epoch 6, gen_loss = 1.150679904562204, disc_loss = 0.0013972999657132696
Trained batch 193 in epoch 6, gen_loss = 1.1493582873000312, disc_loss = 0.0013990800164054272
Trained batch 194 in epoch 6, gen_loss = 1.1500306740785255, disc_loss = 0.0013965121022640513
Trained batch 195 in epoch 6, gen_loss = 1.1494813184348904, disc_loss = 0.0013935164179016209
Trained batch 196 in epoch 6, gen_loss = 1.1488104108626467, disc_loss = 0.001392653369732428
Trained batch 197 in epoch 6, gen_loss = 1.150227842908917, disc_loss = 0.0013910873594336361
Trained batch 198 in epoch 6, gen_loss = 1.151341798916534, disc_loss = 0.0013886594392555818
Trained batch 199 in epoch 6, gen_loss = 1.1513904434442521, disc_loss = 0.0013880576228257268
Trained batch 200 in epoch 6, gen_loss = 1.1515992363887047, disc_loss = 0.0013854971499557593
Trained batch 201 in epoch 6, gen_loss = 1.1511130610314926, disc_loss = 0.0013827263166676137
Trained batch 202 in epoch 6, gen_loss = 1.151774271955631, disc_loss = 0.0013812183754592033
Trained batch 203 in epoch 6, gen_loss = 1.150648762490235, disc_loss = 0.0013820726553425559
Trained batch 204 in epoch 6, gen_loss = 1.1505750077526744, disc_loss = 0.0013784944352398557
Trained batch 205 in epoch 6, gen_loss = 1.149872534194039, disc_loss = 0.0013769136796009194
Trained batch 206 in epoch 6, gen_loss = 1.1489376915249847, disc_loss = 0.00137383350736916
Trained batch 207 in epoch 6, gen_loss = 1.1481328916091185, disc_loss = 0.00137168061477356
Trained batch 208 in epoch 6, gen_loss = 1.1482365804425838, disc_loss = 0.0013677236052011652
Trained batch 209 in epoch 6, gen_loss = 1.148764453615461, disc_loss = 0.0013635336237105852
Trained batch 210 in epoch 6, gen_loss = 1.148554917195397, disc_loss = 0.0013614577886491785
Trained batch 211 in epoch 6, gen_loss = 1.1486816102603696, disc_loss = 0.0013600722720510468
Trained batch 212 in epoch 6, gen_loss = 1.1487522774459051, disc_loss = 0.0013592384531252314
Trained batch 213 in epoch 6, gen_loss = 1.148275691215123, disc_loss = 0.0013560547130824301
Trained batch 214 in epoch 6, gen_loss = 1.1488121481828912, disc_loss = 0.0013530424031223235
Trained batch 215 in epoch 6, gen_loss = 1.1489381646668468, disc_loss = 0.0013532396172835164
Trained batch 216 in epoch 6, gen_loss = 1.1485211354796239, disc_loss = 0.0013505753052199885
Trained batch 217 in epoch 6, gen_loss = 1.1485402430963079, disc_loss = 0.0013466816332240359
Trained batch 218 in epoch 6, gen_loss = 1.1488165550580307, disc_loss = 0.0013424426812378766
Trained batch 219 in epoch 6, gen_loss = 1.1487056650898673, disc_loss = 0.0013380833062745462
Trained batch 220 in epoch 6, gen_loss = 1.1482917955018817, disc_loss = 0.0013349719724314482
Trained batch 221 in epoch 6, gen_loss = 1.1483517579130225, disc_loss = 0.001331504946941644
Trained batch 222 in epoch 6, gen_loss = 1.148287288276604, disc_loss = 0.0013275757728764713
Trained batch 223 in epoch 6, gen_loss = 1.1481810845434666, disc_loss = 0.0013239307186917618
Trained batch 224 in epoch 6, gen_loss = 1.1493352397282919, disc_loss = 0.0013233102636877447
Trained batch 225 in epoch 6, gen_loss = 1.148241897599887, disc_loss = 0.0013213178898317047
Trained batch 226 in epoch 6, gen_loss = 1.1488646893774361, disc_loss = 0.0013188274290324455
Trained batch 227 in epoch 6, gen_loss = 1.148630608592117, disc_loss = 0.0013159392339028336
Trained batch 228 in epoch 6, gen_loss = 1.1490875664756808, disc_loss = 0.001313767681741176
Trained batch 229 in epoch 6, gen_loss = 1.1485990228860274, disc_loss = 0.001310475088488918
Trained batch 230 in epoch 6, gen_loss = 1.1485345193317957, disc_loss = 0.0013073335765322743
Trained batch 231 in epoch 6, gen_loss = 1.1480450959041202, disc_loss = 0.0013035452019690198
Trained batch 232 in epoch 6, gen_loss = 1.147366408882223, disc_loss = 0.0013005230127376116
Trained batch 233 in epoch 6, gen_loss = 1.1468098629743626, disc_loss = 0.0012972767677000908
Trained batch 234 in epoch 6, gen_loss = 1.1471623895016123, disc_loss = 0.0012960999482063617
Trained batch 235 in epoch 6, gen_loss = 1.146582422367597, disc_loss = 0.0012923911056270175
Trained batch 236 in epoch 6, gen_loss = 1.147161047921402, disc_loss = 0.0012885285805437304
Trained batch 237 in epoch 6, gen_loss = 1.1463143011602033, disc_loss = 0.0012855467085967217
Trained batch 238 in epoch 6, gen_loss = 1.1455632595337584, disc_loss = 0.0012820737611036748
Trained batch 239 in epoch 6, gen_loss = 1.1454879341026147, disc_loss = 0.0012786863353539957
Trained batch 240 in epoch 6, gen_loss = 1.1458975004951983, disc_loss = 0.0012748094281148845
Trained batch 241 in epoch 6, gen_loss = 1.14562563635101, disc_loss = 0.0012716323156284999
Trained batch 242 in epoch 6, gen_loss = 1.1465931986094502, disc_loss = 0.0012685200365963527
Trained batch 243 in epoch 6, gen_loss = 1.1471939221268794, disc_loss = 0.0012659861236957635
Trained batch 244 in epoch 6, gen_loss = 1.1477289430949154, disc_loss = 0.0012650012690811512
Trained batch 245 in epoch 6, gen_loss = 1.1468431423834669, disc_loss = 0.0012699973669397168
Trained batch 246 in epoch 6, gen_loss = 1.146957571448585, disc_loss = 0.0012682801941343723
Trained batch 247 in epoch 6, gen_loss = 1.1472574513285392, disc_loss = 0.0012646358869284496
Trained batch 248 in epoch 6, gen_loss = 1.1469101137425526, disc_loss = 0.0012614108189841337
Trained batch 249 in epoch 6, gen_loss = 1.1468932149410247, disc_loss = 0.0012586806596955285
Trained batch 250 in epoch 6, gen_loss = 1.1482208570636125, disc_loss = 0.0012573598921382465
Trained batch 251 in epoch 6, gen_loss = 1.1488668509419002, disc_loss = 0.0012548024026309288
Trained batch 252 in epoch 6, gen_loss = 1.1487515813748357, disc_loss = 0.0012529969201358808
Trained batch 253 in epoch 6, gen_loss = 1.1488189582280286, disc_loss = 0.0012509831259215954
Trained batch 254 in epoch 6, gen_loss = 1.1492616538907967, disc_loss = 0.0012481413018095363
Trained batch 255 in epoch 6, gen_loss = 1.1493450726848096, disc_loss = 0.0012455260424530934
Trained batch 256 in epoch 6, gen_loss = 1.1485367296734672, disc_loss = 0.0012440225921420867
Trained batch 257 in epoch 6, gen_loss = 1.1474740863308426, disc_loss = 0.0012426876289049857
Trained batch 258 in epoch 6, gen_loss = 1.146994144069642, disc_loss = 0.001240854909257877
Trained batch 259 in epoch 6, gen_loss = 1.1466223077132152, disc_loss = 0.0012391288445752042
Trained batch 260 in epoch 6, gen_loss = 1.1459849586432007, disc_loss = 0.0012362979581513553
Trained batch 261 in epoch 6, gen_loss = 1.145038535121743, disc_loss = 0.0012351081297574708
Trained batch 262 in epoch 6, gen_loss = 1.1443435889686469, disc_loss = 0.001235565147074931
Trained batch 263 in epoch 6, gen_loss = 1.143657982575171, disc_loss = 0.001236053639083614
Trained batch 264 in epoch 6, gen_loss = 1.1437240251954996, disc_loss = 0.0012344155907586991
Trained batch 265 in epoch 6, gen_loss = 1.143929611247285, disc_loss = 0.0012315973598786623
Trained batch 266 in epoch 6, gen_loss = 1.1450597447402469, disc_loss = 0.0012293147886335877
Trained batch 267 in epoch 6, gen_loss = 1.1446372157157356, disc_loss = 0.0012266325858619703
Trained batch 268 in epoch 6, gen_loss = 1.1440811908378035, disc_loss = 0.0012244436397393784
Trained batch 269 in epoch 6, gen_loss = 1.1432765234399724, disc_loss = 0.0012223017074305701
Trained batch 270 in epoch 6, gen_loss = 1.1433016785396422, disc_loss = 0.001218980916249961
Trained batch 271 in epoch 6, gen_loss = 1.1439889632165432, disc_loss = 0.0012162363015223116
Trained batch 272 in epoch 6, gen_loss = 1.144060275275192, disc_loss = 0.0012142691754219173
Trained batch 273 in epoch 6, gen_loss = 1.14351870195709, disc_loss = 0.0012116281787931144
Trained batch 274 in epoch 6, gen_loss = 1.1434244034507057, disc_loss = 0.0012093866168817675
Trained batch 275 in epoch 6, gen_loss = 1.1426514197086943, disc_loss = 0.0012084875257721212
Trained batch 276 in epoch 6, gen_loss = 1.1426990686340883, disc_loss = 0.0012061409913852394
Trained batch 277 in epoch 6, gen_loss = 1.1421213988348735, disc_loss = 0.0012040948720352402
Trained batch 278 in epoch 6, gen_loss = 1.1421746611595154, disc_loss = 0.001201617603559935
Trained batch 279 in epoch 6, gen_loss = 1.1411712765693665, disc_loss = 0.0012114369496495263
Trained batch 280 in epoch 6, gen_loss = 1.141891559672101, disc_loss = 0.0012101983475238682
Trained batch 281 in epoch 6, gen_loss = 1.1422386461115899, disc_loss = 0.0012132422974810387
Trained batch 282 in epoch 6, gen_loss = 1.142808324035402, disc_loss = 0.001211338007946864
Trained batch 283 in epoch 6, gen_loss = 1.1427641515160951, disc_loss = 0.0012090940937001429
Trained batch 284 in epoch 6, gen_loss = 1.1430001631117703, disc_loss = 0.0012086631894609972
Trained batch 285 in epoch 6, gen_loss = 1.1436423384226286, disc_loss = 0.0012059097551338543
Trained batch 286 in epoch 6, gen_loss = 1.143863021704378, disc_loss = 0.0012037697584223884
Trained batch 287 in epoch 6, gen_loss = 1.1436366500953834, disc_loss = 0.0012034538878853912
Trained batch 288 in epoch 6, gen_loss = 1.1440207743727213, disc_loss = 0.0012039755207001455
Trained batch 289 in epoch 6, gen_loss = 1.1442520647213377, disc_loss = 0.0012025845784027578
Trained batch 290 in epoch 6, gen_loss = 1.1445622268001647, disc_loss = 0.0011998000306707784
Trained batch 291 in epoch 6, gen_loss = 1.14443112358655, disc_loss = 0.0011992136974123702
Trained batch 292 in epoch 6, gen_loss = 1.1441316372705401, disc_loss = 0.0011965516932211726
Trained batch 293 in epoch 6, gen_loss = 1.1435924492725709, disc_loss = 0.0011939786656301938
Trained batch 294 in epoch 6, gen_loss = 1.1442769252647789, disc_loss = 0.001194489705751224
Trained batch 295 in epoch 6, gen_loss = 1.1446296218279246, disc_loss = 0.001193132012672691
Trained batch 296 in epoch 6, gen_loss = 1.1441795171711984, disc_loss = 0.0011933081906237123
Trained batch 297 in epoch 6, gen_loss = 1.1445138474438814, disc_loss = 0.0011957323544107114
Trained batch 298 in epoch 6, gen_loss = 1.1458368325313197, disc_loss = 0.0011950373776330235
Trained batch 299 in epoch 6, gen_loss = 1.1461436859766643, disc_loss = 0.0011967828736912148
Trained batch 300 in epoch 6, gen_loss = 1.1468222778896953, disc_loss = 0.0012011128148811242
Trained batch 301 in epoch 6, gen_loss = 1.1464851692022866, disc_loss = 0.0012053578585310722
Trained batch 302 in epoch 6, gen_loss = 1.1464879921954063, disc_loss = 0.0012040624479346727
Trained batch 303 in epoch 6, gen_loss = 1.1460560830800157, disc_loss = 0.0012062181121061592
Trained batch 304 in epoch 6, gen_loss = 1.1466689055083228, disc_loss = 0.0012059443404127035
Trained batch 305 in epoch 6, gen_loss = 1.1461943356819402, disc_loss = 0.0012081817485463616
Trained batch 306 in epoch 6, gen_loss = 1.146392639762804, disc_loss = 0.0012074872745763728
Trained batch 307 in epoch 6, gen_loss = 1.146333538092576, disc_loss = 0.0012060087681604343
Trained batch 308 in epoch 6, gen_loss = 1.1460089023830822, disc_loss = 0.00120446266156989
Trained batch 309 in epoch 6, gen_loss = 1.1465875675601345, disc_loss = 0.0012023015277302493
Trained batch 310 in epoch 6, gen_loss = 1.1470655655170943, disc_loss = 0.0011999387676053504
Trained batch 311 in epoch 6, gen_loss = 1.146201524596948, disc_loss = 0.0011999224409056553
Trained batch 312 in epoch 6, gen_loss = 1.1465132388824852, disc_loss = 0.0011989576592349623
Trained batch 313 in epoch 6, gen_loss = 1.1465923520410137, disc_loss = 0.0011982266848816411
Trained batch 314 in epoch 6, gen_loss = 1.1469401143846059, disc_loss = 0.0011965087843164505
Trained batch 315 in epoch 6, gen_loss = 1.146312467659576, disc_loss = 0.0011947444877535682
Trained batch 316 in epoch 6, gen_loss = 1.1463050312048253, disc_loss = 0.0011919750071832857
Trained batch 317 in epoch 6, gen_loss = 1.1469783314369009, disc_loss = 0.0011893855980758515
Trained batch 318 in epoch 6, gen_loss = 1.1467230323713775, disc_loss = 0.0011868833417881595
Trained batch 319 in epoch 6, gen_loss = 1.1472915451973678, disc_loss = 0.001185387070836441
Trained batch 320 in epoch 6, gen_loss = 1.1473257846178666, disc_loss = 0.001183451663062986
Trained batch 321 in epoch 6, gen_loss = 1.1474312351357123, disc_loss = 0.001181091795283549
Trained batch 322 in epoch 6, gen_loss = 1.1469408349356045, disc_loss = 0.0011787257939735688
Trained batch 323 in epoch 6, gen_loss = 1.1468043126809744, disc_loss = 0.0011779710982443281
Trained batch 324 in epoch 6, gen_loss = 1.1465669659467843, disc_loss = 0.0011773005178054938
Trained batch 325 in epoch 6, gen_loss = 1.146123992701981, disc_loss = 0.0011758104990167897
Trained batch 326 in epoch 6, gen_loss = 1.1464671722245872, disc_loss = 0.00117368229448764
Trained batch 327 in epoch 6, gen_loss = 1.14619711350377, disc_loss = 0.0011718542328020614
Trained batch 328 in epoch 6, gen_loss = 1.1469567302150205, disc_loss = 0.00117157313466358
Trained batch 329 in epoch 6, gen_loss = 1.146590782476194, disc_loss = 0.0011699172977717933
Trained batch 330 in epoch 6, gen_loss = 1.1460232478974448, disc_loss = 0.0011689661265374795
Trained batch 331 in epoch 6, gen_loss = 1.1458442193197917, disc_loss = 0.0011669870087118112
Trained batch 332 in epoch 6, gen_loss = 1.1460108209300686, disc_loss = 0.0011652372447968188
Trained batch 333 in epoch 6, gen_loss = 1.146444953844219, disc_loss = 0.0011629171392909658
Trained batch 334 in epoch 6, gen_loss = 1.1463336973047968, disc_loss = 0.0011609233068754035
Trained batch 335 in epoch 6, gen_loss = 1.1464418023824692, disc_loss = 0.0011586490908528156
Trained batch 336 in epoch 6, gen_loss = 1.1464196588589812, disc_loss = 0.0011566145899491412
Trained batch 337 in epoch 6, gen_loss = 1.146093439773695, disc_loss = 0.0011542644641036994
Trained batch 338 in epoch 6, gen_loss = 1.1457644982323885, disc_loss = 0.0011517335407492213
Trained batch 339 in epoch 6, gen_loss = 1.1453430347582874, disc_loss = 0.0011500724369612083
Trained batch 340 in epoch 6, gen_loss = 1.1451046127727653, disc_loss = 0.0011494494900360014
Trained batch 341 in epoch 6, gen_loss = 1.1461392264617116, disc_loss = 0.001148031891493143
Trained batch 342 in epoch 6, gen_loss = 1.1459917382665696, disc_loss = 0.0011464627891535934
Trained batch 343 in epoch 6, gen_loss = 1.146690440039302, disc_loss = 0.001144377260822884
Trained batch 344 in epoch 6, gen_loss = 1.146492462572844, disc_loss = 0.0011424412472558249
Trained batch 345 in epoch 6, gen_loss = 1.1464963996341462, disc_loss = 0.0011407853262478788
Trained batch 346 in epoch 6, gen_loss = 1.1466398483051004, disc_loss = 0.0011401709588680696
Trained batch 347 in epoch 6, gen_loss = 1.146058035993028, disc_loss = 0.0011398540074627943
Trained batch 348 in epoch 6, gen_loss = 1.1461602767080836, disc_loss = 0.001139036354820316
Trained batch 349 in epoch 6, gen_loss = 1.1468555212020874, disc_loss = 0.0011379123037581198
Trained batch 350 in epoch 6, gen_loss = 1.1469936846328257, disc_loss = 0.0011364957404772663
Trained batch 351 in epoch 6, gen_loss = 1.147242835638198, disc_loss = 0.0011343231670418224
Trained batch 352 in epoch 6, gen_loss = 1.1478804241834213, disc_loss = 0.0011331261811374288
Trained batch 353 in epoch 6, gen_loss = 1.1479674156776256, disc_loss = 0.0011311278071407082
Trained batch 354 in epoch 6, gen_loss = 1.147568491479041, disc_loss = 0.0011294195190741038
Trained batch 355 in epoch 6, gen_loss = 1.1472035174289446, disc_loss = 0.0011294415461624125
Trained batch 356 in epoch 6, gen_loss = 1.14722997367549, disc_loss = 0.0011303987863071846
Trained batch 357 in epoch 6, gen_loss = 1.146956560332016, disc_loss = 0.0011319732054477485
Trained batch 358 in epoch 6, gen_loss = 1.1467693446406415, disc_loss = 0.001131197899900387
Trained batch 359 in epoch 6, gen_loss = 1.1463610572947396, disc_loss = 0.001129280736333587
Trained batch 360 in epoch 6, gen_loss = 1.146149090122318, disc_loss = 0.0011276385770759795
Trained batch 361 in epoch 6, gen_loss = 1.14552708818109, disc_loss = 0.0011262475208698344
Trained batch 362 in epoch 6, gen_loss = 1.1461112449977024, disc_loss = 0.0011248996156747594
Trained batch 363 in epoch 6, gen_loss = 1.1457598602378762, disc_loss = 0.0011231493745171874
Trained batch 364 in epoch 6, gen_loss = 1.145968162850158, disc_loss = 0.0011213235920677854
Trained batch 365 in epoch 6, gen_loss = 1.1458428674708299, disc_loss = 0.0011212626584077793
Trained batch 366 in epoch 6, gen_loss = 1.1463111866397493, disc_loss = 0.001119887164625154
Trained batch 367 in epoch 6, gen_loss = 1.145878657374693, disc_loss = 0.001118420815106694
Trained batch 368 in epoch 6, gen_loss = 1.146216697163052, disc_loss = 0.0011174276450315749
Trained batch 369 in epoch 6, gen_loss = 1.1459650957906569, disc_loss = 0.0011158424863793156
Trained batch 370 in epoch 6, gen_loss = 1.1462766118448058, disc_loss = 0.001114139626053039
Trained batch 371 in epoch 6, gen_loss = 1.1457797260053697, disc_loss = 0.0011126904767000377
Trained batch 372 in epoch 6, gen_loss = 1.1451660540084736, disc_loss = 0.0011111727711119147
Trained batch 373 in epoch 6, gen_loss = 1.145523626058497, disc_loss = 0.001109754653534862
Trained batch 374 in epoch 6, gen_loss = 1.1462947484652202, disc_loss = 0.001108614166189606
Trained batch 375 in epoch 6, gen_loss = 1.1458835831664977, disc_loss = 0.0011079236427712145
Trained batch 376 in epoch 6, gen_loss = 1.1460734474564105, disc_loss = 0.0011068606718760774
Trained batch 377 in epoch 6, gen_loss = 1.1462174633508007, disc_loss = 0.001105647036672087
Trained batch 378 in epoch 6, gen_loss = 1.1460615070954476, disc_loss = 0.0011042716052404073
Trained batch 379 in epoch 6, gen_loss = 1.1460022143627469, disc_loss = 0.0011026290878745433
Trained batch 380 in epoch 6, gen_loss = 1.1460967575471233, disc_loss = 0.0011008431345286714
Trained batch 381 in epoch 6, gen_loss = 1.1466838225956362, disc_loss = 0.001099148543651523
Trained batch 382 in epoch 6, gen_loss = 1.1463206503783443, disc_loss = 0.0010985526600949874
Trained batch 383 in epoch 6, gen_loss = 1.1470779992329578, disc_loss = 0.0010975316560385788
Trained batch 384 in epoch 6, gen_loss = 1.1466101465287146, disc_loss = 0.0010980135576751132
Trained batch 385 in epoch 6, gen_loss = 1.146703771822193, disc_loss = 0.001098597263905263
Trained batch 386 in epoch 6, gen_loss = 1.146874899858036, disc_loss = 0.0010972134950955805
Trained batch 387 in epoch 6, gen_loss = 1.1475020421227229, disc_loss = 0.0010954547912295255
Trained batch 388 in epoch 6, gen_loss = 1.1471587025720846, disc_loss = 0.0010940752807372563
Trained batch 389 in epoch 6, gen_loss = 1.1473894279736738, disc_loss = 0.0010922004902311482
Trained batch 390 in epoch 6, gen_loss = 1.1473789381249178, disc_loss = 0.0010903769933000502
Trained batch 391 in epoch 6, gen_loss = 1.1475774185085783, disc_loss = 0.0010888894550812344
Trained batch 392 in epoch 6, gen_loss = 1.1471841148747743, disc_loss = 0.0010872199178617638
Trained batch 393 in epoch 6, gen_loss = 1.1466830141350703, disc_loss = 0.001086016566812316
Trained batch 394 in epoch 6, gen_loss = 1.1464533143405673, disc_loss = 0.0010841778392573418
Trained batch 395 in epoch 6, gen_loss = 1.1469723764393065, disc_loss = 0.00108381756743054
Trained batch 396 in epoch 6, gen_loss = 1.1470954266543352, disc_loss = 0.00108256489721711
Trained batch 397 in epoch 6, gen_loss = 1.146824945906299, disc_loss = 0.0010810613045884277
Trained batch 398 in epoch 6, gen_loss = 1.1469204224141918, disc_loss = 0.0010793875854895369
Trained batch 399 in epoch 6, gen_loss = 1.1468321622908115, disc_loss = 0.001077716241197777
Trained batch 400 in epoch 6, gen_loss = 1.1466037788593264, disc_loss = 0.0010764485663017885
Trained batch 401 in epoch 6, gen_loss = 1.1472869866819524, disc_loss = 0.0010746965678269738
Trained batch 402 in epoch 6, gen_loss = 1.147656733137798, disc_loss = 0.001072935247851568
Trained batch 403 in epoch 6, gen_loss = 1.1485896392328905, disc_loss = 0.0010714077463922192
Trained batch 404 in epoch 6, gen_loss = 1.1484179842619249, disc_loss = 0.0010702965827083881
Trained batch 405 in epoch 6, gen_loss = 1.1486063530586037, disc_loss = 0.0010684628516729243
Trained batch 406 in epoch 6, gen_loss = 1.1487171800775082, disc_loss = 0.0010668156396526688
Trained batch 407 in epoch 6, gen_loss = 1.1486522112699116, disc_loss = 0.0010650305995630904
Trained batch 408 in epoch 6, gen_loss = 1.1487440679650436, disc_loss = 0.0010634522165244669
Trained batch 409 in epoch 6, gen_loss = 1.1483027400040045, disc_loss = 0.0010617331599549777
Trained batch 410 in epoch 6, gen_loss = 1.147944737524882, disc_loss = 0.001060057985494389
Trained batch 411 in epoch 6, gen_loss = 1.1478609850684416, disc_loss = 0.0010585038911707211
Trained batch 412 in epoch 6, gen_loss = 1.1484004155198253, disc_loss = 0.0010588948549217934
Trained batch 413 in epoch 6, gen_loss = 1.1482777065700955, disc_loss = 0.0010591190630864747
Trained batch 414 in epoch 6, gen_loss = 1.1480887645698457, disc_loss = 0.0010580055383370673
Trained batch 415 in epoch 6, gen_loss = 1.1481483578681946, disc_loss = 0.0010566089222265873
Trained batch 416 in epoch 6, gen_loss = 1.1482309260242562, disc_loss = 0.0010556591842468713
Trained batch 417 in epoch 6, gen_loss = 1.1482010221367247, disc_loss = 0.0010555417865401125
Trained batch 418 in epoch 6, gen_loss = 1.148143961207679, disc_loss = 0.0010542901062522182
Trained batch 419 in epoch 6, gen_loss = 1.1481130494957879, disc_loss = 0.0010525142675587198
Trained batch 420 in epoch 6, gen_loss = 1.1477521626796405, disc_loss = 0.001052156635067888
Trained batch 421 in epoch 6, gen_loss = 1.147979736893098, disc_loss = 0.001051755985758219
Trained batch 422 in epoch 6, gen_loss = 1.1476495716870536, disc_loss = 0.0010508568591414014
Trained batch 423 in epoch 6, gen_loss = 1.1474345548535294, disc_loss = 0.0010493902471284426
Trained batch 424 in epoch 6, gen_loss = 1.1476217777588789, disc_loss = 0.0010484997565885458
Trained batch 425 in epoch 6, gen_loss = 1.1472063021200922, disc_loss = 0.0010469799610991644
Trained batch 426 in epoch 6, gen_loss = 1.147360664480464, disc_loss = 0.0010452970342472877
Trained batch 427 in epoch 6, gen_loss = 1.147564349748264, disc_loss = 0.0010438007031943841
Trained batch 428 in epoch 6, gen_loss = 1.1475448990479493, disc_loss = 0.0010422355348042413
Trained batch 429 in epoch 6, gen_loss = 1.1480094012825988, disc_loss = 0.001040595148007797
Trained batch 430 in epoch 6, gen_loss = 1.147720324329323, disc_loss = 0.0010391446997318633
Trained batch 431 in epoch 6, gen_loss = 1.1479025385170072, disc_loss = 0.0010378654758959008
Trained batch 432 in epoch 6, gen_loss = 1.1482475028302324, disc_loss = 0.0010360126186261173
Trained batch 433 in epoch 6, gen_loss = 1.1480930437964778, disc_loss = 0.0010345242425320834
Trained batch 434 in epoch 6, gen_loss = 1.1478684029359927, disc_loss = 0.0010332361568868075
Trained batch 435 in epoch 6, gen_loss = 1.1477466899594035, disc_loss = 0.0010319175521753422
Trained batch 436 in epoch 6, gen_loss = 1.1476676255396356, disc_loss = 0.0010309937163373323
Trained batch 437 in epoch 6, gen_loss = 1.1480450484578468, disc_loss = 0.0010297054644290264
Trained batch 438 in epoch 6, gen_loss = 1.1478477416386095, disc_loss = 0.0010282030265596918
Trained batch 439 in epoch 6, gen_loss = 1.147996330938556, disc_loss = 0.0010264735187361525
Trained batch 440 in epoch 6, gen_loss = 1.1480802296240584, disc_loss = 0.0010255047654978036
Trained batch 441 in epoch 6, gen_loss = 1.1480477825818558, disc_loss = 0.0010238025224598006
Trained batch 442 in epoch 6, gen_loss = 1.1480711853261996, disc_loss = 0.0010220539115834981
Trained batch 443 in epoch 6, gen_loss = 1.1477599816547859, disc_loss = 0.0010204948845418036
Trained batch 444 in epoch 6, gen_loss = 1.1475150613302596, disc_loss = 0.0010194042596829993
Trained batch 445 in epoch 6, gen_loss = 1.1475115973051353, disc_loss = 0.0010187063738651525
Trained batch 446 in epoch 6, gen_loss = 1.1476578188422542, disc_loss = 0.00101910545363068
Trained batch 447 in epoch 6, gen_loss = 1.1477230764659387, disc_loss = 0.0010202591000571764
Trained batch 448 in epoch 6, gen_loss = 1.147558214802519, disc_loss = 0.001019274300863481
Trained batch 449 in epoch 6, gen_loss = 1.1479128131601546, disc_loss = 0.001018082917564445
Trained batch 450 in epoch 6, gen_loss = 1.1480074931935567, disc_loss = 0.0010165004492035247
Trained batch 451 in epoch 6, gen_loss = 1.1475827283827604, disc_loss = 0.00101543069068668
Trained batch 452 in epoch 6, gen_loss = 1.1476209662344807, disc_loss = 0.0010149151868820109
Trained batch 453 in epoch 6, gen_loss = 1.1477513448519854, disc_loss = 0.0010137488596404939
Trained batch 454 in epoch 6, gen_loss = 1.1482105209277227, disc_loss = 0.0010125443589448888
Trained batch 455 in epoch 6, gen_loss = 1.1484083278398765, disc_loss = 0.0010111207601878785
Trained batch 456 in epoch 6, gen_loss = 1.1486993139890926, disc_loss = 0.0010097900242366394
Trained batch 457 in epoch 6, gen_loss = 1.1490683517862095, disc_loss = 0.0010084095013843377
Trained batch 458 in epoch 6, gen_loss = 1.149394027418041, disc_loss = 0.0010068892746172594
Trained batch 459 in epoch 6, gen_loss = 1.1490764214940694, disc_loss = 0.0010067916479665259
Trained batch 460 in epoch 6, gen_loss = 1.1494380666221817, disc_loss = 0.001005642831796748
Trained batch 461 in epoch 6, gen_loss = 1.149005557035471, disc_loss = 0.0010050433300192634
Trained batch 462 in epoch 6, gen_loss = 1.1487306899694851, disc_loss = 0.001003741255013944
Trained batch 463 in epoch 6, gen_loss = 1.1486778115404064, disc_loss = 0.0010025906185860392
Trained batch 464 in epoch 6, gen_loss = 1.1486207767199446, disc_loss = 0.0010012463194578485
Trained batch 465 in epoch 6, gen_loss = 1.1487083128081883, disc_loss = 0.0009997421988014277
Trained batch 466 in epoch 6, gen_loss = 1.1483318233898416, disc_loss = 0.000998506726217466
Trained batch 467 in epoch 6, gen_loss = 1.1480278339650896, disc_loss = 0.0009972757512343347
Trained batch 468 in epoch 6, gen_loss = 1.1479515170237657, disc_loss = 0.0009960194750289833
Trained batch 469 in epoch 6, gen_loss = 1.1475653951472424, disc_loss = 0.0009949221678246605
Trained batch 470 in epoch 6, gen_loss = 1.148221286112589, disc_loss = 0.0009939443273568672
Trained batch 471 in epoch 6, gen_loss = 1.148351541136281, disc_loss = 0.0009927707594785823
Trained batch 472 in epoch 6, gen_loss = 1.1482350275582038, disc_loss = 0.0009919141489868673
Trained batch 473 in epoch 6, gen_loss = 1.1483947140506552, disc_loss = 0.0009911915094332321
Trained batch 474 in epoch 6, gen_loss = 1.1486670156529075, disc_loss = 0.000989746091041812
Trained batch 475 in epoch 6, gen_loss = 1.148341301734708, disc_loss = 0.0009886584441058197
Trained batch 476 in epoch 6, gen_loss = 1.1486564193631619, disc_loss = 0.0009877856284383863
Trained batch 477 in epoch 6, gen_loss = 1.1487892313731765, disc_loss = 0.0009869207433477495
Trained batch 478 in epoch 6, gen_loss = 1.1487329077123352, disc_loss = 0.000985599673240852
Trained batch 479 in epoch 6, gen_loss = 1.149212522432208, disc_loss = 0.0009844552941406922
Trained batch 480 in epoch 6, gen_loss = 1.149141395538116, disc_loss = 0.0009830800730254881
Trained batch 481 in epoch 6, gen_loss = 1.1492656463162039, disc_loss = 0.0009819981305743085
Trained batch 482 in epoch 6, gen_loss = 1.1487339224134172, disc_loss = 0.0009808466685636984
Trained batch 483 in epoch 6, gen_loss = 1.1487951411688624, disc_loss = 0.000979369528488687
Trained batch 484 in epoch 6, gen_loss = 1.148700447426629, disc_loss = 0.000978014208424414
Trained batch 485 in epoch 6, gen_loss = 1.1489523141472429, disc_loss = 0.000976602691850901
Trained batch 486 in epoch 6, gen_loss = 1.1486893216687306, disc_loss = 0.0009753446824857258
Trained batch 487 in epoch 6, gen_loss = 1.1489106082036846, disc_loss = 0.0009739292395128449
Trained batch 488 in epoch 6, gen_loss = 1.1487619596512528, disc_loss = 0.0009725853607462289
Trained batch 489 in epoch 6, gen_loss = 1.1485684664881959, disc_loss = 0.0009710438977166706
Trained batch 490 in epoch 6, gen_loss = 1.1487940690667955, disc_loss = 0.000970045491923102
Trained batch 491 in epoch 6, gen_loss = 1.1483668079221152, disc_loss = 0.0009696189785230435
Trained batch 492 in epoch 6, gen_loss = 1.148362421360751, disc_loss = 0.0009685339045788315
Trained batch 493 in epoch 6, gen_loss = 1.1479337530338813, disc_loss = 0.0009687022206577122
Trained batch 494 in epoch 6, gen_loss = 1.1475389874342716, disc_loss = 0.0009676767435545723
Trained batch 495 in epoch 6, gen_loss = 1.1471566744148731, disc_loss = 0.000966497881182154
Trained batch 496 in epoch 6, gen_loss = 1.1473643596263479, disc_loss = 0.0009654492267006465
Trained batch 497 in epoch 6, gen_loss = 1.1472334566125908, disc_loss = 0.0009641071358867677
Trained batch 498 in epoch 6, gen_loss = 1.1468636336211928, disc_loss = 0.0009628049960455116
Trained batch 499 in epoch 6, gen_loss = 1.1468508697748183, disc_loss = 0.0009614093559794128
Trained batch 500 in epoch 6, gen_loss = 1.1466815479977164, disc_loss = 0.0009599644161829122
Trained batch 501 in epoch 6, gen_loss = 1.1465073836989612, disc_loss = 0.0009588843296582075
Trained batch 502 in epoch 6, gen_loss = 1.146837906026935, disc_loss = 0.000957635867694776
Trained batch 503 in epoch 6, gen_loss = 1.1465689604954115, disc_loss = 0.0009563798848541901
Trained batch 504 in epoch 6, gen_loss = 1.146430765166141, disc_loss = 0.0009549864059795929
Trained batch 505 in epoch 6, gen_loss = 1.1465703287850255, disc_loss = 0.0009543274123722728
Trained batch 506 in epoch 6, gen_loss = 1.1464542904078843, disc_loss = 0.0009533842321849453
Trained batch 507 in epoch 6, gen_loss = 1.146307264843325, disc_loss = 0.000952379067819593
Trained batch 508 in epoch 6, gen_loss = 1.1468082149979641, disc_loss = 0.0009516358420091328
Trained batch 509 in epoch 6, gen_loss = 1.1465141209901548, disc_loss = 0.0009518309701496608
Trained batch 510 in epoch 6, gen_loss = 1.1462856633789151, disc_loss = 0.0009513456303953902
Trained batch 511 in epoch 6, gen_loss = 1.146600715117529, disc_loss = 0.0009502032392845194
Trained batch 512 in epoch 6, gen_loss = 1.1471908870961, disc_loss = 0.0009492638671634988
Trained batch 513 in epoch 6, gen_loss = 1.147317000864081, disc_loss = 0.0009479117831444016
Trained batch 514 in epoch 6, gen_loss = 1.1473175076605047, disc_loss = 0.0009470332362203072
Trained batch 515 in epoch 6, gen_loss = 1.1472155805244002, disc_loss = 0.0009460335856228218
Trained batch 516 in epoch 6, gen_loss = 1.1470350024778562, disc_loss = 0.0009451118733081336
Trained batch 517 in epoch 6, gen_loss = 1.1472545388122324, disc_loss = 0.0009441488832547725
Trained batch 518 in epoch 6, gen_loss = 1.1473373108057159, disc_loss = 0.0009431975093405059
Trained batch 519 in epoch 6, gen_loss = 1.1471305906772613, disc_loss = 0.000942215901299138
Trained batch 520 in epoch 6, gen_loss = 1.1472045887912303, disc_loss = 0.0009408468243877373
Trained batch 521 in epoch 6, gen_loss = 1.14750076938863, disc_loss = 0.000939627111414617
Trained batch 522 in epoch 6, gen_loss = 1.1472703070303223, disc_loss = 0.0009384723705469754
Trained batch 523 in epoch 6, gen_loss = 1.147150145459721, disc_loss = 0.0009375128605172398
Trained batch 524 in epoch 6, gen_loss = 1.1468212631770542, disc_loss = 0.000936386547012565
Trained batch 525 in epoch 6, gen_loss = 1.1469943020280322, disc_loss = 0.0009352911269292678
Trained batch 526 in epoch 6, gen_loss = 1.147332209563572, disc_loss = 0.0009342508646626418
Trained batch 527 in epoch 6, gen_loss = 1.1475638458223054, disc_loss = 0.0009333805343858055
Trained batch 528 in epoch 6, gen_loss = 1.1477616459750948, disc_loss = 0.0009321874550982539
Trained batch 529 in epoch 6, gen_loss = 1.1476927086992084, disc_loss = 0.0009310250625482163
Trained batch 530 in epoch 6, gen_loss = 1.147509287530644, disc_loss = 0.0009302352741722406
Trained batch 531 in epoch 6, gen_loss = 1.1471659661011588, disc_loss = 0.000929414944052985
Trained batch 532 in epoch 6, gen_loss = 1.1467134674091948, disc_loss = 0.0009287667056289196
Trained batch 533 in epoch 6, gen_loss = 1.1463323930899303, disc_loss = 0.000929361082747978
Trained batch 534 in epoch 6, gen_loss = 1.1463751103276405, disc_loss = 0.0009306165724002678
Trained batch 535 in epoch 6, gen_loss = 1.1464430875520208, disc_loss = 0.0009312116168319932
Trained batch 536 in epoch 6, gen_loss = 1.146644919389231, disc_loss = 0.0009306368718127108
Trained batch 537 in epoch 6, gen_loss = 1.146357288037091, disc_loss = 0.0009295327257467555
Trained batch 538 in epoch 6, gen_loss = 1.1462643331189766, disc_loss = 0.0009284889054061769
Trained batch 539 in epoch 6, gen_loss = 1.1463050218643966, disc_loss = 0.0009272109980951494
Trained batch 540 in epoch 6, gen_loss = 1.1463774591408904, disc_loss = 0.0009259007068347898
Trained batch 541 in epoch 6, gen_loss = 1.146726779942143, disc_loss = 0.0009250425158476206
Trained batch 542 in epoch 6, gen_loss = 1.1466751822011467, disc_loss = 0.0009246228593643874
Trained batch 543 in epoch 6, gen_loss = 1.146772404694382, disc_loss = 0.0009245176141602689
Trained batch 544 in epoch 6, gen_loss = 1.146435046961548, disc_loss = 0.0009242926406249011
Trained batch 545 in epoch 6, gen_loss = 1.14612911428724, disc_loss = 0.0009233419072181891
Trained batch 546 in epoch 6, gen_loss = 1.1461860983201746, disc_loss = 0.0009221459595093646
Trained batch 547 in epoch 6, gen_loss = 1.1461945987530868, disc_loss = 0.0009215169356650262
Trained batch 548 in epoch 6, gen_loss = 1.145955727834302, disc_loss = 0.0009205697053919999
Trained batch 549 in epoch 6, gen_loss = 1.146134231524034, disc_loss = 0.0009195027751477689
Trained batch 550 in epoch 6, gen_loss = 1.1460164668555701, disc_loss = 0.0009183469476964673
Trained batch 551 in epoch 6, gen_loss = 1.145907359926597, disc_loss = 0.0009172043285787737
Trained batch 552 in epoch 6, gen_loss = 1.1456372190340949, disc_loss = 0.00091621231042572
Trained batch 553 in epoch 6, gen_loss = 1.1456680833647828, disc_loss = 0.0009152211201541539
Trained batch 554 in epoch 6, gen_loss = 1.1455236205109605, disc_loss = 0.0009141365143518711
Trained batch 555 in epoch 6, gen_loss = 1.145151252047621, disc_loss = 0.000913190988926577
Trained batch 556 in epoch 6, gen_loss = 1.1453721571439472, disc_loss = 0.0009119628288892233
Trained batch 557 in epoch 6, gen_loss = 1.1452935524952454, disc_loss = 0.0009107580507553006
Trained batch 558 in epoch 6, gen_loss = 1.1449216188386429, disc_loss = 0.0009095976801842371
Trained batch 559 in epoch 6, gen_loss = 1.145005366419043, disc_loss = 0.0009085122028149531
Trained batch 560 in epoch 6, gen_loss = 1.1452370627041168, disc_loss = 0.0009073168847588706
Trained batch 561 in epoch 6, gen_loss = 1.145591227609492, disc_loss = 0.0009061656455224334
Trained batch 562 in epoch 6, gen_loss = 1.14557992988539, disc_loss = 0.0009050887566246754
Trained batch 563 in epoch 6, gen_loss = 1.1453515500464337, disc_loss = 0.0009039508987751505
Trained batch 564 in epoch 6, gen_loss = 1.1455663560766034, disc_loss = 0.0009029229480641342
Trained batch 565 in epoch 6, gen_loss = 1.1453477677102646, disc_loss = 0.000901866289984448
Trained batch 566 in epoch 6, gen_loss = 1.1451740468830869, disc_loss = 0.0009010169823240074
Trained batch 567 in epoch 6, gen_loss = 1.1450596294352706, disc_loss = 0.000900051137493943
Trained batch 568 in epoch 6, gen_loss = 1.1451044063786002, disc_loss = 0.0008990203259759934
Trained batch 569 in epoch 6, gen_loss = 1.1449517432012055, disc_loss = 0.0008980155808099529
Trained batch 570 in epoch 6, gen_loss = 1.1448385594396373, disc_loss = 0.0008972272534378447
Trained batch 571 in epoch 6, gen_loss = 1.1448036682355653, disc_loss = 0.0008971123744276111
Trained batch 572 in epoch 6, gen_loss = 1.144605351160126, disc_loss = 0.0008970251882669839
Trained batch 573 in epoch 6, gen_loss = 1.1443936642038697, disc_loss = 0.0008959444149483307
Trained batch 574 in epoch 6, gen_loss = 1.144267410610033, disc_loss = 0.0008948982956454805
Trained batch 575 in epoch 6, gen_loss = 1.14436993892822, disc_loss = 0.0008940334011842626
Trained batch 576 in epoch 6, gen_loss = 1.1443075846551403, disc_loss = 0.0008938143941157366
Trained batch 577 in epoch 6, gen_loss = 1.1441660346044389, disc_loss = 0.0008939558421189101
Trained batch 578 in epoch 6, gen_loss = 1.1441475062378537, disc_loss = 0.0008939819512784236
Trained batch 579 in epoch 6, gen_loss = 1.1442060246549803, disc_loss = 0.0008932849179535847
Trained batch 580 in epoch 6, gen_loss = 1.144378795065691, disc_loss = 0.0008921648234228336
Trained batch 581 in epoch 6, gen_loss = 1.1441955115786941, disc_loss = 0.0008915140394751891
Trained batch 582 in epoch 6, gen_loss = 1.144297186342766, disc_loss = 0.0008908625661976968
Trained batch 583 in epoch 6, gen_loss = 1.1447390264844242, disc_loss = 0.0008900376083209715
Trained batch 584 in epoch 6, gen_loss = 1.1451177682632054, disc_loss = 0.0008890567390192459
Trained batch 585 in epoch 6, gen_loss = 1.1451277684026204, disc_loss = 0.0008881240219963276
Trained batch 586 in epoch 6, gen_loss = 1.1450481463534665, disc_loss = 0.0008869933360990048
Trained batch 587 in epoch 6, gen_loss = 1.1450310158891743, disc_loss = 0.0008859306475964096
Trained batch 588 in epoch 6, gen_loss = 1.1450332809992274, disc_loss = 0.000884671755615742
Trained batch 589 in epoch 6, gen_loss = 1.144791335574651, disc_loss = 0.0008835577810483085
Trained batch 590 in epoch 6, gen_loss = 1.14431748837989, disc_loss = 0.0008830261083245718
Trained batch 591 in epoch 6, gen_loss = 1.1443086425597604, disc_loss = 0.0008823896129576275
Trained batch 592 in epoch 6, gen_loss = 1.1443649474123074, disc_loss = 0.0008817981953322762
Trained batch 593 in epoch 6, gen_loss = 1.1443415524983647, disc_loss = 0.0008808876427363993
Trained batch 594 in epoch 6, gen_loss = 1.1447839033703844, disc_loss = 0.0008799627790630584
Trained batch 595 in epoch 6, gen_loss = 1.144852017596264, disc_loss = 0.0008788779545430838
Trained batch 596 in epoch 6, gen_loss = 1.144436086442203, disc_loss = 0.0008781651109831417
Trained batch 597 in epoch 6, gen_loss = 1.1446101601705903, disc_loss = 0.0008779054322283104
Trained batch 598 in epoch 6, gen_loss = 1.1448331649394983, disc_loss = 0.0008778046392516944
Trained batch 599 in epoch 6, gen_loss = 1.1446244261662166, disc_loss = 0.0008770559491434445
Trained batch 600 in epoch 6, gen_loss = 1.1444819995051811, disc_loss = 0.0008759064513044401
Trained batch 601 in epoch 6, gen_loss = 1.1440283572951029, disc_loss = 0.0008751500849803504
Trained batch 602 in epoch 6, gen_loss = 1.144373129454023, disc_loss = 0.0008743156563476343
Trained batch 603 in epoch 6, gen_loss = 1.1445770954454182, disc_loss = 0.0008733084205654064
Trained batch 604 in epoch 6, gen_loss = 1.1444877325010694, disc_loss = 0.0008722483854661965
Trained batch 605 in epoch 6, gen_loss = 1.1445200667522921, disc_loss = 0.0008712171799710356
Trained batch 606 in epoch 6, gen_loss = 1.144304424377014, disc_loss = 0.0008704021233458093
Trained batch 607 in epoch 6, gen_loss = 1.144360700720235, disc_loss = 0.0008694483476813874
Trained batch 608 in epoch 6, gen_loss = 1.1442429271629095, disc_loss = 0.0008685943107466689
Trained batch 609 in epoch 6, gen_loss = 1.1440586910873163, disc_loss = 0.0008676321169630563
Trained batch 610 in epoch 6, gen_loss = 1.1439655033929452, disc_loss = 0.0008666517418333285
Trained batch 611 in epoch 6, gen_loss = 1.1436398644852483, disc_loss = 0.0008655680728516255
Trained batch 612 in epoch 6, gen_loss = 1.1431673123435913, disc_loss = 0.0008695307214323547
Trained batch 613 in epoch 6, gen_loss = 1.1428755381014137, disc_loss = 0.0008709889621222059
Trained batch 614 in epoch 6, gen_loss = 1.1426666842243536, disc_loss = 0.000870414190865084
Trained batch 615 in epoch 6, gen_loss = 1.1428506572718744, disc_loss = 0.0008697466245949171
Trained batch 616 in epoch 6, gen_loss = 1.1425292255233135, disc_loss = 0.000869361394197443
Trained batch 617 in epoch 6, gen_loss = 1.1424053296880814, disc_loss = 0.0008688078048672153
Trained batch 618 in epoch 6, gen_loss = 1.1423915816239278, disc_loss = 0.0008681791084416072
Trained batch 619 in epoch 6, gen_loss = 1.1423480823155372, disc_loss = 0.000868499637046273
Trained batch 620 in epoch 6, gen_loss = 1.1423065755486297, disc_loss = 0.0008684819053476841
Trained batch 621 in epoch 6, gen_loss = 1.1421740814995536, disc_loss = 0.0008678159707280511
Trained batch 622 in epoch 6, gen_loss = 1.1421278563012665, disc_loss = 0.0008671486296729868
Trained batch 623 in epoch 6, gen_loss = 1.141847044802629, disc_loss = 0.0008668098220928536
Trained batch 624 in epoch 6, gen_loss = 1.1417749210357666, disc_loss = 0.0008661604101303965
Trained batch 625 in epoch 6, gen_loss = 1.1416965523086036, disc_loss = 0.0008654518906245032
Trained batch 626 in epoch 6, gen_loss = 1.1414980534731487, disc_loss = 0.0008644702346910807
Trained batch 627 in epoch 6, gen_loss = 1.141758692682169, disc_loss = 0.0008635784657471842
Trained batch 628 in epoch 6, gen_loss = 1.1418132435157302, disc_loss = 0.0008626928823572156
Trained batch 629 in epoch 6, gen_loss = 1.1417363675813825, disc_loss = 0.0008618645342288627
Trained batch 630 in epoch 6, gen_loss = 1.1418157455093698, disc_loss = 0.0008609944775279186
Trained batch 631 in epoch 6, gen_loss = 1.141662223052375, disc_loss = 0.0008601389361248511
Trained batch 632 in epoch 6, gen_loss = 1.141736698376624, disc_loss = 0.0008591886557470183
Trained batch 633 in epoch 6, gen_loss = 1.1414162265577528, disc_loss = 0.0008584468592709659
Trained batch 634 in epoch 6, gen_loss = 1.141631312163796, disc_loss = 0.0008576533826816035
Trained batch 635 in epoch 6, gen_loss = 1.1413857514190975, disc_loss = 0.0008567288196162444
Trained batch 636 in epoch 6, gen_loss = 1.1414984066969185, disc_loss = 0.0008557284558296066
Trained batch 637 in epoch 6, gen_loss = 1.1415684930396304, disc_loss = 0.0008545784980682167
Trained batch 638 in epoch 6, gen_loss = 1.1416588130877798, disc_loss = 0.0008536622337148895
Trained batch 639 in epoch 6, gen_loss = 1.1412974706850947, disc_loss = 0.0008529688013936721
Trained batch 640 in epoch 6, gen_loss = 1.1413220720432478, disc_loss = 0.0008521054868497189
Trained batch 641 in epoch 6, gen_loss = 1.1413089979289106, disc_loss = 0.0008511067877928516
Trained batch 642 in epoch 6, gen_loss = 1.1410823518158304, disc_loss = 0.000850052001380849
Trained batch 643 in epoch 6, gen_loss = 1.1408460412336432, disc_loss = 0.000849285422061387
Trained batch 644 in epoch 6, gen_loss = 1.1408254693644915, disc_loss = 0.0008484762473651858
Trained batch 645 in epoch 6, gen_loss = 1.1405624357908504, disc_loss = 0.0008475978338481655
Trained batch 646 in epoch 6, gen_loss = 1.1406400795145049, disc_loss = 0.0008468319774889444
Trained batch 647 in epoch 6, gen_loss = 1.1405950878505353, disc_loss = 0.0008463852049833714
Trained batch 648 in epoch 6, gen_loss = 1.1405421440333174, disc_loss = 0.0008460812414299449
Trained batch 649 in epoch 6, gen_loss = 1.1411093060786908, disc_loss = 0.0008457589640546268
Trained batch 650 in epoch 6, gen_loss = 1.1412811244504608, disc_loss = 0.0008451474061715574
Trained batch 651 in epoch 6, gen_loss = 1.1411847393571233, disc_loss = 0.0008442403062526529
Trained batch 652 in epoch 6, gen_loss = 1.141197973699701, disc_loss = 0.0008432311175142738
Trained batch 653 in epoch 6, gen_loss = 1.1412245370561558, disc_loss = 0.0008424862344966972
Trained batch 654 in epoch 6, gen_loss = 1.141320824441109, disc_loss = 0.0008413955816205499
Trained batch 655 in epoch 6, gen_loss = 1.1413077056044485, disc_loss = 0.0008405352923546161
Trained batch 656 in epoch 6, gen_loss = 1.141482993710894, disc_loss = 0.0008396528440713138
Trained batch 657 in epoch 6, gen_loss = 1.1411110010552914, disc_loss = 0.0008390494109987526
Trained batch 658 in epoch 6, gen_loss = 1.1413375542630555, disc_loss = 0.0008384573035385023
Trained batch 659 in epoch 6, gen_loss = 1.1420934955279032, disc_loss = 0.00083805407712961
Trained batch 660 in epoch 6, gen_loss = 1.1419594733329115, disc_loss = 0.0008375408122422203
Trained batch 661 in epoch 6, gen_loss = 1.1420146594234823, disc_loss = 0.0008368660502565365
Trained batch 662 in epoch 6, gen_loss = 1.1419735812493579, disc_loss = 0.0008360687950021113
Trained batch 663 in epoch 6, gen_loss = 1.141871240304177, disc_loss = 0.0008350873413401571
Trained batch 664 in epoch 6, gen_loss = 1.1416682180605437, disc_loss = 0.0008343067538685557
Trained batch 665 in epoch 6, gen_loss = 1.141846423929518, disc_loss = 0.000833316821170682
Trained batch 666 in epoch 6, gen_loss = 1.1421071423226032, disc_loss = 0.0008324901077133112
Trained batch 667 in epoch 6, gen_loss = 1.1422027958010486, disc_loss = 0.000831531071395409
Trained batch 668 in epoch 6, gen_loss = 1.1421506395967196, disc_loss = 0.0008306377843924261
Trained batch 669 in epoch 6, gen_loss = 1.1420147876241313, disc_loss = 0.0008297324170503564
Trained batch 670 in epoch 6, gen_loss = 1.1420446733781726, disc_loss = 0.0008288602596238199
Trained batch 671 in epoch 6, gen_loss = 1.1419970797640937, disc_loss = 0.0008279447814792158
Trained batch 672 in epoch 6, gen_loss = 1.1426038816460529, disc_loss = 0.0008270188411207348
Trained batch 673 in epoch 6, gen_loss = 1.1427086487368237, disc_loss = 0.0008261981069699147
Trained batch 674 in epoch 6, gen_loss = 1.1424690923867402, disc_loss = 0.00082533645004905
Trained batch 675 in epoch 6, gen_loss = 1.142218238679615, disc_loss = 0.000824516633312034
Trained batch 676 in epoch 6, gen_loss = 1.1421662255615392, disc_loss = 0.0008236985983303129
Trained batch 677 in epoch 6, gen_loss = 1.142086960748937, disc_loss = 0.0008227585058086338
Trained batch 678 in epoch 6, gen_loss = 1.1419592965860605, disc_loss = 0.0008217865830690762
Trained batch 679 in epoch 6, gen_loss = 1.142299579346881, disc_loss = 0.0008209380249836079
Trained batch 680 in epoch 6, gen_loss = 1.1420797990107152, disc_loss = 0.0008201238194812348
Trained batch 681 in epoch 6, gen_loss = 1.1424977968165602, disc_loss = 0.0008195881681815315
Trained batch 682 in epoch 6, gen_loss = 1.1424133184190026, disc_loss = 0.0008192736941334685
Trained batch 683 in epoch 6, gen_loss = 1.1421446806331823, disc_loss = 0.0008188882459906285
Trained batch 684 in epoch 6, gen_loss = 1.1419710569138075, disc_loss = 0.0008180421471479348
Trained batch 685 in epoch 6, gen_loss = 1.1421349158961294, disc_loss = 0.0008170315990403176
Trained batch 686 in epoch 6, gen_loss = 1.1421949867771877, disc_loss = 0.0008160206398077199
Trained batch 687 in epoch 6, gen_loss = 1.1423510691627514, disc_loss = 0.0008151303499247195
Trained batch 688 in epoch 6, gen_loss = 1.142276925774202, disc_loss = 0.00081423209975357
Trained batch 689 in epoch 6, gen_loss = 1.1419597938440849, disc_loss = 0.0008141967989196427
Trained batch 690 in epoch 6, gen_loss = 1.141980290757937, disc_loss = 0.0008144097805407145
Trained batch 691 in epoch 6, gen_loss = 1.1418657139202073, disc_loss = 0.000816209737595956
Trained batch 692 in epoch 6, gen_loss = 1.1415734331501166, disc_loss = 0.0008191053084702389
Trained batch 693 in epoch 6, gen_loss = 1.141339100832898, disc_loss = 0.0008203832848363734
Trained batch 694 in epoch 6, gen_loss = 1.1415739360473138, disc_loss = 0.0008205251607322804
Trained batch 695 in epoch 6, gen_loss = 1.1416021067349391, disc_loss = 0.000819990960683325
Trained batch 696 in epoch 6, gen_loss = 1.1414611465277598, disc_loss = 0.0008194162939481238
Trained batch 697 in epoch 6, gen_loss = 1.1413499392718505, disc_loss = 0.0008189300859621679
Trained batch 698 in epoch 6, gen_loss = 1.1410318530339199, disc_loss = 0.0008187102482220969
Trained batch 699 in epoch 6, gen_loss = 1.1414616146257945, disc_loss = 0.000818089848398813
Trained batch 700 in epoch 6, gen_loss = 1.141816848439939, disc_loss = 0.0008174373574113007
Trained batch 701 in epoch 6, gen_loss = 1.1416921110404523, disc_loss = 0.0008168572027854286
Trained batch 702 in epoch 6, gen_loss = 1.1417741413475948, disc_loss = 0.0008165337977188859
Trained batch 703 in epoch 6, gen_loss = 1.1416660548103126, disc_loss = 0.0008163084276743989
Trained batch 704 in epoch 6, gen_loss = 1.1418173002858534, disc_loss = 0.0008159389675504871
Trained batch 705 in epoch 6, gen_loss = 1.142179127539859, disc_loss = 0.0008154552507394148
Trained batch 706 in epoch 6, gen_loss = 1.1419216181972238, disc_loss = 0.0008151658772782534
Trained batch 707 in epoch 6, gen_loss = 1.1421400178960488, disc_loss = 0.0008146765499616977
Trained batch 708 in epoch 6, gen_loss = 1.1421273795438587, disc_loss = 0.000814264532612037
Trained batch 709 in epoch 6, gen_loss = 1.1423308162622048, disc_loss = 0.0008136790996219825
Trained batch 710 in epoch 6, gen_loss = 1.142466220339307, disc_loss = 0.0008128470576638598
Trained batch 711 in epoch 6, gen_loss = 1.1422113107329004, disc_loss = 0.0008121768174492041
Trained batch 712 in epoch 6, gen_loss = 1.1422270380096382, disc_loss = 0.0008117011368945261
Trained batch 713 in epoch 6, gen_loss = 1.1419865533250386, disc_loss = 0.0008109960486783538
Trained batch 714 in epoch 6, gen_loss = 1.141729792431518, disc_loss = 0.0008102581042440614
Trained batch 715 in epoch 6, gen_loss = 1.1416876203687498, disc_loss = 0.0008095774160337591
Trained batch 716 in epoch 6, gen_loss = 1.141689778122443, disc_loss = 0.0008090296343229211
Trained batch 717 in epoch 6, gen_loss = 1.1414241713567697, disc_loss = 0.0008082890125071146
Trained batch 718 in epoch 6, gen_loss = 1.1412949644143127, disc_loss = 0.0008077303615267717
Trained batch 719 in epoch 6, gen_loss = 1.1409455511305067, disc_loss = 0.0008085847085163146
Trained batch 720 in epoch 6, gen_loss = 1.1411886535967273, disc_loss = 0.0008081045034663635
Trained batch 721 in epoch 6, gen_loss = 1.141282303511601, disc_loss = 0.000807488781566989
Trained batch 722 in epoch 6, gen_loss = 1.1413380268698412, disc_loss = 0.0008069429928345901
Trained batch 723 in epoch 6, gen_loss = 1.1410799906563365, disc_loss = 0.0008064916433112211
Trained batch 724 in epoch 6, gen_loss = 1.141149755099724, disc_loss = 0.0008058229396982792
Trained batch 725 in epoch 6, gen_loss = 1.1413095155859125, disc_loss = 0.0008050147256498532
Trained batch 726 in epoch 6, gen_loss = 1.1411381659022388, disc_loss = 0.0008045153300463801
Trained batch 727 in epoch 6, gen_loss = 1.1410480736867412, disc_loss = 0.0008044367525724158
Trained batch 728 in epoch 6, gen_loss = 1.141069551799523, disc_loss = 0.0008039484084083185
Trained batch 729 in epoch 6, gen_loss = 1.1410317818595939, disc_loss = 0.0008032756192671064
Trained batch 730 in epoch 6, gen_loss = 1.1409026559661417, disc_loss = 0.0008026781422281147
Trained batch 731 in epoch 6, gen_loss = 1.1409332612987424, disc_loss = 0.0008021413660904837
Trained batch 732 in epoch 6, gen_loss = 1.1410699467216638, disc_loss = 0.0008015870615843293
Trained batch 733 in epoch 6, gen_loss = 1.140763976837049, disc_loss = 0.0008009354105747872
Trained batch 734 in epoch 6, gen_loss = 1.1404982890401567, disc_loss = 0.0008000913955454182
Trained batch 735 in epoch 6, gen_loss = 1.1404772602507602, disc_loss = 0.0007994359225152868
Trained batch 736 in epoch 6, gen_loss = 1.1406961610715134, disc_loss = 0.0007986988302119161
Trained batch 737 in epoch 6, gen_loss = 1.1406256040421927, disc_loss = 0.0007979720469978594
Trained batch 738 in epoch 6, gen_loss = 1.1405050556940382, disc_loss = 0.0007974308774268906
Trained batch 739 in epoch 6, gen_loss = 1.1402347986762589, disc_loss = 0.0007968129695065137
Trained batch 740 in epoch 6, gen_loss = 1.1401553905283712, disc_loss = 0.0007959407014844094
Trained batch 741 in epoch 6, gen_loss = 1.1401597481532237, disc_loss = 0.0007950938395688133
Trained batch 742 in epoch 6, gen_loss = 1.1401020864458455, disc_loss = 0.0007941846661723261
Trained batch 743 in epoch 6, gen_loss = 1.1402390732239651, disc_loss = 0.0007933948934668899
Trained batch 744 in epoch 6, gen_loss = 1.1401917607992287, disc_loss = 0.0007925669653181005
Trained batch 745 in epoch 6, gen_loss = 1.1401374627693728, disc_loss = 0.0007918725972529345
Trained batch 746 in epoch 6, gen_loss = 1.140221359579758, disc_loss = 0.0007915462524073923
Trained batch 747 in epoch 6, gen_loss = 1.1401637620466916, disc_loss = 0.0007912581051038522
Trained batch 748 in epoch 6, gen_loss = 1.1399481543234098, disc_loss = 0.0007912562304335393
Trained batch 749 in epoch 6, gen_loss = 1.1400725898742676, disc_loss = 0.0007908061577375823
Trained batch 750 in epoch 6, gen_loss = 1.1401901226069098, disc_loss = 0.0007900832125946684
Trained batch 751 in epoch 6, gen_loss = 1.1404213702425043, disc_loss = 0.0007894805047571742
Trained batch 752 in epoch 6, gen_loss = 1.14017601475456, disc_loss = 0.0007890910670747343
Trained batch 753 in epoch 6, gen_loss = 1.139982372759508, disc_loss = 0.0007887711134347515
Trained batch 754 in epoch 6, gen_loss = 1.1403818691013665, disc_loss = 0.0007880815724893905
Trained batch 755 in epoch 6, gen_loss = 1.1405395772406663, disc_loss = 0.0007874041583284178
Trained batch 756 in epoch 6, gen_loss = 1.140559878815433, disc_loss = 0.0007868372930315768
Trained batch 757 in epoch 6, gen_loss = 1.1409317608873573, disc_loss = 0.000786179334921919
Trained batch 758 in epoch 6, gen_loss = 1.140656522061671, disc_loss = 0.0007857833659868872
Trained batch 759 in epoch 6, gen_loss = 1.1409741689500055, disc_loss = 0.0007850143732866854
Trained batch 760 in epoch 6, gen_loss = 1.1410915014308323, disc_loss = 0.0007842159499508346
Trained batch 761 in epoch 6, gen_loss = 1.1410491065246853, disc_loss = 0.0007834870975355042
Trained batch 762 in epoch 6, gen_loss = 1.1410184072948222, disc_loss = 0.0007827405456945924
Trained batch 763 in epoch 6, gen_loss = 1.140932926566813, disc_loss = 0.0007819034982795238
Trained batch 764 in epoch 6, gen_loss = 1.140837047848047, disc_loss = 0.0007811250018539497
Trained batch 765 in epoch 6, gen_loss = 1.1406727508683117, disc_loss = 0.0007804498505606419
Trained batch 766 in epoch 6, gen_loss = 1.1410983322962944, disc_loss = 0.0007801467091350687
Trained batch 767 in epoch 6, gen_loss = 1.1408910877847422, disc_loss = 0.0007796019280306155
Trained batch 768 in epoch 6, gen_loss = 1.1407136944242509, disc_loss = 0.0007789758765449782
Trained batch 769 in epoch 6, gen_loss = 1.1405861514729339, disc_loss = 0.0007782514936267247
Trained batch 770 in epoch 6, gen_loss = 1.1407683640138648, disc_loss = 0.0007775170249181519
Trained batch 771 in epoch 6, gen_loss = 1.1406154046558963, disc_loss = 0.0007768498996573222
Trained batch 772 in epoch 6, gen_loss = 1.140787064566495, disc_loss = 0.0007760494406188821
Trained batch 773 in epoch 6, gen_loss = 1.1406059885055828, disc_loss = 0.0007754273497872085
Trained batch 774 in epoch 6, gen_loss = 1.1406229807484534, disc_loss = 0.0007746199434228812
Trained batch 775 in epoch 6, gen_loss = 1.1406944556180965, disc_loss = 0.0007737953100115998
Trained batch 776 in epoch 6, gen_loss = 1.140814271596101, disc_loss = 0.000773040259677897
Trained batch 777 in epoch 6, gen_loss = 1.1405728529075732, disc_loss = 0.0007724253889971567
Trained batch 778 in epoch 6, gen_loss = 1.1405026036600399, disc_loss = 0.0007717334772489304
Trained batch 779 in epoch 6, gen_loss = 1.1404203058053286, disc_loss = 0.0007709949261576791
Trained batch 780 in epoch 6, gen_loss = 1.1401949593565985, disc_loss = 0.0007703484189242725
Trained batch 781 in epoch 6, gen_loss = 1.140369454689343, disc_loss = 0.0007695719051831182
Trained batch 782 in epoch 6, gen_loss = 1.1406876790416955, disc_loss = 0.0007689069773908021
Trained batch 783 in epoch 6, gen_loss = 1.1406278302322845, disc_loss = 0.0007681270070750135
Trained batch 784 in epoch 6, gen_loss = 1.140589023016061, disc_loss = 0.0007672956672806298
Trained batch 785 in epoch 6, gen_loss = 1.1404237145837632, disc_loss = 0.0007665117691269082
Trained batch 786 in epoch 6, gen_loss = 1.140433438624027, disc_loss = 0.0007657106351659851
Trained batch 787 in epoch 6, gen_loss = 1.1404358710583091, disc_loss = 0.0007649619112206832
Trained batch 788 in epoch 6, gen_loss = 1.1402585469422382, disc_loss = 0.0007642562983263814
Trained batch 789 in epoch 6, gen_loss = 1.1403746039807041, disc_loss = 0.000763592545594799
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 1.0817012786865234, disc_loss = 0.0002785742108244449
Trained batch 1 in epoch 7, gen_loss = 1.091471016407013, disc_loss = 0.00023492483887821436
Trained batch 2 in epoch 7, gen_loss = 1.0753193298975627, disc_loss = 0.00020410150561171272
Trained batch 3 in epoch 7, gen_loss = 1.0746743083000183, disc_loss = 0.00017480094356869813
Trained batch 4 in epoch 7, gen_loss = 1.1179470777511598, disc_loss = 0.00017023249674821272
Trained batch 5 in epoch 7, gen_loss = 1.0855078895886738, disc_loss = 0.00018349930784703852
Trained batch 6 in epoch 7, gen_loss = 1.080490061214992, disc_loss = 0.00018625820874668925
Trained batch 7 in epoch 7, gen_loss = 1.1044587939977646, disc_loss = 0.0001800679028747254
Trained batch 8 in epoch 7, gen_loss = 1.0755275355445013, disc_loss = 0.0001846563997484433
Trained batch 9 in epoch 7, gen_loss = 1.069659698009491, disc_loss = 0.0001858284253103193
Trained batch 10 in epoch 7, gen_loss = 1.0748892805793069, disc_loss = 0.00018237836709224874
Trained batch 11 in epoch 7, gen_loss = 1.0871816476186116, disc_loss = 0.00017976269676485876
Trained batch 12 in epoch 7, gen_loss = 1.0931972907139704, disc_loss = 0.00017696496853694462
Trained batch 13 in epoch 7, gen_loss = 1.0862720949309213, disc_loss = 0.00019059768913263855
Trained batch 14 in epoch 7, gen_loss = 1.1116714159647623, disc_loss = 0.00020250479428796098
Trained batch 15 in epoch 7, gen_loss = 1.1177778840065002, disc_loss = 0.00023695436220805277
Trained batch 16 in epoch 7, gen_loss = 1.1229410452001236, disc_loss = 0.00023767406245871612
Trained batch 17 in epoch 7, gen_loss = 1.114091820187039, disc_loss = 0.00025191789973177947
Trained batch 18 in epoch 7, gen_loss = 1.1131606352956671, disc_loss = 0.00026583728896711315
Trained batch 19 in epoch 7, gen_loss = 1.1118969380855561, disc_loss = 0.00026155018022109287
Trained batch 20 in epoch 7, gen_loss = 1.1057877824420022, disc_loss = 0.0002668942716332995
Trained batch 21 in epoch 7, gen_loss = 1.0988599089058964, disc_loss = 0.0002797181001700334
Trained batch 22 in epoch 7, gen_loss = 1.0981254810872285, disc_loss = 0.00030721003808455703
Trained batch 23 in epoch 7, gen_loss = 1.0945771460731823, disc_loss = 0.00036091765438565443
Trained batch 24 in epoch 7, gen_loss = 1.0961133122444153, disc_loss = 0.00041952181636588647
Trained batch 25 in epoch 7, gen_loss = 1.0936539333600264, disc_loss = 0.0004701899421119239
Trained batch 26 in epoch 7, gen_loss = 1.09279923748087, disc_loss = 0.0004976099851235092
Trained batch 27 in epoch 7, gen_loss = 1.0907773865120751, disc_loss = 0.0005052229350569957
Trained batch 28 in epoch 7, gen_loss = 1.0942230902869126, disc_loss = 0.0005049391467513613
Trained batch 29 in epoch 7, gen_loss = 1.0930684546629588, disc_loss = 0.0004988597785995808
Trained batch 30 in epoch 7, gen_loss = 1.1142853594595385, disc_loss = 0.0005159996782763741
Trained batch 31 in epoch 7, gen_loss = 1.1078738179057837, disc_loss = 0.0005755137538017152
Trained batch 32 in epoch 7, gen_loss = 1.1069469036477986, disc_loss = 0.0006557819859043582
Trained batch 33 in epoch 7, gen_loss = 1.107204621329027, disc_loss = 0.0007219707444806665
Trained batch 34 in epoch 7, gen_loss = 1.1029300366129193, disc_loss = 0.0007850999879467833
Trained batch 35 in epoch 7, gen_loss = 1.1042751951350107, disc_loss = 0.0008179843880498083
Trained batch 36 in epoch 7, gen_loss = 1.1009569764137268, disc_loss = 0.0008362704682292895
Trained batch 37 in epoch 7, gen_loss = 1.1000115698889683, disc_loss = 0.0008541245634229486
Trained batch 38 in epoch 7, gen_loss = 1.100619919789143, disc_loss = 0.0008804078681397443
Trained batch 39 in epoch 7, gen_loss = 1.1003657951951027, disc_loss = 0.000884722889350087
Trained batch 40 in epoch 7, gen_loss = 1.095258850876878, disc_loss = 0.0009943638623354208
Trained batch 41 in epoch 7, gen_loss = 1.1003265650499434, disc_loss = 0.0010100283573029585
Trained batch 42 in epoch 7, gen_loss = 1.0996900977090347, disc_loss = 0.0010295394311596769
Trained batch 43 in epoch 7, gen_loss = 1.1032423796978863, disc_loss = 0.0010361403376670999
Trained batch 44 in epoch 7, gen_loss = 1.1044738014539084, disc_loss = 0.0010575857015080853
Trained batch 45 in epoch 7, gen_loss = 1.10580891241198, disc_loss = 0.001077091301261174
Trained batch 46 in epoch 7, gen_loss = 1.1043381602206128, disc_loss = 0.0010996261771651916
Trained batch 47 in epoch 7, gen_loss = 1.1042721159756184, disc_loss = 0.0011103756213136269
Trained batch 48 in epoch 7, gen_loss = 1.1061954169857258, disc_loss = 0.0011286668300364946
Trained batch 49 in epoch 7, gen_loss = 1.114480689764023, disc_loss = 0.0011624933734128717
Trained batch 50 in epoch 7, gen_loss = 1.1136343981705459, disc_loss = 0.0012032752629773527
Trained batch 51 in epoch 7, gen_loss = 1.1147100455485857, disc_loss = 0.0012361257239927698
Trained batch 52 in epoch 7, gen_loss = 1.1130522410824615, disc_loss = 0.0012498452584314124
Trained batch 53 in epoch 7, gen_loss = 1.1169373095035553, disc_loss = 0.0012503361623977846
Trained batch 54 in epoch 7, gen_loss = 1.11815875118429, disc_loss = 0.001242691045759288
Trained batch 55 in epoch 7, gen_loss = 1.1187700597303254, disc_loss = 0.0012291576257276965
Trained batch 56 in epoch 7, gen_loss = 1.1215363144874573, disc_loss = 0.0012144549406928075
Trained batch 57 in epoch 7, gen_loss = 1.1184403536648586, disc_loss = 0.0012002875402435291
Trained batch 58 in epoch 7, gen_loss = 1.1179631130170014, disc_loss = 0.0011882451319745425
Trained batch 59 in epoch 7, gen_loss = 1.1184788157542547, disc_loss = 0.001173915953283237
Trained batch 60 in epoch 7, gen_loss = 1.1196923969221897, disc_loss = 0.0011596519145284413
Trained batch 61 in epoch 7, gen_loss = 1.1224385509567876, disc_loss = 0.0011498230494673349
Trained batch 62 in epoch 7, gen_loss = 1.1227534432259818, disc_loss = 0.0011388485959503755
Trained batch 63 in epoch 7, gen_loss = 1.1199555797502398, disc_loss = 0.001127463701891429
Trained batch 64 in epoch 7, gen_loss = 1.117952626485091, disc_loss = 0.0011154339067825977
Trained batch 65 in epoch 7, gen_loss = 1.1189297844063153, disc_loss = 0.0011051740078652404
Trained batch 66 in epoch 7, gen_loss = 1.1165646083319365, disc_loss = 0.0010936553699682021
Trained batch 67 in epoch 7, gen_loss = 1.1182947860044592, disc_loss = 0.0010808371913727194
Trained batch 68 in epoch 7, gen_loss = 1.1197893135789512, disc_loss = 0.0010733602987560173
Trained batch 69 in epoch 7, gen_loss = 1.1209470987319947, disc_loss = 0.001063347025670477
Trained batch 70 in epoch 7, gen_loss = 1.1205332547845974, disc_loss = 0.0010506068482383443
Trained batch 71 in epoch 7, gen_loss = 1.1194915374120076, disc_loss = 0.0010393496430778112
Trained batch 72 in epoch 7, gen_loss = 1.1200331694459262, disc_loss = 0.0010280437630558169
Trained batch 73 in epoch 7, gen_loss = 1.1232346811810054, disc_loss = 0.0010177097445537929
Trained batch 74 in epoch 7, gen_loss = 1.124855670928955, disc_loss = 0.0010067547885895085
Trained batch 75 in epoch 7, gen_loss = 1.1271634258722003, disc_loss = 0.0009998422523686283
Trained batch 76 in epoch 7, gen_loss = 1.1251522101365126, disc_loss = 0.000992760007128319
Trained batch 77 in epoch 7, gen_loss = 1.1228429996050322, disc_loss = 0.0009864897599469165
Trained batch 78 in epoch 7, gen_loss = 1.122045052202442, disc_loss = 0.0009778386352714918
Trained batch 79 in epoch 7, gen_loss = 1.1212091863155365, disc_loss = 0.000969221907598694
Trained batch 80 in epoch 7, gen_loss = 1.1185133508694025, disc_loss = 0.0009646783695149489
Trained batch 81 in epoch 7, gen_loss = 1.1174159464312763, disc_loss = 0.0009586027303956188
Trained batch 82 in epoch 7, gen_loss = 1.1161763675241585, disc_loss = 0.0009506653184498975
Trained batch 83 in epoch 7, gen_loss = 1.1162999265250706, disc_loss = 0.000942902921624842
Trained batch 84 in epoch 7, gen_loss = 1.118948775880477, disc_loss = 0.0009391039062928244
Trained batch 85 in epoch 7, gen_loss = 1.1166432035523792, disc_loss = 0.0009335761326859261
Trained batch 86 in epoch 7, gen_loss = 1.120204395946415, disc_loss = 0.0009263717415026689
Trained batch 87 in epoch 7, gen_loss = 1.12001614340327, disc_loss = 0.0009217551349303739
Trained batch 88 in epoch 7, gen_loss = 1.1213222896115165, disc_loss = 0.0009179137075049122
Trained batch 89 in epoch 7, gen_loss = 1.1226966626114316, disc_loss = 0.0009113266945253903
Trained batch 90 in epoch 7, gen_loss = 1.122773778962565, disc_loss = 0.0009094379202796627
Trained batch 91 in epoch 7, gen_loss = 1.121450191606646, disc_loss = 0.0009050194245070958
Trained batch 92 in epoch 7, gen_loss = 1.1232391794522603, disc_loss = 0.0009005413919102691
Trained batch 93 in epoch 7, gen_loss = 1.1250135346930077, disc_loss = 0.0008952748424409482
Trained batch 94 in epoch 7, gen_loss = 1.124685117445494, disc_loss = 0.0008899773631128483
Trained batch 95 in epoch 7, gen_loss = 1.1260841619223356, disc_loss = 0.000884503072560013
Trained batch 96 in epoch 7, gen_loss = 1.1279986463871199, disc_loss = 0.0008808433396421306
Trained batch 97 in epoch 7, gen_loss = 1.12642383149692, disc_loss = 0.0008774189310705489
Trained batch 98 in epoch 7, gen_loss = 1.1246585225818133, disc_loss = 0.0008758966852305222
Trained batch 99 in epoch 7, gen_loss = 1.1249573415517806, disc_loss = 0.0008704220099753001
Trained batch 100 in epoch 7, gen_loss = 1.1259290410740541, disc_loss = 0.0008638733700419186
Trained batch 101 in epoch 7, gen_loss = 1.124922311189128, disc_loss = 0.0008604577818843216
Trained batch 102 in epoch 7, gen_loss = 1.1254057091416665, disc_loss = 0.0008557652457683907
Trained batch 103 in epoch 7, gen_loss = 1.1253465477090616, disc_loss = 0.0008505893727208156
Trained batch 104 in epoch 7, gen_loss = 1.1251976836295354, disc_loss = 0.0008454662663834391
Trained batch 105 in epoch 7, gen_loss = 1.12434620733531, disc_loss = 0.0008399534430590959
Trained batch 106 in epoch 7, gen_loss = 1.1243137928927056, disc_loss = 0.0008349091694641327
Trained batch 107 in epoch 7, gen_loss = 1.1237606113707577, disc_loss = 0.0008306854249692858
Trained batch 108 in epoch 7, gen_loss = 1.1235267618380556, disc_loss = 0.000826693896336135
Trained batch 109 in epoch 7, gen_loss = 1.122993438352238, disc_loss = 0.0008219802772642155
Trained batch 110 in epoch 7, gen_loss = 1.120831487952052, disc_loss = 0.0008192722478368622
Trained batch 111 in epoch 7, gen_loss = 1.1205298991075583, disc_loss = 0.0008156391119363045
Trained batch 112 in epoch 7, gen_loss = 1.1212948513241996, disc_loss = 0.0008110801628929876
Trained batch 113 in epoch 7, gen_loss = 1.1205474561766575, disc_loss = 0.0008073362312866824
Trained batch 114 in epoch 7, gen_loss = 1.1220243718313134, disc_loss = 0.0008034591238474999
Trained batch 115 in epoch 7, gen_loss = 1.12199547321632, disc_loss = 0.0008003561659530407
Trained batch 116 in epoch 7, gen_loss = 1.1199019337311769, disc_loss = 0.0008002538487099262
Trained batch 117 in epoch 7, gen_loss = 1.1207056939601898, disc_loss = 0.0008014101135890765
Trained batch 118 in epoch 7, gen_loss = 1.1213994932775737, disc_loss = 0.0008008653129144775
Trained batch 119 in epoch 7, gen_loss = 1.1203987792134285, disc_loss = 0.0007987151028525356
Trained batch 120 in epoch 7, gen_loss = 1.1196988037795075, disc_loss = 0.0007954465440250279
Trained batch 121 in epoch 7, gen_loss = 1.1210969144203624, disc_loss = 0.0007963935733313833
Trained batch 122 in epoch 7, gen_loss = 1.1197620421890322, disc_loss = 0.0007962357627045234
Trained batch 123 in epoch 7, gen_loss = 1.1204723345656549, disc_loss = 0.0007940859471296614
Trained batch 124 in epoch 7, gen_loss = 1.1206653685569763, disc_loss = 0.000790299906337168
Trained batch 125 in epoch 7, gen_loss = 1.120609689799566, disc_loss = 0.0007877234190620208
Trained batch 126 in epoch 7, gen_loss = 1.1193147015383864, disc_loss = 0.000786004600783821
Trained batch 127 in epoch 7, gen_loss = 1.1201009899377823, disc_loss = 0.0007852076559515808
Trained batch 128 in epoch 7, gen_loss = 1.1202267491540243, disc_loss = 0.0007845660717954837
Trained batch 129 in epoch 7, gen_loss = 1.1220837721457848, disc_loss = 0.0007819417832181968
Trained batch 130 in epoch 7, gen_loss = 1.120814681508159, disc_loss = 0.0007824000821049851
Trained batch 131 in epoch 7, gen_loss = 1.1205946925011547, disc_loss = 0.0007837966686290174
Trained batch 132 in epoch 7, gen_loss = 1.120283269792571, disc_loss = 0.0007816641639083924
Trained batch 133 in epoch 7, gen_loss = 1.1195480214126075, disc_loss = 0.0007781044745869038
Trained batch 134 in epoch 7, gen_loss = 1.1188688538692615, disc_loss = 0.0007758079292317335
Trained batch 135 in epoch 7, gen_loss = 1.1193522438406944, disc_loss = 0.0007735926108259317
Trained batch 136 in epoch 7, gen_loss = 1.1191279065870021, disc_loss = 0.0007716858434812914
Trained batch 137 in epoch 7, gen_loss = 1.1183314422766368, disc_loss = 0.0007681869683965224
Trained batch 138 in epoch 7, gen_loss = 1.118357812329162, disc_loss = 0.0007660886853922446
Trained batch 139 in epoch 7, gen_loss = 1.1178137408835547, disc_loss = 0.0007653548857758453
Trained batch 140 in epoch 7, gen_loss = 1.1167882465301675, disc_loss = 0.0007640697395471123
Trained batch 141 in epoch 7, gen_loss = 1.1166736303080975, disc_loss = 0.0007618259460543132
Trained batch 142 in epoch 7, gen_loss = 1.1165649728341536, disc_loss = 0.0007590461750592144
Trained batch 143 in epoch 7, gen_loss = 1.1156653004388015, disc_loss = 0.0007570244408978195
Trained batch 144 in epoch 7, gen_loss = 1.1153963997446257, disc_loss = 0.0007594147128562828
Trained batch 145 in epoch 7, gen_loss = 1.114227094878889, disc_loss = 0.0007614663983786906
Trained batch 146 in epoch 7, gen_loss = 1.114389595531282, disc_loss = 0.0007623188249781873
Trained batch 147 in epoch 7, gen_loss = 1.1153684065148637, disc_loss = 0.0007606911717507377
Trained batch 148 in epoch 7, gen_loss = 1.1157947306664997, disc_loss = 0.0007587532501026282
Trained batch 149 in epoch 7, gen_loss = 1.1160879516601563, disc_loss = 0.000754854678477083
Trained batch 150 in epoch 7, gen_loss = 1.115878117795022, disc_loss = 0.0007510090666296522
Trained batch 151 in epoch 7, gen_loss = 1.1156250661925267, disc_loss = 0.0007473907909163819
Trained batch 152 in epoch 7, gen_loss = 1.117035802672891, disc_loss = 0.0007440502303283436
Trained batch 153 in epoch 7, gen_loss = 1.116510539085834, disc_loss = 0.0007410072704059731
Trained batch 154 in epoch 7, gen_loss = 1.1171762228012085, disc_loss = 0.0007399890250282272
Trained batch 155 in epoch 7, gen_loss = 1.1182973850996067, disc_loss = 0.0007391141106591721
Trained batch 156 in epoch 7, gen_loss = 1.1177873467184176, disc_loss = 0.0007366547241913019
Trained batch 157 in epoch 7, gen_loss = 1.1189780469182171, disc_loss = 0.0007331112783849446
Trained batch 158 in epoch 7, gen_loss = 1.1195562710552096, disc_loss = 0.0007296246421100929
Trained batch 159 in epoch 7, gen_loss = 1.1188355661928653, disc_loss = 0.0007265128534982068
Trained batch 160 in epoch 7, gen_loss = 1.119041389560107, disc_loss = 0.0007233126012601901
Trained batch 161 in epoch 7, gen_loss = 1.1198051719017972, disc_loss = 0.000720263634444384
Trained batch 162 in epoch 7, gen_loss = 1.1190342698360514, disc_loss = 0.0007173640455210015
Trained batch 163 in epoch 7, gen_loss = 1.1195758733807541, disc_loss = 0.0007149859926668308
Trained batch 164 in epoch 7, gen_loss = 1.1192478562846329, disc_loss = 0.000717079123282791
Trained batch 165 in epoch 7, gen_loss = 1.1207799430353096, disc_loss = 0.0007227893209302971
Trained batch 166 in epoch 7, gen_loss = 1.1211113551419651, disc_loss = 0.0007275150949675673
Trained batch 167 in epoch 7, gen_loss = 1.1216674674124945, disc_loss = 0.0007289333789664116
Trained batch 168 in epoch 7, gen_loss = 1.1205266791687916, disc_loss = 0.0007316786416557607
Trained batch 169 in epoch 7, gen_loss = 1.1202416672426112, disc_loss = 0.0007319811864684144
Trained batch 170 in epoch 7, gen_loss = 1.1204105371620223, disc_loss = 0.0007306493022489329
Trained batch 171 in epoch 7, gen_loss = 1.120061193094697, disc_loss = 0.0007283350257429722
Trained batch 172 in epoch 7, gen_loss = 1.1196460613625587, disc_loss = 0.000725781952791021
Trained batch 173 in epoch 7, gen_loss = 1.1200130492791363, disc_loss = 0.0007244295483015494
Trained batch 174 in epoch 7, gen_loss = 1.120329510143825, disc_loss = 0.0007226095361485412
Trained batch 175 in epoch 7, gen_loss = 1.1200806112451986, disc_loss = 0.0007203596631122557
Trained batch 176 in epoch 7, gen_loss = 1.1217519624085077, disc_loss = 0.0007182171707298728
Trained batch 177 in epoch 7, gen_loss = 1.1227208797851305, disc_loss = 0.0007166723689908722
Trained batch 178 in epoch 7, gen_loss = 1.12255551029184, disc_loss = 0.0007168300123934051
Trained batch 179 in epoch 7, gen_loss = 1.1247656199667189, disc_loss = 0.0007192184706784449
Trained batch 180 in epoch 7, gen_loss = 1.1242223405047675, disc_loss = 0.0007194566849708551
Trained batch 181 in epoch 7, gen_loss = 1.1232445465994405, disc_loss = 0.0007182579603257902
Trained batch 182 in epoch 7, gen_loss = 1.1251663057530512, disc_loss = 0.0007179556399774025
Trained batch 183 in epoch 7, gen_loss = 1.1237872686723005, disc_loss = 0.0007186075313059163
Trained batch 184 in epoch 7, gen_loss = 1.1233913424852733, disc_loss = 0.0007204289568157086
Trained batch 185 in epoch 7, gen_loss = 1.1237648664623179, disc_loss = 0.0007179946352221367
Trained batch 186 in epoch 7, gen_loss = 1.1239572161021718, disc_loss = 0.0007164093908492132
Trained batch 187 in epoch 7, gen_loss = 1.1256267089158931, disc_loss = 0.0007143722383223073
Trained batch 188 in epoch 7, gen_loss = 1.1265160208025937, disc_loss = 0.0007122434298344641
Trained batch 189 in epoch 7, gen_loss = 1.1256304204463958, disc_loss = 0.0007101191348307398
Trained batch 190 in epoch 7, gen_loss = 1.1269125354851728, disc_loss = 0.0007081300060064239
Trained batch 191 in epoch 7, gen_loss = 1.1268737269565463, disc_loss = 0.0007062964031850546
Trained batch 192 in epoch 7, gen_loss = 1.1265491256442095, disc_loss = 0.000703721171689227
Trained batch 193 in epoch 7, gen_loss = 1.128444423073346, disc_loss = 0.0007015222614314815
Trained batch 194 in epoch 7, gen_loss = 1.1283649673828713, disc_loss = 0.0007010469449316868
Trained batch 195 in epoch 7, gen_loss = 1.1295148873207521, disc_loss = 0.000702453524502985
Trained batch 196 in epoch 7, gen_loss = 1.1299077311748176, disc_loss = 0.0007037222560103344
Trained batch 197 in epoch 7, gen_loss = 1.1309310146654494, disc_loss = 0.0007035264818040734
Trained batch 198 in epoch 7, gen_loss = 1.131785136071881, disc_loss = 0.0007016875288035632
Trained batch 199 in epoch 7, gen_loss = 1.1321042475104333, disc_loss = 0.0006990270660389797
Trained batch 200 in epoch 7, gen_loss = 1.1322463694496534, disc_loss = 0.0006961483836381938
Trained batch 201 in epoch 7, gen_loss = 1.132836482017347, disc_loss = 0.0006940282873983961
Trained batch 202 in epoch 7, gen_loss = 1.1326332735310634, disc_loss = 0.0006925321514635081
Trained batch 203 in epoch 7, gen_loss = 1.1341614416416954, disc_loss = 0.0006908475911497554
Trained batch 204 in epoch 7, gen_loss = 1.1355118382267835, disc_loss = 0.0006885077463954165
Trained batch 205 in epoch 7, gen_loss = 1.135427375730959, disc_loss = 0.0006863610698964144
Trained batch 206 in epoch 7, gen_loss = 1.1347311032567047, disc_loss = 0.0006843324256670022
Trained batch 207 in epoch 7, gen_loss = 1.133909943012091, disc_loss = 0.0006837353674270092
Trained batch 208 in epoch 7, gen_loss = 1.13427640262403, disc_loss = 0.0006836590607570926
Trained batch 209 in epoch 7, gen_loss = 1.133447385401953, disc_loss = 0.0006833237842892274
Trained batch 210 in epoch 7, gen_loss = 1.1330917101900724, disc_loss = 0.0006814730166133727
Trained batch 211 in epoch 7, gen_loss = 1.1332828790511724, disc_loss = 0.0006789477389453546
Trained batch 212 in epoch 7, gen_loss = 1.1332301517047791, disc_loss = 0.0006764805584338695
Trained batch 213 in epoch 7, gen_loss = 1.133017322727453, disc_loss = 0.0006741164580940064
Trained batch 214 in epoch 7, gen_loss = 1.1330144982005275, disc_loss = 0.0006721031162711835
Trained batch 215 in epoch 7, gen_loss = 1.133778272955506, disc_loss = 0.000669913138423268
Trained batch 216 in epoch 7, gen_loss = 1.1331911207893477, disc_loss = 0.0006677252600923898
Trained batch 217 in epoch 7, gen_loss = 1.1334141886562383, disc_loss = 0.0006654289823894308
Trained batch 218 in epoch 7, gen_loss = 1.133433368108044, disc_loss = 0.000662964507005843
Trained batch 219 in epoch 7, gen_loss = 1.1336703078313308, disc_loss = 0.0006606733620587461
Trained batch 220 in epoch 7, gen_loss = 1.1334534689312068, disc_loss = 0.0006584927968892091
Trained batch 221 in epoch 7, gen_loss = 1.1328865005089357, disc_loss = 0.0006567586609857211
Trained batch 222 in epoch 7, gen_loss = 1.1318922927561361, disc_loss = 0.0006554441892548732
Trained batch 223 in epoch 7, gen_loss = 1.132089710395251, disc_loss = 0.0006536662447160779
Trained batch 224 in epoch 7, gen_loss = 1.1315522646903993, disc_loss = 0.0006516803240002547
Trained batch 225 in epoch 7, gen_loss = 1.1314403776046449, disc_loss = 0.000649465800736118
Trained batch 226 in epoch 7, gen_loss = 1.1309584056228268, disc_loss = 0.0006473997392369094
Trained batch 227 in epoch 7, gen_loss = 1.130657412242471, disc_loss = 0.0006451119041453797
Trained batch 228 in epoch 7, gen_loss = 1.130361189227958, disc_loss = 0.0006432779418702612
Trained batch 229 in epoch 7, gen_loss = 1.1304068453933882, disc_loss = 0.0006410669700214741
Trained batch 230 in epoch 7, gen_loss = 1.130235916350311, disc_loss = 0.0006390443503933765
Trained batch 231 in epoch 7, gen_loss = 1.130788162607571, disc_loss = 0.0006373218035966194
Trained batch 232 in epoch 7, gen_loss = 1.130682103367834, disc_loss = 0.0006357175806727632
Trained batch 233 in epoch 7, gen_loss = 1.1307643053368626, disc_loss = 0.0006336087481808773
Trained batch 234 in epoch 7, gen_loss = 1.1307910084724426, disc_loss = 0.000631942043664241
Trained batch 235 in epoch 7, gen_loss = 1.1306446757862123, disc_loss = 0.0006306931816159365
Trained batch 236 in epoch 7, gen_loss = 1.1312751958641825, disc_loss = 0.0006293754618875741
Trained batch 237 in epoch 7, gen_loss = 1.131669640290637, disc_loss = 0.0006279416714377698
Trained batch 238 in epoch 7, gen_loss = 1.1312670435865553, disc_loss = 0.000626068647845432
Trained batch 239 in epoch 7, gen_loss = 1.1323475676278274, disc_loss = 0.0006247512410178994
Trained batch 240 in epoch 7, gen_loss = 1.132854835373732, disc_loss = 0.0006234605706485734
Trained batch 241 in epoch 7, gen_loss = 1.1326488224435445, disc_loss = 0.0006218231291246066
Trained batch 242 in epoch 7, gen_loss = 1.1329518014511453, disc_loss = 0.0006202748331273407
Trained batch 243 in epoch 7, gen_loss = 1.1336278307144758, disc_loss = 0.0006186914123958797
Trained batch 244 in epoch 7, gen_loss = 1.1347003209347628, disc_loss = 0.0006177276721858533
Trained batch 245 in epoch 7, gen_loss = 1.1351657972587803, disc_loss = 0.0006179006178889374
Trained batch 246 in epoch 7, gen_loss = 1.134529772316396, disc_loss = 0.0006192266395933424
Trained batch 247 in epoch 7, gen_loss = 1.13460739461645, disc_loss = 0.0006199781646500924
Trained batch 248 in epoch 7, gen_loss = 1.1346191400026222, disc_loss = 0.0006191412394108478
Trained batch 249 in epoch 7, gen_loss = 1.1350472013950348, disc_loss = 0.0006177412324759644
Trained batch 250 in epoch 7, gen_loss = 1.1348639439301662, disc_loss = 0.0006161508451814696
Trained batch 251 in epoch 7, gen_loss = 1.1345444603098764, disc_loss = 0.0006153777417888964
Trained batch 252 in epoch 7, gen_loss = 1.13495086799026, disc_loss = 0.0006154499234060625
Trained batch 253 in epoch 7, gen_loss = 1.1350458712559046, disc_loss = 0.0006161009267833741
Trained batch 254 in epoch 7, gen_loss = 1.1355792365822137, disc_loss = 0.0006162339857694985
Trained batch 255 in epoch 7, gen_loss = 1.134901919402182, disc_loss = 0.0006154689613993014
Trained batch 256 in epoch 7, gen_loss = 1.1348862416085566, disc_loss = 0.0006141417258877058
Trained batch 257 in epoch 7, gen_loss = 1.134335077548212, disc_loss = 0.0006123881697888908
Trained batch 258 in epoch 7, gen_loss = 1.1337443949172856, disc_loss = 0.0006105532348805474
Trained batch 259 in epoch 7, gen_loss = 1.1335871086670801, disc_loss = 0.0006091699841747938
Trained batch 260 in epoch 7, gen_loss = 1.1339911450828173, disc_loss = 0.0006084519545103859
Trained batch 261 in epoch 7, gen_loss = 1.1332487423001354, disc_loss = 0.0006083354136681287
Trained batch 262 in epoch 7, gen_loss = 1.1324437009064416, disc_loss = 0.0006079113465512946
Trained batch 263 in epoch 7, gen_loss = 1.1318773001883968, disc_loss = 0.0006071438189213619
Trained batch 264 in epoch 7, gen_loss = 1.1317349062775666, disc_loss = 0.0006056317921457724
Trained batch 265 in epoch 7, gen_loss = 1.1310783754614062, disc_loss = 0.0006040971349744053
Trained batch 266 in epoch 7, gen_loss = 1.130828060907371, disc_loss = 0.0006026392451878585
Trained batch 267 in epoch 7, gen_loss = 1.1308231478306785, disc_loss = 0.0006015349195850057
Trained batch 268 in epoch 7, gen_loss = 1.1305278739078337, disc_loss = 0.0006003830022601408
Trained batch 269 in epoch 7, gen_loss = 1.1308911835705793, disc_loss = 0.0005993525899948846
Trained batch 270 in epoch 7, gen_loss = 1.1303701677885443, disc_loss = 0.0005982679630274459
Trained batch 271 in epoch 7, gen_loss = 1.1307375216308762, disc_loss = 0.0005965628637407944
Trained batch 272 in epoch 7, gen_loss = 1.1311882930797534, disc_loss = 0.000594894146963983
Trained batch 273 in epoch 7, gen_loss = 1.131165814225691, disc_loss = 0.0005931386326167335
Trained batch 274 in epoch 7, gen_loss = 1.131777707013217, disc_loss = 0.0005915600752235729
Trained batch 275 in epoch 7, gen_loss = 1.1315116813217385, disc_loss = 0.0005902849147326154
Trained batch 276 in epoch 7, gen_loss = 1.1313585701401914, disc_loss = 0.0005889722462716203
Trained batch 277 in epoch 7, gen_loss = 1.131691052759294, disc_loss = 0.0005875515640098116
Trained batch 278 in epoch 7, gen_loss = 1.1316123453092404, disc_loss = 0.0005862720094078327
Trained batch 279 in epoch 7, gen_loss = 1.1315171309879848, disc_loss = 0.0005850261198637392
Trained batch 280 in epoch 7, gen_loss = 1.131350451092703, disc_loss = 0.000583889542326283
Trained batch 281 in epoch 7, gen_loss = 1.1316412184255342, disc_loss = 0.0005826568397404774
Trained batch 282 in epoch 7, gen_loss = 1.1317495823748962, disc_loss = 0.0005811250860078422
Trained batch 283 in epoch 7, gen_loss = 1.1319543295343157, disc_loss = 0.0005795561605160581
Trained batch 284 in epoch 7, gen_loss = 1.132260951242949, disc_loss = 0.0005782233904220017
Trained batch 285 in epoch 7, gen_loss = 1.1318233917643141, disc_loss = 0.000577069341991271
Trained batch 286 in epoch 7, gen_loss = 1.131512948029548, disc_loss = 0.0005759839761265203
Trained batch 287 in epoch 7, gen_loss = 1.131490156882339, disc_loss = 0.0005750687001990526
Trained batch 288 in epoch 7, gen_loss = 1.1309083852800943, disc_loss = 0.0005738437028469238
Trained batch 289 in epoch 7, gen_loss = 1.1313490736073462, disc_loss = 0.0005722502056069688
Trained batch 290 in epoch 7, gen_loss = 1.1304211401447808, disc_loss = 0.0005723269039669388
Trained batch 291 in epoch 7, gen_loss = 1.1304077577509293, disc_loss = 0.0005729467570807622
Trained batch 292 in epoch 7, gen_loss = 1.130219389350748, disc_loss = 0.0005753321899985179
Trained batch 293 in epoch 7, gen_loss = 1.130197864203226, disc_loss = 0.0005792208700403207
Trained batch 294 in epoch 7, gen_loss = 1.1301538695723323, disc_loss = 0.0005833594030079085
Trained batch 295 in epoch 7, gen_loss = 1.1297060498917424, disc_loss = 0.0005862585672681185
Trained batch 296 in epoch 7, gen_loss = 1.1310088897393609, disc_loss = 0.0005890670850465736
Trained batch 297 in epoch 7, gen_loss = 1.1313731192342387, disc_loss = 0.0005907272246766651
Trained batch 298 in epoch 7, gen_loss = 1.1316895375283667, disc_loss = 0.0005908713204777227
Trained batch 299 in epoch 7, gen_loss = 1.1313957474629084, disc_loss = 0.0005913812389917439
Trained batch 300 in epoch 7, gen_loss = 1.131061648015564, disc_loss = 0.0005911438506836477
Trained batch 301 in epoch 7, gen_loss = 1.130807919415417, disc_loss = 0.0005904768653792585
Trained batch 302 in epoch 7, gen_loss = 1.1310342981083559, disc_loss = 0.0005898677386705019
Trained batch 303 in epoch 7, gen_loss = 1.1307142974906845, disc_loss = 0.0005902680929562178
Trained batch 304 in epoch 7, gen_loss = 1.1304918830512, disc_loss = 0.0005904976228208159
Trained batch 305 in epoch 7, gen_loss = 1.1306697685344547, disc_loss = 0.0005896779482629153
Trained batch 306 in epoch 7, gen_loss = 1.1311507393948808, disc_loss = 0.0005884852159340981
Trained batch 307 in epoch 7, gen_loss = 1.131241147974869, disc_loss = 0.0005882152421832729
Trained batch 308 in epoch 7, gen_loss = 1.131742753450153, disc_loss = 0.0005874470632659304
Trained batch 309 in epoch 7, gen_loss = 1.131314786787956, disc_loss = 0.0005865461663615274
Trained batch 310 in epoch 7, gen_loss = 1.1309295145261709, disc_loss = 0.00058519980830228
Trained batch 311 in epoch 7, gen_loss = 1.1310580242902806, disc_loss = 0.0005852508200125437
Trained batch 312 in epoch 7, gen_loss = 1.130963003292632, disc_loss = 0.0005861213074868007
Trained batch 313 in epoch 7, gen_loss = 1.130674689059045, disc_loss = 0.0005862813475247025
Trained batch 314 in epoch 7, gen_loss = 1.1305989250304207, disc_loss = 0.0005855413711129037
Trained batch 315 in epoch 7, gen_loss = 1.1305027732366248, disc_loss = 0.0005844490049041062
Trained batch 316 in epoch 7, gen_loss = 1.130280042672383, disc_loss = 0.0005833557810351966
Trained batch 317 in epoch 7, gen_loss = 1.1298576244768106, disc_loss = 0.0005828374433695447
Trained batch 318 in epoch 7, gen_loss = 1.129461167000678, disc_loss = 0.0005824128403735266
Trained batch 319 in epoch 7, gen_loss = 1.1302885565906764, disc_loss = 0.00058209040314523
Trained batch 320 in epoch 7, gen_loss = 1.1302051889562161, disc_loss = 0.0005821613887514603
Trained batch 321 in epoch 7, gen_loss = 1.130294130085418, disc_loss = 0.0005828868909346689
Trained batch 322 in epoch 7, gen_loss = 1.1310499028155678, disc_loss = 0.0005842878158813726
Trained batch 323 in epoch 7, gen_loss = 1.1312920947869618, disc_loss = 0.0005852221159857661
Trained batch 324 in epoch 7, gen_loss = 1.1320752206215492, disc_loss = 0.0005855562581564299
Trained batch 325 in epoch 7, gen_loss = 1.1326351637489225, disc_loss = 0.0005852689739040662
Trained batch 326 in epoch 7, gen_loss = 1.132929509203733, disc_loss = 0.0005842386489256645
Trained batch 327 in epoch 7, gen_loss = 1.1330676275055582, disc_loss = 0.0005829660863682653
Trained batch 328 in epoch 7, gen_loss = 1.13346640389741, disc_loss = 0.000582934163959653
Trained batch 329 in epoch 7, gen_loss = 1.1331608920386342, disc_loss = 0.0005825218932648458
Trained batch 330 in epoch 7, gen_loss = 1.132995978222873, disc_loss = 0.0005816612390245964
Trained batch 331 in epoch 7, gen_loss = 1.1331041085432811, disc_loss = 0.0005807098330544513
Trained batch 332 in epoch 7, gen_loss = 1.1335368031138056, disc_loss = 0.0005796574823379687
Trained batch 333 in epoch 7, gen_loss = 1.1330741076412316, disc_loss = 0.0005789552491325899
Trained batch 334 in epoch 7, gen_loss = 1.1333654158150972, disc_loss = 0.0005777901121277932
Trained batch 335 in epoch 7, gen_loss = 1.133035417468775, disc_loss = 0.0005765624936256721
Trained batch 336 in epoch 7, gen_loss = 1.1338259830672945, disc_loss = 0.0005753626424492093
Trained batch 337 in epoch 7, gen_loss = 1.1342440176997663, disc_loss = 0.0005741503834526383
Trained batch 338 in epoch 7, gen_loss = 1.1339628650727174, disc_loss = 0.0005729734668775
Trained batch 339 in epoch 7, gen_loss = 1.134295846784816, disc_loss = 0.0005723816970310188
Trained batch 340 in epoch 7, gen_loss = 1.1346352712150194, disc_loss = 0.0005713234192500904
Trained batch 341 in epoch 7, gen_loss = 1.134297033848121, disc_loss = 0.0005704621227714437
Trained batch 342 in epoch 7, gen_loss = 1.1341493939519276, disc_loss = 0.0005697146957373972
Trained batch 343 in epoch 7, gen_loss = 1.1336496254039365, disc_loss = 0.000568756021620661
Trained batch 344 in epoch 7, gen_loss = 1.1335736050122025, disc_loss = 0.0005680403062876355
Trained batch 345 in epoch 7, gen_loss = 1.1336669532549863, disc_loss = 0.0005669499671709457
Trained batch 346 in epoch 7, gen_loss = 1.133797421235516, disc_loss = 0.0005661158271894457
Trained batch 347 in epoch 7, gen_loss = 1.1332367727126198, disc_loss = 0.0005656021070556551
Trained batch 348 in epoch 7, gen_loss = 1.1335468886574906, disc_loss = 0.0005651175493418165
Trained batch 349 in epoch 7, gen_loss = 1.133500280380249, disc_loss = 0.0005647570071700362
Trained batch 350 in epoch 7, gen_loss = 1.1338086192764107, disc_loss = 0.0005644524474407711
Trained batch 351 in epoch 7, gen_loss = 1.1344052312726325, disc_loss = 0.0005637550326479289
Trained batch 352 in epoch 7, gen_loss = 1.1341799622554618, disc_loss = 0.0005634124049243765
Trained batch 353 in epoch 7, gen_loss = 1.1339071561387704, disc_loss = 0.0005622895833525456
Trained batch 354 in epoch 7, gen_loss = 1.1334902138777183, disc_loss = 0.0005614336525724584
Trained batch 355 in epoch 7, gen_loss = 1.1338051631209556, disc_loss = 0.0005603204461478752
Trained batch 356 in epoch 7, gen_loss = 1.1336171897519536, disc_loss = 0.0005593961573305999
Trained batch 357 in epoch 7, gen_loss = 1.1333950841227056, disc_loss = 0.0005586787843619871
Trained batch 358 in epoch 7, gen_loss = 1.1333516407809883, disc_loss = 0.0005578249605159498
Trained batch 359 in epoch 7, gen_loss = 1.132600878841347, disc_loss = 0.0005573574888330767
Trained batch 360 in epoch 7, gen_loss = 1.1322580534665538, disc_loss = 0.0005565083462451817
Trained batch 361 in epoch 7, gen_loss = 1.1319066228458237, disc_loss = 0.0005556470502059564
Trained batch 362 in epoch 7, gen_loss = 1.1313116706435673, disc_loss = 0.0005552458043327907
Trained batch 363 in epoch 7, gen_loss = 1.131118587576426, disc_loss = 0.0005547014340094052
Trained batch 364 in epoch 7, gen_loss = 1.1305338439876087, disc_loss = 0.0005543864041699212
Trained batch 365 in epoch 7, gen_loss = 1.130222847064336, disc_loss = 0.0005542001831674467
Trained batch 366 in epoch 7, gen_loss = 1.129903215316076, disc_loss = 0.0005539124664824839
Trained batch 367 in epoch 7, gen_loss = 1.1301117453562177, disc_loss = 0.0005532980191041449
Trained batch 368 in epoch 7, gen_loss = 1.1300534586596296, disc_loss = 0.0005522458632087
Trained batch 369 in epoch 7, gen_loss = 1.1296306593998058, disc_loss = 0.0005518093720319165
Trained batch 370 in epoch 7, gen_loss = 1.1291332195068626, disc_loss = 0.0005516934575429224
Trained batch 371 in epoch 7, gen_loss = 1.1289863536755245, disc_loss = 0.0005511316075592155
Trained batch 372 in epoch 7, gen_loss = 1.1287750310936178, disc_loss = 0.000550499020445369
Trained batch 373 in epoch 7, gen_loss = 1.128732498476212, disc_loss = 0.0005496770487190909
Trained batch 374 in epoch 7, gen_loss = 1.1288297095298767, disc_loss = 0.0005486281923367641
Trained batch 375 in epoch 7, gen_loss = 1.128825674190166, disc_loss = 0.0005474947471311874
Trained batch 376 in epoch 7, gen_loss = 1.1285697150609855, disc_loss = 0.0005463664237181632
Trained batch 377 in epoch 7, gen_loss = 1.1287777933178755, disc_loss = 0.0005453497626014589
Trained batch 378 in epoch 7, gen_loss = 1.1292840580512478, disc_loss = 0.0005443575090335837
Trained batch 379 in epoch 7, gen_loss = 1.1295495561863247, disc_loss = 0.000543419611245841
Trained batch 380 in epoch 7, gen_loss = 1.1298575271458764, disc_loss = 0.0005423370867350696
Trained batch 381 in epoch 7, gen_loss = 1.129884364873327, disc_loss = 0.0005412114034545503
Trained batch 382 in epoch 7, gen_loss = 1.1294072759058083, disc_loss = 0.0005402568380727418
Trained batch 383 in epoch 7, gen_loss = 1.1289629428647459, disc_loss = 0.0005396513344256467
Trained batch 384 in epoch 7, gen_loss = 1.1285420581891938, disc_loss = 0.0005397080876010276
Trained batch 385 in epoch 7, gen_loss = 1.1280609049636465, disc_loss = 0.0005400577922394786
Trained batch 386 in epoch 7, gen_loss = 1.128084922483725, disc_loss = 0.0005405030059091235
Trained batch 387 in epoch 7, gen_loss = 1.1283374169130915, disc_loss = 0.0005409109406585784
Trained batch 388 in epoch 7, gen_loss = 1.1278500852670645, disc_loss = 0.0005411875818891673
Trained batch 389 in epoch 7, gen_loss = 1.1282338810272705, disc_loss = 0.0005404634599518687
Trained batch 390 in epoch 7, gen_loss = 1.1278955091905716, disc_loss = 0.0005395235236050249
Trained batch 391 in epoch 7, gen_loss = 1.12757273809034, disc_loss = 0.0005387475979548573
Trained batch 392 in epoch 7, gen_loss = 1.1270112986783034, disc_loss = 0.0005389400638434645
Trained batch 393 in epoch 7, gen_loss = 1.1266017955571868, disc_loss = 0.0005399273554781194
Trained batch 394 in epoch 7, gen_loss = 1.1267420693288877, disc_loss = 0.0005408570061907868
Trained batch 395 in epoch 7, gen_loss = 1.1269057320825981, disc_loss = 0.0005404298350700316
Trained batch 396 in epoch 7, gen_loss = 1.1266004642851708, disc_loss = 0.0005397810976591925
Trained batch 397 in epoch 7, gen_loss = 1.126768363181071, disc_loss = 0.0005388349574110435
Trained batch 398 in epoch 7, gen_loss = 1.1263220198172377, disc_loss = 0.0005381457908025051
Trained batch 399 in epoch 7, gen_loss = 1.1259547720849514, disc_loss = 0.0005372783136226644
Trained batch 400 in epoch 7, gen_loss = 1.1258009266377684, disc_loss = 0.0005367325333885076
Trained batch 401 in epoch 7, gen_loss = 1.1253635611996722, disc_loss = 0.0005367281535211476
Trained batch 402 in epoch 7, gen_loss = 1.12546389052649, disc_loss = 0.0005371810432872157
Trained batch 403 in epoch 7, gen_loss = 1.125115890756692, disc_loss = 0.0005369892063898456
Trained batch 404 in epoch 7, gen_loss = 1.125318369306164, disc_loss = 0.0005368791153923218
Trained batch 405 in epoch 7, gen_loss = 1.1247904868842347, disc_loss = 0.0005363484593060984
Trained batch 406 in epoch 7, gen_loss = 1.1246209723064882, disc_loss = 0.0005356560575314432
Trained batch 407 in epoch 7, gen_loss = 1.1242383562174498, disc_loss = 0.0005347572322374189
Trained batch 408 in epoch 7, gen_loss = 1.124127078027189, disc_loss = 0.0005341039844104066
Trained batch 409 in epoch 7, gen_loss = 1.124107306032646, disc_loss = 0.000533236384092938
Trained batch 410 in epoch 7, gen_loss = 1.1238486834976216, disc_loss = 0.0005324725824479896
Trained batch 411 in epoch 7, gen_loss = 1.1242571656854408, disc_loss = 0.0005321017665444089
Trained batch 412 in epoch 7, gen_loss = 1.124285774571555, disc_loss = 0.0005326848571025541
Trained batch 413 in epoch 7, gen_loss = 1.1241085476057542, disc_loss = 0.0005336914334429601
Trained batch 414 in epoch 7, gen_loss = 1.1246291831315283, disc_loss = 0.0005344172570249907
Trained batch 415 in epoch 7, gen_loss = 1.1252634999557183, disc_loss = 0.0005345833992403361
Trained batch 416 in epoch 7, gen_loss = 1.1258485821797122, disc_loss = 0.0005342871127729706
Trained batch 417 in epoch 7, gen_loss = 1.125887908576208, disc_loss = 0.0005337259299702481
Trained batch 418 in epoch 7, gen_loss = 1.125684865192468, disc_loss = 0.0005330979515280772
Trained batch 419 in epoch 7, gen_loss = 1.12520330562478, disc_loss = 0.0005325164120135706
Trained batch 420 in epoch 7, gen_loss = 1.1252301927133863, disc_loss = 0.0005319897670995924
Trained batch 421 in epoch 7, gen_loss = 1.125168300776685, disc_loss = 0.0005317226000593907
Trained batch 422 in epoch 7, gen_loss = 1.125194972711252, disc_loss = 0.0005314651881401035
Trained batch 423 in epoch 7, gen_loss = 1.1248080346663043, disc_loss = 0.0005306606586806461
Trained batch 424 in epoch 7, gen_loss = 1.1243579638705534, disc_loss = 0.0005302275561980958
Trained batch 425 in epoch 7, gen_loss = 1.1242365057759443, disc_loss = 0.0005293852713541401
Trained batch 426 in epoch 7, gen_loss = 1.1239424497238089, disc_loss = 0.000528509878815589
Trained batch 427 in epoch 7, gen_loss = 1.1238568673067004, disc_loss = 0.0005276363986310665
Trained batch 428 in epoch 7, gen_loss = 1.1238129314009127, disc_loss = 0.000526945590103856
Trained batch 429 in epoch 7, gen_loss = 1.1235555169194245, disc_loss = 0.0005263301780613865
Trained batch 430 in epoch 7, gen_loss = 1.123622131734879, disc_loss = 0.0005258418702656293
Trained batch 431 in epoch 7, gen_loss = 1.123856703164401, disc_loss = 0.0005254457839698632
Trained batch 432 in epoch 7, gen_loss = 1.1235820327564972, disc_loss = 0.0005255630362678618
Trained batch 433 in epoch 7, gen_loss = 1.1235078347992786, disc_loss = 0.000525570057907484
Trained batch 434 in epoch 7, gen_loss = 1.1231044518536535, disc_loss = 0.0005256518795678189
Trained batch 435 in epoch 7, gen_loss = 1.1226240356854342, disc_loss = 0.000526128698098596
Trained batch 436 in epoch 7, gen_loss = 1.122629173696723, disc_loss = 0.000525924799431971
Trained batch 437 in epoch 7, gen_loss = 1.1221481515392322, disc_loss = 0.0005257518831091629
Trained batch 438 in epoch 7, gen_loss = 1.1219148057468389, disc_loss = 0.0005257775438603402
Trained batch 439 in epoch 7, gen_loss = 1.1225030229850248, disc_loss = 0.0005257197955870652
Trained batch 440 in epoch 7, gen_loss = 1.1229763249961697, disc_loss = 0.0005259721479298127
Trained batch 441 in epoch 7, gen_loss = 1.1234468194694, disc_loss = 0.0005274261325397329
Trained batch 442 in epoch 7, gen_loss = 1.1232288892866527, disc_loss = 0.0005287484723740072
Trained batch 443 in epoch 7, gen_loss = 1.1233398159881969, disc_loss = 0.0005289216425791876
Trained batch 444 in epoch 7, gen_loss = 1.1231180437495198, disc_loss = 0.0005284056869130111
Trained batch 445 in epoch 7, gen_loss = 1.1228817829636715, disc_loss = 0.0005283780222764654
Trained batch 446 in epoch 7, gen_loss = 1.122964352569324, disc_loss = 0.000529120171346136
Trained batch 447 in epoch 7, gen_loss = 1.122835334656494, disc_loss = 0.0005297456414642251
Trained batch 448 in epoch 7, gen_loss = 1.1224844846003306, disc_loss = 0.0005292099505502944
Trained batch 449 in epoch 7, gen_loss = 1.1223231805695428, disc_loss = 0.0005285641013728714
Trained batch 450 in epoch 7, gen_loss = 1.1225737254001085, disc_loss = 0.0005277945675574576
Trained batch 451 in epoch 7, gen_loss = 1.1227054920344226, disc_loss = 0.0005270702122852043
Trained batch 452 in epoch 7, gen_loss = 1.122264941401829, disc_loss = 0.0005263277114695092
Trained batch 453 in epoch 7, gen_loss = 1.1221112408039329, disc_loss = 0.0005263015954317536
Trained batch 454 in epoch 7, gen_loss = 1.122289080279214, disc_loss = 0.0005272078778943978
Trained batch 455 in epoch 7, gen_loss = 1.121902959257887, disc_loss = 0.0005278635248543109
Trained batch 456 in epoch 7, gen_loss = 1.1219544858066468, disc_loss = 0.0005275390532788111
Trained batch 457 in epoch 7, gen_loss = 1.1219540687367384, disc_loss = 0.0005271205361394921
Trained batch 458 in epoch 7, gen_loss = 1.1218785350099367, disc_loss = 0.0005271499970967654
Trained batch 459 in epoch 7, gen_loss = 1.1217204756062964, disc_loss = 0.0005269864818452018
Trained batch 460 in epoch 7, gen_loss = 1.1215174181342384, disc_loss = 0.0005267088060726113
Trained batch 461 in epoch 7, gen_loss = 1.1215308856912505, disc_loss = 0.0005264233247871113
Trained batch 462 in epoch 7, gen_loss = 1.1221481377568667, disc_loss = 0.0005265634449770359
Trained batch 463 in epoch 7, gen_loss = 1.1222359002407254, disc_loss = 0.0005272619205870483
Trained batch 464 in epoch 7, gen_loss = 1.122938923810118, disc_loss = 0.0005270623379313107
Trained batch 465 in epoch 7, gen_loss = 1.1227688785530467, disc_loss = 0.0005262304086515694
Trained batch 466 in epoch 7, gen_loss = 1.1225961611408748, disc_loss = 0.0005253586057059784
Trained batch 467 in epoch 7, gen_loss = 1.122303085322054, disc_loss = 0.000524524795500294
Trained batch 468 in epoch 7, gen_loss = 1.122167041179722, disc_loss = 0.0005238955776210376
Trained batch 469 in epoch 7, gen_loss = 1.122418536150709, disc_loss = 0.0005231881661723279
Trained batch 470 in epoch 7, gen_loss = 1.1224178099834743, disc_loss = 0.000522567729694663
Trained batch 471 in epoch 7, gen_loss = 1.122404555016655, disc_loss = 0.0005222911771760032
Trained batch 472 in epoch 7, gen_loss = 1.1223504655456946, disc_loss = 0.0005222426154843952
Trained batch 473 in epoch 7, gen_loss = 1.1230995548173848, disc_loss = 0.000522594657650572
Trained batch 474 in epoch 7, gen_loss = 1.1233869443441693, disc_loss = 0.0005239423941728953
Trained batch 475 in epoch 7, gen_loss = 1.1234116815969724, disc_loss = 0.0005250768030573224
Trained batch 476 in epoch 7, gen_loss = 1.1230862652980556, disc_loss = 0.0005258373950225637
Trained batch 477 in epoch 7, gen_loss = 1.123424648241019, disc_loss = 0.0005265130245358883
Trained batch 478 in epoch 7, gen_loss = 1.1233304607096695, disc_loss = 0.0005272744173318438
Trained batch 479 in epoch 7, gen_loss = 1.1233648141225179, disc_loss = 0.0005275535289456457
Trained batch 480 in epoch 7, gen_loss = 1.1234674557826623, disc_loss = 0.0005271952016635608
Trained batch 481 in epoch 7, gen_loss = 1.1236695815418767, disc_loss = 0.0005268239862189185
Trained batch 482 in epoch 7, gen_loss = 1.123553162529355, disc_loss = 0.0005265065922367379
Trained batch 483 in epoch 7, gen_loss = 1.1238144756841266, disc_loss = 0.0005257672871890419
Trained batch 484 in epoch 7, gen_loss = 1.1237194855188586, disc_loss = 0.0005254540408957875
Trained batch 485 in epoch 7, gen_loss = 1.1234428076832383, disc_loss = 0.0005255045074546267
Trained batch 486 in epoch 7, gen_loss = 1.1232803645075224, disc_loss = 0.000525300546532647
Trained batch 487 in epoch 7, gen_loss = 1.1232177701885584, disc_loss = 0.0005247712378910424
Trained batch 488 in epoch 7, gen_loss = 1.1229702372004893, disc_loss = 0.0005242274301742006
Trained batch 489 in epoch 7, gen_loss = 1.1225143616296807, disc_loss = 0.0005241108601063499
Trained batch 490 in epoch 7, gen_loss = 1.1227942747642454, disc_loss = 0.0005255246660991025
Trained batch 491 in epoch 7, gen_loss = 1.122716699795025, disc_loss = 0.0005286813142802425
Trained batch 492 in epoch 7, gen_loss = 1.1226338606335329, disc_loss = 0.0005329556253973185
Trained batch 493 in epoch 7, gen_loss = 1.1228135096640721, disc_loss = 0.0005355131866035442
Trained batch 494 in epoch 7, gen_loss = 1.1225796175725533, disc_loss = 0.0005353508838317169
Trained batch 495 in epoch 7, gen_loss = 1.1224842781741773, disc_loss = 0.0005347723993567811
Trained batch 496 in epoch 7, gen_loss = 1.122418065785882, disc_loss = 0.0005343143759377093
Trained batch 497 in epoch 7, gen_loss = 1.1226215729991116, disc_loss = 0.0005336703566080904
Trained batch 498 in epoch 7, gen_loss = 1.1222106002136796, disc_loss = 0.0005337691495997807
Trained batch 499 in epoch 7, gen_loss = 1.1222630916833878, disc_loss = 0.0005346940879389876
Trained batch 500 in epoch 7, gen_loss = 1.1227437356512942, disc_loss = 0.000535723342000346
Trained batch 501 in epoch 7, gen_loss = 1.122598629904933, disc_loss = 0.0005374107692272178
Trained batch 502 in epoch 7, gen_loss = 1.1222209714753015, disc_loss = 0.0005381652460833705
Trained batch 503 in epoch 7, gen_loss = 1.1220267140676106, disc_loss = 0.0005384533056886063
Trained batch 504 in epoch 7, gen_loss = 1.1219824125271032, disc_loss = 0.0005388689478818963
Trained batch 505 in epoch 7, gen_loss = 1.1216114076229895, disc_loss = 0.0005386996532546719
Trained batch 506 in epoch 7, gen_loss = 1.1213942406445565, disc_loss = 0.0005385089096691528
Trained batch 507 in epoch 7, gen_loss = 1.1214208692077576, disc_loss = 0.0005382555779409971
Trained batch 508 in epoch 7, gen_loss = 1.1214260727108578, disc_loss = 0.0005378776466436657
Trained batch 509 in epoch 7, gen_loss = 1.1215510606765746, disc_loss = 0.000537324376708449
Trained batch 510 in epoch 7, gen_loss = 1.1212448911657538, disc_loss = 0.0005370128900296813
Trained batch 511 in epoch 7, gen_loss = 1.1214248357573524, disc_loss = 0.000537339666109915
Trained batch 512 in epoch 7, gen_loss = 1.120946754024275, disc_loss = 0.0005375122666690493
Trained batch 513 in epoch 7, gen_loss = 1.1208601081417693, disc_loss = 0.0005369856854673549
Trained batch 514 in epoch 7, gen_loss = 1.1208658704479921, disc_loss = 0.0005363753103753959
Trained batch 515 in epoch 7, gen_loss = 1.1207930175370948, disc_loss = 0.0005360422460645457
Trained batch 516 in epoch 7, gen_loss = 1.1207663761577937, disc_loss = 0.0005356266969386839
Trained batch 517 in epoch 7, gen_loss = 1.1209507402766166, disc_loss = 0.0005355045077557051
Trained batch 518 in epoch 7, gen_loss = 1.1210425478874604, disc_loss = 0.0005350446639382208
Trained batch 519 in epoch 7, gen_loss = 1.1213243181888874, disc_loss = 0.0005343391968171301
Trained batch 520 in epoch 7, gen_loss = 1.1208717500408414, disc_loss = 0.0005347800508594889
Trained batch 521 in epoch 7, gen_loss = 1.1205702902485128, disc_loss = 0.0005350088793009393
Trained batch 522 in epoch 7, gen_loss = 1.1202158227021561, disc_loss = 0.0005347248052637962
Trained batch 523 in epoch 7, gen_loss = 1.1197339564789341, disc_loss = 0.0005421034840473466
Trained batch 524 in epoch 7, gen_loss = 1.1197424375443232, disc_loss = 0.0005488043248104596
Trained batch 525 in epoch 7, gen_loss = 1.1198109234240572, disc_loss = 0.0005494901151317765
Trained batch 526 in epoch 7, gen_loss = 1.1201529781099062, disc_loss = 0.0005518002691397053
Trained batch 527 in epoch 7, gen_loss = 1.1200660663572224, disc_loss = 0.0005553524374590779
Trained batch 528 in epoch 7, gen_loss = 1.1201967983480212, disc_loss = 0.0005592291884676427
Trained batch 529 in epoch 7, gen_loss = 1.1197059596484562, disc_loss = 0.0005616058895989313
Trained batch 530 in epoch 7, gen_loss = 1.1197719660406957, disc_loss = 0.0005631458098026082
Trained batch 531 in epoch 7, gen_loss = 1.1204341431533484, disc_loss = 0.0005683266098683926
Trained batch 532 in epoch 7, gen_loss = 1.1201526727282756, disc_loss = 0.0005790482739566067
Trained batch 533 in epoch 7, gen_loss = 1.120547777258055, disc_loss = 0.0006114246841278738
Trained batch 534 in epoch 7, gen_loss = 1.1203880699995523, disc_loss = 0.0006744499596420058
Trained batch 535 in epoch 7, gen_loss = 1.120564829057722, disc_loss = 0.0007589697192794228
Trained batch 536 in epoch 7, gen_loss = 1.1208553607237406, disc_loss = 0.0008043972003167223
Trained batch 537 in epoch 7, gen_loss = 1.1208535964604205, disc_loss = 0.0008171294931415165
Trained batch 538 in epoch 7, gen_loss = 1.120589988572257, disc_loss = 0.0008209472796466099
Trained batch 539 in epoch 7, gen_loss = 1.1203910843089775, disc_loss = 0.0008252011758250538
Trained batch 540 in epoch 7, gen_loss = 1.1201965150022242, disc_loss = 0.0008296450038420943
Trained batch 541 in epoch 7, gen_loss = 1.1200332283093921, disc_loss = 0.0008306107945196593
Trained batch 542 in epoch 7, gen_loss = 1.120449998541212, disc_loss = 0.0008309847566807894
Trained batch 543 in epoch 7, gen_loss = 1.120479996151784, disc_loss = 0.0008328021120525912
Trained batch 544 in epoch 7, gen_loss = 1.1202448737730675, disc_loss = 0.0008350494733841774
Trained batch 545 in epoch 7, gen_loss = 1.1204169613101107, disc_loss = 0.0008363284397514873
Trained batch 546 in epoch 7, gen_loss = 1.120453786588456, disc_loss = 0.0008361102501765767
Trained batch 547 in epoch 7, gen_loss = 1.1204994601489853, disc_loss = 0.0008353563458035253
Trained batch 548 in epoch 7, gen_loss = 1.1205738967450807, disc_loss = 0.0008346004953391839
Trained batch 549 in epoch 7, gen_loss = 1.1202749722654168, disc_loss = 0.000835020619256697
Trained batch 550 in epoch 7, gen_loss = 1.1198827212172715, disc_loss = 0.0008349010639955179
Trained batch 551 in epoch 7, gen_loss = 1.1195480127049529, disc_loss = 0.0008342943112333212
Trained batch 552 in epoch 7, gen_loss = 1.1196229555938817, disc_loss = 0.0008337177707592428
Trained batch 553 in epoch 7, gen_loss = 1.1195334911561614, disc_loss = 0.0008329901008998903
Trained batch 554 in epoch 7, gen_loss = 1.1192272368852083, disc_loss = 0.000832420034265368
Trained batch 555 in epoch 7, gen_loss = 1.1192965464626285, disc_loss = 0.0008319109110874601
Trained batch 556 in epoch 7, gen_loss = 1.1192215687496658, disc_loss = 0.0008326328548928179
Trained batch 557 in epoch 7, gen_loss = 1.1193827527398277, disc_loss = 0.0008344907112075157
Trained batch 558 in epoch 7, gen_loss = 1.1194297909096869, disc_loss = 0.0008349777738321514
Trained batch 559 in epoch 7, gen_loss = 1.1197306539331164, disc_loss = 0.0008342182206173935
Trained batch 560 in epoch 7, gen_loss = 1.119802552323503, disc_loss = 0.0008331493078528675
Trained batch 561 in epoch 7, gen_loss = 1.1194133624911733, disc_loss = 0.0008322658992851578
Trained batch 562 in epoch 7, gen_loss = 1.119341863196866, disc_loss = 0.0008311512491467895
Trained batch 563 in epoch 7, gen_loss = 1.1193003720002817, disc_loss = 0.0008300611178335157
Trained batch 564 in epoch 7, gen_loss = 1.1192006355893296, disc_loss = 0.0008289404353667751
Trained batch 565 in epoch 7, gen_loss = 1.119054288830437, disc_loss = 0.0008279177634023474
Trained batch 566 in epoch 7, gen_loss = 1.1189665239324014, disc_loss = 0.0008269140538144603
Trained batch 567 in epoch 7, gen_loss = 1.1188926854183976, disc_loss = 0.0008262730169674245
Trained batch 568 in epoch 7, gen_loss = 1.1187956632754925, disc_loss = 0.0008260468690193124
Trained batch 569 in epoch 7, gen_loss = 1.1183860779854289, disc_loss = 0.0008255007871954596
Trained batch 570 in epoch 7, gen_loss = 1.1185729220744398, disc_loss = 0.0008244805273889636
Trained batch 571 in epoch 7, gen_loss = 1.1184034607001951, disc_loss = 0.0008235951833097448
Trained batch 572 in epoch 7, gen_loss = 1.1183695086842016, disc_loss = 0.0008224880538400739
Trained batch 573 in epoch 7, gen_loss = 1.1181330680847168, disc_loss = 0.0008219079199704003
Trained batch 574 in epoch 7, gen_loss = 1.1177605187374613, disc_loss = 0.0008221762589528225
Trained batch 575 in epoch 7, gen_loss = 1.1178225841787126, disc_loss = 0.0008214163969392353
Trained batch 576 in epoch 7, gen_loss = 1.1180428756171743, disc_loss = 0.0008208130241196765
Trained batch 577 in epoch 7, gen_loss = 1.118134104050567, disc_loss = 0.0008203961879441356
Trained batch 578 in epoch 7, gen_loss = 1.1179232286459835, disc_loss = 0.0008203954318288388
Trained batch 579 in epoch 7, gen_loss = 1.1176513202231506, disc_loss = 0.000819948933085784
Trained batch 580 in epoch 7, gen_loss = 1.1176247788583555, disc_loss = 0.0008191324760757664
Trained batch 581 in epoch 7, gen_loss = 1.1180448973506587, disc_loss = 0.0008183495279508955
Trained batch 582 in epoch 7, gen_loss = 1.1181083710075037, disc_loss = 0.0008174553702352369
Trained batch 583 in epoch 7, gen_loss = 1.1180093728312075, disc_loss = 0.0008163936503080225
Trained batch 584 in epoch 7, gen_loss = 1.1179132652078938, disc_loss = 0.0008153620014702464
Trained batch 585 in epoch 7, gen_loss = 1.1178041127964906, disc_loss = 0.0008143030005133093
Trained batch 586 in epoch 7, gen_loss = 1.1176045262833876, disc_loss = 0.0008134394311081353
Trained batch 587 in epoch 7, gen_loss = 1.1173279894655253, disc_loss = 0.0008125968167597315
Trained batch 588 in epoch 7, gen_loss = 1.1171916179826993, disc_loss = 0.000811895349813354
Trained batch 589 in epoch 7, gen_loss = 1.1172233158248965, disc_loss = 0.000811237708472556
Trained batch 590 in epoch 7, gen_loss = 1.1169102126370025, disc_loss = 0.0008110565944286591
Trained batch 591 in epoch 7, gen_loss = 1.1167998864642672, disc_loss = 0.0008108119975593188
Trained batch 592 in epoch 7, gen_loss = 1.116730684072131, disc_loss = 0.0008103540423527418
Trained batch 593 in epoch 7, gen_loss = 1.1169770892822382, disc_loss = 0.0008096311338327594
Trained batch 594 in epoch 7, gen_loss = 1.1168578287132649, disc_loss = 0.0008087248231911397
Trained batch 595 in epoch 7, gen_loss = 1.1169006019430672, disc_loss = 0.000807705446863379
Trained batch 596 in epoch 7, gen_loss = 1.1172878661347394, disc_loss = 0.0008069311344409728
Trained batch 597 in epoch 7, gen_loss = 1.117178063627868, disc_loss = 0.0008059667006301823
Trained batch 598 in epoch 7, gen_loss = 1.1169968800672108, disc_loss = 0.0008052488718534982
Trained batch 599 in epoch 7, gen_loss = 1.1171909671028455, disc_loss = 0.0008043180792810745
Trained batch 600 in epoch 7, gen_loss = 1.1174886497403937, disc_loss = 0.0008035290132869637
Trained batch 601 in epoch 7, gen_loss = 1.118214375849974, disc_loss = 0.0008028188694456624
Trained batch 602 in epoch 7, gen_loss = 1.1188869633484835, disc_loss = 0.0008020592076190559
Trained batch 603 in epoch 7, gen_loss = 1.1187075247235645, disc_loss = 0.0008013301937913542
Trained batch 604 in epoch 7, gen_loss = 1.1184710055343376, disc_loss = 0.0008004513018007375
Trained batch 605 in epoch 7, gen_loss = 1.118396001680456, disc_loss = 0.0007998770112199624
Trained batch 606 in epoch 7, gen_loss = 1.1180237980415244, disc_loss = 0.0008037039619734123
Trained batch 607 in epoch 7, gen_loss = 1.1181494818118058, disc_loss = 0.0008047814883172434
Trained batch 608 in epoch 7, gen_loss = 1.1182593123861917, disc_loss = 0.0008040020691292255
Trained batch 609 in epoch 7, gen_loss = 1.1184386676452198, disc_loss = 0.0008034507795661634
Trained batch 610 in epoch 7, gen_loss = 1.1182097256086072, disc_loss = 0.0008039656192497366
Trained batch 611 in epoch 7, gen_loss = 1.117860293758461, disc_loss = 0.0008052909369105846
Trained batch 612 in epoch 7, gen_loss = 1.1178031122314989, disc_loss = 0.0008055590082619523
Trained batch 613 in epoch 7, gen_loss = 1.11798259402331, disc_loss = 0.0008055122579939561
Trained batch 614 in epoch 7, gen_loss = 1.1177344637188484, disc_loss = 0.0008057205325557577
Trained batch 615 in epoch 7, gen_loss = 1.1175391611147236, disc_loss = 0.0008057297738394647
Trained batch 616 in epoch 7, gen_loss = 1.1173936123786135, disc_loss = 0.0008052262811468894
Trained batch 617 in epoch 7, gen_loss = 1.117393125704577, disc_loss = 0.0008047994146841046
Trained batch 618 in epoch 7, gen_loss = 1.117647643909701, disc_loss = 0.000804289928795894
Trained batch 619 in epoch 7, gen_loss = 1.1176850406392929, disc_loss = 0.0008034257386410196
Trained batch 620 in epoch 7, gen_loss = 1.1175239549742804, disc_loss = 0.0008026629811323971
Trained batch 621 in epoch 7, gen_loss = 1.1176340665272961, disc_loss = 0.0008022003390619844
Trained batch 622 in epoch 7, gen_loss = 1.117742461626258, disc_loss = 0.0008014048915846912
Trained batch 623 in epoch 7, gen_loss = 1.1177343622041054, disc_loss = 0.0008005306874507276
Trained batch 624 in epoch 7, gen_loss = 1.117609545993805, disc_loss = 0.0008000993343652227
Trained batch 625 in epoch 7, gen_loss = 1.1174979923060908, disc_loss = 0.0007998013035261285
Trained batch 626 in epoch 7, gen_loss = 1.1175502526322811, disc_loss = 0.0007991682511849583
Trained batch 627 in epoch 7, gen_loss = 1.11807520630633, disc_loss = 0.0008002366822745516
Trained batch 628 in epoch 7, gen_loss = 1.1176281247305757, disc_loss = 0.000801052687466548
Trained batch 629 in epoch 7, gen_loss = 1.1177456018470582, disc_loss = 0.0008012973340454563
Trained batch 630 in epoch 7, gen_loss = 1.1175888955309727, disc_loss = 0.0008021103244695684
Trained batch 631 in epoch 7, gen_loss = 1.1178191431526896, disc_loss = 0.0008024707169768797
Trained batch 632 in epoch 7, gen_loss = 1.1180496985125128, disc_loss = 0.0008022786613108147
Trained batch 633 in epoch 7, gen_loss = 1.118043973712891, disc_loss = 0.0008015354165069396
Trained batch 634 in epoch 7, gen_loss = 1.1176936179634154, disc_loss = 0.0008008103238947608
Trained batch 635 in epoch 7, gen_loss = 1.1173714082570945, disc_loss = 0.0008003193898106898
Trained batch 636 in epoch 7, gen_loss = 1.1172482793334888, disc_loss = 0.0008010457957945098
Trained batch 637 in epoch 7, gen_loss = 1.1170420077714054, disc_loss = 0.0008011459282090847
Trained batch 638 in epoch 7, gen_loss = 1.1166789313437233, disc_loss = 0.0008004425145658892
Trained batch 639 in epoch 7, gen_loss = 1.1162994503974915, disc_loss = 0.0007997650403126499
Trained batch 640 in epoch 7, gen_loss = 1.1166806128021336, disc_loss = 0.0007991024171255199
Trained batch 641 in epoch 7, gen_loss = 1.116893110245559, disc_loss = 0.0007985810585875054
Trained batch 642 in epoch 7, gen_loss = 1.1169967870133846, disc_loss = 0.0007977932426901237
Trained batch 643 in epoch 7, gen_loss = 1.1168162691297, disc_loss = 0.0007969730083024605
Trained batch 644 in epoch 7, gen_loss = 1.116645726307418, disc_loss = 0.0007967178062413992
Trained batch 645 in epoch 7, gen_loss = 1.116834673903675, disc_loss = 0.0007964258797124537
Trained batch 646 in epoch 7, gen_loss = 1.1169407855966913, disc_loss = 0.0007958145465629306
Trained batch 647 in epoch 7, gen_loss = 1.1168625275661916, disc_loss = 0.0007950392930272048
Trained batch 648 in epoch 7, gen_loss = 1.1167689143050066, disc_loss = 0.000794218172797182
Trained batch 649 in epoch 7, gen_loss = 1.1165806104586675, disc_loss = 0.0007933048580553777
Trained batch 650 in epoch 7, gen_loss = 1.1167876458570887, disc_loss = 0.0007923468980828576
Trained batch 651 in epoch 7, gen_loss = 1.116955632081061, disc_loss = 0.0007914057255750615
Trained batch 652 in epoch 7, gen_loss = 1.117117961734579, disc_loss = 0.000790436251904508
Trained batch 653 in epoch 7, gen_loss = 1.1172461099580888, disc_loss = 0.0007894935333195807
Trained batch 654 in epoch 7, gen_loss = 1.1171118146590604, disc_loss = 0.0007884679188554616
Trained batch 655 in epoch 7, gen_loss = 1.1173888404921788, disc_loss = 0.0007874944792935666
Trained batch 656 in epoch 7, gen_loss = 1.1171151353343982, disc_loss = 0.0007867225504125386
Trained batch 657 in epoch 7, gen_loss = 1.1170238983848537, disc_loss = 0.0007857324722465192
Trained batch 658 in epoch 7, gen_loss = 1.116988859607164, disc_loss = 0.0007850047227438456
Trained batch 659 in epoch 7, gen_loss = 1.1168743614897583, disc_loss = 0.0007840566039125076
Trained batch 660 in epoch 7, gen_loss = 1.1169662090545343, disc_loss = 0.000783224956463313
Trained batch 661 in epoch 7, gen_loss = 1.1168373827667755, disc_loss = 0.0007822911042915805
Trained batch 662 in epoch 7, gen_loss = 1.1168604584840627, disc_loss = 0.0007813510064656008
Trained batch 663 in epoch 7, gen_loss = 1.116852951785886, disc_loss = 0.0007805077793599627
Trained batch 664 in epoch 7, gen_loss = 1.1166033550312644, disc_loss = 0.0007800378570052151
Trained batch 665 in epoch 7, gen_loss = 1.1165690072126933, disc_loss = 0.0007793147558329436
Trained batch 666 in epoch 7, gen_loss = 1.116396103752428, disc_loss = 0.00077843689284456
Trained batch 667 in epoch 7, gen_loss = 1.1165562478189697, disc_loss = 0.0007775464243156045
Trained batch 668 in epoch 7, gen_loss = 1.116482949310354, disc_loss = 0.0007766588275399656
Trained batch 669 in epoch 7, gen_loss = 1.1163036361559113, disc_loss = 0.0007758053947598916
Trained batch 670 in epoch 7, gen_loss = 1.1161467013700175, disc_loss = 0.0007748728650534455
Trained batch 671 in epoch 7, gen_loss = 1.1161765120036544, disc_loss = 0.0007740190808254695
Trained batch 672 in epoch 7, gen_loss = 1.1161766726230264, disc_loss = 0.0007732260560807647
Trained batch 673 in epoch 7, gen_loss = 1.1160912903727693, disc_loss = 0.0007724708552072094
Trained batch 674 in epoch 7, gen_loss = 1.115911128256056, disc_loss = 0.0007718227877760202
Trained batch 675 in epoch 7, gen_loss = 1.1162262705303507, disc_loss = 0.0007714534422120778
Trained batch 676 in epoch 7, gen_loss = 1.1163527065753232, disc_loss = 0.0007708954614922618
Trained batch 677 in epoch 7, gen_loss = 1.1164598934418333, disc_loss = 0.0007700554380044142
Trained batch 678 in epoch 7, gen_loss = 1.1166251641485583, disc_loss = 0.0007691983629712617
Trained batch 679 in epoch 7, gen_loss = 1.1165462120490917, disc_loss = 0.0007683670903990039
Trained batch 680 in epoch 7, gen_loss = 1.1165117498011317, disc_loss = 0.0007676140736940142
Trained batch 681 in epoch 7, gen_loss = 1.1167195418363443, disc_loss = 0.0007668531319099005
Trained batch 682 in epoch 7, gen_loss = 1.1167544103820712, disc_loss = 0.0007659491631443582
Trained batch 683 in epoch 7, gen_loss = 1.1165375320883522, disc_loss = 0.0007651639315080985
Trained batch 684 in epoch 7, gen_loss = 1.1165359968686626, disc_loss = 0.0007645039627456827
Trained batch 685 in epoch 7, gen_loss = 1.1165006051258164, disc_loss = 0.0007638943003236524
Trained batch 686 in epoch 7, gen_loss = 1.1165888732871287, disc_loss = 0.0007630422599172237
Trained batch 687 in epoch 7, gen_loss = 1.1165422720964564, disc_loss = 0.0007623631281920859
Trained batch 688 in epoch 7, gen_loss = 1.1166292321699278, disc_loss = 0.0007621631623361177
Trained batch 689 in epoch 7, gen_loss = 1.1166306303895037, disc_loss = 0.0007619319372600369
Trained batch 690 in epoch 7, gen_loss = 1.1166798207590791, disc_loss = 0.0007611662971054462
Trained batch 691 in epoch 7, gen_loss = 1.1165731564767098, disc_loss = 0.0007604697045433232
Trained batch 692 in epoch 7, gen_loss = 1.1164441069139202, disc_loss = 0.0007600039558569648
Trained batch 693 in epoch 7, gen_loss = 1.1164604858294, disc_loss = 0.0007595026927814122
Trained batch 694 in epoch 7, gen_loss = 1.1163562387013606, disc_loss = 0.0007588671768572443
Trained batch 695 in epoch 7, gen_loss = 1.1166267391593976, disc_loss = 0.0007581574402410161
Trained batch 696 in epoch 7, gen_loss = 1.1166370352850412, disc_loss = 0.0007575741591304641
Trained batch 697 in epoch 7, gen_loss = 1.1163960614996857, disc_loss = 0.0007571438584174997
Trained batch 698 in epoch 7, gen_loss = 1.1161192613780413, disc_loss = 0.0007573115908755129
Trained batch 699 in epoch 7, gen_loss = 1.1162286973851068, disc_loss = 0.0007574574618463106
Trained batch 700 in epoch 7, gen_loss = 1.1163437903012428, disc_loss = 0.0007572113049608329
Trained batch 701 in epoch 7, gen_loss = 1.1164362699727388, disc_loss = 0.0007567287517055316
Trained batch 702 in epoch 7, gen_loss = 1.1164752634117647, disc_loss = 0.000756229443412594
Trained batch 703 in epoch 7, gen_loss = 1.1165048921142111, disc_loss = 0.0007556448117921635
Trained batch 704 in epoch 7, gen_loss = 1.1167869616062083, disc_loss = 0.0007549153610627193
Trained batch 705 in epoch 7, gen_loss = 1.1166203791966858, disc_loss = 0.0007542947792904366
Trained batch 706 in epoch 7, gen_loss = 1.116468215258489, disc_loss = 0.0007537297994622736
Trained batch 707 in epoch 7, gen_loss = 1.11638139684995, disc_loss = 0.0007532191382388757
Trained batch 708 in epoch 7, gen_loss = 1.1165035613333052, disc_loss = 0.0007527893941765894
Trained batch 709 in epoch 7, gen_loss = 1.1166946926587065, disc_loss = 0.0007525387681134432
Trained batch 710 in epoch 7, gen_loss = 1.1166645337090042, disc_loss = 0.0007521122949421059
Trained batch 711 in epoch 7, gen_loss = 1.11672463008527, disc_loss = 0.000751375594518322
Trained batch 712 in epoch 7, gen_loss = 1.1165879275989399, disc_loss = 0.0007509114409219389
Trained batch 713 in epoch 7, gen_loss = 1.1164781963791834, disc_loss = 0.0007502699862765011
Trained batch 714 in epoch 7, gen_loss = 1.116571908230548, disc_loss = 0.000749796818666261
Trained batch 715 in epoch 7, gen_loss = 1.1167306378900006, disc_loss = 0.0007491803816310748
Trained batch 716 in epoch 7, gen_loss = 1.1168170455775666, disc_loss = 0.0007484432407101971
Trained batch 717 in epoch 7, gen_loss = 1.1166632960765808, disc_loss = 0.0007477974550081722
Trained batch 718 in epoch 7, gen_loss = 1.116493986777039, disc_loss = 0.0007472488220232365
Trained batch 719 in epoch 7, gen_loss = 1.1163060132000182, disc_loss = 0.0007466912924731635
Trained batch 720 in epoch 7, gen_loss = 1.116356771630487, disc_loss = 0.0007461531151191205
Trained batch 721 in epoch 7, gen_loss = 1.1163603272134248, disc_loss = 0.0007455054916926934
Trained batch 722 in epoch 7, gen_loss = 1.1165010136027884, disc_loss = 0.000744906278053942
Trained batch 723 in epoch 7, gen_loss = 1.1163515226287737, disc_loss = 0.0007443196357282371
Trained batch 724 in epoch 7, gen_loss = 1.1163109263058366, disc_loss = 0.0007435728320430418
Trained batch 725 in epoch 7, gen_loss = 1.11603917382637, disc_loss = 0.0007428118340051624
Trained batch 726 in epoch 7, gen_loss = 1.115945890648329, disc_loss = 0.0007419315440155261
Trained batch 727 in epoch 7, gen_loss = 1.116266702393909, disc_loss = 0.0007410672012186266
Trained batch 728 in epoch 7, gen_loss = 1.1164438811185755, disc_loss = 0.0007402294567551091
Trained batch 729 in epoch 7, gen_loss = 1.1166926677912883, disc_loss = 0.0007396583506767319
Trained batch 730 in epoch 7, gen_loss = 1.1168358389558284, disc_loss = 0.0007391671885251514
Trained batch 731 in epoch 7, gen_loss = 1.1169129797344, disc_loss = 0.000738739817254716
Trained batch 732 in epoch 7, gen_loss = 1.1168271995989394, disc_loss = 0.0007380545730918574
Trained batch 733 in epoch 7, gen_loss = 1.1168195933347178, disc_loss = 0.0007372707191490561
Trained batch 734 in epoch 7, gen_loss = 1.116842822152741, disc_loss = 0.00073645526793117
Trained batch 735 in epoch 7, gen_loss = 1.117245989487223, disc_loss = 0.0007359346271226494
Trained batch 736 in epoch 7, gen_loss = 1.1176358202581005, disc_loss = 0.0007353167063131704
Trained batch 737 in epoch 7, gen_loss = 1.1174901849855252, disc_loss = 0.0007346024601930074
Trained batch 738 in epoch 7, gen_loss = 1.1174433073268368, disc_loss = 0.0007338797277314097
Trained batch 739 in epoch 7, gen_loss = 1.1175008482224233, disc_loss = 0.0007331783262260787
Trained batch 740 in epoch 7, gen_loss = 1.1173836771454084, disc_loss = 0.0007324527884131567
Trained batch 741 in epoch 7, gen_loss = 1.1173297539554194, disc_loss = 0.0007317325945882719
Trained batch 742 in epoch 7, gen_loss = 1.117266736473402, disc_loss = 0.0007312281684283152
Trained batch 743 in epoch 7, gen_loss = 1.117332322302685, disc_loss = 0.0007307097596342936
Trained batch 744 in epoch 7, gen_loss = 1.1173236133268216, disc_loss = 0.0007299741724234124
Trained batch 745 in epoch 7, gen_loss = 1.1170751094498519, disc_loss = 0.0007293195847489611
Trained batch 746 in epoch 7, gen_loss = 1.1170623718974102, disc_loss = 0.0007286598387000075
Trained batch 747 in epoch 7, gen_loss = 1.117076104178148, disc_loss = 0.0007280793880371758
Trained batch 748 in epoch 7, gen_loss = 1.1171682980732225, disc_loss = 0.0007274906227816808
Trained batch 749 in epoch 7, gen_loss = 1.1171050709088644, disc_loss = 0.0007270483025931753
Trained batch 750 in epoch 7, gen_loss = 1.1168256250424646, disc_loss = 0.0007267773940068882
Trained batch 751 in epoch 7, gen_loss = 1.1168492585420609, disc_loss = 0.0007262601978428837
Trained batch 752 in epoch 7, gen_loss = 1.1167657169529484, disc_loss = 0.000725549459271875
Trained batch 753 in epoch 7, gen_loss = 1.1167565253748502, disc_loss = 0.0007248049196543231
Trained batch 754 in epoch 7, gen_loss = 1.1165578343220894, disc_loss = 0.0007241448349919207
Trained batch 755 in epoch 7, gen_loss = 1.116814179552926, disc_loss = 0.0007234308939866313
Trained batch 756 in epoch 7, gen_loss = 1.1167491224042019, disc_loss = 0.0007226575078560184
Trained batch 757 in epoch 7, gen_loss = 1.1168858982956817, disc_loss = 0.0007219087139895004
Trained batch 758 in epoch 7, gen_loss = 1.1170727804558394, disc_loss = 0.0007211471215974569
Trained batch 759 in epoch 7, gen_loss = 1.1169704336869088, disc_loss = 0.000720369254850084
Trained batch 760 in epoch 7, gen_loss = 1.1170889010723881, disc_loss = 0.0007196199286954891
Trained batch 761 in epoch 7, gen_loss = 1.1170221371600635, disc_loss = 0.0007188852353816243
Trained batch 762 in epoch 7, gen_loss = 1.11703644745628, disc_loss = 0.0007181260190673141
Trained batch 763 in epoch 7, gen_loss = 1.116911890463055, disc_loss = 0.0007174051607614908
Trained batch 764 in epoch 7, gen_loss = 1.1169775227316066, disc_loss = 0.0007167195218380881
Trained batch 765 in epoch 7, gen_loss = 1.1171383863952078, disc_loss = 0.0007159636638160094
Trained batch 766 in epoch 7, gen_loss = 1.116966118246822, disc_loss = 0.0007151927254247726
Trained batch 767 in epoch 7, gen_loss = 1.1169013654192288, disc_loss = 0.0007144319466381907
Trained batch 768 in epoch 7, gen_loss = 1.1168279161068801, disc_loss = 0.0007137809074707862
Trained batch 769 in epoch 7, gen_loss = 1.1166812509685369, disc_loss = 0.0007132315658964217
Trained batch 770 in epoch 7, gen_loss = 1.1167670465165076, disc_loss = 0.0007125959766668723
Trained batch 771 in epoch 7, gen_loss = 1.116870707644082, disc_loss = 0.0007118592645897267
Trained batch 772 in epoch 7, gen_loss = 1.1167053978933554, disc_loss = 0.0007111457483019177
Trained batch 773 in epoch 7, gen_loss = 1.1168529825617177, disc_loss = 0.0007104179281005889
Trained batch 774 in epoch 7, gen_loss = 1.116982655986663, disc_loss = 0.0007098555567321337
Trained batch 775 in epoch 7, gen_loss = 1.116986671059402, disc_loss = 0.0007092077754050572
Trained batch 776 in epoch 7, gen_loss = 1.116994522099636, disc_loss = 0.000708482536843719
Trained batch 777 in epoch 7, gen_loss = 1.1168910002953596, disc_loss = 0.000707744490801911
Trained batch 778 in epoch 7, gen_loss = 1.1168693564210532, disc_loss = 0.0007069976548106853
Trained batch 779 in epoch 7, gen_loss = 1.1167002260684966, disc_loss = 0.000706325937006533
Trained batch 780 in epoch 7, gen_loss = 1.1169670389800614, disc_loss = 0.0007059933092016142
Trained batch 781 in epoch 7, gen_loss = 1.1168560506132863, disc_loss = 0.000705739367212725
Trained batch 782 in epoch 7, gen_loss = 1.1168040802956845, disc_loss = 0.0007054413160739471
Trained batch 783 in epoch 7, gen_loss = 1.116811253130436, disc_loss = 0.0007051235524697256
Trained batch 784 in epoch 7, gen_loss = 1.1165065413827349, disc_loss = 0.0007050017811985283
Trained batch 785 in epoch 7, gen_loss = 1.1163725077195932, disc_loss = 0.000704588119837997
Trained batch 786 in epoch 7, gen_loss = 1.1166606213722325, disc_loss = 0.0007040888007120508
Trained batch 787 in epoch 7, gen_loss = 1.1165447924191576, disc_loss = 0.0007034590642544415
Trained batch 788 in epoch 7, gen_loss = 1.1165161138100619, disc_loss = 0.0007028870508055579
Trained batch 789 in epoch 7, gen_loss = 1.116253898943527, disc_loss = 0.0007023746491655931
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 0.9542849659919739, disc_loss = 0.00037643525865860283
Trained batch 1 in epoch 8, gen_loss = 0.9563463628292084, disc_loss = 0.00034380893339402974
Trained batch 2 in epoch 8, gen_loss = 0.9826246698697408, disc_loss = 0.0002904317273835962
Trained batch 3 in epoch 8, gen_loss = 1.0015879422426224, disc_loss = 0.0002934441108664032
Trained batch 4 in epoch 8, gen_loss = 1.0670199751853944, disc_loss = 0.00030797738290857526
Trained batch 5 in epoch 8, gen_loss = 1.0848674476146698, disc_loss = 0.00029533131601056084
Trained batch 6 in epoch 8, gen_loss = 1.1375809141567774, disc_loss = 0.0002846744963400332
Trained batch 7 in epoch 8, gen_loss = 1.1320027336478233, disc_loss = 0.0002944243260571966
Trained batch 8 in epoch 8, gen_loss = 1.11793452501297, disc_loss = 0.0002972513595725306
Trained batch 9 in epoch 8, gen_loss = 1.155301719903946, disc_loss = 0.00029927873838460074
Trained batch 10 in epoch 8, gen_loss = 1.1462551084431736, disc_loss = 0.00028948088848582387
Trained batch 11 in epoch 8, gen_loss = 1.1593330254157383, disc_loss = 0.0002929042032822811
Trained batch 12 in epoch 8, gen_loss = 1.1636398709737337, disc_loss = 0.0002976770841856845
Trained batch 13 in epoch 8, gen_loss = 1.145938596555165, disc_loss = 0.00029701439676240886
Trained batch 14 in epoch 8, gen_loss = 1.1468140403429667, disc_loss = 0.0002923425044476365
Trained batch 15 in epoch 8, gen_loss = 1.1487088166177273, disc_loss = 0.00028914348968100967
Trained batch 16 in epoch 8, gen_loss = 1.151957662666545, disc_loss = 0.00028335710093789897
Trained batch 17 in epoch 8, gen_loss = 1.1491850051614974, disc_loss = 0.00028142176759299927
Trained batch 18 in epoch 8, gen_loss = 1.1544911830048812, disc_loss = 0.0002822123680839707
Trained batch 19 in epoch 8, gen_loss = 1.1475832492113114, disc_loss = 0.0002849904769391287
Trained batch 20 in epoch 8, gen_loss = 1.1404551068941753, disc_loss = 0.00028338674331150414
Trained batch 21 in epoch 8, gen_loss = 1.1313682875849984, disc_loss = 0.00028305686414982614
Trained batch 22 in epoch 8, gen_loss = 1.1239518963772317, disc_loss = 0.0002856203146106766
Trained batch 23 in epoch 8, gen_loss = 1.1150284583369892, disc_loss = 0.000289389319732436
Trained batch 24 in epoch 8, gen_loss = 1.1196552157402038, disc_loss = 0.00028794060053769497
Trained batch 25 in epoch 8, gen_loss = 1.1107830909582286, disc_loss = 0.00028490526500928146
Trained batch 26 in epoch 8, gen_loss = 1.1109163363774617, disc_loss = 0.0002797693779467846
Trained batch 27 in epoch 8, gen_loss = 1.1085919908114843, disc_loss = 0.0002779241066101739
Trained batch 28 in epoch 8, gen_loss = 1.1210209172347496, disc_loss = 0.0002760451245884379
Trained batch 29 in epoch 8, gen_loss = 1.121072769165039, disc_loss = 0.0002773590235544058
Trained batch 30 in epoch 8, gen_loss = 1.12196486226974, disc_loss = 0.00027194345227232383
Trained batch 31 in epoch 8, gen_loss = 1.12501560151577, disc_loss = 0.0002670168410077167
Trained batch 32 in epoch 8, gen_loss = 1.1236624717712402, disc_loss = 0.0002655739522059307
Trained batch 33 in epoch 8, gen_loss = 1.120709412238177, disc_loss = 0.00026550253182101776
Trained batch 34 in epoch 8, gen_loss = 1.133128193446568, disc_loss = 0.0002689783469707306
Trained batch 35 in epoch 8, gen_loss = 1.128495032588641, disc_loss = 0.00027327477760587097
Trained batch 36 in epoch 8, gen_loss = 1.1335975785513182, disc_loss = 0.0002774676831904799
Trained batch 37 in epoch 8, gen_loss = 1.1344214756237834, disc_loss = 0.00028075163994033476
Trained batch 38 in epoch 8, gen_loss = 1.1333811237261846, disc_loss = 0.00028269824598772597
Trained batch 39 in epoch 8, gen_loss = 1.1322011008858681, disc_loss = 0.00028453594786697066
Trained batch 40 in epoch 8, gen_loss = 1.129791482192714, disc_loss = 0.0002940765279629154
Trained batch 41 in epoch 8, gen_loss = 1.12942949788911, disc_loss = 0.0003023514395213819
Trained batch 42 in epoch 8, gen_loss = 1.1291535718496455, disc_loss = 0.00030980341415310844
Trained batch 43 in epoch 8, gen_loss = 1.1291618008505215, disc_loss = 0.0003141753622912802
Trained batch 44 in epoch 8, gen_loss = 1.1323282069630094, disc_loss = 0.0003154513762435979
Trained batch 45 in epoch 8, gen_loss = 1.1363014488116554, disc_loss = 0.00031679607522876364
Trained batch 46 in epoch 8, gen_loss = 1.1356024171443695, disc_loss = 0.0003136390373680463
Trained batch 47 in epoch 8, gen_loss = 1.1334912665188313, disc_loss = 0.0003091397590348303
Trained batch 48 in epoch 8, gen_loss = 1.1315223671952073, disc_loss = 0.00030519873318404946
Trained batch 49 in epoch 8, gen_loss = 1.131676596403122, disc_loss = 0.00030343737191287803
Trained batch 50 in epoch 8, gen_loss = 1.1322636171883227, disc_loss = 0.0003026341314669516
Trained batch 51 in epoch 8, gen_loss = 1.131800528902274, disc_loss = 0.00029999996919426706
Trained batch 52 in epoch 8, gen_loss = 1.127022496934207, disc_loss = 0.00029968341976131823
Trained batch 53 in epoch 8, gen_loss = 1.126765106563215, disc_loss = 0.00030332374525541026
Trained batch 54 in epoch 8, gen_loss = 1.126447739384391, disc_loss = 0.00031100464799568395
Trained batch 55 in epoch 8, gen_loss = 1.1247572696634702, disc_loss = 0.0003203192071461152
Trained batch 56 in epoch 8, gen_loss = 1.1260580315924527, disc_loss = 0.000329007964689497
Trained batch 57 in epoch 8, gen_loss = 1.1269784888316845, disc_loss = 0.00033447708445801883
Trained batch 58 in epoch 8, gen_loss = 1.1265986561775208, disc_loss = 0.00034018427402893935
Trained batch 59 in epoch 8, gen_loss = 1.1262827346722284, disc_loss = 0.0003486926611609912
Trained batch 60 in epoch 8, gen_loss = 1.1271196300866173, disc_loss = 0.00036207879879168373
Trained batch 61 in epoch 8, gen_loss = 1.125690359261728, disc_loss = 0.0003763868235475985
Trained batch 62 in epoch 8, gen_loss = 1.125680771138933, disc_loss = 0.0003887495778534295
Trained batch 63 in epoch 8, gen_loss = 1.1263753911480308, disc_loss = 0.0003956451930662297
Trained batch 64 in epoch 8, gen_loss = 1.1257416881047762, disc_loss = 0.0003985688307483752
Trained batch 65 in epoch 8, gen_loss = 1.1238730649153392, disc_loss = 0.0003978094197615671
Trained batch 66 in epoch 8, gen_loss = 1.1223939328051324, disc_loss = 0.00039649072060632563
Trained batch 67 in epoch 8, gen_loss = 1.1206126256900675, disc_loss = 0.0003935622957856942
Trained batch 68 in epoch 8, gen_loss = 1.121246594449748, disc_loss = 0.00038958147701307917
Trained batch 69 in epoch 8, gen_loss = 1.1195767206805094, disc_loss = 0.0003863886738794723
Trained batch 70 in epoch 8, gen_loss = 1.1186345337142407, disc_loss = 0.0003824859464452536
Trained batch 71 in epoch 8, gen_loss = 1.1191367051667638, disc_loss = 0.00037880509565487347
Trained batch 72 in epoch 8, gen_loss = 1.1186227414705983, disc_loss = 0.00037516451236227374
Trained batch 73 in epoch 8, gen_loss = 1.1174739575063861, disc_loss = 0.0003724223065915253
Trained batch 74 in epoch 8, gen_loss = 1.1196594103177389, disc_loss = 0.00037083128050047285
Trained batch 75 in epoch 8, gen_loss = 1.1198772733148776, disc_loss = 0.00036873573337384426
Trained batch 76 in epoch 8, gen_loss = 1.1180340578029682, disc_loss = 0.0003673466112027731
Trained batch 77 in epoch 8, gen_loss = 1.1174990213834322, disc_loss = 0.00036552771752422606
Trained batch 78 in epoch 8, gen_loss = 1.116516022742549, disc_loss = 0.0003659177896282282
Trained batch 79 in epoch 8, gen_loss = 1.116194373369217, disc_loss = 0.00036877332813674003
Trained batch 80 in epoch 8, gen_loss = 1.1195887268325428, disc_loss = 0.0003728806607987168
Trained batch 81 in epoch 8, gen_loss = 1.119853733516321, disc_loss = 0.0003747508332109158
Trained batch 82 in epoch 8, gen_loss = 1.1192128399768508, disc_loss = 0.00037365014156739014
Trained batch 83 in epoch 8, gen_loss = 1.1203525903679075, disc_loss = 0.00037250057799350804
Trained batch 84 in epoch 8, gen_loss = 1.1195111008251415, disc_loss = 0.000373932188428144
Trained batch 85 in epoch 8, gen_loss = 1.1199090910512348, disc_loss = 0.00037538473212449854
Trained batch 86 in epoch 8, gen_loss = 1.1216235503383067, disc_loss = 0.00037492908483529035
Trained batch 87 in epoch 8, gen_loss = 1.118582691658627, disc_loss = 0.00037639114246055465
Trained batch 88 in epoch 8, gen_loss = 1.1157424021302984, disc_loss = 0.00037545813736440404
Trained batch 89 in epoch 8, gen_loss = 1.1153632521629333, disc_loss = 0.0003725982199183717
Trained batch 90 in epoch 8, gen_loss = 1.1146121928980062, disc_loss = 0.00037079505696905533
Trained batch 91 in epoch 8, gen_loss = 1.11266915694527, disc_loss = 0.0003719433988526757
Trained batch 92 in epoch 8, gen_loss = 1.11571067507549, disc_loss = 0.00037484662239602515
Trained batch 93 in epoch 8, gen_loss = 1.1150508548351044, disc_loss = 0.0003772323854060774
Trained batch 94 in epoch 8, gen_loss = 1.1161836573952122, disc_loss = 0.0003775239735994929
Trained batch 95 in epoch 8, gen_loss = 1.11746097356081, disc_loss = 0.0003776273010013635
Trained batch 96 in epoch 8, gen_loss = 1.1158765732627554, disc_loss = 0.00037755487228986165
Trained batch 97 in epoch 8, gen_loss = 1.115480894336895, disc_loss = 0.000377262120235507
Trained batch 98 in epoch 8, gen_loss = 1.1179142209014508, disc_loss = 0.0003764714750683528
Trained batch 99 in epoch 8, gen_loss = 1.119410966038704, disc_loss = 0.0003775375258555869
Trained batch 100 in epoch 8, gen_loss = 1.1174497633877367, disc_loss = 0.0003793199572137022
Trained batch 101 in epoch 8, gen_loss = 1.1167580315879746, disc_loss = 0.0003801232068166
Trained batch 102 in epoch 8, gen_loss = 1.1166200354261306, disc_loss = 0.0003787376381738283
Trained batch 103 in epoch 8, gen_loss = 1.1143034186500769, disc_loss = 0.0003790713821077728
Trained batch 104 in epoch 8, gen_loss = 1.1163919897306533, disc_loss = 0.0003802076068712354
Trained batch 105 in epoch 8, gen_loss = 1.1156847291397598, disc_loss = 0.0003808606872450393
Trained batch 106 in epoch 8, gen_loss = 1.1143110840120047, disc_loss = 0.00038018399773646477
Trained batch 107 in epoch 8, gen_loss = 1.1153528353682272, disc_loss = 0.00037986464499058286
Trained batch 108 in epoch 8, gen_loss = 1.115148607197158, disc_loss = 0.0003783426969392234
Trained batch 109 in epoch 8, gen_loss = 1.115362610058351, disc_loss = 0.000377664895693835
Trained batch 110 in epoch 8, gen_loss = 1.114007909555693, disc_loss = 0.0003769186999610004
Trained batch 111 in epoch 8, gen_loss = 1.1157740445009299, disc_loss = 0.00037746040750010124
Trained batch 112 in epoch 8, gen_loss = 1.1165639726461563, disc_loss = 0.0003762932120697713
Trained batch 113 in epoch 8, gen_loss = 1.1186040603277976, disc_loss = 0.0003755822825105657
Trained batch 114 in epoch 8, gen_loss = 1.1190588085547737, disc_loss = 0.0003748971651910561
Trained batch 115 in epoch 8, gen_loss = 1.117972976688681, disc_loss = 0.0003754268091142876
Trained batch 116 in epoch 8, gen_loss = 1.1181570164158814, disc_loss = 0.00037655020628918486
Trained batch 117 in epoch 8, gen_loss = 1.1198864816609075, disc_loss = 0.0003790622223755621
Trained batch 118 in epoch 8, gen_loss = 1.1186523162016349, disc_loss = 0.0003834145063286874
Trained batch 119 in epoch 8, gen_loss = 1.1181784932812056, disc_loss = 0.0003862391004683256
Trained batch 120 in epoch 8, gen_loss = 1.116553607558416, disc_loss = 0.0003866922489270252
Trained batch 121 in epoch 8, gen_loss = 1.1151413008814952, disc_loss = 0.0003857923683888836
Trained batch 122 in epoch 8, gen_loss = 1.115716091985625, disc_loss = 0.00038403488630078716
Trained batch 123 in epoch 8, gen_loss = 1.1154566532181156, disc_loss = 0.0003819404606591918
Trained batch 124 in epoch 8, gen_loss = 1.1160606203079224, disc_loss = 0.00038044782396173105
Trained batch 125 in epoch 8, gen_loss = 1.116656604267302, disc_loss = 0.00037882526561992965
Trained batch 126 in epoch 8, gen_loss = 1.1187983319515318, disc_loss = 0.0003787806700694184
Trained batch 127 in epoch 8, gen_loss = 1.1189301842823625, disc_loss = 0.0003774445117983305
Trained batch 128 in epoch 8, gen_loss = 1.1178663640983344, disc_loss = 0.0003759737805957011
Trained batch 129 in epoch 8, gen_loss = 1.1168262128646558, disc_loss = 0.00037471138835266736
Trained batch 130 in epoch 8, gen_loss = 1.1179421243776801, disc_loss = 0.0003730870977391574
Trained batch 131 in epoch 8, gen_loss = 1.1165529972676076, disc_loss = 0.0003718467755926681
Trained batch 132 in epoch 8, gen_loss = 1.115556726330205, disc_loss = 0.00037066294032427364
Trained batch 133 in epoch 8, gen_loss = 1.1151811582828635, disc_loss = 0.0003691232671901243
Trained batch 134 in epoch 8, gen_loss = 1.1155903229007014, disc_loss = 0.00036829391260484787
Trained batch 135 in epoch 8, gen_loss = 1.1156990427304716, disc_loss = 0.00036932383371844055
Trained batch 136 in epoch 8, gen_loss = 1.1166889471729307, disc_loss = 0.00036943049133325296
Trained batch 137 in epoch 8, gen_loss = 1.1172006981096405, disc_loss = 0.0003682800563473248
Trained batch 138 in epoch 8, gen_loss = 1.1174593207647474, disc_loss = 0.00036703972126023924
Trained batch 139 in epoch 8, gen_loss = 1.1178000292607717, disc_loss = 0.00036543695776864685
Trained batch 140 in epoch 8, gen_loss = 1.116116537269971, disc_loss = 0.0003659069967552762
Trained batch 141 in epoch 8, gen_loss = 1.1150285790503864, disc_loss = 0.00036580882796199504
Trained batch 142 in epoch 8, gen_loss = 1.1146774846357066, disc_loss = 0.0003648300520759043
Trained batch 143 in epoch 8, gen_loss = 1.114712276806434, disc_loss = 0.00036433679163868266
Trained batch 144 in epoch 8, gen_loss = 1.1133347326311571, disc_loss = 0.0003639107278512052
Trained batch 145 in epoch 8, gen_loss = 1.1132997139675977, disc_loss = 0.00036352980627370554
Trained batch 146 in epoch 8, gen_loss = 1.1135362796232002, disc_loss = 0.0003620226818297635
Trained batch 147 in epoch 8, gen_loss = 1.112265870377824, disc_loss = 0.0003613723088287893
Trained batch 148 in epoch 8, gen_loss = 1.1122667429431172, disc_loss = 0.0003610518694079431
Trained batch 149 in epoch 8, gen_loss = 1.1123988763491313, disc_loss = 0.00036023117315683823
Trained batch 150 in epoch 8, gen_loss = 1.1130191498244835, disc_loss = 0.000359272306435356
Trained batch 151 in epoch 8, gen_loss = 1.112550485290979, disc_loss = 0.0003588991395238401
Trained batch 152 in epoch 8, gen_loss = 1.1115193222862443, disc_loss = 0.00036031147108445236
Trained batch 153 in epoch 8, gen_loss = 1.1130305416398234, disc_loss = 0.0003630391739451707
Trained batch 154 in epoch 8, gen_loss = 1.1120905218585846, disc_loss = 0.000363398221135515
Trained batch 155 in epoch 8, gen_loss = 1.1116295093909287, disc_loss = 0.0003621884379987396
Trained batch 156 in epoch 8, gen_loss = 1.1125754379922417, disc_loss = 0.0003611719716176432
Trained batch 157 in epoch 8, gen_loss = 1.1123728718184218, disc_loss = 0.0003602090177013498
Trained batch 158 in epoch 8, gen_loss = 1.111491469092339, disc_loss = 0.00036023819591936437
Trained batch 159 in epoch 8, gen_loss = 1.1111352968961001, disc_loss = 0.00035994832392134414
Trained batch 160 in epoch 8, gen_loss = 1.1119160115348627, disc_loss = 0.00035895652517131156
Trained batch 161 in epoch 8, gen_loss = 1.1112770912823853, disc_loss = 0.0003587050439504602
Trained batch 162 in epoch 8, gen_loss = 1.1116417145436526, disc_loss = 0.0003608150553280356
Trained batch 163 in epoch 8, gen_loss = 1.111943179877793, disc_loss = 0.0003646595877642806
Trained batch 164 in epoch 8, gen_loss = 1.1123062592564208, disc_loss = 0.00036624551227732534
Trained batch 165 in epoch 8, gen_loss = 1.1123814658228173, disc_loss = 0.0003660798704595984
Trained batch 166 in epoch 8, gen_loss = 1.111186409781793, disc_loss = 0.00036488105883664303
Trained batch 167 in epoch 8, gen_loss = 1.110852140401091, disc_loss = 0.0003649736875429101
Trained batch 168 in epoch 8, gen_loss = 1.1101537368001317, disc_loss = 0.00036491673833590014
Trained batch 169 in epoch 8, gen_loss = 1.1099695412551656, disc_loss = 0.0003639390288513181
Trained batch 170 in epoch 8, gen_loss = 1.1092462278248971, disc_loss = 0.00036279120461570036
Trained batch 171 in epoch 8, gen_loss = 1.1093459749637649, disc_loss = 0.00036139068093731576
Trained batch 172 in epoch 8, gen_loss = 1.1091360298195325, disc_loss = 0.00036057547166993344
Trained batch 173 in epoch 8, gen_loss = 1.109461596299862, disc_loss = 0.00036063505107993205
Trained batch 174 in epoch 8, gen_loss = 1.1082844257354736, disc_loss = 0.0003611714888912892
Trained batch 175 in epoch 8, gen_loss = 1.1071772317994724, disc_loss = 0.0003607906528900044
Trained batch 176 in epoch 8, gen_loss = 1.1070271110804069, disc_loss = 0.0003601599751138339
Trained batch 177 in epoch 8, gen_loss = 1.109590579954426, disc_loss = 0.0003601547078902472
Trained batch 178 in epoch 8, gen_loss = 1.109485736106361, disc_loss = 0.0003606754971109461
Trained batch 179 in epoch 8, gen_loss = 1.1110321210490333, disc_loss = 0.00036115896093381
Trained batch 180 in epoch 8, gen_loss = 1.1114030259748848, disc_loss = 0.00036069328092888913
Trained batch 181 in epoch 8, gen_loss = 1.1109622140507123, disc_loss = 0.00035990076711251665
Trained batch 182 in epoch 8, gen_loss = 1.1112238194773105, disc_loss = 0.0003593640846548261
Trained batch 183 in epoch 8, gen_loss = 1.110195692466653, disc_loss = 0.0003590291517748087
Trained batch 184 in epoch 8, gen_loss = 1.1109652596551018, disc_loss = 0.000360141099372413
Trained batch 185 in epoch 8, gen_loss = 1.1113386000356367, disc_loss = 0.0003630553363363624
Trained batch 186 in epoch 8, gen_loss = 1.1121320979480438, disc_loss = 0.00036597674858680415
Trained batch 187 in epoch 8, gen_loss = 1.1114285762639755, disc_loss = 0.00036777834050534444
Trained batch 188 in epoch 8, gen_loss = 1.1110955334845043, disc_loss = 0.00036864406650204693
Trained batch 189 in epoch 8, gen_loss = 1.1105993123430955, disc_loss = 0.00036794912214789196
Trained batch 190 in epoch 8, gen_loss = 1.1107584896512057, disc_loss = 0.00036769715008717175
Trained batch 191 in epoch 8, gen_loss = 1.1104022366926074, disc_loss = 0.00036802323866898706
Trained batch 192 in epoch 8, gen_loss = 1.1109550694109862, disc_loss = 0.00037097384438547184
Trained batch 193 in epoch 8, gen_loss = 1.1114779191533315, disc_loss = 0.00037834170225980096
Trained batch 194 in epoch 8, gen_loss = 1.1116083117631765, disc_loss = 0.00038568730819045017
Trained batch 195 in epoch 8, gen_loss = 1.1107092563595091, disc_loss = 0.0003946458338240128
Trained batch 196 in epoch 8, gen_loss = 1.1107092759935988, disc_loss = 0.00040260067483354693
Trained batch 197 in epoch 8, gen_loss = 1.1116846688468047, disc_loss = 0.00040632384645339863
Trained batch 198 in epoch 8, gen_loss = 1.1121109139979186, disc_loss = 0.000409441052571269
Trained batch 199 in epoch 8, gen_loss = 1.112168325483799, disc_loss = 0.0004139225501057808
Trained batch 200 in epoch 8, gen_loss = 1.1123378404337376, disc_loss = 0.00041793796555422924
Trained batch 201 in epoch 8, gen_loss = 1.1129266646238838, disc_loss = 0.00041901903005235017
Trained batch 202 in epoch 8, gen_loss = 1.1139521901243425, disc_loss = 0.00041784393461908584
Trained batch 203 in epoch 8, gen_loss = 1.113369493215692, disc_loss = 0.0004166615521635143
Trained batch 204 in epoch 8, gen_loss = 1.112796620334067, disc_loss = 0.00041562547511847053
Trained batch 205 in epoch 8, gen_loss = 1.1124232634178643, disc_loss = 0.0004144553558149904
Trained batch 206 in epoch 8, gen_loss = 1.113445816696554, disc_loss = 0.0004132580720908953
Trained batch 207 in epoch 8, gen_loss = 1.1129869896058853, disc_loss = 0.0004122659137325312
Trained batch 208 in epoch 8, gen_loss = 1.1130563810681613, disc_loss = 0.0004123326053781074
Trained batch 209 in epoch 8, gen_loss = 1.113991132520494, disc_loss = 0.0004136523271015557
Trained batch 210 in epoch 8, gen_loss = 1.113697058499142, disc_loss = 0.0004143813902292052
Trained batch 211 in epoch 8, gen_loss = 1.1133738157321822, disc_loss = 0.0004154813650873037
Trained batch 212 in epoch 8, gen_loss = 1.112646932613122, disc_loss = 0.00041842226766649975
Trained batch 213 in epoch 8, gen_loss = 1.1123890645593126, disc_loss = 0.00042080212220311315
Trained batch 214 in epoch 8, gen_loss = 1.1121810938036718, disc_loss = 0.0004232933723467922
Trained batch 215 in epoch 8, gen_loss = 1.1119136410178962, disc_loss = 0.00042634108753932025
Trained batch 216 in epoch 8, gen_loss = 1.111230267907068, disc_loss = 0.000428315531871494
Trained batch 217 in epoch 8, gen_loss = 1.1102062846542498, disc_loss = 0.0004293819515415309
Trained batch 218 in epoch 8, gen_loss = 1.1098988268473378, disc_loss = 0.000431305239569517
Trained batch 219 in epoch 8, gen_loss = 1.109865802526474, disc_loss = 0.00043562512228990355
Trained batch 220 in epoch 8, gen_loss = 1.1100641688610093, disc_loss = 0.0004427152055611189
Trained batch 221 in epoch 8, gen_loss = 1.109607202512724, disc_loss = 0.00045203654122930064
Trained batch 222 in epoch 8, gen_loss = 1.1098607222595558, disc_loss = 0.00046074262801521236
Trained batch 223 in epoch 8, gen_loss = 1.1106060887021678, disc_loss = 0.00046655438749049997
Trained batch 224 in epoch 8, gen_loss = 1.1097583950890435, disc_loss = 0.0004688455545045953
Trained batch 225 in epoch 8, gen_loss = 1.11024690518337, disc_loss = 0.0004700298856161391
Trained batch 226 in epoch 8, gen_loss = 1.109523930213525, disc_loss = 0.00047251879597736096
Trained batch 227 in epoch 8, gen_loss = 1.1091565212659669, disc_loss = 0.00047570971311646995
Trained batch 228 in epoch 8, gen_loss = 1.1092464481378748, disc_loss = 0.00047618096141377464
Trained batch 229 in epoch 8, gen_loss = 1.1087154479130454, disc_loss = 0.0004760224938091478
Trained batch 230 in epoch 8, gen_loss = 1.108680635045617, disc_loss = 0.00047460295317530254
Trained batch 231 in epoch 8, gen_loss = 1.109699612804528, disc_loss = 0.00047396772151842015
Trained batch 232 in epoch 8, gen_loss = 1.1086299913123954, disc_loss = 0.0004741365351135115
Trained batch 233 in epoch 8, gen_loss = 1.1092458578765902, disc_loss = 0.0004738446608452926
Trained batch 234 in epoch 8, gen_loss = 1.1104968251066005, disc_loss = 0.0004729060359866398
Trained batch 235 in epoch 8, gen_loss = 1.1101717304880336, disc_loss = 0.00047233857731043827
Trained batch 236 in epoch 8, gen_loss = 1.1101333740391308, disc_loss = 0.0004714778657938267
Trained batch 237 in epoch 8, gen_loss = 1.110132108465964, disc_loss = 0.00047003691715795837
Trained batch 238 in epoch 8, gen_loss = 1.110513738259112, disc_loss = 0.0004692263036947327
Trained batch 239 in epoch 8, gen_loss = 1.1106484579543272, disc_loss = 0.00047004305309504465
Trained batch 240 in epoch 8, gen_loss = 1.1107338135173213, disc_loss = 0.000473765171640427
Trained batch 241 in epoch 8, gen_loss = 1.1111615814945914, disc_loss = 0.00047766716989293146
Trained batch 242 in epoch 8, gen_loss = 1.1104998752904036, disc_loss = 0.00048022342435828766
Trained batch 243 in epoch 8, gen_loss = 1.1116864072983381, disc_loss = 0.00048088206131069455
Trained batch 244 in epoch 8, gen_loss = 1.1115045525589768, disc_loss = 0.00048030362781065954
Trained batch 245 in epoch 8, gen_loss = 1.1119495870136633, disc_loss = 0.00048038092581105676
Trained batch 246 in epoch 8, gen_loss = 1.1120401410921383, disc_loss = 0.00048056880188545003
Trained batch 247 in epoch 8, gen_loss = 1.112671657675697, disc_loss = 0.0004809633122520961
Trained batch 248 in epoch 8, gen_loss = 1.1129299050354096, disc_loss = 0.00048085137651545973
Trained batch 249 in epoch 8, gen_loss = 1.1123755218982696, disc_loss = 0.0004800244610814843
Trained batch 250 in epoch 8, gen_loss = 1.112870970332765, disc_loss = 0.0004792128697065989
Trained batch 251 in epoch 8, gen_loss = 1.1131099233078579, disc_loss = 0.00047836958958849584
Trained batch 252 in epoch 8, gen_loss = 1.113041721078247, disc_loss = 0.0004776535870513341
Trained batch 253 in epoch 8, gen_loss = 1.1123736819883032, disc_loss = 0.00047674281289457256
Trained batch 254 in epoch 8, gen_loss = 1.1118802108016668, disc_loss = 0.0004753061697770403
Trained batch 255 in epoch 8, gen_loss = 1.111768911127001, disc_loss = 0.0004742205796617327
Trained batch 256 in epoch 8, gen_loss = 1.1113252628174273, disc_loss = 0.0004733297808251184
Trained batch 257 in epoch 8, gen_loss = 1.1113682641077411, disc_loss = 0.00047213657296740075
Trained batch 258 in epoch 8, gen_loss = 1.1117806823557408, disc_loss = 0.0004709953610265257
Trained batch 259 in epoch 8, gen_loss = 1.1114202134884321, disc_loss = 0.00046972451144448803
Trained batch 260 in epoch 8, gen_loss = 1.1113013766734536, disc_loss = 0.000468703721652398
Trained batch 261 in epoch 8, gen_loss = 1.1112729963910488, disc_loss = 0.00046831271332890357
Trained batch 262 in epoch 8, gen_loss = 1.1111854317070413, disc_loss = 0.00046791519392383577
Trained batch 263 in epoch 8, gen_loss = 1.1108029220591893, disc_loss = 0.0004681462100272642
Trained batch 264 in epoch 8, gen_loss = 1.110901621377693, disc_loss = 0.00046854269455235347
Trained batch 265 in epoch 8, gen_loss = 1.110602534131, disc_loss = 0.0004690471264746835
Trained batch 266 in epoch 8, gen_loss = 1.110412229536178, disc_loss = 0.0004701169234888422
Trained batch 267 in epoch 8, gen_loss = 1.1107940093350055, disc_loss = 0.0004718513544829156
Trained batch 268 in epoch 8, gen_loss = 1.1103136798706197, disc_loss = 0.000473136685546929
Trained batch 269 in epoch 8, gen_loss = 1.1107368250687917, disc_loss = 0.000473046913086566
Trained batch 270 in epoch 8, gen_loss = 1.110980556239941, disc_loss = 0.0004725132918668777
Trained batch 271 in epoch 8, gen_loss = 1.111809700508328, disc_loss = 0.0004721109132119369
Trained batch 272 in epoch 8, gen_loss = 1.1118485017137214, disc_loss = 0.00047177873771350265
Trained batch 273 in epoch 8, gen_loss = 1.1121398208350162, disc_loss = 0.0004708253680849465
Trained batch 274 in epoch 8, gen_loss = 1.111868724606254, disc_loss = 0.0004696080215878531
Trained batch 275 in epoch 8, gen_loss = 1.1116407278223315, disc_loss = 0.00046853370348390604
Trained batch 276 in epoch 8, gen_loss = 1.1119707812040722, disc_loss = 0.0004674759515616219
Trained batch 277 in epoch 8, gen_loss = 1.111560378572066, disc_loss = 0.000466272898730043
Trained batch 278 in epoch 8, gen_loss = 1.1112021378718824, disc_loss = 0.0004652319140897106
Trained batch 279 in epoch 8, gen_loss = 1.1108049460819789, disc_loss = 0.00046413180189119885
Trained batch 280 in epoch 8, gen_loss = 1.111008485441106, disc_loss = 0.00046287633581592425
Trained batch 281 in epoch 8, gen_loss = 1.1111903503431495, disc_loss = 0.0004617417167627801
Trained batch 282 in epoch 8, gen_loss = 1.1112852997998888, disc_loss = 0.0004604954363316686
Trained batch 283 in epoch 8, gen_loss = 1.1103845012020057, disc_loss = 0.0004597349412813881
Trained batch 284 in epoch 8, gen_loss = 1.1098540285177398, disc_loss = 0.00045865124373353625
Trained batch 285 in epoch 8, gen_loss = 1.1097512157646927, disc_loss = 0.00045742707444949995
Trained batch 286 in epoch 8, gen_loss = 1.1089622777098147, disc_loss = 0.0004567962416635505
Trained batch 287 in epoch 8, gen_loss = 1.1099095644636288, disc_loss = 0.00045739670609792584
Trained batch 288 in epoch 8, gen_loss = 1.1100403740744278, disc_loss = 0.0004591839085645236
Trained batch 289 in epoch 8, gen_loss = 1.1093706106317454, disc_loss = 0.0004591399070893109
Trained batch 290 in epoch 8, gen_loss = 1.1093310556051248, disc_loss = 0.00045834378580081905
Trained batch 291 in epoch 8, gen_loss = 1.109290599006496, disc_loss = 0.00045747930420325807
Trained batch 292 in epoch 8, gen_loss = 1.1091525221033716, disc_loss = 0.00045695225854699084
Trained batch 293 in epoch 8, gen_loss = 1.1093104607393953, disc_loss = 0.00045631401351994366
Trained batch 294 in epoch 8, gen_loss = 1.1098395375882164, disc_loss = 0.00045597707264231896
Trained batch 295 in epoch 8, gen_loss = 1.1103873160239812, disc_loss = 0.0004558610929027939
Trained batch 296 in epoch 8, gen_loss = 1.1108477990635317, disc_loss = 0.000455663136988745
Trained batch 297 in epoch 8, gen_loss = 1.1110137000979994, disc_loss = 0.0004554565707774405
Trained batch 298 in epoch 8, gen_loss = 1.112022351261764, disc_loss = 0.0004556076431537536
Trained batch 299 in epoch 8, gen_loss = 1.112319138844808, disc_loss = 0.0004558992876506333
Trained batch 300 in epoch 8, gen_loss = 1.112515052291642, disc_loss = 0.0004567071217786369
Trained batch 301 in epoch 8, gen_loss = 1.113106259052327, disc_loss = 0.0004582351616139305
Trained batch 302 in epoch 8, gen_loss = 1.1128583792412634, disc_loss = 0.0004600702581853028
Trained batch 303 in epoch 8, gen_loss = 1.1128111328733594, disc_loss = 0.00046215441089340236
Trained batch 304 in epoch 8, gen_loss = 1.1128334338547754, disc_loss = 0.00046495539362859133
Trained batch 305 in epoch 8, gen_loss = 1.1130853295326233, disc_loss = 0.00046748095920086483
Trained batch 306 in epoch 8, gen_loss = 1.1125079700146903, disc_loss = 0.00046847146764266416
Trained batch 307 in epoch 8, gen_loss = 1.1127714986925001, disc_loss = 0.00046916300327991067
Trained batch 308 in epoch 8, gen_loss = 1.112980021242185, disc_loss = 0.0004718062589327431
Trained batch 309 in epoch 8, gen_loss = 1.1127564349482137, disc_loss = 0.00047474845456646665
Trained batch 310 in epoch 8, gen_loss = 1.1133076144184713, disc_loss = 0.00047551152025258854
Trained batch 311 in epoch 8, gen_loss = 1.1128820385306308, disc_loss = 0.00047483748538723326
Trained batch 312 in epoch 8, gen_loss = 1.1123156553259292, disc_loss = 0.0004741789947869033
Trained batch 313 in epoch 8, gen_loss = 1.1123590277638404, disc_loss = 0.0004737707795299053
Trained batch 314 in epoch 8, gen_loss = 1.1117866385550725, disc_loss = 0.00047313957583687696
Trained batch 315 in epoch 8, gen_loss = 1.1116692916124682, disc_loss = 0.0004727358342348406
Trained batch 316 in epoch 8, gen_loss = 1.1110601299192626, disc_loss = 0.00047331999166856144
Trained batch 317 in epoch 8, gen_loss = 1.110447460375492, disc_loss = 0.00047397491213797485
Trained batch 318 in epoch 8, gen_loss = 1.1112204274413728, disc_loss = 0.0004740219233113452
Trained batch 319 in epoch 8, gen_loss = 1.1108740333467721, disc_loss = 0.00047400277778706366
Trained batch 320 in epoch 8, gen_loss = 1.1109077629641952, disc_loss = 0.0004747699216257337
Trained batch 321 in epoch 8, gen_loss = 1.1110840373157715, disc_loss = 0.00047623646813527945
Trained batch 322 in epoch 8, gen_loss = 1.1113905046746457, disc_loss = 0.0004779755335145099
Trained batch 323 in epoch 8, gen_loss = 1.111798526696217, disc_loss = 0.0004786615855091777
Trained batch 324 in epoch 8, gen_loss = 1.1117985600691576, disc_loss = 0.0004781721970917156
Trained batch 325 in epoch 8, gen_loss = 1.1122358371875039, disc_loss = 0.0004771363262743818
Trained batch 326 in epoch 8, gen_loss = 1.1130870624419746, disc_loss = 0.00047685343096020633
Trained batch 327 in epoch 8, gen_loss = 1.1125230194955338, disc_loss = 0.00047719543795765053
Trained batch 328 in epoch 8, gen_loss = 1.1129794651614133, disc_loss = 0.00047643668390085105
Trained batch 329 in epoch 8, gen_loss = 1.1126162182201038, disc_loss = 0.0004754045089419268
Trained batch 330 in epoch 8, gen_loss = 1.1121259020174379, disc_loss = 0.0004750283646583346
Trained batch 331 in epoch 8, gen_loss = 1.112456572702132, disc_loss = 0.0004752076489590347
Trained batch 332 in epoch 8, gen_loss = 1.11265783803957, disc_loss = 0.0004753039721072674
Trained batch 333 in epoch 8, gen_loss = 1.1126389267915737, disc_loss = 0.00047501864424201906
Trained batch 334 in epoch 8, gen_loss = 1.1130140023445017, disc_loss = 0.00047394514556039374
Trained batch 335 in epoch 8, gen_loss = 1.1133379964601426, disc_loss = 0.0004729464574752672
Trained batch 336 in epoch 8, gen_loss = 1.1136306641009865, disc_loss = 0.0004719864581243511
Trained batch 337 in epoch 8, gen_loss = 1.113784019763653, disc_loss = 0.00047099613956986516
Trained batch 338 in epoch 8, gen_loss = 1.1136232396494323, disc_loss = 0.0004699887066472055
Trained batch 339 in epoch 8, gen_loss = 1.1136734741575578, disc_loss = 0.00046977214898266965
Trained batch 340 in epoch 8, gen_loss = 1.1141421840337715, disc_loss = 0.00047156606743073285
Trained batch 341 in epoch 8, gen_loss = 1.1143647881976344, disc_loss = 0.00047538888800943035
Trained batch 342 in epoch 8, gen_loss = 1.1140718672087866, disc_loss = 0.0004801658765470905
Trained batch 343 in epoch 8, gen_loss = 1.1145231651012288, disc_loss = 0.00048291561948687114
Trained batch 344 in epoch 8, gen_loss = 1.1142281262770943, disc_loss = 0.00048305427651781506
Trained batch 345 in epoch 8, gen_loss = 1.1137939553729372, disc_loss = 0.00048249413943940347
Trained batch 346 in epoch 8, gen_loss = 1.1138683049067297, disc_loss = 0.00048171261701479914
Trained batch 347 in epoch 8, gen_loss = 1.1141594699744521, disc_loss = 0.0004807940235616701
Trained batch 348 in epoch 8, gen_loss = 1.1143141650197157, disc_loss = 0.0004798120003749675
Trained batch 349 in epoch 8, gen_loss = 1.114163226740701, disc_loss = 0.00047928551891735486
Trained batch 350 in epoch 8, gen_loss = 1.1139195760091145, disc_loss = 0.00047849785529313865
Trained batch 351 in epoch 8, gen_loss = 1.1132075932215562, disc_loss = 0.0004779665412942532
Trained batch 352 in epoch 8, gen_loss = 1.1124968236634143, disc_loss = 0.0004775894393099976
Trained batch 353 in epoch 8, gen_loss = 1.1136882108146862, disc_loss = 0.0004798665197014001
Trained batch 354 in epoch 8, gen_loss = 1.1139490223266708, disc_loss = 0.00048730450776212156
Trained batch 355 in epoch 8, gen_loss = 1.1140447501721007, disc_loss = 0.0004945821684905853
Trained batch 356 in epoch 8, gen_loss = 1.1141078123191492, disc_loss = 0.0004977643012640808
Trained batch 357 in epoch 8, gen_loss = 1.1145834281790856, disc_loss = 0.0004996718980793713
Trained batch 358 in epoch 8, gen_loss = 1.114498772162913, disc_loss = 0.0005034180118290197
Trained batch 359 in epoch 8, gen_loss = 1.1139815328849687, disc_loss = 0.0005063293272339959
Trained batch 360 in epoch 8, gen_loss = 1.1137468667902115, disc_loss = 0.0005079999155440069
Trained batch 361 in epoch 8, gen_loss = 1.1139862404014524, disc_loss = 0.0005091998182201452
Trained batch 362 in epoch 8, gen_loss = 1.1138889689419225, disc_loss = 0.0005092128961401242
Trained batch 363 in epoch 8, gen_loss = 1.1136883109152973, disc_loss = 0.0005101904028249139
Trained batch 364 in epoch 8, gen_loss = 1.113399271605766, disc_loss = 0.0005124651335940493
Trained batch 365 in epoch 8, gen_loss = 1.1131811570274375, disc_loss = 0.0005151012001625616
Trained batch 366 in epoch 8, gen_loss = 1.1127430375980096, disc_loss = 0.0005173847436017043
Trained batch 367 in epoch 8, gen_loss = 1.1125233490829882, disc_loss = 0.0005178494721092094
Trained batch 368 in epoch 8, gen_loss = 1.112375921027124, disc_loss = 0.0005177717766830847
Trained batch 369 in epoch 8, gen_loss = 1.1121261100511293, disc_loss = 0.000518419066419655
Trained batch 370 in epoch 8, gen_loss = 1.1118518849910108, disc_loss = 0.0005188089583172323
Trained batch 371 in epoch 8, gen_loss = 1.1123493390698587, disc_loss = 0.0005184479617529051
Trained batch 372 in epoch 8, gen_loss = 1.1121177002188347, disc_loss = 0.0005186414730183633
Trained batch 373 in epoch 8, gen_loss = 1.1124595703288196, disc_loss = 0.0005218697146129394
Trained batch 374 in epoch 8, gen_loss = 1.1121069970130921, disc_loss = 0.000527592062659096
Trained batch 375 in epoch 8, gen_loss = 1.1119061957331413, disc_loss = 0.0005333989978332302
Trained batch 376 in epoch 8, gen_loss = 1.111294830825664, disc_loss = 0.0005376116753889641
Trained batch 377 in epoch 8, gen_loss = 1.1117496007964724, disc_loss = 0.0005428926707142237
Trained batch 378 in epoch 8, gen_loss = 1.11135277584549, disc_loss = 0.0005477291638331702
Trained batch 379 in epoch 8, gen_loss = 1.1110346350230669, disc_loss = 0.0005530632735347976
Trained batch 380 in epoch 8, gen_loss = 1.1114911859429728, disc_loss = 0.0005555372716551292
Trained batch 381 in epoch 8, gen_loss = 1.112129461546843, disc_loss = 0.0005552462883348789
Trained batch 382 in epoch 8, gen_loss = 1.1122469639031134, disc_loss = 0.0005544888087757741
Trained batch 383 in epoch 8, gen_loss = 1.1127269216813147, disc_loss = 0.0005536106059291038
Trained batch 384 in epoch 8, gen_loss = 1.11306382634423, disc_loss = 0.0005532780673329162
Trained batch 385 in epoch 8, gen_loss = 1.1132353382098243, disc_loss = 0.0005535797232849743
Trained batch 386 in epoch 8, gen_loss = 1.1128703129383946, disc_loss = 0.000554049198117284
Trained batch 387 in epoch 8, gen_loss = 1.1126626971148954, disc_loss = 0.0005545810630061056
Trained batch 388 in epoch 8, gen_loss = 1.1128319509538096, disc_loss = 0.0005546332305202388
Trained batch 389 in epoch 8, gen_loss = 1.1130680443384708, disc_loss = 0.0005540958007772226
Trained batch 390 in epoch 8, gen_loss = 1.1128314771615635, disc_loss = 0.0005535320459042981
Trained batch 391 in epoch 8, gen_loss = 1.1127291168181264, disc_loss = 0.0005526657936830556
Trained batch 392 in epoch 8, gen_loss = 1.1130464554743003, disc_loss = 0.0005521837986984087
Trained batch 393 in epoch 8, gen_loss = 1.1129019028946834, disc_loss = 0.0005520863907739962
Trained batch 394 in epoch 8, gen_loss = 1.1129924507080755, disc_loss = 0.0005513000426721123
Trained batch 395 in epoch 8, gen_loss = 1.1132938920548467, disc_loss = 0.0005503385019263151
Trained batch 396 in epoch 8, gen_loss = 1.11332803063789, disc_loss = 0.0005495599422098597
Trained batch 397 in epoch 8, gen_loss = 1.113494290329104, disc_loss = 0.0005484832573853768
Trained batch 398 in epoch 8, gen_loss = 1.1135245879789941, disc_loss = 0.0005473277614098031
Trained batch 399 in epoch 8, gen_loss = 1.1131615960597991, disc_loss = 0.0005485229527948832
Trained batch 400 in epoch 8, gen_loss = 1.113666284708608, disc_loss = 0.0005509189588673578
Trained batch 401 in epoch 8, gen_loss = 1.113484863025039, disc_loss = 0.0005539562187378529
Trained batch 402 in epoch 8, gen_loss = 1.1140203440455585, disc_loss = 0.0005567279890681982
Trained batch 403 in epoch 8, gen_loss = 1.1147620179275475, disc_loss = 0.0005611692050650271
Trained batch 404 in epoch 8, gen_loss = 1.1149965618863518, disc_loss = 0.0005681770743570796
Trained batch 405 in epoch 8, gen_loss = 1.1153052284799774, disc_loss = 0.0005754718109940952
Trained batch 406 in epoch 8, gen_loss = 1.1159123536702749, disc_loss = 0.0005796924673033139
Trained batch 407 in epoch 8, gen_loss = 1.1158927147294961, disc_loss = 0.0005825116784976939
Trained batch 408 in epoch 8, gen_loss = 1.115963593963306, disc_loss = 0.0005843574103458402
Trained batch 409 in epoch 8, gen_loss = 1.115574944310072, disc_loss = 0.0005845998603213158
Trained batch 410 in epoch 8, gen_loss = 1.1153739577662336, disc_loss = 0.0005842124278465379
Trained batch 411 in epoch 8, gen_loss = 1.1159482337896107, disc_loss = 0.0005840378086662171
Trained batch 412 in epoch 8, gen_loss = 1.1158568333771268, disc_loss = 0.0005845795472040626
Trained batch 413 in epoch 8, gen_loss = 1.1163578237888319, disc_loss = 0.0005851482850990702
Trained batch 414 in epoch 8, gen_loss = 1.1166117564741387, disc_loss = 0.0005856319555573738
Trained batch 415 in epoch 8, gen_loss = 1.1163999965557685, disc_loss = 0.00058597366147786
Trained batch 416 in epoch 8, gen_loss = 1.1164869095781724, disc_loss = 0.0005859394397214446
Trained batch 417 in epoch 8, gen_loss = 1.116610226448643, disc_loss = 0.000585938217510379
Trained batch 418 in epoch 8, gen_loss = 1.1164917308561557, disc_loss = 0.0005860693015896955
Trained batch 419 in epoch 8, gen_loss = 1.1160567740599314, disc_loss = 0.0005865814103821149
Trained batch 420 in epoch 8, gen_loss = 1.1164464712709259, disc_loss = 0.0005862169788679995
Trained batch 421 in epoch 8, gen_loss = 1.116278141030768, disc_loss = 0.0005853561990458785
Trained batch 422 in epoch 8, gen_loss = 1.1161409083833085, disc_loss = 0.0005843846472474223
Trained batch 423 in epoch 8, gen_loss = 1.115990033127227, disc_loss = 0.0005832598763279164
Trained batch 424 in epoch 8, gen_loss = 1.1159677039875704, disc_loss = 0.0005822126812178313
Trained batch 425 in epoch 8, gen_loss = 1.1163700695888537, disc_loss = 0.0005813373413367061
Trained batch 426 in epoch 8, gen_loss = 1.1166653867627754, disc_loss = 0.0005808111857303879
Trained batch 427 in epoch 8, gen_loss = 1.1165988189037714, disc_loss = 0.0005801244020131831
Trained batch 428 in epoch 8, gen_loss = 1.116995553592424, disc_loss = 0.0005791222103106158
Trained batch 429 in epoch 8, gen_loss = 1.1176604598067528, disc_loss = 0.0005781216522527123
Trained batch 430 in epoch 8, gen_loss = 1.1178564649170346, disc_loss = 0.0005772571521595103
Trained batch 431 in epoch 8, gen_loss = 1.11790129625135, disc_loss = 0.0005763569185580343
Trained batch 432 in epoch 8, gen_loss = 1.1177121629340545, disc_loss = 0.0005758928586583687
Trained batch 433 in epoch 8, gen_loss = 1.117601564128278, disc_loss = 0.0005762636760643507
Trained batch 434 in epoch 8, gen_loss = 1.1170076259251298, disc_loss = 0.0005790213574575067
Trained batch 435 in epoch 8, gen_loss = 1.1172600152022247, disc_loss = 0.0005825017677025161
Trained batch 436 in epoch 8, gen_loss = 1.1171527330335271, disc_loss = 0.0005851748747217258
Trained batch 437 in epoch 8, gen_loss = 1.1169479569615839, disc_loss = 0.0005858454089287507
Trained batch 438 in epoch 8, gen_loss = 1.1166945412110088, disc_loss = 0.0005850974959109174
Trained batch 439 in epoch 8, gen_loss = 1.116337475316091, disc_loss = 0.0005840876740959091
Trained batch 440 in epoch 8, gen_loss = 1.1162387744910052, disc_loss = 0.0005833224107404694
Trained batch 441 in epoch 8, gen_loss = 1.1163654560686775, disc_loss = 0.0005825918052072649
Trained batch 442 in epoch 8, gen_loss = 1.1163533448365688, disc_loss = 0.0005817684613254434
Trained batch 443 in epoch 8, gen_loss = 1.1162986450635635, disc_loss = 0.0005807865556955614
Trained batch 444 in epoch 8, gen_loss = 1.116366780340002, disc_loss = 0.0005797639525471924
Trained batch 445 in epoch 8, gen_loss = 1.1171603949882525, disc_loss = 0.0005789888772976192
Trained batch 446 in epoch 8, gen_loss = 1.1171892962733105, disc_loss = 0.0005788882333648306
Trained batch 447 in epoch 8, gen_loss = 1.1167810794764332, disc_loss = 0.0005789287583541279
Trained batch 448 in epoch 8, gen_loss = 1.116526690649827, disc_loss = 0.0005787173299368301
Trained batch 449 in epoch 8, gen_loss = 1.1162447088294558, disc_loss = 0.0005778460140572861
Trained batch 450 in epoch 8, gen_loss = 1.1162621215018889, disc_loss = 0.000576833974696002
Trained batch 451 in epoch 8, gen_loss = 1.116181296716749, disc_loss = 0.000575809096847326
Trained batch 452 in epoch 8, gen_loss = 1.116090150200505, disc_loss = 0.000574766901099672
Trained batch 453 in epoch 8, gen_loss = 1.1168226606257687, disc_loss = 0.0005740589345036083
Trained batch 454 in epoch 8, gen_loss = 1.1172613986245878, disc_loss = 0.0005735794527476633
Trained batch 455 in epoch 8, gen_loss = 1.1171817608308374, disc_loss = 0.0005726679530453749
Trained batch 456 in epoch 8, gen_loss = 1.1169087408147182, disc_loss = 0.0005718935485147205
Trained batch 457 in epoch 8, gen_loss = 1.1168824878061703, disc_loss = 0.000571222301283048
Trained batch 458 in epoch 8, gen_loss = 1.116820267992082, disc_loss = 0.0005707668801802585
Trained batch 459 in epoch 8, gen_loss = 1.1167076552691666, disc_loss = 0.0005702721414032251
Trained batch 460 in epoch 8, gen_loss = 1.1161416097990602, disc_loss = 0.0005708629354254247
Trained batch 461 in epoch 8, gen_loss = 1.1158811127468622, disc_loss = 0.0005710018610415952
Trained batch 462 in epoch 8, gen_loss = 1.1158918901859556, disc_loss = 0.0005706668706380986
Trained batch 463 in epoch 8, gen_loss = 1.1158204099227642, disc_loss = 0.000571039431132045
Trained batch 464 in epoch 8, gen_loss = 1.115791585881223, disc_loss = 0.0005706786565790554
Trained batch 465 in epoch 8, gen_loss = 1.1152826767622657, disc_loss = 0.0005704477524508267
Trained batch 466 in epoch 8, gen_loss = 1.114898111631324, disc_loss = 0.0005697158762122698
Trained batch 467 in epoch 8, gen_loss = 1.114737141590852, disc_loss = 0.0005691188633400633
Trained batch 468 in epoch 8, gen_loss = 1.1147429607570298, disc_loss = 0.000568545842599094
Trained batch 469 in epoch 8, gen_loss = 1.1144265839394103, disc_loss = 0.0005679415485343619
Trained batch 470 in epoch 8, gen_loss = 1.114197044615533, disc_loss = 0.0005672223008442433
Trained batch 471 in epoch 8, gen_loss = 1.1140317454681559, disc_loss = 0.0005666535689670127
Trained batch 472 in epoch 8, gen_loss = 1.1141925178168943, disc_loss = 0.0005658253036482736
Trained batch 473 in epoch 8, gen_loss = 1.1139915467314578, disc_loss = 0.0005650853451202871
Trained batch 474 in epoch 8, gen_loss = 1.1136632263033013, disc_loss = 0.0005645264918597317
Trained batch 475 in epoch 8, gen_loss = 1.1139959228389404, disc_loss = 0.0005640027148354635
Trained batch 476 in epoch 8, gen_loss = 1.113905788842487, disc_loss = 0.0005632576780258023
Trained batch 477 in epoch 8, gen_loss = 1.1135251739035092, disc_loss = 0.0005625323811046698
Trained batch 478 in epoch 8, gen_loss = 1.1136005457358469, disc_loss = 0.000561852130656362
Trained batch 479 in epoch 8, gen_loss = 1.1133376458038886, disc_loss = 0.0005612741916290058
Trained batch 480 in epoch 8, gen_loss = 1.1132419405508933, disc_loss = 0.0005606852560531611
Trained batch 481 in epoch 8, gen_loss = 1.112789174456814, disc_loss = 0.0005600654354770146
Trained batch 482 in epoch 8, gen_loss = 1.1129843333493108, disc_loss = 0.0005596924702011196
Trained batch 483 in epoch 8, gen_loss = 1.113164847916808, disc_loss = 0.0005593483916181717
Trained batch 484 in epoch 8, gen_loss = 1.1129500299384913, disc_loss = 0.0005593030342649784
Trained batch 485 in epoch 8, gen_loss = 1.1131613123318786, disc_loss = 0.0005592670354660631
Trained batch 486 in epoch 8, gen_loss = 1.1129259487931489, disc_loss = 0.0005596186241395083
Trained batch 487 in epoch 8, gen_loss = 1.1131958267727837, disc_loss = 0.0005599572267202034
Trained batch 488 in epoch 8, gen_loss = 1.1131702880917882, disc_loss = 0.000559377867551349
Trained batch 489 in epoch 8, gen_loss = 1.113188717316608, disc_loss = 0.0005585458124298793
Trained batch 490 in epoch 8, gen_loss = 1.112737851084614, disc_loss = 0.0005581894039594646
Trained batch 491 in epoch 8, gen_loss = 1.112792675330387, disc_loss = 0.0005596205139626385
Trained batch 492 in epoch 8, gen_loss = 1.1125665296163811, disc_loss = 0.0005617255453491663
Trained batch 493 in epoch 8, gen_loss = 1.113125240754502, disc_loss = 0.0005638234909159142
Trained batch 494 in epoch 8, gen_loss = 1.1129742436938816, disc_loss = 0.0005647263347966164
Trained batch 495 in epoch 8, gen_loss = 1.1128023961378681, disc_loss = 0.0005647941501768899
Trained batch 496 in epoch 8, gen_loss = 1.1124154809015379, disc_loss = 0.0005649469878456145
Trained batch 497 in epoch 8, gen_loss = 1.1129263610724944, disc_loss = 0.0005669254022645745
Trained batch 498 in epoch 8, gen_loss = 1.1125225065227502, disc_loss = 0.0005699382125673432
Trained batch 499 in epoch 8, gen_loss = 1.1121941409111022, disc_loss = 0.0005727811059332453
Trained batch 500 in epoch 8, gen_loss = 1.112134082588607, disc_loss = 0.0005757986281988231
Trained batch 501 in epoch 8, gen_loss = 1.112154824325288, disc_loss = 0.000577960237969674
Trained batch 502 in epoch 8, gen_loss = 1.1120373181272927, disc_loss = 0.000578710453912975
Trained batch 503 in epoch 8, gen_loss = 1.1124187256135638, disc_loss = 0.0005788028137762994
Trained batch 504 in epoch 8, gen_loss = 1.1124340338282066, disc_loss = 0.0005787522282502107
Trained batch 505 in epoch 8, gen_loss = 1.1126250561046978, disc_loss = 0.0005784092567977956
Trained batch 506 in epoch 8, gen_loss = 1.112209512989902, disc_loss = 0.0005785377272629754
Trained batch 507 in epoch 8, gen_loss = 1.1121256918184401, disc_loss = 0.0005785609572217433
Trained batch 508 in epoch 8, gen_loss = 1.111712303634711, disc_loss = 0.000578069217694733
Trained batch 509 in epoch 8, gen_loss = 1.1117658728478002, disc_loss = 0.0005772910826136449
Trained batch 510 in epoch 8, gen_loss = 1.111604997206574, disc_loss = 0.0005764803411065438
Trained batch 511 in epoch 8, gen_loss = 1.1114622532622889, disc_loss = 0.0005756145077384645
Trained batch 512 in epoch 8, gen_loss = 1.111804020683668, disc_loss = 0.0005747919751750577
Trained batch 513 in epoch 8, gen_loss = 1.111747740423633, disc_loss = 0.0005741303407606136
Trained batch 514 in epoch 8, gen_loss = 1.1116396011658085, disc_loss = 0.0005738928250050697
Trained batch 515 in epoch 8, gen_loss = 1.111599794769472, disc_loss = 0.0005744761928249071
Trained batch 516 in epoch 8, gen_loss = 1.1117319702179795, disc_loss = 0.0005754086149453836
Trained batch 517 in epoch 8, gen_loss = 1.1116313231267525, disc_loss = 0.0005757510285077502
Trained batch 518 in epoch 8, gen_loss = 1.111389671332115, disc_loss = 0.0005752318916121867
Trained batch 519 in epoch 8, gen_loss = 1.1116835714532778, disc_loss = 0.0005744497631754851
Trained batch 520 in epoch 8, gen_loss = 1.1118255609971777, disc_loss = 0.0005738001937462703
Trained batch 521 in epoch 8, gen_loss = 1.111889783107458, disc_loss = 0.0005730930330257209
Trained batch 522 in epoch 8, gen_loss = 1.1116410853985847, disc_loss = 0.0005722891425368435
Trained batch 523 in epoch 8, gen_loss = 1.1118164151224472, disc_loss = 0.0005713426619370465
Trained batch 524 in epoch 8, gen_loss = 1.1117474844342186, disc_loss = 0.0005705587064481474
Trained batch 525 in epoch 8, gen_loss = 1.1116216411608706, disc_loss = 0.000570004823323943
Trained batch 526 in epoch 8, gen_loss = 1.1113309059468799, disc_loss = 0.0005697435176694073
Trained batch 527 in epoch 8, gen_loss = 1.1111868367050632, disc_loss = 0.0005691909370095042
Trained batch 528 in epoch 8, gen_loss = 1.1113660912432608, disc_loss = 0.0005687150902795695
Trained batch 529 in epoch 8, gen_loss = 1.1110858957722503, disc_loss = 0.0005682643346723503
Trained batch 530 in epoch 8, gen_loss = 1.1116435271871965, disc_loss = 0.0005677542210459663
Trained batch 531 in epoch 8, gen_loss = 1.1114455412205, disc_loss = 0.0005685975203713791
Trained batch 532 in epoch 8, gen_loss = 1.111178775665684, disc_loss = 0.0005711434348903537
Trained batch 533 in epoch 8, gen_loss = 1.1112084464633956, disc_loss = 0.0005739394791783113
Trained batch 534 in epoch 8, gen_loss = 1.1110573089011362, disc_loss = 0.0005760120201549083
Trained batch 535 in epoch 8, gen_loss = 1.1107096603112434, disc_loss = 0.0005780897222868942
Trained batch 536 in epoch 8, gen_loss = 1.1113657653886735, disc_loss = 0.0005802671258713707
Trained batch 537 in epoch 8, gen_loss = 1.111861420829943, disc_loss = 0.000582314501221155
Trained batch 538 in epoch 8, gen_loss = 1.1118429195903006, disc_loss = 0.0005835131156473837
Trained batch 539 in epoch 8, gen_loss = 1.1118016832404667, disc_loss = 0.0005837898337900967
Trained batch 540 in epoch 8, gen_loss = 1.111738640147084, disc_loss = 0.0005838581288090086
Trained batch 541 in epoch 8, gen_loss = 1.111836291547191, disc_loss = 0.0005834582421490046
Trained batch 542 in epoch 8, gen_loss = 1.1119345968819017, disc_loss = 0.0005829142772712236
Trained batch 543 in epoch 8, gen_loss = 1.1120110180448084, disc_loss = 0.0005823051486485757
Trained batch 544 in epoch 8, gen_loss = 1.1120857109717273, disc_loss = 0.0005816278843809381
Trained batch 545 in epoch 8, gen_loss = 1.1118684736363618, disc_loss = 0.0005809777189641441
Trained batch 546 in epoch 8, gen_loss = 1.1118601880953995, disc_loss = 0.0005802143116884267
Trained batch 547 in epoch 8, gen_loss = 1.111636193129268, disc_loss = 0.0005794121449057822
Trained batch 548 in epoch 8, gen_loss = 1.1115638656042963, disc_loss = 0.0005787064997830898
Trained batch 549 in epoch 8, gen_loss = 1.1114911311322992, disc_loss = 0.0005781310051944192
Trained batch 550 in epoch 8, gen_loss = 1.1114347783710044, disc_loss = 0.000577366257992999
Trained batch 551 in epoch 8, gen_loss = 1.1110999699735986, disc_loss = 0.0005765789446477488
Trained batch 552 in epoch 8, gen_loss = 1.1114254037682876, disc_loss = 0.0005759002938091917
Trained batch 553 in epoch 8, gen_loss = 1.1118946173346, disc_loss = 0.0005752875700564416
Trained batch 554 in epoch 8, gen_loss = 1.1119779809101207, disc_loss = 0.0005746900187627001
Trained batch 555 in epoch 8, gen_loss = 1.1115190544359976, disc_loss = 0.0005745247584881124
Trained batch 556 in epoch 8, gen_loss = 1.1112403083104418, disc_loss = 0.0005741821381957747
Trained batch 557 in epoch 8, gen_loss = 1.110933957881825, disc_loss = 0.0005743283564635839
Trained batch 558 in epoch 8, gen_loss = 1.1107562192863982, disc_loss = 0.0005755183309716904
Trained batch 559 in epoch 8, gen_loss = 1.1105344265699386, disc_loss = 0.000577569919680952
Trained batch 560 in epoch 8, gen_loss = 1.1106528870349688, disc_loss = 0.0005788201617532279
Trained batch 561 in epoch 8, gen_loss = 1.1104424156752346, disc_loss = 0.0005796789921071543
Trained batch 562 in epoch 8, gen_loss = 1.1105913842761919, disc_loss = 0.0005807628891346844
Trained batch 563 in epoch 8, gen_loss = 1.1109155397465889, disc_loss = 0.0005813352791776184
Trained batch 564 in epoch 8, gen_loss = 1.1109870864226754, disc_loss = 0.0005810271428055253
Trained batch 565 in epoch 8, gen_loss = 1.1106308711291202, disc_loss = 0.0005804607630022407
Trained batch 566 in epoch 8, gen_loss = 1.1107227137900324, disc_loss = 0.0005796594090003773
Trained batch 567 in epoch 8, gen_loss = 1.1106669856628901, disc_loss = 0.0005789370126210639
Trained batch 568 in epoch 8, gen_loss = 1.1105578440144945, disc_loss = 0.0005782581615156981
Trained batch 569 in epoch 8, gen_loss = 1.1104074455144113, disc_loss = 0.0005776286816782024
Trained batch 570 in epoch 8, gen_loss = 1.1103139583367183, disc_loss = 0.0005777068370139722
Trained batch 571 in epoch 8, gen_loss = 1.110166345859741, disc_loss = 0.0005785542208967174
Trained batch 572 in epoch 8, gen_loss = 1.1099387925332753, disc_loss = 0.0005791246217570266
Trained batch 573 in epoch 8, gen_loss = 1.1098538333945989, disc_loss = 0.0005788500523930886
Trained batch 574 in epoch 8, gen_loss = 1.1100422608334086, disc_loss = 0.0005782102541137567
Trained batch 575 in epoch 8, gen_loss = 1.1101758734633524, disc_loss = 0.0005775139757891642
Trained batch 576 in epoch 8, gen_loss = 1.1108507211328174, disc_loss = 0.0005769350528795728
Trained batch 577 in epoch 8, gen_loss = 1.1110024815199697, disc_loss = 0.000576201978147233
Trained batch 578 in epoch 8, gen_loss = 1.111042697606721, disc_loss = 0.0005756024466431418
Trained batch 579 in epoch 8, gen_loss = 1.11119769606097, disc_loss = 0.0005756734540948949
Trained batch 580 in epoch 8, gen_loss = 1.1111253768769886, disc_loss = 0.000576045893896299
Trained batch 581 in epoch 8, gen_loss = 1.1112070612071716, disc_loss = 0.0005760063090762907
Trained batch 582 in epoch 8, gen_loss = 1.111133903009405, disc_loss = 0.000575514647031984
Trained batch 583 in epoch 8, gen_loss = 1.1108553787208584, disc_loss = 0.0005749497325281208
Trained batch 584 in epoch 8, gen_loss = 1.1106079996141613, disc_loss = 0.0005742918187055864
Trained batch 585 in epoch 8, gen_loss = 1.1104566788510657, disc_loss = 0.0005736132529834381
Trained batch 586 in epoch 8, gen_loss = 1.1105912182562598, disc_loss = 0.0005729255114572544
Trained batch 587 in epoch 8, gen_loss = 1.1103214137002724, disc_loss = 0.0005725112675469793
Trained batch 588 in epoch 8, gen_loss = 1.110433543477277, disc_loss = 0.0005719973363281909
Trained batch 589 in epoch 8, gen_loss = 1.1099793960482387, disc_loss = 0.0005717034936562907
Trained batch 590 in epoch 8, gen_loss = 1.1097741141133703, disc_loss = 0.0005712500392115012
Trained batch 591 in epoch 8, gen_loss = 1.10988127178437, disc_loss = 0.0005706676353371664
Trained batch 592 in epoch 8, gen_loss = 1.1098613879732901, disc_loss = 0.0005701146821093291
Trained batch 593 in epoch 8, gen_loss = 1.1096872312051278, disc_loss = 0.0005694046005422817
Trained batch 594 in epoch 8, gen_loss = 1.1096464409547693, disc_loss = 0.0005686291793073692
Trained batch 595 in epoch 8, gen_loss = 1.1097220410436592, disc_loss = 0.0005680721832742843
Trained batch 596 in epoch 8, gen_loss = 1.1098885170778436, disc_loss = 0.0005674275277458191
Trained batch 597 in epoch 8, gen_loss = 1.11023973003279, disc_loss = 0.0005668430400986604
Trained batch 598 in epoch 8, gen_loss = 1.1100581661488655, disc_loss = 0.0005662435440912933
Trained batch 599 in epoch 8, gen_loss = 1.109827488164107, disc_loss = 0.0005659960788761964
Trained batch 600 in epoch 8, gen_loss = 1.109828760243097, disc_loss = 0.0005656517405047805
Trained batch 601 in epoch 8, gen_loss = 1.1098269286543825, disc_loss = 0.0005652783666511121
Trained batch 602 in epoch 8, gen_loss = 1.109738484247407, disc_loss = 0.0005646360909028032
Trained batch 603 in epoch 8, gen_loss = 1.1099104840826515, disc_loss = 0.0005638654115048949
Trained batch 604 in epoch 8, gen_loss = 1.1106392954006667, disc_loss = 0.0005632438412857865
Trained batch 605 in epoch 8, gen_loss = 1.1105477149927183, disc_loss = 0.000562652647012127
Trained batch 606 in epoch 8, gen_loss = 1.1103853764015525, disc_loss = 0.0005621760983153935
Trained batch 607 in epoch 8, gen_loss = 1.1103948489027589, disc_loss = 0.0005615445567472259
Trained batch 608 in epoch 8, gen_loss = 1.1102442877437486, disc_loss = 0.0005608766951616578
Trained batch 609 in epoch 8, gen_loss = 1.1104047830964698, disc_loss = 0.0005601667618230138
Trained batch 610 in epoch 8, gen_loss = 1.1103520739683348, disc_loss = 0.000559449015761026
Trained batch 611 in epoch 8, gen_loss = 1.1103119855028352, disc_loss = 0.000558737179114532
Trained batch 612 in epoch 8, gen_loss = 1.1100501437560575, disc_loss = 0.000558044568327488
Trained batch 613 in epoch 8, gen_loss = 1.1101039814055937, disc_loss = 0.0005573507771929286
Trained batch 614 in epoch 8, gen_loss = 1.1101571630656235, disc_loss = 0.0005567770568905701
Trained batch 615 in epoch 8, gen_loss = 1.1098664508430989, disc_loss = 0.000556544687419596
Trained batch 616 in epoch 8, gen_loss = 1.1099947941168007, disc_loss = 0.000556558099811379
Trained batch 617 in epoch 8, gen_loss = 1.1099547229731352, disc_loss = 0.0005564733159878671
Trained batch 618 in epoch 8, gen_loss = 1.1096218450774284, disc_loss = 0.0005566877734376063
Trained batch 619 in epoch 8, gen_loss = 1.1094569958025409, disc_loss = 0.0005569725736530663
Trained batch 620 in epoch 8, gen_loss = 1.109310233650576, disc_loss = 0.0005568451269058474
Trained batch 621 in epoch 8, gen_loss = 1.109191695401906, disc_loss = 0.0005564977407840625
Trained batch 622 in epoch 8, gen_loss = 1.1092404747085816, disc_loss = 0.0005559282212035676
Trained batch 623 in epoch 8, gen_loss = 1.1089516531389494, disc_loss = 0.0005552953283628225
Trained batch 624 in epoch 8, gen_loss = 1.1090272336006164, disc_loss = 0.000554734947765246
Trained batch 625 in epoch 8, gen_loss = 1.1091945614106358, disc_loss = 0.0005545583769333915
Trained batch 626 in epoch 8, gen_loss = 1.1086921974232322, disc_loss = 0.0005547339995309972
Trained batch 627 in epoch 8, gen_loss = 1.108425510442181, disc_loss = 0.0005546245471111671
Trained batch 628 in epoch 8, gen_loss = 1.1081058117657283, disc_loss = 0.0005541995951268431
Trained batch 629 in epoch 8, gen_loss = 1.1082429425110893, disc_loss = 0.0005535716123487209
Trained batch 630 in epoch 8, gen_loss = 1.1080059993852716, disc_loss = 0.0005529979510467481
Trained batch 631 in epoch 8, gen_loss = 1.1083670601814608, disc_loss = 0.0005530765062954006
Trained batch 632 in epoch 8, gen_loss = 1.1084679802070485, disc_loss = 0.0005530287791374558
Trained batch 633 in epoch 8, gen_loss = 1.1085882175608013, disc_loss = 0.0005527047990077272
Trained batch 634 in epoch 8, gen_loss = 1.108528684255645, disc_loss = 0.0005525060618611596
Trained batch 635 in epoch 8, gen_loss = 1.1082990229504663, disc_loss = 0.0005522299352550071
Trained batch 636 in epoch 8, gen_loss = 1.1079140473010962, disc_loss = 0.0005517299634028369
Trained batch 637 in epoch 8, gen_loss = 1.1079884156538027, disc_loss = 0.0005511220533947817
Trained batch 638 in epoch 8, gen_loss = 1.1077340608098325, disc_loss = 0.0005506349380952648
Trained batch 639 in epoch 8, gen_loss = 1.1075844751670956, disc_loss = 0.0005500834466829474
Trained batch 640 in epoch 8, gen_loss = 1.107429531546725, disc_loss = 0.0005495454422036599
Trained batch 641 in epoch 8, gen_loss = 1.1074170249273472, disc_loss = 0.0005489565116145527
Trained batch 642 in epoch 8, gen_loss = 1.1072310793270035, disc_loss = 0.000548417463474639
Trained batch 643 in epoch 8, gen_loss = 1.1073800343904436, disc_loss = 0.0005479173220767096
Trained batch 644 in epoch 8, gen_loss = 1.1072809393091718, disc_loss = 0.0005475536704897274
Trained batch 645 in epoch 8, gen_loss = 1.107246762089685, disc_loss = 0.0005477002009388272
Trained batch 646 in epoch 8, gen_loss = 1.107020785395845, disc_loss = 0.0005481753705146433
Trained batch 647 in epoch 8, gen_loss = 1.1069895833914662, disc_loss = 0.0005494171395925891
Trained batch 648 in epoch 8, gen_loss = 1.1070977340126626, disc_loss = 0.0005516338585721664
Trained batch 649 in epoch 8, gen_loss = 1.1070530406328347, disc_loss = 0.0005547567295322481
Trained batch 650 in epoch 8, gen_loss = 1.1069266286130692, disc_loss = 0.0005578355975545651
Trained batch 651 in epoch 8, gen_loss = 1.1070389406629866, disc_loss = 0.0005600116932261136
Trained batch 652 in epoch 8, gen_loss = 1.1070276423033676, disc_loss = 0.0005606537096749329
Trained batch 653 in epoch 8, gen_loss = 1.1067846036467712, disc_loss = 0.0005603095668133787
Trained batch 654 in epoch 8, gen_loss = 1.1068067541559234, disc_loss = 0.0005598245607155823
Trained batch 655 in epoch 8, gen_loss = 1.1067775580577734, disc_loss = 0.0005594539223061363
Trained batch 656 in epoch 8, gen_loss = 1.1071233312107476, disc_loss = 0.0005590568867259016
Trained batch 657 in epoch 8, gen_loss = 1.1074040048390537, disc_loss = 0.000558560324541228
Trained batch 658 in epoch 8, gen_loss = 1.1075779273766848, disc_loss = 0.0005580422596822949
Trained batch 659 in epoch 8, gen_loss = 1.1074072124380054, disc_loss = 0.0005574856231484746
Trained batch 660 in epoch 8, gen_loss = 1.1073933886688163, disc_loss = 0.0005568521220454349
Trained batch 661 in epoch 8, gen_loss = 1.107199118846853, disc_loss = 0.0005562330038999658
Trained batch 662 in epoch 8, gen_loss = 1.107162732074703, disc_loss = 0.0005556490899310876
Trained batch 663 in epoch 8, gen_loss = 1.1071326281112361, disc_loss = 0.0005551561324349437
Trained batch 664 in epoch 8, gen_loss = 1.106894784493554, disc_loss = 0.0005548704601999344
Trained batch 665 in epoch 8, gen_loss = 1.1065744692319863, disc_loss = 0.0005548352802307947
Trained batch 666 in epoch 8, gen_loss = 1.1062854454256426, disc_loss = 0.0005549413030387658
Trained batch 667 in epoch 8, gen_loss = 1.106087024429601, disc_loss = 0.0005552292694086711
Trained batch 668 in epoch 8, gen_loss = 1.1059623905896072, disc_loss = 0.0005550442149243853
Trained batch 669 in epoch 8, gen_loss = 1.1060082831489506, disc_loss = 0.0005548779840091132
Trained batch 670 in epoch 8, gen_loss = 1.106134657621739, disc_loss = 0.0005547026534104683
Trained batch 671 in epoch 8, gen_loss = 1.1062263512008248, disc_loss = 0.0005544821059672921
Trained batch 672 in epoch 8, gen_loss = 1.1061413498016912, disc_loss = 0.000554376160063439
Trained batch 673 in epoch 8, gen_loss = 1.1062741858846001, disc_loss = 0.0005543659715716332
Trained batch 674 in epoch 8, gen_loss = 1.1065473949467695, disc_loss = 0.0005542526576081635
Trained batch 675 in epoch 8, gen_loss = 1.106681108562904, disc_loss = 0.0005539864198009886
Trained batch 676 in epoch 8, gen_loss = 1.1070039783834178, disc_loss = 0.0005538653762632103
Trained batch 677 in epoch 8, gen_loss = 1.1067405806354365, disc_loss = 0.0005541118416900177
Trained batch 678 in epoch 8, gen_loss = 1.107266250257113, disc_loss = 0.0005542073434061715
Trained batch 679 in epoch 8, gen_loss = 1.1075931963675163, disc_loss = 0.0005540259813749478
Trained batch 680 in epoch 8, gen_loss = 1.1075211380896939, disc_loss = 0.0005538079098448917
Trained batch 681 in epoch 8, gen_loss = 1.1076883242801487, disc_loss = 0.0005535949957423879
Trained batch 682 in epoch 8, gen_loss = 1.1076736974681278, disc_loss = 0.0005530846298757141
Trained batch 683 in epoch 8, gen_loss = 1.1081491535344319, disc_loss = 0.0005524759855465515
Trained batch 684 in epoch 8, gen_loss = 1.1083996554360773, disc_loss = 0.0005518462240821716
Trained batch 685 in epoch 8, gen_loss = 1.1081442156964072, disc_loss = 0.0005511655270274044
Trained batch 686 in epoch 8, gen_loss = 1.108144512863659, disc_loss = 0.0005505129735523041
Trained batch 687 in epoch 8, gen_loss = 1.107992450685002, disc_loss = 0.0005498510835592284
Trained batch 688 in epoch 8, gen_loss = 1.1079618178189061, disc_loss = 0.0005492268471846983
Trained batch 689 in epoch 8, gen_loss = 1.1078856449196304, disc_loss = 0.000548562442955976
Trained batch 690 in epoch 8, gen_loss = 1.1077609848872625, disc_loss = 0.0005479341877173557
Trained batch 691 in epoch 8, gen_loss = 1.1074335289139279, disc_loss = 0.0005474045584257558
Trained batch 692 in epoch 8, gen_loss = 1.1075224802435562, disc_loss = 0.000547107090551304
Trained batch 693 in epoch 8, gen_loss = 1.1074245651104953, disc_loss = 0.0005471683489776053
Trained batch 694 in epoch 8, gen_loss = 1.107233811796998, disc_loss = 0.0005474261061804329
Trained batch 695 in epoch 8, gen_loss = 1.1070807850223847, disc_loss = 0.0005479921337087296
Trained batch 696 in epoch 8, gen_loss = 1.1069233973364918, disc_loss = 0.0005487256374916963
Trained batch 697 in epoch 8, gen_loss = 1.1067434916523602, disc_loss = 0.0005492731441148586
Trained batch 698 in epoch 8, gen_loss = 1.1066661288639337, disc_loss = 0.0005494342342109682
Trained batch 699 in epoch 8, gen_loss = 1.106522696018219, disc_loss = 0.0005494312904608835
Trained batch 700 in epoch 8, gen_loss = 1.1065382841820384, disc_loss = 0.0005495598387423525
Trained batch 701 in epoch 8, gen_loss = 1.1063252237447647, disc_loss = 0.0005496702525277816
Trained batch 702 in epoch 8, gen_loss = 1.1061835049904596, disc_loss = 0.0005496024069009325
Trained batch 703 in epoch 8, gen_loss = 1.1059676197950135, disc_loss = 0.0005495494517824475
Trained batch 704 in epoch 8, gen_loss = 1.1060518077924741, disc_loss = 0.0005492863674641501
Trained batch 705 in epoch 8, gen_loss = 1.106038244435875, disc_loss = 0.0005487773120409886
Trained batch 706 in epoch 8, gen_loss = 1.1058476164283644, disc_loss = 0.0005482376568843354
Trained batch 707 in epoch 8, gen_loss = 1.1058625465227385, disc_loss = 0.0005477598779025819
Trained batch 708 in epoch 8, gen_loss = 1.1059217739676892, disc_loss = 0.0005471776577818756
Trained batch 709 in epoch 8, gen_loss = 1.1059951141686506, disc_loss = 0.0005465776835503483
Trained batch 710 in epoch 8, gen_loss = 1.1061979729247329, disc_loss = 0.0005460322001080668
Trained batch 711 in epoch 8, gen_loss = 1.1063193925813344, disc_loss = 0.0005455069684491688
Trained batch 712 in epoch 8, gen_loss = 1.106293393301596, disc_loss = 0.000544999803519376
Trained batch 713 in epoch 8, gen_loss = 1.1061801131532973, disc_loss = 0.0005445925912566917
Trained batch 714 in epoch 8, gen_loss = 1.1062587330391358, disc_loss = 0.0005441062162256592
Trained batch 715 in epoch 8, gen_loss = 1.1062097751727984, disc_loss = 0.0005434910390808477
Trained batch 716 in epoch 8, gen_loss = 1.1059417920797605, disc_loss = 0.0005429259678801084
Trained batch 717 in epoch 8, gen_loss = 1.1060697208872081, disc_loss = 0.0005424569482738535
Trained batch 718 in epoch 8, gen_loss = 1.1059075554985662, disc_loss = 0.000542087360600224
Trained batch 719 in epoch 8, gen_loss = 1.1060754162569841, disc_loss = 0.0005417589828539349
Trained batch 720 in epoch 8, gen_loss = 1.1059973526761535, disc_loss = 0.0005412332965547881
Trained batch 721 in epoch 8, gen_loss = 1.1060940909748922, disc_loss = 0.0005405869936784813
Trained batch 722 in epoch 8, gen_loss = 1.106095993255019, disc_loss = 0.0005400922680232592
Trained batch 723 in epoch 8, gen_loss = 1.1058994101062005, disc_loss = 0.0005400881582318107
Trained batch 724 in epoch 8, gen_loss = 1.1061602442017917, disc_loss = 0.0005401825280318133
Trained batch 725 in epoch 8, gen_loss = 1.1061038262423732, disc_loss = 0.000539946838544785
Trained batch 726 in epoch 8, gen_loss = 1.1063391408861258, disc_loss = 0.0005395017036204316
Trained batch 727 in epoch 8, gen_loss = 1.1060953650337, disc_loss = 0.0005394919293953885
Trained batch 728 in epoch 8, gen_loss = 1.1061726308980924, disc_loss = 0.0005401464882939933
Trained batch 729 in epoch 8, gen_loss = 1.1060697820905137, disc_loss = 0.0005407705300743532
Trained batch 730 in epoch 8, gen_loss = 1.106004584259602, disc_loss = 0.0005415347777932109
Trained batch 731 in epoch 8, gen_loss = 1.1057828232401707, disc_loss = 0.000541939261426104
Trained batch 732 in epoch 8, gen_loss = 1.1060160396043797, disc_loss = 0.0005419828827381878
Trained batch 733 in epoch 8, gen_loss = 1.1057095370922816, disc_loss = 0.0005418347373398747
Trained batch 734 in epoch 8, gen_loss = 1.1056029524932913, disc_loss = 0.000541550985810293
Trained batch 735 in epoch 8, gen_loss = 1.1058753867350195, disc_loss = 0.0005414034705470682
Trained batch 736 in epoch 8, gen_loss = 1.1056129357384537, disc_loss = 0.0005416054520940028
Trained batch 737 in epoch 8, gen_loss = 1.1055258655451177, disc_loss = 0.0005431431323261635
Trained batch 738 in epoch 8, gen_loss = 1.1053412953474848, disc_loss = 0.0005454899098917733
Trained batch 739 in epoch 8, gen_loss = 1.1053376304942208, disc_loss = 0.0005473787990430955
Trained batch 740 in epoch 8, gen_loss = 1.105557103951772, disc_loss = 0.0005496039596065286
Trained batch 741 in epoch 8, gen_loss = 1.1058538097416295, disc_loss = 0.000553970656584339
Trained batch 742 in epoch 8, gen_loss = 1.1060437943540704, disc_loss = 0.000557497295071631
Trained batch 743 in epoch 8, gen_loss = 1.1061357656313526, disc_loss = 0.0005589418068500167
Trained batch 744 in epoch 8, gen_loss = 1.106189953800816, disc_loss = 0.0005593989584802013
Trained batch 745 in epoch 8, gen_loss = 1.1060897395534106, disc_loss = 0.0005593933460500682
Trained batch 746 in epoch 8, gen_loss = 1.1059278855362091, disc_loss = 0.0005597985702912932
Trained batch 747 in epoch 8, gen_loss = 1.1058262711699633, disc_loss = 0.0005601216038057293
Trained batch 748 in epoch 8, gen_loss = 1.1056384512674666, disc_loss = 0.0005599188516498543
Trained batch 749 in epoch 8, gen_loss = 1.1054359569549561, disc_loss = 0.0005598105822864454
Trained batch 750 in epoch 8, gen_loss = 1.1054838676744707, disc_loss = 0.0005600575637804765
Trained batch 751 in epoch 8, gen_loss = 1.105339212144943, disc_loss = 0.0005611072468591954
Trained batch 752 in epoch 8, gen_loss = 1.1049500238372985, disc_loss = 0.0005637684194013201
Trained batch 753 in epoch 8, gen_loss = 1.1049607443556546, disc_loss = 0.000566592491162766
Trained batch 754 in epoch 8, gen_loss = 1.1047658803447193, disc_loss = 0.000569637964638829
Trained batch 755 in epoch 8, gen_loss = 1.104755147739693, disc_loss = 0.0005721786371285186
Trained batch 756 in epoch 8, gen_loss = 1.1048045536328497, disc_loss = 0.0005732747481181963
Trained batch 757 in epoch 8, gen_loss = 1.1045051484435089, disc_loss = 0.0005742916926892264
Trained batch 758 in epoch 8, gen_loss = 1.1045997188339434, disc_loss = 0.0005747056145630365
Trained batch 759 in epoch 8, gen_loss = 1.1046724466901077, disc_loss = 0.0005746771501531169
Trained batch 760 in epoch 8, gen_loss = 1.104518967530104, disc_loss = 0.0005750563482616407
Trained batch 761 in epoch 8, gen_loss = 1.1046004369659375, disc_loss = 0.0005763044857513679
Trained batch 762 in epoch 8, gen_loss = 1.104445565887391, disc_loss = 0.0005775280047055037
Trained batch 763 in epoch 8, gen_loss = 1.1045098498229582, disc_loss = 0.0005781460006548981
Trained batch 764 in epoch 8, gen_loss = 1.104748400519876, disc_loss = 0.0005778480711978179
Trained batch 765 in epoch 8, gen_loss = 1.1048054937905494, disc_loss = 0.0005776981814350603
Trained batch 766 in epoch 8, gen_loss = 1.1050015680171366, disc_loss = 0.0005778717931689824
Trained batch 767 in epoch 8, gen_loss = 1.104813070424522, disc_loss = 0.0005780423206355559
Trained batch 768 in epoch 8, gen_loss = 1.104542615742305, disc_loss = 0.000579304369340965
Trained batch 769 in epoch 8, gen_loss = 1.1043827608808294, disc_loss = 0.0005818689295393868
Trained batch 770 in epoch 8, gen_loss = 1.104158378992563, disc_loss = 0.0005844695403153196
Trained batch 771 in epoch 8, gen_loss = 1.1043579047980085, disc_loss = 0.0005875405259696565
Trained batch 772 in epoch 8, gen_loss = 1.1041984563503042, disc_loss = 0.0005901267782341174
Trained batch 773 in epoch 8, gen_loss = 1.1042495663313903, disc_loss = 0.0005911376482064238
Trained batch 774 in epoch 8, gen_loss = 1.1042194164183832, disc_loss = 0.0005916567127719792
Trained batch 775 in epoch 8, gen_loss = 1.1044247765670117, disc_loss = 0.0005922833319739756
Trained batch 776 in epoch 8, gen_loss = 1.1046366537399734, disc_loss = 0.0005926304608014859
Trained batch 777 in epoch 8, gen_loss = 1.1045980941513818, disc_loss = 0.0005926372154495663
Trained batch 778 in epoch 8, gen_loss = 1.104728300626532, disc_loss = 0.0005922796800978445
Trained batch 779 in epoch 8, gen_loss = 1.104946753077018, disc_loss = 0.0005918336558422127
Trained batch 780 in epoch 8, gen_loss = 1.1050609657767487, disc_loss = 0.0005914942777308543
Trained batch 781 in epoch 8, gen_loss = 1.1049735911209564, disc_loss = 0.0005911620580410386
Trained batch 782 in epoch 8, gen_loss = 1.1050801277921878, disc_loss = 0.0005906612539844853
Trained batch 783 in epoch 8, gen_loss = 1.104992521736695, disc_loss = 0.000590645995182095
Trained batch 784 in epoch 8, gen_loss = 1.1051079015822927, disc_loss = 0.0005903738380389757
Trained batch 785 in epoch 8, gen_loss = 1.1049419599786665, disc_loss = 0.0005898642036552113
Trained batch 786 in epoch 8, gen_loss = 1.1048936587125253, disc_loss = 0.0005893466179277612
Trained batch 787 in epoch 8, gen_loss = 1.1050568426472283, disc_loss = 0.0005889524855973171
Trained batch 788 in epoch 8, gen_loss = 1.1051600460619377, disc_loss = 0.0005883840001517988
Trained batch 789 in epoch 8, gen_loss = 1.1050474944748456, disc_loss = 0.0005878935707383053
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 1.2072421312332153, disc_loss = 0.00027814059285447
Trained batch 1 in epoch 9, gen_loss = 1.151384711265564, disc_loss = 0.000300111947581172
Trained batch 2 in epoch 9, gen_loss = 1.0933967630068462, disc_loss = 0.000318363318607832
Trained batch 3 in epoch 9, gen_loss = 1.1829983741044998, disc_loss = 0.00031269984174286947
Trained batch 4 in epoch 9, gen_loss = 1.1623566031455994, disc_loss = 0.00029383572691585866
Trained batch 5 in epoch 9, gen_loss = 1.1522362927595775, disc_loss = 0.0002863457557396032
Trained batch 6 in epoch 9, gen_loss = 1.1445159826959883, disc_loss = 0.00030840657460170666
Trained batch 7 in epoch 9, gen_loss = 1.117651306092739, disc_loss = 0.00035495441443345044
Trained batch 8 in epoch 9, gen_loss = 1.1326871116956074, disc_loss = 0.00041587468553593173
Trained batch 9 in epoch 9, gen_loss = 1.1431116044521332, disc_loss = 0.00044810888502979653
Trained batch 10 in epoch 9, gen_loss = 1.1594897346063093, disc_loss = 0.0004415375283728777
Trained batch 11 in epoch 9, gen_loss = 1.1428797791401546, disc_loss = 0.0004205707591609098
Trained batch 12 in epoch 9, gen_loss = 1.1418716311454773, disc_loss = 0.0004027917871448713
Trained batch 13 in epoch 9, gen_loss = 1.1414843159062522, disc_loss = 0.0003817178476310801
Trained batch 14 in epoch 9, gen_loss = 1.1366339882214864, disc_loss = 0.00037052084856744233
Trained batch 15 in epoch 9, gen_loss = 1.1358672343194485, disc_loss = 0.0003636066235230828
Trained batch 16 in epoch 9, gen_loss = 1.1305752186214222, disc_loss = 0.0003676748023923103
Trained batch 17 in epoch 9, gen_loss = 1.1253382199340396, disc_loss = 0.0003951158695498533
Trained batch 18 in epoch 9, gen_loss = 1.1295313552806252, disc_loss = 0.00044775982486929645
Trained batch 19 in epoch 9, gen_loss = 1.1201831519603729, disc_loss = 0.0005085748420242453
Trained batch 20 in epoch 9, gen_loss = 1.1143165401050024, disc_loss = 0.000545380922890867
Trained batch 21 in epoch 9, gen_loss = 1.1026613360101527, disc_loss = 0.000604308456703703
Trained batch 22 in epoch 9, gen_loss = 1.1012030399363975, disc_loss = 0.0006673167710845439
Trained batch 23 in epoch 9, gen_loss = 1.0970211649934452, disc_loss = 0.000701295457171606
Trained batch 24 in epoch 9, gen_loss = 1.1005241179466247, disc_loss = 0.0007006590304081328
Trained batch 25 in epoch 9, gen_loss = 1.100965671814405, disc_loss = 0.0006908383782921681
Trained batch 26 in epoch 9, gen_loss = 1.1008024988351044, disc_loss = 0.0006815629811306415
Trained batch 27 in epoch 9, gen_loss = 1.1083164789846964, disc_loss = 0.0006877321744208789
Trained batch 28 in epoch 9, gen_loss = 1.1104260292546502, disc_loss = 0.0007038785685114723
Trained batch 29 in epoch 9, gen_loss = 1.115784086783727, disc_loss = 0.0007216096819320228
Trained batch 30 in epoch 9, gen_loss = 1.115505208892207, disc_loss = 0.0007173829027094818
Trained batch 31 in epoch 9, gen_loss = 1.1178377661854029, disc_loss = 0.0007033220156245079
Trained batch 32 in epoch 9, gen_loss = 1.1158145720308477, disc_loss = 0.000697056198656686
Trained batch 33 in epoch 9, gen_loss = 1.1256240343346315, disc_loss = 0.0007175861188871375
Trained batch 34 in epoch 9, gen_loss = 1.1257198214530946, disc_loss = 0.0007664323054736347
Trained batch 35 in epoch 9, gen_loss = 1.1313109050194423, disc_loss = 0.0008075481424990963
Trained batch 36 in epoch 9, gen_loss = 1.1244126010585476, disc_loss = 0.0008215921448395789
Trained batch 37 in epoch 9, gen_loss = 1.1215732599559582, disc_loss = 0.0008171017936164342
Trained batch 38 in epoch 9, gen_loss = 1.1232407154181066, disc_loss = 0.0008057354315473603
Trained batch 39 in epoch 9, gen_loss = 1.121344792842865, disc_loss = 0.0007918106692159199
Trained batch 40 in epoch 9, gen_loss = 1.12511142870275, disc_loss = 0.0007768871343237484
Trained batch 41 in epoch 9, gen_loss = 1.1208584578264327, disc_loss = 0.0007634102233472125
Trained batch 42 in epoch 9, gen_loss = 1.1215983033180237, disc_loss = 0.0007584720995848414
Trained batch 43 in epoch 9, gen_loss = 1.1244860901073976, disc_loss = 0.0007529051063928902
Trained batch 44 in epoch 9, gen_loss = 1.1248646219571432, disc_loss = 0.0007428167366823699
Trained batch 45 in epoch 9, gen_loss = 1.1298005023728246, disc_loss = 0.0007329339573714052
Trained batch 46 in epoch 9, gen_loss = 1.1313994653681492, disc_loss = 0.0007258455956074845
Trained batch 47 in epoch 9, gen_loss = 1.1263567221661408, disc_loss = 0.0007222390630280037
Trained batch 48 in epoch 9, gen_loss = 1.1225711070761388, disc_loss = 0.0007185059935460342
Trained batch 49 in epoch 9, gen_loss = 1.124455565214157, disc_loss = 0.000709803751524305
Trained batch 50 in epoch 9, gen_loss = 1.12462516041363, disc_loss = 0.0007049970837554201
Trained batch 51 in epoch 9, gen_loss = 1.1234051711284196, disc_loss = 0.0006974732094442096
Trained batch 52 in epoch 9, gen_loss = 1.1218905415175096, disc_loss = 0.0006923618448298548
Trained batch 53 in epoch 9, gen_loss = 1.11861166689131, disc_loss = 0.0006883098910664019
Trained batch 54 in epoch 9, gen_loss = 1.1203880093314431, disc_loss = 0.0006808834900518626
Trained batch 55 in epoch 9, gen_loss = 1.1194294052464622, disc_loss = 0.000673680672662158
Trained batch 56 in epoch 9, gen_loss = 1.1189706116391902, disc_loss = 0.0006662910397464753
Trained batch 57 in epoch 9, gen_loss = 1.114962253077277, disc_loss = 0.0006590280299233513
Trained batch 58 in epoch 9, gen_loss = 1.120212332677033, disc_loss = 0.0006518528489169065
Trained batch 59 in epoch 9, gen_loss = 1.1165694743394852, disc_loss = 0.0006479614730778849
Trained batch 60 in epoch 9, gen_loss = 1.117124888740602, disc_loss = 0.0006495233884961039
Trained batch 61 in epoch 9, gen_loss = 1.1176006822816786, disc_loss = 0.0006550328723660054
Trained batch 62 in epoch 9, gen_loss = 1.1162134039969671, disc_loss = 0.000653231680593712
Trained batch 63 in epoch 9, gen_loss = 1.1173753468319774, disc_loss = 0.0006465221114240194
Trained batch 64 in epoch 9, gen_loss = 1.1138765014134921, disc_loss = 0.0006409473919820112
Trained batch 65 in epoch 9, gen_loss = 1.1148693173220663, disc_loss = 0.0006362016178944473
Trained batch 66 in epoch 9, gen_loss = 1.115694737256463, disc_loss = 0.0006312253428214758
Trained batch 67 in epoch 9, gen_loss = 1.1158130598418854, disc_loss = 0.0006261337605204009
Trained batch 68 in epoch 9, gen_loss = 1.1186017445895984, disc_loss = 0.0006202402208515011
Trained batch 69 in epoch 9, gen_loss = 1.119625039611544, disc_loss = 0.0006148675428578696
Trained batch 70 in epoch 9, gen_loss = 1.1190697466823416, disc_loss = 0.0006079060071833353
Trained batch 71 in epoch 9, gen_loss = 1.1187237459752295, disc_loss = 0.0006015889579834442
Trained batch 72 in epoch 9, gen_loss = 1.11970736474207, disc_loss = 0.0005954634017480078
Trained batch 73 in epoch 9, gen_loss = 1.1189605215111293, disc_loss = 0.0005888385995923592
Trained batch 74 in epoch 9, gen_loss = 1.1169296765327454, disc_loss = 0.000583637200955612
Trained batch 75 in epoch 9, gen_loss = 1.1170514406342256, disc_loss = 0.0005780888635567145
Trained batch 76 in epoch 9, gen_loss = 1.1175983377865382, disc_loss = 0.0005725130908245632
Trained batch 77 in epoch 9, gen_loss = 1.1184379680034442, disc_loss = 0.0005682817492738534
Trained batch 78 in epoch 9, gen_loss = 1.1177457065521916, disc_loss = 0.0005653695079212112
Trained batch 79 in epoch 9, gen_loss = 1.1150345154106618, disc_loss = 0.0005624718376566306
Trained batch 80 in epoch 9, gen_loss = 1.1118614504366746, disc_loss = 0.0005590257292001128
Trained batch 81 in epoch 9, gen_loss = 1.1119497033154093, disc_loss = 0.000556614067335897
Trained batch 82 in epoch 9, gen_loss = 1.1107114776071296, disc_loss = 0.0005558451330106907
Trained batch 83 in epoch 9, gen_loss = 1.109034008923031, disc_loss = 0.0005575552043280498
Trained batch 84 in epoch 9, gen_loss = 1.1088495030122645, disc_loss = 0.0005569182485273546
Trained batch 85 in epoch 9, gen_loss = 1.109148692253024, disc_loss = 0.000552777701117055
Trained batch 86 in epoch 9, gen_loss = 1.1080587444634273, disc_loss = 0.0005487306332871339
Trained batch 87 in epoch 9, gen_loss = 1.109322875738144, disc_loss = 0.0005437632522774617
Trained batch 88 in epoch 9, gen_loss = 1.1095676797159602, disc_loss = 0.0005391368010830857
Trained batch 89 in epoch 9, gen_loss = 1.1077515277597638, disc_loss = 0.0005352385882967307
Trained batch 90 in epoch 9, gen_loss = 1.1053963224966448, disc_loss = 0.0005312175685853268
Trained batch 91 in epoch 9, gen_loss = 1.1050641426573629, disc_loss = 0.0005266522281169233
Trained batch 92 in epoch 9, gen_loss = 1.1045145853873222, disc_loss = 0.0005243460559980913
Trained batch 93 in epoch 9, gen_loss = 1.1044112095173368, disc_loss = 0.0005283023213238227
Trained batch 94 in epoch 9, gen_loss = 1.108584483673698, disc_loss = 0.0005350446722954266
Trained batch 95 in epoch 9, gen_loss = 1.109155224636197, disc_loss = 0.0005377531235808419
Trained batch 96 in epoch 9, gen_loss = 1.108329479841842, disc_loss = 0.0005363335552566551
Trained batch 97 in epoch 9, gen_loss = 1.1097232413535216, disc_loss = 0.0005333639617637512
Trained batch 98 in epoch 9, gen_loss = 1.1099413530995148, disc_loss = 0.0005316974311059275
Trained batch 99 in epoch 9, gen_loss = 1.110177749991417, disc_loss = 0.0005321673530124826
Trained batch 100 in epoch 9, gen_loss = 1.1113154410135628, disc_loss = 0.0005328132185853308
Trained batch 101 in epoch 9, gen_loss = 1.1107983419708176, disc_loss = 0.0005330665215510902
Trained batch 102 in epoch 9, gen_loss = 1.1119124131295288, disc_loss = 0.0005315594703328651
Trained batch 103 in epoch 9, gen_loss = 1.1102216891371286, disc_loss = 0.0005296180130384387
Trained batch 104 in epoch 9, gen_loss = 1.1096711845625014, disc_loss = 0.0005284027387027718
Trained batch 105 in epoch 9, gen_loss = 1.110503743841963, disc_loss = 0.0005279310408816014
Trained batch 106 in epoch 9, gen_loss = 1.1101803283825098, disc_loss = 0.0005284079616953549
Trained batch 107 in epoch 9, gen_loss = 1.1096281834222652, disc_loss = 0.0005281522459241656
Trained batch 108 in epoch 9, gen_loss = 1.1093417400613836, disc_loss = 0.0005278729524868199
Trained batch 109 in epoch 9, gen_loss = 1.107020954652266, disc_loss = 0.0005299167238593906
Trained batch 110 in epoch 9, gen_loss = 1.1058180138871476, disc_loss = 0.0005314030061420346
Trained batch 111 in epoch 9, gen_loss = 1.1054638453892298, disc_loss = 0.0005300028075388192
Trained batch 112 in epoch 9, gen_loss = 1.1052600588418742, disc_loss = 0.0005285304332171584
Trained batch 113 in epoch 9, gen_loss = 1.1046149333318074, disc_loss = 0.0005263130954980417
Trained batch 114 in epoch 9, gen_loss = 1.103309988975525, disc_loss = 0.0005231235881776387
Trained batch 115 in epoch 9, gen_loss = 1.1039565760513832, disc_loss = 0.0005198592939920893
Trained batch 116 in epoch 9, gen_loss = 1.1054690026829386, disc_loss = 0.0005164680162093475
Trained batch 117 in epoch 9, gen_loss = 1.1036386323177207, disc_loss = 0.0005137000517930511
Trained batch 118 in epoch 9, gen_loss = 1.1043494564144551, disc_loss = 0.0005104514163553895
Trained batch 119 in epoch 9, gen_loss = 1.1031407728791236, disc_loss = 0.0005081432283986942
Trained batch 120 in epoch 9, gen_loss = 1.1016640909447157, disc_loss = 0.0005064136744933857
Trained batch 121 in epoch 9, gen_loss = 1.1035423122468542, disc_loss = 0.000503361050803386
Trained batch 122 in epoch 9, gen_loss = 1.1039083033073238, disc_loss = 0.0005017139864787346
Trained batch 123 in epoch 9, gen_loss = 1.1040610151906167, disc_loss = 0.000499457533571272
Trained batch 124 in epoch 9, gen_loss = 1.104584566116333, disc_loss = 0.0004968955333461054
Trained batch 125 in epoch 9, gen_loss = 1.1044515484855288, disc_loss = 0.0004948987009392733
Trained batch 126 in epoch 9, gen_loss = 1.1045443673772135, disc_loss = 0.0004932948644937559
Trained batch 127 in epoch 9, gen_loss = 1.1047921143472195, disc_loss = 0.0004918497216408468
Trained batch 128 in epoch 9, gen_loss = 1.1073726776034334, disc_loss = 0.0004907306166958648
Trained batch 129 in epoch 9, gen_loss = 1.1092229852309594, disc_loss = 0.0004890396578188162
Trained batch 130 in epoch 9, gen_loss = 1.1086572636174792, disc_loss = 0.000487798105141962
Trained batch 131 in epoch 9, gen_loss = 1.1076765922885952, disc_loss = 0.00048707215875875784
Trained batch 132 in epoch 9, gen_loss = 1.1072269431630473, disc_loss = 0.0004865793398904432
Trained batch 133 in epoch 9, gen_loss = 1.1059271884498312, disc_loss = 0.00048527334528539065
Trained batch 134 in epoch 9, gen_loss = 1.1055080903900993, disc_loss = 0.00048474801075860377
Trained batch 135 in epoch 9, gen_loss = 1.108104403842898, disc_loss = 0.0004860644213455517
Trained batch 136 in epoch 9, gen_loss = 1.109309255206672, disc_loss = 0.0004865081667374092
Trained batch 137 in epoch 9, gen_loss = 1.1092008546642635, disc_loss = 0.00048648829065116485
Trained batch 138 in epoch 9, gen_loss = 1.1097062272991207, disc_loss = 0.0004870167478735612
Trained batch 139 in epoch 9, gen_loss = 1.1093218782118388, disc_loss = 0.00048702373652694013
Trained batch 140 in epoch 9, gen_loss = 1.108990653609553, disc_loss = 0.0004874327968156249
Trained batch 141 in epoch 9, gen_loss = 1.1079741930457907, disc_loss = 0.0004863045943354119
Trained batch 142 in epoch 9, gen_loss = 1.10796479036758, disc_loss = 0.0004855797777601218
Trained batch 143 in epoch 9, gen_loss = 1.1073618046939373, disc_loss = 0.0004850957515271956
Trained batch 144 in epoch 9, gen_loss = 1.1059937653870417, disc_loss = 0.0004845606639342993
Trained batch 145 in epoch 9, gen_loss = 1.1069821401001656, disc_loss = 0.0004837891764796103
Trained batch 146 in epoch 9, gen_loss = 1.1110095089795637, disc_loss = 0.00048471428043102895
Trained batch 147 in epoch 9, gen_loss = 1.1113577521330602, disc_loss = 0.0004857125284714228
Trained batch 148 in epoch 9, gen_loss = 1.1106377380006265, disc_loss = 0.00048446123303272045
Trained batch 149 in epoch 9, gen_loss = 1.1098213549455007, disc_loss = 0.000482712107526216
Trained batch 150 in epoch 9, gen_loss = 1.1094573037513833, disc_loss = 0.00048079829577654166
Trained batch 151 in epoch 9, gen_loss = 1.1085747201976024, disc_loss = 0.0004787248821900759
Trained batch 152 in epoch 9, gen_loss = 1.1082647286988552, disc_loss = 0.00047632400060583854
Trained batch 153 in epoch 9, gen_loss = 1.1094186634986432, disc_loss = 0.00047427001543412614
Trained batch 154 in epoch 9, gen_loss = 1.1099023115250373, disc_loss = 0.0004727170077873574
Trained batch 155 in epoch 9, gen_loss = 1.1097057633675063, disc_loss = 0.000472045961009243
Trained batch 156 in epoch 9, gen_loss = 1.1105092851219662, disc_loss = 0.00047074671954088577
Trained batch 157 in epoch 9, gen_loss = 1.110223622638968, disc_loss = 0.0004691828798968345
Trained batch 158 in epoch 9, gen_loss = 1.1117164567581512, disc_loss = 0.0004676520182317673
Trained batch 159 in epoch 9, gen_loss = 1.1108146656304598, disc_loss = 0.00046601525809819577
Trained batch 160 in epoch 9, gen_loss = 1.1115580815706194, disc_loss = 0.0004646252815088153
Trained batch 161 in epoch 9, gen_loss = 1.11209096621584, disc_loss = 0.00046297949823237563
Trained batch 162 in epoch 9, gen_loss = 1.1113133843691072, disc_loss = 0.00046092813930608494
Trained batch 163 in epoch 9, gen_loss = 1.1103629255440177, disc_loss = 0.0004590188220346335
Trained batch 164 in epoch 9, gen_loss = 1.1105136781027822, disc_loss = 0.0004580608129000404
Trained batch 165 in epoch 9, gen_loss = 1.1113770140940884, disc_loss = 0.00045821646970755655
Trained batch 166 in epoch 9, gen_loss = 1.1122760205211755, disc_loss = 0.0004588939800397019
Trained batch 167 in epoch 9, gen_loss = 1.1121134662202425, disc_loss = 0.0004607232865618287
Trained batch 168 in epoch 9, gen_loss = 1.112286778244041, disc_loss = 0.0004645074934170984
Trained batch 169 in epoch 9, gen_loss = 1.113652749271954, disc_loss = 0.00046893441544585475
Trained batch 170 in epoch 9, gen_loss = 1.1123734869455035, disc_loss = 0.00047299899040021505
Trained batch 171 in epoch 9, gen_loss = 1.1127120114343112, disc_loss = 0.00047575963938914696
Trained batch 172 in epoch 9, gen_loss = 1.1127626134481043, disc_loss = 0.00047674706662302526
Trained batch 173 in epoch 9, gen_loss = 1.1136606489789898, disc_loss = 0.00047728638193133855
Trained batch 174 in epoch 9, gen_loss = 1.1146964587484087, disc_loss = 0.000476872292097791
Trained batch 175 in epoch 9, gen_loss = 1.1139909130605785, disc_loss = 0.00047753865783306537
Trained batch 176 in epoch 9, gen_loss = 1.1152731301420826, disc_loss = 0.0004832869347765
Trained batch 177 in epoch 9, gen_loss = 1.1148319840431213, disc_loss = 0.0004910526966729746
Trained batch 178 in epoch 9, gen_loss = 1.1160131140128193, disc_loss = 0.0004998420466123899
Trained batch 179 in epoch 9, gen_loss = 1.1155656192037795, disc_loss = 0.0005148048028382214
Trained batch 180 in epoch 9, gen_loss = 1.1143518692880705, disc_loss = 0.0005369244114584573
Trained batch 181 in epoch 9, gen_loss = 1.1147984659278787, disc_loss = 0.0005672134461097553
Trained batch 182 in epoch 9, gen_loss = 1.1157083661178422, disc_loss = 0.0006025320083911841
Trained batch 183 in epoch 9, gen_loss = 1.115343720368717, disc_loss = 0.0006192328703985803
Trained batch 184 in epoch 9, gen_loss = 1.1151450563121486, disc_loss = 0.0006221662307743335
Trained batch 185 in epoch 9, gen_loss = 1.1145738728584782, disc_loss = 0.0006213856599530236
Trained batch 186 in epoch 9, gen_loss = 1.1143855787216024, disc_loss = 0.0006250704699824689
Trained batch 187 in epoch 9, gen_loss = 1.1142579805343709, disc_loss = 0.0006266322666983507
Trained batch 188 in epoch 9, gen_loss = 1.1141064450854348, disc_loss = 0.0006259129415469481
Trained batch 189 in epoch 9, gen_loss = 1.1144309985010248, disc_loss = 0.0006244179088849035
Trained batch 190 in epoch 9, gen_loss = 1.1144743521176084, disc_loss = 0.0006239661040712216
Trained batch 191 in epoch 9, gen_loss = 1.114789300908645, disc_loss = 0.0006249655010985103
Trained batch 192 in epoch 9, gen_loss = 1.116031725171934, disc_loss = 0.0006250748568403877
Trained batch 193 in epoch 9, gen_loss = 1.1154049997477187, disc_loss = 0.0006253325297724043
Trained batch 194 in epoch 9, gen_loss = 1.1153959702222775, disc_loss = 0.0006249916653942842
Trained batch 195 in epoch 9, gen_loss = 1.1148454924019016, disc_loss = 0.0006239526887746214
Trained batch 196 in epoch 9, gen_loss = 1.1147050760724218, disc_loss = 0.0006235825856834375
Trained batch 197 in epoch 9, gen_loss = 1.1138915684488084, disc_loss = 0.0006254177241124015
Trained batch 198 in epoch 9, gen_loss = 1.1131568679857493, disc_loss = 0.0006287121985443452
Trained batch 199 in epoch 9, gen_loss = 1.113659775853157, disc_loss = 0.0006321530858258484
Trained batch 200 in epoch 9, gen_loss = 1.113067772554521, disc_loss = 0.0006344819646902077
Trained batch 201 in epoch 9, gen_loss = 1.1125596994810765, disc_loss = 0.0006338695408102116
Trained batch 202 in epoch 9, gen_loss = 1.1119197231208162, disc_loss = 0.0006329291239937107
Trained batch 203 in epoch 9, gen_loss = 1.111723112709382, disc_loss = 0.0006346087558246355
Trained batch 204 in epoch 9, gen_loss = 1.1123138770824526, disc_loss = 0.0006358573744896936
Trained batch 205 in epoch 9, gen_loss = 1.1124159566407066, disc_loss = 0.0006355390250620667
Trained batch 206 in epoch 9, gen_loss = 1.1126310635304106, disc_loss = 0.0006343695782333081
Trained batch 207 in epoch 9, gen_loss = 1.1119356906184783, disc_loss = 0.0006324547090956073
Trained batch 208 in epoch 9, gen_loss = 1.1109841021054099, disc_loss = 0.0006305461895092877
Trained batch 209 in epoch 9, gen_loss = 1.1102390831425077, disc_loss = 0.0006304216957817386
Trained batch 210 in epoch 9, gen_loss = 1.1106975386493014, disc_loss = 0.0006360427587639576
Trained batch 211 in epoch 9, gen_loss = 1.1113986566943943, disc_loss = 0.0006403129635420452
Trained batch 212 in epoch 9, gen_loss = 1.1113030353622257, disc_loss = 0.0006415755470215557
Trained batch 213 in epoch 9, gen_loss = 1.1115099261297243, disc_loss = 0.0006395819268916151
Trained batch 214 in epoch 9, gen_loss = 1.1121598723322845, disc_loss = 0.0006377662235578566
Trained batch 215 in epoch 9, gen_loss = 1.1123474817033168, disc_loss = 0.0006366317832510469
Trained batch 216 in epoch 9, gen_loss = 1.11277075764221, disc_loss = 0.0006365149541036977
Trained batch 217 in epoch 9, gen_loss = 1.113405336207206, disc_loss = 0.0006357061471352183
Trained batch 218 in epoch 9, gen_loss = 1.1128979630121902, disc_loss = 0.0006344749886738179
Trained batch 219 in epoch 9, gen_loss = 1.1130806280808014, disc_loss = 0.0006338427811649374
Trained batch 220 in epoch 9, gen_loss = 1.1132397271389336, disc_loss = 0.0006350122876275685
Trained batch 221 in epoch 9, gen_loss = 1.1137179713528436, disc_loss = 0.0006376575599403565
Trained batch 222 in epoch 9, gen_loss = 1.1147626790765155, disc_loss = 0.000640759704219002
Trained batch 223 in epoch 9, gen_loss = 1.1151259730436973, disc_loss = 0.0006428204279862777
Trained batch 224 in epoch 9, gen_loss = 1.1142496246761746, disc_loss = 0.0006438983462026549
Trained batch 225 in epoch 9, gen_loss = 1.1138104036845993, disc_loss = 0.0006436319451004398
Trained batch 226 in epoch 9, gen_loss = 1.1133602185396372, disc_loss = 0.000642435596860937
Trained batch 227 in epoch 9, gen_loss = 1.1125011099012274, disc_loss = 0.0006414337128118955
Trained batch 228 in epoch 9, gen_loss = 1.111625545930654, disc_loss = 0.000641310392567831
Trained batch 229 in epoch 9, gen_loss = 1.1107588348181352, disc_loss = 0.0006422098035134537
Trained batch 230 in epoch 9, gen_loss = 1.1097139050434162, disc_loss = 0.0006437295328652349
Trained batch 231 in epoch 9, gen_loss = 1.1104486833872467, disc_loss = 0.0006430493100698845
Trained batch 232 in epoch 9, gen_loss = 1.1098501784607064, disc_loss = 0.0006415887203421284
Trained batch 233 in epoch 9, gen_loss = 1.1103785791967669, disc_loss = 0.000643508265647663
Trained batch 234 in epoch 9, gen_loss = 1.1100086171576318, disc_loss = 0.0006499745334409415
Trained batch 235 in epoch 9, gen_loss = 1.1100346456139774, disc_loss = 0.0006610541778342341
Trained batch 236 in epoch 9, gen_loss = 1.1093516656618079, disc_loss = 0.000674025434239292
Trained batch 237 in epoch 9, gen_loss = 1.1090155414172582, disc_loss = 0.0006797177783857264
Trained batch 238 in epoch 9, gen_loss = 1.108577472395478, disc_loss = 0.0006793792541947403
Trained batch 239 in epoch 9, gen_loss = 1.1087889278928438, disc_loss = 0.0006800050397335629
Trained batch 240 in epoch 9, gen_loss = 1.109436379428721, disc_loss = 0.00068177474062229
Trained batch 241 in epoch 9, gen_loss = 1.1093955650802487, disc_loss = 0.0006832798274497556
Trained batch 242 in epoch 9, gen_loss = 1.1107665560373063, disc_loss = 0.0006846253801599038
Trained batch 243 in epoch 9, gen_loss = 1.111445273532242, disc_loss = 0.0006847375610005492
Trained batch 244 in epoch 9, gen_loss = 1.1109701465587227, disc_loss = 0.0006834062397223422
Trained batch 245 in epoch 9, gen_loss = 1.1107922538024624, disc_loss = 0.0006810935556131881
Trained batch 246 in epoch 9, gen_loss = 1.1113838133541678, disc_loss = 0.000679184571937196
Trained batch 247 in epoch 9, gen_loss = 1.1118281000564176, disc_loss = 0.0006775468901034929
Trained batch 248 in epoch 9, gen_loss = 1.112453158361366, disc_loss = 0.0006760172040099334
Trained batch 249 in epoch 9, gen_loss = 1.1120164844989777, disc_loss = 0.0006746893385716249
Trained batch 250 in epoch 9, gen_loss = 1.112106895304296, disc_loss = 0.0006729648209956616
Trained batch 251 in epoch 9, gen_loss = 1.1124342124140452, disc_loss = 0.0006712194254572434
Trained batch 252 in epoch 9, gen_loss = 1.1132072193820486, disc_loss = 0.0006693135653937644
Trained batch 253 in epoch 9, gen_loss = 1.1127648548347744, disc_loss = 0.0006673961840755596
Trained batch 254 in epoch 9, gen_loss = 1.1128171909089182, disc_loss = 0.0006664047407171251
Trained batch 255 in epoch 9, gen_loss = 1.112787522142753, disc_loss = 0.0006661948627026959
Trained batch 256 in epoch 9, gen_loss = 1.1124545124718188, disc_loss = 0.0006658454403946636
Trained batch 257 in epoch 9, gen_loss = 1.113117941359217, disc_loss = 0.0006649160155335662
Trained batch 258 in epoch 9, gen_loss = 1.1130694567466795, disc_loss = 0.0006638597038812292
Trained batch 259 in epoch 9, gen_loss = 1.113344124876536, disc_loss = 0.0006627079343721002
Trained batch 260 in epoch 9, gen_loss = 1.1129366458604162, disc_loss = 0.00066172857517381
Trained batch 261 in epoch 9, gen_loss = 1.1122340246011282, disc_loss = 0.00066100619847194
Trained batch 262 in epoch 9, gen_loss = 1.1122781205993189, disc_loss = 0.0006602328596736248
Trained batch 263 in epoch 9, gen_loss = 1.1125410018545208, disc_loss = 0.0006589301024040183
Trained batch 264 in epoch 9, gen_loss = 1.1129478157691235, disc_loss = 0.0006576217784829666
Trained batch 265 in epoch 9, gen_loss = 1.112999086989496, disc_loss = 0.0006563379274187977
Trained batch 266 in epoch 9, gen_loss = 1.1135921960466364, disc_loss = 0.0006548298942982498
Trained batch 267 in epoch 9, gen_loss = 1.1141875003700825, disc_loss = 0.0006532890818209071
Trained batch 268 in epoch 9, gen_loss = 1.114648630184755, disc_loss = 0.0006515950740102529
Trained batch 269 in epoch 9, gen_loss = 1.1149510886934069, disc_loss = 0.0006500512959502413
Trained batch 270 in epoch 9, gen_loss = 1.1156890858583344, disc_loss = 0.0006490825334505
Trained batch 271 in epoch 9, gen_loss = 1.116001616944285, disc_loss = 0.0006483019848714963
Trained batch 272 in epoch 9, gen_loss = 1.1151912018056318, disc_loss = 0.0006472071603265925
Trained batch 273 in epoch 9, gen_loss = 1.1151881089610776, disc_loss = 0.0006458408560764884
Trained batch 274 in epoch 9, gen_loss = 1.1146009575236928, disc_loss = 0.0006454564017952759
Trained batch 275 in epoch 9, gen_loss = 1.1148522561011107, disc_loss = 0.0006457573253747018
Trained batch 276 in epoch 9, gen_loss = 1.1152739696984686, disc_loss = 0.000647223078672453
Trained batch 277 in epoch 9, gen_loss = 1.1152580920740855, disc_loss = 0.0006502874063613922
Trained batch 278 in epoch 9, gen_loss = 1.1155623629101716, disc_loss = 0.0006521937017123328
Trained batch 279 in epoch 9, gen_loss = 1.1149768593055862, disc_loss = 0.0006520095720718797
Trained batch 280 in epoch 9, gen_loss = 1.1147320942946601, disc_loss = 0.0006506080119371385
Trained batch 281 in epoch 9, gen_loss = 1.1140133157266792, disc_loss = 0.0006495864201097251
Trained batch 282 in epoch 9, gen_loss = 1.113764810688504, disc_loss = 0.0006489779400076082
Trained batch 283 in epoch 9, gen_loss = 1.1138247366942151, disc_loss = 0.0006479542652170852
Trained batch 284 in epoch 9, gen_loss = 1.1132890782858196, disc_loss = 0.0006470247836356673
Trained batch 285 in epoch 9, gen_loss = 1.11360334829017, disc_loss = 0.000646732197100601
Trained batch 286 in epoch 9, gen_loss = 1.1132155525975111, disc_loss = 0.0006469553414331052
Trained batch 287 in epoch 9, gen_loss = 1.1139935401992664, disc_loss = 0.0006473010201312314
Trained batch 288 in epoch 9, gen_loss = 1.1140993959350982, disc_loss = 0.0006465237637992648
Trained batch 289 in epoch 9, gen_loss = 1.1146881701617406, disc_loss = 0.0006457775338213682
Trained batch 290 in epoch 9, gen_loss = 1.1146035515975297, disc_loss = 0.0006454999867818299
Trained batch 291 in epoch 9, gen_loss = 1.1143104762655416, disc_loss = 0.0006451759309129557
Trained batch 292 in epoch 9, gen_loss = 1.1139567140426245, disc_loss = 0.0006442396823225826
Trained batch 293 in epoch 9, gen_loss = 1.1131300283532564, disc_loss = 0.0006427743764830592
Trained batch 294 in epoch 9, gen_loss = 1.1131657537767443, disc_loss = 0.0006412112142474359
Trained batch 295 in epoch 9, gen_loss = 1.1131902774040763, disc_loss = 0.0006404104320313923
Trained batch 296 in epoch 9, gen_loss = 1.1129071858996895, disc_loss = 0.0006400426530119687
Trained batch 297 in epoch 9, gen_loss = 1.1126681728251029, disc_loss = 0.0006399243596041553
Trained batch 298 in epoch 9, gen_loss = 1.112478478098394, disc_loss = 0.0006390896072795374
Trained batch 299 in epoch 9, gen_loss = 1.1129943738381067, disc_loss = 0.0006375058768753661
Trained batch 300 in epoch 9, gen_loss = 1.1129772324498706, disc_loss = 0.0006356276820970319
Trained batch 301 in epoch 9, gen_loss = 1.1124863859438738, disc_loss = 0.0006343104380222627
Trained batch 302 in epoch 9, gen_loss = 1.1127261928599266, disc_loss = 0.000633807760053783
Trained batch 303 in epoch 9, gen_loss = 1.1124405404062647, disc_loss = 0.0006339357653240242
Trained batch 304 in epoch 9, gen_loss = 1.1125592253247245, disc_loss = 0.000633920907385487
Trained batch 305 in epoch 9, gen_loss = 1.1126499096162958, disc_loss = 0.0006326660557390948
Trained batch 306 in epoch 9, gen_loss = 1.1130338707265326, disc_loss = 0.0006311718886746594
Trained batch 307 in epoch 9, gen_loss = 1.1131959826528253, disc_loss = 0.0006301910411171516
Trained batch 308 in epoch 9, gen_loss = 1.113894362858584, disc_loss = 0.0006294510615068416
Trained batch 309 in epoch 9, gen_loss = 1.1137204191377086, disc_loss = 0.0006285146899068833
Trained batch 310 in epoch 9, gen_loss = 1.1138326966494225, disc_loss = 0.0006271564367107846
Trained batch 311 in epoch 9, gen_loss = 1.1138122389331842, disc_loss = 0.0006255258032792765
Trained batch 312 in epoch 9, gen_loss = 1.114318809379785, disc_loss = 0.0006240355194229766
Trained batch 313 in epoch 9, gen_loss = 1.1143930150065453, disc_loss = 0.0006223674640895512
Trained batch 314 in epoch 9, gen_loss = 1.1145253047110542, disc_loss = 0.0006207395898638337
Trained batch 315 in epoch 9, gen_loss = 1.11466777117192, disc_loss = 0.0006190997069845966
Trained batch 316 in epoch 9, gen_loss = 1.1144056137803977, disc_loss = 0.0006174809344947244
Trained batch 317 in epoch 9, gen_loss = 1.114468034895711, disc_loss = 0.0006162669517337081
Trained batch 318 in epoch 9, gen_loss = 1.114353778033421, disc_loss = 0.0006153017957986779
Trained batch 319 in epoch 9, gen_loss = 1.1140444176271558, disc_loss = 0.0006138873072814022
Trained batch 320 in epoch 9, gen_loss = 1.1144588351992433, disc_loss = 0.0006124442105520243
Trained batch 321 in epoch 9, gen_loss = 1.1143912745188482, disc_loss = 0.000611113102592149
Trained batch 322 in epoch 9, gen_loss = 1.113755597418676, disc_loss = 0.0006101998468899188
Trained batch 323 in epoch 9, gen_loss = 1.113835820445308, disc_loss = 0.0006091988634804614
Trained batch 324 in epoch 9, gen_loss = 1.114174779011653, disc_loss = 0.0006080024010197331
Trained batch 325 in epoch 9, gen_loss = 1.1141265864752552, disc_loss = 0.0006086342771908274
Trained batch 326 in epoch 9, gen_loss = 1.114630236173624, disc_loss = 0.0006110696395733095
Trained batch 327 in epoch 9, gen_loss = 1.1143156842487614, disc_loss = 0.0006158126673143692
Trained batch 328 in epoch 9, gen_loss = 1.1144779543746206, disc_loss = 0.0006233047021925874
Trained batch 329 in epoch 9, gen_loss = 1.1142526666323345, disc_loss = 0.0006300737061379054
Trained batch 330 in epoch 9, gen_loss = 1.1141461025912236, disc_loss = 0.0006319684829978621
Trained batch 331 in epoch 9, gen_loss = 1.11379846248282, disc_loss = 0.0006320455373410018
Trained batch 332 in epoch 9, gen_loss = 1.1135466728840504, disc_loss = 0.0006311806276711208
Trained batch 333 in epoch 9, gen_loss = 1.1140644678812541, disc_loss = 0.0006304717927067652
Trained batch 334 in epoch 9, gen_loss = 1.11380602032391, disc_loss = 0.000631827182777629
Trained batch 335 in epoch 9, gen_loss = 1.1138320476526307, disc_loss = 0.0006370523423833046
Trained batch 336 in epoch 9, gen_loss = 1.1139176942474411, disc_loss = 0.0006436715656024395
Trained batch 337 in epoch 9, gen_loss = 1.1133600279424318, disc_loss = 0.000650528892807555
Trained batch 338 in epoch 9, gen_loss = 1.112799068116157, disc_loss = 0.0006539008301043345
Trained batch 339 in epoch 9, gen_loss = 1.1121104512144537, disc_loss = 0.0006546316673955195
Trained batch 340 in epoch 9, gen_loss = 1.1126470039666922, disc_loss = 0.0006556182547456713
Trained batch 341 in epoch 9, gen_loss = 1.1126008411945656, disc_loss = 0.0006569672285457283
Trained batch 342 in epoch 9, gen_loss = 1.112754173772328, disc_loss = 0.0006573237901714388
Trained batch 343 in epoch 9, gen_loss = 1.1125121856498164, disc_loss = 0.0006570530804310692
Trained batch 344 in epoch 9, gen_loss = 1.1125827953435372, disc_loss = 0.0006556248427301213
Trained batch 345 in epoch 9, gen_loss = 1.1131839364594807, disc_loss = 0.0006554931911271108
Trained batch 346 in epoch 9, gen_loss = 1.112783756654613, disc_loss = 0.0006552856363173606
Trained batch 347 in epoch 9, gen_loss = 1.1129532562590194, disc_loss = 0.0006547370046911087
Trained batch 348 in epoch 9, gen_loss = 1.1122347000335213, disc_loss = 0.0006543233121557156
Trained batch 349 in epoch 9, gen_loss = 1.1122507544926235, disc_loss = 0.0006543906928605534
Trained batch 350 in epoch 9, gen_loss = 1.1122315378270597, disc_loss = 0.0006545662439323463
Trained batch 351 in epoch 9, gen_loss = 1.1117707572200082, disc_loss = 0.0006542362502428164
Trained batch 352 in epoch 9, gen_loss = 1.1116423985100332, disc_loss = 0.0006541328323462836
Trained batch 353 in epoch 9, gen_loss = 1.111001530609562, disc_loss = 0.0006543387724501002
Trained batch 354 in epoch 9, gen_loss = 1.1103640976086468, disc_loss = 0.0006549355855152588
Trained batch 355 in epoch 9, gen_loss = 1.1101961567830503, disc_loss = 0.0006561792870751959
Trained batch 356 in epoch 9, gen_loss = 1.1096088699266022, disc_loss = 0.000657698263382247
Trained batch 357 in epoch 9, gen_loss = 1.1092428250352764, disc_loss = 0.0006588650690931463
Trained batch 358 in epoch 9, gen_loss = 1.1085420013470237, disc_loss = 0.0006601047645547378
Trained batch 359 in epoch 9, gen_loss = 1.1080898976988263, disc_loss = 0.0006614878837556009
Trained batch 360 in epoch 9, gen_loss = 1.1080430689941152, disc_loss = 0.0006629862941748662
Trained batch 361 in epoch 9, gen_loss = 1.1078777836831235, disc_loss = 0.0006638133938736874
Trained batch 362 in epoch 9, gen_loss = 1.1076064828998786, disc_loss = 0.0006638404789936187
Trained batch 363 in epoch 9, gen_loss = 1.1078351824493198, disc_loss = 0.0006635973710857158
Trained batch 364 in epoch 9, gen_loss = 1.1079410490924364, disc_loss = 0.0006627377796414219
Trained batch 365 in epoch 9, gen_loss = 1.1083685188996988, disc_loss = 0.0006613212171146809
Trained batch 366 in epoch 9, gen_loss = 1.108224793740774, disc_loss = 0.0006601495918251919
Trained batch 367 in epoch 9, gen_loss = 1.1077563459782496, disc_loss = 0.0006592282666331258
Trained batch 368 in epoch 9, gen_loss = 1.1077260555936714, disc_loss = 0.0006587964488599743
Trained batch 369 in epoch 9, gen_loss = 1.107623255736119, disc_loss = 0.0006585790934607488
Trained batch 370 in epoch 9, gen_loss = 1.107639152566699, disc_loss = 0.0006584913504053901
Trained batch 371 in epoch 9, gen_loss = 1.1077973315472245, disc_loss = 0.0006586516051307841
Trained batch 372 in epoch 9, gen_loss = 1.1072982340332012, disc_loss = 0.0006593330838185693
Trained batch 373 in epoch 9, gen_loss = 1.106899561250911, disc_loss = 0.0006605390814770471
Trained batch 374 in epoch 9, gen_loss = 1.1066130366325377, disc_loss = 0.0006620983999843399
Trained batch 375 in epoch 9, gen_loss = 1.1063769711775984, disc_loss = 0.0006628251777580404
Trained batch 376 in epoch 9, gen_loss = 1.1062836803555172, disc_loss = 0.000664086191327032
Trained batch 377 in epoch 9, gen_loss = 1.1059456188527366, disc_loss = 0.0006652183836281654
Trained batch 378 in epoch 9, gen_loss = 1.1060585977219655, disc_loss = 0.0006654771750714227
Trained batch 379 in epoch 9, gen_loss = 1.106142983781664, disc_loss = 0.000665782757048299
Trained batch 380 in epoch 9, gen_loss = 1.1060243421026414, disc_loss = 0.0006654475177907119
Trained batch 381 in epoch 9, gen_loss = 1.1059139447374493, disc_loss = 0.0006650172691141299
Trained batch 382 in epoch 9, gen_loss = 1.105253803512135, disc_loss = 0.0006651666452172005
Trained batch 383 in epoch 9, gen_loss = 1.1053585844735305, disc_loss = 0.0006656312090550879
Trained batch 384 in epoch 9, gen_loss = 1.1050460120300194, disc_loss = 0.0006657607761187503
Trained batch 385 in epoch 9, gen_loss = 1.105646326288658, disc_loss = 0.0006651591350188131
Trained batch 386 in epoch 9, gen_loss = 1.1058226933158954, disc_loss = 0.0006641690794213672
Trained batch 387 in epoch 9, gen_loss = 1.1054714398900258, disc_loss = 0.0006630671688849971
Trained batch 388 in epoch 9, gen_loss = 1.1055088622404554, disc_loss = 0.0006624061446984066
Trained batch 389 in epoch 9, gen_loss = 1.1050872188348038, disc_loss = 0.0006623732873823685
Trained batch 390 in epoch 9, gen_loss = 1.104975071404596, disc_loss = 0.0006623031371130187
Trained batch 391 in epoch 9, gen_loss = 1.1058486326008428, disc_loss = 0.0006626705421973495
Trained batch 392 in epoch 9, gen_loss = 1.1054930958432398, disc_loss = 0.0006624316928775521
Trained batch 393 in epoch 9, gen_loss = 1.1057904276448458, disc_loss = 0.0006613519806816683
Trained batch 394 in epoch 9, gen_loss = 1.1059019500696206, disc_loss = 0.0006601948991765657
Trained batch 395 in epoch 9, gen_loss = 1.1053550163603791, disc_loss = 0.0006591345711535953
Trained batch 396 in epoch 9, gen_loss = 1.104940793826538, disc_loss = 0.000658124009594767
Trained batch 397 in epoch 9, gen_loss = 1.105329968372182, disc_loss = 0.0006571541627051178
Trained batch 398 in epoch 9, gen_loss = 1.1052343951430834, disc_loss = 0.0006559574453934518
Trained batch 399 in epoch 9, gen_loss = 1.105126652866602, disc_loss = 0.0006546796983093372
Trained batch 400 in epoch 9, gen_loss = 1.1052344370066673, disc_loss = 0.0006532674816478
Trained batch 401 in epoch 9, gen_loss = 1.1058412352901192, disc_loss = 0.0006518445382005042
Trained batch 402 in epoch 9, gen_loss = 1.1060917041733602, disc_loss = 0.0006507329226111261
Trained batch 403 in epoch 9, gen_loss = 1.106357259472998, disc_loss = 0.0006496856965193476
Trained batch 404 in epoch 9, gen_loss = 1.1060589403281977, disc_loss = 0.00064846372210642
Trained batch 405 in epoch 9, gen_loss = 1.1061049560314329, disc_loss = 0.000647169495100503
Trained batch 406 in epoch 9, gen_loss = 1.1058251841648206, disc_loss = 0.0006459932782707555
Trained batch 407 in epoch 9, gen_loss = 1.105796512581554, disc_loss = 0.0006449148709269174
Trained batch 408 in epoch 9, gen_loss = 1.1051653705191204, disc_loss = 0.0006441904893786815
Trained batch 409 in epoch 9, gen_loss = 1.1052752273838695, disc_loss = 0.0006438433888145416
Trained batch 410 in epoch 9, gen_loss = 1.1049356167623887, disc_loss = 0.0006435293052055184
Trained batch 411 in epoch 9, gen_loss = 1.1054649434043367, disc_loss = 0.0006429449247626658
Trained batch 412 in epoch 9, gen_loss = 1.10532847645785, disc_loss = 0.0006421699092494263
Trained batch 413 in epoch 9, gen_loss = 1.1047812642682577, disc_loss = 0.0006418709151899827
Trained batch 414 in epoch 9, gen_loss = 1.1044647032956043, disc_loss = 0.0006412517648794778
Trained batch 415 in epoch 9, gen_loss = 1.1045791561213822, disc_loss = 0.0006403796374762841
Trained batch 416 in epoch 9, gen_loss = 1.1047862873946448, disc_loss = 0.000639116062167267
Trained batch 417 in epoch 9, gen_loss = 1.1050176158476104, disc_loss = 0.000637999761168835
Trained batch 418 in epoch 9, gen_loss = 1.104847531899063, disc_loss = 0.0006369847793993096
Trained batch 419 in epoch 9, gen_loss = 1.1047603766123453, disc_loss = 0.0006360764850666913
Trained batch 420 in epoch 9, gen_loss = 1.104673004207022, disc_loss = 0.000635035543978649
Trained batch 421 in epoch 9, gen_loss = 1.1046788183998724, disc_loss = 0.0006339037682444808
Trained batch 422 in epoch 9, gen_loss = 1.1046244785295312, disc_loss = 0.0006327983565582018
Trained batch 423 in epoch 9, gen_loss = 1.1042364609410178, disc_loss = 0.0006317302345880033
Trained batch 424 in epoch 9, gen_loss = 1.1040988309243147, disc_loss = 0.000630707684887217
Trained batch 425 in epoch 9, gen_loss = 1.1041403601706867, disc_loss = 0.0006296883386628377
Trained batch 426 in epoch 9, gen_loss = 1.1039273916139536, disc_loss = 0.0006285880461960336
Trained batch 427 in epoch 9, gen_loss = 1.104798340212519, disc_loss = 0.0006273838382491202
Trained batch 428 in epoch 9, gen_loss = 1.1048505527156216, disc_loss = 0.0006264338555372926
Trained batch 429 in epoch 9, gen_loss = 1.105217007564944, disc_loss = 0.0006258366533709408
Trained batch 430 in epoch 9, gen_loss = 1.1048701375100562, disc_loss = 0.0006258833872571938
Trained batch 431 in epoch 9, gen_loss = 1.104924646930562, disc_loss = 0.0006259855065730301
Trained batch 432 in epoch 9, gen_loss = 1.1051449237464481, disc_loss = 0.0006251141683891626
Trained batch 433 in epoch 9, gen_loss = 1.1057187770643542, disc_loss = 0.0006239649882684419
Trained batch 434 in epoch 9, gen_loss = 1.1061347864140039, disc_loss = 0.0006231066515607674
Trained batch 435 in epoch 9, gen_loss = 1.1061699438259143, disc_loss = 0.0006225947800977262
Trained batch 436 in epoch 9, gen_loss = 1.1061469214186244, disc_loss = 0.0006223350992222216
Trained batch 437 in epoch 9, gen_loss = 1.1060270012513687, disc_loss = 0.0006220053009155683
Trained batch 438 in epoch 9, gen_loss = 1.105665790057128, disc_loss = 0.000621225092097839
Trained batch 439 in epoch 9, gen_loss = 1.106118479506536, disc_loss = 0.0006203175975811478
Trained batch 440 in epoch 9, gen_loss = 1.106116466916878, disc_loss = 0.0006195714518989072
Trained batch 441 in epoch 9, gen_loss = 1.105705093878966, disc_loss = 0.0006196087350259214
Trained batch 442 in epoch 9, gen_loss = 1.1058951195152833, disc_loss = 0.0006192774358733703
Trained batch 443 in epoch 9, gen_loss = 1.1061052552483104, disc_loss = 0.0006184007630705506
Trained batch 444 in epoch 9, gen_loss = 1.1064532886730152, disc_loss = 0.0006173499572428279
Trained batch 445 in epoch 9, gen_loss = 1.1063498944177756, disc_loss = 0.0006161927872790534
Trained batch 446 in epoch 9, gen_loss = 1.1062053197982327, disc_loss = 0.0006151754047783608
Trained batch 447 in epoch 9, gen_loss = 1.1061814452654548, disc_loss = 0.0006142282658012326
Trained batch 448 in epoch 9, gen_loss = 1.1064821329042482, disc_loss = 0.000613315375511408
Trained batch 449 in epoch 9, gen_loss = 1.1064590362707774, disc_loss = 0.0006125008316141449
Trained batch 450 in epoch 9, gen_loss = 1.1062753902306313, disc_loss = 0.0006116867193718856
Trained batch 451 in epoch 9, gen_loss = 1.1063017374382609, disc_loss = 0.0006107790124861717
Trained batch 452 in epoch 9, gen_loss = 1.106245972594415, disc_loss = 0.0006098888999030558
Trained batch 453 in epoch 9, gen_loss = 1.1058870816545865, disc_loss = 0.0006092035271945853
Trained batch 454 in epoch 9, gen_loss = 1.1057370117732457, disc_loss = 0.0006093310738803696
Trained batch 455 in epoch 9, gen_loss = 1.106058832323342, disc_loss = 0.0006101185018658789
Trained batch 456 in epoch 9, gen_loss = 1.105997836563728, disc_loss = 0.0006107725972664814
Trained batch 457 in epoch 9, gen_loss = 1.1063695508319737, disc_loss = 0.0006110085112230312
Trained batch 458 in epoch 9, gen_loss = 1.1061778019196586, disc_loss = 0.00061055614007713
Trained batch 459 in epoch 9, gen_loss = 1.10605516511461, disc_loss = 0.0006097962194357735
Trained batch 460 in epoch 9, gen_loss = 1.106065414732811, disc_loss = 0.0006088813321567454
Trained batch 461 in epoch 9, gen_loss = 1.1057574309053875, disc_loss = 0.0006078473950025133
Trained batch 462 in epoch 9, gen_loss = 1.1060248048207673, disc_loss = 0.0006068089758030885
Trained batch 463 in epoch 9, gen_loss = 1.1060591498068695, disc_loss = 0.0006060192354825318
Trained batch 464 in epoch 9, gen_loss = 1.1064808762201699, disc_loss = 0.0006055127955742821
Trained batch 465 in epoch 9, gen_loss = 1.1064764224152708, disc_loss = 0.0006056035824605692
Trained batch 466 in epoch 9, gen_loss = 1.1063692407638663, disc_loss = 0.0006059532274882961
Trained batch 467 in epoch 9, gen_loss = 1.1058224871372566, disc_loss = 0.0006066577703817389
Trained batch 468 in epoch 9, gen_loss = 1.1052518319219415, disc_loss = 0.0006074946698125031
Trained batch 469 in epoch 9, gen_loss = 1.1056267808092402, disc_loss = 0.0006077171558454791
Trained batch 470 in epoch 9, gen_loss = 1.1062838027684805, disc_loss = 0.0006073293725479466
Trained batch 471 in epoch 9, gen_loss = 1.1060707370861103, disc_loss = 0.0006074378307873257
Trained batch 472 in epoch 9, gen_loss = 1.1059513584755944, disc_loss = 0.000608098694422611
Trained batch 473 in epoch 9, gen_loss = 1.1055363300983412, disc_loss = 0.0006088553700657004
Trained batch 474 in epoch 9, gen_loss = 1.1051448325106972, disc_loss = 0.0006092638707425642
Trained batch 475 in epoch 9, gen_loss = 1.104650503321856, disc_loss = 0.0006089623913045644
Trained batch 476 in epoch 9, gen_loss = 1.10422413816492, disc_loss = 0.000608562468038579
Trained batch 477 in epoch 9, gen_loss = 1.1045709784809017, disc_loss = 0.0006080039773939107
Trained batch 478 in epoch 9, gen_loss = 1.1043337766462178, disc_loss = 0.0006072854756626508
Trained batch 479 in epoch 9, gen_loss = 1.1045247364789248, disc_loss = 0.0006065682304324582
Trained batch 480 in epoch 9, gen_loss = 1.1041914636032992, disc_loss = 0.0006059192577493135
Trained batch 481 in epoch 9, gen_loss = 1.1040659079413195, disc_loss = 0.0006054841040892534
Trained batch 482 in epoch 9, gen_loss = 1.1039823710795023, disc_loss = 0.0006050815063193209
Trained batch 483 in epoch 9, gen_loss = 1.1042465343455639, disc_loss = 0.0006043041435942007
Trained batch 484 in epoch 9, gen_loss = 1.104752656602368, disc_loss = 0.0006036862956609615
Trained batch 485 in epoch 9, gen_loss = 1.1043494849048034, disc_loss = 0.0006034321577092748
Trained batch 486 in epoch 9, gen_loss = 1.104264281858409, disc_loss = 0.0006029205023859928
Trained batch 487 in epoch 9, gen_loss = 1.1044783462755015, disc_loss = 0.0006021812726833216
Trained batch 488 in epoch 9, gen_loss = 1.1045143511641489, disc_loss = 0.0006014163170680252
Trained batch 489 in epoch 9, gen_loss = 1.1042955841336932, disc_loss = 0.0006007184953979996
Trained batch 490 in epoch 9, gen_loss = 1.10401022555629, disc_loss = 0.0005997945722597964
Trained batch 491 in epoch 9, gen_loss = 1.103872108750227, disc_loss = 0.0005988338538949526
Trained batch 492 in epoch 9, gen_loss = 1.1037312922564773, disc_loss = 0.0005979870523833321
Trained batch 493 in epoch 9, gen_loss = 1.1038218176799264, disc_loss = 0.0005975722501771751
Trained batch 494 in epoch 9, gen_loss = 1.1037298118225252, disc_loss = 0.000597659712998347
Trained batch 495 in epoch 9, gen_loss = 1.1037331824341128, disc_loss = 0.0005978616800055006
Trained batch 496 in epoch 9, gen_loss = 1.1041998882408832, disc_loss = 0.0005976899151181543
Trained batch 497 in epoch 9, gen_loss = 1.1038222256673866, disc_loss = 0.0005969366758952411
Trained batch 498 in epoch 9, gen_loss = 1.1039634048341511, disc_loss = 0.0005963647463158303
Trained batch 499 in epoch 9, gen_loss = 1.1035933989286422, disc_loss = 0.0005970167616032995
Trained batch 500 in epoch 9, gen_loss = 1.103530043256497, disc_loss = 0.000597718146737914
Trained batch 501 in epoch 9, gen_loss = 1.1037884844964243, disc_loss = 0.000597994116033368
Trained batch 502 in epoch 9, gen_loss = 1.1034435237615294, disc_loss = 0.0005975500527754515
Trained batch 503 in epoch 9, gen_loss = 1.1038346089540967, disc_loss = 0.0005973622150671122
Trained batch 504 in epoch 9, gen_loss = 1.103737783904123, disc_loss = 0.0005972484449422596
Trained batch 505 in epoch 9, gen_loss = 1.103451990798528, disc_loss = 0.0005970793843394506
Trained batch 506 in epoch 9, gen_loss = 1.1034432355703923, disc_loss = 0.0005971014229176636
Trained batch 507 in epoch 9, gen_loss = 1.1032607330112008, disc_loss = 0.0005969755134066772
Trained batch 508 in epoch 9, gen_loss = 1.1036764053089914, disc_loss = 0.0005961807012079514
Trained batch 509 in epoch 9, gen_loss = 1.1034500590726442, disc_loss = 0.0005953800771499564
Trained batch 510 in epoch 9, gen_loss = 1.103214713458679, disc_loss = 0.0005946476818661529
Trained batch 511 in epoch 9, gen_loss = 1.1031257233116776, disc_loss = 0.000593703898317699
Trained batch 512 in epoch 9, gen_loss = 1.10310282530608, disc_loss = 0.000592671321156039
Trained batch 513 in epoch 9, gen_loss = 1.1030072321687692, disc_loss = 0.0005918913556827714
Trained batch 514 in epoch 9, gen_loss = 1.1029882039838623, disc_loss = 0.0005919130592215897
Trained batch 515 in epoch 9, gen_loss = 1.1026443232630574, disc_loss = 0.0005928642133577066
Trained batch 516 in epoch 9, gen_loss = 1.102447892180725, disc_loss = 0.000594225393357593
Trained batch 517 in epoch 9, gen_loss = 1.1022591840576481, disc_loss = 0.0005958667144925032
Trained batch 518 in epoch 9, gen_loss = 1.10238679330473, disc_loss = 0.0005978260787689757
Trained batch 519 in epoch 9, gen_loss = 1.1023811832070352, disc_loss = 0.0006002584195532388
Trained batch 520 in epoch 9, gen_loss = 1.102719344127201, disc_loss = 0.0006015390768991747
Trained batch 521 in epoch 9, gen_loss = 1.1025851897581327, disc_loss = 0.0006013648628586835
Trained batch 522 in epoch 9, gen_loss = 1.1024707271993501, disc_loss = 0.0006007559748130973
Trained batch 523 in epoch 9, gen_loss = 1.1022437905309765, disc_loss = 0.0006001778039981287
Trained batch 524 in epoch 9, gen_loss = 1.1025839132354374, disc_loss = 0.0005997128228357593
Trained batch 525 in epoch 9, gen_loss = 1.1023776517621464, disc_loss = 0.000599197157643808
Trained batch 526 in epoch 9, gen_loss = 1.1027862310861953, disc_loss = 0.0005988387702829496
Trained batch 527 in epoch 9, gen_loss = 1.1026583241693901, disc_loss = 0.0005995179995862242
Trained batch 528 in epoch 9, gen_loss = 1.1028525425941598, disc_loss = 0.0006020882579052138
Trained batch 529 in epoch 9, gen_loss = 1.1031291199180315, disc_loss = 0.0006056946352780972
Trained batch 530 in epoch 9, gen_loss = 1.1035122016055436, disc_loss = 0.0006098004661510539
Trained batch 531 in epoch 9, gen_loss = 1.1032833432344566, disc_loss = 0.0006150301500506737
Trained batch 532 in epoch 9, gen_loss = 1.1029072398316346, disc_loss = 0.0006172945089260375
Trained batch 533 in epoch 9, gen_loss = 1.103016839045264, disc_loss = 0.0006178292648965747
Trained batch 534 in epoch 9, gen_loss = 1.1030828823553067, disc_loss = 0.0006183211875276501
Trained batch 535 in epoch 9, gen_loss = 1.1026989830963647, disc_loss = 0.0006186340679186518
Trained batch 536 in epoch 9, gen_loss = 1.1028406944132827, disc_loss = 0.0006190321343555072
Trained batch 537 in epoch 9, gen_loss = 1.1028493474407266, disc_loss = 0.0006199835378061686
Trained batch 538 in epoch 9, gen_loss = 1.102547867510447, disc_loss = 0.0006212381159155396
Trained batch 539 in epoch 9, gen_loss = 1.1025463006010763, disc_loss = 0.0006224418316344748
Trained batch 540 in epoch 9, gen_loss = 1.1023681715764313, disc_loss = 0.000623968032496644
Trained batch 541 in epoch 9, gen_loss = 1.102385951474144, disc_loss = 0.0006246976355445997
Trained batch 542 in epoch 9, gen_loss = 1.1024495136013348, disc_loss = 0.0006244896623959017
Trained batch 543 in epoch 9, gen_loss = 1.102667358101291, disc_loss = 0.0006238318524083297
Trained batch 544 in epoch 9, gen_loss = 1.1024540351071488, disc_loss = 0.0006233442946147054
Trained batch 545 in epoch 9, gen_loss = 1.1025423928276523, disc_loss = 0.0006235543298763189
Trained batch 546 in epoch 9, gen_loss = 1.1022464375827168, disc_loss = 0.0006250548848728657
Trained batch 547 in epoch 9, gen_loss = 1.102459448641234, disc_loss = 0.0006300035789921237
Trained batch 548 in epoch 9, gen_loss = 1.1023361948887074, disc_loss = 0.0006401855960555752
Trained batch 549 in epoch 9, gen_loss = 1.102571218772368, disc_loss = 0.0006528015684241175
Trained batch 550 in epoch 9, gen_loss = 1.1023311835668048, disc_loss = 0.0006649542304705372
Trained batch 551 in epoch 9, gen_loss = 1.102377592653468, disc_loss = 0.0006744710022178259
Trained batch 552 in epoch 9, gen_loss = 1.1028836471909425, disc_loss = 0.000680160775222179
Trained batch 553 in epoch 9, gen_loss = 1.1028481782128234, disc_loss = 0.000682134530901033
Trained batch 554 in epoch 9, gen_loss = 1.1031636957649713, disc_loss = 0.0006820121318309543
Trained batch 555 in epoch 9, gen_loss = 1.1031458182729406, disc_loss = 0.0006813827768127725
Trained batch 556 in epoch 9, gen_loss = 1.1029271520874873, disc_loss = 0.0006811069889185127
Trained batch 557 in epoch 9, gen_loss = 1.103005058449229, disc_loss = 0.0006808646242178085
Trained batch 558 in epoch 9, gen_loss = 1.1030530413489437, disc_loss = 0.0006805347384768746
Trained batch 559 in epoch 9, gen_loss = 1.1029238996761186, disc_loss = 0.000679999880568565
Trained batch 560 in epoch 9, gen_loss = 1.102686783209204, disc_loss = 0.0006794374216538431
Trained batch 561 in epoch 9, gen_loss = 1.1025652049699288, disc_loss = 0.0006786187590206344
Trained batch 562 in epoch 9, gen_loss = 1.1022419626717035, disc_loss = 0.0006779999230323744
Trained batch 563 in epoch 9, gen_loss = 1.1020339717890353, disc_loss = 0.0006775072765099429
Trained batch 564 in epoch 9, gen_loss = 1.1020197107728604, disc_loss = 0.0006771946577530404
Trained batch 565 in epoch 9, gen_loss = 1.1017685142928215, disc_loss = 0.0006772513289134966
Trained batch 566 in epoch 9, gen_loss = 1.1016846922549832, disc_loss = 0.0006770802988694172
Trained batch 567 in epoch 9, gen_loss = 1.1015981171332614, disc_loss = 0.0006764129797067628
Trained batch 568 in epoch 9, gen_loss = 1.1018904248524215, disc_loss = 0.0006757328365383152
Trained batch 569 in epoch 9, gen_loss = 1.1018870711326598, disc_loss = 0.0006751219323568716
Trained batch 570 in epoch 9, gen_loss = 1.1015572777562717, disc_loss = 0.0006746969828449415
Trained batch 571 in epoch 9, gen_loss = 1.1014516395288747, disc_loss = 0.0006741385556518514
Trained batch 572 in epoch 9, gen_loss = 1.1019068117957256, disc_loss = 0.0006735257530980297
Trained batch 573 in epoch 9, gen_loss = 1.101869655195429, disc_loss = 0.0006729179323427396
Trained batch 574 in epoch 9, gen_loss = 1.1018602282068004, disc_loss = 0.0006722056187699428
Trained batch 575 in epoch 9, gen_loss = 1.1017549487037792, disc_loss = 0.0006713104455937153
Trained batch 576 in epoch 9, gen_loss = 1.1017013098172959, disc_loss = 0.0006703009938858925
Trained batch 577 in epoch 9, gen_loss = 1.1013629227154809, disc_loss = 0.0006694139072817152
Trained batch 578 in epoch 9, gen_loss = 1.101476598794802, disc_loss = 0.000668594097907696
Trained batch 579 in epoch 9, gen_loss = 1.1016227852681588, disc_loss = 0.0006677450746039916
Trained batch 580 in epoch 9, gen_loss = 1.1018639762922737, disc_loss = 0.0006669500894711687
Trained batch 581 in epoch 9, gen_loss = 1.1014688544461817, disc_loss = 0.0006660952025525795
Trained batch 582 in epoch 9, gen_loss = 1.1015490721879242, disc_loss = 0.0006654121222286597
Trained batch 583 in epoch 9, gen_loss = 1.1017313441389227, disc_loss = 0.000664579762847658
Trained batch 584 in epoch 9, gen_loss = 1.1016750483431368, disc_loss = 0.0006636462009558653
Trained batch 585 in epoch 9, gen_loss = 1.1019057154452028, disc_loss = 0.000662940688801865
Trained batch 586 in epoch 9, gen_loss = 1.1017195838273486, disc_loss = 0.0006623366498264399
Trained batch 587 in epoch 9, gen_loss = 1.1018341350920346, disc_loss = 0.0006615994416341006
Trained batch 588 in epoch 9, gen_loss = 1.1020869011587522, disc_loss = 0.0006610188901981581
Trained batch 589 in epoch 9, gen_loss = 1.1020151826284699, disc_loss = 0.0006606491388515293
Trained batch 590 in epoch 9, gen_loss = 1.1020170172862394, disc_loss = 0.0006606464064616021
Trained batch 591 in epoch 9, gen_loss = 1.1019999482543081, disc_loss = 0.0006606645358039492
Trained batch 592 in epoch 9, gen_loss = 1.1016189847989588, disc_loss = 0.000660610600732621
Trained batch 593 in epoch 9, gen_loss = 1.1017170246402022, disc_loss = 0.0006610386109038183
Trained batch 594 in epoch 9, gen_loss = 1.101744364590204, disc_loss = 0.0006612132752814111
Trained batch 595 in epoch 9, gen_loss = 1.101906358295639, disc_loss = 0.0006609227620595527
Trained batch 596 in epoch 9, gen_loss = 1.101687128120531, disc_loss = 0.0006605067568217089
Trained batch 597 in epoch 9, gen_loss = 1.101802222206441, disc_loss = 0.00066026166609921
Trained batch 598 in epoch 9, gen_loss = 1.101740243737407, disc_loss = 0.0006598859080454554
Trained batch 599 in epoch 9, gen_loss = 1.1019017655650776, disc_loss = 0.0006593842697111541
Trained batch 600 in epoch 9, gen_loss = 1.1019836847675024, disc_loss = 0.0006587248004967317
Trained batch 601 in epoch 9, gen_loss = 1.1020274747447714, disc_loss = 0.000658091876653013
Trained batch 602 in epoch 9, gen_loss = 1.1018462568570924, disc_loss = 0.0006574052019533393
Trained batch 603 in epoch 9, gen_loss = 1.1014569995813812, disc_loss = 0.0006567171433726009
Trained batch 604 in epoch 9, gen_loss = 1.1016474268653176, disc_loss = 0.0006560819041083012
Trained batch 605 in epoch 9, gen_loss = 1.10202423377399, disc_loss = 0.000655558215182489
Trained batch 606 in epoch 9, gen_loss = 1.1016921534569692, disc_loss = 0.0006550081317017471
Trained batch 607 in epoch 9, gen_loss = 1.101627381714551, disc_loss = 0.0006544886721736763
Trained batch 608 in epoch 9, gen_loss = 1.101676856845079, disc_loss = 0.0006544180346662614
Trained batch 609 in epoch 9, gen_loss = 1.1019209851006992, disc_loss = 0.0006554030514008282
Trained batch 610 in epoch 9, gen_loss = 1.1018315304906006, disc_loss = 0.0006576242257623534
Trained batch 611 in epoch 9, gen_loss = 1.101752927003343, disc_loss = 0.0006595799719565357
Trained batch 612 in epoch 9, gen_loss = 1.1017263405280247, disc_loss = 0.0006595620299782717
Trained batch 613 in epoch 9, gen_loss = 1.1017377410532985, disc_loss = 0.0006591433877403528
Trained batch 614 in epoch 9, gen_loss = 1.1015727569417255, disc_loss = 0.0006595644446225208
Trained batch 615 in epoch 9, gen_loss = 1.1017165891342349, disc_loss = 0.0006599391400094965
Trained batch 616 in epoch 9, gen_loss = 1.1015615622653374, disc_loss = 0.0006597421141438498
Trained batch 617 in epoch 9, gen_loss = 1.1015212212758543, disc_loss = 0.0006593996815154183
Trained batch 618 in epoch 9, gen_loss = 1.1012562082926947, disc_loss = 0.0006591283598788171
Trained batch 619 in epoch 9, gen_loss = 1.1012085702150098, disc_loss = 0.0006590170457075733
Trained batch 620 in epoch 9, gen_loss = 1.1008579571657902, disc_loss = 0.0006606514310952982
Trained batch 621 in epoch 9, gen_loss = 1.1009409521553677, disc_loss = 0.0006644065834994921
Trained batch 622 in epoch 9, gen_loss = 1.1011470971482524, disc_loss = 0.0006662087201324507
Trained batch 623 in epoch 9, gen_loss = 1.101087518609487, disc_loss = 0.0006672943050734131
Trained batch 624 in epoch 9, gen_loss = 1.1012456642150878, disc_loss = 0.0006678783645736985
Trained batch 625 in epoch 9, gen_loss = 1.101305130571603, disc_loss = 0.000668437109866158
Trained batch 626 in epoch 9, gen_loss = 1.1011691302583928, disc_loss = 0.0006691136757877174
Trained batch 627 in epoch 9, gen_loss = 1.101069800033691, disc_loss = 0.0006696365901099772
Trained batch 628 in epoch 9, gen_loss = 1.1008741499320123, disc_loss = 0.0006700379633938261
Trained batch 629 in epoch 9, gen_loss = 1.1007438561273, disc_loss = 0.0006699968526571331
Trained batch 630 in epoch 9, gen_loss = 1.1007435848898064, disc_loss = 0.0006698604232830692
Trained batch 631 in epoch 9, gen_loss = 1.1006881111784825, disc_loss = 0.0006692844095319927
Trained batch 632 in epoch 9, gen_loss = 1.100606372947753, disc_loss = 0.0006685217828413517
Trained batch 633 in epoch 9, gen_loss = 1.1002856472313216, disc_loss = 0.0006677114837921382
Trained batch 634 in epoch 9, gen_loss = 1.1006169963070727, disc_loss = 0.0006668724217860021
Trained batch 635 in epoch 9, gen_loss = 1.1007353811518952, disc_loss = 0.0006660316493762137
Trained batch 636 in epoch 9, gen_loss = 1.1005631282902213, disc_loss = 0.0006653904665782908
Trained batch 637 in epoch 9, gen_loss = 1.100493164645467, disc_loss = 0.0006649542005089816
Trained batch 638 in epoch 9, gen_loss = 1.1002542502443555, disc_loss = 0.00066450230117258
Trained batch 639 in epoch 9, gen_loss = 1.1000022095628084, disc_loss = 0.0006638889543523873
Trained batch 640 in epoch 9, gen_loss = 1.0996771649153854, disc_loss = 0.0006633110203499276
Trained batch 641 in epoch 9, gen_loss = 1.0994695488166215, disc_loss = 0.0006627925266291419
Trained batch 642 in epoch 9, gen_loss = 1.099176212287802, disc_loss = 0.0006621851493401886
Trained batch 643 in epoch 9, gen_loss = 1.0992814840182015, disc_loss = 0.000661450458549253
Trained batch 644 in epoch 9, gen_loss = 1.099163819560709, disc_loss = 0.0006607608732161862
Trained batch 645 in epoch 9, gen_loss = 1.0990650409330893, disc_loss = 0.0006600826611258875
Trained batch 646 in epoch 9, gen_loss = 1.0988573282726766, disc_loss = 0.0006594942587052999
Trained batch 647 in epoch 9, gen_loss = 1.0985763182426675, disc_loss = 0.0006587582293372022
Trained batch 648 in epoch 9, gen_loss = 1.0983998210661583, disc_loss = 0.0006581595802532749
Trained batch 649 in epoch 9, gen_loss = 1.0983626150167904, disc_loss = 0.000657633259733512
Trained batch 650 in epoch 9, gen_loss = 1.0983937919231421, disc_loss = 0.0006570993712553347
Trained batch 651 in epoch 9, gen_loss = 1.0981152249625856, disc_loss = 0.0006566861070635582
Trained batch 652 in epoch 9, gen_loss = 1.0977375010801493, disc_loss = 0.0006568791291568247
Trained batch 653 in epoch 9, gen_loss = 1.0976084828012216, disc_loss = 0.000656907799410643
Trained batch 654 in epoch 9, gen_loss = 1.0974555332242077, disc_loss = 0.0006567110501355065
Trained batch 655 in epoch 9, gen_loss = 1.0976854024863825, disc_loss = 0.0006561465583239978
Trained batch 656 in epoch 9, gen_loss = 1.0978514752612991, disc_loss = 0.0006556642969083814
Trained batch 657 in epoch 9, gen_loss = 1.0978750468749767, disc_loss = 0.0006551470791275781
Trained batch 658 in epoch 9, gen_loss = 1.0979460635206948, disc_loss = 0.0006545149241786977
Trained batch 659 in epoch 9, gen_loss = 1.0981804714058385, disc_loss = 0.0006538634641456707
Trained batch 660 in epoch 9, gen_loss = 1.0982443435109148, disc_loss = 0.000653233403066908
Trained batch 661 in epoch 9, gen_loss = 1.0982964777154145, disc_loss = 0.0006527132047701654
Trained batch 662 in epoch 9, gen_loss = 1.0979268375565023, disc_loss = 0.0006521223260764542
Trained batch 663 in epoch 9, gen_loss = 1.0983889247459102, disc_loss = 0.0006513527869612451
Trained batch 664 in epoch 9, gen_loss = 1.0981937204984793, disc_loss = 0.0006507903258810765
Trained batch 665 in epoch 9, gen_loss = 1.0980707773038216, disc_loss = 0.0006504827821505775
Trained batch 666 in epoch 9, gen_loss = 1.0979756137420391, disc_loss = 0.0006502811024577226
Trained batch 667 in epoch 9, gen_loss = 1.0979467135168122, disc_loss = 0.0006498923326824536
Trained batch 668 in epoch 9, gen_loss = 1.0980928718420067, disc_loss = 0.0006492446140143066
Trained batch 669 in epoch 9, gen_loss = 1.0980453773220973, disc_loss = 0.0006485417231012991
Trained batch 670 in epoch 9, gen_loss = 1.0979554582992361, disc_loss = 0.0006478740895182087
Trained batch 671 in epoch 9, gen_loss = 1.0977137490574802, disc_loss = 0.0006471746100400889
Trained batch 672 in epoch 9, gen_loss = 1.0975355970027012, disc_loss = 0.0006465436721309351
Trained batch 673 in epoch 9, gen_loss = 1.0975433295310781, disc_loss = 0.0006457613264328838
Trained batch 674 in epoch 9, gen_loss = 1.0972161473168267, disc_loss = 0.000645022173897208
Trained batch 675 in epoch 9, gen_loss = 1.0969708385552175, disc_loss = 0.0006444335584350505
Trained batch 676 in epoch 9, gen_loss = 1.0972767400952879, disc_loss = 0.0006438845624577872
Trained batch 677 in epoch 9, gen_loss = 1.097340920330149, disc_loss = 0.0006433423015153877
Trained batch 678 in epoch 9, gen_loss = 1.0972912416893534, disc_loss = 0.0006428367845613451
Trained batch 679 in epoch 9, gen_loss = 1.0971350776798585, disc_loss = 0.0006421898284636828
Trained batch 680 in epoch 9, gen_loss = 1.0970013020847338, disc_loss = 0.0006415676140401987
Trained batch 681 in epoch 9, gen_loss = 1.0967436946731859, disc_loss = 0.0006409075704514686
Trained batch 682 in epoch 9, gen_loss = 1.0967127751466297, disc_loss = 0.0006401273222946279
Trained batch 683 in epoch 9, gen_loss = 1.0968380141676517, disc_loss = 0.0006395355298645776
Trained batch 684 in epoch 9, gen_loss = 1.0968386288106877, disc_loss = 0.0006390521834123485
Trained batch 685 in epoch 9, gen_loss = 1.0965869471039786, disc_loss = 0.0006387344644968018
Trained batch 686 in epoch 9, gen_loss = 1.0966294168384836, disc_loss = 0.000638399091311134
Trained batch 687 in epoch 9, gen_loss = 1.0965933031294235, disc_loss = 0.0006379917612173093
Trained batch 688 in epoch 9, gen_loss = 1.0965655337051314, disc_loss = 0.0006377900510589445
Trained batch 689 in epoch 9, gen_loss = 1.0962062449558923, disc_loss = 0.0006472739580625573
Trained batch 690 in epoch 9, gen_loss = 1.0963303722797013, disc_loss = 0.0006624529510829126
Trained batch 691 in epoch 9, gen_loss = 1.0966640849506235, disc_loss = 0.0007327292290086537
Trained batch 692 in epoch 9, gen_loss = 1.096568296224008, disc_loss = 0.0008424435303374133
Trained batch 693 in epoch 9, gen_loss = 1.0969852543186385, disc_loss = 0.001013653225433021
Trained batch 694 in epoch 9, gen_loss = 1.0966891402820889, disc_loss = 0.0011288544431742509
Trained batch 695 in epoch 9, gen_loss = 1.0968681501074768, disc_loss = 0.0012906809008890031
Trained batch 696 in epoch 9, gen_loss = 1.096774111604759, disc_loss = 0.0014655029888181656
Trained batch 697 in epoch 9, gen_loss = 1.0968920391234422, disc_loss = 0.0016299095338990679
Trained batch 698 in epoch 9, gen_loss = 1.0975511729802525, disc_loss = 0.0017620679458031346
Trained batch 699 in epoch 9, gen_loss = 1.097442016175815, disc_loss = 0.0018299720556699736
Trained batch 700 in epoch 9, gen_loss = 1.0975354465200284, disc_loss = 0.0018594826900421146
Trained batch 701 in epoch 9, gen_loss = 1.0973603547977926, disc_loss = 0.0018773039914971082
Trained batch 702 in epoch 9, gen_loss = 1.097275001819578, disc_loss = 0.00189048474711107
Trained batch 703 in epoch 9, gen_loss = 1.0971439590000294, disc_loss = 0.0018931239859202005
Trained batch 704 in epoch 9, gen_loss = 1.0970842766423596, disc_loss = 0.0018967894894023037
Trained batch 705 in epoch 9, gen_loss = 1.0972344307149773, disc_loss = 0.0018978117521884904
Trained batch 706 in epoch 9, gen_loss = 1.0972677835986504, disc_loss = 0.001897879615764442
Trained batch 707 in epoch 9, gen_loss = 1.097374404470126, disc_loss = 0.0018990535436335906
Trained batch 708 in epoch 9, gen_loss = 1.0972789688238136, disc_loss = 0.001899134671529499
Trained batch 709 in epoch 9, gen_loss = 1.097220145732584, disc_loss = 0.0018981553385203087
Trained batch 710 in epoch 9, gen_loss = 1.097055435096832, disc_loss = 0.0018975664354536916
Trained batch 711 in epoch 9, gen_loss = 1.0971281793847512, disc_loss = 0.0018970655618728272
Trained batch 712 in epoch 9, gen_loss = 1.0972602164260468, disc_loss = 0.001897620311235326
Trained batch 713 in epoch 9, gen_loss = 1.0971840667624433, disc_loss = 0.001897407927890654
Trained batch 714 in epoch 9, gen_loss = 1.097024436680587, disc_loss = 0.0018972811825415511
Trained batch 715 in epoch 9, gen_loss = 1.0970264063034643, disc_loss = 0.0018968814033414978
Trained batch 716 in epoch 9, gen_loss = 1.0968167012871726, disc_loss = 0.0018963905305572756
Trained batch 717 in epoch 9, gen_loss = 1.0966737032102676, disc_loss = 0.001895627763486645
Trained batch 718 in epoch 9, gen_loss = 1.0969492934012115, disc_loss = 0.0018940839310063655
Trained batch 719 in epoch 9, gen_loss = 1.096848005635871, disc_loss = 0.001892321582413893
Trained batch 720 in epoch 9, gen_loss = 1.097153464153967, disc_loss = 0.001890796601985279
Trained batch 721 in epoch 9, gen_loss = 1.0972203444741109, disc_loss = 0.0018893929886355301
Trained batch 722 in epoch 9, gen_loss = 1.097492699718739, disc_loss = 0.001888365448364134
Trained batch 723 in epoch 9, gen_loss = 1.0973094432558144, disc_loss = 0.001886827406326009
Trained batch 724 in epoch 9, gen_loss = 1.0972905067739815, disc_loss = 0.0018853765481818018
Trained batch 725 in epoch 9, gen_loss = 1.0975097091894177, disc_loss = 0.0018843366185736525
Trained batch 726 in epoch 9, gen_loss = 1.0971728282092854, disc_loss = 0.0018853492614455416
Trained batch 727 in epoch 9, gen_loss = 1.097004991884415, disc_loss = 0.0018853834391228412
Trained batch 728 in epoch 9, gen_loss = 1.0969263420674045, disc_loss = 0.001884911999000851
Trained batch 729 in epoch 9, gen_loss = 1.096905564037088, disc_loss = 0.0018834877497483082
Trained batch 730 in epoch 9, gen_loss = 1.096942550588078, disc_loss = 0.0018825479485112065
Trained batch 731 in epoch 9, gen_loss = 1.096717133955226, disc_loss = 0.001881329775443574
Trained batch 732 in epoch 9, gen_loss = 1.0967303625883542, disc_loss = 0.0018799876079964165
Trained batch 733 in epoch 9, gen_loss = 1.096660262476196, disc_loss = 0.0018781055247261093
Trained batch 734 in epoch 9, gen_loss = 1.096562533719199, disc_loss = 0.001876329283010639
Trained batch 735 in epoch 9, gen_loss = 1.096357599062764, disc_loss = 0.0018748443388611358
Trained batch 736 in epoch 9, gen_loss = 1.096197362670743, disc_loss = 0.0018738635326285495
Trained batch 737 in epoch 9, gen_loss = 1.0962920536193743, disc_loss = 0.0018725648515396827
Trained batch 738 in epoch 9, gen_loss = 1.0963773245095239, disc_loss = 0.0018714486974150042
Trained batch 739 in epoch 9, gen_loss = 1.0966565140195794, disc_loss = 0.0018699521032701611
Trained batch 740 in epoch 9, gen_loss = 1.0970352268733798, disc_loss = 0.0018687017497287023
Trained batch 741 in epoch 9, gen_loss = 1.0968250115766036, disc_loss = 0.0018675079327564613
Trained batch 742 in epoch 9, gen_loss = 1.0965517957470459, disc_loss = 0.001866574816635
Trained batch 743 in epoch 9, gen_loss = 1.0966328863975823, disc_loss = 0.001865708587502013
Trained batch 744 in epoch 9, gen_loss = 1.0965997203884508, disc_loss = 0.0018641258007651444
Trained batch 745 in epoch 9, gen_loss = 1.0967637876563034, disc_loss = 0.0018621901391068132
Trained batch 746 in epoch 9, gen_loss = 1.0967686100497622, disc_loss = 0.0018602886059814864
Trained batch 747 in epoch 9, gen_loss = 1.0968801776833712, disc_loss = 0.0018584005231198663
Trained batch 748 in epoch 9, gen_loss = 1.0968508035223061, disc_loss = 0.0018567338584338157
Trained batch 749 in epoch 9, gen_loss = 1.0966153852939606, disc_loss = 0.0018556864664618236
Trained batch 750 in epoch 9, gen_loss = 1.0965433300890712, disc_loss = 0.0018548539330038526
Trained batch 751 in epoch 9, gen_loss = 1.0965911133333723, disc_loss = 0.0018543528156713248
Trained batch 752 in epoch 9, gen_loss = 1.0965962450342823, disc_loss = 0.0018531716227753133
Trained batch 753 in epoch 9, gen_loss = 1.096410967389848, disc_loss = 0.0018535672590071373
Trained batch 754 in epoch 9, gen_loss = 1.0967615080985011, disc_loss = 0.001853040534488715
Trained batch 755 in epoch 9, gen_loss = 1.0969476328482703, disc_loss = 0.001851857887097005
Trained batch 756 in epoch 9, gen_loss = 1.0968955979636985, disc_loss = 0.001850163797474075
Trained batch 757 in epoch 9, gen_loss = 1.096810978367964, disc_loss = 0.0018482461308031147
Trained batch 758 in epoch 9, gen_loss = 1.096760016577674, disc_loss = 0.001846566380048999
Trained batch 759 in epoch 9, gen_loss = 1.096724190602177, disc_loss = 0.0018450086833150922
Trained batch 760 in epoch 9, gen_loss = 1.096444723483924, disc_loss = 0.0018437270840310825
Trained batch 761 in epoch 9, gen_loss = 1.0968012051006628, disc_loss = 0.0018423872105839902
Trained batch 762 in epoch 9, gen_loss = 1.096797028187843, disc_loss = 0.001840934874725633
Trained batch 763 in epoch 9, gen_loss = 1.0971536364854944, disc_loss = 0.0018389511947205879
Trained batch 764 in epoch 9, gen_loss = 1.096908637277441, disc_loss = 0.0018379648360827012
Trained batch 765 in epoch 9, gen_loss = 1.0969543458587507, disc_loss = 0.0018369356100880615
Trained batch 766 in epoch 9, gen_loss = 1.0969857925541864, disc_loss = 0.0018357161210791901
Trained batch 767 in epoch 9, gen_loss = 1.0967757486117382, disc_loss = 0.0018339732889103288
Trained batch 768 in epoch 9, gen_loss = 1.0965151501570007, disc_loss = 0.001832858526883786
Trained batch 769 in epoch 9, gen_loss = 1.0967919221172084, disc_loss = 0.0018318227088787932
Trained batch 770 in epoch 9, gen_loss = 1.0967727670719032, disc_loss = 0.0018303390862349236
Trained batch 771 in epoch 9, gen_loss = 1.0966845821840159, disc_loss = 0.0018288982444036562
Trained batch 772 in epoch 9, gen_loss = 1.096689244291298, disc_loss = 0.0018271407560557717
Trained batch 773 in epoch 9, gen_loss = 1.0966947291248528, disc_loss = 0.001825428229278508
Trained batch 774 in epoch 9, gen_loss = 1.0966036773497059, disc_loss = 0.0018234920855649116
Trained batch 775 in epoch 9, gen_loss = 1.0965835518136466, disc_loss = 0.0018220975329613699
Trained batch 776 in epoch 9, gen_loss = 1.0965368875051864, disc_loss = 0.0018208297784028196
Trained batch 777 in epoch 9, gen_loss = 1.0965816252948692, disc_loss = 0.0018190776072117825
Trained batch 778 in epoch 9, gen_loss = 1.0966107272979384, disc_loss = 0.0018170965183399253
Trained batch 779 in epoch 9, gen_loss = 1.096397829055786, disc_loss = 0.0018154338669167677
Trained batch 780 in epoch 9, gen_loss = 1.0968195804407899, disc_loss = 0.0018140037741239878
Trained batch 781 in epoch 9, gen_loss = 1.0970587337108524, disc_loss = 0.001812518054801498
Trained batch 782 in epoch 9, gen_loss = 1.0970547488518296, disc_loss = 0.0018114244070379564
Trained batch 783 in epoch 9, gen_loss = 1.0971078492549, disc_loss = 0.0018103659194078931
Trained batch 784 in epoch 9, gen_loss = 1.0969113921663565, disc_loss = 0.0018085613075063925
Trained batch 785 in epoch 9, gen_loss = 1.0969509866856437, disc_loss = 0.0018064715453823756
Trained batch 786 in epoch 9, gen_loss = 1.0970443895387225, disc_loss = 0.0018044935764466488
Trained batch 787 in epoch 9, gen_loss = 1.0969787470731638, disc_loss = 0.0018027290124923339
Trained batch 788 in epoch 9, gen_loss = 1.0972533812994285, disc_loss = 0.001801202108053501
Trained batch 789 in epoch 9, gen_loss = 1.0970368681074698, disc_loss = 0.0017999685011160136
Testing Epoch 9